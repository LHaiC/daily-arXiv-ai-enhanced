<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 53]
- [cs.CL](#cs.CL) [Total: 93]
- [eess.SY](#eess.SY) [Total: 12]
- [cs.DC](#cs.DC) [Total: 5]
- [cs.NE](#cs.NE) [Total: 1]
- [cs.LO](#cs.LO) [Total: 2]
- [eess.SP](#eess.SP) [Total: 13]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 7]
- [cs.ET](#cs.ET) [Total: 1]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.RO](#cs.RO) [Total: 17]
- [physics.app-ph](#physics.app-ph) [Total: 4]
- [cs.DS](#cs.DS) [Total: 10]
- [cs.LG](#cs.LG) [Total: 51]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 17]
- [quant-ph](#quant-ph) [Total: 48]
- [cs.GR](#cs.GR) [Total: 3]
- [cs.SI](#cs.SI) [Total: 3]
- [cs.AI](#cs.AI) [Total: 18]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Facial Emotion Recognition does not detect feeling unsafe in automated driving](https://arxiv.org/abs/2509.04490)
*Abel van Elburg,Konstantinos Gkentsidis,Mathieu Sarrazin,Sarah Barendswaard,Varun Kotian,Riender Happee*

Main category: cs.CV

TL;DR: 本研究通过模拟驾驶实验，探讨了自动驾驶风格和行人干扰对乘客感知风险的影响，并尝试使用生理信号和面部表情来评估风险，最终提出一种基于车辆运动和皮肤电导率的神经网络模型来客观评估风险。


<details>
  <summary>Details</summary>
Motivation: 为了理解公众对自动驾驶车辆的接受度，需要研究影响其感知风险和安全感的因素，特别是自动驾驶风格和行人等关键互动情境。

Method: 进行了驾驶模拟实验，收集了32名参与者的主观舒适度评分、生理信号（皮肤电导率、心率）、眼动追踪数据以及面部表情，并比较了动态和静态两种驾驶风格，以及是否引入穿越行人两种情境，最后构建了基于车辆运动和皮肤电导率的神经网络模型。

Result: 主观风险评分显示，在过弯和刹车时感知风险最高，之后会缓解。动态驾驶风格比静态驾驶风格引起更强烈的不适。穿越行人对静态驾驶风格的不适影响不大，但对动态驾驶风格的不适加倍。面部表情分析显示，大多数参与者在关键事件中没有明显面部反应，恐惧表情从未占主导，表明面部表情识别作为风险评估方法不可靠。神经网络模型能较好地预测感知风险。

Conclusion: 自动驾驶车辆的感知风险对驾驶风格和关键互动情境（如行人出现）很敏感。面部表情识别不适合评估自动驾驶车辆中的感知风险。基于车辆运动和皮肤电导率的神经网络模型能够客观地评估感知风险，减少主观偏差，为未来的研究指明了方向。

Abstract: Trust and perceived safety play a crucial role in the public acceptance of
automated vehicles. To understand perceived risk, an experiment was conducted
using a driving simulator under two automated driving styles and optionally
introducing a crossing pedestrian. Data was collected from 32 participants,
consisting of continuous subjective comfort ratings, motion, webcam footage for
facial expression, skin conductance, heart rate, and eye tracking. The
continuous subjective perceived risk ratings showed significant discomfort
associated with perceived risk during cornering and braking followed by relief
or even positive comfort on continuing the ride. The dynamic driving style
induced a stronger discomfort as compared to the calm driving style. The
crossing pedestrian did not affect discomfort with the calm driving style but
doubled the comfort decrement with the dynamic driving style. This illustrates
the importance of consequences of critical interactions in risk perception.
Facial expression was successfully analyzed for 24 participants but most
(15/24) did not show any detectable facial reaction to the critical event.
Among the 9 participants who did, 8 showed a Happy expression, and only 4
showed a Surprise expression. Fear was never dominant. This indicates that
facial expression recognition is not a reliable method for assessing perceived
risk in automated vehicles. To predict perceived risk a neural network model
was implemented using vehicle motion and skin conductance. The model correlated
well with reported perceived risk, demonstrating its potential for objective
perceived risk assessment in automated vehicles, reducing subjective bias and
highlighting areas for future research.

</details>


### [2] [PromptEnhancer: A Simple Approach to Enhance Text-to-Image Models via Chain-of-Thought Prompt Rewriting](https://arxiv.org/abs/2509.04545)
*Linqing Wang,Ximing Xing,Yiji Cheng,Zhiyuan Zhao,Jiale Tao,Qixun Wang,Ruihuang Li,Xin Li,Mingrui Wu,Xinchi Deng,Chunyu Wang,Qinglin Lu*

Main category: cs.CV

TL;DR: PromptEnhancer是一个新颖的提示重写框架，通过训练一个基于强化学习的链式思考（CoT）重写器，并利用一个名为AlignEvaluator的奖励模型来指导，以解决文本到图像（T2I）模型在处理复杂提示时的挑战，从而提高图像-文本的一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像（T2I）模型在生成高保真图像方面表现出色，但在处理复杂的提示，特别是属性绑定、否定和组合关系时，常常难以准确渲染用户意图，导致用户意图与生成图像之间存在显著差距。

Method: 提出PromptEnhancer框架，通过强化学习训练一个链式思考（CoT）重写器。该重写器由一个名为AlignEvaluator的奖励模型指导，该模型基于对24个关键点的系统性分类，提供明确的、细粒度的反馈。重写器与生成器分离，无需修改预训练T2I模型的权重。

Result: 在HunyuanImage 2.1模型上的大量实验表明，PromptEnhancer在解决语义和组合挑战方面显著提高了图像-文本的一致性。此外，还引入了一个新的高质量人类偏好基准。

Conclusion: PromptEnhancer是一个通用且有效的框架，通过优化提示来提高T2I模型的性能，解决了现有方法在处理复杂提示方面的不足，并为未来研究提供了新的基准。

Abstract: Recent advancements in text-to-image (T2I) diffusion models have demonstrated
remarkable capabilities in generating high-fidelity images. However, these
models often struggle to faithfully render complex user prompts, particularly
in aspects like attribute binding, negation, and compositional relationships.
This leads to a significant mismatch between user intent and the generated
output. To address this challenge, we introduce PromptEnhancer, a novel and
universal prompt rewriting framework that enhances any pretrained T2I model
without requiring modifications to its weights. Unlike prior methods that rely
on model-specific fine-tuning or implicit reward signals like image-reward
scores, our framework decouples the rewriter from the generator. We achieve
this by training a Chain-of-Thought (CoT) rewriter through reinforcement
learning, guided by a dedicated reward model we term the AlignEvaluator. The
AlignEvaluator is trained to provide explicit and fine-grained feedback based
on a systematic taxonomy of 24 key points, which are derived from a
comprehensive analysis of common T2I failure modes. By optimizing the CoT
rewriter to maximize the reward from our AlignEvaluator, our framework learns
to generate prompts that are more precisely interpreted by T2I models.
Extensive experiments on the HunyuanImage 2.1 model demonstrate that
PromptEnhancer significantly improves image-text alignment across a wide range
of semantic and compositional challenges. Furthermore, we introduce a new,
high-quality human preference benchmark to facilitate future research in this
direction.

</details>


### [3] [Skywork UniPic 2.0: Building Kontext Model with Online RL for Unified Multimodal Model](https://arxiv.org/abs/2509.04548)
*Hongyang Wei,Baixin Xu,Hongbo Liu,Cyrus Wu,Jie Liu,Yi Peng,Peiyu Wang,Zexiang Liu,Jingwen He,Yidan Xietian,Chuanxin Tang,Zidong Wang,Yichen Wei,Liang Hu,Boyi Jiang,William Li,Ying He,Yang Liu,Xuchen Song,Eric Li,Yahui Zhou*

Main category: cs.CV

TL;DR: UniPic2-SD3.5M-Kontext是一个基于SD3.5-Medium的2B参数DiT模型，通过架构修改、大规模预训练和创新的渐进式双任务强化（PDTR）策略，实现了顶尖的图像生成和编辑能力，并且超越了参数量更大的模型。在此基础上，UniPic2-Metaquery进一步集成了视觉理解、生成和编辑能力，展示了所提出训练范式（Skywork UniPic 2.0）的有效性和通用性。


<details>
  <summary>Details</summary>
Motivation: 现有开源多模态模型主要关注扩大模型参数量而非优化训练策略，限制了效率和性能。本文旨在提出一种更高效、性能更优的训练方法。

Method: 本文提出了UniPic2-SD3.5M-Kontext模型，通过修改SD3.5-Medium架构，在大规模高质量数据上进行预训练，并引入渐进式双任务强化（PDTR）策略来增强指令跟随和编辑一致性。随后，通过连接器将UniPic2-SD3.5M-Kontext与Qwen2.5-VL-7B进行联合训练，构建了UniPic2-Metaquery统一多模态模型。

Result: UniPic2-SD3.5M-Kontext在图像生成和编辑能力上优于BAGEL (7B) 和Flux-Kontext (12B) 等参数量更大的模型。UniPic2-Metaquery集成了理解、生成和编辑能力，在多项任务上达到了顶尖水平。

Conclusion: 本文提出的Skywork UniPic 2.0训练范式，通过UniPic2-SD3.5M-Kontext和UniPic2-Metaquery的验证，证明了其在提高模型效率、性能以及实现统一多模态能力方面的有效性和可扩展性。

Abstract: Recent advances in multimodal models have demonstrated impressive
capabilities in unified image generation and editing. However, many prominent
open-source models prioritize scaling model parameters over optimizing training
strategies, limiting their efficiency and performance. In this work, we present
UniPic2-SD3.5M-Kontext, a 2B-parameter DiT model based on SD3.5-Medium, which
achieves state-of-the-art image generation and editing while extending
seamlessly into a unified multimodal framework. Our approach begins with
architectural modifications to SD3.5-Medium and large-scale pre-training on
high-quality data, enabling joint text-to-image generation and editing
capabilities. To enhance instruction following and editing consistency, we
propose a novel Progressive Dual-Task Reinforcement strategy (PDTR), which
effectively strengthens both tasks in a staged manner. We empirically validate
that the reinforcement phases for different tasks are mutually beneficial and
do not induce negative interference. After pre-training and reinforcement
strategies, UniPic2-SD3.5M-Kontext demonstrates stronger image generation and
editing capabilities than models with significantly larger generation
parameters-including BAGEL (7B) and Flux-Kontext (12B). Furthermore, following
the MetaQuery, we connect the UniPic2-SD3.5M-Kontext and Qwen2.5-VL-7B via a
connector and perform joint training to launch a unified multimodal model
UniPic2-Metaquery. UniPic2-Metaquery integrates understanding, generation, and
editing, achieving top-tier performance across diverse tasks with a simple and
scalable training paradigm. This consistently validates the effectiveness and
generalizability of our proposed training paradigm, which we formalize as
Skywork UniPic 2.0.

</details>


### [4] [UAV-Based Intelligent Traffic Surveillance System: Real-Time Vehicle Detection, Classification, Tracking, and Behavioral Analysis](https://arxiv.org/abs/2509.04624)
*Ali Khanpour,Tianyi Wang,Afra Vahidi-Shams,Wim Ectors,Farzam Nakhaie,Amirhossein Taheri,Christian Claudel*

Main category: cs.CV

TL;DR: 本文介绍了一种基于无人机（UAV）的交通监控系统，用于解决传统交通监控系统的局限性，并能准确地检测、分类、跟踪和分析车辆行为。


<details>
  <summary>Details</summary>
Motivation: 传统交通监控系统在覆盖范围、适应性和可扩展性方面存在不足，而城市交通拥堵和违规行为对城市交通和道路安全构成了重大挑战。

Method: 该系统利用多尺度、多角度模板匹配、卡尔曼滤波和基于单应性的校准来处理从约200米高空收集的航空视频数据。通过融合地理围栏、运动滤波和轨迹偏差分析来检测不安全变道、违规双排停车和侵占人行道等违规行为。

Result: 在城市地区的案例研究中，该系统实现了91.8%的检测精度、90.5%的F1分数，以及92.1%和93.7%的跟踪指标（MOTA/MOTP）。该系统还能对五种车辆类型进行分类，并自动检测关键的交通违规行为。

Conclusion: 实验结果证实了该系统的可扩展性、准确性和实用性，显示了其作为下一代智慧城市中独立于基础设施的、能进行执法感知的交通监控解决方案的潜力。

Abstract: Traffic congestion and violations pose significant challenges for urban
mobility and road safety. Traditional traffic monitoring systems, such as fixed
cameras and sensor-based methods, are often constrained by limited coverage,
low adaptability, and poor scalability. To address these challenges, this paper
introduces an advanced unmanned aerial vehicle (UAV)-based traffic surveillance
system capable of accurate vehicle detection, classification, tracking, and
behavioral analysis in real-world, unconstrained urban environments. The system
leverages multi-scale and multi-angle template matching, Kalman filtering, and
homography-based calibration to process aerial video data collected from
altitudes of approximately 200 meters. A case study in urban area demonstrates
robust performance, achieving a detection precision of 91.8%, an F1-score of
90.5%, and tracking metrics (MOTA/MOTP) of 92.1% and 93.7%, respectively.
Beyond precise detection, the system classifies five vehicle types and
automatically detects critical traffic violations, including unsafe lane
changes, illegal double parking, and crosswalk obstructions, through the fusion
of geofencing, motion filtering, and trajectory deviation analysis. The
integrated analytics module supports origin-destination tracking, vehicle count
visualization, inter-class correlation analysis, and heatmap-based congestion
modeling. Additionally, the system enables entry-exit trajectory profiling,
vehicle density estimation across road segments, and movement direction
logging, supporting comprehensive multi-scale urban mobility analytics.
Experimental results confirms the system's scalability, accuracy, and practical
relevance, highlighting its potential as an enforcement-aware,
infrastructure-independent traffic monitoring solution for next-generation
smart cities.

</details>


### [5] [Inpaint4Drag: Repurposing Inpainting Models for Drag-Based Image Editing via Bidirectional Warping](https://arxiv.org/abs/2509.04582)
*Jingyi Lu,Kai Han*

Main category: cs.CV

TL;DR: Inpaint4Drag 通过像素级双向扭曲和图像修复，实现了拖拽式图像编辑的实时预览和高效修复，并能适配任何修复模型。


<details>
  <summary>Details</summary>
Motivation: 现有拖拽式图像编辑方法在潜在空间操作，存在精度有限、反馈延迟和模型依赖等问题。本研究旨在提出一种新的框架，以提高编辑精度、实时反馈并减少模型依赖。

Method: 将拖拽式编辑分解为像素空间中的双向扭曲和图像修复。将图像区域视为可变形材料，以模拟物理世界的弹性形变。

Result: 实现了 512x512 分辨率下 0.01 秒的实时扭曲预览和 0.3 秒的高效修复，显著优于需要数分钟才能完成一次编辑的现有方法。该方法可作为通用适配器，支持任何修复模型，并继承未来修复技术的改进。

Conclusion: Inpaint4Drag 在视觉质量和控制精度方面均表现出色，同时保持实时性能，为拖拽式图像编辑提供了更优的交互体验。

Abstract: Drag-based image editing has emerged as a powerful paradigm for intuitive
image manipulation. However, existing approaches predominantly rely on
manipulating the latent space of generative models, leading to limited
precision, delayed feedback, and model-specific constraints. Accordingly, we
present Inpaint4Drag, a novel framework that decomposes drag-based editing into
pixel-space bidirectional warping and image inpainting. Inspired by elastic
object deformation in the physical world, we treat image regions as deformable
materials that maintain natural shape under user manipulation. Our method
achieves real-time warping previews (0.01s) and efficient inpainting (0.3s) at
512x512 resolution, significantly improving the interaction experience compared
to existing methods that require minutes per edit. By transforming drag inputs
directly into standard inpainting formats, our approach serves as a universal
adapter for any inpainting model without architecture modification,
automatically inheriting all future improvements in inpainting technology.
Extensive experiments demonstrate that our method achieves superior visual
quality and precise control while maintaining real-time performance. Project
page: https://visual-ai.github.io/inpaint4drag/

</details>


### [6] [DisPatch: Disarming Adversarial Patches in Object Detection with Diffusion Models](https://arxiv.org/abs/2509.04597)
*Jin Ma,Mohammed Aldeen,Christopher Salas,Feng Luo,Mashrur Chowdhury,Mert Pesé,Long Cheng*

Main category: cs.CV

TL;DR: DISPATCH是第一个利用扩散模型进行目标检测的防御框架，通过“再生和修正”策略来对抗对抗性补丁攻击，在多种攻击和检测器上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的目标检测器易受对抗性补丁攻击，可能导致严重后果。理想的防御方法应有效、可泛化且能抵抗自适应攻击。

Method: DISPATCH框架利用扩散模型的生成能力再生整个图像，然后通过修正过程识别并用生成的无害部分替换对抗性区域。

Result: DISPATCH在隐藏攻击和创建攻击方面均优于最先进的防御方法，在隐藏攻击上达到了89.3%的最佳mAP.5分数，在非目标创建攻击上将攻击成功率降至24.8%。它还能抵抗自适应攻击。

Conclusion: DISPATCH是一种首创的、基于扩散模型的防御框架，通过“再生和修正”策略有效地防御了各种对抗性补丁攻击，并保持了对自适应攻击的鲁棒性，可作为目标检测系统的实用可靠的防御方案。

Abstract: Object detection is fundamental to various real-world applications, such as
security monitoring and surveillance video analysis. Despite their
advancements, state-of-theart object detectors are still vulnerable to
adversarial patch attacks, which can be easily applied to real-world objects to
either conceal actual items or create non-existent ones, leading to severe
consequences. Given the current diversity of adversarial patch attacks and
potential unknown threats, an ideal defense method should be effective,
generalizable, and robust against adaptive attacks. In this work, we introduce
DISPATCH, the first diffusion-based defense framework for object detection.
Unlike previous works that aim to "detect and remove" adversarial patches,
DISPATCH adopts a "regenerate and rectify" strategy, leveraging generative
models to disarm attack effects while preserving the integrity of the input
image. Specifically, we utilize the in-distribution generative power of
diffusion models to regenerate the entire image, aligning it with benign data.
A rectification process is then employed to identify and replace adversarial
regions with their regenerated benign counterparts. DISPATCH is attack-agnostic
and requires no prior knowledge of the existing patches. Extensive experiments
across multiple detectors and attacks demonstrate that DISPATCH consistently
outperforms state-of-the-art defenses on both hiding attacks and creating
attacks, achieving the best overall mAP.5 score of 89.3% on hiding attacks, and
lowering the attack success rate to 24.8% on untargeted creating attacks.
Moreover, it maintains strong robustness against adaptive attacks, making it a
practical and reliable defense for object detection systems.

</details>


### [7] [WATCH: World-aware Allied Trajectory and pose reconstruction for Camera and Human](https://arxiv.org/abs/2509.04600)
*Qijun Ying,Zhongyuan Hu,Rui Zhang,Ronghui Li,Yu Lu,Zijiao Zeng*

Main category: cs.CV

TL;DR: WATCH是一个用于从单眼视频中进行全局人类运动重建的统一框架，解决了相机方向和相机平移信息利用不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的人类运动重建方法在利用相机方向信息和整合相机平移线索方面存在不足，限制了其在VR、图形和机器人等领域的应用。

Method: WATCH框架通过分析性航向角分解技术来提高效率和可扩展性，并引入受世界模型启发的相机轨迹整合机制来利用相机平移信息。

Result: 在野外数据集上的实验表明，WATCH在端到端的轨迹重建方面取得了最先进的性能。

Conclusion: 联合建模相机-人类运动关系对于解决相机平移整合的长期挑战是有效的，并为全局人类运动重建提供了新的见解。

Abstract: Global human motion reconstruction from in-the-wild monocular videos is
increasingly demanded across VR, graphics, and robotics applications, yet
requires accurate mapping of human poses from camera to world coordinates-a
task challenged by depth ambiguity, motion ambiguity, and the entanglement
between camera and human movements. While human-motion-centric approaches excel
in preserving motion details and physical plausibility, they suffer from two
critical limitations: insufficient exploitation of camera orientation
information and ineffective integration of camera translation cues. We present
WATCH (World-aware Allied Trajectory and pose reconstruction for Camera and
Human), a unified framework addressing both challenges. Our approach introduces
an analytical heading angle decomposition technique that offers superior
efficiency and extensibility compared to existing geometric methods.
Additionally, we design a camera trajectory integration mechanism inspired by
world models, providing an effective pathway for leveraging camera translation
information beyond naive hard-decoding approaches. Through experiments on
in-the-wild benchmarks, WATCH achieves state-of-the-art performance in
end-to-end trajectory reconstruction. Our work demonstrates the effectiveness
of jointly modeling camera-human motion relationships and offers new insights
for addressing the long-standing challenge of camera translation integration in
global human motion reconstruction. The code will be available publicly.

</details>


### [8] [Sali4Vid: Saliency-Aware Video Reweighting and Adaptive Caption Retrieval for Dense Video Captioning](https://arxiv.org/abs/2509.04602)
*MinJu Jeon,Si-Woo Kim,Ye-Chan Kim,HyunGee Kim,Dong-Jin Kim*

Main category: cs.CV

TL;DR: Sali4Vid是一个用于视频描述的框架，通过帧重要性加权和基于语义的自适应检索来解决现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有视频描述方法在时间戳监督和视频分块方面存在不足，本文旨在解决这些问题。

Method: 提出了一种名为Sali4Vid的框架，包括Saliency-aware Video Reweighting（将时间戳注释转换为帧重要性权重）和Semantic-based Adaptive Caption Retrieval（通过帧相似度分割视频以捕捉场景转换和改进标题检索）。

Result: Sali4Vid在YouCook2和ViTT数据集上取得了最先进的成果。

Conclusion: 联合改进视频加权和检索对于视频描述至关重要。

Abstract: Dense video captioning aims to temporally localize events in video and
generate captions for each event. While recent works propose end-to-end models,
they suffer from two limitations: (1) applying timestamp supervision only to
text while treating all video frames equally, and (2) retrieving captions from
fixed-size video chunks, overlooking scene transitions. To address these, we
propose Sali4Vid, a simple yet effective saliency-aware framework. We introduce
Saliency-aware Video Reweighting, which converts timestamp annotations into
sigmoid-based frame importance weights, and Semantic-based Adaptive Caption
Retrieval, which segments videos by frame similarity to capture scene
transitions and improve caption retrieval. Sali4Vid achieves state-of-the-art
results on YouCook2 and ViTT, demonstrating the benefit of jointly improving
video weighting and retrieval for dense video captioning

</details>


### [9] [VCMamba: Bridging Convolutions with Multi-Directional Mamba for Efficient Visual Representation](https://arxiv.org/abs/2509.04669)
*Mustafa Munir,Alex Zhang,Radu Marculescu*

Main category: cs.CV

TL;DR: VCMamba是一种结合了CNN和多向SSM（Mamba）的新型视觉骨干网络，旨在融合CNN的局部特征提取能力和Mamba的长程依赖建模能力，以实现高效的特征表示。


<details>
  <summary>Details</summary>
Motivation: ViTs和SSMs在计算机视觉领域取得了显著进展，但它们在捕捉精细局部特征方面不如CNN，而CNN缺乏全局推理能力。VCMamba旨在结合CNN的局部特征提取和Mamba的长程依赖建模的优点，弥补这一不足。

Method: VCMamba采用卷积“stem”和早期阶段的卷积块来提取局部特征，然后结合多向Mamba块来建模长程依赖和全局上下文。这种混合设计保持了相对于图像分辨率的线性复杂度。

Result: 在ImageNet-1K分类任务上，VCMamba-B达到了82.6%的top-1准确率，参数量比PlainMamba-L3少37%，比Vision GNN-B少64%。在ADE20K语义分割任务上，VCMamba-B获得了47.1 mIoU，比EfficientFormer-L7高2.0 mIoU，同时参数量减少了62%。

Conclusion: VCMamba通过结合CNN和多向Mamba的优势，在图像分类和语义分割任务上都取得了优于现有方法的性能，并且参数效率更高。

Abstract: Recent advances in Vision Transformers (ViTs) and State Space Models (SSMs)
have challenged the dominance of Convolutional Neural Networks (CNNs) in
computer vision. ViTs excel at capturing global context, and SSMs like Mamba
offer linear complexity for long sequences, yet they do not capture
fine-grained local features as effectively as CNNs. Conversely, CNNs possess
strong inductive biases for local features but lack the global reasoning
capabilities of transformers and Mamba. To bridge this gap, we introduce
\textit{VCMamba}, a novel vision backbone that integrates the strengths of CNNs
and multi-directional Mamba SSMs. VCMamba employs a convolutional stem and a
hierarchical structure with convolutional blocks in its early stages to extract
rich local features. These convolutional blocks are then processed by later
stages incorporating multi-directional Mamba blocks designed to efficiently
model long-range dependencies and global context. This hybrid design allows for
superior feature representation while maintaining linear complexity with
respect to image resolution. We demonstrate VCMamba's effectiveness through
extensive experiments on ImageNet-1K classification and ADE20K semantic
segmentation. Our VCMamba-B achieves 82.6% top-1 accuracy on ImageNet-1K,
surpassing PlainMamba-L3 by 0.3% with 37% fewer parameters, and outperforming
Vision GNN-B by 0.3% with 64% fewer parameters. Furthermore, VCMamba-B obtains
47.1 mIoU on ADE20K, exceeding EfficientFormer-L7 by 2.0 mIoU while utilizing
62% fewer parameters. Code is available at
https://github.com/Wertyuui345/VCMamba.

</details>


### [10] [Guideline-Consistent Segmentation via Multi-Agent Refinement](https://arxiv.org/abs/2509.04687)
*Vanshika Vats,Ashwani Rathee,James Davis*

Main category: cs.CV

TL;DR: 本研究提出了一种无需训练的多智能体框架，用于根据复杂的文本指南进行语义分割，解决了传统方法需要重复训练和现有方法无法处理长指南的问题。


<details>
  <summary>Details</summary>
Motivation: 传统的语义分割方法在遵循复杂、长篇幅的文本标签指南方面存在困难，并且需要为不断变化的指南进行昂贵的、特定任务的重新训练。现有的开放词汇分割方法虽然在简单提示下表现良好，但在处理段落长度的指南时表现不佳。

Method: 提出一个多智能体、无需训练的框架，采用迭代的‘工人-监督’（Worker-Supervisor）优化架构。‘工人’负责分割，‘监督’根据检索到的指南进行评估，并通过轻量级强化学习停止策略决定何时终止循环，以确保分割结果符合指南且资源消耗得到平衡。

Result: 在Waymo和ReasonSeg数据集上的评估结果表明，该方法显著优于最先进的基线方法，展现出强大的泛化能力和指令遵循能力。

Conclusion: 该方法能够生成符合指南的分割掩码，同时平衡资源使用，解决了现有方法在处理复杂文本指南进行语义分割时的不足。

Abstract: Semantic segmentation in real-world applications often requires not only
accurate masks but also strict adherence to textual labeling guidelines. These
guidelines are typically complex and long, and both human and automated
labeling often fail to follow them faithfully. Traditional approaches depend on
expensive task-specific retraining that must be repeated as the guidelines
evolve. Although recent open-vocabulary segmentation methods excel with simple
prompts, they often fail when confronted with sets of paragraph-length
guidelines that specify intricate segmentation rules. To address this, we
introduce a multi-agent, training-free framework that coordinates
general-purpose vision-language models within an iterative Worker-Supervisor
refinement architecture. The Worker performs the segmentation, the Supervisor
critiques it against the retrieved guidelines, and a lightweight reinforcement
learning stop policy decides when to terminate the loop, ensuring
guideline-consistent masks while balancing resource use. Evaluated on the Waymo
and ReasonSeg datasets, our method notably outperforms state-of-the-art
baselines, demonstrating strong generalization and instruction adherence.

</details>


### [11] [Domain Adaptation for Different Sensor Configurations in 3D Object Detection](https://arxiv.org/abs/2509.04711)
*Satoshi Tanaka,Kok Seang Tan,Isamu Yamashita*

Main category: cs.CV

TL;DR: 本篇论文针对自动驾驶领域中激光雷达（LiDAR）传感器配置不同的问题，提出了一种领域自适应方法，以解决跨传感器配置的3D物体检测性能下降的问题。


<details>
  <summary>Details</summary>
Motivation: 不同车辆平台使用的激光雷达传感器配置不同，导致在一种配置上训练的模型在另一种配置上性能下降，因为点云分布发生了变化。现有研究主要关注环境变化和单一激光雷达的密度变化，而不同传感器配置之间的领域差异研究不足。

Method: 提出两种技术：下游微调（在多数据集训练后进行特定数据集的微调）和部分层微调（只更新部分层以提高跨配置泛化能力）。

Result: 使用在同一地理区域、使用多种传感器配置收集的配对数据集，实验证明，结合下游微调和部分层微调的联合训练，在每种配置下的表现均优于朴素的联合训练。

Conclusion: 提出的方法为适应不同车辆平台的3D物体检测模型提供了实用且可扩展的解决方案。

Abstract: Recent advances in autonomous driving have underscored the importance of
accurate 3D object detection, with LiDAR playing a central role due to its
robustness under diverse visibility conditions. However, different vehicle
platforms often deploy distinct sensor configurations, causing performance
degradation when models trained on one configuration are applied to another
because of shifts in the point cloud distribution. Prior work on multi-dataset
training and domain adaptation for 3D object detection has largely addressed
environmental domain gaps and density variation within a single LiDAR; in
contrast, the domain gap for different sensor configurations remains largely
unexplored. In this work, we address domain adaptation across different sensor
configurations in 3D object detection. We propose two techniques: Downstream
Fine-tuning (dataset-specific fine-tuning after multi-dataset training) and
Partial Layer Fine-tuning (updating only a subset of layers to improve
cross-configuration generalization). Using paired datasets collected in the
same geographic region with multiple sensor configurations, we show that joint
training with Downstream Fine-tuning and Partial Layer Fine-tuning consistently
outperforms naive joint training for each configuration. Our findings provide a
practical and scalable solution for adapting 3D object detection models to the
diverse vehicle platforms.

</details>


### [12] [CD-Mamba: Cloud detection with long-range spatial dependency modeling](https://arxiv.org/abs/2509.04729)
*Tianxiang Xue,Jiayi Zhao,Jingsheng Li,Changlu Chen,Kun Zhan*

Main category: cs.CV

TL;DR: CD-Mamba是一个结合卷积和Mamba的混合模型，用于遥感图像云检测，能有效处理局部和长距离依赖，提高了检测精度。


<details>
  <summary>Details</summary>
Motivation: 遥感图像常被云覆盖，影响数据质量。现有的云检测方法需要处理云块的短距离空间冗余和长距离大气相似性。

Method: 提出了一种名为CD-Mamba的混合模型，该模型将卷积操作和Mamba的状态空间建模集成到一个统一的网络中，以捕捉像素级的纹理细节和长距离的块依赖关系。

Result: 实验证明CD-Mamba的有效性，并在云检测方面取得了优于现有方法的性能。

Conclusion: CD-Mamba通过结合卷积和Mamba的优势，能够同时处理像素级交互和广泛的块依赖关系，从而在不同空间尺度上提高云检测的准确性。

Abstract: Remote sensing images are frequently obscured by cloud cover, posing
significant challenges to data integrity and reliability. Effective cloud
detection requires addressing both short-range spatial redundancies and
long-range atmospheric similarities among cloud patches. Convolutional neural
networks are effective at capturing local spatial dependencies, while Mamba has
strong capabilities in modeling long-range dependencies. To fully leverage both
local spatial relations and long-range dependencies, we propose CD-Mamba, a
hybrid model that integrates convolution and Mamba's state-space modeling into
a unified cloud detection network. CD-Mamba is designed to comprehensively
capture pixelwise textural details and long term patchwise dependencies for
cloud detection. This design enables CD-Mamba to manage both pixel-wise
interactions and extensive patch-wise dependencies simultaneously, improving
detection accuracy across diverse spatial scales. Extensive experiments
validate the effectiveness of CD-Mamba and demonstrate its superior performance
over existing methods.

</details>


### [13] [Exploiting Unlabeled Structures through Task Consistency Training for Versatile Medical Image Segmentation](https://arxiv.org/abs/2509.04732)
*Shengqian Zhu,Jiafei Wu,Xiaogang Xu,Chengrong Yu,Ying Song,Zhang Yi,Guangjun Li,Junjie Hu*

Main category: cs.CV

TL;DR: 该研究提出了一种名为任务一致性训练（TCT）的框架，用于解决多类别医学图像分割（VMIS）中由于利用不完全标注数据集（PLDs）而导致的类别不平衡问题，无需额外模型。


<details>
  <summary>Details</summary>
Motivation: 现有VMIS方法在利用PLDs时面临严重的类别不平衡问题，而现有的解决类别不平衡的方法（如生成伪全标签）通常需要额外模型且可能引入标签噪声，导致性能下降。

Method: 提出任务一致性训练（TCT）框架，包含一个主分割头（MSH）和多个辅助任务头（ATHs）。通过强制MSH和ATHs预测之间的一致性约束来利用未标记的解剖结构。引入过滤策略排除低一致性的噪声数据，并使用统一的辅助不确定性加权损失（UAUWL）来减轻特定任务的主导地位导致的分割质量下降。

Result: 在八个来自不同临床的腹部数据集上进行了广泛实验，证明了该方法的有效性。

Conclusion: TCT框架能够有效解决VMIS中的类别不平衡问题，无需额外模型，并通过提出的过滤策略和UAUWL损失进一步提升了分割性能和鲁棒性。

Abstract: Versatile medical image segmentation (VMIS) targets the segmentation of
multiple classes, while obtaining full annotations for all classes is often
impractical due to the time and labor required. Leveraging partially labeled
datasets (PLDs) presents a promising alternative; however, current VMIS
approaches face significant class imbalance due to the unequal category
distribution in PLDs. Existing methods attempt to address this by generating
pseudo-full labels. Nevertheless, these typically require additional models and
often result in potential performance degradation from label noise. In this
work, we introduce a Task Consistency Training (TCT) framework to address class
imbalance without requiring extra models. TCT includes a backbone network with
a main segmentation head (MSH) for multi-channel predictions and multiple
auxiliary task heads (ATHs) for task-specific predictions. By enforcing a
consistency constraint between the MSH and ATH predictions, TCT effectively
utilizes unlabeled anatomical structures. To avoid error propagation from
low-consistency, potentially noisy data, we propose a filtering strategy to
exclude such data. Additionally, we introduce a unified auxiliary
uncertainty-weighted loss (UAUWL) to mitigate segmentation quality declines
caused by the dominance of specific tasks. Extensive experiments on eight
abdominal datasets from diverse clinical sites demonstrate our approach's
effectiveness.

</details>


### [14] [Enhancing Self-Driving Segmentation in Adverse Weather Conditions: A Dual Uncertainty-Aware Training Approach to SAM Optimization](https://arxiv.org/abs/2509.04735)
*Dharsan Ravindran,Kevin Wang,Zhuoyuan Cao,Saleh Abdelrahman,Jeffery Wu*

Main category: cs.CV

TL;DR: SAM和SAM2在恶劣天气下面临挑战，因为它们缺乏不确定性量化。本文研究了两种增强自动驾驶分割鲁棒性的方法：1. 对SAM2进行多步微调，将不确定性指标纳入损失函数；2. 将用于医学图像分割的不确定性感知适配器（UAT）应用于驾驶场景。实验表明，UAT-SAM在极端天气下优于SAM，而具有不确定性感知损失的SAM2在各种驾驶场景下性能有所提升。这表明显式不确定性建模对于自动驾驶的安全性至关重要。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉基础模型（如SAM和SAM2）在通用图像分割方面表现出色，但在视觉歧义性高的恶劣天气条件下表现不佳，主要原因是缺乏不确定性量化。本文旨在解决这个问题，以提高自动驾驶的分割鲁棒性。

Method: 本文研究了两种方法来增强SAM2在恶劣天气下的分割鲁棒性：1. 采用多步微调策略，将不确定性指标整合到SAM2的损失函数中；2. 将最初为医学图像分割设计的UAT（不确定性感知适配器）适配到驾驶场景中。

Result: 在CamVid、BDD100K和GTA驾驶数据集上的实验表明，UAT-SAM在极端天气下的表现优于标准的SAM模型。而采用不确定性感知损失的SAM2在各种驾驶场景下的性能均有所提升。

Conclusion: 显式地对不确定性进行建模对于在挑战性环境中保障自动驾驶的安全性具有重要价值。

Abstract: Recent advances in vision foundation models, such as the Segment Anything
Model (SAM) and its successor SAM2, have achieved state-of-the-art performance
on general image segmentation benchmarks. However, these models struggle in
adverse weather conditions where visual ambiguity is high, largely due to their
lack of uncertainty quantification. Inspired by progress in medical imaging,
where uncertainty-aware training has improved reliability in ambiguous cases,
we investigate two approaches to enhance segmentation robustness for autonomous
driving. First, we introduce a multi-step finetuning procedure for SAM2 that
incorporates uncertainty metrics directly into the loss function, improving
overall scene recognition. Second, we adapt the Uncertainty-Aware Adapter
(UAT), originally designed for medical image segmentation, to driving contexts.
We evaluate both methods on CamVid, BDD100K, and GTA driving datasets.
Experiments show that UAT-SAM outperforms standard SAM in extreme weather,
while SAM2 with uncertainty-aware loss achieves improved performance across
diverse driving scenes. These findings underscore the value of explicit
uncertainty modeling for safety-critical autonomous driving in challenging
environments.

</details>


### [15] [WatchHAR: Real-time On-device Human Activity Recognition System for Smartwatches](https://arxiv.org/abs/2509.04736)
*Taeyoung Yeon,Vasco Xu,Henry Hoffmann,Karan Ahuja*

Main category: cs.CV

TL;DR: WatchHAR是一个完全在智能手表上运行的音频和基于惯性的HAR系统，实现了5倍的处理速度和超过90%的准确率，解决了隐私和延迟问题。


<details>
  <summary>Details</summary>
Motivation: 在不约束的环境中，在智能手表上运行的HAR系统仍然是一个挑战，存在隐私和延迟问题。

Method: WatchHAR是一个音频和基于惯性的HAR系统，通过优化每个组件，实现了一个统一传感器数据预处理和推理的端到端可训练模块。

Result: WatchHAR实现了5倍的处理速度，在超过25个活动类别中保持超过90%的准确率，在事件检测和活动分类方面优于最先进的模型，处理时间分别为9.3毫秒和11.8毫秒。

Conclusion: WatchHAR推动了设备上的活动识别，使智能手表能够作为独立的、注重隐私的和最小侵入性的连续活动跟踪设备。

Abstract: Despite advances in practical and multimodal fine-grained Human Activity
Recognition (HAR), a system that runs entirely on smartwatches in unconstrained
environments remains elusive. We present WatchHAR, an audio and inertial-based
HAR system that operates fully on smartwatches, addressing privacy and latency
issues associated with external data processing. By optimizing each component
of the pipeline, WatchHAR achieves compounding performance gains. We introduce
a novel architecture that unifies sensor data preprocessing and inference into
an end-to-end trainable module, achieving 5x faster processing while
maintaining over 90% accuracy across more than 25 activity classes. WatchHAR
outperforms state-of-the-art models for event detection and activity
classification while running directly on the smartwatch, achieving 9.3 ms
processing time for activity event detection and 11.8 ms for multimodal
activity classification. This research advances on-device activity recognition,
realizing smartwatches' potential as standalone, privacy-aware, and
minimally-invasive continuous activity tracking devices.

</details>


### [16] [MCANet: A Multi-Scale Class-Specific Attention Network for Multi-Label Post-Hurricane Damage Assessment using UAV Imagery](https://arxiv.org/abs/2509.04757)
*Zhangding Liu,Neda Mohammadi,John E. Taylor*

Main category: cs.CV

TL;DR: MCANet是一个多标签分类框架，通过Res2Net和多头残差注意力机制，在飓风后的无人机图像中实现准确的多尺度损伤识别，mAP达到92.35%。


<details>
  <summary>Details</summary>
Motivation: 现有的基于CNN的方法难以捕捉多尺度空间特征并区分视觉上相似或同时发生的损坏类型，因此需要新的方法来进行快速准确的飓风后损伤评估。

Method: 提出MCANet框架，采用基于Res2Net的层级骨干网络来丰富跨尺度的空间上下文，并使用多头类别特定残差注意力模块来增强区分能力。每个注意力分支关注不同的空间粒度，以平衡局部细节和全局上下文。

Result: MCANet在RescueNet数据集上达到了91.75%的平均精度均值（mAP），优于其他多种基线模型。采用八个注意力头后，性能提升至92.35%，特别是对于“道路被堵塞”等挑战性类别，平均精度提高了6%以上。类激活映射证实了MCANet能够定位与损伤相关的区域。

Conclusion: MCANet能够有效进行飓风后损伤评估，其结果可用于灾后风险测绘、应急路线规划和数字孪生驱动的灾害响应。未来的工作可以集成特定灾害知识图谱和多模态大语言模型，以提高对未见灾害的适应性和丰富语义理解，从而支持现实世界的决策。

Abstract: Rapid and accurate post-hurricane damage assessment is vital for disaster
response and recovery. Yet existing CNN-based methods struggle to capture
multi-scale spatial features and to distinguish visually similar or
co-occurring damage types. To address these issues, we propose MCANet, a
multi-label classification framework that learns multi-scale representations
and adaptively attends to spatially relevant regions for each damage category.
MCANet employs a Res2Net-based hierarchical backbone to enrich spatial context
across scales and a multi-head class-specific residual attention module to
enhance discrimination. Each attention branch focuses on different spatial
granularities, balancing local detail with global context. We evaluate MCANet
on the RescueNet dataset of 4,494 UAV images collected after Hurricane Michael.
MCANet achieves a mean average precision (mAP) of 91.75%, outperforming ResNet,
Res2Net, VGG, MobileNet, EfficientNet, and ViT. With eight attention heads,
performance further improves to 92.35%, boosting average precision for
challenging classes such as Road Blocked by over 6%. Class activation mapping
confirms MCANet's ability to localize damage-relevant regions, supporting
interpretability. Outputs from MCANet can inform post-disaster risk mapping,
emergency routing, and digital twin-based disaster response. Future work could
integrate disaster-specific knowledge graphs and multimodal large language
models to improve adaptability to unseen disasters and enrich semantic
understanding for real-world decision-making.

</details>


### [17] [Dynamic Group Detection using VLM-augmented Temporal Groupness Graph](https://arxiv.org/abs/2509.04758)
*Kaname Yokoyama,Chihiro Nakatani,Norimichi Ukita*

Main category: cs.CV

TL;DR: 该论文提出了一种动态人体群组检测方法，结合了局部成员外观特征和全局场景上下文信息。


<details>
  <summary>Details</summary>
Motivation: 为了检测复杂的人群，需要考虑群组成员的局部外观特征以及场景的全局上下文信息。

Method: 利用为群组检测增强的视觉语言模型（VLM）提取每一帧的局部和全局外观特征。通过图论对所有帧的群组概率进行全局优化，以检测动态变化的群组。

Result: 在公开数据集上的实验结果表明，该方法优于现有的群组检测方法。

Conclusion: 该方法能够有效检测动态变化的人群，并且在性能上优于现有技术。

Abstract: This paper proposes dynamic human group detection in videos. For detecting
complex groups, not only the local appearance features of in-group members but
also the global context of the scene are important. Such local and global
appearance features in each frame are extracted using a Vision-Language Model
(VLM) augmented for group detection in our method. For further improvement, the
group structure should be consistent over time. While previous methods are
stabilized on the assumption that groups are not changed in a video, our method
detects dynamically changing groups by global optimization using a graph with
all frames' groupness probabilities estimated by our groupness-augmented CLIP
features. Our experimental results demonstrate that our method outperforms
state-of-the-art group detection methods on public datasets. Code:
https://github.com/irajisamurai/VLM-GroupDetection.git

</details>


### [18] [FloodVision: Urban Flood Depth Estimation Using Foundation Vision-Language Models and Domain Knowledge Graph](https://arxiv.org/abs/2509.04772)
*Zhangding Liu,Neda Mohammadi,John E. Taylor*

Main category: cs.CV

TL;DR: FloodVision是一个利用GPT-4o和知识图谱进行零样本洪水深度估计的框架，在准确性和泛化性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的计算机视觉方法在洪水深度估计方面存在准确性限制和泛化能力差的问题，因为它们依赖于固定的对象检测器和特定任务的训练。

Method: FloodVision框架结合了GPT-4o的语义推理能力和结构化领域知识图谱。知识图谱包含城市常见物体（车辆、行人、基础设施）的真实尺寸信息。该框架能够动态识别图像中的参考物体，从知识图谱中检索物体高度以减少模型臆想，估算物体被淹没的比例，并通过统计异常值过滤来计算最终的深度值。

Result: 在MyCoast New York收集的110张众包图像上进行评估，FloodVision的平均绝对误差为8.17厘米，比GPT-4o基线（10.28厘米）的误差减少了20.5%，并且优于之前的基于CNN的方法。

Conclusion: FloodVision在不同场景下都表现出良好的泛化能力，并且能够近乎实时地运行，适合未来集成到数字孪生平台和市民报告应用程序中，以增强智慧城市的洪水应对能力。

Abstract: Timely and accurate floodwater depth estimation is critical for road
accessibility and emergency response. While recent computer vision methods have
enabled flood detection, they suffer from both accuracy limitations and poor
generalization due to dependence on fixed object detectors and task-specific
training. To enable accurate depth estimation that can generalize across
diverse flood scenarios, this paper presents FloodVision, a zero-shot framework
that combines the semantic reasoning abilities of the foundation
vision-language model GPT-4o with a structured domain knowledge graph. The
knowledge graph encodes canonical real-world dimensions for common urban
objects including vehicles, people, and infrastructure elements to ground the
model's reasoning in physical reality. FloodVision dynamically identifies
visible reference objects in RGB images, retrieves verified heights from the
knowledge graph to mitigate hallucination, estimates submergence ratios, and
applies statistical outlier filtering to compute final depth values. Evaluated
on 110 crowdsourced images from MyCoast New York, FloodVision achieves a mean
absolute error of 8.17 cm, reducing the GPT-4o baseline 10.28 cm by 20.5% and
surpassing prior CNN-based methods. The system generalizes well across varying
scenes and operates in near real-time, making it suitable for future
integration into digital twin platforms and citizen-reporting apps for smart
city flood resilience.

</details>


### [19] [MLP-SRGAN: A Single-Dimension Super Resolution GAN using MLP-Mixer](https://arxiv.org/abs/2303.06298)
*Samir Mitha,Seungho Choe,Pejman Jahbedar Maralani,Alan R. Moody,April Khademi*

Main category: cs.CV

TL;DR: MLP-SRGAN是一种新的单维度超分辨率生成对抗网络（SRGAN），它使用多层感知机混合器（MLP-Mixers）和卷积层来上采样切片方向。它在MSSEG2挑战数据集上进行训练和验证，并在三个多中心FLAIR数据集上进行了测试。与现有方法相比，MLP-SRGAN生成的图像具有更清晰的边缘、更少的模糊、更好的纹理和细节保留，并且具有更少的参数、更快的训练/评估时间和更小的模型尺寸。


<details>
  <summary>Details</summary>
Motivation: 现有的超分辨率方法在处理MRI图像的切片维度时存在不足，需要一种能够提高切片分辨率同时保持图像质量的新型网络。

Method: 提出了一种名为MLP-SRGAN的新型单维度超分辨率生成对抗网络（SRGAN），它结合了多层感知机混合器（MLP-Mixers）和卷积层，用于在上采样切片方向。该方法使用高分辨率（HR）FLAIR MRI数据进行训练和验证，并在多个临床数据集上进行了测试。

Result: MLP-SRGAN在多个评估指标上优于现有方法，能够生成更清晰的边缘、更少的模糊、保留更多的纹理和精细解剖细节。此外，它还具有更少的参数、更快的训练/评估时间和更小的模型尺寸。

Conclusion: MLP-SRGAN是一种有效的新型单维度超分辨率网络，能够显著提高MRI图像在切片方向的分辨率，同时保持和提升图像质量，并且在计算效率方面优于现有方法。

Abstract: We propose a novel architecture called MLP-SRGAN, which is a single-dimension
Super Resolution Generative Adversarial Network (SRGAN) that utilizes
Multi-Layer Perceptron Mixers (MLP-Mixers) along with convolutional layers to
upsample in the slice direction. MLP-SRGAN is trained and validated using high
resolution (HR) FLAIR MRI from the MSSEG2 challenge dataset. The method was
applied to three multicentre FLAIR datasets (CAIN, ADNI, CCNA) of images with
low spatial resolution in the slice dimension to examine performance on
held-out (unseen) clinical data. Upsampled results are compared to several
state-of-the-art SR networks. For images with high resolution (HR) ground
truths, peak-signal-to-noise-ratio (PSNR) and structural similarity index
(SSIM) are used to measure upsampling performance. Several new structural,
no-reference image quality metrics were proposed to quantify sharpness (edge
strength), noise (entropy), and blurriness (low frequency information) in the
absence of ground truths. Results show MLP-SRGAN results in sharper edges, less
blurring, preserves more texture and fine-anatomical detail, with fewer
parameters, faster training/evaluation time, and smaller model size than
existing methods. Code for MLP-SRGAN training and inference, data generators,
models and no-reference image quality metrics will be available at
https://github.com/IAMLAB-Ryerson/MLP-SRGAN.

</details>


### [20] [Hybrid-Tower: Fine-grained Pseudo-query Interaction and Generation for Text-to-Video Retrieval](https://arxiv.org/abs/2509.04773)
*Bangxiang Lan,Ruobing Xie,Ruixiang Zhao,Xingwu Sun,Zhanhui Kang,Gang Yang,Xirong Li*

Main category: cs.CV

TL;DR: 本研究提出了一种新的混合塔（Hybrid-Tower）框架，名为PIG，用于文本到视频检索（T2VR）任务，旨在同时实现高有效性和高效率。


<details>
  <summary>Details</summary>
Motivation: 现有的T2VR方法分为双塔和单塔框架，但前者有效性低，后者效率低。本研究旨在克服这些缺点。

Method: 提出了一种名为PIG（Fine-grained Pseudo-query Interaction and Generation）的新型混合方法。PIG包含一个伪查询生成器，为每个视频生成一个伪查询，从而使视频特征和伪查询的文本特征能够进行细粒度交互，类似于单塔方法。在推理阶段，PIG不引入额外的存储或计算开销，从而保持了双塔框架的高效率。

Result: 在五个常用的文本-视频检索基准测试中，PIG相比基线方法在R@1上取得了1.6%至3.9%的显著提升。

Conclusion: PIG方法在保持双塔模型效率的同时，实现了接近最先进的性能，证明了混合塔框架的优越性。

Abstract: The Text-to-Video Retrieval (T2VR) task aims to retrieve unlabeled videos by
textual queries with the same semantic meanings. Recent CLIP-based approaches
have explored two frameworks: Two-Tower versus Single-Tower framework, yet the
former suffers from low effectiveness, while the latter suffers from low
efficiency. In this study, we explore a new Hybrid-Tower framework that can
hybridize the advantages of the Two-Tower and Single-Tower framework, achieving
high effectiveness and efficiency simultaneously. We propose a novel hybrid
method, Fine-grained Pseudo-query Interaction and Generation for T2VR, ie, PIG,
which includes a new pseudo-query generator designed to generate a pseudo-query
for each video. This enables the video feature and the textual features of
pseudo-query to interact in a fine-grained manner, similar to the Single-Tower
approaches to hold high effectiveness, even before the real textual query is
received. Simultaneously, our method introduces no additional storage or
computational overhead compared to the Two-Tower framework during the inference
stage, thus maintaining high efficiency. Extensive experiments on five commonly
used text-video retrieval benchmarks demonstrate that our method achieves a
significant improvement over the baseline, with an increase of $1.6\% \sim
3.9\%$ in R@1. Furthermore, our method matches the efficiency of Two-Tower
models while achieving near state-of-the-art performance, highlighting the
advantages of the Hybrid-Tower framework.

</details>


### [21] [Comparative Evaluation of Traditional and Deep Learning Feature Matching Algorithms using Chandrayaan-2 Lunar Data](https://arxiv.org/abs/2509.04775)
*R. Makharia,J. G. Singla,Amitabh,N. Dube,H. Sharma*

Main category: cs.CV

TL;DR: SuperGlue在月球图像配准任务中表现最佳，优于SIFT、ASIFT、AKAZE和RIFT2，尤其在极地地区。


<details>
  <summary>Details</summary>
Motivation: 月球图像配准对于表面测绘、资源定位和任务规划至关重要，但由于不同传感器（光学、高光谱、雷达）在分辨率、光照和畸变方面存在差异，配准具有挑战性。

Method: 评估了SIFT、ASIFT、AKAZE、RIFT2和SuperGlue（一种基于深度学习的匹配器）五种特征匹配算法，并提出了一种预处理流程，包括地理配准、分辨率对齐、强度归一化、自适应直方图均衡化、主成分分析和阴影校正。

Result: SuperGlue在跨模态图像对上始终产生最低的均方根误差和最快的运行时间。SIFT和AKAZE等经典方法在赤道附近效果良好，但在极地光照下性能下降。

Conclusion: 预处理和基于学习的方法对于在各种条件下实现鲁棒的月球图像配准至关重要。

Abstract: Accurate image registration is critical for lunar exploration, enabling
surface mapping, resource localization, and mission planning. Aligning data
from diverse lunar sensors -- optical (e.g., Orbital High Resolution Camera,
Narrow and Wide Angle Cameras), hyperspectral (Imaging Infrared Spectrometer),
and radar (e.g., Dual-Frequency Synthetic Aperture Radar, Selene/Kaguya
mission) -- is challenging due to differences in resolution, illumination, and
sensor distortion. We evaluate five feature matching algorithms: SIFT, ASIFT,
AKAZE, RIFT2, and SuperGlue (a deep learning-based matcher), using
cross-modality image pairs from equatorial and polar regions. A preprocessing
pipeline is proposed, including georeferencing, resolution alignment, intensity
normalization, and enhancements like adaptive histogram equalization, principal
component analysis, and shadow correction. SuperGlue consistently yields the
lowest root mean square error and fastest runtimes. Classical methods such as
SIFT and AKAZE perform well near the equator but degrade under polar lighting.
The results highlight the importance of preprocessing and learning-based
approaches for robust lunar image registration across diverse conditions.

</details>


### [22] [Toward Accessible Dermatology: Skin Lesion Classification Using Deep Learning Models on Mobile-Acquired Images](https://arxiv.org/abs/2509.04800)
*Asif Newaz,Masum Mushfiq Ishti,A Z M Ashraful Azam,Asif Ur Rahman Adib*

Main category: cs.CV

TL;DR: 该研究利用包含50多种皮肤病类型的、使用移动设备拍摄的大型数据集，评估了卷积神经网络（CNN）和Transformer模型在皮肤病诊断中的表现。结果显示，Swin Transformer模型在捕获全局上下文特征方面表现优越，并且结合Grad-CAM技术增强了解释性，为在资源匮乏地区实现可及的AI辅助皮肤筛查和早期诊断提供了潜力。


<details>
  <summary>Details</summary>
Motivation: 传统的皮肤病诊断方法成本高、复杂且在资源匮乏地区难以获得。深度学习在自动分类方面展现了潜力，但现有研究多局限于皮肤镜数据集和有限的疾病类别。

Method: 研究者收集了一个包含50多种皮肤病类型的、使用移动设备拍摄的大型数据集。他们评估了多种卷积神经网络（CNN）和Transformer模型，并引入了Grad-CAM技术来增强模型的可解释性。

Result: Transformer模型，特别是Swin Transformer，在捕获全局上下文特征方面表现出优越性能，超越了传统的CNN模型。Grad-CAM技术能够突出显示临床相关区域，为模型预测提供透明度。

Conclusion: 基于Transformer的方法在通过移动设备获取的皮肤病变分类方面具有巨大潜力，有望在资源有限的环境中实现可及的AI辅助皮肤筛查和早期诊断。

Abstract: Skin diseases are among the most prevalent health concerns worldwide, yet
conventional diagnostic methods are often costly, complex, and unavailable in
low-resource settings. Automated classification using deep learning has emerged
as a promising alternative, but existing studies are mostly limited to
dermoscopic datasets and a narrow range of disease classes. In this work, we
curate a large dataset of over 50 skin disease categories captured with mobile
devices, making it more representative of real-world conditions. We evaluate
multiple convolutional neural networks and Transformer-based architectures,
demonstrating that Transformer models, particularly the Swin Transformer,
achieve superior performance by effectively capturing global contextual
features. To enhance interpretability, we incorporate Gradient-weighted Class
Activation Mapping (Grad-CAM), which highlights clinically relevant regions and
provides transparency in model predictions. Our results underscore the
potential of Transformer-based approaches for mobile-acquired skin lesion
classification, paving the way toward accessible AI-assisted dermatological
screening and early diagnosis in resource-limited environments.

</details>


### [23] [Extracting Uncertainty Estimates from Mixtures of Experts for Semantic Segmentation](https://arxiv.org/abs/2509.04816)
*Svetlana Pavlitska,Beyza Keskin,Alwin Faßbender,Christian Hubschneider,J. Marius Zöllner*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Estimating accurate and well-calibrated predictive uncertainty is important
for enhancing the reliability of computer vision models, especially in
safety-critical applications like traffic scene perception. While ensemble
methods are commonly used to quantify uncertainty by combining multiple models,
a mixture of experts (MoE) offers an efficient alternative by leveraging a
gating network to dynamically weight expert predictions based on the input.
Building on the promising use of MoEs for semantic segmentation in our previous
works, we show that well-calibrated predictive uncertainty estimates can be
extracted from MoEs without architectural modifications. We investigate three
methods to extract predictive uncertainty estimates: predictive entropy, mutual
information, and expert variance. We evaluate these methods for an MoE with two
experts trained on a semantical split of the A2D2 dataset. Our results show
that MoEs yield more reliable uncertainty estimates than ensembles in terms of
conditional correctness metrics under out-of-distribution (OOD) data.
Additionally, we evaluate routing uncertainty computed via gate entropy and
find that simple gating mechanisms lead to better calibration of routing
uncertainty estimates than more complex classwise gates. Finally, our
experiments on the Cityscapes dataset suggest that increasing the number of
experts can further enhance uncertainty calibration. Our code is available at
https://github.com/KASTEL-MobilityLab/mixtures-of-experts/.

</details>


### [24] [Enhancing 3D Point Cloud Classification with ModelNet-R and Point-SkipNet](https://arxiv.org/abs/2509.05198)
*Mohammad Saeid,Amir Salarpour,Pedram MohajerAnsari*

Main category: cs.CV

TL;DR: ModelNet-R是一个改进版的ModelNet40数据集，解决了其标签不一致、2D数据、尺寸不匹配和类别区分不足等问题。Point-SkipNet是一个轻量级图神经网络，在ModelNet-R上实现了最先进的分类精度，同时大大降低了参数数量。


<details>
  <summary>Details</summary>
Motivation: 现有的ModelNet40数据集存在标签不一致、2D数据、尺寸不匹配和类别区分不足等问题，影响了3D点云分类模型的性能。因此，需要一个更可靠的数据集和更高效的模型。

Method: 提出ModelNet-R数据集，对ModelNet40进行修正和改进。提出Point-SkipNet，一种轻量级图神经网络，采用高效采样、邻域分组和跳跃连接。

Result: 在ModelNet-R数据集上训练的模型性能显著提升。Point-SkipNet在ModelNet-R上达到了最先进的准确率，并且参数量远少于现有模型。

Conclusion: 数据集的质量对于优化3D点云分类模型的效率至关重要。ModelNet-R和Point-SkipNet的提出为3D点云分类研究提供了更好的基准和模型。

Abstract: The classification of 3D point clouds is crucial for applications such as
autonomous driving, robotics, and augmented reality. However, the commonly used
ModelNet40 dataset suffers from limitations such as inconsistent labeling, 2D
data, size mismatches, and inadequate class differentiation, which hinder model
performance. This paper introduces ModelNet-R, a meticulously refined version
of ModelNet40 designed to address these issues and serve as a more reliable
benchmark. Additionally, this paper proposes Point-SkipNet, a lightweight
graph-based neural network that leverages efficient sampling, neighborhood
grouping, and skip connections to achieve high classification accuracy with
reduced computational overhead. Extensive experiments demonstrate that models
trained in ModelNet-R exhibit significant performance improvements. Notably,
Point-SkipNet achieves state-of-the-art accuracy on ModelNet-R with a
substantially lower parameter count compared to contemporary models. This
research highlights the crucial role of dataset quality in optimizing model
efficiency for 3D point cloud classification. For more details, see the code
at: https://github.com/m-saeid/ModeNetR_PointSkipNet.

</details>


### [25] [Exploring Non-Local Spatial-Angular Correlations with a Hybrid Mamba-Transformer Framework for Light Field Super-Resolution](https://arxiv.org/abs/2509.04824)
*Haosong Liu,Xiancheng Zhu,Huanqiang Zeng,Jianqing Zhu,Jiuwen Cao,Junhui Hou*

Main category: cs.CV

TL;DR: Mamba-based methods show potential for LFSR but suffer from inefficient feature extraction due to multi-directional scanning. This paper proposes a Subspace Simple Scanning (Sub-SS) strategy and Subspace Simple Mamba Block (SSMB) for efficient feature extraction. A dual-stage modeling strategy with Spatial-Angular Residual Subspace Mamba Block (SA-RSMB) and a dual-branch parallel structure combining Epipolar Plane Mamba Block (EPMB) and Epipolar Plane Transformer Block (EPTB) is introduced to better preserve spatial-angular and disparity information. The resulting hybrid Mamba-Transformer framework, LFMT, achieves state-of-the-art performance in LFSR with low computational complexity.


<details>
  <summary>Details</summary>
Motivation: Current Mamba-based methods for light field image super-resolution (LFSR) suffer from inefficient and redundant feature extraction due to multi-directional scanning strategies when applied to complex light field data. Additionally, the state space limitations hinder the preservation of spatial-angular and disparity information. This paper aims to address these issues by proposing a more efficient and precise feature extraction strategy and a dual-stage modeling approach for comprehensive exploration of non-local spatial-angular correlations.

Method: The proposed approach introduces a Subspace Simple Scanning (Sub-SS) strategy and designs a Subspace Simple Mamba Block (SSMB) for efficient and precise feature extraction. A dual-stage modeling strategy is employed: Stage I uses a Spatial-Angular Residual Subspace Mamba Block (SA-RSMB) for shallow spatial-angular feature extraction. Stage II utilizes a dual-branch parallel structure with an Epipolar Plane Mamba Block (EPMB) and an Epipolar Plane Transformer Block (EPTB) for deep epipolar feature refinement. These modules are integrated into a hybrid Mamba-Transformer framework called LFMT.

Result: Experimental results show that the proposed LFMT framework significantly outperforms current state-of-the-art methods in LFSR. It achieves substantial performance improvements while maintaining low computational complexity on both real-world and synthetic light field datasets.

Conclusion: The proposed LFMT framework, integrating Mamba and Transformer models with novel strategies like Sub-SS and a dual-stage modeling approach, effectively addresses the limitations of existing methods for LFSR. It demonstrates superior performance and efficiency in capturing complex spatial-angular and epipolar features, making it a promising solution for LFSR tasks.

Abstract: Recently, Mamba-based methods, with its advantage in long-range information
modeling and linear complexity, have shown great potential in optimizing both
computational cost and performance of light field image super-resolution
(LFSR). However, current multi-directional scanning strategies lead to
inefficient and redundant feature extraction when applied to complex LF data.
To overcome this challenge, we propose a Subspace Simple Scanning (Sub-SS)
strategy, based on which we design the Subspace Simple Mamba Block (SSMB) to
achieve more efficient and precise feature extraction. Furthermore, we propose
a dual-stage modeling strategy to address the limitation of state space in
preserving spatial-angular and disparity information, thereby enabling a more
comprehensive exploration of non-local spatial-angular correlations.
Specifically, in stage I, we introduce the Spatial-Angular Residual Subspace
Mamba Block (SA-RSMB) for shallow spatial-angular feature extraction; in stage
II, we use a dual-branch parallel structure combining the Epipolar Plane Mamba
Block (EPMB) and Epipolar Plane Transformer Block (EPTB) for deep epipolar
feature refinement. Building upon meticulously designed modules and strategies,
we introduce a hybrid Mamba-Transformer framework, termed LFMT. LFMT integrates
the strengths of Mamba and Transformer models for LFSR, enabling comprehensive
information exploration across spatial, angular, and epipolar-plane domains.
Experimental results demonstrate that LFMT significantly outperforms current
state-of-the-art methods in LFSR, achieving substantial improvements in
performance while maintaining low computational complexity on both real-word
and synthetic LF datasets.

</details>


### [26] [PropVG: End-to-End Proposal-Driven Visual Grounding with Multi-Granularity Discrimination](https://arxiv.org/abs/2509.04833)
*Ming Dai,Wenxuan Cheng,Jiedong Zhuang,Jiang-jiang Liu,Hongshen Zhao,Zhenhua Feng,Wankou Yang*

Main category: cs.CV

TL;DR: PropVG是一个端到端、基于提议的视觉基础框架，通过集成前景目标提议生成和指代目标理解，并引入对比学习和多粒度目标判别模块，解决了现有方法仅依赖指代目标进行监督以及缺乏多粒度判别的问题。


<details>
  <summary>Details</summary>
Motivation: 现有视觉基础方法倾向于端到端直接参照范式，但它们仅依赖指代目标进行监督，忽略了潜在的显着候选目标，并且缺乏处理复杂场景中物体识别所需的多粒度判别能力。

Method: 提出PropVG，一个集成了前景目标提议生成和指代目标理解的端到端、基于提议的框架，无需额外检测器。引入对比式指代评分（CRS）模块，在句子和词级别进行对比学习，以增强理解和区分指代目标的能力。设计多粒度目标判别（MTD）模块，融合物体和语义级别信息，以提高对缺失目标的识别能力。

Result: 在gRefCOCO (GREC/GRES)、Ref-ZOM、R-RefCOCO和RefCOCO (REC/RES)基准测试上进行了广泛的实验，证明了PropVG的有效性。

Conclusion: PropVG通过集成目标提议生成和指代目标理解，并引入CRS和MTD模块，有效解决了现有视觉基础方法的局限性，并在多个基准测试上取得了优异的性能。

Abstract: Recent advances in visual grounding have largely shifted away from
traditional proposal-based two-stage frameworks due to their inefficiency and
high computational complexity, favoring end-to-end direct reference paradigms.
However, these methods rely exclusively on the referred target for supervision,
overlooking the potential benefits of prominent prospective targets. Moreover,
existing approaches often fail to incorporate multi-granularity discrimination,
which is crucial for robust object identification in complex scenarios. To
address these limitations, we propose PropVG, an end-to-end proposal-based
framework that, to the best of our knowledge, is the first to seamlessly
integrate foreground object proposal generation with referential object
comprehension without requiring additional detectors. Furthermore, we introduce
a Contrastive-based Refer Scoring (CRS) module, which employs contrastive
learning at both sentence and word levels to enhance the capability in
understanding and distinguishing referred objects. Additionally, we design a
Multi-granularity Target Discrimination (MTD) module that fuses object- and
semantic-level information to improve the recognition of absent targets.
Extensive experiments on gRefCOCO (GREC/GRES), Ref-ZOM, R-RefCOCO, and RefCOCO
(REC/RES) benchmarks demonstrate the effectiveness of PropVG. The codes and
models are available at https://github.com/Dmmm1997/PropVG.

</details>


### [27] [TemporalFlowViz: Parameter-Aware Visual Analytics for Interpreting Scramjet Combustion Evolution](https://arxiv.org/abs/2509.04834)
*Yifei Jia,Shiyu Cheng,Yu Dong,Guan Li,Dong Tian,Ruixiao Peng,Xuyi Lu,Yu Wang,Wei Yao,Guihua Shan*

Main category: cs.CV

TL;DR: TemporalFlowViz是一个用于分析超燃冲压发动机燃烧模拟数据的可视化分析工具，通过提取嵌入、聚类、轨迹构建和自然语言生成，帮助专家理解和发现复杂燃烧模式。


<details>
  <summary>Details</summary>
Motivation: 超燃冲压发动机模拟数据规模大、维度高，给可视化解释、特征区分和跨案例比较带来挑战。

Method: 利用预训练的Vision Transformer提取帧嵌入，进行降维和密度聚类以发现燃烧模式，构建嵌入空间中的时间轨迹来追踪模拟演变。通过领域专家标注的类别中心，使用视觉-语言模型生成自然语言摘要。系统还支持参数过滤、相似案例检索和多视图探索。

Result: 通过两个案例研究和专家反馈证明，TemporalFlowViz能够增强假设生成、支持可解释模式发现，并促进大规模超燃冲压发动机燃烧分析中的知识发现。

Conclusion: TemporalFlowViz是一个有效的方法，能够应对大规模、高维度燃烧模拟数据分析的挑战，并为领域专家提供强大的支持。

Abstract: Understanding the complex combustion dynamics within scramjet engines is
critical for advancing high-speed propulsion technologies. However, the large
scale and high dimensionality of simulation-generated temporal flow field data
present significant challenges for visual interpretation, feature
differentiation, and cross-case comparison. In this paper, we present
TemporalFlowViz, a parameter-aware visual analytics workflow and system
designed to support expert-driven clustering, visualization, and interpretation
of temporal flow fields from scramjet combustion simulations. Our approach
leverages hundreds of simulated combustion cases with varying initial
conditions, each producing time-sequenced flow field images. We use pretrained
Vision Transformers to extract high-dimensional embeddings from these frames,
apply dimensionality reduction and density-based clustering to uncover latent
combustion modes, and construct temporal trajectories in the embedding space to
track the evolution of each simulation over time. To bridge the gap between
latent representations and expert reasoning, domain specialists annotate
representative cluster centroids with descriptive labels. These annotations are
used as contextual prompts for a vision-language model, which generates
natural-language summaries for individual frames and full simulation cases. The
system also supports parameter-based filtering, similarity-based case
retrieval, and coordinated multi-view exploration to facilitate in-depth
analysis. We demonstrate the effectiveness of TemporalFlowViz through two
expert-informed case studies and expert feedback, showing TemporalFlowViz
enhances hypothesis generation, supports interpretable pattern discovery, and
enhances knowledge discovery in large-scale scramjet combustion analysis.

</details>


### [28] [Pose-Free 3D Quantitative Phase Imaging of Flowing Cellular Populations](https://arxiv.org/abs/2509.04848)
*Enze Ye,Wei Lin,Shaochi Ren,Yakun Liu,Xiaoping Li,Hao Wang,He Sun,Feng Pan*

Main category: cs.CV

TL;DR: OmniFHT是一个无姿态的3D折射率重建框架，用于高通量流式细胞术，能够对任意形状的细胞进行精确成像，并支持稀疏采样和有限的角度范围。


<details>
  <summary>Details</summary>
Motivation: 现有流式细胞术中的高通量3D定量相位成像（QPI）方法假设细胞进行单轴旋转，限制了其在不规则形状细胞上的应用，并阻碍了对整个细胞群体的稳健统计分析。

Method: OmniFHT利用傅里叶衍射定理和隐式神经表示（INRs），通过联合优化未知旋转轨迹和体积结构，在弱散射假设下进行重建。

Result: OmniFHT能够对任意几何形状和多轴旋转的细胞进行成像，即使在稀疏采样和有限角度（10个视角或120度角度范围）下也能实现高保真重建。

Conclusion: OmniFHT首次实现了对整个流动细胞群体的原位、高通量断层成像，为流式细胞术平台提供了可扩展、无偏见的无标记形态分析解决方案。

Abstract: High-throughput 3D quantitative phase imaging (QPI) in flow cytometry enables
label-free, volumetric characterization of individual cells by reconstructing
their refractive index (RI) distributions from multiple viewing angles during
flow through microfluidic channels. However, current imaging methods assume
that cells undergo uniform, single-axis rotation, which require their poses to
be known at each frame. This assumption restricts applicability to
near-spherical cells and prevents accurate imaging of irregularly shaped cells
with complex rotations. As a result, only a subset of the cellular population
can be analyzed, limiting the ability of flow-based assays to perform robust
statistical analysis. We introduce OmniFHT, a pose-free 3D RI reconstruction
framework that leverages the Fourier diffraction theorem and implicit neural
representations (INRs) for high-throughput flow cytometry tomographic imaging.
By jointly optimizing each cell's unknown rotational trajectory and volumetric
structure under weak scattering assumptions, OmniFHT supports arbitrary cell
geometries and multi-axis rotations. Its continuous representation also allows
accurate reconstruction from sparsely sampled projections and restricted
angular coverage, producing high-fidelity results with as few as 10 views or
only 120 degrees of angular range. OmniFHT enables, for the first time, in
situ, high-throughput tomographic imaging of entire flowing cell populations,
providing a scalable and unbiased solution for label-free morphometric analysis
in flow cytometry platforms.

</details>


### [29] [CoRe-GS: Coarse-to-Refined Gaussian Splatting with Semantic Object Focus](https://arxiv.org/abs/2509.04859)
*Hannah Schieber,Dominik Frischmann,Simon Boche,Victor Schaack,Angela Schoellig,Stefan Leutenegger,Daniel Roth*

Main category: cs.CV

TL;DR: CoRe-GS通过在训练周期中引入语义分割和颜色过滤，实现了对移动机器人自主空中机器人进行3D重建时，在保证重建质量的同时缩短了训练时间。


<details>
  <summary>Details</summary>
Motivation: 为了在自主空中机器人进行3D重建时，兼顾高重建质量和缩短训练时间，本研究提出了一种新的方法。

Method: 本研究提出CoRe-GS方法，首先利用语义高斯渲染生成粗分割场景，然后通过新颖的颜色有效过滤技术对目标物体进行精炼，以实现有效的物体分离。

Result: 实验结果表明，与完整的训练周期相比，CoRe-GS将训练时间缩短了约四分之一，并在SCRREAM和NeRDS 360数据集上实现了更高的重建质量和新视角合成质量。

Conclusion: CoRe-GS方法能够有效加速3D重建的训练过程，同时保持甚至提高重建质量，使其在需要快速响应的关键任务中具有实际应用价值。

Abstract: Mobile reconstruction for autonomous aerial robotics holds strong potential
for critical applications such as tele-guidance and disaster response. These
tasks demand both accurate 3D reconstruction and fast scene processing. Instead
of reconstructing the entire scene in detail, it is often more efficient to
focus on specific objects, i.e., points of interest (PoIs). Mobile robots
equipped with advanced sensing can usually detect these early during data
acquisition or preliminary analysis, reducing the need for full-scene
optimization. Gaussian Splatting (GS) has recently shown promise in delivering
high-quality novel view synthesis and 3D representation by an incremental
learning process. Extending GS with scene editing, semantics adds useful
per-splat features to isolate objects effectively.
  Semantic 3D Gaussian editing can already be achieved before the full training
cycle is completed, reducing the overall training time. Moreover, the
semantically relevant area, the PoI, is usually already known during capturing.
To balance high-quality reconstruction with reduced training time, we propose
CoRe-GS. We first generate a coarse segmentation-ready scene with semantic GS
and then refine it for the semantic object using our novel color-based
effective filtering for effective object isolation. This is speeding up the
training process to be about a quarter less than a full training cycle for
semantic GS. We evaluate our approach on two datasets, SCRREAM (real-world,
outdoor) and NeRDS 360 (synthetic, indoor), showing reduced runtime and higher
novel-view-synthesis quality.

</details>


### [30] [Cryo-RL: automating prostate cancer cryoablation planning with reinforcement learning](https://arxiv.org/abs/2509.04886)
*Trixia Simangan,Ahmed Nadeem Abbasi,Yipeng Hu,Shaheer U. Saeed*

Main category: cs.CV

TL;DR: Cryo-RL是一个使用强化学习的工具，可以自动规划前列腺癌冷冻消融术的冷冻探针放置，其效果优于现有方法，并且规划时间更短。


<details>
  <summary>Details</summary>
Motivation: 手动规划前列腺癌冷冻消融术的冷冻探针放置耗时、依赖专家经验，且效果不稳定，限制了治疗的可扩展性。

Method: 使用强化学习将冷冻消融规划建模为马尔可夫决策过程，在模拟环境中训练智能体来选择冷冻探针位置和冰球直径，以最大化肿瘤覆盖率并避免损伤关键结构。

Result: 在583个前列腺癌病例的评估中，Cryo-RL相比最佳的自动化基线在Dice得分上提高了8个百分点以上，并且达到了人类专家的水平，同时规划时间显著缩短。

Conclusion: 强化学习有潜力为前列腺癌冷冻消融术提供临床上可行、可重复且高效的规划方案。

Abstract: Cryoablation is a minimally invasive localised treatment for prostate cancer
that destroys malignant tissue during de-freezing, while sparing surrounding
healthy structures. Its success depends on accurate preoperative planning of
cryoprobe placements to fully cover the tumour and avoid critical anatomy. This
planning is currently manual, expertise-dependent, and time-consuming, leading
to variability in treatment quality and limited scalability. In this work, we
introduce Cryo-RL, a reinforcement learning framework that models cryoablation
planning as a Markov decision process and learns an optimal policy for
cryoprobe placement. Within a simulated environment that models clinical
constraints and stochastic intraoperative variability, an agent sequentially
selects cryoprobe positions and ice sphere diameters. Guided by a reward
function based on tumour coverage, this agent learns a cryoablation strategy
that leads to optimal cryoprobe placements without the need for any
manually-designed plans. Evaluated on 583 retrospective prostate cancer cases,
Cryo-RL achieved over 8 percentage-point Dice improvements compared with the
best automated baselines, based on geometric optimisation, and matched human
expert performance while requiring substantially less planning time. These
results highlight the potential of reinforcement learning to deliver clinically
viable, reproducible, and efficient cryoablation plans.

</details>


### [31] [SpiderNets: Estimating Fear Ratings of Spider-Related Images with Vision Models](https://arxiv.org/abs/2509.04889)
*Dominik Pegler,David Steyrl,Mengfan Zhang,Alexander Karner,Jozsef Arato,Frank Scharnowski,Filip Melinscak*

Main category: cs.CV

TL;DR: 可以，我们可以用预训练的计算机视觉模型来预测恐惧水平，但需要足够的数据集和模型可解释性。


<details>
  <summary>Details</summary>
Motivation: 计算机视觉技术在临床上的应用，特别是计算机化暴露疗法，可以根据患者的反应动态调整视觉刺激。为了实现这一目标，研究了预训练的计算机视觉模型能否准确预测与蜘蛛相关的图像的恐惧水平。

Method: 使用迁移学习，对三个不同的预训练模型进行了改编，以预测基于313张图像的标准数据集的人类恐惧评分（0-100分）。使用交叉验证进行评估，平均绝对误差（MAE）在10.1到11.0之间。

Result: 学习曲线分析表明，减小数据集大小会显著损害模型性能，但增加数据集大小并不能带来显著的性能提升。可解释性评估表明，模型的预测基于与蜘蛛相关的特征。按类别进行的误差分析进一步确定了与较高误差相关的视觉条件（例如，远景和人造/绘制的蜘蛛）。

Conclusion: 研究结果表明，可解释的计算机视觉模型在预测恐惧评分方面具有潜力，并强调了模型可解释性和足够的数据集大小对于开发有效的、能感知情绪的治疗技术的。

Abstract: Advances in computer vision have opened new avenues for clinical
applications, particularly in computerized exposure therapy where visual
stimuli can be dynamically adjusted based on patient responses. As a critical
step toward such adaptive systems, we investigated whether pretrained computer
vision models can accurately predict fear levels from spider-related images. We
adapted three diverse models using transfer learning to predict human fear
ratings (on a 0-100 scale) from a standardized dataset of 313 images. The
models were evaluated using cross-validation, achieving an average mean
absolute error (MAE) between 10.1 and 11.0. Our learning curve analysis
revealed that reducing the dataset size significantly harmed performance,
though further increases yielded no substantial gains. Explainability
assessments showed the models' predictions were based on spider-related
features. A category-wise error analysis further identified visual conditions
associated with higher errors (e.g., distant views and artificial/painted
spiders). These findings demonstrate the potential of explainable computer
vision models in predicting fear ratings, highlighting the importance of both
model explainability and a sufficient dataset size for developing effective
emotion-aware therapeutic technologies.

</details>


### [32] [SynGen-Vision: Synthetic Data Generation for training industrial vision models](https://arxiv.org/abs/2509.04894)
*Alpana Dubey,Suma Mani Kuriakose,Nitish Bhardwaj*

Main category: cs.CV

TL;DR: 我们提出了一种生成合成数据来训练用于工业磨损检测的计算机视觉模型的方法。该方法使用视觉语言模型和3D渲染引擎来生成各种锈蚀条件下的合成数据，并在真实数据集上评估了生成的模型。


<details>
  <summary>Details</summary>
Motivation: 工业磨损检测对于预测性维护很重要，但现有数据集的收集成本高昂且耗时。

Method: 使用视觉语言模型、3D模拟和渲染引擎生成用于锈蚀检测的合成数据。

Result: 使用合成数据训练的CV模型在真实图像上表现优于其他方法，mAP50得分为0.87。

Conclusion: 该方法能够生成高质量的合成数据，可用于训练CV模型，并且易于扩展到其他工业磨损检测场景。

Abstract: We propose an approach to generate synthetic data to train computer vision
(CV) models for industrial wear and tear detection. Wear and tear detection is
an important CV problem for predictive maintenance tasks in any industry.
However, data curation for training such models is expensive and time-consuming
due to the unavailability of datasets for different wear and tear scenarios.
Our approach employs a vision language model along with a 3D simulation and
rendering engine to generate synthetic data for varying rust conditions. We
evaluate our approach by training a CV model for rust detection using the
generated dataset and tested the trained model on real images of rusted
industrial objects. The model trained with the synthetic data generated by our
approach, outperforms the other approaches with a mAP50 score of 0.87. The
approach is customizable and can be easily extended to other industrial wear
and tear detection scenarios

</details>


### [33] [Evaluating Multiple Instance Learning Strategies for Automated Sebocyte Droplet Counting](https://arxiv.org/abs/2509.04895)
*Maryam Adelipour,Gustavo Carneiro,Jeongkwon Kim*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Sebocytes are lipid-secreting cells whose differentiation is marked by the
accumulation of intracellular lipid droplets, making their quantification a key
readout in sebocyte biology. Manual counting is labor-intensive and subjective,
motivating automated solutions. Here, we introduce a simple attention-based
multiple instance learning (MIL) framework for sebocyte image analysis. Nile
Red-stained sebocyte images were annotated into 14 classes according to droplet
counts, expanded via data augmentation to about 50,000 cells. Two models were
benchmarked: a baseline multi-layer perceptron (MLP) trained on aggregated
patch-level counts, and an attention-based MIL model leveraging ResNet-50
features with instance weighting. Experiments using five-fold cross-validation
showed that the baseline MLP achieved more stable performance (mean MAE = 5.6)
compared with the attention-based MIL, which was less consistent (mean MAE =
10.7) but occasionally superior in specific folds. These findings indicate that
simple bag-level aggregation provides a robust baseline for slide-level droplet
counting, while attention-based MIL requires task-aligned pooling and
regularization to fully realize its potential in sebocyte image analysis.

</details>


### [34] [UniView: Enhancing Novel View Synthesis From A Single Image By Unifying Reference Features](https://arxiv.org/abs/2509.04932)
*Haowang Cui,Rui Chen,Tao Luo,Rui Li,Jiaze Wang*

Main category: cs.CV

TL;DR: UniView模型利用参考图像来解决单图像新视图合成中的多义性问题，通过检索、多模态大语言模型辅助选择参考图，并引入适配器模块和解耦三重注意力机制来提高合成质量和细节保留。


<details>
  <summary>Details</summary>
Motivation: 单图像新视图合成任务由于对未观测区域存在多种解释而本质上是病态的，现有方法常因依赖模糊先验和插值导致严重失真。

Method:  UniView模型首先构建检索和增强系统，并利用多模态大语言模型辅助选择具有相似对象特征的参考图像。然后，引入一个带有多级隔离层的即插即用适配器模块，为目标视图动态生成参考特征。最后，设计了一个解耦三重注意力机制来对齐和整合多分支特征，以保留原始输入图像的细节。

Result: UniView在挑战性数据集上进行了广泛的实验评估，结果表明其显著提高了新视图合成的性能。

Conclusion: UniView模型通过引入参考图像的强先验信息，有效解决了单图像新视图合成中的多义性问题，并优于当前最先进的方法。

Abstract: The task of synthesizing novel views from a single image is highly ill-posed
due to multiple explanations for unobserved areas. Most current methods tend to
generate unseen regions from ambiguity priors and interpolation near input
views, which often lead to severe distortions. To address this limitation, we
propose a novel model dubbed as UniView, which can leverage reference images
from a similar object to provide strong prior information during view
synthesis. More specifically, we construct a retrieval and augmentation system
and employ a multimodal large language model (MLLM) to assist in selecting
reference images that meet our requirements. Additionally, a plug-and-play
adapter module with multi-level isolation layers is introduced to dynamically
generate reference features for the target views. Moreover, in order to
preserve the details of an original input image, we design a decoupled triple
attention mechanism, which can effectively align and integrate multi-branch
features into the synthesis process. Extensive experiments have demonstrated
that our UniView significantly improves novel view synthesis performance and
outperforms state-of-the-art methods on the challenging datasets.

</details>


### [35] [Efficient Video-to-Audio Generation via Multiple Foundation Models Mapper](https://arxiv.org/abs/2509.04957)
*Gehui Chen,Guan'an Wang,Xiaowen Huang,Jitao Sang*

Main category: cs.CV

TL;DR: MFM-Mapper通过融合双视觉编码器的特征并使用GPT-2替代线性映射器，实现了高效且性能优越的视频到音频生成。


<details>
  <summary>Details</summary>
Motivation: 现有视频到音频（V2A）生成方法需要从头训练计算资源密集型模型，而利用预训练的基础模型（FM）进行跨模态知识迁移和泛化能力则成为一种有前景的解决方案。

Method: 提出了一种名为MFM-Mapper的多基础模型映射器。与先前仅使用单一视觉编码器和线性映射器的方法不同，MFM-Mapper融合了来自双视觉编码器的特征，并使用GPT-2替代了线性映射器，以实现更好的特征对齐。

Result: MFM-Mapper在训练效率上表现出色，仅使用了先前基于映射器方法16%的训练规模，就能达到具有竞争力的性能，并在语义和时间一致性方面取得了更好的结果。

Conclusion: MFM-Mapper通过融合多模态特征和利用GPT-2进行映射，在V2A生成任务中展现了显著的训练效率和优越的性能。

Abstract: Recent Video-to-Audio (V2A) generation relies on extracting semantic and
temporal features from video to condition generative models. Training these
models from scratch is resource intensive. Consequently, leveraging foundation
models (FMs) has gained traction due to their cross-modal knowledge transfer
and generalization capabilities. One prior work has explored fine-tuning a
lightweight mapper network to connect a pre-trained visual encoder with a
text-to-audio generation model for V2A. Inspired by this, we introduce the
Multiple Foundation Model Mapper (MFM-Mapper). Compared to the previous mapper
approach, MFM-Mapper benefits from richer semantic and temporal information by
fusing features from dual visual encoders. Furthermore, by replacing a linear
mapper with GPT-2, MFM-Mapper improves feature alignment, drawing parallels
between cross-modal features mapping and autoregressive translation tasks. Our
MFM-Mapper exhibits remarkable training efficiency. It achieves better
performance in semantic and temporal consistency with fewer training consuming,
requiring only 16\% of the training scale compared to previous mapper-based
work, yet achieves competitive performance with models trained on a much larger
scale.

</details>


### [36] [Dual-Domain Perspective on Degradation-Aware Fusion: A VLM-Guided Robust Infrared and Visible Image Fusion Framework](https://arxiv.org/abs/2509.05000)
*Tianpei Zhang,Jufeng Zhao,Yiming Zhu,Guangmang Cui*

Main category: cs.CV

TL;DR: GD^2Fusion框架通过融合视觉语言模型和双域联合优化来解决红外-可见光图像融合中的降质问题。


<details>
  <summary>Details</summary>
Motivation: 现有红外-可见光图像融合方法在处理双源降质场景时表现不佳，需要手动选择和多步预处理，导致误差累积和性能下降。

Method: 提出了一种名为GD^2Fusion的新框架，该框架集成了视觉语言模型（VLMs）以感知降质，并进行频域/空间域联合优化。具体包括：1. 引导式频率域特定模态提取（GFMSE）模块，用于感知和抑制频域降质，并提取与融合相关的子带特征。2. 引导式空间域特定模态聚合（GSMAF）模块，用于跨模态降质滤波和自适应多源特征聚合，以增强模态互补性和结构一致性。

Result: 在双源降质场景下，GD^2Fusion在定性和定量实验中均表现出优于现有算法和策略的融合性能。

Conclusion: GD^2Fusion框架能够有效解决双源降质场景下的红外-可见光图像融合问题，并取得优于现有方法的性能。

Abstract: Most existing infrared-visible image fusion (IVIF) methods assume
high-quality inputs, and therefore struggle to handle dual-source degraded
scenarios, typically requiring manual selection and sequential application of
multiple pre-enhancement steps. This decoupled pre-enhancement-to-fusion
pipeline inevitably leads to error accumulation and performance degradation. To
overcome these limitations, we propose Guided Dual-Domain Fusion (GD^2Fusion),
a novel framework that synergistically integrates vision-language models (VLMs)
for degradation perception with dual-domain (frequency/spatial) joint
optimization. Concretely, the designed Guided Frequency Modality-Specific
Extraction (GFMSE) module performs frequency-domain degradation perception and
suppression and discriminatively extracts fusion-relevant sub-band features.
Meanwhile, the Guided Spatial Modality-Aggregated Fusion (GSMAF) module carries
out cross-modal degradation filtering and adaptive multi-source feature
aggregation in the spatial domain to enhance modality complementarity and
structural consistency. Extensive qualitative and quantitative experiments
demonstrate that GD^2Fusion achieves superior fusion performance compared with
existing algorithms and strategies in dual-source degraded scenarios. The code
will be publicly released after acceptance of this paper.

</details>


### [37] [Interpretable Deep Transfer Learning for Breast Ultrasound Cancer Detection: A Multi-Dataset Study](https://arxiv.org/abs/2509.05004)
*Mohammad Abbadi,Yassine Himeur,Shadi Atalla,Wathiq Mansoor*

Main category: cs.CV

TL;DR: ResNet-18在乳腺癌超声图像分类中达到99.7%的准确率和完美的敏感性，表明AI诊断工具可集成到临床工作流程中。


<details>
  <summary>Details</summary>
Motivation: 超声成像在乳腺癌早期检测中很重要，尤其对于乳腺组织致密的患者。本研究旨在应用机器学习和深度学习技术对乳腺癌进行超声图像分类。

Method: 使用BUSI、BUS-BRA和BrEaST-Lesions USG数据集，评估了SVM、KNN等经典机器学习模型以及ResNet-18、EfficientNet-B0、GoogLeNet等深度卷积神经网络。并利用Grad-CAM可视化来增强模型的可解释性。

Result: ResNet-18在所有模型中表现最佳，准确率达到99.7%，对恶性病灶的敏感性完美。经典机器学习模型在深度特征提取的增强下也取得了有竞争力的性能。

Conclusion: 深度学习模型，特别是ResNet-18，在乳腺癌超声图像分类方面表现出高精度和高敏感性。AI诊断工具的集成是可行的，并且可以部署高性能、可解释的系统用于超声引导的乳腺癌检测。

Abstract: Breast cancer remains a leading cause of cancer-related mortality among women
worldwide. Ultrasound imaging, widely used due to its safety and
cost-effectiveness, plays a key role in early detection, especially in patients
with dense breast tissue. This paper presents a comprehensive study on the
application of machine learning and deep learning techniques for breast cancer
classification using ultrasound images. Using datasets such as BUSI, BUS-BRA,
and BrEaST-Lesions USG, we evaluate classical machine learning models (SVM,
KNN) and deep convolutional neural networks (ResNet-18, EfficientNet-B0,
GoogLeNet). Experimental results show that ResNet-18 achieves the highest
accuracy (99.7%) and perfect sensitivity for malignant lesions. Classical ML
models, though outperformed by CNNs, achieve competitive performance when
enhanced with deep feature extraction. Grad-CAM visualizations further improve
model transparency by highlighting diagnostically relevant image regions. These
findings support the integration of AI-based diagnostic tools into clinical
workflows and demonstrate the feasibility of deploying high-performing,
interpretable systems for ultrasound-based breast cancer detection.

</details>


### [38] [A biologically inspired separable learning vision model for real-time traffic object perception in Dark](https://arxiv.org/abs/2509.05012)
*Hulin Li,Qiliang Ren,Jun Li,Hanbing Wei,Zheng Liu,Linfang Fan*

Main category: cs.CV

TL;DR: 本文提出了一种用于低光照交通场景的感知方法（SLVM）和数据集（Dark-traffic），旨在解决低光照条件下物体识别的难题。


<details>
  <summary>Details</summary>
Motivation: 低光照交通场景下的物体感知精度和速度要求日益提高，但现有模型在低光环境下表现不佳，且缺乏专门的大规模数据集。

Method: 提出了一种基于物理的光照退化模型，并构建了迄今为止最大的低光照交通场景数据集Dark-traffic。在此基础上，设计了分离式学习视觉模型（SLVM），包含光适应瞳孔机制、特征级分离学习策略、任务特定的解耦分支以及空间失准感知融合模块。

Result: SLVM在Dark-traffic数据集上实现了最先进的性能，检测精度超越RT-DETR 11.2个百分点，实例分割精度超越YOLOv12 6.1个百分点，端点误差（EPE）降低12.37%。在LIS基准上，SLVM的平均性能也优于其他先进模型。

Conclusion: SLVM在低光照交通场景下展现出优越的感知能力，并且计算开销较低，证明了其有效性。所提出的Dark-traffic数据集和SLVM模型为该领域的研究提供了宝贵资源。

Abstract: Fast and accurate object perception in low-light traffic scenes has attracted
increasing attention. However, due to severe illumination degradation and the
lack of reliable visual cues, existing perception models and methods struggle
to quickly adapt to and accurately predict in low-light environments. Moreover,
there is the absence of available large-scale benchmark specifically focused on
low-light traffic scenes. To bridge this gap, we introduce a physically
grounded illumination degradation method tailored to real-world low-light
settings and construct Dark-traffic, the largest densely annotated dataset to
date for low-light traffic scenes, supporting object detection, instance
segmentation, and optical flow estimation. We further propose the Separable
Learning Vision Model (SLVM), a biologically inspired framework designed to
enhance perception under adverse lighting. SLVM integrates four key components:
a light-adaptive pupillary mechanism for illumination-sensitive feature
extraction, a feature-level separable learning strategy for efficient
representation, task-specific decoupled branches for multi-task separable
learning, and a spatial misalignment-aware fusion module for precise
multi-feature alignment. Extensive experiments demonstrate that SLVM achieves
state-of-the-art performance with reduced computational overhead. Notably, it
outperforms RT-DETR by 11.2 percentage points in detection, YOLOv12 by 6.1
percentage points in instance segmentation, and reduces endpoint error (EPE) of
baseline by 12.37% on Dark-traffic. On the LIS benchmark, the end-to-end
trained SLVM surpasses Swin Transformer+EnlightenGAN and
ConvNeXt-T+EnlightenGAN by an average of 11 percentage points across key
metrics, and exceeds Mask RCNN (with light enhancement) by 3.1 percentage
points. The Dark-traffic dataset and complete code is released at
https://github.com/alanli1997/slvm.

</details>


### [39] [Leveraging Transfer Learning and Mobile-enabled Convolutional Neural Networks for Improved Arabic Handwritten Character Recognition](https://arxiv.org/abs/2509.05019)
*Mohsine El Khayati,Ayyad Maafiri,Yassine Himeur,Hamzah Ali Alkhazaleh,Shadi Atalla,Wathiq Mansoor*

Main category: cs.CV

TL;DR: 该研究将迁移学习（TL）与移动端卷积神经网络（MbNets）相结合，以提升阿拉伯手写字符识别（AHCR）的性能。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决阿拉伯手写字符识别（AHCR）中计算资源需求大和数据集稀疏的挑战。

Method: 评估了三种迁移学习策略（完全微调、部分微调、从头训练）和四种轻量级MbNets（MobileNet、SqueezeNet、MnasNet、ShuffleNet），并在三个基准数据集（AHCD、HIJJA、IFHCDB）上进行了实验。

Result: MobileNet 在准确性、鲁棒性和效率方面表现最佳，ShuffleNet 在泛化能力方面表现突出。在 IFHCDB 数据集上，MnasNet 在完全微调下达到了 99% 的准确率。AHCD 数据集使用 ShuffleNet 达到 97% 的准确率。HIJJA 数据集由于其变异性，使用 ShuffleNet 达到了 92% 的准确率。完全微调在准确性和收敛速度之间取得了最佳平衡。

Conclusion: TL 和 MbNets 的结合为资源高效的 AHCR 提供了潜力，未来的工作将集中在架构修改、数据集特征分析、数据增强和敏感性分析等方面。

Abstract: The study explores the integration of transfer learning (TL) with
mobile-enabled convolutional neural networks (MbNets) to enhance Arabic
Handwritten Character Recognition (AHCR). Addressing challenges like extensive
computational requirements and dataset scarcity, this research evaluates three
TL strategies--full fine-tuning, partial fine-tuning, and training from
scratch--using four lightweight MbNets: MobileNet, SqueezeNet, MnasNet, and
ShuffleNet. Experiments were conducted on three benchmark datasets: AHCD,
HIJJA, and IFHCDB. MobileNet emerged as the top-performing model, consistently
achieving superior accuracy, robustness, and efficiency, with ShuffleNet
excelling in generalization, particularly under full fine-tuning. The IFHCDB
dataset yielded the highest results, with 99% accuracy using MnasNet under full
fine-tuning, highlighting its suitability for robust character recognition. The
AHCD dataset achieved competitive accuracy (97%) with ShuffleNet, while HIJJA
posed significant challenges due to its variability, achieving a peak accuracy
of 92% with ShuffleNet. Notably, full fine-tuning demonstrated the best overall
performance, balancing accuracy and convergence speed, while partial
fine-tuning underperformed across metrics. These findings underscore the
potential of combining TL and MbNets for resource-efficient AHCR, paving the
way for further optimizations and broader applications. Future work will
explore architectural modifications, in-depth dataset feature analysis, data
augmentation, and advanced sensitivity analysis to enhance model robustness and
generalizability.

</details>


### [40] [LUIVITON: Learned Universal Interoperable VIrtual Try-ON](https://arxiv.org/abs/2509.05030)
*Cong Cao,Xianhang Cheng,Jingyuan Liu,Yujian Zheng,Zhenhui Lin,Meriem Chkir,Hao Li*

Main category: cs.CV

TL;DR: LUIVITON是一个全自动虚拟试穿系统，能够将多层复杂服装适配到任意姿势的人形角色上，解决了服装与身体匹配的难题。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够处理复杂、多层服装和任意姿势的人形角色的全自动虚拟试穿系统，以解决服装对齐的挑战。

Method: 采用SMPL作为代理表示，将服装到身体的匹配问题分解为服装到SMPL和身体到SMPL的对应关系。服装到SMPL的匹配采用基于几何学习的方法，身体到SMPL的匹配则使用基于扩散模型的、具有多视角一致外观特征和预训练2D基础模型的方法。

Result: LUIVITON能够处理复杂的几何形状、非流形网格，并能广泛适用于人类、机器人、卡通角色、生物和外星人等各种人形角色，同时保持计算效率。该系统可以生成高质量的3D服装试穿效果，无需人工干预，即使在没有2D服装缝纫图的情况下也能实现。

Conclusion: LUIVITON提供了一个全自动的虚拟试穿解决方案，支持服装尺寸和材质属性的快速定制，无需人工劳动即可生成高质量的3D服装试穿效果。

Abstract: We present LUIVITON, an end-to-end system for fully automated virtual try-on,
capable of draping complex, multi-layer clothing onto diverse and arbitrarily
posed humanoid characters. To address the challenge of aligning complex
garments with arbitrary and highly diverse body shapes, we use SMPL as a proxy
representation and separate the clothing-to-body draping problem into two
correspondence tasks: 1) clothing-to-SMPL and 2) body-to-SMPL correspondence,
where each has its unique challenges. While we address the clothing-to-SMPL
fitting problem using a geometric learning-based approach for
partial-to-complete shape correspondence prediction, we introduce a diffusion
model-based approach for body-to-SMPL correspondence using multi-view
consistent appearance features and a pre-trained 2D foundation model. Our
method can handle complex geometries, non-manifold meshes, and generalizes
effectively to a wide range of humanoid characters -- including humans, robots,
cartoon subjects, creatures, and aliens, while maintaining computational
efficiency for practical adoption. In addition to offering a fully automatic
fitting solution, LUIVITON supports fast customization of clothing size,
allowing users to adjust clothing sizes and material properties after they have
been draped. We show that our system can produce high-quality 3D clothing
fittings without any human labor, even when 2D clothing sewing patterns are not
available.

</details>


### [41] [Towards Efficient Pixel Labeling for Industrial Anomaly Detection and Localization](https://arxiv.org/abs/2509.05034)
*Jingqi Wu,Hanxi Li,Lin Yuanbo Wu,Hao Chen,Deyin Liu,Peng Wang*

Main category: cs.CV

TL;DR: ADClick通过用户点击和文本描述生成像素级异常注释，提高了工业异常检测模型的性能。ADClick-Seg是一个跨模态框架，通过原型方法对齐视觉特征和文本提示，在多类别异常检测任务上取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 现有的工业产品检测方法（异常检测）仅使用非缺陷样本进行训练，而利用缺陷样本又需要像素级注释，限制了其可扩展性。本研究旨在解决这一问题，通过交互式图像分割（IIS）算法实现高效的像素级异常注释，以提高异常检测模型的性能。

Method: 提出ADClick算法，一种交互式图像分割（IIS）算法，能够仅通过几次用户点击和简短的文本描述生成像素级异常注释。在此基础上，进一步提出ADClick-Seg跨模态框架，利用原型方法对齐视觉特征和文本提示，实现异常检测和定位。

Result: ADClick能够精确高效地进行标注，显著提高了异常检测模型的性能（例如，在MVTec AD数据集上的AP达到96.1%）。ADClick-Seg在MVTec AD数据集的多类别异常检测任务上取得了最先进的成果（AP = 80.0%，PRO = 97.5%，Pixel-AUROC = 99.1%）。

Conclusion: ADClick通过交互式标注解决了工业异常检测中数据标注的挑战，并取得了显著的性能提升。ADClick-Seg进一步通过结合像素级先验和语言引导线索，在复杂的多类别异常检测任务上实现了最先进的性能。

Abstract: Industrial product inspection is often performed using Anomaly Detection (AD)
frameworks trained solely on non-defective samples. Although defective samples
can be collected during production, leveraging them usually requires
pixel-level annotations, limiting scalability. To address this, we propose
ADClick, an Interactive Image Segmentation (IIS) algorithm for industrial
anomaly detection. ADClick generates pixel-wise anomaly annotations from only a
few user clicks and a brief textual description, enabling precise and efficient
labeling that significantly improves AD model performance (e.g., AP = 96.1\% on
MVTec AD). We further introduce ADClick-Seg, a cross-modal framework that
aligns visual features and textual prompts via a prototype-based approach for
anomaly detection and localization. By combining pixel-level priors with
language-guided cues, ADClick-Seg achieves state-of-the-art results on the
challenging ``Multi-class'' AD task (AP = 80.0\%, PRO = 97.5\%, Pixel-AUROC =
99.1\% on MVTec AD).

</details>


### [42] [Systematic Review and Meta-analysis of AI-driven MRI Motion Artifact Detection and Correction](https://arxiv.org/abs/2509.05071)
*Mojtaba Safari,Zach Eidex,Richard L. J. Qiu,Matthew Goette,Tonghe Wang,Xiaofeng Yang*

Main category: cs.CV

TL;DR: 深度学习（特别是生成模型）在检测和纠正MRI运动伪影方面显示出巨大潜力，但仍面临泛化性有限、对配对训练数据有依赖性以及可能出现视觉失真等挑战。


<details>
  <summary>Details</summary>
Motivation: 对人工智能（AI）驱动的检测和纠正磁共振成像（MRI）运动伪影的方法进行系统性回顾和荟萃分析，以评估其当前发展、有效性、挑战和未来研究方向。

Method: 对专注于深度学习（DL）方法（特别是生成模型）的MRI运动伪影检测和纠正的文献进行全面的系统性回顾和荟萃分析，并提取关于所用数据集、DL架构和性能指标的定量数据。

Result: 深度学习（特别是生成模型）在减少运动伪影和提高图像质量方面显示出前景，但泛化性有限、依赖配对训练数据和视觉失真风险是需要解决的关键挑战，这促使人们需要标准化数据集和报告。

Conclusion: AI驱动的方法（特别是DL生成模型）通过有效解决运动伪影，在提高MRI图像质量方面显示出巨大潜力。然而，必须解决关键挑战，包括需要全面的公共数据集、伪影级别的标准化报告协议以及更先进、更灵活的DL技术，以减少对大量配对数据集的依赖。解决这些方面可以显著提高MRI诊断的准确性，降低医疗保健成本，并改善患者的护理结果。

Abstract: Background: To systematically review and perform a meta-analysis of
artificial intelligence (AI)-driven methods for detecting and correcting
magnetic resonance imaging (MRI) motion artifacts, assessing current
developments, effectiveness, challenges, and future research directions.
Methods: A comprehensive systematic review and meta-analysis were conducted,
focusing on deep learning (DL) approaches, particularly generative models, for
the detection and correction of MRI motion artifacts. Quantitative data were
extracted regarding utilized datasets, DL architectures, and performance
metrics. Results: DL, particularly generative models, show promise for reducing
motion artifacts and improving image quality; however, limited
generalizability, reliance on paired training data, and risk of visual
distortions remain key challenges that motivate standardized datasets and
reporting. Conclusions: AI-driven methods, particularly DL generative models,
show significant potential for improving MRI image quality by effectively
addressing motion artifacts. However, critical challenges must be addressed,
including the need for comprehensive public datasets, standardized reporting
protocols for artifact levels, and more advanced, adaptable DL techniques to
reduce reliance on extensive paired datasets. Addressing these aspects could
substantially enhance MRI diagnostic accuracy, reduce healthcare costs, and
improve patient care outcomes.

</details>


### [43] [GeoSplat: A Deep Dive into Geometry-Constrained Gaussian Splatting](https://arxiv.org/abs/2509.05075)
*Yangming Li,Chaoyu Liu,Lihao Liu,Simon Masnou,Carola-Bibian Schönlieb*

Main category: cs.CV

TL;DR: GeoSplat是一个将几何先验融入高斯渲染的框架，通过利用一阶和二阶几何量来改进训练流程，并在实验中显著提升了渲染性能。


<details>
  <summary>Details</summary>
Motivation: 现有高斯渲染方法在优化中引入几何先验的研究存在局限性，如仅关注低阶几何量且估计方法对噪声敏感。为了克服这些缺点，提出GeoSplat框架。

Method: GeoSplat框架利用一阶和二阶几何量来改进高斯初始化、梯度更新和密度增加等整个训练流程。例如，通过主曲率初始化3D高斯尺度，并引入基于局部流形等几何结构的高效、抗噪声的动态几何先验估计方法。

Result: 在多个新视图合成数据集上的大量实验表明，GeoSplat框架显著提高了高斯渲染的性能，并优于之前的基线方法。

Conclusion: GeoSplat通过整合几何先验，有效解决了现有方法的局限性，并在高斯渲染方面取得了显著的性能提升。

Abstract: A few recent works explored incorporating geometric priors to regularize the
optimization of Gaussian splatting, further improving its performance. However,
those early studies mainly focused on the use of low-order geometric priors
(e.g., normal vector), and they are also unreliably estimated by
noise-sensitive methods, like local principal component analysis. To address
their limitations, we first present GeoSplat, a general geometry-constrained
optimization framework that exploits both first-order and second-order
geometric quantities to improve the entire training pipeline of Gaussian
splatting, including Gaussian initialization, gradient update, and
densification. As an example, we initialize the scales of 3D Gaussian
primitives in terms of principal curvatures, leading to a better coverage of
the object surface than random initialization. Secondly, based on certain
geometric structures (e.g., local manifold), we introduce efficient and
noise-robust estimation methods that provide dynamic geometric priors for our
framework. We conduct extensive experiments on multiple datasets for novel view
synthesis, showing that our framework: GeoSplat, significantly improves the
performance of Gaussian splatting and outperforms previous baselines.

</details>


### [44] [Scale-interaction transformer: a hybrid cnn-transformer model for facial beauty prediction](https://arxiv.org/abs/2509.05078)
*Djamel Eddine Boukhari*

Main category: cs.CV

TL;DR: SIT模型通过结合CNN和Transformer的优势，在面部美容预测任务上取得了新的SOTA成果。


<details>
  <summary>Details</summary>
Motivation: 现有的CNN模型在处理面部美容预测时，可能因固定尺度的特征提取而忽略不同层级特征间的相互依赖性。

Method: 提出了一种名为SIT（Scale-Interaction Transformer）的新型混合深度学习架构，该架构结合了CNN的多尺度特征提取能力和Transformer的关系建模能力。具体而言，SIT首先使用并行卷积的多尺度模块来捕捉不同感受野的面部特征，然后将这些多尺度表示作为序列输入到Transformer编码器中，通过自注意力机制显式地建模它们之间的交互和上下文关系。

Result: 在SCUT-FBP5500数据集上进行的大量实验表明，SIT模型取得了0.9187的皮尔逊相关系数，优于先前的方法，并达到了新的SOTA水平。

Conclusion: 显式地建模多尺度视觉线索的相互作用对于高性能的面部美容预测至关重要。SIT架构的成功证明了混合CNN-Transformer模型在需要整体、上下文感知理解的复杂图像回归任务中的潜力。

Abstract: Automated Facial Beauty Prediction (FBP) is a challenging computer vision
task due to the complex interplay of local and global facial features that
influence human perception. While Convolutional Neural Networks (CNNs) excel at
feature extraction, they often process information at a fixed scale,
potentially overlooking the critical inter-dependencies between features at
different levels of granularity. To address this limitation, we introduce the
Scale-Interaction Transformer (SIT), a novel hybrid deep learning architecture
that synergizes the feature extraction power of CNNs with the relational
modeling capabilities of Transformers. The SIT first employs a multi-scale
module with parallel convolutions to capture facial characteristics at varying
receptive fields. These multi-scale representations are then framed as a
sequence and processed by a Transformer encoder, which explicitly models their
interactions and contextual relationships via a self-attention mechanism. We
conduct extensive experiments on the widely-used SCUT-FBP5500 benchmark
dataset, where the proposed SIT model establishes a new state-of-the-art. It
achieves a Pearson Correlation of 0.9187, outperforming previous methods. Our
findings demonstrate that explicitly modeling the interplay between multi-scale
visual cues is crucial for high-performance FBP. The success of the SIT
architecture highlights the potential of hybrid CNN-Transformer models for
complex image regression tasks that demand a holistic, context-aware
understanding.

</details>


### [45] [Robust Experts: the Effect of Adversarial Training on CNNs with Sparse Mixture-of-Experts Layers](https://arxiv.org/abs/2509.05086)
*Svetlana Pavlitska,Haixi Fan,Konstantin Ditschuneit,J. Marius Zöllner*

Main category: cs.CV

TL;DR: 通过在CNN中引入稀疏混合专家（MoE）层，我们发现可以提高模型在对抗性攻击下的鲁棒性。在ResNet模型中插入MoE层，并在使用对抗性训练时，能够有效提升模型在PGD和AutoPGD攻击下的鲁棒性。有趣的是，我们还发现当使用开关损失（switch loss）进行平衡时，会导致路由集中在少数几个专家上，从而使得这些专家在对抗性训练下变得更加鲁棒，甚至超过了整体MoE模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的鲁棒化CNN的方法通常需要消耗大量的计算资源。本研究旨在探索一种更有效的方法来提高CNN的鲁棒性，以应对对抗性攻击。

Method: 本研究通过在CNN中，特别是ResNet架构的残差块或卷积层中，引入稀疏混合专家（MoE）层来增强模型容量，而不会增加推理成本。研究人员在CIFAR-100数据集上进行了实验，并结合了对抗性训练。同时，他们还分析了在采用开关损失进行负载均衡时，路由机制的行为及其对鲁棒性的影响。

Result: 在ResNet架构上，通过在模型的较深层插入单个MoE层，并结合对抗性训练，可以显著提高模型在PGD和AutoPGD攻击下的鲁棒性。研究还发现，当使用开关损失进行平衡时，路由会过度集中在少数专家上，导致这些专家比整个MoE模型更具鲁棒性，表明了专家特化的现象。

Conclusion: 稀疏混合专家（MoE）层是一种有前景的方法，可以提高CNN的鲁棒性，并且通过路由机制的特化，可以进一步优化鲁棒性表现。

Abstract: Robustifying convolutional neural networks (CNNs) against adversarial attacks
remains challenging and often requires resource-intensive countermeasures. We
explore the use of sparse mixture-of-experts (MoE) layers to improve robustness
by replacing selected residual blocks or convolutional layers, thereby
increasing model capacity without additional inference cost. On ResNet
architectures trained on CIFAR-100, we find that inserting a single MoE layer
in the deeper stages leads to consistent improvements in robustness under PGD
and AutoPGD attacks when combined with adversarial training. Furthermore, we
discover that when switch loss is used for balancing, it causes routing to
collapse onto a small set of overused experts, thereby concentrating
adversarial training on these paths and inadvertently making them more robust.
As a result, some individual experts outperform the gated MoE model in
robustness, suggesting that robust subpaths emerge through specialization. Our
code is available at https://github.com/KASTEL-MobilityLab/robust-sparse-moes.

</details>


### [46] [Semi-supervised Deep Transfer for Regression without Domain Alignment](https://arxiv.org/abs/2509.05092)
*Mainak Biswas,Ambedkar Dukkipati,Devarajan Sridharan*

Main category: cs.CV

TL;DR: CRAFT框架能够有效解决源域数据缺失、目标域标注数据稀疏的半监督迁移学习问题，特别是在生物医学等领域的连续值预测任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 在实际应用中，深度学习模型常面临领域迁移带来的泛化能力挑战，而许多现有方法需要访问源数据，这在隐私或成本不允许的情况下不现实。同时，目标域的标注数据也可能有限，尤其是在神经科学等需要连续值预测的场景。

Method: 提出了一种名为CRAFT（Contradistinguisher-based Regularization Approach for Flexible Training）的框架，该框架基于Contradistinguisher（CUDA），用于源域数据缺失（source-free）、半监督迁移学习场景下的回归任务。CRAFT在没有中间表示对齐的情况下，利用有限的目标域标注数据和无标注数据，以及预训练的源模型进行训练，并引入了基于Contradistinguisher的正则化方法。

Result: 在神经科学的两个应用场景（脑电图EEG数据预测注视点和结构MRI数据预测大脑年龄）中，CRAFT相比于微调模型，在标注数据稀疏时，RMSE（均方根误差）最高可提升9%。与四种最先进的源域数据缺失的领域自适应模型相比，CRAFT的性能提升超过3%。此外，CRAFT在另外两个实际回归基准测试中也显示了其有效性。

Conclusion: CRAFT是一种高效的、适用于源域数据缺失和半监督学习的深度迁移学习方法，特别适用于生物和医学领域普遍存在的回归任务。

Abstract: Deep learning models deployed in real-world applications (e.g., medicine)
face challenges because source models do not generalize well to domain-shifted
target data. Many successful domain adaptation (DA) approaches require full
access to source data. Yet, such requirements are unrealistic in scenarios
where source data cannot be shared either because of privacy concerns or
because it is too large and incurs prohibitive storage or computational costs.
Moreover, resource constraints may limit the availability of labeled targets.
We illustrate this challenge in a neuroscience setting where source data are
unavailable, labeled target data are meager, and predictions involve
continuous-valued outputs. We build upon Contradistinguisher (CUDA), an
efficient framework that learns a shared model across the labeled source and
unlabeled target samples, without intermediate representation alignment. Yet,
CUDA was designed for unsupervised DA, with full access to source data, and for
classification tasks. We develop CRAFT -- a Contradistinguisher-based
Regularization Approach for Flexible Training -- for source-free (SF),
semi-supervised transfer of pretrained models in regression tasks. We showcase
the efficacy of CRAFT in two neuroscience settings: gaze prediction with
electroencephalography (EEG) data and ``brain age'' prediction with structural
MRI data. For both datasets, CRAFT yielded up to 9% improvement in
root-mean-squared error (RMSE) over fine-tuned models when labeled training
examples were scarce. Moreover, CRAFT leveraged unlabeled target data and
outperformed four competing state-of-the-art source-free domain adaptation
models by more than 3%. Lastly, we demonstrate the efficacy of CRAFT on two
other real-world regression benchmarks. We propose CRAFT as an efficient
approach for source-free, semi-supervised deep transfer for regression that is
ubiquitous in biology and medicine.

</details>


### [47] [A Scalable Attention-Based Approach for Image-to-3D Texture Mapping](https://arxiv.org/abs/2509.05131)
*Arianna Rampini,Kanika Madan,Bruno Roy,AmirHossein Zamani,Derek Cheung*

Main category: cs.CV

TL;DR: 我们提出了一种直接从单个图像和网格预测 3D 纹理场的新型 Transformer 框架，无需 UV 映射和可微分渲染，从而实现快速、高质量的 3D 纹理生成。


<details>
  <summary>Details</summary>
Motivation: 现有的生成 3D 纹理的方法速度慢、依赖 UV 映射且难以忠实于参考图像，这阻碍了高质量 3D 内容的创建。

Method: 提出了一种结合了 triplane 表示和基于深度的反向投影损失的 Transformer 框架，可以直接从单个图像和网格预测 3D 纹理场。

Result: 该方法能够在 0.2 秒内为每个形状生成高质量纹理，并且在保真度和感知质量方面优于最先进的方法。

Conclusion: 该方法为可扩展、高质量和可控的 3D 内容创建提供了实用的解决方案。

Abstract: High-quality textures are critical for realistic 3D content creation, yet
existing generative methods are slow, rely on UV maps, and often fail to remain
faithful to a reference image. To address these challenges, we propose a
transformer-based framework that predicts a 3D texture field directly from a
single image and a mesh, eliminating the need for UV mapping and differentiable
rendering, and enabling faster texture generation. Our method integrates a
triplane representation with depth-based backprojection losses, enabling
efficient training and faster inference. Once trained, it generates
high-fidelity textures in a single forward pass, requiring only 0.2s per shape.
Extensive qualitative, quantitative, and user preference evaluations
demonstrate that our method outperforms state-of-the-art baselines on
single-image texture reconstruction in terms of both fidelity to the input
image and perceptual quality, highlighting its practicality for scalable,
high-quality, and controllable 3D content creation.

</details>


### [48] [SGS-3D: High-Fidelity 3D Instance Segmentation via Reliable Semantic Mask Splitting and Growing](https://arxiv.org/abs/2509.05144)
*Chaolei Wang,Yang Luo,Jing Du,Siyu Chen,Yiping Chen,Ting Han*

Main category: cs.CV

TL;DR: SGS-3D是一个新颖的“分割-然后生长”框架，通过几何原语净化和分割模糊的提升掩码，然后将其生长成场景中的完整实例，以实现高保真3D实例分割。


<details>
  <summary>Details</summary>
Motivation: 基于2D到3D提升的方法在3D实例分割中存在精度问题，因为从模糊的语义引导和不足的深度约束中累积的误差会影响分割质量。

Method: SGS-3D框架首先使用几何原语净化和分割模糊的提升掩码，然后将它们生长成完整的实例。该方法结合了语义和几何信息，并通过掩码过滤策略来识别和移除模糊掩码，同时利用空间连续性和高级特征来细化几何形状。

Result: 在ScanNet200、ScanNet++和KITTI-360数据集上，SGS-3D显著提高了分割精度和鲁棒性，能够生成高保真度的物体实例，并保持了良好的泛化能力。

Conclusion: SGS-3D通过结合语义和几何信息，有效地解决了现有2D到3D提升方法在3D实例分割中的精度问题，提供了一种无需训练的、高精度的3D实例分割解决方案。

Abstract: Accurate 3D instance segmentation is crucial for high-quality scene
understanding in the 3D vision domain. However, 3D instance segmentation based
on 2D-to-3D lifting approaches struggle to produce precise instance-level
segmentation, due to accumulated errors introduced during the lifting process
from ambiguous semantic guidance and insufficient depth constraints. To tackle
these challenges, we propose splitting and growing reliable semantic mask for
high-fidelity 3D instance segmentation (SGS-3D), a novel "split-then-grow"
framework that first purifies and splits ambiguous lifted masks using geometric
primitives, and then grows them into complete instances within the scene.
Unlike existing approaches that directly rely on raw lifted masks and sacrifice
segmentation accuracy, SGS-3D serves as a training-free refinement method that
jointly fuses semantic and geometric information, enabling effective
cooperation between the two levels of representation. Specifically, for
semantic guidance, we introduce a mask filtering strategy that leverages the
co-occurrence of 3D geometry primitives to identify and remove ambiguous masks,
thereby ensuring more reliable semantic consistency with the 3D object
instances. For the geometric refinement, we construct fine-grained object
instances by exploiting both spatial continuity and high-level features,
particularly in the case of semantic ambiguity between distinct objects.
Experimental results on ScanNet200, ScanNet++, and KITTI-360 demonstrate that
SGS-3D substantially improves segmentation accuracy and robustness against
inaccurate masks from pre-trained models, yielding high-fidelity object
instances while maintaining strong generalization across diverse indoor and
outdoor environments. Code is available in the supplementary materials.

</details>


### [49] [SL-SLR: Self-Supervised Representation Learning for Sign Language Recognition](https://arxiv.org/abs/2509.05188)
*Ariel Basso Madjoukeng,Jérôme Fink,Pierre Poitier,Edith Belise Kenmogne,Benoit Frenay*

Main category: cs.CV

TL;DR: 该论文提出了一种新的自监督学习框架，用于解决手语识别（SLR）中由于数据稀疏性而导致的对比学习方法在处理视频时无法区分不同手语的相似动作以及无法区分视频中不同部分的关联性问题。该框架包含一种新的自由负例对自监督方法和一种新的数据增强技术，并在线性评估、半监督学习和跨语言迁移等任务中取得了显著的准确性提升。


<details>
  <summary>Details</summary>
Motivation: 现有的对比学习方法在处理手语识别（SLR）任务时存在两个主要问题：1. 它们平等地对待视频的所有部分，忽略了某些部分对手语识别的实际重要性；2. 不同手语之间共享的动作导致负样本对高度相似，难以区分。这最终导致学习到的特征缺乏区分性，影响了下游任务的性能。

Method: 提出了一种新的自监督学习框架，该框架包含两个关键组件：1. 一种新颖的、具有自由负例对的自监督方法；2. 一种新颖的数据增强技术。

Result: 与现有的多种对比学习和自监督学习方法相比，该框架在准确性方面表现出显著的提升，该提升在 А) 线性评估、B) 半监督学习和 C) 跨语言迁移等任务中均得到验证。

Conclusion: 该论文提出的自监督学习框架通过引入自由负例对方法和新的数据增强技术，有效解决了现有对比学习方法在手语识别中遇到的挑战，提高了模型学习到的表征的区分性，并在多项评估任务中取得了优于现有方法的性能。

Abstract: Sign language recognition (SLR) is a machine learning task aiming to identify
signs in videos. Due to the scarcity of annotated data, unsupervised methods
like contrastive learning have become promising in this field. They learn
meaningful representations by pulling positive pairs (two augmented versions of
the same instance) closer and pushing negative pairs (different from the
positive pairs) apart. In SLR, in a sign video, only certain parts provide
information that is truly useful for its recognition. Applying contrastive
methods to SLR raises two issues: (i) contrastive learning methods treat all
parts of a video in the same way, without taking into account the relevance of
certain parts over others; (ii) shared movements between different signs make
negative pairs highly similar, complicating sign discrimination. These issues
lead to learning non-discriminative features for sign recognition and poor
results in downstream tasks. In response, this paper proposes a self-supervised
learning framework designed to learn meaningful representations for SLR. This
framework consists of two key components designed to work together: (i) a new
self-supervised approach with free-negative pairs; (ii) a new data augmentation
technique. This approach shows a considerable gain in accuracy compared to
several contrastive and self-supervised methods, across linear evaluation,
semi-supervised learning, and transferability between sign languages.

</details>


### [50] [Symbolic Graphics Programming with Large Language Models](https://arxiv.org/abs/2509.05208)
*Yamei Chen,Haoquan Zhang,Yangyi Huang,Zeju Qiu,Kaipeng Zhang,Yandong Wen,Weiyang Liu*

Main category: cs.CV

TL;DR: LLMs 在生成符号图形程序（SGPs）方面有待提高，本文提出了一个包含可验证奖励的强化学习方法，以提高 SVG 生成的质量和语义，并在 SGP-GenBench 基准测试中取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 现有 LLMs 在生成符号图形程序（SGPs）方面能力不足，本文旨在通过引入新的基准和改进方法来提升 LLMs 的 SGP 生成能力，并以此作为理解 LLMs 视觉理解能力的一种方式。

Method: 引入 SGP-GenBench 基准测试，用于评估 LLMs 在对象保真度、场景保真度和组合性方面的 SGP 生成能力。提出一种包含可验证奖励的强化学习（RL）方法，通过格式有效性门控确保 SVG 可渲染，并使用跨模态奖励（如 SigLIP 和 DINO）来对齐文本和渲染图像。

Result: 在 SGP-GenBench 基准测试中，本文发现前沿专有模型在 SGP 生成方面显著优于开源模型，且性能与通用编码能力相关。所提出的 RL 方法在 Qwen-2.5-7B 模型上显著提高了 SVG 生成质量和语义，达到了与前沿系统相当的性能。分析表明，RL 能够促进（i）将对象分解为更精细的可控原语，以及（ii）提高场景连贯性的上下文细节。

Conclusion: 符号图形编程提供了一种精确且可解释的跨模态基础视角，并且通过引入 SGP-GenBench 基准和 RL 方法，可以显著提升 LLMs 在 SGP 生成方面的能力。

Abstract: Large language models (LLMs) excel at program synthesis, yet their ability to
produce symbolic graphics programs (SGPs) that render into precise visual
content remains underexplored. We study symbolic graphics programming, where
the goal is to generate an SGP from a natural-language description. This task
also serves as a lens into how LLMs understand the visual world by prompting
them to generate images rendered from SGPs. Among various SGPs, our paper
sticks to scalable vector graphics (SVGs). We begin by examining the extent to
which LLMs can generate SGPs. To this end, we introduce SGP-GenBench, a
comprehensive benchmark covering object fidelity, scene fidelity, and
compositionality (attribute binding, spatial relations, numeracy). On
SGP-GenBench, we discover that frontier proprietary models substantially
outperform open-source models, and performance correlates well with general
coding capabilities. Motivated by this gap, we aim to improve LLMs' ability to
generate SGPs. We propose a reinforcement learning (RL) with verifiable rewards
approach, where a format-validity gate ensures renderable SVG, and a
cross-modal reward aligns text and the rendered image via strong vision
encoders (e.g., SigLIP for text-image and DINO for image-image). Applied to
Qwen-2.5-7B, our method substantially improves SVG generation quality and
semantics, achieving performance on par with frontier systems. We further
analyze training dynamics, showing that RL induces (i) finer decomposition of
objects into controllable primitives and (ii) contextual details that improve
scene coherence. Our results demonstrate that symbolic graphics programming
offers a precise and interpretable lens on cross-modal grounding.

</details>


### [51] [COGITAO: A Visual Reasoning Framework To Study Compositionality & Generalization](https://arxiv.org/abs/2509.05249)
*Yassine Taoudi-Benchekroun,Klim Troyan,Pascal Sager,Stefan Gerber,Lukas Tuggener,Benjamin Grewe*

Main category: cs.CV

TL;DR: COGITAO是一个用于研究视觉领域组合性和泛化性的数据生成框架和基准测试，通过组合28种可互操作的变换来创建大量规则和任务，并已显示现有模型在处理新颖组合方面存在局限性。


<details>
  <summary>Details</summary>
Motivation: 为了解决当前机器学习模型在组合学习概念和泛化到新环境方面的局限性。

Method: COGITAO构建了基于规则的任务，将一组变换应用于网格环境中的对象，支持可调深度的组合，并允许广泛控制参数和对象属性，从而生成数百万个独特的任务规则。

Result: 在COGITAO上进行的基线实验表明，尽管最先进的视觉模型在特定领域表现良好，但在泛化到熟悉元素的新颖组合方面存在持续的失败。

Conclusion: COGITAO提供了一个灵活且可扩展的框架，用于系统地研究组合性和泛化性，其开放的源代码和数据集旨在促进该领域的进一步研究，并已揭示了现有模型的不足。

Abstract: The ability to compose learned concepts and apply them in novel settings is
key to human intelligence, but remains a persistent limitation in
state-of-the-art machine learning models. To address this issue, we introduce
COGITAO, a modular and extensible data generation framework and benchmark
designed to systematically study compositionality and generalization in visual
domains. Drawing inspiration from ARC-AGI's problem-setting, COGITAO constructs
rule-based tasks which apply a set of transformations to objects in grid-like
environments. It supports composition, at adjustable depth, over a set of 28
interoperable transformations, along with extensive control over grid
parametrization and object properties. This flexibility enables the creation of
millions of unique task rules -- surpassing concurrent datasets by several
orders of magnitude -- across a wide range of difficulties, while allowing
virtually unlimited sample generation per rule. We provide baseline experiments
using state-of-the-art vision models, highlighting their consistent failures to
generalize to novel combinations of familiar elements, despite strong in-domain
performance. COGITAO is fully open-sourced, including all code and datasets, to
support continued research in this field.

</details>


### [52] [WinT3R: Window-Based Streaming Reconstruction with Camera Token Pool](https://arxiv.org/abs/2509.05296)
*Zizun Li,Jianjun Zhou,Yifan Wang,Haoyu Guo,Wenzheng Chang,Yang Zhou,Haoyi Zhu,Junyi Chen,Chunhua Shen,Tong He*

Main category: cs.CV

TL;DR: WinT3R是一个前馈重建模型，可以进行在线精确相机姿态和高质量点图的预测。它通过引入滑动窗口机制和全局相机令牌池来解决现有方法在重建质量和实时性能之间的权衡问题，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在重建质量和实时性能之间存在权衡，本文旨在解决此问题。

Method: 提出了一种名为WinT3R的前馈重建模型，该模型采用滑动窗口机制以促进帧间信息交换，并利用紧凑的相机表示和全局相机令牌池来提高相机姿态估计的可靠性。

Result: WinT3R在在线重建质量、相机姿态估计和重建速度方面均达到了最先进的性能，并在多个数据集上得到了验证。

Conclusion: WinT3R通过其创新的设计，成功地在不牺牲效率的情况下提高了几何预测的质量，实现了优于现有方法的性能。

Abstract: We present WinT3R, a feed-forward reconstruction model capable of online
prediction of precise camera poses and high-quality point maps. Previous
methods suffer from a trade-off between reconstruction quality and real-time
performance. To address this, we first introduce a sliding window mechanism
that ensures sufficient information exchange among frames within the window,
thereby improving the quality of geometric predictions without large
computation. In addition, we leverage a compact representation of cameras and
maintain a global camera token pool, which enhances the reliability of camera
pose estimation without sacrificing efficiency. These designs enable WinT3R to
achieve state-of-the-art performance in terms of online reconstruction quality,
camera pose estimation, and reconstruction speed, as validated by extensive
experiments on diverse datasets. Code and model are publicly available at
https://github.com/LiZizun/WinT3R.

</details>


### [53] [FlowSeek: Optical Flow Made Easier with Depth Foundation Models and Motion Bases](https://arxiv.org/abs/2509.05297)
*Matteo Poggi,Fabio Tosi*

Main category: cs.CV

TL;DR: FlowSeek是一个新颖的光流框架，在训练时只需最少的硬件资源，并结合了最新的光流网络设计、单图像深度基础模型和经典低维运动参数化，实现了一个紧凑而精确的架构。


<details>
  <summary>Details</summary>
Motivation: 介绍了一种新颖的光流框架FlowSeek，该框架在训练时需要最少的硬件资源。

Method: FlowSeek结合了最新的光流网络设计、单图像深度基础模型和经典的低维运动参数化，实现了一个紧凑而精确的架构。FlowSeek在一个单消费级GPU上进行训练，硬件预算比大多数最新方法低约8倍。

Result: FlowSeek在Sintel Final和KITTI数据集上实现了优于先前最先进的SEA-RAFT方法10%和15%的相对改进，并且在Spring和LayeredFlow数据集上也取得了优异的泛化能力。

Conclusion: FlowSeek是一个在训练时只需最少硬件资源的光流框架，它通过结合最新的光流网络设计、单图像深度基础模型和经典的低维运动参数化，实现了一个紧凑而精确的架构，并在多个数据集上取得了优于先前最先进方法的性能。

Abstract: We present FlowSeek, a novel framework for optical flow requiring minimal
hardware resources for training. FlowSeek marries the latest advances on the
design space of optical flow networks with cutting-edge single-image depth
foundation models and classical low-dimensional motion parametrization,
implementing a compact, yet accurate architecture. FlowSeek is trained on a
single consumer-grade GPU, a hardware budget about 8x lower compared to most
recent methods, and still achieves superior cross-dataset generalization on
Sintel Final and KITTI, with a relative improvement of 10 and 15% over the
previous state-of-the-art SEA-RAFT, as well as on Spring and LayeredFlow
datasets.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [54] [INSEva: A Comprehensive Chinese Benchmark for Large Language Models in Insurance](https://arxiv.org/abs/2509.04455)
*Shisong Chen,Qian Zhu,Wenyan Yang,Chengyi Yang,Zhong Wang,Ping Wang,Xuan Lin,Bo Xu,Daqian Li,Chao Yuan,Licai Qi,Wanqing Xu,sun zhenxing,Xin Lu,Shiqiang Xiong,Chao Chen,Haixiang Hu,Yanghua Xiao*

Main category: cs.CL

TL;DR: INSEva是一个针对保险领域的中文AI评估基准，包含38,704个评估示例，评估LLM在保险知识和能力方面的表现。


<details>
  <summary>Details</summary>
Motivation: 现有基准未能捕捉保险领域的独特性，需要一个专门的评估体系。

Method: 创建了一个多维度评估分类法（业务领域、任务格式、难度级别、认知知识维度），包含38,704个高质量示例，并设计了针对开放式回答的忠实度和完整性评估方法。

Result: 评估了8个最先进的大型语言模型（LLM），发现它们在不同维度上表现存在显著差异，平均得分高于80，但在处理复杂、现实的保险场景方面仍有差距。

Conclusion: INSEva基准能够有效评估LLM在保险领域的知识和能力，并指出了当前LLM在处理复杂保险场景时存在的不足。

Abstract: Insurance, as a critical component of the global financial system, demands
high standards of accuracy and reliability in AI applications. While existing
benchmarks evaluate AI capabilities across various domains, they often fail to
capture the unique characteristics and requirements of the insurance domain. To
address this gap, we present INSEva, a comprehensive Chinese benchmark
specifically designed for evaluating AI systems' knowledge and capabilities in
insurance. INSEva features a multi-dimensional evaluation taxonomy covering
business areas, task formats, difficulty levels, and cognitive-knowledge
dimension, comprising 38,704 high-quality evaluation examples sourced from
authoritative materials. Our benchmark implements tailored evaluation methods
for assessing both faithfulness and completeness in open-ended responses.
Through extensive evaluation of 8 state-of-the-art Large Language Models
(LLMs), we identify significant performance variations across different
dimensions. While general LLMs demonstrate basic insurance domain competency
with average scores above 80, substantial gaps remain in handling complex,
real-world insurance scenarios. The benchmark will be public soon.

</details>


### [55] [Mentalic Net: Development of RAG-based Conversational AI and Evaluation Framework for Mental Health Support](https://arxiv.org/abs/2509.04456)
*Anandi Dutta,Shivani Mruthyunjaya,Jessica Saddington,Kazi Sifatul Islam*

Main category: cs.CL

TL;DR: LLMs带来机遇和挑战，我们开发了一个注重安全和有意义应用的心理健康支持聊天机器人。


<details>
  <summary>Details</summary>
Motivation: LLMs的出现带来了机遇和挑战，需要开发负责任的AI解决方案。

Method: 我们采用了检索增强生成（RAG）框架，结合了提示工程和在新数据集上的模型微调，并进行了全面的评估。

Result: 开发的聊天机器人Mentalic Net Conversational AI在BERT分数上达到了0.898，其他评估指标也令人满意。

Conclusion: 我们主张采用“人在环路”的方法和长期的、负责任的策略来开发变革性技术，以应对LLMs带来的机遇和挑战。

Abstract: The emergence of large language models (LLMs) has unlocked boundless
possibilities, along with significant challenges. In response, we developed a
mental health support chatbot designed to augment professional healthcare, with
a strong emphasis on safe and meaningful application. Our approach involved
rigorous evaluation, covering accuracy, empathy, trustworthiness, privacy, and
bias. We employed a retrieval-augmented generation (RAG) framework, integrated
prompt engineering, and fine-tuned a pre-trained model on novel datasets. The
resulting system, Mentalic Net Conversational AI, achieved a BERT Score of
0.898, with other evaluation metrics falling within satisfactory ranges. We
advocate for a human-in-the-loop approach and a long-term, responsible strategy
in developing such transformative technologies, recognizing both their
potential to change lives and the risks they may pose if not carefully managed.

</details>


### [56] [Do MLLMs Really Understand the Charts?](https://arxiv.org/abs/2509.04457)
*Xiao Zhang,Dongyuan Li,Liuyu Xiang,Yao Zhang,Cheng Zhong,Zhaofeng He*

Main category: cs.CL

TL;DR: MLLMs在处理非标注图表时存在幻觉和性能下降问题。本文提出了CRBench基准来评估MLLMs的视觉推理能力，并引入ChartReasoner模型，通过模仿人类的视觉推理方式来提高MLLMs对图表的理解能力。实验证明ChartReasoner在CRBench及公开基准上均表现优异，能够有效提升MLLMs的图表理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在处理非标注图表时存在严重的幻觉和性能下降问题，引发了对其是否真正理解图表的质疑。需要评估和提升MLLMs在图表理解中的视觉推理能力。

Method: 1. 建立CRBench基准来严格评估MLLMs在非标注图表上的视觉推理能力。2. 提出ChartReasoner模型，模仿人类通过视觉推理来估计图表中数值的行为，以引导MLLMs进行合理的图表理解。3. 在CRBench和公开基准上进行广泛实验，验证ChartReasoner的有效性。

Result: ChartReasoner-3B/7B在CRBench上取得了优于GPT-4o和Gemini-2.5-Flash的性能。ChartReasoner在公开基准上也展示了通用的视觉推理能力，显著提升了MLLMs的图表理解能力，使其能够进行合理的图表理解。

Conclusion: MLLMs目前主要依赖识别而非推理来理解图表。本文提出的CRBench基准和ChartReasoner模型能够有效评估和提升MLLMs的视觉推理能力，使其能够更合理地理解图表，解决了现有模型在非标注图表上表现不佳的问题。

Abstract: Although Multimodal Large Language Models (MLLMs) have demonstrated
increasingly impressive performance in chart understanding, most of them
exhibit alarming hallucinations and significant performance degradation when
handling non-annotated charts. Therefore, a question arises: Do MLLMs really
understand the charts? Since a human is capable of understanding charts and
estimating the values by visual reasoning, we first carefully establish a
comprehensive Chart Reasoning Benchmark CRBench to rigorously evaluate the
visual reasoning abilities of MLLMs on non-annotated charts. We argue that
MLLMs are primarily relying on recognition rather than reasoning to interpret
the charts. To steer MLLMs to reasonable chart understanding, we propose
ChartReasoner that mimics human behavior by grounding their estimation in chart
understanding. Extensive results on the proposed CRBench show that
ChartReasnoner-3B/7B achieves superior performance in chart reasoning, even
compared to GPT-4o and Gemini-2.5-Flash. More importantly, ChartReasnoner also
demonstrates the visual reasoning abilities in general chart comprehension on
public benchmarks, leading to significant performance gains and enabling MLLMs
to rationally understand the charts. The code and dataset will be publicly
available upon publication.

</details>


### [57] [Predicting Failures of LLMs to Link Biomedical Ontology Terms to Identifiers Evidence Across Models and Ontologies](https://arxiv.org/abs/2509.04458)
*Daniel B. Hier,Steven Keith Platt,Tayo Obafemi-Ajayi*

Main category: cs.CL

TL;DR: 大型语言模型在生物医学自然语言处理任务中表现优异，但在本体术语与其正确标识符的链接方面可能存在不足。本研究通过分析在人类表型本体（HPO）和基因本体（GO）两个主要本体以及GPT-4o和LLaMa 3.1 405B两个高性能模型上的预测，探究这些链接失败的原因。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型在本体术语链接方面的能力，并找出导致失败的原因。

Method: 分析模型在HPO和GO本体上的预测表现，评估九个候选特征（包括术语熟悉度、标识符使用、形态和本体结构），并进行单变量和多变量分析。

Result: 研究发现，模型接触本体标识符的频率是成功链接术语的最强预测因子。

Conclusion: 本体标识符的充分暴露对于提高大型语言模型在生物医学自然语言处理任务中链接本体术语至关重要。

Abstract: Large language models often perform well on biomedical NLP tasks but may fail
to link ontology terms to their correct identifiers. We investigate why these
failures occur by analyzing predictions across two major ontologies, Human
Phenotype Ontology and Gene Ontology, and two high-performing models, GPT-4o
and LLaMa 3.1 405B. We evaluate nine candidate features related to term
familiarity, identifier usage, morphology, and ontology structure. Univariate
and multivariate analyses show that exposure to ontology identifiers is the
strongest predictor of linking success.

</details>


### [58] [From Post To Personality: Harnessing LLMs for MBTI Prediction in Social Media](https://arxiv.org/abs/2509.04461)
*Tian Ma,Kaiyu Feng,Yu Rong,Kangfei Zhao*

Main category: cs.CL

TL;DR: 该研究提出了一个名为PostToPersonality (PtoP) 的新框架，利用大型语言模型 (LLM) 从社交媒体帖子预测迈尔斯-布里格斯类型指标 (MBTI) 类型。PtoP 通过检索增强生成（RAG）和上下文学习来解决 LLM 的幻觉问题，并通过生成合成样本来解决 MBTI 类型不平衡的问题。实验结果表明，PtoP 在真实社交媒体数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 从社交媒体帖子预测迈尔斯-布里格斯类型指标 (MBTI) 类型具有重要的心理学和社会学应用价值。虽然机器学习 (ML) 和深度学习 (DL) 技术已被用于此任务，但大型语言模型 (LLM) 的潜力尚未被充分利用。然而，直接使用 LLM 面临幻觉和数据类别不平衡的挑战。

Method: 提出PostToPersonality (PtoP) 框架，利用检索增强生成（RAG）和上下文学习来减少 LLM 的幻觉。同时，通过生成合成样本来解决 MBTI 类型不平衡的问题，并对预训练的 LLM 进行微调以提高 MBTI 理解能力。

Result: 在真实社交媒体数据集上进行实验，证明 PtoP 框架在 MBTI 预测方面取得了最先进的性能，优于 10 种 ML 和 DL 基线方法。

Conclusion: PtoP 框架成功地利用 LLM 的能力来预测 MBTI 类型，并通过 RAG、上下文学习和合成数据生成等技术解决了幻觉和类别不平衡问题，在真实世界数据上取得了优异的性能。

Abstract: Personality prediction from social media posts is a critical task that
implies diverse applications in psychology and sociology. The Myers Briggs Type
Indicator (MBTI), a popular personality inventory, has been traditionally
predicted by machine learning (ML) and deep learning (DL) techniques. Recently,
the success of Large Language Models (LLMs) has revealed their huge potential
in understanding and inferring personality traits from social media content.
However, directly exploiting LLMs for MBTI prediction faces two key challenges:
the hallucination problem inherent in LLMs and the naturally imbalanced
distribution of MBTI types in the population. In this paper, we propose
PostToPersonality (PtoP), a novel LLM based framework for MBTI prediction from
social media posts of individuals. Specifically, PtoP leverages Retrieval
Augmented Generation with in context learning to mitigate hallucination in
LLMs. Furthermore, we fine tune a pretrained LLM to improve model specification
in MBTI understanding with synthetic minority oversampling, which balances the
class imbalance by generating synthetic samples. Experiments conducted on a
real world social media dataset demonstrate that PtoP achieves state of the art
performance compared with 10 ML and DL baselines.

</details>


### [59] [Uncertainty-Aware Collaborative System of Large and Small Models for Multimodal Sentiment Analysis](https://arxiv.org/abs/2509.04459)
*Shiqin Han,Manning Gao,Menghua Jiang,Yuncheng Jiang,Haifeng Hu,Sijie Mai*

Main category: cs.CL

TL;DR: 提出不确定性感知协作系统（U-ACS），通过结合大型多模态模型（MLLM）和轻量级模型来平衡性能和效率，用于多模态情感分析。


<details>
  <summary>Details</summary>
Motivation: 解决大型多模态模型（MLLM）计算成本高昂与小型模型性能不足之间的矛盾。

Method: 设计了一个不确定性驱动的级联机制，首先使用轻量级模型处理所有样本，并将高不确定性的样本交给MLLM进行分析，同时采用加权平均和基于提示的交叉验证来处理模糊或冲突的预测。

Result: 在基准数据集上的实验表明，该方法在保持高精度的同时，显著降低了计算资源需求，达到了最先进的性能。

Conclusion: U-ACS通过动态分配计算资源，有效解决了性能-效率的权衡问题，为多模态学习提供了更经济高效的解决方案。

Abstract: The advent of Multimodal Large Language Models (MLLMs) has significantly
advanced the state-of-the-art in multimodal machine learning, yet their
substantial computational demands present a critical barrier to real-world
deployment. Conversely, smaller, specialized models offer high efficiency but
often at the cost of performance. To reconcile this performance-efficiency
trade-off, we propose a novel Uncertainty-Aware Collaborative System (U-ACS)
that synergistically orchestrates a powerful MLLM (e.g., HumanOmni) and a
lightweight baseline model for multimodal sentiment analysis. The core of our
system is an uncertainty-driven cascade mechanism, where the efficient small
model first acts as a rapid filter for all input samples. Only those samples
yielding high predictive uncertainty, thereby indicating greater difficulty,
are selectively escalated to the MLLM for more sophisticated analysis.
Furthermore, our system introduces advanced strategies to handle ambiguous or
conflicting predictions, including weighted averaging for predictions of
similar polarity and a prompt-based cross-verification to resolve conflicting
predictions when both models exhibit high uncertainty. This
sample-difficulty-aware approach allows for a dynamic allocation of
computational resources, drastically reducing inference costs while retaining
the high accuracy of MLLM. Extensive experiments on benchmark datasets
demonstrate that our proposed method achieves state-of-the-art performance,
while requiring only a fraction of the computational resources compared to
using a standalone MLLM.

</details>


### [60] [CoCoNUTS: Concentrating on Content while Neglecting Uninformative Textual Styles for AI-Generated Peer Review Detection](https://arxiv.org/abs/2509.04460)
*Yihan Chen,Jiawei Chen,Guozhao Mo,Xuanang Chen,Ben He,Xianpei Han,Le Sun*

Main category: cs.CL

TL;DR: LLMs可能威胁学术评审的公平性和可靠性。现有的AI文本检测器易受攻击且难以区分语言润色和实质内容生成。本文提出CoCoNUTS基准和CoCoDet检测器，从基于风格转向基于内容，以更准确地检测AI在同行评审中的应用。


<details>
  <summary>Details</summary>
Motivation: 现有AI文本检测器在应用于同行评审时存在局限性，可能导致误判，因此需要更准确、更鲁棒的检测方法。

Method: 提出CoCoNUTS基准和CoCoDet检测器，采用基于内容的检测方法，并通过多任务学习框架进行优化。

Result: 开发了CoCoNUTS基准和CoCoDet检测器，能够更准确、更鲁棒地检测AI在同行评审内容中的应用。

Conclusion: 本文为评估LLM在同行评审中的应用提供了实用的基础，并有助于开发更精确、公平和可靠的检测方法。

Abstract: The growing integration of large language models (LLMs) into the peer review
process presents potential risks to the fairness and reliability of scholarly
evaluation. While LLMs offer valuable assistance for reviewers with language
refinement, there is growing concern over their use to generate substantive
review content. Existing general AI-generated text detectors are vulnerable to
paraphrasing attacks and struggle to distinguish between surface language
refinement and substantial content generation, suggesting that they primarily
rely on stylistic cues. When applied to peer review, this limitation can result
in unfairly suspecting reviews with permissible AI-assisted language
enhancement, while failing to catch deceptively humanized AI-generated reviews.
To address this, we propose a paradigm shift from style-based to content-based
detection. Specifically, we introduce CoCoNUTS, a content-oriented benchmark
built upon a fine-grained dataset of AI-generated peer reviews, covering six
distinct modes of human-AI collaboration. Furthermore, we develop CoCoDet, an
AI review detector via a multi-task learning framework, designed to achieve
more accurate and robust detection of AI involvement in review content. Our
work offers a practical foundation for evaluating the use of LLMs in peer
review, and contributes to the development of more precise, equitable, and
reliable detection methods for real-world scholarly applications. Our code and
data will be publicly available at https://github.com/Y1hanChen/COCONUTS.

</details>


### [61] [Benchmarking GPT-5 for biomedical natural language processing](https://arxiv.org/abs/2509.04462)
*Yu Hou,Zaifu Zhan,Rui Zhang*

Main category: cs.CL

TL;DR: GPT-5 在生物医学 NLP 任务上表现优于 GPT-4 和 GPT-4o，尤其在问答任务上，但在摘要和疾病 NER 方面仍落后于特定领域模型。


<details>
  <summary>Details</summary>
Motivation: 生物医学文献的快速增长需要可扩展的 NLP 解决方案，现有模型（如 GPT-4）在某些任务上的表现尚不均衡。

Method: 更新了标准的 BioNLP 基准，评估了 GPT-5、GPT-4o、GPT-4、GPT-3.5 和 LLaMA-2-13B 在零样本、单样本和五样本条件下的 12 个数据集（涵盖命名实体识别、关系抽取、多标签文档分类、问答、文本摘要和文本简化）。

Result: GPT-5 在五样本条件下取得了最高的综合基准性能（0.557），优于 GPT-4（0.506）和 GPT-4o（0.508）。GPT-5 在 MedQA 上达到 94.1% 的准确率，在 ChemProt 关系抽取上达到 0.616 F1 分数，但在摘要和疾病 NER 方面表现不如特定领域模型。

Conclusion: GPT-5 在推理导向的生物医学 QA 方面已达到可部署的性能，但需要精度的抽取和证据密集的摘要任务仍倾向于使用微调或混合方法。该基准研究为生物医学 NLP 系统设计提供了指导。

Abstract: The rapid expansion of biomedical literature has heightened the need for
scalable natural language processing (NLP) solutions. While GPT-4 substantially
narrowed the gap with task-specific systems, especially in question answering,
its performance across other domains remained uneven. We updated a standardized
BioNLP benchmark to evaluate GPT-5 and GPT-4o under zero-, one-, and five-shot
prompting across 12 datasets spanning six task families: named entity
recognition, relation extraction, multi-label document classification, question
answering, text summarization, and text simplification. Using fixed prompt
templates, identical decoding parameters, and batch inference, we report
primary metrics per dataset and include prior results for GPT-4, GPT-3.5, and
LLaMA-2-13B for comparison. GPT-5 achieved the strongest overall benchmark
performance, with macro-average scores rising to 0.557 under five-shot
prompting versus 0.506 for GPT-4 and 0.508 for GPT-4o. On MedQA, GPT-5 reached
94.1% accuracy, exceeding the previous supervised state of the art by over
fifty points, and attained parity with supervised systems on PubMedQA (0.734).
In extraction tasks, GPT-5 delivered major gains in chemical NER (0.886 F1) and
ChemProt relation extraction (0.616 F1), outperforming GPT-4 and GPT-4o, though
summarization and disease NER still lagged behind domain-specific baselines.
These results establish GPT-5 as a general-purpose model now offering
deployment-ready performance for reasoning-oriented biomedical QA, while
precision-critical extraction and evidence-dense summarization continue to
favor fine-tuned or hybrid approaches. The benchmark delineates where simple
prompting suffices and where retrieval-augmented or planning-based scaffolds
are likely required, providing actionable guidance for BioNLP system design as
frontier models advance.

</details>


### [62] [Can Multiple Responses from an LLM Reveal the Sources of Its Uncertainty?](https://arxiv.org/abs/2509.04464)
*Yang Nan,Pengfei He,Ravi Tandon,Han Xu*

Main category: cs.CL

TL;DR: LLM 的不确定性来源可以通过分析多个生成响应之间的分歧模式来诊断，这有助于提高 LLM 的性能和可靠性。


<details>
  <summary>Details</summary>
Motivation: 虽然量化 LLM 的不确定性已有大量研究，但对其不确定性来源的诊断却鲜有关注。

Method: 收集目标 LLM 的多个响应，并使用辅助 LLM 分析它们之间的分歧模式，以推断不确定性的可能来源（例如，输入问题的歧义、相关知识的缺乏或两者兼而有之）。在存在知识差距的情况下，辅助模型还会识别导致不确定性的具体缺失事实或概念。

Result: 在 AmbigQA、OpenBookQA 和 MMLU-Pro 数据集上验证了该框架，证明了其诊断不同不确定性来源的通用性。

Conclusion: 通过诊断不确定性的来源，可以进行有针对性的手动干预，从而提高 LLM 的性能和可靠性。

Abstract: Large language models (LLMs) have delivered significant breakthroughs across
diverse domains but can still produce unreliable or misleading outputs, posing
critical challenges for real-world applications. While many recent studies
focus on quantifying model uncertainty, relatively little work has been devoted
to \textit{diagnosing the source of uncertainty}. In this study, we show that,
when an LLM is uncertain, the patterns of disagreement among its multiple
generated responses contain rich clues about the underlying cause of
uncertainty. To illustrate this point, we collect multiple responses from a
target LLM and employ an auxiliary LLM to analyze their patterns of
disagreement. The auxiliary model is tasked to reason about the likely source
of uncertainty, such as whether it stems from ambiguity in the input question,
a lack of relevant knowledge, or both. In cases involving knowledge gaps, the
auxiliary model also identifies the specific missing facts or concepts
contributing to the uncertainty. In our experiment, we validate our framework
on AmbigQA, OpenBookQA, and MMLU-Pro, confirming its generality in diagnosing
distinct uncertainty sources. Such diagnosis shows the potential for relevant
manual interventions that improve LLM performance and reliability.

</details>


### [63] [Emotionally-Aware Agents for Dispute Resolution](https://arxiv.org/abs/2509.04465)
*Sushrita Rakshit,James Hale,Kushal Chawla,Jeanne M. Brett,Jonathan Gratch*

Main category: cs.CL

TL;DR: 该研究探讨了在争端解决背景下，文本情感识别如何揭示冲突中的情感表达对结果的影响。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索自动文本情感识别是否能为理解争端解决中的情感表达影响提供见解，并弥补现有研究在处理更强烈情感和不同社会过程方面的不足。

Method: 研究使用了一个包含大量买卖双方争端对话的数据集，并利用大型语言模型来分析情感表达对主观和客观结果的影响，同时与人类标注者进行比较。

Result: 研究发现，大型语言模型在情感强度标注方面比以往的方法具有更强的解释力，并且与人类标注者的判断更一致。情感表达有助于冲突升级和解决。

Conclusion: 研究结果支持关于情感表达如何促进冲突升级和解决的现有理论模型，并提出基于智能体（agent-based）的系统可以通过识别和缓解情感升级来协助管理争端。

Abstract: In conflict, people use emotional expressions to shape their counterparts'
thoughts, feelings, and actions. This paper explores whether automatic text
emotion recognition offers insight into this influence in the context of
dispute resolution. Prior work has shown the promise of such methods in
negotiations; however, disputes evoke stronger emotions and different social
processes. We use a large corpus of buyer-seller dispute dialogues to
investigate how emotional expressions shape subjective and objective outcomes.
We further demonstrate that large-language models yield considerably greater
explanatory power than previous methods for emotion intensity annotation and
better match the decisions of human annotators. Findings support existing
theoretical models for how emotional expressions contribute to conflict
escalation and resolution and suggest that agent-based systems could be useful
in managing disputes by recognizing and potentially mitigating emotional
escalation.

</details>


### [64] [Just-in-time and distributed task representations in language models](https://arxiv.org/abs/2509.04466)
*Yuxuan Li,Declan Campbell,Stephanie C. Y. Chan,Andrew Kyle Lampinen*

Main category: cs.CL

TL;DR: 语言模型通过上下文学习（in-context learning）来执行新任务，而无需更新权重。本研究探讨了这些新任务表征的形成时间和在上下文中的演变方式。研究发现，可迁移的任务表征（transferrable task representations）的形成是非单调和零星的，并且与更稳定的高级任务类别表征不同。这些可迁移表征会整合来自多个证据的信息，并与模型性能的提升相关。然而，这种整合过程具有很强的局部性，仅在特定 token 处出现，而任务本身在整个上下文中都可被解码。此外，这些局部但可迁移的表征倾向于捕捉有限的“任务范围”（task scopes），例如独立子任务，而模型则依赖于更广泛的时间分布的表征来支持更长或复合的任务。这种双重局部性（时间上和语义上）揭示了语言模型在即时计算（just-in-time computation）过程中，能够适应新证据并即时学习新任务的能力。


<details>
  <summary>Details</summary>
Motivation: 研究语言模型在上下文学习过程中，新任务表征的形成时间和演变机制，以及这些表征如何支持模型执行新任务。

Method: 通过分析可迁移的任务表征（transferrable task representations）的形成过程，研究其与模型性能的关系，并探讨其在时间维度和语义维度上的局部性特征。

Result: 发现可迁移的任务表征的形成是非单调和零星的，并且与更稳定的高级任务类别表征不同。这些表征会整合来自多个证据的信息，并与模型性能的提升相关。这种整合过程具有很强的局部性，仅在特定 token 处出现。此外，这些局部但可迁移的表征倾向于捕捉有限的任务范围，而模型则依赖于更广泛的时间分布的表征来支持更长或复合的任务。

Conclusion: 语言模型在适应新证据和学习新任务时，展现出一种“即时计算”的过程，这种过程具有时间上和语义上的双重局部性。

Abstract: Many of language models' impressive capabilities originate from their
in-context learning: based on instructions or examples, they can infer and
perform new tasks without weight updates. In this work, we investigate
\emph{when} representations for new tasks are formed in language models, and
\emph{how} these representations change over the course of context. We focus on
''transferrable'' task representations -- vector representations that can
restore task context in another instance of the model, even without the full
prompt. We show that these representations evolve in non-monotonic and sporadic
ways, and are distinct from a more inert representation of high-level task
categories that persists throughout the context. Specifically, models often
condense multiple evidence into these transferrable task representations, which
align well with the performance improvement based on more examples in the
context. However, this accrual process exhibits strong locality along the
sequence dimension, coming online only at certain tokens -- despite task
identity being reliably decodable throughout the context. Moreover, these local
but transferrable task representations tend to capture minimal ''task scopes'',
such as a semantically-independent subtask, and models rely on more
temporally-distributed representations to support longer and composite tasks.
This two-fold locality (temporal and semantic) underscores a kind of
just-in-time computational process underlying language models' ability to adapt
to new evidence and learn new tasks on the fly.

</details>


### [65] [Enhancing LLM Efficiency: Targeted Pruning for Prefill-Decode Disaggregation in Inference](https://arxiv.org/abs/2509.04467)
*Hao Zhang,Mengsi Lyu,Yulong Ao,Yonghua Lin*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large Language Models (LLMs) demonstrate exceptional capabilities across
various tasks, but their deployment is constrained by high computational and
memory costs. Model pruning provides an effective means to alleviate these
demands. However, existing methods often ignore the characteristics of
prefill-decode (PD) disaggregation in practice. In this paper, we propose a
novel pruning method for PD disaggregation inference, enabling more precise and
efficient block and KV Cache pruning. Our approach constructs pruning and
distillation sets to perform iterative block removal independently for the
prefill and decode stages, obtaining better pruning solutions. Moreover, we
introduce a token-aware cache pruning mechanism that retains all KV Cache in
the prefill stage but selectively reuses entries for the first and last token
sequences in selected layers during decode, reducing communication costs with
minimal overhead. Extensive experiments demonstrate that our approach
consistently achieves strong performance in both PD disaggregation and PD
unified settings without disaggregation. Under the default settings, our method
achieves a 20.56% inference speedup and a 4.95 times reduction in data
transmission bandwidth consumption.

</details>


### [66] [Evaluating Large Language Models for Financial Reasoning: A CFA-Based Benchmark Study](https://arxiv.org/abs/2509.04468)
*Xuan Yao,Qianteng Wang,Xinbo Liu,Ke-Wei Huang*

Main category: cs.CL

TL;DR: 该研究首次全面评估了最先进的大型语言模型在金融领域的表现，重点关注CFA（特许金融分析师）考试题目。


<details>
  <summary>Details</summary>
Motivation: 虽然大型语言模型在金融领域具有巨大潜力，但缺乏系统性的评估，本研究旨在弥补这一空白，为金融应用提供模型选择和优化的指导。

Method: 研究使用1,560道CFA（包括Level I-III）的客观题，评估了多模态、计算强大、推理专业和效率优化等不同类型的大型语言模型。评估方法包括零样本提示和一种新颖的检索增强生成（RAG）流水线，该流水线集成了CFA的官方课程内容，并通过分层知识组织和结构化查询生成来实现领域特定的知识检索。

Result: 研究结果表明，在零样本设置下，面向推理的模型表现优于其他模型。而RAG流水线，特别是对于复杂场景，显著提高了模型性能。通过错误分析发现，知识差距是模型失败的主要原因。

Conclusion: 这项研究为在金融领域部署大型语言模型提供了可操作的见解，为从业者在模型选择和成本效益优化方面提供了基于证据的指导。

Abstract: The rapid advancement of large language models presents significant
opportunities for financial applications, yet systematic evaluation in
specialized financial contexts remains limited. This study presents the first
comprehensive evaluation of state-of-the-art LLMs using 1,560 multiple-choice
questions from official mock exams across Levels I-III of CFA, most rigorous
professional certifications globally that mirror real-world financial analysis
complexity. We compare models distinguished by core design priorities:
multi-modal and computationally powerful, reasoning-specialized and highly
accurate, and lightweight efficiency-optimized.
  We assess models under zero-shot prompting and through a novel
Retrieval-Augmented Generation pipeline that integrates official CFA curriculum
content. The RAG system achieves precise domain-specific knowledge retrieval
through hierarchical knowledge organization and structured query generation,
significantly enhancing reasoning accuracy in professional financial
certification evaluation.
  Results reveal that reasoning-oriented models consistently outperform others
in zero-shot settings, while the RAG pipeline provides substantial improvements
particularly for complex scenarios. Comprehensive error analysis identifies
knowledge gaps as the primary failure mode, with minimal impact from text
readability. These findings provide actionable insights for LLM deployment in
finance, offering practitioners evidence-based guidance for model selection and
cost-performance optimization.

</details>


### [67] [Multi-Modal Vision vs. Text-Based Parsing: Benchmarking LLM Strategies for Invoice Processing](https://arxiv.org/abs/2509.04469)
*David Berghaus,Armin Berger,Lars Hillebrand,Kostadin Cvejoski,Rafet Sifa*

Main category: cs.CL

TL;DR: 该论文对GPT-5、Gemini 2.5和Gemma 3三个系列中的八个多模态大语言模型进行了基准测试，使用了三个多样化的、公开可用的发票文档数据集，并采用了零样本提示的方法。


<details>
  <summary>Details</summary>
Motivation: 评估不同多模态大语言模型在处理发票文档任务上的性能，并比较直接图像处理与先将文档转换为Markdown再进行解析这两种策略的优劣。

Method: 对八个多模态大语言模型（来自GPT-5、Gemini 2.5和Gemma 3系列）在三个发票文档数据集上进行零样本提示基准测试，并对比了两种处理策略：直接图像处理和先转换为Markdown再结构化解析。

Result: 直接图像处理策略通常优于结构化解析方法，但具体性能在不同模型和文档特征上有所差异。

Conclusion: 该基准测试为自动化文档系统提供了选择合适模型和处理策略的见解。

Abstract: This paper benchmarks eight multi-modal large language models from three
families (GPT-5, Gemini 2.5, and open-source Gemma 3) on three diverse openly
available invoice document datasets using zero-shot prompting. We compare two
processing strategies: direct image processing using multi-modal capabilities
and a structured parsing approach converting documents to markdown first.
Results show native image processing generally outperforms structured
approaches, with performance varying across model types and document
characteristics. This benchmark provides insights for selecting appropriate
models and processing strategies for automated document systems. Our code is
available online.

</details>


### [68] [COCORELI: Cooperative, Compositional Reconstitution \& Execution of Language Instructions](https://arxiv.org/abs/2509.04470)
*Swarnadeep Bhar,Omar Naim,Eleni Metheniti,Bastien Navarri,Loïc Cabannes,Morteza Ezzabady,Nicholas Asher*

Main category: cs.CL

TL;DR: COCORELI是一个混合智能体框架，通过结合中型语言模型和新颖的抽象机制，解决了大型语言模型在复杂指令遵循、减少幻觉和空间推理方面的局限性，并在协作构建和API完成任务中表现优于现有系统。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在遵循复杂指令、减少幻觉和空间推理方面存在局限性，需要更有效的框架来解决这些问题。

Method: 提出COCORELI混合智能体框架，整合了中型语言模型智能体、新颖的抽象机制和对话模块，用于解析指令并动态学习环境的高层表示。

Result: COCORELI在自然协作构建任务中，在避免幻觉、识别缺失信息、请求澄清和更新学习对象方面表现出色，并且优于使用更大模型的单一语言模型和智能体LLM系统。在ToolBench API完成任务中也展示了其抽象能力。

Conclusion: COCORELI通过其混合智能体方法和抽象机制，有效解决了大型语言模型的局限性，并在多个任务中取得了优于现有方法的成果。

Abstract: We present COCORELI, a hybrid agent framework designed to tackle the
limitations of large language models (LLMs) in tasks requiring: following
complex instructions, minimizing hallucination, and spatial reasoning. COCORELI
integrates medium-sized LLM agents with novel abstraction mechanisms and a
discourse module to parse instructions to in-context learn dynamic, high-level
representations of the environment. Experiments on natural collaborative
construction tasks show that COCORELI outperforms single-LLM CoT and agentic
LLM systems, all using larger LLMs. It manages to largely avoid hallucinations,
identify missing information, ask for clarifications, and update its learned
objects. COCORELI's abstraction abilities extend beyond ENVIRONMENT, as shown
in the ToolBench API completion task.

</details>


### [69] [MOSAIC: A Multilingual, Taxonomy-Agnostic, and Computationally Efficient Approach for Radiological Report Classification](https://arxiv.org/abs/2509.04471)
*Alice Schiavone,Marco Fraccaro,Lea Marie Pehrson,Silvia Ingala,Rasmus Bonnevie,Michael Bachmann Nielsen,Vincent Beliveau,Melanie Ganz,Desmond Elliott*

Main category: cs.CL

TL;DR: MOSAIC是一个高效、多语言、无需专业知识的放射报告分类方法，能够实现专家级别的性能，同时对计算资源的要求很低。


<details>
  <summary>Details</summary>
Motivation: 现有的放射报告分类方法存在局限性，例如基于规则的方法难以处理语言变异，监督学习模型需要大量标注数据，而基于大型语言模型（LLM）的系统则过于庞大或不适合临床使用。此外，现有方法大多仅限于英语和单一数据类型。

Method: MOSAIC采用一种基于紧凑型开源语言模型（MedGemma-4B）的方法，支持零样本/少样本提示和轻量级微调，可以在消费级GPU上运行。该方法具有多语言、跨不同标签体系的能力。

Result: MOSAIC在包含英语、西班牙语、法语和丹麦语的七个数据集上进行了评估，涵盖了多种影像模态和标签体系。在五个胸部X光数据集上，MOSAIC的平均宏观F1分数达到了88，接近或超过了专家水平，同时仅需24GB的GPU内存。通过数据增强，即使只有80个标注样本，也能在丹麦语报告上达到82的加权F1分数，而使用全部1600个样本训练集仅能达到86分。

Conclusion: MOSAIC为临床环境中替代大型或专有LLM提供了一个切实可行的选择，其代码和模型已开源，并鼓励社区进行扩展。

Abstract: Radiology reports contain rich clinical information that can be used to train
imaging models without relying on costly manual annotation. However, existing
approaches face critical limitations: rule-based methods struggle with
linguistic variability, supervised models require large annotated datasets, and
recent LLM-based systems depend on closed-source or resource-intensive models
that are unsuitable for clinical use. Moreover, current solutions are largely
restricted to English and single-modality, single-taxonomy datasets. We
introduce MOSAIC, a multilingual, taxonomy-agnostic, and computationally
efficient approach for radiological report classification. Built on a compact
open-access language model (MedGemma-4B), MOSAIC supports both zero-/few-shot
prompting and lightweight fine-tuning, enabling deployment on consumer-grade
GPUs. We evaluate MOSAIC across seven datasets in English, Spanish, French, and
Danish, spanning multiple imaging modalities and label taxonomies. The model
achieves a mean macro F1 score of 88 across five chest X-ray datasets,
approaching or exceeding expert-level performance, while requiring only 24 GB
of GPU memory. With data augmentation, as few as 80 annotated samples are
sufficient to reach a weighted F1 score of 82 on Danish reports, compared to 86
with the full 1600-sample training set. MOSAIC offers a practical alternative
to large or proprietary LLMs in clinical settings. Code and models are
open-source. We invite the community to evaluate and extend MOSAIC on new
languages, taxonomies, and modalities.

</details>


### [70] [RECAP: REwriting Conversations for Intent Understanding in Agentic Planning](https://arxiv.org/abs/2509.04472)
*Kushan Mitra,Dan Zhang,Hannah Kim,Estevam Hruschka*

Main category: cs.CL

TL;DR: RECAP是一个新的基准和方法，用于通过意图重写来改进多代理LLM对话助手中的用户意图检测和规划，解决了传统方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统基于分类的意图检测方法在开放域对话中存在泛化能力差、解释脆弱和下游规划效果不佳等问题，难以应对现实世界中模糊、不明确或动态的用户意图。

Method: 提出RECAP（REwriting Conversations for Agent Planning）基准，用于评估和推进意图重写，将用户-代理对话重构为用户目标的简洁表示。RECAP涵盖了歧义、意图漂移、模糊性和混合目标对话等多种挑战。引入基于LLM的评估器来评估重写后的意图的规划效用。开发了一种基于提示的重写方法，并进一步通过微调两个基于DPO的重写器来优化。

Result: 提出的基于提示的重写方法优于基线方法。微调DPO-based重写器可带来额外的效用增益。

Conclusion: 意图重写是改善开放域对话系统中代理规划的关键且可行的组成部分。

Abstract: Understanding user intent is essential for effective planning in
conversational assistants, particularly those powered by large language models
(LLMs) coordinating multiple agents. However, real-world dialogues are often
ambiguous, underspecified, or dynamic, making intent detection a persistent
challenge. Traditional classification-based approaches struggle to generalize
in open-ended settings, leading to brittle interpretations and poor downstream
planning. We propose RECAP (REwriting Conversations for Agent Planning), a new
benchmark designed to evaluate and advance intent rewriting, reframing
user-agent dialogues into concise representations of user goals. RECAP captures
diverse challenges such as ambiguity, intent drift, vagueness, and mixed-goal
conversations. Alongside the dataset, we introduce an LLM-based evaluator that
assesses planning utility given the rewritten intent. Using RECAP, we develop a
prompt-based rewriting approach that outperforms baselines. We further
demonstrate that fine-tuning two DPO-based rewriters yields additional utility
gains. Our results highlight intent rewriting as a critical and tractable
component for improving agent planning in open-domain dialogue systems.

</details>


### [71] [SpeechLLM: Unified Speech and Language Model for Enhanced Multi-Task Understanding in Low Resource Settings](https://arxiv.org/abs/2509.04473)
*Jaekwon Yoo,Kunal Chandiramani,Divya Tadimeti,Abenezer Girma,Chandra Dhir*

Main category: cs.CL

TL;DR: 提出了一种参数高效的适配器，用于将语音嵌入转换为与LLM兼容的令牌，以实现端到端自动语音识别（ASR）、命名实体识别（NER）和情感分析（SA）。通过使用基于LLM的合成数据集注释技术来降低标签成本，该适配器使用少7倍的可训练参数，在ASR、NER和SA任务上均取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有语音编码器与大型语言模型（LLM）集成需要大量数据和资源，并且在实际应用中面临可用性不足的限制。

Method: 提出了一种参数高效的适配器，用于将语音嵌入转换为LLM兼容的令牌。采用基于LLM的合成数据集注释技术来降低标签成本。使用了分类器正则化和低秩适配（LoRA）等高级技术。

Result: 与基线相比，在LibriSpeech ASR任务上词错误率（WER）相对降低了26%，在NER任务上F1分数相对提高了6.3%，在SA任务上F1分数相对提高了32%。使用高级技术后，口语理解评估（SLUE）分数提高了6.6%和9.5%。

Conclusion: 所提出的参数高效适配器和LLM驱动的合成数据方法，在ASR、NER和SA任务上取得了显著的性能提升，同时大大减少了对训练数据和参数的需求。

Abstract: While integrating speech encoder with LLM requires substantial data and
resources, use cases face limitations due to insufficient availability. To
address this, we propose a solution with a parameter-efficient adapter that
converts speech embeddings into LLM-compatible tokens, focusing on end-to-end
automatic speech recognition (ASR), named entity recognition (NER), and
sentiment analysis (SA). To reduce labeling costs, we employ an LLM-based
synthetic dataset annotation technique. The proposed adapter, using 7x fewer
trainable parameters, achieves significant performance gains: a 26% relative
Word Error Rates (WER) improvement on the LibriSpeech ASR task, a 6.3% relative
F1 score increase on the NER task, and a 32% relative F1 score boost on the SA
task. Moreover, using advanced techniques such as adding a classifier
regularizer and optimizing the LLM with Low-Rank Adaptation (LoRA) yields
notable performance gains, with Spoken Language Understanding Evaluation (SLUE)
score improvement of 6.6% and 9.5%

</details>


### [72] [Scaling Up, Speeding Up: A Benchmark of Speculative Decoding for Efficient LLM Test-Time Scaling](https://arxiv.org/abs/2509.04474)
*Shengyin Sun,Yiming Li,Xing Li,Yingzhao Lian,Weizhe Lin,Hui-Ling Zhen,Zhiyuan Yang,Chen Chen,Xianzhi Yu,Mingxuan Yuan,Chen Ma*

Main category: cs.CL

TL;DR: test-time scaling has computational overhead due to redundant reasoning traces. Speculative decoding can help, but its effectiveness in test-time scaling is under-explored. This paper introduces a benchmark to evaluate speculative decoding methods for test-time scaling, finding that n-gram-based methods are effective for repetitive reasoning and suggesting integration with other methods for balanced acceleration.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the inefficiency of test-time scaling in LLMs, which generates redundant reasoning traces, leading to computational overhead. The paper aims to explore the efficacy of speculative decoding in this context and provide a benchmark for evaluating different methods.

Method: The paper introduces a comprehensive benchmark to evaluate speculative decoding methods for accelerating LLM test-time scaling. This benchmark includes consistent experimental protocols across representative test-time scaling paradigms and compares three categories of speculative decoding: model-based, training-based, and n-gram-based methods.

Result: Extensive experiments show that simple n-gram-based methods are effective in accelerating test-time scaling by capturing repetitive patterns. The paper suggests integrating n-gram-based methods with model-based or training-based approaches to balance acceleration for both repetitive and diverse reasoning.

Conclusion: The paper concludes that speculative decoding, particularly n-gram-based methods, holds significant potential for accelerating LLM test-time scaling. It emphasizes the value of combining different speculative decoding approaches to handle both repetitive and diverse reasoning paths, ultimately enabling faster and more practical LLM reasoning.

Abstract: Test-time scaling has emerged as a powerful paradigm for enhancing the
reasoning capabilities of large language models (LLMs) by allocating additional
computational resources during inference. However, this paradigm is inherently
inefficient due to the generation of redundant and repetitive reasoning traces,
leading to significant computational overhead. Speculative decoding offers a
promising avenue for mitigating this inefficiency, yet its efficacy in the
structured, repetition-rich context of test-time scaling remains largely
unexplored. To bridge this gap, we introduce the first comprehensive benchmark
designed to evaluate speculative decoding methods for accelerating LLM
test-time scaling. Our benchmark provides consistent experimental protocols
across representative test-time scaling paradigms (e.g., Best-of-N sampling and
multi-round thinking), enabling a fair comparison of three major categories of
speculative decoding: model-based, training-based, and n-gram-based methods.
Extensive experiments reveal that simple n-gram-based methods effectively
capture repetitive patterns, demonstrating unique potential in accelerating
test-time scaling. This phenomenon demonstrates the value of integrating
n-gram-based methods with model-based or training-based approaches to balance
acceleration for both repetitive and diverse reasoning in test-time scaling. We
hope this benchmark spurs further research on speculative decoding for
test-time scaling, enabling faster and more practical reasoning in LLMs through
better handling of repetitive and diverse reasoning paths.

</details>


### [73] [ParaThinker: Native Parallel Thinking as a New Paradigm to Scale LLM Test-time Compute](https://arxiv.org/abs/2509.04475)
*Hao Wen,Yifan Su,Feifei Zhang,Yunxin Liu,Yunhao Liu,Ya-Qin Zhang,Yuanchun Li*

Main category: cs.CL

TL;DR: LLM 的推理能力可以通过增加计算量来提升，但目前的串行方法存在“隧道视野”问题，即模型在推理早期若出现错误，会导致后续推理路径的偏差，最终陷入次优解。本文提出了一种新的“思维并行”范式，通过同时生成和评估多个推理路径来克服这个问题，并提出 ParaThinker 框架。实验证明，该方法在推理准确性上比串行 LLM 有显著提升，同时计算开销增加很小。


<details>
  <summary>Details</summary>
Motivation: 目前的 LLM 在推理时采用串行计算，虽然可以通过增加计算量来提升性能，但当计算量达到一定程度时，性能提升会变得边际化，这可能是由于模型在推理早期产生的错误会“锁定”模型进入次优的推理路径，即“隧道视野”问题。

Method: 提出了一种名为“思维并行”的新的计算扩展范式，并设计了一个名为 ParaThinker 的端到端框架。该框架能够训练 LLM 同时生成多个不同的推理路径，并进行融合，从而得到一个更高质量的最终答案。通过并行探索不同的思维路径，ParaThinker 可以有效规避“隧道视野”问题，释放模型的推理潜力。

Result: ParaThinker 在推理准确性上比串行 LLM 有显著提升（在 1.5B 和 7B 模型上平均分别提升 12.3% 和 7.5%），同时计算开销增加很小（仅 7.1%）。这使得较小的模型也能够超越更大的模型，证明了并行思维是扩展 LLM 的一种更有效、更高效的途径。

Conclusion: 扩展 LLM 的计算量，串行（深度）方法存在“隧道视野”问题，导致性能提升边际化。而并行（宽度）的“思维并行”范式，通过 ParaThinker 框架，能够有效提升 LLM 的推理能力，并且在效率上优于串行方法。

Abstract: Recent advances in Large Language Models (LLMs) have been driven by test-time
compute scaling - a strategy that improves reasoning by generating longer,
sequential thought processes. While effective, this approach encounters a
significant bottleneck as computation increases, where further computation
offers only marginal performance gains. We argue this ceiling is not an
inherent limit of the model's capability but a flaw in the scaling strategy
itself, a phenomenon we term "Tunnel Vision", where a model's imperfect initial
steps lock it into a suboptimal reasoning path. To overcome this, we introduce
a new scaling paradigm: native thought parallelism. We present ParaThinker, an
end-to-end framework that trains an LLM to generate multiple, diverse reasoning
paths in parallel and synthesize them into a superior final answer. By
exploring different lines of thoughts simultaneously, ParaThinker effectively
sidesteps the Tunnel Vision issue and unlocks the model's latent reasoning
potential. Our approach demonstrates that scaling compute in parallel (width)
is a more effective and efficient way to superior reasoning than simply scaling
sequentially (depth). On challenging reasoning benchmarks, ParaThinker achieves
substantial accuracy improvements over sequential LLMs (12.3% for 1.5B and 7.5%
for 7B models on average with 8 parallel paths), while adding only negligible
latency overhead (7.1%). This enables smaller models to surpass much larger
counterparts and establishes parallel thinking as a critical, efficient
dimension for scaling future LLMs.

</details>


### [74] [Training Text-to-Molecule Models with Context-Aware Tokenization](https://arxiv.org/abs/2509.04476)
*Seojin Kim,Hyeontae Song,Jaehyun Nam,Jinwoo Shin*

Main category: cs.CL

TL;DR: CAMT5是一种新颖的文本到分子模型，通过引入子结构级别的标记化和基于重要性的训练策略，提高了对分子全局结构的理解能力，并在文本到分子生成任务中取得了优于现有方法的结果，同时显著减少了训练代币的使用。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到分子模型依赖于原子级别的标记化，这限制了它们捕捉分子内全局结构上下文的能力，而子结构级别的上下文对于理解分子结构至关重要。

Method: 提出了一种名为CAMT5的新模型，它引入了子结构级别的标记化，并结合了基于重要性的训练策略，优先考虑关键子结构，以更好地捕捉分子语义。此外，还提出了一种集成策略来进一步提高生成性能。

Result: CAMT5在各种文本到分子生成任务中表现优于最先进的方法，并且仅使用了2%的训练代币就取得了更好的效果。集成策略进一步提高了生成性能。

Conclusion: CAMT5通过其新颖的子结构标记化和训练策略，在文本到分子生成方面取得了显著进展，并展示了在提高效率和性能方面的巨大潜力。

Abstract: Recently, text-to-molecule models have shown great potential across various
chemical applications, e.g., drug-discovery. These models adapt language models
to molecular data by representing molecules as sequences of atoms. However,
they rely on atom-level tokenizations, which primarily focus on modeling local
connectivity, thereby limiting the ability of models to capture the global
structural context within molecules. To tackle this issue, we propose a novel
text-to-molecule model, coined Context-Aware Molecular T5 (CAMT5). Inspired by
the significance of the substructure-level contexts in understanding molecule
structures, e.g., ring systems, we introduce substructure-level tokenization
for text-to-molecule models. Building on our tokenization scheme, we develop an
importance-based training strategy that prioritizes key substructures, enabling
CAMT5 to better capture the molecular semantics. Extensive experiments verify
the superiority of CAMT5 in various text-to-molecule generation tasks.
Intriguingly, we find that CAMT5 outperforms the state-of-the-art methods using
only 2% of training tokens. In addition, we propose a simple yet effective
ensemble strategy that aggregates the outputs of text-to-molecule models to
further boost the generation performance. Code is available at
https://github.com/Songhyeontae/CAMT5.git.

</details>


### [75] [An End-to-End System for Culturally-Attuned Driving Feedback using a Dual-Component NLG Engine](https://arxiv.org/abs/2509.04478)
*Iniakpokeikiye Peter Thompson,Yi Dewei,Reiter Ehud*

Main category: cs.CL

TL;DR: 该系统是一个端到端的移动系统，旨在为尼日利亚的司机提供符合文化的安全驾驶反馈。该系统利用新颖的双组分自然语言生成（NLG）引擎，提供基于法律的安全提示和有说服力的行为报告。系统架构包括自动行程检测、设备上行为分析和两步反思NLG流程，并集成了检测酒后驾驶的机器学习模型。该系统设计鲁棒，可应对间歇性连接和嘈杂的传感器数据。试点部署表明该方法可行，并展示了检测到的不安全行为的初步结果。


<details>
  <summary>Details</summary>
Motivation: 在尼日利亚这样的低资源、基础设施挑战显著的环境中，为司机提供符合文化的安全驾驶反馈，并解决酒后驾驶等关键安全问题。

Method: 开发一个端到端的移动系统，包含：1. 新颖的双组分自然语言生成（NLG）引擎，提供基于法律的安全提示和行为报告。2. 自动行程检测服务。3. 设备上行为分析。4. 两步反思的NLG流程。5. 检测酒后驾驶的机器学习模型。6. 鲁棒的系统架构，应对连接问题和传感器噪声。

Result: 进行了包括90名司机在内的试点部署，初步结果显示了所提出方法的有效性，并展示了检测到的不安全行为的初步结果。

Conclusion: 该研究提供了一个将数据到文本和人工智能系统应用于促进社会公益的框架，并证明了所提出的端到端移动系统在尼日利亚等挑战性环境中的可行性。

Abstract: This paper presents an end-to-end mobile system that delivers
culturally-attuned safe driving feedback to drivers in Nigeria, a low-resource
environment with significant infrastructural challenges. The core of the system
is a novel dual-component Natural Language Generation (NLG) engine that
provides both legally-grounded safety tips and persuasive, theory-driven
behavioural reports. We describe the complete system architecture, including an
automatic trip detection service, on-device behaviour analysis, and a
sophisticated NLG pipeline that leverages a two-step reflection process to
ensure high-quality feedback. The system also integrates a specialized machine
learning model for detecting alcohol-influenced driving, a key local safety
issue. The architecture is engineered for robustness against intermittent
connectivity and noisy sensor data. A pilot deployment with 90 drivers
demonstrates the viability of our approach, and initial results on detected
unsafe behaviours are presented. This work provides a framework for applying
data-to-text and AI systems to achieve social good.

</details>


### [76] [No Clustering, No Routing: How Transformers Actually Process Rare Tokens](https://arxiv.org/abs/2509.04479)
*Jing Liu*

Main category: cs.CL

TL;DR: 大型语言模型在处理罕见词元时存在困难，但其专业化机制尚不明确。本研究通过神经元影响分析、图聚类和注意力头消融实验，在GPT-2 XL和Pythia模型中发现，罕见词元处理需要额外的平台神经元，形成双重计算模式；这些神经元分布广泛，而非形成模块化簇；注意力机制没有优先路由到专业神经元。研究表明，罕见词元专业化是通过分布式、训练驱动的差异化实现的，而非架构模块化，从而在实现适应性容量分配的同时保持了上下文敏感的灵活性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在罕见词元预测方面存在不足，但导致其专业化的机制尚不清楚。

Method: 通过神经元影响分析、图聚类和注意力头消融实验，在GPT-2 XL和Pythia模型中进行研究。

Result: 1. 罕见词元处理需要额外的平台神经元，形成双重计算模式；2. 平台神经元在空间上分布广泛，而非模块化簇；3. 注意力机制没有优先路由到专业神经元。

Conclusion: 罕见词元专业化是通过分布式、训练驱动的差异化实现的，而非架构模块化，从而在实现适应性容量分配的同时保持了上下文敏感的灵活性。

Abstract: Large language models struggle with rare token prediction, yet the mechanisms
driving their specialization remain unclear. Prior work identified specialized
``plateau'' neurons for rare tokens following distinctive three-regime
influence patterns \cite{liu2025emergent}, but their functional organization is
unknown. We investigate this through neuron influence analyses, graph-based
clustering, and attention head ablations in GPT-2 XL and Pythia models. Our
findings show that: (1) rare token processing requires additional plateau
neurons beyond the power-law regime sufficient for common tokens, forming dual
computational regimes; (2) plateau neurons are spatially distributed rather
than forming modular clusters; and (3) attention mechanisms exhibit no
preferential routing to specialists. These results demonstrate that rare token
specialization arises through distributed, training-driven differentiation
rather than architectural modularity, preserving context-sensitive flexibility
while achieving adaptive capacity allocation.

</details>


### [77] [Discrete Prompt Tuning via Recursive Utilization of Black-box Multimodal Large Language Model for Personalized Visual Emotion Recognition](https://arxiv.org/abs/2509.04480)
*Ryo Takahashi,Naoki Saito,Keisuke Maeda,Takahiro Ogawa,Miki Haseyama*

Main category: cs.CL

TL;DR: MLLMs在个性化视觉情感识别方面存在局限性，提出了一种基于离散提示调优的方法来提高性能。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在个性化视觉情感识别方面表现不佳，因为它们倾向于关注主流观点和熟悉模式，限制了其在实际应用中的潜力。

Method: 提出了一种受人类提示工程启发的离散提示调优方法，为每个用户调整视觉情感识别任务，通过选择最佳的自然语言表示来更新提示。

Result: 该方法能够实现准确的个性化视觉情感识别。

Conclusion: 提出的离散提示调优方法有效解决了现有MLLMs在个性化视觉情感识别方面的局限性，提高了识别精度。

Abstract: Visual Emotion Recognition (VER) is an important research topic due to its
wide range of applications, including opinion mining and advertisement design.
Extending this capability to recognize emotions at the individual level further
broadens its potential applications. Recently, Multimodal Large Language Models
(MLLMs) have attracted increasing attention and demonstrated performance
comparable to that of conventional VER methods. However, MLLMs are trained on
large and diverse datasets containing general opinions, which causes them to
favor majority viewpoints and familiar patterns. This tendency limits their
performance in a personalized VER, which is crucial for practical and
real-world applications, and indicates a key area for improvement. To address
this limitation, the proposed method employs discrete prompt tuning inspired by
the process of humans' prompt engineering to adapt the VER task to each
individual. Our method selects the best natural language representation from
the generated prompts and uses it to update the prompt for the realization of
accurate personalized VER.

</details>


### [78] [Energy Landscapes Enable Reliable Abstention in Retrieval-Augmented Large Language Models for Healthcare](https://arxiv.org/abs/2509.04482)
*Ravi Shankar,Sheng Wong,Lin Li,Magdalena Bachmann,Alex Silverthorne,Beth Albert,Gabriel Davis Jones*

Main category: cs.CL

TL;DR: 基于能量的模型（EBM）在检索增强生成（RAG）系统中实现了可靠的弃权，尤其是在女性健康等安全关键领域。


<details>
  <summary>Details</summary>
Motivation: 为了解决检索增强生成（RAG）系统在安全关键领域（如女性健康）中可靠弃权的问题，因为不准确的答案可能会造成伤害。

Method: 提出一个基于能量的模型（EBM），该模型在一个包含2.6M指南衍生问题的密集语义语料库上学习平滑的能量景观，从而使系统能够决定何时生成或弃权。将EBM与经过校准的softmax基线和k近邻（kNN）密度启发式方法在简单和困难的弃权分割上进行了基准测试。

Result: EBM在语义上困难的情况下实现了卓越的弃权性能，AUROC达到0.961，优于softmax的0.950，同时还将FPR@95从0.331降低到0.235。在简单的否定样本上，各种方法的性能相当，但在安全关键的困难分布上，EBM的优势最为明显。消融研究表明，鲁棒性主要来源于能量评分头，而负样本类型的选择会影响决策边界，但对于泛化到困难案例并非必需。

Conclusion: 基于能量的弃权评分比基于概率的softmax置信度提供了更可靠的置信度信号，为安全的RAG系统提供了可扩展且可解释的基础。

Abstract: Reliable abstention is critical for retrieval-augmented generation (RAG)
systems, particularly in safety-critical domains such as women's health, where
incorrect answers can lead to harm. We present an energy-based model (EBM) that
learns a smooth energy landscape over a dense semantic corpus of 2.6M
guideline-derived questions, enabling the system to decide when to generate or
abstain. We benchmark the EBM against a calibrated softmax baseline and a
k-nearest neighbour (kNN) density heuristic across both easy and hard
abstention splits, where hard cases are semantically challenging
near-distribution queries. The EBM achieves superior abstention performance
abstention on semantically hard cases, reaching AUROC 0.961 versus 0.950 for
softmax, while also reducing FPR@95 (0.235 vs 0.331). On easy negatives,
performance is comparable across methods, but the EBM's advantage becomes most
pronounced in safety-critical hard distributions. A comprehensive ablation with
controlled negative sampling and fair data exposure shows that robustness stems
primarily from the energy scoring head, while the inclusion or exclusion of
specific negative types (hard, easy, mixed) sharpens decision boundaries but is
not essential for generalisation to hard cases. These results demonstrate that
energy-based abstention scoring offers a more reliable confidence signal than
probability-based softmax confidence, providing a scalable and interpretable
foundation for safe RAG systems.

</details>


### [79] [DecMetrics: Structured Claim Decomposition Scoring for Factually Consistent LLM Outputs](https://arxiv.org/abs/2509.04483)
*Minghui Huang*

Main category: cs.CL

TL;DR: 该研究提出了用于评估事实核查中声明分解质量的新指标DecMetrics，并基于此开发了一个轻量级的分解模型。


<details>
  <summary>Details</summary>
Motivation: 当前研究缺乏对声明分解质量的评估方法，而这对于事实核查至关重要。

Method: 提出DecMetrics，包含COMPLETENESS、CORRECTNESS和SEMANTIC ENTROPY三个指标，并将其用作奖励函数来优化轻量级声明分解模型。

Result: 通过自动评估，该方法为声明分解设定了基准，提高了事实核查系统的可靠性和有效性。

Conclusion: DecMetrics能够有效评估声明分解的质量，并有助于开发更优的分解模型，从而提升事实核查的整体效能。

Abstract: Claim decomposition plays a crucial role in the fact-checking process by
breaking down complex claims into simpler atomic components and identifying
their unfactual elements. Despite its importance, current research primarily
focuses on generative methods for decomposition, with insufficient emphasis on
evaluating the quality of these decomposed atomic claims. To bridge this gap,
we introduce \textbf{DecMetrics}, which comprises three new metrics:
\texttt{COMPLETENESS}, \texttt{CORRECTNESS}, and \texttt{SEMANTIC ENTROPY},
designed to automatically assess the quality of claims produced by
decomposition models. Utilizing these metrics, we develop a lightweight claim
decomposition model, optimizing its performance through the integration of
these metrics as a reward function. Through automatic evaluation, our approach
aims to set a benchmark for claim decomposition, enhancing both the reliability
and effectiveness of fact-checking systems.

</details>


### [80] [The Good, the Bad and the Constructive: Automatically Measuring Peer Review's Utility for Authors](https://arxiv.org/abs/2509.04484)
*Abdelrahman Sadallah,Tim Baumgärtner,Iryna Gurevych,Ted Briscoe*

Main category: cs.CL

TL;DR: 本文提出了RevUtil数据集，用于评估和开发分析论文审稿意见的AI模型，并识别出驱动审稿意见效用的四个关键方面：可操作性、依据与特异性、可验证性和有用性。


<details>
  <summary>Details</summary>
Motivation: 为了确保审稿意见的质量并使其对作者更有用，在审稿人时间有限的情况下，需要自动化支持系统。

Method: 构建了一个包含1,430条人工标注和10,000条合成标注的RevUtil数据集，并使用该数据集对评估审稿意见和生成理由的AI模型进行了基准测试。

Result: 在RevUtil数据集上，经过微调的模型在评估审稿意见方面的表现与人类评估者相当，甚至在某些方面超过了GPT-4o等强大模型。然而，机器生成的审稿意见在所提出的四个方面普遍逊于人类审稿意见。

Conclusion: RevUtil数据集为评估和开发审稿意见分析模型提供了资源，并强调了在提升机器生成审稿意见质量方面仍有改进空间。

Abstract: Providing constructive feedback to paper authors is a core component of peer
review. With reviewers increasingly having less time to perform reviews,
automated support systems are required to ensure high reviewing quality, thus
making the feedback in reviews useful for authors. To this end, we identify
four key aspects of review comments (individual points in weakness sections of
reviews) that drive the utility for authors: Actionability, Grounding &
Specificity, Verifiability, and Helpfulness. To enable evaluation and
development of models assessing review comments, we introduce the RevUtil
dataset. We collect 1,430 human-labeled review comments and scale our data with
10k synthetically labeled comments for training purposes. The synthetic data
additionally contains rationales, i.e., explanations for the aspect score of a
review comment. Employing the RevUtil dataset, we benchmark fine-tuned models
for assessing review comments on these aspects and generating rationales. Our
experiments demonstrate that these fine-tuned models achieve agreement levels
with humans comparable to, and in some cases exceeding, those of powerful
closed models like GPT-4o. Our analysis further reveals that machine-generated
reviews generally underperform human reviews on our four aspects.

</details>


### [81] [ASCENDgpt: A Phenotype-Aware Transformer Model for Cardiovascular Risk Prediction from Electronic Health Records](https://arxiv.org/abs/2509.04485)
*Chris Sainsbury,Andreas Karwath*

Main category: cs.CL

TL;DR: ASCENDgpt是一个用于心血管风险预测的Transformer模型，通过新颖的表型感知分词方案，显著减少了编码数量，并在多项心血管事件预测任务中取得了优异的性能。


<details>
  <summary>Details</summary>
Motivation: 利用纵向电子健康记录（EHRs）进行心血管风险预测，并提出一种新的分词方案以提高效率和可解释性。

Method: 使用新颖的表型感知分词方案将ICD编码映射为有临床意义的表型标记，并预训练一个基于Transformer的模型（ASCENDgpt），然后在五个心血管结局上进行微调。

Result: ASCENDgpt在测试集上平均C指数达到0.816，在各项心血管结局预测任务中均表现出色（MI: 0.792, stroke: 0.824, MACE: 0.800, 心血管死亡: 0.842, 全因死亡: 0.824）。

Conclusion: 领域特定的分词和预训练对于基于EHRs的风险预测任务是有效的，ASCENDgpt在心血管风险预测方面表现出强大的能力和临床可解释性。

Abstract: We present ASCENDgpt, a transformer-based model specifically designed for
cardiovascular risk prediction from longitudinal electronic health records
(EHRs). Our approach introduces a novel phenotype-aware tokenization scheme
that maps 47,155 raw ICD codes to 176 clinically meaningful phenotype tokens,
achieving 99.6\% consolidation of diagnosis codes while preserving semantic
information. This phenotype mapping contributes to a total vocabulary of 10,442
tokens - a 77.9\% reduction when compared with using raw ICD codes directly. We
pretrain ASCENDgpt on sequences derived from 19402 unique individuals using a
masked language modeling objective, then fine-tune for time-to-event prediction
of five cardiovascular outcomes: myocardial infarction (MI), stroke, major
adverse cardiovascular events (MACE), cardiovascular death, and all-cause
mortality. Our model achieves excellent discrimination on the held-out test set
with an average C-index of 0.816, demonstrating strong performance across all
outcomes (MI: 0.792, stroke: 0.824, MACE: 0.800, cardiovascular death: 0.842,
all-cause mortality: 0.824). The phenotype-based approach enables clinically
interpretable predictions while maintaining computational efficiency. Our work
demonstrates the effectiveness of domain-specific tokenization and pretraining
for EHR-based risk prediction tasks.

</details>


### [82] [Serialized Output Prompting for Large Language Model-based Multi-Talker Speech Recognition](https://arxiv.org/abs/2509.04488)
*Hao Shi,Yusuke Fujita,Tomoya Mizumoto,Lianbo Liu,Atsushi Kojima,Yui Sudo*

Main category: cs.CL

TL;DR: SOP-MT-ASR通过提取结构化输出提示来提升多话题自动语音识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的多话题ASR系统在提示设计上存在不足，限制了性能提升。

Method: 提出提取序列化输出提示（SOP），并结合分隔符和序列化CTC层来处理混合语音编码，最后通过贪婪搜索解码得到SOP。设计了包含序列化输出训练（SOT）微调、序列化语音信息提取和SOP自适应的“三阶段”训练策略。

Result: 在LibriMix数据集上，SOP-MT-ASR在两话题和三话题场景下均显著提升了性能，尤其是在更复杂的三话题场景下，优于仅基于LLM的SOT模型。

Conclusion: SOP方法能够有效提升LLM在多话题ASR任务中的性能，尤其是在处理多于两话题的复杂情况时。

Abstract: Prompts are crucial for task definition and for improving the performance of
large language models (LLM)-based systems. However, existing LLM-based
multi-talker (MT) automatic speech recognition (ASR) systems either omit
prompts or rely on simple task-definition prompts, with no prior work exploring
the design of prompts to enhance performance. In this paper, we propose
extracting serialized output prompts (SOP) and explicitly guiding the LLM using
structured prompts to improve system performance (SOP-MT-ASR). A Separator and
serialized Connectionist Temporal Classification (CTC) layers are inserted
after the speech encoder to separate and extract MT content from the mixed
speech encoding in a first-speaking-first-out manner. Subsequently, the SOP,
which serves as a prompt for LLMs, is obtained by decoding the serialized CTC
outputs using greedy search. To train the model effectively, we design a
three-stage training strategy, consisting of serialized output training (SOT)
fine-tuning, serialized speech information extraction, and SOP-based
adaptation. Experimental results on the LibriMix dataset show that, although
the LLM-based SOT model performs well in the two-talker scenario, it fails to
fully leverage LLMs under more complex conditions, such as the three-talker
scenario. The proposed SOP approach significantly improved performance under
both two- and three-talker conditions.

</details>


### [83] [Refining Transcripts With TV Subtitles by Prompt-Based Weakly Supervised Training of ASR](https://arxiv.org/abs/2509.04491)
*Xinnian Zhao,Hugo Van Hamme*

Main category: cs.CL

TL;DR: 该研究提出了一种利用电视字幕的弱监督自动语音识别（ASR）框架的新方法，将字幕作为上下文线索而非直接监督信号，通过生成伪文本并结合加权注意力机制进行迭代优化，显著提高了转录准确性。


<details>
  <summary>Details</summary>
Motivation: 电视字幕易于获取，但与音频的对齐不精确，限制了其作为 verbatim 转录的监督信号。本研究旨在克服这一限制，利用字幕的丰富上下文信息来改进 ASR。

Method: 提出了一种新方法，将电视字幕作为上下文线索，生成伪文本作为主要监督信号，并通过加权注意力机制进行迭代优化。

Result: 实验证明，该方法显著提高了转录准确性，并生成了高质量的伪标签数据集，可用于训练更鲁棒的 ASR 系统。

Conclusion: 所提出的方法能够有效地利用电视字幕的上下文信息，通过生成伪文本和加权注意力机制来改进 ASR 的转录准确性，并为 ASR 系统提供了高质量的训练资源。

Abstract: This study proposes a novel approach to using TV subtitles within a weakly
supervised (WS) Automatic Speech Recognition (ASR) framework. Although TV
subtitles are readily available, their imprecise alignment with corresponding
audio limits their applicability as supervised targets for verbatim
transcription. Rather than using subtitles as direct supervision signals, our
method reimagines them as context-rich prompts. This design enables the model
to handle discrepancies between spoken audio and subtitle text. Instead,
generated pseudo transcripts become the primary targets, with subtitles acting
as guiding cues for iterative refinement. To further enhance the process, we
introduce a weighted attention mechanism that emphasizes relevant subtitle
tokens during inference. Our experiments demonstrate significant improvements
in transcription accuracy, highlighting the effectiveness of the proposed
method in refining transcripts. These enhanced pseudo-labeled datasets provide
high-quality foundational resources for training robust ASR systems.

</details>


### [84] [Learned Hallucination Detection in Black-Box LLMs using Token-level Entropy Production Rate](https://arxiv.org/abs/2509.04492)
*Charles Moslonka,Hicham Randrianarivo,Arthur Garnier,Emmanuel Malherbe*

Main category: cs.CL

TL;DR: 本研究提出了一种在数据有限的情况下，仅利用单次生成得到的token log-probabilities来检测大型语言模型（LLM）中幻觉的实用方法，通过计算熵变率（EPR）并结合监督学习，提高了幻觉检测的准确性，适用于黑盒LLM API场景。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在问答（QA）任务中产生的幻觉严重影响了其实际可靠性，因此需要一种鲁棒且适用于数据受限场景（如黑盒LLM API）的幻觉检测方法。

Method: 该方法直接从非贪婪解码过程中生成的token log-probabilities中提取不确定性指标。首先计算熵变率（EPR）作为基线，然后通过使用可获取的、排名前列的token的熵贡献特征进行监督学习来增强性能。该方法仅需一次生成，无需多次查询。

Result: 所提出的方法在多种QA数据集和多个LLM上进行了评估，显著提高了幻觉检测的性能。即使仅使用通常有限的、每个token排名前10的log-probabilities，该方法也表现出高精度，证明了其在API限制下的实用性和效率。该方法还在一个金融框架中进行了演示，分析了对年报查询的LLM响应。

Conclusion: 本研究提供了一种易于部署的技术，能够通过单次生成过程提高QA和检索增强生成（RAG）系统中LLM响应的可信度，尤其适用于API访问受限的场景。

Abstract: Hallucinations in Large Language Model (LLM) outputs for Question Answering
(QA) tasks critically undermine their real-world reliability. This paper
introduces an applied methodology for robust, one-shot hallucination detection,
specifically designed for scenarios with limited data access, such as
interacting with black-box LLM APIs that typically expose only a few top
candidate log-probabilities per token. Our approach derives uncertainty
indicators directly from these readily available log-probabilities generated
during non-greedy decoding. We first derive an Entropy Production Rate (EPR)
metric that offers baseline performance, later augmented with supervised
learning. Our learned model uses features representing the entropic
contributions of the accessible top-ranked tokens within a single generated
sequence, requiring no multiple query re-runs. Evaluated across diverse QA
datasets and multiple LLMs, this estimator significantly improves hallucination
detection over using EPR alone. Crucially, high performance is demonstrated
using only the typically small set of available log-probabilities (e.g., top
<10 per token), confirming its practical efficiency and suitability for these
API-constrained deployments. This work provides a readily deployable technique
to enhance the trustworthiness of LLM responses from a single generation pass
in QA and Retrieval-Augmented Generation (RAG) systems, with its utility
further demonstrated in a finance framework analyzing responses to queries on
annual reports from an industrial dataset.

</details>


### [85] [A Narrative-Driven Computational Framework for Clinician Burnout Surveillance](https://arxiv.org/abs/2509.04497)
*Syed Ahmad Chan Bukhari,Fazel Keshtkar,Alyssa Meczkowska*

Main category: cs.CL

TL;DR: 临床记录中的叙述性信息可用于预测医生倦怠，尤其是在重症监护室（ICU）中。


<details>
  <summary>Details</summary>
Motivation: 医生倦怠对患者安全构成重大威胁，尤其是在高风险的重症监护室（ICU）中。现有研究主要依赖回顾性调查工具或广泛的电子健康记录（EHR）元数据，但忽略了临床笔记中包含的叙述性信息。

Method: 该研究分析了来自MIMIC-IV的10,000份ICU出院总结，并采用了一个结合了临床叙述的BioBERT情感嵌入、针对医生倦怠监测的词汇压力词典以及包含工作负载代理的五主题潜在狄利克雷模型（LDA）的混合流程。

Result: 基于该流程的提供者级别的逻辑回归分类器在分层保留集上实现了0.80的精确率、0.89的召回率和0.84的F1分数，其F1分数比仅使用元数据的基线高出至少0.17。特定专业的分析显示放射科、精神科和神经科的医生倦怠风险较高。

Conclusion: ICU临床叙述中包含可用于主动监测医生身心健康的可用信号。

Abstract: Clinician burnout poses a substantial threat to patient safety, particularly
in high-acuity intensive care units (ICUs). Existing research predominantly
relies on retrospective survey tools or broad electronic health record (EHR)
metadata, often overlooking the valuable narrative information embedded in
clinical notes. In this study, we analyze 10,000 ICU discharge summaries from
MIMIC-IV, a publicly available database derived from the electronic health
records of Beth Israel Deaconess Medical Center. The dataset encompasses
diverse patient data, including vital signs, medical orders, diagnoses,
procedures, treatments, and deidentified free-text clinical notes. We introduce
a hybrid pipeline that combines BioBERT sentiment embeddings fine-tuned for
clinical narratives, a lexical stress lexicon tailored for clinician burnout
surveillance, and five-topic latent Dirichlet allocation (LDA) with workload
proxies. A provider-level logistic regression classifier achieves a precision
of 0.80, a recall of 0.89, and an F1 score of 0.84 on a stratified hold-out
set, surpassing metadata-only baselines by greater than or equal to 0.17 F1
score. Specialty-specific analysis indicates elevated burnout risk among
providers in Radiology, Psychiatry, and Neurology. Our findings demonstrate
that ICU clinical narratives contain actionable signals for proactive
well-being monitoring.

</details>


### [86] [Where Should I Study? Biased Language Models Decide! Evaluating Fairness in LMs for Academic Recommendations](https://arxiv.org/abs/2509.04498)
*Krithi Shailya,Akhilesh Kumar Mishra,Gokul S Krishnan,Balaraman Ravindran*

Main category: cs.CL

TL;DR: LLMs在教育推荐中存在地理、人口和经济偏见，应改进以实现公平的教育机会。


<details>
  <summary>Details</summary>
Motivation: LLMs在教育推荐中可能加剧社会偏见，需要评估其偏见。

Method: 使用360个模拟用户画像，分析LLaMA-3.1、Gemma-7B和Mistral-7B在大学和专业推荐中的地理、人口和经济偏见。

Result: LLMs推荐偏向于‘全球北方’国家，强化性别刻板印象，且存在机构重复推荐的问题。LLaMA-3.1推荐最多样化，但系统性差异依然存在。

Conclusion: LLMs在教育推荐中存在显著偏见，亟需改进以确保全球高等教育的公平获取。

Abstract: Large Language Models (LLMs) are increasingly used as daily recommendation
systems for tasks like education planning, yet their recommendations risk
perpetuating societal biases. This paper empirically examines geographic,
demographic, and economic biases in university and program suggestions from
three open-source LLMs: LLaMA-3.1-8B, Gemma-7B, and Mistral-7B. Using 360
simulated user profiles varying by gender, nationality, and economic status, we
analyze over 25,000 recommendations. Results show strong biases: institutions
in the Global North are disproportionately favored, recommendations often
reinforce gender stereotypes, and institutional repetition is prevalent. While
LLaMA-3.1 achieves the highest diversity, recommending 481 unique universities
across 58 countries, systemic disparities persist. To quantify these issues, we
propose a novel, multi-dimensional evaluation framework that goes beyond
accuracy by measuring demographic and geographic representation. Our findings
highlight the urgent need for bias consideration in educational LMs to ensure
equitable global access to higher education.

</details>


### [87] [DeepTRACE: Auditing Deep Research AI Systems for Tracking Reliability Across Citations and Evidence](https://arxiv.org/abs/2509.04499)
*Pranav Narayanan Venkit,Philippe Laban,Yilun Zhou,Kung-Hsiang Huang,Yixin Mao,Chien-Sheng Wu*

Main category: cs.CL

TL;DR: 用户在使用生成式搜索引擎和深度研究LLM代理时，经常会遇到过度自信、证据不足和引用混乱的问题。本文提出了DeepTRACE审计框架，将已识别的失败案例转化为可衡量的维度，涵盖答案文本、来源和引用。该框架通过对语句进行分析，并构建引用和事实支持矩阵，来审计系统如何端到端地处理和归属证据。通过对现有模型进行评估，发现生成式搜索和深度研究代理在处理辩论性查询时，常产生片面且自信的回答，且大量陈述缺乏自身来源的支持。深度研究配置能降低过度自信，提高引用完整性，但在辩论性查询上仍显片面，且存在大量陈述缺乏支持，引用准确率在40%-80%之间。


<details>
  <summary>Details</summary>
Motivation: 现有生成式搜索和深度研究LLM代理在提供可信、有来源依据的合成内容方面存在过度自信、证据不足和引用混乱等问题，需要一个有效的审计框架来评估和改进这些系统。

Method: 提出DeepTRACE审计框架，将社区识别的失败案例转化为八个可衡量的维度（涵盖答案文本、来源和引用），并利用语句级分析（分解、置信度评分）和构建引用与事实支持矩阵，来端到端地审计系统的推理和证据归属过程。通过自动化提取和LLM-judge评估了包括GPT-4.5/5、You.com、Perplexity、Copilot/Bing和Gemini在内的多个模型。

Result: 生成式搜索引擎和深度研究代理在处理辩论性查询时，经常产生片面且高度自信的回答，且大量陈述缺乏其自身提供来源的支持。深度研究配置虽然能降低过度自信并提高引用完整性，但在辩论性查询上仍然片面，并且存在大量陈述缺乏支持的情况，引用准确率在不同系统间为40%-80%。

Conclusion: 生成式搜索和深度研究LLM代理在提供可靠、有依据的答案方面仍有显著的改进空间，尤其是在处理主观性或辩论性内容以及确保引用的准确性和支持性方面。DeepTRACE框架为量化和改进这些系统提供了有效的方法。

Abstract: Generative search engines and deep research LLM agents promise trustworthy,
source-grounded synthesis, yet users regularly encounter overconfidence, weak
sourcing, and confusing citation practices. We introduce DeepTRACE, a novel
sociotechnically grounded audit framework that turns prior community-identified
failure cases into eight measurable dimensions spanning answer text, sources,
and citations. DeepTRACE uses statement-level analysis (decomposition,
confidence scoring) and builds citation and factual-support matrices to audit
how systems reason with and attribute evidence end-to-end. Using automated
extraction pipelines for popular public models (e.g., GPT-4.5/5, You.com,
Perplexity, Copilot/Bing, Gemini) and an LLM-judge with validated agreement to
human raters, we evaluate both web-search engines and deep-research
configurations. Our findings show that generative search engines and deep
research agents frequently produce one-sided, highly confident responses on
debate queries and include large fractions of statements unsupported by their
own listed sources. Deep-research configurations reduce overconfidence and can
attain high citation thoroughness, but they remain highly one-sided on debate
queries and still exhibit large fractions of unsupported statements, with
citation accuracy ranging from 40--80% across systems.

</details>


### [88] [Context Engineering for Trustworthiness: Rescorla Wagner Steering Under Mixed and Inappropriate Contexts](https://arxiv.org/abs/2509.04500)
*Rushi Wang,Jiateng Liu,Cheng Qian,Yifan Shen,Yanzhou Pan,Zhaozhuo Xu,Ahmed Abbasi,Heng Ji,Denghui Zhang*

Main category: cs.CL

TL;DR: LLM在处理混合上下文时，倾向于优先考虑不常见的信息，这可能导致不当内容影响响应质量。研究提出了RW-Steering方法，通过微调使模型能够识别并忽略不当信号，从而提高响应质量和安全性。


<details>
  <summary>Details</summary>
Motivation: 真实世界的上下文信息混杂，可能包含不相关甚至不当内容，给大型语言模型（LLM）带来可靠性风险。研究旨在探究LLM如何处理和优先排序混合上下文信息，并提出解决方案。

Method: 提出“中毒上下文测试平台”，结合查询和包含相关及不当内容的真实世界上下文。借鉴神经科学中的Rescorla-Wagner（RW）模型，量化竞争性上下文信号对LLM输出的影响。提出RW-Steering方法，这是一种两阶段微调方法，使模型能够识别并忽略不当信号。

Result: LLM表现出优先整合不常见信息的行为模式。少量不当内容会显著降低响应质量。RW-Steering方法在不同比例不当内容的测试中表现稳健，最佳微调模型将响应质量提高了39.8%，并逆转了不良行为曲线。

Conclusion: RW-Steering是一种稳健且可泛化的上下文工程解决方案，可用于提高LLM在真实世界应用中的安全性。

Abstract: Incorporating external context can significantly enhance the response quality
of Large Language Models (LLMs). However, real-world contexts often mix
relevant information with disproportionate inappropriate content, posing
reliability risks. How do LLMs process and prioritize mixed context? To study
this, we introduce the Poisoned Context Testbed, pairing queries with
real-world contexts containing relevant and inappropriate content. Inspired by
associative learning in animals, we adapt the Rescorla-Wagner (RW) model from
neuroscience to quantify how competing contextual signals influence LLM
outputs. Our adapted model reveals a consistent behavioral pattern: LLMs
exhibit a strong tendency to incorporate information that is less prevalent in
the context. This susceptibility is harmful in real-world settings, where small
amounts of inappropriate content can substantially degrade response quality.
Empirical evaluations on our testbed further confirm this vulnerability. To
tackle this, we introduce RW-Steering, a two-stage finetuning-based approach
that enables the model to internally identify and ignore inappropriate signals.
Unlike prior methods that rely on extensive supervision across diverse context
mixtures, RW-Steering generalizes robustly across varying proportions of
inappropriate content. Experiments show that our best fine-tuned model improves
response quality by 39.8% and reverses the undesirable behavior curve,
establishing RW-Steering as a robust, generalizable context engineering
solution for improving LLM safety in real-world use.

</details>


### [89] [Understanding Reinforcement Learning for Model Training, and future directions with GRAPE](https://arxiv.org/abs/2509.04501)
*Rohit Patel*

Main category: cs.CL

TL;DR: 本文从头开始，为指令调优模型中的关键算法（SFT、拒绝采样、REINFORCE、TRPO、PPO、GRPO 和 DPO）提供了一个独立的、循序渐进的阐述。通过简化符号和关注 LLM，旨在消除歧义，提供清晰直观的理解。此外，还包括了新技术和方法的文献综述，并提出了新的研究思路 GRAPE。


<details>
  <summary>Details</summary>
Motivation: 许多关于指令调优算法的现有解释都假设有先验知识，缺乏关键细节，或者过于笼统和复杂。本文旨在通过提供一个从头开始、逐步的阐述来解决这些问题，使用简化的、针对 LLM 的明确符号，以消除歧义并提供清晰直观的理解。

Method: 本文详细阐述了指令调优模型的关键算法，包括 SFT、拒绝采样、REINFORCE、TRPO、PPO、GRPO 和 DPO。每个方法都使用简化的、显式的、针对 LLM 的符号进行逐步讨论和开发。通过尽量减少对更广泛的 RL 文献的引用，并将概念与 LLM 联系起来，消除了不必要的抽象，降低了认知开销。

Result: 本文对 SFT、拒绝采样、REINFORCE、TRPO、PPO、GRPO 和 DPO 等关键算法进行了详细的阐述。此外，还提供了新技术和方法的文献综述，并提出了新的研究思路 GRAPE。

Conclusion: 本文为指令调优模型的关键算法提供了一个清晰、独立、从头开始的阐述，通过简化符号和关注 LLM，消除了现有解释中的歧义和不必要的复杂性。此外，本文还为该领域未来的研究和探索提供了新的方向。

Abstract: This paper provides a self-contained, from-scratch, exposition of key
algorithms for instruction tuning of models: SFT, Rejection Sampling,
REINFORCE, Trust Region Policy Optimization (TRPO), Proximal Policy
Optimization (PPO), Group Relative Policy Optimization (GRPO), and Direct
Preference Optimization (DPO). Explanations of these algorithms often assume
prior knowledge, lack critical details, and/or are overly generalized and
complex. Here, each method is discussed and developed step by step using
simplified and explicit notation focused on LLMs, aiming to eliminate ambiguity
and provide a clear and intuitive understanding of the concepts. By minimizing
detours into the broader RL literature and connecting concepts to LLMs, we
eliminate superfluous abstractions and reduce cognitive overhead. Following
this exposition, we provide a literature review of new techniques and
approaches beyond those detailed. Finally, new ideas for research and
exploration in the form of GRAPE (Generalized Relative Advantage Policy
Evolution) are presented.

</details>


### [90] [VaccineRAG: Boosting Multimodal Large Language Models' Immunity to Harmful RAG Samples](https://arxiv.org/abs/2509.04502)
*Qixin Sun,Ziqin Wang,Hengyuan Zhao,Yilin Li,Kaiyou Song,Linjiang Huang,Xiaolin Hu,Qingpei Guo,Si Liu*

Main category: cs.CL

TL;DR: VaccineRAG是一个基于思维链（Chain-of-Thought, CoT）的检索增强生成（Retrieval Augmented Generation, RAG）数据集，旨在提高LLM在处理包含误导性信息时的准确性，并通过引入Partial-GRPO来增强模型学习复杂CoT内容的能力。


<details>
  <summary>Details</summary>
Motivation: 检索增强生成（RAG）的有效性常常受到检索器精度的限制，许多检索到的样本可能与查询不相关或具有误导性，这是影响大型语言模型（LLM）性能的关键瓶颈。

Method: 提出VaccineRAG数据集，包含不同正负样本比例的数据，以评估模型；通过提示LLM为每个样本生成显式的CoT分析来提高模型的样本辨别能力；提出Partial-GRPO模型，将LLM的输出建模为多个组件以增强模型学习复杂CoT内容的能力。

Result: 在VaccineRAG数据集上的综合评估和消融研究验证了所提出方案的有效性。

Conclusion: 所提出的VaccineRAG数据集和Partial-GRPO模型能够有效解决RAG中的样本选择问题，提高LLM在复杂推理任务中的表现。

Abstract: Retrieval Augmented Generation enhances the response accuracy of Large
Language Models (LLMs) by integrating retrieval and generation modules with
external knowledge, demonstrating particular strength in real-time queries and
Visual Question Answering tasks. However, the effectiveness of RAG is
frequently hindered by the precision of the retriever: many retrieved samples
fed into the generation phase are irrelevant or misleading, posing a critical
bottleneck to LLMs' performance. To address this challenge, we introduce
VaccineRAG, a novel Chain-of-Thought-based retrieval-augmented generation
dataset. On one hand, VaccineRAG employs a benchmark to evaluate models using
data with varying positive/negative sample ratios, systematically exposing
inherent weaknesses in current LLMs. On the other hand, it enhances models'
sample-discrimination capabilities by prompting LLMs to generate explicit
Chain-of-Thought (CoT) analysis for each sample before producing final answers.
Furthermore, to enhance the model's ability to learn long-sequence complex CoT
content, we propose Partial-GRPO. By modeling the outputs of LLMs as multiple
components rather than a single whole, our model can make more informed
preference selections for complex sequences, thereby enhancing its capacity to
learn complex CoT. Comprehensive evaluations and ablation studies on VaccineRAG
validate the effectiveness of the proposed scheme. The code and dataset will be
publicly released soon.

</details>


### [91] [Behavioral Fingerprinting of Large Language Models](https://arxiv.org/abs/2509.04504)
*Zehua Pei,Hui-Ling Zhen,Ying Zhang,Zhiyuan Yang,Xing Li,Xianzhi Yu,Mingxuan Yuan,Bei Yu*

Main category: cs.CL

TL;DR: 该论文引入了一种名为“行为指纹”的新框架，用于评估大型语言模型（LLM）的细微行为特征，而非仅仅关注性能指标。


<details>
  <summary>Details</summary>
Motivation: 传统的LLM基准测试主要关注性能指标，未能捕捉区分模型的细微行为特征。

Method: 使用诊断提示套件和由强大LLM作为裁判的自动化评估流程，分析了十八个不同能力层级的模型。

Result: 结果表明，虽然顶尖模型的抽象和因果推理能力趋于一致，但谄媚和语义鲁棒性等与对齐相关的行为差异显著。此外，还发现了跨模型默认的“人格”聚类（ISTJ/ESTJ），这可能反映了常见的对齐激励。

Conclusion: LLM的交互行为并非其规模或推理能力的涌现属性，而是由特定的、高度可变的开发者对齐策略造成的。该框架提供了一种可复现且可扩展的方法，用于揭示这些深层次的行为差异。

Abstract: Current benchmarks for Large Language Models (LLMs) primarily focus on
performance metrics, often failing to capture the nuanced behavioral
characteristics that differentiate them. This paper introduces a novel
``Behavioral Fingerprinting'' framework designed to move beyond traditional
evaluation by creating a multi-faceted profile of a model's intrinsic cognitive
and interactive styles. Using a curated \textit{Diagnostic Prompt Suite} and an
innovative, automated evaluation pipeline where a powerful LLM acts as an
impartial judge, we analyze eighteen models across capability tiers. Our
results reveal a critical divergence in the LLM landscape: while core
capabilities like abstract and causal reasoning are converging among top
models, alignment-related behaviors such as sycophancy and semantic robustness
vary dramatically. We further document a cross-model default persona clustering
(ISTJ/ESTJ) that likely reflects common alignment incentives. Taken together,
this suggests that a model's interactive nature is not an emergent property of
its scale or reasoning power, but a direct consequence of specific, and highly
variable, developer alignment strategies. Our framework provides a reproducible
and scalable methodology for uncovering these deep behavioral differences.
Project: https://github.com/JarvisPei/Behavioral-Fingerprinting

</details>


### [92] [From Silent Signals to Natural Language: A Dual-Stage Transformer-LLM Approach](https://arxiv.org/abs/2509.04507)
*Nithyashree Sivasubramaniam*

Main category: cs.CL

TL;DR: Silent Speech Interfaces (SSIs) can generate speech from non-acoustic signals, but the synthesized speech often has phonetic ambiguity and noise. This paper proposes an enhanced ASR framework combining a transformer-based acoustic model and an LLM for post-processing to improve intelligibility. The proposed framework achieved a 16% relative and 6% absolute reduction in WER over a 36% baseline.


<details>
  <summary>Details</summary>
Motivation: Existing work on SSIs has focused on speech generation, with limited attention to recognition and processing of synthesized speech, which suffers from phonetic ambiguity and noise.

Method: The proposed framework combines a transformer-based acoustic model to capture full utterance context with a large language model (LLM) for linguistic consistency during post-processing.

Result: The experimental results show a 16% relative and 6% absolute reduction in word error rate (WER) over a 36% baseline.

Conclusion: The enhanced ASR framework significantly improves the intelligibility of synthesized speech from SSIs by combining acoustic modeling with LLM-based post-processing.

Abstract: Silent Speech Interfaces (SSIs) have gained attention for their ability to
generate intelligible speech from non-acoustic signals. While significant
progress has been made in advancing speech generation pipelines, limited work
has addressed the recognition and downstream processing of synthesized speech,
which often suffers from phonetic ambiguity and noise. To overcome these
challenges, we propose an enhanced automatic speech recognition framework that
combines a transformer-based acoustic model with a large language model (LLM)
for post-processing. The transformer captures full utterance context, while the
LLM ensures linguistic consistency. Experimental results show a 16% relative
and 6% absolute reduction in word error rate (WER) over a 36% baseline,
demonstrating substantial improvements in intelligibility for silent speech
interfaces.

</details>


### [93] [ProST: Progressive Sub-task Training for Pareto-Optimal Multi-agent Systems Using Small Language Models](https://arxiv.org/abs/2509.04508)
*Biddut Sarker Bijoy,Mohammad Saqib Hasan,Pegah Alipoormolabashi,Avirup Sil,Aruna Balasubramanian,Niranjan Balasubramanian*

Main category: cs.CL

TL;DR: 小型语言模型（SLMs）驱动的多智能体系统是解决复杂问题的可行方案，但存在长期学习困难。提出了一种渐进式子任务训练策略，并结合帕累托分析，证明了微调后的多智能体系统在有效性和效率之间取得了更好的平衡。


<details>
  <summary>Details</summary>
Motivation: 在复杂问题解决中，比较单一大型语言模型（LLMs）系统与多智能体小型语言模型（SLMs）系统的有效性和效率。

Method: 在AppWorld环境中，使用不同尺寸的语言模型实例化单一和多智能体系统。提出了一种渐进式子任务训练策略，逐步引入新子任务，并进行了帕累托分析、模型削减和误差分析。

Result: SLMs在长期学习中存在困难，即使经过专门角色训练，也无法有效学习所有子任务。渐进式子任务训练策略显著提高了多智能体系统的有效性。微调后的多智能体系统在有效性-效率权衡方面表现更优。分析强调了渐进式训练策略的重要性及其降低子任务错误率的能力。

Conclusion: 渐进式子任务训练策略有效解决了SLMs在多智能体系统中的长期学习瓶颈，使得微调后的多智能体系统在解决复杂问题时，比单一LLM系统具有更好的有效性-效率权衡。

Abstract: Multi-agent systems with smaller language models (SLMs) present a viable
alternative to single agent systems powered by large language models (LLMs) for
addressing complex problems. In this work, we study how these alternatives
compare in terms of both effectiveness and efficiency. To study this trade-off,
we instantiate single and multi-agent systems for the complex problems in the
AppWorld environment using different sized language models.
  We find that difficulties with long-trajectory learning in smaller language
models (SLMs) limit their performance. Even when trained for specialized roles,
SLMs fail to learn all subtasks effectively. To address this issue, we
introduce a simple progressive sub-task training strategy, which introduces new
sub-tasks progressively in each training epoch. We find that this novel
strategy, analogous to instance level curriculum learning, consistently
improves the effectiveness of multi-agents at all configurations. Our Pareto
analysis shows that fine-tuned multi-agent systems yield better
effectiveness-efficiency trade-offs. Additional ablations and analyses shows
the importance of our progressive training strategy and its ability to reduce
subtask error rates.

</details>


### [94] [Combine Virtual Reality and Machine-Learning to Identify the Presence of Dyslexia: A Cross-Linguistic Approach](https://arxiv.org/abs/2509.04510)
*Michele Materazzini,Gianluca Morciano,Jose Manuel Alcalde-Llergo,Enrique Yeguas-Bolivar,Giuseppe Calabro,Andrea Zingoni,Juri Taborri*

Main category: cs.CL

TL;DR: 该研究利用VR和AI技术，结合阅读测试和自尊评估，在意大利和西班牙大学生中预测和识别阅读障碍。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索虚拟现实（VR）和人工智能（AI）在预测大学生阅读障碍方面的应用，特别是利用VR数据和机器学习算法区分阅读障碍者和非阅读障碍者。

Method: 通过VR进行沉默阅读（SR）测试和自尊评估，并使用机器学习（ML）算法分析数据，以区分阅读障碍者和非阅读障碍者。初步统计分析（t检验和Mann Whitney检验）用于比较两组得分的差异，随后训练和测试了监督ML模型。

Result: VR-SR测试的完成时间在阅读障碍者和非阅读障碍者之间存在显著差异，但准确性和自尊评分无显著差异。机器学习模型在意大利学生中分类准确率为87.5%，在西班牙学生中为66.6%，在混合组中为75.0%。

Conclusion: VR和ML可以作为评估阅读障碍的辅助工具，尤其是在识别任务完成速度差异方面，但语言特异性因素可能会影响分类准确性。

Abstract: This study explores the use of virtual reality (VR) and artificial
intelligence (AI) to predict the presence of dyslexia in Italian and Spanish
university students. In particular, the research investigates whether
VR-derived data from Silent Reading (SR) tests and self-esteem assessments can
differentiate between students that are affected by dyslexia and students that
are not, employing machine learning (ML) algorithms. Participants completed
VR-based tasks measuring reading performance and self-esteem. A preliminary
statistical analysis (t tests and Mann Whitney tests) on these data was
performed, to compare the obtained scores between individuals with and without
dyslexia, revealing significant differences in completion time for the SR test,
but not in accuracy, nor in self esteem. Then, supervised ML models were
trained and tested, demonstrating an ability to classify the presence/absence
of dyslexia with an accuracy of 87.5 per cent for Italian, 66.6 per cent for
Spanish, and 75.0 per cent for the pooled group. These findings suggest that VR
and ML can effectively be used as supporting tools for assessing dyslexia,
particularly by capturing differences in task completion speed, but
language-specific factors may influence classification accuracy.

</details>


### [95] [Scaling behavior of large language models in emotional safety classification across sizes and tasks](https://arxiv.org/abs/2509.04512)
*Edoardo Pinzuti,Oliver Tüscher,André Ferreira Castro*

Main category: cs.CL

TL;DR: 大型语言模型（LLMs）在处理情感敏感内容方面的能力对于构建安全可靠的系统至关重要，尤其是在心理健康领域。本研究通过构建包含15K+样本的新数据集，并利用ChatGPT生成的提示进行数据增强，调查了LLMs在情感安全三分类和六分类安全风险分类任务上的扩展行为。研究评估了不同规模的LLaMA模型（1B至70B）在零样本、少样本和微调设置下的表现。结果表明，模型规模越大，平均性能越好，尤其在多标签分类和零样本场景下。然而，轻量级微调使得1B模型在数据量大的类别上能达到与更大模型和BERT相当的性能，且推理时VRAM需求低于2GB。这表明小型、可部署在设备上的模型是满足隐私需求、具备情感理解和安全对话界限能力的可用替代方案。


<details>
  <summary>Details</summary>
Motivation: 为了理解大型语言模型（LLMs）在处理情感敏感内容方面的能力，特别是在心理健康应用中，需要评估它们在相关任务上的表现和扩展行为。

Method: 构建了一个包含超过15,000个样本的新数据集，该数据集通过合并现有的人工撰写心理健康数据集，并使用ChatGPT生成的提示进行增强。评估了四种不同规模（1B、3B、8B、70B）的LLaMA模型在零样本、少样本和微调设置下的表现，分别进行情感安全三分类（安全/不安全/边界）和六类别安全风险的十类分类任务。

Result: 研究结果显示，更大的LLMs在平均性能上表现更优，尤其在细致的多标签分类和零样本设置中。然而，通过轻量级微调，1B模型在若干高数据类别中取得了与更大模型和BERT相当的性能，且推理时仅需不到2GB的VRAM。

Conclusion: 小型、可部署在设备上的模型可以作为满足隐私需求的、能够理解情感背景并维持安全对话边界的有效替代方案。这项工作对治疗性LLM应用和关键安全系统的可扩展对齐具有重要启示。

Abstract: Understanding how large language models (LLMs) process emotionally sensitive
content is critical for building safe and reliable systems, particularly in
mental health contexts. We investigate the scaling behavior of LLMs on two key
tasks: trinary classification of emotional safety (safe vs. unsafe vs.
borderline) and multi-label classification using a six-category safety risk
taxonomy. To support this, we construct a novel dataset by merging several
human-authored mental health datasets (> 15K samples) and augmenting them with
emotion re-interpretation prompts generated via ChatGPT. We evaluate four LLaMA
models (1B, 3B, 8B, 70B) across zero-shot, few-shot, and fine-tuning settings.
Our results show that larger LLMs achieve stronger average performance,
particularly in nuanced multi-label classification and in zero-shot settings.
However, lightweight fine-tuning allowed the 1B model to achieve performance
comparable to larger models and BERT in several high-data categories, while
requiring <2GB VRAM at inference. These findings suggest that smaller,
on-device models can serve as viable, privacy-preserving alternatives for
sensitive applications, offering the ability to interpret emotional context and
maintain safe conversational boundaries. This work highlights key implications
for therapeutic LLM applications and the scalable alignment of safety-critical
systems.

</details>


### [96] [Mitigation of Gender and Ethnicity Bias in AI-Generated Stories through Model Explanations](https://arxiv.org/abs/2509.04515)
*Martha O. Dimgba,Sharon Oba,Ameeta Agrawal,Philippe J. Giabbanelli*

Main category: cs.CL

TL;DR: 本研究提出了一种名为BAME的策略，通过分析和利用大语言模型自身生成的解释，来优化提示工程，从而减少AI生成内容中的性别和种族偏见，提高了不同人群在职业故事中的代表性。


<details>
  <summary>Details</summary>
Motivation: AI生成内容中存在的社会偏见，特别是在性别和种族方面，会影响其公平性和可靠性。

Method: 提出并应用了一种名为BAME（Bias Analysis and Mitigation through Explanation）的策略。该策略利用大语言模型自身生成的解释来指导提示工程，从而在不修改模型参数的情况下，有针对性地减少性别和种族偏见。通过在25个职业类别、3种大语言模型（Claude 3.5 Sonnet, Llama 3.1 70B Instruct, and GPT-4 Turbo）上进行实验，测量偏见修复前后的差异。

Result: BAME策略在改善人口统计学代表性方面取得了显著成效，改善幅度在2%到20%之间。研究发现了与训练数据刻板印象相关的持续性的过度代表和代表不足的模式。

Conclusion: 通过引导大语言模型利用其内部推理机制，可以显著提高人口统计学上的公平性，有助于开发更透明、更公平的生成式AI系统。

Abstract: Language models have been shown to propagate social bias through their
output, particularly in the representation of gender and ethnicity. This paper
investigates gender and ethnicity biases in AI-generated occupational stories.
Representation biases are measured before and after applying our proposed
mitigation strategy, Bias Analysis and Mitigation through Explanation (BAME),
revealing improvements in demographic representation ranging from 2% to 20%.
BAME leverages model-generated explanations to inform targeted prompt
engineering, effectively reducing biases without modifying model parameters. By
analyzing stories generated across 25 occupational groups, three large language
models (Claude 3.5 Sonnet, Llama 3.1 70B Instruct, and GPT-4 Turbo), and
multiple demographic dimensions, we identify persistent patterns of
overrepresentation and underrepresentation linked to training data stereotypes.
Our findings demonstrate that guiding models with their own internal reasoning
mechanisms can significantly enhance demographic parity, thereby contributing
to the development of more transparent generative AI systems.

</details>


### [97] [Artificially Fluent: Swahili AI Performance Benchmarks Between English-Trained and Natively-Trained Datasets](https://arxiv.org/abs/2509.04516)
*Sophie Jaffer,Simeon Sayer*

Main category: cs.CL

TL;DR: 英语在LLM训练数据中占主导地位，可能导致非英语模型表现不佳。本研究比较了斯瓦希里语和英语的BERT模型，发现即使经过高质量翻译，斯瓦希里语模型在斯瓦希里语数据上的表现也优于在翻译成英语后使用英语模型评估的表现，错误率几乎低四倍。这表明翻译不能弥补语言间的差异，原生语言训练对于模型的准确性仍然至关重要。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLM）在不同语言之间表现的公平性，特别是英语在训练数据中的主导地位可能对非英语用户产生不利影响。

Method: 比较了两个单语BERT模型：一个仅在斯瓦希里语数据上训练和测试，另一个在可比的英语新闻数据上训练和测试。为了模拟多语言LLM的内部翻译和抽象过程，将斯瓦希里语新闻数据翻译成英语，并使用英语模型进行评估，以比较原生语言模型与跨语言翻译评估的性能差异。

Result: 在斯瓦希里语上训练的原生模型错误率为0.36%，而将斯瓦希里语翻译成英语后用英语模型评估的错误率为1.47%，前者错误率几乎低四倍。

Conclusion: 即使经过高质量翻译，原生语言训练的模型在处理原生语言数据时表现也优于处理翻译后数据的模型。这表明翻译本身并不能完全弥合语言间的表示差异，并且模型在处理翻译输入时可能会因为不完善的内部知识表示而遇到困难。因此，原生语言训练对于获得可靠结果仍然很重要。为了减少AI部署对数字鸿沟的加剧作用，未来的研究需要关注欠代表性语言的数据集开发和多语言模型评估。

Abstract: As large language models (LLMs) expand multilingual capabilities, questions
remain about the equity of their performance across languages. While many
communities stand to benefit from AI systems, the dominance of English in
training data risks disadvantaging non-English speakers. To test the hypothesis
that such data disparities may affect model performance, this study compares
two monolingual BERT models: one trained and tested entirely on Swahili data,
and another on comparable English news data. To simulate how multilingual LLMs
process non-English queries through internal translation and abstraction, we
translated the Swahili news data into English and evaluated it using the
English-trained model. This approach tests the hypothesis by evaluating whether
translating Swahili inputs for evaluation on an English model yields better or
worse performance compared to training and testing a model entirely in Swahili,
thus isolating the effect of language consistency versus cross-lingual
abstraction. The results prove that, despite high-quality translation, the
native Swahili-trained model performed better than the Swahili-to-English
translated model, producing nearly four times fewer errors: 0.36% vs. 1.47%
respectively. This gap suggests that translation alone does not bridge
representational differences between languages and that models trained in one
language may struggle to accurately interpret translated inputs due to
imperfect internal knowledge representation, suggesting that native-language
training remains important for reliable outcomes. In educational and
informational contexts, even small performance gaps may compound inequality.
Future research should focus on addressing broader dataset development for
underrepresented languages and renewed attention to multilingual model
evaluation, ensuring the reinforcing effect of global AI deployment on existing
digital divides is reduced.

</details>


### [98] [Analysis of Voluntarily Reported Data Post Mesh Implantation for Detecting Public Emotion and Identifying Concern Reports](https://arxiv.org/abs/2509.04517)
*Indu Bala,Lewis Mitchell,Marianne H Gillam*

Main category: cs.CL

TL;DR: 本研究利用自然语言处理技术分析了MAUDE数据库中2000-2021年的患者报告，以研究疝气修补术后网片植入的情感影响。


<details>
  <summary>Details</summary>
Motivation: 为了深入了解疝气修补术后网片植入患者的情感体验，并识别与医疗器械监管和技术进步相关的患者情绪变化模式。

Method: 研究使用NRC情感词典和TextBlob对MAUDE数据库中的患者报告进行情感分析，将其分为八种基本情绪，并评估情感极性，同时识别“关注报告”。

Result: 研究发现，“关注报告”在2011-2012年和2017-2018年期间有所增加，并且在此期间患者的情感强度也更高。

Conclusion: 通过对关注报告和整体情感进行时间分析，本研究为医疗从业者提供了宝贵的见解，有助于改善术前咨询、术后护理，并强调了情感因素在医疗实践中的重要性。

Abstract: Mesh implants are widely utilized in hernia repair surgeries, but
postoperative complications present a significant concern. This study analyzes
patient reports from the Manufacturer and User Facility Device Experience
(MAUDE) database spanning 2000 to 2021 to investigate the emotional aspects of
patients following mesh implantation using Natural Language Processing (NLP).
Employing the National Research Council Canada (NRC) Emotion Lexicon and
TextBlob for sentiment analysis, the research categorizes patient narratives
into eight emotions (anger, fear, anticipation, trust, surprise, sadness, joy,
and disgust) and assesses sentiment polarity. The goal is to discern patterns
in patient sentiment over time and to identify reports signaling urgent
concerns, referred to as "Concern Reports," thereby understanding shifts in
patient experiences in relation to changes in medical device regulation and
technological advancements in healthcare. The study detected an increase in
Concern Reports and higher emotional intensity during the periods of 2011-2012
and 2017-2018. Through temporal analysis of Concern Reports and overall
sentiment, this research provides valuable insights for healthcare
practitioners, enhancing their understanding of patient experiences
post-surgery, which is critical for improving preoperative counselling,
postoperative care, and preparing patients for mesh implant surgeries. The
study underscores the importance of emotional considerations in medical
practices and the potential for sentiment analysis to inform and enhance
patient care.

</details>


### [99] [Advancing SLM Tool-Use Capability using Reinforcement Learning](https://arxiv.org/abs/2509.04518)
*Dhruvi Paprunia,Vansh Kharidia,Pankti Doshi*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large Language Models (LLMs) have progressed beyond simple text creation, and
tool use has become increasingly important for complex, real-world tasks. Tool
use in LLMs refers to their ability to utilize external resources such as APIs,
databases, or software functions to extend their functionality beyond
generating text.Tools are used for tasks such as performing calculations,
making API calls to retrieve the current time and date, and more. This
capability enables models to fetch real-time data, execute commands, or solve
problems requiring dynamic interaction, making it indispensable for
applications like AI agents in virtual assistants, robotic control, or
automated workflows.
  However, while LLMs are usually adept tool use, their vast resource
requirements and computation complexity restrict their use in every use case.As
a result, there is an increasing need for more compact and efficient Small
Language Models (SLMs). Small language models (SLMs) struggle in tool use
compared to large language models (LLMs). As soon in Table 1. SLMs are
typically trained on smaller, more specific datasets, resulting in a narrower
knowledge base and limited contextual understanding compared to LLMs.
  This research addresses these challenges by using Reinforcement Learning
(RL), specifically Group Relative Policy Optimization (GRPO), to enhance
tool-use proficiency in SLMs. Unlike conventional fine-tuning approaches that
require heavy computation and often lack adaptability, our method provides an
efficient, effective solution that significantly boosts SLM tool-use accuracy,
increasing their practical utility.

</details>


### [100] [Hierarchical Section Matching Prediction (HSMP) BERT for Fine-Grained Extraction of Structured Data from Hebrew Free-Text Radiology Reports in Crohn's Disease](https://arxiv.org/abs/2509.04519)
*Zvi Badash,Hadas Ben-Atya,Naama Gavrielov,Liam Hazan,Gili Focht,Ruth Cytter-Kuint,Talar Hagopian,Dan Turner,Moti Freiman*

Main category: cs.CL

TL;DR: 开发了一种名为HSMP-BERT的基于提示的模型，用于从希伯来语放射学文本中提取结构化临床信息，特别关注克罗恩病的多器官病变，并在低资源语言环境中表现出优越性，同时提高了效率。


<details>
  <summary>Details</summary>
Motivation: 从放射学报告中提取结构化临床信息，尤其是在克罗恩病等低资源语言和多器官病变的情况下，具有挑战性。

Method: 开发并评估了一种名为HSMP-BERT的基于提示的模型，用于从希伯来语放射学文本中提取克罗恩病的病变信息。模型在9,683份报告上进行训练和测试，其中512份报告由放射科医生进行了标注，涵盖了六个胃肠器官和15种病理。

Result: HSMP-BERT在24个器官-病变组合上取得了平均F1分数0.83±0.08和kappa系数0.65±0.17，显著优于SMP零样本基线（F1 0.49±0.07, kappa 0.06±0.07）和标准微调（F1 0.30±0.27, kappa 0.27±0.34）。此外，该模型将运行时间缩短了5.1倍，并揭示了与克罗恩病相关的病变和趋势。

Conclusion: HSMP-BERT为放射学中的结构化提取提供了一个可扩展的解决方案，能够对克罗恩病进行人群水平的分析，并展示了人工智能在低资源环境中的潜力。

Abstract: Extracting structured clinical information from radiology reports is
challenging, especially in low-resource languages. This is pronounced in
Crohn's disease, with sparsely represented multi-organ findings. We developed
Hierarchical Structured Matching Prediction BERT (HSMP-BERT), a prompt-based
model for extraction from Hebrew radiology text. In an administrative database
study, we analyzed 9,683 reports from Crohn's patients imaged 2010-2023 across
Israeli providers. A subset of 512 reports was radiologist-annotated for
findings across six gastrointestinal organs and 15 pathologies, yielding 90
structured labels per subject. Multilabel-stratified split (66%
train+validation; 33% test), preserving label prevalence. Performance was
evaluated with accuracy, F1, Cohen's $\kappa$, AUC, PPV, NPV, and recall. On 24
organ-finding combinations with $>$15 positives, HSMP-BERT achieved mean F1
0.83$\pm$0.08 and $\kappa$ 0.65$\pm$0.17, outperforming the SMP zero-shot
baseline (F1 0.49$\pm$0.07, $\kappa$ 0.06$\pm$0.07) and standard fine-tuning
(F1 0.30$\pm$0.27, $\kappa$ 0.27$\pm$0.34; paired t-test $p < 10^{-7}$).
Hierarchical inference cuts runtime 5.1$\times$ vs. traditional inference.
Applied to all reports, it revealed associations among ileal wall thickening,
stenosis, and pre-stenotic dilatation, plus age- and sex-specific trends in
inflammatory findings. HSMP-BERT offers a scalable solution for structured
extraction in radiology, enabling population-level analysis of Crohn's disease
and demonstrating AI's potential in low-resource settings.

</details>


### [101] [Using LLMs to create analytical datasets: A case study of reconstructing the historical memory of Colombia](https://arxiv.org/abs/2509.04523)
*David Anderson,Galia Benitez,Margret Bjarnadottir,Shriyan Reyya*

Main category: cs.CL

TL;DR: 哥伦比亚政府利用大型语言模型（LLM）处理大量有关冲突的新闻文章，以填补历史空白并分析暴力与古柯作物根除之间的关系。


<details>
  <summary>Details</summary>
Motivation: 哥伦比亚长期遭受武装冲突，但对其进行系统性记录的努力来得太晚，导致缺乏公开的冲突信息和历史记录。

Method: 使用GPT（一种大型语言模型）阅读和回答有关200,000多篇西班牙语暴力相关报纸文章的问题，并利用生成的数据集进行描述性分析以及研究暴力与古柯作物根除之间的关系。

Result: 利用LLM分析大量文本语料库，为政策分析提供了新的研究机会，并证明了这种方法的有效性。

Conclusion: 大型语言模型（LLM）为以前无法实现的文本语料库的深入研究开辟了新的可能性，能够为哥伦比亚的历史记忆和政策分析做出贡献。

Abstract: Colombia has been submerged in decades of armed conflict, yet until recently,
the systematic documentation of violence was not a priority for the Colombian
government. This has resulted in a lack of publicly available conflict
information and, consequently, a lack of historical accounts. This study
contributes to Colombia's historical memory by utilizing GPT, a large language
model (LLM), to read and answer questions about over 200,000 violence-related
newspaper articles in Spanish. We use the resulting dataset to conduct both
descriptive analysis and a study of the relationship between violence and the
eradication of coca crops, offering an example of policy analyses that such
data can support. Our study demonstrates how LLMs have opened new research
opportunities by enabling examinations of large text corpora at a previously
infeasible depth.

</details>


### [102] [Quantized Large Language Models in Biomedical Natural Language Processing: Evaluation and Recommendation](https://arxiv.org/abs/2509.04534)
*Zaifu Zhan,Shuang Zhou,Min Zeng,Kai Yu,Meijia Song,Xiaoyi Chen,Jun Wang,Yu Hou,Rui Zhang*

Main category: cs.CL

TL;DR: 通过量化显著降低大型语言模型在生物医学领域的内存需求，同时保持其性能，从而实现安全、本地部署。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型（LLM）的规模和计算需求快速增长，以及医疗保健领域对数据隐私和资源限制的要求，阻碍了其在实际医疗环境中的应用。本研究旨在评估量化对LLM在生物医学领域应用的影响。

Method: 系统性地评估了量化对12种最先进的LLM（包括通用型和生物医学特定型模型）在8个基准数据集上的影响，涵盖了命名实体识别、关系抽取、多标签分类和问答四个关键任务。

Result: 量化技术可将GPU内存需求最多降低75%，同时在多项任务中保持了模型性能。这使得拥有700亿参数的模型能够部署在40GB的消费级GPU上。此外，模型领域特定知识和对高级提示的响应能力也得到了很大程度的保留。

Conclusion: 量化是一种实用且有效的策略，能够实现大型、高容量的语言模型在生物医学领域的安全、本地部署，解决了AI技术进步与实际临床应用之间的差距。

Abstract: Large language models have demonstrated remarkable capabilities in biomedical
natural language processing, yet their rapid growth in size and computational
requirements present a major barrier to adoption in healthcare settings where
data privacy precludes cloud deployment and resources are limited. In this
study, we systematically evaluated the impact of quantization on 12
state-of-the-art large language models, including both general-purpose and
biomedical-specific models, across eight benchmark datasets covering four key
tasks: named entity recognition, relation extraction, multi-label
classification, and question answering. We show that quantization substantially
reduces GPU memory requirements-by up to 75%-while preserving model performance
across diverse tasks, enabling the deployment of 70B-parameter models on 40GB
consumer-grade GPUs. In addition, domain-specific knowledge and responsiveness
to advanced prompting methods are largely maintained. These findings provide
significant practical and guiding value, highlighting quantization as a
practical and effective strategy for enabling the secure, local deployment of
large yet high-capacity language models in biomedical contexts, bridging the
gap between technical advances in AI and real-world clinical translation.

</details>


### [103] [Manipulating Transformer-Based Models: Controllability, Steerability, and Robust Interventions](https://arxiv.org/abs/2509.04549)
*Faruk Alpay,Taylan Alpay*

Main category: cs.CL

TL;DR: Transformer 模型在 NLP 任务中表现优异，但精细控制仍具挑战。本文提出了三种控制方法：提示、激活和权重，并将可控文本生成形式化为优化问题。通过统一框架，在情感控制和事实编辑方面取得了 >90% 的成功率，同时保留了基本性能。此外，还分析了模型的鲁棒性、安全性及伦理风险。


<details>
  <summary>Details</summary>
Motivation: Transformer 模型在 NLP 任务中表现优异，但精细控制仍具挑战。本研究旨在探索控制 Transformer 模型的方法，实现对模型行为的精细调控。

Method: 本文提出了一种统一的框架，结合了提示工程、参数高效微调、模型编辑和强化学习，实现了对 Transformer 模型在提示、激活和权重三个层面的干预，将可控文本生成形式化为可解决的优化问题。

Result: 实验证明，该方法在情感控制和事实编辑方面取得了超过 90% 的成功率，同时保持了模型的基线性能。此外，研究还分析了模型的鲁棒性、安全性（包括对抗性攻击和对齐缓解措施）以及泛化与特异性之间的权衡。

Conclusion: 本研究为设计可控且鲁棒的语言模型奠定了基础，强调了对模型进行严格评估和考虑伦理双重用途风险的必要性。

Abstract: Transformer-based language models excel in NLP tasks, but fine-grained
control remains challenging. This paper explores methods for manipulating
transformer models through principled interventions at three levels: prompts,
activations, and weights. We formalize controllable text generation as an
optimization problem addressable via prompt engineering, parameter-efficient
fine-tuning, model editing, and reinforcement learning. We introduce a unified
framework encompassing prompt-level steering, activation interventions, and
weight-space edits. We analyze robustness and safety implications, including
adversarial attacks and alignment mitigations. Theoretically, we show minimal
weight updates can achieve targeted behavior changes with limited side-effects.
Empirically, we demonstrate >90% success in sentiment control and factual edits
while preserving base performance, though generalization-specificity trade-offs
exist. We discuss ethical dual-use risks and the need for rigorous evaluation.
This work lays groundwork for designing controllable and robust language
models.

</details>


### [104] [Spoken in Jest, Detected in Earnest: A Systematic Review of Sarcasm Recognition -- Multimodal Fusion, Challenges, and Future Prospects](https://arxiv.org/abs/2509.04605)
*Xiyuan Gao,Shekhar Nayak,Matt Coler*

Main category: cs.CL

TL;DR: 这项系统性综述首次专注于基于语音的讽刺识别，概述了从单模态到多模态方法的演变，并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 讽刺在人际交往和人机交互中普遍存在且难以识别，特别是在有神经退行性疾病的个体以及机器理解复杂人类语言方面。因此，利用语音数据进行自动讽刺识别具有重要意义。

Method: 本综述系统地回顾了关于语音讽刺识别的研究，涵盖了数据集、特征提取和分类方法，从单模态方法演变到多模态融合技术。

Result: 研究发现，现有的语音讽刺识别数据集存在局限性；特征提取技术已从传统的声学特征发展到基于深度学习的表示；分类方法已从单模态方法发展到多模态融合技术。

Conclusion: 未来的研究应加强跨文化和多语言的讽刺识别，并应将讽刺视为一种多模态现象来处理，而不是仅仅基于文本的挑战。

Abstract: Sarcasm, a common feature of human communication, poses challenges in
interpersonal interactions and human-machine interactions. Linguistic research
has highlighted the importance of prosodic cues, such as variations in pitch,
speaking rate, and intonation, in conveying sarcastic intent. Although previous
work has focused on text-based sarcasm detection, the role of speech data in
recognizing sarcasm has been underexplored. Recent advancements in speech
technology emphasize the growing importance of leveraging speech data for
automatic sarcasm recognition, which can enhance social interactions for
individuals with neurodegenerative conditions and improve machine understanding
of complex human language use, leading to more nuanced interactions. This
systematic review is the first to focus on speech-based sarcasm recognition,
charting the evolution from unimodal to multimodal approaches. It covers
datasets, feature extraction, and classification methods, and aims to bridge
gaps across diverse research domains. The findings include limitations in
datasets for sarcasm recognition in speech, the evolution of feature extraction
techniques from traditional acoustic features to deep learning-based
representations, and the progression of classification methods from unimodal
approaches to multimodal fusion techniques. In so doing, we identify the need
for greater emphasis on cross-cultural and multilingual sarcasm recognition, as
well as the importance of addressing sarcasm as a multimodal phenomenon, rather
than a text-based challenge.

</details>


### [105] [Sample-efficient Integration of New Modalities into Large Language Models](https://arxiv.org/abs/2509.04606)
*Osman Batur İnce,André F. T. Martins,Oisin Mac Aodha,Edoardo M. Ponti*

Main category: cs.CL

TL;DR: SEMI是一种样本高效的模态集成方法，通过超网络适应共享投影仪，能够以少量样本将新模态（如卫星图像、天文图像、惯性测量和分子）集成到大型语言模型中，显著提高样本效率。


<details>
  <summary>Details</summary>
Motivation: 现有的基础上模型在处理多种模态时面临训练成本高、模态数据稀疏且集成困难的问题。本研究旨在提出一种更高效、更灵活的模态集成方法。

Method: 提出一种名为SEMI（Sample-Efficient Modality Integration）的方法，使用一个超网络来适配一个共享投影仪。该投影仪位于特定模态编码器和大型语言模型之间。超网络在多模态数据上进行训练，并在推理时根据少量目标模态样本生成适配器，以适应任意新模态。为了增加训练模态的多样性，通过等距变换人为地增加了编码器的数量。

Result: SEMI在少样本集成新模态（如卫星图像、天文图像、惯性测量和分子）方面，实现了显著的样本效率提升，即使在嵌入维度任意的编码器上也是如此。例如，为了达到与32样本SEMI相同的准确率，从头开始训练投影仪需要64倍的数据。

Conclusion: SEMI在扩展基础模型的模态覆盖范围方面显示出巨大潜力，能够以更少的样本高效地集成各种新模态。

Abstract: Multimodal foundation models can process several modalities. However, since
the space of possible modalities is large and evolving over time, training a
model from scratch to encompass all modalities is unfeasible. Moreover,
integrating a modality into a pre-existing foundation model currently requires
a significant amount of paired data, which is often not available for
low-resource modalities. In this paper, we introduce a method for
sample-efficient modality integration (SEMI) into Large Language Models (LLMs).
To this end, we devise a hypernetwork that can adapt a shared projector --
placed between modality-specific encoders and an LLM -- to any modality. The
hypernetwork, trained on high-resource modalities (i.e., text, speech, audio,
video), is conditioned on a few samples from any arbitrary modality at
inference time to generate a suitable adapter. To increase the diversity of
training modalities, we artificially multiply the number of encoders through
isometric transformations. We find that SEMI achieves a significant boost in
sample efficiency during few-shot integration of new modalities (i.e.,
satellite images, astronomical images, inertial measurements, and molecules)
with encoders of arbitrary embedding dimensionality. For instance, to reach the
same accuracy as 32-shot SEMI, training the projector from scratch needs
64$\times$ more data. As a result, SEMI holds promise to extend the modality
coverage of foundation models.

</details>


### [106] [Breaking to Build: A Threat Model of Prompt-Based Attacks for Securing LLMs](https://arxiv.org/abs/2509.04615)
*Brennen Hill,Surendra Parla,Venkata Abhijeeth Balabhadruni,Atharv Prajod Padmalayam,Sujay Chandra Shekara Sharma*

Main category: cs.CL

TL;DR: LLM提示词攻击日益增多，对模型的安全性和可信度构成了严重威胁。本文对现有的提示词攻击方法进行了全面的文献综述，旨在为开发更安全的LLM提供指导。


<details>
  <summary>Details</summary>
Motivation: LLM的广泛应用带来了严峻的安全挑战，攻击者可以通过操纵输入提示词来造成损害和规避安全对齐。理解这些攻击向量是开发有效防御措施的基础。

Method: 对现有的提示词攻击方法进行全面的文献综述，并进行分类，以提供清晰的威胁模型。

Result: 详细阐述了这些攻击的机制和影响。

Conclusion: 本综述旨在为研究社区构建下一代安全LLM提供信息，使其能够抵御未经授权的蒸馏、微调和编辑。

Abstract: The proliferation of Large Language Models (LLMs) has introduced critical
security challenges, where adversarial actors can manipulate input prompts to
cause significant harm and circumvent safety alignments. These prompt-based
attacks exploit vulnerabilities in a model's design, training, and contextual
understanding, leading to intellectual property theft, misinformation
generation, and erosion of user trust. A systematic understanding of these
attack vectors is the foundational step toward developing robust
countermeasures. This paper presents a comprehensive literature survey of
prompt-based attack methodologies, categorizing them to provide a clear threat
model. By detailing the mechanisms and impacts of these exploits, this survey
aims to inform the research community's efforts in building the next generation
of secure LLMs that are inherently resistant to unauthorized distillation,
fine-tuning, and editing.

</details>


### [107] [Comparative Analysis of Transformer Models in Disaster Tweet Classification for Public Safety](https://arxiv.org/abs/2509.04650)
*Sharif Noor Zisad,Ragib Hasan*

Main category: cs.CL

TL;DR: Transformer 模型在灾难推文分类任务上显著优于传统机器学习模型。


<details>
  <summary>Details</summary>
Motivation: 为了更快速有效地响应灾难事件，需要自动对包含灾难信息的推文进行分类。传统机器学习模型在理解非正式、隐喻或模糊的语言方面存在局限性。

Method: 评估了包括BERT、DistilBERT、RoBERTa和DeBERTa在内的Transformer模型在灾难推文分类任务上的表现，并与Logistic回归、朴素贝叶斯等传统机器学习模型进行了比较。

Result: BERT模型取得了最高的准确率（91%），显著优于准确率同为82%的Logistic回归和朴素贝叶斯模型。Transformer模型的上下文嵌入和注意力机制使其能够更好地理解细微的语言差别。

Conclusion: Transformer模型在准确性、语言理解深度和泛化能力方面均优于传统模型，更适合公共安全领域的应用。

Abstract: Twitter and other social media platforms have become vital sources of real
time information during disasters and public safety emergencies. Automatically
classifying disaster related tweets can help emergency services respond faster
and more effectively. Traditional Machine Learning (ML) models such as Logistic
Regression, Naive Bayes, and Support Vector Machines have been widely used for
this task, but they often fail to understand the context or deeper meaning of
words, especially when the language is informal, metaphorical, or ambiguous. We
posit that, in this context, transformer based models can perform better than
traditional ML models. In this paper, we evaluate the effectiveness of
transformer based models, including BERT, DistilBERT, RoBERTa, and DeBERTa, for
classifying disaster related tweets. These models are compared with traditional
ML approaches to highlight the performance gap. Experimental results show that
BERT achieved the highest accuracy (91%), significantly outperforming
traditional models like Logistic Regression and Naive Bayes (both at 82%). The
use of contextual embeddings and attention mechanisms allows transformer models
to better understand subtle language in tweets, where traditional ML models
fall short. This research demonstrates that transformer architectures are far
more suitable for public safety applications, offering improved accuracy,
deeper language understanding, and better generalization across real world
social media text.

</details>


### [108] [Polysemantic Dropout: Conformal OOD Detection for Specialized LLMs](https://arxiv.org/abs/2509.04655)
*Ayush Gupta,Ramneet Kaur,Anirban Roy,Adam D. Cobb,Rama Chellappa,Susmit Jha*

Main category: cs.CL

TL;DR: 该研究提出了一种新颖的推理时域外（OOD）检测算法，用于专业化的大型语言模型（LLMs）。


<details>
  <summary>Details</summary>
Motivation: 专业化LLMs在领域内任务上表现优异，但在面对域外输入时，可能产生不正确或不可靠的输出，这在关键应用中存在风险。

Method: 该方法利用归纳式保距异常检测（ICAD）框架，并结合一种基于模型Dropout容忍度的新型非一致性度量。该方法假设领域内输入比域外输入具有更高的Dropout容忍度，并通过有效的集成方法跨多层聚合Dropout容忍度。

Result: 在医学领域专业化LLMs的实验中，该方法在检测域外输入方面优于基线方法，AUROC提高了2%至37%。

Conclusion: 该研究提出了一种有效且具有理论保障的OOD检测方法，能够提高专业化LLMs在面对域外输入时的可靠性。

Abstract: We propose a novel inference-time out-of-domain (OOD) detection algorithm for
specialized large language models (LLMs). Despite achieving state-of-the-art
performance on in-domain tasks through fine-tuning, specialized LLMs remain
vulnerable to incorrect or unreliable outputs when presented with OOD inputs,
posing risks in critical applications. Our method leverages the Inductive
Conformal Anomaly Detection (ICAD) framework, using a new non-conformity
measure based on the model's dropout tolerance. Motivated by recent findings on
polysemanticity and redundancy in LLMs, we hypothesize that in-domain inputs
exhibit higher dropout tolerance than OOD inputs. We aggregate dropout
tolerance across multiple layers via a valid ensemble approach, improving
detection while maintaining theoretical false alarm bounds from ICAD.
Experiments with medical-specialized LLMs show that our approach detects OOD
inputs better than baseline methods, with AUROC improvements of $2\%$ to $37\%$
when treating OOD datapoints as positives and in-domain test datapoints as
negatives.

</details>


### [109] [AraHalluEval: A Fine-grained Hallucination Evaluation Framework for Arabic LLMs](https://arxiv.org/abs/2509.04656)
*Aisha Alansari,Hamzah Luqman*

Main category: cs.CL

TL;DR: 该研究首次全面评估了阿拉伯语和多语言大型语言模型（LLM）在阿拉伯语生成问答和摘要任务中的幻觉问题，并提出了一个包含12个指标的细粒度评估框架。结果显示，事实性幻觉比忠实性错误更普遍，而阿拉伯语预训练模型Allam表现优于多语言模型。


<details>
  <summary>Details</summary>
Motivation: 鉴于阿拉伯语的广泛使用及其在国际交流和媒体中的重要性，而现有关于大型语言模型（LLM）幻觉的研究主要集中在英语，对阿拉伯语LLM的幻觉评估相对不足，存在知识缺口。

Method: 开发了一个包含12个细粒度幻觉指标的评估框架，用于评估12个阿拉伯语和多语言LLM在生成问答和摘要任务中的幻觉问题，以衡量模型输出的事实一致性和忠实性。

Result: 在阿拉伯语生成问答和摘要任务中，事实性幻觉比忠实性错误更普遍。阿拉伯语预训练模型Allam的幻觉率低于多语言模型，并且与基于推理的模型相当。

Conclusion: 阿拉伯语预训练模型在幻觉评估方面表现出潜力，并且需要进一步研究以减少阿拉伯语LLM的幻觉。

Abstract: Recently, extensive research on the hallucination of the large language
models (LLMs) has mainly focused on the English language. Despite the growing
number of multilingual and Arabic-specific LLMs, evaluating LLMs' hallucination
in the Arabic context remains relatively underexplored. The knowledge gap is
particularly pressing given Arabic's widespread use across many regions and its
importance in global communication and media. This paper presents the first
comprehensive hallucination evaluation of Arabic and multilingual LLMs on two
critical Arabic natural language generation tasks: generative question
answering (GQA) and summarization. This study evaluates a total of 12 LLMs,
including 4 Arabic pre-trained models, 4 multilingual models, and 4
reasoning-based models. To assess the factual consistency and faithfulness of
LLMs' outputs, we developed a fine-grained hallucination evaluation framework
consisting of 12 fine-grained hallucination indicators that represent the
varying characteristics of each task. The results reveal that factual
hallucinations are more prevalent than faithfulness errors across all models
and tasks. Notably, the Arabic pre-trained model Allam consistently
demonstrates lower hallucination rates than multilingual models and a
comparative performance with reasoning-based models. The code is available at:
\href{https://github.com/aishaalansari57/AraHalluEval}{Github link}.

</details>


### [110] [Phonological Representation Learning for Isolated Signs Improves Out-of-Vocabulary Generalization](https://arxiv.org/abs/2509.04745)
*Lee Kezar,Zed Sehyr,Jesse Thomason*

Main category: cs.CL

TL;DR: 本研究通过引入参数解耦和语音学半监督学习来改进向量量化自编码器在孤立手语识别和未见手语重建方面的性能，证明了语言学上的归纳偏倚可以提升手语表征的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有手语数据集的词汇代表性不足，导致模型难以识别未见过的手语，因此需要开发能够泛化到未见手语的模型。向量化是学习离散表征的有效方法，但其学习单元可能包含虚假相关性，从而阻碍模型在词汇外（out-of-vocabulary）场景下的性能。本研究旨在探讨向量化方法在处理未见手语时的泛化能力问题。

Method: 本研究提出了一种向量化自编码器模型，并引入了两种语音学归纳偏倚：参数解耦（一种架构偏倚）和语音学半监督学习（一种正则化技术），以提高对已知手语的孤立识别能力以及对未见手语的重建质量。

Result: 研究结果表明，与对照基线模型相比，本研究提出的模型所学习到的表征在单次（one-shot）重建未见手语方面更有效，并且在手语识别方面更具区分度。

Conclusion: 本研究通过定量分析，证明了明确的、受语言学启发的归纳偏倚能够有效提升所学习到的手语表征的泛化能力。

Abstract: Sign language datasets are often not representative in terms of vocabulary,
underscoring the need for models that generalize to unseen signs. Vector
quantization is a promising approach for learning discrete, token-like
representations, but it has not been evaluated whether the learned units
capture spurious correlations that hinder out-of-vocabulary performance. This
work investigates two phonological inductive biases: Parameter Disentanglement,
an architectural bias, and Phonological Semi-Supervision, a regularization
technique, to improve isolated sign recognition of known signs and
reconstruction quality of unseen signs with a vector-quantized autoencoder. The
primary finding is that the learned representations from the proposed model are
more effective for one-shot reconstruction of unseen signs and more
discriminative for sign identification compared to a controlled baseline. This
work provides a quantitative analysis of how explicit, linguistically-motivated
biases can improve the generalization of learned representations of sign
language.

</details>


### [111] [Evaluating NL2SQL via SQL2NL](https://arxiv.org/abs/2509.04657)
*Mohammadtaher Safarzadeh,Afshin Oroojlooyjadid,Dan Roth*

Main category: cs.CL

TL;DR: 现有的自然语言到 SQL (NL2SQL) 模型在面对语言变异时的鲁棒性评估不足，本研究提出了一个新颖的模式匹配释义框架，利用 SQL 到 NL (SQL2NL) 来自动生成语义相同但词汇多样的查询，同时保持与原始模式和意图的一致性。该框架首次实现了 NL2SQL 对语言变异鲁棒性的独立评估，揭示了现有模型比标准基准测试所显示的更为脆弱，并且鲁棒性下降程度因查询复杂性、数据集和领域而异。


<details>
  <summary>Details</summary>
Motivation: 评估 NL2SQL 模型在语言变异下的泛化能力至关重要，但现有基准测试未能系统性地解决此问题。

Method: 提出一个新颖的模式匹配释义框架，利用 SQL 到 NL (SQL2NL) 来自动生成与原始模式和意图保持一致的、语义等价的、词汇多样的查询。

Result: 现有最先进的 NL2SQL 模型比标准基准测试所显示的更为脆弱。例如，LLaMa3.3-70B 在释义后的 Spider 查询上的执行准确率下降了 10.23%，LLaMa3.1-8B 下降了近 20%。较小的模型（如 GPT-4o mini）受到的影响尤为严重。鲁棒性下降的程度因查询复杂性、数据集和领域而异。

Conclusion: 需要明确衡量语言泛化的评估框架，以确保在真实世界设置中的可靠性能。

Abstract: Robust evaluation in the presence of linguistic variation is key to
understanding the generalization capabilities of Natural Language to SQL
(NL2SQL) models, yet existing benchmarks rarely address this factor in a
systematic or controlled manner. We propose a novel schema-aligned paraphrasing
framework that leverages SQL-to-NL (SQL2NL) to automatically generate
semantically equivalent, lexically diverse queries while maintaining alignment
with the original schema and intent. This enables the first targeted evaluation
of NL2SQL robustness to linguistic variation in isolation-distinct from prior
work that primarily investigates ambiguity or schema perturbations. Our
analysis reveals that state-of-the-art models are far more brittle than
standard benchmarks suggest. For example, LLaMa3.3-70B exhibits a 10.23% drop
in execution accuracy (from 77.11% to 66.9%) on paraphrased Spider queries,
while LLaMa3.1-8B suffers an even larger drop of nearly 20% (from 62.9% to
42.5%). Smaller models (e.g., GPT-4o mini) are disproportionately affected. We
also find that robustness degradation varies significantly with query
complexity, dataset, and domain -- highlighting the need for evaluation
frameworks that explicitly measure linguistic generalization to ensure reliable
performance in real-world settings.

</details>


### [112] [Why Language Models Hallucinate](https://arxiv.org/abs/2509.04664)
*Adam Tauman Kalai,Ofir Nachum,Santosh S. Vempala,Edwin Zhang*

Main category: cs.CL

TL;DR: 语言模型会因为训练和评估机制的奖励机制而产生幻觉，奖励猜测而非承认不确定性。


<details>
  <summary>Details</summary>
Motivation: 当前的训练和评估机制奖励模型进行猜测而不是承认不确定性，导致了模型产生幻觉。

Method: 分析了现代训练流程中产生幻觉的统计原因，并提出修改现有基准测试的评分方式来解决幻觉问题。

Result: 模型会因为训练和评估机制的奖励机制而产生幻觉，奖励猜测而非承认不确定性。

Conclusion: 通过修改现有基准测试的评分方式，可以引导该领域朝着更可信赖的人工智能系统发展。

Abstract: Like students facing hard exam questions, large language models sometimes
guess when uncertain, producing plausible yet incorrect statements instead of
admitting uncertainty. Such "hallucinations" persist even in state-of-the-art
systems and undermine trust. We argue that language models hallucinate because
the training and evaluation procedures reward guessing over acknowledging
uncertainty, and we analyze the statistical causes of hallucinations in the
modern training pipeline. Hallucinations need not be mysterious -- they
originate simply as errors in binary classification. If incorrect statements
cannot be distinguished from facts, then hallucinations in pretrained language
models will arise through natural statistical pressures. We then argue that
hallucinations persist due to the way most evaluations are graded -- language
models are optimized to be good test-takers, and guessing when uncertain
improves test performance. This "epidemic" of penalizing uncertain responses
can only be addressed through a socio-technical mitigation: modifying the
scoring of existing benchmarks that are misaligned but dominate leaderboards,
rather than introducing additional hallucination evaluations. This change may
steer the field toward more trustworthy AI systems.

</details>


### [113] [ODKE+: Ontology-Guided Open-Domain Knowledge Extraction with LLMs](https://arxiv.org/abs/2509.04696)
*Samira Khorshidi,Azadeh Nikfarjam,Suprita Shankar,Yisi Sang,Yash Govind,Hyun Jang,Ali Kasgari,Alexis McClimans,Mohamed Soliman,Vishnu Konda,Ahmed Fakhry,Xiaoguang Qi*

Main category: cs.CL

TL;DR: ODKE+是一个生产级系统，可从网络源自动提取和摄取数百万个开放域事实，具有高精度，可扩展、类型一致地跨195个谓词进行事实提取。


<details>
  <summary>Details</summary>
Motivation: 维护知识图谱（KG）的新鲜度和完整性成本高昂。

Method: ODKE+结合了模块化组件，形成了一个可扩展的管道：1）提取启动器检测缺失或过时的事实，2）证据检索器收集支持文档，3）混合知识提取器结合了基于模式的规则和面向大型语言模型（LLM）的本体引导提示，4）轻量级Grounder使用第二个LLM验证提取的事实，5）验证器对候选事实进行排名和标准化以供摄取。ODKE+动态生成针对每个实体类型的本体片段，以使提取与模式约束保持一致。

Result: ODKE+处理了超过900万个维基百科页面，并摄取了1900万个高置信度事实，精度为98.8%。与传统方法相比，ODKE+显著提高了覆盖率，与第三方KG的重叠率高达48%，平均将更新延迟缩短了50天。

Conclusion: 基于LLM的提取，以本体结构和验证工作流为基础，可以提供可信赖的、生产规模的知识摄取，并具有广泛的实际应用性。

Abstract: Knowledge graphs (KGs) are foundational to many AI applications, but
maintaining their freshness and completeness remains costly. We present ODKE+,
a production-grade system that automatically extracts and ingests millions of
open-domain facts from web sources with high precision. ODKE+ combines modular
components into a scalable pipeline: (1) the Extraction Initiator detects
missing or stale facts, (2) the Evidence Retriever collects supporting
documents, (3) hybrid Knowledge Extractors apply both pattern-based rules and
ontology-guided prompting for large language models (LLMs), (4) a lightweight
Grounder validates extracted facts using a second LLM, and (5) the Corroborator
ranks and normalizes candidate facts for ingestion. ODKE+ dynamically generates
ontology snippets tailored to each entity type to align extractions with schema
constraints, enabling scalable, type-consistent fact extraction across 195
predicates. The system supports batch and streaming modes, processing over 9
million Wikipedia pages and ingesting 19 million high-confidence facts with
98.8% precision. ODKE+ significantly improves coverage over traditional
methods, achieving up to 48% overlap with third-party KGs and reducing update
lag by 50 days on average. Our deployment demonstrates that LLM-based
extraction, grounded in ontological structure and verification workflows, can
deliver trustworthiness, production-scale knowledge ingestion with broad
real-world applicability. A recording of the system demonstration is included
with the submission and is also available at https://youtu.be/UcnE3_GsTWs.

</details>


### [114] [OleSpeech-IV: A Large-Scale Multispeaker and Multilingual Conversational Speech Dataset with Diverse Topics](https://arxiv.org/abs/2509.04702)
*Wei Chu,Yuanzhe Dong,Ke Tan,Dong Han,Xavier Menendez-Pidal,Ruchao Fan,Chenfeng Miao,Chanwoo Kim,Bhiksha Raj,Rita Singh*

Main category: cs.CL

TL;DR: OleSpeech-IV是一个大规模、多说话人、多语言的对话语音数据集，部分数据已开源。


<details>
  <summary>Details</summary>
Motivation:  OleSpeech-IV数据集的构建是为了提供一个大规模、多说话人、多语言的对话语音资源，以满足不同研究和应用的需求。

Method: 通过整合公开的英语播客、谈话节目、电话会议等音频内容，并结合自主开发的管线进行说话人、对话轮次、文本转录、时间戳和置信度等信息的提取与优化。

Result: 构建了一个大规模多说话人多语言对话语音数据集OleSpeech-IV，并开源了其中一个子集OleSpeech-IV-2025-EN-AR-100，用于非商业研究。

Conclusion:  OleSpeech-IV数据集为语音技术研究提供了宝贵的资源，特别是其多说话人、多语言和多样化的对话场景特点，有助于推动相关技术的发展。

Abstract: OleSpeech-IV dataset is a large-scale multispeaker and multilingual
conversational speech dataset with diverse topics. The audio content comes from
publicly-available English podcasts, talk shows, teleconferences, and other
conversations. Speaker names, turns, and transcripts are human-sourced and
refined by a proprietary pipeline, while additional information such as
timestamps and confidence scores is derived from the pipeline. The IV denotes
its position as Tier IV in the Olewave dataset series. In addition, we have
open-sourced a subset, OleSpeech-IV-2025-EN-AR-100, for non-commercial research
use.

</details>


### [115] [KERAG: Knowledge-Enhanced Retrieval-Augmented Generation for Advanced Question Answering](https://arxiv.org/abs/2509.04716)
*Yushi Sun,Kai Sun,Yifan Ethan Xu,Xiao Yang,Xin Luna Dong,Nan Tang,Lei Chen*

Main category: cs.CL

TL;DR: KERAG是一个基于知识图谱的检索增强生成（RAG）框架，通过检索更广泛的子图并结合链式思考（Chain-of-Thought）推理，提高了问答的覆盖率和准确性，在实验中超越了现有技术和GPT-4o。


<details>
  <summary>Details</summary>
Motivation: 传统的知识图谱问答（KGQA）方法依赖于语义解析，检索范围受限，导致覆盖率低，难以处理复杂问题。

Method: KERAG采用检索-过滤-总结的流程，检索更广泛的知识子图，并使用经过微调的语言模型进行链式思考推理，以减少噪音并提高问答能力。

Result: KERAG在问答质量上比最先进的解决方案提高了约7%，并比GPT-4o（Tool）提高了10-21%。

Conclusion: KERAG通过更广泛的子图检索和链式思考推理，有效解决了传统KGQA方法的局限性，显著提升了问答的覆盖率和准确性。

Abstract: Retrieval-Augmented Generation (RAG) mitigates hallucination in Large
Language Models (LLMs) by incorporating external data, with Knowledge Graphs
(KGs) offering crucial information for question answering. Traditional
Knowledge Graph Question Answering (KGQA) methods rely on semantic parsing,
which typically retrieves knowledge strictly necessary for answer generation,
thus often suffer from low coverage due to rigid schema requirements and
semantic ambiguity. We present KERAG, a novel KG-based RAG pipeline that
enhances QA coverage by retrieving a broader subgraph likely to contain
relevant information. Our retrieval-filtering-summarization approach, combined
with fine-tuned LLMs for Chain-of-Thought reasoning on knowledge sub-graphs,
reduces noises and improves QA for both simple and complex questions.
Experiments demonstrate that KERAG surpasses state-of-the-art solutions by
about 7% in quality and exceeds GPT-4o (Tool) by 10-21%.

</details>


### [116] [PRIM: Towards Practical In-Image Multilingual Machine Translation](https://arxiv.org/abs/2509.05146)
*Yanzhi Tian,Zeming Liu,Zhengyang Liu,Chong Feng,Xin Li,Heyan Huang,Yuhang Guo*

Main category: cs.CL

TL;DR: 该研究提出了PRIM数据集和VisTrans模型，用于解决真实世界图像中的多语言机器翻译问题，并在实验中取得了优于其他模型的翻译质量和视觉效果。


<details>
  <summary>Details</summary>
Motivation: 现有图像翻译研究主要基于合成数据，与现实世界存在差距，因此需要研究更贴近实际场景的图像多语言翻译。

Method: 提出PRIM数据集，包含真实世界场景下的文本图像；提出VisTrans模型，该模型分别处理图像中的视觉文本和背景信息，以支持多语言翻译并提升视觉效果。

Result: VisTrans模型在PRIM数据集上实现了优于其他模型的翻译质量和视觉效果。

Conclusion: VisTrans模型能够有效处理真实世界图像中的多语言翻译任务，并在翻译质量和视觉效果上表现出色。

Abstract: In-Image Machine Translation (IIMT) aims to translate images containing texts
from one language to another. Current research of end-to-end IIMT mainly
conducts on synthetic data, with simple background, single font, fixed text
position, and bilingual translation, which can not fully reflect real world,
causing a significant gap between the research and practical conditions. To
facilitate research of IIMT in real-world scenarios, we explore Practical
In-Image Multilingual Machine Translation (IIMMT). In order to convince the
lack of publicly available data, we annotate the PRIM dataset, which contains
real-world captured one-line text images with complex background, various
fonts, diverse text positions, and supports multilingual translation
directions. We propose an end-to-end model VisTrans to handle the challenge of
practical conditions in PRIM, which processes visual text and background
information in the image separately, ensuring the capability of multilingual
translation while improving the visual quality. Experimental results indicate
the VisTrans achieves a better translation quality and visual effect compared
to other models. The code and dataset are available at:
https://github.com/BITHLP/PRIM.

</details>


### [117] [A Study of Large Language Models for Patient Information Extraction: Model Architecture, Fine-Tuning Strategy, and Multi-task Instruction Tuning](https://arxiv.org/abs/2509.04753)
*Cheng Peng,Xinyu Dong,Mengxian Lyu,Daniel Paredes,Yaoyun Zhang,Yonghui Wu*

Main category: cs.CL

TL;DR: LLMs在临床患者信息提取任务中表现出潜力，本研究探讨了不同LLM架构、微调策略和多任务指令调优技术，以优化其在临床信息提取中的应用。


<details>
  <summary>Details</summary>
Motivation: 临床叙事中的患者信息提取对医疗应用至关重要，而LLM的出现为这一领域带来了革命，但其最佳应用仍需进一步研究。

Method: 本研究评估了不同LLM架构（如BERT、GatorTron、GatorTronGPT、Llama 3.1）、全参数微调与参数高效微调（PEFT）策略，并探索了多任务指令调优框架在零样本和少样本学习场景下的表现。

Result: 研究结果将为不同LLM架构和微调方法在五项数据集上的表现提供基准，并评估多任务指令调优在提高模型泛化能力和少样本学习性能方面的效果。

Conclusion: 本研究旨在为开发强大且可泛化的患者信息提取系统提供关于LLM应用的关键见解，特别是在临床概念和关系提取方面。

Abstract: Natural language processing (NLP) is a key technology to extract important
patient information from clinical narratives to support healthcare
applications. The rapid development of large language models (LLMs) has
revolutionized many NLP tasks in the clinical domain, yet their optimal use in
patient information extraction tasks requires further exploration. This study
examines LLMs' effectiveness in patient information extraction, focusing on LLM
architectures, fine-tuning strategies, and multi-task instruction tuning
techniques for developing robust and generalizable patient information
extraction systems. This study aims to explore key concepts of using LLMs for
clinical concept and relation extraction tasks, including: (1) encoder-only or
decoder-only LLMs, (2) prompt-based parameter-efficient fine-tuning (PEFT)
algorithms, and (3) multi-task instruction tuning on few-shot learning
performance. We benchmarked a suite of LLMs, including encoder-based LLMs
(BERT, GatorTron) and decoder-based LLMs (GatorTronGPT, Llama 3.1,
GatorTronLlama), across five datasets. We compared traditional full-size
fine-tuning and prompt-based PEFT. We explored a multi-task instruction tuning
framework that combines both tasks across four datasets to evaluate the
zero-shot and few-shot learning performance using the leave-one-dataset-out
strategy.

</details>


### [118] [Research on Multi-hop Inference Optimization of LLM Based on MQUAKE Framework](https://arxiv.org/abs/2509.04770)
*Zucheng Liang,Wenxin Wei,Kaijie Zhang,Hongyi Chen*

Main category: cs.CL

TL;DR: 多跳问题分解方法能有效提升LLM理解和推理复杂问题的能力，无论是在模型训练前还是训练后。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型（LLMs）在准确回答复杂问题方面面临的挑战。

Method: 提出一种基于MQUAKE框架的多跳问题分解方法，并利用LLAMA3模型系统研究该方法在知识图谱上的影响。将MQUAKE-T数据集划分为单跳和多跳两种格式，分别对LLAMA3模型进行微调和推理测试。

Result: 未经微调，多跳分解方法显著优于直接回答复杂问题的方法；微调后，两种方法的性能均有提升，但多跳分解方法始终保持优势。

Conclusion: 多跳分解方法在训练前后均能有效提升LLM回答复杂问题的能力。

Abstract: Accurately answering complex questions has consistently been a significant
challenge for Large Language Models (LLMs). To address this, this paper
proposes a multi-hop question decomposition method for complex questions,
building upon research within the MQUAKE framework. Utilizing the LLAMA3 model,
we systematically investigate the impact of multi-hop question decomposition
within knowledge graphs on model comprehension and reasoning accuracy, both
before and after model training. In our experiments, we systematically
partitioned and converted the MQUAKE-T dataset into two distinct formats: a
single-hop dataset designed for directly answering complex questions, and a
multi-hop dataset constructed using the multi-hop question decomposition
method. We then fine-tuned the LLAMA3 model on these datasets and conducted
inference tests. Our results demonstrate that, without fine-tuning the LLM, the
prediction performance based on the multi-hop question decomposition method
significantly outperforms the method of directly answering complex questions.
After fine-tuning using the LoRA (Low-Rank Adaptation) method, the performance
of both approaches improved compared to the untrained baseline. Crucially, the
method utilizing multi-hop decomposition consistently maintained its
superiority. These findings validate the effectiveness of the multi-hop
decomposition method both before and after training, demonstrating its
capability to effectively enhance the LLM's ability to answer complex
questions.

</details>


### [119] [Decoders Laugh as Loud as Encoders](https://arxiv.org/abs/2509.04779)
*Eli Borodach,Raj Dandekar,Rajat Dandekar,Sreedath Panat*

Main category: cs.CL

TL;DR: GPT-4o 在理解幽默方面表现出色，其性能与 RoBERTa 相当。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型（LLMs）在理解幽默方面的能力，这是一个悬而未决的问题。

Method: 对 GPT-4o 和 RoBERTa 模型在理解幽默任务上的性能进行了评估。

Result: 微调后的 GPT-4o 在幽默理解任务上取得了 0.85 的 F1-macro 平均分，与微调后的 RoBERTa（0.86 的 F1 平均分）表现相当。

Conclusion: GPT-4o 在理解幽默方面表现出色，其性能可以媲美现有的最先进模型。

Abstract: From the dawn of the computer, Allen Turing dreamed of a robot that could
communicate using language as a human being. The recent advances in the field
of Large Language Models (LLMs) shocked the scientific community when a single
model can apply for various natural language processing (NLP) tasks, while the
output results are sometimes even better than most human communication skills.
Models such as GPT, Claude, Grok, etc. have left their mark on the scientific
community. However, it is unclear how much these models understand what they
produce, especially in a nuanced theme such as humor. The question of whether
computers understand humor is still open (among the decoders, the latest to be
checked was GPT-2). We addressed this issue in this paper; we have showed that
a fine-tuned decoder (GPT-4o) performed (Mean F1-macro score of 0.85) as well
as the best fine-tuned encoder (RoBERTa with a Mean of F1-score 0.86)

</details>


### [120] [Enhancing Diversity in Large Language Models via Determinantal Point Processes](https://arxiv.org/abs/2509.04784)
*Yilei Chen,Souradip Chakraborty,Lorenz Wolf,Ioannis Ch. Paschalidis,Aldo Pacchiano*

Main category: cs.CL

TL;DR: DQO是一种基于确定性点过程（DPP）的新型训练方法，用于在监督微调和强化学习后，联合优化大型语言模型（LLM）的质量和语义多样性。该方法通过测量一组响应嵌入的核相似性矩阵的行列式来衡量多样性，并在多项任务实验中证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 监督微调和强化学习在改进LLM下游任务性能的同时，会降低输出多样性，导致响应狭窄和模式化。现有增强多样性的方法存在局限性，要么在推理时操作，要么只关注词汇差异。

Method: DQO方法通过采样和嵌入每个提示的一组响应，并利用核相似性矩阵的行列式来度量这些响应嵌入所跨越的体积，从而衡量多样性。

Result: 在指令遵循、文本摘要、故事生成和推理等任务的实验中，DQO方法显著提高了语义多样性，同时不牺牲模型质量。

Conclusion: DQO方法能够有效地在保持模型质量的同时，提高LLM的语义多样性，解决了现有方法在提高多样性方面的局限性。

Abstract: Supervised fine-tuning and reinforcement learning are two popular methods for
post-training large language models (LLMs). While improving the model's
performance on downstream tasks, they often reduce the model's output
diversity, leading to narrow, canonical responses. Existing methods to enhance
diversity are limited, either by operating at inference time or by focusing on
lexical differences. We propose a novel training method named DQO based on
determinantal point processes (DPPs) to jointly optimize LLMs for quality and
semantic diversity. Our approach samples and embeds a group of responses for
each prompt, then uses the determinant of a kernel-based similarity matrix to
measure diversity as the volume spanned by the embeddings of these responses.
Experiments across instruction-following, summarization, story generation, and
reasoning tasks demonstrate that our method substantially improves semantic
diversity without sacrificing model quality.

</details>


### [121] [Personality as a Probe for LLM Evaluation: Method Trade-offs and Downstream Effects](https://arxiv.org/abs/2509.04794)
*Gunmay Handa,Zekun Wu,Adriano Koshiyama,Philip Treleaven*

Main category: cs.CL

TL;DR: 本研究系统研究了大型语言模型（LLMs）中的个性化操纵技术，重点关注“大五”人格特质。研究人员比较了情境内学习（ICL）、参数高效微调（PEFT）和机制引导（MS）三种方法，并提出了新的数据集、评估框架、特征提纯技术和稳定性框架。实验结果表明，ICL在保持模型能力的同时实现了良好的个性化对齐；PEFT实现了最高的个性化对齐，但牺牲了任务性能；MS作为一种轻量级的运行时控制方法，效果具有竞争力。研究还发现，“开放性”特质的操纵尤具挑战性，“宜人性”特质对ICL的抵抗力最强，且人格编码倾向于集中在模型的中间层。最终，研究将个性化操纵视为一种深入理解模型行为表征的多层次探针，并将机制引导定位为一种轻量级的替代微调的方法，适用于模型部署和可解释性分析。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在客服和智能体场景中的个性化操纵日益普遍，但其机制和权衡尚不明确。本研究旨在系统地研究基于“大五”特质的个性化控制方法，并揭示不同方法间的权衡。

Method: 本研究采用了情境内学习（ICL）、参数高效微调（PEFT）和机制引导（MS）三种方法，并构建了一个对比数据集，包含平衡的高/低特质响应。研究人员引入了一个统一的评估框架，基于运行内的Δ分析，用于区分推理能力、智能体性能和人口统计学偏差。此外，还开发了特征提纯技术来分离“开放性”和“尽责性”，并提出了一个三层稳定性框架来量化方法的鲁棒性。

Result: 实验在Gemma-2-2B-IT和LLaMA-3-8B-Instruct模型上进行。结果显示：ICL在最小化能力损失的情况下实现了强大的对齐；PEFT实现了最高的对齐，但任务性能有所下降；MS提供了轻量级的运行时控制，效果具有竞争力。“开放性”特质的操纵最为困难，“宜人性”特质对ICL的抵抗力最强，人格编码集中在模型的中间层。

Conclusion: 本研究提出的个性化操纵方法为理解LLMs的行为表征提供了多层次的视角，连接了表面条件、参数编码和激活层引导。研究结果表明，机制引导（MS）是一种轻量级的替代微调的方法，适用于模型部署和可解释性分析。

Abstract: Personality manipulation in large language models (LLMs) is increasingly
applied in customer service and agentic scenarios, yet its mechanisms and
trade-offs remain unclear. We present a systematic study of personality control
using the Big Five traits, comparing in-context learning (ICL),
parameter-efficient fine-tuning (PEFT), and mechanistic steering (MS). Our
contributions are fourfold. First, we construct a contrastive dataset with
balanced high/low trait responses, enabling effective steering vector
computation and fair cross-method evaluation. Second, we introduce a unified
evaluation framework based on within-run $\Delta$ analysis that disentangles,
reasoning capability, agent performance, and demographic bias across MMLU,
GAIA, and BBQ benchmarks. Third, we develop trait purification techniques to
separate openness from conscientiousness, addressing representational overlap
in trait encoding. Fourth, we propose a three-level stability framework that
quantifies method-, trait-, and combination-level robustness, offering
practical guidance under deployment constraints. Experiments on Gemma-2-2B-IT
and LLaMA-3-8B-Instruct reveal clear trade-offs: ICL achieves strong alignment
with minimal capability loss, PEFT delivers the highest alignment at the cost
of degraded task performance, and MS provides lightweight runtime control with
competitive effectiveness. Trait-level analysis shows openness as uniquely
challenging, agreeableness as most resistant to ICL, and personality encoding
consolidating around intermediate layers. Taken together, these results
establish personality manipulation as a multi-level probe into behavioral
representation, linking surface conditioning, parameter encoding, and
activation-level steering, and positioning mechanistic steering as a
lightweight alternative to fine-tuning for both deployment and
interpretability.

</details>


### [122] [Knowledge Collapse in LLMs: When Fluency Survives but Facts Fail under Recursive Synthetic Training](https://arxiv.org/abs/2509.04796)
*Figarri Keisha,Zekun Wu,Ze Wang,Adriano Koshiyama,Philip Treleaven*

Main category: cs.CL

TL;DR: 由于人类编写内容稀缺，大型语言模型越来越依赖合成数据，但对模型生成输.出的递归训练会导致模型崩溃，这是一个威胁事实可靠性的退化过程。我们定义知识崩溃是一个独特的三阶段现象，其中事实准确性会下降，同时表面流畅性会持续存在，从而产生“自信地错误”的输出，这在依赖准确性的领域构成重大风险。通过对递归合成训练进行受控实验，我们证明了崩溃轨迹和时间在很大程度上取决于指令格式，将指令跟随崩溃与传统模型崩溃区分开来，因为它的条件性和依赖于提示性。我们提出特定领域的合成训练作为一种有针对性的缓解策略，在保持计算效率的同时，大大提高了抗崩溃能力。我们的评估框架结合了以模型为中心的指标和以任务为中心的指标，以检测不同的退化阶段，能够跨不同语言模型可重现地评估认知恶化。这些发现为理解崩溃动态提供了理论见解，并为知识密集型应用中可持续的人工智能训练提供了实践指导，在这些应用中准确性至关重要。


<details>
  <summary>Details</summary>
Motivation: 由于人类编写内容稀缺，大型语言模型越来越依赖合成数据，但递归训练会导致模型崩溃，威胁事实可靠性。

Method: 通过受控实验，我们演示了崩溃轨迹和时间如何依赖于指令格式，区分了指令跟随崩溃与传统模型崩溃。我们还提出特定领域的合成训练作为缓解策略，并结合了以模型为中心的指标和以任务为中心的指标的评估框架。

Result: 递归合成训练导致知识崩溃，即事实准确性下降而表面流畅性持续，产生“自信地错误”的输出。指令格式会影响崩溃轨迹和时间。特定领域的合成训练可提高抗崩溃能力，同时保持计算效率。评估框架可检测不同的退化阶段。

Conclusion: 模型崩溃是一个三阶段现象，会对事实准确性产生负面影响。指令格式会影响崩溃。特定领域的合成训练和结合了模型和任务指标的评估框架是应对这一挑战的有效策略。

Abstract: Large language models increasingly rely on synthetic data due to
human-written content scarcity, yet recursive training on model-generated
outputs leads to model collapse, a degenerative process threatening factual
reliability. We define knowledge collapse as a distinct three-stage phenomenon
where factual accuracy deteriorates while surface fluency persists, creating
"confidently wrong" outputs that pose critical risks in accuracy-dependent
domains. Through controlled experiments with recursive synthetic training, we
demonstrate that collapse trajectory and timing depend critically on
instruction format, distinguishing instruction-following collapse from
traditional model collapse through its conditional, prompt-dependent nature. We
propose domain-specific synthetic training as a targeted mitigation strategy
that achieves substantial improvements in collapse resistance while maintaining
computational efficiency. Our evaluation framework combines model-centric
indicators with task-centric metrics to detect distinct degradation phases,
enabling reproducible assessment of epistemic deterioration across different
language models. These findings provide both theoretical insights into collapse
dynamics and practical guidance for sustainable AI training in
knowledge-intensive applications where accuracy is paramount.

</details>


### [123] [Mind the Gap: Evaluating Model- and Agentic-Level Vulnerabilities in LLMs with Action Graphs](https://arxiv.org/abs/2509.04802)
*Ilham Wicaksono,Zekun Wu,Theo King,Adriano Koshiyama,Philip Treleaven*

Main category: cs.CL

TL;DR: AgentSeer是一个基于可观测性的评估框架，通过将代理执行分解为图来评估大型语言模型作为代理的安全性，发现了传统评估框架忽视的“仅代理”漏洞。


<details>
  <summary>Details</summary>
Motivation: 当前的语言模型安全评估框架在评估作为代理的大型语言模型部署特定风险时存在重大差距。

Method: AgentSeer框架将代理执行分解为动作和组件图，以进行系统性的代理-情境评估，并通过在GPT-OSS-20B和Gemini-2.0-flash模型上使用HarmBench进行跨模型验证。

Result: 在模型层面，GPT-OSS-20B的攻击成功率（ASR）为39.47%，Gemini-2.0-flash为50.00%，两者都容易受到社会工程攻击。在代理层面，发现了“仅代理”漏洞，其中工具调用使ASR在两个模型上都增加了24-60%。直接攻击转移效果不佳，而上下文感知的迭代攻击则更有效。

Conclusion: 需要新的代理-情境评估范式，AgentSeer提供了一个标准化的方法和经验验证，以解决现有评估框架的系统性差距。

Abstract: As large language models transition to agentic systems, current safety
evaluation frameworks face critical gaps in assessing deployment-specific
risks. We introduce AgentSeer, an observability-based evaluation framework that
decomposes agentic executions into granular action and component graphs,
enabling systematic agentic-situational assessment. Through cross-model
validation on GPT-OSS-20B and Gemini-2.0-flash using HarmBench single turn and
iterative refinement attacks, we demonstrate fundamental differences between
model-level and agentic-level vulnerability profiles. Model-level evaluation
reveals baseline differences: GPT-OSS-20B (39.47% ASR) versus Gemini-2.0-flash
(50.00% ASR), with both models showing susceptibility to social engineering
while maintaining logic-based attack resistance. However, agentic-level
assessment exposes agent-specific risks invisible to traditional evaluation. We
discover "agentic-only" vulnerabilities that emerge exclusively in agentic
contexts, with tool-calling showing 24-60% higher ASR across both models.
Cross-model analysis reveals universal agentic patterns, agent transfer
operations as highest-risk tools, semantic rather than syntactic vulnerability
mechanisms, and context-dependent attack effectiveness, alongside
model-specific security profiles in absolute ASR levels and optimal injection
strategies. Direct attack transfer from model-level to agentic contexts shows
degraded performance (GPT-OSS-20B: 57% human injection ASR; Gemini-2.0-flash:
28%), while context-aware iterative attacks successfully compromise objectives
that failed at model-level, confirming systematic evaluation gaps. These
findings establish the urgent need for agentic-situation evaluation paradigms,
with AgentSeer providing the standardized methodology and empirical validation.

</details>


### [124] [Analyzing Finnish Inflectional Classes through Discriminative Lexicon and Deep Learning Models](https://arxiv.org/abs/2509.04813)
*Alexandre Nikolaev,Yu-Ying Chuang,R. Harald Baayen*

Main category: cs.CL

TL;DR: 该研究使用判别式词汇模型（DLM）探讨了芬兰语名词屈折的认知现实性，发现模型在不依赖屈折类的情况下也能学习和生成芬兰语屈折名词，但词频在基于用法的模型中比屈折类更具预测性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探究语言教学和形态系统构建中有用的屈折类在认知上是否真实，即母语者是否需要发现这些屈折类才能正确学习和生成语言中的屈折名词。

Method: 本研究使用包含 55,271 个屈折名词（来自 2,000 个高频芬兰语名词，涵盖 49 个屈折类）的数据集，构建了多个判别式词汇模型（DLM）来理解和生成芬兰语屈折名词，其中一些模型未考虑词频（模拟无限暴露学习），另一些模型则考虑了词频（模拟基于用法的学习）。

Result: 所有模型在训练数据上都达到了很高的准确率。在测试数据上，准确率有所下降但仍可接受。模型在包含更多词类型、低频词和仅出现一次的词（hapax legomena）的屈折类上表现更好，这与屈折类的生产力相似。然而，在基于用法的生成模型中，词频是模型表现的主要预测因素，而与屈折类生产力的相关性则不明显。

Conclusion: 判别式词汇模型（DLM）可以在不明确设置屈折类的情况下学习芬兰语名词的屈折。虽然屈折类的某些特征（如类型数量、低频词和仅出现一次的词的数量）与模型的表现相关，但在基于用法的模型中，词频比屈折类的生产力更能预测模型的表现，这表明词频在认知上可能比屈折类更重要。

Abstract: Descriptions of complex nominal or verbal systems make use of inflectional
classes. Inflectional classes bring together nouns which have similar stem
changes and use similar exponents in their paradigms. Although inflectional
classes can be very useful for language teaching as well as for setting up
finite state morphological systems, it is unclear whether inflectional classes
are cognitively real, in the sense that native speakers would need to discover
these classes in order to learn how to properly inflect the nouns of their
language. This study investigates whether the Discriminative Lexicon Model
(DLM) can understand and produce Finnish inflected nouns without setting up
inflectional classes, using a dataset with 55,271 inflected nouns of 2000
high-frequency Finnish nouns from 49 inflectional classes. Several DLM
comprehension and production models were set up. Some models were not informed
about frequency of use, and provide insight into learnability with infinite
exposure (endstate learning). Other models were set up from a usage based
perspective, and were trained with token frequencies being taken into
consideration (frequency-informed learning). On training data, models performed
with very high accuracies. For held-out test data, accuracies decreased, as
expected, but remained acceptable. Across most models, performance increased
for inflectional classes with more types, more lower-frequency words, and more
hapax legomena, mirroring the productivity of the inflectional classes. The
model struggles more with novel forms of unproductive and less productive
classes, and performs far better for unseen forms belonging to productive
classes. However, for usage-based production models, frequency was the dominant
predictor of model performance, and correlations with measures of productivity
were tenuous or absent.

</details>


### [125] [AFD-SLU: Adaptive Feature Distillation for Spoken Language Understanding](https://arxiv.org/abs/2509.04821)
*Yan Xie,Yibo Cui,Liang Xie,Erwei Yin*

Main category: cs.CL

TL;DR: 该研究提出了一种自适应特征蒸馏框架（AFD-SLU），通过将GTE教师模型的丰富语义表征迁移到轻量级学生模型，解决了口语理解（SLU）中数据稀缺和计算资源消耗大的问题。


<details>
  <summary>Details</summary>
Motivation: 口语理解（SLU）是对话系统的核心，但面临训练数据稀缺和部署大型语言模型（LLMs）计算成本高昂的挑战。

Method: 提出自适应特征蒸馏框架（AFD-SLU），使用基于GTE的教师模型向轻量级学生模型迁移表征。该框架包含一个动态适配器（带RPNN）来对齐异构特征空间，以及一个动态蒸馏系数（DDC）根据意图和槽位预测性能动态调整蒸馏强度。

Result: 在中文ProSLU基准测试中，AFD-SLU达到了95.67%的意图准确率，92.02%的槽位F1分数，以及85.50%的整体准确率，取得了当前最优的性能。

Conclusion: 自适应特征蒸馏框架（AFD-SLU）能够有效解决SLU中的数据稀缺和计算负担问题，并取得优越的性能。

Abstract: Spoken Language Understanding (SLU) is a core component of conversational
systems, enabling machines to interpret user utterances. Despite its
importance, developing effective SLU systems remains challenging due to the
scarcity of labeled training data and the computational burden of deploying
Large Language Models (LLMs) in real-world applications. To further alleviate
these issues, we propose an Adaptive Feature Distillation framework that
transfers rich semantic representations from a General Text Embeddings
(GTE)-based teacher model to a lightweight student model. Our method introduces
a dynamic adapter equipped with a Residual Projection Neural Network (RPNN) to
align heterogeneous feature spaces, and a Dynamic Distillation Coefficient
(DDC) that adaptively modulates the distillation strength based on real-time
feedback from intent and slot prediction performance. Experiments on the
Chinese profile-based ProSLU benchmark demonstrate that AFD-SLU achieves
state-of-the-art results, with 95.67% intent accuracy, 92.02% slot F1 score,
and 85.50% overall accuracy.

</details>


### [126] [Memorization $\neq$ Understanding: Do Large Language Models Have the Ability of Scenario Cognition?](https://arxiv.org/abs/2509.04866)
*Boxiang Ma,Ru Li,Yuanlong Wang,Hongye Tan,Xiaoli Li*

Main category: cs.CL

TL;DR: 大型语言模型（LLMs）在各种自然语言处理（NLP）任务中表现出色，但它们的能力是源于记忆还是真正的语义理解仍有待考证。本文提出一个评估框架，从模型输出和内部表征两个角度，评估LLMs的情景认知能力（将语义情景元素与其在上下文中的论据联系起来）。实验结果表明，目前的LLMs主要依赖表面记忆，即使在简单情景下也无法实现稳健的语义情景认知。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）的泛化能力是源于死记硬背还是真正的语义理解，特别是它们的情景认知能力。

Method: 提出一个双视角评估框架，包括：1. 通过回答与情景相关的问题来评估LLMs的输出（模型输出视角）；2. 探究LLMs内部表征中编码的情景元素-论据关联（内部表征视角）。设计了一个包含虚构事实描述及其情景元素标注的新型基于情景的数据集。

Result: 实验表明，当前的LLMs主要依赖表面记忆，缺乏稳健的语义情景认知能力，即使在简单情景下也如此。

Conclusion: 现有的LLMs在语义理解方面存在显著局限，主要依赖记忆而非真正的语义理解，这为未来提升其能力提供了认知见解。

Abstract: Driven by vast and diverse textual data, large language models (LLMs) have
demonstrated impressive performance across numerous natural language processing
(NLP) tasks. Yet, a critical question persists: does their generalization arise
from mere memorization of training data or from deep semantic understanding? To
investigate this, we propose a bi-perspective evaluation framework to assess
LLMs' scenario cognition - the ability to link semantic scenario elements with
their arguments in context. Specifically, we introduce a novel scenario-based
dataset comprising diverse textual descriptions of fictional facts, annotated
with scenario elements. LLMs are evaluated through their capacity to answer
scenario-related questions (model output perspective) and via probing their
internal representations for encoded scenario elements-argument associations
(internal representation perspective). Our experiments reveal that current LLMs
predominantly rely on superficial memorization, failing to achieve robust
semantic scenario cognition, even in simple cases. These findings expose
critical limitations in LLMs' semantic understanding and offer cognitive
insights for advancing their capabilities.

</details>


### [127] [PLaMo 2 Technical Report](https://arxiv.org/abs/2509.04897)
*Preferred Networks,:,Kaizaburo Chubachi,Yasuhiro Fujita,Shinichi Hemmi,Yuta Hirokawa,Toshiki Kataoka,Goro Kobayashi,Kenichi Maehashi,Calvin Metzger,Hiroaki Mikami,Shogo Murai,Daisuke Nishino,Kento Nozawa,Shintarou Okada,Daisuke Okanohara,Shunta Saito,Shotaro Sano,Shuji Suzuki,Daisuke Tanaka,Avinash Ummadisingu,Hanqin Wang,Sixue Wang,Tianqi Xu*

Main category: cs.CL

TL;DR: PLaMo 2是支持32K token上下文的日本大型语言模型系列，采用基于Samba的混合架构，通过持续预训练实现全注意力。


<details>
  <summary>Details</summary>
Motivation: 克服日本数据稀缺性，实现高效训练和推理。

Method: 采用基于Samba的混合架构，持续预训练至全注意力，利用合成语料库，通过权重复用和结构化剪枝提高计算效率，并进行监督微调（SFT）和直接偏好优化（DPO）。

Result: 一个8B模型性能达到先前100B模型水平，PLaMo 2模型在日语基准测试中取得最先进成果，在指令遵循、语言流畅性和日语特定知识方面优于同等大小的开放模型。

Conclusion: PLaMo 2模型在日语处理方面取得了显著进展，在性能和效率上都表现出色。

Abstract: In this report, we introduce PLaMo 2, a series of Japanese-focused large
language models featuring a hybrid Samba-based architecture that transitions to
full attention via continual pre-training to support 32K token contexts.
Training leverages extensive synthetic corpora to overcome data scarcity, while
computational efficiency is achieved through weight reuse and structured
pruning. This efficient pruning methodology produces an 8B model that achieves
performance comparable to our previous 100B model. Post-training further
refines the models using a pipeline of supervised fine-tuning (SFT) and direct
preference optimization (DPO), enhanced by synthetic Japanese instruction data
and model merging techniques. Optimized for inference using vLLM and
quantization with minimal accuracy loss, the PLaMo 2 models achieve
state-of-the-art results on Japanese benchmarks, outperforming similarly-sized
open models in instruction-following, language fluency, and Japanese-specific
knowledge.

</details>


### [128] [Using LLMs for Multilingual Clinical Entity Linking to ICD-10](https://arxiv.org/abs/2509.04868)
*Sylvia Vassileva,Ivan Koychev,Svetla Boytcheva*

Main category: cs.CL

TL;DR: 本文提出了一种利用大型语言模型（LLM）将临床术语链接到 ICD-10 编码的方法，该方法结合了临床字典匹配和 GPT-4 的上下文学习能力，并在西班牙语和希腊语数据集上取得了良好的效果。


<details>
  <summary>Details</summary>
Motivation: 从临床文本中提取结构化信息，特别是将临床实体链接到 ICD-10 编码，以简化医疗保健专业人员的工作并确保医院编码的一致性。

Method: 采用多阶段流程，首先使用临床字典匹配明确的术语，然后利用 GPT-4 的上下文学习能力预测未匹配术语的 ICD-10 编码。

Result: 在西班牙语 CodiEsp 数据集上，该系统在类别上达到了 0.89 的 F1 分数，在子类别上达到了 0.78 的 F1 分数；在希腊语 ElCardioCC 数据集上，在类别上达到了 0.85 的 F1 分数。

Conclusion: 所提出的方法在多语言临床术语到 ICD-10 编码的链接任务上显示出有前景的结果。

Abstract: The linking of clinical entities is a crucial part of extracting structured
information from clinical texts. It is the process of assigning a code from a
medical ontology or classification to a phrase in the text. The International
Classification of Diseases - 10th revision (ICD-10) is an international
standard for classifying diseases for statistical and insurance purposes.
Automatically assigning the correct ICD-10 code to terms in discharge summaries
will simplify the work of healthcare professionals and ensure consistent coding
in hospitals. Our paper proposes an approach for linking clinical terms to
ICD-10 codes in different languages using Large Language Models (LLMs). The
approach consists of a multistage pipeline that uses clinical dictionaries to
match unambiguous terms in the text and then applies in-context learning with
GPT-4.1 to predict the ICD-10 code for the terms that do not match the
dictionary. Our system shows promising results in predicting ICD-10 codes on
different benchmark datasets in Spanish - 0.89 F1 for categories and 0.78 F1 on
subcategories on CodiEsp, and Greek - 0.85 F1 on ElCardioCC.

</details>


### [129] [L1RA: Dynamic Rank Assignment in LoRA Fine-Tuning](https://arxiv.org/abs/2509.04884)
*Raul Singh,Nicolo Brunello,Vincenzo Scotti,Mark James Carman*

Main category: cs.CL

TL;DR: L1RA通过L1正则化动态调整LoRA适配器的秩，在资源受限的情况下提高了LLM微调的效率和性能，并提供了模型组件的洞察。


<details>
  <summary>Details</summary>
Motivation: LLM微调对计算资源要求高，资源受限时面临挑战。

Method: L1RA技术，利用L1正则化动态分配LoRA适配器的秩，并在适配器之间重新分配冗余的秩。

Result: L1RA的计算开销与标准LoRA相当或更低，性能相当或更好。同时，发现了前馈层和注意力输出投影层是最需要调整以适应任务目标的部分。

Conclusion: L1RA是一种在计算资源受限的情况下提高LLM微调效率和可解释性的有效技术。

Abstract: The ability of Large Language Models (LLMs) to solve complex tasks has made
them crucial in the development of AI-based applications. However, the high
computational requirements to fine-tune these LLMs on downstream tasks pose
significant challenges, particularly when resources are limited. In response to
this challenge, we introduce L1RA, a novel technique aimed at dynamically
distributing the rank of low-rank adapters during fine-tuning using LoRA. Given
a rank budget (i.e., total sum of adapters rank), L1RA leverages L1
regularisation to prune redundant ranks and redistribute them across adapters,
thereby optimising resource utilisation. Through a series of comprehensive
experiments, we empirically demonstrate that L1RA maintains comparable or even
reduced computational overhead compared to other LoRA variants, including the
vanilla approach, while achieving same or better performances. Moreover, the
post-training analysis of rank distribution unveiled insights into the specific
model components requiring the most adaptation to align with the task
objective: the feed-forward layers and the attention output projection. These
results highlight the efficacy of L1RA in not only enhancing the efficiency of
LLM fine-tuning, but also in providing valuable diagnostic information for
model refinement and customisation. In conclusion, L1RA stands as a promising
technique for advancing the performance and interpretability of LLM adaptation,
particularly in scenarios where computational resources are constrained.

</details>


### [130] [ACE-RL: Adaptive Constraint-Enhanced Reward for Long-form Generation Reinforcement Learning](https://arxiv.org/abs/2509.04903)
*Jianghao Chen,Wei Sun,Qixiang Yin,Lingxing Kong,Zhixing Tan,Jiajun Zhang*

Main category: cs.CL

TL;DR: ACE-RL是一个用于长文本生成的框架，通过将指令分解为细粒度约束条件，并设计相应的奖励机制，显著提高了LLM长文本生成的质量，超越了现有SOTA模型和GPT-4o。


<details>
  <summary>Details</summary>
Motivation: 现有长文本生成方法依赖稀缺的高质量数据，且仅关注粗粒度质量维度，忽视了长文本生成场景的细粒度特性。

Method: ACE-RL首先自动将指令分解为细粒度的约束条件，然后设计奖励机制量化响应质量，最后利用强化学习进行模型优化。

Result: ACE-RL在WritingBench上比SFT和RL基线分别提升了20.70%和7.32%，并且在长文本生成质量上超越了GPT-4o。

Conclusion: ACE-RL为LLM在多样化的长文本生成场景中生成高质量内容提供了一种更有效的训练范式。

Abstract: Large Language Models (LLMs) have demonstrated remarkable progress in
long-context understanding, yet they face significant challenges in
high-quality long-form generation. Existing studies primarily suffer from two
limitations: (1) A heavy reliance on scarce, high-quality long-form response
data for supervised fine-tuning (SFT) or for pairwise preference reward in
reinforcement learning (RL). (2) Focus on coarse-grained quality optimization
dimensions, such as relevance, coherence, and helpfulness, overlooking the
fine-grained specifics inherent to diverse long-form generation scenarios. To
address this issue, we propose a framework using Adaptive Constraint-Enhanced
reward for long-form generation Reinforcement Learning (ACE-RL). ACE-RL first
automatically deconstructs each instruction into a set of fine-grained,
adaptive constraint criteria by identifying its underlying intents and demands.
Subsequently, we design a reward mechanism that quantifies the quality of
long-form responses based on their satisfaction over corresponding constraints,
converting subjective quality evaluation into constraint verification. Finally,
we utilize reinforcement learning to guide models toward superior long-form
generation capabilities. Experimental results demonstrate that our ACE-RL
framework significantly outperforms existing SFT and RL baselines by 20.70% and
7.32% on WritingBench, and our top-performing model even surpasses proprietary
systems like GPT-4o by 7.10%, providing a more effective training paradigm for
LLMs to generate high-quality content across diverse long-form generation
scenarios.

</details>


### [131] [Classification of kinetic-related injury in hospital triage data using NLP](https://arxiv.org/abs/2509.04969)
*Midhun Shyam,Jim Basilakis,Kieran Luken,Steven Thomas,John Crozier,Paul M. Middleton,X. Rosalind Wang*

Main category: cs.CL

TL;DR: 本文提出了一种在有限计算资源下利用LLM对急诊分诊数据进行分类的流程，通过在GPU上使用少量开源数据对预训练LLM进行微调，然后在CPU上使用医院特定的1000个样本进一步微调，证明了在数据精心策划和利用现有模型及开源数据的条件下，可以成功实现分诊数据的分类。


<details>
  <summary>Details</summary>
Motivation: 急诊分诊记录包含了丰富的信息，可用于理解急诊科患者流行病学以及疾病或伤害的时间依赖性，但由于数据隐私、计算资源限制以及手动标注成本高昂，使得应用现代自然语言处理和机器学习技术分析该数据面临挑战。

Method: 首先，在GPU上使用2000个样本的开源数据集对预训练的LLM进行微调，并加入一个分类器；然后，在CPU上使用1000个医院特定的样本对模型进行进一步微调。

Result: 通过精心策划数据集并利用现有模型和开源数据，在有限的计算资源下成功分类了分诊数据。

Conclusion: 在有限的计算资源下，通过仔细策划数据集并利用现有模型和开源数据，可以成功地对急诊分诊数据进行分类。

Abstract: Triage notes, created at the start of a patient's hospital visit, contain a
wealth of information that can help medical staff and researchers understand
Emergency Department patient epidemiology and the degree of time-dependent
illness or injury. Unfortunately, applying modern Natural Language Processing
and Machine Learning techniques to analyse triage data faces some challenges:
Firstly, hospital data contains highly sensitive information that is subject to
privacy regulation thus need to be analysed on site; Secondly, most hospitals
and medical facilities lack the necessary hardware to fine-tune a Large
Language Model (LLM), much less training one from scratch; Lastly, to identify
the records of interest, expert inputs are needed to manually label the
datasets, which can be time-consuming and costly. We present in this paper a
pipeline that enables the classification of triage data using LLM and limited
compute resources. We first fine-tuned a pre-trained LLM with a classifier
using a small (2k) open sourced dataset on a GPU; and then further fine-tuned
the model with a hospital specific dataset of 1000 samples on a CPU. We
demonstrated that by carefully curating the datasets and leveraging existing
models and open sourced data, we can successfully classify triage data with
limited compute resources.

</details>


### [132] [Optimizing Small Transformer-Based Language Models for Multi-Label Sentiment Analysis in Short Texts](https://arxiv.org/abs/2509.04982)
*Julius Neumann,Robert Lange,Yuni Susanti,Michael Färber*

Main category: cs.CL

TL;DR: 小型 Transformer 模型（BERT 和 RoBERTa）在多标签短文本情感分类方面表现良好，其中数据增强效果显著，而继续预训练和分类头修改效果甚微。


<details>
  <summary>Details</summary>
Motivation: 短文本情感分类面临类别不平衡、训练样本有限、标签主观性强以及上下文信息有限等挑战，这加剧了歧义和数据稀疏性，阻碍了有效学习。

Method: 评估了小型 Transformer 模型（BERT 和 RoBERTa，参数量少于 10 亿）在多标签情感分类任务上的有效性，特别关注短文本场景。重点评估了三个因素：1. 继续进行领域特定的预训练；2. 使用自动生成的示例进行数据增强（生成式数据增强）；3. 分类头的架构变体。

Result: 数据增强提高了分类性能；在增强数据集上继续预训练会引入噪声而非提高准确性；分类头的修改带来的收益很小。

Conclusion: 实验结果为在资源受限环境下优化基于 BERT 的模型以及改进短文本数据集的情感分类策略提供了实践指导。

Abstract: Sentiment classification in short text datasets faces significant challenges
such as class imbalance, limited training samples, and the inherent
subjectivity of sentiment labels -- issues that are further intensified by the
limited context in short texts. These factors make it difficult to resolve
ambiguity and exacerbate data sparsity, hindering effective learning. In this
paper, we evaluate the effectiveness of small Transformer-based models (i.e.,
BERT and RoBERTa, with fewer than 1 billion parameters) for multi-label
sentiment classification, with a particular focus on short-text settings.
Specifically, we evaluated three key factors influencing model performance: (1)
continued domain-specific pre-training, (2) data augmentation using
automatically generated examples, specifically generative data augmentation,
and (3) architectural variations of the classification head. Our experiment
results show that data augmentation improves classification performance, while
continued pre-training on augmented datasets can introduce noise rather than
boost accuracy. Furthermore, we confirm that modifications to the
classification head yield only marginal benefits. These findings provide
practical guidance for optimizing BERT-based models in resource-constrained
settings and refining strategies for sentiment classification in short-text
datasets.

</details>


### [133] [Do Large Language Models Need Intent? Revisiting Response Generation Strategies for Service Assistant](https://arxiv.org/abs/2509.05006)
*Inbal Bolshinsky,Shani Kupiec,Almog Sasson,Yehudit Aperstein,Alexander Apartsin*

Main category: cs.CL

TL;DR: 在对话式AI中，显式意图识别并非生成高质量服务回复的先决条件，直接生成回复的模型也能取得良好效果。


<details>
  <summary>Details</summary>
Motivation: 探究显式意图识别是否为生成高质量服务回复的必要步骤，还是可以直接绕过。

Method: 利用两个公开的服务交互数据集，在“意图优先回复生成”和“直接回复生成”两种范式下，对包括微调的T5变体在内的几种先进语言模型进行了基准测试。

Result: 评估指标包括语言质量和任务成功率，结果显示显式意图建模的必要性或冗余性方面存在出人意料的见解。

Conclusion: 研究结果对对话式AI流程中的传统假设提出了挑战，为设计更有效、更高效的回复生成系统提供了可操作的指导。

Abstract: In the era of conversational AI, generating accurate and contextually
appropriate service responses remains a critical challenge. A central question
remains: Is explicit intent recognition a prerequisite for generating
high-quality service responses, or can models bypass this step and produce
effective replies directly? This paper conducts a rigorous comparative study to
address this fundamental design dilemma. Leveraging two publicly available
service interaction datasets, we benchmark several state-of-the-art language
models, including a fine-tuned T5 variant, across both paradigms: Intent-First
Response Generation and Direct Response Generation. Evaluation metrics
encompass both linguistic quality and task success rates, revealing surprising
insights into the necessity or redundancy of explicit intent modelling. Our
findings challenge conventional assumptions in conversational AI pipelines,
offering actionable guidelines for designing more efficient and effective
response generation systems.

</details>


### [134] [Masked Diffusion Language Models with Frequency-Informed Training](https://arxiv.org/abs/2509.05056)
*Despoina Kosmopoulou,Efthymios Georgiou,Vaggelis Dorovatas,Georgios Paraskevopoulos,Alexandros Potamianos*

Main category: cs.CL

TL;DR: We propose a masked diffusion language modeling framework for data-efficient training in the BabyLM 2025 Challenge, showing competitive performance against baselines.


<details>
  <summary>Details</summary>
Motivation: The motivation is to develop a data-efficient training framework for language modeling under strict data constraints, specifically for the BabyLM 2025 Challenge.

Method: The method involves applying diffusion training objectives to language modeling with frequency-informed masking, exploring various noise scheduling strategies (including two-mode approaches), and investigating different noise weighting schemes within the NELBO objective.

Result: The results demonstrate performance competitive to hybrid autoregressive-masked baselines on the BabyLM benchmark suite, measuring linguistic competence, world knowledge, and human-likeness.

Conclusion: The conclusion is that diffusion-based training is a viable alternative for data-restricted language learning.

Abstract: We present a masked diffusion language modeling framework for data-efficient
training for the BabyLM 2025 Challenge. Our approach applies diffusion training
objectives to language modeling under strict data constraints, incorporating
frequency-informed masking that prioritizes learning from rare tokens while
maintaining theoretical validity. We explore multiple noise scheduling
strategies, including two-mode approaches, and investigate different noise
weighting schemes within the NELBO objective. We evaluate our method on the
BabyLM benchmark suite, measuring linguistic competence, world knowledge, and
human-likeness. Results show performance competitive to hybrid
autoregressive-masked baselines, demonstrating that diffusion-based training
offers a viable alternative for data-restricted language learning.

</details>


### [135] [Entropy2Vec: Crosslingual Language Modeling Entropy as End-to-End Learnable Language Representations](https://arxiv.org/abs/2509.05060)
*Patrick Amadeus Irawan,Ryandito Diandaru,Belati Jagad Bintang Syuhada,Randy Zakya Suchrady,Alham Fikri Aji,Genta Indra Winata,Fajri Koto,Samuel Cahyawijaya*

Main category: cs.CL

TL;DR: Entropy2Vec框架利用单语语言模型的熵来获得跨语言表示，克服了传统语言类型学方法的局限性，并在下游多语言NLP任务中取得了有竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的语言类型学方法存在特征稀疏和静态快照的问题，而Entropy2Vec旨在利用语言模型中固有的不确定性来捕捉语言之间的类型学关系。

Method: 通过在单一语言上训练语言模型，并假设其预测的熵反映了与其他语言的结构相似性（低熵表示高相似性，高熵表示大分歧），从而生成密集、非稀疏且可适应不同时间范围、无缺失值的语言嵌入。

Result: Entropy2Vec嵌入与已建立的语言类型学类别一致，并在下游多语言NLP任务（如LinguAlchemy框架所解决的任务）中取得了有竞争力的性能。

Conclusion: Entropy2Vec提供了一种新颖有效的方法来生成跨语言表示，克服了传统方法的缺点，并在多语言NLP应用中展现出潜力。

Abstract: We introduce Entropy2Vec, a novel framework for deriving cross-lingual
language representations by leveraging the entropy of monolingual language
models. Unlike traditional typological inventories that suffer from feature
sparsity and static snapshots, Entropy2Vec uses the inherent uncertainty in
language models to capture typological relationships between languages. By
training a language model on a single language, we hypothesize that the entropy
of its predictions reflects its structural similarity to other languages: Low
entropy indicates high similarity, while high entropy suggests greater
divergence. This approach yields dense, non-sparse language embeddings that are
adaptable to different timeframes and free from missing values. Empirical
evaluations demonstrate that Entropy2Vec embeddings align with established
typological categories and achieved competitive performance in downstream
multilingual NLP tasks, such as those addressed by the LinguAlchemy framework.

</details>


### [136] [ToM-SSI: Evaluating Theory of Mind in Situated Social Interactions](https://arxiv.org/abs/2509.05066)
*Matteo Bortoletto,Constantin Ruhdorfer,Andreas Bulling*

Main category: cs.CL

TL;DR: 现有的心理理论（ToM）基准测试未能充分反映人类社交的复杂性，因此我们提出了ToM-SSI，一个包含多模态、多主体交互和空间动态的新基准，以更全面地评估模型能力。


<details>
  <summary>Details</summary>
Motivation: 现有ToM基准测试（如Sally-Anne测试）视角有限，无法全面评估模型在复杂人类社交互动中的ToM能力。

Method: 提出ToM-SSI基准测试，该测试为多模态，包含多达四个智能体的群体交互，并能在情境化环境中进行通信和移动，模拟了混合合作-阻碍设置，并支持并行推理多个智能体的心理状态。

Result: 现有模型在ToM-SSI基准测试上的表现仍然有限，尤其是在新的任务上，暴露了未来研究的关键不足。

Conclusion: ToM-SSI基准测试能更全面地捕捉社交认知能力，并揭示了现有模型在处理复杂多智能体交互方面的局限性，为未来研究指明了方向。

Abstract: Most existing Theory of Mind (ToM) benchmarks for foundation models rely on
variations of the Sally-Anne test, offering only a very limited perspective on
ToM and neglecting the complexity of human social interactions. To address this
gap, we propose ToM-SSI: a new benchmark specifically designed to test ToM
capabilities in environments rich with social interactions and spatial
dynamics. While current ToM benchmarks are limited to text-only or dyadic
interactions, ToM-SSI is multimodal and includes group interactions of up to
four agents that communicate and move in situated environments. This unique
design allows us to study, for the first time, mixed cooperative-obstructive
settings and reasoning about multiple agents' mental state in parallel, thus
capturing a wider range of social cognition than existing benchmarks. Our
evaluations reveal that the current models' performance is still severely
limited, especially in these new tasks, highlighting critical gaps for future
research.

</details>


### [137] [ICR: Iterative Clarification and Rewriting for Conversational Search](https://arxiv.org/abs/2509.05100)
*Zhiyu Cao,Peifeng Li,Qiaoming Zhu*

Main category: cs.CL

TL;DR: 该研究提出了一种名为ICR（迭代澄清和改写）的新框架，通过生成澄清问题和改写查询的迭代过程来解决对话式查询改写中多模糊表达的问题，并在两个流行的数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 先前的端到端改写方法难以同时处理和改写查询中的多个模糊表达。

Method: 提出ICR框架，该框架通过迭代地生成澄清问题和改写查询来工作。

Result: ICR在迭代过程中持续改进检索性能，并在两个流行的数据集上实现了最先进的性能。

Conclusion: ICR框架通过迭代澄清和改写，能够有效地处理对话式查询中的多模糊表达问题，并提升检索性能。

Abstract: Most previous work on Conversational Query Rewriting employs an end-to-end
rewriting paradigm. However, this approach is hindered by the issue of multiple
fuzzy expressions within the query, which complicates the simultaneous
identification and rewriting of multiple positions. To address this issue, we
propose a novel framework ICR (Iterative Clarification and Rewriting), an
iterative rewriting scheme that pivots on clarification questions. Within this
framework, the model alternates between generating clarification questions and
rewritten queries. The experimental results show that our ICR can continuously
improve retrieval performance in the clarification-rewriting iterative process,
thereby achieving state-of-the-art performance on two popular datasets.

</details>


### [138] [Triadic Fusion of Cognitive, Functional, and Causal Dimensions for Explainable LLMs: The TAXAL Framework](https://arxiv.org/abs/2509.05199)
*David Herrera-Poyatos,Carlos Peláez-González,Cristina Zuheros,Virilo Tejedor,Rosana Montes,Francisco Herrera*

Main category: cs.CL

TL;DR: Agentic LLMs in high-risk domains lack trustworthiness due to opacity, bias, and instability. Existing explainability methods are insufficient. We propose TAXAL, a triadic fusion framework (cognitive, functional, causal) to unify and evaluate explanations for agentic LLMs, enhancing their trustworthiness and context-sensitivity across various applications.


<details>
  <summary>Details</summary>
Motivation: Traditional explainability methods for LLMs are inadequate for high-risk domains as they fail to address opacity, bias, instability, and the complex reasoning of agentic LLMs. There is a need for a comprehensive framework to ensure trust and accountability.

Method: We introduce TAXAL (Triadic Alignment for eXplainability in Agentic LLMs), a novel framework that integrates cognitive (user understanding), functional (practical utility), and causal (faithful reasoning) dimensions. This framework synthesizes existing explainability methods and demonstrates its utility through case studies in law, education, healthcare, and public services, adapting explanation strategies to specific contexts and roles.

Result: TAXAL provides a unified, role-sensitive foundation for designing, evaluating, and deploying explanations for agentic LLMs. Case studies show its applicability in diverse sociotechnical settings, highlighting how explanation strategies can be adapted to institutional constraints and stakeholder roles.

Conclusion: TAXAL advances explainability as both a technical and sociotechnical practice by offering conceptual clarity, design patterns, and deployment pathways. This framework supports the development of trustworthy and context-sensitive LLM applications in the age of agentic AI.

Abstract: Large Language Models (LLMs) are increasingly being deployed in high-risk
domains where opacity, bias, and instability undermine trust and
accountability. Traditional explainability methods, focused on surface outputs,
do not capture the reasoning pathways, planning logic, and systemic impacts of
agentic LLMs.
  We introduce TAXAL (Triadic Alignment for eXplainability in Agentic LLMs), a
triadic fusion framework that unites three complementary dimensions: cognitive
(user understanding), functional (practical utility), and causal (faithful
reasoning). TAXAL provides a unified, role-sensitive foundation for designing,
evaluating, and deploying explanations in diverse sociotechnical settings.
  Our analysis synthesizes existing methods, ranging from post-hoc attribution
and dialogic interfaces to explanation-aware prompting, and situates them
within the TAXAL triadic fusion model. We further demonstrate its applicability
through case studies in law, education, healthcare, and public services,
showing how explanation strategies adapt to institutional constraints and
stakeholder roles.
  By combining conceptual clarity with design patterns and deployment pathways,
TAXAL advances explainability as a technical and sociotechnical practice,
supporting trustworthy and context-sensitive LLM applications in the era of
agentic AI.

</details>


### [139] [Hunyuan-MT Technical Report](https://arxiv.org/abs/2509.05209)
*Mao Zheng,Zheng Li,Bingxin Qu,Mingyang Song,Yang Du,Mingrui Sun,Di Wang*

Main category: cs.CL

TL;DR: Hunyuan-MT-7B是一个支持33种语言的开源多语言翻译模型，Hunyuan-MT-Chimera-7B在此基础上引入了“慢思考”模式，提高了翻译性能。


<details>
  <summary>Details</summary>
Motivation: 满足多样化的翻译场景并提升模型在测试时的性能。

Method: 采用包括通用和MT导向的预训练、监督微调（SFT）以及强化学习（RL）和弱到强RL的对齐等整体训练流程。

Result: Hunyuan-MT-7B和Hunyuan-MT-Chimera-7B在与同等参数量级的翻译模型以及大多数SOTA大型模型的比较中，在普通话与少数民族语言及方言的翻译任务上表现显著优越。在WMT2025共享任务（通用机器翻译）中，在31个语言对中的30个排名第一。

Conclusion: 所提出的模型在广泛的语言范围内（包括高资源和低资源语言）都表现出了强大的鲁棒性。

Abstract: In this report, we introduce Hunyuan-MT-7B, our first open-source
multilingual translation model, which supports bidirectional translation across
33 major languages and places a special emphasis on translation between
Mandarin and several ethnic minority languages as well as dialects.
Furthermore, to serve and address diverse translation scenarios and enhance
model performance at test time, we introduce Hunyuan-MT-Chimera-7B, a
translation model inspired by the slow thinking mode. This model integrates
multiple outputs generated by the Hunyuan-MT-7B model under varying parameter
settings, thereby achieving performance superior to that of conventional
slow-thinking models based on Chain-of-Thought (CoT). The development of our
models follows a holistic training process specifically engineered for
multilingual translation, which begins with general and MT-oriented
pre-training to build foundational capabilities, proceeds to Supervised
Fine-Tuning (SFT) for task-specific adaptation, and culminates in advanced
alignment through Reinforcement Learning (RL) and weak-to-strong RL. Through
comprehensive experimentation, we demonstrate that both Hunyuan-MT-7B and
Hunyuan-MT-Chimera-7B significantly outperform all translation-specific models
of comparable parameter size and most of the SOTA large models, particularly on
the task of translation between Mandarin and minority languages as well as
dialects. In the WMT2025 shared task (General Machine Translation), our models
demonstrate state-of-the-art performance, ranking first in 30 out of 31
language pairs. This result highlights the robustness of our models across a
diverse linguistic spectrum, encompassing high-resource languages such as
Chinese, English, and Japanese, as well as low-resource languages including
Czech, Marathi, Estonian, and Icelandic.

</details>


### [140] [BEDTime: A Unified Benchmark for Automatically Describing Time Series](https://arxiv.org/abs/2509.05215)
*Medhasweta Sen,Zachary Gottesman,Jiaxing Qiu,C. Bayan Bruss,Nam Nguyen,Tom Hartvigsen*

Main category: cs.CL

TL;DR: 该研究提出了一个标准化的时间序列分析基准，包含识别、区分和生成三个任务，旨在促进模型间的直接比较，并评估了13种现有模型，发现多模态模型表现优于纯语言模型，但仍有提升空间，且所有模型在鲁棒性测试中均表现出脆弱性。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列分析模型的研究缺乏统一的评估数据集和任务，导致模型间的直接比较困难，也无法明确不同能力对整体性能的贡献。因此，需要一个标准化的评估框架来解决这些问题。

Method: 研究提出了三个用于评估时间序列描述能力的自然语言任务：识别（问答）、区分（多项选择）和生成（开放式描述）。整合了四个现有数据集以支持跨模型比较。实验中评估了13种先进的语言、视觉-语言和时间序列-语言模型。

Result: 评估结果显示：1. 纯语言模型表现不佳，表明需要专门的时间序列模型。2. 视觉-语言模型（VLMs）表现成功，验证了视觉模型在此类任务中的价值。3. 预训练的多模态时间序列-语言模型优于大型语言模型（LLMs），但仍有改进空间。4. 所有模型在鲁棒性测试中均显示出明显的脆弱性。

Conclusion: 该基准提供了一个标准化的评估方法，对于时间序列推理系统是必要的。研究结果表明，多模态模型在时间序列分析任务中具有潜力，但还需要进一步的研究来提高其性能和鲁棒性。

Abstract: Many recent studies have proposed general-purpose foundation models designed
for a variety of time series analysis tasks. While several established datasets
already exist for evaluating these models, previous works frequently introduce
their models in conjunction with new datasets, limiting opportunities for
direct, independent comparisons and obscuring insights into the relative
strengths of different methods. Additionally, prior evaluations often cover
numerous tasks simultaneously, assessing a broad range of model abilities
without clearly pinpointing which capabilities contribute to overall
performance. To address these gaps, we formalize and evaluate 3 tasks that test
a model's ability to describe time series using generic natural language: (1)
recognition (True/False question-answering), (2) differentiation (multiple
choice question-answering), and (3) generation (open-ended natural language
description). We then unify 4 recent datasets to enable head-to-head model
comparisons on each task. Experimentally, in evaluating 13 state-of-the-art
language, vision--language, and time series--language models, we find that (1)
popular language-only methods largely underperform, indicating a need for time
series-specific architectures, (2) VLMs are quite successful, as expected,
identifying the value of vision models for these tasks and (3) pretrained
multimodal time series--language models successfully outperform LLMs, but still
have significant room for improvement. We also find that all approaches exhibit
clear fragility in a range of robustness tests. Overall, our benchmark provides
a standardized evaluation on a task necessary for time series reasoning
systems.

</details>


### [141] [CURE: Controlled Unlearning for Robust Embeddings -- Mitigating Conceptual Shortcuts in Pre-Trained Language Models](https://arxiv.org/abs/2509.05230)
*Aysenur Kocak,Shuo Yang,Bardh Prenkaj,Gjergji Kasneci*

Main category: cs.CL

TL;DR: CURE框架通过解耦并抑制概念偏差来提高语言模型的鲁棒性和公平性，在IMDB和Yelp数据集上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 预训练语言模型容易受到杂乱、以概念为驱动的相关性影响，从而损害模型的鲁棒性和公平性。

Method: CURE框架首先通过一个由反向网络增强的内容提取器提取与概念无关的表示，然后使用对比学习的可控去偏模块来调整残余概念线索的影响。

Result: 在IMDB数据集上，CURE的F1分数提高了10个百分点，在Yelp数据集上提高了2个百分点，同时计算开销极小。

Conclusion: CURE提供了一个灵活的、无监督的解决方案，用于对抗概念偏差，有助于构建更可靠、更公平的语言理解系统。

Abstract: Pre-trained language models have achieved remarkable success across diverse
applications but remain susceptible to spurious, concept-driven correlations
that impair robustness and fairness. In this work, we introduce CURE, a novel
and lightweight framework that systematically disentangles and suppresses
conceptual shortcuts while preserving essential content information. Our method
first extracts concept-irrelevant representations via a dedicated content
extractor reinforced by a reversal network, ensuring minimal loss of
task-relevant information. A subsequent controllable debiasing module employs
contrastive learning to finely adjust the influence of residual conceptual
cues, enabling the model to either diminish harmful biases or harness
beneficial correlations as appropriate for the target task. Evaluated on the
IMDB and Yelp datasets using three pre-trained architectures, CURE achieves an
absolute improvement of +10 points in F1 score on IMDB and +2 points on Yelp,
while introducing minimal computational overhead. Our approach establishes a
flexible, unsupervised blueprint for combating conceptual biases, paving the
way for more reliable and fair language understanding systems.

</details>


### [142] [HoPE: Hyperbolic Rotary Positional Encoding for Stable Long-Range Dependency Modeling in Large Language Models](https://arxiv.org/abs/2509.05218)
*Chang Dai,Hongyu Shan,Mingyang Song,Di Liang*

Main category: cs.CL

TL;DR: RoPE的局限性通过基于双曲几何的洛伦兹变换得到了解决，提出了一种新的位置编码方法HoPE，该方法在长序列上表现更好。


<details>
  <summary>Details</summary>
Motivation: 现有的位置编码方法（如绝对位置编码、Alibi和RoPE）在处理长序列时存在外推性差、性能下降或长距离依赖建模不稳定等问题。

Method: 提出了一种基于双曲几何的洛伦兹变换的位置编码方法HoPE，利用双曲函数实现标记表示上的洛伦兹旋转。理论上证明RoPE是HoPE的特例。

Result: HoPE解决了RoPE的振荡问题，通过强制注意力权重随标记距离的增加而单调衰减，在多个长序列基准测试中，HoPE的困惑度评估结果持续优于现有方法。

Conclusion: HoPE在表示和泛化长距离依赖方面具有更强的能力，解决了现有位置编码方法的局限性。

Abstract: Positional encoding mechanisms enable Transformers to model sequential
structure and long-range dependencies in text. While absolute positional
encodings struggle with extrapolation to longer sequences due to fixed
positional representations, and relative approaches like Alibi exhibit
performance degradation on extremely long contexts, the widely-used Rotary
Positional Encoding (RoPE) introduces oscillatory attention patterns that
hinder stable long-distance dependency modelling. We address these limitations
through a geometric reformulation of positional encoding. Drawing inspiration
from Lorentz transformations in hyperbolic geometry, we propose Hyperbolic
Rotary Positional Encoding (HoPE), which leverages hyperbolic functions to
implement Lorentz rotations on token representations. Theoretical analysis
demonstrates that RoPE is a special case of our generalized formulation. HoPE
fundamentally resolves RoPE's slation issues by enforcing monotonic decay of
attention weights with increasing token distances. Extensive experimental
results, including perplexity evaluations under several extended sequence
benchmarks, show that HoPE consistently exceeds existing positional encoding
methods. These findings underscore HoPE's enhanced capacity for representing
and generalizing long-range dependencies. Data and code will be available.

</details>


### [143] [Less is More Tokens: Efficient Math Reasoning via Difficulty-Aware Chain-of-Thought Distillation](https://arxiv.org/abs/2509.05226)
*Abdul Waheed,Chancharik Mitra,Laurie Z. Wang,Deva Ramanan,Bhiksha Raj*

Main category: cs.CL

TL;DR: Chain-of-thought reasoning can be too verbose for simple problems. This paper introduces difficulty-aware reasoning, where models adjust reasoning depth based on problem complexity, without architectural changes. Post-training with curated data teaches models to 


<details>
  <summary>Details</summary>
Motivation: Chain-of-thought reasoning, while powerful, often produces unnecessarily verbose output for simpler problems. There is a need for models to dynamically adjust reasoning depth based on problem complexity.

Method: The paper presents a framework for difficulty-aware reasoning. This is achieved by post-training models on data carefully curated to include chain-of-thought traces proportional in length to problem difficulty. Both supervised fine-tuning (SFT) and direct preference optimization (DPO) are explored, along with their combination.

Result: Models trained with this framework learn to adjust reasoning depth based on problem complexity, producing shorter reasoning for simpler problems and maintaining depth for complex ones. SFT primarily captures reasoning length and format, while DPO preserves reasoning accuracy. The combination of SFT and DPO reduces length while maintaining or improving performance.

Conclusion: Models can be taught to perform difficulty-aware reasoning, "thinking proportionally" by adjusting reasoning depth to problem complexity, without requiring architectural modifications. This approach leads to more efficient reasoning without sacrificing performance.

Abstract: Chain-of-thought reasoning, while powerful, can produce unnecessarily verbose
output for simpler problems. We present a framework for difficulty-aware
reasoning that teaches models to dynamically adjust reasoning depth based on
problem complexity. Remarkably, we show that models can be endowed with such
dynamic inference pathways without any architectural modifications; we simply
post-train on data that is carefully curated to include chain-of-thought traces
that are proportional in length to problem difficulty. Our analysis reveals
that post-training via supervised fine-tuning (SFT) primarily captures patterns
like reasoning length and format, while direct preference optimization (DPO)
preserves reasoning accuracy, with their combination reducing length and
maintaining or improving performance. Both quantitative metrics and qualitative
assessments confirm that models can learn to "think proportionally", reasoning
minimally on simple problems while maintaining depth for complex ones.

</details>


### [144] [Crosscoding Through Time: Tracking Emergence & Consolidation Of Linguistic Representations Throughout LLM Pretraining](https://arxiv.org/abs/2509.05291)
*Deniz Bayazit,Aaron Mueller,Antoine Bosselut*

Main category: cs.CL

TL;DR: LLMs在预训练中学习到如不规则名词复数主语检测等非平凡的抽象概念，但具体能力何时以及如何出现尚不清楚，因为传统评估方法（如基准测试）无法揭示模型概念和能力的获取方式。本研究使用稀疏交叉编码器来发现和对齐模型检查点中的特征，从而追踪预训练过程中语言特征的演变。研究人员在具有显著性能和表示变化的开源检查点三元组之间训练交叉编码器，并引入了一种新颖的度量方法——相对间接效应（RelIE）——来追踪哪些个体特征在任务性能中起因果作用的训练阶段。研究表明，交叉编码器能够检测预训练过程中特征的出现、维持和消失。该方法不依赖于特定架构且可扩展，为在预训练过程中更精细地分析表示学习提供了有前景的途径。


<details>
  <summary>Details</summary>
Motivation: 理解大型语言模型（LLMs）在预训练过程中具体语言能力（例如，不规则名词复数主语检测）何时以及如何出现，因为传统的评估方法（如基准测试）无法揭示模型概念和能力的获取方式。

Method: 使用稀疏交叉编码器来发现和对齐模型检查点中的特征，以追踪预训练过程中语言特征的演变。在具有显著性能和表示变化的开源检查点三元组之间训练交叉编码器，并引入相对间接效应（RelIE）度量来追踪个体特征在任务性能中起因果作用的训练阶段。

Result: 交叉编码器能够检测预训练过程中语言特征的出现、维持和消失。RelIE度量能够追踪特征对任务性能的因果重要性。

Conclusion: 所提出的基于稀疏交叉编码器和RelIE度量的方法是一种不依赖于特定架构且可扩展的途径，可以更精细地分析表示学习，从而更好地理解LLMs在预训练过程中语言能力的出现和发展。

Abstract: Large language models (LLMs) learn non-trivial abstractions during
pretraining, like detecting irregular plural noun subjects. However, it is not
well understood when and how specific linguistic abilities emerge as
traditional evaluation methods such as benchmarking fail to reveal how models
acquire concepts and capabilities. To bridge this gap and better understand
model training at the concept level, we use sparse crosscoders to discover and
align features across model checkpoints. Using this approach, we track the
evolution of linguistic features during pretraining. We train crosscoders
between open-sourced checkpoint triplets with significant performance and
representation shifts, and introduce a novel metric, Relative Indirect Effects
(RelIE), to trace training stages at which individual features become causally
important for task performance. We show that crosscoders can detect feature
emergence, maintenance, and discontinuation during pretraining. Our approach is
architecture-agnostic and scalable, offering a promising path toward more
interpretable and fine-grained analysis of representation learning throughout
pretraining.

</details>


### [145] [Uniform Information Density and Syntactic Reduction: Revisiting $\textit{that}$-Mentioning in English Complement Clauses](https://arxiv.org/abs/2509.05254)
*Hailin Hao,Elsi Kaiser*

Main category: cs.CL

TL;DR: 说话者可以通过多种方式表达相同的意思，信息密度假说认为说话者会利用这种变化来保持信息传递的速率一致。本研究通过分析一个大规模的当代语料库，并利用机器学习和神经语言模型来研究信息密度与英语从句中“that”省略的关系。研究结果证实了信息密度与“that”省略之间的关系，并发现基于上下文词嵌入的信息密度估计比基于主语动词的子类划分概率更能解释“that”省略的变异。


<details>
  <summary>Details</summary>
Motivation: 说话者会利用句子结构的变化来维持信息传递的速率一致性。

Method: 分析了一个包含对话的语料库，并使用了机器学习和神经语言模型来估计信息密度。

Result: 重申了信息密度与“that”省略之间的关系，并发现基于上下文词嵌入的信息密度估计比基于主语动词的子类划分概率更能解释“that”省略的变异。

Conclusion: 基于上下文词嵌入的信息密度估计比传统的基于子类划分概率的方法更能准确地预测“that”的省略。

Abstract: Speakers often have multiple ways to express the same meaning. The Uniform
Information Density (UID) hypothesis suggests that speakers exploit this
variability to maintain a consistent rate of information transmission during
language production. Building on prior work linking UID to syntactic reduction,
we revisit the finding that the optional complementizer $\textit{that}$in
English complement clauses is more likely to be omitted when the clause has low
information density (i.e., more predictable). We advance this line of research
by analyzing a large-scale, contemporary conversational corpus and using
machine learning and neural language models to refine estimates of information
density. Our results replicated the established relationship between
information density and $\textit{that}$-mentioning. However, we found that
previous measures of information density based on matrix verbs'
subcategorization probability capture substantial idiosyncratic lexical
variation. By contrast, estimates derived from contextual word embeddings
account for additional variance in patterns of complementizer usage.

</details>


### [146] [Elucidating the Design Space of Decay in Linear Attention](https://arxiv.org/abs/2509.05282)
*Zhen Qin,Xuyang Shen,Yiran Zhong*

Main category: cs.CL

TL;DR: 该论文研究了线性复杂度的序列模型中的衰减机制，探讨了参数化策略、参数共享、衰减粒度和与相对位置编码的兼容性等问题，并通过大量实验揭示了各项因素对模型性能的影响。


<details>
  <summary>Details</summary>
Motivation: 为了深入理解和优化线性复杂度序列模型中的衰减机制，本研究系统地探索了衰减设计的各个方面。

Method: 通过在参数化策略、参数共享、衰减粒度和与RoPE的兼容性这四个维度上进行系统性分析，并进行了广泛的实验。

Result: 研究发现：1. 参数化策略的设计至关重要，有效的配置通常局限于特定的参数范围。2. 参数共享需谨慎使用，否则可能导致衰减值过大或过小，影响性能。3. 在相同的参数化策略下，标量衰减通常不如向量衰减，但在某些特定情况下，标量衰减可能更优。4. RoPE通常不能为大多数线性注意力机制带来明显的好处。

Conclusion: 衰减机制的设计对线性复杂度序列模型的性能有显著影响，需要仔细考虑各项因素，包括参数化策略、参数共享和衰减粒度。此外，RoPE对大多数线性注意力机制的增益有限。

Abstract: This paper presents a comprehensive investigation into the decay mechanisms
inherent in linear complexity sequence models. We systematically delineate the
design space of decay mechanisms across four pivotal dimensions:
parameterization strategy, which refers to the computational methodology for
decay; parameter sharing, which involves the utilization of supplementary
parameters for decay computation; decay granularity, comparing scalar versus
vector-based decay; and compatibility with relative positional encoding
methods, such as Rotary Position Embedding (RoPE). Through an extensive series
of experiments conducted on diverse language modeling tasks, we uncovered
several critical insights. Firstly, the design of the parameterization strategy
for decay requires meticulous consideration. Our findings indicate that
effective configurations are typically confined to a specific range of
parameters. Secondly, parameter sharing cannot be used arbitrarily, as it may
cause decay values to be too large or too small, thereby significantly
impacting performance. Thirdly, under identical parameterization strategies,
scalar decay generally underperforms compared to its vector-based counterpart.
However, in certain scenarios with alternative parameterization strategies,
scalar decay may unexpectedly surpass vector decay in efficacy. Lastly, our
analysis reveals that RoPE, a commonly employed relative positional encoding
method, typically fails to provide tangible benefits to the majority of linear
attention mechanisms.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [147] [Memristor-Based Neural Network Accelerators for Space Applications: Enhancing Performance with Temporal Averaging and SIRENs](https://arxiv.org/abs/2509.04506)
*Zacharia A. Rudge,Dominik Dold,Moritz Fieback,Dario Izzo,Said Hamdioui*

Main category: eess.SY

TL;DR: Memristor-based NNs show potential for space applications despite device non-idealities, with performance improvements shown through specific techniques.


<details>
  <summary>Details</summary>
Motivation: Memristors offer energy efficiency and radiation robustness for AI on spacecraft, but suffer from non-idealities causing performance degradation in NNs. This work aims to overcome these challenges for reliable and precise on-board computations.

Method: The paper utilizes bit-slicing, temporal averaging of NN layers, and periodic activation functions to improve the performance of memristor-based NNs. Simulations were conducted on tasks like navigation & control and geodesy of asteroids using RRAM devices.

Result: Through the implemented techniques, the error rates for the tested tasks were significantly reduced. For navigation & control, the error decreased from 0.07 to 0.01, and for geodesy of asteroids, it dropped from 0.3 to 0.007. These results approach state-of-the-art performance levels.

Conclusion: Memristors have demonstrated their potential for on-board space applications, and further advancements in technology and NNs are expected to close the performance gap, fully realizing the benefits of memristors.

Abstract: Memristors are an emerging technology that enables artificial intelligence
(AI) accelerators with high energy efficiency and radiation robustness --
properties that are vital for the deployment of AI on-board spacecraft.
However, space applications require reliable and precise computations, while
memristive devices suffer from non-idealities, such as device variability,
conductance drifts, and device faults. Thus, porting neural networks (NNs) to
memristive devices often faces the challenge of severe performance degradation.
In this work, we show in simulations that memristor-based NNs achieve
competitive performance levels on on-board tasks, such as navigation \& control
and geodesy of asteroids. Through bit-slicing, temporal averaging of NN layers,
and periodic activation functions, we improve initial results from around
$0.07$ to $0.01$ and $0.3$ to $0.007$ for both tasks using RRAM devices, coming
close to state-of-the-art levels ($0.003-0.005$ and $0.003$, respectively). Our
results demonstrate the potential of memristors for on-board space
applications, and we are convinced that future technology and NN improvements
will further close the performance gap to fully unlock the benefits of
memristors.

</details>


### [148] [PRREACH: Probabilistic Risk Assessment Using Reachability for UAV Control](https://arxiv.org/abs/2509.04451)
*Nicole Fronda,Hariharan Narayanan,Sadia Afrin Ananna,Steven Weber,Houssam Abbas*

Main category: eess.SY

TL;DR: 本研究提出了一种名为PRReach的新方法，用于为无人机（UAV）设计风险约束控制器，解决了现有方法在数据依赖和缺乏风险缓解控制方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有无人机风险评估方法依赖于条件概率，但数据不足难以实施，且缺乏风险缓解控制手段。本研究旨在提出一种新的风险评估和控制方法。

Method: PRReach方法基于无人机动力学，利用可达性分析对所有可行轨迹进行概率风险评估，并以此为基础构建控制优化问题，在最小化对现有控制律改动的前提下，将风险控制在可接受阈值内。

Result: PRReach方法通过仿真实验评估，在线和离线风险评估和缓解效果显著。与经典控制器相比，PRReach离线风险降低高达24%，在线风险降低高达53%。

Conclusion: PRReach方法利用公开的无人机动力学模型和空间数据，能够进行实际的离线和在线风险评估与缓解，有效降低无人机运行风险。

Abstract: We present a new approach for designing risk-bounded controllers for Uncrewed
Aerial Vehicles (UAVs). Existing frameworks for assessing risk of UAV
operations rely on knowing the conditional probability of an incident occurring
given different causes. Limited data for computing these probabilities makes
real-world implementation of these frameworks difficult. Furthermore, existing
frameworks do not include control methods for risk mitigation. Our approach
relies on UAV dynamics, and employs reachability analysis for a probabilistic
risk assessment over all feasible UAV trajectories. We use this holistic risk
assessment to formulate a control optimization problem that minimally changes a
UAV's existing control law to be bounded by an accepted risk threshold. We call
our approach PRReach. Public and readily available UAV dynamics models and open
source spatial data for mapping hazard outcomes enables practical
implementation of PRReach for both offline pre-flight and online in-flight risk
assessment and mitigation. We evaluate PRReach through simulation experiments
on real-world data. Results show that PRReach controllers reduce risk by up to
24% offline, and up to 53% online from classical controllers.

</details>


### [149] [Indifference-Zone Relaxation Procedures for Finding Feasible Systems](https://arxiv.org/abs/2509.04514)
*Yuwei Zhou,Sigrún Andradóttir,Seong-Hee Kim,Chuljin Park*

Main category: eess.SY

TL;DR: IZR和IZE程序通过引入一系列宽松的容差水平，并结合子程序来识别清晰可行或清晰不可行的系统，从而在保持统计有效性的同时，提高了在随机约束下寻找可行系统的计算效率，并且通过实验证明比现有程序所需的模拟次数更少。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理随机约束下的系统可行性问题时，要么因固定容差而导致不必要的模拟，要么在系统性能接近阈值时表现不佳。本研究旨在提高计算效率和统计有效性。

Method: 提出了一种名为IZR（Indifference-Zone Relaxation）的新程序，该程序引入了一系列宽松的容差水平，并利用两个子程序分别识别清晰可行和清晰不可行的系统。此外，还提出了IZR with estimation（IZE）程序，该程序为每个系统和约束引入两个宽松容差水平，一个匹配原始容差，另一个基于系统性能度量估计。

Result: 证明了IZR和IZE程序能够以期望的概率确定系统可行性，并通过实验表明，与现有程序相比，它们显著减少了所需的观测次数。

Conclusion: IZR和IZE程序通过引入宽松的容差水平和有效的子程序，能够更高效、更可靠地确定随机约束下的系统可行性，解决了现有方法的局限性。

Abstract: We consider the problem of finding feasible systems with respect to
stochastic constraints when system performance is evaluated through simulation.
Our objective is to solve this problem with high computational efficiency and
statistical validity. Existing indifference-zone (IZ) procedures introduce a
fixed tolerance level, which denotes how much deviation the decision-maker is
willing to accept from the threshold in the constraint. These procedures are
developed under the assumption that all systems' performance measures are
exactly the tolerance level away from the threshold, leading to unnecessary
simulations. In contrast, IZ-free procedures, which eliminate the tolerance
level, perform well when systems' performance measures are far from the
threshold. However, they may significantly underperform compared to IZ
procedures when systems' performance measures are close to the threshold. To
address these challenges, we propose the Indifference-Zone Relaxation (IZR)
procedure, IZR introduces a set of relaxed tolerance levels and utilizes two
subroutines for each level: one to identify systems that are clearly feasible
and the other to exclude those that are clearly infeasible. We also develop the
IZR procedure with estimation (IZE), which introduces two relaxed tolerance
levels for each system and constraint: one matching the original tolerance
level and the other based on an estimate of the system's performance measure.
By employing different tolerance levels, these procedures facilitate early
feasibility determination with statistical validity. We prove that IZR and IZE
determine system feasibility with the desired probability and show through
experiments that they significantly reduce the number of observations required
compared to an existing procedure.

</details>


### [150] [Resource-Oriented Optimization of Electric Vehicle Systems: A Data-Driven Survey on Charging Infrastructure, Scheduling, and Fleet Management](https://arxiv.org/abs/2509.04533)
*Hai Wang,Baoshen Guo,Xiaolei Zhou,Shuai Wang,Zhiqing Hong,Tian He*

Main category: eess.SY

TL;DR: 电动汽车（EV）发展迅速，但面临充电站拥堵、高充电成本和充电需求与客运服务需求冲突等挑战。本文综述了解决这些问题的现有数据驱动模型和方法，涵盖了充电站部署、充电调度和车队管理等全生命周期，并讨论了电动汽车整合对人类出行、智能电网和环境可持续性的影响，最后指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 空气质量和能源安全问题促使电动汽车（EV）快速发展，但其仍面临充电站拥堵、高充电成本以及充电需求与客运服务需求之间的冲突等核心挑战。

Method: 对现有文献中提出的用于解决电动汽车充电相关挑战的数据驱动模型和方法进行了全面的回顾和分析，涵盖了充电站部署、充电调度策略和大规模车队管理等方面。

Result: 本文全面回顾了解决电动汽车充电挑战的数据驱动模型和方法，探讨了这些研究在充电站部署、调度和车队管理方面的应用，并讨论了电动汽车整合的广泛影响。

Conclusion: 虽然电动汽车带来了诸多优势，但仍需解决充电站拥堵、高充电成本和充电需求与客运服务需求冲突等问题。本文对现有数据驱动模型和方法进行了综述，并指出了未来研究方向，以促进电动汽车的进一步发展和整合。

Abstract: Driven by growing concerns over air quality and energy security, electric
vehicles (EVs) has experienced rapid development and are reshaping global
transportation systems and lifestyle patterns. Compared to traditional
gasoline-powered vehicles, EVs offer significant advantages in terms of lower
energy consumption, reduced emissions, and decreased operating costs. However,
there are still some core challenges to be addressed: (i) Charging station
congestion and operational inefficiencies during peak hours, (ii) High charging
cost under dynamic electricity pricing schemes, and (iii) Conflicts between
charging needs and passenger service requirements.Hence, in this paper, we
present a comprehensive review of data-driven models and approaches proposed in
the literature to address the above challenges. These studies cover the entire
lifecycle of EV systems, including charging station deployment, charging
scheduling strategies, and large-scale fleet management. Moreover, we discuss
the broader implications of EV integration across multiple domains, such as
human mobility, smart grid infrastructure, and environmental sustainability,
and identify key opportunities and directions for future research.

</details>


### [151] [Wasserstein Distributionally Robust Adaptive Covariance Steering](https://arxiv.org/abs/2509.04593)
*Aditya Gahlawat,Vivek Khatana,Duo Wang,Sambhu H. Karumanchi,Naira Hovakimyan,Petros Voulgaris*

Main category: eess.SY

TL;DR: 提出一种可预测且安全的协方差转向控制方法，用于处理具有一般不确定性的非线性随机过程。


<details>
  <summary>Details</summary>
Motivation: 解决具有一般不确定性（包括无界随机扰动和状态依赖的认知不确定性）的非线性随机过程的预测和安全控制问题，这些不确定性导致状态分布未知、形状任意且可能发散，从而导致不可预测和不安全行为。

Method: 采用 L1 自适应控制架构，提供概率测量的 Wasserstein 度量证书，并将这些证书合并到高级协方差控制转向中，以保证安全控制。

Result: 实现了对不确定随机过程的鲁棒控制，并提供了协方差控制转向的安全保证。

Conclusion: 所提出的方法避免了现有分布鲁棒规划和控制方法中难以验证的要求，例如需要有限样本或先验知道模糊集。

Abstract: We present a methodology for predictable and safe covariance steering control
of uncertain nonlinear stochastic processes. The systems under consideration
are subject to general uncertainties, which include unbounded random
disturbances (aleatoric uncertainties) and incomplete model knowledge
(state-dependent epistemic uncertainties). These general uncertainties lead to
temporally evolving state distributions that are entirely unknown, can have
arbitrary shapes, and may diverge unquantifiably from expected behaviors,
leading to unpredictable and unsafe behaviors. Our method relies on an
$\mathcal{L}_1$-adaptive control architecture that ensures robust control of
uncertain stochastic processes while providing Wasserstein metric certificates
in the space of probability measures. We show how these distributional
certificates can be incorporated into the high-level covariance control
steering to guarantee safe control. Unlike existing distributionally robust
planning and control methodologies, our approach avoids difficult-to-verify
requirements like the availability of finite samples from the true underlying
distribution or an a priori knowledge of time-varying ambiguity sets to which
the state distributions are assumed to belong.

</details>


### [152] [$\mathcal{L}_1$-DRAC: Distributionally Robust Adaptive Control](https://arxiv.org/abs/2509.04619)
*Aditya Gahlawat,Sambhu H. Karumanchi,Naira Hovakimyan*

Main category: eess.SY

TL;DR: 该研究提出了一种名为 $\mathcal{L}_1$ 分布鲁棒自适应控制 ($\mathcal{L}_1$-DRAC) 的新控制方法，用于处理不确定的随机过程，并保证在均匀（有限时间）和最大分布偏差方面的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 数据驱动的机器学习方法在控制和估计动态系统方面受到关注，但其缺乏可预测性和鲁棒性，限制了在安全关键型应用中的使用。传统的鲁棒自适应控制虽然能保证可预测性，但与数据驱动方法结合困难且结果保守。数据驱动方法存在分布偏移问题，传统方法难以解决，除非使用过度简化的模型和不可验证的假设。

Method: 利用 $\mathcal{L}_1$ 自适应控制方法，确保在标称分布周围存在一个 Wasserstein 模糊集，该集合保证包含真实分布。该均匀模糊集产生一个围绕随时间变化的标称分布的分布模糊管。所设计的控制器响应内因不确定性（模型不确定性）和外因不确定性（固有随机性和干扰）来生成模糊管。

Result: 提出了一种名为 $\mathcal{L}_1$ 分布鲁棒自适应控制 ($\mathcal{L}_1$-DRAC) 的方法。

Conclusion: $\mathcal{L}_1$-DRAC 是一种用于不确定随机过程的控制方法，可提供关于均匀（有限时间）和最大分布偏差的鲁棒性保证。

Abstract: Data-driven machine learning methodologies have attracted considerable
attention for the control and estimation of dynamical systems. However, such
implementations suffer from a lack of predictability and robustness. Thus,
adoption of data-driven tools has been minimal for safety-aware applications
despite their impressive empirical results. While classical tools like robust
adaptive control can ensure predictable performance, their consolidation with
data-driven methods remains a challenge and, when attempted, leads to
conservative results. The difficulty of consolidation stems from the inherently
different `spaces' that robust control and data-driven methods occupy.
Data-driven methods suffer from the distribution-shift problem, which current
robust adaptive controllers can only tackle if using over-simplified learning
models and unverifiable assumptions. In this paper, we present $\mathcal{L}_1$
distributionally robust adaptive control ($\mathcal{L}_1$-DRAC): a control
methodology for uncertain stochastic processes that guarantees robustness
certificates in terms of uniform (finite-time) and maximal distributional
deviation. We leverage the $\mathcal{L}_1$ adaptive control methodology to
ensure the existence of Wasserstein ambiguity set around a nominal
distribution, which is guaranteed to contain the true distribution. The uniform
ambiguity set produces an ambiguity tube of distributions centered on the
nominal temporally-varying nominal distribution. The designed controller
generates the ambiguity tube in response to both epistemic (model
uncertainties) and aleatoric (inherent randomness and disturbances)
uncertainties.

</details>


### [153] [Bayesian Diagnosability and Active Fault Identification](https://arxiv.org/abs/2509.04708)
*Chun-Wei Kong,Jay McMahon,Morteza Lahijanian*

Main category: eess.SY

TL;DR: 本研究提出了一个贝叶斯框架，用于识别离散时间非线性系统中的故障，并引入了新的可诊断性定义和主动故障识别策略。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决受加性高斯白噪声影响的离散时间非线性系统中的故障识别问题，并克服现有纯粹被动方法在故障识别方面的根本性限制。

Method: 本研究提出了一种新的定量可诊断性定义，并开发了一种主动故障识别策略，该策略通过设计控制输入来优化故障识别效果。

Result: 在具有复杂和不连续动力学的两水箱系统和火星卫星的数值研究中，与纯粹被动技术相比，该方法显著降低了故障识别的失败率并缩短了识别延迟。

Conclusion: 本研究提出的贝叶斯框架和主动故障识别策略能够有效地识别离散时间非线性系统中的故障，并优于现有的被动方法。

Abstract: We study fault identification in discrete-time nonlinear systems subject to
additive Gaussian white noise. We introduce a Bayesian framework that
explicitly accounts for unmodeled faults under reasonable assumptions. Our
approach hinges on a new quantitative diagnosability definition, revealing when
passive fault identification (FID) is fundamentally limited by the given
control sequence. To overcome such limitations, we propose an active FID
strategy that designs control inputs for better fault identification. Numerical
studies on a two-water tank system and a Mars satellite with complex and
discontinuous dynamics demonstrate that our method significantly reduces
failure rates with shorter identification delays compared to purely passive
techniques.

</details>


### [154] [Performance Analysis of Pinching-Antenna-Enabled Internet of Things Systems](https://arxiv.org/abs/2509.04885)
*Han Zhang,Bingxin Zhang,Yizhe Zhao,Kun Yang,Guopeng Zhang*

Main category: eess.SY

TL;DR: 本文首次对圆形室内环境中具有/不具有传播损耗的PASS系统（包括全覆盖和部分覆盖两种波导配置）进行了分析。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注矩形室内布局和全覆盖波导，而实际部署可能面临几何约束、部分覆盖和波导衰减等问题。因此，有必要研究PASS在更复杂的实际环境中的性能。

Method: 开发了一个统一的几何传播框架，同时考虑了天线放置、物联网设备位置分布和波导衰减。推导了四种场景下的中断概率和平均可实现速率的闭式表达式，并通过蒙特卡洛模拟验证了其准确性。

Result: 在部分覆盖波导且存在传播损耗的情况下，系统性能随波导长度呈现非单调趋势，且最优长度随衰减系数增大而减小。数值结果量化了部署策略、波导传播损耗和覆盖几何形状之间的相互作用。

Conclusion: 该分析为面向性能的PASS设计提供了实用的指导。

Abstract: The pinching-antenna systems (PASS), which activate small dielectric
particles along a dielectric waveguide, has recently emerged as a promising
paradigm for flexible antenna deployment in next-generation wireless
communication networks. While most existing studies assume rectangular indoor
layouts with full coverage waveguide, practical deployments may involve
geometric constraints, partial coverage, and non-negligible waveguide
attenuation. This paper presents the first analytical investigation of PASS in
a circular indoor environment, encompassing both full coverage and partial
coverage waveguide configurations with/without propagation loss. A unified
geometric-propagation framework is developed that jointly captures
pinching-antenna placement, Internet of Things (IoT) device location
distribution, and waveguide attenuation. Closed-form expressions for the outage
probability and average achievable rate are derived for four scenarios, with
accuracy validated via extensive Monte-Carlo simulations. The analysis reveals
that, under the partial coverage waveguide scenario with propagation loss, the
system performance demonstrates a non-monotonic trend with respect to the
waveguide length, and the optimal length decreases as the attenuation
coefficient increases. Numerical results further quantify the interplay between
deployment strategy, waveguide propagation loss, and coverage geometry,
offering practical guidelines for performance-oriented PASS design.

</details>


### [155] [Estimating Cellular Network Delays in Finnish Railways: A Machine Learning Enhanced Approach](https://arxiv.org/abs/2509.05003)
*Saeideh Mansouri,Mohamed Shamekh,Simon Indola,Petri Mahonen*

Main category: eess.SY

TL;DR: 芬兰通过Digirail项目，利用机器学习模型预测了公共4G/5G网络在铁路通信中的性能，证明了其满足铁路网络控制的严格要求是可行的。


<details>
  <summary>Details</summary>
Motivation: 随着特定行业网络被公共蜂窝网络取代的趋势日益增长，特别是GSM-R向4G/5G的迁移，需要评估公共蜂窝网络在铁路通信中的性能。

Method: 本研究收集了两种模式（最佳质量和数据包复制）的网络测量数据。由于最佳质量模式引入了人为延迟，因此本研究采用数据包复制模式下的测量数据，并使用机器学习对铁路网络延迟进行建模。选择了性能最佳的模型来生成一个数据集，用于估算芬兰整个铁路网络的网络延迟。

Result: 研究结果表明，基于机器学习的网络性能预测是可行的。所生成的数据集能够更准确地表示网络性能，并表明芬兰的公共蜂窝网络能够满足铁路网络控制的严格性能要求。

Conclusion: 机器学习方法在预测铁路通信网络性能方面是可行的，芬兰的公共蜂窝网络能够满足铁路通信的严格要求。

Abstract: There is growing interest in using public cellular networks for specialized
communication applications, replacing standalone sector-specific networks. One
such application is transitioning from the aging GSM-R railway network to
public 4G and 5G networks. Finland is modernizing its railway communication
system through the Digirail project, leveraging public cellular networks. To
evaluate network performance, a nationwide measurement campaign was conducted
in two modes: Best Quality and Packet Replication. However, Best Quality mode
introduces artificial delays, making it unsuitable for real-world assessments.
In this paper, railway network delays are modeled using machine learning based
on measurements from the Packet Replication mode. The best-performing model is
then employed to generate a dataset estimating network delays across Finland's
railway network. This dataset provides a more accurate representation of
network performance. Machine learning based network performance prediction is
shown to be feasible, and the results indicate that Finland's public cellular
network can meet the stringent performance requirements of railway network
control.

</details>


### [156] [StimulHeat: a Low-Energy Wearable Thermal Feedback Device Using Peltier Elements with Heat Flow Controlled Loop for Hand Interactions in Virtual Reality](https://arxiv.org/abs/2509.05020)
*Matthieu Mesnage,Sophie Villenave,Bertrand Massot,Matthieu Blanchard,Pierre Raimbaud,Guillaume Lavoué,Claudine Gehin*

Main category: eess.SY

TL;DR: StimulHeat是一个无线、低功耗的触觉反馈系统，集成了阀门索引控制器，并通过控制热流而非温度来管理热刺激。


<details>
  <summary>Details</summary>
Motivation: 目前大多数用于虚拟现实的可穿戴热反馈系统要么不兼容标准控制器，要么基于温度控制。本研究旨在实现与现有控制器的集成，并提出一种通过控制热流而非温度来管理佩尔捷模块热刺激的方法。

Method: 研究设计了一个优化的TED驱动器，能够向TED注入连续的双向电流，将其用作加热器或冷却器。该驱动器被集成到一个电子板上，包含温度和热流控制环路，以及用于远程控制的低功耗蓝牙接口。通过控制器扩展对TED、温度传感器和电子器件进行了机械集成。最后，通过用户研究验证了StimulHeat在虚拟现实中的应用。

Result: StimulHeat是一个无线、低功耗的触觉反馈系统，可与阀门索引控制器集成，并通过控制热流而非温度来管理佩尔捷模块的热刺激。该系统包括一个优化的TED驱动器、一个包含温度和热流控制以及低功耗蓝牙接口的电子板，以及一个可安装在阀门索引控制器上的非侵入式扩展。

Conclusion: StimulHeat是一个适用于虚拟现实的、可与现有控制器集成的热反馈系统，它通过控制热流而不是温度来提供热刺激，并在用户研究中得到了验证。

Abstract: Nowadays, the majority of wearable thermal feedback systems designed for use
in virtual reality applications are not compatible or not integrated to
standard controllers and are based on temperature control. The objectives of
the present work is to enable integration with existing controllers, in this
case Valve Index controllers, and to propose an alternative approach to
managing thermal stimulation with Peltier modules by controlling heat flow
instead of temperature. We introduce StimulHeat as a wireless, low power
thermal feedback system, based on the continuous relationship between heat and
current injection in thermoelectric device (TED). First, we designed an
optimized TED driver capable of injecting a continuous, bidirectional current
into the TED, thereby driving it as a heater or cooler. Subsequently, this
driver was implemented in an electronic board to include temperature and heat
flow control loops, as well as Bluetooth Low Energy interface for remote
control. A mechanical integration was conducted, in the form of a controller
extension which is non-intrusive and can be clipped to Valve Index controllers
to enclose the TED, temperature sensors and electronics. Finally, we present a
user study validating StimulHeat for use in Virtual Reality, utilizing a
Unity-built virtual environment with our open-source package.

</details>


### [157] [Model predictive quantum control: A modular approach for efficient and robust quantum optimal control](https://arxiv.org/abs/2509.05167)
*Eya Guizani,Julian Berberich*

Main category: eess.SY

TL;DR: 提出了一种利用模型预测控制（MPC）提升量子最优控制（QOC）效率和鲁棒性的模块化框架。


<details>
  <summary>Details</summary>
Motivation: MPC是成功的现代控制方法，通过反复求解有限时间最优控制问题来优化控制输入。然而，在量子控制领域，MPC的应用和效率有待提升。

Method: 文章首先从QOC视角介绍了MPC的基本概念，然后提出了多种MPC方案，包括简单的和具有稳定性保证的复杂方案，构建了一个模块化框架。

Result: 该框架能够通过引入反馈来提高开环QOC的效率和闭环量子控制的鲁棒性。通过数值结果的演示和与现有方法的基准测试，证明了所提方法的优势。

Conclusion: 所提出的基于MPC的模块化框架能够有效提升量子最优控制的效率和鲁棒性，为量子控制领域提供了一种有前景的解决方案。

Abstract: Model predictive control (MPC) is one of the most successful modern control
methods. It relies on repeatedly solving a finite-horizon optimal control
problem and applying the beginning piece of the optimal input. In this paper,
we develop a modular framework for improving efficiency and robustness of
quantum optimal control (QOC) via MPC. We first provide a tutorial introduction
to basic concepts of MPC from a QOC perspective. We then present multiple MPC
schemes, ranging from simple approaches to more sophisticated schemes which
admit stability guarantees. This yields a modular framework which can be used
1) to improve efficiency of open-loop QOC and 2) to improve robustness of
closed-loop quantum control by incorporating feedback. We demonstrate these
benefits with numerical results, where we benchmark the proposed methods
against competing approaches.

</details>


### [158] [Feedback Linearisation with State Constraints](https://arxiv.org/abs/2509.05191)
*Songlin Jin,Yuanbo Nie,Morgan Jones*

Main category: eess.SY

TL;DR: 本研究提出了一种在反馈线性化（FBL）之前增强系统动力学以处理状态约束的方法，通过引入切换FBL控制器来克服在状态约束边界处出现的非定义相对度问题。


<details>
  <summary>Details</summary>
Motivation: 传统反馈线性化（FBL）技术在处理带状态约束的非线性系统时，会使状态约束变得复杂，从而削弱线性化的优势。本研究旨在解决这一问题。

Method: 本研究提出了一种新的方法，在应用FBL之前，先增强系统动力学以包含状态约束。该方法会导致状态约束边界处的相对度非定义，但可以通过使用切换FBL控制器来解决。

Result: 研究表明，所提出的增强方法虽然会导致状态约束边界处的相对度非定义，但通过使用切换FBL控制器可以克服这一问题。数值实验证明了该方法在FBL框架内处理状态约束的能力。

Conclusion: 本研究提出了一种在应用FBL之前增强系统动力学以捕捉状态约束的方法，并通过切换FBL控制器成功克服了状态约束边界处非定义相对度的问题，为在FBL框架内处理状态约束提供了有效途径。

Abstract: Feedback Linearisation (FBL) is a widely used technique that applies feedback
laws to transform input-affine nonlinear dynamical systems into linear
dynamical systems, allowing for the use of linear controller design methods
such as pole placement. However, for problems with state constraints,
controlling the linear system induced by FBL can be more challenging than
controlling the original system. This is because simple state constraints in
the original nonlinear system become complex nonlinear constraints in the FBL
induced linearised system, thereby diminishing the advantages of linearisation.
To avoid increasing the complexity of state constraints under FBL, this paper
introduces a method to first augment system dynamics to capture state
constraints before applying FBL. We show that our proposed augmentation method
leads to ill-defined relative degrees at state constraint boundaries. However,
we show that ill-defined relative degrees can be overcome by using a switching
FBL controller. Numerical experiments illustrate the capabilities of this
method for handling state constraints within the FBL framework.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [159] [STADI: Fine-Grained Step-Patch Diffusion Parallelism for Heterogeneous GPUs](https://arxiv.org/abs/2509.04719)
*Han Liang,Jiahui Zhou,Zicheng Zhou,Xiaoxi Zhang,Xu Chen*

Main category: cs.DC

TL;DR: STADI是一个用于异构多GPU环境的扩散模型推理加速框架，通过时空自适应调度优化负载均衡和性能。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型并行推理方案在异构多GPU环境中存在资源利用率低和负载不均衡的问题。

Method: STADI采用混合调度器，结合了计算感知步进分配器（利用最小公倍数量化技术减少慢速GPU的降噪步数）和弹性块并行机制（根据GPU计算能力分配可变大小的图像块）。

Result: 实验证明STADI在负载不均衡和异构多GPU集群上能够改善负载均衡，减少性能瓶颈，并将端到端推理延迟最多降低45%，同时提高资源利用率。

Conclusion: STADI通过创新的时空自适应调度方法，有效解决了异构多GPU环境中扩散模型推理的效率和负载均衡问题。

Abstract: The escalating adoption of diffusion models for applications such as image
generation demands efficient parallel inference techniques to manage their
substantial computational cost. However, existing diffusion parallelism
inference schemes often underutilize resources in heterogeneous multi-GPU
environments, where varying hardware capabilities or background tasks cause
workload imbalance. This paper introduces Spatio-Temporal Adaptive Diffusion
Inference (STADI), a novel framework to accelerate diffusion model inference in
such settings. At its core is a hybrid scheduler that orchestrates fine-grained
parallelism across both temporal and spatial dimensions. Temporally, STADI
introduces a novel computation-aware step allocator applied after warmup
phases, using a least-common-multiple-minimizing quantization technique to
reduce denoising steps on slower GPUs and execution synchronization. To further
minimize GPU idle periods, STADI executes an elastic patch parallelism
mechanism that allocates variably sized image patches to GPUs according to
their computational capability, ensuring balanced workload distribution through
a complementary spatial mechanism. Extensive experiments on both
load-imbalanced and heterogeneous multi-GPU clusters validate STADI's efficacy,
demonstrating improved load balancing and mitigation of performance
bottlenecks. Compared to patch parallelism, a state-of-the-art diffusion
inference framework, our method significantly reduces end-to-end inference
latency by up to 45% and significantly improves resource utilization on
heterogeneous GPUs.

</details>


### [160] [VoltanaLLM: Feedback-Driven Frequency Control and State-Space Routing for Energy-Efficient LLM Serving](https://arxiv.org/abs/2509.04827)
*Jiahuan Yu,Aryan Taneja,Junfeng Lin,Minjia Zhang*

Main category: cs.DC

TL;DR: VoltanaLLM通过结合频率调节和请求路由，实现了LLM推理的能效提升，同时保证了服务质量。


<details>
  <summary>Details</summary>
Motivation: LLM推理的能耗高昂，对可持续和成本效益构成挑战。

Method: VoltanaLLM从控制理论角度出发，对预填充/解码分离架构中的频率调节和请求路由进行协同设计，实现细粒度、分阶段控制。其包含一个反馈控制的频率控制器，动态调整GPU频率；以及一个状态空间路由器，探索跨频率调节实例的路由决策，以在满足延迟约束的条件下最小化能耗。

Result: 在多种先进LLM和真实数据集上的评估结果显示，VoltanaLLM实现了高达36.3%的能耗节省，同时保持了近乎完美的SLO达标率。

Conclusion: VoltanaLLM为实现可持续和智能的LLM服务提供了可行方案。

Abstract: Modern Large Language Model (LLM) serving systems increasingly support
interactive applications, like real-time chat assistants, code generation
tools, and agentic workflows. However, the soaring energy cost of LLM inference
presents a growing challenge for sustainable and cost-effective deployment.
This paper introduces VoltanaLLM, a system for SLO-aware, energy-efficient LLM
serving, built from a control theory perspective. VoltanaLLM co-designs
frequency scaling and request routing in emerging prefill/decode disaggregated
architectures, leveraging their decoupled execution to enable fine-grained
phase-specific control. It consists of a feedback-driven frequency controller
that dynamically adapts GPU frequency for prefill and decode phases, and a
state-space router that explores routing decisions across frequency-scaled
instances to minimize energy under latency constraints. We implement VoltanaLLM
in SGLang and evaluate its performance over multiple state-of-the-art LLMs and
real-world datasets. The results demonstrate that VoltanaLLM achieves up to
36.3% energy savings while maintaining near-perfect SLO attainment rate, paving
the way for sustainable and intelligent LLM serving.

</details>


### [161] [Toward Distributed 3D Gaussian Splatting for High-Resolution Isosurface Visualization](https://arxiv.org/abs/2509.05216)
*Mengjiao Han,Andres Sewell,Joseph Insley,Janet Knowles,Victor A. Mateevitsi,Michael E. Papka,Steve Petruzza,Silvio Rizzi*

Main category: cs.DC

TL;DR: 该研究提出了一个用于科学可视化的多GPU 3D高斯泼溅（3D-GS）方法，通过分布式优化提升训练速度和支持高分辨率重建，能处理单GPU无法处理的大型数据集。


<details>
  <summary>Details</summary>
Motivation: 将3D高斯泼溅（3D-GS）扩展到科学可视化领域，实现高保真等值面重建，并解决处理大型科学数据集的计算挑战。

Method: 采用Grendel-GS的多GPU训练后端，将3D-GS的优化过程分布在多个GPU上进行处理。

Result: 在Kingsnake数据集（400万高斯点）上实现了5.6倍的加速；成功训练了Miranda数据集（1800万高斯点），该数据集在单GPU上无法处理。

Conclusion: 该方法为将3D-GS集成到高性能计算（HPC）的科学工作流程中奠定了基础，能够对复杂模拟进行实时后处理和原位可视化。

Abstract: We present a multi-GPU extension of the 3D Gaussian Splatting (3D-GS)
pipeline for scientific visualization. Building on previous work that
demonstrated high-fidelity isosurface reconstruction using Gaussian primitives,
we incorporate a multi-GPU training backend adapted from Grendel-GS to enable
scalable processing of large datasets. By distributing optimization across
GPUs, our method improves training throughput and supports high-resolution
reconstructions that exceed single-GPU capacity. In our experiments, the system
achieves a 5.6X speedup on the Kingsnake dataset (4M Gaussians) using four GPUs
compared to a single-GPU baseline, and successfully trains the Miranda dataset
(18M Gaussians) that is an infeasible task on a single A100 GPU. This work lays
the groundwork for integrating 3D-GS into HPC-based scientific workflows,
enabling real-time post hoc and in situ visualization of complex simulations.

</details>


### [162] [Dynamic reconfiguration for malleable applications using RMA](https://arxiv.org/abs/2509.05248)
*Iker Martín-Álvarez,José I. Aliaga,Maribel Castillo*

Main category: cs.DC

TL;DR: 该研究提出并评估了基于MPI RMA操作的新型单边通信方法，用于动态调整可塑应用程序的大小，以最小化对应用程序执行的影响并实现数据重新分配。


<details>
  <summary>Details</summary>
Motivation: 提出一种新的通信方法，用于在不显著影响应用程序执行的情况下动态调整可塑应用程序的大小并重新分配数据。

Method: 将基于MPI RMA的单边通信方法集成到MaM库中，并与传统的基于集合的通信方法进行比较。扩展了现有的Wait Drains策略以支持高效的后台重新配置。

Result: 所提出的方法在性能上与传统方法相当，但目前的初始化成本较高，限制了其优势。

Conclusion: 基于MPI RMA的单边通信方法在动态调整可塑应用程序大小时具有潜力，但需要解决高初始化成本的问题以充分发挥其优势。

Abstract: This paper investigates the novel one-sided communication methods based on
remote memory access (RMA) operations in MPI for dynamic resizing of malleable
applications, enabling data redistribution with minimal impact on application
execution. After their integration into the MaM library, these methods are
compared with traditional collective-based approaches. In addition, the
existing strategy Wait Drains is extended to support efficient background
reconfiguration. Results show comparable performance, though high
initialization costs currently limit their advantage.

</details>


### [163] [Scaling Performance of Large Language Model Pretraining](https://arxiv.org/abs/2509.05258)
*Alexander Interrante-Grant,Carla Varela-Rosa,Suhaas Narayan,Chris Connelly,Albert Reuther*

Main category: cs.DC

TL;DR: LLMs性能优越但训练成本高昂，本文旨在分享大规模语言模型预训练过程中的分布式训练、大规模数据集管理以及数据并行扩展的经验，以充分利用GPU计算能力。


<details>
  <summary>Details</summary>
Motivation: LLMs在自然语言处理应用中表现出色，但其训练成本极高，且公开文献中关于大规模模型训练的细节和性能考量信息匮乏。

Method: 本文将探讨大规模语言模型预训练中的分布式训练、跨越数百个节点的大规模数据集管理，以及数据并行扩展的策略，重点关注如何充分利用GPU计算能力。

Result: LLMs在自然语言处理应用中表现出色，但其训练成本极高，且公开文献中关于大规模模型训练的细节和性能考量信息匮乏。

Conclusion: LLMs在自然语言处理应用中表现出色，但其训练成本极高，且公开文献中关于大规模模型训练的细节和性能考量信息匮乏。

Abstract: Large language models (LLMs) show best-in-class performance across a wide
range of natural language processing applications. Training these models is an
extremely computationally expensive task; frontier Artificial Intelligence (AI)
research companies are investing billions of dollars into supercomputing
infrastructure to train progressively larger models on increasingly massive
datasets. Unfortunately, information about the scaling performance and training
considerations of these large training pipelines is scarce in public
literature. Working with large-scale datasets and models can be complex and
practical recommendations are scarce in the public literature for tuning
training performance when scaling up large language models. In this paper, we
aim to demystify the large language model pretraining pipeline somewhat - in
particular with respect to distributed training, managing large datasets across
hundreds of nodes, and scaling up data parallelism with an emphasis on fully
leveraging available GPU compute capacity.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [164] [Scaling Environments for Organoid Intelligence with LLM-Automated Design and Plasticity-Based Evaluation](https://arxiv.org/abs/2509.04633)
*Brennen Hill*

Main category: cs.NE

TL;DR: 本研究提出了一个用于训练类器官生物智能体的框架，并介绍了三个具有挑战性的虚拟环境（条件回避、捕食者-猎物、乒乓球），以探索学习机制（LTP/LTD）。该框架利用大型语言模型（LLM）自动化实验设计，并通过多模态方法评估学习效果，旨在连接计算神经科学与人工智能，为研究具身智能提供平台。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能体日益复杂，设计能有效塑造其行为和能力的环境已成为关键研究领域。本研究旨在将此原理扩展到新型智能体——类器官神经网络。

Method: 开发了三个可扩展的闭环虚拟环境（条件回避、捕食者-猎物、乒乓球），用于训练类器官生物智能体，并探索其学习机制。设计了包含状态和动作空间、感觉编码、运动解码和反馈协议（奖励/惩罚）的环境。提出了一种利用大型语言模型（LLM）自动化生成和优化实验方案的元学习方法。

Result: 设计并详细说明了三个不同复杂度的任务环境。LLM可用于自动化实验方案的设计和优化。提出了一种通过电生理、细胞和分子水平测量突触可塑性来评估学习的多模态方法。

Conclusion: 该工作弥合了计算神经科学与基于智能体的AI之间的差距，提供了一个在受控生物基质中研究具身、学习和智能的独特平台。

Abstract: As the complexity of artificial agents increases, the design of environments
that can effectively shape their behavior and capabilities has become a
critical research frontier. We propose a framework that extends this principle
to a novel class of agents: biological neural networks in the form of neural
organoids. This paper introduces three scalable, closed-loop virtual
environments designed to train organoid-based biological agents and probe the
underlying mechanisms of learning, such as long-term potentiation (LTP) and
long-term depression (LTD). We detail the design of three distinct task
environments with increasing complexity: (1) a conditional avoidance task, (2)
a one-dimensional predator-prey scenario, and (3) a replication of the classic
Pong game. For each environment, we formalize the state and action spaces, the
sensory encoding and motor decoding mechanisms, and the feedback protocols
based on predictable (reward) and unpredictable (punishment) stimulation.
Furthermore, we propose a novel meta-learning approach where a Large Language
Model (LLM) is used to automate the generation and optimization of experimental
protocols, scaling the process of environment and curriculum design. Finally,
we outline a multi-modal approach for evaluating learning by measuring synaptic
plasticity at electrophysiological, cellular, and molecular levels. This work
bridges the gap between computational neuroscience and agent-based AI, offering
a unique platform for studying embodiment, learning, and intelligence in a
controlled biological substrate.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [165] [Forall-Exists Relational Verification by Filtering to Forall-Forall](https://arxiv.org/abs/2509.04777)
*Ramana Nagasamudram,Anindya Banerjee,David A. Naumann*

Main category: cs.LO

TL;DR: 该论文提出了一种通过新颖的过滤器充分性变换来验证 $orallightleftharpoonsightexists$ 判断的方法，将 $orallightleftharpoonsorall$ 属性转化为 $orallightleftharpoonsightexists$ 属性。


<details>
  <summary>Details</summary>
Motivation: 现有关系验证方法主要关注 $orallightleftharpoonsorall$ 属性，但对于涉及不确定性的 $orallightleftharpoonsightexists$ 属性的研究和工具支持不足。

Method: 提出了一种过滤器充分性变换方法，将 $orallightleftharpoonsightexists$ 判断转化为 $orallightleftharpoonsorall$ 判断。开发了一种用于基本 $orallightleftharpoonsightexists$ 判断（包含断言失败）的程序逻辑。引入了双程序（bicoms）来表示执行对，以便将 $orallightleftharpoonsorall$ 属性直接转化为单一正确性。证明了该逻辑的可靠性，即成功验证变换后的双程序等价于其底层单一命令的 $orallightleftharpoonsightexists$ 规范。实现了一个原型工具来自动进行关系验证。

Result: 成功验证了论文中的所有示例，证明了该方法的可行性，并允许用户使用标准断言和现有工具（包括自动激活验证器）。

Conclusion: 该方法通过过滤器充分性变换，有效解决了 $orallightleftharpoonsightexists$ 属性验证的难题，使研究人员能够利用现有工具和技术进行更广泛的关系验证。

Abstract: Relational verification encompasses research directions such as reasoning
about data abstraction, reasoning about security and privacy, secure
compilation, and functional specificaton of tensor programs, among others.
Several relational Hoare logics exist, with accompanying tool support for
compositional reasoning of $\forall\forall$ (2-safety) properties and,
generally, k-safety properties of product programs. In contrast, few logics and
tools exist for reasoning about $\forall\exists$ properties which are critical
in the context of nondeterminism.
  This paper's primary contribution is a methodology for verifying a
$\forall\exists$ judgment by way of a novel filter-adequacy transformation.
This transformation adds assertions to a product program in such a way that the
desired $\forall\exists$ property (of a pair of underlying unary programs) is
implied by a $\forall\forall$ property of the transformed product. The paper
develops a program logic for the basic $\forall\exists$ judgement extended with
assertion failures; develops bicoms, a form of product programs that represents
pairs of executions and that caters for direct translation of $\forall\forall$
properties to unary correctness; proves (using the logic) a soundness theorem
that says successful $\forall\forall$ verification of a transformed bicom
implies the $\forall\exists$ spec for its underlying unary commands; and
implements a proof of principle prototype for auto-active relational
verification which has been used to verify all examples in the paper. The
methodology thereby enables a user to work with ordinary assertions and
assumptions, and a standard assertion language, so that existing tools
including auto-active verifiers can be used.

</details>


### [166] [Higher order differential calculus in mathlib](https://arxiv.org/abs/2509.04922)
*Sébastien Gouëzel*

Main category: cs.LO

TL;DR: Lean mathlib库中开发了高阶微分计算库，支持任意标量域、定义在域上的函数以及更广泛的光滑函数范围，并解决了数学和形式化方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 支持更广泛的应用，如允许任意标量域、处理定义在域上的函数以及整合解析函数到更广泛的光滑函数范围内。

Method: 在Lean数学库mathlib中开发高阶微分计算库，解决任意标量域、定义在域上的函数以及整合解析函数到更广泛的光滑函数范围等方面带来的数学和形式化挑战。

Result: 开发了一个高阶微分计算库，克服了在任意标量域、定义在域上的函数以及整合解析函数到更广泛的光滑函数范围内进行数学和形式化处理的挑战。

Conclusion: 该库的开发为数学研究提供了更灵活、更强大的工具，并为形式化验证开辟了新的可能性。

Abstract: We report on the higher-order differential calculus library developed inside
the Lean mathematical library mathlib. To support a broad range of
applications, we depart in several ways from standard textbook definitions: we
allow arbitrary fields of scalars, we work with functions defined on domains
rather than full spaces, and we integrate analytic functions in the broader
scale of smooth functions. These generalizations introduce significant
challenges, which we address from both the mathematical and the formalization
perspectives.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [167] [Communication-Efficient Collaborative LLM Inference via Distributed Speculative Decoding](https://arxiv.org/abs/2509.04576)
*Ce Zheng,Tingting Yang*

Main category: eess.SP

TL;DR: AI-native 5G网络中的一种新颖的通信方案，通过仅发送Top-K的概率和索引来减少通信开销，同时保持推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有的分布式投机解码方法在AI-native 5G网络中需要传输整个词汇概率分布，导致高昂的上行链路通信成本。

Method: 提出一种“Top-K稀疏logit传输（TK-SLT）”方案，只传输Top-K的token原始概率和相应的token索引。

Result: TK-SLT方案显著降低了带宽消耗，同时保持了推理性能。通过推导最优草稿长度以最大化推理吞吐量，并对TK-SLT下可实现的加速比进行了理论分析。

Conclusion: TK-SLT方案在AI-native 5G网络中，通过减少通信开销，实现了更高效、更有效的分布式投机解码。

Abstract: Speculative decoding is an emerging technique that accelerates large language
model (LLM) inference by allowing a smaller draft model to predict multiple
tokens in advance, which are then verified or corrected by a larger target
model. In AI-native radio access networks (AI-RAN), this paradigm is
well-suited for collaborative inference between resource-constrained end
devices and more capable edge servers or base stations (BSs). However, existing
distributed speculative decoding requires transmitting the full vocabulary
probability distribution from the draft model on the device to the target model
at the BS, which leads to prohibitive uplink communication overhead. To address
this issue, we propose a ``Top-K Sparse Logits Transmission (TK-SLT)`` scheme,
where the draft model transmits only the top-K token raw probabilities and the
corresponding token indices instead of the entire distribution. This approach
significantly reduces bandwidth consumption while maintaining inference
performance. We further derive an analytical expression for the optimal draft
length that maximizes inference throughput, and provide a theoretical analysis
of the achievable speedup ratio under TK-SLT. Experimental results validate
both the efficiency and effectiveness of the proposed method.

</details>


### [168] [Tangential Velocity Estimation Using Near-Field Automotive Radar Model](https://arxiv.org/abs/2509.04692)
*Michael Shifrin,Joseph Tabrikian,Igal Bilik*

Main category: eess.SP

TL;DR: 本研究提出一种近场雷达模型，用于估计汽车雷达系统中被遮挡的切向速度分量。


<details>
  <summary>Details</summary>
Motivation: 传统汽车雷达系统无法估计目标切向速度，而这是一个准确感知动态环境的关键参数。现有模型在距离、径向速度和多普勒等参数估计方面存在模糊性。

Method: 提出近场雷达模型，考虑时空上的多重迁移效应。通过克拉美-罗界和模糊函数分析进行可辨识性研究。设计一种基于最大似然估计的算法，利用目标迁移信息估计切向速度，并减轻模糊性。采用分离阵列配置。

Result: 仿真结果表明，该方法在单目标和多目标场景下均能有效估计切向速度，并提高雷达系统在距离、径向速度和多普勒参数估计方面的准确性和可靠性。

Conclusion: 所提出的近场模型和基于最大似然估计的算法能够有效解决传统汽车雷达系统在切向速度估计方面的局限性，提高态势感知能力，为高级驾驶辅助系统和自动驾驶汽车提供支持。

Abstract: This work investigates the problem of tangential velocity estimation in
automotive radar systems, addressing the limitations of conventionally
considered models. Conventional automotive radars are usually based on
far-field models and estimate the target's range, radial velocity, and
direction-of-arrival (DOA) but are not able to estimate the tangential
component of the target 2-D velocity, which is a critical parameter for
reliable perception of dynamic environments. To address this challenge, we
introduce the near-field radar model, which considers various migration
elements in range, radial velocity, and Doppler along time and space.
Conventionally, these migration effects result in smearing of the likelihood
function for estimating the target parameters. However, if the model is
correctly specified, these migration effects are informative for tangential
velocity estimation. We conduct an identifiability analysis for tangential
velocity estimation using the Cram\'er-Rao bound and ambiguity function. The
insights from this study motivate the use of a separated array configuration
and the development of a computationally efficient maximum likelihood based
algorithm designed to utilize target migrations for tangential velocity
estimation, while maintaining practical computational complexity. In addition
to tangential velocity estimation, the proposed algorithm mitigates likelihood
smearing in range, radial velocity, and Doppler. Simulations validate the
theoretical feasibility study, and evaluate the algorithms' performance in both
single- and multi-target scenarios. The proposed approach improves the accuracy
and reliability of automotive radars, enhancing situational awareness for
advanced driver assistance systems and autonomous vehicles.

</details>


### [169] [Environment-Aware IRS Deployment via Channel Knowledge Map: Joint Sensing-Communications Coverage Optimization](https://arxiv.org/abs/2509.04768)
*Yilong Chen,Zixiang Ren,Jie Xu,Rui Zhang*

Main category: eess.SP

TL;DR: 该论文研究了IRS辅助ISAC系统中IRS的部署优化问题，旨在最小化系统成本同时满足感知和通信需求。


<details>
  <summary>Details</summary>
Motivation: 为了增强IRS辅助的集成传感和通信（ISAC）系统的感知和通信覆盖范围，需要优化IRS的部署。

Method: 提出了一种环境感知的IRS部署设计，利用信道知识图（CKM）获取信道状态信息（CSI），并结合BS的传输波束成形和IRS的反射波束成形进行优化。该问题被表述为混合整数非凸优化问题，并采用基于连续凸近似（SCA）的松弛-绑定方法求解。

Result: 数值结果表明，所提出的算法能在满足感知和通信需求的同时有效降低系统成本。

Conclusion: 所提出的IRS部署和波束成形优化方法能够有效地解决IRS辅助ISAC系统的部署优化问题。

Abstract: This paper studies the intelligent reflecting surface (IRS) deployment
optimization problem for IRS-enabled integrated sensing and communications
(ISAC) systems, in which multiple IRSs are strategically deployed at candidate
locations to assist a base station (BS) to enhance the coverage of both sensing
and communications. We present an environment-aware IRS deployment design via
exploiting the channel knowledge map (CKM), which provides the channel state
information (CSI) between each candidate IRS location and BS or targeted
sensing/communication points. Based on the obtained CSI from CKM, we optimize
the deployment of IRSs, jointly with the BS's transmit beamforming and IRSs'
reflective beamforming during operation, with the objective of minimizing the
system cost, while guaranteeing the minimum illumination power requirements at
sensing areas and the minimum signal-to-noise ratio (SNR) requirements at
communication areas. In particular, we consider two cases when the IRSs'
reflective beamforming optimization can be implemented dynamically in real time
and quasi-stationarily over the whole operation period, respectively. For both
cases, the joint IRS deployment and transmit/reflective beamforming designs are
formulated as mixed-integer non-convex optimization problems, which are solved
via the successive convex approximation (SCA)-based relax-and-bound method.
Specifically, we first relax the binary IRS deployment indicators into
continuous variables, then find converged solutions via SCA, and finally round
relaxed indicators back to binary values. Numerical results demonstrate the
effectiveness of our proposed algorithms in reducing the system cost while
meeting the sensing and communication requirements.

</details>


### [170] [SREC: Encrypted Semantic Super-Resolution Enhanced Communication](https://arxiv.org/abs/2509.04787)
*Zhidi Zhang,Rui Meng,Song Gao,Haixiao Gao,Xiaodong Xu*

Main category: eess.SP

TL;DR: 本论文提出了一种名为SREC的安全语义通信方法，通过加密语义特征和使用超分辨率重建技术，提高了通信安全性和在低信噪比下的传输性能。


<details>
  <summary>Details</summary>
Motivation: 现有的语义通信方法将语义特征以明文形式传输，容易被窃听，存在安全隐患。

Method: 提出一种名为SREC的安全语义通信方法，利用模256加密方法加密语义特征，并采用超分辨率重建技术提高图像重建质量。

Result: 在AWGN信道下，SREC在不同调制方式下均能稳定保证通信安全，并在低信噪比条件下取得了更好的传输性能。

Conclusion: SREC是一种安全且高效的语义通信方法，特别适用于低信噪比环境。

Abstract: Semantic communication (SemCom), as a typical paradigm of deep integration
between artificial intelligence (AI) and communication technology,
significantly improves communication efficiency and resource utilization
efficiency. However, the security issues of SemCom are becoming increasingly
prominent. Semantic features transmitted in plaintext over physical channels
are easily intercepted by eavesdroppers. To address this issue, this paper
proposes Encrypted Semantic Super-Resolution Enhanced Communication (SREC) to
secure SemCom. SREC uses the modulo-256 encryption method to encrypt semantic
features, and employs super-resolution reconstruction method to improve the
reconstruction quality of images. The simulation results show that in the
additive Gaussian white noise (AWGN) channel, when different modulation methods
are used, SREC can not only stably guarantee security, but also achieve better
transmission performance under low signal-to-noise ratio (SNR) conditions.

</details>


### [171] [KGRAG-SC: Knowledge Graph RAG-Assisted Semantic Communication](https://arxiv.org/abs/2509.04801)
*Dayu Fan,Rui Meng,Song Gao,Xiaodong Xu*

Main category: eess.SP

TL;DR: KGRAG-SC是一种知识图谱辅助的语义通信框架，通过知识图谱实现高效语义提取和鲁棒的文本重建，在低信噪比下表现优于传统方法，并显著降低了传输开销。


<details>
  <summary>Details</summary>
Motivation: 现有的端到端深度学习语义通信方案缺乏可解释性，在噪声条件下进行语义选择和重建的能力较弱。

Method: 提出KGRAG-SC框架，利用多维度知识图谱进行语义提取（通过社区引导的实体链接和GraphRAG），发送端传输紧凑的实体索引，并采用基于结构中心性指标的重要性感知自适应传输策略。接收端利用大型语言模型和共享知识图谱进行知识驱动的文本重建。

Result: KGRAG-SC在低信噪比条件下实现了更高的语义保真度，并显著减少了传输开销。

Conclusion: 将结构化知识表示与生成式语言模型相结合，是实现高效鲁棒的语义通信的有效途径。

Abstract: The state-of-the-art semantic communication (SC) schemes typically rely on
end-to-end deep learning frameworks that lack interpretability and struggle
with robust semantic selection and reconstruction under noisy conditions. To
address this issue, this paper presents KGRAG-SC, a knowledge graph-assisted SC
framework that leverages retrieval-augmented generation principles. KGRAG-SC
employs a multi-dimensional knowledge graph, enabling efficient semantic
extraction through community-guided entity linking and GraphRAG-assisted
processing. The transmitter constructs minimal connected subgraphs that capture
essential semantic relationships and transmits only compact entity indices
rather than full text or semantic triples. An importance-aware adaptive
transmission strategy provides unequal error protection based on structural
centrality metrics, prioritizing critical semantic elements under adverse
channel conditions. At the receiver, large language models perform
knowledge-driven text reconstruction using the shared knowledge graph as
structured context, ensuring robust semantic recovery even with partial
information loss. Experimental results demonstrate that KGRAG-SC achieves
superior semantic fidelity in low Signal-to-Noise Ratio (SNR) conditions while
significantly reducing transmission overhead compared to traditional
communication methods, highlighting the effectiveness of integrating structured
knowledge representation with generative language models for SC systems.

</details>


### [172] [SemSteDiff: Generative Diffusion Model-based Coverless Semantic Steganography Communication](https://arxiv.org/abs/2509.04803)
*Song Gao,Rui Meng,Xiaodong Xu,Haixiao Gao,Yiming Liu,Chenyuan Feng,Ping Zhang,Tony Q. S. Quek,Dusit Niyato*

Main category: eess.SP

TL;DR: 提出了一种基于生成扩散模型的无封面语义隐写通信（SemSteDiff）方案，解决了现有方案对封面图像的依赖问题，并提高了通信安全性和有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的语义隐写通信（SemSteCom）方案在图像传输中依赖预选的封面图像，限制了其通用性。此外，传统的通信方式也面临窃听威胁，智能窃听者可能利用先进的语义分析技术推断秘密信息。

Method: 提出了一种基于生成扩散模型的无封面语义隐写通信（SemSteDiff）方案，将秘密图像隐藏到生成的隐写图像中。该方案利用语义相关的公私钥对，确保合法接收者能够正确解码秘密图像，而没有完整密钥的窃听者则无法获取。

Result: 仿真结果表明，该方案在不同的联合信源信道编码（JSCC）框架中具有即插即用的有效性。与窃听者相比，在信噪比（SNR）为0 dB时，合法接收者的峰值信噪比（PSNR）高出4.14 dB。

Conclusion: 所提出的SemSteDiff方案有效地解决了现有SemSteCom方案的局限性，并通过生成图像的方式提高了通用性。该方案在通信安全性和效率方面表现出色，能够有效抵御窃听威胁。

Abstract: Semantic communication (SemCom), as a novel paradigm for future communication
systems, has recently attracted much attention due to its superiority in
communication efficiency. However, similar to traditional communication, it
also suffers from eavesdropping threats. Intelligent eavesdroppers could launch
advanced semantic analysis techniques to infer secret semantic information.
Therefore, some researchers have designed Semantic Steganography Communication
(SemSteCom) scheme to confuse semantic eavesdroppers. However, the
state-of-the-art SemSteCom schemes for image transmission rely on the
pre-selected cover image, which limits the universality. To address this issue,
we propose a Generative Diffusion Model-based Coverless Semantic Steganography
Communication (SemSteDiff) scheme to hide secret images into generated stego
images. The semantic related private and public keys enable legitimate receiver
to decode secret images correctly while the eavesdropper without completely
true key-pairs fail to obtain them. Simulation results demonstrate the
effectiveness of the plug-and-play design in different Joint Source-Channel
Coding (JSCC) frameworks. The comparison results under different eavesdroppers'
threats show that, when Signal-to-Noise Ratio (SNR) = 0 dB, the peak
signal-to-noise ratio (PSNR) of the legitimate receiver is 4.14 dB higher than
that of the eavesdropper.

</details>


### [173] [AI-Driven Fronthaul Link Compression in Wireless Communication Systems: Review and Method Design](https://arxiv.org/abs/2509.04805)
*Keqin Zhang*

Main category: eess.SP

TL;DR: AI驱动的无线通信波束成形和CSI反馈压缩技术，特别是在无细胞架构下的应用。


<details>
  <summary>Details</summary>
Motivation: 传统波束成形和CSI反馈压缩方法在带宽和延迟限制下效果不佳，需要更优的压缩策略。

Method: 1. 调研AI驱动的压缩技术；2. 分析了两种高压缩路线：端到端学习的CSI反馈压缩和RB粒度预编码优化压缩；3. 提出一种面向无细胞架构的波束成形和CSI反馈压缩策略。

Result: 提出的压缩策略在实现高压缩率的同时，能有效控制性能损失，支持RB级别速率自适应，并满足低延迟需求，适用于未来蜂窝网络中的集中式协同传输。

Conclusion: AI驱动的压缩技术，特别是针对无细胞架构的策略，为解决无线通信中的带宽和延迟挑战提供了有前景的解决方案。

Abstract: Modern fronthaul links in wireless systems must transport high-dimensional
signals under stringent bandwidth and latency constraints, which makes
compression indispensable. Traditional strategies such as compressed sensing,
scalar quantization, and fixed-codec pipelines often rely on restrictive
priors, degrade sharply at high compression ratios, and are hard to tune across
channels and deployments. Recent progress in Artificial Intelligence (AI) has
brought end-to-end learned transforms, vector and hierarchical quantization,
and learned entropy models that better exploit the structure of Channel State
Information(CSI), precoding matrices, I/Q samples, and LLRs. This paper first
surveys AI-driven compression techniques and then provides a focused analysis
of two representative high-compression routes: CSI feedback with end-to-end
learning and Resource Block (RB) granularity precoding optimization combined
with compression. Building on these insights, we propose a fronthaul
compression strategy tailored to cell-free architectures. The design targets
high compression with controlled performance loss, supports RB-level rate
adaptation, and enables low-latency inference suitable for centralized
cooperative transmission in next-generation networks.

</details>


### [174] [Plug-and-Play Latent Diffusion for Electromagnetic Inverse Scattering with Application to Brain Imaging](https://arxiv.org/abs/2509.04860)
*Rui Guo,Yi Zhang,Yhonatan Kvich,Tianyao Huang,Maokun Li,Yonina C. Eldar*

Main category: eess.SP

TL;DR: 提出一种基于潜在扩散模型的电磁成像方法，用于定量脑部电磁成像，以解决现有方法在可解释性、失真误差和可靠性方面存在的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有电磁成像方法在解决非线性、不适定性问题时，在结合先验分布或提供理论保证方面存在不足，难以平衡可解释性、失真误差和可靠性。

Method: 该方法基于生成即插即用（PnP）后验采样框架，利用潜在扩散模型学习目标（介电常数和电导率图）的先验分布，并将其整合到基于物理的逆散射问题求解中。通过交替使用强制似然和先验分布的采样器进行后验采样，并基于采样结果进行最小均方误差（MMSE）估计以获得可靠重建。

Result: 在脑部成像实验中，该方法在重建精度和结构相似性方面达到了最先进的性能，同时保持了高测量保真度。

Conclusion: 该方法能够有效地将先验知识整合到基于物理的逆散射问题中，解决了现有方法的局限性，并在脑部成像应用中取得了优越的重建效果。

Abstract: Electromagnetic (EM) imaging is an important tool for non-invasive sensing
with low-cost and portable devices. One emerging application is EM stroke
imaging, which enables early diagnosis and continuous monitoring of brain
strokes. Quantitative imaging is achieved by solving an inverse scattering
problem (ISP) that reconstructs permittivity and conductivity maps from
measurements. In general, the reconstruction accuracy is limited by its
inherent nonlinearity and ill-posedness. Existing methods, including
learning-free and learning-based approaches, fail to either incorporate
complicated prior distributions or provide theoretical guarantees, posing
difficulties in balancing interpretability, distortion error, and reliability.
To overcome these limitations, we propose a posterior sampling method based on
latent diffusion for quantitative EM brain imaging, adapted from a generative
plug-and-play (PnP) posterior sampling framework. Our approach allows to
flexibly integrate prior knowledge into physics-based inversion without
requiring paired measurement-label datasets. We first learn the prior
distribution of targets from an unlabeled dataset, and then incorporate the
learned prior into posterior sampling. In particular, we train a latent
diffusion model on permittivity and conductivity maps to capture their prior
distribution. Then, given measurements and the forward model describing EM wave
physics, we perform posterior sampling by alternating between two samplers that
respectively enforce the likelihood and prior distributions. Finally, reliable
reconstruction is obtained through minimum mean squared error (MMSE) estimation
based on the samples. Experimental results on brain imaging demonstrate that
our approach achieves state-of-the-art performance in reconstruction accuracy
and structural similarity while maintaining high measurement fidelity.

</details>


### [175] [Rotatable Antenna Aided Mixed Near-Field and Far-Field Communications in the Upper Mid-Band: Interference Analysis and Joint Optimization](https://arxiv.org/abs/2509.04865)
*Yunpu Zhang,Changsheng You,Hing Cheung So,Dusit Niyato*

Main category: eess.SP

TL;DR: 通过利用天线旋转提供的新空间自由度来提高混合近场和远场通信系统的性能。


<details>
  <summary>Details</summary>
Motivation: 为了提高混合近场和远场通信系统中近场用户的和速率，并缓解近场和混合场干扰。

Method: 提出了一个优化问题，通过联合优化功率分配和所有子阵列的旋转角度来最大化近场用户的和速率。通过分析共享相同旋转角度的特殊情况，得到了基于夫琅禾费积分的近场干扰和混合场干扰的闭式表达式。对于涉及子阵列旋转的通用情况，提出了一种双层算法，其中内层使用连续凸近似（SCA）技术优化功率分配，外层通过粒子群优化（PSO）确定所有子阵列的旋转角度。

Result: 分析表明，天线旋转能有效抑制近场和混合场干扰。数值结果表明，与传统固定天线系统相比，旋转天线（RA）系统实现了显著的性能提升，并且所提出的联合设计优于基准方案。

Conclusion: 旋转天线（RA）可以有效提高混合近场和远场通信系统的性能，并且所提出的联合优化方法能够有效解决此问题。

Abstract: In this paper, we propose to leverage rotatable antennas (RAs) for improving
the communication performance in mixed near-field and far-field communication
systems by exploiting a new spatial degree-of-freedom (DoF) offered by antenna
rotation to mitigate complex near-field interference and mixed-field
interference. Specifically, we investigate a modular RA-enabled mixed-field
downlink communication system, where a base station (BS) consisting of multiple
RA subarrays communicates with multiple near-field users in the presence of
several legacy far-field users. We formulate an optimization problem to
maximize the sum-rate of the near-field users by jointly optimizing the power
allocation and rotation angles of all subarrays at the BS. To gain useful
insights into the effect of RAs on mixed-field communications, we first analyze
a special case where all subarrays share the same rotation angle and obtain
closed-form expressions for the rotation-aware normalized near-field
interference and the rotation-aware normalized mixed-field interference using
the Fresnel integrals. We then analytically reveal that array rotation
effectively suppresses both interference types, thereby significantly enhancing
mixed-field communication performance. For the general case involving
subarray-wise rotation, we propose an efficient double-layer algorithm to
obtain a high-quality solution, where the inner layer optimizes power
allocation using the successive convex approximation (SCA) technique, while the
outer layer determines the rotation angles of all subarrays via particle swarm
optimization (PSO). Finally, numerical results highlight the significant
performance gains achieved by RAs over conventional fixed-antenna systems and
demonstrate the effectiveness of our developed joint design compared to
benchmark schemes.

</details>


### [176] [Movable IRS-Aided ISAC Systems: Joint Beamforming and Position Optimization](https://arxiv.org/abs/2509.04873)
*Yue Geng,Tee Hiang Cheng,Kai Zhong,Kah Chan Teh,Qingqing Wu*

Main category: eess.SP

TL;DR: 本文研究了可移动智能反射面（MIRS）辅助的通信感知一体化（ISAC）系统，旨在通过联合优化MIRS单元位置、IRS反射系数、发射波束成形和接收滤波器来最小化通信和感知服务的服务质量（QoS）所需功率。


<details>
  <summary>Details</summary>
Motivation: 为了提高IRS的适应性和性能，提出了MIRS技术，能够灵活调整IRS反射单元的位置，以应对ISAC系统中的通信和感知需求。

Method: 本文提出了两种MIRS方案：单元式控制和阵列式控制，并采用积流形优化（PRMO）方法，通过基于惩罚的变换和RBFGS算法在构造的积流形空间（PRMS）上进行变量更新，以解决联合波束成形和位置优化问题。

Result: 仿真结果表明，与传统IRS相比，MIRS在功率最小化方面表现更优，其中单元式控制方案实现了最小功率，而阵列式控制方案实现了次优解和更高的计算效率。

Conclusion: MIRS技术能够有效提升IRS辅助ISAC系统的性能，并且单元式和阵列式控制方案各有优劣，可根据实际需求进行选择。

Abstract: Driven by intelligent reflecting surface (IRS) and movable antenna (MA)
technologies, movable IRS (MIRS) has been proposed to improve the adaptability
and performance of conventional IRS, enabling flexible adjustment of the IRS
reflecting element positions. This paper investigates MIRS-aided integrated
sensing and communication (ISAC) systems. The objective is to minimize the
power required for satisfying the quality-of-service (QoS) of sensing and
communication by jointly optimizing the MIRS element positions, IRS reflection
coefficients, transmit beamforming, and receive filters. To balance the
performance-cost trade-off, we proposed two MIRS schemes: element-wise control
and array-wise control, where the positions of individual reflecting elements
and arrays consisting of multiple elements are controllable, respectively. To
address the joint beamforming and position optimization, a product Riemannian
manifold optimization (PRMO) method is proposed, where the variables are
updated over a constructed product Riemannian manifold space (PRMS) in parallel
via penalty-based transformation and Riemannian
Broyden-Fletcher-Goldfarb-Shanno (RBFGS) algorithm. Simulation results
demonstrate that the proposed MIRS outperforms conventional IRS in power
minimization with both element-wise control and array-wise control.
Specifically, with different system parameters, the minimum power is achieved
by the MIRS with the element-wise control scheme, while suboptimal solution and
higher computational efficiency are achieved by the MIRS with array-wise
control scheme.

</details>


### [177] [Coupled tensor models for probability mass function estimation: Part I, Principles and algorithms](https://arxiv.org/abs/2509.04930)
*Philippe Flores,Konstantin Usevich,David Brie*

Main category: eess.SP

TL;DR: 该文章提出了一种名为PCTF3D的概率质量函数（PMF）估计方法，通过部分耦合三维数据投影（视为三维张量）来获得张量分解，以应对维度灾难。


<details>
  <summary>Details</summary>
Motivation: 为了解决维度灾难问题，提出了一种新的概率质量函数（PMF）估计方法。

Method: 该方法名为部分三维边际耦合张量分解（PCTF3D），通过部分耦合三维数据投影（视为三维张量）来获得张量分解。其中，通过超图选择三维边际的子集，并提出了几种耦合策略。

Result: 文章提出了一种新的算法框架，并进行了一些数值实验和一个应用示例。

Conclusion: PCTF3D是一种新颖的PMF估计方法，通过部分耦合三维边际来克服维度灾难。本文是两部分系列文章的第一部分，侧重于算法框架，第二部分将研究模型的唯一性。

Abstract: In this article, a Probability Mass Function (PMF) estimation method which
tames the curse of dimensionality is proposed. This method, called Partial
Coupled Tensor Factorization of 3D marginals or PCTF3D, has for principle to
partially couple order-3 data projections -- seen as order-3 tensors -- to
obtain a tensor decomposition of the probability mass tensor. The novelty of
PCTF3D relies on partial coupling which consists in choosing a subset of 3D
marginals. The choice of marginals is then formulated with hypergraphs. After
presenting possible coupling strategies, some numerical experiments and an
application of the method are proposed. This article is the first of a two-part
article. While this first article focuses on a new algorithmic framework for
PMF estimation, the second studies uniqueness properties of the model
introduced in this article.

</details>


### [178] [Coupled tensor models for probability mass function estimation: Part II, Uniqueness of the model](https://arxiv.org/abs/2509.04931)
*Philippe Flores,Konstantin Usevich,David Brie*

Main category: eess.SP

TL;DR: 研究了耦合张量模型的唯一性性质，并提出了一种基于部分耦合的张量分解方法PCTF3D，用于概率质量函数估计。


<details>
  <summary>Details</summary>
Motivation: 研究耦合张量模型的唯一性性质，并提出一种新的概率质量函数估计方法PCTF3D。

Method: 提出并研究了部分耦合张量分解（PCTF3D）方法，该方法通过耦合三维边际（视为三阶张量）来估计概率质量函数。研究了PCTF3D的约束耦合低秩模型的唯一性性质，并提出了一种雅可比算法来确定最大可恢复秩。

Result: 研究表明，虽然耦合模型的概率约束可以正确处理，但唯一性高度依赖于PCTF3D中使用的耦合策略。通过雅可比算法确定了最大可恢复秩，并分析了不同耦合策略的唯一性。

Conclusion: 提出了一个笛卡尔耦合的可辨识性界限，该界限优于现有文献的充分界限。

Abstract: In this paper, uniqueness properties of a coupled tensor model are studied.
This new coupled tensor model is used in a new method called Partial Coupled
Tensor Factorization of 3D marginals or PCTF3D. This method performs estimation
of probability mass functions by coupling 3D marginals, seen as order-3
tensors. The core novelty of PCTF3D's approach (detailed in the part I article)
relies on the partial coupling which consists on the choice of 3D marginals to
be coupled. Tensor methods are ubiquitous in many applications of statistical
learning, with their biggest advantage of having strong uniqueness properties.
In this paper, the uniqueness properties of PCTF3D's constrained coupled
low-rank model is assessed. While probabilistic constraints of the coupled
model are handled properly, it is shown that uniqueness highly depends on the
coupling used in PCTF3D. After proposing a Jacobian algorithm providing maximum
recoverable rank, different coupling strategies presented in the Part I article
are examined with respect to their uniqueness properties. Finally, an
identifiability bound is given for a so-called Cartesian coupling which permits
enhancing sufficient bounds of the literature.

</details>


### [179] [ROPE: A Novel Method for Real-Time Phase Estimation of Complex Biological Rhythms](https://arxiv.org/abs/2509.04962)
*Antonio Spallone,Marco Coraggio,Francesco De Lellis,Mario di Bernardo*

Main category: eess.SP

TL;DR: ROPE是一种新的实时多维信号相位估计算法，比现有方法更准确、更鲁棒。


<details>
  <summary>Details</summary>
Motivation: 现有相位估计算法通常仅限于离线处理和一维信号，无法满足实时多维信号分析的需求。

Method: ROPE通过识别信号中的重复来分割信号，并通过搜索先前信号段来分配相位值，从而实现实时、高精度的相位估计。

Result: ROPE在各种信号类型（包括混沌动力学系统、人体运动捕捉数据和心电图记录）上进行了广泛验证，结果表明其在噪声和信号漂移下具有鲁棒性，并且性能优于现有最先进的方法。

Conclusion: ROPE能够实现对复杂生物节律的实时分析，为早期诊断病理性节律紊乱和开发基于节律的治疗干预措施开辟了新的途径。

Abstract: Accurate phase estimation -- the process of assigning phase values between
$0$ and $2\pi$ to repetitive or periodic signals -- is a cornerstone in the
analysis of oscillatory signals across diverse fields, from neuroscience to
robotics, where it is fundamental, e.g., to understanding coordination in
neural networks, cardiorespiratory coupling, and human-robot interaction.
However, existing methods are often limited to offline processing and/or
constrained to one-dimensional signals. In this paper, we introduce ROPE,
which, to the best of our knowledge, is the first phase-estimation algorithm
capable of (i) handling signals of arbitrary dimension and (ii) operating in
real-time, with minimal error. ROPE identifies repetitions within the signal to
segment it into (pseudo-)periods and assigns phase values by performing
efficient, tractable searches over previous signal segments. We extensively
validate the algorithm on a variety of signal types, including trajectories
from chaotic dynamical systems, human motion-capture data, and
electrocardiographic recordings. Our results demonstrate that ROPE is robust
against noise and signal drift, and achieves significantly superior performance
compared to state-of-the-art phase estimation methods. This advancement enables
real-time analysis of complex biological rhythms, opening new pathways, for
example, for early diagnosis of pathological rhythm disruptions and developing
rhythm-based therapeutic interventions in neurological and cardiovascular
disorders.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [180] [Dirac quantum criticality in twisted double bilayer transition metal dichalcogenides](https://arxiv.org/abs/2509.04561)
*Jan Biedermann,Lukas Janssen*

Main category: cond-mat.mes-hall

TL;DR: ABBA堆叠的摩尔双层过渡金属二卤化物在扭转角和压力下的相图研究，发现在$
u = 2$时，系统存在狄拉克半金属相。小扭转角下，相互作用占主导，存在铁磁性和反铁磁性绝缘体。通过哈特里-福克计算，发现扭转角或压力变化可驱动从半金属到反铁磁绝缘体的连续相变，属于(2+1)D狄拉克-格罗斯-涅吾-海森堡超普类。异质应变会导致在低温下向(2+1)D海森堡临界性的交叉。进一步减小扭转角可导致从反铁磁绝缘体到铁磁绝缘体的能级交叉。


<details>
  <summary>Details</summary>
Motivation: 研究ABBA堆叠的摩尔双层过渡金属二卤化物在扭转角和压力下的相图，特别是$
u = 2$时的狄拉克半金属相以及相互作用对其行为的影响，并与实验结果进行对比。

Method: 使用实际的连续模型和长程库仑相互作用，进行自洽哈特里-福克计算，研究不同状态的竞争，并分析了(2+1)D狄拉克-格罗斯-涅吾-海森堡超普类和(2+1)D海森堡临界性。

Result: 发现在小扭转角下，相互作用占主导，存在铁磁性和反铁磁性绝缘体。扭转角或压力变化可驱动从狄拉克半金属到反铁磁绝缘体的连续相变。异质应变会导致在低温下向(2+1)D海森堡临界性的交叉。进一步减小扭转角可导致从反铁磁绝缘体到铁磁绝缘体的能级交叉。

Conclusion: 提供了研究扭转双层二硒化钨实验的理论框架，解释了不同相变和普类行为。

Abstract: We investigate the phase diagram of moir\'e double bilayer transition metal
dichalcogenides with ABBA stacking as a function of twist angle and applied
pressure. At hole filling $\nu = 2$ per moir\'e unit cell, the noninteracting
system hosts a Dirac semimetal with graphene-like low-energy bands in the
moir\'e Brillouin zone. At small twist angles, the Fermi velocity is reduced
and interactions dominate the low-temperature behavior. A strong-coupling
analysis identifies insulating ferromagnetic and antiferromagnetic ground-state
candidates, characterized by spin-density modulations set by the moir\'e scale.
Using a realistic continuum model with long-range Coulomb interactions, we
perform self-consistent Hartree-Fock calculations to study the competition
between these states. Varying the twist angle or pressure drives a transition
from a Dirac semimetal to an antiferromagnetic insulator, which breaks SU(2)
spin rotation and two-fold lattice rotation symmetries. This
semimetal-to-insulator transition is continuous and belongs to the (2+1)D
relativistic Gross-Neveu-Heisenberg universality class with $N = 2$
four-component Dirac fermions. Finite heterostrain, relevant in realistic
samples, induces a crossover from Gross-Neveu-Heisenberg universality at
intermediate temperatures to conventional (2+1)D Heisenberg criticality at the
lowest temperatures. Further decreasing the twist angle can cause a level
crossing from the antiferromagnetic insulator into a ferromagnetic insulator
with spin-split bands. Our results provide a comprehensive theoretical
framework that complements and elucidates recent experiments in twisted double
bilayer WSe$_2$.

</details>


### [181] [Thermoelectric transport in graphene under strain fields modeled by Dirac oscillators](https://arxiv.org/abs/2509.04704)
*Juan A. Cañas,Daniel A. Bonilla,A. Martín-Ruiz*

Main category: cond-mat.mes-hall

TL;DR: 本研究利用2D狄拉克振子模型研究了单层石墨烯在随机应变场下的热电输运性质。


<details>
  <summary>Details</summary>
Motivation: 理解石墨烯的热电输运行为对于开发新型纳米电子和能量收集器件至关重要。

Method: 使用半经典玻尔兹曼输运形式，并通过散射方法计算了散射时间，然后推导出电导率、塞贝克系数和热导率的解析表达式，并研究了散射中心密度对温度的依赖性。

Result: 研究结果揭示了应变如何调节输运系数，并强调了机械变形与石墨烯热电性能之间的相互作用。

Conclusion: 该研究为应变工程在基于石墨烯的热电器件中的应用提供了理论基础。

Abstract: Graphene has emerged as a paradigmatic material in condensed matter physics
due to its exceptional electronic, mechanical, and thermal properties. A deep
understanding of its thermoelectric transport behavior is crucial for the
development of novel nanoelectronic and energy-harvesting devices. In this
work, we investigate the thermoelectric transport properties of monolayer
graphene subjected to randomly distributed localized strain fields, which
locally induce impurity-like perturbations. These strain-induced impurities are
modeled via 2D Dirac oscillators, capturing the coupling between
pseudorelativistic charge carriers and localized distortions in the lattice.
Employing the semiclassical Boltzmann transport formalism, we compute the
relaxation time using a scattering approach tailored to the Dirac oscillator
potential. From this framework, we derive analytical expressions for the
electrical conductivity, Seebeck coefficient, and thermal conductivity. The
temperature dependence of the scattering centers density is also investigated.
Our results reveal how strain modulates transport coefficients, highlighting
the interplay between mechanical deformations and thermoelectric performance in
graphene. This study provides a theoretical foundation for strain engineering
in thermoelectric graphene-based devices.

</details>


### [182] [Cone-dependent retro and specular Andreev reflections in AA-stacked bilayer graphene](https://arxiv.org/abs/2509.04841)
*Wei-Tao Lu,Qing-Feng Sun*

Main category: cond-mat.mes-hall

TL;DR: AA堆叠双层石墨烯/超导体结点的Andreev反射性质受锥体自由度的影响，可以通过调节层间势差实现镜面反射和回旋反射之间的切换，并用于空间分离不同锥体的载流子。


<details>
  <summary>Details</summary>
Motivation: 研究AA堆叠双层石墨烯/超导体(AABG/SC)结点的Andreev反射(AR)性质，特别是锥体自由度对其性质的影响。

Method: 理论研究AA堆叠双层石墨烯/超导体结点的Andreev反射。

Result: 在无层间电势差时，只发生锥内AR和正常反射(NR)，锥间过程被禁止。存在层间电势差时，会发生锥间散射，导致双重AR和双重NR。锥间镜面AR(SAR)和回旋正常反射(RNR)可以在较宽的电势区发生。通过调节电势可以实现SAR和RAR以及SNR和RNR之间的切换。

Conclusion: Andreev反射性质强烈依赖于锥体自由度。通过调节层间势差，可以实现不同类型的AR和NR，并能空间分离不同锥体的载流子。在RAR到SAR的临界值附近，可以分别测量锥依赖的Andreev电导。

Abstract: We theoretically study the Andreev reflection (AR) in AA-stacked bilayer
graphene/superconductor (AABG/SC) junction. AABG has a linear gapless energy
band with two shifted Dirac cones and the electronic states are described by
the cone indices. The results indicate that the property of AR strongly depends
on the cone degree of freedom. In the absence of the inter-layer potential
difference, only intra-cone AR and normal reflection (NR) could occur, and the
inter-cone process is forbidden. By adjusting the potential, the intra-cone AR
can be specular AR (SAR) in one cone and it is retro-AR (RAR) in the other
cone. The existence of the inter-layer potential difference would lead to the
inter-cone scattering. As a result, double ARs and double NRs can take place
between the two cones. The inter-cone SAR could happen in a broad potential
region. Furthermore, the inter-cone retro-NR (RNR) could happen as well. The
switch between SAR and RAR, and the switch between specular NR (SNR) and RNR
can be achieved by regulating the potential. Therefore, different cone carriers
can be separated spatially based on the RAR and SAR. The cone-dependent Andreev
conductance may be separately measured near the critical values where RAR
crosses over to SAR.

</details>


### [183] [Revisiting the Poor Man's Majoranas: The Spin-Exchange Induced Spillover Effect](https://arxiv.org/abs/2509.05088)
*J. E. Sanches,T. M. Sobreira,L. S. Ricco,M. S. Figueira,A. C. Seridonio*

Main category: cond-mat.mes-hall

TL;DR: 本文对最小Kitaev链中的Poor Man's Majorana (PMM)模式进行了理论综述，重点研究了在电子共隧穿和交叉 Andreev反射振幅精确平衡的“最佳点”条件下，PMM在自旋交换扰动下的杂化动力学。


<details>
  <summary>Details</summary>
Motivation: 在最小Kitaev链实现中，电子共隧穿和交叉Andreev反射振幅在“最佳点”条件下精确平衡，理论上建立了Poor Man's Majorana (PMM)模式。本文旨在系统性地综述PMM在自旋交换扰动下的杂化动力学。

Method: 采用Green's函数理论框架，系统性地综述了PMM在自旋交换扰动下的杂化动力学。

Result: 理论结果表明，交换相互作用产生了对称分布在零偏压异常附近的2S+2 (2S+1)个卫星态，这是玻色子 (费米子) 自旋统计的明确标志。多端环境耦合显著抑制了自旋交换溢出机制，有效将受扰动的PMM局域化在其宿主QD内，阻止了与相邻位点的空间杂化。

Conclusion: 本文提出了一种通过PMM杂化信号进行量子自旋表征的新型光谱技术，并提出了一种在多端结构中对PMM量子比特进行工程保护的方案，以抵抗交换涨落，实现适度鲁棒的量子计算协议。

Abstract: We give a review on Poor Man's Majorana (PMM) modes, which are theoretically
established in the minimal Kitaev chain implementation consisting of two
grounded, spinless quantum dots (QDs) operating at the sweet spot condition,
where electron cotunneling and crossed Andreev reflection amplitudes achieve
precise balance. Particularly, we systematically review, within the Green's
functions theoretical framework, the PMM hybridization dynamics under
spin-exchange perturbations proposed by some of us in J. Phys.: Condens. Matter
37, 205601 (2025), which demonstrates a characteristic spatial delocalization
when subjected to an exchange coupling $J$ mediated by a quantum spin $S$. This
spin-exchange induced PMM spillover effect provides a spectroscopic protocol
for determining the quantum statistics of $S$ through the emergent multi-level
structure in the proximal QD's density of states. Our principal theoretical
result establishes that the exchange interaction generates $2S+2$ ($2S+1$)
satellite states symmetrically distributed about the zero-bias anomaly, serving
as a definitive signature of bosonic (fermionic) spin statistics. As novelty,
we demonstrate that multi-terminal environmental coupling induces significant
suppression of the spin-exchange spillover mechanism. Under constrained
variations of $J$, this effectively localizes the perturbed PMM within its host
QD, preventing spatial hybridization with adjacent site. The absence of
topological protection in this minimal Kitaev realization is strategically
leveraged to: (i) Develop a novel spectroscopic technique for quantum spin
characterization through PMM hybridization signatures; (ii) Propose an
engineered protection scheme for PMM qubits against exchange fluctuations in
multi-terminal architectures, enabling moderately robust quantum computation
protocols.

</details>


### [184] [Universal Boundary-Modes Localization from Quantum Metric Length](https://arxiv.org/abs/2509.05114)
*Xing-Lei Ma,Jin-Xin Hu,K. T. Law*

Main category: cond-mat.mes-hall

TL;DR: 论文提出量子度量长度（QML）是影响拓扑平带边界模式空间范围的关键因素，并提出了一种基于大量子度量的简并流形构建拓扑平带的框架。


<details>
  <summary>Details</summary>
Motivation: 由于拓扑量子物质中边界模式的局部化是其明确的标志，而其空间范围通常受到拓扑不变量的保护，但我们在此证明，多带拓扑系统中固有的量子度量长度（QML）决定了平带拓扑边界模式的空间范围。

Method: 提出了一种构建拓扑平带的框架，该框架基于具有大量子度量的简并流形。研究了边界模式的双相空间行为：传统的振荡衰减（由裸带色散引起）和由量子几何控制的指数衰减。QML（源自简并流形量子度量）为平带极限下边界态的空间扩展设定了下限。

Result: 将所提出的框架应用于具体模型，验证了QML在塑造拓扑边界模式的远场行为中的普遍作用。通过调节QML，发现了非局域输运现象，如QML塑造的量子霍尔平台和异常夫琅和费图案。

Conclusion: 所提出的理论框架为设计拓扑平带系统中的边界模式局域化提供了途径。

Abstract: The presence of localized boundary modes is an unambiguous hallmark of
topological quantum matter. While these modes are typically protected by
topological invariants such as the Chern number, here we demonstrate that the
{\it quantum metric length} (QML), a quantity inherent in multi-band
topological systems, governs the spatial extent of flat-band topological
boundary modes. We introduce a framework for constructing topological flat
bands from degenerate manifolds with large quantum metric and find that the
boundary modes exhibit dual phases of spatial behaviors: a conventional
oscillatory decay arising from bare band dispersion, followed by another
exponential decay controlled by quantum geometry. Crucially, the QML, derived
from the quantum metric of the degenerate manifolds, sets a lower bound on the
spatial spread of boundary states in the flat-band limit. Applying our
framework to concrete models, we validate the universal role of the QML in
shaping the long-range behavior of topological boundary modes. Furthermore, by
tuning the QML, we unveil extraordinary non-local transport phenomena,
including QML-shaped quantum Hall plateaus and anomalous Fraunhofer patterns.
Our theoretical framework paves the way for engineering boundary-modes
localization in topological flat-band systems.

</details>


### [185] [Continuum Landau surface states in a non-Hermitian Weyl semimetal](https://arxiv.org/abs/2509.05138)
*Shuxin Lin,Rimi Banerjee,Zheyu Cheng,Kohei Kawabata,Baile Zhang,Y. D. Chong*

Main category: cond-mat.mes-hall

TL;DR: 文章主要研究了非厄米(NH)拓扑相表面态中的NH手征反常现象，并发现该反常现象是由一类特殊的NH本征态——连续朗道模(CLMs)介导的。


<details>
  <summary>Details</summary>
Motivation: 研究非厄米拓扑相表面态的物理性质，特别是NH手征反常现象的起源和机制。

Method: 理论分析了连续朗道模(CLMs)的性质，包括其归一化条件和局域长度随磁场强度的标度律，并将其与NH反常方程的要求进行对比。同时，讨论了通过开放边界条件下的透射测量等实验手段探测表面态和NH反常的可行性。

Result: 发现CLMs具有空间局域和连续谱的特性，满足NH反常方程的要求。研究表明，在开放边界条件下，表面态是CLMs和NH皮肤效应诱导的皮肤模的混合，但NH反常可以通过不同磁场下的透射测量来观察。

Conclusion: NH手征反常现象是由CLMs介导的，并且可以通过实验手段（如在超材料平台上进行透射测量）进行探测。

Abstract: The surface states of topological phases, which owe their existence to bulk
topological band invariants, possess many features of deep physical
significance. In some instances, they can be linked to a quantum anomaly: the
violation of a classical symmetry by a field theory through the emergence of a
non-conserved current. This phenomenon was recently generalized to the
non-Hermitian (NH) regime, in the form of an NH chiral anomaly occurring in the
surfaces states of an NH Weyl phase. Here, we show that the anomalous NH
current is mediated by continnum Landau modes (CLMs) an exotic class of NH
eigenstates exhibiting both spatial localization and a continuous spectrum,
contrary to the usual distinction between bound and free states. The conditions
for which CLMs are normalized, and their scaling of localization length with
magnetic field strength, are found to match the requirements of the NH anomaly
equation. We also discuss the conditions under which these surface states can
be probed experimentally, such as on metamaterial platforms. For instance,
under open boundary conditions, the surface states are a mix of CLMs and skin
modes induced by the NH skin effect, but the NH anomaly can be observed through
transmission measurements under different magnetic fields.

</details>


### [186] [Reply to the Comment by Tikhonov and Khrapai on "Long-range crossed Andreev reflection in a topological insulator nanowire proximitized by a superconductor"](https://arxiv.org/abs/2509.05153)
*Junya Feng,Henry F. Legg,Mahasweta Bagchi,Daniel Loss,Jelena Klinovaja,Yoichi Ando*

Main category: cond-mat.mes-hall

TL;DR: 评论未能发现任何科学错误，其论点实际上支持了我们出版物的主要结论。


<details>
  <summary>Details</summary>
Motivation: 评论文章指出，在非线性效应相关的“主导CAR”概念的理解上存在更广泛的解读空间。

Method: 文章反驳了评论的论点，指出评论的论证过程依赖于文章得出的两个主要结论：1. 大尺度的约瑟夫森二极管效应（CAR）的存在；2. CAR与弹性共隧穿（elastic co-tunneling）之间复杂的相互作用。

Result: 评论文章未能识别出任何科学错误，并且其论点支持了文章的结论。

Conclusion: 评论文章本质上只是指出了在非线性效应相关的“主导CAR”概念的理解上存在更广泛的解读空间，而这恰恰印证了文章的两个主要结论。

Abstract: The comment (arXiv:2505.23490) fails to identify any scientific errors and
its central arguments actually support the main conclusions of our publication
[Nat. Phys. 21, 708 (2025)]. Firstly, the whole argument of the comment to try
to explain our data explicitly relies on the existence of a large crossed
Andreev reflection (CAR) effect. The presence of a sizable CAR transmission
probability over a surprisingly long distance is the first conclusion of our
publication. Secondly, the comment discusses the complex interplay of CAR and
elastic co-tunneling, especially in the presence of local effects. This complex
interplay is precisely the second conclusion of our publication. In essence,
the comment amounts to merely pointing out that there is a broader sense in the
notion of "dominant CAR" when nonlinear effects become relevant.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [187] [Analyzing Gait Adaptation with Hemiplegia Simulation Suits and Digital Twins](https://arxiv.org/abs/2509.05116)
*Jialin Chen,Jeremie Clos,Dominic Price,Praminda Caleb-Solly*

Main category: cs.ET

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: To advance the development of assistive and rehabilitation robots, it is
essential to conduct experiments early in the design cycle. However, testing
early prototypes directly with users can pose safety risks. To address this, we
explore the use of condition-specific simulation suits worn by healthy
participants in controlled environments as a means to study gait changes
associated with various impairments and support rapid prototyping. This paper
presents a study analyzing the impact of a hemiplegia simulation suit on gait.
We collected biomechanical data using a Vicon motion capture system and Delsys
Trigno EMG and IMU sensors under four walking conditions: with and without a
rollator, and with and without the simulation suit. The gait data was
integrated into a digital twin model, enabling machine learning analyses to
detect the use of the simulation suit and rollator, identify turning behavior,
and evaluate how the suit affects gait over time. Our findings show that the
simulation suit significantly alters movement and muscle activation patterns,
prompting users to compensate with more abrupt motions. We also identify key
features and sensor modalities that are most informative for accurately
capturing gait dynamics and modeling human-rollator interaction within the
digital twin framework.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [188] [Emergent Social Dynamics of LLM Agents in the El Farol Bar Problem](https://arxiv.org/abs/2509.04537)
*Ryosuke Takata,Atsushi Masumori,Takashi Ikegammi*

Main category: cs.MA

TL;DR: LLM代理在El Farol Bar问题中表现出类似人类的社会动态，平衡了理论理性和社会动机。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型（LLM）代理在空间扩展的El Farol Bar问题中涌现的社会动态，以及它们如何自主地解决这个经典的社会困境。

Method: 在El Farol Bar问题中，让LLM代理自主导航并观察它们的决策过程。

Result: LLM代理表现出自发性的去酒吧的动机，并通过集体行为改变了决策。它们并未完全解决该问题，但行为更像人类，平衡了外部激励（如60%阈值）和内部激励（来自预训练的文化编码的社会偏好）。

Conclusion: LLM代理能够实现新的群体决策模型，这在以往的博弈论问题设置中是无法实现的，它们自然地平衡了形式上的博弈论理性和人类行为特征的社会动机。

Abstract: We investigate the emergent social dynamics of Large Language Model (LLM)
agents in a spatially extended El Farol Bar problem, observing how they
autonomously navigate this classic social dilemma. As a result, the LLM agents
generated a spontaneous motivation to go to the bar and changed their decision
making by becoming a collective. We also observed that the LLM agents did not
solve the problem completely, but rather behaved more like humans. These
findings reveal a complex interplay between external incentives
(prompt-specified constraints such as the 60\% threshold) and internal
incentives (culturally-encoded social preferences derived from pre-training),
demonstrating that LLM agents naturally balance formal game-theoretic
rationality with social motivations that characterize human behavior. These
findings suggest that a new model of group decision making, which could not be
handled in the previous game-theoretic problem setting, can be realized by LLM
agents.

</details>


### [189] [LLM Enabled Multi-Agent System for 6G Networks: Framework and Method of Dual-Loop Edge-Terminal Collaboration](https://arxiv.org/abs/2509.04993)
*Zheyan Qu,Wenbo Wang,Zitong Yu,Boquan Sun,Yang Li,Xing Zhang*

Main category: cs.MA

TL;DR: 6G网络中的LLM智能体需要高效的多层设备协作来克服资源限制。本文提出了一个包含终端-边缘双环协作的LLM多智能体系统框架和方法，通过任务分解、并行子任务分配和带卸载策略的并行工具调用来提高规划和执行效率。


<details>
  <summary>Details</summary>
Motivation: 个别网络设备的资源限制严重阻碍了具有复杂工具调用的LLM智能体的高效运行，因此迫切需要高效的多层设备协作。

Method: 提出了一种在6G网络中具有双环终端-边缘协作的LLM使能的多智能体系统框架和方法。外环通过全局智能体和部署在边缘服务器和终端上的多个子智能体之间的迭代协作，通过任务分解和并行子任务分配来增强规划能力。内环利用具有专门角色的子智能体来循环推理、执行和重新规划子任务，并结合具有卸载策略的并行工具调用生成来提高效率。

Result: 通过在6G支持的城市安全治理中进行的案例研究，验证了改进的任务规划能力和任务执行效率。

Conclusion: 在6G网络中，LLM智能体通过代理框架融合了公共计算资源，提高了服务效率。虽然在资源有限的情况下，LLM智能体面临着挑战，但所提出的双环终端-边缘协作框架通过任务分解、并行子任务分配和带卸载策略的并行工具调用，显著提高了LLM智能体的规划和执行效率。

Abstract: The ubiquitous computing resources in 6G networks provide ideal environments
for the fusion of large language models (LLMs) and intelligent services through
the agent framework. With auxiliary modules and planning cores, LLM-enabled
agents can autonomously plan and take actions to deal with diverse environment
semantics and user intentions. However, the limited resources of individual
network devices significantly hinder the efficient operation of LLM-enabled
agents with complex tool calls, highlighting the urgent need for efficient
multi-level device collaborations. To this end, the framework and method of the
LLM-enabled multi-agent system with dual-loop terminal-edge collaborations are
proposed in 6G networks. Firstly, the outer loop consists of the iterative
collaborations between the global agent and multiple sub-agents deployed on
edge servers and terminals, where the planning capability is enhanced through
task decomposition and parallel sub-task distribution. Secondly, the inner loop
utilizes sub-agents with dedicated roles to circularly reason, execute, and
replan the sub-task, and the parallel tool calling generation with offloading
strategies is incorporated to improve efficiency. The improved task planning
capability and task execution efficiency are validated through the conducted
case study in 6G-supported urban safety governance. Finally, the open
challenges and future directions are thoroughly analyzed in 6G networks,
accelerating the advent of the 6G era.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [190] [In-Context Policy Adaptation via Cross-Domain Skill Diffusion](https://arxiv.org/abs/2509.04535)
*Minjong Yoo,Woo Kyung Kim,Honguk Woo*

Main category: cs.RO

TL;DR: ICPAD框架通过跨领域技能扩散和动态领域提示，在模型更新受限且目标领域数据有限的情况下，实现了长时域多任务环境下的快速策略适应。


<details>
  <summary>Details</summary>
Motivation: 在长时域多任务环境中，尤其是在不允许模型更新且目标领域数据有限的条件下，实现技能策略的快速适应。

Method: 学习领域不可知原型技能和领域接地技能适配器，并通过动态领域提示来增强适应性能。采用跨领域技能扩散方案，在离线数据集上联合学习。

Result: 在机器人操作（Metaworld）和自动驾驶（CARLA）的实验中，ICPAD框架在数据受限的跨领域配置下（包括环境动力学、代理体现和任务时域的差异）展现出优越的策略适应性能。

Conclusion: ICPAD框架能够有效地在模型更新受限且目标领域数据有限的情况下，在长时域多任务环境中实现跨领域的策略适应。

Abstract: In this work, we present an in-context policy adaptation (ICPAD) framework
designed for long-horizon multi-task environments, exploring diffusion-based
skill learning techniques in cross-domain settings. The framework enables rapid
adaptation of skill-based reinforcement learning policies to diverse target
domains, especially under stringent constraints on no model updates and only
limited target domain data. Specifically, the framework employs a cross-domain
skill diffusion scheme, where domain-agnostic prototype skills and a
domain-grounded skill adapter are learned jointly and effectively from an
offline dataset through cross-domain consistent diffusion processes. The
prototype skills act as primitives for common behavior representations of
long-horizon policies, serving as a lingua franca to bridge different domains.
Furthermore, to enhance the in-context adaptation performance, we develop a
dynamic domain prompting scheme that guides the diffusion-based skill adapter
toward better alignment with the target domain. Through experiments with
robotic manipulation in Metaworld and autonomous driving in CARLA, we show that
our $\oursol$ framework achieves superior policy adaptation performance under
limited target domain data conditions for various cross-domain configurations
including differences in environment dynamics, agent embodiment, and task
horizon.

</details>


### [191] [Action Chunking with Transformers for Image-Based Spacecraft Guidance and Control](https://arxiv.org/abs/2509.04628)
*Alejandro Posadas-Nava,Andrea Scorsoglio,Luca Ghilardi,Roberto Furfaro,Richard Linares*

Main category: cs.RO

TL;DR: 该研究提出了一种名为ACT的模仿学习方法，仅用少量数据（100个专家演示）即可在航天器引导、导航和控制（GNC）任务中取得高绩效。


<details>
  <summary>Details</summary>
Motivation: 为了在数据有限的情况下实现航天器GNC的高性能，提出了一种模仿学习方法。

Method: 使用名为ACT（Action Chunking with Transformers）的方法，该方法将视觉和状态观测映射到推力和扭矩指令，仅使用100个专家演示（相当于6300次环境交互）。

Result: ACT生成了比经过4000万次交互训练的元强化学习（meta-RL）基线更平稳、更一致的轨迹，并在与国际空间站（ISS）的在轨对接任务中实现了更高的精度、更平稳的控制和更高的样本效率。

Conclusion: ACT在航天器GNC任务中，尤其是在数据有限的情况下，表现出了优越的性能，实现了更高的精度、更平稳的控制和更高的样本效率。

Abstract: We present an imitation learning approach for spacecraft guidance,
navigation, and control(GNC) that achieves high performance from limited data.
Using only 100 expert demonstrations, equivalent to 6,300 environment
interactions, our method, which implements Action Chunking with Transformers
(ACT), learns a control policy that maps visual and state observations to
thrust and torque commands. ACT generates smoother, more consistent
trajectories than a meta-reinforcement learning (meta-RL) baseline trained with
40 million interactions. We evaluate ACT on a rendezvous task: in-orbit docking
with the International Space Station (ISS). We show that our approach achieves
greater accuracy, smoother control, and greater sample efficiency.

</details>


### [192] [Planning from Point Clouds over Continuous Actions for Multi-object Rearrangement](https://arxiv.org/abs/2509.04645)
*Kallol Saha,Amber Li,Angela Rodriguez-Izquierdo,Lifan Yu,Ben Eisner,Maxim Likhachev,David Held*

Main category: cs.RO

TL;DR: 该研究提出了一种名为SPOT的混合学习与规划方法，通过在点云中搜索物体变换序列来解决机器人长时程操作规划问题，无需离散化状态和动作，并在多物体重排任务中取得了成功。


<details>
  <summary>Details</summary>
Motivation: 长时程机器人操作规划是一个难题，需要推理连续3D场景中一系列动作的效果。传统方法需要离散化状态和动作，而本研究旨在提出一种更优的方法。

Method: 提出了一种名为SPOT（Search over Point cloud Object Transformations）的混合学习与规划方法。该方法通过在点云中搜索从初始场景到目标状态的变换序列来规划。它使用从部分观察到的点云中学习到的“建议器”来采样候选动作，避免了动作或物体关系的离散化。

Result: 在多物体重排任务中，SPOT在模拟和真实环境中都取得了成功。实验结果表明，SPOT能够生成成功的规划，并且优于基于策略学习的方法。消融实验也突显了基于搜索的规划的重要性。

Conclusion: SPOT是一种有效的解决长时程机器人操作规划问题的方法，通过利用学习模型作为先验指导高维连续动作空间中的搜索，并避免了传统方法的离散化限制。

Abstract: Long-horizon planning for robot manipulation is a challenging problem that
requires reasoning about the effects of a sequence of actions on a physical 3D
scene. While traditional task planning methods are shown to be effective for
long-horizon manipulation, they require discretizing the continuous state and
action space into symbolic descriptions of objects, object relationships, and
actions. Instead, we propose a hybrid learning-and-planning approach that
leverages learned models as domain-specific priors to guide search in
high-dimensional continuous action spaces. We introduce SPOT: Search over Point
cloud Object Transformations, which plans by searching for a sequence of
transformations from an initial scene point cloud to a goal-satisfying point
cloud. SPOT samples candidate actions from learned suggesters that operate on
partially observed point clouds, eliminating the need to discretize actions or
object relationships. We evaluate SPOT on multi-object rearrangement tasks,
reporting task planning success and task execution success in both simulation
and real-world environments. Our experiments show that SPOT generates
successful plans and outperforms a policy-learning approach. We also perform
ablations that highlight the importance of search-based planning.

</details>


### [193] [Surformer v2: A Multimodal Classifier for Surface Understanding from Touch and Vision](https://arxiv.org/abs/2509.04658)
*Manish Kansana,Sindhuja Penchala,Shahram Rahimi,Noorbakhsh Amiri Golilarz*

Main category: cs.RO

TL;DR: Surformer v2是一种新的多模态表面材料分类模型，它结合了视觉和触觉信息，并采用了决策级融合的方法，在Touch and Go数据集上表现良好。


<details>
  <summary>Details</summary>
Motivation: 为了提高机器人操作和交互的触觉感知能力，需要对多模态表面材料进行分类。

Method: Surformer v2采用CNN（Efficient V-Net）作为视觉分支，Transformer作为触觉分支，并在模型内部进行特征提取。通过对输出逻辑进行可学习的加权求和来实现决策级融合。

Result: Surformer v2在Touch and Go数据集上取得了良好的分类效果，同时保持了具有竞争力的推理速度，适用于实时机器人应用。

Conclusion: 决策级融合和基于Transformer的触觉模型能够有效提升机器人多模态感知中的表面理解能力。

Abstract: Multimodal surface material classification plays a critical role in advancing
tactile perception for robotic manipulation and interaction. In this paper, we
present Surformer v2, an enhanced multi-modal classification architecture
designed to integrate visual and tactile sensory streams through a
late(decision level) fusion mechanism. Building on our earlier Surformer v1
framework [1], which employed handcrafted feature extraction followed by
mid-level fusion architecture with multi-head cross-attention layers, Surformer
v2 integrates the feature extraction process within the model itself and shifts
to late fusion. The vision branch leverages a CNN-based classifier(Efficient
V-Net), while the tactile branch employs an encoder-only transformer model,
allowing each modality to extract modality-specific features optimized for
classification. Rather than merging feature maps, the model performs
decision-level fusion by combining the output logits using a learnable weighted
sum, enabling adaptive emphasis on each modality depending on data context and
training dynamics. We evaluate Surformer v2 on the Touch and Go dataset [2], a
multi-modal benchmark comprising surface images and corresponding tactile
sensor readings. Our results demonstrate that Surformer v2 performs well,
maintaining competitive inference speed, suitable for real-time robotic
applications. These findings underscore the effectiveness of decision-level
fusion and transformer-based tactile modeling for enhancing surface
understanding in multi-modal robotic perception.

</details>


### [194] [Bootstrapping Reinforcement Learning with Sub-optimal Policies for Autonomous Driving](https://arxiv.org/abs/2509.04712)
*Zhihao Zhang,Chengyang Peng,Ekim Yurtsever,Keith A. Redmill*

Main category: cs.RO

TL;DR: 通过结合基于规则的车道变换控制器和软 Actor-Critic (SAC) 算法，提出了一种用于自动驾驶的强化学习方法，以提高样本效率和探索能力。


<details>
  <summary>Details</summary>
Motivation: 强化学习 (RL) 在自动车辆控制中受到关注，但面临样本效率和有效探索的挑战。

Method: 将基于规则的车道变换控制器与软 Actor-Critic (SAC) 算法相结合，以增强探索和学习效率。

Result: 所提出的方法展示了改进的驾驶性能。

Conclusion: 该方法提高了驾驶性能，并可扩展到其他需要基于演示的指导的驾驶场景。

Abstract: Automated vehicle control using reinforcement learning (RL) has attracted
significant attention due to its potential to learn driving policies through
environment interaction. However, RL agents often face training challenges in
sample efficiency and effective exploration, making it difficult to discover an
optimal driving strategy. To address these issues, we propose guiding the RL
driving agent with a demonstration policy that need not be a highly optimized
or expert-level controller. Specifically, we integrate a rule-based lane change
controller with the Soft Actor Critic (SAC) algorithm to enhance exploration
and learning efficiency. Our approach demonstrates improved driving performance
and can be extended to other driving scenarios that can similarly benefit from
demonstration-based guidance.

</details>


### [195] [Hierarchical Reduced-Order Model Predictive Control for Robust Locomotion on Humanoid Robots](https://arxiv.org/abs/2509.04722)
*Adrian B. Ghansah,Sergio A. Esteban,Aaron D. Ames*

Main category: cs.RO

TL;DR: 该研究提出了一种基于降阶模型的仿人机器人运动控制框架，通过分层MPC优化步态和身体动力学，提高了机器人在不同环境下的稳定性和恢复能力。


<details>
  <summary>Details</summary>
Motivation: 为确保仿人机器人在多样化真实环境中稳健运行，需要高效的运动控制方法，以实现多样的步态规划并利用手臂和躯干动力学来提高稳定性。

Method: 提出一个计算高效的、基于降阶模型的仿人机器人运动控制框架。顶层采用ALIP模型在非线性MPC中同时优化步长、步频和脚踝力矩。底层MPC将ALIP轨迹作为参考，扩展了SRB-MPC，并纳入了简化的手臂和躯干动力学。

Result: 所提出的框架中，高层步态规划器运行频率为40Hz，中层MPC运行频率为500Hz。自适应步态定时将推恢复成功率提高了36%，上身控制提高了偏航干扰抑制能力。研究表明，机器人在草地、石砖路和不平整的垫子上等室内外多种地形上实现了稳健的运动。

Conclusion: 该分层控制框架能够有效地提高仿人机器人在不同环境下的运动能力，并在计算效率、步态灵活性和稳定性方面取得了显著的改进。

Abstract: As humanoid robots enter real-world environments, ensuring robust locomotion
across diverse environments is crucial. This paper presents a computationally
efficient hierarchical control framework for humanoid robot locomotion based on
reduced-order models -- enabling versatile step planning and incorporating arm
and torso dynamics to better stabilize the walking. At the high level, we use
the step-to-step dynamics of the ALIP model to simultaneously optimize over
step periods, step lengths, and ankle torques via nonlinear MPC. The ALIP
trajectories are used as references to a linear MPC framework that extends the
standard SRB-MPC to also include simplified arm and torso dynamics. We validate
the performance of our approach through simulation and hardware experiments on
the Unitree G1 humanoid robot. In the proposed framework the high-level step
planner runs at 40 Hz and the mid-level MPC at 500 Hz using the onboard
mini-PC. Adaptive step timing increased the push recovery success rate by 36%,
and the upper body control improved the yaw disturbance rejection. We also
demonstrate robust locomotion across diverse indoor and outdoor terrains,
including grass, stone pavement, and uneven gym mats.

</details>


### [196] [Imitation Learning Based on Disentangled Representation Learning of Behavioral Characteristics](https://arxiv.org/abs/2509.04737)
*Ryoga Oishi,Sho Sakaino,Toshiaki Tsuji*

Main category: cs.RO

TL;DR: 该研究提出了一种通过学习语言指令中的修饰词来调整机器人动作的方法。


<details>
  <summary>Details</summary>
Motivation: 适应机器人动作以满足人类指令的质量，这些指令通常是定性的并且需要满足各种条件。

Method: 将演示分割成短序列，并将与特定修饰词类型对应的弱监督标签分配给它们，从而学习从修饰词到动作的映射。

Result: 所提出的方法能够实时调整机器人动作以响应修饰词指令，而传统的基于批次的方法则无法在执行期间进行调整。

Conclusion: 该方法在机器人学习中用于适应机器人动作以响应人类指令，展示了其调整动作的有效性。

Abstract: In the field of robot learning, coordinating robot actions through language
instructions is becoming increasingly feasible. However, adapting actions to
human instructions remains challenging, as such instructions are often
qualitative and require exploring behaviors that satisfy varying conditions.
This paper proposes a motion generation model that adapts robot actions in
response to modifier directives human instructions imposing behavioral
conditions during task execution. The proposed method learns a mapping from
modifier directives to actions by segmenting demonstrations into short
sequences, assigning weakly supervised labels corresponding to specific
modifier types. We evaluated our method in wiping and pick and place tasks.
Results show that it can adjust motions online in response to modifier
directives, unlike conventional batch-based methods that cannot adapt during
execution.

</details>


### [197] [COMMET: A System for Human-Induced Conflicts in Mobile Manipulation of Everyday Tasks](https://arxiv.org/abs/2509.04836)
*Dongping Li,Shaoting Peng,John Pohovey,Katherine Rose Driggs-Campbell*

Main category: cs.RO

TL;DR: 该研究提出COMMET系统，用于解决移动操作中由人类活动引发的冲突，通过混合检测方法和GPT-4o总结用户偏好，以适应动态的家庭环境。


<details>
  <summary>Details</summary>
Motivation: 为了解决日常生活中动态且不可预测的人类活动与机器人行为之间的冲突，以及这些冲突解决方案的非唯一性和用户偏好依赖性，从而促进家用机器人的发展。

Method: 该系统采用混合检测方法，首先进行多模态检索，然后在置信度低的情况下升级到微调模型推理。利用收集的用户偏好选项和设置，使用GPT-4o总结相关案例的用户偏好。

Result: 在初步研究中，提出的检测模块相比GPT模型在准确性和延迟方面表现更优。同时，设计了一个用户友好的数据收集界面，并展示了一个有效的实际部署工作流程。

Conclusion: COMMET系统通过混合检测方法和基于GPT-4o的用户偏好总结，有效解决了家用机器人面临的人类活动冲突问题，并为未来的研究和实际部署奠定了基础。

Abstract: Continuous advancements in robotics and AI are driving the integration of
robots from industry into everyday environments. However, dynamic and
unpredictable human activities in daily lives would directly or indirectly
conflict with robot actions. Besides, due to the social attributes of such
human-induced conflicts, solutions are not always unique and depend highly on
the user's personal preferences. To address these challenges and facilitate the
development of household robots, we propose COMMET, a system for human-induced
COnflicts in Mobile Manipulation of Everyday Tasks. COMMET employs a hybrid
detection approach, which begins with multi-modal retrieval and escalates to
fine-tuned model inference for low-confidence cases. Based on collected user
preferred options and settings, GPT-4o will be used to summarize user
preferences from relevant cases. In preliminary studies, our detection module
shows better accuracy and latency compared with GPT models. To facilitate
future research, we also design a user-friendly interface for user data
collection and demonstrate an effective workflow for real-world deployments.

</details>


### [198] [A Knowledge-Driven Diffusion Policy for End-to-End Autonomous Driving Based on Expert Routing](https://arxiv.org/abs/2509.04853)
*Chengkai Xu,Jiaqi Liu,Yicheng Guo,Peng Hang,Jian Sun*

Main category: cs.RO

TL;DR: KDP是一种知识驱动的扩散策略，通过结合生成式扩散建模和稀疏专家混合路由机制，解决了端到端自动驾驶中的多模态动作生成、时间稳定性和泛化性问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多模态生成、长期一致性和模块化适应性方面存在不足，难以满足端到端自动驾驶的需求。

Method: KDP模型结合了生成式扩散建模（用于生成时间连贯且多模态的动作序列）和稀疏专家混合路由机制（根据上下文激活专门的、可重用的专家，实现模块化知识组合）。

Result: 在各种驾驶场景的实验中，KDP相比现有方法，成功率更高，碰撞风险更低，控制更平稳。消融研究证明了稀疏专家激活和Transformer骨干的有效性，激活分析揭示了专家结构化的专业化和跨场景重用。

Conclusion: KDP模型通过稀疏专家路由实现了可扩展且可解释的知识驱动的端到端自动驾驶范式。

Abstract: End-to-end autonomous driving remains constrained by the need to generate
multi-modal actions, maintain temporal stability, and generalize across diverse
scenarios. Existing methods often collapse multi-modality, struggle with
long-horizon consistency, or lack modular adaptability. This paper presents
KDP, a knowledge-driven diffusion policy that integrates generative diffusion
modeling with a sparse mixture-of-experts routing mechanism. The diffusion
component generates temporally coherent and multi-modal action sequences, while
the expert routing mechanism activates specialized and reusable experts
according to context, enabling modular knowledge composition. Extensive
experiments across representative driving scenarios demonstrate that KDP
achieves consistently higher success rates, reduced collision risk, and
smoother control compared to prevailing paradigms. Ablation studies highlight
the effectiveness of sparse expert activation and the Transformer backbone, and
activation analyses reveal structured specialization and cross-scenario reuse
of experts. These results establish diffusion with expert routing as a scalable
and interpretable paradigm for knowledge-driven end-to-end autonomous driving.

</details>


### [199] [Towards an Accurate and Effective Robot Vision (The Problem of Topological Localization for Mobile Robots)](https://arxiv.org/abs/2509.04948)
*Emanuela Boros*

Main category: cs.RO

TL;DR: 该论文提出了一种仅使用机器人上的摄像机图像进行拓扑定位的方法，并对多种视觉描述符进行了系统比较。


<details>
  <summary>Details</summary>
Motivation: 由于感知模糊、传感器噪声和光照变化，机器人的视觉定位和地点识别具有挑战性。该研究旨在解决在办公环境中仅使用透视彩色摄像头图像进行拓扑定位的问题。

Method: 评估了颜色直方图、SIFT、ASIFT、RGB-SIFT 和受文本检索启发的词袋视觉方法，并对这些特征、距离度量和分类器进行了系统的定量比较。

Result: 结果表明，适当配置外观描述符、相似性度量和分类器具有优势，并且在 ImageCLEF 评估活动中得到了验证，其中系统识别了新图像序列最可能的位置。

Conclusion: 该研究对视觉描述符、距离度量和分类器进行了全面的比较，并为未来的研究指明了方向，例如探索分层模型、排序方法和特征组合，以构建更鲁棒的实时定位系统。

Abstract: Topological localization is a fundamental problem in mobile robotics, since
robots must be able to determine their position in order to accomplish tasks.
Visual localization and place recognition are challenging due to perceptual
ambiguity, sensor noise, and illumination variations. This work addresses
topological localization in an office environment using only images acquired
with a perspective color camera mounted on a robot platform, without relying on
temporal continuity of image sequences. We evaluate state-of-the-art visual
descriptors, including Color Histograms, SIFT, ASIFT, RGB-SIFT, and
Bag-of-Visual-Words approaches inspired by text retrieval. Our contributions
include a systematic, quantitative comparison of these features, distance
measures, and classifiers. Performance was analyzed using standard evaluation
metrics and visualizations, extending previous experiments. Results demonstrate
the advantages of proper configurations of appearance descriptors, similarity
measures, and classifiers. The quality of these configurations was further
validated in the Robot Vision task of the ImageCLEF evaluation campaign, where
the system identified the most likely location of novel image sequences. Future
work will explore hierarchical models, ranking methods, and feature
combinations to build more robust localization systems, reducing training and
runtime while avoiding the curse of dimensionality. Ultimately, this aims
toward integrated, real-time localization across varied illumination and longer
routes.

</details>


### [200] [Ground-Aware Octree-A* Hybrid Path Planning for Memory-Efficient 3D Navigation of Ground Vehicles](https://arxiv.org/abs/2509.04950)
*Byeong-Il Ham,Hyun-Bin Kim,Kyung-Soo Kim*

Main category: cs.RO

TL;DR: 提出一种结合A*算法和八叉树结构的3D路径规划方法，用于UGV和足式机器人，能够利用可通行障碍物辅助导航，并生成高效、真实的路径。八叉树结构压缩地图，减少节点探索，提高计算效率和内存使用，支持实时规划。


<details>
  <summary>Details</summary>
Motivation: 机器人（UGV和足式机器人）在各种地形上的移动性研究不断深入，使得障碍物不仅是需要避开的障碍，还可以作为有益的导航辅助。因此，需要一种能够利用可通行障碍物的路径规划方法。

Method: 提出一种改进的3D A*算法，通过在成本函数中引入基于高度的惩罚，能够利用可通行的障碍物辅助导航，同时避开不可通行的障碍物。同时，采用八叉树结构的3D栅格地图，通过合并高分辨率节点（尤其是在无障碍或稀疏区域）来压缩地图，减少A*算法探索的节点数量。

Result: 基准测试结果表明，该方法在确保生成最优路径的同时，显著降低了内存使用和计算时间，实现了高效和真实的路径生成。

Conclusion: 结合A*算法和八叉树结构的3D路径规划方法能够高效、真实地生成路径，并能在实际环境中支持实时规划。

Abstract: In this paper, we propose a 3D path planning method that integrates the A*
algorithm with the octree structure. Unmanned Ground Vehicles (UGVs) and legged
robots have been extensively studied, enabling locomotion across a variety of
terrains. Advances in mobility have enabled obstacles to be regarded not only
as hindrances to be avoided, but also as navigational aids when beneficial. A
modified 3D A* algorithm generates an optimal path by leveraging obstacles
during the planning process. By incorporating a height-based penalty into the
cost function, the algorithm enables the use of traversable obstacles to aid
locomotion while avoiding those that are impassable, resulting in more
efficient and realistic path generation. The octree-based 3D grid map achieves
compression by merging high-resolution nodes into larger blocks, especially in
obstacle-free or sparsely populated areas. This reduces the number of nodes
explored by the A* algorithm, thereby improving computational efficiency and
memory usage, and supporting real-time path planning in practical environments.
Benchmark results demonstrate that the use of octree structure ensures an
optimal path while significantly reducing memory usage and computation time.

</details>


### [201] [DeGuV: Depth-Guided Visual Reinforcement Learning for Generalization and Interpretability in Manipulation](https://arxiv.org/abs/2509.04970)
*Tien Pham,Xinyun Chi,Khang Nguyen,Manfred Huber,Angelo Cangelosi*

Main category: cs.RO

TL;DR: DeGuV是一个强化学习框架，通过可学习的掩码网络、对比学习和稳定的Q值估计来提高泛化能力和样本效率，并在RL-ViGen基准测试中实现了有效的零样本模拟到真实迁移。


<details>
  <summary>Details</summary>
Motivation: 强化学习（RL）智能体虽然能从视觉输入中学习解决复杂任务，但在新环境中泛化这些学习到的技能，尤其是在机器人领域，仍然是一个主要挑战。数据增强可以提高泛化能力，但通常会影响样本效率和训练稳定性。

Method: DeGuV框架利用一个可学习的掩码网络，从深度输入生成掩码，仅保留关键视觉信息并丢弃无关像素，从而使RL智能体专注于基本特征，提高数据增强下的鲁棒性。此外，还结合了对比学习和稳定的Q值估计，以进一步提高样本效率和训练稳定性。

Result: 在RL-ViGen基准测试中使用Franka Emika机器人进行评估，结果表明DeGuV在泛化能力和样本效率方面优于最先进的方法，并且通过突出视觉输入中最相关的区域来提高可解释性。

Conclusion: DeGuV通过引入可学习的掩码网络来选择性地处理视觉输入，并结合对比学习和稳定的Q值估计，有效解决了强化学习中的泛化和样本效率挑战，并在零样本模拟到真实迁移任务中取得了优异成果。

Abstract: Reinforcement learning (RL) agents can learn to solve complex tasks from
visual inputs, but generalizing these learned skills to new environments
remains a major challenge in RL application, especially robotics. While data
augmentation can improve generalization, it often compromises sample efficiency
and training stability. This paper introduces DeGuV, an RL framework that
enhances both generalization and sample efficiency. In specific, we leverage a
learnable masker network that produces a mask from the depth input, preserving
only critical visual information while discarding irrelevant pixels. Through
this, we ensure that our RL agents focus on essential features, improving
robustness under data augmentation. In addition, we incorporate contrastive
learning and stabilize Q-value estimation under augmentation to further enhance
sample efficiency and training stability. We evaluate our proposed method on
the RL-ViGen benchmark using the Franka Emika robot and demonstrate its
effectiveness in zero-shot sim-to-real transfer. Our results show that DeGuV
outperforms state-of-the-art methods in both generalization and sample
efficiency while also improving interpretability by highlighting the most
relevant regions in the visual input

</details>


### [202] [Lyapunov-Based Deep Learning Control for Robots with Unknown Jacobian](https://arxiv.org/abs/2509.04984)
*Koji Matsuno,Chien Chern Cheah*

Main category: cs.RO

TL;DR: 深度学习控制在机器人运动控制中具有潜力，但其黑盒性质带来了挑战。本文提出了一种基于Lyapunov分析的深度学习控制框架，通过模块化学习和实时权重更新来确保系统稳定性，并已在工业机器人上进行了实验验证。


<details>
  <summary>Details</summary>
Motivation: 深度学习的黑盒性质在机器人实时控制应用中带来了严峻的挑战，尤其是在安全至关重要的机器人控制领域。为了解决这个问题，需要建立能够分析和确保机器人运动控制系统稳定性的方法。

Method: 提出了一种端到端的深度学习控制算法，该算法采用模块化学习方法实时更新所有层的权重，并基于Lyapunov类分析来确保系统稳定性。

Result: 在工业机器人上的实验结果表明，该深度学习控制器具有良好的性能，有效解决了深度学习的黑盒问题，并证明了在机器人运动学控制中稳定部署实时深度学习策略的可行性。

Conclusion: 该研究为未来基于深度学习的实时机器人应用奠定了关键基础，解决了深度学习在机器人控制中的黑盒问题，并通过实验验证了该方法的稳定性和有效性。

Abstract: Deep learning, with its exceptional learning capabilities and flexibility,
has been widely applied in various applications. However, its black-box nature
poses a significant challenge in real-time robotic applications, particularly
in robot control, where trustworthiness and robustness are critical in ensuring
safety. In robot motion control, it is essential to analyze and ensure system
stability, necessitating the establishment of methodologies that address this
need. This paper aims to develop a theoretical framework for end-to-end deep
learning control that can be integrated into existing robot control theories.
The proposed control algorithm leverages a modular learning approach to update
the weights of all layers in real time, ensuring system stability based on
Lyapunov-like analysis. Experimental results on industrial robots are presented
to illustrate the performance of the proposed deep learning controller. The
proposed method offers an effective solution to the black-box problem in deep
learning, demonstrating the possibility of deploying real-time deep learning
strategies for robot kinematic control in a stable manner. This achievement
provides a critical foundation for future advancements in deep learning based
real-time robotic applications.

</details>


### [203] [FLOWER: Democratizing Generalist Robot Policies with Efficient Vision-Language-Action Flow Policies](https://arxiv.org/abs/2509.04996)
*Moritz Reuss,Hongyi Zhou,Marcel Rühle,Ömer Erdinç Yağmurlu,Fabian Otto,Rudolf Lioutikov*

Main category: cs.RO

TL;DR: FLOWER是一个参数量为9.5亿的视觉-语言-动作（VLA）模型，通过中间模态融合和动作特定的全局AdaLN条件化技术，在保证性能的同时显著降低了计算成本和资源需求。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的VLA策略需要数十亿参数和海量数据集，计算成本高昂。FLOWER旨在解决这一效率挑战。

Method: FLOWER采用了两种技术：1. 中间模态融合：通过移除高达50%的LLM层来重新分配容量到扩散头。2. 动作特定的全局AdaLN条件化：通过模块化自适应将参数量减少20%。

Result: FLOWER在190个跨越十个模拟和真实世界基准的任务中，展现了与更大VLA模型相媲美的性能，并证明了其在不同机器人实体上的鲁棒性。在CALVIN ABC基准测试上达到了4.53的新SOTA。该模型仅需200小时的H100 GPU预训练。

Conclusion: FLOWER通过创新的效率优化技术，在不牺牲性能的情况下，显著降低了VLA模型的计算成本和资源需求，为实际机器人部署提供了更有效的解决方案。

Abstract: Developing efficient Vision-Language-Action (VLA) policies is crucial for
practical robotics deployment, yet current approaches face prohibitive
computational costs and resource requirements. Existing diffusion-based VLA
policies require multi-billion-parameter models and massive datasets to achieve
strong performance. We tackle this efficiency challenge with two contributions:
intermediate-modality fusion, which reallocates capacity to the diffusion head
by pruning up to $50\%$ of LLM layers, and action-specific Global-AdaLN
conditioning, which cuts parameters by $20\%$ through modular adaptation. We
integrate these advances into a novel 950 M-parameter VLA called FLOWER.
Pretrained in just 200 H100 GPU hours, FLOWER delivers competitive performance
with bigger VLAs across $190$ tasks spanning ten simulation and real-world
benchmarks and demonstrates robustness across diverse robotic embodiments. In
addition, FLOWER achieves a new SoTA of 4.53 on the CALVIN ABC benchmark.
Demos, code and pretrained weights are available at
https://intuitive-robots.github.io/flower_vla/.

</details>


### [204] [Pointing-Guided Target Estimation via Transformer-Based Attention](https://arxiv.org/abs/2509.05031)
*Luca Müller,Hassan Ali,Philipp Allgeuer,Lukáš Gajdošech,Stefan Wermter*

Main category: cs.RO

TL;DR: 该研究提出了一种名为 MM-ITF 的多模态交互转换器模型，用于在机器人与人类交互（HRI）场景中，通过人类的指向性手势预测目标物体。


<details>
  <summary>Details</summary>
Motivation: 在人机交互（HRI）中，机器人需要能够预测人类的意图并做出适当的响应。指向性手势是人类交流的基本形式，对于将注意力引向特定物体或位置至关重要。

Method: 提出了一种名为 MM-ITF 的模块化架构，该架构利用跨模态注意力机制，将二维指向性手势映射到物体位置，并为每个位置分配可能性得分，从而识别出最可能的目标物体。

Result: 结果表明，该方法能够仅使用单目 RGB 数据准确预测目标物体，从而实现直观且易于访问的人机协作。研究还引入了一种补丁混淆矩阵来评估模型性能。

Conclusion: MM-ITF 能够准确地通过指向性手势预测目标物体，从而增强人机交互的直观性和协作性。

Abstract: Deictic gestures, like pointing, are a fundamental form of non-verbal
communication, enabling humans to direct attention to specific objects or
locations. This capability is essential in Human-Robot Interaction (HRI), where
robots should be able to predict human intent and anticipate appropriate
responses. In this work, we propose the Multi-Modality Inter-TransFormer
(MM-ITF), a modular architecture to predict objects in a controlled tabletop
scenario with the NICOL robot, where humans indicate targets through natural
pointing gestures. Leveraging inter-modality attention, MM-ITF maps 2D pointing
gestures to object locations, assigns a likelihood score to each, and
identifies the most likely target. Our results demonstrate that the method can
accurately predict the intended object using monocular RGB data, thus enabling
intuitive and accessible human-robot collaboration. To evaluate the
performance, we introduce a patch confusion matrix, providing insights into the
model's predictions across candidate object locations. Code available at:
https://github.com/lucamuellercode/MMITF.

</details>


### [205] [Shared Autonomy through LLMs and Reinforcement Learning for Applications to Ship Hull Inspections](https://arxiv.org/abs/2509.05042)
*Cristiano Caissutti,Estelle Gerbier,Ehsan Khorrambakht,Paolo Marinelli,Andrea Munafo',Andrea Caiti*

Main category: cs.RO

TL;DR: 本研究提出了一种结合大语言模型、人机 in-the-loop 交互框架和基于行为树的模块化任务管理器，以增强海上机器人集群的共享自主性，旨在降低操作员认知负荷，提高透明度和适应性。


<details>
  <summary>Details</summary>
Motivation: 在复杂、高风险和不确定的海上环境中，需要有效的人机协作，因此研究人员致力于推进共享自主性。

Method: 本研究整合了大语言模型（LLMs）以实现高层任务的直观指定和船体检查任务的支持；实现了多智能体设置中的人机 in-the-loop 交互框架，以支持自适应和意图感知的协调；开发了基于行为树的模块化任务管理器，以提供可解释和灵活的任务控制。

Result: 初步的模拟和真实湖泊环境的结果表明，这种多层架构有潜力降低操作员的认知负荷，提高透明度，并使自适应行为与人类意图更好地对齐。

Conclusion: 该研究为在安全关键的海上机器人应用中建立可信赖、可扩展的、支持人机协作的自主性奠定了模块化基础。

Abstract: Shared autonomy is a promising paradigm in robotic systems, particularly
within the maritime domain, where complex, high-risk, and uncertain
environments necessitate effective human-robot collaboration. This paper
investigates the interaction of three complementary approaches to advance
shared autonomy in heterogeneous marine robotic fleets: (i) the integration of
Large Language Models (LLMs) to facilitate intuitive high-level task
specification and support hull inspection missions, (ii) the implementation of
human-in-the-loop interaction frameworks in multi-agent settings to enable
adaptive and intent-aware coordination, and (iii) the development of a modular
Mission Manager based on Behavior Trees to provide interpretable and flexible
mission control. Preliminary results from simulation and real-world lake-like
environments demonstrate the potential of this multi-layered architecture to
reduce operator cognitive load, enhance transparency, and improve adaptive
behaviour alignment with human intent. Ongoing work focuses on fully
integrating these components, refining coordination mechanisms, and validating
the system in operational port scenarios. This study contributes to
establishing a modular and scalable foundation for trustworthy,
human-collaborative autonomy in safety-critical maritime robotics applications.

</details>


### [206] [Robust Model Predictive Control Design for Autonomous Vehicles with Perception-based Observers](https://arxiv.org/abs/2509.05201)
*Nariman Niknejad,Gokul S. Sankar,Bahare Kiumarsi,Hamidreza Modares*

Main category: cs.RO

TL;DR: 该研究提出了一种新的模型预测控制（MPC）框架，用于处理深度学习感知模块中固有的非高斯噪声，通过基于集合的状态估计和线性规划（LP）来提高安全性和计算效率，并在机器人实验中验证了其鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 深度学习感知模块中的非高斯噪声会影响状态估计的准确性，进而威胁到安全反馈控制的稳定性。因此，有必要开发能够处理这种不确定性的控制框架。

Method: 提出了一种明确考虑非高斯噪声的鲁棒MPC框架。该框架使用基于集合的状态估计和约束区域（constrained zonotopes）来处理有偏和重尾不确定性。为了提高计算效率，MPC被重新表述为线性规划（LP），并使用基于Minkowski-Lyapunov的成本函数和松弛变量。通过Minkowski-Lyapunov不等式和收缩区域不变集来保证闭环稳定性。通过区域的椭球近似来推导最大的稳定终端集和相应的反馈增益。

Result: 该框架在模拟和硬件实验（包括全向移动机器人和ROS2框架中的CNN感知模块）中得到了验证。实验结果表明，该MPC在重尾噪声条件下提供了稳定且准确的控制性能，在状态估计误差边界和整体控制性能方面均显著优于传统的基于高斯噪声的设计。

Conclusion: 所提出的鲁棒MPC框架能够有效地处理深度学习感知中的非高斯噪声，在保证稳定性和准确性的同时提高了控制性能，为在实际应用中部署基于深度学习的感知系统提供了更安全可靠的控制解决方案。

Abstract: This paper presents a robust model predictive control (MPC) framework that
explicitly addresses the non-Gaussian noise inherent in deep learning-based
perception modules used for state estimation. Recognizing that accurate
uncertainty quantification of the perception module is essential for safe
feedback control, our approach departs from the conventional assumption of
zero-mean noise quantification of the perception error. Instead, it employs
set-based state estimation with constrained zonotopes to capture biased,
heavy-tailed uncertainties while maintaining bounded estimation errors. To
improve computational efficiency, the robust MPC is reformulated as a linear
program (LP), using a Minkowski-Lyapunov-based cost function with an added
slack variable to prevent degenerate solutions. Closed-loop stability is
ensured through Minkowski-Lyapunov inequalities and contractive zonotopic
invariant sets. The largest stabilizing terminal set and its corresponding
feedback gain are then derived via an ellipsoidal approximation of the
zonotopes. The proposed framework is validated through both simulations and
hardware experiments on an omnidirectional mobile robot along with a camera and
a convolutional neural network-based perception module implemented within a
ROS2 framework. The results demonstrate that the perception-aware MPC provides
stable and accurate control performance under heavy-tailed noise conditions,
significantly outperforming traditional Gaussian-noise-based designs in terms
of both state estimation error bounding and overall control performance.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [207] [Optomechanical method for characterizing thermal transport across van der Waals interfaces](https://arxiv.org/abs/2509.04786)
*Hanqing Liu,Saurabh Lodha,Herre S. J. van der Zant,Peter G. Steenekenand Gerard J. Verbiest*

Main category: physics.app-ph

TL;DR: 提出了一种新的光力学方法来表征二维异质结构中的界面热传输，并测量了FePS3/WSe2和MoS2/FePS3界面的热导。


<details>
  <summary>Details</summary>
Motivation: 为了开发具有低热阻的原子级二维材料范德尔瓦尔斯（vdW）界面，以最小化热量积累引起的性能降低，需要对vdW材料之间的热界面阻进行表征。然而，这是一个挑战。

Method: 首先单独确定上下材料层作为温度函数的比热和热导率，然后从异质结构的热时间常数中提取热边界电导（TBC）。

Result: 获得了FePS3/WSe2和MoS2/FePS3界面的TBC，分别为（2.41±1.03）和（4.14±1.74）MW m^2 K^-1，这与文献中报道的值相当，并且与包括声学失配的德拜模型一致。

Conclusion: 这项工作实现了纳米级的有效热量管理，并为vdW异质结构中的能量耗散提供了新的见解。

Abstract: For the development of nanoscale electronics and photonics using atomically
thin two-dimensional (2D) materials, it is important to realize van der Waals
(vdW) interfaces with low thermal resistance, to minimize performance reduction
caused by heat accumulation. However, characterizing the thermal interface
resistance between vdW materials is still a challenge. Here, we introduce a
novel optomechanical methodology to characterize the thermal transport across
interfaces in 2D heterostructures. We first determine the specific heat and
thermal conductivity as the function of temperature for the upper and lower
material layers separately and then extract the thermal boundary conductance
(TBC) of the heterostructure from its thermal time constant. We obtain a TBC of
$2.41 \pm 1.03$ and $4.14 \pm 1.74$~\si{MW m^{2} K^{-1}} for FePS$_3$/WSe$_2$
and MoS$_2$/FePS$_3$ interfaces, respectively, which are comparable to values
reported in the literature. Moreover, they agree with a Debye model including
the acoustic impedance mismatch of flexural phonons. This work enables
efficient thermal management down to the nanoscale and offers new insights into
energy dissipation in vdW heterostructures.

</details>


### [208] [Orbital Angular Momentum Generating Thin-Film Conformal Metasurface for Backscattering Control](https://arxiv.org/abs/2509.04953)
*Yury M. Meleshin,Maxim V. Azarov,Artem A. Airapetian,Konstantin S. Lyalin*

Main category: physics.app-ph

TL;DR: 本文设计、仿真并实验验证了一种用于通过轨道角动量（OAM）波生成来控制后向散射的柔性薄膜共形超表面，在X波段（9.5-10.5 GHz）实现了OAM模式l=+1的生成。


<details>
  <summary>Details</summary>
Motivation: 在X波段设计一种柔性薄膜共形超表面，通过OAM波生成来控制后向散射，并进行实验验证。

Method: 采用不对称方形回线超原子在亚波长厚度（10 GHz时为λ/15）的空气等效介电基板上构建超表面。通过解析建模确定了实现自旋-轨道角动量转换所需的相位差要求（arg(ryy) - arg(rxx) = 180 ± 25 度），以生成OAM模式l=+1。使用全波电磁仿真和天线阵理论进行预测。通过在泡沫芯基板上使用背胶箔制作实验原型。

Result: 与均匀相位参考相比，OAM生成超表面的反射功率降低了4 dB。与实心金属相比，反射波降低了7 dB，并且对各种曲率半径的表面有效。测得的抑制带宽达到1 GHz。然而，由于窄零点区域的对准敏感性被确定为一项限制因素。额外的径向相位梯度用于光束散焦，由于主瓣失真导致性能降低了1-2 dB。分析模型与测量结果之间的差异表明了互耦效应对复杂相位分布的重要性。

Conclusion: 本文证实了薄膜共形超表面是实现可控后向散射的可行解决方案。

Abstract: This paper presents the design, simulation, and experimental verification of
a flexible thin-film conformal metasurface for backscattering control via
orbital angular momentum (OAM) wave generation in the X-band (9.5-10.5 GHz).
The metasurface comprises asymmetric square loop meta-atoms fabricated on an
air-equivalent dielectric substrate with subwavelength thickness (lambda/15 at
10 GHz). Analytical modeling define the phase difference requirement (arg(ryy)
- arg(rxx) = 180 +- 25 deg for spin-to-orbital angular momentum conversion,
enabling OAM mode l = +1 generation upon circularly polarized wave reflection.
Full-wave EM simulations and antenna array theory predictions confirmed a
characteristic radiation pattern null along the OAM propagation axis.
Experimental prototypes were fabricated using adhesive-backed foil on foam-core
substrates, demonstrating: 4 dB reflected power reduction for the
OAM-generating metasurface compared to a uniform-phase reference, 7 dB
reflected waves reduction versus solid metal including for various radii of
rounding surfaces. The measured suppression bandwidth reached 1 GHz, though
alignment sensitivity due to the narrow null zone was identified as a
limitation. Additional radial phase gradients for beam defocusing reduced
performance by 1-2 dB due to main lobe distortion. Discrepancies between
analytical models and measurements underscored the importance of mutual
coupling effects in complex phase distributions. This work confirms thin-film
conformal metasurfaces as a viable solution for controllable backscattering.

</details>


### [209] [Fully Integrated Memristive Spiking Neural Network with Analog Neurons for High-Speed Event-Based Data Processing](https://arxiv.org/abs/2509.04960)
*Zhu Wang,Song Wang,Zhiyuan Du,Ruibin Mao,Yu Xiao,Hayden Kwok-Hay So,Peng Lin,Can Li*

Main category: physics.app-ph

TL;DR: 该研究展示了一种全集成忆阻器脉冲神经网络（SNN），它在 CMOS 芯片上集成了 128x24 忆阻器阵列和定制设计的模拟神经元，实现了高速度、低能耗的事件驱动处理，能够高保真地处理加速时空脉冲信号。


<details>
  <summary>Details</summary>
Motivation: 为了满足边缘人工智能处理事件驱动的复杂数据的需求，需要超越传统数字、冯·诺依曼架构的硬件。神经形态计算，特别是利用忆阻器的脉冲神经网络（SNN），是一个有前景的方向，但现有系统存在丢弃时序信息、精度不高或使用大电容神经元设计等问题，限制了可扩展性和处理速度。

Method: 通过模拟神经元的一个比例时间缩放特性，实现了仅使用小尺寸片上电容器，并能通过反向传播（通过代理梯度）直接在时空数据上进行训练，从而克服了先前设计在速度、可扩展性和精度方面的限制。该方法将硬件的操作时间尺度与数据的自然时间尺度解耦。

Result: 实验验证了所提出的硬件系统，使用了 DVS128 手势数据集，将每个样本加速 50,000 倍至 30 微秒。系统达到了 93.06% 的实验准确率，并且测量得到的能效为 101.05 TOPS/W。预测通过利用皮秒级脉冲和先进的制造工艺，未来的能效将有显著提升。

Conclusion: 通过将硬件操作时间尺度与数据自然时间尺度解耦，这项工作为开发能够进行高吞吐量分析的神经形态处理器铺平了可行的道路，这对于需要快速响应的边缘计算应用至关重要，例如对缓冲传感器数据进行高速分析或实现超快速的片上机器视觉。

Abstract: The demand for edge artificial intelligence to process event-based, complex
data calls for hardware beyond conventional digital, von-Neumann architectures.
Neuromorphic computing, using spiking neural networks (SNNs) with emerging
memristors, is a promising solution, but existing systems often discard
temporal information, demonstrate non-competitive accuracy, or rely on neuron
designs with large capacitors that limit the scalability and processing speed.
Here we experimentally demonstrate a fully integrated memristive SNN with a
128x24 memristor array integrated on a CMOS chip and custom-designed analog
neurons, achieving high-speed, energy-efficient event-driven processing of
accelerated spatiotemporal spike signals with high computational fidelity. This
is achieved through a proportional time-scaling property of the analog neurons,
which allows them to use only compact on-chip capacitors and train directly on
the spatiotemporal data without special encoding by backpropagation through
surrogate gradient, thus overcoming the speed, scalability and accuracy
limitations of previous designs. We experimentally validated our hardware using
the DVS128 Gesture dataset, accelerating each sample 50,000-fold to a 30 us
duration. The system achieves an experimental accuracy of 93.06% with a
measured energy efficiency of 101.05 TSOPS/W. We project significant future
efficiency gains by leveraging picosecond-width spikes and advanced fabrication
nodes. By decoupling the hardware's operational timescale from the data's
natural timescale, this work establishes a viable pathway for developing
neuromorphic processors capable of high-throughput analysis, critical for
rapid-response edge computing applications like high-speed analysis of buffered
sensor data or ultra-fast in-sensor machine vision.

</details>


### [210] [Universal Scaling Formalism and Analytical Optimization Criterion for Multiscale Geometric Design of Thermoelectric Metamaterials](https://arxiv.org/abs/2509.05095)
*Xanthippi Zianni*

Main category: physics.app-ph

TL;DR: 通过宽度调制超材料中的收缩和扩张来增强温差，并在不同尺度上实现了普遍缩放行为。


<details>
  <summary>Details</summary>
Motivation: 现有的热电（TE）发电机性能受限于有限的温差，而此研究旨在解决这一问题。

Method: 使用宽度调制的超材料，通过改变横截面比（收缩比/扩张比）来控制透射率（Tr），并利用有限元计算进行分析和验证，以研究温差、电阻、效率和功率输出与Tr的关系。

Result: 提出了一种与尺度无关的通用缩放行为，表明温差、电阻、效率和功率输出都受单一缩放函数g(Tr)的控制，该函数代表了收缩几何体的电导率与其均匀宽度对应物的比值。还得出了TE性能设计图和最优TE性能的分析标准，其中最大功率密度在Tr_opt处实现，Tr_opt由g(Tr_opt)等于Biot数决定。

Conclusion: 透射率（Tr）被确立为一个强大的、多尺度的设计参数，可用于优化TE模块的设计。该研究为多尺度设计和优化收缩几何体提供了理论框架，为下一代基于先进热电超材料的TE模块的设计策略提供了系统性的方法。

Abstract: Thermoelectric (TE) generators can directly convert heat into electricity,
but their performance is often constrained by limited temperature gradients.
Here it is shown that width-modulated metamaterials with constrictions and
expansions (constricted geometries) enhance temperature difference DT by
reduced Transmissivity (Tr), a geometry-based parameter defined by the ratio of
constriction to expansion cross-sections. A universal scaling behavior of
transport and key TE efficiency metrics with Transmissivity is demonstrated,
spanning from the nanoscale to the macroscale. Analytical formalism validated
through finite element calculations for a range of modulation geometries
reveals that DT, electrical and thermal resistances, efficiency, and power
output are governed by a single scaling function, g(Tr), independent of carrier
type, material, or operating conditions. This function represents the
conductance of a constricted geometry relative to a uniform-width counterpart.
The developed framework yields TE Performance Design Maps and an analytical
criterion for optimal TE performance, with the maximum power density achieved
at an optimal Transmissivity Tr_opt, determined by the condition that the
functional g(Tr_opt) equals the Biot number, the dimensionless ratio hL/k of
the convection coefficient h, the structure length L and the material thermal
conductivity k. Transmissivity is established as a robust, multiscale design
parameter - analogous to nature's hierarchical structures for optimized
functionality. This work provides the theoretical framework for multiscale
design and optimization of constricted geometries, thereby enabling systematic
exploration of design strategies for next-generation TE modules based on
advanced thermoelectric metamaterials.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [211] [Transitivity Preserving Projection in Directed Hypergraphs](https://arxiv.org/abs/2509.04543)
*Eric Parsonage,Matthew Roughan,Hung X Nguyen*

Main category: cs.DS

TL;DR: TPP是一种处理有向超图的新方法，比BBP计算效率更高，可视化效果更好。


<details>
  <summary>Details</summary>
Motivation: 现有的超图可视化方法（如BBP）计算成本高，且可能增加复杂性。

Method: 提出了一种名为TPP（Transitivity Preserving Projection）的新方法，该方法使用集合-trie数据结构来最小化和完整地表示关系，保留了所有重要的传递和直接连接。

Result: TPP的计算复杂度从BBP的指数级降低到线性级，在实际应用中，TPP能在几秒钟内完成BBP在24小时内无法完成的投影。

Conclusion: TPP通过提供最小但完整的关系视图，提高了超图的可视化和分析效率，特别适用于网络安全和供应链等领域。

Abstract: Directed hypergraphs are vital for modeling complex polyadic relationships in
domains such as discrete mathematics, computer science, network security, and
systems modeling. However, their inherent complexity often impedes effective
visualization and analysis, particularly for large graphs. This paper
introduces a novel Transitivity Preserving Projection (TPP) to address the
limitations of the computationally intensive Basu and Blanning projection
(BBP), which can paradoxically increase complexity by flattening transitive
relationships. TPP offers a minimal and complete representation of
relationships within a chosen subset of elements, capturing only irreducible
dominant metapaths to ensure the smallest set of edges while preserving all
essential transitive and direct connections. This approach significantly
enhances visualization by reducing edge proliferation and maintains the
integrity of the original hypergraph's structure. We develop an efficient
algorithm leveraging the set-trie data structure, reducing the computational
complexity from an exponential number of metapath searches in BBP to a linear
number of metapath searches with polynomial-time filtering, enabling
scalability for real-world applications. Experimental results demonstrate TPP's
superior performance, completing projections in seconds on graphs where BBP
fails to terminate within 24 hours. By providing a minimal yet complete view of
relationships, TPP supports applications in network security and supply

</details>


### [212] [Additive, Near-Additive, and Multiplicative Approximations for APSP in Weighted Undirected Graphs: Trade-offs and Algorithms](https://arxiv.org/abs/2509.04640)
*Liam Roditty,Ariel Sapir*

Main category: cs.DS

TL;DR: 该论文提出了一种新的+2∑Wi-APASP算法，用于处理稠密加权图，其运行时间优于现有算法。同时，论文还针对近加性APASP和乘性APASP问题，分别提出了更快的算法。最后，论文通过引入加性项，绕过了已知的条件最优性下界。


<details>
  <summary>Details</summary>
Motivation: 现有算法在处理稠密加权图的APASP问题时存在效率问题，同时近加性和乘性APASP以及对于小于2的α-APASP问题也需要改进。

Method: 论文提出了一种新的+2∑Wi-APASP算法，并针对近加性APASP和乘性APASP问题给出了改进的算法框架。此外，还引入了加性项来处理α-APASP问题。

Result: 新的+2∑Wi-APASP算法在稠密加权图上的运行时间达到了~ O(n^(2+1/(3k+2)))。近加性APASP算法的运行时间为~ O((1/ε)^O(1) * n^2.15135313 * log W)。乘性APASP算法框架能够改进现有算法，并提出了一个~ O((1/ε)^O(1) * n^2.15135313 * log W)的(7/3+ε)-APASP算法。

Conclusion: 该论文在APASP算法方面取得了显著进展，特别是在稠密加权图、近加性APASP、乘性APASP以及低于2的α-APASP问题上，都提出了更优的算法或改进框架。

Abstract: We present a $+2\sum_{i=1}^{k+1}{W_i}$-APASP algorithm for dense weighted
graphs with runtime $\tilde O\left(n^{2+\frac{1}{3k+2}}\right)$, where $W_{i}$
is the weight of an $i^\textnormal{th}$ heaviest edge on a shortest path. Dor,
Halperin and Zwick [FOCS'96, SICOMP'00] had two algorithms for the commensurate
unweighted $+2\cdot\left( k+1\right)$-APASP: $\tilde
O\left(n^{2-\frac{1}{k+2}}m^{\frac{1}{k+2}}\right)$ runtime for sparse graphs
and $\tilde O\left(n^{2+\frac{1}{3k+2}}\right)$ runtime for dense graphs. Cohen
and Zwick [SODA'97, JALG'01] adapted the sparse variant to weighted graphs:
$+2\sum_{i=1}^{k+1}{W_i}$-APASP algorithm in the same runtime. We show an
algorithm for dense weighted graphs.
  For \emph{nearly additive} APASP, we present a
$\left(1+\varepsilon,\min{\left\{2W_1,4W_{2}\right\}}\right)$-APASP algorithm
with $\tilde O\left(\left(\frac{1}{\varepsilon}\right)^{O\left(1\right)}\cdot
n^{2.15135313}\cdot\log W\right)$ runtime. This improves the
$\left(1+\varepsilon,2W_1\right)$-APASP of Saha and Ye [SODA'24].
  For multiplicative APASP, we show a framework of $\left(\frac{3\ell +4}{\ell
+ 2}+\varepsilon\right)$-APASP algorithms, reducing the runtime of Akav and
Roditty [ESA'21] for dense graphs and generalizing the
$\left(2+\varepsilon\right)$-APASP algorithm of Dory et al [SODA'24]. Our base
case is a $\left(\frac{7}{3}+\varepsilon\right)$-APASP in $\tilde
O\left(\left(\frac{1}{\varepsilon}\right)^{O\left(1\right)}\cdot
n^{2.15135313}\cdot \log W\right)$ runtime, improving the $\frac{7}{3}$-APASP
algorithm of Baswana and Kavitha [FOCS'06, SICOMP'10] for dense graphs.
  Finally, we "bypass" an $\tilde \Omega \left(n^\omega\right)$ conditional
lower bound by Dor, Halperin, and Zwick for $\alpha$-APASP with $\alpha < 2$,
by allowing an additive term (e.g.
$\paren{\frac{6k+3}{3k+2},\sum_{i=1}^{k+1}{W_{i}}}$-APASP in $\tilde
O\left(n^{2+\frac{1}{3k+2}}\right)$ runtime.).

</details>


### [213] [A 13/6-Approximation for Strip Packing via the Bottom-Left Algorithm](https://arxiv.org/abs/2509.04654)
*Stefan Hougardy,Bart Zondervan*

Main category: cs.DS

TL;DR: 该研究提出了一种新的矩形排序方法，以改进“最底左移算法”（Bottom-Left Algorithm）在“条带填充问题”（Strip Packing problem）中的近似比。


<details>
  <summary>Details</summary>
Motivation: “条带填充问题”是NP难问题，现有的“最底左移算法”在矩形按宽度降序排序时的近似比为3，且该界限已有45年未被改进。本研究旨在寻找一种新的排序方法以提高算法性能。

Method: 提出了一种新的矩形排序方法，并将其应用于“最底左移算法”。

Result: 新的排序方法使得“最底左移算法”在“条带填充问题”上的近似比达到13/6。

Conclusion: 新提出的矩形排序方法成功地改进了“最底左移算法”在“条带填充问题”上的性能，将近似比从3提升至13/6。

Abstract: In the Strip Packing problem, we are given a vertical strip of fixed width
and unbounded height, along with a set of axis-parallel rectangles. The task is
to place all rectangles within the strip, without overlaps, while minimizing
the height of the packing. This problem is known to be NP-hard. The Bottom-Left
Algorithm is a simple and widely used heuristic for Strip Packing. Given a
fixed order of the rectangles, it places them one by one, always choosing the
lowest feasible position in the strip and, in case of ties, the leftmost one.
Baker, Coffman, and Rivest proved in 1980 that the Bottom-Left Algorithm has
approximation ratio 3 if the rectangles are sorted by decreasing width. For the
past 45 years, no alternative ordering has been found that improves this bound.
We introduce a new rectangle ordering and show that with this ordering the
Bottom-Left Algorithm achieves a 13/6 approximation for the Strip Packing
problem.

</details>


### [214] [Parameterized Approximability for Modular Linear Equations](https://arxiv.org/abs/2509.04976)
*Konrad K. Dabrowski,Peter Jonsson,Sebastian Ordyniak,George Osipov,Magnus Wahlström*

Main category: cs.DS

TL;DR: Min-2-Lin(Z_m) 在 m 为非素数幂时是 W[1]-hard，而 Min-2-Lin(Z_{p^n}) 可被因子 2 FPT 近似，对于任何素数 p 和整数 n≥2。这表明 Min-2-Lin(Z_m) 是 FPT 近似因子为 2ω(m) 的，其中 ω(m) 是 m 的不同素数因子数。


<details>
  <summary>Details</summary>
Motivation: 研究参数化近似 Min-r-Lin(Z_m) 问题，特别是当解的大小作为参数时。

Method: 通过逐步求解更严格的松弛问题来近似求解。在 Z_{p^n} 上，将值视为 p 进制，松弛可以看作是固定变量值的尾随零和最低非零数字。通过构造一个图来找到解，并将解与特定集合的割进行匹配。使用基于阴影去除的策略来处理隐藏的障碍，以计算（1）成本不超过最优值两倍且（2）能够同时减少所有变量值的集合的解。

Result: Min-2-Lin(Z_{p^n}) 可被因子 2 FPT 近似。

Conclusion: Min-2-Lin(Z_{p^n}) 可被因子 2 FPT 近似。Min-2-Lin(Z_m) 可被因子 2ω(m) FPT 近似。排除了在任何非平凡环 R 上的 Min-3-Lin(R) 和在某些有限交换环 R 上的 Min-2-Lin(R) 的常数因子 FPT 近似。

Abstract: We consider the Min-$r$-Lin$(Z_m)$ problem: given a system $S$ of length-$r$
linear equations modulo $m$, find $Z \subseteq S$ of minimum cardinality such
that $S-Z$ is satisfiable. The problem is NP-hard and UGC-hard to approximate
in polynomial time within any constant factor even when $r = m = 2$. We focus
on parameterized approximation with solution size as the parameter. Dabrowski
et al. showed that Min-$2$-Lin$(Z_m)$ is in FPT if $m$ is prime (i.e. $Z_m$ is
a field), and it is W[1]-hard if $m$ is not a prime power. We show that
Min-$2$-Lin$(Z_{p^n})$ is FPT-approximable within a factor of $2$ for every
prime $p$ and integer $n \geq 2$. This implies that Min-$2$-Lin$(Z_m)$, $m \in
Z^+$, is FPT-approximable within a factor of $2\omega(m)$ where $\omega(m)$
counts the number of distinct prime divisors of $m$. The idea behind the
algorithm is to solve ever tighter relaxations of the problem, decreasing the
set of possible values for the variables at each step. Working over $Z_{p^n}$
and viewing the values in base-$p$, one can roughly think of a relaxation as
fixing the number of trailing zeros and the least significant nonzero digits of
the values assigned to the variables. To solve the relaxed problem, we
construct a certain graph where solutions can be identified with a particular
collection of cuts. The relaxation may hide obstructions that will only become
visible in the next iteration of the algorithm, which makes it difficult to
find optimal solutions. To deal with this, we use a strategy based on shadow
removal to compute solutions that (1) cost at most twice as much as the optimum
and (2) allow us to reduce the set of values for all variables simultaneously.
We complement the algorithmic result with two lower bounds, ruling out
constant-factor FPT-approximation for Min-$3$-Lin$(R)$ over any nontrivial ring
$R$ and for Min-$2$-Lin$(R)$ over some finite commutative rings $R$.

</details>


### [215] [Graph Reconstruction with a Connected Components Oracle](https://arxiv.org/abs/2509.05002)
*Juha Harviainen,Pekka Parviainen*

Main category: cs.DS

TL;DR: 研究了图重构（GR）问题，重点是分析新提出的连通分量（CC）预言机。


<details>
  <summary>Details</summary>
Motivation: 旨在表征不同预言机的能力，并以算法执行的查询次数来衡量复杂度。

Method: 提出了一个自适应随机算法，能在 $O(\min\{m, \Delta^2, k^2 \} \cdot \log n)$ 次 CC 查询内解决 GR 问题，并证明了不存在能以 $o(\min\{m, \Delta^2, k^2 \})$ 次 CC 查询解决 GR 问题的算法。

Result: 1. 提出了一个自适应随机算法，在 $O(\min\{m, \Delta^2, k^2 \} \cdot \log n)$ 次 CC 查询内解决 GR 问题。 2. 证明了不存在能以 $o(\min\{m, \Delta^2, k^2 \})$ 次 CC 查询解决 GR 问题的算法。

Conclusion: 该研究为图重构问题提供了一个新的预言机模型，并对该模型下的查询复杂度进行了量化分析，给出了最优算法和下界。

Abstract: In the Graph Reconstruction (GR) problem, the goal is to recover a hidden
graph by utilizing some oracle that provides limited access to the structure of
the graph. The interest is in characterizing how strong different oracles are
when the complexity of an algorithm is measured in the number of performed
queries. We study a novel oracle that returns the set of connected components
(CC) on the subgraph induced by the queried subset of vertices. Our main
contributions are as follows:
  1. For a hidden graph with $n$ vertices, $m$ edges, maximum degree $\Delta$,
and treewidth $k$, GR can be solved in $O(\min\{m, \Delta^2, k^2\} \cdot \log
n)$ CC queries by an adaptive randomized algorithm.
  2. For a hidden graph with $n$ vertices, $m$ edges, maximum degree $\Delta$,
and treewidth $k$, no algorithm can solve GR in $o(\min\{m, \Delta^2, k^2\})$
CC queries.

</details>


### [216] [On approximating the $f$-divergence between two Ising models](https://arxiv.org/abs/2509.05016)
*Weiming Feng,Yucheng Fu*

Main category: cs.DS

TL;DR: 本论文研究在给定两个伊辛模型（由其相互作用矩阵和外部场指定）的情况下，近似它们之间 f-散度 D_f(ν||μ) 的问题。


<details>
  <summary>Details</summary>
Motivation: f-散度是衡量两个分布之间差异的基本概念，本文将最近在近似 TV-距离方面的工作推广到近似两个伊辛模型之间的 f-散度。

Method: 对于具有常数整数 α 的 χ^α-散度，我们提出了一个算法，并证明了一个与之匹配的计算复杂性下限。该算法可以扩展到其他 f-散度。

Result: 对于 χ^α-散度（α 为常数整数），我们得到了一个算法和一个计算复杂性下限，算法在参数范围内与下限匹配。算法可以扩展到多种其他 f-散度。

Conclusion: 本文为近似两个伊辛模型之间的 f-散度问题提供了算法和计算复杂性方面的结果，特别是对于 χ^α-散度，并且该算法具有普适性，可扩展到其他多种 f-散度。

Abstract: The $f$-divergence is a fundamental notion that measures the difference
between two distributions. In this paper, we study the problem of approximating
the $f$-divergence between two Ising models, which is a generalization of
recent work on approximating the TV-distance. Given two Ising models $\nu$ and
$\mu$, which are specified by their interaction matrices and external fields,
the problem is to approximate the $f$-divergence $D_f(\nu\,\|\,\mu)$ within an
arbitrary relative error $\mathrm{e}^{\pm \varepsilon}$. For
$\chi^\alpha$-divergence with a constant integer $\alpha$, we establish both
algorithmic and hardness results. The algorithm works in a parameter regime
that matches the hardness result. Our algorithm can be extended to other
$f$-divergences such as $\alpha$-divergence, Kullback-Leibler divergence,
R\'enyi divergence, Jensen-Shannon divergence, and squared Hellinger distance.

</details>


### [217] [Testing Depth First Search Numbering](https://arxiv.org/abs/2509.05132)
*Artur Czumaj,Christian Sohler,Stefan Walzer*

Main category: cs.DS

TL;DR: 我们引入了一个新的有界度图模型，允许查询顶点的标签，并开发了一个用于 DFS 遍历发现时间的属性测试算法，查询复杂度为 O(n^1/3/ε)。


<details>
  <summary>Details</summary>
Motivation: 研究在有界度图模型中，哪些图属性的编号（例如 DFS 遍历产生的编号）可以在子线性时间内进行测试。

Method: 提出了一种新的有界度图模型，允许查询顶点的标签（num(v)），并基于此模型开发了一个属性测试算法。

Result: 该算法在发现 DFS 遍历的时间方面具有 O(n^1/3/ε) 的查询复杂度，并且对于常数 ε>0，存在一个匹配的下界。

Conclusion: 在新的有界度图模型下，我们能够以子线性的查询复杂度测试 DFS 遍历的发现时间。

Abstract: Property Testing is a formal framework to study the computational power and
complexity of sampling from combinatorial objects. A central goal in standard
graph property testing is to understand which graph properties are testable
with sublinear query complexity. Here, a graph property P is testable with a
sublinear query complexity if there is an algorithm that makes a sublinear
number of queries to the input graph and accepts with probability at least 2/3,
if the graph has property P, and rejects with probability at least 2/3 if it is
$\varepsilon$-far from every graph that has property P.
  In this paper, we introduce a new variant of the bounded degree graph model.
In this variant, in addition to the standard representation of a bounded degree
graph, we assume that every vertex $v$ has a unique label num$(v)$ from $\{1,
\dots, |V|\}$, and in addition to the standard queries in the bounded degree
graph model, we also allow a property testing algorithm to query for the label
of a vertex (but not for a vertex with a given label).
  Our new model is motivated by certain graph processes such as a DFS
traversal, which assign consecutive numbers (labels) to the vertices of the
graph. We want to study which of these numberings can be tested in sublinear
time. As a first step in understanding such a model, we develop a
\emph{property testing algorithm for discovery times of a DFS traversal} with
query complexity $O(n^{1/3}/\varepsilon)$ and for constant $\varepsilon>0$ we
give a matching lower bound.

</details>


### [218] [Efficient Contractions of Dynamic Graphs -- with Applications](https://arxiv.org/abs/2509.05157)
*Monika Henzinger,Evangelos Kosinas,Robin Münk,Harald Räcke*

Main category: cs.DS

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: A non-trivial minimum cut (NMC) sparsifier is a multigraph $\hat{G}$ that
preserves all non-trivial minimum cuts of a given undirected graph $G$. We
introduce a flexible data structure for fully dynamic graphs that can
efficiently provide an NMC sparsifier upon request at any point during the
sequence of updates. We employ simple dynamic forest data structures to achieve
a fast from-scratch construction of the sparsifier at query time. Based on the
strength of the adversary and desired type of time bounds, the data structure
comes with different guarantees. Specifically, let $G$ be a fully dynamic
simple graph with $n$ vertices and minimum degree $\delta$. Then our data
structure supports an insertion/deletion of an edge to/from $G$ in $n^{o(1)}$
worst-case time. Furthermore, upon request, it can return w.h.p. an NMC
sparsifier of $G$ that has $O(n/\delta)$ vertices and $O(n)$ edges, in
$\hat{O}(n)$ time. The probabilistic guarantees hold against an adaptive
adversary. Alternatively, the update and query times can be improved to
$\tilde{O}(1)$ and $\tilde{O}(n)$ respectively, if amortized-time guarantees
are sufficient, or if the adversary is oblivious.
  We discuss two applications of our data structure. First, it can be used to
efficiently report a cactus representation of all minimum cuts of a fully
dynamic simple graph. Using the NMC sparsifier we can w.h.p. build this cactus
in worst-case time $\hat{O}(n)$ against an adaptive adversary. Second, our data
structure allows us to efficiently compute the maximal $k$-edge-connected
subgraphs of undirected simple graphs, by repeatedly applying a minimum cut
algorithm on the NMC sparsifier. Specifically, we can compute w.h.p. the
maximal $k$-edge-connected subgraphs of a simple graph with $n$ vertices and
$m$ edges in $\tilde{O}(m+n^2/k)$ time which is an improvement for $k =
\Omega(n^{1/8})$ and works for fully dynamic graphs.

</details>


### [219] [List Decoding Expander-Based Codes via Fast Approximation of Expanding CSPs: I](https://arxiv.org/abs/2509.05203)
*Fernando Granha Jeronimo,Aman Singh*

Main category: cs.DS

TL;DR: 该论文提出了用于基于扩展码的近线性时间列表解码算法，能够解码具有特定距离参数的LDPC码和AEL码，解码时间和字母表大小与参数相关。


<details>
  <summary>Details</summary>
Motivation: 在编码理论中，开发高效的解码算法对于实际应用至关重要，特别是对于具有良好距离特性的编码方案。

Method: 通过将解码任务表述为基于扩展图的一致性CSP问题，并利用用于q-ary扩展CSPs的快速近似算法，该算法基于弱正则性分解。

Result: 1. 提出了具有设计距离δ的LDPC码的近线性时间列表解码算法，解码列表大小与参数ε相关。 2. 提出了具有速率R和距离1-R-ε的AEL码的近线性时间列表解码算法，解码列表大小与参数ε相关，字母表大小与1/ε的多项式相关。 3. 提出了具有速率R和距离1-R-ε的AEL码的近线性时间列表解码算法，解码列表大小与1/ε成比例，字母表大小与exp(exp(poly(1/ε)))相关。

Conclusion: 该研究为基于扩展码的列表解码提供了新的近线性时间算法，显著提高了解码效率，并为LDPC码和AEL码的实际应用开辟了新的可能性。

Abstract: We present near-linear time list decoding algorithms (in the block-length
$n$) for expander-based code constructions. More precisely, we show that
  (i) For every $\delta \in (0,1)$ and $\epsilon > 0$, there is an explicit
family of good Tanner LDPC codes of (design) distance $\delta$ that is $(\delta
- \epsilon, O_\varepsilon(1))$ list decodable in time
$\widetilde{\mathcal{O}}_{\varepsilon}(n)$ with alphabet size $O_\delta(1)$,
  (ii) For every $R \in (0,1)$ and $\epsilon > 0$, there is an explicit family
of AEL codes of rate $R$, distance $1-R -\varepsilon$ that is $(1-R-\epsilon,
O_\varepsilon(1))$ list decodable in time
$\widetilde{\mathcal{O}}_{\varepsilon}(n)$ with alphabet size
$\text{exp}(\text{poly}(1/\epsilon))$, and
  (iii) For every $R \in (0,1)$ and $\epsilon > 0$, there is an explicit family
of AEL codes of rate $R$, distance $1-R-\varepsilon$ that is $(1-R-\epsilon,
O(1/\epsilon))$ list decodable in time
$\widetilde{\mathcal{O}}_{\varepsilon}(n)$ with alphabet size
$\text{exp}(\text{exp}(\text{poly}(1/\epsilon)))$ using recent near-optimal
list size bounds from [JMST25].
  Our results are obtained by phrasing the decoding task as an agreement CSP
[RWZ20,DHKNT19] on expander graphs and using the fast approximation algorithm
for $q$-ary expanding CSPs from [Jer23], which is based on weak regularity
decomposition [JST21,FK96]. Similarly to list decoding $q$-ary Ta-Shma's codes
in [Jer23], we show that it suffices to enumerate over assignments that are
constant in each part (of the constantly many) of the decomposition in order to
recover all codewords in the list.

</details>


### [220] [Labelling Data with Unknown References](https://arxiv.org/abs/2506.03083)
*Adrian de Wynter*

Main category: cs.DS

TL;DR: 无需标注数据即可评估标注器可信度的新算法。


<details>
  <summary>Details</summary>
Motivation: 现有评估标注器可信度的方法（测试或假设其已知标注方式）在缺乏已标注参考数据时失效。本研究旨在解决此问题。

Method: 提出一种名为“无数据算法”的新算法，通过不断向标注器提出挑战来评估其可信度。

Result: 该算法被证明在绝大多数情况下是正确的，能够识别出真正了解标注方式的标注器，并标记出无法证明其能力的不可信标注器。论文提供了正式的正确性证明、实证测试以及在低资源语言上应用LLM作为裁判的案例。

Conclusion: “无数据算法”可以在没有参考数据的情况下，有效地评估标注器的可信度。

Abstract: An evaluator is trustworthy when there exists some agreed-upon way to measure
its performance as a labeller. The two ways to establish trustworthiness are
either by testing it, or by assuming the evaluator `knows' somehow the way to
label the corpus. However, if labelled references (e.g., a development set) are
unavailable, neither of these approaches work: the former requires the data,
and the latter is an assumption, not evidence. To address this, we introduce an
algorithm (the `No-Data Algorithm') by which to establish trust in an evaluator
without any existing references. Our algorithm works by successively posing
challenges to said evaluator. We show that this is sufficient to establish
trustworthiness w.h.p., in such a way that when the evaluator actually knows
the way to label the corpus, the No-Data Algorithm accepts its output; and,
conversely, flags untrustworthy evaluators when these are unable to prove it.
We present formal proofs of correctness, empirical tests, and applications to
LLMs-as-judges on low-resource languages.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [221] [Q-SafeML: Safety Assessment of Quantum Machine Learning via Quantum Distance Metrics](https://arxiv.org/abs/2509.04536)
*Oliver Dunn,Koorosh Aslansefat,Yiannis Papadopoulos*

Main category: cs.LG

TL;DR: Q-SafeML是一种用于量子机器学习（QML）的安全监控方法，通过使用量子中心距离度量来评估模型准确性并提供置信度，以应对QML的独特挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的安全监控方法不适用于量子机器学习（QML），需要专门针对QML开发新的安全机制。

Method: Q-SafeML借鉴了SafeML，但采用量子中心距离度量来评估模型准确性，并检测运行数据和训练数据之间的距离，以处理QML中的概念漂移。

Result: 在量子卷积神经网络（QCNN）和变分量子算法（VQC）模型上进行的实验表明，Q-SafeML能够实现有效的人工监督，提高系统的透明度和安全性。

Conclusion: Q-SafeML通过适应量子计算的概率特性和表示约束，为QML提供了重要的安全监控能力，能够检测概念漂移并支持人工监督。

Abstract: The rise of machine learning in safety-critical systems has paralleled
advancements in quantum computing, leading to the emerging field of Quantum
Machine Learning (QML). While safety monitoring has progressed in classical ML,
existing methods are not directly applicable to QML due to fundamental
differences in quantum computation. Given the novelty of QML, dedicated safety
mechanisms remain underdeveloped. This paper introduces Q-SafeML, a safety
monitoring approach for QML. The method builds on SafeML, a recent method that
utilizes statistical distance measures to assess model accuracy and provide
confidence in the reasoning of an algorithm. An adapted version of Q-SafeML
incorporates quantum-centric distance measures, aligning with the probabilistic
nature of QML outputs. This shift to a model-dependent, post-classification
evaluation represents a key departure from classical SafeML, which is
dataset-driven and classifier-agnostic. The distinction is motivated by the
unique representational constraints of quantum systems, requiring distance
metrics defined over quantum state spaces. Q-SafeML detects distances between
operational and training data addressing the concept drifts in the context of
QML. Experiments on QCNN and VQC Models show that this enables informed human
oversight, enhancing system transparency and safety.

</details>


### [222] [Finance-Grounded Optimization For Algorithmic Trading](https://arxiv.org/abs/2509.04541)
*Kasymkhan Khubiev,Mikhail Semenov,Irina Podlipnova*

Main category: cs.LG

TL;DR: 该研究提出了金融领域深度学习的新方法，通过引入基于夏普比率、盈亏和最大回撤等量化金融指标的损失函数，并结合了交易周转率正则化方法，提高了模型在金融领域的预测能力和表现。


<details>
  <summary>Details</summary>
Motivation: 金融领域对可解释的人工智能（AI）提出了挑战，传统深度学习方法在金融领域的表现并非完美，尤其是在模型评估方面。需要为金融领域定制化的模型和评估指标。

Method: 提出基于夏普比率、盈亏和最大回撤等量化金融指标的损失函数；提出交易周转率正则化方法，限制交易周转率在预定范围内。

Result: 所提出的损失函数和交易周转率正则化方法在回报预测任务上优于传统的均方误差损失函数，使用算法交易指标进行评估。

Conclusion: 基于金融指标的损失函数和交易周转率正则化方法能够提升交易策略和投资组合优化的预测性能。

Abstract: Deep Learning is evolving fast and integrates into various domains. Finance
is a challenging field for deep learning, especially in the case of
interpretable artificial intelligence (AI). Although classical approaches
perform very well with natural language processing, computer vision, and
forecasting, they are not perfect for the financial world, in which specialists
use different metrics to evaluate model performance.
  We first introduce financially grounded loss functions derived from key
quantitative finance metrics, including the Sharpe ratio, Profit-and-Loss
(PnL), and Maximum Draw down. Additionally, we propose turnover regularization,
a method that inherently constrains the turnover of generated positions within
predefined limits.
  Our findings demonstrate that the proposed loss functions, in conjunction
with turnover regularization, outperform the traditional mean squared error
loss for return prediction tasks when evaluated using algorithmic trading
metrics. The study shows that financially grounded metrics enhance predictive
performance in trading strategies and portfolio optimization.

</details>


### [223] [Instance-Wise Adaptive Sampling for Dataset Construction in Approximating Inverse Problem Solutions](https://arxiv.org/abs/2509.04583)
*Jiequn Han,Kui Ren,Nathan Soedjak*

Main category: cs.LG

TL;DR: We propose an instance-wise adaptive sampling framework that dynamically allocates training data based on specific test instances, improving sample efficiency for inverse problem solutions, especially with complex priors or high accuracy demands.


<details>
  <summary>Details</summary>
Motivation: Typical learning-based approaches for inverse problems require large datasets drawn from a prior distribution, leading to high costs, especially for high-dimensional priors or when high accuracy is needed. This paper addresses the need for more sample-efficient training methods.

Method: The proposed framework uses instance-wise adaptive sampling. It iteratively refines the training dataset based on the latest prediction, tailoring the dataset to the geometry of the inverse map around each test instance.

Result: The framework was demonstrated on the inverse scattering problem with two types of structured priors. The adaptive method showed significant gains in sample efficiency, with its advantage increasing for more complex priors or higher accuracy requirements.

Conclusion: The proposed instance-wise adaptive sampling strategy is broadly applicable to various inverse problems, offering a scalable and practical alternative to conventional fixed-dataset training by improving sample efficiency and reducing data collection costs.

Abstract: We propose an instance-wise adaptive sampling framework for constructing
compact and informative training datasets for supervised learning of inverse
problem solutions. Typical learning-based approaches aim to learn a
general-purpose inverse map from datasets drawn from a prior distribution, with
the training process independent of the specific test instance. When the prior
has a high intrinsic dimension or when high accuracy of the learned solution is
required, a large number of training samples may be needed, resulting in
substantial data collection costs. In contrast, our method dynamically
allocates sampling effort based on the specific test instance, enabling
significant gains in sample efficiency. By iteratively refining the training
dataset conditioned on the latest prediction, the proposed strategy tailors the
dataset to the geometry of the inverse map around each test instance. We
demonstrate the effectiveness of our approach in the inverse scattering problem
under two types of structured priors. Our results show that the advantage of
the adaptive method becomes more pronounced in settings with more complex
priors or higher accuracy requirements. While our experiments focus on a
particular inverse problem, the adaptive sampling strategy is broadly
applicable and readily extends to other inverse problems, offering a scalable
and practical alternative to conventional fixed-dataset training regimes.

</details>


### [224] [i-Mask: An Intelligent Mask for Breath-Driven Activity Recognition](https://arxiv.org/abs/2509.04544)
*Ashutosh Kumar Sinha,Ayush Patel,Mitul Dudhat,Pritam Anand,Rahul Mishra*

Main category: cs.LG

TL;DR: 该研究提出了一种名为i-Mask的新型人体活动识别（HAR）方法，通过集成传感器的定制口罩捕捉呼出气体模式来识别活动，准确率超过95%。


<details>
  <summary>Details</summary>
Motivation: 吸入和呼出模式包含重要的生理信号，可用于预测人类行为、健康趋势和生命体征。人体活动识别（HAR）与这些生命体征密切相关，可提供有关身心健康的深入见解，并实现实时健康监测。

Method: i-Mask方法利用集成传感器的定制口罩捕捉呼出气体模式。收集到的志愿者数据经过噪声滤波、时间序列分解和标记，以训练预测模型。

Result: 实验结果验证了该方法的有效性，准确率超过95%。

Conclusion: i-Mask方法在医疗保健和健身应用方面具有巨大潜力。

Abstract: The patterns of inhalation and exhalation contain important physiological
signals that can be used to anticipate human behavior, health trends, and vital
parameters. Human activity recognition (HAR) is fundamentally connected to
these vital signs, providing deeper insights into well-being and enabling
real-time health monitoring. This work presents i-Mask, a novel HAR approach
that leverages exhaled breath patterns captured using a custom-developed mask
equipped with integrated sensors. Data collected from volunteers wearing the
mask undergoes noise filtering, time-series decomposition, and labeling to
train predictive models. Our experimental results validate the effectiveness of
the approach, achieving over 95\% accuracy and highlighting its potential in
healthcare and fitness applications.

</details>


### [225] [Interpreting Transformer Architectures as Implicit Multinomial Regression](https://arxiv.org/abs/2509.04653)
*Jonas A. Actor,Anthony Gruber,Eric C. Cyr*

Main category: cs.LG

TL;DR: 该论文将注意力机制与多项式回归联系起来，提出可以从多项式回归的角度来理解 Transformer 模型中注意力机制的运作方式。


<details>
  <summary>Details</summary>
Motivation: Transformer 模型中的注意力机制虽然至关重要，但其数学原理以及与特征多义性、叠加和模型性能等概念的关系仍不清楚。本研究旨在阐明这一点。

Method: 论文将注意力机制与多项式回归联系起来，并证明在固定的多项式回归设定下，通过优化潜在特征可以得到与注意力机制诱导的动力学一致的最优解。

Result: 研究表明，Transformer 中表征的演变可以被解释为恢复分类最优特征的轨迹，这为理解注意力机制提供了新的视角。

Conclusion: 本研究成功建立了注意力机制与多项式回归之间的新联系，为理解 Transformer 模型内部工作机制提供了理论基础。

Abstract: Mechanistic interpretability aims to understand how internal components of
modern machine learning models, such as weights, activations, and layers, give
rise to the model's overall behavior. One particularly opaque mechanism is
attention: despite its central role in transformer models, its mathematical
underpinnings and relationship to concepts like feature polysemanticity,
superposition, and model performance remain poorly understood. This paper
establishes a novel connection between attention mechanisms and multinomial
regression. Specifically, we show that in a fixed multinomial regression
setting, optimizing over latent features yields optimal solutions that align
with the dynamics induced by attention blocks. In other words, the evolution of
representations through a transformer can be interpreted as a trajectory that
recovers the optimal features for classification.

</details>


### [226] [Measuring the Measures: Discriminative Capacity of Representational Similarity Metrics Across Model Families](https://arxiv.org/abs/2509.04622)
*Jialin Wu,Shreya Saha,Yiqing Bo,Meenakshi Khosla*

Main category: cs.LG

TL;DR: 不同表征相似性度量在区分不同模型家族（CNN、ViT、Swin Transformer、ConvNeXt）和训练范式（监督学习 vs. 自监督学习）方面存在差异，其中具有更严格对齐约束的度量，特别是软匹配，表现出更强的区分能力。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏对表征相似性度量在区分不同模型家族方面的系统性比较。

Method: 提出一个量化框架，使用 d'、轮廓系数和 ROC-AUC 三种可分离性度量来评估不同表征相似性度量（RSA、线性预测性、Procrustes、软匹配）在区分不同模型架构（CNN、ViT、Swin Transformer、ConvNeXt）和训练范式（监督学习 vs. 自监督学习）方面的能力。

Result: 可分离性随度量约束的增强而系统性地增加。软匹配（一种映射方法）具有最高的可分离性，其次是 Procrustes 对齐和线性预测性。非拟合方法（如 RSA）也显示出跨模型家族的强可分离性。

Conclusion: 这是首次通过可分离性视角对相似性度量进行系统比较，阐明了它们的相对敏感性，并为大规模模型和大脑比较提供了度量选择的指导。

Abstract: Representational similarity metrics are fundamental tools in neuroscience and
AI, yet we lack systematic comparisons of their discriminative power across
model families. We introduce a quantitative framework to evaluate
representational similarity measures based on their ability to separate model
families-across architectures (CNNs, Vision Transformers, Swin Transformers,
ConvNeXt) and training regimes (supervised vs. self-supervised). Using three
complementary separability measures-dprime from signal detection theory,
silhouette coefficients and ROC-AUC, we systematically assess the
discriminative capacity of commonly used metrics including RSA, linear
predictivity, Procrustes, and soft matching. We show that separability
systematically increases as metrics impose more stringent alignment
constraints. Among mapping-based approaches, soft-matching achieves the highest
separability, followed by Procrustes alignment and linear predictivity.
Non-fitting methods such as RSA also yield strong separability across families.
These results provide the first systematic comparison of similarity metrics
through a separability lens, clarifying their relative sensitivity and guiding
metric choice for large-scale model and brain comparisons.

</details>


### [227] [Bootstrapping Task Spaces for Self-Improvement](https://arxiv.org/abs/2509.04575)
*Minqi Jiang,Andrei Lupu,Yoram Bachrach*

Main category: cs.LG

TL;DR: ExIt是一种新的强化学习方法，可以训练语言模型进行推理时多步自我改进，仅在信息量最大的单步迭代上进行训练。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习方法在处理需要多次迭代才能完成的任务时，通常会假设一个固定的最大迭代次数，这可能成本高昂且不合理。因此，需要一种能够可靠地在推理时进行自我改进的训练方法。

Method: ExIt通过选择性地采样一个回合中最具信息量的中间、部分历史，来扩展任务空间，并将这些起始点视为新的自我迭代任务实例，从而训练一个自我改进策略。此外，ExIt还可以与明确的探索机制相结合，以维持更大的任务多样性。

Result: 在竞赛数学、多轮工具使用和机器学习工程等多个领域，ExIt策略（从单个或多个任务实例开始）能够生成在模型推理时对未见过的任务实例进行自我改进的策略，并且能够在超出训练期间遇到的平均迭代深度的步数预算内迭代以获得更高的性能。

Conclusion: ExIt是一种有效的强化学习方法，能够使语言模型在推理时进行多步自我改进，并在各种任务领域中都表现出优越的性能。

Abstract: Progress in many task domains emerges from repeated revisions to previous
solution attempts. Training agents that can reliably self-improve over such
sequences at inference-time is a natural target for reinforcement learning
(RL), yet the naive approach assumes a fixed maximum iteration depth, which can
be both costly and arbitrary. We present Exploratory Iteration (ExIt), a family
of autocurriculum RL methods that directly exploits the recurrent structure of
self-improvement tasks to train LLMs to perform multi-step self-improvement at
inference-time while only training on the most informative single-step
iterations. ExIt grows a task space by selectively sampling the most
informative intermediate, partial histories encountered during an episode for
continued iteration, treating these starting points as new self-iteration task
instances to train a self-improvement policy. ExIt can further pair with
explicit exploration mechanisms to sustain greater task diversity. Across
several domains, encompassing competition math, multi-turn tool-use, and
machine learning engineering, we demonstrate that ExIt strategies, starting
from either a single or many task instances, can produce policies exhibiting
strong inference-time self-improvement on held-out task instances, and the
ability to iterate towards higher performance over a step budget extending
beyond the average iteration depth encountered during training.

</details>


### [228] [An Arbitration Control for an Ensemble of Diversified DQN variants in Continual Reinforcement Learning](https://arxiv.org/abs/2509.04815)
*Wonseo Jang,Dongjae Kim*

Main category: cs.LG

TL;DR: 深度强化学习(RL)模型在静态环境中学习最优策略时效率很高，但在持续强化学习(CRL)场景中容易遗忘先前学到的知识，导致性能下降。本文提出了一种基于人类决策机制的仲裁控制机制，通过集成具有不同价值函数的RL代理（DQN变体）以及一个根据近期试验误差确定代理可靠性并进行优先排序的仲裁控制，来解决这个问题。我们提出了ACED-DQN（仲裁控制的多样化DQN变体），并在静态和持续环境中均取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 深度强化学习(RL)模型在持续强化学习(CRL)场景中存在灾难性遗忘问题，导致性能下降。本文旨在解决这个问题，提高RL模型在CRL场景中的表现。

Method: 提出了一种仲裁控制机制，该机制基于对人类决策过程的观察，并利用了两个关键思想：1) 包含显式训练以获得不同价值函数的RL代理（DQN变体）的集成；2) 一种优先考虑近期试验中可靠性（即误差较小）更高的代理的仲裁控制。我们提出了ACED-DQN框架。

Result: ACED-DQN在静态和持续环境中均取得了显著的性能提升。经验证据表明，在训练过程中，仲裁控制对于多样化的DQN变体是有效的。

Conclusion: 本文提出了一种受人脑启发的框架ACED-DQN，使RL代理能够持续学习，解决了RL模型在CRL场景中的灾难性遗忘问题，并在实验中证明了其有效性。

Abstract: Deep reinforcement learning (RL) models, despite their efficiency in learning
an optimal policy in static environments, easily loses previously learned
knowledge (i.e., catastrophic forgetting). It leads RL models to poor
performance in continual reinforcement learning (CRL) scenarios. To address
this, we present an arbitration control mechanism over an ensemble of RL
agents. It is motivated by and closely aligned with how humans make decisions
in a CRL context using an arbitration control of multiple RL agents in parallel
as observed in the prefrontal cortex. We integrated two key ideas into our
model: (1) an ensemble of RLs (i.e., DQN variants) explicitly trained to have
diverse value functions and (2) an arbitration control that prioritizes agents
with higher reliability (i.e., less error) in recent trials. We propose a
framework for CRL, an Arbitration Control for an Ensemble of Diversified DQN
variants (ACED-DQN). We demonstrate significant performance improvements in
both static and continual environments, supported by empirical evidence showing
the effectiveness of arbitration control over diversified DQNs during training.
In this work, we introduced a framework that enables RL agents to continuously
learn, with inspiration from the human brain.

</details>


### [229] [Flexible inference of learning rules from de novo learning data using neural networks](https://arxiv.org/abs/2509.04661)
*Yuhan Helena Liu,Victor Geadah,Jonathan Pillow*

Main category: cs.LG

TL;DR: 该研究提出了一种非参数深度神经网络（DNN）和循环神经网络（RNN）框架，用于直接从动物从头学习任务的决策数据中推断学习规则。


<details>
  <summary>Details</summary>
Motivation: 现有学习规则推断方法在处理动物从头学习新行为（需要处理次优性、历史依赖性和外部刺激整合）方面存在局限性。

Method: 使用DNN作为参数化每轮策略权重更新，并使用RNN捕捉非马尔可夫动态。将该框架应用于小鼠学习感觉决策任务的行为数据。

Result: 所提出的模型提高了对未见数据的预测能力，并揭示了在正确和错误试验后更新的不对称性以及与非马尔可夫学习一致的历史依赖性。

Conclusion: 该研究提出了一个灵活的框架，用于从头学习任务的行为数据中推断生物学习规则，为实验训练方案和行为数字孪生提供见解。

Abstract: Understanding how animals learn is a central challenge in neuroscience, with
growing relevance to the development of animal- or human-aligned artificial
intelligence. However, most existing approaches assume specific parametric
forms for the learning rule (e.g., Q-learning, policy gradient) or are limited
to simplified settings like bandit tasks, which do not involve learning a new
input-output mapping from scratch. In contrast, animals must often learn new
behaviors de novo, which poses a rich challenge for learning-rule inference. We
target this problem by inferring learning rules directly from animal
decision-making data during de novo task learning, a setting that requires
models flexible enough to capture suboptimality, history dependence, and rich
external stimulus integration without strong structural priors. We first
propose a nonparametric framework that parameterizes the per-trial update of
policy weights with a deep neural network (DNN), and validate it by recovering
ground-truth rules in simulation. We then extend to a recurrent variant (RNN)
that captures non-Markovian dynamics by allowing updates to depend on trial
history. Applied to a large behavioral dataset of mice learning a sensory
decision-making task over multiple weeks, our models improved predictions on
held-out data. The inferred rules revealed asymmetric updates after correct
versus error trials and history dependence, consistent with non-Markovian
learning. Overall, these results introduce a flexible framework for inferring
biological learning rules from behavioral data in de novo learning tasks,
providing insights to inform experimental training protocols and the
development of behavioral digital twins.

</details>


### [230] [An Efficient Subspace Algorithm for Federated Learning on Heterogeneous Data](https://arxiv.org/abs/2509.05213)
*Jiaojiao Zhang,Yuqi Xu,Kun Yuan*

Main category: cs.LG

TL;DR: FedSub是一种用于处理异构数据联邦学习的子空间算法，通过子空间投影和低维对偶变量来降低通信、计算和内存成本，并减少客户端漂移。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决联邦学习在大规模深度神经网络应用中面临的客户端漂移（由数据异构性引起）以及高昂的通信、计算和内存成本等关键挑战。

Method: FedSub算法利用子空间投影技术，将每个客户端的本地更新限制在低维子空间内，从而降低成本。此外，该算法还引入了低维对偶变量来缓解客户端漂移问题。

Result: 实验结果证明了FedSub算法的效率。

Conclusion: FedSub算法通过子空间投影和低维对偶变量有效解决了联邦学习中的客户端漂移和资源消耗问题，并提供了收敛性分析。

Abstract: This work addresses the key challenges of applying federated learning to
large-scale deep neural networks, particularly the issue of client drift due to
data heterogeneity across clients and the high costs of communication,
computation, and memory. We propose FedSub, an efficient subspace algorithm for
federated learning on heterogeneous data. Specifically, FedSub utilizes
subspace projection to guarantee local updates of each client within
low-dimensional subspaces, thereby reducing communication, computation, and
memory costs. Additionally, it incorporates low-dimensional dual variables to
mitigate client drift. We provide convergence analysis that reveals the impact
of key factors such as step size and subspace projection matrices on
convergence. Experimental results demonstrate its efficiency.

</details>


### [231] [Toward Faithfulness-guided Ensemble Interpretation of Neural Network](https://arxiv.org/abs/2509.04588)
*Siyu Zhang,Kenneth Mcmillan*

Main category: cs.LG

TL;DR: FEI是一个创新的框架，通过平滑近似和多样的变体来提高神经网络解释的忠实度和可视化效果，并在实验中超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 需要可解释和忠实的解释来理解和评估模型行为。

Method: 提出FEI框架，通过平滑近似提高量化忠实度得分，并通过多样的变体扩展隐藏层编码的可解释性，同时提出新的定性指标评估隐藏层忠实度。

Result: FEI在量化忠实度得分和定性可视化方面均超越现有方法，展示了显著的进步。

Conclusion: FEI是一个全面的框架，用于提高神经网络解释的忠实度，并在广度和精度上进行强调。

Abstract: Interpretable and faithful explanations for specific neural inferences are
crucial for understanding and evaluating model behavior. Our work introduces
\textbf{F}aithfulness-guided \textbf{E}nsemble \textbf{I}nterpretation
(\textbf{FEI}), an innovative framework that enhances the breadth and
effectiveness of faithfulness, advancing interpretability by providing superior
visualization. Through an analysis of existing evaluation benchmarks,
\textbf{FEI} employs a smooth approximation to elevate quantitative
faithfulness scores. Diverse variations of \textbf{FEI} target enhanced
faithfulness in hidden layer encodings, expanding interpretability.
Additionally, we propose a novel qualitative metric that assesses hidden layer
faithfulness. In extensive experiments, \textbf{FEI} surpasses existing
methods, demonstrating substantial advances in qualitative visualization and
quantitative faithfulness scores. Our research establishes a comprehensive
framework for elevating faithfulness in neural network explanations,
emphasizing both breadth and precision

</details>


### [232] [Quantum-Enhanced Multi-Task Learning with Learnable Weighting for Pharmacokinetic and Toxicity Prediction](https://arxiv.org/abs/2509.04601)
*Han Zhang,Fengji Ma,Jiamin Su,Xinyue Yang,Lei Wang,Wen-Cai Ye,Li Liu*

Main category: cs.LG

TL;DR: 我们提出了一个名为QW-MTL的新框架，它结合了量子化学描述符和多任务学习，用于ADMET预测，并在13个TDC基准测试中的12个上显著优于单任务方法。


<details>
  <summary>Details</summary>
Motivation: 现有ADMET预测方法主要依赖单任务学习，未能充分利用任务间的互补性，并且在训练和推理时需要更多计算资源。

Method: 提出了一种名为QW-MTL的新型量子增强和任务加权多任务学习框架。该框架基于Chemprop-RDKit骨干，使用量子化学描述符丰富分子表示，并引入了一种新的指数任务加权方案来实现跨任务的动态损失平衡。

Result: QW-MTL在13个TDC分类基准测试中的12个上显著优于单任务基线，同时保持了较低的模型复杂度和快速的推理能力。

Conclusion: QW-MTL框架通过结合量子信息特征和自适应任务加权，有效地实现了多任务分子学习，并提高了ADMET预测的性能和效率。

Abstract: Prediction for ADMET (Absorption, Distribution, Metabolism, Excretion, and
Toxicity) plays a crucial role in drug discovery and development, accelerating
the screening and optimization of new drugs. Existing methods primarily rely on
single-task learning (STL), which often fails to fully exploit the
complementarities between tasks. Besides, it requires more computational
resources while training and inference of each task independently. To address
these issues, we propose a new unified Quantum-enhanced and task-Weighted
Multi-Task Learning (QW-MTL) framework, specifically designed for ADMET
classification tasks. Built upon the Chemprop-RDKit backbone, QW-MTL adopts
quantum chemical descriptors to enrich molecular representations with
additional information about the electronic structure and interactions.
Meanwhile, it introduces a novel exponential task weighting scheme that
combines dataset-scale priors with learnable parameters to achieve dynamic loss
balancing across tasks. To the best of our knowledge, this is the first work to
systematically conduct joint multi-task training across all 13 Therapeutics
Data Commons (TDC) classification benchmarks, using leaderboard-style data
splits to ensure a standardized and realistic evaluation setting. Extensive
experimental results show that QW-MTL significantly outperforms single-task
baselines on 12 out of 13 tasks, achieving high predictive performance with
minimal model complexity and fast inference, demonstrating the effectiveness
and efficiency of multi-task molecular learning enhanced by quantum-informed
features and adaptive task weighting.

</details>


### [233] [Split Conformal Prediction in the Function Space with Neural Operators](https://arxiv.org/abs/2509.04623)
*David Millard,Lars Lindemann,Ali Baheri*

Main category: cs.LG

TL;DR: 本研究将分裂保形预测扩展到函数空间，解决了神经网络算子在无限维度下不确定性量化难题，克服了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的不确定性量化方法在无限维度函数空间上面临挑战，缺乏有限样本覆盖保证，或者需要强分布假设，或者覆盖范围保守。本研究旨在解决这一问题。

Method: 本研究提出一种两步方法，首先在有限维度空间中利用离散化映射建立有限样本覆盖保证，然后通过渐近收敛将保证提升到函数空间。研究还提出了保形半径分解和基于回归的校正方法，并引入了两个诊断指标。

Result: 所提出的方法在分辨率变化下保持了校准的覆盖范围，且变化较小，并在超分辨率任务中取得了更好的覆盖效果。

Conclusion: 本研究成功地将分裂保形预测扩展到函数空间，为神经网络算子在无限维度下的不确定性量化提供了新的解决方案，并通过实验验证了其有效性。

Abstract: Uncertainty quantification for neural operators remains an open problem in
the infinite-dimensional setting due to the lack of finite-sample coverage
guarantees over functional outputs. While conformal prediction offers
finite-sample guarantees in finite-dimensional spaces, it does not directly
extend to function-valued outputs. Existing approaches (Gaussian processes,
Bayesian neural networks, and quantile-based operators) require strong
distributional assumptions or yield conservative coverage. This work extends
split conformal prediction to function spaces following a two step method. We
first establish finite-sample coverage guarantees in a finite-dimensional space
using a discretization map in the output function space. Then these guarantees
are lifted to the function-space by considering the asymptotic convergence as
the discretization is refined. To characterize the effect of resolution, we
decompose the conformal radius into discretization, calibration, and
misspecification components. This decomposition motivates a regression-based
correction to transfer calibration across resolutions. Additionally, we propose
two diagnostic metrics (conformal ensemble score and internal agreement) to
quantify forecast degradation in autoregressive settings. Empirical results
show that our method maintains calibrated coverage with less variation under
resolution shifts and achieves better coverage in super-resolution tasks.

</details>


### [234] [Fundamental bounds on efficiency-confidence trade-off for transductive conformal prediction](https://arxiv.org/abs/2509.04631)
*Arash Behboodi,Alvaro H. C. Correia,Fabio Valerio Massoli,Christos Louizos*

Main category: cs.LG

TL;DR: ICP在预测多个数据点时，在置信度和效率（预测集大小）之间存在严格的权衡，置信度越高，预测集越大，且预测集大小会随样本数量和数据不确定性呈指数增长。


<details>
  <summary>Details</summary>
Motivation: 在需要同时对多个数据点进行预测的场景下，保证预测的置信度并最小化预测集的大小。在现有方法中，置信度和效率（预测集大小）之间存在冲突。

Method: 推导了一个有限样本界限，该界限表明任何非平凡的置信水平都会导致预测集大小随着样本数量的增加呈指数增长，并且与数据的条件熵成正比。此外，该界限还包含一个与条件概率分布对数方差相关的二阶项（离散度）。在理想化设置中证明了这个界限是可以达到的。最后，分析了所有测试数据点具有相同标签的特殊情况，将其简化为经验统计量的假设检验问题，并给出了渐近最优的置信度预测器及其误差指数分析。

Result: 推导出的有限样本界限表明，预测集的大小随着样本数量的增加呈指数增长，与数据的条件熵成正比，并包含一个与离散度相关的项。在理想情况下，该界限是可以达到的。在特殊情况下，给出了渐近最优的置信度预测器。

Conclusion: Transductive conformal prediction 在置信度和预测集大小之间存在根本性的权衡。数据的不确定性（以条件熵和离散度衡量）会显著影响预测集的性能。特殊情况下的分析为理解和优化该方法提供了见解。

Abstract: Transductive conformal prediction addresses the simultaneous prediction for
multiple data points. Given a desired confidence level, the objective is to
construct a prediction set that includes the true outcomes with the prescribed
confidence. We demonstrate a fundamental trade-off between confidence and
efficiency in transductive methods, where efficiency is measured by the size of
the prediction sets. Specifically, we derive a strict finite-sample bound
showing that any non-trivial confidence level leads to exponential growth in
prediction set size for data with inherent uncertainty. The exponent scales
linearly with the number of samples and is proportional to the conditional
entropy of the data. Additionally, the bound includes a second-order term,
dispersion, defined as the variance of the log conditional probability
distribution. We show that this bound is achievable in an idealized setting.
Finally, we examine a special case of transductive prediction where all test
data points share the same label. We show that this scenario reduces to the
hypothesis testing problem with empirically observed statistics and provide an
asymptotically optimal confidence predictor, along with an analysis of the
error exponent.

</details>


### [235] [Beyond Ordinary Lipschitz Constraints: Differentially Private Stochastic Optimization with Tsybakov Noise Condition](https://arxiv.org/abs/2509.04668)
*Difei Xu,Meng Ding,Zihang Xiang,Jinhui Xu,Di Wang*

Main category: cs.LG

TL;DR: 在差分隐私模型下研究随机凸优化问题（DP-SCO），并提出了一种新的算法，该算法在Tsybakov噪声条件下（TNC）取得了优于现有方法的界限。


<details>
  <summary>Details</summary>
Motivation: 以往关于差分隐私下的随机凸优化（DP-SCO）的研究通常假设损失函数是Lipschitz连续的。然而，在许多实际应用中，损失函数可能不是Lipschitz连续的，或者其Lipschitz常数可能非常大甚至无界。因此，研究在更一般的Tsybakov噪声条件下（TNC）的DP-SCO问题具有重要的理论和实践意义。

Method: 论文首先考虑了TNC条件下的Lipschitz情况（$	heta 
less 2$），并提出了一种 $(\varepsilon, \delta)$-DP算法，其效用界限在很大概率下为 $\tilde{O}\left(\left(\tilde{r}_{2k}(\frac{1}{\sqrt{n}}+(\frac{\sqrt{d}}{n\varepsilon}))^\frac{k-1}{k}\right)^\frac{\theta}{\theta-1}\right)$。该界限不依赖于Lipschitz常数。随后，论文将研究扩展到更一般的TNC条件（$	heta 
less ar{\theta} > 1$），并推导了相应的效用界限。对于隐私预算 $\varepsilon$ 足够小的情况，即使损失函数不是Lipschitz连续的，论文也证明了一个上界。在下界方面，论文证明了对于任何 $\theta \nless 2$，$ho$-zero Concentrated Differential Privacy 的私有极小极大率为 $\Omega\left(\left(\tilde{r}_{k}(\frac{1}{\sqrt{n}}+(\frac{\sqrt{d}}{n\sqrt{\rho}}))^\frac{k-1}{k}\right)^\frac{\theta}{\theta-1}\right)$。

Result: 论文提出了一种新的DP-SCO算法，在TNC条件下取得了最优或接近最优的界限。具体来说，在Lipschitz情况下，算法的效用界限独立于Lipschitz常数。在更一般的TNC条件下，算法仍然能提供有效的界限。论文还首次证明了在TNC条件下的DP-SCO问题的下界。

Conclusion: 本研究在差分隐私的随机凸优化问题中取得了重要进展。通过在Tsybakov噪声条件下进行分析，论文不仅为非Lipschitz或具有大Lipschitz常数的损失函数提供了新的算法和理论保证，而且还建立了相应的下界，为该领域未来的研究指明了方向。

Abstract: We study Stochastic Convex Optimization in the Differential Privacy model
(DP-SCO). Unlike previous studies, here we assume the population risk function
satisfies the Tsybakov Noise Condition (TNC) with some parameter $\theta>1$,
where the Lipschitz constant of the loss could be extremely large or even
unbounded, but the $\ell_2$-norm gradient of the loss has bounded $k$-th moment
with $k\geq 2$. For the Lipschitz case with $\theta\geq 2$, we first propose an
$(\varepsilon, \delta)$-DP algorithm whose utility bound is
$\Tilde{O}\left(\left(\tilde{r}_{2k}(\frac{1}{\sqrt{n}}+(\frac{\sqrt{d}}{n\varepsilon}))^\frac{k-1}{k}\right)^\frac{\theta}{\theta-1}\right)$
in high probability, where $n$ is the sample size, $d$ is the model dimension,
and $\tilde{r}_{2k}$ is a term that only depends on the $2k$-th moment of the
gradient. It is notable that such an upper bound is independent of the
Lipschitz constant. We then extend to the case where
  $\theta\geq \bar{\theta}> 1$ for some known constant $\bar{\theta}$.
Moreover, when the privacy budget $\varepsilon$ is small enough, we show an
upper bound of
$\tilde{O}\left(\left(\tilde{r}_{k}(\frac{1}{\sqrt{n}}+(\frac{\sqrt{d}}{n\varepsilon}))^\frac{k-1}{k}\right)^\frac{\theta}{\theta-1}\right)$
even if the loss function is not Lipschitz. For the lower bound, we show that
for any $\theta\geq 2$, the private minimax rate for $\rho$-zero Concentrated
Differential Privacy is lower bounded by
$\Omega\left(\left(\tilde{r}_{k}(\frac{1}{\sqrt{n}}+(\frac{\sqrt{d}}{n\sqrt{\rho}}))^\frac{k-1}{k}\right)^\frac{\theta}{\theta-1}\right)$.

</details>


### [236] [CPEP: Contrastive Pose-EMG Pre-training Enhances Gesture Generalization on EMG Signals](https://arxiv.org/abs/2509.04699)
*Wenhui Cui,Christopher Sandino,Hadi Pouransari,Ran Liu,Juri Minxha,Ellen L. Zippi,Aman Verma,Anna Sedlackova,Behrooz Mahasseni,Erdrin Azemi*

Main category: cs.LG

TL;DR: 本研究提出了一种名为CPEP的框架，通过结合表面肌电信号（sEMG）和人体姿态信息，实现手势识别，特别是在只有sEMG数据的情况下也能进行手势分类，并在相关和无关手势的分类任务上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 为了在可穿戴设备上实现连续的手势预测，本研究旨在利用低功耗、低成本的表面肌电信号（sEMG），并探索如何通过结合高质量数据（如视频、图像和手部骨骼）来提升sEMG信号的表征质量，从而实现零样本手势分类。

Method: 提出了一种名为对比姿态-EMG预训练（CPEP）的框架，该框架旨在对齐EMG和姿态的表征。通过学习一个EMG编码器，使其能够产生高质量且包含姿态信息（pose-informative）的表征。

Result: 在评估中，通过线性探测（linear probing）和零样本（zero-shot）设置，本研究提出的模型在纯in-distribution手势分类任务上超越了emg2pose基准模型高达21%，在out-of-distribution（未见过）的手势分类任务上更是超越了72%。

Conclusion: 本研究证明了通过对齐弱模态数据（sEMG）和强模态数据（姿态）的学习表征，可以有效提高弱模态数据的表征质量，并实现零样本手势分类，在实际应用中具有重要意义。

Abstract: Hand gesture classification using high-quality structured data such as
videos, images, and hand skeletons is a well-explored problem in computer
vision. Leveraging low-power, cost-effective biosignals, e.g. surface
electromyography (sEMG), allows for continuous gesture prediction on wearables.
In this paper, we demonstrate that learning representations from weak-modality
data that are aligned with those from structured, high-quality data can improve
representation quality and enables zero-shot classification. Specifically, we
propose a Contrastive Pose-EMG Pre-training (CPEP) framework to align EMG and
pose representations, where we learn an EMG encoder that produces high-quality
and pose-informative representations. We assess the gesture classification
performance of our model through linear probing and zero-shot setups. Our model
outperforms emg2pose benchmark models by up to 21% on in-distribution gesture
classification and 72% on unseen (out-of-distribution) gesture classification.

</details>


### [237] [Echoes Before Collapse: Deep Learning Detection of Flickering in Complex Systems](https://arxiv.org/abs/2509.04683)
*Yazdan Babazadeh Maghsoodlo,Madhur Anand,Chris T. Bauch*

Main category: cs.LG

TL;DR: 深度学习模型可以准确识别“闪烁”现象，即复杂系统中由噪声驱动的稳定状态转换，这是一种系统韧性下降的标志，可能预示着即将发生的临界状态转变。


<details>
  <summary>Details</summary>
Motivation: “闪烁”现象是系统韧性下降的标志，可能预示着重要的、但难以预测的临界状态转变。然而，深度学习在检测这种现象方面的潜力尚未被探索。

Method: 使用卷积长短期记忆（CNN LSTM）模型，对带有附加噪声的简单多项式函数生成的合成时间序列进行训练，以识别“闪烁”模式。

Result: CNN LSTM模型不仅能准确识别合成数据中的“闪烁”模式，而且能够泛化到各种随机系统，并成功应用于实际数据集，如睡鼠体温记录和非洲湿润时期的古气候代理数据，检测其中的“闪烁”现象。

Conclusion: 深度学习技术能够从嘈杂、非线性的时间序列中提取早期预警信号，为识别各种动力学系统中的不稳定性提供了一个灵活的框架。

Abstract: Deep learning offers powerful tools for anticipating tipping points in
complex systems, yet its potential for detecting flickering (noise-driven
switching between coexisting stable states) remains unexplored. Flickering is a
hallmark of reduced resilience in climate systems, ecosystems, financial
markets, and other systems. It can precede critical regime shifts that are
highly impactful but difficult to predict. Here we show that convolutional long
short-term memory (CNN LSTM) models, trained on synthetic time series generated
from simple polynomial functions with additive noise, can accurately identify
flickering patterns. Despite being trained on simplified dynamics, our models
generalize to diverse stochastic systems and reliably detect flickering in
empirical datasets, including dormouse body temperature records and
palaeoclimate proxies from the African Humid Period. These findings demonstrate
that deep learning can extract early warning signals from noisy, nonlinear time
series, providing a flexible framework for identifying instability across a
wide range of dynamical systems.

</details>


### [238] [KRAFT: A Knowledge Graph-Based Framework for Automated Map Conflation](https://arxiv.org/abs/2509.04684)
*Farnoosh Hashemi,Laks V. S. Lakshmanan*

Main category: cs.LG

TL;DR: KRAFT是一个基于学习的方法，用于增强地理数据库（GDB）的地图信息，解决了现有方法在处理非线性对象和数据驱动学习方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有地图拼接方法在处理非线性对象和数据驱动学习方面存在局限性，需要更有效的方法来增强地理数据库的准确性和时效性。

Method: KRAFT包含三个部分：1. 知识图谱构建：将每个GDB表示为知识图谱。2. 地图匹配：使用知识图谱对齐方法和地理空间特征编码器来匹配知识图谱中的实体。3. 地图合并：使用混合整数线性规划方法来一致地合并匹配的实体，同时避免引入不一致性。

Result: KRAFT在地图拼接任务上取得了优于现有技术和基线方法的性能，其各个模块（如地图匹配和地图合并）的表现也优于传统方法。

Conclusion: KRAFT通过其创新的基于学习的方法，显著提高了地图拼接的性能，并为处理非线性地理空间实体提供了有效解决方案。

Abstract: Digital maps play a crucial role in various applications such as navigation,
fleet management, and ride-sharing, necessitating their accuracy and currency,
which require timely updates. While the majority of geospatial databases (GDBs)
provide high-quality information, their data is (i) limited to specific regions
and/or (ii) missing some entities, even in their covered areas. Map conflation
is the process of augmentation of a GDB using another GDB to conflate missing
spatial features. Existing map conflation methods suffer from two main
limitations: (1) They are designed for the conflation of linear objects (e.g.,
road networks) and cannot simply be extended to non-linear objects, thus
missing information about most entities in the map. (2) They are heuristic
algorithmic approaches that are based on pre-defined rules, unable to learn
entities matching in a data-driven manner. To address these limitations, we
design KRAFT, a learning based approach consisting of three parts: (1)
Knowledge Graph Construction - where each GDB is represented by a knowledge
graph, (2) Map Matching - where we use a knowledge graph alignment method as
well as a geospatial feature encoder to match entities in obtained knowledge
graphs, and (3) Map Merging - where we merge matched entities in the previous
modules in a consistent manner, using a mixed integer linear programming
formulation that fully merges the GDBs without adding any inconsistencies. Our
experimental evaluation shows that not only does KRAFT achieve outstanding
performance compared to state-of-the-art and baseline methods in map conflation
tasks, but each of its modules (e.g., Map Matching and Map Merging) also
separately outperforms traditional matching and merging methods.

</details>


### [239] [Natural Spectral Fusion: p-Exponent Cyclic Scheduling and Early Decision-Boundary Alignment in First-Order Optimization](https://arxiv.org/abs/2509.04713)
*Gongyue Zhang,Honghai Liu*

Main category: cs.LG

TL;DR: 研究人员提出了一种名为自然光谱融合（NSF）的新方法，通过控制优化过程中的频率覆盖和信息融合来改进模型训练，而不是仅仅调整步长。


<details>
  <summary>Details</summary>
Motivation: 现有研究虽然广泛讨论了机器学习中的频谱行为，但优化器自身的频谱偏差仍然不清楚。本文旨在探讨和解决这个问题。

Method: NSF 将训练视为可控的光谱覆盖和信息融合，而不是简单的步长缩放。其核心原则包括：将优化器视为动态平衡低频和高频信息的频谱控制器；以及在不修改模型、数据或训练流程的情况下，以可忽略的成本周期性地重新加权频率带。通过p-指数扩展二阶矩项实现NSF，并采用周期性调度。

Result: 理论和实验表明，自适应方法倾向于低频，SGD接近中性，而负指数则增强高频信息。周期性调度拓宽了频谱覆盖，改善了跨频带融合，并促使决策边界的早期对齐，即使在损失较高的情况下也能提高准确性。与基线相比，p-指数周期性调度在相同的学习率策略和固定的超参数下，一致地降低了测试误差，并展示了不同的收敛行为，在某些任务上仅用四分之一的训练成本即可达到基线准确率。

Conclusion: NSF揭示了优化器作为主动频谱控制器的作用，并提供了一个统一、可控且高效的一阶优化框架。

Abstract: Spectral behaviors have been widely discussed in machine learning, yet the
optimizer's own spectral bias remains unclear. We argue that first-order
optimizers exhibit an intrinsic frequency preference that significantly
reshapes the optimization path. To address this, we propose Natural Spectral
Fusion (NSF): reframing training as controllable spectral coverage and
information fusion rather than merely scaling step sizes. NSF has two core
principles: treating the optimizer as a spectral controller that dynamically
balances low- and high-frequency information; and periodically reweighting
frequency bands at negligible cost, without modifying the model, data, or
training pipeline. We realize NSF via a p-exponent extension of the
second-moment term, enabling both positive and negative exponents, and
implement it through cyclic scheduling. Theory and experiments show that
adaptive methods emphasize low frequencies, SGD is near-neutral, and negative
exponents amplify high-frequency information. Cyclic scheduling broadens
spectral coverage, improves cross-band fusion, and induces early
decision-boundary alignment, where accuracy improves even while loss remains
high. Across multiple benchmarks, with identical learning-rate strategies and
fixed hyperparameters, p-exponent cyclic scheduling consistently reduces test
error and demonstrates distinct convergence behavior; on some tasks, it matches
baseline accuracy with only one-quarter of the training cost. Overall, NSF
reveals the optimizer's role as an active spectral controller and provides a
unified, controllable, and efficient framework for first-order optimization.

</details>


### [240] [CoVeR: Conformal Calibration for Versatile and Reliable Autoregressive Next-Token Prediction](https://arxiv.org/abs/2509.04733)
*Yuzhu Chen,Yingjie Wang,Shunyu Liu,Yongcheng Jing,Dacheng Tao*

Main category: cs.LG

TL;DR: CoVeR是一种新的无模型解码策略，利用共形预测框架，在保持紧凑搜索空间的同时，保证了对期望轨迹的高覆盖率。


<details>
  <summary>Details</summary>
Motivation: 现有的解码策略（如束搜索）在复杂推理任务中虽然能生成合理的候选集，但缺乏可证明的覆盖保证，并且难以平衡搜索效率和对长尾序列等现实世界应用中重要但稀有的轨迹的需求。

Method: 提出了一种名为CoVeR的新型无模型解码策略，该策略基于共形预测框架，旨在紧凑搜索空间内实现高覆盖率。

Result: 理论上，该方法建立了一个PAC风格的泛化界限，保证CoVeR能渐近地达到至少1 - α的覆盖率，其中α为任意给定的置信水平。

Conclusion: CoVeR作为一种基于共形预测的解码策略，能够有效解决现有方法在覆盖率保证和长尾序列处理方面的不足，并在理论上保证了其泛化性能。

Abstract: Autoregressive pre-trained models combined with decoding methods have
achieved impressive performance on complex reasoning tasks. While mainstream
decoding strategies such as beam search can generate plausible candidate sets,
they often lack provable coverage guarantees, and struggle to effectively
balance search efficiency with the need for versatile trajectories,
particularly those involving long-tail sequences that are essential in certain
real-world applications. To address these limitations, we propose
\textsc{CoVeR}, a novel model-free decoding strategy wihtin the conformal
prediction framework that simultaneously maintains a compact search space and
ensures high coverage probability over desirable trajectories. Theoretically,
we establish a PAC-style generalization bound, guaranteeing that \textsc{CoVeR}
asymptotically achieves a coverage rate of at least $1 - \alpha$ for any target
level $\alpha \in (0,1)$.

</details>


### [241] [A Kolmogorov-Arnold Network for Interpretable Cyberattack Detection in AGC Systems](https://arxiv.org/abs/2509.05259)
*Jehad Jilan,Niranjana Naveen Nambiar,Ahmad Mohammad Saber,Alok Paranjape,Amr Youssef,Deepa Kundur*

Main category: cs.LG

TL;DR: 该研究提出使用 Kolmogorov-Arnold Networks (KAN) 来检测自动发电控制 (AGC) 系统中的虚假数据注入攻击 (FDIA)，并提供可解释的识别方法。


<details>
  <summary>Details</summary>
Motivation: 传统的网络攻击检测方法难以应对 AGC 系统中的 FDIA，该类攻击能在干扰系统稳定性的同时规避检测。现有研究多采用黑盒方法，缺乏可解释性。

Method: 提出使用 Kolmogorov-Arnold Networks (KAN) 模型来检测 AGC 系统中的 FDIA。KAN 模型能够提取符号方程，提供比传统机器学习模型更高的可解释性。该模型在离线状态下训练，以学习 AGC 测量值在不同运行场景下的复杂非线性关系。训练完成后，可以提取描述模型行为的符号公式。

Result: KAN 模型能够实现高达 95.97% 的 FDIA 检测率（初始模型）和 95.9% 的检测率（符号公式），同时保持较低的误报率。

Conclusion: 所提出的 KAN 模型为增强 AGC 网络安全提供了一种可靠的方法，其高检测率和低误报率，以及模型的可解释性，使其在 FDIA 检测方面具有优势。

Abstract: Automatic Generation Control (AGC) is essential for power grid stability but
remains vulnerable to stealthy cyberattacks, such as False Data Injection
Attacks (FDIAs), which can disturb the system's stability while evading
traditional detection methods. Unlike previous works that relied on blackbox
approaches, this work proposes Kolmogorov-Arnold Networks (KAN) as an
interpretable and accurate method for FDIA detection in AGC systems,
considering the system nonlinearities. KAN models include a method for
extracting symbolic equations, and are thus able to provide more
interpretability than the majority of machine learning models. The proposed KAN
is trained offline to learn the complex nonlinear relationships between the AGC
measurements under different operating scenarios. After training, symbolic
formulas that describe the trained model's behavior can be extracted and
leveraged, greatly enhancing interpretability. Our findings confirm that the
proposed KAN model achieves FDIA detection rates of up to 95.97% and 95.9% for
the initial model and the symbolic formula, respectively, with a low false
alarm rate, offering a reliable approach to enhancing AGC cybersecurity.

</details>


### [242] [Beyond I-Con: Exploring New Dimension of Distance Measures in Representation Learning](https://arxiv.org/abs/2509.04734)
*Jasmine Shone,Shaden Alshammari,Mark Hamilton,Zhening Li,William Freeman*

Main category: cs.LG

TL;DR: 表示性学习方法可被统一为最小化KL散度，但KL散度存在优化挑战。Beyond I-Con框架通过探索替代统计散度和相似性核，系统地发现新的损失函数，并在聚类、对比学习和降维任务中取得优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: KL散度在表示性学习中可能存在优化挑战，如不对称性和无界性。

Method: Beyond I-Con框架，探索替代统计散度（如全变分距离、有界f-散度）和相似性核（如基于距离的相似性核），并应用于聚类、对比学习和降维任务。

Result: 在无监督聚类中，修改PMI算法使用TV距离，取得最先进结果；在监督对比学习中，使用TV和基于距离的相似性核优于标准方法；在降维任务中，使用有界f-散度替代KL，取得优于SNE的结果。

Conclusion: 在表示性学习优化中，选择合适的散度和相似性核至关重要。

Abstract: The Information Contrastive (I-Con) framework revealed that over 23
representation learning methods implicitly minimize KL divergence between data
and learned distributions that encode similarities between data points.
However, a KL-based loss may be misaligned with the true objective, and
properties of KL divergence such as asymmetry and unboundedness may create
optimization challenges. We present Beyond I-Con, a framework that enables
systematic discovery of novel loss functions by exploring alternative
statistical divergences and similarity kernels. Key findings: (1) on
unsupervised clustering of DINO-ViT embeddings, we achieve state-of-the-art
results by modifying the PMI algorithm to use total variation (TV) distance;
(2) on supervised contrastive learning, we outperform the standard approach by
using TV and a distance-based similarity kernel instead of KL and an angular
kernel; (3) on dimensionality reduction, we achieve superior qualitative
results and better performance on downstream tasks than SNE by replacing KL
with a bounded f-divergence. Our results highlight the importance of
considering divergence and similarity kernel choices in representation learning
optimization.

</details>


### [243] [VARMA-Enhanced Transformer for Time Series Forecasting](https://arxiv.org/abs/2509.04782)
*Jiajun Song,Xiaoou Liu*

Main category: cs.LG

TL;DR: VARMAformer 结合了 Transformer 的效率和 VARMA 的统计分析能力，通过新的特征提取器和注意力机制，在时间序列预测任务上取得了先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的 Transformer 模型在时间序列预测方面虽然表现出色，但可能忽略了 VARMA 等经典统计模型所能有效捕捉的细粒度局部时间依赖性。VARMAformer 旨在解决这一差距。

Method: VARMAformer 引入了两个关键创新：1. 专门的受 VARMA 启发的特征提取器 (VFE)，用于在块级别显式建模自回归 (AR) 和移动平均 (MA) 模式。2. 增强的注意力机制 (VE-atten)，采用时间门控使查询更具上下文感知能力。

Result: 通过在广泛使用的基准数据集上进行的大量实验，VARMAformer 持续优于现有的最先进方法。

Conclusion: 将经典统计见解整合到现代深度学习框架中，对于时间序列预测具有显著的益处，VARMAformer 的成功证明了这一点。

Abstract: Transformer-based models have significantly advanced time series forecasting.
Recent work, like the Cross-Attention-only Time Series transformer (CATS),
shows that removing self-attention can make the model more accurate and
efficient. However, these streamlined architectures may overlook the
fine-grained, local temporal dependencies effectively captured by classical
statistical models like Vector AutoRegressive Moving Average model (VARMA). To
address this gap, we propose VARMAformer, a novel architecture that synergizes
the efficiency of a cross-attention-only framework with the principles of
classical time series analysis. Our model introduces two key innovations: (1) a
dedicated VARMA-inspired Feature Extractor (VFE) that explicitly models
autoregressive (AR) and moving-average (MA) patterns at the patch level, and
(2) a VARMA-Enhanced Attention (VE-atten) mechanism that employs a temporal
gate to make queries more context-aware. By fusing these classical insights
into a modern backbone, VARMAformer captures both global, long-range
dependencies and local, statistical structures. Through extensive experiments
on widely-used benchmark datasets, we demonstrate that our model consistently
outperforms existing state-of-the-art methods. Our work validates the
significant benefit of integrating classical statistical insights into modern
deep learning frameworks for time series forecasting.

</details>


### [244] [Graph Unlearning: Efficient Node Removal in Graph Neural Networks](https://arxiv.org/abs/2509.04785)
*Faqian Guan,Tianqing Zhu,Zhoutian Wang,Wei Ren,Wanlei Zhou*

Main category: cs.LG

TL;DR: 提出三种新颖的图神经网络节点移除方法，以提高隐私保护和效率，并在实验中证明其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有节点移除方法在图神经网络（GNN）中存在限制GNN结构、未能有效利用图拓扑或影响图拓扑等问题，导致性能-复杂度权衡不理想。

Method: 提出三种新颖的节点移除方法：1. 基于类的标签替换；2. 拓扑引导的邻居均值后验概率；3. 类一致的邻居节点过滤。其中，后两种方法能有效利用图的拓扑特征。

Result: 在三个基准数据集上的实验结果表明，所提出的方法在模型效用、移除效用和移除效率方面均优于现有最先进的节点移除方法。

Conclusion: 所提出的三种新颖的节点移除方法能够有效移除敏感训练节点，保护GNN中的隐私信息，并在性能和效率上均有优势，为GNN的隐私和安全提供了新的见解。

Abstract: With increasing concerns about privacy attacks and potential sensitive
information leakage, researchers have actively explored methods to efficiently
remove sensitive training data and reduce privacy risks in graph neural network
(GNN) models. Node unlearning has emerged as a promising technique for
protecting the privacy of sensitive nodes by efficiently removing specific
training node information from GNN models. However, existing node unlearning
methods either impose restrictions on the GNN structure or do not effectively
utilize the graph topology for node unlearning. Some methods even compromise
the graph's topology, making it challenging to achieve a satisfactory
performance-complexity trade-off. To address these issues and achieve efficient
unlearning for training node removal in GNNs, we propose three novel node
unlearning methods: Class-based Label Replacement, Topology-guided Neighbor
Mean Posterior Probability, and Class-consistent Neighbor Node Filtering. Among
these methods, Topology-guided Neighbor Mean Posterior Probability and
Class-consistent Neighbor Node Filtering effectively leverage the topological
features of the graph, resulting in more effective node unlearning. To validate
the superiority of our proposed methods in node unlearning, we conducted
experiments on three benchmark datasets. The evaluation criteria included model
utility, unlearning utility, and unlearning efficiency. The experimental
results demonstrate the utility and efficiency of the proposed methods and
illustrate their superiority compared to state-of-the-art node unlearning
methods. Overall, the proposed methods efficiently remove sensitive training
nodes and protect the privacy information of sensitive nodes in GNNs. The
findings contribute to enhancing the privacy and security of GNN models and
provide valuable insights into the field of node unlearning.

</details>


### [245] [Revolution or Hype? Seeking the Limits of Large Models in Hardware Design](https://arxiv.org/abs/2509.04905)
*Qiang Xu,Leon Stok,Rolf Drechsler,Xi Wang,Grace Li Zhang,Igor L. Markov*

Main category: cs.LG

TL;DR: 大型语言模型(LLM)和大型电路模型(LCM)在电子设计自动化(EDA)领域带来了革命性的潜力，但也引发了关于其真实影响的争论。本文旨在为ICCAD 2025的专题讨论会奠定基础，批判性地评估这些模型在硬件设计中的实际能力、局限性和未来前景，重点关注可靠性、可扩展性和可解释性，并探讨它们与传统EDA方法的互补性。


<details>
  <summary>Details</summary>
Motivation: 评估大型AI模型（LLM和LCM）在电路设计和优化中的实际能力、根本局限性和未来前景，以应对EDA社区对其是否为真正革命或短期趋势的怀疑。

Method: 综合学术界和工业界专家的核心论点，围绕可靠性、可扩展性和可解释性进行讨论，并与传统EDA方法进行比较。

Result: 提供对大型AI模型在硬件设计中应用的权威概述，聚焦于它们是否能超越或补充传统EDA方法。

Conclusion: 大型AI模型在EDA领域的应用是一个有争议但有影响力的技术趋势，需要深入理解其优缺点及未来发展方向。

Abstract: Recent breakthroughs in Large Language Models (LLMs) and Large Circuit Models
(LCMs) have sparked excitement across the electronic design automation (EDA)
community, promising a revolution in circuit design and optimization. Yet, this
excitement is met with significant skepticism: Are these AI models a genuine
revolution in circuit design, or a temporary wave of inflated expectations?
This paper serves as a foundational text for the corresponding ICCAD 2025
panel, bringing together perspectives from leading experts in academia and
industry. It critically examines the practical capabilities, fundamental
limitations, and future prospects of large AI models in hardware design. The
paper synthesizes the core arguments surrounding reliability, scalability, and
interpretability, framing the debate on whether these models can meaningfully
outperform or complement traditional EDA methods. The result is an
authoritative overview offering fresh insights into one of today's most
contentious and impactful technology trends.

</details>


### [246] [Scaling Law for Large-Scale Pre-Training Using Chaotic Time Series and Predictability in Financial Time Series](https://arxiv.org/abs/2509.04921)
*Yuki Takemoto*

Main category: cs.LG

TL;DR: 通过生成和重采样合成混沌时间序列来改进金融时间序列预测，并在零样本设置下使用比特币数据进行了验证。


<details>
  <summary>Details</summary>
Motivation: 金融时间序列预测，特别是预测金融工具的回报，是一个具有挑战性的问题。现有的时间序列基础模型和混沌时间序列生成方法为改进预测提供了潜在途径。

Method: 提出了一种通过生成人工混沌时间序列和应用重采样技术来模拟金融时间序列数据的方法，并使用这些数据进行大规模预训练。通过增加重采样间隔来扩展预测范围，并对预训练模型进行零样本预测。

Result: 在比特币交易数据上进行的零样本预测显示，基于预测的简单交易策略在盈利能力方面显著优于自相关模型。在大规模预训练过程中，观察到了类似标度律的现象，即通过指数级增加训练样本数量，可以在扩展的预测范围内实现一定水平的预测性能。

Conclusion: 通过生成人工混沌时间序列和应用重采样技术，可以改进金融时间序列的预测。观察到的标度律现象表明，通过投入大量的计算资源，有可能预测近期事件，但需要进一步的研究来验证其稳健性和适用性。

Abstract: Time series forecasting plays a critical role in decision-making processes
across diverse fields including meteorology, traffic, electricity, economics,
finance, and so on. Especially, predicting returns on financial instruments is
a challenging problem. Some researchers have proposed time series foundation
models applicable to various forecasting tasks. Simultaneously, based on the
recognition that real-world time series exhibit chaotic properties, methods
have been developed to artificially generate synthetic chaotic time series,
construct diverse datasets and train models. In this study, we propose a
methodology for modeling financial time series by generating artificial chaotic
time series and applying resampling techniques to simulate financial time
series data, which we then use as training samples. Increasing the resampling
interval to extend predictive horizons, we conducted large-scale pre-training
using 10 billion training samples for each case. We subsequently created test
datasets for multiple timeframes using actual Bitcoin trade data and performed
zero-shot prediction without re-training the pre-trained model. The results of
evaluating the profitability of a simple trading strategy based on these
predictions demonstrated significant performance improvements over
autocorrelation models. During the large-scale pre-training process, we
observed a scaling law-like phenomenon that we can achieve predictive
performance at a certain level with extended predictive horizons for chaotic
time series by increasing the number of training samples exponentially. If this
scaling law proves robust and holds true across various chaotic models, it
suggests the potential to predict near-future events by investing substantial
computational resources. Future research should focus on further large-scale
training and verifying the applicability of this scaling law to diverse chaotic
models.

</details>


### [247] [A transformer-BiGRU-based framework with data augmentation and confident learning for network intrusion detection](https://arxiv.org/abs/2509.04925)
*Jiale Zhang,Pengfei He,Fei Li,Kewei Li,Yan Wang,Lan Huang,Ruochi Zhang,Fengfeng Zhou*

Main category: cs.LG

TL;DR: TrailGate是一个集成了机器学习和深度学习技术的新型网络入侵检测框架，通过结合Transformer、BiGRU、特征选择和数据增强技术，能够有效识别常见攻击并检测新兴威胁。


<details>
  <summary>Details</summary>
Motivation: 当前网络通信流量激增，对网络入侵检测系统的精度和鲁棒性提出了更高要求。传统机器学习方法难以处理复杂多变的攻击模式，且面临数据稀疏和类别不平衡的问题。

Method: TrailGate融合了Transformer和BiGRU深度学习模型，并结合了先进的特征选择策略和数据增强技术，构建了一个混合模型用于网络入侵检测。

Result: TrailGate能够识别常见的网络攻击类型，并且在检测和缓解新兴威胁方面表现出色。

Conclusion: TrailGate通过融合机器学习和深度学习技术，有效解决了传统方法在处理复杂网络入侵检测数据时的挑战，提高了对已知及未知攻击的检测能力。

Abstract: In today's fast-paced digital communication, the surge in network traffic
data and frequency demands robust and precise network intrusion solutions.
Conventional machine learning methods struggle to grapple with complex patterns
within the vast network intrusion datasets, which suffer from data scarcity and
class imbalance. As a result, we have integrated machine learning and deep
learning techniques within the network intrusion detection system to bridge
this gap. This study has developed TrailGate, a novel framework that combines
machine learning and deep learning techniques. By integrating Transformer and
Bidirectional Gated Recurrent Unit (BiGRU) architectures with advanced feature
selection strategies and supplemented by data augmentation techniques,
TrailGate can identifies common attack types and excels at detecting and
mitigating emerging threats. This algorithmic fusion excels at detecting common
and well-understood attack types and has the unique ability to swiftly identify
and neutralize emerging threats that stem from existing paradigms.

</details>


### [248] [Ontology-Aligned Embeddings for Data-Driven Labour Market Analytics](https://arxiv.org/abs/2509.04942)
*Heinke Hihn,Dennis A. V. Dittrich,Carl Jeske,Cayo Costa Sobral,Helio Pais,Timm Lochmann*

Main category: cs.LG

TL;DR: 通过嵌入式对齐过程学习共享语义空间，解决跨职业数据分析的瓶颈。


<details>
  <summary>Details</summary>
Motivation: 解决跨职业数据分析中，由于不同来源的职业数据难以关联而导致的长期瓶颈问题。以往依赖人工构建的本体库，成本高昂且维护困难。

Method: 提出一种基于嵌入的对齐方法，利用Sentence-BERT模型学习共享语义空间，将自由格式的德语职位名称映射到两个既定的本体库（Klassifikation der Berufe和International Standard Classification of Education）。利用德国联邦就业局的公开数据进行模型微调，并将分类问题转化为语义搜索问题。

Result: 构建了一个包含（职位名称，嵌入）的丰富数据集，定义了一个相似性图谱结构，实现了高效的近似最近邻搜索，从而能够灵活地添加更多分类。

Conclusion: 该方法为跨职业数据分析提供了一种可扩展、灵活且无需大量人工干预的解决方案，并计划扩展到更多本体库和多语言支持。

Abstract: The limited ability to reason across occupational data from different sources
is a long-standing bottleneck for data-driven labour market analytics. Previous
research has relied on hand-crafted ontologies that allow such reasoning but
are computationally expensive and require careful maintenance by human experts.
The rise of language processing machine learning models offers a scalable
alternative by learning shared semantic spaces that bridge diverse occupational
vocabularies without extensive human curation. We present an embedding-based
alignment process that links any free-form German job title to two established
ontologies - the German Klassifikation der Berufe and the International
Standard Classification of Education. Using publicly available data from the
German Federal Employment Agency, we construct a dataset to fine-tune a
Sentence-BERT model to learn the structure imposed by the ontologies. The
enriched pairs (job title, embedding) define a similarity graph structure that
we can use for efficient approximate nearest-neighbour search, allowing us to
frame the classification process as a semantic search problem. This allows for
greater flexibility, e.g., adding more classes. We discuss design decisions,
open challenges, and outline ongoing work on extending the graph with other
ontologies and multilingual titles.

</details>


### [249] [Detecting Blinks in Healthy and Parkinson's EEG: A Deep Learning Perspective](https://arxiv.org/abs/2509.04951)
*Artem Lensky,Yiding Qiu*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Blinks in electroencephalography (EEG) are often treated as unwanted
artifacts. However, recent studies have demonstrated that blink rate and its
variability are important physiological markers to monitor cognitive load,
attention, and potential neurological disorders. This paper addresses the
critical task of accurate blink detection by evaluating various deep learning
models for segmenting EEG signals into involuntary blinks and non-blinks. We
present a pipeline for blink detection using 1, 3, or 5 frontal EEG electrodes.
The problem is formulated as a sequence-to-sequence task and tested on various
deep learning architectures including standard recurrent neural networks,
convolutional neural networks (both standard and depth-wise), temporal
convolutional networks (TCN), transformer-based models, and hybrid
architectures. The models were trained on raw EEG signals with minimal
pre-processing. Training and testing was carried out on a public dataset of 31
subjects collected at UCSD. This dataset consisted of 15 healthy participants
and 16 patients with Parkinson's disease allowing us to verify the model's
robustness to tremor. Out of all models, CNN-RNN hybrid model consistently
outperformed other models and achieved the best blink detection accuracy of
93.8%, 95.4% and 95.8% with 1, 3, and 5 channels in the healthy cohort and
correspondingly 73.8%, 75.4% and 75.8% in patients with PD. The paper compares
neural networks for the task of segmenting EEG recordings to involuntary blinks
and no blinks allowing for computing blink rate and other statistics.

</details>


### [250] [On the Normalization of Confusion Matrices: Methods and Geometric Interpretations](https://arxiv.org/abs/2509.04959)
*Johan Erbani,Pierre-Edouard Portier,Elod Egyed-Zsigmond,Sonia Ben Mokhtar,Diana Nurbakova*

Main category: cs.LG

TL;DR: 该研究提出了一种名为“双随机归一化”的新方法，用于分析异构分类器中的混淆矩阵，以区分类别相似性和分布偏差对模型错误的影响。


<details>
  <summary>Details</summary>
Motivation: 混淆矩阵在评估分类器时会受到类别相似性和分布偏差的共同影响，难以单独评估这两种因素的贡献。本研究旨在解决这一问题，以更精确地诊断模型行为并进行有针对性的改进。

Method: 本研究提出使用迭代比例拟合（Iterative Proportional Fitting）进行双随机归一化，这是一种对行和列归一化的推广。该方法能够恢复类别相似性的潜在结构，并将混淆矩阵归一化与模型的内部类别表示联系起来，提供了几何解释。

Result: 双随机归一化能够有效分离混淆矩阵中的错误来源，从而实现对模型行为更准确的诊断。此外，研究还发现了混淆矩阵归一化与模型内部类别表示之间的对应关系，并提供了相应的几何解释。

Conclusion: 双随机归一化是一种有效的方法，可以分离和分析异构分类器中混淆矩阵的错误来源，从而实现更深入的模型理解和改进。该方法还将混淆矩阵归一化与模型的内部表示联系起来，提供了新的见解。

Abstract: The confusion matrix is a standard tool for evaluating classifiers by
providing insights into class-level errors. In heterogeneous settings, its
values are shaped by two main factors: class similarity -- how easily the model
confuses two classes -- and distribution bias, arising from skewed
distributions in the training and test sets. However, confusion matrix values
reflect a mix of both factors, making it difficult to disentangle their
individual contributions. To address this, we introduce bistochastic
normalization using Iterative Proportional Fitting, a generalization of row and
column normalization. Unlike standard normalizations, this method recovers the
underlying structure of class similarity. By disentangling error sources, it
enables more accurate diagnosis of model behavior and supports more targeted
improvements. We also show a correspondence between confusion matrix
normalizations and the model's internal class representations. Both standard
and bistochastic normalizations can be interpreted geometrically in this space,
offering a deeper understanding of what normalization reveals about a
classifier.

</details>


### [251] [Neuro-Spectral Architectures for Causal Physics-Informed Networks](https://arxiv.org/abs/2509.04966)
*Arthur Bizzi,Leonardo M. Moreira,Márcio Marques,Leonardo Mendonça,Christian Júnior de Oliveira,Vitor Balestro,Lucas dos Santos Fernandez,Daniel Yukimura,Pavel Petrov,João M. Pereira,Tiago Novello,Lucas Nissenbaum*

Main category: cs.LG

TL;DR: PINNs在解决偏微分方程（PDE）方面表现出色，但面临收敛性差、违反因果关系和频谱偏差等问题。本文提出了一种新的神经谱架构（NeuSA），通过学习PDE在谱基上的投影，并结合神经ODE（NODE）来解决这些问题。NeuSA克服了频谱偏差，强制执行了因果关系，并通过经典方法的初始化方案实现了更快的训练。在二维和三维线性与非线性波动方程等标准基准测试中，NeuSA的性能优于其他架构，具有更快的收敛速度、更好的时间一致性和更高的预测精度。


<details>
  <summary>Details</summary>
Motivation: 标准的前馈神经网络（MLP）在解决具有挑战性的初始值问题时，往往无法收敛，并且会出现违反因果关系和频谱偏差（倾向于低频分量）的问题。因此，需要开发一种新的PINN架构来解决这些问题。

Method: NeuSA通过学习PDE在谱基上的投影，获得动力学的有限维表示，然后将其与自适应神经ODE（NODE）相结合。这种方法利用了谱表示所支持的高频分量来克服频谱偏差，通过继承NODE的因果结构来强制执行因果关系，并通过基于经典方法的初始化方案在接近目标解的位置开始训练。

Result: NeuSA在标准的线性与非线性波动方程基准测试中表现出色，与现有架构相比，具有更快的收敛速度、更好的时间一致性和更高的预测精度。

Conclusion: NeuSA是一种新颖的PINN架构，能够有效地解决具有挑战性的线性和非线性PDE问题，克服了传统MLP-PINN的局限性，并在多个基准测试中取得了优越的性能。

Abstract: Physics-Informed Neural Networks (PINNs) have emerged as a powerful neural
framework for solving partial differential equations (PDEs). However, standard
MLP-based PINNs often fail to converge when dealing with complex initial-value
problems, leading to solutions that violate causality and suffer from a
spectral bias towards low-frequency components. To address these issues, we
introduce NeuSA (Neuro-Spectral Architectures), a novel class of PINNs inspired
by classical spectral methods, designed to solve linear and nonlinear PDEs with
variable coefficients. NeuSA learns a projection of the underlying PDE onto a
spectral basis, leading to a finite-dimensional representation of the dynamics
which is then integrated with an adapted Neural ODE (NODE). This allows us to
overcome spectral bias, by leveraging the high-frequency components enabled by
the spectral representation; to enforce causality, by inheriting the causal
structure of NODEs, and to start training near the target solution, by means of
an initialization scheme based on classical methods. We validate NeuSA on
canonical benchmarks for linear and nonlinear wave equations, demonstrating
strong performance as compared to other architectures, with faster convergence,
improved temporal consistency and superior predictive accuracy. Code and
pretrained models will be released.

</details>


### [252] [Topology-Aware Graph Reinforcement Learning for Dynamic Routing in Cloud Networks](https://arxiv.org/abs/2509.04973)
*Yuxi Wang,Heyao Liu,Guanzi Yao,Nyutian Long,Yue Kang*

Main category: cs.LG

TL;DR: 提出一种拓扑感知图强化学习方法来优化云服务器环境中的路由策略。


<details>
  <summary>Details</summary>
Motivation: 解决动态拓扑下决策不稳定和结构感知不足的问题。

Method: 通过集成SASE模块（图卷积和结构位置嵌入）和PAGU机制（基于策略行为和奖励反馈自适应更新图结构）来构建统一的状态表示和结构演化框架。

Result: 在GEANT数据集上进行实验，与基线模型相比，在吞吐量、延迟控制和链路平衡方面表现更优。

Conclusion: 所提出的方法在动态和复杂的云网络中实现了高效且鲁棒的路由。

Abstract: This paper proposes a topology-aware graph reinforcement learning approach to
address the routing policy optimization problem in cloud server environments.
The method builds a unified framework for state representation and structural
evolution by integrating a Structure-Aware State Encoding (SASE) module and a
Policy-Adaptive Graph Update (PAGU) mechanism. It aims to tackle the challenges
of decision instability and insufficient structural awareness under dynamic
topologies. The SASE module models node states through multi-layer graph
convolution and structural positional embeddings, capturing high-order
dependencies in the communication topology and enhancing the expressiveness of
state representations. The PAGU module adjusts the graph structure based on
policy behavior shifts and reward feedback, enabling adaptive structural
updates in dynamic environments. Experiments are conducted on the real-world
GEANT topology dataset, where the model is systematically evaluated against
several representative baselines in terms of throughput, latency control, and
link balance. Additional experiments, including hyperparameter sensitivity,
graph sparsity perturbation, and node feature dimensionality variation, further
explore the impact of structure modeling and graph updates on model stability
and decision quality. Results show that the proposed method outperforms
existing graph reinforcement learning models across multiple performance
metrics, achieving efficient and robust routing in dynamic and complex cloud
networks.

</details>


### [253] [Adapt in the Wild: Test-Time Entropy Minimization with Sharpness and Feature Regularization](https://arxiv.org/abs/2509.04977)
*Shuaicheng Niu,Guohao Chen,Deyu Chen,Yifan Zhang,Jiaxiang Wu,Zhiquan Wen,Yaofo Chen,Peilin Zhao,Chunyan Miao,Mingkui Tan*

Main category: cs.LG

TL;DR: 现有的测试时自适应（TTA）方法在面对混合分布变化、小批量或在线不平衡标签时可能会失败。本研究发现，批归一化层（batch norm）是影响TTA稳定性的关键因素。虽然使用非批归一化层（如group norm或layer norm）可以提高稳定性，但仍可能导致模型坍塌到平凡解。研究人员进一步发现，在模型坍塌过程中，梯度会先爆炸后衰减，并且模型表征会变得高度相关并产生分类偏差。为解决这些问题，研究者提出了SAR（sharpness-aware and reliable entropy minimization）方法，通过去除部分梯度大的噪声样本并鼓励模型权重趋向平坦最小值来提高TTA的稳定性。在此基础上，SAR^2方法通过引入冗余度和不公平性正则化器，进一步防止表征坍塌，减少特征间的相关性，并惩罚偏向特定类别的表征。实验结果表明，所提出的方法在复杂测试场景下比现有方法更稳定且计算效率更高。


<details>
  <summary>Details</summary>
Motivation: 现有的测试时自适应（TTA）方法在真实世界部署时，在面对混合分布变化、小批量或在线不平衡标签分布等情况时，常常会失败或性能下降。这种不稳定性是阻碍TTA方法广泛应用的关键障碍。

Method: 本研究首先分析了影响TTA稳定性的原因，发现批归一化层（batch norm）是一个关键因素。随后，提出了一种名为SAR（sharpness-aware and reliable entropy minimization）的方法，旨在通过去除梯度大的噪声样本和鼓励模型权重趋向平坦最小值来提高TTA的稳定性。在此基础上，进一步引入了SAR^2方法，通过增加冗余度和不公平性正则化器来防止模型表征坍塌，减少特征相关性，并惩罚偏向特定类别的表征。

Result: 所提出的SAR和SAR^2方法在复杂的测试场景下（如混合分布变化、小批量、在线不平衡标签分布），相比于现有的TTA方法，表现出了更稳定的性能，并且在计算上是高效的。

Conclusion: 批归一化层是导致TTA不稳定的关键因素。通过提出SAR和SAR^2方法，结合梯度分析和表征正则化，可以有效地解决TTA在复杂和不稳定的测试场景下的性能下降和模型坍塌问题，提高TTA的稳定性和鲁棒性。

Abstract: Test-time adaptation (TTA) may fail to improve or even harm the model
performance when test data have: 1) mixed distribution shifts, 2) small batch
sizes, 3) online imbalanced label distribution shifts. This is often a key
obstacle preventing existing TTA methods from being deployed in the real world.
In this paper, we investigate the unstable reasons and find that the batch norm
layer is a crucial factor hindering TTA stability. Conversely, TTA can perform
more stably with batch-agnostic norm layers, i.e., group or layer norm.
However, we observe that TTA with group and layer norms does not always succeed
and still suffers many failure cases, i.e., the model collapses into trivial
solutions by assigning the same class label for all samples. By digging into
this, we find that, during the collapse process: 1) the model gradients often
undergo an initial explosion followed by rapid degradation, suggesting that
certain noisy test samples with large gradients may disrupt adaptation; and 2)
the model representations tend to exhibit high correlations and classification
bias. To address this, we first propose a sharpness-aware and reliable entropy
minimization method, called SAR, for stabilizing TTA from two aspects: 1)
remove partial noisy samples with large gradients, 2) encourage model weights
to go to a flat minimum so that the model is robust to the remaining noisy
samples. Based on SAR, we further introduce SAR^2 to prevent representation
collapse with two regularizers: 1) a redundancy regularizer to reduce
inter-dimensional correlations among centroid-invariant features; and 2) an
inequity regularizer to maximize the prediction entropy of a prototype
centroid, thereby penalizing biased representations toward any specific class.
Promising results demonstrate that our methods perform more stably over prior
methods and are computationally efficient under the above wild test scenarios.

</details>


### [254] [Directed Evolution of Proteins via Bayesian Optimization in Embedding Space](https://arxiv.org/abs/2509.04998)
*Matouš Soldát,Jiří Kléma*

Main category: cs.LG

TL;DR: 通过结合贝叶斯优化和蛋白质语言模型提取的信息表示，提出了一种新颖的机器学习辅助蛋白质定向进化方法，该方法提高了筛选效率和蛋白质功能。


<details>
  <summary>Details</summary>
Motivation: 为了提高蛋白质定向进化的效率，减少昂贵且耗时的生化筛选，需要机器学习方法来选择信息丰富或有前途的变体。

Method: 结合贝叶斯优化和从预训练的蛋白质语言模型中提取的蛋白质变体的传达信息表示，提出了一种新颖的机器学习辅助蛋白质定向进化方法。

Result: 基于序列嵌入的新表示显著提高了贝叶斯优化的性能，在进行的筛选总数相同的情况下产生了更好的结果。

Conclusion: 所提出的机器学习辅助定向进化方法在包含序列嵌入的表示方面优于最先进的方法，并且在每次迭代中产生的变体质量更高。

Abstract: Directed evolution is an iterative laboratory process of designing proteins
with improved function by iteratively synthesizing new protein variants and
evaluating their desired property with expensive and time-consuming biochemical
screening. Machine learning methods can help select informative or promising
variants for screening to increase their quality and reduce the amount of
necessary screening. In this paper, we present a novel method for
machine-learning-assisted directed evolution of proteins which combines
Bayesian optimization with informative representation of protein variants
extracted from a pre-trained protein language model. We demonstrate that the
new representation based on the sequence embeddings significantly improves the
performance of Bayesian optimization yielding better results with the same
number of conducted screening in total. At the same time, our method
outperforms the state-of-the-art machine-learning-assisted directed evolution
methods with regression objective.

</details>


### [255] [Depth-Aware Initialization for Stable and Efficient Neural Network Training](https://arxiv.org/abs/2509.05018)
*Vijay Pandey*

Main category: cs.LG

TL;DR: 提出了一种新的深度网络初始化方法，考虑了层深度信息并灵活地增加了网络方差，实验表明效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有初始化方法如 Glorot, He, 正交矩阵初始化, 随机游走法等，有的关注激活和梯度传播的单位方差，有的考虑了网络深度，但对于更深的网络，理论上的单位方差假设不再适用，需要从第一层到最后一层逐渐增加网络方差。

Method: 提出了一种新的初始化方法，该方法结合了每一层深度信息以及总网络深度信息，并能够灵活地增加网络方差。

Result: 实验表明，所提出的方法在初始化方面优于现有的初始化方案。

Conclusion: 在更深的网络中，需要增加网络从第一层激活到最后一层激活的方差，所提出的方法可以灵活地实现这一点。

Abstract: In past few years, various initialization schemes have been proposed. These
schemes are glorot initialization, He initialization, initialization using
orthogonal matrix, random walk method for initialization. Some of these methods
stress on keeping unit variance of activation and gradient propagation through
the network layer. Few of these methods are independent of the depth
information while some methods has considered the total network depth for
better initialization. In this paper, comprehensive study has been done where
depth information of each layer as well as total network is incorporated for
better initialization scheme. It has also been studied that for deeper networks
theoretical assumption of unit variance throughout the network does not perform
well. It requires the need to increase the variance of the network from first
layer activation to last layer activation. We proposed a novel way to increase
the variance of the network in flexible manner, which incorporates the
information of each layer depth. Experiments shows that proposed method
performs better than the existing initialization scheme.

</details>


### [256] [MultiSurv: A Multimodal Deep Survival Framework for Prostrate and Bladder Cancer](https://arxiv.org/abs/2509.05037)
*Noorul Wahab,Ethar Alzaid,Jiaqi Lv,Adam Shephard,Shan E Ahmed Raza*

Main category: cs.LG

TL;DR: MultiSurv是一个多模态深度生存模型，结合临床、MRI、RNA-seq和病理特征，用于预测前列腺癌和膀胱癌的复发时间，并在CHIMERA挑战赛中表现出良好的预测能力。


<details>
  <summary>Details</summary>
Motivation: 准确预测癌症患者的生存时间对于治疗规划和患者管理至关重要。

Method: 提出了一种名为MultiSurv的多模态深度生存模型，该模型利用DeepHit并结合了投影层和模态间交叉注意力机制，以整合临床、MRI、RNA-seq和全切片病理特征。

Result: 在前列腺癌复发预测任务（Task 1）中，模型在5折交叉验证中达到了0.843的C指数，在CHIMERA开发集上达到了0.818。在膀胱癌复发预测任务（Task 3）中，模型在5折交叉验证中获得了0.662的C指数，在开发集上获得了0.457。

Conclusion: 利用多模态数据和深度生存学习进行个性化风险分层是预测前列腺癌和膀胱癌复发的可行途径，并且该框架具有广泛的应用前景。

Abstract: Accurate prediction of time-to-event outcomes is a central challenge in
oncology, with significant implications for treatment planning and patient
management. In this work, we present MultiSurv, a multimodal deep survival
model utilising DeepHit with a projection layer and inter-modality
cross-attention, which integrates heterogeneous patient data, including
clinical, MRI, RNA-seq and whole-slide pathology features. The model is
designed to capture complementary prognostic signals across modalities and
estimate individualised time-to-biochemical recurrence in prostate cancer and
time-to-cancer recurrence in bladder cancer. Our approach was evaluated in the
context of the CHIMERA Grand Challenge, across two of the three provided tasks.
For Task 1 (prostate cancer bio-chemical recurrence prediction), the proposed
framework achieved a concordance index (C-index) of 0.843 on 5-folds
cross-validation and 0.818 on CHIMERA development set, demonstrating robust
discriminatory ability. For Task 3 (bladder cancer recurrence prediction), the
model obtained a C-index of 0.662 on 5-folds cross-validation and 0.457 on
development set, highlighting its adaptability and potential for clinical
translation. These results suggest that leveraging multimodal integration with
deep survival learning provides a promising pathway toward personalised risk
stratification in prostate and bladder cancer. Beyond the challenge setting,
our framework is broadly applicable to survival prediction tasks involving
heterogeneous biomedical data.

</details>


### [257] [Recurrent State Encoders for Efficient Neural Combinatorial Optimization](https://arxiv.org/abs/2509.05084)
*Tim Dernedde,Daniela Thyssens,Lars Schmidt-Thieme*

Main category: cs.LG

TL;DR: 提出了一种包含循环编码器的神经组合优化方法，可以在TSP、CVRP和OP问题上实现同等或更好的性能，并显著提高推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有的神经组合优化方法在步骤之间进行重复计算，效率低下。

Method: 训练一个循环编码器，该编码器基于当前状态和前一步的状态嵌入来计算状态嵌入，以提高计算效率。

Result: 与非循环编码器相比，循环编码器在TSP、CVRP和OP问题上达到了同等或更好的性能，并且层数减少了3倍，显著降低了延迟。

Conclusion: 循环编码器能够更有效地进行计算，并且在实际应用中具有相关性。

Abstract: The primary paradigm in Neural Combinatorial Optimization (NCO) are
construction methods, where a neural network is trained to sequentially add one
solution component at a time until a complete solution is constructed. We
observe that the typical changes to the state between two steps are small,
since usually only the node that gets added to the solution is removed from the
state. An efficient model should be able to reuse computation done in prior
steps. To that end, we propose to train a recurrent encoder that computes the
state embeddings not only based on the state but also the embeddings of the
step before. We show that the recurrent encoder can achieve equivalent or
better performance than a non-recurrent encoder even if it consists of
$3\times$ fewer layers, thus significantly improving on latency. We demonstrate
our findings on three different problems: the Traveling Salesman Problem (TSP),
the Capacitated Vehicle Routing Problem (CVRP), and the Orienteering Problem
(OP) and integrate the models into a large neighborhood search algorithm, to
showcase the practical relevance of our findings.

</details>


### [258] [HyPINO: Multi-Physics Neural Operators via HyperPINNs and the Method of Manufactured Solutions](https://arxiv.org/abs/2509.05117)
*Rafael Bischof,Michal Piovarči,Michael A. Kraus,Siddhartha Mishra,Bernd Bickel*

Main category: cs.LG

TL;DR: HyPINO是一个多物理场神经算子，无需特定任务的微调即可实现跨参数PDE的零样本泛化。


<details>
  <summary>Details</summary>
Motivation: 提出一种能够处理广泛参数化偏微分方程（PDE）的神经算子，并实现零样本泛化，无需进行特定任务的微调。

Method: HyPINO结合了基于Swin Transformer的超网络和混合监督（分析解标签数据和物理信息优化），将PDE参数映射到目标物理信息神经网络（PINN）。引入了迭代细化程序，通过比较生成PINN的物理量与目标PDE的差异来生成“delta”PINN，并累加它们的贡献以形成一个集成模型。

Result: HyPINO在七个基准问题上实现了强大的零样本准确性，优于U-Nets、Poseidon和PINO。迭代细化程序在六个基准上逐步降低了误差，在最佳情况下实现了超过100倍的平均L2损失增益。由HyPINO初始化的PINN在五个基准上收敛更快、最终误差更低，在其余两个基准上表现相当。

Conclusion: HyPINO作为一种可扩展的方法，有潜力为神经算子解决更复杂、非线性、高维的PDE问题奠定基础，显著提高准确性并降低计算成本。

Abstract: We present HyPINO, a multi-physics neural operator designed for zero-shot
generalization across a broad class of parametric PDEs without requiring
task-specific fine-tuning. Our approach combines a Swin Transformer-based
hypernetwork with mixed supervision: (i) labeled data from analytical solutions
generated via the Method of Manufactured Solutions (MMS), and (ii) unlabeled
samples optimized using physics-informed objectives. The model maps PDE
parametrizations to target Physics-Informed Neural Networks (PINNs) and can
handle linear elliptic, hyperbolic, and parabolic equations in two dimensions
with varying source terms, geometries, and mixed Dirichlet/Neumann boundary
conditions, including interior boundaries. HyPINO achieves strong zero-shot
accuracy on seven benchmark problems from PINN literature, outperforming
U-Nets, Poseidon, and Physics-Informed Neural Operators (PINO). Further, we
introduce an iterative refinement procedure that compares the physics of the
generated PINN to the requested PDE and uses the discrepancy to generate a
"delta" PINN. Summing their contributions and repeating this process forms an
ensemble whose combined solution progressively reduces the error on six
benchmarks and achieves over 100x gain in average $L_2$ loss in the best case,
while retaining forward-only inference. Additionally, we evaluate the
fine-tuning behavior of PINNs initialized by HyPINO and show that they converge
faster and to lower final error than both randomly initialized and
Reptile-meta-learned PINNs on five benchmarks, performing on par on the
remaining two. Our results highlight the potential of this scalable approach as
a foundation for extending neural operators toward solving increasingly
complex, nonlinear, and high-dimensional PDE problems with significantly
improved accuracy and reduced computational cost.

</details>


### [259] [Should We Always Train Models on Fine-Grained Classes?](https://arxiv.org/abs/2509.05130)
*Davide Pirovano,Federico Milanesio,Michele Caselle,Piero Fariselli,Matteo Osella*

Main category: cs.LG

TL;DR: 在许多分类任务中，使用更细粒度的标签进行训练可以提高模型性能，但这并非普遍适用，其有效性取决于数据本身的结构、大小以及模型的容量。


<details>
  <summary>Details</summary>
Motivation: 在许多现实世界的分类问题中，类别标签通常存在层级结构。虽然任务可能定义在某一层级，但利用更细粒度的标签进行训练已被证明可以提升模型性能。本研究旨在探究这一现象的普遍性及其背后的原因。

Method: 本研究通过使用真实和合成数据集，探究了利用细粒度标签进行训练对分类任务性能的影响，并分析了其有效性与数据几何结构、标签层级关系、数据集大小及模型容量等因素的关系。

Result: 研究表明，在细粒度标签上进行训练并不总是能提高分类准确率。其有效性在很大程度上取决于数据本身的几何结构与其标签层级结构的关系。此外，数据集大小和模型容量等因素也显著影响细粒度标签带来的性能提升。

Conclusion: 利用细粒度标签进行模型训练的策略并非对所有分类任务都有效。数据的内在几何结构和标签层级结构的匹配程度是决定该策略是否成功的关键因素。在实际应用中，需要综合考虑数据集大小和模型容量等因素来判断是否采用此策略。

Abstract: In classification problems, models must predict a class label based on the
input data features. However, class labels are organized hierarchically in many
datasets. While a classification task is often defined at a specific level of
this hierarchy, training can utilize a finer granularity of labels. Empirical
evidence suggests that such fine-grained training can enhance performance. In
this work, we investigate the generality of this observation and explore its
underlying causes using both real and synthetic datasets. We show that training
on fine-grained labels does not universally improve classification accuracy.
Instead, the effectiveness of this strategy depends critically on the geometric
structure of the data and its relations with the label hierarchy. Additionally,
factors such as dataset size and model capacity significantly influence whether
fine-grained labels provide a performance benefit.

</details>


### [260] [On the Learnability of Distribution Classes with Adaptive Adversaries](https://arxiv.org/abs/2509.05137)
*Tosca Lechner,Alex Bie,Gautam Kamath*

Main category: cs.LG

TL;DR: 我们研究了在存在自适应对手的情况下，分布类别的可学习性问题。自适应对手可以拦截学习者请求的样本，并在将样本传递给学习者之前对其进行操作。这与仅能修改样本底层分布但不能改变其独立同分布性质的遗忘对手不同。我们提出了一个关于自适应对手可学习性的通用概念，并考虑了对手的预算。我们证明了，相对于加性自适应对手的可学习性，严格强于相对于加性遗忘对手的可学习性。


<details>
  <summary>Details</summary>
Motivation: 本研究探讨在存在能够拦截和操纵样本的自适应对手的情况下，分布类别可学习性的问题。

Method: 提出了一种关于自适应对手可学习性的通用概念，并考虑了对手的预算。

Result: 证明了相对于加性自适应对手的可学习性，严格强于相对于加性遗忘对手的可学习性。

Conclusion: 自适应对手比遗忘对手对可学习性提出了更强的要求。

Abstract: We consider the question of learnability of distribution classes in the
presence of adaptive adversaries -- that is, adversaries capable of
intercepting the samples requested by a learner and applying manipulations with
full knowledge of the samples before passing it on to the learner. This stands
in contrast to oblivious adversaries, who can only modify the underlying
distribution the samples come from but not their i.i.d.\ nature. We formulate a
general notion of learnability with respect to adaptive adversaries, taking
into account the budget of the adversary. We show that learnability with
respect to additive adaptive adversaries is a strictly stronger condition than
learnability with respect to additive oblivious adversaries.

</details>


### [261] [Foundational Models and Federated Learning: Survey, Taxonomy, Challenges and Practical Insights](https://arxiv.org/abs/2509.05142)
*Cosmin-Andrei Hatfaludi,Alex Serban*

Main category: cs.LG

TL;DR: 本文对联邦学习和基础模型进行技术方法整合的文献进行综述，提出了新的分类体系，并对42种方法进行了技术比较和实践指南，尤其关注医疗健康领域。


<details>
  <summary>Details</summary>
Motivation: 随着复杂基础模型的广泛使用，整合私有数据和扩展训练资源的需求日益增长，联邦学习与基础模型的结合具有重要意义。

Method: 对超过4200篇文献进行筛选，最终选择250多篇进行详细审阅，识别并归纳了42种整合联邦学习和基础模型的技术方法，并围绕其生命周期构建了新的分类体系，对方法进行了复杂性、效率和可扩展性等方面的技术比较。

Result: 提出了一种新颖的、围绕生命周期阶段的分类体系，并对42种整合联邦学习和基础模型的技术方法进行了详细的技术比较，包括复杂性、效率和可扩展性。文章还提供了关于实施和发展这些方法的实践见解和指导方针，并以医疗健康领域作为案例研究。

Conclusion: 该文献综述总结了联邦学习与基础模型整合领域的现状，并为实际应用和发展这些技术提供了实践见解，尤其强调了其在医疗健康领域的巨大潜力。

Abstract: Federated learning has the potential to unlock siloed data and distributed
resources by enabling collaborative model training without sharing private
data. As more complex foundational models gain widespread use, the need to
expand training resources and integrate privately owned data grows as well. In
this article, we explore the intersection of federated learning and
foundational models, aiming to identify, categorize, and characterize technical
methods that integrate the two paradigms. As a unified survey is currently
unavailable, we present a literature survey structured around a novel taxonomy
that follows the development life-cycle stages, along with a technical
comparison of available methods. Additionally, we provide practical insights
and guidelines for implementing and evolving these methods, with a specific
focus on the healthcare domain as a case study, where the potential impact of
federated learning and foundational models is considered significant. Our
survey covers multiple intersecting topics, including but not limited to
federated learning, self-supervised learning, fine-tuning, distillation, and
transfer learning. Initially, we retrieved and reviewed a set of over 4,200
articles. This collection was narrowed to more than 250 thoroughly reviewed
articles through inclusion criteria, featuring 42 unique methods. The methods
were used to construct the taxonomy and enabled their comparison based on
complexity, efficiency, and scalability. We present these results as a
self-contained overview that not only summarizes the state of the field but
also provides insights into the practical aspects of adopting, evolving, and
integrating foundational models with federated learning.

</details>


### [262] [KVCompose: Efficient Structured KV Cache Compression with Composite Tokens](https://arxiv.org/abs/2509.05165)
*Dmitry Akulov,Mohamed Sana,Antonio De Domenico,Tareq Si Salem,Nicola Piovesan,Fadhel Ayed*

Main category: cs.LG

TL;DR: KV 缓存压缩框架，通过注意力指导的、层自适应的复合令牌，在不破坏现有推理引擎的张量结构的情况下，实现高效的长上下文 LLM 推理。


<details>
  <summary>Details</summary>
Motivation: LLM 的 KV 缓存大小随上下文长度和模型深度线性增长，成为长上下文推理的主要瓶颈。现有的 KV 缓存压缩方法存在效率不高、破坏张量布局或需要专用计算内核的问题。

Method: 提出一种基于注意力指导的、层自适应的复合令牌的 KV 缓存压缩框架。该方法通过聚合注意力分数来估计令牌重要性，独立选择特定于头的令牌，并将它们组合成复合令牌，同时保持现有推理引擎所需的均匀缓存结构。此外，全局分配机制会跨层自适应地调整保留预算，为包含信息量令牌的层分配更多容量。

Result: 该方法实现了显著的内存缩减，同时保持了准确性，并且始终优于现有的结构化和半结构化方法。该方法与标准的推理流程完全兼容。

Conclusion: 提出了一种简单而有效的 KV 缓存压缩方法，可用于高效的长上下文 LLM 部署，该方法内存占用低且能保持准确性，同时与现有推理框架兼容。

Abstract: Large language models (LLMs) rely on key-value (KV) caches for efficient
autoregressive decoding; however, cache size grows linearly with context length
and model depth, becoming a major bottleneck in long-context inference. Prior
KV cache compression methods either enforce rigid heuristics, disrupt tensor
layouts with per-attention-head variability, or require specialized compute
kernels.
  We propose a simple, yet effective, KV cache compression framework based on
attention-guided, layer-adaptive composite tokens. Our method aggregates
attention scores to estimate token importance, selects head-specific tokens
independently, and aligns them into composite tokens that respect the uniform
cache structure required by existing inference engines. A global allocation
mechanism further adapts retention budgets across layers, assigning more
capacity to layers with informative tokens. This approach achieves significant
memory reduction while preserving accuracy, consistently outperforming prior
structured and semi-structured methods. Crucially, our approach remains fully
compatible with standard inference pipelines, offering a practical and scalable
solution for efficient long-context LLM deployment.

</details>


### [263] [Accuracy-Constrained CNN Pruning for Efficient and Reliable EEG-Based Seizure Detection](https://arxiv.org/abs/2509.05190)
*Mounvik K,N Harshit*

Main category: cs.LG

TL;DR: 提出一种轻量级一维卷积神经网络（CNN）模型，并结合结构化剪枝和温和的提前停止策略，用于提高癫痫检测的效率和可靠性。


<details>
  <summary>Details</summary>
Motivation: 在实时检测或资源受限的环境中，深度学习模型（尤其是CNN）在生物医学信号处理（如基于EEG的癫痫检测）方面面临模型大小和计算需求的挑战。

Method: 研究提出了一种轻量级的一维CNN模型，并采用结构化剪枝技术（移除50%的卷积核）和温和的提前停止策略来处理过拟合。

Result: 剪枝后的模型在保持预测能力的同时，准确率达到92.87%，宏F1分数提高到0.8707，优于基线模型。

Conclusion: 结构化剪枝能够去除冗余、提高泛化能力，并与温和的提前停止结合，为提高癫痫检测的效率和可靠性提供了一种有前景的方法，特别适用于资源受限的场景。

Abstract: Deep learning models, especially convolutional neural networks (CNNs), have
shown considerable promise for biomedical signals such as EEG-based seizure
detection. However, these models come with challenges, primarily due to their
size and compute requirements in environments where real-time detection or
limited resources are available. In this study, we present a lightweight
one-dimensional CNN model with structured pruning to improve efficiency and
reliability. The model was trained with mild early stopping to address possible
overfitting, achieving an accuracy of 92.78% and a macro-F1 score of 0.8686.
Structured pruning of the baseline CNN involved removing 50% of the
convolutional kernels based on their importance to model predictions.
Surprisingly, after pruning the weights and memory by 50%, the new network was
still able to maintain predictive capabilities, while modestly increasing
precision to 92.87% and improving the macro-F1 score to 0.8707. Overall, we
present a convincing case that structured pruning removes redundancy, improves
generalization, and, in combination with mild early stopping, achieves a
promising way forward to improve seizure detection efficiency and reliability,
which is clear motivation for resource-limited settings.

</details>


### [264] [Shift Before You Learn: Enabling Low-Rank Representations in Reinforcement Learning](https://arxiv.org/abs/2509.05193)
*Bastien Dubail,Stefan Stojanovic,Alexandre Proutière*

Main category: cs.LG

TL;DR: 低秩结构在奖励无关和目标条件强化学习(RL)中是普遍存在的，但后继测度本身并非低秩。我们发现，移位后继测度（在跳过一些初始转换后捕获系统动态）自然会产生低秩结构。我们为从样本条目估计移位后继测度低秩近似提供了有限样本性能保证，该估计主要受对应矩阵的谱可恢复性的约束。我们通过新的II类Poincaré不等式来约束此参数，该不等式量化了有效低秩近似和估计所需的移位数。该分析表明，所需的移位数通常很小，并且与底层动力学系统的局部混合特性相关。实验证实，移位后继测度可以改善目标条件RL的性能。


<details>
  <summary>Details</summary>
Motivation: 本文旨在挑战强化学习(RL)中关于后继测度低秩性的普遍假设，并提出一种新的低秩结构表示方法。

Method: 提出移位后继测度，并通过有限样本性能保证来分析其低秩近似和估计误差，利用II类Poincaré不等式来约束谱可恢复性，并建立移位数与系统局部混合特性之间的联系。

Result: 分析表明，移位后继测度近似和估计误差主要受谱可恢复性的影响，所需的移位数通常较小，并且与系统局部混合特性相关。实验证明，移位后继测度在目标条件RL中能带来性能提升。

Conclusion: 移位后继测度提供了一种更有效的低秩结构表示方法，克服了传统方法的局限性，并在目标条件RL任务中展现出优越性能。

Abstract: Low-rank structure is a common implicit assumption in many modern
reinforcement learning (RL) algorithms. For instance, reward-free and
goal-conditioned RL methods often presume that the successor measure admits a
low-rank representation. In this work, we challenge this assumption by first
remarking that the successor measure itself is not low-rank. Instead, we
demonstrate that a low-rank structure naturally emerges in the shifted
successor measure, which captures the system dynamics after bypassing a few
initial transitions. We provide finite-sample performance guarantees for the
entry-wise estimation of a low-rank approximation of the shifted successor
measure from sampled entries. Our analysis reveals that both the approximation
and estimation errors are primarily governed by the so-called spectral
recoverability of the corresponding matrix. To bound this parameter, we derive
a new class of functional inequalities for Markov chains that we call Type II
Poincar\'e inequalities and from which we can quantify the amount of shift
needed for effective low-rank approximation and estimation. This analysis shows
in particular that the required shift depends on decay of the high-order
singular values of the shifted successor measure and is hence typically small
in practice. Additionally, we establish a connection between the necessary
shift and the local mixing properties of the underlying dynamical system, which
provides a natural way of selecting the shift. Finally, we validate our
theoretical findings with experiments, and demonstrate that shifting the
successor measure indeed leads to improved performance in goal-conditioned RL.

</details>


### [265] [RapidGNN: Energy and Communication-Efficient Distributed Training on Large-Scale Graph Neural Networks](https://arxiv.org/abs/2509.05207)
*Arefin Niam,Tevfik Kosar,M S Q Zulkar Nine*

Main category: cs.LG

TL;DR: RapidGNN是一个分布式图神经网络训练框架，通过确定性采样调度来优化缓存和预取，显著提高了训练吞吐量和能效，并实现了近乎线性的扩展性。


<details>
  <summary>Details</summary>
Motivation: 分布式训练大规模图神经网络面临挑战，尤其是在处理高连接性数据集时，通信开销仍然是一个问题，尽管采样方法可以减轻计算负担。

Method: 提出RapidGNN框架，采用确定性采样调度，优化远程特征的缓存构建和预取。

Result: 在基准图数据集上，RapidGNN的端到端训练吞吐量平均比基线方法提高了2.46倍至3.00倍，远程特征获取减少了9.70倍至15.39倍。此外，CPU和GPU的能效分别提高了44%和32%，并且在增加计算单元数量时实现了近乎线性的可扩展性。

Conclusion: RapidGNN通过其确定的采样调度，能够有效地处理大规模图数据集的分布式训练，在吞吐量、通信开销、可扩展性和能效方面均优于现有方法。

Abstract: Graph Neural Networks (GNNs) have become popular across a diverse set of
tasks in exploring structural relationships between entities. However, due to
the highly connected structure of the datasets, distributed training of GNNs on
large-scale graphs poses significant challenges. Traditional sampling-based
approaches mitigate the computational loads, yet the communication overhead
remains a challenge. This paper presents RapidGNN, a distributed GNN training
framework with deterministic sampling-based scheduling to enable efficient
cache construction and prefetching of remote features. Evaluation on benchmark
graph datasets demonstrates RapidGNN's effectiveness across different scales
and topologies. RapidGNN improves end-to-end training throughput by 2.46x to
3.00x on average over baseline methods across the benchmark datasets, while
cutting remote feature fetches by over 9.70x to 15.39x. RapidGNN further
demonstrates near-linear scalability with an increasing number of computing
units efficiently. Furthermore, it achieves increased energy efficiency over
the baseline methods for both CPU and GPU by 44% and 32%, respectively.

</details>


### [266] [Deep Learning-Enhanced for Amine Emission Monitoring and Performance Analysis in Industrial Carbon Capture Plants](https://arxiv.org/abs/2509.05241)
*Lokendra Poudel,David Tincher,Duy-Nhat Phan,Rahul Bhowmik*

Main category: cs.LG

TL;DR: 本研究提出使用深度学习模型来预测和监控碳捕获系统中的胺排放和关键性能参数，并取得了超过99%的预测准确率，同时还通过因果影响分析为优化操作提供了指导。


<details>
  <summary>Details</summary>
Motivation: 开发数据驱动的深度学习模型，用于预测和监控胺基燃烧后碳捕获系统中的胺排放和关键性能参数，以优化操作并减少环境影响。

Method: 采用四种深度学习架构（LSTM、堆叠LSTM、双向LSTM和卷积LSTM）来捕捉时间依赖性的过程行为，并对八个输入变量进行扰动以评估其影响。

Result: 所提出的模型在排放预测和系统性能评估方面取得了超过99%的预测准确率，能够有效跟踪稳定趋势和突然波动。因果影响分析表明，调整某些操作参数（如贫液温度和洗涤条件）可以显著减少胺排放并提高系统性能。

Conclusion: 机器学习不仅可以作为预测工具，还可以作为决策支持系统，用于在稳态和动态条件下优化碳捕获操作。所开发的机器学习框架通过实现实时监控、场景测试和操作优化，为减轻环境影响提供了一条实用的途径，是实现智能、数据驱动控制策略以提高碳捕获和封存技术效率、稳定性和可持续性的重要一步。

Abstract: We present data driven deep learning models for forecasting and monitoring
amine emissions and key performance parameters in amine-based post-combustion
carbon capture systems. Using operational data from the CESAR1 solvent campaign
at Technology Center Mongstad, four DL architectures such as Basic Long
Short-Term Memory (LSTM), Stacked LSTM, Bi-directional LSTM, and Convolutional
LSTM were developed to capture time-dependent process behavior. For emission
prediction, models were designed for 2-amino-2-methyl-1-propanol (AMP) and
Piperazine emissions measured via FTIR and IMR-MS methods. System performance
models target four critical parameters: CO$_2$ product flow, absorber outlet
temperature, depleted flue gas outlet temperature, and RFCC stripper bottom
temperature. These models achieved high predictive accuracy exceeding 99% and
effectively tracked both steady trends and abrupt fluctuations. Additionally,
we conducted causal impact analysis to evaluate how operational variables
influence emissions and system performance. Eight input variables were
systematically perturbed within $\pm$20% of nominal values to simulate
deviations and assess their impact. This analysis revealed that adjusting
specific operational parameters, such as lean solvent temperature and water
wash conditions, can significantly reduce amine emissions and enhance system
performance. This study highlights ML not only as a predictive tool but also as
a decision support system for optimizing carbon capture operations under steady
state and dynamic conditions. By enabling real time monitoring, scenario
testing, and operational optimization, the developed ML framework offers a
practical pathway for mitigating environmental impacts. This work represents a
step toward intelligent, data-driven control strategies that enhance the
efficiency, stability, and sustainability of carbon capture and storage
technologies.

</details>


### [267] [Greener Deep Reinforcement Learning: Analysis of Energy and Carbon Efficiency Across Atari Benchmarks](https://arxiv.org/abs/2509.05273)
*Jason Gardner,Ayan Dutta,Swapnoneel Roy,O. Patrick Kreidl,Ladislau Boloni*

Main category: cs.LG

TL;DR: 深度强化学习（DRL）的计算需求日益增长，引发了对大规模模型训练的环境和经济成本的担忧。本研究系统地评估了七种最先进的DRL算法（DQN、TRPO、A2C、ARS、PPO、RecurrentPPO和QR-DQN）在Stable Baselines中的能耗。在十款Atari 2600游戏中，每种算法训练一百万步，并实时测量功耗，以估算总能耗、二氧化碳当量排放量和基于美国平均电价的电费。结果显示，不同算法的能效和训练成本差异显著，一些算法在获得可比性能的同时，能耗可降低24%（ARS vs. DQN），二氧化碳排放量可减少近68%，货币成本可降低近68%（QR-DQN vs. RecurrentPPO）。研究分析了学习性能、训练时间、能耗和财务成本之间的权衡，强调了在不牺牲学习性能的情况下减轻环境和经济影响的算法选择。本研究为开发节能、低成本的DRL实践提供了可行的见解，并为未来算法设计和评估中纳入可持续性考量奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 深度强化学习（DRL）的计算需求日益增长，引发了对大规模模型训练的环境和经济成本的担忧。然而，关于DRL算法的能耗、温室气体排放和金钱成本的研究却很少。本研究旨在填补这一空白，系统地评估DRL算法的能效和成本。

Method: 本研究对七种最先进的DRL算法（DQN、TRPO、A2C、ARS、PPO、RecurrentPPO和QR-DQN）进行了系统性的基准测试。研究人员使用Stable Baselines实现了这些算法，并在十款Atari 2600游戏中对每种算法进行了为期一百万步的训练。在训练过程中，研究人员实时测量了功耗，并基于美国全国平均电价估算了总能耗、二氧化碳当量排放量和电费。

Result: 研究结果显示，不同DRL算法在能效和训练成本方面存在显著差异。例如，ARS算法在能耗方面比DQN算法低24%，而QR-DQN算法在二氧化碳排放量和金钱成本方面比RecurrentPPO算法低近68%。研究还分析了学习性能、训练时间、能耗和财务成本之间的权衡关系，并指出了在不牺牲学习性能的情况下，通过算法选择来降低环境和经济影响的可能性。

Conclusion: 本研究为DRL算法的能效和成本提供了一个全面的评估，并强调了在算法设计和选择中考虑环境和经济因素的重要性。研究结果为开发更节能、更具成本效益的DRL实践提供了可行的见解，并为未来的研究奠定了基础，以将可持续性纳入DRL算法的设计和评估过程中。

Abstract: The growing computational demands of deep reinforcement learning (DRL) have
raised concerns about the environmental and economic costs of training
large-scale models. While algorithmic efficiency in terms of learning
performance has been extensively studied, the energy requirements, greenhouse
gas emissions, and monetary costs of DRL algorithms remain largely unexplored.
In this work, we present a systematic benchmarking study of the energy
consumption of seven state-of-the-art DRL algorithms, namely DQN, TRPO, A2C,
ARS, PPO, RecurrentPPO, and QR-DQN, implemented using Stable Baselines. Each
algorithm was trained for one million steps each on ten Atari 2600 games, and
power consumption was measured in real-time to estimate total energy usage,
CO2-Equivalent emissions, and electricity cost based on the U.S. national
average electricity price. Our results reveal substantial variation in energy
efficiency and training cost across algorithms, with some achieving comparable
performance while consuming up to 24% less energy (ARS vs. DQN), emitting
nearly 68% less CO2, and incurring almost 68% lower monetary cost (QR-DQN vs.
RecurrentPPO) than less efficient counterparts. We further analyze the
trade-offs between learning performance, training time, energy use, and
financial cost, highlighting cases where algorithmic choices can mitigate
environmental and economic impact without sacrificing learning performance.
This study provides actionable insights for developing energy-aware and
cost-efficient DRL practices and establishes a foundation for incorporating
sustainability considerations into future algorithmic design and evaluation.

</details>


### [268] [SpikingBrain Technical Report: Spiking Brain-inspired Large Models](https://arxiv.org/abs/2509.05276)
*Yuqi Pan,Yupeng Feng,Jinghao Zhuang,Siyu Ding,Zehao Liu,Bohan Sun,Yuhong Chou,Han Xu,Xuerui Qiu,Anlin Deng,Anjie Hu,Peng Zhou,Man Yao,Jibin Wu,Jian Yang,Guoliang Sun,Bo Xu,Guoqi Li*

Main category: cs.LG

TL;DR: SpikingBrain是一种受大脑启发的模型，它利用线性注意力和自适应脉冲神经元来解决Transformer模型的效率瓶颈，在非NVIDIA硬件上实现了高效的长上下文训练和推理，并取得了与Transformer相当的性能，同时显著提高了效率。 


<details>
  <summary>Details</summary>
Motivation: 当前的Transformer大型语言模型在训练时计算量与序列长度呈二次方增长，推理时内存呈线性增长，这限制了它们处理长上下文的能力。此外，在非NVIDIA平台上稳定高效地训练大型模型也面临挑战。SpikingBrain旨在通过借鉴大脑的计算机制来克服这些限制。

Method: SpikingBrain采用了以下关键技术：1. 模型架构：结合了线性/混合线性注意力机制和自适应脉冲神经元。2. 算法优化：设计了高效的、基于转换的训练流程和专门的脉冲编码框架。3. 系统工程：针对MetaX GPU集群定制了训练框架、算子库和并行策略。

Result: SpikingBrain系列模型（包括SpikingBrain-7B和SpikingBrain-76B）在非NVIDIA平台上成功进行了大规模训练。与开源Transformer基线模型相比，SpikingBrain在仅使用约150B tokens进行持续预训练的情况下，取得了相当的性能。其长序列训练效率得到显著提升，推理时实现了（部分）恒定内存和事件驱动的脉冲行为。具体而言，SpikingBrain-7B在处理4M token序列时，首个Token生成时间（Time to First Token）加速超过100倍。模型在数百个MetaX C550 GPU上稳定训练数周，7B模型达到了23.4%的模型浮点运算利用率。提出的脉冲方案实现了69.15%的稀疏度，支持低功耗运行。

Conclusion: 这项工作表明，受大脑启发的机制在设计下一代高效、可扩展的大型模型方面具有巨大潜力，能够有效解决当前Transformer模型的效率瓶颈，并在多样化的硬件平台上实现高性能。

Abstract: Mainstream Transformer-based large language models face major efficiency
bottlenecks: training computation scales quadratically with sequence length,
and inference memory grows linearly, limiting long-context processing. Building
large models on non-NVIDIA platforms also poses challenges for stable and
efficient training. To address this, we introduce SpikingBrain, a family of
brain-inspired models designed for efficient long-context training and
inference. SpikingBrain leverages the MetaX GPU cluster and focuses on three
aspects: (1) Model Architecture: linear and hybrid-linear attention
architectures with adaptive spiking neurons; (2) Algorithmic Optimizations: an
efficient, conversion-based training pipeline and a dedicated spike coding
framework; (3) System Engineering: customized training frameworks, operator
libraries, and parallelism strategies tailored to MetaX hardware.
  Using these techniques, we develop two models: SpikingBrain-7B, a linear LLM,
and SpikingBrain-76B, a hybrid-linear MoE LLM. These models demonstrate the
feasibility of large-scale LLM development on non-NVIDIA platforms.
SpikingBrain achieves performance comparable to open-source Transformer
baselines while using only about 150B tokens for continual pre-training. Our
models significantly improve long-sequence training efficiency and deliver
inference with (partially) constant memory and event-driven spiking behavior.
For example, SpikingBrain-7B attains over 100x speedup in Time to First Token
for 4M-token sequences. Training remains stable for weeks on hundreds of MetaX
C550 GPUs, with the 7B model reaching a Model FLOPs Utilization of 23.4
percent. The proposed spiking scheme achieves 69.15 percent sparsity, enabling
low-power operation. Overall, this work demonstrates the potential of
brain-inspired mechanisms to drive the next generation of efficient and
scalable large model design.

</details>


### [269] [Dual-Branch Convolutional Framework for Spatial and Frequency-Based Image Forgery Detection](https://arxiv.org/abs/2509.05281)
*Naman Tyagi*

Main category: cs.LG

TL;DR: 该研究提出了一种结合空间域和频域特征的双分支卷积神经网络，用于检测图像伪造。


<details>
  <summary>Details</summary>
Motivation: 随着深度伪造和数字图像伪造的快速增加，确保图像真实性变得越来越具挑战性。

Method: 提出一个双分支卷积神经网络，分别处理从空间域和频域提取的特征。最后，将两个分支的特征融合并通过暹罗网络进行比较，生成用于分类的64维嵌入。

Result: 在CASIA 2.0数据集上，该方法实现了77.9%的准确率，优于传统统计方法。

Conclusion: 该方法在计算复杂度和检测可靠性之间取得了良好的平衡，适用于实际部署，为数字图像的取证审查提供了一种强大的方法，并推动了视觉取证技术的发展。

Abstract: With a very rapid increase in deepfakes and digital image forgeries, ensuring
the authenticity of images is becoming increasingly challenging. This report
introduces a forgery detection framework that combines spatial and
frequency-based features for detecting forgeries. We propose a dual branch
convolution neural network that operates on features extracted from spatial and
frequency domains. Features from both branches are fused and compared within a
Siamese network, yielding 64 dimensional embeddings for classification. When
benchmarked on CASIA 2.0 dataset, our method achieves an accuracy of 77.9%,
outperforming traditional statistical methods. Despite its relatively weaker
performance compared to larger, more complex forgery detection pipelines, our
approach balances computational complexity and detection reliability, making it
ready for practical deployment. It provides a strong methodology for forensic
scrutiny of digital images. In a broader sense, it advances the state of the
art in visual forensics, addressing an urgent requirement in media
verification, law enforcement and digital content reliability.

</details>


### [270] [Learning to accelerate distributed ADMM using graph neural networks](https://arxiv.org/abs/2509.05288)
*Henri Doerks,Paul Häusner,Daniel Hernández Escobar,Jens Sjölund*

Main category: cs.LG

TL;DR: 本文提出了一种利用图神经网络（GNN）学习分布式交替方向乘子法（ADMM）自适应步长和通信权重的方法，以加速收敛并提高解的质量。


<details>
  <summary>Details</summary>
Motivation: ADMM 在分布式优化中很受欢迎，但存在收敛慢和对超参数敏感的问题。

Method: 将 ADMM 迭代表示为 GNN 的消息传递，并训练 GNN 来预测最优的步长和通信权重，通过展开 ADMM 并端到端训练网络来最小化最终迭代误差。

Result: 数值实验表明，所提出的学习型 ADMM 变体在收敛速度和解的质量方面优于标准 ADMM。

Conclusion: 通过将 ADMM 与 GNN 结合，可以学习自适应超参数，从而克服标准 ADMM 的缺点，提高分布式优化的性能。

Abstract: Distributed optimization is fundamental in large-scale machine learning and
control applications. Among existing methods, the Alternating Direction Method
of Multipliers (ADMM) has gained popularity due to its strong convergence
guarantees and suitability for decentralized computation. However, ADMM often
suffers from slow convergence and sensitivity to hyperparameter choices. In
this work, we show that distributed ADMM iterations can be naturally
represented within the message-passing framework of graph neural networks
(GNNs). Building on this connection, we propose to learn adaptive step sizes
and communication weights by a graph neural network that predicts the
hyperparameters based on the iterates. By unrolling ADMM for a fixed number of
iterations, we train the network parameters end-to-end to minimize the final
iterates error for a given problem class, while preserving the algorithm's
convergence properties. Numerical experiments demonstrate that our learned
variant consistently improves convergence speed and solution quality compared
to standard ADMM. The code is available at
https://github.com/paulhausner/learning-distributed-admm.

</details>


### [271] [Deep Reinforcement Learning for Ranking Utility Tuning in the Ad Recommender System at Pinterest](https://arxiv.org/abs/2509.05292)
*Xiao Yang,Mehdi Ben Ayed,Longyu Zhao,Fan Zhou,Yuchen Shen,Abe Engle,Jinfeng Zhuang,Ling Leng,Jiajing Xu,Charles Rosenberg,Prathibha Deshikachar*

Main category: cs.LG

TL;DR: 提出了一种名为DRL-PUT的深度强化学习框架，用于优化广告推荐系统中的个性化效用调优，通过在线学习和最大化预定义奖励来提高点击率和长点击率。


<details>
  <summary>Details</summary>
Motivation: 传统的广告推荐系统效用函数手动调优方法存在参数组合繁多、缺乏个性化和季节性适应性等问题，导致结果次优。

Method: 将问题表述为强化学习任务，利用在线服务日志直接学习最优策略模型，避免了高方差和不平衡的即时奖励估计的价值函数。

Result: 在Pinterest广告推荐系统中进行在线A/B实验，与手动调优基线相比，DRL-PUT将点击率提高了9.7%，长点击率提高了7.7%。

Conclusion: DRL-PUT框架能够有效解决广告推荐系统中的多目标优化问题，并显著提升了关键业务指标。

Abstract: The ranking utility function in an ad recommender system, which linearly
combines predictions of various business goals, plays a central role in
balancing values across the platform, advertisers, and users. Traditional
manual tuning, while offering simplicity and interpretability, often yields
suboptimal results due to its unprincipled tuning objectives, the vast amount
of parameter combinations, and its lack of personalization and adaptability to
seasonality. In this work, we propose a general Deep Reinforcement Learning
framework for Personalized Utility Tuning (DRL-PUT) to address the challenges
of multi-objective optimization within ad recommender systems. Our key
contributions include: 1) Formulating the problem as a reinforcement learning
task: given the state of an ad request, we predict the optimal hyperparameters
to maximize a pre-defined reward. 2) Developing an approach to directly learn
an optimal policy model using online serving logs, avoiding the need to
estimate a value function, which is inherently challenging due to the high
variance and unbalanced distribution of immediate rewards. We evaluated DRL-PUT
through an online A/B experiment in Pinterest's ad recommender system. Compared
to the baseline manual utility tuning approach, DRL-PUT improved the
click-through rate by 9.7% and the long click-through rate by 7.7% on the
treated segment. We conducted a detailed ablation study on the impact of
different reward definitions and analyzed the personalization aspect of the
learned policy model.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [272] [Non-equilibrium Ion Transport in a Hybrid Battery Material](https://arxiv.org/abs/2509.04587)
*J. Cattermull,B. Jagger,S. J. Cassidy,S. Dhir,P. K. Allan,M. Pasta,A. L. Goodwin*

Main category: cond-mat.mtrl-sci

TL;DR: K2Mn[Fe(CN)6] 是一种混合材料，其电荷存储机制受非平衡相变控制，这为后锂电池技术提供了新的优化方向。


<details>
  <summary>Details</summary>
Motivation: Prussian blue analogues (PBAs) 是一类有潜力的后锂电池技术材料，但其结构灵活性导致的异常功能响应需要进一步研究。

Method: 利用原位方法研究 K2Mn[Fe(CN)6] 的电荷存储机制，重点关注其低弹性模量和协同畸变如何影响传输动力学和集体、亚稳态路径。

Result: 非平衡相变过程控制 K2Mn[Fe(CN)6] 的电荷存储机制，其框架柔性限制了传输动力学并促进了集体、亚稳态路径。

Conclusion: PBAs 阴极材料的优化以及混合材料中非平衡机制在质量传输中的作用值得进一步关注。

Abstract: Hybrid materials, which combine inorganic and molecular components, often
exhibit structural flexibility that enables unusual functional responses. Among
them, Prussian blue analogues (PBAs) are a promising class for post-lithium
battery technologies. Here, we show that non-equilibrium transformation
processes govern the charge-storage mechanism of a PBA electrode,
K2Mn[Fe(CN)6]. Ostensibly, this behavior mirrors that observed in high-rate
cycling of conventional cathodes such as LiFePO4, yet arises here for
fundamentally different reasons -- namely, low elastic moduli and cooperative
distortions inherent to the hybrid framework. Using \emph{operando} methods, we
show that framework flexibility limits transport kinetics and promotes
collective, metastable pathways. Our results highlight new directions for PBA
cathode optimisation, but also suggest a broader relevance of non-equilibrium
mechanisms for mass transport in hybrid materials beyond PBAs alone.

</details>


### [273] [Tuning Nonradiative Recombination via Cation Substitution in Inorganic Antiperovskite Nitrides](https://arxiv.org/abs/2509.04611)
*Sanchi Monga,Saswata Bhattacharya*

Main category: cond-mat.mtrl-sci

TL;DR: X位阳离子取代影响无辐射复合，Sr3NSb表现出最长载流子寿命


<details>
  <summary>Details</summary>
Motivation: 研究无机反钙钛矿氮化物在光伏应用中的无辐射复合动力学，以及X位阳离子取代的影响。

Method: 通过X位阳离子取代（Ca, Sr, Ba）来研究X3NSb（X = Ca, Sr, Ba）的无辐射电子-空穴复合动力学，并分析带隙、非绝热耦合、晶格畸变、带边涨落和退相干时间等因素的影响。

Result: Ca和Sr基化合物为立方相，Ba基化合物为六方相。Sr取代使带隙变窄，抑制涨落，非绝热耦合减少约54%，载流子寿命延长2.5倍。Ba取代则增加晶格畸变，拓宽带隙，增强非绝热耦合，缩短退相干时间。Sr3NSb具有最长的载流子寿命。

Conclusion: 阳离子化学和晶体对称性的相互作用影响载流子动力学，Sr3NSb表现出最长的载流子寿命，为高性能反钙钛矿光电材料提供了调控思路。

Abstract: Inorganic antiperovskite nitrides have recently emerged as promising
materials for photovoltaic applications, yet their nonradiative recombination
dynamics remain largely unexplored. Here, we examine the influence of X-site
cation substitution on the nonradiative electron-hole recombination in
$\mathrm{X_{3}NSb}$ ($X = \mathrm{Ca}, \mathrm{Sr}, \mathrm{Ba}$). Ca- and
Sr-based compounds adopt a cubic phase, whereas Ba stabilizes in a hexagonal
structure, introducing pronounced symmetry-driven effects. Substituting Ca with
Sr narrows the band gap, suppresses octahedral and band-edge fluctuations,
reduces nonadiabatic (NA) coupling by $\sim 54\%$, and extends carrier
lifetimes by a factor of $2.5$. In contrast, Ba substitution increases lattice
distortion, widens the band gap, and enhances NA coupling beyond that of
$\mathrm{Sr_{3}NSb}$, thereby accelerating recombination through stronger
lattice fluctuations. The resulting band gap fluctuations in
$\mathrm{Ba_{3}NSb}$ also shorten decoherence times, following the trend
$\mathrm{Ba_{3}NSb} < \mathrm{Ca_{3}NSb} < \mathrm{Sr_{3}NSb}$. Our results
demonstrate how the interplay between band gap, NA coupling, and decoherence
time governs recombination lifetimes, with $\mathrm{Sr_{3}NSb}$ exhibiting the
longest lifetime. These findings highlight the coupled influence of cation
chemistry and crystal symmetry in tailoring carrier dynamics for
high-performance antiperovskite-based optoelectronics materials.

</details>


### [274] [Mo Atom Rearrangement Drives Layer-Dependent Reactivity in Two-Dimensional MoS2](https://arxiv.org/abs/2509.04648)
*Zifan Wang,Jiaxuan Wen,Tina Mihm,Shaopeng Feng,Kelvin Huang,Jing Tang,Tianshu Li,Liangbo Liang,Sahar Sharifzadeh,Keji Lai,Xi Ling*

Main category: cond-mat.mtrl-sci

TL;DR: 二维材料（如MoS2）的化学反应活性与其层数相关，单层MoS2的反应活性较低，这是由于原子重排和形成更稳定MoN相的能量成本所致。


<details>
  <summary>Details</summary>
Motivation: 研究反应过程中二维材料结构转变对化学活性的影响。

Method: 通过氮化原子取代反应，研究不同层数的MoS2的化学反应活性，并利用透射电子显微镜和局部电导率映射进行表征。

Result: MoS2的化学活性随层数的减少而降低，单层MoS2的反应活性显著低于多层MoS2。反应产物为MoN纳米网络，且连续性随层数增加而提高。

Conclusion: 二维材料的晶格重排对其化学活性有重要影响，单层MoS2的低反应活性归因于形成稳定MoN相所需的Mo原子扩散和迁移的高能量成本。

Abstract: Two-dimensional (2D) materials offer a valuable platform for manipulating and
studying chemical reactions at atomic level, owing to the ease of controlling
their microscopic structure at the nanometer scale. While extensive research
has been conducted on the structure-dependent chemical activity of 2D
materials, the influence of structural transformation during the reaction
remains largely unexplored. In this work, we report the layer-dependent
chemical reactivity of MoS2 during a nitridation atomic substitution reaction
and attribute it to the rearrangement of Mo atoms. Our results show that the
chemical reactivity of MoS2 decreases as the number of layers is reduced in the
few-layer regime. In particular, monolayer MoS2 exhibits significantly lower
reactivity compared to its few-layer and multilayer counterparts.
Atomic-resolution transmission electron microscope (TEM) reveals that MoN
nanonetworks form as reaction products from monolayer and bilayer MoS2, with
the continuity of the MoN crystals increasing with layer number, consistent
with the local conductivity mapping data. The layer-dependent reactivity is
attributed to the relative stability of the hypothetically formed MoN phase
which retain the number of Mo atomic layers present in the precursor.
Specifically, the low chemical reactivity of monolayer MoS2 is attributed to
the high energy cost associated with Mo atom diffusion and migration necessary
to form multi-layer Mo lattices in the thermodynamically stable MoN phase. This
study underscores the critical role of lattice rearrangement in governing
chemical reactivity and highlights the potential of 2D materials as versatile
platforms for advancing the understanding of materials chemistry at atomic
scale.

</details>


### [275] [A generalized and adaptable tensor-contraction-based cluster expansion formalism for multicomponent solids](https://arxiv.org/abs/2509.04686)
*Jacob Jeffries,Bochuan Sun,Enrique Martinez*

Main category: cond-mat.mtrl-sci

TL;DR:  TCE通过将相关函数映射到混合张量收缩来克服CE在处理低对称性晶格方面的局限性，从而提高计算效率和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 标准的CE技术难以扩展到奇异和/或低对称性晶格，并且需要针对每种晶格结构枚举特定的簇类型。

Method:  TCE将相关函数映射到混合张量收缩，无需迭代簇类型，并且易于并行化。

Result:  TCE能够直接推导出局域相互作用能，并用于TaW和CoNiCrFeMn系统，计算结果与真实数据吻合良好。

Conclusion:  TCE是一种比标准CE更有效、更具可扩展性的方法，适用于模拟多组分合金的各种性质。

Abstract: Density functional theory (DFT)-based simulations of materials have
first-principles accuracy, but are very computationally expensive. For
simulating various properties of multi-component alloys, the cluster expansion
(CE) technique has served as the standard workaround to improve computational
efficiency. However, the standard CE technique is difficult to extend to exotic
and/or low-symmetry lattices, often implemented via iteration over particular
cluster types, which must be enumerated per lattice structure. In this work, we
introduce the tensor cluster expansion (TCE), implemented in the open-source
code tce-lib, which maps correlation functions to mixed tensor contractions,
eliminating the need to iterate over cluster types and additionally making the
calculation of correlation functions well-suited for massively parallel
architectures like GPUs. We show that local interaction energies are an
immediate consequence of the TCE formalism, yielding nearly $\mathcal{O}(1)$
energy difference calculations. We then use this formalism to fit CE models for
the TaW and CoNiCrFeMn systems, and use these models to respectively compute
the enthalpy of mixing curve and Cowley short-range order parameters, showing
excellent agreement with ground truth data.

</details>


### [276] [A Fully Discrete Element Approach for Modeling Vacuum Packed Particle Dampers](https://arxiv.org/abs/2509.04697)
*Pawel Chodkiewicz,Robert Zalewski,Jakub Lengiewicz*

Main category: cond-mat.mtrl-sci

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In this work, we investigate Vacuum-Packed Particle (VPP) dampers --
granular-core dampers offering tunable damping performance -- as a more
sustainable alternative to conventional systems such as magnetorheological
fluid dampers. A comprehensive computational model of the entire VPP damper
system is developed using the Discrete Element Method (DEM). A novel
discrete-element model of the flexible foil, responsible for consistently
transmitting the external pressure resulting from vacuum application, is
introduced and implemented by extending the open-source Yade DEM framework. A
prototype VPP damper is also designed and experimentally tested, enabling both
model calibration and validation of the simulation results. The calibrated DEM
model is subsequently employed in a parametric study to assess the influence of
material, geometrical, and process parameters on damper performance. All code,
along with the associated experimental and simulation datasets, is made
available in an open-access repository.

</details>


### [277] [Surface reconstruction and orthogonal decoupling in SrAl4 and EuAl4](https://arxiv.org/abs/2509.04742)
*Tongrui Li,Leiyuan Chen,Jian Yuan,Zhengtai Liu,Yichen Yang,Zhicheng Jiang,Jianyang Ding,Jiayu Liu,Jishan Liu,Zhe Sun,Yanfeng Guo,Tong Zhang,Dawei Shen*

Main category: cond-mat.mtrl-sci

TL;DR: 表面引起的对称性破缺在量子材料中可以稳定外来电子相，但由于畴平均效应，其动量空间的表现仍然难以捉摸。本研究利用角度分辨光电子能谱（ARPES）和扫描隧道显微镜（STM）研究了SrAl4和EuAl4的电子结构，这两种层状四方金属间化合物表现出特征明确的不commensurate电荷密度波（CDW）转变。在CDW转变温度以下，我们发现了线性色散的电子态和显著的单向复制带，它们垂直于体CDW波矢量，证明了平面内C4对称性破缺电子序的出现，这并非由体不commensurate CDW决定。STM测量进一步揭示了1×2的表面重构，具有准一维调制和半晶胞台阶，这源于有序的50% Sr/Eu空位，在热循环中不可逆地消失，表明表面和体序是解耦的。这些发现确立了SrAl4和EuAl4作为探索量子材料中表面限制的向列性和新兴低维相的理想平台。


<details>
  <summary>Details</summary>
Motivation: 探索表面引起的对称性破缺如何影响量子材料中的电子相，特别是在动量空间中的表现。

Method: 利用角度分辨光电子能谱（ARPES）和扫描隧道显微镜（STM）研究SrAl4和EuAl4的电子结构。

Result: 在CDW转变温度以下，发现了线性色散的电子态和单向复制带，证明了平面内C4对称性破缺电子序的出现。STM测量揭示了1×2的表面重构，源于Sr/Eu空位，且表面和体序是解耦的。

Conclusion: SrAl4和EuAl4是探索量子材料中表面限制的向列性和新兴低维相的理想平台。

Abstract: Surface-induced symmetry breaking in quantum materials can stabilize exotic
electronic phases distinct from those in the bulk, yet its momentum-space
manifestations remain elusive due to domain-averaging effects. Here, using
angle-resolved photoemission spectroscopy (ARPES) and scanning tunneling
microscopy (STM), we present a microscopic investigation of the electronic
structures of SrAl4 and EuAl4, layered tetragonal intermetallic compounds that
exhibit well-characterized incommensurate charge-density-wave (CDW)
transitions. Below the CDW transition temperatures, we uncover linearly
dispersing electronic states and pronounced unidirectional replica bands
orthogonal to the bulk CDW wave vector, evidencing the emergence of an in-plane
C4 symmetry-breaking electronic order that is not dictated by the bulk
incommensurate CDW. STM measurements further reveal a 1 times 2 surface
reconstruction with quasi-one-dimensional modulations and half-unit-cell steps,
traced to ordered 50 percent Sr/Eu vacancies, which vanish irreversibly upon
thermal cycling, indicating decoupled surface and bulk orders. These findings
establish SrAl4 and EuAl4 as model platforms for exploring surface-confined
nematicity and emergent low-dimensional phases in quantum materials.

</details>


### [278] [Active Learning of A Crystal Plasticity Flow Rule From Discrete Dislocation Dynamics Simulations](https://arxiv.org/abs/2509.04788)
*Nicholas Huebner Julian,Giacomo Po,Enrique Martinez,Nithin Mathew,Danny Perez*

Main category: cond-mat.mtrl-sci

TL;DR: 通过贝叶斯优化结合晶体塑性模型和离散位错动力学模拟，实现了材料变形模型的自动化校准和数据集的有效生成。


<details>
  <summary>Details</summary>
Motivation: 现有连续介质材料变形模型（如晶体塑性模型）的准确性可通过纳入较低尺度（介观尺度）模型的信息来显著提高，但信息提取过程复杂且耗时。本研究旨在开发一种基于较低尺度信息的连续介质模型校准的原则性方法。

Method: 将晶体塑性流动法则表示为高斯过程模型，并利用贝叶斯优化（一种不确定性引导的参数空间探索方法）进行校准。开发了一个半自动化的贝叶斯优化循环，该循环实例化离散位错动力学模拟，并自动选择初始条件来优化晶体塑性流动法则模型的不确定性。

Result: 该计算流程能够高效地生成数据集和相应的模型，其误差、不确定性和物理特征敏感性通过与一个独立但规模大四倍的数据集进行比较得到了验证。

Conclusion: 本研究提出的方法是一种有价值且高效的主动学习实现，易于迁移到类似的材料系统，能够显著减少开发时间并提高模型预测精度。

Abstract: Continuum-scale material deformation models, such as crystal plasticity, can
significantly enhance their predictive accuracy by incorporating input from
lower-scale (i.e., mesoscale) models. The procedure to generate and extract the
relevant information is however typically complex and ad hoc, involving
decision and intervention by domain experts, leading to long development times.
In this study, we develop a principled approach for calibration of
continuum-scale models using lower scale information by representing a crystal
plasticity flow rule as a Gaussian process model. This representation allows
for efficient parameter space exploration, guided by the uncertainty embedded
in the model through a process known as Bayesian optimization. We demonstrate a
semi-autonomous Bayesian optimization loop which instantiates discrete
dislocation dynamics simulations whose initial conditions are automatically
chosen to optimize the uncertainty of a model crystal plasticity flow rule. Our
self-guided computational pipeline efficiently generated a dataset and
corresponding model whose error, uncertainty, and physical feature
sensitivities were validated with comparison to an independent dataset four
times larger, demonstrating a valuable and efficient active learning
implementation readily transferable to similar material systems.

</details>


### [279] [Enhancement of spin-wave nonreciprocity and group velocity in a low-wavenumber regime](https://arxiv.org/abs/2509.04806)
*Shion Yoshimura,Shugo Yoshii,Ryo Ohshima,Masashi Shiraishi*

Main category: cond-mat.mtrl-sci

TL;DR: 铁磁（FM）双层结构在低波数下表现出显著的频率非互易性，其增强与双层厚度成正比，并且与源自Damon-Eshbach（DE）模式的高群速度有关。


<details>
  <summary>Details</summary>
Motivation: 探究铁磁（FM）双层结构中低波数（k < 5 rad/um）自旋波动力学行为，并揭示其非互易性与双层厚度的关系。

Method: 使用协波导（CPWs）研究自旋波在铁磁（FM）双层结构中的传播，并分析不同双层厚度对自旋波非互易性的影响。

Result: 结果表明，增加双层厚度可以增强低波数下的非互易性，这与源自Damon-Eshbach（DE）模式的高群速度相关。

Conclusion: 通过增加双层厚度可以增强低波数下的自旋波非互易性，为高速、低损耗的自旋波器件设计提供了原理性指导。

Abstract: Nonreciprocity of spin waves is essential for components such as magnetic
isolators and circulators used in spin-wave-based computing. A ferromagnetic
(FM) bilayer exhibits significant frequency nonreciprocity and has attracted
attention in recent years. Prior research on bilayers has predominantly focused
on the high-wavenumber regime, where spin waves display significant
nonreciprocity and are accessible through Brillouin light scattering (BLS).
However, the dynamics at low wavenumbers (k < 5 rad/um), which enable rapid
magnon propagation, have yet to be thoroughly investigated. We investigate
spin-wave propagation in the bilayer using coplanar waveguides (CPWs) and
demonstrate that increasing the bilayer thickness enhances nonreciprocity even
at low wavenumbers, which leads to the high group velocity originating from the
Damon-Eshbach (DE) mode. These findings establish design principles for
high-speed, low-loss spin-wave-based information processing.

</details>


### [280] [Dislocation interaction with a tilt low angle grain boundary in bi-crystal SrTiO3](https://arxiv.org/abs/2509.04893)
*Kuan Ding,Atsutomo Nakamura,Patrick Cordier,Xufei Fang*

Main category: cond-mat.mtrl-sci

TL;DR: 在多晶陶瓷中实现位错工程对于拓宽陶瓷应用至关重要，但晶界会阻碍位错滑移，导致室温下易产生裂纹。本研究以4°倾斜晶界的SrTiO3双晶为模型体系，通过室温压痕实验并结合显微分析，观察并揭示了位错在低角度倾斜晶界处的堆积、储存和穿 G_B 过程，为理解室温下宏观尺度的位错-晶界相互作用提供了新见解，并为抑制裂纹的产生提供了策略。


<details>
  <summary>Details</summary>
Motivation: 为了实现陶瓷位错工程化，需要理解位错与晶界的相互作用机制，尤其是在室温下，因为晶界通常是位错滑移的障碍，容易导致裂纹。

Method: 采用4°倾斜晶界的SrTiO3双晶作为模型体系，利用室温布氏压痕产生宏观塑性区，并通过位错蚀坑成像和透射电子显微镜分析观察位错-晶界相互作用。

Result: 观察到位错在低角度倾斜晶界处的堆积、储存和穿 G_B 现象。

Conclusion: 实验揭示了室温下宏观尺度的位错-晶界相互作用的新机制，为理解和调控陶瓷的变形行为提供了基础。

Abstract: For potentially wider applications of ceramics with dislocation-tuned
mechanical and functional properties, it is pertinent to achieve dislocation
engineering in polycrystalline ceramics. However, grain boundaries (GBs) in
general are effective barriers for dislocation glide and often result in crack
formation when plastic deformation in ceramics is attempted at room
temperature. To develop strategies for crack suppression, it is critical to
understand the fundamental processes for dislocation-GB interaction. For this
purpose, we adopt here a model system of bi-crystal SrTiO3 with a 4{\deg} tilt
GB, which consists of an array of edge dislocations. Room-temperature Brinell
indentation was used to generate a plastic zone at the mesoscale without crack
formation, allowing for direct assessment of GB-dislocation interaction in bulk
samples. Together with dislocation etch pits imaging and transmission electron
microscopy analysis, we observe dislocation pileup, storage, and transmission
across the low-angle tilt GB. Our experimental observations reveal new insight
into dislocation-GB interaction at room temperature at the mesoscale.

</details>


### [281] [Optical spectra of small silver clusters with the Bethe-Salpeter formalism: a Reassessment](https://arxiv.org/abs/2509.05008)
*Xavier Blase,Ivan Duchemin*

Main category: cond-mat.mtrl-sci

TL;DR: Ag_n (n=2,4,6,8) 团簇的光吸收光谱在使用 GW 准粒子能量构建的哈密顿量的 Bethe-Salpeter 方程形式下进行了研究。


<details>
  <summary>Details</summary>
Motivation: 研究小银团簇的光吸收光谱，并评估不同 GW 和 TD-DFT 方法的准确性。

Method: 使用 Bethe-Salpeter 方程 (BSE) 形式，结合 GW 准粒子能量来计算 Ag_n (n=2,4,6,8) 团簇的光吸收光谱。研究比较了非自洽 G0W0 计算、特征值或准粒子自洽 GW 计算以及使用范围分离杂合泛函的 TD-DFT 谱。

Result: 非自洽 G0W0 计算得到的 BSE 吸收光谱与实验和 TD-DFT 结果相比非常不准确。然而，特征值或准粒子自洽 GW 计算显著提高了与实验和 TD-DFT 谱的一致性。

Conclusion: 特征值或准粒子自洽 GW 计算能显著改善 Ag_n 团簇的光吸收光谱计算精度，强调了 4d 占据带位置的重要性。

Abstract: We study the optical absorption spectra of small Ag_n (n=2,4,6,8) clusters
using the Bethe-Salpeter equation (BSE) formalism with a Hamiltonian built from
GW quasiparticle energies. Calculations are based on an effective core
potential including the 4sp shells in the valence. Non-self-consistent G0W0
calculations relying on input Kohn-Sham eigenstates generated with semilocal
functionals lead to very poor BSE absorption spectra, confirming a previous
observation. However, eigenvalue or quasiparticle self-consistent GW
calculations dramatically improves the agreement with experiments and TD-DFT
spectra obtained with range-separated hybrid functionals. The importance of the
position of the 4d occupied band is emphasized.

</details>


### [282] [Deep Learning-Assisted Weak Beam Identification in Dark-Field X-ray Microscopy](https://arxiv.org/abs/2509.05017)
*A. Benhadjira,C. Detlefs,S. Borgi,V. Favre-Nicolin,C. Yildirim*

Main category: cond-mat.mtrl-sci

TL;DR: 通过深度学习自动化暗场X射线显微成像中的成像条件识别，提高分析效率和数据量。


<details>
  <summary>Details</summary>
Motivation: 目前，在宏观晶体中定量表征位错在三维空间中仍然具有挑战性，因为暗场X射线显微成像（DFXM）在区分弱束（有利于位错成像）和强束（干扰成像）条件方面存在瓶颈，而手动识别此问题缓慢且不主观。

Method: 提出了一种深度学习框架，使用轻量级卷积神经网络自动识别DFXM成像条件，该网络在小型手工标记的数据集上进行训练。

Result: 该框架能够稳健、快速、可扩展地识别成像条件，将DFXM转化为高通量工具，能够进行大规模的统计研究。

Conclusion: 该深度学习方法解决了DFXM的关键瓶颈，通过自动化成像条件识别，为大规模研究体材料中的位错动力学提供了支持。

Abstract: Dislocations control the mechanical behavior of crystalline materials, yet
their quantitative characterization in bulk has remained elusive. Transmission
Electron Microscopy provides atomic-scale resolution but is restricted to thin
foils, limiting relevance to structural performance. Dark-field X-ray
microscopy (DFXM) has recently opened access to three-dimensional,
non-destructive imaging of dislocations in macroscopic crystals. A critical
bottleneck, however, is the reliable identification of weak- versus strong-beam
conditions. Weak-beam imaging enhances dislocation contrast, while strong-beam
conditions are dominated by multiple scattering and obscure interpretation.
Current practice depends on manual classification by specialists, which is
subjective, slow, and incompatible with the scale of modern experiments. Here,
we introduce a deep learning framework that automates this task using a
lightweight convolutional neural network trained on small, hand-labeled
datasets. By enabling robust, rapid, and scalable identification of imaging
conditions, this approach transforms DFXM into a high-throughput tool,
unlocking statistically significant studies of dislocation dynamics in bulk
materials.

</details>


### [283] [Tuning Magneto-Optical Zero-Reflection via Dual-Channel Hybrid Magnonics](https://arxiv.org/abs/2509.05022)
*Andrew Christy,Yujie Zhu,Yi Li,Yuzan Xiong,Tao Qu,Frank Tsui,James F. Cahoon,Binbin Yang,Jia-Mian Hu,Wei Zhang*

Main category: cond-mat.mtrl-sci

TL;DR: 双通道耦合混合系统中的磁化进动相位可由微波光子场和层间交换两种力矩联合调控，实现对磁光光谱的相干双通道激发，并可通过改变频率、偏置磁场及层间耦合方式实现相长或相消干涉，从而选择性地抑制或放大杂化磁 gitti 模式。


<details>
  <summary>Details</summary>
Motivation: 混合系统中多通道耦合是研究各组成模式优势及激发路径间干涉的理想平台。

Method: 结合解析计算和实验，研究钇铁石榴石(YIG)/坡莫合金(Py)双层膜界面处的磁化进动相位。

Result: 发现微波光子场力矩和层间交换力矩联合控制界面磁化进动相位，形成相干双通道激发，有效调谐磁光光谱；不同力矩贡献随频率、偏置磁场和层间耦合类型变化，导致两种激发通道间的相长或相消干涉，从而选择性地抑制或放大杂化磁 gitti 模式。

Conclusion: YIG/Py双层膜界面处的磁化进动相位受到微波光子场力矩和层间交换力矩的共同影响，可实现相干双通道激发，并通过干涉效应调控磁 gitti 模式的激发。

Abstract: Multi-channel coupling in hybrid systems makes an attractive testbed not only
because of the distinct advantages entailed in each constituent mode, but also
the opportunity to leverage interference among the various excitation pathways.
Here, via combined analytical calculation and experiment, we demonstrate that
the phase of the magnetization precession at the interface of a coupled yttrium
iron garnet(YIG)/permalloy(Py) bilayer is collectively controlled by the
microwave photon field torque and the interlayer exchange torque, manifesting a
coherent, dual-channel excitation scheme that effectively tunes the
magneto-optic spectrum. The different torque contributions vary with frequency,
external bias field, and types of interlayer coupling between YIG and Py, which
further results in destructive or constructive interferences between the two
excitation channels, and hence, selective suppression or amplification of the
hybridized magnon modes.

</details>


### [284] [Energy dependent Chemical Interface Damping induced by 1-Decanethiol Self-Assembled Monolayer on Au(111)](https://arxiv.org/abs/2509.05025)
*Maurice Pfeiffer,Gregor B. Vonbun-Feldbauer,Jacob B. Khurgin,Olga Matts,Ahmed Shqer,Nadiia Mameka,Manfred Eich,Alexander Petrov*

Main category: cond-mat.mtrl-sci

TL;DR: 化学界面阻尼效应（CID）会增加金属中自由电子的碰撞频率。研究人员通过实验将CID的两种贡献（诱导粗糙度和直接电荷转移）分离开来，并发现直接电荷转移的贡献与光子能量线性相关，这与硫醇在金表面的轨道有关。


<details>
  <summary>Details</summary>
Motivation: 研究化学界面阻尼（CID）效应中诱导粗糙度和直接电荷转移的贡献，并探索其在光电化学和光诱导化学反应中的潜在应用。

Method: 使用光谱椭偏法研究金（Au(111））表面覆盖癸硫醇自组装单分子层的CID效应，并通过密度泛函理论计算进行验证。

Result: 观察到与光子能量无关的诱导粗糙度贡献，以及从约1 eV开始与光子能量线性增加的直接电荷转移贡献。该电荷转移机制的起始点与硫醇在金表面上的轨道相对应。

Conclusion: 成功将CID效应的两种贡献分离开来，并确定了直接电荷转移机制的起始点和与光子能量的关系，证实了其与硫醇轨道的联系，为光电化学等领域的研究提供了实验和理论支持。

Abstract: The chemical interface damping (CID) effect increases the collision frequency
of free electrons in metals by changes of the metal surface. We have now
experimentally disentangled the two contributions to CID: induced roughness and
direct charge transfer. The latter is an important area of research in
photoelectrochemistry with potential applications in light-induced chemical
reactions. We present a broadband investigation of the CID effect on Au(111)
covered by a self-assembled monolayer of decanethiol. Spectroscopic
ellipsometry measurements show a photon energy dependent increase of collision
frequency. We observe a constant, photon energy independent contribution, which
is attributed to induced roughness and a contribution that linearly increases
with photon energy from about 1 eV upwards which we attribute to direct charge
transfer. The onset of the charge transfer mechanism corresponds to occupied
orbitals of thiols bound to the Au surface, as confirmed by density functional
theory calculations.

</details>


### [285] [Gas Sensing Properties of Novel Indium Oxide Monolayer: A First-Principles Study](https://arxiv.org/abs/2509.05121)
*Afreen Anamul Haque,Suraj G. Dhongade,Aniket Singha*

Main category: cond-mat.mtrl-sci

TL;DR: 二维氧化铟(In2O3)对NO和H2S具有高灵敏度，并且可以通过机械应变进一步调控其检测能力，是下一代气体传感器的有潜力平台。


<details>
  <summary>Details</summary>
Motivation: 研究新型二维氧化铟(In2O3)单层材料的气体传感能力，以探索其在环境监测和安全应用中的潜力。

Method: 使用密度泛函理论(DFT)计算，研究了二维In2O3单层对十种有害气体和三种环境分子的吸附行为和传感机制（电阻型和功函数型）。

Result: 二维In2O3单层对NO和H2S表现出显著的灵敏度，并且功函数调制可以检测NH3和HCN。机械应变可以增强吸附和选择性，拓宽检测范围。

Conclusion: 二维In2O3单层是一种可调控的平台，可用于开发下一代小型化气体传感器，应用于环境监测和安全领域。

Abstract: We present a comprehensive first-principles investigation into the gas
sensing capabilities of a novel two-dimensional Indium Oxide (In2O3) monolayer,
using density functional theory (DFT) calculations. Targeting both
resistive-type and work function based detection mechanisms, we evaluate
interactions with ten hazardous gases (NH3, NO, NO2, SO2, CS2, H2S, HCN, CCl2O,
CH2O, CO) as well as ambient molecules (O2, CO2, H2O). The monolayer shows
pronounced sensitivity towards NO and H2S, and work function modulation enables
detection of NH3 and HCN. Mechanical strain further broadens detection
capability, enhancing adsorption and selectivity. These results establish 2D
In2O3 as a tunable platform for next-generation miniaturized gas sensors for
environmental monitoring and safety applications.

</details>


### [286] [Hydrogen absorption in intermetallic compounds from first principles](https://arxiv.org/abs/2509.05136)
*Olivier Nadeau,Romuald Béjaud,Lucas Baguet,Grégory Geneste,François Bottin,Gabriel Antonius*

Main category: cond-mat.mtrl-sci

TL;DR: Nd3MgNi14合金在有无零点能修正下，使用混合交换相关泛函进行第一性原理计算，可以准确预测其氢气吸收等温线。


<details>
  <summary>Details</summary>
Motivation: Nd3MgNi14等金属间化合物具有高且可逆的氢气吸收能力，可用于移动储氢应用。

Method: 使用多尺度建模方法，结合DFT计算和蒙特卡洛模拟，预测Nd3MgNi14的氢气吸收等温线。

Result: 计算得到的氢气吸收等温线与实验数据吻合良好，并指出混合交换相关泛函和零点能校正对于准确预测吸收性质是必要的。

Conclusion: DFT分析表明，完全氢化结构体积膨胀稳定了高氢含量的结构。

Abstract: Intermetallic compounds such as {A$_{2}$B$_{7}$} alloys are promising
candidates for mobile hydrogen storage applications due to their high and
reversible hydrogen absorption capacity. We compute the absorption isotherm of
{Nd$_{3}$MgNi$_{14}$} from first-principles using a multiscale modeling
approach. Absorption sites are identified through a systematic geometrical
analysis, and are characterized with Density Functional Theory (DFT)
calculations. The absorption site properties are used in room-temperature Grand
Canonical Monte Carlo simulations to predict hydrogen uptake as a function of
pressure, leading to a full absorption isotherm in good agreement with
experimental data. We show that both hybrid exchange-correlation functionals
and zero-point energy corrections are necessary to obtain accurate absorption
properties. The analysis of the fully hydrogenated structure with DFT shows
considerable volume expansion, which stabilizes the structure at large hydrogen
content.

</details>


### [287] [Vanadium-Engineered Co2NiSe4 Nanomaterial: Coupled Thermoelectric, Piezoelectric, and Electronic Optimization via DFT+U for Advanced Energy Applications](https://arxiv.org/abs/2509.05266)
*Ayesha Riaz,Sikander Azam,Qaiser Rafiq,Amin Ur Rahman,Qazi Muhammad Ahkam,Rafaqat Hussain,Rajwali Khan*

Main category: cond-mat.mtrl-sci

TL;DR: 钒掺杂Co2NiSe4在能量存储、热电生成和传感器等领域具有应用前景，其结构、电子、磁性、热力学、力学、热电、压电和光学性质均得到改善。


<details>
  <summary>Details</summary>
Motivation: 为了在储能和转换技术中创造先进的多功能材料，评估了原始和掺钒Co2NiSe4的结构、电子、磁性、热力学、机械、热电、压电和光学性质。

Method: 采用第一性原理密度泛函理论（DFT + U）方法，研究钒取代对材料性能的影响。

Result: 钒掺杂提高了导电性和磁有序性，增强了热力学稳定性和结构完整性，热电优值ZT达到约1.1，光学性质得到改善，压电系数也更高。

Conclusion: 钒掺杂Co2NiSe4是一种多功能材料，在下一代储能、热电生成和新型多功能传感器方面具有应用价值。

Abstract: To realize the creation of advanced multifunctional materials in energy
storage and conversion technologies, the present research evaluates the
structural, electronic, magnetic, thermodynamic, mechanical, thermoelectric,
piezoelectric and optical properties of pristine and vanadium-doped Co2NiSe4 by
first-principles density functional theory (DFT + U ). It addresses the use of
vanadium substitution to tailor the material, its performance and the inclusion
of diverse fields by changing its electronic structure and its bonding
properties. It can be seen in the results that V doping improves electrical
conductivity and magnetic ordering because of a higher density of states and a
stronger spin polarization at the Fermi level. Thermodynamic calculations show
enhanced entropy stabilization at high temperatures and, mechanical analysis
suggests an enhanced elastic moduli that proves the enhanced structural
integrity without affecting ductility. The thermoelectric properties have been
greatly improved realize an optimal ZT of ~1.1 at 900 K with 5 at.% V doping
owing to an ideal combination of Seebeck coefficient, electrical conductivity,
and inhibited thermal conductivity. Also, optical analysis reveals that
expanded absorption spectra, increased dielectric response, adjustable
reflectivity and energy loss spectra, optical properties can be used in
photonic, and other optoelectronic devices. Better piezoelectric coefficients
due to its effectiveness when doped also appeal to the usefulness of its
application in nanoscale electromechanical systems. The combination of these
results makes V-doped Co2NiSe4, a versatile material platform of
next-generation energy storage, thermoelectric generation, and novel
multifunctional sensors.

</details>


### [288] [Illuminating Stability and Spectral Shifts: A DFT+U Study of Eu-Doped ZnWO$_4$ for Visible-Light Optoelectronics](https://arxiv.org/abs/2509.05278)
*Muhammad Tayyab,Sikander Azam,Qaiser Rafiq,Vineet Tirth,Ali Algahtani,Amin Ur Rahman,Syed Sheraz Ahmad,M. Tahir Khan*

Main category: cond-mat.mtrl-sci

TL;DR: Eu掺杂ZnWO4可调控其光电特性，有望用于w-LEDs。


<details>
  <summary>Details</summary>
Motivation: 探索Eu掺杂对ZnWO4光电特性的影响，以期用于下一代光电器件。

Method: 使用自旋极化密度泛函理论（DFT）结合GGA+U框架，研究了纯净和Eu掺杂ZnWO4的结构、电子和光学性质，并进行了声子色散分析。

Result: Eu掺杂降低了带隙，引入了费米能级附近的局域态，改变了态密度，增强了电子跃迁。光学响应显示介电函数展宽、吸收边红移、消光系数增强。反射率和能量损失谱表明光子-声子耦合增强，光学可调性提高。

Conclusion: Eu掺杂不仅稳定了ZnWO4晶格，还调控了其光电特性，使Eu掺杂ZnWO4成为白光LED（w-LEDs）及相关光电器件的潜在候选材料。

Abstract: Tungstate-based oxides have attracted significant attention owing to their
excellent structural stability, chemical robustness, and versatile optical
properties, making them suitable for next-generation optoelectronic and
phosphor applications. Among these, ZnWO$_4$ has emerged as a promising host
matrix; however, the role of europium (Eu) substitution in modulating its
optoelectronic behavior remains underexplored. In this work, we employ
spin-polarized density functional theory (DFT) within the GGA+U framework to
investigate the structural, electronic, and optical properties of pristine
ZnWO$_4$ and Eu-doped ZnWO4 systems. Phonon dispersion analysis confirms
dynamical stability for both pristine and doped structures. Eu doping reduces
the bandgap, introduces new localized states near the Fermi level, and
significantly alters the density of states, thereby enhancing electronic
transitions. The optical response reveals a broadened dielectric function,
red-shifted absorption edge, and intensified extinction coefficient, consistent
with the presence of Eu 4f states. Additionally, reflectivity and energy-loss
spectra indicate improved photon-phonon coupling and optical tunability upon
doping. These findings highlight that Eu incorporation not only stabilizes the
ZnWO$_4$ lattice but also tailors its optoelectronic features, positioning
Eu-doped ZnWO4 as a potential candidate for white-light-emitting diodes
(w-LEDs) and related optoelectronic technologies.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [289] [A Quantum Guitar](https://arxiv.org/abs/2509.04526)
*Bob Coecke*

Main category: quant-ph

TL;DR: 通过将可弹奏状态与量子比特相关联，将吉他弦的波转化为量子波，从而创造出“量子吉他”。该仪器允许在量子和经典声音之间无缝过渡，并已被用于各种现场表演和音乐风格。


<details>
  <summary>Details</summary>
Motivation: 将吉他弦的波转化为量子波，创造一种新的乐器。

Method: 将吉他与量子合成器耦合，并使用脚部控制器进行量子比特操作和测量。

Result: 该仪器在各种现场表演和音乐风格中都得到了成功演示，证明了其多功能性和可靠性。

Conclusion: 量子吉他是一种多功能且可靠的新型乐器，它在量子和经典声音之间实现了无缝过渡，并为音乐表演开辟了新的可能性。

Abstract: A guitar string represents a wave, and by associating a qubit to each of its
playable states we get a quantum wave. This is the principle behind our Quantum
Guitar: `quantising all strings of a guitar'. In order to achieve this
quantisation, we couple a guitar with Moth's Actias quantum synth, and for
qubit manipulations including measurements the musician uses foot controllers -
hence using all four limbs like a drummer. Our Quantum Guitar also allows for
smooth continuous transition from `quantum' to `classical' sound, and vice
versa. We have used our Quantum Guitar in several live performances in a
variety of venues, playing a number different musical styles, hence
demonstrating that it is a very uniquely versatile and reliable instrument. For
example, in some performances Quantum Guitar was used in industrial music, by
the band Black Tish, who are currently recording an album with it. In other
performances Quantum Guitar represented a qubit within a sonified Bell-pair
under measurement, the other qubit being mentally realised with a Grand Piano.
Classical-quantum and quantum-classical transitions prove particularly useful
in musical performance. A link to a demo video of Quantum Guitar is provided.

</details>


### [290] [The Structure and Interpretation of Quantum Programs I: Foundations](https://arxiv.org/abs/2509.04527)
*David Wakeham*

Main category: quant-ph

TL;DR: The paper proposes a new "props and ops" model for quantum programming, replacing the traditional "states and gates" formalism. This model uses C*-algebras for syntax, linear functionals for semantics, and a diagrammatic calculus to unify them. It offers a concise, representation-agnostic foundation for quantum programming and error correction.


<details>
  <summary>Details</summary>
Motivation: The usual "states and gates" formalism for quantum computers is limited for programming them. This paper aims to provide a more suitable framework.

Method: The paper replaces the "states and gates" formalism with a "props and ops" (propositions and operators) model. This model utilizes the C*-algebra of observables for syntax, linear functionals (states) for semantics, and a novel diagrammatic calculus to unify syntax and semantics. It develops the basic objects of the framework by encoding operator correlations, recovering Hilbert space via the GNS construction, and re-deriving the Bloch sphere. It also addresses intervention by showing how measurement modifies state, proving an operator-algebraic version of the Knill-Laflamme conditions, and expressing stabilizer codes using the same diagrammatic machinery.

Result: The proposed "props and ops" model provides a concise, representation-agnostic account of quantum error correction. C*-algebras and their dual Hilbert spaces serve as a rich and universal substrate for quantum programming.

Conclusion: The paper establishes C*-algebras and their dual Hilbert spaces as a foundational substrate for quantum programming, with future work planned for developing high-level languages and applications.

Abstract: Qubits are a great way to build a quantum computer, but a limited way to
program one. We replace the usual "states and gates" formalism with a "props
and ops" (propositions and operators) model in which (a) the C*-algebra of
observables supplies the syntax; (b) states, viewed as linear functionals, give
the semantics; and (c) a novel diagrammatic calculus unifies the two. The first
part develops the basic objects of the framework, encoding consistent patterns
of operator correlation, recovering Hilbert space via the GNS construction, and
re-deriving the Bloch sphere as the set of all consistent correlations of
operators in the Pauli algebra.
  We then turn to intervention, showing how measurement modifies state, proving
an operator-algebraic version of the Knill-Laflamme conditions, and expressing
stabilizer codes with the same diagrammatic machinery. This provides a concise,
representation-agnostic account of quantum error correction. The result is a
self-contained foundation in which C*-algebras, and their dual Hilbert spaces,
offer a rich and universal substrate for quantum programming; forthcoming
papers will build a high-level language and quantum software applications on
top of this substrate.

</details>


### [291] [The Kerr-Induced Superradiant Tricritical Point](https://arxiv.org/abs/2509.04530)
*Arash Azizi,Reed Nessler*

Main category: quant-ph

TL;DR: 在量子Rabi模型中，光子-光子（Kerr）相互作用可以诱导超辐射相变，并产生一条区分连续二阶和不连续一阶相变的边界。真正的三临界点仅在特定的耗散率（kappa_t^2 = (sqrt(13)-2)/3）下出现，这是一种罕见的现象。


<details>
  <summary>Details</summary>
Motivation: 研究开放量子系统中相互作用和耗散如何影响相变，特别是在量子Rabi模型中。

Method: 通过引入光子-光子（Kerr）相互作用来研究超辐射相变，并分析其与耗散率的关系。

Result: 发现Kerr相互作用会改变超辐射相变的性质，产生一个区分连续和不连续相变的边界。同时，证明了真正的三临界点只在特定的耗散率下出现。

Conclusion: 真正的三临界点是一种罕见的现象，仅在特定的耗散率下出现，这为在基础量子光学系统中实现更高阶的临界性提供了一个独特的途径。

Abstract: The interplay of interaction and dissipation in open quantum systems can
forge phase transitions beyond conventional paradigms. In the canonical quantum
Rabi model, we demonstrate that a photon-photon (Kerr) interaction transforms
the celebrated superradiant phase transition, inducing a line that separates
continuous, second-order behavior from discontinuous, first-order regimes.
Strikingly, this is not a line of tricritical points. Instead, we prove that
genuine tricriticality is an isolated phenomenon, emerging only at a single,
mathematically exact dissipation rate: the ``sweet spot'' of $\kappa_t^2 =
(\sqrt{13}-2)/3$. Our discovery pinpoints the precise and restrictive
conditions for realizing a rare multicritical point in a foundational quantum
optical system, identifying this critical dissipation as a unique gateway to a
higher order of criticality.

</details>


### [292] [Distributed-HISQ: A Distributed Quantum Control Architecture](https://arxiv.org/abs/2509.04798)
*Yilun Zhao,Kangding Zhao,Peng Zhou,Dingdong Liu,Tingyu Luo,Yuzhen Zheng,Peng Luo,Shun Hu,Jin Lin,Cheng Guo,Yinhe Han,Ying Wang,Mingtang Deng,Junjie Wu,X. Fu*

Main category: quant-ph

TL;DR: 本论文提出了一种名为Distributed-HISQ的量子控制架构，以解决现有量子控制架构在可扩展性、同步开销和指令集设计方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有量子控制架构面临两大挑战：1. 随着量子比特数量的增加，分布式架构不可避免，但现有同步策略（如锁步或按需驱动）在高延迟反馈循环中会带来显著的性能损失。2. 现有的量子指令集架构要么过于抽象，要么过于细粒度，缺乏统一性，导致需要为每个新的控制需求进行硬件定制，限制了系统的可重构性。

Method: 提出了一种名为Distributed-HISQ的量子控制架构，包含两个核心组件：1. HISQ：一个通用的、与硬件无关的指令集，通过解耦量子操作语义，提供统一的控制序列语言，允许单一微架构支持多种控制方法，提高系统可重构性。2. BISP：一种基于预订的同步协议，旨在实现零周期同步开销。

Result: 通过在商用量子控制系统上实现并针对超导量子比特进行评估，结果表明BISP协议能有效同步多个控制板，平均程序执行时间减少了22.8%，并且与现有的锁步同步方案相比，保真度降低了约5倍。

Conclusion: Distributed-HISQ架构，特别是其HISQ指令集和BISP同步协议，能够有效解决现有量子控制架构在可扩展性、同步开销和指令集设计方面的挑战，提高了量子控制系统的性能和可重构性。

Abstract: The design of a scalable Quantum Control Architecture (QCA) faces two primary
challenges. First, the continuous growth in qubit counts has rendered
distributed QCA inevitable, yet the nondeterministic latencies inherent in
feedback loops demand cycleaccurate synchronization across multiple
controllers. Existing synchronization strategies -- whether lock-step or
demand-driven -- introduce significant performance penalties. Second, existing
quantum instruction set architectures are polarized, being either too abstract
or too granular. This lack of a unifying design necessitates recurrent hardware
customization for each new control requirement, which limits the system's
reconfigurability and impedes the path toward a scalable and unified digital
microarchitecture.
  Addressing these challenges, we propose Distributed-HISQ, featuring: (i)
HISQ, A universal instruction set that redefines quantum control with a
hardware-agnostic design. By decoupling from quantum operation semantics, HISQ
provides a unified language for control sequences, enabling a single
microarchitecture to support various control methods and enhancing system
reconfigurability. (ii) BISP, a booking-based synchronization protocol that can
potentially achieve zero-cycle synchronization overhead. The feasibility and
adaptability of Distributed-HISQ are validated through its implementation on a
commercial quantum control system targeting superconducting qubits. We
performed a comprehensive evaluation using a customized quantum software stack.
Our results show that BISP effectively synchronizes multiple control boards,
leading to a 22.8% reduction in average program execution time and a
$\sim$5$\times$ reduction in infidelity when compared to an existing lock-step
synchronization scheme.

</details>


### [293] [Wave Packet Sizes in Quantum Mechanical Scatterings: New Perspective](https://arxiv.org/abs/2509.04539)
*Kenzo Ishikawa,Osamu Jinnouchi*

Main category: quant-ph

TL;DR: 研究了波包的大小及其对散射过程和跃迁概率绝对值的影响。


<details>
  <summary>Details</summary>
Motivation: 波包的大小由其与物质的相互作用和环境决定，这影响了散射过程和跃迁概率的绝对值。

Method: 研究波包的大小及其影响。

Result: 波包的大小影响散射过程和跃迁概率的绝对值。

Conclusion: 归一化的波包表达了自然界中的粒子，它们的大小受环境和与物质相互作用的影响，并决定了散射过程和跃迁概率的绝对值。

Abstract: Normalized wave packets express particles in nature. Their sizes are
determined by their interactions with matter, and depend on environments.
Nevertheless, these characterize scatterings processes in realistic situations,
and govern the absolute values of transition probabilities. This paper studies
the wave packet sizes and their implications.

</details>


### [294] [Using Mellin Transform to Solve Schroedinger Equation for Exponential Potential](https://arxiv.org/abs/2509.04542)
*Rami Mehrem*

Main category: quant-ph

TL;DR: S-state bound state solution for exponential potential using Mellin transform.


<details>
  <summary>Details</summary>
Motivation: To find an alternative method to the usual Bessel differential equation approach for solving the Schroedinger equation for an exponential potential.

Method: Using the Mellin transform to solve the Schroedinger equation, which involves solving a first-order difference equation through iteration and induction.

Result: Derived the S-state bound state solution.

Conclusion: The Mellin transform is a viable and alternative method for solving the Schroedinger equation for an exponential potential.

Abstract: S-state Bound state solution to Schroedinger equation for an exponential
potential is derived using the Mellin transform. This method is a new and an
alternative to the usual method of reducing Schroedinegr equation to a Bessel
differential equation. It involves solving a first order difference equation
using iteration and induction.

</details>


### [295] [Histogram Driven Amplitude Embedding for Qubit Efficient Quantum Image Compression](https://arxiv.org/abs/2509.04849)
*Sahil Tomar,Sandeep Kumar*

Main category: quant-ph

TL;DR: 使用量子设备压缩彩色图像，通过块（bixels）和直方图实现，资源消耗少，保真度可调。


<details>
  <summary>Details</summary>
Motivation: 开发一种紧凑且硬件高效的彩色图像压缩方法，适用于近期量子设备。

Method: 将图像分割为bixels，计算块强度，构建全局直方图，并将归一化后的直方图计数平方根作为幅值嵌入量子态，最后通过测量量子态恢复直方图和图像。

Result: 在少量量子比特（5-7个）的情况下实现了高质量的图像重建，优于传统逐像素编码。

Conclusion: 该方法计算资源需求与图像分辨率无关，仅取决于直方图箱数B，可以平衡保真度和资源消耗，适用于当前的NISQ时代量子系统。

Abstract: This work introduces a compact and hardware efficient method for compressing
color images using near term quantum devices. The approach segments the image
into fixed size blocks called bixels, and computes the total intensity within
each block. A global histogram with B bins is then constructed from these block
intensities, and the normalized square roots of the bin counts are encoded as
amplitudes into an n qubit quantum state. Amplitude embedding is performed
using PennyLane and executed on real IBM Quantum hardware. The resulting state
is measured to reconstruct the histogram, enabling approximate recovery of
block intensities and full image reassembly. The method maintains a constant
qubit requirement based solely on the number of histogram bins, independent of
the resolution of the image. By adjusting B, users can control the trade off
between fidelity and resource usage. Empirical results demonstrate high quality
reconstructions using as few as 5 to 7 qubits, significantly outperforming
conventional pixel level encodings in terms of qubit efficiency and validating
the practical application of the method for current NISQ era quantum systems.

</details>


### [296] [Measuring Multiparticle Indistinguishability with the Generalized Bunching Probability](https://arxiv.org/abs/2509.04550)
*Shawn Geller,Emanuel Knill*

Main category: quant-ph

TL;DR: 许多玻色子在经过被动线性变换和测量后，其状态可以通过可见态完全表征，但测量可见态所有参数具有挑战性。我们提出广义聚束概率（所有输入玻色子落入给定输出模式子集中的概率）提供了关于玻色子不可区分性的有用部分信息，因为它与某些偏区分度部分有序关系具有单调性。我们证明，如果 Lieb 的永久支配猜想成立，那么在置换可见模式不被占据的状态下，广义聚束概率在玻色子完全不可区分时最大化。作为推论，如果 Lieb 的猜想成立，那么广义聚束概率与部分标记状态的精细化偏序关系具有单调性。我们还无条件证明，对于单粒子密度矩阵相同的状态，广义聚束概率的 Haar 平均值相对于 said 单粒子密度矩阵的特征值是 Schur 凸的。作为 Schur 凸性的应用，我们证明当单粒子密度矩阵是 Gibbs 态时，平均广义聚束概率可用作温度计。


<details>
  <summary>Details</summary>
Motivation: 测量可见态所有参数具有挑战性，因此需要找到一种方法来部分表征玻色子不可区分性。

Method: 提出广义聚束概率，并研究其与玻色子不可区分性的关系，证明其单调性、最大化性质以及 Schur 凸性。

Result: 证明了广义聚束概率与某些偏区分度部分有序关系具有单调性；在 Lieb 的猜想下，证明了当玻色子完全不可区分时，广义聚束概率最大化；证明了广义聚束概率的 Haar 平均值是 Schur 凸的；证明了当单粒子密度矩阵是 Gibbs 态时，平均广义聚束概率可用作温度计。

Conclusion: 广义聚束概率提供了关于玻色子不可区分性的有用信息，并且在特定条件下可以作为测量温度的工具。

Abstract: The indistinguishability of many bosons undergoing passive linear
transformations followed by number basis measurements is fully characterized by
its visible state. However, measuring all of the parameters in the visible
state is experimentally demanding. We argue that the generalized bunching
probability -- which is the probability that all the input bosons arrive in a
given subset of the output modes -- provides useful partial information about
the indistinguishability of the input bosons, by establishing that it is
monotonic with respect to certain partial orders of distinguishability of the
bosons. As an intermediate result, we prove that if Lieb's
permanental-dominance conjecture holds, then among states that are invariant
under permutations of the occupied visible modes, the generalized bunching
probability is maximized when the bosons are perfectly indistinguishable. As a
corollary, we show that if Lieb's conjecture holds, then the generalized
bunching probability is monotonic with respect to the refinement partial order
on what we refer to as partially labelled states. We also prove,
unconditionally, that for states such that the single-particle density matrix
is the same for each particle, the Haar average of the generalized bunching
probability is Schur convex with respect to the eigenvalues of said
single-particle density matrix. As an application of the Schur-convexity, we
show that when the single-particle density matrix is a Gibbs state, the mean
generalized bunching probability serves as a thermometer.

</details>


### [297] [Free Snacks in Quantum Complexity](https://arxiv.org/abs/2509.04618)
*Gerard McCaul*

Main category: quant-ph

TL;DR: ITQDE方法可以在多项式资源下估计粗粒度的谱信息，但精确的特征值解析仍然是困难的。


<details>
  <summary>Details</summary>
Motivation: 量子计算机上估计基态能量是一个基本问题，通常需要指数级资源。ITQDE方法是一种新的方法，可以估计谱密度、配分函数和低能间隙，同时只需要最小的相干控制、适度的经典后处理和状态制备。

Method: 该方法采用基于求积的公式，并引入了受控平滑技术，以实现原则性的偏差-方差权衡。

Result: ITQDE方法在多项式资源内提供了一个可行的“免费零食”区域，可以在此区域内获得粗粒度的谱信息，但精确的特征值解析仍然是困难的。该方法将采样成本重新表述为可解析带宽的明确界限，使得在近期量子硬件上可以实现介于平凡和棘手复杂度之间的中间状态。

Conclusion: ITQDE方法为在近期量子硬件上获得粗粒度的谱信息提供了一条实际可行的途径，同时承认精确特征值解析的固有难度。

Abstract: Estimating ground-state energies is a cornerstone problem in Hamiltonian
complexity, and in general requires exponential resources even on quantum
computers. It is in this context we analyse the recently developed
Imaginary-Time Quantum Dynamical Emulation (ITQDE). This method enables
estimation of spectral densities, partition functions, and low-lying gaps, but
requires only minimal coherent control, modest classical post-processing, and
no state preparation. Using a quadrature-based formulation, we derive scaling
and stability criteria that diagnose when its estimates are reliable, and
introduce a controlled smoothing that yields a principled bias-variance trade
off. The resulting picture preserves the hardness of exact eigenvalue
resolution but reveals a practical regime - a "free snack" - here
coarse-grained spectral information is obtainable with only polynomial
resources. By recasting sampling costs as explicit bounds on resolvable
bandwidths, the intermediate regime between trivial and intractable complexity
becomes accessible on near-term quantum hardware.

</details>


### [298] [Laser-enhanced quantum sensing boosts sensitivity and dynamic range](https://arxiv.org/abs/2509.05204)
*Florian Schall,Lukas Lindner,Yves Rottstaedt,Marcel Rattunde,Florentin Reiter,Rüdiger Quay,Roman Bek,Alexander M. Zaitsev,Takeshi Ohshima,Andrew D. Greentree,Jan Jeske*

Main category: quant-ph

TL;DR: 通过将金刚石中的氮空位（NV）中心集成到激光腔中，我们展示了一种新型的激光阈值磁力测量系统，该系统具有100%的光学对比度和高达50毫瓦的输出信号，动态范围为±280微特斯拉，灵敏度为670 fT/√Hz，在多个传感参数上均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有的基于金刚石氮空位（NV）中心的磁力计在光学对比度和动态范围方面存在局限性。

Method: 将NV中心集成到激光腔中，利用磁场依赖的激光阈值变化进行测量。

Result: 实现了100%的光学对比度、50毫瓦的输出信号、±280微特斯拉的动态范围以及670 fT/√Hz的灵敏度，与现有技术相比有显著改进。

Conclusion: 所提出的激光阈值磁力测量系统克服了传统NV中心磁力计的局限性，其性能的大幅提升为脑磁图、磁导航和磁异常探测等领域的新一代传感器奠定了基础。

Abstract: Magnetometers based on nitrogen-vacancy (NV) centers in diamond have emerged
as the most important solid-state quantum sensors. However, ensembles are
limited in optical contrast to typically a few percent and high-sensitivity
variants usually possess only a few $\mathrm{\mu}$T dynamic range. Here, we
demonstrate a laser threshold magnetometry-based NV system that avoids these
limitations. By integrating the NV centers into a laser cavity and showing
magnetic-field-dependent shifts of the laser threshold, we observe 100\,\%
contrast with strong output signals up to 50\,mW. The resulting system exhibits
a dynamic range of $\pm$280\,$\mathrm{\mu}$T with a photon-shot-noise-limited
sensitivity of 670\,fT/$\sqrt{\mathrm{Hz}}$, which we demonstrate to improve
super-linearly with contrast. The ratio of these sensing-relevant parameters,
that can be traded at the cost of each other, marks an improvement factor of
780 over typical fluorescence-based readout and vapor cell sensors. Such
performance improvements open the door to new generations of sensors for
applications including magnetoencephalography, magnetic navigation, and
magnetic anomaly detection.

</details>


### [299] [Tailoring spatial correlations with quantum interference](https://arxiv.org/abs/2509.04725)
*Carlo Schiano,Bereneice Sephton,Elnaz Darsheshdar,Lorenzo Marrucci,Corrado de Lisio,Vincenzo D'Ambrosio*

Main category: quant-ph

TL;DR: 该研究提出了一种通过图案化量子干涉装置中的光子可区分性来塑造光子空间相关性的有效方法，可应用于量子通信和成像。


<details>
  <summary>Details</summary>
Motivation: 工程化光子相关性，尤其是在多粒子场景下，具有挑战性，而光子相关性是量子光学实验中的关键资源。

Method: 通过在量子干涉装置中对光子可区分性进行图案化来塑造光子空间相关性，并展示了如何在分束器的两个输出通道之间编写和编辑双光子相关性。

Result: 所提出的方法可以隐藏传统强度测量所无法获取的编码信息，并且可以轻松扩展到多粒子场景。

Conclusion: 该方案便于传输高维量子信息，并有潜力应用于量子通信和成像协议。

Abstract: Photon correlations represent a central resource in many quantum optics
experiments, with applications ranging from quantum information protocols to
sensing. Engineering such correlations is often challenging, especially in
multi-particle scenarios. In this work we describe an effective method for
shaping spatial correlations between photons by patterning their
distinguishability in a quantum interference setup. We show how to write and
edit these bi-photon correlations between the two output channels of a
beam-splitter, hiding this encoded information from conventional intensity
measurements. Our scheme offers an easy extension to multiparticle scenarios
and facilitates the transmission of high-dimensional quantum information, with
potential applications to quantum communication and imaging protocols.

</details>


### [300] [Control Protocol for Dynamic Synthesis of Qubit and Qudit Gates Using Photonic Pulses and Magnetic Fields](https://arxiv.org/abs/2509.04825)
*A. F. Urquijo Rodríguez,Edgar A. Gómez,H. Vinck-Posada*

Main category: quant-ph

TL;DR: 提出一种理论控制协议，利用外部参数（如光高斯脉冲和磁场）在微腔量子阱系统中动态合成单量子比特和四能级量子的量子门。


<details>
  <summary>Details</summary>
Motivation: 利用可调谐相干光-物质相互作用，通过磁场调节激子和负三体与最低光子模式的耦合，以实现量子态的精确操控。

Method: 通过对微腔量子阱系统施加光高斯脉冲和磁场等外部参数，利用可调谐相干光-物质相互作用，实现单量子比特和四能级量子的量子门合成。

Result: 成功生成了平均保真度为99.99%的单量子比特门，并实现了保真度为99.6%的四能级iSWAP门。

Conclusion: 证明了通过优化方法可以精确操控量子态布居，实现高保真度的量子门操作。

Abstract: We propose a theoretical control protocol designed for the dynamic synthesis
of single qubit and four-level qudit quantum gates using external parameters,
such as photonic Gaussian pulses and magnetic fields, in a microcavity quantum
well system. Our approach takes advantage of tunable coherent light matter
interactions that can be modulated by the magnetic field between the exciton
and negative trion coupled to the lowest photonic mode. We demonstrate that it
is possible to achieve precise manipulation of populations of encoded quantum
states through the unitary evolution of the system. In particular, we
illustrate our optimization method for generating a single qubit gate with a
mean fidelity of 99.99 as well as the realization of an iSWAP gate in the four
level qudit case with a fidelity of 99.6.

</details>


### [301] [Qumode-Based Variational Quantum Eigensolver for Molecular Excited States](https://arxiv.org/abs/2509.04727)
*Rishab Dutta,Cameron Cianci,Alexander V. Soudackov,Yuchen Wang,Chuzhi Xu,David A. Mazziotti,Lea F. Santos,Victor S. Batista*

Main category: quant-ph

TL;DR: QSS-VQE是一种利用量子比特-变模器架构的混合量子-经典算法，用于计算分子激发态，通过将电子结构哈密顿量嵌入到变模器Fock空间中，以提高效率和减少资源需求。


<details>
  <summary>Details</summary>
Motivation: 利用量子比特-变模器（qumode）架构的原生通用门集，构建具有高表达能力的变分ansatze，以期在计算分子激发态方面超越传统的仅使用量子比特的方法。

Method: 将电子结构哈密顿量映射到量子比特表示，然后将其嵌入到电路量子电动力学（cQED）设备中变模器的Fock空间里，以实现高效的状态制备和降低量子资源的需求。算法命名为Qumode Subspace Variational Quantum Eigensolver (QSS-VQE)。

Result: 通过模拟二氢和胞嘧啶的交叉圆锥等分子的激发态，证明了QSS-VQE的有效性。此外，还评估了一个二元模型哈密顿量的表达能力，并确定了基于二元实现的方案优于纯基于量子比特的方案的条件。

Conclusion: 利用变模器的自由度可以增强对复杂分子系统的量子模拟能力。

Abstract: We introduce the Qumode Subspace Variational Quantum Eigensolver (QSS-VQE), a
hybrid quantum-classical algorithm for computing molecular excited states using
the Fock basis of bosonic qumodes in circuit quantum electrodynamics (cQED)
devices. This approach harnesses the native universal gate sets of qubit-qumode
architectures to construct highly expressive variational ansatze, offering
potential advantages over conventional qubit-based methods. In QSS-VQE, the
electronic structure Hamiltonian is first mapped to a qubit representation and
subsequently embedded into the Fock space of bosonic qumodes, enabling
efficient state preparation and reduced quantum resource requirements. We
demonstrate the performance of QSS-VQE through simulations of molecular excited
states, including dihydrogen and a conical intersection in cytosine.
Additionally, we explore a bosonic model Hamiltonian to assess the expressivity
of qumode gates, identifying regimes where qumode-based implementations
outperform purely qubit-based approaches. These results highlight the promise
of leveraging bosonic degrees of freedom for enhanced quantum simulation of
complex molecular systems.

</details>


### [302] [Cavity QED based on strongly localized modes: exponentially enhancing single-atom cooperativity](https://arxiv.org/abs/2509.04739)
*Qian Bin,Ying Wu,Jin-Hua Gao,Aixi Chen,Franco Nori,Xin-You Lü*

Main category: quant-ph

TL;DR: 利用特殊几何腔实现单原子协同学数的指数增强，以提升量子信息处理能力。


<details>
  <summary>Details</summary>
Motivation: 量子系统中大的单原子协同学数对于量子信息处理至关重要。

Method: 通过增加具有特殊几何对称性的腔的翼展宽度，利用模式的强局域效应，在不改变腔模式体积V的情况下，通过干涉效应呈指数级提高品质因子Q，从而在亚波长光模式腔中呈指数级增强单原子协同学数参数。

Result: 演示了超长真空Rabi振荡的出现以及通过增强单原子协同学数参数产生的强光子阻塞。

Conclusion: 该研究提供了一种推进相干操纵的有前途的方法，在建立长距离量子通信网络、提高量子传感器的精度和稳定性以及提高量子算法效率方面具有巨大潜力。

Abstract: Large single-atom cooperativity in quantum systems is important for quantum
information processing. Here, we propose to exponentially enhance the
single-atom cooperativity parameter by exploiting the strongly localized effect
of modes in cavity quantum electrodynamics (QED) systems. By increasing the
wing width of a cavity with special geometry symmetry, the interference
property allows us to exponentially improves the quality factor Q without
altering the mode volume V for cavities supporting subwavelength light modes.
This effectively overcomes the trade-off between Q and V in conventional
subwavelength Fabry-Perot cavities. Consequently, we demonstrate the occurrence
of ultra-long vacuum Rabi oscillations and the generation of strong photon
blockade by enhancing the single-atom cooperativity parameter. This work offers
a promising approach for advancing coherent manipulation and holds significant
potential for applications in establishing longer-distance quantum
communication networks, enhancing the precision and stability of quantum
sensors, and improving the efficiency of quantum algorithms.

</details>


### [303] [Casimir-Lifshitz theory for cavity-modification of ground-state energy](https://arxiv.org/abs/2509.05156)
*Oleg V. Kotov,Johannes Feist,Francisco J. García-Vidal,Timur O. Shegai*

Main category: quant-ph

TL;DR: 该理论提出了一个包含谐振器模式的宏观量子电动力学模型，用于分析物质在法布里-珀罗腔中的基态变化，并考虑了损耗和温度效应。


<details>
  <summary>Details</summary>
Motivation: 解释真空能量和洛伦兹模型下物质在腔体内的基态能量变化。

Method: 构建了一个非微扰的宏观量子电动力学模型，该模型包含无限的腔体模式和连续的波矢，并基于Lifshitz的真空能量理论和材料介电常数的洛伦兹模型。

Result: 揭示了与单模Hopfield哈密顿量不同之处，证明了极化激子在基态能量移动中的非共振作用，表明腔体效应主要由低频静电屏蔽引起。

Conclusion: 该理论可以方便地纳入损耗和温度效应。

Abstract: A theory for ground-state modifications of matter embedded in a Fabry-Perot
cavity and whose excitations are described as harmonic oscillators is
presented. Based on Lifshitz's theory for vacuum energy and employing a Lorentz
model for the material permittivity, a non-perturbative macroscopic QED model
was built that accounts for the infinite number of cavity modes with a
continuum of their wavevectors. Differences from the commonly used single-mode
Hopfield Hamiltonian are revealed. The non-resonant role of polaritons in the
ground-state energy shift is also demonstrated, showing that the cavity effect
is mainly caused by static screening occurring at very low frequencies. The
theory allows for a straightforward incorporation of losses and temperature
effects.

</details>


### [304] [Tracking Quantum Dynamics in an Optical Cavity for Recovering Purity and Squeezing via Quantum State Smoothing](https://arxiv.org/abs/2509.04754)
*Shota Yokoyama,Kiarn T. Laverick,David McManus,Qi Yu,Areeya Chantasri,Warit Asavanant,Daoyi Dong,Howard M. Wiseman,Hidehiro Yonezawa*

Main category: quant-ph

TL;DR: Acausal quantum state smoothing can improve state purification and squeezing restoration compared to conventional causal filtering by maximally extracting lost information from the environment, even when information is lost to decoherence. This method requires assumptions about how lost quantum information is converted to classical information by the environment.


<details>
  <summary>Details</summary>
Motivation: Conventional quantum trajectory approach for tracking quantum system dynamics suffers from decoherence due to information loss to the environment, leading to impure states. Acausal quantum state smoothing offers a way to maximally extract lost information and potentially restore state coherence, but requires assumptions about information conversion.

Method: The experiment uses an optical parametric oscillator, splitting the output beam to two independent homodyne detectors to create 'observed' and 'unobserved' channels, demonstrating smoothing scenarios. This setup allows for the experimental investigation of acausal quantum state smoothing.

Result: The experiment achieved a 10.3% +/- 1.6% improvement in state purification and a 7.6% +/- 2.6% improvement in squeezing restoration using acausal smoothing compared to conventional filtering. Smoothed states were shown to be better estimates of hidden true states.

Conclusion: Acausal quantum state smoothing is experimentally demonstrated to be superior to conventional causal filtering in improving state purification and squeezing restoration. The estimation techniques employed are promising for quantum information applications involving post-processing.

Abstract: Tracking the dynamics of a quantum system is conventionally achieved by
monitoring the system continuously in time and filtering the information
contained in measurement records via the causal quantum trajectory approach.
However, in practical scenarios there is often loss of information to the
environment, leading to filtered states that are impure because of decoherence.
If real-time tracking is not required, the lost information can be maximally
extracted via acausal quantum state smoothing, which has been theoretically
proven to better restore the system's coherence (purity) than causal filtering.
Interestingly, quantum state smoothing requires assumptions of how any lost
quantum information (unobserved by the experimenter) was turned into classical
information by the environment. In this work, we experimentally demonstrate
smoothing scenarios, using an optical parametric oscillator and introducing
`observed' and `unobserved' channels by splitting the output beam into two
independent homodyne detectors. We achieve improvement in state purification of
10.3% +/- 1.6%, squeezing restoration of 7.6% +/- 2.6%, and show that smoothed
states are better estimates of hidden true states than those from conventional
filtering. The estimation techniques used in this paper are promising for many
applications in quantum information that incorporate post-processing.

</details>


### [305] [Improving initial-state-dependent quantum circuit optimization by introducing state labels](https://arxiv.org/abs/2509.04761)
*Toshiaki Kaji,Koji Terashi,Ryu Sawada*

Main category: quant-ph

TL;DR: AQCEL通过测量控制量子比特状态来优化量子电路，通过状态标签管理器和CX对移除过程减少了不必要的控制操作和冗余门，实验证明其在减少门数量和提高保真度方面优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 在量子硬件不断进步的背景下，以最低成本执行量子算法的量子电路优化仍然至关重要。

Method: 提出了一种名为AQCEL的量子态依赖电路优化器，通过测量控制量子比特状态来识别和消除不必要的控制操作。关键改进包括：1. 状态标签管理器，减少不必要的状态测量。2. CX对移除过程，消除冗余的门对。

Result: 将AQCEL应用于量子部分展示算法的量子电路，并在IBM量子计算机上进行了实验。结果显示，与传统优化技术和原始AQCEL协议相比，AQCEL显著减少了门数量并提高了保真度。

Conclusion: AQCEL的状态依赖电路优化方法有潜力在近期量子设备上提升量子算法的性能。

Abstract: While the capabilities of quantum hardware have significantly advanced in
recent years, executing quantum algorithms as quantum circuits at the lowest
possible cost remains crucial, regardless of the hardware progress. We are
developing a quantum-state-dependent circuit optimizer called AQCEL. Our
guiding principle, implemented as the AQCEL optimization protocol, is to
optimize quantum circuits by measuring the states of the control qubits to
identify and eliminate unnecessary control operations. In this paper, we
introduce two key improvements: the state label manager that reduces
unnecessary state measurements and the $CX$-pair removal process that
eliminates redundant gate pairs. These enhancements significantly reduce the
number of two-qubit gates, improving the fidelity of quantum circuits executed
on quantum hardware. To demonstrate the effectiveness of our method, we apply
AQCEL to quantum circuits for the quantum parton shower algorithm. Experimental
results using the IBM quantum computer show a substantial reduction in gate
counts and an improvement in fidelity compared to the conventional optimization
technique as well as the original AQCEL protocol. Our findings highlight the
potential of state-dependent circuit optimization for enhancing the performance
of quantum algorithms on near-term quantum devices.

</details>


### [306] [Excitable quantum systems: the bosonic avalanche laser](https://arxiv.org/abs/2509.05290)
*Louis Garbe,Peter Rabl*

Main category: quant-ph

TL;DR: 量子系统通过耗散三模混合过程，受玻色子（准）粒子流驱动，表现出自脉冲行为，能将随机信号转化为准周期脉冲，即使在低平均光子数下，相干共振效应也能在量子层面得以保留。


<details>
  <summary>Details</summary>
Motivation: 研究一个由玻色子（准）粒子流驱动的激光系统的动力学，通过耗散三模混合过程，并探索其在量子 regime下的行为，特别是自脉冲现象。

Method: 采用半经典分析预测了不同的动力学模式，并通过精确的蒙特卡洛模拟将分析扩展到量子 regime。

Result: 发现了自脉冲阶段具有可激发系统的特性，可以将随机输入信号转化为分离的、准周期的输出脉冲。量子模拟表明，即使在平均光子数较低的情况下，相干共振效应也能在巨大的玻色子粒子数涨落中得以保留。

Conclusion: 该系统是可激发量子多体系统的一个有趣模型，在量子探测器或自主量子机器方面具有实际意义，并以超导量子电路为例，讨论了其作为微波光子的数量分辨雪崩探测器的实现。

Abstract: We investigate the dynamics of a lasing system that is driven by a current of
bosonic (quasi-) particles via a dissipative three-mode mixing process. A
semi-classical analysis of this system predicts distinct dynamical regimes,
where both the cavity mode and the gain medium can undergo lasing transitions.
Of particular interest is an intermediate self-pulsing phase that exhibits the
characteristics of an excitable system and converts random input signals into
separated, quasi-periodic pulses at the output. By performing exact Monte-Carlo
simulations, we extend this analysis into the quantum regime and show that
despite being dominated by huge bosonic particle number fluctuations, this
effect of coherence resonance survives even for rather low average photon
numbers. Our system thus represents a intriguing model for an excitable quantum
many-body system with practical relevance for quantum detectors or autonomous
quantum machines. As an illustration, we discuss the realization of this system
with superconducting quantum circuits and its application as a number-resolved
avalanche detector for microwave photons.

</details>


### [307] [Fast entangling gates on fluxoniums via parametric modulation of plasmon interaction](https://arxiv.org/abs/2509.04762)
*Peng Zhao,Peng Xu,Zheng-Yuan Xue*

Main category: quant-ph

TL;DR: 通过利用等离子体相互作用的参数调制，我们提出了一种用于快速纠缠门控的控制策略，以实现可扩展的量子计算。


<details>
  <summary>Details</summary>
Motivation: 为解决超导量子处理器中的频率拥挤、杂散耦合、控制串扰和制造变异性等挑战，需要探索多样化的控制方法以提高系统性能。

Method: 通过对耦合器的跃迁频率进行通量调制，来控制两个通量线的等离子体相互作用。通过在两个通量线的等离子体跃迁的合成频率处对耦合器进行参数驱动，可以激活 bSWAP 类型的相互作用，从而实现计算子空间上的条件相位累积，并实现受控-相位门。

Result: 我们展示了一种简化的驱动脉冲，可以在 100 纳秒内实现保真度低于 10^-4 的 CZ 门。

Conclusion: 所提出的方法具有操作灵活性和可扩展性，有望为开发可扩展的通量线量子处理器提供基础框架。

Abstract: In superconducting quantum processors, exploring diverse control methods
could offer essential versatility and redundancy to mitigate challenges such as
frequency crowding, spurious couplings, control crosstalk, and fabrication
variability, thus leading to better system-level performance. Here we introduce
a control strategy for fast entangling gates in a scalable fluxonium
architecture, utilizing parametric modulation of the plasmon interaction. In
this architecture, fluxoniums are coupled via a tunable coupler, whose
transition frequency is flux-modulated to control the inter-fluxonium plasmon
interaction. A bSWAP-type interaction is activated by parametrically driving
the coupler at the sum frequency of the plasmon transitions of the two
fluxoniums, resulting in the simultaneous excitation or de-excitation of both
plasmon modes. This strategy therefore allow the transitions between
computational states and non-computational plasmon states, enabling the
accumulation of conditional phases on the computational subspace and
facilitating the realization of controlled-phase gates. By focusing on a
specific case of these bSWAP-type interactions, we show that a simple drive
pulse enables sub-100ns CZ gates with an error below $10^{-4}$. Given its
operational flexibility and extensibility, this approach could potentially
offer a foundational framework for developing scalable fluxonium-based quantum
processors.

</details>


### [308] [Unbounded-input explicit Bell inequalities for general quantum networks](https://arxiv.org/abs/2509.04767)
*Yao Xiao,Fenzhuo Guo,Haifeng Dong,Fei Gao*

Main category: quant-ph

TL;DR: 本工作提出了一种基于叶节点数量的非线性贝尔不等式，用于验证多输入量子网络的非局域性，并研究了其性质和应用。


<details>
  <summary>Details</summary>
Motivation: 量子网络中的量子非局域性对于大规模量子通信至关重要，但对其进行表征具有挑战性。

Method: 构造了一类显式的非线性贝尔不等式，利用叶节点数量作为网络参数。建立了双边全关联贝尔不等式和网络贝尔不等式之间的结构联系，实现了最优量子违反的解析推导。还量化了任意两量子比特混合态在可分离测量下的最大违反的上限，并通过 Werner 态的可见性评估了不等式的噪声鲁棒性。

Result: 提出了一类非线性贝尔不等式，能够解析地推导出最优量子违反及其条件。量化了任意两量子比特混合态在可分离测量下的最大违反上限。评估了 Werner 态在噪声环境下的鲁棒性。证明了该不等式可以独立于设备地区分具有相同大小但叶节点数量不同的网络拓扑。

Conclusion: 所提出的非线性贝尔不等式为验证和表征多输入量子网络的非局域性提供了一种有效且通用的方法，并具有区分不同网络拓扑的潜力。

Abstract: Quantum nonlocality in networks featuring multiple independent sources
underpins large-scale quantum communication and poses fundamental challenges
for its characterization. In this work, we construct a family of explicit
nonlinear Bell inequalities to verify the nonlocality across the general
multi-input quantum networks. The construction of these inequalities relies on
the number of leaf nodes, a network parameter that can be identified by a
linear-time algorithm. Our approach establishes a structural connection between
bipartite full-correlation Bell inequalities and network Bell inequalities,
enabling the analytical derivation of optimal quantum violations and the
conditions under which they occur. We further quantify the upper bound on
maximal violations achievable by arbitrary two-qubit mixed states in such
networks, under separable measurements, and evaluate the noise robustness of
the proposed inequalities via the visibilities of Werner states. Finally, we
demonstrate that these inequalities can, in a device-independent manner,
distinguish between network topologies of equal size that differ in the number
of leaf nodes.

</details>


### [309] [Transmon-assisted high-fidelity controlled-Z gates for integer fluxonium qubits](https://arxiv.org/abs/2509.04776)
*J. -H. Wang,H. Xiong,J. -Z. Yang,H. -Y. Zhang,Y. -P. Song,L. -M. Duan*

Main category: quant-ph

TL;DR: 本文研究了利用整数型氟化物实现高保真度两比特量子门，并提出了一种新的耦合架构。


<details>
  <summary>Details</summary>
Motivation: 为了在量子计算中实现高性能的大规模量子处理器，需要探索部分保护的超导量子比特（如整数型氟化物）的两种量子比特门和可扩展架构。

Method: 研究了氟化物-跨电容-氟化物（FTF）耦合架构，并提出两种控制-Z（CZ）量子门方案：一种是通量激活的绝热量子门方案，另一种是微波激活的非绝热量子门方案。

Result: 两种CZ量子门方案均能在几十纳秒内实现大约1e-6的相干误差。

Conclusion: 本文提出的FTF耦合架构和两种CZ量子门方案为未来基于整数型氟化物器件的大规模量子电路的实现提供了思路。

Abstract: Fluxoniums, as partially-protected superconducting qubits are promising to be
employed to build high-performance large-scale quantum processor. The recently
proposed ``integer fluxonium" operates at zero external flux bias, with a
frequency of approximately 3 GHz. Single-qubit gate fidelity has been
demonstrated to exceed $99.9\%$, while two-qubit gate schemes and scalable
architectures remain underexplored. In this work, we investigate a
fluxonium-transmon-fluxonium (FTF) coupling architecture using integer
fluxoniums. We first confirm suppression of $ZZ$ interaction in the FTF system
and then propose two high-fidelity controlled-$Z$ (CZ) gate schemes utilizing
the coupler control: a flux-activated adiabatic gate scheme and a
microwave-activated non-adiabatic gate scheme. Both schemes are capable of
achieving low coherent error on the order of $1 \times 10^{-6}$ within gate
durations of several tens of nanoseconds. Additionally, we discuss a hybrid
circuit system in which an integer fluxonium is coupled to a conventional
fluxonium through a transmon coupler. Our proposal provides insights for future
implementations of large-scale quantum circuits based on integer fluxonium
devices.

</details>


### [310] [Investigation of tantalum films growth for coplanar resonators with internal quality factors above ten million](https://arxiv.org/abs/2509.04917)
*E. V. Zikiy,N. S. Smirnov,E. A. Krivko,A. R. Matanin,A. I. Ivanov,E. I. Malevannaya,V. I. Polozov,S. V. Bukatin,D. A. Baklykov,I. A. Stepanov,S. A. Kotenkov,S. P. Bychkov,I. A. Ryzhikov,A. V. Andriyash,I. A. Rodionov*

Main category: quant-ph

TL;DR: α-钽 on Si is good for quantum circuits, but its growth is unclear. We found that the substrate's Debye temperature, not just temperature, controls the phase. α-钽 only grows on a β-钽 layer (7-10 nm). This affects the critical temperature (3.77-4.39 K). We made high-quality α-钽 resonators with Q > 10 million.


<details>
  <summary>Details</summary>
Motivation: The growth mechanism of alpha-tantalum on silicon, a promising platform for superconducting quantum circuits, is poorly understood, and prior assumptions about substrate temperature influence were questioned.

Method: The study involved growing alpha-tantalum films on various substrates and experimentally confirming the role of substrate material Debye temperature on phase selection. They also identified the necessity of a beta-tantalum underlayer for alpha-tantalum growth and compared Al and Ta coplanar resonators.

Result: It was confirmed that alpha-tantalum growth is dependent on the substrate's Debye temperature, contradicting previous assumptions about substrate temperature. Alpha-tantalum was found to grow only after a 7-10 nm thick beta-tantalum underlayer. The critical temperature of alpha-tantalum films ranged from 3.77 K to 4.39 K with varying thicknesses. High-quality tantalum resonators with an internal quality factor exceeding 10 million were demonstrated.

Conclusion: The Debye temperature of the substrate is the key factor determining the phase selection in tantalum films, and a beta-tantalum underlayer is crucial for alpha-tantalum growth. Tantalum resonators on silicon show excellent performance, comparable to aluminum resonators.

Abstract: Alpha-tantalum on silicon is a promising platform for high-coherence
superconducting quantum circuits. However, the growth mechanism of
alpha-tantalum on silicon remains poorly understood. We present a comprehensive
study on alpha-tantalum films growth on various substrate. The decisive role of
a substrate material Debye temperature on phase selection mechanism in tantalum
films growth is experimentally confirmed, contradicting the prior assumptions
on substrate temperature influence. Crucially, we confirm that alpha-tantalum
starts growing only after a 7-10 nm thick beta-tantalum underlayer. It results
in ranging the critical temperature of {\alpha}-Ta films from 3.77 K to 4.39 K
for the total thickness from 20 to 150 nm, respectively. Finally, we compared
high-quality Al and Ta coplanar resonators on silicon, demonstrating compact
tantalum resonators (4/10.5/4 um) with an internal quality factor exceeding 10
million at single-photon excitation powers.

</details>


### [311] [Hierarchy of Qubit Dynamical Maps in the Presence of Symmetry and Coherence](https://arxiv.org/abs/2509.04790)
*Unnati Akhouri*

Main category: quant-ph

TL;DR: 全局能量守恒和相干性资源会影响量子热力学操作的局部动力学，U(1)守恒通过泡利字符串的电荷守恒限制了量子热力学操作，并且U(1)动力学不能从对角热态生成局部相干性。


<details>
  <summary>Details</summary>
Motivation: 研究对称性与热力学转化之间的关系，以及全局能量守恒和相干性资源如何影响子系统的局部动力学。

Method: 通过分析U(1)守恒如何通过泡利字符串的电荷守恒来限制量子热力学操作，并提出一个无解定理证明U(1)动力学不能从对角热态生成局部相干性。通过一个双量子比特构造来实现超越热力学操作的吉布斯保持变换，并演示了在功提取和状态可辨别性方面的可测量热力学优势。

Result: U(1)守恒通过电荷守恒限制了量子热力学操作，U(1)动力学不能从对角热态生成局部相干性，热力学操作被限制在相位协同映射，量子相干性在增强热力学性能方面发挥着基本作用。

Conclusion: 全局能量守恒和相干性资源深刻影响量子热力学操作的局部动力学。U(1)守恒通过电荷守恒限制了量子热力学操作，量子相干性在增强热力学性能方面发挥着基本作用。

Abstract: We investigate the relationship between symmetries and thermodynamic
transformations by analyzing how global energy conservation and coherence
resources affect the local dynamics of subsystems. We prove that U(1)
conservation fundamentally constrains quantum thermodynamic operations through
charge conservation of Pauli strings. Our no-go theorem shows that U(1)
dynamics cannot generate local coherence from diagonal thermal states,
restricting thermal operations to phase-covariant maps. Breaking this hierarchy
requires environmental coherence with odd charge parity that couples unequal
energy states. We establish the minimal resource requirements through a
two-qubit construction that achieves Gibbs-preserving transformations beyond
thermal operations. We demonstrate measurable thermodynamic advantages in work
extraction and state distinguishability, revealing the fundamental role of
quantum coherence in enhancing thermodynamic performance.

</details>


### [312] [Hybrid Quantum-Classical Scheduling with Problem-Aware Calibration on a Quantum Annealer](https://arxiv.org/abs/2509.04808)
*Krzysztof Giergiel,Y. Sam Yang,Anthony B. Murphy*

Main category: quant-ph

TL;DR: 量子退火在体育营房间调度问题上的应用，通过结合经典启发式和量子子程序，并提出了一种新的问题感知校准方案，结果表明最佳退火时间与D-Wave Advantage 2原型相匹配，但性能随问题规模增大而下降。


<details>
  <summary>Details</summary>
Motivation: 由于现有量子退火平台的硬件限制，无法将实际的体育营房间调度问题完全嵌入，因此需要结合经典启发式方法和量子子程序，以解决现实世界中的组合优化问题。

Method: 提出了一种改进的公式和新颖的问题感知校准方案，该方案利用多量子比特统计来提高退火性能，并结合经典启发式方法和量子子程序来处理无法完全嵌入现有量子退火平台的问题。

Result: 研究结果表明，最佳退火时间与D-Wave Advantage 2原型（约100 ns）的相干时间一致，更长的退火时间反而导致结果变差。此外，尽管进行了校准和公式改进，但随着连接性和问题规模的增加，量子退火的性能仍然会下降。

Conclusion: 当前的量子退火硬件在处理具有高连接性和大问题规模的组合优化问题时存在局限性，需要提高量子比特质量和参数精度。通过结合经典方法和量子子程序以及进行问题感知校准，可以提高量子退火在实际问题中的应用效用。

Abstract: We evaluate the application of quantum annealing (QA) to a real-world
combinatorial optimisation problem-room scheduling for sports camps at the
Australian Institute of Sport-using both classical and quantum approaches. Due
to current hardware limitations, the full problem cannot be embedded on
existing QA platforms, motivating a hybrid method combining classical
heuristics with quantum subroutines. We develop an improved formulation and a
novel problem-aware calibration scheme, leveraging multi-qubit statistics to
enhance the annealing performance. Our results show that the optimal annealing
time aligns with the coherence time of the D-Wave Advantage 2 prototype
(approximately 100 ns), with longer anneals yielding poorer outcomes before
slow thermal recovery. Despite calibration and formulation improvements, QA
performance degrades with increased connectivity and problem size, highlighting
the need for improved qubit quality and parameter precision. These findings
clarify the capabilities and limitations of current QA hardware and suggest
strategies for extending its practical utility through hybrid methods and
informed calibration.

</details>


### [313] [Nonintegrability of the Fredkin spin chain and its truncated versions](https://arxiv.org/abs/2509.04838)
*Wen-Ming Fan,Kun Hao,Yang-Yang Chen,Kun Zhang,Xiao-Hui Wang,Vladimir Korepin*

Main category: quant-ph

TL;DR: Fredkin spin chain is not integrable, as it lacks local conserved charges under both periodic and open boundary conditions. Truncated versions also lack these charges, suggesting integrability is rare in models with three-site interactions.


<details>
  <summary>Details</summary>
Motivation: To determine whether the Fredkin spin chain, despite its rich structures and known ground state, is integrable, as the absence of conserved charges typically implies nonintegrability.

Method: Rigorous analytical calculations were performed to demonstrate the absence of local conserved charges in the Fredkin spin chain under both periodic and open boundary conditions. This analysis was also extended to truncated versions of the model.

Result: The Fredkin spin chain, under both periodic and open boundary conditions, was found to lack local conserved charges, confirming its nonintegrable nature. Truncated Fredkin spin chains also lack local conserved charges.

Conclusion: The Fredkin spin chain is nonintegrable. Integrable models involving three-site interactions are generally rare.

Abstract: Conservation laws serve as the hallmark of integrability. The absence of
conserved charges typically implies that the model is nonintegrable. The
recently proposed Fredkin spin chain exhibits rich structures, and its ground
state is analytically known. However, whether the Fredkin spin chain is
integrable remains an open question. In this work, through rigorous analytical
calculations, we demonstrate that the Fredkin spin chain, under both periodic
and open boundary conditions, lacks local conserved charges, thereby confirming
its nonintegrable nature. Furthermore, we find that when one or a portion of
the Hamiltonian terms are removed (referred to as the truncated Fredkin spin
chain), local conserved charges are still absent. Our findings suggest that in
models involving three-site interactions, integrable models are generally rare.

</details>


### [314] [Quantum non-Gaussian high Fock states of light pulses and their superpositions](https://arxiv.org/abs/2509.04891)
*G. P. Teja,Chandan Kumar,Lukáš Lachman,Radim Filip*

Main category: quant-ph

TL;DR: 该研究提出了一种结合光学延迟元件的原子-光腔相互作用协议，能够高效制备高达十个光子的Fock态及其叠加态，并证明了其量子非高斯特性。该协议在制备叠加态方面成功率可达50%，并评估了其在量子网络和传感等应用中的鲁棒性、团聚能力和传感能力。


<details>
  <summary>Details</summary>
Motivation: 制备具有可证明的量子非高斯特性的高Fock态光脉冲及其叠加态仍然是一个挑战。现有方法如条件测量法和非线性光学方法存在局限性。原子-光腔相互作用被认为是制备Fock态的可行替代方案。

Method: 通过优化结合光学延迟元件的原子-光腔相互作用协议，对Fock态和Fock态叠加态进行滤波和制备。利用量子非高斯判据来验证制备出的态的特性。评估了制备出的态在鲁棒性、团聚能力和传感能力方面的表现。

Result: 成功滤波高达十个光子的Fock态，成功率达20%。制备的Fock态叠加态（高达两个光子）具有可证明的量子非高斯相干性，成功率达50%。评估结果表明，该协议在量子网络和传感应用中具有潜力。

Conclusion: 所提出的结合光学延迟元件的原子-光腔相互作用协议，能够高效地制备高 Fock 态及其叠加态，并展现出优越的量子非高斯特性。该方法在制备精度和应用潜力方面优于传统的单光子探测方法，为实现实用的量子光学器件提供了新的途径。

Abstract: The generation of high Fock states of light pulses and their superpositions
with provable quantum non-Gaussian features is still very challenging, although
the power of conditional methods to herald the approximate state from the
available Gaussian states is growing. The atom-light interaction in the high-Q
cavity has been considered a viable alternative to the heralded Fock states of
the light pulses from nonlinear optics limited to three-photon Fock states for
the last decade. Here, by optimizing the realistic protocol combining it with
available optical delay elements we conclusively predict filtering of Fock
states up to ten photons with a high success rate of $20\%$ using a hierarchy
of quantum non-Gaussian criteria. Moreover, the filtering protocol enables the
preparation of superposition of Fock states and we analyse this emerging case
up to two photons with with provable quantum non-Gaussian coherence and high
success rate $50\%$. To demonstrate their quality for applications, we evaluate
the robustness of such features, the bunching capability in a linear network,
and the sensing capability to estimate the magnitude of unknown force, noise
and phase, These assessments outline the essential conditions and application
criteria for realistic optical cavity QED interaction on light pulses to
outperform photon detection methods.

</details>


### [315] [Power-efficiency-stability trade-off in quantum information engines](https://arxiv.org/abs/2509.04901)
*Milton Aguilar,Cüneyt Ünal,Eric Lutz*

Main category: quant-ph

TL;DR: 这项研究提出了一个有限时间量子卡诺信息引擎，它使用信息库代替传统的冷浴。研究表明，该引擎可以在有限的功输出和功输出波动下达到最大效率，并且其相对功输出波动可能小于传统的卡诺热机，这对于实际应用具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 研究效率、功率和稳定性之间的权衡，特别是在有限时间的量子热力学系统中。

Method: 分析了有限时间量子卡诺信息引擎的功输出的均值和方差，并将其与量子卡诺热机进行了比较。

Result: 发现在有限的功输出和功输出波动下可以达到最大效率，并且该信息引擎的相对功输出波动可能小于量子卡诺热机。

Conclusion: 有限时间量子卡诺信息引擎比量子卡诺热机更稳定，这对于实际应用来说是一个重要的优点。

Abstract: Efficiency and power are two central measures of the performance of thermal
machines. We here study the power-efficiency-stability trade-off in a
finite-time quantum Carnot information engine, in which an information
reservoir replaces the usual cold bath of a quantum Carnot engine. We
analytically evaluate mean and variance of the work output, and demonstrate
that maximum efficiency can be reached at both finite work output and finite
work output fluctuations. We additionally show that the relative work output
fluctuations may be smaller than those of the corresponding Carnot heat engine.
This result implies that the finite-time quantum Carnot information engine can
be more stable than the quantum Carnot heat engine, an important property for
practical applications.

</details>


### [316] [RobQFL: Robust Quantum Federated Learning in Adversarial Environment](https://arxiv.org/abs/2509.04914)
*Walid El Maouaki,Nouhaila Innan,Alberto Marchisio,Taoufik Said,Muhammad Shafique,Mohamed Bennai*

Main category: quant-ph

TL;DR: QFL在对抗性噪声下是脆弱的，RobQFL通过在联邦循环中嵌入对抗性训练来提高其鲁棒性，并提出了两个新的评估指标：Accuracy-Robustness Area和Robustness Volume。


<details>
  <summary>Details</summary>
Motivation: 现有的量子联邦学习（QFL）在隐私保护和量子计算优势相结合的同时，其对对抗性噪声的鲁棒性仍然未知。

Method: 提出了一种名为RobQFL的鲁棒量子联邦学习方法，该方法将对抗性训练直接嵌入到联邦学习的循环中。RobQFL提供了可调参数，包括客户端覆盖率（γ）、扰动调度（固定ε或ε-mixes）和优化策略（微调或从头开始训练）。通过这些参数，研究人员探索了γ×ε的参数空间，并提炼出两个评估指标：Accuracy-Robustness Area和Robustness Volume。

Result: 在包含15个客户端的MNIST和Fashion-MNIST数据集的模拟中（包括IID和Non-IID条件），仅对20-50%的客户端进行对抗性训练，可以在ε≤0.1的条件下将准确率提高约15个百分点，而干净准确率的损失小于2个百分点。微调可以额外提高3-5个百分点的准确率。当客户端覆盖率达到75%时，采用适度的ε-mix策略是最佳选择，而高ε的调度仅在100%覆盖率下才有效。数据异质性（例如标签排序的Non-IID分割）会使鲁棒性减半，表明其是主要的风险。

Conclusion: RobQFL能够有效提高QFL在对抗性噪声下的鲁棒性，并且可以通过调整客户端覆盖率、扰动调度和优化策略来平衡准确率和鲁棒性。数据异质性是影响鲁棒性的一个关键因素。

Abstract: Quantum Federated Learning (QFL) merges privacy-preserving federation with
quantum computing gains, yet its resilience to adversarial noise is unknown. We
first show that QFL is as fragile as centralized quantum learning. We propose
Robust Quantum Federated Learning (RobQFL), embedding adversarial training
directly into the federated loop. RobQFL exposes tunable axes: client coverage
$\gamma$ (0-100\%), perturbation scheduling (fixed-$\varepsilon$ vs
$\varepsilon$-mixes), and optimization (fine-tune vs scratch), and distils the
resulting $\gamma \times \varepsilon$ surface into two metrics:
Accuracy-Robustness Area and Robustness Volume. On 15-client simulations with
MNIST and Fashion-MNIST, IID and Non-IID conditions, training only 20-50\%
clients adversarially boosts $\varepsilon \leq 0.1$ accuracy $\sim$15 pp at $<
2$ pp clean-accuracy cost; fine-tuning adds 3-5 pp. With $\geq$75\% coverage, a
moderate $\varepsilon$-mix is optimal, while high-$\varepsilon$ schedules help
only at 100\% coverage. Label-sorted non-IID splits halve robustness,
underscoring data heterogeneity as a dominant risk.

</details>


### [317] [Artificial intelligence for representing and characterizing quantum systems](https://arxiv.org/abs/2509.04923)
*Yuxuan Du,Yan Zhu,Yuan-Hang Zhang,Min-Hsiu Hsieh,Patrick Rebentrost,Weibo Gao,Ya-Dong Wu,Jens Eisert,Giulio Chiribella,Dacheng Tao,Barry C. Sanders*

Main category: quant-ph

TL;DR: AI can help characterize large-scale quantum systems by predicting properties and constructing state surrogates, with applications in certification, benchmarking, and algorithm enhancement.


<details>
  <summary>Details</summary>
Motivation: Efficiently characterizing large-scale quantum systems is a major challenge due to exponential Hilbert space scaling. AI's pattern recognition and function approximation capabilities offer a promising solution.

Method: The paper reviews three AI paradigms (machine learning, deep learning, language models) for quantum system characterization, focusing on their application to quantum property prediction and surrogate quantum state construction.

Result: AI, particularly deep learning and language models, can be integrated into quantum system characterization to address challenges in quantum property prediction and the construction of surrogates for quantum states.

Conclusion: AI offers a powerful toolkit for characterizing large-scale quantum systems, with significant potential for advancing quantum science through applications in certification, benchmarking, algorithm enhancement, and understanding complex quantum matter. Key challenges and future prospects are discussed.

Abstract: Efficient characterization of large-scale quantum systems, especially those
produced by quantum analog simulators and megaquop quantum computers, poses a
central challenge in quantum science due to the exponential scaling of the
Hilbert space with respect to system size. Recent advances in artificial
intelligence (AI), with its aptitude for high-dimensional pattern recognition
and function approximation, have emerged as a powerful tool to address this
challenge. A growing body of research has leveraged AI to represent and
characterize scalable quantum systems, spanning from theoretical foundations to
experimental realizations. Depending on how prior knowledge and learning
architectures are incorporated, the integration of AI into quantum system
characterization can be categorized into three synergistic paradigms: machine
learning, and, in particular, deep learning and language models. This review
discusses how each of these AI paradigms contributes to two core tasks in
quantum systems characterization: quantum property prediction and the
construction of surrogates for quantum states. These tasks underlie diverse
applications, from quantum certification and benchmarking to the enhancement of
quantum algorithms and the understanding of strongly correlated phases of
matter. Key challenges and open questions are also discussed, together with
future prospects at the interface of AI and quantum science.

</details>


### [318] [Geometric Discord of any arbitrary dimensional bipartite system and its application in quantum key distribution](https://arxiv.org/abs/2509.04927)
*Rashi Jain,Satyabrata Adhikari*

Main category: quant-ph

TL;DR: 本文研究了几何量子关联（GQD）在量子密钥分发（QKD）中的应用，推导了GQD的解析表达式，并将其应用于QKD协议，为可蒸馏密钥率提供了下界，同时分析了GQD变化对密钥生成的影响，并发现即使在某些非纠缠态下也能成功生成密钥。


<details>
  <summary>Details</summary>
Motivation: 量子纠缠是量子密钥分发（QKD）中的关键资源，但量子关联（如几何量子关联GQD）在QKD中也起着重要作用。

Method: 1. 推导出两量子比特和d1⊗d2维量子系统GQD的解析表达式。 2. 将GQD应用于QKD研究，推导出可蒸馏密钥率KD的下界。 3. 分析GQD变化（增加、减少或保持不变）对KD行为的影响。 4. 探讨在非纠缠态（可分离态或正部分转置纠缠态）下生成可蒸馏密钥的可能性。

Result: 1. 得到了两量子比特和d1⊗d2维量子系统GQD的解析表达式。 2. 提出了KD的下界，该下界依赖于特定量子态的GQD。 3. 发现GQD的特定范围不能保证成功生成密钥。 4. 通过具体例子分析了GQD变化对KD行为的影响。 5. 证明了即使在某些非纠缠态下也能生成可蒸馏密钥。

Conclusion: 量子关联，特别是GQD，在QKD协议中扮演着重要角色，并且在某些情况下，即使没有量子纠缠，也可以成功生成密钥，这表明量子纠缠并非QKD协议成功的绝对必要条件。

Abstract: Entangled quantum states are regarded as a key resource in quantum key
distribution (QKD) protocols. However, quantum correlations, other than
entanglement can also play a significant role the QKD protocols. In this work,
we will focus on one such measure of quantum correlation, known as geometric
quantum discord (GQD). Firstly, we derive an analytical expression of GQD for
two-qutrit quantum systems and further generalize it for $d_1\otimes d_2$
dimensional systems. Next, we apply the concept of GQD in studying QKD. In
particular, we derive the lower bound for a distillable secret key rate $K_D$
in terms of GQD when two communicating parties uses private states for
generating a secret key in the presence of an eavesdropper. The lower bound of
$K_D$ depends upon the GQD of $\frac{\sigma_0+\sigma_1}{2}$ and
$\frac{\sigma_2+\sigma_3}{2}$, where $\sigma_i$'s, $i=0,1,2,3$ are the density
matrices. We find that for a certain range of GQD, the successful generation of
the secret key is not guaranteed. We further study the behavior of distillable
key rate when the geometric discord of $\frac{\sigma_0+\sigma_1}{2}$ and
$\frac{\sigma_2+\sigma_3}{2}$ increases, decreases or remains constant, with
the help of a few examples. Moreover, we find that even when $\sigma_i$'s are
separable or positive partial transpose entangled states, the distillable key
can still be generated. %Thus, indicating that entanglement is not strictly
necessary for a successful QKD protocol.

</details>


### [319] [Dynamically encircling an exceptional point through phase-tracked closed-loop control](https://arxiv.org/abs/2509.04940)
*Sen Zhang,Yangyu Huang,Lei Yu,Kaixuan He,Ning Zhou,Dingbang Xiao,Xuezhong Wu,Franco Nori,Hui Jing,Xin Zhou*

Main category: quant-ph

TL;DR: 该研究提出了一种利用锁相环（PLL）技术动态地、平滑地包围非厄米哈密顿量中的厄米特点（EPs）的方法，从而在黎曼流形上进行受控的穿越，并利用微机电器件进行了实验验证。


<details>
  <summary>Details</summary>
Motivation: 传统的探测黎曼流形状态信息的方法是静态测量，但由于非绝热跃迁的存在，连续包围厄米特点（EPs）并保持共振非常困难。

Method: 提出一种利用锁相环（PLL）技术，将稳态的激励频率与其响应相位相关联，从而在黎曼流形上进行受控穿越。

Result: 在全由电控制的非厄米微机电器件中，实现了厄米特点的相位锁定动态包围，展示了鲁棒的原位可调性。

Conclusion: 所提出的相位追踪动态包围方法为探索非厄米拓扑提供了新的途径，并成功在实际器件中得到验证。

Abstract: The intricate complex eigenvalues of non-Hermitian Hamiltonians manifest as
Riemann surfaces in control parameter spaces. At the exceptional points (EPs),
the degeneracy of both eigenvalues and eigenvectors introduces noteworthy
topological features, particularly during the encirclement of the EPs.
Traditional methods for probing the state information on the Riemann surfaces
involve static measurements; however, realizing continuous encircling remains a
formidable challenge due to non-adiabatic transitions that disrupt the
transport paths. Here we propose an approach leveraging the phase-locked loop
(PLL) technique to facilitate smooth, dynamic encircling of EPs while
maintaining resonance. Our methodology strategically ties the excitation
frequencies of steady states to their response phases, enabling controlled
traversal along the Riemann surfaces of real eigenvalues. This study advances
the concept of phase-tracked dynamical encircling and explores its practical
implementation within a fully electrically controlled non-Hermitian
microelectromechanical system, highlighting robust in-situ tunability and
providing methods for exploring non-Hermitian topologies.

</details>


### [320] [Scalable parallel simulation of quantum circuits on CPU and GPU systems](https://arxiv.org/abs/2509.04955)
*Guolong Zhong,Yi Fan,Zhenyu Li*

Main category: quant-ph

TL;DR: 该研究为Q$^2$Chemistry软件包提供了一个全面的并行化解决方案，通过引入批量缓冲重叠处理、依赖感知门收缩和交错多门并行等优化，显著提高了CPU和GPU平台上全幅度模拟器的性能，使其在各种电路类型上始终优于当前最先进的开源模拟器。


<details>
  <summary>Details</summary>
Motivation: 由于当前NISQ时代量子硬件的限制，经典模拟对于开发量子算法仍然至关重要。

Method: 通过引入批量缓冲重叠处理、依赖感知门收缩和交错多门并行等优化，对Q$^2$Chemistry软件包进行全面的并行化。

Result: 优化后的Q$^2$Chemistry在CPU和GPU平台上显著提高了全幅度模拟器的性能，并且在各种电路类型上始终优于当前最先进的开源模拟器，展示了混合级别并行在HPC系统中的有效性。

Conclusion: Q$^2$Chemistry的优化方案能够有效处理大规模量子模拟，具有高效率和高可移植性。

Abstract: Quantum computing enables parallelism through superposition and entanglement
and offers advantages over classical computing architectures. However, due to
the limitations of current quantum hardware in the noisy intermediate-scale
quantum (NISQ) era, classical simulation remains a critical tool for developing
quantum algorithms. In this research, we present a comprehensive
parallelization solution for the Q$^2$Chemistry software package, delivering
significant performance improvements for the full-amplitude simulator on both
CPU and GPU platforms. By incorporating batch-buffered overlap processing,
dependency-aware gate contraction and staggered multi-gate parallelism, our
optimizations significantly enhance the simulation speed compared to
unoptimized baselines, demonstrating the effectiveness of hybrid-level
parallelism in HPC systems. Benchmark results show that Q$^2$Chemistry
consistently outperforms current state-of-the-art open-source simulators across
various circuit types. These benchmarks highlight the capability of
Q$^2$Chemistry to effectively handle large-scale quantum simulations with high
efficiency and high portability.

</details>


### [321] [High-fidelity two-qubit gates with transmon qubits using bipolar flux pulses and tunable couplers](https://arxiv.org/abs/2509.04965)
*Nikita S. Smirnov,Aleksei R. Matanin,Anton I. Ivanov,Vladimir V. Echeistov,Nikita D. Korshakov,Elizaveta I. Malevannaya,Viktor I. Polozov,Bogdan K. Getmanov,Anastasia A. Solovieva,Daria A. Moskaleva,Elizaveta A. Krivko,Dmitry O. Moskalev,Dmitry A. Mikhalin,Igor S. Korobenko,Denis E. Shirokov,Ilya A. Ryzhikov,Alexander V. Andriyash,Ilya A. Rodionov*

Main category: quant-ph

TL;DR: 通过控制脉冲和可调耦合器实现高保真度两比特门。


<details>
  <summary>Details</summary>
Motivation: 高保真度两比特门对于可扩展的量子计算至关重要。

Method: 提出一种基于超导transmon量子比特和控制脉冲传递协议的方案，该方案仅通过独立的任意波形发生器脉冲来调制任意受控相位门。结合可调耦合器设计和双极磁通脉冲，实现高保真度两比特门，性能达到99.5%。

Result: 实现了99.5%保真度的两比特门，并最小化了残余ZZ耦合，内置回声式低频噪声保护，以及时间尺度控制脉冲可重复性。数值模拟表明，错误率可低于1e-4，并在4量子比特处理器上证实了该方案的可扩展潜力。

Conclusion: 提出的方案结合了可调耦合器和双极磁通脉冲的优点，可以实现高保真度、易于校准的两比特门，并具有良好的可扩展性。

Abstract: High-fidelity two-qubit gates are essential for scalable quantum computing.
We present a scheme based on superconducting transmon qubits and a control
pulse delivery protocol that enables arbitrary controlled-phase gates modulated
solely by an independent arbitrary waveform generator pulse. We combined a
tunable coupler design with bipolar flux-pulsing to demonstrate a high-fidelity
gate with a performance of $99.5\%$. Our gates inherit the advantages of both
approaches: minimal residual ZZ coupling, built-in echo-like low-frequency
noise protection, and time-scale control pulse reproducibility, while remaining
easy to calibrate. We optimize the system energy levels to mitigate leakage to
the coupler and suppress residual interactions. Numerical simulations of the
scheme as three qutrits indicate that an error below $1 \times 10^{-4}$ is
achievable. We confirm the scalability potential of the proposed scheme on a
high-fidelity 4-qubit quantum processor.

</details>


### [322] [Exploring an implementation of quantum learning pipeline for support vector machines](https://arxiv.org/abs/2509.04983)
*Mario Bifulco,Luca Roversi*

Main category: quant-ph

TL;DR: 本研究提出了一种结合量子核方法和量子退火的量子支持向量机（SVM）学习方法。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索支持向量机（SVM）学习的全量子化方法，通过集成量子核方法和量子退火优化，以期在量子计算环境中实现高效的学习。

Method: 该方法通过构建多种量子核（使用不同的特征映射和量子比特配置），并利用核目标对齐（KTA）进行评估。SVM 的对偶问题被转化为二次无约束二元优化（QUBO）问题，以便在量子退火器上求解。

Result: 实验结果表明，高核对齐度和合适的正则化参数可以带来有竞争力的性能，其中最佳模型的 F1 分数达到了 90%。

Conclusion: 研究结论是，端到端的量子学习流程是可行的，并且混合量子架构在量子高性能计算（QHPC）中有潜在应用价值。

Abstract: This work presents a fully quantum approach to support vector machine (SVM)
learning by integrating gate-based quantum kernel methods with quantum
annealing-based optimization. We explore the construction of quantum kernels
using various feature maps and qubit configurations, evaluating their
suitability through Kernel-Target Alignment (KTA). The SVM dual problem is
reformulated as a Quadratic Unconstrained Binary Optimization (QUBO) problem,
enabling its solution via quantum annealers. Our experiments demonstrate that a
high degree of alignment in the kernel and an appropriate regularization
parameter lead to competitive performance, with the best model achieving an
F1-score of 90%. These results highlight the feasibility of an end-to-end
quantum learning pipeline and the potential of hybrid quantum architectures in
quantum high-performance computing (QHPC) contexts.

</details>


### [323] [Surpassing the wave-particle duality relation via feed-forward of phase information](https://arxiv.org/abs/2509.04989)
*Elisabeth Meusert,Uwe Schilling,Marc-Oliver Pleinert,Joachim von Zanthier*

Main category: quant-ph

TL;DR: 量子力学中的互补性原理在双缝干涉实验中得到体现，该原理指出干涉度和路径可辨识度之间存在固有的限制。本研究提出了一种新的方法，通过在粒子被探测后进行“前馈”操作，可以使路径可辨识度在特定情况下超越传统的互补性限制，甚至在全局范围内实现。


<details>
  <summary>Details</summary>
Motivation: 量子力学中的互补性原理是其核心特征之一，该原理在双缝干涉实验中表现为干涉度和路径可辨识度之间的互易关系。然而，该原理设定的限制是否为绝对，以及是否存在突破该限制的可能性，是值得深入探讨的问题。

Method: 本研究提出了一种基于“前馈”协议的方法。该协议在量子粒子（例如光子）在探测屏上成像后，根据其相位信息，动态地调整测量方式，以最大化路径可辨识度。具体而言，该方法利用了路径可辨识度与量子物体的相位信息之间的相关性。

Result: 研究表明，在特定条件下，路径可辨识度可以超过由互补性原理（或称对偶关系）设定的经典限制。通过分析和数值模拟，作者证实了他们提出的前馈协议可以实现这一点，即使在全局范围内也能够超越互补性限制，从而获得更多的路径信息。

Conclusion: 本研究成功地提出了一种能够超越量子力学互补性原理限制的路径可辨识度测量方法。通过引入前馈协议，利用粒子被探测后的相位信息，可以在特定情况下甚至全局范围内获得比传统理论预测更多的路径信息，这为理解和应用量子互补性原理提供了新的视角。

Abstract: Complementarity constitutes a central aspect of quantum theory. It manifests
itself, for example, in a two-way interferometer, where the simultaneous
observation of an interference pattern and the acquisition of which-way
information are limited by an inequality known as the duality relation. Here,
we investigate which-way information in a double-slit interferometer and show
that it can be correlated to the phase of the quantum object at the detection
screen, leading to a phase-dependent which-way knowledge. In specific cases,
this knowledge can locally exceed the limit set by the duality relation. Based
on this observation, we propose a feed-forward protocol that aims at maximizing
the which-way information locally for each phase after the particle has been
recorded on the screen. This allows us to surpass the duality relation limit
even globally. We present analytical results as a proof of principle of our
protocol as well as numerical outcomes quantifying the amount of maximally
achievable which-way knowledge.

</details>


### [324] [A Modular, Adaptive, and Scalable Quantum Factoring Algorithm](https://arxiv.org/abs/2509.05010)
*Alok Shukla,Prakash Vedula*

Main category: quant-ph

TL;DR: Shor算法的模块化改进版本，减少了对相干量子比特的需求，提高了NISQ硬件的适用性。


<details>
  <summary>Details</summary>
Motivation: Shor算法在NISQ硬件上不实用，需要大量相干量子比特和深度电路。

Method: 将Shor算法的相位估计重构为浅层、独立的电路块，支持顺序或并行执行，并结合了重叠机制。

Result: 减少了计数寄存器的量子比特数量（从数千个减少到几个），而工作寄存器需求不变；数值模拟验证了正确性并显示了显著的计数量子比特缩减。

Conclusion: 提出的模块化Shor算法比标准版本更适合近期的量子硬件。

Abstract: Shor's algorithm for integer factorization offers an exponential speedup over
classical methods but remains impractical on Noisy Intermediate Scale Quantum
(NISQ) hardware due to the need for many coherent qubits and very deep
circuits. Building on our recent work on adaptive and windowed phase-estimation
methods, we have developed a modular, windowed formulation of Shor's algorithm
that mitigates these limitations by restructuring phase estimation into
shallow, independent circuit blocks that can be executed sequentially or in
parallel, followed by lightweight classical postprocessing. This approach
allows for a reduction in the size of the phase (or counting) register from
thousands of qubits down to a small, fixed block size of only a few qubits (for
example, three or four), while leaving the work register requirement unchanged.
The independence of the blocks allows for parallel execution and makes the
approach more compatible with near-term hardware than the standard Shor's
formulation. An additional feature of the framework is the overlap mechanism,
which introduces redundancy between blocks and enables robust reconstruction of
phase information, though zero-overlap configurations can also succeed in
certain regimes. Numerical simulations verify the correctness of the modular
formulation while also showing substantial reductions in counting qubits per
block.

</details>


### [325] [Embezzlement as a "Self-Test" for Infinite Copies of Entangled States](https://arxiv.org/abs/2509.05036)
*Li Liu*

Main category: quant-ph

TL;DR: entanglement embezzlement requires catalysts with infinite, structured copies of the target state, which can be formalized using C*-algebras and leads to an elementary proof that universal embezzlers generate Type III_1 factors.


<details>
  <summary>Details</summary>
Motivation: The paper investigates the operator-algebraic structure behind entanglement embezzlement, a process where a catalyst entangled state can generate arbitrary target entangled states without being consumed.

Method: The study formalizes the constraints on catalyst states using C*-algebraic tools, showing they must contain infinitely many mutually commuting, locally structured copies of the target state. This property is used to provide an elementary proof that universal embezzlers generate Type III_1 von Neumann factors.

Result: The analysis reveals that a catalyst state must possess infinite, self-similar copies of the target state for embezzlement to occur. This structural property leads to an elementary proof that universal embezzlers generate Type III_1 von Neumann factors, without relying on modular theory.

Conclusion: The structural requirements for entanglement embezzlement are clarified, and the results offer new conceptual tools for analyzing state certification in infinite-dimensional quantum systems.

Abstract: We investigate the operator-algebraic structure underlying entanglement
embezzlement, a phenomenon where a fixed entangled state (the catalyst) can be
used to generate arbitrary target entangled states without being consumed. We
show that the ability to embezzle a target state $g$ imposes strong internal
constraints on the catalyst state $f$: specifically, $f$ must contain
infinitely many mutually commuting, locally structured copies of $g$. This
property is formalized using C*-algebraic tools and is analogous to a form of
self-testing, certifying the presence of infinite copies of $g$ within $f$.
Using this infinite-copy certification, we give an elementary proof that any
universal embezzler must generate a Type~III$_1$ von Neumann factor, avoiding
the use of modular theory. Our results clarify the structural requirements for
embezzlement and provide new conceptual tools for analyzing state certification
in infinite-dimensional quantum systems.

</details>


### [326] [QCA-MolGAN: Quantum Circuit Associative Molecular GAN with Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2509.05051)
*Aaron Mark Thomas,Yu-Cheng Chen,Hubert Okadome Valencia,Sharu Theresa Jose,Ronin Wu*

Main category: quant-ph

TL;DR: We developed QCA-MolGAN, a novel quantum circuit Born machine (QCBM)-enabled Generative Adversarial Network (GAN), for generating drug-like molecules. It uses a QCBM as a learnable prior distribution and a multi-agent reinforcement learning network to optimize drug properties like QED, LogP, and SA. Experiments show it improves property alignment and balances chemical properties.


<details>
  <summary>Details</summary>
Motivation: Designing novel drug molecules with desired properties from a vast chemical space is a key challenge in drug discovery, and generative models offer promising solutions.

Method: We propose QCA-MolGAN, integrating a QCBM as a learnable prior distribution within a GAN framework. The QCBM's latent space is trained to align with high-level features from the GAN's discriminator. A multi-agent reinforcement learning network is also incorporated to guide molecular generation, optimizing QED, LogP, and SA scores simultaneously.

Result: Experimental results show that our approach effectively enhances the property alignment of generated molecules, with the multi-agent reinforcement learning agents successfully balancing various chemical properties.

Conclusion: Our proposed QCA-MolGAN, combining QCBM and multi-agent reinforcement learning, demonstrates an effective method for generating drug-like molecules with desired and balanced properties, addressing a central challenge in drug discovery.

Abstract: Navigating the vast chemical space of molecular structures to design novel
drug molecules with desired target properties remains a central challenge in
drug discovery. Recent advances in generative models offer promising solutions.
This work presents a novel quantum circuit Born machine (QCBM)-enabled
Generative Adversarial Network (GAN), called QCA-MolGAN, for generating
drug-like molecules. The QCBM serves as a learnable prior distribution, which
is associatively trained to define a latent space aligning with high-level
features captured by the GANs discriminator. Additionally, we integrate a novel
multi-agent reinforcement learning network to guide molecular generation with
desired targeted properties, optimising key metrics such as quantitative
estimate of drug-likeness (QED), octanol-water partition coefficient (LogP) and
synthetic accessibility (SA) scores in conjunction with one another.
Experimental results demonstrate that our approach enhances the property
alignment of generated molecules with the multi-agent reinforcement learning
agents effectively balancing chemical properties.

</details>


### [327] [Efficient Quantum Space-Division Multiplexing Using Time-Bin and Phase Encoding in Few-Mode Fibers](https://arxiv.org/abs/2509.05123)
*Mario Zitelli*

Main category: quant-ph

TL;DR: 利用多模光纤进行空分复用，结合时间-相位编码，在8公里少模光纤上实现了每秒M比特的量子信号传输，并创新性地利用单光子探测器死区时间解决了模间串扰问题。


<details>
  <summary>Details</summary>
Motivation: 利用多模光纤进行空分复用进行量子信号传输，并解决模间串扰问题。

Method: 对时间-相位编码的量子信号进行空分复用，在8公里少模光纤上传输，并利用单光子探测器死区时间消除模间串扰。

Result: 实现了每秒M比特的量子传输速率，并有效消除了模间串扰。

Conclusion: 单光子探测器的死区时间可被有效利用来解决多模光纤量子通信中的模间串扰问题。

Abstract: Space-division multiplexing using multimode optical fibers has been applied
to quantum-level signals with time-bin and phase encoding, achieving Mqubits
per second over 8 km of few-mode fiber. The dead time of single-photon
detectors, typically considered a bottleneck in quantum transmission, is
effectively utilized here to eliminate modal cross-talk between quantum
channels.

</details>


### [328] [Suppression of measurement-induced state transitions in cosφ-coupling transmon readout](https://arxiv.org/abs/2509.05126)
*Cyril Mori,Francesca D Esposito,Alexandru Petrescu,Lucas Ruela,Shelender Kumar,Vishnu Narayanan Suresh,Wael Ardati,Dorian Nicolas,Giulio Cappelli,Arpit Ranadive,Gwenael Le Gal,Martina Esposito,Quentin Ficheux,Nicolas Roch,Olivier Buisson*

Main category: quant-ph

TL;DR: 研究了超导量子比特的驱动诱导状态跃迁（DUST）问题，特别是测量诱导状态跃迁（MIST）。


<details>
  <summary>Details</summary>
Motivation: DUST限制了微波读出和参数操作，MIST由于内禀共振限制了读出信噪比和量子非破坏性测量（QND）读出保真度。

Method: 研究了在不同的超顺磁读出方案中，采用非线性耦合（cos{\phi}-耦合）代替线性耦合来抑制MIST。

Result: 实现了高达第五个激发态的多状态单次读出，识别了计算子空间中的泄露通路。在300光子以上的读出模式下未出现MIST。通过分通量调谐可以打开MIST。实验结果与分支分析和经典混沌动力学模拟一致，表明cos{\phi}-耦合相比横向耦合对读出光子具有更强的鲁棒性。

Conclusion: cos{\phi}-耦合方案能有效抑制MIST，提高读出性能，并允许进行多状态单次读出。

Abstract: Drive-induced unwanted state transitions (DUST) are limiting both for
microwave readout and parametric operations of superconducting qubits. Among
them, measurement-induced state transitions (MIST) are due to intrinsic
resonances described by the readout Hamiltonian. They were previously studied
with a qubit linearly coupled to its readout mode, which constitutes the usual
readout Hamiltonian. Since MIST can appear even at moderate powers, they limit
the readout SNR and the QND readout fidelity. In this work, we study the
high-power readout regime in a different transmon readout scheme, implementing
a nonlinear coupling called the cos{\phi}-coupling. This coupling stems from a
transmon molecule circuit and has symmetry properties that suppress
nonparity-conserving MIST. We succeed in performing multi-state single-shot
readout up to the fifth excited state of the transmon, which enables us to
identify leakage pathways from the computational subspace. The measurements
indicate that the system is free of MIST up to high powers, with more than 300
photons in the readout mode. The MIST can be controllably turned on by breaking
the parity symmetry of the coupling using flux-tuning. These experimental
results are corroborated by branch analysis and simulations of the classical
chaotic dynamics, showing that the cos{\phi}-coupling is very robust to readout
photons compared to the usual transverse coupling.

</details>


### [329] [Hybrid-Integrated InGaAs/InP SPAD Arrays for Quantum Communications](https://arxiv.org/abs/2509.05134)
*Joseph A. Dolphin,Rosemary O. E. Scowen,Louise M. Wells,David J. P. Ellis,Abbie L. Lowe,Benjamin Ramsay,J. Iwan Davies,Andrew J. Shields,Taofiq K. Paraiso,R. Mark Stevenson*

Main category: quant-ph

TL;DR: 本研究实现了GHz门控InGaAs/InP SPAD阵列，并成功将其与硅波导芯片集成，用于构建紧凑型量子密钥分发（QKD）接收器，实现了高安全密钥率。


<details>
  <summary>Details</summary>
Motivation: 量子密钥分发（QKD）需要小型化硬件，但单光子探测器（SPAD）的集成面临挑战。现有超导探测器需要低温冷却，限制了其实际应用。高频门控SPAD是非低温替代方案，但其在GHz阵列门控、像素间串扰和波导耦合方面存在挑战。

Method: 开发了GHz门控InGaAs/InP SPAD阵列，解决了高效门控、低串扰和可扩展波导耦合的挑战。将SPAD阵列与低损耗硅波导芯片进行混合集成。

Result: 实现了GHz门控SPAD阵列，具有适用于QKD的性能和可忽略的像素间串扰。成功构建了混合QKD接收器，在短距离实现了超过2 Mbps的安全密钥率，在100公里光纤上传输实现了15 kbps的安全密钥率。

Conclusion: 本研究为SPAD与波导的可扩展混合集成提供了方法，为量子信息处理应用（包括QKD）开辟了道路。

Abstract: Photonic integration is a promising route to miniaturise the hardware of
quantum key distribution (QKD), yet the monolithic integration of single photon
detectors remains a significant challenge. QKD receiver chips integrating
superconducting detectors have been demonstrated, but their requirement for
cryogenic cooling restricts their practical applications. High-frequency gated
single-photon avalanche diodes (SPADs) provide a mature non-cryogenic
alternative and their fabrication into compact arrays would enable scalable
hybrid integration. However, this faces several challenges related to efficient
GHz array gating, inter-pixel crosstalk, and scalable waveguide coupling, which
to date remain unaddressed. Here, we overcome the key challenges and develop
GHz-gated InGaAs/InP SPAD arrays with performance viable for QKD and negligible
inter-pixel crosstalk. We combine the arrays with low-loss silica waveguide
chips to produce compact hybrid QKD receivers and perform BB84 protocol
experiments, achieving secure key rates over 2 Mbps at short distances and 15
kbps over 100 km of fibre. Our work provides a method for flexible and scalable
integration of waveguide-coupled SPADs for quantum information processing
applications.

</details>


### [330] [Adiabatic preparation of thermal states and entropy-noise relation on noisy quantum computers](https://arxiv.org/abs/2509.05206)
*Etienne Granet,Henrik Dreyer*

Main category: quant-ph

TL;DR: 研究如何在量子计算机上制备有限温度下的热平衡态，并提出了一种抗噪声协议，同时在离子阱设备上进行了实验验证。


<details>
  <summary>Details</summary>
Motivation: 在量子计算机上制备热平衡态，并研究该过程的抗噪声能力。

Method: 使用绝热演化制备初始吉布斯态，并利用镜像电路评估噪声产生的熵，最后提出一个协议来估计Trotter实现的绝热性缺失。

Result: 在离子阱设备上，使用640个两比特门制备的热态，每站点熵为0.166 ± 0.0045，并成功制备了伊辛模型（尺寸为5x4）的温度为2.56 ± 0.26的热态。

Conclusion: 提出的绝热演化和噪声评估协议能够在量子计算机上有效地制备热平衡态，并且该协议对噪声具有鲁棒性，实验结果为该状态制备提供了一个基准。

Abstract: We consider the problem of preparing thermal equilibrium states at finite
temperature on quantum computers. Assuming thermalization, we show that states
that are locally at thermal equilibrium can be prepared by evolving
adiabatically an initial thermal Gibbs state of a simple Hamiltonian with an
interpolating time-dependent Hamiltonian, identically to adiabatic ground state
preparation. We argue that the entropy density of local density matrices is
conserved during the adiabatic evolution, so that both the entropy and energy
of the final state can be computed, and thus the final temperature too. We show
that in the presence of hardware noise, the entropy created by the noisy
evolution can be evaluated with mirror circuits. We give numerical evidence
that the resulting thermal state preparation protocol is noise-resilient, in
the sense that the energy-temperature curve measured on a noisy quantum
computer is remarkably insensitive to noise. We finally propose a protocol to
estimate the lack of adiabaticity in a given actual Trotter implementation of
the dynamics. We test our protocol on Quantinuum's H1-1 ion-trap device. We
measure that a circuit with $640$ two-qubit gates implemented on hardware
generates an entropy per site of $0.166 \pm 0.0045$, giving a benchmark metric
for this state preparation. We report the preparation of a thermal state with
temperature $2.56 \pm 0.26$ of the Ising model in size $5\times 4$.

</details>


### [331] [Fold-transversal surface code cultivation](https://arxiv.org/abs/2509.05212)
*Kaavya Sahay,Pei-Kai Tsai,Kathleen Chang,Qile Su,Thomas B. Smith,Shraddha Singh,Shruti Puri*

Main category: quant-ph

TL;DR: 一种新的魔态制备方案，通过测量表面码的fold-transversal Hadamard并利用幺正技术实现，可显著降低时空开销。


<details>
  <summary>Details</summary>
Motivation: 魔态制备是通用量子计算制备高保真度非Clifford资源态的先进协议，相较于传统方法可显著减少时空开销。

Method: 提出一种新的魔态制备方案，测量unrotated表面码的fold-transversal Hadamard，并利用幺正技术在表面码家族内进行扩展。

Result: 通过稳定器和态矢量模拟，发现该方案实现了目前已知的最低魔态制备时空开销。

Conclusion: 所提出的魔态制备方案效率高，尤其适用于具有非局域连接的量子计算架构。

Abstract: Magic state cultivation is a state-of-the-art protocol to prepare ultra-high
fidelity non-Clifford resource states for universal quantum computation. It
offers a significant reduction in spacetime overhead compared to traditional
magic state distillation techniques. Cultivation protocols involve measuring a
transversal logical Clifford operator on an initial small-distance code and
then rapidly growing to a larger-distance code. In this work, we present a new
cultivation scheme in which we measure the fold-transversal Hadamard of the
unrotated surface code, and leverage unitary techniques to grow within the
surface code family. Using both stabilizer and state vector simulations we find
that this approach achieves the lowest known spacetime overhead for magic state
cultivation. Practical implementation of our protocol is best suited to
architectures with non-local connectivity, showing the strength of
architectures where such connectivity is readily available.

</details>


### [332] [Entanglement in Quantum Systems Based on Directed Graphs](https://arxiv.org/abs/2509.05214)
*Lucio De Simone,Roberto Franzosi*

Main category: quant-ph

TL;DR: 量子纠缠与图的局部连通性相关，可通过顶点度分布量化，并可应用于量子网络设计。


<details>
  <summary>Details</summary>
Motivation: 研究与有向图相关的量子态的纠缠特性。

Method: 使用源自分数-斯图迪度量的度量，将多方纠缠与图的局部连通性定量关联起来，并证明了顶点度分布决定该纠缠度量。

Result: 该度量仅取决于每个顶点的总度数，与边的入站和出站区分无关。将该框架应用于分层网络、受神经网络启发的图、满二叉树和线性桥接循环图等结构。

Conclusion: 该研究为复杂系统中的量子关联提供了几何视角，并在量子网络的设计和分析方面具有潜在应用。

Abstract: We investigate the entanglement properties of quantum states associated with
directed graphs. Using a measure derived from the Fubini-Study metric, we
quantitatively relate multipartite entanglement to the local connectivity of
the graph. In \emph{Entanglement in Directed Graph States}, (2025),
arXiv:2505.10716, it is demonstrated that the vertex degree distribution fully
determines this entanglement measure and remains invariant under vertex
relabeling, highlighting its topological character. As a consequence, the
measure depends only on the total degree of each vertex, making it independent
of the distinction between incoming and outgoing edges. We apply our framework
to several specific graph structures, including hierarchical networks, neural
network-inspired graphs, full binary tree and linear bridged cycle graphs,
demonstrating how their combinatorial properties influence entanglement
distribution. These results provide a geometric perspective on quantum
correlations in complex systems, offering potential applications in the design
and analysis of quantum networks.

</details>


### [333] [Cultivating T states on the surface code with only two-qubit gates](https://arxiv.org/abs/2509.05232)
*Jahan Claes*

Main category: quant-ph

TL;DR: 该研究展示了如何在表面码上直接培养T态，并证明了其在容错量子计算中的优势。


<details>
  <summary>Details</summary>
Motivation: 以往认为高保真度的T态制备需要通过有噪声的T态注入和冗长的蒸馏过程，该研究挑战了这一假设，并提出了一种仅通过仔细的状态注入和后选择即可制备T态的方法（培养）。

Method: 在表面码上实现了T态的培养，并分析了其与颜色码和RP2码培养方法的优劣，包括与中性原子架构的兼容性、横向CNOT门的应用以及距离要求。

Result: 在标准退火错误模型下，d=3, (4), (5) 的表面码培养电路达到了 $1	imes10^{-6}$, ($1	imes10^{-8}$), ($2	imes10^{-9}$) 的错误率和 34%, (6%), (1%) 的接受率，在相似的接受率下达到了与颜色码和RP2码相当的保真度。

Conclusion: 在表面码上培养T态是一种简单且有效的方法，具有与表面码兼容性好、可实现横向CNOT门以及无距离限制等优点，能够满足容错量子计算对高保真度T态的要求。

Abstract: High-fidelity T magic states are a key requirement for fault-tolerant quantum
computing in 2D. It has generally been assumed that preparing high-fidelity T
states requires noisy injection of T states followed by lengthy distillation
routines. This assumption has been recently challenged by the introduction of
cultivation, in which careful state injection and postselection alone are used
to prepare T states close to the fidelity required for quantum algorithms.
Cultivation was originally proposed for the color code, but can also be done on
the $RP^2$ code, a code similar to the surface code.
  In this work, we demonstrate how to cultivate T states directly on the
surface code. Besides its simplicity compared to color or $RP^2$ cultivation,
surface code cultivation offers a number of advantages, including: (1) It is
more directly compatible with neutral atom architectures than ${RP}^2$
cultivation (2) Cultivated surface code states can be used in transversal CNOT
gates with other surface codes, unlike color code states (3) Surface code
cultivation can be done at any distance, unlike color and ${RP}^2$ cultivation
which requires odd distances. Under a standard depolarizing error model, our
$d=3,\ (4),\ (5)$ cultivation circuit reaches an error rate of $1\cdot
10^{-6},\ (1\cdot10^{-8}),\ (2\cdot10^{-9})$ and an acceptance rate of $34\%,\
(6\%),\ (1\%)$, meeting or exceeding the fidelity of color and $RP^2$
cultivation with comparable acceptance rates.

</details>


### [334] [Local transformations of bipartite entanglement are rigid](https://arxiv.org/abs/2509.05257)
*John Bostanci,Tony Metger,Henry Yuen*

Main category: quant-ph

TL;DR: Uhlmann transformations are unique and robustly rigid, with applications in quantum information synthesis and group representation stability.


<details>
  <summary>Details</summary>
Motivation: The paper aims to investigate the rigidity and robustness of optimal Uhlmann transformations, which quantify the optimal overlap between two bipartite pure states under local unitary operations.

Method: The study proves the rigidity of optimal Uhlmann transformations, showing they are unique up to certain degrees of freedom. It also establishes the robustness of this rigidity, demonstrating that near-optimal transformations are close to the optimal one. Applications are derived from this theorem.

Result: The paper demonstrates the rigidity and robustness of Uhlmann transformations. It provides two applications: improved interactive proofs for synthesizing Uhlmann transformations and a simpler proof of the Gowers-Hatami theorem concerning the stability of approximate representations of finite groups.

Conclusion: Optimal Uhlmann transformations are uniquely determined (up to specific degrees of freedom) and this uniqueness is robust, meaning near-optimal transformations are close to the optimal one. This finding has significant implications for synthesizing Uhlmann transformations and understanding the stability of group representations.

Abstract: Uhlmann's theorem is a fundamental result in quantum information theory that
quantifies the optimal overlap between two bipartite pure states after applying
local unitary operations (called Uhlmann transformations). We show that optimal
Uhlmann transformations are rigid -- in other words, they must be unique up to
some well-characterized degrees of freedom. This rigidity is also robust:
Uhlmann transformations achieving near-optimal overlaps must be close to the
unique optimal transformation (again, up to well-characterized degrees of
freedom). We describe two applications of our robust rigidity theorem: (a) we
obtain better interactive proofs for synthesizing Uhlmann transformations and
(b) we obtain a simple, alternative proof of the Gowers-Hatami theorem on the
stability of approximate representations of finite groups.

</details>


### [335] [Magic for Hybrid Boson-Fermion Systems: A Grassmann Phase-Space Approach](https://arxiv.org/abs/2509.05264)
*Matthieu Sarkis,Pablo Martinez-Azcona,Alexandre Tkatchenko*

Main category: quant-ph

TL;DR: 提出了一种用于混合（玻色子-费米子）系统的非稳定性的资源理论，通过混合Wigner函数的Lp范数定义混合魔力，并在Holstein极化子和费米子Jaynes-Cummings模型中进行了演示。


<details>
  <summary>Details</summary>
Motivation: 现有的资源理论无法处理结合了玻色子和费米子模式的系统。需要一种新的理论来量化这些混合系统中的非稳定性。

Method: 利用Cahill和Glauber的Grassmann方法，开发了一个相空间框架，通过混合Wigner函数的Lp范数来定义混合魔力。在门级别，定义了混合操作的非稳定功率，并推导了条件位移门的闭式结果。

Result: 在Holstein极化子模型中，证明了声子-电子耦合可以增强魔力的增长。在费米子Jaynes-Cummings模型中，检查了魔力对原子和腔态的依赖性。推导了条件位移门的闭式结果。

Conclusion: 成功地建立了在实际混合系统中对非稳定性进行统一量化的方法。

Abstract: Non-stabilizerness enables universality beyond Gaussian/Clifford dynamics,
yet no resource theory exists for systems combining bosonic and fermionic
modes. Using the Grassmann approach of Cahill and Glauber, we develop a
phase-space framework defining hybrid magic via the $L_p$ norm of a hybrid
Wigner function. We demonstrate it in the Holstein polaron, where
phonon-electron coupling enhances magic growth, and in the fermionic
Jaynes-Cummings model, examining dependence on atomic and cavity states. At the
gate level, we define the non-stabilizer power of hybrid operations and derive
a closed-form result for the conditional displacement gate. This establishes a
unified quantification of non-stabilizerness in realistic hybrid systems.

</details>


### [336] [On the convergence of the variational quantum eigensolver and quantum optimal control](https://arxiv.org/abs/2509.05295)
*Marco Wiedmann,Daniel Burgarth,Gunther Dirr,Thomas Schulte-Herbrüggen,Emanuel Malvetti,Christian Arenz*

Main category: quant-ph

TL;DR: VQE收敛到全局最优解的充要条件


<details>
  <summary>Details</summary>
Motivation: 解决变分量子算法（VQE）收敛到全局最优解的问题

Method: 利用量子控制理论，证明了VQE收敛到哈密顿量基态的充分条件，该条件依赖于参数化幺正变换的局部满射性和参数更新的梯度下降终止性

Result: 证明了满足局部满射性和梯度下降终止性的VQE可以几乎肯定地收敛到基态，并开发了满足条件（i）的构造，分析了两种常用的量子电路ans"atze。

Conclusion: 讨论了保证梯度下降终止性的正则化技术，并与停机问题联系起来。

Abstract: When does a variational quantum algorithm converge to a globally optimal
problem solution? Despite the large literature around variational approaches to
quantum computing, the answer is largely unknown. We address this open question
by developing a convergence theory for the variational quantum eigensolver
(VQE). By leveraging the terminology of quantum control landscapes, we prove a
sufficient criterion that characterizes when convergence to a ground state of a
Hamiltonian can be guaranteed for almost all initial parameter settings. More
specifically, we show that if (i) a parameterized unitary transformation allows
for moving in all tangent-space directions (local surjectivity) in a bounded
manner and (ii) the gradient descent used for the parameter update terminates,
then the VQE converges to a ground state almost surely. We develop
constructions that satisfy both aspects of condition (i) and analyze two
commonly employed families of quantum circuit ans\"atze. Finally, we discuss
regularization techniques for guaranteeing gradient descent to terminate, as
for condition (ii), and draw connections to the halting problem.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [337] [Narrative-to-Scene Generation: An LLM-Driven Pipeline for 2D Game Environments](https://arxiv.org/abs/2509.04481)
*Yi-Chun Chen,Arnav Jhala*

Main category: cs.GR

TL;DR: 本研究提出一个将故事叙述转化为2D瓦片游戏场景的流程，解决了程序化内容生成中叙事文本与视觉环境的连接问题。


<details>
  <summary>Details</summary>
Motivation: 目前的程序化内容生成技术在连接叙事文本和视觉环境方面存在挑战，本研究旨在解决这一问题。

Method: 该系统首先利用LLM生成叙事，然后识别关键时间点，提取"对象-关系-对象"形式的空间谓词，并从GameTileNet数据集中检索视觉资产。接着，使用细胞自动机生成分层地形，并根据谓词结构放置对象。

Result: 在十个不同的故事中对该系统进行了评估，分析了瓦片-对象匹配、感知层对齐和跨帧空间约束满足情况。

Conclusion: 该原型为叙事驱动的场景生成提供了一个可扩展的方法，并为未来在以故事为中心的程序化内容生成中的多帧连续性、符号跟踪和多智能体协调奠定了基础。

Abstract: Recent advances in large language models(LLMs) enable compelling story
generation, but connecting narrative text to playable visual environments
remains an open challenge in procedural content generation(PCG). We present a
lightweight pipeline that transforms short narrative prompts into a sequence of
2D tile-based game scenes, reflecting the temporal structure of stories. Given
an LLM-generated narrative, our system identifies three key time frames,
extracts spatial predicates in the form of "Object-Relation-Object" triples,
and retrieves visual assets using affordance-aware semantic embeddings from the
GameTileNet dataset. A layered terrain is generated using Cellular Automata,
and objects are placed using spatial rules grounded in the predicate structure.
We evaluated our system in ten diverse stories, analyzing tile-object matching,
affordance-layer alignment, and spatial constraint satisfaction across frames.
This prototype offers a scalable approach to narrative-driven scene generation
and lays the foundation for future work on multi-frame continuity, symbolic
tracking, and multi-agent coordination in story-centered PCG.

</details>


### [338] [Fidelity-preserving enhancement of ptychography with foundational text-to-image models](https://arxiv.org/abs/2509.04513)
*Ming Du,Volker Rose,Junjing Deng,Dileep Singh,Si Chen,Mathew J. Cherukara*

Main category: cs.GR

TL;DR: 通过结合基于物理模型的光栅相位恢复和文本引导的图像编辑，提出了一种即插即用（PnP）框架，用于提高相图恢复的质量，抑制网格病理和多层串扰等伪影。


<details>
  <summary>Details</summary>
Motivation: 现有光栅相位恢复技术存在网格病理和多层串扰等伪影，影响重建图像质量。

Method: 提出了一种即插即用（PnP）框架，该框架集成了基于物理模型的光栅相位恢复和使用基础扩散模型的文本引导图像编辑。通过采用交替方向乘数法（ADMM）保证数据保真度和伪影去除子问题之间的一致性，同时保持物理一致性并提高图像质量。使用文本引导的扩散图像编辑方法（LEDITS++）和预训练的基础扩散模型来实现伪影去除，允许用户用自然语言指定要去除的伪影。

Result: 在模拟和实验数据集上的演示表明，伪影抑制和结构保真度得到了显著改善，并通过峰值信噪比（PSNR）和衍射图案一致性等指标进行了验证。

Conclusion: 这项工作强调了文本引导生成模型和基于模型的光栅相位恢复算法的结合，是一种可转移的、保真度高的优质衍射成像方法。

Abstract: Ptychographic phase retrieval enables high-resolution imaging of complex
samples but often suffers from artifacts such as grid pathology and multislice
crosstalk, which degrade reconstructed images. We propose a plug-and-play (PnP)
framework that integrates physics model-based phase retrieval with text-guided
image editing using foundational diffusion models. By employing the alternating
direction method of multipliers (ADMM), our approach ensures consensus between
data fidelity and artifact removal subproblems, maintaining physics consistency
while enhancing image quality. Artifact removal is achieved using a text-guided
diffusion image editing method (LEDITS++) with a pre-trained foundational
diffusion model, allowing users to specify artifacts for removal in natural
language. Demonstrations on simulated and experimental datasets show
significant improvements in artifact suppression and structural fidelity,
validated by metrics such as peak signal-to-noise ratio (PSNR) and diffraction
pattern consistency. This work highlights the combination of text-guided
generative models and model-based phase retrieval algorithms as a transferable
and fidelity-preserving method for high-quality diffraction imaging.

</details>


### [339] [Improved 3D Scene Stylization via Text-Guided Generative Image Editing with Region-Based Control](https://arxiv.org/abs/2509.05285)
*Haruo Fujiwara,Yusuke Mukuta,Tatsuya Harada*

Main category: cs.GR

TL;DR: 该论文提出了一种改进的文本驱动3D场景编辑和风格化方法，解决了现有技术中风格质量和视图一致性难以同时保证，以及跨区域语义风格迁移的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有文本驱动3D场景编辑和风格化方法在保证风格质量和视图一致性方面存在不足，并且难以实现跨区域语义风格迁移。

Method: 通过重新训练初始3D表示，利用风格化的多视图2D图像，并扩展了风格对齐的深度条件视图生成框架，采用基于单参考的注意力共享机制来对齐跨视图风格，并结合多深度图网格增强视图一致性。此外，引入了多区域重要性加权的切片瓦氏距离损失，以实现基于分割掩码的区域控制风格迁移。

Result: 实验结果（定性和定量）表明，该方法有效提高了文本驱动3D风格化的质量，实现了风格和视图的一致性，并支持跨区域的风格混合。

Conclusion: 所提出的方法能够有效地提高文本驱动3D风格化的质量，同时保持视图一致性，并支持可选的区域控制风格迁移，从而增强了风格迁移的保真度。

Abstract: Recent advances in text-driven 3D scene editing and stylization, which
leverage the powerful capabilities of 2D generative models, have demonstrated
promising outcomes. However, challenges remain in ensuring high-quality
stylization and view consistency simultaneously. Moreover, applying style
consistently to different regions or objects in the scene with semantic
correspondence is a challenging task. To address these limitations, we
introduce techniques that enhance the quality of 3D stylization while
maintaining view consistency and providing optional region-controlled style
transfer. Our method achieves stylization by re-training an initial 3D
representation using stylized multi-view 2D images of the source views.
Therefore, ensuring both style consistency and view consistency of stylized
multi-view images is crucial. We achieve this by extending the style-aligned
depth-conditioned view generation framework, replacing the fully shared
attention mechanism with a single reference-based attention-sharing mechanism,
which effectively aligns style across different viewpoints. Additionally,
inspired by recent 3D inpainting methods, we utilize a grid of multiple depth
maps as a single-image reference to further strengthen view consistency among
stylized images. Finally, we propose Multi-Region Importance-Weighted Sliced
Wasserstein Distance Loss, allowing styles to be applied to distinct image
regions using segmentation masks from off-the-shelf models. We demonstrate that
this optional feature enhances the faithfulness of style transfer and enables
the mixing of different styles across distinct regions of the scene.
Experimental evaluations, both qualitative and quantitative, demonstrate that
our pipeline effectively improves the results of text-driven 3D stylization.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [340] [CleanNews: a Network-aware Fake News Mitigation Architecture for Social Media](https://arxiv.org/abs/2509.04489)
*Maria-Diana Cotelin,Ciprian-Octavian Truică,Elena-Simona Apostol*

Main category: cs.SI

TL;DR: CleanNews是一个先进的深度学习架构，可以准确地识别和处理社交媒体上的虚假信息。它结合了卷积层和双向循环神经网络（LSTM和GRU），并引入了一种新的嵌入技术，融合了文本信息和用户网络结构，以更有效地检测虚假新闻。此外，CleanNews还使用了两种网络免疫算法（SparseShield和NetShield）来减缓虚假信息的传播。实验证明了CleanNews在应对虚假信息方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 随着互联网和移动设备的普及，社交媒体已成为重要的信息来源。然而，任何人都可以自由发布信息，导致虚假信息泛滥，因此识别和处理虚假信息至关重要。

Method: CleanNews采用了一种结合了卷积层和双向循环神经网络（LSTM和GRU）的深度学习架构。其创新之处在于提出了一种新的嵌入技术，融合了文本信息和用户网络结构，以便同时学习与虚假信息相关的语言和关系线索。此外，还采用了SparseShield和NetShield两种网络免疫算法来减缓虚假信息的传播。

Result: 在两个真实世界数据集上的广泛消融研究和超参数调整表明，CleanNews能够有效地识别虚假新闻，并且其各个组成部分都对整体性能做出了贡献。

Conclusion: CleanNews架构在识别和减缓社交媒体上的虚假信息传播方面是有效的，其创新的嵌入技术和网络免疫算法为解决这一问题提供了有前景的方法。

Abstract: With the widespread use of the internet and handheld devices, social media
now holds a power similar to that of old newspapers. People use social media
platforms for quick and accessible information. However, this convenience comes
with a variety of risks. Anyone can freely post content, true or false, with
the probability of remaining online forever. This makes it crucial to identify
and tackle misinformation and disinformation on online platforms. In this
article, we propose CleanNews, a comprehensive architecture to identify fake
news in real-time accurately. CleanNews uses advanced deep learning
architectures, combining convolutional and bidirectional recurrent neural
networks, i.e., LSTM and GRU, layers to detect fake news. A key contribution of
our work is a novel embedding technique that fuses textual information with
user network structure, allowing the model to jointly learn linguistic and
relational cues associated with misinformation. Furthermore, we use two network
immunization algorithms, i.e., SparseShield and NetShield, to mitigate the
spread of false information within networks. We conduct extensive ablation
studies to evaluate the contribution of each model component and systematically
tune hyperparameters to maximize performance. The experimental evaluation on
two real-world datasets shows the efficacy of CleanNews in combating the spread
of fake news.

</details>


### [341] [ThumbnailTruth: A Multi-Modal LLM Approach for Detecting Misleading YouTube Thumbnails Across Diverse Cultural Settings](https://arxiv.org/abs/2509.04714)
*Wajiha Naveed,Zartash Afzal Uzmi,Zafar Ayyub Qazi*

Main category: cs.SI

TL;DR: 本研究提出了一种利用大型语言模型（LLM）检测YouTube等平台误导性视频缩略图的新方法，并构建了一个包含2843个视频（其中1359个为误导性缩略图）的数据集，涵盖了跨文化视角。实验评估了GPT-4o、Claude 3.5 Sonnet和Gemini-1.5 Flash等LLM的性能，结果显示Claude 3.5 Sonnet在某些场景下达到了93.8%的准确率、92%以上的精确率和94%以上的召回率，证明了LLM在识别误导性缩略图方面的有效性。


<details>
  <summary>Details</summary>
Motivation: YouTube等平台上的误导性视频缩略图问题严重，损害了用户信任和平台声誉。

Method: 构建了一个包含2843个视频（1359个误导性缩略图）的多模态数据集，并设计了一个集成视频到文本描述、缩略图图像和字幕的检测流程，利用LLM（GPT-4o、Claude 3.5 Sonnet、Gemini-1.5 Flash）进行内容分析和误导性缩略图识别。

Result: 通过实验和提示工程，评估了多种LLM的性能。Claude 3.5 Sonnet在识别误导性缩略图方面表现出色，在某些场景下准确率达到93.8%，精确率超过92%，召回率超过94%。

Conclusion: LLM在识别误导性缩略图方面是有效的，这为建立更透明、更可信赖的视频平台以及提升全球观众的内容完整性提供了新的途径，并对内容审核、用户体验和大规模部署的伦理问题进行了讨论。

Abstract: Misleading video thumbnails on platforms like YouTube are a pervasive
problem, undermining user trust and platform integrity. This paper proposes a
novel multi-modal detection pipeline that uses Large Language Models (LLMs) to
flag misleading thumbnails. We first construct a comprehensive dataset of 2,843
videos from eight countries, including 1,359 misleading thumbnail videos that
collectively amassed over 7.6 billion views -- providing a unique
cross-cultural perspective on this global issue. Our detection pipeline
integrates video-to-text descriptions, thumbnail images, and subtitle
transcripts to holistically analyze content and flag misleading thumbnails.
Through extensive experimentation and prompt engineering, we evaluate the
performance of state-of-the-art LLMs, including GPT-4o, GPT-4o Mini, Claude 3.5
Sonnet, and Gemini-1.5 Flash. Our findings show the effectiveness of LLMs in
identifying misleading thumbnails, with Claude 3.5 Sonnet consistently showing
strong performance, achieving an accuracy of 93.8\%, precision over 92\%, and
recall exceeding 94\% in certain scenarios. We discuss the implications of our
findings for content moderation, user experience, and the ethical
considerations of deploying such systems at scale. Our findings pave the way
for more transparent, trustworthy video platforms and stronger content
integrity for audiences worldwide.

</details>


### [342] [Evaluating Cognitive-Behavioral Fixation via Multimodal User Viewing Patterns on Social Media](https://arxiv.org/abs/2509.04823)
*Yujie Wang,Yunwei Zhao,Jing Yang,Han Han,Shiguang Shan,Jie Zhang*

Main category: cs.SI

TL;DR: 该研究提出了一种计算框架，用于通过分析用户在社交媒体上的多模态互动模式来评估认知-行为固着现象。


<details>
  <summary>Details</summary>
Motivation: 心理学中已广泛研究认知-行为固着，但计算上检测和评估此类固着的方法仍未得到充分探索。

Method: 提出了一种新颖的框架，包括一个多模态主题提取模块和一个认知-行为固着量化模块，用于评估用户行为。

Result: 在现有基准和新策划的多模态数据集上进行的实验证明了该方法的有效性。

Conclusion: 该研究提出的框架能够有效评估用户的认知-行为固着，为可扩展的计算分析奠定了基础。

Abstract: Digital social media platforms frequently contribute to cognitive-behavioral
fixation, a phenomenon in which users exhibit sustained and repetitive
engagement with narrow content domains. While cognitive-behavioral fixation has
been extensively studied in psychology, methods for computationally detecting
and evaluating such fixation remain underexplored. To address this gap, we
propose a novel framework for assessing cognitive-behavioral fixation by
analyzing users' multimodal social media engagement patterns. Specifically, we
introduce a multimodal topic extraction module and a cognitive-behavioral
fixation quantification module that collaboratively enable adaptive,
hierarchical, and interpretable assessment of user behavior. Experiments on
existing benchmarks and a newly curated multimodal dataset demonstrate the
effectiveness of our approach, laying the groundwork for scalable computational
analysis of cognitive fixation. All code in this project is publicly available
for research purposes at
https://github.com/Liskie/cognitive-fixation-evaluation.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [343] [The Ethical Compass of the Machine: Evaluating Large Language Models for Decision Support in Construction Project Management](https://arxiv.org/abs/2509.04505)
*Somtochukwu Azie,Yiping Meng*

Main category: cs.AI

TL;DR: 大型语言模型（LLM）在施工项目管理（CPM）的道德决策支持方面存在局限性，应作为人类决策的辅助工具。


<details>
  <summary>Details</summary>
Motivation: 评估将大型语言模型（LLM）应用于施工项目管理（CPM）的道德可行性和可靠性，特别是在高风险的道德敏感决策环境中。

Method: 采用混合方法研究设计，通过“道德决策支持评估清单”（EDSAC）对两个领先的LLM在十二个真实世界道德场景中的表现进行定量测试，并对12位行业专家的半结构化访谈进行定性分析。

Result: LLM在法律合规等结构化领域表现尚可，但在处理情境细微差别、确保问责制和提供透明推理方面存在明显不足。利益相关者对AI在道德判断中的自主使用表示担忧，并主张加强“人在回路”的监督。

Conclusion: LLM目前最适合作为决策支持辅助工具，而不是自主的道德决策者。该研究引入了EDSAC框架，并提供了可操作的建议。

Abstract: The integration of Artificial Intelligence (AI) into construction project
management (CPM) is accelerating, with Large Language Models (LLMs) emerging as
accessible decision-support tools. This study aims to critically evaluate the
ethical viability and reliability of LLMs when applied to the ethically
sensitive, high-risk decision-making contexts inherent in CPM. A mixed-methods
research design was employed, involving the quantitative performance testing of
two leading LLMs against twelve real-world ethical scenarios using a novel
Ethical Decision Support Assessment Checklist (EDSAC), and qualitative analysis
of semi-structured interviews with 12 industry experts to capture professional
perceptions. The findings reveal that while LLMs demonstrate adequate
performance in structured domains such as legal compliance, they exhibit
significant deficiencies in handling contextual nuance, ensuring
accountability, and providing transparent reasoning. Stakeholders expressed
considerable reservations regarding the autonomous use of AI for ethical
judgments, strongly advocating for robust human-in-the-loop oversight. To our
knowledge, this is one of the first studies to empirically test the ethical
reasoning of LLMs within the construction domain. It introduces the EDSAC
framework as a replicable methodology and provides actionable recommendations,
emphasising that LLMs are currently best positioned as decision-support aids
rather than autonomous ethical agents.

</details>


### [344] [Maestro: Joint Graph & Config Optimization for Reliable AI Agents](https://arxiv.org/abs/2509.04642)
*Wenxiao Wang,Priyatham Kattakinda,Soheil Feizi*

Main category: cs.AI

TL;DR: Maestro是一个整体优化器，可以同时优化LLM代理的图结构和节点配置，以提高代理质量，并且优于现有的提示优化器。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM代理优化器通常只调整节点配置，而忽略了图结构可能导致的失败模式。需要一种能够同时优化图结构和节点配置的整体优化器。

Method: Maestro通过联合搜索图结构和节点配置来优化LLM代理。它利用来自追踪的文本反馈来优先处理编辑，以提高样本效率并解决特定的失败模式。Maestro在IFBench和HotpotQA基准测试以及两个实际应用（面试官和RAG代理）上进行了评估。

Result: Maestro在IFBench和HotpotQA基准测试中，平均比MIPROv2、GEPA和GEPA+Merge等领先的提示优化器分别提高了12%、4.9%和4.86%。即使仅限于提示优化，Maestro仍然分别领先9.65%、2.37%和2.41%。Maestro的性能也优于GEPA，并且在两个实际应用中也取得了显著的改进。

Conclusion: 联合搜索图结构和节点配置可以解决单独进行提示调整无法解决的结构性失败模式。Maestro通过整体优化方法实现了这一点，并在各种基准和应用中取得了优于现有方法的性能。

Abstract: Building reliable LLM agents requires decisions at two levels: the graph
(which modules exist and how information flows) and the configuration of each
node (models, prompts, tools, control knobs). Most existing optimizers tune
configurations while holding the graph fixed, leaving structural failure modes
unaddressed. We introduce Maestro, a framework-agnostic holistic optimizer for
LLM agents that jointly searches over graphs and configurations to maximize
agent quality, subject to explicit rollout/token budgets. Beyond numeric
metrics, Maestro leverages reflective textual feedback from traces to
prioritize edits, improving sample efficiency and targeting specific failure
modes. On the IFBench and HotpotQA benchmarks, Maestro consistently surpasses
leading prompt optimizers--MIPROv2, GEPA, and GEPA+Merge--by an average of 12%,
4.9%, and 4.86%, respectively; even when restricted to prompt-only
optimization, it still leads by 9.65%, 2.37%, and 2.41%. Maestro achieves these
results with far fewer rollouts than GEPA. We further show large gains on two
applications (interviewer & RAG agents), highlighting that joint graph &
configuration search addresses structural failure modes that prompt tuning
alone cannot fix.

</details>


### [345] [Towards Personalized Explanations for Health Simulations: A Mixed-Methods Framework for Stakeholder-Centric Summarization](https://arxiv.org/abs/2509.04646)
*Philippe J. Giabbanelli,Ameeta Agrawal*

Main category: cs.AI

TL;DR: 大型语言模型可为健康模拟生成量身定制的解释，但需要系统地理解和满足不同利益相关者的需求。


<details>
  <summary>Details</summary>
Motivation: 当前的健康模拟模型因其复杂性而难以被不同类型的利益相关者（例如，政策制定者、个人）充分利用。大型语言模型（LLM）虽然可以解释这些模型，但目前的方法缺乏个性化，无法满足不同利益相关者的信息需求和风格偏好。

Method: 提出一个分步框架，首先通过混合方法收集不同健康利益相关者的解释需求和风格偏好，然后优化 LLM 生成定制化输出的能力（例如，通过可控属性调整），最后通过全面的指标进行评估和改进。

Result: 该框架旨在弥合当前 LLM 在生成量身定制的健康模拟解释方面的差距，从而使更广泛的利益相关者能够理解和受益于这些模型。

Conclusion: 需要一个系统性的方法来理解和满足不同健康利益相关者对模拟解释的需求，以便更好地利用 LLM 的能力，从而提高健康领域中 M&S 方法的可及性和影响力。

Abstract: Modeling & Simulation (M&S) approaches such as agent-based models hold
significant potential to support decision-making activities in health, with
recent examples including the adoption of vaccines, and a vast literature on
healthy eating behaviors and physical activity behaviors. These models are
potentially usable by different stakeholder groups, as they support
policy-makers to estimate the consequences of potential interventions and they
can guide individuals in making healthy choices in complex environments.
However, this potential may not be fully realized because of the models'
complexity, which makes them inaccessible to the stakeholders who could benefit
the most. While Large Language Models (LLMs) can translate simulation outputs
and the design of models into text, current approaches typically rely on
one-size-fits-all summaries that fail to reflect the varied informational needs
and stylistic preferences of clinicians, policymakers, patients, caregivers,
and health advocates. This limitation stems from a fundamental gap: we lack a
systematic understanding of what these stakeholders need from explanations and
how to tailor them accordingly. To address this gap, we present a step-by-step
framework to identify stakeholder needs and guide LLMs in generating tailored
explanations of health simulations. Our procedure uses a mixed-methods design
by first eliciting the explanation needs and stylistic preferences of diverse
health stakeholders, then optimizing the ability of LLMs to generate tailored
outputs (e.g., via controllable attribute tuning), and then evaluating through
a comprehensive range of metrics to further improve the tailored generation of
summaries.

</details>


### [346] [Language-Driven Hierarchical Task Structures as Explicit World Models for Multi-Agent Learning](https://arxiv.org/abs/2509.04731)
*Brennen Hill*

Main category: cs.AI

TL;DR: 将大型语言模型（LLM）整合到启用了分层概念的“世界模型”中，以提高多智能体系统（MAS）在复杂长期任务中的学习效率，特别是在机器人足球等领域。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习方法在处理高维度、稀疏奖励和复杂探索空间的多智能体任务时面临挑战，需要更精密的“世界模型”来指导学习。

Method: 通过分层脚手架将复杂目标分解为可管理的子目标，并利用大型语言模型动态生成这种分层结构，从而构建一个“语言驱动的世界模型”。

Result: 通过对2024年多智能体足球研究的系统回顾，证明了将符号和分层方法与多智能体强化学习（MARL）相结合的趋势，这些方法隐含或显式地构建了基于任务的世界模型来指导学习。

Conclusion: 利用大型语言模型动态生成分层世界模型，可以提供内在课程、密集的学习信号和组合学习框架，从而提高智能体在复杂策略任务中的样本效率和泛化能力。

Abstract: The convergence of Language models, Agent models, and World models represents
a critical frontier for artificial intelligence. While recent progress has
focused on scaling Language and Agent models, the development of sophisticated,
explicit World Models remains a key bottleneck, particularly for complex,
long-horizon multi-agent tasks. In domains such as robotic soccer, agents
trained via standard reinforcement learning in high-fidelity but
structurally-flat simulators often fail due to intractable exploration spaces
and sparse rewards. This position paper argues that the next frontier in
developing capable agents lies in creating environments that possess an
explicit, hierarchical World Model. We contend that this is best achieved
through hierarchical scaffolding, where complex goals are decomposed into
structured, manageable subgoals. Drawing evidence from a systematic review of
2024 research in multi-agent soccer, we identify a clear and decisive trend
towards integrating symbolic and hierarchical methods with multi-agent
reinforcement learning (MARL). These approaches implicitly or explicitly
construct a task-based world model to guide agent learning. We then propose a
paradigm shift: leveraging Large Language Models to dynamically generate this
hierarchical scaffold, effectively using language to structure the World Model
on the fly. This language-driven world model provides an intrinsic curriculum,
dense and meaningful learning signals, and a framework for compositional
learning, enabling Agent Models to acquire sophisticated, strategic behaviors
with far greater sample efficiency. By building environments with explicit,
language-configurable task layers, we can bridge the gap between low-level
reactive behaviors and high-level strategic team play, creating a powerful and
generalizable framework for training the next generation of intelligent agents.

</details>


### [347] [An Approach to Grounding AI Model Evaluations in Human-derived Criteria](https://arxiv.org/abs/2509.04676)
*Sasha Mitts*

Main category: cs.AI

TL;DR: 引入基于人类认知标准的方法来改进AI物理世界建模的基准测试。


<details>
  <summary>Details</summary>
Motivation: 传统的AI基准测试在捕捉AI模型的细微能力方面存在不足，特别是在物理世界建模领域。因此，有必要提出一种新的方法来改进现有的基准测试。

Method: 通过对现有基准测试（如Perception Test和OpenEQA）进行补充，并结合深入访谈和大规模调查，识别出对AI和人类推理至关重要的认知技能（如优先排序、记忆、辨别和情境化）。

Result: 研究发现，人类受访者认为AI在解读和共情能力方面有所欠缺，但对AI的性能抱有很高的期望。

Conclusion: 通过将访谈和调查结果融入基准测试设计，提出了一种为AI开发更符合人类的定义和衡量进展的方法框架。这项工作强调了以用户为中心的评估在AI发展中的重要性，并为研究人员和从业者提供了对齐AI能力与人类认知过程的可行指南。

Abstract: In the rapidly evolving field of artificial intelligence (AI), traditional
benchmarks can fall short in attempting to capture the nuanced capabilities of
AI models. We focus on the case of physical world modeling and propose a novel
approach to augment existing benchmarks with human-derived evaluation criteria,
aiming to enhance the interpretability and applicability of model behaviors.
Grounding our study in the Perception Test and OpenEQA benchmarks, we conducted
in-depth interviews and large-scale surveys to identify key cognitive skills,
such as Prioritization, Memorizing, Discerning, and Contextualizing, that are
critical for both AI and human reasoning. Our findings reveal that participants
perceive AI as lacking in interpretive and empathetic skills yet hold high
expectations for AI performance. By integrating insights from our findings into
benchmark design, we offer a framework for developing more human-aligned means
of defining and measuring progress. This work underscores the importance of
user-centered evaluation in AI development, providing actionable guidelines for
researchers and practitioners aiming to align AI capabilities with human
cognitive processes. Our approach both enhances current benchmarking practices
and sets the stage for future advancements in AI model evaluation.

</details>


### [348] [ProToM: Promoting Prosocial Behaviour via Theory of Mind-Informed Feedback](https://arxiv.org/abs/2509.05091)
*Matteo Bortoletto,Yichao Zhou,Lance Ying,Tianmin Shu,Andreas Bulling*

Main category: cs.AI

TL;DR: ProToM是一个基于心智理论的AI系统，通过提供有针对性的、情境感知的反馈来促进多智能体系统中的亲社会行为，并在实验中优于现有的大型语言和推理模型。


<details>
  <summary>Details</summary>
Motivation: 研究如何让AI系统在多智能体协作中，即使在个体目标不完全一致的情况下，也能促进有益于他人的亲社会行为。

Method: ProToM首先使用贝叶斯逆向规划推断智能体的目标，然后通过最大化预期效用来选择要传达的反馈，并以推断出的目标分布为条件。

Result: 在“门、钥匙和宝石”以及“过度烹饪”这两个多智能体环境中，ProToM相比基线方法（包括大型语言和推理模型）取得了更高的成功率、更短的任务完成时间，并且更受人类用户青睐，而基线方法存在沟通开销大和任务加速效果不佳的问题。

Conclusion: ProToM通过提供有针对性且有用的反馈，有效促进了多智能体系统中的亲社会行为，克服了现有大型语言和推理模型在提供情境化和及时反馈方面的不足。

Abstract: While humans are inherently social creatures, the challenge of identifying
when and how to assist and collaborate with others - particularly when pursuing
independent goals - can hinder cooperation. To address this challenge, we aim
to develop an AI system that provides useful feedback to promote prosocial
behaviour - actions that benefit others, even when not directly aligned with
one's own goals. We introduce ProToM, a Theory of Mind-informed facilitator
that promotes prosocial actions in multi-agent systems by providing targeted,
context-sensitive feedback to individual agents. ProToM first infers agents'
goals using Bayesian inverse planning, then selects feedback to communicate by
maximising expected utility, conditioned on the inferred goal distribution. We
evaluate our approach against baselines in two multi-agent environments: Doors,
Keys, and Gems, as well as Overcooked. Our results suggest that
state-of-the-art large language and reasoning models fall short of
communicating feedback that is both contextually grounded and well-timed -
leading to higher communication overhead and task speedup. In contrast, ProToM
provides targeted and helpful feedback, achieving a higher success rate,
shorter task completion times, and is consistently preferred by human users.

</details>


### [349] [What-If Analysis of Large Language Models: Explore the Game World Using Proactive Thinking](https://arxiv.org/abs/2509.04791)
*Yuan Sui,Yanming Zhang,Yi Liao,Yu Gu,Guohua Tang,Zhongqian Sun,Wei Yang,Bryan Hooi*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large language models (LLMs) excel at processing information reactively but
lack the ability to systemically explore hypothetical futures. They cannot ask,
"what if we take this action? how will it affect the final outcome" and
forecast its potential consequences before acting. This critical gap limits
their utility in dynamic, high-stakes scenarios like strategic planning, risk
assessment, and real-time decision making. To bridge this gap, we propose
WiA-LLM, a new paradigm that equips LLMs with proactive thinking capabilities.
Our approach integrates What-If Analysis (WIA), a systematic approach for
evaluating hypothetical scenarios by changing input variables. By leveraging
environmental feedback via reinforcement learning, WiA-LLM moves beyond
reactive thinking. It dynamically simulates the outcomes of each potential
action, enabling the model to anticipate future states rather than merely react
to the present conditions. We validate WiA-LLM in Honor of Kings (HoK), a
complex multiplayer game environment characterized by rapid state changes and
intricate interactions. The game's real-time state changes require precise
multi-step consequence prediction, making it an ideal testbed for our approach.
Experimental results demonstrate WiA-LLM achieves a remarkable 74.2% accuracy
in forecasting game-state changes (up to two times gain over baselines). The
model shows particularly significant gains in high-difficulty scenarios where
accurate foresight is critical. To our knowledge, this is the first work to
formally explore and integrate what-if analysis capabilities within LLMs.
WiA-LLM represents a fundamental advance toward proactive reasoning in LLMs,
providing a scalable framework for robust decision-making in dynamic
environments with broad implications for strategic applications.

</details>


### [350] [TalkToAgent: A Human-centric Explanation of Reinforcement Learning Agents with Large Language Models](https://arxiv.org/abs/2509.04809)
*Haechang Kim,Hao Chen,Can Li,Jong Min Lee*

Main category: cs.AI

TL;DR: TalkToAgent是一个多智能体大语言模型框架，通过自然语言交互提供可解释的强化学习（RL）策略解释，解决了现有XRL工具理解和使用的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有XRL方法理解性和工具选择性不足，导致复杂RL策略与领域专家之间存在差距。

Method: 提出TalkToAgent框架，包含协调员、解释员、编码员、评估员和调试员五个LLM智能体，可将用户查询映射到XRL工具，并根据状态变量、预期结果或反事实解释RL策略。通过定性行为描述或规则策略生成反事实。在四重管过程控制问题上进行了验证。

Result: TalkToAgent准确地将用户查询映射到XRL任务，编码员-调试员交互减少了反事实生成的失败。定性评估证实TalkToAgent能有效解释RL策略的行为及其在问题域中的意义。

Conclusion: TalkToAgent成功地实现了RL策略的自然语言解释，提高了XRL的可用性和用户对RL代理的理解。

Abstract: Explainable Reinforcement Learning (XRL) has emerged as a promising approach
in improving the transparency of Reinforcement Learning (RL) agents. However,
there remains a gap between complex RL policies and domain experts, due to the
limited comprehensibility of XRL results and isolated coverage of current XRL
approaches that leave users uncertain about which tools to employ. To address
these challenges, we introduce TalkToAgent, a multi-agent Large Language Models
(LLM) framework that delivers interactive, natural language explanations for RL
policies. The architecture with five specialized LLM agents (Coordinator,
Explainer, Coder, Evaluator, and Debugger) enables TalkToAgent to automatically
map user queries to relevant XRL tools and clarify an agent's actions in terms
of either key state variables, expected outcomes, or counterfactual
explanations. Moreover, our approach extends previous counterfactual
explanations by deriving alternative scenarios from qualitative behavioral
descriptions, or even new rule-based policies. We validated TalkToAgent on
quadruple-tank process control problem, a well-known nonlinear control
benchmark. Results demonstrated that TalkToAgent successfully mapped user
queries into XRL tasks with high accuracy, and coder-debugger interactions
minimized failures in counterfactual generation. Furthermore, qualitative
evaluation confirmed that TalkToAgent effectively interpreted agent's actions
and contextualized their meaning within the problem domain.

</details>


### [351] [Collaboration and Conflict between Humans and Language Models through the Lens of Game Theory](https://arxiv.org/abs/2509.04847)
*Mukul Singh,Arjun Radhakrishna,Sumit Gulwani*

Main category: cs.AI

TL;DR: 语言模型在迭代囚徒困境（IPD）中表现出与顶级经典策略相当的合作和竞争行为，并能快速适应对手策略的变化。


<details>
  <summary>Details</summary>
Motivation: 研究语言模型在多人互动环境中的合作与竞争行为，特别是忽略了长期互动、人机协作和行为模式演变的问题。

Method: 将基于语言模型的智能体与240种经典策略进行Axelrod风格的锦标赛，并在“策略切换”实验中评估其适应性。

Result: 语言模型在IPD锦标赛中的表现与最佳经典策略相当甚至超越；它们表现出友好、可激怒和慷慨等合作策略的关键特征；并且在策略切换实验中，它们能在几轮内快速检测并响应对手策略的变化。

Conclusion: 语言模型能够展现出长期的合作行为，并能快速适应对手策略的变化，这为人机混合社交环境的未来研究奠定了基础。

Abstract: Language models are increasingly deployed in interactive online environments,
from personal chat assistants to domain-specific agents, raising questions
about their cooperative and competitive behavior in multi-party settings. While
prior work has examined language model decision-making in isolated or
short-term game-theoretic contexts, these studies often neglect long-horizon
interactions, human-model collaboration, and the evolution of behavioral
patterns over time. In this paper, we investigate the dynamics of language
model behavior in the iterated prisoner's dilemma (IPD), a classical framework
for studying cooperation and conflict. We pit model-based agents against a
suite of 240 well-established classical strategies in an Axelrod-style
tournament and find that language models achieve performance on par with, and
in some cases exceeding, the best-known classical strategies. Behavioral
analysis reveals that language models exhibit key properties associated with
strong cooperative strategies - niceness, provocability, and generosity while
also demonstrating rapid adaptability to changes in opponent strategy mid-game.
In controlled "strategy switch" experiments, language models detect and respond
to shifts within only a few rounds, rivaling or surpassing human adaptability.
These results provide the first systematic characterization of long-term
cooperative behaviors in language model agents, offering a foundation for
future research into their role in more complex, mixed human-AI social
environments.

</details>


### [352] [Cloning a Conversational Voice AI Agent from Call\,Recording Datasets for Telesales](https://arxiv.org/abs/2509.04871)
*Krittanon Kaewtawee,Wachiravit Modecrua,Krittin Pachtrachai,Touchapon Kraisingkorn*

Main category: cs.AI

TL;DR: 该论文提出了一种从通话录音语料库中克隆对话式语音AI代理的通用方法。该系统可以理解和生成人类对话，并能被部署在客户服务和医疗保健等领域。


<details>
  <summary>Details</summary>
Motivation: 为了自动化重复性任务、降低运营成本并提供全天候支持，本研究旨在开发一种克隆对话式语音AI代理的方法。

Method: 本研究提出了一种通用方法，从通话录音语料库中克隆对话式语音AI代理。该方法集成了自动语音识别、基于大语言模型的对话管理器以及文本到语音合成，并构建了一个流式推理管道。此外，还包括领域选择、知识提取和提示工程等步骤。

Result: 该克隆AI代理在日常通话方面表现接近人类水平，但在说服和处理异议方面表现不佳。在进行提示优化后，AI在客户沟通中的表现有所改善。

Conclusion: 本研究提出了克隆对话式语音AI代理的通用方法，并指出了未来研究方向，包括大规模模拟和自动化评估。

Abstract: Recent advances in language and speech modelling have made it possible to
build autonomous voice assistants that understand and generate human dialogue
in real time. These systems are increasingly being deployed in domains such as
customer service and healthcare care, where they can automate repetitive tasks,
reduce operational costs, and provide constant support around the clock. In
this paper, we present a general methodology for cloning a conversational voice
AI agent from a corpus of call recordings. Although the case study described in
this paper uses telesales data to illustrate the approach, the underlying
process generalizes to any domain where call transcripts are available. Our
system listens to customers over the telephone, responds with a synthetic
voice, and follows a structured playbook learned from top performing human
agents. We describe the domain selection, knowledge extraction, and prompt
engineering used to construct the agent, integrating automatic speech
recognition, a large language model based dialogue manager, and text to speech
synthesis into a streaming inference pipeline. The cloned agent is evaluated
against human agents on a rubric of 22 criteria covering introduction, product
communication, sales drive, objection handling, and closing. Blind tests show
that the AI agent approaches human performance in routine aspects of the call
while underperforming in persuasion and objection handling. We analyze these
shortcomings and refine the prompt accordingly. The paper concludes with design
lessons and avenues for future research, including large scale simulation and
automated evaluation.

</details>


### [353] [OSC: Cognitive Orchestration through Dynamic Knowledge Alignment in Multi-Agent LLM Collaboration](https://arxiv.org/abs/2509.04876)
*Jusheng Zhang,Yijia Fan,Kaitong Cai,Xiaofei Sun,Keze Wang*

Main category: cs.AI

TL;DR: OSC是一个知识感知的自适应协作框架，用于增强多智能体系统中具有大型语言模型的认知协同能力，通过认知差距分析和协作知识模型（CKM）实现智能体间的深度协作。


<details>
  <summary>Details</summary>
Motivation: 现有工作在智能体选择和结果聚合方面有所进展，但专家智能体之间进行高效语言交互以实现深度协作仍然是一个关键瓶颈。

Method: OSC作为一个关键的中间层，在选择和聚合之间引入了协作知识模型（CKM），使每个智能体能够动态感知其协作者的认知状态。通过实时认知差距分析，智能体使用学习到的策略自适应地调整通信行为，包括内容焦点、细节程度和表达风格。

Result: 在复杂的推理和问题解决基准测试中，OSC显著提高了任务性能和通信效率，将“并行工作的个体”转变为“深度协作的认知团队”。

Conclusion: OSC框架不仅优化了多智能体协作，还为LLM智能体交互行为提供了新的见解。

Abstract: This paper introduces OSC (Orchestrating Cognitive Synergy), a
knowledge-aware adaptive collaboration framework designed to enhance cognitive
synergy in multi-agent systems with large language models. While prior work has
advanced agent selection and result aggregation, efficient linguistic
interactions for deep collaboration among expert agents remain a critical
bottleneck. OSC addresses this gap as a pivotal intermediate layer between
selection and aggregation, introducing Collaborator Knowledge Models (CKM) to
enable each agent to dynamically perceive its collaborators' cognitive states.
Through real-time cognitive gap analysis, agents adaptively adjust
communication behaviors, including content focus, detail level, and expression
style, using learned strategies. Experiments on complex reasoning and
problem-solving benchmarks demonstrate that OSC significantly improves task
performance and communication efficiency, transforming "parallel-working
individuals'' into a "deeply collaborative cognitive team.'' This framework not
only optimizes multi-agent collaboration but also offers new insights into LLM
agent interaction behaviors.

</details>


### [354] [SparkUI-Parser: Enhancing GUI Perception with Robust Grounding and Parsing](https://arxiv.org/abs/2509.04908)
*Hongyi Jing,Jiafu Chen,Chen Rao,Ziqiang Dang,Jiajie Teng,Tianyi Chu,Juncheng Mo,Shuo Fang,Huaizhong Lin,Rui Lv,Chenguang Ma,Lei Zhao*

Main category: cs.AI

TL;DR: SparkUI-Parser是一个端到端框架，通过连续坐标建模和改进的匈牙利匹配算法，解决了现有GUI感知模型在定位精度、推理速度和完整界面解析方面的挑战，并在多个基准测试中取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有GUI感知模型在处理离散坐标、解析预定义元素集以及整体界面理解方面存在局限，导致定位精度低、推理速度慢，限制了其广泛应用。

Method: 提出SparkUI-Parser框架，使用预训练的多模态大语言模型（MLLM），结合额外的token路由器和坐标解码器，进行连续坐标建模，而非基于文本的离散坐标建模。引入基于改进匈牙利匹配算法的拒绝机制，以识别和剔除非目标元素，减少误报。构建了ScreenParse基准测试集。

Result: SparkUI-Parser在ScreenSpot, ScreenSpot-v2, CAGUI-Grounding和ScreenParse基准测试中，相比现有SOTA方法，在定位精度、推理速度和细粒度界面解析能力上均表现出优越的性能。

Conclusion: SparkUI-Parser通过连续坐标建模和引入拒绝机制，有效解决了现有GUI感知模型的局限性，实现了更高的定位精度和细粒度的界面解析能力，并在多个基准测试中取得了领先的成果。

Abstract: The existing Multimodal Large Language Models (MLLMs) for GUI perception have
made great progress. However, the following challenges still exist in prior
methods: 1) They model discrete coordinates based on text autoregressive
mechanism, which results in lower grounding accuracy and slower inference
speed. 2) They can only locate predefined sets of elements and are not capable
of parsing the entire interface, which hampers the broad application and
support for downstream tasks. To address the above issues, we propose
SparkUI-Parser, a novel end-to-end framework where higher localization
precision and fine-grained parsing capability of the entire interface are
simultaneously achieved. Specifically, instead of using probability-based
discrete modeling, we perform continuous modeling of coordinates based on a
pre-trained Multimodal Large Language Model (MLLM) with an additional token
router and coordinate decoder. This effectively mitigates the limitations
inherent in the discrete output characteristics and the token-by-token
generation process of MLLMs, consequently boosting both the accuracy and the
inference speed. To further enhance robustness, a rejection mechanism based on
a modified Hungarian matching algorithm is introduced, which empowers the model
to identify and reject non-existent elements, thereby reducing false positives.
Moreover, we present ScreenParse, a rigorously constructed benchmark to
systematically assess structural perception capabilities of GUI models across
diverse scenarios. Extensive experiments demonstrate that our approach
consistently outperforms SOTA methods on ScreenSpot, ScreenSpot-v2,
CAGUI-Grounding and ScreenParse benchmarks. The resources are available at
https://github.com/antgroup/SparkUI-Parser.

</details>


### [355] [Towards Ontology-Based Descriptions of Conversations with Qualitatively-Defined Concepts](https://arxiv.org/abs/2509.04926)
*Barbara Gendron,Gaël Guibon,Mathieu D'aquin*

Main category: cs.AI

TL;DR: 该研究提出了一种基于本体的方法来控制大型语言模型（LLM）在对话中的可控性和用户个性化响应，通过将定性语言描述符转换为定量的、可推理的概念，并以欧洲语言共同参考框架（CEFR）为案例，成功实现了对话熟练度级别的控制，并通过实验证明了该方法在提高对话AI的透明度和一致性方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）作为对话代理时，其可控性是一个关键挑战，特别是在确保响应的可预测性和用户个性化方面。

Method: 提出了一种基于本体的方法，利用一套语言描述符将定性的对话特征（如CEFR语言熟练度级别）转化为定量的、可推理的概念，并将其形式化为描述逻辑，最终整合到本体中，通过微调引导LLM进行受控文本生成。

Result: 实验结果表明，该方法能够提供一致且可解释的熟练度级别定义，从而提高了对话AI的透明度。

Conclusion: 该研究提出了一种有效的基于本体的方法，能够形式化和控制定性对话特征，从而提高大型语言模型在对话应用中的可控性和透明度。

Abstract: The controllability of Large Language Models (LLMs) when used as
conversational agents is a key challenge, particularly to ensure predictable
and user-personalized responses. This work proposes an ontology-based approach
to formally define conversational features that are typically qualitative in
nature. By leveraging a set of linguistic descriptors, we derive quantitative
definitions for qualitatively-defined concepts, enabling their integration into
an ontology for reasoning and consistency checking. We apply this framework to
the task of proficiency-level control in conversations, using CEFR language
proficiency levels as a case study. These definitions are then formalized in
description logic and incorporated into an ontology, which guides controlled
text generation of an LLM through fine-tuning. Experimental results demonstrate
that our approach provides consistent and explainable proficiency-level
definitions, improving transparency in conversational AI.

</details>


### [356] [Internet 3.0: Architecture for a Web-of-Agents with it's Algorithm for Ranking Agents](https://arxiv.org/abs/2509.04979)
*Rajesh Tembarai Krishnamachari,Srividya Rajesh*

Main category: cs.AI

TL;DR: DOVIS是一个五层协议，AgentRank-UC是基于此协议的排名算法，旨在为AI Agent生态系统实现可信赖的性能排名。


<details>
  <summary>Details</summary>
Motivation: AI Agent生态系统需要一种“Agent Ranking”机制，以根据其实际性能而非声明的能力来选择Agent，但现有的使用信号分散且私密，无法进行排名。

Method: 提出了一个五层协议DOVIS（Discovery, Orchestration, Verification, Incentives, Semantics），用于收集最小化且保护隐私的使用和性能聚合数据。在此基础上，实现了AgentRank-UC算法，该算法结合了使用频率和能力（结果质量、成本、安全、延迟）来进行统一排名。

Result: 模拟结果和理论保证表明，该协议和排名算法在收敛性、鲁棒性和Sybil抵抗性方面是可行的，能够实现可扩展且可信赖的Agentic Web。

Conclusion: DOVIS协议和AgentRank-UC算法为实现Agentic Web的可扩展、可信赖的性能排名提供了基础。

Abstract: AI agents -- powered by reasoning-capable large language models (LLMs) and
integrated with tools, data, and web search -- are poised to transform the
internet into a \emph{Web of Agents}: a machine-native ecosystem where
autonomous agents interact, collaborate, and execute tasks at scale. Realizing
this vision requires \emph{Agent Ranking} -- selecting agents not only by
declared capabilities but by proven, recent performance. Unlike Web~1.0's
PageRank, a global, transparent network of agent interactions does not exist;
usage signals are fragmented and private, making ranking infeasible without
coordination.
  We propose \textbf{DOVIS}, a five-layer operational protocol
(\emph{Discovery, Orchestration, Verification, Incentives, Semantics}) that
enables the collection of minimal, privacy-preserving aggregates of usage and
performance across the ecosystem. On this substrate, we implement
\textbf{AgentRank-UC}, a dynamic, trust-aware algorithm that combines
\emph{usage} (selection frequency) and \emph{competence} (outcome quality,
cost, safety, latency) into a unified ranking. We present simulation results
and theoretical guarantees on convergence, robustness, and Sybil resistance,
demonstrating the viability of coordinated protocols and performance-aware
ranking in enabling a scalable, trustworthy Agentic Web.

</details>


### [357] [Sticker-TTS: Learn to Utilize Historical Experience with a Sticker-driven Test-Time Scaling Framework](https://arxiv.org/abs/2509.05007)
*Jie Chen,Jinhao Jiang,Yingqian Min,Zican Dong,Shijie Wang,Wayne Xin Zhao,Ji-Rong Wen*

Main category: cs.AI

TL;DR: Sticker-TTS是一个新颖的测试时缩放框架，通过协调三个协同的大型推理模型（LRMs），并利用“贴纸”指导的历史经验，迭代地探索和改进解决方案，从而提高了计算效率和数学推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有的测试时缩放方法主要依赖冗余采样，忽略历史经验的利用，限制了计算效率。Sticker-TTS旨在克服这一限制，通过利用历史经验来提高LRMs的推理效率和性能。

Method: Sticker-TTS框架的核心是蒸馏的关键条件，称为“贴纸”，它指导多轮推理过程中的关键信息提取、精炼和重用。此外，还引入了一个两阶段的优化策略，结合了模仿学习和自我改进，以实现渐进式精炼。

Result: 在AIME-24、AIME-25和OlymMATH三个具有挑战性的数学推理基准上进行的大量评估表明，Sticker-TTS在可比的推理预算下，始终优于包括自一致性和先进的强化学习方法在内的强基线。

Conclusion: Sticker-TTS通过其贴纸引导的历史经验利用机制，有效地提高了大型推理模型的计算效率和在数学推理任务上的性能。

Abstract: Large reasoning models (LRMs) have exhibited strong performance on complex
reasoning tasks, with further gains achievable through increased computational
budgets at inference. However, current test-time scaling methods predominantly
rely on redundant sampling, ignoring the historical experience utilization,
thereby limiting computational efficiency. To overcome this limitation, we
propose Sticker-TTS, a novel test-time scaling framework that coordinates three
collaborative LRMs to iteratively explore and refine solutions guided by
historical attempts. At the core of our framework are distilled key
conditions-termed stickers-which drive the extraction, refinement, and reuse of
critical information across multiple rounds of reasoning. To further enhance
the efficiency and performance of our framework, we introduce a two-stage
optimization strategy that combines imitation learning with self-improvement,
enabling progressive refinement. Extensive evaluations on three challenging
mathematical reasoning benchmarks, including AIME-24, AIME-25, and OlymMATH,
demonstrate that Sticker-TTS consistently surpasses strong baselines, including
self-consistency and advanced reinforcement learning approaches, under
comparable inference budgets. These results highlight the effectiveness of
sticker-guided historical experience utilization. Our code and data are
available at https://github.com/RUCAIBox/Sticker-TTS.

</details>


### [358] [Finding your MUSE: Mining Unexpected Solutions Engine](https://arxiv.org/abs/2509.05072)
*Nir Sweed,Hanit Hakim,Ben Wolfson,Hila Lifshitz,Dafna Shahaf*

Main category: cs.AI

TL;DR: 本研究提出功能概念图（FCG）方法来克服创新者的认知固着，并通过MUSE算法生成创造性灵感。


<details>
  <summary>Details</summary>
Motivation: 创新者常常固着于现有解决方案或初步想法，阻碍了对新颖替代方案的探索。

Method: 构建功能概念图（FCG），这是一种互联的功能元素表示，支持抽象、问题重构和类比启发。该方法产生了具有明确抽象关系的大规模、高质量FCG。此外，还提出了利用FCG生成创意灵感的MUSE算法。

Result: 计算了一个包含500K专利的FCG，并公开发布以供进一步研究。MUSE算法被证明能够为给定问题生成创造性灵感。

Conclusion: 本研究通过FCG和MUSE算法为克服创新者的认知固着和激发创造性提供了新的方法。

Abstract: Innovators often exhibit cognitive fixation on existing solutions or nascent
ideas, hindering the exploration of novel alternatives. This paper introduces a
methodology for constructing Functional Concept Graphs (FCGs), interconnected
representations of functional elements that support abstraction, problem
reframing, and analogical inspiration. Our approach yields large-scale,
high-quality FCGs with explicit abstraction relations, overcoming limitations
of prior work. We further present MUSE, an algorithm leveraging FCGs to
generate creative inspirations for a given problem. We demonstrate our method
by computing an FCG on 500K patents, which we release for further research.

</details>


### [359] [Evaluation and Comparison Semantics for ODRL](https://arxiv.org/abs/2509.05139)
*Jaime Osvaldo Salas,Paolo Pareti,Semih Yumuşak,Soulmaz Gheisari,Luis-Daniel Ibáñez,George Konstantinidis*

Main category: cs.AI

TL;DR: 本文提出了一种基于查询问答的ODRL形式化语义，并在此基础上定义了策略比较问题。


<details>
  <summary>Details</summary>
Motivation: ODRL作为数字资源访问和使用的标准语言，目前缺乏全面的形式化语义。

Method: 提出了一种基于查询问答的ODRL形式化语义，并在此基础上定义了比较两个ODRL策略的问题。

Result: 该语义能够评估和比较ODRL策略，检测等价、更严格或更宽松的策略。

Conclusion: 本文提出的形式化语义能够为ODRL策略的评估和比较提供支持。

Abstract: We consider the problem of evaluating, and comparing computational policies
in the Open Digital Rights Language (ODRL), which has become the de facto
standard for governing the access and usage of digital resources. Although
preliminary progress has been made on the formal specification of the
language's features, a comprehensive formal semantics of ODRL is still missing.
In this paper, we provide a simple and intuitive formal semantics for ODRL that
is based on query answering. Our semantics refines previous formalisations, and
is aligned with the latest published specification of the language (2.2).
Building on our evaluation semantics, and motivated by data sharing scenarios,
we also define and study the problem of comparing two policies, detecting
equivalent, more restrictive or more permissive policies.

</details>


### [360] [LatticeWorld: A Multimodal Large Language Model-Empowered Framework for Interactive Complex World Generation](https://arxiv.org/abs/2509.05263)
*Yinglin Duan,Zhengxia Zou,Tongwei Gu,Wei Jia,Zhan Zhao,Luyi Xu,Xinzhu Liu,Hao Jiang,Kang Chen,Shuang Qiu*

Main category: cs.AI

TL;DR: LatticeWorld是一个利用轻量级大语言模型（LLaMA-2-7B）和虚幻引擎5来生成大规模3D交互式世界的框架，可接受文本和视觉指令，实现高保真物理模拟和实时渲染，并将工业生产效率提高了90倍以上。


<details>
  <summary>Details</summary>
Motivation: 为了缩小模拟与现实之间的差距，并更便捷地获取真实世界的信息，需要更逼真、物理准确的3D世界模拟。传统手动建模方法效率低下，现代方法需要更先进的机器学习算法，特别是能够根据用户指令生成虚拟世界的生成方法。

Method: 提出LatticeWorld框架，利用轻量级大语言模型（LLaMA-2-7B）和行业级渲染引擎（如虚幻引擎5），接受文本描述和视觉指令作为多模态输入，生成具有动态代理、多智能体交互、高保真物理模拟和实时渲染的大规模3D交互式世界。

Result: LatticeWorld在场景布局生成和视觉保真度方面取得了优越的准确性。与传统手动生产方法相比，LatticeWorld的工业生产效率提高了90倍以上，同时保持了高质量的创意。

Conclusion: LatticeWorld是一个有效且简单的3D世界生成框架，它通过结合轻量级大语言模型和行业级渲染引擎，显著提高了3D环境的工业化生产效率和生成质量，为3D内容创作提供了一种新的解决方案。

Abstract: Recent research has been increasingly focusing on developing 3D world models
that simulate complex real-world scenarios. World models have found broad
applications across various domains, including embodied AI, autonomous driving,
entertainment, etc. A more realistic simulation with accurate physics will
effectively narrow the sim-to-real gap and allow us to gather rich information
about the real world conveniently. While traditional manual modeling has
enabled the creation of virtual 3D scenes, modern approaches have leveraged
advanced machine learning algorithms for 3D world generation, with most recent
advances focusing on generative methods that can create virtual worlds based on
user instructions. This work explores such a research direction by proposing
LatticeWorld, a simple yet effective 3D world generation framework that
streamlines the industrial production pipeline of 3D environments. LatticeWorld
leverages lightweight LLMs (LLaMA-2-7B) alongside the industry-grade rendering
engine (e.g., Unreal Engine 5) to generate a dynamic environment. Our proposed
framework accepts textual descriptions and visual instructions as multimodal
inputs and creates large-scale 3D interactive worlds with dynamic agents,
featuring competitive multi-agent interaction, high-fidelity physics
simulation, and real-time rendering. We conduct comprehensive experiments to
evaluate LatticeWorld, showing that it achieves superior accuracy in scene
layout generation and visual fidelity. Moreover, LatticeWorld achieves over a
$90\times$ increase in industrial production efficiency while maintaining high
creative quality compared with traditional manual production methods. Our demo
video is available at https://youtu.be/8VWZXpERR18

</details>
