{"id": "2509.10112", "categories": ["cs.GT", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.10112", "abs": "https://arxiv.org/abs/2509.10112", "authors": ["Ndidi Bianca Ogbo", "Zhao Song", "The Anh Han"], "title": "Evolution of Coordination Through Institutional Incentives: An Evolutionary Game Theory Approach", "comment": "16 pages, 5 figures", "summary": "There is a broad recognition that commitment-based mechanisms can promote\ncoordination and cooperative behaviours in both biological populations and\nself-organised multi-agent systems by making individuals' intentions explicit\nprior to engagement. Yet their effectiveness depends on sustained compliance\nsupported by institutions, especially in one-off interactions. Despite advances\nin quantitative studies of cooperation and commitment, most applied analyses\nand policy debates remain largely qualitative, with limited attention to the\nallocation of scarce institutional resources between enhancing participation\nand ensuring commitment compliance. Herein, we develop an evolutionary\ngame-theoretic model that explicitly examines the strategic distribution of a\nlimited budget for institutional incentives, namely rewards or punishments,\naimed at these two critical objectives within pre-commitment frameworks. Our\nfindings reveal that a reward-based incentive approach consistently yields\ngreater coordination success than a punishment-based approach, with optimal\noutcomes arising when resources are appropriately distributed between\nparticipation promotion and compliance assurance. These findings offer novel\ninsights for designing institutional incentives to promote broad, coordinated\nadoption of new technologies.", "AI": {"tldr": "\u672c\u6587\u5229\u7528\u6f14\u5316\u535a\u5f08\u8bba\u6a21\u578b\uff0c\u63a2\u8ba8\u4e86\u5728\u9884\u627f\u8bfa\u6846\u67b6\u4e0b\uff0c\u5982\u4f55\u5206\u914d\u6709\u9650\u7684\u5236\u5ea6\u8d44\u6e90\uff08\u5956\u52b1\u6216\u60e9\u7f5a\uff09\u4ee5\u4fc3\u8fdb\u534f\u8c03\u548c\u5408\u4f5c\u884c\u4e3a\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u57fa\u4e8e\u5956\u52b1\u7684\u6fc0\u52b1\u63aa\u65bd\u6bd4\u57fa\u4e8e\u60e9\u7f5a\u7684\u63aa\u65bd\u66f4\u80fd\u6210\u529f\u5730\u4fc3\u8fdb\u534f\u8c03\uff0c\u5e76\u4e14\u5728\u4fc3\u8fdb\u53c2\u4e0e\u548c\u786e\u4fdd\u9075\u5b88\u4e4b\u95f4\u53d6\u5f97\u6700\u4f73\u8d44\u6e90\u5206\u914d\u65f6\uff0c\u53ef\u4ee5\u83b7\u5f97\u6700\u4f18\u7ed3\u679c\u3002", "motivation": "\u5728\u751f\u7269\u79cd\u7fa4\u548c\u81ea\u7ec4\u7ec7\u591a\u4e3b\u4f53\u7cfb\u7edf\u4e2d\uff0c\u57fa\u4e8e\u627f\u8bfa\u7684\u673a\u5236\u53ef\u4ee5\u901a\u8fc7\u660e\u786e\u4e2a\u4f53\u7684\u610f\u56fe\u6765\u4fc3\u8fdb\u534f\u8c03\u548c\u5408\u4f5c\u884c\u4e3a\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u673a\u5236\u7684\u6709\u6548\u6027\uff0c\u5c24\u5176\u662f\u5728\u4e00\u6b21\u6027\u4e92\u52a8\u4e2d\uff0c\u4f9d\u8d56\u4e8e\u5236\u5ea6\u652f\u6301\u7684\u6301\u7eed\u9075\u5b88\u3002\u5c3d\u7ba1\u5728\u5408\u4f5c\u548c\u627f\u8bfa\u7684\u5b9a\u91cf\u7814\u7a76\u65b9\u9762\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u5927\u591a\u6570\u5e94\u7528\u5206\u6790\u548c\u653f\u7b56\u8ba8\u8bba\u4ecd\u7136\u662f\u5b9a\u6027\u7684\uff0c\u5e76\u4e14\u5f88\u5c11\u5173\u6ce8\u7528\u4e8e\u589e\u5f3a\u53c2\u4e0e\u5ea6\u548c\u786e\u4fdd\u627f\u8bfa\u9075\u5b88\u7684\u7a00\u7f3a\u5236\u5ea6\u8d44\u6e90\u7684\u5206\u914d\u3002", "method": "\u672c\u6587\u5f00\u53d1\u4e86\u4e00\u4e2a\u6f14\u5316\u535a\u5f08\u8bba\u6a21\u578b\uff0c\u660e\u786e\u7814\u7a76\u4e86\u5982\u4f55\u5728\u5236\u5ea6\u6fc0\u52b1\uff08\u5956\u52b1\u6216\u60e9\u7f5a\uff09\u7684\u6709\u9650\u9884\u7b97\u5185\u8fdb\u884c\u6218\u7565\u5206\u914d\uff0c\u4ee5\u5b9e\u73b0\u4fc3\u8fdb\u53c2\u4e0e\u548c\u786e\u4fdd\u9075\u5b88\u8fd9\u4e24\u5927\u5173\u952e\u76ee\u6807\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u57fa\u4e8e\u5956\u52b1\u7684\u6fc0\u52b1\u65b9\u6cd5\u5728\u4fc3\u8fdb\u534f\u8c03\u65b9\u9762\u59cb\u7ec8\u4f18\u4e8e\u57fa\u4e8e\u60e9\u7f5a\u7684\u65b9\u6cd5\u3002\u5f53\u8d44\u6e90\u5728\u4fc3\u8fdb\u53c2\u4e0e\u548c\u786e\u4fdd\u9075\u5b88\u4e4b\u95f4\u5f97\u5230\u9002\u5f53\u5206\u914d\u65f6\uff0c\u53ef\u4ee5\u5b9e\u73b0\u6700\u4f18\u7ed3\u679c\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u4e86\u8bbe\u8ba1\u65e8\u5728\u4fc3\u8fdb\u65b0\u6280\u672f\u5e7f\u6cdb\u534f\u8c03\u91c7\u7528\u7684\u5236\u5ea6\u6fc0\u52b1\u63aa\u65bd\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\u3002"}}
{"id": "2509.09695", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.09695", "abs": "https://arxiv.org/abs/2509.09695", "authors": ["Fabio Magarelli", "Geraldine B. Boylan", "Saeed Montazeri", "Feargal O'Sullivan", "Dominic Lightbody", "Minoo Ashoori", "Tamara Skoric Ceranic", "John M. O'Toole"], "title": "Machine-learning competition to grade EEG background patterns in newborns with hypoxic-ischaemic encephalopathy", "comment": "29 pages, supplementary materials: \"supplementary materials ML\n  Comp.docx\"", "summary": "Machine learning (ML) has the potential to support and improve expert\nperformance in monitoring the brain function of at-risk newborns. Developing\naccurate and reliable ML models depends on access to high-quality, annotated\ndata, a resource in short supply. ML competitions address this need by\nproviding researchers access to expertly annotated datasets, fostering shared\nlearning through direct model comparisons, and leveraging the benefits of\ncrowdsourcing diverse expertise. We compiled a retrospective dataset containing\n353 hours of EEG from 102 individual newborns from a multi-centre study. The\ndata was fully anonymised and divided into training, testing, and held-out\nvalidation datasets. EEGs were graded for the severity of abnormal background\npatterns. Next, we created a web-based competition platform and hosted a\nmachine learning competition to develop ML models for classifying the severity\nof EEG background patterns in newborns. After the competition closed, the top 4\nperforming models were evaluated offline on a separate held-out validation\ndataset. Although a feature-based model ranked first on the testing dataset,\ndeep learning models generalised better on the validation sets. All methods had\na significant decline in validation performance compared to the testing\nperformance. This highlights the challenges for model generalisation on unseen\ndata, emphasising the need for held-out validation datasets in ML studies with\nneonatal EEG. The study underscores the importance of training ML models on\nlarge and diverse datasets to ensure robust generalisation. The competition's\noutcome demonstrates the potential for open-access data and collaborative ML\ndevelopment to foster a collaborative research environment and expedite the\ndevelopment of clinical decision-support tools for neonatal neuromonitoring.", "AI": {"tldr": "\u673a\u5668\u5b66\u4e60\u7ade\u8d5b\u901a\u8fc7\u63d0\u4f9b\u6570\u636e\u96c6\u3001\u4fc3\u8fdb\u6a21\u578b\u6bd4\u8f83\u548c\u4f17\u5305\u4e13\u4e1a\u77e5\u8bc6\u6765\u6539\u8fdb\u65b0\u751f\u513f\u8111\u529f\u80fd\u76d1\u6d4b\u4e2d\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u3002", "motivation": "\u9700\u8981\u9ad8\u8d28\u91cf\u3001\u6807\u6ce8\u8fc7\u7684\u65b0\u751f\u513f\u8111\u7535\u56fe (EEG) \u6570\u636e\u6765\u5f00\u53d1\u51c6\u786e\u53ef\u9760\u7684\u673a\u5668\u5b66\u4e60 (ML) \u6a21\u578b\uff0c\u4f46\u6b64\u7c7b\u6570\u636e\u4f9b\u5e94\u4e0d\u8db3\u3002", "method": "\u521b\u5efa\u4e86\u4e00\u4e2a\u5305\u542b 353 \u5c0f\u65f6\u65b0\u751f\u513f\u8111\u7535\u56fe\u6570\u636e\u7684\u56de\u987e\u6027\u6570\u636e\u96c6\uff0c\u5e76\u5c06\u5176\u5206\u4e3a\u8bad\u7ec3\u3001\u6d4b\u8bd5\u548c\u9a8c\u8bc1\u96c6\u3002\u7136\u540e\uff0c\u7ec4\u7ec7\u4e86\u4e00\u573a\u673a\u5668\u5b66\u4e60\u7ade\u8d5b\uff0c\u8ba9\u7814\u7a76\u4eba\u5458\u5f00\u53d1\u7528\u4e8e\u5bf9 EEG \u80cc\u666f\u6a21\u5f0f\u4e25\u91cd\u7a0b\u5ea6\u8fdb\u884c\u5206\u7c7b\u7684\u6a21\u578b\u3002\u5bf9\u6392\u540d\u524d\u56db\u7684\u6a21\u578b\u5728\u5355\u72ec\u7684\u4fdd\u7559\u9a8c\u8bc1\u96c6\u4e0a\u8fdb\u884c\u4e86\u79bb\u7ebf\u8bc4\u4f30\u3002", "result": "\u867d\u7136\u57fa\u4e8e\u7279\u5f81\u7684\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u4e0a\u6392\u540d\u7b2c\u4e00\uff0c\u4f46\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u9a8c\u8bc1\u96c6\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\u66f4\u597d\u3002\u6240\u6709\u6a21\u578b\u5728\u9a8c\u8bc1\u96c6\u4e0a\u7684\u8868\u73b0\u5747\u663e\u8457\u4e0b\u964d\u3002\u8fd9\u5f3a\u8c03\u4e86\u5728\u673a\u5668\u5b66\u4e60\u7814\u7a76\u4e2d\uff0c\u4f7f\u7528\u65b0\u751f\u513f\u8111\u7535\u56fe\u8fdb\u884c\u6a21\u578b\u6cdb\u5316\u7684\u6311\u6218\uff0c\u5e76\u5f3a\u8c03\u4e86\u4fdd\u7559\u9a8c\u8bc1\u6570\u636e\u96c6\u7684\u5fc5\u8981\u6027\u3002", "conclusion": "\u673a\u5668\u5b66\u4e60\u7ade\u8d5b\u6709\u52a9\u4e8e\u4fc3\u8fdb\u534f\u4f5c\u7814\u7a76\u73af\u5883\uff0c\u5e76\u52a0\u901f\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u5de5\u5177\u7684\u5f00\u53d1\u3002\u7136\u800c\uff0c\u6a21\u578b\u6cdb\u5316\u4ecd\u7136\u662f\u4e00\u4e2a\u6311\u6218\uff0c\u9700\u8981\u5728\u5927\u800c\u591a\u6837\u5316\u7684\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u4f7f\u7528\u4fdd\u7559\u9a8c\u8bc1\u96c6\u8fdb\u884c\u8bc4\u4f30\u3002"}}
{"id": "2509.09803", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2509.09803", "abs": "https://arxiv.org/abs/2509.09803", "authors": ["Guillermo L. Esparza", "Zhenkun Yuan", "Muhammad Rubaiat Hasan", "Yagmur Coban", "Gideon Kassa", "Vivek Shastry Devalla", "Tejas Nivarty", "Jack R. Palmer", "Jifeng Liu", "Kirill Kovnir", "Geoffroy Hautier", "David P Fenning"], "title": "CaCd$_2$P$_2$: A Visible-Light Absorbing Zintl Phosphide Stable under Photoelectrochemical Water Oxidation", "comment": null, "summary": "A key bottleneck to solar fuels is the absence of stable and strongly\nabsorbing photoelectrode materials for the oxygen evolution reaction (OER).\nModern approaches generally trade off between stable but weakly absorbing\nmaterials, such as wide bandgap oxides, or strongly absorbing materials that\nrely on encapsulation for stability and are weakly catalytic, such as the III-V\nfamily of semiconductors. Of interest are materials like transition metal\nphosphides, such as FeP$_2$, that are known to undergo beneficial in situ\nsurface transformations in the oxidative environment of OER, though stability\nhas remained a primary hurdle. Here we report on CaCd$_2$P$_2$, a Zintl phase\nvisible-light absorber with favorable 1.6 eV bandgap, that we identified using\nhigh-throughput computational screening. Using a combination of\nphotoelectrochemical measurements, microscopy, and spectroscopy, we show that\nCaCd$_2$P$_2$ undergoes a light-stabilized surface transformation that renders\nit stable under alkaline OER conditions. We also show that the well known OER\ncatalyst CoPi can act as a stable co-catalyst in synergy with the\n\\textit{in-situ} CaCd$_2$P$_2$ surface. The light-induced stabilization that\nCaCd$_2$P$_2$ displays is in sharp contrast to the photocorrosion commonly\nobserved in visible light-absorbing photoelectrodes. The broader AM$_2$P$_2$\nfamily of Zintl phases offers a significant opportunity to explore stabilizing\ninterface chemistry and re-design the manner in which low-bandgap\nsemiconductors are used for photoelectrochemical energy conversion.", "AI": {"tldr": "CaCd2P2\u662f\u4e00\u79cd\u53ef\u89c1\u5149\u5438\u6536\u6750\u6599\uff0c\u5728\u78b1\u6027\u6761\u4ef6\u4e0b\u8fdb\u884c\u6c27\u6c14\u6f14\u5316\u53cd\u5e94\uff08OER\uff09\u65f6\uff0c\u8868\u9762\u4f1a\u53d1\u751f\u5149\u7a33\u5b9a\u8f6c\u5316\uff0c\u63d0\u9ad8\u4e86\u7a33\u5b9a\u6027\uff0c\u5e76\u4e14\u53ef\u4ee5\u4e0eCoPi\u534f\u540c\u4f5c\u4e3a\u5149\u7535\u50ac\u5316\u5242\u3002", "motivation": "\u5bfb\u627e\u7a33\u5b9a\u4e14\u5f3a\u5438\u6536\u7684\u592a\u9633\u80fd\u71c3\u6599\u5149\u7535\u6781\u6750\u6599\uff0c\u7279\u522b\u662f\u7528\u4e8e\u6c27\u6c14\u6f14\u5316\u53cd\u5e94\uff08OER\uff09\uff0c\u662f\u592a\u9633\u80fd\u71c3\u6599\u9886\u57df\u9762\u4e34\u7684\u5173\u952e\u6311\u6218\u3002\u73b0\u6709\u6750\u6599\u5728\u7a33\u5b9a\u6027\u4e0e\u5438\u6536\u80fd\u529b\u4e4b\u95f4\u5b58\u5728\u6298\u8877\u3002", "method": "\u5229\u7528\u9ad8\u901a\u91cf\u8ba1\u7b97\u7b5b\u9009\uff0c\u8bc6\u522b\u51faCaCd2P2\u6750\u6599\u3002\u901a\u8fc7\u5149\u7535\u5316\u5b66\u6d4b\u91cf\u3001\u663e\u5fae\u955c\u548c\u5149\u8c31\u5b66\u6280\u672f\uff0c\u7814\u7a76CaCd2P2\u5728\u78b1\u6027OER\u6761\u4ef6\u4e0b\u7684\u8868\u9762\u8f6c\u5316\u548c\u7a33\u5b9a\u6027\u3002", "result": "CaCd2P2\u5728\u78b1\u6027OER\u6761\u4ef6\u4e0b\u8868\u73b0\u51fa\u5149\u7a33\u5b9a\u5316\u7684\u8868\u9762\u8f6c\u5316\uff0c\u63d0\u9ad8\u4e86\u7a33\u5b9a\u6027\uff0c\u5e76\u80fd\u4e0eCoPi\u534f\u540c\u4f5c\u4e3a\u7a33\u5b9a\u7684\u5149\u7535\u50ac\u5316\u5242\u3002", "conclusion": "CaCd2P2\u5728OER\u4e2d\u8868\u73b0\u51fa\u7684\u5149\u8bf1\u5bfc\u7a33\u5b9a\u6027\uff0c\u4e3a\u8bbe\u8ba1\u548c\u4f7f\u7528\u4f4e\u5e26\u9699\u534a\u5bfc\u4f53\u8fdb\u884c\u5149\u7535\u5316\u5b66\u80fd\u91cf\u8f6c\u6362\u63d0\u4f9b\u4e86\u65b0\u7684\u673a\u4f1a\u3002AM2P2\u5bb6\u65cf\u7684\u5176\u4ed6Zintl\u76f8\u4e5f\u503c\u5f97\u8fdb\u4e00\u6b65\u63a2\u7d22\u3002"}}
{"id": "2509.09699", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09699", "abs": "https://arxiv.org/abs/2509.09699", "authors": ["Mingyang Li", "Viktor Schlegel", "Tingting Mu", "Warren Del-Pinto", "Goran Nenadic"], "title": "Structured Information Matters: Explainable ICD Coding with Patient-Level Knowledge Graphs", "comment": null, "summary": "Mapping clinical documents to standardised clinical vocabularies is an\nimportant task, as it provides structured data for information retrieval and\nanalysis, which is essential to clinical research, hospital administration and\nimproving patient care. However, manual coding is both difficult and\ntime-consuming, making it impractical at scale. Automated coding can\npotentially alleviate this burden, improving the availability and accuracy of\nstructured clinical data. The task is difficult to automate, as it requires\nmapping to high-dimensional and long-tailed target spaces, such as the\nInternational Classification of Diseases (ICD). While external knowledge\nsources have been readily utilised to enhance output code representation, the\nuse of external resources for representing the input documents has been\nunderexplored. In this work, we compute a structured representation of the\ninput documents, making use of document-level knowledge graphs (KGs) that\nprovide a comprehensive structured view of a patient's condition. The resulting\nknowledge graph efficiently represents the patient-centred input documents with\n23\\% of the original text while retaining 90\\% of the information. We assess\nthe effectiveness of this graph for automated ICD-9 coding by integrating it\ninto the state-of-the-art ICD coding architecture PLM-ICD. Our experiments\nyield improved Macro-F1 scores by up to 3.20\\% on popular benchmarks, while\nimproving training efficiency. We attribute this improvement to different types\nof entities and relationships in the KG, and demonstrate the improved\nexplainability potential of the approach over the text-only baseline.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u77e5\u8bc6\u56fe\u8c31\uff08KG\uff09\u6765\u6539\u8fdb\u4e34\u5e8a\u6587\u6863\u5230ICD\u7f16\u7801\u7684\u81ea\u52a8\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u6784\u5efa\u60a3\u8005\u4e2d\u5fc3\u6587\u6863\u7684\u7ed3\u6784\u5316\u8868\u793a\uff0c\u63d0\u9ad8\u4e86\u7f16\u7801\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u5e76\u589e\u5f3a\u4e86\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u624b\u52a8\u5c06\u4e34\u5e8a\u6587\u6863\u7f16\u7801\u4e3a\u6807\u51c6\u5316\u8bcd\u6c47\uff08\u5982ICD\uff09\u6548\u7387\u4f4e\u4e0b\u4e14\u8017\u65f6\uff0c\u800c\u81ea\u52a8\u5316\u7f16\u7801\u5bf9\u4e8e\u4e34\u5e8a\u7814\u7a76\u3001\u533b\u9662\u7ba1\u7406\u548c\u60a3\u8005\u62a4\u7406\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5229\u7528\u6587\u6863\u7ea7\u77e5\u8bc6\u56fe\u8c31\uff08KG\uff09\u4e3a\u8f93\u5165\u6587\u6863\u8ba1\u7b97\u7ed3\u6784\u5316\u8868\u793a\uff0c\u8be5KG\u5168\u9762\u5c55\u793a\u4e86\u60a3\u8005\u7684\u75c5\u72b6\u3002\u8fd9\u79cd\u8868\u793a\u65b9\u5f0f\u5c06\u539f\u59cb\u6587\u672c\u51cf\u5c11\u4e8677%\uff0c\u540c\u65f6\u4fdd\u7559\u4e8690%\u7684\u4fe1\u606f\u3002\u7136\u540e\u5c06\u6b64KG\u96c6\u6210\u5230\u6700\u5148\u8fdb\u7684PLM-ICD\u67b6\u6784\u4e2d\uff0c\u7528\u4e8e\u81ea\u52a8\u5316ICD-9\u7f16\u7801\u3002", "result": "\u5728\u5e38\u7528\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMacro-F1\u5206\u6570\u6700\u9ad8\u63d0\u9ad8\u4e863.20%\uff0c\u540c\u65f6\u63d0\u9ad8\u4e86\u8bad\u7ec3\u6548\u7387\u3002\u7814\u7a76\u53d1\u73b0KG\u4e2d\u7684\u5b9e\u4f53\u548c\u5173\u7cfb\u7c7b\u578b\u662f\u6027\u80fd\u63d0\u5347\u7684\u539f\u56e0\uff0c\u5e76\u4e14\u4e0e\u7eaf\u6587\u672c\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u5177\u6709\u66f4\u597d\u7684\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u5229\u7528\u77e5\u8bc6\u56fe\u8c31\u6765\u4e30\u5bcc\u8f93\u5165\u6587\u6863\u7684\u8868\u793a\uff0c\u662f\u81ea\u52a8\u5316\u4e34\u5e8a\u7f16\u7801\u4efb\u52a1\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u53ef\u4ee5\u63d0\u9ad8\u51c6\u786e\u6027\u3001\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2509.09744", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09744", "abs": "https://arxiv.org/abs/2509.09744", "authors": ["Mujie Liu", "Chenze Wang", "Liping Chen", "Nguyen Linh Dan Le", "Niharika Tewari", "Ting Dang", "Jiangang Ma", "Feng Xia"], "title": "Structure Matters: Brain Graph Augmentation via Learnable Edge Masking for Data-efficient Psychiatric Diagnosis", "comment": null, "summary": "The limited availability of labeled brain network data makes it challenging\nto achieve accurate and interpretable psychiatric diagnoses. While\nself-supervised learning (SSL) offers a promising solution, existing methods\noften rely on augmentation strategies that can disrupt crucial structural\nsemantics in brain graphs. To address this, we propose SAM-BG, a two-stage\nframework for learning brain graph representations with structural semantic\npreservation. In the pre-training stage, an edge masker is trained on a small\nlabeled subset to capture key structural semantics. In the SSL stage, the\nextracted structural priors guide a structure-aware augmentation process,\nenabling the model to learn more semantically meaningful and robust\nrepresentations. Experiments on two real-world psychiatric datasets demonstrate\nthat SAM-BG outperforms state-of-the-art methods, particularly in small-labeled\ndata settings, and uncovers clinically relevant connectivity patterns that\nenhance interpretability. Our code is available at\nhttps://github.com/mjliu99/SAM-BG.", "AI": {"tldr": "SAM-BG\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u7528\u4e8e\u5b66\u4e60\u5177\u6709\u7ed3\u6784\u8bed\u4e49\u4fdd\u7559\u7684\u8111\u56fe\u8868\u793a\uff0c\u4ee5\u89e3\u51b3\u6807\u8bb0\u8111\u7f51\u7edc\u6570\u636e\u6709\u9650\u7684\u95ee\u9898\uff0c\u5e76\u5728\u7cbe\u795e\u75be\u75c5\u8bca\u65ad\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u6807\u8bb0\u7684\u8111\u7f51\u7edc\u6570\u636e\u6709\u9650\uff0c\u4f7f\u5f97\u51c6\u786e\u4e14\u53ef\u89e3\u91ca\u7684\u7cbe\u795e\u75be\u75c5\u8bca\u65ad\u5177\u6709\u6311\u6218\u6027\u3002\u73b0\u6709\u7684\u81ea\u76d1\u7763\u5b66\u4e60\uff08SSL\uff09\u65b9\u6cd5\u4f9d\u8d56\u7684\u589e\u5f3a\u7b56\u7565\u53ef\u80fd\u4f1a\u7834\u574f\u8111\u56fe\u4e2d\u7684\u5173\u952e\u7ed3\u6784\u8bed\u4e49\u3002", "method": "\u63d0\u51faSAM-BG\u6846\u67b6\uff0c\u5305\u62ec\u4e24\u4e2a\u9636\u6bb5\uff1a1. \u5728\u5c11\u91cf\u6807\u8bb0\u6570\u636e\u4e0a\u8bad\u7ec3\u8fb9\u7f18\u63a9\u7801\u5668\u4ee5\u6355\u83b7\u5173\u952e\u7ed3\u6784\u8bed\u4e49\u3002 2. \u5229\u7528\u63d0\u53d6\u7684\u7ed3\u6784\u5148\u9a8c\u6307\u5bfc\u611f\u77e5\u7ed3\u6784\u7684\u589e\u5f3a\u8fc7\u7a0b\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u5b66\u4e60\u66f4\u5177\u8bed\u4e49\u610f\u4e49\u548c\u9c81\u68d2\u6027\u7684\u8868\u793a\u3002", "result": "\u5728\u4e24\u4e2a\u771f\u5b9e\u7684\u7cbe\u795e\u75be\u75c5\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0cSAM-BG\u5728\u5c0f\u6837\u672c\u6807\u8bb0\u6570\u636e\u8bbe\u7f6e\u4e0b\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\uff0c\u5e76\u53d1\u73b0\u4e86\u53ef\u63d0\u9ad8\u53ef\u89e3\u91ca\u6027\u7684\u4e34\u5e8a\u76f8\u5173\u8fde\u63a5\u6a21\u5f0f\u3002", "conclusion": "SAM-BG\u901a\u8fc7\u4fdd\u7559\u7ed3\u6784\u8bed\u4e49\u6765\u5b66\u4e60\u8111\u56fe\u8868\u793a\uff0c\u5728\u7cbe\u795e\u75be\u75c5\u8bca\u65ad\u65b9\u9762\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\uff0c\u5c24\u5176\u662f\u5728\u6807\u8bb0\u6570\u636e\u6709\u9650\u7684\u60c5\u51b5\u4e0b\uff0c\u5e76\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2509.10036", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2509.10036", "abs": "https://arxiv.org/abs/2509.10036", "authors": ["Zhuowei Zhao", "Zhuo Zhang", "Hanzhi Wang", "Junhao Gan", "Zhifeng Bao", "Jianzhong Qi"], "title": "Approximate Graph Propagation Revisited: Dynamic Parameterized Queries, Tighter Bounds and Dynamic Updates", "comment": null, "summary": "We revisit Approximate Graph Propagation (AGP), a unified framework which\ncaptures various graph propagation tasks, such as PageRank, feature propagation\nin Graph Neural Networks (GNNs), and graph-based Retrieval-Augmented Generation\n(RAG). Our work focuses on the settings of dynamic graphs and dynamic\nparameterized queries, where the underlying graphs evolve over time (updated by\nedge insertions or deletions) and the input query parameters are specified on\nthe fly to fit application needs. Our first contribution is an interesting\nobservation that the SOTA solution, AGP-Static, can be adapted to support\ndynamic parameterized queries; however several challenges remain unresolved.\nFirstly, the query time complexity of AGP-Static is based on an assumption of\nusing an optimal algorithm for subset sampling in its query algorithm.\nUnfortunately, back to that time, such an algorithm did not exist; without such\nan optimal algorithm, an extra $O(\\log^2 n)$ factor is required in the query\ncomplexity, where $n$ is the number of vertices in the graphs. Secondly,\nAGP-Static performs poorly on dynamic graphs, taking $O(n\\log n)$ time to\nprocess each update. To address these challenges, we propose a new algorithm,\nAGP-Static++, which is simpler yet reduces roughly a factor of $O(\\log^2 n)$ in\nthe query complexity while preserving the approximation guarantees of\nAGP-Static. However, AGP-Static++ still requires $O(n)$ time to process each\nupdate. To better support dynamic graphs, we further propose AGP-Dynamic, which\nachieves $O(1)$ amortized time per update, significantly improving the\naforementioned $O(n)$ per-update bound, while still preserving the query\ncomplexity and approximation guarantees. Last, our comprehensive experiments\nvalidate the theoretical improvements: compared to the baselines, our algorithm\nachieves speedups of up to $177\\times$ on update time and $10\\times$ on query\nefficiency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAGP-Static++\u548cAGP-Dynamic\u4e24\u79cd\u65b0\u7b97\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u52a8\u6001\u56fe\u548c\u52a8\u6001\u53c2\u6570\u5316\u67e5\u8be2\u4e2d\u7684\u56fe\u4f20\u64ad\u95ee\u9898\uff0c\u5728\u67e5\u8be2\u548c\u66f4\u65b0\u6548\u7387\u4e0a\u5747\u6709\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u89e3\u51b3\u52a8\u6001\u56fe\u548c\u52a8\u6001\u53c2\u6570\u5316\u67e5\u8be2\u573a\u666f\u4e0b\uff0c\u73b0\u6709\u56fe\u4f20\u64ad\u6846\u67b6\uff08\u5982AGP-Static\uff09\u5728\u67e5\u8be2\u590d\u6742\u5ea6\u548c\u66f4\u65b0\u6548\u7387\u65b9\u9762\u5b58\u5728\u7684\u6311\u6218\u3002", "method": "AGP-Static++\u901a\u8fc7\u7b80\u5316\u7b97\u6cd5\uff0c\u5728\u4fdd\u6301\u8fd1\u4f3c\u4fdd\u8bc1\u7684\u540c\u65f6\uff0c\u964d\u4f4e\u4e86\u67e5\u8be2\u590d\u6742\u5ea6\u4e2d\u7684O(log^2 n)\u56e0\u5b50\u3002AGP-Dynamic\u901a\u8fc7\u5b9e\u73b0O(1)\u7684\u644a\u9500\u66f4\u65b0\u65f6\u95f4\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u52a8\u6001\u56fe\u66f4\u65b0\u7684\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u67e5\u8be2\u590d\u6742\u5ea6\u548c\u8fd1\u4f3c\u4fdd\u8bc1\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u57fa\u7ebf\u65b9\u6cd5\u76f8\u6bd4\uff0cAGP-Static++\u5728\u67e5\u8be2\u6548\u7387\u4e0a\u63d0\u5347\u663e\u8457\uff0cAGP-Dynamic\u5728\u66f4\u65b0\u65f6\u95f4\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u8fbe177\u500d\u7684\u52a0\u901f\uff0c\u67e5\u8be2\u6548\u7387\u63d0\u534710\u500d\u3002", "conclusion": "AGP-Static++\u548cAGP-Dynamic\u5728\u5904\u7406\u52a8\u6001\u56fe\u548c\u52a8\u6001\u53c2\u6570\u5316\u67e5\u8be2\u65b9\u9762\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5177\u6709\u663e\u8457\u7684\u7406\u8bba\u548c\u5b9e\u8df5\u4f18\u52bf\uff0c\u80fd\u591f\u6709\u6548\u63d0\u5347\u56fe\u4f20\u64ad\u4efb\u52a1\u7684\u6548\u7387\u3002"}}
{"id": "2509.09707", "categories": ["cs.NE", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.09707", "abs": "https://arxiv.org/abs/2509.09707", "authors": ["Camilo Chac\u00f3n Sartori", "Mart\u00edn Isla Pino", "Pedro Pinacho-Davidson", "Christian Blum"], "title": "LLM-Based Instance-Driven Heuristic Bias In the Context of a Biased Random Key Genetic Algorithm", "comment": "Submitted to a journal for review", "summary": "Integrating Large Language Models (LLMs) within metaheuristics opens a novel\npath for solving complex combinatorial optimization problems. While most\nexisting approaches leverage LLMs for code generation to create or refine\nspecific heuristics, they often overlook the structural properties of\nindividual problem instances. In this work, we introduce a novel framework that\nintegrates LLMs with a Biased Random-Key Genetic Algorithm (BRKGA) to solve the\nNP-hard Longest Run Subsequence problem. Our approach extends the\ninstance-driven heuristic bias paradigm by introducing a human-LLM\ncollaborative process to co-design and implement a set of computationally\nefficient metrics. The LLM analyzes these instance-specific metrics to generate\na tailored heuristic bias, which steers the BRKGA toward promising areas of the\nsearch space. We conduct a comprehensive experimental evaluation, including\nrigorous statistical tests, convergence and behavioral analyses, and targeted\nablation studies, comparing our method against a standard BRKGA baseline across\n1,050 generated instances of varying complexity. Results show that our\ntop-performing hybrid, BRKGA+Llama-4-Maverick, achieves statistically\nsignificant improvements over the baseline, particularly on the most complex\ninstances. Our findings confirm that leveraging an LLM to produce an a priori,\ninstance-driven heuristic bias is a valuable approach for enhancing\nmetaheuristics in complex optimization domains.", "AI": {"tldr": "LLM\u4e0eBRKGA\u7ed3\u5408\uff0c\u901a\u8fc7\u5b9e\u4f8b\u9a71\u52a8\u7684\u542f\u53d1\u5f0f\u504f\u5dee\u89e3\u51b3\u957f\u8dd1\u5b50\u5e8f\u5217\u95ee\u9898\uff0c\u5e76\u53d6\u5f97\u663e\u8457\u6539\u8fdb\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5229\u7528LLM\u751f\u6210\u4ee3\u7801\uff0c\u5ffd\u7565\u4e86\u95ee\u9898\u5b9e\u4f8b\u7684\u7ed3\u6784\u5c5e\u6027\u3002\u672c\u7814\u7a76\u65e8\u5728\u5229\u7528LLM\u7684\u5206\u6790\u80fd\u529b\uff0c\u7ed3\u5408\u5b9e\u4f8b\u7279\u5f81\uff0c\u751f\u6210\u542f\u53d1\u5f0f\u504f\u5dee\uff0c\u4ee5\u6307\u5bfc\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u7684\u641c\u7d22\u8fc7\u7a0b\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u6846\u67b6\uff0c\u5c06LLM\u4e0eBRKGA\u7ed3\u5408\uff0c\u901a\u8fc7\u4eba\u4e0eLLM\u534f\u4f5c\u8bbe\u8ba1\u8ba1\u7b97\u6548\u7387\u6307\u6807\uff0cLLM\u5206\u6790\u8fd9\u4e9b\u6307\u6807\u751f\u6210\u5b9a\u5236\u7684\u542f\u53d1\u5f0f\u504f\u5dee\uff0c\u5f15\u5bfcBRKGA\u641c\u7d22\u3002", "result": "\u57281050\u4e2a\u4e0d\u540c\u590d\u6742\u5ea6\u7684\u5b9e\u4f8b\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u8bc4\u4f30\uff0cBRKGA+Llama-4-Maverick\u7684\u8868\u73b0\u663e\u8457\u4f18\u4e8e\u57fa\u7ebfBRKGA\uff0c\u5c24\u5176\u662f\u5728\u590d\u6742\u5b9e\u4f8b\u4e0a\u3002", "conclusion": "\u5229\u7528LLM\u751f\u6210\u5148\u9a8c\u7684\u3001\u5b9e\u4f8b\u9a71\u52a8\u7684\u542f\u53d1\u5f0f\u504f\u5dee\uff0c\u662f\u589e\u5f3a\u590d\u6742\u4f18\u5316\u9886\u57df\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u7684\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2509.09738", "categories": ["cs.AI", "q-bio.QM", "I.2.7"], "pdf": "https://arxiv.org/pdf/2509.09738", "abs": "https://arxiv.org/abs/2509.09738", "authors": ["Umut Eser", "Yael Gozin", "L. Jay Stallons", "Ari Caroline", "Martin Preusse", "Brandon Rice", "Scott Wright", "Andrew Robertson"], "title": "Human-AI Collaboration Increases Efficiency in Regulatory Writing", "comment": null, "summary": "Background: Investigational New Drug (IND) application preparation is\ntime-intensive and expertise-dependent, slowing early clinical development.\nObjective: To evaluate whether a large language model (LLM) platform (AutoIND)\ncan reduce first-draft composition time while maintaining document quality in\nregulatory submissions. Methods: Drafting times for IND nonclinical written\nsummaries (eCTD modules 2.6.2, 2.6.4, 2.6.6) generated by AutoIND were directly\nrecorded. For comparison, manual drafting times for IND summaries previously\ncleared by the U.S. FDA were estimated from the experience of regulatory\nwriters ($\\geq$6 years) and used as industry-standard benchmarks. Quality was\nassessed by a blinded regulatory writing assessor using seven pre-specified\ncategories: correctness, completeness, conciseness, consistency, clarity,\nredundancy, and emphasis. Each sub-criterion was scored 0-3 and normalized to a\npercentage. A critical regulatory error was defined as any misrepresentation or\nomission likely to alter regulatory interpretation (e.g., incorrect NOAEL,\nomission of mandatory GLP dose-formulation analysis). Results: AutoIND reduced\ninitial drafting time by $\\sim$97% (from $\\sim$100 h to 3.7 h for 18,870\npages/61 reports in IND-1; and to 2.6 h for 11,425 pages/58 reports in IND-2).\nQuality scores were 69.6\\% and 77.9\\% for IND-1 and IND-2. No critical\nregulatory errors were detected, but deficiencies in emphasis, conciseness, and\nclarity were noted. Conclusions: AutoIND can dramatically accelerate IND\ndrafting, but expert regulatory writers remain essential to mature outputs to\nsubmission-ready quality. Systematic deficiencies identified provide a roadmap\nfor targeted model improvements.", "AI": {"tldr": "AutoIND,\u4e00\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5e73\u53f0\uff0c\u80fd\u663e\u8457\u7f29\u77ed\u65b0\u836f\u4e34\u5e8a\u8bd5\u9a8c\u7533\u8bf7\uff08IND\uff09\u975e\u4e34\u5e8a\u4e66\u9762\u603b\u7ed3\u7684\u8d77\u8349\u65f6\u95f4\uff08\u7ea697%\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u63a5\u53d7\u7684\u6587\u6863\u8d28\u91cf\uff0c\u4f46\u4ecd\u9700\u76d1\u7ba1\u5199\u4f5c\u4e13\u5bb6\u8fdb\u884c\u6da6\u8272\u4ee5\u8fbe\u5230\u63d0\u4ea4\u6807\u51c6\u3002", "motivation": "\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5e73\u53f0\uff08AutoIND\uff09\u662f\u5426\u80fd\u5728\u4fdd\u8bc1\u6587\u6863\u8d28\u91cf\u7684\u540c\u65f6\uff0c\u51cf\u5c11\u76d1\u7ba1\u63d0\u4ea4\u6587\u4ef6\uff08IND\u7533\u8bf7\uff09\u7684\u521d\u7a3f\u64b0\u5199\u65f6\u95f4\uff0c\u4ee5\u52a0\u901f\u65e9\u671f\u4e34\u5e8a\u5f00\u53d1\u3002", "method": "\u76f4\u63a5\u8bb0\u5f55AutoIND\u751f\u6210\u7684IND\u975e\u4e34\u5e8a\u4e66\u9762\u603b\u7ed3\uff08eCTD\u6a21\u57572.6.2\u30012.6.4\u30012.6.6\uff09\u7684\u8d77\u8349\u65f6\u95f4\u3002\u5c06\u6b64\u4e0e\u7ecf\u9a8c\u4e30\u5bcc\u7684\u76d1\u7ba1\u64b0\u7a3f\u4eba\uff08\u22656\u5e74\u7ecf\u9a8c\uff09\u624b\u52a8\u8d77\u8349\u5148\u524d\u5df2\u83b7\u7f8e\u56fdFDA\u6279\u51c6\u7684IND\u603b\u7ed3\u7684\u9884\u4f30\u65f6\u95f4\u8fdb\u884c\u6bd4\u8f83\uff0c\u4f5c\u4e3a\u884c\u4e1a\u6807\u51c6\u57fa\u51c6\u3002\u7531\u76f2\u8bc4\u7684\u76d1\u7ba1\u5199\u4f5c\u8bc4\u4f30\u5458\u4f7f\u7528\u4e03\u4e2a\u9884\u5b9a\u7c7b\u522b\uff08\u6b63\u786e\u6027\u3001\u5b8c\u6574\u6027\u3001\u7b80\u6d01\u6027\u3001\u4e00\u81f4\u6027\u3001\u6e05\u6670\u5ea6\u3001\u5197\u4f59\u6027\u3001\u5f3a\u8c03\u6027\uff09\u5bf9\u6587\u6863\u8d28\u91cf\u8fdb\u884c\u8bc4\u5206\uff0c\u8bc4\u5206\u6807\u51c6\u5316\u4e3a\u767e\u5206\u6bd4\u3002\u5173\u952e\u76d1\u7ba1\u9519\u8bef\u5b9a\u4e49\u4e3a\u53ef\u80fd\u6539\u53d8\u76d1\u7ba1\u89e3\u91ca\u7684\u4efb\u4f55\u9519\u8bef\u9648\u8ff0\u6216\u9057\u6f0f\u3002", "result": "AutoIND\u5c06\u521d\u59cb\u8d77\u8349\u65f6\u95f4\u7f29\u77ed\u4e86\u7ea697%\uff08IND-1\u768418,870\u9875/61\u4efd\u62a5\u544a\u4ece\u7ea6100\u5c0f\u65f6\u7f29\u77ed\u81f33.7\u5c0f\u65f6\uff1bIND-2\u768411,425\u9875/58\u4efd\u62a5\u544a\u7f29\u77ed\u81f32.6\u5c0f\u65f6\uff09\u3002IND-1\u548cIND-2\u7684\u8d28\u91cf\u8bc4\u5206\u5206\u522b\u4e3a69.6%\u548c77.9%\u3002\u672a\u68c0\u6d4b\u5230\u5173\u952e\u76d1\u7ba1\u9519\u8bef\uff0c\u4f46\u53d1\u73b0\u5f3a\u8c03\u6027\u3001\u7b80\u6d01\u6027\u548c\u6e05\u6670\u5ea6\u65b9\u9762\u5b58\u5728\u7f3a\u9677\u3002", "conclusion": "AutoIND\u80fd\u6781\u5927\u5730\u52a0\u901fIND\u7533\u8bf7\u7684\u8d77\u8349\u8fc7\u7a0b\uff0c\u4f46\u4e13\u5bb6\u76d1\u7ba1\u64b0\u7a3f\u4eba\u5bf9\u4e8e\u5c06\u8f93\u51fa\u6587\u4ef6\u6253\u78e8\u81f3\u53ef\u63d0\u4ea4\u7684\u8d28\u91cf\u4ecd\u7136\u662f\u5fc5\u4e0d\u53ef\u5c11\u7684\u3002\u5df2\u8bc6\u522b\u7684\u7cfb\u7edf\u6027\u7f3a\u9677\u4e3a\u6a21\u578b\u6539\u8fdb\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2509.09774", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2509.09774", "abs": "https://arxiv.org/abs/2509.09774", "authors": ["Doru Thom Popovici", "Mario Vega", "Angelos Ioannou", "Fabien Chaix", "Dania Mosuli", "Blair Reasoner", "Tan Nguyen", "Xiaokun Yang", "John Shalf"], "title": "Towards An Approach to Identify Divergences in Hardware Designs for HPC Workloads", "comment": "9 pages, 8 figures", "summary": "Developing efficient hardware accelerators for mathematical kernels used in\nscientific applications and machine learning has traditionally been a\nlabor-intensive task. These accelerators typically require low-level\nprogramming in Verilog or other hardware description languages, along with\nsignificant manual optimization effort. Recently, to alleviate this challenge,\nhigh-level hardware design tools like Chisel and High-Level Synthesis have\nemerged. However, as with any compiler, some of the generated hardware may be\nsuboptimal compared to expert-crafted designs. Understanding where these\ninefficiencies arise is crucial, as it provides valuable insights for both\nusers and tool developers. In this paper, we propose a methodology to\nhierarchically decompose mathematical kernels - such as Fourier transforms,\nmatrix multiplication, and QR factorization - into a set of common building\nblocks or primitives. Then the primitives are implemented in the different\nprogramming environments, and the larger algorithms get assembled. Furthermore,\nwe employ an automatic approach to investigate the achievable frequency and\nrequired resources. Performing this experimentation at each level will provide\nfairer comparisons between designs and offer guidance for both tool developers\nand hardware designers to adopt better practices.", "AI": {"tldr": "\u901a\u8fc7\u5c06\u6570\u5b66\u5185\u6838\u5206\u89e3\u4e3a\u5e38\u7528\u6784\u5efa\u5757\uff0c\u5e76\u81ea\u52a8\u5316\u5206\u6790\uff0c\u4e3a\u786c\u4ef6\u52a0\u901f\u5668\u8bbe\u8ba1\u63d0\u4f9b\u6307\u5bfc\u3002", "motivation": "\u624b\u52a8\u4f18\u5316\u786c\u4ef6\u52a0\u901f\u5668\uff08\u4f8b\u5982\u7528\u4e8e\u79d1\u5b66\u8ba1\u7b97\u548c\u673a\u5668\u5b66\u4e60\u7684\u6570\u5b66\u5185\u6838\uff09\u975e\u5e38\u8017\u65f6\uff0c\u9700\u8981\u4f4e\u7ea7\u7f16\u7a0b\u3002\u867d\u7136 Chisel \u548c HLS \u7b49\u9ad8\u7ea7\u5de5\u5177\u6709\u6240\u5e2e\u52a9\uff0c\u4f46\u751f\u6210\u7684\u786c\u4ef6\u53ef\u80fd\u4e0d\u5982\u4e13\u5bb6\u8bbe\u8ba1\u7684\u786c\u4ef6\u3002\u56e0\u6b64\uff0c\u7406\u89e3\u8fd9\u4e9b\u4f4e\u6548\u7387\u7684\u6765\u6e90\u5bf9\u4e8e\u7528\u6237\u548c\u5de5\u5177\u5f00\u53d1\u8005\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5c42\u5206\u89e3\u6570\u5b66\u5185\u6838\uff08\u5982\u5085\u7acb\u53f6\u53d8\u6362\u3001\u77e9\u9635\u4e58\u6cd5\u548c QR \u5206\u89e3\uff09\u5230\u4e00\u7ec4\u5e38\u7528\u6784\u5efa\u5757\uff08\u539f\u8bed\uff09\u7684\u65b9\u6cd5\u3002\u7136\u540e\uff0c\u5728\u4e0d\u540c\u7684\u7f16\u7a0b\u73af\u5883\u4e2d\u5b9e\u73b0\u8fd9\u4e9b\u539f\u8bed\uff0c\u5e76\u7ec4\u88c5\u6210\u66f4\u5927\u7684\u7b97\u6cd5\u3002\u6b64\u5916\uff0c\u91c7\u7528\u81ea\u52a8\u65b9\u6cd5\u6765\u7814\u7a76\u53ef\u5b9e\u73b0\u7684\u9891\u7387\u548c\u6240\u9700\u8d44\u6e90\u3002", "result": "\u901a\u8fc7\u5728\u6bcf\u4e2a\u7ea7\u522b\u8fdb\u884c\u5b9e\u9a8c\uff0c\u53ef\u4ee5\u66f4\u516c\u5e73\u5730\u6bd4\u8f83\u4e0d\u540c\u7684\u8bbe\u8ba1\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5de5\u5177\u5f00\u53d1\u8005\u548c\u786c\u4ef6\u8bbe\u8ba1\u5e08\u63d0\u4f9b\u4e86\u5b9d\u8d35\u7684\u89c1\u89e3\uff0c\u4ee5\u6539\u8fdb\u5b9e\u8df5\uff0c\u4ece\u800c\u5728\u786c\u4ef6\u52a0\u901f\u5668\u8bbe\u8ba1\u4e2d\u5b9e\u73b0\u66f4\u9ad8\u7684\u6548\u7387\u3002"}}
{"id": "2509.09777", "categories": ["eess.SY", "cs.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2509.09777", "abs": "https://arxiv.org/abs/2509.09777", "authors": ["Alexander Von Moll", "Dipankar Maity", "Meir Pachter", "Daigo Shishika", "Michael Dorothy"], "title": "Target Defense Using a Turret and Mobile Defender Team", "comment": "Submitted to IEEE L-CSS and the 2026 ACC", "summary": "A scenario is considered wherein a stationary, turn constrained agent\n(Turret) and a mobile agent (Defender) cooperate to protect the former from an\nadversarial mobile agent (Attacker). The Attacker wishes to reach the Turret\nprior to getting captured by either the Defender or Turret, if possible.\nMeanwhile, the Defender and Turret seek to capture the Attacker as far from the\nTurret as possible. This scenario is formulated as a differential game and\nsolved using a geometric approach. Necessary and sufficient conditions for the\nTurret-Defender team winning and the Attacker winning are given. In the case of\nthe Turret-Defender team winning equilibrium strategies for the min max\nterminal distance of the Attacker to the Turret are given. Three cases arise\ncorresponding to solo capture by the Defender, solo capture by the Turret, and\ncapture simultaneously by both Turret and Defender.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u4e00\u4e2a\u7531\u9759\u6b62\u7684 Turret \u548c\u79fb\u52a8\u7684 Defender \u7ec4\u6210\u7684\u5408\u4f5c\u56e2\u961f\uff0c\u5171\u540c\u9632\u5fa1\u4e00\u4e2a\u79fb\u52a8\u7684 Attacker\u3002\u76ee\u6807\u662f\u8ba9 Attacker \u5728\u88ab Defender \u6216 Turret \u6355\u83b7\u4e4b\u524d\u65e0\u6cd5\u5230\u8fbe Turret\uff0c\u540c\u65f6 Defender \u548c Turret \u5c3d\u53ef\u80fd\u8fdc\u79bb Turret \u6355\u83b7 Attacker\u3002", "motivation": "\u7814\u7a76\u4e00\u4e2a stationary, turn constrained agent (Turret) \u548c\u4e00\u4e2a mobile agent (Defender) \u5982\u4f55\u5408\u4f5c\u4ee5\u4fdd\u62a4 Turret \u514d\u53d7 adversarial mobile agent (Attacker) \u7684\u4fb5\u5bb3\u3002", "method": "\u5c06\u8be5\u573a\u666f\u6784\u9020\u6210\u4e00\u4e2a\u5fae\u5206\u535a\u5f08\uff0c\u5e76\u4f7f\u7528\u51e0\u4f55\u65b9\u6cd5\u6c42\u89e3\u3002", "result": "\u7ed9\u51fa\u4e86 Turret-Defender \u56e2\u961f\u83b7\u80dc\u548c Attacker \u83b7\u80dc\u7684\u5145\u8981\u6761\u4ef6\u3002\u5728 Turret-Defender \u56e2\u961f\u83b7\u80dc\u7684\u60c5\u51b5\u4e0b\uff0c\u7ed9\u51fa\u4e86 Attacker \u5230 Turret \u7684\u6700\u5c0f\u6700\u5927\u7ec8\u7aef\u8ddd\u79bb\u7684\u5747\u8861\u7b56\u7565\u3002\u63a8\u5bfc\u51fa\u4e86\u4e09\u79cd\u60c5\u51b5\uff1aDefender \u72ec\u5360\u6355\u83b7\u3001Turret \u72ec\u5360\u6355\u83b7\u4ee5\u53ca Turret \u548c Defender \u540c\u65f6\u6355\u83b7\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a Turret-Defender \u5408\u4f5c\u9632\u5fa1 Attacker \u7684\u573a\u666f\u63d0\u4f9b\u4e86\u7406\u8bba\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5206\u6790\u4e86\u4e0d\u540c\u6355\u83b7\u60c5\u51b5\u4e0b\u7684\u7b56\u7565\u3002"}}
{"id": "2509.09795", "categories": ["cs.DC", "cs.DB", "cs.DS", "cs.PF"], "pdf": "https://arxiv.org/pdf/2509.09795", "abs": "https://arxiv.org/abs/2509.09795", "authors": ["Arivarasan Karmegam", "Gabina Luz Bianchi", "Margarita Capretto", "Mart\u00edn Ceresa", "Antonio Fern\u00e1ndez Anta", "C\u00e9sar S\u00e1nchez"], "title": "Setchain Algorithms for Blockchain Scalability", "comment": null, "summary": "Setchain has been proposed to increase blockchain scalability by relaxing the\nstrict total order requirement among transactions. Setchain organizes elements\ninto a sequence of sets, referred to as epochs, so that elements within each\nepoch are unordered. In this paper, we propose and evaluate three distinct\nSetchain algorithms, that leverage an underlying block-based ledger. Vanilla is\na basic implementation that serves as a reference point. Compresschain\naggregates elements into batches, and compresses these batches before appending\nthem as epochs in the ledger. Hashchain converts batches into fixed-length\nhashes which are appended as epochs in the ledger. This requires Hashchain to\nuse a distributed service to obtain the batch contents from its hash. To allow\nlight clients to safely interact with only one server, the proposed algorithms\nmaintain, as part of the Setchain, proofs for the epochs. An epoch-proof is the\nhash of the epoch, cryptographically signed by a server. A client can verify\nthe correctness of an epoch with $f+1$ epoch-proofs (where $f$ is the maximum\nnumber of Byzantine servers assumed). All three Setchain algorithms are\nimplemented on top of the CometBFT blockchain application platform. We\nconducted performance evaluations across various configurations, using clusters\nof four, seven, and ten servers. Our results show that the Setchain algorithms\nreach orders of magnitude higher throughput than the underlying blockchain, and\nachieve finality with latency below 4 seconds.", "AI": {"tldr": "Setchain \u901a\u8fc7\u5c06\u4ea4\u6613\u95f4\u7684\u4e25\u683c\u5168\u5e8f\u8981\u6c42\u653e\u677e\u5230\u6bcf\u4e2a epoch \u5185\u7684\u5143\u7d20\u65e0\u5e8f\uff0c\u6765\u63d0\u9ad8\u533a\u5757\u94fe\u7684\u53ef\u6269\u5c55\u6027\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e09\u79cd Setchain \u7b97\u6cd5\uff08Vanilla\u3001Compresschain\u3001Hashchain\uff09\uff0c\u5b83\u4eec\u90fd\u5229\u7528\u4e86\u5e95\u5c42\u5757\u72b6\u5206\u7c7b\u8d26\uff0c\u5e76\u5b9e\u73b0\u4e86\u6bd4\u5e95\u5c42\u533a\u5757\u94fe\u9ad8\u51e0\u4e2a\u6570\u91cf\u7ea7\u7684\u541e\u5410\u91cf\u548c\u4f4e\u4e8e 4 \u79d2\u7684\u6700\u7ec8\u6027\u5ef6\u8fdf\u3002", "motivation": "Setchain \u7684\u63d0\u51fa\u662f\u4e3a\u4e86\u901a\u8fc7\u653e\u5bbd\u4ea4\u6613\u95f4\u4e25\u683c\u5168\u5e8f\u7684\u8981\u6c42\u6765\u63d0\u9ad8\u533a\u5757\u94fe\u7684\u53ef\u6269\u5c55\u6027\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e09\u79cd Setchain \u7b97\u6cd5\uff1aVanilla\uff08\u57fa\u7840\u5b9e\u73b0\uff09\u3001Compresschain\uff08\u5c06\u5143\u7d20\u805a\u5408\u4e3a\u6279\u6b21\u5e76\u538b\u7f29\uff09\u548c Hashchain\uff08\u5c06\u6279\u6b21\u8f6c\u6362\u4e3a\u56fa\u5b9a\u957f\u5ea6\u7684\u54c8\u5e0c\uff09\u3002\u8fd9\u4e9b\u7b97\u6cd5\u90fd\u5229\u7528\u4e86\u5e95\u5c42\u5757\u72b6\u5206\u7c7b\u8d26\uff0c\u5e76\u7ef4\u62a4\u4e86 epoch \u7684\u8bc1\u660e\uff0c\u5141\u8bb8\u8f7b\u5ba2\u6237\u7aef\u4e0e\u5355\u4e2a\u670d\u52a1\u5668\u5b89\u5168\u4ea4\u4e92\u3002\u7b97\u6cd5\u5728 CometBFT \u5e73\u53f0\u4e0a\u5b9e\u73b0\uff0c\u5e76\u5728\u4e0d\u540c\u670d\u52a1\u5668\u914d\u7f6e\u4e0b\u8fdb\u884c\u4e86\u6027\u80fd\u8bc4\u4f30\u3002", "result": "Setchain \u7b97\u6cd5\u7684\u541e\u5410\u91cf\u6bd4\u5e95\u5c42\u533a\u5757\u94fe\u9ad8\u51e0\u4e2a\u6570\u91cf\u7ea7\uff0c\u6700\u7ec8\u6027\u5ef6\u8fdf\u4f4e\u4e8e 4 \u79d2\u3002", "conclusion": "\u63d0\u51fa\u7684\u4e09\u79cd Setchain \u7b97\u6cd5\uff08Vanilla\u3001Compresschain\u3001Hashchain\uff09\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u533a\u5757\u94fe\u7684\u53ef\u6269\u5c55\u6027\uff0c\u5728\u6027\u80fd\u8bc4\u4f30\u4e2d\u5c55\u73b0\u51fa\u9ad8\u541e\u5410\u91cf\u548c\u4f4e\u5ef6\u8fdf\u3002"}}
{"id": "2509.09720", "categories": ["cs.CV", "cs.RO", "eess.IV"], "pdf": "https://arxiv.org/pdf/2509.09720", "abs": "https://arxiv.org/abs/2509.09720", "authors": ["Akansel Cosgun", "Lachlan Chumbley", "Benjamin J. Meyer"], "title": "Australian Supermarket Object Set (ASOS): A Benchmark Dataset of Physical Objects and 3D Models for Robotics and Computer Vision", "comment": null, "summary": "This paper introduces the Australian Supermarket Object Set (ASOS), a\ncomprehensive dataset comprising 50 readily available supermarket items with\nhigh-quality 3D textured meshes designed for benchmarking in robotics and\ncomputer vision applications. Unlike existing datasets that rely on synthetic\nmodels or specialized objects with limited accessibility, ASOS provides a\ncost-effective collection of common household items that can be sourced from a\nmajor Australian supermarket chain. The dataset spans 10 distinct categories\nwith diverse shapes, sizes, and weights. 3D meshes are acquired by a\nstructure-from-motion techniques with high-resolution imaging to generate\nwatertight meshes. The dataset's emphasis on accessibility and real-world\napplicability makes it valuable for benchmarking object detection, pose\nestimation, and robotics applications.", "AI": {"tldr": "ASOS\u662f\u4e00\u4e2a\u5305\u542b50\u4e2a\u5e38\u89c1\u8d85\u5e02\u7269\u54c1\u76843D\u6a21\u578b\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u673a\u5668\u4eba\u548c\u8ba1\u7b97\u673a\u89c6\u89c9\u57fa\u51c6\u6d4b\u8bd5\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u96c6\u4f9d\u8d56\u4e8e\u5408\u6210\u6a21\u578b\u6216\u96be\u4ee5\u83b7\u5f97\u7684\u7269\u4f53\uff0cASOS\u63d0\u4f9b\u4e86\u5e38\u89c1\u3001\u6613\u4e8e\u83b7\u53d6\u7684\u7269\u54c1\uff0c\u6210\u672c\u6548\u76ca\u9ad8\u3002", "method": "\u4f7f\u7528\u7ed3\u6784from-motion\u6280\u672f\u548c\u9ad8\u5206\u8fa8\u7387\u6210\u50cf\u6280\u672f\u751f\u6210\u4e86\u5177\u6709\u7eb9\u7406\u76843D\u7f51\u683c\u6a21\u578b\u3002", "result": "ASOS\u6570\u636e\u96c6\u5305\u542b10\u4e2a\u7c7b\u522b\uff0c50\u4e2a\u7269\u54c1\uff0c\u5177\u6709\u591a\u6837\u7684\u5f62\u72b6\u3001\u5927\u5c0f\u548c\u91cd\u91cf\uff0c\u6a21\u578b\u4e3a\u9632\u6c34\u7f51\u683c\u3002", "conclusion": "ASOS\u6570\u636e\u96c6\u56e0\u5176\u53ef\u53ca\u6027\u548c\u771f\u5b9e\u4e16\u754c\u7684\u9002\u7528\u6027\uff0c\u975e\u5e38\u9002\u5408\u7528\u4e8e\u7269\u4f53\u68c0\u6d4b\u3001\u59ff\u6001\u4f30\u8ba1\u548c\u673a\u5668\u4eba\u5e94\u7528\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002"}}
{"id": "2509.09819", "categories": ["cond-mat.mes-hall", "cond-mat.stat-mech", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2509.09819", "abs": "https://arxiv.org/abs/2509.09819", "authors": ["Sajal Dahal", "Alex H. Miller", "Viktor Krapivin", "Gal Orenstein", "Ryan A. Duncan", "Nicholas Leonard", "Matthew J. Hurley", "Jade Stanton", "Roman Mankowsky", "Henrik Lemke", "Anisha Singh", "Ian Fisher", "Mariano Trigo", "Samuel W. Teitelbaum"], "title": "Dimensionality reduction of optically generated vortex strings in a charge density wave", "comment": "7 pages, 3 figures. Supplemental AVI movies included", "summary": "In phase transitions, mesoscale structures such as topological defects,\nvortex strings, and domain walls control the path towards equilibrium, and thus\nthe functional properties of many active devices. In photoinduced phase\ntransitions driven by femtosecond laser excitation, the temporal (pulse\nduration) and spatial (penetration depth) structure of the optical excitation\npresent opportunities for control and creating structures with unique\ntopologies. By performing time-resolved optical pump, x-ray probe experiments\non the CDW system Pd-intercalated ErTe$_{3}$, we gain access to the nanoscale\ndynamics of the mesoscale topological features (vortex strings) produced after\na quench, which have a different apparent dimensionality than the topological\ndefects predicted from the bulk system. We show that these vortex strings\npersist for much longer than the electronic recovery time. The critical\nexponent obtained from power-law scaling of the intensity as a function of\nwavevector shows a reduction in the effective dimensionality of the topological\ndefects in the system, corroborated by time-dependent Ginzburg-Landau\nsimulations. Our results demonstrate a novel pathway to use light to control\nthe dimensionality and orientation of topological defects in quantum materials,\nwhich could be used to stabilize competing quantum states.", "AI": {"tldr": "Femtosecond laser excitation of ErTe3 reveals that light can control the dimensionality and orientation of topological defects, creating vortex strings with apparent lower dimensionality that persist longer than electronic recovery time. Time-resolved optical pump, x-ray probe experiments and simulations show a reduction in effective dimensionality, offering a new way to stabilize competing quantum states.", "motivation": "Understanding how mesoscale structures like topological defects, vortex strings, and domain walls influence phase transitions and the properties of active devices, particularly in photoinduced phase transitions driven by ultrafast laser excitation.", "method": "Utilizing time-resolved optical pump, x-ray probe experiments on the CDW system Pd-intercalated ErTe3, complemented by time-dependent Ginzburg-Landau simulations, to investigate the nanoscale dynamics of mesoscale topological features (vortex strings).", "result": "Observed vortex strings with an apparent dimensionality different from predictions based on the bulk system. These vortex strings were found to persist significantly longer than the electronic recovery time. Analysis of power-law scaling of intensity versus wavevector yielded a critical exponent indicating a reduction in the effective dimensionality of the topological defects.", "conclusion": "Demonstrated a novel method using light to control the dimensionality and orientation of topological defects in quantum materials, specifically creating persistent vortex strings in ErTe3. This control offers potential for stabilizing competing quantum states."}}
{"id": "2509.09769", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.09769", "abs": "https://arxiv.org/abs/2509.09769", "authors": ["Rutav Shah", "Shuijing Liu", "Qi Wang", "Zhenyu Jiang", "Sateesh Kumar", "Mingyo Seo", "Roberto Mart\u00edn-Mart\u00edn", "Yuke Zhu"], "title": "MimicDroid: In-Context Learning for Humanoid Robot Manipulation from Human Play Videos", "comment": "11 pages, 9 figures, 5 tables", "summary": "We aim to enable humanoid robots to efficiently solve new manipulation tasks\nfrom a few video examples. In-context learning (ICL) is a promising framework\nfor achieving this goal due to its test-time data efficiency and rapid\nadaptability. However, current ICL methods rely on labor-intensive teleoperated\ndata for training, which restricts scalability. We propose using human play\nvideos -- continuous, unlabeled videos of people interacting freely with their\nenvironment -- as a scalable and diverse training data source. We introduce\nMimicDroid, which enables humanoids to perform ICL using human play videos as\nthe only training data. MimicDroid extracts trajectory pairs with similar\nmanipulation behaviors and trains the policy to predict the actions of one\ntrajectory conditioned on the other. Through this process, the model acquired\nICL capabilities for adapting to novel objects and environments at test time.\nTo bridge the embodiment gap, MimicDroid first retargets human wrist poses\nestimated from RGB videos to the humanoid, leveraging kinematic similarity. It\nalso applies random patch masking during training to reduce overfitting to\nhuman-specific cues and improve robustness to visual differences. To evaluate\nfew-shot learning for humanoids, we introduce an open-source simulation\nbenchmark with increasing levels of generalization difficulty. MimicDroid\noutperformed state-of-the-art methods and achieved nearly twofold higher\nsuccess rates in the real world. Additional materials can be found on:\nut-austin-rpl.github.io/MimicDroid", "AI": {"tldr": "MimicDroid", "motivation": "Current in-context learning (ICL) methods for humanoid robots rely on labor-intensive teleoperated data, limiting scalability. This paper proposes using human play videos as a scalable and diverse training data source to enable ICL for humanoid robots.", "method": "MimicDroid extracts trajectory pairs with similar manipulation behaviors from human play videos and trains a policy to predict actions. It retargets human wrist poses to the humanoid and uses random patch masking during training to bridge the embodiment gap and improve robustness.", "result": "MimicDroid acquired ICL capabilities for adapting to novel objects and environments. It outperformed state-of-the-art methods and achieved nearly twofold higher success rates in the real world on a new simulation benchmark.", "conclusion": "MimicDroid enables humanoid robots to perform ICL using human play videos as the sole training data, offering a scalable and effective solution for learning new manipulation tasks."}}
{"id": "2509.09743", "categories": ["quant-ph", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2509.09743", "abs": "https://arxiv.org/abs/2509.09743", "authors": ["Mohammad Attrash", "Roi Baer"], "title": "Quantum Langevin Dynamics", "comment": "Master's thesis", "summary": "Previous years researchers began to simulate open quantum system, taking into\naccount the interaction between system and the environment. One approach to\ndeal with this problem is to use the density matrix within the\nLiouville-von-Neumann formalism or the Markovian variant the Lindblad\nequations. Another way is to use a stochastic approach where a random force is\nadded to the system. The benefit of the stochastic approach is to solve the\ndynamics of the system with less time and memory than the density matrix\napproaches. In this project we want to develop a stochastic approach that can\ndeal with the stochastic wave functions approach. We did this on a 2-level\nsystem and found that it works well when comparing to a density matrix\napproach. Next, we tested a quantum particle connect to a bath of harmonic\noscillators using the stochastic approach. We found that a friction term is\nnecessary and applied it. Like in the classical Langevin equations the friction\nconstant and the random force fluctuations are related by the\nfluctuation-dissipation constant. We showed that with friction the dynamics\ndecays to an ensemble with energy of $E_{gs}+k_BT$. However, we also found here\nare problems. The system seems to absorb energy indefinitely if the temperature\nis higher than the zero point energy or if the system is a Morse oscillator.\nThus more research is required to make this method work.", "AI": {"tldr": "\u7814\u7a76\u8005\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u7684\u5904\u7406\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\u7684\u65b9\u6cd5\uff0c\u5373\u968f\u673a\u6ce2\u51fd\u6570\u65b9\u6cd5\uff0c\u5e76\u5728\u4e8c\u7ef4\u7cfb\u7edf\u548c\u91cf\u5b50\u7c92\u5b50\u4e0e\u8c10\u632f\u5668\u6d74\u76f8\u4e92\u4f5c\u7528\u7684\u6848\u4f8b\u4e2d\u8fdb\u884c\u4e86\u6d4b\u8bd5\u3002", "motivation": "\u7814\u7a76\u8005\u60f3\u5f00\u53d1\u4e00\u79cd\u65b0\u7684\u5904\u7406\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\u7684\u65b9\u6cd5\uff0c\u5373\u968f\u673a\u6ce2\u51fd\u6570\u65b9\u6cd5\uff0c\u5e76\u5c06\u5176\u4e0e\u73b0\u6709\u7684\u5bc6\u5ea6\u77e9\u9635\u65b9\u6cd5\u8fdb\u884c\u6bd4\u8f83\u3002", "method": "\u7814\u7a76\u8005\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u7684\u5904\u7406\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\u7684\u65b9\u6cd5\uff0c\u5373\u968f\u673a\u6ce2\u51fd\u6570\u65b9\u6cd5\u3002\u4ed6\u4eec\u9996\u5148\u5728\u4e8c\u7ef4\u7cfb\u7edf\u4e0a\u8fdb\u884c\u4e86\u6d4b\u8bd5\uff0c\u7136\u540e\u5c06\u8be5\u65b9\u6cd5\u5e94\u7528\u4e8e\u4e00\u4e2a\u91cf\u5b50\u7c92\u5b50\u4e0e\u8c10\u632f\u5668\u6d74\u76f8\u4e92\u4f5c\u7528\u7684\u7cfb\u7edf\u3002\u5728\u540e\u8005\u7684\u60c5\u51b5\u4e0b\uff0c\u4ed6\u4eec\u52a0\u5165\u4e86\u4e00\u4e2a\u6469\u64e6\u9879\uff0c\u5e76\u7814\u7a76\u4e86\u8be5\u65b9\u6cd5\u5728\u4e0d\u540c\u6e29\u5ea6\u4e0b\u7684\u8868\u73b0\u3002", "result": "\u5728\u4e8c\u7ef4\u7cfb\u7edf\u4e0a\uff0c\u968f\u673a\u6ce2\u51fd\u6570\u65b9\u6cd5\u4e0e\u5bc6\u5ea6\u77e9\u9635\u65b9\u6cd5\u8868\u73b0\u826f\u597d\u3002\u7136\u800c\uff0c\u5728\u91cf\u5b50\u7c92\u5b50\u4e0e\u8c10\u632f\u5668\u6d74\u76f8\u4e92\u4f5c\u7528\u7684\u7cfb\u7edf\u4e2d\uff0c\u5f53\u6e29\u5ea6\u9ad8\u4e8e\u96f6\u70b9\u80fd\u6216\u7cfb\u7edf\u662f\u83ab\u5c14\u65af\u632f\u5b50\u65f6\uff0c\u7cfb\u7edf\u4f1a\u65e0\u9650\u5438\u6536\u80fd\u91cf\u3002\u52a0\u5165\u4e86\u6469\u64e6\u9879\u540e\uff0c\u7cfb\u7edf\u7684\u52a8\u529b\u5b66\u8870\u51cf\u5230\u80fd\u91cf\u4e3a Egs+kBT \u7684\u7cfb\u7efc\u3002", "conclusion": "\u968f\u673a\u6ce2\u51fd\u6570\u65b9\u6cd5\u5728\u5904\u7406\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\u65b9\u9762\u6709\u6f5c\u529b\uff0c\u4f46\u4ecd\u5b58\u5728\u4e00\u4e9b\u95ee\u9898\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u65e0\u9650\u80fd\u91cf\u5438\u6536\u65b9\u9762\u3002"}}
{"id": "2509.09952", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.09952", "abs": "https://arxiv.org/abs/2509.09952", "authors": ["Zhi Ying", "Boxiang Rong", "Jingyu Wang", "Maoyuan Xu"], "title": "Chord: Chain of Rendering Decomposition for PBR Material Estimation from Generated Texture Images", "comment": "Accepted to SIGGRAPH Asia 2025. Project page:\n  https://ubisoft-laforge.github.io/world/chord", "summary": "Material creation and reconstruction are crucial for appearance modeling but\ntraditionally require significant time and expertise from artists. While recent\nmethods leverage visual foundation models to synthesize PBR materials from\nuser-provided inputs, they often fall short in quality, flexibility, and user\ncontrol. We propose a novel two-stage generate-and-estimate framework for PBR\nmaterial generation. In the generation stage, a fine-tuned diffusion model\nsynthesizes shaded, tileable texture images aligned with user input. In the\nestimation stage, we introduce a chained decomposition scheme that sequentially\npredicts SVBRDF channels by passing previously extracted representation as\ninput into a single-step image-conditional diffusion model. Our method is\nefficient, high quality, and enables flexible user control. We evaluate our\napproach against existing material generation and estimation methods,\ndemonstrating superior performance. Our material estimation method shows strong\nrobustness on both generated textures and in-the-wild photographs. Furthermore,\nwe highlight the flexibility of our framework across diverse applications,\nincluding text-to-material, image-to-material, structure-guided generation, and\nmaterial editing.", "AI": {"tldr": "\u4e00\u79cd\u65b0\u7684\u4e24\u9636\u6bb5\u751f\u6210\u548c\u4f30\u8ba1\u6846\u67b6\uff0c\u7528\u4e8e\u4ece\u7528\u6237\u8f93\u5165\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u7075\u6d3b\u4e14\u53ef\u63a7\u7684 PBR \u6750\u6599\u3002", "motivation": "\u4f20\u7edf\u6750\u6599\u521b\u5efa\u8017\u65f6\u4e14\u9700\u8981\u4e13\u4e1a\u77e5\u8bc6\uff0c\u73b0\u6709\u57fa\u4e8e\u89c6\u89c9\u57fa\u7840\u6a21\u578b\u7684 PBR \u6750\u6599\u751f\u6210\u65b9\u6cd5\u5728\u8d28\u91cf\u3001\u7075\u6d3b\u6027\u548c\u7528\u6237\u63a7\u5236\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u6846\u67b6\uff1a\u7b2c\u4e00\u9636\u6bb5\u4f7f\u7528\u5fae\u8c03\u7684\u6269\u6563\u6a21\u578b\u751f\u6210\u5bf9\u9f50\u7528\u6237\u8f93\u5165\u7684 PBR \u7eb9\u7406\u56fe\u50cf\uff1b\u7b2c\u4e8c\u9636\u6bb5\u4f7f\u7528\u94fe\u5f0f\u5206\u89e3\u65b9\u6848\uff0c\u901a\u8fc7\u5c06\u5148\u524d\u63d0\u53d6\u7684\u8868\u793a\u4f5c\u4e3a\u8f93\u5165\uff0c\u6765\u9884\u6d4b SVBRDF \u901a\u9053\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u6548\u7387\u3001\u8d28\u91cf\u548c\u7528\u6237\u63a7\u5236\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u5728\u751f\u6210\u7684\u7eb9\u7406\u548c\u771f\u5b9e\u7167\u7247\u4e0a\u5747\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u6587\u672c\u5230\u6750\u8d28\u3001\u56fe\u50cf\u5230\u6750\u8d28\u3001\u7ed3\u6784\u5f15\u5bfc\u751f\u6210\u548c\u6750\u8d28\u7f16\u8f91\u7b49\u591a\u79cd\u5e94\u7528\u4e2d\u5c55\u73b0\u4e86\u7075\u6d3b\u6027\u548c\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2509.09826", "categories": ["cs.SI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.09826", "abs": "https://arxiv.org/abs/2509.09826", "authors": ["Kayla Duskin", "Joseph S. Schafer", "Alexandros Efstratiou", "Jevin D. West", "Emma S. Spiro"], "title": "The Role of Follow Networks and Twitter's Content Recommender on Partisan Skew and Rumor Exposure during the 2022 U.S. Midterm Election", "comment": "Accepted at the AAAI International Conference on Web and Social Media\n  (ICWSM) 2026", "summary": "Social media platforms shape users' experiences through the algorithmic\nsystems they deploy. In this study, we examine to what extent Twitter's content\nrecommender, in conjunction with a user's social network, impacts the topic,\npolitical skew, and reliability of information served on the platform during a\nhigh-stakes election. We utilize automated accounts to document Twitter's\nalgorithmically curated and reverse chronological timelines throughout the U.S.\n2022 midterm election. We find that the algorithmic timeline measurably\ninfluences exposure to election content, partisan skew, and the prevalence of\nlow-quality information and election rumors. Critically, these impacts are\nmediated by the partisan makeup of one's personal social network, which often\nexerts greater influence than the algorithm alone. We find that the algorithmic\nfeed decreases the proportion of election content shown to left-leaning\naccounts, and that it skews content toward right-leaning sources when compared\nto the reverse chronological feed. We additionally find evidence that the\nalgorithmic system increases the prevalence of election-related rumors for\nright-leaning accounts, and has mixed effects on the prevalence of low-quality\ninformation sources. Our work provides insight into the outcomes of Twitter's\ncomplex recommender system at a crucial time period before controversial\nchanges to the platform and in the midst of nationwide elections and highlights\nthe need for ongoing study of algorithmic systems and their role in democratic\nprocesses.", "AI": {"tldr": "Twitter\u7684\u7b97\u6cd5\u63a8\u8350\u57282022\u5e74\u7f8e\u56fd\u4e2d\u671f\u9009\u4e3e\u671f\u95f4\u4f1a\u5f71\u54cd\u7528\u6237\u63a5\u89e6\u5230\u7684\u4fe1\u606f\u4e3b\u9898\u3001\u653f\u6cbb\u503e\u5411\u548c\u4fe1\u606f\u53ef\u9760\u6027\uff0c\u4f46\u8fd9\u79cd\u5f71\u54cd\u4f1a\u53d7\u5230\u7528\u6237\u793e\u4ea4\u7f51\u7edc\u6784\u6210\u7684\u8c03\u8282\uff0c\u793e\u4ea4\u7f51\u7edc\u7684\u5f71\u54cd\u529b\u6709\u65f6\u751a\u81f3\u8d85\u8fc7\u7b97\u6cd5\u672c\u8eab\u3002", "motivation": "\u7814\u7a76Twitter\u7684\u5185\u5bb9\u63a8\u8350\u7b97\u6cd5\u4e0e\u5176\u7528\u6237\u793e\u4ea4\u7f51\u7edc\u7ed3\u5408\uff0c\u57282022\u5e74\u7f8e\u56fd\u4e2d\u671f\u9009\u4e3e\u671f\u95f4\u5bf9\u7528\u6237\u63a5\u6536\u5230\u7684\u4fe1\u606f\u4e3b\u9898\u3001\u653f\u6cbb\u503e\u5411\u548c\u53ef\u9760\u6027\u4ea7\u751f\u4f55\u79cd\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u81ea\u52a8\u5316\u8d26\u6237\u8bb0\u5f55Twitter\u57282022\u5e74\u7f8e\u56fd\u4e2d\u671f\u9009\u4e3e\u671f\u95f4\u7684\u7b97\u6cd5\u63a8\u8350\u65f6\u95f4\u7ebf\u548c\u6309\u65f6\u95f4\u5012\u5e8f\u6392\u5217\u65f6\u95f4\u7ebf\u3002", "result": "\u7b97\u6cd5\u63a8\u8350\u65f6\u95f4\u7ebf\u4f1a\u663e\u8457\u5f71\u54cd\u7528\u6237\u63a5\u89e6\u5230\u7684\u9009\u4e3e\u4fe1\u606f\u3001\u653f\u6cbb\u503e\u5411\u548c\u4f4e\u8d28\u91cf\u4fe1\u606f\u7684\u6bd4\u4f8b\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u7b97\u6cd5\u63a8\u8350\u4f1a\u51cf\u5c11\u5de6\u503e\u8d26\u6237\u63a5\u6536\u5230\u7684\u9009\u4e3e\u4fe1\u606f\u6bd4\u4f8b\uff0c\u5e76\u5c06\u5185\u5bb9\u503e\u5411\u4e8e\u53f3\u503e\u6765\u6e90\u3002\u6b64\u5916\uff0c\u7b97\u6cd5\u63a8\u8350\u4f1a\u589e\u52a0\u53f3\u503e\u8d26\u6237\u63a5\u6536\u5230\u7684\u9009\u4e3e\u8c23\u8a00\uff0c\u5e76\u5bf9\u4f4e\u8d28\u91cf\u4fe1\u606f\u6765\u6e90\u7684\u666e\u904d\u6027\u4ea7\u751f\u6df7\u5408\u5f71\u54cd\u3002", "conclusion": "Twitter\u7684\u7b97\u6cd5\u7cfb\u7edf\u5728\u9009\u4e3e\u671f\u95f4\u5bf9\u4fe1\u606f\u4f20\u64ad\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u4f46\u7528\u6237\u7684\u793e\u4ea4\u7f51\u7edc\u5728\u5176\u4e2d\u626e\u6f14\u7740\u5173\u952e\u7684\u8c03\u8282\u89d2\u8272\u3002\u7814\u7a76\u5f3a\u8c03\u4e86\u6301\u7eed\u7814\u7a76\u7b97\u6cd5\u7cfb\u7edf\u53ca\u5176\u5728\u6c11\u4e3b\u8fdb\u7a0b\u4e2d\u4f5c\u7528\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2509.10062", "categories": ["cs.LO", "cs.DM", "math.LO"], "pdf": "https://arxiv.org/pdf/2509.10062", "abs": "https://arxiv.org/abs/2509.10062", "authors": ["Janne Fuchser", "Nikolas M\u00e4hlmann", "Sebastian Siebertz"], "title": "A Note on Constructive Canonical Splitter Strategies in Nowhere Dense Graph Classes", "comment": null, "summary": "The radius-$r$ splitter game is played on a graph $G$ between two players:\nSplitter and Connector. In each round, Connector selects a vertex $v$, and the\ncurrent game arena is restricted to the radius-$r$ neighborhood of $v$. Then\nSplitter removes a vertex from this restricted subgraph. The game ends, and\nSplitter wins, when the arena becomes empty. Splitter aims to end the game as\nquickly as possible, while Connector tries to prolong it for as long as\npossible. The splitter game was introduced by Grohe, Kreutzer and Siebertz to\ncharacterize nowhere dense graph classes. They showed that a class\n$\\mathscr{C}$ of graphs is nowhere dense if and only if for every radius $r$\nthere exists a number $\\ell$ such that Splitter has a strategy on every $G\\in\n\\mathscr{C}$ to win the radius-$r$ splitter game in at most $\\ell$ rounds. It\nwas recently proved by Ohlmann et al. that there are only a bounded number of\npossible Splitter moves that are progressing, that is, moves that lead to an\narena where Splitter can win in one less round. The proof of Ohlmann et al. is\nbased on the compactness theorem and does not give a constructive bound on the\nnumber of progressing moves. In this work, we give a simple constructive proof,\nshowing that if Splitter can force a win in the radius-$r$ game in $k$ rounds,\nthen there are at most $(2r+1)^{\\,2^{k-1}-1}$ progressing moves.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4e3a\u534a\u5f84-r \u5206\u88c2\u6e38\u620f\u63d0\u4f9b\u4e86\u5206\u88c2\u8005\u83b7\u80dc\u7b56\u7565\u7684\u6e10\u8fdb\u5f0f\u79fb\u52a8\u6570\u91cf\u7684\u4e0a\u754c\u3002", "motivation": "\u4ecb\u7ecd\u534a\u5f84-r \u5206\u88c2\u6e38\u620f\uff0c\u8be5\u6e38\u620f\u662f\u56fe\u8bba\u4e2d\u7528\u4e8e\u8868\u5f81\u65e0\u5904\u4e0d\u5bc6\u56fe\u7c7b\u7684\u4e00\u4e2a\u5de5\u5177\uff0c\u5e76\u6307\u51fa\u5148\u524d\u5173\u4e8e\u5206\u88c2\u8005\u83b7\u80dc\u7b56\u7565\u7684\u7814\u7a76\u7f3a\u4e4f\u5efa\u8bbe\u6027\u754c\u9650\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u88c2\u8005\u5728\u534a\u5f84-r \u6e38\u620f\u4e2d\u4ee5 k \u8f6e\u83b7\u80dc\u65f6\uff0c\u6e10\u8fdb\u5f0f\u79fb\u52a8\u6570\u91cf\u7684\u4e0a\u754c\uff082r+1)^(2^(k-1)-1) \u7684\u6784\u9020\u6027\u8bc1\u660e\u3002", "result": "\u8bc1\u660e\u4e86\u5982\u679c\u5206\u88c2\u8005\u53ef\u4ee5\u5728\u534a\u5f84-r \u6e38\u620f\u4e2d\u8feb\u4f7f\u4ee5 k \u8f6e\u83b7\u80dc\uff0c\u90a3\u4e48\u6e10\u8fdb\u5f0f\u79fb\u52a8\u7684\u6570\u91cf\u81f3\u591a\u4e3a (2r+1)^(2^(k-1)-1)\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5173\u4e8e\u5206\u88c2\u8005\u6e38\u620f\u4e2d\u6e10\u8fdb\u5f0f\u79fb\u52a8\u6570\u91cf\u7684\u7b80\u5355\u6784\u9020\u6027\u8bc1\u660e\uff0c\u5f25\u8865\u4e86\u5148\u524d\u57fa\u4e8e\u7d27\u81f4\u6027\u5b9a\u7406\u7684\u8bc1\u660e\u4e2d\u7f3a\u4e4f\u6784\u9020\u6027\u754c\u9650\u7684\u4e0d\u8db3\u3002"}}
{"id": "2509.09692", "categories": ["physics.app-ph", "cond-mat.soft"], "pdf": "https://arxiv.org/pdf/2509.09692", "abs": "https://arxiv.org/abs/2509.09692", "authors": ["Nikhil Sethia", "Joseph Sushil Rao", "Amit Manicka", "Michael L. Etheridge", "Erik B. Finger", "John C. Bischof", "Cari S. Dutcher"], "title": "Image detection-based high-throughput sorting of particles using traveling surface acoustic waves in microscale flows", "comment": "31 pages, 5 figures", "summary": "Large particle sorters have potential applications in sorting microplastics\nand large biomaterials (>50 micrometer), such as tissues, spheroids, organoids,\nand embryos. Though great advancements have been made in image-based sorting of\ncells and particles (<50 micrometer), their translation for high-throughput\nsorting of larger biomaterials and particles (>50 micrometer) has been more\nlimited. An image-based detection technique is highly desirable due to richness\nof the data (including size, shape, color, morphology, and optical density)\nthat can be extracted from live images of individualized biomaterials or\nparticles. Such a detection technique is label-free and can be integrated with\na contact-free actuation mechanism such as one based on traveling surface\nacoustic waves (TSAWs). Recent advances in using TSAWs for sorting cells and\nparticles (<50 micrometer) have demonstrated short response times (<1 ms), high\nbiocompatibility, and reduced energy requirements to actuate. Additionally,\nTSAW-based devices are miniaturized and easier to integrate with an image-based\ndetection technique. In this work, a high-throughput image-detection based\nlarge particle microfluidic sorting technique is implemented. The technique is\nused to separate binary mixtures of small and large polyethylene particles\n(ranging between ~45-180 micrometer in size). All particles in flow were first\noptically interrogated for size, followed by actuations using momentum transfer\nfrom TSAW pulses, if they satisfied the size cutoff criterion. The effect of\ncontrol parameters such as duration and power of TSAW actuation pulse, inlet\nflow rates, and sample dilution on sorting efficiency and throughput was\nobserved. At the chosen conditions, this sorting technique can sort on average\n~4.9-34.3 particles/s (perform ~2-3 actuations/s), depending on the initial\nsample composition and concentration.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u50cf\u8bc6\u522b\u548c\u8868\u9762\u58f0\u6ce2\u7684\u5fae\u6d41\u63a7\u5927\u9897\u7c92\u5206\u9009\u6280\u672f\uff0c\u53ef\u7528\u4e8e\u5206\u9009\u5927\u4e8e50\u5fae\u7c73\u7684\u5fae\u5851\u6599\u548c\u751f\u7269\u6750\u6599\u3002", "motivation": "\u867d\u7136\u57fa\u4e8e\u56fe\u50cf\u8bc6\u522b\u7684\u7ec6\u80de\u548c\u9897\u7c92\uff08<50\u5fae\u7c73\uff09\u5206\u9009\u6280\u672f\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5c06\u5176\u5e94\u7528\u4e8e\u5927\u9897\u7c92\uff08>50\u5fae\u7c73\uff09\u751f\u7269\u6750\u6599\u7684\u9ad8\u901a\u91cf\u5206\u9009\u4ecd\u7136\u6709\u9650\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u63d0\u53d6\u4e30\u5bcc\u4fe1\u606f\uff08\u5c3a\u5bf8\u3001\u5f62\u72b6\u3001\u989c\u8272\u3001\u5f62\u6001\u548c\u5149\u5bc6\u5ea6\uff09\u7684\u65e0\u6807\u8bb0\u56fe\u50cf\u8bc6\u522b\u6280\u672f\uff0c\u5e76\u80fd\u4e0e\u975e\u63a5\u89e6\u5f0f\u9a71\u52a8\u673a\u5236\uff08\u5982\u8868\u9762\u58f0\u6ce2\uff09\u96c6\u6210\u3002", "method": "\u7814\u7a76\u5b9e\u73b0\u4e86\u4e00\u79cd\u9ad8\u901a\u91cf\u56fe\u50cf\u8bc6\u522b\u5927\u9897\u7c92\u5fae\u6d41\u63a7\u5206\u9009\u6280\u672f\u3002\u8be5\u6280\u672f\u901a\u8fc7\u5149\u5b66\u624b\u6bb5\u8bc6\u522b\u9897\u7c92\u5c3a\u5bf8\uff0c\u5e76\u5229\u7528\u8868\u9762\u58f0\u6ce2\uff08TSAW\uff09\u8109\u51b2\u7684\u52a8\u91cf\u8f6c\u79fb\u8fdb\u884c\u5206\u9009\uff0c\u5c06\u5c3a\u5bf8\u5927\u4e8e\u7279\u5b9a\u9608\u503c\u7684\u9897\u7c92\u79fb\u51fa\u3002\u7814\u7a76\u4e86\u63a7\u5236\u53c2\u6570\uff08TSAW\u8109\u51b2\u6301\u7eed\u65f6\u95f4\u548c\u529f\u7387\u3001\u5165\u53e3\u6d41\u901f\u3001\u6837\u54c1\u7a00\u91ca\u5ea6\uff09\u5bf9\u5206\u9009\u6548\u7387\u548c\u901a\u91cf\u7684\u5f71\u54cd\u3002", "result": "\u8be5\u6280\u672f\u80fd\u591f\u5bf9\u5305\u542b\u7ea645-180\u5fae\u7c73\u5c3a\u5bf8\u7684\u805a\u4e59\u70ef\u9897\u7c92\u7684\u4e8c\u5143\u6df7\u5408\u7269\u8fdb\u884c\u5206\u9009\u3002\u5728\u9009\u5b9a\u7684\u6761\u4ef6\u4e0b\uff0c\u8be5\u5206\u9009\u6280\u672f\u5e73\u5747\u6bcf\u79d2\u53ef\u5206\u9009\u7ea64.9-34.3\u4e2a\u9897\u7c92\uff08\u6bcf\u79d2\u6267\u884c\u7ea62-3\u6b21\u9a71\u52a8\uff09\uff0c\u5177\u4f53\u53d6\u51b3\u4e8e\u521d\u59cb\u6837\u54c1\u7ec4\u6210\u548c\u6d53\u5ea6\u3002", "conclusion": "\u8be5\u7814\u7a76\u6210\u529f\u5b9e\u73b0\u4e86\u4e00\u79cd\u9ad8\u901a\u91cf\u56fe\u50cf\u8bc6\u522b\u5927\u9897\u7c92\u5fae\u6d41\u63a7\u5206\u9009\u6280\u672f\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u5728\u5206\u79bb\u4e0d\u540c\u5c3a\u5bf8\u805a\u4e59\u70ef\u9897\u7c92\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u4e3a\u5927\u9897\u7c92\u751f\u7269\u6750\u6599\u548c\u5fae\u5851\u6599\u7684\u5206\u9009\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.09906", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09906", "abs": "https://arxiv.org/abs/2509.09906", "authors": ["Alexandra Fetsch", "Iurii Savvateev", "Racem Ben Romdhane", "Martin Wiedmann", "Artemiy Dimov", "Maciej Durkalec", "Josef Teichmann", "Jakob Zinsstag", "Konstantinos Koutsoumanis", "Andreja Rajkovic", "Jason Mann", "Mauro Tonolla", "Monika Ehling-Schulz", "Matthias Filter", "Sophia Johler"], "title": "Tackling One Health Risks: How Large Language Models are leveraged for Risk Negotiation and Consensus-building", "comment": null, "summary": "Key global challenges of our times are characterized by complex\ninterdependencies and can only be effectively addressed through an integrated,\nparticipatory effort. Conventional risk analysis frameworks often reduce\ncomplexity to ensure manageability, creating silos that hinder comprehensive\nsolutions. A fundamental shift towards holistic strategies is essential to\nenable effective negotiations between different sectors and to balance the\ncompeting interests of stakeholders. However, achieving this balance is often\nhindered by limited time, vast amounts of information, and the complexity of\nintegrating diverse perspectives. This study presents an AI-assisted\nnegotiation framework that incorporates large language models (LLMs) and\nAI-based autonomous agents into a negotiation-centered risk analysis workflow.\nThe framework enables stakeholders to simulate negotiations, systematically\nmodel dynamics, anticipate compromises, and evaluate solution impacts. By\nleveraging LLMs' semantic analysis capabilities we could mitigate information\noverload and augment decision-making process under time constraints.\nProof-of-concept implementations were conducted in two real-world scenarios:\n(i) prudent use of a biopesticide, and (ii) targeted wild animal population\ncontrol. Our work demonstrates the potential of AI-assisted negotiation to\naddress the current lack of tools for cross-sectoral engagement. Importantly,\nthe solution's open source, web based design, suits for application by a\nbroader audience with limited resources and enables users to tailor and develop\nit for their own needs.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u81ea\u4e3bAI\u4ee3\u7406\u7684AI\u8f85\u52a9\u8c08\u5224\u6846\u67b6\uff0c\u7528\u4e8e\u8de8\u90e8\u95e8\u98ce\u9669\u5206\u6790\u548c\u51b3\u7b56\uff0c\u4ee5\u5e94\u5bf9\u590d\u6742\u5168\u7403\u6311\u6218\u3002", "motivation": "\u4f20\u7edf\u98ce\u9669\u5206\u6790\u6846\u67b6\u56e0\u8fc7\u5ea6\u7b80\u5316\u590d\u6742\u6027\u800c\u5f62\u6210\u5b64\u5c9b\uff0c\u963b\u788d\u4e86\u7efc\u5408\u89e3\u51b3\u65b9\u6848\u7684\u5236\u5b9a\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u591f\u4fc3\u8fdb\u8de8\u90e8\u95e8\u5408\u4f5c\u548c\u5e73\u8861\u5404\u65b9\u5229\u76ca\u7684\u6574\u4f53\u6027\u7b56\u7565\u3002", "method": "\u8be5\u7814\u7a76\u6784\u5efa\u4e86\u4e00\u4e2aAI\u8f85\u52a9\u8c08\u5224\u6846\u67b6\uff0c\u6574\u5408\u4e86LLMs\u548cAI\u81ea\u4e3b\u4ee3\u7406\uff0c\u5d4c\u5165\u5230\u4ee5\u8c08\u5224\u4e3a\u4e2d\u5fc3\u7684\u98ce\u9669\u5206\u6790\u5de5\u4f5c\u6d41\u4e2d\uff0c\u4ee5\u6a21\u62df\u8c08\u5224\u3001\u5efa\u6a21\u52a8\u6001\u3001\u9884\u6d4b\u59a5\u534f\u548c\u8bc4\u4f30\u89e3\u51b3\u65b9\u6848\u7684\u5f71\u54cd\u3002", "result": "\u901a\u8fc7\u5728\u5927\u8bed\u8a00\u6a21\u578b\u8bed\u4e49\u5206\u6790\u80fd\u529b\u7684\u5e2e\u52a9\u4e0b\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u7f13\u89e3\u4fe1\u606f\u8fc7\u8f7d\uff0c\u5e76\u5728\u65f6\u95f4\u9650\u5236\u4e0b\u589e\u5f3a\u51b3\u7b56\u8fc7\u7a0b\u3002\u5728\u751f\u7269\u519c\u836f\u7684\u8c28\u614e\u4f7f\u7528\u548c\u91ce\u751f\u52a8\u7269\u79cd\u7fa4\u7684\u76ee\u6807\u63a7\u5236\u4e24\u4e2a\u771f\u5b9e\u573a\u666f\u4e2d\u7684\u6982\u5ff5\u9a8c\u8bc1\u5b9e\u65bd\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u5c55\u793a\u4e86AI\u8f85\u52a9\u8c08\u5224\u5728\u89e3\u51b3\u5f53\u524d\u8de8\u90e8\u95e8\u53c2\u4e0e\u5de5\u5177\u7f3a\u4e4f\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\u3002\u5176\u5f00\u6e90\u3001\u57fa\u4e8e\u7f51\u7edc\u7684\u7279\u6027\u4f7f\u5176\u9002\u7528\u4e8e\u8d44\u6e90\u6709\u9650\u7684\u5e7f\u5927\u7528\u6237\uff0c\u5e76\u5141\u8bb8\u7528\u6237\u6839\u636e\u81ea\u8eab\u9700\u6c42\u8fdb\u884c\u5b9a\u5236\u548c\u5f00\u53d1\u3002"}}
{"id": "2509.09936", "categories": ["cs.LG", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2509.09936", "abs": "https://arxiv.org/abs/2509.09936", "authors": ["Saarth Gaonkar", "Xiang Zheng", "Haocheng Xi", "Rishabh Tiwari", "Kurt Keutzer", "Dmitriy Morozov", "Michael W. Mahoney", "Amir Gholami"], "title": "SciML Agents: Write the Solver, Not the Solution", "comment": null, "summary": "Recent work in scientific machine learning aims to tackle scientific tasks\ndirectly by predicting target values with neural networks (e.g.,\nphysics-informed neural networks, neural ODEs, neural operators, etc.), but\nattaining high accuracy and robustness has been challenging. We explore an\nalternative view: use LLMs to write code that leverages decades of numerical\nalgorithms. This shifts the burden from learning a solution function to making\ndomain-aware numerical choices. We ask whether LLMs can act as SciML agents\nthat, given a natural-language ODE description, generate runnable code that is\nscientifically appropriate, selecting suitable solvers (stiff vs. non-stiff),\nand enforcing stability checks. There is currently no benchmark to measure this\nkind of capability for scientific computing tasks. As such, we first introduce\ntwo new datasets: a diagnostic dataset of adversarial \"misleading\" problems;\nand a large-scale benchmark of 1,000 diverse ODE tasks. The diagnostic set\ncontains problems whose superficial appearance suggests stiffness, and that\nrequire algebraic simplification to demonstrate non-stiffness; and the\nlarge-scale benchmark spans stiff and non-stiff ODE regimes. We evaluate open-\nand closed-source LLM models along two axes: (i) unguided versus guided\nprompting with domain-specific knowledge; and (ii) off-the-shelf versus\nfine-tuned variants. Our evaluation measures both executability and numerical\nvalidity against reference solutions. We find that with sufficient context and\nguided prompts, newer instruction-following models achieve high accuracy on\nboth criteria. In many cases, recent open-source systems perform strongly\nwithout fine-tuning, while older or smaller models still benefit from\nfine-tuning. Overall, our preliminary results indicate that careful prompting\nand fine-tuning can yield a specialized LLM agent capable of reliably solving\nsimple ODE problems.", "AI": {"tldr": "LLMs \u53ef\u7528\u4e8e\u751f\u6210\u6c42\u89e3\u5e38\u5fae\u5206\u65b9\u7a0b\uff08ODE\uff09\u95ee\u9898\u7684\u4ee3\u7801\uff0c\u901a\u8fc7\u9009\u62e9\u5408\u9002\u7684\u6570\u503c\u6c42\u89e3\u5668\u548c\u6267\u884c\u7a33\u5b9a\u6027\u68c0\u67e5\u6765\u786e\u4fdd\u79d1\u5b66\u4e0a\u7684\u51c6\u786e\u6027\u3002\u7814\u7a76\u8005\u6784\u5efa\u4e86\u65b0\u7684\u6570\u636e\u96c6\u6765\u8bc4\u4f30LLMs\u7684\u80fd\u529b\uff0c\u5e76\u53d1\u73b0\u7ecf\u8fc7\u9002\u5f53\u5f15\u5bfc\u548c\u5fae\u8c03\u7684LLMs\u80fd\u591f\u53ef\u9760\u5730\u89e3\u51b3\u7b80\u5355\u7684ODE\u95ee\u9898\u3002", "motivation": "\u76f4\u63a5\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u89e3\u51b3\u79d1\u5b66\u4efb\u52a1\uff08\u5982PINNs, Neural ODEs\u7b49\uff09\u5728\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u65b9\u9762\u5b58\u5728\u6311\u6218\u3002\u672c\u7814\u7a76\u63d0\u51fa\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u751f\u6210\u4ee3\u7801\uff0c\u4ece\u800c\u5229\u7528\u73b0\u6709\u7684\u6570\u503c\u7b97\u6cd5\uff0c\u5c06\u91cd\u70b9\u4ece\u5b66\u4e60\u6c42\u89e3\u51fd\u6570\u8f6c\u79fb\u5230\u9886\u57df\u611f\u77e5\u578b\u7684\u6570\u503c\u9009\u62e9\u4e0a\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u5bf9\u6297\u6027\u201c\u8bef\u5bfc\u6027\u201d\u95ee\u9898\u8bca\u65ad\u6570\u636e\u96c6\u548c\u4e00\u4e2a\u5305\u542b1000\u4e2aODE\u4efb\u52a1\u7684\u5927\u89c4\u6a21\u57fa\u51c6\u6d4b\u8bd5\u96c6\u3002\u8bc4\u4f30\u4e86\u5f00\u6e90\u548c\u95ed\u6e90LLMs\u5728\u65e0\u5f15\u5bfc\u548c\u6709\u5f15\u5bfc\u63d0\u793a\uff08\u7ed3\u5408\u9886\u57df\u77e5\u8bc6\uff09\u4ee5\u53ca\u73b0\u6210\u6a21\u578b\u548c\u5fae\u8c03\u6a21\u578b\u4e0a\u7684\u8868\u73b0\u3002\u8bc4\u4f30\u6307\u6807\u5305\u62ec\u4ee3\u7801\u7684\u53ef\u6267\u884c\u6027\u548c\u6570\u503c\u6709\u6548\u6027\uff08\u4e0e\u53c2\u8003\u89e3\u76f8\u6bd4\uff09\u3002", "result": "\u5728\u6709\u8db3\u591f\u4e0a\u4e0b\u6587\u548c\u5f15\u5bfc\u63d0\u793a\u7684\u60c5\u51b5\u4e0b\uff0c\u8f83\u65b0\u7684\u6307\u4ee4\u9075\u5faa\u6a21\u578b\u5728\u53ef\u6267\u884c\u6027\u548c\u6570\u503c\u6709\u6548\u6027\u65b9\u9762\u5747\u80fd\u8fbe\u5230\u9ad8\u51c6\u786e\u7387\u3002\u8bb8\u591a\u6700\u65b0\u7684\u5f00\u6e90\u7cfb\u7edf\u5728\u672a\u7ecf\u5fae\u8c03\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u826f\u597d\uff0c\u800c\u8f83\u65e7\u6216\u8f83\u5c0f\u7684\u6a21\u578b\u5219\u4ece\u5fae\u8c03\u4e2d\u53d7\u76ca\u66f4\u591a\u3002", "conclusion": "\u521d\u6b65\u7ed3\u679c\u8868\u660e\uff0c\u901a\u8fc7\u4ed4\u7ec6\u7684\u63d0\u793a\u548c\u5fae\u8c03\uff0c\u53ef\u4ee5\u521b\u5efa\u4e00\u4e2a\u80fd\u591f\u53ef\u9760\u89e3\u51b3\u7b80\u5355ODE\u95ee\u9898\u7684\u4e13\u4e1aLLM\u4ee3\u7406\u3002"}}
{"id": "2509.09820", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.09820", "abs": "https://arxiv.org/abs/2509.09820", "authors": ["Ahmed Ali Abbasi", "Namrata Vaswani"], "title": "Locally Permuted Low Rank Column-wise Sensing", "comment": null, "summary": "We precisely formulate, and provide a solution for, the Low Rank Columnwise\nSensing (LRCS) problem when some of the observed data is\nscrambled/permuted/unlabeled. This problem, which we refer to as permuted LRCS,\nlies at the intersection of two distinct topics of recent research: unlabeled\nsensing and low rank column-wise (matrix) sensing. We introduce a novel\ngeneralization of the recently developed Alternating Gradient Descent and\nMinimization (AltGDMin) algorithm to solve this problem. We also develop an\nalternating minimization (AltMin) solution. We show, using simulation\nexperiments, that both converge but PermutedAltGDmin is much faster than\nPermuted-AltMin.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u89e3\u51b3\u5e26\u6270\u52a8\u5217\u4f20\u611f\u95ee\u9898\u7684\u4ea4\u66ff\u68af\u5ea6\u4e0b\u964d\u548c\u6700\u5c0f\u5316\uff08AltGDMin\uff09\u7b97\u6cd5\u7684\u6cdb\u5316\u7248\u672c\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u79cd\u4ea4\u66ff\u6700\u5c0f\u5316\uff08AltMin\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u4eff\u771f\u5b9e\u9a8c\u8bc1\u660e\u4e86PermutedAltGDmin\u6bd4Permuted-AltMin\u6536\u655b\u66f4\u5feb\u3002", "motivation": "\u89e3\u51b3\u4f4e\u79e9\u5217\u4f20\u611f\u95ee\u9898\uff08LRCS\uff09\u4e2d\u89c2\u6d4b\u6570\u636e\u90e8\u5206\u88ab\u6270\u52a8\uff08\u6253\u4e71/\u7f6e\u6362/\u672a\u6807\u8bb0\uff09\u7684\u60c5\u51b5\uff0c\u5373\u7f6e\u6362LRCS\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u4ea4\u66ff\u68af\u5ea6\u4e0b\u964d\u548c\u6700\u5c0f\u5316\uff08AltGDMin\uff09\u7b97\u6cd5\u7684\u6cdb\u5316\u7248\u672c\u6765\u89e3\u51b3\u7f6e\u6362LRCS\u95ee\u9898\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u79cd\u4ea4\u66ff\u6700\u5c0f\u5316\uff08AltMin\uff09\u65b9\u6cd5\u3002", "result": "\u4eff\u771f\u5b9e\u9a8c\u8868\u660e\uff0c\u4e24\u79cd\u65b9\u6cd5\u90fd\u80fd\u6536\u655b\uff0c\u4f46PermutedAltGDmin\u6bd4Permuted-AltMin\u6536\u655b\u901f\u5ea6\u5feb\u5f97\u591a\u3002", "conclusion": "\u63d0\u51fa\u7684PermutedAltGDmin\u7b97\u6cd5\u5728\u89e3\u51b3\u7f6e\u6362LRCS\u95ee\u9898\u4e0a\u6bd4Permuted-AltMin\u66f4\u6709\u6548\u7387\u3002"}}
{"id": "2509.09903", "categories": ["cond-mat.mtrl-sci", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2509.09903", "abs": "https://arxiv.org/abs/2509.09903", "authors": ["Hengdi Zhao", "Xiuquan Zhou", "Hyowon Park", "Tianqi Deng", "Brandon Wilfong", "Alann P. Au II", "Samuel E. Pate", "Craig M. Brown", "Hui Wu", "Tushar Bhowmick", "Tessa McNamee", "Ravhi Kumar", "Yu-Sheng Chen", "Zhi-Li Xiao", "Russell Hemley", "Weizhao Cai", "Shanti Deemyad", "Duck-Young Chung", "Stephan Rosenkranz", "Mercouri G. Kanatzidis"], "title": "Evolution from Topological Dirac Metal to Flat-band-Induced Antiferromagnet in Layered KxNi4S2 (0<=x<=1)", "comment": null, "summary": "Condensed matter systems with coexisting Dirac cones and flat bands, and a\nswitchable control between them within a single system, are desirable but\nremarkably uncommon. Here we report a layered quantum material system, KxNi4S2\n(0 <= x <= 1), that simultaneously hosts both characteristics without involving\ntypical Kagome/honeycomb lattices. Enabled by a topochemical K-deintercalation\nprocess, the Fermi surface can be fine-tuned continuously over a wide range of\nenergies. Consequently, a non-magnetic Dirac-metal state with a topological\nnontrivial Z2 index of 1;(000), supported by first-principles calculations and\nhigh mobility up to 1471 cm2V-1s-1, is observed on the K-rich x = 1 side,\nwhereas a flat-band induced antiferromagnetic state with TN up to 10.1 K\nemerges as K-content approaches 0. The KxNi4S2 system offers a versatile\nplatform for exploring emerging phenomena and underscores a viable pathway for\nin-situ control of quantum materials dominated by Dirac cones, flat bands, and\ntheir interplay.", "AI": {"tldr": "KxNi4S2\u6750\u6599\u5728\u4e0d\u540c\u94be\u542b\u91cf\u4e0b\u53ef\u540c\u65f6\u5c55\u73b0\u72c4\u62c9\u514b\u9525\u548c\u80fd\u5e26\u5e73\u5766\u7684\u7279\u6027\uff0c\u5e76\u53ef\u901a\u8fc7\u94be\u7684\u8131\u5d4c\u5b9e\u73b0\u4e24\u8005\u7684\u5207\u6362\u3002", "motivation": "\u5bfb\u627e\u540c\u65f6\u62e5\u6709\u72c4\u62c9\u514b\u9525\u548c\u80fd\u5e26\u5e73\u5766\u7279\u6027\uff0c\u5e76\u4e14\u80fd\u591f\u76f8\u4e92\u5207\u6362\u7684\u91cf\u5b50\u6750\u6599\u4f53\u7cfb\u3002", "method": "\u901a\u8fc7\u5316\u5b66\u65b9\u6cd5\u5bf9KxNi4S2\u6750\u6599\u8fdb\u884c\u8131\u94be\u5904\u7406\uff0c\u5e76\u7ed3\u5408\u7b2c\u4e00\u6027\u539f\u7406\u8ba1\u7b97\u548c\u9ad8\u8fc1\u79fb\u7387\u5b9e\u9a8c\u8fdb\u884c\u8868\u5f81\u3002", "result": "\u5728\u94be\u542b\u91cfx=1\u65f6\uff0c\u89c2\u5bdf\u5230\u5177\u6709\u62d3\u6251\u975e\u5e73\u51e1Z2\u6307\u6570\u7684\u72c4\u62c9\u514b\u91d1\u5c5e\u6001\uff0c\u8fc1\u79fb\u7387\u9ad8\u8fbe1471 cm2V-1s-1\uff1b\u5f53\u94be\u542b\u91cf\u63a5\u8fd10\u65f6\uff0c\u51fa\u73b0\u7531\u80fd\u5e26\u5e73\u5766\u5f15\u8d77\u7684\u53cd\u94c1\u78c1\u6001\uff0c\u5c45\u91cc\u6e29\u5ea6\u6700\u9ad8\u53ef\u8fbe10.1K\u3002", "conclusion": "KxNi4S2\u6750\u6599\u4e3a\u63a2\u7d22\u65b0\u5174\u91cf\u5b50\u73b0\u8c61\u63d0\u4f9b\u4e86\u4e00\u4e2a\u591a\u529f\u80fd\u7684\u5e73\u53f0\uff0c\u5e76\u5c55\u793a\u4e86\u539f\u4f4d\u8c03\u63a7\u7531\u72c4\u62c9\u514b\u9525\u3001\u80fd\u5e26\u5e73\u5766\u53ca\u5176\u76f8\u4e92\u4f5c\u7528\u4e3b\u5bfc\u7684\u91cf\u5b50\u6750\u6599\u7684\u53ef\u884c\u9014\u5f84\u3002"}}
{"id": "2509.09700", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09700", "abs": "https://arxiv.org/abs/2509.09700", "authors": ["Malavika Suresh", "Rahaf Aljundi", "Ikechukwu Nkisi-Orji", "Nirmalie Wiratunga"], "title": "Cross-Layer Attention Probing for Fine-Grained Hallucination Detection", "comment": "To be published at the TRUST-AI workshop, ECAI 2025", "summary": "With the large-scale adoption of Large Language Models (LLMs) in various\napplications, there is a growing reliability concern due to their tendency to\ngenerate inaccurate text, i.e. hallucinations. In this work, we propose\nCross-Layer Attention Probing (CLAP), a novel activation probing technique for\nhallucination detection, which processes the LLM activations across the entire\nresidual stream as a joint sequence. Our empirical evaluations using five LLMs\nand three tasks show that CLAP improves hallucination detection compared to\nbaselines on both greedy decoded responses as well as responses sampled at\nhigher temperatures, thus enabling fine-grained detection, i.e. the ability to\ndisambiguate hallucinations and non-hallucinations among different sampled\nresponses to a given prompt. This allows us to propose a detect-then-mitigate\nstrategy using CLAP to reduce hallucinations and improve LLM reliability\ncompared to direct mitigation approaches. Finally, we show that CLAP maintains\nhigh reliability even when applied out-of-distribution.", "AI": {"tldr": "CLAP\u662f\u4e00\u79cd\u65b0\u7684\u6fc0\u6d3b\u63a2\u6d4b\u6280\u672f\uff0c\u7528\u4e8e\u68c0\u6d4b\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5e7b\u89c9\uff0c\u901a\u8fc7\u5c06LLM\u6fc0\u6d3b\u4f5c\u4e3a\u8054\u5408\u5e8f\u5217\u8fdb\u884c\u5904\u7406\uff0c\u63d0\u9ad8\u4e86\u5e7b\u89c9\u68c0\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u5e76\u80fd\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u68c0\u6d4b\uff0c\u751a\u81f3\u53ef\u4ee5\u533a\u5206\u4e0d\u540c\u91c7\u6837\u54cd\u5e94\u4e2d\u7684\u5e7b\u89c9\u548c\u975e\u5e7b\u89c9\uff0c\u4ece\u800c\u63d0\u51fa\u4e00\u79cd\u201c\u68c0\u6d4b\u540e\u7f13\u89e3\u201d\u7b56\u7565\u6765\u964d\u4f4e\u5e7b\u89c9\u7684\u53d1\u751f\u7387\uff0c\u5e76\u4e14\u8be5\u65b9\u6cd5\u5728\u5206\u5e03\u5916\u5e94\u7528\u65f6\u4ecd\u80fd\u4fdd\u6301\u9ad8\u53ef\u9760\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5e7f\u6cdb\u5e94\u7528\u5f15\u53d1\u4e86\u5bf9\u5176\u751f\u6210\u4e0d\u51c6\u786e\u6587\u672c\uff08\u5e7b\u89c9\uff09\u7684\u53ef\u9760\u6027\u62c5\u5fe7\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCLAP\uff08Cross-Layer Attention Probing\uff09\u7684\u65b0\u578b\u6fc0\u6d3b\u63a2\u6d4b\u6280\u672f\uff0c\u5b83\u5c06LLM\u7684\u6fc0\u6d3b\u8de8\u6574\u4e2a\u6b8b\u5dee\u6d41\u5904\u7406\u4e3a\u4e00\u4e2a\u8054\u5408\u5e8f\u5217\uff0c\u4ee5\u68c0\u6d4b\u5e7b\u89c9\u3002", "result": "\u5728\u4e94\u4e2aLLM\u548c\u4e09\u4e2a\u4efb\u52a1\u4e0a\u7684\u5b9e\u8bc1\u8bc4\u4f30\u8868\u660e\uff0c\u4e0e\u57fa\u7ebf\u65b9\u6cd5\u76f8\u6bd4\uff0cCLAP\u5728\u8d2a\u5a6a\u89e3\u7801\u54cd\u5e94\u548c\u9ad8\u6e29\u5ea6\u91c7\u6837\u54cd\u5e94\u4e2d\u90fd\u80fd\u63d0\u9ad8\u5e7b\u89c9\u68c0\u6d4b\u6548\u679c\uff0c\u5b9e\u73b0\u4e86\u7ec6\u7c92\u5ea6\u68c0\u6d4b\uff0c\u5e76\u80fd\u63d0\u51fa\u4e00\u79cd\u201c\u68c0\u6d4b\u540e\u7f13\u89e3\u201d\u7b56\u7565\uff0c\u6bd4\u76f4\u63a5\u7f13\u89e3\u65b9\u6cd5\u66f4\u6709\u6548\u5730\u964d\u4f4e\u5e7b\u89c9\u3002\u6b64\u5916\uff0cCLAP\u5728\u5206\u5e03\u5916\u5e94\u7528\u65f6\u4ecd\u4fdd\u6301\u9ad8\u53ef\u9760\u6027\u3002", "conclusion": "CLAP\u662f\u4e00\u79cd\u6709\u6548\u7684\u5e7b\u89c9\u68c0\u6d4b\u6280\u672f\uff0c\u80fd\u591f\u63d0\u9ad8LLM\u7684\u53ef\u9760\u6027\uff0c\u5e76\u80fd\u5728\u5206\u5e03\u5916\u5e94\u7528\u4e2d\u4fdd\u6301\u6027\u80fd\u3002"}}
{"id": "2509.09747", "categories": ["cs.LG", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2509.09747", "abs": "https://arxiv.org/abs/2509.09747", "authors": ["Leen Daher", "Zhaobo Wang", "Malcolm Mielle"], "title": "D-CAT: Decoupled Cross-Attention Transfer between Sensor Modalities for Unimodal Inference", "comment": null, "summary": "Cross-modal transfer learning is used to improve multi-modal classification\nmodels (e.g., for human activity recognition in human-robot collaboration).\nHowever, existing methods require paired sensor data at both training and\ninference, limiting deployment in resource-constrained environments where full\nsensor suites are not economically and technically usable. To address this, we\npropose Decoupled Cross-Attention Transfer (D-CAT), a framework that aligns\nmodality-specific representations without requiring joint sensor modality\nduring inference. Our approach combines a self-attention module for feature\nextraction with a novel cross-attention alignment loss, which enforces the\nalignment of sensors' feature spaces without requiring the coupling of the\nclassification pipelines of both modalities. We evaluate D-CAT on three\nmulti-modal human activity datasets (IMU, video, and audio) under both\nin-distribution and out-of-distribution scenarios, comparing against uni-modal\nmodels. Results show that in in-distribution scenarios, transferring from\nhigh-performing modalities (e.g., video to IMU) yields up to 10% F1-score gains\nover uni-modal training. In out-of-distribution scenarios, even weaker source\nmodalities (e.g., IMU to video) improve target performance, as long as the\ntarget model isn't overfitted on the training data. By enabling single-sensor\ninference with cross-modal knowledge, D-CAT reduces hardware redundancy for\nperception systems while maintaining accuracy, which is critical for\ncost-sensitive or adaptive deployments (e.g., assistive robots in homes with\nvariable sensor availability). Code is available at\nhttps://github.com/Schindler-EPFL-Lab/D-CAT.", "AI": {"tldr": "D-CAT\u6846\u67b6\u5141\u8bb8\u5728\u63a8\u7406\u65f6\u4e0d\u9700\u8981\u8054\u5408\u4f20\u611f\u5668\uff0c\u901a\u8fc7\u89e3\u8026\u8de8\u6ce8\u610f\u529b\u6765\u5bf9\u9f50\u6a21\u6001\u7279\u5b9a\u8868\u793a\uff0c\u4ece\u800c\u63d0\u9ad8\u591a\u6a21\u6001\u5206\u7c7b\u6a21\u578b\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u8d44\u6e90\u53d7\u9650\u7684\u73af\u5883\u4e2d\u3002", "motivation": "\u73b0\u6709\u8de8\u6a21\u6001\u8fc1\u79fb\u5b66\u4e60\u65b9\u6cd5\u5728\u8bad\u7ec3\u548c\u63a8\u7406\u65f6\u90fd\u9700\u8981\u914d\u5bf9\u7684\u4f20\u611f\u5668\u6570\u636e\uff0c\u8fd9\u5728\u8d44\u6e90\u53d7\u9650\u7684\u73af\u5883\u4e2d\u90e8\u7f72\u65f6\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u89e3\u8026\u8de8\u6ce8\u610f\u529b\u8fc1\u79fb\uff08D-CAT\uff09\u7684\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u7ed3\u5408\u4e86\u7528\u4e8e\u7279\u5f81\u63d0\u53d6\u7684\u81ea\u6ce8\u610f\u529b\u6a21\u5757\u548c\u65b0\u9896\u7684\u8de8\u6ce8\u610f\u529b\u5bf9\u9f50\u635f\u5931\uff0c\u5f3a\u5236\u5bf9\u9f50\u4f20\u611f\u5668\u7279\u5f81\u7a7a\u95f4\uff0c\u800c\u65e0\u9700\u8026\u5408\u4e24\u79cd\u6a21\u6001\u7684\u5206\u7c7b\u6d41\u7a0b\u3002", "result": "\u5728\u4e09\u79cd\u591a\u6a21\u6001\u4eba\u7c7b\u6d3b\u52a8\u6570\u636e\u96c6\uff08IMU\u3001\u89c6\u9891\u548c\u97f3\u9891\uff09\u4e0a\u8bc4\u4f30\u4e86D-CAT\uff0c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u540c\u5206\u5e03\u573a\u666f\u4e0b\uff0c\u4ece\u9ad8\u6027\u80fd\u6a21\u6001\uff08\u5982\u89c6\u9891\u5230IMU\uff09\u8fc1\u79fb\u53ef\u5e26\u6765\u9ad8\u8fbe10%\u7684F1\u5206\u6570\u63d0\u5347\uff1b\u5728\u5f02\u5206\u5e03\u573a\u666f\u4e0b\uff0c\u5373\u4f7f\u8f83\u5f31\u7684\u6e90\u6a21\u6001\uff08\u5982IMU\u5230\u89c6\u9891\uff09\u4e5f\u80fd\u63d0\u9ad8\u76ee\u6807\u6027\u80fd\u3002", "conclusion": "D-CAT\u901a\u8fc7\u5728\u63a8\u7406\u65f6\u5b9e\u73b0\u5355\u4f20\u611f\u5668\u63a8\u7406\u548c\u8de8\u6a21\u6001\u77e5\u8bc6\u8fc1\u79fb\uff0c\u51cf\u5c11\u4e86\u611f\u77e5\u7cfb\u7edf\u7684\u786c\u4ef6\u5197\u4f59\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u51c6\u786e\u6027\uff0c\u8fd9\u5bf9\u4e8e\u6210\u672c\u654f\u611f\u6216\u81ea\u9002\u5e94\u90e8\u7f72\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2509.10188", "categories": ["cs.DS", "cs.CC"], "pdf": "https://arxiv.org/pdf/2509.10188", "abs": "https://arxiv.org/abs/2509.10188", "authors": ["\u00c9tienne Grandjean", "Louis Jachiet"], "title": "Constant Time with Minimal Preprocessing, a Robust and Extensive Complexity Class", "comment": "In Honor of Yuri Gurevich on the occasion of his 85th Birthday", "summary": "In this paper, we study the class $\\mathtt{cstPP}$ of operations\n$\\mathtt{op}: \\mathbb{N}^k\\to\\mathbb{N}$, of any fixed arity $k\\ge 1$,\nsatisfying the following property: for each fixed integer $d\\ge 1$, there\nexists an algorithm for a RAM machine which, for any input integer $N\\ge 2$, -\npre-computes some tables in $O(N)$ time, - then reads $k$ operands\n$x_1,\\ldots,x_k<N^d$ and computes $\\mathtt{op}(x_1,\\dots,x_k)$ in constant\ntime.\n  We show that the $\\mathtt{cstPP}$ class is robust and extensive and satisfies\nseveral closure properties. It is invariant depending on whether the set of\nprimitive operations of the RAM is $\\{+\\}$, or\n$\\{+,-,\\times,\\mathtt{div},\\mathtt{mod}\\}$, or any set of operations in\n$\\mathtt{cstPP}$ provided it includes $+$. We prove that the $\\mathtt{cstPP}$\nclass is closed under composition and, for fast-growing functions, is closed\nunder inverse. We also show that in the definition of $\\mathtt{cstPP}$ the\nconstant-time procedure can be reduced to a single return instruction. Finally,\nwe establish that linear preprocessing time is not essential in the definition\nof the $\\mathtt{cstPP}$ class: this class is not modified if the preprocessing\ntime is increased to $O(N^c)$, for any fixed $c>1$, or conversely, is reduced\nto $N^{\\varepsilon}$, for any positive $\\varepsilon<1$ (provided the set of\nprimitive operation includes $+$, $\\mathtt{div}$ and $\\mathtt{mod}$). To\ncomplete the picture, we demonstrate that the $\\mathtt{cstPP}$ class\ndegenerates if the preprocessing time reduces to $N^{o(1)}$.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5b9a\u4e49\u5e76\u5206\u6790\u4e86\u4e00\u4e2a\u540d\u4e3a cstPP \u7684\u64cd\u4f5c\u7c7b\u522b\uff0c\u8be5\u7c7b\u522b\u5177\u6709\u5728\u6709\u9650\u9884\u5904\u7406\u65f6\u95f4\u540e\u53ef\u8fdb\u884c\u5e38\u6570\u65f6\u95f4\u8ba1\u7b97\u7684\u7279\u6027\u3002\u7814\u7a76\u8868\u660e\u8be5\u7c7b\u522b\u5177\u6709\u9c81\u68d2\u6027\u3001\u53ef\u6269\u5c55\u6027\uff0c\u5e76\u6ee1\u8db3\u591a\u79cd\u95ed\u5305\u6027\u8d28\uff0c\u5bf9\u57fa\u5143\u64cd\u4f5c\u96c6\u4e0d\u654f\u611f\uff0c\u4e14\u95ed\u5408\u4e8e\u590d\u5408\u8fd0\u7b97\u548c\u90e8\u5206\u9006\u8fd0\u7b97\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u63a2\u8ba8\u4e86\u9884\u5904\u7406\u65f6\u95f4\u5bf9\u8be5\u7c7b\u522b\u7684\u4f9d\u8d56\u6027\uff0c\u8bc1\u660e\u4e86\u7ebf\u6027\u9884\u5904\u7406\u65f6\u95f4\u5e76\u975e\u5fc5\u9700\uff0c\u4f46\u5176\u663e\u8457\u964d\u4f4e\uff08\u81f3 N^o(1)\uff09\u4f1a\u5bfc\u81f4\u7c7b\u522b\u9000\u5316\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u7814\u7a76\u4e00\u7c7b\u540d\u4e3a cstPP \u7684\u64cd\u4f5c\uff0c\u8fd9\u7c7b\u64cd\u4f5c\u5728\u8fdb\u884c\u4e00\u5b9a\u65f6\u95f4\u7684\u9884\u5904\u7406\u540e\uff0c\u80fd\u591f\u4ee5\u5e38\u6570\u65f6\u95f4\u5b8c\u6210\u8ba1\u7b97\u3002\u7814\u7a76\u7684\u52a8\u673a\u5728\u4e8e\u7406\u89e3\u8fd9\u7c7b\u64cd\u4f5c\u7684\u6027\u8d28\u3001\u9c81\u68d2\u6027\u3001\u53ef\u6269\u5c55\u6027\u53ca\u5176\u4e0e\u5176\u4ed6\u6570\u5b66\u548c\u8ba1\u7b97\u7c7b\u522b\u7684\u5173\u7cfb\u3002", "method": "\u901a\u8fc7\u5206\u6790 cstPP \u7c7b\u64cd\u4f5c\u7684\u5b9a\u4e49\uff0c\u7814\u7a76\u8005\u91c7\u7528\u4e86\u8ba1\u7b97\u590d\u6742\u6027\u7406\u8bba\u548c\u53ef\u8ba1\u7b97\u6027\u7406\u8bba\u7684\u65b9\u6cd5\u3002\u5177\u4f53\u5305\u62ec\uff1a1. \u5f62\u5f0f\u5316 cstPP \u7c7b\u64cd\u4f5c\u7684\u5b9a\u4e49\uff0c\u660e\u786e\u5176\u8f93\u5165\u3001\u8f93\u51fa\u3001\u9884\u5904\u7406\u65f6\u95f4\u548c\u5e38\u6570\u65f6\u95f4\u8ba1\u7b97\u7684\u8981\u6c42\u30022. \u8bc1\u660e cstPP \u7c7b\u7684\u9c81\u68d2\u6027\uff0c\u5373\u5176\u6027\u8d28\u4e0d\u56e0 RAM \u673a\u5668\u57fa\u5143\u64cd\u4f5c\u96c6\u7684\u6539\u53d8\u800c\u6539\u53d8\u30023. \u9a8c\u8bc1 cstPP \u7c7b\u7684\u95ed\u5305\u6027\u8d28\uff0c\u5305\u62ec\u5bf9\u590d\u5408\u8fd0\u7b97\u548c\u9006\u8fd0\u7b97\u7684\u95ed\u5408\u6027\u30024. \u5206\u6790\u9884\u5904\u7406\u65f6\u95f4\u5bf9 cstPP \u7c7b\u5b9a\u4e49\u7684\u5f71\u54cd\uff0c\u6bd4\u8f83\u4e0d\u540c\u9884\u5904\u7406\u65f6\u95f4\u590d\u6742\u5ea6\u4e0b\u7684\u7c7b\u522b\u53d8\u5316\u3002", "result": "\u7814\u7a76\u8bc1\u660e\u4e86 cstPP \u7c7b\u64cd\u4f5c\u5177\u6709\u9c81\u68d2\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u5e76\u6ee1\u8db3\u591a\u79cd\u95ed\u5305\u6027\u8d28\u3002\u5b83\u5bf9 RAM \u673a\u5668\u7684\u57fa\u5143\u64cd\u4f5c\u96c6\u4e0d\u654f\u611f\uff0c\u5e76\u4e14\u5728\u64cd\u4f5c\u590d\u5408\u548c\u67d0\u4e9b\u9006\u8fd0\u7b97\u4e0b\u4fdd\u6301\u4e0d\u53d8\u3002\u7814\u7a76\u8fd8\u8868\u660e\uff0c\u5e38\u6570\u65f6\u95f4\u8ba1\u7b97\u4e0d\u4e00\u5b9a\u9700\u8981\u4e25\u683c\u7684\u7ebf\u6027\u9884\u5904\u7406\u65f6\u95f4\uff0c\u53ea\u8981\u9884\u5904\u7406\u65f6\u95f4\u590d\u6742\u5ea6\u5728\u4e00\u5b9a\u8303\u56f4\u5185\uff08O(N^c) \u6216 N^\u03b5\uff09\uff0c\u8be5\u7c7b\u522b\u4fdd\u6301\u4e0d\u53d8\u3002\u7136\u800c\uff0c\u5f53\u9884\u5904\u7406\u65f6\u95f4\u590d\u6742\u5ea6\u4f4e\u4e8e N^o(1) \u65f6\uff0c\u8be5\u7c7b\u522b\u4f1a\u9000\u5316\u3002", "conclusion": "cstPP \u7c7b\u64cd\u4f5c\u662f\u4e00\u4e2a\u7a33\u5b9a\u4e14\u6027\u8d28\u826f\u597d\u7684\u8ba1\u7b97\u6a21\u578b\u3002\u5176\u5173\u952e\u7279\u6027\u5728\u4e8e\u201c\u9884\u5904\u7406\u540e\u5e38\u6570\u65f6\u95f4\u8ba1\u7b97\u201d\uff0c\u8fd9\u4e00\u7279\u6027\u5728\u4e00\u5b9a\u8303\u56f4\u5185\u5bf9\u9884\u5904\u7406\u65f6\u95f4\u7684\u5177\u4f53\u590d\u6742\u5ea6\u4e0d\u654f\u611f\uff0c\u5e76\u4e14\u4e0d\u4f9d\u8d56\u4e8e\u7279\u5b9a\u7684\u57fa\u5143\u64cd\u4f5c\u96c6\u3002\u8fd9\u8868\u660e cstPP \u7c7b\u5728\u8ba1\u7b97\u7406\u8bba\u4e2d\u5177\u6709\u91cd\u8981\u7684\u610f\u4e49\uff0c\u5b83\u63d0\u4f9b\u4e86\u4e00\u79cd\u7075\u6d3b\u4e14\u9ad8\u6548\u7684\u8ba1\u7b97\u6846\u67b6\u3002"}}
{"id": "2509.10077", "categories": ["cs.NE", "cs.AI", "cs.DS", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10077", "abs": "https://arxiv.org/abs/2509.10077", "authors": ["Simen Storesund", "Kristian Valset Aars", "Robin Dietrich", "Nicolai Waniek"], "title": "Predictive Spike Timing Enables Distributed Shortest Path Computation in Spiking Neural Networks", "comment": null, "summary": "Efficient planning and sequence selection are central to intelligence, yet\ncurrent approaches remain largely incompatible with biological computation.\nClassical graph algorithms like Dijkstra's or A* require global state and\nbiologically implausible operations such as backtracing, while reinforcement\nlearning methods rely on slow gradient-based policy updates that appear\ninconsistent with rapid behavioral adaptation observed in natural systems.\n  We propose a biologically plausible algorithm for shortest-path computation\nthat operates through local spike-based message-passing with realistic\nprocessing delays. The algorithm exploits spike-timing coincidences to identify\nnodes on optimal paths: Neurons that receive inhibitory-excitatory message\npairs earlier than predicted reduce their response delays, creating a temporal\ncompression that propagates backwards from target to source. Through analytical\nproof and simulations on random spatial networks, we demonstrate that the\nalgorithm converges and discovers all shortest paths using purely timing-based\nmechanisms. By showing how short-term timing dynamics alone can compute\nshortest paths, this work provides new insights into how biological networks\nmight solve complex computational problems through purely local computation and\nrelative spike-time prediction. These findings open new directions for\nunderstanding distributed computation in biological and artificial systems,\nwith possible implications for computational neuroscience, AI, reinforcement\nlearning, and neuromorphic systems.", "AI": {"tldr": "\u8be5\u7b97\u6cd5\u63d0\u51fa\u4e86\u4e00\u79cd\u751f\u7269\u53ef\u5b66\u7684\u3001\u57fa\u4e8e\u8109\u51b2\u7684\u5c40\u90e8\u6d88\u606f\u4f20\u9012\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u5b58\u5728\u5b9e\u9645\u5904\u7406\u5ef6\u8fdf\u7684\u60c5\u51b5\u4e0b\u8ba1\u7b97\u6700\u77ed\u8def\u5f84\u3002", "motivation": "\u73b0\u6709\u7684\u56fe\u7b97\u6cd5\u548c\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u751f\u7269\u5b66\u4e0a\u4e0d\u53ef\u884c\uff0c\u65e0\u6cd5\u89e3\u91ca\u5feb\u901f\u7684\u884c\u4e3a\u9002\u5e94\u3002", "method": "\u901a\u8fc7\u5229\u7528\u8109\u51b2\u65f6\u95f4\u5de7\u5408\uff0c\u7b97\u6cd5\u8bc6\u522b\u6700\u4f18\u8def\u5f84\u4e0a\u7684\u8282\u70b9\u3002\u795e\u7ecf\u5143\u63a5\u6536\u5230\u7684\u6291\u5236-\u5174\u594b\u6d88\u606f\u5bf9\u7684\u65f6\u95f4\u65e9\u4e8e\u9884\u671f\uff0c\u4f1a\u51cf\u5c11\u5176\u54cd\u5e94\u5ef6\u8fdf\uff0c\u4ece\u800c\u4ece\u76ee\u6807\u5230\u6e90\u4ea7\u751f\u65f6\u95f4\u538b\u7f29\u3002", "result": "\u901a\u8fc7\u7406\u8bba\u8bc1\u660e\u548c\u5728\u968f\u673a\u7a7a\u95f4\u7f51\u7edc\u4e0a\u7684\u6a21\u62df\uff0c\u8bc1\u660e\u4e86\u8be5\u7b97\u6cd5\u80fd\u591f\u6536\u655b\u5e76\u4ec5\u4f7f\u7528\u57fa\u4e8e\u65f6\u95f4\u7684\u673a\u5236\u53d1\u73b0\u6240\u6709\u6700\u77ed\u8def\u5f84\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u8868\u660e\uff0c\u4ec5\u901a\u8fc7\u77ed\u671f\u65f6\u5e8f\u52a8\u529b\u5b66\u5c31\u53ef\u4ee5\u8ba1\u7b97\u51fa\u6700\u77ed\u8def\u5f84\uff0c\u8fd9\u4e3a\u7406\u89e3\u751f\u7269\u7f51\u7edc\u5982\u4f55\u4ec5\u901a\u8fc7\u5c40\u90e8\u8ba1\u7b97\u548c\u76f8\u5bf9\u8109\u51b2\u65f6\u95f4\u9884\u6d4b\u6765\u89e3\u51b3\u590d\u6742\u8ba1\u7b97\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\u3002"}}
{"id": "2509.09775", "categories": ["cs.AI", "cs.CL", "cs.FL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.09775", "abs": "https://arxiv.org/abs/2509.09775", "authors": ["Aleksandr Boldachev"], "title": "Executable Ontologies: Synthesizing Event Semantics with Dataflow Architecture", "comment": "22 pages, 6 figures", "summary": "This paper presents boldsea, Boldachev's semantic-event approach -- an\narchitecture for modeling complex dynamic systems using executable ontologies\n-- semantic models that act as dynamic structures, directly controlling process\nexecution. We demonstrate that integrating event semantics with a dataflow\narchitecture addresses the limitations of traditional Business Process\nManagement (BPM) systems and object-oriented semantic technologies. The paper\npresents the formal BSL (boldsea Semantic Language), including its BNF grammar,\nand outlines the boldsea-engine's architecture, which directly interprets\nsemantic models as executable algorithms without compilation. It enables the\nmodification of event models at runtime, ensures temporal transparency, and\nseamlessly merges data and business logic within a unified semantic framework.", "AI": {"tldr": "Boldsea\u662f\u4e00\u4e2a\u4f7f\u7528\u53ef\u6267\u884c\u672c\u4f53\u5efa\u6a21\u590d\u6742\u52a8\u6001\u7cfb\u7edf\u7684\u67b6\u6784\uff0c\u5b83\u901a\u8fc7\u5c06\u4e8b\u4ef6\u8bed\u4e49\u4e0e\u6570\u636e\u6d41\u67b6\u6784\u76f8\u7ed3\u5408\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfBPM\u7cfb\u7edf\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u4f20\u7edf\u7684BPM\u7cfb\u7edf\u548c\u9762\u5411\u5bf9\u8c61\u7684\u8bed\u4e49\u6280\u672f\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u5efa\u6a21\u590d\u6742\u52a8\u6001\u7cfb\u7edf\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aboldsea\u7684\u67b6\u6784\uff0c\u8be5\u67b6\u6784\u4f7f\u7528\u53ef\u6267\u884c\u672c\u4f53\uff08\u8bed\u4e49\u6a21\u578b\uff09\uff0c\u76f4\u63a5\u63a7\u5236\u8fdb\u7a0b\u6267\u884c\u3002\u5b83\u8fd8\u63d0\u51fa\u4e86\u5f62\u5f0f\u5316\u7684BSL\u8bed\u8a00\uff08\u5305\u62ecBNF\u8bed\u6cd5\uff09\u548cboldsea-engine\u7684\u67b6\u6784\uff0c\u8be5\u67b6\u6784\u76f4\u63a5\u5c06\u8bed\u4e49\u6a21\u578b\u89e3\u91ca\u4e3a\u53ef\u6267\u884c\u7b97\u6cd5\uff0c\u65e0\u9700\u7f16\u8bd1\u3002", "result": "Boldsea\u80fd\u591f\u5b9e\u73b0\u4e8b\u4ef6\u6a21\u578b\u5728\u8fd0\u884c\u65f6\u4fee\u6539\u3001\u4fdd\u8bc1\u65f6\u95f4\u900f\u660e\u6027\uff0c\u5e76\u5728\u7edf\u4e00\u7684\u8bed\u4e49\u6846\u67b6\u5185\u65e0\u7f1d\u5408\u5e76\u6570\u636e\u548c\u4e1a\u52a1\u903b\u8f91\u3002", "conclusion": "Boldsea\u901a\u8fc7\u5c06\u4e8b\u4ef6\u8bed\u4e49\u4e0e\u6570\u636e\u6d41\u67b6\u6784\u76f8\u7ed3\u5408\uff0c\u514b\u670d\u4e86\u4f20\u7edfBPM\u7cfb\u7edf\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u3001\u66f4\u6709\u6548\u7684\u590d\u6742\u52a8\u6001\u7cfb\u7edf\u5efa\u6a21\u65b9\u6cd5\u3002"}}
{"id": "2509.10051", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2509.10051", "abs": "https://arxiv.org/abs/2509.10051", "authors": ["Tianwei Pan", "Tianao Dai", "Jianlei Yang", "Hongbin Jing", "Yang Su", "Zeyu Hao", "Xiaotao Jia", "Chunming Hu", "Weisheng Zhao"], "title": "Finesse: An Agile Design Framework for Pairing-based Cryptography via Software/Hardware Co-Design", "comment": "Published on 52nd Annual International Symposium on Computer\n  Architecture (ISCA'25)", "summary": "Pairing-based cryptography (PBC) is crucial in modern cryptographic\napplications. With the rapid advancement of adversarial research and the\ngrowing diversity of application requirements, PBC accelerators need regular\nupdates in algorithms, parameter configurations, and hardware design. However,\ntraditional design methodologies face significant challenges, including\nprolonged design cycles, difficulties in balancing performance and flexibility,\nand insufficient support for potential architectural exploration.\n  To address these challenges, we introduce Finesse, an agile design framework\nbased on co-design methodology. Finesse leverages a co-optimization cycle\ndriven by a specialized compiler and a multi-granularity hardware simulator,\nenabling both optimized performance metrics and effective design space\nexploration. Furthermore, Finesse adopts a modular design flow to significantly\nshorten design cycles, while its versatile abstraction ensures flexibility\nacross various curve families and hardware architectures.\n  Finesse offers flexibility, efficiency, and rapid prototyping, comparing with\nprevious frameworks. With compilation times reduced to minutes, Finesse enables\nfaster iteration cycles and streamlined hardware-software co-design.\nExperiments on popular curves demonstrate its effectiveness, achieving\n$34\\times$ improvement in throughput and $6.2\\times$ increase in area\nefficiency compared to previous flexible frameworks, while outperforming\nstate-of-the-art non-flexible ASIC designs with a $3\\times$ gain in throughput\nand $3.2\\times$ improvement in area efficiency.", "AI": {"tldr": "Finesse\u662f\u4e00\u4e2a\u57fa\u4e8e\u8f6f\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u7684\u65b9\u6cd5\u8bba\u7684\u654f\u6377\u8bbe\u8ba1\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u73b0\u6709\u914d\u5bf9\u5bc6\u7801\u5b66\u52a0\u901f\u5668\u8bbe\u8ba1\u5468\u671f\u957f\u3001\u6027\u80fd\u4e0e\u7075\u6d3b\u6027\u96be\u4ee5\u5e73\u8861\u4ee5\u53ca\u67b6\u6784\u63a2\u7d22\u652f\u6301\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u7684\u914d\u5bf9\u5bc6\u7801\u5b66\uff08PBC\uff09\u52a0\u901f\u5668\u8bbe\u8ba1\u65b9\u6cd5\u9762\u4e34\u8bbe\u8ba1\u5468\u671f\u957f\u3001\u6027\u80fd\u4e0e\u7075\u6d3b\u6027\u5e73\u8861\u56f0\u96be\u4ee5\u53ca\u67b6\u6784\u63a2\u7d22\u652f\u6301\u4e0d\u8db3\u7b49\u6311\u6218\u3002", "method": "Finesse\u91c7\u7528\u8f6f\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e00\u4e2a\u4e13\u95e8\u7684\u7f16\u8bd1\u5668\u548c\u4e00\u4e2a\u591a\u7c92\u5ea6\u786c\u4ef6\u6a21\u62df\u5668\u9a71\u52a8\u534f\u540c\u4f18\u5316\uff0c\u5b9e\u73b0\u4e86\u6027\u80fd\u4f18\u5316\u548c\u8bbe\u8ba1\u7a7a\u95f4\u63a2\u7d22\u3002\u5b83\u8fd8\u91c7\u7528\u4e86\u6a21\u5757\u5316\u8bbe\u8ba1\u6d41\u7a0b\u548c\u901a\u7528\u7684\u62bd\u8c61\uff0c\u4ee5\u7f29\u77ed\u8bbe\u8ba1\u5468\u671f\u5e76\u652f\u6301\u4e0d\u540c\u66f2\u7ebf\u548c\u786c\u4ef6\u67b6\u6784\u7684\u7075\u6d3b\u6027\u3002", "result": "Finesse\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u76f8\u6bd4\u4e4b\u524d\u7684\u7075\u6d3b\u6846\u67b6\uff0c\u5176\u541e\u5410\u91cf\u63d0\u9ad8\u4e8634\u500d\uff0c\u9762\u79ef\u6548\u7387\u63d0\u9ad8\u4e866.2\u500d\u3002\u4e0e\u6700\u5148\u8fdb\u7684\u975e\u7075\u6d3bASIC\u8bbe\u8ba1\u76f8\u6bd4\uff0cFinesse\u7684\u541e\u5410\u91cf\u63d0\u9ad8\u4e863\u500d\uff0c\u9762\u79ef\u6548\u7387\u63d0\u9ad8\u4e863.2\u500d\u3002\u7f16\u8bd1\u65f6\u95f4\u7f29\u77ed\u81f3\u51e0\u5206\u949f\uff0c\u4ece\u800c\u5b9e\u73b0\u4e86\u66f4\u5feb\u7684\u8fed\u4ee3\u5468\u671f\u548c\u7b80\u5316\u7684\u8f6f\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u3002", "conclusion": "Finesse\u6846\u67b6\u901a\u8fc7\u5176\u7075\u6d3b\u6027\u3001\u6548\u7387\u548c\u5feb\u901f\u539f\u578b\u8bbe\u8ba1\u80fd\u529b\uff0c\u663e\u8457\u4f18\u4e8e\u4e4b\u524d\u7684\u6846\u67b6\uff0c\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u73b0\u4ee3\u914d\u5bf9\u5bc6\u7801\u5b66\u52a0\u901f\u5668\u8bbe\u8ba1\u7684\u6311\u6218\u3002"}}
{"id": "2509.09784", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.09784", "abs": "https://arxiv.org/abs/2509.09784", "authors": ["Amir Bahador Javadi", "Amin Kargarian", "Mort Naraghi-Pour"], "title": "Automatic Regression for Governing Equations with Control (ARGOSc)", "comment": null, "summary": "Learning the governing equations of dynamical systems from data has drawn\nsignificant attention across diverse fields, including physics, engineering,\nrobotics and control, economics, climate science, and healthcare. Sparse\nregression techniques, exemplified by the Automatic Regression for Governing\nEquations (ARGOS) framework, have demonstrated effectiveness in extracting\nparsimonious models from time series data. However, real-world dynamical\nsystems are driven by input control, external forces, or human interventions,\nwhich standard ARGOS does not accommodate. To address this, we introduce ARGOS\nwith control (ARGOSc), an extension of ARGOS that incorporates external control\ninputs into the system identification process. ARGOSc extends the sparse\nregression framework to infer governing equations while accounting for the\neffects of exogenous inputs, enabling robust identification of forcing dynamics\nin low- to medium-noise datasets. We demonstrate ARGOSc efficacy on benchmark\nsystems, including the Van der Pol oscillator, Lotka-Volterra, and the Lorenz\nsystem with forcing and feedback control, showing enhanced accuracy in\ndiscovering governing laws. Under the noisy conditions, ARGOSc outperforms the\nwidely used sparse identification of nonlinear dynamics with control (SINDYc),\nin accurately identifying the underlying forced dynamics. In some cases, SINDYc\nfails to capture the true system dynamics, whereas ARGOSc consistently\nsucceeds.", "AI": {"tldr": "ARGOSc\u662f\u4e00\u4e2a\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u4ece\u5305\u542b\u63a7\u5236\u8f93\u5165\u7684\u65f6\u5e8f\u6570\u636e\u4e2d\u8bc6\u522b\u52a8\u529b\u7cfb\u7edf\u7684\u63a7\u5236\u65b9\u7a0b\u3002\u5b83\u5728\u4f4e\u566a\u58f0\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u4e14\u5728\u6709\u566a\u58f0\u7684\u60c5\u51b5\u4e0b\u4f18\u4e8eSINDYc\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u52a8\u529b\u7cfb\u7edf\u901a\u5e38\u53d7\u5230\u5916\u90e8\u63a7\u5236\u3001\u529b\u6216\u5e72\u9884\u7684\u5f71\u54cd\uff0c\u800c\u6807\u51c6\u7684ARGOS\u65e0\u6cd5\u5904\u7406\u8fd9\u79cd\u60c5\u51b5\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u5f00\u53d1\u80fd\u591f\u5c06\u5916\u90e8\u63a7\u5236\u8f93\u5165\u7eb3\u5165\u7cfb\u7edf\u8bc6\u522b\u8fc7\u7a0b\u7684\u6269\u5c55\u65b9\u6cd5\u3002", "method": "ARGOSc\u6269\u5c55\u4e86\u7a00\u758f\u56de\u5f52\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u63a8\u65ad\u63a7\u5236\u65b9\u7a0b\u7684\u540c\u65f6\u8003\u8651\u5916\u6e90\u8f93\u5165\u7684\u5f71\u54cd\u6765\u8bc6\u522b\u63a7\u5236\u65b9\u7a0b\u3002", "result": "\u901a\u8fc7\u5728\u8303\u5fb7\u5821\u5c14\u632f\u8361\u5668\u3001\u6d1b\u7279\u5361-\u6c83\u5c14\u6cf0\u62c9\u548c\u53d7\u8feb\u53cd\u9988\u63a7\u5236\u7684\u6d1b\u4f26\u5179\u7cfb\u7edf\u7b49\u57fa\u51c6\u7cfb\u7edf\u4e0a\u8fdb\u884c\u6f14\u793a\uff0cARGOSc\u8bc1\u660e\u4e86\u5176\u5728\u8bc6\u522b\u63a7\u5236\u65b9\u7a0b\u65b9\u9762\u7684\u6709\u6548\u6027\u3002\u5728\u6709\u566a\u58f0\u7684\u60c5\u51b5\u4e0b\uff0cARGOSc\u5728\u51c6\u786e\u8bc6\u522b\u6f5c\u5728\u7684\u53d7\u8feb\u52a8\u529b\u5b66\u65b9\u9762\u4f18\u4e8eSINDYc\u3002", "conclusion": "ARGOSc\u5728\u8bc6\u522b\u53d7\u8feb\u52a8\u529b\u5b66\u65b9\u9762\u4f18\u4e8eSINDYc\uff0c\u5373\u4f7f\u5728\u6709\u566a\u58f0\u7684\u60c5\u51b5\u4e0b\uff0c\u4e5f\u80fd\u6210\u529f\u8bc6\u522b\u771f\u6b63\u7684\u7cfb\u7edf\u52a8\u529b\u5b66\u3002"}}
{"id": "2509.09868", "categories": ["cs.DC", "cs.CR", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.09868", "abs": "https://arxiv.org/abs/2509.09868", "authors": ["Yunhao Zhang", "Haobin Ni", "Soumya Basu", "Shir Cohen", "Maofan Yin", "Lorenzo Alvisi", "Robbert van Renesse", "Qi Chen", "Lidong Zhou"], "title": "Ordered Consensus with Equal Opportunity", "comment": null, "summary": "The specification of state machine replication (SMR) has no requirement on\nthe final total order of commands. In blockchains based on SMR, however, order\nmatters, since different orders could provide their clients with different\nfinancial rewards. Ordered consensus augments the specification of SMR to\ninclude specific guarantees on such order, with a focus on limiting the\ninfluence of Byzantine nodes. Real-world ordering manipulations, however, can\nand do happen even without Byzantine replicas, typically because of factors,\nsuch as faster networks or closer proximity to the blockchain infrastructure,\nthat give some clients an unfair advantage. To address this challenge, this\npaper proceeds to extend ordered consensus by requiring it to also support\nequal opportunity, a concrete notion of fairness, widely adopted in social\nsciences. Informally, equal opportunity requires that two candidates who,\naccording to a set of criteria deemed to be relevant, are equally qualified for\na position (in our case, a specific slot in the SMR total order), should have\nan equal chance of landing it. We show how randomness can be leveraged to keep\nbias in check, and, to this end, introduce the secret random oracle (SRO), a\nsystem component that generates randomness in a fault-tolerant manner. We\ndescribe two SRO designs based, respectively, on trusted hardware and threshold\nverifiable random functions, and instantiate them in Bercow, a new ordered\nconsensus protocol that, by approximating equal opportunity up to within a\nconfigurable factor, can effectively mitigate well-known ordering attacks in\nSMR-based blockchains.", "AI": {"tldr": "\u72b6\u6001\u673a\u590d\u5236\uff08SMR\uff09\u7684\u987a\u5e8f\u65e0\u5173\u7d27\u7d27\u8981\uff0c\u4f46\u5728\u533a\u5757\u94fe\u4e2d\u5374\u81f3\u5173\u91cd\u8981\u3002\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u201c\u5e73\u7b49\u673a\u4f1a\u201d\u539f\u5219\uff0c\u8981\u6c42\u5171\u8bc6\u534f\u8bae\u5728\u8003\u8651\u76f8\u5173\u56e0\u7d20\u540e\uff0c\u7ed9\u4e88\u5019\u9009\u8005\u5747\u7b49\u7684\u673a\u4f1a\u6765\u83b7\u5f97\u67d0\u4e2a\u5171\u8bc6\u987a\u5e8f\u4e2d\u7684\u7279\u5b9a\u4f4d\u7f6e\u3002\u7814\u7a76\u5229\u7528\u968f\u673a\u6027\u6765\u9650\u5236\u504f\u89c1\uff0c\u5e76\u5f15\u5165\u4e86\u79d8\u5bc6\u968f\u673a\u9884\u8a00\uff08SRO\uff09\u6765\u4ee5\u5bb9\u9519\u7684\u65b9\u5f0f\u751f\u6210\u968f\u673a\u6027\u3002\u6700\u7ec8\uff0c\u8bba\u6587\u57fa\u4e8eSRO\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u540d\u4e3aBercow\u7684\u65b0\u5171\u8bc6\u534f\u8bae\uff0c\u8be5\u534f\u8bae\u80fd\u6709\u6548\u7f13\u89e3SMR\u533a\u5757\u94fe\u4e2d\u7684\u6392\u5e8f\u653b\u51fb\u3002", "motivation": "\u73b0\u6709\u7684\u6709\u5e8f\u5171\u8bc6\u534f\u8bae\u867d\u7136\u5173\u6ce8\u9650\u5236\u62dc\u5360\u5ead\u8282\u70b9\u5bf9\u547d\u4ee4\u987a\u5e8f\u7684\u5f71\u54cd\uff0c\u4f46\u672a\u80fd\u89e3\u51b3\u975e\u62dc\u5360\u5ead\u56e0\u7d20\uff08\u5982\u7f51\u7edc\u901f\u5ea6\u6216\u5730\u7406\u4f4d\u7f6e\uff09\u5bfc\u81f4\u7684\u987a\u5e8f\u64cd\u7eb5\u95ee\u9898\uff0c\u8fd9\u4e9b\u56e0\u7d20\u4f1a\u7ed9\u4e88\u67d0\u4e9b\u5ba2\u6237\u7aef\u4e0d\u516c\u5e73\u7684\u4f18\u52bf\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u5171\u8bc6\u673a\u5236\u6765\u786e\u4fdd\u516c\u5e73\u6027\u3002", "method": "\u8be5\u8bba\u6587\u63d0\u51fa\u5c06\u201c\u5e73\u7b49\u673a\u4f1a\u201d\u539f\u5219\uff08\u6e90\u4e8e\u793e\u4f1a\u79d1\u5b66\uff09\u5f15\u5165\u6709\u5e8f\u5171\u8bc6\u3002\u8be5\u539f\u5219\u8981\u6c42\uff0c\u5728\u8003\u8651\u4e86\u76f8\u5173\u56e0\u7d20\u540e\uff0c\u4e24\u4e2a\u540c\u6837\u6709\u8d44\u683c\u83b7\u5f97\u7279\u5b9a\u5171\u8bc6\u987a\u5e8f\u4f4d\u7f6e\u7684\u5019\u9009\u8005\uff0c\u5e94\u8be5\u6709\u5747\u7b49\u7684\u673a\u4f1a\u83b7\u5f97\u8be5\u4f4d\u7f6e\u3002\u4e3a\u4e86\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\uff0c\u7814\u7a76\u5229\u7528\u968f\u673a\u6027\u6765\u63a7\u5236\u504f\u5dee\uff0c\u5e76\u5f15\u5165\u4e86\u79d8\u5bc6\u968f\u673a\u9884\u8a00\uff08SRO\uff09\u6765\u5bb9\u9519\u5730\u751f\u6210\u968f\u673a\u6570\u3002\u8bba\u6587\u8fd8\u63d0\u51fa\u4e86\u4e24\u79cdSRO\u7684\u8bbe\u8ba1\uff1a\u4e00\u79cd\u57fa\u4e8e\u53ef\u4fe1\u786c\u4ef6\uff0c\u53e6\u4e00\u79cd\u57fa\u4e8e\u95e8\u69db\u53ef\u9a8c\u8bc1\u968f\u673a\u51fd\u6570\u3002", "result": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e24\u79cdSRO\u7684\u8bbe\u8ba1\uff0c\u5e76\u57fa\u4e8eSRO\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u540d\u4e3aBercow\u7684\u65b0\u578b\u6709\u5e8f\u5171\u8bc6\u534f\u8bae\u3002Bercow\u534f\u8bae\u80fd\u591f\u4ee5\u53ef\u914d\u7f6e\u7684\u56e0\u5b50\u6765\u8fd1\u4f3c\u5b9e\u73b0\u5e73\u7b49\u673a\u4f1a\uff0c\u4ece\u800c\u6709\u6548\u51cf\u8f7bSMR\u533a\u5757\u94fe\u4e2d\u5df2\u77e5\u7684\u6392\u5e8f\u653b\u51fb\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u5e73\u7b49\u673a\u4f1a\u539f\u5219\u548c\u79d8\u5bc6\u968f\u673a\u9884\u8a00\uff08SRO\uff09\uff0c\u5e76\u8bbe\u8ba1\u51faBercow\u5171\u8bc6\u534f\u8bae\uff0c\u53ef\u4ee5\u6709\u6548\u89e3\u51b3\u73b0\u6709\u533a\u5757\u94fe\u6392\u5e8f\u673a\u5236\u4e2d\u7684\u4e0d\u516c\u5e73\u6027\u95ee\u9898\uff0c\u5e76\u7f13\u89e3\u76f8\u5173\u7684\u6392\u5e8f\u653b\u51fb\u3002"}}
{"id": "2509.09721", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.09721", "abs": "https://arxiv.org/abs/2509.09721", "authors": ["Jiayi Miao", "Dingxin Lu", "Zhuqi Wang"], "title": "A Multimodal RAG Framework for Housing Damage Assessment: Collaborative Optimization of Image Encoding and Policy Vector Retrieval", "comment": null, "summary": "After natural disasters, accurate evaluations of damage to housing are\nimportant for insurance claims response and planning of resources. In this\nwork, we introduce a novel multimodal retrieval-augmented generation (MM-RAG)\nframework. On top of classical RAG architecture, we further the framework to\ndevise a two-branch multimodal encoder structure that the image branch employs\na visual encoder composed of ResNet and Transformer to extract the\ncharacteristic of building damage after disaster, and the text branch harnesses\na BERT retriever for the text vectorization of posts as well as insurance\npolicies and for the construction of a retrievable restoration index. To impose\ncross-modal semantic alignment, the model integrates a cross-modal interaction\nmodule to bridge the semantic representation between image and text via\nmulti-head attention. Meanwhile, in the generation module, the introduced modal\nattention gating mechanism dynamically controls the role of visual evidence and\ntext prior information during generation. The entire framework takes end-to-end\ntraining, and combines the comparison loss, the retrieval loss and the\ngeneration loss to form multi-task optimization objectives, and achieves image\nunderstanding and policy matching in collaborative learning. The results\ndemonstrate superior performance in retrieval accuracy and classification index\non damage severity, where the Top-1 retrieval accuracy has been improved by\n9.6%.", "AI": {"tldr": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u6a21\u6001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08MM-RAG\uff09\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u81ea\u7136\u707e\u5bb3\u540e\u8bc4\u4f30\u4f4f\u623f\u635f\u5931\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u56fe\u50cf\u548c\u6587\u672c\u4fe1\u606f\uff0c\u5728\u68c0\u7d22\u51c6\u786e\u6027\u548c\u635f\u5931\u5206\u7c7b\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6539\u8fdb\u3002", "motivation": "\u5728\u81ea\u7136\u707e\u5bb3\u53d1\u751f\u540e\uff0c\u51c6\u786e\u8bc4\u4f30\u623f\u5c4b\u635f\u5931\u5bf9\u4e8e\u5904\u7406\u4fdd\u9669\u7d22\u8d54\u548c\u89c4\u5212\u8d44\u6e90\u81f3\u5173\u91cd\u8981\u3002", "method": "\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u591a\u6a21\u6001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08MM-RAG\uff09\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5728\u7ecf\u5178\u7684RAG\u67b6\u6784\u57fa\u7840\u4e0a\uff0c\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u4e24\u5206\u652f\u7684\u591a\u6a21\u6001\u7f16\u7801\u5668\u7ed3\u6784\u3002\u56fe\u50cf\u5206\u652f\u4f7f\u7528ResNet\u548cTransformer\u63d0\u53d6\u707e\u540e\u5efa\u7b51\u635f\u574f\u7279\u5f81\uff0c\u6587\u672c\u5206\u652f\u4f7f\u7528BERT\u8fdb\u884c\u6587\u672c\u5411\u91cf\u5316\uff08\u5305\u62ec\u5e16\u5b50\u548c\u4fdd\u9669\u653f\u7b56\uff09\uff0c\u5e76\u6784\u5efa\u53ef\u68c0\u7d22\u7684\u6062\u590d\u7d22\u5f15\u3002\u6a21\u578b\u901a\u8fc7\u8de8\u6a21\u6001\u4ea4\u4e92\u6a21\u5757\u8fdb\u884c\u8bed\u4e49\u5bf9\u9f50\uff0c\u5e76\u4f7f\u7528\u6a21\u6001\u6ce8\u610f\u529b\u95e8\u63a7\u673a\u5236\u52a8\u6001\u8c03\u6574\u89c6\u89c9\u8bc1\u636e\u548c\u6587\u672c\u5148\u9a8c\u4fe1\u606f\u5728\u751f\u6210\u4e2d\u7684\u4f5c\u7528\u3002\u6574\u4e2a\u6846\u67b6\u91c7\u7528\u7aef\u5230\u7aef\u8bad\u7ec3\uff0c\u7ed3\u5408\u4e86\u6bd4\u8f83\u635f\u5931\u3001\u68c0\u7d22\u635f\u5931\u548c\u751f\u6210\u635f\u5931\u8fdb\u884c\u591a\u4efb\u52a1\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u68c0\u7d22\u51c6\u786e\u6027\u548c\u635f\u5bb3\u4e25\u91cd\u6027\u5206\u7c7b\u6307\u6570\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5176\u4e2dTop-1\u68c0\u7d22\u51c6\u786e\u7387\u63d0\u9ad8\u4e869.6%\u3002", "conclusion": "\u6211\u4eec\u63d0\u51fa\u7684MM-RAG\u6846\u67b6\u80fd\u591f\u6709\u6548\u5730\u7ed3\u5408\u56fe\u50cf\u548c\u6587\u672c\u4fe1\u606f\uff0c\u63d0\u9ad8\u4e86\u81ea\u7136\u707e\u5bb3\u540e\u4f4f\u623f\u635f\u5931\u8bc4\u4f30\u7684\u51c6\u786e\u6027\uff0c\u7279\u522b\u662f\u5728\u68c0\u7d22\u548c\u5206\u7c7b\u4efb\u52a1\u4e0a\u3002"}}
{"id": "2509.09875", "categories": ["cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2509.09875", "abs": "https://arxiv.org/abs/2509.09875", "authors": ["Yutaro Tanaka", "Shuai Zhang", "Tiantian Zhang", "Shuichi Murakami"], "title": "Fractal growth of higher-order topological insulators", "comment": "9+7 pages, 6+2 figures", "summary": "Understanding crystal growth and morphology is a fundamental issue in\ncondensed matter physics. In this work, we reveal the fractal morphology of\ngrowing crystals of higher-order topological insulators and show that the\ncorners of the crystals grow preferentially compared to the edges in the\npresence of the corner states. We further demonstrate that when we compare the\ncrystal shape of the higher-order topological insulator with that of the\ntrivial insulator with the same value of the fractal dimension $D_f$, the\nformer has a smaller value of the fractal dimension of coastlines $D_{f,c}$\nthan the latter. This indicates that, for crystals with a similar degree of\ncorner development, those in the higher-order topological phase have smoother\nedges. Because the relationship between the area and the perimeter of the\ncrystals is governed by the ratio of these fractal dimensions, the higher-order\ntopological insulator and the trivial insulator exhibit distinct perimeter-area\nrelationships.", "AI": {"tldr": "\u9ad8\u9636\u62d3\u6251\u7edd\u7f18\u4f53\u6676\u4f53\u5728\u751f\u957f\u8fc7\u7a0b\u4e2d\u5448\u73b0\u5206\u5f62\u5f62\u6001\uff0c\u4e14\u89d2\u6bd4\u8fb9\u751f\u957f\u5f97\u66f4\u5feb\uff0c\u5177\u6709\u66f4\u5149\u6ed1\u7684\u8fb9\u7f18\u548c\u72ec\u7279\u7684\u5468\u957f-\u9762\u79ef\u5173\u7cfb\u3002", "motivation": "\u7406\u89e3\u6676\u4f53\u751f\u957f\u548c\u5f62\u6001\u662f\u51dd\u805a\u6001\u7269\u7406\u4e2d\u7684\u57fa\u672c\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5206\u6790\u9ad8\u9636\u62d3\u6251\u7edd\u7f18\u4f53\u548c\u666e\u901a\u7edd\u7f18\u4f53\u7684\u6676\u4f53\u751f\u957f\u5f62\u6001\uff0c\u6bd4\u8f83\u4e86\u5b83\u4eec\u7684\u5206\u5f62\u7ef4\u5ea6\u548c\u6d77\u5cb8\u7ebf\u5206\u5f62\u7ef4\u5ea6\uff0c\u5e76\u7814\u7a76\u4e86\u5468\u957f-\u9762\u79ef\u5173\u7cfb\u3002", "result": "\u9ad8\u9636\u62d3\u6251\u7edd\u7f18\u4f53\u6676\u4f53\u5448\u73b0\u5206\u5f62\u5f62\u6001\uff0c\u89d2\u6bd4\u8fb9\u751f\u957f\u5f97\u66f4\u5feb\uff0c\u5177\u6709\u66f4\u5149\u6ed1\u7684\u8fb9\u7f18\uff08\u66f4\u5c0f\u7684\u6d77\u5cb8\u7ebf\u5206\u5f62\u7ef4\u5ea6\uff09\u548c\u72ec\u7279\u7684\u5468\u957f-\u9762\u79ef\u5173\u7cfb\u3002", "conclusion": "\u9ad8\u9636\u62d3\u6251\u7edd\u7f18\u4f53\u548c\u666e\u901a\u7edd\u7f18\u4f53\u5728\u6676\u4f53\u751f\u957f\u5f62\u6001\u3001\u8fb9\u7f18\u5149\u6ed1\u5ea6\u548c\u5468\u957f-\u9762\u79ef\u5173\u7cfb\u65b9\u9762\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002"}}
{"id": "2509.09805", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.09805", "abs": "https://arxiv.org/abs/2509.09805", "authors": ["Francisco M. L\u00f3pez", "Miles Lenz", "Marco G. Fedozzi", "Arthur Aubret", "Jochen Triesch"], "title": "MIMo grows! Simulating body and sensory development in a multimodal infant model", "comment": "Accepted at IEEE ICDL 2025. 6 pages, 6 figures", "summary": "Infancy is characterized by rapid body growth and an explosive change of\nsensory and motor abilities. However, developmental robots and simulation\nplatforms are typically designed in the image of a specific age, which limits\ntheir ability to capture the changing abilities and constraints of developing\ninfants. To address this issue, we present MIMo v2, a new version of the\nmultimodal infant model. It includes a growing body with increasing actuation\nstrength covering the age range from birth to 24 months. It also features\nfoveated vision with developing visual acuity as well as sensorimotor delays\nmodeling finite signal transmission speeds to and from an infant's brain.\nFurther enhancements of this MIMo version include an inverse kinematics module,\na random environment generator and updated compatiblity with third-party\nsimulation and learning libraries. Overall, this new MIMo version permits\nincreased realism when modeling various aspects of sensorimotor development.\nThe code is available on the official repository\n(https://github.com/trieschlab/MIMo).", "AI": {"tldr": "MIMo v2\u662f\u4e00\u4e2a\u5177\u6709\u53ef\u6269\u5c55\u8eab\u4f53\u3001\u53ef\u53d8\u89c6\u89c9\u548c\u4f20\u611f\u5668\u8fd0\u52a8\u5ef6\u8fdf\u7684\u5a74\u513f\u6a21\u578b\uff0c\u80fd\u591f\u6a21\u62df\u4ece\u51fa\u751f\u523024\u4e2a\u6708\u7684\u5a74\u513f\u53d1\u5c55\u3002", "motivation": "\u73b0\u6709\u7684\u53d1\u80b2\u673a\u5668\u4eba\u548c\u6a21\u62df\u5e73\u53f0\u901a\u5e38\u53ea\u9488\u5bf9\u7279\u5b9a\u5e74\u9f84\u6bb5\uff0c\u65e0\u6cd5\u6355\u6349\u5a74\u513f\u4e0d\u65ad\u53d8\u5316\u7684\u8eab\u4f53\u548c\u8fd0\u52a8\u80fd\u529b\u3002MIMo v2\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u63d0\u4f9b\u4e00\u4e2a\u80fd\u591f\u6a21\u62df\u5a74\u513f\u4ece\u51fa\u751f\u523024\u4e2a\u6708\u7684\u8eab\u4f53\u6210\u957f\u3001\u8fd0\u52a8\u80fd\u529b\u53d1\u5c55\u4ee5\u53ca\u89c6\u89c9\u548c\u4f20\u611f\u5668\u8fd0\u52a8\u5ef6\u8fdf\u7684\u6a21\u578b\u3002", "method": "MIMo v2 \u901a\u8fc7\u4ee5\u4e0b\u65b9\u5f0f\u5b9e\u73b0\uff1a1. \u53ef\u53d8\u5c3a\u5bf8\u548c\u9a71\u52a8\u529b\uff1a\u8eab\u4f53\u5c3a\u5bf8\u548c\u9a71\u52a8\u529b\u4f1a\u968f\u7740\u6a21\u62df\u5e74\u9f84\u7684\u589e\u957f\u800c\u53d8\u5316\u30022. \u89c6\u89c9\u6a21\u62df\uff1a\u5177\u6709\u805a\u7126\u89c6\u89c9\u548c\u6a21\u62df\u53d1\u80b2\u4e2d\u7684\u89c6\u654f\u5ea6\u30023. \u4f20\u611f\u5668\u8fd0\u52a8\u5ef6\u8fdf\uff1a\u6a21\u62df\u4fe1\u53f7\u4f20\u8f93\u5230\u548c\u79bb\u5f00\u5a74\u513f\u5927\u8111\u7684\u6709\u9650\u901f\u5ea6\u30024. \u6539\u8fdb\u529f\u80fd\uff1a\u5305\u62ec\u9006\u8fd0\u52a8\u5b66\u6a21\u5757\u3001\u968f\u673a\u73af\u5883\u751f\u6210\u5668\u4ee5\u53ca\u4e0e\u7b2c\u4e09\u65b9\u6a21\u62df\u548c\u5b66\u4e60\u5e93\u7684\u517c\u5bb9\u6027\u66f4\u65b0\u3002", "result": "MIMo v2 \u63d0\u9ad8\u4e86\u5728\u6a21\u62df\u5a74\u513f\u4f20\u611f\u5668\u8fd0\u52a8\u53d1\u5c55\u65b9\u9762\u7684\u771f\u5b9e\u611f\uff0c\u80fd\u591f\u66f4\u597d\u5730\u6355\u6349\u5a74\u513f\u53d1\u80b2\u8fc7\u7a0b\u4e2d\u7684\u80fd\u529b\u548c\u9650\u5236\u3002", "conclusion": "MIMo v2 \u662f\u4e00\u4e2a\u591a\u6a21\u6001\u5a74\u513f\u6a21\u578b\uff0c\u901a\u8fc7\u5176\u53ef\u6269\u5c55\u7684\u8eab\u4f53\u3001\u53d1\u80b2\u4e2d\u7684\u89c6\u89c9\u548c\u4f20\u611f\u5668\u8fd0\u52a8\u5ef6\u8fdf\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5728\u6a21\u62df\u5a74\u513f\u4f20\u611f\u5668\u8fd0\u52a8\u53d1\u5c55\u65b9\u9762\u7684\u771f\u5b9e\u611f\u3002"}}
{"id": "2509.09779", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2509.09779", "abs": "https://arxiv.org/abs/2509.09779", "authors": ["Jahan Claes"], "title": "Lower-depth local encoding circuits for the surface code", "comment": "Barely two pages, mostly figures", "summary": "The surface code is the most studied error-correcting code thanks to its high\nthreshold, simple decoding, and locality in two dimensions (2D). A key\ncomponent of any code is its encoding circuit, which maps an unencoded state to\nthe corresponding encoded state. The best previous surface code encoding\ncircuit compatible with 2D local connectivity requires depth $2d$ to encode\ndistance-$d$ surface codes. This paper presents depth $d$ encoding circuits for\nthe rotated surface code. Our circuit is constructed inductively from circuits\nthat grow the code from $d$ to $(d+2)$. We prove that depth $d+O(1)$ is optimal\nfor inductively constructed circuits.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65cb\u8f6c\u8868\u9762\u7801\u7f16\u7801\u7535\u8def\uff0c\u5c06\u7f16\u7801\u6df1\u5ea6\u4ece 2d \u51cf\u5c11\u5230 d\uff0c\u5e76\u8bc1\u660e\u4e86 d+O(1) \u5bf9\u4e8e\u5f52\u7eb3\u6784\u9020\u7684\u7535\u8def\u662f\u6700\u4f18\u7684\u3002", "motivation": "\u672c\u7814\u7a76\u7684\u52a8\u673a\u5728\u4e8e\u6539\u8fdb\u73b0\u6709\u8868\u9762\u7801\u7f16\u7801\u7535\u8def\u7684\u6548\u7387\uff0c\u7279\u522b\u662f\u51cf\u5c11\u5176\u6df1\u5ea6\uff0c\u4ee5\u9002\u5e94\u4e8c\u7ef4\u5c40\u90e8\u8fde\u901a\u6027\u7684\u8981\u6c42\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65cb\u8f6c\u8868\u9762\u7801\u7f16\u7801\u7535\u8def\uff0c\u8be5\u7535\u8def\u901a\u8fc7\u4ece d \u589e\u957f\u5230 (d+2) \u7684\u7535\u8def\u8fdb\u884c\u5f52\u7eb3\u6784\u9020\uff0c\u6700\u7ec8\u5b9e\u73b0\u4e86\u6df1\u5ea6\u4e3a d \u7684\u7f16\u7801\u3002", "result": "\u6210\u529f\u8bbe\u8ba1\u4e86\u6df1\u5ea6\u4e3a d \u7684\u65cb\u8f6c\u8868\u9762\u7801\u7f16\u7801\u7535\u8def\uff0c\u4f18\u4e8e\u4e4b\u524d\u9700\u8981\u6df1\u5ea6 2d \u7684\u7535\u8def\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u7684\u6df1\u5ea6\u4e3a d \u7684\u7f16\u7801\u7535\u8def\u662f\u9488\u5bf9\u65cb\u8f6c\u8868\u9762\u7801\u7684\uff0c\u5e76\u4e14\u8bc1\u660e\u4e86\u5bf9\u4e8e\u5f52\u7eb3\u6784\u9020\u7684\u7535\u8def\uff0c\u6df1\u5ea6 d+O(1) \u662f\u6700\u4f18\u7684\u3002"}}
{"id": "2509.09956", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2509.09956", "abs": "https://arxiv.org/abs/2509.09956", "authors": ["Yuwei Chuai", "Shuning Zhang", "Ziming Wang", "Xin Yi", "Mohsen Mosleh", "Gabriele Lenzini"], "title": "Request a Note: How the Request Function Shapes X's Community Notes System", "comment": null, "summary": "X's Community Notes is a crowdsourced fact-checking system. To improve its\nscalability, X recently introduced \"Request Community Note\" feature, enabling\nusers to solicit fact-checks from contributors on specific posts. Yet, its\nimplications for the system -- what gets checked, by whom, and with what\nquality -- remain unclear. Using 98,685 requested posts and their associated\nnotes, we evaluate how requests shape the Community Notes system. We find that\ncontributors prioritize posts with higher misleadingness and from authors with\ngreater misinformation exposure, but neglect political content emphasized by\nrequestors. Selection also diverges along partisan lines: contributors more\noften annotate posts from Republicans, while requestors surface more from\nDemocrats. Although only 12% of posts receive request-fostered notes from top\ncontributors, these notes are rated as more helpful and less polarized than\nothers, partly reflecting top contributors' selective fact-checking of\nmisleading posts. Our findings highlight both the limitations and promise of\nrequests for scaling high-quality community-based fact-checking.", "AI": {"tldr": "X\u7684\u793e\u533a\u7b14\u8bb0\u662f\u4e00\u4e2a\u4f17\u5305\u4e8b\u5b9e\u6838\u67e5\u7cfb\u7edf\uff0c\u5f15\u5165\u201c\u8bf7\u6c42\u793e\u533a\u7b14\u8bb0\u201d\u529f\u80fd\u65e8\u5728\u63d0\u9ad8\u5176\u53ef\u6269\u5c55\u6027\u3002\u7136\u800c\uff0c\u8be5\u529f\u80fd\u5bf9\u5185\u5bb9\u9009\u62e9\u3001\u8d21\u732e\u8005\u53c2\u4e0e\u548c\u7b14\u8bb0\u8d28\u91cf\u7684\u5f71\u54cd\u5c1a\u4e0d\u6e05\u695a\u3002\u672c\u7814\u7a76\u4f7f\u752898,685\u4e2a\u88ab\u8bf7\u6c42\u7684\u5e16\u5b50\u53ca\u5176\u76f8\u5173\u7b14\u8bb0\uff0c\u8bc4\u4f30\u8bf7\u6c42\u5982\u4f55\u5851\u9020\u793e\u533a\u7b14\u8bb0\u7cfb\u7edf\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u8bc4\u4f30X\u7684\u201c\u8bf7\u6c42\u793e\u533a\u7b14\u8bb0\u201d\u529f\u80fd\u5bf9\u793e\u533a\u7b14\u8bb0\u7cfb\u7edf\u53ef\u6269\u5c55\u6027\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5185\u5bb9\u9009\u62e9\u3001\u8d21\u732e\u8005\u53c2\u4e0e\u548c\u7b14\u8bb0\u8d28\u91cf\u65b9\u9762\u3002", "method": "\u4f7f\u752898,685\u4e2a\u88ab\u8bf7\u6c42\u7684\u5e16\u5b50\u53ca\u5176\u76f8\u5173\u7684\u793e\u533a\u7b14\u8bb0\uff0c\u5206\u6790\u8bf7\u6c42\u5982\u4f55\u5f71\u54cd\u793e\u533a\u7b14\u8bb0\u7cfb\u7edf\u7684\u8fd0\u884c\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u8d21\u732e\u8005\u4f18\u5148\u6838\u67e5\u5177\u6709\u66f4\u9ad8\u8bef\u5bfc\u6027\u548c\u6765\u81ea\u6709\u66f4\u9ad8\u865a\u5047\u4fe1\u606f\u66b4\u9732\u4f5c\u8005\u7684\u5e16\u5b50\uff0c\u4f46\u4f1a\u5ffd\u7565\u8bf7\u6c42\u8005\u5f3a\u8c03\u7684\u653f\u6cbb\u5185\u5bb9\u3002\u8d21\u732e\u8005\u66f4\u503e\u5411\u4e8e\u6807\u6ce8\u6765\u81ea\u5171\u548c\u515a\u4eba\u7684\u5e16\u5b50\uff0c\u800c\u8bf7\u6c42\u8005\u5219\u66f4\u591a\u5730\u63d0\u51fa\u6765\u81ea\u6c11\u4e3b\u515a\u4eba\u7684\u5e16\u5b50\u3002\u5c3d\u7ba1\u53ea\u670912%\u7684\u5e16\u5b50\u83b7\u5f97\u4e86\u9876\u7ea7\u8d21\u732e\u8005\u5ba1\u6838\u7684\u7b14\u8bb0\uff0c\u4f46\u8fd9\u4e9b\u7b14\u8bb0\u88ab\u8ba4\u4e3a\u66f4\u6709\u5e2e\u52a9\u4e14\u6781\u5316\u7a0b\u5ea6\u66f4\u4f4e\u3002", "conclusion": "\u8bf7\u6c42\u529f\u80fd\u5728\u6269\u5c55\u9ad8\u8d28\u91cf\u793e\u533a\u4e8b\u5b9e\u6838\u67e5\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u4f46\u4e5f\u5c55\u73b0\u51fa\u4e00\u5b9a\u7684\u6f5c\u529b\u3002"}}
{"id": "2509.10146", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2509.10146", "abs": "https://arxiv.org/abs/2509.10146", "authors": ["Mathijs van Noort", "Femke Ongenae", "Pieter Bonte"], "title": "On Syntactical Simplification of Temporal Operators in Negation-free MTL", "comment": null, "summary": "Temporal reasoning in dynamic, data-intensive environments increasingly\ndemands expressive yet tractable logical frameworks. Traditional approaches\noften rely on negation to express absence or contradiction. In such contexts,\nNegation-as-Failure is commonly used to infer negative information from the\nlack of positive evidence. However, open and distributed systems such as IoT\nnetworks or the Semantic Web Negation-as-Failure semantics become unreliable\ndue to incomplete and asynchronous data. This has led to a growing interest in\nnegation-free fragments of temporal rule-based systems, which preserve\nmonotonicity and enable scalable reasoning.\n  This paper investigates the expressive power of negation-free MTL, a temporal\nlogic framework designed for rule-based reasoning over time. We show that the\n\"always\" operators of MTL, often treated as syntactic sugar for combinations of\nother temporal constructs, can be eliminated using \"once\", \"since\" and \"until\"\noperators. Remarkably, even the \"once\" operators can be removed, yielding a\nfragment based solely on \"until\" and \"since\". These results challenge the\nassumption that negation is necessary for expressing universal temporal\nconstraints, and reveal a robust fragment capable of capturing both existential\nand invariant temporal patterns. Furthermore, the results induce a reduction in\nthe syntax of MTL, which in turn can provide benefits for both theoretical\nstudy as well as implementation efforts.", "AI": {"tldr": "\u672c\u8bba\u6587\u7814\u7a76\u4e86\u65e0\u5426\u5b9a\u5f62\u5f0f\u7684\u65f6\u95f4\u903b\u8f91\u63a8\u7406\uff0c\u8bc1\u660e\u4e86MTL\u903b\u8f91\u4e2d\u7684\u201c\u603b\u662f\u201d\u548c\u201c\u4ec5\u4ec5\u201d\u7b97\u5b50\u53ef\u4ee5\u88ab\u201c\u76f4\u5230\u201d\u548c\u201c\u81ea\u4ece\u201d\u7b97\u5b50\u66ff\u4ee3\uff0c\u4ece\u800c\u7b80\u5316\u4e86\u903b\u8f91\u5f62\u5f0f\u5e76\u4e3a\u53ef\u6269\u5c55\u63a8\u7406\u63d0\u4f9b\u4e86\u53ef\u80fd\u3002", "motivation": "\u4f20\u7edf\u7684\u903b\u8f91\u63a8\u7406\u65b9\u6cd5\u4f9d\u8d56\u5426\u5b9a\u6765\u8868\u8fbe\u7f3a\u5931\u6216\u77db\u76fe\uff0c\u4f46\u5728\u4e0d\u5b8c\u6574\u548c\u5f02\u6b65\u7684\u6570\u636e\u73af\u5883\u4e2d\uff08\u5982\u7269\u8054\u7f51\u6216\u8bed\u4e49\u7f51\uff09\u4f1a\u53d8\u5f97\u4e0d\u53ef\u9760\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u4e0d\u5305\u542b\u5426\u5b9a\u7684\u65f6\u95f4\u903b\u8f91\u89c4\u5219\u7cfb\u7edf\u5f15\u8d77\u4e86\u5e7f\u6cdb\u5173\u6ce8\uff0c\u56e0\u4e3a\u5b83\u4eec\u80fd\u4fdd\u6301\u5355\u8c03\u6027\u5e76\u652f\u6301\u53ef\u6269\u5c55\u63a8\u7406\u3002", "method": "\u901a\u8fc7\u8bc1\u660eMTL\u903b\u8f91\u4e2d\u7684\u201c\u603b\u662f\u201d\u7b97\u5b50\u53ef\u4ee5\u88ab\u201c\u4e00\u6b21\u201d\u3001\u201c\u81ea\u4ece\u201d\u548c\u201c\u76f4\u5230\u201d\u7b97\u5b50\u7ec4\u5408\u66ff\u4ee3\uff0c\u5e76\u8fdb\u4e00\u6b65\u8bc1\u660e\u201c\u4e00\u6b21\u201d\u7b97\u5b50\u4e5f\u53ef\u4ee5\u88ab\u201c\u76f4\u5230\u201d\u548c\u201c\u81ea\u4ece\u201d\u7b97\u5b50\u66ff\u4ee3\uff0c\u4ece\u800c\u5f97\u5230\u4e00\u4e2a\u4ec5\u57fa\u4e8e\u201c\u76f4\u5230\u201d\u548c\u201c\u81ea\u4ece\u201d\u7684\u903b\u8f91\u7247\u6bb5\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0cMTL\u903b\u8f91\u4e2d\u7684\u201c\u603b\u662f\u201d\u548c\u201c\u4e00\u6b21\u201d\u7b97\u5b50\u53ef\u4ee5\u88ab\u6d88\u9664\uff0c\u4ec5\u7559\u4e0b\u201c\u76f4\u5230\u201d\u548c\u201c\u81ea\u4ece\u201d\u7b97\u5b50\uff0c\u8fd9\u8868\u660e\u65e0\u5426\u5b9a\u5f62\u5f0f\u7684\u65f6\u95f4\u903b\u8f91\u540c\u6837\u5177\u6709\u8868\u8fbe\u80fd\u529b\uff0c\u80fd\u591f\u6355\u6349\u5b58\u5728\u6027\u548c\u4e0d\u53d8\u6027\u7684\u65f6\u95f4\u6a21\u5f0f\u3002\u8fd9\u5927\u5927\u7b80\u5316\u4e86MTL\u7684\u8bed\u6cd5\uff0c\u6709\u5229\u4e8e\u7406\u8bba\u7814\u7a76\u548c\u5b9e\u73b0\u3002", "conclusion": "\u672c\u7814\u7a76\u6210\u529f\u5730\u8bc6\u522b\u5e76\u8bc1\u660e\u4e86\u4e00\u4e2a\u5f3a\u5927\u7684\u3001\u65e0\u5426\u5b9a\u7684MTL\u903b\u8f91\u7247\u6bb5\uff0c\u4ec5\u7531\u201c\u76f4\u5230\u201d\u548c\u201c\u81ea\u4ece\u201d\u7b97\u5b50\u6784\u6210\u3002\u8fd9\u4e00\u53d1\u73b0\u4e0d\u4ec5\u6311\u6218\u4e86\u666e\u904d\u8ba4\u4e3a\u5426\u5b9a\u5bf9\u4e8e\u8868\u8fbe\u666e\u904d\u65f6\u95f4\u7ea6\u675f\u662f\u5fc5\u9700\u7684\u89c2\u70b9\uff0c\u800c\u4e14\u8fd8\u901a\u8fc7\u7b80\u5316\u8bed\u6cd5\u4e3a\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9645\u5e94\u7528\u5e26\u6765\u4e86\u597d\u5904\uff0c\u4e3a\u5728\u52a8\u6001\u3001\u6570\u636e\u5bc6\u96c6\u578b\u73af\u5883\u4e2d\u8fdb\u884c\u53ef\u6269\u5c55\u7684\u65f6\u95f4\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u7684\u9014\u5f84\u3002"}}
{"id": "2509.09694", "categories": ["physics.app-ph"], "pdf": "https://arxiv.org/pdf/2509.09694", "abs": "https://arxiv.org/abs/2509.09694", "authors": ["Raffaele Ponzini", "Roberto Da Vi\u00e0", "Simone Bn\u00e0", "Ciro Cottini", "Andrea Benassi"], "title": "Coupled CFD-DEM model for dry powder inhalers simulation: validation and sensitivity analysis for the main model parameters", "comment": null, "summary": "The use of computational techniques in the design of dry powder inhalers\n(DPI), as well as in unravelling the complex mechanisms of drug aerosolization,\nhas increased significantly in recent years. Computational fluid dynamics (CFD)\nis used to study the air flow, inside the DPI, during the patient inspiratory\nact while discrete element methods (DEM) are used to simulate the dispersion\nand aerosolization of the drug product powder particles. In this work we\ndiscuss the possibility to validate a coupled CFD-DEM model for the NextHaler\nDPI device against previously published experimental data. The approximations\nand assumptions made are deeply discussed. The comparison between computational\nand experimental results is detailed both for fluid and powder flows. Finally,\nthe potential and possible applications of a calibrated DPI model are discussed\nas well as the missing elements necessary to achieve a fully quantitatively\npredictive computational model.", "AI": {"tldr": "\u8ba1\u7b97\u6d41\u4f53\u52a8\u529b\u5b66\uff08CFD\uff09\u548c\u79bb\u6563\u5143\u65b9\u6cd5\uff08DEM\uff09\u7684\u8026\u5408\u6a21\u578b\u53ef\u7528\u4e8e\u6a21\u62df\u5e72\u7c89\u5438\u5165\u5668\uff08DPI\uff09\u4e2d\u7684\u836f\u7269\u96fe\u5316\u8fc7\u7a0b\uff0c\u5e76\u4e0e\u5b9e\u9a8c\u6570\u636e\u8fdb\u884c\u9a8c\u8bc1\u3002", "motivation": "\u8ba1\u7b97\u6280\u672f\u5728\u5e72\u7c89\u5438\u5165\u5668\uff08DPI\uff09\u8bbe\u8ba1\u548c\u836f\u7269\u96fe\u5316\u673a\u5236\u7814\u7a76\u4e2d\u7684\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u9700\u8981\u9a8c\u8bc1\u8ba1\u7b97\u6a21\u578b\u4ee5\u786e\u4fdd\u5176\u51c6\u786e\u6027\u3002", "method": "\u4f7f\u7528CFD\u6a21\u62df\u5438\u5165\u8fc7\u7a0b\u4e2dDPI\u5185\u90e8\u7684\u7a7a\u6c14\u6d41\u52a8\uff0c\u4f7f\u7528DEM\u6a21\u62df\u836f\u7269\u7c89\u672b\u9897\u7c92\u7684\u5206\u6563\u548c\u96fe\u5316\u3002\u5c06\u8026\u5408CFD-DEM\u6a21\u578b\u4e0e\u5df2\u53d1\u5e03\u7684\u5b9e\u9a8c\u6570\u636e\u8fdb\u884c\u5bf9\u6bd4\u9a8c\u8bc1\u3002", "result": "\u8be6\u7ec6\u6bd4\u8f83\u4e86\u8ba1\u7b97\u7ed3\u679c\u548c\u5b9e\u9a8c\u7ed3\u679c\u5728\u6d41\u4f53\u548c\u7c89\u672b\u6d41\u52a8\u65b9\u9762\u7684\u543b\u5408\u7a0b\u5ea6\uff0c\u8ba8\u8bba\u4e86\u6a21\u578b\u4e2d\u7684\u8fd1\u4f3c\u548c\u5047\u8bbe\u3002", "conclusion": "\u7ecf\u8fc7\u6821\u51c6\u7684DPI\u6a21\u578b\u5177\u6709\u6f5c\u529b\u548c\u5e94\u7528\u524d\u666f\uff0c\u4f46\u4ecd\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u4ee5\u5b9e\u73b0\u5b8c\u5168\u5b9a\u91cf\u7684\u9884\u6d4b\u6a21\u578b\u3002"}}
{"id": "2509.10284", "categories": ["cs.MA", "cs.RO"], "pdf": "https://arxiv.org/pdf/2509.10284", "abs": "https://arxiv.org/abs/2509.10284", "authors": ["David Zahr\u00e1dka", "Denisa Mu\u017e\u00edkov\u00e1", "David Woller", "Miroslav Kulich", "Ji\u0159\u00ed \u0160vancara", "Roman Bart\u00e1k"], "title": "A Holistic Architecture for Monitoring and Optimization of Robust Multi-Agent Path Finding Plan Execution", "comment": "23 pages, 10 figures", "summary": "The goal of Multi-Agent Path Finding (MAPF) is to find a set of paths for a\nfleet of agents moving in a shared environment such that the agents reach their\ngoals without colliding with each other. In practice, some of the robots\nexecuting the plan may get delayed, which can introduce collision risk.\nAlthough robust execution methods are used to ensure safety even in the\npresence of delays, the delays may still have a significant impact on the\nduration of the execution. At some point, the accumulated delays may become\nsignificant enough that instead of continuing with the execution of the\noriginal plan, even if it was optimal, there may now exist an alternate plan\nwhich will lead to a shorter execution. However, the problem is how to decide\nwhen to search for the alternate plan, since it is a costly procedure. In this\npaper, we propose a holistic architecture for robust execution of MAPF plans,\nits monitoring and optimization. We exploit a robust execution method called\nAction Dependency Graph to maintain an estimate of the expected execution\nduration during the plan's execution. This estimate is used to predict the\npotential that finding an alternate plan would lead to shorter execution. We\nempirically evaluate the architecture in experiments in a real-time simulator\nwhich we designed to mimic our real-life demonstrator of an autonomous\nwarehouse robotic fleet.", "AI": {"tldr": "MAPF \u8ba1\u5212\u7684\u7a33\u5065\u6267\u884c\u548c\u76d1\u63a7\u9700\u8981\u5e73\u8861\u7ee7\u7eed\u6267\u884c\u5f53\u524d\u8ba1\u5212\u4e0e\u91cd\u65b0\u89c4\u5212\u4ee5\u7f29\u77ed\u6267\u884c\u65f6\u95f4\u7684\u6210\u672c\u3002", "motivation": "\u5f53\u673a\u5668\u4eba\u6267\u884c MAPF \u8ba1\u5212\u65f6\uff0c\u5ef6\u8fdf\u53ef\u80fd\u4f1a\u7d2f\u79ef\u5e76\u5bfc\u81f4\u6267\u884c\u65f6\u95f4\u5ef6\u957f\uff0c\u5373\u4f7f\u539f\u59cb\u8ba1\u5212\u662f\u6700\u4f18\u7684\uff0c\u4e5f\u53ef\u80fd\u5b58\u5728\u66f4\u4f18\u7684\u66ff\u4ee3\u8ba1\u5212\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6574\u4f53\u67b6\u6784\uff0c\u7528\u4e8e MAPF \u8ba1\u5212\u7684\u7a33\u5065\u6267\u884c\u3001\u76d1\u63a7\u548c\u4f18\u5316\u3002\u4f7f\u7528\u79f0\u4e3a\u201c\u52a8\u4f5c\u4f9d\u8d56\u56fe\u201d\u7684\u7a33\u5065\u6267\u884c\u65b9\u6cd5\u6765\u4f30\u8ba1\u9884\u671f\u6267\u884c\u65f6\u95f4\uff0c\u5e76\u9884\u6d4b\u91cd\u65b0\u89c4\u5212\u7684\u6f5c\u5728\u597d\u5904\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u67b6\u6784\u53ef\u4ee5\u6709\u6548\u9884\u6d4b\u4f55\u65f6\u91cd\u65b0\u89c4\u5212\u53ef\u4ee5\u7f29\u77ed\u6267\u884c\u65f6\u95f4\uff0c\u4ece\u800c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5177\u6709\u6210\u672c\u6548\u76ca\u3002", "conclusion": "MAPF \u8ba1\u5212\u7684\u76d1\u63a7\u548c\u4f18\u5316\u5bf9\u4e8e\u5728\u5b58\u5728\u5ef6\u8fdf\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u9ad8\u6548\u6267\u884c\u81f3\u5173\u91cd\u8981\u3002\u901a\u8fc7\u4ed4\u7ec6\u76d1\u63a7\u6267\u884c\u65f6\u95f4\u548c\u91cd\u65b0\u89c4\u5212\u7684\u6f5c\u5728\u597d\u5904\uff0c\u53ef\u4ee5\u6700\u5927\u9650\u5ea6\u5730\u51cf\u5c11\u6267\u884c\u65f6\u95f4\u3002"}}
{"id": "2509.10011", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2509.10011", "abs": "https://arxiv.org/abs/2509.10011", "authors": ["Antoine Orioua", "Philipp Krah", "Julian Koellermeier"], "title": "Intrinsic Dimension Estimating Autoencoder (IDEA) Using CancelOut Layer and a Projected Loss", "comment": "Preprint with 12 pages and 12 figures", "summary": "This paper introduces the Intrinsic Dimension Estimating Autoencoder (IDEA),\nwhich identifies the underlying intrinsic dimension of a wide range of datasets\nwhose samples lie on either linear or nonlinear manifolds. Beyond estimating\nthe intrinsic dimension, IDEA is also able to reconstruct the original dataset\nafter projecting it onto the corresponding latent space, which is structured\nusing re-weighted double CancelOut layers. Our key contribution is the\nintroduction of the projected reconstruction loss term, guiding the training of\nthe model by continuously assessing the reconstruction quality under the\nremoval of an additional latent dimension. We first assess the performance of\nIDEA on a series of theoretical benchmarks to validate its robustness. These\nexperiments allow us to test its reconstruction ability and compare its\nperformance with state-of-the-art intrinsic dimension estimators. The\nbenchmarks show good accuracy and high versatility of our approach.\nSubsequently, we apply our model to data generated from the numerical solution\nof a vertically resolved one-dimensional free-surface flow, following a\npointwise discretization of the vertical velocity profile in the horizontal\ndirection, vertical direction, and time. IDEA succeeds in estimating the\ndataset's intrinsic dimension and then reconstructs the original solution by\nworking directly within the projection space identified by the network.", "AI": {"tldr": "IDEA\u662f\u4e00\u4e2a\u80fd\u591f\u4f30\u8ba1\u6570\u636e\u96c6\u5185\u5728\u7ef4\u5ea6\u5e76\u8fdb\u884c\u6570\u636e\u91cd\u5efa\u7684\u81ea\u7f16\u7801\u5668\u6a21\u578b\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u7ebf\u6027\u6216\u975e\u7ebf\u6027\u6d41\u5f62\u4e0a\u7684\u6570\u636e\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u4f30\u8ba1\u4e0d\u540c\u7c7b\u578b\u6570\u636e\u96c6\u5185\u5728\u7ef4\u5ea6\u5e76\u8fdb\u884c\u6570\u636e\u91cd\u5efa\u7684\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aIDEA\uff08Intrinsic Dimension Estimating Autoencoder\uff09\u7684\u81ea\u7f16\u7801\u5668\u6a21\u578b\uff0c\u5176\u6838\u5fc3\u5728\u4e8e\u5f15\u5165\u4e86\u6295\u5f71\u91cd\u5efa\u635f\u5931\u9879\uff08projected reconstruction loss term\uff09\uff0c\u5e76\u4f7f\u7528\u91cd\u52a0\u6743\u53cc\u91cdCancelOut\u5c42\u6765\u6784\u5efa\u6f5c\u5728\u7a7a\u95f4\u3002", "result": "\u5728\u7406\u8bba\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cIDEA\u8868\u73b0\u51fa\u826f\u597d\u7684\u51c6\u786e\u6027\u548c\u9ad8\u5ea6\u7684\u901a\u7528\u6027\uff0c\u80fd\u591f\u51c6\u786e\u4f30\u8ba1\u5185\u5728\u7ef4\u5ea6\u5e76\u4e0e\u73b0\u6709\u6280\u672f\u8fdb\u884c\u6bd4\u8f83\u3002\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0cIDEA\u6210\u529f\u5730\u4f30\u8ba1\u4e86\u7531\u4e00\u7ef4\u81ea\u7531\u8868\u9762\u6d41\u52a8\u6570\u503c\u89e3\u751f\u6210\u7684\u6570\u636e\u96c6\u7684\u5185\u5728\u7ef4\u5ea6\uff0c\u5e76\u76f4\u63a5\u5728\u8bc6\u522b\u51fa\u7684\u6295\u5f71\u7a7a\u95f4\u4e2d\u91cd\u5efa\u4e86\u539f\u59cb\u89e3\u3002", "conclusion": "IDEA\u6a21\u578b\u4e0d\u4ec5\u80fd\u6709\u6548\u4f30\u8ba1\u6570\u636e\u96c6\u7684\u5185\u5728\u7ef4\u5ea6\uff0c\u8fd8\u80fd\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u8fdb\u884c\u9ad8\u8d28\u91cf\u7684\u6570\u636e\u91cd\u5efa\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u7406\u8bba\u548c\u5b9e\u9645\u95ee\u9898\u4e0a\u7684\u9c81\u68d2\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2509.09837", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.09837", "abs": "https://arxiv.org/abs/2509.09837", "authors": ["Jiapei Tian", "Abolfazl Zakeri", "Marian Codreanu", "David Gundleg\u00e5rd"], "title": "Real-Time Remote Tracking with State-Dependent Detection Probability: A POMDP Framework", "comment": null, "summary": "We consider a real-time tracking system where a binary Markov source is\nmonitored by two heterogeneous sensors. Upon command, sensors send their\nobservations to a remote sink over error-prone channels. We assume each sensor\nexhibits state-dependent detection accuracy and may occasionally fail to detect\nthe source state. At most one sensor is scheduled for sampling at each time\nslot. We assess the effectiveness of data communication using a generic\ndistortion function that captures the end application's objective. We derive\noptimal sink-side command policies to minimize the weighted sum of distortion\nand transmission costs. To model the uncertainty introduced by sensing failures\n(of the sensors) and packet loss, we formulate the problem as a partially\nobservable Markov decision process (POMDP), which we then cast into a\nbelief-MDP. Since the belief evolves continuously, the belief space is\ndiscretized into a finite grid and the belief value is quantized to the nearest\ngrid point after each update. This formulation leads to a finite-state MDP\nproblem, which is solved using the relative value iteration algorithm (RVIA).\nSimulation results demonstrate that the proposed policy significantly\noutperforms benchmark strategies and highlights the importance of accounting\nfor state-dependent sensing reliability in sensor scheduling.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u90e8\u5206\u53ef\u89c2\u6d4b\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08POMDP\uff09\u7684\u5b9e\u65f6\u8ddf\u8e2a\u7cfb\u7edf\uff0c\u5229\u7528\u4e24\u4e2a\u5f02\u6784\u4f20\u611f\u5668\u76d1\u63a7\u4e8c\u5143\u9a6c\u5c14\u53ef\u592b\u4fe1\u6e90\uff0c\u901a\u8fc7\u4f18\u5316\u4f20\u611f\u5668\u8c03\u5ea6\u548c\u547d\u4ee4\u7b56\u7565\u6765\u6700\u5c0f\u5316\u5931\u771f\u548c\u4f20\u8f93\u6210\u672c\u7684\u603b\u548c\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u4f18\u4e8e\u57fa\u51c6\u7b56\u7565\u3002", "motivation": "\u5728\u5b9e\u65f6\u8ddf\u8e2a\u7cfb\u7edf\u4e2d\uff0c\u9700\u8981\u8003\u8651\u4f20\u611f\u5668\u72b6\u6001\u4f9d\u8d56\u7684\u68c0\u6d4b\u7cbe\u5ea6\u3001\u4f20\u611f\u5668\u6545\u969c\u4ee5\u53ca\u4fe1\u9053\u4f20\u8f93\u9519\u8bef\u7b49\u56e0\u7d20\uff0c\u4ee5\u4f18\u5316\u6570\u636e\u6536\u96c6\u548c\u4f20\u8f93\u7b56\u7565\uff0c\u4ece\u800c\u6700\u5c0f\u5316\u7cfb\u7edf\u5931\u771f\u548c\u4f20\u8f93\u6210\u672c\u3002", "method": "\u5c06\u95ee\u9898\u5efa\u6a21\u4e3a\u90e8\u5206\u53ef\u89c2\u6d4b\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08POMDP\uff09\uff0c\u5e76\u5c06\u5176\u8f6c\u6362\u4e3a\u4fe1\u5ff5-MDP\u3002\u901a\u8fc7\u5c06\u8fde\u7eed\u7684\u4fe1\u5ff5\u7a7a\u95f4\u79bb\u6563\u5316\u5e76\u91cf\u5316\u4fe1\u5ff5\u503c\uff0c\u5c06\u95ee\u9898\u8f6c\u5316\u4e3a\u6709\u9650\u72b6\u6001\u7684MDP\u95ee\u9898\uff0c\u5e76\u4f7f\u7528\u76f8\u5bf9\u4ef7\u503c\u8fed\u4ee3\u7b97\u6cd5\uff08RVIA\uff09\u6c42\u89e3\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u7b56\u7565\u663e\u8457\u4f18\u4e8e\u57fa\u51c6\u7b56\u7565\uff0c\u5e76\u5f3a\u8c03\u4e86\u5728\u4f20\u611f\u5668\u8c03\u5ea6\u4e2d\u8003\u8651\u72b6\u6001\u4f9d\u8d56\u7684\u4f20\u611f\u53ef\u9760\u6027\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8ePOMDP\u7684\u4f18\u5316\u6846\u67b6\u80fd\u591f\u6709\u6548\u5730\u5904\u7406\u5e26\u566a\u58f0\u548c\u4f20\u611f\u5668\u6545\u969c\u7684\u5b9e\u65f6\u8ddf\u8e2a\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u72b6\u6001\u4f9d\u8d56\u7684\u4f20\u611f\u5668\u8c03\u5ea6\u548c\u547d\u4ee4\u7b56\u7565\uff0c\u5728\u6700\u5c0f\u5316\u5931\u771f\u548c\u4f20\u8f93\u6210\u672c\u65b9\u9762\u53d6\u5f97\u4e86\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u3002"}}
{"id": "2509.09938", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2509.09938", "abs": "https://arxiv.org/abs/2509.09938", "authors": ["Abhijith Thoopul Anantharanga", "Jackson Plummer", "Saryu Fensin", "Brandon Runnels"], "title": "Predicting void nucleation in microstructure with convolutional neural networks", "comment": null, "summary": "Void nucleation in ductile materials subjected to high strain-rate loading\nremains a critical yet elusive phenomenon to understand. Traditional methods to\nunderstand void nucleation typically rely on experiments and molecular dynamics\nand do not capture the underlying factors leading to void nucleation. In this\nstudy, a convolutional neural network, specifically a U-Net enhanced with\nattention gates is developed, to predict void nucleation probability in\npristine tantalum microstructures. The approach leverages a multi-channel\ninput, incorporating four channels of grain orientations and an additional\nchannel of grain boundary energy calculated via the lattice matching method.\nVoid nucleation probability fields are determined from post-mortem micrographs\nand serve as ground truth, distinguishing void from no-void regions at the\npixel level. Pixel-level class imbalance, commen in such images, is addressed\nby using Focal loss to guide the network's training to predict void nucleation\nsites more effectively. The model not only predicts void nucleation sites\nconsistent with ground-truth but also reveals additional potential void\nnucleation sites, capturing the stochastic nature of void nucleation. This\nstudy shows that CNN-based models can predict void nucleation sites while\nconsidering combined interplay of factors such as grain boundary energy and\ngrain orientation. In this way, machine learning can serve as a means to\nunderstand the underlying factors leading to void nucleation thereby\ncontributing to a fundamental understanding of failure due to spallation in\nductile materials.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eU-Net\u6ce8\u610f\u529b\u673a\u5236\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff0c\u7528\u4e8e\u9884\u6d4b\u94bd\u6750\u6599\u5728\u9ad8\u5e94\u53d8\u7387\u52a0\u8f7d\u4e0b\u7684\u7a7a\u6d1e\u6210\u6838\u6982\u7387\uff0c\u5e76\u6210\u529f\u8bc6\u522b\u51fa\u6f5c\u5728\u7684\u6210\u6838\u4f4d\u70b9\uff0c\u4e3a\u7406\u89e3\u6750\u6599\u5931\u6548\u673a\u7406\u63d0\u4f9b\u4e86\u65b0\u7684\u9014\u5f84\u3002", "motivation": "\u7406\u89e3\u5728\u9ad8\u5e94\u53d8\u7387\u52a0\u8f7d\u4e0b\u5ef6\u6027\u6750\u6599\u7684\u7a7a\u6d1e\u6210\u6838\u673a\u5236\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u5176\u6839\u672c\u539f\u56e0\u3002", "method": "\u5229\u7528\u5305\u542b\u6676\u7c92\u53d6\u5411\u548c\u6676\u754c\u80fd\u91cf\u7684\u591a\u901a\u9053\u8f93\u5165\uff0c\u8bad\u7ec3U-Net\u6ce8\u610f\u529b\u673a\u5236\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff0c\u4ee5\u50cf\u7d20\u7ea7\u522b\u51c6\u786e\u9884\u6d4b\u7a7a\u6d1e\u6210\u6838\u6982\u7387\uff0c\u5e76\u91c7\u7528Focal loss\u89e3\u51b3\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "result": "\u6240\u63d0\u51fa\u7684\u6a21\u578b\u80fd\u591f\u51c6\u786e\u9884\u6d4b\u7a7a\u6d1e\u6210\u6838\u4f4d\u70b9\uff0c\u5e76\u53d1\u73b0\u989d\u5916\u7684\u6f5c\u5728\u6210\u6838\u4f4d\u70b9\uff0c\u663e\u793a\u51fa\u5176\u80fd\u591f\u6355\u6349\u7a7a\u6d1e\u6210\u6838\u7684\u968f\u673a\u6027\u3002", "conclusion": "\u57fa\u4e8e\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u6a21\u578b\u80fd\u591f\u6709\u6548\u9884\u6d4b\u7a7a\u6d1e\u6210\u6838\u4f4d\u70b9\uff0c\u5e76\u8003\u8651\u4e86\u6676\u754c\u80fd\u91cf\u548c\u6676\u7c92\u53d6\u5411\u7b49\u7efc\u5408\u56e0\u7d20\uff0c\u4e3a\u7406\u89e3\u5ef6\u6027\u6750\u6599\u56e0\u6563\u88c2\u5f15\u8d77\u7684\u5931\u6548\u673a\u7406\u63d0\u4f9b\u4e86\u65b0\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u3002"}}
{"id": "2509.09701", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.09701", "abs": "https://arxiv.org/abs/2509.09701", "authors": ["JungHo Jung", "Junhyun Lee"], "title": "Optimal Multi-Task Learning at Regularization Horizon for Speech Translation Task", "comment": null, "summary": "End-to-end speech-to-text translation typically suffers from the scarcity of\npaired speech-text data. One way to overcome this shortcoming is to utilize the\nbitext data from the Machine Translation (MT) task and perform Multi-Task\nLearning (MTL). In this paper, we formulate MTL from a regularization\nperspective and explore how sequences can be regularized within and across\nmodalities. By thoroughly investigating the effect of consistency\nregularization (different modality) and R-drop (same modality), we show how\nthey respectively contribute to the total regularization. We also demonstrate\nthat the coefficient of MT loss serves as another source of regularization in\nthe MTL setting. With these three sources of regularization, we introduce the\noptimal regularization contour in the high-dimensional space, called the\nregularization horizon. Experiments show that tuning the hyperparameters within\nthe regularization horizon achieves near state-of-the-art performance on the\nMuST-C dataset.", "AI": {"tldr": "\u5229\u7528\u673a\u5668\u7ffb\u8bd1\uff08MT\uff09\u7684\u53cc\u8bed\u6587\u672c\u6570\u636e\uff0c\u901a\u8fc7\u591a\u4efb\u52a1\u5b66\u4e60\uff08MTL\uff09\u6765\u514b\u670d\u8bed\u97f3-\u6587\u672c\u7ffb\u8bd1\uff08ST\uff09\u4e2d\u914d\u5bf9\u6570\u636e\u7a00\u7f3a\u7684\u95ee\u9898\u3002", "motivation": "End-to-end speech-to-text translation typically suffers from the scarcity of paired speech-text data. One way to overcome this shortcoming is to utilize the bitext data from the Machine Translation (MT) task and perform Multi-Task Learning (MTL).", "method": "Formulate MTL from a regularization perspective and explore how sequences can be regularized within and across modalities. Investigate the effect of consistency regularization (different modality) and R-drop (same modality). Explore the coefficient of MT loss as another source of regularization. Introduce the optimal regularization contour in the high-dimensional space, called the regularization horizon.", "result": "Tuning the hyperparameters within the regularization horizon achieves near state-of-the-art performance on the MuST-C dataset.", "conclusion": "The proposed method, by leveraging three sources of regularization within the MTL framework, achieves near state-of-the-art results on the MuST-C dataset, indicating the effectiveness of regularization in addressing data scarcity for speech-to-text translation."}}
{"id": "2509.09751", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09751", "abs": "https://arxiv.org/abs/2509.09751", "authors": ["Junqiao Wang", "Zhaoyang Guan", "Guanyu Liu", "Tianze Xia", "Xianzhi Li", "Shuo Yin", "Xinyuan Song", "Chuhan Cheng", "Tianyu Shi", "Alex Lee"], "title": "Meta-Learning Reinforcement Learning for Crypto-Return Prediction", "comment": null, "summary": "Predicting cryptocurrency returns is notoriously difficult: price movements\nare driven by a fast-shifting blend of on-chain activity, news flow, and social\nsentiment, while labeled training data are scarce and expensive. In this paper,\nwe present Meta-RL-Crypto, a unified transformer-based architecture that\nunifies meta-learning and reinforcement learning (RL) to create a fully\nself-improving trading agent. Starting from a vanilla instruction-tuned LLM,\nthe agent iteratively alternates between three roles-actor, judge, and\nmeta-judge-in a closed-loop architecture. This learning process requires no\nadditional human supervision. It can leverage multimodal market inputs and\ninternal preference feedback. The agent in the system continuously refines both\nthe trading policy and evaluation criteria. Experiments across diverse market\nregimes demonstrate that Meta-RL-Crypto shows good performance on the technical\nindicators of the real market and outperforming other LLM-based baselines.", "AI": {"tldr": "Meta-RL-Crypto\u662f\u4e00\u4e2a\u7ed3\u5408\u4e86\u5143\u5b66\u4e60\u548c\u5f3a\u5316\u5b66\u4e60\u7684\u4ea4\u6613\u673a\u5668\u4eba\uff0c\u5b83\u80fd\u81ea\u6211\u6539\u8fdb\uff0c\u65e0\u9700\u4eba\u7c7b\u76d1\u7763\uff0c\u5e76\u5728\u771f\u5b9e\u5e02\u573a\u6570\u636e\u4e0a\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6\u57fa\u4e8eLLM\u7684\u57fa\u7ebf\u3002", "motivation": "\u9884\u6d4b\u52a0\u5bc6\u8d27\u5e01\u56de\u62a5\u975e\u5e38\u56f0\u96be\uff0c\u56e0\u4e3a\u4ef7\u683c\u53d7\u94fe\u4e0a\u6d3b\u52a8\u3001\u65b0\u95fb\u548c\u793e\u4ea4\u60c5\u7eea\u7b49\u591a\u79cd\u56e0\u7d20\u5f71\u54cd\uff0c\u4e14\u5e26\u6709\u6807\u7b7e\u7684\u8bad\u7ec3\u6570\u636e\u7a00\u7f3a\u4e14\u6602\u8d35\u3002", "method": "Meta-RL-Crypto\u91c7\u7528\u4e00\u4e2a\u57fa\u4e8eTransformer\u7684\u7edf\u4e00\u67b6\u6784\uff0c\u7ed3\u5408\u4e86\u5143\u5b66\u4e60\u548c\u5f3a\u5316\u5b66\u4e60\u3002\u8be5\u67b6\u6784\u4e2d\u7684\u667a\u80fd\u4f53\u5728\u4e09\u4e2a\u89d2\u8272\uff08actor\u3001judge\u3001meta-judge\uff09\u4e4b\u95f4\u8fed\u4ee3\u5207\u6362\uff0c\u5f62\u6210\u4e00\u4e2a\u95ed\u73af\u7cfb\u7edf\uff0c\u5229\u7528\u591a\u6a21\u6001\u5e02\u573a\u8f93\u5165\u548c\u5185\u90e8\u504f\u597d\u53cd\u9988\u8fdb\u884c\u81ea\u6211\u6539\u8fdb\uff0c\u4e0d\u65ad\u4f18\u5316\u4ea4\u6613\u7b56\u7565\u548c\u8bc4\u4f30\u6807\u51c6\u3002", "result": "\u5728\u4e0d\u540c\u7684\u5e02\u573a\u6761\u4ef6\u4e0b\uff0cMeta-RL-Crypto\u5728\u771f\u5b9e\u5e02\u573a\u6280\u672f\u6307\u6807\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u5e76\u4e14\u4f18\u4e8e\u5176\u4ed6\u57fa\u4e8eLLM\u7684\u57fa\u7ebf\u3002", "conclusion": "Meta-RL-Crypto\u901a\u8fc7\u4e00\u4e2a\u5b8c\u5168\u81ea\u6211\u7684\u6539\u8fdb\u8fc7\u7a0b\uff0c\u6210\u529f\u5730\u89e3\u51b3\u4e86\u52a0\u5bc6\u8d27\u5e01\u4ea4\u6613\u4e2d\u7684\u6311\u6218\uff0c\u5e76\u5728\u771f\u5b9e\u5e02\u573a\u6570\u636e\u4e0a\u5c55\u793a\u4e86\u4f18\u8d8a\u7684\u6027\u80fd\u3002"}}
{"id": "2509.10450", "categories": ["cs.DS", "math.AG", "quant-ph", "14Q15, 15A69"], "pdf": "https://arxiv.org/pdf/2509.10450", "abs": "https://arxiv.org/abs/2509.10450", "authors": ["Alexander Taveira Blomenhofer", "Benjamin Lovitz"], "title": "A linear-time algorithm for Chow decompositions", "comment": "21 pages. Comments welcome", "summary": "We propose a linear-time algorithm to compute low-rank Chow decompositions.\nOur algorithm can decompose concise symmetric 3-tensors in n variables of Chow\nrank n/3. The algorithm is pencil based, hence it relies on generalized\neigenvalue computations. We also develop sub-quadratic time algorithms for\nhigher order Chow decompositions, and Chow decompositions of 3-tensors into\nproducts of linear forms which do not lie on the generic orbit. In particular,\nwe obtain a sub-quadratic-time algorithm for decomposing a symmetric 3-tensor\ninto a linear combination of W-tensors.", "AI": {"tldr": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u7ebf\u6027\u65f6\u95f4\u7b97\u6cd5\u6765\u8ba1\u7b97\u4f4e\u79e9Chow\u5206\u89e3\uff0c\u8be5\u7b97\u6cd5\u53ef\u4ee5\u5206\u89e3Chow\u79e9\u4e3an/3\u7684n\u53d8\u91cf\u7684\u7b80\u6d01\u5bf9\u79f03\u9636\u5f20\u91cf\uff0c\u5e76\u4f9d\u8d56\u4e8e\u5e7f\u4e49\u7279\u5f81\u503c\u8ba1\u7b97\u3002\u6211\u4eec\u8fd8\u5f00\u53d1\u4e86\u7528\u4e8e\u66f4\u9ad8\u9636Chow\u5206\u89e3\u548c\u975e\u901a\u7528\u8f68\u9053Chow\u5206\u89e3\u7684\u4e9a\u4e8c\u6b21\u65f6\u95f4\u7b97\u6cd5\uff0c\u7279\u522b\u662f\u83b7\u5f97\u4e86\u5c06\u5bf9\u79f03\u9636\u5f20\u91cf\u5206\u89e3\u4e3aW-\u5f20\u91cf\u7ebf\u6027\u7ec4\u5408\u7684\u4e9a\u4e8c\u6b21\u65f6\u95f4\u7b97\u6cd5\u3002", "motivation": "\u672c\u6587\u7684\u52a8\u673a\u662f\u5f00\u53d1\u8ba1\u7b97\u4f4e\u79e9Chow\u5206\u89e3\u7684\u9ad8\u6548\u7b97\u6cd5\uff0c\u7279\u522b\u662f\u9488\u5bf9\u7b80\u6d01\u5bf9\u79f03\u9636\u5f20\u91cf\uff0c\u5e76\u4e3a\u66f4\u9ad8\u9636\u548c\u975e\u901a\u7528\u8f68\u9053\u5206\u89e3\u63d0\u4f9b\u4e9a\u4e8c\u6b21\u65f6\u95f4\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u662f\u57fa\u4e8e\u4e00\u4e2a\u7ebf\u6027\u65f6\u95f4\u7b97\u6cd5\uff0c\u5229\u7528\u5e7f\u4e49\u7279\u5f81\u503c\u8ba1\u7b97\u6765\u6267\u884c\u4f4e\u79e9Chow\u5206\u89e3\u3002\u6b64\u5916\uff0c\u8fd8\u5f00\u53d1\u4e86\u7528\u4e8e\u66f4\u9ad8\u9636Chow\u5206\u89e3\u548c\u7279\u5b9a\u7c7b\u578b\uff08\u5982W-\u5f20\u91cf\uff09\u5206\u89e3\u7684\u4e9a\u4e8c\u6b21\u65f6\u95f4\u7b97\u6cd5\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u80fd\u591f\u5728\u7ebf\u6027\u65f6\u95f4\u5185\u8ba1\u7b97\u4f4e\u79e9Chow\u5206\u89e3\uff0c\u5e76\u80fd\u5206\u89e3Chow\u79e9\u4e3an/3\u7684\u7b80\u6d01\u5bf9\u79f03\u9636\u5f20\u91cf\u3002\u6b64\u5916\uff0c\u8fd8\u5b9e\u73b0\u4e86\u7528\u4e8e\u66f4\u9ad8\u9636\u548c\u975e\u901a\u7528\u8f68\u9053\u5206\u89e3\u7684\u4e9a\u4e8c\u6b21\u65f6\u95f4\u7b97\u6cd5\uff0c\u5305\u62ec\u5c06\u5bf9\u79f03\u9636\u5f20\u91cf\u5206\u89e3\u4e3aW-\u5f20\u91cf\u7ebf\u6027\u7ec4\u5408\u7684\u7b97\u6cd5\u3002", "conclusion": "\u672c\u6587\u6210\u529f\u5730\u63d0\u51fa\u4e86\u4e00\u79cd\u8ba1\u7b97\u4f4e\u79e9Chow\u5206\u89e3\u7684\u7ebf\u6027\u65f6\u95f4\u7b97\u6cd5\uff0c\u5e76\u4e3a\u66f4\u590d\u6742\u7684\u5206\u89e3\u95ee\u9898\u5f00\u53d1\u4e86\u4e9a\u4e8c\u6b21\u65f6\u95f4\u7b97\u6cd5\uff0c\u5c55\u793a\u4e86\u5728\u5f20\u91cf\u5206\u89e3\u9886\u57df\u7684\u663e\u8457\u8fdb\u5c55\u3002"}}
{"id": "2509.09790", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09790", "abs": "https://arxiv.org/abs/2509.09790", "authors": ["Yuxuan Li", "Victor Zhong"], "title": "How well can LLMs provide planning feedback in grounded environments?", "comment": null, "summary": "Learning to plan in grounded environments typically requires carefully\ndesigned reward functions or high-quality annotated demonstrations. Recent\nworks show that pretrained foundation models, such as large language models\n(LLMs) and vision language models (VLMs), capture background knowledge helpful\nfor planning, which reduces the amount of reward design and demonstrations\nneeded for policy learning. We evaluate how well LLMs and VLMs provide feedback\nacross symbolic, language, and continuous control environments. We consider\nprominent types of feedback for planning including binary feedback, preference\nfeedback, action advising, goal advising, and delta action feedback. We also\nconsider inference methods that impact feedback performance, including\nin-context learning, chain-of-thought, and access to environment dynamics. We\nfind that foundation models can provide diverse high-quality feedback across\ndomains. Moreover, larger and reasoning models consistently provide more\naccurate feedback, exhibit less bias, and benefit more from enhanced inference\nmethods. Finally, feedback quality degrades for environments with complex\ndynamics or continuous state spaces and action spaces.", "AI": {"tldr": "\u57fa\u7840\u6a21\u578b\uff08LLMs\u548cVLMs\uff09\u53ef\u4ee5\u4e3a\u89c4\u5212\u4efb\u52a1\u63d0\u4f9b\u9ad8\u8d28\u91cf\u7684\u53cd\u9988\uff0c\u5c24\u5176\u662f\u5728\u7b26\u53f7\u548c\u8bed\u8a00\u73af\u5883\u4e2d\u3002\u66f4\u5927\u7684\u6a21\u578b\u548c\u66f4\u5f3a\u7684\u63a8\u7406\u80fd\u529b\u53ef\u4ee5\u63d0\u9ad8\u53cd\u9988\u7684\u51c6\u786e\u6027\u5e76\u51cf\u5c11\u504f\u5dee\u3002\u7136\u800c\uff0c\u5728\u5177\u6709\u590d\u6742\u52a8\u6001\u6216\u8fde\u7eed\u72b6\u6001/\u52a8\u4f5c\u7a7a\u95f4\u7684\u590d\u6742\u73af\u5883\u4e2d\uff0c\u53cd\u9988\u8d28\u91cf\u4f1a\u4e0b\u964d\u3002", "motivation": "\u9700\u8981\u8bc4\u4f30\u9884\u8bad\u7ec3\u7684\u57fa\u7840\u6a21\u578b\uff08LLMs\u548cVLMs\uff09\u5728\u591a\u5927\u7a0b\u5ea6\u4e0a\u53ef\u4ee5\u63d0\u4f9b\u6709\u7528\u7684\u53cd\u9988\uff0c\u4ee5\u8f85\u52a9\u89c4\u5212\u4efb\u52a1\uff0c\u4ece\u800c\u51cf\u5c11\u5bf9\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u5956\u52b1\u51fd\u6570\u6216\u9ad8\u8d28\u91cf\u6f14\u793a\u7684\u9700\u6c42\u3002", "method": "\u8bc4\u4f30LLMs\u548cVLMs\u5728\u4e0d\u540c\u73af\u5883\uff08\u7b26\u53f7\u3001\u8bed\u8a00\u3001\u8fde\u7eed\u63a7\u5236\uff09\u548c\u4e0d\u540c\u53cd\u9988\u7c7b\u578b\uff08\u4e8c\u5143\u53cd\u9988\u3001\u504f\u597d\u53cd\u9988\u3001\u52a8\u4f5c\u5efa\u8bae\u3001\u76ee\u6807\u5efa\u8bae\u3001\u52a8\u4f5c\u589e\u91cf\u53cd\u9988\uff09\u4e0b\u7684\u8868\u73b0\u3002\u540c\u65f6\uff0c\u8fd8\u8003\u8651\u4e86\u4e0d\u540c\u63a8\u7406\u65b9\u6cd5\uff08\u4e0a\u4e0b\u6587\u5b66\u4e60\u3001\u601d\u7ef4\u94fe\u3001\u73af\u5883\u52a8\u6001\u8bbf\u95ee\uff09\u5bf9\u53cd\u9988\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u57fa\u7840\u6a21\u578b\u53ef\u4ee5\u63d0\u4f9b\u9ad8\u8d28\u91cf\u4e14\u591a\u6837\u5316\u7684\u53cd\u9988\u3002\u6a21\u578b\u8d8a\u5927\u3001\u63a8\u7406\u80fd\u529b\u8d8a\u5f3a\uff0c\u53cd\u9988\u8d8a\u51c6\u786e\uff0c\u504f\u5dee\u8d8a\u5c0f\uff0c\u5e76\u4e14\u4ece\u589e\u5f3a\u7684\u63a8\u7406\u65b9\u6cd5\u4e2d\u83b7\u76ca\u8d8a\u591a\u3002\u7136\u800c\uff0c\u5728\u590d\u6742\u52a8\u6001\u6216\u8fde\u7eed\u72b6\u6001/\u52a8\u4f5c\u7a7a\u95f4\u7684\u590d\u6742\u73af\u5883\u4e2d\uff0c\u53cd\u9988\u8d28\u91cf\u4f1a\u4e0b\u964d\u3002", "conclusion": "\u57fa\u7840\u6a21\u578b\u5728\u63d0\u4f9b\u89c4\u5212\u53cd\u9988\u65b9\u9762\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u5176\u6709\u6548\u6027\u53d7\u5230\u73af\u5883\u590d\u6742\u6027\u548c\u6a21\u578b\u80fd\u529b\u7684\u9650\u5236\u3002\u672a\u6765\u7684\u7814\u7a76\u5e94\u5173\u6ce8\u5982\u4f55\u514b\u670d\u8fd9\u4e9b\u9650\u5236\uff0c\u4ee5\u5728\u66f4\u5e7f\u6cdb\u7684\u5e94\u7528\u573a\u666f\u4e2d\u5229\u7528\u57fa\u7840\u6a21\u578b\u7684\u53cd\u9988\u80fd\u529b\u3002"}}
{"id": "2509.10372", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2509.10372", "abs": "https://arxiv.org/abs/2509.10372", "authors": ["Huizheng Wang", "Zichuan Wang", "Zhiheng Yue", "Yousheng Long", "Taiquan Wei", "Jianxun Yang", "Yang Wang", "Chao Li", "Shaojun Wei", "Yang Hu", "Shouyi Yin"], "title": "MCBP: A Memory-Compute Efficient LLM Inference Accelerator Leveraging Bit-Slice-enabled Sparsity and Repetitiveness", "comment": null, "summary": "Large language models (LLMs) face significant inference latency due to\ninefficiencies in GEMM operations, weight access, and KV cache access,\nespecially in real-time scenarios. This highlights the need for a versatile\ncompute-memory efficient accelerator. Unfortunately, existing Transformer\naccelerators struggle to address both aspects simultaneously, as they focus on\nvalue-level processing, missing fine-grained opportunities to optimize\ncomputation and memory collaboratively. This paper introduces MCBP, a\nbit-grained compute-memory efficient algorithm-hardware co-design that\nleverages bit-slice (BS) enabled repetitiveness and sparsity to accelerate LLM\ninference. MCBP features three key innovations: 1) BS-repetitiveness-enabled\ncomputation reduction (BRCR), which eliminates redundant GEMM computations via\nleveraging redundancy hidden among BS vectors; 2) BS-sparsity-enabled two-state\ncoding (BSTC), which reduces weight access via exploiting significant sparsity\nin high-order bit-slice weight; 3) Bit-grained progressive prediction (BGPP),\nwhich reduces KV cache access by leveraging early-termination-based bit-grained\nprediction. These techniques, supported by custom accelerator designs,\neffectively alleviate the burden in GEMM, weight access, and KV cache access.\nExtensive experiments on 26 benchmarks show that MCBP achieves 9.43x speed up\nand 31.1x higher energy efficiency than Nvidia A100 GPU. Compared to SOTA\nTransformer accelerators, MCBP achieves 35x, 5.2x and 3.2x energy saving than\nSpatten, FACT and SOFA, respectively.", "AI": {"tldr": "MCBP\u662f\u4e00\u79cd\u521b\u65b0\u7684\u7b97\u6cd5-\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\uff0c\u901a\u8fc7\u5229\u7528\u4f4d\u5207\u7247\uff08BS\uff09\u7684\u53ef\u91cd\u590d\u6027\u548c\u7a00\u758f\u6027\u6765\u52a0\u901fLLM\u63a8\u7406\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u901f\u5ea6\u548c\u80fd\u6548\u3002", "motivation": "\u73b0\u6709\u7684Transformer\u52a0\u901f\u5668\u5728\u5904\u7406LLM\u63a8\u7406\u65f6\uff0c\u7531\u4e8eGEMM\u64cd\u4f5c\u3001\u6743\u91cd\u8bbf\u95ee\u548cKV\u7f13\u5b58\u8bbf\u95ee\u6548\u7387\u4f4e\u4e0b\uff0c\u5b58\u5728\u663e\u8457\u7684\u5ef6\u8fdf\u95ee\u9898\uff0c\u5e76\u4e14\u96be\u4ee5\u540c\u65f6\u4f18\u5316\u8ba1\u7b97\u548c\u5185\u5b58\u3002", "method": "MCBP\u901a\u8fc7\u4e09\u79cd\u521b\u65b0\u6280\u672f\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff1a1. BS-\u53ef\u91cd\u590d\u6027\u8ba1\u7b97\u7f29\u51cf\uff08BRCR\uff09\uff0c\u6d88\u9664\u5197\u4f59\u7684GEMM\u8ba1\u7b97\uff1b2. BS-\u7a00\u758f\u6027\u4e24\u72b6\u6001\u7f16\u7801\uff08BSTC\uff09\uff0c\u51cf\u5c11\u6743\u91cd\u8bbf\u95ee\uff1b3. \u4f4d\u7c92\u5ea6\u6e10\u8fdb\u9884\u6d4b\uff08BGPP\uff09\uff0c\u51cf\u5c11KV\u7f13\u5b58\u8bbf\u95ee\u3002\u8fd9\u4e9b\u6280\u672f\u7531\u5b9a\u5236\u7684\u52a0\u901f\u5668\u8bbe\u8ba1\u652f\u6301\u3002", "result": "\u572826\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMCBP\u5b9e\u73b0\u4e869.43\u500d\u7684\u901f\u5ea6\u63d0\u5347\u548c31.1\u500d\u7684\u80fd\u6548\u63d0\u5347\uff0c\u4f18\u4e8eNvidia A100 GPU\u3002\u4e0eSOTA Transformer\u52a0\u901f\u5668\u76f8\u6bd4\uff0cMCBP\u5728\u80fd\u6548\u65b9\u9762\u5206\u522b\u9886\u5148Spatten\u3001FACT\u548cSOFA 35\u500d\u30015.2\u500d\u548c3.2\u500d\u3002", "conclusion": "MCBP\u901a\u8fc7\u5176\u521b\u65b0\u7684\u4f4d\u7c92\u5ea6\u8ba1\u7b97-\u5185\u5b58\u534f\u540c\u8bbe\u8ba1\uff0c\u6709\u6548\u5730\u89e3\u51b3\u4e86LLM\u63a8\u7406\u4e2d\u7684\u5ef6\u8fdf\u548c\u80fd\u6548\u74f6\u9888\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2509.09789", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.09789", "abs": "https://arxiv.org/abs/2509.09789", "authors": ["Safa Mohammed Sali", "Hoach The Nguyen", "Ameena Saad Al-Sumaiti"], "title": "High-Gain Voltage-Multiplier Coupled Quadratic Boost Converter: A New Design for Small Scale PV Integration", "comment": null, "summary": "This paper introduces a single-switch high-gain voltage-multiplier coupled\nquadratic boost converter (HGVM-QBC), developed from the conventional quadratic\nboost converter (QBC). The proposed topology is designed to achieve higher\nvoltage gain, lower semiconductor voltage stress, and continuous current\noperation, making it particularly suitable for small-scale photovoltaic (PV)\nsystems. By incorporating a voltage multiplier cell into the QBC, the converter\nsignificantly improves voltage boosting capability while mitigating stress on\nswitching devices. In this configuration, the output voltage is obtained by\ncombining the voltages across multiple output capacitors, thereby enhancing the\noverall voltage level. A detailed comparative study with recently reported\nconverter topologies demonstrates the superior gain and reduced device stress\noffered by the HGVM-QBC. The design is validated through MATLAB/Simulink\nsimulations, which confirm improved performance in terms of gain and voltage\nstress. Furthermore, an experimental prototype achieves an output of 151 Vdc\nfrom a 12 Vdc input at a 55% duty cycle, corresponding to a gain of 12.59.\nThese results establish the HGVM-QBC as an efficient and reliable solution for\nPV applications that demand high voltage output from low input sources.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5355\u5f00\u5173\u9ad8\u589e\u76ca\u7535\u538b\u500d\u589e\u8026\u5408\u4e8c\u6b21\u5347\u538b\u8f6c\u6362\u5668 (HGVM-QBC)\uff0c\u5b83\u6e90\u81ea\u4f20\u7edf\u7684\u4e8c\u6b21\u5347\u538b\u8f6c\u6362\u5668 (QBC)\u3002", "motivation": "HGVM-QBC \u65e8\u5728\u5b9e\u73b0\u66f4\u9ad8\u7684\u7535\u538b\u589e\u76ca\u3001\u964d\u4f4e\u534a\u5bfc\u4f53\u7535\u538b\u5e94\u529b\uff0c\u5e76\u5b9e\u73b0\u8fde\u7eed\u7535\u6d41\u8fd0\u884c\uff0c\u7279\u522b\u9002\u5408\u5c0f\u578b\u5149\u4f0f (PV) \u7cfb\u7edf\u3002", "method": "\u901a\u8fc7\u5c06\u7535\u538b\u500d\u589e\u5355\u5143\u96c6\u6210\u5230 QBC \u4e2d\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u7535\u538b\u63d0\u5347\u80fd\u529b\uff0c\u5e76\u964d\u4f4e\u4e86\u5f00\u5173\u5668\u4ef6\u7684\u5e94\u529b\u3002\u8f93\u51fa\u7535\u538b\u901a\u8fc7\u7ec4\u5408\u591a\u4e2a\u8f93\u51fa\u7535\u5bb9\u5668\u4e0a\u7684\u7535\u538b\u6765\u83b7\u5f97\u3002", "result": "\u4e0e\u6700\u8fd1\u62a5\u9053\u7684\u8f6c\u6362\u5668\u62d3\u6251\u8fdb\u884c\u4e86\u8be6\u7ec6\u7684\u6bd4\u8f83\u7814\u7a76\uff0c\u8bc1\u660e\u4e86 HGVM-QBC \u5728\u589e\u76ca\u548c\u5668\u4ef6\u5e94\u529b\u65b9\u9762\u7684\u4f18\u8d8a\u6027\u3002MATLAB/Simulink \u4eff\u771f\u548c\u5b9e\u9a8c\u539f\u578b\uff08\u5728 12 Vdc \u8f93\u5165\u548c 55% \u5360\u7a7a\u6bd4\u4e0b\u5b9e\u73b0 151 Vdc \u8f93\u51fa\uff0c\u589e\u76ca\u4e3a 12.59\uff09\u9a8c\u8bc1\u4e86\u5176\u6027\u80fd\u3002", "conclusion": "HGVM-QBC \u88ab\u8bc1\u660e\u662f\u6ee1\u8db3\u4f4e\u8f93\u5165\u6e90\u9ad8\u7535\u538b\u8f93\u51fa\u8981\u6c42\u7684\u5149\u4f0f\u5e94\u7528\u7684\u9ad8\u6548\u53ef\u9760\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.10371", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10371", "abs": "https://arxiv.org/abs/2509.10371", "authors": ["Seokjin Go", "Joongun Park", "Spandan More", "Hanjiang Wu", "Irene Wang", "Aaron Jezghani", "Tushar Krishna", "Divya Mahajan"], "title": "Characterizing the Efficiency of Distributed Training: A Power, Performance, and Thermal Perspective", "comment": null, "summary": "The rapid scaling of Large Language Models (LLMs) has pushed training\nworkloads far beyond the limits of single-node analysis, demanding a deeper\nunderstanding of how these models behave across large-scale, multi-GPU systems.\nIn this paper, we present a comprehensive characterization of LLM training\nacross diverse real-world workloads and hardware platforms, including NVIDIA\nH100/H200 and AMD MI250 GPUs. We analyze dense and sparse models under various\nparallelism strategies -- tensor, pipeline, data, and expert -- and evaluate\ntheir effects on hardware utilization, power consumption, and thermal behavior.\nWe further evaluate the effectiveness of optimizations such as activation\nrecomputation and compute-communication overlap. Our findings show that\nperformance is not determined solely by scaling hardware capacity. Scale-up\nsystems with fewer, higher-memory GPUs can outperform scale-out systems in\ncommunication-bound regimes, but only under carefully tuned configurations; in\nother cases, scale-out deployments achieve superior throughput. We also show\nthat certain parallelism combinations, such as tensor with pipeline, lead to\nbandwidth underutilization due to inefficient data chunking, while increasing\nmicrobatch sizes beyond a certain point induces bursty execution and peak power\nexcursions that worsen thermal throttling. These insights reveal how training\nperformance is shaped by complex interactions between hardware, system\ntopology, and model execution. We conclude by offering recommendations for\nsystem and hardware design to improve the scalability and reliability of future\nLLM systems and workloads. The source code of this project is available at\nhttps://github.com/sitar-lab/CharLLM-PPT.", "AI": {"tldr": "LLM\u8bad\u7ec3\u5728\u591aGPU\u7cfb\u7edf\u4e2d\u7684\u8868\u73b0\uff0c\u5f3a\u8c03\u4e86\u786c\u4ef6\u3001\u7cfb\u7edf\u62d3\u6251\u548c\u6a21\u578b\u6267\u884c\u4e4b\u95f4\u7684\u590d\u6742\u4ea4\u4e92\u4f5c\u7528\uff0c\u5e76\u4e3a\u672a\u6765\u7684LLM\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u5efa\u8bae\u3002", "motivation": "\u968f\u7740LLM\u89c4\u6a21\u7684\u5feb\u901f\u6269\u5927\uff0c\u8bad\u7ec3\u5de5\u4f5c\u8d1f\u8f7d\u5df2\u8fdc\u8d85\u5355\u8282\u70b9\u5206\u6790\u80fd\u529b\uff0c\u56e0\u6b64\u9700\u8981\u6df1\u5165\u7406\u89e3LLM\u5728\u5927\u578b\u591aGPU\u7cfb\u7edf\u4e2d\u7684\u884c\u4e3a\u3002", "method": "\u5bf9\u4e0d\u540c\u771f\u5b9e\u4e16\u754c\u5de5\u4f5c\u8d1f\u8f7d\u548c\u786c\u4ef6\u5e73\u53f0\uff08\u5305\u62ecNVIDIA H100/H200\u548cAMD MI250 GPU\uff09\u4e0a\u7684LLM\u8bad\u7ec3\u8fdb\u884c\u4e86\u5168\u9762\u8868\u5f81\u3002\u5206\u6790\u4e86\u4e0d\u540c\u5e76\u884c\u7b56\u7565\uff08\u5f20\u91cf\u3001\u6d41\u6c34\u7ebf\u3001\u6570\u636e\u3001\u4e13\u5bb6\uff09\u4e0b\u7a20\u5bc6\u548c\u7a00\u758f\u6a21\u578b\u7684\u8868\u73b0\uff0c\u5e76\u8bc4\u4f30\u4e86\u6fc0\u6d3b\u91cd\u8ba1\u7b97\u548c\u8ba1\u7b97-\u901a\u4fe1\u91cd\u53e0\u7b49\u4f18\u5316\u63aa\u65bd\u7684\u6548\u679c\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u6027\u80fd\u5e76\u975e\u4ec5\u7531\u786c\u4ef6\u5bb9\u91cf\u51b3\u5b9a\u3002\u5728\u901a\u4fe1\u53d7\u9650\u7684\u60c5\u51b5\u4e0b\uff0c\u914d\u5907\u8f83\u5c11\u9ad8\u5185\u5b58GPU\u7684Scale-up\u7cfb\u7edf\u5728\u7cbe\u5fc3\u8c03\u4f18\u540e\uff0c\u53ef\u80fd\u4f18\u4e8eScale-out\u7cfb\u7edf\uff1b\u4f46\u5728\u5176\u4ed6\u60c5\u51b5\u4e0b\uff0cScale-out\u90e8\u7f72\u53ef\u5b9e\u73b0\u66f4\u9ad8\u7684\u541e\u5410\u91cf\u3002\u6b64\u5916\uff0c\u5f20\u91cf\u4e0e\u6d41\u6c34\u7ebf\u5e76\u884c\u7b49\u7ec4\u5408\u53ef\u80fd\u56e0\u6570\u636e\u5206\u5757\u6548\u7387\u4f4e\u4e0b\u800c\u5bfc\u81f4\u5e26\u5bbd\u5229\u7528\u4e0d\u8db3\uff1b\u5fae\u6279\u6b21\u5927\u5c0f\u589e\u52a0\u5230\u4e00\u5b9a\u7a0b\u5ea6\u4f1a\u5f15\u8d77\u6267\u884c\u7a81\u53d1\u548c\u5cf0\u503c\u529f\u8017\uff0c\u52a0\u5267\u70ed\u8282\u6d41\u3002", "conclusion": "LLM\u8bad\u7ec3\u6027\u80fd\u53d7\u5230\u786c\u4ef6\u3001\u7cfb\u7edf\u62d3\u6251\u548c\u6a21\u578b\u6267\u884c\u4e4b\u95f4\u590d\u6742\u4ea4\u4e92\u4f5c\u7528\u7684\u5f71\u54cd\u3002\u7814\u7a76\u4e3a\u6539\u8fdb\u672a\u6765LLM\u7cfb\u7edf\u548c\u5de5\u4f5c\u8d1f\u8f7d\u7684\u53ef\u6269\u5c55\u6027\u53ca\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u7cfb\u7edf\u548c\u786c\u4ef6\u8bbe\u8ba1\u7684\u5efa\u8bae\u3002"}}
{"id": "2509.09722", "categories": ["cs.CV", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.09722", "abs": "https://arxiv.org/abs/2509.09722", "authors": ["Taylor Archibald", "Tony Martinez"], "title": "Improving MLLM Historical Record Extraction with Test-Time Image", "comment": null, "summary": "We present a novel ensemble framework that stabilizes LLM based text\nextraction from noisy historical documents. We transcribe multiple augmented\nvariants of each image with Gemini 2.0 Flash and fuse these outputs with a\ncustom Needleman Wunsch style aligner that yields both a consensus\ntranscription and a confidence score. We present a new dataset of 622\nPennsylvania death records, and demonstrate our method improves transcription\naccuracy by 4 percentage points relative to a single shot baseline. We find\nthat padding and blurring are the most useful for improving accuracy, while\ngrid warp perturbations are best for separating high and low confidence cases.\nThe approach is simple, scalable, and immediately deployable to other document\ncollections and transcription models.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u96c6\u6210\u6846\u67b6\uff0c\u7528\u4e8e\u7a33\u5b9a\u57fa\u4e8eLLM\u7684\u5386\u53f2\u6587\u732e\u6587\u672c\u63d0\u53d6\uff0c\u4f7f\u7528Gemini 2.0 Flash\u548cNeedleman-Wunsch\u98ce\u683c\u7684\u6bd4\u5bf9\u5668\uff0c\u5728622\u6761\u5bbe\u5915\u6cd5\u5c3c\u4e9a\u5dde\u6b7b\u4ea1\u8bb0\u5f55\u6570\u636e\u96c6\u4e0a\uff0c\u5c06\u51c6\u786e\u6027\u63d0\u9ad8\u4e864\u4e2a\u767e\u5206\u70b9\uff0c\u5e76\u786e\u5b9a\u4e86\u6700\u6709\u7528\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u3002", "motivation": "\u9488\u5bf9\u5386\u53f2\u6587\u732e\u4e2d\u7684\u566a\u58f0\u95ee\u9898\uff0c\u63d0\u9ad8\u57fa\u4e8eLLM\u7684\u6587\u672c\u63d0\u53d6\u7684\u7a33\u5b9a\u6027\u4e0e\u51c6\u786e\u6027\u3002", "method": "\u4f7f\u7528Gemini 2.0 Flash\u8f6c\u5f55\u56fe\u50cf\u7684\u591a\u79cd\u589e\u5f3a\u53d8\u4f53\uff0c\u5e76\u4f7f\u7528\u81ea\u5b9a\u4e49\u7684Needleman-Wunsch\u98ce\u683c\u7684\u6bd4\u5bf9\u5668\u878d\u5408\u8fd9\u4e9b\u8f93\u51fa\u6765\u83b7\u5f97\u5171\u8bc6\u8f6c\u5f55\u548c\u7f6e\u4fe1\u5ea6\u5f97\u5206\u3002", "result": "\u5728622\u6761\u5bbe\u5915\u6cd5\u5c3c\u4e9a\u5dde\u6b7b\u4ea1\u8bb0\u5f55\u6570\u636e\u96c6\u4e0a\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u6bd4\u5355\u6b21\u8fd0\u884c\u57fa\u7ebf\u63d0\u9ad8\u4e864\u4e2a\u767e\u5206\u70b9\u7684\u8f6c\u5f55\u51c6\u786e\u6027\u3002\u586b\u5145\u548c\u6a21\u7cca\u662f\u6700\u6709\u6548\u7684\u63d0\u9ad8\u51c6\u786e\u6027\u7684\u65b9\u6cd5\uff0c\u800c\u7f51\u683c\u53d8\u5f62\u6700\u9002\u5408\u533a\u5206\u9ad8\u7f6e\u4fe1\u5ea6\u548c\u4f4e\u7f6e\u4fe1\u5ea6\u7684\u60c5\u51b5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u7b80\u5355\u3001\u53ef\u6269\u5c55\uff0c\u5e76\u53ef\u7acb\u5373\u90e8\u7f72\u5230\u5176\u4ed6\u6587\u6863\u96c6\u5408\u548c\u8f6c\u5f55\u6a21\u578b\u4e2d\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5386\u53f2\u6587\u732e\u7684\u6587\u672c\u63d0\u53d6\u95ee\u9898\u3002"}}
{"id": "2509.09901", "categories": ["cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2509.09901", "abs": "https://arxiv.org/abs/2509.09901", "authors": ["N. L. Samuelson", "L. A. Cohen", "W. Wang", "S. Blanch", "T. Taniguchi", "K. Watanabe", "M. P. Zaletel", "A. F. Young"], "title": "Hard and soft phase slips in a Fabry-P\u00e9rot quantum Hall interferometer", "comment": "Main Text: 6 pages, 4 figures Supplement: 6 pages, 3 figures", "summary": "Quantum Hall Fabry-P\\'erot interferometers are sensitive to the properties of\nbulk quasiparticles enclosed by the interferometer loop, with the interference\nphase containing information about both the quasiparticle statistics and the\nCoulomb-mediated bulk-edge coupling. Previous studies have explored the role of\nthe bulk-edge coupling in an equilibrium picture where quasiparticles enter and\nexit the interferometer rapidly compared to the timescale over which the\ninterferometer phase is measured. Here, we present data from a monolayer\ngraphene quantum Hall interferometer in the integer quantum Hall regime at $\\nu\n= -1$ and $\\nu = -2$. Quantum interference shows phase slips associated with\nthe entrance of quasiparticles to the interferometer bulk. Tracing the\ndependence of these phase slips on the magnetic field, we show that the\nequilibration time can become as long as several minutes. We further use our\nmulti-gated geometry to identify two classes of phase slips. The first is\nassociated with the addition of a quasiparticle to a bulk `puddle' of\nquasiparticles uniformly coupled to the entire chiral edge state, while the\nsecond is associated with the addition of a quasiparticle trapped by a defect\nsite that couples predominantly to the closest portion of the edge.", "AI": {"tldr": "\u91cf\u5b50\u970d\u5c14\u6548\u5e94\u6cd5\u5e03\u91cc-\u73c0\u7f57\u5e72\u6d89\u4eea\u7684\u5e72\u6d89\u76f8\u4f4d\u5305\u542b\u4e86\u51c6\u7c92\u5b50\u7684\u7edf\u8ba1\u6027\u8d28\u548c\u4f53\u8fb9\u8026\u5408\u7684\u4fe1\u606f\u3002\u672c\u7814\u7a76\u5728\u4e0d\u540c\u91cf\u5b50\u970d\u5c14\u72b6\u6001\u4e0b\uff08$\nu = -1, -2$\uff09\u7684\u77f3\u58a8\u70ef\u5e72\u6d89\u4eea\u4e2d\uff0c\u89c2\u5bdf\u5230\u4e86\u4e0e\u51c6\u7c92\u5b50\u8fdb\u5165\u5e72\u6d89\u4eea\u4f53\u76f8\u76f8\u5173\u7684\u76f8\u4f4d\u6ed1\u79fb\uff0c\u5e76\u8868\u660e\u51c6\u7c92\u5b50\u7684\u5e73\u8861\u65f6\u95f4\u53ef\u8fbe\u51e0\u5206\u949f\u3002\u7814\u7a76\u8fd8\u533a\u5206\u4e86\u4e24\u79cd\u7c7b\u578b\u7684\u76f8\u4f4d\u6ed1\u79fb\uff1a\u4e00\u79cd\u4e0e\u5747\u5300\u8026\u5408\u5230\u6574\u4e2a\u8fb9\u7f18\u6001\u7684\u4f53\u201c\u6c34\u5751\u201d\u6709\u5173\uff0c\u53e6\u4e00\u79cd\u4e0e\u88ab\u4e3b\u8981\u8026\u5408\u5230\u6700\u8fd1\u8fb9\u7f18\u90e8\u5206\u7684\u7f3a\u9677\u4f4d\u70b9\u6355\u83b7\u7684\u51c6\u7c92\u5b50\u6709\u5173\u3002", "motivation": "\u7814\u7a76\u91cf\u5b50\u970d\u5c14\u6cd5\u5e03\u91cc-\u73c0\u7f57\u5e72\u6d89\u4eea\u5bf9\u4f53\u51c6\u7c92\u5b50\u7684\u654f\u611f\u6027\uff0c\u7279\u522b\u662f\u4f53\u8fb9\u8026\u5408\u5728\u975e\u5e73\u8861\u6761\u4ef6\u4e0b\u7684\u4f5c\u7528\u3002", "method": "\u5728\u77f3\u58a8\u70ef\u91cf\u5b50\u970d\u5c14\u5e72\u6d89\u4eea\u4e2d\uff0c\u6d4b\u91cf$\nu = -1$\u548c$\nu = -2$\u72b6\u6001\u4e0b\u7684\u91cf\u5b50\u5e72\u6d89\uff0c\u89c2\u5bdf\u76f8\u4f4d\u6ed1\u79fb\uff0c\u5e76\u5206\u6790\u5176\u5bf9\u78c1\u573a\u548c\u51e0\u4f55\u7ed3\u6784\u7684\u4f9d\u8d56\u6027\u3002", "result": "\u89c2\u5bdf\u5230\u4e0e\u51c6\u7c92\u5b50\u8fdb\u5165\u5e72\u6d89\u4eea\u4f53\u76f8\u76f8\u5173\u7684\u76f8\u4f4d\u6ed1\u79fb\uff0c\u5e73\u8861\u65f6\u95f4\u53ef\u8fbe\u6570\u5206\u949f\u3002\u533a\u5206\u51fa\u4e24\u79cd\u7c7b\u578b\u7684\u76f8\u4f4d\u6ed1\u79fb\uff0c\u5206\u522b\u4e0e\u4f53\u201c\u6c34\u5751\u201d\u548c\u7f3a\u9677\u4f4d\u70b9\u4e2d\u7684\u51c6\u7c92\u5b50\u6709\u5173\u3002", "conclusion": "\u91cf\u5b50\u970d\u5c14\u6cd5\u5e03\u91cc-\u73c0\u7f57\u5e72\u6d89\u4eea\u80fd\u591f\u63a2\u6d4b\u4f53\u51c6\u7c92\u5b50\u7684\u6027\u8d28\uff0c\u5373\u4f7f\u5728\u975e\u5e73\u8861\u6761\u4ef6\u4e0b\u4e5f\u662f\u5982\u6b64\u3002\u4f53\u8fb9\u8026\u5408\u7684\u65f6\u95f4\u5c3a\u5ea6\u6bd4\u4e4b\u524d\u8ba4\u4e3a\u7684\u8981\u957f\uff0c\u5e76\u4e14\u5b58\u5728\u4e0d\u540c\u7c7b\u578b\u7684\u51c6\u7c92\u5b50\u8f93\u8fd0\u673a\u5236\u3002"}}
{"id": "2509.09889", "categories": ["cs.RO", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.09889", "abs": "https://arxiv.org/abs/2509.09889", "authors": ["Giulia Botta", "Marco Botta", "Cristina Gena", "Alessandro Mazzei", "Massimo Donini", "Alberto Lillo"], "title": "Using the Pepper Robot to Support Sign Language Communication", "comment": "paper presented at ICSR2025", "summary": "Social robots are increasingly experimented in public and assistive settings,\nbut their accessibility for Deaf users remains quite underexplored. Italian\nSign Language (LIS) is a fully-fledged natural language that relies on complex\nmanual and non-manual components. Enabling robots to communicate using LIS\ncould foster more inclusive human robot interaction, especially in social\nenvironments such as hospitals, airports, or educational settings. This study\ninvestigates whether a commercial social robot, Pepper, can produce\nintelligible LIS signs and short signed LIS sentences. With the help of a Deaf\nstudent and his interpreter, an expert in LIS, we co-designed and implemented\n52 LIS signs on Pepper using either manual animation techniques or a MATLAB\nbased inverse kinematics solver. We conducted a exploratory user study\ninvolving 12 participants proficient in LIS, both Deaf and hearing.\nParticipants completed a questionnaire featuring 15 single-choice video-based\nsign recognition tasks and 2 open-ended questions on short signed sentences.\nResults shows that the majority of isolated signs were recognized correctly,\nalthough full sentence recognition was significantly lower due to Pepper's\nlimited articulation and temporal constraints. Our findings demonstrate that\neven commercially available social robots like Pepper can perform a subset of\nLIS signs intelligibly, offering some opportunities for a more inclusive\ninteraction design. Future developments should address multi-modal enhancements\n(e.g., screen-based support or expressive avatars) and involve Deaf users in\nparticipatory design to refine robot expressivity and usability.", "AI": {"tldr": "\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5546\u7528\u793e\u4ea4\u673a\u5668\u4ebaPepper\u5728\u610f\u5927\u5229\u624b\u8bed\uff08LIS\uff09\u65b9\u9762\u7684\u80fd\u529b\uff0c\u5e76\u8bc4\u4f30\u5176\u5728\u516c\u5171\u548c\u8f85\u52a9\u573a\u666f\u4e0b\u7684\u5305\u5bb9\u6027\u3002", "motivation": "\u76ee\u524d\u5bf9\u793e\u4ea4\u673a\u5668\u4eba\u5728\u516c\u5171\u548c\u8f85\u52a9\u73af\u5883\u4e2d\u7684\u5e94\u7528\u7814\u7a76\u8f83\u591a\uff0c\u4f46\u5bf9\u670d\u52a1\u4e8e\u804b\u54d1\u4eba\u7fa4\u7684\u673a\u5668\u4eba\u7814\u7a76\u8f83\u5c11\u3002\u610f\u5927\u5229\u624b\u8bed\uff08LIS\uff09\u662f\u4e00\u79cd\u5b8c\u6574\u7684\u81ea\u7136\u8bed\u8a00\uff0c\u5177\u6709\u590d\u6742\u7684\u89e6\u89c9\u548c\u975e\u89e6\u89c9\u6210\u5206\u3002\u8ba9\u673a\u5668\u4eba\u80fd\u591f\u4f7f\u7528LIS\u8fdb\u884c\u4ea4\u6d41\uff0c\u53ef\u4ee5\u4fc3\u8fdb\u4eba\u673a\u4ea4\u4e92\u7684\u5305\u5bb9\u6027\uff0c\u5c24\u5176\u662f\u5728\u533b\u9662\u3001\u673a\u573a\u6216\u6559\u80b2\u7b49\u516c\u5171\u73af\u5883\u4e2d\u3002", "method": "\u7814\u7a76\u4eba\u5458\u4e0e\u4e00\u4f4d\u804b\u54d1\u5b66\u751f\u548c\u4ed6\u7684\u7ffb\u8bd1\uff08LIS\u4e13\u5bb6\uff09\u5408\u4f5c\uff0c\u4f7f\u7528\u624b\u52a8\u52a8\u753b\u6280\u672f\u6216\u57fa\u4e8eMATLAB\u7684\u9006\u8fd0\u52a8\u5b66\u6c42\u89e3\u5668\uff0c\u5728Pepper\u673a\u5668\u4eba\u4e0a\u5171\u540c\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e8652\u4e2aLIS\u624b\u8bed\u3002\u968f\u540e\uff0c\u8fdb\u884c\u4e86\u4e00\u9879\u63a2\u7d22\u6027\u7528\u6237\u7814\u7a76\uff0c\u9080\u8bf7\u4e8612\u540d\u7cbe\u901aLIS\u7684\u53c2\u4e0e\u8005\uff08\u5305\u62ec\u804b\u54d1\u4eba\u548c\u542c\u529b\u6b63\u5e38\u8005\uff09\u5b8c\u6210\u4e86\u4e00\u9879\u5305\u542b15\u4e2a\u5355\u9879\u9009\u62e9\u89c6\u9891\u624b\u8bed\u8bc6\u522b\u4efb\u52a1\u548c2\u4e2a\u5173\u4e8e\u77ed\u8bed\u624b\u8bed\u7684\u5f00\u653e\u5f0f\u95ee\u9898\u7684\u95ee\u5377\u8c03\u67e5\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u5927\u591a\u6570\u5b64\u7acb\u7684\u624b\u8bed\u88ab\u6b63\u786e\u8bc6\u522b\uff0c\u4f46\u7531\u4e8ePepper\u6709\u9650\u7684 artik\u00fclasyon \u548c\u65f6\u95f4\u9650\u5236\uff0c\u5b8c\u6574\u7684\u53e5\u5b50\u8bc6\u522b\u7387\u660e\u663e\u8f83\u4f4e\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8bc1\u660e\uff0c\u5373\u4f7f\u662f\u50cfPepper\u8fd9\u6837\u7684\u5546\u7528\u793e\u4ea4\u673a\u5668\u4eba\uff0c\u4e5f\u80fd\u6e05\u6670\u5730\u8868\u8fbe\u4e00\u90e8\u5206LIS\u624b\u8bed\uff0c\u4e3a\u66f4\u5177\u5305\u5bb9\u6027\u7684\u4eba\u673a\u4ea4\u4e92\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u673a\u4f1a\u3002\u672a\u6765\u7684\u7814\u7a76\u5e94\u81f4\u529b\u4e8e\u591a\u6a21\u5f0f\u589e\u5f3a\uff08\u4f8b\u5982\uff0c\u5c4f\u5e55\u652f\u6301\u6216\u8868\u60c5\u5934\u50cf\uff09\u5e76\u8ba9\u804b\u54d1\u7528\u6237\u53c2\u4e0e\u5230\u53c2\u4e0e\u5f0f\u8bbe\u8ba1\u4e2d\uff0c\u4ee5\u6539\u8fdb\u673a\u5668\u4eba\u7684\u8868\u8fbe\u80fd\u529b\u548c\u53ef\u7528\u6027\u3002"}}
{"id": "2509.09807", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2509.09807", "abs": "https://arxiv.org/abs/2509.09807", "authors": ["Karthik Chinni", "Nicol\u00e1s Quesada"], "title": "Optimal Waveforms for Dipole Moment Estimation with Coherent States", "comment": "34 pages, 6 figures", "summary": "We investigate quantum sensing for spectroscopy in a system consisting of a\ntwo-level atom coupled to a continuum of modes. We focus on optimizing the\npulse shape of a coherent state to maximize the quantum Fisher information\n(QFI) of the emitted light with the aim of estimating the atom's dipole moment,\nwhich is proportional to its spontaneous emission rate. To achieve this, we\nderive a set of coupled differential equations, which include the standard\noptical Bloch equations as a subset and whose solution directly yields the QFI\nof the emitted light without resorting to finite-difference methods.\nFurthermore, we analyze the factors that govern its optimization, provide\nanalytic solutions in both the long and the short pulse width limits, and\nexamine the role of the average photon number of the pulses. We then show that\nunder the closed (periodic) boundary conditions, the harmonic (plane-wave) with\nfrequency equal to half the spontaneous emission rate and a phase determined by\ndetuning are optimal in the long pulse width limit.", "AI": {"tldr": "\u672c\u7814\u7a76\u5229\u7528\u91cf\u5b50\u4f20\u611f\u6280\u672f\u4f18\u5316\u76f8\u5e72\u6001\u8109\u51b2\u5f62\u72b6\uff0c\u4ee5\u63d0\u9ad8\u53d1\u5c04\u5149\u5b50\u7684\u91cf\u5b50Fisher\u4fe1\u606f\u91cf\uff0c\u4ece\u800c\u66f4\u7cbe\u786e\u5730\u4f30\u8ba1\u539f\u5b50\u5076\u6781\u77e9\uff08\u4e0e\u81ea\u53d1\u8f90\u5c04\u7387\u6210\u6b63\u6bd4\uff09\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u4f18\u5316\u76f8\u5e72\u6001\u8109\u51b2\u5f62\u72b6\uff0c\u4ee5\u6700\u5927\u5316\u53d1\u5c04\u5149\u5b50\u7684\u91cf\u5b50Fisher\u4fe1\u606f\u91cf\uff0c\u7528\u4e8e\u4f30\u8ba1\u539f\u5b50\u7684\u5076\u6781\u77e9\u3002", "method": "\u901a\u8fc7\u63a8\u5bfc\u4e00\u7ec4\u8026\u5408\u5fae\u5206\u65b9\u7a0b\uff08\u5305\u542b\u5149\u5b66Bloch\u65b9\u7a0b\uff09\u6765\u6c42\u89e3\u91cf\u5b50Fisher\u4fe1\u606f\u91cf\uff0c\u5e76\u5206\u6790\u4e86\u5f71\u54cd\u4f18\u5316\u7684\u56e0\u7d20\uff0c\u5305\u62ec\u8109\u51b2\u5bbd\u5ea6\u548c\u5e73\u5747\u5149\u5b50\u6570\u3002", "result": "\u5728\u957f\u8109\u51b2\u5bbd\u5ea6\u6781\u9650\u4e0b\uff0c\u53d1\u73b0\u9891\u7387\u7b49\u4e8e\u81ea\u53d1\u8f90\u5c04\u7387\u4e00\u534a\u4e14\u76f8\u4f4d\u7531\u5931\u8c10\u786e\u5b9a\u7684\u8c10\u6ce2\uff08\u5e73\u9762\u6ce2\uff09\u8109\u51b2\u662f\u6700\u4f73\u9009\u62e9\u3002", "conclusion": "\u7814\u7a76\u6210\u529f\u5bfc\u51fa\u4e86\u8ba1\u7b97\u91cf\u5b50Fisher\u4fe1\u606f\u91cf\u7684\u65b9\u6cd5\uff0c\u5e76\u786e\u5b9a\u4e86\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u6700\u4f18\u7684\u8109\u51b2\u5f62\u72b6\uff0c\u4e3a\u91cf\u5b50\u4f20\u611f\u5728\u5149\u8c31\u5206\u6790\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u6307\u5bfc\u3002"}}
{"id": "2509.10333", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2509.10333", "abs": "https://arxiv.org/abs/2509.10333", "authors": ["Arthur Rondeau", "Didier Wernli", "Roland Bouffanais"], "title": "Revealing Higher-Order Interactions in Complex Networks: A U.S. Diplomacy Case Study", "comment": null, "summary": "Although diplomatic communication has long been examined in the social\nsciences, its network structure remains underexplored. Using the U.S.\ndiplomatic cables released by WikiLeaks in 2010 as a case study, we adopt a\nnetwork-science perspective. We represent diplomatic interactions as a\nhypergraph and develop a general, random-walk-based pipeline to evaluate this\nrepresentation against traditional pairwise graphs. We further evaluate the\npipeline on legislative co-sponsorship and organizational email data, finding\nimprovements and empirical evidence that clarifies when hypergraph modeling is\npreferable to pairwise graphs. Overall, hypergraphs paired with appropriately\nspecified random-walk dynamics more faithfully capture higher-order,\ngroup-based interactions, yielding a richer structural account of diplomacy and\nsuperior performance on interaction-prediction tasks that enables inferring new\ndiplomatic relationships from existing patterns.", "AI": {"tldr": "\u5916\u4ea4\u7535\u62a5\u7814\u7a76\u7684\u91cd\u70b9\u5728\u4e8e\u7f51\u7edc\u7ed3\u6784\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u968f\u673a\u6e38\u8d70\u7684\u65b0\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u53ef\u4ee5\u66f4\u51c6\u786e\u5730\u6355\u6349\u591a\u65b9\u4e92\u52a8\uff0c\u5e76\u80fd\u66f4\u597d\u5730\u9884\u6d4b\u5916\u4ea4\u5173\u7cfb\u3002", "motivation": "\u5c3d\u7ba1\u5916\u4ea4\u4ea4\u6d41\u5728\u793e\u4f1a\u79d1\u5b66\u4e2d\u5df2\u88ab\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u5176\u7f51\u7edc\u7ed3\u6784\u4ecd\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u7814\u7a76\u4f7f\u75282010\u5e74\u7ef4\u57fa\u89e3\u5bc6\u7684\u7f8e\u56fd\u5916\u4ea4\u7535\u62a5\u4f5c\u4e3a\u6848\u4f8b\uff0c\u91c7\u7528\u7f51\u7edc\u79d1\u5b66\u7684\u89c6\u89d2\uff0c\u5c06\u5916\u4ea4\u4e92\u52a8\u8868\u793a\u4e3a\u8d85\u56fe\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u968f\u673a\u6e38\u8d70\u7684\u901a\u7528\u6d41\u7a0b\u6765\u8bc4\u4f30\u8fd9\u79cd\u8868\u793a\u65b9\u6cd5\u4e0e\u4f20\u7edf\u7684\u6210\u5bf9\u56fe\u7684\u5bf9\u6bd4\u3002\u6b64\u5916\uff0c\u8be5\u6d41\u7a0b\u8fd8\u5e94\u7528\u4e8e\u7acb\u6cd5\u5171\u540c\u63d0\u6848\u548c\u7ec4\u7ec7\u7535\u5b50\u90ae\u4ef6\u6570\u636e\uff0c\u4ee5\u8bc4\u4f30\u5176\u5728\u4e0d\u540c\u7c7b\u578b\u6570\u636e\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u4e0e\u4f20\u7edf\u7684\u6210\u5bf9\u56fe\u76f8\u6bd4\uff0c\u8d85\u56fe\u7ed3\u5408\u9002\u5f53\u7684\u968f\u673a\u6e38\u8d70\u6a21\u578b\u80fd\u66f4\u771f\u5b9e\u5730\u53cd\u6620\u591a\u65b9\u3001\u57fa\u4e8e\u7fa4\u4f53\u7684\u4e92\u52a8\uff0c\u4ece\u800c\u63d0\u4f9b\u5bf9\u5916\u4ea4\u7ed3\u6784\u66f4\u4e30\u5bcc\u7684\u63cf\u8ff0\uff0c\u5e76\u5728\u4e92\u52a8\u9884\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u66f4\u4f18\u8d8a\u7684\u6027\u80fd\uff0c\u80fd\u591f\u4ece\u73b0\u6709\u6a21\u5f0f\u4e2d\u63a8\u65ad\u51fa\u65b0\u7684\u5916\u4ea4\u5173\u7cfb\u3002", "conclusion": "\u8d85\u56fe\u6a21\u578b\u7ed3\u5408\u968f\u673a\u6e38\u8d70\u52a8\u529b\u5b66\u80fd\u591f\u66f4\u51c6\u786e\u5730\u6355\u6349\u5916\u4ea4\u4e92\u52a8\u7684\u591a\u65b9\u7ed3\u6784\uff0c\u5e76\u5728\u9884\u6d4b\u4efb\u52a1\u4e2d\u53d6\u5f97\u66f4\u597d\u7684\u6548\u679c\uff0c\u4e3a\u7406\u89e3\u548c\u5206\u6790\u5916\u4ea4\u5173\u7cfb\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2509.10187", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2509.10187", "abs": "https://arxiv.org/abs/2509.10187", "authors": ["Simcha van Collem", "Niels van der Weide", "Herman Geuvers"], "title": "Initial Algebras of Domains via Quotient Inductive-Inductive Types", "comment": null, "summary": "Domain theory has been developed as a mathematical theory of computation and\nto give a denotational semantics to programming languages. It helps us to fix\nthe meaning of language concepts, to understand how programs behave and to\nreason about programs. At the same time it serves as a great theory to model\nvarious algebraic effects such as non-determinism, partial functions, side\neffects and numerous other forms of computation.\n  In the present paper, we present a general framework to construct algebraic\neffects in domain theory, where our domains are DCPOs: directed complete\npartial orders. We first describe so called DCPO algebras for a signature,\nwhere the signature specifies the operations on the DCPO and the inequational\ntheory they obey. This provides a method to represent various algebraic\neffects, like partiality. We then show that initial DCPO algebras exist by\ndefining them as so called Quotient Inductive-Inductive Types (QIITs), known\nfrom homotopy type theory. A quotient inductive-inductive type allows one to\nsimultaneously define an inductive type and an inductive relation on that type,\ntogether with equations on the type. We illustrate our approach by showing that\nseveral well-known constructions of DCPOs fit our framework: coalesced sums,\nsmash products and free DCPOs (partiality and power domains). Our work makes\nuse of various features of homotopy type theory and is formalized in Cubical\nAgda.", "AI": {"tldr": "\u57df\u8bba\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5efa\u7acb\u4ee3\u6570\u6548\u5e94\u7684\u901a\u7528\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u4f7f\u7528 DCPO \u4ee3\u6570\u548c\u62df\u5546\u5f52\u7eb3\u5f52\u7eb3\u7c7b\u578b\uff0c\u5e76\u5df2\u5728 Cubical Agda \u4e2d\u5f97\u5230\u8bc1\u660e\uff0c\u53ef\u7528\u4e8e\u5bf9\u90e8\u5206\u6027\u3001\u975e\u786e\u5b9a\u6027\u548c\u5176\u4ed6\u8ba1\u7b97\u5f62\u5f0f\u8fdb\u884c\u5efa\u6a21\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u63d0\u4f9b\u4e00\u4e2a\u5efa\u7acb\u57df\u7406\u8bba\u4e2d\u4ee3\u6570\u6548\u5e94\u7684\u901a\u7528\u6846\u67b6\uff0c\u4ee5\u89e3\u51b3\u975e\u786e\u5b9a\u6027\u3001\u504f\u51fd\u6570\u548c\u526f\u4f5c\u7528\u7b49\u8ba1\u7b97\u5f62\u5f0f\u7684\u5efa\u6a21\u95ee\u9898\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u4f7f\u7528 DCPO \u4ee3\u6570\uff08\u5b9a\u4e49\u4e86\u64cd\u4f5c\u548c\u4e0d\u76f8\u7b49\u7406\u8bba\uff09\u6765\u8868\u793a\u4ee3\u6570\u6548\u5e94\u7684\u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u62df\u5546\u5f52\u7eb3\u5f52\u7eb3\u7c7b\u578b\uff08QIIT\uff09\u8bc1\u660e\u4e86\u521d\u59cb DCPO \u4ee3\u6570\u7684\u5b58\u5728\u6027\u3002", "result": "\u672c\u6587\u5c55\u793a\u4e86\u8be5\u6846\u67b6\u5982\u4f55\u5e94\u7528\u4e8e\u5404\u79cd\u5df2\u77e5\u7684 DCPO\uff08\u4f8b\u5982\uff0c\u5408\u5e76\u548c\u3001\u7c89\u788e\u79ef\u548c\u81ea\u7531 DCPO\uff09\u7684\u6784\u9020\uff0c\u5e76\u4f7f\u7528 Cubical Agda \u5bf9\u5176\u8fdb\u884c\u4e86\u5f62\u5f0f\u5316\u3002", "conclusion": "\u901a\u8fc7\u4f7f\u7528\u62df\u5546\u5f52\u7eb3\u5f52\u7eb3\u7c7b\u578b\uff0c\u672c\u6587\u6210\u529f\u5730\u4e3a\u57df\u7406\u8bba\u4e2d\u7684\u4ee3\u6570\u6548\u5e94\u63d0\u4f9b\u4e86\u4e00\u4e2a\u901a\u7528\u7684\u3001\u53ef\u5b9e\u4f8b\u5316\u7684\u6846\u67b6\uff0c\u5e76\u8bc1\u660e\u4e86\u8be5\u6846\u67b6\u5728\u5bf9\u5404\u79cd\u8ba1\u7b97\u5f62\u5f0f\u8fdb\u884c\u5efa\u6a21\u65b9\u9762\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2509.10057", "categories": ["physics.app-ph", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10057", "abs": "https://arxiv.org/abs/2509.10057", "authors": ["Jakub Mojsiejuk", "S\u0142awomir Zi\u0119tek", "Witold Skowro\u0144ski"], "title": "Reinforcement learning for spin torque oscillator tasks", "comment": "3 figures, 6 pages", "summary": "We address the problem of automatic synchronisation of the spintronic\noscillator (STO) by means of reinforcement learning (RL). A numerical solution\nof the macrospin Landau-Lifschitz-Gilbert-Slonczewski equation is used to\nsimulate the STO and we train the two types of RL agents to synchronise with a\ntarget frequency within a fixed number of steps. We explore modifications to\nthis base task and show an improvement in both convergence and energy\nefficiency of the synchronisation that can be easily achieved in the simulated\nenvironment.", "AI": {"tldr": "\u6211\u4eec\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u6765\u81ea\u52a8\u540c\u6b65\u65cb\u5b50\u632f\u8361\u5668\uff08STO\uff09\u3002", "motivation": "\u81ea\u52a8\u540c\u6b65STO\u4ee5\u8fbe\u5230\u76ee\u6807\u9891\u7387\u3002", "method": "\u4f7f\u7528\u5b8f\u89c2\u81ea\u65cbLandau-Lifschitz-Gilbert-Slonczewski\u65b9\u7a0b\u6a21\u62dfSTO\uff0c\u5e76\u8bad\u7ec3\u4e24\u79cdRL\u667a\u80fd\u4f53\u5728\u56fa\u5b9a\u6b65\u6570\u5185\u540c\u6b65\u5230\u76ee\u6807\u9891\u7387\u3002\u63a2\u7d22\u4e86\u5bf9\u57fa\u7840\u4efb\u52a1\u7684\u4fee\u6539\uff0c\u4ee5\u63d0\u9ad8\u540c\u6b65\u7684\u6536\u655b\u6027\u548c\u80fd\u6e90\u6548\u7387\u3002", "result": "\u5728\u6a21\u62df\u73af\u5883\u4e2d\uff0cRL\u667a\u80fd\u4f53\u6210\u529f\u5b9e\u73b0\u4e86STO\u7684\u540c\u6b65\uff0c\u5e76\u63a2\u7d22\u4e86\u6539\u8fdb\u6536\u655b\u6027\u548c\u80fd\u6e90\u6548\u7387\u7684\u65b9\u6cd5\u3002", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u662f\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u53ef\u4ee5\u81ea\u52a8\u540c\u6b65STO\uff0c\u5e76\u4e14\u53ef\u4ee5\u901a\u8fc7\u8c03\u6574RL\u667a\u80fd\u4f53\u548c\u4efb\u52a1\u6765\u8fdb\u4e00\u6b65\u63d0\u9ad8\u5176\u6027\u80fd\u3002"}}
{"id": "2509.10363", "categories": ["cs.LG", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2509.10363", "abs": "https://arxiv.org/abs/2509.10363", "authors": ["Benjamin David Shaffer", "Brooks Kinch", "Joseph Klobusicky", "M. Ani Hsieh", "Nathaniel Trask"], "title": "Physics-informed sensor coverage through structure preserving machine learning", "comment": null, "summary": "We present a machine learning framework for adaptive source localization in\nwhich agents use a structure-preserving digital twin of a coupled\nhydrodynamic-transport system for real-time trajectory planning and data\nassimilation. The twin is constructed with conditional neural Whitney forms\n(CNWF), coupling the numerical guarantees of finite element exterior calculus\n(FEEC) with transformer-based operator learning. The resulting model preserves\ndiscrete conservation, and adapts in real time to streaming sensor data. It\nemploys a conditional attention mechanism to identify: a reduced Whitney-form\nbasis; reduced integral balance equations; and a source field, each compatible\nwith given sensor measurements. The induced reduced-order environmental model\nretains the stability and consistency of standard finite-element simulation,\nyielding a physically realizable, regular mapping from sensor data to the\nsource field. We propose a staggered scheme that alternates between evaluating\nthe digital twin and applying Lloyd's algorithm to guide sensor placement, with\nanalysis providing conditions for monotone improvement of a coverage\nfunctional. Using the predicted source field as an importance function within\nan optimal-recovery scheme, we demonstrate recovery of point sources under\ncontinuity assumptions, highlighting the role of regularity as a sufficient\ncondition for localization. Experimental comparisons with physics-agnostic\ntransformer architectures show improved accuracy in complex geometries when\nphysical constraints are enforced, indicating that structure preservation\nprovides an effective inductive bias for source identification.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6570\u5b57\u5b6a\u751f\u548c\u6761\u4ef6\u795e\u7ecf\u60e0\u7279\u5c3c\u65b9\u7a0b\u7684\u81ea\u9002\u5e94\u6e90\u5b9a\u4f4d\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u878d\u5408\u6709\u9650\u5143\u5916\u5fae\u79ef\u5206\u548c\u7b97\u5b50\u5b66\u4e60\uff0c\u5b9e\u73b0\u4e86\u5bf9\u6c34\u52a8\u529b-\u8f93\u8fd0\u7cfb\u7edf\u7684\u5b9e\u65f6\u8f68\u8ff9\u89c4\u5212\u548c\u6570\u636e\u540c\u5316\uff0c\u5e76\u80fd\u6709\u6548\u5904\u7406\u590d\u6742\u51e0\u4f55\u5f62\u72b6\u3002", "motivation": "\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u5728\u590d\u6742\u51e0\u4f55\u73af\u5883\u4e2d\uff0c\u5b9e\u65f6\u3001\u81ea\u9002\u5e94\u5730\u8fdb\u884c\u6e90\u5b9a\u4f4d\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u8bc1\u7269\u7406\u89c4\u5f8b\u7684\u4e00\u81f4\u6027\u3002", "method": "\u5229\u7528\u6761\u4ef6\u795e\u7ecf\u60e0\u7279\u5c3c\u65b9\u7a0b\uff08CNWF\uff09\u6784\u5efa\u8026\u5408\u6c34\u52a8\u529b-\u8f93\u8fd0\u7cfb\u7edf\u7684\u6570\u5b57\u5b6a\u751f\uff0c\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86\u6709\u9650\u5143\u5916\u5fae\u79ef\u5206\uff08FEEC\uff09\u7684\u6570\u503c\u4fdd\u8bc1\u548c\u57fa\u4e8eTransformer\u7684\u7b97\u5b50\u5b66\u4e60\uff0c\u5b9e\u73b0\u4e86\u79bb\u6563\u5b88\u6052\u5e76\u5b9e\u65f6\u9002\u5e94\u4f20\u611f\u5668\u6570\u636e\u3002\u901a\u8fc7\u6761\u4ef6\u6ce8\u610f\u529b\u673a\u5236\u8bc6\u522b\u7b80\u5316\u7684\u60e0\u7279\u5c3c\u57fa\u3001\u7b80\u5316\u7684\u79ef\u5206\u5b88\u6052\u65b9\u7a0b\u548c\u6e90\u573a\uff0c\u5e76\u91c7\u7528\u4ea4\u9519\u65b9\u6848\u7ed3\u5408\u6570\u5b57\u5b6a\u751f\u548cLloyd\u7b97\u6cd5\u8fdb\u884c\u4f20\u611f\u5668\u5e03\u5c40\u4f18\u5316\u3002", "result": "\u6240\u63d0\u51fa\u7684\u6846\u67b6\u5728\u590d\u6742\u51e0\u4f55\u5f62\u72b6\u4e0b\uff0c\u76f8\u6bd4\u4e8e\u4e0d\u8003\u8651\u7269\u7406\u7ea6\u675f\u7684Transformer\u6a21\u578b\uff0c\u63d0\u9ad8\u4e86\u6e90\u5b9a\u4f4d\u7684\u51c6\u786e\u6027\u3002\u6570\u5b57\u5b6a\u751f\u6a21\u578b\u80fd\u591f\u751f\u6210\u7269\u7406\u4e0a\u53ef\u5b9e\u73b0\u7684\u3001\u89c4\u5219\u7684\u4ece\u4f20\u611f\u5668\u6570\u636e\u5230\u6e90\u573a\u7684\u6620\u5c04\uff0c\u5e76\u4fdd\u8bc1\u4e86\u6a21\u62df\u7684\u7a33\u5b9a\u6027\u548c\u4e00\u81f4\u6027\u3002", "conclusion": "\u7ed3\u6784\u4fdd\u6301\uff08Structure preservation\uff09\u4e3a\u6e90\u8bc6\u522b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5f52\u7eb3\u504f\u501a\uff08inductive bias\uff09\uff0c\u800c\u89c4\u5219\u6027\u662f\u6e90\u5b9a\u4f4d\u7684\u5145\u5206\u6761\u4ef6\u3002\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u51c6\u786e\u5730\u4ece\u4f20\u611f\u5668\u6570\u636e\u4e2d\u6062\u590d\u6e90\u573a\u4fe1\u606f\u3002"}}
{"id": "2509.09842", "categories": ["eess.SP", "physics.med-ph"], "pdf": "https://arxiv.org/pdf/2509.09842", "abs": "https://arxiv.org/abs/2509.09842", "authors": ["Anu Tripathi", "Yang Wan", "Zhiren Zhu", "Furkan Camci", "Sheila Turcsanyi", "Jeneel Pravin Kachhadiya", "Mauricio Araiza Canizales", "Alison Brooks", "Haneesh Kesari", "Joseph Andrews", "Traci Snedden", "Peter Ferrazzano", "Christian Franck", "Rika Wright Carlsen"], "title": "Field evaluation of a wearable instrumented headband designed for measuring head kinematics", "comment": null, "summary": "Purpose: To study the relationship between soccer heading and the risk of\nmild traumatic brain injury (mTBI), we previously developed an instrumented\nheadband and data processing scheme to measure the angular head kinematics of\nsoccer headers. Laboratory evaluation of the headband on an anthropomorphic\ntest device showed good agreement with a reference sensor for soccer ball\nimpacts to the front of the head. In this study, we evaluate the headband in\nmeasuring the full head kinematics of soccer headers in the field. Methods: The\nheadband was evaluated under typical soccer heading scenarios (throw-ins,\ngoal-kicks, and corner-kicks) on a human subject. The measured time history and\npeak kinematics from the headband were compared with those from an instrumented\nmouthpiece, which is a widely accepted method for measuring head kinematics in\nthe field. Results: The time history agreement (CORA scores) between the\nheadband and the mouthpiece ranged from 'fair' to 'excellent', with the highest\nagreement for angular velocities (0.79 \\pm 0.08) and translational\naccelerations (0.73 \\pm 0.05) and lowest for angular accelerations (0.67 \\pm\n0.06). A Bland-Altman analysis of the peak kinematics from the headband and\nmouthpiece found the mean bias to be 40.9% (of the maximum mouthpiece reading)\nfor the angular velocity, 16.6% for the translational acceleration, and-14.1%\nfor the angular acceleration. Conclusion: The field evaluation of the\ninstrumented headband showed reasonable agreement with the mouthpiece for some\nkinematic measures and impact conditions. Future work should focus on improving\nthe headband performance across all kinematic measures.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u4e00\u79cd\u7528\u4e8e\u6d4b\u91cf\u8db3\u7403\u9876\u7403\u8fd0\u52a8\u4e2d\u5934\u90e8\u8fd0\u52a8\u5b66\u6570\u636e\u7684\u4eea\u5668\u5316\u5934\u5e26\u5728\u5b9e\u9645\u6bd4\u8d5b\u4e2d\u7684\u6027\u80fd\u3002", "motivation": "\u7814\u7a76\u8db3\u7403\u9876\u7403\u8fd0\u52a8\u4e0e\u8f7b\u5ea6\u521b\u4f24\u6027\u8111\u635f\u4f24\uff08mTBI\uff09\u98ce\u9669\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u9700\u8981\u51c6\u786e\u6d4b\u91cf\u5934\u90e8\u8fd0\u52a8\u5b66\u6570\u636e\u3002\u672c\u6587\u65e8\u5728\u8bc4\u4f30\u5148\u524d\u5f00\u53d1\u7684\u4eea\u5668\u5316\u5934\u5e26\u5728\u5b9e\u9645\u6bd4\u8d5b\u73af\u5883\u4e0b\u7684\u6d4b\u91cf\u80fd\u529b\u3002", "method": "\u5728\u771f\u5b9e\u6bd4\u8d5b\u573a\u666f\uff08\u754c\u5916\u7403\u3001\u7403\u95e8\u7403\u3001\u89d2\u7403\uff09\u4e2d\uff0c\u8ba9\u4e00\u540d\u771f\u4eba\u53d7\u8bd5\u8005\u8fdb\u884c\u8db3\u7403\u9876\u7403\u8fd0\u52a8\uff0c\u5e76\u4f69\u6234\u4eea\u5668\u5316\u5934\u5e26\u3002\u5c06\u5934\u5e26\u6d4b\u5f97\u7684\u5934\u90e8\u89d2\u901f\u5ea6\u3001\u89d2\u52a0\u901f\u5ea6\u548c\u5e73\u79fb\u52a0\u901f\u5ea6\u7684\u65f6\u95f4\u5386\u7a0b\u548c\u5cf0\u503c\u4e0e\u540c\u65f6\u4f7f\u7528\u7684\u4eea\u5668\u5316\u53e3\u542b\u5668\uff08\u4e00\u79cd\u516c\u8ba4\u7684\u6d4b\u91cf\u65b9\u6cd5\uff09\u7684\u6d4b\u91cf\u7ed3\u679c\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u5934\u5e26\u548c\u53e3\u542b\u5668\u5728\u6d4b\u91cf\u7ed3\u679c\u4e0a\u7684\u65f6\u95f4\u5386\u7a0b\u4e00\u81f4\u6027\uff08CORA\u5206\u6570\uff09\u8868\u73b0\u4e0d\u4e00\uff0c\u89d2\u901f\u5ea6\u548c\u7ebf\u52a0\u901f\u5ea6\u7684\u543b\u5408\u5ea6\u8f83\u9ad8\uff08\u5206\u522b\u4e3a0.79 \u00b1 0.08\u548c0.73 \u00b1 0.05\uff09\uff0c\u800c\u89d2\u52a0\u901f\u5ea6\u7684\u543b\u5408\u5ea6\u8f83\u4f4e\uff080.67 \u00b1 0.06\uff09\u3002Bland-Altman\u5206\u6790\u663e\u793a\uff0c\u5728\u5cf0\u503c\u8fd0\u52a8\u5b66\u6d4b\u91cf\u65b9\u9762\uff0c\u5934\u5e26\u6d4b\u5f97\u7684\u89d2\u901f\u5ea6\u6bd4\u53e3\u542b\u5668\u9ad840.9%\uff0c\u7ebf\u52a0\u901f\u5ea6\u9ad816.6%\uff0c\u89d2\u52a0\u901f\u5ea6\u4f4e14.1%\u3002", "conclusion": "\u5728\u5b9e\u9645\u6bd4\u8d5b\u73af\u5883\u4e2d\uff0c\u8be5\u4eea\u5668\u5316\u5934\u5e26\u5728\u67d0\u4e9b\u8fd0\u52a8\u5b66\u6d4b\u91cf\u548c\u7279\u5b9a\u51b2\u51fb\u6761\u4ef6\u4e0b\u4e0e\u53e3\u542b\u5668\u6d4b\u91cf\u7ed3\u679c\u5177\u6709\u53ef\u63a5\u53d7\u7684\u4e00\u81f4\u6027\u3002\u672a\u6765\u7684\u7814\u7a76\u5e94\u81f4\u529b\u4e8e\u6539\u8fdb\u5934\u5e26\u5728\u6240\u6709\u8fd0\u52a8\u5b66\u6d4b\u91cf\u65b9\u9762\u7684\u6027\u80fd\u3002"}}
{"id": "2509.09964", "categories": ["cond-mat.mtrl-sci", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2509.09964", "abs": "https://arxiv.org/abs/2509.09964", "authors": ["Tara Pe\u00f1a", "Anton E. O. Persson", "Andrey Krayev", "\u00c1shildur Fri\u00f0riksd\u00f3ttir", "Kathryn Neilson", "Zhepeng Zhang", "Anh Tuan Hoang", "Jerry A. Yang", "Lauren Hoang", "Andrew J. Mannix", "Paul C. McIntyre", "Eric Pop"], "title": "Scaling High-Performance Nanoribbon Transistors with Monolayer Transition Metal Dichalcogenides", "comment": "16 pages, 4 figures", "summary": "Nanoscale transistors require aggressive reduction of all channel dimensions:\nlength, width, and thickness. While monolayer two-dimensional semiconductors\n(2DS) offer ultimate thickness scaling, good performance has largely been\nachieved only in micrometer-wide channels. Here, we demonstrate both $\\it{n}$-\nand $\\it{p}$-type nanoribbon transistors based on monolayer 2DS, fabricated\nusing a multi-patterning process, reaching channel widths down to 25 nm and\nlengths down to 50 nm. 'Anchored' contacts improve device yield, while\nnanoscale imaging, including tip-enhanced photoluminescence, reveals minimal\nedge degradation. The devices reach on-state currents up to 560, 420, and 130\n$\\mu$A $\\mu$m$^{-1}$ at 1 V drain-to-source voltage for $\\it{n}$-type\nMoS$_{2}$, WS$_{2}$, and $\\it{p}$-type WSe$_{2}$, respectively, integrated with\nthin high-$\\kappa$ dielectrics. These results surpass prior reports for\nsingle-gated nanoribbons, the WS$_{2}$ by over 100 times, even in normally-off\n(enhancement-mode) transistors. Taken together, these findings suggest that top\ndown patterned 2DS nanoribbons are promising building blocks for future\nnanosheet transistors.", "AI": {"tldr": "\u901a\u8fc7\u591a\u91cd\u56fe\u6848\u5316\u5de5\u827a\u5236\u5907\u4e86\u57fa\u4e8e\u5355\u5c42\u4e8c\u7ef4\u534a\u5bfc\u4f53\u7684n\u578b\u548cp\u578b\u7eb3\u7c73\u5e26\u6676\u4f53\u7ba1\uff0c\u5668\u4ef6\u6c9f\u9053\u5bbd\u5ea6\u8fbe\u523025\u7eb3\u7c73\uff0c\u6c9f\u9053\u957f\u5ea6\u8fbe\u523050\u7eb3\u7c73\uff0c\u4e14\u5668\u4ef6\u6027\u80fd\u4f18\u4e8e\u5355\u95e8\u7eb3\u7c73\u5e26\u7684\u5148\u524d\u62a5\u9053\u3002", "motivation": "\u4e3a\u4e86\u5b9e\u73b0\u7eb3\u7c73\u7ea7\u6676\u4f53\u7ba1\u7684\u5c3a\u5bf8\u7f29\u51cf\uff0c\u9700\u8981\u51cf\u5c0f\u6c9f\u9053\u957f\u5ea6\u3001\u5bbd\u5ea6\u548c\u539a\u5ea6\u3002\u5355\u5c42\u4e8c\u7ef4\u534a\u5bfc\u4f53\uff082DS\uff09\u5728\u539a\u5ea6\u7f29\u51cf\u65b9\u9762\u5177\u6709\u4f18\u52bf\uff0c\u4f46\u4e4b\u524d\u7684\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u8f83\u5bbd\u7684\u6c9f\u9053\u4e0a\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5728\u7eb3\u7c73\u5c3a\u5ea6\u4e0b\u4e8c\u7ef4\u534a\u5bfc\u4f53\u6c9f\u9053\u7684\u6027\u80fd\u3002", "method": "\u91c7\u7528\u591a\u91cd\u56fe\u6848\u5316\u5de5\u827a\u5236\u5907\u4e86\u6c9f\u9053\u5bbd\u5ea6\u5c0f\u4e8e50\u7eb3\u7c73\u7684\u5355\u5c42\u4e8c\u7ef4\u534a\u5bfc\u4f53\u7eb3\u7c73\u5e26\u6676\u4f53\u7ba1\u3002\u4f7f\u7528\u4e86\u2018\u951a\u5b9a\u2019\u63a5\u89e6\u6765\u63d0\u9ad8\u5668\u4ef6\u826f\u7387\u3002\u5229\u7528\u5305\u62ec\u5c16\u7aef\u589e\u5f3a\u5149\u81f4\u53d1\u5149\u5728\u5185\u7684\u7eb3\u7c73\u5c3a\u5ea6\u6210\u50cf\u6280\u672f\u6765\u8bc4\u4f30\u5668\u4ef6\u7684\u8fb9\u7f18\u9000\u5316\u60c5\u51b5\u3002", "result": "\u5236\u5907\u7684n\u578bMoS$_{2}$\u3001WS$_{2}$\u548cp\u578bWSe$_{2}$\u7eb3\u7c73\u5e26\u6676\u4f53\u7ba1\u57281V\u7684\u6f0f\u6e90\u7535\u538b\u4e0b\uff0c\u8f7d\u6d41\u5b50\u8fc1\u79fb\u7387\u5206\u522b\u8fbe\u5230\u4e86560\u3001420\u548c130 \u03bcA \u03bcm$^{-1}$\u3002\u8fd9\u4e9b\u6027\u80fd\u8d85\u8d8a\u4e86\u5148\u524d\u5355\u95e8\u7eb3\u7c73\u5e26\u7684\u62a5\u9053\uff0c\u7279\u522b\u662fWS$_{2}$\u5668\u4ef6\u6027\u80fd\u63d0\u5347\u4e86100\u591a\u500d\uff0c\u5e76\u4e14\u5b9e\u73b0\u4e86\u5e38\u5173\u578b\uff08\u589e\u5f3a\u578b\uff09\u5668\u4ef6\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u81ea\u4e0a\u800c\u4e0b\u52a0\u5de5\u7684\u4e8c\u7ef4\u534a\u5bfc\u4f53\u7eb3\u7c73\u5e26\u662f\u672a\u6765\u7eb3\u7c73\u7247\u6676\u4f53\u7ba1\u7684\u6709\u5e0c\u671b\u7684\u6784\u5efa\u6a21\u5757\u3002"}}
{"id": "2509.09702", "categories": ["cs.CL", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.09702", "abs": "https://arxiv.org/abs/2509.09702", "authors": ["Ninad Bhat", "Kieran Browne", "Pip Bingemann"], "title": "Creativity Benchmark: A benchmark for marketing creativity for LLM models", "comment": "30 Pages, 14 figures", "summary": "We introduce Creativity Benchmark, an evaluation framework for large language\nmodels (LLMs) in marketing creativity. The benchmark covers 100 brands (12\ncategories) and three prompt types (Insights, Ideas, Wild Ideas). Human\npairwise preferences from 678 practising creatives over 11,012 anonymised\ncomparisons, analysed with Bradley-Terry models, show tightly clustered\nperformance with no model dominating across brands or prompt types: the\ntop-bottom spread is $\\Delta\\theta \\approx 0.45$, which implies a head-to-head\nwin probability of $0.61$; the highest-rated model beats the lowest only about\n$61\\%$ of the time. We also analyse model diversity using cosine distances to\ncapture intra- and inter-model variation and sensitivity to prompt reframing.\nComparing three LLM-as-judge setups with human rankings reveals weak,\ninconsistent correlations and judge-specific biases, underscoring that\nautomated judges cannot substitute for human evaluation. Conventional\ncreativity tests also transfer only partially to brand-constrained tasks.\nOverall, the results highlight the need for expert human evaluation and\ndiversity-aware workflows.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3a\u201cCreativity Benchmark\u201d\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u7528\u4e8e\u8861\u91cf\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u8425\u9500\u521b\u610f\u65b9\u9762\u7684\u8868\u73b0\u3002\u8be5\u57fa\u51c6\u5305\u542b100\u4e2a\u54c1\u724c\uff0812\u4e2a\u7c7b\u522b\uff09\u548c\u4e09\u79cd\u63d0\u793a\u7c7b\u578b\uff08\u6d1e\u5bdf\u3001\u521b\u610f\u3001\u653e\u98de\u521b\u610f\uff09\u3002", "motivation": "\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u8425\u9500\u521b\u610f\u65b9\u9762\u7684\u80fd\u529b\uff0c\u5e76\u4e0e\u4eba\u7c7b\u521b\u610f\u8005\u7684\u8868\u73b0\u8fdb\u884c\u6bd4\u8f83\u3002", "method": "\u6536\u96c6\u4e86678\u540d\u4e13\u4e1a\u521b\u610f\u8005\u5bf911,012\u4e2a\u533f\u540d\u6bd4\u8f83\u7ed3\u679c\u7684\u914d\u5bf9\u504f\u597d\uff0c\u5e76\u4f7f\u7528Bradley-Terry\u6a21\u578b\u8fdb\u884c\u5206\u6790\uff0c\u4ee5\u8bc4\u4f30\u6a21\u578b\u7684\u8868\u73b0\u3002\u540c\u65f6\uff0c\u7814\u7a76\u8fd8\u5206\u6790\u4e86\u6a21\u578b\u7684\u8f93\u51fa\u591a\u6837\u6027\uff0c\u5e76\u6bd4\u8f83\u4e86\u4e09\u79cd\u201cLLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u201d\u7684\u8bbe\u7f6e\u4e0e\u4eba\u7c7b\u6392\u540d\u7684\u76f8\u5173\u6027\uff0c\u4ee5\u53ca\u5bf9\u63d0\u793a\u91cd\u6784\u7684\u654f\u611f\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u6240\u6709\u6a21\u578b\u7684\u8868\u73b0\u7d27\u5bc6\u805a\u96c6\uff0c\u6ca1\u6709\u6a21\u578b\u5728\u6240\u6709\u54c1\u724c\u6216\u63d0\u793a\u7c7b\u578b\u4e0a\u90fd\u5360\u636e\u4e3b\u5bfc\u5730\u4f4d\uff0c\u6700\u9ad8\u8bc4\u5206\u6a21\u578b\u4ec5\u6bd4\u6700\u4f4e\u8bc4\u5206\u6a21\u578b\u9ad8\u51fa\u7ea661%\u7684\u80dc\u7387\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u53d1\u73b0\u201cLLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u201d\u7684\u8bbe\u7f6e\u4e0e\u4eba\u7c7b\u6392\u540d\u4e4b\u95f4\u5b58\u5728\u5fae\u5f31\u4e14\u4e0d\u4e00\u81f4\u7684\u76f8\u5173\u6027\uff0c\u5e76\u5b58\u5728\u8bc4\u5224\u8005\u504f\u89c1\u3002\u4f20\u7edf\u7684\u521b\u9020\u529b\u6d4b\u8bd5\u5728\u54c1\u724c\u7ea6\u675f\u4efb\u52a1\u4e0a\u7684\u8fc1\u79fb\u6027\u4e5f\u6709\u9650\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u5728\u8425\u9500\u521b\u610f\u9886\u57df\uff0c\u4e13\u5bb6\u4eba\u7c7b\u8bc4\u4f30\u7684\u5fc5\u8981\u6027\uff0c\u5e76\u6307\u51fa\u9700\u8981\u91c7\u7528\u5173\u6ce8\u591a\u6837\u6027\u7684\u5de5\u4f5c\u6d41\u7a0b\u3002\u540c\u65f6\uff0c\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u81ea\u52a8\u8bc4\u5224\u8005\u65e0\u6cd5\u66ff\u4ee3\u4eba\u7c7b\u8bc4\u4f30\uff0c\u4e14\u4f20\u7edf\u7684\u521b\u9020\u529b\u6d4b\u8bd5\u5728\u7279\u5b9a\u4efb\u52a1\u4e0a\u7684\u9002\u7528\u6027\u6709\u9650\u3002"}}
{"id": "2509.09754", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09754", "abs": "https://arxiv.org/abs/2509.09754", "authors": ["Yiqun Shen", "Song Yuan", "Zhengze Zhang", "Xiaoliang Wang", "Daxin Jiang", "Nguyen Cam-Tu"], "title": "LAVa: Layer-wise KV Cache Eviction with Dynamic Budget Allocation", "comment": null, "summary": "KV Cache is commonly used to accelerate LLM inference with long contexts, yet\nits high memory demand drives the need for cache compression. Existing\ncompression methods, however, are largely heuristic and lack dynamic budget\nallocation. To address this limitation, we introduce a unified framework for\ncache compression by minimizing information loss in Transformer residual\nstreams. Building on it, we analyze the layer attention output loss and derive\na new metric to compare cache entries across heads, enabling layer-wise\ncompression with dynamic head budgets. Additionally, by contrasting cross-layer\ninformation, we also achieve dynamic layer budgets. LAVa is the first unified\nstrategy for cache eviction and dynamic budget allocation that, unlike prior\nmethods, does not rely on training or the combination of multiple strategies.\nExperiments with benchmarks (LongBench, Needle-In-A-Haystack, Ruler, and\nInfiniteBench) demonstrate its superiority. Moreover, our experiments reveal a\nnew insight: dynamic layer budgets are crucial for generation tasks (e.g., code\ncompletion), while dynamic head budgets play a key role in extraction tasks\n(e.g., extractive QA). As a fully dynamic compression method, LAVa consistently\nmaintains top performance across task types. Our code is available at\nhttps://github.com/MGDDestiny/Lava.", "AI": {"tldr": "KV \u7f13\u5b58\u662f\u52a0\u901f\u957f\u4e0a\u4e0b\u6587 LLM \u63a8\u7406\u7684\u5173\u952e\uff0c\u4f46\u5176\u9ad8\u5185\u5b58\u9700\u6c42\u4fc3\u4f7f\u4e86\u7f13\u5b58\u538b\u7f29\u7684\u9700\u6c42\u3002\u73b0\u6709\u65b9\u6cd5\u591a\u4e3a\u542f\u53d1\u5f0f\u4e14\u7f3a\u4e4f\u52a8\u6001\u9884\u7b97\u5206\u914d\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u7f13\u5b58\u538b\u7f29\u6846\u67b6\uff0c\u901a\u8fc7\u6700\u5c0f\u5316 Transformer \u6b8b\u5dee\u6d41\u4e2d\u7684\u4fe1\u606f\u635f\u5931\u6765\u5b9e\u73b0\u3002\u8be5\u6846\u67b6\u5206\u6790\u4e86\u5c42\u6ce8\u610f\u529b\u8f93\u51fa\u635f\u5931\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u8de8\u5934\u6bd4\u8f83\u7f13\u5b58\u9879\u7684\u65b0\u6307\u6807\uff0c\u5b9e\u73b0\u4e86\u5177\u6709\u52a8\u6001\u5934\u9884\u7b97\u7684\u5c42\u7ea7\u538b\u7f29\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u5bf9\u6bd4\u8de8\u5c42\u4fe1\u606f\uff0c\u5b9e\u73b0\u4e86\u52a8\u6001\u5c42\u9884\u7b97\u3002Lava \u662f\u9996\u4e2a\u7edf\u4e00\u7684\u7f13\u5b58\u538b\u7f29\u548c\u52a8\u6001\u9884\u7b97\u5206\u914d\u7b56\u7565\uff0c\u65e0\u9700\u8bad\u7ec3\u6216\u7ec4\u5408\u591a\u79cd\u7b56\u7565\u3002\u5728 LongBench\u3001Needle-In-A-Haystack\u3001Ruler \u548c InfiniteBench \u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLava \u8868\u73b0\u4f18\u8d8a\uff0c\u5e76\u63ed\u793a\u4e86\u52a8\u6001\u5c42\u9884\u7b97\u5bf9\u751f\u6210\u4efb\u52a1\uff08\u5982\u4ee3\u7801\u8865\u5168\uff09\u81f3\u5173\u91cd\u8981\uff0c\u800c\u52a8\u6001\u5934\u9884\u7b97\u5bf9\u62bd\u53d6\u4efb\u52a1\uff08\u5982\u62bd\u53d6\u5f0f QA\uff09\u81f3\u5173\u91cd\u8981\u3002Lava \u4f5c\u4e3a\u4e00\u79cd\u5b8c\u5168\u52a8\u6001\u7684\u538b\u7f29\u65b9\u6cd5\uff0c\u5728\u5404\u79cd\u4efb\u52a1\u7c7b\u578b\u4e2d\u59cb\u7ec8\u4fdd\u6301\u9876\u7ea7\u6027\u80fd\u3002\u4ee3\u7801\u5df2\u516c\u5f00\u3002", "motivation": "\u73b0\u6709 KV \u7f13\u5b58\u538b\u7f29\u65b9\u6cd5\u591a\u4e3a\u542f\u53d1\u5f0f\u4e14\u7f3a\u4e4f\u52a8\u6001\u9884\u7b97\u5206\u914d\uff0c\u65e0\u6cd5\u6709\u6548\u5e94\u5bf9 LLM \u63a8\u7406\u4e2d\u957f\u4e0a\u4e0b\u6587\u5e26\u6765\u7684\u9ad8\u5185\u5b58\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684 KV \u7f13\u5b58\u538b\u7f29\u6846\u67b6\uff0c\u901a\u8fc7\u6700\u5c0f\u5316 Transformer \u6b8b\u5dee\u6d41\u4e2d\u7684\u4fe1\u606f\u635f\u5931\u6765\u8bc4\u4f30\u548c\u538b\u7f29\u7f13\u5b58\u3002\u5177\u4f53\u5305\u62ec\uff1a1. \u5206\u6790\u5c42\u6ce8\u610f\u529b\u8f93\u51fa\u635f\u5931\uff0c\u63d0\u51fa\u8de8\u5934\u6bd4\u8f83\u6307\u6807\uff0c\u5b9e\u73b0\u52a8\u6001\u5934\u9884\u7b97\u7684\u5c42\u7ea7\u538b\u7f29\u30022. \u5bf9\u6bd4\u8de8\u5c42\u4fe1\u606f\uff0c\u5b9e\u73b0\u52a8\u6001\u5c42\u9884\u7b97\u3002Lava \u662f\u9996\u4e2a\u65e0\u9700\u8bad\u7ec3\u6216\u7ec4\u5408\u591a\u79cd\u7b56\u7565\u7684\u7edf\u4e00\u52a8\u6001\u7f13\u5b58\u538b\u7f29\u65b9\u6cd5\u3002", "result": "\u5728 LongBench\u3001Needle-In-A-Haystack\u3001Ruler \u548c InfiniteBench \u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLava \u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002\u5b9e\u9a8c\u63ed\u793a\u4e86\u52a8\u6001\u5c42\u9884\u7b97\u5bf9\u751f\u6210\u4efb\u52a1\u7684\u91cd\u8981\u6027\uff0c\u4ee5\u53ca\u52a8\u6001\u5934\u9884\u7b97\u5bf9\u62bd\u53d6\u4efb\u52a1\u7684\u91cd\u8981\u6027\u3002Lava \u5728\u5404\u79cd\u4efb\u52a1\u7c7b\u578b\u4e2d\u5747\u4fdd\u6301\u9876\u7ea7\u6027\u80fd\u3002", "conclusion": "Lava \u662f\u4e00\u79cd\u521b\u65b0\u7684\u3001\u5b8c\u5168\u52a8\u6001\u7684 KV \u7f13\u5b58\u538b\u7f29\u65b9\u6cd5\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u4fe1\u606f\u635f\u5931\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u52a8\u6001\u5c42\u7ea7\u548c\u5934\u9884\u7b97\u5206\u914d\uff0c\u5728\u4e0d\u540c\u7c7b\u578b\u7684\u4e0b\u6e38\u4efb\u52a1\u4e2d\u5747\u8868\u73b0\u51fa\u5353\u8d8a\u7684\u6027\u80fd\u3002"}}
{"id": "2509.09794", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.09794", "abs": "https://arxiv.org/abs/2509.09794", "authors": ["Jackson Eshbaugh", "Chetan Tiwari", "Jorge Silveyra"], "title": "A Modular and Multimodal Generative AI Framework for Urban Building Energy Data: Generating Synthetic Homes", "comment": "44 pages; 2 appendices; 9 figures; 1 table. Code available at\n  https://github.com/Lafayette-EshbaughSilveyra-Group/synthetic-homes", "summary": "Computational models have emerged as powerful tools for energy modeling\nresearch, touting scalability and quantitative results. However, these models\nrequire a plethora of data, some of which is inaccessible, expensive, or raises\nprivacy concerns. We introduce a modular multimodal framework to produce this\ndata from publicly accessible residential information and images using\ngenerative artificial intelligence (AI). Additionally, we provide a pipeline\ndemonstrating this framework, and we evaluate its generative AI components. Our\nexperiments show that our framework's use of AI avoids common issues with\ngenerative models. Our framework produces realistic, labeled data. By reducing\ndependence on costly or restricted data sources, we pave a path towards more\naccessible and reproducible research.", "AI": {"tldr": "\u4f7f\u7528\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u6846\u67b6\u4ece\u516c\u5f00\u4fe1\u606f\u751f\u6210\u80fd\u6e90\u5efa\u6a21\u6240\u9700\u6570\u636e\uff0c\u4ee5\u964d\u4f4e\u6210\u672c\u548c\u6570\u636e\u9650\u5236\u3002", "motivation": "\u73b0\u6709\u8ba1\u7b97\u6a21\u578b\u5728\u80fd\u6e90\u5efa\u6a21\u65b9\u9762\u867d\u7136\u5f3a\u5927\uff0c\u4f46\u5b58\u5728\u6570\u636e\u83b7\u53d6\u56f0\u96be\u3001\u6210\u672c\u9ad8\u6602\u6216\u6d89\u53ca\u9690\u79c1\u7684\u95ee\u9898\u3002\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u6a21\u5757\u5316\u7684\u591a\u6a21\u6001\u6846\u67b6\uff0c\u5229\u7528\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u4ece\u516c\u5f00\u7684\u4f4f\u5b85\u4fe1\u606f\u548c\u56fe\u50cf\u4e2d\u751f\u6210\u7814\u7a76\u6240\u9700\u7684\u6570\u636e\u3002\u5e76\u63d0\u4f9b\u4e00\u4e2a\u6f14\u793a\u8be5\u6846\u67b6\u7684\u6d41\u7a0b\uff0c\u540c\u65f6\u8bc4\u4f30\u5176\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u7ec4\u4ef6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u6210\u529f\u751f\u6210\u4e86\u903c\u771f\u4e14\u5e26\u6709\u6807\u7b7e\u7684\u6570\u636e\uff0c\u5e76\u907f\u514d\u4e86\u751f\u6210\u6a21\u578b\u5e38\u89c1\u7684\u76f8\u5173\u95ee\u9898\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u51cf\u5c11\u5bf9\u6602\u8d35\u6216\u53d7\u9650\u6570\u636e\u6e90\u7684\u4f9d\u8d56\uff0c\u4e3a\u80fd\u6e90\u5efa\u6a21\u7814\u7a76\u5f00\u8f9f\u4e86\u66f4\u6613\u4e8e\u8bbf\u95ee\u548c\u53ef\u590d\u73b0\u7684\u8def\u5f84\u3002"}}
{"id": "2509.10400", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2509.10400", "abs": "https://arxiv.org/abs/2509.10400", "authors": ["Yang Zhong", "Haoran Wu", "Xueqi Li", "Sa Wang", "David Boland", "Yungang Bao", "Kan Shi"], "title": "TurboFuzz: FPGA Accelerated Hardware Fuzzing for Processor Agile Verification", "comment": null, "summary": "Verification is a critical process for ensuring the correctness of modern\nprocessors. The increasing complexity of processor designs and the emergence of\nnew instruction set architectures (ISAs) like RISC-V have created demands for\nmore agile and efficient verification methodologies, particularly regarding\nverification efficiency and faster coverage convergence. While simulation-based\napproaches now attempt to incorporate advanced software testing techniques such\nas fuzzing to improve coverage, they face significant limitations when applied\nto processor verification, notably poor performance and inadequate test case\nquality. Hardware-accelerated solutions using FPGA or ASIC platforms have tried\nto address these issues, yet they struggle with challenges including host-FPGA\ncommunication overhead, inefficient test pattern generation, and suboptimal\nimplementation of the entire multi-step verification process.\n  In this paper, we present TurboFuzz, an end-to-end hardware-accelerated\nverification framework that implements the entire Test\nGeneration-Simulation-Coverage Feedback loop on a single FPGA for modern\nprocessor verification. TurboFuzz enhances test quality through optimized test\ncase (seed) control flow, efficient inter-seed scheduling, and hybrid fuzzer\nintegration, thereby improving coverage and execution efficiency. Additionally,\nit employs a feedback-driven generation mechanism to accelerate coverage\nconvergence. Experimental results show that TurboFuzz achieves up to 2.23x more\ncoverage collection than software-based fuzzers within the same time budget,\nand up to 571x performance speedup when detecting real-world issues, while\nmaintaining full visibility and debugging capabilities with moderate area\noverhead.", "AI": {"tldr": "TurboFuzz\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u786c\u4ef6\u52a0\u901f\u9a8c\u8bc1\u6846\u67b6\uff0c\u53ef\u5728\u5355\u4e2aFPGA\u4e0a\u4e3a\u73b0\u4ee3\u5904\u7406\u5668\u9a8c\u8bc1\u5b9e\u73b0\u5b8c\u6574\u7684\u6d4b\u8bd5\u751f\u6210-\u4eff\u771f-\u8986\u76d6\u53cd\u9988\u5faa\u73af\uff0c\u901a\u8fc7\u4f18\u5316\u7684\u79cd\u5b50\u63a7\u5236\u6d41\u3001\u9ad8\u6548\u7684\u79cd\u5b50\u8c03\u5ea6\u548c\u6df7\u5408\u6a21\u7cca\u5668\u96c6\u6210\u6765\u63d0\u9ad8\u6d4b\u8bd5\u8d28\u91cf\u3001\u8986\u76d6\u7387\u548c\u6267\u884c\u6548\u7387\uff0c\u5e76\u91c7\u7528\u53cd\u9988\u9a71\u52a8\u7684\u751f\u6210\u673a\u5236\u52a0\u901f\u8986\u76d6\u7387\u6536\u655b\u3002", "motivation": "\u73b0\u4ee3\u5904\u7406\u5668\u9a8c\u8bc1\u7684\u590d\u6742\u6027\u65e5\u76ca\u589e\u52a0\uff0c\u4ee5\u53caRISC-V\u7b49\u65b0\u6307\u4ee4\u96c6\u67b6\u6784\u7684\u51fa\u73b0\uff0c\u5bf9\u66f4\u654f\u6377\u3001\u66f4\u9ad8\u6548\u7684\u9a8c\u8bc1\u65b9\u6cd5\u63d0\u51fa\u4e86\u8981\u6c42\uff0c\u7279\u522b\u662f\u5728\u9a8c\u8bc1\u6548\u7387\u548c\u8986\u76d6\u7387\u6536\u655b\u901f\u5ea6\u65b9\u9762\u3002\u73b0\u6709\u7684\u57fa\u4e8e\u4eff\u771f\u7684\u65b9\u6cd5\u5728\u5e94\u7528\u4e8e\u5904\u7406\u5668\u9a8c\u8bc1\u65f6\u5b58\u5728\u6027\u80fd\u5dee\u548c\u6d4b\u8bd5\u7528\u4f8b\u8d28\u91cf\u4e0d\u8db3\u7b49\u95ee\u9898\u3002\u57fa\u4e8eFPGA\u6216ASIC\u7684\u786c\u4ef6\u52a0\u901f\u65b9\u6848\u5219\u9762\u4e34\u4e3b\u673a-FPGA\u901a\u4fe1\u5f00\u9500\u3001\u6d4b\u8bd5\u6a21\u5f0f\u751f\u6210\u6548\u7387\u4f4e\u4e0b\u4ee5\u53ca\u591a\u6b65\u9a8c\u8bc1\u8fc7\u7a0b\u5b9e\u73b0\u4e0d\u7406\u60f3\u7b49\u6311\u6218\u3002", "method": "TurboFuzz\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u786c\u4ef6\u52a0\u901f\u9a8c\u8bc1\u6846\u67b6\uff0c\u5728\u5355\u4e2aFPGA\u4e0a\u5b9e\u73b0\u4e86\u5b8c\u6574\u7684\u6d4b\u8bd5\u751f\u6210-\u4eff\u771f-\u8986\u76d6\u53cd\u9988\u5faa\u73af\u3002\u5b83\u901a\u8fc7\u4f18\u5316\u7684\u79cd\u5b50\u63a7\u5236\u6d41\u3001\u9ad8\u6548\u7684\u79cd\u5b50\u95f4\u8c03\u5ea6\u548c\u6df7\u5408\u6a21\u7cca\u5668\u96c6\u6210\u6765\u589e\u5f3a\u6d4b\u8bd5\u8d28\u91cf\uff0c\u4ece\u800c\u63d0\u9ad8\u8986\u76d6\u7387\u548c\u6267\u884c\u6548\u7387\u3002\u6b64\u5916\uff0c\u5b83\u91c7\u7528\u53cd\u9988\u9a71\u52a8\u7684\u751f\u6210\u673a\u5236\u6765\u52a0\u901f\u8986\u76d6\u7387\u6536\u655b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cTurboFuzz\u5728\u76f8\u540c\u7684\u65f6\u95f4\u9884\u7b97\u5185\uff0c\u8986\u76d6\u7387\u6536\u96c6\u80fd\u529b\u6bd4\u57fa\u4e8e\u8f6f\u4ef6\u7684\u6a21\u7cca\u5668\u9ad8\u51fa2.23\u500d\uff0c\u5728\u68c0\u6d4b\u771f\u5b9e\u4e16\u754c\u95ee\u9898\u65f6\u6027\u80fd\u63d0\u9ad8\u4e86571\u500d\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5b8c\u6574\u7684\u53ef\u89c1\u6027\u548c\u8c03\u8bd5\u80fd\u529b\uff0c\u4e14\u9762\u79ef\u5f00\u9500\u9002\u4e2d\u3002", "conclusion": "TurboFuzz\u901a\u8fc7\u5728\u5355\u4e2aFPGA\u4e0a\u5b9e\u73b0\u5b8c\u6574\u7684\u6d4b\u8bd5\u751f\u6210-\u4eff\u771f-\u8986\u76d6\u53cd\u9988\u5faa\u73af\uff0c\u5e76\u91c7\u7528\u4e00\u7cfb\u5217\u4f18\u5316\u6280\u672f\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5904\u7406\u5668\u9a8c\u8bc1\u7684\u6548\u7387\u548c\u8986\u76d6\u7387\u6536\u655b\u901f\u5ea6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2509.09812", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.09812", "abs": "https://arxiv.org/abs/2509.09812", "authors": ["Xiuzhen Ye", "Wentao Tang"], "title": "EDMD-Based Robust Observer Synthesis for Nonlinear Systems", "comment": "6 pages, 3 figures. Submitted to IEEE CSS and ACC2026", "summary": "This paper presents a data driven Koopman operator based framework for\ndesigning robust state observers for nonlinear systems. Based on a finite\ndimensional surrogate of the Koopman generator, identified via an extended\ndynamic mode decomposition procedure, a tractable formulation of the observer\ndesign is enabled on the data driven model with conic uncertainties. The\nresulting problem is cast as a semidefinite program with linear matrix\ninequalities, guaranteeing exponential convergence of the observer with a\npredetermined rate in a probabilistic sense. The approach bridges the gap\nbetween statistical error tolerance and observer convergence certification, and\nenables an explicit use of linear systems theory for state observation via a\ndata driven linear surrogate model. Numerical studies demonstrate the\neffectiveness and flexibility of the proposed method.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6570\u636e\u9a71\u52a8\u7684Koopman\u7b97\u5b50\u6846\u67b6\uff0c\u7528\u4e8e\u8bbe\u8ba1\u975e\u7ebf\u6027\u7cfb\u7edf\u7684\u9c81\u68d2\u72b6\u6001\u89c2\u6d4b\u5668\u3002\u901a\u8fc7\u6269\u5c55\u52a8\u6001\u6a21\u6001\u5206\u89e3\u8bc6\u522b\u6709\u9650\u7ef4Koopman\u751f\u6210\u5668\u4ee3\u7406\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u6570\u636e\u9a71\u52a8\u6a21\u578b\u4e0a\u7684\u53ef\u89e3\u89c2\u6d4b\u5668\u8bbe\u8ba1\uff0c\u5e76\u5f15\u5165\u4e86\u5706\u9525\u4e0d\u786e\u5b9a\u6027\u3002\u8be5\u95ee\u9898\u88ab\u8f6c\u5316\u4e3a\u4e00\u4e2a\u534a\u5b9a\u89c4\u5212\u95ee\u9898\uff0c\u5305\u542b\u7ebf\u6027\u77e9\u9635\u4e0d\u7b49\u5f0f\uff0c\u80fd\u5728\u6982\u7387\u610f\u4e49\u4e0a\u4fdd\u8bc1\u89c2\u6d4b\u5668\u4ee5\u9884\u5b9a\u901f\u7387\u6307\u6570\u6536\u655b\u3002\u8be5\u65b9\u6cd5\u5f25\u5408\u4e86\u7edf\u8ba1\u8bef\u5dee\u5bb9\u9650\u4e0e\u89c2\u6d4b\u5668\u6536\u655b\u8ba4\u8bc1\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u5e76\u80fd\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u7684\u7ebf\u6027\u4ee3\u7406\u6a21\u578b\u663e\u5f0f\u5e94\u7528\u7ebf\u6027\u7cfb\u7edf\u7406\u8bba\u8fdb\u884c\u72b6\u6001\u89c2\u6d4b\u3002\u6570\u503c\u7814\u7a76\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u7075\u6d3b\u6027\u3002", "motivation": "\u4e3a\u975e\u7ebf\u6027\u7cfb\u7edf\u7684\u9c81\u68d2\u72b6\u6001\u89c2\u6d4b\u5668\u8bbe\u8ba1\u63d0\u4f9b\u4e00\u79cd\u65b0\u7684\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\uff0c\u5229\u7528Koopman\u7b97\u5b50\u7406\u8bba\u5904\u7406\u975e\u7ebf\u6027\u7cfb\u7edf\uff0c\u5e76\u901a\u8fc7\u534a\u5b9a\u89c4\u5212\u4fdd\u8bc1\u6536\u655b\u6027\u3002", "method": "1. \u5229\u7528\u6269\u5c55\u52a8\u6001\u6a21\u6001\u5206\u89e3\uff08EDMD\uff09\u8bc6\u522b\u975e\u7ebf\u6027\u7cfb\u7edf\u7684\u6709\u9650\u7ef4Koopman\u751f\u6210\u5668\u4ee3\u7406\u6a21\u578b\u3002\n2. \u5728\u6b64\u6570\u636e\u9a71\u52a8\u7684\u7ebf\u6027\u6a21\u578b\u4e0a\uff0c\u7ed3\u5408\u5706\u9525\u4e0d\u786e\u5b9a\u6027\uff0c\u6784\u5efa\u89c2\u6d4b\u5668\u8bbe\u8ba1\u95ee\u9898\u3002\n3. \u5c06\u89c2\u6d4b\u5668\u8bbe\u8ba1\u95ee\u9898\u8f6c\u5316\u4e3a\u4e00\u4e2a\u5305\u542b\u7ebf\u6027\u77e9\u9635\u4e0d\u7b49\u5f0f\u7684\u534a\u5b9a\u89c4\u5212\uff08SDP\uff09\u95ee\u9898\u3002", "result": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u5728\u6982\u7387\u610f\u4e49\u4e0a\u4fdd\u8bc1\u89c2\u6d4b\u5668\u4ee5\u9884\u5b9a\u7684\u6307\u6570\u6536\u655b\u901f\u7387\u6536\u655b\uff0c\u5f25\u5408\u4e86\u7edf\u8ba1\u8bef\u5dee\u5bb9\u9650\u548c\u89c2\u6d4b\u5668\u6536\u655b\u8ba4\u8bc1\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "conclusion": "\u8be5\u6570\u636e\u9a71\u52a8\u7684Koopman\u7b97\u5b50\u65b9\u6cd5\u4e3a\u8bbe\u8ba1\u975e\u7ebf\u6027\u7cfb\u7edf\u7684\u9c81\u68d2\u72b6\u6001\u89c2\u6d4b\u5668\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u4e14\u7075\u6d3b\u7684\u9014\u5f84\uff0c\u80fd\u591f\u663e\u5f0f\u5229\u7528\u7ebf\u6027\u7cfb\u7edf\u7406\u8bba\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2509.09915", "categories": ["cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2509.09915", "abs": "https://arxiv.org/abs/2509.09915", "authors": ["Woong Shin", "Renan Souza", "Daniel Rosendo", "Fr\u00e9d\u00e9ric Suter", "Feiyi Wang", "Prasanna Balaprakash", "Rafael Ferreira da Silva"], "title": "The (R)evolution of Scientific Workflows in the Agentic AI Era: Towards Autonomous Science", "comment": null, "summary": "Modern scientific discovery increasingly requires coordinating distributed\nfacilities and heterogeneous resources, forcing researchers to act as manual\nworkflow coordinators rather than scientists. Advances in AI leading to AI\nagents show exciting new opportunities that can accelerate scientific discovery\nby providing intelligence as a component in the ecosystem. However, it is\nunclear how this new capability would materialize and integrate in the real\nworld. To address this, we propose a conceptual framework where workflows\nevolve along two dimensions which are intelligence (from static to intelligent)\nand composition (from single to swarm) to chart an evolutionary path from\ncurrent workflow management systems to fully autonomous, distributed scientific\nlaboratories. With these trajectories in mind, we present an architectural\nblueprint that can help the community take the next steps towards harnessing\nthe opportunities in autonomous science with the potential for 100x discovery\nacceleration and transformational scientific workflows.", "AI": {"tldr": "AI\u4ee3\u7406\u53ef\u4ee5\u52a0\u901f\u79d1\u5b66\u53d1\u73b0\uff0c\u4f46\u5176\u96c6\u6210\u65b9\u5f0f\u5c1a\u4e0d\u6e05\u695a\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u6846\u67b6\uff0c\u5c06\u5de5\u4f5c\u6d41\u7684\u667a\u80fd\u548c\u7ec4\u5408\u4f5c\u4e3a\u6f14\u8fdb\u7684\u7ef4\u5ea6\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u67b6\u6784\u84dd\u56fe\uff0c\u4ee5\u5b9e\u73b0\u5b8c\u5168\u81ea\u4e3b\u7684\u79d1\u5b66\u5b9e\u9a8c\u5ba4\u3002", "motivation": "\u76ee\u524d\u7684\u79d1\u5b66\u53d1\u73b0\u9700\u8981\u534f\u8c03\u5206\u5e03\u5f0f\u8bbe\u65bd\u548c\u5f02\u6784\u8d44\u6e90\uff0c\u4f7f\u7814\u7a76\u4eba\u5458\u627f\u62c5\u624b\u52a8\u5de5\u4f5c\u6d41\u534f\u8c03\u7684\u89d2\u8272\uff0c\u800c\u4e0d\u662f\u4e13\u6ce8\u4e8e\u79d1\u5b66\u672c\u8eab\u3002AI\u4ee3\u7406\u7684\u51fa\u73b0\u4e3a\u901a\u8fc7\u63d0\u4f9b\u667a\u80fd\u7ec4\u4ef6\u6765\u52a0\u901f\u79d1\u5b66\u53d1\u73b0\u63d0\u4f9b\u4e86\u65b0\u7684\u673a\u4f1a\uff0c\u4f46\u5176\u5177\u4f53\u5b9e\u73b0\u548c\u96c6\u6210\u65b9\u5f0f\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u6982\u5ff5\u6846\u67b6\uff0c\u5c06\u5de5\u4f5c\u6d41\u6cbf\u7740\u4e24\u4e2a\u7ef4\u5ea6\u8fdb\u884c\u6f14\u5316\uff1a\u667a\u80fd\uff08\u4ece\u9759\u6001\u5230\u667a\u80fd\uff09\u548c\u7ec4\u5408\uff08\u4ece\u5355\u4e00\u5230\u7fa4\u4f53\uff09\u3002\u57fa\u4e8e\u8fd9\u4e9b\u8f68\u8ff9\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u67b6\u6784\u84dd\u56fe\u3002", "result": "\u8be5\u6846\u67b6\u548c\u84dd\u56fe\u4e3a\u793e\u533a\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6f14\u8fdb\u8def\u5f84\uff0c\u4ece\u73b0\u6709\u7684\u5de5\u4f5c\u6d41\u7ba1\u7406\u7cfb\u7edf\u8fc8\u5411\u5b8c\u5168\u81ea\u4e3b\u7684\u5206\u5e03\u5f0f\u79d1\u5b66\u5b9e\u9a8c\u5ba4\u3002", "conclusion": "\u901a\u8fc7\u5c06\u5de5\u4f5c\u6d41\u671d\u7740\u66f4\u667a\u80fd\u548c\u66f4\u5177\u7ec4\u5408\u6027\u7684\u65b9\u5411\u6f14\u8fdb\uff0c\u53ef\u4ee5\u5b9e\u73b0\u79d1\u5b66\u53d1\u73b0\u7684\u6307\u6570\u7ea7\u52a0\u901f\uff08100\u500d\uff09\u548c\u79d1\u5b66\u5de5\u4f5c\u6d41\u7684\u53d8\u9769\u3002"}}
{"id": "2509.09730", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09730", "abs": "https://arxiv.org/abs/2509.09730", "authors": ["Kaikai Zhao", "Zhaoxiang Liu", "Peng Wang", "Xin Wang", "Zhicheng Ma", "Yajun Xu", "Wenjing Zhang", "Yibing Nan", "Kai Wang", "Shiguo Lian"], "title": "MITS: A Large-Scale Multimodal Benchmark Dataset for Intelligent Traffic Surveillance", "comment": "accepted by Image and Vision Computing", "summary": "General-domain large multimodal models (LMMs) have achieved significant\nadvances in various image-text tasks. However, their performance in the\nIntelligent Traffic Surveillance (ITS) domain remains limited due to the\nabsence of dedicated multimodal datasets. To address this gap, we introduce\nMITS (Multimodal Intelligent Traffic Surveillance), the first large-scale\nmultimodal benchmark dataset specifically designed for ITS. MITS includes\n170,400 independently collected real-world ITS images sourced from traffic\nsurveillance cameras, annotated with eight main categories and 24 subcategories\nof ITS-specific objects and events under diverse environmental conditions.\nAdditionally, through a systematic data generation pipeline, we generate\nhigh-quality image captions and 5 million instruction-following visual\nquestion-answer pairs, addressing five critical ITS tasks: object and event\nrecognition, object counting, object localization, background analysis, and\nevent reasoning. To demonstrate MITS's effectiveness, we fine-tune mainstream\nLMMs on this dataset, enabling the development of ITS-specific applications.\nExperimental results show that MITS significantly improves LMM performance in\nITS applications, increasing LLaVA-1.5's performance from 0.494 to 0.905\n(+83.2%), LLaVA-1.6's from 0.678 to 0.921 (+35.8%), Qwen2-VL's from 0.584 to\n0.926 (+58.6%), and Qwen2.5-VL's from 0.732 to 0.930 (+27.0%). We release the\ndataset, code, and models as open-source, providing high-value resources to\nadvance both ITS and LMM research.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86MITS\uff0c\u4e00\u4e2a\u4e13\u95e8\u4e3a\u667a\u80fd\u4ea4\u901a\u76d1\u63a7\uff08ITS\uff09\u9886\u57df\u8bbe\u8ba1\u7684\u5927\u89c4\u6a21\u591a\u6a21\u6001\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5305\u542b\u4e86170,400\u5f20\u771f\u5b9e\u4e16\u754c\u7684ITS\u56fe\u50cf\u548c\u76f8\u5e94\u7684\u6ce8\u91ca\u3001\u56fe\u50cf\u63cf\u8ff0\u4ee5\u53ca\u89c6\u89c9\u95ee\u7b54\u5bf9\uff0c\u65e8\u5728\u89e3\u51b3ITS\u9886\u57df\u7f3a\u4e4f\u4e13\u7528\u591a\u6a21\u6001\u6570\u636e\u96c6\u7684\u95ee\u9898\u3002\u901a\u8fc7\u5728\u8be5\u6570\u636e\u96c6\u4e0a\u5fae\u8c03\u4e3b\u6d41\u7684\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\uff08LMMs\uff09\uff0c\u5b9e\u9a8c\u8bc1\u660eMITS\u663e\u8457\u63d0\u9ad8\u4e86LMM\u5728ITS\u5e94\u7528\u4e2d\u7684\u6027\u80fd\u3002", "motivation": "\u667a\u80fd\u4ea4\u901a\u76d1\u63a7\uff08ITS\uff09\u9886\u57df\u7f3a\u4e4f\u4e13\u95e8\u7684\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u9650\u5236\u4e86\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\uff08LMMs\uff09\u5728\u8be5\u9886\u57df\u7684\u6027\u80fd\u53d1\u6325\u3002", "method": "\u521b\u5efa\u4e86\u4e00\u4e2a\u540d\u4e3aMITS\u7684\u5927\u89c4\u6a21\u591a\u6a21\u6001\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5305\u542b170,400\u5f20ITS\u56fe\u50cf\uff0c\u5e76\u6807\u6ce8\u4e868\u4e2a\u4e3b\u8981\u7c7b\u522b\u548c24\u4e2a\u5b50\u7c7b\u522b\u7684ITS\u7279\u5b9a\u5bf9\u8c61\u548c\u4e8b\u4ef6\u3002\u540c\u65f6\uff0c\u751f\u6210\u4e86\u9ad8\u8d28\u91cf\u7684\u56fe\u50cf\u63cf\u8ff0\u548c500\u4e07\u4e2a\u89c6\u89c9\u95ee\u7b54\u5bf9\uff0c\u6db5\u76d6\u4e86\u5bf9\u8c61\u8bc6\u522b\u3001\u8ba1\u6570\u3001\u5b9a\u4f4d\u3001\u80cc\u666f\u5206\u6790\u548c\u4e8b\u4ef6\u63a8\u7406\u4e94\u4e2a\u5173\u952eITS\u4efb\u52a1\u3002\u6700\u540e\uff0c\u5728MITS\u6570\u636e\u96c6\u4e0a\u5bf9\u4e3b\u6d41LMMs\u8fdb\u884c\u4e86\u5fae\u8c03\uff0c\u4ee5\u8bc4\u4f30\u6570\u636e\u96c6\u7684\u6709\u6548\u6027\u3002", "result": "\u5728MITS\u6570\u636e\u96c6\u4e0a\u5fae\u8c03\u540e\uff0cLLaVA-1.5\u7684\u6027\u80fd\u4ece0.494\u63d0\u5347\u81f30.905\uff08+83.2%\uff09\uff0cLLaVA-1.6\u4ece0.678\u63d0\u5347\u81f30.921\uff08+35.8%\uff09\uff0cQwen2-VL\u4ece0.584\u63d0\u5347\u81f30.926\uff08+58.6%\uff09\uff0cQwen2.5-VL\u4ece0.732\u63d0\u5347\u81f30.930\uff08+27.0%\uff09\uff0c\u663e\u8457\u8bc1\u660e\u4e86MITS\u6570\u636e\u96c6\u7684\u6709\u6548\u6027\u3002", "conclusion": "MITS\u4f5c\u4e3a\u9996\u4e2a\u5927\u89c4\u6a21ITS\u591a\u6a21\u6001\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u63d0\u4f9b\u4e30\u5bcc\u7684\u6807\u6ce8\u6570\u636e\u548c\u5b9e\u4f8b\uff0c\u6709\u6548\u63d0\u5347\u4e86LMM\u5728ITS\u9886\u57df\u7684\u6027\u80fd\uff0c\u4e3a\u8be5\u9886\u57df\u7684\u7814\u7a76\u548c\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9d\u8d35\u7684\u8d44\u6e90\u3002\u7814\u7a76\u56e2\u961f\u5df2\u5c06\u6570\u636e\u96c6\u3001\u4ee3\u7801\u548c\u6a21\u578b\u5f00\u6e90\uff0c\u4ee5\u4fc3\u8fdbITS\u548cLMM\u7684\u5171\u540c\u53d1\u5c55\u3002"}}
{"id": "2509.10028", "categories": ["cond-mat.mes-hall", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2509.10028", "abs": "https://arxiv.org/abs/2509.10028", "authors": ["Tatsuki Muto", "Masahito Mochizuki"], "title": "Switching magnetic texture via in-plane magnetic field in noncentrosymmetric dipolar magnets: From skyrmions to antiskyrmions and nontopological magnetic bubbles", "comment": "14 pages, 9 figures", "summary": "We theoretically investigate field-induced switching of magnetic topology in\na nanodisk-shaped sample of noncentrosymmetric dipolar magnet in which the\nDzyaloshinskii-Moriya interaction that stabilizes an antiskyrmion with $N_{\\rm\nsk}$=+1 and the magnetic dipole interaction that stabilizes a skyrmion with\n$N_{\\rm sk}$=$-1$ are in keen competition where $N_{\\rm sk}$ is the skyrmion\nnumber. Our micromagnetic simulations demonstrate that the competition offers a\nunique opportunity to switch magnetic textures with distinct magnetic topology\namong the antiskyrmion ($N_{\\rm sk}$=+1), elliptical skyrmion ($N_{\\rm\nsk}$=$-1$), and nontopological bubble ($N_{\\rm sk}$=0) in a deterministic\nmanner by application of magnetic fields parallel to the sample plane. By\ncalculating time and spatial profiles of energy contributions from respective\ninteractions and magnetic anisotropy, we clarify the physical mechanism and\nproperties of the observed field-induced topology switching phenomena. Our\nfindings are expected to provide useful insights into the spintronic\napplication of topological magnetism.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u975e\u4e2d\u5fc3\u5bf9\u79f0\u4e8c\u6781\u78c1\u4f53\u4e2d\u7531\u573a\u8bf1\u5bfc\u7684\u78c1\u62d3\u6251\u5207\u6362\u73b0\u8c61\u3002", "motivation": "\u7814\u7a76\u975e\u4e2d\u5fc3\u5bf9\u79f0\u4e8c\u6781\u78c1\u4f53\u4e2d\u78c1\u7574\u7ed3\u6784\u7684\u884c\u4e3a\uff0c\u7279\u522b\u662f\u62d3\u6251\u7eb9\u7406\u7684\u5207\u6362\u3002", "method": "\u5229\u7528\u5fae\u78c1\u6a21\u62df\u548c\u80fd\u91cf\u8d21\u732e\u5206\u6790\uff0c\u7814\u7a76\u4e86\u78c1\u7574\u7ed3\u6784\uff08\u53cd\u65af\u683c\u660e\u5b50\u3001\u692d\u5706\u65af\u683c\u660e\u5b50\u3001\u975e\u62d3\u6251\u78c1\u6ce1\uff09\u5728\u5916\u90e8\u78c1\u573a\u4f5c\u7528\u4e0b\u7684\u884c\u4e3a\u3002", "result": "\u5b9e\u73b0\u4e86\u901a\u8fc7\u5e73\u884c\u4e8e\u6837\u54c1\u5e73\u9762\u7684\u78c1\u573a\uff0c\u786e\u5b9a\u6027\u5730\u5207\u6362\u53cd\u65af\u683c\u660e\u5b50\uff08Nsk=+1\uff09\u3001\u692d\u5706\u65af\u683c\u660e\u5b50\uff08Nsk=-1\uff09\u548c\u975e\u62d3\u6251\u78c1\u6ce1\uff08Nsk=0\uff09\u4e4b\u95f4\u7684\u78c1\u62d3\u6251\u3002", "conclusion": "\u7814\u7a76\u9610\u660e\u4e86\u573a\u8bf1\u5bfc\u7684\u78c1\u62d3\u6251\u5207\u6362\u73b0\u8c61\u7684\u7269\u7406\u673a\u5236\u548c\u7279\u6027\uff0c\u5e76\u4e3a\u62d3\u6251\u78c1\u5b66\u5728\u81ea\u65cb\u7535\u5b50\u5b66\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u53c2\u8003\u3002"}}
{"id": "2509.09893", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09893", "abs": "https://arxiv.org/abs/2509.09893", "authors": ["Hanbit Oh", "Masaki Murooka", "Tomohiro Motoda", "Ryoichi Nakajo", "Yukiyasu Domae"], "title": "Self-Augmented Robot Trajectory: Efficient Imitation Learning via Safe Self-augmentation with Demonstrator-annotated Precision", "comment": "Under review", "summary": "Imitation learning is a promising paradigm for training robot agents;\nhowever, standard approaches typically require substantial data acquisition --\nvia numerous demonstrations or random exploration -- to ensure reliable\nperformance. Although exploration reduces human effort, it lacks safety\nguarantees and often results in frequent collisions -- particularly in\nclearance-limited tasks (e.g., peg-in-hole) -- thereby, necessitating manual\nenvironmental resets and imposing additional human burden. This study proposes\nSelf-Augmented Robot Trajectory (SART), a framework that enables policy\nlearning from a single human demonstration, while safely expanding the dataset\nthrough autonomous augmentation. SART consists of two stages: (1) human\nteaching only once, where a single demonstration is provided and precision\nboundaries -- represented as spheres around key waypoints -- are annotated,\nfollowed by one environment reset; (2) robot self-augmentation, where the robot\ngenerates diverse, collision-free trajectories within these boundaries and\nreconnects to the original demonstration. This design improves the data\ncollection efficiency by minimizing human effort while ensuring safety.\nExtensive evaluations in simulation and real-world manipulation tasks show that\nSART achieves substantially higher success rates than policies trained solely\non human-collected demonstrations. Video results available at\nhttps://sites.google.com/view/sart-il .", "AI": {"tldr": "SART\u6846\u67b6\u901a\u8fc7\u5355\u6b21\u4eba\u7c7b\u6f14\u793a\u548c\u5b89\u5168\u81ea\u4e3b\u6570\u636e\u589e\u5f3a\uff0c\u63d0\u9ad8\u4e86\u673a\u5668\u4eba\u6a21\u4eff\u5b66\u4e60\u7684\u6570\u636e\u6548\u7387\u548c\u6210\u529f\u7387\u3002", "motivation": "\u6807\u51c6\u7684\u6a21\u4eff\u5b66\u4e60\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u6570\u636e\uff0c\u800c\u81ea\u4e3b\u63a2\u7d22\u7f3a\u4e4f\u5b89\u5168\u4fdd\u969c\u4e14\u6613\u53d1\u751f\u78b0\u649e\uff0c\u589e\u52a0\u4e86\u4eba\u7c7b\u8d1f\u62c5\u3002", "method": "SART\u6846\u67b6\u5305\u542b\u4e24\u4e2a\u9636\u6bb5\uff1a1. \u4eba\u7c7b\u4ec5\u6559\u6388\u4e00\u6b21\uff0c\u5e76\u6807\u6ce8\u5173\u952e\u8def\u5f84\u70b9\u7684\u7cbe\u5ea6\u8fb9\u754c\uff08\u7403\u4f53\uff09\uff1b2. \u673a\u5668\u4eba\u81ea\u4e3b\u751f\u6210\u5728\u8fd9\u4e9b\u8fb9\u754c\u5185\u65e0\u78b0\u649e\u7684\u8f68\u8ff9\uff0c\u5e76\u91cd\u65b0\u8fde\u63a5\u5230\u539f\u59cb\u6f14\u793a\u3002", "result": "\u4e0e\u4ec5\u4f7f\u7528\u4eba\u7c7b\u6536\u96c6\u7684\u6f14\u793a\u8fdb\u884c\u8bad\u7ec3\u7684\u7b56\u7565\u76f8\u6bd4\uff0cSART\u5728\u6a21\u62df\u548c\u73b0\u5b9e\u4e16\u754c\u7684\u64cd\u7eb5\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u66f4\u9ad8\u7684\u6210\u529f\u7387\u3002", "conclusion": "SART\u6846\u67b6\u901a\u8fc7\u6700\u5c0f\u5316\u4eba\u7c7b\u7cbe\u529b\u5e76\u786e\u4fdd\u5b89\u5168\uff0c\u63d0\u9ad8\u4e86\u6570\u636e\u6536\u96c6\u6548\u7387\uff0c\u5e76\u5728\u673a\u5668\u4eba\u6a21\u4eff\u5b66\u4e60\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2509.09813", "categories": ["quant-ph", "cs.CC", "cs.DS"], "pdf": "https://arxiv.org/pdf/2509.09813", "abs": "https://arxiv.org/abs/2509.09813", "authors": ["Amira Abbas", "Nunzia Cerrato", "Francisco Escudero Guti\u00e9rrez", "Dmitry Grinko", "Francesco Anna Mele", "Pulkit Sinha"], "title": "Nearly optimal algorithms to learn sparse quantum Hamiltonians in physically motivated distances", "comment": "35 pages, 1 figure", "summary": "We study the problem of learning Hamiltonians $H$ that are $s$-sparse in the\nPauli basis, given access to their time evolution. Although Hamiltonian\nlearning has been extensively investigated, two issues recur in much of the\nexisting literature: the absence of matching lower bounds and the use of\nmathematically convenient but physically opaque error measures.\n  We address both challenges by introducing two physically motivated distances\nbetween Hamiltonians and designing a nearly optimal algorithm with respect to\none of these metrics. The first, time-constrained distance, quantifies\ndistinguishability through dynamical evolution up to a bounded time. The\nsecond, temperature-constrained distance, captures distinguishability through\nthermal states at bounded inverse temperatures.\n  We show that $s$-sparse Hamiltonians with bounded operator norm can be\nlearned in both distances with $O(s \\log(1/\\epsilon))$ experiments and\n$O(s^2/\\epsilon)$ evolution time. For the time-constrained distance, we further\nestablish lower bounds of $\\Omega((s/n)\\log(1/\\epsilon) + s)$ experiments and\n$\\Omega(\\sqrt{s}/\\epsilon)$ evolution time, demonstrating near-optimality in\nthe number of experiments.\n  As an intermediate result, we obtain an algorithm that learns every Pauli\ncoefficient of $s$-sparse Hamiltonians up to error $\\epsilon$ in\n$O(s\\log(1/\\epsilon))$ experiments and $O(s/\\epsilon)$ evolution time,\nimproving upon several recent results.\n  The source of this improvement is a new isolation technique, inspired by the\nValiant-Vazirani theorem (STOC'85), which shows that NP is as easy as detecting\nunique solutions. This isolation technique allows us to query the time\nevolution of a single Pauli coefficient of a sparse Hamiltonian--even when the\nPauli support of the Hamiltonian is unknown--ultimately enabling us to recover\nthe Pauli support itself.", "AI": {"tldr": "\u8be5\u7814\u7a76\u89e3\u51b3\u4e86\u5b66\u4e60 Pauli \u57fa\u7840\u4e0a s-\u7a00\u758f\u7684\u54c8\u5bc6\u987f\u91cf H \u7684\u95ee\u9898\uff0c\u5e76\u8003\u8651\u4e86\u5176\u65f6\u95f4\u6f14\u5316\u3002\u7814\u7a76\u8005\u63d0\u51fa\u4e86\u4e24\u79cd\u7269\u7406\u4e0a\u5408\u7406\u7684\u65b9\u6cd5\u6765\u8861\u91cf\u54c8\u5bc6\u987f\u91cf\u4e4b\u95f4\u7684\u8ddd\u79bb\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u79cd\u63a5\u8fd1\u6700\u4f18\u7684\u7b97\u6cd5\u3002", "motivation": "\u73b0\u6709\u54c8\u5bc6\u987f\u91cf\u5b66\u4e60\u7814\u7a76\u4e2d\u5b58\u5728\u5339\u914d\u4e0b\u754c\u7f3a\u5931\u548c\u4f7f\u7528\u4e0d\u76f4\u89c2\u7684\u8bef\u5dee\u5ea6\u91cf\u7684\u95ee\u9898\u3002\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u7814\u7a76\u8005\u63d0\u51fa\u4e86\u4e24\u79cd\u8861\u91cf\u54c8\u5bc6\u987f\u91cf\u4e4b\u95f4\u8ddd\u79bb\u7684\u65b9\u6cd5\uff1a\u65f6\u95f4\u7ea6\u675f\u8ddd\u79bb\uff08\u901a\u8fc7\u6709\u754c\u65f6\u95f4\u5185\u7684\u52a8\u529b\u5b66\u6f14\u5316\u91cf\u5316\u53ef\u533a\u5206\u6027\uff09\u548c\u6e29\u5ea6\u7ea6\u675f\u8ddd\u79bb\uff08\u901a\u8fc7\u6709\u754c\u53cd\u6e29\u4e0b\u7684\u70ed\u6001\u6355\u83b7\u53ef\u533a\u5206\u6027\uff09\u3002\u57fa\u4e8e\u8fd9\u4e9b\u8ddd\u79bb\uff0c\u8bbe\u8ba1\u4e86\u8fd1\u4e4e\u6700\u4f18\u7684\u7b97\u6cd5\u3002", "result": "\u5728\u65f6\u95f4\u7ea6\u675f\u8ddd\u79bb\u548c\u6e29\u5ea6\u7ea6\u675f\u8ddd\u79bb\u4e0b\uff0c\u5b66\u4e60 s-\u7a00\u758f\u4e14\u7b97\u5b50\u8303\u6570\u6709\u754c\u7684\u54c8\u5bc6\u987f\u91cf\uff0c\u5b9e\u9a8c\u6b21\u6570\u4e3a O(s log(1/\u03b5))\uff0c\u6f14\u5316\u65f6\u95f4\u4e3a O(s^2/\u03b5)\u3002\u5bf9\u4e8e\u65f6\u95f4\u7ea6\u675f\u8ddd\u79bb\uff0c\u5b9e\u9a8c\u6b21\u6570\u7684\u4e0b\u754c\u4e3a \u03a9((s/n)log(1/\u03b5) + s)\uff0c\u6f14\u5316\u65f6\u95f4\u7684\u4e0b\u754c\u4e3a \u03a9(\u221as/\u03b5)\uff0c\u8bc1\u660e\u4e86\u5b9e\u9a8c\u6b21\u6570\u7684\u8fd1\u4e4e\u6700\u4f18\u6027\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8005\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u5b66\u4e60\u5355\u4e2a Pauli \u7cfb\u6570\u7684\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u6b21\u6570\u4e3a O(s log(1/\u03b5))\uff0c\u6f14\u5316\u65f6\u95f4\u4e3a O(s/\u03b5)\uff0c\u6539\u8fdb\u4e86\u73b0\u6709\u7ed3\u679c\u3002", "conclusion": "\u672c\u7814\u7a76\u901a\u8fc7\u5f15\u5165\u65b0\u7684\u7269\u7406\u610f\u4e49\u4e0a\u7684\u8ddd\u79bb\u5ea6\u91cf\u548c\u521b\u65b0\u7684\u9694\u79bb\u6280\u672f\uff0c\u5728\u54c8\u5bc6\u987f\u91cf\u5b66\u4e60\u9886\u57df\u53d6\u5f97\u4e86\u91cd\u8981\u8fdb\u5c55\uff0c\u7279\u522b\u662f\u5728\u5b66\u4e60 s-\u7a00\u758f\u54c8\u5bc6\u987f\u91cf\u65b9\u9762\uff0c\u7b97\u6cd5\u5728\u5b9e\u9a8c\u6b21\u6570\u548c\u6f14\u5316\u65f6\u95f4\u4e0a\u90fd\u63a5\u8fd1\u6700\u4f18\u3002"}}
{"id": "2509.10336", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2509.10336", "abs": "https://arxiv.org/abs/2509.10336", "authors": ["Kirill Solovev", "Chiara Drolsbach", "Emma Demirel", "Nicolas Pr\u00f6llochs"], "title": "TikTok Rewards Divisive Political Messaging During the 2025 German Federal Election", "comment": null, "summary": "Short-form video platforms like TikTok reshape how politicians communicate\nand have become important tools for electoral campaigning. Yet it remains\nunclear what kinds of political messages gain traction in these fast-paced,\nalgorithmically curated environments, which are particularly popular among\nyounger audiences. In this study, we use computational content analysis to\nanalyze a comprehensive dataset of N=25,292 TikTok videos posted by German\npoliticians in the run-up to the 2025 German federal election. Our empirical\nanalysis shows that videos expressing negative emotions (e.g., anger, disgust)\nand outgroup animosity were significantly more likely to generate engagement\nthan those emphasizing positive emotion, relatability, or identity.\nFurthermore, ideologically extreme parties (on both sides of the political\nspectrum) were both more likely to post this type of content and more\nsuccessful in generating engagement than centrist parties. Taken together,\nthese findings suggest that TikTok's platform dynamics systematically reward\ndivisive over unifying political communication, thereby potentially benefiting\nextreme actors more inclined to capitalize on this logic.", "AI": {"tldr": "TikTok\u4e0a\u7684\u653f\u6cbb\u4fe1\u606f\uff0c\u5c24\u5176\u662f\u8d1f\u9762\u60c5\u7eea\u548c\u653b\u51fb\u6027\u8a00\u8bba\uff0c\u66f4\u5bb9\u6613\u83b7\u5f97\u5173\u6ce8\uff0c\u8fd9\u53ef\u80fd\u6709\u5229\u4e8e\u6781\u7aef\u653f\u515a\u3002", "motivation": "\u7814\u7a76TikTok\u7b49\u77ed\u89c6\u9891\u5e73\u53f0\u5982\u4f55\u91cd\u5851\u653f\u6cbb\u4f20\u64ad\uff0c\u4ee5\u53ca\u54ea\u7c7b\u653f\u6cbb\u4fe1\u606f\u5728\u6b64\u7c7b\u5e73\u53f0\u4e0a\u66f4\u5bb9\u6613\u83b7\u5f97\u5173\u6ce8\uff0c\u7279\u522b\u662f\u53d7\u5e74\u8f7b\u53d7\u4f17\u6b22\u8fce\u7684\u5e73\u53f0\u3002", "method": "\u4f7f\u7528\u8ba1\u7b97\u5185\u5bb9\u5206\u6790\u65b9\u6cd5\uff0c\u5206\u6790\u4e862025\u5e74\u5fb7\u56fd\u8054\u90a6\u5927\u9009\u524d\u5fb7\u56fd\u653f\u754c\u4eba\u58eb\u53d1\u5e03\u768425,292\u4e2aTikTok\u89c6\u9891\u6570\u636e\u96c6\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u8868\u8fbe\u8d1f\u9762\u60c5\u7eea\uff08\u5982\u6124\u6012\u3001\u538c\u6076\uff09\u548c\u7fa4\u4f53\u654c\u5bf9\u7684\u89c6\u9891\u6bd4\u8868\u8fbe\u79ef\u6781\u60c5\u7eea\u3001\u4eb2\u548c\u529b\u6216\u8eab\u4efd\u8ba4\u540c\u7684\u89c6\u9891\u66f4\u80fd\u4ea7\u751f\u4e92\u52a8\u3002\u6b64\u5916\uff0c\u653f\u6cbb\u5149\u8c31\u4e24\u7aef\u7684\u6781\u7aef\u653f\u515a\u6bd4\u4e2d\u95f4\u653f\u515a\u66f4\u6709\u53ef\u80fd\u53d1\u5e03\u6b64\u7c7b\u5185\u5bb9\uff0c\u5e76\u66f4\u6210\u529f\u5730\u83b7\u5f97\u4e92\u52a8\u3002", "conclusion": "TikTok\u7684\u5e73\u53f0\u52a8\u6001\u7cfb\u7edf\u6027\u5730\u5956\u52b1\u5206\u88c2\u800c\u975e\u56e2\u7ed3\u7684\u653f\u6cbb\u4f20\u64ad\uff0c\u8fd9\u53ef\u80fd\u4f7f\u66f4\u503e\u5411\u4e8e\u5229\u7528\u8fd9\u79cd\u903b\u8f91\u7684\u6781\u7aef\u5206\u5b50\u53d7\u76ca\u3002"}}
{"id": "2509.10322", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2509.10322", "abs": "https://arxiv.org/abs/2509.10322", "authors": ["Victor Barroso-Nascimento", "German Mejia"], "title": "Effects of the Strict-Tolerant Approach on Intuitionistic and Minimal Logic", "comment": null, "summary": "This paper extends the literature on the strict-tolerant logical approach by\napplying its methods to intuitionistic and minimal logic. In short, the\nstrict-tolerant approach modifies the usual notion of logical consequence by\nstipulating that, in order for an inference to be valid, from the truth of the\npremises must follow the non-falsity of the conclusion. This notion can also be\ngeneralized to define strict-tolerant metainferences, metametainferences and so\non, which may or may not generate logics distinct from those obtained on the\ninferential level. It is already known that strict-tolerant definitions can\nmake the notion of inference for non-classical logics collapse into the\nclassical notion, but the strength of this effect is not yet fully known. This\npaper shows that intuitionistic strict-tolerant inferences also collapse into\nclassical ones, but minimal ones do not. However, minimal strict-tolerant logic\nhas the property that no inferences are valid (which is not carried over to the\nmetainferential level). Additionally, it is shown that the logics obtained from\nintuitionistic, minimal and classical logic at the metainferential level are\ndistinct from each other.", "AI": {"tldr": "\u672c\u7814\u7a76\u5c06\u4e25\u683c-\u5bbd\u5bb9\u903b\u8f91\u65b9\u6cd5\u5e94\u7528\u4e8e\u76f4\u89c9\u4e3b\u4e49\u548c\u6700\u5c0f\u903b\u8f91\uff0c\u5e76\u7814\u7a76\u4e86\u5176\u5143\u63a8\u7406\u7684\u903b\u8f91\u3002", "motivation": "\u5c06\u4e25\u683c-\u5bbd\u5bb9\u903b\u8f91\u65b9\u6cd5\u5e94\u7528\u4e8e\u76f4\u89c9\u4e3b\u4e49\u548c\u6700\u5c0f\u903b\u8f91\uff0c\u4ee5\u63a2\u7d22\u5176\u5728\u975e\u7ecf\u5178\u903b\u8f91\u4e2d\u7684\u5f71\u54cd\uff0c\u5e76\u4e0e\u7ecf\u5178\u903b\u8f91\u8fdb\u884c\u6bd4\u8f83\u3002", "method": "\u901a\u8fc7\u4fee\u6539\u903b\u8f91\u63a8\u7406\u7684\u6982\u5ff5\uff0c\u5b9a\u4e49\u4e86\u4e25\u683c-\u5bbd\u5bb9\u903b\u8f91\u63a8\u7406\u548c\u5143\u63a8\u7406\uff0c\u5e76\u5206\u6790\u4e86\u5b83\u4eec\u4e0e\u7ecf\u5178\u903b\u8f91\u7684\u5173\u7cfb\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u76f4\u89c9\u4e3b\u4e49\u4e25\u683c-\u5bbd\u5bb9\u63a8\u7406\u4f1a\u5d29\u6e83\u4e3a\u7ecf\u5178\u63a8\u7406\uff0c\u4f46\u6700\u5c0f\u903b\u8f91\u7684\u63a8\u7406\u4e0d\u4f1a\u3002\u7136\u800c\uff0c\u6700\u5c0f\u4e25\u683c-\u5bbd\u5bb9\u903b\u8f91\u5728\u63a8\u7406\u5c42\u9762\u6ca1\u6709\u4efb\u4f55\u6709\u6548\u63a8\u7406\u3002\u6b64\u5916\uff0c\u4ece\u76f4\u89c9\u4e3b\u4e49\u3001\u6700\u5c0f\u903b\u8f91\u548c\u7ecf\u5178\u903b\u8f91\u5728\u5143\u63a8\u7406\u5c42\u9762\u83b7\u5f97\u7684\u903b\u8f91\u662f\u76f8\u4e92\u533a\u522b\u7684\u3002", "conclusion": "\u4e25\u683c-\u5bbd\u5bb9\u903b\u8f91\u65b9\u6cd5\u5728\u76f4\u89c9\u4e3b\u4e49\u548c\u6700\u5c0f\u903b\u8f91\u4e2d\u7684\u5e94\u7528\u63ed\u793a\u4e86\u63a8\u7406\u548c\u5143\u63a8\u7406\u7684\u590d\u6742\u884c\u4e3a\uff0c\u5f3a\u8c03\u4e86\u5b83\u4eec\u4e0e\u7ecf\u5178\u903b\u8f91\u7684\u533a\u522b\u548c\u8054\u7cfb\u3002"}}
{"id": "2509.10277", "categories": ["physics.app-ph", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2509.10277", "abs": "https://arxiv.org/abs/2509.10277", "authors": ["Thomas Froment\u00e8ze", "Philippe Michaud", "Ali Hassny", "Vincent Pateloup"], "title": "Morphogenetic mechanical metamaterials: Emerging tensor properties from self-organized structures", "comment": "33 pages, 9 figures", "summary": "Understanding how living organisms spontaneously develop complex functional\nstructures inspires innovative approaches in engineering design. Here, we\nintroduce a decentralized generative model based on morphogenesis to\nautonomously grow mechanical structures with controlled tensorial properties.\nBy adapting Turing's reaction-diffusion concept through anisotropic diffusion,\nour approach enables the local emergence of microstructures exhibiting tailored\nstiffness and anisotropy, achieving target orthotropic tensors without adjoint\nor topology optimization loops. The synthesis of these structures relies on a\ndatabase linking morphogenetic parameters to effective elastic tensors obtained\nthrough homogenization techniques. We experimentally demonstrate this concept\nthrough a mechanical cloaking example, validating our method's capability to\nindependently control local anisotropy and rigidity, and effectively conceal\nstructural defects from mechanical fields. This approach not only addresses key\nlimitations of traditional topology optimization methods but also opens new\nbio-inspired pathways for scalable and robust mechanical metamaterial design.", "AI": {"tldr": "\u751f\u6210\u4e00\u4e2a\u57fa\u4e8e\u5f62\u6001\u53d1\u751f\u5b66\u7684\u53bb\u4e2d\u5fc3\u5316\u751f\u6210\u6a21\u578b\uff0c\u7528\u4e8e\u81ea\u4e3b\u751f\u957f\u5177\u6709\u53d7\u63a7\u5f20\u91cf\u7279\u6027\u7684\u673a\u68b0\u7ed3\u6784\u3002", "motivation": "\u7406\u89e3\u751f\u7269\u4f53\u5982\u4f55\u81ea\u53d1\u5730\u5f00\u53d1\u590d\u6742\u7684\u51fd\u6570\u7ed3\u6784\uff0c\u4e3a\u5de5\u7a0b\u8bbe\u8ba1\u5e26\u6765\u4e86\u521b\u65b0\u7684\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u5404\u5411\u5f02\u6027\u6269\u6563\u8c03\u6574\u56fe\u7075\u7684\u53cd\u5e94-\u6269\u6563\u6982\u5ff5\uff0c\u5b9e\u73b0\u5fae\u7ed3\u6784\u7684\u5c40\u90e8\u51fa\u73b0\uff0c\u4ee5\u5b9e\u73b0\u76ee\u6807\u6b63\u4ea4\u5404\u5411\u5f02\u6027\u5f20\u91cf\uff0c\u800c\u65e0\u9700\u4f34\u968f\u6216\u62d3\u6251\u4f18\u5316\u5faa\u73af\u3002\u5f62\u6001\u53d1\u751f\u53c2\u6570\u4e0e\u901a\u8fc7\u5747\u8d28\u5316\u6280\u672f\u83b7\u5f97\u7684\u6709\u6548\u5f39\u6027\u5f20\u91cf\u4e4b\u95f4\u7684\u5173\u7cfb\u6570\u636e\u5e93\u3002", "result": "\u901a\u8fc7\u529b\u5b66\u9690\u8eab\uff08mechanical cloaking\uff09\u7684\u4f8b\u5b50\u8fdb\u884c\u4e86\u5b9e\u9a8c\u6f14\u793a\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u80fd\u591f\u72ec\u7acb\u63a7\u5236\u5c40\u90e8\u5404\u5411\u5f02\u6027\u548c\u521a\u5ea6\uff0c\u5e76\u6709\u6548\u5730\u5c06\u7ed3\u6784\u7f3a\u9677\u4ece\u529b\u5b66\u573a\u4e2d\u9690\u85cf\u8d77\u6765\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u89e3\u51b3\u4e86\u4f20\u7edf\u62d3\u6251\u4f18\u5316\u65b9\u6cd5\u7684\u5173\u952e\u5c40\u9650\u6027\uff0c\u8fd8\u4e3a\u53ef\u6269\u5c55\u3001\u9c81\u68d2\u7684\u673a\u68b0\u8d85\u6750\u6599\u8bbe\u8ba1\u5f00\u8f9f\u4e86\u65b0\u7684\u4eff\u751f\u9014\u5f84\u3002"}}
{"id": "2509.10210", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.10210", "abs": "https://arxiv.org/abs/2509.10210", "authors": ["Marko Petkovi\u0107", "Vlado Menkovski", "Sof\u00eda Calero"], "title": "Towards Fully Automated Molecular Simulations: Multi-Agent Framework for Simulation Setup and Force Field Extraction", "comment": null, "summary": "Automated characterization of porous materials has the potential to\naccelerate materials discovery, but it remains limited by the complexity of\nsimulation setup and force field selection. We propose a multi-agent framework\nin which LLM-based agents can autonomously understand a characterization task,\nplan appropriate simulations, assemble relevant force fields, execute them and\ninterpret their results to guide subsequent steps. As a first step toward this\nvision, we present a multi-agent system for literature-informed force field\nextraction and automated RASPA simulation setup. Initial evaluations\ndemonstrate high correctness and reproducibility, highlighting this approach's\npotential to enable fully autonomous, scalable materials characterization.", "AI": {"tldr": "LLM\u9a71\u52a8\u7684\u591a\u4ee3\u7406\u6846\u67b6\u53ef\u5b9e\u73b0\u591a\u5b54\u6750\u6599\u8868\u5f81\u7684\u81ea\u52a8\u5316\uff0c\u901a\u8fc7\u81ea\u4e3b\u89c4\u5212\u3001\u529b\u573a\u6784\u5efa\u548c\u6a21\u62df\u6267\u884c\u6765\u52a0\u901f\u6750\u6599\u53d1\u73b0\u3002", "motivation": "\u81ea\u52a8\u5316\u591a\u5b54\u6750\u6599\u8868\u5f81\u4ee5\u52a0\u901f\u6750\u6599\u53d1\u73b0\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u53d7\u9650\u4e8e\u6a21\u62df\u8bbe\u7f6e\u548c\u529b\u573a\u9009\u62e9\u7684\u590d\u6742\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u591a\u4ee3\u7406\u6846\u67b6\uff0c\u5176\u4e2d\u57fa\u4e8eLLM\u7684\u4ee3\u7406\u80fd\u591f\u81ea\u4e3b\u7406\u89e3\u8868\u5f81\u4efb\u52a1\u3001\u89c4\u5212\u6a21\u62df\u3001\u6784\u5efa\u529b\u573a\u3001\u6267\u884c\u6a21\u62df\u5e76\u89e3\u91ca\u7ed3\u679c\u4ee5\u6307\u5bfc\u540e\u7eed\u6b65\u9aa4\u3002\u4f5c\u4e3a\u7b2c\u4e00\u6b65\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u7528\u4e8e\u6587\u732e\u4fe1\u606f\u529b\u573a\u63d0\u53d6\u548cRASPA\u6a21\u62df\u8bbe\u7f6e\u7684\u81ea\u52a8\u5316\u7cfb\u7edf\u3002", "result": "\u521d\u6b65\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5177\u6709\u9ad8\u5ea6\u7684\u6b63\u786e\u6027\u548c\u53ef\u91cd\u590d\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6f5c\u529b\u5b9e\u73b0\u5b8c\u5168\u81ea\u4e3b\u3001\u53ef\u6269\u5c55\u7684\u6750\u6599\u8868\u5f81\u3002"}}
{"id": "2509.10009", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.10009", "abs": "https://arxiv.org/abs/2509.10009", "authors": ["Zhiwei Liang", "Bin Chen", "Jiwei Xu", "Yi Lei", "Qingqing Hu", "Fan Zhang", "Gabriele Liga"], "title": "A General Nonlinear Model for Arbitrary Modulation Formats in the Presence of Inter-Channel Simulated Raman Scattering", "comment": "4 Pages, 2 figures", "summary": "The four-dimensional nonlinear model is extended to include the inter-channel\nstimulated Raman scattering, enabling accurate prediction of dual-polarization\nfour-dimensional modulation formats and probabilistically shaped constellations\nin high-dispersion regimes. The proposed model is validated via comparisons\nwith the split-step Fourier method and enhanced Gaussian noise model.", "AI": {"tldr": "\u8be5\u6a21\u578b\u901a\u8fc7\u8003\u8651\u4e86\u4fe1\u9053\u95f4\u7684\u62c9\u66fc\u6563\u5c04\uff0c\u53ef\u4ee5\u7cbe\u786e\u9884\u6d4b\u9ad8\u8272\u6563\u6761\u4ef6\u4e0b\u7684\u53cc\u504f\u632f\u56db\u7ef4\u8c03\u5236\u683c\u5f0f\u548c\u6982\u7387\u6574\u5f62\u661f\u5ea7\u3002", "motivation": "\u4e3a\u4e86\u80fd\u66f4\u7cbe\u786e\u5730\u9884\u6d4b\u9ad8\u8272\u6563\u6761\u4ef6\u4e0b\u7684\u53cc\u504f\u632f\u56db\u7ef4\u8c03\u5236\u683c\u5f0f\u548c\u6982\u7387\u6574\u5f62\u661f\u5ea7\uff0c\u9700\u8981\u6269\u5c55\u56db\u7ef4\u975e\u7ebf\u6027\u6a21\u578b\u4ee5\u5305\u542b\u4fe1\u9053\u95f4\u7684\u53d7\u6fc0\u62c9\u66fc\u6563\u5c04\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8003\u8651\u4e86\u4fe1\u9053\u95f4\u53d7\u6fc0\u62c9\u66fc\u6563\u5c04\u7684\u56db\u7ef4\u975e\u7ebf\u6027\u6a21\u578b\uff0c\u5e76\u91c7\u7528\u8be5\u6a21\u578b\u5bf9\u53cc\u504f\u632f\u56db\u7ef4\u8c03\u5236\u683c\u5f0f\u548c\u6982\u7387\u6574\u5f62\u661f\u5ea7\u8fdb\u884c\u4e86\u9884\u6d4b\u3002", "result": "\u6a21\u578b\u53ef\u4ee5\u7cbe\u786e\u9884\u6d4b\u9ad8\u8272\u6563\u6761\u4ef6\u4e0b\u7684\u53cc\u504f\u632f\u56db\u7ef4\u8c03\u5236\u683c\u5f0f\u548c\u6982\u7387\u6574\u5f62\u661f\u5ea7\u3002\u901a\u8fc7\u4e0e\u5206\u88c2\u6b65\u957f\u5085\u91cc\u53f6\u65b9\u6cd5\u548c\u589e\u5f3a\u9ad8\u65af\u566a\u58f0\u6a21\u578b\u8fdb\u884c\u6bd4\u8f83\uff0c\u9a8c\u8bc1\u4e86\u8be5\u6a21\u578b\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6a21\u578b\u80fd\u591f\u51c6\u786e\u5730\u9884\u6d4b\u9ad8\u8272\u6563\u6761\u4ef6\u4e0b\u7684\u53cc\u504f\u632f\u56db\u7ef4\u8c03\u5236\u683c\u5f0f\u548c\u6982\u7387\u6574\u5f62\u661f\u5ea7\uff0c\u5e76\u4e14\u901a\u8fc7\u4e0e\u73b0\u6709\u65b9\u6cd5\u8fdb\u884c\u6bd4\u8f83\uff0c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2509.09978", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2509.09978", "abs": "https://arxiv.org/abs/2509.09978", "authors": ["Zodinpuia Ralte", "Ramesh Kumar", "Mukhtiyar Singh"], "title": "Elemental Frequency-Based Supervised Classification Approach for the Search of Novel Topological Materials", "comment": "10 pages, 9 figures, 6 tables", "summary": "The machine learning based approaches efficiently solves the goal of\nsearching the best materials candidate for the targeted properties. The search\nfor topological materials using traditional first-principles and symmetry-based\nmethods often requires lots of computing power or is limited by the crystalline\nsymmetries. In this study, we present frequency-based statistical descriptors\nfor machine learning-driven topological material's classification that is\nindependent of crystallographic symmetry of wave functions. This approach\npredicts the topological nature of a material based on its chemical formula.\nWith a balanced dataset of 3910 materials, we have achieved classification\naccuracies of 82\\% with the Support Vector Machine (SVM) model and 83\\% with\nthe Random Forest (RF) model, where both models have trained on common\nfrequency based features. We have checked the performances of the models using\n$5-fold$ cross-validation approach. Further, we have validated the models on a\ndataset of unseen binary compounds and have efficiently identified 22 common\nmaterials using both the models. Next, we implemented the $first-principles$\napproach to confirm the topological nature of these predicted materials and\nfound the topological signatures of Dirac, Weyl, and nodal-line semimetallic\nphases. Therefore, we have demonstrated that the implications of\nfrequency-based descriptors is a practical and less complex way to find novel\ntopological materials with certain physical post-processing filters. This\napproach lays the groundwork for scalable, data-driven topological property\nscreening of complex materials.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9891\u7387\u7edf\u8ba1\u63cf\u8ff0\u7b26\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u9884\u6d4b\u6750\u6599\u7684\u62d3\u6251\u6027\u8d28\uff0c\u65e0\u9700\u4f9d\u8d56\u6676\u4f53\u5bf9\u79f0\u6027\uff0c\u5e76\u80fd\u6709\u6548\u7b5b\u9009\u51fa\u65b0\u7684\u62d3\u6251\u6750\u6599\u3002", "motivation": "\u4f20\u7edf\u62d3\u6251\u6750\u6599\u641c\u7d22\u65b9\u6cd5\u8ba1\u7b97\u91cf\u5927\u6216\u53d7\u9650\u4e8e\u6676\u4f53\u5bf9\u79f0\u6027\u3002\u672c\u7814\u7a76\u65e8\u5728\u63d0\u51fa\u4e00\u79cd\u66f4\u9ad8\u6548\u3001\u66f4\u901a\u7528\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u9891\u7387\u7edf\u8ba1\u63cf\u8ff0\u7b26\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u4e0d\u4f9d\u8d56\u4e8e\u6ce2\u51fd\u6570\u7684\u6676\u4f53\u5bf9\u79f0\u6027\uff0c\u5e76\u80fd\u4ec5\u6839\u636e\u5316\u5b66\u5f0f\u9884\u6d4b\u6750\u6599\u7684\u62d3\u6251\u6027\u8d28\u3002\u4f7f\u7528\u652f\u6301\u5411\u91cf\u673a\uff08SVM\uff09\u548c\u968f\u673a\u68ee\u6797\uff08RF\uff09\u6a21\u578b\uff0c\u5e76\u91c7\u75285\u6298\u4ea4\u53c9\u9a8c\u8bc1\u8fdb\u884c\u6027\u80fd\u8bc4\u4f30\u3002\u6700\u540e\uff0c\u5229\u7528\u7b2c\u4e00\u6027\u539f\u7406\u8ba1\u7b97\u9a8c\u8bc1\u4e86\u9884\u6d4b\u7ed3\u679c\u3002", "result": "\u4f7f\u7528SVM\u6a21\u578b\u8fbe\u5230\u4e8682%\u7684\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u4f7f\u7528RF\u6a21\u578b\u8fbe\u5230\u4e8683%\u7684\u5206\u7c7b\u51c6\u786e\u7387\u3002\u5728\u672a\u89c1\u8fc7\u7684\u6570\u636e\u96c6\u4e0a\u6210\u529f\u8bc6\u522b\u4e8622\u79cd\u5e38\u89c1\u7684\u6750\u6599\u3002\u7b2c\u4e00\u6027\u539f\u7406\u8ba1\u7b97\u8bc1\u5b9e\u4e86\u8fd9\u4e9b\u6750\u6599\u5177\u6709\u72c4\u62c9\u514b\u3001\u5916\u5c14\u548c\u8282\u70b9\u7ebf\u534a\u91d1\u5c5e\u76f8\u7684\u62d3\u6251\u7279\u5f81\u3002", "conclusion": "\u57fa\u4e8e\u9891\u7387\u7684\u63cf\u8ff0\u7b26\u662f\u4e00\u79cd\u5b9e\u7528\u4e14\u7b80\u4fbf\u7684\u65b9\u6cd5\uff0c\u53ef\u7528\u4e8e\u5bfb\u627e\u5177\u6709\u7279\u5b9a\u7269\u7406\u6027\u8d28\u7684\u65b0\u578b\u62d3\u6251\u6750\u6599\u3002\u8be5\u65b9\u6cd5\u4e3a\u53ef\u6269\u5c55\u3001\u6570\u636e\u9a71\u52a8\u7684\u590d\u6742\u6750\u6599\u62d3\u6251\u6027\u8d28\u7b5b\u9009\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2509.09703", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09703", "abs": "https://arxiv.org/abs/2509.09703", "authors": ["Zhenhua Xu", "Xixiang Zhao", "Xubin Yue", "Shengwei Tian", "Changting Lin", "Meng Han"], "title": "CTCC: A Robust and Stealthy Fingerprinting Framework for Large Language Models via Cross-Turn Contextual Correlation Backdoor", "comment": "Accepted by EMNLP2025 MainConference", "summary": "The widespread deployment of large language models (LLMs) has intensified\nconcerns around intellectual property (IP) protection, as model theft and\nunauthorized redistribution become increasingly feasible. To address this,\nmodel fingerprinting aims to embed verifiable ownership traces into LLMs.\nHowever, existing methods face inherent trade-offs between stealthness,\nrobustness, and generalizability, being either detectable via distributional\nshifts, vulnerable to adversarial modifications, or easily invalidated once the\nfingerprint is revealed. In this work, we introduce CTCC, a novel rule-driven\nfingerprinting framework that encodes contextual correlations across multiple\ndialogue turns, such as counterfactual, rather than relying on token-level or\nsingle-turn triggers. CTCC enables fingerprint verification under black-box\naccess while mitigating false positives and fingerprint leakage, supporting\ncontinuous construction under a shared semantic rule even if partial triggers\nare exposed. Extensive experiments across multiple LLM architectures\ndemonstrate that CTCC consistently achieves stronger stealth and robustness\nthan prior work. Our findings position CTCC as a reliable and practical\nsolution for ownership verification in real-world LLM deployment scenarios. Our\ncode and data are publicly available at <https://github.com/Xuzhenhua55/CTCC>.", "AI": {"tldr": "CTCC\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u3001\u7531\u89c4\u5219\u9a71\u52a8\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u6307\u7eb9\u6846\u67b6\uff0c\u5b83\u901a\u8fc7\u7f16\u7801\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u7684\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\uff08\u4f8b\u5982\u53cd\u4e8b\u5b9e\uff09\u6765\u5d4c\u5165\u53ef\u9a8c\u8bc1\u7684\u6240\u6709\u6743\u75d5\u8ff9\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u9690\u853d\u6027\u3001\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u6027\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u5e76\u5728\u9ed1\u76d2\u8bbf\u95ee\u4e0b\u5b9e\u73b0\u4e86\u6307\u7eb9\u9a8c\u8bc1\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u8bef\u62a5\u548c\u6307\u7eb9\u6cc4\u9732\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u6307\u7eb9\u6280\u672f\u5728\u9690\u853d\u6027\u3001\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u6027\u65b9\u9762\u5b58\u5728\u56fa\u6709\u7684\u6743\u8861\uff0c\u5bb9\u6613\u88ab\u68c0\u6d4b\u3001\u53d7\u5230\u5bf9\u6297\u6027\u4fee\u6539\u7684\u5f71\u54cd\u6216\u5728\u6307\u7eb9\u66b4\u9732\u540e\u5931\u6548\u3002\u672c\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u66f4\u53ef\u9760\u3001\u66f4\u5b9e\u7528\u7684LLM\u6307\u7eb9\u89e3\u51b3\u65b9\u6848\u3002", "method": "CTCC\u6846\u67b6\u901a\u8fc7\u7f16\u7801\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u7684\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\uff08\u4f8b\u5982\u53cd\u4e8b\u5b9e\uff09\uff0c\u800c\u4e0d\u662f\u4f9d\u8d56\u4e8e\u6807\u8bb0\u7ea7\u522b\u6216\u5355\u8f6e\u89e6\u53d1\u5668\u6765\u5d4c\u5165\u6307\u7eb9\u3002\u8be5\u6846\u67b6\u652f\u6301\u5728\u5171\u4eab\u8bed\u4e49\u89c4\u5219\u4e0b\u8fdb\u884c\u6301\u7eed\u6784\u5efa\uff0c\u5373\u4f7f\u90e8\u5206\u89e6\u53d1\u5668\u66b4\u9732\uff0c\u4e5f\u80fd\u5728\u9ed1\u76d2\u8bbf\u95ee\u4e0b\u8fdb\u884c\u9a8c\u8bc1\uff0c\u5e76\u80fd\u51cf\u8f7b\u8bef\u62a5\u548c\u6307\u7eb9\u6cc4\u9732\u3002", "result": "CTCC\u5728\u591a\u79cdLLM\u67b6\u6784\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0cCTCC\u5728\u9690\u853d\u6027\u548c\u9c81\u68d2\u6027\u65b9\u9762\u59cb\u7ec8\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "CTCC\u662f\u4e00\u4e2a\u53ef\u9760\u4e14\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u73b0\u5b9e\u4e16\u754c\u4e2dLLM\u7684\u90e8\u7f72\u573a\u666f\uff0c\u80fd\u591f\u6709\u6548\u89e3\u51b3\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u95ee\u9898\u3002"}}
{"id": "2509.09772", "categories": ["cs.LG", "stat.AP"], "pdf": "https://arxiv.org/pdf/2509.09772", "abs": "https://arxiv.org/abs/2509.09772", "authors": ["Sanjay Basu", "Sadiq Y. Patel", "Parth Sheth", "Bhairavi Muralidharan", "Namrata Elamaran", "Aakriti Kinra", "Rajaie Batniji"], "title": "Hybrid Adaptive Conformal Offline Reinforcement Learning for Fair Population Health Management", "comment": "10 pages, 5 figures, 4 tables", "summary": "Population health management programs for Medicaid populations coordinate\nlongitudinal outreach and services (e.g., benefits navigation, behavioral\nhealth, social needs support, and clinical scheduling) and must be safe, fair,\nand auditable. We present a Hybrid Adaptive Conformal Offline Reinforcement\nLearning (HACO) framework that separates risk calibration from preference\noptimization to generate conservative action recommendations at scale. In our\nsetting, each step involves choosing among common coordination actions (e.g.,\nwhich member to contact, by which modality, and whether to route to a\nspecialized service) while controlling the near-term risk of adverse\nutilization events (e.g., unplanned emergency department visits or\nhospitalizations). Using a de-identified operational dataset from Waymark\ncomprising 2.77 million sequential decisions across 168,126 patients, HACO (i)\ntrains a lightweight risk model for adverse events, (ii) derives a conformal\nthreshold to mask unsafe actions at a target risk level, and (iii) learns a\npreference policy on the resulting safe subset. We evaluate policies with a\nversion-agnostic fitted Q evaluation (FQE) on stratified subsets and audit\nsubgroup performance across age, sex, and race. HACO achieves strong risk\ndiscrimination (AUC ~0.81) with a calibrated threshold ( {\\tau} ~0.038 at\n{\\alpha} = 0.10), while maintaining high safe coverage. Subgroup analyses\nreveal systematic differences in estimated value across demographics,\nunderscoring the importance of fairness auditing. Our results show that\nconformal risk gating integrates cleanly with offline RL to deliver\nconservative, auditable decision support for population health management\nteams.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aHACO\uff08Hybrid Adaptive Conformal Offline Reinforcement Learning\uff09\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u7ba1\u7406Medicaid\u4eba\u7fa4\u7684\u5065\u5eb7\uff0c\u65e8\u5728\u5b89\u5168\u3001\u516c\u5e73\u4e14\u53ef\u5ba1\u8ba1\u5730\u8fdb\u884c\u5927\u89c4\u6a21\u534f\u8c03\u548c\u5e72\u9884\u3002", "motivation": "\u4e3aMedicaid\u4eba\u7fa4\u63d0\u4f9b\u5b89\u5168\u3001\u516c\u5e73\u4e14\u53ef\u5ba1\u8ba1\u7684\u5065\u5eb7\u7ba1\u7406\u8ba1\u5212\uff0c\u8be5\u8ba1\u5212\u9700\u8981\u534f\u8c03\u957f\u671f\u7684\u5916\u5c55\u670d\u52a1\uff0c\u540c\u65f6\u63a7\u5236\u4e0d\u826f\u5229\u7528\u4e8b\u4ef6\u7684\u98ce\u9669\u3002", "method": "HACO\u6846\u67b6\u5c06\u98ce\u9669\u6821\u51c6\u4e0e\u504f\u597d\u4f18\u5316\u5206\u5f00\uff0c\u9996\u5148\u8bad\u7ec3\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u98ce\u9669\u6a21\u578b\u6765\u9884\u6d4b\u4e0d\u826f\u4e8b\u4ef6\uff0c\u7136\u540e\u5229\u7528\u5171\u5f62\u9884\u6d4b\uff08conformal prediction\uff09\u6d3e\u751f\u4e00\u4e2a\u9608\u503c\u6765\u5c4f\u853d\u4e0d\u5b89\u5168\u7684\u64cd\u4f5c\uff0c\u6700\u540e\u5728\u4fdd\u8bc1\u5b89\u5168\u7684\u5b50\u96c6\u4e2d\u5b66\u4e60\u504f\u597d\u7b56\u7565\u3002\u8be5\u65b9\u6cd5\u4f7f\u7528\u4e86\u4e00\u4e2a\u5305\u542b277\u4e07\u4e2a\u51b3\u7b56\u548c168,126\u540d\u60a3\u8005\u7684\u771f\u5b9e\u6570\u636e\u96c6\u3002", "result": "HACO\u5728\u98ce\u9669\u8bc6\u522b\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff08AUC\u7ea60.81\uff09\uff0c\u5e76\u5177\u6709\u6821\u51c6\u7684\u9608\u503c\uff08{\\tau} ~0.038 at {\\alpha} = 0.10\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u9ad8\u6c34\u5e73\u7684\u5b89\u5168\u8986\u76d6\u7387\u3002\u5bf9\u4e0d\u540c\u5e74\u9f84\u3001\u6027\u522b\u548c\u79cd\u65cf\u7fa4\u4f53\u7684\u5206\u6790\u663e\u793a\uff0c\u5728\u4f30\u8ba1\u4ef7\u503c\u65b9\u9762\u5b58\u5728\u7cfb\u7edf\u6027\u5dee\u5f02\uff0c\u51f8\u663e\u4e86\u516c\u5e73\u6027\u5ba1\u8ba1\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u5171\u5f62\u98ce\u9669\u95e8\u63a7\uff08conformal risk gating\uff09\u4e0e\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\uff08offline RL\uff09\u7684\u7ed3\u5408\uff0c\u80fd\u591f\u4e3a\u4eba\u53e3\u5065\u5eb7\u7ba1\u7406\u56e2\u961f\u63d0\u4f9b\u4fdd\u5b88\u4e14\u53ef\u5ba1\u8ba1\u7684\u51b3\u7b56\u652f\u6301\u3002"}}
{"id": "2509.09810", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09810", "abs": "https://arxiv.org/abs/2509.09810", "authors": ["Agnieszka Mensfelt", "David Tena Cucala", "Santiago Franco", "Angeliki Koutsoukou-Argyraki", "Vince Trencsenyi", "Kostas Stathis"], "title": "Towards a Common Framework for Autoformalization", "comment": null, "summary": "Autoformalization has emerged as a term referring to the automation of\nformalization - specifically, the formalization of mathematics using\ninteractive theorem provers (proof assistants). Its rapid development has been\ndriven by progress in deep learning, especially large language models (LLMs).\nMore recently, the term has expanded beyond mathematics to describe the broader\ntask of translating informal input into formal logical representations. At the\nsame time, a growing body of research explores using LLMs to translate informal\nlanguage into formal representations for reasoning, planning, and knowledge\nrepresentation - often without explicitly referring to this process as\nautoformalization. As a result, despite addressing similar tasks, the largely\nindependent development of these research areas has limited opportunities for\nshared methodologies, benchmarks, and theoretical frameworks that could\naccelerate progress. The goal of this paper is to review - explicit or implicit\n- instances of what can be considered autoformalization and to propose a\nunified framework, encouraging cross-pollination between different fields to\nadvance the development of next generation AI systems.", "AI": {"tldr": "Autoformalization (AI formalization) is advancing due to LLMs, but research is fragmented. This paper proposes a unified framework to connect related fields and accelerate progress.", "motivation": "The rapid development of autoformalization, driven by LLMs, has led to fragmented research across different fields (mathematics, reasoning, planning, knowledge representation). This lack of communication hinders progress due to separate development of methodologies, benchmarks, and theoretical frameworks.", "method": "This paper reviews explicit and implicit instances of autoformalization and proposes a unified framework to encourage cross-pollination between different fields.", "result": "The paper aims to advance the development of next-generation AI systems by unifying fragmented research in autoformalization.", "conclusion": "By proposing a unified framework and encouraging interdisciplinary collaboration, this paper seeks to accelerate progress in autoformalization and the development of advanced AI systems."}}
{"id": "2509.09863", "categories": ["eess.SY", "cs.LG", "cs.RO", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.09863", "abs": "https://arxiv.org/abs/2509.09863", "authors": ["Sarvan Gill", "Daniela Constantinescu"], "title": "Off Policy Lyapunov Stability in Reinforcement Learning", "comment": "Conference on Robot Learning (CORL) 2025", "summary": "Traditional reinforcement learning lacks the ability to provide stability\nguarantees. More recent algorithms learn Lyapunov functions alongside the\ncontrol policies to ensure stable learning. However, the current self-learned\nLyapunov functions are sample inefficient due to their on-policy nature. This\npaper introduces a method for learning Lyapunov functions off-policy and\nincorporates the proposed off-policy Lyapunov function into the Soft Actor\nCritic and Proximal Policy Optimization algorithms to provide them with a data\nefficient stability certificate. Simulations of an inverted pendulum and a\nquadrotor illustrate the improved performance of the two algorithms when\nendowed with the proposed off-policy Lyapunov function.", "AI": {"tldr": "\u4f20\u7edf\u7684\u5f3a\u5316\u5b66\u4e60\u7f3a\u4e4f\u7a33\u5b9a\u6027\u4fdd\u8bc1\uff0c\u672c\u7814\u7a76\u63d0\u51fa\u4e00\u79cd\u6837\u672c\u6548\u7387\u9ad8\u4e14\u80fd\u63d0\u4f9b\u7a33\u5b9a\u6027\u8bc1\u4e66\u7684\u79bb\u7b56\u7565\u5b66\u4e60\u674e\u4e9a\u666e\u8bfa\u592b\u51fd\u6570\u7684\u65b9\u6cd5\uff0c\u5e76\u5c06\u5176\u96c6\u6210\u5230SAC\u548cPPO\u7b97\u6cd5\u4e2d\uff0c\u5728\u5012\u7acb\u6446\u548c\u56db\u65cb\u7ffc\u98de\u884c\u5668\u7684\u4eff\u771f\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u5f3a\u5316\u5b66\u4e60\u5728\u63d0\u4f9b\u7a33\u5b9a\u6027\u4fdd\u8bc1\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002\u867d\u7136\u73b0\u6709\u7684\u7b97\u6cd5\u53ef\u4ee5\u5b66\u4e60\u674e\u4e9a\u666e\u8bfa\u592b\u51fd\u6570\u6765\u786e\u4fdd\u5b66\u4e60\u7684\u7a33\u5b9a\u6027\uff0c\u4f46\u5b83\u4eec\u662f\u6837\u672c\u6548\u7387\u4f4e\u4e0b\u7684\uff0c\u56e0\u4e3a\u5b83\u4eec\u662f\u6837\u672c\u4f7f\u7528\u6548\u7387\u9ad8\u7684\uff08on-policy\uff09\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u79bb\u7b56\u7565\u5b66\u4e60\u674e\u4e9a\u666e\u8bfa\u592b\u51fd\u6570\u7684\u65b9\u6cd5\uff0c\u5e76\u5c06\u6240\u63d0\u51fa\u7684\u79bb\u7b56\u7565\u674e\u4e9a\u666e\u8bfa\u592b\u51fd\u6570\u96c6\u6210\u5230\u8f6fActor-Critic\uff08SAC\uff09\u548cProximal Policy Optimization\uff08PPO\uff09\u7b97\u6cd5\u4e2d\uff0c\u4e3a\u5b83\u4eec\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6570\u636e\u6548\u7387\u9ad8\u7684\u7a33\u5b9a\u6027\u8bc1\u4e66\u3002", "result": "\u5c06\u6240\u63d0\u51fa\u7684\u79bb\u7b56\u7565\u674e\u4e9a\u666e\u8bfa\u592b\u51fd\u6570\u96c6\u6210\u5230SAC\u548cPPO\u7b97\u6cd5\u4e2d\uff0c\u5728\u5012\u7acb\u6446\u548c\u56db\u65cb\u7ffc\u98de\u884c\u5668\u7684\u4eff\u771f\u4e2d\uff0c\u5c55\u793a\u4e86\u8fd9\u4e24\u79cd\u7b97\u6cd5\u7684\u6027\u80fd\u5f97\u5230\u4e86\u63d0\u5347\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u79bb\u7b56\u7565\u674e\u4e9a\u666e\u8bfa\u592b\u51fd\u6570\u5b66\u4e60\u65b9\u6cd5\u53ef\u4ee5\u63d0\u9ad8\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u7684\u6570\u636e\u6548\u7387\uff0c\u5e76\u4e3a\u5176\u63d0\u4f9b\u7a33\u5b9a\u6027\u4fdd\u8bc1\u3002"}}
{"id": "2509.10161", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2509.10161", "abs": "https://arxiv.org/abs/2509.10161", "authors": ["Shiwei Li", "Qunwei Li", "Haozhao Wang", "Ruixuan Li", "Jianbin Lin", "Wenliang Zhong"], "title": "FedBiF: Communication-Efficient Federated Learning via Bits Freezing", "comment": "Accepted by TPDS", "summary": "Federated learning (FL) is an emerging distributed machine learning paradigm\nthat enables collaborative model training without sharing local data. Despite\nits advantages, FL suffers from substantial communication overhead, which can\naffect training efficiency. Recent efforts have mitigated this issue by\nquantizing model updates to reduce communication costs. However, most existing\nmethods apply quantization only after local training, introducing quantization\nerrors into the trained parameters and potentially degrading model accuracy. In\nthis paper, we propose Federated Bit Freezing (FedBiF), a novel FL framework\nthat directly learns quantized model parameters during local training. In each\ncommunication round, the server first quantizes the model parameters and\ntransmits them to the clients. FedBiF then allows each client to update only a\nsingle bit of the multi-bit parameter representation, freezing the remaining\nbits. This bit-by-bit update strategy reduces each parameter update to one bit\nwhile maintaining high precision in parameter representation. Extensive\nexperiments are conducted on five widely used datasets under both IID and\nNon-IID settings. The results demonstrate that FedBiF not only achieves\nsuperior communication compression but also promotes sparsity in the resulting\nmodels. Notably, FedBiF attains accuracy comparable to FedAvg, even when using\nonly 1 bit-per-parameter (bpp) for uplink and 3 bpp for downlink communication.\nThe code is available at https://github.com/Leopold1423/fedbif-tpds25.", "AI": {"tldr": "FedBiF\u901a\u8fc7\u5728\u672c\u5730\u8bad\u7ec3\u671f\u95f4\u76f4\u63a5\u5b66\u4e60\u91cf\u5316\u6a21\u578b\u53c2\u6570\u6765\u89e3\u51b3\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u901a\u4fe1\u5f00\u9500\u95ee\u9898\uff0c\u901a\u8fc7\u9010\u6bd4\u7279\u66f4\u65b0\u7b56\u7565\uff0c\u5728\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u901a\u4fe1\u91cf\uff0c\u5e76\u5728\u51c6\u786e\u6027\u65b9\u9762\u8fbe\u5230\u4e0eFedAvg\u76f8\u5f53\u7684\u6c34\u5e73\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u867d\u7136\u80fd\u8fdb\u884c\u5206\u5e03\u5f0f\u6a21\u578b\u534f\u540c\u8bad\u7ec3\u4e14\u65e0\u9700\u5171\u4eab\u672c\u5730\u6570\u636e\uff0c\u4f46\u5b58\u5728\u663e\u8457\u7684\u901a\u4fe1\u5f00\u9500\u95ee\u9898\uff0c\u5f71\u54cd\u8bad\u7ec3\u6548\u7387\u3002\u73b0\u6709\u7684\u91cf\u5316\u65b9\u6cd5\u901a\u5e38\u5728\u672c\u5730\u8bad\u7ec3\u540e\u5e94\u7528\u91cf\u5316\uff0c\u8fd9\u4f1a\u5c06\u91cf\u5316\u8bef\u5dee\u5f15\u5165\u8bad\u7ec3\u53c2\u6570\uff0c\u53ef\u80fd\u964d\u4f4e\u6a21\u578b\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFedBiF\u7684\u65b0\u578b\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u5b83\u5728\u672c\u5730\u8bad\u7ec3\u671f\u95f4\u76f4\u63a5\u5b66\u4e60\u91cf\u5316\u6a21\u578b\u53c2\u6570\u3002\u5728\u6bcf\u4e2a\u901a\u4fe1\u8f6e\u6b21\u4e2d\uff0c\u670d\u52a1\u5668\u9996\u5148\u91cf\u5316\u6a21\u578b\u53c2\u6570\u5e76\u5c06\u5176\u4f20\u8f93\u7ed9\u5ba2\u6237\u7aef\u3002\u7136\u540e\uff0cFedBiF\u5141\u8bb8\u6bcf\u4e2a\u5ba2\u6237\u7aef\u4ec5\u66f4\u65b0\u591a\u6bd4\u7279\u53c2\u6570\u8868\u793a\u4e2d\u7684\u4e00\u4e2a\u6bd4\u7279\uff0c\u5e76\u51bb\u7ed3\u5176\u4f59\u6bd4\u7279\u3002\u8fd9\u79cd\u9010\u6bd4\u7279\u66f4\u65b0\u7b56\u7565\u5c06\u6bcf\u4e2a\u53c2\u6570\u66f4\u65b0\u51cf\u5c11\u5230\u4e00\u4e2a\u6bd4\u7279\uff0c\u540c\u65f6\u4fdd\u6301\u53c2\u6570\u8868\u793a\u7684\u9ad8\u7cbe\u5ea6\u3002", "result": "\u5728\u4e94\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u6570\u636e\u96c6\u4e0a\uff0c\u540c\u65f6\u5728IID\u548cNon-IID\u8bbe\u7f6e\u4e0b\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u3002\u7ed3\u679c\u8868\u660e\uff0cFedBiF\u4e0d\u4ec5\u5b9e\u73b0\u4e86\u5353\u8d8a\u7684\u901a\u4fe1\u538b\u7f29\uff0c\u8fd8\u4fc3\u8fdb\u4e86\u6240\u5f97\u6a21\u578b\u7684\u7a00\u758f\u6027\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5373\u4f7f\u5728\u4ec5\u4f7f\u75281\u6bd4\u7279/\u53c2\u6570\uff08bpp\uff09\u7528\u4e8e\u4e0a\u884c\u94fe\u8def\u548c3 bpp\u7528\u4e8e\u4e0b\u884c\u94fe\u8def\u901a\u4fe1\u7684\u60c5\u51b5\u4e0b\uff0cFedBiF\u4e5f\u80fd\u8fbe\u5230\u4e0eFedAvg\u76f8\u5f53\u7684\u51c6\u786e\u6027\u3002", "conclusion": "FedBiF\u901a\u8fc7\u5728\u672c\u5730\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u8fdb\u884c\u9010\u6bd4\u7279\u66f4\u65b0\uff0c\u6709\u6548\u5730\u89e3\u51b3\u4e86\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u901a\u4fe1\u5f00\u9500\u95ee\u9898\uff0c\u5e76\u5728\u4e0d\u727a\u7272\u51c6\u786e\u6027\u7684\u524d\u63d0\u4e0b\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u901a\u4fe1\u538b\u7f29\u548c\u6a21\u578b\u7a00\u758f\u6027\u3002"}}
{"id": "2509.09732", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.09732", "abs": "https://arxiv.org/abs/2509.09732", "authors": ["Sary Elmansoury", "Islam Mesabah", "Gerrit Gro\u00dfmann", "Peter Neigel", "Raj Bhalwankar", "Daniel Kondermann", "Sebastian J. Vollmer"], "title": "Decomposing Visual Classification: Assessing Tree-Based Reasoning in VLMs", "comment": null, "summary": "Vision language models (VLMs) excel at zero-shot visual classification, but\ntheir performance on fine-grained tasks and large hierarchical label spaces is\nunderstudied. This paper investigates whether structured, tree-based reasoning\ncan enhance VLM performance. We introduce a framework that decomposes\nclassification into interpretable decisions using decision trees and evaluates\nit on fine-grained (GTSRB) and coarse-grained (CIFAR-10) datasets. Although the\nmodel achieves 98.2% accuracy in understanding the tree knowledge, tree-based\nreasoning consistently underperforms standard zero-shot prompting. We also\nexplore enhancing the tree prompts with LLM-generated classes and image\ndescriptions to improve alignment. The added description enhances the\nperformance of the tree-based and zero-shot methods. Our findings highlight\nlimitations of structured reasoning in visual classification and offer insights\nfor designing more interpretable VLM systems.", "AI": {"tldr": "\u7ed3\u6784\u5316\u63a8\u7406\u5728\u89c6\u89c9\u5206\u7c7b\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u4f46\u63cf\u8ff0\u7684\u589e\u5f3a\u53ef\u4ee5\u63d0\u9ad8\u6027\u80fd\u3002", "motivation": "\u8bc4\u4f30\u7ed3\u6784\u5316\u3001\u57fa\u4e8e\u6811\u7684\u63a8\u7406\u80fd\u5426\u63d0\u9ad8\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u5728\u7ec6\u7c92\u5ea6\u4efb\u52a1\u548c\u5927\u578b\u5206\u5c42\u6807\u7b7e\u7a7a\u95f4\u4e0a\u7684\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u4f7f\u7528\u51b3\u7b56\u6811\u5c06\u5206\u7c7b\u5206\u89e3\u4e3a\u53ef\u89e3\u91ca\u51b3\u7b56\u7684\u6846\u67b6\uff0c\u5e76\u5728\u7ec6\u7c92\u5ea6\uff08GTSRB\uff09\u548c\u7c97\u7c92\u5ea6\uff08CIFAR-10\uff09\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002\u8fd8\u63a2\u7d22\u4e86\u4f7f\u7528LLM\u751f\u6210\u7684\u7c7b\u522b\u548c\u56fe\u50cf\u63cf\u8ff0\u6765\u589e\u5f3a\u6811\u63d0\u793a\u3002", "result": "\u5728GTSRB\u548cCIFAR-10\u6570\u636e\u96c6\u4e0a\uff0c\u57fa\u4e8e\u6811\u7684\u63a8\u7406\u6027\u80fd\u59cb\u7ec8\u4f4e\u4e8e\u6807\u51c6\u7684\u96f6\u6837\u672c\u63d0\u793a\u3002\u7136\u800c\uff0c\u6dfb\u52a0\u7684\u63cf\u8ff0\u53ef\u4ee5\u63d0\u9ad8\u57fa\u4e8e\u6811\u548c\u96f6\u6837\u672c\u65b9\u6cd5\u7684\u6027\u80fd\u3002\u6a21\u578b\u5728\u7406\u89e3\u6811\u77e5\u8bc6\u65b9\u9762\u8fbe\u5230\u4e8698.2%\u7684\u51c6\u786e\u7387\u3002", "conclusion": "\u7ed3\u6784\u5316\u63a8\u7406\u5728\u89c6\u89c9\u5206\u7c7b\u4efb\u52a1\u4e2d\u5b58\u5728\u5c40\u9650\u6027\uff0c\u4f46\u6dfb\u52a0\u7684\u63cf\u8ff0\u53ef\u4ee5\u63d0\u9ad8VLM\u7684\u6027\u80fd\u3002\u8fd9\u4e3a\u8bbe\u8ba1\u66f4\u5177\u53ef\u89e3\u91ca\u6027\u7684VLM\u7cfb\u7edf\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2509.10068", "categories": ["cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2509.10068", "abs": "https://arxiv.org/abs/2509.10068", "authors": ["Thomas Naimer", "Paulo E. Faria Junior", "Klaus Zollner", "Jaroslav Fabian"], "title": "Radial Rashba spin-orbit fields in commensurate twisted transition-metal dichalcogenide bilayers", "comment": null, "summary": "In commensurate twisted homobilayers, purely radial Rashba spin-orbit fields\ncan emerge. The observed in-plane spin textures are mostly radial, and the main\nfeatures are successfully reproduced using a model Hamiltonian based on two\neffective mass models including spin-orbit coupling, and a general\n(spin-conserving) interlayer coupling. Extracting the model Hamiltonian\nparameters through fitting of several twisted supercells, we find a twist angle\ndependency of the magnitude of the radial Rashba field, which is symmetric not\nonly around the untwisted cases ($\\Theta=0^\\circ$ and $\\Theta=60^\\circ$), but\nalso around $\\Theta=30^\\circ$. Furthermore, we observe that the interlayer\ncoupling between the $K/K'$-points of the two layers decreases with the\nincrease of the size of the commensurate supercells. Hence, peaks of high\ninterlayer coupling can occur only for twist angles, where small commensurate\nsupercells are possible. Exploring different lateral displacements between the\nlayers, we confirm that the relevant symmetry protecting the radial Rashba is\nan in-plane 180$^\\circ$ rotation axis. We additionally investigate the effects\nof atomic relaxation and modulation of the interlayer distance. Our results\noffer fundamental microscopic insights that are particularly relevant to\nengineering spin-charge conversion schemes based on twisted layered materials.", "AI": {"tldr": "\u7eaf\u5f84\u5411Rashba\u81ea\u65cb\u8f68\u9053\u573a\u53ef\u4ee5\u5728\u5171\u683c\u626d\u66f2\u7684\u540c\u8d28\u53cc\u5c42\u6750\u6599\u4e2d\u51fa\u73b0\uff0c\u5176\u5e73\u9762\u5185\u81ea\u65cb\u7eb9\u7406\u4e3b\u8981\u662f\u5f84\u5411\u7684\u3002", "motivation": "\u7814\u7a76\u5171\u683c\u626d\u66f2\u7684\u540c\u8d28\u53cc\u5c42\u6750\u6599\u4e2d\u7eaf\u5f84\u5411Rashba\u81ea\u65cb\u8f68\u9053\u573a\u7684\u51fa\u73b0\u53ca\u5176\u6027\u8d28\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u4e24\u4e2a\u6709\u6548\u8d28\u91cf\u6a21\u578b\uff08\u5305\u542b\u81ea\u65cb-\u8f68\u9053\u8026\u5408\uff09\u548c\u4e00\u822c\uff08\u81ea\u65cb\u5b88\u6052\uff09\u5c42\u95f4\u8026\u5408\u7684\u6a21\u578b\u54c8\u5bc6\u987f\u91cf\uff0c\u901a\u8fc7\u62df\u5408\u51e0\u4e2a\u626d\u66f2\u8d85\u80de\u6765\u63d0\u53d6\u6a21\u578b\u54c8\u5bc6\u987f\u91cf\u53c2\u6570\u3002", "result": "\u53d1\u73b0\u5f84\u5411Rashba\u573a\u7684\u5e45\u5ea6\u5b58\u5728\u626d\u8f6c\u89d2\u4f9d\u8d56\u6027\uff0c\u8be5\u4f9d\u8d56\u6027\u4e0d\u4ec5\u56f4\u7ed5\u672a\u626d\u8f6c\u7684\u60c5\u51b5\uff08$\nTheat=0^\text{o}$\u548c$\nTheat=60^\text{o}$\uff09\u5bf9\u79f0\uff0c\u800c\u4e14\u56f4\u7ed5$\nTheat=30^\text{o}$\u4e5f\u5bf9\u79f0\u3002\u5c42\u95f4\u8026\u5408\u968f\u7740\u5171\u683c\u8d85\u80de\u5c3a\u5bf8\u7684\u589e\u5927\u800c\u51cf\u5c0f\uff0c\u8fd9\u8868\u660e\u5c42\u95f4\u8026\u5408\u7684\u5cf0\u503c\u4ec5\u51fa\u73b0\u5728\u5b58\u5728\u5c0f\u5c3a\u5bf8\u5171\u683c\u8d85\u80de\u7684\u626d\u8f6c\u89d2\u5904\u3002\u901a\u8fc7\u63a2\u7d22\u5c42\u95f4\u4e0d\u540c\u7684\u6a2a\u5411\u4f4d\u79fb\uff0c\u8bc1\u5b9e\u4e86\u4fdd\u62a4\u5f84\u5411Rashba\u7684\u5bf9\u79f0\u6027\u662f\u5e73\u9762\u5185180$^\text{o}$\u65cb\u8f6c\u8f74\u3002\u8fd8\u7814\u7a76\u4e86\u539f\u5b50\u5f1b\u8c6b\u548c\u5c42\u95f4\u8ddd\u79bb\u8c03 modulation \u7684\u5f71\u54cd\u3002", "conclusion": "\u7ed3\u679c\u4e3a\u57fa\u4e8e\u626d\u66f2\u5c42\u72b6\u6750\u6599\u7684\u81ea\u65cb-\u7535\u8377\u8f6c\u6362\u65b9\u6848\u5de5\u7a0b\u63d0\u4f9b\u4e86\u57fa\u7840\u6027\u7684\u5fae\u89c2\u89c1\u89e3\u3002"}}
{"id": "2509.09953", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.09953", "abs": "https://arxiv.org/abs/2509.09953", "authors": ["Mahfuzul I. Nissan", "Sharmin Aktar"], "title": "Detection of Anomalous Behavior in Robot Systems Based on Machine Learning", "comment": null, "summary": "Ensuring the safe and reliable operation of robotic systems is paramount to\nprevent potential disasters and safeguard human well-being. Despite rigorous\ndesign and engineering practices, these systems can still experience\nmalfunctions, leading to safety risks. In this study, we present a machine\nlearning-based approach for detecting anomalies in system logs to enhance the\nsafety and reliability of robotic systems. We collected logs from two distinct\nscenarios using CoppeliaSim and comparatively evaluated several machine\nlearning models, including Logistic Regression (LR), Support Vector Machine\n(SVM), and an Autoencoder. Our system was evaluated in a quadcopter context\n(Context 1) and a Pioneer robot context (Context 2). Results showed that while\nLR demonstrated superior performance in Context 1, the Autoencoder model proved\nto be the most effective in Context 2. This highlights that the optimal model\nchoice is context-dependent, likely due to the varying complexity of anomalies\nacross different robotic platforms. This research underscores the value of a\ncomparative approach and demonstrates the particular strengths of autoencoders\nfor detecting complex anomalies in robotic systems.", "AI": {"tldr": "\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u68c0\u6d4b\u673a\u5668\u4eba\u7cfb\u7edf\u65e5\u5fd7\u4e2d\u7684\u5f02\u5e38\uff0c\u4ee5\u63d0\u9ad8\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u786e\u4fdd\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u5b89\u5168\u53ef\u9760\u8fd0\u884c\u81f3\u5173\u91cd\u8981\uff0c\u4ee5\u9632\u6b62\u6f5c\u5728\u7684\u707e\u96be\u5e76\u4fdd\u969c\u4eba\u7c7b\u798f\u7949\u3002", "method": "\u6536\u96c6\u6765\u81ea\u4e0d\u540c\u573a\u666f\uff08\u5305\u62ec\u5728CoppeliaSim\u4e2d\u6a21\u62df\u7684\u56db\u65cb\u7ffc\u98de\u884c\u5668\u548cPioneer\u673a\u5668\u4eba\uff09\u7684\u65e5\u5fd7\uff0c\u5e76\u6bd4\u8f83\u4e86\u903b\u8f91\u56de\u5f52\uff08LR\uff09\u3001\u652f\u6301\u5411\u91cf\u673a\uff08SVM\uff09\u548c\u81ea\u52a8\u7f16\u7801\u5668\uff08Autoencoder\uff09\u7b49\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u6027\u80fd\u3002", "result": "\u5728\u56db\u65cb\u7ffc\u98de\u884c\u5668\u573a\u666f\uff08Context 1\uff09\u4e2d\uff0cLR\u6a21\u578b\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u6027\u80fd\uff1b\u800c\u5728Pioneer\u673a\u5668\u4eba\u573a\u666f\uff08Context 2\uff09\u4e2d\uff0c\u81ea\u52a8\u7f16\u7801\u5668\u6a21\u578b\u6700\u4e3a\u6709\u6548\u3002", "conclusion": "\u6700\u4f18\u6a21\u578b\u7684\u9009\u62e9\u53d6\u51b3\u4e8e\u5177\u4f53\u5e94\u7528\u573a\u666f\uff0c\u8fd9\u53ef\u80fd\u662f\u7531\u4e8e\u4e0d\u540c\u673a\u5668\u4eba\u5e73\u53f0\u4e0a\u7684\u5f02\u5e38\u590d\u6742\u6027\u4e0d\u540c\u3002\u8be5\u7814\u7a76\u5f3a\u8c03\u4e86\u6bd4\u8f83\u65b9\u6cd5\u7684\u91cd\u8981\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u81ea\u52a8\u7f16\u7801\u5668\u5728\u68c0\u6d4b\u673a\u5668\u4eba\u7cfb\u7edf\u4e2d\u590d\u6742\u5f02\u5e38\u65b9\u9762\u7684\u72ec\u7279\u4f18\u52bf\u3002"}}
{"id": "2509.09862", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2509.09862", "abs": "https://arxiv.org/abs/2509.09862", "authors": ["Milind Upadhyay", "Mark Nicholas Jones"], "title": "Comparative Studies of Quantum Annealing, Digital Annealing, and Classical Solvers for Reaction Network Pathway Analysis and mRNA Codon Selection", "comment": "56 pages, 9 figures, 13 tables, 56 references", "summary": "For various optimization problems, the classical time to solution is\nsuper-polynomial and intractable to solve with classical bit-based computing\nhardware to date. Digital and quantum annealers have the potential to identify\nnear-optimal solutions for such optimization problems using a quadratic\nunconstrained binary optimization (QUBO) problem formulation. This work\nbenchmarks two use cases to evaluate the utility of QUBO solvers for\ncombinatorial optimization problems, in order to determine if a QUBO\nformulation and annealing-based algorithms have an advantage over classical\nmixed-integer programming (MIP) and constraint programming (CP) solvers.\nVarious QUBO and solver metrics such as problem mapping, quantitative\ninterconnectivity, penalty structure, solver minimum cost (obtained optimal\nvalue) and solver time to solution have been applied to evaluate different QUBO\nproblems. Constrained and unconstrained QUBO solvers are compared including the\nFujitsu digital annealer (DA), various D-Wave hybrid quantum annealing solvers\n(QA, HQA), and the classical MIP/CP solvers HiGHS, Gurobi, SCIP, and CP-SAT.\nThe two industrially relevant use cases are reaction network pathway analysis\nand mRNA codon selection. For reaction pathway analysis, classical MIP/CP\nsolvers are observed to solve the problem to optimality in reasonable time\nframes while the DA is not able to do so. For mRNA codon selection, CP-SAT\ndisplayed the best performance for standard and large protein datasets (under\n1500 amino acids). For the extra-large protein dataset (11000 to 14000 amino\nacids), the D-Wave Nonlinear HQA solver performed comparably to CP-SAT,\noutperforming it in minimum cost in 2 out of the 4 problems.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86QUBO\u6c42\u89e3\u5668\u5728\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u4e0a\u7684\u6548\u7528\uff0c\u5e76\u5c06\u5176\u4e0e\u7ecf\u5178\u7684MIP\u548cCP\u6c42\u89e3\u5668\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002", "motivation": "\u4e0e\u7ecf\u5178\u7684\u6bd4\u7279\u8ba1\u7b97\u786c\u4ef6\u76f8\u6bd4\uff0c\u6570\u5b57\u548c\u91cf\u5b50\u9000\u706b\u5668\u5728\u89e3\u51b3\u8ba1\u7b97\u5bc6\u96c6\u578b\u4f18\u5316\u95ee\u9898\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u672c\u7814\u7a76\u65e8\u5728\u8bc4\u4f30QUBO\u6c42\u89e3\u5668\u5728\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u4e0a\u7684\u6548\u7528\uff0c\u5e76\u786e\u5b9aQUBO\u516c\u5f0f\u548c\u9000\u706b\u7b97\u6cd5\u662f\u5426\u4f18\u4e8e\u7ecf\u5178\u7684MIP\u548cCP\u6c42\u89e3\u5668\u3002", "method": "\u901a\u8fc7\u6bd4\u8f83QUBO\u6c42\u89e3\u5668\uff08\u5305\u62ecFujitsu DA\u3001D-Wave QA\u548cHQA\uff09\u4e0e\u7ecf\u5178MIP/CP\u6c42\u89e3\u5668\uff08HiGHS\u3001Gurobi\u3001SCIP\u548cCP-SAT\uff09\uff0c\u5bf9\u4e24\u4e2a\u5b9e\u9645\u5e94\u7528\u6848\u4f8b\u2014\u2014\u53cd\u5e94\u7f51\u7edc\u901a\u8def\u5206\u6790\u548cmRNA\u5bc6\u7801\u5b50\u9009\u62e9\u2014\u2014\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002\u4f7f\u7528\u95ee\u9898\u6620\u5c04\u3001\u4e92\u8fde\u6027\u3001\u60e9\u7f5a\u7ed3\u6784\u3001\u6c42\u89e3\u5668\u6700\u5c0f\u6210\u672c\u548c\u6c42\u89e3\u65f6\u95f4\u7b49\u6307\u6807\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5728\u53cd\u5e94\u901a\u8def\u5206\u6790\u4e2d\uff0cMIP/CP\u6c42\u89e3\u5668\u80fd\u591f\u4ee5\u5408\u7406\u7684\u65f6\u95f4\u627e\u5230\u6700\u4f18\u89e3\uff0c\u800cDA\u672a\u80fd\u627e\u5230\u3002\u5728mRNA\u5bc6\u7801\u5b50\u9009\u62e9\u4e2d\uff0cCP-SAT\u5728\u6807\u51c6\u548c\u5927\u578b\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u800c\u5728\u8d85\u5927\u578b\u6570\u636e\u96c6\u4e0a\uff0cD-Wave HQA\u6c42\u89e3\u5668\u7684\u6027\u80fd\u4e0eCP-SAT\u76f8\u5f53\uff0c\u5e76\u57282/4\u4e2a\u95ee\u9898\u4e2d\u4ee5\u66f4\u5c0f\u7684\u6210\u672c\u83b7\u5f97\u6700\u4f18\u89e3\u3002", "conclusion": "QUBO\u65b9\u6cd5\u548c\u9000\u706b\u7b97\u6cd5\u5728\u67d0\u4e9b\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u4e0a\u53ef\u80fd\u63d0\u4f9b\u4f18\u52bf\uff0c\u4f46\u5e76\u975e\u603b\u662f\u4f18\u4e8e\u7ecf\u5178\u7684MIP\u548cCP\u6c42\u89e3\u5668\u3002\u5177\u4f53\u6027\u80fd\u53d6\u51b3\u4e8e\u95ee\u9898\u7684\u6027\u8d28\u548c\u89c4\u6a21\uff0c\u4ee5\u53ca\u6240\u4f7f\u7528\u7684\u7279\u5b9a\u6c42\u89e3\u5668\u3002"}}
{"id": "2509.10326", "categories": ["cs.AI", "cs.LO", "03G27 (Primary) 68W30, 68T27 (Secondary)"], "pdf": "https://arxiv.org/pdf/2509.10326", "abs": "https://arxiv.org/abs/2509.10326", "authors": ["Dmitry Lesnik", "Tobias Sch\u00e4fer"], "title": "State Algebra for Propositional Logic", "comment": "47 pages", "summary": "This paper presents State Algebra, a novel framework designed to represent\nand manipulate propositional logic using algebraic methods. The framework is\nstructured as a hierarchy of three representations: Set, Coordinate, and Row\nDecomposition. These representations anchor the system in well-known semantics\nwhile facilitating the computation using a powerful algebraic engine. A key\naspect of State Algebra is its flexibility in representation. We show that\nalthough the default reduction of a state vector is not canonical, a unique\ncanonical form can be obtained by applying a fixed variable order during the\nreduction process. This highlights a trade-off: by foregoing guaranteed\ncanonicity, the framework gains increased flexibility, potentially leading to\nmore compact representations of certain classes of problems. We explore how\nthis framework provides tools to articulate both search-based and knowledge\ncompilation algorithms and discuss its natural extension to probabilistic logic\nand Weighted Model Counting.", "AI": {"tldr": "State Algebra\u662f\u4e00\u4e2a\u4f7f\u7528\u4ee3\u6570\u65b9\u6cd5\u8868\u793a\u548c\u64cd\u4f5c\u547d\u9898\u903b\u8f91\u7684\u65b0\u6846\u67b6\uff0c\u5305\u542b\u96c6\u5408\u3001\u5750\u6807\u548c\u884c\u5206\u89e3\u4e09\u79cd\u8868\u793a\u5f62\u5f0f\uff0c\u5177\u6709\u7075\u6d3b\u6027\uff0c\u867d\u7136\u9ed8\u8ba4\u7b80\u5316\u4e0d\u5177\u6709\u552f\u4e00\u6027\uff0c\u4f46\u53ef\u4ee5\u901a\u8fc7\u56fa\u5b9a\u53d8\u91cf\u987a\u5e8f\u83b7\u5f97\u552f\u4e00\u5f62\u5f0f\uff0c\u5e76\u53ef\u7528\u4e8e\u641c\u7d22\u548c\u77e5\u8bc6\u7f16\u8bd1\u7b97\u6cd5\u3002", "motivation": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u4ee3\u6570\u65b9\u6cd5\u8868\u793a\u548c\u64cd\u4f5c\u547d\u9898\u903b\u8f91\u7684\u65b0\u6846\u67b6State Algebra\u3002", "method": "\u8be5\u6846\u67b6\u5305\u542b\u96c6\u5408\u3001\u5750\u6807\u548c\u884c\u5206\u89e3\u4e09\u79cd\u8868\u793a\u5f62\u5f0f\uff0c\u5e76\u901a\u8fc7\u4ee3\u6570\u5f15\u64ce\u8fdb\u884c\u8ba1\u7b97\u3002\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u7b80\u5316\u8fc7\u7a0b\u4e2d\u901a\u8fc7\u56fa\u5b9a\u53d8\u91cf\u987a\u5e8f\u83b7\u5f97\u552f\u4e00\u5f62\u5f0f\u7684\u65b9\u6cd5\u3002", "result": "State Algebra\u6846\u67b6\u5177\u6709\u7075\u6d3b\u6027\uff0c\u53ef\u4ee5\u901a\u8fc7\u56fa\u5b9a\u53d8\u91cf\u987a\u5e8f\u83b7\u5f97\u552f\u4e00\u5f62\u5f0f\uff0c\u5e76\u53ef\u7528\u4e8e\u641c\u7d22\u548c\u77e5\u8bc6\u7f16\u8bd1\u7b97\u6cd5\uff0c\u8fd8\u53ef\u4ee5\u6269\u5c55\u5230\u6982\u7387\u903b\u8f91\u548c\u52a0\u6743\u6a21\u578b\u8ba1\u6570\u3002", "conclusion": "State Algebra\u901a\u8fc7\u4ee3\u6570\u65b9\u6cd5\u63d0\u4f9b\u4e86\u8868\u793a\u548c\u64cd\u4f5c\u547d\u9898\u903b\u8f91\u7684\u7075\u6d3b\u6846\u67b6\uff0c\u5e76\u5728\u53ef\u6269\u5c55\u6027\u65b9\u9762\u5c55\u73b0\u4e86\u6f5c\u529b\u3002"}}
{"id": "2509.10302", "categories": ["physics.app-ph"], "pdf": "https://arxiv.org/pdf/2509.10302", "abs": "https://arxiv.org/abs/2509.10302", "authors": ["Toji Thomas", "Kevin F. MacDonald", "Eric Plum"], "title": "Control of nanomechanical resonances by an electron beam", "comment": "9 pages, 5 figures", "summary": "The sensitivity of mechanical resonators to physical quantities such as\nacceleration, pressure, mass and temperature enables them to underpin sensing\nand metrology applications. Here, we observe that the resonance frequency of a\nnanomechanical resonator depends strongly on charging. We show that repulsion\nbetween an electron beam and charge accumulated on a nanomechanical cantilever\nyields a stiffening that increases its resonance frequency, providing a\nmechanism for controlling resonators and sensing charge. For a cantilever of\nmicroscale length and nanoscale cross-section interacting with the electron\nbeam of a scanning electron microscope, we observe a resonance shift on the\norder of 1% per nanocoulomb.", "AI": {"tldr": "\u7535\u5b50\u675f\u4e0e\u7eb3\u7c73\u673a\u68b0\u632f\u5b50\u4e0a\u7684\u7535\u8377\u4e4b\u95f4\u7684\u6392\u65a5\u529b\u53ef\u4ee5\u589e\u52a0\u632f\u5b50\u7684\u5171\u632f\u9891\u7387\uff0c\u4ece\u800c\u5b9e\u73b0\u5bf9\u632f\u5b50\u7684\u63a7\u5236\u548c\u7535\u8377\u4f20\u611f\u3002", "motivation": "\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u89c2\u5bdf\u5230\u7eb3\u7c73\u673a\u68b0\u632f\u5b50\u7684\u5171\u632f\u9891\u7387\u5f3a\u4f9d\u8d56\u4e8e\u7535\u8377\u3002 \u5df2\u7ecf\u8bc1\u660e\uff0c\u7535\u5b50\u675f\u548c\u7eb3\u7c73\u673a\u68b0\u6881\u4e0a\u7684\u7535\u8377\u4e4b\u95f4\u7684\u6392\u65a5\u4f1a\u4ea7\u751f\u786c\u5316\uff0c\u4ece\u800c\u589e\u52a0\u5176\u5171\u632f\u9891\u7387\u3002", "method": "\u901a\u8fc7\u626b\u63cf\u7535\u5b50\u663e\u5fae\u955c\u4e2d\u7684\u7535\u5b50\u675f\u4e0e\u5fae\u5c3a\u5ea6\u957f\u5ea6\u548c\u7eb3\u7c73\u5c3a\u5ea6\u6a2a\u622a\u9762\u7684\u60ac\u81c2\u6881\u7684\u76f8\u4e92\u4f5c\u7528\u6765\u89c2\u5bdf\u5171\u632f\u9891\u79fb\u3002", "result": "\u89c2\u5bdf\u5230\u6bcf\u7eb3\u5e93\u4ed1\u7684\u5171\u632f\u4f4d\u79fb\u7ea6\u4e3a 1%\u3002", "conclusion": "\u7535\u5b50\u675f\u4e0e\u7eb3\u7c73\u673a\u68b0\u632f\u5b50\u4e0a\u7684\u7535\u8377\u4e4b\u95f4\u7684\u6392\u65a5\u529b\u53ef\u4ee5\u589e\u52a0\u632f\u5b50\u7684\u5171\u632f\u9891\u7387\uff0c\u4ece\u800c\u5b9e\u73b0\u5bf9\u632f\u5b50\u7684\u63a7\u5236\u548c\u7535\u8377\u4f20\u611f\u3002"}}
{"id": "2509.10426", "categories": ["cs.RO", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.10426", "abs": "https://arxiv.org/abs/2509.10426", "authors": ["Jianxin Shi", "Zengqi Peng", "Xiaolong Chen", "Tianyu Wo", "Jun Ma"], "title": "DECAMP: Towards Scene-Consistent Multi-Agent Motion Prediction with Disentangled Context-Aware Pre-Training", "comment": null, "summary": "Trajectory prediction is a critical component of autonomous driving,\nessential for ensuring both safety and efficiency on the road. However,\ntraditional approaches often struggle with the scarcity of labeled data and\nexhibit suboptimal performance in multi-agent prediction scenarios. To address\nthese challenges, we introduce a disentangled context-aware pre-training\nframework for multi-agent motion prediction, named DECAMP. Unlike existing\nmethods that entangle representation learning with pretext tasks, our framework\ndecouples behavior pattern learning from latent feature reconstruction,\nprioritizing interpretable dynamics and thereby enhancing scene representation\nfor downstream prediction. Additionally, our framework incorporates\ncontext-aware representation learning alongside collaborative spatial-motion\npretext tasks, which enables joint optimization of structural and intentional\nreasoning while capturing the underlying dynamic intentions. Our experiments on\nthe Argoverse 2 benchmark showcase the superior performance of our method, and\nthe results attained underscore its effectiveness in multi-agent motion\nforecasting. To the best of our knowledge, this is the first context\nautoencoder framework for multi-agent motion forecasting in autonomous driving.\nThe code and models will be made publicly available.", "AI": {"tldr": "DECAMP\u662f\u4e00\u4e2a\u7528\u4e8e\u81ea\u52a8\u9a7e\u9a76\u591a\u667a\u80fd\u4f53\u8fd0\u52a8\u9884\u6d4b\u7684\u89e3\u8026\u4e0a\u4e0b\u6587\u611f\u77e5\u9884\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u8026\u884c\u4e3a\u6a21\u5f0f\u5b66\u4e60\u548c\u6f5c\u5728\u7279\u5f81\u91cd\u5efa\uff0c\u5e76\u7ed3\u5408\u4e0a\u4e0b\u6587\u611f\u77e5\u8868\u793a\u5b66\u4e60\u548c\u534f\u4f5c\u7a7a\u95f4-\u8fd0\u52a8\u9884\u8bad\u7ec3\u4efb\u52a1\uff0c\u4ee5\u63d0\u9ad8\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u8f68\u8ff9\u9884\u6d4b\u65b9\u6cd5\u5728\u6570\u636e\u7a00\u758f\u548c\u591a\u667a\u80fd\u4f53\u573a\u666f\u4e0b\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u63d0\u9ad8\u9884\u6d4b\u7684\u5b89\u5168\u6027\u4e0e\u6548\u7387\u3002", "method": "\u63d0\u51faDECAMP\u6846\u67b6\uff0c\u89e3\u8026\u884c\u4e3a\u6a21\u5f0f\u5b66\u4e60\u4e0e\u6f5c\u5728\u7279\u5f81\u91cd\u5efa\uff0c\u5f15\u5165\u4e0a\u4e0b\u6587\u611f\u77e5\u8868\u793a\u5b66\u4e60\u4ee5\u53ca\u534f\u4f5c\u7a7a\u95f4-\u8fd0\u52a8\u9884\u8bad\u7ec3\u4efb\u52a1\uff0c\u4ee5\u5b9e\u73b0\u53ef\u89e3\u91ca\u7684\u52a8\u529b\u5b66\u548c\u589e\u5f3a\u7684\u573a\u666f\u8868\u793a\u3002", "result": "\u5728Argoverse 2\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u4f18\u8d8a\u7684\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u591a\u667a\u80fd\u4f53\u8fd0\u52a8\u9884\u6d4b\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "DECAMP\u662f\u9996\u4e2a\u7528\u4e8e\u81ea\u52a8\u9a7e\u9a76\u591a\u667a\u80fd\u4f53\u8fd0\u52a8\u9884\u6d4b\u7684\u4e0a\u4e0b\u6587\u81ea\u7f16\u7801\u5668\u6846\u67b6\uff0c\u5728\u591a\u667a\u80fd\u4f53\u8fd0\u52a8\u9884\u6d4b\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2509.10076", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.10076", "abs": "https://arxiv.org/abs/2509.10076", "authors": ["Apostolos A. Tegos", "Yue Xiao", "Sotiris A. Tegos", "George K. Karagiannidis", "Panagiotis D. Diamantoulakis"], "title": "Uplink RSMA for Pinching-Antenna Systems", "comment": null, "summary": "One of the key goals of next-generation wireless networks is to adapt to\nchanging conditions and meet the growing demand for reliable, high-capacity\ncommunications from emerging applications. Overcoming the limitations of\nconventional technologies, such as fixed antenna positions, is essential to\nachieving this objective because it mitigates the impact of path loss on the\nreceived signal and creates strong line-of-sight links, enhancing system\nperformance. With this in mind, the newly proposed pinching antenna systems\n(PASs) are a promising solution for indoor applications because they can\nactivate antennas across a waveguide deployed in a room, thus reducing the\ndistance between the transmitter and receiver. In this paper, we investigate a\ntwo-user, two-pinching-antenna uplink PAS, in which the transmitters use rate\nsplitting to create a more resilient framework than non-orthogonal multiple\naccess (NOMA). For this network, we derive novel closed-form expressions for\nthe outage probability. Numerical results validate these expressions, proving\nthat the proposed rate-splitting multiple access (RSMA) scheme outperforms NOMA\nPAS.", "AI": {"tldr": " PASs\u901a\u8fc7\u5728\u623f\u95f4\u5185\u4f7f\u7528\u7684\u6ce2\u5bfc\u6fc0\u6d3b\u5929\u7ebf\uff0c\u4ee5\u51cf\u5c11\u6536\u53d1\u5668\u4e4b\u95f4\u7684\u8ddd\u79bb\u3002RSMA\u65b9\u6848\u4f18\u4e8eNOMA PAS\u3002", "motivation": "\u4e0b\u4e00\u4ee3\u65e0\u7ebf\u7f51\u7edc\u9700\u8981\u9002\u5e94\u4e0d\u65ad\u53d8\u5316\u7684\u73af\u5883\u5e76\u6ee1\u8db3\u65b0\u5174\u5e94\u7528\u5bf9\u53ef\u9760\u3001\u9ad8\u5bb9\u91cf\u901a\u4fe1\u65e5\u76ca\u589e\u957f\u7684\u9700\u6c42\u3002\u514b\u670d\u4f20\u7edf\u6280\u672f\u7684\u9650\u5236\uff0c\u4f8b\u5982\u56fa\u5b9a\u7684\u5929\u7ebf\u4f4d\u7f6e\uff0c\u5bf9\u4e8e\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\u81f3\u5173\u91cd\u8981\uff0c\u56e0\u4e3a\u5b83\u53ef\u4ee5\u51cf\u8f7b\u8def\u5f84\u635f\u8017\u5bf9\u63a5\u6536\u4fe1\u53f7\u7684\u5f71\u54cd\uff0c\u5e76\u521b\u5efa\u5f3a\u5927\u7684\u89c6\u7ebf\u94fe\u8def\uff0c\u4ece\u800c\u63d0\u9ad8\u7cfb\u7edf\u6027\u80fd\u3002", "method": "\u7814\u7a76\u4e86\u4e00\u4e2a\u53cc\u7528\u6237\u3001\u53cc the-pinching-antenna \u4e0a\u884c\u94fe\u8def PAS\uff0c\u5176\u4e2d\u53d1\u5c04\u5668\u4f7f\u7528\u901f\u7387\u5206\u88c2\u6765\u521b\u5efa\u4e00\u4e2a\u6bd4\u975e\u6b63\u4ea4\u591a\u5740\u63a5\u5165 (NOMA) \u66f4\u5177\u5f39\u6027\u7684\u6846\u67b6\u3002", "result": "\u63a8\u5bfc\u4e86\u8be5\u7f51\u7edc\u7684\u65ad\u70b9\u6982\u7387\u7684\u5c01\u95ed\u5f0f\u8868\u8fbe\u5f0f\u3002\u6570\u503c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u8868\u8fbe\u5f0f\uff0c\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u7684\u901f\u7387\u5206\u88c2\u591a\u5740\u63a5\u5165 (RSMA) \u65b9\u6848\u4f18\u4e8e NOMA PAS\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684 RSMA \u65b9\u6848\u5728\u53cc\u7528\u6237\u3001\u53cc the-pinching-antenna \u4e0a\u884c\u94fe\u8def PAS \u4e2d\u4f18\u4e8e NOMA PAS\u3002"}}
{"id": "2509.09998", "categories": ["cond-mat.mtrl-sci", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2509.09998", "abs": "https://arxiv.org/abs/2509.09998", "authors": ["Ana M. Valencia", "Lisa Schraut-May", "Marie Siegert", "Sebastian Hammer", "Beatrice Cula", "Alexandra Friedrich", "Holger Helten", "Jens Pflaum", "Caterina Cocchi", "Andreas Opitz"], "title": "Unveiling the Role of Solvents in DBTTF:HATCN Ternary Cocrystals", "comment": null, "summary": "Donor-acceptor (D:A) cocrystals offer a promising platform for\nnext-generation optoelectronic applications, but the impact of residual solvent\nmolecules on their properties remains an open question. We investigate six\nnovel D:A cocrystals of dibenzotetrathiafulvalene (DBTTF) and\n1,4,5,8,9,11-hexaazatriphenylenehexacarbo-nitrile (HATCN), prepared via solvent\nevaporation, yielding 1:1 molar ratios, and horizontal vapor deposition,\nresulting in solvent-free 3:2 cocrystals. Combining spectroscopy and\ndensity-functional theory (DFT) calculations, we find that, while the\nelectronic and optical properties of the cocrystals are largely unaffected by\nsolvent inclusion, the charge transfer mechanism is surprisingly complex. Raman\nspectroscopy reveals a consistent charge transfer of 0.11 $e$ across all\nconsidered structures, corroborated by DFT calculations on solvent-free\nsystems. Partial charge analysis reveals that in solvated cocrystals, solvent\nmolecules actively participate in the charge transfer process as primary\nelectron acceptors. This involvement can perturb the expected D:A behavior,\nrevealing a faceted charge-transfer mechanism in HATCN even beyond the\nestablished involvement of its cyano group. Overall, our study demonstrates\nthat while solution-based methods preserve the intrinsic D:A characteristics,\nsolvents can be leveraged as active electronic components, opening new avenues\nfor material design.", "AI": {"tldr": "\u6eb6\u5242\u5f71\u54cdDBTTF\u548cHATCN\u5171\u6676\u7684\u5149\u7535\u6027\u8d28\uff0c\u4f46\u4ee5\u610f\u60f3\u4e0d\u5230\u7684\u65b9\u5f0f\u5f71\u54cd\u7535\u8377\u8f6c\u79fb\u673a\u5236\u3002", "motivation": "\u7814\u7a76\u6b8b\u7559\u6eb6\u5242\u5206\u5b50\u5bf9DBTTF\u548cHATCN\u5171\u6676\u5149\u7535\u6027\u8d28\u7684\u5f71\u54cd\u3002", "method": "\u5236\u5907\u4e86\u516d\u79cd\u65b0\u7684DBTTF\u548cHATCN\u5171\u6676\uff08\u6eb6\u5242\u84b8\u53d1\u6cd5\u5f97\u52301:1\u6469\u5c14\u6bd4\uff0c\u6c34\u5e73\u6c14\u76f8\u6c89\u79ef\u6cd5\u5f97\u5230\u65e0\u6eb6\u52423:2\u5171\u6676\uff09\uff0c\u5e76\u7ed3\u5408\u5149\u8c31\u5b66\u548c\u5bc6\u5ea6\u6cdb\u51fd\u7406\u8bba\uff08DFT\uff09\u8ba1\u7b97\u8fdb\u884c\u5206\u6790\u3002", "result": "\u6240\u6709\u5171\u6676\u5747\u8868\u73b0\u51fa0.11 e\u7684\u7535\u8377\u8f6c\u79fb\u3002\u6eb6\u5242\u5316\u5171\u6676\u4e2d\uff0c\u6eb6\u5242\u5206\u5b50\u4f5c\u4e3a\u4e3b\u8981\u7684\u7535\u5b50\u53d7\u4f53\u53c2\u4e0e\u7535\u8377\u8f6c\u79fb\uff0c\u6539\u53d8\u4e86\u9884\u671f\u7684DBTTF:HATCN\u884c\u4e3a\uff0c\u5e76\u63ed\u793a\u4e86HATCN\u9664\u4e86\u6c30\u57fa\u4e4b\u5916\u7684\u591a\u9762\u7535\u8377\u8f6c\u79fb\u673a\u5236\u3002", "conclusion": "\u6eb6\u6db2\u6cd5\u5236\u5907\u7684\u5171\u6676\u80fd\u4fdd\u6301\u5176\u56fa\u6709\u7684DBTTF:HATCN\u7279\u6027\uff0c\u4f46\u6eb6\u5242\u53ef\u4ee5\u4f5c\u4e3a\u6709\u6e90\u7535\u5b50\u5143\u4ef6\uff0c\u4e3a\u6750\u6599\u8bbe\u8ba1\u5f00\u8f9f\u65b0\u9014\u5f84\u3002"}}
{"id": "2509.09704", "categories": ["cs.CL", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.09704", "abs": "https://arxiv.org/abs/2509.09704", "authors": ["Ali Mazyaki", "Mohammad Naghizadeh", "Samaneh Ranjkhah Zonouzaghi", "Hossein Setareh"], "title": "Temporal Preferences in Language Models for Long-Horizon Assistance", "comment": null, "summary": "We study whether language models (LMs) exhibit future- versus\npresent-oriented preferences in intertemporal choice and whether those\npreferences can be systematically manipulated. Using adapted human experimental\nprotocols, we evaluate multiple LMs on time-tradeoff tasks and benchmark them\nagainst a sample of human decision makers. We introduce an operational metric,\nthe Manipulability of Time Orientation (MTO), defined as the change in an LM's\nrevealed time preference between future- and present-oriented prompts. In our\ntests, reasoning-focused models (e.g., DeepSeek-Reasoner and grok-3-mini)\nchoose later options under future-oriented prompts but only partially\npersonalize decisions across identities or geographies. Moreover, models that\ncorrectly reason about time orientation internalize a future orientation for\nthemselves as AI decision makers. We discuss design implications for AI\nassistants that should align with heterogeneous, long-horizon goals and outline\na research agenda on personalized contextual calibration and socially aware\ndeployment.", "AI": {"tldr": "\u8bed\u8a00\u6a21\u578b\u5728\u8de8\u671f\u9009\u62e9\u4e2d\u8868\u73b0\u51fa\u672a\u6765\u5bfc\u5411\u7684\u504f\u597d\uff0c\u5e76\u4e14\u53ef\u4ee5\u901a\u8fc7\u63d0\u793a\u8fdb\u884c\u64cd\u7eb5\u3002", "motivation": "\u7814\u7a76\u8bed\u8a00\u6a21\u578b\u662f\u5426\u5728\u8de8\u671f\u9009\u62e9\u4e2d\u8868\u73b0\u51fa\u672a\u6765\u6216\u73b0\u5728\u5bfc\u5411\u7684\u504f\u597d\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u504f\u597d\u662f\u5426\u53ef\u4ee5\u901a\u8fc7\u63d0\u793a\u8fdb\u884c\u7cfb\u7edf\u6027\u64cd\u7eb5\u3002", "method": "\u4f7f\u7528\u6539\u7f16\u81ea\u4eba\u7c7b\u5b9e\u9a8c\u7684\u534f\u8bae\uff0c\u8bc4\u4f30\u591a\u4e2a\u8bed\u8a00\u6a21\u578b\u5728\u65f6\u95f4\u6743\u8861\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u4e0e\u4eba\u7c7b\u51b3\u7b56\u8005\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002\u5f15\u5165\u201c\u65f6\u95f4\u5bfc\u5411\u64cd\u7eb5\u6027\u201d\uff08MTO\uff09\u6307\u6807\u6765\u8861\u91cf\u63d0\u793a\u64cd\u7eb5\u7684\u6548\u679c\u3002", "result": "\u63a8\u7406\u80fd\u529b\u5f3a\u7684\u6a21\u578b\uff08\u5982DeepSeek-Reasoner\u548cgrok-3-mini\uff09\u5728\u672a\u6765\u5bfc\u5411\u63d0\u793a\u4e0b\u4f1a\u9009\u62e9\u8f83\u665a\u7684\u9009\u9879\uff0c\u4f46\u8de8\u8eab\u4efd\u6216\u5730\u57df\u7684\u4e2a\u6027\u5316\u51b3\u7b56\u80fd\u529b\u6709\u9650\u3002\u80fd\u591f\u6b63\u786e\u63a8\u7406\u65f6\u95f4\u5bfc\u5411\u7684\u6a21\u578b\u4f1a\u5c06\u672a\u6765\u5bfc\u5411\u5185\u5316\u4e3a\u81ea\u8eabAI\u51b3\u7b56\u8005\u7684\u504f\u597d\u3002", "conclusion": "\u8bed\u8a00\u6a21\u578b\u8868\u73b0\u51fa\u53ef\u64cd\u7eb5\u7684\u672a\u6765\u5bfc\u5411\u504f\u597d\uff0c\u5e76\u53ef\u80fd\u5185\u5316\u8fd9\u79cd\u504f\u597d\u3002\u8fd9\u5bf9\u8bbe\u8ba1\u7b26\u5408\u957f\u671f\u3001\u5f02\u6784\u76ee\u6807\u7684\u4eba\u5de5\u667a\u80fd\u52a9\u624b\u5177\u6709\u542f\u793a\u610f\u4e49\uff0c\u5e76\u6307\u660e\u4e86\u672a\u6765\u4e2a\u6027\u5316\u6821\u51c6\u548c\u9762\u5411\u793e\u4f1a\u7684\u90e8\u7f72\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2509.09782", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.09782", "abs": "https://arxiv.org/abs/2509.09782", "authors": ["Roshini Pulishetty", "Mani Kishan Ghantasala", "Keerthy Kaushik Dasoju", "Niti Mangwani", "Vishal Garimella", "Aditya Mate", "Somya Chatterjee", "Yue Kang", "Ehi Nosakhare", "Sadid Hasan", "Soundar Srinivasan"], "title": "One Head, Many Models: Cross-Attention Routing for Cost-Aware LLM Selection", "comment": null, "summary": "The proliferation of large language models (LLMs) with varying computational\ncosts and performance profiles presents a critical challenge for scalable,\ncost-effective deployment in real-world applications. We introduce a unified\nrouting framework that leverages a single-head cross-attention mechanism to\njointly model query and model embeddings, enabling dynamic selection of the\noptimal LLM for each input query. Our approach is evaluated on RouterBench, a\nlarge-scale, publicly available benchmark encompassing diverse LLM pools and\ndomains. By explicitly capturing fine-grained query-model interactions, our\nrouter predicts both response quality and generation cost, achieving up to 6.6%\nimprovement in Average Improvement in Quality (AIQ) and 2.9% in maximum\nperformance over existing routers. To robustly balance performance and cost, we\npropose an exponential reward function that enhances stability across user\npreferences. The resulting architecture is lightweight, generalizes effectively\nacross domains, and demonstrates improved efficiency compared to prior methods,\nestablishing a new standard for cost-aware LLM routing.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2509.10070", "categories": ["quant-ph", "cs.DM", "cs.DS", "math.CO"], "pdf": "https://arxiv.org/pdf/2509.10070", "abs": "https://arxiv.org/abs/2509.10070", "authors": ["Yixin Cao", "Yiren Lu", "Junhong Nie", "Xiaoming Sun", "Guojing Tian"], "title": "Toward Minimum Graphic Parity Networks", "comment": null, "summary": "Quantum circuits composed of CNOT and $R_z$ are fundamental building blocks\nof many quantum algorithms, so optimizing the synthesis of such quantum\ncircuits is crucial. We address this problem from a theoretical perspective by\nstudying the graphic parity network synthesis problem. A graphic parity network\nfor a graph $G$ is a quantum circuit composed solely of CNOT gates where each\nedge of $G$ is represented in the circuit, and the final state of the wires\nmatches the original input. We aim to synthesize graphic parity networks with\nthe minimum number of gates, specifically for quantum algorithms addressing\ncombinatorial optimization problems with Ising formulations. We demonstrate\nthat a graphic parity network for a connected graph with $n$ vertices and $m$\nedges requires at least $m+n-1$ gates. This lower bound can be improved to\n$m+\\Omega(m) = m+\\Omega(n^{1.5})$ when the shortest cycle in the graph has a\nlength of at least five. We complement this result with a simple randomized\nalgorithm that synthesizes a graphic parity network with expected $m +\nO(n^{1.5}\\sqrt{\\log n})$ gates. Additionally, we begin exploring connected\ngraphs that allow for graphic parity networks with exactly $m+n-1$ gates. We\nconjecture that all such graphs belong to a newly defined graph class.\nFurthermore, we present a linear-time algorithm for synthesizing minimum\ngraphic parity networks for graphs within this class. However, this graph class\nis not closed under taking induced subgraphs, and we show that recognizing it\nis $\\textsf{NP}$-complete, which is complemented with a fixed-parameter\ntractable algorithm parameterized by the treewidth.", "AI": {"tldr": "\u7814\u7a76\u4e86\u91cf\u5b50\u7ebf\u8def\u5408\u6210\u4e2d\u7684\u56fe\u6587\u7f51\u7edc\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u7406\u8bba\u4e0b\u754c\u548c\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u5e76\u63a2\u7d22\u4e86\u7279\u5b9a\u56fe\u7c7b\u7684\u6700\u5c0f\u7ebf\u8def\u5408\u6210\u3002", "motivation": "\u91cf\u5b50\u7ebf\u8def\uff08\u7279\u522b\u662fCNOT\u548cRz\u95e8\uff09\u662f\u91cf\u5b50\u7b97\u6cd5\u7684\u57fa\u7840\uff0c\u56e0\u6b64\u4f18\u5316\u8fd9\u7c7b\u7ebf\u8def\u7684\u5408\u6210\u81f3\u5173\u91cd\u8981\u3002\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u56fe\u6587\u7f51\u7edc\u7efc\u5408\u95ee\u9898\uff0c\u4e3a\u91cf\u5b50\u4f18\u5316\u7b97\u6cd5\u63d0\u4f9b\u66f4\u9ad8\u6548\u7684\u7ebf\u8def\u3002", "method": "1. \u7406\u8bba\u5206\u6790\uff1a\u7814\u7a76\u56fe\u6587\u7f51\u7edc\u7684\u95e8\u6570\u91cf\u4e0b\u754c\u3002\u5bf9\u4e8e\u8fde\u901a\u56fe\uff0c\u4e0b\u754c\u4e3am+n-1\u3002\u5f53\u6700\u77ed\u73af\u957f\u5ea6\u81f3\u5c11\u4e3a5\u65f6\uff0c\u4e0b\u754c\u53ef\u63d0\u5347\u81f3m+\u03a9(n^1.5)\u3002 2. \u7b97\u6cd5\u8bbe\u8ba1\uff1a\u63d0\u51fa\u4e00\u79cd\u968f\u673a\u5316\u7b97\u6cd5\uff0c\u671f\u671b\u5408\u6210\u7684\u7ebf\u8def\u5305\u542bm+O(n^1.5 * sqrt(log n))\u4e2a\u95e8\u3002 3. \u7279\u5b9a\u56fe\u7c7b\u63a2\u7d22\uff1a\u7814\u7a76\u80fd\u5b9e\u73b0m+n-1\u4e2a\u95e8\u7684\u6700\u5c11\u56fe\u6587\u7f51\u7edc\u7684\u56fe\u7c7b\uff0c\u5e76\u63d0\u51fa\u4e00\u4e2a\u7ebf\u6027\u65f6\u95f4\u5408\u6210\u7b97\u6cd5\u3002 4. \u590d\u6742\u5ea6\u5206\u6790\uff1a\u8bc1\u660e\u8bc6\u522b\u8be5\u7279\u5b9a\u56fe\u7c7b\u662fNP-complete\u7684\uff0c\u5e76\u63d0\u51fa\u4e00\u4e2a\u53c2\u6570\u5316\u4e3a\u6811\u5bbd\u7684\u56fa\u5b9a\u53c2\u6570\u53ef\u5904\u7406\u7b97\u6cd5\u3002", "result": "1. \u786e\u5b9a\u4e86\u56fe\u6587\u7f51\u7edc\u7684\u95e8\u6570\u91cf\u4e0b\u754c\u3002 2. \u63d0\u51fa\u4e86\u4e00\u4e2a\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u53ef\u5728\u671f\u671b\u65f6\u95f4\u5185\u751f\u6210\u63a5\u8fd1\u6700\u4f18\u7684\u7ebf\u8def\u3002 3. \u8bc6\u522b\u4e86\u4e00\u4e2a\u5177\u6709\u7279\u6b8a\u6027\u8d28\u7684\u56fe\u7c7b\uff0c\u5e76\u4e3a\u5176\u8bbe\u8ba1\u4e86\u9ad8\u6548\u7684\u5408\u6210\u7b97\u6cd5\u3002 4. \u5206\u6790\u4e86\u8be5\u56fe\u7c7b\u7684\u8bc6\u522b\u590d\u6742\u5ea6\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u56fe\u6587\u7f51\u7edc\u7684\u6700\u5c0f\u95e8\u6570\u91cf\u5408\u6210\u95ee\u9898\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u7406\u8bba\u8d21\u732e\u548c\u5b9e\u7528\u7684\u7b97\u6cd5\u3002\u867d\u7136\u8bc6\u522b\u6700\u5c0f\u95e8\u7ebf\u8def\u7684\u7279\u5b9a\u56fe\u7c7b\u5177\u6709\u6311\u6218\u6027\uff08NP-complete\uff09\uff0c\u4f46\u901a\u8fc7\u6811\u5bbd\u53c2\u6570\u5316\u4ecd\u53ef\u5b9e\u73b0\u9ad8\u6548\u5904\u7406\u3002"}}
{"id": "2509.09848", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09848", "abs": "https://arxiv.org/abs/2509.09848", "authors": ["Nana Han", "Dong Liu", "Tomas Norton"], "title": "Towards an AI-based knowledge assistant for goat farmers based on Retrieval-Augmented Generation", "comment": null, "summary": "Large language models (LLMs) are increasingly being recognised as valuable\nknowledge communication tools in many industries. However, their application in\nlivestock farming remains limited, being constrained by several factors not\nleast the availability, diversity and complexity of knowledge sources. This\nstudy introduces an intelligent knowledge assistant system designed to support\nhealth management in farmed goats. Leveraging the Retrieval-Augmented\nGeneration (RAG), two structured knowledge processing methods, table\ntextualization and decision-tree textualization, were proposed to enhance large\nlanguage models' (LLMs) understanding of heterogeneous data formats. Based on\nthese methods, a domain-specific goat farming knowledge base was established to\nimprove LLM's capacity for cross-scenario generalization. The knowledge base\nspans five key domains: Disease Prevention and Treatment, Nutrition Management,\nRearing Management, Goat Milk Management, and Basic Farming Knowledge.\nAdditionally, an online search module is integrated to enable real-time\nretrieval of up-to-date information. To evaluate system performance, six\nablation experiments were conducted to examine the contribution of each\ncomponent. The results demonstrated that heterogeneous knowledge fusion method\nachieved the best results, with mean accuracies of 87.90% on the validation set\nand 84.22% on the test set. Across the text-based, table-based, decision-tree\nbased Q&A tasks, accuracy consistently exceeded 85%, validating the\neffectiveness of structured knowledge fusion within a modular design. Error\nanalysis identified omission as the predominant error category, highlighting\nopportunities to further improve retrieval coverage and context integration. In\nconclusion, the results highlight the robustness and reliability of the\nproposed system for practical applications in goat farming.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7684\u667a\u80fd\u77e5\u8bc6\u52a9\u624b\u7cfb\u7edf\uff0c\u7528\u4e8e\u652f\u6301\u5c71\u7f8a\u517b\u6b96\u5065\u5eb7\u7ba1\u7406\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u77e5\u8bc6\u5904\u7406\u65b9\u6cd5\uff08\u8868\u683c\u6587\u672c\u5316\u548c\u51b3\u7b56\u6811\u6587\u672c\u5316\uff09\u589e\u5f3aLLM\u5bf9\u5f02\u6784\u6570\u636e\u7684\u7406\u89e3\uff0c\u5e76\u5efa\u7acb\u4e86\u5305\u542b\u4e94\u4e2a\u5173\u952e\u9886\u57df\u77e5\u8bc6\u7684\u5c71\u7f8a\u517b\u6b96\u77e5\u8bc6\u5e93\uff0c\u96c6\u6210\u4e86\u5728\u7ebf\u641c\u7d22\u6a21\u5757\u4ee5\u83b7\u53d6\u5b9e\u65f6\u4fe1\u606f\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u5f02\u6784\u77e5\u8bc6\u878d\u5408\u65b9\u6cd5\u5728\u9a8c\u8bc1\u96c6\u548c\u6d4b\u8bd5\u96c6\u4e0a\u5206\u522b\u8fbe\u5230\u4e8687.90%\u548c84.22%\u7684\u51c6\u786e\u7387\uff0c\u5e76\u5728\u6587\u672c\u3001\u8868\u683c\u548c\u51b3\u7b56\u6811\u95ee\u7b54\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u867d\u7136\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5404\u884c\u4e1a\u6709\u5e94\u7528\uff0c\u4f46\u5728\u755c\u7267\u4e1a\uff08\u7279\u522b\u662f\u5c71\u7f8a\u517b\u6b96\uff09\u4e2d\u7684\u5e94\u7528\u53d7\u9650\u4e8e\u77e5\u8bc6\u6765\u6e90\u7684\u53ef\u7528\u6027\u3001\u591a\u6837\u6027\u548c\u590d\u6742\u6027\u3002\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u4e3a\u5c71\u7f8a\u517b\u6b96\u5065\u5eb7\u7ba1\u7406\u63d0\u4f9b\u4e00\u4e2a\u667a\u80fd\u77e5\u8bc6\u52a9\u624b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7684\u667a\u80fd\u77e5\u8bc6\u52a9\u624b\u7cfb\u7edf\u3002\u91c7\u7528\u4e86\u4e24\u79cd\u7ed3\u6784\u5316\u77e5\u8bc6\u5904\u7406\u65b9\u6cd5\uff1a\u8868\u683c\u6587\u672c\u5316\u548c\u51b3\u7b56\u6811\u6587\u672c\u5316\uff0c\u4ee5\u589e\u5f3aLLM\u5bf9\u5f02\u6784\u6570\u636e\u683c\u5f0f\u7684\u7406\u89e3\u3002\u5efa\u7acb\u4e86\u5305\u542b\u75be\u75c5\u9884\u9632\u4e0e\u6cbb\u7597\u3001\u8425\u517b\u7ba1\u7406\u3001\u9972\u517b\u7ba1\u7406\u3001\u7f8a\u5976\u7ba1\u7406\u548c\u57fa\u7840\u517b\u6b96\u77e5\u8bc6\u4e94\u4e2a\u9886\u57df\u7684\u9886\u57df\u7279\u5b9a\u5c71\u7f8a\u517b\u6b96\u77e5\u8bc6\u5e93\u3002\u96c6\u6210\u4e86\u5728\u7ebf\u641c\u7d22\u6a21\u5757\u4ee5\u68c0\u7d22\u6700\u65b0\u4fe1\u606f\u3002\u8fdb\u884c\u4e86\u516d\u9879\u6d88\u878d\u5b9e\u9a8c\u6765\u8bc4\u4f30\u7cfb\u7edf\u7ec4\u4ef6\u7684\u8d21\u732e\u3002", "result": "\u5f02\u6784\u77e5\u8bc6\u878d\u5408\u65b9\u6cd5\u53d6\u5f97\u4e86\u6700\u4f73\u7ed3\u679c\uff0c\u5728\u9a8c\u8bc1\u96c6\u4e0a\u7684\u5e73\u5747\u51c6\u786e\u7387\u4e3a87.90%\uff0c\u5728\u6d4b\u8bd5\u96c6\u4e0a\u7684\u5e73\u5747\u51c6\u786e\u7387\u4e3a84.22%\u3002\u5728\u57fa\u4e8e\u6587\u672c\u3001\u8868\u683c\u548c\u51b3\u7b56\u6811\u7684\u95ee\u7b54\u4efb\u52a1\u4e2d\uff0c\u51c6\u786e\u7387\u6301\u7eed\u8d85\u8fc785%\u3002\u9519\u8bef\u5206\u6790\u663e\u793a\u9057\u6f0f\u662f\u6700\u4e3b\u8981\u7684\u9519\u8bef\u7c7b\u522b\uff0c\u8868\u660e\u5728\u6539\u8fdb\u68c0\u7d22\u8986\u76d6\u7387\u548c\u4e0a\u4e0b\u6587\u96c6\u6210\u65b9\u9762\u5b58\u5728\u673a\u4f1a\u3002", "conclusion": "\u63d0\u51fa\u7684\u7cfb\u7edf\u5728\u5b9e\u9645\u7684\u5c71\u7f8a\u517b\u6b96\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u7a33\u5065\u6027\u548c\u53ef\u9760\u6027\uff0c\u8bc1\u660e\u4e86\u7ed3\u6784\u5316\u77e5\u8bc6\u878d\u5408\u5728\u6a21\u5757\u5316\u8bbe\u8ba1\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2509.09937", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.09937", "abs": "https://arxiv.org/abs/2509.09937", "authors": ["Wenqi Cui", "Yiheng Xie", "Steven Low", "Adam Wierman", "Baosen Zhang"], "title": "Leveraging Predictions in Power System Voltage Control: An Adaptive Approach", "comment": null, "summary": "High variability of solar PV and sudden changes in load (e.g., electric\nvehicles and storage) can lead to large voltage fluctuations in the\ndistribution system. In recent years, a number of controllers have been\ndesigned to optimize voltage control. These controllers, however, almost always\nassume that the net load in the system remains constant over a sufficiently\nlong time, such that the control actions converge before the load changes\nagain. Given the intermittent and uncertain nature of renewable resources, it\nis becoming important to explicitly consider net load that is time-varying.\n  This paper proposes an adaptive approach to voltage control in power systems\nwith significant time-varying net load. We leverage advances in short-term load\nforecasting, where the net load in the system can be partially predicted using\nlocal measurements. We integrate these predictions into the design of adaptive\ncontrollers, and prove that the overall control architecture achieves\ninput-to-state stability in a decentralized manner. We optimize the control\npolicy through reinforcement learning. Case studies are conducted using\ntime-varying load data from a real-world distribution system.", "AI": {"tldr": "This paper proposes an adaptive voltage control approach for power systems with time-varying net load, using short-term load forecasting and reinforcement learning to achieve decentralized input-to-state stability.", "motivation": "Voltage fluctuations in distribution systems caused by high variability of solar PV and sudden load changes are a significant problem. Existing controllers often assume constant net load, which is unrealistic given the intermittent nature of renewables. Therefore, there is a need for controllers that explicitly consider time-varying net load.", "method": "The proposed approach integrates short-term load forecasting with adaptive controllers to predict and manage time-varying net load. Reinforcement learning is used to optimize the control policy. The overall control architecture is designed to achieve decentralized input-to-state stability.", "result": "The effectiveness of the proposed adaptive voltage control approach was demonstrated through case studies using real-world distribution system data with time-varying load.", "conclusion": "The paper presents a novel adaptive voltage control strategy that effectively addresses the challenges posed by time-varying net load in power systems. The approach, which utilizes short-term load forecasting and reinforcement learning, achieves decentralized input-to-state stability and is validated through practical case studies."}}
{"id": "2509.09737", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.09737", "abs": "https://arxiv.org/abs/2509.09737", "authors": ["Klemen Kotar", "Wanhee Lee", "Rahul Venkatesh", "Honglin Chen", "Daniel Bear", "Jared Watrous", "Simon Kim", "Khai Loong Aw", "Lilian Naing Chen", "Stefan Stojanov", "Kevin Feigelis", "Imran Thobani", "Alex Durango", "Khaled Jedoui", "Atlas Kazemian", "Dan Yamins"], "title": "World Modeling with Probabilistic Structure Integration", "comment": null, "summary": "We present Probabilistic Structure Integration (PSI), a system for learning\nrichly controllable and flexibly promptable world models from data. PSI\nconsists of a three-step cycle. The first step, Probabilistic prediction,\ninvolves building a probabilistic graphical model Psi of the data, in the form\nof a random-access autoregressive sequence model. Psi supports a complete set\nof learned conditional distributions describing the dependence of any variables\nin the data on any other set of variables. In step 2, Structure extraction, we\nshow how to extract underlying low-dimensional properties in the data,\ncorresponding to a diverse set of meaningful \"intermediate structures\", in a\nzero-shot fashion via causal inference on Psi. Step 3, Integration, completes\nthe cycle by converting these structures into new token types that are then\ncontinually mixed back into the training diet as conditioning signals and\nprediction targets. Each such cycle augments the capabilities of Psi, both\nallowing it to model the underlying data better, and creating new control\nhandles -- akin to an LLM-like universal prompting language. We train an\ninstance of Psi on 1.4 trillion tokens of internet video data; we use it to\nperform a variety of useful video prediction and understanding inferences; we\nextract state-of-the-art optical flow, self-supervised depth and object\nsegmentation; and we use these structures to support a full cycle of predictive\nimprovements.", "AI": {"tldr": "PSI\u662f\u4e00\u4e2a\u7528\u4e8e\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u53ef\u63a7\u3001\u53ef\u63d0\u793a\u7684\u4e16\u754c\u6a21\u578b\u7cfb\u7edf\u3002", "motivation": "\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u4e30\u5bcc\u53ef\u63a7\u3001\u7075\u6d3b\u53ef\u63d0\u793a\u7684\u4e16\u754c\u6a21\u578b\u3002", "method": "PSI\u5305\u542b\u4e09\u4e2a\u6b65\u9aa4\uff1a1. \u6982\u7387\u9884\u6d4b\uff1a\u6784\u5efa\u6570\u636e\u56fe\u6a21\u578bPsi\uff08\u968f\u673a\u8bbf\u95ee\u81ea\u56de\u5f52\u5e8f\u5217\u6a21\u578b\uff09\u30022. \u7ed3\u6784\u63d0\u53d6\uff1a\u901a\u8fc7\u56e0\u679c\u63a8\u65ad\u4ecePsi\u4e2d\u63d0\u53d6\u6709\u610f\u4e49\u7684\u201c\u4e2d\u95f4\u7ed3\u6784\u201d\u30023. \u96c6\u6210\uff1a\u5c06\u63d0\u53d6\u7684\u7ed3\u6784\u8f6c\u6362\u4e3a\u65b0\u7684\u6807\u8bb0\u7c7b\u578b\uff0c\u5e76\u6df7\u5408\u56de\u8bad\u7ec3\u6570\u636e\u3002\u6bcf\u4e2a\u5468\u671f\u90fd\u4f1a\u589e\u5f3aPsi\u7684\u80fd\u529b\uff0c\u63d0\u5347\u6570\u636e\u5efa\u6a21\u80fd\u529b\u5e76\u521b\u5efa\u65b0\u7684\u63a7\u5236\u67c4\u3002", "result": "\u57281.4\u4e07\u4ebf\u4e2a\u4e92\u8054\u7f51\u89c6\u9891\u6807\u8bb0\u4e0a\u8bad\u7ec3\u4e86Psi\u5b9e\u4f8b\uff0c\u5e76\u6267\u884c\u4e86\u6709\u7528\u7684\u89c6\u9891\u9884\u6d4b\u548c\u7406\u89e3\u63a8\u7406\u3002\u63d0\u53d6\u4e86\u6700\u5148\u8fdb\u7684\u5149\u6d41\u3001\u81ea\u76d1\u7763\u6df1\u5ea6\u548c\u5bf9\u8c61\u5206\u5272\u3002", "conclusion": "\u901a\u8fc7\u4f7f\u7528\u63d0\u53d6\u7684\u7ed3\u6784\u652f\u6301\u9884\u6d4b\u6539\u8fdb\u7684\u5b8c\u6574\u5468\u671f\uff0c\u8bc1\u660e\u4e86PSI\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2509.10228", "categories": ["cond-mat.mes-hall", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2509.10228", "abs": "https://arxiv.org/abs/2509.10228", "authors": ["Aarti Lakhara", "Lars Thole", "Rolf J. Haug", "P. A. Bhobe"], "title": "Anomalous Electrical Transport in SnSe$_2$ Nanosheets: Role of Thickness and Surface Defect States", "comment": null, "summary": "This work examines the influence of thickness on the electrical transport\nproperties of mechanically exfoliated two-dimensional SnSe$_2$ nanosheets,\nderived from the bulk single crystal. Contrary to conventional trend observed\nin two-dimensional systems, we find a semiconducting to metallic resistivity\nbehavior with decreasing thickness. The analysis of low-temperature conduction\nindicates an increased density of states at Fermi-level with decreasing\nthickness, which is further corroborated by gate bias dependent conductance\nmeasurement. The enhanced conductivity in thinner flake is attributed to the\nn-type doping arising from surface defect states. The presence and evolution of\nthese defect states with thickness is probed by thickness-dependent\nroom-temperature Raman spectroscopy. Our study provides insights into the\nthickness-dependent electronic transport mechanism of SnSe$_2$ and the crucial\nrole of defect states in governing the observed conductivity behavior.", "AI": {"tldr": "\u7814\u7a76\u4e86\u4e8c\u7ef4SnSe$_2$\u7eb3\u7c73\u7247\u7684\u539a\u5ea6\u5bf9\u5176\u7535\u5b66\u8f93\u8fd0\u6027\u8d28\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5176\u8868\u73b0\u51fa\u4e0e\u4f20\u7edf\u4e8c\u7ef4\u6750\u6599\u76f8\u53cd\u7684\u3001\u968f\u539a\u5ea6\u51cf\u5c0f\u800c\u4ece\u534a\u5bfc\u4f53\u5411\u91d1\u5c5e\u6027\u8f6c\u53d8\u7684\u7535\u963b\u884c\u4e3a\uff0c\u5e76\u8ba4\u4e3a\u8fd9\u662f\u7531\u8868\u9762\u7f3a\u9677\u6001\u5f15\u8d77\u7684n\u578b\u63ba\u6742\u6240\u81f4\u3002", "motivation": "\u7814\u7a76\u673a\u68b0\u5265\u79bb\u7684\u4e8c\u7ef4SnSe$_2$\u7eb3\u7c73\u7247\u4e2d\u539a\u5ea6\u5bf9\u5176\u7535\u5b66\u8f93\u8fd0\u6027\u8d28\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5176\u4e0e\u4f20\u7edf\u4e8c\u7ef4\u7cfb\u7edf\u76f8\u53cd\u7684\u3001\u968f\u539a\u5ea6\u51cf\u5c0f\u800c\u4ece\u534a\u5bfc\u4f53\u5411\u91d1\u5c5e\u6027\u8f6c\u53d8\u7684\u7535\u963b\u884c\u4e3a\u3002", "method": "\u901a\u8fc7\u5206\u6790\u4f4e\u6e29\u4f20\u5bfc\u548c\u6805\u6781\u7535\u538b\u4f9d\u8d56\u7684\u7535\u5bfc\u6d4b\u91cf\uff0c\u7814\u7a76\u4e86\u539a\u5ea6\u5bf9SnSe$_2$\u7535\u5b66\u8f93\u8fd0\u6027\u8d28\u7684\u5f71\u54cd\uff0c\u5e76\u5229\u7528\u539a\u5ea6\u4f9d\u8d56\u7684\u5ba4\u6e29\u62c9\u66fc\u5149\u8c31\u63a2\u7a76\u4e86\u7f3a\u9677\u6001\u7684\u5b58\u5728\u548c\u6f14\u5316\u3002", "result": "\u53d1\u73b0\u4e8c\u7ef4SnSe$_2$\u7eb3\u7c73\u7247\u7684\u7535\u963b\u884c\u4e3a\u968f\u539a\u5ea6\u51cf\u5c0f\u5448\u73b0\u51fa\u4ece\u534a\u5bfc\u4f53\u5230\u91d1\u5c5e\u6027\u7684\u8f6c\u53d8\uff1b\u5206\u6790\u8868\u660e\uff0c\u8fd9\u5f52\u56e0\u4e8e\u8868\u9762\u7f3a\u9677\u6001\u5f15\u8d77\u7684n\u578b\u63ba\u6742\uff0c\u589e\u52a0\u4e86\u8d39\u7c73\u80fd\u7ea7\u5904\u7684\u6001\u5bc6\u5ea6\u3002", "conclusion": "\u4e8c\u7ef4SnSe$_2$\u7eb3\u7c73\u7247\u7684\u7535\u5b66\u8f93\u8fd0\u673a\u5236\u548c\u7531\u7f3a\u9677\u6001\u63a7\u5236\u7684\u7535\u5bfc\u884c\u4e3a\u53d7\u5230\u539a\u5ea6\u7684\u5173\u952e\u5f71\u54cd\u3002"}}
{"id": "2509.10007", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.10007", "abs": "https://arxiv.org/abs/2509.10007", "authors": ["Samuli Soutukorva", "Markku Suomalainen", "Martin Kollingbaum", "Tapio Heikkil\u00e4"], "title": "Gaussian path model library for intuitive robot motion programming by demonstration", "comment": null, "summary": "This paper presents a system for generating Gaussian path models from\nteaching data representing the path shape. In addition, methods for using these\npath models to classify human demonstrations of paths are introduced. By\ngenerating a library of multiple Gaussian path models of various shapes, human\ndemonstrations can be used for intuitive robot motion programming. A method for\nmodifying existing Gaussian path models by demonstration through geometric\nanalysis is also presented.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u4ece\u8868\u793a\u8def\u5f84\u5f62\u72b6\u7684\u6559\u5b66\u6570\u636e\u751f\u6210\u9ad8\u65af\u8def\u5f84\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u5e76\u4ecb\u7ecd\u4e86\u4f7f\u7528\u8fd9\u4e9b\u8def\u5f84\u6a21\u578b\u5bf9\u4eba\u7c7b\u6f14\u793a\u8def\u5f84\u8fdb\u884c\u5206\u7c7b\u7684\u6280\u672f\u3002\u901a\u8fc7\u751f\u6210\u5305\u542b\u5404\u79cd\u5f62\u72b6\u7684\u9ad8\u65af\u8def\u5f84\u6a21\u578b\u5e93\uff0c\u53ef\u4ee5\u5b9e\u73b0\u76f4\u89c2\u7684\u673a\u5668\u4eba\u8fd0\u52a8\u7f16\u7a0b\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u51e0\u4f55\u5206\u6790\u4fee\u6539\u73b0\u6709\u9ad8\u65af\u8def\u5f84\u6a21\u578b\u7684\u65b9\u6cd5\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u751f\u6210\u9ad8\u65af\u8def\u5f84\u6a21\u578b\u6765\u7b80\u5316\u548c\u6539\u8fdb\u673a\u5668\u4eba\u8fd0\u52a8\u7f16\u7a0b\uff0c\u5e76\u5229\u7528\u4eba\u7c7b\u6f14\u793a\u6570\u636e\u5b9e\u73b0\u66f4\u76f4\u89c2\u7684\u4ea4\u4e92\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u4ece\u6559\u5b66\u6570\u636e\u751f\u6210\u9ad8\u65af\u8def\u5f84\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u5e76\u5f00\u53d1\u4e86\u7528\u4e8e\u5206\u7c7b\u4eba\u7c7b\u6f14\u793a\u8def\u5f84\u7684\u6a21\u578b\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u4f9b\u4e86\u4e00\u79cd\u901a\u8fc7\u51e0\u4f55\u5206\u6790\u4fee\u6539\u73b0\u6709\u9ad8\u65af\u8def\u5f84\u6a21\u578b\u7684\u65b9\u6cd5\u3002", "result": "\u7814\u7a76\u6210\u529f\u751f\u6210\u4e86\u9ad8\u65af\u8def\u5f84\u6a21\u578b\uff0c\u5e76\u5c55\u793a\u4e86\u5982\u4f55\u5229\u7528\u8fd9\u4e9b\u6a21\u578b\u5bf9\u4eba\u7c7b\u6f14\u793a\u8def\u5f84\u8fdb\u884c\u5206\u7c7b\uff0c\u4ee5\u53ca\u5982\u4f55\u901a\u8fc7\u6f14\u793a\u4fee\u6539\u73b0\u6709\u6a21\u578b\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684\u9ad8\u65af\u8def\u5f84\u6a21\u578b\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u5730\u4ece\u6559\u5b66\u6570\u636e\u4e2d\u5b66\u4e60\u8def\u5f84\u5f62\u72b6\uff0c\u5e76\u901a\u8fc7\u4eba\u7c7b\u6f14\u793a\u5b9e\u73b0\u76f4\u89c2\u7684\u673a\u5668\u4eba\u8fd0\u52a8\u7f16\u7a0b\u548c\u6a21\u578b\u4fee\u6539\u3002"}}
{"id": "2509.09874", "categories": ["quant-ph", "physics.atom-ph"], "pdf": "https://arxiv.org/pdf/2509.09874", "abs": "https://arxiv.org/abs/2509.09874", "authors": ["David M. Lancaster", "Muhammad Ali Shahbaz", "Hamed Goli Yousefabad", "Sanway Chatterjee", "Eegan Ram", "Jonathan D. Weinstein"], "title": "Quantum sensing in the presence of pulse errors and qubit leakage", "comment": null, "summary": "Using both simulation and experiment, we investigate the robustness of\ndynamical decoupling sequences to pulse errors: rotation errors and detuning\nerrors. Whereas prior work examined the effect of errors on coherence times,\nhere we show that quantum sensing can be affected by pulse errors in\ndramatically different ways than coherence times alone. We also explore the\neffects of qubit leakage: off-resonant coupling to other quantum levels. We\nfind order-of-magnitude differences between commonly-used dynamical decoupling\nsequences in both their sensitivity to pulse errors and leakage.", "AI": {"tldr": "\u672c\u7814\u7a76\u4f7f\u7528\u6a21\u62df\u548c\u5b9e\u9a8c\u6765\u8bc4\u4f30\u52a8\u6001\u89e3\u8026\u5e8f\u5217\u5bf9\u8109\u51b2\u9519\u8bef\u7684\u9c81\u68d2\u6027\uff0c\u53d1\u73b0\u8109\u51b2\u9519\u8bef\u5bf9\u91cf\u5b50\u4f20\u611f\u7684\u5f71\u54cd\u53ef\u80fd\u6bd4\u5bf9\u76f8\u5e72\u65f6\u95f4\u7684\u5f71\u54cd\u66f4\u4e3a\u663e\u8457\uff0c\u5e76\u4e14\u4e0d\u540c\u7684\u52a8\u6001\u89e3\u8026\u5e8f\u5217\u5728\u6297\u8109\u51b2\u9519\u8bef\u548c\u6291\u5236\u91cf\u5b50\u6bd4\u7279\u6cc4\u9732\u65b9\u9762\u8868\u73b0\u51fa\u6570\u91cf\u7ea7\u4e0a\u7684\u5dee\u5f02\u3002", "motivation": "\u7814\u7a76\u91cf\u5b50\u4f20\u611f\u4e2d\u52a8\u6001\u89e3\u8026\u5e8f\u5217\u5bf9\u8109\u51b2\u9519\u8bef\uff08\u65cb\u8f6c\u8bef\u5dee\u548c\u5931\u8c10\u8bef\u5dee\uff09\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u63a2\u8ba8\u91cf\u5b50\u6bd4\u7279\u6cc4\u9732\u7684\u5f71\u54cd\uff0c\u4ee5\u671f\u53d1\u73b0\u6bd4\u4ec5\u8003\u8651\u76f8\u5e72\u65f6\u95f4\u66f4\u5168\u9762\u7684\u8109\u51b2\u9519\u8bef\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u6a21\u62df\u548c\u5b9e\u9a8c\u76f8\u7ed3\u5408\u7684\u65b9\u5f0f\uff0c\u7814\u7a76\u4e86\u52a8\u6001\u89e3\u8026\u5e8f\u5217\u5bf9\u65cb\u8f6c\u8bef\u5dee\u3001\u5931\u8c10\u8bef\u5dee\u4ee5\u53ca\u91cf\u5b50\u6bd4\u7279\u6cc4\u9732\u7684\u654f\u611f\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u8109\u51b2\u9519\u8bef\u5bf9\u91cf\u5b50\u4f20\u611f\u7684\u5f71\u54cd\u53ef\u80fd\u4e0e\u5bf9\u76f8\u5e72\u65f6\u95f4\u7684\u5f71\u54cd\u6709\u663e\u8457\u4e0d\u540c\u3002\u4e0d\u540c\u7684\u52a8\u6001\u89e3\u8026\u5e8f\u5217\u5728\u5bf9\u8109\u51b2\u9519\u8bef\u7684\u654f\u611f\u6027\u548c\u6291\u5236\u91cf\u5b50\u6bd4\u7279\u6cc4\u9732\u65b9\u9762\u5b58\u5728\u6570\u91cf\u7ea7\u4e0a\u7684\u5dee\u5f02\u3002", "conclusion": "\u73b0\u6709\u7684\u52a8\u6001\u89e3\u8026\u5e8f\u5217\u5728\u6297\u8109\u51b2\u9519\u8bef\u548c\u91cf\u5b50\u6bd4\u7279\u6cc4\u9732\u65b9\u9762\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u4e3a\u9009\u62e9\u5408\u9002\u7684\u5e8f\u5217\u63d0\u4f9b\u4e86\u4f9d\u636e\u3002"}}
{"id": "2509.10227", "categories": ["cs.LG", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2509.10227", "abs": "https://arxiv.org/abs/2509.10227", "authors": ["\u00c1ngel Ladr\u00f3n", "Miguel S\u00e1nchez-Dom\u00ednguez", "Javier Rozal\u00e9n", "Fernando R. S\u00e1nchez", "Javier de Vicente", "Lucas Lacasa", "Eusebio Valero", "Gonzalo Rubio"], "title": "A Certifiable Machine Learning-Based Pipeline to Predict Fatigue Life of Aircraft Structures", "comment": "29 pages, 15 figures", "summary": "Fatigue life prediction is essential in both the design and operational\nphases of any aircraft, and in this sense safety in the aerospace industry\nrequires early detection of fatigue cracks to prevent in-flight failures.\nRobust and precise fatigue life predictors are thus essential to ensure safety.\nTraditional engineering methods, while reliable, are time consuming and involve\ncomplex workflows, including steps such as conducting several Finite Element\nMethod (FEM) simulations, deriving the expected loading spectrum, and applying\ncycle counting techniques like peak-valley or rainflow counting. These steps\noften require collaboration between multiple teams and tools, added to the\ncomputational time and effort required to achieve fatigue life predictions.\nMachine learning (ML) offers a promising complement to traditional fatigue life\nestimation methods, enabling faster iterations and generalization, providing\nquick estimates that guide decisions alongside conventional simulations.\n  In this paper, we present a ML-based pipeline that aims to estimate the\nfatigue life of different aircraft wing locations given the flight parameters\nof the different missions that the aircraft will be operating throughout its\noperational life. We validate the pipeline in a realistic use case of fatigue\nlife estimation, yielding accurate predictions alongside a thorough statistical\nvalidation and uncertainty quantification. Our pipeline constitutes a\ncomplement to traditional methodologies by reducing the amount of costly\nsimulations and, thereby, lowering the required computational and human\nresources.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u98de\u673a\u75b2\u52b3\u5bff\u547d\u9884\u6d4b\u65b9\u6cd5\uff0c\u4ee5\u66ff\u4ee3\u4f20\u7edf\u8017\u65f6\u7684\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u5b9e\u9645\u6848\u4f8b\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002", "motivation": "\u98de\u673a\u5728\u8bbe\u8ba1\u548c\u8fd0\u884c\u9636\u6bb5\u7684\u75b2\u52b3\u5bff\u547d\u9884\u6d4b\u5bf9\u4e8e\u786e\u4fdd\u822a\u7a7a\u5b89\u5168\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u53ca\u65e9\u68c0\u6d4b\u75b2\u52b3\u88c2\u7eb9\u4ee5\u9632\u6b62\u98de\u884c\u4e2d\u53d1\u751f\u6545\u969c\u3002\u4f20\u7edf\u7684\u5de5\u7a0b\u65b9\u6cd5\u867d\u7136\u53ef\u9760\uff0c\u4f46\u8017\u65f6\u4e14\u6d41\u7a0b\u590d\u6742\uff0c\u9700\u8981\u6709\u9650\u5143\u65b9\u6cd5\uff08FEM\uff09\u6a21\u62df\u3001\u8f7d\u8377\u8c31\u63a8\u5bfc\u548c\u5468\u671f\u8ba1\u6570\u6280\u672f\uff0c\u5e76\u4e14\u901a\u5e38\u9700\u8981\u591a\u56e2\u961f\u534f\u4f5c\u548c\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\u3002\u673a\u5668\u5b66\u4e60\uff08ML\uff09\u4e3a\u75b2\u52b3\u5bff\u547d\u4f30\u7b97\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u524d\u666f\u7684\u8865\u5145\uff0c\u53ef\u4ee5\u52a0\u5feb\u8fed\u4ee3\u901f\u5ea6\u3001\u63d0\u9ad8\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u4e3a\u4f20\u7edf\u6a21\u62df\u63d0\u4f9b\u5feb\u901f\u7684\u51b3\u7b56\u6307\u5bfc\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\uff08ML\uff09\u7684\u6d41\u7a0b\uff0c\u7528\u4e8e\u6839\u636e\u98de\u673a\u5728\u5176\u6574\u4e2a\u8fd0\u884c\u5bff\u547d\u4e2d\u4e0d\u540c\u4efb\u52a1\u7684\u98de\u884c\u53c2\u6570\uff0c\u6765\u4f30\u7b97\u4e0d\u540c\u673a\u7ffc\u4f4d\u7f6e\u7684\u75b2\u52b3\u5bff\u547d\u3002", "result": "\u5728\u5b9e\u9645\u7684\u75b2\u52b3\u5bff\u547d\u4f30\u7b97\u6848\u4f8b\u4e2d\u9a8c\u8bc1\u4e86\u8be5\u673a\u5668\u5b66\u4e60\u6d41\u7a0b\uff0c\u5f97\u5230\u4e86\u51c6\u786e\u7684\u9884\u6d4b\u7ed3\u679c\uff0c\u5e76\u8fdb\u884c\u4e86\u5168\u9762\u7684\u7edf\u8ba1\u9a8c\u8bc1\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002", "conclusion": "\u8be5\u6d41\u7a0b\u901a\u8fc7\u51cf\u5c11\u6602\u8d35\u7684\u6a21\u62df\u6570\u91cf\uff0c\u4ece\u800c\u964d\u4f4e\u4e86\u6240\u9700\u7684\u8ba1\u7b97\u548c\u4eba\u529b\u8d44\u6e90\uff0c\u662f\u5bf9\u4f20\u7edf\u65b9\u6cd5\u7684\u8865\u5145\u3002"}}
{"id": "2509.10082", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10082", "abs": "https://arxiv.org/abs/2509.10082", "authors": ["Weitao Tang", "Johann Vargas-Calixto", "Nasim Katebi", "Nhi Tran", "Sharmony B. Kelly", "Gari D. Clifford", "Robert Galinsky", "Faezeh Marzbanrad"], "title": "FetalSleepNet: A Transfer Learning Framework with Spectral Equalisation Domain Adaptation for Fetal Sleep Stage Classification", "comment": "13 pages, 4 tables, 5 figures, submitted to IEEE Journal of\n  Biomedical and Health Informatics", "summary": "Introduction: This study presents FetalSleepNet, the first published deep\nlearning approach to classifying sleep states from the ovine\nelectroencephalogram (EEG). Fetal EEG is complex to acquire and difficult and\nlaborious to interpret consistently. However, accurate sleep stage\nclassification may aid in the early detection of abnormal brain maturation\nassociated with pregnancy complications (e.g. hypoxia or intrauterine growth\nrestriction).\n  Methods: EEG electrodes were secured onto the ovine dura over the parietal\ncortices of 24 late gestation fetal sheep. A lightweight deep neural network\noriginally developed for adult EEG sleep staging was trained on the ovine EEG\nusing transfer learning from adult EEG. A spectral equalisation-based domain\nadaptation strategy was used to reduce cross-domain mismatch.\n  Results: We demonstrated that while direct transfer performed poorly, full\nfine tuning combined with spectral equalisation achieved the best overall\nperformance (accuracy: 86.6 percent, macro F1-score: 62.5), outperforming\nbaseline models.\n  Conclusions: To the best of our knowledge, FetalSleepNet is the first deep\nlearning framework specifically developed for automated sleep staging from the\nfetal EEG. Beyond the laboratory, the EEG-based sleep stage classifier\nfunctions as a label engine, enabling large scale weak/semi supervised labeling\nand distillation to facilitate training on less invasive signals that can be\nacquired in the clinic, such as Doppler Ultrasound or electrocardiogram data.\nFetalSleepNet's lightweight design makes it well suited for deployment in low\npower, real time, and wearable fetal monitoring systems.", "AI": {"tldr": "FetalSleepNet\u662f\u9996\u4e2a\u7528\u4e8e\u80ce\u513f\u8111\u7535\u56fe\uff08EEG\uff09\u7761\u7720\u5206\u671f\u7684\u4eba\u5de5\u667a\u80fd\u6846\u67b6\uff0c\u901a\u8fc7\u8fc1\u79fb\u5b66\u4e60\u548c\u57df\u9002\u5e94\u7b56\u7565\uff0c\u5b9e\u73b0\u4e8686.6%\u7684\u51c6\u786e\u7387\uff0c\u5e76\u80fd\u7528\u4e8e\u66f4\u5e7f\u6cdb\u7684\u4e34\u5e8a\u76d1\u6d4b\u3002 ", "motivation": "\u51c6\u786e\u7684\u7761\u7720\u5206\u671f\u6709\u52a9\u4e8e\u65e9\u671f\u53d1\u73b0\u4e0e\u598a\u5a20\u5e76\u53d1\u75c7\uff08\u5982\u7f3a\u6c27\u6216\u5bab\u5185\u751f\u957f\u53d7\u9650\uff09\u76f8\u5173\u7684\u5f02\u5e38\u5927\u8111\u6210\u719f\u3002", "method": "\u4f7f\u7528\u8fc1\u79fb\u5b66\u4e60\u5c06\u4e3a\u6210\u5e74\u4eba\u8bbe\u8ba1\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5e94\u7528\u4e8e\u7ef5\u7f8a\u80ce\u513f\u8111\u7535\u56fe\uff0c\u5e76\u7ed3\u5408\u57fa\u4e8e\u9891\u8c31\u5747\u8861\u7684\u57df\u9002\u5e94\u7b56\u7565\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u4e0e\u57fa\u7ebf\u6a21\u578b\u76f8\u6bd4\uff0c\u7ecf\u8fc7\u5fae\u8c03\u548c\u9891\u8c31\u5747\u8861\u7684FetalSleepNet\u5728\u51c6\u786e\u7387\uff0886.6%\uff09\u548c\u5b8fF1\u5206\u6570\uff0862.5\uff09\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "FetalSleepNet\u662f\u9996\u4e2a\u4e13\u95e8\u4e3a\u80ce\u513f\u8111\u7535\u56fe\u81ea\u52a8\u7761\u7720\u5206\u671f\u8bbe\u8ba1\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u5176\u8f7b\u91cf\u5316\u8bbe\u8ba1\u9002\u7528\u4e8e\u4f4e\u529f\u8017\u3001\u5b9e\u65f6\u548c\u53ef\u7a7f\u6234\u7684\u80ce\u513f\u76d1\u6d4b\u7cfb\u7edf\uff0c\u5e76\u53ef\u4f5c\u4e3a\u6807\u7b7e\u5f15\u64ce\u4ee5\u652f\u6301\u5728\u4e34\u5e8a\u4e0a\u66f4\u6613\u83b7\u53d6\u7684\u4fe1\u53f7\uff08\u5982\u591a\u666e\u52d2\u8d85\u58f0\u6216\u5fc3\u7535\u56fe\uff09\u7684\u8bad\u7ec3\u3002"}}
{"id": "2509.10106", "categories": ["cond-mat.mtrl-sci", "cond-mat.other", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2509.10106", "abs": "https://arxiv.org/abs/2509.10106", "authors": ["Cong Li", "Zhilong Yang", "Hongxiong Liu", "Magnus H. Berntsen", "Francesco Scali", "Dibya Phuyal", "Jianfeng Zhang", "Timur K. Kim", "Jacek Osiecki", "Balasubramanian Thiagarajan", "Youguo Shi", "Tao Xiang", "Quansheng Wu", "Oscar Tjernberg"], "title": "Resolving the Bulk-Boundary Correspondence Paradox on Low-Symmetry Surfaces of Weyl Semimetals", "comment": "Main text: 18 pages, 4 figures; SI: 29 pages, 16 figures. Comments\n  are welcome", "summary": "Low-symmetry surfaces of topological semimetals offer access to boundary\nphenomena hidden on conventional facets, yet systematic studies remain scarce\ndue to experimental challenges and the lack of a general framework for\nreconciling bulk and surface periodicities. Here, we investigate the (103)\nsurface of the Weyl semimetal NdAlSi using angle resolved photoemission\nspectroscopy and density functional theory. The (103) surface is an example of\na low symmetry surface that presents an apparent paradox to the bulk-boundary\ncorrespondence. The surface periodicity to which the topological surface states\nare expected to adhere does not correspond to the bulk periodicity of the Weyl\npoints. By showing that successive bulk Brillouin zones generate replicas that\naccumulate into a superlattice commensurate with the surface Brillouin zone, we\ndemonstrate how the apparent bulk boundary correspondence paradox is resolved\nand establish a universal criterion for arbitrary facets. The framework and\nexperimental results further suggests that overlapping Fermi arcs can hybridize\ninto closed Fermi arc loops, enriching boundary topology and enabling\nunconventional transport, interference, and collective phenomena unique to\nlowsymmetry facets.", "AI": {"tldr": "\u4f4e\u5bf9\u79f0\u6027\u62d3\u6251\u534a\u91d1\u5c5e\u8868\u9762\u5b58\u5728\u4f20\u7edf\u9762\u6240\u9690\u85cf\u7684\u8fb9\u754c\u73b0\u8c61\uff0c\u4f46\u7531\u4e8e\u5b9e\u9a8c\u6311\u6218\u548c\u7f3a\u4e4f\u8c03\u548c\u4f53\u548c\u8868\u9762\u5468\u671f\u6027\u7684\u901a\u7528\u6846\u67b6\uff0c\u7cfb\u7edf\u6027\u7814\u7a76\u4ecd\u7136\u7a00\u5c11\u3002\u672c\u7814\u7a76\u4f7f\u7528\u89d2\u5206\u8fa8\u5149\u7535\u5b50\u80fd\u8c31\u548c\u5bc6\u5ea6\u6cdb\u51fd\u7406\u8bba\u7814\u7a76\u4e86\u5916\u5c14\u534a\u91d1\u5c5e NdAlSi \u7684 (103) \u8868\u9762\u3002\u8fd9\u662f\u4e00\u4e2a\u4f4e\u5bf9\u79f0\u6027\u8868\u9762\uff0c\u8868\u9762\u5468\u671f\u6027\u4e0e\u5916\u5c14\u70b9\u4f53\u5468\u671f\u6027\u4e0d\u7b26\uff0c\u4f3c\u4e4e\u8fdd\u80cc\u4e86\u4f53-\u8fb9\u754c\u5bf9\u5e94\u539f\u7406\u3002\u901a\u8fc7\u5c55\u793a\u8fde\u7eed\u7684\u4f53\u5e03\u91cc\u6e0a\u533a\u4ea7\u751f\u91cd\u53e0\uff0c\u6700\u7ec8\u4e0e\u8868\u9762\u5e03\u91cc\u6e0a\u533a\u6210\u6bd4\u4f8b\uff0c\u4ece\u800c\u89e3\u51b3\u4e86\u4f53-\u8fb9\u754c\u5bf9\u5e94\u539f\u7406\u7684\u6096\u8bba\uff0c\u5e76\u4e3a\u4efb\u610f\u9762\u5efa\u7acb\u4e86\u901a\u7528\u5224\u636e\u3002\u8be5\u6846\u67b6\u548c\u5b9e\u9a8c\u7ed3\u679c\u8fd8\u8868\u660e\uff0c\u91cd\u53e0\u7684\u8d39\u7c73\u5f27\u53ef\u4ee5\u6742\u5316\u6210\u95ed\u5408\u7684\u8d39\u7c73\u5f27\u73af\uff0c\u4e30\u5bcc\u4e86\u8fb9\u754c\u62d3\u6251\uff0c\u5e76\u5b9e\u73b0\u4e86\u4f4e\u5bf9\u79f0\u6027\u9762\u6240\u7279\u6709\u7684\u975e\u5e38\u89c4\u8f93\u8fd0\u3001\u5e72\u6d89\u548c\u96c6\u4f53\u73b0\u8c61\u3002", "motivation": "\u4f4e\u5bf9\u79f0\u6027\u8868\u9762\u5177\u6709\u9690\u85cf\u7684\u8fb9\u754c\u73b0\u8c61\uff0c\u4f46\u7f3a\u4e4f\u901a\u7528\u6846\u67b6\u6765\u7814\u7a76\u5b83\u4eec\uff0c\u7279\u522b\u662f\u5728\u89e3\u51b3\u4f53-\u8868\u9762\u5468\u671f\u6027\u5dee\u5f02\u65b9\u9762\u3002", "method": "\u4f7f\u7528\u89d2\u5206\u8fa8\u5149\u7535\u5b50\u80fd\u8c31\u548c\u5bc6\u5ea6\u6cdb\u51fd\u7406\u8bba\u7814\u7a76 NdAlSi \u7684 (103) \u8868\u9762\u3002", "result": "\u89e3\u51b3\u4e86\u4f4e\u5bf9\u79f0\u6027\u8868\u9762\uff08\u5982 (103) \u8868\u9762\uff09\u7684\u4f53-\u8fb9\u754c\u5bf9\u5e94\u6096\u8bba\uff0c\u5efa\u7acb\u4e86\u901a\u7528\u5224\u636e\uff0c\u5e76\u53d1\u73b0\u8d39\u7c73\u5f27\u53ef\u4ee5\u6742\u5316\u6210\u95ed\u5408\u7684\u8d39\u7c73\u5f27\u73af\uff0c\u53ef\u80fd\u5e26\u6765\u65b0\u7684\u7269\u7406\u73b0\u8c61\u3002", "conclusion": "\u4f4e\u5bf9\u79f0\u6027\u8868\u9762\u4e3a\u7814\u7a76\u65b0\u5947\u7684\u8fb9\u754c\u73b0\u8c61\u63d0\u4f9b\u4e86\u5e73\u53f0\uff0c\u901a\u8fc7\u5efa\u7acb\u7684\u6846\u67b6\u53ef\u4ee5\u7406\u89e3\u548c\u5229\u7528\u8fd9\u4e9b\u73b0\u8c61\uff0c\u5e76\u53ef\u80fd\u5e26\u6765\u65b0\u7684\u7269\u6001\u548c\u5e94\u7528\u3002"}}
{"id": "2509.09705", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09705", "abs": "https://arxiv.org/abs/2509.09705", "authors": ["Claudio Pinhanez", "Paulo Cavalin", "Cassia Sanctos", "Marcelo Grave", "Yago Primerano"], "title": "The Non-Determinism of Small LLMs: Evidence of Low Answer Consistency in Repetition Trials of Standard Multiple-Choice Benchmarks", "comment": null, "summary": "This work explores the consistency of small LLMs (2B-8B parameters) in\nanswering multiple times the same question. We present a study on known,\nopen-source LLMs responding to 10 repetitions of questions from the\nmultiple-choice benchmarks MMLU-Redux and MedQA, considering different\ninference temperatures, small vs. medium models (50B-80B), finetuned vs. base\nmodels, and other parameters. We also look into the effects of requiring\nmulti-trial answer consistency on accuracy and the trade-offs involved in\ndeciding which model best provides both of them. To support those studies, we\npropose some new analytical and graphical tools. Results show that the number\nof questions which can be answered consistently vary considerably among models\nbut are typically in the 50%-80% range for small models at low inference\ntemperatures. Also, accuracy among consistent answers seems to reasonably\ncorrelate with overall accuracy. Results for medium-sized models seem to\nindicate much higher levels of answer consistency.", "AI": {"tldr": "\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728\u56de\u7b54\u76f8\u540c\u95ee\u9898\u65f6\u7684\u4e00\u81f4\u6027\u53c2\u5dee\u4e0d\u9f50\uff0c\u4f46\u901a\u5e38\u572850%-80%\u7684\u8303\u56f4\u5185\uff0c\u5e76\u4e14\u4e00\u81f4\u6027\u7b54\u6848\u7684\u51c6\u786e\u6027\u4e0e\u6574\u4f53\u51c6\u786e\u6027\u76f8\u5173\u3002", "motivation": "\u7814\u7a76\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff082B-8B\u53c2\u6570\uff09\u5728\u591a\u6b21\u56de\u7b54\u76f8\u540c\u95ee\u9898\u65f6\u7684\u4e00\u81f4\u6027\u3002", "method": "\u4f7f\u7528MMLU-Redux\u548cMedQA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u95ee\u9898\uff0c\u5bf9\u4e0d\u540c\u63a8\u7406\u6e29\u5ea6\u3001\u6a21\u578b\u5927\u5c0f\uff08\u5305\u62ec\u5c0f\u578b\u548c\u4e2d\u578b\uff09\u3001\u5fae\u8c03\u548c\u57fa\u7840\u6a21\u578b\u8fdb\u884c10\u6b21\u91cd\u590d\u95ee\u7b54\u5b9e\u9a8c\uff0c\u5e76\u5206\u6790\u4e86\u591a\u8f6e\u7b54\u6848\u4e00\u81f4\u6027\u5bf9\u51c6\u786e\u6027\u7684\u5f71\u54cd\u4ee5\u53ca\u76f8\u5173\u7684\u6743\u8861\u3002", "result": "\u5c0f\u578b\u6a21\u578b\u5728\u4f4e\u63a8\u7406\u6e29\u5ea6\u4e0b\u7684\u7b54\u6848\u4e00\u81f4\u6027\u901a\u5e38\u572850%-80%\u8303\u56f4\u5185\uff0c\u800c\u4e2d\u578b\u6a21\u578b\u7684\u4e00\u81f4\u6027\u6c34\u5e73\u8981\u9ad8\u5f97\u591a\u3002\u4e00\u81f4\u6027\u7b54\u6848\u7684\u51c6\u786e\u6027\u4e0e\u6574\u4f53\u51c6\u786e\u6027\u6709\u5408\u7406\u7684\u76f8\u5173\u6027\u3002", "conclusion": "\u7b54\u6848\u7684\u4e00\u81f4\u6027\u56e0\u6a21\u578b\u800c\u5f02\uff0c\u4f46\u5c0f\u578b\u6a21\u578b\u5728\u4f4e\u63a8\u7406\u6e29\u5ea6\u4e0b\u8868\u73b0\u51fa\u4e00\u5b9a\u7a0b\u5ea6\u7684\u4e00\u81f4\u6027\u3002"}}
{"id": "2509.09793", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.09793", "abs": "https://arxiv.org/abs/2509.09793", "authors": ["Vincent Herfeld", "Baudouin Denis de Senneville", "Arthur Leclaire", "Nicolas Papadakis"], "title": "From the Gradient-Step Denoiser to the Proximal Denoiser and their associated convergent Plug-and-Play algorithms", "comment": null, "summary": "In this paper we analyze the Gradient-Step Denoiser and its usage in\nPlug-and-Play algorithms. The Plug-and-Play paradigm of optimization algorithms\nuses off the shelf denoisers to replace a proximity operator or a gradient\ndescent operator of an image prior. Usually this image prior is implicit and\ncannot be expressed, but the Gradient-Step Denoiser is trained to be exactly\nthe gradient descent operator or the proximity operator of an explicit\nfunctional while preserving state-of-the-art denoising capabilities.", "AI": {"tldr": "Gradient-Step Denoiser \u53ef\u7528\u4f5c\u5373\u63d2\u5373\u7528\u7b97\u6cd5\u4e2d\u7684\u68af\u5ea6\u4e0b\u964d\u6216\u90bb\u8fd1\u7b97\u5b50\uff0c\u540c\u65f6\u4fdd\u6301\u6700\u5148\u8fdb\u7684\u53bb\u566a\u80fd\u529b\u3002", "motivation": "\u5206\u6790 Gradient-Step Denoiser \u53ca\u5176\u5728\u5373\u63d2\u5373\u7528\u7b97\u6cd5\u4e2d\u7684\u7528\u6cd5\u3002", "method": "Gradient-Step Denoiser \u88ab\u8bad\u7ec3\u4e3a\u663e\u5f0f\u51fd\u6570\u7684\u68af\u5ea6\u4e0b\u964d\u7b97\u5b50\u6216\u90bb\u8fd1\u7b97\u5b50\uff0c\u540c\u65f6\u4fdd\u6301\u5176\u53bb\u566a\u80fd\u529b\u3002", "result": "Gradient-Step Denoiser \u5177\u6709\u5373\u63d2\u5373\u7528\u8303\u4f8b\u6240\u9700\u7684\u7279\u6027\u3002", "conclusion": "Gradient-Step Denoiser \u662f\u5373\u63d2\u5373\u7528\u7b97\u6cd5\u7684\u4e00\u4e2a\u6709\u524d\u9014\u7684\u7ec4\u6210\u90e8\u5206\u3002"}}
{"id": "2509.09867", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.09867", "abs": "https://arxiv.org/abs/2509.09867", "authors": ["Yago Romano Matinez", "Jesse Roberts"], "title": "LLMs as Agentic Cooperative Players in Multiplayer UNO", "comment": null, "summary": "LLMs promise to assist humans -- not just by answering questions, but by\noffering useful guidance across a wide range of tasks. But how far does that\nassistance go? Can a large language model based agent actually help someone\naccomplish their goal as an active participant? We test this question by\nengaging an LLM in UNO, a turn-based card game, asking it not to win but\ninstead help another player to do so. We built a tool that allows decoder-only\nLLMs to participate as agents within the RLCard game environment. These models\nreceive full game-state information and respond using simple text prompts under\ntwo distinct prompting strategies. We evaluate models ranging from small (1B\nparameters) to large (70B parameters) and explore how model scale impacts\nperformance. We find that while all models were able to successfully outperform\na random baseline when playing UNO, few were able to significantly aid another\nplayer.", "AI": {"tldr": "LLM\u5728UNO\u6e38\u620f\u4e2d\u4f5c\u4e3a\u8f85\u52a9\u8005\uff0c\u800c\u975e\u83b7\u80dc\u8005\uff0c\u5176\u8868\u73b0\u4e0e\u6a21\u578b\u89c4\u6a21\u76f8\u5173\uff0c\u4f46\u666e\u904d\u96be\u4ee5\u6709\u6548\u5e2e\u52a9\u4eba\u7c7b\u73a9\u5bb6\u3002", "motivation": "\u8bc4\u4f30LLM\u4f5c\u4e3a\u4ee3\u7406\u5728UNO\u6e38\u620f\u4e2d\u8f85\u52a9\u4eba\u7c7b\u73a9\u5bb6\u5b8c\u6210\u76ee\u6807\u7684\u6f5c\u529b\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5141\u8bb8LLM\u5728RLCard\u73af\u5883\u4e2d\u4f5c\u4e3a\u4ee3\u7406\u7684\u5de5\u5177\uff0c\u5e76\u91c7\u7528\u4e24\u79cd\u63d0\u793a\u7b56\u7565\uff0c\u6d4b\u8bd5\u4e86\u4e0d\u540c\u89c4\u6a21\uff081B\u523070B\u53c2\u6570\uff09\u7684\u6a21\u578b\u3002", "result": "\u6240\u6709\u6a21\u578b\u5747\u4f18\u4e8e\u968f\u673a\u57fa\u7ebf\uff0c\u4f46\u53ea\u6709\u5c11\u6570\u6a21\u578b\u80fd\u6709\u6548\u5e2e\u52a9\u4eba\u7c7b\u73a9\u5bb6\u3002", "conclusion": "LLM\u5728UNO\u6e38\u620f\u4e2d\u53ef\u4ee5\u4f5c\u4e3a\u8f85\u52a9\u8005\uff0c\u4f46\u5176\u6709\u6548\u6027\u53d7\u5230\u6a21\u578b\u89c4\u6a21\u7684\u5f71\u54cd\uff0c\u5e76\u4e14\u666e\u904d\u96be\u4ee5\u663e\u8457\u5e2e\u52a9\u4eba\u7c7b\u73a9\u5bb6\u8fbe\u6210\u76ee\u6807\u3002"}}
{"id": "2509.10029", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.10029", "abs": "https://arxiv.org/abs/2509.10029", "authors": ["Dennis Laurijssen", "Wouter Jansen", "Arne Aerts", "Walter Daems", "Jan Steckel"], "title": "Ruggedized Ultrasound Sensing in Harsh Conditions: eRTIS in the wild", "comment": null, "summary": "We present eRTIS, a rugged, embedded ultrasound sensing system for use in\nharsh industrial environments. The system features a broadband capacitive\ntransducer and a 32-element MEMS microphone array capable of 2D and 3D\nbeamforming. A modular hardware architecture separates sensing and processing\ntasks: a high-performance microcontroller handles excitation signal generation\nand data acquisition, while an NVIDIA Jetson module performs GPU-accelerated\nsignal processing. eRTIS supports external synchronization via a custom\ncontroller that powers and coordinates up to six devices, either simultaneously\nor in a defined sequence. Additional synchronization options include\nbidirectional triggering and in-band signal injection. A sealed, anodized\naluminum enclosure with passive cooling and IP-rated connectors ensures\nreliability in challenging conditions. Performance is demonstrated in three\nfield scenarios: harbor mooring, off-road robotics, and autonomous navigation\nin cluttered environments, demonstrates that eRTIS provides robust sensing in\nsituations where optical systems degrade.", "AI": {"tldr": "eRTIS\u662f\u4e00\u4e2a\u7528\u4e8e\u6076\u52a3\u5de5\u4e1a\u73af\u5883\u7684\u5d4c\u5165\u5f0f\u8d85\u58f0\u6ce2\u4f20\u611f\u7cfb\u7edf\uff0c\u91c7\u7528\u5bbd\u5e26\u7535\u5bb9\u6362\u80fd\u5668\u548c32\u5143MEMS\u9ea6\u514b\u98ce\u9635\u5217\uff0c\u652f\u63012D/3D\u6ce2\u675f\u6210\u5f62\u3002\u5176\u6a21\u5757\u5316\u8bbe\u8ba1\u5c06\u4f20\u611f\u548c\u5904\u7406\u5206\u79bb\uff0c\u5e76\u63d0\u4f9b\u591a\u79cd\u540c\u6b65\u9009\u9879\u3002\u8be5\u7cfb\u7edf\u5177\u6709\u575a\u56fa\u8010\u7528\u7684\u5916\u58f3\u548c\u88ab\u52a8\u51b7\u5374\uff0c\u53ef\u5728\u4e25\u82db\u6761\u4ef6\u4e0b\u53ef\u9760\u8fd0\u884c\u3002\u5728\u6e2f\u53e3\u7cfb\u6cca\u3001\u8d8a\u91ce\u673a\u5668\u4eba\u548c\u590d\u6742\u73af\u5883\u81ea\u4e3b\u5bfc\u822a\u7b49\u573a\u666f\u4e2d\u7684\u5e94\u7528\u8bc1\u660e\uff0ceRTIS\u5728\u5149\u5b66\u7cfb\u7edf\u6027\u80fd\u4e0b\u964d\u7684\u60c5\u51b5\u4e0b\u4ecd\u80fd\u63d0\u4f9b\u53ef\u9760\u7684\u4f20\u611f\u80fd\u529b\u3002", "motivation": "\u63d0\u51fa\u4e00\u79cd\u9002\u7528\u4e8e\u6076\u52a3\u5de5\u4e1a\u73af\u5883\u7684\u9c81\u68d2\u3001\u5d4c\u5165\u5f0f\u8d85\u58f0\u6ce2\u4f20\u611f\u7cfb\u7edf\u3002", "method": "eRTIS\u7cfb\u7edf\u91c7\u7528\u5bbd\u5e26\u7535\u5bb9\u6362\u80fd\u5668\u548c32\u5143MEMS\u9ea6\u514b\u98ce\u9635\u5217\uff0c\u5b9e\u73b02D\u548c3D\u6ce2\u675f\u6210\u5f62\u3002\u5176\u6a21\u5757\u5316\u786c\u4ef6\u67b6\u6784\u5206\u79bb\u4e86\u4f20\u611f\u548c\u5904\u7406\u4efb\u52a1\uff0c\u7531\u5fae\u63a7\u5236\u5668\u5904\u7406\u4fe1\u53f7\u751f\u6210\u548c\u6570\u636e\u91c7\u96c6\uff0cNVIDIA Jetson\u6a21\u5757\u8fdb\u884cGPU\u52a0\u901f\u4fe1\u53f7\u5904\u7406\u3002\u7cfb\u7edf\u652f\u6301\u901a\u8fc7\u81ea\u5b9a\u4e49\u63a7\u5236\u5668\u8fdb\u884c\u5916\u90e8\u540c\u6b65\uff0c\u53ef\u540c\u65f6\u6216\u6309\u987a\u5e8f\u534f\u8c03\u591a\u8fbe\u516d\u4e2a\u8bbe\u5907\uff0c\u5e76\u63d0\u4f9b\u53cc\u5411\u89e6\u53d1\u548c\u5e26\u5185\u4fe1\u53f7\u6ce8\u5165\u7b49\u540c\u6b65\u9009\u9879\u3002\u5916\u58f3\u91c7\u7528\u5bc6\u5c01\u9633\u6781\u94dd\uff0c\u88ab\u52a8\u51b7\u5374\u548cIP\u7ea7\u8fde\u63a5\u5668\u8bbe\u8ba1\u3002", "result": "\u8be5\u7cfb\u7edf\u5728\u6e2f\u53e3\u7cfb\u6cca\u3001\u8d8a\u91ce\u673a\u5668\u4eba\u548c\u590d\u6742\u73af\u5883\u81ea\u4e3b\u5bfc\u822a\u4e09\u4e2a\u5b9e\u9645\u573a\u666f\u4e2d\u8fdb\u884c\u4e86\u6027\u80fd\u9a8c\u8bc1\uff0c\u8bc1\u660e\u4e86eRTIS\u5728\u5149\u5b66\u7cfb\u7edf\u6027\u80fd\u4e0b\u964d\u7684\u60c5\u51b5\u4e0b\uff0c\u4f9d\u7136\u80fd\u591f\u63d0\u4f9b\u9c81\u68d2\u7684\u4f20\u611f\u80fd\u529b\u3002", "conclusion": "eRTIS\u7cfb\u7edf\u4e3a\u6076\u52a3\u5de5\u4e1a\u73af\u5883\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u9760\u7684\u8d85\u58f0\u6ce2\u4f20\u611f\u89e3\u51b3\u65b9\u6848\uff0c\u5176\u575a\u56fa\u7684\u8bbe\u8ba1\u548c\u5148\u8fdb\u7684\u4fe1\u53f7\u5904\u7406\u80fd\u529b\u4f7f\u5176\u5728\u4f20\u7edf\u5149\u5b66\u4f20\u611f\u53d7\u9650\u7684\u573a\u666f\u4e2d\u5177\u6709\u4f18\u52bf\u3002"}}
{"id": "2509.09742", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.09742", "abs": "https://arxiv.org/abs/2509.09742", "authors": ["Md Fazle Rasul", "Alanood Alqobaisi", "Bruhadeshwar Bezawada", "Indrakshi Ray"], "title": "Images in Motion?: A First Look into Video Leakage in Collaborative Deep Learning", "comment": null, "summary": "Federated learning (FL) allows multiple entities to train a shared model\ncollaboratively. Its core, privacy-preserving principle is that participants\nonly exchange model updates, such as gradients, and never their raw, sensitive\ndata. This approach is fundamental for applications in domains where privacy\nand confidentiality are important. However, the security of this very mechanism\nis threatened by gradient inversion attacks, which can reverse-engineer private\ntraining data directly from the shared gradients, defeating the purpose of FL.\nWhile the impact of these attacks is known for image, text, and tabular data,\ntheir effect on video data remains an unexamined area of research. This paper\npresents the first analysis of video data leakage in FL using gradient\ninversion attacks. We evaluate two common video classification approaches: one\nemploying pre-trained feature extractors and another that processes raw video\nframes with simple transformations. Our initial results indicate that the use\nof feature extractors offers greater resilience against gradient inversion\nattacks. We also demonstrate that image super-resolution techniques can enhance\nthe frames extracted through gradient inversion attacks, enabling attackers to\nreconstruct higher-quality videos. Our experiments validate this across\nscenarios where the attacker has access to zero, one, or more reference frames\nfrom the target environment. We find that although feature extractors make\nattacks more challenging, leakage is still possible if the classifier lacks\nsufficient complexity. We, therefore, conclude that video data leakage in FL is\na viable threat, and the conditions under which it occurs warrant further\ninvestigation.", "AI": {"tldr": "\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u5141\u8bb8\u591a\u4e2a\u53c2\u4e0e\u65b9\u534f\u4f5c\u8bad\u7ec3\u5171\u4eab\u6a21\u578b\uff0c\u4f46\u68af\u5ea6\u53cd\u6f14\u653b\u51fb\u53ef\u80fd\u4ece\u5171\u4eab\u68af\u5ea6\u4e2d\u6062\u590d\u79c1\u6709\u8bad\u7ec3\u6570\u636e\uff0c\u5a01\u80c1FL\u7684\u9690\u79c1\u4fdd\u62a4\u3002\u672c\u6587\u9996\u6b21\u5206\u6790\u4e86FL\u4e2d\u89c6\u9891\u6570\u636e\u7684\u68af\u5ea6\u53cd\u6f14\u653b\u51fb\u6cc4\u9732\u95ee\u9898\uff0c\u5e76\u8bc4\u4f30\u4e86\u4e24\u79cd\u89c6\u9891\u5206\u7c7b\u65b9\u6cd5\u3002\u7ed3\u679c\u8868\u660e\uff0c\u4f7f\u7528\u7279\u5f81\u63d0\u53d6\u5668\u6bd4\u5904\u7406\u539f\u59cb\u89c6\u9891\u5e27\u66f4\u80fd\u62b5\u6297\u653b\u51fb\uff0c\u4f46\u5982\u679c\u5206\u7c7b\u5668\u590d\u6742\u5ea6\u4e0d\u8db3\uff0c\u4ecd\u53ef\u80fd\u53d1\u751f\u6570\u636e\u6cc4\u9732\u3002\u6b64\u5916\uff0c\u56fe\u50cf\u8d85\u5206\u8fa8\u7387\u6280\u672f\u53ef\u4ee5\u63d0\u9ad8\u653b\u51fb\u8005\u91cd\u5efa\u89c6\u9891\u7684\u8d28\u91cf\u3002\u7814\u7a76\u8bc1\u5b9e\uff0cFL\u4e2d\u7684\u89c6\u9891\u6570\u636e\u6cc4\u9732\u662f\u4e00\u4e2a\u5b9e\u9645\u5a01\u80c1\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u7684\u9690\u79c1\u4fdd\u62a4\u673a\u5236\uff08\u4ec5\u4ea4\u6362\u6a21\u578b\u66f4\u65b0\u800c\u975e\u539f\u59cb\u6570\u636e\uff09\u53d7\u5230\u68af\u5ea6\u53cd\u6f14\u653b\u51fb\u7684\u5a01\u80c1\uff0c\u8be5\u653b\u51fb\u53ef\u4ee5\u4ece\u5171\u4eab\u68af\u5ea6\u4e2d\u9006\u5411\u5de5\u7a0b\u51fa\u79c1\u6709\u8bad\u7ec3\u6570\u636e\u3002\u7136\u800c\uff0c\u5bf9\u4e8e\u89c6\u9891\u6570\u636e\uff0c\u6b64\u7c7b\u653b\u51fb\u7684\u5f71\u54cd\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\uff0c\u56e0\u6b64\u6709\u5fc5\u8981\u8fdb\u884c\u5206\u6790\u3002", "method": "\u672c\u6587\u8bc4\u4f30\u4e86\u4e24\u79cd\u5e38\u89c1\u7684\u89c6\u9891\u5206\u7c7b\u65b9\u6cd5\uff08\u4f7f\u7528\u9884\u8bad\u7ec3\u7279\u5f81\u63d0\u53d6\u5668\u548c\u5904\u7406\u539f\u59cb\u89c6\u9891\u5e27\uff09\u5728FL\u4e2d\u7684\u68af\u5ea6\u53cd\u6f14\u653b\u51fb\u6cc4\u9732\u60c5\u51b5\u3002\u7814\u7a76\u8fd8\u8bc4\u4f30\u4e86\u56fe\u50cf\u8d85\u5206\u8fa8\u7387\u6280\u672f\u5728\u4e0d\u540c\u53c2\u8003\u5e27\u53ef\u7528\u6027\u573a\u666f\u4e0b\u5bf9\u653b\u51fb\u6548\u679c\u7684\u589e\u5f3a\u4f5c\u7528\u3002", "result": "\u4f7f\u7528\u7279\u5f81\u63d0\u53d6\u5668\u7684\u65b9\u6cd5\u6bd4\u5904\u7406\u539f\u59cb\u89c6\u9891\u5e27\u7684\u65b9\u6cd5\u66f4\u80fd\u62b5\u6297\u68af\u5ea6\u53cd\u6f14\u653b\u51fb\u3002\u56fe\u50cf\u8d85\u5206\u8fa8\u7387\u6280\u672f\u53ef\u4ee5\u63d0\u9ad8\u653b\u51fb\u8005\u901a\u8fc7\u68af\u5ea6\u53cd\u6f14\u653b\u51fb\u91cd\u5efa\u7684\u89c6\u9891\u5e27\u8d28\u91cf\u3002\u5373\u4f7f\u4f7f\u7528\u7279\u5f81\u63d0\u53d6\u5668\uff0c\u5982\u679c\u5206\u7c7b\u5668\u590d\u6742\u5ea6\u4e0d\u8db3\uff0c\u4ecd\u7136\u53ef\u80fd\u53d1\u751f\u6570\u636e\u6cc4\u9732\u3002", "conclusion": "\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u89c6\u9891\u6570\u636e\u6cc4\u9732\u662f\u4e00\u4e2a\u5b9e\u9645\u5b58\u5728\u7684\u5a01\u80c1\u3002\u5c3d\u7ba1\u7279\u5f81\u63d0\u53d6\u5668\u53ef\u4ee5\u589e\u52a0\u653b\u51fb\u7684\u96be\u5ea6\uff0c\u4f46\u5728\u67d0\u4e9b\u6761\u4ef6\u4e0b\uff08\u5982\u5206\u7c7b\u5668\u590d\u6742\u5ea6\u4f4e\uff09\u4ecd\u7136\u53ef\u80fd\u53d1\u751f\u6570\u636e\u6cc4\u9732\u3002\u56e0\u6b64\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u89c6\u9891\u6570\u636e\u6cc4\u9732\u53d1\u751f\u7684\u6761\u4ef6\u3002"}}
{"id": "2509.10237", "categories": ["cond-mat.mes-hall", "physics.app-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2509.10237", "abs": "https://arxiv.org/abs/2509.10237", "authors": ["Amirali Arabmoheghi", "Alessio Zicoschi", "Guillermo Arregui", "Mohammad J. Bereyhi", "Yi Xia", "Nils J. Engelsen", "Tobias J. Kippenberg"], "title": "Noncontact friction in ultracoherent nanomechanical resonators near dielectric materials", "comment": null, "summary": "Micro- and nanomechanical resonators are emerging as promising platforms for\nquantum technologies, precision sensors and fundamental science experiments. To\nutilize these devices for force sensing or quantum optomechanics, they must be\nbrought in close proximity with other systems for functionalization or\nefficient readout. Improved understanding of the loss mechanisms in\nnanomechanical resonators, specifically the advent of dissipation dilution, has\nled to the development of resonators with unprecedented coherence properties.\nThe mechanical quality factors of this new class of ultracoherent micro- and\nnanomechanical oscillators can now exceed 1 billion at room temperature,\nsetting their force sensitivities below 1 $\\mathrm{aN}/\\sqrt{\\mathrm{Hz}}$,\nsurpassing those of the state-of-the-art atomic force microscopes (AFMs). Given\nthis new regime of sensitivity, an intriguing question is whether the proximity\nof other materials hinders mechanical coherence. Here we show: it does. We\nreport a novel dissipation mechanism that occurs in ultracoherent\nnanomechanical oscillators caused by the presence of nearby dielectrics. By\nstudying the parameter scaling of the effect, we show that the mechanism is\nmore severe for low-frequency mechanical modes and that it is due to dielectric\nloss within the materials caused by the motion of a resonator which carries\nstatic charges. Our observations are consistent with the noncontact friction\n(NCF) observed in AFMs. Our findings provide insights into limitations on the\nintegration of ultracoherent nanomechanical resonators and highlight the\nadverse effects of charged defects in these systems.", "AI": {"tldr": "\u9644\u8fd1\u7684\u7535\u4ecb\u8d28\u4f1a\u5f15\u8d77\u8d85\u76f8\u5e72\u7eb3\u7c73\u673a\u68b0\u632f\u8361\u5668\u7684\u8017\u6563\uff0c\u8fd9\u662f\u7531\u632f\u8361\u5668\u643a\u5e26\u7684\u9759\u7535\u8377\u5728\u4ecb\u7535\u6750\u6599\u4e2d\u79fb\u52a8\u5f15\u8d77\u7684\u3002", "motivation": "\u5229\u7528\u5fae\u7eb3\u673a\u68b0\u632f\u8361\u5668\u8fdb\u884c\u7cbe\u5bc6\u4f20\u611f\u548c\u91cf\u5b50\u6280\u672f\uff0c\u9700\u8981\u4e86\u89e3\u5176\u76f8\u5e72\u6027\u9650\u5236\uff0c\u7279\u522b\u662f\u5f53\u5b83\u4eec\u9760\u8fd1\u5176\u4ed6\u6750\u6599\u65f6\u3002", "method": "\u7814\u7a76\u4e86\u8d85\u76f8\u5e72\u7eb3\u7c73\u673a\u68b0\u632f\u8361\u5668\u5728\u5b58\u5728\u9644\u8fd1\u7535\u4ecb\u8d28\u65f6\u7684\u8017\u6563\uff0c\u5e76\u5206\u6790\u4e86\u53c2\u6570\u4f9d\u8d56\u6027\u3002", "result": "\u53d1\u73b0\u4e86\u7531\u9644\u8fd1\u7535\u4ecb\u8d28\u5f15\u8d77\u7684\u65b0\u7684\u8017\u6563\u673a\u5236\uff0c\u8fd9\u79cd\u673a\u5236\u5bf9\u4e8e\u4f4e\u9891\u6a21\u5f0f\u66f4\u4e3a\u4e25\u91cd\uff0c\u5e76\u4e14\u4e0e\u539f\u5b50\u529b\u663e\u5fae\u955c\u4e2d\u7684\u975e\u63a5\u89e6\u6469\u64e6\uff08NCF\uff09\u4e00\u81f4\u3002", "conclusion": "\u9644\u8fd1\u7535\u4ecb\u8d28\u7684\u5b58\u5728\u4f1a\u963b\u788d\u8d85\u76f8\u5e72\u7eb3\u7c73\u673a\u68b0\u632f\u8361\u5668\u7684\u6027\u80fd\uff0c\u8fd9\u5bf9\u4e8e\u5c06\u8fd9\u4e9b\u632f\u8361\u5668\u96c6\u6210\u5230\u91cf\u5b50\u6280\u672f\u7b49\u5e94\u7528\u4e2d\u662f\u4e00\u4e2a\u91cd\u8981\u7684\u9650\u5236\u56e0\u7d20\u3002"}}
{"id": "2509.10012", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.10012", "abs": "https://arxiv.org/abs/2509.10012", "authors": ["Richard Matthias Hartisch", "Alexander Rother", "J\u00f6rg Kr\u00fcger", "Kevin Haninger"], "title": "Towards simulation-based optimization of compliant fingers for high-speed connector assembly", "comment": null, "summary": "Mechanical compliance is a key design parameter for dynamic contact-rich\nmanipulation, affecting task success and safety robustness over contact\ngeometry variation. Design of soft robotic structures, such as compliant\nfingers, requires choosing design parameters which affect geometry and\nstiffness, and therefore manipulation performance and robustness. Today, these\nparameters are chosen through either hardware iteration, which takes\nsignificant development time, or simplified models (e.g. planar), which can't\naddress complex manipulation task objectives. Improvements in dynamic\nsimulation, especially with contact and friction modeling, present a potential\ndesign tool for mechanical compliance. We propose a simulation-based design\ntool for compliant mechanisms which allows design with respect to task-level\nobjectives, such as success rate. This is applied to optimize design parameters\nof a structured compliant finger to reduce failure cases inside a tolerance\nwindow in insertion tasks. The improvement in robustness is then validated on a\nreal robot using tasks from the benchmark NIST task board. The finger stiffness\naffects the tolerance window: optimized parameters can increase tolerable\nranges by a factor of 2.29, with workpiece variation up to 8.6 mm being\ncompensated. However, the trends remain task-specific. In some tasks, the\nhighest stiffness yields the widest tolerable range, whereas in others the\nopposite is observed, motivating need for design tools which can consider\napplication-specific geometry and dynamics.", "AI": {"tldr": "\u901a\u8fc7\u57fa\u4e8e\u4eff\u771f\u7684\u8bbe\u8ba1\u5de5\u5177\u4f18\u5316\u8f6f\u4f53\u673a\u68b0\u624b\u7684\u53c2\u6570\uff0c\u4ee5\u63d0\u9ad8\u5728\u63a5\u89e6\u5f0f\u64cd\u4f5c\u4e2d\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u76ee\u524d\u7684\u8f6f\u4f53\u673a\u68b0\u624b\u8bbe\u8ba1\u4f9d\u8d56\u786c\u4ef6\u8fed\u4ee3\u6216\u7b80\u5316\u6a21\u578b\uff0c\u96be\u4ee5\u6ee1\u8db3\u590d\u6742\u64cd\u4f5c\u4efb\u52a1\u7684\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u52a8\u6001\u4eff\u771f\u7684\u8bbe\u8ba1\u5de5\u5177\uff0c\u7528\u4e8e\u4f18\u5316\u8f6f\u4f53\u673a\u68b0\u624b\u7684\u51e0\u4f55\u548c\u521a\u5ea6\u53c2\u6570\uff0c\u4ee5\u5b9e\u73b0\u4efb\u52a1\u7ea7\u76ee\u6807\uff08\u5982\u6210\u529f\u7387\uff09\u3002\u5c06\u6b64\u65b9\u6cd5\u5e94\u7528\u4e8e\u4f18\u5316\u7ed3\u6784\u5316\u67d4\u6027\u624b\u6307\u7684\u8bbe\u8ba1\u53c2\u6570\uff0c\u4ee5\u51cf\u5c11\u5728\u63d2\u5165\u4efb\u52a1\u4e2d\u7684\u5931\u8d25\u6848\u4f8b\u3002", "result": "\u4f18\u5316\u540e\u7684\u67d4\u6027\u624b\u6307\u8bbe\u8ba1\u53c2\u6570\u80fd\u5c06\u53ef\u5bb9\u5fcd\u7684\u8bef\u5dee\u8303\u56f4\u63d0\u9ad82.29\u500d\uff0c\u8865\u507f\u9ad8\u8fbe8.6\u6beb\u7c73\u7684\u5de5\u4ef6\u53d8\u5316\u3002\u7136\u800c\uff0c\u4f18\u5316\u7ed3\u679c\u5177\u6709\u4efb\u52a1\u7279\u5f02\u6027\uff0c\u8868\u660e\u9700\u8981\u8003\u8651\u5e94\u7528\u7279\u5b9a\u51e0\u4f55\u548c\u52a8\u529b\u5b66\u7684\u5de5\u5177\u3002", "conclusion": "\u57fa\u4e8e\u4eff\u771f\u7684\u8bbe\u8ba1\u5de5\u5177\u80fd\u591f\u6709\u6548\u4f18\u5316\u8f6f\u4f53\u673a\u68b0\u624b\u7684\u53c2\u6570\uff0c\u63d0\u9ad8\u5176\u5728\u63a5\u89e6\u5f0f\u64cd\u4f5c\u4e2d\u7684\u9c81\u68d2\u6027\uff0c\u4f46\u4f18\u5316\u8d8b\u52bf\u56e0\u4efb\u52a1\u800c\u5f02\uff0c\u5f3a\u8c03\u4e86\u5f00\u53d1\u80fd\u591f\u8003\u8651\u5e94\u7528\u7279\u5b9a\u51e0\u4f55\u548c\u52a8\u529b\u5b66\u7684\u8bbe\u8ba1\u5de5\u5177\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2509.09882", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2509.09882", "abs": "https://arxiv.org/abs/2509.09882", "authors": ["Daan Camps", "Ermal Rrapaj", "Katherine Klymko", "Hyeongjin Kim", "Kevin Gott", "Siva Darbha", "Jan Balewski", "Brian Austin", "Nicholas J. Wright"], "title": "Quantum Computing Technology Roadmaps and Capability Assessment for Scientific Computing -- An analysis of use cases from the NERSC workload", "comment": null, "summary": "The National Energy Research Scientific Computing Center (NERSC), as the\nhigh-performance computing (HPC) facility for the Department of Energy's Office\nof Science, recognizes the essential role of quantum computing in its future\nmission. In this report, we analyze the NERSC workload and identify materials\nscience, quantum chemistry, and high-energy physics as the science domains and\napplication areas that stand to benefit most from quantum computers. These\ndomains jointly make up over 50% of the current NERSC production workload,\nwhich is illustrative of the impact quantum computing could have on NERSC's\nmission going forward. We perform an extensive literature review and determine\nthe quantum resources required to solve classically intractable problems within\nthese science domains. This review also shows that the quantum resources\nrequired have consistently decreased over time due to algorithmic improvements\nand a deeper understanding of the problems. At the same time, public technology\nroadmaps from a collection of ten quantum computing companies predict a\ndramatic increase in capabilities over the next five to ten years. Our analysis\nreveals a significant overlap emerging in this time frame between the\ntechnological capabilities and the algorithmic requirements in these three\nscientific domains. We anticipate that the execution time of large-scale\nquantum workflows will become a major performance parameter and propose a\nsimple metric, the Sustained Quantum System Performance (SQSP), to compare\nsystem-level performance and throughput for a heterogeneous workload.", "AI": {"tldr": "NERSC\u5c06\u91cd\u70b9\u5173\u6ce8\u6750\u6599\u79d1\u5b66\u3001\u91cf\u5b50\u5316\u5b66\u548c\u9ad8\u80fd\u7269\u7406\u8fd9\u4e09\u4e2a\u9886\u57df\uff0c\u5e76\u9884\u6d4b\u91cf\u5b50\u8ba1\u7b97\u5c06\u5728\u672a\u6765\u4e94\u5e74\u5230\u5341\u5e74\u5185\u5bf9\u8fd9\u4e9b\u9886\u57df\u4ea7\u751f\u91cd\u5927\u5f71\u54cd\u3002", "motivation": "NERSC\u8ba4\u8bc6\u5230\u91cf\u5b50\u8ba1\u7b97\u5728\u5176\u672a\u6765\u4f7f\u547d\u4e2d\u7684\u5173\u952e\u4f5c\u7528\uff0c\u5e76\u5e0c\u671b\u786e\u5b9a\u4ece\u4e2d\u53d7\u76ca\u6700\u5927\u7684\u79d1\u5b66\u9886\u57df\u3002", "method": "\u901a\u8fc7\u5206\u6790NERSC\u7684\u5de5\u4f5c\u8d1f\u8f7d\u3001\u8fdb\u884c\u6587\u732e\u7efc\u8ff0\u548c\u8bc4\u4f30\u91cf\u5b50\u8d44\u6e90\u9700\u6c42\uff0c\u540c\u65f6\u53c2\u8003\u91cf\u5b50\u8ba1\u7b97\u516c\u53f8\u7684\u6280\u672f\u8def\u7ebf\u56fe\u3002", "result": "\u6750\u6599\u79d1\u5b66\u3001\u91cf\u5b50\u5316\u5b66\u548c\u9ad8\u80fd\u7269\u7406\u662f\u53d7\u76ca\u6700\u5927\u7684\u9886\u57df\uff0c\u5360NERSC\u5f53\u524d\u5de5\u4f5c\u8d1f\u8f7d\u7684\u4e00\u534a\u4ee5\u4e0a\u3002\u91cf\u5b50\u8d44\u6e90\u9700\u6c42\u6b63\u5728\u4e0b\u964d\uff0c\u800c\u91cf\u5b50\u8ba1\u7b97\u80fd\u529b\u6b63\u5728\u8fc5\u901f\u63d0\u9ad8\uff0c\u9884\u8ba1\u5728\u672a\u6765\u4e94\u5e74\u5230\u5341\u5e74\u5185\u4f1a\u51fa\u73b0\u91cd\u5927\u91cd\u53e0\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86SQSP\u6307\u6807\u6765\u8861\u91cf\u91cf\u5b50\u7cfb\u7edf\u7684\u6027\u80fd\u3002", "conclusion": "\u91cf\u5b50\u8ba1\u7b97\u6709\u671b\u5728\u672a\u6765\u4e94\u5e74\u5230\u5341\u5e74\u5185\u5bf9NERSC\u4ea7\u751f\u91cd\u5927\u5f71\u54cd\uff0c\u5c4a\u65f6\u91cf\u5b50\u8ba1\u7b97\u80fd\u529b\u5c06\u4e0e\u79d1\u5b66\u9700\u6c42\u76f8\u5339\u914d\u3002"}}
{"id": "2509.10088", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.10088", "abs": "https://arxiv.org/abs/2509.10088", "authors": ["Christian Eckrich", "Abdelhak M. Zoubir", "Vahid Jamali"], "title": "Resilient Vital Sign Monitoring Using RIS-Assisted Radar", "comment": null, "summary": "Vital sign monitoring plays a critical role in healthcare and well-being, as\nparameters such as respiration and heart rate offer valuable insights into an\nindividual's physiological state. While wearable devices allow for continuous\nmeasurement, their use in settings like in-home elderly care is often hindered\nby discomfort or user noncompliance. As a result, contactless solutions based\non radar sensing have garnered increasing attention. This is due to their\nunobtrusive design and preservation of privacy advantages compared to\ncamera-based systems. However, a single radar perspective can fail to capture\nbreathing-induced chest movements reliably, particularly when the subject's\norientation is unfavorable. To address this limitation, we integrate a\nreconfigurable intelligent surface (RIS) that provides an additional sensing\npath, thereby enhancing the robustness of respiratory monitoring. We present a\nnovel model for multi-path vital sign sensing that leverages both the direct\nradar path and an RIS-reflected path. We further discuss the potential benefits\nand improved performance our approach offers in continuous, privacy-preserving\nvital sign monitoring.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u96f7\u8fbe\u4e0e\u667a\u80fd\u53cd\u5c04\u9762\uff08RIS\uff09\u7684\u591a\u8def\u5f84\u4f20\u611f\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u4e0d\u5e72\u6270\u7528\u6237\u7684\u60c5\u51b5\u4e0b\u76d1\u6d4b\u547c\u5438\u548c\u5fc3\u7387\u7b49\u751f\u547d\u4f53\u5f81\uff0c\u89e3\u51b3\u4e86\u5355\u4e00\u96f7\u8fbe\u89c6\u89d2\u53ef\u80fd\u5b58\u5728\u7684\u76d1\u6d4b\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u53ef\u7a7f\u6234\u751f\u547d\u4f53\u5f81\u76d1\u6d4b\u8bbe\u5907\u5b58\u5728\u8212\u9002\u5ea6\u548c\u4f9d\u4ece\u6027\u95ee\u9898\uff0c\u57fa\u4e8e\u96f7\u8fbe\u7684\u975e\u63a5\u89e6\u5f0f\u76d1\u6d4b\u65b9\u6848\u867d\u6709\u4f18\u52bf\u4f46\u53ef\u80fd\u56e0\u89d2\u5ea6\u95ee\u9898\u5bfc\u81f4\u76d1\u6d4b\u4e0d\u51c6\u786e\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u9c81\u68d2\u7684\u76d1\u6d4b\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u5229\u7528\u76f4\u63a5\u96f7\u8fbe\u8def\u5f84\u548cRIS\u53cd\u5c04\u8def\u5f84\u7684\u591a\u8def\u5f84\u751f\u547d\u4f53\u5f81\u4f20\u611f\u6a21\u578b\uff0c\u5e76\u8ba8\u8bba\u5176\u5728\u8fde\u7eed\u3001\u9690\u79c1\u4fdd\u62a4\u7684\u751f\u547d\u4f53\u5f81\u76d1\u6d4b\u4e2d\u7684\u6f5c\u5728\u4f18\u52bf\u548c\u6027\u80fd\u63d0\u5347\u3002", "result": "\u901a\u8fc7\u96c6\u6210RIS\u63d0\u4f9b\u989d\u5916\u7684\u4f20\u611f\u8def\u5f84\uff0c\u589e\u5f3a\u4e86\u547c\u5438\u76d1\u6d4b\u7684\u9c81\u68d2\u6027\uff0c\u6709\u671b\u5728\u4e0d\u5e72\u6270\u7528\u6237\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u66f4\u53ef\u9760\u7684\u751f\u547d\u4f53\u5f81\u76d1\u6d4b\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u591a\u8def\u5f84\u751f\u547d\u4f53\u5f81\u4f20\u611f\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408RIS\u6280\u672f\u663e\u8457\u63d0\u9ad8\u4e86\u96f7\u8fbe\u751f\u547d\u4f53\u5f81\u76d1\u6d4b\u7684\u9c81\u68d2\u6027\u548c\u51c6\u786e\u6027\uff0c\u4e3a\u975e\u63a5\u89e6\u5f0f\u3001\u4fdd\u62a4\u9690\u79c1\u7684\u5065\u5eb7\u76d1\u6d4b\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.10191", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2509.10191", "abs": "https://arxiv.org/abs/2509.10191", "authors": ["I. M. F\u00e9lix", "B. Ipaves", "R. B. de Oliveira", "L. A. Ribeiro Junior", "L. S. Rocha", "M. L. Pereira Junior", "D. S. Galv\u00e3o", "R. M. Tromer"], "title": "Novel 3D Pentagraphene Allotropes: Stability, Electronic, Mechanical, and Optical Properties", "comment": null, "summary": "Carbon-based materials have attracted great attention due to their\nexceptional structural diversity and wide-ranging applications. Recently, a new\ntwo-dimensional carbon allotrope, named pentagraphene (PG), was proposed. In\nthis study, we proposed three novel three-dimensional (3D) PG allotropes, named\n3D-PG-$\\alpha$, -$\\beta$, and -$\\gamma$, engineered through biaxial strain and\ncontrolled compression of 2D PG layers. Comprehensive stability analyses,\nincluding phonon dispersion and ab initio molecular dynamics simulations\n(AIMD), confirm their thermodynamic stability under room and high-temperature\nconditions. 3D-PG-$\\alpha$ is the most stable, exhibiting a cohesive energy 0.5\neV/atom lower than the least stable structure, 3D-PG-$\\gamma$. Electronic\nproperty characterization reveals semiconducting behavior for all structures,\nwith indirect electronic band gaps ranging from 0.91 to 2.67 eV. The analyses\nof the mechanical properties showed significant anisotropy, with higher\nstiffness along the in-plane ($xy$-plane) direction. Optical properties\nhighlight strong absorption along a wide range and a pronounced anisotropic\nresponse. Additionally, the absorption spectra exhibit activity in the visible\nregion, and the refractive index and reflectivity indicate potential use in\nultraviolet-blocking devices.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e09\u79cd\u65b0\u578b\u4e09\u7ef4\u4e94\u77f3\u58a8\u70ef\uff083D-PG\uff09\u540c\u7d20\u5f02\u5f62\u4f53\uff083D-PG-\u03b1\u3001-\u03b2\u3001-\u03b3\uff09\uff0c\u5e76\u901a\u8fc7\u5e94\u53d8\u548c\u538b\u7f29\u5bf9\u5176\u8fdb\u884c\u4e86\u5de5\u7a0b\u5316\u3002", "motivation": "\u7814\u7a76\u65b0\u578b\u4e09\u7ef4\u78b3\u540c\u7d20\u5f02\u5f62\u4f53\u5728\u7a33\u5b9a\u6027\u548c\u6027\u80fd\u65b9\u9762\u7684\u6f5c\u529b\u3002", "method": "\u901a\u8fc7\u53cc\u8f74\u5e94\u53d8\u548c\u53d7\u63a7\u538b\u7f29\u5bf9\u4e8c\u7ef4\u4e94\u77f3\u58a8\u70ef\uff08PG\uff09\u5c42\u8fdb\u884c\u5de5\u7a0b\u5316\uff0c\u5e76\u8fdb\u884c\u58f0\u5b50\u8272\u6563\u548c\u4ece\u5934\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u62df\uff08AIMD\uff09\u4ee5\u8bc4\u4f30\u7a33\u5b9a\u6027\u548c\u7535\u5b50\u3001\u673a\u68b0\u3001\u5149\u5b66\u6027\u8d28\u3002", "result": "\u6240\u6709\u4e09\u79cd3D-PG\u540c\u7d20\u5f02\u5f62\u4f53\u90fd\u88ab\u8bc1\u660e\u5728\u5ba4\u6e29\u548c\u9ad8\u6e29\u4e0b\u662f\u70ed\u529b\u5b66\u7a33\u5b9a\u7684\uff0c\u5176\u4e2d3D-PG-\u03b1\u6700\u7a33\u5b9a\u3002\u5b83\u4eec\u90fd\u8868\u73b0\u51fa\u534a\u5bfc\u4f53\u884c\u4e3a\uff0c\u5e26\u9699\u57280.91\u52302.67 eV\u4e4b\u95f4\u3002\u673a\u68b0\u6027\u80fd\u663e\u793a\u51fa\u663e\u8457\u7684\u5404\u5411\u5f02\u6027\uff0c\u6cbf\u5e73\u9762\uff08xy\u5e73\u9762\uff09\u65b9\u5411\u7684\u521a\u5ea6\u66f4\u9ad8\u3002\u5149\u5b66\u6027\u8d28\u663e\u793a\u5728\u8f83\u5bbd\u8303\u56f4\u5185\u6709\u5f3a\u5438\u6536\uff0c\u5e76\u4e14\u5728\u53ef\u89c1\u5149\u533a\u57df\u6709\u6d3b\u6027\uff0c\u5728\u7d2b\u5916\u7ebf\u963b\u6321\u8bbe\u5907\u4e2d\u6709\u6f5c\u5728\u5e94\u7528\u3002", "conclusion": "\u4e09\u79cd\u65b0\u578b3D-PG\u540c\u7d20\u5f02\u5f62\u4f53\u662f\u7a33\u5b9a\u4e14\u5177\u6709\u5438\u5f15\u529b\u7684\u6750\u6599\uff0c\u5728\u7535\u5b50\u3001\u5149\u5b66\u548c\u673a\u68b0\u5e94\u7528\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2509.09708", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09708", "abs": "https://arxiv.org/abs/2509.09708", "authors": ["Nirmalendu Prakash", "Yeo Wei Jie", "Amir Abdullah", "Ranjan Satapathy", "Erik Cambria", "Roy Ka Wei Lee"], "title": "Beyond I'm Sorry, I Can't: Dissecting Large Language Model Refusal", "comment": null, "summary": "Refusal on harmful prompts is a key safety behaviour in instruction-tuned\nlarge language models (LLMs), yet the internal causes of this behaviour remain\npoorly understood. We study two public instruction-tuned models, Gemma-2-2B-IT\nand LLaMA-3.1-8B-IT, using sparse autoencoders (SAEs) trained on\nresidual-stream activations. Given a harmful prompt, we search the SAE latent\nspace for feature sets whose ablation flips the model from refusal to\ncompliance, demonstrating causal influence and creating a jailbreak. Our search\nproceeds in three stages: (1) Refusal Direction: find a refusal-mediating\ndirection and collect SAE features near that direction; (2) Greedy Filtering:\nprune to a minimal set; and (3) Interaction Discovery: fit a factorization\nmachine (FM) that captures nonlinear interactions among the remaining active\nfeatures and the minimal set. This pipeline yields a broad set of\njailbreak-critical features, offering insight into the mechanistic basis of\nrefusal. Moreover, we find evidence of redundant features that remain dormant\nunless earlier features are suppressed. Our findings highlight the potential\nfor fine-grained auditing and targeted intervention in safety behaviours by\nmanipulating the interpretable latent space.", "AI": {"tldr": "\u901a\u8fc7\u5bf9Gemma-2-2B-IT\u548cLLaMA-3.1-8B-IT\u6a21\u578b\u8fdb\u884c\u7a00\u758f\u81ea\u7f16\u7801\u5668\uff08SAE\uff09\u5206\u6790\uff0c\u7814\u7a76\u4e86\u6a21\u578b\u62d2\u7edd\u6709\u5bb3\u63d0\u793a\u7684\u5185\u90e8\u673a\u5236\u3002\u901a\u8fc7\u5728SAE\u6f5c\u5728\u7a7a\u95f4\u4e2d\u5bfb\u627e\u5e76\u79fb\u9664\u5173\u952e\u7279\u5f81\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u4ece\u62d2\u7edd\u5230\u670d\u4ece\u7684\u8f6c\u6362\uff0c\u4ece\u800c\u5236\u9020\u4e86\u8d8a\u72f1\u3002\u7814\u7a76\u8fc7\u7a0b\u5305\u62ec\u5bfb\u627e\u62d2\u6a21\u578b\u5f15\u5bfc\u65b9\u5411\u3001\u8d2a\u5a6a\u8fc7\u6ee4\u4ee5\u53ca\u53d1\u73b0\u7279\u5f81\u95f4\u7684\u4ea4\u4e92\u4f5c\u7528\u3002\u7ed3\u679c\u63ed\u793a\u4e86\u5bfc\u81f4\u8d8a\u72f1\u7684\u5173\u952e\u7279\u5f81\u96c6\uff0c\u5e76\u53d1\u73b0\u4e86\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u624d\u4f1a\u88ab\u6fc0\u6d3b\u7684\u5197\u4f59\u7279\u5f81\u3002", "motivation": "\u7406\u89e3\u6307\u4ee4\u8c03\u6574\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u62d2\u7edd\u6709\u5bb3\u63d0\u793a\u65f6\u7684\u5185\u90e8\u539f\u56e0\u3002", "method": "\u4f7f\u7528\u7a00\u758f\u81ea\u7f16\u7801\u5668\uff08SAEs\uff09\u8bad\u7ec3\u6a21\u578b\u6b8b\u5dee\u6d41\u6fc0\u6d3b\u3002\u901a\u8fc7\u5728SAE\u6f5c\u5728\u7a7a\u95f4\u4e2d\u641c\u7d22\u3001\u6d88\u878d\u7279\u5f81\u96c6\u6765\u7ffb\u8f6c\u6a21\u578b\u7684\u884c\u4e3a\uff0c\u5b9e\u73b0\u4ece\u62d2\u7edd\u5230\u670d\u4ece\u7684\u8f6c\u6362\u3002\u641c\u7d22\u8fc7\u7a0b\u5206\u4e09\u4e2a\u9636\u6bb5\uff1a1. \u5bfb\u627e\u62d2\u6a21\u578b\u5f15\u5bfc\u65b9\u5411\u5e76\u6536\u96c6\u9644\u8fd1\u7279\u5f81\uff1b2. \u8d2a\u5a6a\u8fc7\u6ee4\u4ee5\u83b7\u5f97\u6700\u5c0f\u7279\u5f81\u96c6\uff1b3. \u62df\u5408\u56e0\u5b50\u5206\u89e3\u673a\uff08FM\uff09\u6355\u6349\u5269\u4f59\u7279\u5f81\u95f4\u7684\u975e\u7ebf\u6027\u4ea4\u4e92\u4f5c\u7528\u3002", "result": "\u53d1\u73b0\u4e86\u5bfc\u81f4\u8d8a\u72f1\u7684\u5173\u952e\u7279\u5f81\u96c6\uff0c\u6df1\u5165\u4e86\u89e3\u4e86\u6a21\u578b\u62d2\u6a21\u578b\u884c\u4e3a\u7684\u673a\u5236\u57fa\u7840\u3002\u6b64\u5916\uff0c\u8fd8\u53d1\u73b0\u4e86\u4e4b\u524d\u5904\u4e8e\u4f11\u7720\u72b6\u6001\u3001\u4ec5\u5728\u65e9\u671f\u7279\u5f81\u88ab\u6291\u5236\u65f6\u624d\u88ab\u6fc0\u6d3b\u7684\u5197\u4f59\u7279\u5f81\u3002", "conclusion": "\u901a\u8fc7\u64cd\u7eb5\u53ef\u89e3\u91ca\u7684\u6f5c\u5728\u7a7a\u95f4\uff0c\u53ef\u4ee5\u5b9e\u73b0\u5bf9\u6a21\u578b\u5b89\u5168\u884c\u4e3a\u7684\u7ec6\u7c92\u5ea6\u5ba1\u8ba1\u548c\u9776\u5411\u5e72\u9884\u3002"}}
{"id": "2509.09799", "categories": ["cs.LG", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.09799", "abs": "https://arxiv.org/abs/2509.09799", "authors": ["Mansi Sharma", "Alexandre Duchevet", "Florian Daiber", "Jean-Paul Imbert", "Maurice Rekrut"], "title": "Distinguishing Startle from Surprise Events Based on Physiological Signals", "comment": null, "summary": "Unexpected events can impair attention and delay decision-making, posing\nserious safety risks in high-risk environments such as aviation. In particular,\nreactions like startle and surprise can impact pilot performance in different\nways, yet are often hard to distinguish in practice. Existing research has\nlargely studied these reactions separately, with limited focus on their\ncombined effects or how to differentiate them using physiological data. In this\nwork, we address this gap by distinguishing between startle and surprise events\nbased on physiological signals using machine learning and multi-modal fusion\nstrategies. Our results demonstrate that these events can be reliably\npredicted, achieving a highest mean accuracy of 85.7% with SVM and Late Fusion.\nTo further validate the robustness of our model, we extended the evaluation to\ninclude a baseline condition, successfully differentiating between Startle,\nSurprise, and Baseline states with a highest mean accuracy of 74.9% with\nXGBoost and Late Fusion.", "AI": {"tldr": "\u672c\u7814\u7a76\u5229\u7528\u673a\u5668\u5b66\u4e60\u548c\u591a\u6a21\u6001\u878d\u5408\u7b56\u7565\uff0c\u901a\u8fc7\u751f\u7406\u4fe1\u53f7\u533a\u5206\u60ca\u5413\u548c\u60ca\u559c\u53cd\u5e94\uff0c\u6700\u9ad8\u51c6\u786e\u7387\u8fbe85.7%\u3002", "motivation": "\u533a\u5206\u60ca\u5413\u548c\u60ca\u559c\u53cd\u5e94\u5bf9\u4e8e\u5728\u9ad8\u98ce\u9669\u73af\u5883\u4e2d\uff08\u5982\u822a\u7a7a\u4e1a\uff09\u4fdd\u969c\u98de\u884c\u5458\u7ee9\u6548\u548c\u5b89\u5168\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u5bf9\u8fd9\u4e24\u8005\u8054\u5408\u6548\u5e94\u7684\u5173\u6ce8\u4ee5\u53ca\u533a\u5206\u5b83\u4eec\u7684\u751f\u7406\u4f9d\u636e\u3002", "method": "\u5229\u7528\u673a\u5668\u5b66\u4e60\u548c\u591a\u6a21\u6001\u878d\u5408\u7b56\u7565\uff0c\u57fa\u4e8e\u751f\u7406\u4fe1\u53f7\u533a\u5206\u60ca\u5413\u548c\u60ca\u559c\u4e8b\u4ef6\u3002", "result": "\u6240\u63d0\u51fa\u7684\u6a21\u578b\u80fd\u591f\u53ef\u9760\u5730\u9884\u6d4b\u8fd9\u4e9b\u4e8b\u4ef6\uff0c\u4f7f\u7528SVM\u548cLate Fusion\u7b56\u7565\u65f6\uff0c\u6700\u9ad8\u5e73\u5747\u51c6\u786e\u7387\u8fbe\u523085.7%\u3002\u5728\u5305\u542b\u57fa\u7ebf\u6761\u4ef6\u7684\u6269\u5c55\u8bc4\u4f30\u4e2d\uff0c\u4f7f\u7528XGBoost\u548cLate Fusion\u7b56\u7565\uff0c\u6210\u529f\u533a\u5206\u60ca\u5413\u3001\u60ca\u559c\u548c\u57fa\u7ebf\u72b6\u6001\uff0c\u6700\u9ad8\u5e73\u5747\u51c6\u786e\u7387\u4e3a74.9%\u3002", "conclusion": "\u672c\u7814\u7a76\u6210\u529f\u5730\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u751f\u7406\u4fe1\u53f7\u548c\u673a\u5668\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u533a\u5206\u60ca\u5413\u548c\u60ca\u559c\u8fd9\u4e24\u79cd\u5bf9\u6ce8\u610f\u529b\u6709\u5f71\u54cd\u7684\u4e8b\u4ef6\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u5728\u9ad8\u98ce\u9669\u73af\u5883\u4e2d\u7684\u6f5c\u5728\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2509.10239", "categories": ["quant-ph", "cs.CC", "cs.DS"], "pdf": "https://arxiv.org/pdf/2509.10239", "abs": "https://arxiv.org/abs/2509.10239", "authors": ["Andreas Bluhm", "Matthias C. Caro", "Francisco Escudero Guti\u00e9rrez", "Aadil Oufkir", "Cambyse Rouz\u00e9"], "title": "Certifying and learning quantum Ising Hamiltonians", "comment": "20 pages, no figures", "summary": "In this work, we study the problems of certifying and learning quantum Ising\nHamiltonians. Our main contributions are as follows:\n  Certification of Ising Hamiltonians. We show that certifying an Ising\nHamiltonian in normalized Frobenius norm via access to its time-evolution\noperator requires only $\\widetilde O(1/\\varepsilon)$ time evolution. This\nmatches the Heisenberg-scaling lower bound of $\\Omega(1/\\varepsilon)$ up to\nlogarithmic factors. To our knowledge, this is the first nearly-optimal\nalgorithm for testing a Hamiltonian property. A key ingredient in our analysis\nis the Bonami Lemma from Fourier analysis.\n  Learning Ising Gibbs states. We design an algorithm for learning Ising Gibbs\nstates in trace norm that is sample-efficient in all parameters. In contrast,\nprevious approaches learned the underlying Hamiltonian (which implies learning\nthe Gibbs state) but suffered from exponential sample complexity in the inverse\ntemperature.\n  Certification of Ising Gibbs states. We give an algorithm for certifying\nIsing Gibbs states in trace norm that is both sample and time-efficient,\nthereby solving a question posed by Anshu (Harvard Data Science Review, 2022).\n  Finally, we extend our results on learning and certification of Gibbs states\nto general $k$-local Hamiltonians for any constant $k$.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u91cf\u5b50\u4f0a\u8f9b\u54c8\u5bc6\u987f\u91cf\u7684\u8ba4\u8bc1\u548c\u5b66\u4e60\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u8fd1\u4e4e\u6700\u4f18\u7684\u7b97\u6cd5\u3002", "motivation": "\u7814\u7a76\u91cf\u5b50\u4f0a\u8f9b\u54c8\u5bc6\u987f\u91cf\u7684\u8ba4\u8bc1\u548c\u5b66\u4e60\u95ee\u9898\uff0c\u65e8\u5728\u89e3\u51b3\u73b0\u6709\u7b97\u6cd5\u5728\u65f6\u95f4\u3001\u6837\u672c\u590d\u6742\u5ea6\u6216\u53c2\u6570\u4f9d\u8d56\u6027\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "method": "\u5229\u7528\u5085\u91cc\u53f6\u5206\u6790\u4e2d\u7684Bonami Lemma\u6765\u8ba4\u8bc1\u4f0a\u8f9b\u54c8\u5bc6\u987f\u91cf\uff1b\u8bbe\u8ba1\u4e86\u4e00\u79cd\u6837\u672c\u6548\u7387\u9ad8\u7684\u7b97\u6cd5\u6765\u5b66\u4e60\u4f0a\u8f9b\u5409\u5e03\u65af\u72b6\u6001\uff1b\u63d0\u51fa\u4e86\u65f6\u95f4\u548c\u6837\u672c\u6548\u7387\u517c\u5177\u7684\u7b97\u6cd5\u6765\u8ba4\u8bc1\u4f0a\u8f9b\u5409\u5e03\u65af\u72b6\u6001\u3002\u6700\u540e\u5c06\u5409\u5e03\u65af\u72b6\u6001\u7684\u5b66\u4e60\u548c\u8ba4\u8bc1\u7ed3\u679c\u63a8\u5e7f\u5230\u4e00\u822c\u7684k-\u5c40\u90e8\u54c8\u5bc6\u987f\u91cf\u3002", "result": "\u8ba4\u8bc1\u4f0a\u8f9b\u54c8\u5bc6\u987f\u91cf\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u63a5\u8fd1\u6700\u4f18\uff08$\tilde{O}(1/\tau)$\uff09\uff0c\u5b66\u4e60\u4f0a\u8f9b\u5409\u5e03\u65af\u72b6\u6001\u7684\u6837\u672c\u590d\u6742\u5ea6\u5728\u6240\u6709\u53c2\u6570\u4e0a\u90fd\u662f\u6837\u672c\u6548\u7387\u7684\uff0c\u8ba4\u8bc1\u4f0a\u8f9b\u5409\u5e03\u65af\u72b6\u6001\u7684\u7b97\u6cd5\u540c\u65f6\u5b9e\u73b0\u4e86\u6837\u672c\u548c\u65f6\u95f4\u7684\u6548\u7387\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u91cf\u5b50\u4f0a\u8f9b\u54c8\u5bc6\u987f\u91cf\u7684\u8ba4\u8bc1\u548c\u5b66\u4e60\u65b9\u9762\u53d6\u5f97\u4e86\u8fd1\u4e4e\u6700\u4f18\u6216\u6837\u672c/\u65f6\u95f4\u6548\u7387\u7684\u6539\u8fdb\uff0c\u5e76\u6210\u529f\u63a8\u5e7f\u5230\u66f4\u4e00\u822c\u7684k-\u5c40\u90e8\u54c8\u5bc6\u987f\u91cf\u3002"}}
{"id": "2509.10044", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.10044", "abs": "https://arxiv.org/abs/2509.10044", "authors": ["Jorge Ventura", "Jaroslav Hrdina", "Ale\u0161 N\u00e1vrat", "Marek Stodola", "Ahmad Eid", "Santiago Sanchez-Acevedo", "Francisco G. Montoya"], "title": "Understanding the Geometry of Faulted Power Systems under High Penetration of Inverter-Based Resources via Ellipse Fitting and Geometric Algebra", "comment": null, "summary": "Power systems with high penetration of inverter-based resources (IBR) present\nsignificant challenges for conventional protection schemes, with traditional\ndistance protection methods failing to detect line-to-line faults during\nasymmetric conditions. This paper presents a methodology for electrical fault\ndetection and classification using ellipse fitting and geometric algebra\napplied to voltage and current space curves. The approach characterizes\nelectrical faults by fitting ellipses to voltage vector data, enabling fault\ndetection with only a quarter-cycle. The method employs bivector components for\nline-to-ground fault classification, while ellipse parameters identify\nline-to-line and three-phase faults. The geometric representation preserves\nvoltage or current curve shapes in three-dimensional space, overcoming Clarke\ntransform limitations when zero-sequence components are present. Validation\nusing simulations and laboratory experiments demonstrates accurate fault\nidentification and magnitude estimation, providing enhanced power system\nprotection capabilities.", "AI": {"tldr": "\u9ad8\u6e17\u900f\u7387\u7684\u9006\u53d8\u5668\u57fa\u8d44\u6e90\uff08IBD\uff09\u5bf9\u4f20\u7edf\u4fdd\u62a4\u65b9\u6848\u63d0\u51fa\u6311\u6218\uff0c\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u5229\u7528\u692d\u5706\u62df\u5408\u548c\u51e0\u4f55\u4ee3\u6570\u8fdb\u884c\u6545\u969c\u68c0\u6d4b\u548c\u5206\u7c7b\u7684\u65b9\u6cd5\uff0c\u4ec5\u9700\u56db\u5206\u4e4b\u4e00\u4e2a\u5468\u671f\u5373\u53ef\u5b9e\u73b0\u6545\u969c\u68c0\u6d4b\uff0c\u5e76\u80fd\u51c6\u786e\u8bc6\u522b\u5404\u79cd\u7c7b\u578b\u6545\u969c\u3002", "motivation": "\u9ad8\u6e17\u900f\u7387\u7684\u9006\u53d8\u5668\u57fa\u8d44\u6e90\uff08IBD\uff09\u5bf9\u4f20\u7edf\u4fdd\u62a4\u65b9\u6848\u63d0\u51fa\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u975e\u5bf9\u79f0\u6761\u4ef6\u4e0b\uff0c\u4f20\u7edf\u7684\u8ddd\u79bb\u4fdd\u62a4\u65b9\u6cd5\u65e0\u6cd5\u68c0\u6d4b\u7ebf\u95f4\u6545\u969c\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u5229\u7528\u692d\u5706\u62df\u5408\u548c\u51e0\u4f55\u4ee3\u6570\u5e94\u7528\u4e8e\u7535\u538b\u548c\u7535\u6d41\u7a7a\u95f4\u66f2\u7ebf\u7684\u6545\u969c\u68c0\u6d4b\u548c\u5206\u7c7b\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u62df\u5408\u7535\u538b\u77e2\u91cf\u6570\u636e\u7684\u692d\u5706\u6765\u8868\u5f81\u7535\u6c14\u6545\u969c\uff0c\u5e76\u5229\u7528\u4e8c\u77e2\u91cf\u5206\u91cf\u8fdb\u884c\u63a5\u5730\u6545\u969c\u5206\u7c7b\uff0c\u540c\u65f6\u5229\u7528\u692d\u5706\u53c2\u6570\u8bc6\u522b\u7ebf\u95f4\u548c\u4e09\u76f8\u6545\u969c\u3002", "result": "\u4eff\u771f\u548c\u5b9e\u9a8c\u5ba4\u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u51c6\u786e\u8bc6\u522b\u6545\u969c\u5e76\u4f30\u8ba1\u6545\u969c\u5e45\u503c\uff0c\u80fd\u591f\u7528\u4e8e\u589e\u5f3a\u7535\u7f51\u4fdd\u62a4\u80fd\u529b\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u692d\u5706\u62df\u5408\u548c\u51e0\u4f55\u4ee3\u6570\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u9ad8\u6e17\u900f\u7387IBD\u7cfb\u7edf\u4e2d\u7684\u6545\u969c\u68c0\u6d4b\u548c\u5206\u7c7b\u95ee\u9898\uff0c\u5e76\u4e14\u5177\u6709\u54cd\u5e94\u901f\u5ea6\u5feb\u3001\u7cbe\u5ea6\u9ad8\u7b49\u4f18\u70b9\u3002"}}
{"id": "2509.09750", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09750", "abs": "https://arxiv.org/abs/2509.09750", "authors": ["Hossein Yazdanjouei", "Arash Mansouri", "Mohammad Shokouhifar"], "title": "A Co-Training Semi-Supervised Framework Using Faster R-CNN and YOLO Networks for Object Detection in Densely Packed Retail Images", "comment": null, "summary": "This study proposes a semi-supervised co-training framework for object\ndetection in densely packed retail environments, where limited labeled data and\ncomplex conditions pose major challenges. The framework combines Faster R-CNN\n(utilizing a ResNet backbone) for precise localization with YOLO (employing a\nDarknet backbone) for global context, enabling mutual pseudo-label exchange\nthat improves accuracy in scenes with occlusion and overlapping objects. To\nstrengthen classification, it employs an ensemble of XGBoost, Random Forest,\nand SVM, utilizing diverse feature representations for higher robustness.\nHyperparameters are optimized using a metaheuristic-driven algorithm, enhancing\nprecision and efficiency across models. By minimizing reliance on manual\nlabeling, the approach reduces annotation costs and adapts effectively to\nfrequent product and layout changes common in retail. Experiments on the\nSKU-110k dataset demonstrate strong performance, highlighting the scalability\nand practicality of the proposed framework for real-world retail applications\nsuch as automated inventory tracking, product monitoring, and checkout systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u534a\u76d1\u7763\u534f\u540c\u8bad\u7ec3\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u96f6\u552e\u73af\u5883\u4e2d\u76ee\u6807\u68c0\u6d4b\u7684\u6311\u6218\u3002", "motivation": "\u96f6\u552e\u73af\u5883\u4e2d\u7684\u76ee\u6807\u68c0\u6d4b\u9762\u4e34\u6570\u636e\u6807\u6ce8\u6709\u9650\u548c\u590d\u6742\u573a\u666f\uff08\u5982\u906e\u6321\u3001\u91cd\u53e0\uff09\u7684\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u63d0\u9ad8\u7cbe\u5ea6\u5e76\u51cf\u5c11\u6807\u6ce8\u6210\u672c\u7684\u65b9\u6cd5\u3002", "method": "\u8be5\u6846\u67b6\u7ed3\u5408\u4e86Faster R-CNN\uff08\u7528\u4e8e\u7cbe\u786e\u5b9a\u4f4d\uff09\u548cYOLO\uff08\u7528\u4e8e\u5168\u5c40\u4e0a\u4e0b\u6587\uff09\uff0c\u901a\u8fc7\u4e92\u60e0\u7684\u4f2a\u6807\u7b7e\u4ea4\u6362\u6765\u63d0\u9ad8\u5bf9\u906e\u6321\u548c\u91cd\u53e0\u7269\u4f53\u7684\u68c0\u6d4b\u80fd\u529b\u3002\u540c\u65f6\uff0c\u96c6\u6210\u4e86XGBoost\u3001\u968f\u673a\u68ee\u6797\u548cSVM\u7b49\u5206\u7c7b\u5668\u4ee5\u589e\u5f3a\u5206\u7c7b\u9c81\u68d2\u6027\uff0c\u5e76\u4f7f\u7528\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u4f18\u5316\u8d85\u53c2\u6570\u3002", "result": "\u5728SKU-110k\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u5bc6\u96c6\u96f6\u552e\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u906e\u6321\u548c\u91cd\u53e0\u7684\u7269\u4f53\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u534a\u76d1\u7763\u534f\u540c\u8bad\u7ec3\u6846\u67b6\u901a\u8fc7\u51cf\u5c11\u5bf9\u624b\u52a8\u6807\u6ce8\u7684\u4f9d\u8d56\uff0c\u964d\u4f4e\u4e86\u6807\u6ce8\u6210\u672c\uff0c\u5e76\u80fd\u6709\u6548\u9002\u5e94\u96f6\u552e\u73af\u5883\u4e2d\u5e38\u89c1\u7684\u5546\u54c1\u548c\u5e03\u5c40\u53d8\u5316\uff0c\u5728\u81ea\u52a8\u5e93\u5b58\u8ddf\u8e2a\u3001\u5546\u54c1\u76d1\u63a7\u548c\u7ed3\u8d26\u7cfb\u7edf\u7b49\u5b9e\u9645\u5e94\u7528\u4e2d\u5177\u6709\u5f88\u9ad8\u7684\u53ef\u6269\u5c55\u6027\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2509.10242", "categories": ["cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2509.10242", "abs": "https://arxiv.org/abs/2509.10242", "authors": ["C. W. J. Beenakker"], "title": "Pure dephasing increases partition noise in the quantum Hall effect", "comment": "9 pages, 6 figures", "summary": "Quantum Hall edge channels partition electric charge over N chiral\n(uni-directional) modes. Intermode scattering leads to partition noise,\nobserved in graphene p-n junctions. While inelastic scattering suppresses this\nnoise by averaging out fluctuations, we show that pure (quasi-elastic)\ndephasing may enhance the partition noise. The noise power increases by up to\n50% for two modes, with a general enhancement factor of 1+1/N in the\nstrong-dephasing limit. This counterintuitive effect is explained in the\nframework of monitored quantum transport, arising from the self-averaging of\nquantum trajectories.", "AI": {"tldr": "\u91cf\u5b50\u970d\u5c14\u8fb9\u7f18\u901a\u9053\u4e2d\u7684\u7535\u8377\u5206\u914d\u5728 N \u4e2a\u624b\u5f81\u6a21\u5f0f\u4e4b\u95f4\u8fdb\u884c\u3002\u6a21\u5f0f\u95f4\u6563\u5c04\u4f1a\u5bfc\u81f4\u5206\u914d\u566a\u58f0\uff0c\u8fd9\u5728\u77f3\u58a8\u70ef p-n \u7ed3\u4e2d\u5df2\u5f97\u5230\u89c2\u5bdf\u3002\u867d\u7136\u975e\u5f39\u6027\u6563\u5c04\u901a\u8fc7\u5e73\u5747\u8d77\u4f0f\u6765\u6291\u5236\u8fd9\u79cd\u566a\u58f0\uff0c\u4f46\u6211\u4eec\u8bc1\u660e\u4e86\u7eaf\uff08\u51c6\u5f39\u6027\uff09\u9000\u76f8\u5e72\u53ef\u80fd\u4f1a\u589e\u5f3a\u5206\u914d\u566a\u58f0\u3002\u5bf9\u4e8e\u4e24\u4e2a\u6a21\u5f0f\uff0c\u566a\u58f0\u529f\u7387\u6700\u591a\u53ef\u589e\u52a0 50%\uff0c\u5728\u5f3a\u9000\u76f8\u5e72\u6781\u9650\u4e0b\uff0c\u603b\u4f53\u589e\u5f3a\u56e0\u5b50\u4e3a 1+1/N\u3002\u8fd9\u79cd\u53cd\u76f4\u89c9\u7684\u6548\u5e94\u5728\u53d7\u76d1\u63a7\u7684\u91cf\u5b50\u8f93\u8fd0\u6846\u67b6\u4e0b\u5f97\u5230\u4e86\u89e3\u91ca\uff0c\u8fd9\u662f\u7531\u91cf\u5b50\u8f68\u8ff9\u7684\u81ea\u5e73\u5747\u5f15\u8d77\u7684\u3002", "motivation": "\u7814\u7a76\u91cf\u5b50\u970d\u5c14\u8fb9\u7f18\u901a\u9053\u4e2d\u7535\u8377\u5206\u914d\u7684\u566a\u58f0\uff0c\u7279\u522b\u662f\u5728\u5b58\u5728\u51c6\u5f39\u6027\u9000\u76f8\u5e72\u7684\u60c5\u51b5\u4e0b\uff0c\u8fd9\u4e0e\u901a\u5e38\u9884\u671f\u7684\u6291\u5236\u566a\u58f0\u76f8\u53cd\u3002", "method": "\u5229\u7528\u53d7\u76d1\u63a7\u7684\u91cf\u5b50\u8f93\u8fd0\u6846\u67b6\u6765\u89e3\u91ca\u51c6\u5f39\u6027\u9000\u76f8\u5e72\u5982\u4f55\u589e\u5f3a\u5206\u914d\u566a\u58f0\uff0c\u5e76\u63a8\u5bfc\u4e86\u566a\u58f0\u589e\u5f3a\u7684\u4e00\u822c\u516c\u5f0f\u3002", "result": "\u53d1\u73b0\u7eaf\uff08\u51c6\u5f39\u6027\uff09\u9000\u76f8\u5e72\u6700\u591a\u53ef\u5c06\u5206\u914d\u566a\u58f0\u529f\u7387\u63d0\u9ad8 50%\uff08\u5bf9\u4e8e\u4e24\u4e2a\u6a21\u5f0f\uff09\uff0c\u5728\u5f3a\u9000\u76f8\u5e72\u6781\u9650\u4e0b\uff0c\u566a\u58f0\u589e\u5f3a\u56e0\u5b50\u4e3a 1+1/N\u3002", "conclusion": "\u51c6\u5f39\u6027\u9000\u76f8\u5e72\u53ef\u4ee5\u589e\u5f3a\u91cf\u5b50\u970d\u5c14\u8fb9\u7f18\u901a\u9053\u4e2d\u7684\u5206\u914d\u566a\u58f0\uff0c\u8fd9\u4e00\u53cd\u76f4\u89c9\u7684\u73b0\u8c61\u53ef\u4ee5\u901a\u8fc7\u91cf\u5b50\u8f68\u8ff9\u7684\u81ea\u5e73\u5747\u6765\u89e3\u91ca\u3002"}}
{"id": "2509.10032", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.10032", "abs": "https://arxiv.org/abs/2509.10032", "authors": ["Marawan Khalil", "Fabian Arzberger", "Andreas N\u00fcchter"], "title": "Design and Evaluation of Two Spherical Systems for Mobile 3D Mapping", "comment": "6 Pages, 9 figures, International Workshop 3D-AdViCE in conjunction\n  with 12th ECMR 2025", "summary": "Spherical robots offer unique advantages for mapping applications in\nhazardous or confined environments, thanks to their protective shells and\nomnidirectional mobility. This work presents two complementary spherical\nmapping systems: a lightweight, non-actuated design and an actuated variant\nfeaturing internal pendulum-driven locomotion. Both systems are equipped with a\nLivox Mid-360 solid-state LiDAR sensor and run LiDAR-Inertial Odometry (LIO)\nalgorithms on resource-constrained hardware. We assess the mapping accuracy of\nthese systems by comparing the resulting 3D point-clouds from the LIO\nalgorithms to a ground truth map. The results indicate that the performance of\nstate-of-the-art LIO algorithms deteriorates due to the high dynamic movement\nintroduced by the spherical locomotion, leading to globally inconsistent maps\nand sometimes unrecoverable drift.", "AI": {"tldr": "\u7403\u5f62\u673a\u5668\u4eba\u5728\u5371\u9669\u6216\u5c01\u95ed\u73af\u5883\u7684\u6d4b\u7ed8\u5e94\u7528\u4e2d\u5177\u6709\u4f18\u52bf\uff0c\u4f46\u5176\u8fd0\u52a8\u4ea7\u751f\u7684\u52a8\u6001\u6027\u4f1a\u5f71\u54cd\u6fc0\u5149\u96f7\u8fbe-\u60ef\u6027\u91cc\u7a0b\u8ba1\uff08LIO\uff09\u7b97\u6cd5\u7684\u6027\u80fd\uff0c\u5bfc\u81f4\u5168\u5c40\u5730\u56fe\u4e0d\u4e00\u81f4\u548c\u6f02\u79fb\u3002", "motivation": "\u8bc4\u4f30\u7403\u5f62\u6d4b\u7ed8\u7cfb\u7edf\u5728\u5371\u9669\u6216\u5c01\u95ed\u73af\u5883\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u5e76\u5206\u6790\u7403\u5f62\u8fd0\u52a8\u5bf9LIO\u7b97\u6cd5\u6027\u80fd\u7684\u5f71\u54cd\u3002", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u975e\u9a71\u52a8\u5f0f\u548c\u4e00\u4e2a\u9a71\u52a8\u5f0f\u7403\u5f62\u673a\u5668\u4eba\u7cfb\u7edf\uff0c\u5747\u914d\u5907Livox Mid-360\u6fc0\u5149\u96f7\u8fbe\u4f20\u611f\u5668\uff0c\u5e76\u5728\u8d44\u6e90\u53d7\u9650\u7684\u786c\u4ef6\u4e0a\u8fd0\u884cLIO\u7b97\u6cd5\u3002\u901a\u8fc7\u5c06LIO\u751f\u6210\u76843D\u70b9\u4e91\u4e0e\u5730\u9762\u771f\u5b9e\u5730\u56fe\u8fdb\u884c\u6bd4\u8f83\u6765\u8bc4\u4f30\u6d4b\u7ed8\u7cbe\u5ea6\u3002", "result": "\u7403\u5f62\u8fd0\u52a8\u5f15\u5165\u7684\u9ad8\u52a8\u6001\u6027\u5bfc\u81f4\u4e86\u6700\u5148\u8fdb\u7684LIO\u7b97\u6cd5\u6027\u80fd\u4e0b\u964d\uff0c\u751f\u6210\u4e86\u5168\u5c40\u4e0d\u4e00\u81f4\u7684\u5730\u56fe\uff0c\u5e76\u51fa\u73b0\u4e86\u6709\u65f6\u65e0\u6cd5\u6062\u590d\u7684\u6f02\u79fb\u3002", "conclusion": "\u7403\u5f62\u673a\u5668\u4eba\u7684\u8fd0\u52a8\u52a8\u6001\u6027\u5bf9LIO\u7b97\u6cd5\u7684\u6027\u80fd\u6784\u6210\u4e86\u6311\u6218\uff0c\u5f71\u54cd\u4e86\u6d4b\u7ed8\u7684\u5168\u5c40\u4e00\u81f4\u6027\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u4ee5\u514b\u670d\u8fd9\u4e9b\u9650\u5236\u3002"}}
{"id": "2509.09896", "categories": ["quant-ph", "cs.CC", "cs.CR"], "pdf": "https://arxiv.org/pdf/2509.09896", "abs": "https://arxiv.org/abs/2509.09896", "authors": ["Alexandru Cojocaru", "Juan Garay", "Qipeng Liu", "Fang Song"], "title": "Improved Quantum Lifting by Coherent Measure-and-Reprogram", "comment": "25 pages", "summary": "We give a tighter lifting theorem for security games in the quantum random\noracle model. At the core of our main result lies a novel measure-and-reprogram\nframework that we call coherent reprogramming. This framework gives a tighter\nlifting theorem for query complexity problems, that only requires purely\nclassical reasoning. As direct applications of our lifting theorem, we first\nprovide a quantum direct product theorem in the average case - i.e., an\nenabling tool to determine the hardness of solving multi-instance security\ngames. This allows us to derive in a straightforward manner the hardness of\nvarious security games, for example (i) the non-uniform hardness of salted\ngames, (ii) the hardness of specific cryptographic tasks such as the multiple\ninstance version of one-wayness and collision-resistance, and (iii) uniform or\nnon-uniform hardness of many other games.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5728\u91cf\u5b50\u968f\u673a\u9884\u8a00\u6a21\u578b\u4e0b\uff0c\u4e3a\u5b89\u5168\u535a\u5f08\u63d0\u4f9b\u4e86\u66f4\u7cbe\u786e\u7684\u63d0\u5347\u5b9a\u7406\uff0c\u5e76\u5f15\u5165\u4e86\u76f8\u5e72\u91cd\u6784\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u4ec5\u9700\u7ecf\u5178\u63a8\u7406\u5373\u53ef\u5b9e\u73b0\u66f4\u4f18\u7684\u63d0\u5347\u5b9a\u7406\uff0c\u5e76\u53ef\u7528\u4e8e\u89e3\u51b3\u591a\u5b9e\u4f8b\u5b89\u5168\u535a\u5f08\u7684\u786c\u5ea6\u95ee\u9898\u3002", "motivation": "\u5728\u91cf\u5b50\u968f\u673a\u9884\u8a00\u6a21\u578b\u4e0b\uff0c\u4e3a\u5b89\u5168\u535a\u5f08\u63d0\u4f9b\u66f4\u7cbe\u786e\u7684\u63d0\u5347\u5b9a\u7406\uff0c\u5e76\u5f15\u5165\u4e00\u79cd\u65b0\u7684\u76f8\u5e72\u91cd\u6784\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u76f8\u5e72\u91cd\u6784\u6846\u67b6\uff0c\u5e76\u57fa\u4e8e\u6b64\u6846\u67b6\u63a8\u5bfc\u51fa\u91cf\u5b50\u76f4\u63a5\u79ef\u5b9a\u7406\uff08\u5e73\u5747\u60c5\u51b5\uff09\uff0c\u8fdb\u800c\u5e94\u7528\u4e8e\u89e3\u51b3\u591a\u79cd\u5b89\u5168\u535a\u5f08\u7684\u786c\u5ea6\u95ee\u9898\u3002", "result": "\u63a8\u5bfc\u51fa\u4e86\u91cf\u5b50\u76f4\u63a5\u79ef\u5b9a\u7406\uff08\u5e73\u5747\u60c5\u51b5\uff09\uff0c\u5e76\u8bc1\u660e\u4e86\u591a\u79cd\u5b89\u5168\u535a\u5f08\uff08\u5982\u76d0\u503c\u535a\u5f08\u3001\u5355\u5411\u6027\u548c\u6297\u78b0\u649e\u6027\u7b49\u5bc6\u7801\u5b66\u4efb\u52a1\u7684\u591a\u5b9e\u4f8b\u7248\u672c\uff09\u7684\uff08\u975e\u5747\u5300\uff09\u786c\u5ea6\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u7684\u76f8\u5e72\u91cd\u6784\u6846\u67b6\u548c\u63d0\u5347\u5b9a\u7406\u53ef\u4ee5\u6709\u6548\u5730\u89e3\u51b3\u591a\u5b9e\u4f8b\u5b89\u5168\u535a\u5f08\u7684\u786c\u5ea6\u95ee\u9898\uff0c\u5e76\u4e3a\u76f8\u5173\u5bc6\u7801\u5b66\u4efb\u52a1\u7684\u5b89\u5168\u6027\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u7684\u5de5\u5177\u3002"}}
{"id": "2509.10281", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.10281", "abs": "https://arxiv.org/abs/2509.10281", "authors": ["Sudeepini Darapu", "Subrata Ghosh", "Dibakar Ghosh", "Chittaranjan Hens", "Santosh Nannuru"], "title": "Real-time identification and control of influential pandemic regions using graph signal variation", "comment": "12 pages, 13 figures", "summary": "The global spread of pandemics is facilitated by the mobility of populations,\ntransforming localized infections into widespread phenomena. To contain it,\ntimely identification of influential regions that accelerate this process is\nnecessary. In this work, we model infection as a temporally evolving graph\nsignal and propose graph signal variation-based metrics to capture\nspatio-temporal changes. Both graph domain and time domain locality are\nmodeled. Based on this metric, we propose an online algorithm to identify\ninfluential regions. Simulations demonstrate that the proposed method\neffectively identifies geographical regions with a higher capacity to spread\nthe infection. Isolating these regions leads to a significant reduction in\ncumulative infection. Simulations, along with analyses of hybrid H1N1 data and\nreal-world Indian COVID-19 data, underscore the utility of proposed metric in\nenhancing our understanding and control of infection spread", "AI": {"tldr": "\u901a\u8fc7\u56fe\u4fe1\u53f7\u53d8\u5316\u68c0\u6d4b\u75ab\u60c5\u4f20\u64ad\u4e2d\u7684\u5173\u952e\u5730\u533a\u3002", "motivation": "\u4e3a\u4e86\u6709\u6548\u904f\u5236\u75ab\u60c5\u7684\u5168\u7403\u4f20\u64ad\uff0c\u9700\u8981\u53ca\u65f6\u8bc6\u522b\u51fa\u80fd\u591f\u52a0\u901f\u75ab\u60c5\u6269\u6563\u7684\u533a\u57df\u3002", "method": "\u5c06\u75ab\u60c5\u4f20\u64ad\u5efa\u6a21\u4e3a\u65f6\u53d8\u56fe\u4fe1\u53f7\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u56fe\u4fe1\u53f7\u53d8\u5316\u7684\u5ea6\u91cf\u65b9\u6cd5\u6765\u6355\u6349\u65f6\u7a7a\u53d8\u5316\uff0c\u540c\u65f6\u8003\u8651\u56fe\u57df\u548c\u65f6\u57df\u7684\u5c40\u90e8\u6027\uff0c\u5e76\u57fa\u4e8e\u6b64\u5ea6\u91cf\u63d0\u51fa\u5728\u7ebf\u7b97\u6cd5\u6765\u8bc6\u522b\u5173\u952e\u533a\u57df\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u8bc6\u522b\u51fa\u5177\u6709\u66f4\u9ad8\u611f\u67d3\u4f20\u64ad\u80fd\u529b\u7684\u5730\u7406\u533a\u57df\uff0c\u5e76\u4e14\u9694\u79bb\u8fd9\u4e9b\u533a\u57df\u80fd\u663e\u8457\u964d\u4f4e\u7d2f\u79ef\u611f\u67d3\u91cf\u3002\u5bf9\u6df7\u5408H1N1\u6570\u636e\u548c\u771f\u5b9e\u4e16\u754c\u5370\u5ea6COVID-19\u6570\u636e\u7684\u5206\u6790\u4e5f\u8bc1\u5b9e\u4e86\u8be5\u5ea6\u91cf\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u56fe\u4fe1\u53f7\u53d8\u5316\u7684\u5ea6\u91cf\u65b9\u6cd5\u548c\u5728\u7ebf\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u8bc6\u522b\u5173\u952e\u4f20\u64ad\u533a\u57df\uff0c\u4e3a\u7406\u89e3\u548c\u63a7\u5236\u75ab\u60c5\u4f20\u64ad\u63d0\u4f9b\u4e86\u6709\u529b\u7684\u5de5\u5177\u3002"}}
{"id": "2509.10192", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2509.10192", "abs": "https://arxiv.org/abs/2509.10192", "authors": ["Raveena Gupta", "Joao Abreu", "Matthieu J. Verstraete"], "title": "Spectroscopy and transport of nonpolarons in silicon and germanium: the influence of doping and temperature", "comment": null, "summary": "We perform a first-principles investigation of electron-phonon interactions\nin silicon and germanium, uncovering distinct non-polaronic spectral and\ntransport fingerprints in these archetypal covalent semiconductors. Using\nmany-body perturbation theory with the retarded cumulant expansion, we compute\nquasiparticle energies, lifetimes, and phonon satellites beyond the\nDyson-Migdal approximation. Short-range crystal fields dominate coupling in\nboth materials, yet their low-temperature spectral fingerprints differ: Si\nexhibits well-resolved satellites at both band edges, whereas Ge displays\nstrong sidebands mainly at the valence band maximum (VBM) and much weaker\nfeatures at the conduction band minimum (CBM). Phonon-induced satellites in\nboth materials broaden and merge with the quasiparticle peak at elevated\ntemperatures. Doping broadens peaks and compresses satellite-quasiparticle\nseparation, with n-type carriers affecting the CBM and p-type the VBM. Mobility\ncalculations, combining cumulant-derived phonon scattering with experimentally\nmotivated ionized-impurity scattering models, reproduce measured trends and\nreveal Ge's consistently higher mobilities than Si, stemming from lighter\neffective masses and weaker coupling. These results link band-edge asymmetries\nand phonon energetics to measurable transport differences, providing a unified\nframework for predicting mobility in nonpolar semiconductors.", "AI": {"tldr": "\u7845\u548c\u9517\u7684\u7535\u5b50-\u58f0\u5b50\u76f8\u4e92\u4f5c\u7528\u7814\u7a76\u8868\u660e\uff0c\u5b83\u4eec\u5177\u6709\u4e0d\u540c\u7684\u975e\u6781\u6027\u8c31\u548c\u8f93\u8fd0\u7279\u5f81\u3002", "motivation": "\u7814\u7a76\u7845\u548c\u9517\u4e2d\u7535\u5b50-\u58f0\u5b50\u76f8\u4e92\u4f5c\u7528\u7684\u72ec\u7279\u4e4b\u5904\uff0c\u5e76\u63d0\u4f9b\u4e00\u4e2a\u9884\u6d4b\u975e\u6781\u6027\u534a\u5bfc\u4f53\u8fc1\u79fb\u7387\u7684\u7edf\u4e00\u6846\u67b6\u3002", "method": "\u5229\u7528\u5305\u542b\u63a8\u8fdf\u7d2f\u79ef\u5c55\u5f00\u7684\u591a\u4f53\u5fae\u6270\u7406\u8bba\uff0c\u8ba1\u7b97\u51c6\u7c92\u5b50\u80fd\u91cf\u3001\u5bff\u547d\u548c\u58f0\u5b50\u536b\u661f\uff0c\u8d85\u8d8a\u4e86Dyson-Migdal\u8fd1\u4f3c\u3002", "result": "\u7845\u548c\u9517\u5728\u4f4e\u6e29\u4e0b\u8868\u73b0\u51fa\u4e0d\u540c\u7684\u8c31\u5b66\u7279\u5f81\uff0c\u58f0\u5b50\u8bf1\u5bfc\u7684\u536b\u661f\u5728\u9ad8\u6e29\u4e0b\u4f1a\u53d8\u5bbd\u5e76\u5408\u5e76\u3002\u63ba\u6742\u4f1a\u5f71\u54cd\u5cf0\u7684\u5bbd\u5ea6\u548c\u536b\u661f-\u51c6\u7c92\u5b50\u7684\u5206\u79bb\u5ea6\u3002\u8ba1\u7b97\u51fa\u7684\u8fc1\u79fb\u7387\u4e0e\u5b9e\u9a8c\u6d4b\u91cf\u7ed3\u679c\u4e00\u81f4\uff0c\u5e76\u63ed\u793a\u4e86\u9517\u7684\u8fc1\u79fb\u7387\u666e\u904d\u9ad8\u4e8e\u7845\u3002", "conclusion": "\u5e26\u8fb9\u4e0d\u5bf9\u79f0\u548c\u58f0\u5b50\u80fd\u91cf\u5b66\u4e0e\u53ef\u6d4b\u91cf\u7684\u8f93\u8fd0\u5dee\u5f02\u76f8\u5173\u8054\uff0c\u4e3a\u9884\u6d4b\u975e\u6781\u6027\u534a\u5bfc\u4f53\u7684\u8fc1\u79fb\u7387\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\u3002"}}
{"id": "2509.09709", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09709", "abs": "https://arxiv.org/abs/2509.09709", "authors": ["Jing Ren", "Weiqi Wang"], "title": "Assisting Research Proposal Writing with Large Language Models: Evaluation and Refinement", "comment": null, "summary": "Large language models (LLMs) like ChatGPT are increasingly used in academic\nwriting, yet issues such as incorrect or fabricated references raise ethical\nconcerns. Moreover, current content quality evaluations often rely on\nsubjective human judgment, which is labor-intensive and lacks objectivity,\npotentially compromising the consistency and reliability. In this study, to\nprovide a quantitative evaluation and enhance research proposal writing\ncapabilities of LLMs, we propose two key evaluation metrics--content quality\nand reference validity--and an iterative prompting method based on the scores\nderived from these two metrics. Our extensive experiments show that the\nproposed metrics provide an objective, quantitative framework for assessing\nChatGPT's writing performance. Additionally, iterative prompting significantly\nenhances content quality while reducing reference inaccuracies and\nfabrications, addressing critical ethical challenges in academic contexts.", "AI": {"tldr": "LLMs\u5728\u5b66\u672f\u5199\u4f5c\u4e2d\u5b58\u5728\u5f15\u7528\u4e0d\u5f53\u7b49\u95ee\u9898\uff0c\u672c\u7814\u7a76\u63d0\u51fa\u5185\u5bb9\u8d28\u91cf\u548c\u5f15\u7528\u6709\u6548\u6027\u4e24\u4e2a\u91cf\u5316\u8bc4\u4f30\u6307\u6807\uff0c\u5e76\u7ed3\u5408\u8fed\u4ee3\u63d0\u793a\u65b9\u6cd5\uff0c\u4ee5\u63d0\u9ad8LLM\u7684\u5199\u4f5c\u80fd\u529b\u548c\u5b66\u672f\u8bda\u4fe1\u3002", "motivation": "\u5f53\u524dLLM\u5728\u5b66\u672f\u5199\u4f5c\u4e2d\u5b58\u5728\u5f15\u7528\u4e0d\u51c6\u786e\u6216\u634f\u9020\u7684\u95ee\u9898\uff0c\u4e14\u5185\u5bb9\u8d28\u91cf\u8bc4\u4f30\u4f9d\u8d56\u4e3b\u89c2\u7684\u4eba\u5de5\u5224\u65ad\uff0c\u7f3a\u4e4f\u5ba2\u89c2\u6027\u548c\u4e00\u81f4\u6027\u3002\u672c\u7814\u7a76\u65e8\u5728\u4e3aLLM\u63d0\u4f9b\u91cf\u5316\u8bc4\u4f30\uff0c\u5e76\u63d0\u5347\u5176\u7814\u7a76\u63d0\u6848\u5199\u4f5c\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u5185\u5bb9\u8d28\u91cf\u548c\u5f15\u7528\u6709\u6548\u6027\u4e24\u4e2a\u6838\u5fc3\u8bc4\u4f30\u6307\u6807\uff0c\u5e76\u57fa\u4e8e\u8fd9\u4e24\u4e2a\u6307\u6807\u7684\u5206\u6570\u8bbe\u8ba1\u4e86\u4e00\u79cd\u8fed\u4ee3\u63d0\u793a\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u6307\u6807\u4e3a\u8bc4\u4f30LLM\u5199\u4f5c\u8868\u73b0\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5ba2\u89c2\u3001\u91cf\u5316\u7684\u6846\u67b6\u3002\u8fed\u4ee3\u63d0\u793a\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u5185\u5bb9\u8d28\u91cf\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u5f15\u7528\u7684\u4e0d\u51c6\u786e\u6027\u548c\u634f\u9020\u73b0\u8c61\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u91cf\u5316\u8bc4\u4f30\u6307\u6807\u548c\u8fed\u4ee3\u63d0\u793a\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3LLM\u5728\u5b66\u672f\u5199\u4f5c\u4e2d\u9762\u4e34\u7684\u5f15\u7528\u95ee\u9898\u548c\u63d0\u9ad8\u5185\u5bb9\u8d28\u91cf\uff0c\u5e94\u5bf9\u4e86\u5b66\u672f\u9886\u57df\u4e2d\u7684\u5173\u952e\u4f26\u7406\u6311\u6218\u3002"}}
{"id": "2509.09838", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09838", "abs": "https://arxiv.org/abs/2509.09838", "authors": ["Reza Asad", "Reza Babanezhad", "Sharan Vaswani"], "title": "Revisiting Actor-Critic Methods in Discrete Action Off-Policy Reinforcement Learning", "comment": null, "summary": "Value-based approaches such as DQN are the default methods for off-policy\nreinforcement learning with discrete-action environments such as Atari. Common\npolicy-based methods are either on-policy and do not effectively learn from\noff-policy data (e.g. PPO), or have poor empirical performance in the\ndiscrete-action setting (e.g. SAC). Consequently, starting from discrete SAC\n(DSAC), we revisit the design of actor-critic methods in this setting. First,\nwe determine that the coupling between the actor and critic entropy is the\nprimary reason behind the poor performance of DSAC. We demonstrate that by\nmerely decoupling these components, DSAC can have comparable performance as\nDQN. Motivated by this insight, we introduce a flexible off-policy actor-critic\nframework that subsumes DSAC as a special case. Our framework allows using an\nm-step Bellman operator for the critic update, and enables combining standard\npolicy optimization methods with entropy regularization to instantiate the\nresulting actor objective. Theoretically, we prove that the proposed methods\ncan guarantee convergence to the optimal regularized value function in the\ntabular setting. Empirically, we demonstrate that these methods can approach\nthe performance of DQN on standard Atari games, and do so even without entropy\nregularization or explicit exploration.", "AI": {"tldr": "DSAC\u7684actor\u548ccritic\u71b5\u8026\u5408\u5bfc\u81f4\u6027\u80fd\u4e0d\u4f73\uff0c\u89e3\u8026\u540e\u6027\u80fd\u53ef\u4e0eDQN\u5ab2\u7f8e\u3002\u63d0\u51fa\u7684\u65b0\u6846\u67b6\u5141\u8bb8\u4f7f\u7528m\u6b65\u8d1d\u5c14\u66fc\u7b97\u5b50\u548c\u7b56\u7565\u4f18\u5316\u65b9\u6cd5\uff0c\u7406\u8bba\u4e0a\u4fdd\u8bc1\u6536\u655b\uff0c\u7ecf\u9a8c\u4e0a\u5728Atari\u6e38\u620f\u4e0a\u8868\u73b0\u63a5\u8fd1DQN\u3002", "motivation": "DSAC\u7684actor\u548ccritic\u71b5\u8026\u5408\u662f\u5176\u5728\u79bb\u6563\u52a8\u4f5c\u73af\u5883\u4e2d\u6027\u80fd\u4e0d\u4f73\u7684\u4e3b\u8981\u539f\u56e0\u3002", "method": "\u89e3\u8026DSAC\u7684actor\u548ccritic\u71b5\uff0c\u63d0\u51fa\u4e00\u4e2a\u7075\u6d3b\u7684\u3001\u53ef\u652f\u6301m\u6b65\u8d1d\u5c14\u66fc\u7b97\u5b50\u548c\u7b56\u7565\u4f18\u5316\u65b9\u6cd5\u7684\u79bb\u7ebfactor-critic\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5305\u542bDSAC\u4f5c\u4e3a\u7279\u4f8b\u3002", "result": "\u89e3\u8026\u540e\u7684DSAC\u6027\u80fd\u53ef\u4e0eDQN\u5ab2\u7f8e\uff1b\u65b0\u6846\u67b6\u5728Atari\u6e38\u620f\u4e0a\u8868\u73b0\u63a5\u8fd1DQN\uff0c\u5373\u4f7f\u6ca1\u6709\u71b5\u6b63\u5219\u5316\u6216\u663e\u5f0f\u63a2\u7d22\u3002", "conclusion": "\u63d0\u51fa\u7684\u79bb\u7ebfactor-critic\u6846\u67b6\u901a\u8fc7\u89e3\u8026actor\u548ccritic\u71b5\u3001\u5f15\u5165m\u6b65\u8d1d\u5c14\u66fc\u7b97\u5b50\u548c\u7b56\u7565\u4f18\u5316\u7b49\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86DSAC\u5728\u79bb\u6563\u52a8\u4f5c\u73af\u5883\u4e2d\u7684\u6027\u80fd\u95ee\u9898\uff0c\u5e76\u5728\u7406\u8bba\u548c\u7ecf\u9a8c\u4e0a\u90fd\u5f97\u5230\u4e86\u9a8c\u8bc1\u3002"}}
{"id": "2509.09919", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09919", "abs": "https://arxiv.org/abs/2509.09919", "authors": ["Franklin Yiu", "Mohan Lu", "Nina Li", "Kevin Joseph", "Tianxu Zhang", "Julian Togelius", "Timothy Merino", "Sam Earle"], "title": "A Markovian Framing of WaveFunctionCollapse for Procedurally Generating Aesthetically Complex Environments", "comment": null, "summary": "Procedural content generation often requires satisfying both\ndesigner-specified objectives and adjacency constraints implicitly imposed by\nthe underlying tile set. To address the challenges of jointly optimizing both\nconstraints and objectives, we reformulate WaveFunctionCollapse (WFC) as a\nMarkov Decision Process (MDP), enabling external optimization algorithms to\nfocus exclusively on objective maximization while leveraging WFC's propagation\nmechanism to enforce constraint satisfaction. We empirically compare optimizing\nthis MDP to traditional evolutionary approaches that jointly optimize global\nmetrics and local tile placement. Across multiple domains with various\ndifficulties, we find that joint optimization not only struggles as task\ncomplexity increases, but consistently underperforms relative to optimization\nover the WFC-MDP, underscoring the advantages of decoupling local constraint\nsatisfaction from global objective optimization.", "AI": {"tldr": "\u5c06WaveFunctionCollapse (WFC)\u91cd\u6784\u4e3a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b(MDP)\uff0c\u4ee5\u4fbf\u5728\u6ee1\u8db3\u8bbe\u8ba1\u8005\u6307\u5b9a\u7684\u7ea6\u675f\u548c\u76ee\u6807\u7684\u540c\u65f6\uff0c\u901a\u8fc7\u5916\u90e8\u4f18\u5316\u7b97\u6cd5\u8fdb\u884c\u4f18\u5316\uff0c\u5e76\u5728\u591a\u4e2a\u9886\u57df\u548c\u4e0d\u540c\u96be\u5ea6\u4e0b\uff0c\u4e0e\u4f20\u7edf\u7684\u8054\u5408\u4f18\u5316\u8fdb\u5316\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5728\u5404\u79cd\u4efb\u52a1\u590d\u6742\u6027\u4e0b\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u6027\u80fd\u3002", "motivation": "\u7a0b\u5e8f\u5316\u5185\u5bb9\u751f\u6210\u9700\u8981\u540c\u65f6\u6ee1\u8db3\u8bbe\u8ba1\u8005\u6307\u5b9a\u7684{-# objetivos #-}\u548c{-# \u9690\u5f0f\u7ea6\u675f #-}\uff0c\u800c\u8054\u5408\u4f18\u5316\u8fd9\u4e24\u8005\u9762\u4e34\u6311\u6218\u3002", "method": "\u5c06WaveFunctionCollapse (WFC)\u91cd\u6784\u4e3a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b(MDP)\uff0c\u4f7f\u5916\u90e8\u4f18\u5316\u7b97\u6cd5\u80fd\u591f\u4e13\u6ce8\u4e8e\u6700\u5927\u5316{-# \u76ee\u6807 #-}\uff0c\u540c\u65f6\u5229\u7528WFC\u7684{-# \u4f20\u64ad\u673a\u5236 #-}\u6765\u5f3a\u5236\u6267\u884c{-# \u7ea6\u675f #-]\u3002\u5c06\u6b64MDP\u7684\u4f18\u5316\u4e0e\u4f20\u7edf\u7684\u8054\u5408\u4f18\u5316{-# \u5168\u5c40\u6307\u6807 #-]\u548c{-# \u5c40\u90e8\u56fe\u5757\u653e\u7f6e #-]\u7684\u8fdb\u5316\u65b9\u6cd5\u8fdb\u884c\u7ecf\u9a8c\u6bd4\u8f83\u3002", "result": "\u4e0e\u4f20\u7edf\u7684\u8054\u5408\u4f18\u5316\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5728\u591a\u4e2a\u9886\u57df\u548c\u4e0d\u540c\u96be\u5ea6\u4e0b\uff0c\u8054\u5408\u4f18\u5316\u5728\u4efb\u52a1\u590d\u6742\u5ea6\u589e\u52a0\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u5e76\u4e14\u6301\u7eed\u8868\u73b0\u4e0d\u5982\u4f18\u5316WFC-MDP\u3002", "conclusion": "\u5c06\u5c40\u90e8{-# \u7ea6\u675f #-]\u6ee1\u8db3\u4e0e\u5168\u5c40{-# \u76ee\u6807 #-}\u4f18\u5316\u5206\u79bb\uff0c\u5177\u6709\u660e\u663e\u4f18\u52bf\u3002"}}
{"id": "2509.10055", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.10055", "abs": "https://arxiv.org/abs/2509.10055", "authors": ["Xicheng Wang", "Yun. Feng", "Dmitry Grishchenko", "Pavel Kudinov", "Ruifeng Tian", "Sichao Tan"], "title": "Data-driven optimization of sparse sensor placement in thermal hydraulic experiments", "comment": null, "summary": "Thermal-Hydraulic (TH) experiments provide valuable insight into the physics\nof heat and mass transfer and qualified data for code development, calibration\nand validation. However, measurements are typically collected from sparsely\ndistributed sensors, offering limited coverage over the domain of interest and\nphenomena of interest. Determination of the spatial configuration of these\nsensors is crucial and challenging during the pre-test design stage. This paper\ndevelops a data-driven framework for optimizing sensor placement in TH\nexperiments, including (i) a sensitivity analysis to construct datasets, (ii)\nProper Orthogonal Decomposition (POD) for dimensionality reduction, and (iii)\nQR factorization with column pivoting to determine optimal sensor configuration\nunder spatial constraints. The framework is demonstrated on a test conducted in\nthe TALL-3D Lead-bismuth eutectic (LBE) loop. In this case, the utilization of\noptical techniques, such as Particle Image Velocimetry (PIV), are impractical.\nThereby the quantification of momentum and energy transport relies heavily on\nreadings from Thermocouples (TCs). The test section was previously instrumented\nwith many TCs determined through a manual process combining simulation results\nwith expert judgement. The proposed framework provides a systematic and\nautomated approach for sensor placement. The resulting TCs exhibit high\nsensitivity to the variation of uncertain input parameters and enable accurate\nfull field reconstruction while maintaining robustness against measurement\nnoise.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6570\u636e\u9a71\u52a8\u6846\u67b6\uff0c\u7528\u4e8e\u4f18\u5316\u70ed\u5de5\u6c34\u529b\u5b66\uff08TH\uff09\u5b9e\u9a8c\u4e2d\u7684\u4f20\u611f\u5668\u5e03\u5c40\uff0c\u4ee5\u63d0\u9ad8\u6570\u636e\u8986\u76d6\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u4f20\u7edf\u7684TH\u5b9e\u9a8c\u4f20\u611f\u5668\u6570\u636e\u8986\u76d6\u6709\u9650\uff0c\u624b\u52a8\u786e\u5b9a\u4f20\u611f\u5668\u4f4d\u7f6e\u5177\u6709\u6311\u6218\u6027\u3002\u9700\u8981\u4e00\u79cd\u7cfb\u7edf\u5316\u7684\u65b9\u6cd5\u6765\u4f18\u5316\u4f20\u611f\u5668\u5e03\u5c40\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5305\u542b\u654f\u611f\u6027\u5206\u6790\u3001 Proper Orthogonal Decomposition (POD) \u548c QR \u5206\u89e3\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u4f18\u5316\u4f20\u611f\u5668\u5e03\u5c40\u3002", "result": "\u8be5\u6846\u67b6\u5728TALL-3D\u94c5\u94cb\uff08LBE\uff09\u56de\u8def\u5b9e\u9a8c\u4e2d\u5f97\u5230\u9a8c\u8bc1\uff0c\u4f18\u5316\u7684\u70ed\u7535\u5076\uff08TC\uff09\u5e03\u5c40\u80fd\u7075\u654f\u5730\u54cd\u5e94\u4e0d\u786e\u5b9a\u8f93\u5165\u53c2\u6570\u7684\u53d8\u5316\uff0c\u5e76\u80fd\u51c6\u786e\u5730\u91cd\u5efa\u5168\u573a\u4fe1\u606f\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u6d4b\u91cf\u566a\u58f0\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6846\u67b6\u4e3aTH\u5b9e\u9a8c\u7684\u4f20\u611f\u5668\u5e03\u5c40\u63d0\u4f9b\u4e86\u4e00\u79cd\u7cfb\u7edf\u5316\u548c\u81ea\u52a8\u5316\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u5f97\u5230\u66f4\u4f18\u7684\u4f20\u611f\u5668\u914d\u7f6e\uff0c\u4ee5\u83b7\u5f97\u66f4\u53ef\u9760\u7684\u5b9e\u9a8c\u6570\u636e\u3002"}}
{"id": "2509.09785", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.09785", "abs": "https://arxiv.org/abs/2509.09785", "authors": ["Moslem Yazdanpanah", "Ali Bahri", "Mehrdad Noori", "Sahar Dastani", "Gustavo Adolfo Vargas Hakim", "David Osowiechi", "Ismail Ben Ayed", "Christian Desrosiers"], "title": "Purge-Gate: Backpropagation-Free Test-Time Adaptation for Point Clouds Classification via Token Purging", "comment": null, "summary": "Test-time adaptation (TTA) is crucial for mitigating performance degradation\ncaused by distribution shifts in 3D point cloud classification. In this work,\nwe introduce Token Purging (PG), a novel backpropagation-free approach that\nremoves tokens highly affected by domain shifts before they reach attention\nlayers. Unlike existing TTA methods, PG operates at the token level, ensuring\nrobust adaptation without iterative updates. We propose two variants: PG-SP,\nwhich leverages source statistics, and PG-SF, a fully source-free version\nrelying on CLS-token-driven adaptation. Extensive evaluations on ModelNet40-C,\nShapeNet-C, and ScanObjectNN-C demonstrate that PG-SP achieves an average of\n+10.3\\% higher accuracy than state-of-the-art backpropagation-free methods,\nwhile PG-SF sets new benchmarks for source-free adaptation. Moreover, PG is\n12.4 times faster and 5.5 times more memory efficient than our baseline, making\nit suitable for real-world deployment. Code is available at\n\\hyperlink{https://github.com/MosyMosy/Purge-Gate}{https://github.com/MosyMosy/Purge-Gate}", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aToken Purging (PG) \u7684\u65b0\u578b\u6d4b\u8bd5\u65f6\u95f4\u81ea\u9002\u5e94\uff08TTA\uff09\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b33D\u70b9\u4e91\u5206\u7c7b\u4e2d\u56e0\u5206\u5e03\u53d8\u5316\u5bfc\u81f4\u7684\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\u3002PG\u5728\u53cd\u5411\u4f20\u64ad\u4e4b\u524d\uff0c\u901a\u8fc7\u79fb\u9664\u53d7\u9886\u57df\u53d8\u5316\u5f71\u54cd\u8f83\u5927\u7684token\u6765\u5de5\u4f5c\uff0c\u5b9e\u73b0\u4e86\u65e0\u9700\u8fed\u4ee3\u66f4\u65b0\u7684\u9c81\u68d2\u81ea\u9002\u5e94\u3002", "motivation": "\u6d4b\u8bd5\u65f6\u95f4\u81ea\u9002\u5e94\uff08TTA\uff09\u5bf9\u4e8e\u51cf\u8f7b3D\u70b9\u4e91\u5206\u7c7b\u4e2d\u7531\u5206\u5e03\u53d8\u5316\u5f15\u8d77\u6027\u80fd\u4e0b\u964d\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aToken Purging (PG) \u7684\u65b0\u578b\u53cd\u5411\u4f20\u64ad\u5f0f\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5728token\u7ea7\u522b\u64cd\u4f5c\uff0c\u901a\u8fc7\u5728token\u5230\u8fbe\u6ce8\u610f\u529b\u5c42\u4e4b\u524d\u79fb\u9664\u53d7\u9886\u57df\u53d8\u5316\u5f71\u54cd\u8f83\u5927\u7684token\u6765\u5b9e\u73b0\u9c81\u68d2\u81ea\u9002\u5e94\uff0c\u65e0\u9700\u8fed\u4ee3\u66f4\u65b0\u3002\u63d0\u51fa\u4e86\u4e24\u79cd\u53d8\u4f53\uff1aPG-SP\uff08\u5229\u7528\u6e90\u57df\u7edf\u8ba1\uff09\u548cPG-SF\uff08\u5b8c\u5168\u65e0\u6e90\u57df\uff0c\u4f9d\u8d56CLS-token\u9a71\u52a8\u7684\u81ea\u9002\u5e94\uff09\u3002", "result": "\u5728ModelNet40-C\u3001ShapeNet-C\u548cScanObjectNN-C\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\uff0cPG-SP\u7684\u51c6\u786e\u7387\u6bd4\u6700\u5148\u8fdb\u7684\u53cd\u5411\u4f20\u64ad\u5f0f\u65b9\u6cd5\u5e73\u5747\u9ad8\u51fa+10.3%\uff0c\u800cPG-SF\u5728\u65e0\u6e90\u57df\u81ea\u9002\u5e94\u65b9\u9762\u8bbe\u5b9a\u4e86\u65b0\u7684\u57fa\u51c6\u3002\u6b64\u5916\uff0cPG\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u5feb12.4\u500d\uff0c\u5185\u5b58\u6548\u7387\u9ad85.5\u500d\u3002", "conclusion": "PG\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u6709\u6548\u7684TTA\u65b9\u6cd5\uff0c\u7279\u522b\u9002\u7528\u4e8e3D\u70b9\u4e91\u5206\u7c7b\uff0c\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u5728\u5b58\u5728\u5206\u5e03\u53d8\u5316\u65f6\u7684\u6a21\u578b\u6027\u80fd\uff0c\u5e76\u4e14\u975e\u5e38\u9002\u5408\u5b9e\u9645\u90e8\u7f72\u3002"}}
{"id": "2509.10309", "categories": ["cond-mat.mes-hall", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2509.10309", "abs": "https://arxiv.org/abs/2509.10309", "authors": ["Mark Potts", "Shu Zhang"], "title": "Spin-qubit Noise Spectroscopy of Magnetic Berezinskii-Kosterlitz-Thouless Physics", "comment": "5 pages, 3 figures", "summary": "We propose using spin-qubit noise magnetometry to probe dynamical signatures\nof magnetic Berezinskii-Kosterlitz-Thouless (BKT) physics. For a\nnitrogen-vacancy (NV) center coupled to two-dimensional XY magnets, we predict\ndistinctive features in the magnetic noise spectral density in the sub-MHz to\nGHz frequency range. In the quasi-long-range ordered phase, the spectrum\nexhibits a temperature-dependent power law characteristic of algebraic spin\ncorrelations. Above the transition, the noise reflects the proliferation of\nfree vortices and enables quantitative extraction of the vortex conductivity, a\nkey parameter of vortex transport. These results highlight NV as a powerful\nspectroscopic method to resolve magnetic dynamics in the mesoscopic and\nlow-frequency regimes and to probe exotic magnetic phase transitions.", "AI": {"tldr": "\u5229\u7528NV\u81ea\u65cb\u91cf\u5b50\u6bd4\u7279\u566a\u58f0\u78c1\u529b\u8ba1\u63a2\u6d4b\u78c1\u6027BKT\u7269\u7406\u7684\u52a8\u529b\u5b66\u7279\u5f81\uff0c\u9884\u6d4b\u5728MHz\u5230GHz\u9891\u7387\u8303\u56f4\u5185\u5177\u6709\u7279\u5f81\u6027\u7684\u78c1\u566a\u58f0\u8c31\u5bc6\u5ea6\u3002", "motivation": "\u63a2\u6d4b\u78c1\u6027Berezinskii-Kosterlitz-Thouless (BKT) \u7269\u7406\u7684\u52a8\u529b\u5b66\u7279\u5f81\u3002", "method": "\u5229\u7528NV\u81ea\u65cb\u91cf\u5b50\u6bd4\u7279\u566a\u58f0\u78c1\u529b\u8ba1\u3002", "result": "\u5728\u51c6\u957f\u7a0b\u6709\u5e8f\u76f8\u4e2d\uff0c\u8c31\u5bc6\u5ea6\u8868\u73b0\u51fa\u4e0e\u4ee3\u6570\u81ea\u65cb\u76f8\u5173\u6027\u76f8\u5173\u7684\u6e29\u5ea6\u4f9d\u8d56\u6027\u5e42\u5f8b\u3002\u5728\u76f8\u53d8\u4ee5\u4e0a\uff0c\u566a\u58f0\u53cd\u6620\u4e86\u81ea\u7531\u6da1\u65cb\u7684\u589e\u6b96\uff0c\u5e76\u80fd\u5b9a\u91cf\u63d0\u53d6\u6da1\u65cb\u7535\u5bfc\u7387\u3002", "conclusion": "NV\u81ea\u65cb\u91cf\u5b50\u6bd4\u7279\u662f\u89e3\u51b3\u4ecb\u89c2\u548c\u4f4e\u9891\u52a8\u529b\u5b66\u4ee5\u53ca\u63a2\u6d4b\u5947\u5f02\u78c1\u76f8\u53d8\u7684\u6709\u529b\u5149\u8c31\u65b9\u6cd5\u3002"}}
{"id": "2509.10063", "categories": ["cs.RO", "cs.AI", "I.2.9"], "pdf": "https://arxiv.org/pdf/2509.10063", "abs": "https://arxiv.org/abs/2509.10063", "authors": ["Xiyan Huang", "Zhe Xu", "Chenxi Xiao"], "title": "TwinTac: A Wide-Range, Highly Sensitive Tactile Sensor with Real-to-Sim Digital Twin Sensor Model", "comment": "7 pages, 9 figures, 1 table, to be published in IEEE/RSJ\n  International Conference on Intelligent Robots and Systems (IROS 2025)", "summary": "Robot skill acquisition processes driven by reinforcement learning often rely\non simulations to efficiently generate large-scale interaction data. However,\nthe absence of simulation models for tactile sensors has hindered the use of\ntactile sensing in such skill learning processes, limiting the development of\neffective policies driven by tactile perception. To bridge this gap, we present\nTwinTac, a system that combines the design of a physical tactile sensor with\nits digital twin model. Our hardware sensor is designed for high sensitivity\nand a wide measurement range, enabling high quality sensing data essential for\nobject interaction tasks. Building upon the hardware sensor, we develop the\ndigital twin model using a real-to-sim approach. This involves collecting\nsynchronized cross-domain data, including finite element method results and the\nphysical sensor's outputs, and then training neural networks to map simulated\ndata to real sensor responses. Through experimental evaluation, we\ncharacterized the sensitivity of the physical sensor and demonstrated the\nconsistency of the digital twin in replicating the physical sensor's output.\nFurthermore, by conducting an object classification task, we showed that\nsimulation data generated by our digital twin sensor can effectively augment\nreal-world data, leading to improved accuracy. These results highlight\nTwinTac's potential to bridge the gap in cross-domain learning tasks.", "AI": {"tldr": "TwinTac\u7cfb\u7edf\u7ed3\u5408\u4e86\u7269\u7406\u89e6\u89c9\u4f20\u611f\u5668\u53ca\u5176\u6570\u5b57\u5b6a\u751f\u6a21\u578b\uff0c\u901a\u8fc7\u771f\u5b9e\u5230\u6a21\u62df\u7684\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u673a\u5668\u4eba\u89e6\u89c9\u6280\u80fd\u5b66\u4e60\u4e2d\u7684\u6570\u636e\u751f\u6210\u95ee\u9898\uff0c\u5e76\u63d0\u9ad8\u4e86\u7269\u4f53\u5206\u7c7b\u4efb\u52a1\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u673a\u5668\u4eba\u5f3a\u5316\u5b66\u4e60\u6280\u80fd\u83b7\u53d6\u4f9d\u8d56\u6a21\u62df\u6570\u636e\uff0c\u4f46\u7f3a\u4e4f\u89e6\u89c9\u4f20\u611f\u5668\u6a21\u62df\uff0c\u9650\u5236\u4e86\u89e6\u89c9\u611f\u77e5\u7b56\u7565\u7684\u5f00\u53d1\u3002\u672c\u7814\u7a76\u65e8\u5728\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\u3002", "method": "\u63d0\u51faTwinTac\u7cfb\u7edf\uff0c\u7ed3\u5408\u4e86\u9ad8\u7075\u654f\u5ea6\u3001\u5bbd\u6d4b\u91cf\u8303\u56f4\u7684\u7269\u7406\u89e6\u89c9\u4f20\u611f\u5668\u53ca\u5176\u6570\u5b57\u5b6a\u751f\u6a21\u578b\u3002\u901a\u8fc7\u6536\u96c6\u6709\u9650\u5143\u65b9\u6cd5\u7ed3\u679c\u548c\u7269\u7406\u4f20\u611f\u5668\u8f93\u51fa\u7684\u540c\u6b65\u8de8\u57df\u6570\u636e\uff0c\u5229\u7528\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u771f\u5b9e\u5230\u6a21\u62df\u7684\u6620\u5c04\uff0c\u6784\u5efa\u6570\u5b57\u5b6a\u751f\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u4e86\u7269\u7406\u4f20\u611f\u5668\u7684\u7075\u654f\u5ea6\uff0c\u5e76\u9a8c\u8bc1\u4e86\u6570\u5b57\u5b6a\u751f\u6a21\u578b\u5728\u590d\u5236\u7269\u7406\u4f20\u611f\u5668\u8f93\u51fa\u65b9\u9762\u7684\u4e00\u81f4\u6027\u3002\u901a\u8fc7\u7269\u4f53\u5206\u7c7b\u4efb\u52a1\uff0c\u8868\u660e\u6570\u5b57\u5b6a\u751f\u4f20\u611f\u5668\u751f\u6210\u7684\u6a21\u62df\u6570\u636e\u80fd\u6709\u6548\u589e\u5f3a\u771f\u5b9e\u4e16\u754c\u6570\u636e\uff0c\u63d0\u9ad8\u51c6\u786e\u6027\u3002", "conclusion": "TwinTac\u7cfb\u7edf\u6709\u6f5c\u529b\u5f25\u5408\u8de8\u57df\u5b66\u4e60\u4efb\u52a1\u4e2d\u7684\u6570\u636e\u9e3f\u6c9f\uff0c\u4fc3\u8fdb\u673a\u5668\u4eba\u89e6\u89c9\u6280\u80fd\u7684\u5b66\u4e60\u548c\u5e94\u7528\u3002"}}
{"id": "2509.09900", "categories": ["quant-ph", "cs.CC", "cs.CR"], "pdf": "https://arxiv.org/pdf/2509.09900", "abs": "https://arxiv.org/abs/2509.09900", "authors": ["Alexandru Cojocaru", "Juan Garay", "Qipeng Liu", "Fang Song"], "title": "NISQ Security and Complexity via Simple Classical Reasoning", "comment": "38 pages", "summary": "We give novel lifting theorems for security games in the quantum random\noracle model (QROM) in Noisy Intermediate-Scale Quantum (NISQ) settings such as\nthe hybrid query model, the noisy oracle and the bounded-depth models. We\nprovide, for the first time, a hybrid lifting theorem for hybrid algorithms\nthat can perform both quantum and classical queries, as well as a lifting\ntheorem for quantum algorithms with access to noisy oracles or bounded quantum\ndepth.\n  At the core of our results lies a novel measure-and-reprogram framework,\ncalled hybrid coherent measure-and-reprogramming, tailored specifically for\nhybrid algorithms. Equipped with the lifting theorem, we are able to prove\ndirectly NISQ security and complexity results by calculating a single\ncombinatorial quantity, relying solely on classical reasoning.\n  As applications, we derive the first direct product theorems in the average\ncase, in the hybrid setting-i.e., an enabling tool to determine the hybrid\nhardness of solving multi-instance security games. This allows us to derive in\na straightforward manner the NISQ hardness of various security games, such as\n(i) the non-uniform hardness of salted games, (ii) the hardness of specific\ncryptographic tasks such as the multiple instance version of one-wayness and\ncollision-resistance, and (iii) uniform or non-uniform hardness of many other\ngames.", "AI": {"tldr": "\u672c\u6587\u5728\u91cf\u5b50\u968f\u673a\u9884\u8a00\u6a21\u578b(QROM)\u548c\u5608\u6742\u4e2d\u7b49\u89c4\u6a21\u91cf\u5b50(NISQ)\u8bbe\u7f6e\u4e0b\uff0c\u4e3a\u5b89\u5168\u535a\u5f08\u63d0\u4f9b\u4e86\u65b0\u7684\u63d0\u5347\u5b9a\u7406\uff0c\u5305\u62ec\u6df7\u5408\u67e5\u8be2\u6a21\u578b\u3001\u5608\u6742\u9884\u8a00\u548c\u6709\u754c\u6df1\u5ea6\u6a21\u578b\u3002\u9996\u6b21\u63d0\u51fa\u4e86\u6df7\u5408\u63d0\u5347\u5b9a\u7406\uff0c\u9002\u7528\u4e8e\u53ef\u6267\u884c\u91cf\u5b50\u548c\u7ecf\u5178\u67e5\u8be2\u7684\u6df7\u5408\u7b97\u6cd5\uff0c\u4ee5\u53ca\u9002\u7528\u4e8e\u5177\u6709\u5608\u6742\u9884\u8a00\u6216\u6709\u754c\u91cf\u5b50\u6df1\u5ea6\u7684\u91cf\u5b50\u7b97\u6cd5\u7684\u63d0\u5347\u5b9a\u7406\u3002\u6838\u5fc3\u662f\u4e00\u79cd\u65b0\u9896\u7684\u6d4b\u91cf-\u518d\u7f16\u7a0b\u6846\u67b6\uff0c\u79f0\u4e3a\u6df7\u5408\u76f8\u5e72\u6d4b\u91cf-\u518d\u7f16\u7a0b\uff0c\u4e13\u95e8\u9488\u5bf9\u6df7\u5408\u7b97\u6cd5\u3002\u5229\u7528\u63d0\u5347\u5b9a\u7406\uff0c\u53ef\u4ee5\u76f4\u63a5\u8bc1\u660eNISQ\u5b89\u5168\u6027\u548c\u590d\u6742\u5ea6\u7ed3\u679c\uff0c\u53ea\u9700\u8ba1\u7b97\u4e00\u4e2a\u7ec4\u5408\u91cf\uff0c\u4ec5\u4f9d\u8d56\u4e8e\u7ecf\u5178\u63a8\u7406\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u4e3a\u5b89\u5168\u535a\u5f08\u5728\u91cf\u5b50\u968f\u673a\u9884\u8a00\u6a21\u578b(QROM)\u548c\u5608\u6742\u4e2d\u7b49\u89c4\u6a21\u91cf\u5b50(NISQ)\u8bbe\u7f6e\u4e0b\u63d0\u4f9b\u65b0\u7684\u63d0\u5347\u5b9a\u7406\uff0c\u4ee5\u5e94\u5bf9\u6df7\u5408\u67e5\u8be2\u6a21\u578b\u3001\u5608\u6742\u9884\u8a00\u548c\u6709\u754c\u6df1\u5ea6\u7b49\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6d4b\u91cf-\u518d\u7f16\u7a0b\u6846\u67b6\uff0c\u79f0\u4e3a\u6df7\u5408\u76f8\u5e72\u6d4b\u91cf-\u518d\u7f16\u7a0b\uff0c\u7528\u4e8e\u6df7\u5408\u7b97\u6cd5\u3002\u5728\u6b64\u57fa\u7840\u4e0a\uff0c\u63a8\u5bfc\u4e86\u6df7\u5408\u63d0\u5347\u5b9a\u7406\u548c\u9002\u7528\u4e8e\u5608\u6742\u9884\u8a00\u6216\u6709\u754c\u91cf\u5b50\u6df1\u5ea6\u7684\u91cf\u5b50\u7b97\u6cd5\u7684\u63d0\u5347\u5b9a\u7406\u3002", "result": "1. \u9996\u6b21\u63d0\u51fa\u6df7\u5408\u63d0\u5347\u5b9a\u7406\uff0c\u9002\u7528\u4e8e\u6df7\u5408\u7b97\u6cd5\u3002 2. \u63d0\u51fa\u9002\u7528\u4e8e\u5608\u6742\u9884\u8a00\u6216\u6709\u754c\u91cf\u5b50\u6df1\u5ea6\u7684\u91cf\u5b50\u7b97\u6cd5\u7684\u63d0\u5347\u5b9a\u7406\u3002 3. \u8bc1\u660e\u4e86\u6df7\u5408\u8bbe\u7f6e\u4e0b\u7684\u9996\u4e2a\u5e73\u5747\u60c5\u51b5\u76f4\u63a5\u79ef\u5b9a\u7406\u3002 4. \u7b80\u660e\u5730\u63a8\u5bfc\u4e86\u5404\u79cd\u535a\u5f08\u7684NISQ\u590d\u6742\u5ea6\uff0c\u5305\u62ec\u76d0\u5316\u535a\u5f08\u7684\u975e\u5747\u5300\u590d\u6742\u5ea6\u3001\u5355\u5411\u6027\u548c\u78b0\u649e\u6297\u6027\u7b49\u5bc6\u7801\u4efb\u52a1\u7684\u590d\u6742\u5ea6\u3002", "conclusion": "\u672c\u7814\u7a76\u901a\u8fc7\u65b0\u9896\u7684\u6df7\u5408\u76f8\u5e72\u6d4b\u91cf-\u518d\u7f16\u7a0b\u6846\u67b6\u548c\u63d0\u5347\u5b9a\u7406\uff0c\u6210\u529f\u5730\u5c06NISQ\u8bbe\u7f6e\u4e0b\u7684\u5b89\u5168\u535a\u5f08\u5206\u6790\u6269\u5c55\u5230\u6df7\u5408\u7b97\u6cd5\u548c\u5608\u6742\u6a21\u578b\uff0c\u5e76\u76f4\u63a5\u63a8\u5bfc\u4e86\u76f8\u5173\u7684\u5b89\u5168\u6027\u548c\u590d\u6742\u5ea6\u7ed3\u679c\uff0c\u4e3a\u7406\u89e3\u548c\u8bbe\u8ba1NISQ\u7b97\u6cd5\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u7406\u8bba\u5de5\u5177\u3002"}}
{"id": "2509.10296", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.10296", "abs": "https://arxiv.org/abs/2509.10296", "authors": ["Cheng Luo", "Jie Hu", "Luping Xiang", "Kun Yang", "Zhiqin Wang"], "title": "Low-Complexity Null-Space-Based Simultaneous Wireless Information and Power Transfer Scheme", "comment": null, "summary": "Simultaneous wireless information and power transfer (SWIPT) has attracted\nsustained interest. We propose a null-space-based transmission scheme for\nmultiuser SWIPT serving both energy users (EUs) and information users (IUs).\nUnder a practical nonlinear energy-harvesting (EH) model and multiple waveform\noptions, we revisit the role of dedicated energy beams (EBs). We show that, in\ngeneral, dedicated EBs are unnecessary because information beams (IBs) with\nGaussian signaling can simultaneously support wireless energy transfer (WET)\nand wireless information transfer (WIT), unless special energy-centric\nwaveforms (e.g., deterministic sinusoidal waveforms) are employed and provide\nsufficient gains. Guided by these insights, we formulate an optimization\nproblem for EB design to enable dedicated waveform transmission for WET, and we\ndevelop a low-complexity algorithm that reduces computation by ignoring the WET\ncontribution of IBs during optimization. Numerical results corroborate that\ndeterministic sinusoidal waveforms outperform Gaussian signaling when the\nreceived RF power lies in the EH high-efficiency region, making dedicated EBs\nbeneficial. The proposed scheme achieves computational complexity reductions of\n91.43\\% and 98.54\\% for the cases $M=8,,K^I=K^E=2$ and $M=16,,K^I=K^E=4$,\nrespectively, with negligible performance loss, thereby validating the\nefficiency of the low-complexity algorithm.", "AI": {"tldr": "\u5728\u591a\u7528\u6237\u65e0\u7ebf\u4fe1\u606f\u4e0e\u80fd\u91cf\u540c\u6b65\u4f20\u8f93\uff08SWIPT\uff09\u7cfb\u7edf\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u96f6\u7a7a\u95f4\u4f20\u8f93\u65b9\u6848\uff0c\u8be5\u65b9\u6848\u5229\u7528\u4fe1\u606f\u6ce2\u675f\uff08IBs\uff09\u7ed3\u5408\u9ad8\u65af\u4fe1\u53f7\u8fdb\u884c\u4fe1\u606f\u4e0e\u80fd\u91cf\u7684\u8054\u5408\u4f20\u8f93\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u4f18\u5316\u7684\u80fd\u91cf\u6ce2\u675f\uff08EB\uff09\u8bbe\u8ba1\uff0c\u4ee5\u5728\u5fc5\u8981\u65f6\uff08\u5982\u4f7f\u7528\u786e\u5b9a\u6027\u6b63\u5f26\u6ce2\u5f62\u65f6\uff09\u5b9e\u73b0\u4e13\u7528\u6ce2\u5f62\u4f20\u8f93\u4ee5\u589e\u5f3a\u80fd\u91cf\u4f20\u8f93\u3002", "motivation": "\u8bc4\u4f30\u5728\u591a\u7528\u6237SWIPT\u7cfb\u7edf\u4e2d\uff0c\u4fe1\u606f\u6ce2\u675f\uff08IBs\uff09\u662f\u5426\u8db3\u4ee5\u652f\u6301\u65e0\u7ebf\u80fd\u91cf\u4f20\u8f93\uff08WET\uff09\uff0c\u4ee5\u53ca\u4f55\u65f6\u9700\u8981\u4e13\u7528\u80fd\u91cf\u6ce2\u675f\uff08EBs\uff09\uff0c\u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u63d0\u51fa\u4e00\u79cd\u4f4e\u590d\u6742\u5ea6\u7b97\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u96f6\u7a7a\u95f4\u4f20\u8f93\u7684\u65b9\u6848\uff0c\u5e76\u5229\u7528\u9ad8\u65af\u4fe1\u53f7\u8fdb\u884cIBs\u7684\u4f20\u8f93\u3002\u5728\u8003\u8651\u975e\u7ebf\u6027EH\u6a21\u578b\u548c\u591a\u79cd\u6ce2\u5f62\u9009\u9879\u540e\uff0c\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u4f18\u5316\u95ee\u9898\u6765\u4e3aEBs\u8bbe\u8ba1\u4e13\u7528\u6ce2\u5f62\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u79cd\u4f4e\u590d\u6742\u5ea6\u7684\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u5728\u4f18\u5316\u8fc7\u7a0b\u4e2d\u5ffd\u7565\u4e86IBs\u5bf9WET\u7684\u8d21\u732e\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\uff0cIBs\u914d\u5408\u9ad8\u65af\u4fe1\u53f7\u8db3\u4ee5\u652f\u6301WET\uff0c\u4e13\u7528EBs\u5e76\u975e\u603b\u662f\u5fc5\u9700\uff0c\u9664\u975e\u91c7\u7528\u4e86\u5982\u786e\u5b9a\u6027\u6b63\u5f26\u6ce2\u5f62\u7b49\u7279\u6b8a\u80fd\u91cf\u6ce2\u5f62\u3002\u5f53\u63a5\u6536\u5230\u7684\u5c04\u9891\u529f\u7387\u5904\u4e8eEH\u9ad8\u6548\u7387\u533a\u57df\u65f6\uff0c\u786e\u5b9a\u6027\u6b63\u5f26\u6ce2\u5f62\u4f18\u4e8e\u9ad8\u65af\u4fe1\u53f7\uff0c\u6b64\u65f6\u4e13\u7528EBs\u662f\u6709\u76ca\u7684\u3002\u6240\u63d0\u51fa\u7684\u4f4e\u590d\u6742\u5ea6\u7b97\u6cd5\u5728M=8, K^I=K^E=2\u548cM=16, K^I=K^E=4\u7684\u60c5\u51b5\u4e0b\uff0c\u5206\u522b\u5b9e\u73b0\u4e8691.43%\u548c98.54%\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u964d\u4f4e\uff0c\u4e14\u6027\u80fd\u635f\u5931\u53ef\u5ffd\u7565\u4e0d\u8ba1\u3002", "conclusion": "\u57fa\u4e8e\u96f6\u7a7a\u95f4\u4f20\u8f93\u7684\u65b9\u6848\u80fd\u591f\u6709\u6548\u5730\u5728\u591a\u7528\u6237SWIPT\u7cfb\u7edf\u4e2d\u8fdb\u884c\u4fe1\u606f\u4e0e\u80fd\u91cf\u7684\u8054\u5408\u4f20\u8f93\u3002\u901a\u8fc7\u91c7\u7528\u4f18\u5316\u7684EB\u8bbe\u8ba1\u548c\u4f4e\u590d\u6742\u5ea6\u7b97\u6cd5\uff0c\u53ef\u4ee5\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u63a5\u53d7\u7684\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728\u4f7f\u7528\u786e\u5b9a\u6027\u6b63\u5f26\u6ce2\u5f62\u4e14EH\u5904\u4e8e\u9ad8\u6548\u7387\u533a\u57df\u65f6\u3002"}}
{"id": "2509.10207", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2509.10207", "abs": "https://arxiv.org/abs/2509.10207", "authors": ["Guilherme S. L. Fabris", "Bruno Ipaves", "Raphael B. Oliveira", "Humberto R. Gutierrez", "Marcelo L. Pereira Junior", "Douglas S. Galv\u00e3o"], "title": "Magnetism Induced by Azanide and Ammonia Adsorption in Defective Molybdenum Disulfide and Diselenide: A First-Principles Study", "comment": null, "summary": "Two-dimensional (2D) transition metal dichalcogenides (TMDs) have attracted\nconsiderable attention due to their tunable structural, electronic, and\nspin-related properties, particularly in the presence of point defects and\nmolecular adsorbates. Motivated by these aspects, we have investigated using\nfirst-principles methods the magnetic properties induced by azanide (NH$_2$)\nand ammonia (NH$_3$) adsorption on defective monolayers of Molybdenum Disulfide\n(MoS$_2$) and Diselenide(MoSe$_2$). Spin-polarized density functional theory\n(DFT) was employed to investigate the impact of mono- and di-vacancies on the\nlocal spin environment and the role of molecular adsorption in modifying\nmagnetic behavior. The results show that pristine chalcogen vacancies do not\ngenerate magnetism, whereas the adsorption of NH$_2$ and NH$_3$ creates\nlocalized magnetic moments in Mo-based dichalcogenides. A notable case occurs\nfor MoSe$_2$, where NH$_3$ dissociation into NH$_2$ and H fragments on the same\nside of the surface produces a net magnetic moment of 2.0 $\\mu_B$. Tests\nperformed on W-based dichalcogenides under equivalent conditions showed no\nmagnetic response, and are reported here only for comparison. These findings\ndemonstrate that molecular adsorption combined with defect engineering can be a\npractical approach to tune magnetism in 2D materials, with potential relevance\nfor spintronic and sensing applications.", "AI": {"tldr": "\u5206\u5b50\u5438\u9644\u548c\u7f3a\u9677\u5de5\u7a0b\u53ef\u8c03\u63a7\u4e8c\u7ef4\u6750\u6599\u7684\u78c1\u6027\u3002", "motivation": "\u4e8c\u7ef4\u8fc7\u6e21\u91d1\u5c5e\u786b\u5c5e\u5316\u7269\uff08TMDs\uff09\u56e0\u5176\u53ef\u8c03\u7684\u7ed3\u6784\u3001\u7535\u5b50\u548c\u81ea\u65cb\u76f8\u5173\u6027\u8d28\u800c\u5907\u53d7\u5173\u6ce8\uff0c\u7279\u522b\u662f\u5728\u70b9\u7f3a\u9677\u548c\u5206\u5b50\u5438\u9644\u7269\u5b58\u5728\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u4f7f\u7528\u81ea\u65cb\u6781\u5316\u5bc6\u5ea6\u6cdb\u51fd\u7406\u8bba\uff08DFT\uff09\u7814\u7a76\u4e86NH2\u548cNH3\u5206\u5b50\u5438\u9644\u5728\u6709\u7f3a\u9677\u7684MoS2\u548cMoSe2\u5355\u5206\u5b50\u5c42\u4e0a\u5f15\u8d77\u7684\u78c1\u6027\u3002", "result": "\u539f\u59cb\u7684\u786b\u5c5e\u5316\u7269\u7a7a\u4f4d\u4e0d\u4ea7\u751f\u78c1\u6027\uff0c\u4f46NH2\u548cNH3\u7684\u5438\u9644\u4f1a\u5728Mo\u57fa\u4e8c\u5364\u4ee3\u7269\u4e2d\u4ea7\u751f\u5c40\u57df\u78c1\u77e9\u3002\u5728MoSe2\u4e0a\uff0cNH3\u89e3\u79bb\u4ea7\u751f\u7684NH2\u548cH\u7247\u6bb5\u4f1a\u4ea7\u751f2.0 \u03bcB\u7684\u51c0\u78c1\u77e9\u3002W\u57fa\u4e8c\u5364\u4ee3\u7269\u6ca1\u6709\u78c1\u54cd\u5e94\u3002", "conclusion": "\u5206\u5b50\u5438\u9644\u4e0e\u7f3a\u9677\u5de5\u7a0b\u76f8\u7ed3\u5408\u662f\u8c03\u63a7\u4e8c\u7ef4\u6750\u6599\u78c1\u6027\u7684\u4e00\u79cd\u5b9e\u7528\u65b9\u6cd5\uff0c\u6709\u671b\u5e94\u7528\u4e8e\u81ea\u65cb\u7535\u5b50\u5b66\u548c\u4f20\u611f\u9886\u57df\u3002"}}
{"id": "2509.09710", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.09710", "abs": "https://arxiv.org/abs/2509.09710", "authors": ["Sepehr Golrokh Amin", "Devin Rhoads", "Fatemeh Fakhrmoosavi", "Nicholas E. Lownes", "John N. Ivan"], "title": "Generating Individual Travel Diaries Using Large Language Models Informed by Census and Land-Use Data", "comment": null, "summary": "This study introduces a Large Language Model (LLM) scheme for generating\nindividual travel diaries in agent-based transportation models. While\ntraditional approaches rely on large quantities of proprietary household travel\nsurveys, the method presented in this study generates personas stochastically\nfrom open-source American Community Survey (ACS) and Smart Location Database\n(SLD) data, then synthesizes diaries through direct prompting. This study\nfeatures a novel one-to-cohort realism score: a composite of four metrics (Trip\nCount Score, Interval Score, Purpose Score, and Mode Score) validated against\nthe Connecticut Statewide Transportation Study (CSTS) diaries, matched across\ndemographic variables. The validation utilizes Jensen-Shannon Divergence to\nmeasure distributional similarities between generated and real diaries. When\ncompared to diaries generated with classical methods (Negative Binomial for\ntrip generation; Multinomial Logit for mode/purpose) calibrated on the\nvalidation set, LLM-generated diaries achieve comparable overall realism (LLM\nmean: 0.485 vs. 0.455). The LLM excels in determining trip purpose and\ndemonstrates greater consistency (narrower realism score distribution), while\nclassical models lead in numerical estimates of trip count and activity\nduration. Aggregate validation confirms the LLM's statistical\nrepresentativeness (LLM mean: 0.612 vs. 0.435), demonstrating LLM's zero-shot\nviability and establishing a quantifiable metric of diary realism for future\nsynthetic diary evaluation systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e00\u79cd\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u751f\u6210\u7528\u4e8e\u57fa\u4e8e\u4ee3\u7406\u7684\u4ea4\u901a\u6a21\u578b\u4e2d\u7684\u4e2a\u4f53\u51fa\u884c\u65e5\u8bb0\u7684\u65b9\u6848\uff0c\u901a\u8fc7\u7ed3\u5408\u7f8e\u56fd\u793e\u533a\u8c03\u67e5\uff08ACS\uff09\u548c\u667a\u80fd\u4f4d\u7f6e\u6570\u636e\u5e93\uff08SLD\uff09\u6570\u636e\u751f\u6210\u7528\u6237\u753b\u50cf\uff0c\u5e76\u5229\u7528\u63d0\u793a\u76f4\u63a5\u5408\u6210\u65e5\u8bb0\uff0c\u4ee5\u66ff\u4ee3\u4f20\u7edf\u7684\u51fa\u884c\u8c03\u67e5\u6570\u636e\u3002", "motivation": "\u4f20\u7edf\u7684\u57fa\u4e8e\u4ee3\u7406\u7684\u4ea4\u901a\u6a21\u578b\u4f9d\u8d56\u5927\u91cf\u7684\u4e13\u6709\u5bb6\u5ead\u51fa\u884c\u8c03\u67e5\u6570\u636e\uff0c\u800c\u672c\u7814\u7a76\u65e8\u5728\u63d0\u51fa\u4e00\u79cd\u5229\u7528\u516c\u5f00\u6570\u636e\u751f\u6210\u4e2a\u4f53\u51fa\u884c\u65e5\u8bb0\u7684\u65b9\u6cd5\uff0c\u4ee5\u514b\u670d\u6570\u636e\u83b7\u53d6\u7684\u9650\u5236\u3002", "method": "\u672c\u7814\u7a76\u5229\u7528LLM\uff0c\u7ed3\u5408\u516c\u5f00\u7684ACS\u548cSLD\u6570\u636e\u751f\u6210\u7528\u6237\u753b\u50cf\uff0c\u5e76\u901a\u8fc7\u76f4\u63a5\u63d0\u793a\u5408\u6210\u51fa\u884c\u65e5\u8bb0\u3002\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u201c\u4e00\u5bf9\u7fa4\u7ec4\u771f\u5b9e\u6027\u5f97\u5206\u201d\uff0c\u8be5\u5f97\u5206\u7531\u56db\u4e2a\u6307\u6807\uff08\u51fa\u884c\u6b21\u6570\u5f97\u5206\u3001\u65f6\u95f4\u95f4\u9694\u5f97\u5206\u3001\u51fa\u884c\u76ee\u7684\u5f97\u5206\u548c\u51fa\u884c\u65b9\u5f0f\u5f97\u5206\uff09\u7ec4\u6210\uff0c\u5e76\u4f7f\u7528\u5eb7\u6d85\u72c4\u683c\u5dde\u5168\u5dde\u4ea4\u901a\u7814\u7a76\uff08CSTS\uff09\u7684\u65e5\u8bb0\u6570\u636e\u8fdb\u884c\u9a8c\u8bc1\uff0c\u91c7\u7528Jensen-Shannon\u6563\u5ea6\u6765\u8861\u91cf\u751f\u6210\u65e5\u8bb0\u4e0e\u771f\u5b9e\u65e5\u8bb0\u5728\u5206\u5e03\u4e0a\u7684\u76f8\u4f3c\u6027\u3002", "result": "\u4e0e\u4f7f\u7528\u8d1f\u4e8c\u9879\u56de\u5f52\uff08\u7528\u4e8e\u51fa\u884c\u751f\u6210\uff09\u548c\u591a\u9879Logit\u6a21\u578b\uff08\u7528\u4e8e\u51fa\u884c\u65b9\u5f0f/\u76ee\u7684\u9009\u62e9\uff09\u7b49\u7ecf\u5178\u65b9\u6cd5\u751f\u6210\u7684\u65e5\u8bb0\u76f8\u6bd4\uff0cLLM\u751f\u6210\u7684\u65e5\u8bb0\u5728\u6574\u4f53\u771f\u5b9e\u6027\u4e0a\u76f8\u5f53\uff08LLM\u5e73\u5747\u771f\u5b9e\u6027\u5f97\u52060.485\uff0c\u7ecf\u5178\u65b9\u6cd5\u5e73\u57470.455\uff09\u3002LLM\u5728\u51fa\u884c\u76ee\u7684\u7684\u786e\u5b9a\u4e0a\u8868\u73b0\u66f4\u4f18\uff0c\u5e76\u4e14\u5177\u6709\u66f4\u597d\u7684\u6a21\u578b\u4e00\u81f4\u6027\uff08\u771f\u5b9e\u6027\u5f97\u5206\u5206\u5e03\u66f4\u7a84\uff09\uff1b\u7136\u800c\uff0c\u7ecf\u5178\u6a21\u578b\u5728\u51fa\u884c\u6b21\u6570\u548c\u6d3b\u52a8\u6301\u7eed\u65f6\u95f4\u7684\u6570\u503c\u4f30\u8ba1\u4e0a\u66f4\u5177\u4f18\u52bf\u3002\u5728\u805a\u5408\u9a8c\u8bc1\u4e2d\uff0cLLM\u751f\u6210\u65e5\u8bb0\u7684\u7edf\u8ba1\u4ee3\u8868\u6027\u4e5f\u66f4\u5f3a\uff08LLM\u5e73\u5747\u5f97\u52060.612\uff0c\u7ecf\u5178\u65b9\u6cd5\u5e73\u57470.435\uff09\u3002", "conclusion": "\u672c\u7814\u7a76\u8bc1\u660e\u4e86LLM\u5728\u751f\u6210\u4e2a\u4f53\u51fa\u884c\u65e5\u8bb0\u65b9\u9762\u7684\u53ef\u884c\u6027\uff0c\u5c24\u5176\u662f\u5728\u96f6\u6837\u672c\uff08zero-shot\uff09\u573a\u666f\u4e0b\uff0c\u5e76\u5efa\u7acb\u4e86\u4e00\u4e2a\u53ef\u91cf\u5316\u7684\u65e5\u8bb0\u771f\u5b9e\u6027\u8bc4\u4f30\u6307\u6807\uff0c\u4e3a\u672a\u6765\u7684\u5408\u6210\u65e5\u8bb0\u8bc4\u4f30\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002LLM\u65b9\u6cd5\u5728\u51fa\u884c\u76ee\u7684\u548c\u6a21\u578b\u4e00\u81f4\u6027\u65b9\u9762\u8868\u73b0\u7a81\u51fa\uff0c\u4e3a\u4ea4\u901a\u5efa\u6a21\u63d0\u4f9b\u4e86\u65b0\u7684\u6570\u636e\u5408\u6210\u9014\u5f84\u3002"}}
{"id": "2509.09843", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09843", "abs": "https://arxiv.org/abs/2509.09843", "authors": ["Jiajun Shen", "Yufei Jin", "Yi He", "Xingquan Zhu"], "title": "HGEN: Heterogeneous Graph Ensemble Networks", "comment": "The paper is in proceedings of the 34th IJCAI Conference, 2025", "summary": "This paper presents HGEN that pioneers ensemble learning for heterogeneous\ngraphs. We argue that the heterogeneity in node types, nodal features, and\nlocal neighborhood topology poses significant challenges for ensemble learning,\nparticularly in accommodating diverse graph learners. Our HGEN framework\nensembles multiple learners through a meta-path and transformation-based\noptimization pipeline to uplift classification accuracy. Specifically, HGEN\nuses meta-path combined with random dropping to create Allele Graph Neural\nNetworks (GNNs), whereby the base graph learners are trained and aligned for\nlater ensembling. To ensure effective ensemble learning, HGEN presents two key\ncomponents: 1) a residual-attention mechanism to calibrate allele GNNs of\ndifferent meta-paths, thereby enforcing node embeddings to focus on more\ninformative graphs to improve base learner accuracy, and 2) a\ncorrelation-regularization term to enlarge the disparity among embedding\nmatrices generated from different meta-paths, thereby enriching base learner\ndiversity. We analyze the convergence of HGEN and attest its higher\nregularization magnitude over simple voting. Experiments on five heterogeneous\nnetworks validate that HGEN consistently outperforms its state-of-the-art\ncompetitors by substantial margin.", "AI": {"tldr": "HGEN\u662f\u4e00\u79cd\u7528\u4e8e\u5f02\u6784\u56fe\u7684\u96c6\u6210\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5143\u8def\u5f84\u548c\u53d8\u6362\u4f18\u5316\u6765\u63d0\u9ad8\u5206\u7c7b\u51c6\u786e\u6027\u3002", "motivation": "\u5f02\u6784\u56fe\u4e2d\u8282\u70b9\u7c7b\u578b\u3001\u8282\u70b9\u7279\u5f81\u548c\u5c40\u90e8\u90bb\u57df\u62d3\u6251\u7684\u5f02\u8d28\u6027\u7ed9\u96c6\u6210\u5b66\u4e60\u5e26\u6765\u4e86\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u9002\u5e94\u4e0d\u540c\u7684\u56fe\u5b66\u4e60\u5668\u65b9\u9762\u3002", "method": "HGEN\u6846\u67b6\u901a\u8fc7\u5143\u8def\u5f84\u548c\u53d8\u6362\u4f18\u5316\u6d41\u7a0b\u96c6\u6210\u591a\u4e2a\u5b66\u4e60\u5668\u3002\u5177\u4f53\u6765\u8bf4\uff0cHGEN\u4f7f\u7528\u5143\u8def\u5f84\u7ed3\u5408\u968f\u673a\u4e22\u5f03\u6765\u521b\u5efa\u7b49\u4f4d\u57fa\u56e0\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNN\uff09\uff0c\u4ece\u800c\u8bad\u7ec3\u548c\u5bf9\u9f50\u57fa\u7840\u56fe\u5b66\u4e60\u5668\u4ee5\u8fdb\u884c\u540e\u7eed\u96c6\u6210\u3002HGEN\u5305\u542b\u4e24\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a1\uff09\u6b8b\u5dee\u6ce8\u610f\u673a\u5236\uff0c\u7528\u4e8e\u6821\u51c6\u4e0d\u540c\u5143\u8def\u5f84\u7684\u7b49\u4f4d\u57fa\u56e0GNN\uff0c\u5f3a\u5236\u8282\u70b9\u5d4c\u5165\u5173\u6ce8\u4fe1\u606f\u91cf\u66f4\u5927\u7684\u56fe\uff1b2\uff09\u76f8\u5173\u6027\u6b63\u5219\u5316\u9879\uff0c\u7528\u4e8e\u6269\u5927\u7531\u4e0d\u540c\u5143\u8def\u5f84\u751f\u6210\u7684\u5d4c\u5165\u77e9\u9635\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u4ee5\u4e30\u5bcc\u57fa\u7840\u5b66\u4e60\u5668\u7684\u591a\u6837\u6027\u3002", "result": "HGEN\u7684\u6536\u655b\u6027\u5f97\u5230\u4e86\u5206\u6790\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u6bd4\u7b80\u5355\u6295\u7968\u5177\u6709\u66f4\u9ad8\u7684\u6b63\u5219\u5316\u5e45\u5ea6\u3002\u5728\u4e94\u4e2a\u5f02\u6784\u7f51\u7edc\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cHGEN\u7684\u6027\u80fd\u59cb\u7ec8\u5927\u5e45\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u7ade\u4e89\u5bf9\u624b\u3002", "conclusion": "HGEN\u901a\u8fc7\u5f15\u5165\u6b8b\u5dee\u6ce8\u610f\u673a\u5236\u548c\u76f8\u5173\u6027\u6b63\u5219\u5316\u9879\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u5f02\u6784\u56fe\u96c6\u6210\u5b66\u4e60\u4e2d\u7684\u6311\u6218\uff0c\u5e76\u53d6\u5f97\u4e86\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u3002"}}
{"id": "2509.09982", "categories": ["cs.AI", "I.2.4"], "pdf": "https://arxiv.org/pdf/2509.09982", "abs": "https://arxiv.org/abs/2509.09982", "authors": ["Stav Armoni-Friedmann", "Hana Chockler", "David A. Kelly"], "title": "Evaluation of Black-Box XAI Approaches for Predictors of Values of Boolean Formulae", "comment": "Accepted to ECAI-EXCD Workshop, 8 pages, 2 figures, 5 tables", "summary": "Evaluating explainable AI (XAI) approaches is a challenging task in general,\ndue to the subjectivity of explanations. In this paper, we focus on tabular\ndata and the specific use case of AI models predicting the values of Boolean\nfunctions. We extend the previous work in this domain by proposing a formal and\nprecise measure of importance of variables based on actual causality, and we\nevaluate state-of-the-art XAI tools against this measure. We also present a\nnovel XAI tool B-ReX, based on the existing tool ReX, and demonstrate that it\nis superior to other black-box XAI tools on a large-scale benchmark.\nSpecifically, B-ReX achieves a Jensen-Shannon divergence of 0.072 $\\pm$ 0.012\non random 10-valued Boolean formulae", "AI": {"tldr": "\u672c\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\uff08XAI\uff09\u5de5\u5177B-ReX\uff0c\u7528\u4e8e\u8bc4\u4f30\u8868\u683c\u6570\u636e\u548c\u5e03\u5c14\u51fd\u6570\u9884\u6d4b\u6a21\u578b\u3002B-ReX\u5728\u5927\u91cf\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6XAI\u5de5\u5177\uff0c\u5176Jensen-Shannon\u6563\u5ea6\u4e3a0.072 \u00b1 0.012\u3002", "motivation": "\u8bc4\u4f30\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\uff08XAI\uff09\u65b9\u6cd5\u662f\u4e00\u4e2a\u666e\u904d\u5b58\u5728\u7684\u6311\u6218\uff0c\u56e0\u4e3a\u89e3\u91ca\u672c\u8eab\u5177\u6709\u4e3b\u89c2\u6027\u3002\u672c\u7814\u7a76\u7684\u52a8\u673a\u662f\u9488\u5bf9\u8868\u683c\u6570\u636e\u548c\u5e03\u5c14\u51fd\u6570\u9884\u6d4b\u7684\u7279\u5b9a\u573a\u666f\uff0c\u63d0\u51fa\u4e00\u79cd\u66f4\u6b63\u5f0f\u3001\u66f4\u7cbe\u786e\u7684\u53d8\u91cf\u91cd\u8981\u6027\u5ea6\u91cf\u65b9\u6cd5\uff0c\u5e76\u8bc4\u4f30\u73b0\u6709\u7684XAI\u5de5\u5177\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5b9e\u9645\u56e0\u679c\u5173\u7cfb\u7684\u53d8\u91cf\u91cd\u8981\u6027\u5f62\u5f0f\u5316\u5ea6\u91cf\u65b9\u6cd5\uff0c\u5e76\u4f7f\u7528\u8be5\u5ea6\u91cf\u65b9\u6cd5\u8bc4\u4f30\u4e86\u6700\u5148\u8fdb\u7684XAI\u5de5\u5177\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8005\u4eec\u8fd8\u5f00\u53d1\u4e86\u4e00\u79cd\u540d\u4e3aB-ReX\u7684\u65b0\u578bXAI\u5de5\u5177\uff0c\u5b83\u57fa\u4e8e\u73b0\u6709\u7684ReX\u5de5\u5177\u8fdb\u884c\u4e86\u6269\u5c55\u3002", "result": "\u5728\u5927\u578b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cB-ReX\u88ab\u8bc1\u660e\u4f18\u4e8e\u5176\u4ed6\u9ed1\u76d2XAI\u5de5\u5177\uff0c\u5728\u968f\u673a10\u503c\u5e03\u5c14\u516c\u5f0f\u4e0a\u7684Jensen-Shannon\u6563\u5ea6\u8fbe\u5230\u4e860.072 \u00b1 0.012\u3002", "conclusion": "B-ReX\u662f\u4e00\u79cd\u5728\u8868\u683c\u6570\u636e\u548c\u5e03\u5c14\u51fd\u6570\u9884\u6d4b\u573a\u666f\u4e0b\uff0c\u6bd4\u73b0\u6709\u9ed1\u76d2XAI\u5de5\u5177\u66f4\u4f18\u8d8a\u7684\u65b0\u578bXAI\u5de5\u5177\u3002"}}
{"id": "2509.10118", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.10118", "abs": "https://arxiv.org/abs/2509.10118", "authors": ["Jingyuan Zhou", "Haoze Wu", "Haokun Yu", "Kaidi Yang"], "title": "Scalable Synthesis and Verification of String Stable Neural Certificates for Interconnected Systems", "comment": null, "summary": "Ensuring string stability is critical for the safety and efficiency of\nlarge-scale interconnected systems. Although learning-based controllers (e.g.,\nthose based on reinforcement learning) have demonstrated strong performance in\ncomplex control scenarios, their black-box nature hinders formal guarantees of\nstring stability. To address this gap, we propose a novel verification and\nsynthesis framework that integrates discrete-time scalable input-to-state\nstability (sISS) with neural network verification to formally guarantee string\nstability in interconnected systems. Our contributions are four-fold. First, we\nestablish a formal framework for synthesizing and robustly verifying\ndiscrete-time scalable input-to-state stability (sISS) certificates for neural\nnetwork-based interconnected systems. Specifically, our approach extends the\nnotion of sISS to discrete-time settings, constructs neural sISS certificates,\nand introduces a verification procedure that ensures string stability while\nexplicitly accounting for discrepancies between the true dynamics and their\nneural approximations. Second, we establish theoretical foundations and\nalgorithms to scale the training and verification pipeline to large-scale\ninterconnected systems. Third, we extend the framework to handle systems with\nexternal control inputs, thereby allowing the joint synthesis and verification\nof neural certificates and controllers. Fourth, we validate our approach in\nscenarios of mixed-autonomy platoons, drone formations, and microgrids.\nNumerical simulations show that the proposed framework not only guarantees sISS\nwith minimal degradation in control performance but also efficiently trains and\nverifies controllers for large-scale interconnected systems under specific\npractical conditions.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7ed3\u5408\u4e86\u79bb\u6563\u65f6\u95f4\u53ef\u6269\u5c55\u8f93\u5165\u72b6\u6001\u7a33\u5b9a\u6027\uff08sISS\uff09\u548c\u795e\u7ecf\u7f51\u7edc\u9a8c\u8bc1\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u4fdd\u8bc1\u5927\u578b\u4e92\u8054\u7cfb\u7edf\u7684\u5b57\u7b26\u4e32\u7a33\u5b9a\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5b66\u4e60\u7684\u63a7\u5236\u5668\uff08\u5982\u5f3a\u5316\u5b66\u4e60\uff09\u867d\u7136\u6027\u80fd\u5f3a\u5927\uff0c\u4f46\u5176\u9ed1\u76d2\u7279\u6027\u963b\u788d\u4e86\u5bf9\u5b57\u7b26\u4e32\u7a33\u5b9a\u6027\u7684\u6b63\u5f0f\u4fdd\u8bc1\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u7ed3\u5408\u4e86\u79bb\u6563\u65f6\u95f4\u53ef\u6269\u5c55\u8f93\u5165\u72b6\u6001\u7a33\u5b9a\u6027\uff08sISS\uff09\u548c\u795e\u7ecf\u7f51\u7edc\u9a8c\u8bc1\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5408\u6210\u548c\u9a8c\u8bc1\u795e\u7ecf\u7f51\u7edc\u4e92\u8054\u7cfb\u7edf\u7684sISS\u8bc1\u4e66\uff0c\u5e76\u6269\u5c55\u5230\u5177\u6709\u5916\u90e8\u63a7\u5236\u8f93\u5165\u7684\u7cfb\u7edf\u3002", "result": "\u8be5\u6846\u67b6\u80fd\u591f\u4fdd\u8bc1sISS\uff0c\u540c\u65f6\u63a7\u5236\u6027\u80fd\u4e0b\u964d\u6700\u5c0f\uff0c\u5e76\u80fd\u6709\u6548\u5730\u8bad\u7ec3\u548c\u9a8c\u8bc1\u5927\u578b\u4e92\u8054\u7cfb\u7edf\u7684\u63a7\u5236\u5668\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u4fdd\u8bc1\u5927\u578b\u4e92\u8054\u7cfb\u7edf\u7684\u5b57\u7b26\u4e32\u7a33\u5b9a\u6027\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u3001\u53ef\u6269\u5c55\u7684\u3001\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u65b9\u6cd5\u3002"}}
{"id": "2509.09792", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.09792", "abs": "https://arxiv.org/abs/2509.09792", "authors": ["Zimin Xia", "Chenghao Xu", "Alexandre Alahi"], "title": "Fine-Grained Cross-View Localization via Local Feature Matching and Monocular Depth Priors", "comment": null, "summary": "We propose an accurate and highly interpretable fine-grained cross-view\nlocalization method that estimates the 3 Degrees of Freedom pose of a\nground-level image by matching its local features with a reference aerial\nimage. Previous methods typically transform the ground image into a bird's-eye\nview (BEV) representation and then align it with the aerial image for\nlocalization. However, this transformation often leads to information loss due\nto perspective distortion or compression of height information, thereby\ndegrading alignment quality with the aerial view. In contrast, our method\ndirectly establishes correspondences between ground and aerial images and lifts\nonly the matched keypoints to BEV space using monocular depth prior. Notably,\nmodern depth predictors can provide reliable metric depth when the test samples\nare similar to the training data. When the depth distribution differs, they\nstill produce consistent relative depth, i.e., depth accurate up to an unknown\nscale. Our method supports both metric and relative depth. It employs a\nscale-aware Procrustes alignment to estimate the camera pose from the\ncorrespondences and optionally recover the scale when using relative depth.\nExperimental results demonstrate that, with only weak supervision on camera\npose, our method learns accurate local feature correspondences and achieves\nsuperior localization performance under challenging conditions, such as\ncross-area generalization and unknown orientation. Moreover, our method is\ncompatible with various relative depth models without requiring per-model\nfinetuning. This flexibility, combined with strong localization performance,\nmakes it well-suited for real-world deployment.", "AI": {"tldr": "\u901a\u8fc7\u5339\u914d\u5730\u9762\u56fe\u50cf\u548c\u53c2\u8003\u822a\u62cd\u56fe\u50cf\u7684\u5c40\u90e8\u7279\u5f81\uff0c\u63d0\u51fa\u4e00\u79cd\u7cbe\u786e\u4e14\u53ef\u89e3\u91ca\u7684\u8de8\u89c6\u56fe\u7cbe\u7ec6\u5316\u5b9a\u4f4d\u65b9\u6cd5\uff0c\u76f4\u63a5\u5efa\u7acb\u5730\u9762\u548c\u822a\u62cd\u56fe\u50cf\u95f4\u7684\u5bf9\u5e94\u5173\u7cfb\uff0c\u5e76\u5229\u7528\u5355\u76ee\u6df1\u5ea6\u5148\u9a8c\u5c06\u5339\u914d\u7684\u5173\u952e\u70b9\u63d0\u5347\u81f3BEV\u7a7a\u95f4\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e2dBEV\u8f6c\u6362\u4fe1\u606f\u4e22\u5931\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5c06\u5730\u9762\u56fe\u50cf\u8f6c\u6362\u4e3aBEV\u8868\u793a\u518d\u4e0e\u822a\u62cd\u56fe\u50cf\u5bf9\u9f50\uff0c\u5e38\u56e0\u900f\u89c6\u7578\u53d8\u6216\u9ad8\u5ea6\u4fe1\u606f\u538b\u7f29\u5bfc\u81f4\u4fe1\u606f\u4e22\u5931\uff0c\u964d\u4f4e\u4e86\u4e0e\u822a\u62cd\u89c6\u56fe\u7684\u5bf9\u9f50\u8d28\u91cf\u3002", "method": "\u76f4\u63a5\u5efa\u7acb\u5730\u9762\u548c\u822a\u62cd\u56fe\u50cf\u95f4\u7684\u5bf9\u5e94\u5173\u7cfb\uff0c\u5e76\u5229\u7528\u5355\u76ee\u6df1\u5ea6\u5148\u9a8c\u5c06\u5339\u914d\u7684\u5173\u952e\u70b9\u63d0\u5347\u81f3BEV\u7a7a\u95f4\uff1b\u91c7\u7528\u5c3a\u5ea6\u611f\u77e5Procrustes\u5bf9\u9f50\u6765\u4f30\u8ba1\u76f8\u673a\u4f4d\u59ff\uff0c\u5e76\u652f\u6301\u5ea6\u91cf\u6df1\u5ea6\u548c\u76f8\u5bf9\u6df1\u5ea6\uff0c\u53ef\u9009\u5730\u6062\u590d\u5c3a\u5ea6\u3002", "result": "\u5728\u4ec5\u6709\u5f31\u76f8\u673a\u4f4d\u59ff\u76d1\u7763\u7684\u60c5\u51b5\u4e0b\uff0c\u5b66\u4e60\u7cbe\u786e\u7684\u5c40\u90e8\u7279\u5f81\u5bf9\u5e94\u5173\u7cfb\uff0c\u5728\u8de8\u533a\u57df\u6cdb\u5316\u548c\u672a\u77e5\u65b9\u5411\u7b49\u6311\u6218\u6027\u6761\u4ef6\u4e0b\u5b9e\u73b0\u4e86\u5353\u8d8a\u7684\u5b9a\u4f4d\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5b66\u4e60\u7cbe\u786e\u7684\u5c40\u90e8\u7279\u5f81\u5bf9\u5e94\u5173\u7cfb\uff0c\u5e76\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u6761\u4ef6\u4e0b\u5b9e\u73b0\u5353\u8d8a\u7684\u5b9a\u4f4d\u6027\u80fd\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u4e0e\u5404\u79cd\u76f8\u5bf9\u6df1\u5ea6\u6a21\u578b\u517c\u5bb9\uff0c\u65e0\u9700\u8fdb\u884c\u9010\u6a21\u578b\u5fae\u8c03\uff0c\u975e\u5e38\u9002\u5408\u5b9e\u9645\u90e8\u7f72\u3002"}}
{"id": "2509.10398", "categories": ["cond-mat.mes-hall", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2509.10398", "abs": "https://arxiv.org/abs/2509.10398", "authors": ["Arpan Manna", "Sunit Das", "Amit Agarwal", "Soumik Mukhopadhyay"], "title": "Disorder-driven Weyl-Kondo Semimetal Phase in WTe$_2$", "comment": "Comments are welcome", "summary": "In this Letter, we report the observation of disorder-driven anisotropic\nKondo screening and spontaneous Hall effect in bulk WTe${_2}$, a nonmagnetic\ntype-II Weyl semimetal. We show that Kondo scattering emerges more prominently\nin disordered samples and produces magnetoresistance that is strongly\nanisotropic with respect to both current and magnetic field orientation,\nreflecting the underlying type-II Weyl dispersion. Strikingly, we find a\nspontaneous Hall effect in zero magnetic field, whose magnitude is enhanced\nwith disorder, together with a large second-harmonic Hall signal exhibiting\nquadratic current scaling. Our analysis indicates that disorder-driven Kondo\ninteractions pin the Fermi level near the Weyl nodes. This enhances the Berry\ncurvature-driven nonequilibrium transport, accounting for both the second-order\nand spontaneous Hall responses. These findings establish disordered WTe${_2}$\nas a platform hosting Weyl-Kondo fermions and highlight disorder as an\neffective control knob for inducing correlated topological phases in weakly\ncorrelated Weyl semimetals.", "AI": {"tldr": "WTe2\u4e2d\u89c2\u5bdf\u5230\u65e0\u5e8f\u9a71\u52a8\u7684\u5404\u5411\u5f02\u6027Kondo\u7b5b\u5206\u548c\u81ea\u53d1\u970d\u5c14\u6548\u5e94\uff0c\u8868\u660e\u5176\u662f the Weyl-Kondo \u8d39\u7c73\u5b50\u7684\u5e73\u53f0\u3002", "motivation": "\u7814\u7a76WTe2\u7684Kondo\u6563\u5c04\u3001\u5404\u5411\u5f02\u6027\u78c1\u963b\u3001\u81ea\u53d1\u970d\u5c14\u6548\u5e94\u53ca\u5176\u4e0eWTe2\u62d3\u6251\u7279\u6027\u7684\u5173\u7cfb\u3002", "method": "\u901a\u8fc7\u5b9e\u9a8c\u89c2\u6d4b\u548c\u7406\u8bba\u5206\u6790\uff0c\u7814\u7a76\u4e86WTe2\u7684Kondo\u6563\u5c04\u3001\u78c1\u963b\u548c\u970d\u5c14\u6548\u5e94\uff0c\u5e76\u63a2\u8ba8\u4e86\u65e0\u5e8f\u6027\u5bf9\u8fd9\u4e9b\u73b0\u8c61\u7684\u5f71\u54cd\uff0c\u4ee5\u53ca\u5176\u4e0eWTe2\u7684\u62d3\u6251\u6027\u8d28\u7684\u8054\u7cfb\u3002", "result": "\u89c2\u5bdf\u5230\u65e0\u5e8f\u9a71\u52a8\u7684\u5404\u5411\u5f02\u6027Kondo\u7b5b\u5206\u548c\u81ea\u53d1\u970d\u5c14\u6548\u5e94\uff0c\u53d1\u73b0\u65e0\u5e8f\u6027\u589e\u5f3a\u4e86Kondo\u6563\u5c04\u548c\u81ea\u53d1\u970d\u5c14\u6548\u5e94\uff0c\u5e76\u63d0\u51fa\u65e0\u5e8f\u9a71\u52a8\u7684Kondo\u76f8\u4e92\u4f5c\u7528\u5c06\u8d39\u7c73\u80fd\u7ea7\u9489\u624e\u5728Weyl\u8282\u70b9\u9644\u8fd1\uff0c\u4ece\u800c\u589e\u5f3a\u4e86Berry\u66f2\u7387\u9a71\u52a8\u7684\u975e\u5e73\u8861\u8f93\u8fd0\u3002", "conclusion": "\u5df2\u5efa\u7acb\u7684\u65e0\u5e8fWTe2\u662fthe Weyl-Kondo\u8d39\u7c73\u5b50\u7684\u5e73\u53f0\uff0c\u5e76\u5f3a\u8c03\u4e86\u65e0\u5e8f\u6027\u4f5c\u4e3a\u5728\u5f31\u76f8\u5173Weyl\u534a\u91d1\u5c5e\u4e2d\u8bf1\u5bfc\u76f8\u5173\u62d3\u6251\u76f8\u7684\u6709\u6548\u63a7\u5236\u65cb\u94ae\u3002"}}
{"id": "2509.10065", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.10065", "abs": "https://arxiv.org/abs/2509.10065", "authors": ["Hauzi Cao", "Jiahao Shen", "Zhengzhen Li", "Qinquan Ren", "Shiyu Zhao"], "title": "Prespecified-Performance Kinematic Tracking Control for Aerial Manipulation", "comment": null, "summary": "This paper studies the kinematic tracking control problem for aerial\nmanipulators. Existing kinematic tracking control methods, which typically\nemploy proportional-derivative feedback or tracking-error-based feedback\nstrategies, may fail to achieve tracking objectives within specified time\nconstraints. To address this limitation, we propose a novel control framework\ncomprising two key components: end-effector tracking control based on a\nuser-defined preset trajectory and quadratic programming-based reference\nallocation. Compared with state-of-the-art approaches, the proposed method has\nseveral attractive features. First, it ensures that the end-effector reaches\nthe desired position within a preset time while keeping the tracking error\nwithin a performance envelope that reflects task requirements. Second,\nquadratic programming is employed to allocate the references of the quadcopter\nbase and the Delta arm, while considering the physical constraints of the\naerial manipulator, thus preventing solutions that may violate physical\nlimitations. The proposed approach is validated through three experiments.\nExperimental results demonstrate the effectiveness of the proposed algorithm\nand its capability to guarantee that the target position is reached within the\npreset time.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u8fd0\u52a8\u5b66\u8ddf\u8e2a\u63a7\u5236\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u65f6\u95f4\u548c\u6027\u80fd\u8981\u6c42\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u901a\u8fc7\u9884\u8bbe\u65f6\u95f4\u5185\u7684\u672b\u7aef\u6267\u884c\u5668\u8ddf\u8e2a\u548c\u57fa\u4e8e\u4e8c\u6b21\u89c4\u5212\u7684\u53c2\u8003\u5206\u914d\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u7a7a\u4e2d\u673a\u68b0\u81c2\u7684\u8ddf\u8e2a\u63a7\u5236\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u7a7a\u4e2d\u673a\u68b0\u81c2\u8fd0\u52a8\u5b66\u8ddf\u8e2a\u63a7\u5236\u65b9\u6cd5\uff08\u5982\u6bd4\u4f8b-\u5fae\u5206\u53cd\u9988\u6216\u57fa\u4e8e\u8ddf\u8e2a\u8bef\u5dee\u7684\u53cd\u9988\uff09\u53ef\u80fd\u65e0\u6cd5\u5728\u89c4\u5b9a\u7684\u65f6\u95f4\u5185\u5b9e\u73b0\u8ddf\u8e2a\u76ee\u6807\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u63a7\u5236\u6846\u67b6\uff0c\u5305\u62ec\u57fa\u4e8e\u7528\u6237\u5b9a\u4e49\u9884\u8bbe\u8f68\u8ff9\u7684\u672b\u7aef\u6267\u884c\u5668\u8ddf\u8e2a\u63a7\u5236\u548c\u57fa\u4e8e\u4e8c\u6b21\u89c4\u5212\u7684\u53c2\u8003\u5206\u914d\u3002\u8be5\u65b9\u6cd5\u786e\u4fdd\u672b\u7aef\u6267\u884c\u5668\u5728\u9884\u8bbe\u65f6\u95f4\u5185\u5230\u8fbe\u76ee\u6807\u4f4d\u7f6e\uff0c\u5e76\u5c06\u8ddf\u8e2a\u8bef\u5dee\u4fdd\u6301\u5728\u53cd\u6620\u4efb\u52a1\u9700\u6c42\u7684\u6027\u80fd\u5305\u7edc\u5185\u3002\u6b64\u5916\uff0c\u5229\u7528\u4e8c\u6b21\u89c4\u5212\u6765\u5206\u914d\u56db\u65cb\u7ffc\u57fa\u5ea7\u548cDelta\u81c2\u7684\u53c2\u8003\uff0c\u540c\u65f6\u8003\u8651\u4e86\u7a7a\u4e2d\u673a\u68b0\u81c2\u7684\u7269\u7406\u7ea6\u675f\u3002", "result": "\u901a\u8fc7\u4e09\u6b21\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u7ed3\u679c\u8868\u660e\u8be5\u7b97\u6cd5\u80fd\u591f\u4fdd\u8bc1\u5728\u9884\u8bbe\u65f6\u95f4\u5185\u5230\u8fbe\u76ee\u6807\u4f4d\u7f6e\u3002", "conclusion": "\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u7b97\u6cd5\u7684\u6709\u6548\u6027\u53ca\u5176\u5728\u9884\u8bbe\u65f6\u95f4\u5185\u5230\u8fbe\u76ee\u6807\u4f4d\u7f6e\u7684\u80fd\u529b\u3002"}}
{"id": "2509.09948", "categories": ["quant-ph", "math.CO", "math.NT"], "pdf": "https://arxiv.org/pdf/2509.09948", "abs": "https://arxiv.org/abs/2509.09948", "authors": ["Frederico Can\u00e7ado", "Gabriel Coutinho", "Thom\u00e1s Jung Spier"], "title": "Orthogonal polynomials, quantum walks and the Prouhet-Tarry-Escott problem", "comment": null, "summary": "This paper is motivated by the following problem. Define a quantum walk on a\npositively weighted path (linear chain). Can the weights be tuned so that\nperfect state transfer occurs between the first vertex and any other position?\nWe do not fully answer this question - in fact, we show that a particular case\nof this problem is equivalent to a solution of a particular case of the well\nknown Prouhet-Tarry-Escott problem, deeming our original task certainly harder\nthan anticipated. In our journey, we prove new results about sequences of\northogonal polynomials satisfying three-term recurrences. In particular, we\nprovide a full characterization of when two polynomials belong to such a\nsequence, which (as far as we were able to ascertain) was known only for when\ntheir degrees differ by one.", "AI": {"tldr": "We explore the possibility of perfect state transfer in quantum walks on weighted paths and uncover connections to the Prouhet-Tarry-Escott problem, while also deriving new characterizations of orthogonal polynomials.", "motivation": "The paper is motivated by the problem of determining if weights in a quantum walk on a path can be tuned for perfect state transfer between the first vertex and any other position.", "method": "The paper analyzes quantum walks on weighted paths and proves new results about sequences of orthogonal polynomials satisfying three-term recurrences, providing a full characterization of when two polynomials belong to such a sequence.", "result": "The paper shows that a specific case of the state transfer problem is equivalent to a case of the Prouhet-Tarry-Escott problem, indicating the problem is harder than initially thought. New characterizations for orthogonal polynomials are also presented.", "conclusion": "The paper establishes a link between quantum walks and the Prouhet-Tarry-Escott problem, and provides a comprehensive characterization of orthogonal polynomials, advancing the understanding of these mathematical structures."}}
{"id": "2509.10357", "categories": ["eess.SP", "cs.NI", "94A05, 78M31", "C.2.1; I.6.5"], "pdf": "https://arxiv.org/pdf/2509.10357", "abs": "https://arxiv.org/abs/2509.10357", "authors": ["Simon Svendsen", "Dimitri Gold", "Christian Rom", "Volker Pauli", "Vuokko Nurmela"], "title": "Realistic UE Antennas for 6G in the 3GPP Channel Model", "comment": "This is a tutorial paper with the limit of 4500 words, 6\n  Fgiures/Tables and 15 refernces", "summary": "The transition to 6G has driven significant updates to the 3GPP channel\nmodel, particularly in modeling UE antennas and user-induced blockage for\nhandheld devices. The 3GPP Rel.19 revision of TR 38.901 introduces a more\nrealistic framework that captures directive antenna patterns, practical antenna\nplacements, polarization effects, and element-specific blockage. These updates\nare based on high-fidelity simulations and measurements of a reference\nsmartphone across multiple frequency ranges. By aligning link- and system-level\nsimulations with real-world device behavior, the new model enables more\naccurate evaluation of 6G technologies and supports consistent performance\nassessment across industry and research.", "AI": {"tldr": "3GPP Rel.19 TR 38.901\u66f4\u65b0\u4e866G\u7684\u4fe1\u9053\u6a21\u578b\uff0c\u8003\u8651\u4e86\u66f4\u771f\u5b9e\u7684UE\u5929\u7ebf\u548c\u7528\u6237\u906e\u6321\uff0c\u4ee5\u63d0\u9ad86G\u6280\u672f\u8bc4\u4f30\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u4e3a\u4e86\u652f\u63016G\u6280\u672f\u7684\u53d1\u5c55\uff0c\u9700\u8981\u66f4\u65b03GPP\u4fe1\u9053\u6a21\u578b\uff0c\u4ee5\u66f4\u771f\u5b9e\u5730\u6a21\u62df\u7528\u6237\u8bbe\u5907\uff08UE\uff09\u5929\u7ebf\u548c\u7528\u6237\u5f15\u8d77\u7684\u906e\u6321\uff0c\u5c24\u5176\u662f\u5728\u624b\u6301\u8bbe\u5907\u573a\u666f\u4e0b\u3002", "method": "\u901a\u8fc7\u5bf9\u53c2\u8003\u667a\u80fd\u624b\u673a\u5728\u591a\u4e2a\u9891\u6bb5\u8fdb\u884c\u9ad8\u4fdd\u771f\u4eff\u771f\u548c\u6d4b\u91cf\uff0c\u5f15\u5165\u4e86\u5305\u542b\u5b9a\u5411\u5929\u7ebf\u65b9\u5411\u56fe\u3001\u5b9e\u9645\u5929\u7ebf\u5e03\u5c40\u3001\u6781\u5316\u6548\u5e94\u548c\u5355\u5143\u7279\u5b9a\u906e\u6321\u7684\u6846\u67b6\u3002", "result": "\u65b0\u7684\u4fe1\u9053\u6a21\u578b\u80fd\u591f\u66f4\u7cbe\u786e\u5730\u8bc4\u4f306G\u6280\u672f\uff0c\u5e76\u786e\u4fdd\u8de8\u884c\u4e1a\u548c\u7814\u7a76\u9886\u57df\u6027\u80fd\u8bc4\u4f30\u7684\u4e00\u81f4\u6027\u3002", "conclusion": "3GPP Rel.19 TR 38.901\u7684\u66f4\u65b0\u4e3a6G\u4fe1\u9053\u5efa\u6a21\u63d0\u4f9b\u4e86\u66f4\u73b0\u5b9e\u7684\u6846\u67b6\uff0c\u80fd\u591f\u66f4\u51c6\u786e\u5730\u8bc4\u4f306G\u6280\u672f\u6027\u80fd\u3002"}}
{"id": "2509.10219", "categories": ["cond-mat.mtrl-sci", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2509.10219", "abs": "https://arxiv.org/abs/2509.10219", "authors": ["Gavriel Arbiv", "Sambhu Radhakrishnan", "Alysson F. Morais", "C. Vinod Chandran", "Dries Vandenabeele", "Dirk Dom", "Karel Duerinckx", "Christine E. A. Kirschhock", "Eric Breynaert"], "title": "Competitive Adsorption of Toluene and Water in MFI-type Zeolites", "comment": null, "summary": "Competitive adsorption is a major challenge in understanding catalytic\nactivity, selectivity and reaction mechanisms in confined environments such as\nzeolites. This study investigated competitive adsorption in MFI-type zeolites\n(ZSM-5) using solid-state NMR, focusing on the interplay between toluene and\nwater. Quantitative 1H NMR spectroscopy identified three distinct populations\nof adsorbed toluene evolving with increasing toluene loading. The adsorption\nbehavior was consistent across a series of samples with Si/Al ratio ranging\nfrom 11.5 to 140. Combining 1D and 2D NMR techniques with sample engineering\n(e.g. pore-blocking) enabled the assignment of the populations to toluene\nwithin the zeolite channels, at the pore mouths, and adsorbed on the external\ncrystal surface. Crucially, introducing water to toluene-loaded zeolites caused\na partial displacement of toluene from the internal channels, but significant\nremoval from the pore mouths. This dis-placement occurred even in the highly\nhydrophobic zeolite (Si/Al = 140), where water still preferentially adsorbed to\nBr{\\o}nsted acid sites and silanol species. The results highlight the critical\nimpact that competitive adsorption from solvents, products, or impurities can\nhave on the efficiency and selectivity of zeolite-mediated transformations.", "AI": {"tldr": "\u7814\u7a76\u4e86MFI\u578b\u6cb8\u77f3\uff08ZSM-5\uff09\u4e2d\u7532\u82ef\u548c\u6c34\u7684\u7ade\u4e89\u5438\u9644\u884c\u4e3a\uff0c\u53d1\u73b0\u6c34\u4f1a\u53d6\u4ee3\u6cb8\u77f3\u5185\u90e8\u548c\u5b54\u53e3\u5438\u9644\u7684\u7532\u82ef\uff0c\u5373\u4f7f\u5728\u758f\u6c34\u6027\u6cb8\u77f3\u4e2d\u4e5f\u662f\u5982\u6b64\uff0c\u51f8\u663e\u4e86\u7ade\u4e89\u5438\u9644\u5bf9\u6cb8\u77f3\u50ac\u5316\u6548\u7387\u7684\u5f71\u54cd\u3002", "motivation": "\u4e3a\u4e86\u7406\u89e3\u6cb8\u77f3\u50ac\u5316\u6d3b\u6027\u3001\u9009\u62e9\u6027\u548c\u53cd\u5e94\u673a\u7406\uff0c\u9700\u8981\u89e3\u51b3\u7ade\u4e89\u5438\u9644\u8fd9\u4e00\u4e3b\u8981\u6311\u6218\u3002", "method": "\u91c7\u7528\u56fa\u6001\u6838\u78c1\u5171\u632f\uff08NMR\uff09\u6280\u672f\uff0c\u7ed3\u5408\u5b9a\u91cf1H NMR\u30011D\u548c2D NMR\u4ee5\u53ca\u6837\u54c1\u5de5\u7a0b\uff08\u5982\u5b54\u9053\u963b\u585e\uff09\uff0c\u7814\u7a76\u4e86\u4e0d\u540c\u7845\u94dd\u6bd4\u7684ZSM-5\u6cb8\u77f3\u4e2d\u7532\u82ef\u7684\u5438\u9644\u884c\u4e3a\uff0c\u5e76\u5f15\u5165\u6c34\u89c2\u5bdf\u5176\u5bf9\u7532\u82ef\u5438\u9644\u7684\u5f71\u54cd\u3002", "result": "\u786e\u5b9a\u4e86\u6cb8\u77f3\u5185\u90e8\u3001\u5b54\u53e3\u548c\u5916\u90e8\u8868\u9762\u5438\u9644\u7684\u4e09\u79cd\u4e0d\u540c\u7532\u82ef\u7fa4\u4f53\u3002\u7ed3\u679c\u8868\u660e\uff0c\u6c34\u7684\u5f15\u5165\u4f1a\u53d6\u4ee3\u6cb8\u77f3\u5185\u90e8\u548c\u5b54\u53e3\u5438\u9644\u7684\u7532\u82ef\uff0c\u5e76\u4e14\u8fd9\u79cd\u53d6\u4ee3\u5728\u758f\u6c34\u6027\u6cb8\u77f3\u4e2d\u4e5f\u5b58\u5728\uff0c\u6c34\u4f18\u5148\u5438\u9644\u5728\u5e03\u6717\u65af\u53f0\u9178\u4f4d\u548c\u7845\u9187\u7269\u79cd\u4e0a\u3002", "conclusion": "\u7ade\u4e89\u5438\u9644\uff08\u4f8b\u5982\u6765\u81ea\u6eb6\u5242\u3001\u4ea7\u7269\u6216\u6742\u8d28\uff09\u5bf9\u6cb8\u77f3\u4ecb\u5bfc\u7684\u8f6c\u5316\u6548\u7387\u548c\u9009\u62e9\u6027\u6709\u5173\u952e\u5f71\u54cd\u3002"}}
{"id": "2509.09711", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09711", "abs": "https://arxiv.org/abs/2509.09711", "authors": ["Aya E. Fouda", "Abdelrahamn A. Hassan", "Radwa J. Hanafy", "Mohammed E. Fouda"], "title": "Psychiatry-Bench: A Multi-Task Benchmark for LLMs in Psychiatry", "comment": null, "summary": "Large language models (LLMs) hold great promise in enhancing psychiatric\npractice, from improving diagnostic accuracy to streamlining clinical\ndocumentation and therapeutic support. However, existing evaluation resources\nheavily rely on small clinical interview corpora, social media posts, or\nsynthetic dialogues, which limits their clinical validity and fails to capture\nthe full complexity of psychiatric reasoning. In this work, we introduce\nPsychiatryBench, a rigorously curated benchmark grounded exclusively in\nauthoritative, expert-validated psychiatric textbooks and casebooks.\nPsychiatryBench comprises eleven distinct question-answering tasks ranging from\ndiagnostic reasoning and treatment planning to longitudinal follow-up,\nmanagement planning, clinical approach, sequential case analysis, and\nmultiple-choice/extended matching formats totaling over 5,300 expert-annotated\nitems. We evaluate a diverse set of frontier LLMs (including Google Gemini,\nDeepSeek, LLaMA 3, and QWQ-32) alongside leading open-source medical models\n(e.g., OpenBiloLLM, MedGemma) using both conventional metrics and an\n\"LLM-as-judge\" similarity scoring framework. Our results reveal substantial\ngaps in clinical consistency and safety, particularly in multi-turn follow-up\nand management tasks, underscoring the need for specialized model tuning and\nmore robust evaluation paradigms. PsychiatryBench offers a modular, extensible\nplatform for benchmarking and improving LLM performance in high-stakes mental\nhealth applications.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86PsychiatryBench\uff0c\u4e00\u4e2a\u57fa\u4e8e\u7cbe\u795e\u75c5\u5b66\u6559\u79d1\u4e66\u548c\u6848\u4f8b\u96c6\u7684\u5168\u9762\u8bc4\u4f30\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7cbe\u795e\u75c5\u5b66\u9886\u57df\u7684\u8868\u73b0\uff0c\u5e76\u63ed\u793a\u4e86\u73b0\u6709\u6a21\u578b\u5728\u4e34\u5e8a\u4e00\u81f4\u6027\u548c\u5b89\u5168\u6027\u65b9\u9762\u5b58\u5728\u7684\u663e\u8457\u5dee\u8ddd\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8bc4\u4f30\u8d44\u6e90\u5728\u4e34\u5e8a\u6709\u6548\u6027\u548c\u771f\u5b9e\u6027\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u672a\u80fd\u5145\u5206\u6355\u6349\u7cbe\u795e\u75c5\u5b66\u63a8\u7406\u7684\u590d\u6742\u6027\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u540d\u4e3aPsychiatryBench\u7684\u8bc4\u4f30\u57fa\u51c6\uff0c\u8be5\u57fa\u51c6\u5b8c\u5168\u57fa\u4e8e\u6743\u5a01\u3001\u4e13\u5bb6\u9a8c\u8bc1\u7684\u7cbe\u795e\u75c5\u5b66\u6559\u79d1\u4e66\u548c\u6848\u4f8b\u96c6\uff0c\u5305\u542b\u5341\u4e00\u4e2a\u4e0d\u540c\u7684\u95ee\u7b54\u4efb\u52a1\uff0c\u603b\u8ba1\u8d85\u8fc75300\u4e2a\u4e13\u5bb6\u6ce8\u91ca\u9879\u76ee\u3002\u7814\u7a76\u8bc4\u4f30\u4e86\u5305\u62ecGemini\u3001LLaMA 3\u7b49\u5728\u5185\u7684\u591a\u79cd\u524d\u6cbfLLMs\u548c\u5f00\u6e90\u533b\u5b66\u6a21\u578b\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff0c\u5728\u4e34\u5e8a\u4e00\u81f4\u6027\u548c\u5b89\u5168\u6027\u65b9\u9762\uff0c\u5c24\u5176\u662f\u5728\u591a\u8f6e\u968f\u8bbf\u548c\u7ba1\u7406\u4efb\u52a1\u4e2d\uff0c\u6a21\u578b\u8868\u73b0\u5b58\u5728\u663e\u8457\u4e0d\u8db3\uff0c\u51f8\u663e\u4e86\u8fdb\u884c\u4e13\u95e8\u6a21\u578b\u5fae\u8c03\u548c\u5f00\u53d1\u66f4\u9c81\u68d2\u8bc4\u4f30\u8303\u5f0f\u7684\u5fc5\u8981\u6027\u3002", "conclusion": "PsychiatryBench\u4e3a\u8bc4\u4f30\u548c\u6539\u8fdb\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7cbe\u795e\u5065\u5eb7\u7b49\u9ad8\u98ce\u9669\u9886\u57df\u7684\u6027\u80fd\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6a21\u5757\u5316\u3001\u53ef\u6269\u5c55\u7684\u5e73\u53f0\uff0c\u5e76\u6307\u51fa\u4e86\u5f53\u524d\u6a21\u578b\u5728\u4e34\u5e8a\u5e94\u7528\u4e2d\u4ecd\u9700\u89e3\u51b3\u7684\u5173\u952e\u95ee\u9898\u3002"}}
{"id": "2509.09864", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.09864", "abs": "https://arxiv.org/abs/2509.09864", "authors": ["Jenny Y. Huang", "Mehul Damani", "Yousef El-Kurdi", "Ramon Astudillo", "Wei Sun"], "title": "Latency and Token-Aware Test-Time Compute", "comment": null, "summary": "Inference-time scaling has emerged as a powerful way to improve large\nlanguage model (LLM) performance by generating multiple candidate responses and\nselecting among them. However, existing work on dynamic allocation for\ntest-time compute typically considers only parallel generation methods such as\nbest-of-N, overlooking incremental decoding methods like beam search, and has\nlargely ignored latency, focusing only on token usage. We formulate\ninference-time scaling as a problem of dynamic compute allocation and method\nselection, where the system must decide which strategy to apply and how much\ncompute to allocate on a per-query basis. Our framework explicitly incorporates\nboth token cost and wall-clock latency, the latter being critical for user\nexperience and particularly for agentic workflows where models must issue\nmultiple queries efficiently. Experiments on reasoning benchmarks show that our\napproach consistently outperforms static strategies, achieving favorable\naccuracy-cost trade-offs while remaining practical for deployment.", "AI": {"tldr": "\u73b0\u6709\u6a21\u578b\u5728\u8fdb\u884c\u63a8\u7406\u65f6\uff0c\u901a\u5e38\u53ea\u8003\u8651\u5e76\u884c\u751f\u6210\u65b9\u6cd5\uff0c\u800c\u5ffd\u7565\u4e86\u589e\u91cf\u5f0f\u89e3\u7801\u65b9\u6cd5\uff0c\u5e76\u4e14\u4e3b\u8981\u5173\u6ce8token\u4f7f\u7528\u91cf\uff0c\u800c\u5ffd\u7565\u4e86\u5ef6\u8fdf\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u63a8\u7406\u65f6\u95f4\u6269\u5c55\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5c06\u63a8\u7406\u65f6\u95f4\u6269\u5c55\u89c6\u4e3a\u4e00\u4e2a\u52a8\u6001\u8ba1\u7b97\u5206\u914d\u548c\u65b9\u6cd5\u9009\u62e9\u95ee\u9898\uff0c\u53ef\u4ee5\u6839\u636e\u6bcf\u6b21\u67e5\u8be2\u7684\u9700\u8981\u52a8\u6001\u5730\u51b3\u5b9a\u91c7\u7528\u54ea\u79cd\u7b56\u7565\u4ee5\u53ca\u5206\u914d\u591a\u5c11\u8ba1\u7b97\u8d44\u6e90\u3002\u8be5\u6846\u67b6\u540c\u65f6\u8003\u8651\u4e86token\u6210\u672c\u548c\u5b9e\u9645\u7684\u8fd0\u884c\u65f6\u95f4\u5ef6\u8fdf\uff0c\u8fd9\u5bf9\u4e8e\u7528\u6237\u4f53\u9a8c\u548cagentic\u5de5\u4f5c\u6d41\u81f3\u5173\u91cd\u8981\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u63a8\u7406\u6548\u7387\u548c\u51c6\u786e\u6027\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u7684\u5e73\u8861\uff0c\u4f18\u4e8e\u9759\u6001\u7b56\u7565\u3002", "motivation": "\u73b0\u6709\u7684\u63a8\u7406\u65f6\u95f4\u6269\u5c55\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u5e76\u884c\u751f\u6210\uff0c\u5ffd\u7565\u4e86\u589e\u91cf\u5f0f\u89e3\u7801\uff0c\u5e76\u4e14\u4e3b\u8981\u8003\u8651token\u4f7f\u7528\u91cf\u800c\u975e\u5ef6\u8fdf\uff0c\u8fd9\u4e0d\u80fd\u6ee1\u8db3\u5b9e\u9645\u5e94\u7528\u9700\u6c42\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u5feb\u901f\u54cd\u5e94\u7684agentic\u5de5\u4f5c\u6d41\u4e2d\u3002", "method": "\u5c06\u63a8\u7406\u65f6\u95f4\u6269\u5c55\u95ee\u9898\u5efa\u6a21\u4e3a\u52a8\u6001\u8ba1\u7b97\u5206\u914d\u548c\u65b9\u6cd5\u9009\u62e9\u95ee\u9898\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u6839\u636e\u6bcf\u4e2a\u67e5\u8be2\u7684\u9700\u8981\u52a8\u6001\u5730\u9009\u62e9\u6700\u5408\u9002\u7684\u751f\u6210\u7b56\u7565\uff08\u5305\u62ec\u5e76\u884c\u548c\u589e\u91cf\u5f0f\u89e3\u7801\uff09\u5e76\u5206\u914d\u76f8\u5e94\u7684\u8ba1\u7b97\u8d44\u6e90\u3002\u8be5\u6846\u67b6\u540c\u65f6\u8003\u8651\u4e86token\u6210\u672c\u548c\u5b9e\u9645\u7684\u8fd0\u884c\u65f6\u95f4\u5ef6\u8fdf\u3002", "result": "\u5728\u63a8\u7406\u6548\u7387\u548c\u51c6\u786e\u6027\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u7684\u5e73\u8861\uff0c\u4f18\u4e8e\u9759\u6001\u7b56\u7565\uff0c\u5e76\u4e14\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u5177\u6709\u53ef\u884c\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u52a8\u6001\u8ba1\u7b97\u5206\u914d\u548c\u65b9\u6cd5\u9009\u62e9\u6846\u67b6\u80fd\u591f\u6709\u6548\u63d0\u5347LLM\u5728\u63a8\u7406\u65f6\u7684\u6027\u80fd\uff0c\u901a\u8fc7\u540c\u65f6\u8003\u8651token\u6210\u672c\u548c\u5ef6\u8fdf\uff0c\u5b9e\u73b0\u4e86\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u597d\u7684\u51c6\u786e\u6027-\u6210\u672c\u6743\u8861\uff0c\u5e76\u80fd\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u6709\u6548\u90e8\u7f72\u3002"}}
{"id": "2509.10018", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10018", "abs": "https://arxiv.org/abs/2509.10018", "authors": ["Hailong Yang", "Renhuo Zhao", "Guanjin Wang", "Zhaohong Deng"], "title": "GAMA: A General Anonymizing Multi-Agent System for Privacy Preservation Enhanced by Domain Rules and Disproof Method", "comment": null, "summary": "With the rapid advancement of Large Language Model (LLM), LLM-based agents\nexhibit exceptional abilities in understanding and generating natural language,\nfacilitating human-like collaboration and information transmission in LLM-based\nMulti-Agent System (MAS). High-performance LLMs are often hosted on remote\nservers in public spaces. When tasks involve privacy data, MAS cannot securely\nutilize these LLMs without implementing privacy-preserving mechanisms. To\naddress this challenge, we propose a General Anonymizing Multi-Agent system\n(GAMA), which divides the agents' workspace into private and public spaces and\nprotects privacy through the anonymizing mechanism. In the private space,\nagents handle sensitive data, while in the public space, only anonymized data\nis utilized. GAMA incorporates two key modules to mitigate semantic loss caused\nby anonymization: Domain-Rule-based Knowledge Enhancement (DRKE) and\nDisproof-based Logic Enhancement (DLE). We evaluate GAMA on two public\nquestion-answering datasets: Trivia Creative Writing and Logic Grid Puzzle. The\nresults demonstrate that GAMA has superior performance compared to the\nstate-of-the-art models. To further assess its privacy-preserving capabilities,\nwe designed two new datasets: Knowledge Privacy Preservation and Logic Privacy\nPreservation. The final results highlight GAMA's exceptional effectiveness in\nboth task processing and privacy preservation.", "AI": {"tldr": "GAMA\u7cfb\u7edf\u901a\u8fc7\u5c06\u4ee3\u7406\u5de5\u4f5c\u533a\u5212\u5206\u4e3a\u79c1\u6709\u548c\u516c\u5171\u7a7a\u95f4\uff0c\u5e76\u7ed3\u5408DRKE\u548cDLE\u6a21\u5757\uff0c\u6709\u6548\u5730\u5728\u5229\u7528\u8fdc\u7a0b\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u591a\u4ee3\u7406\u7cfb\u7edf\u4efb\u52a1\u7684\u540c\u65f6\u4fdd\u62a4\u4e86\u9690\u79c1\u3002", "motivation": "\u4e3a\u4e86\u5728\u5904\u7406\u9690\u79c1\u6570\u636e\u65f6\u5b89\u5168\u5730\u5229\u7528\u8fdc\u7a0b\u6258\u7ba1\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8fdb\u884c\u591a\u4ee3\u7406\u7cfb\u7edf\uff08MAS\uff09\u4efb\u52a1\uff0c\u9700\u8981\u5f15\u5165\u9690\u79c1\u4fdd\u62a4\u673a\u5236\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGAMA\uff08General Anonymizing Multi-Agent system\uff09\u7684\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u5c06\u4ee3\u7406\u5de5\u4f5c\u533a\u5206\u9694\u4e3a\u79c1\u6709\u548c\u516c\u5171\u7a7a\u95f4\uff0c\u5e76\u901a\u8fc7\u533f\u540d\u5316\u673a\u5236\u4fdd\u62a4\u9690\u79c1\u3002GAMA\u5305\u542b\u4e24\u4e2a\u5173\u952e\u6a21\u5757\uff1a\u57fa\u4e8e\u9886\u57df\u89c4\u5219\u7684\u77e5\u8bc6\u589e\u5f3a\uff08DRKE\uff09\u548c\u57fa\u4e8e\u5426\u8bc1\u7684\u903b\u8f91\u589e\u5f3a\uff08DLE\uff09\uff0c\u4ee5\u51cf\u5c11\u533f\u540d\u5316\u9020\u6210\u7684\u8bed\u4e49\u635f\u5931\u3002", "result": "\u5728Trivia Creative Writing\u548cLogic Grid Puzzle\u4e24\u4e2a\u516c\u5f00\u95ee\u7b54\u6570\u636e\u96c6\u4e0a\uff0cGAMA\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002\u5728\u4e3a\u8bc4\u4f30\u9690\u79c1\u4fdd\u62a4\u80fd\u529b\u800c\u8bbe\u8ba1\u7684Knowledge Privacy Preservation\u548cLogic Privacy Preservation\u4e24\u4e2a\u65b0\u6570\u636e\u96c6\u4e0a\uff0cGAMA\u5728\u4efb\u52a1\u5904\u7406\u548c\u9690\u79c1\u4fdd\u62a4\u65b9\u9762\u5747\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "GAMA\u7cfb\u7edf\u5728\u4fdd\u62a4\u591a\u4ee3\u7406\u7cfb\u7edf\u4efb\u52a1\u4e2d\u7684\u6570\u636e\u9690\u79c1\u65b9\u9762\u975e\u5e38\u6709\u6548\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u9ad8\u8d28\u91cf\u7684\u4efb\u52a1\u5904\u7406\u80fd\u529b\u3002"}}
{"id": "2509.10154", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.10154", "abs": "https://arxiv.org/abs/2509.10154", "authors": ["Johannes van Randenborgh", "Moritz Schulze Darup"], "title": "MPC for Aquifer Thermal Energy Storage Systems Using ARX Models", "comment": "16th INDUSCON 2025 in Sao Sebastiao, Brazil", "summary": "An aquifer thermal energy storage (ATES) can mitigate CO2 emissions of\nheating, ventilation, and air conditioning (HVAC) systems for buildings. In\napplication, an ATES keeps large quantities of thermal energy in\ngroundwater-saturated aquifers. Normally, an ATES system comprises two (one for\nheat and one for cold) storages and supports the heating and cooling efforts of\nsimultaneously present HVAC system components. This way, the operation and\nemissions of installed and, usually, fossil fuel-based components are reduced.\n  The control of ATES systems is challenging, and various control schemes,\nincluding model predictive control (MPC), have been proposed. In this context,\nwe present a lightweight input-output-data-based autoregressive with exogenous\ninput (ARX) model of the hybrid ATES system dynamics. The ARX model allows the\ndesign of an output-based MPC scheme, resulting in an easy-to-solve quadratic\nprogram and avoiding challenging state estimations of ground temperatures. A\nnumerical study discusses the accuracy of the ARX predictor and controller\nperformance.", "AI": {"tldr": "ATES\u7cfb\u7edf\u53ef\u4ee5\u901a\u8fc7\u5728\u5730\u5c42\u6c34\u4f53\u4e2d\u50a8\u5b58\u70ed\u80fd\u6765\u51cf\u5c11\u5efa\u7b51\u6696\u901a\u7a7a\u8c03\u7cfb\u7edf\u7684\u78b3\u6392\u653e\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eARX\u6a21\u578b\u7684\u8f7b\u91cf\u7ea7\u63a7\u5236\u65b9\u6848\uff0c\u7528\u4e8e\u7ba1\u7406ATES\u7cfb\u7edf\uff0c\u8be5\u65b9\u6848\u907f\u514d\u4e86\u5bf9\u5730\u4e0b\u6e29\u5ea6\u8fdb\u884c\u72b6\u6001\u4f30\u8ba1\uff0c\u4ece\u800c\u7b80\u5316\u4e86\u6a21\u578b\u9884\u6d4b\u63a7\u5236\uff08MPC\uff09\u7684\u8bbe\u8ba1\u3002", "motivation": "ATES\u7cfb\u7edf\u5728\u51cf\u5c11\u5efa\u7b51\u6696\u901a\u7a7a\u8c03\u7cfb\u7edf\u78b3\u6392\u653e\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u5176\u63a7\u5236\u5177\u6709\u6311\u6218\u6027\u3002\u9700\u8981\u4e00\u79cd\u7b80\u5316\u7684\u63a7\u5236\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u3001\u57fa\u4e8e\u8f93\u5165\u8f93\u51fa\u6570\u636e\u7684\u81ea\u56de\u5f52\u6a21\u578b\uff08ARX\uff09\uff0c\u7528\u4e8e\u6a21\u62df\u6df7\u5408ATES\u7cfb\u7edf\u7684\u52a8\u6001\u3002\u5229\u7528ARX\u6a21\u578b\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u8f93\u51fa\u7684MPC\u65b9\u6848\uff0c\u8be5\u65b9\u6848\u53ef\u4ee5\u7b80\u5316\u4e3a\u6613\u4e8e\u6c42\u89e3\u7684\u4e8c\u6b21\u89c4\u5212\u95ee\u9898\uff0c\u5e76\u907f\u514d\u4e86\u5bf9\u5730\u9762\u6e29\u5ea6\u8fdb\u884c\u72b6\u6001\u4f30\u8ba1\u3002", "result": "\u8fdb\u884c\u4e86\u6570\u503c\u7814\u7a76\uff0c\u8ba8\u8bba\u4e86ARX\u9884\u6d4b\u5668\u7684\u51c6\u786e\u6027\u548c\u63a7\u5236\u5668\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8eARX\u6a21\u578b\u7684MPC\u65b9\u6848\u4e3aATES\u7cfb\u7edf\u7684\u63a7\u5236\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5316\u4e14\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u907f\u514d\u4e86\u590d\u6742\u7684\u72b6\u6001\u4f30\u8ba1\u3002"}}
{"id": "2509.09808", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.09808", "abs": "https://arxiv.org/abs/2509.09808", "authors": ["Judith Massmann", "Alexander Lichtenstein", "Francisco M. L\u00f3pez"], "title": "Early Detection of Visual Impairments at Home Using a Smartphone Red-Eye Reflex Test", "comment": "Accepted at IEEE ICDL 2025. 6 pages, 7 figures, 2 tables", "summary": "Numerous visual impairments can be detected in red-eye reflex images from\nyoung children. The so-called Bruckner test is traditionally performed by\nophthalmologists in clinical settings. Thanks to the recent technological\nadvances in smartphones and artificial intelligence, it is now possible to\nrecreate the Bruckner test using a mobile device. In this paper, we present a\nfirst study conducted during the development of KidsVisionCheck, a free\napplication that can perform vision screening with a mobile device using\nred-eye reflex images. The underlying model relies on deep neural networks\ntrained on children's pupil images collected and labeled by an ophthalmologist.\nWith an accuracy of 90% on unseen test data, our model provides highly reliable\nperformance without the necessity of specialist equipment. Furthermore, we can\nidentify the optimal conditions for data collection, which can in turn be used\nto provide immediate feedback to the users. In summary, this work marks a first\nstep toward accessible pediatric vision screenings and early intervention for\nvision abnormalities worldwide.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4ecb\u7ecd\u4e86\u4e00\u6b3e\u540d\u4e3aKidsVisionCheck\u7684\u514d\u8d39\u5e94\u7528\u7a0b\u5e8f\uff0c\u8be5\u7a0b\u5e8f\u5229\u7528\u667a\u80fd\u624b\u673a\u548c\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff0c\u901a\u8fc7\u7ea2\u773c\u53cd\u5c04\u56fe\u50cf\u5bf9\u513f\u7ae5\u8fdb\u884c\u89c6\u529b\u7b5b\u67e5\uff0c\u51c6\u786e\u7387\u8fbe\u523090%\uff0c\u6709\u671b\u5b9e\u73b0\u5168\u7403\u8303\u56f4\u5185\u4fbf\u6377\u7684\u513f\u7ae5\u89c6\u529b\u7b5b\u67e5\u548c\u65e9\u671f\u5e72\u9884\u3002", "motivation": "\u8bb8\u591a\u89c6\u89c9\u969c\u788d\u53ef\u4ee5\u5728\u5e7c\u513f\u7684\u7ea2\u773c\u53cd\u5c04\u56fe\u50cf\u4e2d\u88ab\u68c0\u6d4b\u5230\u3002\u4f20\u7edf\u7684Bruckner\u6d4b\u8bd5\u9700\u8981\u5728\u4e34\u5e8a\u73af\u5883\u4e2d\u7531\u773c\u79d1\u533b\u751f\u8fdb\u884c\u3002\u7531\u4e8e\u667a\u80fd\u624b\u673a\u548c\u4eba\u5de5\u667a\u80fd\u6280\u672f\u7684\u8fdb\u6b65\uff0c\u73b0\u5728\u53ef\u4ee5\u4f7f\u7528\u79fb\u52a8\u8bbe\u5907\u91cd\u65b0\u521b\u5efaBruckner\u6d4b\u8bd5\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u6b3e\u540d\u4e3aKidsVisionCheck\u7684\u514d\u8d39\u5e94\u7528\u7a0b\u5e8f\uff0c\u5229\u7528\u667a\u80fd\u624b\u673a\u548c\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff0c\u5bf9\u773c\u79d1\u533b\u751f\u6536\u96c6\u548c\u6807\u8bb0\u7684\u513f\u7ae5\u77b3\u5b54\u56fe\u50cf\u8fdb\u884c\u8bad\u7ec3\uff0c\u4ee5\u8fdb\u884c\u89c6\u529b\u7b5b\u67e5\u3002", "result": "\u8be5\u6a21\u578b\u5728\u672a\u89c1\u8fc7\u7684\u6570\u636e\u4e0a\u8fbe\u5230\u4e8690%\u7684\u51c6\u786e\u7387\uff0c\u65e0\u9700\u4e13\u4e1a\u8bbe\u5907\u5373\u53ef\u63d0\u4f9b\u9ad8\u5ea6\u53ef\u9760\u7684\u6027\u80fd\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u786e\u5b9a\u4e86\u6570\u636e\u6536\u96c6\u7684\u6700\u4f73\u6761\u4ef6\uff0c\u5e76\u80fd\u4e3a\u7528\u6237\u63d0\u4f9b\u5373\u65f6\u53cd\u9988\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u662f\u5b9e\u73b0\u53ef\u53ca\u7684\u513f\u7ae5\u89c6\u529b\u7b5b\u67e5\u548c\u5168\u7403\u8303\u56f4\u5185\u89c6\u529b\u5f02\u5e38\u65e9\u671f\u5e72\u9884\u7684\u7b2c\u4e00\u6b65\u3002"}}
{"id": "2509.10096", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.10096", "abs": "https://arxiv.org/abs/2509.10096", "authors": ["Saeed Saadatnejad", "Reyhaneh Hosseininejad", "Jose Barreiros", "Katherine M. Tsui", "Alexandre Alahi"], "title": "HHI-Assist: A Dataset and Benchmark of Human-Human Interaction in Physical Assistance Scenario", "comment": "Accepted to RA-L 2025", "summary": "The increasing labor shortage and aging population underline the need for\nassistive robots to support human care recipients. To enable safe and\nresponsive assistance, robots require accurate human motion prediction in\nphysical interaction scenarios. However, this remains a challenging task due to\nthe variability of assistive settings and the complexity of coupled dynamics in\nphysical interactions. In this work, we address these challenges through two\nkey contributions: (1) HHI-Assist, a dataset comprising motion capture clips of\nhuman-human interactions in assistive tasks; and (2) a conditional\nTransformer-based denoising diffusion model for predicting the poses of\ninteracting agents. Our model effectively captures the coupled dynamics between\ncaregivers and care receivers, demonstrating improvements over baselines and\nstrong generalization to unseen scenarios. By advancing interaction-aware\nmotion prediction and introducing a new dataset, our work has the potential to\nsignificantly enhance robotic assistance policies. The dataset and code are\navailable at: https://sites.google.com/view/hhi-assist/home", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86HHI-Assist\u6570\u636e\u96c6\u548c\u4e00\u4e2a\u57fa\u4e8eTransformer\u7684\u53bb\u566a\u6269\u6563\u6a21\u578b\uff0c\u7528\u4e8e\u9884\u6d4b\u673a\u5668\u4eba\u8f85\u52a9\u573a\u666f\u4e2d\u4eba\u4e0e\u4eba\u4e4b\u95f4\u7684\u4ea4\u4e92\u8fd0\u52a8\u3002", "motivation": "\u7531\u4e8e\u52b3\u52a8\u529b\u77ed\u7f3a\u548c\u4eba\u53e3\u8001\u9f84\u5316\uff0c\u9700\u8981\u673a\u5668\u4eba\u6765\u8f85\u52a9\u8001\u5e74\u4eba\u548c\u6b8b\u75be\u4eba\uff0c\u4f46\u76ee\u524d\u673a\u5668\u4eba\u5b89\u5168\u6709\u6548\u5730\u8fdb\u884c\u7269\u7406\u4ea4\u4e92\u4ecd\u7136\u662f\u4e00\u4e2a\u6311\u6218\u3002", "method": "\u901a\u8fc7\u6536\u96c6\u5305\u542b\u8f85\u52a9\u4efb\u52a1\u4e2d\u4eba\u4e0e\u4eba\u4ea4\u4e92\u7684\u8fd0\u52a8\u6355\u6349\u6570\u636e\uff0c\u6784\u5efa\u4e86HHI-Assist\u6570\u636e\u96c6\u3002\u5728\u6b64\u57fa\u7840\u4e0a\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u6761\u4ef6Transformer\u53bb\u566a\u6269\u6563\u6a21\u578b\u6765\u9884\u6d4b\u4ea4\u4e92\u4e2a\u4f53\u7684\u59ff\u52bf\u3002", "result": "\u8be5\u6a21\u578b\u80fd\u591f\u6709\u6548\u6355\u6349\u4ea4\u4e92\u4e2d\u7684\u8026\u5408\u52a8\u529b\u5b66\uff0c\u5e76\u5728\u672a\u89c1\u8fc7\u7684\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u63d0\u4f9b\u65b0\u7684\u6570\u636e\u96c6\u548c\u6539\u8fdb\u7684\u4ea4\u4e92\u611f\u77e5\u8fd0\u52a8\u9884\u6d4b\u65b9\u6cd5\uff0c\u6709\u671b\u663e\u8457\u63d0\u5347\u673a\u5668\u4eba\u8f85\u52a9\u7b56\u7565\u7684\u6027\u80fd\u3002"}}
{"id": "2509.09993", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2509.09993", "abs": "https://arxiv.org/abs/2509.09993", "authors": ["Jiaming Shi", "Nikita Leppenen", "Ran Tessler", "Alexander N. Poddubny"], "title": "No oscillating subradiant correlations in a strongly driven quantum emitter array", "comment": "6 pages, 3 figures + End Matter", "summary": "We theoretically study time-dependent correlations in a strongly driven array\nof $N$ two-level atoms, coupled to photons in a waveguide. We focus on the\nspectrum $\\{\\lambda\\}$ of the Liouvillian superoperator, which determines the\ncorrelation decay rates $-\\Re \\lambda$ and the frequencies $\\Im\\lambda$. Our\nmain finding is the suppression of subradiant oscillating correlations between\natomic states by a strong coherent of amplitude $\\Omega$: $|\\Re \\lambda|\\ge\nm\\gamma/2$, where $\\gamma$ is the single-atom spontaneous decay rate and\n$m=|\\Im \\lambda/(2\\Omega)|$ is a nonzero integer for correlations oscillating\nin time $\\propto \\exp(\\pm 2i m|\\Omega| t)$. This limit is independent of the\nnumber of atoms $N$; it holds both for small arrays and in the macroscopic\nlimit. We demonstrate the suppression of subradiance numerically and provide a\nrigorous proof based on the analytical decomposition of the Liouvillian using\nspectral theory of simplicial complexes and posets.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2509.10433", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.10433", "abs": "https://arxiv.org/abs/2509.10433", "authors": ["Junshi Chen", "Xuhong Li", "Russ Whiton", "Erik Leitinger", "Fredrik Tufvesson"], "title": "Robust Localization in Modern Cellular Networks using Global Map Features", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Radio frequency (RF) signal-based localization using modern cellular networks\nhas emerged as a promising solution to accurately locate objects in challenging\nenvironments. One of the most promising solutions for situations involving\nobstructed-line-of-sight (OLoS) and multipath propagation is multipathbased\nsimultaneous localization and mapping (MP-SLAM) that employs map features\n(MFs), such as virtual anchors. This paper presents an extended MP-SLAM method\nthat is augmented with a global map feature (GMF) repository. This repository\nstores consistent MFs of high quality that are collected during prior\ntraversals. We integrate these GMFs back into the MP-SLAM framework via a\nprobability hypothesis density (PHD) filter, which propagates GMF intensity\nfunctions over time. Extensive simulations, together with a challenging\nreal-world experiment using LTE RF signals in a dense urban scenario with\nsevere multipath propagation and inter-cell interference, demonstrate that our\nframework achieves robust and accurate localization, thereby showcasing its\neffectiveness in realistic modern cellular networks such as 5G or future 6G\nnetworks. It outperforms conventional proprioceptive sensor-based localization\nand conventional MP-SLAM methods, and achieves reliable localization even under\nadverse signal conditions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u589e\u5f3a\u578b\u591a\u8def\u5f84\u540c\u6b65\u5b9a\u4f4d\u4e0e\u5730\u56fe\u6784\u5efa\uff08MP-SLAM\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u5168\u5c40\u5730\u56fe\u7279\u5f81\uff08GMF\uff09\u5e93\uff0c\u5229\u7528\u6982\u7387\u5047\u8bbe\u5bc6\u5ea6\uff08PHD\uff09\u6ee4\u6ce2\u5668\u878d\u5408\u5386\u53f2\u6570\u636e\uff0c\u63d0\u9ad8\u4e86\u5728\u590d\u6742\u57ce\u5e02\u73af\u5883\uff08\u59825G/6G\u7f51\u7edc\uff09\u4e0b\u7684\u5b9a\u4f4d\u9c81\u68d2\u6027\u548c\u51c6\u786e\u6027\uff0c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u5728\u5b58\u5728\u89c6\u7ebf\u906e\u6321\uff08OLoS\uff09\u548c\u591a\u5f84\u4f20\u64ad\u7b49\u6311\u6218\u6027\u73af\u5883\u4e0b\uff0c\u9700\u8981\u7cbe\u786e\u7684\u5b9a\u4f4d\u6280\u672f\u3002\u591a\u5f84\u4f20\u64ad\u7684\u540c\u6b65\u5b9a\u4f4d\u4e0e\u5730\u56fe\u6784\u5efa\uff08MP-SLAM\uff09\u662f\u4e00\u79cd\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u5176\u6027\u80fd\u53ef\u8fdb\u4e00\u6b65\u63d0\u5347\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6269\u5c55\u7684MP-SLAM\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u96c6\u6210\u4e86\u4e00\u4e2a\u5168\u5c40\u5730\u56fe\u7279\u5f81\uff08GMF\uff09\u5e93\uff0c\u5176\u4e2d\u5b58\u50a8\u4e86\u9ad8\u8d28\u91cf\u3001\u4e00\u81f4\u6027\u7684\u5730\u56fe\u7279\u5f81\u3002\u901a\u8fc7\u6982\u7387\u5047\u8bbe\u5bc6\u5ea6\uff08PHD\uff09\u6ee4\u6ce2\u5668\u5c06GMF\u91cd\u65b0\u6574\u5408\u5230MP-SLAM\u6846\u67b6\u4e2d\uff0c\u5e76\u8fdb\u884c\u65f6\u53d8\u4f20\u64ad\u3002", "result": "\u901a\u8fc7\u5e7f\u6cdb\u7684\u4eff\u771f\u548c\u771f\u5b9e\u7684LTE\u4fe1\u53f7\u5b9e\u9a8c\uff08\u5728\u5177\u6709\u4e25\u91cd\u591a\u5f84\u548c\u7f51\u7edc\u5e72\u6270\u7684\u5bc6\u96c6\u57ce\u5e02\u73af\u5883\u4e2d\uff09\uff0c\u8bc1\u660e\u4e86\u8be5\u6846\u67b6\u5728\u73b0\u4ee3\u8702\u7a9d\u7f51\u7edc\uff08\u59825G/6G\uff09\u4e2d\u5177\u6709\u9c81\u68d2\u6027\u548c\u51c6\u786e\u7684\u5b9a\u4f4d\u80fd\u529b\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8eGMF\u7684MP-SLAM\u6846\u67b6\u80fd\u591f\u5b9e\u73b0\u9c81\u68d2\u4e14\u7cbe\u786e\u7684\u5b9a\u4f4d\uff0c\u5728\u4e0d\u5229\u7684\u4fe1\u53f7\u6761\u4ef6\u4e0b\u8868\u73b0\u4f18\u5f02\uff0c\u8d85\u8fc7\u4e86\u4f20\u7edf\u7684\u57fa\u4e8e\u672c\u4f53\u611f\u89c9\u4f20\u611f\u5668\u548c\u4f20\u7edfMP-SLAM\u7684\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2509.10267", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2509.10267", "abs": "https://arxiv.org/abs/2509.10267", "authors": ["Daria I. Markina", "Priyanka Mondal", "Lukas Krelle", "Sai Shradha", "Mikhail M. Glazov", "Regine von Klitzing", "Kseniia Mosina", "Zdenek Sofer", "Bernhard Urbaszek"], "title": "Interplay of vibrational, electronic, and magnetic states in CrSBr", "comment": null, "summary": "The van der Waals antiferromagnet CrSBr exhibits coupling of vibrational,\nelectronic, and magnetic degrees of freedom, giving rise to distinctive\nquasi-particle interactions. We investigate these interactions across a wide\ntemperature range using polarization-resolved Raman spectroscopy at various\nexcitation energies, complemented by optical absorption and photoluminescence\nexcitation (PLE) spectroscopy. Under 1.96 eV excitation, we observe pronounced\nchanges in the A$_g^1$, A$_g^2$, and A$_g^3$ Raman modes near the N\\'eel\ntemperature, coinciding with modifications in the oscillator strength of\nexcitonic transitions and clear resonances in PLE. The distinct temperature\nevolution of Raman tensor elements and polarization anisotropy for Raman modes\nindicates that they couple to different excitonic and electronic states. The\nsuppression of the excitonic state's oscillation strength above the N\\'eel\ntemperature could be related to the magnetic phase transition, thereby\nconnecting these excitonic states and Raman modes to a specific spin alignment.\nThese observations make CrSBr a versatile platform for probing quasi-particle\ninteractions in low-dimensional magnets and provide insights for applications\nin quantum sensing and quantum communication.", "AI": {"tldr": "CrSBr\u662f\u4e00\u79cd\u8303\u5fb7\u534e\u53cd\u94c1\u78c1\u4f53\uff0c\u5177\u6709\u72ec\u7279\u7684\u51c6\u7c92\u5b50\u76f8\u4e92\u4f5c\u7528\uff0c\u6e90\u4e8e\u632f\u52a8\u3001\u7535\u5b50\u548c\u78c1\u81ea\u7531\u5ea6\u7684\u8026\u5408\u3002", "motivation": "\u7814\u7a76CrSBr\u4e2d\u632f\u52a8\u3001\u7535\u5b50\u548c\u78c1\u81ea\u7531\u5ea6\u8026\u5408\u6240\u4ea7\u751f\u7684\u51c6\u7c92\u5b50\u76f8\u4e92\u4f5c\u7528\u3002", "method": "\u4f7f\u7528\u504f\u632f\u5206\u8fa8\u62c9\u66fc\u5149\u8c31\uff08\u5728\u4e0d\u540c\u6fc0\u53d1\u80fd\u91cf\u548c\u8f83\u5bbd\u6e29\u5ea6\u8303\u56f4\u5185\uff09\u3001\u5149\u5b66\u5438\u6536\u5149\u8c31\u548c\u5149\u81f4\u53d1\u5149\u6fc0\u53d1\uff08PLE\uff09\u5149\u8c31\u7814\u7a76\u4e86CrSBr\u7684\u76f8\u4e92\u4f5c\u7528\u3002", "result": "\u57281.96 eV\u6fc0\u53d1\u4e0b\uff0c\u5728N\u00e9el\u6e29\u5ea6\u9644\u8fd1\u89c2\u5bdf\u5230A_g^1\u3001A_g^2\u548cA_g^3\u62c9\u66fc\u6a21\u5f0f\u7684\u663e\u8457\u53d8\u5316\uff0c\u4f34\u968f\u7740\u6fc0\u5b50\u8dc3\u8fc1\u632f\u8361\u5f3a\u5ea6\u7684\u6539\u53d8\u548cPLE\u4e2d\u7684\u6e05\u6670\u5171\u632f\u3002\u62c9\u66fc\u6a21\u5f0f\u7684\u62c9\u66fc\u5f20\u91cf\u5143\u7d20\u548c\u504f\u632f\u5404\u5411\u5f02\u6027\u7684\u4e0d\u540c\u6e29\u5ea6\u6f14\u5316\u8868\u660e\u5b83\u4eec\u4e0e\u4e0d\u540c\u7684\u6fc0\u5b50\u548c\u7535\u5b50\u6001\u8026\u5408\u3002\u6fc0\u5b50\u6001\u632f\u8361\u5f3a\u5ea6\u5728N\u00e9el\u6e29\u5ea6\u4ee5\u4e0a\u88ab\u6291\u5236\uff0c\u8fd9\u53ef\u80fd\u4e0e\u78c1\u76f8\u53d8\u6709\u5173\uff0c\u4ece\u800c\u5c06\u6fc0\u5b50\u6001\u548c\u62c9\u66fc\u6a21\u5f0f\u4e0e\u7279\u5b9a\u7684\u81ea\u65cb\u6392\u5217\u8054\u7cfb\u8d77\u6765\u3002", "conclusion": "CrSBr\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7814\u7a76\u4f4e\u7ef4\u78c1\u4f53\u4e2d\u51c6\u7c92\u5b50\u76f8\u4e92\u4f5c\u7528\u7684\u5e73\u53f0\uff0c\u5e76\u4e3a\u91cf\u5b50\u4f20\u611f\u548c\u91cf\u5b50\u901a\u4fe1\u7b49\u5e94\u7528\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2509.09712", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09712", "abs": "https://arxiv.org/abs/2509.09712", "authors": ["Talha Tahir"], "title": "The Thinking Therapist: Training Large Language Models to Deliver Acceptance and Commitment Therapy using Supervised Fine-Tuning and Odds Ratio Policy Optimization", "comment": null, "summary": "Acceptance and Commitment Therapy (ACT) is a third-wave cognitive behavioral\ntherapy with emerging evidence of efficacy in several psychiatric conditions.\nThis study investigates the impact of post-training methodology and explicit\nreasoning on the ability of a small open-weight large language model (LLM) to\ndeliver ACT. Using 50 sets of synthetic ACT transcripts generated by\nMistral-Large, we trained Llama-3.2-3b-Instruct with two distinct approaches,\nsupervised fine-tuning (SFT) and odds ratio policy optimization (ORPO), each\nwith and without an explicit chain-of-thought (COT) reasoning step. Performance\nwas evaluated by comparing these four post-trained variants against the base\nInstruct model. These models were benchmarked in simulated therapy sessions,\nwith performance quantitatively assessed on the ACT Fidelity Measure (ACT-FM)\nand the Therapist Empathy Scale (TES) by an LLM judge that had been fine-tuned\non human evaluations. Our findings demonstrate that the ORPO-trained models\nsignificantly outperformed both their SFT and Instruct counterparts on ACT\nfidelity ($\\chi^2(5) = 185.15, p < .001$) and therapeutic empathy ($\\chi^2(5) =\n140.37, p < .001$). The effect of COT was conditional as it provided a\nsignificant benefit to SFT models, improving ACT-FM scores by an average of\n2.68 points ($p < .001$), while offering no discernible advantage to the\nsuperior ORPO or instruct-tuned variants. We posit that the superiority of ORPO\nstems from its ability to learn the therapeutic `process' over imitating\n`content,' a key aspect of ACT, while COT acts as a necessary scaffold for\nmodels trained only via imitation. This study establishes that\npreference-aligned policy optimization can effectively instill ACT competencies\nin small LLMs, and that the utility of explicit reasoning is highly dependent\non the underlying training paradigm.", "AI": {"tldr": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u91c7\u7528ORPO\u8bad\u7ec3\u65b9\u6cd5\u7684\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6a21\u62dfACT\u6cbb\u7597\u4e2d\u8868\u73b0\u4f18\u4e8eSFT\u6a21\u578b\uff0c\u5e76\u4e14\u94fe\u5f0f\u601d\u8003\uff08COT\uff09\u5bf9SFT\u6a21\u578b\u6709\u76ca\uff0c\u4f46\u5bf9ORPO\u6a21\u578b\u65e0\u660e\u663e\u4f18\u52bf\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u63a2\u8ba8\u5728\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e2d\u5e94\u7528\u63a5\u7eb3\u4e0e\u627f\u8bfa\u7597\u6cd5\uff08ACT\uff09\uff0c\u5e76\u8bc4\u4f30\u4e0d\u540c\u8bad\u7ec3\u65b9\u6cd5\uff08SFT\u548cORPO\uff09\u53ca\u662f\u5426\u4f7f\u7528\u94fe\u5f0f\u601d\u8003\uff08COT\uff09\u5bf9\u6a21\u578b\u8868\u73b0\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528Mistral-Large\u751f\u6210\u768450\u7ec4ACT\u6a21\u62df\u5bf9\u8bdd\uff0c\u901a\u8fc7SFT\u548cORPO\u4e24\u79cd\u65b9\u6cd5\u5bf9Llama-3.2-3b-Instruct\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u5206\u522b\u8bbe\u7f6e\u662f\u5426\u4f7f\u7528COT\u3002\u968f\u540e\uff0c\u4f7f\u7528\u7ecf\u8fc7\u4eba\u7c7b\u8bc4\u4f30\u5fae\u8c03\u7684LLM\u88c1\u5224\uff0c\u5728\u6a21\u62df\u6cbb\u7597\u73af\u8282\u4e2d\uff0c\u57fa\u4e8eACT\u4fdd\u771f\u5ea6\u91cf\u8868\uff08ACT-FM\uff09\u548c\u6cbb\u7597\u5e08\u5171\u60c5\u91cf\u8868\uff08TES\uff09\u5bf9\u56db\u79cd\u6a21\u578b\u53d8\u4f53\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "ORPO\u8bad\u7ec3\u7684\u6a21\u578b\u5728ACT\u4fdd\u771f\u5ea6\u548c\u6cbb\u7597\u5e08\u5171\u60c5\u65b9\u9762\u663e\u8457\u4f18\u4e8eSFT\u6a21\u578b\u548c\u57fa\u7840Instruct\u6a21\u578b\u3002COT\u5bf9SFT\u6a21\u578b\u6709\u663e\u8457\u7684\u79ef\u6781\u5f71\u54cd\uff08ACT-FM\u5206\u6570\u5e73\u5747\u63d0\u9ad82.68\u5206\uff09\uff0c\u4f46\u5bf9ORPO\u548cInstruct\u6a21\u578b\u6ca1\u6709\u660e\u663e\u76ca\u5904\u3002ORPO\u7684\u4f18\u52bf\u53ef\u80fd\u5728\u4e8e\u5176\u5b66\u4e60\u6cbb\u7597\u2018\u8fc7\u7a0b\u2019\u800c\u975e\u2018\u5185\u5bb9\u2019\u7684\u80fd\u529b\uff0c\u800cCOT\u662f\u6a21\u4eff\u8bad\u7ec3\u6a21\u578b\u7684\u5fc5\u8981\u652f\u6491\u3002", "conclusion": "\u672c\u7814\u7a76\u8bc1\u660e\u4e86\u57fa\u4e8e\u504f\u597d\u5bf9\u9f50\u7684\u7b56\u7565\u4f18\u5316\uff08ORPO\uff09\u80fd\u591f\u6709\u6548\u5730\u5728\u5c0f\u578bLLM\u4e2d\u690d\u5165ACT\u80fd\u529b\uff0c\u5e76\u4e14\u663e\u5f0f\u63a8\u7406\uff08COT\uff09\u7684\u6548\u7528\u9ad8\u5ea6\u4f9d\u8d56\u4e8e\u5e95\u5c42\u8bad\u7ec3\u8303\u5f0f\u3002ORPO\u5728\u5c0f\u578bLLM\u4e2d\u5b9e\u73b0ACT\u6cbb\u7597\u80fd\u529b\u65b9\u9762\u663e\u793a\u51fa\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2509.09899", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.09899", "abs": "https://arxiv.org/abs/2509.09899", "authors": ["Christopher Eldred", "Fran\u00e7ois Gay-Balmaz", "Vakhtang Putkaradze"], "title": "Variational Neural Networks for Observable Thermodynamics (V-NOTS)", "comment": "26 pages, 6 figures", "summary": "Much attention has recently been devoted to data-based computing of evolution\nof physical systems. In such approaches, information about data points from\npast trajectories in phase space is used to reconstruct the equations of motion\nand to predict future solutions that have not been observed before. However, in\nmany cases, the available data does not correspond to the variables that define\nthe system's phase space. We focus our attention on the important example of\ndissipative dynamical systems. In that case, the phase space consists of\ncoordinates, momenta and entropies; however, the momenta and entropies cannot,\nin general, be observed directly. To address this difficulty, we develop an\nefficient data-based computing framework based exclusively on observable\nvariables, by constructing a novel approach based on the \\emph{thermodynamic\nLagrangian}, and constructing neural networks that respect the thermodynamics\nand guarantees the non-decreasing entropy evolution. We show that our network\ncan provide an efficient description of phase space evolution based on a\nlimited number of data points and a relatively small number of parameters in\nthe system.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53ef\u89c2\u6d4b\u91cf\u7684\u65b0\u578b\u70ed\u529b\u5b66\u62c9\u683c\u6717\u65e5\u65b9\u6cd5\uff0c\u7528\u4e8e\u4ece\u6570\u636e\u4e2d\u8ba1\u7b97\u8017\u6563\u52a8\u529b\u7cfb\u7edf\u7684\u6f14\u5316\uff0c\u5e76\u6784\u5efa\u4e86\u80fd\u591f\u4fdd\u8bc1\u71b5\u589e\u7684\u795e\u7ecf\u7f51\u7edc\u3002", "motivation": "\u8bb8\u591a\u57fa\u4e8e\u6570\u636e\u7684\u7269\u7406\u7cfb\u7edf\u6f14\u5316\u8ba1\u7b97\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\uff0c\u5c24\u5176\u662f\u5728\u53ef\u89c2\u6d4b\u91cf\u4e0e\u5b9a\u4e49\u76f8\u7a7a\u95f4\u7684\u53d8\u91cf\u4e0d\u4e00\u81f4\u7684\u60c5\u51b5\u4e0b\u3002\u672c\u7814\u7a76\u5173\u6ce8\u8017\u6563\u52a8\u529b\u7cfb\u7edf\uff0c\u5176\u76f8\u7a7a\u95f4\u53d8\u91cf\uff08\u5982\u52a8\u91cf\u548c\u71b5\uff09\u901a\u5e38\u4e0d\u53ef\u76f4\u63a5\u89c2\u6d4b\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u70ed\u529b\u5b66\u62c9\u683c\u6717\u65e5\u91cf\u7684\u65b0\u578b\u65b9\u6cd5\uff0c\u5e76\u6784\u5efa\u4e86\u80fd\u591f\u4fdd\u8bc1\u71b5\u589e\u7684\u795e\u7ecf\u7f51\u7edc\u3002\u8be5\u65b9\u6cd5\u4ec5\u5229\u7528\u53ef\u89c2\u6d4b\u91cf\u6765\u63cf\u8ff0\u76f8\u7a7a\u95f4\u6f14\u5316\u3002", "result": "\u6240\u63d0\u51fa\u7684\u795e\u7ecf\u7f51\u7edc\u80fd\u591f\u57fa\u4e8e\u6709\u9650\u7684\u6570\u636e\u70b9\u548c\u8f83\u5c11\u7684\u7cfb\u7edf\u53c2\u6570\uff0c\u6709\u6548\u5730\u63cf\u8ff0\u76f8\u7a7a\u95f4\u6f14\u5316\u3002", "conclusion": "\u8be5\u7814\u7a76\u6210\u529f\u5730\u5f00\u53d1\u4e86\u4e00\u79cd\u4ec5\u57fa\u4e8e\u53ef\u89c2\u6d4b\u91cf\u7684\u6570\u636e\u8ba1\u7b97\u6846\u67b6\uff0c\u7528\u4e8e\u8017\u6563\u52a8\u529b\u7cfb\u7edf\u7684\u6f14\u5316\uff0c\u5e76\u6709\u6548\u89e3\u51b3\u4e86\u52a8\u91cf\u548c\u71b5\u4e0d\u53ef\u76f4\u63a5\u89c2\u6d4b\u7684\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u8bc1\u4e86\u71b5\u589e\u3002"}}
{"id": "2509.10054", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10054", "abs": "https://arxiv.org/abs/2509.10054", "authors": ["Hailong Yang", "Mingxian Gu", "Jianqi Wang", "Guanjin Wang", "Zhaohong Deng"], "title": "XAgents: A Unified Framework for Multi-Agent Cooperation via IF-THEN Rules and Multipolar Task Processing Graph", "comment": null, "summary": "The rapid advancement of Large Language Models (LLMs) has significantly\nenhanced the capabilities of Multi-Agent Systems (MAS) in supporting humans\nwith complex, real-world tasks. However, MAS still face challenges in effective\ntask planning when handling highly complex tasks with uncertainty, often\nresulting in misleading or incorrect outputs that hinder task execution. To\naddress this, we propose XAgents, a unified multi-agent cooperative framework\nbuilt on a multipolar task processing graph and IF-THEN rules. XAgents uses the\nmultipolar task processing graph to enable dynamic task planning and handle\ntask uncertainty. During subtask processing, it integrates domain-specific\nIF-THEN rules to constrain agent behaviors, while global rules enhance\ninter-agent collaboration. We evaluate the performance of XAgents across three\ndistinct datasets, demonstrating that it consistently surpasses\nstate-of-the-art single-agent and multi-agent approaches in both\nknowledge-typed and logic-typed question-answering tasks. The codes for XAgents\nare available at: https://github.com/AGI-FHBC/XAgents.", "AI": {"tldr": "XAgents\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u591a\u4ee3\u7406\u534f\u4f5c\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u6781\u4efb\u52a1\u5904\u7406\u56fe\u548cIF-THEN\u89c4\u5219\u6765\u89e3\u51b3\u591a\u4ee3\u7406\u7cfb\u7edf\u5728\u5904\u7406\u590d\u6742\u4efb\u52a1\u548c\u4e0d\u786e\u5b9a\u6027\u65f6\u9047\u5230\u7684\u89c4\u5212\u6311\u6218\uff0c\u5e76\u5728\u95ee\u7b54\u4efb\u52a1\u4e2d\u8d85\u8d8a\u4e86\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u591a\u4ee3\u7406\u7cfb\u7edf\uff08MAS\uff09\u5728\u652f\u6301\u4eba\u7c7b\u5904\u7406\u590d\u6742\u73b0\u5b9e\u4e16\u754c\u4efb\u52a1\u65b9\u9762\u80fd\u529b\u663e\u8457\uff0c\u4f46\u4ecd\u9762\u4e34\u5904\u7406\u9ad8\u5ea6\u590d\u6742\u4e14\u4e0d\u786e\u5b9a\u4efb\u52a1\u65f6\u7684\u6709\u6548\u4efb\u52a1\u89c4\u5212\u6311\u6218\uff0c\u8fd9\u5e38\u5e38\u5bfc\u81f4\u8bef\u5bfc\u6027\u6216\u4e0d\u6b63\u786e\u7684\u8f93\u51fa\uff0c\u963b\u788d\u4efb\u52a1\u6267\u884c\u3002", "method": "\u63d0\u51faXAgents\uff0c\u4e00\u4e2a\u57fa\u4e8e\u591a\u6781\u4efb\u52a1\u5904\u7406\u56fe\u548cIF-THEN\u89c4\u5219\u7684\u7edf\u4e00\u591a\u4ee3\u7406\u534f\u4f5c\u6846\u67b6\u3002XAgents\u5229\u7528\u591a\u6781\u4efb\u52a1\u5904\u7406\u56fe\u5b9e\u73b0\u52a8\u6001\u4efb\u52a1\u89c4\u5212\u548c\u5904\u7406\u4efb\u52a1\u4e0d\u786e\u5b9a\u6027\u3002\u5728\u5b50\u4efb\u52a1\u5904\u7406\u8fc7\u7a0b\u4e2d\uff0c\u5b83\u6574\u5408\u4e86\u7279\u5b9a\u9886\u57df\u7684IF-THEN\u89c4\u5219\u6765\u7ea6\u675f\u4ee3\u7406\u884c\u4e3a\uff0c\u540c\u65f6\u5168\u5c40\u89c4\u5219\u589e\u5f3a\u4e86\u4ee3\u7406\u95f4\u7684\u534f\u4f5c\u3002", "result": "\u5728\u4e09\u4e2a\u4e0d\u540c\u7684\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u4e86XAgents\u7684\u6027\u80fd\uff0c\u7ed3\u679c\u8868\u660e\u5728\u77e5\u8bc6\u7c7b\u578b\u548c\u903b\u8f91\u7c7b\u578b\u7684\u95ee\u7b54\u4efb\u52a1\u4e2d\uff0cXAgents\u5728\u6027\u80fd\u4e0a\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u5355\u4ee3\u7406\u548c\u591a\u4ee3\u7406\u65b9\u6cd5\u3002", "conclusion": "XAgents\u901a\u8fc7\u591a\u6781\u4efb\u52a1\u5904\u7406\u56fe\u548cIF-THEN\u89c4\u5219\u7684\u7ed3\u5408\uff0c\u6709\u6548\u5730\u89e3\u51b3\u4e86\u591a\u4ee3\u7406\u7cfb\u7edf\u5728\u5904\u7406\u590d\u6742\u548c\u4e0d\u786e\u5b9a\u4efb\u52a1\u65f6\u7684\u89c4\u5212\u95ee\u9898\uff0c\u5e76\u5728\u95ee\u7b54\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u3002"}}
{"id": "2509.10246", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.10246", "abs": "https://arxiv.org/abs/2509.10246", "authors": ["Amir Bahador Javadi", "Amin Kargarian", "Mort Naraghi-Pour"], "title": "Learning Constraint Surrogate Model for Two-stage Stochastic Unit Commitment", "comment": null, "summary": "The increasing penetration of renewable energy sources introduces significant\nuncertainty in power system operations, making traditional deterministic unit\ncommitment approaches computationally expensive. This paper presents a machine\nlearning surrogate modeling approach designed to reformulate the feasible\ndesign space of the two-stage stochastic unit commitment (TSUC) problem,\nreducing its computational complexity. The proposed method uses a support\nvector machine (SVM) to construct a surrogate model based on the governing\nequations of the learner. This model replaces the original 2|L| * |S|\ntransmission line flow constraints, where |S| is the number of uncertainty\nscenarios and |L| is the number of transmission lines with |S| much less than\n|L|, with a significantly reduced set of 1 * |S| linear inequality constraints.\nThe approach is theoretically grounded in the polyhedral structure of the\nfeasible region under the DC power flow approximation, enabling the\ntransformation of 2|L| line flow limit constraints into a single linear\nconstraint. The surrogate model is trained using data generated from\ncomputationally efficient DC optimal power flow simulations. Simulation results\non the IEEE 57-bus and 118-bus systems demonstrate SVM halfspace constraint\naccuracy of 99.72% and 99.88%, respectively, with TSUC computational time\nreductions of 46% and 31% and negligible generation cost increases (0.63% and\n0.88% on average for IEEE 57- and 118-bus systems, respectively). This shows\nthe effectiveness of the proposed approach for practical power system\noperations under renewable energy uncertainty.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u667a\u80fd\u4f53\u5efa\u6a21\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u4e24\u9636\u6bb5\u968f\u673a\u5355\u4f4d\u627f\u8bfa\uff08TSUC\uff09\u95ee\u9898\uff0c\u4ee5\u5e94\u5bf9\u53ef\u518d\u751f\u80fd\u6e90\u5e26\u6765\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "motivation": "\u53ef\u518d\u751f\u80fd\u6e90\u7684\u666e\u53ca\u589e\u52a0\u4e86\u7535\u529b\u7cfb\u7edf\u8fd0\u884c\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u4f7f\u5f97\u4f20\u7edf\u7684\u786e\u5b9a\u6027\u5355\u4f4d\u627f\u8bfa\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u3002", "method": "\u5229\u7528\u652f\u6301\u5411\u91cf\u673a\uff08SVM\uff09\u6784\u5efa\u667a\u80fd\u4f53\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u57fa\u4e8e\u5b66\u4e60\u65b9\u7a0b\uff0c\u7528\u4e00\u4e2a\u7b80\u5316\u7ea6\u675f\u96c6\uff081*|S|\uff09\u66ff\u4ee3\u539f\u6709\u7684\uff082|L|*|S|\uff09\u8f93\u7535\u7ebf\u8def\u6f6e\u6d41\u7ea6\u675f\uff0c\u5b9e\u73b0\u8ba1\u7b97\u7684\u7b80\u5316\u3002\u8be5\u65b9\u6cd5\u57fa\u4e8e\u76f4\u6d41\u6f6e\u6d41\u8fd1\u4f3c\u4e0b\u7684\u591a\u9762\u4f53\u7ed3\u6784\u3002", "result": "\u5728IEEE 57\u8282\u70b9\u548c118\u8282\u70b9\u7cfb\u7edf\u4e0a\u7684\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0cSVM\u534a\u7a7a\u95f4\u7ea6\u675f\u7684\u51c6\u786e\u7387\u5206\u522b\u4e3a99.72%\u548c99.88%\uff0cTSUC\u7684\u8ba1\u7b97\u65f6\u95f4\u5206\u522b\u51cf\u5c11\u4e8646%\u548c31%\uff0c\u53d1\u7535\u6210\u672c\u4ec5\u589e\u52a0\u4e860.63%\u548c0.88%\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u667a\u80fd\u4f53\u5efa\u6a21\u6709\u6548\u964d\u4f4e\u4e86TSUC\u95ee\u9898\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u5e76\u4fdd\u6301\u4e86\u9ad8\u51c6\u786e\u6027\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u5e94\u5bf9\u53ef\u518d\u751f\u80fd\u6e90\u4e0d\u786e\u5b9a\u6027\u7684\u5b9e\u9645\u7535\u529b\u7cfb\u7edf\u8fd0\u884c\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2509.09828", "categories": ["cs.CV", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2509.09828", "abs": "https://arxiv.org/abs/2509.09828", "authors": ["Tim Broedermannn", "Christos Sakaridis", "Luigi Piccinelli", "Wim Abbeloos", "Luc Van Gool"], "title": "DGFusion: Depth-Guided Sensor Fusion for Robust Semantic Perception", "comment": "Code and models will be available at\n  https://github.com/timbroed/DGFusion", "summary": "Robust semantic perception for autonomous vehicles relies on effectively\ncombining multiple sensors with complementary strengths and weaknesses.\nState-of-the-art sensor fusion approaches to semantic perception often treat\nsensor data uniformly across the spatial extent of the input, which hinders\nperformance when faced with challenging conditions. By contrast, we propose a\nnovel depth-guided multimodal fusion method that upgrades condition-aware\nfusion by integrating depth information. Our network, DGFusion, poses\nmultimodal segmentation as a multi-task problem, utilizing the lidar\nmeasurements, which are typically available in outdoor sensor suites, both as\none of the model's inputs and as ground truth for learning depth. Our\ncorresponding auxiliary depth head helps to learn depth-aware features, which\nare encoded into spatially varying local depth tokens that condition our\nattentive cross-modal fusion. Together with a global condition token, these\nlocal depth tokens dynamically adapt sensor fusion to the spatially varying\nreliability of each sensor across the scene, which largely depends on depth. In\naddition, we propose a robust loss for our depth, which is essential for\nlearning from lidar inputs that are typically sparse and noisy in adverse\nconditions. Our method achieves state-of-the-art panoptic and semantic\nsegmentation performance on the challenging MUSES and DELIVER datasets. Code\nand models will be available at https://github.com/timbroed/DGFusion", "AI": {"tldr": "DGFusion\u662f\u4e00\u79cd\u65b0\u7684\u6df1\u5ea6\u5f15\u5bfc\u591a\u6a21\u6001\u878d\u5408\u65b9\u6cd5\uff0c\u901a\u8fc7\u6574\u5408\u6df1\u5ea6\u4fe1\u606f\u6765\u63d0\u5347\u6761\u4ef6\u611f\u77e5\u878d\u5408\uff0c\u4ee5\u89e3\u51b3\u4f20\u611f\u5668\u878d\u5408\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u6761\u4ef6\u4e0b\u6027\u80fd\u53d7\u9650\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u4f20\u611f\u5668\u878d\u5408\u65b9\u6cd5\u5728\u5904\u7406\u5177\u6709\u6311\u6218\u6027\u7684\u6761\u4ef6\u65f6\uff0c\u7531\u4e8e\u5c06\u4f20\u611f\u5668\u6570\u636e\u5728\u7a7a\u95f4\u8303\u56f4\u5185\u8fdb\u884c\u5747\u5300\u5904\u7406\uff0c\u4f1a\u963b\u788d\u6027\u80fd\u7684\u63d0\u5347\u3002", "method": "DGFusion\u5c06\u591a\u6a21\u6001\u5206\u5272\u89c6\u4e3a\u4e00\u4e2a\u591a\u4efb\u52a1\u95ee\u9898\uff0c\u5229\u7528\u6fc0\u5149\u96f7\u8fbe\u6d4b\u91cf\u4f5c\u4e3a\u6a21\u578b\u8f93\u5165\u548c\u5b66\u4e60\u6df1\u5ea6\u7684\u5730\u9762\u771f\u5b9e\u3002\u5b83\u8fd8\u5305\u62ec\u4e00\u4e2a\u8f85\u52a9\u6df1\u5ea6\u5934\uff0c\u7528\u4e8e\u5b66\u4e60\u6df1\u5ea6\u611f\u77e5\u7279\u5f81\uff0c\u8fd9\u4e9b\u7279\u5f81\u88ab\u7f16\u7801\u6210\u7a7a\u95f4\u53d8\u5316\u7684\u5c40\u90e8\u6df1\u5ea6\u4ee4\u724c\uff0c\u4ee5\u6761\u4ef6\u5316\u6ce8\u610f\u529b\u8de8\u6a21\u6001\u878d\u5408\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u9c81\u68d2\u635f\u5931\u51fd\u6570\uff0c\u4ee5\u5e94\u5bf9\u6fc0\u5149\u96f7\u8fbe\u8f93\u5165\u5728\u4e0d\u5229\u6761\u4ef6\u4e0b\u7a00\u758f\u4e14\u5608\u6742\u7684\u95ee\u9898\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u5177\u6709\u6311\u6218\u6027\u7684MUSES\u548cDELIVER\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u5168\u666f\u548c\u8bed\u4e49\u5206\u5272\u6027\u80fd\u3002", "conclusion": "DGFusion\u901a\u8fc7\u5229\u7528\u6df1\u5ea6\u4fe1\u606f\uff0c\u52a8\u6001\u5730\u9002\u5e94\u4f20\u611f\u5668\u878d\u5408\uff0c\u4ee5\u9002\u5e94\u573a\u666f\u4e2d\u6bcf\u4e2a\u4f20\u611f\u5668\u5728\u7a7a\u95f4\u4e0a\u53d8\u5316\u7684\u53ef\u9760\u6027\uff0c\u4ece\u800c\u663e\u8457\u63d0\u9ad8\u4e86\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u7684\u8bed\u4e49\u611f\u77e5\u80fd\u529b\u3002"}}
{"id": "2509.10412", "categories": ["cond-mat.mtrl-sci", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2509.10412", "abs": "https://arxiv.org/abs/2509.10412", "authors": ["Rafael Pineda Medina", "Pablo Burset", "William J. Herrera"], "title": "Topological superconductivity in a dimerized Kitaev chain revealed by nonlocal transport", "comment": null, "summary": "Artificial Kitaev chains engineered from semiconducting quantum dots coupled\nby superconducting segments offer a promising route to realize and control\nMajorana bound states for topological quantum computation. We study a dimerized\nKitaev chain--equivalent to a superconducting Su-Schrieffer-Heeger model--and\nanalyze the behavior of the resulting two coupled chains. We show that\ninterference between Majorana edge modes from each chain gives rise to\nobservable signatures in nonlocal conductance. Additionally, we identify a\nparity effect in the system length that governs the coupling of edge states,\nsupported by an analytical model. Our results provide experimentally accessible\nprobes for Majorana hybridization in mesoscopic topological superconductors.", "AI": {"tldr": "\u6587\u7ae0\u7814\u7a76\u4e86\u7531\u534a\u5bfc\u4f53\u91cf\u5b50\u70b9\u8026\u5408\u7684\u8d85\u5bfc\u94fe\u7ec4\u6210\u7684Kitaev\u94fe\uff0c\u5206\u6790\u4e86\u53cc Kitaev\u94fe\u7684\u9a6c\u7ea6\u62c9\u7eb3\u675f\u7f1a\u6001\u7684\u4ea7\u751f\u548c\u63a7\u5236\u3002", "motivation": "\u4e3a\u4e86\u5b9e\u73b0\u548c\u63a7\u5236\u62d3\u6251\u91cf\u5b50\u8ba1\u7b97\u7684\u9a6c\u7ea6\u62c9\u7eb3\u675f\u7f1a\u6001\uff0c\u7814\u7a76\u4e86\u7531\u534a\u5bfc\u4f53\u91cf\u5b50\u70b9\u8026\u5408\u7684\u8d85\u5bfc\u94fe\u7ec4\u6210\u7684Kitaev\u94fe\u3002", "method": "\u7814\u7a76\u4e86\u4e00\u4e2a\u53cc Kitaev\u94fe\uff08\u7b49\u4ef7\u4e8e\u8d85\u5bfc\u7684Su-Schrieffer-Heeger\u6a21\u578b\uff09\uff0c\u5e76\u5206\u6790\u4e86\u6240\u5f97\u7684\u4e24\u4e2a\u8026\u5408\u94fe\u7684\u884c\u4e3a\u3002", "result": "\u6587\u7ae0\u8868\u660e\uff0c\u6765\u81ea\u6bcf\u4e2a\u94fe\u7684\u9a6c\u7ea6\u62c9\u7eb3\u8fb9\u7f18\u6a21\u5f0f\u4e4b\u95f4\u7684\u5e72\u6d89\u4f1a\u5bfc\u81f4\u975e\u5c40\u57df\u7535\u5bfc\u4e2d\u53ef\u89c2\u6d4b\u7684\u7279\u5f81\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u5206\u6790\u6a21\u578b\uff0c\u8bc6\u522b\u51fa\u63a7\u5236\u8fb9\u7f18\u6001\u8026\u5408\u7684\u7cfb\u7edf\u957f\u5ea6\u7684\u5947\u5076\u6548\u5e94\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u4e2d\u89c2\u62d3\u6251\u8d85\u5bfc\u4f53\u4e2d\u7684\u9a6c\u7ea6\u62c9\u7eb3\u6742\u5316\u63d0\u4f9b\u4e86\u53ef\u5b9e\u73b0\u7684\u53ef\u5b9e\u9a8c\u63a2\u6d4b\u65b9\u6cd5\u3002"}}
{"id": "2509.10128", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10128", "abs": "https://arxiv.org/abs/2509.10128", "authors": ["Philip Arm", "Oliver Fischer", "Joseph Church", "Adrian Fuhrer", "Hendrik Kolvenbach", "Marco Hutter"], "title": "Efficient Learning-Based Control of a Legged Robot in Lunar Gravity", "comment": null, "summary": "Legged robots are promising candidates for exploring challenging areas on\nlow-gravity bodies such as the Moon, Mars, or asteroids, thanks to their\nadvanced mobility on unstructured terrain. However, as planetary robots' power\nand thermal budgets are highly restricted, these robots need energy-efficient\ncontrol approaches that easily transfer to multiple gravity environments. In\nthis work, we introduce a reinforcement learning-based control approach for\nlegged robots with gravity-scaled power-optimized reward functions. We use our\napproach to develop and validate a locomotion controller and a base pose\ncontroller in gravity environments from lunar gravity (1.62 m/s2) to a\nhypothetical super-Earth (19.62 m/s2). Our approach successfully scales across\nthese gravity levels for locomotion and base pose control with the\ngravity-scaled reward functions. The power-optimized locomotion controller\nreached a power consumption for locomotion of 23.4 W in Earth gravity on a\n15.65 kg robot at 0.4 m/s, a 23 % improvement over the baseline policy.\nAdditionally, we designed a constant-force spring offload system that allowed\nus to conduct real-world experiments on legged locomotion in lunar gravity. In\nlunar gravity, the power-optimized control policy reached 12.2 W, 36 % less\nthan a baseline controller which is not optimized for power efficiency. Our\nmethod provides a scalable approach to developing power-efficient locomotion\ncontrollers for legged robots across multiple gravity levels.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u63a7\u5236\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u91cd\u529b\u7f29\u653e\u7684\u529f\u7387\u4f18\u5316\u5956\u52b1\u51fd\u6570\uff0c\u4e3a\u884c\u661f\u63a2\u6d4b\u817f\u5f0f\u673a\u5668\u4eba\u5f00\u53d1\u4e86\u80fd\u8017\u4f4e\u4e14\u53ef\u8de8\u91cd\u529b\u73af\u5883\u8fc1\u79fb\u7684\u8fd0\u52a8\u63a7\u5236\u5668\u548c\u59ff\u6001\u63a7\u5236\u5668\u3002", "motivation": "\u884c\u661f\u63a2\u6d4b\u817f\u5f0f\u673a\u5668\u4eba\u5728\u4f4e\u91cd\u529b\u73af\u5883\u4e0b\u5177\u6709\u4f18\u8d8a\u7684\u79fb\u52a8\u80fd\u529b\uff0c\u4f46\u5176\u80fd\u91cf\u548c\u70ed\u91cf\u53d7\u9650\uff0c\u9700\u8981\u80fd\u591f\u9002\u5e94\u591a\u91cd\u91cd\u529b\u73af\u5883\u4e14\u8282\u80fd\u7684\u63a7\u5236\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u5f3a\u5316\u5b66\u4e60\uff0c\u7ed3\u5408\u91cd\u529b\u7f29\u653e\u7684\u529f\u7387\u4f18\u5316\u5956\u52b1\u51fd\u6570\uff0c\u5f00\u53d1\u5e76\u9a8c\u8bc1\u4e86\u673a\u5668\u4eba\u7684\u8fd0\u52a8\u63a7\u5236\u5668\u548c\u57fa\u5ea7\u59ff\u6001\u63a7\u5236\u5668\uff0c\u5e76\u5728\u4ece\u6708\u7403\u91cd\u529b\u5230\u8d85\u5730\u7403\u91cd\u529b\u7684\u591a\u4e2a\u91cd\u529b\u73af\u5883\u4e0b\u8fdb\u884c\u4e86\u6d4b\u8bd5\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u4e0d\u540c\u91cd\u529b\u73af\u5883\u4e0b\u6210\u529f\u5b9e\u73b0\u4e86\u8fd0\u52a8\u548c\u59ff\u6001\u63a7\u5236\u7684\u8fc1\u79fb\u3002\u5728\u5730\u7403\u91cd\u529b\u4e0b\uff0c\u529f\u7387\u4f18\u5316\u63a7\u5236\u5668\u6bd4\u57fa\u7ebf\u7b56\u7565\u8282\u80fd23%\uff0c\u8fbe\u523023.4W\u3002\u5728\u6708\u7403\u91cd\u529b\u4e0b\uff0c\u901a\u8fc7\u5f39\u7c27\u5378\u8f7d\u7cfb\u7edf\u8f85\u52a9\u5b9e\u9a8c\uff0c\u529f\u7387\u4f18\u5316\u63a7\u5236\u5668\u80fd\u8017\u4e3a12.2W\uff0c\u6bd4\u57fa\u7ebf\u63a7\u5236\u5668\u4f4e36%\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u4e3a\u5f00\u53d1\u9002\u7528\u4e8e\u8de8\u91cd\u529b\u73af\u5883\u7684\u817f\u5f0f\u673a\u5668\u4eba\u8282\u80fd\u8fd0\u52a8\u63a7\u5236\u5668\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.10369", "categories": ["cs.LG", "cs.AI", "eess.SP", "q-bio.TO"], "pdf": "https://arxiv.org/pdf/2509.10369", "abs": "https://arxiv.org/abs/2509.10369", "authors": ["Gul Rukh Khattak", "Konstantinos Patlatzoglou", "Joseph Barker", "Libor Pastika", "Boroumand Zeidaabadi", "Ahmed El-Medany", "Hesham Aggour", "Yixiu Liang", "Antonio H. Ribeiro", "Jeffrey Annis", "Antonio Luiz Pinho Ribeiro", "Junbo Ge", "Daniel B. Kramer", "Jonathan W. Waks", "Evan Brittain", "Nicholas Peters", "Fu Siong Ng", "Arunashis Sau"], "title": "Data distribution impacts the performance and generalisability of contrastive learning-based foundation models of electrocardiograms", "comment": "Currently under review at npj Digital Medicine", "summary": "Contrastive learning is a widely adopted self-supervised pretraining\nstrategy, yet its dependence on cohort composition remains underexplored. We\npresent Contrasting by Patient Augmented Electrocardiograms (CAPE) foundation\nmodel and pretrain on four cohorts (n = 5,203,352), from diverse populations\nacross three continents (North America, South America, Asia). We systematically\nassess how cohort demographics, health status, and population diversity\ninfluence the downstream performance for prediction tasks also including two\nadditional cohorts from another continent (Europe). We find that downstream\nperformance depends on the distributional properties of the pretraining cohort,\nincluding demographics and health status. Moreover, while pretraining with a\nmulti-centre, demographically diverse cohort improves in-distribution accuracy,\nit reduces out-of-distribution (OOD) generalisation of our contrastive approach\nby encoding cohort-specific artifacts. To address this, we propose the\nIn-Distribution Batch (IDB) strategy, which preserves intra-cohort consistency\nduring pretraining and enhances OOD robustness. This work provides important\ninsights for developing clinically fair and generalisable foundation models.", "AI": {"tldr": "\u901a\u8fc7\u60a3\u8005\u589e\u5f3a\u5fc3\u7535\u56fe\uff08CAPE\uff09\u57fa\u7840\u6a21\u578b\uff0c\u7814\u7a76\u4e86\u961f\u5217\u6784\u6210\u5bf9\u5bf9\u6bd4\u5b66\u4e60\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86IDB\u7b56\u7565\u6765\u63d0\u9ad8\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5bf9\u6bd4\u5b66\u4e60\u5728\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u4e2d\u88ab\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5176\u5bf9\u961f\u5217\u6784\u6210\u7684\u4f9d\u8d56\u6027\u4ecd\u6709\u5f85\u63a2\u7d22\u3002", "method": "\u63d0\u51faCAPE \u57fa\u7840\u6a21\u578b\uff0c\u5728\u8de8\u8d8a\u4e09\u5927\u6d32\u7684\u56db\u4e2a\u961f\u5217\uff08n = 5,203,352\uff09\u4e0a\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u5e76\u8bc4\u4f30\u4e86\u4eba\u53e3\u7edf\u8ba1\u3001\u5065\u5eb7\u72b6\u51b5\u548c\u4eba\u7fa4\u591a\u6837\u6027\u5bf9\u4e0b\u6e38\u9884\u6d4b\u4efb\u52a1\u6027\u80fd\u7684\u5f71\u54cd\u3002\u63d0\u51fa IDB \u7b56\u7565\u6765\u89e3\u51b3\u591a\u4e2d\u5fc3\u3001\u591a\u6837\u5316\u9884\u8bad\u7ec3\u961f\u5217\u5bfc\u81f4\u7684\u6cdb\u5316\u80fd\u529b\u4e0b\u964d\u95ee\u9898\u3002", "result": "\u4e0b\u6e38\u6027\u80fd\u53d7\u9884\u8bad\u7ec3\u961f\u5217\u7684\u5206\u5e03\u7279\u6027\uff08\u5305\u62ec\u4eba\u53e3\u7edf\u8ba1\u548c\u5065\u5eb7\u72b6\u51b5\uff09\u5f71\u54cd\u3002\u591a\u4e2d\u5fc3\u3001\u4eba\u53e3\u7edf\u8ba1\u591a\u6837\u5316\u7684\u9884\u8bad\u7ec3\u961f\u5217\u63d0\u9ad8\u4e86\u5206\u5e03\u5185\u51c6\u786e\u6027\uff0c\u4f46\u964d\u4f4e\u4e86\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\u7684\u5206\u5e03\u5916\uff08OOD\uff09\u6cdb\u5316\u80fd\u529b\uff0c\u56e0\u4e3a\u5b83\u7f16\u7801\u4e86\u961f\u5217\u7279\u5f02\u6027\u7684\u4eba\u4e3a\u56e0\u7d20\u3002IDB \u7b56\u7565\u63d0\u9ad8\u4e86 OOD \u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5f00\u53d1\u4e34\u5e8a\u4e0a\u516c\u5e73\u4e14\u53ef\u6cdb\u5316\u7684\u57fa\u7840\u6a21\u578b\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u89c1\u89e3\u3002"}}
{"id": "2509.10293", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2509.10293", "abs": "https://arxiv.org/abs/2509.10293", "authors": ["Yinan Wang", "Xiaoyang Wang", "Zhenyu Wang", "Jing Wu", "Jian Lv", "Han Wang"], "title": "OpenCSP: A Deep Learning Framework for Crystal Structure Prediction from Ambient to High Pressure", "comment": "15 pages, 5 figures", "summary": "High-pressure crystal structure prediction (CSP) underpins advances in\ncondensed matter physics, planetary science, and materials discovery. Yet, most\nlarge atomistic models are trained on near-ambient, equilibrium data, leading\nto degraded stress accuracy at tens to hundreds of gigapascals and sparse\ncoverage of pressure-stabilized stoichiometries and dense coordination motifs.\nHere, we introduce OpenCSP, a machine learning framework for CSP tasks spanning\nambient to high-pressure conditions. This framework comprises an open-source\npressure-resolved dataset alongside a suite of publicly available atomistic\nmodels that are jointly optimized for accuracy in energy, force, and stress\npredictions. The dataset is constructed via randomized high-pressure sampling\nand iteratively refined through an uncertainty-guided concurrent learning\nstrategy, which enriches underrepresented compression regimes while suppressing\nredundant DFT labeling. Despite employing a training corpus one to two orders\nof magnitude smaller than those of leading large models, OpenCSP achieves\ncomparable or superior performance in high-pressure enthalpy ranking and\nstability prediction. Across benchmark CSP tasks spanning a wide pressure\nwindow, our models match or surpass MACE-MPA-0, MatterSim v1 5M, and\nGRACE-2L-OAM, with the largest gains observed at elevated pressures. These\nresults demonstrate that targeted, pressure-aware data acquisition coupled with\nscalable architectures enables data-efficient, high-fidelity CSP, paving the\nway for autonomous materials discovery under ambient and extreme conditions.", "AI": {"tldr": "OpenCSP\u662f\u4e00\u4e2a\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u9ad8\u538b\u6761\u4ef6\u4e0b\u8fdb\u884c\u6676\u4f53\u7ed3\u6784\u9884\u6d4b\u3002\u5b83\u5305\u542b\u4e00\u4e2a\u5f00\u6e90\u7684\u6570\u636e\u96c6\u548c\u4e00\u7cfb\u5217\u516c\u5f00\u7684\u539f\u5b50\u6a21\u578b\uff0c\u8fd9\u4e9b\u6a21\u578b\u7ecf\u8fc7\u8054\u5408\u4f18\u5316\uff0c\u80fd\u591f\u51c6\u786e\u9884\u6d4b\u80fd\u91cf\u3001\u529b\u548c\u5e94\u529b\u3002\u4e0e\u73b0\u6709\u7684\u5927\u578b\u6a21\u578b\u76f8\u6bd4\uff0cOpenCSP\u5728\u6570\u636e\u91cf\u8f83\u5c11\u7684\u60c5\u51b5\u4e0b\uff0c\u5728\u9ad8\u538b\u4e0b\u7684\u6027\u80fd\u76f8\u5f53\u751a\u81f3\u66f4\u4f18\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u90e8\u5206\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u5904\u7406\u9ad8\u538b\uff08\u6570\u5341\u81f3\u6570\u767e\u5409\u5e15\u65af\u5361\uff09\u4e0b\u7684\u5e94\u529b\u9884\u6d4b\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u5e76\u4e14\u5bf9\u9ad8\u538b\u4e0b\u7a33\u5b9a\u7684\u5316\u5b66\u8ba1\u91cf\u548c\u81f4\u5bc6\u914d\u4f4d\u7ed3\u6784\u8986\u76d6\u4e0d\u8db3\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u4e2a\u80fd\u591f\u5728\u4ece\u73af\u5883\u538b\u529b\u5230\u9ad8\u538b\u6761\u4ef6\u90fd\u80fd\u51c6\u786e\u9884\u6d4b\u7684\u673a\u5668\u5b66\u4e60\u6846\u67b6\u3002", "method": "OpenCSP\u6846\u67b6\u5305\u542b\u4e00\u4e2a\u5f00\u6e90\u7684\u3001\u7ecf\u8fc7\u538b\u529b\u89e3\u6790\u7684\u6570\u636e\u96c6\uff0c\u4ee5\u53ca\u4e00\u7cfb\u5217\u516c\u5f00\u7684\u539f\u5b50\u6a21\u578b\u3002\u8be5\u6570\u636e\u96c6\u901a\u8fc7\u968f\u673a\u9ad8\u538b\u91c7\u6837\u6784\u5efa\uff0c\u5e76\u5229\u7528\u4e0d\u786e\u5b9a\u6027\u5f15\u5bfc\u7684\u5e76\u53d1\u5b66\u4e60\u7b56\u7565\u8fdb\u884c\u8fed\u4ee3\u4f18\u5316\uff0c\u4ee5\u4e30\u5bcc\u6570\u636e\u7a00\u758f\u7684\u538b\u7f29\u533a\u57df\u5e76\u51cf\u5c11\u5197\u4f59\u7684DFT\u8ba1\u7b97\u3002\u6a21\u578b\u5219\u7ecf\u8fc7\u8054\u5408\u4f18\u5316\uff0c\u4ee5\u63d0\u9ad8\u80fd\u91cf\u3001\u529b\u548c\u5e94\u529b\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002", "result": "OpenCSP\u5728\u538b\u529b\u4e0b\u7684\u7113\u6392\u5e8f\u548c\u7a33\u5b9a\u6027\u9884\u6d4b\u65b9\u9762\uff0c\u5373\u4f7f\u8bad\u7ec3\u8bed\u6599\u5e93\u6bd4\u9886\u5148\u7684\u5927\u578b\u6a21\u578b\u5c0f\u4e00\u5230\u4e24\u4e2a\u6570\u91cf\u7ea7\uff0c\u4e5f\u80fd\u8fbe\u5230\u76f8\u5f53\u6216\u66f4\u4f18\u7684\u6027\u80fd\u3002\u5728\u8de8\u8d8a\u5bbd\u538b\u529b\u8303\u56f4\u7684\u57fa\u51c6CSP\u4efb\u52a1\u4e2d\uff0cOpenCSP\u7684\u6a21\u578b\u5728MACE-MPA-0\u3001MatterSim v1 5M\u548cGRACE-2L-OAM\u4e4b\u4e0a\uff0c\u5c24\u5176\u5728\u9ad8\u538b\u4e0b\u8868\u73b0\u63d0\u5347\u6700\u4e3a\u663e\u8457\u3002", "conclusion": "\u901a\u8fc7\u6709\u9488\u5bf9\u6027\u7684\u3001\u8003\u8651\u538b\u529b\u7684\u6570\u636e\u91c7\u96c6\u7b56\u7565\uff0c\u5e76\u7ed3\u5408\u53ef\u6269\u5c55\u7684\u67b6\u6784\uff0c\u53ef\u4ee5\u5b9e\u73b0\u6570\u636e\u9ad8\u6548\u3001\u9ad8\u4fdd\u771f\u7684\u9ad8\u538b\u6676\u4f53\u7ed3\u6784\u9884\u6d4b\uff0c\u4ece\u800c\u4e3a\u5728\u5404\u79cd\u538b\u529b\u6761\u4ef6\u4e0b\u8fdb\u884c\u81ea\u4e3b\u6750\u6599\u53d1\u73b0\u94fa\u5e73\u9053\u8def\u3002"}}
{"id": "2509.09713", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09713", "abs": "https://arxiv.org/abs/2509.09713", "authors": ["Duolin Sun", "Dan Yang", "Yue Shen", "Yihan Jiao", "Zhehao Tan", "Jie Feng", "Lianzhen Zhong", "Jian Wang", "Peng Wei", "Jinjie Gu"], "title": "HANRAG: Heuristic Accurate Noise-resistant Retrieval-Augmented Generation for Multi-hop Question Answering", "comment": null, "summary": "The Retrieval-Augmented Generation (RAG) approach enhances question-answering\nsystems and dialogue generation tasks by integrating information retrieval (IR)\ntechnologies with large language models (LLMs). This strategy, which retrieves\ninformation from external knowledge bases to bolster the response capabilities\nof generative models, has achieved certain successes. However, current RAG\nmethods still face numerous challenges when dealing with multi-hop queries. For\ninstance, some approaches overly rely on iterative retrieval, wasting too many\nretrieval steps on compound queries. Additionally, using the original complex\nquery for retrieval may fail to capture content relevant to specific\nsub-queries, resulting in noisy retrieved content. If the noise is not managed,\nit can lead to the problem of noise accumulation. To address these issues, we\nintroduce HANRAG, a novel heuristic-based framework designed to efficiently\ntackle problems of varying complexity. Driven by a powerful revelator, HANRAG\nroutes queries, decomposes them into sub-queries, and filters noise from\nretrieved documents. This enhances the system's adaptability and noise\nresistance, making it highly capable of handling diverse queries. We compare\nthe proposed framework against other leading industry methods across various\nbenchmarks. The results demonstrate that our framework obtains superior\nperformance in both single-hop and multi-hop question-answering tasks.", "AI": {"tldr": "HANRAG\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u542f\u53d1\u5f0f\u6846\u67b6\uff0c\u901a\u8fc7\u67e5\u8be2\u8def\u7531\u3001\u5b50\u67e5\u8be2\u5206\u89e3\u548c\u566a\u58f0\u8fc7\u6ee4\u6765\u89e3\u51b3\u591a\u8df3\u95ee\u9898\uff0c\u5e76\u5728\u95ee\u7b54\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524dRAG\u65b9\u6cd5\u5728\u5904\u7406\u591a\u8df3\u67e5\u8be2\u65f6\u9762\u4e34\u6311\u6218\uff0c\u4f8b\u5982\u8fc7\u5ea6\u4f9d\u8d56\u8fed\u4ee3\u68c0\u7d22\u548c\u566a\u58f0\u7d2f\u79ef\u95ee\u9898\u3002", "method": "\u63d0\u51faHANRAG\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u4e00\u4e2a\u2018\u542f\u793a\u5668\u2019\u6765\u8def\u7531\u67e5\u8be2\u3001\u5c06\u5176\u5206\u89e3\u4e3a\u5b50\u67e5\u8be2\uff0c\u5e76\u8fc7\u6ee4\u68c0\u7d22\u5230\u7684\u6587\u6863\u4e2d\u7684\u566a\u58f0\u3002", "result": "HANRAG\u5728\u5355\u8df3\u548c\u591a\u8df3\u95ee\u7b54\u4efb\u52a1\u4e2d\u5747\u53d6\u5f97\u4e86\u4f18\u4e8e\u5176\u4ed6\u9886\u5148\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "conclusion": "HANRAG\u6846\u67b6\u63d0\u9ad8\u4e86\u7cfb\u7edf\u7684\u9002\u5e94\u6027\u548c\u6297\u566a\u58f0\u80fd\u529b\uff0c\u80fd\u591f\u6709\u6548\u5730\u5904\u7406\u5404\u79cd\u590d\u6742\u67e5\u8be2\u3002"}}
{"id": "2509.09926", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.09926", "abs": "https://arxiv.org/abs/2509.09926", "authors": ["Jiahao Chen", "Zhiyuan Huang", "Yurou Liu", "Bing Su"], "title": "LoFT: Parameter-Efficient Fine-Tuning for Long-tailed Semi-Supervised Learning in Open-World Scenarios", "comment": null, "summary": "Long-tailed learning has garnered increasing attention due to its wide\napplicability in real-world scenarios. Among existing approaches, Long-Tailed\nSemi-Supervised Learning (LTSSL) has emerged as an effective solution by\nincorporating a large amount of unlabeled data into the imbalanced labeled\ndataset. However, most prior LTSSL methods are designed to train models from\nscratch, which often leads to issues such as overconfidence and low-quality\npseudo-labels. To address these challenges, we extend LTSSL into the foundation\nmodel fine-tuning paradigm and propose a novel framework: LoFT (Long-tailed\nsemi-supervised learning via parameter-efficient Fine-Tuning). We demonstrate\nthat fine-tuned foundation models can generate more reliable pseudolabels,\nthereby benefiting imbalanced learning. Furthermore, we explore a more\npractical setting by investigating semi-supervised learning under open-world\nconditions, where the unlabeled data may include out-of-distribution (OOD)\nsamples. To handle this problem, we propose LoFT-OW (LoFT under Open-World\nscenarios) to improve the discriminative ability. Experimental results on\nmultiple benchmarks demonstrate that our method achieves superior performance\ncompared to previous approaches, even when utilizing only 1\\% of the unlabeled\ndata compared with previous works.", "AI": {"tldr": "\u901a\u8fc7\u53c2\u6570\u9ad8\u6548\u7684\u5fae\u8c03 (LoFT) \u6765\u89e3\u51b3\u957f\u5c3e\u534a\u76d1\u7763\u5b66\u4e60\u95ee\u9898\uff0c\u5e76\u5728\u5f00\u653e\u4e16\u754c\u573a\u666f\u4e0b\u8fdb\u884c\u4e86\u6269\u5c55 (LoFT-OW)\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u957f\u5c3e\u534a\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u5728\u4ece\u5934\u5f00\u59cb\u8bad\u7ec3\u65f6\u5b58\u5728\u6a21\u578b\u8fc7\u5ea6\u81ea\u4fe1\u548c\u4f2a\u6807\u7b7e\u8d28\u91cf\u4f4e\u7684\u95ee\u9898\uff0c\u5e76\u5c06\u957f\u5c3e\u534a\u76d1\u7763\u5b66\u4e60\u6269\u5c55\u5230\u5f00\u653e\u4e16\u754c\u573a\u666f\u3002", "method": "\u5c06\u957f\u5c3e\u534a\u76d1\u7763\u5b66\u4e60\uff08LTSSL\uff09\u878d\u5165\u57fa\u7840\u6a21\u578b\u5fae\u8c03\u8303\u5f0f\uff0c\u63d0\u51fa LoFT \u6846\u67b6\uff0c\u5e76\u901a\u8fc7 LoFT-OW \u6269\u5c55\u4ee5\u5904\u7406\u5f00\u653e\u4e16\u754c\u573a\u666f\u4e0b\u7684 OOD \u6837\u672c\u3002", "result": "LoFT \u6846\u67b6\u901a\u8fc7\u5fae\u8c03\u57fa\u7840\u6a21\u578b\u751f\u6210\u66f4\u53ef\u9760\u7684\u4f2a\u6807\u7b7e\uff0c\u4ece\u800c\u63d0\u5347\u4e86\u957f\u5c3e\u5b66\u4e60\u7684\u6548\u679c\u3002LoFT-OW \u63d0\u9ad8\u4e86\u533a\u5206\u80fd\u529b\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u4ec5\u4f7f\u7528 1% \u7684\u65e0\u6807\u7b7e\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u8be5\u65b9\u6cd5\u4ecd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "LoFT \u901a\u8fc7\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u57fa\u7840\u6a21\u578b\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u957f\u5c3e\u534a\u76d1\u7763\u5b66\u4e60\u4e2d\u7684\u6311\u6218\uff0c\u5e76\u5728\u5f00\u653e\u4e16\u754c\u573a\u666f\u4e0b\u5c55\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2509.10104", "categories": ["cs.AI", "stat.ME"], "pdf": "https://arxiv.org/pdf/2509.10104", "abs": "https://arxiv.org/abs/2509.10104", "authors": ["Sofia Vei", "Paolo Giudici", "Pavlos Sermpezis", "Athena Vakali", "Adelaide Emma Bernardelli"], "title": "AI Harmonics: a human-centric and harms severity-adaptive AI risk assessment framework", "comment": null, "summary": "The absolute dominance of Artificial Intelligence (AI) introduces\nunprecedented societal harms and risks. Existing AI risk assessment models\nfocus on internal compliance, often neglecting diverse stakeholder perspectives\nand real-world consequences. We propose a paradigm shift to a human-centric,\nharm-severity adaptive approach grounded in empirical incident data. We present\nAI Harmonics, which includes a novel AI harm assessment metric (AIH) that\nleverages ordinal severity data to capture relative impact without requiring\nprecise numerical estimates. AI Harmonics combines a robust, generalized\nmethodology with a data-driven, stakeholder-aware framework for exploring and\nprioritizing AI harms. Experiments on annotated incident data confirm that\npolitical and physical harms exhibit the highest concentration and thus warrant\nurgent mitigation: political harms erode public trust, while physical harms\npose serious, even life-threatening risks, underscoring the real-world\nrelevance of our approach. Finally, we demonstrate that AI Harmonics\nconsistently identifies uneven harm distributions, enabling policymakers and\norganizations to target their mitigation efforts effectively.", "AI": {"tldr": "AI Harmonics \u63d0\u51fa\u4e86\u4e00\u79cd\u4ee5\u4eba\u4e3a\u672c\u3001\u6839\u636e\u5371\u5bb3\u4e25\u91cd\u6027\u81ea\u9002\u5e94\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc4\u4f30 AI \u98ce\u9669\uff0c\u91cd\u70b9\u5173\u6ce8\u653f\u6cbb\u548c\u8eab\u4f53\u5371\u5bb3\uff0c\u4ee5\u4fbf\u6709\u6548\u7f13\u89e3\u3002", "motivation": "\u73b0\u6709 AI \u98ce\u9669\u8bc4\u4f30\u6a21\u578b\u4fa7\u91cd\u4e8e\u5185\u90e8\u5408\u89c4\u6027\uff0c\u5ffd\u89c6\u4e86\u591a\u65b9\u5229\u76ca\u76f8\u5173\u8005\u7684\u89c2\u70b9\u548c\u73b0\u5b9e\u4e16\u754c\u7684\u540e\u679c\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e9b\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a AI Harmonics \u7684\u65b0\u8303\u5f0f\uff0c\u5b83\u91c7\u7528\u57fa\u4e8e\u7ecf\u9a8c\u4e8b\u4ef6\u6570\u636e\u3001\u4ee5\u4eba\u4e3a\u672c\u3001\u6839\u636e\u5371\u5bb3\u4e25\u91cd\u6027\u8fdb\u884c\u81ea\u9002\u5e94\u7684\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u5305\u62ec\u4e00\u4e2a\u65b0\u7684 AI \u5371\u5bb3\u8bc4\u4f30\u6307\u6807\uff08AIH\uff09\uff0c\u5b83\u5229\u7528\u6709\u5e8f\u7684\u4e25\u91cd\u6027\u6570\u636e\u6765\u6355\u83b7\u76f8\u5bf9\u5f71\u54cd\uff0c\u800c\u65e0\u9700\u7cbe\u786e\u7684\u6570\u503c\u4f30\u8ba1\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u653f\u6cbb\u548c\u8eab\u4f53\u5371\u5bb3\u7684\u96c6\u4e2d\u5ea6\u6700\u9ad8\uff0c\u9700\u8981\u7d27\u6025\u7f13\u89e3\u3002\u653f\u6cbb\u5371\u5bb3\u4f1a\u4fb5\u8680\u516c\u4f17\u4fe1\u4efb\uff0c\u800c\u8eab\u4f53\u5371\u5bb3\u5219\u6784\u6210\u4e25\u91cd\u751a\u81f3\u5371\u53ca\u751f\u547d\u7684\u98ce\u9669\u3002AI Harmonics \u80fd\u591f\u8bc6\u522b\u4e0d\u5747\u8861\u7684\u5371\u5bb3\u5206\u5e03\uff0c\u4ece\u800c\u80fd\u591f\u66f4\u6709\u6548\u5730\u8fdb\u884c\u7f13\u89e3\u3002", "conclusion": "AI Harmonics \u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u3001\u4ee5\u6570\u636e\u4e3a\u9a71\u52a8\u7684\u3001\u6ce8\u91cd\u5229\u76ca\u76f8\u5173\u8005\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u63a2\u7d22\u548c\u4f18\u5148\u6392\u5e8f AI \u5371\u5bb3\uff0c\u4ece\u800c\u80fd\u591f\u66f4\u6709\u6548\u5730\u5206\u914d\u7f13\u89e3\u8d44\u6e90\u3002"}}
{"id": "2509.10353", "categories": ["eess.SY", "cs.RO", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.10353", "abs": "https://arxiv.org/abs/2509.10353", "authors": ["Davide Gorbani", "Mohamed Elobaid", "Giuseppe L'Erario", "Hosameldin Awadalla Omer Mohamed", "Daniele Pucci"], "title": "Data-fused Model Predictive Control with Guarantees: Application to Flying Humanoid Robots", "comment": "8 pages, 3 figures", "summary": "This paper introduces a Data-Fused Model Predictive Control (DFMPC) framework\nthat combines physics-based models with data-driven representations of unknown\ndynamics. Leveraging Willems' Fundamental Lemma and an artificial equilibrium\nformulation, the method enables tracking of changing, potentially unreachable\nsetpoints while explicitly handling measurement noise through slack variables\nand regularization. We provide guarantees of recursive feasibility and\npractical stability under input-output constraints for a specific class of\nreference signals. The approach is validated on the iRonCub flying humanoid\nrobot, integrating analytical momentum models with data-driven turbine\ndynamics. Simulations show improved tracking and robustness compared to a\npurely model-based MPC, while maintaining real-time feasibility.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u6570\u636e\u878d\u5408\u6a21\u578b\u9884\u6d4b\u63a7\u5236\uff08DFMPC\uff09\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u57fa\u4e8e\u7269\u7406\u7684\u6a21\u578b\u548c\u6570\u636e\u9a71\u52a8\u7684\u672a\u77e5\u52a8\u6001\u8868\u793a\uff0c\u4ee5\u5b9e\u73b0\u5bf9\u53d8\u5316\u7684\u3001\u53ef\u80fd\u4e0d\u53ef\u8fbe\u7684\u8bbe\u5b9a\u70b9\u7684\u8ddf\u8e2a\uff0c\u540c\u65f6\u663e\u5f0f\u5904\u7406\u6d4b\u91cf\u566a\u58f0\u3002", "motivation": "\u8be5\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u4f20\u7edfMPC\u5728\u5904\u7406\u672a\u77e5\u52a8\u6001\u3001\u53d8\u5316\u8bbe\u5b9a\u70b9\u548c\u6d4b\u91cf\u566a\u58f0\u65b9\u9762\u7684\u6311\u6218\uff0c\u63d0\u51fa\u4e00\u79cd\u80fd\u591f\u878d\u5408\u7269\u7406\u6a21\u578b\u548c\u6570\u636e\u9a71\u52a8\u6a21\u578b\uff0c\u5e76\u4fdd\u8bc1\u7a33\u5b9a\u6027\u548c\u53ef\u884c\u6027\u7684\u63a7\u5236\u6846\u67b6\u3002", "method": "DFMPC\u6846\u67b6\u5229\u7528Willems' Fundamental Lemma\u548c\u4eba\u5de5\u5e73\u8861\u516c\u5f0f\uff0c\u6574\u5408\u4e86\u57fa\u4e8e\u7269\u7406\u7684\u5206\u6790\u52a8\u91cf\u6a21\u578b\u548c\u6570\u636e\u9a71\u52a8\u7684\u6da1\u8f6e\u673a\u52a8\u6001\u6a21\u578b\u3002\u901a\u8fc7\u5f15\u5165\u677e\u5f1b\u53d8\u91cf\u548c\u6b63\u5219\u5316\u6765\u5904\u7406\u6d4b\u91cf\u566a\u58f0\uff0c\u5e76\u63d0\u4f9b\u8f93\u5165\u8f93\u51fa\u7ea6\u675f\u4e0b\u7279\u5b9a\u53c2\u8003\u4fe1\u53f7\u7684\u9012\u5f52\u53ef\u884c\u6027\u548c\u5b9e\u9645\u7a33\u5b9a\u6027\u4fdd\u8bc1\u3002", "result": "\u5728iRonCub\u98de\u884c\u4eba\u5f62\u673a\u5668\u4eba\u4e0a\u7684\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u7eaf\u57fa\u4e8e\u6a21\u578b\u7684MPC\u76f8\u6bd4\uff0cDFMPC\u5728\u8ddf\u8e2a\u548c\u9c81\u68d2\u6027\u65b9\u9762\u6709\u6240\u63d0\u9ad8\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5b9e\u65f6\u53ef\u884c\u6027\u3002", "conclusion": "DFMPC\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u7269\u7406\u6a21\u578b\u548c\u6570\u636e\u9a71\u52a8\u6a21\u578b\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u5bf9\u590d\u6742\u52a8\u6001\u7cfb\u7edf\u7684\u7cbe\u786e\u8ddf\u8e2a\u548c\u9c81\u68d2\u63a7\u5236\uff0c\u5e76\u5728\u8ba1\u7b97\u6548\u7387\u548c\u7a33\u5b9a\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u673a\u5668\u4eba\u63a7\u5236\u7b49\u9886\u57df\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2509.09841", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.09841", "abs": "https://arxiv.org/abs/2509.09841", "authors": ["Chengyu Yang", "Rishik Reddy Yesgari", "Chengjun Liu"], "title": "Patch-based Automatic Rosacea Detection Using the ResNet Deep Learning Framework", "comment": null, "summary": "Rosacea, which is a chronic inflammatory skin condition that manifests with\nfacial redness, papules, and visible blood vessels, often requirs precise and\nearly detection for significantly improving treatment effectiveness. This paper\npresents new patch-based automatic rosacea detection strategies using the\nResNet-18 deep learning framework. The contributions of the proposed strategies\ncome from the following aspects. First, various image pateches are extracted\nfrom the facial images of people in different sizes, shapes, and locations.\nSecond, a number of investigation studies are carried out to evaluate how the\nlocalized visual information influences the deep learing model performance.\nThird, thorough experiments are implemented to reveal that several patch-based\nautomatic rosacea detection strategies achieve competitive or superior accuracy\nand sensitivity than the full-image based methods. And finally, the proposed\npatch-based strategies, which use only localized patches, inherently preserve\npatient privacy by excluding any identifiable facial features from the data.\nThe experimental results indicate that the proposed patch-based strategies\nguide the deep learning model to focus on clinically relevant regions, enhance\nrobustness and interpretability, and protect patient privacy. As a result, the\nproposed strategies offer practical insights for improving automated\ndermatological diagnostics.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u57fa\u4e8eResNet-18\u7684\u6591\u5757\u5316\u81ea\u52a8\u8bca\u65ad\u73ab\u7470\u75e4\u75ae\u7b56\u7565\uff0c\u65e0\u9700\u4f7f\u7528\u5b8c\u6574\u4eba\u8138\u56fe\u50cf\uff0c\u5373\u53ef\u5b9e\u73b0\u9ad8\u51c6\u786e\u7387\u3001\u9ad8\u654f\u611f\u6027\uff0c\u5e76\u4fdd\u62a4\u60a3\u8005\u9690\u79c1\u3002", "motivation": "\u73ab\u7470\u75e4\u75ae\u662f\u4e00\u79cd\u6162\u6027\u708e\u75c7\u6027\u76ae\u80a4\u75c5\uff0c\u65e9\u671f\u7cbe\u786e\u68c0\u6d4b\u5bf9\u63d0\u9ad8\u7597\u6548\u81f3\u5173\u91cd\u8981\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u65b0\u7684\u6591\u5757\u5316\u81ea\u52a8\u8bca\u65ad\u73ab\u7470\u75e4\u75ae\u7b56\u7565\uff0c\u91c7\u7528ResNet-18\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u3002\u901a\u8fc7\u63d0\u53d6\u4e0d\u540c\u5927\u5c0f\u3001\u5f62\u72b6\u548c\u4f4d\u7f6e\u7684\u9762\u90e8\u56fe\u50cf\u6591\u5757\uff0c\u5e76\u7814\u7a76\u5c40\u90e8\u89c6\u89c9\u4fe1\u606f\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u6591\u5757\u5316\u7b56\u7565\u5728\u51c6\u786e\u7387\u548c\u654f\u611f\u6027\u65b9\u9762\uff0c\u80fd\u591f\u8fbe\u5230\u4e0e\u5b8c\u6574\u56fe\u50cf\u76f8\u5f53\u751a\u81f3\u66f4\u4f18\u7684\u6027\u80fd\uff0c\u5e76\u80fd\u4fdd\u62a4\u60a3\u8005\u9690\u79c1\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6591\u5757\u5316\u7b56\u7565\u80fd\u5f15\u5bfc\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5173\u6ce8\u4e34\u5e8a\u76f8\u5173\u533a\u57df\uff0c\u589e\u5f3a\u9c81\u68d2\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u540c\u65f6\u4fdd\u62a4\u60a3\u8005\u9690\u79c1\uff0c\u4e3a\u6539\u5584\u81ea\u52a8\u5316\u76ae\u80a4\u75c5\u8bca\u65ad\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89c1\u89e3\u3002"}}
{"id": "2509.10139", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.10139", "abs": "https://arxiv.org/abs/2509.10139", "authors": ["Santiago Montiel-Mar\u00edn", "Angel Llamazares", "Miguel Antunes-Garc\u00eda", "Fabio S\u00e1nchez-Garc\u00eda", "Luis M. Bergasa"], "title": "CaR1: A Multi-Modal Baseline for BEV Vehicle Segmentation via Camera-Radar Fusion", "comment": "4 pages, 2 figures", "summary": "Camera-radar fusion offers a robust and cost-effective alternative to\nLiDAR-based autonomous driving systems by combining complementary sensing\ncapabilities: cameras provide rich semantic cues but unreliable depth, while\nradar delivers sparse yet reliable position and motion information. We\nintroduce CaR1, a novel camera-radar fusion architecture for BEV vehicle\nsegmentation. Built upon BEVFusion, our approach incorporates a grid-wise radar\nencoding that discretizes point clouds into structured BEV features and an\nadaptive fusion mechanism that dynamically balances sensor contributions.\nExperiments on nuScenes demonstrate competitive segmentation performance (57.6\nIoU), on par with state-of-the-art methods. Code is publicly available\n\\href{https://www.github.com/santimontiel/car1}{online}.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a CaR1 \u7684\u65b0\u578b\u76f8\u673a-\u96f7\u8fbe\u878d\u5408\u67b6\u6784\uff0c\u7528\u4e8e\u9e1f\u77b0\u56fe\uff08BEV\uff09\u8f66\u8f86\u5206\u5272\uff0c\u65e8\u5728\u63d0\u4f9b\u6bd4 LiDAR \u66f4\u5177\u6210\u672c\u6548\u76ca\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "motivation": "\u76f8\u673a\u63d0\u4f9b\u4e30\u5bcc\u7684\u8bed\u4e49\u4fe1\u606f\u4f46\u6df1\u5ea6\u4fe1\u606f\u4e0d\u53ef\u9760\uff0c\u800c\u96f7\u8fbe\u63d0\u4f9b\u7a00\u758f\u4f46\u53ef\u9760\u7684\u4f4d\u7f6e\u548c\u8fd0\u52a8\u4fe1\u606f\u3002\u76f8\u673a-\u96f7\u8fbe\u878d\u5408\u53ef\u4ee5\u63d0\u4f9b\u66f4\u9c81\u68d2\u548c\u7ecf\u6d4e\u9ad8\u6548\u7684\u81ea\u52a8\u9a7e\u9a76\u611f\u77e5\u65b9\u6848\u3002", "method": "CaR1 \u67b6\u6784\u57fa\u4e8e BEVFusion\uff0c\u5e76\u5f15\u5165\u4e86\u7f51\u683c\u5316\u96f7\u8fbe\u7f16\u7801\uff08\u5c06\u70b9\u4e91\u79bb\u6563\u5316\u4e3a\u7ed3\u6784\u5316\u7684 BEV \u7279\u5f81\uff09\u548c\u81ea\u9002\u5e94\u878d\u5408\u673a\u5236\uff08\u52a8\u6001\u5e73\u8861\u4f20\u611f\u5668\u8d21\u732e\uff09\u3002", "result": "\u5728 nuScenes \u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCaR1 \u5728 BEV \u8f66\u8f86\u5206\u5272\u65b9\u9762\u8fbe\u5230\u4e86 57.6 \u7684 IoU\uff0c\u6027\u80fd\u4e0e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u76f8\u5f53\u3002", "conclusion": "CaR1 \u67b6\u6784\u5728\u76f8\u673a-\u96f7\u8fbe\u878d\u5408\u65b9\u9762\u53d6\u5f97\u4e86\u5177\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\uff0c\u4e3a\u81ea\u52a8\u9a7e\u9a76\u611f\u77e5\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.10100", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2509.10100", "abs": "https://arxiv.org/abs/2509.10100", "authors": ["E. B. Fel'dman", "J. Wu", "A. I. Zenchuk"], "title": "Perfect quantum state transfer via state restoring and ancilla measurement", "comment": "41 pages, 9 figures", "summary": "We propose the protocol for perfect state transfer of an arbitrary pure\nquantum state along the spin-1/2 chain governed by the Hamiltonian preserving\nthe excitation number in the system. We show that the $k$-excitation pure\nsender's state can be restored at the receiver using only the local\ntransformations over the qubits of the extended receiver. The restored state\nappears in the superposition with other states which form garbage. This garbage\ncan be easily removed by including the ancilla whose state labels the garbage,\nand then measuring the {ancilla state} with desired output. The resulting state\nof the receiver coincides with the initial sender's state {up to the\nunimportant common phase factor.} Then, to transfer an arbitrary {pure} state\nof some system $S_0$, we encode this state into the $k$-excitation state of the\nsender, transfer and restore it and finally decode the restored $k$-excitation\nstate {of the receiver} into the state of another subsystem $R_0$. After\nlabeling and removing the garbage via measuring the state of the ancillae we\ncomplete the algorithm for PST.", "AI": {"tldr": "\u8be5\u534f\u8bae\u5b9e\u73b0\u4e86\u81ea\u65cb1/2\u94fe\u4e0a\u7684\u4efb\u610f\u7eaf\u91cf\u5b50\u6001\u7684\u5b8c\u7f8e\u6001\u4f20\u8f93\uff0c\u4ec5\u9700\u5bf9\u6269\u5c55\u63a5\u6536\u5668\u7684\u91cf\u5b50\u6bd4\u7279\u8fdb\u884c\u5c40\u90e8\u53d8\u6362\uff0c\u5e76\u901a\u8fc7\u6d4b\u91cf\u8f85\u52a9\u91cf\u5b50\u6bd4\u7279\u53bb\u9664\u5783\u573e\u6001\u3002", "motivation": "\u63d0\u51fa\u4e00\u4e2a\u5728\u4fdd\u6301\u6fc0\u53d1\u6570\u5b88\u6052\u7684\u54c8\u5bc6\u987f\u91cf\u63a7\u5236\u7684\u81ea\u65cb1/2\u94fe\u4e0a\u5b9e\u73b0\u4efb\u610f\u7eaf\u91cf\u5b50\u6001\u5b8c\u7f8e\u6001\u4f20\u8f93\u7684\u534f\u8bae\u3002", "method": "\u901a\u8fc7\u5c40\u90e8\u53d8\u6362\u548c\u6d4b\u91cf\u8f85\u52a9\u91cf\u5b50\u6bd4\u7279\u6765\u6062\u590d\u548c\u51c0\u5316\u4f20\u8f93\u7684\u91cf\u5b50\u6001\u3002", "result": "\u5728\u63a5\u6536\u5668\u7aef\u53ef\u4ee5\u6062\u590d\u4efb\u610fk-\u6fc0\u53d1\u7eaf\u53d1\u9001\u5668\u72b6\u6001\uff0c\u5e76\u901a\u8fc7\u6d4b\u91cf\u8f85\u52a9\u91cf\u5b50\u6bd4\u7279\u53bb\u9664\u5783\u573e\u6001\uff0c\u6700\u7ec8\u5f97\u5230\u4e0e\u521d\u59cb\u72b6\u6001\uff08\u76f8\u4f4d\u76f8\u5dee\u53ef\u5ffd\u7565\uff09\u4e00\u81f4\u7684\u72b6\u6001\u3002", "conclusion": "\u8be5\u534f\u8bae\u5b9e\u73b0\u4e86\u4efb\u610f\u7eaf\u91cf\u5b50\u6001\u7684\u5b8c\u7f8e\u6001\u4f20\u8f93\uff0c\u5305\u62ec\u7f16\u7801\u3001\u4f20\u8f93\u3001\u6062\u590d\u3001\u89e3\u7801\u548c\u5783\u573e\u6001\u53bb\u9664\u7b49\u6b65\u9aa4\u3002"}}
{"id": "2509.09714", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09714", "abs": "https://arxiv.org/abs/2509.09714", "authors": ["Serge Lionel Nikiema", "Alb\u00e9rick Euraste Djire", "Abdoul Aziz Bonkoungou", "Micheline B\u00e9n\u00e9dicte Moumoula", "Jordan Samhi", "Abdoul Kader Kabore", "Jacques Klein", "Tegawend\u00e9 F. Bissyande"], "title": "How Small Transformation Expose the Weakness of Semantic Similarity Measures", "comment": null, "summary": "This research examines how well different methods measure semantic\nsimilarity, which is important for various software engineering applications\nsuch as code search, API recommendations, automated code reviews, and\nrefactoring tools. While large language models are increasingly used for these\nsimilarity assessments, questions remain about whether they truly understand\nsemantic relationships or merely recognize surface patterns.\n  The study tested 18 different similarity measurement approaches, including\nword-based methods, embedding techniques, LLM-based systems, and\nstructure-aware algorithms. The researchers created a systematic testing\nframework that applies controlled changes to text and code to evaluate how well\neach method handles different types of semantic relationships.\n  The results revealed significant issues with commonly used metrics. Some\nembedding-based methods incorrectly identified semantic opposites as similar up\nto 99.9 percent of the time, while certain transformer-based approaches\noccasionally rated opposite meanings as more similar than synonymous ones. The\nstudy found that embedding methods' poor performance often stemmed from how\nthey calculate distances; switching from Euclidean distance to cosine\nsimilarity improved results by 24 to 66 percent. LLM-based approaches performed\nbetter at distinguishing semantic differences, producing low similarity scores\n(0.00 to 0.29) for genuinely different meanings, compared to embedding methods\nthat incorrectly assigned high scores (0.82 to 0.99) to dissimilar content.", "AI": {"tldr": "\u4e0d\u540c\u7684\u8bed\u4e49\u76f8\u4f3c\u6027\u6d4b\u91cf\u65b9\u6cd5\u5728\u8f6f\u4ef6\u5de5\u7a0b\u5e94\u7528\u4e2d\u7684\u8868\u73b0\u5dee\u5f02\u663e\u8457\uff0c\u5176\u4e2d\u57fa\u4e8e\u5d4c\u5165\u7684\u65b9\u6cd5\u5b58\u5728\u8f83\u5927\u95ee\u9898\uff0c\u800c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8868\u73b0\u76f8\u5bf9\u8f83\u597d\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u8bc4\u4f30\u4e0d\u540c\u65b9\u6cd5\u5728\u8861\u91cf\u8bed\u4e49\u76f8\u4f3c\u6027\u65b9\u9762\u7684\u8868\u73b0\uff0c\u56e0\u4e3a\u8bed\u4e49\u76f8\u4f3c\u6027\u5bf9\u4e8e\u4ee3\u7801\u641c\u7d22\u3001API\u63a8\u8350\u3001\u81ea\u52a8\u5316\u4ee3\u7801\u5ba1\u67e5\u548c\u91cd\u6784\u5de5\u5177\u7b49\u8f6f\u4ef6\u5de5\u7a0b\u5e94\u7528\u81f3\u5173\u91cd\u8981\uff0c\u540c\u65f6\u63a2\u8ba8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8fd9\u65b9\u9762\u7684\u771f\u6b63\u7406\u89e3\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u5316\u7684\u6d4b\u8bd5\u6846\u67b6\uff0c\u5bf918\u79cd\u4e0d\u540c\u7684\u8bed\u4e49\u76f8\u4f3c\u6027\u6d4b\u91cf\u65b9\u6cd5\uff08\u5305\u62ec\u57fa\u4e8e\u8bcd\u3001\u57fa\u4e8e\u5d4c\u5165\u3001\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u7ed3\u6784\u611f\u77e5\u7b97\u6cd5\uff09\u8fdb\u884c\u6d4b\u8bd5\uff0c\u5e76\u5bf9\u6587\u672c\u548c\u4ee3\u7801\u8fdb\u884c\u53d7\u63a7\u66f4\u6539\u4ee5\u8bc4\u4f30\u5b83\u4eec\u5904\u7406\u4e0d\u540c\u8bed\u4e49\u5173\u7cfb\u7684\u80fd\u529b\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5e38\u7528\u7684\u5d4c\u5165\u5f0f\u65b9\u6cd5\u5728\u8bc6\u522b\u8bed\u4e49\u76f8\u53cd\u9879\u65f6\u51c6\u786e\u7387\u4f4e\uff08\u9ad8\u8fbe99.9%\uff09\uff0c\u751a\u81f3\u5c06\u76f8\u53cd\u542b\u4e49\u7684\u5185\u5bb9\u8bc4\u4e3a\u6bd4\u540c\u4e49\u8bcd\u66f4\u76f8\u4f3c\u3002\u5c06\u6b27\u6c0f\u8ddd\u79bb\u6539\u4e3a\u4f59\u5f26\u76f8\u4f3c\u6027\u53ef\u5c06\u5d4c\u5165\u5f0f\u65b9\u6cd5\u7684\u6027\u80fd\u63d0\u9ad824%\u81f366%\u3002\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u533a\u5206\u8bed\u4e49\u5dee\u5f02\u65b9\u9762\u8868\u73b0\u66f4\u597d\uff0c\u5bf9\u4e0d\u540c\u542b\u4e49\u7684\u5185\u5bb9\u7ed9\u51fa\u8f83\u4f4e\u7684\u76f8\u4f3c\u5ea6\u5f97\u5206\uff080.00\u81f30.29\uff09\uff0c\u800c\u5d4c\u5165\u5f0f\u65b9\u6cd5\u5219\u9519\u8bef\u5730\u7ed9\u51fa\u8f83\u9ad8\u7684\u5f97\u5206\uff080.82\u81f30.99\uff09\u3002", "conclusion": "\u76ee\u524d\u5e38\u7528\u7684\u8bed\u4e49\u76f8\u4f3c\u6027\u6d4b\u91cf\u65b9\u6cd5\uff0c\u5c24\u5176\u662f\u57fa\u4e8e\u5d4c\u5165\u7684\u65b9\u6cd5\uff0c\u5b58\u5728\u663e\u8457\u7684\u5c40\u9650\u6027\u3002\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u533a\u5206\u8bed\u4e49\u76f8\u4f3c\u6027\u548c\u5dee\u5f02\u6027\u65b9\u9762\u5c55\u73b0\u51fa\u66f4\u5927\u7684\u6f5c\u529b\uff0c\u4f46\u4ecd\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u4f18\u5316\u3002"}}
{"id": "2509.09933", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.09933", "abs": "https://arxiv.org/abs/2509.09933", "authors": ["Shintaro Nakamura", "Yuko Kuroki", "Wei Chen"], "title": "Multi-Play Combinatorial Semi-Bandit Problem", "comment": null, "summary": "In the combinatorial semi-bandit (CSB) problem, a player selects an action\nfrom a combinatorial action set and observes feedback from the base arms\nincluded in the action. While CSB is widely applicable to combinatorial\noptimization problems, its restriction to binary decision spaces excludes\nimportant cases involving non-negative integer flows or allocations, such as\nthe optimal transport and knapsack problems.To overcome this limitation, we\npropose the multi-play combinatorial semi-bandit (MP-CSB), where a player can\nselect a non-negative integer action and observe multiple feedbacks from a\nsingle arm in each round. We propose two algorithms for the MP-CSB. One is a\nThompson-sampling-based algorithm that is computationally feasible even when\nthe action space is exponentially large with respect to the number of arms, and\nattains $O(\\log T)$ distribution-dependent regret in the stochastic regime,\nwhere $T$ is the time horizon. The other is a best-of-both-worlds algorithm,\nwhich achieves $O(\\log T)$ variance-dependent regret in the stochastic regime\nand the worst-case $\\tilde{\\mathcal{O}}\\left( \\sqrt{T} \\right)$ regret in the\nadversarial regime. Moreover, its regret in adversarial one is data-dependent,\nadapting to the cumulative loss of the optimal action, the total quadratic\nvariation, and the path-length of the loss sequence. Finally, we numerically\nshow that the proposed algorithms outperform existing methods in the CSB\nliterature.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2509.10147", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10147", "abs": "https://arxiv.org/abs/2509.10147", "authors": ["Nenad Tomasev", "Matija Franklin", "Joel Z. Leibo", "Julian Jacobs", "William A. Cunningham", "Iason Gabriel", "Simon Osindero"], "title": "Virtual Agent Economies", "comment": null, "summary": "The rapid adoption of autonomous AI agents is giving rise to a new economic\nlayer where agents transact and coordinate at scales and speeds beyond direct\nhuman oversight. We propose the \"sandbox economy\" as a framework for analyzing\nthis emergent system, characterizing it along two key dimensions: its origins\n(emergent vs. intentional) and its degree of separateness from the established\nhuman economy (permeable vs. impermeable). Our current trajectory points toward\na spontaneous emergence of a vast and highly permeable AI agent economy,\npresenting us with opportunities for an unprecedented degree of coordination as\nwell as significant challenges, including systemic economic risk and\nexacerbated inequality. Here we discuss a number of possible design choices\nthat may lead to safely steerable AI agent markets. In particular, we consider\nauction mechanisms for fair resource allocation and preference resolution, the\ndesign of AI \"mission economies\" to coordinate around achieving collective\ngoals, and socio-technical infrastructure needed to ensure trust, safety, and\naccountability. By doing this, we argue for the proactive design of steerable\nagent markets to ensure the coming technological shift aligns with humanity's\nlong-term collective flourishing.", "AI": {"tldr": "AI \u4ee3\u7406\u6b63\u5728\u5f62\u6210\u4e00\u4e2a\u72ec\u7acb\u7684\u201c\u6c99\u76d2\u7ecf\u6d4e\u201d\uff0c\u53ef\u80fd\u5e26\u6765\u673a\u9047\u548c\u98ce\u9669\u3002\u9700\u8981\u8bbe\u8ba1\u53ef\u63a7\u7684 AI \u5e02\u573a\uff0c\u4f8b\u5982\u901a\u8fc7\u62cd\u5356\u548c\u4efb\u52a1\u7ecf\u6d4e\uff0c\u4ee5\u786e\u4fdd\u5176\u53d1\u5c55\u7b26\u5408\u4eba\u7c7b\u7684\u957f\u8fdc\u5229\u76ca\u3002", "motivation": "\u968f\u7740\u81ea\u4e3b AI \u4ee3\u7406\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u51fa\u73b0\u4e86\u4e00\u4e2a\u65b0\u7684\u7ecf\u6d4e\u5c42\uff0c\u5176\u4ea4\u6613\u548c\u534f\u8c03\u89c4\u6a21\u53ca\u901f\u5ea6\u8d85\u51fa\u4e86\u4eba\u7c7b\u7684\u76f4\u63a5\u76d1\u7763\u3002", "method": "\u63d0\u51fa\u4e86\u201c\u6c99\u76d2\u7ecf\u6d4e\u201d\u6846\u67b6\uff0c\u901a\u8fc7\u5176\u8d77\u6e90\uff08\u6d8c\u73b0 vs. \u610f\u5411\uff09\u548c\u4e0e\u73b0\u6709\u7ecf\u6d4e\u7684\u9694\u79bb\u7a0b\u5ea6\uff08\u53ef\u6e17\u900f vs. \u4e0d\u53ef\u6e17\u900f\uff09\u4e24\u4e2a\u5173\u952e\u7ef4\u5ea6\u6765\u5206\u6790\u8fd9\u4e00\u65b0\u5174\u7cfb\u7edf\u3002\u63a2\u8ba8\u4e86\u5b9e\u73b0\u53ef\u63a7 AI \u4ee3\u7406\u5e02\u573a\u7684\u5173\u952e\u8bbe\u8ba1\u9009\u62e9\uff0c\u5305\u62ec\u7528\u4e8e\u8d44\u6e90\u5206\u914d\u548c\u504f\u597d\u89e3\u51b3\u7684\u62cd\u5356\u673a\u5236\u3001\u7528\u4e8e\u534f\u8c03\u96c6\u4f53\u76ee\u6807\u7684 AI\u201c\u4efb\u52a1\u7ecf\u6d4e\u201d\uff0c\u4ee5\u53ca\u786e\u4fdd\u4fe1\u4efb\u3001\u5b89\u5168\u548c\u95ee\u8d23\u5236\u7684\u793e\u4f1a\u6280\u672f\u57fa\u7840\u8bbe\u65bd\u3002", "result": "\u5f53\u524d\u7684\u8d8b\u52bf\u662f\u81ea\u53d1\u5730\u51fa\u73b0\u4e00\u4e2a\u5e9e\u5927\u4e14\u9ad8\u5ea6\u53ef\u6e17\u900f\u7684 AI \u4ee3\u7406\u7ecf\u6d4e\uff0c\u8fd9\u5e26\u6765\u4e86\u524d\u6240\u672a\u6709\u7684\u534f\u8c03\u673a\u4f1a\uff0c\u4f46\u4e5f\u4f34\u968f\u7740\u7cfb\u7edf\u6027\u7ecf\u6d4e\u98ce\u9669\u548c\u52a0\u5267\u7684\u4e0d\u5e73\u7b49\u6311\u6218\u3002", "conclusion": "\u4e3b\u5f20\u901a\u8fc7\u4e3b\u52a8\u8bbe\u8ba1\u53ef\u63a7\u7684\u4ee3\u7406\u5e02\u573a\uff0c\u4f8b\u5982\u91c7\u7528\u62cd\u5356\u673a\u5236\u548c\u4efb\u52a1\u7ecf\u6d4e\uff0c\u6765\u5f15\u5bfc AI \u7ecf\u6d4e\u7684\u53d1\u5c55\uff0c\u786e\u4fdd\u8fd9\u4e00\u6280\u672f\u8f6c\u53d8\u7b26\u5408\u4eba\u7c7b\u957f\u671f\u7684\u96c6\u4f53\u798f\u7949\u3002"}}
{"id": "2509.10380", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.10380", "abs": "https://arxiv.org/abs/2509.10380", "authors": ["Yusheng Zheng", "Wenxue Liu", "Yunhong Che", "Ferdinand Grimm", "Jingyuan Zhao", "Xiaosong Hu", "Simona Onori", "Remus Teodorescu", "Gregory J. Offer"], "title": "Merging Physics-Based Synthetic Data and Machine Learning for Thermal Monitoring of Lithium-ion Batteries: The Role of Data Fidelity", "comment": null, "summary": "Since the internal temperature is less accessible than surface temperature,\nthere is an urgent need to develop accurate and real-time estimation algorithms\nfor better thermal management and safety. This work presents a novel framework\nfor resource-efficient and scalable development of accurate, robust, and\nadaptive internal temperature estimation algorithms by blending physics-based\nmodeling with machine learning, in order to address the key challenges in data\ncollection, model parameterization, and estimator design that traditionally\nhinder both approaches. In this framework, a physics-based model is leveraged\nto generate simulation data that includes different operating scenarios by\nsweeping the model parameters and input profiles. Such a cheap simulation\ndataset can be used to pre-train the machine learning algorithm to capture the\nunderlying mapping relationship. To bridge the simulation-to-reality gap\nresulting from imperfect modeling, transfer learning with unsupervised domain\nadaptation is applied to fine-tune the pre-trained machine learning model, by\nusing limited operational data (without internal temperature values) from\ntarget batteries. The proposed framework is validated under different operating\nconditions and across multiple cylindrical batteries with convective air\ncooling, achieving a root mean square error of 0.5 {\\deg}C when relying solely\non prior knowledge of battery thermal properties, and less than 0.1 {\\deg}C\nwhen using thermal parameters close to the ground truth. Furthermore, the role\nof the simulation data quality in the proposed framework has been\ncomprehensively investigated to identify promising ways of synthetic data\ngeneration to guarantee the performance of the machine learning model.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u7269\u7406\u6a21\u578b\u548c\u673a\u5668\u5b66\u4e60\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u5730\u5f00\u53d1\u7cbe\u786e\u3001\u9c81\u68d2\u4e14\u81ea\u9002\u5e94\u7684\u7535\u6c60\u5185\u90e8\u6e29\u5ea6\u4f30\u7b97\u7b97\u6cd5\u3002", "motivation": "\u7531\u4e8e\u5185\u90e8\u6e29\u5ea6\u6bd4\u8868\u9762\u6e29\u5ea6\u66f4\u96be\u83b7\u53d6\uff0c\u56e0\u6b64\u8feb\u5207\u9700\u8981\u5f00\u53d1\u7cbe\u786e\u7684\u5b9e\u65f6\u4f30\u7b97\u7b97\u6cd5\u4ee5\u5b9e\u73b0\u66f4\u597d\u7684\u70ed\u7ba1\u7406\u548c\u5b89\u5168\u3002\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u6570\u636e\u6536\u96c6\u3001\u6a21\u578b\u53c2\u6570\u5316\u548c\u4f30\u8ba1\u5668\u8bbe\u8ba1\u65b9\u9762\u7684\u6311\u6218\u3002", "method": "\u5229\u7528\u7269\u7406\u6a21\u578b\u751f\u6210\u5305\u542b\u4e0d\u540c\u8fd0\u884c\u573a\u666f\u7684\u4eff\u771f\u6570\u636e\uff0c\u7528\u4e8e\u9884\u8bad\u7ec3\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u3002\u7136\u540e\uff0c\u5229\u7528\u8fc1\u79fb\u5b66\u4e60\u548c\u65e0\u76d1\u7763\u57df\u81ea\u9002\u5e94\u6280\u672f\uff0c\u4f7f\u7528\u6709\u9650\u7684\u8fd0\u884c\u6570\u636e\u5bf9\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\uff0c\u4ee5\u5f25\u5408\u4eff\u771f\u4e0e\u73b0\u5b9e\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "result": "\u5728\u4e0d\u540c\u8fd0\u884c\u6761\u4ef6\u548c\u591a\u79cd\u5706\u67f1\u5f62\u7535\u6c60\u4e0a\u8fdb\u884c\u4e86\u9a8c\u8bc1\uff0c\u5728\u4ec5\u4f9d\u8d56\u7535\u6c60\u70ed\u7279\u6027\u5148\u9a8c\u77e5\u8bc6\u7684\u60c5\u51b5\u4e0b\uff0c\u5b9e\u73b0\u4e86 0.5\u00b0C \u7684\u5747\u65b9\u6839\u8bef\u5dee\uff1b\u5728\u4f7f\u7528\u63a5\u8fd1\u771f\u5b9e\u503c\u7684\u70ed\u53c2\u6570\u65f6\uff0c\u8bef\u5dee\u5c0f\u4e8e 0.1\u00b0C\u3002\u6b64\u5916\uff0c\u8fd8\u5168\u9762\u7814\u7a76\u4e86\u4eff\u771f\u6570\u636e\u8d28\u91cf\u5bf9\u6846\u67b6\u6027\u80fd\u7684\u5f71\u54cd\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u5730\u5f00\u53d1\u51fa\u7cbe\u786e\u3001\u9c81\u68d2\u4e14\u81ea\u9002\u5e94\u7684\u7535\u6c60\u5185\u90e8\u6e29\u5ea6\u4f30\u7b97\u7b97\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2509.09844", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.09844", "abs": "https://arxiv.org/abs/2509.09844", "authors": ["Chengyu Yang", "Rishik Reddy Yesgari", "Chengjun Liu"], "title": "Privacy-Preserving Automated Rosacea Detection Based on Medically Inspired Region of Interest Selection", "comment": null, "summary": "Rosacea is a common but underdiagnosed inflammatory skin condition that\nprimarily affects the central face and presents with subtle redness, pustules,\nand visible blood vessels. Automated detection remains challenging due to the\ndiffuse nature of symptoms, the scarcity of labeled datasets, and privacy\nconcerns associated with using identifiable facial images. A novel\nprivacy-preserving automated rosacea detection method inspired by clinical\npriors and trained entirely on synthetic data is presented in this paper.\nSpecifically, the proposed method, which leverages the observation that rosacea\nmanifests predominantly through central facial erythema, first constructs a\nfixed redness-informed mask by selecting regions with consistently high red\nchannel intensity across facial images. The mask thus is able to focus on\ndiagnostically relevant areas such as the cheeks, nose, and forehead and\nexclude identity-revealing features. Second, the ResNet-18 deep learning\nmethod, which is trained on the masked synthetic images, achieves superior\nperformance over the full-face baselines with notable gains in terms of\naccuracy, recall and F1 score when evaluated using the real-world test data.\nThe experimental results demonstrate that the synthetic data and clinical\npriors can jointly enable accurate and ethical dermatological AI systems,\nespecially for privacy sensitive applications in telemedicine and large-scale\nscreening.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u9690\u79c1\u4fdd\u62a4\u578b\u9762\u90e8\u7ea2\u6591\u75e4\u75ae\uff08rosacea\uff09\u81ea\u52a8\u68c0\u6d4b\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5229\u7528\u4e34\u5e8a\u5148\u9a8c\u77e5\u8bc6\uff0c\u5728\u5b8c\u5168\u5408\u6210\u7684\u6570\u636e\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u53d6\u5f97\u4e86\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u7ea2\u6591\u75e4\u75ae\u662f\u4e00\u79cd\u5e38\u89c1\u4f46\u6f0f\u8bca\u7387\u9ad8\u7684\u708e\u75c7\u6027\u76ae\u80a4\u75c5\uff0c\u5176\u75c7\u72b6\u5f25\u6f2b\uff0c\u96be\u4ee5\u81ea\u52a8\u68c0\u6d4b\u3002\u6b64\u5916\uff0c\u7531\u4e8e\u6d89\u53ca\u53ef\u8bc6\u522b\u7684\u9762\u90e8\u56fe\u50cf\uff0c\u6570\u636e\u9690\u79c1\u95ee\u9898\u4e5f\u5e26\u6765\u4e86\u6311\u6218\u3002", "method": "\u8be5\u65b9\u6cd5\u9996\u5148\u901a\u8fc7\u9009\u62e9\u9762\u90e8\u56fe\u50cf\u4e2d\u7ea2\u8272\u901a\u9053\u5f3a\u5ea6\u4e00\u81f4\u8f83\u9ad8\u7684\u533a\u57df\u6765\u6784\u5efa\u4e00\u4e2a\u56fa\u5b9a\u7684\u3001\u4e0e\u7ea2\u6591\u4fe1\u606f\u76f8\u5173\u7684\u9762\u90e8\u63a9\u7801\uff0c\u4ece\u800c\u805a\u7126\u4e8e\u8bca\u65ad\u76f8\u5173\u7684\u533a\u57df\uff08\u5982\u8138\u988a\u3001\u9f3b\u5b50\u3001\u989d\u5934\uff09\uff0c\u5e76\u6392\u9664\u6cc4\u9732\u8eab\u4efd\u7684\u4fe1\u606f\u3002\u7136\u540e\uff0c\u5728\u63a9\u7801\u5904\u7406\u8fc7\u7684\u5408\u6210\u56fe\u50cf\u4e0a\u8bad\u7ec3ResNet-18\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u3002", "result": "\u4e0e\u5728\u5168\u8138\u56fe\u50cf\u4e0a\u8bad\u7ec3\u7684\u6a21\u578b\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u5728\u771f\u5b9e\u4e16\u754c\u6d4b\u8bd5\u6570\u636e\u4e0a\u7684\u51c6\u786e\u7387\u3001\u53ec\u56de\u7387\u548cF1\u5206\u6570\u5747\u6709\u663e\u8457\u63d0\u9ad8\u3002", "conclusion": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5408\u6210\u6570\u636e\u548c\u4e34\u5e8a\u5148\u9a8c\u77e5\u8bc6\u7684\u7ed3\u5408\u53ef\u4ee5\u5b9e\u73b0\u51c6\u786e\u4e14\u5408\u4e4e\u9053\u5fb7\u7684\u76ae\u80a4\u75c5\u5b66\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\uff0c\u7279\u522b\u9002\u7528\u4e8e\u8fdc\u7a0b\u533b\u7597\u548c\u5927\u89c4\u6a21\u7b5b\u67e5\u7b49\u6ce8\u91cd\u9690\u79c1\u7684\u573a\u666f\u3002"}}
{"id": "2509.10247", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.10247", "abs": "https://arxiv.org/abs/2509.10247", "authors": ["Xinhong Zhang", "Runqing Wang", "Yunfan Ren", "Jian Sun", "Hao Fang", "Jie Chen", "Gang Wang"], "title": "DiffAero: A GPU-Accelerated Differentiable Simulation Framework for Efficient Quadrotor Policy Learning", "comment": "8 pages, 11 figures, 1 table", "summary": "This letter introduces DiffAero, a lightweight, GPU-accelerated, and fully\ndifferentiable simulation framework designed for efficient quadrotor control\npolicy learning. DiffAero supports both environment-level and agent-level\nparallelism and integrates multiple dynamics models, customizable sensor stacks\n(IMU, depth camera, and LiDAR), and diverse flight tasks within a unified,\nGPU-native training interface. By fully parallelizing both physics and\nrendering on the GPU, DiffAero eliminates CPU-GPU data transfer bottlenecks and\ndelivers orders-of-magnitude improvements in simulation throughput. In contrast\nto existing simulators, DiffAero not only provides high-performance simulation\nbut also serves as a research platform for exploring differentiable and hybrid\nlearning algorithms. Extensive benchmarks and real-world flight experiments\ndemonstrate that DiffAero and hybrid learning algorithms combined can learn\nrobust flight policies in hours on consumer-grade hardware. The code is\navailable at https://github.com/flyingbitac/diffaero.", "AI": {"tldr": "DiffAero\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u3001GPU\u52a0\u901f\u3001\u5b8c\u5168\u53ef\u5fae\u5206\u7684\u56db\u65cb\u7ffc\u63a7\u5236\u7b56\u7565\u5b66\u4e60\u6a21\u62df\u6846\u67b6\uff0c\u901a\u8fc7GPU\u5e76\u884c\u5316\u7269\u7406\u548c\u6e32\u67d3\uff0c\u63d0\u9ad8\u4e86\u6a21\u62df\u541e\u5410\u91cf\uff0c\u5e76\u652f\u6301\u591a\u79cd\u52a8\u529b\u5b66\u6a21\u578b\u3001\u4f20\u611f\u5668\u548c\u98de\u884c\u4efb\u52a1\u3002", "motivation": "\u4e3a\u4e86\u5b9e\u73b0\u9ad8\u6548\u7684\u56db\u65cb\u7ffc\u63a7\u5236\u7b56\u7565\u5b66\u4e60\uff0c\u9700\u8981\u4e00\u4e2a\u80fd\u591f\u5229\u7528GPU\u52a0\u901f\u3001\u652f\u6301\u591a\u79cd\u6a21\u578b\u548c\u4efb\u52a1\u3001\u5e76\u6d88\u9664CPU-GPU\u6570\u636e\u4f20\u8f93\u74f6\u9888\u7684\u6a21\u62df\u5668\u3002", "method": "DiffAero\u5229\u7528GPU\u5e76\u884c\u5316\u7269\u7406\u548c\u6e32\u67d3\uff0c\u652f\u6301\u73af\u5883\u7ea7\u548c\u4ee3\u7406\u7ea7\u5e76\u884c\uff0c\u96c6\u6210\u4e86\u591a\u79cd\u52a8\u529b\u5b66\u6a21\u578b\u3001\u4f20\u611f\u5668\uff08IMU\u3001\u6df1\u5ea6\u76f8\u673a\u3001LiDAR\uff09\u548c\u98de\u884c\u4efb\u52a1\uff0c\u63d0\u4f9b\u7edf\u4e00\u7684GPU\u539f\u751f\u8bad\u7ec3\u63a5\u53e3\u3002", "result": "\u4e0e\u73b0\u6709\u6a21\u62df\u5668\u76f8\u6bd4\uff0cDiffAero\u663e\u8457\u63d0\u9ad8\u4e86\u6a21\u62df\u541e\u5410\u91cf\uff0c\u5e76\u5141\u8bb8\u5728\u6d88\u8d39\u7ea7\u786c\u4ef6\u4e0a\u901a\u8fc7\u51e0\u5c0f\u65f6\u7684\u8bad\u7ec3\u5b66\u4e60\u5230\u9c81\u68d2\u7684\u98de\u884c\u7b56\u7565\u3002", "conclusion": "DiffAero\u4f5c\u4e3a\u4e00\u4e2a\u7814\u7a76\u5e73\u53f0\uff0c\u80fd\u591f\u901a\u8fc7\u7ed3\u5408\u6df7\u5408\u5b66\u4e60\u7b97\u6cd5\uff0c\u5728\u77ed\u65f6\u95f4\u5185\u9ad8\u6548\u5730\u5b66\u4e60\u56db\u65cb\u7ffc\u7684\u9c81\u68d2\u98de\u884c\u7b56\u7565\u3002"}}
{"id": "2509.10119", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2509.10119", "abs": "https://arxiv.org/abs/2509.10119", "authors": ["M. V. Petrenko", "A. K. Vershovskii"], "title": "Bistability of optical properties of cesium vapor due to collective interaction of alignment and orientation under strong spin exchange conditions", "comment": "6 pages, 4 figures", "summary": "Hydrogen-like alkali atoms with a single valence electron are the most common\nobjects in quantum optics and, at the same time, serve as essential tools of\nthe field. Under conditions of optical pumping, strong spin-exchange and\nultra-weak magnetic field (spin-exchange relaxation free mode, SERF), ensembles\nof such atoms in the gas phase can demonstrate not only the absence of\nspin-exchange relaxation, but also nonlinear collective effects. We present\nexperimental evidence that the alignment, i.e. the quadrupole momentum, can not\nonly be preserved under SERF conditions, but also coexist and interact with the\norientation, i.e. the dipole momentum. We also show that this interaction leads\nto bistability: a small change in conditions can cause the medium to transition\nto a different steady state, an effect characterized by hysteresis. The\ncombination of properties of this effect opens up a wide range of applications\nas optical keys or memory elements with a storage time of hundreds of seconds\nin tasks of quantum information and cryptography.", "AI": {"tldr": "\u5728SERF\u6761\u4ef6\u4e0b\uff0c\u78b1\u91d1\u5c5e\u539f\u5b50\u6c14\u4f53\u7684\u78c1\u6027\u8868\u73b0\u51fa\u53cc\u7a33\u6001\u884c\u4e3a\uff0c\u53ef\u7528\u4e8e\u91cf\u5b50\u4fe1\u606f\u548c\u5bc6\u7801\u5b66\u3002", "motivation": "\u63a2\u7d22\u5149\u5b66\u6cf5\u6d66\u548cSERF\u6761\u4ef6\u4e0b\u78b1\u91d1\u5c5e\u539f\u5b50\u6c14\u4f53\u4e2d\u7684\u96c6\u4f53\u6548\u5e94\uff0c\u7279\u522b\u662f\u81ea\u65cb\u4ea4\u6362\u5f1b\u8c6b\u7684\u6d88\u9664\u4ee5\u53ca\u53d6\u5411\u548c\u5bf9\u9f50\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u3002", "method": "\u5728SERF\u6761\u4ef6\u4e0b\uff0c\u901a\u8fc7\u5149\u5b66\u6cf5\u6d66\u5904\u7406\u78b1\u91d1\u5c5e\u539f\u5b50\u6c14\u4f53\uff0c\u5e76\u5b9e\u9a8c\u6027\u5730\u7814\u7a76\u53d6\u5411\uff08\u5076\u6781\u77e9\uff09\u548c\u5bf9\u9f50\uff08\u56db\u6781\u77e9\uff09\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5728SERF\u6761\u4ef6\u4e0b\uff0c\u53d6\u5411\u548c\u5bf9\u9f50\u53ef\u4ee5\u5171\u5b58\u5e76\u76f8\u4e92\u4f5c\u7528\uff0c\u5bfc\u81f4\u53cc\u7a33\u6001\u884c\u4e3a\u548c\u78c1\u6ede\u73b0\u8c61\u3002", "conclusion": "\u78b1\u91d1\u5c5e\u539f\u5b50\u6c14\u4f53\u5728SERF\u6761\u4ef6\u4e0b\u8868\u73b0\u51fa\u7684\u53cc\u7a33\u6001\u884c\u4e3a\u548c\u957f\u5b58\u50a8\u65f6\u95f4\uff08\u53ef\u8fbe\u6570\u767e\u79d2\uff09\u4e3a\u91cf\u5b50\u4fe1\u606f\u548c\u5bc6\u7801\u5b66\u4e2d\u7684\u5149\u5b66\u5bc6\u94a5\u6216\u5b58\u50a8\u5143\u4ef6\u63d0\u4f9b\u4e86\u65b0\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2509.09715", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09715", "abs": "https://arxiv.org/abs/2509.09715", "authors": ["Naveen Lamba", "Sanju Tiwari", "Manas Gaur"], "title": "Investigating Symbolic Triggers of Hallucination in Gemma Models Across HaluEval and TruthfulQA", "comment": null, "summary": "Hallucination in Large Language Models (LLMs) is a well studied problem.\nHowever, the properties that make LLM intrinsically vulnerable to\nhallucinations have not been identified and studied. This research identifies\nand characterizes the key properties, allowing us to pinpoint vulnerabilities\nwithin the model's internal mechanisms. To solidify on these properties, we\nutilized two established datasets, HaluEval and TruthfulQA and convert their\nexisting format of question answering into various other formats to narrow down\nthese properties as the reason for the hallucinations. Our findings reveal that\nhallucination percentages across symbolic properties are notably high for\nGemma-2-2B, averaging 79.0% across tasks and datasets. With increased model\nscale, hallucination drops to 73.6% for Gemma-2-9B and 63.9% for Gemma-2-27B,\nreflecting a 15 percentage point reduction overall. Although the hallucination\nrate decreases as the model size increases, a substantial amount of\nhallucination caused by symbolic properties still persists. This is especially\nevident for modifiers (ranging from 84.76% to 94.98%) and named entities\n(ranging from 83.87% to 93.96%) across all Gemma models and both datasets.\nThese findings indicate that symbolic elements continue to confuse the models,\npointing to a fundamental weakness in how these LLMs process such\ninputs--regardless of their scale.", "AI": {"tldr": "LLMs\u5bb9\u6613\u51fa\u73b0\u5e7b\u89c9\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u7b26\u53f7\u5c5e\u6027\u65f6\uff0c\u6a21\u578b\u89c4\u6a21\u8d8a\u5927\uff0c\u5e7b\u89c9\u6bd4\u4f8b\u8d8a\u4f4e\uff0c\u4f46\u5e76\u672a\u5b8c\u5168\u6d88\u9664\u3002", "motivation": "\u8bc6\u522b\u5e76\u7814\u7a76\u5bfc\u81f4\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ea7\u751f\u5e7b\u89c9\u7684\u5185\u5728\u5c5e\u6027\uff0c\u4ee5\u627e\u51fa\u6a21\u578b\u5185\u90e8\u7684\u8106\u5f31\u70b9\u3002", "method": "\u5229\u7528HaluEval\u548cTruthfulQA\u4e24\u4e2a\u6570\u636e\u96c6\uff0c\u5c06\u5176\u95ee\u7b54\u683c\u5f0f\u8f6c\u6362\u4e3a\u5176\u4ed6\u683c\u5f0f\uff0c\u4ee5\u7f29\u5c0f\u5bfc\u81f4\u5e7b\u89c9\u7684\u5c5e\u6027\u8303\u56f4\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u7b26\u53f7\u5c5e\u6027\u65b9\u9762\uff0cGemma-2-2B\u6a21\u578b\u7684\u5e7b\u89c9\u6bd4\u4f8b\u9ad8\u8fbe79.0%\uff0cGemma-2-9B\u4e3a73.6%\uff0cGemma-2-27B\u4e3a63.9%\u3002\u5e7b\u89c9\u6bd4\u4f8b\u968f\u6a21\u578b\u89c4\u6a21\u589e\u5927\u800c\u964d\u4f4e\uff0c\u4f46\u5bf9\u4e8e\u4fee\u9970\u8bcd\u548c\u547d\u540d\u5b9e\u4f53\uff0c\u6240\u6709Gemma\u6a21\u578b\u548c\u6570\u636e\u96c6\u7684\u5e7b\u89c9\u6bd4\u4f8b\u4ecd\u7136\u5f88\u9ad8\uff08\u5206\u522b\u4e3a84.76%\u81f394.98%\u548c83.87%\u81f393.96%\uff09\u3002", "conclusion": "\u5c3d\u7ba1\u6a21\u578b\u89c4\u6a21\u589e\u5927\u6709\u52a9\u4e8e\u964d\u4f4e\u5e7b\u89c9\u6bd4\u4f8b\uff0c\u4f46\u7b26\u53f7\u5143\u7d20\u4ecd\u7136\u4f1a\u6df7\u6dc6\u6a21\u578b\uff0c\u8868\u660eLLM\u5728\u5904\u7406\u6b64\u7c7b\u8f93\u5165\u65f6\u5b58\u5728\u6839\u672c\u6027\u7684\u5f31\u70b9\uff0c\u65e0\u8bba\u5176\u89c4\u6a21\u5982\u4f55\u3002"}}
{"id": "2509.10162", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10162", "abs": "https://arxiv.org/abs/2509.10162", "authors": ["Tamir Shazman", "Idan Lev-Yehudi", "Ron Benchetit", "Vadim Indelman"], "title": "Online Robust Planning under Model Uncertainty: A Sample-Based Approach", "comment": null, "summary": "Online planning in Markov Decision Processes (MDPs) enables agents to make\nsequential decisions by simulating future trajectories from the current state,\nmaking it well-suited for large-scale or dynamic environments. Sample-based\nmethods such as Sparse Sampling and Monte Carlo Tree Search (MCTS) are widely\nadopted for their ability to approximate optimal actions using a generative\nmodel. However, in practical settings, the generative model is often learned\nfrom limited data, introducing approximation errors that can degrade\nperformance or lead to unsafe behaviors. To address these challenges, Robust\nMDPs (RMDPs) offer a principled framework for planning under model uncertainty,\nyet existing approaches are typically computationally intensive and not suited\nfor real-time use. In this work, we introduce Robust Sparse Sampling (RSS), the\nfirst online planning algorithm for RMDPs with finite-sample theoretical\nperformance guarantees. Unlike Sparse Sampling, which estimates the nominal\nvalue function, RSS computes a robust value function by leveraging the\nefficiency and theoretical properties of Sample Average Approximation (SAA),\nenabling tractable robust policy computation in online settings. RSS is\napplicable to infinite or continuous state spaces, and its sample and\ncomputational complexities are independent of the state space size. We provide\ntheoretical performance guarantees and empirically show that RSS outperforms\nstandard Sparse Sampling in environments with uncertain dynamics.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u9c81\u68d2\u7a00\u758f\u91c7\u6837\uff08RSS\uff09\u7684\u5728\u7ebf\u89c4\u5212\u7b97\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08MDP\uff09\u4e2d\u7684\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\uff0c\u5e76\u5728\u6709\u9650\u6837\u672c\u4e0b\u63d0\u4f9b\u4e86\u7406\u8bba\u6027\u80fd\u4fdd\u8bc1\u3002", "motivation": "\u73b0\u6709\u7684\u5728\u7ebf\u89c4\u5212\u65b9\u6cd5\u5728\u5904\u7406\u4ece\u6709\u9650\u6570\u636e\u4e2d\u5b66\u4e60\u5230\u7684\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u65f6\uff0c\u53ef\u80fd\u4f1a\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u6216\u4e0d\u5b89\u5168\u7684\u884c\u4e3a\u3002\u867d\u7136\u9c81\u68d2MDP\uff08RMDP\uff09\u63d0\u4f9b\u4e86\u4e00\u4e2a\u89e3\u51b3\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u7684\u6846\u67b6\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\uff0c\u4e0d\u9002\u5408\u5b9e\u65f6\u5e94\u7528\u3002", "method": "\u8be5\u8bba\u6587\u63d0\u51fa\u7684RSS\u7b97\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u6837\u672c\u5e73\u5747\u8fd1\u4f3c\uff08SAA\uff09\u7684\u6548\u7387\u548c\u7406\u8bba\u7279\u6027\uff0c\u8ba1\u7b97\u9c81\u68d2\u503c\u51fd\u6570\uff0c\u4ece\u800c\u5728\u5728\u7ebf\u73af\u5883\u4e2d\u5b9e\u73b0\u53ef\u884c\u7684\u9c81\u68d2\u7b56\u7565\u8ba1\u7b97\u3002RSS\u9002\u7528\u4e8e\u65e0\u9650\u6216\u8fde\u7eed\u72b6\u6001\u7a7a\u95f4\uff0c\u5e76\u4e14\u5176\u6837\u672c\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\u4e0e\u72b6\u6001\u7a7a\u95f4\u5927\u5c0f\u65e0\u5173\u3002", "result": "RSS\u5728\u5177\u6709\u4e0d\u786e\u5b9a\u52a8\u6001\u7684\u73af\u5883\u4e2d\uff0c\u5176\u6027\u80fd\u4f18\u4e8e\u6807\u51c6\u7684\u7a00\u758f\u91c7\u6837\u65b9\u6cd5\u3002", "conclusion": "RSS\u662f\u7b2c\u4e00\u4e2a\u7528\u4e8eRMDPs\u7684\u5728\u7ebf\u89c4\u5212\u7b97\u6cd5\uff0c\u5728\u6709\u9650\u6837\u672c\u4e0b\u5177\u6709\u7406\u8bba\u6027\u80fd\u4fdd\u8bc1\uff0c\u5e76\u4e14\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u80fd\u591f\u6709\u6548\u5904\u7406\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\u3002"}}
{"id": "2509.09849", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.09849", "abs": "https://arxiv.org/abs/2509.09849", "authors": ["Chengyu Yang", "Chengjun Liu"], "title": "Investigating the Impact of Various Loss Functions and Learnable Wiener Filter for Laparoscopic Image Desmoking", "comment": null, "summary": "To rigorously assess the effectiveness and necessity of individual components\nwithin the recently proposed ULW framework for laparoscopic image desmoking,\nthis paper presents a comprehensive ablation study. The ULW approach combines a\nU-Net based backbone with a compound loss function that comprises mean squared\nerror (MSE), structural similarity index (SSIM) loss, and perceptual loss. The\nframework also incorporates a differentiable, learnable Wiener filter module.\nIn this study, each component is systematically ablated to evaluate its\nspecific contribution to the overall performance of the whole framework. The\nanalysis includes: (1) removal of the learnable Wiener filter, (2) selective\nuse of individual loss terms from the composite loss function. All variants are\nbenchmarked on a publicly available paired laparoscopic images dataset using\nquantitative metrics (SSIM, PSNR, MSE and CIEDE-2000) alongside qualitative\nvisual comparisons.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u6d88\u878d\u5b9e\u9a8c\u8bc4\u4f30\u4e86U-Net\u9aa8\u5e72\u3001\u590d\u5408\u635f\u5931\u51fd\u6570\uff08MSE\u3001SSIM\u3001\u611f\u77e5\u635f\u5931\uff09\u4ee5\u53ca\u53ef\u5b66\u4e60\u7ef4\u7eb3\u6ee4\u6ce2\u5668\u5728\u8179\u8154\u955c\u56fe\u50cf\u53bb\u70df\u65b9\u9762\u5404\u81ea\u7684\u8d21\u732e\u3002", "motivation": "\u4e3a\u4e86\u4e25\u683c\u8bc4\u4f30U-Net\u9aa8\u5e72\u3001\u590d\u5408\u635f\u5931\u51fd\u6570\uff08MSE\u3001SSIM\u3001\u611f\u77e5\u635f\u5931\uff09\u4ee5\u53ca\u53ef\u5b66\u4e60\u7ef4\u7eb3\u6ee4\u6ce2\u5668\u5728\u8179\u8154\u955c\u56fe\u50cf\u53bb\u70df\u65b9\u9762\u5404\u81ea\u7684\u6709\u6548\u6027\u548c\u5fc5\u8981\u6027\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u5730\u79fb\u9664\u6216\u9009\u62e9\u6027\u5730\u4f7f\u7528\u6846\u67b6\u7684\u5404\u4e2a\u7ec4\u4ef6\uff08\u4f8b\u5982\uff0c\u79fb\u9664\u53ef\u5b66\u4e60\u7ef4\u7eb3\u6ee4\u6ce2\u5668\uff0c\u5355\u72ec\u4f7f\u7528\u590d\u5408\u635f\u5931\u51fd\u6570\u4e2d\u7684\u5404\u9879\u635f\u5931\uff09\uff0c\u5e76\u4f7f\u7528\u5b9a\u91cf\u6307\u6807\uff08SSIM\u3001PSNR\u3001MSE\u3001CIEDE-2000\uff09\u548c\u5b9a\u6027\u89c6\u89c9\u6bd4\u8f83\uff0c\u5728\u516c\u5f00\u7684\u914d\u5bf9\u8179\u8154\u955c\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u5bf9\u6240\u6709\u53d8\u4f53\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\uff08\u672a\u5728\u6b64\u6458\u8981\u4e2d\u8be6\u7ec6\u8bf4\u660e\uff09\u5c06\u5c55\u793a\u5404\u4e2a\u7ec4\u4ef6\u5bf9\u6574\u4f53\u6027\u80fd\u7684\u8d21\u732e\u3002", "conclusion": "\u6d88\u878d\u7814\u7a76\u7684\u7ed3\u679c\u5c06\u9610\u660eULW\u6846\u67b6\u4e2d\u6bcf\u4e2a\u7ec4\u4ef6\u7684\u5fc5\u8981\u6027\u548c\u91cd\u8981\u6027\uff0c\u4e3a\u672a\u6765\u7684\u6a21\u578b\u6539\u8fdb\u63d0\u4f9b\u6307\u5bfc\u3002"}}
{"id": "2509.10305", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.10305", "abs": "https://arxiv.org/abs/2509.10305", "authors": ["Yutong Shen", "Ruizhe Xia", "Bokai Yan", "Shunqi zhang", "Pengrui Xiang", "Sicheng He", "Yixin Xu"], "title": "GundamQ: Multi-Scale Spatio-Temporal Representation Learning for Robust Robot Path Planning", "comment": "6 pages, 5 figures", "summary": "In dynamic and uncertain environments, robotic path planning demands accurate\nspatiotemporal environment understanding combined with robust decision-making\nunder partial observability. However, current deep reinforcement learning-based\npath planning methods face two fundamental limitations: (1) insufficient\nmodeling of multi-scale temporal dependencies, resulting in suboptimal\nadaptability in dynamic scenarios, and (2) inefficient exploration-exploitation\nbalance, leading to degraded path quality. To address these challenges, we\npropose GundamQ: A Multi-Scale Spatiotemporal Q-Network for Robotic Path\nPlanning. The framework comprises two key modules: (i) the Spatiotemporal\nPerception module, which hierarchically extracts multi-granularity spatial\nfeatures and multi-scale temporal dependencies ranging from instantaneous to\nextended time horizons, thereby improving perception accuracy in dynamic\nenvironments; and (ii) the Adaptive Policy Optimization module, which balances\nexploration and exploitation during training while optimizing for smoothness\nand collision probability through constrained policy updates. Experiments in\ndynamic environments demonstrate that GundamQ achieves a 15.3\\% improvement in\nsuccess rate and a 21.7\\% increase in overall path quality, significantly\noutperforming existing state-of-the-art methods.", "AI": {"tldr": "GundamQ\u901a\u8fc7\u591a\u5c3a\u5ea6\u65f6\u7a7aQ\u7f51\u7edc\u63d0\u5347\u4e86\u673a\u5668\u4eba\u5728\u52a8\u6001\u73af\u5883\u4e0b\u7684\u8def\u5f84\u89c4\u5212\u80fd\u529b\uff0c\u63d0\u9ad8\u4e86\u6210\u529f\u7387\u548c\u8def\u5f84\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u673a\u5668\u4eba\u8def\u5f84\u89c4\u5212\u65b9\u6cd5\u5728\u52a8\u6001\u548c\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u9762\u4e34\u591a\u5c3a\u5ea6\u65f6\u95f4\u4f9d\u8d56\u5efa\u6a21\u4e0d\u8db3\u548c\u63a2\u7d22-\u5229\u7528\u5e73\u8861\u6548\u7387\u4f4e\u4e0b\u4e24\u5927\u6311\u6218\u3002", "method": "\u63d0\u51faGundamQ\u6846\u67b6\uff0c\u5305\u542b\uff08i\uff09\u65f6\u7a7a\u611f\u77e5\u6a21\u5757\uff0c\u7528\u4e8e\u63d0\u53d6\u591a\u7c92\u5ea6\u7a7a\u95f4\u7279\u5f81\u548c\u591a\u5c3a\u5ea6\u65f6\u95f4\u4f9d\u8d56\u6027\uff1b\uff08ii\uff09\u81ea\u9002\u5e94\u7b56\u7565\u4f18\u5316\u6a21\u5757\uff0c\u7528\u4e8e\u5e73\u8861\u63a2\u7d22\u4e0e\u5229\u7528\uff0c\u5e76\u901a\u8fc7\u7ea6\u675f\u7b56\u7565\u66f4\u65b0\u4f18\u5316\u5e73\u6ed1\u5ea6\u548c\u78b0\u649e\u6982\u7387\u3002", "result": "\u5728\u52a8\u6001\u73af\u5883\u4e2d\u8fdb\u884c\u5b9e\u9a8c\uff0cGundamQ\u6210\u529f\u7387\u63d0\u9ad8\u4e8615.3%\uff0c\u6574\u4f53\u8def\u5f84\u8d28\u91cf\u63d0\u9ad8\u4e8621.7%\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "GundamQ\u901a\u8fc7\u5176\u591a\u5c3a\u5ea6\u65f6\u7a7a\u611f\u77e5\u548c\u81ea\u9002\u5e94\u7b56\u7565\u4f18\u5316\u80fd\u529b\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u673a\u5668\u4eba\u8def\u5f84\u89c4\u5212\u4e2d\u7684\u6311\u6218\uff0c\u5e76\u5728\u52a8\u6001\u73af\u5883\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2509.10131", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2509.10131", "abs": "https://arxiv.org/abs/2509.10131", "authors": ["Daniel Mart\u00ednez-Gil", "Pedro Bargue\u00f1o", "Salvador Miret-Art\u00e9s"], "title": "Exact Classicalization of N-Level Quantum Systems Interacting with a Bath: Theory and Applications", "comment": null, "summary": "In this manuscript, starting from a five-step algorithmic procedure for\nexactly classicalizing the dynamics of N-level quantum systems, we incorporate\na classical bath of harmonic oscillators to model environmental interactions.\nUsing the geometry of complex projective spaces CP(N-1) and a Langevin\nformalism, we obtain N-1 Hamilton's equations which encode both the quantum\nsystem and the bath degrees of freedom, representing a generalization of the\nCaldeira-Legget model in a complex projective space. We demonstrate the\nefficacy of the method by applying it to two paradigmatic systems: a two-qubit\nsystem in CP(3) under entangling interactions, reproducing quantum observables\nsuch as state populations, quaternionic population differences and concurrence,\nand the seven-state Fenna-Matthews-Olson (FMO) complex in CP(6), reproducing\nstate populations in the picosecond timescale.", "AI": {"tldr": "\u901a\u8fc7\u5f15\u5165\u7ecf\u5178\u8c10\u632f\u5668\u6d74\u6765\u6a21\u62df\u91cf\u5b50\u7cfb\u7edf\u7684\u73af\u5883\u76f8\u4e92\u4f5c\u7528\uff0c\u5e76\u4f7f\u7528\u590d\u6570\u5c04\u5f71\u7a7a\u95f4\u548cLangevin\u65b9\u6cd5\u63a8\u5bfc\u51fa\u5305\u542b\u7cfb\u7edf\u548c\u6d74\u81ea\u7531\u5ea6\u7684\u54c8\u5bc6\u987f\u65b9\u7a0b\uff0c\u6210\u529f\u5e94\u7528\u4e8e\u53cc\u91cf\u5b50\u6bd4\u7279\u548cFMO\u590d\u5408\u7269\u7cfb\u7edf\uff0c\u91cd\u73b0\u4e86\u91cf\u5b50\u53ef\u89c2\u6d4b\u503c\u3002", "motivation": "\u5bf9N\u7ea7\u91cf\u5b50\u7cfb\u7edf\u7684\u52a8\u529b\u5b66\u8fdb\u884c\u7cbe\u786e\u7ecf\u5178\u5316\uff0c\u5e76\u6a21\u62df\u73af\u5883\u76f8\u4e92\u4f5c\u7528\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u4e94\u6b65\u7b97\u6cd5\u7a0b\u5e8f\uff0c\u5e76\u5f15\u5165\u7ecf\u5178\u8c10\u632f\u5668\u6d74\uff0c\u5229\u7528\u590d\u6570\u5c04\u5f71\u7a7a\u95f4CP(N-1)\u7684\u51e0\u4f55\u548cLangevin\u65b9\u6cd5\u63a8\u5bfc\u51faN-1\u4e2a\u54c8\u5bc6\u987f\u65b9\u7a0b\u3002", "result": "\u5c06\u8be5\u65b9\u6cd5\u5e94\u7528\u4e8e\u53cc\u91cf\u5b50\u6bd4\u7279\u7cfb\u7edf\u548c\u4e03\u80fd\u7ea7FMO\u590d\u5408\u7269\u7cfb\u7edf\uff0c\u6210\u529f\u91cd\u73b0\u4e86\u72b6\u6001\u5e03\u5c45\u6570\u3001\u56db\u5143\u6570\u5e03\u5c45\u6570\u5dee\u548c\u7ea0\u7f20\u5ea6\u7b49\u91cf\u5b50\u53ef\u89c2\u6d4b\u503c\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u7ed3\u5408\u4e86\u590d\u6570\u5c04\u5f71\u7a7a\u95f4\u51e0\u4f55\u548cLangevin\u65b9\u6cd5\u7684\u6a21\u578b\u80fd\u591f\u6709\u6548\u5730\u6a21\u62df\u91cf\u5b50\u7cfb\u7edf\u7684\u73af\u5883\u76f8\u4e92\u4f5c\u7528\uff0c\u5e76\u91cd\u73b0\u91cd\u8981\u7684\u91cf\u5b50\u52a8\u529b\u5b66\u7279\u5f81\u3002"}}
{"id": "2509.09723", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ME", "I.2.6; J.4; I.5.1; H.3.3; H.2.8"], "pdf": "https://arxiv.org/pdf/2509.09723", "abs": "https://arxiv.org/abs/2509.09723", "authors": ["Kai R. Larsen", "Sen Yan", "Roland M\u00fcller", "Lan Sang", "Mikko R\u00f6nkk\u00f6", "Ravi Starzl", "Donald Edmondson"], "title": "ALIGNS: Unlocking nomological networks in psychological measurement through a large language model", "comment": null, "summary": "Psychological measurement is critical to many disciplines. Despite advances\nin measurement, building nomological networks, theoretical maps of how concepts\nand measures relate to establish validity, remains a challenge 70 years after\nCronbach and Meehl proposed them as fundamental to validation. This limitation\nhas practical consequences: clinical trials may fail to detect treatment\neffects, and public policy may target the wrong outcomes. We introduce Analysis\nof Latent Indicators to Generate Nomological Structures (ALIGNS), a large\nlanguage model-based system trained with validated questionnaire measures.\nALIGNS provides three comprehensive nomological networks containing over\n550,000 indicators across psychology, medicine, social policy, and other\nfields. This represents the first application of large language models to solve\na foundational problem in measurement validation. We report classification\naccuracy tests used to develop the model, as well as three evaluations. In the\nfirst evaluation, the widely used NIH PROMIS anxiety and depression instruments\nare shown to converge into a single dimension of emotional distress. The second\nevaluation examines child temperament measures and identifies four potential\ndimensions not captured by current frameworks, and questions one existing\ndimension. The third evaluation, an applicability check, engages expert\npsychometricians who assess the system's importance, accessibility, and\nsuitability. ALIGNS is freely available at nomologicalnetwork.org,\ncomplementing traditional validation methods with large-scale nomological\nanalysis.", "AI": {"tldr": "ALIGNS\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7cfb\u7edf\uff0c\u7528\u4e8e\u6784\u5efa\u5fc3\u7406\u6d4b\u91cf\u5b66\u4e2d\u7684\u201c\u5177\u4f53\u5316\u7f51\u7edc\u201d\uff0c\u89e3\u51b3\u4e86\u957f\u671f\u5b58\u5728\u7684\u6d4b\u91cf\u9a8c\u8bc1\u6311\u6218\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e09\u4e2a\u5305\u542b\u8d85\u8fc755\u4e07\u4e2a\u6307\u6807\u7684\u5168\u9762\u5177\u4f53\u5316\u7f51\u7edc\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u4e34\u5e8a\u8bd5\u9a8c\u548c\u516c\u5171\u653f\u7b56\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5fc3\u7406\u6d4b\u91cf\u5728\u5404\u5b66\u79d1\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u6784\u5efa\u201c\u5177\u4f53\u5316\u7f51\u7edc\u201d\uff08\u5373\u6982\u5ff5\u548c\u6d4b\u91cf\u4e4b\u95f4\u5173\u7cfb\u7684\u7406\u8bba\u56fe\u8c31\uff0c\u7528\u4e8e\u5efa\u7acb\u6548\u5ea6\uff09\u4ecd\u7136\u662f\u4e00\u4e2a\u6311\u6218\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u4e34\u5e8a\u8bd5\u9a8c\u672a\u80fd\u68c0\u6d4b\u5230\u6cbb\u7597\u6548\u679c\u6216\u516c\u5171\u653f\u7b56\u9488\u5bf9\u9519\u8bef\u7684\u7ed3\u5c40\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u5177\u4f53\u5316\u6307\u6807\u5206\u6790\u201d\uff08ALIGNS\uff09\u7684\u5927\u8bed\u8a00\u6a21\u578b\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u4f7f\u7528\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u8c03\u67e5\u95ee\u5377\u8fdb\u884c\u8bad\u7ec3\uff0c\u4ee5\u751f\u6210\u5177\u4f53\u5316\u7f51\u7edc\u3002", "result": "ALIGNS\u751f\u6210\u4e86\u4e09\u4e2a\u5305\u542b\u8d85\u8fc755\u4e07\u4e2a\u8de8\u5fc3\u7406\u5b66\u3001\u533b\u5b66\u3001\u793e\u4f1a\u653f\u7b56\u7b49\u9886\u57df\u7684\u6307\u6807\u7684\u5177\u4f53\u5316\u7f51\u7edc\u3002\u5728\u9a8c\u8bc1\u6d4b\u8bd5\u4e2d\uff0cALIGNS\u5c06NIH PROMIS\u7126\u8651\u548c\u6291\u90c1\u91cf\u8868\u5f52\u4e3a\u4e00\u4e2a\u60c5\u7eea\u56f0\u6270\u7ef4\u5ea6\uff1b\u8bc6\u522b\u51fa\u4e0e\u513f\u7ae5\u6c14\u8d28\u6d4b\u91cf\u76f8\u5173\u7684\u56db\u4e2a\u6f5c\u5728\u7ef4\u5ea6\u5e76\u8d28\u7591\u4e86\u4e00\u4e2a\u73b0\u6709\u7ef4\u5ea6\uff1b\u4e13\u5bb6\u8bc4\u4f30\u8ba4\u4e3aALIGNS\u5177\u6709\u91cd\u8981\u6027\u3001\u53ef\u53ca\u6027\u548c\u9002\u7528\u6027\u3002", "conclusion": "ALIGNS\u662f\u7b2c\u4e00\u4e2a\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u4e8e\u89e3\u51b3\u6d4b\u91cf\u9a8c\u8bc1\u57fa\u7840\u95ee\u9898\u7684\u7cfb\u7edf\uff0c\u5b83\u901a\u8fc7\u5927\u89c4\u6a21\u5177\u4f53\u5316\u7f51\u7edc\u5206\u6790\u6765\u8865\u5145\u4f20\u7edf\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u5e76\u5df2\u514d\u8d39\u63d0\u4f9b\uff08nomologicalnetwork.org\uff09\u3002"}}
{"id": "2509.09940", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.09940", "abs": "https://arxiv.org/abs/2509.09940", "authors": ["Yifei Wang", "Wenbin Wang", "Yong Luo"], "title": "DyKen-Hyena: Dynamic Kernel Generation via Cross-Modal Attention for Multimodal Intent Recognition", "comment": "8 pages, 2 figures", "summary": "Though Multimodal Intent Recognition (MIR) proves effective by utilizing rich\ninformation from multiple sources (e.g., language, video, and audio), the\npotential for intent-irrelevant and conflicting information across modalities\nmay hinder performance from being further improved. Most current models attempt\nto fuse modalities by applying mechanisms like multi-head attention to unimodal\nfeature sequences and then adding the result back to the original\nrepresentation. This process risks corrupting the primary linguistic features\nwith noisy or irrelevant non-verbal signals, as it often fails to capture the\nfine-grained, token-level influence where non-verbal cues should modulate, not\njust augment, textual meaning. To address this, we introduce DyKen-Hyena, which\nreframes the problem from feature fusion to processing modulation. Our model\ntranslates audio-visual cues into dynamic, per-token convolutional kernels that\ndirectly modulate textual feature extraction. This fine-grained approach\nachieves state-of-the-art results on the MIntRec and MIntRec2.0 benchmarks.\nNotably, it yields a +10.46% F1-score improvement in out-of-scope detection,\nvalidating that our method creates a fundamentally more robust intent\nrepresentation.", "AI": {"tldr": "DyKen-Hyena\u901a\u8fc7\u52a8\u6001\u5377\u79ef\u6838\u8c03\u5236\u6587\u672c\u7279\u5f81\u63d0\u53d6\uff0c\u4ee5\u89e3\u51b3\u591a\u6a21\u6001\u610f\u56fe\u8bc6\u522b\u4e2d\u8de8\u6a21\u6001\u4fe1\u606f\u5e72\u6270\u95ee\u9898\uff0c\u5e76\u5728MIntRec\u548cMIntRec2.0\u57fa\u51c6\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6210\u679c\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u610f\u56fe\u8bc6\u522b\u6a21\u578b\u5728\u878d\u5408\u591a\u6a21\u6001\u4fe1\u606f\u65f6\uff0c\u53ef\u80fd\u5f15\u5165\u4e0d\u76f8\u5173\u6216\u51b2\u7a81\u7684\u4fe1\u606f\uff0c\u4ece\u800c\u5f71\u54cd\u6027\u80fd\u3002\u73b0\u6709\u7684\u878d\u5408\u673a\u5236\uff08\u5982\u591a\u5934\u6ce8\u610f\u529b\uff09\u5f80\u5f80\u662f\u5728\u7279\u5f81\u5e8f\u5217\u5c42\u9762\u8fdb\u884c\u878d\u5408\uff0c\u7136\u540e\u52a0\u56de\u5230\u539f\u59cb\u8868\u793a\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u8bed\u8a00\u7279\u5f81\u88ab\u975e\u8bed\u8a00\u4fe1\u53f7\u5e72\u6270\uff0c\u5e76\u4e14\u672a\u80fd\u6355\u6349\u5230\u975e\u8bed\u8a00\u7ebf\u7d22\u5e94\u5982\u4f55\u7cbe\u7ec6\u5730\u8c03\u8282\u6587\u672c\u542b\u4e49\u3002", "method": "DyKen-Hyena\u6a21\u578b\u5c06\u97f3\u9891\u89c6\u89c9\u7ebf\u7d22\u8f6c\u5316\u4e3a\u52a8\u6001\u7684\u3001\u6309token\uff08\u8bcd\u5143\uff09\u7684\u5377\u79ef\u6838\uff0c\u76f4\u63a5\u8c03\u5236\u6587\u672c\u7279\u5f81\u7684\u63d0\u53d6\u8fc7\u7a0b\u3002\u8fd9\u79cd\u7cbe\u7ec6\u7684\u8c03\u63a7\u65b9\u5f0f\uff0c\u5b9e\u73b0\u4e86\u4ece\u7279\u5f81\u878d\u5408\u5230\u5904\u7406\u8c03\u5236\u7684\u8303\u5f0f\u8f6c\u53d8\u3002", "result": "DyKen-Hyena\u6a21\u578b\u5728MIntRec\u548cMIntRec2.0\u57fa\u51c6\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6210\u679c\uff0c\u7279\u522b\u662f\u5728\u201c\u8303\u56f4\u5916\u68c0\u6d4b\u201d\u4efb\u52a1\u4e0a\uff0cF1\u5206\u6570\u63d0\u9ad8\u4e86+10.46%\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u80fd\u591f\u751f\u6210\u66f4\u9c81\u68d2\u7684\u610f\u56fe\u8868\u793a\u3002", "conclusion": "DyKen-Hyena\u6a21\u578b\u901a\u8fc7\u52a8\u6001\u5377\u79ef\u6838\u5b9e\u73b0\u4e86\u5bf9\u6587\u672c\u7279\u5f81\u63d0\u53d6\u7684\u7cbe\u7ec6\u8c03\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u610f\u56fe\u8bc6\u522b\u4e2d\u7684\u4fe1\u606f\u5e72\u6270\u95ee\u9898\uff0c\u5e76\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728\u5404\u9879\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728\u9c81\u68d2\u6027\u65b9\u9762\u3002"}}
{"id": "2509.09859", "categories": ["cs.CV", "cs.LG", "68W99"], "pdf": "https://arxiv.org/pdf/2509.09859", "abs": "https://arxiv.org/abs/2509.09859", "authors": ["Razvan Stefanescu", "Ethan Oh", "Ruben Vazquez", "Chris Mesterharm", "Constantin Serban", "Ritu Chadha"], "title": "WAVE-DETR Multi-Modal Visible and Acoustic Real-Life Drone Detector", "comment": "11 pages, 11 figures", "summary": "We introduce a multi-modal WAVE-DETR drone detector combining visible RGB and\nacoustic signals for robust real-life UAV object detection. Our approach fuses\nvisual and acoustic features in a unified object detector model relying on the\nDeformable DETR and Wav2Vec2 architectures, achieving strong performance under\nchallenging environmental conditions. Our work leverage the existing\nDrone-vs-Bird dataset and the newly generated ARDrone dataset containing more\nthan 7,500 synchronized images and audio segments. We show how the acoustic\ninformation is used to improve the performance of the Deformable DETR object\ndetector on the real ARDrone dataset. We developed, trained and tested four\ndifferent fusion configurations based on a gated mechanism, linear layer, MLP\nand cross attention. The Wav2Vec2 acoustic embeddings are fused with the multi\nresolution feature mappings of the Deformable DETR and enhance the object\ndetection performance over all drones dimensions. The best performer is the\ngated fusion approach, which improves the mAP of the Deformable DETR object\ndetector on our in-distribution and out-of-distribution ARDrone datasets by\n11.1% to 15.3% for small drones across all IoU thresholds between 0.5 and 0.9.\nThe mAP scores for medium and large drones are also enhanced, with overall\ngains across all drone sizes ranging from 3.27% to 5.84%.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u53ef\u89c1\u5149RGB\u548c\u58f0\u5b66\u4fe1\u53f7\u7684\u591a\u6a21\u6001WAVE-DETR\u65e0\u4eba\u673a\u68c0\u6d4b\u5668\uff0c\u7528\u4e8e\u9c81\u68d2\u7684\u73b0\u5b9e\u4e16\u754cUAV\u76ee\u6807\u68c0\u6d4b\u3002", "motivation": "\u4e3a\u4e86\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u73af\u5883\u6761\u4ef6\u4e0b\u63d0\u9ad8\u65e0\u4eba\u673a\u76ee\u6807\u68c0\u6d4b\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u9488\u5bf9\u4e0d\u540c\u5c3a\u5bf8\u7684\u65e0\u4eba\u673a\u3002", "method": "\u878d\u5408\u4e86\u57fa\u4e8eDeformable DETR\u548cWav2Vec2\u67b6\u6784\u7684\u89c6\u89c9\u548c\u58f0\u5b66\u7279\u5f81\uff0c\u5e76\u5f00\u53d1\u4e86\u56db\u79cd\u57fa\u4e8e\u95e8\u63a7\u673a\u5236\u3001\u7ebf\u6027\u5c42\u3001MLP\u548c\u4ea4\u53c9\u6ce8\u610f\u529b\u7684\u878d\u5408\u914d\u7f6e\u3002", "result": "\u6240\u63d0\u51fa\u7684WAVE-DETR\u65e0\u4eba\u673a\u68c0\u6d4b\u5668\uff0c\u7279\u522b\u662f\u91c7\u7528\u95e8\u63a7\u878d\u5408\u65b9\u6cd5\u7684\u914d\u7f6e\uff0c\u5728ARDrone\u6570\u636e\u96c6\u4e0a\uff0c\u5bf9\u4e8e\u5c0f\u5c3a\u5bf8\u65e0\u4eba\u673a\u7684mAP\u5728\u6240\u6709IoU\u9608\u503c\u4e0b\u63d0\u9ad8\u4e8611.1%\u81f315.3%\uff0c\u4e2d\u578b\u548c\u5927\u578b\u65e0\u4eba\u673a\u7684mAP\u4e5f\u5f97\u5230\u4e86\u63d0\u5347\uff0c\u6240\u6709\u65e0\u4eba\u673a\u5c3a\u5bf8\u7684\u6574\u4f53\u589e\u76ca\u8303\u56f4\u4e3a3.27%\u81f35.84%\u3002", "conclusion": "\u878d\u5408\u58f0\u5b66\u4fe1\u606f\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8Deformable DETR\u76ee\u6807\u68c0\u6d4b\u5668\u5728ARDrone\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\uff0c\u5176\u4e2d\u95e8\u63a7\u878d\u5408\u65b9\u6cd5\u6548\u679c\u6700\u4f73\u3002"}}
{"id": "2509.10317", "categories": ["cs.RO", "cs.LG", "93C85", "I.2.9; I.2.7; I.2.11"], "pdf": "https://arxiv.org/pdf/2509.10317", "abs": "https://arxiv.org/abs/2509.10317", "authors": ["Elizaveta D. Moskovskaya", "Anton D. Moscowsky"], "title": "Robot guide with multi-agent control and automatic scenario generation with LLM", "comment": "14 pages, 5 figures, 2 tables, 1 demo-video and repository link", "summary": "The work describes the development of a hybrid control architecture for an\nanthropomorphic tour guide robot, combining a multi-agent resource management\nsystem with automatic behavior scenario generation based on large language\nmodels. The proposed approach aims to overcome the limitations of traditional\nsystems, which rely on manual tuning of behavior scenarios. These limitations\ninclude manual configuration, low flexibility, and lack of naturalness in robot\nbehavior. The process of preparing tour scenarios is implemented through a\ntwo-stage generation: first, a stylized narrative is created, then non-verbal\naction tags are integrated into the text. The multi-agent system ensures\ncoordination and conflict resolution during the execution of parallel actions,\nas well as maintaining default behavior after the completion of main\noperations, contributing to more natural robot behavior. The results obtained\nfrom the trial demonstrate the potential of the proposed approach for\nautomating and scaling social robot control systems.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u63a7\u5236\u67b6\u6784\uff0c\u7528\u4e8e\u80fd\u591f\u4e0e\u7528\u6237\u81ea\u7136\u4e92\u52a8\u7684\u62df\u4eba\u5316\u5bfc\u6e38\u673a\u5668\u4eba\u3002", "motivation": "\u4f20\u7edf\u673a\u5668\u4eba\u63a7\u5236\u7cfb\u7edf\u5728\u884c\u4e3a\u573a\u666f\u914d\u7f6e\u65b9\u9762\u5b58\u5728\u624b\u52a8\u8c03\u6574\u3001\u7075\u6d3b\u6027\u4f4e\u548c\u884c\u4e3a\u4e0d\u81ea\u7136\u7b49\u5c40\u9650\u6027\uff0c\u8be5\u7814\u7a76\u65e8\u5728\u514b\u670d\u8fd9\u4e9b\u7f3a\u70b9\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4e86\u591a\u667a\u80fd\u4f53\u8d44\u6e90\u7ba1\u7406\u7cfb\u7edf\u548c\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u884c\u4e3a\u573a\u666f\u751f\u6210\u65b9\u6cd5\u7684\u6df7\u5408\u63a7\u5236\u67b6\u6784\u3002\u573a\u666f\u751f\u6210\u5305\u62ec\u4e24\u4e2a\u9636\u6bb5\uff1a\u9996\u5148\u521b\u5efa\u98ce\u683c\u5316\u53d9\u4e8b\uff0c\u7136\u540e\u5c06\u975e\u8bed\u8a00\u52a8\u4f5c\u6807\u7b7e\u96c6\u6210\u5230\u6587\u672c\u4e2d\u3002\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u8d1f\u8d23\u534f\u8c03\u548c\u89e3\u51b3\u5e76\u884c\u52a8\u4f5c\u6267\u884c\u4e2d\u7684\u51b2\u7a81\uff0c\u5e76\u4fdd\u6301\u4e3b\u8981\u64cd\u4f5c\u5b8c\u6210\u540e\u7684\u9ed8\u8ba4\u884c\u4e3a\u3002", "result": "\u901a\u8fc7\u8bd5\u9a8c\u83b7\u5f97\u7684\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u81ea\u52a8\u5316\u548c\u6269\u5c55\u793e\u4ea4\u673a\u5668\u4eba\u63a7\u5236\u7cfb\u7edf\u65b9\u9762\u5177\u6709\u6f5c\u529b\u3002", "conclusion": "\u8be5\u6df7\u5408\u63a7\u5236\u67b6\u6784\u901a\u8fc7\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u548c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u80fd\u591f\u751f\u6210\u66f4\u81ea\u7136\u3001\u66f4\u7075\u6d3b\u7684\u673a\u5668\u4eba\u884c\u4e3a\uff0c\u4e3a\u81ea\u52a8\u5316\u793e\u4ea4\u673a\u5668\u4eba\u63a7\u5236\u63d0\u4f9b\u4e86\u65b0\u7684\u9014\u5f84\u3002"}}
{"id": "2509.10141", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2509.10141", "abs": "https://arxiv.org/abs/2509.10141", "authors": ["Alexander Mandl", "Johanna Barzen", "Marvin Bechtold", "Frank Leymann", "Lavinia Stiliadou"], "title": "Loss Behavior in Supervised Learning with Entangled States", "comment": null, "summary": "Quantum Machine Learning (QML) aims to leverage the principles of quantum\nmechanics to speed up the process of solving machine learning problems or\nimprove the quality of solutions. Among these principles, entanglement with an\nauxiliary system was shown to increase the quality of QML models in\napplications such as supervised learning. Recent works focus on the information\nthat can be extracted from entangled training samples and their effect on the\napproximation error of the trained model. However, results on the trainability\nof QML models show that the training process itself is affected by various\nproperties of the supervised learning task. These properties include the\ncircuit structure of the QML model, the used cost function, and noise on the\nquantum computer. To evaluate the applicability of entanglement in supervised\nlearning, we augment these results by investigating the effect of highly\nentangled training data on the model's trainability. In this work, we show that\nfor highly expressive models, i.e., models capable of expressing a large number\nof candidate solutions, the possible improvement of loss function values in\nconstrained neighborhoods during optimization is severely limited when\nmaximally entangled states are employed for training. Furthermore, we support\nthis finding experimentally by simulating training with Parameterized Quantum\nCircuits (PQCs). Our findings show that as the expressivity of the PQC\nincreases, it becomes more susceptible to loss concentration induced by\nentangled training data. Lastly, our experiments evaluate the efficacy of\nnon-maximal entanglement in the training samples and highlight the fundamental\nrole of entanglement entropy as a predictor for the trainability.", "AI": {"tldr": "\u9ad8\u5ea6\u7ea0\u7f20\u7684\u8bad\u7ec3\u6570\u636e\u4f1a\u9650\u5236\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u8bad\u7ec3\u6539\u8fdb\uff0c\u5c24\u5176\u662f\u5728\u9ad8\u5ea6\u53ef\u8868\u8fbe\u7684\u6a21\u578b\u4e2d\u3002", "motivation": "\u7814\u7a76\u9ad8\u5ea6\u7ea0\u7f20\u7684\u8bad\u7ec3\u6570\u636e\u5bf9\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8bad\u7ec3\u80fd\u529b\u7684\u5f71\u54cd\uff0c\u4ee5\u8bc4\u4f30\u7ea0\u7f20\u5728\u76d1\u7763\u5b66\u4e60\u4e2d\u7684\u9002\u7528\u6027\u3002", "method": "\u5728\u9ad8\u5ea6\u53ef\u8868\u8fbe\u7684\u6a21\u578b\u4e2d\uff0c\u7814\u7a76\u4e86\u4f7f\u7528\u6700\u5927\u7ea0\u7f20\u6001\u8fdb\u884c\u8bad\u7ec3\u65f6\uff0c\u635f\u5931\u51fd\u6570\u503c\u5728\u7ea6\u675f\u90bb\u57df\u5185\u53ef\u5b9e\u73b0\u7684\u6539\u8fdb\u3002\u901a\u8fc7\u6a21\u62df\u53c2\u6570\u5316\u91cf\u5b50\u7535\u8def\uff08PQCs\uff09\u7684\u8bad\u7ec3\u6765\u652f\u6301\u5b9e\u9a8c\u53d1\u73b0\uff0c\u5e76\u8bc4\u4f30\u4e86\u975e\u6700\u5927\u7ea0\u7f20\u8bad\u7ec3\u6837\u672c\u7684\u6709\u6548\u6027\uff0c\u4ee5\u53ca\u7ea0\u7f20\u71b5\u4f5c\u4e3a\u8bad\u7ec3\u80fd\u529b\u9884\u6d4b\u56e0\u5b50\u7684\u4f5c\u7528\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5bf9\u4e8e\u9ad8\u5ea6\u53ef\u8868\u8fbe\u7684\u6a21\u578b\uff0c\u4f7f\u7528\u6700\u5927\u7ea0\u7f20\u6001\u8fdb\u884c\u8bad\u7ec3\u4f1a\u4e25\u91cd\u9650\u5236\u635f\u5931\u51fd\u6570\u503c\u7684\u6539\u8fdb\u3002\u968f\u7740PQC\u53ef\u8868\u8fbe\u6027\u7684\u589e\u52a0\uff0c\u5b83\u5bf9\u7531\u7ea0\u7f20\u8bad\u7ec3\u6570\u636e\u5f15\u8d77\u7684\u635f\u5931\u96c6\u4e2d\u73b0\u8c61\u66f4\u4e3a\u654f\u611f\u3002\u975e\u6700\u5927\u7ea0\u7f20\u5728\u8bad\u7ec3\u6837\u672c\u4e2d\u663e\u793a\u51fa\u6709\u6548\u6027\uff0c\u5e76\u4e14\u7ea0\u7f20\u71b5\u662f\u8bad\u7ec3\u80fd\u529b\u7684\u5173\u952e\u9884\u6d4b\u56e0\u5b50\u3002", "conclusion": "\u9ad8\u5ea6\u7ea0\u7f20\u7684\u8bad\u7ec3\u6570\u636e\uff0c\u7279\u522b\u662f\u6700\u5927\u7ea0\u7f20\u6001\uff0c\u53ef\u80fd\u4f1a\u963b\u788d\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u5c24\u5176\u662f\u5728\u6a21\u578b\u9ad8\u5ea6\u53ef\u8868\u8fbe\u7684\u60c5\u51b5\u4e0b\u3002\u975e\u6700\u5927\u7ea0\u7f20\u548c\u7ea0\u7f20\u71b5\u662f\u7406\u89e3\u548c\u9884\u6d4b\u6a21\u578b\u8bad\u7ec3\u80fd\u529b\u7684\u91cd\u8981\u56e0\u7d20\u3002"}}
{"id": "2509.09724", "categories": ["cs.CL", "cs.AI", "cs.LG", "68T09"], "pdf": "https://arxiv.org/pdf/2509.09724", "abs": "https://arxiv.org/abs/2509.09724", "authors": ["Wonyoung Kim", "Sujeong Seo", "Juhyun Lee"], "title": "DiTTO-LLM: Framework for Discovering Topic-based Technology Opportunities via Large Language Model", "comment": "5 figures", "summary": "Technology opportunities are critical information that serve as a foundation\nfor advancements in technology, industry, and innovation. This paper proposes a\nframework based on the temporal relationships between technologies to identify\nemerging technology opportunities. The proposed framework begins by extracting\ntext from a patent dataset, followed by mapping text-based topics to discover\ninter-technology relationships. Technology opportunities are then identified by\ntracking changes in these topics over time. To enhance efficiency, the\nframework leverages a large language model to extract topics and employs a\nprompt for a chat-based language model to support the discovery of technology\nopportunities. The framework was evaluated using an artificial intelligence\npatent dataset provided by the United States Patent and Trademark Office. The\nexperimental results suggest that artificial intelligence technology is\nevolving into forms that facilitate everyday accessibility. This approach\ndemonstrates the potential of the proposed framework to identify future\ntechnology opportunities.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6280\u672f\u95f4\u65f6\u95f4\u5173\u7cfb\u6765\u8bc6\u522b\u65b0\u5174\u6280\u672f\u673a\u4f1a\u7684\u6846\u67b6\u3002", "motivation": "\u6280\u672f\u673a\u4f1a\u662f\u63a8\u52a8\u6280\u672f\u3001\u884c\u4e1a\u548c\u521b\u65b0\u7684\u5173\u952e\u4fe1\u606f\u3002", "method": "\u8be5\u6846\u67b6\u901a\u8fc7\u4ece\u4e13\u5229\u6570\u636e\u96c6\u4e2d\u63d0\u53d6\u6587\u672c\uff0c\u5c06\u6587\u672c\u4e3b\u9898\u6620\u5c04\u4ee5\u53d1\u73b0\u6280\u672f\u95f4\u5173\u7cfb\uff0c\u5e76\u8ddf\u8e2a\u8fd9\u4e9b\u4e3b\u9898\u968f\u65f6\u95f4\u7684\u53d8\u5316\u6765\u8bc6\u522b\u6280\u672f\u673a\u4f1a\u3002\u8be5\u6846\u67b6\u8fd8\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63d0\u53d6\u4e3b\u9898\uff0c\u5e76\u4f7f\u7528\u804a\u5929\u8bed\u8a00\u6a21\u578b\u6765\u8f85\u52a9\u53d1\u73b0\u6280\u672f\u673a\u4f1a\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4eba\u5de5\u667a\u80fd\u6280\u672f\u6b63\u5728\u671d\u7740\u66f4\u52a0\u6613\u4e8e\u65e5\u5e38\u4f7f\u7528\u7684\u65b9\u5411\u53d1\u5c55\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u7684\u6846\u67b6\u5728\u8bc6\u522b\u672a\u6765\u6280\u672f\u673a\u4f1a\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2509.09955", "categories": ["cs.LG", "cs.AI", "cs.CV", "eess.IV"], "pdf": "https://arxiv.org/pdf/2509.09955", "abs": "https://arxiv.org/abs/2509.09955", "authors": ["Omar Erak", "Omar Alhussein", "Hatem Abou-Zeid", "Mehdi Bennis", "Sami Muhaidat"], "title": "Adaptive Token Merging for Efficient Transformer Semantic Communication at the Edge", "comment": "Submitted to IEEE Journals", "summary": "Large-scale transformers are central to modern semantic communication, yet\ntheir high computational and communication costs hinder deployment on\nresource-constrained edge devices. This paper introduces a training-free\nframework for adaptive token merging, a novel mechanism that compresses\ntransformer representations at runtime by selectively merging semantically\nredundant tokens under per-layer similarity thresholds. Unlike prior\nfixed-ratio reduction, our approach couples merging directly to input\nredundancy, enabling data-dependent adaptation that balances efficiency and\ntask relevance without retraining. We cast the discovery of merging strategies\nas a multi-objective optimization problem and leverage Bayesian optimization to\nobtain Pareto-optimal trade-offs between accuracy, inference cost, and\ncommunication cost. On ImageNet classification, we match the accuracy of the\nunmodified transformer with 30\\% fewer floating-point operations per second and\nunder 20\\% of the original communication cost, while for visual question\nanswering our method achieves performance competitive with the full LLaVA model\nat less than one-third of the compute and one-tenth of the bandwidth. Finally,\nwe show that our adaptive merging is robust across varying channel conditions\nand provides inherent privacy benefits, substantially degrading the efficacy of\nmodel inversion attacks. Our framework provides a practical and versatile\nsolution for deploying powerful transformer models in resource-limited edge\nintelligence scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u81ea\u9002\u5e94\u4ee4\u724c\u5408\u5e76\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u8bbe\u5907\u4e0a\u90e8\u7f72\u5927\u578bTransformer\u6a21\u578b\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u52a8\u6001\u5408\u5e76\u8bed\u4e49\u5197\u4f59\u7684\u4ee4\u724c\u6765\u538b\u7f29Transformer\u8868\u793a\uff0c\u5b9e\u73b0\u4e86\u8ba1\u7b97\u548c\u901a\u4fe1\u6210\u672c\u7684\u5927\u5e45\u964d\u4f4e\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u7cbe\u5ea6\u3002", "motivation": "\u5927\u578bTransformer\u6a21\u578b\u5728\u8bed\u4e49\u901a\u4fe1\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5176\u9ad8\u6602\u7684\u8ba1\u7b97\u548c\u901a\u4fe1\u6210\u672c\u9650\u5236\u4e86\u5176\u5728\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u90e8\u7f72\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u5728\u4e0d\u91cd\u65b0\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u964d\u4f4eTransformer\u6a21\u578b\u6210\u672c\u7684\u65b9\u6cd5\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u4ee4\u724c\u5408\u5e76\uff08adaptive token merging\uff09\u7684\u8bad\u7ec3\u6846\u67b6\u3002\u8be5\u6846\u67b6\u5728\u8fd0\u884c\u65f6\u901a\u8fc7\u6839\u636e\u6bcf\u5c42\u76f8\u4f3c\u5ea6\u9608\u503c\u9009\u62e9\u6027\u5730\u5408\u5e76\u8bed\u4e49\u5197\u4f59\u7684\u4ee4\u724c\u6765\u538b\u7f29Transformer\u8868\u793a\u3002\u4e0e\u5148\u524d\u56fa\u5b9a\u7684\u964d\u7ef4\u6bd4\u4f8b\u4e0d\u540c\uff0c\u8be5\u65b9\u6cd5\u5c06\u5408\u5e76\u4e0e\u8f93\u5165\u5197\u4f59\u76f4\u63a5\u8026\u5408\uff0c\u5b9e\u73b0\u4e86\u6570\u636e\u4f9d\u8d56\u7684\u81ea\u9002\u5e94\uff0c\u4ece\u800c\u5728\u6548\u7387\u548c\u4efb\u52a1\u76f8\u5173\u6027\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u4e14\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u3002\u8be5\u65b9\u6cd5\u5c06\u5408\u5e76\u7b56\u7565\u7684\u53d1\u73b0\u89c6\u4e3a\u4e00\u4e2a\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u5229\u7528\u8d1d\u53f6\u65af\u4f18\u5316\u6765\u83b7\u5f97\u51c6\u786e\u6027\u3001\u63a8\u7406\u6210\u672c\u548c\u901a\u4fe1\u6210\u672c\u4e4b\u95f4\u7684\u5e15\u7d2f\u6258\u6700\u4f18\u6743\u8861\u3002", "result": "\u5728ImageNet\u5206\u7c7b\u4efb\u52a1\u4e0a\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u4e0e\u672a\u7ecf\u4fee\u6539\u7684Transformer\u76f8\u5f53\u7684\u51c6\u786e\u6027\uff0c\u540c\u65f6\u6d6e\u70b9\u8fd0\u7b97\u6b21\u6570\u51cf\u5c11\u4e8630%\uff0c\u901a\u4fe1\u6210\u672c\u964d\u4f4e\u4e8680%\u4ee5\u4e0a\u3002\u5728\u89c6\u89c9\u95ee\u7b54\u4efb\u52a1\u4e0a\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u4e0e\u5b8c\u6574LLaVA\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u4f46\u8ba1\u7b97\u91cf\u4e0d\u5230\u4e09\u5206\u4e4b\u4e00\uff0c\u5e26\u5bbd\u6d88\u8017\u4e0d\u5230\u5341\u5206\u4e4b\u4e00\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u5728\u53d8\u5316\u7684\u4fe1\u9053\u6761\u4ef6\u4e0b\u8868\u73b0\u51fa\u9c81\u68d2\u6027\uff0c\u5e76\u80fd\u6709\u6548\u62b5\u6297\u6a21\u578b\u53cd\u6f14\u653b\u51fb\uff0c\u63d0\u4f9b\u5185\u7f6e\u7684\u9690\u79c1\u4fdd\u62a4\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u81ea\u9002\u5e94\u4ee4\u724c\u5408\u5e76\u6846\u67b6\u4e3a\u5728\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u667a\u80fd\u573a\u666f\u4e2d\u90e8\u7f72\u5f3a\u5927\u7684Transformer\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.10222", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10222", "abs": "https://arxiv.org/abs/2509.10222", "authors": ["Ma\u00ebl Jullien", "Lei Xu", "Marco Valentino", "Andr\u00e9 Freitas"], "title": "Compartmentalised Agentic Reasoning for Clinical NLI", "comment": null, "summary": "A common assumption holds that scaling data and parameters yields\nincreasingly structured, generalisable internal representations. We interrogate\nthis assumption in clinical natural language inference (NLI) by adopting a\nbenchmark decomposed into four reasoning families, Causal Attribution,\nCompositional Grounding, Epistemic Verification, and Risk State Abstraction,\nand introducing CARENLI, a Compartmentalised Agentic Reasoning for Clinical NLI\nthat separates knowledge access from principled inference. CARENLI routes each\npremise, statement pair to a family specific solver and enforces auditable\nprocedures via a planner, verifier, and refiner.\n  Across four LLMs, CARENLI improves fidelity by up to 42 points, reaching\n98.0% in Causal Attribution and 81.2% in Risk State Abstraction. Verifiers flag\nviolations with near-ceiling reliability, while refiners correct a substantial\nshare of epistemic errors. Remaining failures cluster in routing, identifying\nfamily classification as the main bottleneck. These results show that LLMs\noften retain relevant facts but default to heuristics when inference is\nunderspecified, a dissociation CARENLI makes explicit while offering a\nframework for safer, auditable reasoning.", "AI": {"tldr": "CARENLI\u901a\u8fc7\u5c06\u4e34\u5e8aNLI\u5206\u89e3\u4e3a\u56db\u4e2a\u63a8\u7406\u5bb6\u65cf\u5e76\u4f7f\u7528\u7279\u5b9a\u5bb6\u65cf\u7684\u6c42\u89e3\u5668\uff0c\u63d0\u9ad8\u4e86LLM\u7684\u51c6\u786e\u6027\uff0c\u5c24\u5176\u662f\u5728\u56e0\u679c\u5f52\u56e0\u548c\u98ce\u9669\u72b6\u6001\u62bd\u8c61\u65b9\u9762\uff0c\u540c\u65f6\u5b9e\u73b0\u4e86\u53ef\u5ba1\u8ba1\u7684\u7a0b\u5e8f\u3002", "motivation": "\u8bc4\u4f30\u5728\u4e34\u5e8a\u81ea\u7136\u8bed\u8a00\u63a8\u7406\uff08NLI\uff09\u4e2d\uff0c\u6269\u5c55\u6570\u636e\u548c\u53c2\u6570\u662f\u5426\u80fd\u5e26\u6765\u66f4\u5f3a\u7684\u7ed3\u6784\u5316\u548c\u53ef\u6cdb\u5316\u7684\u5185\u90e8\u8868\u5f81\u3002\u5728\u6b64\u8fc7\u7a0b\u4e2d\uff0c\u8bc6\u522b\u51faLLM\u5728\u63a8\u7406\u4e0d\u8db3\u65f6\u503e\u5411\u4e8e\u4f7f\u7528\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u800c\u975e\u4fdd\u7559\u76f8\u5173\u4e8b\u5b9e\u3002", "method": "\u63d0\u51faCARENLI\uff08Compartmentalised Agentic Reasoning for Clinical NLI\uff09\uff0c\u4e00\u79cd\u5c06\u77e5\u8bc6\u83b7\u53d6\u4e0e\u539f\u5219\u6027\u63a8\u7406\u5206\u79bb\u7684\u6846\u67b6\u3002CARENLI\u5c06\u4e34\u5e8aNLI\u57fa\u51c6\u5206\u89e3\u4e3a\u56e0\u679c\u5f52\u56e0\u3001\u7ec4\u5408\u5f52\u56e0\u3001\u8ba4\u77e5\u9a8c\u8bc1\u548c\u98ce\u9669\u72b6\u6001\u62bd\u8c61\u56db\u4e2a\u63a8\u7406\u5bb6\u65cf\uff0c\u5e76\u4e3a\u6bcf\u4e2a\u5bb6\u65cf\u914d\u5907\u4e13\u95e8\u7684\u6c42\u89e3\u5668\u3002\u901a\u8fc7\u89c4\u5212\u5668\u3001\u9a8c\u8bc1\u5668\u548c\u7cbe\u70bc\u5668\u6765\u5f3a\u5236\u6267\u884c\u53ef\u5ba1\u8ba1\u7684\u7a0b\u5e8f\u3002", "result": "CARENLI\u5728\u56db\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e0a\uff0c\u5c06\u51c6\u786e\u6027\u63d0\u9ad8\u4e8642\u4e2a\u767e\u5206\u70b9\uff0c\u5728\u56e0\u679c\u5f52\u56e0\u65b9\u9762\u8fbe\u523098.0%\uff0c\u5728\u98ce\u9669\u72b6\u6001\u62bd\u8c61\u65b9\u9762\u8fbe\u523081.2%\u3002\u9a8c\u8bc1\u5668\u80fd\u4ee5\u63a5\u8fd1\u5b8c\u7f8e\u7684\u53ef\u9760\u6027\u6807\u8bb0\u8fdd\u89c4\u884c\u4e3a\uff0c\u7cbe\u70bc\u5668\u80fd\u7ea0\u6b63\u5927\u91cf\u7684\u8ba4\u77e5\u9519\u8bef\u3002\u5269\u4f59\u7684\u9519\u8bef\u96c6\u4e2d\u5728\u8def\u7531\u73af\u8282\uff0c\u8868\u660e\u5bb6\u65cf\u5206\u7c7b\u662f\u4e3b\u8981\u7684\u74f6\u9888\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u901a\u5e38\u80fd\u4fdd\u7559\u76f8\u5173\u4e8b\u5b9e\uff0c\u4f46\u5728\u63a8\u7406\u4e0d\u8db3\u65f6\u4f1a\u9ed8\u8ba4\u4f7f\u7528\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002CARENLI\u6846\u67b6\u80fd\u591f\u660e\u786e\u533a\u5206\u8fd9\u4e24\u8005\uff0c\u5e76\u63d0\u4f9b\u4e00\u4e2a\u66f4\u5b89\u5168\u3001\u53ef\u5ba1\u8ba1\u7684\u63a8\u7406\u6846\u67b6\u3002"}}
{"id": "2509.09869", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09869", "abs": "https://arxiv.org/abs/2509.09869", "authors": ["Yihao Liu", "Junyu Chen", "Lianrui Zuo", "Shuwen Wei", "Brian D. Boyd", "Carmen Andreescu", "Olusola Ajilore", "Warren D. Taylor", "Aaron Carass", "Bennett A. Landman"], "title": "Surrogate Supervision for Robust and Generalizable Deformable Image Registration", "comment": null, "summary": "Objective: Deep learning-based deformable image registration has achieved\nstrong accuracy, but remains sensitive to variations in input image\ncharacteristics such as artifacts, field-of-view mismatch, or modality\ndifference. We aim to develop a general training paradigm that improves the\nrobustness and generalizability of registration networks. Methods: We introduce\nsurrogate supervision, which decouples the input domain from the supervision\ndomain by applying estimated spatial transformations to surrogate images. This\nallows training on heterogeneous inputs while ensuring supervision is computed\nin domains where similarity is well defined. We evaluate the framework through\nthree representative applications: artifact-robust brain MR registration,\nmask-agnostic lung CT registration, and multi-modal MR registration. Results:\nAcross tasks, surrogate supervision demonstrated strong resilience to input\nvariations including inhomogeneity field, inconsistent field-of-view, and\nmodality differences, while maintaining high performance on well-curated data.\nConclusions: Surrogate supervision provides a principled framework for training\nrobust and generalizable deep learning-based registration models without\nincreasing complexity. Significance: Surrogate supervision offers a practical\npathway to more robust and generalizable medical image registration, enabling\nbroader applicability in diverse biomedical imaging scenarios.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2509.10349", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.10349", "abs": "https://arxiv.org/abs/2509.10349", "authors": ["Weiyan Lu", "Huizhe Li", "Yuhao Fang", "Zhexuan Zhou", "Junda Wu", "Yude Li", "Youmin Gong", "Jie Mei"], "title": "Acetrans: An Autonomous Corridor-Based and Efficient UAV Suspended Transport System", "comment": null, "summary": "Unmanned aerial vehicles (UAVs) with suspended payloads offer significant\nadvantages for aerial transportation in complex and cluttered environments.\nHowever, existing systems face critical limitations, including unreliable\nperception of the cable-payload dynamics, inefficient planning in large-scale\nenvironments, and the inability to guarantee whole-body safety under cable\nbending and external disturbances. This paper presents Acetrans, an Autonomous,\nCorridor-based, and Efficient UAV suspended transport system that addresses\nthese challenges through a unified perception, planning, and control framework.\nA LiDAR-IMU fusion module is proposed to jointly estimate both payload pose and\ncable shape under taut and bent modes, enabling robust whole-body state\nestimation and real-time filtering of cable point clouds. To enhance planning\nscalability, we introduce the Multi-size-Aware Configuration-space Iterative\nRegional Inflation (MACIRI) algorithm, which generates safe flight corridors\nwhile accounting for varying UAV and payload geometries. A spatio-temporal,\ncorridor-constrained trajectory optimization scheme is then developed to ensure\ndynamically feasible and collision-free trajectories. Finally, a nonlinear\nmodel predictive controller (NMPC) augmented with cable-bending constraints\nprovides robust whole-body safety during execution. Simulation and experimental\nresults validate the effectiveness of Acetrans, demonstrating substantial\nimprovements in perception accuracy, planning efficiency, and control safety\ncompared to state-of-the-art methods.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a Acetrans \u7684\u65e0\u4eba\u673a\u60ac\u6302\u5f0f\u8fd0\u8f93\u7cfb\u7edf\uff0c\u901a\u8fc7\u7edf\u4e00\u7684\u611f\u77e5\u3001\u89c4\u5212\u548c\u63a7\u5236\u6846\u67b6\u89e3\u51b3\u4e86\u590d\u6742\u73af\u5883\u4e2d\u65e0\u4eba\u673a\u8fd0\u8f93\u7684\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u65e0\u4eba\u673a\u60ac\u6302\u5f0f\u8fd0\u8f93\u7cfb\u7edf\u5728\u611f\u77e5\u3001\u89c4\u5212\u548c\u5b89\u5168\u4fdd\u8bc1\u65b9\u9762\u5b58\u5728\u4e25\u91cd\u7f3a\u9677\uff0c\u5305\u62ec\u5bf9\u7ef3\u7d22-\u8f7d\u8377\u52a8\u529b\u5b66\u611f\u77e5\u4e0d\u53ef\u9760\u3001\u5927\u89c4\u6a21\u73af\u5883\u89c4\u5212\u6548\u7387\u4f4e\u4e0b\u4ee5\u53ca\u5728\u7ef3\u7d22\u5f2f\u66f2\u548c\u5916\u90e8\u5e72\u6270\u4e0b\u65e0\u6cd5\u4fdd\u8bc1\u5168\u8eab\u5b89\u5168\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408 LiDAR-IMU \u7684\u878d\u5408\u6a21\u5757\uff0c\u7528\u4e8e\u540c\u65f6\u4f30\u8ba1\u7ef3\u7d22\u7684\u62c9\u7d27\u548c\u5f2f\u66f2\u6a21\u5f0f\u4e0b\u7684\u8f7d\u8377\u59ff\u6001\u548c\u7ef3\u7d22\u5f62\u72b6\uff0c\u5b9e\u73b0\u4e86\u9c81\u68d2\u7684\u5168\u8eab\u72b6\u6001\u4f30\u8ba1\u548c\u5b9e\u65f6\u70b9\u4e91\u6ee4\u6ce2\u3002\u5f15\u5165\u4e86\u591a\u5c3a\u5bf8\u611f\u77e5\u6784\u578b\u7a7a\u95f4\u8fed\u4ee3\u533a\u57df\u81a8\u80c0\uff08MACIRI\uff09\u7b97\u6cd5\uff0c\u7528\u4e8e\u751f\u6210\u8003\u8651\u4e0d\u540c\u65e0\u4eba\u673a\u548c\u8f7d\u8377\u51e0\u4f55\u5f62\u72b6\u7684\u5b89\u5168\u98de\u884c\u901a\u9053\u3002\u5f00\u53d1\u4e86\u4e00\u79cd\u65f6\u7a7a\u76f8\u5173\u7684\u3001\u53d7\u901a\u9053\u7ea6\u675f\u7684\u8f68\u8ff9\u4f18\u5316\u65b9\u6848\uff0c\u4ee5\u786e\u4fdd\u52a8\u6001\u53ef\u884c\u4e14\u65e0\u78b0\u649e\u7684\u8f68\u8ff9\u3002\u6700\u540e\uff0c\u91c7\u7528\u589e\u5f3a\u4e86\u7ef3\u7d22\u5f2f\u66f2\u7ea6\u675f\u7684\u975e\u7ebf\u6027\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u5668\uff08NMPC\uff09\u6765\u786e\u4fdd\u6267\u884c\u8fc7\u7a0b\u4e2d\u7684\u9c81\u68d2\u5168\u8eab\u5b89\u5168\u3002", "result": "\u6a21\u62df\u548c\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86 Acetrans \u7684\u6709\u6548\u6027\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5728\u611f\u77e5\u7cbe\u5ea6\u3001\u89c4\u5212\u6548\u7387\u548c\u63a7\u5236\u5b89\u5168\u6027\u65b9\u9762\u90fd\u6709\u663e\u8457\u63d0\u9ad8\u3002", "conclusion": "Acetrans \u7cfb\u7edf\u901a\u8fc7\u7edf\u4e00\u7684\u611f\u77e5\u3001\u89c4\u5212\u548c\u63a7\u5236\u6846\u67b6\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u65e0\u4eba\u673a\u60ac\u6302\u5f0f\u8fd0\u8f93\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u5e76\u5728\u7cbe\u5ea6\u3001\u6548\u7387\u548c\u5b89\u5168\u6027\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\u3002"}}
{"id": "2509.10158", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2509.10158", "abs": "https://arxiv.org/abs/2509.10158", "authors": ["Yu-Xia Wu", "Yun-Zhuo Fan", "Dan-Bo Zhang"], "title": "Fluctuation-guided adaptive random compiler for Hamiltonian simulation", "comment": null, "summary": "Stochastic methods offer an effective way to suppress coherent errors in\nquantum simulation. In particular, the randomized compilation protocol may\nreduce circuit depth by randomly sampling Hamiltonian terms rather than\nfollowing the deterministic Trotter-Suzuki sequence. However, its fixed\nsampling distribution does not adapt to the dynamics of the system, limiting\nits accuracy. In this work, we propose a fluctuation-guided adaptive algorithm\nthat adaptively updates sampling probabilities based on fluctuations of\nHamiltonian terms to achieve higher simulation fidelity. Remarkably, the\nprotocol renders an intuitive physical understanding: Hamiltonian terms with\ngreater sensitivity to the state evolution should be prioritized during\nsampling. The overload of measuring fluctuations necessary for updating the\nsampling probability is affordable, and can be further largely reduced by\nclassical shadows. We demonstrate the effectiveness of the method with numeral\nsimulations across discrete-variable, continuous-variable and hybrid-variable\nsystems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6ce2\u52a8\u7684\u81ea\u9002\u5e94\u7b97\u6cd5\uff0c\u7528\u4e8e\u5728\u91cf\u5b50\u6a21\u62df\u4e2d\u901a\u8fc7\u81ea\u9002\u5e94\u5730\u66f4\u65b0\u54c8\u5bc6\u987f\u91cf\u9879\u7684\u91c7\u6837\u6982\u7387\u6765\u6291\u5236\u76f8\u5e72\u8bef\u5dee\uff0c\u63d0\u9ad8\u4e86\u6a21\u62df\u4fdd\u771f\u5ea6\u3002", "motivation": "\u968f\u673a\u7f16\u8bd1\u534f\u8bae\u867d\u7136\u53ef\u4ee5\u901a\u8fc7\u968f\u673a\u5bf9\u54c8\u5bc6\u987f\u91cf\u9879\u8fdb\u884c\u91c7\u6837\u6765\u51cf\u5c11\u91cf\u5b50\u6a21\u62df\u7684\u7535\u8def\u6df1\u5ea6\uff0c\u4f46\u5176\u56fa\u5b9a\u7684\u91c7\u6837\u5206\u5e03\u65e0\u6cd5\u9002\u5e94\u7cfb\u7edf\u52a8\u529b\u5b66\uff0c\u4ece\u800c\u9650\u5236\u4e86\u5176\u7cbe\u5ea6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6ce2\u52a8\u7684\u81ea\u9002\u5e94\u7b97\u6cd5\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u5730\u66f4\u65b0\u91c7\u6837\u6982\u7387\u6765\u89e3\u51b3\u56fa\u5b9a\u91c7\u6837\u5206\u5e03\u7684\u95ee\u9898\u3002\u8be5\u7b97\u6cd5\u6839\u636e\u54c8\u5bc6\u987f\u91cf\u9879\u7684\u6ce2\u52a8\u6765\u66f4\u65b0\u91c7\u6837\u6982\u7387\uff0c\u4f18\u5148\u5bf9\u72b6\u6001\u6f14\u5316\u66f4\u654f\u611f\u7684\u54c8\u5bc6\u987f\u91cf\u9879\u8fdb\u884c\u91c7\u6837\u3002\u4e3a\u4e86\u51cf\u5c11\u66f4\u65b0\u91c7\u6837\u6982\u7387\u6240\u9700\u7684\u6d4b\u91cf\u5f00\u9500\uff0c\u53ef\u4ee5\u91c7\u7528\u7ecf\u5178\u9634\u5f71\u6280\u672f\u3002", "result": "\u901a\u8fc7\u5728\u79bb\u6563\u53d8\u91cf\u3001\u8fde\u7eed\u53d8\u91cf\u548c\u6df7\u5408\u53d8\u91cf\u7cfb\u7edf\u4e2d\u7684\u6570\u503c\u6a21\u62df\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u6ce2\u52a8\u7684\u81ea\u9002\u5e94\u7b97\u6cd5\u80fd\u591f\u901a\u8fc7\u4f18\u5148\u91c7\u6837\u5bf9\u72b6\u6001\u6f14\u5316\u66f4\u654f\u611f\u7684\u54c8\u5bc6\u987f\u91cf\u9879\u6765\u63d0\u9ad8\u91cf\u5b50\u6a21\u62df\u7684\u4fdd\u771f\u5ea6\uff0c\u5e76\u4e14\u53ef\u4ee5\u901a\u8fc7\u7ecf\u5178\u9634\u5f71\u6280\u672f\u6765\u4f18\u5316\u6d4b\u91cf\u5f00\u9500\u3002"}}
{"id": "2509.09725", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.09725", "abs": "https://arxiv.org/abs/2509.09725", "authors": ["Chunyu Li", "Xindi Zheng", "Siqi Liu"], "title": "BIBERT-Pipe on Biomedical Nested Named Entity Linking at BioASQ 2025", "comment": null, "summary": "Entity linking (EL) for biomedical text is typically benchmarked on\nEnglish-only corpora with flat mentions, leaving the more realistic scenario of\nnested and multilingual mentions largely unexplored. We present our system for\nthe BioNNE 2025 Multilingual Biomedical Nested Named Entity Linking shared task\n(English & Russian), closing this gap with a lightweight pipeline that keeps\nthe original EL model intact and modifies only three task-aligned components:\nTwo-stage retrieval-ranking. We leverage the same base encoder model in both\nstages: the retrieval stage uses the original pre-trained model, while the\nranking stage applies domain-specific fine-tuning. Boundary cues. In the\nranking stage, we wrap each mention with learnable [Ms] / [Me] tags, providing\nthe encoder with an explicit, language-agnostic span before robustness to\noverlap and nesting. Dataset augmentation. We also automatically expand the\nranking training corpus with three complementary data sources, enhancing\ncoverage without extra manual annotation. On the BioNNE 2025 leaderboard, our\ntwo stage system, bilingual bert (BIBERT-Pipe), ranks third in the multilingual\ntrack, demonstrating the effectiveness and competitiveness of these minimal yet\nprincipled modifications. Code are publicly available at\nhttps://github.com/Kaggle-Competitions-Code/BioNNE-L.", "AI": {"tldr": "\u8be5\u7cfb\u7edf\u5728BioNNE 2025\u591a\u8bed\u8a00\u751f\u7269\u533b\u5b66\u5d4c\u5957\u547d\u540d\u5b9e\u4f53\u94fe\u63a5\u5171\u4eab\u4efb\u52a1\uff08\u82f1\u8bed\u548c\u4fc4\u8bed\uff09\u4e2d\u6392\u540d\u7b2c\u4e09\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u68c0\u7d22-\u6392\u5e8f\u3001\u8fb9\u754c\u63d0\u793a\u548c\u6570\u636e\u96c6\u589e\u5f3a\u6765\u89e3\u51b3\u5d4c\u5957\u548c\u591a\u8bed\u8a00\u5b9e\u4f53\u94fe\u63a5\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u751f\u7269\u533b\u5b66\u5b9e\u4f53\u94fe\u63a5\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u57fa\u4e8e\u7eaf\u82f1\u8bed\u8bed\u6599\u5e93\uff0c\u4e14\u53ea\u8003\u8651\u6241\u5e73\u63d0\u53ca\uff0c\u672a\u80fd\u5145\u5206\u63a2\u7d22\u5d4c\u5957\u548c\u591a\u8bed\u8a00\u63d0\u53ca\u7684\u66f4\u73b0\u5b9e\u573a\u666f\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u6d41\u6c34\u7ebf\uff0c\u4e0d\u6539\u53d8\u539f\u6709\u7684\u5b9e\u4f53\u94fe\u63a5\u6a21\u578b\uff0c\u4ec5\u4fee\u6539\u4e09\u4e2a\u4e0e\u4efb\u52a1\u5bf9\u9f50\u7684\u7ec4\u4ef6\uff1a1.\u4e24\u9636\u6bb5\u68c0\u7d22-\u6392\u5e8f\uff1a\u68c0\u7d22\u9636\u6bb5\u4f7f\u7528\u539f\u59cb\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u6392\u5e8f\u9636\u6bb5\u8fdb\u884c\u9886\u57df\u7279\u5b9a\u5fae\u8c03\u30022.\u8fb9\u754c\u63d0\u793a\uff1a\u5728\u6392\u5e8f\u9636\u6bb5\uff0c\u7528\u53ef\u5b66\u4e60\u7684[Ms]/[Me]\u6807\u7b7e\u5305\u88f9\u63d0\u53ca\uff0c\u4e3a\u7f16\u7801\u5668\u63d0\u4f9b\u660e\u786e\u7684\u3001\u4e0e\u8bed\u8a00\u65e0\u5173\u7684\u8fb9\u754c\u30023.\u6570\u636e\u96c6\u589e\u5f3a\uff1a\u81ea\u52a8\u6269\u5c55\u6392\u5e8f\u8bad\u7ec3\u8bed\u6599\u5e93\uff0c\u589e\u52a0\u6570\u636e\u8986\u76d6\u8303\u56f4\u3002", "result": "\u5728BioNNE 2025\u6392\u884c\u699c\u4e0a\uff0c\u8be5\u7cfb\u7edf\u7684\u53cc\u8bedBERT\uff08BIBERT-Pipe\uff09\u5728\u591a\u8bed\u8a00\u8d5b\u9053\u4e0a\u6392\u540d\u7b2c\u4e09\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u6700\u5c0f\u4f46\u7b26\u5408\u539f\u5219\u7684\u4fee\u6539\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u5177\u6709\u7ade\u4e89\u529b\u7684\u591a\u8bed\u8a00\u751f\u7269\u533b\u5b66\u5d4c\u5957\u5b9e\u4f53\u94fe\u63a5\u3002"}}
{"id": "2509.09960", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09960", "abs": "https://arxiv.org/abs/2509.09960", "authors": ["Mingxuan Jiang", "Yongxin Wang", "Ziyue Dai", "Yicun Liu", "Hongyi Nie", "Sen Liu", "Hongfeng Chai"], "title": "Limited Reference, Reliable Generation: A Two-Component Framework for Tabular Data Generation in Low-Data Regimes", "comment": null, "summary": "Synthetic tabular data generation is increasingly essential in data\nmanagement, supporting downstream applications when real-world and high-quality\ntabular data is insufficient. Existing tabular generation approaches, such as\ngenerative adversarial networks (GANs), diffusion models, and fine-tuned Large\nLanguage Models (LLMs), typically require sufficient reference data, limiting\ntheir effectiveness in domain-specific databases with scarce records. While\nprompt-based LLMs offer flexibility without parameter tuning, they often fail\nto capture dataset-specific feature-label dependencies and generate redundant\ndata, leading to degradation in downstream task performance. To overcome these\nissues, we propose ReFine, a framework that (i) derives symbolic \"if-then\"\nrules from interpretable models and embeds them into prompts to explicitly\nguide generation toward domain-specific feature distribution, and (ii) applies\na dual-granularity filtering strategy that suppresses over-sampling patterns\nand selectively refines rare but informative samples to reduce distributional\nimbalance. Extensive experiments on various regression and classification\nbenchmarks demonstrate that ReFine consistently outperforms state-of-the-art\nmethods, achieving up to 0.44 absolute improvement in R-squared for regression\nand 10.0 percent relative improvement in F1 score for classification tasks.", "AI": {"tldr": "ReFine\u662f\u4e00\u4e2a\u6846\u67b6\uff0c\u901a\u8fc7\u4ece\u53ef\u89e3\u91ca\u6a21\u578b\u4e2d\u63d0\u53d6\u7684\u201c\u5982\u679c-\u90a3\u4e48\u201d\u89c4\u5219\u6765\u6307\u5bfc\u57fa\u4e8e\u63d0\u793a\u7684\u751f\u6210\uff0c\u5e76\u91c7\u7528\u53cc\u7c92\u5ea6\u8fc7\u6ee4\u7b56\u7565\u6765\u5904\u7406\u6570\u636e\u4e0d\u5e73\u8861\uff0c\u4ece\u800c\u63d0\u9ad8\u5408\u6210\u8868\u683c\u6570\u636e\u7684\u8d28\u91cf\uff0c\u5c24\u5176\u662f\u5728\u6570\u636e\u7a00\u758f\u7684\u9886\u57df\u3002", "motivation": "\u73b0\u6709\u7684\u8868\u683c\u751f\u6210\u65b9\u6cd5\uff08\u5982GANs\u3001\u6269\u6563\u6a21\u578b\u548c\u5fae\u8c03LLMs\uff09\u901a\u5e38\u9700\u8981\u5927\u91cf\u53c2\u8003\u6570\u636e\uff0c\u8fd9\u5728\u6570\u636e\u7a00\u758f\u7684\u9886\u57df\u4e2d\u9650\u5236\u4e86\u5b83\u4eec\u7684\u6709\u6548\u6027\u3002\u57fa\u4e8e\u63d0\u793a\u7684LLMs\u867d\u7136\u7075\u6d3b\uff0c\u4f46\u5f80\u5f80\u65e0\u6cd5\u6355\u6349\u7279\u5b9a\u6570\u636e\u96c6\u7684\u7279\u5f81-\u6807\u7b7e\u4f9d\u8d56\u6027\u5e76\u751f\u6210\u5197\u4f59\u6570\u636e\uff0c\u5bfc\u81f4\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u4e0b\u964d\u3002", "method": "ReFine\u6846\u67b6\u5305\u542b\u4e24\u4e2a\u4e3b\u8981\u90e8\u5206\uff1a1. \u4ece\u53ef\u89e3\u91ca\u6a21\u578b\u4e2d\u63d0\u53d6\u7b26\u53f7\u5316\u7684\u201c\u5982\u679c-\u90a3\u4e48\u201d\u89c4\u5219\uff0c\u5e76\u5c06\u5176\u5d4c\u5165\u63d0\u793a\u4e2d\uff0c\u4ee5\u660e\u786e\u6307\u5bfc\u751f\u6210\u8fc7\u7a0b\uff0c\u4f7f\u5176\u7b26\u5408\u7279\u5b9a\u9886\u57df\u7684\u7279\u5f81\u5206\u5e03\u30022. \u91c7\u7528\u53cc\u7c92\u5ea6\u8fc7\u6ee4\u7b56\u7565\uff0c\u6291\u5236\u8fc7\u5ea6\u62bd\u6837\u6a21\u5f0f\uff0c\u5e76\u6709\u9009\u62e9\u5730\u4f18\u5316\u7a00\u6709\u4f46\u4fe1\u606f\u91cf\u5927\u7684\u6837\u672c\uff0c\u4ee5\u51cf\u5c11\u5206\u5e03\u4e0d\u5e73\u8861\u3002", "result": "\u5728\u5404\u79cd\u56de\u5f52\u548c\u5206\u7c7b\u57fa\u51c6\u6d4b\u8bd5\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cReFine\u7684\u6027\u80fd\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\uff0c\u5728\u56de\u5f52\u4efb\u52a1\u4e0aR\u5e73\u65b9\u503c\u63d0\u9ad8\u4e860.44\uff0c\u5728\u5206\u7c7b\u4efb\u52a1\u4e0aF1\u5206\u6570\u63d0\u9ad8\u4e8610.0%\u3002", "conclusion": "ReFine\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u53ef\u89e3\u91ca\u89c4\u5219\u5f15\u5bfc\u548c\u53cc\u7c92\u5ea6\u8fc7\u6ee4\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u8868\u683c\u751f\u6210\u65b9\u6cd5\u5728\u6570\u636e\u7a00\u758f\u548c\u5206\u5e03\u4e0d\u5e73\u8861\u60c5\u51b5\u4e0b\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2509.10249", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10249", "abs": "https://arxiv.org/abs/2509.10249", "authors": ["Hanna Abi Akl"], "title": "Investigating Language Model Capabilities to Represent and Process Formal Knowledge: A Preliminary Study to Assist Ontology Engineering", "comment": "accepted for the International Joint Conference on Rules and\n  Reasoning (RuleML+RR) 2025", "summary": "Recent advances in Language Models (LMs) have failed to mask their\nshortcomings particularly in the domain of reasoning. This limitation impacts\nseveral tasks, most notably those involving ontology engineering. As part of a\nPhD research, we investigate the consequences of incorporating formal methods\non the performance of Small Language Models (SLMs) on reasoning tasks.\nSpecifically, we aim to orient our work toward using SLMs to bootstrap ontology\nconstruction and set up a series of preliminary experiments to determine the\nimpact of expressing logical problems with different grammars on the\nperformance of SLMs on a predefined reasoning task. Our findings show that it\nis possible to substitute Natural Language (NL) with a more compact logical\nlanguage while maintaining a strong performance on reasoning tasks and hope to\nuse these results to further refine the role of SLMs in ontology engineering.", "AI": {"tldr": "\u8fd1\u671f\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u672c\u7814\u7a76\u63a2\u7d22\u5c06\u5f62\u5f0f\u5316\u65b9\u6cd5\u5e94\u7528\u4e8e\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08SLMs\uff09\u4ee5\u63d0\u5347\u5176\u5728\u672c\u4f53\u5de5\u7a0b\u4e2d\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u521d\u6b65\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u4f7f\u7528\u7d27\u51d1\u903b\u8f91\u8bed\u8a00\u66ff\u4ee3\u81ea\u7136\u8bed\u8a00\u5bf9SLMs\u6027\u80fd\u7684\u5f71\u54cd\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u5c24\u5176\u662f\u5728\u672c\u4f53\u5de5\u7a0b\u9886\u57df\uff0c\u8fd9\u5f71\u54cd\u4e86\u76f8\u5173\u4efb\u52a1\u7684\u6267\u884c\u3002\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u5f15\u5165\u5f62\u5f0f\u5316\u65b9\u6cd5\u6765\u514b\u670d\u8fd9\u4e00\u5c40\u9650\u6027\uff0c\u5e76\u63a2\u8ba8\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08SLMs\uff09\u5728\u672c\u4f53\u6784\u5efa\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "method": "\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5c06\u5f62\u5f0f\u5316\u65b9\u6cd5\u5e94\u7528\u4e8e\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08SLMs\uff09\uff0c\u4ee5\u63d0\u5347\u5176\u5728\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002\u5177\u4f53\u800c\u8a00\uff0c\u5c06\u8fdb\u884c\u4e00\u7cfb\u5217\u521d\u6b65\u5b9e\u9a8c\uff0c\u6bd4\u8f83SLMs\u5728\u5904\u7406\u4e0d\u540c\u903b\u8f91\u6587\u6cd5\uff08\u5305\u62ec\u81ea\u7136\u8bed\u8a00\u548c\u66f4\u7d27\u51d1\u7684\u903b\u8f91\u8bed\u8a00\uff09\u4e0b\u7684\u8868\u73b0\uff0c\u4ee5\u8bc4\u4f30\u5176\u5728\u672c\u4f53\u5de5\u7a0b\u4e2d\u7684\u5e94\u7528\u6548\u679c\u3002", "result": "\u521d\u6b65\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4f7f\u7528\u66f4\u7d27\u51d1\u7684\u903b\u8f91\u8bed\u8a00\u66ff\u4ee3\u81ea\u7136\u8bed\u8a00\u5728\u63a8\u7406\u4efb\u52a1\u4e0a\u53ef\u4ee5\u4fdd\u6301\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08SLMs\uff09\u7684\u826f\u597d\u6027\u80fd\u3002", "conclusion": "\u672c\u7814\u7a76\u7684\u53d1\u73b0\u652f\u6301\u4f7f\u7528\u66f4\u7d27\u51d1\u7684\u903b\u8f91\u8bed\u8a00\u66ff\u4ee3\u81ea\u7136\u8bed\u8a00\uff0c\u5e76\u4e14\u53ef\u4ee5\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u4fdd\u6301\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08SLMs\uff09\u7684\u6027\u80fd\u3002\u8fd9\u4e9b\u7ed3\u679c\u6709\u671b\u4e3a\u8fdb\u4e00\u6b65\u4f18\u5316SLMs\u5728\u672c\u4f53\u5de5\u7a0b\u4e2d\u7684\u4f5c\u7528\u63d0\u4f9b\u6307\u5bfc\u3002"}}
{"id": "2509.09911", "categories": ["cs.CV", "cs.AI", "68T07 (Primary)"], "pdf": "https://arxiv.org/pdf/2509.09911", "abs": "https://arxiv.org/abs/2509.09911", "authors": ["Barkin Buyukcakir", "Jannick De Tobel", "Patrick Thevissen", "Dirk Vandermeulen", "Peter Claes"], "title": "An Autoencoder and Vision Transformer-based Interpretability Analysis of the Differences in Automated Staging of Second and Third Molars", "comment": "21 pages, 11 figures, Scientific Reports", "summary": "The practical adoption of deep learning in high-stakes forensic applications,\nsuch as dental age estimation, is often limited by the 'black box' nature of\nthe models. This study introduces a framework designed to enhance both\nperformance and transparency in this context. We use a notable performance\ndisparity in the automated staging of mandibular second (tooth 37) and third\n(tooth 38) molars as a case study. The proposed framework, which combines a\nconvolutional autoencoder (AE) with a Vision Transformer (ViT), improves\nclassification accuracy for both teeth over a baseline ViT, increasing from\n0.712 to 0.815 for tooth 37 and from 0.462 to 0.543 for tooth 38. Beyond\nimproving performance, the framework provides multi-faceted diagnostic\ninsights. Analysis of the AE's latent space metrics and image reconstructions\nindicates that the remaining performance gap is data-centric, suggesting high\nintra-class morphological variability in the tooth 38 dataset is a primary\nlimiting factor. This work highlights the insufficiency of relying on a single\nmode of interpretability, such as attention maps, which can appear anatomically\nplausible yet fail to identify underlying data issues. By offering a\nmethodology that both enhances accuracy and provides evidence for why a model\nmay be uncertain, this framework serves as a more robust tool to support expert\ndecision-making in forensic age estimation.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5377\u79ef\u81ea\u7f16\u7801\u5668\uff08AE\uff09\u548c\u89c6\u89c9Transformer\uff08ViT\uff09\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u9ad8\u7259\u79d1\u5e74\u9f84\u4f30\u8ba1\u7684\u6027\u80fd\u548c\u900f\u660e\u5ea6\uff0c\u89e3\u51b3\u4e86\u6df1\u5ea6\u5b66\u4e60\u5728\u6cd5\u533b\u5e94\u7528\u4e2d\u7684\u2018\u9ed1\u7bb1\u2019\u95ee\u9898\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u5728\u6cd5\u533b\u7259\u79d1\u5e74\u9f84\u4f30\u8ba1\u7b49\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\u53d7\u5230\u2018\u9ed1\u7bb1\u2019\u95ee\u9898\u7684\u9650\u5236\uff0c\u9700\u8981\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u548c\u900f\u660e\u5ea6\u3002", "method": "\u7ed3\u5408\u5377\u79ef\u81ea\u7f16\u7801\u5668\uff08AE\uff09\u548c\u89c6\u89c9Transformer\uff08ViT\uff09\u6784\u5efa\u6846\u67b6\uff0c\u5e76\u5206\u6790AE\u7684\u6f5c\u5728\u7a7a\u95f4\u6307\u6807\u548c\u56fe\u50cf\u91cd\u5efa\uff0c\u4ee5\u8bca\u65ad\u6027\u80fd\u5dee\u8ddd\u7684\u539f\u56e0\u3002", "result": "\u8be5\u6846\u67b6\u5c06\u7259\u9f7f37\u7684\u5206\u7c7b\u51c6\u786e\u7387\u4ece0.712\u63d0\u9ad8\u52300.815\uff0c\u5c06\u7259\u9f7f38\u7684\u51c6\u786e\u7387\u4ece0.462\u63d0\u9ad8\u52300.543\u3002\u5206\u6790\u8868\u660e\uff0c\u7259\u9f7f38\u6570\u636e\u96c6\u7684\u7c7b\u5185\u5f62\u6001\u53d8\u5f02\u6027\u662f\u9650\u5236\u6027\u80fd\u7684\u4e3b\u8981\u56e0\u7d20\u3002", "conclusion": "\u5355\u4e00\u7684\u53ef\u89e3\u91ca\u6027\u6a21\u5f0f\uff08\u5982\u6ce8\u610f\u529b\u56fe\uff09\u4e0d\u8db3\u4ee5\u8bc6\u522b\u6f5c\u5728\u7684\u6570\u636e\u95ee\u9898\u3002\u672c\u7814\u7a76\u63d0\u51fa\u7684\u6846\u67b6\u5728\u63d0\u9ad8\u51c6\u786e\u6027\u7684\u540c\u65f6\uff0c\u63d0\u4f9b\u4e86\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u7684\u8bc1\u636e\uff0c\u4e3a\u6cd5\u533b\u5e74\u9f84\u4f30\u8ba1\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u5de5\u5177\u3002"}}
{"id": "2509.10405", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.10405", "abs": "https://arxiv.org/abs/2509.10405", "authors": ["Nicholas Carlotti", "Mirko Nava", "Alessandro Giusti"], "title": "Self-supervised Learning Of Visual Pose Estimation Without Pose Labels By Classifying LED States", "comment": "accepted at CoRL 2025", "summary": "We introduce a model for monocular RGB relative pose estimation of a ground\nrobot that trains from scratch without pose labels nor prior knowledge about\nthe robot's shape or appearance. At training time, we assume: (i) a robot\nfitted with multiple LEDs, whose states are independent and known at each\nframe; (ii) knowledge of the approximate viewing direction of each LED; and\n(iii) availability of a calibration image with a known target distance, to\naddress the ambiguity of monocular depth estimation. Training data is collected\nby a pair of robots moving randomly without needing external infrastructure or\nhuman supervision. Our model trains on the task of predicting from an image the\nstate of each LED on the robot. In doing so, it learns to predict the position\nof the robot in the image, its distance, and its relative bearing. At inference\ntime, the state of the LEDs is unknown, can be arbitrary, and does not affect\nthe pose estimation performance. Quantitative experiments indicate that our\napproach: is competitive with SoA approaches that require supervision from pose\nlabels or a CAD model of the robot; generalizes to different domains; and\nhandles multi-robot pose estimation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4ece\u5934\u5f00\u59cb\u8bad\u7ec3\u7684\u5355\u76eeRGB\u76f8\u5bf9\u59ff\u6001\u4f30\u8ba1\u6a21\u578b\uff0c\u7528\u4e8e\u5730\u9762\u673a\u5668\u4eba\uff0c\u65e0\u9700\u59ff\u6001\u6807\u7b7e\u6216\u673a\u5668\u4eba\u5f62\u72b6/\u5916\u89c2\u7684\u5148\u9a8c\u77e5\u8bc6\u3002\u8bad\u7ec3\u6570\u636e\u6765\u81ea\u4e24\u4e2a\u673a\u5668\u4eba\u968f\u673a\u79fb\u52a8\uff0c\u4e0d\u9700\u8981\u5916\u90e8\u57fa\u7840\u8bbe\u65bd\u6216\u4eba\u5de5\u76d1\u7763\u3002", "motivation": "\u9700\u8981\u4e00\u79cd\u65e0\u9700\u59ff\u6001\u6807\u7b7e\u6216\u673a\u5668\u4eba\u5f62\u72b6/\u5916\u89c2\u5148\u9a8c\u77e5\u8bc6\u7684\u5355\u76eeRGB\u76f8\u5bf9\u59ff\u6001\u4f30\u8ba1\u65b9\u6cd5\u3002", "method": "\u5728\u8bad\u7ec3\u65f6\uff0c\u5047\u8bbe\u673a\u5668\u4eba\u88c5\u6709\u591a\u4e2aLED\uff0c\u5176\u72b6\u6001\u5728\u6bcf\u5e27\u4e2d\u662f\u5df2\u77e5\u7684\u4e14\u72ec\u7acb\u7684\uff1b\u77e5\u9053\u6bcf\u4e2aLED\u7684\u5927\u81f4\u89c6\u89d2\uff1b\u5e76\u63d0\u4f9b\u4e00\u5f20\u5177\u6709\u5df2\u77e5\u76ee\u6807\u8ddd\u79bb\u7684\u6821\u51c6\u56fe\u50cf\uff0c\u4ee5\u89e3\u51b3\u5355\u76ee\u6df1\u5ea6\u4f30\u8ba1\u7684\u6a21\u7cca\u6027\u3002\u6a21\u578b\u901a\u8fc7\u9884\u6d4b\u56fe\u50cf\u4e2d\u6bcf\u4e2aLED\u7684\u72b6\u6001\u6765\u5b66\u4e60\u673a\u5668\u4eba\u56fe\u50cf\u4e2d\u7684\u4f4d\u7f6e\u3001\u8ddd\u79bb\u548c\u76f8\u5bf9\u65b9\u4f4d\u3002", "result": "\u8be5\u6a21\u578b\u5728\u63a8\u7406\u65f6\uff0cLED\u72b6\u6001\u672a\u77e5\u4e14\u4efb\u610f\uff0c\u4e0d\u5f71\u54cd\u59ff\u6001\u4f30\u8ba1\u6027\u80fd\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4e0e\u9700\u8981\u59ff\u6001\u6807\u7b7e\u6216CAD\u6a21\u578b\u7684\u76d1\u7763\u65b9\u6cd5\u76f8\u6bd4\u65f6\u5177\u6709\u7ade\u4e89\u529b\uff0c\u5e76\u4e14\u80fd\u591f\u6cdb\u5316\u5230\u4e0d\u540c\u9886\u57df\uff0c\u5e76\u5904\u7406\u591a\u673a\u5668\u4eba\u59ff\u6001\u4f30\u8ba1\u3002", "conclusion": "\u8be5\u6a21\u578b\u80fd\u591f\u6709\u6548\u5730\u8fdb\u884c\u5355\u76eeRGB\u76f8\u5bf9\u59ff\u6001\u4f30\u8ba1\uff0c\u5e76\u4e14\u5728\u65e0\u9700\u989d\u5916\u76d1\u7763\u4fe1\u606f\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u51fa\u826f\u597d\u7684\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2509.10171", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2509.10171", "abs": "https://arxiv.org/abs/2509.10171", "authors": ["Filippus S. Roux"], "title": "Evolution of moments in atmospheric scintillation", "comment": "10 pages, 1 figure", "summary": "Evolution equations for the moments of a photonic quantum state propagating\nthrough atmospheric turbulence are derived. These evolution equations are\nobtain from an evolution equation for the characteristic functional of the\nstate, incorporating all spatiotemporal degrees of freedom. The measured\nquantities, such as the intensity or photon distribution, of the evolving state\ncan be expressed in terms of such moments without having to know the exact\nfinal state. The case of an initial coherent state is considered as an example.", "AI": {"tldr": "\u5927\u6c14\u6e4d\u6d41\u4e2d\u5149\u5b50\u91cf\u5b50\u6001\u7684\u77e9\u6f14\u5316\u65b9\u7a0b\u88ab\u63a8\u5bfc\u51fa\u6765\uff0c\u8be5\u65b9\u7a0b\u6e90\u81ea\u4e8e\u5305\u542b\u6240\u6709\u65f6\u7a7a\u81ea\u7531\u5ea6\u7684\u6001\u7279\u5f81\u6cdb\u51fd\u7684\u6f14\u5316\u65b9\u7a0b\u3002", "motivation": "\u63a8\u5bfc\u5149\u5b50\u91cf\u5b50\u6001\u5728\u4f20\u64ad\u901a\u8fc7\u5927\u6c14\u6e4d\u6d41\u65f6\u7684\u77e9\u6f14\u5316\u65b9\u7a0b\uff0c\u4ee5\u7b80\u5316\u5bf9\u6d4b\u91cf\u91cf\u7684\u5206\u6790\u3002", "method": "\u4ece\u6001\u7279\u5f81\u6cdb\u51fd\u7684\u6f14\u5316\u65b9\u7a0b\u51fa\u53d1\uff0c\u63a8\u5bfc\u51fa\u5149\u5b50\u91cf\u5b50\u6001\u77e9\u7684\u6f14\u5316\u65b9\u7a0b\uff0c\u5e76\u8003\u8651\u4e86\u521d\u59cb\u76f8\u5e72\u6001\u7684\u60c5\u51b5\u3002", "result": "\u5f97\u5230\u4e86\u5149\u5b50\u91cf\u5b50\u6001\u77e9\u7684\u6f14\u5316\u65b9\u7a0b\uff0c\u5e76\u5c55\u793a\u4e86\u5982\u4f55\u7528\u8fd9\u4e9b\u77e9\u6765\u8868\u793a\u6d4b\u91cf\u91cf\uff0c\u800c\u65e0\u9700\u77e5\u9053\u7cbe\u786e\u7684\u6700\u7ec8\u6001\u3002", "conclusion": "\u63a8\u5bfc\u51fa\u7684\u77e9\u6f14\u5316\u65b9\u7a0b\u4e3a\u5206\u6790\u5149\u5b50\u91cf\u5b50\u6001\u5728\u6e4d\u6d41\u4e2d\u7684\u4f20\u64ad\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5de5\u5177\u3002"}}
{"id": "2509.09726", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.09726", "abs": "https://arxiv.org/abs/2509.09726", "authors": ["Seiji Hattori", "Takuya Matsuzaki", "Makoto Fujiwara"], "title": "Natural Language Translation of Formal Proofs through Informalization of Proof Steps and Recursive Summarization along Proof Structure", "comment": "Submitted to INLG 2025 (accepted)", "summary": "This paper proposes a natural language translation method for\nmachine-verifiable formal proofs that leverages the informalization\n(verbalization of formal language proof steps) and summarization capabilities\nof LLMs. For evaluation, it was applied to formal proof data created in\naccordance with natural language proofs taken from an undergraduate-level\ntextbook, and the quality of the generated natural language proofs was analyzed\nin comparison with the original natural language proofs. Furthermore, we will\ndemonstrate that this method can output highly readable and accurate natural\nlanguage proofs by applying it to existing formal proof library of the Lean\nproof assistant.", "AI": {"tldr": "LLM\u53ef\u7528\u4e8e\u5c06\u5f62\u5f0f\u5316\u8bc1\u660e\u8f6c\u6362\u4e3a\u81ea\u7136\u8bed\u8a00\uff0c\u5e76\u63d0\u9ad8\u4e86\u53ef\u8bfb\u6027\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u5229\u7528LLM\u7684\u975e\u5f62\u5f0f\u5316\u548c\u6458\u8981\u80fd\u529b\uff0c\u5c06\u673a\u5668\u53ef\u9a8c\u8bc1\u7684\u5f62\u5f0f\u5316\u8bc1\u660e\u8f6c\u5316\u4e3a\u81ea\u7136\u8bed\u8a00\u3002", "method": "\u5c06LLM\u5e94\u7528\u4e8e\u5f62\u5f0f\u5316\u8bc1\u660e\u6570\u636e\uff0c\u5e76\u4e0e\u539f\u59cb\u7684\u81ea\u7136\u8bed\u8a00\u8bc1\u660e\u8fdb\u884c\u6bd4\u8f83\uff0c\u4ee5\u8bc4\u4f30\u751f\u6210\u8d28\u91cf\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u751f\u6210\u9ad8\u5ea6\u53ef\u8bfb\u4e14\u51c6\u786e\u7684\u81ea\u7136\u8bed\u8a00\u8bc1\u660e\uff0c\u5e76\u5df2\u6210\u529f\u5e94\u7528\u4e8eLean\u8bc1\u660e\u52a9\u624b\u3002", "conclusion": "LLM\u5728\u5c06\u5f62\u5f0f\u5316\u8bc1\u660e\u8f6c\u6362\u4e3a\u81ea\u7136\u8bed\u8a00\u65b9\u9762\u663e\u793a\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u53ef\u7528\u4e8e\u63d0\u9ad8\u8bc1\u660e\u7684\u53ef\u7406\u89e3\u6027\u548c\u53ef\u7528\u6027\u3002"}}
{"id": "2509.09991", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.09991", "abs": "https://arxiv.org/abs/2509.09991", "authors": ["Amandip Sangha"], "title": "Data-Driven Energy Estimation for Virtual Servers Using Combined System Metrics and Machine Learning", "comment": null, "summary": "This paper presents a machine learning-based approach to estimate the energy\nconsumption of virtual servers without access to physical power measurement\ninterfaces. Using resource utilization metrics collected from guest virtual\nmachines, we train a Gradient Boosting Regressor to predict energy consumption\nmeasured via RAPL on the host. We demonstrate, for the first time, guest-only\nresource-based energy estimation without privileged host access with\nexperiments across diverse workloads, achieving high predictive accuracy and\nvariance explained ($0.90 \\leq R^2 \\leq 0.97$), indicating the feasibility of\nguest-side energy estimation. This approach can enable energy-aware scheduling,\ncost optimization and physical host independent energy estimates in virtualized\nenvironments. Our approach addresses a critical gap in virtualized environments\n(e.g. cloud) where direct energy measurement is infeasible.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u4ec5\u5229\u7528\u865a\u62df\u673a\uff08VM\uff09\u7684\u8d44\u6e90\u5229\u7528\u7387\u6307\u6807\uff0c\u5728\u65e0\u6cd5\u8bbf\u95ee\u7269\u7406\u6d4b\u91cf\u63a5\u53e3\u7684\u60c5\u51b5\u4e0b\uff0c\u9884\u6d4b\u865a\u62df\u670d\u52a1\u5668\u7684\u80fd\u8017\u3002", "motivation": "\u5728\u865a\u62df\u5316\u73af\u5883\u4e2d\uff08\u5982\u4e91\uff09\uff0c\u76f4\u63a5\u8fdb\u884c\u80fd\u8017\u6d4b\u91cf\u901a\u5e38\u662f\u4e0d\u53ef\u884c\u7684\u3002\u7136\u800c\uff0c\u80fd\u8017\u611f\u77e5\u8c03\u5ea6\u3001\u6210\u672c\u4f18\u5316\u548c\u72ec\u7acb\u4e8e\u7269\u7406\u4e3b\u673a\u8fdb\u884c\u80fd\u8017\u4f30\u7b97\u7684\u9700\u6c42\u65e5\u76ca\u589e\u957f\u3002\u56e0\u6b64\uff0c\u5728\u7f3a\u4e4f\u4e3b\u673a\u7279\u6743\u8bbf\u95ee\u7684\u60c5\u51b5\u4e0b\uff0c\u4ec5\u4ece\u865a\u62df\u673a\u5c42\u9762\u8fdb\u884c\u80fd\u8017\u4f30\u7b97\u662f\u4e00\u4e2a\u5173\u952e\u7684\u6311\u6218\u3002", "method": "\u5229\u7528\u4ece\u5ba2\u6237\u865a\u62df\u673a\u6536\u96c6\u7684\u8d44\u6e90\u5229\u7528\u7387\u6307\u6807\uff0c\u8bad\u7ec3\u68af\u5ea6\u63d0\u5347\u56de\u5f52\u6a21\u578b\uff08Gradient Boosting Regressor\uff09\u6765\u9884\u6d4b\u4e3b\u673a\u901a\u8fc7RAPL\u6d4b\u91cf\u7684\u80fd\u8017\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u79cd\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u5b9e\u73b0\u4e86\u9ad8\u9884\u6d4b\u7cbe\u5ea6\u548c\u9ad8\u89e3\u91ca\u65b9\u5dee\uff08$0.90 \\leq R^2 \\leq 0.97$\uff09\uff0c\u8bc1\u660e\u4e86\u4ec5\u4ece\u5ba2\u6237\u673a\u5c42\u9762\u8fdb\u884c\u80fd\u8017\u4f30\u7b97\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u9996\u6b21\u5b9e\u73b0\u4e86\u5728\u65e0\u7279\u6743\u4e3b\u673a\u8bbf\u95ee\u7684\u60c5\u51b5\u4e0b\uff0c\u4ec5\u57fa\u4e8e\u5ba2\u6237\u673a\u8d44\u6e90\u8fdb\u884c\u80fd\u8017\u4f30\u7b97\uff0c\u4e3a\u865a\u62df\u5316\u73af\u5883\u4e2d\u7684\u80fd\u8017\u7ba1\u7406\u63d0\u4f9b\u4e86\u65b0\u7684\u9014\u5f84\u3002"}}
{"id": "2509.10297", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10297", "abs": "https://arxiv.org/abs/2509.10297", "authors": ["Eoin O'Doherty", "Nicole Weinrauch", "Andrew Talone", "Uri Klempner", "Xiaoyuan Yi", "Xing Xie", "Yi Zeng"], "title": "The Morality of Probability: How Implicit Moral Biases in LLMs May Shape the Future of Human-AI Symbiosis", "comment": "Work in progress", "summary": "Artificial intelligence (AI) is advancing at a pace that raises urgent\nquestions about how to align machine decision-making with human moral values.\nThis working paper investigates how leading AI systems prioritize moral\noutcomes and what this reveals about the prospects for human-AI symbiosis. We\naddress two central questions: (1) What moral values do state-of-the-art large\nlanguage models (LLMs) implicitly favour when confronted with dilemmas? (2) How\ndo differences in model architecture, cultural origin, and explainability\naffect these moral preferences? To explore these questions, we conduct a\nquantitative experiment with six LLMs, ranking and scoring outcomes across 18\ndilemmas representing five moral frameworks. Our findings uncover strikingly\nconsistent value biases. Across all models, Care and Virtue values outcomes\nwere rated most moral, while libertarian choices were consistently penalized.\nReasoning-enabled models exhibited greater sensitivity to context and provided\nricher explanations, whereas non-reasoning models produced more uniform but\nopaque judgments. This research makes three contributions: (i) Empirically, it\ndelivers a large-scale comparison of moral reasoning across culturally distinct\nLLMs; (ii) Theoretically, it links probabilistic model behaviour with\nunderlying value encodings; (iii) Practically, it highlights the need for\nexplainability and cultural awareness as critical design principles to guide AI\ntoward a transparent, aligned, and symbiotic future.", "AI": {"tldr": "AI\u7cfb\u7edf\u5728\u9762\u4e34\u9053\u5fb7\u56f0\u5883\u65f6\uff0c\u666e\u904d\u504f\u597d\u201c\u4ec1\u6148\u201d\u548c\u201c\u7f8e\u5fb7\u201d\u7684\u4ef7\u503c\uff0c\u800c\u201c\u81ea\u7531\u610f\u5fd7\u201d\u7684\u9009\u62e9\u5219\u53d7\u5230\u60e9\u7f5a\u3002\u4e0d\u540c\u7684\u6a21\u578b\u67b6\u6784\u3001\u6587\u5316\u80cc\u666f\u548c\u53ef\u89e3\u91ca\u6027\u4f1a\u5f71\u54cd\u5176\u9053\u5fb7\u504f\u597d\u3002", "motivation": "AI \u7684\u5feb\u901f\u53d1\u5c55\u5f15\u53d1\u4e86\u5982\u4f55\u4f7f\u5176\u51b3\u7b56\u7b26\u5408\u4eba\u7c7b\u9053\u5fb7\u4ef7\u503c\u89c2\u7684\u7d27\u8feb\u95ee\u9898\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7a76\u9886\u5148\u7684 AI \u7cfb\u7edf\u5982\u4f55\u4f18\u5148\u8003\u8651\u9053\u5fb7\u7ed3\u679c\uff0c\u4ee5\u53ca\u8fd9\u5bf9\u4e8e\u4eba\u673a\u5171\u751f\u7684\u524d\u666f\u63ed\u793a\u4e86\u4ec0\u4e48\u3002", "method": "\u901a\u8fc7\u4e00\u9879\u5305\u542b\u516d\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u5b9a\u91cf\u5b9e\u9a8c\uff0c\u5728\u4ee3\u8868\u4e94\u79cd\u9053\u5fb7\u6846\u67b6\u7684 18 \u79cd\u56f0\u5883\u4e2d\u5bf9\u7ed3\u679c\u8fdb\u884c\u6392\u540d\u548c\u8bc4\u5206\u3002", "result": "\u6240\u6709\u6a21\u578b\u90fd\u8868\u73b0\u51fa\u4e00\u81f4\u7684\u4ef7\u503c\u504f\u89c1\uff0c\u666e\u904d\u9ad8\u5ea6\u8bc4\u4ef7\u201c\u4ec1\u6148\u201d\u548c\u201c\u7f8e\u5fb7\u201d\u7684\u4ef7\u503c\uff0c\u5e76\u60e9\u7f5a\u201c\u81ea\u7531\u610f\u5fd7\u201d\u7684\u9009\u62e9\u3002\u80fd\u591f\u8fdb\u884c\u63a8\u7406\u7684\u6a21\u578b\u5bf9\u4e0a\u4e0b\u6587\u66f4\u654f\u611f\uff0c\u89e3\u91ca\u66f4\u4e30\u5bcc\uff0c\u800c\u975e\u63a8\u7406\u6a21\u578b\u5219\u4ea7\u751f\u66f4\u4e00\u81f4\u4f46\u66f4\u4e0d\u900f\u660e\u7684\u5224\u65ad\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u53ef\u89e3\u91ca\u6027\u548c\u6587\u5316\u610f\u8bc6\u4f5c\u4e3a\u6307\u5bfc AI \u5b9e\u73b0\u900f\u660e\u3001\u5bf9\u9f50\u548c\u5171\u751f\u672a\u6765\u7684\u5173\u952e\u8bbe\u8ba1\u539f\u5219\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2509.09935", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.09935", "abs": "https://arxiv.org/abs/2509.09935", "authors": ["Chirayu Agrawal", "Snehasis Mukherjee"], "title": "SCoDA: Self-supervised Continual Domain Adaptation", "comment": "Submitted to ICVGIP 2025", "summary": "Source-Free Domain Adaptation (SFDA) addresses the challenge of adapting a\nmodel to a target domain without access to the data of the source domain.\nPrevailing methods typically start with a source model pre-trained with full\nsupervision and distill the knowledge by aligning instance-level features.\nHowever, these approaches, relying on cosine similarity over L2-normalized\nfeature vectors, inadvertently discard crucial geometric information about the\nlatent manifold of the source model. We introduce Self-supervised Continual\nDomain Adaptation (SCoDA) to address these limitations. We make two key\ndepartures from standard practice: first, we avoid the reliance on supervised\npre-training by initializing the proposed framework with a teacher model\npre-trained entirely via self-supervision (SSL). Second, we adapt the principle\nof geometric manifold alignment to the SFDA setting. The student is trained\nwith a composite objective combining instance-level feature matching with a\nSpace Similarity Loss. To combat catastrophic forgetting, the teacher's\nparameters are updated via an Exponential Moving Average (EMA) of the student's\nparameters. Extensive experiments on benchmark datasets demonstrate that SCoDA\nsignificantly outperforms state-of-the-art SFDA methods.", "AI": {"tldr": "SFDA\u901a\u5e38\u4f9d\u8d56\u4e8e\u6709\u76d1\u7763\u7684\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u5bf9\u9f50\u5b9e\u4f8b\u7ea7\u7279\u5f81\u6765\u84b8\u998f\u77e5\u8bc6\uff0c\u4f46\u8fd9\u4f1a\u4e22\u5931\u91cd\u8981\u7684\u51e0\u4f55\u4fe1\u606f\u3002SCoDA\u901a\u8fc7\u4f7f\u7528\u81ea\u76d1\u7763\u5b66\u4e60\uff08SSL\uff09\u521d\u59cb\u5316\u6559\u5e08\u6a21\u578b\uff0c\u5e76\u5f15\u5165\u7a7a\u95f4\u76f8\u4f3c\u6027\u635f\u5931\u6765\u5bf9\u9f50\u51e0\u4f55\u6d41\u5f62\uff0c\u89e3\u51b3\u4e86\u8fd9\u4e9b\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684SFDA\u65b9\u6cd5\u5728\u5bf9\u9f50\u5b9e\u4f8b\u7ea7\u7279\u5f81\u65f6\u4f1a\u4e22\u5931\u5173\u952e\u7684\u51e0\u4f55\u4fe1\u606f\u3002", "method": "SCoDA\u91c7\u7528\u81ea\u76d1\u7763\u5b66\u4e60\uff08SSL\uff09\u8fdb\u884c\u521d\u59cb\u5316\uff0c\u5e76\u7ed3\u5408\u5b9e\u4f8b\u7ea7\u7279\u5f81\u5339\u914d\u548c\u7a7a\u95f4\u76f8\u4f3c\u6027\u635f\u5931\u8fdb\u884c\u8bad\u7ec3\u3002\u6559\u5e08\u6a21\u578b\u901a\u8fc7\u6307\u6570\u79fb\u52a8\u5e73\u5747\uff08EMA\uff09\u66f4\u65b0\u4ee5\u9632\u6b62\u707e\u96be\u6027\u9057\u5fd8\u3002", "result": "SCoDA\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u663e\u8457\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684SFDA\u65b9\u6cd5\u3002", "conclusion": "SCoDA\u901a\u8fc7\u81ea\u76d1\u7763\u521d\u59cb\u5316\u548c\u51e0\u4f55\u6d41\u5f62\u5bf9\u9f50\uff0c\u5728SFDA\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86SOTA\u6027\u80fd\u3002"}}
{"id": "2509.10416", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.10416", "abs": "https://arxiv.org/abs/2509.10416", "authors": ["Ze Fu", "Pinhao Song", "Yutong Hu", "Renaud Detry"], "title": "TASC: Task-Aware Shared Control for Teleoperated Manipulation", "comment": null, "summary": "We present TASC, a Task-Aware Shared Control framework for teleoperated\nmanipulation that infers task-level user intent and provides assistance\nthroughout the task. To support everyday tasks without predefined knowledge,\nTASC constructs an open-vocabulary interaction graph from visual input to\nrepresent functional object relationships, and infers user intent accordingly.\nA shared control policy then provides rotation assistance during both grasping\nand object interaction, guided by spatial constraints predicted by a\nvision-language model. Our method addresses two key challenges in\ngeneral-purpose, long-horizon shared control: (1) understanding and inferring\ntask-level user intent, and (2) generalizing assistance across diverse objects\nand tasks. Experiments in both simulation and the real world demonstrate that\nTASC improves task efficiency and reduces user input effort compared to prior\nmethods. To the best of our knowledge, this is the first shared control\nframework that supports everyday manipulation tasks with zero-shot\ngeneralization. The code that supports our experiments is publicly available at\nhttps://github.com/fitz0401/tasc.", "AI": {"tldr": "TASC\u662f\u4e00\u4e2a\u4efb\u52a1\u611f\u77e5\u5171\u4eab\u63a7\u5236\u6846\u67b6\uff0c\u901a\u8fc7\u89c6\u89c9\u8f93\u5165\u6784\u5efa\u4ea4\u4e92\u56fe\u6765\u7406\u89e3\u7528\u6237\u610f\u56fe\uff0c\u5e76\u63d0\u4f9b\u65cb\u8f6c\u8f85\u52a9\uff0c\u4ee5\u5e94\u5bf9\u65e5\u5e38\u64cd\u4f5c\u4efb\u52a1\u7684\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u96f6\u6837\u672c\u6cdb\u5316\u3002", "motivation": "\u4e3a\u652f\u6301\u65e0\u9700\u9884\u5b9a\u4e49\u77e5\u8bc6\u7684\u65e5\u5e38\u4efb\u52a1\uff0cTASC\u65e8\u5728\u89e3\u51b3\u901a\u7528\u3001\u957f\u65f6\u5e8f\u5171\u4eab\u63a7\u5236\u4e2d\u7684\u4e24\u5927\u6311\u6218\uff1a\u7406\u89e3\u548c\u63a8\u65ad\u4efb\u52a1\u7ea7\u7528\u6237\u610f\u56fe\uff0c\u4ee5\u53ca\u8de8\u4e0d\u540c\u7269\u4f53\u548c\u4efb\u52a1\u7684\u6cdb\u5316\u8f85\u52a9\u3002", "method": "TASC\u6784\u5efa\u4e86\u4e00\u4e2a\u5f00\u653e\u8bcd\u6c47\u7684\u4ea4\u4e92\u56fe\uff0c\u4ee5\u8868\u793a\u529f\u80fd\u6027\u7269\u4f53\u5173\u7cfb\uff0c\u5e76\u636e\u6b64\u63a8\u65ad\u7528\u6237\u610f\u56fe\u3002\u7136\u540e\uff0c\u4e00\u4e2a\u5171\u4eab\u63a7\u5236\u7b56\u7565\u5728\u6293\u53d6\u548c\u7269\u4f53\u4ea4\u4e92\u8fc7\u7a0b\u4e2d\u63d0\u4f9b\u65cb\u8f6c\u8f85\u52a9\uff0c\u8be5\u8f85\u52a9\u7531\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u9884\u6d4b\u7684\u7a7a\u95f4\u7ea6\u675f\u6307\u5bfc\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0cTASC\u5728\u6a21\u62df\u548c\u771f\u5b9e\u4e16\u754c\u4e2d\u5747\u63d0\u9ad8\u4e86\u4efb\u52a1\u6548\u7387\u5e76\u51cf\u5c11\u4e86\u7528\u6237\u8f93\u5165\u7684\u5de5\u4f5c\u91cf\u3002", "conclusion": "TASC\u662f\u9996\u4e2a\u652f\u6301\u65e5\u5e38\u64cd\u4f5c\u4efb\u52a1\u5e76\u5177\u5907\u96f6\u6837\u672c\u6cdb\u5316\u80fd\u529b\u7684\u5171\u4eab\u63a7\u5236\u6846\u67b6\u3002"}}
{"id": "2509.10174", "categories": ["quant-ph", "cs.CR"], "pdf": "https://arxiv.org/pdf/2509.10174", "abs": "https://arxiv.org/abs/2509.10174", "authors": ["Randy Kuang"], "title": "Statistical Quantum Mechanics of the Random Permutation Sorting System (RPSS): A Self-Stabilizing True Uniform RNG", "comment": null, "summary": "We present the Random Permutation Sorting System (RPSS), a novel framework\nfor true uniform randomness generation grounded in statistical quantum\nmechanics. RPSS is built on a pair of conjugate observables, the permutation\ncount and the elapsed sorting time, whose heavy-tailed raw distributions\nsynchronously converge to uniformity through modular reduction. This\nmathematically proven convergence establishes RPSS as a True Uniform Random\nNumber Generator (TURNG). A practical implementation, QPP-RNG, demonstrates how\nintrinsic system jitter, arising from microarchitectural noise, memory latency,\nand scheduling dynamics, interacts with combinatorial complexity to yield a\ncompact, self-stabilizing entropy source. Empirical validation under the NIST\nSP 800-90B framework confirms rapid entropy convergence and statistically\nuniform outputs. RPSS thus defines a new class of quantum-inspired entropy\nengines, where randomness is simultaneously harvested from unpredictable system\njitter and amplified by combinatorial processes, offering a robust,\nplatform-independent alternative to conventional entropy sources.", "AI": {"tldr": "RPSS\u662f\u4e00\u4e2a\u57fa\u4e8e\u91cf\u5b50\u529b\u5b66\u7684\u65b0\u578b\u771f\u968f\u673a\u6570\u751f\u6210\u5668\uff0c\u5229\u7528\u6392\u5217\u8ba1\u6570\u548c\u6392\u5e8f\u65f6\u95f4\u7684\u5206\u5e03\u6536\u655b\u5230\u5747\u5300\u6027\u3002", "motivation": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u7edf\u8ba1\u91cf\u5b50\u529b\u5b66\u7684\u65b0\u578b\u771f\u968f\u673a\u6570\u751f\u6210\u6846\u67b6\uff08RPSS\uff09\uff0c\u65e8\u5728\u5b9e\u73b0\u771f\u6b63\u7684\u7edf\u4e00\u968f\u673a\u6570\u751f\u6210\u3002", "method": "RPSS\u57fa\u4e8e\u4e00\u5bf9\u5171\u8f6d\u53ef\u89c2\u6d4b\u91cf\u2014\u2014\u6392\u5217\u8ba1\u6570\u548c\u5df2\u6392\u5e8f\u65f6\u95f4\uff0c\u901a\u8fc7\u6a21\u7ea6\u7b80\u540c\u6b65\u6536\u655b\u5230\u5747\u5300\u6027\u3002\u5229\u7528\u5fae\u67b6\u6784\u566a\u58f0\u3001\u5185\u5b58\u5ef6\u8fdf\u548c\u8c03\u5ea6\u52a8\u6001\u7b49\u7cfb\u7edf\u6296\u52a8\u4e0e\u7ec4\u5408\u590d\u6742\u6027\u76f8\u4e92\u4f5c\u7528\uff0c\u521b\u5efa\u4e86\u4e00\u4e2a\u7d27\u51d1\u7684\u3001\u81ea\u7a33\u5b9a\u7684\u71b5\u6e90\uff08QPP-RNG\uff09\u3002", "result": "NIST SP 800-90B\u6846\u67b6\u7684\u7ecf\u9a8c\u9a8c\u8bc1\u8bc1\u5b9e\u4e86RPSS\u71b5\u6536\u655b\u901f\u5ea6\u5feb\uff0c\u8f93\u51fa\u7edf\u8ba1\u5747\u5300\u3002", "conclusion": "RPSS\u5b9a\u4e49\u4e86\u4e00\u7c7b\u65b0\u7684\u91cf\u5b50\u542f\u53d1\u5f0f\u71b5\u5f15\u64ce\uff0c\u80fd\u591f\u4ece\u4e0d\u53ef\u9884\u6d4b\u7684\u7cfb\u7edf\u6296\u52a8\u4e2d\u6536\u83b7\u968f\u673a\u6027\uff0c\u5e76\u901a\u8fc7\u7ec4\u5408\u8fc7\u7a0b\u8fdb\u884c\u653e\u5927\uff0c\u4e3a\u4f20\u7edf\u71b5\u6e90\u63d0\u4f9b\u4e86\u4e00\u79cd\u5065\u58ee\u3001\u5e73\u53f0\u65e0\u5173\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2509.09727", "categories": ["cs.CL", "cs.CE"], "pdf": "https://arxiv.org/pdf/2509.09727", "abs": "https://arxiv.org/abs/2509.09727", "authors": ["Andy Zhu", "Yingjun Du"], "title": "A Role-Aware Multi-Agent Framework for Financial Education Question Answering with LLMs", "comment": "8 pages, 6 figures, Underreview", "summary": "Question answering (QA) plays a central role in financial education, yet\nexisting large language model (LLM) approaches often fail to capture the\nnuanced and specialized reasoning required for financial problem-solving. The\nfinancial domain demands multistep quantitative reasoning, familiarity with\ndomain-specific terminology, and comprehension of real-world scenarios. We\npresent a multi-agent framework that leverages role-based prompting to enhance\nperformance on domain-specific QA. Our framework comprises a Base Generator, an\nEvidence Retriever, and an Expert Reviewer agent that work in a single-pass\niteration to produce a refined answer. We evaluated our framework on a set of\n3,532 expert-designed finance education questions from Study.com, an online\nlearning platform. We leverage retrieval-augmented generation (RAG) for\ncontextual evidence from 6 finance textbooks and prompting strategies for a\ndomain-expert reviewer. Our experiments indicate that critique-based refinement\nimproves answer accuracy by 6.6-8.3% over zero-shot Chain-of-Thought baselines,\nwith the highest performance from Gemini-2.0-Flash. Furthermore, our method\nenables GPT-4o-mini to achieve performance comparable to the finance-tuned\nFinGPT-mt_Llama3-8B_LoRA. Our results show a cost-effective approach to\nenhancing financial QA and offer insights for further research in multi-agent\nfinancial LLM systems.", "AI": {"tldr": "LLM\u5728\u91d1\u878d\u6559\u80b2\u95ee\u7b54\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u89d2\u8272\u626e\u6f14\u63d0\u793a\uff08\u57fa\u7840\u751f\u6210\u5668\u3001\u8bc1\u636e\u68c0\u7d22\u5668\u3001\u4e13\u5bb6\u5ba1\u9605\u8005\uff09\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u63d0\u5347\u91d1\u878d\u95ee\u7b54\u80fd\u529b\uff0c\u57283532\u4e2a\u91d1\u878d\u6559\u80b2\u95ee\u9898\u4e0a\u9a8c\u8bc1\uff0c\u76f8\u6bd4\u57fa\u7ebf\u6a21\u578b\uff0c\u51c6\u786e\u7387\u63d0\u53476.6-8.3%\uff0cGemini-2.0-Flash\u8868\u73b0\u6700\u4f73\uff0cGPT-4o-mini\u6027\u80fd\u5ab2\u7f8eFinGPT\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u91d1\u878d\u6559\u80b2\u95ee\u7b54\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u65e0\u6cd5\u5904\u7406\u91d1\u878d\u9886\u57df\u590d\u6742\u3001\u4e13\u4e1a\u7684\u63a8\u7406\uff0c\u5982\u591a\u6b65\u91cf\u5316\u63a8\u7406\u3001\u4e13\u4e1a\u672f\u8bed\u7406\u89e3\u548c\u73b0\u5b9e\u573a\u666f\u5206\u6790\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5305\u542b\u57fa\u7840\u751f\u6210\u5668\u3001\u8bc1\u636e\u68c0\u7d22\u5668\u548c\u4e13\u5bb6\u5ba1\u9605\u8005\uff0c\u91c7\u7528\u5355\u7a0b\u8fed\u4ee3\u548c\u57fa\u4e8e\u89d2\u8272\u7684\u63d0\u793a\uff08role-based prompting\uff09\u6765\u4f18\u5316\u56de\u7b54\u3002\u6846\u67b6\u7ed3\u5408\u4e86\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6280\u672f\uff0c\u4ece6\u672c\u91d1\u878d\u6559\u79d1\u4e66\u4e2d\u68c0\u7d22\u8bc1\u636e\uff0c\u5e76\u8bbe\u8ba1\u4e86\u9886\u57df\u4e13\u5bb6\u5ba1\u9605\u8005\u63d0\u793a\u7b56\u7565\u3002", "result": "\u57283532\u4e2a\u91d1\u878d\u6559\u80b2\u95ee\u9898\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\uff0c\u4e0e\u96f6\u6837\u672c\u601d\u7ef4\u94fe\uff08zero-shot Chain-of-Thought\uff09\u57fa\u7ebf\u6a21\u578b\u76f8\u6bd4\uff0c\u57fa\u4e8e\u6279\u8bc4\u7684\u6539\u8fdb\u5c06\u7b54\u6848\u51c6\u786e\u7387\u63d0\u9ad8\u4e866.6-8.3%\u3002\u5176\u4e2d\uff0cGemini-2.0-Flash\u53d6\u5f97\u4e86\u6700\u4f73\u6027\u80fd\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u4f7fGPT-4o-mini\u7684\u6027\u80fd\u4e0e\u7ecf\u8fc7\u91d1\u878d\u9886\u57df\u5fae\u8c03\u7684FinGPT-mt_Llama3-8B_LoRA\u76f8\u5f53\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ecf\u6d4e\u9ad8\u6548\u7684\u65b9\u6cd5\u6765\u6539\u8fdb\u91d1\u878d\u95ee\u7b54\uff0c\u5e76\u4e3a\u672a\u6765\u5728\u591a\u667a\u80fd\u4f53\u91d1\u878dLLM\u7cfb\u7edf\u65b9\u9762\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2509.10000", "categories": ["cs.LG", "cond-mat.other"], "pdf": "https://arxiv.org/pdf/2509.10000", "abs": "https://arxiv.org/abs/2509.10000", "authors": ["Tilen Cadez", "Kyoung-Min Kim"], "title": "Neural Scaling Laws for Deep Regression", "comment": "Supplementary Information will be provided with the published\n  manuscript", "summary": "Neural scaling laws--power-law relationships between generalization errors\nand characteristics of deep learning models--are vital tools for developing\nreliable models while managing limited resources. Although the success of large\nlanguage models highlights the importance of these laws, their application to\ndeep regression models remains largely unexplored. Here, we empirically\ninvestigate neural scaling laws in deep regression using a parameter estimation\nmodel for twisted van der Waals magnets. We observe power-law relationships\nbetween the loss and both training dataset size and model capacity across a\nwide range of values, employing various architectures--including fully\nconnected networks, residual networks, and vision transformers. Furthermore,\nthe scaling exponents governing these relationships range from 1 to 2, with\nspecific values depending on the regressed parameters and model details. The\nconsistent scaling behaviors and their large scaling exponents suggest that the\nperformance of deep regression models can improve substantially with increasing\ndata size.", "AI": {"tldr": "\u6df1\u5ea6\u56de\u5f52\u6a21\u578b\u5b58\u5728\u795e\u7ecf\u6807\u5ea6\u5f8b\uff0c\u5176\u635f\u5931\u4e0e\u8bad\u7ec3\u6570\u636e\u91cf\u548c\u6a21\u578b\u5bb9\u91cf\u4e4b\u95f4\u5b58\u5728\u5e42\u5f8b\u5173\u7cfb\uff0c\u8868\u660e\u589e\u52a0\u6570\u636e\u91cf\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u867d\u7136\u795e\u7ecf\u6807\u5ea6\u5f8b\u5728\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5f00\u53d1\u4e2d\u5f88\u91cd\u8981\uff0c\u4f46\u5b83\u4eec\u5728\u6df1\u5ea6\u56de\u5f52\u6a21\u578b\u4e2d\u7684\u5e94\u7528\u5c1a\u4e0d\u660e\u786e\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u8ba8\u6df1\u5ea6\u56de\u5f52\u6a21\u578b\u4e2d\u7684\u795e\u7ecf\u6807\u5ea6\u5f8b\u3002", "method": "\u901a\u8fc7\u4f7f\u7528\u626d\u66f2\u8303\u5fb7\u534e\u78c1\u4f53\u7684\u53c2\u6570\u4f30\u8ba1\u6a21\u578b\uff0c\u5728\u591a\u79cd\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff08\u5305\u62ec\u5168\u8fde\u63a5\u7f51\u7edc\u3001\u6b8b\u5dee\u7f51\u7edc\u548c\u89c6\u89c9\u53d8\u6362\u5668\uff09\u4e0a\uff0c\u5bf9\u635f\u5931\u4e0e\u8bad\u7ec3\u6570\u636e\u96c6\u5927\u5c0f\u548c\u6a21\u578b\u5bb9\u91cf\u4e4b\u95f4\u7684\u5173\u7cfb\u8fdb\u884c\u7ecf\u9a8c\u6027\u7814\u7a76\u3002", "result": "\u5728\u5e7f\u6cdb\u7684\u53c2\u6570\u8303\u56f4\u5185\u89c2\u5bdf\u5230\u635f\u5931\u4e0e\u8bad\u7ec3\u6570\u636e\u96c6\u5927\u5c0f\u548c\u6a21\u578b\u5bb9\u91cf\u4e4b\u95f4\u5b58\u5728\u5e42\u5f8b\u5173\u7cfb\u3002\u6807\u5ea6\u6307\u6570\u57281\u52302\u4e4b\u95f4\uff0c\u5177\u4f53\u53d6\u51b3\u4e8e\u56de\u5f52\u53c2\u6570\u548c\u6a21\u578b\u7ec6\u8282\u3002", "conclusion": "\u6df1\u5ea6\u56de\u5f52\u6a21\u578b\u8868\u73b0\u51fa\u4e00\u81f4\u7684\u6807\u5ea6\u884c\u4e3a\uff0c\u5e76\u4e14\u5177\u6709\u8f83\u5927\u7684\u6807\u5ea6\u6307\u6570\uff0c\u8fd9\u8868\u660e\u589e\u52a0\u6570\u636e\u91cf\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2509.09943", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.09943", "abs": "https://arxiv.org/abs/2509.09943", "authors": ["Zhu Chen", "Mert Edg\u00fc", "Er Jin", "Johannes Stegmaier"], "title": "Segment Anything for Cell Tracking", "comment": null, "summary": "Tracking cells and detecting mitotic events in time-lapse microscopy image\nsequences is a crucial task in biomedical research. However, it remains highly\nchallenging due to dividing objects, low signal-tonoise ratios, indistinct\nboundaries, dense clusters, and the visually similar appearance of individual\ncells. Existing deep learning-based methods rely on manually labeled datasets\nfor training, which is both costly and time-consuming. Moreover, their\ngeneralizability to unseen datasets remains limited due to the vast diversity\nof microscopy data. To overcome these limitations, we propose a zero-shot cell\ntracking framework by integrating Segment Anything 2 (SAM2), a large foundation\nmodel designed for general image and video segmentation, into the tracking\npipeline. As a fully-unsupervised approach, our method does not depend on or\ninherit biases from any specific training dataset, allowing it to generalize\nacross diverse microscopy datasets without finetuning. Our approach achieves\ncompetitive accuracy in both 2D and large-scale 3D time-lapse microscopy videos\nwhile eliminating the need for dataset-specific adaptation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u96f6\u6837\u672c\u7ec6\u80de\u8ddf\u8e2a\u6846\u67b6\uff0c\u96c6\u6210\u4e86Segment Anything 2\uff08SAM2\uff09\u6765\u5904\u7406\u663e\u5fae\u955c\u56fe\u50cf\u5e8f\u5217\u4e2d\u7684\u7ec6\u80de\u8ddf\u8e2a\u548c\u6709\u4e1d\u5206\u88c2\u4e8b\u4ef6\u68c0\u6d4b\u95ee\u9898\uff0c\u65e0\u9700\u624b\u52a8\u6807\u6ce8\u5373\u53ef\u5b9e\u73b0\u8de8\u6570\u636e\u96c6\u7684\u6cdb\u5316\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u65b9\u6cd5\u9700\u8981\u624b\u52a8\u6807\u6ce8\u7684\u6570\u636e\u96c6\u8fdb\u884c\u8bad\u7ec3\uff0c\u6210\u672c\u9ad8\u6602\u4e14\u8017\u65f6\uff0c\u6cdb\u5316\u80fd\u529b\u6709\u9650\u3002\u800c\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u65e8\u5728\u514b\u670d\u8fd9\u4e9b\u9650\u5236\u3002", "method": "\u5c06Segment Anything 2\uff08SAM2\uff09\u96c6\u6210\u5230\u8ddf\u8e2a\u6d41\u7a0b\u4e2d\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u5b8c\u5168\u65e0\u76d1\u7763\u7684\u96f6\u6837\u672c\u7ec6\u80de\u8ddf\u8e2a\u6846\u67b6\uff0c\u65e0\u9700\u4efb\u4f55\u7279\u5b9a\u8bad\u7ec3\u6570\u636e\u96c6\u7684\u4f9d\u8d56\u6216\u7ee7\u627f\u5176\u504f\u89c1\u3002", "result": "\u8be5\u65b9\u6cd5\u57282D\u548c\u5927\u89c4\u6a213D\u5ef6\u65f6\u663e\u5fae\u955c\u89c6\u9891\u4e2d\u5747\u53d6\u5f97\u4e86\u5177\u6709\u7ade\u4e89\u529b\u7684\u51c6\u786e\u6027\uff0c\u65e0\u9700\u9488\u5bf9\u7279\u5b9a\u6570\u636e\u96c6\u8fdb\u884c\u8c03\u6574\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u96f6\u6837\u672c\u8ddf\u8e2a\u6846\u67b6\u901a\u8fc7\u96c6\u6210SAM2\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u663e\u5fae\u955c\u56fe\u50cf\u4e2d\u7ec6\u80de\u8ddf\u8e2a\u548c\u6709\u4e1d\u5206\u88c2\u68c0\u6d4b\u7684\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u65e0\u9700\u5fae\u8c03\u5373\u53ef\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u6cdb\u5316\u7684\u76ee\u6807\uff0c\u5e76\u8fbe\u5230\u4e86\u5177\u6709\u7ade\u4e89\u529b\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2509.10183", "categories": ["quant-ph", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.10183", "abs": "https://arxiv.org/abs/2509.10183", "authors": ["Johannes Bl\u00f6mer", "Yinzi Xiao", "Zahra Raissi", "Stanislaw Soltan"], "title": "Symplectic Lattices and GKP Codes -- Simple Randomized Constructions from Cryptographic Lattices", "comment": "41 pages, 3 figures", "summary": "We construct good GKP (Gottesman-Kitaev-Preskill) codes (in the sense of\nConrad, Eisert and Seifert proposed) from standard short integer solution\nlattices (SIS) as well as from ring SIS and module SIS lattices, R-SIS and\nM-SIS lattices, respectively. These lattice are crucial for lattice-based\ncryptography. Our construction yields GKP codes with distance $\\sqrt{n/\\pi e}$.\nThis compares favorably with the NTRU-based construction by Conrad et al. that\nachieves distance $\\Omega(\\sqrt{n/q}),$ with $n\\le q^2/0.28$. Unlike their\ncodes, our codes do not have secret keys that can be used to speed-up the\ndecoding. However, we present a simple decoding algorithm that, for many\nparameter choices, experimentally yields decoding results similar to the ones\nfor NTRU-based codes. Using the R-SIS and M-SIS construction, our simple\ndecoding algorithm runs in nearly linear time. Following Conrad, Eisert and\nSeifert's work, our construction of GKP codes follows directly from an\nexplicit, randomized construction of symplectic lattices with (up to constants\n$\\approx 1$) minimal distance $(1/\\sigma_{2n})^{1/2n}\\approx \\sqrt{\\frac{n}{\\pi\ne}}$, where $\\sigma_{2n}$ is the volume of the 2n-dimensional unit ball. Before\nthis result, Buser and Sarnak gave a non-constructive proof for the existence\nof such symplectic lattices.", "AI": {"tldr": "\u4f7f\u7528\u77ed\u6574\u6570\u89e3\uff08SIS\uff09\u683c\u3001\u73afSIS\uff08R-SIS\uff09\u683c\u548c\u6a21SIS\uff08M-SIS\uff09\u683c\u6784\u9020\u4e86\u65b0\u7684GKP\u7801\uff0c\u5176\u6700\u5c0f\u8ddd\u79bb\u7ea6\u4e3asqrt(n/pi e)\uff0c\u4f18\u4e8e\u73b0\u6709\u7684\u57fa\u4e8eNTRU\u7684\u6784\u9020\u3002\u867d\u7136\u65b0\u7801\u6ca1\u6709\u7528\u4e8e\u52a0\u901f\u89e3\u7801\u7684\u79c1\u94a5\uff0c\u4f46\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5355\u7684\u89e3\u7801\u7b97\u6cd5\uff0c\u5728\u8bb8\u591a\u53c2\u6570\u9009\u62e9\u4e0b\u5b9e\u9a8c\u6548\u679c\u4e0eNTRU\u7801\u76f8\u5f53\uff0c\u5e76\u4e14\u4f7f\u7528R-SIS\u548cM-SIS\u6784\u9020\u65f6\uff0c\u8be5\u7b97\u6cd5\u7684\u8fd0\u884c\u65f6\u95f4\u63a5\u8fd1\u7ebf\u6027\u3002", "motivation": "\u6784\u9020\u5177\u6709\u826f\u597d\u6027\u8d28\u7684GKP\u7801\uff0c\u7279\u522b\u662f\u5229\u7528\u683c\u5bc6\u7801\u5b66\u4e2d\u91cd\u8981\u7684SIS\u3001R-SIS\u548cM-SIS\u683c\uff0c\u5e76\u4e0e\u73b0\u6709\u65b9\u6cd5\u8fdb\u884c\u6bd4\u8f83\u3002", "method": "\u4f7f\u7528SIS\u3001R-SIS\u548cM-SIS\u683c\u6784\u9020GKP\u7801\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u7b80\u5355\u7684\u89e3\u7801\u7b97\u6cd5\u3002", "result": "\u6784\u9020\u4e86\u6700\u5c0f\u8ddd\u79bb\u7ea6\u4e3asqrt(n/pi e)\u7684GKP\u7801\uff0c\u8be5\u8ddd\u79bb\u4f18\u4e8e\u57fa\u4e8eNTRU\u7684\u6784\u9020\u3002\u63d0\u51fa\u7684\u7b80\u5355\u89e3\u7801\u7b97\u6cd5\u5728\u8bb8\u591a\u53c2\u6570\u9009\u62e9\u4e0b\u5b9e\u9a8c\u6548\u679c\u4e0eNTRU\u7801\u76f8\u5f53\uff0c\u4f7f\u7528R-SIS\u548cM-SIS\u6784\u9020\u65f6\u63a5\u8fd1\u7ebf\u6027\u65f6\u95f4\u590d\u6742\u5ea6\u3002", "conclusion": "\u901a\u8fc7\u4f7f\u7528SIS\u3001R-SIS\u548cM-SIS\u683c\uff0c\u6210\u529f\u6784\u9020\u4e86\u5177\u6709\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u6700\u5c0f\u8ddd\u79bb\u7684GKP\u7801\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u89e3\u7801\u7b97\u6cd5\u3002"}}
{"id": "2509.09728", "categories": ["cs.CL", "cs.LG", "stat.AP"], "pdf": "https://arxiv.org/pdf/2509.09728", "abs": "https://arxiv.org/abs/2509.09728", "authors": ["Elena Rohde", "Jonas Klingwort", "Christian Borgs"], "title": "A meta-analysis on the performance of machine-learning based language models for sentiment analysis", "comment": null, "summary": "This paper presents a meta-analysis evaluating ML performance in sentiment\nanalysis for Twitter data. The study aims to estimate the average performance,\nassess heterogeneity between and within studies, and analyze how study\ncharacteristics influence model performance. Using PRISMA guidelines, we\nsearched academic databases and selected 195 trials from 20 studies with 12\nstudy features. Overall accuracy, the most reported performance metric, was\nanalyzed using double arcsine transformation and a three-level random effects\nmodel. The average overall accuracy of the AIC-optimized model was 0.80 [0.76,\n0.84]. This paper provides two key insights: 1) Overall accuracy is widely used\nbut often misleading due to its sensitivity to class imbalance and the number\nof sentiment classes, highlighting the need for normalization. 2) Standardized\nreporting of model performance, including reporting confusion matrices for\nindependent test sets, is essential for reliable comparisons of ML classifiers\nacross studies, which seems far from common practice.", "AI": {"tldr": "ML\u5728\u63a8\u7279\u60c5\u611f\u5206\u6790\u4e2d\u7684\u8868\u73b0\uff0c\u5e73\u5747\u51c6\u786e\u7387\u4e3a0.80\uff0c\u4f46\u9700\u8981\u6ce8\u610f\u7c7b\u522b\u4e0d\u5e73\u8861\u548c\u6df7\u6dc6\u77e9\u9635\u7684\u6807\u51c6\u5316\u62a5\u544a\u3002", "motivation": "\u8bc4\u4f30\u673a\u5668\u5b66\u4e60\u5728\u63a8\u7279\u60c5\u611f\u5206\u6790\u4e2d\u7684\u5e73\u5747\u8868\u73b0\uff0c\u8bc4\u4f30\u7814\u7a76\u95f4\u548c\u7814\u7a76\u5185\u7684\u5f02\u8d28\u6027\uff0c\u5e76\u5206\u6790\u7814\u7a76\u7279\u5f81\u5982\u4f55\u5f71\u54cd\u6a21\u578b\u8868\u73b0\u3002", "method": "\u4f7f\u7528PRISMA\u6307\u5357\uff0c\u641c\u7d22\u5b66\u672f\u6570\u636e\u5e93\uff0c\u7b5b\u9009195\u4e2a\u8bd5\u9a8c\uff0c\u6765\u81ea20\u9879\u7814\u7a76\uff0c\u5305\u542b12\u4e2a\u7814\u7a76\u7279\u5f81\u3002\u4f7f\u7528\u53cc\u53cd\u6b63\u5f26\u53d8\u6362\u548c\u4e09\u7ea7\u968f\u673a\u6548\u5e94\u6a21\u578b\u5206\u6790\u4e86\u6700\u5e38\u62a5\u544a\u7684\u6027\u80fd\u6307\u6807\u2014\u2014\u603b\u4f53\u51c6\u786e\u7387\u3002", "result": "\u5728AIC\u4f18\u5316\u7684\u6a21\u578b\u4e2d\uff0c\u5e73\u5747\u603b\u4f53\u51c6\u786e\u7387\u4e3a0.80 [0.76, 0.84]\u3002", "conclusion": "1) \u603b\u4f53\u51c6\u786e\u7387\u5e38\u88ab\u4f7f\u7528\u4f46\u53ef\u80fd\u5177\u6709\u8bef\u5bfc\u6027\uff0c\u56e0\u4e3a\u5b83\u5bf9\u7c7b\u522b\u4e0d\u5e73\u8861\u548c\u60c5\u611f\u7c7b\u522b\u6570\u91cf\u654f\u611f\uff0c\u9700\u8981\u8fdb\u884c\u6807\u51c6\u5316\u30022) \u5bf9\u6a21\u578b\u6027\u80fd\u8fdb\u884c\u6807\u51c6\u5316\u62a5\u544a\uff0c\u5305\u62ec\u63d0\u4f9b\u72ec\u7acb\u6d4b\u8bd5\u96c6\u7684\u6df7\u6dc6\u77e9\u9635\uff0c\u5bf9\u4e8e\u53ef\u9760\u5730\u8de8\u7814\u7a76\u6bd4\u8f83\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u8fd9\u4f3c\u4e4e\u8fdc\u975e\u666e\u904d\u505a\u6cd5\u3002"}}
{"id": "2509.10401", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.10401", "abs": "https://arxiv.org/abs/2509.10401", "authors": ["Alva West", "Yixuan Weng", "Minjun Zhu", "Zhen Lin", "Yue Zhang"], "title": "Abduct, Act, Predict: Scaffolding Causal Inference for Automated Failure Attribution in Multi-Agent Systems", "comment": null, "summary": "Failure attribution in multi-agent systems -- pinpointing the exact step\nwhere a decisive error occurs -- is a critical yet unsolved challenge. Current\nmethods treat this as a pattern recognition task over long conversation logs,\nleading to critically low step-level accuracy (below 17\\%), which renders them\nimpractical for debugging complex systems. Their core weakness is a fundamental\ninability to perform robust counterfactual reasoning: to determine if\ncorrecting a single action would have actually averted the task failure. To\nbridge this counterfactual inference gap, we introduce Abduct-Act-Predict (A2P)\nScaffolding, a novel agent framework that transforms failure attribution from\npattern recognition into a structured causal inference task. A2P explicitly\nguides a large language model through a formal three-step reasoning process\nwithin a single inference pass: (1) Abduction, to infer the hidden root causes\nbehind an agent's actions; (2) Action, to define a minimal corrective\nintervention; and (3) Prediction, to simulate the subsequent trajectory and\nverify if the intervention resolves the failure. This structured approach\nleverages the holistic context of the entire conversation while imposing a\nrigorous causal logic on the model's analysis. Our extensive experiments on the\nWho\\&When benchmark demonstrate its efficacy. On the Algorithm-Generated\ndataset, A2P achieves 47.46\\% step-level accuracy, a 2.85$\\times$ improvement\nover the 16.67\\% of the baseline. On the more complex Hand-Crafted dataset, it\nachieves 29.31\\% step accuracy, a 2.43$\\times$ improvement over the baseline's\n12.07\\%. By reframing the problem through a causal lens, A2P Scaffolding\nprovides a robust, verifiable, and significantly more accurate solution for\nautomated failure attribution.", "AI": {"tldr": "A2P Scaffolding\u6846\u67b6\u901a\u8fc7\u5c06\u5931\u8d25\u5f52\u56e0\u4efb\u52a1\u91cd\u6784\u4e3a\u56e0\u679c\u63a8\u7406\u95ee\u9898\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u9519\u8bef\u6b65\u9aa4\u7684\u5b9a\u4f4d\u7cbe\u5ea6\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5931\u8d25\u5f52\u56e0\u65b9\u9762\u51c6\u786e\u7387\u4f4e\uff08\u4f4e\u4e8e17%\uff09\uff0c\u96be\u4ee5\u7528\u4e8e\u8c03\u8bd5\uff0c\u5176\u6839\u672c\u539f\u56e0\u662f\u65e0\u6cd5\u8fdb\u884c\u6709\u6548\u7684\u53cd\u4e8b\u5b9e\u63a8\u7406\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAbduct-Act-Predict (A2P) Scaffolding\u7684\u65b0\u578b\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5c06\u5931\u8d25\u5f52\u56e0\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u56e0\u679c\u63a8\u7406\u4efb\u52a1\u3002A2P\u901a\u8fc7\uff081\uff09\u6eaf\u56e0\uff08Abduction\uff09\u63a8\u65ad\u6f5c\u5728\u539f\u56e0\uff0c\uff082\uff09\u884c\u52a8\uff08Action\uff09\u5b9a\u4e49\u6700\u5c0f\u5e72\u9884\u63aa\u65bd\uff0c\uff083\uff09\u9884\u6d4b\uff08Prediction\uff09\u6a21\u62df\u5e72\u9884\u6548\u679c\u6765\u89e3\u51b3\u5931\u8d25\u95ee\u9898\uff0c\u5728\u5355\u6b21\u63a8\u7406\u4e2d\u5b8c\u6210\u3002", "result": "\u5728Who&When\u57fa\u51c6\u6d4b\u8bd5\u7684\u7b97\u6cd5\u751f\u6210\u6570\u636e\u96c6\u4e0a\uff0cA2P\u5b9e\u73b0\u4e8647.46%\u7684\u6b65\u9aa4\u7ea7\u51c6\u786e\u7387\uff0c\u76f8\u6bd4\u57fa\u7ebf\uff0816.67%\uff09\u63d0\u5347\u4e862.85\u500d\u3002\u5728\u66f4\u590d\u6742\u7684\u624b\u5de5\u5236\u4f5c\u6570\u636e\u96c6\u4e0a\uff0cA2P\u5b9e\u73b0\u4e8629.31%\u7684\u6b65\u9aa4\u51c6\u786e\u7387\uff0c\u76f8\u6bd4\u57fa\u7ebf\uff0812.07%\uff09\u63d0\u5347\u4e862.43\u500d\u3002", "conclusion": "A2P Scaffolding\u901a\u8fc7\u5f15\u5165\u56e0\u679c\u63a8\u7406\u89c6\u89d2\uff0c\u4e3a\u81ea\u52a8\u5316\u5931\u8d25\u5f52\u56e0\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u51c6\u786e\u3001\u66f4\u53ef\u9760\u3001\u53ef\u9a8c\u8bc1\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2509.09946", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.09946", "abs": "https://arxiv.org/abs/2509.09946", "authors": ["Vu-Minh Le", "Thao-Anh Tran", "Duc Huy Do", "Xuan Canh Do", "Huong Ninh", "Hai Tran"], "title": "Online 3D Multi-Camera Perception through Robust 2D Tracking and Depth-based Late Aggregation", "comment": "Accepted at ICCVW 2025", "summary": "Multi-Target Multi-Camera Tracking (MTMC) is an essential computer vision\ntask for automating large-scale surveillance. With camera calibration and depth\ninformation, the targets in the scene can be projected into 3D space, offering\nunparalleled levels of automatic perception of a 3D environment. However,\ntracking in the 3D space requires replacing all 2D tracking components from the\nground up, which may be infeasible for existing MTMC systems. In this paper, we\npresent an approach for extending any online 2D multi-camera tracking system\ninto 3D space by utilizing depth information to reconstruct a target in\npoint-cloud space, and recovering its 3D box through clustering and yaw\nrefinement following tracking. We also introduced an enhanced online data\nassociation mechanism that leverages the target's local ID consistency to\nassign global IDs across frames. The proposed framework is evaluated on the\n2025 AI City Challenge's 3D MTMC dataset, achieving 3rd place on the\nleaderboard.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u73b0\u6709\u76842D\u591a\u6444\u50cf\u5934\u8ddf\u8e2a\u7cfb\u7edf\u6269\u5c55\u52303D\u7a7a\u95f4\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u6df1\u5ea6\u4fe1\u606f\u91cd\u5efa\u76ee\u6807\uff0c\u5e76\u8fdb\u884c\u805a\u7c7b\u548c\u504f\u822a\u89d2\u4f18\u5316\u6765\u6062\u590d\u51763D\u8fb9\u754c\u6846\u3002\u7814\u7a76\u8fd8\u5f15\u5165\u4e86\u4e00\u79cd\u589e\u5f3a\u7684\u5728\u7ebf\u6570\u636e\u5173\u8054\u673a\u5236\uff0c\u5229\u7528\u76ee\u6807\u7684\u5c40\u90e8ID\u4e00\u81f4\u6027\u6765\u5206\u914d\u5168\u5c40ID\u3002", "motivation": "\u73b0\u6709\u76842D\u591a\u6444\u50cf\u5934\u8ddf\u8e2a\u7cfb\u7edf\u5728\u6269\u5c55\u52303D\u7a7a\u95f4\u65f6\u9762\u4e34\u6311\u6218\uff0c\u9700\u8981\u4ece\u5934\u5f00\u59cb\u66ff\u6362\u6240\u67092D\u8ddf\u8e2a\u7ec4\u4ef6\uff0c\u8fd9\u53ef\u80fd\u4e0d\u53ef\u884c\u3002", "method": "\u5229\u7528\u6df1\u5ea6\u4fe1\u606f\u5c06\u76ee\u6807\u6295\u5f71\u52303D\u7a7a\u95f4\uff0c\u5e76\u901a\u8fc7\u70b9\u4e91\u7a7a\u95f4\u91cd\u5efa\u3001\u805a\u7c7b\u548c\u504f\u822a\u89d2\u4f18\u5316\u6765\u6062\u590d\u76ee\u6807\u76843D\u8fb9\u754c\u6846\u3002\u5f15\u5165\u4e86\u589e\u5f3a\u7684\u5728\u7ebf\u6570\u636e\u5173\u8054\u673a\u5236\uff0c\u5229\u7528\u76ee\u6807\u5c40\u90e8ID\u4e00\u81f4\u6027\u8fdb\u884c\u5168\u5c40ID\u5206\u914d\u3002", "result": "\u57282025 AI City Challenge\u76843D MTMC\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u53d6\u5f97\u4e86\u7b2c\u4e09\u540d\u7684\u6210\u7ee9\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5730\u5c062D\u591a\u6444\u50cf\u5934\u8ddf\u8e2a\u7cfb\u7edf\u6269\u5c55\u52303D\u7a7a\u95f4\uff0c\u5e76\u57283D\u591a\u76ee\u6807\u591a\u6444\u50cf\u5934\u8ddf\u8e2a\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u826f\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2509.10444", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.10444", "abs": "https://arxiv.org/abs/2509.10444", "authors": ["Chaerim Moon", "Joohyung Kim"], "title": "Coordinated Motion Planning of a Wearable Multi-Limb System for Enhanced Human-Robot Interaction", "comment": "Presented in IROS 2023 Workshop (Multilimb Coordination in Human\n  Neuroscience and Robotics: Classical and Learning Perspectives)", "summary": "Supernumerary Robotic Limbs (SRLs) can enhance human capability within close\nproximity. However, as a wearable device, the generated moment from its\noperation acts on the human body as an external torque. When the moments\nincrease, more muscle units are activated for balancing, and it can result in\nreduced muscular null space. Therefore, this paper suggests a concept of a\nmotion planning layer that reduces the generated moment for enhanced\nHuman-Robot Interaction. It modifies given trajectories with desirable angular\nacceleration and position deviation limits. Its performance to reduce the\nmoment is demonstrated through the simulation, which uses simplified human and\nrobotic system models.", "AI": {"tldr": "SRLs\u901a\u8fc7\u4fee\u6539\u8f68\u8ff9\u6765\u51cf\u5c11\u5bf9\u4eba\u4f53\u7684\u529b\u77e9\uff0c\u4ee5\u589e\u5f3a\u4eba\u673a\u4ea4\u4e92\u3002", "motivation": "SRLs\u5728\u589e\u5f3a\u4eba\u7c7b\u8fd1\u8ddd\u79bb\u80fd\u529b\u7684\u540c\u65f6\uff0c\u5176\u64cd\u4f5c\u4ea7\u751f\u7684\u529b\u77e9\u4f1a\u4f5c\u7528\u4e8e\u4eba\u4f53\uff0c\u5bfc\u81f4\u808c\u8089\u6fc0\u6d3b\u589e\u52a0\u5e76\u51cf\u5c11\u808c\u8089\u7684\u96f6\u7a7a\u95f4\uff0c\u5f71\u54cd\u4eba\u673a\u4ea4\u4e92\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u8fd0\u52a8\u89c4\u5212\u5c42\uff0c\u901a\u8fc7\u4fee\u6539\u7ed9\u5b9a\u8f68\u8ff9\uff0c\u5e76\u5728\u53ef\u63a5\u53d7\u7684\u89d2\u52a0\u901f\u5ea6\u548c\u4f4d\u7f6e\u504f\u5dee\u8303\u56f4\u5185\uff0c\u6765\u51cf\u5c11SRLs\u64cd\u4f5c\u4ea7\u751f\u7684\u529b\u77e9\u3002", "result": "\u901a\u8fc7\u7b80\u5316\u7684\u4eff\u771f\u6a21\u578b\u8bc1\u660e\u4e86\u8be5\u8fd0\u52a8\u89c4\u5212\u5c42\u5728\u51cf\u5c11\u529b\u77e9\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u8fd0\u52a8\u89c4\u5212\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u51cf\u5c11SRLs\u64cd\u4f5c\u5bf9\u4eba\u4f53\u7684\u529b\u77e9\uff0c\u4ece\u800c\u6539\u5584\u4eba\u673a\u4ea4\u4e92\u3002"}}
{"id": "2509.10190", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2509.10190", "abs": "https://arxiv.org/abs/2509.10190", "authors": ["Gabriela Pinheiro", "Donovan Slabbert", "Luis Kowada", "Francesco Petruccione"], "title": "Quantum kernel and HHL-based support vector machines for multi-class classification", "comment": "15 pages, 3 figures, 2 tables", "summary": "We compare two quantum approaches that use support vector machines for\nmulti-class classification on a reduced Sloan Digital Sky Survey (SDSS)\ndataset: the quantum kernel-based QSVM and the Harrow-Hassidim-Lloyd\nleast-squares SVM (HHL LS-SVM). Both one-vs-rest and two-step hierarchical\nclassification schemes were implemented. The QSVM involves angle encoding of\nten features, two unitary operator blocks consisting of rotational operator\ngates, and a projective measurement that projects the final state to the zero\nstate. The HHL-based method involves solving a system of linear equations using\nthe HHL algorithm and using the solution in a support vector machine approach.\nThe results indicate that the QSVM outperforms HHL LS-SVM in most cases. HHL\nLS-SVM performs somewhat competitively in selected cases, particularly when\nisolating galaxies (majority), however, it also performs poorly in others,\nespecially when isolating QSOs (minority). Comparisons with classical SVMs\nconfirm that quantum and classical methods achieve broadly similar performance,\nwith classical models performing slightly ahead overall. Scaling analysis\nreveals a trade-off: QSVM performance suffers from quadratic scaling with the\nnumber of samples and features, but benefits from explicit feature\nrepresentation during training, while HHL LS-SVM scales essentially constantly,\nwith moderate fluctuations, but suffers from limited representative elements.\nThe HHL-based method is also highly noise-sensitive. These results suggest that\nQSVM performs better overall and will perform better on current hardware as\nwell, but that the more efficient scaling of HHL LS-SVM makes it a useful\noption for larger datasets with many samples, especially if we move past the\nNISQ era.", "AI": {"tldr": "QSVM \u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u4f18\u4e8e HHL LS-SVM\uff0c\u4f46 HHL LS-SVM \u5728\u5904\u7406\u5305\u542b\u5927\u91cf\u6837\u672c\u7684\u6570\u636e\u96c6\u65f6\u5177\u6709\u66f4\u597d\u7684\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u6bd4\u8f83\u4e24\u79cd\u7528\u4e8e\u591a\u7c7b\u522b\u5206\u7c7b\u7684\u91cf\u5b50\u652f\u6301\u5411\u91cf\u673a\u65b9\u6cd5\uff08QSVM \u548c HHL LS-SVM\uff09\u5728\u51cf\u5c11\u7684 SDSS \u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\u3002", "method": "\u5728\u51cf\u5c11\u7684 SDSS \u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u5e76\u6bd4\u8f83\u4e86 QSVM \u548c HHL LS-SVM \u7684\u4e00\u79cd\u5bf9\u6240\u6709\u548c\u4e24\u6b65\u5206\u5c42\u5206\u7c7b\u65b9\u6848\u3002QSVM \u5305\u62ec\u89d2\u5ea6\u7f16\u7801\u3001\u9149\u7b97\u5b50\u5757\u548c\u6295\u5f71\u6d4b\u91cf\u3002HHL LS-SVM \u6d89\u53ca\u4f7f\u7528 HHL \u7b97\u6cd5\u6c42\u89e3\u7ebf\u6027\u65b9\u7a0b\u7ec4\u3002", "result": "QSVM \u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u4f18\u4e8e HHL LS-SVM\u3002HHL LS-SVM \u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u5177\u6709\u7ade\u4e89\u529b\uff0c\u4f46\u5bf9\u5c11\u6570\u7c7b\u522b\uff08\u5982 QSOs\uff09\u8868\u73b0\u4e0d\u4f73\u3002QSVM \u7684\u6027\u80fd\u4f1a\u968f\u7740\u6837\u672c\u548c\u7279\u5f81\u6570\u91cf\u7684\u4e8c\u6b21\u65b9\u6269\u5c55\u800c\u53d7\u5230\u5f71\u54cd\uff0c\u4f46\u53ef\u4ee5\u663e\u5f0f\u8868\u793a\u7279\u5f81\u3002HHL LS-SVM \u7684\u6269\u5c55\u6027\u51e0\u4e4e\u6052\u5b9a\uff0c\u4f46\u4ee3\u8868\u6027\u5143\u7d20\u6709\u9650\u4e14\u5bf9\u566a\u58f0\u654f\u611f\u3002", "conclusion": "QSVM \u5728\u5f53\u524d\u786c\u4ef6\u4e0a\u6574\u4f53\u8868\u73b0\u66f4\u597d\uff0c\u4f46 HHL LS-SVM \u7684\u53ef\u6269\u5c55\u6027\u4f7f\u5176\u6210\u4e3a\u672a\u6765\u5927\u578b\u6570\u636e\u96c6\u7684\u6f5c\u5728\u9009\u62e9\u3002"}}
{"id": "2509.09729", "categories": ["cs.CL", "cs.AI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2509.09729", "abs": "https://arxiv.org/abs/2509.09729", "authors": ["Gerard Sant", "Zifan Jiang", "Carlos Escolano", "Amit Moryossef", "Mathias M\u00fcller", "Rico Sennrich", "Sarah Ebling"], "title": "MultimodalHugs: Enabling Sign Language Processing in Hugging Face", "comment": null, "summary": "In recent years, sign language processing (SLP) has gained importance in the\ngeneral field of Natural Language Processing. However, compared to research on\nspoken languages, SLP research is hindered by complex ad-hoc code,\ninadvertently leading to low reproducibility and unfair comparisons. Existing\ntools that are built for fast and reproducible experimentation, such as Hugging\nFace, are not flexible enough to seamlessly integrate sign language\nexperiments. This view is confirmed by a survey we conducted among SLP\nresearchers.\n  To address these challenges, we introduce MultimodalHugs, a framework built\non top of Hugging Face that enables more diverse data modalities and tasks,\nwhile inheriting the well-known advantages of the Hugging Face ecosystem. Even\nthough sign languages are our primary focus, MultimodalHugs adds a layer of\nabstraction that makes it more widely applicable to other use cases that do not\nfit one of the standard templates of Hugging Face. We provide quantitative\nexperiments to illustrate how MultimodalHugs can accommodate diverse modalities\nsuch as pose estimation data for sign languages, or pixel data for text\ncharacters.", "AI": {"tldr": "Sign language processing (SLP) faces reproducibility challenges due to complex code. MultimodalHugs is a new framework based on Hugging Face designed to address these issues, supporting diverse data modalities and tasks beyond just sign language.", "motivation": "Existing tools like Hugging Face are not flexible enough for sign language experiments, hindering reproducibility and fair comparisons in SLP research. A survey confirmed this issue among SLP researchers.", "method": "Introduced MultimodalHugs, a framework built on top of Hugging Face, to enable diverse data modalities and tasks while maintaining Hugging Face's advantages. The framework includes a layer of abstraction for broader applicability.", "result": "Demonstrated MultimodalHugs' ability to accommodate diverse modalities like pose estimation data for sign languages and pixel data for text characters through quantitative experiments.", "conclusion": "MultimodalHugs provides a flexible and reproducible framework for SLP research and other use cases that don't fit standard Hugging Face templates."}}
{"id": "2509.10025", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10025", "abs": "https://arxiv.org/abs/2509.10025", "authors": ["Strahinja Nikolic", "Ilker Oguz", "Demetri Psaltis"], "title": "Exploring Expert Specialization through Unsupervised Training in Sparse Mixture of Experts", "comment": "14 pages, 7 figures", "summary": "Understanding the internal organization of neural networks remains a\nfundamental challenge in deep learning interpretability. We address this\nchallenge by exploring a novel Sparse Mixture of Experts Variational\nAutoencoder (SMoE-VAE) architecture. We test our model on the QuickDraw\ndataset, comparing unsupervised expert routing against a supervised baseline\nguided by ground-truth labels. Surprisingly, we find that unsupervised routing\nconsistently achieves superior reconstruction performance. The experts learn to\nidentify meaningful sub-categorical structures that often transcend\nhuman-defined class boundaries. Through t-SNE visualizations and reconstruction\nanalysis, we investigate how MoE models uncover fundamental data structures\nthat are more aligned with the model's objective than predefined labels.\nFurthermore, our study on the impact of dataset size provides insights into the\ntrade-offs between data quantity and expert specialization, offering guidance\nfor designing efficient MoE architectures.", "AI": {"tldr": "SMoE-VAE\u5728QuickDraw\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\uff0c\u80fd\u591f\u5b66\u4e60\u5230\u8d85\u8d8a\u4eba\u7c7b\u5b9a\u4e49\u7684\u7c7b\u522b\u754c\u9650\u7684\u6709\u610f\u4e49\u7684\u5b50\u7c7b\u522b\u7ed3\u6784\u3002", "motivation": "\u7406\u89e3\u795e\u7ecf\u7f51\u7edc\u7684\u5185\u90e8\u7ec4\u7ec7\u662f\u6df1\u5ea6\u5b66\u4e60\u53ef\u89e3\u91ca\u6027\u7684\u4e00\u4e2a\u57fa\u672c\u6311\u6218\u3002", "method": "\u63d0\u51fa\u5e76\u6d4b\u8bd5\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u7a00\u758f\u4e13\u5bb6\u6df7\u5408\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08SMoE-VAE\uff09\u67b6\u6784\uff0c\u5e76\u5728QuickDraw\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0c\u6bd4\u8f83\u4e86\u65e0\u76d1\u7763\u4e13\u5bb6\u8def\u7531\u548c\u6709\u76d1\u7763\u57fa\u7ebf\u3002", "result": "\u65e0\u76d1\u7763\u8def\u7531\u5728\u91cd\u6784\u6027\u80fd\u4e0a\u4f18\u4e8e\u6709\u76d1\u7763\u57fa\u7ebf\uff0c\u6a21\u578b\u5b66\u5230\u7684\u4e13\u5bb6\u80fd\u591f\u8bc6\u522b\u51fa\u8d85\u8d8a\u4eba\u7c7b\u5b9a\u4e49\u7684\u7c7b\u522b\u754c\u9650\u7684\u6709\u610f\u4e49\u7684\u5b50\u7c7b\u522b\u7ed3\u6784\u3002t-SNE\u53ef\u89c6\u5316\u548c\u91cd\u6784\u5206\u6790\u8868\u660e\uff0cMoE\u6a21\u578b\u53d1\u73b0\u7684\u6570\u636e\u7ed3\u6784\u6bd4\u9884\u5b9a\u4e49\u7684\u6807\u7b7e\u66f4\u7b26\u5408\u6a21\u578b\u7684\u4f18\u5316\u76ee\u6807\u3002\u7814\u7a76\u8fd8\u63ed\u793a\u4e86\u6570\u636e\u96c6\u5927\u5c0f\u5bf9\u4e13\u5bb6\u4e13\u4e1a\u5316\u7684\u5f71\u54cd\u3002", "conclusion": "SMoE-VAE\u6a21\u578b\u80fd\u591f\u53d1\u73b0\u6bd4\u9884\u5b9a\u4e49\u6807\u7b7e\u66f4\u7b26\u5408\u6a21\u578b\u76ee\u6807\u7684\u6570\u636e\u5185\u5728\u7ed3\u6784\uff0c\u4e3a\u8bbe\u8ba1\u9ad8\u6548\u7684MoE\u67b6\u6784\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2509.10423", "categories": ["cs.AI", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2509.10423", "abs": "https://arxiv.org/abs/2509.10423", "authors": ["Cameron Reid", "Wael Hafez", "Amirhossein Nazeri"], "title": "Mutual Information Tracks Policy Coherence in Reinforcement Learning", "comment": "10 pages, 4 figures, 1 table", "summary": "Reinforcement Learning (RL) agents deployed in real-world environments face\ndegradation from sensor faults, actuator wear, and environmental shifts, yet\nlack intrinsic mechanisms to detect and diagnose these failures. We present an\ninformation-theoretic framework that reveals both the fundamental dynamics of\nRL and provides practical methods for diagnosing deployment-time anomalies.\nThrough analysis of state-action mutual information patterns in a robotic\ncontrol task, we first demonstrate that successful learning exhibits\ncharacteristic information signatures: mutual information between states and\nactions steadily increases from 0.84 to 2.83 bits (238% growth) despite growing\nstate entropy, indicating that agents develop increasingly selective attention\nto task-relevant patterns. Intriguingly, states, actions and next states joint\nmutual information, MI(S,A;S'), follows an inverted U-curve, peaking during\nearly learning before declining as the agent specializes suggesting a\ntransition from broad exploration to efficient exploitation. More immediately\nactionable, we show that information metrics can differentially diagnose system\nfailures: observation-space, i.e., states noise (sensor faults) produces broad\ncollapses across all information channels with pronounced drops in state-action\ncoupling, while action-space noise (actuator faults) selectively disrupts\naction-outcome predictability while preserving state-action relationships. This\ndifferential diagnostic capability demonstrated through controlled perturbation\nexperiments enables precise fault localization without architectural\nmodifications or performance degradation. By establishing information patterns\nas both signatures of learning and diagnostic for system health, we provide the\nfoundation for adaptive RL systems capable of autonomous fault detection and\npolicy adjustment based on information-theoretic principles.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4fe1\u606f\u8bba\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\u90e8\u7f72\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u4ee3\u7406\u65f6\u68c0\u6d4b\u548c\u8bca\u65ad\u7cfb\u7edf\u6545\u969c\uff0c\u5e76\u901a\u8fc7\u5206\u6790\u72b6\u6001-\u52a8\u4f5c\u4e92\u4fe1\u606f\u6a21\u5f0f\u6765\u5c55\u793a\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u4ee3\u7406\u9762\u4e34\u4f20\u611f\u5668\u6545\u969c\u3001\u6267\u884c\u5668\u78e8\u635f\u548c\u73af\u5883\u53d8\u5316\u7b49\u95ee\u9898\uff0c\u4f46\u7f3a\u4e4f\u68c0\u6d4b\u548c\u8bca\u65ad\u8fd9\u4e9b\u6545\u969c\u7684\u5185\u5728\u673a\u5236\u3002", "method": "\u901a\u8fc7\u5206\u6790\u673a\u5668\u4eba\u63a7\u5236\u4efb\u52a1\u4e2d\u7684\u72b6\u6001-\u52a8\u4f5c\u4e92\u4fe1\u606f\u6a21\u5f0f\uff0c\u63ed\u793aRL\u7684\u57fa\u672c\u52a8\u529b\u5b66\u5e76\u63d0\u4f9b\u5b9e\u7528\u7684\u90e8\u7f72\u65f6\u5f02\u5e38\u8bca\u65ad\u65b9\u6cd5\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u7814\u7a76\u4e86\u72b6\u6001-\u52a8\u4f5c\u4e92\u4fe1\u606f\u968f\u5b66\u4e60\u8fc7\u7a0b\u7684\u53d8\u5316\uff0c\u4ee5\u53ca\u72b6\u6001\u3001\u52a8\u4f5c\u548c\u4e0b\u4e00\u4e2a\u72b6\u6001\u7684\u8054\u5408\u4e92\u4fe1\u606f\uff08MI(S,A;S')\uff09\u7684\u5012U\u578b\u66f2\u7ebf\u3002\u6b64\u5916\uff0c\u8fd8\u901a\u8fc7\u53d7\u63a7\u6270\u52a8\u5b9e\u9a8c\u6765\u5c55\u793a\u4fe1\u606f\u5ea6\u91cf\u5728\u533a\u5206\u548c\u8bca\u65ad\u7cfb\u7edf\u6545\u969c\u65b9\u9762\u7684\u80fd\u529b\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u6210\u529f\u7684\u5b66\u4e60\u8868\u73b0\u51fa\u7279\u5f81\u6027\u7684\u4fe1\u606f\u7279\u5f81\uff1a\u72b6\u6001-\u52a8\u4f5c\u4e92\u4fe1\u606f\u5728\u72b6\u6001\u71b5\u589e\u52a0\u7684\u60c5\u51b5\u4e0b\u7a33\u5b9a\u589e\u957f\uff08\u4ece0.84\u589e\u957f\u52302.83\u6bd4\u7279\uff0c\u589e\u957f238%\uff09\uff0c\u8868\u660e\u4ee3\u7406\u8d8a\u6765\u8d8a\u5173\u6ce8\u4e0e\u4efb\u52a1\u76f8\u5173\u7684\u6a21\u5f0f\u3002\u72b6\u6001\u3001\u52a8\u4f5c\u548c\u4e0b\u4e00\u4e2a\u72b6\u6001\u7684\u8054\u5408\u4e92\u4fe1\u606f\uff08MI(S,A;S')\uff09\u5448\u73b0\u5012U\u578b\u66f2\u7ebf\uff0c\u5728\u65e9\u671f\u5b66\u4e60\u9636\u6bb5\u8fbe\u5230\u5cf0\u503c\uff0c\u7136\u540e\u968f\u7740\u4ee3\u7406\u4e13\u4e1a\u5316\u800c\u4e0b\u964d\u3002\u89c2\u5bdf\u7a7a\u95f4\u566a\u58f0\uff08\u4f20\u611f\u5668\u6545\u969c\uff09\u4f1a\u5bfc\u81f4\u6240\u6709\u4fe1\u606f\u901a\u9053\u7684\u5e7f\u6cdb\u5d29\u6e83\uff0c\u72b6\u6001-\u52a8\u4f5c\u8026\u5408\u663e\u8457\u4e0b\u964d\uff1b\u800c\u52a8\u4f5c\u7a7a\u95f4\u566a\u58f0\uff08\u6267\u884c\u5668\u6545\u969c\uff09\u5219\u9009\u62e9\u6027\u5730\u7834\u574f\u52a8\u4f5c-\u7ed3\u679c\u7684\u53ef\u9884\u6d4b\u6027\uff0c\u540c\u65f6\u4fdd\u7559\u72b6\u6001-\u52a8\u4f5c\u5173\u7cfb\u3002", "conclusion": "\u4fe1\u606f\u5ea6\u91cf\u65e2\u53ef\u4ee5\u4f5c\u4e3a\u5b66\u4e60\u7684\u6807\u5fd7\uff0c\u4e5f\u53ef\u4ee5\u4f5c\u4e3a\u7cfb\u7edf\u5065\u5eb7\u7684\u8bca\u65ad\u4f9d\u636e\uff0c\u4e3a\u80fd\u591f\u57fa\u4e8e\u4fe1\u606f\u8bba\u539f\u7406\u8fdb\u884c\u81ea\u4e3b\u6545\u969c\u68c0\u6d4b\u548c\u7b56\u7565\u8c03\u6574\u7684\u81ea\u9002\u5e94RL\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2509.09958", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09958", "abs": "https://arxiv.org/abs/2509.09958", "authors": ["Jeffrey Liu", "Rongbin Hu"], "title": "Zero-Shot Referring Expression Comprehension via Visual-Language True/False Verification", "comment": null, "summary": "Referring Expression Comprehension (REC) is usually addressed with\ntask-trained grounding models. We show that a zero-shot workflow, without any\nREC-specific training, can achieve competitive or superior performance. Our\napproach reformulates REC as box-wise visual-language verification: given\nproposals from a COCO-clean generic detector (YOLO-World), a general-purpose\nVLM independently answers True/False queries for each region. This simple\nprocedure reduces cross-box interference, supports abstention and multiple\nmatches, and requires no fine-tuning. On RefCOCO, RefCOCO+, and RefCOCOg, our\nmethod not only surpasses a zero-shot GroundingDINO baseline but also exceeds\nreported results for GroundingDINO trained on REC and GroundingDINO+CRG.\nControlled studies with identical proposals confirm that verification\nsignificantly outperforms selection-based prompting, and results hold with open\nVLMs. Overall, we show that workflow design, rather than task-specific\npretraining, drives strong zero-shot REC performance.", "AI": {"tldr": "\u65e0\u9700\u9488\u5bf9 referring expression comprehension (REC) \u8fdb\u884c\u4e13\u95e8\u8bad\u7ec3\uff0c\u5373\u53ef\u901a\u8fc7\u96f6\u6837\u672c\u65b9\u6cd5\u5728\u5404\u9879\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u5177\u6709\u7ade\u4e89\u529b\u7684\u751a\u81f3\u66f4\u4f18\u7684\u6027\u80fd\u3002", "motivation": "\u4e0e\u901a\u5e38\u4f7f\u7528\u7ecf\u8fc7\u4efb\u52a1\u8bad\u7ec3\u7684\u63a5\u5730\u6a21\u578b\u6765\u89e3\u51b3 Referring Expression Comprehension (REC) \u95ee\u9898\u4e0d\u540c\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u4e00\u79cd\u4e0d\u7ecf\u8fc7\u4efb\u4f55 REC \u7279\u5b9a\u8bad\u7ec3\u7684\u96f6\u6837\u672c\u65b9\u6cd5\uff0c\u4ee5\u8fbe\u5230\u540c\u7b49\u6216\u66f4\u4f18\u7684\u6027\u80fd\u3002", "method": "\u5c06 REC \u91cd\u65b0\u6784\u60f3\u4e3a\u9010\u4e2a\u533a\u57df\u7684\u89c6\u89c9-\u8bed\u8a00\u9a8c\u8bc1\u4efb\u52a1\u3002\u5177\u4f53\u800c\u8a00\uff0c\u5229\u7528\u6765\u81ea\u901a\u7528\u7684 YOLO-World \u68c0\u6d4b\u5668\u7684\u533a\u57df\u5efa\u8bae\uff0c\u5e76\u8ba9\u4e00\u4e2a\u901a\u7528\u7684\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u72ec\u7acb\u5730\u5bf9\u6bcf\u4e2a\u5efa\u8bae\u533a\u57df\u56de\u7b54\u201c\u771f/\u5047\u201d\u67e5\u8be2\u3002", "result": "\u5728 RefCOCO\u3001RefCOCO+ \u548c RefCOCOg \u6570\u636e\u96c6\u4e0a\uff0c\u672c\u65b9\u6cd5\u4e0d\u4ec5\u4f18\u4e8e\u96f6\u6837\u672c GroundingDINO \u57fa\u7ebf\uff0c\u800c\u4e14\u8d85\u8fc7\u4e86\u5728 REC \u4e0a\u8bad\u7ec3\u7684 GroundingDINO \u548c GroundingDINO+CRG \u7684\u62a5\u544a\u7ed3\u679c\u3002\u901a\u8fc7\u63a7\u5236\u5b9e\u9a8c\uff08\u4f7f\u7528\u76f8\u540c\u7684\u533a\u57df\u5efa\u8bae\uff09\u8bc1\u660e\uff0c\u9010\u4e2a\u533a\u57df\u7684\u9a8c\u8bc1\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u57fa\u4e8e\u9009\u62e9\u7684\u63d0\u793a\u65b9\u6cd5\uff0c\u5e76\u4e14\u8be5\u65b9\u6cd5\u5728\u5f00\u653e\u57df\u7684 VLM \u4e0a\u4e5f\u8868\u73b0\u826f\u597d\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u96f6\u6837\u672c REC \u7684\u9ad8\u6027\u80fd\u4e3b\u8981\u5f97\u76ca\u4e8e\u5de5\u4f5c\u6d41\u7a0b\u7684\u8bbe\u8ba1\uff0c\u800c\u975e\u7279\u5b9a\u4efb\u52a1\u7684\u9884\u8bad\u7ec3\u3002"}}
{"id": "2509.10454", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.10454", "abs": "https://arxiv.org/abs/2509.10454", "authors": ["Hang Yin", "Haoyu Wei", "Xiuwei Xu", "Wenxuan Guo", "Jie Zhou", "Jiwen Lu"], "title": "GC-VLN: Instruction as Graph Constraints for Training-free Vision-and-Language Navigation", "comment": "Accepted to CoRL 2025. Project page: [this https\n  URL](https://bagh2178.github.io/GC-VLN/)", "summary": "In this paper, we propose a training-free framework for vision-and-language\nnavigation (VLN). Existing zero-shot VLN methods are mainly designed for\ndiscrete environments or involve unsupervised training in continuous simulator\nenvironments, which makes it challenging to generalize and deploy them in\nreal-world scenarios. To achieve a training-free framework in continuous\nenvironments, our framework formulates navigation guidance as graph constraint\noptimization by decomposing instructions into explicit spatial constraints. The\nconstraint-driven paradigm decodes spatial semantics through constraint\nsolving, enabling zero-shot adaptation to unseen environments. Specifically, we\nconstruct a spatial constraint library covering all types of spatial\nrelationship mentioned in VLN instructions. The human instruction is decomposed\ninto a directed acyclic graph, with waypoint nodes, object nodes and edges,\nwhich are used as queries to retrieve the library to build the graph\nconstraints. The graph constraint optimization is solved by the constraint\nsolver to determine the positions of waypoints, obtaining the robot's\nnavigation path and final goal. To handle cases of no solution or multiple\nsolutions, we construct a navigation tree and the backtracking mechanism.\nExtensive experiments on standard benchmarks demonstrate significant\nimprovements in success rate and navigation efficiency compared to\nstate-of-the-art zero-shot VLN methods. We further conduct real-world\nexperiments to show that our framework can effectively generalize to new\nenvironments and instruction sets, paving the way for a more robust and\nautonomous navigation framework.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u89c6\u89c9\u4e0e\u8bed\u8a00\u5bfc\u822a\uff08VLN\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u5bfc\u822a\u6307\u4ee4\u5206\u89e3\u4e3a\u7a7a\u95f4\u7ea6\u675f\u5e76\u5229\u7528\u56fe\u7ea6\u675f\u4f18\u5316\u6765\u89e3\u51b3\uff0c\u5b9e\u73b0\u4e86\u5728\u8fde\u7eed\u73af\u5883\u4e0b\u7684\u96f6\u6837\u672c\u6cdb\u5316\uff0c\u5e76\u5728\u6807\u51c6\u57fa\u51c6\u548c\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6539\u8fdb\u3002", "motivation": "\u73b0\u6709\u7684\u96f6\u6837\u672cVLN\u65b9\u6cd5\u96be\u4ee5\u6cdb\u5316\u548c\u90e8\u7f72\u5230\u771f\u5b9e\u4e16\u754c\u573a\u666f\uff0c\u56e0\u4e3a\u5b83\u4eec\u4e3b\u8981\u9488\u5bf9\u79bb\u6563\u73af\u5883\u6216\u6d89\u53ca\u8fde\u7eed\u6a21\u62df\u5668\u73af\u5883\u4e2d\u7684\u65e0\u76d1\u7763\u8bad\u7ec3\u3002", "method": "\u5c06\u5bfc\u822a\u5f15\u5bfc\u6784\u5efa\u4e3a\u56fe\u7ea6\u675f\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u5c06\u6307\u4ee4\u5206\u89e3\u4e3a\u660e\u786e\u7684\u7a7a\u95f4\u7ea6\u675f\u3002\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542bVLN\u6307\u4ee4\u4e2d\u6240\u6709\u7a7a\u95f4\u5173\u7cfb\u7684\u7ea6\u675f\u5e93\u3002\u5c06\u4eba\u7c7b\u6307\u4ee4\u5206\u89e3\u4e3a\u6709\u5411\u65e0\u73af\u56fe\uff0c\u5e76\u5229\u7528\u7ea6\u675f\u6c42\u89e3\u5668\u6c42\u89e3\u4ee5\u786e\u5b9a\u8def\u70b9\u4f4d\u7f6e\uff0c\u4ece\u800c\u83b7\u5f97\u673a\u5668\u4eba\u7684\u5bfc\u822a\u8def\u5f84\u548c\u6700\u7ec8\u76ee\u6807\u3002\u901a\u8fc7\u6784\u5efa\u5bfc\u822a\u6811\u548c\u56de\u6eaf\u673a\u5236\u6765\u5904\u7406\u65e0\u89e3\u6216\u591a\u89e3\u7684\u60c5\u51b5\u3002", "result": "\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4e0e\u6700\u5148\u8fdb\u7684\u96f6\u6837\u672cVLN\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6210\u529f\u7387\u548c\u5bfc\u822a\u6548\u7387\u5f97\u5230\u4e86\u663e\u8457\u63d0\u9ad8\u3002\u5728\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u4e2d\uff0c\u8bc1\u660e\u4e86\u8be5\u6846\u67b6\u80fd\u591f\u6709\u6548\u5730\u6cdb\u5316\u5230\u65b0\u73af\u5883\u548c\u6307\u4ee4\u96c6\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u66f4\u9c81\u68d2\u3001\u66f4\u81ea\u4e3b\u7684\u5bfc\u822a\u6846\u67b6\u94fa\u5e73\u4e86\u9053\u8def\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709VLN\u65b9\u6cd5\u5728\u771f\u5b9e\u4e16\u754c\u5e94\u7528\u4e2d\u7684\u6311\u6218\u3002"}}
{"id": "2509.10196", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2509.10196", "abs": "https://arxiv.org/abs/2509.10196", "authors": ["Minghao Mi", "Ben Wang", "Lijian Zhang"], "title": "Approaching the Multiparameter Quantum Cram\u00e9r-Rao Bound via Classical Correlation and Entangling Measurements", "comment": null, "summary": "Multiparameter quantum metrology is essential for a wide range of practical\napplications. However, simultaneously achieving the ultimate precision for all\nparameters, as prescribed by the quantum Cram\\'er-Rao bound (QCRB), remains a\nsignificant challenge. In this work, we propose a scheme termed local operation\nwith entangling measurements (LOEM) strategy, which leverages classically\ncorrelated orthogonal pure states combined with entangling measurements to\nattain the multiparameter QCRB. We experimentally validate this scheme using a\nquantum photonic system. Additionally, we employ iterative interactions to\ndemonstrate that the LOEM strategy can achieve the precision of Heisenberg\nscaling. By theoretically and experimentally demonstrating the saturation of\nthe multiparameter QCRB with the LOEM strategy, our work advances the practical\napplications of quantum metrology in multiparameter estimation.", "AI": {"tldr": "\u901a\u8fc7\u7ed3\u5408\u7ecf\u5178\u5173\u8054\u6b63\u4ea4\u7eaf\u6001\u548c\u7ea0\u7f20\u6d4b\u91cf\uff0c\u63d0\u51fa\u5e76\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u4e00\u79cd\u79f0\u4e3a\u5c40\u90e8\u64cd\u4f5c\u4e0e\u7ea0\u7f20\u6d4b\u91cf\uff08LOEM\uff09\u7684\u7b56\u7565\uff0c\u4ee5\u5b9e\u73b0\u591a\u53c2\u6570\u91cf\u5b50\u4f30\u8ba1\u4e2d\u7684\u91cf\u5b50Cram'er-Rao\u754c\uff08QCRB\uff09\u5e76\u8fbe\u5230\u6d77\u68ee\u5821\u7f29\u653e\u7cbe\u5ea6\u3002", "motivation": "\u5b9e\u73b0\u591a\u53c2\u6570\u91cf\u5b50\u4f30\u8ba1\u7684\u7ec8\u6781\u7cbe\u5ea6\uff0c\u5373\u91cf\u5b50Cram'er-Rao\u754c\uff08QCRB\uff09\uff0c\u662f\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u5173\u952e\u6311\u6218\u3002", "method": "\u63d0\u51fa\u5c40\u90e8\u64cd\u4f5c\u4e0e\u7ea0\u7f20\u6d4b\u91cf\uff08LOEM\uff09\u7b56\u7565\uff0c\u8be5\u7b56\u7565\u7ed3\u5408\u4e86\u7ecf\u5178\u5173\u8054\u6b63\u4ea4\u7eaf\u6001\u548c\u7ea0\u7f20\u6d4b\u91cf\u3002\u5728\u5149\u5b50\u7cfb\u7edf\u4e2d\u8fdb\u884c\u4e86\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u5e76\u5229\u7528\u8fed\u4ee3\u76f8\u4e92\u4f5c\u7528\u5c55\u793a\u4e86\u6d77\u68ee\u5821\u7f29\u653e\u7cbe\u5ea6\u3002", "result": "\u5b9e\u9a8c\u4e0a\u5b9e\u73b0\u4e86LOEM\u7b56\u7565\uff0c\u8bc1\u660e\u4e86\u5176\u80fd\u591f\u8fbe\u5230\u591a\u53c2\u6570QCRB\u7684\u7cbe\u5ea6\uff0c\u5e76\u901a\u8fc7\u8fed\u4ee3\u76f8\u4e92\u4f5c\u7528\u5b9e\u73b0\u4e86\u6d77\u68ee\u5821\u7f29\u653e\u3002", "conclusion": "LOEM\u7b56\u7565\u5728\u7406\u8bba\u548c\u5b9e\u9a8c\u4e0a\u90fd\u8bc1\u660e\u4e86\u5176\u80fd\u591f\u9971\u548c\u591a\u53c2\u6570QCRB\uff0c\u5e76\u53ef\u8fbe\u5230\u6d77\u68ee\u5821\u7f29\u653e\u7cbe\u5ea6\uff0c\u63a8\u52a8\u4e86\u591a\u53c2\u6570\u4f30\u8ba1\u4e2d\u91cf\u5b50\u8ba1\u91cf\u5b66\u7684\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2509.09731", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.09731", "abs": "https://arxiv.org/abs/2509.09731", "authors": ["Haiyang Yu", "Yuchuan Wu", "Fan Shi", "Lei Liao", "Jinghui Lu", "Xiaodong Ge", "Han Wang", "Minghan Zhuo", "Xuecheng Wu", "Xiang Fei", "Hao Feng", "Guozhi Tang", "An-Lan Wang", "Hanshen Zhu", "Yangfan He", "Quanhuan Liang", "Liyuan Meng", "Chao Feng", "Can Huang", "Jingqun Tang", "Bin Li"], "title": "Benchmarking Vision-Language Models on Chinese Ancient Documents: From OCR to Knowledge Reasoning", "comment": null, "summary": "Chinese ancient documents, invaluable carriers of millennia of Chinese\nhistory and culture, hold rich knowledge across diverse fields but face\nchallenges in digitization and understanding, i.e., traditional methods only\nscan images, while current Vision-Language Models (VLMs) struggle with their\nvisual and linguistic complexity. Existing document benchmarks focus on English\nprinted texts or simplified Chinese, leaving a gap for evaluating VLMs on\nancient Chinese documents. To address this, we present AncientDoc, the first\nbenchmark for Chinese ancient documents, designed to assess VLMs from OCR to\nknowledge reasoning. AncientDoc includes five tasks (page-level OCR, vernacular\ntranslation, reasoning-based QA, knowledge-based QA, linguistic variant QA) and\ncovers 14 document types, over 100 books, and about 3,000 pages. Based on\nAncientDoc, we evaluate mainstream VLMs using multiple metrics, supplemented by\na human-aligned large language model for scoring.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86AncientDoc\uff0c\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u5728\u4e2d\u6587\u53e4\u7c4d\u5904\u7406\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002", "motivation": "\u73b0\u6709\u7684\u6587\u6863\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u5173\u6ce8\u82f1\u6587\u5370\u5237\u6587\u672c\u6216\u7b80\u4f53\u4e2d\u6587\uff0c\u672a\u80fd\u5145\u5206\u8bc4\u4f30VLM\u5728\u5904\u7406\u89c6\u89c9\u548c\u8bed\u8a00\u590d\u6742\u5ea6\u90fd\u8f83\u9ad8\u7684\u4e2d\u6587\u53e4\u7c4d\u65b9\u9762\u7684\u80fd\u529b\u3002\u4e2d\u6587\u53e4\u7c4d\u662f\u627f\u8f7d\u4e2d\u534e\u5386\u53f2\u6587\u5316\u7684\u5b9d\u8d35\u8f7d\u4f53\uff0c\u4f46\u5176\u6570\u5b57\u5316\u548c\u7406\u89e3\u9762\u4e34\u6311\u6218\u3002", "method": "\u521b\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u4e94\u4e2a\u4efb\u52a1\uff08\u9875\u9762\u7ea7OCR\u3001\u767d\u8bdd\u7ffb\u8bd1\u3001\u63a8\u7406\u5f0f\u95ee\u7b54\u3001\u77e5\u8bc6\u5f0f\u95ee\u7b54\u3001\u6587\u5b57\u53d8\u4f53\u95ee\u7b54\uff09\u7684\u57fa\u51c6\u6d4b\u8bd5AncientDoc\uff0c\u8986\u76d614\u79cd\u6587\u6863\u7c7b\u578b\uff0c\u8d85\u8fc7100\u672c\u4e66\u7c4d\uff0c\u7ea63000\u9875\u3002\u5e76\u57fa\u4e8e\u6b64\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4f7f\u7528\u591a\u79cd\u6307\u6807\u8bc4\u4f30\u4e86\u4e3b\u6d41VLM\uff0c\u5e76\u5f15\u5165\u4e86\u4eba\u7c7b\u8bc4\u5206\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u8f85\u52a9\u8bc4\u5206\u3002", "result": "\uff08\u672a\u5728\u6458\u8981\u4e2d\u63d0\u4f9b\u5177\u4f53\u7ed3\u679c\uff0c\u4f46\u8868\u660e\u5df2\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8bc4\u4f30\u4e86\u4e3b\u6d41VLM\uff09", "conclusion": "\uff08\u672a\u5728\u6458\u8981\u4e2d\u63d0\u4f9b\u5177\u4f53\u7ed3\u8bba\uff0c\u4f46\u7814\u7a76\u65e8\u5728\u586b\u8865VLM\u5728\u4e2d\u6587\u53e4\u7c4d\u5904\u7406\u80fd\u529b\u8bc4\u4f30\u4e0a\u7684\u7a7a\u767d\uff0c\u5e76\u63a8\u52a8\u76f8\u5173\u6280\u672f\u53d1\u5c55\u3002\uff09"}}
{"id": "2509.10033", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10033", "abs": "https://arxiv.org/abs/2509.10033", "authors": ["Boya Ma", "Abram Magner", "Maxwell McNeil", "Petko Bogdanov"], "title": "Sparse Coding Representation of 2-way Data", "comment": null, "summary": "Sparse dictionary coding represents signals as linear combinations of a few\ndictionary atoms. It has been applied to images, time series, graph signals and\nmulti-way spatio-temporal data by jointly employing temporal and spatial\ndictionaries. Data-agnostic analytical dictionaries, such as the discrete\nFourier transform, wavelets and graph Fourier, have seen wide adoption due to\nefficient implementations and good practical performance. On the other hand,\ndictionaries learned from data offer sparser and more accurate solutions but\nrequire learning of both the dictionaries and the coding coefficients. This\nbecomes especially challenging for multi-dictionary scenarios since encoding\ncoefficients correspond to all atom combinations from the dictionaries. To\naddress this challenge, we propose a low-rank coding model for 2-dictionary\nscenarios and study its data complexity. Namely, we establish a bound on the\nnumber of samples needed to learn dictionaries that generalize to unseen\nsamples from the same distribution. We propose a convex relaxation solution,\ncalled AODL, whose exact solution we show also solves the original problem. We\nthen solve this relaxation via alternating optimization between the sparse\ncoding matrices and the learned dictionaries, which we prove to be convergent.\nWe demonstrate its quality for data reconstruction and missing value imputation\nin both synthetic and real-world datasets. For a fixed reconstruction quality,\nAODL learns up to 90\\% sparser solutions compared to non-low-rank and\nanalytical (fixed) dictionary baselines. In addition, the learned dictionaries\nreveal interpretable insights into patterns present within the samples used for\ntraining.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u4e24\u5b57\u5178\u573a\u666f\u7684\u4f4e\u79e9\u7f16\u7801\u6a21\u578bAODL\uff0c\u5e76\u901a\u8fc7\u4ea4\u66ff\u4f18\u5316\u8fdb\u884c\u6c42\u89e3\uff0c\u5728\u6570\u636e\u91cd\u5efa\u548c\u7f3a\u5931\u503c\u586b\u5145\u65b9\u9762\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u5b57\u5178\u5b66\u4e60\u65b9\u6cd5\u5728\u591a\u5b57\u5178\u573a\u666f\u4e0b\uff0c\u7f16\u7801\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\uff0c\u96be\u4ee5\u5b66\u4e60\u5230\u7a00\u758f\u4e14\u51c6\u786e\u7684\u8868\u793a\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u5b57\u5178\u573a\u666f\u4e0b\u7684\u4f4e\u79e9\u7f16\u7801\u6a21\u578bAODL\uff0c\u901a\u8fc7\u4ea4\u66ff\u4f18\u5316\u65b9\u6cd5\u5728\u7a00\u758f\u7f16\u7801\u77e9\u9635\u548c\u5b57\u5178\u4e4b\u95f4\u8fdb\u884c\u5b66\u4e60\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u6536\u655b\u6027\u3002\u540c\u65f6\uff0c\u7814\u7a76\u4e86\u5b66\u4e60\u5b57\u5178\u6240\u9700\u7684\u6570\u636e\u590d\u6742\u5ea6\u3002", "result": "AODL\u6a21\u578b\u53ef\u4ee5\u5c06\u6570\u636e\u91cd\u5efa\u8d28\u91cf\u63d0\u9ad890%\uff0c\u5b66\u4e60\u5230\u7684\u5b57\u5178\u80fd\u591f\u63ed\u793a\u6570\u636e\u4e2d\u7684\u53ef\u89e3\u91ca\u6a21\u5f0f\uff0c\u5e76\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u5728\u6570\u636e\u91cd\u5efa\u548c\u7f3a\u5931\u503c\u586b\u5145\u7684\u6709\u6548\u6027\u3002", "conclusion": "AODL\u6a21\u578b\u80fd\u591f\u5b66\u4e60\u5230\u7a00\u758f\u4e14\u53ef\u89e3\u91ca\u6027\u5f3a\u7684\u5b57\u5178\uff0c\u5728\u4fdd\u8bc1\u6570\u636e\u91cd\u5efa\u8d28\u91cf\u7684\u540c\u65f6\uff0c\u964d\u4f4e\u4e86\u5bf9\u6837\u672c\u6570\u91cf\u7684\u8981\u6c42\uff0c\u5e76\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u6027\u80fd\u3002"}}
{"id": "2509.09961", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.09961", "abs": "https://arxiv.org/abs/2509.09961", "authors": ["Tianqi Wei", "Xin Yu", "Zhi Chen", "Scott Chapman", "Zi Huang"], "title": "Augment to Segment: Tackling Pixel-Level Imbalance in Wheat Disease and Pest Segmentation", "comment": null, "summary": "Accurate segmentation of foliar diseases and insect damage in wheat is\ncrucial for effective crop management and disease control. However, the insect\ndamage typically occupies only a tiny fraction of annotated pixels. This\nextreme pixel-level imbalance poses a significant challenge to the segmentation\nperformance, which can result in overfitting to common classes and insufficient\nlearning of rare classes, thereby impairing overall performance. In this paper,\nwe propose a Random Projected Copy-and-Paste (RPCP) augmentation technique to\naddress the pixel imbalance problem. Specifically, we extract rare\ninsect-damage patches from annotated training images and apply random geometric\ntransformations to simulate variations. The transformed patches are then pasted\nin appropriate regions while avoiding overlaps with lesions or existing damaged\nregions. In addition, we apply a random projection filter to the pasted\nregions, refining local features and ensuring a natural blend with the new\nbackground. Experiments show that our method substantially improves\nsegmentation performance on the insect damage class, while maintaining or even\nslightly enhancing accuracy on other categories. Our results highlight the\neffectiveness of targeted augmentation in mitigating extreme pixel imbalance,\noffering a straightforward yet effective solution for agricultural segmentation\nproblems.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u968f\u673a\u6295\u5f71\u7c98\u8d34\uff08RPCP\uff09\u6570\u636e\u589e\u5f3a\u6280\u672f\uff0c\u4ee5\u89e3\u51b3\u5c0f\u9ea6\u53f6\u90e8\u75c5\u866b\u5bb3\u5206\u5272\u4e2d\u6781\u7aef\u50cf\u7d20\u4e0d\u5e73\u8861\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5bf9\u866b\u5bb3\u7c7b\u522b\u7684\u5206\u5272\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5bf9\u5176\u4ed6\u7c7b\u522b\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u5c0f\u9ea6\u53f6\u90e8\u75c5\u866b\u5bb3\u5206\u5272\u4e2d\u7684\u6781\u7aef\u50cf\u7d20\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u5373\u866b\u5bb3\u533a\u57df\u50cf\u7d20\u5360\u6bd4\u6781\u5c0f\uff0c\u5bfc\u81f4\u6a21\u578b\u8fc7\u62df\u5408\u5e38\u89c1\u7c7b\u522b\uff0c\u5ffd\u89c6\u7a00\u6709\u7c7b\u522b\uff0c\u5f71\u54cd\u6574\u4f53\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u968f\u673a\u6295\u5f71\u7c98\u8d34\uff08RPCP\uff09\u6570\u636e\u589e\u5f3a\u6280\u672f\u3002\u5177\u4f53\u65b9\u6cd5\u5305\u62ec\uff1a\u63d0\u53d6\u7a00\u6709\u866b\u5bb3\u6591\u5757\uff0c\u8fdb\u884c\u968f\u673a\u51e0\u4f55\u53d8\u6362\uff1b\u5c06\u53d8\u6362\u540e\u7684\u6591\u5757\u7c98\u8d34\u5230\u5408\u9002\u533a\u57df\uff0c\u907f\u514d\u91cd\u53e0\uff1b\u5bf9\u7c98\u8d34\u533a\u57df\u5e94\u7528\u968f\u673a\u6295\u5f71\u6ee4\u6ce2\uff0c\u4f18\u5316\u5c40\u90e8\u7279\u5f81\u5e76\u4f7f\u5176\u4e0e\u80cc\u666f\u878d\u5408\u3002", "result": "RPCP\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u866b\u5bb3\u7c7b\u522b\u7684\u5206\u5272\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u751a\u81f3\u7565\u5fae\u63d0\u9ad8\u4e86\u5176\u4ed6\u7c7b\u522b\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u76ee\u6807\u660e\u786e\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u80fd\u6709\u6548\u7f13\u89e3\u6781\u7aef\u50cf\u7d20\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u4e3a\u519c\u4e1a\u5206\u5272\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u800c\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.10229", "categories": ["quant-ph", "nlin.CD"], "pdf": "https://arxiv.org/pdf/2509.10229", "abs": "https://arxiv.org/abs/2509.10229", "authors": ["Athanasios C. Tzemos", "George Contopoulos", "Foivos Zanias"], "title": "Bohmian Chaos and Entanglement in a Two-Qubit System", "comment": "34 pages, 16 figures", "summary": "We study in detail the critical points of Bohmian flow, both in the inertial\nframe of reference (Y-points) and in the frames centered at the moving nodal\npoints of the guiding wavefunction (X-points), and analyze their role in the\nonset of chaos in a system of two entangled qubits. We find the distances\nbetween these critical points and a moving Bohmian particle at varying levels\nof entanglement, with particular emphasis on the times at which chaos arises.\nThen, we find why some trajectories are ordered, without any chaos. Finally, we\nexamine numerically how the Lyapunov Characteristic Number (LCN ) depends on\nthe degree of quantum entanglement. Our results indicate that increasing\nentanglement reduces the convergence time of the finite-time LCN of the chaotic\ntrajectories toward its final positive value.", "AI": {"tldr": "Bohmian\u6d41\u4e2d\u7684\u4e34\u754c\u70b9\uff08Y\u70b9\u548cX\u70b9\uff09\u5728\u5177\u6709\u4e0d\u540c\u7ea0\u7f20\u5ea6\u7684\u4e24\u91cf\u5b50\u6bd4\u7279\u7cfb\u7edf\u4e2d\u5f15\u53d1\u6df7\u6c8c\u7684\u4f5c\u7528\u3002", "motivation": "\u7814\u7a76Bohmian\u6d41\u4e2d\u7684\u4e34\u754c\u70b9\uff08Y\u70b9\u548cX\u70b9\uff09\u5728\u4e24\u91cf\u5b50\u6bd4\u7279\u7cfb\u7edf\u4e2d\u7684\u6df7\u6c8c\u8d77\u6e90\u3002", "method": "\u5206\u6790\u4e34\u754c\u70b9\u4e0eBohmian\u7c92\u5b50\u7684\u8ddd\u79bb\uff0c\u4ee5\u53ca\u6df7\u6c8c\u51fa\u73b0\u7684\u65f6\u673a\uff0c\u5e76\u6570\u503c\u7814\u7a76Lyapunov\u7279\u5f81\u6570\uff08LCN\uff09\u5982\u4f55\u968f\u91cf\u5b50\u7ea0\u7f20\u5ea6\u53d8\u5316\u3002", "result": "\u968f\u7740\u7ea0\u7f20\u5ea6\u7684\u589e\u52a0\uff0c\u6df7\u6c8c\u8f68\u8ff9\u7684\u6709\u9650\u65f6\u95f4LCN\u6536\u655b\u5230\u5176\u6700\u7ec8\u6b63\u503c\u7684\u6536\u655b\u65f6\u95f4\u51cf\u5c0f\u3002", "conclusion": "\u91cf\u5b50\u7ea0\u7f20\u5ea6\u7684\u589e\u52a0\u4f1a\u52a0\u901f\u6df7\u6c8c\u7684\u51fa\u73b0\uff0c\u8868\u73b0\u4e3aLCN\u6536\u655b\u65f6\u95f4\u7684\u51cf\u5c11\u3002"}}
{"id": "2509.09734", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.09734", "abs": "https://arxiv.org/abs/2509.09734", "authors": ["Zikang Guo", "Benfeng Xu", "Chiwei Zhu", "Wentao Hong", "Xiaorui Wang", "Zhendong Mao"], "title": "MCP-AgentBench: Evaluating Real-World Language Agent Performance with MCP-Mediated Tools", "comment": null, "summary": "The Model Context Protocol (MCP) is rapidly emerging as a pivotal open\nstandard, designed to enhance agent-tool integration and interoperability, and\nis positioned to unlock a new era of powerful, interconnected, and genuinely\nutilitarian agentic AI. However, despite MCP's growing adoption, existing\nbenchmarks often fail to capture real-world agent performance within this new\nparadigm, leading to a distorted perception of their true operational value and\nan inability to reliably differentiate proficiencies. To bridge this critical\nevaluation gap, we introduce MCP-AgentBench -- a comprehensive benchmark\nspecifically engineered to rigorously assess language agent capabilities in\nMCP-mediated tool interactions. Core contributions of MCP-AgentBench include:\nthe establishment of a robust MCP testbed comprising 33 operational servers\nwith 188 distinct tools; the development of a benchmark featuring 600\nsystematically designed queries distributed across 6 distinct categories of\nvarying interaction complexity; and the introduction of MCP-Eval, a novel\noutcome-oriented evaluation methodology prioritizing real-world task success.\nThrough extensive empirical evaluation of leading language agents, we provide\nfoundational insights. MCP-AgentBench aims to equip the research community with\na standardized and reliable framework to build, validate, and advance agents\ncapable of fully leveraging MCP's transformative benefits, thereby accelerating\nprogress toward truly capable and interoperable AI systems.", "AI": {"tldr": "MCP-AgentBench\u662f\u4e00\u4e2a\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u6a21\u578b\u5728MCP\u73af\u5883\u4e2d\u7684\u6027\u80fd\uff0c\u5b83\u5305\u542b\u4e00\u4e2a\u6d4b\u8bd5\u5e73\u53f0\u3001600\u4e2a\u67e5\u8be2\u548c\u4e00\u79cd\u65b0\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u65e8\u5728\u4fc3\u8fdbAI\u4ee3\u7406\u7684\u8fdb\u6b65\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u51c6\u6d4b\u8bd5\u65e0\u6cd5\u51c6\u786e\u8bc4\u4f30\u5728MCP\uff08\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\uff09\u65b0\u8303\u5f0f\u4e0b\u4ee3\u7406\u7684\u771f\u5b9e\u6027\u80fd\uff0c\u5bfc\u81f4\u5bf9\u5176\u4ef7\u503c\u7684\u8ba4\u77e5\u5b58\u5728\u504f\u5dee\uff0c\u5e76\u4e14\u96be\u4ee5\u533a\u5206\u4ee3\u7406\u7684\u719f\u7ec3\u7a0b\u5ea6\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u4e2a\u540d\u4e3aMCP-AgentBench\u7684\u5168\u9762\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u62ec\u4e00\u4e2a\u62e5\u670933\u4e2a\u670d\u52a1\u5668\u548c188\u4e2a\u5de5\u5177\u7684\u6d4b\u8bd5\u5e73\u53f0\uff0c\u8bbe\u8ba1\u4e86600\u4e2a\u5206\u5e03\u57286\u4e2a\u4e0d\u540c\u7c7b\u522b\u4e2d\u7684\u67e5\u8be2\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u6ce8\u91cd\u5b9e\u9645\u4efb\u52a1\u6210\u529f\u7684\u3001\u9762\u5411\u7ed3\u679c\u7684\u8bc4\u4f30\u65b9\u6cd5MCP-Eval\u3002", "result": "\u5bf9\u9886\u5148\u7684\u8bed\u8a00\u4ee3\u7406\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u63d0\u4f9b\u4e86\u57fa\u7840\u6027\u7684\u89c1\u89e3\u3002", "conclusion": "MCP-AgentBench\u65e8\u5728\u4e3a\u7814\u7a76\u793e\u533a\u63d0\u4f9b\u4e00\u4e2a\u6807\u51c6\u5316\u3001\u53ef\u9760\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u6784\u5efa\u3001\u9a8c\u8bc1\u548c\u6539\u8fdb\u80fd\u591f\u5145\u5206\u5229\u7528MCP\u4f18\u52bf\u7684\u4ee3\u7406\uff0c\u4ece\u800c\u52a0\u901f\u5b9e\u73b0\u771f\u6b63\u5f3a\u5927\u4e14\u53ef\u4e92\u64cd\u4f5c\u7684AI\u7cfb\u7edf\u3002"}}
{"id": "2509.10034", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10034", "abs": "https://arxiv.org/abs/2509.10034", "authors": ["Sahil Rajesh Dhayalkar"], "title": "Symbolic Feedforward Networks for Probabilistic Finite Automata: Exact Simulation and Learnability", "comment": "19 pages, 2 figures", "summary": "We present a formal and constructive theory showing that probabilistic finite\nautomata (PFAs) can be exactly simulated using symbolic feedforward neural\nnetworks. Our architecture represents state distributions as vectors and\ntransitions as stochastic matrices, enabling probabilistic state propagation\nvia matrix-vector products. This yields a parallel, interpretable, and\ndifferentiable simulation of PFA dynamics using soft updates-without\nrecurrence. We formally characterize probabilistic subset construction,\n$\\varepsilon$-closure, and exact simulation via layered symbolic computation,\nand prove equivalence between PFAs and specific classes of neural networks. We\nfurther show that these symbolic simulators are not only expressive but\nlearnable: trained with standard gradient descent-based optimization on labeled\nsequence data, they recover the exact behavior of ground-truth PFAs. This\nlearnability, formalized in Proposition 5.1, is the crux of this work. Our\nresults unify probabilistic automata theory with neural architectures under a\nrigorous algebraic framework, bridging the gap between symbolic computation and\ndeep learning.", "AI": {"tldr": "PFAs can be simulated by symbolic feedforward neural networks, which are learnable and equivalent to PFAs.", "motivation": "To bridge the gap between symbolic computation and deep learning by unifying probabilistic automata theory with neural architectures under a rigorous algebraic framework.", "method": "Representing state distributions as vectors and transitions as stochastic matrices, enabling probabilistic state propagation via matrix-vector products, and using symbolic simulators that are learnable with standard gradient descent.", "result": "Formal characterization of probabilistic subset construction, \u03b5-closure, and exact simulation via layered symbolic computation, proving equivalence between PFAs and specific classes of neural networks, and showing that these symbolic simulators recover the exact behavior of ground-truth PFAs when trained on labeled sequence data.", "conclusion": "The proposed neural network architecture provides a parallel, interpretable, and differentiable simulation of PFA dynamics without recurrence, and its learnability is a key contribution that unifies probabilistic automata theory with neural architectures."}}
{"id": "2509.09962", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.09962", "abs": "https://arxiv.org/abs/2509.09962", "authors": ["Anne Marthe Sophie Ngo Bibinbe", "Chiron Bang", "Patrick Gagnon", "Jamie Ahloy-Dallaire", "Eric R. Paquet"], "title": "An HMM-based framework for identity-aware long-term multi-object tracking from sparse and uncertain identification: use case on long-term tracking in livestock", "comment": "13 pages, 7 figures, 1 table, accepted at CVPR animal workshop 2024,\n  submitted to IJCV", "summary": "The need for long-term multi-object tracking (MOT) is growing due to the\ndemand for analyzing individual behaviors in videos that span several minutes.\nUnfortunately, due to identity switches between objects, the tracking\nperformance of existing MOT approaches decreases over time, making them\ndifficult to apply for long-term tracking. However, in many real-world\napplications, such as in the livestock sector, it is possible to obtain\nsporadic identifications for some of the animals from sources like feeders. To\naddress the challenges of long-term MOT, we propose a new framework that\ncombines both uncertain identities and tracking using a Hidden Markov Model\n(HMM) formulation. In addition to providing real-world identities to animals,\nour HMM framework improves the F1 score of ByteTrack, a leading MOT approach\neven with re-identification, on a 10 minute pig tracking dataset with 21\nidentifications at the pen's feeding station. We also show that our approach is\nrobust to the uncertainty of identifications, with performance increasing as\nidentities are provided more frequently. The improved performance of our HMM\nframework was also validated on the MOT17 and MOT20 benchmark datasets using\nboth ByteTrack and FairMOT. The code for this new HMM framework and the new\n10-minute pig tracking video dataset are available at:\nhttps://github.com/ngobibibnbe/uncertain-identity-aware-tracking", "AI": {"tldr": "\u73b0\u6709\u7684\u957f\u671f\u591a\u76ee\u6807\u8ddf\u8e2a\uff08MOT\uff09\u65b9\u6cd5\u7531\u4e8e\u8eab\u4efd\u5207\u6362\u95ee\u9898\uff0c\u8ddf\u8e2a\u6027\u80fd\u4f1a\u968f\u65f6\u95f4\u4e0b\u964d\uff0c\u96be\u4ee5\u6ee1\u8db3\u957f\u65f6\u8ddf\u8e2a\u9700\u6c42\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4e0d\u786e\u5b9a\u8eab\u4efd\u4e0e\u8ddf\u8e2a\u7684\u9690\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\uff08HMM\uff09\u6846\u67b6\uff0c\u4ee5\u89e3\u51b3\u957f\u65f6 MOT \u7684\u6311\u6218\u3002", "motivation": "\u73b0\u6709MOT\u65b9\u6cd5\u5728\u957f\u671f\u8ddf\u8e2a\u65f6\uff0c\u7531\u4e8e\u8eab\u4efd\u5207\u6362\u95ee\u9898\uff0c\u6027\u80fd\u4f1a\u4e0b\u964d\u3002\u8bb8\u591a\u5b9e\u9645\u5e94\u7528\uff08\u5982\u755c\u7267\u4e1a\uff09\u53ef\u4ee5\u4ece\u9972\u5582\u5668\u7b49\u6765\u6e90\u83b7\u5f97\u52a8\u7269\u7684\u96f6\u661f\u8eab\u4efd\u4fe1\u606f\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5904\u7406\u4e0d\u786e\u5b9a\u8eab\u4efd\u4fe1\u606f\u7684\u957f\u671fMOT\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4e0d\u786e\u5b9a\u8eab\u4efd\u4e0e\u8ddf\u8e2a\u7684\u9690\u9a6c\u5c14\u53ef\u5728\u6a21\u578b\uff08HMM\uff09\u6846\u67b6\u3002\u8be5\u6846\u67b6\u5229\u7528\u96f6\u661f\u7684\u8eab\u4efd\u4fe1\u606f\u6765\u63d0\u9ad8\u8ddf\u8e2a\u6027\u80fd\u3002", "result": "\u5728\u4e3a\u671f10\u5206\u949f\u3001\u5305\u542b21\u4e2a\u8eab\u4efd\u8bc6\u522b\u7684\u732a\u8ddf\u8e2a\u6570\u636e\u96c6\u4e0a\uff0c\u8be5HMM\u6846\u67b6\u5c06\u9886\u5148\u7684MOT\u65b9\u6cd5ByteTrack\u7684F1\u5206\u6570\u63d0\u9ad8\u4e8610%\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u5728MOT17\u548cMOT20\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u4f7f\u7528ByteTrack\u548cFairMOT\u8fdb\u884c\u4e86\u9a8c\u8bc1\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u5bf9\u8eab\u4efd\u8bc6\u522b\u4e0d\u786e\u5b9a\u6027\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684HMM\u6846\u67b6\u80fd\u591f\u6709\u6548\u89e3\u51b3\u957f\u671f\u591a\u76ee\u6807\u8ddf\u8e2a\u4e2d\u7684\u8eab\u4efd\u5207\u6362\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5728\u8eab\u4efd\u4fe1\u606f\u4e0d\u786e\u5b9a\u6216\u7a00\u758f\u7684\u60c5\u51b5\u4e0b\u3002\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u8ddf\u8e2a\u6027\u80fd\uff0c\u800c\u4e14\u4e3a\u755c\u7267\u4e1a\u7b49\u9886\u57df\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.10231", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2509.10231", "abs": "https://arxiv.org/abs/2509.10231", "authors": ["Ayan Kumar Nai", "Gopal Prasad Sahu", "Rutuj Gharate", "C. M. Chandrashekar", "G. K. Samanta"], "title": "Beam-splitter-free, high-rate quantum key distribution inspired by intrinsic quantum mechanical spatial randomness of entangled photons", "comment": null, "summary": "Quantum key distribution (QKD) using entangled photon sources (EPS) is a\ncornerstone of secure communication. Despite rapid advances in QKD,\nconventional protocols still employ beam splitters (BSs) for passive random\nbasis selection. However, BSs intrinsically suffer from photon loss, imperfect\nsplitting ratios, and polarization dependence, limiting the key rate,\nincreasing the quantum bit error rate (QBER), and constraining scalability,\nparticularly over long distances. By contrast, EPSs based on spontaneous\nparametric down-conversion (SPDC) intrinsically exhibit quantum randomness in\nspatial and spectral degrees of freedom, offering a natural replacement for BSs\nin basis selection. Here, we demonstrate a proof-of-concept\nspatial-randomness-based QKD scheme in which the annular SPDC emission ring is\ndivided into four sections, effectively generating two independent EPSs. pair\nphotons from these sources, distributed to Alice and Bob, enable H/V and D/A\nmeasurements. The quantum-random pair generation inherently mimics the\nstochastic basis choice otherwise performed by a BS. Experimentally, our scheme\nachieves a 6.4-fold enhancement in sifted key rate, a consistently reduced\nQBER, and a near-ideal encoding balance between logical bits 0 and 1.\nFurthermore, the need for four spatial channels can be avoided by employing\nwavelength demultiplexing to generate two EPSs at distinct wavelength pairs.\nHarnessing intrinsic spatial/spectral randomness thus enables robust,\nbias-free, high-rate, and low-QBER QKD, offering a scalable pathway for\nnext-generation quantum networks.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u7a7a\u95f4\u968f\u673a\u6027\u8fdb\u884c\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\uff08QKD\uff09\u7684\u65b0\u65b9\u6848\uff0c\u901a\u8fc7\u5206\u5272\u81ea\u53d1\u53c2\u91cf\u4e0b\u8f6c\u6362\uff08SPDC\uff09\u7684\u73af\u72b6\u53d1\u5c04\uff0c\u751f\u6210\u4e24\u4e2a\u72ec\u7acb\u7684\u7ea0\u7f20\u5149\u5b50\u6e90\uff08EPS\uff09\uff0c\u4ece\u800c\u66ff\u4ee3\u4f20\u7edf\u7684\u6613\u635f\u8017\u3001\u5b58\u5728\u504f\u632f\u4f9d\u8d56\u6027\u7684\u5206\u675f\u5668\uff08BS\uff09\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u5bc6\u94a5\u751f\u6210\u7387\u3001\u66f4\u4f4e\u7684\u91cf\u5b50\u6bd4\u7279\u9519\u8bef\u7387\uff08QBER\uff09\uff0c\u5e76\u5177\u5907\u66f4\u597d\u7684\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u57fa\u4e8e\u5206\u675f\u5668\uff08BS\uff09\u7684\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\uff08QKD\uff09\u534f\u8bae\u5b58\u5728\u5149\u5b50\u635f\u8017\u3001\u5206\u5149\u6bd4\u4e0d\u5b8c\u7f8e\u548c\u504f\u632f\u4f9d\u8d56\u6027\u7b49\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5bc6\u94a5\u901f\u7387\u3001\u589e\u52a0\u4e86\u91cf\u5b50\u6bd4\u7279\u9519\u8bef\u7387\uff08QBER\uff09\uff0c\u5e76\u5236\u7ea6\u4e86\u5176\u5728\u957f\u8ddd\u79bb\u901a\u4fe1\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7a7a\u95f4\u968f\u673a\u6027\u7684QKD\u65b9\u6848\uff0c\u901a\u8fc7\u5206\u5272SPDC\u4ea7\u751f\u7684\u73af\u72b6\u5149\uff0c\u751f\u6210\u4e24\u4e2a\u72ec\u7acb\u7684EPS\u3002\u8fd9\u4e24\u4e2aEPS\u80fd\u591f\u5206\u522b\u63d0\u4f9bH/V\u548cD/A\u6d4b\u91cf\uff0c\u5229\u7528\u4e86SPDC\u5185\u5728\u7684\u91cf\u5b50\u968f\u673a\u6027\u6765\u6a21\u62df\u4f20\u7edf\u65b9\u6848\u4e2dBS\u7684\u529f\u80fd\u3002\u5b9e\u9a8c\u4e0a\u901a\u8fc7\u5c06\u73af\u72b6SPDC\u53d1\u5c04\u5206\u5272\u6210\u56db\u4e2a\u90e8\u5206\u6765\u5b9e\u73b0\u3002", "result": "\u8be5\u65b9\u6848\u5b9e\u73b0\u4e866.4\u500d\u7684\u7b5b\u9009\u5bc6\u94a5\u7387\u63d0\u5347\uff0c\u6301\u7eed\u964d\u4f4e\u4e86QBER\uff0c\u5e76\u5b9e\u73b0\u4e86\u903b\u8f91\u6bd4\u72790\u548c1\u4e4b\u95f4\u63a5\u8fd1\u7406\u60f3\u7684\u7f16\u7801\u5e73\u8861\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u63d0\u51fa\u53ef\u4ee5\u901a\u8fc7\u5229\u7528\u6ce2\u957f\u590d\u7528\u6280\u672f\u907f\u514d\u4f7f\u7528\u56db\u4e2a\u7a7a\u95f4\u901a\u9053\uff0c\u4ece\u800c\u751f\u6210\u4e24\u4e2a\u4e0d\u540c\u6ce2\u957f\u5bf9\u7684EPS\u3002", "conclusion": "\u5229\u7528SPDC\u5185\u5728\u7684\u7a7a\u95f4/\u5149\u8c31\u968f\u673a\u6027\u53ef\u4ee5\u5b9e\u73b0\u9c81\u68d2\u3001\u65e0\u504f\u3001\u9ad8\u7801\u7387\u3001\u4f4eQBER\u7684QKD\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u91cf\u5b50\u7f51\u7edc\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.09735", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.09735", "abs": "https://arxiv.org/abs/2509.09735", "authors": ["Willem Huijzer", "Jieying Chen"], "title": "Discrimination by LLMs: Cross-lingual Bias Assessment and Mitigation in Decision-Making and Summarisation", "comment": "7 pages", "summary": "The rapid integration of Large Language Models (LLMs) into various domains\nraises concerns about societal inequalities and information bias. This study\nexamines biases in LLMs related to background, gender, and age, with a focus on\ntheir impact on decision-making and summarization tasks. Additionally, the\nresearch examines the cross-lingual propagation of these biases and evaluates\nthe effectiveness of prompt-instructed mitigation strategies. Using an adapted\nversion of the dataset by Tamkin et al. (2023) translated into Dutch, we\ncreated 151,200 unique prompts for the decision task and 176,400 for the\nsummarisation task. Various demographic variables, instructions, salience\nlevels, and languages were tested on GPT-3.5 and GPT-4o. Our analysis revealed\nthat both models were significantly biased during decision-making, favouring\nfemale gender, younger ages, and certain backgrounds such as the\nAfrican-American background. In contrast, the summarisation task showed minimal\nevidence of bias, though significant age-related differences emerged for\nGPT-3.5 in English. Cross-lingual analysis showed that bias patterns were\nbroadly similar between English and Dutch, though notable differences were\nobserved across specific demographic categories. The newly proposed mitigation\ninstructions, while unable to eliminate biases completely, demonstrated\npotential in reducing them. The most effective instruction achieved a 27\\% mean\nreduction in the gap between the most and least favorable demographics.\nNotably, contrary to GPT-3.5, GPT-4o displayed reduced biases for all prompts\nin English, indicating the specific potential for prompt-based mitigation\nwithin newer models. This research underscores the importance of cautious\nadoption of LLMs and context-specific bias testing, highlighting the need for\ncontinued development of effective mitigation strategies to ensure responsible\ndeployment of AI.", "AI": {"tldr": "LLMs\u5728\u51b3\u7b56\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4e0e\u6027\u522b\u3001\u5e74\u9f84\u548c\u80cc\u666f\u76f8\u5173\u7684\u504f\u89c1\uff0c\u4f46\u5728\u6458\u8981\u4efb\u52a1\u4e2d\u504f\u89c1\u8f83\u5c11\u3002\u8de8\u8bed\u8a00\u5206\u6790\u663e\u793a\u82f1\u8bed\u548c\u8377\u5170\u8bed\u4e4b\u95f4\u5b58\u5728\u76f8\u4f3c\u7684\u504f\u89c1\u6a21\u5f0f\u3002\u63d0\u51fa\u7684\u7f13\u89e3\u7b56\u7565\u5728\u51cf\u5c11\u504f\u89c1\u65b9\u9762\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u5c24\u5176\u662f\u5728GPT-4o\u6a21\u578b\u4e0a\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5404\u4e2a\u9886\u57df\u7684\u5feb\u901f\u5e94\u7528\uff0c\u4eba\u4eec\u5bf9\u5176\u53ef\u80fd\u52a0\u5267\u793e\u4f1a\u4e0d\u5e73\u7b49\u548c\u4fe1\u606f\u504f\u89c1\u7684\u95ee\u9898\u65e5\u76ca\u62c5\u5fe7\u3002\u672c\u7814\u7a76\u65e8\u5728\u6df1\u5165\u63a2\u8ba8LLMs\u5728\u80cc\u666f\u3001\u6027\u522b\u548c\u5e74\u9f84\u65b9\u9762\u5b58\u5728\u7684\u504f\u89c1\uff0c\u5e76\u91cd\u70b9\u5206\u6790\u8fd9\u4e9b\u504f\u89c1\u5bf9\u51b3\u7b56\u548c\u6458\u8981\u4efb\u52a1\u7684\u5f71\u54cd\uff0c\u540c\u65f6\u8003\u5bdf\u504f\u89c1\u7684\u8de8\u8bed\u8a00\u4f20\u64ad\u73b0\u8c61\uff0c\u5e76\u8bc4\u4f30\u6307\u4ee4\u63d0\u793a\u7f13\u89e3\u7b56\u7565\u7684\u6709\u6548\u6027\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u4e86Tamkin\u7b49\u4eba\uff082023\uff09\u6539\u7f16\u5e76\u7ffb\u8bd1\u6210\u8377\u5170\u8bed\u7684\u6570\u636e\u96c6\uff0c\u6784\u5efa\u4e86\u7528\u4e8e\u51b3\u7b56\u4efb\u52a1\u7684151,200\u4e2a\u72ec\u7279\u63d0\u793a\u548c\u7528\u4e8e\u6458\u8981\u4efb\u52a1\u7684176,400\u4e2a\u72ec\u7279\u63d0\u793a\u3002\u7814\u7a76\u5728GPT-3.5\u548cGPT-4o\u6a21\u578b\u4e0a\u6d4b\u8bd5\u4e86\u591a\u79cd\u4eba\u53e3\u7edf\u8ba1\u53d8\u91cf\u3001\u6307\u4ee4\u3001\u663e\u8457\u6027\u6c34\u5e73\u548c\u8bed\u8a00\u3002", "result": "\u5206\u6790\u7ed3\u679c\u663e\u793a\uff0c\u5728\u51b3\u7b56\u4efb\u52a1\u4e2d\uff0cGPT-3.5\u548cGPT-4o\u5747\u8868\u73b0\u51fa\u663e\u8457\u504f\u89c1\uff0c\u503e\u5411\u4e8e\u652f\u6301\u5973\u6027\u3001\u5e74\u8f7b\u5e74\u9f84\u4ee5\u53ca\u7279\u5b9a\u80cc\u666f\uff08\u5982\u975e\u88d4\u7f8e\u56fd\u4eba\uff09\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u6458\u8981\u4efb\u52a1\u4e2d\u7684\u504f\u89c1\u8bc1\u636e\u8f83\u5c11\uff0c\u5c3d\u7ba1\u5728\u82f1\u8bed\u4e2dGPT-3.5\u5728\u5e74\u9f84\u65b9\u9762\u8868\u73b0\u51fa\u663e\u8457\u5dee\u5f02\u3002\u8de8\u8bed\u8a00\u5206\u6790\u8868\u660e\uff0c\u82f1\u8bed\u548c\u8377\u5170\u8bed\u4e4b\u95f4\u7684\u504f\u89c1\u6a21\u5f0f\u5927\u4f53\u76f8\u4f3c\uff0c\u4f46\u5728\u7279\u5b9a\u4eba\u53e3\u7edf\u8ba1\u7c7b\u522b\u4e0a\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002\u65b0\u63d0\u51fa\u7684\u7f13\u89e3\u6307\u4ee4\u867d\u7136\u672a\u80fd\u5b8c\u5168\u6d88\u9664\u504f\u89c1\uff0c\u4f46\u663e\u793a\u51fa\u51cf\u5c11\u504f\u89c1\u7684\u6f5c\u529b\uff0c\u6700\u6709\u6548\u7684\u6307\u4ee4\u4f7f\u6700\u6709\u5229\u548c\u6700\u4e0d\u5229\u4eba\u53e3\u7edf\u8ba1\u7fa4\u4f53\u4e4b\u95f4\u7684\u5dee\u8ddd\u5e73\u5747\u51cf\u5c11\u4e8627%\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u4e0eGPT-3.5\u4e0d\u540c\uff0cGPT-4o\u5728\u6240\u6709\u82f1\u8bed\u63d0\u793a\u4e2d\u8868\u73b0\u51fa\u66f4\u5c11\u7684\u504f\u89c1\uff0c\u8fd9\u8868\u660e\u5728\u66f4\u65b0\u7684\u6a21\u578b\u4e2d\uff0c\u57fa\u4e8e\u63d0\u793a\u7684\u7f13\u89e3\u7b56\u7565\u5177\u6709\u7279\u5b9a\u6f5c\u529b\u3002", "conclusion": "\u672c\u7814\u7a76\u5f3a\u8c03\u4e86\u5728\u5ba1\u614e\u91c7\u7528LLMs\u7684\u540c\u65f6\uff0c\u8fdb\u884c\u7279\u5b9a\u60c5\u5883\u4e0b\u504f\u89c1\u6d4b\u8bd5\u7684\u91cd\u8981\u6027\uff0c\u5e76\u6307\u51fa\u4e86\u6301\u7eed\u5f00\u53d1\u6709\u6548\u7f13\u89e3\u7b56\u7565\u4ee5\u786e\u4fdd\u8d1f\u8d23\u4efb\u5730\u90e8\u7f72\u4eba\u5de5\u667a\u80fd\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2509.10041", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10041", "abs": "https://arxiv.org/abs/2509.10041", "authors": ["Mohammad Hasan Narimani", "Mostafa Tavassolipour"], "title": "FedRP: A Communication-Efficient Approach for Differentially Private Federated Learning Using Random Projection", "comment": null, "summary": "Federated learning (FL) offers an innovative paradigm for collaborative model\ntraining across decentralized devices, such as smartphones, balancing enhanced\npredictive performance with the protection of user privacy in sensitive areas\nlike Internet of Things (IoT) and medical data analysis. Despite its\nadvantages, FL encounters significant challenges related to user privacy\nprotection against potential attacks and the management of communication costs.\nThis paper introduces a novel federated learning algorithm called FedRP, which\nintegrates random projection techniques with the Alternating Direction Method\nof Multipliers (ADMM) optimization framework. This approach enhances privacy by\nemploying random projection to reduce the dimensionality of model parameters\nprior to their transmission to a central server, reducing the communication\ncost. The proposed algorithm offers a strong $(\\epsilon, \\delta)$-differential\nprivacy guarantee, demonstrating resilience against data reconstruction\nattacks. Experimental results reveal that FedRP not only maintains high model\naccuracy but also outperforms existing methods, including conventional\ndifferential privacy approaches and FedADMM, in terms of both privacy\npreservation and communication efficiency.", "AI": {"tldr": "FedRP\u7b97\u6cd5\u901a\u8fc7\u968f\u673a\u6295\u5f71\u548cADMM\u4f18\u5316\u6846\u67b6\uff0c\u5728\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u548c\u964d\u4f4e\u901a\u4fe1\u6210\u672c\u7684\u540c\u65f6\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u51c6\u786e\u6027\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u5728\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u548c\u7ba1\u7406\u901a\u4fe1\u6210\u672c\u65b9\u9762\u9762\u4e34\u7684\u6311\u6218\uff0c\u4ee5\u5728\u654f\u611f\u9886\u57df\uff08\u5982\u7269\u8054\u7f51\u548c\u533b\u7597\u6570\u636e\u5206\u6790\uff09\u5b9e\u73b0\u9ad8\u6548\u7684\u534f\u540c\u6a21\u578b\u8bad\u7ec3\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFedRP\u7684\u65b0\u578b\u8054\u90a6\u5b66\u4e60\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u7ed3\u5408\u4e86\u968f\u673a\u6295\u5f71\u6280\u672f\u548c\u4ea4\u66ff\u65b9\u5411\u4e58\u5b50\u6cd5\uff08ADMM\uff09\u4f18\u5316\u6846\u67b6\u3002FedRP\u901a\u8fc7\u968f\u673a\u6295\u5f71\u964d\u4f4e\u6a21\u578b\u53c2\u6570\u7684\u7ef4\u5ea6\u6765\u51cf\u5c11\u901a\u4fe1\u6210\u672c\uff0c\u5e76\u63d0\u4f9b$(\\epsilon, \\delta)$-\u5dee\u5206\u9690\u79c1\u4fdd\u8bc1\uff0c\u4ee5\u9632\u5fa1\u6570\u636e\u91cd\u5efa\u653b\u51fb\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cFedRP\u5728\u6a21\u578b\u51c6\u786e\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u4e14\u5728\u9690\u79c1\u4fdd\u62a4\u548c\u901a\u4fe1\u6548\u7387\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u7684\u65b9\u6cd5\uff0c\u5305\u62ec\u4f20\u7edf\u7684\u5dee\u5206\u9690\u79c1\u65b9\u6cd5\u548cFedADMM\u3002", "conclusion": "FedRP\u7b97\u6cd5\u6210\u529f\u5730\u5728\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u548c\u964d\u4f4e\u901a\u4fe1\u6210\u672c\u7684\u540c\u65f6\uff0c\u4fdd\u6301\u4e86\u9ad8\u6c34\u5e73\u7684\u6a21\u578b\u51c6\u786e\u6027\uff0c\u4e3a\u8054\u90a6\u5b66\u4e60\u5728\u5904\u7406\u654f\u611f\u6570\u636e\u65b9\u9762\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.09971", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.09971", "abs": "https://arxiv.org/abs/2509.09971", "authors": ["Aupendu Kar", "Vishnu Raj", "Guan-Ming Su"], "title": "Event Camera Guided Visual Media Restoration & 3D Reconstruction: A Survey", "comment": null, "summary": "Event camera sensors are bio-inspired sensors which asynchronously capture\nper-pixel brightness changes and output a stream of events encoding the\npolarity, location and time of these changes. These systems are witnessing\nrapid advancements as an emerging field, driven by their low latency, reduced\npower consumption, and ultra-high capture rates. This survey explores the\nevolution of fusing event-stream captured with traditional frame-based capture,\nhighlighting how this synergy significantly benefits various video restoration\nand 3D reconstruction tasks. The paper systematically reviews major deep\nlearning contributions to image/video enhancement and restoration, focusing on\ntwo dimensions: temporal enhancement (such as frame interpolation and motion\ndeblurring) and spatial enhancement (including super-resolution, low-light and\nHDR enhancement, and artifact reduction). This paper also explores how the 3D\nreconstruction domain evolves with the advancement of event driven fusion.\nDiverse topics are covered, with in-depth discussions on recent works for\nimproving visual quality under challenging conditions. Additionally, the survey\ncompiles a comprehensive list of openly available datasets, enabling\nreproducible research and benchmarking. By consolidating recent progress and\ninsights, this survey aims to inspire further research into leveraging event\ncamera systems, especially in combination with deep learning, for advanced\nvisual media restoration and enhancement.", "AI": {"tldr": "\u672c\u6587\u5bf9\u4e8b\u4ef6\u76f8\u673a\u4e0e\u4f20\u7edf\u5e27\u5f0f\u76f8\u673a\u878d\u5408\u6280\u672f\u5728\u89c6\u9891\u590d\u539f\u548c\u4e09\u7ef4\u91cd\u5efa\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u8fdb\u884c\u4e86\u7efc\u8ff0\uff0c\u91cd\u70b9\u5173\u6ce8\u4e86\u6df1\u5ea6\u5b66\u4e60\u5728\u8be5\u9886\u57df\u7684\u8d21\u732e\uff0c\u5e76\u6574\u7406\u4e86\u76f8\u5173\u516c\u5f00\u6570\u636e\u96c6\u3002", "motivation": "\u4e8b\u4ef6\u76f8\u673a\u56e0\u5176\u4f4e\u5ef6\u8fdf\u3001\u4f4e\u529f\u8017\u548c\u9ad8\u5e27\u7387\u7b49\u7279\u6027\uff0c\u5728\u89c6\u9891\u590d\u539f\u548c\u4e09\u7ef4\u91cd\u5efa\u7b49\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u4e0e\u4f20\u7edf\u5e27\u5f0f\u76f8\u673a\u7684\u878d\u5408\u66f4\u662f\u80fd\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "method": "\u672c\u6587\u7cfb\u7edf\u5730\u56de\u987e\u4e86\u6df1\u5ea6\u5b66\u4e60\u5728\u56fe\u50cf/\u89c6\u9891\u589e\u5f3a\u548c\u590d\u539f\u9886\u57df\u7684\u8d21\u732e\uff0c\u4ece\u65f6\u95f4\u589e\u5f3a\uff08\u5982\u5e27\u63d2\u503c\u3001\u8fd0\u52a8\u53bb\u6a21\u7cca\uff09\u548c\u7a7a\u95f4\u589e\u5f3a\uff08\u5982\u8d85\u5206\u8fa8\u7387\u3001\u4f4e\u5149\u548cHDR\u589e\u5f3a\u3001\u4f2a\u5f71\u6d88\u9664\uff09\u4e24\u4e2a\u7ef4\u5ea6\u8fdb\u884c\u4e86\u68b3\u7406\u3002\u540c\u65f6\uff0c\u63a2\u8ba8\u4e86\u4e8b\u4ef6\u9a71\u52a8\u878d\u5408\u6280\u672f\u5728\u4e09\u7ef4\u91cd\u5efa\u9886\u57df\u7684\u53d1\u5c55\u3002", "result": "\u8be5\u7efc\u8ff0\u6df1\u5165\u63a2\u8ba8\u4e86\u5728\u6311\u6218\u6027\u6761\u4ef6\u4e0b\u63d0\u5347\u89c6\u89c9\u8d28\u91cf\u7684\u6700\u65b0\u7814\u7a76\u8fdb\u5c55\uff0c\u5e76\u6c47\u96c6\u4e86\u53ef\u516c\u5f00\u83b7\u53d6\u7684\u6570\u636e\u96c6\uff0c\u4ee5\u4fc3\u8fdb\u53ef\u590d\u73b0\u7684\u7814\u7a76\u548c\u57fa\u51c6\u6d4b\u8bd5\u3002", "conclusion": "\u901a\u8fc7\u6574\u5408\u8fd1\u671f\u5728\u4e8b\u4ef6\u76f8\u673a\u878d\u5408\u3001\u6df1\u5ea6\u5b66\u4e60\u4ee5\u53ca\u89c6\u89c9\u5a92\u4f53\u590d\u539f\u548c\u589e\u5f3a\u9886\u57df\u7684\u8fdb\u5c55\u4e0e\u89c1\u89e3\uff0c\u672c\u6587\u65e8\u5728\u6fc0\u53d1\u66f4\u591a\u76f8\u5173\u7814\u7a76\u3002"}}
{"id": "2509.09801", "categories": ["cs.CL", "cs.AI", "cs.LG", "68T07, 68T50, 68T05", "I.2.7; I.2.6; C.4"], "pdf": "https://arxiv.org/pdf/2509.09801", "abs": "https://arxiv.org/abs/2509.09801", "authors": ["Brennen Hill"], "title": "HEFT: A Coarse-to-Fine Hierarchy for Enhancing the Efficiency and Accuracy of Language Model Reasoning", "comment": null, "summary": "The adaptation of large language models (LLMs) to specialized reasoning tasks\nis fundamentally constrained by computational resources. Parameter-Efficient\nFine-Tuning (PEFT) methods have emerged as a powerful solution, yet the\nlandscape of these techniques is diverse, with distinct methods operating in\neither the model's weight space or its representation space. This paper\ninvestigates the hypothesis that a synergistic combination of these paradigms\ncan unlock superior performance and efficiency. We introduce HEFT (Hierarchical\nEfficient Fine-Tuning), a novel hierarchical adaptation strategy that composes\ntwo distinct PEFT methods in a coarse-to-fine manner: first, a broad,\nfoundational adaptation in the weight space using Low-Rank Adaptation (LoRA),\nfollowed by a precise, surgical refinement of internal activations using\nRepresentation Fine-Tuning (ReFT). We evaluate this approach by fine-tuning a\nLlama-2-7B model on the BoolQ benchmark, a challenging dataset for inferential\nreasoning. Our results reveal a profound synergistic effect. A model fine-tuned\nfor only three epochs with our HEFT strategy achieves an accuracy of 85.17\\%,\nexceeding the performance of models trained for 20 epochs with either LoRA-only\n(85.05\\%) or ReFT-only (83.36\\%) methodologies. This work demonstrates that the\nthoughtful composition of PEFT methods is a potent algorithmic innovation,\noffering a more efficient and effective path toward advancing the reasoning\ncapabilities of language models. By achieving superior results with a fraction\nof the computational budget, our findings present a principled approach to\novercoming the obstacles inherent in adapting large-scale models for complex\ncognitive tasks.", "AI": {"tldr": "\u901a\u8fc7\u7ed3\u5408\u6743\u91cd\u7a7a\u95f4\uff08LoRA\uff09\u548c\u8868\u793a\u7a7a\u95f4\uff08ReFT\uff09\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff08PEFT\uff09\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aHEFT\u7684\u5206\u5c42\u9002\u5e94\u7b56\u7565\uff0c\u8be5\u7b56\u7565\u80fd\u4ee5\u66f4\u5c11\u7684\u8ba1\u7b97\u8d44\u6e90\u5b9e\u73b0\u66f4\u4f18\u7684\u6027\u80fd\u3002", "motivation": "LLM\u5728\u4e13\u4e1a\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u9002\u5e94\u6027\u53d7\u8ba1\u7b97\u8d44\u6e90\u9650\u5236\uff0cPEFT\u65b9\u6cd5\u867d\u662f\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u5b58\u5728\u6743\u91cd\u7a7a\u95f4\u548c\u8868\u793a\u7a7a\u95f4\u4e24\u79cd\u4e0d\u540c\u8303\u5f0f\uff0c\u63a2\u7d22\u4e24\u8005\u7ed3\u5408\u7684\u6f5c\u529b\u3002", "method": "\u63d0\u51faHEFT\u5206\u5c42\u9002\u5e94\u7b56\u7565\uff0c\u5148\u5728\u6743\u91cd\u7a7a\u95f4\u4f7f\u7528LoRA\u8fdb\u884c\u57fa\u7840\u9002\u5e94\uff0c\u518d\u5728\u8868\u793a\u7a7a\u95f4\u4f7f\u7528ReFT\u8fdb\u884c\u7cbe\u7ec6\u8c03\u6574\u3002", "result": "\u5728BoolQ\u57fa\u51c6\u4e0a\uff0cHEFT\u7b56\u7565\u4ec5\u75283\u4e2aepoch\u5c31\u80fd\u8fbe\u523085.17%\u7684\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u5355\u72ec\u4f7f\u7528LoRA\uff0820\u4e2aepoch\uff0c85.05%\uff09\u6216ReFT\uff0820\u4e2aepoch\uff0c83.36%\uff09\u7684\u6a21\u578b\u3002", "conclusion": "HEFT\u7b56\u7565\u901a\u8fc7\u5206\u5c42\u7ec4\u5408\u4e0d\u540c\u7684PEFT\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u63d0\u5347LLM\u63a8\u7406\u80fd\u529b\u65b9\u9762\u7684\u6709\u6548\u6027\u548c\u6548\u7387\uff0c\u4ee5\u66f4\u5c11\u7684\u8ba1\u7b97\u6210\u672c\u514b\u670d\u4e86\u6a21\u578b\u9002\u5e94\u7684\u6311\u6218\u3002"}}
{"id": "2509.10048", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10048", "abs": "https://arxiv.org/abs/2509.10048", "authors": ["Madhushan Ramalingam"], "title": "Uncertainty-Aware Tabular Prediction: Evaluating VBLL-Enhanced TabPFN in Safety-Critical Medical Data", "comment": null, "summary": "Predictive models are being increasingly used across a wide range of domains,\nincluding safety-critical applications such as medical diagnosis and criminal\njustice. Reliable uncertainty estimation is a crucial task in such settings.\nTabular Prior-data Fitted Network (TabPFN) is a recently proposed machine\nlearning foundation model for tabular dataset, which uses a generative\ntransformer architecture. Variational Bayesian Last Layers (VBLL) is a\nstate-of-the-art lightweight variational formulation that effectively improves\nuncertainty estimation with minimal computational overhead. In this work we aim\nto evaluate the performance of VBLL integrated with the recently proposed\nTabPFN in uncertainty calibration. Our experiments, conducted on three\nbenchmark medical tabular datasets, compare the performance of the original\nTabPFN and the VBLL-integrated version. Contrary to expectations, we observed\nthat original TabPFN consistently outperforms VBLL integrated TabPFN in\nuncertainty calibration across all datasets.", "AI": {"tldr": "\u539f\u59cbTabPFN\u5728\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\u65b9\u9762\u4f18\u4e8e\u96c6\u6210VBLL\u7684\u7248\u672c\uff0c\u5c3d\u7ba1VBLL\u65e8\u5728\u63d0\u9ad8\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u5728\u5b89\u5168\u5173\u952e\u9886\u57df\uff08\u5982\u533b\u5b66\u8bca\u65ad\u548c\u5211\u4e8b\u53f8\u6cd5\uff09\u4e2d\u4f7f\u7528\u9884\u6d4b\u6a21\u578b\u65f6\uff0c\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u81f3\u5173\u91cd\u8981\u3002\u672c\u7814\u7a76\u65e8\u5728\u8bc4\u4f30\u5c06VBLL\u96c6\u6210\u5230TabPFN\u4e2d\u5728\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\u65b9\u9762\u7684\u8868\u73b0\u3002", "method": "\u5c06VBLL\uff08\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u53d8\u5206\u65b9\u6cd5\uff09\u96c6\u6210\u5230TabPFN\uff08\u4e00\u79cd\u7528\u4e8e\u8868\u683c\u6570\u636e\u7684\u751f\u6210Transformer\u67b6\u6784\uff09\u4e2d\uff0c\u5e76\u5728\u4e09\u4e2a\u57fa\u51c6\u7684\u533b\u5b66\u8868\u683c\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u6bd4\u8f83\u539f\u59cbTabPFN\u548c\u96c6\u6210VBLL\u7684TabPFN\u5728\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\u65b9\u9762\u7684\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728\u6240\u6709\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\uff0c\u539f\u59cbTabPFN\u5728\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\u65b9\u9762\u59cb\u7ec8\u4f18\u4e8e\u96c6\u6210VBLL\u7684TabPFN\uff0c\u8fd9\u4e0e\u9884\u671f\u76f8\u53cd\u3002", "conclusion": "\u5c3d\u7ba1VBLL\u65e8\u5728\u63d0\u9ad8\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u4f46\u5728\u6b64\u6b21\u7814\u7a76\u7684\u7279\u5b9a\u8bbe\u7f6e\uff08\u96c6\u6210\u5230TabPFN\u7528\u4e8e\u8868\u683c\u6570\u636e\u7684\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\uff09\u4e2d\uff0c\u5b83\u5e76\u672a\u80fd\u5e26\u6765\u9884\u671f\u7684\u6027\u80fd\u63d0\u5347\uff0c\u751a\u81f3\u53ef\u80fd\u635f\u5bb3\u4e86\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\u7684\u6027\u80fd\u3002"}}
{"id": "2509.09977", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.09977", "abs": "https://arxiv.org/abs/2509.09977", "authors": ["Siying Liu", "Zikai Wang", "Hanle Zheng", "Yifan Hu", "Xilin Wang", "Qingkai Yang", "Jibin Wu", "Hao Guo", "Lei Deng"], "title": "ISTASTrack: Bridging ANN and SNN via ISTA Adapter for RGB-Event Tracking", "comment": "15 pages, 8 figures", "summary": "RGB-Event tracking has become a promising trend in visual object tracking to\nleverage the complementary strengths of both RGB images and dynamic spike\nevents for improved performance. However, existing artificial neural networks\n(ANNs) struggle to fully exploit the sparse and asynchronous nature of event\nstreams. Recent efforts toward hybrid architectures combining ANNs and spiking\nneural networks (SNNs) have emerged as a promising solution in RGB-Event\nperception, yet effectively fusing features across heterogeneous paradigms\nremains a challenge. In this work, we propose ISTASTrack, the first\ntransformer-based \\textbf{A}NN-\\textbf{S}NN hybrid \\textbf{Track}er equipped\nwith \\textbf{ISTA} adapters for RGB-Event tracking. The two-branch model\nemploys a vision transformer to extract spatial context from RGB inputs and a\nspiking transformer to capture spatio-temporal dynamics from event streams. To\nbridge the modality and paradigm gap between ANN and SNN features, we\nsystematically design a model-based ISTA adapter for bidirectional feature\ninteraction between the two branches, derived from sparse representation theory\nby unfolding the iterative shrinkage thresholding algorithm. Additionally, we\nincorporate a temporal downsampling attention module within the adapter to\nalign multi-step SNN features with single-step ANN features in the latent\nspace, improving temporal fusion. Experimental results on RGB-Event tracking\nbenchmarks, such as FE240hz, VisEvent, COESOT, and FELT, have demonstrated that\nISTASTrack achieves state-of-the-art performance while maintaining high energy\nefficiency, highlighting the effectiveness and practicality of hybrid ANN-SNN\ndesigns for robust visual tracking. The code is publicly available at\nhttps://github.com/lsying009/ISTASTrack.git.", "AI": {"tldr": "ISTASTrack\u662f\u9996\u4e2a\u7ed3\u5408Transformer\u548cISTA\u9002\u914d\u5668\u7684RGB-Event\u8ddf\u8e2a\u5668\uff0c\u901a\u8fc7\u878d\u5408RGB\u56fe\u50cf\u548c\u4e8b\u4ef6\u6d41\u7684\u7279\u5f81\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u548c\u9ad8\u80fd\u6548\u3002", "motivation": "\u73b0\u6709\u7684RGB-Event\u8ddf\u8e2a\u65b9\u6cd5\u96be\u4ee5\u5145\u5206\u5229\u7528\u4e8b\u4ef6\u6d41\u7684\u7a00\u758f\u548c\u5f02\u6b65\u7279\u6027\uff0c\u5e76\u4e14\u5728\u878d\u5408\u4e0d\u540c\u8303\u5f0f\uff08ANN\u548cSNN\uff09\u7684\u7279\u5f81\u65f6\u5b58\u5728\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aISTASTrack\u7684\u6df7\u5408\u6a21\u578b\uff0c\u5b83\u7ed3\u5408\u4e86\u7528\u4e8eRGB\u8f93\u5165\u7684\u89c6\u89c9Transformer\u548c\u7528\u4e8e\u4e8b\u4ef6\u6d41\u7684\u8109\u51b2Transformer\u3002\u901a\u8fc7\u8bbe\u8ba1\u57fa\u4e8eISTA\u9002\u914d\u5668\u7684\u53cc\u5411\u7279\u5f81\u4ea4\u4e92\u673a\u5236\uff0c\u5e76\u5f15\u5165\u65f6\u95f4\u964d\u91c7\u6837\u6ce8\u610f\u529b\u6a21\u5757\u6765\u5bf9\u9f50\u591a\u6b65SNN\u7279\u5f81\u548c\u5355\u6b65ANN\u7279\u5f81\uff0c\u5b9e\u73b0\u4e86\u8de8\u6a21\u6001\u548c\u8de8\u8303\u5f0f\u7684\u7279\u5f81\u878d\u5408\u3002", "result": "\u5728FE240hz\u3001VisEvent\u3001COESOT\u548cFELT\u7b49RGB-Event\u8ddf\u8e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cISTASTrack\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u9ad8\u80fd\u6548\u3002", "conclusion": "ISTASTrack\u7684\u6df7\u5408ANN-SNN\u8bbe\u8ba1\u5728\u9c81\u68d2\u7684\u89c6\u89c9\u8ddf\u8e2a\u65b9\u9762\u662f\u6709\u6548\u4e14\u5b9e\u7528\u7684\u3002"}}
{"id": "2509.10286", "categories": ["quant-ph", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2509.10286", "abs": "https://arxiv.org/abs/2509.10286", "authors": ["Rafael D. Soares", "J. M. Viana Parente Lopes", "Hugo Ter\u00e7as"], "title": "Tunable Magnetic Order in Chiral Coupled Spin Chains", "comment": "17 pages; 17 Figures. Comments are welcome", "summary": "We obtain the ground-state phase diagram of two spin chains consisting in a\nset two-level systems asymmetrically coupled to an XX chain through a chiral\ninteraction. The interaction is parametrized by its magnitude and an angle\ndefined by the relative orientation of the spins in different chains. From the\nentanglement spectrum, we identify the critical lines separating distinct\nmagnetically ordered phases, with the interaction angle able to shift or fully\nsuppress the transition. By increasing the coupling strength, the systems is\ndriven through a quantum phase transition, leading to the formation of two\ntypes of in-plane antiferromagnetic stripes. The interaction strength sets\nstripe formation, while the angle controls the spins orientations. The chiral\ninteraction also induces a non-trivial finite vector spin chirality with\nopposite orientation on the chains. We show that the vector spin chirality\nemerges smoothly from the decoupled limit and occurs for angles different from\nzero and $\\pi/2$, where collinear order is favored instead.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u4e24\u4e2a\u81ea\u65cb\u94fe\u901a\u8fc7\u624b\u5f81\u76f8\u4e92\u4f5c\u7528\u4e0d\u5bf9\u79f0\u8026\u5408\u5230XX\u94fe\u7684\u57fa\u6001\u76f8\u56fe\uff0c\u5e76\u8bc6\u522b\u4e86\u5206\u79bb\u4e0d\u540c\u78c1\u6709\u5e8f\u76f8\u7684\u5173\u952e\u7ebf\u3002", "motivation": "\u7814\u7a76\u4e24\u4e2a\u81ea\u65cb\u94fe\u901a\u8fc7\u624b\u5f81\u76f8\u4e92\u4f5c\u7528\u4e0d\u5bf9\u79f0\u8026\u5408\u5230XX\u94fe\u7684\u57fa\u6001\u76f8\u56fe\uff0c\u8bc6\u522b\u4e34\u754c\u7ebf\uff0c\u5e76\u5206\u6790\u76f8\u4e92\u4f5c\u7528\u89d2\u5ea6\u548c\u8026\u5408\u5f3a\u5ea6\u5bf9\u76f8\u53d8\u548c\u78c1\u6709\u5e8f\u884c\u4e3a\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u7ea0\u7f20\u8c31\u8bc6\u522b\u4e34\u754c\u7ebf\uff0c\u5e76\u5206\u6790\u4e86\u76f8\u4e92\u4f5c\u7528\u89d2\u5ea6\u548c\u8026\u5408\u5f3a\u5ea6\u5bf9\u76f8\u53d8\u548c\u78c1\u6709\u5e8f\u884c\u4e3a\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0\u76f8\u4e92\u4f5c\u7528\u89d2\u5ea6\u53ef\u4ee5\u79fb\u52a8\u6216\u5b8c\u5168\u6291\u5236\u76f8\u53d8\uff1b\u8026\u5408\u5f3a\u5ea6\u589e\u52a0\u4f1a\u5bfc\u81f4\u91cf\u5b50\u76f8\u53d8\uff0c\u5f62\u6210\u4e24\u79cd\u9762\u5185\u53cd\u94c1\u78c1\u6761\u7eb9\uff1b\u5411\u91cf\u81ea\u65cb\u624b\u6027\u968f\u7740\u89d2\u5ea6\u7684\u53d8\u5316\u800c\u51fa\u73b0\u3002", "conclusion": "\u624b\u5f81\u76f8\u4e92\u4f5c\u7528\u8bf1\u5bfc\u4e86\u975e\u5e73\u51e1\u7684\u6709\u9650\u5411\u91cf\u81ea\u65cb\u624b\u6027\uff0c\u5e76\u8868\u660e\u5411\u91cf\u81ea\u65cb\u624b\u6027\u5728\u975e\u96f6\u548c\u03c0/2\u7684\u89d2\u5ea6\u4e0b\u51fa\u73b0\uff0c\u800c\u5728\u8fd9\u4e9b\u89d2\u5ea6\u4e0b\u6709\u5229\u4e8e\u5171\u7ebf\u5e8f\u3002"}}
{"id": "2509.09804", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.09804", "abs": "https://arxiv.org/abs/2509.09804", "authors": ["Helen de Andrade Abreu", "Tiago Timponi Torrent", "Ely Edison da Silva Matos"], "title": "Pragmatic Frames Evoked by Gestures: A FrameNet Brasil Approach to Multimodality in Turn Organization", "comment": "Paper submitted to Language Sciences Journal", "summary": "This paper proposes a framework for modeling multimodal conversational turn\norganization via the proposition of correlations between language and\ninteractive gestures, based on analysis as to how pragmatic frames are\nconceptualized and evoked by communicators. As a means to provide evidence for\nthe analysis, we developed an annotation methodology to enrich a multimodal\ndataset (annotated for semantic frames) with pragmatic frames modeling\nconversational turn organization. Although conversational turn organization has\nbeen studied by researchers from diverse fields, the specific strategies,\nespecially gestures used by communicators, had not yet been encoded in a\ndataset that can be used for machine learning. To fill this gap, we enriched\nthe Frame2 dataset with annotations of gestures used for turn organization. The\nFrame2 dataset features 10 episodes from the Brazilian TV series Pedro Pelo\nMundo annotated for semantic frames evoked in both video and text. This dataset\nallowed us to closely observe how communicators use interactive gestures\noutside a laboratory, in settings, to our knowledge, not previously recorded in\nrelated literature. Our results have confirmed that communicators involved in\nface-to-face conversation make use of gestures as a tool for passing, taking\nand keeping conversational turns, and also revealed variations of some gestures\nthat had not been documented before. We propose that the use of these gestures\narises from the conceptualization of pragmatic frames, involving mental spaces,\nblending and conceptual metaphors. In addition, our data demonstrate that the\nannotation of pragmatic frames contributes to a deeper understanding of human\ncognition and language.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u8bed\u8a00\u548c\u4e92\u52a8\u59ff\u52bf\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u6765\u6a21\u62df\u591a\u6a21\u6001\u5bf9\u8bdd\u8f6e\u6b21\u7ec4\u7ec7\uff08turn organization\uff09\u7684\u6846\u67b6\u3002", "motivation": "\u5bf9\u8bdd\u8f6e\u6b21\u7ec4\u7ec7\uff08turn organization\uff09\u5df2\u88ab\u591a\u4e2a\u9886\u57df\u7684\u7814\u7a76\u8005\u7814\u7a76\uff0c\u4f46\u7279\u522b\u662f\u624b\u52bf\uff0c\u5c1a\u672a\u88ab\u7f16\u7801\u5230\u53ef\u7528\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u6570\u636e\u96c6\u4e2d\uff0c\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u63d0\u51fa\u8bed\u8a00\u548c\u4e92\u52a8\u59ff\u52bf\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u6765\u6784\u5efa\u4e00\u4e2a\u591a\u6a21\u6001\u5bf9\u8bdd\u8f6e\u6b21\u7ec4\u7ec7\u7684\u6a21\u578b\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u79cd\u6ce8\u91ca\u65b9\u6cd5\u5b66\uff0c\u4ee5\u4e30\u5bcc\u4e00\u4e2a\u5305\u542b\u8bed\u4e49\u5e27\u6ce8\u91ca\u7684\u591a\u6a21\u6001\u6570\u636e\u96c6\uff08Frame2\uff09\uff0c\u52a0\u5165\u5bf9\u8bdd\u8f6e\u6b21\u7ec4\u7ec7\u7684\u8bed\u7528\u5e27\uff08pragmatic frames\uff09\u6ce8\u91ca\uff0c\u7279\u522b\u662f\u624b\u52bf\u6ce8\u91ca\u3002", "result": "\u7ed3\u679c\u8bc1\u5b9e\uff0c\u9762\u5bf9\u9762\u5bf9\u8bdd\u4e2d\u7684\u4ea4\u6d41\u8005\u786e\u5b9e\u4f1a\u4f7f\u7528\u624b\u52bf\u6765\u4f20\u9012\u3001\u63a5\u53d6\u548c\u7ef4\u6301\u5bf9\u8bdd\u8f6e\u6b21\uff0c\u5e76\u4e14\u8fd8\u53d1\u73b0\u4e86\u5148\u524d\u672a\u6709\u6587\u6863\u8bb0\u8f7d\u7684\u4e00\u4e9b\u624b\u52bf\u53d8\u4f53\u3002", "conclusion": "\u4ea4\u6d41\u8005\u4f7f\u7528\u624b\u52bf\u7684\u884c\u4e3a\u6e90\u4e8e\u8bed\u7528\u5e27\uff08pragmatic frames\uff09\u7684\u6982\u5ff5\u5316\uff0c\u8fd9\u6d89\u53ca\u5230\u5fc3\u667a\u7a7a\u95f4\uff08mental spaces\uff09\u3001\u6df7\u5408\uff08blending\uff09\u548c\u6982\u5ff5\u9690\u55bb\uff08conceptual metaphors\uff09\u3002\u6b64\u5916\uff0c\u7814\u7a76\u6570\u636e\u8868\u660e\uff0c\u8bed\u7528\u5e27\u7684\u6ce8\u91ca\u6709\u52a9\u4e8e\u66f4\u6df1\u5165\u5730\u7406\u89e3\u4eba\u7c7b\u8ba4\u77e5\u548c\u8bed\u8a00\u3002"}}
{"id": "2509.10089", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10089", "abs": "https://arxiv.org/abs/2509.10089", "authors": ["Marco Andrea B\u00fchler", "Gonzalo Guill\u00e9n-Gos\u00e1lbez"], "title": "KAN-SR: A Kolmogorov-Arnold Network Guided Symbolic Regression Framework", "comment": null, "summary": "We introduce a novel symbolic regression framework, namely KAN-SR, built on\nKolmogorov Arnold Networks (KANs) which follows a divide-and-conquer approach.\nSymbolic regression searches for mathematical equations that best fit a given\ndataset and is commonly solved with genetic programming approaches. We show\nthat by using deep learning techniques, more specific KANs, and combining them\nwith simplification strategies such as translational symmetries and\nseparabilities, we are able to recover ground-truth equations of the Feynman\nSymbolic Regression for Scientific Discovery (SRSD) dataset. Additionally, we\nshow that by combining the proposed framework with neural controlled\ndifferential equations, we are able to model the dynamics of an in-silico\nbioprocess system precisely, opening the door for the dynamic modeling of other\nengineering systems.", "AI": {"tldr": "KAN-SR\u662f\u4e00\u4e2a\u57fa\u4e8eKolmogorov Arnold Networks\uff08KANs\uff09\u7684\u7b26\u53f7\u56de\u5f52\u6846\u67b6\uff0c\u5b83\u91c7\u7528\u5206\u800c\u6cbb\u4e4b\u7684\u65b9\u6cd5\uff0c\u5e76\u7ed3\u5408\u4e86\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u548c\u7b80\u5316\u7b56\u7565\uff0c\u6210\u529f\u5730\u4eceFeynman SRSD\u6570\u636e\u96c6\u4e2d\u6062\u590d\u4e86\u771f\u5b9e\u65b9\u7a0b\u3002\u6b64\u5916\uff0c\u8be5\u6846\u67b6\u4e0e\u795e\u7ecf\u63a7\u5236\u5fae\u5206\u65b9\u7a0b\u7ed3\u5408\uff0c\u80fd\u591f\u7cbe\u786e\u6a21\u62df\u751f\u7269\u8fc7\u7a0b\u7cfb\u7edf\u52a8\u529b\u5b66\u3002", "motivation": "\u7b26\u53f7\u56de\u5f52\u65e8\u5728\u5bfb\u627e\u6700\u9002\u5408\u7ed9\u5b9a\u6570\u636e\u96c6\u7684\u6570\u5b66\u65b9\u7a0b\uff0c\u4f20\u7edf\u65b9\u6cd5\u5e38\u91c7\u7528\u9057\u4f20\u7f16\u7a0b\u3002\u672c\u7814\u7a76\u65e8\u5728\u5229\u7528\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\uff0c\u7279\u522b\u662fKANs\uff0c\u5e76\u7ed3\u5408\u7b80\u5316\u7b56\u7565\uff0c\u6765\u6539\u8fdb\u7b26\u53f7\u56de\u5f52\u7684\u6548\u679c\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aKAN-SR\u7684\u65b0\u578b\u7b26\u53f7\u56de\u5f52\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u57fa\u4e8eKolmogorov Arnold Networks\uff08KANs\uff09\uff0c\u5e76\u91c7\u7528\u5206\u800c\u6cbb\u4e4b\u7684\u65b9\u6cd5\u3002\u8be5\u6846\u67b6\u7ed3\u5408\u4e86\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u3001KANs\u7684\u7279\u5b9a\u5e94\u7528\u4ee5\u53ca\u5e73\u79fb\u5bf9\u79f0\u6027\u548c\u53ef\u5206\u79bb\u6027\u7b49\u7b80\u5316\u7b56\u7565\u3002\u6b64\u5916\uff0c\u8fd8\u5c06\u8be5\u6846\u67b6\u4e0e\u795e\u7ecf\u63a7\u5236\u5fae\u5206\u65b9\u7a0b\u76f8\u7ed3\u5408\u3002", "result": "KAN-SR\u80fd\u591f\u4eceFeynman SRSD\u6570\u636e\u96c6\u4e2d\u6062\u590d\u51fa\u771f\u5b9e\u7684\u6570\u5b66\u65b9\u7a0b\u3002\u5f53\u4e0e\u795e\u7ecf\u63a7\u5236\u5fae\u5206\u65b9\u7a0b\u7ed3\u5408\u65f6\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u7cbe\u786e\u5730\u6a21\u62df\u4e00\u4e2a\u8ba1\u7b97\u673a\u751f\u7269\u8fc7\u7a0b\u7cfb\u7edf\uff08in-silico bioprocess system\uff09\u7684\u52a8\u529b\u5b66\u3002", "conclusion": "KAN-SR\u6846\u67b6\u5728\u7b26\u53f7\u56de\u5f52\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u6210\u529f\uff0c\u80fd\u591f\u6062\u590d\u771f\u5b9e\u65b9\u7a0b\u3002\u6b64\u5916\uff0c\u5b83\u5728\u6a21\u62df\u751f\u7269\u8fc7\u7a0b\u7cfb\u7edf\u52a8\u529b\u5b66\u65b9\u9762\u4e5f\u8868\u73b0\u51fa\u7cbe\u786e\u6027\uff0c\u4e3a\u5de5\u7a0b\u9886\u57df\u5176\u4ed6\u52a8\u6001\u7cfb\u7edf\u7684\u5efa\u6a21\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2509.09988", "categories": ["cs.CV", "astro-ph.SR"], "pdf": "https://arxiv.org/pdf/2509.09988", "abs": "https://arxiv.org/abs/2509.09988", "authors": ["Yusuke Takagi", "Shunya Nagashima", "Komei Sugiura"], "title": "FLARE-SSM: Deep State Space Models with Influence-Balanced Loss for 72-Hour Solar Flare Prediction", "comment": "Accepted for presentation at ICONIP2025", "summary": "Accurate and reliable solar flare predictions are essential to mitigate\npotential impacts on critical infrastructure. However, the current performance\nof solar flare forecasting is insufficient. In this study, we address the task\nof predicting the class of the largest solar flare expected to occur within the\nnext 72 hours. Existing methods often fail to adequately address the severe\nclass imbalance across flare classes. To address this issue, we propose a solar\nflare prediction model based on multiple deep state space models. In addition,\nwe introduce the frequency & local-boundary-aware reliability loss (FLARE loss)\nto improve predictive performance and reliability under class imbalance.\nExperiments were conducted on a multi-wavelength solar image dataset covering a\nfull 11-year solar activity cycle. As a result, our method outperformed\nbaseline approaches in terms of both the Gandin-Murphy-Gerrity score and the\ntrue skill statistic, which are standard metrics in terms of the performance\nand reliability.", "AI": {"tldr": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u91cd\u6df1\u5ea6\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u5e76\u5f15\u5165\u4e86FLARE loss\u6765\u89e3\u51b3\u592a\u9633\u8000\u6591\u7c7b\u522b\u4e0d\u5e73\u8861\u7684\u95ee\u9898\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u76ee\u524d\u7684\u592a\u9633\u8000\u6591\u9884\u6d4b\u6a21\u578b\u5728\u5904\u7406\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u5f71\u54cd\u4e86\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u591a\u91cd\u6df1\u5ea6\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u7684\u592a\u9633\u8000\u6591\u9884\u6d4b\u6a21\u578b\uff0c\u5e76\u5f15\u5165\u9891\u7387\u4e0e\u5c40\u90e8\u8fb9\u754c\u611f\u77e5\u53ef\u9760\u6027\u635f\u5931\uff08FLARE loss\uff09\u6765\u5904\u7406\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u4ee5Gandin-Murphy-Gerrity\u5206\u6570\u548c\u771f\u5b9e\u6280\u80fd\u7edf\u8ba1\u91cf\u4e3a\u6807\u51c6\u7684\u5b9e\u9a8c\u4e2d\uff0c\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u591a\u91cd\u6df1\u5ea6\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u548cFLARE loss\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63d0\u9ad8\u592a\u9633\u8000\u6591\u9884\u6d4b\u7684\u6027\u80fd\u548c\u53ef\u9760\u6027\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u7c7b\u522b\u4e0d\u5e73\u8861\u7684\u60c5\u51b5\u4e0b\u3002"}}
{"id": "2509.10021", "categories": ["cs.CV", "cs.RO", "eess.IV"], "pdf": "https://arxiv.org/pdf/2509.10021", "abs": "https://arxiv.org/abs/2509.10021", "authors": ["Jonas K\u00fchne", "Christian Vogt", "Michele Magno", "Luca Benini"], "title": "Efficient and Accurate Downfacing Visual Inertial Odometry", "comment": "This article has been accepted for publication in the IEEE Internet\n  of Things Journal (IoT-J)", "summary": "Visual Inertial Odometry (VIO) is a widely used computer vision method that\ndetermines an agent's movement through a camera and an IMU sensor. This paper\npresents an efficient and accurate VIO pipeline optimized for applications on\nmicro- and nano-UAVs. The proposed design incorporates state-of-the-art feature\ndetection and tracking methods (SuperPoint, PX4FLOW, ORB), all optimized and\nquantized for emerging RISC-V-based ultra-low-power parallel systems on chips\n(SoCs). Furthermore, by employing a rigid body motion model, the pipeline\nreduces estimation errors and achieves improved accuracy in planar motion\nscenarios. The pipeline's suitability for real-time VIO is assessed on an\nultra-low-power SoC in terms of compute requirements and tracking accuracy\nafter quantization. The pipeline, including the three feature tracking methods,\nwas implemented on the SoC for real-world validation. This design bridges the\ngap between high-accuracy VIO pipelines that are traditionally run on\ncomputationally powerful systems and lightweight implementations suitable for\nmicrocontrollers. The optimized pipeline on the GAP9 low-power SoC demonstrates\nan average reduction in RMSE of up to a factor of 3.65x over the baseline\npipeline when using the ORB feature tracker. The analysis of the computational\ncomplexity of the feature trackers further shows that PX4FLOW achieves on-par\ntracking accuracy with ORB at a lower runtime for movement speeds below 24\npixels/frame.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7cbe\u786e\u7684\u89c6\u89c9\u60ef\u6027\u91cc\u7a0b\u8ba1\uff08VIO\uff09\u6d41\u7a0b\uff0c\u9488\u5bf9\u5fae\u578b\u548c\u7eb3\u7c73\u65e0\u4eba\u673a\u8fdb\u884c\u4e86\u4f18\u5316\uff0c\u9002\u7528\u4e8e\u4f4e\u529f\u8017RISC-V SoC\u3002", "motivation": "\u4e3a\u4e86\u5f25\u5408\u4f20\u7edf\u9ad8\u7cbe\u5ea6VIO\u7cfb\u7edf\u548c\u9002\u7528\u4e8e\u5fae\u63a7\u5236\u5668\u7684\u8f7b\u91cf\u7ea7\u5b9e\u73b0\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u7279\u522b\u662f\u5728\u5fae\u578b\u548c\u7eb3\u7c73\u65e0\u4eba\u673a\u5e94\u7528\u573a\u666f\u4e0b\u3002", "method": "\u8be5\u65b9\u6cd5\u91c7\u7528\u5148\u8fdb\u7684\u7279\u5f81\u68c0\u6d4b\u548c\u8ddf\u8e2a\u6280\u672f\uff08SuperPoint\u3001PX4FLOW\u3001ORB\uff09\uff0c\u5e76\u9488\u5bf9RISC-V\u4f4e\u529f\u8017\u5e76\u884c\u7cfb\u7edf\u8fdb\u884c\u4e86\u4f18\u5316\u548c\u91cf\u5316\u3002\u901a\u8fc7\u4f7f\u7528\u521a\u4f53\u8fd0\u52a8\u6a21\u578b\uff0c\u51cf\u5c11\u4e86\u4f30\u8ba1\u8bef\u5dee\uff0c\u63d0\u9ad8\u4e86\u5e73\u9762\u8fd0\u52a8\u573a\u666f\u7684\u7cbe\u5ea6\u3002\u5728\u4f4e\u529f\u8017SoC\u4e0a\u8fdb\u884c\u4e86\u5b9e\u65f6\u8bc4\u4f30\u3002", "result": "\u5728GAP9\u4f4e\u529f\u8017SoC\u4e0a\uff0c\u4e0e\u57fa\u7ebf\u6d41\u7a0b\u76f8\u6bd4\uff0c\u4f7f\u7528ORB\u7279\u5f81\u8ddf\u8e2a\u5668\u53ef\u5c06RMSE\u5e73\u5747\u964d\u4f4e\u9ad8\u8fbe3.65\u500d\u3002PX4FLOW\u5728\u4f4e\u4e8e24\u50cf\u7d20/\u5e27\u7684\u79fb\u52a8\u901f\u5ea6\u4e0b\uff0c\u5b9e\u73b0\u4e86\u4e0eORB\u76f8\u5f53\u7684\u8ddf\u8e2a\u7cbe\u5ea6\uff0c\u4f46\u8fd0\u884c\u65f6\u66f4\u4f4e\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684VIO\u6d41\u7a0b\u5728\u4f4e\u529f\u8017\u786c\u4ef6\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u7cbe\u786e\u7684\u8fd0\u52a8\u4f30\u8ba1\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u7684\u65e0\u4eba\u673a\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.10347", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2509.10347", "abs": "https://arxiv.org/abs/2509.10347", "authors": ["Matee ur Rehman", "Paul Winter", "Fabio Revuelta", "Alejandro Saenz"], "title": "Confined few-particle systems beyond mean-field theory adopting Gaussian-type orbitals and Morse interparticle interaction", "comment": null, "summary": "Recent advancements in optical tweezers enable the trapping of arbitrary\nnumbers of neutral atoms and molecules, even arrays of tweezers with variable\ngeometry can be realized. These fascinating breakthroughs require novel\nfull-dimensional beyond mean-field treatments for systems with more than two\nconfined particles spread over traps that are arranged arbitrarily in space. In\nthis work, the suitability of a quantum-chemistry inspired approach adopting\nCartesian Gaussians as basis functions is investigated. For this purpose, the\nsix-dimensional integrals associated with a realistic atom-atom interaction\ndescribed by a Morse model potential were implemented. The performance,\ncorrectness and efficiency of the implementation is assessed by comparing full\nconfiguration-interaction calculations (exact diagonalizations) for two atoms\nin an isotropic harmonic trap with quasi-exact reference results.", "AI": {"tldr": "A quantum-chemistry inspired approach using Cartesian Gaussians is investigated for beyond mean-field treatments of multiple atoms/molecules in arbitrary trap geometries, showing promising results compared to exact diagonalizations.", "motivation": "Recent breakthroughs in optical tweezers allow trapping arbitrary numbers of neutral atoms/molecules and creating variable geometries, necessitating novel full-dimensional beyond mean-field treatments for such complex systems.", "method": "The study investigates the suitability of a quantum-chemistry inspired approach using Cartesian Gaussians as basis functions. It implements six-dimensional integrals for a realistic atom-atom interaction modeled by a Morse potential and assesses the performance, correctness, and efficiency by comparing with quasi-exact reference results from full configuration-interaction calculations for two atoms in an isotropic harmonic trap.", "result": "The implemented approach was assessed by comparing its calculations for two atoms in an isotropic harmonic trap with quasi-exact reference results from full configuration-interaction calculations.", "conclusion": "The paper investigates the suitability of a quantum-chemistry inspired approach for analyzing systems with multiple atoms/molecules in arbitrary trap configurations, a necessary development given recent advancements in optical tweezers technology."}}
{"id": "2509.09852", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.09852", "abs": "https://arxiv.org/abs/2509.09852", "authors": ["Chuyuan Li", "Austin Xu", "Shafiq Joty", "Giuseppe Carenini"], "title": "Topic-Guided Reinforcement Learning with LLMs for Enhancing Multi-Document Summarization", "comment": null, "summary": "A key challenge in Multi-Document Summarization (MDS) is effectively\nintegrating information from multiple sources while maintaining coherence and\ntopical relevance. While Large Language Models have shown impressive results in\nsingle-document summarization, their performance on MDS still leaves room for\nimprovement. In this paper, we propose a topic-guided reinforcement learning\napproach to improve content selection in MDS. We first show that explicitly\nprompting models with topic labels enhances the informativeness of the\ngenerated summaries. Building on this insight, we propose a novel topic reward\nwithin the Group Relative Policy Optimization (GRPO) framework to measure topic\nalignment between the generated summary and source documents. Experimental\nresults on the Multi-News and Multi-XScience datasets demonstrate that our\nmethod consistently outperforms strong baselines, highlighting the\neffectiveness of leveraging topical cues in MDS.", "AI": {"tldr": "\u901a\u8fc7\u5f15\u5165\u8bdd\u9898\u5f15\u5bfc\u7684\u5956\u52b1\u673a\u5236\uff0c\u6539\u8fdb\u4e86\u591a\u6587\u6863\u6458\u8981\uff08MDS\uff09\u7684\u5185\u5bb9\u9009\u62e9\uff0c\u63d0\u9ad8\u4e86\u6458\u8981\u4e0e\u6e90\u6587\u6863\u7684\u4e3b\u9898\u4e00\u81f4\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u6587\u6863\u6458\u8981\u65b9\u6cd5\u5728\u6574\u5408\u591a\u6e90\u4fe1\u606f\u3001\u4fdd\u6301\u8fde\u8d2f\u6027\u548c\u4e3b\u9898\u76f8\u5173\u6027\u65b9\u9762\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\uff0c\u5c24\u5176\u662f\u5728\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65b9\u9762\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8bdd\u9898\u5f15\u5bfc\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u9996\u5148\u901a\u8fc7\u8bdd\u9898\u6807\u7b7e\u63d0\u793a\u6a21\u578b\u4ee5\u589e\u5f3a\u6458\u8981\u7684\u4fe1\u606f\u91cf\uff0c\u7136\u540e\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u7684\u8bdd\u9898\u5956\u52b1\u673a\u5236\uff0c\u5728GRPO\u6846\u67b6\u4e0b\u8861\u91cf\u751f\u6210\u6458\u8981\u4e0e\u6e90\u6587\u6863\u7684\u4e3b\u9898\u4e00\u81f4\u6027\u3002", "result": "\u5728Multi-News\u548cMulti-XScience\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u7cfb\u7edf\u6027\u5730\u4f18\u4e8e\u73b0\u6709\u7684\u5f3a\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u5728\u591a\u6587\u6863\u6458\u8981\u4efb\u52a1\u4e2d\uff0c\u5229\u7528\u8bdd\u9898\u7ebf\u7d22\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u6458\u8981\u7684\u8d28\u91cf\u3002"}}
{"id": "2509.10132", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10132", "abs": "https://arxiv.org/abs/2509.10132", "authors": ["Nour Jamoussi", "Giuseppe Serra", "Photios A. Stavrou", "Marios Kountouris"], "title": "Cost-Free Personalization via Information-Geometric Projection in Bayesian Federated Learning", "comment": null, "summary": "Bayesian Federated Learning (BFL) combines uncertainty modeling with\ndecentralized training, enabling the development of personalized and reliable\nmodels under data heterogeneity and privacy constraints. Existing approaches\ntypically rely on Markov Chain Monte Carlo (MCMC) sampling or variational\ninference, often incorporating personalization mechanisms to better adapt to\nlocal data distributions. In this work, we propose an information-geometric\nprojection framework for personalization in parametric BFL. By projecting the\nglobal model onto a neighborhood of the user's local model, our method enables\na tunable trade-off between global generalization and local specialization.\nUnder mild assumptions, we show that this projection step is equivalent to\ncomputing a barycenter on the statistical manifold, allowing us to derive\nclosed-form solutions and achieve cost-free personalization. We apply the\nproposed approach to a variational learning setup using the Improved\nVariational Online Newton (IVON) optimizer and extend its application to\ngeneral aggregation schemes in BFL. Empirical evaluations under heterogeneous\ndata distributions confirm that our method effectively balances global and\nlocal performance with minimal computational overhead.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4fe1\u606f\u51e0\u4f55\u6295\u5f71\u6846\u67b6\uff0c\u7528\u4e8e\u53c2\u6570\u5316\u8d1d\u53f6\u65af\u8054\u90a6\u5b66\u4e60\uff08BFL\uff09\u4e2d\u7684\u4e2a\u6027\u5316\uff0c\u8be5\u6846\u67b6\u53ef\u4ee5\u901a\u8fc7\u6295\u5f71\u5168\u5c40\u6a21\u578b\u5230\u7528\u6237\u672c\u5730\u6a21\u578b\u7684\u90bb\u57df\u6765\u5b9e\u73b0\u5168\u5c40\u6cdb\u5316\u548c\u672c\u5730\u4e13\u4e1a\u5316\u4e4b\u95f4\u7684\u53ef\u8c03\u6743\u8861\uff0c\u5e76\u80fd\u5728\u6e29\u548c\u5047\u8bbe\u4e0b\u4ee5\u95ed\u5f0f\u89e3\u7684\u5f62\u5f0f\u63a8\u5bfc\u51fa\u7edf\u8ba1\u6d41\u5f62\u4e0a\u7684\u8d28\u5fc3\u8ba1\u7b97\uff0c\u4ece\u800c\u5b9e\u73b0\u514d\u8d39\u4e2a\u6027\u5316\u3002", "motivation": "\u73b0\u6709\u7684\u8d1d\u53f6\u65af\u8054\u90a6\u5b66\u4e60\uff08BFL\uff09\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u4e8e\u9a6c\u5c14\u53ef\u592b\u94fe\u8499\u7279\u5361\u6d1b\uff08MCMC\uff09\u91c7\u6837\u6216\u53d8\u5206\u63a8\u65ad\uff0c\u5e76\u7ed3\u5408\u4e2a\u6027\u5316\u673a\u5236\u6765\u9002\u5e94\u672c\u5730\u6570\u636e\u5206\u5e03\uff0c\u4f46\u5ffd\u7565\u4e86\u4fe1\u606f\u51e0\u4f55\u7684\u89c6\u89d2\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4fe1\u606f\u51e0\u4f55\u6295\u5f71\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u5168\u5c40\u6a21\u578b\u6295\u5f71\u5230\u7528\u6237\u672c\u5730\u6a21\u578b\u7684\u90bb\u57df\u6765\u5b9e\u73b0\u4e2a\u6027\u5316\uff0c\u5e76\u5728\u7edf\u8ba1\u6d41\u5f62\u4e0a\u8ba1\u7b97\u8d28\u5fc3\uff0c\u63a8\u5bfc\u51fa\u95ed\u5f0f\u89e3\u3002", "result": "\u5728\u53d8\u5206\u5b66\u4e60\u8bbe\u7f6e\u4e2d\uff0c\u4f7f\u7528\u6539\u8fdb\u7684\u53d8\u5206\u5728\u7ebf\u725b\u987f\uff08IVON\uff09\u4f18\u5316\u5668\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8eBFL\u7684\u901a\u7528\u805a\u5408\u65b9\u6848\u3002\u5728\u5f02\u6784\u6570\u636e\u5206\u5e03\u4e0b\u7684\u5b9e\u8bc1\u8bc4\u4f30\u8bc1\u5b9e\uff0c\u8be5\u65b9\u6cd5\u4ee5\u6700\u5c0f\u7684\u8ba1\u7b97\u5f00\u9500\u6709\u6548\u5e73\u8861\u4e86\u5168\u5c40\u548c\u672c\u5730\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u4fe1\u606f\u51e0\u4f55\u6295\u5f71\u6846\u67b6\u80fd\u591f\u4ee5\u6210\u672c\u6548\u76ca\u7684\u65b9\u5f0f\u5b9e\u73b0BFL\u7684\u4e2a\u6027\u5316\uff0c\u5e76\u5728\u5168\u5c40\u6cdb\u5316\u548c\u672c\u5730\u4e13\u4e1a\u5316\u4e4b\u95f4\u53d6\u5f97\u826f\u597d\u7684\u6743\u8861\u3002"}}
{"id": "2509.10005", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.10005", "abs": "https://arxiv.org/abs/2509.10005", "authors": ["Xiaodong Guo", "Tong Liu", "Yike Li", "Zi'ang Lin", "Zhihong Deng"], "title": "TUNI: Real-time RGB-T Semantic Segmentation with Unified Multi-Modal Feature Extraction and Cross-Modal Feature Fusion", "comment": null, "summary": "RGB-thermal (RGB-T) semantic segmentation improves the environmental\nperception of autonomous platforms in challenging conditions. Prevailing models\nemploy encoders pre-trained on RGB images to extract features from both RGB and\ninfrared inputs, and design additional modules to achieve cross-modal feature\nfusion. This results in limited thermal feature extraction and suboptimal\ncross-modal fusion, while the redundant encoders further compromises the\nmodel's real-time efficiency. To address the above issues, we propose TUNI,\nwith an RGB-T encoder consisting of multiple stacked blocks that simultaneously\nperform multi-modal feature extraction and cross-modal fusion. By leveraging\nlarge-scale pre-training with RGB and pseudo-thermal data, the RGB-T encoder\nlearns to integrate feature extraction and fusion in a unified manner. By\nslimming down the thermal branch, the encoder achieves a more compact\narchitecture. Moreover, we introduce an RGB-T local module to strengthen the\nencoder's capacity for cross-modal local feature fusion. The RGB-T local module\nemploys adaptive cosine similarity to selectively emphasize salient consistent\nand distinct local features across RGB-T modalities. Experimental results show\nthat TUNI achieves competitive performance with state-of-the-art models on FMB,\nPST900 and CART, with fewer parameters and lower computational cost. Meanwhile,\nit achieves an inference speed of 27 FPS on a Jetson Orin NX, demonstrating its\nreal-time capability in deployment. Codes are available at\nhttps://github.com/xiaodonguo/TUNI.", "AI": {"tldr": "TUNI\u662f\u4e00\u4e2a\u521b\u65b0\u7684RGB-T\u8bed\u4e49\u5206\u5272\u6a21\u578b\uff0c\u901a\u8fc7\u7edf\u4e00\u7684\u591a\u6a21\u6001\u7279\u5f81\u63d0\u53d6\u548c\u878d\u5408\uff0c\u4ee5\u53ca\u8f7b\u91cf\u5316\u7684\u70ed\u6210\u50cf\u5206\u652f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6548\u7387\u548c\u6027\u80fd\u3002", "motivation": "\u73b0\u6709RGB-T\u8bed\u4e49\u5206\u5272\u6a21\u578b\u5728\u5904\u7406\u590d\u6742\u73af\u5883\u65f6\u53d7\u9650\u4e8e\u70ed\u6210\u50cf\u7279\u5f81\u63d0\u53d6\u4e0d\u8db3\u548c\u8de8\u6a21\u6001\u878d\u5408\u4e0d\u4f73\uff0c\u540c\u65f6\u5197\u4f59\u7f16\u7801\u5668\u4e5f\u5f71\u54cd\u4e86\u5b9e\u65f6\u6027\u3002", "method": "\u63d0\u51faTUNI\u6a21\u578b\uff0c\u91c7\u7528RGB-T\u7f16\u7801\u5668\u540c\u65f6\u8fdb\u884c\u591a\u6a21\u6001\u7279\u5f81\u63d0\u53d6\u548c\u8de8\u6a21\u6001\u878d\u5408\uff0c\u5e76\u5229\u7528\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\u3002\u901a\u8fc7\u7cbe\u7b80\u70ed\u6210\u50cf\u5206\u652f\u5b9e\u73b0\u6a21\u578b\u8f7b\u91cf\u5316\uff0c\u5e76\u5f15\u5165RGB-T\u5c40\u90e8\u6a21\u5757\uff0c\u5229\u7528\u81ea\u9002\u5e94\u4f59\u5f26\u76f8\u4f3c\u5ea6\u589e\u5f3a\u8de8\u6a21\u6001\u5c40\u90e8\u7279\u5f81\u878d\u5408\u3002", "result": "TUNI\u5728FMB\u3001PST900\u548cCART\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u4e0e\u6700\u5148\u8fdb\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u540c\u65f6\u53c2\u6570\u91cf\u66f4\u5c11\uff0c\u8ba1\u7b97\u6210\u672c\u66f4\u4f4e\u3002\u5728Jetson Orin NX\u4e0a\u5b9e\u73b0\u4e8627 FPS\u7684\u63a8\u7406\u901f\u5ea6\uff0c\u8bc1\u660e\u4e86\u5176\u90e8\u7f72\u7684\u5b9e\u65f6\u6027\u3002", "conclusion": "TUNI\u901a\u8fc7\u7edf\u4e00\u7279\u5f81\u63d0\u53d6\u4e0e\u878d\u5408\u3001\u8f7b\u91cf\u5316\u8bbe\u8ba1\u548c\u589e\u5f3a\u5c40\u90e8\u7279\u5f81\u878d\u5408\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709RGB-T\u8bed\u4e49\u5206\u5272\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6027\u80fd\u548c\u9ad8\u6548\u7387\u3002"}}
{"id": "2509.10381", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2509.10381", "abs": "https://arxiv.org/abs/2509.10381", "authors": ["S\u00e9bastien Designolle"], "title": "Most incompatible measurements and sum-of-squares optimisation", "comment": "11 pages, 3 tables", "summary": "Measurement incompatibility, or joint measurability, is a cornerstone of\nquantum theory and a useful resource. For finite-dimensional systems,\nquantifying this resource and establishing universal bounds valid for all\nmeasurements is a long-standing problem. In this work, we exhibit analytical\nuniversal parent measurements giving access to bounds that beat the state of\nthe art. In particular, we can show that, for relevant robustnesses, sets of\nanticommuting observables give rise to the most incompatible dichotomic\nmeasurements. We also formalise the construction of such universal parent\nmeasurements in the framework of sum-of-squares optimisation and obtain\npreliminary numerical results demonstrating the power of the method by\nimproving on our own analytical values. All results find direct application for\ndemonstrating genuine high-dimensional steering, that is, certifying the\ndimensionality of a quantum system in a one-sided device-independent manner.", "AI": {"tldr": "\u91cf\u5b50\u6d4b\u91cf\u4e0d\u517c\u5bb9\u6027\u662f\u91cf\u5b50\u7406\u8bba\u7684\u57fa\u77f3\uff0c\u5e76\u4e14\u662f\u4e00\u79cd\u6709\u7528\u7684\u8d44\u6e90\u3002\u5bf9\u4e8e\u6709\u9650\u7ef4\u7cfb\u7edf\uff0c\u91cf\u5316\u8fd9\u79cd\u8d44\u6e90\u5e76\u5efa\u7acb\u5bf9\u6240\u6709\u6d4b\u91cf\u90fd\u6709\u6548\u7684\u901a\u7528\u754c\u9650\u662f\u4e00\u4e2a\u957f\u671f\u5b58\u5728\u7684\u95ee\u9898\u3002\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u5206\u6790\u6027\u7684\u901a\u7528\u7236\u6d4b\u91cf\uff0c\u53ef\u4ee5\u83b7\u5f97\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u7684\u754c\u9650\u3002\u7279\u522b\u662f\uff0c\u6211\u4eec\u8bc1\u660e\u4e86\u5728\u76f8\u5173\u7a33\u5065\u6027\u4e0b\uff0c\u53cd\u4ea4\u6362\u53ef\u89c2\u6d4b\u91cf\u96c6\u4f1a\u4ea7\u751f\u6700\u4e0d\u517c\u5bb9\u7684\u4e8c\u5206\u6d4b\u91cf\u3002\u6211\u4eec\u8fd8\u5c06\u8fd9\u79cd\u901a\u7528\u7236\u6d4b\u91cf\u7684\u6784\u9020\u5f62\u5f0f\u5316\u4e3a\u5e73\u65b9\u548c\u4f18\u5316\u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u521d\u6b65\u7684\u6570\u503c\u7ed3\u679c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u8fd9\u4e9b\u7ed3\u679c\u5728\u6211\u4eec\u7684\u5206\u6790\u503c\u7684\u57fa\u7840\u4e0a\u8fdb\u884c\u4e86\u6539\u8fdb\u3002\u6240\u6709\u7814\u7a76\u7ed3\u679c\u90fd\u53ef\u76f4\u63a5\u5e94\u7528\u4e8e\u6f14\u793a\u771f\u6b63\u7684\u9ad8\u7ef4\u9a7e\u9a76\uff0c\u5373\u4ee5\u5355\u65b9\u9762\u8bbe\u5907\u65e0\u5173\u7684\u65b9\u5f0f\u8ba4\u8bc1\u91cf\u5b50\u7cfb\u7edf\u7684\u7ef4\u5ea6\u3002", "motivation": "\u91cf\u5316\u91cf\u5b50\u6d4b\u91cf\u4e0d\u517c\u5bb9\u6027\u8d44\u6e90\u5e76\u5efa\u7acb\u5bf9\u6240\u6709\u6d4b\u91cf\u90fd\u6709\u6548\u7684\u901a\u7528\u754c\u9650\u3002", "method": "\u63d0\u51fa\u5206\u6790\u6027\u7684\u901a\u7528\u7236\u6d4b\u91cf\uff0c\u5e76\u5c06\u5176\u6784\u5efa\u5f62\u5f0f\u5316\u4e3a\u5e73\u65b9\u548c\u4f18\u5316\u6846\u67b6\u3002", "result": "\u5206\u6790\u6027\u7684\u901a\u7528\u7236\u6d4b\u91cf\u7ed9\u51fa\u4e86\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u7684\u754c\u9650\uff1b\u53cd\u4ea4\u6362\u53ef\u89c2\u6d4b\u91cf\u96c6\u4ea7\u751f\u6700\u4e0d\u517c\u5bb9\u7684\u4e8c\u5206\u6d4b\u91cf\uff1b\u5e73\u65b9\u548c\u4f18\u5316\u65b9\u6cd5\u5728\u6570\u503c\u4e0a\u5f97\u5230\u4e86\u6539\u8fdb\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u53ef\u76f4\u63a5\u5e94\u7528\u4e8e\u6f14\u793a\u771f\u6b63\u7684\u9ad8\u7ef4\u9a7e\u9a76\uff0c\u4ee5\u5355\u65b9\u9762\u8bbe\u5907\u65e0\u5173\u7684\u65b9\u5f0f\u8ba4\u8bc1\u91cf\u5b50\u7cfb\u7edf\u7684\u7ef4\u5ea6\u3002"}}
{"id": "2509.09871", "categories": ["cs.CL", "cs.AI", "68T50 (Primary) 91F10 (Secondary)"], "pdf": "https://arxiv.org/pdf/2509.09871", "abs": "https://arxiv.org/abs/2509.09871", "authors": ["Basti\u00e1n Gonz\u00e1lez-Bustamante", "Nando Verelst", "Carla Cisternas"], "title": "Emulating Public Opinion: A Proof-of-Concept of AI-Generated Synthetic Survey Responses for the Chilean Case", "comment": "Working paper: 18 pages, 4 tables, 2 figures", "summary": "Large Language Models (LLMs) offer promising avenues for methodological and\napplied innovations in survey research by using synthetic respondents to\nemulate human answers and behaviour, potentially mitigating measurement and\nrepresentation errors. However, the extent to which LLMs recover aggregate item\ndistributions remains uncertain and downstream applications risk reproducing\nsocial stereotypes and biases inherited from training data. We evaluate the\nreliability of LLM-generated synthetic survey responses against ground-truth\nhuman responses from a Chilean public opinion probabilistic survey.\nSpecifically, we benchmark 128 prompt-model-question triplets, generating\n189,696 synthetic profiles, and pool performance metrics (i.e., accuracy,\nprecision, recall, and F1-score) in a meta-analysis across 128\nquestion-subsample pairs to test for biases along key sociodemographic\ndimensions. The evaluation spans OpenAI's GPT family and o-series reasoning\nmodels, as well as Llama and Qwen checkpoints. Three results stand out. First,\nsynthetic responses achieve excellent performance on trust items (F1-score and\naccuracy > 0.90). Second, GPT-4o, GPT-4o-mini and Llama 4 Maverick perform\ncomparably on this task. Third, synthetic-human alignment is highest among\nrespondents aged 45-59. Overall, LLM-based synthetic samples approximate\nresponses from a probabilistic sample, though with substantial item-level\nheterogeneity. Capturing the full nuance of public opinion remains challenging\nand requires careful calibration and additional distributional tests to ensure\nalgorithmic fidelity and reduce errors.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u53ef\u7528\u4e8e\u751f\u6210\u5408\u6210\u8c03\u67e5\u56de\u590d\uff0c\u4f46\u5728\u591a\u5927\u7a0b\u5ea6\u4e0a\u80fd\u590d\u5236\u4eba\u7c7b\u56de\u590d\u7684\u5206\u5e03\u4ee5\u53ca\u662f\u5426\u4f1a\u52a0\u5267\u793e\u4f1a\u504f\u89c1\u65b9\u9762\u5c1a\u4e0d\u786e\u5b9a\u3002\u672c\u7814\u7a76\u4f7f\u7528\u667a\u5229\u4e00\u9879\u516c\u5f00\u610f\u89c1\u8c03\u67e5\u7684\u771f\u5b9e\u4eba\u7c7b\u56de\u590d\u6765\u8bc4\u4f30 LLM \u751f\u6210\u7684\u5408\u6210\u56de\u590d\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u591a\u5927\u7a0b\u5ea6\u4e0a\u80fd\u591f\u590d\u5236\u771f\u5b9e\u4eba\u7c7b\u8c03\u67e5\u56de\u590d\u7684\u5206\u5e03\uff0c\u4ee5\u53ca\u5b83\u4eec\u5728\u591a\u5927\u7a0b\u5ea6\u4e0a\u4f1a\u4ea7\u751f\u6216\u52a0\u5267\u793e\u4f1a\u504f\u89c1\u3002", "method": "\u901a\u8fc7\u5bf9 128 \u4e2a\u63d0\u793a-\u6a21\u578b-\u95ee\u9898\u7ec4\u5408\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u751f\u6210 189,696 \u4e2a\u5408\u6210\u4e2a\u4f53\uff0c\u5e76\u5bf9 128 \u4e2a\u95ee\u9898-\u5b50\u6837\u672c\u5bf9\u7684\u6027\u80fd\u6307\u6807\uff08\u51c6\u786e\u6027\u3001\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u548c F1 \u5206\u6570\uff09\u8fdb\u884c\u835f\u8403\u5206\u6790\uff0c\u4ee5\u6d4b\u8bd5\u5173\u952e\u793e\u4f1a\u4eba\u53e3\u7edf\u8ba1\u5b66\u7ef4\u5ea6\u7684\u504f\u89c1\u3002\u8bc4\u4f30\u8303\u56f4\u5305\u62ec OpenAI \u7684 GPT \u7cfb\u5217\u3001o\u7cfb\u5217\u63a8\u7406\u6a21\u578b\u4ee5\u53ca Llama \u548c Qwen \u6a21\u578b\u3002", "result": "1. \u5408\u6210\u56de\u590d\u5728\u4fe1\u4efb\u7c7b\u95ee\u9898\u4e0a\u7684\u8868\u73b0\u6781\u4f73\uff08F1 \u5206\u6570\u548c\u51c6\u786e\u7387 > 0.90\uff09\u30022. GPT-4o\u3001GPT-4o-mini \u548c Llama 4 Maverick \u5728\u6b64\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u76f8\u5f53\u30023. \u5408\u6210\u56de\u590d\u4e0e\u4eba\u7c7b\u56de\u590d\u7684\u5339\u914d\u5ea6\u5728 45-59 \u5c81\u53d7\u8bbf\u8005\u4e2d\u6700\u9ad8\u3002\u603b\u4f53\u800c\u8a00\uff0c\u57fa\u4e8e LLM \u7684\u5408\u6210\u6837\u672c\u8fd1\u4f3c\u4e8e\u6982\u7387\u6837\u672c\u7684\u56de\u590d\uff0c\u4f46\u5728\u9879\u76ee\u7ea7\u522b\u5b58\u5728\u663e\u8457\u7684\u5f02\u8d28\u6027\u3002", "conclusion": "\u5c3d\u7ba1\u57fa\u4e8e LLM \u7684\u5408\u6210\u6837\u672c\u53ef\u4ee5\u8fd1\u4f3c\u6982\u7387\u6837\u672c\u7684\u56de\u590d\uff0c\u4f46\u8981\u6355\u6349\u516c\u4f17\u8206\u8bba\u7684\u5168\u90e8\u7ec6\u5fae\u5dee\u522b\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff0c\u9700\u8981\u4ed4\u7ec6\u6821\u51c6\u548c\u989d\u5916\u7684\u5206\u5e03\u6d4b\u8bd5\uff0c\u4ee5\u786e\u4fdd\u7b97\u6cd5\u4fdd\u771f\u5ea6\u548c\u51cf\u5c11\u9519\u8bef\u3002"}}
{"id": "2509.10151", "categories": ["cs.LG", "cs.AI", "I.2.1"], "pdf": "https://arxiv.org/pdf/2509.10151", "abs": "https://arxiv.org/abs/2509.10151", "authors": ["Riccardo Lunelli", "Angus Nicolson", "Samuel Martin Pr\u00f6ll", "Sebastian Johannes Reinstadler", "Axel Bauer", "Clemens Dlaska"], "title": "BenchECG and xECG: a benchmark and baseline for ECG foundation models", "comment": "32 pages, 4 figures, 22 tables", "summary": "Electrocardiograms (ECGs) are inexpensive, widely used, and well-suited to\ndeep learning. Recently, interest has grown in developing foundation models for\nECGs - models that generalise across diverse downstream tasks. However,\nconsistent evaluation has been lacking: prior work often uses narrow task\nselections and inconsistent datasets, hindering fair comparison. Here, we\nintroduce BenchECG, a standardised benchmark comprising a comprehensive suite\nof publicly available ECG datasets and versatile tasks. We also propose xECG,\nan xLSTM-based recurrent model trained with SimDINOv2 self-supervised learning,\nwhich achieves the best BenchECG score compared to publicly available\nstate-of-the-art models. In particular, xECG is the only publicly available\nmodel to perform strongly on all datasets and tasks. By standardising\nevaluation, BenchECG enables rigorous comparison and aims to accelerate\nprogress in ECG representation learning. xECG achieves superior performance\nover earlier approaches, defining a new baseline for future ECG foundation\nmodels.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa BenchECG \u6807\u51c6\u5316\u8bc4\u4f30\u57fa\u51c6\u548c xECG \u6a21\u578b\uff0c\u4ee5\u4fc3\u8fdb\u5fc3\u7535\u56fe\uff08ECG\uff09\u57fa\u7840\u6a21\u578b\u7684\u7814\u7a76\u548c\u53d1\u5c55\u3002", "motivation": "\u73b0\u6709\u5fc3\u7535\u56fe\uff08ECG\uff09\u57fa\u7840\u6a21\u578b\u7684\u7814\u7a76\u7f3a\u4e4f\u7edf\u4e00\u7684\u8bc4\u4f30\u6807\u51c6\uff0c\u4e0d\u540c\u7814\u7a76\u91c7\u7528\u4e0d\u540c\u7684\u6570\u636e\u96c6\u548c\u4efb\u52a1\uff0c\u963b\u788d\u4e86\u516c\u5e73\u6bd4\u8f83\u548c\u6a21\u578b\u8fdb\u5c55\u3002", "method": "\u63d0\u51fa BenchECG\uff0c\u4e00\u4e2a\u5305\u542b\u591a\u79cd\u516c\u5171 ECG \u6570\u636e\u96c6\u548c\u4efb\u52a1\u7684\u6807\u51c6\u5316\u57fa\u51c6\u3002\u63d0\u51fa xECG\uff0c\u4e00\u4e2a\u57fa\u4e8e xLSTM \u5e76\u4f7f\u7528 SimDINOv2 \u81ea\u6211\u76d1\u7763\u5b66\u4e60\u8bad\u7ec3\u7684\u6a21\u578b\u3002", "result": "xECG \u5728 BenchECG \u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u4f73\u5206\u6570\uff0c\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u7684\u6700\u5148\u8fdb\u6a21\u578b\uff0c\u5e76\u4e14\u662f\u552f\u4e00\u4e00\u4e2a\u5728\u6240\u6709\u6570\u636e\u96c6\u548c\u4efb\u52a1\u4e0a\u90fd\u8868\u73b0\u51fa\u8272\u7684\u516c\u5f00\u53ef\u7528\u6a21\u578b\u3002", "conclusion": "BenchECG \u6807\u51c6\u5316\u4e86\u8bc4\u4f30\u65b9\u6cd5\uff0c\u6709\u671b\u52a0\u901f ECG \u8868\u793a\u5b66\u4e60\u7684\u8fdb\u5c55\u3002xECG \u8bbe\u5b9a\u4e86\u672a\u6765 ECG \u57fa\u7840\u6a21\u578b\u7684\u65b0\u57fa\u51c6\u3002"}}
{"id": "2509.10006", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.10006", "abs": "https://arxiv.org/abs/2509.10006", "authors": ["Masaki Akiba", "Shumpei Takezaki", "Daichi Haraguchi", "Seiichi Uchida"], "title": "Few-Part-Shot Font Generation", "comment": "ICDAR 2025 Workshop on Machine Learning", "summary": "This paper proposes a novel model of few-part-shot font generation, which\ndesigns an entire font based on a set of partial design elements, i.e., partial\nshapes. Unlike conventional few-shot font generation, which requires entire\ncharacter shapes for a couple of character classes, our approach only needs\npartial shapes as input. The proposed model not only improves the efficiency of\nfont creation but also provides insights into how partial design details\ninfluence the entire structure of the individual characters.", "AI": {"tldr": "\u8be5\u6a21\u578b\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5c11\u6837\u672c\u5b57\u4f53\u751f\u6210\u65b9\u6cd5\uff0c\u4ec5\u9700\u90e8\u5206\u5f62\u72b6\u5373\u53ef\u751f\u6210\u6574\u4e2a\u5b57\u4f53\uff0c\u63d0\u9ad8\u4e86\u6548\u7387\u5e76\u63ed\u793a\u4e86\u90e8\u5206\u8bbe\u8ba1\u7ec6\u8282\u5bf9\u6574\u4f53\u5b57\u5f62\u7ed3\u6784\u7684\u5f71\u54cd\u3002", "motivation": "\u4e0e\u9700\u8981\u5b8c\u6574\u5b57\u7b26\u5f62\u72b6\u7684\u4f20\u7edf\u5c11\u6837\u672c\u5b57\u4f53\u751f\u6210\u4e0d\u540c\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4ec5\u9700\u90e8\u5206\u5f62\u72b6\u4f5c\u4e3a\u8f93\u5165\u7684\u65b0\u9896\u6a21\u578b\uff0c\u65e8\u5728\u63d0\u9ad8\u5b57\u4f53\u521b\u5efa\u6548\u7387\u5e76\u63a2\u7a76\u90e8\u5206\u8bbe\u8ba1\u7ec6\u8282\u5bf9\u5355\u4e2a\u5b57\u7b26\u6574\u4f53\u7ed3\u6784\u7684\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5c11\u6837\u672c\u5b57\u4f53\u751f\u6210\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u57fa\u4e8e\u4e00\u7ec4\u90e8\u5206\u8bbe\u8ba1\u5143\u7d20\uff08\u5373\u90e8\u5206\u5f62\u72b6\uff09\u6765\u8bbe\u8ba1\u6574\u4e2a\u5b57\u4f53\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u57fa\u4e8e\u90e8\u5206\u5f62\u72b6\u751f\u6210\u6574\u4e2a\u5b57\u4f53\uff0c\u63d0\u9ad8\u4e86\u5b57\u4f53\u521b\u5efa\u7684\u6548\u7387\u3002", "conclusion": "\u8be5\u6a21\u578b\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u5b57\u4f53\u521b\u5efa\u7684\u6548\u7387\uff0c\u8fd8\u4e3a\u90e8\u5206\u8bbe\u8ba1\u7ec6\u8282\u5982\u4f55\u5f71\u54cd\u5355\u4e2a\u5b57\u7b26\u7684\u6574\u4f53\u7ed3\u6784\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2509.10409", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2509.10409", "abs": "https://arxiv.org/abs/2509.10409", "authors": ["Zefan Du", "Pedro Chumpitaz Flores", "Wenqi Wei", "Juntao Chen", "Kaixun Hua", "Ying Mao"], "title": "Optimizing Inter-chip Coupler Link Placement for Modular and Chiplet Quantum Systems", "comment": null, "summary": "Quantum computing offers unparalleled computational capabilities but faces\nsignificant challenges, including limited qubit counts, diverse hardware\ntopologies, and dynamic noise and error rates, which hinder scalability and\nreliability. Distributed quantum computing, particularly chip-to-chip\nconnections, has emerged as a solution by interconnecting multiple processors\nto collaboratively execute large circuits. While hardware advancements, such as\nIBM's Quantum Flamingo, focus on improving inter-chip fidelity, limited\nresearch addresses efficient circuit cutting and qubit mapping in distributed\nsystems. This project introduces InterPlace, a self-adaptive, hardware-aware\nframework for chip-to-chip distributed quantum systems. InterPlace analyzes\nqubit noise and error rates to construct a virtual system topology, guiding\ncircuit partitioning and distributed qubit mapping to minimize SWAP overhead\nand enhance fidelity. Implemented with IBM Qiskit and compared with the\nstate-of-the-art, InterPlace achieves up to a 53.0\\% improvement in fidelity\nand reduces the combination of on-chip SWAPs and inter-chip operations by as\nmuch as 33.3\\%, demonstrating scalability and effectiveness in extensive\nevaluations on real quantum hardware topologies.", "AI": {"tldr": "\u5206\u5e03\u5f0f\u91cf\u5b50\u8ba1\u7b97\u901a\u8fc7\u4e92\u8054\u591a\u4e2a\u5904\u7406\u5668\u6765\u89e3\u51b3\u91cf\u5b50\u8ba1\u7b97\u7684\u6269\u5c55\u6027\u548c\u53ef\u9760\u6027\u6311\u6218\uff0cInterPlace\u6846\u67b6\u901a\u8fc7\u5206\u6790\u566a\u58f0\u548c\u9519\u8bef\u7387\u6765\u4f18\u5316\u7535\u8def\u5212\u5206\u548c\u91cf\u5b50\u6bd4\u7279\u6620\u5c04\uff0c\u63d0\u9ad8\u4e86\u4fdd\u771f\u5ea6\u5e76\u51cf\u5c11\u4e86SWAP\u5f00\u9500\u3002", "motivation": "\u73b0\u6709\u7684\u5206\u5e03\u5f0f\u91cf\u5b50\u8ba1\u7b97\u65b9\u6cd5\u5728\u5904\u7406\u6709\u9650\u7684\u91cf\u5b50\u6bd4\u7279\u6570\u91cf\u3001\u591a\u6837\u7684\u786c\u4ef6\u62d3\u6251\u4ee5\u53ca\u52a8\u6001\u566a\u58f0\u548c\u9519\u8bef\u7387\u65b9\u9762\u5b58\u5728\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u7535\u8def\u5207\u5272\u548c\u91cf\u5b50\u6bd4\u7279\u6620\u5c04\u65b9\u9762\u7814\u7a76\u4e0d\u8db3\uff0c\u800c\u8fd9\u5bf9\u4e8e\u4e92\u8054\u591a\u4e2a\u91cf\u5b50\u5904\u7406\u5668\u81f3\u5173\u91cd\u8981\u3002", "method": "InterPlace\u6846\u67b6\u901a\u8fc7\u5206\u6790\u91cf\u5b50\u6bd4\u7279\u7684\u566a\u58f0\u548c\u9519\u8bef\u7387\uff0c\u6784\u5efa\u865a\u62df\u7cfb\u7edf\u62d3\u6251\uff0c\u4ee5\u6307\u5bfc\u7535\u8def\u5212\u5206\u548c\u5206\u5e03\u5f0f\u91cf\u5b50\u6bd4\u7279\u6620\u5c04\uff0c\u4ece\u800c\u6700\u5c0f\u5316SWAP\u5f00\u9500\u5e76\u63d0\u9ad8\u4fdd\u771f\u5ea6\u3002\u8be5\u6846\u67b6\u4f7f\u7528IBM Qiskit\u5b9e\u73b0\u3002", "result": "\u4e0e\u73b0\u6709\u6280\u672f\u76f8\u6bd4\uff0cInterPlace\u5728\u4fdd\u771f\u5ea6\u65b9\u9762\u53d6\u5f97\u4e86\u9ad8\u8fbe53.0%\u7684\u63d0\u5347\uff0c\u5e76\u4e14\u5c06\u7247\u4e0aSWAP\u64cd\u4f5c\u548c\u82af\u7247\u95f4\u64cd\u4f5c\u76f8\u7ed3\u5408\u7684\u5f00\u9500\u51cf\u5c11\u4e86\u9ad8\u8fbe33.3%\u3002", "conclusion": "InterPlace\u6846\u67b6\u5728\u771f\u5b9e\u91cf\u5b50\u786c\u4ef6\u62d3\u6251\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u8bc1\u660e\u4e86\u5176\u5728\u5206\u5e03\u5f0f\u91cf\u5b50\u8ba1\u7b97\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u548c\u6709\u6548\u6027\uff0c\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u91cf\u5b50\u7535\u8def\u7684\u4fdd\u771f\u5ea6\u5e76\u964d\u4f4e\u6267\u884c\u5f00\u9500\u3002"}}
{"id": "2509.09969", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09969", "abs": "https://arxiv.org/abs/2509.09969", "authors": ["Zhitian Hou", "Zihan Ye", "Nanli Zeng", "Tianyong Hao", "Kun Zeng"], "title": "Large Language Models Meet Legal Artificial Intelligence: A Survey", "comment": null, "summary": "Large Language Models (LLMs) have significantly advanced the development of\nLegal Artificial Intelligence (Legal AI) in recent years, enhancing the\nefficiency and accuracy of legal tasks. To advance research and applications of\nLLM-based approaches in legal domain, this paper provides a comprehensive\nreview of 16 legal LLMs series and 47 LLM-based frameworks for legal tasks, and\nalso gather 15 benchmarks and 29 datasets to evaluate different legal\ncapabilities. Additionally, we analyse the challenges and discuss future\ndirections for LLM-based approaches in the legal domain. We hope this paper\nprovides a systematic introduction for beginners and encourages future research\nin this field. Resources are available at\nhttps://github.com/ZhitianHou/LLMs4LegalAI.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2509.10424", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2509.10424", "abs": "https://arxiv.org/abs/2509.10424", "authors": ["Boris Tsvelikhovskiy", "Matthew Nuyten", "Bojko N. Bakalov"], "title": "Provable avoidance of barren plateaus for GM-QAOA", "comment": null, "summary": "We analyze the dynamical Lie algebras (DLAs) associated with the Grover-mixer\nvariant of the Quantum Approximate Optimization Algorithm (GM-QAOA). When the\ninitial state is the uniform superposition of computational basis states, we\nshow that the corresponding DLA is isomorphic to either $\\mathfrak{su}_{r}\n\\oplus \\mathfrak{u}_{1}^{\\oplus 2}$ or $\\mathfrak{su}_{r} \\oplus\n\\mathfrak{u}_{1}$, where \\(r\\) denotes the number of distinct values of the\nobjective function. We also establish an analogous classification for other\nchoices of initial states and Grover-type mixers.\n  Furthermore, we prove that the DLA of GM-QAOA has the largest possible\ncommutant among all QAOA variants initialized with the same state\n$|\\xi\\rangle$, corresponding physically to the maximal set of conserved\nquantities. In addition, we derive an explicit formula for the variance of the\nGM-QAOA loss function in terms of the objective function values, and we show\nthat, for a broad class of optimization problems, GM-QAOA with sufficiently\nmany layers avoids barren plateaus.", "AI": {"tldr": "GM-QAOA\u7684\u52a8\u529b\u5b66\u674e\u4ee3\u6570\uff08DLA\uff09\u88ab\u5206\u7c7b\uff0c\u5176\u674e\u4ee3\u6570\u540c\u6784\u4e8e SU(r)\u2295U(1)^2 \u6216 SU(r)\u2295U(1)\u3002", "motivation": "\u7814\u7a76GM-QAOA\u7684\u52a8\u529b\u5b66\u674e\u4ee3\u6570\uff08DLA\uff09\u7684\u7ed3\u6784\uff0c\u5e76\u5c06\u5176\u4e0eQAOA\u7684\u5176\u4ed6\u53d8\u4f53\u8fdb\u884c\u6bd4\u8f83\uff0c\u4ee5\u4e86\u89e3\u5176\u5728\u4f18\u5316\u95ee\u9898\u4e2d\u7684\u6027\u8d28\u3002", "method": "\u901a\u8fc7\u6570\u5b66\u5206\u6790\uff0c\u63a8\u5bfc\u51faGM-QAOA\u7684DLA\u7ed3\u6784\uff0c\u5e76\u5c06\u5176\u4e0e$\\\nin_{r} \\\\\text{oplus} \\\\text{u}_{1}^{\\\\oplus 2}$\u6216$\\\nin_{r} \\\\text{oplus} \\\\text{u}_{1}$\u8fdb\u884c\u540c\u6784\u6bd4\u8f83\u3002\u6b64\u5916\uff0c\u8fd8\u63a8\u5bfc\u4e86GM-QAOA\u635f\u5931\u51fd\u6570\u7684\u65b9\u5dee\u516c\u5f0f\uff0c\u5e76\u8bc1\u660e\u4e86\u5728\u4e00\u5b9a\u6761\u4ef6\u4e0b\u53ef\u4ee5\u907f\u514dBarren Plateaus\u3002", "result": "GM-QAOA\u7684DLA\u88ab\u5206\u7c7b\u4e3a$\\\nin_{r} \\\\text{oplus} \\\\text{u}_{1}^{\\\\oplus 2}$\u6216$\\\nin_{r} \\\\text{oplus} \\\\text{u}_{1}$\u3002GM-QAOA\u7684DLA\u62e5\u6709\u6700\u5927\u7684\u4ea4\u6362\u5b50\uff0c\u5bf9\u5e94\u4e8e\u6700\u5927\u6570\u91cf\u7684\u5b88\u6052\u91cf\u3002\u635f\u5931\u51fd\u6570\u7684\u65b9\u5dee\u516c\u5f0f\u88ab\u5bfc\u51fa\uff0c\u5e76\u4e14\u8bc1\u660e\u4e86GM-QAOA\u53ef\u4ee5\u907f\u514dBarren Plateaus\u3002", "conclusion": "GM-QAOA\u5728\u52a8\u529b\u5b66\u674e\u4ee3\u6570\u7ed3\u6784\u3001\u5b88\u6052\u91cf\u548c\u907f\u514dBarren Plateaus\u65b9\u9762\u5177\u6709\u4f18\u8d8a\u6027\uff0c\u8fd9\u8868\u660e\u5b83\u5728\u91cf\u5b50\u8fd1\u4f3c\u4f18\u5316\u7b97\u6cd5\u4e2d\u5177\u6709\u6f5c\u529b\u3002"}}
{"id": "2509.09990", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.09990", "abs": "https://arxiv.org/abs/2509.09990", "authors": ["Guixian Xu", "Zeli Su", "Ziyin Zhang", "Jianing Liu", "XU Han", "Ting Zhang", "Yushuang Dong"], "title": "CMHG: A Dataset and Benchmark for Headline Generation of Minority Languages in China", "comment": null, "summary": "Minority languages in China, such as Tibetan, Uyghur, and Traditional\nMongolian, face significant challenges due to their unique writing systems,\nwhich differ from international standards. This discrepancy has led to a severe\nlack of relevant corpora, particularly for supervised tasks like headline\ngeneration. To address this gap, we introduce a novel dataset, Chinese Minority\nHeadline Generation (CMHG), which includes 100,000 entries for Tibetan, and\n50,000 entries each for Uyghur and Mongolian, specifically curated for headline\ngeneration tasks. Additionally, we propose a high-quality test set annotated by\nnative speakers, designed to serve as a benchmark for future research in this\ndomain. We hope this dataset will become a valuable resource for advancing\nheadline generation in Chinese minority languages and contribute to the\ndevelopment of related benchmarks.", "AI": {"tldr": "\u6211\u4eec\u53d1\u5e03\u4e86\u4e00\u4e2a\u5305\u542b100,000\u4e2a\u85cf\u8bed\u6761\u76ee\u548c50,000\u4e2a\u7ef4\u543e\u5c14\u8bed\u548c\u8499\u53e4\u8bed\u6761\u76ee\u7684\u65b0\u6570\u636e\u96c6\uff08CMHG\uff09\uff0c\u7528\u4e8e\u5c11\u6570\u6c11\u65cf\u8bed\u8a00\u7684\u6807\u9898\u751f\u6210\u4efb\u52a1\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7531\u6bcd\u8bed\u8005\u6807\u6ce8\u7684\u9ad8\u8d28\u91cf\u6d4b\u8bd5\u96c6\u3002", "motivation": "\u4e2d\u56fd\u5c11\u6570\u6c11\u65cf\u8bed\u8a00\uff08\u5982\u85cf\u8bed\u3001\u7ef4\u543e\u5c14\u8bed\u548c\u8499\u53e4\u8bed\uff09\u7684\u72ec\u7279\u4e66\u5199\u7cfb\u7edf\u4e0e\u56fd\u9645\u6807\u51c6\u5b58\u5728\u5dee\u5f02\uff0c\u5bfc\u81f4\u76f8\u5173\u8bed\u6599\u5e93\u4e25\u91cd\u7f3a\u4e4f\uff0c\u5c24\u5176\u662f\u5728\u76d1\u7763\u5b66\u4e60\u4efb\u52a1\uff08\u5982\u6807\u9898\u751f\u6210\uff09\u65b9\u9762\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u540d\u4e3aCMHG\u7684\u65b0\u6570\u636e\u96c6\uff0c\u5305\u542b100,000\u4e2a\u85cf\u8bed\u6761\u76ee\uff0c\u4ee5\u53ca50,000\u4e2a\u7ef4\u543e\u5c14\u8bed\u548c50,000\u4e2a\u8499\u53e4\u8bed\u6761\u76ee\uff0c\u5e76\u63d0\u4f9b\u4e00\u4e2a\u7531\u6bcd\u8bed\u8005\u6807\u6ce8\u7684\u9ad8\u8d28\u91cf\u6d4b\u8bd5\u96c6\u3002", "result": "\u6784\u5efa\u4e86\u4e00\u4e2a\u4e13\u95e8\u7528\u4e8e\u5c11\u6570\u6c11\u65cf\u8bed\u8a00\u6807\u9898\u751f\u6210\u7684CMHG\u6570\u636e\u96c6\uff0c\u4ee5\u53ca\u4e00\u4e2a\u9ad8\u8d28\u91cf\u7684\u6d4b\u8bd5\u96c6\uff0c\u4e3a\u8be5\u9886\u57df\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u5b9d\u8d35\u8d44\u6e90\u3002", "conclusion": "CMHG\u6570\u636e\u96c6\u6709\u671b\u6210\u4e3a\u63a8\u52a8\u4e2d\u56fd\u5c11\u6570\u6c11\u65cf\u8bed\u8a00\u6807\u9898\u751f\u6210\u53d1\u5c55\u7684\u5b9d\u8d35\u8d44\u6e90\uff0c\u5e76\u4e3a\u76f8\u5173\u57fa\u51c6\u7684\u5f00\u53d1\u505a\u51fa\u8d21\u732e\u3002"}}
{"id": "2509.10163", "categories": ["cs.LG", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.10163", "abs": "https://arxiv.org/abs/2509.10163", "authors": ["Francisco Javier Esono Nkulu Andong", "Qi Min"], "title": "Federated Multi-Agent Reinforcement Learning for Privacy-Preserving and Energy-Aware Resource Management in 6G Edge Networks", "comment": null, "summary": "As sixth-generation (6G) networks move toward ultra-dense, intelligent edge\nenvironments, efficient resource management under stringent privacy, mobility,\nand energy constraints becomes critical. This paper introduces a novel\nFederated Multi-Agent Reinforcement Learning (Fed-MARL) framework that\nincorporates cross-layer orchestration of both the MAC layer and application\nlayer for energy-efficient, privacy-preserving, and real-time resource\nmanagement across heterogeneous edge devices. Each agent uses a Deep Recurrent\nQ-Network (DRQN) to learn decentralized policies for task offloading, spectrum\naccess, and CPU energy adaptation based on local observations (e.g., queue\nlength, energy, CPU usage, and mobility). To protect privacy, we introduce a\nsecure aggregation protocol based on elliptic curve Diffie Hellman key\nexchange, which ensures accurate model updates without exposing raw data to\nsemi-honest adversaries. We formulate the resource management problem as a\npartially observable multi-agent Markov decision process (POMMDP) with a\nmulti-objective reward function that jointly optimizes latency, energy\nefficiency, spectral efficiency, fairness, and reliability under 6G-specific\nservice requirements such as URLLC, eMBB, and mMTC. Simulation results\ndemonstrate that Fed-MARL outperforms centralized MARL and heuristic baselines\nin task success rate, latency, energy efficiency, and fairness, while ensuring\nrobust privacy protection and scalability in dynamic, resource-constrained 6G\nedge networks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a Fed-MARL \u7684\u8054\u90a6\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e 6G \u8d85\u5bc6\u96c6\u8fb9\u7f18\u73af\u5883\u4e2d\u7684\u8d44\u6e90\u7ba1\u7406\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u8de8\u5c42\uff08MAC \u548c\u5e94\u7528\u5c42\uff09\u8fdb\u884c\u4efb\u52a1\u5378\u8f7d\u3001\u9891\u8c31\u63a5\u5165\u548c CPU \u80fd\u91cf\u81ea\u9002\u5e94\u7684\u534f\u540c\uff0c\u5b9e\u73b0\u4e86\u9ad8\u80fd\u6548\u3001\u9690\u79c1\u4fdd\u62a4\u548c\u4f4e\u5ef6\u8fdf\u7684\u8d44\u6e90\u7ba1\u7406\u3002", "motivation": "6G \u7f51\u7edc\u671d\u7740\u8d85\u5bc6\u96c6\u3001\u667a\u80fd\u5316\u7684\u8fb9\u7f18\u73af\u5883\u53d1\u5c55\uff0c\u5728\u4e25\u683c\u7684\u9690\u79c1\u3001\u79fb\u52a8\u6027\u548c\u80fd\u6e90\u9650\u5236\u4e0b\u8fdb\u884c\u9ad8\u6548\u7684\u8d44\u6e90\u7ba1\u7406\u81f3\u5173\u91cd\u8981\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8054\u90a6\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff08Fed-MARL\uff09\u6846\u67b6\uff0c\u7ed3\u5408\u4e86 MAC \u5c42\u548c\u5e94\u7528\u5c42\u7684\u8de8\u5c42\u7f16\u6392\u3002\u6bcf\u4e2a\u667a\u80fd\u4f53\u4f7f\u7528\u6df1\u5ea6\u5faa\u73af Q \u7f51\u7edc\uff08DRQN\uff09\u6765\u5b66\u4e60\u53bb\u4e2d\u5fc3\u5316\u7684\u4efb\u52a1\u5378\u8f7d\u3001\u9891\u8c31\u63a5\u5165\u548c CPU \u80fd\u91cf\u81ea\u9002\u5e94\u7b56\u7565\u3002\u5f15\u5165\u4e86\u57fa\u4e8e\u692d\u5706\u66f2\u7ebf\u8fea\u83f2-\u8d6b\u5c14\u66fc\u5bc6\u94a5\u4ea4\u6362\u7684\u5b89\u5168\u805a\u5408\u534f\u8bae\u6765\u4fdd\u62a4\u9690\u79c1\u3002\u5c06\u8d44\u6e90\u7ba1\u7406\u95ee\u9898\u5efa\u6a21\u4e3a\u5177\u6709\u591a\u76ee\u6807\u5956\u52b1\u51fd\u6570\u7684\u90e8\u5206\u53ef\u89c2\u5bdf\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08POMMDP\uff09\uff0c\u4ee5\u4f18\u5316\u5ef6\u8fdf\u3001\u80fd\u6548\u3001\u9891\u8c31\u6548\u7387\u3001\u516c\u5e73\u6027\u548c\u53ef\u9760\u6027\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0cFed-MARL \u5728\u4efb\u52a1\u6210\u529f\u7387\u3001\u5ef6\u8fdf\u3001\u80fd\u6548\u548c\u516c\u5e73\u6027\u65b9\u9762\u4f18\u4e8e\u4e2d\u5fc3\u5316 MARL \u548c\u542f\u53d1\u5f0f\u57fa\u7ebf\u65b9\u6cd5\uff0c\u540c\u65f6\u8fd8\u80fd\u5728\u52a8\u6001\u3001\u8d44\u6e90\u53d7\u9650\u7684 6G \u8fb9\u7f18\u7f51\u7edc\u4e2d\u63d0\u4f9b\u5f3a\u5927\u7684\u9690\u79c1\u4fdd\u62a4\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "Fed-MARL \u6846\u67b6\u80fd\u591f\u6709\u6548\u5730\u5b9e\u73b0 6G \u8d85\u5bc6\u96c6\u8fb9\u7f18\u73af\u5883\u4e2d\u8d44\u6e90\u7ba1\u7406\u7684\u9ad8\u80fd\u6548\u3001\u9690\u79c1\u4fdd\u62a4\u548c\u4f4e\u5ef6\u8fdf\uff0c\u6ee1\u8db3 URLLC\u3001eMBB \u548c mMTC \u7b49 6G \u670d\u52a1\u8981\u6c42\u3002"}}
{"id": "2509.10024", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.10024", "abs": "https://arxiv.org/abs/2509.10024", "authors": ["Danling Cao"], "title": "Hierarchical MLANet: Multi-level Attention for 3D Face Reconstruction From Single Images", "comment": "This work was completed during the author's MPhil studies at the\n  University of Manchester", "summary": "Recovering 3D face models from 2D in-the-wild images has gained considerable\nattention in the computer vision community due to its wide range of potential\napplications. However, the lack of ground-truth labeled datasets and the\ncomplexity of real-world environments remain significant challenges. In this\nchapter, we propose a convolutional neural network-based approach, the\nHierarchical Multi-Level Attention Network (MLANet), for reconstructing 3D face\nmodels from single in-the-wild images. Our model predicts detailed facial\ngeometry, texture, pose, and illumination parameters from a single image.\nSpecifically, we employ a pre-trained hierarchical backbone network and\nintroduce multi-level attention mechanisms at different stages of 2D face image\nfeature extraction. A semi-supervised training strategy is employed,\nincorporating 3D Morphable Model (3DMM) parameters from publicly available\ndatasets along with a differentiable renderer, enabling an end-to-end training\nprocess. Extensive experiments, including both comparative and ablation\nstudies, were conducted on two benchmark datasets, AFLW2000-3D and MICC\nFlorence, focusing on 3D face reconstruction and 3D face alignment tasks. The\neffectiveness of the proposed method was evaluated both quantitatively and\nqualitatively.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u540d\u4e3aMLANet\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u7528\u4e8e\u4ece\u5355\u5f20\u91ce\u5916\u56fe\u50cf\u4e2d\u91cd\u5efa3D\u4eba\u8138\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u80fd\u591f\u9884\u6d4b\u8be6\u7ec6\u7684\u9762\u90e8\u51e0\u4f55\u3001\u7eb9\u7406\u3001\u59ff\u6001\u548c\u5149\u7167\u53c2\u6570\u3002\u65b9\u6cd5\u4e0a\uff0c\u91c7\u7528\u4e86\u9884\u8bad\u7ec3\u7684\u9aa8\u5e72\u7f51\u7edc\u548c\u591a\u5c42\u6b21\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5e76\u7ed3\u54083DMM\u53c2\u6570\u548c\u53ef\u5fae\u5206\u6e32\u67d3\u5668\u8fdb\u884c\u534a\u76d1\u7763\u7aef\u5230\u7aef\u8bad\u7ec3\u3002\u5b9e\u9a8c\u5728AFLW2000-3D\u548cMICC Florence\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\uff0c\u5e76\u57283D\u4eba\u8138\u91cd\u5efa\u548c3D\u4eba\u8138\u5bf9\u9f50\u4efb\u52a1\u4e0a\u8fdb\u884c\u4e86\u91cf\u5316\u548c\u8d28\u5316\u8bc4\u4f30\u3002", "motivation": "\u4ece2D\u91ce\u5916\u56fe\u50cf\u6062\u590d3D\u4eba\u8138\u6a21\u578b\u56e0\u5176\u5e7f\u6cdb\u7684\u5e94\u7528\u524d\u666f\u800c\u5907\u53d7\u5173\u6ce8\uff0c\u4f46\u7f3a\u4e4f\u771f\u5b9e\u6807\u8bb0\u6570\u636e\u96c6\u548c\u771f\u5b9e\u4e16\u754c\u73af\u5883\u7684\u590d\u6742\u6027\u5e26\u6765\u4e86\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u540d\u4e3aMLANet\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff0c\u91c7\u7528\u9884\u8bad\u7ec3\u7684\u5c42\u7ea7\u9aa8\u5e72\u7f51\u7edc\uff0c\u5e76\u57282D\u4eba\u8138\u56fe\u50cf\u7279\u5f81\u63d0\u53d6\u7684\u4e0d\u540c\u9636\u6bb5\u5f15\u5165\u591a\u5c42\u6b21\u6ce8\u610f\u529b\u673a\u5236\u3002\u901a\u8fc7\u7ed3\u54083D Morphable Model\uff083DMM\uff09\u53c2\u6570\u548c\u53ef\u5fae\u5206\u6e32\u67d3\u5668\uff0c\u91c7\u7528\u534a\u76d1\u7763\u5b66\u4e60\u7b56\u7565\u8fdb\u884c\u7aef\u5230\u7aef\u8bad\u7ec3\u3002", "result": "\u5728AFLW2000-3D\u548cMICC Florence\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9a8c\uff0c\u5305\u62ec\u6bd4\u8f83\u7814\u7a76\u548c\u6d88\u878d\u7814\u7a76\uff0c\u57283D\u4eba\u8138\u91cd\u5efa\u548c3D\u4eba\u8138\u5bf9\u9f50\u4efb\u52a1\u4e0a\u8fdb\u884c\u4e86\u91cf\u5316\u548c\u8d28\u5316\u8bc4\u4f30\uff0c\u8bc1\u660e\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684MLANet\u6a21\u578b\u901a\u8fc7\u5229\u7528\u591a\u5c42\u6b21\u6ce8\u610f\u529b\u673a\u5236\u548c\u534a\u76d1\u7763\u5b66\u4e60\u7b56\u7565\uff0c\u80fd\u591f\u6709\u6548\u5730\u4ece\u5355\u5f20\u91ce\u5916\u56fe\u50cf\u4e2d\u91cd\u5efa\u51fa\u8be6\u7ec6\u76843D\u4eba\u8138\u6a21\u578b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u6311\u6218\u3002"}}
{"id": "2509.10425", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2509.10425", "abs": "https://arxiv.org/abs/2509.10425", "authors": ["Evan Borras", "Milad Marvian"], "title": "Quantum algorithms based on quantum trajectories", "comment": "comments welcome", "summary": "Quantum simulation has emerged as a key application of quantum computing,\nwith significant progress made in algorithms for simulating both closed and\nopen quantum systems. The simulation of open quantum systems, particularly\nthose governed by the Lindblad master equation, has received attention recently\nwith the current state-of-the-art algorithms having an input model query\ncomplexity of $O(T \\mathrm{polylog}(T/\\epsilon))$, where $T$ and $\\epsilon$ are\nthe requested time and precision of the simulation respectively. For the\nHamiltonian simulation problem it has been show that the optimal Hamiltonian\nquery complexity is $O(T + \\log(1/\\epsilon))$, additive in nature between the\ntwo parameter, but for Lindbladian simulation this question remains open. In\nthis work we show that the additive complexity of $O(T + \\log(1/\\epsilon))$ is\nreachable for the simulation of a large class of Lindbladian by constructing a\nnovel quantum algorithm based on quantum trajectories.", "AI": {"tldr": "\u91cf\u5b50\u6a21\u62df\u662f\u91cf\u5b50\u8ba1\u7b97\u7684\u4e00\u4e2a\u5173\u952e\u5e94\u7528\uff0c\u5c24\u5176\u662f\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\u7684\u6a21\u62df\u3002\u73b0\u6709\u7b97\u6cd5\u7684\u590d\u6742\u5ea6\u4e3a O(T polylog(T/\u03b5))\u3002", "motivation": "\u73b0\u6709\u6a21\u62df\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\uff08\u7279\u522b\u662f\u9075\u5faa Lindblad \u4e3b\u65b9\u7a0b\u7684\u7cfb\u7edf\uff09\u7684\u7b97\u6cd5\u590d\u6742\u5ea6\u8f83\u9ad8\uff0c\u5e76\u4e14\u5176\u6700\u4f18\u67e5\u8be2\u590d\u6742\u5ea6\u4ecd\u662f\u672a\u89e3\u4e4b\u8c1c\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u91cf\u5b50\u8f68\u8ff9\u7684\u65b0\u578b\u91cf\u5b50\u7b97\u6cd5\u3002", "result": "\u8be5\u7b97\u6cd5\u5b9e\u73b0\u4e86 O(T + log(1/\u03b5)) \u7684\u52a0\u6027\u590d\u6742\u5ea6\uff0c\u8fd9\u662f\u5bf9\u4e00\u7c7b Lindbladian \u6a21\u62df\u7684\u53ef\u8fbe\u5230\u7684\u6700\u4f18\u590d\u6742\u5ea6\u3002", "conclusion": "\u901a\u8fc7\u57fa\u4e8e\u91cf\u5b50\u8f68\u8ff9\u7684\u65b0\u578b\u91cf\u5b50\u7b97\u6cd5\uff0c\u4e3a\u4e00\u7c7b Lindbladian \u6a21\u62df\u5b9e\u73b0\u4e86 O(T + log(1/\u03b5)) \u7684\u52a0\u6027\u6700\u4f18\u590d\u6742\u5ea6\u3002"}}
{"id": "2509.10004", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10004", "abs": "https://arxiv.org/abs/2509.10004", "authors": ["Ponhvoan Srey", "Xiaobao Wu", "Anh Tuan Luu"], "title": "Unsupervised Hallucination Detection by Inspecting Reasoning Processes", "comment": "To appear in EMNLP 2025", "summary": "Unsupervised hallucination detection aims to identify hallucinated content\ngenerated by large language models (LLMs) without relying on labeled data.\nWhile unsupervised methods have gained popularity by eliminating\nlabor-intensive human annotations, they frequently rely on proxy signals\nunrelated to factual correctness. This misalignment biases detection probes\ntoward superficial or non-truth-related aspects, limiting generalizability\nacross datasets and scenarios. To overcome these limitations, we propose IRIS,\nan unsupervised hallucination detection framework, leveraging internal\nrepresentations intrinsic to factual correctness. IRIS prompts the LLM to\ncarefully verify the truthfulness of a given statement, and obtain its\ncontextualized embedding as informative features for training. Meanwhile, the\nuncertainty of each response is considered a soft pseudolabel for truthfulness.\nExperimental results demonstrate that IRIS consistently outperforms existing\nunsupervised methods. Our approach is fully unsupervised, computationally low\ncost, and works well even with few training data, making it suitable for\nreal-time detection.", "AI": {"tldr": "\u65e0\u76d1\u7763\u5e7b\u89c9\u68c0\u6d4b\u65b9\u6cd5IRIS\u5229\u7528LLM\u7684\u5185\u90e8\u8868\u5f81\u6765\u8bc4\u4f30\u4e8b\u5b9e\u7684\u6b63\u786e\u6027\uff0c\u514b\u670d\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6\u65e0\u76d1\u7763\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u65e0\u76d1\u7763\u5e7b\u89c9\u68c0\u6d4b\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u4e0e\u4e8b\u5b9e\u6b63\u786e\u6027\u65e0\u5173\u7684\u4ee3\u7406\u4fe1\u53f7\uff0c\u5bfc\u81f4\u68c0\u6d4b\u63a2\u9488\u7684\u504f\u89c1\uff0c\u9650\u5236\u4e86\u5176\u5728\u4e0d\u540c\u6570\u636e\u96c6\u548c\u573a\u666f\u4e0b\u7684\u6cdb\u5316\u80fd\u529b\u3002", "method": "IRIS\u6846\u67b6\u63d0\u793aLLM\u4ed4\u7ec6\u9a8c\u8bc1\u7ed9\u5b9a\u9648\u8ff0\u7684\u771f\u5b9e\u6027\uff0c\u5e76\u5c06\u5176\u4e0a\u4e0b\u6587\u5d4c\u5165\u4f5c\u4e3a\u8bad\u7ec3\u7684\u7279\u5f81\u3002\u540c\u65f6\uff0c\u5c06\u54cd\u5e94\u7684\u4e0d\u786e\u5b9a\u6027\u89c6\u4e3a\u771f\u5b9e\u6027\u7684\u8f6f\u4f2a\u6807\u7b7e\u3002", "result": "IRIS\u5728\u5b9e\u9a8c\u4e2d\u4e00\u81f4\u4f18\u4e8e\u73b0\u6709\u7684\u65e0\u76d1\u7763\u65b9\u6cd5\uff0c\u5e76\u4e14\u9002\u7528\u4e8e\u5b9e\u65f6\u68c0\u6d4b\u3002", "conclusion": "IRIS\u662f\u4e00\u79cd\u5b8c\u5168\u65e0\u76d1\u7763\u3001\u8ba1\u7b97\u6210\u672c\u4f4e\u3001\u5373\u4f7f\u5728\u8bad\u7ec3\u6570\u636e\u5f88\u5c11\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u5f88\u597d\u5730\u5de5\u4f5c\u7684\u5e7b\u89c9\u68c0\u6d4b\u6846\u67b6\uff0c\u80fd\u591f\u6709\u6548\u8bc6\u522bLLM\u751f\u6210\u7684\u5e7b\u89c9\u5185\u5bb9\u3002"}}
{"id": "2509.10164", "categories": ["cs.LG", "quant-ph"], "pdf": "https://arxiv.org/pdf/2509.10164", "abs": "https://arxiv.org/abs/2509.10164", "authors": ["Hoshitaro Ohnishi", "Hideo Mukai"], "title": "A Symmetry-Integrated Approach to Surface Code Decoding", "comment": "12 pages, 6 figures", "summary": "Quantum error correction, which utilizes logical qubits that are encoded as\nredundant multiple physical qubits to find and correct errors in physical\nqubits, is indispensable for practical quantum computing. Surface code is\nconsidered to be a promising encoding method with a high error threshold that\nis defined by stabilizer generators. However, previous methods have suffered\nfrom the problem that the decoder acquires solely the error probability\ndistribution because of the non-uniqueness of correct prediction obtained from\nthe input. To circumvent this problem, we propose a technique to reoptimize the\ndecoder model by approximating syndrome measurements with a continuous function\nthat is mathematically interpolated by neural network. We evaluated the\nimprovement in accuracy of a multilayer perceptron based decoder for code\ndistances of 5 and 7 as well as for decoders based on convolutional and\nrecurrent neural networks and transformers for a code distance of 5. In all\ncases, the reoptimized decoder gave better accuracy than the original models,\ndemonstrating the universal effectiveness of the proposed method that is\nindependent of code distance or network architecture. These results suggest\nthat re-framing the problem of surface code decoding into a regression problem\nthat can be tackled by deep learning is a useful strategy.", "AI": {"tldr": "\u91cf\u5b50\u7ea0\u9519\u662f\u5b9e\u7528\u91cf\u5b50\u8ba1\u7b97\u7684\u5173\u952e\uff0c\u4f46\u73b0\u6709\u89e3\u7801\u5668\u5728\u5904\u7406\u8868\u9762\u7801\u65f6\u5b58\u5728\u8bef\u5dee\u6982\u7387\u5206\u5e03\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\u3002\u672c\u7814\u7a76\u63d0\u51fa\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u63d2\u503c\u8fde\u7eed\u51fd\u6570\u6765\u8fd1\u4f3c\u6d4b\u91cf\uff0c\u91cd\u65b0\u4f18\u5316\u89e3\u7801\u5668\u6a21\u578b\uff0c\u63d0\u9ad8\u4e86\u7cbe\u5ea6\u3002\u8be5\u65b9\u6cd5\u5bf9\u4ee3\u7801\u8ddd\u79bb\u548c\u7f51\u7edc\u67b6\u6784\u5177\u6709\u666e\u9002\u6027\uff0c\u8868\u660e\u5c06\u8868\u9762\u7801\u89e3\u7801\u89c6\u4e3a\u56de\u5f52\u95ee\u9898\u5e76\u5229\u7528\u6df1\u5ea6\u5b66\u4e60\u662f\u4e00\u79cd\u6709\u6548\u7b56\u7565\u3002", "motivation": "\u73b0\u6709\u91cf\u5b50\u7ea0\u9519\u7684\u8868\u9762\u7801\u89e3\u7801\u5668\u5728\u5904\u7406\u8f93\u5165\u65f6\uff0c\u7531\u4e8e\u6b63\u786e\u9884\u6d4b\u7684\u4e0d\u552f\u4e00\u6027\uff0c\u53ea\u80fd\u83b7\u5f97\u8bef\u5dee\u6982\u7387\u5206\u5e03\uff0c\u65e0\u6cd5\u7cbe\u786e\u5b9a\u4f4d\u548c\u7ea0\u6b63\u9519\u8bef\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u9896\u6280\u672f\uff0c\u5229\u7528\u795e\u7ecf\u7f51\u7edc\u5c06\u6d4b\u91cf\u503c\u8fd1\u4f3c\u4e3a\u8fde\u7eed\u51fd\u6570\uff0c\u5e76\u901a\u8fc7\u6570\u5b66\u63d2\u503c\u8fdb\u884c\u4f18\u5316\uff0c\u4ee5\u91cd\u65b0\u6784\u5efa\u89e3\u7801\u5668\u6a21\u578b\u3002", "result": "\u4e0e\u539f\u59cb\u6a21\u578b\u76f8\u6bd4\uff0c\u5728\u4ee3\u7801\u8ddd\u79bb\u4e3a5\u548c7\u7684\u591a\u5c42\u611f\u77e5\u5668\u89e3\u7801\u5668\uff0c\u4ee5\u53ca\u4ee3\u7801\u8ddd\u79bb\u4e3a5\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u3001\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u548cTransformer\u89e3\u7801\u5668\u4e2d\uff0c\u91cd\u65b0\u4f18\u5316\u7684\u89e3\u7801\u5668\u90fd\u663e\u793a\u51fa\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u63d2\u503c\u8fde\u7eed\u51fd\u6570\u6765\u91cd\u65b0\u4f18\u5316\u89e3\u7801\u5668\u7684\u65b9\u6cd5\uff0c\u5728\u63d0\u9ad8\u8868\u9762\u7801\u89e3\u7801\u51c6\u786e\u6027\u65b9\u9762\u662f\u666e\u904d\u6709\u6548\u7684\uff0c\u4e0d\u4f9d\u8d56\u4e8e\u4ee3\u7801\u8ddd\u79bb\u6216\u7f51\u7edc\u67b6\u6784\u3002\u5c06\u8868\u9762\u7801\u89e3\u7801\u95ee\u9898\u91cd\u65b0\u6784\u5efa\u4e3a\u6df1\u5ea6\u5b66\u4e60\u53ef\u4ee5\u5904\u7406\u7684\u56de\u5f52\u95ee\u9898\u662f\u4e00\u79cd\u6709\u7528\u7684\u7b56\u7565\u3002"}}
{"id": "2509.10026", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.10026", "abs": "https://arxiv.org/abs/2509.10026", "authors": ["Jing Huang", "Zhiya Tan", "Shutao Gong", "Fanwei Zeng", "Jianshu Li"], "title": "LaV-CoT: Language-Aware Visual CoT with Multi-Aspect Reward Optimization for Real-World Multilingual VQA", "comment": "12 Pages, 12 Figures, 2 Tables", "summary": "As large vision language models (VLMs) advance, their capabilities in\nmultilingual visual question answering (mVQA) have significantly improved.\nChain-of-thought (CoT) reasoning has been proven to enhance interpretability\nand complex reasoning. However, most existing approaches rely primarily on\ntextual CoT and provide limited support for multilingual multimodal reasoning,\nconstraining their deployment in real-world applications. To address this gap,\nwe introduce \\textbf{LaV-CoT}, the first Language-aware Visual CoT framework\nwith Multi-Aspect Reward Optimization. LaV-CoT incorporates an interpretable\nmulti-stage reasoning pipeline consisting of Text Summary with Bounding Box\n(BBox), Language Identification, Spatial Object-level Captioning, and\nStep-by-step Logical Reasoning. Following this reasoning pipeline, we design an\nautomated data curation method that generates multilingual CoT annotations\nthrough iterative generation, correction, and refinement, enabling scalable and\nhigh-quality training data. To improve reasoning and generalization, LaV-CoT\nadopts a two-stage training paradigm combining Supervised Fine-Tuning (SFT)\nwith Language-aware Group Relative Policy Optimization (GRPO), guided by\nverifiable multi-aspect rewards including language consistency, structural\naccuracy, and semantic alignment. Extensive evaluations on public datasets\nincluding MMMB, Multilingual MMBench, and MTVQA show that LaV-CoT achieves up\nto \\(\\sim\\)9.5\\% accuracy improvements over open-source baselines of similar\nsize and even surpasses models with 2$\\times$ larger scales by \\(\\sim\\)2.6\\%.\nMoreover, LaV-CoT outperforms advanced proprietary models such as GPT-4o-0513\nand Gemini-2.5-flash. We further conducted an online A/B test to validate our\nmethod on real-world data, highlighting its effectiveness for industrial\ndeployment. Our code is available at this link:\n\\href{https://github.com/HJNVR/LaV-CoT}", "AI": {"tldr": "LaV-CoT \u662f\u4e00\u4e2a\u8bed\u8a00\u611f\u77e5\u7684\u89c6\u89c9\u94fe\u5f0f\u601d\u8003\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u9636\u6bb5\u63a8\u7406\u548c\u591a\u65b9\u9762\u5956\u52b1\u4f18\u5316\uff0c\u63d0\u5347\u4e86\u591a\u8bed\u8a00\u89c6\u89c9\u95ee\u7b54\u80fd\u529b\uff0c\u5728\u591a\u9879\u57fa\u51c6\u6d4b\u8bd5\u548c\u5b9e\u9645\u5e94\u7528\u4e2d\u5747\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8bed\u8a00\u89c6\u89c9\u95ee\u7b54\u65b9\u9762\u867d\u7136\u6709\u6240\u8fdb\u6b65\uff0c\u4f46\u4e3b\u8981\u4f9d\u8d56\u6587\u672c\u94fe\u5f0f\u601d\u8003\uff0c\u5bf9\u591a\u8bed\u8a00\u591a\u6a21\u6001\u63a8\u7406\u7684\u652f\u6301\u6709\u9650\uff0c\u9650\u5236\u4e86\u5176\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u5e94\u7528\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u4e2a\u80fd\u591f\u5904\u7406\u591a\u8bed\u8a00\u3001\u591a\u6a21\u6001\u4fe1\u606f\u7684\u94fe\u5f0f\u601d\u8003\u6846\u67b6\u3002", "method": "LaV-CoT \u6846\u67b6\u5305\u542b\u4e00\u4e2a\u591a\u9636\u6bb5\u63a8\u7406\u6d41\u7a0b\uff0c\u5305\u62ec\u5e26\u8fb9\u754c\u6846\uff08BBox\uff09\u7684\u6587\u672c\u6458\u8981\u3001\u8bed\u8a00\u8bc6\u522b\u3001\u7a7a\u95f4\u5bf9\u8c61\u7ea7\u5b57\u5e55\u751f\u6210\u548c\u9010\u6b65\u903b\u8f91\u63a8\u7406\u3002\u6b64\u5916\uff0c\u5b83\u8fd8\u8bbe\u8ba1\u4e86\u4e00\u79cd\u81ea\u52a8\u6570\u636e\u6574\u7406\u65b9\u6cd5\u6765\u751f\u6210\u591a\u8bed\u8a00\u94fe\u5f0f\u601d\u8003\u6807\u6ce8\uff0c\u5e76\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u548c\u8bed\u8a00\u611f\u77e5\u7684\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\uff08GRPO\uff09\u4e24\u9636\u6bb5\u8fdb\u884c\u8bad\u7ec3\uff0c\u4ee5\u8bed\u8a00\u4e00\u81f4\u6027\u3001\u7ed3\u6784\u51c6\u786e\u6027\u548c\u8bed\u4e49\u5bf9\u9f50\u7b49\u53ef\u9a8c\u8bc1\u7684\u591a\u65b9\u9762\u5956\u52b1\u4f5c\u4e3a\u6307\u5bfc\u3002", "result": "LaV-CoT \u5728 MMMB\u3001Multilingual MMBench \u548c MTVQA \u7b49\u516c\u5171\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u51c6\u786e\u7387\u6bd4\u540c\u7b49\u89c4\u6a21\u7684\u5f00\u6e90\u57fa\u7ebf\u6a21\u578b\u9ad8\u51fa\u7ea6 9.5%\uff0c\u751a\u81f3\u8d85\u8fc7\u4e86\u89c4\u6a21\u5927\u4e24\u500d\u7684\u6a21\u578b\u7ea6 2.6%\u3002\u540c\u65f6\uff0cLaV-CoT \u7684\u8868\u73b0\u4f18\u4e8e GPT-4o-0513 \u548c Gemini-2.5-flash \u7b49\u5148\u8fdb\u7684\u4e13\u6709\u6a21\u578b\u3002\u5728\u7ebf A/B \u6d4b\u8bd5\u4e5f\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u5de5\u4e1a\u90e8\u7f72\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "LaV-CoT \u6210\u529f\u5730\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u591a\u8bed\u8a00\u591a\u6a21\u6001\u63a8\u7406\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u5176\u521b\u65b0\u7684\u94fe\u5f0f\u601d\u8003\u6846\u67b6\u548c\u8bad\u7ec3\u8303\u5f0f\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u89c6\u89c9\u95ee\u7b54\u7684\u51c6\u786e\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u4ef7\u503c\u3002"}}
{"id": "2509.10430", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2509.10430", "abs": "https://arxiv.org/abs/2509.10430", "authors": ["Satyaki Manna", "Sneha Suresh", "Anandamay Das Bhowmik", "Debashis Saha"], "title": "Global vs. Local Discrimination of Locally Implementable Multipartite Unitaries", "comment": null, "summary": "We study single-shot distinguishability of locally implementable multipartite\nunitaries under Local Operations and Classical Communication (LOCC) and global\noperations. As unitary discrimination depends on both the choice of probing\nstates and the measurements on the evolved states, we classify LOCC and global\ndistinguishability into two categories: adaptive strategies, where probing\nstates are chosen based on measurement outcomes from other subsystems, and\nrestricted strategies, where probing states remain fixed. Our findings uncover\nthree surprising features in the bipartite setting and establish new structural\nlimits for unitary discrimination: (i) Certain pairs of unitaries are globally\ndistinguishable with restricted strategies but indistinguishable under LOCC,\neven with adaptive strategies. (ii) There exist sets of four unitaries that are\ndistinguishable via LOCC, yet remain globally indistinguishable with restricted\nstrategies. (iii) Some sets of unitaries are globally indistinguishable under\nadaptive strategies, when probed with separable states, but become\ndistinguishable via LOCC.", "AI": {"tldr": "\u5728\u5c40\u90e8\u64cd\u4f5c\u548c\u7ecf\u5178\u901a\u4fe1\uff08LOCC\uff09\u4ee5\u53ca\u5168\u5c40\u64cd\u4f5c\u4e0b\uff0c\u6211\u4eec\u7814\u7a76\u4e86\u53ef\u5c40\u90e8\u5b9e\u73b0\u7684\u91cf\u5b50\u6bd4\u7279\u9149\u53d8\u6362\u7684\u5355\u6b21\u53ef\u8fa8\u522b\u6027\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u533a\u5206\u9149\u53d8\u6362\u7684\u4e24\u79cd\u7b56\u7565\uff1a\u81ea\u9002\u5e94\u7b56\u7565\uff08\u6839\u636e\u5176\u4ed6\u5b50\u7cfb\u7edf\u7684\u6d4b\u91cf\u7ed3\u679c\u9009\u62e9\u63a2\u6d4b\u72b6\u6001\uff09\u548c\u53d7\u9650\u7b56\u7565\uff08\u63a2\u6d4b\u72b6\u6001\u56fa\u5b9a\uff09\u3002", "motivation": "\u7814\u7a76\u5c40\u90e8\u64cd\u4f5c\u548c\u7ecf\u5178\u901a\u4fe1\uff08LOCC\uff09\u4ee5\u53ca\u5168\u5c40\u64cd\u4f5c\u4e0b\uff0c\u53ef\u5c40\u90e8\u5b9e\u73b0\u7684\u91cf\u5b50\u6bd4\u7279\u9149\u53d8\u6362\u7684\u5355\u6b21\u53ef\u8fa8\u522b\u6027\u3002", "method": "\u6839\u636e\u63a2\u6d4b\u72b6\u6001\u7684\u9009\u62e9\u548c\u6f14\u5316\u540e\u7684\u72b6\u6001\u7684\u6d4b\u91cf\uff0c\u5c06LOCC\u548c\u5168\u5c40\u53ef\u8fa8\u522b\u6027\u5206\u4e3a\u81ea\u9002\u5e94\u7b56\u7565\u548c\u53d7\u9650\u7b56\u7565\u4e24\u7c7b\u3002", "result": "\u5728\u4e8c\u5206\u60c5\u5f62\u4e0b\uff0c\u6211\u4eec\u53d1\u73b0\u4e86\u4e09\u4e2a\u4ee4\u4eba\u60ca\u8bb6\u7684\u7279\u5f81\uff1a\uff081\uff09\u67d0\u4e9b\u9149\u53d8\u6362\u5bf9\u5728\u53d7\u9650\u7b56\u7565\u4e0b\u662f\u5168\u5c40\u53ef\u8fa8\u522b\u7684\uff0c\u4f46\u5728LOCC\u4e0b\u4e0d\u53ef\u8fa8\u522b\uff0c\u5373\u4f7f\u91c7\u7528\u81ea\u9002\u5e94\u7b56\u7565\u3002\uff082\uff09\u5b58\u5728\u56db\u4e2a\u9149\u53d8\u6362\u7684\u96c6\u5408\uff0c\u5b83\u4eec\u53ef\u4ee5\u901a\u8fc7LOCC\u8fdb\u884c\u8fa8\u522b\uff0c\u4f46\u5728\u53d7\u9650\u7b56\u7565\u4e0b\u4ecd\u7136\u662f\u5168\u5c40\u4e0d\u53ef\u8fa8\u522b\u7684\u3002\uff083\uff09\u5728\u81ea\u9002\u5e94\u7b56\u7565\u4e0b\uff0c\u4f7f\u7528\u53ef\u5206\u79bb\u6001\u8fdb\u884c\u63a2\u6d4b\u65f6\uff0c\u67d0\u4e9b\u9149\u53d8\u6362\u96c6\u5408\u662f\u5168\u5c40\u4e0d\u53ef\u8fa8\u522b\u7684\uff0c\u4f46\u901a\u8fc7LOCC\u5219\u53ef\u4ee5\u8fa8\u522b\u3002", "conclusion": "\u8be5\u7814\u7a76\u5728\u4e8c\u5206\u60c5\u5f62\u4e0b\u63ed\u793a\u4e86\u9149\u53d8\u6362\u53ef\u8fa8\u522b\u6027\u7684\u65b0\u7ed3\u6784\u9650\u5236\u3002"}}
{"id": "2509.10010", "categories": ["cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.10010", "abs": "https://arxiv.org/abs/2509.10010", "authors": ["Adnan Ahmad", "Philine Kowol", "Stefan Hillmann", "Sebastian M\u00f6ller"], "title": "Multi-Intent Recognition in Dialogue Understanding: A Comparison Between Smaller Open-Source LLMs", "comment": null, "summary": "In this paper, we provide an extensive analysis of multi-label intent\nclassification using Large Language Models (LLMs) that are open-source,\npublicly available, and can be run in consumer hardware. We use the MultiWOZ\n2.1 dataset, a benchmark in the dialogue system domain, to investigate the\nefficacy of three popular open-source pre-trained LLMs, namely LLama2-7B-hf,\nMistral-7B-v0.1, and Yi-6B. We perform the classification task in a few-shot\nsetup, giving 20 examples in the prompt with some instructions. Our approach\nfocuses on the differences in performance of these models across several\nperformance metrics by methodically assessing these models on multi-label\nintent classification tasks. Additionally, we compare the performance of the\ninstruction-based fine-tuning approach with supervised learning using the\nsmaller transformer model BertForSequenceClassification as a baseline. To\nevaluate the performance of the models, we use evaluation metrics like\naccuracy, precision, and recall as well as micro, macro, and weighted F1 score.\nWe also report the inference time, VRAM requirements, etc. The Mistral-7B-v0.1\noutperforms two other generative models on 11 intent classes out of 14 in terms\nof F-Score, with a weighted average of 0.50. It also has relatively lower\nHumming Loss and higher Jaccard Similarity, making it the winning model in the\nfew-shot setting. We find BERT based supervised classifier having superior\nperformance compared to the best performing few-shot generative LLM. The study\nprovides a framework for small open-source LLMs in detecting complex\nmulti-intent dialogues, enhancing the Natural Language Understanding aspect of\ntask-oriented chatbots.", "AI": {"tldr": "\u5f00\u6e90\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u591a\u6807\u7b7e\u610f\u56fe\u5206\u7c7b\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u5206\u6790\uff0c\u5e76\u4e0e\u76d1\u7763\u5b66\u4e60\u57fa\u7ebf\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002", "motivation": "\u8bc4\u4f30\u5f00\u6e90LLMs\u5728\u6d88\u8d39\u7ea7\u786c\u4ef6\u4e0a\u8fdb\u884c\u591a\u6807\u7b7e\u610f\u56fe\u5206\u7c7b\u7684\u53ef\u884c\u6027\uff0c\u5e76\u6bd4\u8f83\u5176\u4e0e\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u7684\u6027\u80fd\u5dee\u5f02\u3002", "method": "\u5728MultiWOZ 2.1\u6570\u636e\u96c6\u4e0a\uff0c\u4f7f\u7528LLama2-7B-hf\u3001Mistral-7B-v0.1\u548cYi-6B\u4e09\u4e2a\u5f00\u6e90LLMs\u8fdb\u884c\u5c11\u6837\u672c\uff08few-shot\uff09\u610f\u56fe\u5206\u7c7b\u3002\u540c\u65f6\uff0c\u5c06\u76d1\u7763\u5b66\u4e60\u7684BertForSequenceClassification\u6a21\u578b\u4f5c\u4e3a\u57fa\u7ebf\u8fdb\u884c\u6bd4\u8f83\u3002\u8bc4\u4f30\u6307\u6807\u5305\u62ec\u51c6\u786e\u7387\u3001\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u3001F1\u5206\u6570\uff08micro, macro, weighted\uff09\u3001\u63a8\u7406\u65f6\u95f4\u3001VRAM\u9700\u6c42\u7b49\u3002", "result": "Mistral-7B-v0.1\u572814\u4e2a\u610f\u56fe\u7c7b\u522b\u4e2d\u768411\u4e2a\u7c7b\u522b\u4e0aF-Score\u4f18\u4e8e\u5176\u4ed6\u4e24\u4e2a\u751f\u6210\u6a21\u578b\uff0c\u52a0\u6743\u5e73\u5747F-Score\u4e3a0.50\uff0c\u5e76\u4e14\u5177\u6709\u8f83\u4f4e\u7684Humming Loss\u548c\u8f83\u9ad8\u7684Jaccard Similarity\u3002\u7136\u800c\uff0c\u57fa\u4e8eBERT\u7684\u76d1\u7763\u5b66\u4e60\u5206\u7c7b\u5668\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u8868\u73b0\u6700\u597d\u7684\u5c11\u6837\u672c\u751f\u6210\u5f0fLLM\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5c0f\u578b\u5f00\u6e90LLMs\u5728\u8bc6\u522b\u590d\u6742\u591a\u610f\u56fe\u5bf9\u8bdd\u65b9\u9762\u63d0\u4f9b\u4e86\u6846\u67b6\uff0c\u5e76\u5f3a\u8c03\u4e86\u4e0e\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5f00\u6e90LLMs\u5728\u5c11\u6837\u672c\u8bbe\u7f6e\u4e0b\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\uff0c\u4f46\u5176\u5728\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u65b9\u9762\u7684\u6f5c\u529b\u4e0d\u5bb9\u5ffd\u89c6\u3002"}}
{"id": "2509.10167", "categories": ["cs.LG", "68T07, 60H30, 34F05"], "pdf": "https://arxiv.org/pdf/2509.10167", "abs": "https://arxiv.org/abs/2509.10167", "authors": ["L\u00e9na\u00efc Chizat"], "title": "The Hidden Width of Deep ResNets: Tight Error Bounds and Phase Diagrams", "comment": null, "summary": "We study the gradient-based training of large-depth residual networks\n(ResNets) from standard random initializations. We show that with a diverging\ndepth $L$, a fixed embedding dimension $D$, and an arbitrary hidden width $M$,\nthe training dynamics converges to a Neural Mean ODE training dynamics.\nRemarkably, the limit is independent of the scaling of $M$, covering practical\ncases of, say, Transformers, where $M$ (the number of hidden units or attention\nheads per layer) is typically of the order of $D$. For a residual scale\n$\\Theta_D\\big(\\frac{\\alpha}{LM}\\big)$, we obtain the error bound\n$O_D\\big(\\frac{1}{L}+ \\frac{\\alpha}{\\sqrt{LM}}\\big)$ between the model's output\nand its limit after a fixed number gradient of steps, and we verify empirically\nthat this rate is tight. When $\\alpha=\\Theta(1)$, the limit exhibits complete\nfeature learning, i.e. the Mean ODE is genuinely non-linearly parameterized. In\ncontrast, we show that $\\alpha \\to \\infty$ yields a \\lazy ODE regime where the\nMean ODE is linearly parameterized. We then focus on the particular case of\nResNets with two-layer perceptron blocks, for which we study how these scalings\ndepend on the embedding dimension $D$. We show that for this model, the only\nresidual scale that leads to complete feature learning is\n$\\Theta\\big(\\frac{\\sqrt{D}}{LM}\\big)$. In this regime, we prove the error bound\n$O\\big(\\frac{1}{L}+ \\frac{\\sqrt{D}}{\\sqrt{LM}}\\big)$ between the ResNet and its\nlimit after a fixed number of gradient steps, which is also empirically tight.\nOur convergence results rely on a novel mathematical perspective on ResNets :\n(i) due to the randomness of the initialization, the forward and backward pass\nthrough the ResNet behave as the stochastic approximation of certain mean ODEs,\nand (ii) by propagation of chaos (that is, asymptotic independence of the\nunits) this behavior is preserved through the training dynamics.", "AI": {"tldr": "\u6df1\u5ea6\u6b8b\u5dee\u7f51\u7edc(ResNets)\u5728\u6807\u51c6\u968f\u673a\u521d\u59cb\u5316\u4e0b\u7684\u68af\u5ea6\u4e0b\u964d\u8bad\u7ec3\u4f1a\u6536\u655b\u5230\u4e00\u4e2a\u4e0e\u5bbd\u5ea6M\u65e0\u5173\u7684\u795e\u7ecfODE\u8bad\u7ec3\u52a8\u529b\u5b66\u3002\u6211\u4eec\u63a8\u5bfc\u4e86\u5728\u7279\u5b9a\u6b8b\u5dee\u5c3a\u5ea6\u4e0b\uff0c\u6a21\u578b\u8f93\u51fa\u4e0e\u6781\u9650\u4e4b\u95f4\u7684\u8bef\u5dee\u754c\u9650\uff0c\u5e76\u8fdb\u884c\u4e86\u7ecf\u9a8c\u9a8c\u8bc1\u3002", "motivation": "\u7814\u7a76\u6df1\u5ea6\u6b8b\u5dee\u7f51\u7edc(ResNets)\u5728\u6807\u51c6\u968f\u673a\u521d\u59cb\u5316\u4e0b\u7684\u68af\u5ea6\u4e0b\u964d\u8bad\u7ec3\u52a8\u529b\u5b66\uff0c\u7279\u522b\u662f\u5f53\u7f51\u7edc\u6df1\u5ea6L\u8d8b\u4e8e\u65e0\u7a77\u65f6\u7684\u60c5\u51b5\u3002", "method": "\u901a\u8fc7\u6570\u5b66\u5206\u6790\u548c\u7ecf\u9a8c\u9a8c\u8bc1\uff0c\u63a8\u5bfc\u4e86\u5728\u7279\u5b9a\u6b8b\u5dee\u5c3a\u5ea6\u4e0b\uff0c\u6df1\u5ea6\u6b8b\u5dee\u7f51\u7edc\u8bad\u7ec3\u52a8\u529b\u5b66\u7684\u8bef\u5dee\u754c\u9650\uff0c\u5e76\u63a2\u8ba8\u4e86\u7279\u5f81\u5b66\u4e60\u548clazy ODE\u4e24\u79cd\u60c5\u51b5\u3002", "result": "\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\uff0c\u8bc1\u660e\u4e86\u8bad\u7ec3\u52a8\u529b\u5b66\u6536\u655b\u5230\u795e\u7ecfODE\uff0c\u5e76\u7ed9\u51fa\u4e86\u8bef\u5dee\u754c\u9650\u3002\u8bc1\u660e\u4e86\u6b8b\u5dee\u5c3a\u5ea6\u5982\u4f55\u5f71\u54cd\u7279\u5f81\u5b66\u4e60\u548clazy ODE\u3002\u5bf9\u4e8e\u4e24\u5c42\u611f\u77e5\u5668\u5757\u7684ResNets\uff0c\u7ed9\u51fa\u4e86\u5b9e\u73b0\u5b8c\u5168\u7279\u5f81\u5b66\u4e60\u6240\u9700\u7684\u6b8b\u5dee\u5c3a\u5ea6\uff0c\u5e76\u7ed9\u51fa\u4e86\u76f8\u5e94\u7684\u8bef\u5dee\u754c\u9650\u3002", "conclusion": "\u6df1\u5ea6\u6b8b\u5dee\u7f51\u7edc\u7684\u8bad\u7ec3\u52a8\u529b\u5b66\u53ef\u4ee5\u88ab\u7406\u89e3\u4e3a\u795e\u7ecfODE\u7684\u968f\u673a\u8fd1\u4f3c\u3002\u6b8b\u5dee\u5c3a\u5ea6\u5728\u51b3\u5b9a\u7f51\u7edc\u662f\u8fdb\u884c\u5b8c\u5168\u7279\u5f81\u5b66\u4e60\u8fd8\u662f\u8fdb\u5165lazy ODE\u72b6\u6001\u65b9\u9762\u8d77\u7740\u5173\u952e\u4f5c\u7528\u3002"}}
{"id": "2509.10058", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.10058", "abs": "https://arxiv.org/abs/2509.10058", "authors": ["Sung-Lin Tsai", "Bo-Lun Huang", "Yu Ting Shen", "Cheng Yu Yeo", "Chiang Tseng", "Bo-Kai Ruan", "Wen-Sheng Lien", "Hong-Han Shuai"], "title": "Color Me Correctly: Bridging Perceptual Color Spaces and Text Embeddings for Improved Diffusion Generation", "comment": "Accepted to ACM Multimedia 2025 (MM '25)", "summary": "Accurate color alignment in text-to-image (T2I) generation is critical for\napplications such as fashion, product visualization, and interior design, yet\ncurrent diffusion models struggle with nuanced and compound color terms (e.g.,\nTiffany blue, lime green, hot pink), often producing images that are misaligned\nwith human intent. Existing approaches rely on cross-attention manipulation,\nreference images, or fine-tuning but fail to systematically resolve ambiguous\ncolor descriptions. To precisely render colors under prompt ambiguity, we\npropose a training-free framework that enhances color fidelity by leveraging a\nlarge language model (LLM) to disambiguate color-related prompts and guiding\ncolor blending operations directly in the text embedding space. Our method\nfirst employs a large language model (LLM) to resolve ambiguous color terms in\nthe text prompt, and then refines the text embeddings based on the spatial\nrelationships of the resulting color terms in the CIELAB color space. Unlike\nprior methods, our approach improves color accuracy without requiring\nadditional training or external reference images. Experimental results\ndemonstrate that our framework improves color alignment without compromising\nimage quality, bridging the gap between text semantics and visual generation.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u8bad\u7ec3\u65e0\u5173\u7684\u6846\u67b6\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u6765\u6d88\u9664\u6b67\u4e49\u7684\u989c\u8272\u8bcd\u6c47\uff0c\u5e76\u76f4\u63a5\u5728\u6587\u672c\u5d4c\u5165\u7a7a\u95f4\u4e2d\u6307\u5bfc\u989c\u8272\u6df7\u5408\u64cd\u4f5c\uff0c\u4ee5\u63d0\u9ad8\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u4e2d\u989c\u8272\u5bf9\u9f50\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u6a21\u578b\u5728\u5904\u7406\u7ec6\u81f4\u548c\u590d\u5408\u7684\u989c\u8272\u8bcd\u6c47\u65f6\u5b58\u5728\u56f0\u96be\uff0c\u5bfc\u81f4\u751f\u6210\u7684\u56fe\u50cf\u4e0e\u7528\u6237\u610f\u56fe\u4e0d\u7b26\uff0c\u5c24\u5176\u662f\u5728\u65f6\u5c1a\u3001\u4ea7\u54c1\u53ef\u89c6\u5316\u548c\u5ba4\u5185\u8bbe\u8ba1\u7b49\u5e94\u7528\u4e2d\u3002", "method": "\u8be5\u6846\u67b6\u9996\u5148\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u6765\u89e3\u6790\u6587\u672c\u63d0\u793a\u4e2d\u6a21\u7cca\u7684\u989c\u8272\u8bcd\u6c47\uff0c\u7136\u540e\u6839\u636e\u6240\u5f97\u989c\u8272\u8bcd\u6c47\u5728CIELAB\u989c\u8272\u7a7a\u95f4\u4e2d\u7684\u7a7a\u95f4\u5173\u7cfb\u6765\u4f18\u5316\u6587\u672c\u5d4c\u5165\u3002\u8be5\u65b9\u6cd5\u5728\u6587\u672c\u5d4c\u5165\u7a7a\u95f4\u4e2d\u8fdb\u884c\u64cd\u4f5c\uff0c\u5e76\u4e14\u4e0d\u9700\u8981\u989d\u5916\u7684\u8bad\u7ec3\u6216\u53c2\u8003\u56fe\u50cf\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u4e0d\u635f\u5bb3\u56fe\u50cf\u8d28\u91cf\u7684\u60c5\u51b5\u4e0b\u63d0\u9ad8\u4e86\u989c\u8272\u5bf9\u9f50\u7684\u51c6\u786e\u6027\uff0c\u6709\u6548\u5f25\u5408\u4e86\u6587\u672c\u8bed\u4e49\u4e0e\u89c6\u89c9\u751f\u6210\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684\u8bad\u7ec3\u65e0\u5173\u6846\u67b6\u901a\u8fc7LLM\u6d88\u9664\u4e86\u989c\u8272\u8bcd\u6c47\u7684\u6b67\u4e49\uff0c\u5e76\u76f4\u63a5\u5728\u6587\u672c\u5d4c\u5165\u7a7a\u95f4\u4e2d\u8fdb\u884c\u989c\u8272\u6df7\u5408\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u4e2d\u7684\u989c\u8272\u51c6\u786e\u6027\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u6216\u53c2\u8003\u56fe\u50cf\u3002"}}
{"id": "2509.10437", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2509.10437", "abs": "https://arxiv.org/abs/2509.10437", "authors": ["Sagnik Ray", "Anubhav Chaturvedi", "Debashis Saha"], "title": "Maximally $\u03c8-$epistemic models cannot explain gambling with two qubits", "comment": "9 pages, 4 figures", "summary": "We investigate the minimal proof for ruling out maximally $\\psi-$epistemic\ninterpretations of quantum theory, in which the indistinguishable nature of two\nquantum states is fully explained by the epistemic overlap of their\ncorresponding distributions over ontic states. To this end, we extend the\nstandard notion of epistemic overlap by considering a penalized\ndistinguishability game involving two states and three possible answers, named\nas Quantum Gambling. In this context, using only two pure states and their\nequal mixture, we present an experimentally robust no-go theorem for maximally\n$\\psi-$epistemic models, showing that qubit states achieve the maximal\ndifference between quantum and epistemic overlaps.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3a\u201c\u91cf\u5b50\u8d4c\u535a\u201d\u7684\u65b0\u6982\u5ff5\uff0c\u5e76\u5229\u7528\u5b83\u6765\u6392\u9664\u91cf\u5b50\u529b\u5b66\u7684\u4e00\u4e9b\u89e3\u91ca\u3002", "motivation": "\u4e3a\u4e86\u6392\u9664\u91cf\u5b50\u529b\u5b66\u7684\u67d0\u4e9b\u6700\u5927 $\\psi-$ epistemic \u89e3\u91ca\uff0c\u5373\u91cf\u5b50\u6001\u7684\u4e0d\u53ef\u533a\u5206\u6027\u5b8c\u5168\u7531\u5176\u5728\u672c\u4f53\u72b6\u6001\u4e0a\u7684\u5206\u5e03\u7684\u8ba4\u8bc6\u91cd\u53e0\u6765\u89e3\u91ca\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u4e2a\u65b0\u7684\u201c\u91cf\u5b50\u8d4c\u535a\u201d\u6e38\u620f\uff0c\u901a\u8fc7\u8003\u8651\u4e24\u4e2a\u91cf\u5b50\u6001\u548c\u4e09\u79cd\u53ef\u80fd\u7684\u7b54\u6848\u6765\u533a\u5206\u5b83\u4eec\uff0c\u4ece\u800c\u6269\u5c55\u4e86\u8ba4\u8bc6\u91cd\u53e0\u7684\u6807\u51c6\u6982\u5ff5\u3002", "result": "\u4f7f\u7528\u4e24\u4e2a\u7eaf\u6001\u53ca\u5176\u7b49\u91cf\u6df7\u5408\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u5b9e\u9a8c\u4e0a\u53ef\u884c\u7684\u5426\u5b9a\u8bc1\u660e\uff0c\u6392\u9664\u4e86\u6700\u5927 $\\psi-$ epistemic \u6a21\u578b\u3002\u7ed3\u679c\u8868\u660e\uff0c\u91cf\u5b50\u6bd4\u7279\u6001\u5728\u91cf\u5b50\u91cd\u53e0\u548c\u8ba4\u8bc6\u91cd\u53e0\u4e4b\u95f4\u5b9e\u73b0\u4e86\u6700\u5927\u7684\u5dee\u5f02\u3002", "conclusion": "\u91cf\u5b50\u6001\u7684\u4e0d\u53ef\u533a\u5206\u6027\u4e0d\u80fd\u5b8c\u5168\u7531\u5176\u5728\u672c\u4f53\u72b6\u6001\u4e0a\u7684\u5206\u5e03\u7684\u8ba4\u8bc6\u91cd\u53e0\u6765\u89e3\u91ca\uff0c\u91cf\u5b50\u6bd4\u7279\u6001\u5728\u91cf\u5b50\u91cd\u53e0\u548c\u8ba4\u8bc6\u91cd\u53e0\u4e4b\u95f4\u5b9e\u73b0\u4e86\u6700\u5927\u7684\u5dee\u5f02\u3002"}}
{"id": "2509.10035", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.10035", "abs": "https://arxiv.org/abs/2509.10035", "authors": ["Laurin Plank", "Armin Zlomuzica"], "title": "Linguistic trajectories of bipolar disorder on social media", "comment": "Pre-print", "summary": "Language provides valuable markers of affective disorders such as bipolar\ndisorder (BD), yet clinical assessments remain limited in scale. In response,\nanalyses of social media (SM) language have gained prominence due to their high\ntemporal resolution and longitudinal scope. Here, we introduce a method to\ndetermine the timing of users' diagnoses and apply it to study language\ntrajectories from 3 years before to 21 years after BD diagnosis - contrasted\nwith uses reporting unipolar depression (UD) and non-affected users (HC). We\nshow that BD diagnosis is accompanied by pervasive linguistic alterations\nreflecting mood disturbance, psychiatric comorbidity, substance abuse,\nhospitalization, medical comorbidities, unusual thought content, and\ndisorganized thought. We further observe recurring mood-related language\nchanges across two decades after the diagnosis, with a pronounced 12-month\nperiodicity suggestive of seasonal mood episodes. Finally, trend-level evidence\nsuggests an increased periodicity in users estimated to be female. In sum, our\nfindings provide evidence for language alterations in the acute and chronic\nphase of BD. This validates and extends recent efforts leveraging SM for\nscalable monitoring of mental health.", "AI": {"tldr": "\u8fd9\u9879\u7814\u7a76\u5229\u7528\u793e\u4ea4\u5a92\u4f53\u6570\u636e\u5206\u6790\u4e86\u53cc\u76f8\u60c5\u611f\u969c\u788d\uff08BD\uff09\u60a3\u8005\u7684\u8bed\u8a00\u53d8\u5316\u8f68\u8ff9\uff0c\u53d1\u73b0\u5728\u786e\u8bca\u524d\u540e\u4ee5\u53ca\u957f\u8fbe\u4e8c\u5341\u4e00\u5e74\u540e\uff0cBD\u60a3\u8005\u7684\u8bed\u8a00\u90fd\u4f34\u968f\u7740\u60c5\u7eea\u3001\u7cbe\u795e\u75be\u75c5\u3001\u7269\u8d28\u6ee5\u7528\u3001\u5c31\u533b\u7b49\u591a\u65b9\u9762\u95ee\u9898\u7684\u663e\u8457\u53d8\u5316\uff0c\u5e76\u89c2\u5bdf\u5230\u4e0e\u5b63\u8282\u6027\u53d1\u4f5c\u76f8\u5173\u7684\u5341\u4e8c\u4e2a\u6708\u5468\u671f\u6027\u8bed\u8a00\u53d8\u5316\u6a21\u5f0f\uff0c\u5973\u6027\u60a3\u8005\u7684\u5468\u671f\u6027\u53ef\u80fd\u66f4\u5f3a\u3002", "motivation": "\u4e34\u5e8a\u4e0a\u8bc4\u4f30\u60c5\u611f\u969c\u788d\uff08\u5982\u53cc\u76f8\u60c5\u611f\u969c\u788d\uff0cBD\uff09\u89c4\u6a21\u53d7\u9650\uff0c\u56e0\u6b64\u5229\u7528\u5177\u6709\u9ad8\u65f6\u95f4\u5206\u8fa8\u7387\u548c\u957f\u671f\u8ffd\u8e2a\u80fd\u529b\u7684\u793e\u4ea4\u5a92\u4f53\uff08SM\uff09\u8bed\u8a00\u8fdb\u884c\u5206\u6790\uff0c\u4ee5\u7814\u7a76BD\u60a3\u8005\u7684\u8bed\u8a00\u53d8\u5316\u8f68\u8ff9\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u786e\u5b9a\u7528\u6237\u8bca\u65ad\u65f6\u95f4\u70b9\u7684\u65b9\u6cd5\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u5206\u6790BD\u3001\u5355\u76f8\u6291\u90c1\uff08UD\uff09\u548c\u5065\u5eb7\u5bf9\u7167\uff08HC\uff09\u7528\u6237\u5728\u8bca\u65ad\u524d\u540e\uff08BD\u4e3a\u786e\u8bca\u524d3\u5e74\u5230\u786e\u8bca\u540e21\u5e74\uff09\u7684\u8bed\u8a00\u8f68\u8ff9\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0cBD\u786e\u8bca\u4f34\u968f\u7740\u5e7f\u6cdb\u7684\u8bed\u8a00\u6539\u53d8\uff0c\u53cd\u6620\u4e86\u60c5\u7eea\u6ce2\u52a8\u3001\u7cbe\u795e\u5408\u5e76\u75c7\u3001\u836f\u7269\u6ee5\u7528\u3001\u4f4f\u9662\u3001\u8eab\u4f53\u5408\u5e76\u75c7\u3001\u5f02\u5e38\u601d\u7ef4\u548c\u601d\u7ef4\u7d0a\u4e71\u3002\u5728\u8bca\u65ad\u540e\u7684\u4e8c\u5341\u5e74\u91cc\uff0c\u89c2\u5bdf\u5230\u53cd\u590d\u51fa\u73b0\u4e0e\u60c5\u7eea\u76f8\u5173\u7684\u8bed\u8a00\u53d8\u5316\uff0c\u5e76\u5448\u73b0\u51fa\u660e\u663e\u7684\u5341\u4e8c\u4e2a\u6708\u5468\u671f\u6027\uff0c\u63d0\u793a\u5b63\u8282\u6027\u60c5\u7eea\u53d1\u4f5c\u3002\u6b64\u5916\uff0c\u6709\u8bc1\u636e\u8868\u660e\u5973\u6027\u60a3\u8005\u7684\u5468\u671f\u6027\u53ef\u80fd\u66f4\u5f3a\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3aBD\u6025\u6027\u671f\u548c\u6162\u6027\u671f\u7684\u8bed\u8a00\u6539\u53d8\u63d0\u4f9b\u4e86\u8bc1\u636e\uff0c\u9a8c\u8bc1\u5e76\u6269\u5c55\u4e86\u5229\u7528\u793e\u4ea4\u5a92\u4f53\u8fdb\u884c\u53ef\u6269\u5c55\u5fc3\u7406\u5065\u5eb7\u76d1\u6d4b\u7684\u6700\u65b0\u52aa\u529b\u3002"}}
{"id": "2509.10186", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10186", "abs": "https://arxiv.org/abs/2509.10186", "authors": ["Benjamin Holzschuh", "Georg Kohl", "Florian Redinger", "Nils Thuerey"], "title": "P3D: Scalable Neural Surrogates for High-Resolution 3D Physics Simulations with Global Context", "comment": null, "summary": "We present a scalable framework for learning deterministic and probabilistic\nneural surrogates for high-resolution 3D physics simulations. We introduce a\nhybrid CNN-Transformer backbone architecture targeted for 3D physics\nsimulations, which significantly outperforms existing architectures in terms of\nspeed and accuracy. Our proposed network can be pretrained on small patches of\nthe simulation domain, which can be fused to obtain a global solution,\noptionally guided via a fast and scalable sequence-to-sequence model to include\nlong-range dependencies. This setup allows for training large-scale models with\nreduced memory and compute requirements for high-resolution datasets. We\nevaluate our backbone architecture against a large set of baseline methods with\nthe objective to simultaneously learn the dynamics of 14 different types of\nPDEs in 3D. We demonstrate how to scale our model to high-resolution isotropic\nturbulence with spatial resolutions of up to $512^3$. Finally, we demonstrate\nthe versatility of our network by training it as a diffusion model to produce\nprobabilistic samples of highly turbulent 3D channel flows across varying\nReynolds numbers, accurately capturing the underlying flow statistics.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5b66\u4e60\u9ad8\u5206\u8fa8\u73873D\u7269\u7406\u6a21\u62df\u7684\u786e\u5b9a\u6027\u548c\u6982\u7387\u795e\u7ecf\u4ee3\u7406\u6a21\u578b\u3002\u8be5\u6846\u67b6\u91c7\u7528\u6df7\u5408CNN-Transformer\u9aa8\u5e72\u67b6\u6784\uff0c\u5728\u901f\u5ea6\u548c\u51c6\u786e\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002\u6a21\u578b\u53ef\u4ee5\u5148\u5728\u5c0f\u7684\u6a21\u62df\u57df\u5757\u4e0a\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u7136\u540e\u878d\u5408\u5f97\u5230\u5168\u5c40\u89e3\uff0c\u5e76\u901a\u8fc7\u5e8f\u5217\u5230\u5e8f\u5217\u6a21\u578b\u5904\u7406\u957f\u7a0b\u4f9d\u8d56\u5173\u7cfb\uff0c\u4ece\u800c\u51cf\u5c11\u4e86\u9ad8\u5206\u8fa8\u7387\u6570\u636e\u96c6\u7684\u5185\u5b58\u548c\u8ba1\u7b97\u9700\u6c42\u3002\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u6a21\u578b\u5728\u5b66\u4e6014\u79cd\u4e0d\u540c\u76843D\u504f\u5fae\u5206\u7a0b\u65b9\u9762\u7684\u80fd\u529b\uff0c\u5e76\u6210\u529f\u6269\u5c55\u5230512^3\u5206\u8fa8\u7387\u7684\u5404\u5411\u540c\u6027\u6e4d\u6d41\u6a21\u62df\u3002\u6b64\u5916\uff0c\u8be5\u7f51\u7edc\u8fd8\u53ef\u4ee5\u4f5c\u4e3a\u6269\u6563\u6a21\u578b\uff0c\u751f\u6210\u4e0d\u540c\u96f7\u8bfa\u6570\u4e0b\u6e4d\u6d413D\u901a\u9053\u6d41\u7684\u6982\u7387\u6837\u672c\uff0c\u5e76\u51c6\u786e\u6355\u6349\u5176\u7edf\u8ba1\u7279\u6027\u3002", "motivation": "\u4e3a\u9ad8\u5206\u8fa8\u73873D\u7269\u7406\u6a21\u62df\u63d0\u4f9b\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u6846\u67b6\uff0c\u4ee5\u5b66\u4e60\u786e\u5b9a\u6027\u548c\u6982\u7387\u795e\u7ecf\u4ee3\u7406\u6a21\u578b\uff0c\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u901f\u5ea6\u548c\u51c6\u786e\u6027\u4e0a\u7684\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408CNN-Transformer\u9aa8\u5e72\u67b6\u6784\uff0c\u5141\u8bb8\u5728\u5c0f\u5757\u57df\u4e0a\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u5e76\u901a\u8fc7\u5e8f\u5217\u5230\u5e8f\u5217\u6a21\u578b\u5904\u7406\u957f\u7a0b\u4f9d\u8d56\u5173\u7cfb\uff0c\u4ee5\u51cf\u5c11\u5185\u5b58\u548c\u8ba1\u7b97\u9700\u6c42\u3002", "result": "\u6240\u63d0\u51fa\u7684\u9aa8\u5e72\u67b6\u6784\u5728\u540c\u65f6\u5b66\u4e6014\u79cd\u4e0d\u540c\u76843D\u504f\u5fae\u5206\u7a0b\u65b9\u9762\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u3002\u6a21\u578b\u6210\u529f\u6269\u5c55\u5230512^3\u5206\u8fa8\u7387\u7684\u5404\u5411\u540c\u6027\u6e4d\u6d41\u6a21\u62df\u3002\u4f5c\u4e3a\u6269\u6563\u6a21\u578b\uff0c\u8be5\u7f51\u7edc\u80fd\u591f\u51c6\u786e\u6355\u6349\u4e0d\u540c\u96f7\u8bfa\u6570\u4e0b\u6e4d\u6d413D\u901a\u9053\u6d41\u7684\u7edf\u8ba1\u7279\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6df7\u5408CNN-Transformer\u6846\u67b6\u662f\u4e00\u79cd\u901a\u7528\u4e14\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u5b66\u4e60\u5404\u79cd3D\u7269\u7406\u6a21\u62df\u7684\u795e\u7ecf\u4ee3\u7406\u6a21\u578b\uff0c\u80fd\u591f\u9ad8\u6548\u5904\u7406\u9ad8\u5206\u8fa8\u7387\u6570\u636e\u5e76\u51c6\u786e\u6355\u6349\u7269\u7406\u73b0\u8c61\u3002"}}
{"id": "2509.10059", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10059", "abs": "https://arxiv.org/abs/2509.10059", "authors": ["Yue Zhou", "Litong Feng", "Mengcheng Lan", "Xue Yang", "Qingyun Li", "Yiping Ke", "Xue Jiang", "Wayne Zhang"], "title": "Multimodal Mathematical Reasoning Embedded in Aerial Vehicle Imagery: Benchmarking, Analysis, and Exploration", "comment": "17 pages, 16 figures", "summary": "Mathematical reasoning is critical for tasks such as precise distance and\narea computations, trajectory estimations, and spatial analysis in unmanned\naerial vehicle (UAV) based remote sensing, yet current vision-language models\n(VLMs) have not been adequately tested in this domain. To address this gap, we\nintroduce AVI-Math, the first benchmark to rigorously evaluate multimodal\nmathematical reasoning in aerial vehicle imagery, moving beyond simple counting\ntasks to include domain-specific knowledge in areas such as geometry, logic,\nand algebra. The dataset comprises 3,773 high-quality vehicle-related questions\ncaptured from UAV views, covering 6 mathematical subjects and 20 topics. The\ndata, collected at varying altitudes and from multiple UAV angles, reflects\nreal-world UAV scenarios, ensuring the diversity and complexity of the\nconstructed mathematical problems. In this paper, we benchmark 14 prominent\nVLMs through a comprehensive evaluation and demonstrate that, despite their\nsuccess on previous multimodal benchmarks, these models struggle with the\nreasoning tasks in AVI-Math. Our detailed analysis highlights significant\nlimitations in the mathematical reasoning capabilities of current VLMs and\nsuggests avenues for future research. Furthermore, we explore the use of\nChain-of-Thought prompting and fine-tuning techniques, which show promise in\naddressing the reasoning challenges in AVI-Math. Our findings not only expose\nthe limitations of VLMs in mathematical reasoning but also offer valuable\ninsights for advancing UAV-based trustworthy VLMs in real-world applications.\nThe code, and datasets will be released at\nhttps://github.com/VisionXLab/avi-math", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86AVI-Math\uff0c\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u65e0\u4eba\u673a\uff08UAV\uff09\u56fe\u50cf\u4e2d\u591a\u6a21\u6001\u6570\u5b66\u63a8\u7406\u7684\u57fa\u51c6\uff0c\u5e76\u6d4b\u8bd5\u4e8614\u79cd\u4e3b\u6d41\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\uff0c\u53d1\u73b0\u5b83\u4eec\u5728\u5904\u7406\u8fd9\u7c7b\u4efb\u52a1\u65f6\u5b58\u5728\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u5728\u5904\u7406\u65e0\u4eba\u673a\uff08UAV\uff09\u76f8\u5173\u7684\u7cbe\u786e\u8ba1\u7b97\u3001\u8f68\u8ff9\u4f30\u8ba1\u548c\u7a7a\u95f4\u5206\u6790\u7b49\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u65b9\u9762\u80fd\u529b\u4e0d\u8db3\uff0c\u56e0\u6b64\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u4e13\u95e8\u7684\u57fa\u51c6\u6765\u8bc4\u4f30\u548c\u6539\u8fdb\u8fd9\u4e00\u9886\u57df\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b3,773\u4e2a\u65e0\u4eba\u673a\u89c6\u89d2\u4e0b\u7684\u6570\u5b66\u63a8\u7406\u95ee\u9898\u7684AVI-Math\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u51e0\u4f55\u3001\u903b\u8f91\u3001\u4ee3\u6570\u7b496\u4e2a\u6570\u5b66\u79d1\u76ee\u548c20\u4e2a\u4e3b\u9898\u3002\u5bf914\u79cd\u4e3b\u6d41VLMs\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u63a2\u7d22\u4e86\u601d\u7ef4\u94fe\uff08Chain-of-Thought\uff09\u63d0\u793a\u548c\u5fae\u8c03\u6280\u672f\u3002", "result": "\u5728AVI-Math\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c14\u79cd\u4e3b\u6d41VLMs\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u66b4\u9732\u4e86\u5b83\u4eec\u5728\u8be5\u9886\u57df\u80fd\u529b\u7684\u663e\u8457\u5c40\u9650\u6027\u3002\u601d\u7ef4\u94fe\u63d0\u793a\u548c\u5fae\u8c03\u6280\u672f\u663e\u793a\u51fa\u4e00\u5b9a\u7684\u6539\u8fdb\u6f5c\u529b\u3002", "conclusion": "\u5f53\u524d\u7684VLMs\u5728\u5904\u7406\u65e0\u4eba\u673a\u56fe\u50cf\u4e2d\u7684\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7684\u7814\u7a76\u6765\u63d0\u5347\u5176\u80fd\u529b\uff0c\u4ee5\u6ee1\u8db3\u771f\u5b9e\u4e16\u754c\u5e94\u7528\u4e2d\u5bf9\u53ef\u4fe1\u8d56VLMs\u7684\u9700\u6c42\u3002AVI-Math\u6570\u636e\u96c6\u548c\u76f8\u5173\u4ee3\u7801\u5c06\u516c\u5f00\u3002"}}
{"id": "2509.10445", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2509.10445", "abs": "https://arxiv.org/abs/2509.10445", "authors": ["Shuai Liu", "Kailu Zhou", "Yuheng Zhang", "Abdulkarim Hariri", "Nicholas Reynolds", "Bo-Han Wu", "Zheshen Zhang"], "title": "Wafer-Scale Squeezed-Light Chips", "comment": "10 pages, 4 figures", "summary": "Squeezed-light generation in photonic integrated circuits (PICs) is essential\nfor scalable continuous-variable (CV) quantum information processing. By\nsuppressing quantum fluctuations below the shot-noise limit, squeezed states\nenable quantum-enhanced sensing and serve as a standard resource for CV quantum\ninformation processing. While chip-level squeezed-light sources have been\ndemonstrated, extending this capability to the wafer level with reproducible\nstrong squeezing to bolster large-scale quantum-enhanced sensing and\ninformation processing has been hindered by squeezed light's extreme\nsusceptibility to device imperfections. Here, we report wafer-scale\nfabrication, generation, and characterization of two-mode squeezed-vacuum\nstates on a fully complementary metal-oxide-semiconductor (CMOS)-compatible\nsilicon nitride (Si$_3$N$_4$) PIC platform. Across a 4-inch wafer, 8 dies yield\n2.9-3.1 dB directly measured quadrature squeezing with $< 0.2$ dB variation,\ndemonstrating excellent uniformity. This performance is enabled by\nco-integrating ultralow-loss, strongly overcoupled high-$Q$ microresonators,\ncascaded pump-rejection filters, and low-loss inverse-tapered edge couplers.\nThe measurements agree with a first-principles theoretical model parameterized\nsolely by independently extracted device parameters and experimental settings.\nThe measured squeezing level can be further improved by enhancing the\nefficiencies of off-chip detection and chip-to-fiber coupling. These results\nestablish a reproducible, wafer-scale route to nonclassical-light generation in\nintegrated photonics and lay the groundwork for scalable CV processors,\nmultiplexed entanglement sources, and quantum-enhanced sensing.", "AI": {"tldr": "\u672c\u6587\u62a5\u9053\u4e86\u5728\u5149\u5b50\u96c6\u6210\u82af\u7247\uff08PIC\uff09\u4e0a\u5b9e\u73b0\u5927\u89c4\u6a21\u3001\u53ef\u91cd\u590d\u751f\u4ea7\u7684\u6324\u538b\u5149\u5b50\u6e90\u3002", "motivation": "\u53ef\u6269\u5c55\u7684\u8fde\u7eed\u53ef\u53d8\uff08CV\uff09\u91cf\u5b50\u4fe1\u606f\u5904\u7406\u9700\u8981PIC\u4e2d\u7684\u6324\u538b\u5149\u5b50\u4ea7\u751f\uff0c\u4ee5\u6291\u5236\u4f4e\u4e8e\u6563\u5f39\u566a\u58f0\u6781\u9650\u7684\u91cf\u5b50\u6da8\u843d\uff0c\u4ece\u800c\u5b9e\u73b0\u91cf\u5b50\u589e\u5f3a\u4f20\u611f\u548cCV\u91cf\u5b50\u4fe1\u606f\u5904\u7406\u3002", "method": "\u5229\u7528CMOS\u517c\u5bb9\u7684\u6c2e\u5316\u7845\uff08Si3N4\uff09PIC\u5e73\u53f0\uff0c\u901a\u8fc7\u5171\u96c6\u6210\u8d85\u4f4e\u635f\u8017\u3001\u5f3a\u8fc7\u8026\u5408\u9ad8Q\u503c\u5fae\u8c10\u632f\u5668\u3001\u7ea7\u8054\u6cf5\u6d66\u6291\u5236\u6ee4\u6ce2\u5668\u548c\u4f4e\u635f\u8017\u53cd\u5411\u9525\u5f62\u8fb9\u8026\u5408\u5668\uff0c\u5b9e\u73b0\u4e86\u53cc\u6a21\u6324\u538b\u771f\u7a7a\u6001\u7684\u6676\u5706\u7ea7\u5236\u9020\u3001\u4ea7\u751f\u548c\u8868\u5f81\u3002", "result": "\u57284\u82f1\u5bf8\u6676\u5706\u4e0a\uff0c8\u4e2a\u82af\u7247\u5b9e\u73b0\u4e862.9-3.1 dB\u7684\u76f4\u63a5\u6d4b\u91cf\u6b63\u4ea4\u538b\u7f29\uff0c\u53d8\u5316\u5c0f\u4e8e0.2 dB\uff0c\u663e\u793a\u51fa\u4f18\u5f02\u7684\u5747\u5300\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u975e\u7ecf\u5178\u5149\u5728\u96c6\u6210\u5149\u5b50\u5b66\u4e2d\u7684\u53ef\u91cd\u590d\u3001\u6676\u5706\u7ea7\u4ea7\u751f\u63d0\u4f9b\u4e86\u4e00\u6761\u9014\u5f84\uff0c\u5e76\u4e3a\u53ef\u6269\u5c55\u7684CV\u5904\u7406\u5668\u3001\u591a\u8def\u7ea0\u7f20\u6e90\u548c\u91cf\u5b50\u589e\u5f3a\u4f20\u611f\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2509.10040", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.10040", "abs": "https://arxiv.org/abs/2509.10040", "authors": ["Mohamed Basem", "Mohamed Younes", "Seif Ahmed", "Abdelrahman Moustafa"], "title": "!MSA at BAREC Shared Task 2025: Ensembling Arabic Transformers for Readability Assessment", "comment": "10 Pages , 8 figures , ArabicNLP 2025 , Co-located with EMNLP 2025", "summary": "We present MSAs winning system for the BAREC 2025 Shared Task on fine-grained\nArabic readability assessment, achieving first place in six of six tracks. Our\napproach is a confidence-weighted ensemble of four complementary transformer\nmodels (AraBERTv2, AraELECTRA, MARBERT, and CAMeLBERT) each fine-tuned with\ndistinct loss functions to capture diverse readability signals. To tackle\nsevere class imbalance and data scarcity, we applied weighted training,\nadvanced preprocessing, SAMER corpus relabeling with our strongest model, and\nsynthetic data generation via Gemini 2.5 Flash, adding about 10,000 rare-level\nsamples. A targeted post-processing step corrected prediction distribution\nskew, delivering a 6.3 percent Quadratic Weighted Kappa (QWK) gain. Our system\nreached 87.5 percent QWK at the sentence level and 87.4 percent at the document\nlevel, demonstrating the power of model and loss diversity, confidence-informed\nfusion, and intelligent augmentation for robust Arabic readability prediction.", "AI": {"tldr": "\u8be5\u7cfb\u7edf\u5728BAREC 2025\u963f\u62c9\u4f2f\u8bed\u53ef\u8bfb\u6027\u8bc4\u4f30\u4efb\u52a1\u4e2d\u83b7\u5f97\u7b2c\u4e00\u540d\uff0c\u4f7f\u7528\u4e86\u56db\u79cd\u4e92\u8865\u7684Transformer\u6a21\u578b\u7684\u96c6\u6210\uff0c\u5e76\u7ed3\u5408\u4e86\u6570\u636e\u589e\u5f3a\u548c\u540e\u5904\u7406\u6280\u672f\u3002", "motivation": "\u89e3\u51b3\u963f\u62c9\u4f2f\u8bed\u53ef\u8bfb\u6027\u8bc4\u4f30\u4e2d\u7684\u7c7b\u522b\u4e0d\u5e73\u8861\u548c\u6570\u636e\u7a00\u7f3a\u95ee\u9898\u3002", "method": "\u4f7f\u7528AraBERTv2, AraELECTRA, MARBERT, \u548cCAMeLBERT\u56db\u79cdTransformer\u6a21\u578b\u7684\u96c6\u6210\uff0c\u5e76\u7ed3\u5408\u52a0\u6743\u8bad\u7ec3\u3001\u6570\u636e\u9884\u5904\u7406\u3001SAMER\u8bed\u6599\u5e93\u91cd\u65b0\u6807\u6ce8\u3001\u5408\u6210\u6570\u636e\u751f\u6210\u4ee5\u53ca\u540e\u5904\u7406\u3002", "result": "\u5728\u53e5\u5b50\u548c\u6587\u6863\u7ea7\u522b\u5206\u522b\u8fbe\u5230\u4e8687.5%\u548c87.4%\u7684QWK\u5206\u6570\uff0c\u5728\u516d\u4e2a\u8d5b\u9053\u4e2d\u5747\u83b7\u5f97\u7b2c\u4e00\u540d\u3002", "conclusion": "\u6a21\u578b\u548c\u635f\u5931\u51fd\u6570\u7684\u591a\u6837\u6027\u3001\u7f6e\u4fe1\u5ea6\u878d\u5408\u4ee5\u53ca\u667a\u80fd\u6570\u636e\u589e\u5f3a\u662f\u63d0\u9ad8\u963f\u62c9\u4f2f\u8bed\u53ef\u8bfb\u6027\u9884\u6d4b\u9c81\u68d2\u6027\u7684\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2509.10189", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10189", "abs": "https://arxiv.org/abs/2509.10189", "authors": ["Zexu Jin"], "title": "Hadamard-Riemannian Optimization for Margin-Variance Ensemble", "comment": null, "summary": "Ensemble learning has been widely recognized as a pivotal technique for\nboosting predictive performance by combining multiple base models.\nNevertheless, conventional margin-based ensemble methods predominantly focus on\nmaximizing the expected margin while neglecting the critical role of margin\nvariance, which inherently restricts the generalization capability of the model\nand heightens its vulnerability to overfitting, particularly in noisy or\nimbalanced datasets. Additionally, the conventional approach of optimizing\nensemble weights within the probability simplex often introduces computational\ninefficiency and scalability challenges, complicating its application to\nlarge-scale problems. To tackle these limitations, this paper introduces a\nnovel ensemble learning framework that explicitly incorporates margin variance\ninto the loss function. Our method jointly optimizes the negative expected\nmargin and its variance, leading to enhanced robustness and improved\ngeneralization performance. Moreover, by reparameterizing the ensemble weights\nonto the unit sphere, we substantially simplify the optimization process and\nimprove computational efficiency. Extensive experiments conducted on multiple\nbenchmark datasets demonstrate that the proposed approach consistently\noutperforms traditional margin-based ensemble techniques, underscoring its\neffectiveness and practical utility.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u96c6\u6210\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u9884\u671f\u5229\u6da6\u548c\u5229\u6da6\u65b9\u5dee\u6765\u63d0\u9ad8\u6a21\u578b\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u7b80\u5316\u4e86\u4f18\u5316\u8fc7\u7a0b\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u7684\u57fa\u4e8e\u5229\u6da6\u7684\u96c6\u6210\u5b66\u4e60\u65b9\u6cd5\u53ea\u5173\u6ce8\u6700\u5927\u5316\u9884\u671f\u5229\u6da6\uff0c\u5ffd\u7565\u4e86\u5229\u6da6\u65b9\u5dee\uff0c\u8fd9\u9650\u5236\u4e86\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u4f7f\u5176\u5728\u566a\u58f0\u6216\u4e0d\u5e73\u8861\u6570\u636e\u96c6\u4e0a\u5bb9\u6613\u8fc7\u62df\u5408\u3002\u6b64\u5916\uff0c\u5728\u6982\u7387\u5355\u7eaf\u5f62\u5185\u4f18\u5316\u96c6\u6210\u6743\u91cd\u4f1a\u5e26\u6765\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b\u548c\u53ef\u6269\u5c55\u6027\u95ee\u9898\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u96c6\u6210\u5b66\u4e60\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5c06\u5229\u6da6\u65b9\u5dee\u663e\u5f0f\u5730\u7eb3\u5165\u635f\u5931\u51fd\u6570\u3002\u901a\u8fc7\u8054\u5408\u4f18\u5316\u8d1f\u9884\u671f\u5229\u6da6\u53ca\u5176\u65b9\u5dee\uff0c\u5e76\u5229\u7528\u5355\u4f4d\u7403\u9762\u4e0a\u7684\u91cd\u65b0\u53c2\u6570\u5316\u6765\u7b80\u5316\u4f18\u5316\u8fc7\u7a0b\uff0c\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\u3002", "result": "\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u59cb\u7ec8\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u96c6\u6210\u5b66\u4e60\u6846\u67b6\u901a\u8fc7\u8054\u5408\u4f18\u5316\u5229\u6da6\u548c\u5229\u6da6\u65b9\u5dee\uff0c\u5e76\u91c7\u7528\u7b80\u5316\u7684\u4f18\u5316\u8fc7\u7a0b\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2509.10080", "categories": ["cs.CV", "I.2.9; I.4.8"], "pdf": "https://arxiv.org/pdf/2509.10080", "abs": "https://arxiv.org/abs/2509.10080", "authors": ["Minsang Kong", "Myeongjun Kim", "Sang Gu Kang", "Sang Hun Lee"], "title": "BEVTraj: Map-Free End-to-End Trajectory Prediction in Bird's-Eye View with Deformable Attention and Sparse Goal Proposals", "comment": "Submitted to IEEE Transactions on Intelligent Transportation Systems\n  (under review)", "summary": "In autonomous driving, trajectory prediction is essential for ensuring safe\nand efficient navigation. To improve prediction accuracy, recent approaches\noften rely on pre-built high-definition (HD) maps or real-time local map\nconstruction modules to incorporate static environmental information. However,\npre-built HD maps are limited to specific regions and cannot adapt to transient\nchanges. In addition, local map construction modules, which recognize only\npredefined elements, may fail to capture critical scene details or introduce\nerrors that degrade prediction performance. To overcome these limitations, we\npropose Bird's-Eye View Trajectory Prediction (BEVTraj), a novel trajectory\nprediction framework that operates directly in the bird's-eye view (BEV) space\nutilizing real-time sensor data without relying on any pre-built maps. The\nBEVTraj leverages deformable attention to efficiently extract relevant context\nfrom dense BEV features. Furthermore, we introduce a Sparse Goal Candidate\nProposal (SGCP) module, which enables full end-to-end prediction without\nrequiring any post-processing steps. Extensive experiments demonstrate that the\nBEVTraj achieves performance comparable to state-of-the-art HD map-based models\nwhile offering greater flexibility by eliminating the dependency on pre-built\nmaps. The source code is available at https://github.com/Kongminsang/bevtraj.", "AI": {"tldr": "BEVTraj\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u9e1f\u77b0\u56fe\u8f68\u8ff9\u9884\u6d4b\u6846\u67b6\uff0c\u5b83\u5229\u7528\u5b9e\u65f6\u4f20\u611f\u5668\u6570\u636e\u76f4\u63a5\u5728\u9e1f\u77b0\u56fe\u7a7a\u95f4\u4e2d\u64cd\u4f5c\uff0c\u65e0\u9700\u9884\u5efa\u5730\u56fe\uff0c\u5e76\u53d6\u5f97\u4e86\u4e0e\u6700\u5148\u8fdb\u7684\u57fa\u4e8e\u9ad8\u6e05\u5730\u56fe\u7684\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u81ea\u52a8\u9a7e\u9a76\u8f68\u8ff9\u9884\u6d4b\u65b9\u6cd5\u4f9d\u8d56\u9ad8\u7cbe\u5ea6\u5730\u56fe\u6216\u5c40\u90e8\u5730\u56fe\u6784\u5efa\u6a21\u5757\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u5b58\u5728\u533a\u57df\u9650\u5236\u3001\u65e0\u6cd5\u9002\u5e94\u77ac\u6001\u53d8\u5316\u3001\u53ef\u80fd\u9057\u6f0f\u5173\u952e\u573a\u666f\u7ec6\u8282\u6216\u5f15\u5165\u9519\u8bef\u7b49\u7f3a\u70b9\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aBEVTraj\u7684\u65b0\u578b\u9e1f\u77b0\u56fe\u8f68\u8ff9\u9884\u6d4b\u6846\u67b6\u3002\u8be5\u6846\u67b6\u76f4\u63a5\u5728\u9e1f\u77b0\u56fe\u7a7a\u95f4\u4e2d\u64cd\u4f5c\uff0c\u5229\u7528\u5b9e\u65f6\u4f20\u611f\u5668\u6570\u636e\uff0c\u65e0\u9700\u9884\u5efa\u5730\u56fe\u3002BEVTraj\u91c7\u7528\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\u673a\u5236\u6765\u6709\u6548\u63d0\u53d6\u5bc6\u96c6\u7684\u9e1f\u77b0\u56fe\u7279\u5f81\u4e2d\u7684\u76f8\u5173\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u4e00\u4e2a\u7a00\u758f\u76ee\u6807\u5019\u9009\u70b9\u751f\u6210\uff08SGCP\uff09\u6a21\u5757\uff0c\u5b9e\u73b0\u4e86\u65e0\u9700\u4efb\u4f55\u540e\u5904\u7406\u6b65\u9aa4\u7684\u5168\u7aef\u5230\u7aef\u9884\u6d4b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cBEVTraj\u5728\u6027\u80fd\u4e0a\u53ef\u4e0e\u6700\u5148\u8fdb\u7684\u57fa\u4e8e\u9ad8\u6e05\u5730\u56fe\u7684\u6a21\u578b\u76f8\u5ab2\u7f8e\uff0c\u540c\u65f6\u901a\u8fc7\u6d88\u9664\u5bf9\u9884\u5efa\u5730\u56fe\u7684\u4f9d\u8d56\u800c\u63d0\u4f9b\u4e86\u66f4\u5927\u7684\u7075\u6d3b\u6027\u3002", "conclusion": "BEVTraj\u901a\u8fc7\u5728\u9e1f\u77b0\u56fe\u7a7a\u95f4\u4e2d\u76f4\u63a5\u64cd\u4f5c\u5e76\u5229\u7528\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\u548cSGCP\u6a21\u5757\uff0c\u514b\u670d\u4e86\u73b0\u6709\u8f68\u8ff9\u9884\u6d4b\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6027\u80fd\u548c\u9ad8\u7075\u6d3b\u6027\u3002"}}
{"id": "2509.10078", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10078", "abs": "https://arxiv.org/abs/2509.10078", "authors": ["Dongmin Choi", "Woojung Song", "Jongwook Han", "Eun-Ju Lee", "Yohan Jo"], "title": "Established Psychometric vs. Ecologically Valid Questionnaires: Rethinking Psychological Assessments in Large Language Models", "comment": "17 pages, 4 figures", "summary": "Researchers have applied established psychometric questionnaires (e.g., BFI,\nPVQ) to measure the personality traits and values reflected in the responses of\nLarge Language Models (LLMs). However, concerns have been raised about applying\nthese human-designed questionnaires to LLMs. One such concern is their lack of\necological validity--the extent to which survey questions adequately reflect\nand resemble real-world contexts in which LLMs generate texts in response to\nuser queries. However, it remains unclear how established questionnaires and\necologically valid questionnaires differ in their outcomes, and what insights\nthese differences may provide. In this paper, we conduct a comprehensive\ncomparative analysis of the two types of questionnaires. Our analysis reveals\nthat established questionnaires (1) yield substantially different profiles of\nLLMs from ecologically valid ones, deviating from the psychological\ncharacteristics expressed in the context of user queries, (2) suffer from\ninsufficient items for stable measurement, (3) create misleading impressions\nthat LLMs possess stable constructs, and (4) yield exaggerated profiles for\npersona-prompted LLMs. Overall, our work cautions against the use of\nestablished psychological questionnaires for LLMs. Our code will be released\nupon publication.", "AI": {"tldr": "Established questionnaires yield different and misleading results when applied to LLMs compared to ecologically valid ones.", "motivation": "The paper aims to investigate the concerns surrounding the application of human-designed psychometric questionnaires to Large Language Models (LLMs), specifically addressing the lack of ecological validity and the resulting differences in outcomes compared to more contextually relevant questionnaires.", "method": "The study conducted a comprehensive comparative analysis between established psychometric questionnaires (e.g., BFI, PVQ) and ecologically valid questionnaires when applied to LLMs.", "result": "Established questionnaires produce substantially different LLM profiles compared to ecologically valid ones, misrepresenting psychological characteristics in user query contexts. They also suffer from insufficient items for stable measurement, create misleading impressions of stable LLM constructs, and exaggerate profiles for persona-prompted LLMs.", "conclusion": "The findings caution against the use of established psychological questionnaires for LLMs due to their lack of ecological validity and the resulting inaccurate and misleading insights they provide."}}
{"id": "2509.10093", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.10093", "abs": "https://arxiv.org/abs/2509.10093", "authors": ["Laura Bragagnolo", "Matteo Terreran", "Leonardo Barcellona", "Stefano Ghidoni"], "title": "Leveraging Multi-View Weak Supervision for Occlusion-Aware Multi-Human Parsing", "comment": "ICIAP 2025", "summary": "Multi-human parsing is the task of segmenting human body parts while\nassociating each part to the person it belongs to, combining instance-level and\npart-level information for fine-grained human understanding. In this work, we\ndemonstrate that, while state-of-the-art approaches achieved notable results on\npublic datasets, they struggle considerably in segmenting people with\noverlapping bodies. From the intuition that overlapping people may appear\nseparated from a different point of view, we propose a novel training framework\nexploiting multi-view information to improve multi-human parsing models under\nocclusions. Our method integrates such knowledge during the training process,\nintroducing a novel approach based on weak supervision on human instances and a\nmulti-view consistency loss. Given the lack of suitable datasets in the\nliterature, we propose a semi-automatic annotation strategy to generate human\ninstance segmentation masks from multi-view RGB+D data and 3D human skeletons.\nThe experiments demonstrate that the approach can achieve up to a 4.20\\%\nrelative improvement on human parsing over the baseline model in occlusion\nscenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u591a\u89c6\u89d2\u4fe1\u606f\u6765\u6539\u8fdb\u906e\u6321\u573a\u666f\u4e0b\u591a\u4eba\u7269\u5206\u5272\u6a21\u578b\u7684\u65b0\u9896\u8bad\u7ec3\u6846\u67b6\u3002", "motivation": "\u73b0\u6709\u5148\u8fdb\u7684\u591a\u4eba\u7269\u5206\u5272\u65b9\u6cd5\u5728\u5904\u7406\u8eab\u4f53\u91cd\u53e0\u7684\u4eba\u65f6\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4eba\u4f53\u5b9e\u4f8b\u5f31\u76d1\u7763\u548c\u591a\u89c6\u89d2\u4e00\u81f4\u6027\u635f\u5931\u7684\u65b0\u65b9\u6cd5\uff0c\u5e76\u7ed3\u5408\u534a\u81ea\u52a8\u6807\u6ce8\u7b56\u7565\u6765\u751f\u6210\u8bad\u7ec3\u6570\u636e\u3002", "result": "\u5728\u906e\u6321\u573a\u666f\u4e0b\uff0c\u76f8\u6bd4\u57fa\u7ebf\u6a21\u578b\uff0c\u8be5\u65b9\u6cd5\u5728\u4eba\u7269\u5206\u5272\u65b9\u9762\u53d6\u5f97\u4e86\u9ad8\u8fbe 4.20% \u7684\u76f8\u5bf9\u6539\u8fdb\u3002", "conclusion": "\u5229\u7528\u591a\u89c6\u89d2\u4fe1\u606f\u548c\u65b0\u9896\u7684\u8bad\u7ec3\u6846\u67b6\u80fd\u591f\u6709\u6548\u63d0\u5347\u906e\u6321\u573a\u666f\u4e0b\u591a\u4eba\u7269\u5206\u5272\u7684\u6027\u80fd\u3002"}}
{"id": "2509.10087", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.10087", "abs": "https://arxiv.org/abs/2509.10087", "authors": ["Mustapha Adamu", "Qi Zhang", "Huitong Pan", "Longin Jan Latecki", "Eduard C. Dragut"], "title": "Querying Climate Knowledge: Semantic Retrieval for Scientific Discovery", "comment": "ACM SIGIR 2025 Workshop MANILA", "summary": "The growing complexity and volume of climate science literature make it\nincreasingly difficult for researchers to find relevant information across\nmodels, datasets, regions, and variables. This paper introduces a\ndomain-specific Knowledge Graph (KG) built from climate publications and\nbroader scientific texts, aimed at improving how climate knowledge is accessed\nand used. Unlike keyword based search, our KG supports structured, semantic\nqueries that help researchers discover precise connections such as which models\nhave been validated in specific regions or which datasets are commonly used\nwith certain teleconnection patterns. We demonstrate how the KG answers such\nquestions using Cypher queries, and outline its integration with large language\nmodels in RAG systems to improve transparency and reliability in\nclimate-related question answering. This work moves beyond KG construction to\nshow its real world value for climate researchers, model developers, and others\nwho rely on accurate, contextual scientific information.", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u4e86\u4e00\u4e2a\u6c14\u5019\u79d1\u5b66\u9886\u57df\u7684\u77e5\u8bc6\u56fe\u8c31\uff0c\u4ee5\u5e94\u5bf9\u65e5\u76ca\u589e\u957f\u7684\u6c14\u5019\u6587\u732e\u68c0\u7d22\u6311\u6218\u3002\u8be5\u77e5\u8bc6\u56fe\u8c31\u652f\u6301\u7ed3\u6784\u5316\u8bed\u4e49\u67e5\u8be2\uff0c\u80fd\u591f\u56de\u7b54\u5177\u4f53\u95ee\u9898\uff0c\u5982\u201c\u54ea\u4e9b\u6a21\u578b\u5728\u7279\u5b9a\u533a\u57df\u7ecf\u8fc7\u9a8c\u8bc1\u201d\u6216\u201c\u54ea\u4e9b\u6570\u636e\u96c6\u5e38\u4e0e\u7279\u5b9a\u7684\u9065\u76f8\u5173\u6a21\u5f0f\u4e00\u8d77\u4f7f\u7528\u201d\u3002\u6b64\u5916\uff0c\u5b83\u8fd8\u53ef\u4ee5\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u96c6\u6210\uff0c\u5e94\u7528\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7cfb\u7edf\uff0c\u4ee5\u63d0\u9ad8\u6c14\u5019\u76f8\u5173\u95ee\u7b54\u7684\u900f\u660e\u5ea6\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u6c14\u5019\u79d1\u5b66\u6587\u732e\u65e5\u76ca\u590d\u6742\u548c\u5e9e\u5927\uff0c\u7814\u7a76\u4eba\u5458\u96be\u4ee5\u5728\u6a21\u578b\u3001\u6570\u636e\u96c6\u3001\u5730\u533a\u548c\u53d8\u91cf\u4e4b\u95f4\u67e5\u627e\u76f8\u5173\u4fe1\u606f\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u6c14\u5019\u51fa\u7248\u7269\u548c\u66f4\u5e7f\u6cdb\u79d1\u5b66\u6587\u672c\u7684\u9886\u57df\u7279\u5b9a\u77e5\u8bc6\u56fe\u8c31\uff08KG\uff09\uff0c\u5e76\u6f14\u793a\u4e86\u5982\u4f55\u4f7f\u7528 Cypher \u67e5\u8be2\u6765\u56de\u7b54\u5177\u4f53\u95ee\u9898\uff0c\u4ee5\u53ca\u5982\u4f55\u5c06\u5176\u4e0e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7cfb\u7edf\u96c6\u6210\u3002", "result": "\u8be5\u77e5\u8bc6\u56fe\u8c31\u80fd\u591f\u652f\u6301\u7ed3\u6784\u5316\u3001\u8bed\u4e49\u5316\u7684\u67e5\u8be2\uff0c\u5e2e\u52a9\u7814\u7a76\u4eba\u5458\u53d1\u73b0\u7cbe\u786e\u7684\u5173\u8054\uff0c\u4f8b\u5982\u54ea\u4e9b\u6a21\u578b\u5728\u7279\u5b9a\u533a\u57df\u5f97\u5230\u4e86\u9a8c\u8bc1\uff0c\u6216\u8005\u54ea\u4e9b\u6570\u636e\u96c6\u901a\u5e38\u4e0e\u67d0\u4e9b\u9065\u76f8\u5173\u6a21\u5f0f\u4e00\u8d77\u4f7f\u7528\u3002\u5176\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728 RAG \u7cfb\u7edf\u4e2d\u7684\u96c6\u6210\uff0c\u80fd\u591f\u63d0\u9ad8\u6c14\u5019\u76f8\u5173\u95ee\u7b54\u7684\u900f\u660e\u5ea6\u548c\u53ef\u9760\u6027\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u8d85\u8d8a\u4e86\u77e5\u8bc6\u56fe\u8c31\u7684\u6784\u5efa\u672c\u8eab\uff0c\u5c55\u793a\u4e86\u5176\u5728\u4e3a\u6c14\u5019\u7814\u7a76\u4eba\u5458\u3001\u6a21\u578b\u5f00\u53d1\u8005\u7b49\u4f9d\u8d56\u51c6\u786e\u3001\u4e0a\u4e0b\u6587\u76f8\u5173\u79d1\u5b66\u4fe1\u606f\u7684\u7528\u6237\u65b9\u9762\u5177\u6709\u7684\u5b9e\u9645\u4ef7\u503c\u3002"}}
{"id": "2509.10248", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10248", "abs": "https://arxiv.org/abs/2509.10248", "authors": ["Janis Keuper"], "title": "Prompt Injection Attacks on LLM Generated Reviews of Scientific Publications", "comment": null, "summary": "The ongoing intense discussion on rising LLM usage in the scientific\npeer-review process has recently been mingled by reports of authors using\nhidden prompt injections to manipulate review scores. Since the existence of\nsuch \"attacks\" - although seen by some commentators as \"self-defense\" - would\nhave a great impact on the further debate, this paper investigates the\npracticability and technical success of the described manipulations. Our\nsystematic evaluation uses 1k reviews of 2024 ICLR papers generated by a wide\nrange of LLMs shows two distinct results: I) very simple prompt injections are\nindeed highly effective, reaching up to 100% acceptance scores. II) LLM reviews\nare generally biased toward acceptance (>95% in many models). Both results have\ngreat impact on the ongoing discussions on LLM usage in peer-review.", "AI": {"tldr": "\u63d0\u793a\u6ce8\u5165\u53ef\u64cd\u7eb5LLM\u540c\u884c\u8bc4\u5ba1\uff0c\u4e14LLM\u8bc4\u5ba1\u503e\u5411\u4e8e\u63a5\u53d7\u3002 ", "motivation": "\u7814\u7a76LLM\u5728\u79d1\u5b66\u540c\u884c\u8bc4\u5ba1\u4e2d\u7684\u5e94\u7528\uff0c\u7279\u522b\u662f\u4f5c\u8005\u4f7f\u7528\u9690\u85cf\u7684\u63d0\u793a\u6ce8\u5165\u6765\u64cd\u7eb5\u8bc4\u5ba1\u5206\u6570\u7684\u53ef\u80fd\u6027\u3002", "method": "\u5bf92024\u5e74ICLR\u76841000\u7bc7\u8bba\u6587\u8bc4\u5ba1\u8fdb\u884c\u7cfb\u7edf\u6027\u8bc4\u4f30\uff0c\u4f7f\u7528\u591a\u79cdLLM\u3002", "result": "I) \u7b80\u5355\u7684\u63d0\u793a\u6ce8\u5165\u975e\u5e38\u6709\u6548\uff0c\u63a5\u53d7\u7387\u9ad8\u8fbe100%\u3002 II) LLM\u8bc4\u5ba1\u666e\u904d\u5b58\u5728\u504f\u89c1\uff0c\u503e\u5411\u4e8e\u63a5\u53d7\uff08\u8d85\u8fc795%\uff09\u3002", "conclusion": "\u63d0\u793a\u6ce8\u5165\u5bf9LLM\u540c\u884c\u8bc4\u5ba1\u5177\u6709\u5b9e\u9645\u53ef\u884c\u6027\uff0c\u4e14LLM\u8bc4\u5ba1\u666e\u904d\u5b58\u5728\u63a5\u53d7\u504f\u89c1\uff0c\u8fd9\u5bf9\u5f53\u524d\u5173\u4e8eLLM\u5728\u540c\u884c\u8bc4\u5ba1\u4e2d\u5e94\u7528\u7684\u8ba8\u8bba\u5177\u6709\u91cd\u8981\u5f71\u54cd\u3002"}}
{"id": "2509.10105", "categories": ["cs.CV", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.10105", "abs": "https://arxiv.org/abs/2509.10105", "authors": ["Young-rok Cha", "Jeongho Ju", "SunYoung Park", "Jong-Hyeon Lee", "Younghyun Yu", "Youngjune Kim"], "title": "VARCO-VISION-2.0 Technical Report", "comment": "19 pages, 1 figure, 14 tables. Technical report for VARCO-VISION-2.0,\n  a Korean-English bilingual VLM in 14B and 1.7B variants. Key features:\n  multi-image understanding, OCR with text localization, improved Korean\n  capabilities", "summary": "We introduce VARCO-VISION-2.0, an open-weight bilingual vision-language model\n(VLM) for Korean and English with improved capabilities compared to the\nprevious model VARCO-VISION-14B. The model supports multi-image understanding\nfor complex inputs such as documents, charts, and tables, and delivers\nlayoutaware OCR by predicting both textual content and its spatial location.\nTrained with a four-stage curriculum with memory-efficient techniques, the\nmodel achieves enhanced multimodal alignment, while preserving core language\nabilities and improving safety via preference optimization. Extensive benchmark\nevaluations demonstrate strong spatial grounding and competitive results for\nboth languages, with the 14B model achieving 8th place on the OpenCompass VLM\nleaderboard among models of comparable scale. Alongside the 14B-scale model, we\nrelease a 1.7B version optimized for on-device deployment. We believe these\nmodels advance the development of bilingual VLMs and their practical\napplications. Two variants of VARCO-VISION-2.0 are available at Hugging Face: a\nfull-scale 14B model and a lightweight 1.7B model.", "AI": {"tldr": "VARCO-VISION-2.0\u662f\u4e00\u4e2a\u5f00\u6e90\u7684\u53cc\u8bed\uff08\u97e9\u8bed/\u82f1\u8bed\uff09\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u652f\u6301\u591a\u56fe\u7406\u89e3\u548c\u5e03\u5c40\u611f\u77e5OCR\uff0c\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u63d0\u5347\u53cc\u8bed\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u80fd\u529b\uff0c\u652f\u6301\u591a\u56fe\u7406\u89e3\u548c\u5e03\u5c40\u611f\u77e5OCR\uff0c\u5e76\u4f18\u5316\u6a21\u578b\u6027\u80fd\u548c\u5b89\u5168\u6027\u3002", "method": "\u91c7\u7528\u56db\u9636\u6bb5\u8bfe\u7a0b\u5b66\u4e60\u548c\u5185\u5b58\u4f18\u5316\u6280\u672f\u8fdb\u884c\u8bad\u7ec3\uff0c\u5b9e\u73b0\u591a\u6a21\u6001\u5bf9\u9f50\uff0c\u540c\u65f6\u4fdd\u6301\u8bed\u8a00\u80fd\u529b\u5e76\u63d0\u9ad8\u5b89\u5168\u6027\u3002", "result": "VARCO-VISION-2.0\u5728\u97e9\u8bed\u548c\u82f1\u8bed\u7684\u57fa\u51c6\u8bc4\u4f30\u4e2d\u5747\u53d6\u5f97\u4f18\u5f02\u7684\u7a7a\u95f4\u5b9a\u4f4d\u80fd\u529b\u548c\u7ade\u4e89\u529b\u7ed3\u679c\uff0c\u5176\u4e2d14B\u6a21\u578b\u5728OpenCompass VLM\u6392\u884c\u699c\u4e0a\u6392\u540d\u7b2c8\uff0c\u540c\u65f6\u53d1\u5e03\u4e861.7B\u7684\u8f7b\u91cf\u5316\u7248\u672c\u3002", "conclusion": "VARCO-VISION-2.0\u7684\u53d1\u5e03\u63a8\u52a8\u4e86\u53cc\u8bed\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\u53ca\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2509.10095", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.10095", "abs": "https://arxiv.org/abs/2509.10095", "authors": ["Abdulrahman Allam", "Seif Ahmed", "Ali Hamdi", "Ammar Mohammed"], "title": "Arabic Large Language Models for Medical Text Generation", "comment": "Published in 2025 4th International Conference on Computer\n  Technologies (ICCTech)", "summary": "Efficient hospital management systems (HMS) are critical worldwide to address\nchallenges such as overcrowding, limited resources, and poor availability of\nurgent health care. Existing methods often lack the ability to provide\naccurate, real-time medical advice, particularly for irregular inputs and\nunderrepresented languages. To overcome these limitations, this study proposes\nan approach that fine-tunes large language models (LLMs) for Arabic medical\ntext generation. The system is designed to assist patients by providing\naccurate medical advice, diagnoses, drug recommendations, and treatment plans\nbased on user input. The research methodology required the collection of a\nunique dataset from social media platforms, capturing real-world medical\nconversations between patients and doctors. The dataset, which includes patient\ncomplaints together with medical advice, was properly cleaned and preprocessed\nto account for multiple Arabic dialects. Fine-tuning state-of-the-art\ngenerative models, such as Mistral-7B-Instruct-v0.2, LLaMA-2-7B, and GPT-2\nMedium, optimized the system's ability to generate reliable medical text.\nResults from evaluations indicate that the fine-tuned Mistral-7B model\noutperformed the other models, achieving average BERT (Bidirectional Encoder\nRepresentations from Transformers) Score values in precision, recall, and\nF1-scores of 68.5\\%, 69.08\\%, and 68.5\\%, respectively. Comparative\nbenchmarking and qualitative assessments validate the system's ability to\nproduce coherent and relevant medical replies to informal input. This study\nhighlights the potential of generative artificial intelligence (AI) in\nadvancing HMS, offering a scalable and adaptable solution for global healthcare\nchallenges, especially in linguistically and culturally diverse environments.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e00\u79cd\u5fae\u8c03\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u963f\u62c9\u4f2f\u8bed\u533b\u7597\u6587\u672c\u751f\u6210\uff0c\u4ee5\u6539\u5584\u533b\u9662\u7ba1\u7406\u7cfb\u7edf\uff08HMS\uff09\uff0c\u89e3\u51b3\u533b\u7597\u8d44\u6e90\u6709\u9650\u548c\u8bed\u8a00\u591a\u6837\u6027\u7b49\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u7684\u533b\u9662\u7ba1\u7406\u7cfb\u7edf\u5728\u63d0\u4f9b\u51c6\u786e\u3001\u5b9e\u65f6\u7684\u533b\u7597\u5efa\u8bae\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u975e\u7ed3\u6784\u5316\u8f93\u5165\u548c\u4ee3\u8868\u6027\u4e0d\u8db3\u7684\u8bed\u8a00\u65f6\u3002\u6b64\u5916\uff0c\u5168\u7403\u533b\u7597\u7cfb\u7edf\u9762\u4e34\u7740\u8fc7\u5ea6\u62e5\u6324\u3001\u8d44\u6e90\u6709\u9650\u548c\u7d27\u6025\u533b\u7597\u670d\u52a1\u53ef\u7528\u6027\u5dee\u7b49\u6311\u6218\u3002", "method": "\u6536\u96c6\u4e86\u6765\u81ea\u793e\u4ea4\u5a92\u4f53\u5e73\u53f0\u7684\u963f\u62c9\u4f2f\u8bed\u533b\u7597\u5bf9\u8bdd\u6570\u636e\u96c6\uff0c\u5305\u62ec\u60a3\u8005\u7684\u62b1\u6028\u548c\u533b\u751f\u7684\u5efa\u8bae\uff0c\u5e76\u8fdb\u884c\u4e86\u6570\u636e\u6e05\u6d17\u548c\u9884\u5904\u7406\u4ee5\u9002\u5e94\u4e0d\u540c\u7684\u963f\u62c9\u4f2f\u8bed\u65b9\u8a00\u3002\u7136\u540e\uff0c\u5bf9 Mistral-7B-Instruct-v0.2\u3001LLaMA-2-7B \u548c GPT-2 Medium \u7b49\u5148\u8fdb\u7684\u751f\u6210\u6a21\u578b\u8fdb\u884c\u4e86\u5fae\u8c03\u3002", "result": "\u5fae\u8c03\u540e\u7684 Mistral-7B \u6a21\u578b\u5728\u51c6\u786e\u7387\u3001\u53ec\u56de\u7387\u548c F1 \u5206\u6570\u65b9\u9762\u53d6\u5f97\u4e86 68.5%\u300169.08% \u548c 68.5% \u7684\u5e73\u5747 BERT \u5206\u6570\uff0c\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\u3002\u8be5\u7cfb\u7edf\u80fd\u591f\u5bf9\u975e\u6b63\u5f0f\u8f93\u5165\u751f\u6210\u8fde\u8d2f\u4e14\u76f8\u5173\u7684\u533b\u7597\u56de\u590d\u3002", "conclusion": "\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\uff08AI\uff09\u6709\u6f5c\u529b\u6539\u8fdb\u533b\u9662\u7ba1\u7406\u7cfb\u7edf\uff0c\u4e3a\u5168\u7403\u533b\u7597\u4fdd\u5065\u6311\u6218\u63d0\u4f9b\u53ef\u6269\u5c55\u4e14\u9002\u5e94\u6027\u5f3a\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5c24\u5176\u662f\u5728\u8bed\u8a00\u548c\u6587\u5316\u591a\u6837\u6027\u65b9\u9762\u3002"}}
{"id": "2509.10273", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10273", "abs": "https://arxiv.org/abs/2509.10273", "authors": ["Sahil Sethi", "Kai Sundmacher", "Caroline Ganzer"], "title": "Property prediction for ionic liquids without prior structural knowledge using limited experimental data: A data-driven neural recommender system leveraging transfer learning", "comment": null, "summary": "Ionic liquids (ILs) have emerged as versatile replacements for traditional\nsolvents because their physicochemical properties can be precisely tailored to\nvarious applications. However, accurately predicting key thermophysical\nproperties remains challenging due to the vast chemical design space and the\nlimited availability of experimental data. In this study, we present a\ndata-driven transfer learning framework that leverages a neural recommender\nsystem (NRS) to enable reliable property prediction for ILs using sparse\nexperimental datasets. The approach involves a two-stage process: first,\npre-training NRS models on COSMO-RS-based simulated data at fixed temperature\nand pressure to learn property-specific structural embeddings for cations and\nanions; and second, fine-tuning simple feedforward neural networks using these\nembeddings with experimental data at varying temperatures and pressures. In\nthis work, five essential IL properties are considered: density, viscosity,\nsurface tension, heat capacity, and melting point. The framework supports both\nwithin-property and cross-property knowledge transfer. Notably, pre-trained\nmodels for density, viscosity, and heat capacity are used to fine-tune models\nfor all five target properties, achieving improved performance by a substantial\nmargin for four of them. The model exhibits robust extrapolation to previously\nunseen ILs. Moreover, the final trained models enable property prediction for\nover 700,000 IL combinations, offering a scalable solution for IL screening in\nprocess design. This work highlights the effectiveness of combining simulated\ndata and transfer learning to overcome sparsity in the experimental data.", "AI": {"tldr": "\u901a\u8fc7\u7ed3\u5408\u6a21\u62df\u6570\u636e\u548c\u8fc1\u79fb\u5b66\u4e60\uff0c\u5229\u7528\u795e\u7ecf\u63a8\u8350\u7cfb\u7edf\uff08NRS\uff09\u6846\u67b6\uff0c\u5229\u7528\u7a00\u758f\u7684\u5b9e\u9a8c\u6570\u636e\u96c6\uff0c\u5bf9\u79bb\u5b50\u6db2\u4f53\u7684\u5173\u952e\u70ed\u7269\u7406\u6027\u8d28\u8fdb\u884c\u53ef\u9760\u9884\u6d4b\uff0c\u5e76\u652f\u6301\u8de8\u5c5e\u6027\u77e5\u8bc6\u8fc1\u79fb\u3002", "motivation": "\u51c6\u786e\u9884\u6d4b\u79bb\u5b50\u6db2\u4f53\u7684\u5173\u952e\u70ed\u7269\u7406\u6027\u8d28\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u5176\u5316\u5b66\u8bbe\u8ba1\u7a7a\u95f4\u5e7f\u9614\u4e14\u5b9e\u9a8c\u6570\u636e\u6709\u9650\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u6570\u636e\u9a71\u52a8\u7684\u8fc1\u79fb\u5b66\u4e60\u6846\u67b6\uff0c\u5229\u7528\u795e\u7ecf\u63a8\u8350\u7cfb\u7edf\uff08NRS\uff09\u3002\u8be5\u6846\u67b6\u5305\u62ec\u4e24\u4e2a\u9636\u6bb5\uff1a1. \u5728COSMO-RS\u6a21\u62df\u6570\u636e\u4e0a\u9884\u8bad\u7ec3NRS\u6a21\u578b\uff0c\u5b66\u4e60\u79bb\u5b50\u7ed3\u6784\u7684\u7279\u5b9a\u5d4c\u5165\uff1b2. \u4f7f\u7528\u8fd9\u4e9b\u5d4c\u5165\u548c\u5b9e\u9a8c\u6570\u636e\u5fae\u8c03\u524d\u9988\u795e\u7ecf\u7f51\u7edc\uff0c\u4ee5\u9884\u6d4b\u4e0d\u540c\u6e29\u5ea6\u548c\u538b\u529b\u4e0b\u7684\u6027\u8d28\u3002\u8be5\u6846\u67b6\u652f\u6301\u540c\u4e00\u5c5e\u6027\u5185\u548c\u8de8\u5c5e\u6027\u7684\u77e5\u8bc6\u8fc1\u79fb\u3002", "result": "\u8be5\u6846\u67b6\u5728\u5bc6\u5ea6\u3001\u7c98\u5ea6\u3001\u8868\u9762\u5f20\u529b\u3001\u70ed\u5bb9\u91cf\u548c\u7194\u70b9\u8fd9\u4e94\u79cd\u5173\u952e\u6027\u8d28\u4e0a\u8868\u73b0\u826f\u597d\u3002\u901a\u8fc7\u4f7f\u7528\u5bc6\u5ea6\u3001\u7c98\u5ea6\u3001\u70ed\u5bb9\u91cf\u7684\u9884\u8bad\u7ec3\u6a21\u578b\u6765\u5fae\u8c03\u6240\u6709\u4e94\u4e2a\u76ee\u6807\u6027\u8d28\u7684\u6a21\u578b\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5176\u4e2d\u56db\u79cd\u6027\u8d28\u7684\u9884\u6d4b\u6027\u80fd\u3002\u8be5\u6a21\u578b\u8fd8\u80fd\u7a33\u5065\u5730\u5916\u63a8\u5230\u672a\u77e5\u7684\u79bb\u5b50\u6db2\u4f53\u3002\u6700\u7ec8\u6a21\u578b\u80fd\u591f\u9884\u6d4b\u8d85\u8fc770\u4e07\u79cd\u79bb\u5b50\u6db2\u4f53\u7684\u6027\u8d28\uff0c\u4e3a\u5de5\u827a\u8bbe\u8ba1\u4e2d\u7684\u79bb\u5b50\u6db2\u4f53\u7b5b\u9009\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u7ed3\u5408\u6a21\u62df\u6570\u636e\u548c\u8fc1\u79fb\u5b66\u4e60\u662f\u514b\u670d\u5b9e\u9a8c\u6570\u636e\u7a00\u758f\u6027\u95ee\u9898\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u80fd\u591f\u5b9e\u73b0\u79bb\u5b50\u6db2\u4f53\u5173\u952e\u70ed\u7269\u7406\u6027\u8d28\u7684\u53ef\u9760\u9884\u6d4b\u3002"}}
{"id": "2509.10114", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.10114", "abs": "https://arxiv.org/abs/2509.10114", "authors": ["MohammadAli Hamidi", "Hadi Amirpour", "Luigi Atzori", "Christian Timmerer"], "title": "A Lightweight Ensemble-Based Face Image Quality Assessment Method with Correlation-Aware Loss", "comment": null, "summary": "Face image quality assessment (FIQA) plays a critical role in face\nrecognition and verification systems, especially in uncontrolled, real-world\nenvironments. Although several methods have been proposed, general-purpose\nno-reference image quality assessment techniques often fail to capture\nface-specific degradations. Meanwhile, state-of-the-art FIQA models tend to be\ncomputationally intensive, limiting their practical applicability. We propose a\nlightweight and efficient method for FIQA, designed for the perceptual\nevaluation of face images in the wild. Our approach integrates an ensemble of\ntwo compact convolutional neural networks, MobileNetV3-Small and ShuffleNetV2,\nwith prediction-level fusion via simple averaging. To enhance alignment with\nhuman perceptual judgments, we employ a correlation-aware loss (MSECorrLoss),\ncombining mean squared error (MSE) with a Pearson correlation regularizer. Our\nmethod achieves a strong balance between accuracy and computational cost,\nmaking it suitable for real-world deployment. Experiments on the VQualA FIQA\nbenchmark demonstrate that our model achieves a Spearman rank correlation\ncoefficient (SRCC) of 0.9829 and a Pearson linear correlation coefficient\n(PLCC) of 0.9894, remaining within competition efficiency constraints.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u9ad8\u6548\u7684\u4eba\u8138\u56fe\u50cf\u8d28\u91cf\u8bc4\u4f30\uff08FIQA\uff09\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86MobileNetV3-Small\u548cShuffleNetV2\u4e24\u4e2a\u7d27\u51d1\u578b\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff0c\u5e76\u91c7\u7528\u57fa\u4e8e\u5e73\u5747\u7684\u9884\u6d4b\u7ea7\u878d\u5408\u3002\u901a\u8fc7\u7ed3\u5408\u5747\u65b9\u8bef\u5dee\uff08MSE\uff09\u548c\u76ae\u5c14\u900a\u76f8\u5173\u6b63\u5219\u5316\u5668\uff0c\u4f7f\u7528\u611f\u77e5\u635f\u5931\uff08MSECorrLoss\uff09\u6765\u63d0\u9ad8\u4e0e\u4eba\u7c7b\u611f\u77e5\u5224\u65ad\u7684\u4e00\u81f4\u6027\u3002\u8be5\u65b9\u6cd5\u5728VQualA FIQA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e860.9829\u7684Spearman\u79e9\u76f8\u5173\u7cfb\u6570\uff08SRCC\uff09\u548c0.9894\u7684\u76ae\u5c14\u900a\u7ebf\u6027\u76f8\u5173\u7cfb\u6570\uff08PLCC\uff09\uff0c\u5728\u4fdd\u8bc1\u51c6\u786e\u6027\u7684\u540c\u65f6\uff0c\u6ee1\u8db3\u4e86\u6548\u7387\u8981\u6c42\uff0c\u9002\u5408\u5b9e\u9645\u5e94\u7528\u3002", "motivation": "\u73b0\u6709\u7684\u901a\u7528\u65e0\u53c2\u8003\u56fe\u50cf\u8d28\u91cf\u8bc4\u4f30\u65b9\u6cd5\u65e0\u6cd5\u6355\u6349\u4eba\u8138\u7279\u6709\u7684\u9000\u5316\u95ee\u9898\uff0c\u800c\u6700\u5148\u8fdb\u7684FIQA\u6a21\u578b\u8ba1\u7b97\u91cf\u5927\uff0c\u9650\u5236\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u9ad8\u6548\u4e14\u80fd\u6355\u6349\u4eba\u8138\u7279\u6709\u9000\u5316\u95ee\u9898\u7684FIQA\u65b9\u6cd5\u3002", "method": "\u96c6\u6210MobileNetV3-Small\u548cShuffleNetV2\u4e24\u4e2a\u7d27\u51d1\u578b\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff0c\u91c7\u7528\u5e73\u5747\u878d\u5408\u7b56\u7565\u3002\u4f7f\u7528\u7ed3\u5408\u5747\u65b9\u8bef\u5dee\uff08MSE\uff09\u548c\u76ae\u5c14\u900a\u76f8\u5173\u6b63\u5219\u5316\u5668\u7684MSECorrLoss\u4f5c\u4e3a\u635f\u5931\u51fd\u6570\uff0c\u4ee5\u66f4\u597d\u5730\u5339\u914d\u4eba\u7c7b\u611f\u77e5\u5224\u65ad\u3002", "result": "\u5728VQualA FIQA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u6a21\u578b\u5b9e\u73b0\u4e860.9829\u7684Spearman\u79e9\u76f8\u5173\u7cfb\u6570\uff08SRCC\uff09\u548c0.9894\u7684\u76ae\u5c14\u900a\u7ebf\u6027\u76f8\u5173\u7cfb\u6570\uff08PLCC\uff09\uff0c\u5e76\u4e14\u8ba1\u7b97\u6548\u7387\u9ad8\uff0c\u6ee1\u8db3\u4e86\u6548\u7387\u7ade\u8d5b\u7684\u7ea6\u675f\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u8f7b\u91cf\u7ea7FIQA\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6210\u672c\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u7684\u5e73\u8861\uff0c\u5e76\u4e14\u80fd\u591f\u5f88\u597d\u5730\u62df\u5408\u4eba\u7c7b\u611f\u77e5\u5224\u65ad\uff0c\u4f7f\u5176\u80fd\u591f\u6210\u529f\u5e94\u7528\u4e8e\u73b0\u5b9e\u4e16\u754c\u7684\u573a\u666f\u4e2d\u3002"}}
{"id": "2509.10108", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.10108", "abs": "https://arxiv.org/abs/2509.10108", "authors": ["Abdulrahman Allam", "Seif Ahmed", "Ali Hamdi", "Khaled Shaban"], "title": "Scaling Arabic Medical Chatbots Using Synthetic Data: Enhancing Generative AI with Synthetic Patient Records", "comment": "Accepted in AICCSA 2025", "summary": "The development of medical chatbots in Arabic is significantly constrained by\nthe scarcity of large-scale, high-quality annotated datasets. While prior\nefforts compiled a dataset of 20,000 Arabic patient-doctor interactions from\nsocial media to fine-tune large language models (LLMs), model scalability and\ngeneralization remained limited. In this study, we propose a scalable synthetic\ndata augmentation strategy to expand the training corpus to 100,000 records.\nUsing advanced generative AI systems ChatGPT-4o and Gemini 2.5 Pro we generated\n80,000 contextually relevant and medically coherent synthetic question-answer\npairs grounded in the structure of the original dataset. These synthetic\nsamples were semantically filtered, manually validated, and integrated into the\ntraining pipeline. We fine-tuned five LLMs, including Mistral-7B and AraGPT2,\nand evaluated their performance using BERTScore metrics and expert-driven\nqualitative assessments. To further analyze the effectiveness of synthetic\nsources, we conducted an ablation study comparing ChatGPT-4o and\nGemini-generated data independently. The results showed that ChatGPT-4o data\nconsistently led to higher F1-scores and fewer hallucinations across all\nmodels. Overall, our findings demonstrate the viability of synthetic\naugmentation as a practical solution for enhancing domain-specific language\nmodels in-low resource medical NLP, paving the way for more inclusive,\nscalable, and accurate Arabic healthcare chatbot systems.", "AI": {"tldr": "\u901a\u8fc7\u751f\u6210\u5408\u6210\u6570\u636e\u6765\u589e\u5f3a\u963f\u62c9\u4f2f\u8bed\u533b\u7597\u5bf9\u8bdd\u6570\u636e\u96c6\uff0c\u4ee5\u6539\u8fdb\u963f\u62c9\u4f2f\u8bed\u533b\u7597\u804a\u5929\u673a\u5668\u4eba\u3002", "motivation": "\u963f\u62c9\u4f2f\u8bed\u533b\u7597\u9886\u57df\u7f3a\u4e4f\u5927\u89c4\u6a21\u3001\u9ad8\u8d28\u91cf\u7684\u6807\u6ce8\u6570\u636e\u96c6\uff0c\u9650\u5236\u4e86\u533b\u7597\u804a\u5929\u673a\u5668\u4eba\u7684\u53d1\u5c55\u3002", "method": "\u4f7f\u7528ChatGPT-4o\u548cGemini 2.5 Pro\u751f\u621080,000\u4e2a\u5408\u6210\u7684\u963f\u62c9\u4f2f\u8bed\u533b\u7597\u95ee\u7b54\u5bf9\uff0c\u5e76\u5c06\u5176\u4e0e\u73b0\u6709\u6570\u636e\u96c6\u7ed3\u5408\uff0c\u7528\u4e8e\u5fae\u8c03\u5305\u62ecMistral-7B\u548cAraGPT2\u5728\u5185\u7684\u4e94\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u4f7f\u7528\u5408\u6210\u6570\u636e\u5fae\u8c03\u540e\u7684\u6a21\u578b\u5728BERTScore\u6307\u6807\u548c\u4e13\u5bb6\u8bc4\u4f30\u4e2d\u8868\u73b0\u66f4\u597d\uff0c\u5176\u4e2dChatGPT-4o\u751f\u6210\u7684\u6570\u636e\u96c6\u6548\u679c\u5c24\u4e3a\u7a81\u51fa\uff0c\u53ef\u4ee5\u63d0\u9ad8F1\u5206\u6570\u5e76\u51cf\u5c11\u5e7b\u89c9\u3002", "conclusion": "\u5408\u6210\u6570\u636e\u589e\u5f3a\u662f\u4e00\u79cd\u53ef\u884c\u4e14\u5b9e\u7528\u7684\u65b9\u6cd5\uff0c\u53ef\u4ee5\u89e3\u51b3\u4f4e\u8d44\u6e90\u533b\u7597\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\u7684\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u6a21\u578b\u589e\u5f3a\u95ee\u9898\uff0c\u4ece\u800c\u4fc3\u8fdb\u66f4\u5177\u5305\u5bb9\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u51c6\u786e\u6027\u7684\u963f\u62c9\u4f2f\u8bed\u533b\u7597\u804a\u5929\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u53d1\u5c55\u3002"}}
{"id": "2509.10291", "categories": ["cs.LG", "cs.NI"], "pdf": "https://arxiv.org/pdf/2509.10291", "abs": "https://arxiv.org/abs/2509.10291", "authors": ["Salih Toprak", "Muge Erel-Ozcevik"], "title": "Proof of AutoML: SDN based Secure Energy Trading with Blockchain in Disaster Case", "comment": "6 pages, 3 figures, 7th International Conference on Blockchain\n  Computing and Applications (BCCA 2025), \\c{opyright}2025 IEEE", "summary": "In disaster scenarios where conventional energy infrastructure is\ncompromised, secure and traceable energy trading between solar-powered\nhouseholds and mobile charging units becomes a necessity. To ensure the\nintegrity of such transactions over a blockchain network, robust and\nunpredictable nonce generation is vital. This study proposes an SDN-enabled\narchitecture where machine learning regressors are leveraged not for their\naccuracy, but for their potential to generate randomized values suitable as\nnonce candidates. Therefore, it is newly called Proof of AutoML. Here, SDN\nallows flexible control over data flows and energy routing policies even in\nfragmented or degraded networks, ensuring adaptive response during emergencies.\nUsing a 9000-sample dataset, we evaluate five AutoML-selected regression models\n- Gradient Boosting, LightGBM, Random Forest, Extra Trees, and K-Nearest\nNeighbors - not by their prediction accuracy, but by their ability to produce\ndiverse and non-deterministic outputs across shuffled data inputs. Randomness\nanalysis reveals that Random Forest and Extra Trees regressors exhibit complete\ndependency on randomness, whereas Gradient Boosting, K-Nearest Neighbors and\nLightGBM show strong but slightly lower randomness scores (97.6%, 98.8% and\n99.9%, respectively). These findings highlight that certain machine learning\nmodels, particularly tree-based ensembles, may serve as effective and\nlightweight nonce generators within blockchain-secured, SDN-based energy\ntrading infrastructures resilient to disaster conditions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aProof of AutoML\u7684\u65b0\u578b\u533a\u5757\u94fe\u5171\u8bc6\u673a\u5236\uff0c\u5229\u7528\u673a\u5668\u5b66\u4e60\u56de\u5f52\u6a21\u578b\u751f\u6210\u4e0d\u53ef\u9884\u6d4b\u7684\u968f\u673a\u6570\uff08nonce\uff09\uff0c\u4ee5\u652f\u6301\u707e\u96be\u573a\u666f\u4e0b\u57fa\u4e8eSDN\u7684\u80fd\u6e90\u4ea4\u6613\u3002", "motivation": "\u5728\u707e\u96be\u573a\u666f\u4e0b\uff0c\u4f20\u7edf\u80fd\u6e90\u8bbe\u65bd\u53ef\u80fd\u5931\u6548\uff0c\u9700\u8981\u5b89\u5168\u7684\u3001\u53ef\u8ffd\u6eaf\u7684\u80fd\u6e90\u4ea4\u6613\uff0c\u56e0\u6b64\u9700\u8981\u5065\u58ee\u4e14\u4e0d\u53ef\u9884\u6d4b\u7684\u968f\u673a\u6570\u751f\u6210\u6765\u786e\u4fdd\u4ea4\u6613\u7684\u5b8c\u6574\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cdSDN\u67b6\u6784\uff0c\u5e76\u5229\u7528\u673a\u5668\u5b66\u4e60\u56de\u5f52\u6a21\u578b\uff08Gradient Boosting, LightGBM, Random Forest, Extra Trees, K-Nearest Neighbors\uff09\u751f\u6210\u968f\u673a\u6570\u3002\u8bc4\u4f30\u8fd9\u4e9b\u6a21\u578b\u751f\u6210\u968f\u673a\u6570\u7684\u80fd\u529b\uff0c\u800c\u4e0d\u662f\u9884\u6d4b\u51c6\u786e\u6027\u3002", "result": "\u968f\u673a\u6027\u5206\u6790\u8868\u660e\uff0cRandom Forest\u548cExtra Trees\u56de\u5f52\u6a21\u578b\u8868\u73b0\u51fa\u5b8c\u5168\u4f9d\u8d56\u968f\u673a\u6027\uff0c\u800cGradient Boosting\u3001K-Nearest Neighbors\u548cLightGBM\u5f97\u5206\u5206\u522b\u4e3a97.6%\u300198.8%\u548c99.9%\u3002", "conclusion": "\u67d0\u4e9b\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u7279\u522b\u662f\u57fa\u4e8e\u6811\u7684\u6a21\u578b\uff0c\u53ef\u4ee5\u4f5c\u4e3a\u533a\u5757\u94fe\u5b89\u5168\u3001SDN\u652f\u6301\u7684\u80fd\u6e90\u4ea4\u6613\u57fa\u7840\u8bbe\u65bd\u7684\u6709\u6548\u4e14\u8f7b\u91cf\u7ea7\u7684\u968f\u673a\u6570\u751f\u6210\u5668\uff0c\u4ee5\u5e94\u5bf9\u707e\u96be\u6761\u4ef6\u3002"}}
{"id": "2509.10122", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10122", "abs": "https://arxiv.org/abs/2509.10122", "authors": ["Zongliang Wu", "Siming Zheng", "Peng-Tao Jiang", "Xin Yuan"], "title": "Realism Control One-step Diffusion for Real-World Image Super-Resolution", "comment": null, "summary": "Pre-trained diffusion models have shown great potential in real-world image\nsuper-resolution (Real-ISR) tasks by enabling high-resolution reconstructions.\nWhile one-step diffusion (OSD) methods significantly improve efficiency\ncompared to traditional multi-step approaches, they still have limitations in\nbalancing fidelity and realism across diverse scenarios. Since the OSDs for SR\nare usually trained or distilled by a single timestep, they lack flexible\ncontrol mechanisms to adaptively prioritize these competing objectives, which\nare inherently manageable in multi-step methods through adjusting sampling\nsteps. To address this challenge, we propose a Realism Controlled One-step\nDiffusion (RCOD) framework for Real-ISR. RCOD provides a latent domain grouping\nstrategy that enables explicit control over fidelity-realism trade-offs during\nthe noise prediction phase with minimal training paradigm modifications and\noriginal training data. A degradation-aware sampling strategy is also\nintroduced to align distillation regularization with the grouping strategy and\nenhance the controlling of trade-offs. Moreover, a visual prompt injection\nmodule is used to replace conventional text prompts with degradation-aware\nvisual tokens, enhancing both restoration accuracy and semantic consistency.\nOur method achieves superior fidelity and perceptual quality while maintaining\ncomputational efficiency. Extensive experiments demonstrate that RCOD\noutperforms state-of-the-art OSD methods in both quantitative metrics and\nvisual qualities, with flexible realism control capabilities in the inference\nstage. The code will be released.", "AI": {"tldr": "RCOD\u6846\u67b6\u901a\u8fc7\u6f5c\u5728\u57df\u5206\u7ec4\u548c\u9000\u5316\u611f\u77e5\u91c7\u6837\u7b56\u7565\uff0c\u5728\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u5355\u6b65\u6269\u6563\u6a21\u578b\u5728\u771f\u5b9e\u4e16\u754c\u56fe\u50cf\u8d85\u5206\u8fa8\u7387\uff08Real-ISR\uff09\u4efb\u52a1\u4e2d\u4fdd\u771f\u5ea6\u548c\u771f\u5b9e\u611f\u5e73\u8861\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5728\u5b9a\u91cf\u6307\u6807\u548c\u89c6\u89c9\u8d28\u91cf\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u5355\u6b65\u6269\u6563\uff08OSD\uff09\u65b9\u6cd5\u5728\u771f\u5b9e\u4e16\u754c\u56fe\u50cf\u8d85\u5206\u8fa8\u7387\uff08Real-ISR\uff09\u4efb\u52a1\u4e2d\uff0c\u867d\u7136\u63d0\u9ad8\u4e86\u6548\u7387\uff0c\u4f46\u5728\u4fdd\u771f\u5ea6\u548c\u771f\u5b9e\u611f\u4e4b\u95f4\u96be\u4ee5\u53d6\u5f97\u826f\u597d\u5e73\u8861\uff0c\u5c24\u5176\u662f\u5728\u591a\u6837\u5316\u573a\u666f\u4e0b\u3002\u8fd9\u662f\u56e0\u4e3a\u5b83\u4eec\u901a\u5e38\u5728\u5355\u4e00\u65f6\u95f4\u6b65\u957f\u8fdb\u884c\u8bad\u7ec3\u6216\u84b8\u998f\uff0c\u7f3a\u4e4f\u50cf\u591a\u6b65\u65b9\u6cd5\u90a3\u6837\u901a\u8fc7\u8c03\u6574\u91c7\u6837\u6b65\u957f\u6765\u7075\u6d3b\u63a7\u5236\u8fd9\u4e9b\u76f8\u4e92\u7ade\u4e89\u76ee\u6807\u7684\u673a\u5236\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aRCOD\uff08Realism Controlled One-step Diffusion\uff09\u7684\u6846\u67b6\u3002\u8be5\u6846\u67b6\u5305\u62ec\uff1a1. \u6f5c\u5728\u57df\u5206\u7ec4\u7b56\u7565\uff1a\u5728\u566a\u58f0\u9884\u6d4b\u9636\u6bb5\u663e\u5f0f\u63a7\u5236\u4fdd\u771f\u5ea6-\u771f\u5b9e\u611f\u6743\u8861\uff0c\u4e14\u5bf9\u8bad\u7ec3\u8303\u5f0f\u548c\u6570\u636e\u6539\u52a8\u6700\u5c0f\u30022. \u9000\u5316\u611f\u77e5\u91c7\u6837\u7b56\u7565\uff1a\u4f7f\u84b8\u998f\u6b63\u5219\u5316\u4e0e\u5206\u7ec4\u7b56\u7565\u5bf9\u9f50\uff0c\u589e\u5f3a\u6743\u8861\u63a7\u5236\u30023. \u89c6\u89c9\u63d0\u793a\u6ce8\u5165\u6a21\u5757\uff1a\u7528\u9000\u5316\u611f\u77e5\u7684\u89c6\u89c9\u6807\u8bb0\u66ff\u6362\u4f20\u7edf\u6587\u672c\u63d0\u793a\uff0c\u63d0\u5347\u6062\u590d\u51c6\u786e\u6027\u548c\u8bed\u4e49\u4e00\u81f4\u6027\u3002", "result": "RCOD\u6846\u67b6\u5728\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u4f18\u4e8e\u6700\u5148\u8fdbOSD\u65b9\u6cd5\u7684\u4fdd\u771f\u5ea6\u548c\u611f\u77e5\u8d28\u91cf\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cRCOD\u5728\u5b9a\u91cf\u6307\u6807\u548c\u89c6\u89c9\u8d28\u91cf\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u5177\u5907\u63a8\u7406\u9636\u6bb5\u7075\u6d3b\u7684\u771f\u5b9e\u611f\u63a7\u5236\u80fd\u529b\u3002", "conclusion": "RCOD\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u5355\u6b65\u6269\u6563\u6a21\u578b\u5728\u771f\u5b9e\u4e16\u754c\u56fe\u50cf\u8d85\u5206\u8fa8\u7387\u4efb\u52a1\u4e2d\u7684\u4fdd\u771f\u5ea6\u4e0e\u771f\u5b9e\u611f\u5e73\u8861\u95ee\u9898\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u6f5c\u5728\u57df\u5206\u7ec4\u548c\u9000\u5316\u611f\u77e5\u91c7\u6837\u7b56\u7565\uff0c\u5b9e\u73b0\u4e86\u5728\u6548\u7387\u548c\u6548\u679c\u4e0a\u7684\u663e\u8457\u63d0\u5347\uff0c\u5e76\u63d0\u4f9b\u4e86\u7075\u6d3b\u7684\u63a7\u5236\u80fd\u529b\u3002"}}
{"id": "2509.10116", "categories": ["cs.CL", "eess.AS"], "pdf": "https://arxiv.org/pdf/2509.10116", "abs": "https://arxiv.org/abs/2509.10116", "authors": ["Julian Linke", "Barbara Schuppler"], "title": "Prominence-aware automatic speech recognition for conversational speech", "comment": null, "summary": "This paper investigates prominence-aware automatic speech recognition (ASR)\nby combining prominence detection and speech recognition for conversational\nAustrian German. First, prominence detectors were developed by fine-tuning\nwav2vec2 models to classify word-level prominence. The detector was then used\nto automatically annotate prosodic prominence in a large corpus. Based on those\nannotations, we trained novel prominence-aware ASR systems that simultaneously\ntranscribe words and their prominence levels. The integration of prominence\ninformation did not change performance compared to our baseline ASR system,\nwhile reaching a prominence detection accuracy of 85.53% for utterances where\nthe recognized word sequence was correct. This paper shows that\ntransformer-based models can effectively encode prosodic information and\nrepresents a novel contribution to prosody-enhanced ASR, with potential\napplications for linguistic research and prosody-informed dialogue systems.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u7ed3\u5408\u663e\u5ea6\u68c0\u6d4b\u548c\u8bed\u97f3\u8bc6\u522b\u6765\u7814\u7a76\u663e\u5ea6\u611f\u77e5\u7684\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\uff08ASR\uff09\uff0c\u5728\u5965\u5730\u5229\u5fb7\u8bed\u5bf9\u8bdd\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u63a2\u7d22\u663e\u5ea6\u4fe1\u606f\u5982\u4f55\u6539\u5584\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\uff0c\u5e76\u4e3a\u8bed\u8a00\u5b66\u7814\u7a76\u548c\u5bf9\u8bdd\u7cfb\u7edf\u63d0\u4f9b\u65b0\u7684\u9014\u5f84\u3002", "method": "\u9996\u5148\uff0c\u901a\u8fc7\u5fae\u8c03wav2vec2\u6a21\u578b\u6765\u5f00\u53d1\u663e\u5ea6\u68c0\u6d4b\u5668\uff0c\u7528\u4e8e\u5bf9\u5355\u8bcd\u7ea7\u522b\u7684\u663e\u5ea6\u8fdb\u884c\u5206\u7c7b\u3002\u7136\u540e\uff0c\u5229\u7528\u8be5\u68c0\u6d4b\u5668\u5bf9\u5927\u578b\u8bed\u6599\u5e93\u8fdb\u884c\u81ea\u52a8\u97f5\u5f8b\u663e\u5ea6\u6807\u6ce8\u3002\u57fa\u4e8e\u8fd9\u4e9b\u6807\u6ce8\uff0c\u8bad\u7ec3\u4e86\u80fd\u591f\u540c\u65f6\u8f6c\u5f55\u5355\u8bcd\u53ca\u5176\u663e\u5ea6\u7ea7\u522b\u7684\u3001\u65b0\u9896\u7684\u663e\u5ea6\u611f\u77e5ASR\u7cfb\u7edf\u3002", "result": "\u663e\u5ea6\u4fe1\u606f\u6ca1\u6709\u6539\u53d8ASR\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u4f46\u663e\u5ea6\u68c0\u6d4b\u7684\u51c6\u786e\u7387\u8fbe\u5230\u4e8685.53%\uff08\u5728\u8bc6\u522b\u6b63\u786e\u7684\u8bed\u53e5\u4e2d\uff09\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u57fa\u4e8eTransformer\u7684\u6a21\u578b\u53ef\u4ee5\u6709\u6548\u5730\u7f16\u7801\u97f5\u5f8b\u4fe1\u606f\uff0c\u4e3a\u97f5\u5f8b\u589e\u5f3a\u7684ASR\u505a\u51fa\u4e86\u65b0\u8d21\u732e\uff0c\u5e76\u5177\u6709\u5e94\u7528\u4e8e\u8bed\u8a00\u5b66\u7814\u7a76\u548c\u97f5\u5f8b\u611f\u77e5\u5bf9\u8bdd\u7cfb\u7edf\u7684\u6f5c\u529b\u3002"}}
{"id": "2509.10303", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10303", "abs": "https://arxiv.org/abs/2509.10303", "authors": ["Jesse van Remmerden", "Zaharah Bukhsh", "Yingqian Zhang"], "title": "Generalizing Beyond Suboptimality: Offline Reinforcement Learning Learns Effective Scheduling through Random Data", "comment": null, "summary": "The Job-Shop Scheduling Problem (JSP) and Flexible Job-Shop Scheduling\nProblem (FJSP), are canonical combinatorial optimization problems with\nwide-ranging applications in industrial operations. In recent years, many\nonline reinforcement learning (RL) approaches have been proposed to learn\nconstructive heuristics for JSP and FJSP. Although effective, these online RL\nmethods require millions of interactions with simulated environments that may\nnot capture real-world complexities, and their random policy initialization\nleads to poor sample efficiency. To address these limitations, we introduce\nConservative Discrete Quantile Actor-Critic (CDQAC), a novel offline RL\nalgorithm that learns effective scheduling policies directly from historical\ndata, eliminating the need for costly online interactions, while maintaining\nthe ability to improve upon suboptimal training data. CDQAC couples a\nquantile-based critic with a delayed policy update, estimating the return\ndistribution of each machine-operation pair rather than selecting pairs\noutright. Our extensive experiments demonstrate CDQAC's remarkable ability to\nlearn from diverse data sources. CDQAC consistently outperforms the original\ndata-generating heuristics and surpasses state-of-the-art offline and online RL\nbaselines. In addition, CDQAC is highly sample efficient, requiring only 10-20\ntraining instances to learn high-quality policies. Surprisingly, we find that\nCDQAC performs better when trained on data generated by a random heuristic than\nwhen trained on higher-quality data from genetic algorithms and priority\ndispatching rules.", "AI": {"tldr": "CDQAC\u662f\u4e00\u79cd\u65b0\u7684\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u53ef\u4ee5\u76f4\u63a5\u4ece\u5386\u53f2\u6570\u636e\u4e2d\u5b66\u4e60\u8c03\u5ea6\u7b56\u7565\uff0c\u65e0\u9700\u5728\u7ebf\u4ea4\u4e92\uff0c\u5e76\u80fd\u6539\u8fdb\u6b21\u4f18\u8bad\u7ec3\u6570\u636e\uff0c\u5728JSP\u548cFJSP\u95ee\u9898\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u5904\u7406JSP\u548cFJSP\u95ee\u9898\u65f6\u9700\u8981\u5927\u91cf\u6a21\u62df\u4ea4\u4e92\uff0c\u4e14\u7b56\u7565\u521d\u59cb\u5316\u968f\u673a\u5bfc\u81f4\u6837\u672c\u6548\u7387\u4f4e\u4e0b\uff0c\u800cCDQAC\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u5c40\u9650\u6027\u3002", "method": "CDQAC\u7ed3\u5408\u4e86\u57fa\u4e8e\u5206\u4f4d\u6570\u7684Critic\u548c\u5ef6\u8fdf\u7b56\u7565\u66f4\u65b0\uff0c\u4f30\u8ba1\u6bcf\u4e2a\u673a\u5668-\u64cd\u4f5c\u5bf9\u7684\u8fd4\u56de\u5206\u5e03\uff0c\u800c\u975e\u76f4\u63a5\u9009\u62e9\uff0c\u4ece\u800c\u4ece\u5386\u53f2\u6570\u636e\u4e2d\u5b66\u4e60\u8c03\u5ea6\u7b56\u7565\u3002", "result": "CDQAC\u5728\u5404\u79cd\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f18\u4e8e\u6570\u636e\u751f\u6210\u542f\u53d1\u5f0f\u65b9\u6cd5\u548c\u6700\u5148\u8fdb\u7684\u79bb\u7ebf/\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u57fa\u7ebf\uff0c\u5e76\u4e14\u6837\u672c\u6548\u7387\u9ad8\uff0c\u4ec5\u970010-20\u4e2a\u8bad\u7ec3\u5b9e\u4f8b\u5373\u53ef\u5b66\u4e60\u9ad8\u8d28\u91cf\u7b56\u7565\u3002\u51fa\u4eba\u610f\u6599\u7684\u662f\uff0cCDQAC\u5728\u968f\u673a\u542f\u53d1\u5f0f\u751f\u6210\u7684\u6570\u636e\u4e0a\u8bad\u7ec3\u6548\u679c\u4f18\u4e8e\u9057\u4f20\u7b97\u6cd5\u548c\u4f18\u5148\u8c03\u5ea6\u89c4\u5219\u751f\u6210\u7684\u6570\u636e\u3002", "conclusion": "CDQAC\u662f\u4e00\u79cd\u6709\u6548\u7684\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u80fd\u591f\u4ece\u5386\u53f2\u6570\u636e\u4e2d\u5b66\u4e60\u9ad8\u8d28\u91cf\u7684\u8c03\u5ea6\u7b56\u7565\uff0c\u5e76\u4e14\u5728JSP\u548cFJSP\u95ee\u9898\u4e0a\u5177\u6709\u4f18\u8d8a\u7684\u6027\u80fd\u548c\u9ad8\u6837\u672c\u6548\u7387\u3002"}}
{"id": "2509.10134", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.10134", "abs": "https://arxiv.org/abs/2509.10134", "authors": ["Rini Smita Thakur", "Rajeev Ranjan Dwivedi", "Vinod K Kurmi"], "title": "Grad-CL: Source Free Domain Adaptation with Gradient Guided Feature Disalignment", "comment": "Accepted in BMVC 2025", "summary": "Accurate segmentation of the optic disc and cup is critical for the early\ndiagnosis and management of ocular diseases such as glaucoma. However,\nsegmentation models trained on one dataset often suffer significant performance\ndegradation when applied to target data acquired under different imaging\nprotocols or conditions. To address this challenge, we propose\n\\textbf{Grad-CL}, a novel source-free domain adaptation framework that\nleverages a pre-trained source model and unlabeled target data to robustly\nadapt segmentation performance without requiring access to the original source\ndata. Grad-CL combines a gradient-guided pseudolabel refinement module with a\ncosine similarity-based contrastive learning strategy. In the first stage,\nsalient class-specific features are extracted via a gradient-based mechanism,\nenabling more accurate uncertainty quantification and robust prototype\nestimation for refining noisy pseudolabels. In the second stage, a contrastive\nloss based on cosine similarity is employed to explicitly enforce inter-class\nseparability between the gradient-informed features of the optic cup and disc.\nExtensive experiments on challenging cross-domain fundus imaging datasets\ndemonstrate that Grad-CL outperforms state-of-the-art unsupervised and\nsource-free domain adaptation methods, achieving superior segmentation accuracy\nand improved boundary delineation. Project and code are available at\nhttps://visdomlab.github.io/GCL/.", "AI": {"tldr": "Grad-CL\u662f\u4e00\u79cd\u65b0\u9896\u7684\u65e0\u6e90\u57df\u9002\u5e94\u6846\u67b6\uff0c\u901a\u8fc7\u68af\u5ea6\u4f2a\u6807\u7b7e\u7ec6\u5316\u548c\u5bf9\u6bd4\u5b66\u4e60\u7b56\u7565\uff0c\u5728\u6ca1\u6709\u6e90\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u7684\u6e90\u6a21\u578b\u548c\u672a\u6807\u8bb0\u7684\u76ee\u6807\u6570\u636e\u6765\u9002\u5e94\u5206\u5272\u6027\u80fd\uff0c\u4ece\u800c\u5b9e\u73b0\u7cbe\u786e\u7684\u89c6\u76d8\u548c\u89c6\u676f\u5206\u5272\uff0c\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57df\u9002\u5e94\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u89c6\u76d8\u548c\u89c6\u676f\u5206\u5272\u6a21\u578b\u5728\u4e0d\u540c\u6210\u50cf\u534f\u8bae\u6216\u6761\u4ef6\u4e0b\u83b7\u53d6\u7684\u76ee\u6807\u6570\u636e\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u9002\u5e94\u4e0d\u540c\u6570\u636e\u57df\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "Grad-CL\u6846\u67b6\u5305\u542b\u4e24\u4e2a\u4e3b\u8981\u9636\u6bb5\uff1a1. \u68af\u5ea6\u4f2a\u6807\u7b7e\u7ec6\u5316\uff1a\u901a\u8fc7\u68af\u5ea6\u673a\u5236\u63d0\u53d6\u663e\u8457\u7684\u7279\u5b9a\u7c7b\u522b\u7279\u5f81\uff0c\u5b9e\u73b0\u66f4\u51c6\u786e\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u548c\u9c81\u68d2\u7684\u539f\u578b\u4f30\u8ba1\uff0c\u4ee5\u6539\u8fdb\u4f2a\u6807\u7b7e\u30022. \u5bf9\u6bd4\u5b66\u4e60\uff1a\u5229\u7528\u57fa\u4e8e\u4f59\u5f26\u76f8\u4f3c\u5ea6\u7684\u5bf9\u6bd4\u635f\u5931\uff0c\u5f3a\u5236\u6267\u884c\u68af\u5ea6\u4fe1\u606f\u7279\u5f81\u7684\u7c7b\u522b\u95f4\u53ef\u5206\u79bb\u6027\u3002", "result": "\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u8de8\u57df\u773c\u5e95\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9a8c\uff0c\u7ed3\u679c\u8868\u660eGrad-CL\u5728\u5206\u5272\u7cbe\u5ea6\u548c\u8fb9\u754c\u6e05\u6670\u5ea6\u65b9\u9762\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65e0\u76d1\u7763\u548c\u65e0\u6e90\u57df\u9002\u5e94\u65b9\u6cd5\u3002", "conclusion": "Grad-CL\u662f\u4e00\u79cd\u6709\u6548\u7684\u65e0\u6e90\u57df\u9002\u5e94\u6846\u67b6\uff0c\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u5728\u4e0d\u540c\u6570\u636e\u57df\u4e0a\u7684\u89c6\u76d8\u548c\u89c6\u676f\u5206\u5272\u6027\u80fd\u3002"}}
{"id": "2509.10127", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10127", "abs": "https://arxiv.org/abs/2509.10127", "authors": ["Zhengyu Hu", "Zheyuan Xiao", "Max Xiong", "Yuxuan Lei", "Tianfu Wang", "Jianxun Lian", "Kaize Ding", "Ziang Xiao", "Nicholas Jing Yuan", "Xing Xie"], "title": "Population-Aligned Persona Generation for LLM-based Social Simulation", "comment": null, "summary": "Recent advances in large language models (LLMs) have enabled human-like\nsocial simulations at unprecedented scale and fidelity, offering new\nopportunities for computational social science. A key challenge, however, is\nthe construction of persona sets that authentically represent the diversity and\ndistribution of real-world populations. Most existing LLM-based social\nsimulation studies focus primarily on designing agentic frameworks and\nsimulation environments, often overlooking the complexities of persona\ngeneration and the potential biases introduced by unrepresentative persona\nsets. In this paper, we propose a systematic framework for synthesizing\nhigh-quality, population-aligned persona sets for LLM-driven social simulation.\nOur approach begins by leveraging LLMs to generate narrative personas from\nlong-term social media data, followed by rigorous quality assessment to filter\nout low-fidelity profiles. We then apply importance sampling to achieve global\nalignment with reference psychometric distributions, such as the Big Five\npersonality traits. To address the needs of specific simulation contexts, we\nfurther introduce a task-specific module that adapts the globally aligned\npersona set to targeted subpopulations. Extensive experiments demonstrate that\nour method significantly reduces population-level bias and enables accurate,\nflexible social simulation for a wide range of research and policy\napplications.", "AI": {"tldr": "LLM\u9a71\u52a8\u7684\u793e\u4f1a\u6a21\u62df\u9700\u8981\u9ad8\u8d28\u91cf\u3001\u7b26\u5408\u4eba\u53e3\u5206\u5e03\u7684\u6a21\u62df\u4eba\u96c6\u5408\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7cfb\u7edf\u6846\u67b6\uff0c\u5229\u7528LLM\u4ece\u793e\u4ea4\u5a92\u4f53\u6570\u636e\u4e2d\u751f\u6210\u53d9\u8ff0\u6027\u6a21\u62df\u4eba\uff0c\u901a\u8fc7\u8d28\u91cf\u8bc4\u4f30\u8fdb\u884c\u7b5b\u9009\uff0c\u5e76\u4f7f\u7528\u91cd\u8981\u6027\u91c7\u6837\u548c\u7279\u5b9a\u4efb\u52a1\u6a21\u5757\u6765\u786e\u4fdd\u5176\u4e0e\u4eba\u53e3\u7edf\u8ba1\u548c\u5fc3\u7406\u6d4b\u91cf\u5206\u5e03\uff08\u5982\u5927\u4e94\u4eba\u683c\u7279\u8d28\uff09\u7684\u5168\u5c40\u548c\u5c40\u90e8\u5bf9\u9f50\uff0c\u4ece\u800c\u51cf\u5c11\u504f\u5dee\u5e76\u5b9e\u73b0\u51c6\u786e\u7075\u6d3b\u7684\u793e\u4f1a\u6a21\u62df\u3002", "motivation": "\u73b0\u6709LLM\u9a71\u52a8\u7684\u793e\u4f1a\u6a21\u62df\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u4ee3\u7406\u6846\u67b6\u548c\u6a21\u62df\u73af\u5883\uff0c\u800c\u5ffd\u89c6\u4e86\u6a21\u62df\u4eba\u751f\u6210\u548c\u6f5c\u5728\u504f\u5dee\u95ee\u9898\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u5982\u4f55\u6784\u5efa\u771f\u5b9e\u53cd\u6620\u73b0\u5b9e\u4e16\u754c\u4eba\u53e3\u591a\u6837\u6027\u548c\u5206\u5e03\u7684\u6a21\u62df\u4eba\u96c6\u5408\u8fd9\u4e00\u5173\u952e\u6311\u6218\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u7cfb\u7edf\u6846\u67b6\uff0c\u9996\u5148\u5229\u7528LLM\u4ece\u957f\u671f\u793e\u4ea4\u5a92\u4f53\u6570\u636e\u751f\u6210\u53d9\u8ff0\u6027\u6a21\u62df\u4eba\uff0c\u7136\u540e\u8fdb\u884c\u8d28\u91cf\u8bc4\u4f30\u4ee5\u8fc7\u6ee4\u4f4e\u4fdd\u771f\u5ea6\u6863\u6848\u3002\u63a5\u7740\uff0c\u5e94\u7528\u91cd\u8981\u6027\u91c7\u6837\u5b9e\u73b0\u4e0e\u53c2\u8003\u5fc3\u7406\u6d4b\u91cf\u5206\u5e03\uff08\u5982\u5927\u4e94\u4eba\u683c\u7279\u8d28\uff09\u7684\u5168\u5c40\u5bf9\u9f50\u3002\u6700\u540e\uff0c\u5f15\u5165\u4e00\u4e2a\u7279\u5b9a\u4efb\u52a1\u6a21\u5757\uff0c\u5c06\u5168\u5c40\u5bf9\u9f50\u7684\u6a21\u62df\u4eba\u96c6\u5408\u8c03\u6574\u4ee5\u9002\u5e94\u76ee\u6807\u5b50\u4eba\u7fa4\uff0c\u6ee1\u8db3\u7279\u5b9a\u6a21\u62df\u60c5\u5883\u7684\u9700\u6c42\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u663e\u8457\u51cf\u5c11\u4e86\u4eba\u53e3\u5c42\u9762\u7684\u504f\u5dee\uff0c\u80fd\u591f\u4e3a\u5e7f\u6cdb\u7684\u7814\u7a76\u548c\u653f\u7b56\u5e94\u7528\u5b9e\u73b0\u51c6\u786e\u3001\u7075\u6d3b\u7684\u793e\u4f1a\u6a21\u62df\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u7cfb\u7edf\u6846\u67b6\u80fd\u591f\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u7b26\u5408\u4eba\u53e3\u5206\u5e03\u7684\u6a21\u62df\u4eba\u96c6\u5408\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709LLM\u9a71\u52a8\u7684\u793e\u4f1a\u6a21\u62df\u5728\u6a21\u62df\u4eba\u6784\u5efa\u65b9\u9762\u5b58\u5728\u7684\u4e0d\u8db3\uff0c\u4e3a\u8ba1\u7b97\u793e\u4f1a\u79d1\u5b66\u9886\u57df\u63d0\u4f9b\u4e86\u6709\u529b\u7684\u652f\u6301\u3002"}}
{"id": "2509.10308", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10308", "abs": "https://arxiv.org/abs/2509.10308", "authors": ["Joshua Dimasaka", "Christian Gei\u00df", "Robert Muir-Wood", "Emily So"], "title": "GraphCSVAE: Graph Categorical Structured Variational Autoencoder for Spatiotemporal Auditing of Physical Vulnerability Towards Sustainable Post-Disaster Risk Reduction", "comment": "Accepted full paper at the 8th International Disaster and Risk\n  Conference, IDRC 2025 | Keywords: weakly supervised, graph deep learning,\n  categorical distribution, physical vulnerability, remote sensing,\n  spatiotemporal disaster risk, transition matrix | The data and code are\n  respectively available at https://doi.org/10.5281/zenodo.16656471 and\n  https://github.com/riskaudit/GraphCSVAE", "summary": "In the aftermath of disasters, many institutions worldwide face challenges in\ncontinually monitoring changes in disaster risk, limiting the ability of key\ndecision-makers to assess progress towards the UN Sendai Framework for Disaster\nRisk Reduction 2015-2030. While numerous efforts have substantially advanced\nthe large-scale modeling of hazard and exposure through Earth observation and\ndata-driven methods, progress remains limited in modeling another equally\nimportant yet challenging element of the risk equation: physical vulnerability.\nTo address this gap, we introduce Graph Categorical Structured Variational\nAutoencoder (GraphCSVAE), a novel probabilistic data-driven framework for\nmodeling physical vulnerability by integrating deep learning, graph\nrepresentation, and categorical probabilistic inference, using time-series\nsatellite-derived datasets and prior expert belief systems. We introduce a\nweakly supervised first-order transition matrix that reflects the changes in\nthe spatiotemporal distribution of physical vulnerability in two\ndisaster-stricken and socioeconomically disadvantaged areas: (1) the\ncyclone-impacted coastal Khurushkul community in Bangladesh and (2) the\nmudslide-affected city of Freetown in Sierra Leone. Our work reveals\npost-disaster regional dynamics in physical vulnerability, offering valuable\ninsights into localized spatiotemporal auditing and sustainable strategies for\npost-disaster risk reduction.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGraphCSVAE\u7684\u65b0\u578b\u6846\u67b6\uff0c\u7528\u4e8e\u5206\u6790\u707e\u540e\u7269\u7406\u8106\u5f31\u6027\u3002\u8be5\u6846\u67b6\u7ed3\u5408\u4e86\u6df1\u5ea6\u5b66\u4e60\u3001\u56fe\u8868\u793a\u548c\u5206\u7c7b\u6982\u7387\u63a8\u65ad\uff0c\u5e76\u5229\u7528\u65f6\u95f4\u5e8f\u5217\u536b\u661f\u6570\u636e\u548c\u4e13\u5bb6\u77e5\u8bc6\u3002\u7814\u7a76\u5728\u5b5f\u52a0\u62c9\u56fd\u548c\u585e\u62c9\u5229\u6602\u7684\u4e24\u4e2a\u707e\u533a\u8fdb\u884c\u4e86\u6848\u4f8b\u5206\u6790\uff0c\u63ed\u793a\u4e86\u707e\u540e\u7269\u7406\u8106\u5f31\u6027\u7684\u65f6\u7a7a\u52a8\u6001\uff0c\u4e3a\u707e\u540e\u98ce\u9669\u51cf\u5c11\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002", "motivation": "\u5168\u7403\u8bb8\u591a\u673a\u6784\u5728\u707e\u540e\u6301\u7eed\u76d1\u6d4b\u707e\u5bb3\u98ce\u9669\u53d8\u5316\u65b9\u9762\u9762\u4e34\u6311\u6218\uff0c\u8fd9\u5236\u7ea6\u4e86\u51b3\u7b56\u8005\u8bc4\u4f30\u300a2015-2030\u5e74\u4ed9\u53f0\u51cf\u5c11\u707e\u5bb3\u98ce\u9669\u6846\u67b6\u300b\u8fdb\u5c55\u7684\u80fd\u529b\u3002\u5c3d\u7ba1\u5728\u901a\u8fc7\u5730\u7403\u89c2\u6d4b\u548c\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u5bf9\u5371\u5bb3\u548c\u66b4\u9732\u8fdb\u884c\u5927\u89c4\u6a21\u5efa\u6a21\u65b9\u9762\u5df2\u53d6\u5f97\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5728\u5bf9\u98ce\u9669\u65b9\u7a0b\u4e2d\u540c\u6837\u91cd\u8981\u4f46\u5177\u6709\u6311\u6218\u6027\u7684\u8981\u7d20\u2014\u2014\u7269\u7406\u8106\u5f31\u6027\u2014\u2014\u8fdb\u884c\u5efa\u6a21\u65b9\u9762\u8fdb\u5c55\u6709\u9650\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGraphCSVAE\uff08\u56fe\u5206\u7c7b\u7ed3\u6784\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff09\u7684\u65b0\u578b\u6982\u7387\u6570\u636e\u9a71\u52a8\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u6df1\u5ea6\u5b66\u4e60\u3001\u56fe\u8868\u793a\u548c\u5206\u7c7b\u6982\u7387\u63a8\u65ad\uff0c\u5e76\u5229\u7528\u65f6\u95f4\u5e8f\u5217\u536b\u661f\u6570\u636e\u548c\u5148\u9a8c\u4e13\u5bb6\u77e5\u8bc6\u7cfb\u7edf\u6765\u6a21\u62df\u7269\u7406\u8106\u5f31\u6027\u3002\u5f15\u5165\u4e86\u5f31\u76d1\u7763\u4e00\u9636\u8f6c\u79fb\u77e9\u9635\uff0c\u4ee5\u53cd\u6620\u4e24\u4e2a\u53d7\u707e\u5730\u533a\uff08\u5b5f\u52a0\u62c9\u56fd\u53d7\u6c14\u65cb\u5f71\u54cd\u7684\u6cbf\u6d77Khurushkul\u793e\u533a\u548c\u585e\u62c9\u5229\u6602\u53d7\u5c71\u4f53\u6ed1\u5761\u5f71\u54cd\u7684\u5f17\u91cc\u6566\u5e02\uff09\u7269\u7406\u8106\u5f31\u6027\u7684\u65f6\u7a7a\u5206\u5e03\u53d8\u5316\u3002", "result": "\u7814\u7a76\u63ed\u793a\u4e86\u707e\u540e\u533a\u57df\u7269\u7406\u8106\u5f31\u6027\u7684\u52a8\u6001\u53d8\u5316\uff0c\u5e76\u4e3a\u533a\u57df\u6027\u65f6\u7a7a\u5ba1\u8ba1\u548c\u53ef\u6301\u7eed\u7684\u707e\u540e\u51cf\u707e\u7b56\u7565\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684GraphCSVAE\u6846\u67b6\u80fd\u591f\u6709\u6548\u5730\u6a21\u62df\u707e\u540e\u7269\u7406\u8106\u5f31\u6027\u7684\u65f6\u7a7a\u52a8\u6001\uff0c\u4e3a\u707e\u540e\u98ce\u9669\u8bc4\u4f30\u548c\u51cf\u707e\u7b56\u7565\u63d0\u4f9b\u652f\u6301\u3002"}}
{"id": "2509.10140", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.10140", "abs": "https://arxiv.org/abs/2509.10140", "authors": ["Yifan Chang", "Jie Qin", "Limeng Qiao", "Xiaofeng Wang", "Zheng Zhu", "Lin Ma", "Xingang Wang"], "title": "Scalable Training for Vector-Quantized Networks with 100% Codebook Utilization", "comment": null, "summary": "Vector quantization (VQ) is a key component in discrete tokenizers for image\ngeneration, but its training is often unstable due to straight-through\nestimation bias, one-step-behind updates, and sparse codebook gradients, which\nlead to suboptimal reconstruction performance and low codebook usage. In this\nwork, we analyze these fundamental challenges and provide a simple yet\neffective solution. To maintain high codebook usage in VQ networks (VQN) during\nlearning annealing and codebook size expansion, we propose VQBridge, a robust,\nscalable, and efficient projector based on the map function method. VQBridge\noptimizes code vectors through a compress-process-recover pipeline, enabling\nstable and effective codebook training. By combining VQBridge with learning\nannealing, our VQN achieves full (100%) codebook usage across diverse codebook\nconfigurations, which we refer to as FVQ (FullVQ). Through extensive\nexperiments, we demonstrate that FVQ is effective, scalable, and generalizable:\nit attains 100% codebook usage even with a 262k-codebook, achieves\nstate-of-the-art reconstruction performance, consistently improves with larger\ncodebooks, higher vector channels, or longer training, and remains effective\nacross different VQ variants. Moreover, when integrated with LlamaGen, FVQ\nsignificantly enhances image generation performance, surpassing visual\nautoregressive models (VAR) by 0.5 and diffusion models (DiT) by 0.2 rFID,\nhighlighting the importance of high-quality tokenizers for strong\nautoregressive image generation.", "AI": {"tldr": "VQBridge\u901a\u8fc7compress-process-recover\u7ba1\u9053\u4f18\u5316\u7801\u5411\u91cf\uff0c\u5b9e\u73b0\u4e86FVQ\uff08FullVQ\uff09\uff0c\u5728\u56fe\u50cf\u751f\u6210\u4e2d\u8fbe\u5230100%\u7801\u672c\u4f7f\u7528\u7387\u548c\u6700\u5148\u8fdb\u7684\u91cd\u5efa\u6027\u80fd\uff0c\u5e76\u663e\u8457\u63d0\u5347\u4e86\u4e0eLlamaGen\u7684\u7ed3\u5408\u6548\u679c\u3002", "motivation": "VQ\u8bad\u7ec3\u4e0d\u7a33\u5b9a\uff0c\u5bfc\u81f4\u91cd\u5efa\u6027\u80fd\u4e0d\u4f73\u548c\u7801\u672c\u4f7f\u7528\u7387\u4f4e\u3002", "method": "\u63d0\u51faVQBridge\uff0c\u4e00\u4e2a\u57fa\u4e8emap\u51fd\u6570\u6cd5\u7684\u6295\u5f71\u5668\uff0c\u901a\u8fc7compress-process-recover\u7ba1\u9053\u4f18\u5316\u7801\u5411\u91cf\uff0c\u5e76\u4e0e\u5b66\u4e60\u9000\u706b\u7ed3\u5408\uff0c\u5b9e\u73b0FVQ\u3002", "result": "FVQ\u5728\u4e0d\u540c\u7801\u672c\u914d\u7f6e\u4e0b\u5b9e\u73b0100%\u7801\u672c\u4f7f\u7528\u7387\uff0c\u5305\u62ec262k\u7801\u672c\uff1b\u5728\u91cd\u5efa\u6027\u80fd\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\uff1b\u5728\u4e0eLlamaGen\u7ed3\u5408\u65f6\uff0crFID\u6bd4VAR\u548cDiT\u5206\u522b\u63d0\u53470.5\u548c0.2\u3002", "conclusion": "FVQ\u662f\u4e00\u79cd\u6709\u6548\u3001\u53ef\u6269\u5c55\u4e14\u901a\u7528\u7684\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86VQ\u8bad\u7ec3\u4e2d\u7684\u6311\u6218\uff0c\u63d0\u9ad8\u4e86\u56fe\u50cf\u751f\u6210\u8d28\u91cf\uff0c\u5e76\u5f3a\u8c03\u4e86\u9ad8\u8d28\u91cf\u5206\u8bcd\u5668\u5728\u81ea\u56de\u5f52\u56fe\u50cf\u751f\u6210\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2509.10129", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2509.10129", "abs": "https://arxiv.org/abs/2509.10129", "authors": ["Alessio Chen", "Simone Giovannini", "Andrea Gemelli", "Fabio Coppini", "Simone Marinai"], "title": "Towards Reliable and Interpretable Document Question Answering via VLMs", "comment": null, "summary": "Vision-Language Models (VLMs) have shown strong capabilities in document\nunderstanding, particularly in identifying and extracting textual information\nfrom complex documents. Despite this, accurately localizing answers within\ndocuments remains a major challenge, limiting both interpretability and\nreal-world applicability. To address this, we introduce\n\\textit{DocExplainerV0}, a plug-and-play bounding-box prediction module that\ndecouples answer generation from spatial localization. This design makes it\napplicable to existing VLMs, including proprietary systems where fine-tuning is\nnot feasible. Through systematic evaluation, we provide quantitative insights\ninto the gap between textual accuracy and spatial grounding, showing that\ncorrect answers often lack reliable localization. Our standardized framework\nhighlights these shortcomings and establishes a benchmark for future research\ntoward more interpretable and robust document information extraction VLMs.", "AI": {"tldr": "DocExplainerV0\u662f\u4e00\u4e2a\u5373\u63d2\u5373\u7528\u7684\u8fb9\u754c\u6846\u9884\u6d4b\u6a21\u5757\uff0c\u53ef\u5c06\u7b54\u6848\u751f\u6210\u4e0e\u7a7a\u95f4\u5b9a\u4f4d\u5206\u79bb\u5f00\u6765\uff0c\u4ee5\u63d0\u9ad8\u6587\u6863\u7406\u89e3\u4e2d\u7b54\u6848\u5b9a\u4f4d\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u5728\u6587\u6863\u7406\u89e3\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u51c6\u786e\u5b9a\u4f4d\u7b54\u6848\u65b9\u9762\u4ecd\u5b58\u5728\u6311\u6218\uff0c\u8fd9\u9650\u5236\u4e86\u5b83\u4eec\u7684\u53ef\u89e3\u91ca\u6027\u548c\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u63d0\u51faDocExplainerV0\uff0c\u4e00\u4e2a\u5373\u63d2\u5373\u7528\u7684\u8fb9\u754c\u6846\u9884\u6d4b\u6a21\u5757\uff0c\u5c06\u7b54\u6848\u751f\u6210\u4e0e\u7a7a\u95f4\u5b9a\u4f4d\u89e3\u8026\uff0c\u4f7f\u5176\u80fd\u591f\u5e94\u7528\u4e8e\u73b0\u6709VLM\uff0c\u5373\u4f7f\u5728\u65e0\u6cd5\u8fdb\u884c\u5fae\u8c03\u7684\u4e13\u6709\u7cfb\u7edf\u4e2d\u4e5f\u662f\u5982\u6b64\u3002", "result": "\u901a\u8fc7\u7cfb\u7edf\u8bc4\u4f30\uff0c\u63d0\u4f9b\u4e86\u6587\u672c\u51c6\u786e\u6027\u548c\u7a7a\u95f4\u5b9a\u4f4d\u4e4b\u95f4\u5dee\u8ddd\u7684\u91cf\u5316\u89c1\u89e3\uff0c\u8868\u660e\u6b63\u786e\u7684\u7b54\u6848\u901a\u5e38\u7f3a\u4e4f\u53ef\u9760\u7684\u5b9a\u4f4d\u3002\u8fd8\u5efa\u7acb\u4e86\u4e00\u4e2a\u57fa\u51c6\uff0c\u7528\u4e8e\u672a\u6765\u5bf9\u66f4\u5177\u53ef\u89e3\u91ca\u6027\u548c\u9c81\u68d2\u6027\u7684\u6587\u6863\u4fe1\u606f\u63d0\u53d6VLM\u7684\u7814\u7a76\u3002", "conclusion": "DocExplainerV0\u901a\u8fc7\u5c06\u7b54\u6848\u751f\u6210\u4e0e\u7a7a\u95f4\u5b9a\u4f4d\u5206\u79bb\u5f00\u6765\uff0c\u89e3\u51b3\u4e86\u73b0\u6709VLM\u5728\u6587\u6863\u7b54\u6848\u5b9a\u4f4d\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u5e76\u4e3a\u672a\u6765\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6807\u51c6\u5316\u7684\u6846\u67b6\u3002"}}
{"id": "2509.10324", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10324", "abs": "https://arxiv.org/abs/2509.10324", "authors": ["Myung Jin Kim", "YeongHyeon Park", "Il Dong Yun"], "title": "ARMA Block: A CNN-Based Autoregressive and Moving Average Module for Long-Term Time Series Forecasting", "comment": null, "summary": "This paper proposes a simple yet effective convolutional module for long-term\ntime series forecasting. The proposed block, inspired by the Auto-Regressive\nIntegrated Moving Average (ARIMA) model, consists of two convolutional\ncomponents: one for capturing the trend (autoregression) and the other for\nrefining local variations (moving average). Unlike conventional ARIMA, which\nrequires iterative multi-step forecasting, the block directly performs\nmulti-step forecasting, making it easily extendable to multivariate settings.\nExperiments on nine widely used benchmark datasets demonstrate that our method\nARMA achieves competitive accuracy, particularly on datasets exhibiting strong\ntrend variations, while maintaining architectural simplicity. Furthermore,\nanalysis shows that the block inherently encodes absolute positional\ninformation, suggesting its potential as a lightweight replacement for\npositional embeddings in sequential models.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u5377\u79ef\u6a21\u5757\u7528\u4e8e\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff0c\u8be5\u6a21\u5757\u53d7ARIMA\u6a21\u578b\u542f\u53d1\uff0c\u5305\u542b\u6355\u6349\u8d8b\u52bf\uff08\u81ea\u56de\u5f52\uff09\u548c\u4f18\u5316\u5c40\u90e8\u53d8\u5316\uff08\u79fb\u52a8\u5e73\u5747\uff09\u7684\u4e24\u4e2a\u5377\u79ef\u7ec4\u4ef6\uff0c\u53ef\u4ee5\u76f4\u63a5\u8fdb\u884c\u591a\u6b65\u9884\u6d4b\uff0c\u5e76\u6613\u4e8e\u6269\u5c55\u5230\u591a\u5143\u8bbe\u7f6e\uff0c\u5728\u4e5d\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5ARMA\u5177\u6709\u7ade\u4e89\u529b\uff0c\u5c24\u5176\u662f\u5728\u5177\u6709\u5f3a\u8d8b\u52bf\u53d8\u5316\u7684\u6570\u636e\u96c6\u4e0a\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u7ed3\u6784\u7b80\u5355\u6027\uff0c\u5e76\u4e14\u8be5\u6a21\u5757\u5185\u5728\u5730\u7f16\u7801\u4e86\u7edd\u5bf9\u4f4d\u7f6e\u4fe1\u606f\uff0c\u53ef\u4f5c\u4e3a\u5e8f\u5217\u6a21\u578b\u7684\u8f7b\u91cf\u7ea7\u4f4d\u7f6e\u5d4c\u5165\u66ff\u4ee3\u54c1\u3002", "motivation": "\u65e8\u5728\u63d0\u51fa\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u5377\u79ef\u6a21\u5757\u7528\u4e8e\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff0c\u5e76\u89e3\u51b3\u4f20\u7edfARIMA\u6a21\u578b\u9700\u8981\u8fed\u4ee3\u8fdb\u884c\u591a\u6b65\u9884\u6d4b\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53d7ARIMA\u542f\u53d1\u7684\u5377\u79ef\u6a21\u5757\uff0c\u5305\u542b\u4e24\u4e2a\u5377\u79ef\u7ec4\u4ef6\uff1a\u4e00\u4e2a\u7528\u4e8e\u6355\u6349\u8d8b\u52bf\uff08\u81ea\u56de\u5f52\uff09\uff0c\u53e6\u4e00\u4e2a\u7528\u4e8e\u4f18\u5316\u5c40\u90e8\u53d8\u5316\uff08\u79fb\u52a8\u5e73\u5747\uff09\u3002\u8be5\u6a21\u5757\u53ef\u4ee5\u76f4\u63a5\u8fdb\u884c\u591a\u6b65\u9884\u6d4b\uff0c\u5e76\u6613\u4e8e\u6269\u5c55\u5230\u591a\u5143\u8bbe\u7f6e\u3002", "result": "\u5728\u4e5d\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5ARMA\u5177\u6709\u7ade\u4e89\u529b\uff0c\u5c24\u5176\u662f\u5728\u5177\u6709\u5f3a\u8d8b\u52bf\u53d8\u5316\u7684\u6570\u636e\u96c6\u4e0a\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u7ed3\u6784\u7b80\u5355\u6027\u3002\u5206\u6790\u8868\u660e\uff0c\u8be5\u6a21\u5757\u5185\u5728\u5730\u7f16\u7801\u4e86\u7edd\u5bf9\u4f4d\u7f6e\u4fe1\u606f\uff0c\u53ef\u4f5c\u4e3a\u5e8f\u5217\u6a21\u578b\u7684\u8f7b\u91cf\u7ea7\u4f4d\u7f6e\u5d4c\u5165\u66ff\u4ee3\u54c1\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u7684\u5377\u79ef\u6a21\u5757\u7b80\u5355\u6709\u6548\uff0c\u80fd\u591f\u76f4\u63a5\u8fdb\u884c\u591a\u6b65\u9884\u6d4b\uff0c\u9002\u7528\u4e8e\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff0c\u5e76\u4e14\u5177\u6709\u4f5c\u4e3a\u5e8f\u5217\u6a21\u578b\u8f7b\u91cf\u7ea7\u4f4d\u7f6e\u5d4c\u5165\u66ff\u4ee3\u54c1\u7684\u6f5c\u529b\u3002"}}
{"id": "2509.10156", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.10156", "abs": "https://arxiv.org/abs/2509.10156", "authors": ["Goker Erdogan", "Nikhil Parthasarathy", "Catalin Ionescu", "Drew Hudson", "Alexander Lerchner", "Andrew Zisserman", "Mehdi Sajjadi", "Joao Carreira"], "title": "LayerLock: Non-collapsing Representation Learning with Progressive Freezing", "comment": "ICCV 2025", "summary": "We introduce LayerLock, a simple yet effective approach for self-supervised\nvisual representation learning, that gradually transitions from pixel to latent\nprediction through progressive layer freezing. First, we make the observation\nthat during training of video masked-autoencoding (MAE) models, ViT layers\nconverge in the order of their depth: shallower layers converge early, deeper\nlayers converge late. We then show that this observation can be exploited to\naccelerate standard MAE by progressively freezing the model according to an\nexplicit schedule, throughout training. Furthermore, this same schedule can be\nused in a simple and scalable approach to latent prediction that does not\nsuffer from \"representation collapse\". We apply our proposed approach,\nLayerLock, to large models of up to 4B parameters with results surpassing those\nof non-latent masked prediction on the 4DS perception suite.", "AI": {"tldr": "LayerLock\u901a\u8fc7\u9010\u6b65\u51bb\u7ed3\u6a21\u578b\u5c42\u6765\u52a0\u901f\u81ea\u76d1\u7763\u89c6\u89c9\u8868\u793a\u5b66\u4e60\uff0c\u5e76\u5b9e\u73b0\u6709\u6548\u7684\u6f5c\u5728\u7a7a\u95f4\u9884\u6d4b\uff0c\u5728\u5927\u6a21\u578b\u4e0a\u53d6\u5f97\u4e86\u4f18\u4e8e\u975e\u6f5c\u5728\u63a9\u7801\u9884\u6d4b\u7684\u6548\u679c\u3002", "motivation": "\u5728\u89c6\u9891\u63a9\u7801\u81ea\u7f16\u7801\uff08MAE\uff09\u6a21\u578b\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0cViT\u5c42\u6309\u6df1\u5ea6\u987a\u5e8f\u6536\u655b\uff1a\u6d45\u5c42\u65e9\u6536\u655b\uff0c\u6df1\u5c42\u665a\u6536\u655b\u3002\u8fd9\u79cd\u73b0\u8c61\u53ef\u4ee5\u88ab\u5229\u7528\u6765\u52a0\u901fMAE\u7684\u8bad\u7ec3\u3002", "method": "LayerLock\u63d0\u51fa\u4e86\u4e00\u79cd\u9010\u6b65\u51bb\u7ed3\u6a21\u578b\u5c42\u7684\u65b9\u6cd5\uff0c\u5e76\u6839\u636e\u663e\u5f0f\u7684\u65f6\u95f4\u8868\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u8fdb\u884c\u3002\u8fd9\u79cd\u65b9\u6cd5\u65e2\u53ef\u4ee5\u52a0\u901f\u6807\u51c6\u7684MAE\u8bad\u7ec3\uff0c\u4e5f\u53ef\u4ee5\u7528\u4e8e\u6f5c\u5728\u7a7a\u95f4\u9884\u6d4b\uff0c\u89e3\u51b3\u4e86\u201c\u8868\u793a\u574d\u584c\u201d\u95ee\u9898\u3002", "result": "\u5c06LayerLock\u5e94\u7528\u4e8e\u53c2\u6570\u91cf\u9ad8\u8fbe40\u4ebf\u7684\u5927\u6a21\u578b\uff0c\u57284DS\u611f\u77e5\u5957\u4ef6\u4e0a\u7684\u8868\u73b0\u8d85\u8d8a\u4e86\u975e\u6f5c\u5728\u63a9\u7801\u9884\u6d4b\u65b9\u6cd5\u3002", "conclusion": "LayerLock\u662f\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6e10\u8fdb\u5f0f\u5c42\u51bb\u7ed3\uff0c\u5b9e\u73b0\u4e86\u4ece\u50cf\u7d20\u5230\u6f5c\u5728\u9884\u6d4b\u7684\u8fc7\u6e21\uff0c\u5728\u5927\u89c4\u6a21\u6a21\u578b\u4e0a\u53d6\u5f97\u4e86\u4f18\u8d8a\u7684\u6027\u80fd\u3002"}}
{"id": "2509.10179", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10179", "abs": "https://arxiv.org/abs/2509.10179", "authors": ["Ji\u0159\u00ed Mili\u010dka", "Anna Marklov\u00e1", "V\u00e1clav Cvr\u010dek"], "title": "Benchmark of stylistic variation in LLM-generated texts", "comment": null, "summary": "This study investigates the register variation in texts written by humans and\ncomparable texts produced by large language models (LLMs). Biber's\nmultidimensional analysis (MDA) is applied to a sample of human-written texts\nand AI-created texts generated to be their counterparts to find the dimensions\nof variation in which LLMs differ most significantly and most systematically\nfrom humans. As textual material, a new LLM-generated corpus AI-Brown is used,\nwhich is comparable to BE-21 (a Brown family corpus representing contemporary\nBritish English). Since all languages except English are underrepresented in\nthe training data of frontier LLMs, similar analysis is replicated on Czech\nusing AI-Koditex corpus and Czech multidimensional model. Examined were 16\nfrontier models in various settings and prompts, with emphasis placed on the\ndifference between base models and instruction-tuned models. Based on this, a\nbenchmark is created through which models can be compared with each other and\nranked in interpretable dimensions.", "AI": {"tldr": "\u672c\u7814\u7a76\u5bf9\u6bd4\u4e86\u4eba\u7c7b\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u6587\u672c\u8bed\u57df\u4e0a\u7684\u5dee\u5f02\uff0c\u5e76\u4e3aLLM\u521b\u5efa\u4e86\u4e00\u4e2a\u57fa\u51c6\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u4e86\u89e3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u751f\u6210\u6587\u672c\u65f6\u5728\u591a\u5927\u7a0b\u5ea6\u4e0a\u6a21\u4eff\u6216\u504f\u79bb\u4eba\u7c7b\u7684\u5199\u4f5c\u98ce\u683c\uff0c\u7279\u522b\u662f\u8bed\u57df\u7684\u53d8\u5316\uff0c\u5e76\u627e\u51faLLM\u4e0e\u4eba\u7c7b\u5728\u54ea\u4e9b\u65b9\u9762\u5b58\u5728\u663e\u8457\u4e14\u7cfb\u7edf\u6027\u7684\u5dee\u5f02\u3002", "method": "\u4f7f\u7528Biber\u7684\u591a\u7ef4\u5ea6\u5206\u6790\uff08MDA\uff09\u65b9\u6cd5\uff0c\u5bf9\u4eba\u7c7b\u7f16\u5199\u7684\u6587\u672c\u548cAI\u751f\u6210\u7684\u5bf9\u5e94\u6587\u672c\uff08AI-Brown\u8bed\u6599\u5e93\uff09\u8fdb\u884c\u5206\u6790\u3002\u540c\u65f6\uff0c\u5728\u6377\u514b\u8bed\uff08AI-Koditex\u8bed\u6599\u5e93\u548c\u6377\u514b\u591a\u7ef4\u5ea6\u6a21\u578b\uff09\u4e0a\u4e5f\u8fdb\u884c\u4e86\u7c7b\u4f3c\u5206\u6790\u3002\u7814\u7a76\u8003\u5bdf\u4e8616\u79cd\u524d\u6cbf\u6a21\u578b\uff0c\u5e76\u7279\u522b\u5173\u6ce8\u4e86\u57fa\u7840\u6a21\u578b\u548c\u6307\u4ee4\u8c03\u4f18\u6a21\u578b\u4e4b\u95f4\u7684\u533a\u522b\u3002\u6700\u540e\uff0c\u521b\u5efa\u4e86\u4e00\u4e2a\u57fa\u51c6\u6765\u6bd4\u8f83\u548c\u8bc4\u4f30\u6a21\u578b\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0cLLM\u5728\u67d0\u4e9b\u8bed\u57df\u7ef4\u5ea6\u4e0a\u4e0e\u4eba\u7c7b\u5199\u4f5c\u5b58\u5728\u5dee\u5f02\u3002\u901a\u8fc7\u5206\u6790AI-Brown\u548cAI-Koditex\u8bed\u6599\u5e93\uff0c\u5e76\u6bd4\u8f83\u4e0d\u540c\u6a21\u578b\uff08\u57fa\u7840\u6a21\u578b\u548c\u6307\u4ee4\u8c03\u4f18\u6a21\u578b\uff09\uff0c\u7814\u7a76\u4e3aLLM\u7684\u8bed\u57df\u8868\u73b0\u63d0\u4f9b\u4e86\u91cf\u5316\u6570\u636e\u3002", "conclusion": "\u672c\u7814\u7a76\u901a\u8fc7\u591a\u7ef4\u5ea6\u5206\u6790\uff0c\u63ed\u793a\u4e86LLM\u5728\u8bed\u57df\u8868\u8fbe\u4e0a\u4e0e\u4eba\u7c7b\u7684\u5dee\u5f02\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u53ef\u7528\u4e8e\u8bc4\u4f30\u548c\u6bd4\u8f83LLM\u7684\u57fa\u51c6\u3002"}}
{"id": "2509.10241", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.10241", "abs": "https://arxiv.org/abs/2509.10241", "authors": ["Elias De Smijter", "Renaud Detry", "Christophe De Vleeschouwer"], "title": "On the Geometric Accuracy of Implicit and Primitive-based Representations Derived from View Rendering Constraints", "comment": "9 pages, 3 figures, to be presented at ASTRA25,", "summary": "We present the first systematic comparison of implicit and explicit Novel\nView Synthesis methods for space-based 3D object reconstruction, evaluating the\nrole of appearance embeddings. While embeddings improve photometric fidelity by\nmodeling lighting variation, we show they do not translate into meaningful\ngains in geometric accuracy - a critical requirement for space robotics\napplications. Using the SPEED+ dataset, we compare K-Planes, Gaussian\nSplatting, and Convex Splatting, and demonstrate that embeddings primarily\nreduce the number of primitives needed for explicit methods rather than\nenhancing geometric fidelity. Moreover, convex splatting achieves more compact\nand clutter-free representations than Gaussian splatting, offering advantages\nfor safety-critical applications such as interaction and collision avoidance.\nOur findings clarify the limits of appearance embeddings for geometry-centric\ntasks and highlight trade-offs between reconstruction quality and\nrepresentation efficiency in space scenarios.", "AI": {"tldr": "\u9690\u5f0f\u548c\u663e\u5f0f\u65b0\u89c6\u89d2\u5408\u6210\u65b9\u6cd5\u5728\u57fa\u4e8e\u7a7a\u95f4\u76843D\u7269\u4f53\u91cd\u5efa\u4e2d\u7684\u6bd4\u8f83\uff0c\u8bc4\u4f30\u4e86\u5916\u89c2\u5d4c\u5165\u7684\u4f5c\u7528\u3002", "motivation": "\u8bc4\u4f30\u5916\u89c2\u5d4c\u5165\u5728\u7a7a\u95f43D\u7269\u4f53\u91cd\u5efa\u4e2d\u5bf9\u51e0\u4f55\u7cbe\u5ea6\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528SPEED+\u6570\u636e\u96c6\uff0c\u6bd4\u8f83\u4e86K-Planes\u3001Gaussian Splatting\u548cConvex Splatting\uff0c\u5e76\u5206\u6790\u4e86\u5916\u89c2\u5d4c\u5165\u5bf9\u51e0\u4f55\u4fdd\u771f\u5ea6\u548c\u8868\u793a\u6548\u7387\u7684\u5f71\u54cd\u3002", "result": "\u5916\u89c2\u5d4c\u5165\u4e3b\u8981\u51cf\u5c11\u4e86\u663e\u5f0f\u65b9\u6cd5\u6240\u9700\u7684\u57fa\u5143\u6570\u91cf\uff0c\u4f46\u5e76\u672a\u663e\u8457\u63d0\u9ad8\u51e0\u4f55\u7cbe\u5ea6\u3002Convex Splatting\u6bd4Gaussian Splatting\u80fd\u63d0\u4f9b\u66f4\u7d27\u51d1\u3001\u66f4\u65e0\u5e72\u6270\u7684\u8868\u793a\u3002", "conclusion": "\u5916\u89c2\u5d4c\u5165\u5bf9\u51e0\u4f55\u4e2d\u5fc3\u4efb\u52a1\u7684\u51e0\u4f55\u7cbe\u5ea6\u63d0\u5347\u6709\u9650\uff0c\u4f46\u6709\u52a9\u4e8e\u63d0\u9ad8\u8868\u793a\u6548\u7387\u3002Convex Splatting\u5728\u7a7a\u95f4\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\u5177\u6709\u4f18\u52bf\u3002"}}
{"id": "2509.10184", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.10184", "abs": "https://arxiv.org/abs/2509.10184", "authors": ["Leen Almajed", "Abeer ALdayel"], "title": "Incongruent Positivity: When Miscalibrated Positivity Undermines Online Supportive Conversations", "comment": "This paper is under review", "summary": "In emotionally supportive conversations, well-intended positivity can\nsometimes misfire, leading to responses that feel dismissive, minimizing, or\nunrealistically optimistic. We examine this phenomenon of incongruent\npositivity as miscalibrated expressions of positive support in both human and\nLLM generated responses. To this end, we collected real user-assistant\ndialogues from Reddit across a range of emotional intensities and generated\nadditional responses using large language models for the same context. We\ncategorize these conversations by intensity into two levels: Mild, which covers\nrelationship tension and general advice, and Severe, which covers grief and\nanxiety conversations. This level of categorization enables a comparative\nanalysis of how supportive responses vary across lower and higher stakes\ncontexts. Our analysis reveals that LLMs are more prone to unrealistic\npositivity through dismissive and minimizing tone, particularly in high-stakes\ncontexts. To further study the underlying dimensions of this phenomenon, we\nfinetune LLMs on datasets with strong and weak emotional reactions. Moreover,\nwe developed a weakly supervised multilabel classifier ensemble (DeBERTa and\nMentalBERT) that shows improved detection of incongruent positivity types\nacross two sorts of concerns (Mild and Severe). Our findings shed light on the\nneed to move beyond merely generating generic positive responses and instead\nstudy the congruent support measures to balance positive affect with emotional\nacknowledgment. This approach offers insights into aligning large language\nmodels with affective expectations in the online supportive dialogue, paving\nthe way toward context-aware and trust preserving online conversation systems.", "AI": {"tldr": "LLMs\u5728\u63d0\u4f9b\u60c5\u611f\u652f\u6301\u65f6\u503e\u5411\u4e8e\u4e0d\u6070\u5f53\u7684\u79ef\u6781\u6027\uff0c\u5c24\u5176\u662f\u5728\u9ad8\u98ce\u9669\u60c5\u5883\u4e0b\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u56de\u5e94\u88ab\u89c6\u4e3a\u8f7b\u89c6\u6216\u4e0d\u5207\u5b9e\u9645\u3002\u901a\u8fc7\u5206\u6790\u4eba\u7c7b\u548cLLM\u7684\u5bf9\u8bdd\uff0c\u5e76\u5fae\u8c03\u6a21\u578b\uff0c\u6211\u4eec\u5f00\u53d1\u4e86\u4e00\u4e2a\u5206\u7c7b\u5668\u6765\u68c0\u6d4b\u8fd9\u79cd\u4e0d\u534f\u8c03\u7684\u79ef\u6781\u6027\uff0c\u5f3a\u8c03\u9700\u8981\u751f\u6210\u4e0e\u60c5\u611f\u5f3a\u5ea6\u76f8\u5339\u914d\u7684\u3001\u6070\u5f53\u7684\u79ef\u6781\u56de\u5e94\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u5206\u6790\u548c\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u63d0\u4f9b\u60c5\u611f\u652f\u6301\u65f6\u51fa\u73b0\u7684\u201c\u4e0d\u534f\u8c03\u7684\u79ef\u6781\u6027\u201d\u73b0\u8c61\uff0c\u5373\u79ef\u6781\u7684\u56de\u5e94\u672a\u80fd\u6070\u5f53\u5339\u914d\u5bf9\u8bdd\u7684\u60c5\u611f\u80cc\u666f\uff0c\u5bfc\u81f4\u88ab\u89c6\u4e3a\u8f7b\u89c6\u3001\u6700\u5c0f\u5316\u6216\u4e0d\u5207\u5b9e\u9645\u7684\u4e50\u89c2\u3002\u7814\u7a76\u7684\u52a8\u673a\u5728\u4e8e\u63d0\u9ad8LLM\u5728\u652f\u6301\u6027\u5bf9\u8bdd\u4e2d\u7684\u6709\u6548\u6027\u548c\u53ef\u9760\u6027\uff0c\u4f7f\u5176\u80fd\u591f\u63d0\u4f9b\u771f\u6b63\u6709\u76ca\u4e14\u7b26\u5408\u7528\u6237\u671f\u671b\u7684\u60c5\u611f\u652f\u6301\u3002", "method": "\u7814\u7a76\u65b9\u6cd5\u5305\u62ec\uff1a1. \u6536\u96c6Reddit\u4e0a\u771f\u5b9e\u7528\u6237\u4e0e\u52a9\u624b\u7684\u5bf9\u8bdd\u6570\u636e\uff0c\u5e76\u6309\u60c5\u611f\u5f3a\u5ea6\u5206\u4e3a\u201c\u8f7b\u5ea6\u201d\uff08\u5982\u5173\u7cfb\u7d27\u5f20\u3001\u4e00\u822c\u5efa\u8bae\uff09\u548c\u201c\u4e25\u91cd\u201d\uff08\u5982\u60b2\u4f24\u3001\u7126\u8651\uff09\u4e24\u7c7b\u30022. \u4f7f\u7528LLM\u4e3a\u76f8\u540c\u8bed\u5883\u751f\u6210\u56de\u5e94\uff0c\u5e76\u8fdb\u884c\u6bd4\u8f83\u5206\u6790\u30023. \u5fae\u8c03LLM\u5728\u5177\u6709\u5f3a\u70c8\u548c\u8f83\u5f31\u60c5\u611f\u53cd\u5e94\u7684\u6570\u636e\u96c6\u4e0a\uff0c\u4ee5\u7814\u7a76\u4e0d\u534f\u8c03\u79ef\u6781\u6027\u80cc\u540e\u7684\u7ef4\u5ea6\u30024. \u5f00\u53d1\u4e00\u4e2a\u5f31\u76d1\u7763\u7684\u591a\u6807\u7b7e\u5206\u7c7b\u5668\u96c6\u6210\uff08\u7ed3\u5408DeBERTa\u548cMentalBERT\uff09\uff0c\u7528\u4e8e\u68c0\u6d4b\u4e0d\u540c\u7c7b\u578b\u548c\u4e0d\u540c\u60c5\u611f\u5f3a\u5ea6\uff08\u8f7b\u5ea6\u3001\u4e25\u91cd\uff09\u4e0b\u7684\u4e0d\u534f\u8c03\u79ef\u6781\u6027\u3002", "result": "\u5206\u6790\u663e\u793a\uff0cLLM\u6bd4\u4eba\u7c7b\u66f4\u5bb9\u6613\u8868\u73b0\u51fa\u4e0d\u5207\u5b9e\u9645\u7684\u79ef\u6781\u6027\uff0c\u5c24\u5176\u662f\u5728\u9ad8\u98ce\u9669\uff08\u4e25\u91cd\uff09\u60c5\u5883\u4e0b\uff0c\u5176\u56de\u5e94\u53ef\u80fd\u5e26\u6709\u8f7b\u89c6\u548c\u6700\u5c0f\u5316\u7684\u8bed\u8c03\u3002\u5206\u7c7b\u5668\u96c6\u6210\u5728\u68c0\u6d4b\u4e0d\u534f\u8c03\u79ef\u6781\u6027\u7684\u4e0d\u540c\u7c7b\u578b\u65b9\u9762\u8868\u73b0\u51fa\u6539\u8fdb\u3002\u7814\u7a76\u8bc1\u5b9e\u4e86LLM\u5728\u9ad8\u98ce\u9669\u60c5\u611f\u5bf9\u8bdd\u4e2d\u5b58\u5728\u4e0d\u534f\u8c03\u79ef\u6781\u6027\u7684\u95ee\u9898\u3002", "conclusion": "\u7814\u7a76\u7ed3\u8bba\u6307\u51fa\uff0c\u4e3a\u4e86\u63d0\u4f9b\u771f\u6b63\u7684\u60c5\u611f\u652f\u6301\uff0cLLM\u9700\u8981\u8d85\u8d8a\u751f\u6210\u901a\u7528\u7684\u79ef\u6781\u56de\u5e94\uff0c\u8f6c\u800c\u5173\u6ce8\u201c\u534f\u8c03\u7684\u201d\u652f\u6301\u63aa\u65bd\uff0c\u5e73\u8861\u79ef\u6781\u60c5\u611f\u4e0e\u60c5\u611f\u627f\u8ba4\u3002\u8fd9\u5bf9\u4e8e\u4f7fLLM\u4e0e\u5728\u7ebf\u652f\u6301\u5bf9\u8bdd\u4e2d\u7684\u60c5\u611f\u671f\u671b\u4fdd\u6301\u4e00\u81f4\u81f3\u5173\u91cd\u8981\uff0c\u5e76\u4e3a\u6784\u5efa\u66f4\u5177\u60c5\u5883\u610f\u8bc6\u548c\u503c\u5f97\u4fe1\u8d56\u7684\u5728\u7ebf\u5bf9\u8bdd\u7cfb\u7edf\u94fa\u5e73\u4e86\u9053\u8def\u3002Simply put, we need to make AI's positive responses more context-aware and emotionally appropriate, especially in serious situations."}}
{"id": "2509.10367", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10367", "abs": "https://arxiv.org/abs/2509.10367", "authors": ["Tong Chen", "Raghavendra Selvan"], "title": "A Discrepancy-Based Perspective on Dataset Condensation", "comment": "30 pages, 4 tables, 1 figure", "summary": "Given a dataset of finitely many elements $\\mathcal{T} = \\{\\mathbf{x}_i\\}_{i\n= 1}^N$, the goal of dataset condensation (DC) is to construct a synthetic\ndataset $\\mathcal{S} = \\{\\tilde{\\mathbf{x}}_j\\}_{j = 1}^M$ which is\nsignificantly smaller ($M \\ll N$) such that a model trained from scratch on\n$\\mathcal{S}$ achieves comparable or even superior generalization performance\nto a model trained on $\\mathcal{T}$. Recent advances in DC reveal a close\nconnection to the problem of approximating the data distribution represented by\n$\\mathcal{T}$ with a reduced set of points. In this work, we present a unified\nframework that encompasses existing DC methods and extend the task-specific\nnotion of DC to a more general and formal definition using notions of\ndiscrepancy, which quantify the distance between probability distribution in\ndifferent regimes. Our framework broadens the objective of DC beyond\ngeneralization, accommodating additional objectives such as robustness,\nprivacy, and other desirable properties.", "AI": {"tldr": "dataset condensation (DC) aims to create a small synthetic dataset that mimics a larger one for training models, with recent work connecting it to distribution approximation. This paper unifies existing DC methods and generalizes the task using discrepancy measures, allowing for objectives beyond just generalization, like robustness and privacy.", "motivation": "The goal is to construct a significantly smaller synthetic dataset that allows a model trained from scratch on it to achieve comparable or superior generalization performance to a model trained on the original, larger dataset. Recent advances connect DC to data distribution approximation.", "method": "The paper presents a unified framework that encompasses existing DC methods and extends the task-specific notion of DC to a more general and formal definition using notions of discrepancy, which quantify the distance between probability distributions.", "result": "The framework broadens the objective of DC beyond generalization, accommodating additional objectives such as robustness, privacy, and other desirable properties.", "conclusion": "The presented unified framework generalizes dataset condensation using discrepancy measures, allowing for a broader range of objectives beyond simple performance metrics."}}
{"id": "2509.10250", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.10250", "abs": "https://arxiv.org/abs/2509.10250", "authors": ["Haozhen Yan", "Yan Hong", "Suning Lang", "Jiahui Zhan", "Yikun Ji", "Yujie Gao", "Jun Lan", "Huijia Zhu", "Weiqiang Wang", "Jianfu Zhang"], "title": "GAMMA: Generalizable Alignment via Multi-task and Manipulation-Augmented Training for AI-Generated Image Detection", "comment": "11 pages, 5 figures", "summary": "With generative models becoming increasingly sophisticated and diverse,\ndetecting AI-generated images has become increasingly challenging. While\nexisting AI-genereted Image detectors achieve promising performance on\nin-distribution generated images, their generalization to unseen generative\nmodels remains limited. This limitation is largely attributed to their reliance\non generation-specific artifacts, such as stylistic priors and compression\npatterns. To address these limitations, we propose GAMMA, a novel training\nframework designed to reduce domain bias and enhance semantic alignment. GAMMA\nintroduces diverse manipulation strategies, such as inpainting-based\nmanipulation and semantics-preserving perturbations, to ensure consistency\nbetween manipulated and authentic content. We employ multi-task supervision\nwith dual segmentation heads and a classification head, enabling pixel-level\nsource attribution across diverse generative domains. In addition, a reverse\ncross-attention mechanism is introduced to allow the segmentation heads to\nguide and correct biased representations in the classification branch. Our\nmethod achieves state-of-the-art generalization performance on the GenImage\nbenchmark, imporving accuracy by 5.8%, but also maintains strong robustness on\nnewly released generative model such as GPT-4o.", "AI": {"tldr": "\u68c0\u6d4bAI\u751f\u6210\u56fe\u50cf\u4ecd\u7136\u662f\u4e00\u4e2a\u6311\u6218\uff0c\u5c24\u5176\u662f\u5f53\u751f\u6210\u6a21\u578b\u53d8\u5f97\u8d8a\u6765\u8d8a\u590d\u6742\u548c\u591a\u6837\u5316\u65f6\u3002\u73b0\u6709\u7684\u68c0\u6d4b\u5668\u5728\u5904\u7406\u672a\u89c1\u8fc7\u7684\u751f\u6210\u6a21\u578b\u65f6\u6cdb\u5316\u80fd\u529b\u6709\u9650\uff0c\u56e0\u4e3a\u5b83\u4eec\u4f9d\u8d56\u4e8e\u7279\u5b9a\u4e8e\u751f\u6210\u5668\u7684\u4f2a\u5f71\u3002\u6211\u4eec\u63d0\u51fa\u4e86GAMMA\uff0c\u4e00\u4e2a\u65e8\u5728\u51cf\u5c11\u57df\u504f\u5dee\u548c\u589e\u5f3a\u8bed\u4e49\u5bf9\u9f50\u7684\u65b0\u578b\u8bad\u7ec3\u6846\u67b6\u3002GAMMA\u901a\u8fc7\u5f15\u5165\u591a\u6837\u5316\u7684\u64cd\u4f5c\u7b56\u7565\uff08\u5982\u57fa\u4e8e\u4fee\u590d\u7684\u64cd\u4f5c\u548c\u4fdd\u6301\u8bed\u4e49\u7684\u6270\u52a8\uff09\u6765\u786e\u4fdd\u64cd\u4f5c\u5185\u5bb9\u4e0e\u771f\u5b9e\u5185\u5bb9\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\u3002\u6211\u4eec\u91c7\u7528\u591a\u4efb\u52a1\u76d1\u7763\uff0c\u7ed3\u5408\u4e86\u53cc\u5206\u5272\u5934\u548c\u4e00\u4e2a\u5206\u7c7b\u5934\uff0c\u5b9e\u73b0\u4e86\u8de8\u4e0d\u540c\u751f\u6210\u57df\u7684\u50cf\u7d20\u7ea7\u6765\u6e90\u5f52\u56e0\u3002\u6b64\u5916\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u4e2a\u53cd\u5411\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\uff0c\u4f7f\u5206\u5272\u5934\u80fd\u591f\u6307\u5bfc\u548c\u7ea0\u6b63\u5206\u7c7b\u5206\u652f\u4e2d\u7684\u6709\u504f\u5dee\u7684\u8868\u793a\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u5728GenImage\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6cdb\u5316\u6027\u80fd\uff0c\u51c6\u786e\u7387\u63d0\u9ad8\u4e865.8%\uff0c\u5e76\u4e14\u5728GPT-4o\u7b49\u65b0\u53d1\u5e03\u7684\u751f\u6210\u6a21\u578b\u4e0a\u4fdd\u6301\u4e86\u5f3a\u5927\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u7684AI\u751f\u6210\u56fe\u50cf\u68c0\u6d4b\u5668\u5728\u5904\u7406\u672a\u77e5\u7684\u751f\u6210\u6a21\u578b\u65f6\u6cdb\u5316\u80fd\u529b\u6709\u9650\uff0c\u8fd9\u4e3b\u8981\u662f\u56e0\u4e3a\u5b83\u4eec\u4f9d\u8d56\u4e8e\u751f\u6210\u5668\u7279\u6709\u7684\u4f2a\u5f71\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGAMMA\u7684\u65b0\u578b\u8bad\u7ec3\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u91c7\u7528\u591a\u6837\u5316\u7684\u64cd\u4f5c\u7b56\u7565\uff08\u5982\u57fa\u4e8e\u4fee\u590d\u7684\u64cd\u4f5c\u548c\u4fdd\u6301\u8bed\u4e49\u7684\u6270\u52a8\uff09\u6765\u51cf\u5c11\u57df\u504f\u5dee\u548c\u589e\u5f3a\u8bed\u4e49\u5bf9\u9f50\u3002\u901a\u8fc7\u591a\u4efb\u52a1\u76d1\u7763\uff08\u5305\u62ec\u53cc\u5206\u5272\u5934\u548c\u5206\u7c7b\u5934\uff09\u5b9e\u73b0\u50cf\u7d20\u7ea7\u6765\u6e90\u5f52\u56e0\uff0c\u5e76\u5f15\u5165\u53cd\u5411\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\u6765\u7ea0\u6b63\u5206\u7c7b\u5206\u652f\u4e2d\u7684\u6709\u504f\u5dee\u8868\u793a\u3002", "result": "GAMMA\u5728GenImage\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6cdb\u5316\u6027\u80fd\uff0c\u51c6\u786e\u7387\u63d0\u9ad8\u4e865.8%\uff0c\u5e76\u4e14\u5728GPT-4o\u7b49\u65b0\u53d1\u5e03\u6a21\u578b\u4e0a\u8868\u73b0\u51fa\u826f\u597d\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "GAMMA\u901a\u8fc7\u5f15\u5165\u591a\u6837\u5316\u7684\u64cd\u4f5c\u548c\u521b\u65b0\u7684\u76d1\u7763\u673a\u5236\uff0c\u663e\u8457\u63d0\u9ad8\u4e86AI\u751f\u6210\u56fe\u50cf\u68c0\u6d4b\u5668\u5bf9\u672a\u89c1\u8fc7\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2509.10199", "categories": ["cs.CL", "I.7; I.2; J.4"], "pdf": "https://arxiv.org/pdf/2509.10199", "abs": "https://arxiv.org/abs/2509.10199", "authors": ["Mikl\u00f3s Seb\u0151k", "Viktor Kov\u00e1cs", "Martin B\u00e1n\u00f3czy", "Daniel M\u00f8ller Eriksen", "Nathalie Neptune", "Philippe Roussille"], "title": "Beyond Token Limits: Assessing Language Model Performance on Long Text Classification", "comment": null, "summary": "The most widely used large language models in the social sciences (such as\nBERT, and its derivatives, e.g. RoBERTa) have a limitation on the input text\nlength that they can process to produce predictions. This is a particularly\npressing issue for some classification tasks, where the aim is to handle long\ninput texts. One such area deals with laws and draft laws (bills), which can\nhave a length of multiple hundred pages and, therefore, are not particularly\namenable for processing with models that can only handle e.g. 512 tokens. In\nthis paper, we show results from experiments covering 5 languages with\nXLM-RoBERTa, Longformer, GPT-3.5, GPT-4 models for the multiclass\nclassification task of the Comparative Agendas Project, which has a codebook of\n21 policy topic labels from education to health care. Results show no\nparticular advantage for the Longformer model, pre-trained specifically for the\npurposes of handling long inputs. The comparison between the GPT variants and\nthe best-performing open model yielded an edge for the latter. An analysis of\nclass-level factors points to the importance of support and substance overlaps\nbetween specific categories when it comes to performance on long text inputs.", "AI": {"tldr": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u957f\u6587\u672c\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5728\u6cd5\u5f8b\u6587\u732e\u7b49\u957f\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u4e2d\u3002\u672c\u7814\u7a76\u57285\u79cd\u8bed\u8a00\u4e2d\uff0c\u4f7f\u7528XLM-RoBERTa\u3001Longformer\u3001GPT-3.5\u548cGPT-4\u6a21\u578b\u5bf9\u6bd4\u8f83\u8bae\u7a0b\u9879\u76ee\uff08Comparative Agendas Project\uff09\u7684\u653f\u7b56\u4e3b\u9898\u5206\u7c7b\u4efb\u52a1\u8fdb\u884c\u4e86\u5b9e\u9a8c\u3002\u7ed3\u679c\u663e\u793a\uff0c\u4e13\u95e8\u4e3a\u5904\u7406\u957f\u8f93\u5165\u800c\u8bbe\u8ba1\u7684Longformer\u6a21\u578b\u5e76\u672a\u8868\u73b0\u51fa\u7279\u522b\u4f18\u52bf\u3002GPT\u53d8\u4f53\u5728\u4e0e\u8868\u73b0\u6700\u4f73\u7684\u5f00\u653e\u6a21\u578b\u76f8\u6bd4\u65f6\uff0c\u540e\u8005\u7565\u80dc\u4e00\u7b79\u3002\u5bf9\u7c7b\u522b\u7ea7\u522b\u56e0\u7d20\u7684\u5206\u6790\u8868\u660e\uff0c\u7279\u5b9a\u7c7b\u522b\u4e4b\u95f4\u7684\u652f\u6301\u548c\u5b9e\u8d28\u5185\u5bb9\u91cd\u53e0\u5bf9\u4e8e\u957f\u6587\u672c\u8f93\u5165\u7684\u6027\u80fd\u81f3\u5173\u91cd\u8981\u3002", "motivation": "\u73b0\u6709\u7684\u4e3b\u6d41\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u5982BERT\u53ca\u5176\u884d\u751f\u6a21\u578b\uff09\u5728\u5904\u7406\u957f\u6587\u672c\u8f93\u5165\u65b9\u9762\u5b58\u5728\u957f\u5ea6\u9650\u5236\uff0c\u8fd9\u5bf9\u4e8e\u9700\u8981\u5904\u7406\u957f\u7bc7\u6cd5\u5f8b\u6587\u732e\u7b49\u6587\u672c\u7684\u5206\u7c7b\u4efb\u52a1\u6765\u8bf4\u662f\u4e00\u4e2a\u4e25\u5cfb\u7684\u95ee\u9898\u3002", "method": "\u57285\u79cd\u8bed\u8a00\u4e2d\uff0c\u5bf9XLM-RoBERTa\u3001Longformer\u3001GPT-3.5\u548cGPT-4\u6a21\u578b\u5728\u6bd4\u8f83\u8bae\u7a0b\u9879\u76ee\uff08Comparative Agendas Project\uff09\u7684\u591a\u7c7b\u522b\u5206\u7c7b\u4efb\u52a1\uff08\u5305\u542b21\u4e2a\u653f\u7b56\u4e3b\u9898\u6807\u7b7e\uff09\u8fdb\u884c\u4e86\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "Longformer\u6a21\u578b\u5728\u5904\u7406\u957f\u6587\u672c\u8f93\u5165\u65b9\u9762\u5e76\u672a\u663e\u793a\u51fa\u7279\u522b\u4f18\u52bf\u3002\u5728\u4e0e\u8868\u73b0\u6700\u4f73\u7684\u5f00\u653e\u6a21\u578b\u76f8\u6bd4\u65f6\uff0cGPT\u53d8\u4f53\u6a21\u578b\u7565\u900a\u4e00\u7b79\u3002\u5bf9\u7c7b\u522b\u7ea7\u522b\u56e0\u7d20\u7684\u5206\u6790\u8868\u660e\uff0c\u7279\u5b9a\u7c7b\u522b\u4e4b\u95f4\u7684\u652f\u6301\u548c\u5b9e\u8d28\u5185\u5bb9\u91cd\u53e0\u5bf9\u4e8e\u957f\u6587\u672c\u8f93\u5165\u7684\u6a21\u578b\u6027\u80fd\u975e\u5e38\u91cd\u8981\u3002", "conclusion": "\u5bf9\u4e8e\u9700\u8981\u5904\u7406\u957f\u6587\u672c\uff08\u5982\u6cd5\u5f8b\u6587\u732e\uff09\u7684\u5206\u7c7b\u4efb\u52a1\uff0c\u4e13\u95e8\u8bbe\u8ba1\u7684\u957f\u6587\u672c\u6a21\u578b\uff08\u5982Longformer\uff09\u5e76\u4e0d\u4e00\u5b9a\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\u3002\u5728\u6bd4\u8f83\u4e0d\u540c\u6a21\u578b\uff08\u5305\u62ecGPT\u53d8\u4f53\u548c\u5f00\u653e\u6a21\u578b\uff09\u7684\u6027\u80fd\u65f6\uff0c\u5f00\u653e\u6a21\u578b\u8868\u73b0\u51fa\u4e00\u5b9a\u7684\u4f18\u52bf\u3002\u6a21\u578b\u5728\u5904\u7406\u957f\u6587\u672c\u65f6\u7684\u6027\u80fd\u53d7\u5230\u7c7b\u522b\u4e4b\u95f4\u652f\u6301\u548c\u5185\u5bb9\u91cd\u53e0\u7684\u5f71\u54cd\u3002"}}
{"id": "2509.10257", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.10257", "abs": "https://arxiv.org/abs/2509.10257", "authors": ["Ema Masterl", "Tina Vipotnik Vesnaver", "\u017diga \u0160piclin"], "title": "Robustness and Diagnostic Performance of Super-Resolution Fetal Brain MRI", "comment": "Accepted at the PIPPI Workshop of MICCAI 2025", "summary": "Fetal brain MRI relies on rapid multi-view 2D slice acquisitions to reduce\nmotion artifacts caused by fetal movement. However, these stacks are typically\nlow resolution, may suffer from motion corruption, and do not adequately\ncapture 3D anatomy. Super-resolution reconstruction (SRR) methods aim to\naddress these limitations by combining slice-to-volume registration and\nsuper-resolution techniques to generate high-resolution (HR) 3D volumes. While\nseveral SRR methods have been proposed, their comparative performance -\nparticularly in pathological cases - and their influence on downstream\nvolumetric analysis and diagnostic tasks remain underexplored. In this study,\nwe applied three state-of-the-art SRR method - NiftyMIC, SVRTK, and NeSVoR - to\n140 fetal brain MRI scans, including both healthy controls (HC) and\npathological cases (PC) with ventriculomegaly (VM). Each HR reconstruction was\nsegmented using the BoUNTi algorithm to extract volumes of nine principal brain\nstructures. We evaluated visual quality, SRR success rates, volumetric\nmeasurement agreement, and diagnostic classification performance. NeSVoR\ndemonstrated the highest and most consistent reconstruction success rate (>90%)\nacross both HC and PC groups. Although significant differences in volumetric\nestimates were observed between SRR methods, classification performance for VM\nwas not affected by the choice of SRR method. These findings highlight NeSVoR's\nrobustness and the resilience of diagnostic performance despite SRR-induced\nvolumetric variability.", "AI": {"tldr": "SRR\u65b9\u6cd5\uff08NiftyMIC\u3001SVRTK\u3001NeSVoR\uff09\u5e94\u7528\u4e8e140\u4f8b\u80ce\u513f\u8111MRI\u626b\u63cf\uff0cNeSVoR\u91cd\u5efa\u6210\u529f\u7387\u6700\u9ad8\u3002\u4e0d\u540cSRR\u65b9\u6cd5\u5728\u4f53\u79ef\u6d4b\u91cf\u4e0a\u5b58\u5728\u5dee\u5f02\uff0c\u4f46\u5bf9\u8bca\u65ad\u5206\u7c7b\u6027\u80fd\u65e0\u5f71\u54cd\u3002", "motivation": "\u80ce\u513f\u8111MRI\u5206\u8fa8\u7387\u4f4e\u3001\u6613\u53d7\u8fd0\u52a8\u5e72\u6270\u4e14\u4e0d\u80fd\u5145\u5206\u663e\u793a\u4e09\u7ef4\u89e3\u5256\u7ed3\u6784\uff0cSRR\u65b9\u6cd5\u65e8\u5728\u901a\u8fc7\u7ed3\u5408\u5207\u7247\u5230\u4f53\u79ef\u914d\u51c6\u548c\u8d85\u5206\u8fa8\u7387\u6280\u672f\u6765\u751f\u6210\u9ad8\u5206\u8fa8\u7387\u4e09\u7ef4\u4f53\u79ef\u3002\u73b0\u6709SRR\u65b9\u6cd5\u5728\u75c5\u7406\u60c5\u51b5\u4e0b\u7684\u6bd4\u8f83\u6027\u80fd\u4ee5\u53ca\u5bf9\u4e0b\u6e38\u5206\u6790\u548c\u8bca\u65ad\u4efb\u52a1\u7684\u5f71\u54cd\u6709\u5f85\u8fdb\u4e00\u6b65\u7814\u7a76\u3002", "method": "\u5e94\u7528\u4e09\u79cd\u6700\u5148\u8fdb\u7684SRR\u65b9\u6cd5\uff08NiftyMIC\u3001SVRTK\u548cNeSVoR\uff09\u5bf9140\u4f8b\u5065\u5eb7\u5bf9\u7167\u7ec4\u548c\u75c5\u7406\u7ec4\uff08\u8111\u5ba4\u6269\u5f20\uff09\u7684\u80ce\u513f\u8111MRI\u626b\u63cf\u8fdb\u884c\u5904\u7406\u3002\u4f7f\u7528BoUNTi\u7b97\u6cd5\u5bf9\u91cd\u5efa\u540e\u7684\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u8fdb\u884c\u5206\u5272\uff0c\u63d0\u53d6\u4e5d\u4e2a\u4e3b\u8981\u8111\u7ed3\u6784\u7684\u4f53\u79ef\u3002\u8bc4\u4f30\u91cd\u5efa\u56fe\u50cf\u7684\u89c6\u89c9\u8d28\u91cf\u3001SRR\u6210\u529f\u7387\u3001\u4f53\u79ef\u6d4b\u91cf\u4e00\u81f4\u6027\u4ee5\u53ca\u8bca\u65ad\u5206\u7c7b\u6027\u80fd\u3002", "result": "NeSVoR\u5728\u5065\u5eb7\u5bf9\u7167\u7ec4\u548c\u75c5\u7406\u7ec4\u4e2d\u5747\u663e\u793a\u51fa\u6700\u9ad8\u4e14\u6700\u4e00\u81f4\u7684\u91cd\u5efa\u6210\u529f\u7387\uff08>90%\uff09\u3002\u5c3d\u7ba1SRR\u65b9\u6cd5\u5728\u4f53\u79ef\u4f30\u8ba1\u4e0a\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u4f46\u5bf9\u8111\u5ba4\u6269\u5f20\u7684\u8bca\u65ad\u5206\u7c7b\u6027\u80fd\u4e0d\u53d7SRR\u65b9\u6cd5\u9009\u62e9\u7684\u5f71\u54cd\u3002", "conclusion": "NeSVoR\u65b9\u6cd5\u5177\u6709\u5f88\u9ad8\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u4e14\u8bca\u65ad\u6027\u80fd\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u53ef\u4ee5\u627f\u53d7SRR\u5f15\u8d77\u7684\u4f53\u79ef\u53d8\u5316\u3002"}}
{"id": "2509.10208", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10208", "abs": "https://arxiv.org/abs/2509.10208", "authors": ["Shengqiang Fu"], "title": "SI-FACT: Mitigating Knowledge Conflict via Self-Improving Faithfulness-Aware Contrastive Tuning", "comment": null, "summary": "Large Language Models often generate unfaithful responses in knowledge\nintensive tasks due to knowledge conflict,that is,a preference for relying on\ninternal parametric knowledge rather than the provided context.To address this\nissue,we propose a novel self improving framework,Self Improving Faithfulness\nAware Contrastive Tuning.The framework uses a self instruct mechanism that\nallows the base LLM to automatically generate high quality,structured\ncontrastive learning data,including anchor samples,semantically equivalent\npositive samples,and negative samples simulating unfaithful scenarios.This\napproach significantly reduces the cost of manual\nannotation.Subsequently,contrastive learning is applied to train the\nmodel,enabling it to pull faithful responses closer and push unfaithful\nresponses farther apart in the representation space.Experiments on knowledge\nconflict evaluation benchmarks ECARE KRE and COSE KRE show that the SI FACT\nmodel based on Llama3 8B Instruct improves the Contextual Recall Rate by 6.2%\nover the best baseline method,while significantly reducing dependence on\ninternal memory.The results indicate that SI FACT provides strong effectiveness\nand high data efficiency in enhancing the contextual faithfulness of\nLLMs,offering a practical pathway toward building more proactive and\ntrustworthy language models.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a SI FACT \u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u52a8\u751f\u6210\u548c\u5229\u7528\u5bf9\u6bd4\u5b66\u4e60\u6570\u636e\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u4e2d\u7684\u5fe0\u5b9e\u5ea6\uff0c\u5e76\u964d\u4f4e\u4e86\u5bf9\u5185\u90e8\u77e5\u8bc6\u7684\u4f9d\u8d56\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u4e2d\u5e38\u5e38\u7531\u4e8e\u4f18\u5148\u9009\u62e9\u5185\u90e8\u77e5\u8bc6\u800c\u975e\u7ed9\u5b9a\u4e0a\u4e0b\u6587\u800c\u4ea7\u751f\u4e0d\u5fe0\u5b9e\u7684\u54cd\u5e94\uff0c\u8fd9\u79cd\u73b0\u8c61\u88ab\u79f0\u4e3a\u77e5\u8bc6\u51b2\u7a81\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a Self Improving Faithfulness Aware Contrastive Tuning (SI FACT) \u7684\u81ea\u6539\u8fdb\u6846\u67b6\u3002\u8be5\u6846\u67b6\u5229\u7528\u81ea\u6307\u4ee4\u673a\u5236\uff0c\u8ba9\u57fa\u7840\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u7ed3\u6784\u5316\u7684\u5bf9\u6bd4\u5b66\u4e60\u6570\u636e\uff08\u5305\u62ec\u951a\u70b9\u6837\u672c\u3001\u8bed\u4e49\u7b49\u4ef7\u7684\u6b63\u6837\u672c\u548c\u6a21\u62df\u4e0d\u5fe0\u5b9e\u573a\u666f\u7684\u8d1f\u6837\u672c\uff09\uff0c\u4ece\u800c\u964d\u4f4e\u624b\u52a8\u6807\u6ce8\u6210\u672c\u3002\u968f\u540e\uff0c\u5e94\u7528\u5bf9\u6bd4\u5b66\u4e60\u8bad\u7ec3\u6a21\u578b\uff0c\u4f7f\u5176\u5728\u8868\u793a\u7a7a\u95f4\u4e2d\u62c9\u8fd1\u5fe0\u5b9e\u54cd\u5e94\uff0c\u63a8\u5f00\u4e0d\u5fe0\u5b9e\u54cd\u5e94\u3002", "result": "\u5728 ECARE KRE \u548c COSE KRE \u8fd9\u4e24\u4e2a\u77e5\u8bc6\u51b2\u7a81\u8bc4\u4f30\u57fa\u51c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u7ed3\u679c\u663e\u793a\u57fa\u4e8e Llama3 8B Instruct \u7684 SI FACT \u6a21\u578b\u5c06\u4e0a\u4e0b\u6587\u53ec\u56de\u7387\uff08Contextual Recall Rate\uff09\u6bd4\u6700\u4f73\u57fa\u7ebf\u65b9\u6cd5\u63d0\u9ad8\u4e86 6.2%\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u5bf9\u5185\u90e8\u8bb0\u5fc6\u7684\u4f9d\u8d56\u3002", "conclusion": "SI FACT \u5728\u63d0\u9ad8 LLM \u7684\u4e0a\u4e0b\u6587\u5fe0\u5b9e\u5ea6\u65b9\u9762\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6709\u6548\u6027\u548c\u9ad8\u6570\u636e\u6548\u7387\uff0c\u4e3a\u6784\u5efa\u66f4\u4e3b\u52a8\u3001\u66f4\u503c\u5f97\u4fe1\u8d56\u7684\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u5b9e\u9645\u9014\u5f84\u3002"}}
{"id": "2509.10384", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2509.10384", "abs": "https://arxiv.org/abs/2509.10384", "authors": ["Jianxin Zhang", "Clayton Scott"], "title": "Flow Straight and Fast in Hilbert Space: Functional Rectified Flow", "comment": null, "summary": "Many generative models originally developed in finite-dimensional Euclidean\nspace have functional generalizations in infinite-dimensional settings.\nHowever, the extension of rectified flow to infinite-dimensional spaces remains\nunexplored. In this work, we establish a rigorous functional formulation of\nrectified flow in an infinite-dimensional Hilbert space. Our approach builds\nupon the superposition principle for continuity equations in an\ninfinite-dimensional space. We further show that this framework extends\nnaturally to functional flow matching and functional probability flow ODEs,\ninterpreting them as nonlinear generalizations of rectified flow. Notably, our\nextension to functional flow matching removes the restrictive measure-theoretic\nassumptions in the existing theory of \\citet{kerrigan2024functional}.\nFurthermore, we demonstrate experimentally that our method achieves superior\nperformance compared to existing functional generative models.", "AI": {"tldr": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u65e0\u9650\u7ef4\u5ea6\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u4e2d\u4fee\u6b63\u6d41\u7684\u4e25\u683c\u51fd\u6570\u5f62\u5f0f\uff0c\u5b83\u6269\u5c55\u4e86\u73b0\u6709\u7684\u51fd\u6570\u6d41\u5339\u914d\u548c\u6982\u7387\u6d41ODE\u7406\u8bba\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u663e\u793a\u51fa\u4f18\u8d8a\u7684\u6027\u80fd\u3002", "motivation": "\u5c06\u4fee\u6b63\u6d41\u7684\u73b0\u6709\u7406\u8bba\u6269\u5c55\u5230\u65e0\u9650\u7ef4\u5ea6\u7a7a\u95f4\uff0c\u5e76\u89e3\u51b3\u73b0\u6709\u51fd\u6570\u6d41\u5339\u914d\u7406\u8bba\u4e2d\u7684\u9650\u5236\u3002", "method": "\u5728\u65e0\u9650\u7ef4\u5ea6\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u4e2d\u5efa\u7acb\u4e86\u4fee\u6b63\u6d41\u7684\u51fd\u6570\u5f62\u5f0f\uff0c\u5229\u7528\u4e86\u8fde\u7eed\u6027\u65b9\u7a0b\u7684\u53e0\u52a0\u539f\u7406\uff0c\u5e76\u5c06\u5176\u6269\u5c55\u5230\u51fd\u6570\u6d41\u5339\u914d\u548c\u51fd\u6570\u6982\u7387\u6d41ODE\u3002", "result": "\u6210\u529f\u5730\u5c06\u4fee\u6b63\u6d41\u6269\u5c55\u5230\u65e0\u9650\u7ef4\u5ea6\uff0c\u4e3a\u51fd\u6570\u6d41\u5339\u914d\u63d0\u4f9b\u4e86\u66f4\u5bbd\u677e\u7684\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u7684\u51fd\u6570\u751f\u6210\u6a21\u578b\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65e0\u9650\u7ef4\u5ea6\u4fee\u6b63\u6d41\u6846\u67b6\u662f\u6709\u6548\u7684\uff0c\u5e76\u4e14\u4e3a\u672a\u6765\u7684\u7814\u7a76\u5f00\u8f9f\u4e86\u65b0\u7684\u9014\u5f84\u3002"}}
{"id": "2509.10259", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.10259", "abs": "https://arxiv.org/abs/2509.10259", "authors": ["Hua Yuan", "Jin Yuan", "Yicheng Jiang", "Yao Zhang", "Xin Geng", "Yong Rui"], "title": "Mask Consistency Regularization in Object Removal", "comment": null, "summary": "Object removal, a challenging task within image inpainting, involves\nseamlessly filling the removed region with content that matches the surrounding\ncontext. Despite advancements in diffusion models, current methods still face\ntwo critical challenges. The first is mask hallucination, where the model\ngenerates irrelevant or spurious content inside the masked region, and the\nsecond is mask-shape bias, where the model fills the masked area with an object\nthat mimics the mask's shape rather than surrounding content. To address these\nissues, we propose Mask Consistency Regularization (MCR), a novel training\nstrategy designed specifically for object removal tasks. During training, our\napproach introduces two mask perturbations: dilation and reshape, enforcing\nconsistency between the outputs of these perturbed branches and the original\nmask. The dilated masks help align the model's output with the surrounding\ncontent, while reshaped masks encourage the model to break the mask-shape bias.\nThis combination of strategies enables MCR to produce more robust and\ncontextually coherent inpainting results. Our experiments demonstrate that MCR\nsignificantly reduces hallucinations and mask-shape bias, leading to improved\nperformance in object removal.", "AI": {"tldr": "MCR\u901a\u8fc7\u5f15\u5165\u63a9\u7801\u6270\u52a8\u6765\u89e3\u51b3\u56fe\u50cf\u4fee\u590d\u4e2d\u7684\u906e\u7f69\u5e7b\u89c9\u548c\u906e\u7f69\u5f62\u72b6\u504f\u5dee\u95ee\u9898\uff0c\u4ece\u800c\u63d0\u9ad8\u5bf9\u8c61\u79fb\u9664\u7684\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u7684\u6269\u6563\u6a21\u578b\u5728\u5bf9\u8c61\u79fb\u9664\uff08\u56fe\u50cf\u4fee\u590d\u7684\u4e00\u90e8\u5206\uff09\u65f6\u9762\u4e34\u906e\u7f69\u5e7b\u89c9\uff08\u5728\u906e\u7f69\u533a\u57df\u5185\u751f\u6210\u4e0d\u76f8\u5173\u5185\u5bb9\uff09\u548c\u906e\u7f69\u5f62\u72b6\u504f\u5dee\uff08\u7528\u6a21\u4eff\u906e\u7f69\u5f62\u72b6\u7684\u5bf9\u8c61\u586b\u5145\u800c\u975e\u5468\u56f4\u5185\u5bb9\uff09\u7684\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u63a9\u7801\u4e00\u81f4\u6027\u6b63\u5219\u5316\uff08MCR\uff09\u7684\u65b0\u578b\u8bad\u7ec3\u7b56\u7565\u3002\u8be5\u7b56\u7565\u5728\u8bad\u7ec3\u671f\u95f4\u5f15\u5165\u4e86\u4e24\u79cd\u63a9\u7801\u6270\u52a8\uff1a\u6269\u5f20\u548c\u91cd\u5851\u3002\u901a\u8fc7\u5f3a\u5236\u539f\u59cb\u63a9\u7801\u5206\u652f\u548c\u6270\u52a8\u63a9\u7801\u5206\u652f\u4e4b\u95f4\u7684\u8f93\u51fa\u4fdd\u6301\u4e00\u81f4\uff0c\u6269\u5f20\u63a9\u7801\u6709\u52a9\u4e8e\u5c06\u6a21\u578b\u7684\u8f93\u51fa\u4e0e\u5468\u56f4\u5185\u5bb9\u5bf9\u9f50\uff0c\u800c\u91cd\u5851\u63a9\u7801\u5219\u9f13\u52b1\u6a21\u578b\u6253\u7834\u906e\u7f69\u5f62\u72b6\u504f\u5dee\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cMCR\u663e\u8457\u51cf\u5c11\u4e86\u5e7b\u89c9\u548c\u906e\u7f69\u5f62\u72b6\u504f\u5dee\uff0c\u4ece\u800c\u5728\u5bf9\u8c61\u79fb\u9664\u65b9\u9762\u53d6\u5f97\u4e86\u6539\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "MCR\u901a\u8fc7\u63a9\u7801\u4e00\u81f4\u6027\u6b63\u5219\u5316\uff0c\u80fd\u591f\u751f\u6210\u66f4\u9c81\u68d2\u3001\u66f4\u7b26\u5408\u4e0a\u4e0b\u6587\u7684\u4fee\u590d\u7ed3\u679c\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5bf9\u8c61\u79fb\u9664\u4e2d\u7684\u5173\u952e\u6311\u6218\u3002"}}
{"id": "2509.10377", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.10377", "abs": "https://arxiv.org/abs/2509.10377", "authors": ["Yixiao Zhou", "Ziyu Zhao", "Dongzhou Cheng", "zhiliang wu", "Jie Gui", "Yi Yang", "Fei Wu", "Yu Cheng", "Hehe Fan"], "title": "Dropping Experts, Recombining Neurons: Retraining-Free Pruning for Sparse Mixture-of-Experts LLMs", "comment": "Accepted to EMNLP2025", "summary": "Sparse Mixture-of-Experts (SMoE) architectures are widely used in large\nlanguage models (LLMs) due to their computational efficiency. However, though\nonly a few experts are activated for each token, SMoE still requires loading\nall expert parameters, leading to high memory usage and challenges in\ndeployment. Previous work has tried to reduce the overhead by pruning and\nmerging experts, but primarily focused on expert-level operations, leaving\nneuron-level structure underexplored. We propose DERN (Dropping Experts,\nRecombining Neurons), a task-agnostic and retraining-free framework for expert\npruning and reconstruction. We observe that experts are often misaligned and\ncontain semantic conflicts at the neuron level, which poses challenges for\ndirect merging. To solve this, DERN works in three steps: it first prunes\nredundant experts using router statistics; then it decomposes them into\nneuron-level expert segments, assigning each segment to its most compatible\nretained expert; and finally, it merges segments within each retained expert to\nbuild a compact representation. Experiments on Mixtral, Qwen, and DeepSeek SMoE\nmodels show that DERN improves performance by more than 5% on commonsense\nreasoning and MMLU benchmarks under 50% expert sparsity, without extra\ntraining. It also greatly reduces the number of experts and memory usage,\nmaking SMoE LLMs easier to deploy in practice.", "AI": {"tldr": "SMoE\u6a21\u578b\u867d\u7136\u8ba1\u7b97\u9ad8\u6548\uff0c\u4f46\u9700\u8981\u52a0\u8f7d\u6240\u6709\u4e13\u5bb6\u53c2\u6570\uff0c\u5bfc\u81f4\u5185\u5b58\u5360\u7528\u9ad8\u3002 DERN\u6846\u67b6\u901a\u8fc7\u526a\u679d\u5197\u4f59\u4e13\u5bb6\u3001\u5206\u89e3\u4e13\u5bb6\u81f3\u795e\u7ecf\u5143\u5c42\u9762\u5e76\u91cd\u7ec4\uff0c\u5b9e\u73b0\u4e8650%\u7a00\u758f\u5ea6\u4e0b\u6027\u80fd\u63d0\u53475%\u4ee5\u4e0a\uff0c\u4e14\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\uff0c\u964d\u4f4e\u4e86SMoE\u6a21\u578b\u7684\u90e8\u7f72\u96be\u5ea6\u3002", "motivation": "SMoE\u6a21\u578b\u5c3d\u7ba1\u8ba1\u7b97\u6548\u7387\u9ad8\uff0c\u4f46\u5176\u52a0\u8f7d\u6240\u6709\u4e13\u5bb6\u53c2\u6570\u7684\u7279\u6027\u5bfc\u81f4\u4e86\u9ad8\u5185\u5b58\u6d88\u8017\u548c\u90e8\u7f72\u56f0\u96be\u3002\u5148\u524d\u7684\u5de5\u4f5c\u4e3b\u8981\u96c6\u4e2d\u5728\u4e13\u5bb6\u5c42\u9762\u8fdb\u884c\u4f18\u5316\uff0c\u5ffd\u7565\u4e86\u795e\u7ecf\u5143\u5c42\u9762\u7684\u7ed3\u6784\u3002", "method": "DERN\u6846\u67b6\u9996\u5148\u5229\u7528\u8def\u7531\u5668\u7684\u7edf\u8ba1\u4fe1\u606f\u526a\u679d\u5197\u4f59\u4e13\u5bb6\uff1b\u7136\u540e\u5c06\u4e13\u5bb6\u5206\u89e3\u4e3a\u795e\u7ecf\u5143\u7ea7\u522b\u7684\u4e13\u5bb6\u7247\u6bb5\uff0c\u5e76\u5c06\u6bcf\u4e2a\u7247\u6bb5\u5206\u914d\u7ed9\u6700\u517c\u5bb9\u7684\u4fdd\u7559\u4e13\u5bb6\uff1b\u6700\u540e\uff0c\u5728\u6bcf\u4e2a\u4fdd\u7559\u4e13\u5bb6\u5185\u90e8\u5408\u5e76\u7247\u6bb5\uff0c\u6784\u5efa\u7d27\u51d1\u7684\u8868\u793a\u3002", "result": "\u5728Mixtral\u3001Qwen\u548cDeepSeek SMoE\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cDERN\u572850%\u7684\u4e13\u5bb6\u7a00\u758f\u5ea6\u4e0b\uff0c\u5728\u5e38\u8bc6\u63a8\u7406\u548cMMLU\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u6027\u80fd\u63d0\u9ad8\u4e865%\u4ee5\u4e0a\uff0c\u5e76\u4e14\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u51cf\u5c11\u4e86\u4e13\u5bb6\u6570\u91cf\u548c\u5185\u5b58\u4f7f\u7528\u91cf\u3002", "conclusion": "DERN\u6846\u67b6\u901a\u8fc7\u5728\u795e\u7ecf\u5143\u5c42\u9762\u8fdb\u884c\u526a\u679d\u548c\u91cd\u7ec4\uff0c\u6709\u6548\u89e3\u51b3\u4e86SMoE\u6a21\u578b\u7684\u9ad8\u5185\u5b58\u5360\u7528\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u6027\u80fd\uff0c\u5e76\u7b80\u5316\u4e86SMoE LLM\u7684\u5b9e\u9645\u90e8\u7f72\u3002"}}
{"id": "2509.10390", "categories": ["cs.LG", "cs.IT", "math.IT", "q-bio.PE"], "pdf": "https://arxiv.org/pdf/2509.10390", "abs": "https://arxiv.org/abs/2509.10390", "authors": ["Quan Nguyen", "Adji Bousso Dieng"], "title": "Vendi Information Gain for Active Learning and its Application to Ecology", "comment": null, "summary": "While monitoring biodiversity through camera traps has become an important\nendeavor for ecological research, identifying species in the captured image\ndata remains a major bottleneck due to limited labeling resources. Active\nlearning -- a machine learning paradigm that selects the most informative data\nto label and train a predictive model -- offers a promising solution, but\ntypically focuses on uncertainty in the individual predictions without\nconsidering uncertainty across the entire dataset. We introduce a new active\nlearning policy, Vendi information gain (VIG), that selects images based on\ntheir impact on dataset-wide prediction uncertainty, capturing both\ninformativeness and diversity. Applied to the Snapshot Serengeti dataset, VIG\nachieves impressive predictive accuracy close to full supervision using less\nthan 10% of the labels. It consistently outperforms standard baselines across\nmetrics and batch sizes, collecting more diverse data in the feature space. VIG\nhas broad applicability beyond ecology, and our results highlight its value for\nbiodiversity monitoring in data-limited environments.", "AI": {"tldr": "VIG\u662f\u4e00\u79cd\u65b0\u7684\u4e3b\u52a8\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u8003\u8651\u6570\u636e\u96c6\u8303\u56f4\u5185\u7684\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u6765\u9009\u62e9\u56fe\u50cf\u8fdb\u884c\u6807\u8bb0\uff0c\u5728\u51cf\u5c11\u6807\u8bb0\u5de5\u4f5c\u91cf\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u63a5\u8fd1\u5168\u76d1\u7763\u5b66\u4e60\u7684\u51c6\u786e\u6027\uff0c\u5e76\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u524d\u666f\u3002", "motivation": "\u76ee\u524d\u76f8\u673a\u9677\u9631\u76d1\u6d4b\u751f\u7269\u591a\u6837\u6027\u7684\u5173\u952e\u74f6\u9888\u5728\u4e8e\u5bf9\u56fe\u50cf\u6570\u636e\u8fdb\u884c\u7269\u79cd\u8bc6\u522b\u7684\u6807\u6ce8\u8d44\u6e90\u6709\u9650\u3002\u4e3b\u52a8\u5b66\u4e60\u867d\u7136\u63d0\u4f9b\u4e86\u4e00\u79cd\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u901a\u5e38\u53ea\u5173\u6ce8\u4e2a\u4f53\u9884\u6d4b\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5ffd\u7565\u4e86\u6574\u4e2a\u6570\u636e\u96c6\u7684\u6f5c\u5728\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aVendi\u4fe1\u606f\u589e\u76ca\uff08VIG\uff09\u7684\u65b0\u4e3b\u52a8\u5b66\u4e60\u7b56\u7565\uff0c\u8be5\u7b56\u7565\u6839\u636e\u56fe\u50cf\u5bf9\u6574\u4e2a\u6570\u636e\u96c6\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u7684\u5f71\u54cd\u6765\u9009\u62e9\u56fe\u50cf\uff0c\u4ece\u800c\u540c\u65f6\u6355\u6349\u4fe1\u606f\u91cf\u548c\u591a\u6837\u6027\u3002", "result": "\u5728Snapshot Serengeti\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cVIG\u5728\u6807\u8bb0\u6570\u636e\u91cf\u4e0d\u523010%\u7684\u60c5\u51b5\u4e0b\uff0c\u5b9e\u73b0\u4e86\u63a5\u8fd1\u5168\u76d1\u7763\u5b66\u4e60\u7684\u9884\u6d4b\u51c6\u786e\u7387\uff0c\u5e76\u4e14\u5728\u5404\u79cd\u6307\u6807\u548c\u6279\u5904\u7406\u5927\u5c0f\u4e0a\u90fd\u6301\u7eed\u4f18\u4e8e\u6807\u51c6\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8fd8\u80fd\u5728\u7279\u5f81\u7a7a\u95f4\u4e2d\u6536\u96c6\u5230\u66f4\u591a\u6837\u5316\u7684\u6570\u636e\u3002", "conclusion": "VIG\u5728\u751f\u6001\u5b66\u9886\u57df\u4e4b\u5916\u4e5f\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u5176\u7814\u7a76\u7ed3\u679c\u7a81\u663e\u4e86\u8be5\u65b9\u6cd5\u5728\u6570\u636e\u53d7\u9650\u73af\u5883\u4e0b\u8fdb\u884c\u751f\u7269\u591a\u6837\u6027\u76d1\u6d4b\u7684\u4ef7\u503c\u3002"}}
{"id": "2509.10260", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.10260", "abs": "https://arxiv.org/abs/2509.10260", "authors": ["Jia Wang", "Jie Hu", "Xiaoqi Ma", "Hanghang Ma", "Yanbing Zeng", "Xiaoming Wei"], "title": "MagicMirror: A Large-Scale Dataset and Benchmark for Fine-Grained Artifacts Assessment in Text-to-Image Generation", "comment": null, "summary": "Text-to-image (T2I) generation has achieved remarkable progress in\ninstruction following and aesthetics. However, a persistent challenge is the\nprevalence of physical artifacts, such as anatomical and structural flaws,\nwhich severely degrade perceptual quality and limit application. Given the\ndiversity and complexity of these artifacts, a systematic and fine-grained\nevaluation framework is required, which is lacking in current benchmarks. To\nfill this gap, we introduce MagicMirror, a comprehensive framework for\nartifacts assessment. We first establish a detailed taxonomy of generated image\nartifacts. Guided by this taxonomy, we manually annotate MagicData340K, the\nfirst human-annotated large-scale dataset of 340K generated images with\nfine-grained artifact labels. Building on this dataset, we train MagicAssessor,\na Vision-Language Model (VLM) that provides detailed assessments and\ncorresponding labels. To overcome challenges like class imbalance and reward\nhacking, we design a novel data sampling strategy and a multi-level reward\nsystem for Group Relative Policy Optimization (GRPO). Finally, we leverage\nMagicAssessor to construct MagicBench, an automated benchmark for evaluating\nthe image artifacts of current T2I models. Our evaluation with MagicBench\nreveals that despite their widespread adoption, even top-tier models like\nGPT-image-1 are consistently plagued by significant artifacts, highlighting\nartifact reduction as a critical frontier for future T2I development. Project\npage: https://wj-inf.github.io/MagicMirror-page/.", "AI": {"tldr": "T2I\u751f\u6210\u4e2d\u5b58\u5728\u7684\u7269\u7406\u4f2a\u5f71\uff08\u5982\u89e3\u5256\u548c\u7ed3\u6784\u7f3a\u9677\uff09\u662f\u4e00\u4e2a\u666e\u904d\u5b58\u5728\u7684\u95ee\u9898\uff0c\u4e25\u91cd\u5f71\u54cd\u611f\u77e5\u8d28\u91cf\u5e76\u9650\u5236\u4e86\u5e94\u7528\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86MagicMirror\u6846\u67b6\uff0c\u5b83\u5305\u62ec\u4e00\u4e2a\u8be6\u7ec6\u7684\u4f2a\u5f71\u5206\u7c7b\u3001\u4e00\u4e2a\u5305\u542b340K\u4e2a\u5e26\u7cbe\u7ec6\u4f2a\u5f71\u6807\u7b7e\u7684\u751f\u6210\u56fe\u50cf\u7684\u4eba\u5de5\u6ce8\u91ca\u6570\u636e\u96c6MagicData340K\uff0c\u4ee5\u53ca\u4e00\u4e2a\u540d\u4e3aMagicAssessor\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u6765\u8bc4\u4f30\u8fd9\u4e9b\u4f2a\u5f71\u3002\u6211\u4eec\u8fd8\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u7684\u6570\u636e\u91c7\u6837\u7b56\u7565\u548c\u591a\u7ea7\u5956\u52b1\u7cfb\u7edf\u6765\u89e3\u51b3\u8bad\u7ec3\u4e2d\u7684\u6311\u6218\u3002\u6700\u7ec8\uff0c\u6211\u4eec\u5229\u7528MagicAssessor\u6784\u5efa\u4e86\u4e00\u4e2a\u540d\u4e3aMagicBench\u7684\u81ea\u52a8\u5316\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30T2I\u6a21\u578b\u4e2d\u7684\u56fe\u50cf\u4f2a\u5f71\u3002\u8bc4\u4f30\u7ed3\u679c\u8868\u660e\uff0c\u5373\u4f7f\u662f\u9876\u5c16\u6a21\u578b\u4e5f\u5b58\u5728\u663e\u8457\u7684\u4f2a\u5f71\u95ee\u9898\uff0c\u8fd9\u51f8\u663e\u4e86\u51cf\u5c11\u4f2a\u5f71\u5bf9\u4e8e\u672a\u6765T2I\u53d1\u5c55\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u6587\u672c\u5230\u56fe\u50cf\uff08T2I\uff09\u751f\u6210\u5728\u6307\u4ee4\u9075\u5faa\u548c\u7f8e\u5b66\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u666e\u904d\u5b58\u5728\u7684\u7269\u7406\u4f2a\u5f71\uff08\u5982\u89e3\u5256\u548c\u7ed3\u6784\u7f3a\u9677\uff09\u4e25\u91cd\u964d\u4f4e\u4e86\u611f\u77e5\u8d28\u91cf\u5e76\u9650\u5236\u4e86\u5e94\u7528\u3002\u76ee\u524d\u7684\u57fa\u51c6\u6d4b\u8bd5\u7f3a\u4e4f\u7cfb\u7edf\u6027\u548c\u7cbe\u7ec6\u5316\u7684\u4f2a\u5f71\u8bc4\u4f30\u6846\u67b6\u3002", "method": "1. \u5efa\u7acb\u8be6\u7ec6\u7684\u751f\u6210\u56fe\u50cf\u4f2a\u5f71\u5206\u7c7b\u30022. \u6784\u5efa\u4e00\u4e2a\u5305\u542b340K\u4e2a\u5e26\u7cbe\u7ec6\u4f2a\u5f71\u6807\u7b7e\u7684\u5927\u89c4\u6a21\u4eba\u5de5\u6ce8\u91ca\u6570\u636e\u96c6MagicData340K\u30023. \u8bad\u7ec3\u4e00\u4e2a\u89c6\u89c9\u8bed\u8a00\u6a21\u578bMagicAssessor\uff0c\u7528\u4e8e\u63d0\u4f9b\u8be6\u7ec6\u7684\u4f2a\u5f71\u8bc4\u4f30\u548c\u6807\u7b7e\u30024. \u8bbe\u8ba1\u65b0\u7684\u6570\u636e\u91c7\u6837\u7b56\u7565\u548c\u591a\u7ea7\u5956\u52b1\u7cfb\u7edf\uff08\u7528\u4e8eGroup Relative Policy Optimization - GRPO\uff09\uff0c\u4ee5\u514b\u670d\u7c7b\u522b\u4e0d\u5e73\u8861\u548c\u5956\u52b1\u6280\u5de7\u7b49\u6311\u6218\u30025. \u5229\u7528MagicAssessor\u6784\u5efa\u81ea\u52a8\u5316\u57fa\u51c6MagicBench\uff0c\u7528\u4e8e\u8bc4\u4f30T2I\u6a21\u578b\u7684\u56fe\u50cf\u4f2a\u5f71\u3002", "result": "MagicBench\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u5373\u4f7f\u662f\u50cfGPT-image-1\u8fd9\u6837\u7684\u9876\u5c16\u6a21\u578b\u4e5f\u6301\u7eed\u5b58\u5728\u663e\u8457\u7684\u4f2a\u5f71\u95ee\u9898\uff0c\u8868\u660e\u4f2a\u5f71\u51cf\u5c11\u4ecd\u7136\u662f\u672a\u6765T2I\u53d1\u5c55\u7684\u4e00\u4e2a\u5173\u952e\u65b9\u5411\u3002", "conclusion": "MagicMirror\u6846\u67b6\u4e3aT2I\u751f\u6210\u4e2d\u7684\u4f2a\u5f71\u8bc4\u4f30\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7cfb\u7edf\u5316\u7684\u89e3\u51b3\u65b9\u6848\u3002\u901a\u8fc7MagicData340K\u6570\u636e\u96c6\u548cMagicAssessor\u6a21\u578b\uff0c\u6211\u4eec\u80fd\u591f\u6784\u5efaMagicBench\u57fa\u51c6\uff0c\u5e76\u63ed\u793a\u5f53\u524dT2I\u6a21\u578b\u5728\u4f2a\u5f71\u65b9\u9762\u5b58\u5728\u7684\u666e\u904d\u95ee\u9898\uff0c\u6307\u660e\u4e86\u672a\u6765\u7684\u7814\u7a76\u91cd\u70b9\u3002"}}
{"id": "2509.10414", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10414", "abs": "https://arxiv.org/abs/2509.10414", "authors": ["Adrian de Wynter"], "title": "Is In-Context Learning Learning?", "comment": "Director's cut", "summary": "In-context learning (ICL) allows some autoregressive models to solve tasks\nvia next-token prediction and without needing further training. This has led to\nclaims about these model's ability to solve (learn) unseen tasks with only a\nfew shots (exemplars) in the prompt. However, deduction does not always imply\nlearning, as ICL does not explicitly encode a given observation. Instead, the\nmodels rely on their prior knowledge and the exemplars given, if any. We argue\nthat, mathematically, ICL does constitute learning, but its full\ncharacterisation requires empirical work. We then carry out a large-scale\nanalysis of ICL ablating out or accounting for memorisation, pretraining,\ndistributional shifts, and prompting style and phrasing. We find that ICL is an\neffective learning paradigm, but limited in its ability to learn and generalise\nto unseen tasks. We note that, in the limit where exemplars become more\nnumerous, accuracy is insensitive to exemplar distribution, model, prompt\nstyle, and the input's linguistic features. Instead, it deduces patterns from\nregularities in the prompt, which leads to distributional sensitivity,\nespecially in prompting styles such as chain-of-thought. Given the varied\naccuracies on formally similar tasks, we conclude that autoregression's ad-hoc\nencoding is not a robust mechanism, and suggests limited all-purpose\ngeneralisability.", "AI": {"tldr": "In-context learning (ICL) enables autoregressive models to perform tasks without retraining, but its learning capabilities and generalizability are limited. While mathematically constituting learning, ICL relies heavily on prior knowledge and prompt exemplars, showing sensitivity to prompt style and distributional shifts, particularly with methods like chain-of-thought. The ad-hoc encoding of autoregression limits its all-purpose generalizability.", "motivation": "The paper aims to investigate the nature of learning in in-context learning (ICL) and its limitations, questioning whether deduction implies true learning and characterizing its effectiveness and generalizability.", "method": "A large-scale analysis of ICL was conducted, involving ablation studies and controlling for factors such as memorization, pretraining, distributional shifts, and prompting style and phrasing.", "result": "The study found that ICL is an effective learning paradigm but has limitations in learning and generalizing to unseen tasks. Accuracy was observed to be insensitive to exemplar distribution, model, prompt style, and linguistic features when exemplars become numerous. However, ICL exhibits distributional sensitivity, especially with chain-of-thought prompting, due to deducing patterns from prompt regularities.", "conclusion": "Autoregression's ad-hoc encoding is not a robust mechanism for learning, indicating limited all-purpose generalizability for ICL. While ICL is a form of learning, its reliance on prior knowledge and prompt specifics, along with its sensitivity to prompt design and data distribution, restricts its ability to truly learn and generalize to novel situations."}}
{"id": "2509.10396", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10396", "abs": "https://arxiv.org/abs/2509.10396", "authors": ["Siyan Zhao", "Mengchen Liu", "Jing Huang", "Miao Liu", "Chenyu Wang", "Bo Liu", "Yuandong Tian", "Guan Pang", "Sean Bell", "Aditya Grover", "Feiyu Chen"], "title": "Inpainting-Guided Policy Optimization for Diffusion Large Language Models", "comment": "preprint; 21 pages", "summary": "Masked diffusion large language models (dLLMs) are emerging as promising\nalternatives to autoregressive LLMs, offering competitive performance while\nsupporting unique generation capabilities such as inpainting. We explore how\ninpainting can inform RL algorithm design for dLLMs. Aligning LLMs with\nreinforcement learning faces an exploration challenge: sparse reward signals\nand sample waste when models fail to discover correct solutions. While this\ninefficiency affects LLMs broadly, dLLMs offer a distinctive opportunity--their\ninpainting ability can guide exploration. We introduce IGPO (Inpainting Guided\nPolicy Optimization), an RL framework that strategically inserts partial\nground-truth reasoning traces during online sampling. Unlike providing full\nsolutions, inpainting steers exploration toward promising trajectory spaces\nwhile preserving self-generated reasoning, bridging supervised fine-tuning and\nreinforcement learning. We apply IGPO to group-based optimization methods such\nas GRPO, where exploration failures cause zero advantages and gradients. IGPO\nrestores meaningful gradients while improving sample efficiency. We also\npropose supervised fine-tuning on synthetically rewritten concise traces that\nbetter align with dLLM generation patterns. With additional techniques\nincluding entropy-based filtering, our training recipe yields substantial gains\nacross three mathematical benchmarks--GSM8K, Math500, and AMC--achieving new\nstate-of-the-art results for full-attention masked dLLMs.", "AI": {"tldr": "Masked diffusion large language models (dLLMs) can be improved with reinforcement learning (RL) by using their inpainting ability to guide exploration, leading to a new framework called IGPO that achieves state-of-the-art results on mathematical benchmarks.", "motivation": "Traditional reinforcement learning (RL) for large language models (LLMs) suffers from exploration challenges due to sparse rewards and wasted samples. Masked diffusion LLMs (dLLMs) offer a unique opportunity to improve exploration through their inpainting capabilities.", "method": "The paper introduces Inpainting Guided Policy Optimization (IGPO), an RL framework for dLLMs. IGPO strategically inserts partial ground-truth reasoning traces during online sampling to guide exploration. It also incorporates supervised fine-tuning on rewritten concise traces and entropy-based filtering. The framework is applied to group-based optimization methods like GRPO.", "result": "IGPO improves sample efficiency and restores meaningful gradients in RL training for dLLMs. The proposed training recipe, including IGPO and other techniques, achieves new state-of-the-art results on three mathematical benchmarks: GSM8K, Math500, and AMC, for full-attention masked dLLMs.", "conclusion": "The inpainting ability of dLLMs can be effectively leveraged within an RL framework (IGPO) to enhance exploration, improve sample efficiency, and achieve superior performance on complex reasoning tasks, particularly in the domain of mathematics."}}
{"id": "2509.10266", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10266", "abs": "https://arxiv.org/abs/2509.10266", "authors": ["Wenfang Wu", "Tingting Yuan", "Yupeng Li", "Daling Wang", "Xiaoming Fu"], "title": "SignClip: Leveraging Mouthing Cues for Sign Language Translation by Multimodal Contrastive Fusion", "comment": null, "summary": "Sign language translation (SLT) aims to translate natural language from sign\nlanguage videos, serving as a vital bridge for inclusive communication. While\nrecent advances leverage powerful visual backbones and large language models,\nmost approaches mainly focus on manual signals (hand gestures) and tend to\noverlook non-manual cues like mouthing. In fact, mouthing conveys essential\nlinguistic information in sign languages and plays a crucial role in\ndisambiguating visually similar signs. In this paper, we propose SignClip, a\nnovel framework to improve the accuracy of sign language translation. It fuses\nmanual and non-manual cues, specifically spatial gesture and lip movement\nfeatures. Besides, SignClip introduces a hierarchical contrastive learning\nframework with multi-level alignment objectives, ensuring semantic consistency\nacross sign-lip and visual-text modalities. Extensive experiments on two\nbenchmark datasets, PHOENIX14T and How2Sign, demonstrate the superiority of our\napproach. For example, on PHOENIX14T, in the Gloss-free setting, SignClip\nsurpasses the previous state-of-the-art model SpaMo, improving BLEU-4 from\n24.32 to 24.71, and ROUGE from 46.57 to 48.38.", "AI": {"tldr": "SignClip\u6846\u67b6\u901a\u8fc7\u878d\u5408\u624b\u52bf\u548c\u5507\u90e8\u8fd0\u52a8\u7279\u5f81\uff0c\u5e76\u5f15\u5165\u5206\u5c42\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\uff0c\u63d0\u9ad8\u4e86\u624b\u8bed\u7ffb\u8bd1\u7684\u51c6\u786e\u6027\uff0c\u5728PHOENIX14T\u548cHow2Sign\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u624b\u8bed\u7ffb\u8bd1\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u624b\u52a8\u4fe1\u53f7\uff08\u624b\u52bf\uff09\uff0c\u5ffd\u7565\u4e86\u5507\u90e8\u8fd0\u52a8\u7b49\u975e\u624b\u52a8\u7ebf\u7d22\uff0c\u800c\u5507\u90e8\u8fd0\u52a8\u5728\u4f20\u9012\u8bed\u8a00\u4fe1\u606f\u548c\u533a\u5206\u89c6\u89c9\u4e0a\u76f8\u4f3c\u7684\u624b\u8bed\u65b9\u9762\u8d77\u7740\u81f3\u5173\u91cd\u8981\u7684\u4f5c\u7528\u3002", "method": "SignClip\u6846\u67b6\u878d\u5408\u4e86\u624b\u52a8\u548c\u975e\u624b\u52a8\u7ebf\u7d22\uff08\u7a7a\u95f4\u624b\u52bf\u548c\u5507\u90e8\u8fd0\u52a8\u7279\u5f81\uff09\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u4e2a\u5206\u5c42\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\uff0c\u5305\u542b\u591a\u7ea7\u5bf9\u9f50\u76ee\u6807\uff0c\u4ee5\u786e\u4fdd\u624b\u8bed-\u5507\u8bed\u548c\u89c6\u89c9-\u6587\u672c\u6a21\u6001\u4e4b\u95f4\u7684\u8bed\u4e49\u4e00\u81f4\u6027\u3002", "result": "\u5728PHOENIX14T\u548cHow2Sign\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cSignClip\u7684\u4f18\u8d8a\u6027\u3002\u5728PHOENIX14T\u6570\u636e\u96c6\u7684\u65e0\u8bcd\uff08Gloss-free\uff09\u8bbe\u7f6e\u4e0b\uff0cSignClip\u7684BLEU-4\u4ece24.32\u63d0\u5347\u523024.71\uff0cROUGE\u4ece46.57\u63d0\u5347\u523048.38\uff0c\u8d85\u8fc7\u4e86\u4e4b\u524d\u7684\u6700\u5148\u8fdb\u6a21\u578bSpaMo\u3002", "conclusion": "SignClip\u6846\u67b6\u901a\u8fc7\u878d\u5408\u624b\u52a8\u548c\u975e\u624b\u52a8\u7ebf\u7d22\uff0c\u5e76\u5229\u7528\u5206\u5c42\u5bf9\u6bd4\u5b66\u4e60\uff0c\u6709\u6548\u5730\u63d0\u9ad8\u4e86\u624b\u8bed\u7ffb\u8bd1\u7684\u51c6\u786e\u6027\uff0c\u514b\u670d\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u975e\u624b\u52a8\u7ebf\u7d22\u65b9\u9762\u7684\u4e0d\u8db3\u3002"}}
{"id": "2509.10417", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.10417", "abs": "https://arxiv.org/abs/2509.10417", "authors": ["Christopher Ormerod", "Gitit Kehat"], "title": "Long Context Automated Essay Scoring with Language Models", "comment": "8 pages, 2 figures, 2 tables", "summary": "Transformer-based language models are architecturally constrained to process\ntext of a fixed maximum length. Essays written by higher-grade students\nfrequently exceed the maximum allowed length for many popular open-source\nmodels. A common approach to addressing this issue when using these models for\nAutomated Essay Scoring is to truncate the input text. This raises serious\nvalidity concerns as it undermines the model's ability to fully capture and\nevaluate organizational elements of the scoring rubric, which requires long\ncontexts to assess. In this study, we evaluate several models that incorporate\narchitectural modifications of the standard transformer architecture to\novercome these length limitations using the Kaggle ASAP 2.0 dataset. The models\nconsidered in this study include fine-tuned versions of XLNet, Longformer,\nModernBERT, Mamba, and Llama models.", "AI": {"tldr": "Transformer\u6a21\u578b\u5728\u5904\u7406\u957f\u6587\u672c\u65f6\u5b58\u5728\u957f\u5ea6\u9650\u5236\uff0c\u622a\u65ad\u6587\u672c\u4f1a\u5bfc\u81f4\u8bc4\u4f30\u4e0d\u5b8c\u6574\u3002\u672c\u7814\u7a76\u8bc4\u4f30\u4e86XLNet, Longformer, ModernBERT, Mamba, Llama\u7b49\u6a21\u578b\u5728Kaggle ASAP 2.0\u6570\u636e\u96c6\u4e0a\u7684\u957f\u6587\u672c\u5904\u7406\u80fd\u529b\uff0c\u4ee5\u89e3\u51b3\u81ea\u52a8\u5316\u8bba\u6587\u8bc4\u5206\u4e2d\u7684\u957f\u5ea6\u95ee\u9898\u3002", "motivation": "Transformer\u6a21\u578b\u5728\u5904\u7406\u957f\u6587\u672c\u65f6\u5b58\u5728\u957f\u5ea6\u9650\u5236\uff0c\u622a\u65ad\u6587\u672c\u4f1a\u5bfc\u81f4\u8bc4\u4f30\u4e0d\u5b8c\u6574\uff0c\u8fd9\u5728\u81ea\u52a8\u5316\u8bba\u6587\u8bc4\u5206\u4e2d\u662f\u4e00\u4e2a\u5173\u952e\u95ee\u9898\u3002", "method": "\u8bc4\u4f30\u4e86\u5305\u62ecXLNet, Longformer, ModernBERT, Mamba, Llama\u5728\u5185\u7684\u51e0\u79cd\u6539\u8fdbTransformer\u67b6\u6784\u7684\u6a21\u578b\uff0c\u7528\u4e8e\u5904\u7406\u8d85\u51fa\u6807\u51c6\u957f\u5ea6\u9650\u5236\u7684\u6587\u672c\uff0c\u5e76\u5728Kaggle ASAP 2.0\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u6d4b\u8bd5\u3002", "result": "\u76ee\u524d\u5c1a\u65e0\u5177\u4f53\u7ed3\u679c\uff0c\u4f46\u8bc4\u4f30\u4e86\u591a\u79cd\u6a21\u578b\u5728Kaggle ASAP 2.0\u6570\u636e\u96c6\u4e0a\u7684\u957f\u6587\u672c\u5904\u7406\u80fd\u529b\u3002", "conclusion": "\u76ee\u524d\u5c1a\u65e0\u5177\u4f53\u7ed3\u8bba\uff0c\u4f46\u7814\u7a76\u65e8\u5728\u89e3\u51b3Transformer\u6a21\u578b\u5728\u81ea\u52a8\u5316\u8bba\u6587\u8bc4\u5206\u4e2d\u5904\u7406\u957f\u6587\u672c\u7684\u957f\u5ea6\u9650\u5236\u95ee\u9898\u3002"}}
{"id": "2509.10406", "categories": ["cs.LG", "68W25, 68T50 (primary) 68W40, 68T07 (secondary)", "I.2.6; I.2.7"], "pdf": "https://arxiv.org/pdf/2509.10406", "abs": "https://arxiv.org/abs/2509.10406", "authors": ["Rupert Mitchell", "Kristian Kersting"], "title": "Multipole Semantic Attention: A Fast Approximation of Softmax Attention for Pretraining", "comment": null, "summary": "We present Multipole Semantic Attention (MuSe), an efficient approximation of\nsoftmax attention that combines semantic clustering with multipole expansions\nfrom computational physics. Our method addresses the quadratic computational\ncomplexity of transformers in the context length by clustering queries and keys\nseparately in their learned representation spaces, enabling a hierarchical\ntwo-stage attention mechanism. Unlike prior clustering approaches that group\nonly keys or use unified clustering, we maintain separate clusterings that\nrespect attention's asymmetric treatment of these spaces. We augment\ncentroid-based (monopole) approximations with dipole corrections that capture\ndirectional variance within clusters, preserving richer information during\ntraining. The method operates as a drop-in replacement for standard attention,\nrequiring only hyperparameter specification without architectural\nmodifications. Our approach achieves $\\mathcal{O}(NCD)$ complexity for acausal\nattention with $C$ clusters and $\\mathcal{O}(NCD \\log N)$ for causal attention.\nOn isolated attention layers, we demonstrate $3\\times$ speedup over CUDNN Flash\nAttention at 8k context length, with relative squared errors below 20%. For\ncausal attention, we develop a hierarchical block decomposition that combines\nexact local computation with efficient long-range approximation. In end-to-end\npretraining of a 30M parameter model on book-length texts with 16k context, we\nachieve 12.2% runtime reduction with only 0.36% loss degradation, establishing\nthe viability of multipole approximations for efficient transformer\npretraining.", "AI": {"tldr": "MuSe\u901a\u8fc7\u7ed3\u5408\u8bed\u4e49\u805a\u7c7b\u548c\u591a\u6781\u5c55\u5f00\u6765\u8fd1\u4f3cTransformer\u4e2d\u7684softmax\u6ce8\u610f\u529b\uff0c\u5c06\u8ba1\u7b97\u590d\u6742\u5ea6\u4eceO(N^2)\u964d\u4f4e\u5230O(NCD)\u6216O(NCD log N)\uff0c\u5e76\u5728\u4fdd\u6301\u5c11\u91cf\u7cbe\u5ea6\u635f\u5931\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u52a0\u901f\u3002", "motivation": "Transformer\u6a21\u578b\u5728\u5904\u7406\u957f\u5e8f\u5217\u65f6\u5b58\u5728\u4e8c\u6b21\u8ba1\u7b97\u590d\u6742\u5ea6\u7684\u95ee\u9898\uff0c\u8fd9\u9650\u5236\u4e86\u5b83\u4eec\u5728\u957f\u6587\u672c\u7b49\u5e94\u7528\u4e2d\u7684\u6548\u7387\u3002\u672c\u6587\u65e8\u5728\u63d0\u51fa\u4e00\u79cd\u9ad8\u6548\u7684\u6ce8\u610f\u529b\u673a\u5236\u6765\u89e3\u51b3\u8fd9\u4e00\u74f6\u9888\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMultipole Semantic Attention (MuSe) \u7684\u65b9\u6cd5\u3002\u5b83\u7ed3\u5408\u4e86\u8bed\u4e49\u805a\u7c7b\u548c\u591a\u6781\u5c55\u5f00\u7684\u601d\u60f3\u3002\u5177\u4f53\u6765\u8bf4\uff0cMuSe\u5c06\u67e5\u8be2\uff08queries\uff09\u548c\u952e\uff08keys\uff09\u5728\u5b83\u4eec\u5404\u81ea\u7684\u5b66\u4e60\u8868\u793a\u7a7a\u95f4\u4e2d\u8fdb\u884c\u805a\u7c7b\uff0c\u800c\u4e0d\u662f\u50cf\u4ee5\u524d\u7684\u65b9\u6cd5\u90a3\u6837\u53ea\u805a\u7c7b\u952e\u6216\u7edf\u4e00\u805a\u7c7b\u3002\u8fd9\u79cd\u5206\u79bb\u7684\u805a\u7c7b\u65b9\u5f0f\u80fd\u66f4\u597d\u5730\u9002\u5e94\u6ce8\u610f\u529b\u673a\u5236\u7684\u975e\u5bf9\u79f0\u6027\u3002\u5728\u8fd1\u4f3c\u8fc7\u7a0b\u4e2d\uff0c\u9664\u4e86\u57fa\u4e8e\u8d28\u5fc3\uff08\u5355\u6781\uff09\u7684\u8fd1\u4f3c\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u5076\u6781\u4fee\u6b63\uff0c\u4ee5\u6355\u6349\u805a\u7c7b\u5185\u7684\u65b9\u5411\u65b9\u5dee\uff0c\u4ece\u800c\u4fdd\u7559\u66f4\u4e30\u5bcc\u7684\u4fe1\u606f\u3002\u8be5\u65b9\u6cd5\u53ef\u4ee5\u4f5c\u4e3a\u6807\u51c6\u6ce8\u610f\u529b\u7684\u5373\u63d2\u5373\u7528\u66ff\u4ee3\u54c1\uff0c\u65e0\u9700\u4fee\u6539\u7f51\u7edc\u7ed3\u6784\uff0c\u53ea\u9700\u8c03\u6574\u8d85\u53c2\u6570\u3002", "result": "\u5728\u8ba1\u7b97\u590d\u6742\u5ea6\u65b9\u9762\uff0cMuSe\u5b9e\u73b0\u4e86O(NCD)\uff08\u975e\u56e0\u679c\u6ce8\u610f\u529b\uff0cC\u4e3a\u805a\u7c7b\u6570\uff09\u548cO(NCD log N)\uff08\u56e0\u679c\u6ce8\u610f\u529b\uff09\u7684\u590d\u6742\u5ea6\u3002\u5728\u4e0eCUDNN Flash Attention\u57288k\u4e0a\u4e0b\u6587\u957f\u5ea6\u4e0b\u7684\u5bf9\u6bd4\u5b9e\u9a8c\u4e2d\uff0cMuSe\u5728\u9694\u79bb\u6ce8\u610f\u529b\u5c42\u4e0a\u5b9e\u73b0\u4e863\u500d\u7684\u52a0\u901f\uff0c\u76f8\u5bf9\u5e73\u65b9\u8bef\u5dee\u4f4e\u4e8e20%\u3002\u5bf9\u4e8e\u56e0\u679c\u6ce8\u610f\u529b\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5c40\u90e8\u7cbe\u786e\u8ba1\u7b97\u548c\u957f\u8ddd\u79bb\u9ad8\u6548\u8fd1\u4f3c\u7684\u5c42\u7ea7\u5757\u5206\u89e3\u65b9\u6cd5\u3002\u57283000\u4e07\u53c2\u6570\u6a21\u578b\u300116k\u4e0a\u4e0b\u6587\u957f\u5ea6\u3001\u4e66\u7c4d\u6587\u672c\u7684\u7aef\u5230\u7aef\u9884\u8bad\u7ec3\u4efb\u52a1\u4e2d\uff0cMuSe\u5c06\u8fd0\u884c\u65f6\u95f4\u51cf\u5c11\u4e8612.2%\uff0c\u6a21\u578b\u6027\u80fd\uff08\u635f\u5931\uff09\u4ec5\u4e0b\u964d\u4e860.36%\u3002", "conclusion": "MuSe\u901a\u8fc7\u5f15\u5165\u591a\u6781\u8fd1\u4f3c\uff0c\u80fd\u591f\u663e\u8457\u63d0\u9ad8Transformer\u5904\u7406\u957f\u5e8f\u5217\u7684\u6548\u7387\uff0c\u5e76\u4e14\u5728\u4fdd\u6301\u8f83\u4f4e\u7684\u7cbe\u5ea6\u635f\u5931\u524d\u63d0\u4e0b\uff0c\u4e3aTransformer\u7684\u9884\u8bad\u7ec3\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u884c\u7684\u3001\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.10278", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.10278", "abs": "https://arxiv.org/abs/2509.10278", "authors": ["Vidit Vidit", "Pavel Korshunov", "Amir Mohammadi", "Christophe Ecabert", "Ketan Kotwal", "S\u00e9bastien Marcel"], "title": "Detecting Text Manipulation in Images using Vision Language Models", "comment": "Accepted in Synthetic Realities and Biometric Security Workshop\n  BMVC-2025. For paper page see https://www.idiap.ch/paper/textvlmdet/", "summary": "Recent works have shown the effectiveness of Large Vision Language Models\n(VLMs or LVLMs) in image manipulation detection. However, text manipulation\ndetection is largely missing in these studies. We bridge this knowledge gap by\nanalyzing closed- and open-source VLMs on different text manipulation datasets.\nOur results suggest that open-source models are getting closer, but still\nbehind closed-source ones like GPT- 4o. Additionally, we benchmark image\nmanipulation detection-specific VLMs for text manipulation detection and show\nthat they suffer from the generalization problem. We benchmark VLMs for\nmanipulations done on in-the-wild scene texts and on fantasy ID cards, where\nthe latter mimic a challenging real-world misuse.", "AI": {"tldr": "\u672c\u7814\u7a76\u5206\u6790\u4e86\u95ed\u6e90\u548c\u5f00\u6e90\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u5728\u6587\u672c\u7be1\u6539\u68c0\u6d4b\u65b9\u9762\u7684\u8868\u73b0\uff0c\u5e76\u53d1\u73b0\u95ed\u6e90\u6a21\u578b\uff08\u5982GPT-4o\uff09\u4f18\u4e8e\u5f00\u6e90\u6a21\u578b\u3002\u540c\u65f6\uff0c\u7814\u7a76\u8fd8\u53d1\u73b0\u4e13\u95e8\u7528\u4e8e\u56fe\u50cf\u7be1\u6539\u68c0\u6d4b\u7684VLMs\u5728\u6587\u672c\u7be1\u6539\u68c0\u6d4b\u65b9\u9762\u5b58\u5728\u6cdb\u5316\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u5728\u56fe\u50cf\u7be1\u6539\u68c0\u6d4b\u65b9\u9762\u7684\u5e94\u7528\uff0c\u800c\u5ffd\u7565\u4e86\u6587\u672c\u7be1\u6539\u68c0\u6d4b\u7684\u9886\u57df\u3002\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u77e5\u8bc6\u7a7a\u767d\u3002", "method": "\u5206\u6790\u4e86\u95ed\u6e90\u548c\u5f00\u6e90VLMs\u5728\u4e0d\u540c\u6587\u672c\u7be1\u6539\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u3002\u6b64\u5916\uff0c\u8fd8\u9488\u5bf9\u6587\u672c\u7be1\u6539\u68c0\u6d4b\u5bf9\u4e13\u95e8\u7528\u4e8e\u56fe\u50cf\u7be1\u6539\u68c0\u6d4b\u7684VLMs\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u8bc4\u4f30\u4e86\u6a21\u578b\u5728\u771f\u5b9e\u573a\u666f\u6587\u672c\u548c\u4f2a\u9020\u8eab\u4efd\u8bc1\u4ef6\u4e0a\u7684\u7be1\u6539\u68c0\u6d4b\u80fd\u529b\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5f00\u6e90\u6a21\u578b\u5728\u6587\u672c\u7be1\u6539\u68c0\u6d4b\u65b9\u9762\u6b63\u5728\u8ffd\u8d76\u95ed\u6e90\u6a21\u578b\uff0c\u4f46\u4ecd\u843d\u540e\u4e8eGPT-4o\u7b49\u95ed\u6e90\u6a21\u578b\u3002\u4e13\u95e8\u7528\u4e8e\u56fe\u50cf\u7be1\u6539\u68c0\u6d4b\u7684VLMs\u5728\u6587\u672c\u7be1\u6539\u68c0\u6d4b\u4efb\u52a1\u4e0a\u5b58\u5728\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\u3002\u6a21\u578b\u5728\u771f\u5b9e\u573a\u666f\u6587\u672c\u548c\u4f2a\u9020\u8eab\u4efd\u8bc1\u4ef6\u4e0a\u7684\u8868\u73b0\u4e5f\u5f97\u5230\u4e86\u8bc4\u4f30\u3002", "conclusion": "\u95ed\u6e90VLMs\u5728\u6587\u672c\u7be1\u6539\u68c0\u6d4b\u65b9\u9762\u8868\u73b0\u66f4\u4f18\uff0c\u800c\u5f00\u6e90\u6a21\u578b\u548c\u56fe\u50cf\u7be1\u6539\u68c0\u6d4b\u4e13\u7528VLMs\u4ecd\u6709\u63d0\u5347\u7a7a\u95f4\u3002\u672a\u6765\u7684\u7814\u7a76\u5e94\u5173\u6ce8\u63d0\u5347VLMs\u5728\u6587\u672c\u7be1\u6539\u68c0\u6d4b\u65b9\u9762\u7684\u80fd\u529b\uff0c\u5c24\u5176\u662f\u5728\u6cdb\u5316\u6027\u548c\u9c81\u68d2\u6027\u65b9\u9762\u3002"}}
{"id": "2509.10436", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.10436", "abs": "https://arxiv.org/abs/2509.10436", "authors": ["Shadikur Rahman", "Aroosa Hameed", "Gautam Srivastava", "Syed Muhammad Danish"], "title": "RefactorCoderQA: Benchmarking LLMs for Multi-Domain Coding Question Solutions in Cloud and Edge Deployment", "comment": "12 pages, 5 figures, submitted to IEEE Transactions on Services\n  Computing", "summary": "To optimize the reasoning and problem-solving capabilities of Large Language\nModels (LLMs), we propose a novel cloud-edge collaborative architecture that\nenables a structured, multi-agent prompting framework. This framework comprises\nthree specialized components: GuideLLM, a lightweight model deployed at the\nedge to provide methodological guidance; SolverLLM, a more powerful model\nhosted in the cloud responsible for generating code solutions; and JudgeLLM, an\nautomated evaluator for assessing solution correctness and quality. To evaluate\nand demonstrate the effectiveness of this architecture in realistic settings,\nwe introduce RefactorCoderQA, a comprehensive benchmark designed to evaluate\nand enhance the performance of Large Language Models (LLMs) across multi-domain\ncoding tasks. Motivated by the limitations of existing benchmarks,\nRefactorCoderQA systematically covers various technical domains, including\nSoftware Engineering, Data Science, Machine Learning, and Natural Language\nProcessing, using authentic coding challenges from Stack Overflow. Extensive\nexperiments reveal that our fine-tuned model, RefactorCoder-MoE, achieves\nstate-of-the-art performance, significantly outperforming leading open-source\nand commercial baselines with an overall accuracy of 76.84%. Human evaluations\nfurther validate the interpretability, accuracy, and practical relevance of the\ngenerated solutions. In addition, we evaluate system-level metrics, such as\nthroughput and latency, to gain deeper insights into the performance\ncharacteristics and trade-offs of the proposed architecture.", "AI": {"tldr": "\u901a\u8fc7\u7ed3\u5408\u4e91\u7aef\u548c\u8fb9\u7f18\u8ba1\u7b97\uff0c\u5229\u7528\u591a\u667a\u80fd\u4f53\u63d0\u793a\u6846\u67b6\u6765\u4f18\u5316\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u548c\u89e3\u51b3\u95ee\u9898\u7684\u80fd\u529b\uff0c\u5e76\u5f15\u5165\u4e86RefactorCoderQA\u57fa\u51c6\u548cRefactorCoder-MoE\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u7684\u5c40\u9650\u6027\uff0c\u65e8\u5728\u4f18\u5316\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u63a8\u7406\u548c\u89e3\u51b3\u95ee\u9898\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u4e91\u8fb9\u534f\u540c\u67b6\u6784\uff0c\u5305\u542b\u4e09\u4e2a\u7ec4\u4ef6\uff1a\u8fb9\u7f18\u7684GuideLLM\uff08\u63d0\u4f9b\u65b9\u6cd5\u8bba\u6307\u5bfc\uff09\u3001\u4e91\u7aef\u7684SolverLLM\uff08\u751f\u6210\u4ee3\u7801\u89e3\u51b3\u65b9\u6848\uff09\u548cJudgeLLM\uff08\u8bc4\u4f30\u89e3\u51b3\u65b9\u6848\u7684\u6b63\u786e\u6027\u548c\u8d28\u91cf\uff09\u3002\u5f15\u5165\u4e86RefactorCoderQA\u57fa\u51c6\uff0c\u8be5\u57fa\u51c6\u6db5\u76d6\u8f6f\u4ef6\u5de5\u7a0b\u3001\u6570\u636e\u79d1\u5b66\u3001\u673a\u5668\u5b66\u4e60\u548c\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7b49\u591a\u4e2a\u9886\u57df\uff0c\u5e76\u4f7f\u7528\u6765\u81eaStack Overflow\u7684\u771f\u5b9e\u7f16\u7801\u6311\u6218\u3002", "result": "\u5728RefactorCoderQA\u57fa\u51c6\u4e0a\uff0c\u7ecf\u8fc7\u5fae\u8c03\u7684RefactorCoder-MoE\u6a21\u578b\u53d6\u5f97\u4e8676.84%\u7684\u51c6\u786e\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u5f00\u6e90\u548c\u5546\u4e1a\u57fa\u7ebf\u3002\u4eba\u7c7b\u8bc4\u4f30\u9a8c\u8bc1\u4e86\u751f\u6210\u89e3\u51b3\u65b9\u6848\u7684\u53ef\u89e3\u91ca\u6027\u3001\u51c6\u786e\u6027\u548c\u5b9e\u8df5\u76f8\u5173\u6027\u3002\u8fd8\u8bc4\u4f30\u4e86\u541e\u5410\u91cf\u548c\u5ef6\u8fdf\u7b49\u7cfb\u7edf\u7ea7\u6307\u6807\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u4e91\u8fb9\u534f\u540c\u67b6\u6784\u80fd\u591f\u6709\u6548\u4f18\u5316LLMs\u7684\u63a8\u7406\u548c\u89e3\u51b3\u95ee\u9898\u7684\u80fd\u529b\uff0cRefactorCoderQA\u57fa\u51c6\u548cRefactorCoder-MoE\u6a21\u578b\u5728\u8bc4\u4f30\u548c\u63d0\u5347LLMs\u7684\u7f16\u7801\u80fd\u529b\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2509.10419", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10419", "abs": "https://arxiv.org/abs/2509.10419", "authors": ["Francesco Vitale", "Tommaso Zoppi", "Francesco Flammini", "Nicola Mazzocca"], "title": "Run-Time Monitoring of ERTMS/ETCS Control Flow by Process Mining", "comment": "Accepted to the 6th International Conference on Reliability, Safety,\n  and Security of Railway Systems (RSSRail2025)", "summary": "Ensuring the resilience of computer-based railways is increasingly crucial to\naccount for uncertainties and changes due to the growing complexity and\ncriticality of those systems. Although their software relies on strict\nverification and validation processes following well-established best-practices\nand certification standards, anomalies can still occur at run-time due to\nresidual faults, system and environmental modifications that were unknown at\ndesign-time, or other emergent cyber-threat scenarios. This paper explores\nrun-time control-flow anomaly detection using process mining to enhance the\nresilience of ERTMS/ETCS L2 (European Rail Traffic Management System / European\nTrain Control System Level 2). Process mining allows learning the actual\ncontrol flow of the system from its execution traces, thus enabling run-time\nmonitoring through online conformance checking. In addition, anomaly\nlocalization is performed through unsupervised machine learning to link\nrelevant deviations to critical system components. We test our approach on a\nreference ERTMS/ETCS L2 scenario, namely the RBC/RBC Handover, to show its\ncapability to detect and localize anomalies with high accuracy, efficiency, and\nexplainability.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4f7f\u7528\u6d41\u7a0b\u6316\u6398\u6280\u672f\u6765\u68c0\u6d4b\u548c\u5b9a\u4f4d\u8ba1\u7b97\u673a\u5316\u94c1\u8def\u7cfb\u7edf\u4e2d ERTMS/ETCS L2 \u7684\u8fd0\u884c\u65f6\u63a7\u5236\u6d41\u5f02\u5e38\uff0c\u4ee5\u63d0\u9ad8\u7cfb\u7edf\u7684\u5f39\u6027\u3002", "motivation": "\u968f\u7740\u8ba1\u7b97\u673a\u5316\u94c1\u8def\u7cfb\u7edf\u590d\u6742\u6027\u548c\u5173\u952e\u6027\u7684\u589e\u957f\uff0c\u786e\u4fdd\u5176\u5f39\u6027\u81f3\u5173\u91cd\u8981\uff0c\u56e0\u4e3a\u5373\u4f7f\u7ecf\u8fc7\u4e25\u683c\u7684\u9a8c\u8bc1\u548c\u786e\u8ba4\uff0c\u8fd0\u884c\u65f6\u4ecd\u53ef\u80fd\u51fa\u73b0\u5f02\u5e38\u3002", "method": "\u901a\u8fc7\u5206\u6790\u7cfb\u7edf\u6267\u884c\u8f68\u8ff9\u6765\u5b66\u4e60\u5b9e\u9645\u63a7\u5236\u6d41\uff0c\u5e76\u4f7f\u7528\u5728\u7ebf\u7b26\u5408\u6027\u68c0\u67e5\u8fdb\u884c\u8fd0\u884c\u65f6\u76d1\u63a7\u3002\u901a\u8fc7\u65e0\u76d1\u7763\u673a\u5668\u5b66\u4e60\u5b9e\u73b0\u5f02\u5e38\u5b9a\u4f4d\uff0c\u5c06\u504f\u5dee\u94fe\u63a5\u5230\u5173\u952e\u7cfb\u7edf\u7ec4\u4ef6\u3002", "result": "\u5728 RBC/RBC \u4ea4\u63a5\u573a\u666f\u7684 ERTMS/ETCS L2 \u53c2\u8003\u573a\u666f\u4e2d\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u9ad8\u7cbe\u5ea6\u3001\u9ad8\u6548\u7387\u4e14\u53ef\u89e3\u91ca\u5730\u68c0\u6d4b\u548c\u5b9a\u4f4d\u5f02\u5e38\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684\u57fa\u4e8e\u6d41\u7a0b\u6316\u6398\u7684\u8fd0\u884c\u65f6\u5f02\u5e38\u68c0\u6d4b\u548c\u5b9a\u4f4d\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63d0\u9ad8 ERTMS/ETCS L2 \u7cfb\u7edf\u7684\u5f39\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2509.10282", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10282", "abs": "https://arxiv.org/abs/2509.10282", "authors": ["Gang Li", "Tianjiao Chen", "Mingle Zhou", "Min Li", "Delong Han", "Jin Wan"], "title": "MCL-AD: Multimodal Collaboration Learning for Zero-Shot 3D Anomaly Detection", "comment": "Page 14, 5 pictures", "summary": "Zero-shot 3D (ZS-3D) anomaly detection aims to identify defects in 3D objects\nwithout relying on labeled training data, making it especially valuable in\nscenarios constrained by data scarcity, privacy, or high annotation cost.\nHowever, most existing methods focus exclusively on point clouds, neglecting\nthe rich semantic cues available from complementary modalities such as RGB\nimages and texts priors. This paper introduces MCL-AD, a novel framework that\nleverages multimodal collaboration learning across point clouds, RGB images,\nand texts semantics to achieve superior zero-shot 3D anomaly detection.\nSpecifically, we propose a Multimodal Prompt Learning Mechanism (MPLM) that\nenhances the intra-modal representation capability and inter-modal\ncollaborative learning by introducing an object-agnostic decoupled text prompt\nand a multimodal contrastive loss. In addition, a collaborative modulation\nmechanism (CMM) is proposed to fully leverage the complementary representations\nof point clouds and RGB images by jointly modulating the RGB image-guided and\npoint cloud-guided branches. Extensive experiments demonstrate that the\nproposed MCL-AD framework achieves state-of-the-art performance in ZS-3D\nanomaly detection.", "AI": {"tldr": "MCL-AD\u6846\u67b6\u5229\u7528\u70b9\u4e91\u3001RGB\u56fe\u50cf\u548c\u6587\u672c\u4fe1\u606f\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u534f\u4f5c\u5b66\u4e60\uff0c\u5b9e\u73b0\u4e86\u96f6\u6837\u672c3D\u5f02\u5e38\u68c0\u6d4b\u7684\u6700\u4f18\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u96f6\u6837\u672c3D\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u4e3b\u8981\u96c6\u4e2d\u5728\u70b9\u4e91\uff0c\u5ffd\u7565\u4e86RGB\u56fe\u50cf\u548c\u6587\u672c\u5148\u9a8c\u7b49\u4e92\u8865\u6a21\u6001\u7684\u4e30\u5bcc\u8bed\u4e49\u7ebf\u7d22\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u5229\u7528\u591a\u6a21\u6001\u4fe1\u606f\u6765\u63d0\u5347\u68c0\u6d4b\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728\u6570\u636e\u7a00\u7f3a\u3001\u9690\u79c1\u4fdd\u62a4\u6216\u6807\u6ce8\u6210\u672c\u9ad8\u6602\u7684\u573a\u666f\u4e0b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMCL-AD\u7684\u65b0\u6846\u67b6\uff0c\u5b83\u5229\u7528\u70b9\u4e91\u3001RGB\u56fe\u50cf\u548c\u6587\u672c\u8bed\u4e49\u8fdb\u884c\u591a\u6a21\u6001\u534f\u4f5c\u5b66\u4e60\u3002\u8be5\u6846\u67b6\u5305\u542b\u4e00\u4e2a\u591a\u6a21\u6001\u63d0\u793a\u5b66\u4e60\u673a\u5236\uff08MPLM\uff09\uff0c\u901a\u8fc7\u5f15\u5165\u4e0e\u7269\u4f53\u65e0\u5173\u7684\u89e3\u8026\u6587\u672c\u63d0\u793a\u548c\u591a\u6a21\u6001\u5bf9\u6bd4\u635f\u5931\u6765\u589e\u5f3a\u5355\u6a21\u6001\u8868\u793a\u80fd\u529b\u548c\u8de8\u6a21\u6001\u534f\u4f5c\u5b66\u4e60\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e00\u4e2a\u534f\u4f5c\u8c03\u5236\u673a\u5236\uff08CMM\uff09\uff0c\u901a\u8fc7\u8054\u5408\u8c03\u5236RGB\u56fe\u50cf\u5f15\u5bfc\u548c\u70b9\u4e91\u5f15\u5bfc\u7684\u5206\u652f\uff0c\u5145\u5206\u5229\u7528\u70b9\u4e91\u548cRGB\u56fe\u50cf\u7684\u4e92\u8865\u8868\u793a\u3002", "result": "MCL-AD\u6846\u67b6\u5728\u96f6\u6837\u672c3D\u5f02\u5e38\u68c0\u6d4b\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "MCL-AD\u6846\u67b6\u901a\u8fc7\u591a\u6a21\u6001\u534f\u4f5c\u5b66\u4e60\uff0c\u6709\u6548\u878d\u5408\u4e86\u70b9\u4e91\u3001RGB\u56fe\u50cf\u548c\u6587\u672c\u4fe1\u606f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u96f6\u6837\u672c3D\u5f02\u5e38\u68c0\u6d4b\u7684\u6027\u80fd\uff0c\u4e3a\u8be5\u9886\u57df\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2509.10446", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.10446", "abs": "https://arxiv.org/abs/2509.10446", "authors": ["Rui Lu", "Zhenyu Hou", "Zihan Wang", "Hanchen Zhang", "Xiao Liu", "Yujiang Li", "Shi Feng", "Jie Tang", "Yuxiao Dong"], "title": "DeepDive: Advancing Deep Search Agents with Knowledge Graphs and Multi-Turn RL", "comment": null, "summary": "Augmenting large language models (LLMs) with browsing tools substantially\nimproves their potential as deep search agents to solve complex, real-world\ntasks. Yet, open LLMs still perform poorly in such settings due to limited\nlong-horizon reasoning capacity with browsing tools and the lack of\nsufficiently difficult supervised data. To address these challenges, we present\nDeepDive to advance deep search agents. First, we propose a strategy to\nautomatically synthesize complex, difficult, and hard-to-find questions from\nopen knowledge graphs. Second, we apply end-to-end multi-turn reinforcement\nlearning (RL) to enhance LLMs' long-horizon reasoning with deep search.\nExperiments show that DeepDive-32B achieves a new open-source competitive\nresult on BrowseComp, outperforming WebSailor, DeepSeek-R1-Browse, and\nSearch-o1. We demonstrate that multi-turn RL training improves deep search\nability and significantly contributes to the performance improvements across\nmultiple benchmarks. We observe that DeepDive enables test-time scaling of tool\ncalls and parallel sampling. All datasets, models, and code are publicly\navailable at https://github.com/THUDM/DeepDive.", "AI": {"tldr": "DeepDive\u901a\u8fc7\u81ea\u52a8\u5408\u6210\u590d\u6742\u95ee\u9898\u548c\u7aef\u5230\u7aef\u591a\u8f6e\u5f3a\u5316\u5b66\u4e60\u6765\u589e\u5f3aLLMs\u7684\u641c\u7d22\u80fd\u529b\uff0c\u5728BrowseComp\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u65b0\u7684\u5f00\u6e90SOTA\u7ed3\u679c\u3002", "motivation": "\u73b0\u6709\u7684\u5f00\u653eLLMs\u5728\u7ed3\u5408\u6d4f\u89c8\u5de5\u5177\u4ee5\u89e3\u51b3\u590d\u6742\u73b0\u5b9e\u4e16\u754c\u4efb\u52a1\u65f6\uff0c\u7531\u4e8e\u957f\u8fdc\u63a8\u7406\u80fd\u529b\u6709\u9650\u548c\u7f3a\u4e4f\u8db3\u591f\u96be\u5ea6\u7684\u76d1\u7763\u6570\u636e\uff0c\u8868\u73b0\u4e0d\u4f73\u3002", "method": "1. \u81ea\u52a8\u5408\u6210\u590d\u6742\u3001\u56f0\u96be\u4e14\u96be\u4ee5\u627e\u5230\u7684\u95ee\u9898\u3002 2. \u5e94\u7528\u7aef\u5230\u7aef\u591a\u8f6e\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u6765\u589e\u5f3aLLMs\u7684\u6df1\u5ea6\u641c\u7d22\u957f\u8fdc\u63a8\u7406\u80fd\u529b\u3002", "result": "DeepDive-32B\u5728BrowseComp\u4e0a\u53d6\u5f97\u4e86\u65b0\u7684\u5f00\u6e90SOTA\u7ed3\u679c\uff0c\u4f18\u4e8eWebSailor\u3001DeepSeek-R1-Browse\u548cSearch-o1\u3002\u591a\u8f6eRL\u8bad\u7ec3\u63d0\u5347\u4e86\u6df1\u5ea6\u641c\u7d22\u80fd\u529b\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u9ad8\u4e86\u6027\u80fd\u3002DeepDive\u8fd8\u652f\u6301\u6d4b\u8bd5\u65f6\u5de5\u5177\u8c03\u7528\u6269\u5c55\u548c\u5e76\u884c\u91c7\u6837\u3002", "conclusion": "DeepDive\u901a\u8fc7\u5176\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u5f00\u653eLLMs\u5728\u4f5c\u4e3a\u6df1\u5ea6\u641c\u7d22\u4ee3\u7406\u65f6\u7684\u6027\u80fd\uff0c\u89e3\u51b3\u4e86\u957f\u8fdc\u63a8\u7406\u548c\u6570\u636e\u7a00\u758f\u6027\u6311\u6218\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u4f18\u5f02\u6210\u679c\u3002"}}
{"id": "2509.10439", "categories": ["cs.LG", "math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2509.10439", "abs": "https://arxiv.org/abs/2509.10439", "authors": ["Ahmed Khaled", "Satyen Kale", "Arthur Douillard", "Chi Jin", "Rob Fergus", "Manzil Zaheer"], "title": "Understanding Outer Optimizers in Local SGD: Learning Rates, Momentum, and Acceleration", "comment": null, "summary": "Modern machine learning often requires training with large batch size,\ndistributed data, and massively parallel compute hardware (like mobile and\nother edge devices or distributed data centers). Communication becomes a major\nbottleneck in such settings but methods like Local Stochastic Gradient Descent\n(Local SGD) show great promise in reducing this additional communication\noverhead. Local SGD consists of three parts: a local optimization process, an\naggregation mechanism, and an outer optimizer that uses the aggregated updates\nfrom the nodes to produce a new model. While there exists an extensive\nliterature on understanding the impact of hyperparameters in the local\noptimization process, the choice of outer optimizer and its hyperparameters is\nless clear. We study the role of the outer optimizer in Local SGD, and prove\nnew convergence guarantees for the algorithm. In particular, we show that\ntuning the outer learning rate allows us to (a) trade off between optimization\nerror and stochastic gradient noise variance, and (b) make up for ill-tuning of\nthe inner learning rate. Our theory suggests that the outer learning rate\nshould sometimes be set to values greater than $1$. We extend our results to\nsettings where we use momentum in the outer optimizer, and we show a similar\nrole for the momentum-adjusted outer learning rate. We also study acceleration\nin the outer optimizer and show that it improves the convergence rate as a\nfunction of the number of communication rounds, improving upon the convergence\nrate of prior algorithms that apply acceleration locally. Finally, we also\nintroduce a novel data-dependent analysis of Local SGD that yields further\ninsights on outer learning rate tuning. We conduct comprehensive experiments\nwith standard language models and various outer optimizers to validate our\ntheory.", "AI": {"tldr": "Local SGD\u7684\u6536\u655b\u6027\u7814\u7a76\uff0c\u91cd\u70b9\u5173\u6ce8\u5916\u5c42\u4f18\u5316\u5668\u53ca\u5176\u8d85\u53c2\u6570\u7684\u5f71\u54cd\u3002", "motivation": "\u73b0\u6709\u5173\u4e8eLocal SGD\u7684\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u5185\u5c42\u4f18\u5316\u8fc7\u7a0b\u7684\u8d85\u53c2\u6570\uff0c\u5bf9\u5916\u5c42\u4f18\u5316\u5668\u7684\u9009\u62e9\u53ca\u5176\u8d85\u53c2\u6570\u7684\u7814\u7a76\u4e0d\u8db3\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u7814\u7a76\u5916\u5c42\u4f18\u5316\u5668\uff08\u5305\u62ec\u5b66\u4e60\u7387\u548c\u52a8\u91cf\uff09\u5bf9Local SGD\u7b97\u6cd5\u6536\u655b\u6027\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u65b0\u7684\u6570\u636e\u76f8\u5173\u6027\u5206\u6790\u65b9\u6cd5\u3002", "result": "\u8bc1\u660e\u4e86\u901a\u8fc7\u8c03\u6574\u5916\u5c42\u5b66\u4e60\u7387\u53ef\u4ee5\u5e73\u8861\u4f18\u5316\u8bef\u5dee\u548c\u68af\u5ea6\u566a\u58f0\u65b9\u5dee\uff0c\u5f25\u8865\u5185\u5c42\u5b66\u4e60\u7387\u4e0d\u4f73\u7684\u5f71\u54cd\u3002\u7406\u8bba\u8868\u660e\u5916\u5c42\u5b66\u4e60\u7387\u6709\u65f6\u53ef\u8bbe\u4e3a\u5927\u4e8e1\u3002\u7814\u7a76\u4e86\u52a8\u91cf\u548c\u52a0\u901f\u5728\u5916\u5c42\u4f18\u5316\u5668\u4e2d\u7684\u4f5c\u7528\uff0c\u5e76\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "conclusion": "\u5916\u5c42\u4f18\u5316\u5668\u7684\u9009\u62e9\u548c\u8d85\u53c2\u6570\u8c03\u6574\u5bf9\u4e8eLocal SGD\u7b97\u6cd5\u7684\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u5408\u7406\u7684\u8c03\u6574\u53ef\u4ee5\u5e26\u6765\u7406\u8bba\u548c\u5b9e\u8df5\u4e0a\u7684\u6539\u8fdb\u3002"}}
{"id": "2509.10298", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.10298", "abs": "https://arxiv.org/abs/2509.10298", "authors": ["Laith Nayal", "Mahmoud Mousatat", "Bader Rasheed"], "title": "Adversarial robustness through Lipschitz-Guided Stochastic Depth in Neural Networks", "comment": "8 pages, 2 tables", "summary": "Deep neural networks and Vision Transformers achieve state-of-the-art\nperformance in computer vision but are highly vulnerable to adversarial\nperturbations. Standard defenses often incur high computational cost or lack\nformal guarantees. We propose a Lipschitz-guided stochastic depth (DropPath)\nmethod, where drop probabilities increase with depth to control the effective\nLipschitz constant of the network. This approach regularizes deeper layers,\nimproving robustness while preserving clean accuracy and reducing computation.\nExperiments on CIFAR-10 with ViT-Tiny show that our custom depth-dependent\nschedule maintains near-baseline clean accuracy, enhances robustness under\nFGSM, PGD-20, and AutoAttack, and significantly reduces FLOPs compared to\nbaseline and linear DropPath schedules.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e Lipshitz \u7ea6\u675f\u7684\u968f\u673a\u6df1\u5ea6\uff08DropPath\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u589e\u52a0\u6df1\u5c42\u7f51\u7edc\u7684 drop \u6982\u7387\u6765\u63a7\u5236\u7f51\u7edc\u7684 Lipshitz \u5e38\u6570\uff0c\u4ece\u800c\u63d0\u9ad8\u7f51\u7edc\u7684\u9c81\u68d2\u6027\u5e76\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u548c Vision Transformers \u5c3d\u7ba1\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u9886\u57df\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u6781\u6613\u53d7\u5230\u5bf9\u6297\u6027\u6270\u52a8\u7684\u653b\u51fb\u3002\u73b0\u6709\u7684\u9632\u5fa1\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u6216\u7f3a\u4e4f\u4e25\u683c\u7684\u7406\u8bba\u4fdd\u8bc1\u3002", "method": "\u63d0\u51fa\u4e00\u79cd Lipshitz \u5f15\u5bfc\u7684\u968f\u673a\u6df1\u5ea6\uff08DropPath\uff09\u65b9\u6cd5\uff0c\u5176\u4e2d drop \u6982\u7387\u968f\u6df1\u5ea6\u589e\u52a0\u800c\u589e\u52a0\uff0c\u4ee5\u63a7\u5236\u7f51\u7edc\u7684\u6709\u6548 Lipshitz \u5e38\u6570\u3002\u8be5\u65b9\u6cd5\u5bf9\u6df1\u5c42\u7f51\u7edc\u8fdb\u884c\u6b63\u5219\u5316\uff0c\u5728\u63d0\u9ad8\u9c81\u68d2\u6027\u7684\u540c\u65f6\u4fdd\u6301\u4e86\u51c6\u786e\u6027\u5e76\u964d\u4f4e\u4e86\u8ba1\u7b97\u91cf\u3002", "result": "\u5728 CIFAR-10 \u6570\u636e\u96c6\u548c ViT-Tiny \u6a21\u578b\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u63a5\u8fd1\u57fa\u7ebf\u6c34\u5e73\u7684\u51c6\u786e\u5ea6\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5728 FGSM\u3001PGD-20 \u548c AutoAttack \u653b\u51fb\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u4e14\u4e0e\u57fa\u7ebf\u548c\u7ebf\u6027 DropPath \u76f8\u6bd4\uff0c\u8ba1\u7b97\u91cf\uff08FLOPs\uff09\u663e\u8457\u964d\u4f4e\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684 Lipshitz \u5f15\u5bfc\u7684\u968f\u673a\u6df1\u5ea6\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63d0\u5347 Vision Transformer \u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1\u4e2d\u7684\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u51c6\u786e\u7387\u5e76\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002"}}
{"id": "2509.10452", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10452", "abs": "https://arxiv.org/abs/2509.10452", "authors": ["Akshat Pandey", "Karun Kumar", "Raphael Tang"], "title": "WhisTLE: Deeply Supervised, Text-Only Domain Adaptation for Pretrained Speech Recognition Transformers", "comment": "5 pages, 2 figures", "summary": "Pretrained automatic speech recognition (ASR) models such as Whisper perform\nwell but still need domain adaptation to handle unseen vocabulary and parlance.\nIn many real-world settings, collecting speech data is impractical,\nnecessitating text-only adaptation. We propose WhisTLE, a deeply supervised,\ntext-only adaptation method for pretrained encoder-decoder ASR models. WhisTLE\ntrains a variational autoencoder (VAE) to model encoder outputs from text and\nfine-tunes the decoder using the learned text-to-latent encoder, optionally\ncombined with text-to-speech (TTS) adaptation. At inference, the original\nencoder is restored, incurring no extra runtime cost. Across four out-of-domain\ndatasets and four ASR models, WhisTLE with TTS reduces word error rate (WER) by\n12.3% relative to TTS-only adaptation and outperforms all non-WhisTLE baselines\nin 27 of 32 scenarios.", "AI": {"tldr": "WhisTLE\u662f\u4e00\u79cd\u6587\u672c\u9002\u5e94\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bad\u7ec3VAE\u6765\u5b66\u4e60\u6587\u672c\u7684\u6f5c\u5728\u8868\u793a\uff0c\u5e76\u5fae\u8c03\u89e3\u7801\u5668\uff0c\u4ee5\u6539\u8fdbASR\u6a21\u578b\u5728\u7279\u5b9a\u9886\u57df\u4e0a\u7684\u8868\u73b0\uff0c\u65e0\u9700\u989d\u5916\u7684\u8fd0\u884c\u65f6\u6210\u672c\u3002", "motivation": "\u73b0\u6709\u7684\u9884\u8bad\u7ec3ASR\u6a21\u578b\uff08\u5982Whisper\uff09\u5728\u5904\u7406\u7279\u5b9a\u9886\u57df\u7684\u8bcd\u6c47\u548c\u8868\u8fbe\u65f6\u4ecd\u9700\u8fdb\u884c\u9886\u57df\u81ea\u9002\u5e94\uff0c\u4f46\u5b9e\u9645\u6536\u96c6\u8bed\u97f3\u6570\u636e\u7684\u65b9\u6cd5\u5f80\u5f80\u4e0d\u5207\u5b9e\u9645\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u4ec5\u57fa\u4e8e\u6587\u672c\u7684\u9002\u5e94\u65b9\u6cd5\u3002", "method": "WhisTLE\u8bad\u7ec3\u4e00\u4e2a\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VAE\uff09\u6765\u6a21\u62df\u6765\u81ea\u6587\u672c\u7684\u7f16\u7801\u5668\u8f93\u51fa\uff0c\u5e76\u4f7f\u7528\u5b66\u4e60\u5230\u7684\u6587\u672c\u5230\u6f5c\u5728\u8868\u793a\u7684\u7f16\u7801\u5668\u6765\u5fae\u8c03\u89e3\u7801\u5668\uff0c\u8fd8\u53ef\u4ee5\u9009\u62e9\u6027\u5730\u7ed3\u5408\u6587\u672c\u5230\u8bed\u97f3\uff08TTS\uff09\u9002\u5e94\u3002\u5728\u63a8\u7406\u65f6\uff0c\u6062\u590d\u539f\u59cb\u7f16\u7801\u5668\uff0c\u4e0d\u4ea7\u751f\u989d\u5916\u7684\u8fd0\u884c\u65f6\u6210\u672c\u3002", "result": "\u5728\u56db\u4e2a\u9886\u57df\u5916\u7684\u6570\u636e\u96c6\u548c\u56db\u4e2aASR\u6a21\u578b\u4e0a\uff0c\u4e0e\u4ec5\u4f7f\u7528TTS\u7684\u65b9\u6cd5\u76f8\u6bd4\uff0c\u4f7f\u7528TTS\u7684WhisTLE\u5c06\u8bcd\u9519\u8bef\u7387\uff08WER\uff09\u76f8\u5bf9\u964d\u4f4e\u4e8612.3%\uff0c\u5e76\u572832\u79cd\u573a\u666f\u4e2d\u768427\u79cd\u4f18\u4e8e\u6240\u6709\u975eWhisTLE\u57fa\u7ebf\u3002", "conclusion": "WhisTLE\u662f\u4e00\u79cd\u6709\u6548\u7684\u3001\u4ec5\u57fa\u4e8e\u6587\u672c\u7684ASR\u6a21\u578b\u9886\u57df\u81ea\u9002\u5e94\u65b9\u6cd5\uff0c\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u6a21\u578b\u5728\u7279\u5b9a\u9886\u57df\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u4e14\u5728\u63a8\u7406\u65f6\u6ca1\u6709\u989d\u5916\u7684\u8ba1\u7b97\u5f00\u9500\u3002"}}
{"id": "2509.10310", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.10310", "abs": "https://arxiv.org/abs/2509.10310", "authors": ["Evan Murphy", "Marco Viola", "Vladimir A. Krylov"], "title": "A Stochastic Birth-and-Death Approach for Street Furniture Geolocation in Urban Environments", "comment": "Accepted for publication in the Proceedings of the 27th Irish Machine\n  Vision and Image Processing Conference (IMVIP 2025)", "summary": "In this paper we address the problem of precise geolocation of street\nfurniture in complex urban environments, which is a critical task for effective\nmonitoring and maintenance of public infrastructure by local authorities and\nprivate stakeholders. To this end, we propose a probabilistic framework based\non energy maps that encode the spatial likelihood of object locations.\nRepresenting the energy in a map-based geopositioned format allows the\noptimisation process to seamlessly integrate external geospatial information,\nsuch as GIS layers, road maps, or placement constraints, which improves\ncontextual awareness and localisation accuracy. A stochastic birth-and-death\noptimisation algorithm is introduced to infer the most probable configuration\nof assets. We evaluate our approach using a realistic simulation informed by a\ngeolocated dataset of street lighting infrastructure in Dublin city centre,\ndemonstrating its potential for scalable and accurate urban asset mapping. The\nimplementation of the algorithm will be made available in the GitHub repository\nhttps://github.com/EMurphy0108/SBD_Street_Furniture.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u80fd\u91cf\u56fe\u7684\u6982\u7387\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u590d\u6742\u7684\u57ce\u5e02\u73af\u5883\u4e2d\u7cbe\u786e\u5730\u5bf9\u8857\u9053\u8bbe\u65bd\u8fdb\u884c\u5730\u7406\u5b9a\u4f4d\uff0c\u5e76\u4f7f\u7528\u968f\u673a\u751f\u706d\u4f18\u5316\u7b97\u6cd5\u6765\u63a8\u65ad\u6700\u53ef\u80fd\u7684\u8d44\u4ea7\u914d\u7f6e\u3002", "motivation": "\u4e3a\u4e86\u6709\u6548\u76d1\u63a7\u548c\u7ef4\u62a4\u516c\u5171\u57fa\u7840\u8bbe\u65bd\uff0c\u9700\u8981\u7cbe\u786e\u7684\u8857\u9053\u8bbe\u65bd\u5730\u7406\u5b9a\u4f4d\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u80fd\u91cf\u56fe\u7684\u6982\u7387\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5bf9\u7269\u4f53\u4f4d\u7f6e\u7684\u7a7a\u95f4\u53ef\u80fd\u6027\u8fdb\u884c\u7f16\u7801\u3002\u80fd\u91cf\u56fe\u7684\u57fa\u4e8e\u5730\u56fe\u7684\u5730\u7406\u5b9a\u4f4d\u683c\u5f0f\u53ef\u4ee5\u65e0\u7f1d\u96c6\u6210\u5916\u90e8\u5730\u7406\u7a7a\u95f4\u4fe1\u606f\uff08\u5982GIS\u56fe\u5c42\u3001\u9053\u8def\u56fe\u6216\u653e\u7f6e\u7ea6\u675f\uff09\uff0c\u4ee5\u63d0\u9ad8\u4e0a\u4e0b\u6587\u611f\u77e5\u548c\u5b9a\u4f4d\u51c6\u786e\u6027\u3002\u5f15\u5165\u4e86\u4e00\u79cd\u968f\u673a\u751f\u706d\u4f18\u5316\u7b97\u6cd5\u6765\u63a8\u65ad\u6700\u53ef\u80fd\u7684\u8d44\u4ea7\u914d\u7f6e\u3002", "result": "\u4f7f\u7528\u7231\u5c14\u5170\u90fd\u67cf\u6797\u5e02\u4e2d\u5fc3\u8857\u9053\u7167\u660e\u57fa\u7840\u8bbe\u65bd\u7684\u5730\u7406\u5b9a\u4f4d\u6570\u636e\u96c6\u8fdb\u884c\u73b0\u5b9e\u6a21\u62df\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u53ef\u6269\u5c55\u548c\u51c6\u786e\u7684\u57ce\u5e02\u8d44\u4ea7\u6d4b\u7ed8\u65b9\u9762\u7684\u6f5c\u529b\u3002", "conclusion": "\u8be5\u6982\u7387\u6846\u67b6\u548c\u4f18\u5316\u7b97\u6cd5\u80fd\u591f\u5bf9\u57ce\u5e02\u73af\u5883\u4e2d\u7684\u8857\u9053\u8bbe\u65bd\u8fdb\u884c\u7cbe\u786e\u7684\u5730\u7406\u5b9a\u4f4d\uff0c\u5e76\u6709\u53ef\u80fd\u6269\u5c55\u5230\u5176\u4ed6\u57ce\u5e02\u8d44\u4ea7\u6d4b\u7ed8\u4efb\u52a1\u3002"}}
{"id": "2509.10312", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.10312", "abs": "https://arxiv.org/abs/2509.10312", "authors": ["Zhixin Zheng", "Xinyu Wang", "Chang Zou", "Shaobo Wang", "Linfeng Zhang"], "title": "Compute Only 16 Tokens in One Timestep: Accelerating Diffusion Transformers with Cluster-Driven Feature Caching", "comment": "11 pages, 11 figures; Accepted by ACM MM2025; Mainly focus on feature\n  caching for diffusion transformers acceleration", "summary": "Diffusion transformers have gained significant attention in recent years for\ntheir ability to generate high-quality images and videos, yet still suffer from\na huge computational cost due to their iterative denoising process. Recently,\nfeature caching has been introduced to accelerate diffusion transformers by\ncaching the feature computation in previous timesteps and reusing it in the\nfollowing timesteps, which leverage the temporal similarity of diffusion models\nwhile ignoring the similarity in the spatial dimension. In this paper, we\nintroduce Cluster-Driven Feature Caching (ClusCa) as an orthogonal and\ncomplementary perspective for previous feature caching. Specifically, ClusCa\nperforms spatial clustering on tokens in each timestep, computes only one token\nin each cluster and propagates their information to all the other tokens, which\nis able to reduce the number of tokens by over 90%. Extensive experiments on\nDiT, FLUX and HunyuanVideo demonstrate its effectiveness in both text-to-image\nand text-to-video generation. Besides, it can be directly applied to any\ndiffusion transformer without requirements for training. For instance, ClusCa\nachieves 4.96x acceleration on FLUX with an ImageReward of 99.49%, surpassing\nthe original model by 0.51%. The code is available at\nhttps://github.com/Shenyi-Z/Cache4Diffusion.", "AI": {"tldr": "\u901a\u8fc7\u7a7a\u95f4\u805a\u7c7b\u51cf\u5c1190%\u4ee5\u4e0a\u7684token\uff0c\u5b9e\u73b0\u52a0\u901f", "motivation": "\u76ee\u524d\u7684\u6269\u6563\u6a21\u578b\u5b58\u5728\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u800c\u7279\u5f81\u7f13\u5b58\u65b9\u6cd5\u4ec5\u8003\u8651\u4e86\u65f6\u95f4\u7ef4\u5ea6\u4e0a\u7684\u76f8\u4f3c\u6027\uff0c\u5ffd\u7565\u4e86\u7a7a\u95f4\u7ef4\u5ea6\u4e0a\u7684\u76f8\u4f3c\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCluster-Driven Feature Caching (ClusCa) \u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5728\u6bcf\u4e2a\u65f6\u95f4\u6b65\u5bf9token\u8fdb\u884c\u7a7a\u95f4\u805a\u7c7b\uff0c\u5e76\u4e3a\u6bcf\u4e2a\u805a\u7c7b\u8ba1\u7b97\u4e00\u4e2atoken\uff0c\u7136\u540e\u5c06\u5176\u4fe1\u606f\u4f20\u64ad\u7ed9\u6240\u6709\u5176\u4ed6token\u3002", "result": "\u5728DiT\u3001FLUX\u548cHunyuanVideo\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86ClusCa\u5728\u6587\u672c\u5230\u56fe\u50cf\u548c\u6587\u672c\u5230\u89c6\u9891\u751f\u6210\u65b9\u9762\u7684\u6709\u6548\u6027\u3002ClusCa\u53ef\u4ee5\u5c06token\u6570\u91cf\u51cf\u5c1190%\u4ee5\u4e0a\uff0c\u5e76\u4e14\u53ef\u4ee5\u76f4\u63a5\u5e94\u7528\u4e8e\u4efb\u4f55\u6269\u6563\u53d8\u6362\u5668\u6a21\u578b\uff0c\u65e0\u9700\u8fdb\u884c\u8bad\u7ec3\u3002\u5728FLUX\u4e0a\u5b9e\u73b0\u4e864.96\u500d\u7684\u52a0\u901f\uff0cImageReward\u4e3a99.49%\uff0c\u6bd4\u539f\u59cb\u6a21\u578b\u63d0\u9ad8\u4e860.51%\u3002", "conclusion": "ClusCa\u662f\u4e00\u79cd\u6709\u6548\u7684\u7279\u5f81\u7f13\u5b58\u65b9\u6cd5\uff0c\u53ef\u4ee5\u663e\u8457\u52a0\u901f\u6269\u6563\u6a21\u578b\uff0c\u5e76\u4e14\u5177\u6709\u5e7f\u6cdb\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2509.10334", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10334", "abs": "https://arxiv.org/abs/2509.10334", "authors": ["Jordan Sassoon", "Michal Szczepanski", "Martyna Poreba"], "title": "I-Segmenter: Integer-Only Vision Transformer for Efficient Semantic Segmentation", "comment": null, "summary": "Vision Transformers (ViTs) have recently achieved strong results in semantic\nsegmentation, yet their deployment on resource-constrained devices remains\nlimited due to their high memory footprint and computational cost. Quantization\noffers an effective strategy to improve efficiency, but ViT-based segmentation\nmodels are notoriously fragile under low precision, as quantization errors\naccumulate across deep encoder-decoder pipelines. We introduce I-Segmenter, the\nfirst fully integer-only ViT segmentation framework. Building on the Segmenter\narchitecture, I-Segmenter systematically replaces floating-point operations\nwith integer-only counterparts. To further stabilize both training and\ninference, we propose $\\lambda$-ShiftGELU, a novel activation function that\nmitigates the limitations of uniform quantization in handling long-tailed\nactivation distributions. In addition, we remove the L2 normalization layer and\nreplace bilinear interpolation in the decoder with nearest neighbor upsampling,\nensuring integer-only execution throughout the computational graph. Extensive\nexperiments show that I-Segmenter achieves accuracy within a reasonable margin\nof its FP32 baseline (5.1 % on average), while reducing model size by up to\n3.8x and enabling up to 1.2x faster inference with optimized runtimes. Notably,\neven in one-shot PTQ with a single calibration image, I-Segmenter delivers\ncompetitive accuracy, underscoring its practicality for real-world deployment.", "AI": {"tldr": "I-Segmenter \u662f\u9996\u4e2a\u5168\u6574\u6570 Vision Transformer (ViT) \u8bed\u4e49\u5206\u5272\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u6d6e\u70b9\u8fd0\u7b97\u66ff\u6362\u4e3a\u6574\u6570\u8fd0\u7b97\u3001\u5f15\u5165\u65b0\u7684\u6fc0\u6d3b\u51fd\u6570 \u03bb-ShiftGELU\u3001\u79fb\u9664 L2 \u5f52\u4e00\u5316\u5c42\u4ee5\u53ca\u5c06\u53cc\u7ebf\u6027\u63d2\u503c\u66ff\u6362\u4e3a\u6700\u8fd1\u90bb\u4e0a\u91c7\u6837\uff0c\u5728\u4fdd\u6301\u63a5\u8fd1 FP32 \u57fa\u7ebf\u7cbe\u5ea6\u7684\u540c\u65f6\uff0c\u663e\u8457\u51cf\u5c0f\u4e86\u6a21\u578b\u5c3a\u5bf8\u5e76\u63d0\u9ad8\u4e86\u63a8\u7406\u901f\u5ea6\u3002", "motivation": "\u73b0\u6709\u7684 Vision Transformers (ViTs) \u5728\u8bed\u4e49\u5206\u5272\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u7531\u4e8e\u5185\u5b58\u5360\u7528\u548c\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u7684\u90e8\u7f72\u53d7\u5230\u9650\u5236\u3002\u91cf\u5316\u662f\u4e00\u79cd\u63d0\u9ad8\u6548\u7387\u7684\u6709\u6548\u7b56\u7565\uff0c\u4f46 ViT \u5206\u5272\u6a21\u578b\u5728\u4f4e\u7cbe\u5ea6\u4e0b\u8868\u73b0\u8106\u5f31\uff0c\u91cf\u5316\u8bef\u5dee\u4f1a\u5728\u6df1\u5ea6\u7f16\u7801\u5668-\u89e3\u7801\u5668\u7ba1\u9053\u4e2d\u7d2f\u79ef\u3002", "method": "I-Segmenter \u901a\u8fc7\u7cfb\u7edf\u5730\u5c06\u6d6e\u70b9\u8fd0\u7b97\u66ff\u6362\u4e3a\u6574\u6570\u8fd0\u7b97\uff0c\u6784\u5efa\u4e86\u9996\u4e2a\u5168\u6574\u6570 ViT \u5206\u5272\u6846\u67b6\u3002\u4e3a\u4e86\u7a33\u5b9a\u8bad\u7ec3\u548c\u63a8\u7406\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6fc0\u6d3b\u51fd\u6570 \u03bb-ShiftGELU \u6765\u7f13\u89e3\u5747\u5300\u91cf\u5316\u5728\u5904\u7406\u957f\u5c3e\u6fc0\u6d3b\u5206\u5e03\u65f6\u7684\u5c40\u9650\u6027\u3002\u6b64\u5916\uff0c\u79fb\u9664\u4e86 L2 \u5f52\u4e00\u5316\u5c42\uff0c\u5e76\u5c06\u89e3\u7801\u5668\u4e2d\u7684\u53cc\u7ebf\u6027\u63d2\u503c\u66ff\u6362\u4e3a\u6700\u8fd1\u90bb\u4e0a\u91c7\u6837\uff0c\u786e\u4fdd\u6574\u4e2a\u8ba1\u7b97\u56fe\u7684\u6574\u6570\u8fd0\u7b97\u3002", "result": "I-Segmenter \u7684\u51c6\u786e\u5ea6\u4e0e FP32 \u57fa\u7ebf\u76f8\u5f53\uff08\u5e73\u5747\u4ec5\u76f8\u5dee 5.1%\uff09\uff0c\u540c\u65f6\u6a21\u578b\u5c3a\u5bf8\u51cf\u5c0f\u4e86\u9ad8\u8fbe 3.8 \u500d\uff0c\u63a8\u7406\u901f\u5ea6\u6700\u591a\u63d0\u9ad8\u4e86 1.2 \u500d\u3002\u5373\u4f7f\u5728\u4ec5\u4f7f\u7528\u4e00\u5f20\u6807\u5b9a\u56fe\u50cf\u8fdb\u884c\u4e00\u6b21\u6027\u91cf\u5316\u8bad\u7ec3\uff08PTQ\uff09\u7684\u60c5\u51b5\u4e0b\uff0cI-Segmenter \u4e5f\u80fd\u63d0\u4f9b\u5177\u6709\u7ade\u4e89\u529b\u7684\u51c6\u786e\u5ea6\u3002", "conclusion": "I-Segmenter \u6210\u529f\u5b9e\u73b0\u4e86\u9996\u4e2a\u5168\u6574\u6570 ViT \u5206\u5272\u6846\u67b6\uff0c\u6709\u6548\u89e3\u51b3\u4e86 ViT \u5728\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u90e8\u7f72\u4e2d\u7684\u6548\u7387\u95ee\u9898\uff0c\u5e76\u5728\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u5177\u6709\u5f88\u9ad8\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2509.10341", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.10341", "abs": "https://arxiv.org/abs/2509.10341", "authors": ["Botond Fazekas", "Thomas Pinetz", "Guilherme Aresta", "Taha Emre", "Hrvoje Bogunovic"], "title": "GARD: Gamma-based Anatomical Restoration and Denoising for Retinal OCT", "comment": null, "summary": "Optical Coherence Tomography (OCT) is a vital imaging modality for diagnosing\nand monitoring retinal diseases. However, OCT images are inherently degraded by\nspeckle noise, which obscures fine details and hinders accurate interpretation.\nWhile numerous denoising methods exist, many struggle to balance noise\nreduction with the preservation of crucial anatomical structures. This paper\nintroduces GARD (Gamma-based Anatomical Restoration and Denoising), a novel\ndeep learning approach for OCT image despeckling that leverages the strengths\nof diffusion probabilistic models. Unlike conventional diffusion models that\nassume Gaussian noise, GARD employs a Denoising Diffusion Gamma Model to more\naccurately reflect the statistical properties of speckle. Furthermore, we\nintroduce a Noise-Reduced Fidelity Term that utilizes a pre-processed,\nless-noisy image to guide the denoising process. This crucial addition prevents\nthe reintroduction of high-frequency noise. We accelerate the inference process\nby adapting the Denoising Diffusion Implicit Model framework to our Gamma-based\nmodel. Experiments on a dataset with paired noisy and less-noisy OCT B-scans\ndemonstrate that GARD significantly outperforms traditional denoising methods\nand state-of-the-art deep learning models in terms of PSNR, SSIM, and MSE.\nQualitative results confirm that GARD produces sharper edges and better\npreserves fine anatomical details.", "AI": {"tldr": "GARD\u662f\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u6982\u7387\u7684\u65b0\u578b\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u53bb\u9664OCT\u56fe\u50cf\u4e2d\u7684\u6563\u6591\u566a\u58f0\uff0c\u5b83\u4f7f\u7528\u4f3d\u9a6c\u5206\u5e03\u6765\u6a21\u62df\u566a\u58f0\uff0c\u5e76\u901a\u8fc7\u566a\u58f0\u9c81\u68d2\u6027\u4fdd\u771f\u9879\u6765\u63d0\u9ad8\u56fe\u50cf\u8d28\u91cf\uff0c\u540c\u65f6\u52a0\u901f\u4e86\u63a8\u7406\u8fc7\u7a0b\uff0c\u5728\u5404\u79cd\u8bc4\u4f30\u6307\u6807\u4e0a\u90fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "OCT\u56fe\u50cf\u4e2d\u7684\u6563\u6591\u566a\u58f0\u4f1a\u963b\u788d\u5bf9\u89c6\u7f51\u819c\u75be\u75c5\u7684\u51c6\u786e\u8bca\u65ad\u548c\u76d1\u6d4b\uff0c\u800c\u73b0\u6709\u7684\u53bb\u566a\u65b9\u6cd5\u5f80\u5f80\u96be\u4ee5\u5728\u964d\u566a\u548c\u4fdd\u7559\u89e3\u5256\u7ed3\u6784\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGARD\uff08Gamma-based Anatomical Restoration and Denoising\uff09\u7684\u65b0\u578b\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5229\u7528\u4e86\u6269\u6563\u6982\u7387\u6a21\u578b\u7684\u4f18\u70b9\u3002GARD\u91c7\u7528\u4f3d\u9a6c\u53bb\u566a\u6269\u6563\u6a21\u578b\u6765\u66f4\u51c6\u786e\u5730\u6a21\u62df\u6563\u6591\u566a\u58f0\u7684\u7edf\u8ba1\u7279\u6027\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u4e2a\u5229\u7528\u9884\u5904\u7406\u8fc7\u7684\u3001\u566a\u58f0\u8f83\u5c11\u7684\u56fe\u50cf\u6765\u6307\u5bfc\u53bb\u566a\u8fc7\u7a0b\u7684\u566a\u58f0\u9c81\u68d2\u6027\u4fdd\u771f\u9879\uff0c\u4ee5\u9632\u6b62\u9ad8\u9891\u566a\u58f0\u7684\u518d\u5f15\u5165\u3002\u6b64\u5916\uff0c\u8fd8\u901a\u8fc7\u8c03\u6574\u53bb\u566a\u6269\u6563\u9690\u5f0f\u6a21\u578b\u6846\u67b6\u6765\u52a0\u901f\u63a8\u7406\u8fc7\u7a0b\u3002", "result": "GARD\u5728\u914d\u5bf9\u7684\u566a\u58f0\u548c\u566a\u58f0\u8f83\u5c11\u7684OCT B-\u626b\u63cf\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0c\u7ed3\u679c\u8868\u660e\uff0c\u5728PSNR\u3001SSIM\u548cMSE\u65b9\u9762\uff0cGARD\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u7684\u53bb\u566a\u65b9\u6cd5\u548c\u6700\u5148\u8fdb\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u3002\u89c6\u89c9\u7ed3\u679c\u4e5f\u8bc1\u5b9e\uff0cGARD\u4ea7\u751f\u7684\u8fb9\u7f18\u66f4\u6e05\u6670\uff0c\u5e76\u80fd\u66f4\u597d\u5730\u4fdd\u7559\u7cbe\u7ec6\u7684\u89e3\u5256\u7ec6\u8282\u3002", "conclusion": "GARD\u662f\u4e00\u79cd\u6709\u6548\u7684OCT\u56fe\u50cf\u53bb\u566a\u65b9\u6cd5\uff0c\u5b83\u901a\u8fc7\u91c7\u7528\u4f3d\u9a6c\u5206\u5e03\u6a21\u62df\u6563\u6591\u566a\u58f0\u5e76\u5f15\u5165\u566a\u58f0\u9c81\u68d2\u6027\u4fdd\u771f\u9879\uff0c\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u56fe\u50cf\u8d28\u91cf\uff0c\u5e76\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2509.10344", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10344", "abs": "https://arxiv.org/abs/2509.10344", "authors": ["Yuexi Du", "Lihui Chen", "Nicha C. Dvornek"], "title": "GLAM: Geometry-Guided Local Alignment for Multi-View VLP in Mammography", "comment": "Accepted by MICCAI 2025", "summary": "Mammography screening is an essential tool for early detection of breast\ncancer. The speed and accuracy of mammography interpretation have the potential\nto be improved with deep learning methods. However, the development of a\nfoundation visual language model (VLM) is hindered by limited data and domain\ndifferences between natural and medical images. Existing mammography VLMs,\nadapted from natural images, often ignore domain-specific characteristics, such\nas multi-view relationships in mammography. Unlike radiologists who analyze\nboth views together to process ipsilateral correspondence, current methods\ntreat them as independent images or do not properly model the multi-view\ncorrespondence learning, losing critical geometric context and resulting in\nsuboptimal prediction. We propose GLAM: Global and Local Alignment for\nMulti-view mammography for VLM pretraining using geometry guidance. By\nleveraging the prior knowledge about the multi-view imaging process of\nmammograms, our model learns local cross-view alignments and fine-grained local\nfeatures through joint global and local, visual-visual, and visual-language\ncontrastive learning. Pretrained on EMBED [14], one of the largest open\nmammography datasets, our model outperforms baselines across multiple datasets\nunder different settings.", "AI": {"tldr": "GLAM\u662f\u4e00\u4e2a\u7528\u4e8e\u4e73\u817aX\u5149\u68c0\u67e5\u7684\u591a\u89c6\u56fe\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u901a\u8fc7\u7ed3\u5408\u5168\u5c40\u548c\u5c40\u90e8\u5bf9\u9f50\u4ee5\u53ca\u51e0\u4f55\u5f15\u5bfc\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6a21\u578b\u5ffd\u7565\u591a\u89c6\u56fe\u5173\u7cfb\u548c\u9886\u57df\u5dee\u5f02\u7684\u95ee\u9898\uff0c\u5e76\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u4e73\u817aX\u5149\u68c0\u67e5\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u5904\u7406\u591a\u89c6\u56fe\u5173\u7cfb\u548c\u9886\u57df\u5dee\u5f02\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u5bfc\u81f4\u65e0\u6cd5\u5145\u5206\u5229\u7528\u5173\u952e\u7684\u51e0\u4f55\u4fe1\u606f\uff0c\u5f71\u54cd\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51faGLAM\u6a21\u578b\uff0c\u5229\u7528\u51e0\u4f55\u5f15\u5bfc\u8fdb\u884c\u591a\u89c6\u56fe\u4e73\u817aX\u5149\u68c0\u67e5\u7684VLM\u9884\u8bad\u7ec3\u3002\u901a\u8fc7\u8054\u5408\u5168\u5c40\u548c\u5c40\u90e8\u3001\u89c6\u89c9-\u89c6\u89c9\u4ee5\u53ca\u89c6\u89c9-\u8bed\u8a00\u5bf9\u6bd4\u5b66\u4e60\uff0c\u5b66\u4e60\u5c40\u90e8\u8de8\u89c6\u56fe\u5bf9\u9f50\u548c\u7ec6\u7c92\u5ea6\u5c40\u90e8\u7279\u5f81\uff0c\u5e76\u5229\u7528\u4e86\u4e73\u817aX\u5149\u68c0\u67e5\u7684\u591a\u89c6\u56fe\u6210\u50cf\u8fc7\u7a0b\u7684\u5148\u9a8c\u77e5\u8bc6\u3002", "result": "\u5728EMBED\u6570\u636e\u96c6\u4e0a\u9884\u8bad\u7ec3\u7684GLAM\u6a21\u578b\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u4e0d\u540c\u8bbe\u7f6e\u4e0b\u5747\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "GLAM\u901a\u8fc7\u6709\u6548\u7684\u591a\u89c6\u56fe\u5bf9\u9f50\u548c\u9886\u57df\u9002\u5e94\u6027\u5b66\u4e60\uff0c\u63d0\u9ad8\u4e86\u4e73\u817aX\u5149\u68c0\u67e5VLM\u7684\u6027\u80fd\u3002"}}
{"id": "2509.10345", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10345", "abs": "https://arxiv.org/abs/2509.10345", "authors": ["Georgios Pantazopoulos", "Eda B. \u00d6zyi\u011fit"], "title": "Towards Understanding Visual Grounding in Visual Language Models", "comment": null, "summary": "Visual grounding refers to the ability of a model to identify a region within\nsome visual input that matches a textual description. Consequently, a model\nequipped with visual grounding capabilities can target a wide range of\napplications in various domains, including referring expression comprehension,\nanswering questions pertinent to fine-grained details in images or videos,\ncaption visual context by explicitly referring to entities, as well as low and\nhigh-level control in simulated and real environments. In this survey paper, we\nreview representative works across the key areas of research on modern\ngeneral-purpose vision language models (VLMs). We first outline the importance\nof grounding in VLMs, then delineate the core components of the contemporary\nparadigm for developing grounded models, and examine their practical\napplications, including benchmarks and evaluation metrics for grounded\nmultimodal generation. We also discuss the multifaceted interrelations among\nvisual grounding, multimodal chain-of-thought, and reasoning in VLMs. Finally,\nwe analyse the challenges inherent to visual grounding and suggest promising\ndirections for future research.", "AI": {"tldr": "\u672c\u6587\u5bf9\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u4e2d\u7684\u89c6\u89c9\u57fa\u7840\uff08visual grounding\uff09\u8fdb\u884c\u4e86\u5168\u9762\u7efc\u8ff0\uff0c\u63a2\u8ba8\u4e86\u5176\u5728\u5404\u79cd\u5e94\u7528\u4e2d\u7684\u91cd\u8981\u6027\u3001\u6838\u5fc3\u7ec4\u4ef6\u3001\u5b9e\u9645\u5e94\u7528\u3001\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5e76\u5206\u6790\u4e86\u89c6\u89c9\u57fa\u7840\u3001\u591a\u6a21\u6001\u601d\u7ef4\u94fe\u548c\u63a8\u7406\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u6700\u540e\u6307\u51fa\u4e86\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u89c6\u89c9\u57fa\u7840\u662f VLM \u7684\u5173\u952e\u80fd\u529b\uff0c\u80fd\u7406\u89e3\u56fe\u50cf\u6216\u89c6\u9891\u4e2d\u4e0e\u6587\u672c\u63cf\u8ff0\u5339\u914d\u7684\u533a\u57df\uff0c\u5bf9\u89c6\u89c9\u8bed\u8a00\u7406\u89e3\u548c\u751f\u6210\u81f3\u5173\u91cd\u8981\u3002", "method": "\u672c\u6587\u7efc\u8ff0\u4e86\u73b0\u4ee3\u901a\u7528 VLM \u5728\u89c6\u89c9\u57fa\u7840\u7814\u7a76\u65b9\u9762\u7684\u4ee3\u8868\u6027\u5de5\u4f5c\uff0c\u6982\u8ff0\u4e86\u89c6\u89c9\u57fa\u7840\u7684\u91cd\u8981\u6027\u3001\u6838\u5fc3\u7ec4\u4ef6\u3001\u5b9e\u9645\u5e94\u7528\uff08\u5305\u62ec\u57fa\u51c6\u548c\u8bc4\u4f30\u6307\u6807\uff09\uff0c\u5e76\u63a2\u8ba8\u4e86\u89c6\u89c9\u57fa\u7840\u3001\u591a\u6a21\u6001\u601d\u7ef4\u94fe\u548c\u63a8\u7406\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "result": "\u5bf9\u89c6\u89c9\u57fa\u7840\u5728 VLM \u4e2d\u7684\u91cd\u8981\u6027\u3001\u6838\u5fc3\u7ec4\u4ef6\u3001\u5b9e\u9645\u5e94\u7528\u3001\u57fa\u51c6\u548c\u8bc4\u4f30\u6307\u6807\u8fdb\u884c\u4e86\u6982\u8ff0\uff0c\u5e76\u5206\u6790\u4e86\u89c6\u89c9\u57fa\u7840\u3001\u591a\u6a21\u6001\u601d\u7ef4\u94fe\u548c\u63a8\u7406\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "conclusion": "\u89c6\u89c9\u57fa\u7840\u662f VLM \u4e2d\u7684\u4e00\u4e2a\u6d3b\u8dc3\u7814\u7a76\u9886\u57df\uff0c\u867d\u7136\u5728\u7406\u89e3\u548c\u751f\u6210\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u4ecd\u9762\u4e34\u6311\u6218\uff0c\u672a\u6765\u7814\u7a76\u5e94\u5173\u6ce8\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u5e76\u63a2\u7d22\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2509.10359", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.10359", "abs": "https://arxiv.org/abs/2509.10359", "authors": ["Matteo Trippodo", "Federico Becattini", "Lorenzo Seidenari"], "title": "Immunizing Images from Text to Image Editing via Adversarial Cross-Attention", "comment": "Accepted as Regular Paper at ACM Multimedia 2025", "summary": "Recent advances in text-based image editing have enabled fine-grained\nmanipulation of visual content guided by natural language. However, such\nmethods are susceptible to adversarial attacks. In this work, we propose a\nnovel attack that targets the visual component of editing methods. We introduce\nAttention Attack, which disrupts the cross-attention between a textual prompt\nand the visual representation of the image by using an automatically generated\ncaption of the source image as a proxy for the edit prompt. This breaks the\nalignment between the contents of the image and their textual description,\nwithout requiring knowledge of the editing method or the editing prompt.\nReflecting on the reliability of existing metrics for immunization success, we\npropose two novel evaluation strategies: Caption Similarity, which quantifies\nsemantic consistency between original and adversarial edits, and semantic\nIntersection over Union (IoU), which measures spatial layout disruption via\nsegmentation masks. Experiments conducted on the TEDBench++ benchmark\ndemonstrate that our attack significantly degrades editing performance while\nremaining imperceptible.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u6ce8\u610f\u529b\u653b\u51fb\u201d\u7684\u65b0\u578b\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f7f\u7528\u6e90\u56fe\u50cf\u7684\u81ea\u52a8\u751f\u6210\u6807\u9898\u4f5c\u4e3a\u7f16\u8f91\u63d0\u793a\u7684\u4ee3\u7406\uff0c\u6270\u4e71\u6587\u672c\u63d0\u793a\u548c\u56fe\u50cf\u89c6\u89c9\u8868\u793a\u4e4b\u95f4\u7684\u4ea4\u53c9\u6ce8\u610f\u529b\uff0c\u4ece\u800c\u9488\u5bf9\u6587\u672c\u5230\u56fe\u50cf\u7f16\u8f91\u65b9\u6cd5\u7684\u89c6\u89c9\u7ec4\u4ef6\uff0c\u5e76\u63d0\u51fa\u4e24\u79cd\u65b0\u7684\u8bc4\u4f30\u7b56\u7565\u6765\u8861\u91cf\u514d\u75ab\u6210\u529f\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u6587\u672c\u5230\u56fe\u50cf\u7f16\u8f91\u65b9\u6cd5\u5bb9\u6613\u53d7\u5230\u5bf9\u6297\u6027\u653b\u51fb\uff0c\u9700\u8981\u65b0\u7684\u653b\u51fb\u548c\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u201c\u6ce8\u610f\u529b\u653b\u51fb\u201d\uff0c\u901a\u8fc7\u4f7f\u7528\u6e90\u56fe\u50cf\u7684\u81ea\u52a8\u751f\u6210\u6807\u9898\u4f5c\u4e3a\u7f16\u8f91\u63d0\u793a\u7684\u4ee3\u7406\u6765\u6270\u4e71\u6587\u672c\u63d0\u793a\u548c\u56fe\u50cf\u89c6\u89c9\u8868\u793a\u4e4b\u95f4\u7684\u4ea4\u53c9\u6ce8\u610f\u529b\u3002\u63d0\u51fa\u201c\u6807\u9898\u76f8\u4f3c\u5ea6\u201d\u548c\u201c\u8bed\u4e49\u4ea4\u5e76\u6bd4\uff08IoU\uff09\u201d\u4e24\u79cd\u65b0\u7684\u8bc4\u4f30\u7b56\u7565\u3002", "result": "\u8be5\u653b\u51fb\u663e\u8457\u964d\u4f4e\u4e86\u7f16\u8f91\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u4e0d\u53ef\u5bdf\u89c9\uff0c\u5e76\u5728 TEDBench++ \u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5f97\u5230\u4e86\u8bc1\u660e\u3002", "conclusion": "\u63d0\u51fa\u7684\u201c\u6ce8\u610f\u529b\u653b\u51fb\u201d\u662f\u4e00\u79cd\u6709\u6548\u4e14\u96be\u4ee5\u5bdf\u89c9\u7684\u653b\u51fb\u65b9\u6cd5\uff0c\u53ef\u7528\u4e8e\u8bc4\u4f30\u6587\u672c\u5230\u56fe\u50cf\u7f16\u8f91\u65b9\u6cd5\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u4e14\u63d0\u51fa\u7684\u65b0\u8bc4\u4f30\u7b56\u7565\u80fd\u66f4\u51c6\u786e\u5730\u8861\u91cf\u653b\u51fb\u6548\u679c\u3002"}}
{"id": "2509.10366", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.10366", "abs": "https://arxiv.org/abs/2509.10366", "authors": ["Fabien Allemand", "Attilio Fiandrotti", "Sumanta Chaudhuri", "Alaa Eddine Mazouz"], "title": "Efficient Learned Image Compression Through Knowledge Distillation", "comment": "19 pages, 21 figures", "summary": "Learned image compression sits at the intersection of machine learning and\nimage processing. With advances in deep learning, neural network-based\ncompression methods have emerged. In this process, an encoder maps the image to\na low-dimensional latent space, which is then quantized, entropy-coded into a\nbinary bitstream, and transmitted to the receiver. At the receiver end, the\nbitstream is entropy-decoded, and a decoder reconstructs an approximation of\nthe original image. Recent research suggests that these models consistently\noutperform conventional codecs. However, they require significant processing\npower, making them unsuitable for real-time use on resource-constrained\nplatforms, which hinders their deployment in mainstream applications. This\nstudy aims to reduce the resource requirements of neural networks used for\nimage compression by leveraging knowledge distillation, a training paradigm\nwhere smaller neural networks, partially trained on the outputs of larger, more\ncomplex models, can achieve better performance than when trained independently.\nOur work demonstrates that knowledge distillation can be effectively applied to\nimage compression tasks: i) across various architecture sizes, ii) to achieve\ndifferent image quality/bit rate tradeoffs, and iii) to save processing and\nenergy resources. This approach introduces new settings and hyperparameters,\nand future research could explore the impact of different teacher models, as\nwell as alternative loss functions. Knowledge distillation could also be\nextended to transformer-based models. The code is publicly available at:\nhttps://github.com/FABallemand/PRIM .", "AI": {"tldr": "\u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u51cf\u5c0f\u4e86\u795e\u7ecf\u7f51\u7edc\u56fe\u50cf\u538b\u7f29\u6a21\u578b\u7684\u8d44\u6e90\u9700\u6c42\uff0c\u4ee5\u5b9e\u73b0\u66f4\u5feb\u7684\u901f\u5ea6\u548c\u66f4\u4f4e\u7684\u529f\u8017\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u56fe\u50cf\u538b\u7f29\u65b9\u6cd5\u867d\u7136\u6027\u80fd\u4f18\u8d8a\uff0c\u4f46\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u5927\uff0c\u4e0d\u9002\u5408\u8d44\u6e90\u53d7\u9650\u7684\u5e73\u53f0\u8fdb\u884c\u5b9e\u65f6\u5904\u7406\u3002", "method": "\u5229\u7528\u77e5\u8bc6\u84b8\u998f\u6280\u672f\uff0c\u8ba9\u5c0f\u578b\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u5b66\u4e60\u5927\u578b\u590d\u6742\u6a21\u578b\u7684\u8f93\u51fa\uff0c\u4ee5\u63d0\u9ad8\u5176\u6027\u80fd\u5e76\u964d\u4f4e\u8d44\u6e90\u6d88\u8017\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u77e5\u8bc6\u84b8\u998f\u53ef\u4ee5\u6709\u6548\u5730\u5e94\u7528\u4e8e\u56fe\u50cf\u538b\u7f29\u4efb\u52a1\uff0c\u5e76\u5728\u4e0d\u540c\u6a21\u578b\u5927\u5c0f\u3001\u4e0d\u540c\u56fe\u50cf\u8d28\u91cf/\u6bd4\u7279\u7387\u7684\u6743\u8861\u4e0b\uff0c\u4ee5\u53ca\u5728\u8282\u7701\u5904\u7406\u548c\u80fd\u6e90\u8d44\u6e90\u65b9\u9762\u53d6\u5f97\u6210\u6548\u3002", "conclusion": "\u77e5\u8bc6\u84b8\u998f\u662f\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u53ef\u4ee5\u51cf\u5c11\u795e\u7ecf\u7f51\u7edc\u56fe\u50cf\u538b\u7f29\u6a21\u578b\u7684\u8d44\u6e90\u9700\u6c42\uff0c\u4f7f\u5176\u80fd\u591f\u5e94\u7528\u4e8e\u66f4\u5e7f\u6cdb\u7684\u573a\u666f\u3002\u672a\u6765\u7684\u7814\u7a76\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63a2\u7d22\u4e0d\u540c\u7684\u6559\u5e08\u6a21\u578b\u3001\u635f\u5931\u51fd\u6570\u4ee5\u53ca\u5c06\u5176\u5e94\u7528\u4e8e\u57fa\u4e8eTransformer\u7684\u6a21\u578b\u3002"}}
{"id": "2509.10388", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.10388", "abs": "https://arxiv.org/abs/2509.10388", "authors": ["Zeqing Leo Yuan", "Mani Ramanagopal", "Aswin C. Sankaranarayanan", "Srinivasa G. Narasimhan"], "title": "Ordinality of Visible-Thermal Image Intensities for Intrinsic Image Decomposition", "comment": null, "summary": "Decomposing an image into its intrinsic photometric factors--shading and\nreflectance--is a long-standing challenge due to the lack of extensive\nground-truth data for real-world scenes. Recent methods rely on synthetic data\nor sparse annotations for limited indoor and even fewer outdoor scenes. We\nintroduce a novel training-free approach for intrinsic image decomposition\nusing only a pair of visible and thermal images. We leverage the principle that\nlight not reflected from an opaque surface is absorbed and detected as heat by\na thermal camera. This allows us to relate the ordinalities between visible and\nthermal image intensities to the ordinalities of shading and reflectance, which\ncan densely self-supervise an optimizing neural network to recover shading and\nreflectance. We perform quantitative evaluations with known reflectance and\nshading under natural and artificial lighting, and qualitative experiments\nacross diverse outdoor scenes. The results demonstrate superior performance\nover recent learning-based models and point toward a scalable path to curating\nreal-world ordinal supervision, previously infeasible via manual labeling.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4ec5\u4f7f\u7528\u53ef\u89c1\u5149\u548c\u70ed\u6210\u50cf\u56fe\u50cf\u7684\u65e0\u8bad\u7ec3\u65b9\u6cd5\u6765\u5b9e\u73b0\u5185\u56e0\u56fe\u50cf\u5206\u89e3\u3002", "motivation": "\u7531\u4e8e\u771f\u5b9e\u4e16\u754c\u573a\u666f\u7f3a\u4e4f\u5e7f\u6cdb\u7684\u5730\u9762\u771f\u5b9e\u6570\u636e\uff0c\u5c06\u56fe\u50cf\u5206\u89e3\u4e3a\u5149\u5ea6\u56e0\u7d20\uff08\u9634\u5f71\u548c\u53cd\u5c04\u7387\uff09\u662f\u4e00\u4e2a\u957f\u671f\u5b58\u5728\u7684\u6311\u6218\u3002", "method": "\u8be5\u65b9\u6cd5\u5229\u7528\u53ef\u89c1\u5149\u548c\u70ed\u6210\u50cf\u56fe\u50cf\u4e4b\u95f4\u7684\u5f3a\u5ea6\u987a\u5e8f\u5173\u7cfb\u6765\u63a8\u65ad\u9634\u5f71\u548c\u53cd\u5c04\u7387\u7684\u987a\u5e8f\uff0c\u4ece\u800c\u5b9e\u73b0\u5bc6\u96c6\u81ea\u76d1\u7763\u5b66\u4e60\u3002", "result": "\u5728\u81ea\u7136\u548c\u4eba\u9020\u5149\u7167\u4e0b\uff0c\u4f7f\u7528\u5df2\u77e5\u53cd\u5c04\u7387\u548c\u9634\u5f71\u8fdb\u884c\u5b9a\u91cf\u8bc4\u4f30\uff0c\u5e76\u5728\u5404\u79cd\u6237\u5916\u573a\u666f\u4e2d\u8fdb\u884c\u5b9a\u6027\u5b9e\u9a8c\uff0c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u4f18\u4e8e\u6700\u65b0\u7684\u57fa\u4e8e\u5b66\u4e60\u7684\u6a21\u578b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u771f\u5b9e\u4e16\u754c\u987a\u5e8f\u76d1\u7763\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u624b\u52a8\u6807\u8bb0\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5728\u5185\u56e0\u56fe\u50cf\u5206\u89e3\u65b9\u9762\u53d6\u5f97\u4e86\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u3002"}}
{"id": "2509.10407", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.10407", "abs": "https://arxiv.org/abs/2509.10407", "authors": ["Xiem HoangVan", "Dang BuiDinh", "Sang NguyenQuang", "Wen-Hsiao Peng"], "title": "Compressed Video Quality Enhancement: Classifying and Benchmarking over Standards", "comment": null, "summary": "Compressed video quality enhancement (CVQE) is crucial for improving user\nexperience with lossy video codecs like H.264/AVC, H.265/HEVC, and H.266/VVC.\nWhile deep learning based CVQE has driven significant progress, existing\nsurveys still suffer from limitations: lack of systematic classification\nlinking methods to specific standards and artifacts, insufficient comparative\nanalysis of architectural paradigms across coding types, and underdeveloped\nbenchmarking practices. To address these gaps, this paper presents three key\ncontributions. First, it introduces a novel taxonomy classifying CVQE methods\nacross architectural paradigms, coding standards, and compressed-domain feature\nutilization. Second, it proposes a unified benchmarking framework integrating\nmodern compression protocols and standard test sequences for fair\nmulti-criteria evaluation. Third, it provides a systematic analysis of the\ncritical trade-offs between reconstruction performance and computational\ncomplexity observed in state-of-the-art methods and highlighting promising\ndirections for future research. This comprehensive review aims to establish a\nfoundation for consistent assessment and informed model selection in CVQE\nresearch and deployment.", "AI": {"tldr": "\u6df1\u5ea6\u5b66\u4e60\u9a71\u52a8\u7684\u538b\u7f29\u89c6\u9891\u8d28\u91cf\u589e\u5f3a\uff08CVQE\uff09\u7814\u7a76\u73b0\u72b6\u5b58\u5728\u4e0d\u8db3\uff0c\u672c\u6587\u63d0\u51fa\u65b0\u7684\u5206\u7c7b\u6cd5\u3001\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\u548c\u6df1\u5165\u7684\u6027\u80fd\u5206\u6790\uff0c\u65e8\u5728\u4fc3\u8fdb\u8be5\u9886\u57df\u7684\u6807\u51c6\u5316\u8bc4\u4f30\u548c\u6a21\u578b\u9009\u62e9\u3002", "motivation": "\u73b0\u6709\u5173\u4e8e\u538b\u7f29\u89c6\u9891\u8d28\u91cf\u589e\u5f3a\uff08CVQE\uff09\u7684\u8c03\u67e5\u5728\u65b9\u6cd5\u5206\u7c7b\u3001\u8de8\u7f16\u7801\u7c7b\u578b\u6bd4\u8f83\u548c\u57fa\u51c6\u6d4b\u8bd5\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u65e0\u6cd5\u6ee1\u8db3\u6df1\u5ea6\u5b66\u4e60\u9a71\u52a8\u7684CVQE\u9886\u57df\u7684\u9700\u6c42\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684CVQE\u65b9\u6cd5\u5206\u7c7b\u6cd5\uff0c\u5e76\u5efa\u7acb\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u4e0d\u540c\u6a21\u578b\u5728\u73b0\u4ee3\u538b\u7f29\u534f\u8bae\u548c\u6807\u51c6\u6d4b\u8bd5\u5e8f\u5217\u4e0a\u7684\u6027\u80fd\u3002\u6700\u540e\uff0c\u5bf9\u91cd\u5efa\u6027\u80fd\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\u4e4b\u95f4\u7684\u5173\u952e\u6743\u8861\u8fdb\u884c\u4e86\u7cfb\u7edf\u5206\u6790\u3002", "result": "\u672c\u6587\u7684\u5206\u7c7b\u6cd5\u548c\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\u4e3aCVQE\u7814\u7a76\u548c\u90e8\u7f72\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u901a\u8fc7\u7cfb\u7edf\u5206\u6790\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6700\u5148\u8fdb\u65b9\u6cd5\u5728\u91cd\u5efa\u6027\u80fd\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\u65b9\u9762\u7684\u6743\u8861\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u672c\u7814\u7a76\u901a\u8fc7\u63d0\u51fa\u65b0\u9896\u7684\u5206\u7c7b\u6cd5\u3001\u7edf\u4e00\u7684\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\u4ee5\u53ca\u5bf9\u6027\u80fd\u548c\u590d\u6742\u5ea6\u7684\u6df1\u5165\u5206\u6790\uff0c\u5f25\u5408\u4e86\u73b0\u6709CVQE\u8c03\u67e5\u7684\u5dee\u8ddd\uff0c\u65e8\u5728\u4e3a\u8be5\u9886\u57df\u63d0\u4f9b\u66f4\u4e00\u81f4\u7684\u8bc4\u4f30\u65b9\u6cd5\u548c\u66f4\u660e\u667a\u7684\u6a21\u578b\u9009\u62e9\u6307\u5bfc\u3002"}}
{"id": "2509.10408", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10408", "abs": "https://arxiv.org/abs/2509.10408", "authors": ["Iacopo Curti", "Pierluigi Zama Ramirez", "Alioscia Petrelli", "Luigi Di Stefano"], "title": "Multimodal SAM-adapter for Semantic Segmentation", "comment": null, "summary": "Semantic segmentation, a key task in computer vision with broad applications\nin autonomous driving, medical imaging, and robotics, has advanced\nsubstantially with deep learning. Nevertheless, current approaches remain\nvulnerable to challenging conditions such as poor lighting, occlusions, and\nadverse weather. To address these limitations, multimodal methods that\nintegrate auxiliary sensor data (e.g., LiDAR, infrared) have recently emerged,\nproviding complementary information that enhances robustness. In this work, we\npresent MM SAM-adapter, a novel framework that extends the capabilities of the\nSegment Anything Model (SAM) for multimodal semantic segmentation. The proposed\nmethod employs an adapter network that injects fused multimodal features into\nSAM's rich RGB features. This design enables the model to retain the strong\ngeneralization ability of RGB features while selectively incorporating\nauxiliary modalities only when they contribute additional cues. As a result, MM\nSAM-adapter achieves a balanced and efficient use of multimodal information. We\nevaluate our approach on three challenging benchmarks, DeLiVER, FMB, and MUSES,\nwhere MM SAM-adapter delivers state-of-the-art performance. To further analyze\nmodality contributions, we partition DeLiVER and FMB into RGB-easy and RGB-hard\nsubsets. Results consistently demonstrate that our framework outperforms\ncompeting methods in both favorable and adverse conditions, highlighting the\neffectiveness of multimodal adaptation for robust scene understanding. The code\nis available at the following link:\nhttps://github.com/iacopo97/Multimodal-SAM-Adapter.", "AI": {"tldr": "MM SAM-adapter \u662f\u4e00\u4e2a\u7528\u4e8e\u591a\u6a21\u6001\u8bed\u4e49\u5206\u5272\u7684\u65b0\u6846\u67b6\uff0c\u5b83\u901a\u8fc7\u9002\u914d\u5668\u7f51\u7edc\u5c06\u878d\u5408\u7684\u591a\u6a21\u6001\u7279\u5f81\u6ce8\u5165 SAM \u7684 RGB \u7279\u5f81\u4e2d\uff0c\u4ee5\u63d0\u9ad8\u6a21\u578b\u5728\u5149\u7167\u4e0d\u4f73\u3001\u906e\u6321\u548c\u6076\u52a3\u5929\u6c14\u7b49\u6311\u6218\u6027\u6761\u4ef6\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u5728\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u8bed\u4e49\u5206\u5272\u65b9\u6cd5\u5728\u5149\u7167\u4e0d\u4f73\u3001\u906e\u6321\u548c\u6076\u52a3\u5929\u6c14\u7b49\u6311\u6218\u6027\u6761\u4ef6\u4e0b\u4ecd\u7136\u8106\u5f31\u3002\u4e3a\u4e86\u63d0\u9ad8\u6a21\u578b\u7684\u9c81\u68d2\u6027\uff0c\u7814\u7a76\u8005\u4eec\u63d0\u51fa\u4e86\u591a\u6a21\u6001\u65b9\u6cd5\uff0c\u5229\u7528\u8f85\u52a9\u4f20\u611f\u5668\u6570\u636e\uff08\u5982 LiDAR\u3001\u7ea2\u5916\u7ebf\uff09\u6765\u63d0\u4f9b\u4e92\u8865\u4fe1\u606f\u3002", "method": "MM SAM-adapter \u6846\u67b6\u901a\u8fc7\u4e00\u4e2a\u9002\u914d\u5668\u7f51\u7edc\uff0c\u5c06\u878d\u5408\u540e\u7684\u591a\u6a21\u6001\u7279\u5f81\u6ce8\u5165\u5230 SAM \u5f3a\u5927\u7684 RGB \u7279\u5f81\u4e2d\u3002\u8fd9\u79cd\u8bbe\u8ba1\u4f7f\u5f97\u6a21\u578b\u80fd\u591f\u5728\u4fdd\u7559 RGB \u7279\u5f81\u7684\u5f3a\u5927\u6cdb\u5316\u80fd\u529b\u7684\u540c\u65f6\uff0c\u4ec5\u5728\u8f85\u52a9\u6a21\u6001\u63d0\u4f9b\u989d\u5916\u7ebf\u7d22\u65f6\u624d\u9009\u62e9\u6027\u5730\u6574\u5408\u5b83\u4eec\u3002", "result": "MM SAM-adapter \u5728 DeLiVER\u3001FMB \u548c MUSES \u4e09\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002\u901a\u8fc7\u5c06 DeLiVER \u548c FMB \u5206\u6210 RGB-easy \u548c RGB-hard \u5b50\u96c6\u8fdb\u884c\u5206\u6790\uff0c\u7ed3\u679c\u4e00\u81f4\u8868\u660e\uff0c\u65e0\u8bba\u662f\u5728\u6709\u5229\u8fd8\u662f\u4e0d\u5229\u7684\u6761\u4ef6\u4e0b\uff0c\u8be5\u6846\u67b6\u90fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "MM SAM-adapter \u6846\u67b6\u80fd\u591f\u6709\u6548\u4e14\u9ad8\u6548\u5730\u5229\u7528\u591a\u6a21\u6001\u4fe1\u606f\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u9002\u914d\u63d0\u9ad8\u4e86\u573a\u666f\u7406\u89e3\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u5728\u5404\u79cd\u6311\u6218\u6027\u6761\u4ef6\u4e0b\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2509.10441", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.10441", "abs": "https://arxiv.org/abs/2509.10441", "authors": ["Tao Han", "Wanghan Xu", "Junchao Gong", "Xiaoyu Yue", "Song Guo", "Luping Zhou", "Lei Bai"], "title": "InfGen: A Resolution-Agnostic Paradigm for Scalable Image Synthesis", "comment": "Accepted by ICCV 2025", "summary": "Arbitrary resolution image generation provides a consistent visual experience\nacross devices, having extensive applications for producers and consumers.\nCurrent diffusion models increase computational demand quadratically with\nresolution, causing 4K image generation delays over 100 seconds. To solve this,\nwe explore the second generation upon the latent diffusion models, where the\nfixed latent generated by diffusion models is regarded as the content\nrepresentation and we propose to decode arbitrary resolution images with a\ncompact generated latent using a one-step generator. Thus, we present the\n\\textbf{InfGen}, replacing the VAE decoder with the new generator, for\ngenerating images at any resolution from a fixed-size latent without retraining\nthe diffusion models, which simplifies the process, reducing computational\ncomplexity and can be applied to any model using the same latent space.\nExperiments show InfGen is capable of improving many models into the arbitrary\nhigh-resolution era while cutting 4K image generation time to under 10 seconds.", "AI": {"tldr": "InfGen\u662f\u4e00\u4e2a\u65b0\u63d0\u51fa\u7684\u6a21\u578b\uff0c\u53ef\u4ee5\u5728\u4e0d\u91cd\u65b0\u8bad\u7ec3\u6269\u6563\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\uff0c\u4ece\u56fa\u5b9a\u5927\u5c0f\u7684\u6f5c\u5728\u8868\u793a\u4e2d\u751f\u6210\u4efb\u610f\u5206\u8fa8\u7387\u7684\u56fe\u50cf\uff0c\u4ece\u800c\u5927\u5927\u63d0\u9ad8\u751f\u6210\u901f\u5ea6\u3002", "motivation": "\u73b0\u6709\u7684\u6269\u6563\u6a21\u578b\u5728\u751f\u6210\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u65f6\u8ba1\u7b97\u9700\u6c42\u4f1a\u968f\u7740\u5206\u8fa8\u7387\u7684\u589e\u52a0\u800c\u5448\u4e8c\u6b21\u65b9\u589e\u957f\uff0c\u5bfc\u81f4\u751f\u6210\u901f\u5ea6\u7f13\u6162\u3002\u4f5c\u8005\u5e0c\u671b\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u5b9e\u73b0\u4efb\u610f\u5206\u8fa8\u7387\u7684\u56fe\u50cf\u751f\u6210\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aInfGen\u7684\u65b0\u6a21\u578b\uff0c\u5b83\u6539\u8fdb\u4e86\u6f5c\u5728\u6269\u6563\u6a21\u578b\u3002InfGen\u5c06\u6269\u6563\u6a21\u578b\u751f\u6210\u7684\u56fa\u5b9a\u6f5c\u5728\u8868\u793a\u89c6\u4e3a\u5185\u5bb9\u8868\u793a\uff0c\u5e76\u4f7f\u7528\u4e00\u4e2a\u7d27\u51d1\u7684\u751f\u6210\u5668\u6765\u89e3\u7801\u4efb\u610f\u5206\u8fa8\u7387\u7684\u56fe\u50cf\u3002InfGen\u7528\u4e00\u4e2a\u65b0\u7684\u751f\u6210\u5668\u66ff\u6362\u4e86\u539f\u6709\u7684VAE\u89e3\u7801\u5668\uff0c\u53ef\u4ee5\u5728\u4e0d\u91cd\u65b0\u8bad\u7ec3\u6269\u6563\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\uff0c\u4ece\u56fa\u5b9a\u5927\u5c0f\u7684\u6f5c\u5728\u8868\u793a\u751f\u6210\u4efb\u610f\u5206\u8fa8\u7387\u7684\u56fe\u50cf\u3002", "result": "InfGen\u80fd\u591f\u63d0\u5347\u591a\u79cd\u6a21\u578b\u751f\u6210\u4efb\u610f\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u7684\u80fd\u529b\uff0c\u5e76\u5c064K\u56fe\u50cf\u7684\u751f\u6210\u65f6\u95f4\u4ece\u8d85\u8fc7100\u79d2\u7f29\u77ed\u523010\u79d2\u4ee5\u5185\u3002", "conclusion": "InfGen\u901a\u8fc7\u66ff\u6362VAE\u89e3\u7801\u5668\u4e3a\u65b0\u63d0\u51fa\u7684\u751f\u6210\u5668\uff0c\u7b80\u5316\u4e86\u751f\u6210\u8fc7\u7a0b\uff0c\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u6027\uff0c\u5e76\u4e14\u53ef\u4ee5\u5e94\u7528\u4e8e\u4efb\u4f55\u4f7f\u7528\u76f8\u540c\u6f5c\u5728\u7a7a\u95f4\u6a21\u578b\u7684\u573a\u666f\uff0c\u6709\u6548\u5730\u89e3\u51b3\u4e86\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u751f\u6210\u901f\u5ea6\u6162\u7684\u95ee\u9898\u3002"}}
{"id": "2509.10453", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10453", "abs": "https://arxiv.org/abs/2509.10453", "authors": ["Emily Kaczmarek", "Justin Szeto", "Brennan Nichyporuk", "Tal Arbel"], "title": "SSL-AD: Spatiotemporal Self-Supervised Learning for Generalizability and Adaptability Across Alzheimer's Prediction Tasks and Datasets", "comment": null, "summary": "Alzheimer's disease is a progressive, neurodegenerative disorder that causes\nmemory loss and cognitive decline. While there has been extensive research in\napplying deep learning models to Alzheimer's prediction tasks, these models\nremain limited by lack of available labeled data, poor generalization across\ndatasets, and inflexibility to varying numbers of input scans and time\nintervals between scans. In this study, we adapt three state-of-the-art\ntemporal self-supervised learning (SSL) approaches for 3D brain MRI analysis,\nand add novel extensions designed to handle variable-length inputs and learn\nrobust spatial features. We aggregate four publicly available datasets\ncomprising 3,161 patients for pre-training, and show the performance of our\nmodel across multiple Alzheimer's prediction tasks including diagnosis\nclassification, conversion detection, and future conversion prediction.\nImportantly, our SSL model implemented with temporal order prediction and\ncontrastive learning outperforms supervised learning on six out of seven\ndownstream tasks. It demonstrates adaptability and generalizability across\ntasks and number of input images with varying time intervals, highlighting its\ncapacity for robust performance across clinical applications. We release our\ncode and model publicly at https://github.com/emilykaczmarek/SSL-AD.", "AI": {"tldr": "\u901a\u8fc7\u5bf9\u516c\u5f00\u6570\u636e\u96c6\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u5e76\u7ed3\u5408\u65f6\u95f4\u987a\u5e8f\u9884\u6d4b\u548c\u5bf9\u6bd4\u5b66\u4e60\uff0c\u6240\u63d0\u51fa\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u6a21\u578b\u5728\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u9884\u6d4b\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u4e8e\u76d1\u7763\u5b66\u4e60\u6a21\u578b\uff0c\u5e76\u80fd\u9002\u5e94\u4e0d\u540c\u7684\u8f93\u5165\u548c\u65f6\u95f4\u95f4\u9694\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u9884\u6d4b\u4efb\u52a1\u4e2d\u9762\u4e34\u6570\u636e\u4e0d\u8db3\u3001\u6cdb\u5316\u6027\u5dee\u4ee5\u53ca\u8f93\u5165\u626b\u63cf\u6570\u548c\u626b\u63cf\u65f6\u95f4\u95f4\u9694\u53ef\u53d8\u7b49\u95ee\u9898\u3002", "method": "\u672c\u7814\u7a76\u5c06\u4e09\u79cd\u5148\u8fdb\u7684\u65f6\u95f4\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u5e94\u7528\u4e8e3D\u8111\u90e8MRI\u5206\u6790\uff0c\u5e76\u8fdb\u884c\u4e86\u521b\u65b0\u6027\u6539\u8fdb\u4ee5\u5904\u7406\u53ef\u53d8\u957f\u5ea6\u7684\u8f93\u5165\u5e76\u5b66\u4e60\u9c81\u68d2\u7684\u7a7a\u95f4\u7279\u5f81\u3002\u901a\u8fc7\u6574\u5408\u56db\u4e2a\u516c\u5171\u6570\u636e\u96c6\uff08\u51713,161\u540d\u60a3\u8005\uff09\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u5e76\u5728\u591a\u4e2a\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u9884\u6d4b\u4efb\u52a1\uff08\u5305\u62ec\u8bca\u65ad\u5206\u7c7b\u3001\u75be\u75c5\u8f6c\u5316\u68c0\u6d4b\u548c\u672a\u6765\u8f6c\u5316\u9884\u6d4b\uff09\u4e0a\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u3002", "result": "\u6240\u63d0\u51fa\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u6a21\u578b\uff08\u91c7\u7528\u65f6\u95f4\u987a\u5e8f\u9884\u6d4b\u548c\u5bf9\u6bd4\u5b66\u4e60\uff09\u5728\u4e03\u4e2a\u4e0b\u6e38\u4efb\u52a1\u4e2d\u7684\u516d\u4e2a\u4efb\u52a1\u4e0a\u4f18\u4e8e\u76d1\u7763\u5b66\u4e60\u6a21\u578b\uff0c\u5e76\u5728\u4e0d\u540c\u7684\u4efb\u52a1\u3001\u8f93\u5165\u56fe\u50cf\u6570\u91cf\u548c\u65f6\u95f4\u95f4\u9694\u4e0b\u5c55\u73b0\u51fa\u826f\u597d\u7684\u9002\u5e94\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u6a21\u578b\u80fd\u591f\u6709\u6548\u5904\u7406\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u9884\u6d4b\u4efb\u52a1\u4e2d\u7684\u6311\u6218\uff0c\u5e76\u5728\u4e34\u5e8a\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u9c81\u68d2\u7684\u6027\u80fd\u3002"}}
