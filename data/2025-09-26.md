<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 88]
- [cs.CL](#cs.CL) [Total: 66]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 8]
- [cs.LG](#cs.LG) [Total: 113]
- [cs.AR](#cs.AR) [Total: 2]
- [cs.DC](#cs.DC) [Total: 9]
- [cs.SY](#cs.SY) [Total: 1]
- [cs.GR](#cs.GR) [Total: 9]
- [cs.SI](#cs.SI) [Total: 5]
- [cs.MA](#cs.MA) [Total: 2]
- [physics.app-ph](#physics.app-ph) [Total: 2]
- [eess.SY](#eess.SY) [Total: 11]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 15]
- [quant-ph](#quant-ph) [Total: 28]
- [eess.SP](#eess.SP) [Total: 10]
- [cs.DS](#cs.DS) [Total: 1]
- [cs.GT](#cs.GT) [Total: 2]
- [cs.RO](#cs.RO) [Total: 49]
- [cs.LO](#cs.LO) [Total: 3]
- [cs.AI](#cs.AI) [Total: 36]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Leveraging NTPs for Efficient Hallucination Detection in VLMs](https://arxiv.org/abs/2509.20379)
*Ofir Azachi,Kfir Eliyahu,Eyal El Ani,Rom Himelstein,Roi Reichart,Yuval Pinter,Nitay Calderon*

Main category: cs.CV

TL;DR: 通过分析视觉语言模型（VLM）生成文本的下一个词元概率（NTP），可以有效检测幻觉，该方法比使用VLM自身评估更高效，并且结合语言NTP和VLM的幻觉预测分数可以进一步提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（VLM）的幻觉问题（即生成文本与视觉内容不一致）会影响其可靠性。现有检测方法计算量大，增加了延迟。因此，需要一种高效的幻觉检测方法。

Method: 训练传统的机器学习模型，利用VLM的下一个词元概率（NTP）作为信号。NTP直接量化模型的不确定性，低NTP值（高不确定性）与幻觉相关。构建了一个包含1,400个标注语句的数据集来测试该方法。此外，还结合了仅基于生成文本计算的语言NTP，并集成了VLM的幻觉预测分数。

Result: 基于NTP的特征能够有效预测幻觉，使得简单轻量级的机器学习模型能达到与强VLM相当的性能。结合语言NTP可以进一步提升检测性能。将VLM的幻觉预测分数整合到NTP模型中，效果优于单独使用VLM或NTP。

Conclusion: 本文提出的基于NTP的轻量级方法，结合语言NTP和VLM的幻觉预测分数，能够高效且准确地检测VLM的幻觉，为提升VLM的可靠性提供了简单有效的解决方案。

Abstract: Hallucinations of vision-language models (VLMs), which are misalignments
between visual content and generated text, undermine the reliability of VLMs.
One common approach for detecting them employs the same VLM, or a different
one, to assess generated outputs. This process is computationally intensive and
increases model latency. In this paper, we explore an efficient on-the-fly
method for hallucination detection by training traditional ML models over
signals based on the VLM's next-token probabilities (NTPs). NTPs provide a
direct quantification of model uncertainty. We hypothesize that high
uncertainty (i.e., a low NTP value) is strongly associated with hallucinations.
To test this, we introduce a dataset of 1,400 human-annotated statements
derived from VLM-generated content, each labeled as hallucinated or not, and
use it to test our NTP-based lightweight method. Our results demonstrate that
NTP-based features are valuable predictors of hallucinations, enabling fast and
simple ML models to achieve performance comparable to that of strong VLMs.
Furthermore, augmenting these NTPs with linguistic NTPs, computed by feeding
only the generated text back into the VLM, enhances hallucination detection
performance. Finally, integrating hallucination prediction scores from VLMs
into the NTP-based models led to better performance than using either VLMs or
NTPs alone. We hope this study paves the way for simple, lightweight solutions
that enhance the reliability of VLMs.

</details>


### [2] [Quasi-Synthetic Riemannian Data Generation for Writer-Independent Offline Signature Verification](https://arxiv.org/abs/2509.20420)
*Elias N. Zois,Moises Diaz,Salem Said,Miguel A. Ferrer*

Main category: cs.CV

TL;DR: 提出了一种利用对称正定矩阵 (SPD) 的黎曼几何的准合成数据生成框架，用于解决离线手写签名验证中的 writer-independent 问题。


<details>
  <summary>Details</summary>
Motivation: 现有的手写签名验证方法通常依赖真实数据集进行分类器训练，而 writer-independent 的设置尤其具有挑战性，模型需要泛化到未见过的个体。因此，需要一种新的方法来生成数据以解决此问题。

Method: 提出了一种基于黎曼几何的准合成数据生成框架。该框架首先利用一小组真实签名样本在 SPD 空间中生成黎曼高斯混合模型，识别出合成写作者及其属性。然后，通过在每个中心进行黎曼高斯采样来生成合成的 SPD 数据。最后，利用度量学习框架来训练模型，并将其在真实数据集上进行测试。

Result: 在两个主流的签名数据集（包括西方和亚洲书写风格）上进行了实验。结果表明，所提出的准合成方法在 intra- and cross- dataset 评估协议下均能实现低错误率。

Conclusion: 该研究证明了在黎曼空间中生成合成数据用于 writer-independent 手写签名验证系统的潜力。

Abstract: Offline handwritten signature verification remains a challenging task,
particularly in writer-independent settings where models must generalize across
unseen individuals. Recent developments have highlighted the advantage of
geometrically inspired representations, such as covariance descriptors on
Riemannian manifolds. However, past or present, handcrafted or data-driven
methods usually depend on real-world signature datasets for classifier
training. We introduce a quasi-synthetic data generation framework leveraging
the Riemannian geometry of Symmetric Positive Definite matrices (SPD). A small
set of genuine samples in the SPD space is the seed to a Riemannian Gaussian
Mixture which identifies Riemannian centers as synthetic writers and variances
as their properties. Riemannian Gaussian sampling on each center generates
positive as well as negative synthetic SPD populations. A metric learning
framework utilizes pairs of similar and dissimilar SPD points, subsequently
testing it over on real-world datasets. Experiments conducted on two popular
signature datasets, encompassing Western and Asian writing styles, demonstrate
the efficacy of the proposed approach under both intra- and cross- dataset
evaluation protocols. The results indicate that our quasi-synthetic approach
achieves low error rates, highlighting the potential of generating synthetic
data in Riemannian spaces for writer-independent signature verification
systems.

</details>


### [3] [Seedream 4.0: Toward Next-generation Multimodal Image Generation](https://arxiv.org/abs/2509.20427)
*Team Seedream,Yunpeng Chen,Yu Gao,Lixue Gong,Meng Guo,Qiushan Guo,Zhiyao Guo,Xiaoxia Hou,Weilin Huang,Yixuan Huang,Xiaowen Jian,Huafeng Kuang,Zhichao Lai,Fanshi Li,Liang Li,Xiaochen Lian,Chao Liao,Liyang Liu,Wei Liu,Yanzuo Lu,Zhengxiong Luo,Tongtong Ou,Guang Shi,Yichun Shi,Shiqi Sun,Yu Tian,Zhi Tian,Peng Wang,Rui Wang,Xun Wang,Ye Wang,Guofeng Wu,Jie Wu,Wenxu Wu,Yonghui Wu,Xin Xia,Xuefeng Xiao,Shuang Xu,Xin Yan,Ceyuan Yang,Jianchao Yang,Zhonghua Zhai,Chenlin Zhang,Heng Zhang,Qi Zhang,Xinyu Zhang,Yuwei Zhang,Shijia Zhao,Wenliang Zhao,Wenjia Zhu*

Main category: cs.CV

TL;DR: Seedream 4.0 是一个高效、高性能的多模态图像生成系统，集成了文生图、图像编辑和多图合成。


<details>
  <summary>Details</summary>
Motivation: 将文本到图像合成、图像编辑和多图像组合统一到单个框架中，以实现高效和高性能的多模态图像生成。

Method: 开发了一个高效的扩散 Transformer 和一个强大的 VAE，能够显著减少图像 token 数量，从而实现高效的模型训练和快速生成高分辨率图像（1K-4K）。模型在数十亿文本-图像对上进行了预训练，并通过多模态后训练进行了微调，同时支持文生图和图像编辑任务。通过集成对抗性蒸馏、分布匹配、量化和推测性解码等技术来加速推理。

Result: Seedream 4.0 在文生图和多模态图像编辑方面均取得了最先进的成果，特别在复杂的图像编辑和上下文推理任务中展现了出色的多模态能力，并支持多图参考和多输出生成。生成 2K 图像的推理时间最快可达 1.8 秒。

Conclusion: Seedream 4.0 将传统的文生图系统扩展为更具交互性和多维度的创意工具，推动了生成式人工智能在创意和专业应用方面的边界。

Abstract: We introduce Seedream 4.0, an efficient and high-performance multimodal image
generation system that unifies text-to-image (T2I) synthesis, image editing,
and multi-image composition within a single framework. We develop a highly
efficient diffusion transformer with a powerful VAE which also can reduce the
number of image tokens considerably. This allows for efficient training of our
model, and enables it to fast generate native high-resolution images (e.g.,
1K-4K). Seedream 4.0 is pretrained on billions of text-image pairs spanning
diverse taxonomies and knowledge-centric concepts. Comprehensive data
collection across hundreds of vertical scenarios, coupled with optimized
strategies, ensures stable and large-scale training, with strong
generalization. By incorporating a carefully fine-tuned VLM model, we perform
multi-modal post-training for training both T2I and image editing tasks
jointly. For inference acceleration, we integrate adversarial distillation,
distribution matching, and quantization, as well as speculative decoding. It
achieves an inference time of up to 1.8 seconds for generating a 2K image
(without a LLM/VLM as PE model). Comprehensive evaluations reveal that Seedream
4.0 can achieve state-of-the-art results on both T2I and multimodal image
editing. In particular, it demonstrates exceptional multimodal capabilities in
complex tasks, including precise image editing and in-context reasoning, and
also allows for multi-image reference, and can generate multiple output images.
This extends traditional T2I systems into an more interactive and
multidimensional creative tool, pushing the boundary of generative AI for both
creativity and professional applications. Seedream 4.0 is now accessible on
https://www.volcengine.com/experience/ark?launch=seedream.

</details>


### [4] [A Contrastive Learning Framework for Breast Cancer Detection](https://arxiv.org/abs/2509.20474)
*Samia Saeed,Khuram Naveed*

Main category: cs.CV

TL;DR: 本研究提出了一种基于对比学习（CL）的框架，使用半监督CL方法和相似性指标在大量未标记的乳腺X光数据上训练Resnet-50，以提高乳腺癌的早期检测准确性，尤其是在标记数据有限的情况下。


<details>
  <summary>Details</summary>
Motivation: 为了降低乳腺癌的死亡率，早期检测至关重要。虽然传统的计算机辅助检测（CAD）系统依赖于图像分析，但深度学习方法因其有效性而备受关注。然而，深度学习方法在标记数据集有限的情况下准确性会受到影响。因此，有必要开发一种在标记数据有限的情况下也能有效提高检测准确性的方法。

Method: 本研究提出了一种半监督的对比学习（CL）框架。该框架使用相似性指标在大量的未标记乳腺X光数据上训练Resnet-50模型。研究中采用了各种数据增强和变换技术来提高模型性能。最后，在少量标记数据上对模型进行微调。

Result: 所提出的对比学习框架在基准数据集INbreast和MIAS上取得了96.7%的乳腺癌检测准确率，优于现有的最先进方法。

Conclusion: 本研究提出的基于对比学习的半监督方法能够有效解决标记数据有限的问题，显著提高了乳腺癌检测的准确性，达到了96.7%的准确率，为早期检测提供了有前景的解决方案。

Abstract: Breast cancer, the second leading cause of cancer-related deaths globally,
accounts for a quarter of all cancer cases [1]. To lower this death rate, it is
crucial to detect tumors early, as early-stage detection significantly improves
treatment outcomes. Advances in non-invasive imaging techniques have made early
detection possible through computer-aided detection (CAD) systems which rely on
traditional image analysis to identify malignancies. However, there is a
growing shift towards deep learning methods due to their superior
effectiveness. Despite their potential, deep learning methods often struggle
with accuracy due to the limited availability of large-labeled datasets for
training. To address this issue, our study introduces a Contrastive Learning
(CL) framework, which excels with smaller labeled datasets. In this regard, we
train Resnet-50 in semi supervised CL approach using similarity index on a
large amount of unlabeled mammogram data. In this regard, we use various
augmentation and transformations which help improve the performance of our
approach. Finally, we tune our model on a small set of labelled data that
outperforms the existing state of the art. Specifically, we observed a 96.7%
accuracy in detecting breast cancer on benchmark datasets INbreast and MIAS.

</details>


### [5] [Are Foundation Models Ready for Industrial Defect Recognition? A Reality Check on Real-World Data](https://arxiv.org/abs/2509.20479)
*Simon Baeuerle,Pratik Khanna,Nils Friederich,Angelo Jovin Yamachui Sitcheu,Damir Shakirov,Andreas Steimer,Ralf Mikut*

Main category: cs.CV

TL;DR: 在实际工业图像数据上，基础模型（FM）表现不佳，尽管它们在公开数据集上表现良好。


<details>
  <summary>Details</summary>
Motivation: 基础模型（FM）在各种文本和图像处理任务上表现出色，并且能够进行零样本泛化，这使其在系列制造的自动化质量检验中具有应用潜力。与需要标注训练数据的监督学习模型相比，FM可以通过简单的文本提示来描述异常，并跨多个产品使用，从而节省大量模型设置和实施成本。然而，在实际工业场景中的应用仍需验证。

Method: 测试多种近期基础模型（FM）在定制的真实世界工业图像数据和公开图像数据上的表现。

Result: 所有被测FM在真实世界的工业图像数据上均表现不佳，但在相同的公开基准数据集上表现良好。

Conclusion: 基础模型（FM）在实际工业图像数据上的表现不佳，表明它们在零样本工业质量检验的应用中存在挑战，尽管它们在公开数据集上表现出色。

Abstract: Foundation Models (FMs) have shown impressive performance on various text and
image processing tasks. They can generalize across domains and datasets in a
zero-shot setting. This could make them suitable for automated quality
inspection during series manufacturing, where various types of images are being
evaluated for many different products. Replacing tedious labeling tasks with a
simple text prompt to describe anomalies and utilizing the same models across
many products would save significant efforts during model setup and
implementation. This is a strong advantage over supervised Artificial
Intelligence (AI) models, which are trained for individual applications and
require labeled training data. We test multiple recent FMs on both custom
real-world industrial image data and public image data. We show that all of
those models fail on our real-world data, while the very same models perform
well on public benchmark datasets.

</details>


### [6] [Shared Neural Space: Unified Precomputed Feature Encoding for Multi-Task and Cross Domain Vision](https://arxiv.org/abs/2509.20481)
*Jing Li,Oskar Bartosz,Chengyu Wang,Michal Wnuczynski,Dilshan Godaliyadda,Michael Polley*

Main category: cs.CV

TL;DR: 提出了一个通用的神经空间（NS），用于解决现有AI模型在处理一系列模块化任务时的低效问题，该模型通过共享的特征空间减少了冗余，提高了跨域泛化能力，并允许在各种硬件上进行高效的多任务处理。


<details>
  <summary>Details</summary>
Motivation: 现有的AI模型通常针对特定任务进行定制，这对于需要处理一系列模块化任务的应用来说效率低下，因为每个任务都需要映射到一个不同的潜在域。

Method: 提出了一种通用的神经空间（NS），采用编码器-解码器框架，跨视觉和成像任务预计算特征。编码器学习具有变换感知能力的通用表示，使多个下游AI模块能够共享同一个特征空间。该骨干网络采用轻量级CNN设计。

Result: 证明了在神经空间中可以高效地执行去马赛克、去噪、深度估计和语义分割等成像和视觉任务，并且相比于大型Transformer骨干网络，该模型更加轻量级，支持更广泛的硬件。

Conclusion: 提出的通用神经空间（NS）通过共享特征空间，提高了AI模型在处理一系列模块化任务时的效率和泛化能力，并且支持更广泛的硬件平台。

Abstract: The majority of AI models in imaging and vision are customized to perform on
specific high-precision task. However, this strategy is inefficient for
applications with a series of modular tasks, since each requires a mapping into
a disparate latent domain. To address this inefficiency, we proposed a
universal Neural Space (NS), where an encoder-decoder framework pre-computes
features across vision and imaging tasks. Our encoder learns transformation
aware, generalizable representations, which enable multiple downstream AI
modules to share the same feature space. This architecture reduces redundancy,
improves generalization across domain shift, and establishes a foundation for
effecient multi-task vision pipelines. Furthermore, as opposed to larger
transformer backbones, our backbone is lightweight and CNN-based, allowing for
wider across hardware. We furthur demonstrate that imaging and vision modules,
such as demosaicing, denoising, depth estimation and semantic segmentation can
be performed efficiently in the NS.

</details>


### [7] [Data-Efficient Stream-Based Active Distillation for Scalable Edge Model Deployment](https://arxiv.org/abs/2509.20484)
*Dani Manjah,Tim Bary,Benoît Gérin,Benoît Macq,Christophe de Vleeschouwer*

Main category: cs.CV

TL;DR: 通过高置信度流式选择和多样性方法，在相似训练负载下，以最少的查询次数来训练高质量模型，以适应边缘计算。


<details>
  <summary>Details</summary>
Motivation: 为了解决边缘摄像头系统模型更新的效率和成本问题，需要选择最有用的图像进行训练，以提高模型质量并降低传输成本。

Method: 提出了一种结合高置信度流式选择和多样性方法的数据选择策略，用于训练适用于边缘设备的模型。

Result: 该策略在相似的训练负载下，能够以最少的查询次数生成高质量的模型，有效降低了数据集查询成本。

Conclusion: 结合高置信度流式选择和多样性方法的数据选择策略，是提高边缘摄像头系统模型更新效率和降低成本的有效途径。

Abstract: Edge camera-based systems are continuously expanding, facing ever-evolving
environments that require regular model updates. In practice, complex teacher
models are run on a central server to annotate data, which is then used to
train smaller models tailored to the edge devices with limited computational
power. This work explores how to select the most useful images for training to
maximize model quality while keeping transmission costs low. Our work shows
that, for a similar training load (i.e., iterations), a high-confidence
stream-based strategy coupled with a diversity-based approach produces a
high-quality model with minimal dataset queries.

</details>


### [8] [InstructVTON: Optimal Auto-Masking and Natural-Language-Guided Interactive Style Control for Inpainting-Based Virtual Try-On](https://arxiv.org/abs/2509.20524)
*Julien Han,Shuwen Qiu,Qi Li,Xingzi Xu,Mehmet Saygin Seyfioglu,Kavosh Asadi,Karim Bouyarmane*

Main category: cs.CV

TL;DR: InstructVTON是一个基于指令的虚拟试穿系统，利用VLM和图像分割自动生成掩码，实现精细化的服装造型控制，并可与现有模型集成以获得最佳效果。


<details>
  <summary>Details</summary>
Motivation: 现有基于掩码的虚拟试穿方法难以精确控制生成布局，尤其在复杂造型场景下（如袖子卷起），掩码生成困难且可能不适用。

Method: InstructVTON利用视觉语言模型（VLM）和图像分割模型，根据用户提供的图像和文本指令自动生成二值掩码，将虚拟试穿问题构建为图像引导或图像条件化的图像修复任务。

Result: InstructVTON能够实现对虚拟试穿结果的细粒度、复杂造型控制，简化了用户体验，无需用户手动绘制精确掩码，并能处理传统掩码方法难以解决的场景。

Conclusion: InstructVTON通过自动化掩码生成和支持复杂造型控制，简化了虚拟试穿流程，并能与现有模型协同工作，达到最先进的性能。

Abstract: We present InstructVTON, an instruction-following interactive virtual try-on
system that allows fine-grained and complex styling control of the resulting
generation, guided by natural language, on single or multiple garments. A
computationally efficient and scalable formulation of virtual try-on formulates
the problem as an image-guided or image-conditioned inpainting task. These
inpainting-based virtual try-on models commonly use a binary mask to control
the generation layout. Producing a mask that yields desirable result is
difficult, requires background knowledge, might be model dependent, and in some
cases impossible with the masking-based approach (e.g. trying on a long-sleeve
shirt with "sleeves rolled up" styling on a person wearing long-sleeve shirt
with sleeves down, where the mask will necessarily cover the entire sleeve).
InstructVTON leverages Vision Language Models (VLMs) and image segmentation
models for automated binary mask generation. These masks are generated based on
user-provided images and free-text style instructions. InstructVTON simplifies
the end-user experience by removing the necessity of a precisely drawn mask,
and by automating execution of multiple rounds of image generation for try-on
scenarios that cannot be achieved with masking-based virtual try-on models
alone. We show that InstructVTON is interoperable with existing virtual try-on
models to achieve state-of-the-art results with styling control.

</details>


### [9] [Innovative Deep Learning Architecture for Enhanced Altered Fingerprint Recognition](https://arxiv.org/abs/2509.20537)
*Dana A Abdullah,Dana Rasul Hamad,Bishar Rasheed Ibrahim,Sirwan Abdulwahid Aula,Aso Khaleel Ameen,Sabat Salih Hamadamin*

Main category: cs.CV

TL;DR: DeepAFRNet是一个深度学习模型，可以识别被篡改的指纹，在真实篡改数据集上达到了96.7%-99.54%的准确率，强调了阈值选择的重要性。


<details>
  <summary>Details</summary>
Motivation: 为了应对边境控制、法证和财政准入等应用中，对手指纹模式进行篡改以逃避检测的挑战，需要鲁棒的被篡改指纹识别技术。

Method: 提出了一种名为DeepAFRNet的深度学习模型，使用VGG16骨干提取高维特征，并采用余弦相似度比较嵌入来实现被篡改指纹的匹配和识别。

Result: 在SOCOFing真实篡改子集上，针对三个难度级别（简单、中等、困难），DeepAFRNet在严格阈值下分别取得了96.7%、98.76%和99.54%的准确率。阈值敏感性研究表明，当阈值从0.92放松到0.72时，准确率急剧下降至7.86%、27.05%和29.51%。

Conclusion: DeepAFRNet模型能够有效识别真实篡改的指纹，其在真实篡改数据集上的表现优于以往基于合成篡改或有限验证协议的工作，表明该模型已准备好部署于对安全性和识别鲁棒性都有要求的真实世界场景。阈值选择对于维持系统准确性至关重要。

Abstract: Altered fingerprint recognition (AFR) is challenging for biometric
verification in applications such as border control, forensics, and fiscal
admission. Adversaries can deliberately modify ridge patterns to evade
detection, so robust recognition of altered prints is essential. We present
DeepAFRNet, a deep learning recognition model that matches and recognizes
distorted fingerprint samples. The approach uses a VGG16 backbone to extract
high-dimensional features and cosine similarity to compare embeddings. We
evaluate on the SOCOFing Real-Altered subset with three difficulty levels
(Easy, Medium, Hard). With strict thresholds, DeepAFRNet achieves accuracies of
96.7 percent, 98.76 percent, and 99.54 percent for the three levels. A
threshold-sensitivity study shows that relaxing the threshold from 0.92 to 0.72
sharply degrades accuracy to 7.86 percent, 27.05 percent, and 29.51 percent,
underscoring the importance of threshold selection in biometric systems. By
using real altered samples and reporting per-level metrics, DeepAFRNet
addresses limitations of prior work based on synthetic alterations or limited
verification protocols, and indicates readiness for real-world deployments
where both security and recognition resilience are critical.

</details>


### [10] [Large Pre-Trained Models for Bimanual Manipulation in 3D](https://arxiv.org/abs/2509.20579)
*Hanna Yurchyk,Wei-Di Chang,Gregory Dudek,David Meger*

Main category: cs.CV

TL;DR: 通过将预训练 Vision Transformer 的注意力图集成到体素表示中，以增强双臂机器人操作，并在 RLBench 双臂基准测试中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是提升双臂机器人操作任务中的性能，特别是通过引入视觉信息来增强机器人的决策能力。

Method: 本研究提出了一种将预训练 Vision Transformer (DINOv2) 的注意力图提取并转化为体素级语义线索的方法，并将其集成到行为克隆策略中，以指导双臂机器人操作。

Result: 与最先进的基于体素的策略相比，所提出的注意力引导特征化在 RLBench 双臂基准测试的所有任务上平均绝对提高了 8.2%，相对提高了 21.9%。

Conclusion: 将预训练 ViT 的注意力图融入体素表示能够有效地提升双臂机器人操作的性能。

Abstract: We investigate the integration of attention maps from a pre-trained Vision
Transformer into voxel representations to enhance bimanual robotic
manipulation. Specifically, we extract attention maps from DINOv2, a
self-supervised ViT model, and interpret them as pixel-level saliency scores
over RGB images. These maps are lifted into a 3D voxel grid, resulting in
voxel-level semantic cues that are incorporated into a behavior cloning policy.
When integrated into a state-of-the-art voxel-based policy, our
attention-guided featurization yields an average absolute improvement of 8.2%
and a relative gain of 21.9% across all tasks in the RLBench bimanual
benchmark.

</details>


### [11] [A Comparative Benchmark of Real-time Detectors for Blueberry Detection towards Precision Orchard Management](https://arxiv.org/abs/2509.20580)
*Xinyang Mu,Yuzhen Lu,Boyang Deng*

Main category: cs.CV

TL;DR: 本研究提出了一个针对蓝莓检测的新基准，评估了 YOLO 和 RT-DETR 系列的 36 种模型变体，并在包含 85,879 个标注实例的新数据集上进行了测试。通过半监督学习进一步提升了检测性能，并公开了数据集和软件。


<details>
  <summary>Details</summary>
Motivation: 在自然环境中准确检测蓝莓是一个挑战，需要能够处理各种光照、遮挡和运动模糊的大规模数据集。同时，在实际应用中需要考虑模型的准确性、速度和内存的权衡。

Method: 本研究对 YOLO (v8-v12) 和 RT-DETR (v1-v2) 系列的 36 种模型变体进行了基准分析，并在新收集的包含 661 张图像和 85,879 个标注实例的蓝莓检测数据集上进行了评估。此外，还采用了基于无偏均教的半监督学习方法，在 1,035 张未标注图像上对模型进行了微调。

Result: 在未微调的情况下，YOLOv12m 的 mAP@50 为 93.3%，RT-DETRv2-X 的 mAP@50 为 93.6%。经过半监督学习微调后，RT-DETR-v2-X 达到了最高的 mAP@50 为 94.8%，准确率提升了 1.2%。中等规模的模型在准确性和速度之间取得了较好的平衡。

Conclusion: 先进的实时目标检测器在蓝莓检测任务上表现出色，半监督学习可以进一步提升性能。研究表明，RT-DETRv2-X 在经过半监督学习后表现最佳。未来需要更多研究来探索如何更好地利用跨领域未标注数据。本研究公开了数据集和软件，以促进未来的研究。

Abstract: Blueberry detection in natural environments remains challenging due to
variable lighting, occlusions, and motion blur due to environmental factors and
imaging devices. Deep learning-based object detectors promise to address these
challenges, but they demand a large-scale, diverse dataset that captures the
real-world complexities. Moreover, deploying these models in practical
scenarios often requires the right accuracy/speed/memory trade-off in model
selection. This study presents a novel comparative benchmark analysis of
advanced real-time object detectors, including YOLO (You Only Look Once)
(v8-v12) and RT-DETR (Real-Time Detection Transformers) (v1-v2) families,
consisting of 36 model variants, evaluated on a newly curated dataset for
blueberry detection. This dataset comprises 661 canopy images collected with
smartphones during the 2022-2023 seasons, consisting of 85,879 labelled
instances (including 36,256 ripe and 49,623 unripe blueberries) across a wide
range of lighting conditions, occlusions, and fruit maturity stages. Among the
YOLO models, YOLOv12m achieved the best accuracy with a mAP@50 of 93.3%, while
RT-DETRv2-X obtained a mAP@50 of 93.6%, the highest among all the RT-DETR
variants. The inference time varied with the model scale and complexity, and
the mid-sized models appeared to offer a good accuracy-speed balance. To
further enhance detection performance, all the models were fine-tuned using
Unbiased Mean Teacher-based semi-supervised learning (SSL) on a separate set of
1,035 unlabeled images acquired by a ground-based machine vision platform in
2024. This resulted in accuracy gains ranging from -1.4% to 2.9%, with
RT-DETR-v2-X achieving the best mAP@50 of 94.8%. More in-depth research into
SSL is needed to better leverage cross-domain unlabeled data. Both the dataset
and software programs of this study are made publicly available to support
further research.

</details>


### [12] [Region-of-Interest Augmentation for Mammography Classification under Patient-Level Cross-Validation](https://arxiv.org/abs/2509.20585)
*Farbod Bigdeli,Mohsen Mohammadagha,Ali Bigdeli*

Main category: cs.CV

TL;DR: 通过在训练过程中使用区域感兴趣（ROI）增强策略，改进了在有限数据集上的乳腺癌筛查模型，但仅在部分评估指标上显示出适度改进。


<details>
  <summary>Details</summary>
Motivation: 在有限分辨率和样本量的数据集上，深度学习在乳腺癌筛查中的应用受到限制，需要改进方法来提高其性能。

Method: 提出了一种轻量级的区域感兴趣（ROI）增强策略，在训练时随机替换全图为ROI裁剪图，并引入抖动以增加变化性。在Mini-DDSM数据集上进行了严格的患者级别交叉验证。

Result: ROI增强策略在Mini-DDSM数据集上实现了适度的平均ROC-AUC增益，但PR-AUC持平或略有下降。模型性能因交叉验证折叠而异。

Conclusion: 简单的数据中心ROI策略可以在不增加标签或修改模型结构的情况下，提高在约束条件下的乳腺X光摄影分类性能。

Abstract: Breast cancer screening with mammography remains central to early detection
and mortality reduction. Deep learning has shown strong potential for
automating mammogram interpretation, yet limited-resolution datasets and small
sample sizes continue to restrict performance. We revisit the Mini-DDSM dataset
(9,684 images; 2,414 patients) and introduce a lightweight region-of-interest
(ROI) augmentation strategy. During training, full images are probabilistically
replaced with random ROI crops sampled from a precomputed, label-free
bounding-box bank, with optional jitter to increase variability. We evaluate
under strict patient-level cross-validation and report ROC-AUC, PR-AUC, and
training-time efficiency metrics (throughput and GPU memory). Because ROI
augmentation is training-only, inference-time cost remains unchanged. On
Mini-DDSM, ROI augmentation (best: p_roi = 0.10, alpha = 0.10) yields modest
average ROC-AUC gains, with performance varying across folds; PR-AUC is flat to
slightly lower. These results demonstrate that simple, data-centric ROI
strategies can enhance mammography classification in constrained settings
without requiring additional labels or architectural modifications.

</details>


### [13] [Reflect3r: Single-View 3D Stereo Reconstruction Aided by Mirror Reflections](https://arxiv.org/abs/2509.20607)
*Jing Wu,Zirui Wang,Iro Laina,Victor Adrian Prisacariu*

Main category: cs.CV

TL;DR: 本研究提出了一种利用镜像反射从单张图像生成多视图立体图像的方法，并取得了显著效果。


<details>
  <summary>Details</summary>
Motivation: 日常环境中的镜面反射能够提供额外的立体信息，但现有技术未能充分利用这一特性。本研究旨在利用镜面反射，通过构建虚拟相机，直接在像素域生成虚拟视图，从而实现从单张图像进行多视图立体重建。

Method: 本研究将镜面反射视为辅助视图，设计了一种物理上有效的虚拟相机变换，实现了像素域的虚拟视图生成。此外，研究还提出了对称感知损失来优化姿态估计，并自然地将方法扩展到动态场景，实现了高效的逐帧几何恢复。研究人员还构建了一个包含16个Blender场景的合成数据集，用以进行定量评估。

Result: 通过在真实和合成数据上的大量实验，证明了该方法在多视图立体重建方面的有效性。

Conclusion: 本研究成功利用镜面反射实现了从单张图像进行多视图立体重建，简化了成像过程，并提高了三维重建的泛化性和鲁棒性。所提出的方法对动态场景也同样有效。

Abstract: Mirror reflections are common in everyday environments and can provide stereo
information within a single capture, as the real and reflected virtual views
are visible simultaneously. We exploit this property by treating the reflection
as an auxiliary view and designing a transformation that constructs a
physically valid virtual camera, allowing direct pixel-domain generation of the
virtual view while adhering to the real-world imaging process. This enables a
multi-view stereo setup from a single image, simplifying the imaging process,
making it compatible with powerful feed-forward reconstruction models for
generalizable and robust 3D reconstruction. To further exploit the geometric
symmetry introduced by mirrors, we propose a symmetric-aware loss to refine
pose estimation. Our framework also naturally extends to dynamic scenes, where
each frame contains a mirror reflection, enabling efficient per-frame geometry
recovery. For quantitative evaluation, we provide a fully customizable
synthetic dataset of 16 Blender scenes, each with ground-truth point clouds and
camera poses. Extensive experiments on real-world data and synthetic data are
conducted to illustrate the effectiveness of our method.

</details>


### [14] [Recov-Vision: Linking Street View Imagery and Vision-Language Models for Post-Disaster Recovery](https://arxiv.org/abs/2509.20628)
*Yiming Xiao,Archit Gupta,Miguel Esparza,Yu-Hsuan Ho,Antonia Sebastian,Hannah Weas,Rose Houck,Ali Mostafavi*

Main category: cs.CV

TL;DR: FacadeTrack是一个街景图像分析框架，用于评估灾后建筑物的居住状况，通过链接街景视频和地块信息，提取可解释的属性，并采用两种策略进行决策，在飓风灾后评估中表现出高精度和召回率。


<details>
  <summary>Details</summary>
Motivation: 灾后建筑物居住状况的评估对于分诊、检查、恢复公用设施和公平分配资源至关重要。而现有的方法，如仅使用高空图像，会忽略决定居住性的 fachada 和入口线索，而街景图像虽然能捕捉这些细节，但数据稀疏且难以与地块对齐。

Method: FacadeTrack是一个街景、语言引导的框架，它将全景视频链接到地块，校正到 fachada 视图，并提取可解释的属性（例如，入口阻塞、临时覆盖物、局部碎片），这些属性可以驱动两种决策策略：一种透明的单阶段规则，以及一种将感知与保守推理分离的两阶段设计。

Result: 在对两次飓风 Helene 灾后进行的调查中，两阶段方法实现了 0.927 的精确率、0.781 的召回率和 0.848 的 F-1 分数，而单阶段基线方法的精确率为 0.943、召回率为 0.728、F-1 分数为 0.822。

Conclusion: FacadeTrack 框架不仅提高了灾后建筑物居住状况评估的准确性，而且通过中间属性和空间诊断揭示了错误的发生地点和原因，从而能够进行有针对性的质量控制。该流程提供了可审计、可扩展的居住状况评估，适用于与地理空间和应急管理工作流程的集成。

Abstract: Building-level occupancy after disasters is vital for triage, inspections,
utility re-energization, and equitable resource allocation. Overhead imagery
provides rapid coverage but often misses facade and access cues that determine
habitability, while street-view imagery captures those details but is sparse
and difficult to align with parcels. We present FacadeTrack, a street-level,
language-guided framework that links panoramic video to parcels, rectifies
views to facades, and elicits interpretable attributes (for example, entry
blockage, temporary coverings, localized debris) that drive two decision
strategies: a transparent one-stage rule and a two-stage design that separates
perception from conservative reasoning. Evaluated across two post-Hurricane
Helene surveys, the two-stage approach achieves a precision of 0.927, a recall
of 0.781, and an F-1 score of 0.848, compared with the one-stage baseline at a
precision of 0.943, a recall of 0.728, and an F-1 score of 0.822. Beyond
accuracy, intermediate attributes and spatial diagnostics reveal where and why
residual errors occur, enabling targeted quality control. The pipeline provides
auditable, scalable occupancy assessments suitable for integration into
geospatial and emergency-management workflows.

</details>


### [15] [Human Semantic Representations of Social Interactions from Moving Shapes](https://arxiv.org/abs/2509.20673)
*Yiling Yun,Hongjing Lu*

Main category: cs.CV

TL;DR: 人类通过视觉和语义信息来识别社会互动，其中语义信息，特别是基于动词的语义信息，比视觉信息更能解释人类的判断。


<details>
  <summary>Details</summary>
Motivation: 探讨人类在识别简单动画中的社会互动时，除了视觉特征外，还采用了何种语义表征。

Method: 研究一：要求参与者根据动画的印象进行标注，分析标注结果的分布。研究二：通过计算27种社会互动的相似性判断，构建表征几何，并与基于视觉特征、标签和动画描述的语义嵌入的模型预测进行比较。

Result: 研究一发现人类的标注结果是分布式的。研究二发现语义模型提供了视觉特征之外的互补信息，其中基于动词的语义嵌入最能解释人类的相似性判断。

Conclusion: 简单的显示中的社会感知反映了社会互动的语义结构，连接了视觉和抽象表征。

Abstract: Humans are social creatures who readily recognize various social interactions
from simple display of moving shapes. While previous research has often focused
on visual features, we examine what semantic representations that humans employ
to complement visual features. In Study 1, we directly asked human participants
to label the animations based on their impression of moving shapes. We found
that human responses were distributed. In Study 2, we measured the
representational geometry of 27 social interactions through human similarity
judgments and compared it with model predictions based on visual features,
labels, and semantic embeddings from animation descriptions. We found that
semantic models provided complementary information to visual features in
explaining human judgments. Among the semantic models, verb-based embeddings
extracted from descriptions account for human similarity judgments the best.
These results suggest that social perception in simple displays reflects the
semantic structure of social interactions, bridging visual and abstract
representations.

</details>


### [16] [Enhancing Cross-View Geo-Localization Generalization via Global-Local Consistency and Geometric Equivariance](https://arxiv.org/abs/2509.20684)
*Xiaowei Wang,Di Wang,Ke Li,Yifeng Wang,Chengjian Wang,Libin Sun,Zhihong Wu,Yiming Zhang,Quan Wang*

Main category: cs.CV

TL;DR: EGS框架通过使用E(2)-可定向CNN编码器提取稳定特征，并构建包含虚拟超级节点的图来聚合全局语义，从而提高了跨域视觉地理定位的性能。


<details>
  <summary>Details</summary>
Motivation: 现有跨视图地理定位方法在应对无人机姿态和视场变化引起的外观变化以及同时捕捉全局和局部细节方面存在挑战。

Method: 提出了一种名为EGS的新型跨视图地理定位框架，该框架采用E(2)-可定向CNN编码器来提取对旋转和视点变化鲁棒的特征，并构建了一个带虚拟超级节点的图来整合全局和局部信息，以实现全局-局部一致性。

Result: 在University-1652和SUES-200数据集上的实验表明，EGS在跨域视觉地理定位方面取得了显著的性能提升，达到了新的最先进水平。

Conclusion: EGS框架通过其设计的编码器和图结构，成功解决了跨域视觉地理定位中的关键挑战，提高了在不同视角下的匹配鲁棒性和准确性。

Abstract: Cross-view geo-localization (CVGL) aims to match images of the same location
captured from drastically different viewpoints. Despite recent progress,
existing methods still face two key challenges: (1) achieving robustness under
severe appearance variations induced by diverse UAV orientations and fields of
view, which hinders cross-domain generalization, and (2) establishing reliable
correspondences that capture both global scene-level semantics and fine-grained
local details. In this paper, we propose EGS, a novel CVGL framework designed
to enhance cross-domain generalization. Specifically, we introduce an
E(2)-Steerable CNN encoder to extract stable and reliable features under
rotation and viewpoint shifts. Furthermore, we construct a graph with a virtual
super-node that connects to all local nodes, enabling global semantics to be
aggregated and redistributed to local regions, thereby enforcing global-local
consistency. Extensive experiments on the University-1652 and SUES-200
benchmarks demonstrate that EGS consistently achieves substantial performance
gains and establishes a new state of the art in cross-domain CVGL.

</details>


### [17] [DENet: Dual-Path Edge Network with Global-Local Attention for Infrared Small Target Detection](https://arxiv.org/abs/2509.20701)
*Jiayi Zuo,Songwei Pei,Qian Li*

Main category: cs.CV

TL;DR: 提出了一种新的双路径边缘网络（Dual-Path Edge Network）来解决红外小目标检测中的挑战，该网络通过两个互补的路径分别处理边缘增强和语义建模。


<details>
  <summary>Details</summary>
Motivation: 红外小目标检测对于灾难预警和海上监视等遥感应用至关重要，但由于缺乏独特的纹理和形态特征，小目标容易与杂乱的背景融为一体。现有深度模型在捕捉小目标的高分辨率空间细节和提取大目标的鲁棒语义上下文之间存在冲突，导致特征不对齐和性能不佳。现有方法依赖于固定的梯度算子或简单的注意力机制，难以在低对比度和高噪声下精确提取目标边缘。

Method: 提出了一种新的双路径边缘网络。第一条路径使用双向交互模块（Bidirectional Interaction Module），结合局部自注意力和全局注意力（基于Transformer）来捕捉多尺度特征依赖关系和长距离语义信息。第二条路径引入了多边缘细化器（Multi-Edge Refiner），使用多尺度的泰勒有限差分算子和注意力门控机制来增强边缘细节并抑制噪声。

Result: 该方法结合了结构语义和边缘细化，为精确的红外小目标检测和定位提供了一个统一的框架，能够处理不同尺寸的目标，同时有效抑制噪声。

Conclusion: 该双路径边缘网络通过显式地将边缘增强和语义建模分离到两个互补的处理路径中，解决了红外小目标检测的挑战。

Abstract: Infrared small target detection is crucial for remote sensing applications
like disaster warning and maritime surveillance. However, due to the lack of
distinctive texture and morphological features, infrared small targets are
highly susceptible to blending into cluttered and noisy backgrounds. A
fundamental challenge in designing deep models for this task lies in the
inherent conflict between capturing high-resolution spatial details for minute
targets and extracting robust semantic context for larger targets, often
leading to feature misalignment and suboptimal performance. Existing methods
often rely on fixed gradient operators or simplistic attention mechanisms,
which are inadequate for accurately extracting target edges under low contrast
and high noise. In this paper, we propose a novel Dual-Path Edge Network that
explicitly addresses this challenge by decoupling edge enhancement and semantic
modeling into two complementary processing paths. The first path employs a
Bidirectional Interaction Module, which uses both Local Self-Attention and
Global Self-Attention to capture multi-scale local and global feature
dependencies. The global attention mechanism, based on a Transformer
architecture, integrates long-range semantic relationships and contextual
information, ensuring robust scene understanding. The second path introduces
the Multi-Edge Refiner, which enhances fine-grained edge details using cascaded
Taylor finite difference operators at multiple scales. This mathematical
approach, along with an attention-driven gating mechanism, enables precise edge
localization and feature enhancement for targets of varying sizes, while
effectively suppressing noise. Our method provides a promising solution for
precise infrared small target detection and localization, combining structural
semantics and edge refinement in a unified framework.

</details>


### [18] [Beyond the Individual: Introducing Group Intention Forecasting with SHOT Dataset](https://arxiv.org/abs/2509.20715)
*Ruixu Zhang,Yuran Wang,Xinyi Hu,Chaoyu Mai,Wenxuan Liu,Danni Xu,Xian Zhong,Zheng Wang*

Main category: cs.CV

TL;DR: 该论文提出了一种名为“群智预测”（GIF）的新任务，用于预测群体意图的出现，并介绍了首个用于此任务的大规模数据集“SHOT”和一个名为“GIFT”的预测框架。


<details>
  <summary>Details</summary>
Motivation: 传统意图识别侧重于个体意图，忽略了群体设置中的集体意图的复杂性。

Method: 提出“群智预测”（GIF）任务，并构建了首个大规模数据集“SHOT”，包含1979个篮球视频片段，涵盖多视角和多层次意图。还提出了“GIFT”框架，用于提取个体特征和建模群体动态以预测意图的出现。

Result: 实验结果证明了“SHOT”数据集和“GIFT”框架在群智预测任务上的有效性。

Conclusion: 该研究为未来的群智预测研究奠定了基础。

Abstract: Intention recognition has traditionally focused on individual intentions,
overlooking the complexities of collective intentions in group settings. To
address this limitation, we introduce the concept of group intention, which
represents shared goals emerging through the actions of multiple individuals,
and Group Intention Forecasting (GIF), a novel task that forecasts when group
intentions will occur by analyzing individual actions and interactions before
the collective goal becomes apparent. To investigate GIF in a specific
scenario, we propose SHOT, the first large-scale dataset for GIF, consisting of
1,979 basketball video clips captured from 5 camera views and annotated with 6
types of individual attributes. SHOT is designed with 3 key characteristics:
multi-individual information, multi-view adaptability, and multi-level
intention, making it well-suited for studying emerging group intentions.
Furthermore, we introduce GIFT (Group Intention ForecasTer), a framework that
extracts fine-grained individual features and models evolving group dynamics to
forecast intention emergence. Experimental results confirm the effectiveness of
SHOT and GIFT, establishing a strong foundation for future research in group
intention forecasting. The dataset is available at
https://xinyi-hu.github.io/SHOT_DATASET.

</details>


### [19] [Neptune-X: Active X-to-Maritime Generation for Universal Maritime Object Detection](https://arxiv.org/abs/2509.20745)
*Yu Guo,Shengfeng He,Yuxu Lu,Haonan An,Yihang Tao,Huilin Zhu,Jingxian Liu,Yuguang Fang*

Main category: cs.CV

TL;DR: Neptune-X是一个数据驱动的生成-选择框架，通过结合合成数据生成和任务感知样本选择来增强海上目标检测的训练效果，解决了海上数据稀疏和泛化能力不足的问题。


<details>
  <summary>Details</summary>
Motivation: 海上目标检测对于导航安全、监控和自主操作至关重要，但面临数据集稀疏和跨属性泛化能力差的挑战，特别是在开放海域等代表性不足的场景中表现不佳。

Method: 提出了一种名为Neptune-X的数据中心生成-选择框架。该框架包括：1) X-to-Maritime，一个多模态条件生成模型，利用双向对象-水注意力模块生成多样化、逼真的海上场景。2) 属性相关主动采样，动态选择与任务相关的合成样本。3) 构建了第一个针对生成式海上学习的海上生成数据集。

Result: 实验证明，该方法在海上场景合成方面设定了新的基准，显著提高了检测精度，特别是在具有挑战性且以前代表性不足的场景中。

Conclusion: Neptune-X通过生成式合成和智能样本选择，有效提升了海上目标检测的性能，尤其是在数据稀疏和泛化能力受限的场景下。

Abstract: Maritime object detection is essential for navigation safety, surveillance,
and autonomous operations, yet constrained by two key challenges: the scarcity
of annotated maritime data and poor generalization across various maritime
attributes (e.g., object category, viewpoint, location, and imaging
environment). % In particular, models trained on existing datasets often
underperform in underrepresented scenarios such as open-sea environments. To
address these challenges, we propose Neptune-X, a data-centric
generative-selection framework that enhances training effectiveness by
leveraging synthetic data generation with task-aware sample selection. From the
generation perspective, we develop X-to-Maritime, a multi-modality-conditioned
generative model that synthesizes diverse and realistic maritime scenes. A key
component is the Bidirectional Object-Water Attention module, which captures
boundary interactions between objects and their aquatic surroundings to improve
visual fidelity. To further improve downstream tasking performance, we propose
Attribute-correlated Active Sampling, which dynamically selects synthetic
samples based on their task relevance. To support robust benchmarking, we
construct the Maritime Generation Dataset, the first dataset tailored for
generative maritime learning, encompassing a wide range of semantic conditions.
Extensive experiments demonstrate that our approach sets a new benchmark in
maritime scene synthesis, significantly improving detection accuracy,
particularly in challenging and previously underrepresented settings.The code
is available at https://github.com/gy65896/Neptune-X.

</details>


### [20] [AI-Enabled Crater-Based Navigation for Lunar Mapping](https://arxiv.org/abs/2509.20748)
*Sofia McLeod,Chee-Kheng Chng,Matthew Rodda,Tat-Jun Chin*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Crater-Based Navigation (CBN) uses the ubiquitous impact craters of the Moon
observed on images as natural landmarks to determine the six degrees of freedom
pose of a spacecraft. To date, CBN has primarily been studied in the context of
powered descent and landing. These missions are typically short in duration,
with high-frequency imagery captured from a nadir viewpoint over well-lit
terrain. In contrast, lunar mapping missions involve sparse, oblique imagery
acquired under varying illumination conditions over potentially year-long
campaigns, posing significantly greater challenges for pose estimation. We
bridge this gap with STELLA - the first end-to-end CBN pipeline for
long-duration lunar mapping. STELLA combines a Mask R-CNN-based crater
detector, a descriptor-less crater identification module, a robust
perspective-n-crater pose solver, and a batch orbit determination back-end. To
rigorously test STELLA, we introduce CRESENT-365 - the first public dataset
that emulates a year-long lunar mapping mission. Each of its 15,283 images is
rendered from high-resolution digital elevation models with SPICE-derived Sun
angles and Moon motion, delivering realistic global coverage, illumination
cycles, and viewing geometries. Experiments on CRESENT+ and CRESENT-365 show
that STELLA maintains metre-level position accuracy and sub-degree attitude
accuracy on average across wide ranges of viewing angles, illumination
conditions, and lunar latitudes. These results constitute the first
comprehensive assessment of CBN in a true lunar mapping setting and inform
operational conditions that should be considered for future missions.

</details>


### [21] [Seeing Through Words, Speaking Through Pixels: Deep Representational Alignment Between Vision and Language Models](https://arxiv.org/abs/2509.20751)
*Zoe Wanying He,Sean Trott,Meenakshi Khosla*

Main category: cs.CV

TL;DR: 深度模型在视觉和语言任务中，即使在独立数据集上训练，也能在部分对齐的表示空间中投影输入。


<details>
  <summary>Details</summary>
Motivation: 探究深度模型中表征对齐的出现位置、视觉或语言线索的支持、对多对多图像-文本场景下人类偏好的捕捉能力，以及同一概念的聚合对齐的影响。

Method: 系统性地调查上述问题，包括分析不同层级的表征、对外观和语义变化的敏感性、在“Pick-a-Pic”任务中评估人类偏好与嵌入空间的匹配度、以及研究聚合样本对齐的影响。

Result: 对齐在视觉和语言模型的中间到晚期层级达到峰值，表明从特定模态到共享概念的表征转变。这种对齐对于外观变化是稳健的，但对于语义改变（如物体移除或词序颠倒）则会崩溃。在“Pick-a-Pic”任务中，人类偏好与嵌入空间的匹配度一致，即使在存在多对一图像-文本对应关系的情况下也能捕捉到细微的语义差异。聚合同一概念的嵌入反而增强了对齐。

Conclusion: 单一模态的网络能够收敛到共享的语义代码，该代码与人类的判断一致，并且通过聚合样本能够得到加强。

Abstract: Recent studies show that deep vision-only and language-only models--trained
on disjoint modalities--nonetheless project their inputs into a partially
aligned representational space. Yet we still lack a clear picture of where in
each network this convergence emerges, what visual or linguistic cues support
it, whether it captures human preferences in many-to-many image-text scenarios,
and how aggregating exemplars of the same concept affects alignment. Here, we
systematically investigate these questions. We find that alignment peaks in
mid-to-late layers of both model types, reflecting a shift from
modality-specific to conceptually shared representations. This alignment is
robust to appearance-only changes but collapses when semantics are altered
(e.g., object removal or word-order scrambling), highlighting that the shared
code is truly semantic. Moving beyond the one-to-one image-caption paradigm, a
forced-choice "Pick-a-Pic" task shows that human preferences for image-caption
matches are mirrored in the embedding spaces across all vision-language model
pairs. This pattern holds bidirectionally when multiple captions correspond to
a single image, demonstrating that models capture fine-grained semantic
distinctions akin to human judgments. Surprisingly, averaging embeddings across
exemplars amplifies alignment rather than blurring detail. Together, our
results demonstrate that unimodal networks converge on a shared semantic code
that aligns with human judgments and strengthens with exemplar aggregation.

</details>


### [22] [FreeInsert: Personalized Object Insertion with Geometric and Style Control](https://arxiv.org/abs/2509.20756)
*Yuhong Zhang,Han Wang,Yiwen Wang,Rong Xie,Li Song*

Main category: cs.CV

TL;DR: FreeInsert框架通过利用3D几何信息，实现了在任意场景中对物体进行定制化插入，解决了现有图像编辑方法在几何控制、风格一致性和无需训练方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有图像编辑方法在处理个性化图像组合任务时，在几何控制、风格一致性和无需训练方面存在局限性。

Method: 将2D物体转换为3D，在3D层面进行交互式编辑，然后从指定视图重新渲染成2D图像，并结合扩散模型适配器实现的风格和内容控制，最终通过扩散模型生成在几何上受控、风格一致的编辑图像。

Result: 提出了一种名为FreeInsert的新型免训练框架，该框架通过引入3D几何信息，实现了对物体形状和视图的精确几何控制，并能保持物体与背景的风格一致性。

Conclusion: FreeInsert框架通过整合3D几何信息和扩散模型，成功解决了现有图像编辑方法的痛点，实现了无需训练即可在任意场景中进行几何可控、风格一致的物体插入。

Abstract: Text-to-image diffusion models have made significant progress in image
generation, allowing for effortless customized generation. However, existing
image editing methods still face certain limitations when dealing with
personalized image composition tasks. First, there is the issue of lack of
geometric control over the inserted objects. Current methods are confined to 2D
space and typically rely on textual instructions, making it challenging to
maintain precise geometric control over the objects. Second, there is the
challenge of style consistency. Existing methods often overlook the style
consistency between the inserted object and the background, resulting in a lack
of realism. In addition, the challenge of inserting objects into images without
extensive training remains significant. To address these issues, we propose
\textit{FreeInsert}, a novel training-free framework that customizes object
insertion into arbitrary scenes by leveraging 3D geometric information.
Benefiting from the advances in existing 3D generation models, we first convert
the 2D object into 3D, perform interactive editing at the 3D level, and then
re-render it into a 2D image from a specified view. This process introduces
geometric controls such as shape or view. The rendered image, serving as
geometric control, is combined with style and content control achieved through
diffusion adapters, ultimately producing geometrically controlled,
style-consistent edited images via the diffusion model.

</details>


### [23] [CusEnhancer: A Zero-Shot Scene and Controllability Enhancement Method for Photo Customization via ResInversion](https://arxiv.org/abs/2509.20775)
*Maoye Ren,Praneetha Vaddamanu,Jianjin Xu,Fernando De la Torre Frade*

Main category: cs.CV

TL;DR: CustomEnhancer 是一个用于提升文本到图像模型在处理退化场景、增强身份控制和感知保真度方面的新框架。它利用面部交换技术和预训练的扩散模型，通过三流融合的 PerGeneration 方法统一了生成和重建过程，实现了三个流的生成。该框架还提供训练免费的全局控制，并引入了 ResInversion 方法，将空文本反演（NTI）的时间复杂度降低了 129 倍。实验证明 CustomEnhancer 在场景多样性、身份保真度和训练免费控制方面达到了最先进的水平。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像扩散模型在处理退化场景、身份控制和感知保真度方面存在不足，需要更强大的方法来定制个性化身份。

Method: CustomEnhancer 框架整合了面部交换技术和预训练的扩散模型，通过一个称为“三流融合的 PerGeneration”的新颖方法，识别并结合两个反向的潜在空间来操控个性化模型的关键空间，从而统一了生成和重建过程。此外，还提出了一种名为 ResInversion 的新颖反演方法，通过预扩散机制进行噪声校正，以克服空文本反演（NTI）的高时间复杂度。

Result: CustomEnhancer 在场景多样性、身份保真度和训练免费控制方面取得了最先进的成果。ResInversion 方法比 NTI 在反演效率上表现更优，将反演时间缩短了 129 倍。

Conclusion: CustomEnhancer 框架通过其创新的三流融合方法和高效的 ResInversion 反演技术，显著提升了文本到图像生成中身份定制的质量和效率，解决了现有方法的局限性。

Abstract: Recently remarkable progress has been made in synthesizing realistic human
photos using text-to-image diffusion models. However, current approaches face
degraded scenes, insufficient control, and suboptimal perceptual identity. We
introduce CustomEnhancer, a novel framework to augment existing identity
customization models. CustomEnhancer is a zero-shot enhancement pipeline that
leverages face swapping techniques, pretrained diffusion model, to obtain
additional representations in a zeroshot manner for encoding into personalized
models. Through our proposed triple-flow fused PerGeneration approach, which
identifies and combines two compatible counter-directional latent spaces to
manipulate a pivotal space of personalized model, we unify the generation and
reconstruction processes, realizing generation from three flows. Our pipeline
also enables comprehensive training-free control over the generation process of
personalized models, offering precise controlled personalization for them and
eliminating the need for controller retraining for per-model. Besides, to
address the high time complexity of null-text inversion (NTI), we introduce
ResInversion, a novel inversion method that performs noise rectification via a
pre-diffusion mechanism, reducing the inversion time by 129 times. Experiments
demonstrate that CustomEnhancer reach SOTA results at scene diversity, identity
fidelity, training-free controls, while also showing the efficiency of our
ResInversion over NTI. The code will be made publicly available upon paper
acceptance.

</details>


### [24] [CompressAI-Vision: Open-source software to evaluate compression methods for computer vision tasks](https://arxiv.org/abs/2509.20777)
*Hyomin Choi,Heeji Han,Chris Rosewarne,Fabien Racapé*

Main category: cs.CV

TL;DR: CompressAI-Vision是一个用于评估针对计算机视觉任务优化的视频压缩方法的综合平台，支持远程和分割推理两种场景。


<details>
  <summary>Details</summary>
Motivation: 随着基于神经网络的计算机视觉应用处理大量图像和视频数据，需要一个统一的平台来实施和评估针对下游视觉任务优化的压缩方法。

Method: CompressAI-Vision平台集成了标准编解码器，用于评估在不同数据集上，在保持任务精度的前提下，压缩增益在比特率和任务精度方面的表现。

Result: 该平台展示了集成标准编解码器的各种用例，并通过在多个数据集上检查比特率与任务精度的关系来检验压缩增益。

Conclusion: CompressAI-Vision作为一个开源软件，已被MPEG采纳用于开发面向机器的特征编码（FCM）标准，为评估和发展视觉任务优化压缩技术提供了共同基础。

Abstract: With the increasing use of neural network (NN)-based computer vision
applications that process image and video data as input, interest has emerged
in video compression technology optimized for computer vision tasks. In fact,
given the variety of vision tasks, associated NN models and datasets, a
consolidated platform is needed as a common ground to implement and evaluate
compression methods optimized for downstream vision tasks. CompressAI-Vision is
introduced as a comprehensive evaluation platform where new coding tools
compete to efficiently compress the input of vision network while retaining
task accuracy in the context of two different inference scenarios: "remote" and
"split" inferencing. Our study showcases various use cases of the evaluation
platform incorporated with standard codecs (under development) by examining the
compression gain on several datasets in terms of bit-rate versus task accuracy.
This evaluation platform has been developed as open-source software and is
adopted by the Moving Pictures Experts Group (MPEG) for the development the
Feature Coding for Machines (FCM) standard. The software is available publicly
at https://github.com/InterDigitalInc/CompressAI-Vision.

</details>


### [25] [Dual-supervised Asymmetric Co-training for Semi-supervised Medical Domain Generalization](https://arxiv.org/abs/2509.20785)
*Jincai Song,Haipeng Chen,Jun Qin,Na Zhao*

Main category: cs.CV

TL;DR: 该论文提出了一种用于交叉域半监督域泛化（CD-SSDG）的


<details>
  <summary>Details</summary>
Motivation: 现有半监督域泛化（SSDG）方法假设标记和未标记数据来自同一源域，

Method: 提出了一种新颖的双监督非对称协同训练（DAC）框架，

Result: 在真实世界医学图像分割数据集（Fundus, Polyp, and SCGM）上进行了广泛的实验，

Conclusion: 实验证明了所提出的DAC框架在CD-SSDG场景下具有鲁棒的泛化能力。

Abstract: Semi-supervised domain generalization (SSDG) in medical image segmentation
offers a promising solution for generalizing to unseen domains during testing,
addressing domain shift challenges and minimizing annotation costs. However,
conventional SSDG methods assume labeled and unlabeled data are available for
each source domain in the training set, a condition that is not always met in
practice. The coexistence of limited annotation and domain shift in the
training set is a prevalent issue. Thus, this paper explores a more practical
and challenging scenario, cross-domain semi-supervised domain generalization
(CD-SSDG), where domain shifts occur between labeled and unlabeled training
data, in addition to shifts between training and testing sets. Existing SSDG
methods exhibit sub-optimal performance under such domain shifts because of
inaccurate pseudolabels. To address this issue, we propose a novel
dual-supervised asymmetric co-training (DAC) framework tailored for CD-SSDG.
Building upon the co-training paradigm with two sub-models offering cross
pseudo supervision, our DAC framework integrates extra feature-level
supervision and asymmetric auxiliary tasks for each sub-model. This
feature-level supervision serves to address inaccurate pseudo supervision
caused by domain shifts between labeled and unlabeled data, utilizing
complementary supervision from the rich feature space. Additionally, two
distinct auxiliary self-supervised tasks are integrated into each sub-model to
enhance domain-invariant discriminative feature learning and prevent model
collapse. Extensive experiments on real-world medical image segmentation
datasets, i.e., Fundus, Polyp, and SCGM, demonstrate the robust
generalizability of the proposed DAC framework.

</details>


### [26] [Real-Time Object Detection Meets DINOv3](https://arxiv.org/abs/2509.20787)
*Shihua Huang,Yongjie Hou,Longfei Liu,Xuanlong Yu,Xi Shen*

Main category: cs.CV

TL;DR: DEIMv2是DEIM的升级版，引入了DINOv3特征，并提供了多种模型尺寸，适用于不同的部署场景。它通过引入空间调整适配器（STA）和采用HGNetv2等技术，实现了优越的性能-成本比，并在COCO数据集上刷新了多项最先进的纪录。


<details>
  <summary>Details</summary>
Motivation: DEIM作为实时DETR的主流训练框架，虽然有效，但仍有提升空间。作者希望通过结合DINOv3特征并优化模型结构，进一步提升其性能和效率，使其能够覆盖更广泛的应用场景，并打破现有性能记录。

Method: DEIMv2在DEIM的基础上，整合了DINOv3特征。对于较大的模型（X, L, M, S），采用了DINOv3预训练或蒸馏的骨干网络，并引入了空间调整适配器（STA）来处理单尺度输出并融合多尺度信息。对于超轻量级模型（Nano, Pico, Femto, Atto），则采用了HGNetv2，并通过深度和宽度剪枝来满足资源限制。此外，还采用了简化的解码器和升级的Dense O2O。

Result: DEIMv2在COCO数据集上取得了多项最先进的成果：最大的DEIMv2-X模型参数量少于现有X-scale模型，但AP值更高（57.8 vs 56.5）；DEIMv2-S是首个突破50AP的千万级以下模型（9.71M参数，50.9AP）；DEIMv2-Pico（1.5M参数）实现了38.5AP，在参数量约少一半的情况下，性能与YOLOv10-Nano相当。

Conclusion: DEIMv2通过结合DINOv3特征、引入STA、优化轻量级模型结构以及改进训练策略，成功地在性能和成本之间取得了卓越的平衡，并在各种规模的模型上都达到了新的最先进水平，展示了其在实时目标检测领域的强大潜力。

Abstract: Benefiting from the simplicity and effectiveness of Dense O2O and MAL, DEIM
has become the mainstream training framework for real-time DETRs, significantly
outperforming the YOLO series. In this work, we extend it with DINOv3 features,
resulting in DEIMv2. DEIMv2 spans eight model sizes from X to Atto, covering
GPU, edge, and mobile deployment. For the X, L, M, and S variants, we adopt
DINOv3-pretrained or distilled backbones and introduce a Spatial Tuning Adapter
(STA), which efficiently converts DINOv3's single-scale output into multi-scale
features and complements strong semantics with fine-grained details to enhance
detection. For ultra-lightweight models (Nano, Pico, Femto, and Atto), we
employ HGNetv2 with depth and width pruning to meet strict resource budgets.
Together with a simplified decoder and an upgraded Dense O2O, this unified
design enables DEIMv2 to achieve a superior performance-cost trade-off across
diverse scenarios, establishing new state-of-the-art results. Notably, our
largest model, DEIMv2-X, achieves 57.8 AP with only 50.3 million parameters,
surpassing prior X-scale models that require over 60 million parameters for
just 56.5 AP. On the compact side, DEIMv2-S is the first sub-10 million model
(9.71 million) to exceed the 50 AP milestone on COCO, reaching 50.9 AP. Even
the ultra-lightweight DEIMv2-Pico, with just 1.5 million parameters, delivers
38.5 AP, matching YOLOv10-Nano (2.3 million) with around 50 percent fewer
parameters.

</details>


### [27] [DAC-LoRA: Dynamic Adversarial Curriculum for Efficient and Robust Few-Shot Adaptation](https://arxiv.org/abs/2509.20792)
*Ved Umrajkar*

Main category: cs.CV

TL;DR: LoRA等参数高效微调方法虽然能高效适配视觉-语言模型（VLM)，但仍易受对抗性攻击，可能危及安全关键决策。CLIP作为许多下游VLM的骨干，其漏洞可能波及整个多模态AI生态系统。本研究提出了一种名为DAC-LoRA（动态对抗课程-LoRA）的新框架，将对抗训练整合到参数高效微调（PEFT）中。该方法的核心思想是采用智能的、逐步增强的攻击课程，这种方法是通用的，可以应用于任何迭代攻击方法。DAC-LoRA受一阶平稳条件（FOSC）和类似TRADES的损失函数的指导，在不显著损害干净准确率的情况下，显著提高了对抗鲁棒性。该框架易于集成到标准的PEFT流程中，能有效、轻便且广泛地增强鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 由于LoRA等参数高效微调（PEFT）方法虽然能高效适配视觉-语言模型（VLM），但这些模型仍易受对抗性攻击，可能危及安全关键决策。CLIP作为许多下游VLM的骨干，其漏洞可能波及整个多模态AI生态系统，因此需要提高VLM的鲁棒性。

Method: 提出了一种名为DAC-LoRA（动态对抗课程-LoRA）的新框架，将对抗训练整合到参数高效微调（PEFT）中。该方法的核心思想是采用智能的、逐步增强的攻击课程，并受一阶平稳条件（FOSC）和类似TRADES的损失函数的指导。

Result: DAC-LoRA在不显著损害干净准确率的情况下，显著提高了对抗鲁棒性。该框架易于集成到标准的PEFT流程中，能有效、轻便且广泛地增强鲁棒性。

Conclusion: DAC-LoRA是一种有效、轻便且广泛适用的方法，能够轻松集成到标准的PEFT流程中，显著增强视觉-语言模型的鲁棒性，解决了参数高效微调方法在对抗性攻击下的脆弱性问题。

Abstract: Vision-Language Models (VLMs) are foundational to critical applications like
autonomous driving, medical diagnosis, and content moderation. While
Parameter-Efficient Fine-Tuning (PEFT) methods like LoRA enable their efficient
adaptation to specialized tasks, these models remain vulnerable to adversarial
attacks that can compromise safety-critical decisions. CLIP, the backbone for
numerous downstream VLMs, is a high-value target whose vulnerabilities can
cascade across the multimodal AI ecosystem. We propose Dynamic Adversarial
Curriculum DAC-LoRA, a novel framework that integrates adversarial training
into PEFT. The core principle of our method i.e. an intelligent curriculum of
progressively challenging attack, is general and can potentially be applied to
any iterative attack method. Guided by the First-Order Stationary Condition
(FOSC) and a TRADES-inspired loss, DAC-LoRA achieves substantial improvements
in adversarial robustness without significantly compromising clean accuracy.
Our work presents an effective, lightweight, and broadly applicable method to
demonstrate that the DAC-LoRA framework can be easily integrated into a
standard PEFT pipeline to significantly enhance robustness.

</details>


### [28] [Federated Domain Generalization with Domain-specific Soft Prompts Generation](https://arxiv.org/abs/2509.20807)
*Jianhan Wu,Xiaoyang Qu,Zhangcheng Huang,Jianzong Wang*

Main category: cs.CV

TL;DR: Prompt learning for federated learning can be inefficient due to domain shift. This paper proposes FedDSPG, a generative method that creates domain-specific soft prompts to improve generalization in unseen domains, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Existing federated domain generalization (FDG) methods based on prompt learning struggle with limited prompt diversity and ignoring information from unknown domains, hindering effective adaptation in federated learning scenarios with domain shift.

Method: FedDSPG introduces domain-specific soft prompts (DSPs) for each domain during training and integrates content and domain knowledge into a generative model across clients. In the inference phase, the generator creates DSPs for unseen target domains to guide downstream tasks.

Result: Comprehensive evaluations on public datasets show that FedDSPG outperforms existing strong baselines in FDG, achieving state-of-the-art results.

Conclusion: The proposed FedDSPG method, utilizing a generative approach with domain-specific soft prompts, effectively addresses the challenges of federated domain generalization by improving model adaptability to unseen domains.

Abstract: Prompt learning has become an efficient paradigm for adapting CLIP to
downstream tasks. Compared with traditional fine-tuning, prompt learning
optimizes a few parameters yet yields highly competitive results, especially
appealing in federated learning for computational efficiency. engendering
domain shift among clients and posing a formidable challenge for
downstream-task adaptation. Existing federated domain generalization (FDG)
methods based on prompt learning typically learn soft prompts from training
samples, replacing manually designed prompts to enhance the generalization
ability of federated models. However, these learned prompts exhibit limited
diversity and tend to ignore information from unknown domains. We propose a
novel and effective method from a generative perspective for handling FDG
tasks, namely federated domain generalization with domain-specific soft prompts
generation (FedDSPG). Specifically, during training, we introduce
domain-specific soft prompts (DSPs) for each domain and integrate content and
domain knowledge into the generative model among clients. In the inference
phase, the generator is utilized to obtain DSPs for unseen target domains, thus
guiding downstream tasks in unknown domains. Comprehensive evaluations across
several public datasets confirm that our method outperforms existing strong
baselines in FDG, achieving state-of-the-art results.

</details>


### [29] [Revolutionizing Precise Low Back Pain Diagnosis via Contrastive Learning](https://arxiv.org/abs/2509.20813)
*Thanh Binh Le,Hoang Nhat Khang Vo,Tan-Ha Mai,Trong Nhan Phan*

Main category: cs.CV

TL;DR: LumbarCLIP是一个多模态框架，利用对比语言-图像预训练来对腰椎核磁共振成像扫描和放射学报告进行匹配，在下游分类任务上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 低背痛影响着全球数百万人，因此需要能够联合分析复杂的医学图像和相关的文本报告的鲁棒的诊断模型。

Method: LumbarCLIP框架集成了视觉编码器（ResNet-50、Vision Transformer、Swin Transformer）和基于BERT的文本编码器，以提取密集的表示。这些表示通过可学习的投影头（线性或非线性）被投影到共享的嵌入空间，并通过软CLIP损失进行归一化以进行稳定的对比训练。

Result: 该模型在下游分类任务上达到了最先进的性能，在测试集上的准确率高达95.00%，F1分数高达94.75%，并且克服了固有的类别不平衡问题。消融研究表明，线性投影头比非线性投影头能更有效地实现跨模态对齐。

Conclusion: LumbarCLIP为自动肌肉骨骼诊断和临床决策支持提供了一个有前景的基础。

Abstract: Low back pain affects millions worldwide, driving the need for robust
diagnostic models that can jointly analyze complex medical images and
accompanying text reports. We present LumbarCLIP, a novel multimodal framework
that leverages contrastive language-image pretraining to align lumbar spine MRI
scans with corresponding radiological descriptions. Built upon a curated
dataset containing axial MRI views paired with expert-written reports,
LumbarCLIP integrates vision encoders (ResNet-50, Vision Transformer, Swin
Transformer) with a BERT-based text encoder to extract dense representations.
These are projected into a shared embedding space via learnable projection
heads, configurable as linear or non-linear, and normalized to facilitate
stable contrastive training using a soft CLIP loss. Our model achieves
state-of-the-art performance on downstream classification, reaching up to
95.00% accuracy and 94.75% F1-score on the test set, despite inherent class
imbalance. Extensive ablation studies demonstrate that linear projection heads
yield more effective cross-modal alignment than non-linear variants. LumbarCLIP
offers a promising foundation for automated musculoskeletal diagnosis and
clinical decision support.

</details>


### [30] [Poisoning Prompt-Guided Sampling in Video Large Language Models](https://arxiv.org/abs/2509.20851)
*Yuxin Cao,Wei Song,Jingling Xue,Jin Song Dong*

Main category: cs.CV

TL;DR: 视频大语言模型（VideoLLMs）在理解视频方面表现出色，但其提示引导的采样策略存在安全漏洞。本文提出了首个针对该漏洞的黑盒攻击方法PoisonVID，通过闭环优化策略和精心构建的描述集，成功地干扰了提示引导的采样机制，攻击成功率高达82%-99%，凸显了对VideoLLMs未来采样策略安全性进行研究的必要性。


<details>
  <summary>Details</summary>
Motivation: 当前视频大语言模型（VideoLLMs）的采样策略（从统一采样到基于语义相似性，再到提示引导）虽不断进步，但提示引导采样策略的安全性尚未得到充分研究。本文旨在填补这一研究空白，探讨并揭示提示引导采样策略可能存在的安全风险。

Method: 本文提出了一种名为PoisonVID的黑盒攻击方法，专门针对VideoLLMs的提示引导采样策略。该方法采用闭环优化策略，通过迭代优化一个通用的扰动，来降低有害帧的相关性得分。具体实现上，利用一个由释义后的有害描述构成的“描述集”，并借助一个影子VideoLLM和轻量级语言模型（GPT-4o-mini）来指导扰动优化过程。

Result: PoisonVID在三种不同的提示引导采样策略和三种先进的VideoLLMs上进行了全面评估，取得了82%至99%的攻击成功率。这表明该攻击方法能够有效地破坏VideoLLMs的提示引导采样机制。

Conclusion: PoisonVID作为首个针对VideoLLMs提示引导采样策略的黑盒攻击方法，成功证明了该策略的脆弱性。实验结果（82%-99%的攻击成功率）强调了在未来开发更安全的VideoLLMs采样策略的重要性。

Abstract: Video Large Language Models (VideoLLMs) have emerged as powerful tools for
understanding videos, supporting tasks such as summarization, captioning, and
question answering. Their performance has been driven by advances in frame
sampling, progressing from uniform-based to semantic-similarity-based and, most
recently, prompt-guided strategies. While vulnerabilities have been identified
in earlier sampling strategies, the safety of prompt-guided sampling remains
unexplored. We close this gap by presenting PoisonVID, the first black-box
poisoning attack that undermines prompt-guided sampling in VideoLLMs. PoisonVID
compromises the underlying prompt-guided sampling mechanism through a
closed-loop optimization strategy that iteratively optimizes a universal
perturbation to suppress harmful frame relevance scores, guided by a depiction
set constructed from paraphrased harmful descriptions leveraging a shadow
VideoLLM and a lightweight language model, i.e., GPT-4o-mini. Comprehensively
evaluated on three prompt-guided sampling strategies and across three advanced
VideoLLMs, PoisonVID achieves 82% - 99% attack success rate, highlighting the
importance of developing future advanced sampling strategies for VideoLLMs.

</details>


### [31] [Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer](https://arxiv.org/abs/2509.20854)
*Abdur Rehman,S M A Sharif,Md Abdur Rahaman,Mohamed Jismy Aashik Rasool,Seongwan Kim,Jaeho Lee*

Main category: cs.CV

TL;DR: GoR是一种新的可学习正则化方法，通过自适应地平衡任务损失和知识蒸馏损失，解决了现有QAT-KD方法在低比特量化下梯度不一致的问题，从而提高了小型量化模型的性能，并在图像分类、目标检测和大型语言模型压缩方面取得了优于现有SOTA方法的成果。


<details>
  <summary>Details</summary>
Motivation: 现有的量化感知训练（QAT）结合知识蒸馏（KD）方法在低比特量化时，由于梯度大小不一致，难以平衡任务损失和蒸馏损失，影响模型性能。

Method: 提出了一种名为Game of Regularizer (GoR) 的新型可学习正则化方法，使用两个可训练参数动态调整任务损失和知识蒸馏损失的权重，以解决监督信号冲突问题并改善收敛性。此外，还引入了一个集成蒸馏框架QAT-EKD-GoR，使用多个异构教师模型。

Result: GoR在图像分类、目标检测和大型语言模型压缩任务上，显著优于现有的QAT-KD方法。在低功耗边缘设备上，GoR能实现更快的推理速度，同时保持全精度模型的准确性。EKD-GoR框架在最佳条件下甚至能超越全精度模型。

Conclusion: GoR是一种有效的QAT-KD方法，能够解决现有方法的不足，并通过自适应损失平衡来提升小型量化模型的性能。EKD-GoR框架为实际部署提供了鲁棒的解决方案。

Abstract: Quantization-aware training (QAT) combined with knowledge distillation (KD)
is a promising strategy for compressing Artificial Intelligence (AI) models for
deployment on resource-constrained hardware. However, existing QAT-KD methods
often struggle to balance task-specific (TS) and distillation losses due to
heterogeneous gradient magnitudes, especially under low-bit quantization. We
propose Game of Regularizer (GoR), a novel learnable regularization method that
adaptively balances TS and KD objectives using only two trainable parameters
for dynamic loss weighting. GoR reduces conflict between supervision signals,
improves convergence, and boosts the performance of small quantized models
(SQMs). Experiments on image classification, object detection (OD), and large
language model (LLM) compression show that GoR consistently outperforms
state-of-the-art QAT-KD methods. On low-power edge devices, it delivers faster
inference while maintaining full-precision accuracy. We also introduce
QAT-EKD-GoR, an ensemble distillation framework that uses multiple
heterogeneous teacher models. Under optimal conditions, the proposed EKD-GoR
can outperform full-precision models, providing a robust solution for
real-world deployment.

</details>


### [32] [Plant identification based on noisy web data: the amazing performance of deep learning (LifeCLEF 2017)](https://arxiv.org/abs/2509.20856)
*Herve Goeau,Pierre Bonnet,Alexis Joly*

Main category: cs.CV

TL;DR: LifeCLEF 2017植物识别挑战赛旨在评估包含大量标记错误的、从网络收集的嘈杂训练数据集与专家审核的、较小的可靠训练数据集的竞争力，并分析了参赛方法的成果。


<details>
  <summary>Details</summary>
Motivation: 评估从网络收集的大量带有标记错误的训练数据与专家审核的小型可靠训练数据在植物识别任务上的竞争力。

Method: 提出并评估了两种训练策略：使用网络收集的包含大量标记错误的嘈杂数据集，以及使用专家审核的小型可靠数据集。使用Pl@ntNet移动应用程序收集的图像作为测试数据集进行公平比较。

Result: 挑战赛评估了两种训练数据集的有效性，并总结了参赛者的系统方法和主要结果。

Conclusion: LifeCLEF 2017植物识别挑战赛的结果将有助于推动自动化植物识别系统的发展，并为未来处理大规模、多样化植物图像数据提供参考。

Abstract: The 2017-th edition of the LifeCLEF plant identification challenge is an
important milestone towards automated plant identification systems working at
the scale of continental floras with 10.000 plant species living mainly in
Europe and North America illustrated by a total of 1.1M images. Nowadays, such
ambitious systems are enabled thanks to the conjunction of the dazzling recent
progress in image classification with deep learning and several outstanding
international initiatives, such as the Encyclopedia of Life (EOL), aggregating
the visual knowledge on plant species coming from the main national botany
institutes. However, despite all these efforts the majority of the plant
species still remain without pictures or are poorly illustrated. Outside the
institutional channels, a much larger number of plant pictures are available
and spread on the web through botanist blogs, plant lovers web-pages, image
hosting websites and on-line plant retailers. The LifeCLEF 2017 plant challenge
presented in this paper aimed at evaluating to what extent a large noisy
training dataset collected through the web and containing a lot of labelling
errors can compete with a smaller but trusted training dataset checked by
experts. To fairly compare both training strategies, the test dataset was
created from a third data source, i.e. the Pl@ntNet mobile application that
collects millions of plant image queries all over the world. This paper
presents more precisely the resources and assessments of the challenge,
summarizes the approaches and systems employed by the participating research
groups, and provides an analysis of the main outcomes.

</details>


### [33] [TasselNetV4: A vision foundation model for cross-scene, cross-scale, and cross-species plant counting](https://arxiv.org/abs/2509.20857)
*Xiaonan Hu,Xuebing Li,Jinyu Xu,Abdulkadir Duran Adan,Letian Zhou,Xuhui Zhu,Yanan Li,Wei Guo,Shouyang Liu,Wenzhong Liu,Hao Lu*

Main category: cs.CV

TL;DR: TasselNetV4通过结合局部计数和提取匹配范式，并引入多分支感知局部计数器，实现了跨物种、跨尺度植物计数，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有植物计数方法多为特定物种设计，难以适应新品种的出现，且在处理植物的动态性和非刚性结构时表现不佳。因此，需要一种能够从“计数什么”转向“如何计数”的通用方法。

Method: 提出TasselNetV4，继承TasselNet的局部计数思想，并结合CAC的提取-匹配范式。模型基于视觉Transformer，并引入多分支感知局部计数器以增强跨尺度鲁棒性，实现跨物种计数。

Result: 在PAC-105和PAC-Somalia两个数据集上进行了广泛实验，TasselNetV4的计数性能和效率均优于最先进的CAC模型。

Conclusion: TasselNetV4是一种适用于跨场景、跨尺度、跨物种植物计数的视觉基础模型。

Abstract: Accurate plant counting provides valuable information for agriculture such as
crop yield prediction, plant density assessment, and phenotype quantification.
Vision-based approaches are currently the mainstream solution. Prior art
typically uses a detection or a regression model to count a specific plant.
However, plants have biodiversity, and new cultivars are increasingly bred each
year. It is almost impossible to exhaust and build all species-dependent
counting models. Inspired by class-agnostic counting (CAC) in computer vision,
we argue that it is time to rethink the problem formulation of plant counting,
from what plants to count to how to count plants. In contrast to most daily
objects with spatial and temporal invariance, plants are dynamic, changing with
time and space. Their non-rigid structure often leads to worse performance than
counting rigid instances like heads and cars such that current CAC and
open-world detection models are suboptimal to count plants. In this work, we
inherit the vein of the TasselNet plant counting model and introduce a new
extension, TasselNetV4, shifting from species-specific counting to
cross-species counting. TasselNetV4 marries the local counting idea of
TasselNet with the extract-and-match paradigm in CAC. It builds upon a plain
vision transformer and incorporates novel multi-branch box-aware local counters
used to enhance cross-scale robustness. Two challenging datasets, PAC-105 and
PAC-Somalia, are harvested. Extensive experiments against state-of-the-art CAC
models show that TasselNetV4 achieves not only superior counting performance
but also high efficiency.Our results indicate that TasselNetV4 emerges to be a
vision foundation model for cross-scene, cross-scale, and cross-species plant
counting.

</details>


### [34] [SD-RetinaNet: Topologically Constrained Semi-Supervised Retinal Lesion and Layer Segmentation in OCT](https://arxiv.org/abs/2509.20864)
*Botond Fazekas,Guilherme Aresta,Philipp Seeböck,Julia Mai,Ursula Schmidt-Erfurth,Hrvoje Bogunović*

Main category: cs.CV

TL;DR: 提出了一种新的半监督模型，通过可微分生物标记拓扑引擎来强制执行解剖学上正确的病变和层分割，以解决现有方法在视网膜分割中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的半监督学习方法在视网膜分割中存在解剖学上不合理、未能有效模拟层-病变相互作用以及缺乏拓扑正确性保证的问题。

Method: 提出了一种新的半监督模型，该模型引入了一个完全可微分的生物标记拓扑引擎，以强制执行病变和层的解剖学上正确的分割。该模型能够实现标签和病变之间的双向学习，并利用未标记和部分标记的数据集。它还学习了一个分离空间和风格因素的解耦表示。

Result: 所提出的模型在公共和内部OCT扫描数据集上进行了评估，结果显示其在病变和层分割方面均优于当前最先进的方法，并能通过部分标注的训练数据将层分割推广到病理情况。

Conclusion: 解剖学约束在半监督学习中具有巨大潜力，可实现准确、鲁棒和可信的视网膜生物标记分割。

Abstract: Optical coherence tomography (OCT) is widely used for diagnosing and
monitoring retinal diseases, such as age-related macular degeneration (AMD).
The segmentation of biomarkers such as layers and lesions is essential for
patient diagnosis and follow-up. Recently, semi-supervised learning has shown
promise in improving retinal segmentation performance. However, existing
methods often produce anatomically implausible segmentations, fail to
effectively model layer-lesion interactions, and lack guarantees on topological
correctness.
  To address these limitations, we propose a novel semi-supervised model that
introduces a fully differentiable biomarker topology engine to enforce
anatomically correct segmentation of lesions and layers. This enables joint
learning with bidirectional influence between layers and lesions, leveraging
unlabeled and diverse partially labeled datasets. Our model learns a
disentangled representation, separating spatial and style factors. This
approach enables more realistic layer segmentations and improves lesion
segmentation, while strictly enforcing lesion location in their anatomically
plausible positions relative to the segmented layers.
  We evaluate the proposed model on public and internal datasets of OCT scans
and show that it outperforms the current state-of-the-art in both lesion and
layer segmentation, while demonstrating the ability to generalize layer
segmentation to pathological cases using partially annotated training data. Our
results demonstrate the potential of using anatomical constraints in
semi-supervised learning for accurate, robust, and trustworthy retinal
biomarker segmentation.

</details>


### [35] [Plant identification in an open-world (LifeCLEF 2016)](https://arxiv.org/abs/2509.20870)
*Herve Goeau,Pierre Bonnet,Alexis Joly*

Main category: cs.CV

TL;DR: LifeCLEF 2016 评估了大规模植物识别方法，重点是开放集识别，即区分已知和未知植物物种。


<details>
  <summary>Details</summary>
Motivation: 在接近真实世界的条件下，大规模评估植物识别方法和系统，特别是要应对未知植物物种的挑战。

Method: 本次挑战引入了开放集识别的评估方式，要求识别系统能够处理训练集中未出现的植物物种，并自动拒绝错误分类。

Result: 分析了参与者的方法和系统，并总结了挑战的主要结果。

Conclusion: 本次挑战的主要成果是评估了参与者在开放集识别方面的能力，即区分已知和未知植物物种。

Abstract: The LifeCLEF plant identification challenge aims at evaluating plant
identification methods and systems at a very large scale, close to the
conditions of a real-world biodiversity monitoring scenario. The 2016-th
edition was actually conducted on a set of more than 110K images illustrating
1000 plant species living in West Europe, built through a large-scale
participatory sensing platform initiated in 2011 and which now involves tens of
thousands of contributors. The main novelty over the previous years is that the
identification task was evaluated as an open-set recognition problem, i.e. a
problem in which the recognition system has to be robust to unknown and never
seen categories. Beyond the brute-force classification across the known classes
of the training set, the big challenge was thus to automatically reject the
false positive classification hits that are caused by the unknown classes. This
overview presents more precisely the resources and assessments of the
challenge, summarizes the approaches and systems employed by the participating
research groups, and provides an analysis of the main outcomes.

</details>


### [36] [SCRA-VQA: Summarized Caption-Rerank for Augmented Large Language Models in Visual Question Answering](https://arxiv.org/abs/2509.20871)
*Yan Zhang,Jiaqing Lin,Miao Zhang,Kui Xiao,Xiaoju Hou,Yue Zhao,Zhifei Li*

Main category: cs.CV

TL;DR: SCRA-VQA通过总结和重新排序图像标题来提高基于知识的视觉问答效果，从而增强大型语言模型理解图像和问题的能力，并在OK-VQA和A-OKVQA数据集上取得了优秀的准确率。


<details>
  <summary>Details</summary>
Motivation: 目前的基于知识的视觉问答方法依赖于大型语言模型（LLMs）作为知识引擎，但通常使用包含噪声且与问题无关的图像标题，并且LLMs本身对视觉问答任务的理解能力有限，这限制了它们的推理能力。

Method: 提出SCRA-VQA方法，使用预训练的视觉语言模型将图像转换为标题，并生成上下文示例，同时对标题进行总结和重新排序，以去除不相关信息，从而增强LLMs对图像信息和问题的理解能力，提升推理能力和任务适应性，而无需昂贵的端到端训练。

Result: 在拥有6.7B参数的LLM上，SCRA-VQA在OK-VQA和A-OKVQA数据集上分别达到了38.8%和34.6%的准确率。

Conclusion: SCRA-VQA通过优化的标题处理策略，有效提升了大型语言模型在基于知识的视觉问答任务中的表现，增强了其理解和推理能力。

Abstract: Acquiring high-quality knowledge is a central focus in Knowledge-Based Visual
Question Answering (KB-VQA). Recent methods use large language models (LLMs) as
knowledge engines for answering. These methods generally employ image captions
as visual text descriptions to assist LLMs in interpreting images. However, the
captions frequently include excessive noise irrelevant to the question, and
LLMs generally do not comprehend VQA tasks, limiting their reasoning
capabilities. To address this issue, we propose the Summarized Caption-Rerank
Augmented VQA (SCRA-VQA), which employs a pre-trained visual language model to
convert images into captions. Moreover, SCRA-VQA generates contextual examples
for the captions while simultaneously summarizing and reordering them to
exclude unrelated information. The caption-rerank process enables LLMs to
understand the image information and questions better, thus enhancing the
model's reasoning ability and task adaptability without expensive end-to-end
training. Based on an LLM with 6.7B parameters, SCRA-VQA performs excellently
on two challenging knowledge-based VQA datasets: OK-VQA and A-OKVQA, achieving
accuracies of 38.8% and 34.6%. Our code is available at
https://github.com/HubuKG/SCRA-VQA.

</details>


### [37] [The Unanticipated Asymmetry Between Perceptual Optimization and Assessment](https://arxiv.org/abs/2509.20878)
*Jiabei Zhang,Qi Wang,Siyu Wu,Du Chen,Tianhe Wu*

Main category: cs.CV

TL;DR: 感知优化和图像质量评估（IQA）之间的关系未被充分探索，尽管它们在感知优化中起着关键作用。本研究通过系统分析揭示了感知优化和评估之间的不对称性：在对抗性训练下，在IQA中表现良好的保真度指标在感知优化中并非总是有效。此外，判别器虽然能有效抑制伪影，但其学习到的表示在作为IQA模型的初始化骨干时益处有限。研究还表明，判别器的设计对优化有决定性影响，其中块级和卷积架构比标准或基于Transformer的架构更能忠实地重建细节。


<details>
  <summary>Details</summary>
Motivation: 探索感知优化（主要由保真度目标驱动，同时考虑语义一致性和视觉真实感，并辅以对抗性目标以增强细节）与图像质量评估（IQA）度量之间的相关性。

Method: 系统分析保真度目标和对抗性目标在感知优化中的作用，以及判别器表示在IQA模型初始化中的作用。研究了不同判别器架构（块级、卷积、标准、Transformer）对细节重建的影响。

Result: 发现保真度指标在IQA中表现优异，但在感知优化中并非总是有效，尤其是在对抗性训练下。判别器有助于抑制伪影，但其学习表示对IQA模型的初始化作用有限。判别器的架构设计（块级和卷积）比标准和Transformer架构更能促进细节重建。

Conclusion: 感知优化和IQA之间存在不对称性。判别器的设计对优化和细节重建至关重要。这些发现为感知优化的损失函数设计和IQA可转移性提供了新的见解，有望推动更合理的感知优化方法。

Abstract: Perceptual optimization is primarily driven by the fidelity objective, which
enforces both semantic consistency and overall visual realism, while the
adversarial objective provides complementary refinement by enhancing perceptual
sharpness and fine-grained detail. Despite their central role, the correlation
between their effectiveness as optimization objectives and their capability as
image quality assessment (IQA) metrics remains underexplored. In this work, we
conduct a systematic analysis and reveal an unanticipated asymmetry between
perceptual optimization and assessment: fidelity metrics that excel in IQA are
not necessarily effective for perceptual optimization, with this misalignment
emerging more distinctly under adversarial training. In addition, while
discriminators effectively suppress artifacts during optimization, their
learned representations offer only limited benefits when reused as backbone
initializations for IQA models. Beyond this asymmetry, our findings further
demonstrate that discriminator design plays a decisive role in shaping
optimization, with patch-level and convolutional architectures providing more
faithful detail reconstruction than vanilla or Transformer-based alternatives.
These insights advance the understanding of loss function design and its
connection to IQA transferability, paving the way for more principled
approaches to perceptual optimization.

</details>


### [38] [Integrating Object Interaction Self-Attention and GAN-Based Debiasing for Visual Question Answering](https://arxiv.org/abs/2509.20884)
*Zhifei Li,Feng Qiu,Yiran Wang,Yujing Xia,Kui Xiao,Miao Zhang,Yan Zhang*

Main category: cs.CV

TL;DR: IOG-VQA通过结合对象交互自注意力机制和基于GAN的去偏方法，解决了视觉问答（VQA）中的数据偏见问题，并在VQA-CP数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有VQA模型常因训练数据中的偏见而过度依赖肤浅模式，泛化能力不足。

Method: 提出了一种名为IOG-VQA的新模型，该模型集成了对象交互自注意力和基于GAN的去偏方法。自注意力机制用于捕捉图像中对象间的复杂交互，而GAN去偏框架用于生成无偏数据分布，从而学习更鲁棒、更具泛化性的特征。

Result: 在VQA-CP v1和VQA-CP v2数据集上的广泛实验表明，IOG-VQA与现有方法相比表现出优越的性能，尤其在处理有偏和不平衡的数据分布方面。

Conclusion: 该研究强调了在VQA任务中同时解决对象交互和数据集偏见对于提升模型性能的重要性。

Abstract: Visual Question Answering (VQA) presents a unique challenge by requiring
models to understand and reason about visual content to answer questions
accurately. Existing VQA models often struggle with biases introduced by the
training data, leading to over-reliance on superficial patterns and inadequate
generalization to diverse questions and images. This paper presents a novel
model, IOG-VQA, which integrates Object Interaction Self-Attention and
GAN-Based Debiasing to enhance VQA model performance. The self-attention
mechanism allows our model to capture complex interactions between objects
within an image, providing a more comprehensive understanding of the visual
context. Meanwhile, the GAN-based debiasing framework generates unbiased data
distributions, helping the model to learn more robust and generalizable
features. By leveraging these two components, IOG-VQA effectively combines
visual and textual information to address the inherent biases in VQA datasets.
Extensive experiments on the VQA-CP v1 and VQA-CP v2 datasets demonstrate that
our model shows excellent performance compared with the existing methods,
particularly in handling biased and imbalanced data distributions highlighting
the importance of addressing both object interactions and dataset biases in
advancing VQA tasks. Our code is available at
https://github.com/HubuKG/IOG-VQA.

</details>


### [39] [Nuclear Diffusion Models for Low-Rank Background Suppression in Videos](https://arxiv.org/abs/2509.20886)
*Tristan S. W. Stevens,Oisín Nolan,Jean-Luc Robert,Ruud J. G. van Sloun*

Main category: cs.CV

TL;DR: 该研究提出了一种名为 Nuclear Diffusion 的混合框架，结合低秩时间建模和扩散后验采样，以克服传统 RPCA 方法在视频去噪和恢复中的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统的鲁棒主成分分析（RPCA）方法在处理视频中的结构化噪声和背景伪影时，其稀疏性假设往往无法捕捉真实视频数据的丰富变化性。

Method: 提出了一种混合框架，该框架整合了低秩时间建模与扩散后验采样。

Result: 在心脏超声去雾的实际医疗成像问题中，与传统的 RPCA 方法相比，所提出的 Nuclear Diffusion 方法在对比度增强（gCNR）和信号保留（KS 统计量）方面表现出更优越的去雾性能。

Conclusion: 将基于模型的时域模型与深度生成先验相结合，在视频恢复方面具有巨大潜力。

Abstract: Video sequences often contain structured noise and background artifacts that
obscure dynamic content, posing challenges for accurate analysis and
restoration. Robust principal component methods address this by decomposing
data into low-rank and sparse components. Still, the sparsity assumption often
fails to capture the rich variability present in real video data. To overcome
this limitation, a hybrid framework that integrates low-rank temporal modeling
with diffusion posterior sampling is proposed. The proposed method, Nuclear
Diffusion, is evaluated on a real-world medical imaging problem, namely cardiac
ultrasound dehazing, and demonstrates improved dehazing performance compared to
traditional RPCA concerning contrast enhancement (gCNR) and signal preservation
(KS statistic). These results highlight the potential of combining model-based
temporal models with deep generative priors for high-fidelity video
restoration.

</details>


### [40] [FerretNet: Efficient Synthetic Image Detection via Local Pixel Dependencies](https://arxiv.org/abs/2509.20890)
*Shuqiao Liang,Jian Liu,Renzhang Chen,Quanlong Guan*

Main category: cs.CV

TL;DR: FerretNet是一个轻量级神经网络，通过利用局部像素依赖性（LPD）来检测生成式模型产生的伪造图像，在22种生成模型组成的开放世界基准测试中平均准确率达到97.1%，超过了最先进的方法10.6%。


<details>
  <summary>Details</summary>
Motivation: 由于VAE、GAN和LDM等先进模型生成的合成图像日益逼真，因此在合成图像检测方面带来了重大挑战。

Method: 利用局部像素依赖性（LPD）属性，重建合成图像以暴露纹理连续性和边缘连贯性中的中断。在此基础上，提出了FerretNet，一个只有110万个参数的轻量级神经网络。

Result: FerretNet在仅使用4类ProGAN数据集进行训练的情况下，在包含22种生成模型的开放世界基准测试中平均准确率达到了97.1%，比最先进的方法高出10.6%。

Conclusion: FerretNet能够高效且可靠地检测合成图像，克服了现有合成图像检测方法的局限性。

Abstract: The increasing realism of synthetic images generated by advanced models such
as VAEs, GANs, and LDMs poses significant challenges for synthetic image
detection. To address this issue, we explore two artifact types introduced
during the generation process: (1) latent distribution deviations and (2)
decoding-induced smoothing effects, which manifest as inconsistencies in local
textures, edges, and color transitions. Leveraging local pixel dependencies
(LPD) properties rooted in Markov Random Fields, we reconstruct synthetic
images using neighboring pixel information to expose disruptions in texture
continuity and edge coherence. Building upon LPD, we propose FerretNet, a
lightweight neural network with only 1.1M parameters that delivers efficient
and robust synthetic image detection. Extensive experiments demonstrate that
FerretNet, trained exclusively on the 4-class ProGAN dataset, achieves an
average accuracy of 97.1% on an open-world benchmark comprising across 22
generative models, surpassing state-of-the-art methods by 10.6%.

</details>


### [41] [Concepts in Motion: Temporal Bottlenecks for Interpretable Video Classification](https://arxiv.org/abs/2509.20899)
*Patrick Knab,Sascha Marton,Philipp J. Schubert,Drago Guggiana,Christian Bartelt*

Main category: cs.CV

TL;DR: MoTIF是一个受Transformer启发的框架，用于视频分类，它将概念瓶颈模型扩展到处理任意长度的视频序列，并提供全局、局部和时间维度上的概念重要性分析，同时保持了有竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的概念瓶颈模型（CBMs）在图像分类方面取得了进展，但将其扩展到视频数据面临挑战，因为视频数据具有固有的时间依赖性，这对于捕捉动作和事件至关重要。

Method: 提出MoTIF（Moving Temporal Interpretable Framework）框架，这是一个受Transformer启发的架构设计，用于视频分类，能够处理任意长度的视频序列。该框架能够从全局、局部和时间依赖性三个维度来分析概念的重要性。

Result: 概念驱动的建模范式可以有效地迁移到视频数据中，从而在时间背景下更好地理解概念的贡献，同时保持有竞争力的性能。

Conclusion: 概念驱动的建模范式可以有效地迁移到视频数据中，从而在时间背景下更好地理解概念的贡献，同时保持有竞争力的性能。

Abstract: Conceptual models such as Concept Bottleneck Models (CBMs) have driven
substantial progress in improving interpretability for image classification by
leveraging human-interpretable concepts. However, extending these models from
static images to sequences of images, such as video data, introduces a
significant challenge due to the temporal dependencies inherent in videos,
which are essential for capturing actions and events. In this work, we
introduce MoTIF (Moving Temporal Interpretable Framework), an architectural
design inspired by a transformer that adapts the concept bottleneck framework
for video classification and handles sequences of arbitrary length. Within the
video domain, concepts refer to semantic entities such as objects, attributes,
or higher-level components (e.g., 'bow', 'mount', 'shoot') that reoccur across
time - forming motifs collectively describing and explaining actions. Our
design explicitly enables three complementary perspectives: global concept
importance across the entire video, local concept relevance within specific
windows, and temporal dependencies of a concept over time. Our results
demonstrate that the concept-based modeling paradigm can be effectively
transferred to video data, enabling a better understanding of concept
contributions in temporal contexts while maintaining competitive performance.
Code available at github.com/patrick-knab/MoTIF.

</details>


### [42] [FSMODNet: A Closer Look at Few-Shot Detection in Multispectral Data](https://arxiv.org/abs/2509.20905)
*Manuel Nkegoum,Minh-Tan Pham,Élisa Fromont,Bruno Avignon,Sébastien Lefèvre*

Main category: cs.CV

TL;DR: FSMODNet通过跨模态特征融合和可变形注意力机制，在少样本多光谱目标检测任务中取得了良好性能。


<details>
  <summary>Details</summary>
Motivation: 在仅用少量标注数据的情况下，实现可见光与热成像两种模态下的目标检测，以应对复杂的光照和环境条件。

Method: 提出FSMODNet框架，利用可变形注意力机制集成可见光与热成像的特征，以增强在少样本条件下的检测能力。

Result: 在两个公开数据集上，FSMODNet在低数据量情况下表现出有效的目标检测能力，优于多个基线模型。

Conclusion: FSMODNet在挑战性的少样本多光谱目标检测任务中，通过跨模态特征融合展现了强大的鲁棒性和有效性。

Abstract: Few-shot multispectral object detection (FSMOD) addresses the challenge of
detecting objects across visible and thermal modalities with minimal annotated
data. In this paper, we explore this complex task and introduce a framework
named "FSMODNet" that leverages cross-modality feature integration to improve
detection performance even with limited labels. By effectively combining the
unique strengths of visible and thermal imagery using deformable attention, the
proposed method demonstrates robust adaptability in complex illumination and
environmental conditions. Experimental results on two public datasets show
effective object detection performance in challenging low-data regimes,
outperforming several baselines we established from state-of-the-art models.
All code, models, and experimental data splits can be found at
https://anonymous.4open.science/r/Test-B48D.

</details>


### [43] [Finding 3D Positions of Distant Objects from Noisy Camera Movement and Semantic Segmentation Sequences](https://arxiv.org/abs/2509.20906)
*Julius Pesonen,Arno Solin,Eija Honkavaara*

Main category: cs.CV

TL;DR: 本研究提出使用粒子滤波器进行基于相机测量的3D目标定位，特别适用于计算资源受限或目标距离较远的情况，如无人机火灾监测。


<details>
  <summary>Details</summary>
Motivation: 在安全关键的监控任务（如无人机火灾监测）中，基于相机测量序列的3D目标定位至关重要。然而，对于遥远目标或计算资源有限的情况，传统的稠密深度估计或3D场景重建方法不可行。

Method: 提出使用粒子滤波器来解决单目标和多目标场景的3D目标定位问题。

Result: 研究结果表明，在仅有相机位姿和图像分割信息的条件下，粒子滤波器能够有效解决其他方法失效的实际定位问题。粒子滤波器不依赖于检测方法，具有灵活性。

Conclusion: 粒子滤波器可以解决现有方法在遥远目标或计算资源受限情况下的3D目标定位问题，并且可以与现有的图像分割模型结合用于无人机火灾监测等实际任务。

Abstract: 3D object localisation based on a sequence of camera measurements is
essential for safety-critical surveillance tasks, such as drone-based wildfire
monitoring. Localisation of objects detected with a camera can typically be
solved with dense depth estimation or 3D scene reconstruction. However, in the
context of distant objects or tasks limited by the amount of available
computational resources, neither solution is feasible. In this paper, we show
that the task can be solved using particle filters for both single and multiple
target scenarios. The method was studied using a 3D simulation and a
drone-based image segmentation sequence with global navigation satellite system
(GNSS)-based camera pose estimates. The results showed that a particle filter
can be used to solve practical localisation tasks based on camera poses and
image segments in these situations where other solutions fail. The particle
filter is independent of the detection method, making it flexible for new
tasks. The study also demonstrates that drone-based wildfire monitoring can be
conducted using the proposed method paired with a pre-existing image
segmentation model.

</details>


### [44] [SwinMamba: A hybrid local-global mamba framework for enhancing semantic segmentation of remotely sensed images](https://arxiv.org/abs/2509.20918)
*Qinfeng Zhu,Han Li,Liang He,Lei Fan*

Main category: cs.CV

TL;DR: SwinMamba通过结合Swin Transformer的移位窗口和Vision Mamba的全局扫描，在保留局部细节的同时增强全局上下文理解，从而在遥感图像语义分割任务上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 当前的Vision Mamba模型在遥感图像语义分割中存在不足，因为它虽然具有全局感受野和低计算复杂度，但全局扫描容易忽略纹理和边缘等关键局部特征。

Method: 提出了一种名为SwinMamba的新框架，该框架借鉴了Swin Transformer的设计，将局部移位窗口的Mamba扫描与全局感受野相结合。模型的前两个阶段进行局部扫描以捕捉精细细节，后两个阶段进行全局扫描以融合更广泛的上下文信息。通过使用重叠的移位窗口来增强跨区域信息交换，促进整个图像的特征融合。

Result: 在LoveDA和ISPRS Potsdam数据集上的广泛实验表明，SwinMamba的性能优于最先进的方法。

Conclusion: SwinMamba是一种有效的新型框架，能够处理遥感图像语义分割的挑战，并在局部特征感知和全局上下文融合方面取得了显著的改进。

Abstract: Semantic segmentation of remote sensing imagery is a fundamental task in
computer vision, supporting a wide range of applications such as land use
classification, urban planning, and environmental monitoring. However, this
task is often challenged by the high spatial resolution, complex scene
structures, and diverse object scales present in remote sensing data. To
address these challenges, various deep learning architectures have been
proposed, including convolutional neural networks, Vision Transformers, and the
recently introduced Vision Mamba. Vision Mamba features a global receptive
field and low computational complexity, demonstrating both efficiency and
effectiveness in image segmentation. However, its reliance on global scanning
tends to overlook critical local features, such as textures and edges, which
are essential for achieving accurate segmentation in remote sensing contexts.
To tackle this limitation, we propose SwinMamba, a novel framework inspired by
the Swin Transformer. SwinMamba integrates localized Mamba-style scanning
within shifted windows with a global receptive field, to enhance the model's
perception of both local and global features. Specifically, the first two
stages of SwinMamba perform local scanning to capture fine-grained details,
while its subsequent two stages leverage global scanning to fuse broader
contextual information. In our model, the use of overlapping shifted windows
enhances inter-region information exchange, facilitating more robust feature
integration across the entire image. Extensive experiments on the LoveDA and
ISPRS Potsdam datasets demonstrate that SwinMamba outperforms state-of-the-art
methods, underscoring its effectiveness and potential as a superior solution
for semantic segmentation of remotely sensed imagery.

</details>


### [45] [Revisiting Data Challenges of Computational Pathology: A Pack-based Multiple Instance Learning Framework](https://arxiv.org/abs/2509.20923)
*Wenhao Tang,Heng Fang,Ge Wu,Xiang Li,Ming-Ming Cheng*

Main category: cs.CV

TL;DR: 提出了一种基于 pack-based MIL 的计算病理学框架，通过将变长序列打包成定长序列，并引入残差分支和注意力下采样器，在 PANDA 数据集上实现了高达 8% 的准确率提升和 88% 的训练时间缩减。


<details>
  <summary>Details</summary>
Motivation: 计算病理学中的全切片图像（WSIs）存在序列长度长、长度变化大、监督信号有限等挑战，这导致数据异质性和冗余性高，现有方法在训练效率和优化方面存在妥协。

Method: 提出了一种基于 pack-based MIL 的框架，包括：1. pack-based MIL：将多个采样、变长的特征序列打包成固定长度的序列，实现批量训练并保留数据异质性。2. 残差分支：将多个幻灯片中被丢弃的特征组合成一个超幻灯片，并使用定制标签进行训练，提供多幻灯片监督并减少采样特征损失。3. 注意力驱动的下采样器：压缩两个分支中的特征，减少冗余。

Result: 该方法在 PANDA 数据集上实现了高达 8% 的准确率提升，同时将训练时间缩减了 88%（仅使用了 12% 的训练时间）。

Conclusion: 计算病理学中的数据挑战（如序列长度变化大、冗余性）的解决对于利用基础模型具有重要意义。所提出的 pack-based MIL 框架有效地解决了这些挑战，并在准确性和训练效率方面取得了显著改进。

Abstract: Computational pathology (CPath) digitizes pathology slides into whole slide
images (WSIs), enabling analysis for critical healthcare tasks such as cancer
diagnosis and prognosis. However, WSIs possess extremely long sequence lengths
(up to 200K), significant length variations (from 200 to 200K), and limited
supervision. These extreme variations in sequence length lead to high data
heterogeneity and redundancy. Conventional methods often compromise on training
efficiency and optimization to preserve such heterogeneity under limited
supervision. To comprehensively address these challenges, we propose a
pack-based MIL framework. It packs multiple sampled, variable-length feature
sequences into fixed-length ones, enabling batched training while preserving
data heterogeneity. Moreover, we introduce a residual branch that composes
discarded features from multiple slides into a hyperslide which is trained with
tailored labels. It offers multi-slide supervision while mitigating feature
loss from sampling. Meanwhile, an attention-driven downsampler is introduced to
compress features in both branches to reduce redundancy. By alleviating these
challenges, our approach achieves an accuracy improvement of up to 8% while
using only 12% of the training time in the PANDA(UNI). Extensive experiments
demonstrate that focusing data challenges in CPath holds significant potential
in the era of foundation models. The code is
https://github.com/FangHeng/PackMIL

</details>


### [46] [SimDiff: Simulator-constrained Diffusion Model for Physically Plausible Motion Generation](https://arxiv.org/abs/2509.20927)
*Akihisa Watanabe,Jiawei Ren,Li Siyao,Yichen Peng,Erwin Wu,Edgar Simo-Serra*

Main category: cs.CV

TL;DR: SimDiff通过将基于模拟器的运动投影视为一种引导形式，将环境参数直接集成到去噪过程中，从而在不进行重复模拟的情况下高效生成物理上可行的运动。


<details>
  <summary>Details</summary>
Motivation: 现有方法为了保证物理上可行性，通常在扩散过程中加入基于模拟器的运动投影层，但这种方法由于模拟器的顺序性而计算成本高昂，无法并行化。

Method: 将基于模拟器的运动投影解释为一种引导（基于分类器或无分类器），并将环境参数（例如重力、风）直接集成到扩散模型的去噪过程中，提出SimDiff模型。

Result: SimDiff能够高效地生成物理上可行的运动，无需在推理时进行重复的模拟，并且可以对不同的物理系数进行细粒度控制。此外，SimDiff在未见过得环境参数组合上表现出良好的泛化能力，证明了其组合泛化能力。

Conclusion: SimDiff通过将环境参数直接纳入去噪过程，克服了现有方法的计算瓶颈，实现了高效、可控且泛化的物理运动生成。

Abstract: Generating physically plausible human motion is crucial for applications such
as character animation and virtual reality. Existing approaches often
incorporate a simulator-based motion projection layer to the diffusion process
to enforce physical plausibility. However, such methods are computationally
expensive due to the sequential nature of the simulator, which prevents
parallelization. We show that simulator-based motion projection can be
interpreted as a form of guidance, either classifier-based or classifier-free,
within the diffusion process. Building on this insight, we propose SimDiff, a
Simulator-constrained Diffusion Model that integrates environment parameters
(e.g., gravity, wind) directly into the denoising process. By conditioning on
these parameters, SimDiff generates physically plausible motions efficiently,
without repeated simulator calls at inference, and also provides fine-grained
control over different physical coefficients. Moreover, SimDiff successfully
generalizes to unseen combinations of environmental parameters, demonstrating
compositional generalization.

</details>


### [47] [Unlocking Noise-Resistant Vision: Key Architectural Secrets for Robust Models](https://arxiv.org/abs/2509.20939)
*Bum Jun Kim,Makoto Kawano,Yusuke Iwasawa,Yutaka Matsuo*

Main category: cs.CV

TL;DR: 研究视觉模型对高斯噪声的鲁棒性，发现更大的stem核、更小的输入分辨率、平均池化以及监督ViTs比CLIP ViTs能显著提高鲁棒性，并提供了相应的理论分析和设计指南。


<details>
  <summary>Details</summary>
Motivation: 许多研究关注视觉模型的鲁棒性度量，但很少深入分析特定架构设计选择对其鲁棒性的影响。

Method: 对1174个预训练视觉模型进行了广泛的评估，识别出四种提高对高斯噪声鲁棒性的设计模式：更大的stem核、更小的输入分辨率、平均池化以及监督ViTs而非CLIP ViTs。通过理论分析解释了这些发现，并将观察到的相关性转化为因果机制。

Result: 证明了低通stem核能衰减噪声，其增益随核大小二次方减小；抗混叠下采样能按下采样因子平方的比例减少噪声能量；平均池化具有无偏性，并能按池化窗口面积的比例抑制噪声，而最大池化则产生正偏差，具有较高的均方误差和更差的最坏情况敏感性。揭示了CLIP ViTs的脆弱性，其较小的标准化标准差会放大最坏情况敏感性。

Conclusion: 研究结果将鲁棒性分解为可解释的模块，提供了解释观察趋势的理论，并建立了用于设计对高斯噪声更鲁棒的视觉模型的实用、即插即用的指南。

Abstract: While the robustness of vision models is often measured, their dependence on
specific architectural design choices is rarely dissected. We investigate why
certain vision architectures are inherently more robust to additive Gaussian
noise and convert these empirical insights into simple, actionable design
rules. Specifically, we performed extensive evaluations on 1,174 pretrained
vision models, empirically identifying four consistent design patterns for
improved robustness against Gaussian noise: larger stem kernels, smaller input
resolutions, average pooling, and supervised vision transformers (ViTs) rather
than CLIP ViTs, which yield up to 506 rank improvements and 21.6\%p accuracy
gains. We then develop a theoretical analysis that explains these findings,
converting observed correlations into causal mechanisms. First, we prove that
low-pass stem kernels attenuate noise with a gain that decreases quadratically
with kernel size and that anti-aliased downsampling reduces noise energy
roughly in proportion to the square of the downsampling factor. Second, we
demonstrate that average pooling is unbiased and suppresses noise in proportion
to the pooling window area, whereas max pooling incurs a positive bias that
grows slowly with window size and yields a relatively higher mean-squared error
and greater worst-case sensitivity. Third, we reveal and explain the
vulnerability of CLIP ViTs via a pixel-space Lipschitz bound: The smaller
normalization standard deviations used in CLIP preprocessing amplify worst-case
sensitivity by up to 1.91 times relative to the Inception-style preprocessing
common in supervised ViTs. Our results collectively disentangle robustness into
interpretable modules, provide a theory that explains the observed trends, and
build practical, plug-and-play guidelines for designing vision models more
robust against Gaussian noise.

</details>


### [48] [Decoding the Surgical Scene: A Scoping Review of Scene Graphs in Surgery](https://arxiv.org/abs/2509.20941)
*Angelo Henriques,Korab Hoxha,Daniel Zapp,Peter C. Issa,Nassir Navab,M. Ali Nasseri*

Main category: cs.CV

TL;DR: 本综述系统地梳理了手术场景图（SG）的研究进展，分析了其应用、方法和未来方向，并指出了一个关键的数据鸿沟：内视角研究多使用真实数据，而外视角研究多使用模拟数据，这暴露了研究转化中的关键问题。


<details>
  <summary>Details</summary>
Motivation: 梳理手术场景图（SG）的研究进展，分析其应用、方法和未来方向，以理解其在复杂手术环境中的作用，并指出当前研究存在的挑战和机遇。

Method: 采用PRISMA-ScR指导的范围审查方法，系统地分析了手术场景图（SG）的研究，关注其应用、方法学进展和未来方向。

Result: 研究显示手术场景图（SG）领域增长迅速，但存在“数据鸿沟”，即内视角研究（如三元组识别）多使用真实2D视频，而外视角4D建模则依赖模拟数据。方法学上，研究已从图神经网络发展到基础模型，并在手术场景中显著优于通用的视觉-语言模型。SG技术已成为分析（如工作流识别、安全监控）和生成（如可控手术模拟）任务的基石。

Conclusion: 手术场景图（SG）正日趋成熟，成为连接语义的关键技术，能够驱动新一代智能系统，从而提高手术安全性、效率和培训水平。尽管数据标注和实时实现仍面临挑战，但新兴技术正在积极应对。

Abstract: Scene graphs (SGs) provide structured relational representations crucial for
decoding complex, dynamic surgical environments. This PRISMA-ScR-guided scoping
review systematically maps the evolving landscape of SG research in surgery,
charting its applications, methodological advancements, and future directions.
Our analysis reveals rapid growth, yet uncovers a critical 'data divide':
internal-view research (e.g., triplet recognition) almost exclusively uses
real-world 2D video, while external-view 4D modeling relies heavily on
simulated data, exposing a key translational research gap. Methodologically,
the field has advanced from foundational graph neural networks to specialized
foundation models that now significantly outperform generalist large
vision-language models in surgical contexts. This progress has established SGs
as a cornerstone technology for both analysis, such as workflow recognition and
automated safety monitoring, and generative tasks like controllable surgical
simulation. Although challenges in data annotation and real-time implementation
persist, they are actively being addressed through emerging techniques.
Surgical SGs are maturing into an essential semantic bridge, enabling a new
generation of intelligent systems to improve surgical safety, efficiency, and
training.

</details>


### [49] [A Real-Time On-Device Defect Detection Framework for Laser Power-Meter Sensors via Unsupervised Learning](https://arxiv.org/abs/2509.20946)
*Dongqi Zheng,Wenjin Fu,Guangzong Chen*

Main category: cs.CV

TL;DR: 开发了一个自动化的视觉检测系统，用于检测和分类激光功率计传感器涂层缺陷，能够识别热损伤和划痕等问题，并能发现新的缺陷类型。


<details>
  <summary>Details</summary>
Motivation: 解决医疗和工业应用中，激光功率计传感器涂层缺陷（如热损伤、划痕）影响测量准确性的问题。

Method: 采用无监督异常检测框架，仅用“好”的传感器图像训练，学习正常涂层分布模式。具体包括：1. 使用拉普拉斯边缘检测和K-means聚类进行预处理和区域分割。2. 利用StyleGAN2进行合成数据增强。3. 使用UFlow神经网络进行多尺度特征提取和异常图生成。

Result: 在366张真实传感器图像上进行评估，对缺陷样本的准确率为93.8%，对好样本的准确率为89.3%，图像级AUROC为0.957，像素级AUROC为0.961。

Conclusion: 该系统通过自动化质量控制，可节省年成本，并且在设备上实现时，处理时间为0.5秒/图像。

Abstract: We present an automated vision-based system for defect detection and
classification of laser power meter sensor coatings. Our approach addresses the
critical challenge of identifying coating defects such as thermal damage and
scratches that can compromise laser energy measurement accuracy in medical and
industrial applications. The system employs an unsupervised anomaly detection
framework that trains exclusively on ``good'' sensor images to learn normal
coating distribution patterns, enabling detection of both known and novel
defect types without requiring extensive labeled defect datasets. Our
methodology consists of three key components: (1) a robust preprocessing
pipeline using Laplacian edge detection and K-means clustering to segment the
area of interest, (2) synthetic data augmentation via StyleGAN2, and (3) a
UFlow-based neural network architecture for multi-scale feature extraction and
anomaly map generation. Experimental evaluation on 366 real sensor images
demonstrates $93.8\%$ accuracy on defective samples and $89.3\%$ accuracy on
good samples, with image-level AUROC of 0.957 and pixel-level AUROC of 0.961.
The system provides potential annual cost savings through automated quality
control and processing times of 0.5 seconds per image in on-device
implementation.

</details>


### [50] [Unlocking Financial Insights: An advanced Multimodal Summarization with Multimodal Output Framework for Financial Advisory Videos](https://arxiv.org/abs/2509.20961)
*Sarmistha Das,R E Zera Marveen Lyngkhoi,Sriparna Saha,Alka Maurya*

Main category: cs.CV

TL;DR: FASTER是一个框架，用于从长篇金融咨询播客视频中提取信息并生成简洁的多模态摘要，解决了特征提取、摘要优化和视觉-文本对齐的挑战。它使用BLIP、OCR和Whisper等技术，并通过基于DPO的损失函数和事实核查确保摘要的准确性和一致性。该研究还发布了一个名为Fin-APT的新数据集。


<details>
  <summary>Details</summary>
Motivation: 社交媒体的金融咨询内容以播客视频的形式得到了广泛传播，但从长达30-40分钟的多模态内容中提取信息仍然是一个挑战。

Method: FASTER框架提取特定模态的特征，利用BLIP进行视觉描述，OCR提取文本模式，Whisper进行语音转录和说话人识别。通过修改后的基于DPO的损失函数和事实核查来优化摘要，并使用基于排序器的检索机制将关键帧与摘要内容对齐。

Result: FASTER框架在多模态摘要方面表现出色，其性能、鲁棒性和泛化能力均优于现有的LLMs和VLMs。所提出的Fin-APT数据集为多模态研究提供了资源。

Conclusion: FASTER框架为金融咨询内容的多模态摘要设定了新的标准，提高了内容的可访问性和可操作性，并为相关研究开辟了新途径。

Abstract: The dynamic propagation of social media has broadened the reach of financial
advisory content through podcast videos, yet extracting insights from lengthy,
multimodal segments (30-40 minutes) remains challenging. We introduce FASTER
(Financial Advisory Summariser with Textual Embedded Relevant images), a
modular framework that tackles three key challenges: (1) extracting
modality-specific features, (2) producing optimized, concise summaries, and (3)
aligning visual keyframes with associated textual points. FASTER employs BLIP
for semantic visual descriptions, OCR for textual patterns, and Whisper-based
transcription with Speaker diarization as BOS features. A modified Direct
Preference Optimization (DPO)-based loss function, equipped with BOS-specific
fact-checking, ensures precision, relevance, and factual consistency against
the human-aligned summary. A ranker-based retrieval mechanism further aligns
keyframes with summarized content, enhancing interpretability and cross-modal
coherence. To acknowledge data resource scarcity, we introduce Fin-APT, a
dataset comprising 470 publicly accessible financial advisory pep-talk videos
for robust multimodal research. Comprehensive cross-domain experiments confirm
FASTER's strong performance, robustness, and generalizability when compared to
Large Language Models (LLMs) and Vision-Language Models (VLMs). By establishing
a new standard for multimodal summarization, FASTER makes financial advisory
content more accessible and actionable, thereby opening new avenues for
research. The dataset and code are available at:
https://github.com/sarmistha-D/FASTER

</details>


### [51] [An Adaptor for Triggering Semi-Supervised Learning to Out-of-Box Serve Deep Image Clustering](https://arxiv.org/abs/2509.20976)
*Yue Duan,Lei Qi,Yinghuan Shi,Yang Gao*

Main category: cs.CV

TL;DR: ASD是一个无需预训练、聚类学习或训练好的聚类模型即可用于深度图像聚类的适配器，通过随机采样伪标签数据、实例级分类和聚类级标签分配，实现了SSL学习器的冷启动，并在多个基准测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的深度聚类框架集成SSL技术需要预训练、聚类学习或训练好的聚类模型，限制了SSL学习器的灵活应用。

Method: 1. 随机采样伪标签数据。 2. 训练实例级分类器学习伪标签数据。 3. 跟踪预测的类别转换以提取实例级类别的语义对齐。 4. 将提取的聚类级标签分配给伪标签数据。 5. 使用带有聚类级标签的伪标签数据来触发在无标签数据上训练的通用SSL学习器进行图像聚类。

Result: ASD在多个基准测试中表现优于最新的深度图像聚类方法，与使用真实标签的SSL方法相比，准确率差距极小（例如，在CIFAR-10上仅为1.33%）。此外，ASD还能提升现有集成SSL的深度图像聚类方法的性能。

Conclusion: ASD成功实现了SSL学习器在深度图像聚类任务中的冷启动，无需任何先验知识，并在性能上超越了现有方法。

Abstract: Recently, some works integrate SSL techniques into deep clustering frameworks
to enhance image clustering performance. However, they all need pretraining,
clustering learning, or a trained clustering model as prerequisites, limiting
the flexible and out-of-box application of SSL learners in the image clustering
task. This work introduces ASD, an adaptor that enables the cold-start of SSL
learners for deep image clustering without any prerequisites. Specifically, we
first randomly sample pseudo-labeled data from all unlabeled data, and set an
instance-level classifier to learn them with semantically aligned
instance-level labels. With the ability of instance-level classification, we
track the class transitions of predictions on unlabeled data to extract
high-level similarities of instance-level classes, which can be utilized to
assign cluster-level labels to pseudo-labeled data. Finally, we use the
pseudo-labeled data with assigned cluster-level labels to trigger a general SSL
learner trained on the unlabeled data for image clustering. We show the
superior performance of ASD across various benchmarks against the latest deep
image clustering approaches and very slight accuracy gaps compared to SSL
methods using ground-truth, e.g., only 1.33% on CIFAR-10. Moreover, ASD can
also further boost the performance of existing SSL-embedded deep image
clustering methods.

</details>


### [52] [SiNGER: A Clearer Voice Distills Vision Transformers Further](https://arxiv.org/abs/2509.20986)
*Geunhyeok Yu,Sunjae Jeong,Yoonyoung Choi,Jaeseung Kim,Hyoseok Hwang*

Main category: cs.CV

TL;DR: ViT主干模型存在高范数伪影问题，这会影响表示质量。在知识蒸馏中，这些伪影会主导目标，导致学生模型过拟合伪影并忽视有用信息。为了解决这个问题，我们提出了SiNGER框架，通过利用零空间引导扰动来精炼教师特征，从而在抑制伪影的同时保留有用信息。该方法效率高，只需少量结构修改。实验表明，SiNGER能提升学生模型性能，并在下游任务中达到最先进水平，同时生成更清晰、更可解释的表示。


<details>
  <summary>Details</summary>
Motivation: Vision Transformers（ViT）作为视觉基础模型的主干，存在高范数伪影问题，影响表示质量。在知识蒸馏过程中，这些伪影会主导目标函数，导致学生模型过拟合伪影，忽视有用信号，从而削弱大模型带来的增益。现有方法在抑制伪影和保留教师信息之间存在权衡。

Method: 提出了一种名为SiNGER（Singular Nullspace-Guided Energy Reallocation）的新型知识蒸馏框架。其核心思想是通过零空间引导扰动来精炼教师特征，从而在抑制伪影的同时保留有用信息。该扰动通过一个LoRA适配器高效实现，只需少量结构修改。

Result: SiNGER能够有效地抑制伪影，同时保留教师特征中的有用信息，显著提升学生模型的性能。在多个下游任务上取得了最先进的性能，并生成了更清晰、更可解释的表示。

Conclusion: SiNGER是一种有效的知识蒸馏框架，通过零空间引导的教师特征精炼，成功解决了ViT的高范数伪影问题，在提升模型性能和表示质量方面均表现出色。

Abstract: Vision Transformers are widely adopted as the backbone of vision foundation
models, but they are known to produce high-norm artifacts that degrade
representation quality. When knowledge distillation transfers these features to
students, high-norm artifacts dominate the objective, so students overfit to
artifacts and underweight informative signals, diminishing the gains from
larger models. Prior work attempted to remove artifacts but encountered an
inherent trade-off between artifact suppression and preserving informative
signals from teachers. To address this, we introduce Singular Nullspace-Guided
Energy Reallocation (SiNGER), a novel distillation framework that suppresses
artifacts while preserving informative signals. The key idea is principled
teacher feature refinement: during refinement, we leverage the nullspace-guided
perturbation to preserve information while suppressing artifacts. Then, the
refined teacher's features are distilled to a student. We implement this
perturbation efficiently with a LoRA-based adapter that requires minimal
structural modification. Extensive experiments show that \oursname consistently
improves student models, achieving state-of-the-art performance in multiple
downstream tasks and producing clearer and more interpretable representations.

</details>


### [53] [Fast-SEnSeI: Lightweight Sensor-Independent Cloud Masking for On-board Multispectral Sensors](https://arxiv.org/abs/2509.20991)
*Jan Kněžík,Jonáš Herec,Rado Pitoňák*

Main category: cs.CV

TL;DR: Fast-SEnSeI是一个轻量级的、传感器无关的编码器模块，可以实现跨多光谱传感器的灵活的、板载云分割，并能处理不同的波段配置。


<details>
  <summary>Details</summary>
Motivation: 云分割是许多地球观测任务的关键预处理步骤，但现有模型通常与特定传感器配置耦合，并依赖于地面处理。本研究旨在开发一种能够实现灵活、板载云分割的解决方案，使其能够独立于特定传感器，并适应不同的波段配置。

Method: 提出了一种名为Fast-SEnSeI的轻量级、传感器无关的编码器模块，该模块建立在SEnSeI-v2的基础上，集成了改进的光谱描述符、轻量级架构和鲁棒的填充波段处理。该模块能够接受任意组合的光谱波段及其波长，生成固定大小的特征图，作为基于修改版U-Net的紧凑型、量化分割模型的输入。该模块在嵌入式CPU上使用Apache TVM高效运行，而分割模型则部署在FPGA上，形成一个适用于空间认证硬件的CPU-FPGA混合流水线。

Result: 在Sentinel-2和Landsat 8数据集上的评估表明，Fast-SEnSeI在各种输入配置下都能实现准确的分割。

Conclusion: Fast-SEnSeI通过提供一个轻量级、传感器无关且高效的编码器模块，实现了跨多光谱传感器的灵活的、板载云分割，并能处理不同的波段配置，从而克服了现有方法的局限性。

Abstract: Cloud segmentation is a critical preprocessing step for many Earth
observation tasks, yet most models are tightly coupled to specific sensor
configurations and rely on ground-based processing. In this work, we propose
Fast-SEnSeI, a lightweight, sensor-independent encoder module that enables
flexible, on-board cloud segmentation across multispectral sensors with varying
band configurations. Building upon SEnSeI-v2, Fast-SEnSeI integrates an
improved spectral descriptor, lightweight architecture, and robust padding-band
handling. It accepts arbitrary combinations of spectral bands and their
wavelengths, producing fixed-size feature maps that feed into a compact,
quantized segmentation model based on a modified U-Net. The module runs
efficiently on embedded CPUs using Apache TVM, while the segmentation model is
deployed on FPGA, forming a CPU-FPGA hybrid pipeline suitable for
space-qualified hardware. Evaluations on Sentinel-2 and Landsat 8 datasets
demonstrate accurate segmentation across diverse input configurations.

</details>


### [54] [A Single Neuron Works: Precise Concept Erasure in Text-to-Image Diffusion Models](https://arxiv.org/abs/2509.21008)
*Qinqin He,Jiaqi Weng,Jialing Tao,Hui Xue*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Text-to-image models exhibit remarkable capabilities in image generation.
However, they also pose safety risks of generating harmful content. A key
challenge of existing concept erasure methods is the precise removal of target
concepts while minimizing degradation of image quality. In this paper, we
propose Single Neuron-based Concept Erasure (SNCE), a novel approach that can
precisely prevent harmful content generation by manipulating only a single
neuron. Specifically, we train a Sparse Autoencoder (SAE) to map text
embeddings into a sparse, disentangled latent space, where individual neurons
align tightly with atomic semantic concepts. To accurately locate neurons
responsible for harmful concepts, we design a novel neuron identification
method based on the modulated frequency scoring of activation patterns. By
suppressing activations of the harmful concept-specific neuron, SNCE achieves
surgical precision in concept erasure with minimal disruption to image quality.
Experiments on various benchmarks demonstrate that SNCE achieves
state-of-the-art results in target concept erasure, while preserving the
model's generation capabilities for non-target concepts. Additionally, our
method exhibits strong robustness against adversarial attacks, significantly
outperforming existing methods.

</details>


### [55] [OmniPlantSeg: Species Agnostic 3D Point Cloud Organ Segmentation for High-Resolution Plant Phenotyping Across Modalities](https://arxiv.org/abs/2509.21038)
*Andreas Gilson,Lukas Meyer,Oliver Scholz,Ute Schmid*

Main category: cs.CV

TL;DR: KDSS是一种简单有效的算法，用于对生物点云进行子采样，适用于不同植物种类和传感器数据。该算法能保留全分辨率点云，无需进行密集预处理和降采样，即可实现植物器官分割。


<details>
  <summary>Details</summary>
Motivation: 现有植物器官分割方法存在问题特异性强、依赖特定植物种类或传感器、需要密集预处理和降采样等局限。

Method: 提出了一种名为KDSS的子采样算法，该算法能够处理生物点云，并且不依赖于特定的传感器或植物种类。

Result: 将KDSS与现有的先进分割模型结合使用，并在不同传感器（如摄影测量、激光三角测量和激光雷达）和多种植物物种上进行了评估，取得了满意的结果。

Conclusion: KDSS作为一种轻量级的、保留分辨率的替代方法，可以应用于各种植物物种和传感器，用于植物器官分割，克服了密集预处理和降采样的限制。

Abstract: Accurate point cloud segmentation for plant organs is crucial for 3D plant
phenotyping. Existing solutions are designed problem-specific with a focus on
certain plant species or specified sensor-modalities for data acquisition.
Furthermore, it is common to use extensive pre-processing and down-sample the
plant point clouds to meet hardware or neural network input size requirements.
We propose a simple, yet effective algorithm KDSS for sub-sampling of
biological point clouds that is agnostic to sensor data and plant species. The
main benefit of this approach is that we do not need to down-sample our input
data and thus, enable segmentation of the full-resolution point cloud.
Combining KD-SS with current state-of-the-art segmentation models shows
satisfying results evaluated on different modalities such as photogrammetry,
laser triangulation and LiDAR for various plant species. We propose KD-SS as
lightweight resolution-retaining alternative to intensive pre-processing and
down-sampling methods for plant organ segmentation regardless of used species
and sensor modality.

</details>


### [56] [Background Prompt for Few-Shot Out-of-Distribution Detection](https://arxiv.org/abs/2509.21055)
*Songyue Cai,Zongqian Wu,Yujie Mo,Liang Peng,Ping Hu,Xiaoshuang Shi,Xiaofeng Zhu*

Main category: cs.CV

TL;DR: Mambo框架通过学习背景提示并结合类别相似性来改进前景-背景分解，解决了现有方法鲁棒性不足的问题，并在OOD检测和近OOD检测方面取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有前景-背景（FG-BG）分解方法在少样本离群（FS-OOD）检测中，由于过度依赖局部类别相似性和固定的背景块提取策略，鲁棒性不足。

Method: 提出了一种名为Mambo的新型FG-BG分解框架。首先，学习背景提示以获得包含背景和图像语义信息的局部背景相似性；然后，利用局部类别相似性优化局部背景相似性。最后，利用优化后的局部背景相似性和局部类别相似性进行背景提取。此外，提出了一种自校准的块调整方法，以考虑样本多样性，灵活选择不同样本的背景块数量。

Result: Mambo框架在前景-背景分解中，通过结合背景提示和类别相似性，并采用自校准的块调整策略，提高了OOD检测和近OOD检测的性能，并在真实世界数据集上取得了SOTA结果。

Conclusion: Mambo框架通过引入背景提示和自校准块调整策略，克服了现有FS-OOD检测方法的局限性，显著提高了检测性能。

Abstract: Existing foreground-background (FG-BG) decomposition methods for the few-shot
out-of-distribution (FS-OOD) detection often suffer from low robustness due to
over-reliance on the local class similarity and a fixed background patch
extraction strategy. To address these challenges, we propose a new FG-BG
decomposition framework, namely Mambo, for FS-OOD detection. Specifically, we
propose to first learn a background prompt to obtain the local background
similarity containing both the background and image semantic information, and
then refine the local background similarity using the local class similarity.
As a result, we use both the refined local background similarity and the local
class similarity to conduct background extraction, reducing the dependence of
the local class similarity in previous methods. Furthermore, we propose the
patch self-calibrated tuning to consider the sample diversity to flexibly
select numbers of background patches for different samples, and thus exploring
the issue of fixed background extraction strategies in previous methods.
Extensive experiments on real-world datasets demonstrate that our proposed
Mambo achieves the best performance, compared to SOTA methods in terms of OOD
detection and near OOD detection setting. The source code will be released at
https://github.com/YuzunoKawori/Mambo.

</details>


### [57] [Stratify or Die: Rethinking Data Splits in Image Segmentation](https://arxiv.org/abs/2509.21056)
*Naga Venkata Sai Jitin Jami,Thomas Altstidl,Jonas Mueller,Jindong Li,Dario Zanca,Bjoern Eskofier,Heike Leutheuser*

Main category: cs.CV

TL;DR: 本篇论文提出了一种名为迭代像素分层（IPS）的新的数据集划分方法，并结合了旨在使用沃塞尔斯坦距离来优化标签分布相似性的遗传算法（WDES），以解决图像分割中数据集划分不具代表性的问题。


<details>
  <summary>Details</summary>
Motivation: 随机划分数据集在图像分割任务中会导致测试集代表性不足，模型评估产生偏差且泛化能力差。虽然分层采样在分类任务中有效，但由于多标签结构和类别不平衡，将其应用于分割任务具有挑战性。

Method: 论文首先提出了一种名为迭代像素分层（IPS）的简单、感知标签的数据采样方法，适用于分割任务。然后，提出了一种新的遗传算法——沃塞尔斯坦驱动的进化分层（WDES），旨在最小化沃塞尔斯坦距离，以优化数据集划分中的标签分布相似性。最后，利用新提出的统计异质性指标，评估了IPS和WDES与随机采样相比的效果。

Result: 研究结果表明，WDES 持续生成更具代表性的数据集划分，并且在街景、医学影像和卫星图像等多种分割任务中，使用 WDES 划分的数据集能够降低模型评估的性能方差并提高评估精度。特别是在处理小型、不平衡和多样性低的数据集时，WDES 的优势尤为明显。

Conclusion: WDES 是一种有效的、全局最优的数据集划分方法，尤其适用于图像分割任务，能够生成更具代表性的数据集划分，从而实现更可靠的模型评估和改进模型泛化能力。

Abstract: Random splitting of datasets in image segmentation often leads to
unrepresentative test sets, resulting in biased evaluations and poor model
generalization. While stratified sampling has proven effective for addressing
label distribution imbalance in classification tasks, extending these ideas to
segmentation remains challenging due to the multi-label structure and class
imbalance typically present in such data. Building on existing stratification
concepts, we introduce Iterative Pixel Stratification (IPS), a straightforward,
label-aware sampling method tailored for segmentation tasks. Additionally, we
present Wasserstein-Driven Evolutionary Stratification (WDES), a novel genetic
algorithm designed to minimize the Wasserstein distance, thereby optimizing the
similarity of label distributions across dataset splits. We prove that WDES is
globally optimal given enough generations. Using newly proposed statistical
heterogeneity metrics, we evaluate both methods against random sampling and
find that WDES consistently produces more representative splits. Applying WDES
across diverse segmentation tasks, including street scenes, medical imaging,
and satellite imagery, leads to lower performance variance and improved model
evaluation. Our results also highlight the particular value of WDES in handling
small, imbalanced, and low-diversity datasets, where conventional splitting
strategies are most prone to bias.

</details>


### [58] [EnGraf-Net: Multiple Granularity Branch Network with Fine-Coarse Graft Grained for Classification Task](https://arxiv.org/abs/2509.21061)
*Riccardo La Grassa,Ignazio Gallo,Nicola Landro*

Main category: cs.CV

TL;DR: EnGraf-Net利用语义层级结构作为监督信号，在细粒度图像识别任务中无需手动标注或裁剪即可达到先进水平。


<details>
  <summary>Details</summary>
Motivation: 现有细粒度分类模型依赖于部分标注或复杂的注意力机制，但可能忽略局部特征的完整性。本文提出利用人类识别物体的方式——形成语义联想，来改进分类性能。

Method: 提出了一种名为EnGraf-Net的端到端深度神经网络模型，该模型利用分层组织的语义联想（即分类法）作为监督信号。

Result: 在CIFAR-100、CUB-200-2011和FGVC-Aircraft三个数据集上进行了广泛的实验，EnGraf-Net的性能优于许多现有模型，并与最新的先进方法具有竞争力。

Conclusion: EnGraf-Net在细粒度图像识别任务中，通过利用语义层级结构，成功避免了对裁剪技术和手动标注的依赖，并取得了优越的性能。

Abstract: Fine-grained classification models are designed to focus on the relevant
details necessary to distinguish highly similar classes, particularly when
intra-class variance is high and inter-class variance is low. Most existing
models rely on part annotations such as bounding boxes, part locations, or
textual attributes to enhance classification performance, while others employ
sophisticated techniques to automatically extract attention maps. We posit that
part-based approaches, including automatic cropping methods, suffer from an
incomplete representation of local features, which are fundamental for
distinguishing similar objects. While fine-grained classification aims to
recognize the leaves of a hierarchical structure, humans recognize objects by
also forming semantic associations. In this paper, we leverage semantic
associations structured as a hierarchy (taxonomy) as supervised signals within
an end-to-end deep neural network model, termed EnGraf-Net. Extensive
experiments on three well-known datasets CIFAR-100, CUB-200-2011, and
FGVC-Aircraft demonstrate the superiority of EnGraf-Net over many existing
fine-grained models, showing competitive performance with the most recent
state-of-the-art approaches, without requiring cropping techniques or manual
annotations.

</details>


### [59] [Vision Transformers: the threat of realistic adversarial patches](https://arxiv.org/abs/2509.21084)
*Kasper Cools,Clara Maathuis,Alexander M. van Oers,Claudia S. Hübner,Nikos Deligiannis,Marijke Vandewal,Geert De Cubber*

Main category: cs.CV

TL;DR: Vision Transformers (ViTs) 虽然比 CNNs 更强大且更具鲁棒性，但仍然容易受到对抗性补丁的攻击，特别是在人物分类任务中。本研究使用 Creases Transformation (CT) 技术设计了逼真的对抗性补丁，并评估了这些补丁在不同 ViT 模型上的攻击成功率，发现攻击成功率差异很大，从 40.04% 到 99.97%。研究还证实了对抗性补丁可以从 CNNs 迁移到 ViTs，并且预训练数据集的大小和方法会显著影响模型的防御能力。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习系统越来越广泛地被依赖，其安全性已成为一个关键问题。特别是，逃避攻击可能导致安全漏洞或目标错误分类。尽管 Vision Transformers (ViTs) 在性能和鲁棒性方面优于卷积神经网络 (CNNs)，但它们仍然容易受到对抗性补丁的攻击。因此，研究 ViTs 在人物分类任务中对这些攻击的漏洞至关重要。

Method: 本研究通过设计逼真的对抗性补丁来调查 ViTs 在人物分类任务中的漏洞。这些补丁利用 Creases Transformation (CT) 技术，该技术会引入类似于穿着衣物时发生的自然几何失真。此外，研究还探讨了用于 CNNs 的对抗性攻击技术在 ViT 分类模型上的可转移性。

Result: 在针对人物分类任务的四个微调 ViT 模型进行的实验评估中，攻击成功率存在显著差异，范围从 google/vit-base-patch16-224-in21k 的 40.04% 到 facebook/dino-vitb16 的 99.97%。google/vit-base-patch16-224 的成功率为 66.40%，facebook/dinov3-vitb16 的成功率为 65.17%。

Conclusion: 研究结果证实了对抗性补丁可以跨架构从 CNNs 迁移到 ViTs。此外，预训练数据集的规模和方法在很大程度上影响了模型对这些对抗性攻击的抵抗能力。

Abstract: The increasing reliance on machine learning systems has made their security a
critical concern. Evasion attacks enable adversaries to manipulate the
decision-making processes of AI systems, potentially causing security breaches
or misclassification of targets. Vision Transformers (ViTs) have gained
significant traction in modern machine learning due to increased 1) performance
compared to Convolutional Neural Networks (CNNs) and 2) robustness against
adversarial perturbations. However, ViTs remain vulnerable to evasion attacks,
particularly to adversarial patches, unique patterns designed to manipulate AI
classification systems. These vulnerabilities are investigated by designing
realistic adversarial patches to cause misclassification in person vs.
non-person classification tasks using the Creases Transformation (CT)
technique, which adds subtle geometric distortions similar to those occurring
naturally when wearing clothing. This study investigates the transferability of
adversarial attack techniques used in CNNs when applied to ViT classification
models. Experimental evaluation across four fine-tuned ViT models on a binary
person classification task reveals significant vulnerability variations: attack
success rates ranged from 40.04% (google/vit-base-patch16-224-in21k) to 99.97%
(facebook/dino-vitb16), with google/vit-base-patch16-224 achieving 66.40% and
facebook/dinov3-vitb16 reaching 65.17%. These results confirm the
cross-architectural transferability of adversarial patches from CNNs to ViTs,
with pre-training dataset scale and methodology strongly influencing model
resilience to adversarial attacks.

</details>


### [60] [UniTransfer: Video Concept Transfer via Progressive Spatial and Timestep Decomposition](https://arxiv.org/abs/2509.21086)
*Guojun Lei,Rong Zhang,Chi Wang,Tianhang Liu,Hong Li,Zhiyuan Ma,Weiwei Xu*

Main category: cs.CV

TL;DR: UniTransfer是一种新颖的视频概念迁移架构，通过空间和扩散时间步长分解，实现精确可控的迁移。


<details>
  <summary>Details</summary>
Motivation: 旨在实现精确、可控的视频概念迁移，并解决现有方法的局限性。

Method: 提出UniTransfer架构，包含空间分解（前景、背景、运动流）、双到单流DiT架构、自监督预训练策略（随机掩码）、Chain-of-Prompt（CoP）机制（多阶段去噪、LLM引导）以及OpenAnimal数据集。

Result: 在视觉保真度和可编辑性方面超越现有基线，实现高质量、可控的视频概念迁移。

Conclusion: UniTransfer在视频概念迁移任务上取得了显著成果，展示了其在生成质量和控制方面的优越性。

Abstract: We propose a novel architecture UniTransfer, which introduces both spatial
and diffusion timestep decomposition in a progressive paradigm, achieving
precise and controllable video concept transfer. Specifically, in terms of
spatial decomposition, we decouple videos into three key components: the
foreground subject, the background, and the motion flow. Building upon this
decomposed formulation, we further introduce a dual-to-single-stream DiT-based
architecture for supporting fine-grained control over different components in
the videos. We also introduce a self-supervised pretraining strategy based on
random masking to enhance the decomposed representation learning from
large-scale unlabeled video data. Inspired by the Chain-of-Thought reasoning
paradigm, we further revisit the denoising diffusion process and propose a
Chain-of-Prompt (CoP) mechanism to achieve the timestep decomposition. We
decompose the denoising process into three stages of different granularity and
leverage large language models (LLMs) for stage-specific instructions to guide
the generation progressively. We also curate an animal-centric video dataset
called OpenAnimal to facilitate the advancement and benchmarking of research in
video concept transfer. Extensive experiments demonstrate that our method
achieves high-quality and controllable video concept transfer across diverse
reference images and scenes, surpassing existing baselines in both visual
fidelity and editability. Web Page:
https://yu-shaonian.github.io/UniTransfer-Web/

</details>


### [61] [VideoChat-R1.5: Visual Test-Time Scaling to Reinforce Multimodal Reasoning by Iterative Perception](https://arxiv.org/abs/2509.21100)
*Ziang Yan,Xinhao Li,Yinan He,Zhengrong Yue,Xiangyu Zeng,Yali Wang,Yu Qiao,Limin Wang,Yi Wang*

Main category: cs.CV

TL;DR: VTTS是一种通过迭代感知来增强多模态大语言模型（MLLMs）推理的新方法，通过渐进式地关注高置信度时空区域来模仿人类的层级注意力，并利用强化学习和时空监督进行优化。该方法在Videochat-R1.5模型上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 增强多模态大语言模型（MLLMs）的推理能力，以实现更高级别的人类感知和理解，克服现有方法受限于静态感知阶段的局限性。

Method: 提出视觉测试时扩展（VTTS）方法，包含迭代感知（ITP）机制，利用强化学习和时空监督来优化推理过程。VTTS通过更新的文本预测来指导，逐步优化对高置信度时空区域的关注，从而增加感知计算量。

Result: VTTS在Videochat-R1.5模型上取得了显著的性能提升，在超过15个基准测试中平均提升超过5%，这些测试涵盖了视频对话、视频推理和时空感知等任务。模型在各种任务和基准测试中表现出有效性和泛化能力。

Conclusion: VTTS通过迭代感知显著增强了MLLMs的推理能力，并且在视频理解相关任务上取得了优越的性能。

Abstract: Inducing reasoning in multimodal large language models (MLLMs) is critical
for achieving human-level perception and understanding. Existing methods mainly
leverage LLM reasoning to analyze parsed visuals, often limited by static
perception stages. This paper introduces Visual Test-Time Scaling (VTTS), a
novel approach to enhance MLLMs' reasoning via iterative perception during
inference. VTTS mimics humans' hierarchical attention by progressively refining
focus on high-confidence spatio-temporal regions, guided by updated textual
predictions. Specifically, VTTS employs an Iterative Perception (ITP)
mechanism, incorporating reinforcement learning with spatio-temporal
supervision to optimize reasoning. To support this paradigm, we also present
VTTS-80K, a dataset tailored for iterative perception. These designs allows a
MLLM to enhance its performance by increasing its perceptual compute. Extensive
experiments validate VTTS's effectiveness and generalization across diverse
tasks and benchmarks. Our newly introduced Videochat-R1.5 model has achieved
remarkable improvements, with an average increase of over 5\%, compared to
robust baselines such as Qwen2.5VL-3B and -7B, across more than 15 benchmarks
that encompass video conversation, video reasoning, and spatio-temporal
perception.

</details>


### [62] [Mammo-CLIP Dissect: A Framework for Analysing Mammography Concepts in Vision-Language Models](https://arxiv.org/abs/2509.21102)
*Suaiba Amina Salahuddin,Teresa Dorszewski,Marit Almenning Martiniussen,Tone Hovda,Antonio Portaluri,Solveig Thrun,Michael Kampffmeyer,Elisabeth Wetzer,Kristoffer Wickstrøm,Robert Jenssen*

Main category: cs.CV

TL;DR: 本研究提出了Mammo-CLIP Dissect，一个用于解剖深度学习（DL）在乳腺X线摄影中使用的视觉模型，通过识别和量化模型学习到的文本概念，以提高AI在临床环境中的安全性。


<details>
  <summary>Details</summary>
Motivation: 在临床环境中安全部署人工智能（AI）需要理解深度学习（DL）模型所学的内容。本研究旨在解决现有基于像素的可解释性方法在临床应用中的局限性，专注于模型学习到的文本概念，这可能更符合临床医生的推理方式。

Method: 本研究引入了一种名为Mammo-CLIP Dissect的概念化解释框架，该框架利用一个专门的乳腺X线摄影视觉-语言模型（Mammo-CLIP）来标记特定层的神经元，并将其与人类可理解的文本概念相关联。通过量化这些概念与领域知识的对齐程度，来分析不同训练数据集（通用图像 vs. 乳腺X线摄影）和下游任务微调对模型概念学习的影响。

Result: 研究表明，在乳腺X线摄影数据上训练的模型能够学习到更多临床相关概念，并更好地契合放射科医生的工作流程。然而，针对特定任务的微调会影响概念的专门化程度，可能导致某些概念（如良性钙化）的识别能力增强，而另一些概念（如密度相关特征）的覆盖范围减小，这表明专门化和泛化能力之间存在权衡。此外，研究还揭示了某些与乳腺X线摄影相关的概念在模型中可能存在代表性不足的情况。

Conclusion: Mammo-CLIP Dissect 框架能够深入了解卷积神经网络（CNN）如何学习乳腺X线摄影相关的知识，并通过比较不同训练和微调策略下的模型，揭示领域特定训练和任务特定适应如何塑造概念学习。

Abstract: Understanding what deep learning (DL) models learn is essential for the safe
deployment of artificial intelligence (AI) in clinical settings. While previous
work has focused on pixel-based explainability methods, less attention has been
paid to the textual concepts learned by these models, which may better reflect
the reasoning used by clinicians. We introduce Mammo-CLIP Dissect, the first
concept-based explainability framework for systematically dissecting DL vision
models trained for mammography. Leveraging a mammography-specific
vision-language model (Mammo-CLIP) as a "dissector," our approach labels
neurons at specified layers with human-interpretable textual concepts and
quantifies their alignment to domain knowledge. Using Mammo-CLIP Dissect, we
investigate three key questions: (1) how concept learning differs between DL
vision models trained on general image datasets versus mammography-specific
datasets; (2) how fine-tuning for downstream mammography tasks affects concept
specialisation; and (3) which mammography-relevant concepts remain
underrepresented. We show that models trained on mammography data capture more
clinically relevant concepts and align more closely with radiologists'
workflows than models not trained on mammography data. Fine-tuning for
task-specific classification enhances the capture of certain concept categories
(e.g., benign calcifications) but can reduce coverage of others (e.g.,
density-related features), indicating a trade-off between specialisation and
generalisation. Our findings show that Mammo-CLIP Dissect provides insights
into how convolutional neural networks (CNNs) capture mammography-specific
knowledge. By comparing models across training data and fine-tuning regimes, we
reveal how domain-specific training and task-specific adaptation shape concept
learning. Code and concept set are available:
https://github.com/Suaiba/Mammo-CLIP-Dissect.

</details>


### [63] [MOSS-ChatV: Reinforcement Learning with Process Reasoning Reward for Video Temporal Reasoning](https://arxiv.org/abs/2509.21113)
*Sicheng Tao,Jungang Li,Yibo Yan,Junyan Zhang,Yubo Gao,Hanqian Li,ShuHang Xun,Yuxuan Fan,Hong Chen,Jianxiang He,Xuming Hu*

Main category: cs.CV

TL;DR: MOSS-ChatV是一个基于强化学习的视频推理框架，通过动态时间规整（DTW）奖励来解决现有模型过程不一致的问题，并在MOSS-Video基准测试和其他通用视频基准测试上取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型（MLLMs）在视频推理时常出现过程不一致的问题，即中间推理过程偏离视频动态，影响可解释性和鲁棒性。

Method: 提出了一种名为MOSS-ChatV的强化学习框架，并引入了基于动态时间规整（DTW）的过程奖励，以监督推理过程。同时构建了MOSS-Video基准来评估模型在动态状态预测上的表现。

Result: MOSS-ChatV在MOSS-Video测试集上达到了87.2%的准确率，并在MVBench和MMVU等通用视频基准测试上有所提升。该框架对Qwen2.5-VL和Phi-2等不同架构均有效。GPT-4o评估显示MOSS-ChatV的推理过程更一致、更稳定。

Conclusion: MOSS-ChatV框架通过引入DTW奖励有效解决了视频推理中的过程不一致问题，提高了模型的可解释性和鲁棒性，并在多个基准测试中展现出优越性能和广泛适用性。

Abstract: Video reasoning has emerged as a critical capability for multimodal large
language models (MLLMs), requiring models to move beyond static perception
toward coherent understanding of temporal dynamics in complex scenes. Yet
existing MLLMs often exhibit process inconsistency, where intermediate
reasoning drifts from video dynamics even when the final answer is correct,
undermining interpretability and robustness. To address this issue, we
introduce MOSS-ChatV, a reinforcement learning framework with a Dynamic Time
Warping (DTW)-based process reward. This rule-based reward aligns reasoning
traces with temporally grounded references, enabling efficient process
supervision without auxiliary reward models. We further identify dynamic state
prediction as a key measure of video reasoning and construct MOSS-Video, a
benchmark with annotated reasoning traces, where the training split is used to
fine-tune MOSS-ChatV and the held-out split is reserved for evaluation.
MOSS-ChatV achieves 87.2\% on MOSS-Video (test) and improves performance on
general video benchmarks such as MVBench and MMVU. The framework consistently
yields gains across different architectures, including Qwen2.5-VL and Phi-2,
confirming its broad applicability. Evaluations with GPT-4o-as-judge further
show that MOSS-ChatV produces more consistent and stable reasoning traces.

</details>


### [64] [MotionFlow:Learning Implicit Motion Flow for Complex Camera Trajectory Control in Video Generation](https://arxiv.org/abs/2509.21119)
*Guojun Lei,Chi Wang,Yikai Wang,Hong Li,Ying Song,Weiwei Xu*

Main category: cs.CV

TL;DR: 该研究提出了一种将相机和物体运动统一为像素运动的新方法，利用稳定扩散网络学习运动图谱，并结合语义物体先验，通过图像到视频网络生成能精确跟随相机轨迹并保持物体运动一致性的视频，实验证明效果优于现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成相机轨迹引导的视频时，尤其是在同时存在相机和物体运动的情况下，难以保持一致性和泛化性，因为它们通常分别学习这两种运动，容易混淆它们的相对运动。

Method: 将相机和物体运动统一转换为对应像素的运动。利用稳定扩散网络学习与指定相机轨迹相关的参考运动图谱，并结合提取的语义物体先验，输入到图像到视频网络中以生成视频。

Result: 所提出的模型能够生成精确跟随指定相机轨迹并保持物体运动一致性的视频，并且在大量实验中证明其性能显著优于现有最先进的方法。

Conclusion: 该方法通过将相机和物体运动统一为像素运动，有效解决了现有方法在生成相机轨迹引导视频时的一致性和泛化性问题，并取得了优于现有方法的性能。

Abstract: Generating videos guided by camera trajectories poses significant challenges
in achieving consistency and generalizability, particularly when both camera
and object motions are present. Existing approaches often attempt to learn
these motions separately, which may lead to confusion regarding the relative
motion between the camera and the objects. To address this challenge, we
propose a novel approach that integrates both camera and object motions by
converting them into the motion of corresponding pixels. Utilizing a stable
diffusion network, we effectively learn reference motion maps in relation to
the specified camera trajectory. These maps, along with an extracted semantic
object prior, are then fed into an image-to-video network to generate the
desired video that can accurately follow the designated camera trajectory while
maintaining consistent object motions. Extensive experiments verify that our
model outperforms SOTA methods by a large margin.

</details>


### [65] [The Unwinnable Arms Race of AI Image Detection](https://arxiv.org/abs/2509.21135)
*Till Aczel,Lorenzo Vettor,Andreas Plesner,Roger Wattenhofer*

Main category: cs.CV

TL;DR: 图像生成AI的进步使得区分真实和合成图像变得更加困难。本研究探讨了数据维度和数据复杂度如何影响判别器在区分中的能力。


<details>
  <summary>Details</summary>
Motivation: 探究在图像生成AI的“生成器”与“判别器”的军备竞赛中，哪些因素会使判别器处于不利地位。

Method: 通过分析数据维度和数据复杂度这两个关键因素，并使用柯尔莫哥洛夫复杂度作为衡量数据集内在结构的指标。

Result: 研究发现，非常简单或高度复杂的数据集都会降低合成图像的可检测性。简单数据集易于被生成器完美学习，而极端复杂性则会掩盖瑕疵。相反，中等复杂性的数据集为检测提供了最有利的条件，因为生成器无法完全捕捉数据分布，其错误仍然可见。

Conclusion: 数据复杂度对判别器检测合成图像的能力有显著影响，中等复杂度的数据集最有利于判别器识别出生成器的错误。

Abstract: The rapid progress of image generative AI has blurred the boundary between
synthetic and real images, fueling an arms race between generators and
discriminators. This paper investigates the conditions under which
discriminators are most disadvantaged in this competition. We analyze two key
factors: data dimensionality and data complexity. While increased
dimensionality often strengthens the discriminators ability to detect subtle
inconsistencies, complexity introduces a more nuanced effect. Using Kolmogorov
complexity as a measure of intrinsic dataset structure, we show that both very
simple and highly complex datasets reduce the detectability of synthetic
images; generators can learn simple datasets almost perfectly, whereas extreme
diversity masks imperfections. In contrast, intermediate-complexity datasets
create the most favorable conditions for detection, as generators fail to fully
capture the distribution and their errors remain visible.

</details>


### [66] [WAVECLIP: Wavelet Tokenization for Adaptive-Resolution CLIP](https://arxiv.org/abs/2509.21153)
*Moshe Kimhi,Erez Koifman,Ehud Rivlin,Eli Schwartz,Chaim Baskin*

Main category: cs.CV

TL;DR: WAVECLIP是一个基于小波的统一模型，用于CLIP的自适应分辨率推理，通过多级小波分解实现粗到精的图像处理，支持同一模型内的多分辨率。它在推理时从低分辨率令牌开始，通过键值缓存和因果跨层注意力重用计算，仅在需要时进行精炼。该模型在零次学习分类中表现出色，通过基于置信度的门控机制实现自适应提前退出，允许用户动态选择计算-准确性权衡。WAVECLIP仅需要与冻结的CLIP教师进行轻量级蒸馏，即可在显著节省计算资源的同时，达到具有竞争力的准确性。


<details>
  <summary>Details</summary>
Motivation: WAVECLIP旨在解决CLIP模型在处理不同分辨率图像时计算效率和灵活性不足的问题，提出一种能够自适应调整计算量以在准确性和计算成本之间取得平衡的统一模型。

Method: WAVECLIP采用基于小波分解的令牌化方法，取代了标准的图像块嵌入。这种方法允许模型从粗略到精细地处理图像，并能在同一模型内自然地支持多分辨率。在推理过程中，模型从低分辨率令牌开始，利用键值缓存和因果跨层注意力机制，仅在需要时引入新的信息并进行计算精炼，从而实现计算的重用和优化。

Result: 在零次学习分类任务的评估中，WAVECLIP通过引入简单的置信度门控机制，实现了自适应的提前退出策略。这使得用户能够使用单一部署的模型，动态地选择计算量和准确性之间的权衡。结果表明，WAVECLIP在保持高准确性的同时，显著降低了计算成本，并且仅需要与冻结的CLIP教师进行轻量级蒸馏。

Conclusion: WAVECLIP成功地通过小波变换实现了CLIP模型的自适应分辨率推理，提供了一种在准确性和计算效率之间灵活权衡的解决方案。该方法不仅在技术上实现了计算重用和多分辨率支持，而且在实际应用中，通过简化的蒸馏和自适应门控机制，为用户提供了可定制的性能选择，具有显著的计算优势。

Abstract: We introduce WAVECLIP, a single unified model for adaptive resolution
inference in CLIP, enabled by wavelet-based tokenization. WAVECLIP replaces
standard patch embeddings with a multi-level wavelet decomposition, enabling
the model to process images coarse to fine while naturally supporting multiple
resolutions within the same model. At inference time, the model begins with low
resolution tokens and refines only when needed, using key-value caching and
causal cross-level attention to reuse computation, effectively introducing to
the model only new information when needed. We evaluate WAVECLIP in zero-shot
classification, demonstrating that a simple confidence-based gating mechanism
enables adaptive early exits. This allows users to dynamically choose a
compute-accuracy trade-off using a single deployed model. Our approach requires
only lightweight distillation from a frozen CLIP teacher and achieves
competitive accuracy with significant computational savings.

</details>


### [67] [Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy](https://arxiv.org/abs/2509.21173)
*Aymen Bouguerra,Daniel Montoya,Alexandra Gomez-Villa,Fabio Arnez,Chokri Mraidha*

Main category: cs.CV

TL;DR: 量化可以提高CLIP模型的校准能力（对于通常校准不足的模型）并改善OOD检测，同时可以通过特定的量化感知训练方法在效率和性能之间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 研究量化对CLIP模型在准确性之外的可靠性指标（如校准和OOD检测）的影响，并探索如何在效率和性能之间取得平衡。

Method: 对CLIP模型进行大规模量化评估，评估指标包括分布内准确性、可靠性指标（如校准）和OOD检测能力。探索了不同的量化感知训练（QAT）方法。

Result: 量化可以改善校准不足模型的校准能力，但可能降低过拟合模型的校准能力。即使在校准能力下降的情况下，OOD检测能力仍可能提高。存在可以同时提高准确性、校准能力和OOD鲁棒性的QAT方法，这挑战了效率-性能权衡的观点。

Conclusion: 量化是部署高效、可靠和鲁棒的视觉-语言模型（VLMs）的重要手段，其作用超越了传统意义上的效率提升。

Abstract: The powerful zero-shot generalization capabilities of vision-language models
(VLMs) like CLIP have enabled new paradigms for safety-related tasks such as
out-of-distribution (OOD) detection. However, additional aspects crucial for
the computationally efficient and reliable deployment of CLIP are still
overlooked. In particular, the impact of quantization on CLIP's performance
beyond accuracy remains underexplored. This work presents a large-scale
evaluation of quantization on CLIP models, assessing not only in-distribution
accuracy but a comprehensive suite of reliability metrics and revealing
counterintuitive results driven by pre-training source. We demonstrate that
quantization consistently improves calibration for typically underconfident
pre-trained models, while often degrading it for overconfident variants.
Intriguingly, this degradation in calibration does not preclude gains in other
reliability metrics; we find that OOD detection can still improve for these
same poorly calibrated models. Furthermore, we identify specific
quantization-aware training (QAT) methods that yield simultaneous gains in
zero-shot accuracy, calibration, and OOD robustness, challenging the view of a
strict efficiency-performance trade-off. These findings offer critical insights
for navigating the multi-objective problem of deploying efficient, reliable,
and robust VLMs by utilizing quantization beyond its conventional role.

</details>


### [68] [TABLET: A Large-Scale Dataset for Robust Visual Table Understanding](https://arxiv.org/abs/2509.21205)
*Iñigo Alonso,Imanol Miranda,Eneko Agirre,Mirella Lapata*

Main category: cs.CV

TL;DR: 该研究提出了TABLET，一个包含400万个示例、20个任务的大规模视觉表格理解（VTU）数据集，旨在解决现有VTU基准测试中真实世界表格复杂性和视觉多样性不足的问题。TABLET包含200万个独特的表格，其中88%保留了原始可视化，并提供了配对的图像-HTML表示、元数据和来源信息。研究表明，在TABLET上对Qwen2.5-VL-7B等视觉语言模型进行微调，可以提高模型在已见和未见VTU任务上的性能，并增强其在真实世界表格可视化上的鲁棒性。TABLET通过保留原始可视化和实例可追溯性，为未来VTU模型的鲁棒训练和可扩展评估奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 现有视觉表格理解（VTU）基准测试主要使用缺乏真实世界表格复杂性和视觉多样性的合成渲染表格，并且数据集提供的示例固定，缺乏底层序列化数据进行重构。需要一个更全面、更贴近真实世界的数据集来训练和评估VTU模型。

Method: 创建了一个名为TABLET的大规模VTU数据集，包含400万个示例和20个任务，基于200万个独特的表格。数据集中88%的表格保留了原始可视化，并提供了图像-HTML表示、元数据和来源信息。使用该数据集对Qwen2.5-VL-7B等视觉语言模型进行了微调。

Result: 在TABLET数据集上微调的模型在已见和未见VTU任务上表现更好，并且在处理真实世界表格可视化时更加鲁棒。

Conclusion: TABLET数据集通过保留原始可视化和实例可追溯性，为VTU模型的鲁棒训练和可扩展评估提供了坚实的基础，推动了VTU领域的发展。

Abstract: While table understanding increasingly relies on pixel-only settings where
tables are processed as visual representations, current benchmarks
predominantly use synthetic renderings that lack the complexity and visual
diversity of real-world tables. Additionally, existing visual table
understanding (VTU) datasets offer fixed examples with single visualizations
and pre-defined instructions, providing no access to underlying serialized data
for reformulation. We introduce TABLET, a large-scale VTU dataset with 4
million examples across 20 tasks, grounded in 2 million unique tables where 88%
preserve original visualizations. Each example includes paired image-HTML
representations, comprehensive metadata, and provenance information linking
back to the source datasets. Fine-tuning vision-language models like
Qwen2.5-VL-7B on TABLET improves performance on seen and unseen VTU tasks while
increasing robustness on real-world table visualizations. By preserving
original visualizations and maintaining example traceability in a unified
large-scale collection, TABLET establishes a foundation for robust training and
extensible evaluation of future VTU models.

</details>


### [69] [CARINOX: Inference-time Scaling with Category-Aware Reward-based Initial Noise Optimization and Exploration](https://arxiv.org/abs/2509.17458)
*Seyed Amir Kasaei,Ali Aghayari,Arash Marioriyad,Niki Sepasian,Shayan Baghayi Nejad,MohammadAmin Fazli,Mahdieh Soleymani Baghshah,Mohammad Hossein Rohban*

Main category: cs.CV

TL;DR: CARINOX是一个结合了噪声优化和探索的统一框架，通过基于类别感知的奖励选择程序，提高了文本到图像生成模型在组合对齐方面的表现，并优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像扩散模型（如Stable Diffusion）在生成高质量和多样化图像方面表现出色，但在实现组合对齐方面存在不足，尤其是在处理复杂对象关系、属性或空间排列时。现有的推理时方法虽然有前景，但单独使用时存在局限性，例如优化可能因糟糕的初始化或不利的搜索轨迹而停滞，而探索则可能需要大量的样本才能找到满意的输出。此外，单一的奖励指标或临时的组合并不能可靠地捕捉到组合性的所有方面，导致指导效果较弱或不一致。

Method: CARINOX框架结合了噪声优化和探索，并引入了一个基于与人类判断相关性的原则性奖励选择程序。通过这种方式，该框架旨在克服现有方法在组合对齐方面的挑战。

Result: 在两个互补的基准测试（T2I-CompBench++和HRS）上进行的评估显示，CARINOX将平均对齐分数分别提高了+16%和+11%。该方法在所有主要类别上持续优于最先进的基于优化和基于探索的方法，同时保持了图像质量和多样性。

Conclusion: CARINOX通过结合优化和探索，并采用类别感知的奖励选择程序，成功地提高了文本到图像扩散模型在组合对齐方面的能力，并优于现有方法，同时保持了图像质量和多样性。

Abstract: Text-to-image diffusion models, such as Stable Diffusion, can produce
high-quality and diverse images but often fail to achieve compositional
alignment, particularly when prompts describe complex object relationships,
attributes, or spatial arrangements. Recent inference-time approaches address
this by optimizing or exploring the initial noise under the guidance of reward
functions that score text-image alignment without requiring model fine-tuning.
While promising, each strategy has intrinsic limitations when used alone:
optimization can stall due to poor initialization or unfavorable search
trajectories, whereas exploration may require a prohibitively large number of
samples to locate a satisfactory output. Our analysis further shows that
neither single reward metrics nor ad-hoc combinations reliably capture all
aspects of compositionality, leading to weak or inconsistent guidance. To
overcome these challenges, we present Category-Aware Reward-based Initial Noise
Optimization and Exploration (CARINOX), a unified framework that combines noise
optimization and exploration with a principled reward selection procedure
grounded in correlation with human judgments. Evaluations on two complementary
benchmarks covering diverse compositional challenges show that CARINOX raises
average alignment scores by +16% on T2I-CompBench++ and +11% on the HRS
benchmark, consistently outperforming state-of-the-art optimization and
exploration-based methods across all major categories, while preserving image
quality and diversity. The project page is available at
https://amirkasaei.com/carinox/{this URL}.

</details>


### [70] [Learning Conformal Explainers for Image Classifiers](https://arxiv.org/abs/2509.21209)
*Amr Alkhatib,Stephanie Lowry*

Main category: cs.CV

TL;DR: 该方法提出了一种基于一致性预测的特征归因方法，用于提高图像解释的保真度和信息效率。


<details>
  <summary>Details</summary>
Motivation: 现有的特征归因方法在稳健性和忠实反映模型推理方面存在局限性，并且通常需要访问地面真实解释进行校准。

Method: 提出了一种基于一致性预测的新方法，该方法可以识别出足以保留模型预测的显著特征子集，而无需访问地面真实解释进行校准。提出了四种一致性函数来量化解释与模型预测的一致性程度。

Result: 在六个图像数据集和五个解释器上进行的方法的经验评估表明，与竞争方法相比，FastSHAP在保真度和信息效率（由解释区域的大小衡量）方面始终表现更好。基于超像素的一致性度量比像素级度量更有效。

Conclusion: 所提出的基于一致性预测的方法能够直接控制生成解释的保真度，并且在保持模型预测方面比现有方法更有效。

Abstract: Feature attribution methods are widely used for explaining image-based
predictions, as they provide feature-level insights that can be intuitively
visualized. However, such explanations often vary in their robustness and may
fail to faithfully reflect the reasoning of the underlying black-box model. To
address these limitations, we propose a novel conformal prediction-based
approach that enables users to directly control the fidelity of the generated
explanations. The method identifies a subset of salient features that is
sufficient to preserve the model's prediction, regardless of the information
carried by the excluded features, and without demanding access to ground-truth
explanations for calibration. Four conformity functions are proposed to
quantify the extent to which explanations conform to the model's predictions.
The approach is empirically evaluated using five explainers across six image
datasets. The empirical results demonstrate that FastSHAP consistently
outperforms the competing methods in terms of both fidelity and informational
efficiency, the latter measured by the size of the explanation regions.
Furthermore, the results reveal that conformity measures based on super-pixels
are more effective than their pixel-wise counterparts.

</details>


### [71] [Sigma: Semantically Informative Pre-training for Skeleton-based Sign Language Understanding](https://arxiv.org/abs/2509.21223)
*Muxin Pu,Mei Kuan Lim,Chun Yong Chong,Chen Change Loy*

Main category: cs.CV

TL;DR: Sigma 是一个统一的、基于骨骼的美国手语理解框架，通过新颖的融合、对齐和预训练方法，在各种 SLU 任务和语言上取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 当前基于骨骼的手语理解方法存在语义基础薄弱、局部细节与全局上下文不平衡以及跨模态学习效率低下等问题。

Method: Sigma 提出了一个结合了符号感知早期融合机制、分层对齐学习策略以及对比学习、文本匹配和语言建模的统一预训练框架。

Result: Sigma 在孤立手语识别、连续手语识别和无词手语翻译任务上均取得了新的最先进成果，证明了语义信息预训练和纯骨骼数据在 SLU 中的有效性。

Conclusion: Sigma 通过其新颖的机制有效地解决了现有基于骨骼的手语理解方法的局限性，并为该领域设定了新的标准。

Abstract: Pre-training has proven effective for learning transferable features in sign
language understanding (SLU) tasks. Recently, skeleton-based methods have
gained increasing attention because they can robustly handle variations in
subjects and backgrounds without being affected by appearance or environmental
factors. Current SLU methods continue to face three key limitations: 1) weak
semantic grounding, as models often capture low-level motion patterns from
skeletal data but struggle to relate them to linguistic meaning; 2) imbalance
between local details and global context, with models either focusing too
narrowly on fine-grained cues or overlooking them for broader context; and 3)
inefficient cross-modal learning, as constructing semantically aligned
representations across modalities remains difficult. To address these, we
propose Sigma, a unified skeleton-based SLU framework featuring: 1) a
sign-aware early fusion mechanism that facilitates deep interaction between
visual and textual modalities, enriching visual features with linguistic
context; 2) a hierarchical alignment learning strategy that jointly maximises
agreements across different levels of paired features from different
modalities, effectively capturing both fine-grained details and high-level
semantic relationships; and 3) a unified pre-training framework that combines
contrastive learning, text matching and language modelling to promote semantic
consistency and generalisation. Sigma achieves new state-of-the-art results on
isolated sign language recognition, continuous sign language recognition, and
gloss-free sign language translation on multiple benchmarks spanning different
sign and spoken languages, demonstrating the impact of semantically informative
pre-training and the effectiveness of skeletal data as a stand-alone solution
for SLU.

</details>


### [72] [Evaluating the Evaluators: Metrics for Compositional Text-to-Image Generation](https://arxiv.org/abs/2509.21227)
*Seyed Amir Kasaei,Ali Aghayari,Arash Marioriyad,Niki Sepasian,MohammadAmin Fazli,Mahdieh Soleymani Baghshah,Mohammad Hossein Rohban*

Main category: cs.CV

TL;DR: 现有文本-图像生成评估指标在成分组合方面与人类判断存在偏差，在不同组合任务上的表现不一致。


<details>
  <summary>Details</summary>
Motivation: 文本-图像生成在捕捉提示中的对象、属性和关系方面仍存在挑战，而现有评估指标的有效性未经充分验证，需要研究其与人类判断的一致性。

Method: 对广泛使用的成分文本-图像评估指标进行大规模研究，分析其在不同成分挑战下的行为，并与人类判断进行比较。

Result: 没有单一指标在所有任务上都表现良好，性能因成分问题的类型而异。基于视觉问答（VQA）的指标并不总是最优，而某些基于嵌入的指标在特定情况下表现更好。仅基于图像的指标对成分评估的贡献很小。

Conclusion: 在选择评估指标时，需要仔细且透明，以确保评估的可信度，并为生成模型提供有效的奖励模型。

Abstract: Text-image generation has advanced rapidly, but assessing whether outputs
truly capture the objects, attributes, and relations described in prompts
remains a central challenge. Evaluation in this space relies heavily on
automated metrics, yet these are often adopted by convention or popularity
rather than validated against human judgment. Because evaluation and reported
progress in the field depend directly on these metrics, it is critical to
understand how well they reflect human preferences. To address this, we present
a broad study of widely used metrics for compositional text-image evaluation.
Our analysis goes beyond simple correlation, examining their behavior across
diverse compositional challenges and comparing how different metric families
align with human judgments. The results show that no single metric performs
consistently across tasks: performance varies with the type of compositional
problem. Notably, VQA-based metrics, though popular, are not uniformly
superior, while certain embedding-based metrics prove stronger in specific
cases. Image-only metrics, as expected, contribute little to compositional
evaluation, as they are designed for perceptual quality rather than alignment.
These findings underscore the importance of careful and transparent metric
selection, both for trustworthy evaluation and for their use as reward models
in generation. Project page is available at
\href{https://amirkasaei.com/eval-the-evals/}{this URL}.

</details>


### [73] [SlideMamba: Entropy-Based Adaptive Fusion of GNN and Mamba for Enhanced Representation Learning in Digital Pathology](https://arxiv.org/abs/2509.21239)
*Shakib Khan,Fariba Dambandkhameneh,Nazim Shaikh,Yao Nie,Raghavan Venugopal,Xiao Li*

Main category: cs.CV

TL;DR: 本研究提出了一种名为SlideMamba的通用深度学习框架，结合了Mamba架构和图神经网络（GNN），用于分析全切片图像（WSI），并成功预测基因融合和突变状态。


<details>
  <summary>Details</summary>
Motivation: 为了增强全切片图像（WSI）分析能力，特别是在计算病理学领域，以支持临床和生物学任务。

Method: 提出了一种结合Mamba架构（用于捕捉长程依赖）和图神经网络（GNN，用于捕捉短程空间关系）的深度学习框架，并引入了一种基于熵的置信度加权机制来实现自适应融合。

Result: SlideMamba在预测基因融合和突变状态任务中，PRAUC达到了0.751 ± 0.05，优于多种基线方法（MIL, Trans-MIL, Mamba-only, GNN-only, GAT-Mamba）。同时在ROC AUC、敏感性和特异性方面也取得了有竞争力的结果。

Conclusion: 结合Mamba和GNN的SlideMamba框架，通过熵基自适应融合策略，在计算病理学中具有处理空间分辨预测任务的潜力。

Abstract: Advances in computational pathology increasingly rely on extracting
meaningful representations from Whole Slide Images (WSIs) to support various
clinical and biological tasks. In this study, we propose a generalizable deep
learning framework that integrates the Mamba architecture with Graph Neural
Networks (GNNs) for enhanced WSI analysis. Our method is designed to capture
both local spatial relationships and long-range contextual dependencies,
offering a flexible architecture for digital pathology analysis. Mamba modules
excels in capturing long-range global dependencies, while GNNs emphasize
fine-grained short-range spatial interactions. To effectively combine these
complementary signals, we introduce an adaptive fusion strategy that uses an
entropy-based confidence weighting mechanism. This approach dynamically
balances contributions from both branches by assigning higher weight to the
branch with more confident (lower-entropy) predictions, depending on the
contextual importance of local versus global information for different
downstream tasks. We demonstrate the utility of our approach on a
representative task: predicting gene fusion and mutation status from WSIs. Our
framework, SlideMamba, achieves an area under the precision recall curve
(PRAUC) of 0.751 \pm 0.05, outperforming MIL (0.491 \pm 0.042), Trans-MIL (0.39
\pm 0.017), Mamba-only (0.664 \pm 0.063), GNN-only (0.748 \pm 0.091), and a
prior similar work GAT-Mamba (0.703 \pm 0.075). SlideMamba also achieves
competitive results across ROC AUC (0.738 \pm 0.055), sensitivity (0.662 \pm
0.083), and specificity (0.725 \pm 0.094). These results highlight the strength
of the integrated architecture, enhanced by the proposed entropy-based adaptive
fusion strategy, and suggest promising potential for application of
spatially-resolved predictive modeling tasks in computational pathology.

</details>


### [74] [Hunyuan3D-Omni: A Unified Framework for Controllable Generation of 3D Assets](https://arxiv.org/abs/2509.21245)
*Team Hunyuan3D,:,Bowen Zhang,Chunchao Guo,Haolin Liu,Hongyu Yan,Huiwen Shi,Jingwei Huang,Junlin Yu,Kunhong Li,Linus,Penghao Wang,Qingxiang Lin,Sicong Liu,Xianghui Yang,Yixuan Tang,Yunfei Zhao,Zeqiang Lai,Zhihao Liang,Zibo Zhao*

Main category: cs.CV

TL;DR: Hunyuan3D-Omni是一个统一的框架，用于精细化、可控的3D资产生成，它接受多种模态的条件信号，如点云、体素、边界框和骨骼姿态，以实现对几何、拓扑和姿态的精确控制。


<details>
  <summary>Details</summary>
Motivation: 现有的3D生成模型主要依赖图像或文本条件，缺乏精细、跨模态的控制，限制了其可控性和实际应用。

Method: Hunyuan3D-Omni通过单一的跨模态架构统一处理多种信号，并采用渐进式、难度感知的采样策略，优先选择更难的信号（如骨骼姿态），同时降低简单信号（如点云）的权重，以促进多模态融合和处理缺失输入。

Result: 实验表明，Hunyuan3D-Omni的附加控制提高了生成精度，实现了几何感知变换，并增强了生产流程的鲁棒性。

Conclusion: Hunyuan3D-Omni通过引入多模态条件控制，显著提升了3D资产生成的可控性和实用性。

Abstract: Recent advances in 3D-native generative models have accelerated asset
creation for games, film, and design. However, most methods still rely
primarily on image or text conditioning and lack fine-grained, cross-modal
controls, which limits controllability and practical adoption. To address this
gap, we present Hunyuan3D-Omni, a unified framework for fine-grained,
controllable 3D asset generation built on Hunyuan3D 2.1. In addition to images,
Hunyuan3D-Omni accepts point clouds, voxels, bounding boxes, and skeletal pose
priors as conditioning signals, enabling precise control over geometry,
topology, and pose. Instead of separate heads for each modality, our model
unifies all signals in a single cross-modal architecture. We train with a
progressive, difficulty-aware sampling strategy that selects one control
modality per example and biases sampling toward harder signals (e.g., skeletal
pose) while downweighting easier ones (e.g., point clouds), encouraging robust
multi-modal fusion and graceful handling of missing inputs. Experiments show
that these additional controls improve generation accuracy, enable
geometry-aware transformations, and increase robustness for production
workflows.

</details>


### [75] [Learning to Look: Cognitive Attention Alignment with Vision-Language Models](https://arxiv.org/abs/2509.21247)
*Ryan L. Yang,Dipkamal Bhusal,Nidhi Rastogi*

Main category: cs.CV

TL;DR: 使用基于视觉语言模型的自然语言提示生成语义注意力图，以提高CNN的可靠性和可解释性，无需手动标注。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖耗时的人工标注来引导模型注意力，限制了其可扩展性。

Method: 提出一个利用视觉语言模型自动生成语义注意力图的框架，并通过引入一个辅助损失函数来使CNN的注意力与这些语言引导的图对齐。

Result: 在ColoredMNIST和DecoyMNIST数据集上，该方法在ColoredMNIST上达到了最先进的性能，并在DecoyMNIST上与需要大量标注的方法具有竞争力，证明了其泛化能力、减少了对捷径的依赖，并使模型的注意力更能反映人类的直觉。

Conclusion: 所提出的无需手动标注的框架能够有效提高CNN的可靠性和可解释性，使其决策过程更符合人类认知。

Abstract: Convolutional Neural Networks (CNNs) frequently "cheat" by exploiting
superficial correlations, raising concerns about whether they make predictions
for the right reasons. Inspired by cognitive science, which highlights the role
of attention in robust human perception, recent methods have sought to guide
model attention using concept-based supervision and explanation regularization.
However, these techniques depend on labor-intensive, expert-provided
annotations, limiting their scalability. We propose a scalable framework that
leverages vision-language models to automatically generate semantic attention
maps using natural language prompts. By introducing an auxiliary loss that
aligns CNN attention with these language-guided maps, our approach promotes
more reliable and cognitively plausible decision-making without manual
annotation. Experiments on challenging datasets, ColoredMNIST and DecoyMNIST,
show that our method achieves state-of-the-art performance on ColorMNIST and
remains competitive with annotation-heavy baselines on DecoyMNIST,
demonstrating improved generalization, reduced shortcut reliance, and model
attention that better reflects human intuition.

</details>


### [76] [Decipher-MR: A Vision-Language Foundation Model for 3D MRI Representations](https://arxiv.org/abs/2509.21249)
*Zhijian Yang,Noel DSouza,Istvan Megyeri,Xiaojian Xu,Amin Honarmandi Shandiz,Farzin Haddadpour,Krisztian Koos,Laszlo Rusko,Emanuele Valeriano,Bharadwaj Swaninathan,Lei Wu,Parminder Bhatia,Taha Kass-Hout,Erhan Bas*

Main category: cs.CV

TL;DR: Decipher-MR是一个针对3D MRI的视觉-语言基础模型，它在包含200,000个MRI序列的大规模数据集上进行训练，并能在多种临床任务中实现高性能。


<details>
  <summary>Details</summary>
Motivation: MRI的复杂性和异质性给自动化分析带来了挑战，尤其是在可扩展和可泛化的机器学习应用方面。基础模型在MRI领域的应用因数据稀疏和解剖学焦点狭窄而受到限制。

Method: Decipher-MR通过结合自监督视觉学习和报告引导的文本监督，构建了强大的、可泛化的表示。它采用了模块化设计，可以通过调整轻量级的、特定任务的解码器来适应不同的应用，而无需对预训练编码器进行重新训练。

Result: Decipher-MR在疾病分类、人口统计学预测、解剖定位和跨模态检索等多种基准测试中，均表现出比现有基础模型和特定任务方法更优越的性能。

Conclusion: Decipher-MR为基于MRI的人工智能提供了一个可扩展且通用的基础，能够高效地促进临床和研究领域的发展。

Abstract: Magnetic Resonance Imaging (MRI) is a critical medical imaging modality in
clinical diagnosis and research, yet its complexity and heterogeneity pose
challenges for automated analysis, particularly in scalable and generalizable
machine learning applications. While foundation models have revolutionized
natural language and vision tasks, their application to MRI remains limited due
to data scarcity and narrow anatomical focus. In this work, we present
Decipher-MR, a 3D MRI-specific vision-language foundation model trained on a
large-scale dataset comprising 200,000 MRI series from over 22,000 studies
spanning diverse anatomical regions, sequences, and pathologies. Decipher-MR
integrates self-supervised vision learning with report-guided text supervision
to build robust, generalizable representations, enabling effective adaptation
across broad applications. To enable robust and diverse clinical tasks with
minimal computational overhead, Decipher-MR supports a modular design that
enables tuning of lightweight, task-specific decoders attached to a frozen
pretrained encoder. Following this setting, we evaluate Decipher-MR across
diverse benchmarks including disease classification, demographic prediction,
anatomical localization, and cross-modal retrieval, demonstrating consistent
performance gains over existing foundation models and task-specific approaches.
Our results establish Decipher-MR as a scalable and versatile foundation for
MRI-based AI, facilitating efficient development across clinical and research
domains.

</details>


### [77] [Instruction-tuned Self-Questioning Framework for Multimodal Reasoning](https://arxiv.org/abs/2509.21251)
*You-Won Jang,Yu-Jung Heo,Jaeseok Kim,Minsu Lee,Du-Seong Chang,Byoung-Tak Zhang*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The field of vision-language understanding has been actively researched in
recent years, thanks to the development of Large Language Models~(LLMs).
However, it still needs help with problems requiring multi-step reasoning, even
for very simple questions. Recent studies adopt LLMs to tackle this problem by
iteratively generating sub-questions and answers. However, there are
disadvantages such as 1) the fine-grained visual contents of images are not
available using LLMs that cannot read visual information, 2) internal
mechanisms are inaccessible and difficult to reproduce by using black-box LLMs.
To solve these problems, we propose the SQ (Self-Questioning)-InstructBLIP,
which improves inference performance by generating image-aware informative
sub-questions and sub-answers iteratively. The SQ-InstructBLIP, which consists
of a Questioner, Answerer, and Reasoner that share the same architecture.
Questioner and Answerer generate sub-questions and sub-answers to help infer
the main-question, and Reasoner performs reasoning on the main-question
considering the generated sub-question information. Our experiments show that
the proposed method SQ-InstructBLIP, which uses the generated sub-questions as
additional information when solving the VQA task, performs more accurate
reasoning than the previous works.

</details>


### [78] [Hallucination as an Upper Bound: A New Perspective on Text-to-Image Evaluation](https://arxiv.org/abs/2509.21257)
*Seyed Amir Kasaei,Mohammad Hossein Rohban*

Main category: cs.CV

TL;DR: T2I模型中存在幻觉现象，表现为模型生成的内容偏离输入提示，源于模型的先验知识或偏见。本文提出了一个包含属性、关系和对象幻觉的分类体系，为T2I模型提供了一个更全面的评估框架。


<details>
  <summary>Details</summary>
Motivation: 现有T2I模型评估主要关注提示内容的对齐，忽视了模型超出提示的生成内容，导致幻觉现象未被充分研究。

Method: 提出将T2I中的幻觉定义为由偏见驱动的偏差，并构建了一个包含属性、关系和对象幻觉的分类体系，以评估T2I模型的偏见。

Result: 该分类体系为T2I模型的幻觉评估设定了上限，并揭示了模型潜在的偏见，为更深入的评估奠定了基础。

Conclusion: T2I模型中存在幻觉现象，该现象源于模型的先验知识或偏见，而非输入。通过将幻觉定义为由偏见驱动的偏差，并提出属性、关系和对象幻觉的分类，可以更全面地评估T2I模型。

Abstract: In language and vision-language models, hallucination is broadly understood
as content generated from a model's prior knowledge or biases rather than from
the given input. While this phenomenon has been studied in those domains, it
has not been clearly framed for text-to-image (T2I) generative models. Existing
evaluations mainly focus on alignment, checking whether prompt-specified
elements appear, but overlook what the model generates beyond the prompt. We
argue for defining hallucination in T2I as bias-driven deviations and propose a
taxonomy with three categories: attribute, relation, and object hallucinations.
This framing introduces an upper bound for evaluation and surfaces hidden
biases, providing a foundation for richer assessment of T2I models.

</details>


### [79] [Every Subtlety Counts: Fine-grained Person Independence Micro-Action Recognition via Distributionally Robust Optimization](https://arxiv.org/abs/2509.21261)
*Feng-Qi Cui,Jinyang Huang,Anyang Tong,Ziyu Jia,Jie Zhang,Zhi Liu,Dan Guo,Jianwei Lu,Meng Wang*

Main category: cs.CV

TL;DR: 该研究提出了一种名为“Person Independence Universal Micro-action Recognition Framework”的新框架，通过结合分布鲁棒优化（DRO）原理来学习与人物无关的表征，以解决现有微动作识别方法在处理个体差异时泛化能力不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有微动作识别方法因个体差异导致模型泛化能力不足，难以在真实场景中稳健运行。

Method: 提出了一种包含特征层面和损失层面的即插即用框架。特征层面，通过时频对齐模块（Temporal-Frequency Alignment Module）进行归一化，其中时间分支使用Wasserstein正则化对齐来稳定动态轨迹，频率分支引入方差引导扰动来增强对频谱差异的鲁棒性，并采用一致性融合机制整合两个分支。损失层面，使用基于组不变性的正则化损失（Group-Invariant Regularized Loss）对样本进行伪分组，模拟未见过的个体分布，通过上调边界样本和正则化子集方差来提升模型泛化能力。

Result: 在大型MA-52数据集上的实验表明，该框架在准确性和鲁棒性方面均优于现有方法，并在细粒度条件下实现了稳定的泛化。

Conclusion: 所提出的框架通过整合分布鲁棒优化，有效解决了微动作识别中的个体差异问题，显著提高了模型的泛化能力和鲁棒性。

Abstract: Micro-action Recognition is vital for psychological assessment and
human-computer interaction. However, existing methods often fail in real-world
scenarios because inter-person variability causes the same action to manifest
differently, hindering robust generalization. To address this, we propose the
Person Independence Universal Micro-action Recognition Framework, which
integrates Distributionally Robust Optimization principles to learn
person-agnostic representations. Our framework contains two plug-and-play
components operating at the feature and loss levels. At the feature level, the
Temporal-Frequency Alignment Module normalizes person-specific motion
characteristics with a dual-branch design: the temporal branch applies
Wasserstein-regularized alignment to stabilize dynamic trajectories, while the
frequency branch introduces variance-guided perturbations to enhance robustness
against person-specific spectral differences. A consistency-driven fusion
mechanism integrates both branches. At the loss level, the Group-Invariant
Regularized Loss partitions samples into pseudo-groups to simulate unseen
person-specific distributions. By up-weighting boundary cases and regularizing
subgroup variance, it forces the model to generalize beyond easy or frequent
samples, thus enhancing robustness to difficult variations. Experiments on the
large-scale MA-52 dataset demonstrate that our framework outperforms existing
methods in both accuracy and robustness, achieving stable generalization under
fine-grained conditions.

</details>


### [80] [Dense Semantic Matching with VGGT Prior](https://arxiv.org/abs/2509.21263)
*Songlin Yang,Tianyi Wei,Yushi Lan,Zeqi Xiao,Anyi Rao,Xingang Pan*

Main category: cs.CV

TL;DR: 现有方法在语义匹配中存在几何歧义和最近邻规则的局限性，本文提出一种改进方法，利用VGGT并结合数据增强和循环一致性训练，提高了匹配的几何感知、可靠性和流形保持能力。


<details>
  <summary>Details</summary>
Motivation: 现有语义匹配方法在处理对称结构和忽略跨图像不可见性方面存在不足，需要更具几何意识的像素描述符和整体密集对应机制。

Method: 本文提出一种改进方法，通过重用VGGT的早期特征、微调后期特征并增加一个语义头来处理双向对应关系，并结合了循环一致性训练策略、合成数据增强和渐进式训练方法来解决数据稀缺性问题。

Result: 实验证明，本文提出的方法在几何感知、匹配可靠性和流形保持方面表现优于现有方法。

Conclusion: 本文提出的方法有效解决了现有语义匹配方法的局限性，并在多个方面取得了优于基线方法的性能。

Abstract: Semantic matching aims to establish pixel-level correspondences between
instances of the same category and represents a fundamental task in computer
vision. Existing approaches suffer from two limitations: (i) Geometric
Ambiguity: Their reliance on 2D foundation model features (e.g., Stable
Diffusion, DINO) often fails to disambiguate symmetric structures, requiring
extra fine-tuning yet lacking generalization; (ii) Nearest-Neighbor Rule: Their
pixel-wise matching ignores cross-image invisibility and neglects manifold
preservation. These challenges call for geometry-aware pixel descriptors and
holistic dense correspondence mechanisms. Inspired by recent advances in 3D
geometric foundation models, we turn to VGGT, which provides geometry-grounded
features and holistic dense matching capabilities well aligned with these
needs. However, directly transferring VGGT is challenging, as it was originally
designed for geometry matching within cross views of a single instance,
misaligned with cross-instance semantic matching, and further hindered by the
scarcity of dense semantic annotations. To address this, we propose an approach
that (i) retains VGGT's intrinsic strengths by reusing early feature stages,
fine-tuning later ones, and adding a semantic head for bidirectional
correspondences; and (ii) adapts VGGT to the semantic matching scenario under
data scarcity through cycle-consistent training strategy, synthetic data
augmentation, and progressive training recipe with aliasing artifact
mitigation. Extensive experiments demonstrate that our approach achieves
superior geometry awareness, matching reliability, and manifold preservation,
outperforming previous baselines.

</details>


### [81] [MedVSR: Medical Video Super-Resolution with Cross State-Space Propagation](https://arxiv.org/abs/2509.21265)
*Xinyu Liu,Guolei Sun,Cheng Wang,Yixuan Yuan,Ender Konukoglu*

Main category: cs.CV

TL;DR: MedVSR是一个为医学视频超分辨率设计的框架，通过CSSP和ISSR模块解决低分辨率医学视频中的对齐和伪影问题，在医学场景下显著优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 硬件限制和生理限制导致难以获取高分辨率医学视频，而低分辨率医学视频存在相机抖动、噪声、帧间突变等问题，给视频超分辨率带来挑战，现有模型易引入伪影和扭曲特征，误导医生。因此，需要一个专门针对医学视频超分辨率的框架。

Method: 提出MedVSR框架。通过交叉状态空间传播（CSSP）模块解决对齐不精确的问题，将远距离帧投影为状态空间模型内的控制矩阵，选择性地传播一致且有用的特征到邻近帧以实现有效对齐。通过内部状态空间重建（ISSR）模块，结合长距离空间特征学习和大的卷积核短距离信息聚合，增强组织结构并减少伪影。

Result: 在内窥镜和白内障手术等多种医学场景的四个数据集上进行实验，MedVSR在重建性能和效率方面显著优于现有的视频超分辨率模型。

Conclusion: MedVSR是一个为医学视频超分辨率量身定制的框架，通过CSSP和ISSR模块有效解决了医学视频超分辨率中的关键挑战，并在多项实验中证明了其优越性。

Abstract: High-resolution (HR) medical videos are vital for accurate diagnosis, yet are
hard to acquire due to hardware limitations and physiological constraints.
Clinically, the collected low-resolution (LR) medical videos present unique
challenges for video super-resolution (VSR) models, including camera shake,
noise, and abrupt frame transitions, which result in significant optical flow
errors and alignment difficulties. Additionally, tissues and organs exhibit
continuous and nuanced structures, but current VSR models are prone to
introducing artifacts and distorted features that can mislead doctors. To this
end, we propose MedVSR, a tailored framework for medical VSR. It first employs
Cross State-Space Propagation (CSSP) to address the imprecise alignment by
projecting distant frames as control matrices within state-space models,
enabling the selective propagation of consistent and informative features to
neighboring frames for effective alignment. Moreover, we design an Inner
State-Space Reconstruction (ISSR) module that enhances tissue structures and
reduces artifacts with joint long-range spatial feature learning and
large-kernel short-range information aggregation. Experiments across four
datasets in diverse medical scenarios, including endoscopy and cataract
surgeries, show that MedVSR significantly outperforms existing VSR models in
reconstruction performance and efficiency. Code released at
https://github.com/CUHK-AIM-Group/MedVSR.

</details>


### [82] [MMR1: Enhancing Multimodal Reasoning with Variance-Aware Sampling and Open Resources](https://arxiv.org/abs/2509.21268)
*Sicong Leng,Jing Wang,Jiaxi Li,Hao Zhang,Zhiqiang Hu,Boqiang Zhang,Yuming Jiang,Hang Zhang,Xin Li,Lidong Bing,Deli Zhao,Wei Lu,Yu Rong,Aixin Sun,Shijian Lu*

Main category: cs.CV

TL;DR: 该论文提出了一种名为方差感知采样（VAS）的新策略，旨在解决大型多模态推理模型在训练中遇到的数据稀疏和强化学习（RL）不稳定的问题。该方法通过优先选择具有高方差和轨迹多样性的数据来提升奖励方差，从而稳定策略优化过程。此外，研究团队发布了包含约160万个长链式思考（CoT）冷启动数据和约15,000个RL问答对的大规模数据集，以及端到端的训练代码库和一系列多模态推理模型，为社区提供了可复现的基线。实验证明了所提出方法和数据集在数学推理任务上的有效性，并通过理论分析证实了奖励方差与策略梯度幅度的关系。


<details>
  <summary>Details</summary>
Motivation: 大型多模态推理模型在发展中受限于缺乏开放、大规模、高质量的长链式思考（CoT）数据，以及强化学习（RL）后训练过程中的不稳定性。GRPO等标准RL框架在低奖励方差下容易出现梯度消失问题，阻碍优化和收敛。

Method: 提出了一种名为方差感知采样（VAS）的数据选择策略，该策略基于方差提升分数（VPS），结合了结果方差和轨迹多样性来提升奖励方差，从而稳定策略优化。同时，发布了大规模CoT冷启动数据、RL问答对、端到端训练代码库以及一系列多模态推理模型。

Result: 在数学推理基准测试中，所提出的VAS策略和发布的数据集被证明是有效的。全面的消融研究和分析深入阐述了各组成部分的贡献。理论上，研究证明了奖励方差是策略梯度幅度的下界，而VAS是实现这一保证的实用机制。

Conclusion: 该研究通过提出VAS策略和发布大规模数据集，有效解决了大型多模态推理模型的两大核心挑战：长CoT数据的缺乏和RL训练的不稳定性，为多模态推理领域的研究和应用奠定了坚实基础。

Abstract: Large multimodal reasoning models have achieved rapid progress, but their
advancement is constrained by two major limitations: the absence of open,
large-scale, high-quality long chain-of-thought (CoT) data, and the instability
of reinforcement learning (RL) algorithms in post-training. Group Relative
Policy Optimization (GRPO), the standard framework for RL fine-tuning, is prone
to gradient vanishing when reward variance is low, which weakens optimization
signals and impairs convergence. This work makes three contributions: (1) We
propose Variance-Aware Sampling (VAS), a data selection strategy guided by
Variance Promotion Score (VPS) that combines outcome variance and trajectory
diversity to promote reward variance and stabilize policy optimization. (2) We
release large-scale, carefully curated resources containing ~1.6M long CoT
cold-start data and ~15k RL QA pairs, designed to ensure quality, difficulty,
and diversity, along with a fully reproducible end-to-end training codebase.
(3) We open-source a family of multimodal reasoning models in multiple scales,
establishing standardized baselines for the community. Experiments across
mathematical reasoning benchmarks demonstrate the effectiveness of both the
curated data and the proposed VAS. Comprehensive ablation studies and analyses
provide further insight into the contributions of each component. In addition,
we theoretically establish that reward variance lower-bounds the expected
policy gradient magnitude, with VAS serving as a practical mechanism to realize
this guarantee. Our code, data, and checkpoints are available at
https://github.com/LengSicong/MMR1.

</details>


### [83] [A Sentinel-3 foundation model for ocean colour](https://arxiv.org/abs/2509.21273)
*Geoffrey Dawson,Remy Vandaele,Andrew Taylor,David Moffat,Helen Tamura-Wicks,Sarah Jackson,Rosie Lickorish,Paolo Fraccaro,Hywel Williams,Chunbo Luo,Anne Jones*

Main category: cs.CV

TL;DR: AI基础模型（FMs）通过在海量未标记数据上进行预训练，有潜力彻底改变海洋科学中的AI应用，因为这些领域标记数据稀疏且难以获取。本研究提出了一种基于Prithvi-EO Vision Transformer架构的新型基础模型，该模型经过预训练，能够重建Sentinel-3海洋和陆地彩色仪器（OLCI）的数据。我们通过在两个下游海洋地球观测任务上进行微调来评估该模型。首先，我们将其性能与目前用于量化叶绿素浓度的基线模型进行比较。其次，我们评估了该模型优化海洋初级生产力估算的遥感能力。结果表明，自训练的FMs在海洋监测方面具有实用性，尤其是在利用少量高质量标记数据和捕捉海洋颜色的详细空间模式方面，同时还能与点观测数据相匹配。我们认为，这一代新的地理空间AI模型有潜力为海洋生态系统及其在全球气候过程中的作用提供更强大、数据驱动的见解。


<details>
  <summary>Details</summary>
Motivation: 海洋科学领域标记数据稀疏且昂贵，AI基础模型（FMs）可以通过预训练在海量未标记数据上来解决这一问题，从而改变AI在海洋科学中的应用。

Method: 使用Prithvi-EO Vision Transformer架构，并针对Sentinel-3 OLCI数据进行重建任务的预训练。随后，在两个下游任务（叶绿素浓度量化和海洋初级生产力估算）上进行微调和评估。

Result: 该模型在叶绿素浓度量化和海洋初级生产力估算任务上表现良好，能够利用少量高质量标记数据，捕捉海洋颜色的详细空间模式，并与点观测数据相匹配。

Conclusion: 自训练的AI基础模型在海洋监测方面非常有用，并且有潜力为海洋生态系统及其在全球气候过程中的作用提供更强大、数据驱动的见解。

Abstract: Artificial Intelligence (AI) Foundation models (FMs), pre-trained on massive
unlabelled datasets, have the potential to drastically change AI applications
in ocean science, where labelled data are often sparse and expensive to
collect. In this work, we describe a new foundation model using the Prithvi-EO
Vision Transformer architecture which has been pre-trained to reconstruct data
from the Sentinel-3 Ocean and Land Colour Instrument (OLCI). We evaluate the
model by fine-tuning on two downstream marine earth observation tasks. We first
assess model performance compared to current baseline models used to quantify
chlorophyll concentration. We then evaluate the FMs ability to refine remote
sensing-based estimates of ocean primary production. Our results demonstrate
the utility of self-trained FMs for marine monitoring, in particular for making
use of small amounts of high quality labelled data and in capturing detailed
spatial patterns of ocean colour whilst matching point observations. We
conclude that this new generation of geospatial AI models has the potential to
provide more robust, data-driven insights into ocean ecosystems and their role
in global climate processes.

</details>


### [84] [Does FLUX Already Know How to Perform Physically Plausible Image Composition?](https://arxiv.org/abs/2509.21278)
*Shilin Lu,Zhuming Lian,Zihan Zhou,Shaocong Zhang,Chen Zhao,Adams Wai-Kin Kong*

Main category: cs.CV

TL;DR: SHINE是一个训练框架，用于将用户指定的对象无缝、高保真地插入新场景，解决了现有模型在复杂光照和高分辨率输入方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有图像合成模型在处理复杂光照（如精确的阴影、水面倒影）和多样化、高分辨率输入时存在困难。尽管现代文本到图像扩散模型（如SD3.5、FLUX）已经包含了重要的物理和分辨率先验，但缺乏一种在不进行潜在反演（可能导致对象姿态不当）或脆弱的注意力手术的情况下释放它们潜力的框架。

Method: SHINE框架引入了流形引导锚定损失，利用预训练的定制适配器（如IP-Adapter）来引导潜在表示，以实现对主体对象的忠实表示，同时保持背景的完整性。此外，还提出了降级抑制引导和自适应背景融合，以消除低质量的输出和可见的接缝。为了解决缺乏严格基准的问题，研究者们引入了ComplexCompo数据集，该数据集包含各种分辨率和具有挑战性的条件，如低光照、强光照、复杂的阴影和反光表面。

Result: 在ComplexCompo和DreamEditBench数据集上的实验表明，SHINE在标准指标（如DINOv2）和人类对齐得分（如DreamSim、ImageReward、VisionReward）方面达到了最先进的性能。

Conclusion: SHINE框架能够有效地将用户指定的对象无缝、高保真地插入新场景，并在各种具有挑战性的条件下实现了优于现有方法的性能。其引入的ComplexCompo数据集也为该领域的研究提供了新的基准。

Abstract: Image composition aims to seamlessly insert a user-specified object into a
new scene, but existing models struggle with complex lighting (e.g., accurate
shadows, water reflections) and diverse, high-resolution inputs. Modern
text-to-image diffusion models (e.g., SD3.5, FLUX) already encode essential
physical and resolution priors, yet lack a framework to unleash them without
resorting to latent inversion, which often locks object poses into contextually
inappropriate orientations, or brittle attention surgery. We propose SHINE, a
training-free framework for Seamless, High-fidelity Insertion with Neutralized
Errors. SHINE introduces manifold-steered anchor loss, leveraging pretrained
customization adapters (e.g., IP-Adapter) to guide latents for faithful subject
representation while preserving background integrity. Degradation-suppression
guidance and adaptive background blending are proposed to further eliminate
low-quality outputs and visible seams. To address the lack of rigorous
benchmarks, we introduce ComplexCompo, featuring diverse resolutions and
challenging conditions such as low lighting, strong illumination, intricate
shadows, and reflective surfaces. Experiments on ComplexCompo and
DreamEditBench show state-of-the-art performance on standard metrics (e.g.,
DINOv2) and human-aligned scores (e.g., DreamSim, ImageReward, VisionReward).
Code and benchmark will be publicly available upon publication.

</details>


### [85] [Quantized Visual Geometry Grounded Transformer](https://arxiv.org/abs/2509.21302)
*Weilun Feng,Haotong Qin,Mingqiang Wu,Chuanguang Yang,Yuqi Li,Xiangqi Li,Zhulin An,Libo Huang,Yulun Zhang,Michele Magno,Yongjun Xu*

Main category: cs.CV

TL;DR: 本文提出了QuantVGGT，一个用于视觉几何基础Transformer（VGGT）的量化框架，通过双平滑细粒度量化和噪声过滤多样性采样解决了PTQ在VGGT压缩中遇到的挑战，实现了显著的内存和速度提升，同时保持了重建精度，适用于资源受限场景。


<details>
  <summary>Details</summary>
Motivation: 解决基于学习的3D重建模型（如VGGT）因计算和内存成本高昂而难以在实际中部署的问题，特别是现有的模型压缩方法（如PTQ）在处理VGGT时面临数据独立特殊标记引起的重尾激活分布和多视图3D数据校准样本选择不稳定的挑战。

Method: 提出QuantVGGT框架，包含两个主要技术贡献：1. 双平滑细粒度量化（Dual-Smoothed Fine-Grained Quantization），结合预全局Hadamard旋转和后局部通道平滑，以稳健地减轻重尾分布和通道间方差。2. 噪声过滤多样性采样（Noise-Filtered Diverse Sampling），通过深层统计过滤异常值，并构建帧感知多样性校准簇以确保量化范围的稳定性。

Result: QuantVGGT在不同基准和比特宽度上取得了最先进的结果，相比之前的通用量化方法有显著优势。具体而言，4位QuantVGGT实现了3.7倍的内存减少和2.5倍的实际硬件推理加速，同时重建精度保持在全精度模型的98%以上。

Conclusion: QuantVGGT成功解决了VGGT量化中的关键挑战，并在实际硬件部署中展现了显著的性能提升和实用性，特别是在资源受限的环境下，为3D重建模型的实际应用提供了可行方案。

Abstract: Learning-based 3D reconstruction models, represented by Visual Geometry
Grounded Transformers (VGGTs), have made remarkable progress with the use of
large-scale transformers. Their prohibitive computational and memory costs
severely hinder real-world deployment. Post-Training Quantization (PTQ) has
become a common practice for compressing and accelerating models. However, we
empirically observe that PTQ faces unique obstacles when compressing
billion-scale VGGTs: the data-independent special tokens induce heavy-tailed
activation distributions, while the multi-view nature of 3D data makes
calibration sample selection highly unstable. This paper proposes the first
Quantization framework for VGGTs, namely QuantVGGT. This mainly relies on two
technical contributions: First, we introduce Dual-Smoothed Fine-Grained
Quantization, which integrates pre-global Hadamard rotation and post-local
channel smoothing to mitigate heavy-tailed distributions and inter-channel
variance robustly. Second, we design Noise-Filtered Diverse Sampling, which
filters outliers via deep-layer statistics and constructs frame-aware diverse
calibration clusters to ensure stable quantization ranges. Comprehensive
experiments demonstrate that QuantVGGT achieves the state-of-the-art results
across different benchmarks and bit-width, surpassing the previous
state-of-the-art generic quantization method with a great margin. We highlight
that our 4-bit QuantVGGT can deliver a 3.7$\times$ memory reduction and
2.5$\times$ acceleration in real-hardware inference, while maintaining
reconstruction accuracy above 98\% of its full-precision counterpart. This
demonstrates the vast advantages and practicality of QuantVGGT in
resource-constrained scenarios. Our code is released in
https://github.com/wlfeng0509/QuantVGGT.

</details>


### [86] [NewtonGen: Physics-Consistent and Controllable Text-to-Video Generation via Neural Newtonian Dynamics](https://arxiv.org/abs/2509.21309)
*Yu Yuan,Xijun Wang,Tharindu Wickremasinghe,Zeeshan Nadir,Bole Ma,Stanley H. Chan*

Main category: cs.CV

TL;DR: NewtonGen是一个集成数据驱动合成和可学习物理原理的框架，用于解决文本到视频生成中的物理一致性和可控性问题。


<details>
  <summary>Details</summary>
Motivation: 当前文本到视频生成模型在物理一致性和可控性方面存在瓶颈，常生成不切实际的运动，且缺乏精确的参数控制，这是因为模型仅从外观学习运动分布，而未能理解底层动力学。

Method: 提出了一种可训练的神经牛顿动力学（NND）模型，用于模拟和预测牛顿运动，将潜在的动力学约束注入视频生成过程，并通过结合数据先验和动力学指导来实现。

Result: NewtonGen能够生成物理上一致的视频，并具有精确的参数控制能力。

Conclusion: 通过结合数据先验和动力学指导，NewtonGen能够生成物理上一致且可控的视频。

Abstract: A primary bottleneck in large-scale text-to-video generation today is
physical consistency and controllability. Despite recent advances,
state-of-the-art models often produce unrealistic motions, such as objects
falling upward, or abrupt changes in velocity and direction. Moreover, these
models lack precise parameter control, struggling to generate physically
consistent dynamics under different initial conditions. We argue that this
fundamental limitation stems from current models learning motion distributions
solely from appearance, while lacking an understanding of the underlying
dynamics. In this work, we propose NewtonGen, a framework that integrates
data-driven synthesis with learnable physical principles. At its core lies
trainable Neural Newtonian Dynamics (NND), which can model and predict a
variety of Newtonian motions, thereby injecting latent dynamical constraints
into the video generation process. By jointly leveraging data priors and
dynamical guidance, NewtonGen enables physically consistent video synthesis
with precise parameter control.

</details>


### [87] [SD3.5-Flash: Distribution-Guided Distillation of Generative Flows](https://arxiv.org/abs/2509.21318)
*Hmrishav Bandyopadhyay,Rahim Entezari,Jim Scott,Reshinth Adithyan,Yi-Zhe Song,Varun Jampani*

Main category: cs.CV

TL;DR: SD3.5-Flash是一个高效的几步蒸馏框架，通过改进的分布匹配目标和创新技术（如时间步共享和拆分时间步微调），能够从计算成本高昂的流模型中蒸馏出高质量图像生成能力，并进行管道优化，最终在消费级设备上实现快速、内存高效的图像生成，优于现有几步法。


<details>
  <summary>Details</summary>
Motivation: 使高质量图像生成能够部署在计算资源有限的消费级设备上，从而 democratize（普及化）先进生成式AI的实际应用。

Method: 提出SD3.5-Flash框架，通过蒸馏计算成本高昂的流模型，并针对几步生成任务重新设计了分布匹配目标。引入了“时间步共享”和“拆分时间步微调”两项创新技术。结合文本编码器重构和专门量化等管道优化，实现了快速生成和内存高效部署。

Result: SD3.5-Flash 实现了快速生成和内存高效部署，并在大规模用户研究中证明其性能优于现有的几步法方法。

Conclusion: SD3.5-Flash 成功地将先进的生成式AI普及到从手机到台式机的各种设备上，使其能够进行实际部署。

Abstract: We present SD3.5-Flash, an efficient few-step distillation framework that
brings high-quality image generation to accessible consumer devices. Our
approach distills computationally prohibitive rectified flow models through a
reformulated distribution matching objective tailored specifically for few-step
generation. We introduce two key innovations: "timestep sharing" to reduce
gradient noise and "split-timestep fine-tuning" to improve prompt alignment.
Combined with comprehensive pipeline optimizations like text encoder
restructuring and specialized quantization, our system enables both rapid
generation and memory-efficient deployment across different hardware
configurations. This democratizes access across the full spectrum of devices,
from mobile phones to desktop computers. Through extensive evaluation including
large-scale user studies, we demonstrate that SD3.5-Flash consistently
outperforms existing few-step methods, making advanced generative AI truly
accessible for practical deployment.

</details>


### [88] [Copycats: the many lives of a publicly available medical imaging dataset](https://arxiv.org/abs/2402.06353)
*Amelia Jiménez-Sánchez,Natalia-Rozalia Avlona,Dovile Juodelyte,Théo Sourget,Caroline Vang-Larsen,Anna Rogers,Hubert Dariusz Zając,Veronika Cheplygina*

Main category: cs.CV

TL;DR: 当前社区贡献平台（CCPs）的医学影像（MI）数据集治理模式未能保证模型的准确性、鲁棒性和公平性所需的质量，需要改进数据共享、文档记录和维护。


<details>
  <summary>Details</summary>
Motivation: 提高医疗保健领域人工智能（AI）诊断算法的准确性、鲁棒性和公平性，因其依赖于训练和评估模型的数据质量。

Method: 分析了在CCPs上公开的MI数据集，评估了数据共享、文档记录和维护方面的现有实践，并与计算机视觉数据集进行了比较。

Result: 发现MI数据集存在许可证不明确、缺乏持久标识符和存储、重复数据以及元数据缺失等问题，并且不同平台之间存在差异。

Conclusion: 当前的CCPs治理模式在MI数据集的质量保证方面存在不足，需要改进数据共享、文档记录和维护的实践，以支持负责任的数据整理和AI算法在医疗保健领域的应用。

Abstract: Medical Imaging (MI) datasets are fundamental to artificial intelligence in
healthcare. The accuracy, robustness, and fairness of diagnostic algorithms
depend on the data (and its quality) used to train and evaluate the models. MI
datasets used to be proprietary, but have become increasingly available to the
public, including on community-contributed platforms (CCPs) like Kaggle or
HuggingFace. While open data is important to enhance the redistribution of
data's public value, we find that the current CCP governance model fails to
uphold the quality needed and recommended practices for sharing, documenting,
and evaluating datasets. In this paper, we conduct an analysis of publicly
available machine learning datasets on CCPs, discussing datasets' context, and
identifying limitations and gaps in the current CCP landscape. We highlight
differences between MI and computer vision datasets, particularly in the
potentially harmful downstream effects from poor adoption of recommended
dataset management practices. We compare the analyzed datasets across several
dimensions, including data sharing, data documentation, and maintenance. We
find vague licenses, lack of persistent identifiers and storage, duplicates,
and missing metadata, with differences between the platforms. Our research
contributes to efforts in responsible data curation and AI algorithms for
healthcare.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [89] [Interpreting Public Sentiment in Diplomacy Events: A Counterfactual Analysis Framework Using Large Language Models](https://arxiv.org/abs/2509.20367)
*Leyi Ouyang*

Main category: cs.CL

TL;DR: 该研究提出了一个新框架，通过修改外交事件叙述来引导公众情绪，实现了70%的成功率。


<details>
  <summary>Details</summary>
Motivation: 传统的公众情绪评估方法耗时费力且缺乏前瞻性，因此需要新的方法来量化和引导公众对外交事件的情绪。

Method: 研究人员首先训练了一个语言模型来预测公众对外交事件的反应，并构建了一个包含外交事件描述及其相关公众讨论的数据集。然后，他们基于传播理论和领域专家的合作，确定了几种文本修改的特征，以改变事件的叙述框架但不失事实。最后，他们开发了一种反事实生成算法，利用大型语言模型系统地生成原始文本的修改版本。

Result: 研究框架成功地将公众情绪从负面转向中性或正面，成功率为70%。

Conclusion: 该框架能够为外交官、政策制定者和传播专家提供数据驱动的见解，以更有效地构建外交倡议或报道相关事件，从而培养更理想的公众情绪。

Abstract: Diplomatic events consistently prompt widespread public discussion and
debate. Public sentiment plays a critical role in diplomacy, as a good
sentiment provides vital support for policy implementation, helps resolve
international issues, and shapes a nation's international image. Traditional
methods for gauging public sentiment, such as large-scale surveys or manual
content analysis of media, are typically time-consuming, labor-intensive, and
lack the capacity for forward-looking analysis. We propose a novel framework
that identifies specific modifications for diplomatic event narratives to shift
public sentiment from negative to neutral or positive. First, we train a
language model to predict public reaction towards diplomatic events. To this
end, we construct a dataset comprising descriptions of diplomatic events and
their associated public discussions. Second, guided by communication theories
and in collaboration with domain experts, we predetermined several textual
features for modification, ensuring that any alterations changed the event's
narrative framing while preserving its core facts.We develop a counterfactual
generation algorithm that employs a large language model to systematically
produce modified versions of an original text. The results show that this
framework successfully shifted public sentiment to a more favorable state with
a 70\% success rate. This framework can therefore serve as a practical tool for
diplomats, policymakers, and communication specialists, offering data-driven
insights on how to frame diplomatic initiatives or report on events to foster a
more desirable public sentiment.

</details>


### [90] [Speaker Style-Aware Phoneme Anchoring for Improved Cross-Lingual Speech Emotion Recognition](https://arxiv.org/abs/2509.20373)
*Shreya G. Upadhyay,Carlos Busso,Chi-Chun Lee*

Main category: cs.CL

TL;DR: 提出一个跨语言语音情感识别的框架，通过构建情感相关的说话人社群并利用双空间锚定来对齐不同说话人和语言的情感表达，提升了跨语言情感识别的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 跨语言语音情感识别（SER）因语音变异性和说话人表达风格的差异而面临挑战，需要一个能对齐不同说话人和语言情感外化的框架。

Method: 构建情感特定的说话人社群（通过图聚类）来捕捉共享的说话人特征，并利用说话人空间和语音空间的双空间锚定来实现跨语言情感迁移。

Result: 在MSP-Podcast（英语）和BIIC-Podcast（台湾国语）语料库上的评估显示，所提出的方法优于现有方法，并揭示了跨语言情感表征的共性。

Conclusion: 所提出的说话人风格感知语音锚定框架能够有效提升跨语言语音情感识别的性能，并对跨语言情感表征的共性提供了有价值的见解。

Abstract: Cross-lingual speech emotion recognition (SER) remains a challenging task due
to differences in phonetic variability and speaker-specific expressive styles
across languages. Effectively capturing emotion under such diverse conditions
requires a framework that can align the externalization of emotions across
different speakers and languages. To address this problem, we propose a
speaker-style aware phoneme anchoring framework that aligns emotional
expression at the phonetic and speaker levels. Our method builds
emotion-specific speaker communities via graph-based clustering to capture
shared speaker traits. Using these groups, we apply dual-space anchoring in
speaker and phonetic spaces to enable better emotion transfer across languages.
Evaluations on the MSP-Podcast (English) and BIIC-Podcast (Taiwanese Mandarin)
corpora demonstrate improved generalization over competitive baselines and
provide valuable insights into the commonalities in cross-lingual emotion
representation.

</details>


### [91] [CFD-LLMBench: A Benchmark Suite for Evaluating Large Language Models in Computational Fluid Dynamics](https://arxiv.org/abs/2509.20374)
*Nithin Somasekharan,Ling Yue,Yadi Cao,Weichao Li,Patrick Emami,Pochinapeddi Sai Bhargav,Anurag Acharya,Xingyu Xie,Shaowu Pan*

Main category: cs.CL

TL;DR: LLMs在自动化复杂物理系统的数值实验方面仍未得到充分探索，本研究提出了CFDLLMBench基准套件，包含CFDQuery、CFDCodeBench和FoamBench三个部分，用于评估LLM在CFD知识、数值和物理推理以及CFD工作流实现方面的能力，旨在推动LLM在计算科学领域的应用。


<details>
  <summary>Details</summary>
Motivation: LLMs在通用NLP任务中表现强大，但在自动化复杂物理系统的数值实验方面能力仍未被充分探索。计算流体动力学（CFD）作为计算科学的核心，是评估LLM科学能力的一个具有挑战性的测试平台。

Method: 本研究提出了CFDLLMBench基准套件，该套件包含三个互补的组成部分：CFDQuery、CFDCodeBench和FoamBench。该基准旨在全面评估LLM在三个关键能力方面的表现：研究生级别的CFD知识、CFD的数值和物理推理以及CFD工作流的上下文相关实现。

Result: CFDLLMBench基准结合了详细的任务分类和严格的评估框架，以实现可重复的结果，并量化LLM在代码可执行性、解的准确性和数值收敛行为方面的表现。

Conclusion: CFDLLMBench为开发和评估由LLM驱动的复杂物理系统数值实验自动化奠定了坚实的基础。

Abstract: Large Language Models (LLMs) have demonstrated strong performance across
general NLP tasks, but their utility in automating numerical experiments of
complex physical system -- a critical and labor-intensive component -- remains
underexplored. As the major workhorse of computational science over the past
decades, Computational Fluid Dynamics (CFD) offers a uniquely challenging
testbed for evaluating the scientific capabilities of LLMs. We introduce
CFDLLMBench, a benchmark suite comprising three complementary components --
CFDQuery, CFDCodeBench, and FoamBench -- designed to holistically evaluate LLM
performance across three key competencies: graduate-level CFD knowledge,
numerical and physical reasoning of CFD, and context-dependent implementation
of CFD workflows. Grounded in real-world CFD practices, our benchmark combines
a detailed task taxonomy with a rigorous evaluation framework to deliver
reproducible results and quantify LLM performance across code executability,
solution accuracy, and numerical convergence behavior. CFDLLMBench establishes
a solid foundation for the development and evaluation of LLM-driven automation
of numerical experiments for complex physical systems. Code and data are
available at https://github.com/NREL-Theseus/cfdllmbench/.

</details>


### [92] [Assessing Classical Machine Learning and Transformer-based Approaches for Detecting AI-Generated Research Text](https://arxiv.org/abs/2509.20375)
*Sharanya Parimanoharan,Ruwan D. Nawarathna*

Main category: cs.CL

TL;DR: 本研究比较了多种机器学习方法在区分ChatGPT生成文本与人类撰写文本方面的表现，发现DistilBERT效果最佳，集成模型未能超越单一模型。


<details>
  <summary>Details</summary>
Motivation: 为了应对大型语言模型（LLMs）模糊人机文本界限所带来的学术诚信、知识产权及错误信息传播等问题，需要可靠的AI文本检测方法来保障人类的真实性和数字通信的可信度。

Method: 研究采用了包含250对摘要的标注数据集，测试和比较了包括逻辑回归（基于词袋模型、词性、TF-IDF特征）、BERT（结合N-grams）、DistilBERT、BERT（自定义轻量级分类器）以及基于LSTM的N-gram模型等多种经典和基于Transformer的机器学习检测技术。同时，也测试了集成模型是否能超越单一模型。

Result: 结果显示，DistilBERT在区分AI生成文本方面表现最佳。逻辑回归和BERT-Custom模型提供了稳健且均衡的替代方案，而LSTM和BERT-N-gram模型效果较差。由三种最佳模型组成的最大投票集成模型未能超越单独的DistilBERT模型，这表明单一基于Transformer的表征优于模型多样性。

Conclusion: 本研究全面评估了不同AI文本检测方法的优缺点，为开发更强大的、基于更大更丰富数据集的Transformer框架奠定了基础，以应对不断进步的生成式AI模型。

Abstract: The rapid adoption of large language models (LLMs) such as ChatGPT has
blurred the line between human and AI-generated texts, raising urgent questions
about academic integrity, intellectual property, and the spread of
misinformation. Thus, reliable AI-text detection is needed for fair assessment
to safeguard human authenticity and cultivate trust in digital communication.
In this study, we investigate how well current machine learning (ML) approaches
can distinguish ChatGPT-3.5-generated texts from human-written texts employing
a labeled data set of 250 pairs of abstracts from a wide range of research
topics. We test and compare both classical (Logistic Regression armed with
classical Bag-of-Words, POS, and TF-IDF features) and transformer-based (BERT
augmented with N-grams, DistilBERT, BERT with a lightweight custom classifier,
and LSTM-based N-gram models) ML detection techniques. As we aim to assess each
model's performance in detecting AI-generated research texts, we also aim to
test whether an ensemble of these models can outperform any single detector.
Results show DistilBERT achieves the overall best performance, while Logistic
Regression and BERT-Custom offer solid, balanced alternatives; LSTM- and
BERT-N-gram approaches lag. The max voting ensemble of the three best models
fails to surpass DistilBERT itself, highlighting the primacy of a single
transformer-based representation over mere model diversity. By comprehensively
assessing the strengths and weaknesses of these AI-text detection approaches,
this work lays a foundation for more robust transformer frameworks with larger,
richer datasets to keep pace with ever-improving generative AI models.

</details>


### [93] [ConceptViz: A Visual Analytics Approach for Exploring Concepts in Large Language Models](https://arxiv.org/abs/2509.20376)
*Haoxuan Li,Zhen Wen,Qiqi Jiang,Chenxiao Li,Yuwei Wu,Yuchen Yang,Yiyao Wang,Xiuqi Huang,Minfeng Zhu,Wei Chen*

Main category: cs.CL

TL;DR: ConceptViz是一个可视化分析系统，用于探索大型语言模型（LLMs）中的概念，通过“识别=>解释=>验证”流程，使用户能够查询概念、探索概念与特征的对应关系，并通过模型行为验证来确认对应关系。该系统旨在弥合SAE特征与人类概念之间的差距，提高LLMs的可解释性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在自然语言任务中表现出色，但理解其内部知识表征仍然是一个挑战。稀疏自编码器（SAEs）虽然可以提取可解释特征，但这些特征并不直接与人类概念对齐，导致解释工作繁琐。本项目旨在解决SAE特征与人类概念之间的鸿沟。

Method: 本项目提出了ConceptViz，一个可视化分析系统，用于探索LLMs中的概念。该系统包含一个新颖的“识别=>解释=>验证”流程，使用户能够：1. 使用感兴趣的概念查询SAEs；2. 交互式地探索概念到特征的对齐；3. 通过模型行为验证来确认这些对应关系。

Result: 通过两个使用场景和一个用户研究，证明了ConceptViz的有效性。结果表明，ConceptViz通过简化LLM中有意义的概念表征的发现和验证过程，增强了可解释性研究，并最终帮助研究人员构建更准确的LLM特征心智模型。

Conclusion: ConceptViz通过提供一个结构化的流程和可视化工具，有效地弥合了SAE特征与人类可理解概念之间的差距，显著提升了LLM可解释性研究的效率和深度。

Abstract: Large language models (LLMs) have achieved remarkable performance across a
wide range of natural language tasks. Understanding how LLMs internally
represent knowledge remains a significant challenge. Despite Sparse
Autoencoders (SAEs) have emerged as a promising technique for extracting
interpretable features from LLMs, SAE features do not inherently align with
human-understandable concepts, making their interpretation cumbersome and
labor-intensive. To bridge the gap between SAE features and human concepts, we
present ConceptViz, a visual analytics system designed for exploring concepts
in LLMs. ConceptViz implements a novel dentification => Interpretation =>
Validation pipeline, enabling users to query SAEs using concepts of interest,
interactively explore concept-to-feature alignments, and validate the
correspondences through model behavior verification. We demonstrate the
effectiveness of ConceptViz through two usage scenarios and a user study. Our
results show that ConceptViz enhances interpretability research by streamlining
the discovery and validation of meaningful concept representations in LLMs,
ultimately aiding researchers in building more accurate mental models of LLM
features. Our code and user guide are publicly available at
https://github.com/Happy-Hippo209/ConceptViz.

</details>


### [94] [SKILL-RAG: Self-Knowledge Induced Learning and Filtering for Retrieval-Augmented Generation](https://arxiv.org/abs/2509.20377)
*Tomoaki Isoda*

Main category: cs.CL

TL;DR: SKILL-RAG是一种利用模型自身知识来过滤检索到的不相关信息的新方法，能够提高RAG的生成质量并减少输入文档数量。


<details>
  <summary>Details</summary>
Motivation: 检索增强生成（RAG）虽然提高了大语言模型在知识密集型任务上的表现，但检索到的不相关内容会导致模型产生幻觉。因此，识别和过滤不 সহায়检索内容是提升RAG性能的关键挑战。

Method: SKILL-RAG首先通过基于强化学习的训练框架来获取模型的“自我知识”（即模型知道什么、不知道什么），然后利用这些自我知识在句子级别上过滤不相关的检索内容，只保留有用的知识。

Result: 在Llama2-7B和Qwen3-8B模型以及多个问答基准上的实验表明，SKILL-RAG提高了生成质量，并显著减少了输入文档的数量。

Conclusion: SKILL-RAG的实验结果验证了利用模型自身知识来指导选择高质量检索内容的重要性。

Abstract: Retrieval-Augmented Generation (RAG) has significantly improved the
performance of large language models (LLMs) on knowledge-intensive tasks in
recent years. However, since retrieval systems may return irrelevant content,
incorporating such information into the model often leads to hallucinations.
Thus, identifying and filtering out unhelpful retrieved content is a key
challenge for improving RAG performance.To better integrate the internal
knowledge of the model with external knowledge from retrieval, it is essential
to understand what the model "knows" and "does not know" (which is also called
"self-knowledge"). Based on this insight, we propose SKILL-RAG (Self-Knowledge
Induced Learning and Filtering for RAG), a novel method that leverages the
model's self-knowledge to determine which retrieved documents are beneficial
for answering a given query. We design a reinforcement learning-based training
framework to explicitly elicit self-knowledge from the model and employs
sentence-level granularity to filter out irrelevant content while preserving
useful knowledge.We evaluate SKILL-RAG using Llama2-7B and Qwen3-8B on several
question answering benchmarks. Experimental results demonstrate that SKILL-RAG
not only improves generation quality but also significantly reduces the number
of input documents, validating the importance of self-knowledge in guiding the
selection of high-quality retrievals.

</details>


### [95] [Beyond Global Emotion: Fine-Grained Emotional Speech Synthesis with Dynamic Word-Level Modulation](https://arxiv.org/abs/2509.20378)
*Sirui Wang,Andong Chen,Tiejun Zhao*

Main category: cs.CL

TL;DR: Emo-FiLM是一个用于基于大型语言模型（LLM）的文本到语音（TTS）的情感建模框架，它能在单词级别上控制情感，并且在FEDD数据集上的实验表明，它在全局和细粒度任务上都优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有情感文本到语音（E-TTS）系统依赖句子级控制，无法捕捉句子内部动态情感变化。

Method: Emo-FiLM通过对齐emotion2vec的帧级特征到单词，获得单词级情感标注，并通过特征级线性调制（FiLM）层映射，实现直接调制文本嵌入的单词级情感控制。

Result: Emo-FiLM在全局和细粒度情感表达任务上均优于现有方法，证明了其在富有表现力的语音合成方面的有效性和通用性。

Conclusion: Emo-FiLM通过单词级情感控制，克服了现有E-TTS系统的局限性，提高了人机交互的自然度和可信度。

Abstract: Emotional text-to-speech (E-TTS) is central to creating natural and
trustworthy human-computer interaction. Existing systems typically rely on
sentence-level control through predefined labels, reference audio, or natural
language prompts. While effective for global emotion expression, these
approaches fail to capture dynamic shifts within a sentence. To address this
limitation, we introduce Emo-FiLM, a fine-grained emotion modeling framework
for LLM-based TTS. Emo-FiLM aligns frame-level features from emotion2vec to
words to obtain word-level emotion annotations, and maps them through a
Feature-wise Linear Modulation (FiLM) layer, enabling word-level emotion
control by directly modulating text embeddings. To support evaluation, we
construct the Fine-grained Emotion Dynamics Dataset (FEDD) with detailed
annotations of emotional transitions. Experiments show that Emo-FiLM
outperforms existing approaches on both global and fine-grained tasks,
demonstrating its effectiveness and generality for expressive speech synthesis.

</details>


### [96] [USB-Rec: An Effective Framework for Improving Conversational Recommendation Capability of Large Language Model](https://arxiv.org/abs/2509.20381)
*Jianyu Wen,Jingyun Wang,Cilin Yan,Jiayin Cai,Xiaolong Jiang,Ying Zhang*

Main category: cs.CL

TL;DR: 通过集成训练-推理框架USB-Rec，利用基于用户的模拟器，以及PO数据集和SES策略，改进了LLM在对话推荐中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的对话推荐方法主要关注如何利用LLM的总结和分析能力，而忽略了训练问题。本研究旨在解决这一问题，通过提出一个集成训练-推理框架来改进LLM在对话推荐中的模型级性能。

Method: 本研究提出了一种名为USB-Rec的集成训练-推理框架。该框架包括：1. 设计了一个基于LLM的偏好优化（PO）数据集构建策略，用于强化学习（RL）训练，帮助LLM理解对话推荐的策略和方法。2. 在推理阶段提出了一个自增强策略（SES），以进一步挖掘RL训练获得的对话推荐潜力。

Result: 通过在多个数据集上进行的大量实验表明，本研究提出的方法在对话推荐任务上持续优于先前最先进的方法。

Conclusion: USB-Rec框架通过结合PO数据集和SES策略，有效提升了LLM在对话推荐中的性能，并在多项基准测试中取得了优越的结果。

Abstract: Recently, Large Language Models (LLMs) have been widely employed in
Conversational Recommender Systems (CRSs). Unlike traditional language model
approaches that focus on training, all existing LLMs-based approaches are
mainly centered around how to leverage the summarization and analysis
capabilities of LLMs while ignoring the issue of training. Therefore, in this
work, we propose an integrated training-inference framework,
User-Simulator-Based framework (USB-Rec), for improving the performance of LLMs
in conversational recommendation at the model level. Firstly, we design a
LLM-based Preference Optimization (PO) dataset construction strategy for RL
training, which helps the LLMs understand the strategies and methods in
conversational recommendation. Secondly, we propose a Self-Enhancement Strategy
(SES) at the inference stage to further exploit the conversational
recommendation potential obtained from RL training. Extensive experiments on
various datasets demonstrate that our method consistently outperforms previous
state-of-the-art methods.

</details>


### [97] [Document Summarization with Conformal Importance Guarantees](https://arxiv.org/abs/2509.20461)
*Bruce Kuwahara,Chen-Yuan Lin,Xiao Shi Huang,Kin Kwan Leung,Jullian Arta Yapeter,Ilya Stanevich,Felipe Perez,Jesse C. Cresswell*

Main category: cs.CL

TL;DR: 本研究提出了一种名为“共形重要性摘要”的新框架，使用共形预测来保证摘要中包含关键信息，解决了现有自动摘要系统在高风险领域（如医疗、法律、金融）的不足。


<details>
  <summary>Details</summary>
Motivation: 现有自动摘要系统在大语言模型（LLMs）的推动下取得了显著进展，但在医疗、法律和金融等高风险领域，仍然缺乏对关键内容包含性的可靠保证。

Method: 本研究提出共形重要性摘要（Conformal Importance Summarization）框架，利用共形预测提供严格的、无分布的覆盖保证。通过校准句子级重要性得分的阈值，实现了具有用户指定覆盖率和关键内容召回率的抽取式文档摘要。

Result: 实验表明，共形重要性摘要在已有的摘要基准测试中，能够实现理论上保证的信息覆盖率，并且该方法是模型无关的，只需要一个小的校准数据集，并且可以与现有的黑盒LLMs无缝集成。

Conclusion: 共形重要性摘要可以与现有技术结合，实现可靠、可控的自动摘要，为在关键应用中更安全地部署AI摘要工具铺平了道路。

Abstract: Automatic summarization systems have advanced rapidly with large language
models (LLMs), yet they still lack reliable guarantees on inclusion of critical
content in high-stakes domains like healthcare, law, and finance. In this work,
we introduce Conformal Importance Summarization, the first framework for
importance-preserving summary generation which uses conformal prediction to
provide rigorous, distribution-free coverage guarantees. By calibrating
thresholds on sentence-level importance scores, we enable extractive document
summarization with user-specified coverage and recall rates over critical
content. Our method is model-agnostic, requires only a small calibration set,
and seamlessly integrates with existing black-box LLMs. Experiments on
established summarization benchmarks demonstrate that Conformal Importance
Summarization achieves the theoretically assured information coverage rate. Our
work suggests that Conformal Importance Summarization can be combined with
existing techniques to achieve reliable, controllable automatic summarization,
paving the way for safer deployment of AI summarization tools in critical
applications. Code is available at
https://github.com/layer6ai-labs/conformal-importance-summarization.

</details>


### [98] [ShortCheck: Checkworthiness Detection of Multilingual Short-Form Videos](https://arxiv.org/abs/2509.20467)
*Henrik Vatndal,Vinay Setty*

Main category: cs.CL

TL;DR: ShortCheck是一个自动识别可核查短视频的系统，以协助人工事实核查员。


<details>
  <summary>Details</summary>
Motivation: 短视频平台（如TikTok）因其多模态、动态和嘈杂的内容，对错误信息检测提出了独特的挑战。

Method: ShortCheck是一个模块化、仅推理的流水线，集成了语音转录、OCR、对象和深度伪造检测、视频到文本摘要以及声明验证，并提供用户友好的界面。

Result: 在两个手动注释的数据集上，以多语言环境对TikTok视频进行评估，取得了超过70%的F1加权分数。

Conclusion: ShortCheck在识别可核查短视频方面取得了有希望的结果，可以帮助事实核查员更有效地工作。

Abstract: Short-form video platforms like TikTok present unique challenges for
misinformation detection due to their multimodal, dynamic, and noisy content.
We present ShortCheck, a modular, inference-only pipeline with a user-friendly
interface that automatically identifies checkworthy short-form videos to help
human fact-checkers. The system integrates speech transcription, OCR, object
and deepfake detection, video-to-text summarization, and claim verification.
ShortCheck is validated by evaluating it on two manually annotated datasets
with TikTok videos in a multilingual setting. The pipeline achieves promising
results with F1-weighted score over 70\%.

</details>


### [99] [MARS: toward more efficient multi-agent collaboration for LLM reasoning](https://arxiv.org/abs/2509.20502)
*Xiao Wang,Jia Wang,Yijie Wang,Pengtao Dang,Sha Cao,Chi Zhang*

Main category: cs.CL

TL;DR: MARS通过模仿评审流程，使用作者、评审者和元评审者等角色来解决多智能体辩论（MAD）的计算开销问题，在保持准确性的同时，将代币使用和推理时间减少了约50%。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体辩论（MAD）方法虽然能提升大型语言模型（LLMs）的推理能力，但计算开销大，需要频繁通信。

Method: 提出MARS（Multi-Agent Review System）框架，模仿评审流程，包含作者、评审者和元评审者三个角色，评审者独立提供意见，元评审者整合反馈并指导修改，避免了昂贵的评审者之间交互。

Result: MARS在多个基准测试中，与MAD和其他最先进的推理策略相比，准确性相当，但代币消耗和推理时间减少了约50%。

Conclusion: MARS在不牺牲准确性的前提下，有效降低了LLMs进行协作推理的成本。

Abstract: Large language models (LLMs) have achieved impressive results in natural
language understanding, yet their reasoning capabilities remain limited when
operating as single agents. Multi-Agent Debate (MAD) has been proposed to
address this limitation by enabling collaborative reasoning among multiple
models in a round-table debate manner. While effective, MAD introduces
substantial computational overhead due to the number of agents involved and the
frequent communication required. In this paper, we propose MARS (Multi-Agent
Review System), a role-based collaboration framework inspired by the review
process. In MARS, an author agent generates an initial solution, reviewer
agents provide decisions and comments independently, and a meta-reviewer
integrates the feedback to make the final decision and guide further revision.
This design enhances reasoning quality while avoiding costly
reviewer-to-reviewer interactions, thereby controlling token consumption and
inference time. We compared MARS with both MAD and other state-of-the-art
reasoning strategies across multiple benchmarks. Extensive experiments with
different LLMs show that MARS matches the accuracy of MAD while reducing both
token usage and inference time by approximately 50\%. Code is available at
https://github.com/xwang97/MARS.

</details>


### [100] [SiniticMTError: A Machine Translation Dataset with Error Annotations for Sinitic Languages](https://arxiv.org/abs/2509.20557)
*Hannah Liu,Junghyun Min,Ethan Yue Heng Cheung,Shou-Yi Hung,Syed Mekael Wasti,Runtong Liang,Shiyao Qian,Shizhao Zheng,Elsie Chan,Ka Ieng Charlotte Lo,Wing Yu Yip,Richard Tzong-Han Tsai,En-Shiun Annie Lee*

Main category: cs.CL

TL;DR: Despite advances in MT, low-resource languages like Cantonese and Wu Chinese lag due to data scarcity. This paper introduces SiniticMTError, a novel dataset with error annotations for English to Mandarin, Cantonese, and Wu Chinese, to aid in MT error detection, quality estimation, and low-resource evaluation. The paper details the annotation process, inter-annotator agreement, and error patterns.


<details>
  <summary>Details</summary>
Motivation: Machine translation (MT) progress is limited for low-resource languages like Cantonese and Wu Chinese due to insufficient training data and linguistic resources, despite their large speaker populations.

Method: The paper introduces SiniticMTError, a novel dataset that builds on existing parallel corpora. It provides error span, error type, and error severity annotations for machine-translated examples from English to Mandarin, Cantonese, and Wu Chinese. The annotation process involved native speakers and included analyses of inter-annotator agreement, iterative feedback, and error patterns.

Result: The SiniticMTError dataset is presented as a resource for the MT community to fine-tune models with error detection capabilities. This supports research in translation quality estimation, error-aware generation, and low-resource language evaluation. Analyses of the annotation process, including inter-annotator agreement and error patterns, are reported.

Conclusion: The SiniticMTError dataset provides valuable annotations for improving MT for low-resource Sinitic languages, addressing the limitations of current MT systems and supporting further research in MT quality and error analysis.

Abstract: Despite major advances in machine translation (MT) in recent years, progress
remains limited for many low-resource languages that lack large-scale training
data and linguistic resources. Cantonese and Wu Chinese are two Sinitic
examples, although each enjoys more than 80 million speakers around the world.
In this paper, we introduce SiniticMTError, a novel dataset that builds on
existing parallel corpora to provide error span, error type, and error severity
annotations in machine-translated examples from English to Mandarin, Cantonese,
and Wu Chinese. Our dataset serves as a resource for the MT community to
utilize in fine-tuning models with error detection capabilities, supporting
research on translation quality estimation, error-aware generation, and
low-resource language evaluation. We report our rigorous annotation process by
native speakers, with analyses on inter-annotator agreement, iterative
feedback, and patterns in error type and severity.

</details>


### [101] [SwasthLLM: a Unified Cross-Lingual, Multi-Task, and Meta-Learning Zero-Shot Framework for Medical Diagnosis Using Contrastive Representations](https://arxiv.org/abs/2509.20567)
*Ayan Sar,Pranav Singh Puri,Sumit Aich,Tanupriya Choudhury,Abhijit Kumar*

Main category: cs.CL

TL;DR: SwasthLLM是一个统一的、零样本、跨语言、多任务学习框架，用于在英语、印地语和孟加拉语中进行医疗诊断，无需特定语言的微调。


<details>
  <summary>Details</summary>
Motivation: 在少样本语言的带注释医疗数据稀缺和不同人群的语言可变性导致多语言医疗环境中自动从临床文本进行疾病诊断具有挑战性。

Method: SwasthLLM利用多语言XLM-RoBERTa编码器，并结合了语言感知注意机制和疾病分类头。它还包括一个暹罗对比学习模块、一个翻译一致性模块和一个对比投影头，以实现跨语言的语义对齐和语言不变的表示学习。该模型采用多任务学习策略进行训练，并结合模型无关元学习（MAML）以适应新语言或任务。

Result: SwasthLLM在监督设置下达到了97.22%的测试准确率和97.17%的F1分数。在零样本场景下，它在印地语医疗文本上达到了92.78%的准确率，在孟加拉语医疗文本上达到了73.33%的准确率。

Conclusion: SwasthLLM在少样本医疗文本诊断方面表现出强大的泛化能力，并且能够有效应对跨语言和多任务学习的挑战。

Abstract: In multilingual healthcare environments, automatic disease diagnosis from
clinical text remains a challenging task due to the scarcity of annotated
medical data in low-resource languages and the linguistic variability across
populations. This paper proposes SwasthLLM, a unified, zero-shot,
cross-lingual, and multi-task learning framework for medical diagnosis that
operates effectively across English, Hindi, and Bengali without requiring
language-specific fine-tuning. At its core, SwasthLLM leverages the
multilingual XLM-RoBERTa encoder augmented with a language-aware attention
mechanism and a disease classification head, enabling the model to extract
medically relevant information regardless of the language structure. To align
semantic representations across languages, a Siamese contrastive learning
module is introduced, ensuring that equivalent medical texts in different
languages produce similar embeddings. Further, a translation consistency module
and a contrastive projection head reinforce language-invariant representation
learning. SwasthLLM is trained using a multi-task learning strategy, jointly
optimizing disease classification, translation alignment, and contrastive
learning objectives. Additionally, we employ Model-Agnostic Meta-Learning
(MAML) to equip the model with rapid adaptation capabilities for unseen
languages or tasks with minimal data. Our phased training pipeline emphasizes
robust representation alignment before task-specific fine-tuning. Extensive
evaluation shows that SwasthLLM achieves high diagnostic performance, with a
test accuracy of 97.22% and an F1-score of 97.17% in supervised settings.
Crucially, in zero-shot scenarios, it attains 92.78% accuracy on Hindi and
73.33% accuracy on Bengali medical text, demonstrating strong generalization in
low-resource contexts.

</details>


### [102] [Dynamic Reasoning Chains through Depth-Specialized Mixture-of-Experts in Transformer Architectures](https://arxiv.org/abs/2509.20577)
*Sampurna Roy,Ayan Sar,Anurag Kaushish,Kanav Gupta,Tanupriya Choudhury,Abhijit Kumar*

Main category: cs.CL

TL;DR: DS-MoE通过引入专家模块优化不同推理深度，并使用学习到的路由网络动态组装定制推理链，实现了计算节省、推理加速和准确性提升，同时增强了可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有Transformer模型对所有输入应用相同的处理深度，存在效率低下和推理质量受限的问题，复杂逻辑问题和简单事实查询被赋予相同的计算量，浪费资源并限制了深度推理。

Method: 提出了一种名为动态推理链（DS-MoE）的深度专业化混合专家模型，该模型将混合专家范式从基于宽度的计算扩展到基于深度的专业化计算。DS-MoE引入了针对不同推理深度（如浅层模式识别、组合推理、逻辑推理、记忆整合和元认知监督）进行优化的专家模块。通过学习到的路由网络动态地组装定制的推理链，仅激活必要的专家来匹配输入复杂性。模型在包含科学论文、法律文本、编程代码和网络内容等多样化领域的800GB语料库“The Pile”上进行训练和评估。

Result: DS-MoE实现了高达16%的计算节省和35%的推理速度提升，同时在复杂的多步推理基准测试中准确率提高了2.8%。此外，路由决策产生了可解释的推理链，提高了透明度和可扩展性。

Conclusion: DS-MoE是自适应神经架构的重大进步，证明了深度专业化模块化处理可以在大规模语言模型中同时提高效率、推理质量和可解释性。

Abstract: Contemporary transformer architectures apply identical processing depth to
all inputs, creating inefficiencies and limiting reasoning quality. Simple
factual queries are subjected to the same multilayered computation as complex
logical problems, wasting resources while constraining deep inference. To
overcome this, we came up with a concept of Dynamic Reasoning Chains through
Depth Specialised Mixture of Experts (DS-MoE), a modular framework that extends
the Mixture of Experts paradigm from width-based to depth specialised
computation. DS-MoE introduces expert modules optimised for distinct reasoning
depths, shallow pattern recognition, compositional reasoning, logical
inference, memory integration, and meta-cognitive supervision. A learned
routing network dynamically assembles custom reasoning chains, activating only
the necessary experts to match input complexity. The dataset on which we
trained and evaluated DS-MoE is on The Pile, an 800GB corpus covering diverse
domains such as scientific papers, legal texts, programming code, and web
content, enabling systematic assessment across reasoning depths. Experimental
results demonstrate that DS-MoE achieves up to 16 per cent computational
savings and 35 per cent faster inference compared to uniform-depth
transformers, while delivering 2.8 per cent higher accuracy on complex
multi-step reasoning benchmarks. Furthermore, routing decisions yield
interpretable reasoning chains, enhancing transparency and scalability. These
findings establish DS-MoE as a significant advancement in adaptive neural
architectures, demonstrating that depth-specialised modular processing can
simultaneously improve efficiency, reasoning quality, and interpretability in
large-scale language models.

</details>


### [103] [Hierarchical Resolution Transformers: A Wavelet-Inspired Architecture for Multi-Scale Language Understanding](https://arxiv.org/abs/2509.20581)
*Ayan Sar,Sampurna Roy,Kanav Gupta,Anurag Kaushish,Tanupriya Choudhury,Abhijit Kumar*

Main category: cs.CL

TL;DR: HRT是一种新颖的、受小波启发的神经网络架构，它能够同时处理文本的多个分辨率，从而在计算效率和语言理解方面取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: Transformer架构在处理自然语言任务时存在二次计算成本、泛化能力弱以及篇章建模不足等问题，因为它将文本视为扁平的标记序列，而未能捕捉到人类语言的固有层级结构。

Method: HRT通过构建一种多分辨率注意力机制，实现了从字符到篇章单元的多尺度语言处理，能够进行自下而上的组合和自上而下的情境化。利用跨尺度指数级序列缩减技术，HRT实现了O(nlogn)的计算复杂度。

Result: 在GLUE、SuperGLUE、Long Range Arena和WikiText-103等基准测试中，HRT的表现优于标准Transformer模型，平均准确率分别提高了+3.8%、+4.5%和+6.1%。此外，与参数量相似的BERT和GPT模型相比，HRT的内存占用减少了42%，推理延迟降低了37%。消融实验也证实了跨分辨率注意力和专用模块的有效性。

Conclusion: HRT是第一个在计算结构上与人类语言层级组织相匹配的架构，证明了多尺度、受小波启发的处理方式能够在理论效率和实际语言理解能力上都带来提升。

Abstract: Transformer architectures have achieved state-of-the-art performance across
natural language tasks, yet they fundamentally misrepresent the hierarchical
nature of human language by processing text as flat token sequences. This
results in quadratic computational cost, weak computational cost, weak
compositional generalization, and inadequate discourse-level modeling. We
propose Hierarchical Resolution Transformer (HRT), a novel wavelet-inspired
neural architecture that processes language simultaneously across multiple
resolutions, from characters to discourse-level units. HRT constructs a
multi-resolution attention, enabling bottom-up composition and top-down
contextualization. By employing exponential sequence reduction across scales,
HRT achieves O(nlogn) complexity, offering significant efficiency improvements
over standard transformers. We evaluated HRT on a diverse suite of benchmarks,
including GLUE, SuperGLUE, Long Range Arena, and WikiText-103, and results
demonstrated that HRT outperforms standard transformer baselines by an average
of +3.8% on GLUE, +4.5% on SuperGLUE, and +6.1% on Long Range Arena, while
reducing memory usage by 42% and inference latency by 37% compared to BERT and
GPT style models of similar parameter count. Ablation studies confirm the
effectiveness of cross-resolution attention and scale-specialized modules,
showing that each contributes independently to both efficiency and accuracy.
Our findings establish HRT as the first architecture to align computational
structure with the hierarchical organization of human language, demonstrating
that multi-scale, wavelet-inspired processing yields both theoretical
efficiency gains and practical improvements in language understanding.

</details>


### [104] [FS-DFM: Fast and Accurate Long Text Generation with Few-Step Diffusion Language Models](https://arxiv.org/abs/2509.20624)
*Amin Karimi Monsefi,Nikhil Bhendawade,Manuel Rafael Ciosici,Dominic Culver,Yizhe Zhang,Irina Belousova*

Main category: cs.CL

TL;DR: FS-DFM通过显式地将采样步数设为参数，并训练模型使其在不同的步数预算下保持一致，从而在保证生成质量的同时，大幅提升了文本生成的效率，实现了比传统离散扩散模型快128倍的采样速度。


<details>
  <summary>Details</summary>
Motivation: 现有的自回归语言模型（ARMs）生成效率低，而标准的离散扩散模型（DLMs）虽然可以并行处理，但需要大量的模型评估才能达到高质量的生成效果。FS-DFM旨在解决这一问题，实现快速且高质量的文本生成。

Method: FS-DFM是一种离散流匹配模型，其核心思想是将采样步数作为显式参数进行训练，使模型在不同的步数预算下都能保持一致性，并采用了一个可靠的更新规则，能够准确地移动概率分布而不会出现超调，同时结合了从长序列轨迹中蒸馏出的强教师指导。

Result: 在语言模型基准测试中，FS-DFM在仅使用8个采样步数的情况下，达到了与使用1024个采样步数的离散流基线模型相当的困惑度（perplexity），并且在生成1024个token时，使用了相似规模的模型，采样速度提升了高达128倍，相应地提高了延迟和吞吐量。

Conclusion: FS-DFM通过创新的方法，在文本生成速度和质量之间取得了良好的平衡，为需要高效文本生成的应用场景提供了有前景的解决方案。

Abstract: Autoregressive language models (ARMs) deliver strong likelihoods, but are
inherently serial: they generate one token per forward pass, which limits
throughput and inflates latency for long sequences. Diffusion Language Models
(DLMs) parallelize across positions and thus appear promising for language
generation, yet standard discrete diffusion typically needs hundreds to
thousands of model evaluations to reach high quality, trading serial depth for
iterative breadth. We introduce FS-DFM, Few-Step Discrete Flow-Matching. A
discrete flow-matching model designed for speed without sacrificing quality.
The core idea is simple: make the number of sampling steps an explicit
parameter and train the model to be consistent across step budgets, so one big
move lands where many small moves would. We pair this with a reliable update
rule that moves probability in the right direction without overshooting, and
with strong teacher guidance distilled from long-run trajectories. Together,
these choices make few-step sampling stable, accurate, and easy to control. On
language modeling benchmarks, FS-DFM with 8 sampling steps achieves perplexity
parity with a 1,024-step discrete-flow baseline for generating 1,024 tokens
using a similar-size model, delivering up to 128 times faster sampling and
corresponding latency/throughput gains.

</details>


### [105] [Look Before you Leap: Estimating LLM Benchmark Scores from Descriptions](https://arxiv.org/abs/2509.20645)
*Jungsoo Park,Ethan Mendes,Gabriel Stanovsky,Alan Ritter*

Main category: cs.CL

TL;DR: LLM评估存在瓶颈，可以通过预测模型在未见过的数据上的表现来缓解。本文提出了PRECOG数据集，并证明了在不访问数据集实例的情况下，对模型性能进行预测是可行的，但具有挑战性。


<details>
  <summary>Details</summary>
Motivation: LLM的进展受限于评估瓶颈，需要手动构建基准、评估模型并迭代。本文旨在探索在不运行任何实验的情况下预测模型性能的可能性，以克服这一瓶颈。

Method: 构建了一个名为PRECOG的语料库，包含经过处理的任务描述和对应的性能指标。利用该语料库，训练能够根据任务描述和模型配置预测模型性能的模型，并引入了包含检索模块的模型来提升预测能力。对不同模型（包括GPT-5）在不同设置下的预测能力进行了评估。

Result: 在PRECOG数据集上，即使排除了原始论文信息，基于任务描述和模型配置的性能预测也达到了中等水平的预测精度，在特定阈值下平均绝对误差低至8.7。研究发现，更强的推理模型会进行多样化的迭代查询，而现有的开源模型则在这方面表现不足。即使在零泄露的设置下（预测尚未被索引的新发布的数据集或实验），GPT-5仍然取得了显著的预测准确性。

Conclusion: 本文的研究表明，在不访问数据集实例的情况下，对LLM的性能进行预测是可行的，并提出了PRECOG数据集和相关分析。这项工作为开放式的预测性评估奠定了基础，有助于评估任务难度和优化实验的优先级。

Abstract: Progress in large language models is constrained by an evaluation bottleneck:
build a benchmark, evaluate models and settings, then iterate. We therefore ask
a simple question: can we forecast outcomes before running any experiments? We
study text-only performance forecasting: estimating a model's score from a
redacted task description and intended configuration, with no access to dataset
instances. To support systematic study, we curate PRECOG, a corpus of redacted
description-performance pairs spanning diverse tasks, domains, and metrics.
Experiments show the task is challenging but feasible: models equipped with a
retrieval module that excludes source papers achieve moderate prediction
performance with well-calibrated uncertainty, reaching mean absolute error as
low as 8.7 on the Accuracy subset at high-confidence thresholds. Our analysis
indicates that stronger reasoning models engage in diverse, iterative querying,
whereas current open-source models lag and often skip retrieval or gather
evidence with limited diversity. We further test a zero-leakage setting,
forecasting on newly released datasets or experiments before their papers are
indexed, where GPT-5 with built-in web search still attains nontrivial
prediction accuracy. Overall, our corpus and analyses offer an initial step
toward open-ended anticipatory evaluation, supporting difficulty estimation and
smarter experiment prioritization.

</details>


### [106] [Building Tailored Speech Recognizers for Japanese Speaking Assessment](https://arxiv.org/abs/2509.20655)
*Yotaro Kubo,Richard Sproat,Chihiro Taguchi,Llion Jones*

Main category: cs.CL

TL;DR: 本文提出了一种为日语口语评估任务构建语音识别器的方法，通过多任务学习和模型融合来缓解数据稀疏问题，将平均词标错误率从12.3%降低到7.1%。


<details>
  <summary>Details</summary>
Motivation: 由于日语口语评估任务缺乏包含音素和重音标记的标注数据，需要开发能够处理数据稀疏问题的语音识别方法。

Method: 提出两种方法：1. 多任务学习，引入辅助损失函数来估计音标文本和音高模式，利用只有音标标注的语音进行训练。2. 融合模型，结合音素字母串和文本序列的估计器，并基于有限状态转换器框架开发了融合算法。

Result: 通过多任务学习和模型融合，成功构建了一个准确的音素识别器，平均词标错误率从12.3%显著降低到7.1%，优于通用多语言识别器。

Conclusion: 所提出的多任务学习和模型融合方法对于构建准确的日语口语评估语音识别器是有效的，并且在处理数据稀疏性方面具有优势。

Abstract: This paper presents methods for building speech recognizers tailored for
Japanese speaking assessment tasks. Specifically, we build a speech recognizer
that outputs phonemic labels with accent markers. Although Japanese is
resource-rich, there is only a small amount of data for training models to
produce accurate phonemic transcriptions that include accent marks. We propose
two methods to mitigate data sparsity. First, a multitask training scheme
introduces auxiliary loss functions to estimate orthographic text labels and
pitch patterns of the input signal, so that utterances with only orthographic
annotations can be leveraged in training. The second fuses two estimators, one
over phonetic alphabet strings, and the other over text token sequences. To
combine these estimates we develop an algorithm based on the finite-state
transducer framework. Our results indicate that the use of multitask learning
and fusion is effective for building an accurate phonemic recognizer. We show
that this approach is advantageous compared to the use of generic multilingual
recognizers. The relative advantages of the proposed methods were also
compared. Our proposed methods reduced the average of mora-label error rates
from 12.3% to 7.1% over the CSJ core evaluation sets.

</details>


### [107] [Enhancing Molecular Property Prediction with Knowledge from Large Language Models](https://arxiv.org/abs/2509.20664)
*Peng Zhou,Lai Hou Tim,Zhixiang Cheng,Kun Xie,Chaoyi Li,Wei Liu,Xiangxiang Zeng*

Main category: cs.CL

TL;DR: 通过结合大型语言模型（LLM）提取的知识和预训练分子模型的结构特征，来改进分子属性预测（MPP）。


<details>
  <summary>Details</summary>
Motivation: 尽管图神经网络（GNNs）和自监督学习在分子属性预测（MPP）方面取得了进展，但整合人类先验知识仍然至关重要，特别是当模型存在知识空白和幻觉时。大型语言模型（LLMs）虽然能够提取知识，但也存在这些局限性，尤其是在研究较少的分子属性方面。

Method: 提出了一种新颖的框架，该框架首次将从LLMs提取的知识与从预训练分子模型派生的结构特征相结合，以增强MPP。该方法提示LLMs生成领域相关知识和可执行代码以进行分子向量化，产生基于知识的特征，然后将这些特征与结构表示融合。实验中使用了三种先进的LLMs：GPT-4o、GPT-4.1和DeepSeek-R1。

Result: 通过对三种先进LLMs（GPT-4o、GPT-4.1和DeepSeek-R1）进行知识提取，并将提取的知识特征与结构特征融合，在广泛的实验中，证明了所提出的集成方法优于现有方法。

Conclusion: LLM提取的知识与结构信息的结合为MPP提供了一个强大而有效的解决方案，克服了单独使用LLM的局限性。

Abstract: Predicting molecular properties is a critical component of drug discovery.
Recent advances in deep learning, particularly Graph Neural Networks (GNNs),
have enabled end-to-end learning from molecular structures, reducing reliance
on manual feature engineering. However, while GNNs and self-supervised learning
approaches have advanced molecular property prediction (MPP), the integration
of human prior knowledge remains indispensable, as evidenced by recent methods
that leverage large language models (LLMs) for knowledge extraction. Despite
their strengths, LLMs are constrained by knowledge gaps and hallucinations,
particularly for less-studied molecular properties. In this work, we propose a
novel framework that, for the first time, integrates knowledge extracted from
LLMs with structural features derived from pre-trained molecular models to
enhance MPP. Our approach prompts LLMs to generate both domain-relevant
knowledge and executable code for molecular vectorization, producing
knowledge-based features that are subsequently fused with structural
representations. We employ three state-of-the-art LLMs, GPT-4o, GPT-4.1, and
DeepSeek-R1, for knowledge extraction. Extensive experiments demonstrate that
our integrated method outperforms existing approaches, confirming that the
combination of LLM-derived knowledge and structural information provides a
robust and effective solution for MPP.

</details>


### [108] [RedHerring Attack: Testing the Reliability of Attack Detection](https://arxiv.org/abs/2509.20691)
*Jonathan Rusert*

Main category: cs.CL

TL;DR: RedHerring攻击通过制造分类器和检测器之间的冲突来降低攻击检测模型的可靠性，同时保持分类器准确性，并提出了一种基于置信度检查的防御方法。


<details>
  <summary>Details</summary>
Motivation: 现有攻击检测模型虽然能识别被篡改的文本，但其可靠性未经充分检验。需要新的攻击方式来探测和评估这些模型的鲁棒性。

Method: 提出并测试了一种名为RedHerring的新型攻击方式。该攻击旨在让攻击检测模型错误地预测文本被攻击，但同时保持NLP分类器正确判断文本类别。通过在4个数据集上针对3种检测器和4种分类器进行测试。

Result: RedHerring攻击能够显著降低检测准确率（20-71个百分点），同时保持甚至提高分类器的准确性。实验还表明，一种简单的置信度检查方法能在不重新训练模型的情况下，有效提升检测准确率。

Conclusion: RedHerring攻击模型揭示了攻击者可能如何针对检测模型的新途径，并强调了评估和增强攻击检测模型可靠性的重要性。提出的置信度检查为防御此类攻击提供了一个初步且有效的解决方案。

Abstract: In response to adversarial text attacks, attack detection models have been
proposed and shown to successfully identify text modified by adversaries.
Attack detection models can be leveraged to provide an additional check for NLP
models and give signals for human input. However, the reliability of these
models has not yet been thoroughly explored. Thus, we propose and test a novel
attack setting and attack, RedHerring. RedHerring aims to make attack detection
models unreliable by modifying a text to cause the detection model to predict
an attack, while keeping the classifier correct. This creates a tension between
the classifier and detector. If a human sees that the detector is giving an
``incorrect'' prediction, but the classifier a correct one, then the human will
see the detector as unreliable. We test this novel threat model on 4 datasets
against 3 detectors defending 4 classifiers. We find that RedHerring is able to
drop detection accuracy between 20 - 71 points, while maintaining (or
improving) classifier accuracy. As an initial defense, we propose a simple
confidence check which requires no retraining of the classifier or detector and
increases detection accuracy greatly. This novel threat model offers new
insights into how adversaries may target detection models.

</details>


### [109] [Overcoming Black-box Attack Inefficiency with Hybrid and Dynamic Select Algorithms](https://arxiv.org/abs/2509.20699)
*Abhinay Shankar Belde,Rohit Ramkumar,Jonathan Rusert*

Main category: cs.CL

TL;DR: 提出Hybrid Select和Dynamic Select两种新的攻击选择策略，以降低NLP模型鲁棒性测试的计算成本。


<details>
  <summary>Details</summary>
Motivation: Transformer等复杂模型导致NLP模型测试成本增加，现有黑盒攻击方法需要大量查询，不适用于资源有限的研究者。

Method: Hybrid Select策略结合BinarySelect和GreedySelect，引入大小阈值决定使用哪种算法。Dynamic Select策略学习不同长度文本适用的选择方法，结合了Binary和GreedySelect。

Result: 在4个数据集和6个模型上，提出的Hybrid Select和Dynamic Select策略有效减少了查询数量，同时保持了攻击效果。其中，句子级别的Hybrid Select策略平均减少了25.82%的查询。

Conclusion: 提出的Hybrid Select和Dynamic Select策略能够显著降低NLP模型对抗性测试的查询数量，同时保证攻击的有效性，为资源有限的研究者提供了更实用的解决方案。

Abstract: Adversarial text attack research plays a crucial role in evaluating the
robustness of NLP models. However, the increasing complexity of
transformer-based architectures has dramatically raised the computational cost
of attack testing, especially for researchers with limited resources (e.g.,
GPUs). Existing popular black-box attack methods often require a large number
of queries, which can make them inefficient and impractical for researchers. To
address these challenges, we propose two new attack selection strategies called
Hybrid and Dynamic Select, which better combine the strengths of previous
selection algorithms. Hybrid Select merges generalized BinarySelect techniques
with GreedySelect by introducing a size threshold to decide which selection
algorithm to use. Dynamic Select provides an alternative approach of combining
the generalized Binary and GreedySelect by learning which lengths of texts each
selection method should be applied to. This greatly reduces the number of
queries needed while maintaining attack effectiveness (a limitation of
BinarySelect). Across 4 datasets and 6 target models, our best
method(sentence-level Hybrid Select) is able to reduce the number of required
queries per attack up 25.82\% on average against both encoder models and LLMs,
without losing the effectiveness of the attack.

</details>


### [110] [MI-Fuse: Label Fusion for Unsupervised Domain Adaptation with Closed-Source Large-Audio Language Model](https://arxiv.org/abs/2509.20706)
*Hsiao-Ying Huang,Yi-Cheng Lin,Hung-yi Lee*

Main category: cs.CL

TL;DR: 在目标域数据和API形式的大型语音语言模型(LALM)可用的情况下，提出MI-Fuse框架，使学生模型在语音情感识别(SER)任务上能够超越LALM和现有最佳基线。


<details>
  <summary>Details</summary>
Motivation: 在实际应用中，语音情感识别(SER)常因领域不匹配而失败，此时无法获得源域数据，且只能通过API访问强大的LALM。本研究旨在探索在仅有目标域的未标记音频和API形式的LALM可用时，能否使学生模型适应目标域并优于LALM。

Method: 提出MI-Fuse框架，该框架使用一个在源域训练的SER分类器作为辅助教师，结合LALM。该框架从两个教师模型中提取多个随机预测，根据互信息不确定性对它们的平均分布进行加权，并使用指数移动平均教师来稳定训练。

Result: 在三个公开情感数据集和六个跨域迁移实验中，MI-Fuse框架均取得了显著的改进，学生模型不仅超越了LALM，而且比最强的基线提高了3.9%。

Conclusion: MI-Fuse框架能够在不共享源域数据的情况下，增强面向情感的语音系统，实现有效的迁移学习和适应性改进。

Abstract: Large audio-language models (LALMs) show strong zero-shot ability on speech
tasks, suggesting promise for speech emotion recognition (SER). However, SER in
real-world deployments often fails under domain mismatch, where source data are
unavailable and powerful LALMs are accessible only through an API. We ask:
given only unlabeled target-domain audio and an API-only LALM, can a student
model be adapted to outperform the LALM in the target domain? To this end, we
propose MI-Fuse, a denoised label fusion framework that supplements the LALM
with a source-domain trained SER classifier as an auxiliary teacher. The
framework draws multiple stochastic predictions from both teachers, weights
their mean distributions by mutual-information-based uncertainty, and
stabilizes training with an exponential moving average teacher. Experiments
across three public emotion datasets and six cross-domain transfers show
consistent gains, with the student surpassing the LALM and outperforming the
strongest baseline by 3.9%. This approach strengthens emotion-aware speech
systems without sharing source data, enabling realistic adaptation.

</details>


### [111] [Probability Distribution Collapse: A Critical Bottleneck to Compact Unsupervised Neural Grammar Induction](https://arxiv.org/abs/2509.20734)
*Jinwook Park,Kangil Kim*

Main category: cs.CL

TL;DR: 现有的无监督神经语法归纳模型存在表达能力瓶颈，导致语法冗长且性能不佳。本文识别出“概率分布坍塌”是核心问题，并提出“坍塌-放松神经参数化”方法来缓解此问题，从而在多语言上显著提高句法分析性能并生成更紧凑的语法。


<details>
  <summary>Details</summary>
Motivation: 现有的无监督神经语法归纳模型存在表达能力瓶颈，导致生成的语法冗长且性能不佳。

Method: 识别出“概率分布坍塌”是导致模型表达能力受限的核心问题，并提出“坍塌-放松神经参数化”方法来缓解此问题。

Result: 提出的方法在多语言上显著提高了句法分析性能，并能生成更紧凑的语法。

Conclusion: “坍塌-放松神经参数化”方法有效解决了无监督神经语法归纳中的表达能力瓶颈和概率分布坍塌问题，提高了模型性能并允许使用更紧凑的语法。

Abstract: Unsupervised neural grammar induction aims to learn interpretable
hierarchical structures from language data. However, existing models face an
expressiveness bottleneck, often resulting in unnecessarily large yet
underperforming grammars. We identify a core issue, $\textit{probability
distribution collapse}$, as the underlying cause of this limitation. We analyze
when and how the collapse emerges across key components of neural
parameterization and introduce a targeted solution, $\textit{collapse-relaxing
neural parameterization}$, to mitigate it. Our approach substantially improves
parsing performance while enabling the use of significantly more compact
grammars across a wide range of languages, as demonstrated through extensive
empirical analysis.

</details>


### [112] [Confidence-guided Refinement Reasoning for Zero-shot Question Answering](https://arxiv.org/abs/2509.20750)
*Youwon Jang,Woo Suk Choi,Minjoon Jung,Minsu Lee,Byoung-Tak Zhang*

Main category: cs.CL

TL;DR: C2R是一个训练无关的框架，通过构建和精炼子问题和答案来提高QA任务的置信度评分，从而选择最可靠的最终答案，并可无缝集成到现有QA模型中。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在提出一个训练无关的框架，通过构建和精炼子问题和答案来提高QA任务的置信度评分，从而选择最可靠的最终答案。

Method: C2R框架首先精选子问题和答案的子集以探索不同的推理路径，然后比较由此产生的答案候选者的置信度评分，以选择最可靠的最终答案。

Result: C2R框架可以无缝集成到各种现有的QA模型中，并在不同的模型和基准测试中展示出一致的性能提升。

Conclusion: C2R框架通过利用子问题和答案，在提高模型行为、鲁棒性和可靠性方面提供了有价值的见解，并分析了子问题和答案的数量和质量对模型性能的影响。

Abstract: We propose Confidence-guided Refinement Reasoning (C2R), a novel
training-free framework applicable to question-answering (QA) tasks across
text, image, and video domains. C2R strategically constructs and refines
sub-questions and their answers (sub-QAs), deriving a better confidence score
for the target answer. C2R first curates a subset of sub-QAs to explore diverse
reasoning paths, then compares the confidence scores of the resulting answer
candidates to select the most reliable final answer. Since C2R relies solely on
confidence scores derived from the model itself, it can be seamlessly
integrated with various existing QA models, demonstrating consistent
performance improvements across diverse models and benchmarks. Furthermore, we
provide essential yet underexplored insights into how leveraging sub-QAs
affects model behavior, specifically analyzing the impact of both the quantity
and quality of sub-QAs on achieving robust and reliable reasoning.

</details>


### [113] [SFT Doesn't Always Hurt General Capabilities: Revisiting Domain-Specific Fine-Tuning in LLMs](https://arxiv.org/abs/2509.20758)
*Jiacheng Lin,Zhongruo Wang,Kun Qian,Tian Wang,Arvind Srinivasan,Hansi Zeng,Ruochen Jiao,Xie Zhou,Jiri Gesi,Dakuo Wang,Yufan Guo,Kai Zhong,Weiqi Zhang,Sujay Sanghavi,Changyou Chen,Hyokun Yun,Lihong Li*

Main category: cs.CL

TL;DR: SFT 损害 LLM 的通用能力是一个常见的观点，但通过使用较小的学习率可以缓解这种损害。我们提出了一种名为 TALR 的新方法，通过代币自适应损失重加权来进一步改善这种平衡，并在实验中证明其优于其他基线方法。


<details>
  <summary>Details</summary>
Motivation: 评估和减轻监督微调（SFT）对大型语言模型（LLM）通用能力的损害，并提出一种改进的微调方法。

Method: 首先，研究了使用较小学习率对 SFT 中通用能力下降的影响。然后，提出了理论分析来解释这些现象，并开发了一种名为 Token-Adaptive Loss Reweighting（TALR）的新方法。最后，将 TALR 与 L2 正则化、LoRA、模型平均和 FLOW 等其他减少通用能力损失的策略进行了比较。

Result: 实验表明，使用较小的学习率可以显著缓解通用能力下降，同时保持目标域的性能。虽然没有一种方法可以完全消除这种权衡，但 TALR 在平衡域内收益和通用能力方面始终优于其他基线方法。

Conclusion: 在适应 LLM 到新领域时，建议采用小学习率以获得有利的权衡；当需要更强的平衡时，应采用 TALR 作为一种有效的策略。

Abstract: Supervised Fine-Tuning (SFT) on domain-specific datasets is a common approach
to adapt Large Language Models (LLMs) to specialized tasks but is often
believed to degrade their general capabilities. In this work, we revisit this
trade-off and present both empirical and theoretical insights. First, we show
that SFT does not always hurt: using a smaller learning rate can substantially
mitigate general performance degradation while preserving comparable
target-domain performance. We then provide a theoretical analysis that explains
these phenomena and further motivates a new method, Token-Adaptive Loss
Reweighting (TALR). Building on this, and recognizing that smaller learning
rates alone do not fully eliminate general-performance degradation in all
cases, we evaluate a range of strategies for reducing general capability loss,
including L2 regularization, LoRA, model averaging, FLOW, and our proposed
TALR. Experimental results demonstrate that while no method completely
eliminates the trade-off, TALR consistently outperforms these baselines in
balancing domain-specific gains and general capabilities. Finally, we distill
our findings into practical guidelines for adapting LLMs to new domains: (i)
using a small learning rate to achieve a favorable trade-off, and (ii) when a
stronger balance is further desired, adopt TALR as an effective strategy.

</details>


### [114] [Towards Atoms of Large Language Models](https://arxiv.org/abs/2509.20784)
*Chenhui Hu,Pengfei Cao,Yubo Chen,Kang Liu,Jun Zhao*

Main category: cs.CL

TL;DR: LLM内部表征单元未明确，提出“原子理论”，通过原子内积（AIP）解决表征偏移，定义原子并证明其满足RIP性质，保证稀疏表示的稳定性和可恢复性，并通过SAEs实现原子的可靠识别。实验在Gemma2和Llama3.1上验证了原子理论的有效性。


<details>
  <summary>Details</summary>
Motivation: LLM内部表征单元（如神经元或特征）的定义不明确，存在多义性、重构不可靠和不稳定性等问题，阻碍了对其机制的深入理解。

Method: 提出“原子理论”，定义原子作为LLM内部表征的基本单元。引入原子内积（AIP）来修正表征偏移。证明了原子满足限制等距性质（RIP），确保了稀疏表示的稳定性和与压缩感知的联系。在更强的条件下，证明了稀疏表示的唯一性和精确$\ell_1$可恢复性。提出使用具有阈值激活的单层稀疏自编码器（SAEs）来可靠地识别原子。

Result: 在Gemma2-2B、Gemma2-9B和Llama3.1-8B上训练的SAEs实现了平均99.9%的稀疏重构率。超过99.8%的原子满足唯一性条件，远高于神经元（0.5%）和特征（68.2%）。扩展性实验揭示了SAEs大小与恢复能力之间的联系。

Conclusion: 原子理论为理解LLM内部表征提供了一个系统性的理论框架和基础，解决了现有表征单元定义的问题，并通过实验验证了其有效性。

Abstract: The fundamental units of internal representations in large language models
(LLMs) remain undefined, limiting further understanding of their mechanisms.
Neurons or features are often regarded as such units, yet neurons suffer from
polysemy, while features face concerns of unreliable reconstruction and
instability. To address this issue, we propose the Atoms Theory, which defines
such units as atoms. We introduce the atomic inner product (AIP) to correct
representation shifting, formally define atoms, and prove the conditions that
atoms satisfy the Restricted Isometry Property (RIP), ensuring stable sparse
representations over atom set and linking to compressed sensing. Under stronger
conditions, we further establish the uniqueness and exact $\ell_1$
recoverability of the sparse representations, and provide guarantees that
single-layer sparse autoencoders (SAEs) with threshold activations can reliably
identify the atoms. To validate the Atoms Theory, we train threshold-activated
SAEs on Gemma2-2B, Gemma2-9B, and Llama3.1-8B, achieving 99.9% sparse
reconstruction across layers on average, and more than 99.8% of atoms satisfy
the uniqueness condition, compared to 0.5% for neurons and 68.2% for features,
showing that atoms more faithfully capture intrinsic representations of LLMs.
Scaling experiments further reveal the link between SAEs size and recovery
capacity. Overall, this work systematically introduces and validates Atoms
Theory of LLMs, providing a theoretical framework for understanding internal
representations and a foundation for mechanistic interpretability. Code
available at https://github.com/ChenhuiHu/towards_atoms.

</details>


### [115] [Few-Shot and Training-Free Review Generation via Conversational Prompting](https://arxiv.org/abs/2509.20805)
*Genki Kusano*

Main category: cs.CL

TL;DR: 该研究提出了一种名为“对话式提示”的新方法，用于在评论数量有限且无需模型训练的情况下生成个性化用户评论。


<details>
  <summary>Details</summary>
Motivation: 现有评论生成方法通常需要大量用户评论或进行模型微调，这在实际应用中难以实现。而大语言模型（LLM）虽然适用于低资源场景，但效果依赖于提示工程。

Method: 研究者提出了“对话式提示”方法，将用户评论改写为多轮对话。其中，简单对话式提示（SCP）仅使用用户自己的评论；对比对话式提示（CCP）则通过插入其他用户或LLM生成的错误回复，并要求模型进行纠正，从而模仿用户风格。

Result: 实验表明，与传统的非对话式提示相比，SCP和CCP在评论生成上能更准确地模仿目标用户风格，即使在每个用户只有两条评论的极端情况下也能取得良好效果。CCP在有高质量负面示例时效果更佳，而SCP在无法获取此类数据时仍具竞争力。

Conclusion: 对话式提示为在少样本、免训练的约束下进行评论生成提供了一个有效的解决方案。

Abstract: Personalized review generation helps businesses understand user preferences,
yet most existing approaches assume extensive review histories of the target
user or require additional model training. Real-world applications often face
few-shot and training-free situations, where only a few user reviews are
available and fine-tuning is infeasible. It is well known that large language
models (LLMs) can address such low-resource settings, but their effectiveness
depends on prompt engineering. In this paper, we propose Conversational
Prompting, a lightweight method that reformulates user reviews as multi-turn
conversations. Its simple variant, Simple Conversational Prompting (SCP),
relies solely on the user's own reviews, while the contrastive variant,
Contrastive Conversational Prompting (CCP), inserts reviews from other users or
LLMs as incorrect replies and then asks the model to correct them, encouraging
the model to produce text in the user's style. Experiments on eight product
domains and five LLMs showed that the conventional non-conversational prompt
often produced reviews similar to those written by random users, based on
text-based metrics such as ROUGE-L and BERTScore, and application-oriented
tasks like user identity matching and sentiment analysis. In contrast, both SCP
and CCP produced reviews much closer to those of the target user, even when
each user had only two reviews. CCP brings further improvements when
high-quality negative examples are available, whereas SCP remains competitive
when such data cannot be collected. These results suggest that conversational
prompting offers a practical solution for review generation under few-shot and
training-free constraints.

</details>


### [116] [Enrich-on-Graph: Query-Graph Alignment for Complex Reasoning with LLM Enriching](https://arxiv.org/abs/2509.20810)
*Songze Li,Zhiqiang Liu,Zhengke Gui,Huajun Chen,Wen Zhang*

Main category: cs.CL

TL;DR: LLMs 在知识图谱问答 (KGQA) 中存在幻觉和事实错误问题，原因是结构化知识图谱 (KGs) 和非结构化查询之间存在语义鸿沟。本文提出 Enrich-on-Graph (EoG) 框架，利用 LLMs 的先验知识来丰富 KGs，弥合语义鸿沟，从而实现高效、精确、鲁棒的推理，同时保证低计算成本、可扩展性和适应性。此外，还提出了三个图质量评估指标来分析 KGQA 任务中的查询-图对齐。实验表明 EoG 能够生成高质量的 KGs 并达到最先进的性能。


<details>
  <summary>Details</summary>
Motivation: LLMs 在 KGQA 中存在幻觉和事实错误，原因是 KGs 和查询之间的语义鸿沟。现有方法未能解决此问题。

Method: 提出 Enrich-on-Graph (EoG) 框架，利用 LLMs 丰富 KGs，弥合语义鸿沟，实现高效、精确、鲁棒的推理。并提出三个图质量评估指标。

Result: EoG 框架在两个 KGQA 基准数据集上实现了最先进的性能。

Conclusion: EoG 框架能够有效生成高质量的 KGs，并实现 KGQA 任务的最优性能。

Abstract: Large Language Models (LLMs) exhibit strong reasoning capabilities in complex
tasks. However, they still struggle with hallucinations and factual errors in
knowledge-intensive scenarios like knowledge graph question answering (KGQA).
We attribute this to the semantic gap between structured knowledge graphs (KGs)
and unstructured queries, caused by inherent differences in their focuses and
structures. Existing methods usually employ resource-intensive, non-scalable
workflows reasoning on vanilla KGs, but overlook this gap. To address this
challenge, we propose a flexible framework, Enrich-on-Graph (EoG), which
leverages LLMs' prior knowledge to enrich KGs, bridge the semantic gap between
graphs and queries. EoG enables efficient evidence extraction from KGs for
precise and robust reasoning, while ensuring low computational costs,
scalability, and adaptability across different methods. Furthermore, we propose
three graph quality evaluation metrics to analyze query-graph alignment in KGQA
task, supported by theoretical validation of our optimization objectives.
Extensive experiments on two KGQA benchmark datasets indicate that EoG can
effectively generate high-quality KGs and achieve the state-of-the-art
performance. Our code and data are available at
https://github.com/zjukg/Enrich-on-Graph.

</details>


### [117] [Leveraging What's Overfixed: Post-Correction via LLM Grammatical Error Overcorrection](https://arxiv.org/abs/2509.20811)
*Taehee Park,Heejin Do,Gary Geunbae Lee*

Main category: cs.CL

TL;DR: LLMs 容易过度纠正，sLMs 容易纠正不足。PoCO 方法先用 LLM 过度纠正以最大化召回率，再用 sLM 精确修正以提高准确率。


<details>
  <summary>Details</summary>
Motivation: 为了解决 sLM 召回率低和 LLM 准确率低的问题，提出 PoCO 方法来平衡召回率和准确率。

Method: PoCO 方法首先利用 LLM 故意触发过度纠正以最大化召回率，然后通过微调更小的模型来识别和精炼错误的输出来进行目标后纠正。

Result: 实验证明 PoCO 有效地平衡了 GEC 性能，在保持可观准确率的同时提高了召回率，最终提高了语法纠错的整体质量。

Conclusion: PoCO 方法通过利用 LLM 的生成能力并保持更小的监督模型的可靠性，有效地平衡了 GEC 性能。

Abstract: Robust supervised fine-tuned small Language Models (sLMs) often show high
reliability but tend to undercorrect. They achieve high precision at the cost
of low recall. Conversely, Large Language Models (LLMs) often show the opposite
tendency, making excessive overcorrection, leading to low precision. To
effectively harness the strengths of LLMs to address the recall challenges in
sLMs, we propose Post-Correction via Overcorrection (PoCO), a novel approach
that strategically balances recall and precision. PoCO first intentionally
triggers overcorrection via LLM to maximize recall by allowing comprehensive
revisions, then applies a targeted post-correction step via fine-tuning smaller
models to identify and refine erroneous outputs. We aim to harmonize both
aspects by leveraging the generative power of LLMs while preserving the
reliability of smaller supervised models. Our extensive experiments demonstrate
that PoCO effectively balances GEC performance by increasing recall with
competitive precision, ultimately improving the overall quality of grammatical
error correction.

</details>


### [118] [Distilling Many-Shot In-Context Learning into a Cheat Sheet](https://arxiv.org/abs/2509.20820)
*Ukyo Honda,Soichiro Murakami,Peinan Zhang*

Main category: cs.CL

TL;DR: Cheat-sheet ICL uses a concise summary of many-shot examples to achieve similar or better performance than many-shot ICL with fewer tokens, offering a practical alternative for leveraging LLMs.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the high computational demand of many-shot in-context learning (ICL) in large language models (LLMs) due to long input tokens.

Method: The proposed method, cheat-sheet ICL, distills information from many-shot ICL into a concise textual summary (cheat sheet) that is used as context during inference.

Result: Experiments on challenging reasoning tasks show that cheat-sheet ICL achieves comparable or better performance than many-shot ICL using significantly fewer tokens. It also matches retrieval-based ICL performance without needing test-time retrieval.

Conclusion: Cheat-sheet ICL is a practical and efficient alternative for utilizing LLMs in downstream tasks.

Abstract: Recent advances in large language models (LLMs) enable effective in-context
learning (ICL) with many-shot examples, but at the cost of high computational
demand due to longer input tokens. To address this, we propose cheat-sheet ICL,
which distills the information from many-shot ICL into a concise textual
summary (cheat sheet) used as the context at inference time. Experiments on
challenging reasoning tasks show that cheat-sheet ICL achieves comparable or
better performance than many-shot ICL with far fewer tokens, and matches
retrieval-based ICL without requiring test-time retrieval. These findings
demonstrate that cheat-sheet ICL is a practical alternative for leveraging LLMs
in downstream tasks.

</details>


### [119] [Zero-Shot Privacy-Aware Text Rewriting via Iterative Tree Search](https://arxiv.org/abs/2509.20838)
*Shuo Huang,Xingliang Yuan,Gholamreza Haffari,Lizhen Qu*

Main category: cs.CL

TL;DR: LLMs在云服务中的应用引发了隐私担忧，现有文本匿名化技术难以平衡隐私和文本自然度。本研究提出一种零样本、基于树搜索的迭代句子重写算法，在保留文本连贯性、相关性和自然性的同时，系统地混淆或删除隐私信息。


<details>
  <summary>Details</summary>
Motivation: 现有文本匿名化和去标识化技术（如基于规则的 redaction 和 scrubbing）在平衡隐私保护与文本自然度和实用性方面存在挑战。

Method: 提出一种零样本、基于树搜索的迭代句子重写算法，通过结构化搜索和奖励模型，逐步重写隐私敏感的片段，以探索重写空间。

Result: 实验结果表明，该方法在隐私敏感数据集上显著优于现有基线，在隐私保护和效用保持之间取得了更好的平衡。

Conclusion: 所提出的零样本、基于树搜索的迭代句子重写算法能够有效解决LLMs应用中的隐私问题，并在保护隐私的同时保持文本的自然度和实用性。

Abstract: The increasing adoption of large language models (LLMs) in cloud-based
services has raised significant privacy concerns, as user inputs may
inadvertently expose sensitive information. Existing text anonymization and
de-identification techniques, such as rule-based redaction and scrubbing, often
struggle to balance privacy preservation with text naturalness and utility. In
this work, we propose a zero-shot, tree-search-based iterative sentence
rewriting algorithm that systematically obfuscates or deletes private
information while preserving coherence, relevance, and naturalness. Our method
incrementally rewrites privacy-sensitive segments through a structured search
guided by a reward model, enabling dynamic exploration of the rewriting space.
Experiments on privacy-sensitive datasets show that our approach significantly
outperforms existing baselines, achieving a superior balance between privacy
protection and utility preservation.

</details>


### [120] [Concise and Sufficient Sub-Sentence Citations for Retrieval-Augmented Generation](https://arxiv.org/abs/2509.20859)
*Guo Chen,Qiuyuan Li,Qiuxian Li,Hongliang Dai,Xiang Chen,Piji Li*

Main category: cs.CL

TL;DR: 现有的检索增强生成（RAG）问答系统在生成引用时存在问题：引用粒度粗糙（句子或段落级别），可能包含不相关信息，或遗漏关键验证信息。本文提出了一种生成子句子级别的引用方法，旨在提供更简洁、充分的引用，以减少用户验证工作量。为此，我们制定了标注指南并构建了数据集，然后提出了一种利用LLM自动生成微调数据并结合信用模型筛选的归因框架。实验证明，该方法能生成更高质量、更易读的引用。


<details>
  <summary>Details</summary>
Motivation: 现有的归因方法生成的引用粒度粗糙（句子或段落级别），可能包含不相关信息或遗漏关键验证信息，增加了用户验证的难度。

Method: 1.制定子句子引用标注指南并构建数据集。 2.提出一种归因框架，利用LLM自动生成微调数据，并使用信用模型筛选低质量数据。

Result: 所提出的方法能够生成更高质量、更易读的引用。

Conclusion: 本文提出的子句子引用生成方法能够有效解决现有方法的不足，提高引用的可读性和准确性，从而提升用户验证效率。

Abstract: In retrieval-augmented generation (RAG) question answering systems,
generating citations for large language model (LLM) outputs enhances
verifiability and helps users identify potential hallucinations. However, we
observe two problems in the citations produced by existing attribution methods.
First, the citations are typically provided at the sentence or even paragraph
level. Long sentences or paragraphs may include a substantial amount of
irrelevant content. Second, sentence-level citations may omit information that
is essential for verifying the output, forcing users to read the surrounding
context. In this paper, we propose generating sub-sentence citations that are
both concise and sufficient, thereby reducing the effort required by users to
confirm the correctness of the generated output. To this end, we first develop
annotation guidelines for such citations and construct a corresponding dataset.
Then, we propose an attribution framework for generating citations that adhere
to our standards. This framework leverages LLMs to automatically generate
fine-tuning data for our task and employs a credit model to filter out
low-quality examples. Our experiments on the constructed dataset demonstrate
that the propose approach can generate high-quality and more readable
citations.

</details>


### [121] [WeFT: Weighted Entropy-driven Fine-Tuning for dLLMs](https://arxiv.org/abs/2509.20863)
*Guowei Xu,Wenxin Xu,Jiawang Zhao,Kaisheng Ma*

Main category: cs.CL

TL;DR: WeFT是一种加权的监督微调（SFT）方法，用于扩散语言模型，通过根据熵为 token 分配不同的权重来解决 SFT 在扩散模型上的挑战，并实现了在推理基准上的显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在语言建模方面展现出潜力，但直接进行监督微调（SFT）存在挑战，因为它们缺乏精确的概率估计，并且生成过程可能不稳定。因此，需要一种方法来控制引导生成方向的关键 token。

Method: 提出了一种名为WeFT的加权SFT方法，该方法根据 token 的熵为其分配不同的权重。这种加权机制源于扩散理论，旨在提高扩散模型微调的效率和效果。

Result: 在s1K、s1K-1.1和3k样本的open-r1数据集上进行训练，WeFT在四个推理基准（Sudoku、Countdown、GSM8K和MATH-500）上相比标准SFT取得了39%、64%和83%的相对提升。

Conclusion: WeFT通过为 token 分配基于熵的权重，有效解决了扩散语言模型在监督微调（SFT）方面面临的挑战，并在多个推理任务上取得了显著的性能改进。

Abstract: Diffusion models have recently shown strong potential in language modeling,
offering faster generation compared to traditional autoregressive approaches.
However, applying supervised fine-tuning (SFT) to diffusion models remains
challenging, as they lack precise probability estimates at each denoising step.
While the diffusion mechanism enables the model to reason over entire
sequences, it also makes the generation process less predictable and often
inconsistent. This highlights the importance of controlling key tokens that
guide the direction of generation. To address this issue, we propose WeFT, a
weighted SFT method for diffusion language models, where tokens are assigned
different weights based on their entropy. Derived from diffusion theory, WeFT
delivers substantial gains: training on s1K, s1K-1.1, and 3k samples from
open-r1, it achieves relative improvements of 39%, 64%, and 83% over standard
SFT on four widely used reasoning benchmarks (Sudoku, Countdown, GSM8K, and
MATH-500). The code and models will be made publicly available.

</details>


### [122] [Single Answer is Not Enough: On Generating Ranked Lists with Medical Reasoning Models](https://arxiv.org/abs/2509.20866)
*Pittawat Taveekitworachai,Natpatchara Pongjirapat,Krittaphas Chaisutyakorn,Piyalitt Ittichaiwong,Tossaporn Saengja,Kunat Pipatanakul*

Main category: cs.CL

TL;DR: 本研究旨在改进医疗推理模型（MRMs），使其能够为开放式问题生成排名答案列表，以弥补当前模型只能生成单一答案的不足，并提高临床决策的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 临床决策通常需要考虑多个选项而非单一答案，但现有MRMs在此方面能力有限。本研究旨在解决这一问题。

Method: 本研究探索了两种方法：提示（prompting）和微调（fine-tuning）。对于微调，研究了监督微调（SFT）和强化微调（RFT），并提出了针对排名答案格式的新奖励函数，同时进行了消融研究。

Result: 研究发现，虽然SFT模型在某些答案格式上表现良好，但RFT模型在多种格式上表现更稳健。此外，在MedQA的案例研究中，MRMs能够识别有效的答案，即使它们不总是选择基准测试中的首选答案。

Conclusion: 本研究是首次系统性地研究使MRMs能够生成排名答案列表的方法，为开发超越单一答案的替代答案格式迈出了第一步，有望在医学领域带来益处。

Abstract: This paper presents a systematic study on enabling medical reasoning models
(MRMs) to generate ranked lists of answers for open-ended questions. Clinical
decision-making rarely relies on a single answer but instead considers multiple
options, reducing the risks of narrow perspectives. Yet current MRMs are
typically trained to produce only one answer, even in open-ended settings. We
propose an alternative format: ranked lists and investigate two approaches:
prompting and fine-tuning. While prompting is a cost-effective way to steer an
MRM's response, not all MRMs generalize well across different answer formats:
choice, short text, and list answers. Based on our prompting findings, we train
and evaluate MRMs using supervised fine-tuning (SFT) and reinforcement
fine-tuning (RFT). SFT teaches a model to imitate annotated responses, and RFT
incentivizes exploration through the responses that maximize a reward. We
propose new reward functions targeted at ranked-list answer formats, and
conduct ablation studies for RFT. Our results show that while some SFT models
generalize to certain answer formats, models trained with RFT are more robust
across multiple formats. We also present a case study on a modified MedQA with
multiple valid answers, finding that although MRMs might fail to select the
benchmark's preferred ground truth, they can recognize valid answers. To the
best of our knowledge, this is the first systematic investigation of approaches
for enabling MRMs to generate answers as ranked lists. We hope this work
provides a first step toward developing alternative answer formats that are
beneficial beyond single answers in medical domains.

</details>


### [123] [Learning to Summarize by Learning to Quiz: Adversarial Agentic Collaboration for Long Document Summarization](https://arxiv.org/abs/2509.20900)
*Weixuan Wang,Minghao Wu,Barry Haddow,Alexandra Birch*

Main category: cs.CL

TL;DR: SummQ是一个新颖的多智能体框架，通过生成和评估问题来解决长文档摘要中的信息丢失、事实不一致和连贯性问题，并在多个基准测试中超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的长文档摘要方法在处理超长文档时，常常在信息丢失、事实不一致和连贯性方面遇到困难。

Method: 提出了一种名为SummQ的新颖的对抗性多智能体框架，该框架结合了摘要生成和问答两个领域的协作智能。它包括摘要生成器、审阅器、问题生成器、审阅器和一个负责验证摘要是否包含回答问题所需信息的考生代理。这种对抗性动态通过多方面的反馈机制实现迭代优化。

Result: 在三个广泛使用的长文档摘要基准测试中，SummQ框架在ROUGE和BERTScore指标、LLM-as-a-Judge评估和人类评估中均显著优于现有的最先进方法。

Conclusion: SummQ通过利用对抗性智能体协作来提高摘要质量，为长文档摘要提供了一种新方法。

Abstract: Long document summarization remains a significant challenge for current large
language models (LLMs), as existing approaches commonly struggle with
information loss, factual inconsistencies, and coherence issues when processing
excessively long documents. We propose SummQ, a novel adversarial multi-agent
framework that addresses these limitations through collaborative intelligence
between specialized agents operating in two complementary domains:
summarization and quizzing. Our approach employs summary generators and
reviewers that work collaboratively to create and evaluate comprehensive
summaries, while quiz generators and reviewers create comprehension questions
that serve as continuous quality checks for the summarization process. This
adversarial dynamic, enhanced by an examinee agent that validates whether the
generated summary contains the information needed to answer the quiz questions,
enables iterative refinement through multifaceted feedback mechanisms. We
evaluate SummQ on three widely used long document summarization benchmarks.
Experimental results demonstrate that our framework significantly outperforms
existing state-of-the-art methods across ROUGE and BERTScore metrics, as well
as in LLM-as-a-Judge and human evaluations. Our comprehensive analyses reveal
the effectiveness of the multi-agent collaboration dynamics, the influence of
different agent configurations, and the impact of the quizzing mechanism. This
work establishes a new approach for long document summarization that uses
adversarial agentic collaboration to improve summarization quality.

</details>


### [124] [MemLens: Uncovering Memorization in LLMs with Activation Trajectories](https://arxiv.org/abs/2509.20909)
*Zirui He,Haiyan Zhao,Ali Payani,Mengnan du*

Main category: cs.CL

TL;DR: LLMs的基准测试易受污染，现有的检测方法效果不佳。我们提出了MemLens，通过分析数值token的概率轨迹来检测模型记忆，发现污染样本在早期层就锁定答案，而干净样本则在模型深层逐渐积累证据。MemLens能有效识别记忆行为。


<details>
  <summary>Details</summary>
Motivation: 现有LLM基准测试（如AIME和Math500）容易被污染，且可能被模型记忆。现有的检测方法（基于词汇重叠和困惑度）泛化能力差，无法有效检测隐式污染数据。

Method: 提出MemLens方法，通过分析模型生成过程中数值token的概率轨迹来检测记忆。研究发现，被污染的样本在模型早期层就会以高置信度锁定答案（“捷径”行为），而干净样本则在模型全部层中逐渐积累证据。

Result: 被污染样本和干净样本表现出明显不同的、分离的推理轨迹。通过LoRA微调注入精心设计的样本，观察到了与自然污染数据相同的轨迹模式，证明MemLens捕捉到的是真实的记忆信号，而非虚假相关性。

Conclusion: MemLens能够有效地区分被污染和干净的数据，并通过分析数值token的概率轨迹为LLM的记忆检测提供了一种新颖且可靠的方法。

Abstract: Large language models (LLMs) are commonly evaluated on challenging benchmarks
such as AIME and Math500, which are susceptible to contamination and risk of
being memorized. Existing detection methods, which primarily rely on
surface-level lexical overlap and perplexity, demonstrate low generalization
and degrade significantly when encountering implicitly contaminated data. In
this paper, we propose MemLens (An Activation Lens for Memorization Detection)
to detect memorization by analyzing the probability trajectories of numeric
tokens during generation. Our method reveals that contaminated samples exhibit
``shortcut'' behaviors, locking onto an answer with high confidence in the
model's early layers, whereas clean samples show more gradual evidence
accumulation across the model's full depth. We observe that contaminated and
clean samples exhibit distinct and well-separated reasoning trajectories. To
further validate this, we inject carefully designed samples into the model
through LoRA fine-tuning and observe the same trajectory patterns as in
naturally contaminated data. These results provide strong evidence that MemLens
captures genuine signals of memorization rather than spurious correlations.

</details>


### [125] [Cross-Linguistic Analysis of Memory Load in Sentence Comprehension: Linear Distance and Structural Density](https://arxiv.org/abs/2509.20916)
*Krishna Aggarwal*

Main category: cs.CL

TL;DR: 本研究提出“干预物复杂度”概念，解释句子理解中的记忆负荷，发现它比线性距离更能解释记忆负荷，并调和了线性与层级视角。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探究句子理解中的记忆负荷是由句法相关词语间的线性距离还是中间物质的结构密度更好地解释。

Method: 本研究使用统一的依赖句法树库，并采用混合效应模型，同时评估句子长度、依赖长度和干预物复杂度（两个句法成分之间隔断的中心词数量）作为记忆负荷指标的预测因子。

Result: 研究结果显示，句子长度、依赖长度和干预物复杂度都与记忆负荷正相关，其中句子长度的影响最广泛，而干预物复杂度比线性距离提供了更强的解释力。

Conclusion: 本研究的发现通过将依赖长度视为重要的表面特征，并将中间中心词视为整合和维持需求更直接的指标，从而调和了关于区域性的线性与层级视角。该研究还展示了如何利用基于UD的图度量和跨语言混合效应模型来区分处理效率中的线性和结构因素，为评估句子理解中记忆负荷的竞争理论提供了原则性的方法。

Abstract: This study examines whether sentence-level memory load in comprehension is
better explained by linear proximity between syntactically related words or by
the structural density of the intervening material. Building on locality-based
accounts and cross-linguistic evidence for dependency length minimization, the
work advances Intervener Complexity-the number of intervening heads between a
head and its dependent-as a structurally grounded lens that refines linear
distance measures. Using harmonized dependency treebanks and a mixed-effects
framework across multiple languages, the analysis jointly evaluates sentence
length, dependency length, and Intervener Complexity as predictors of the
Memory-load measure. Studies in Psycholinguistics have reported the
contributions of feature interference and misbinding to memory load during
processing. For this study, I operationalized sentence-level memory load as the
linear sum of feature misbinding and feature interference for tractability;
current evidence does not establish that their cognitive contributions combine
additively. All three factors are positively associated with memory load, with
sentence length exerting the broadest influence and Intervener Complexity
offering explanatory power beyond linear distance. Conceptually, the findings
reconcile linear and hierarchical perspectives on locality by treating
dependency length as an important surface signature while identifying
intervening heads as a more proximate indicator of integration and maintenance
demands. Methodologically, the study illustrates how UD-based graph measures
and cross-linguistic mixed-effects modelling can disentangle linear and
structural contributions to processing efficiency, providing a principled path
for evaluating competing theories of memory load in sentence comprehension.

</details>


### [126] [Tool Calling for Arabic LLMs: Data Strategies and Instruction Tuning](https://arxiv.org/abs/2509.20957)
*Asim Ersoy,Enes Altinisik,Husrev Taha Sencar,Kareem Darwish*

Main category: cs.CL

TL;DR: 英文LLM工具调用研究为主，本文研究阿拉伯语工具调用能力。


<details>
  <summary>Details</summary>
Motivation: 英文LLM工具调用研究为主，缺少其他语言（如阿拉伯语）的研究。本文旨在填补这一空白，研究阿拉伯语工具调用的关键问题。

Method: 通过翻译和改编两个开源工具调用数据集到阿拉伯语，并使用基础和后训练的阿拉伯语LLM进行实验，研究三个关键问题：1. 阿拉伯语工具调用数据与跨语言迁移的必要性；2. 通用指令调优对工具调用性能的影响；3. 针对特定高优先级工具进行微调的价值。

Result: 本文的实验结果为开发强大的阿拉伯语工具增强型AI提供了重要的见解。

Conclusion: 本文为开发阿拉伯语工具增强型AI提供了重要的见解。

Abstract: Tool calling is a critical capability that allows Large Language Models
(LLMs) to interact with external systems, significantly expanding their
utility. However, research and resources for tool calling are predominantly
English-centric, leaving a gap in our understanding of how to enable this
functionality for other languages, such as Arabic. This paper investigates
three key research questions: (1) the necessity of in-language (Arabic)
tool-calling data versus relying on cross-lingual transfer, (2) the effect of
general-purpose instruction tuning on tool-calling performance, and (3) the
value of fine-tuning on specific, high-priority tools. To address these
questions, we conduct extensive experiments using base and post-trained
variants of an open-weight Arabic LLM. To enable this study, we bridge the
resource gap by translating and adapting two open-source tool-calling datasets
into Arabic. Our findings provide crucial insights into the optimal strategies
for developing robust tool-augmented agents for Arabic.

</details>


### [127] [Analysis of instruction-based LLMs' capabilities to score and judge text-input problems in an academic setting](https://arxiv.org/abs/2509.20982)
*Valeria Ramirez-Garcia,David de-Fitero-Dominguez,Antonio Garcia-Cabot,Eva Garcia-Lopez*

Main category: cs.CL

TL;DR: LLM可作为学术文本输入问题自动评估系统，其中“参考辅助评估”方法表现最佳。


<details>
  <summary>Details</summary>
Motivation: 研究LLM在教育领域的应用，特别是针对学术文本输入问题的自动评估系统。

Method: 提出五种LLM评估系统（JudgeLM评估、参考辅助评估、无参考评估、加性评估、自适应评估），并在包含110个计算机科学答案的数据集上进行测试，与人类评估者进行比较。

Result: 参考辅助评估在评估准确性（MAD为0.945，RMSD为1.214）和评估质量方面优于其他方法，而加性评估、自适应评估、无参考评估和JudgeLM评估则存在局限性。

Conclusion: LLM驱动的自动评估系统，结合恰当的方法学，有潜力作为学术资源的补充工具。

Abstract: Large language models (LLMs) can act as evaluators, a role studied by methods
like LLM-as-a-Judge and fine-tuned judging LLMs. In the field of education,
LLMs have been studied as assistant tools for students and teachers. Our
research investigates LLM-driven automatic evaluation systems for academic
Text-Input Problems using rubrics. We propose five evaluation systems that have
been tested on a custom dataset of 110 answers about computer science from
higher education students with three models: JudgeLM, Llama-3.1-8B and
DeepSeek-R1-Distill-Llama-8B. The evaluation systems include: The JudgeLM
evaluation, which uses the model's single answer prompt to obtain a score;
Reference Aided Evaluation, which uses a correct answer as a guide aside from
the original context of the question; No Reference Evaluation, which ommits the
reference answer; Additive Evaluation, which uses atomic criteria; and Adaptive
Evaluation, which is an evaluation done with generated criteria fitted to each
question. All evaluation methods have been compared with the results of a human
evaluator. Results show that the best method to automatically evaluate and
score Text-Input Problems using LLMs is Reference Aided Evaluation. With the
lowest median absolute deviation (0.945) and the lowest root mean square
deviation (1.214) when compared to human evaluation, Reference Aided Evaluation
offers fair scoring as well as insightful and complete evaluations. Other
methods such as Additive and Adaptive Evaluation fail to provide good results
in concise answers, No Reference Evaluation lacks information needed to
correctly assess questions and JudgeLM Evaluations have not provided good
results due to the model's limitations. As a result, we conclude that
Artificial Intelligence-driven automatic evaluation systems, aided with proper
methodologies, show potential to work as complementary tools to other academic
resources.

</details>


### [128] [Generative AI for FFRDCs](https://arxiv.org/abs/2509.21040)
*Arun S. Maiya*

Main category: cs.CL

TL;DR: 通过使用OnPrem.LLM等开源框架，结合少数示例，可以加速对国防政策文件和科学文献等文本繁重工作负载的摘要、分类、提取和分析，从而在不影响数据主权和可审计性的前提下，提高政府敏感环境下的洞察力和战略分析能力。


<details>
  <summary>Details</summary>
Motivation: 联邦资助的研究与开发中心（FFRDC）面临着海量的文本分析工作，手动处理效率低下，需要加速处理。

Method: 利用大型语言模型（LLM）和开源框架OnPrem.LLM，通过少量示例输入输出来实现摘要、分类、提取和意义分析。

Result: 在国防政策文件（如NDAA）和科学文献（如NSF奖项）的案例研究中，证明了该方法能够提高监督和战略分析的效率。

Conclusion: 在不影响数据主权和可审计性的前提下，利用LLM和OnPrem.LLM可以有效加速FFRDC的文本分析工作，增强其在敏感政府环境下的能力。

Abstract: Federally funded research and development centers (FFRDCs) face text-heavy
workloads, from policy documents to scientific and engineering papers, that are
slow to analyze manually. We show how large language models can accelerate
summarization, classification, extraction, and sense-making with only a few
input-output examples. To enable use in sensitive government contexts, we apply
OnPrem$.$LLM, an open-source framework for secure and flexible application of
generative AI. Case studies on defense policy documents and scientific corpora,
including the National Defense Authorization Act (NDAA) and National Science
Foundation (NSF) Awards, demonstrate how this approach enhances oversight and
strategic analysis while maintaining auditability and data sovereignty.

</details>


### [129] [Behind RoPE: How Does Causal Mask Encode Positional Information?](https://arxiv.org/abs/2509.21042)
*Junu Kim,Xiao Liu,Zhenghao Lin,Lei Ji,Yeyun Gong,Edward Choi*

Main category: cs.CL

TL;DR: Transformer解码器中的因果掩码（causal mask）本身就能提供位置信息，并可能诱导模型偏爱关注邻近的查询-键对，这种现象在实际模型中也得到了验证，甚至会扭曲显式位置编码（如RoPE）的行为。


<details>
  <summary>Details</summary>
Motivation: Transformer解码器中的因果掩码（causal mask）除了显式位置编码（如RoPE）外，也提供了位置信息。本研究旨在证明因果掩码能够诱导产生依赖于位置的注意力分数模式，即使在没有参数或因果依赖的情况下也是如此。

Method: 理论分析表明，因果掩码诱导的注意力模式倾向于偏爱邻近的查询-键对。通过经验分析，验证了训练好的模型也表现出这种行为，并且学习到的参数会进一步增强这些模式。

Result: 我们发现因果掩码和RoPE的相互作用会将RoPE的相对注意力分数模式扭曲为非相对模式。在现代大型语言模型中观察到这一效应，表明因果掩码是除显式位置编码外，一个重要的位置信息来源。

Conclusion: 因果掩码是Transformer解码器中一个不容忽视的位置信息来源，它不仅能独立地诱导位置依赖模式，还会与显式位置编码（如RoPE）相互作用，影响其行为。因此，在分析和设计Transformer模型时，应同时考虑因果掩码和显式位置编码的作用。

Abstract: While explicit positional encodings such as RoPE are a primary source of
positional information in Transformer decoders, the causal mask also provides
positional information. In this work, we prove that the causal mask can induce
position-dependent patterns in attention scores, even without parameters or
causal dependency in the input. Our theoretical analysis indicates that the
induced attention pattern tends to favor nearby query-key pairs, mirroring the
behavior of common positional encodings. Empirical analysis confirms that
trained models exhibit the same behavior, with learned parameters further
amplifying these patterns. Notably, we found that the interaction of causal
mask and RoPE distorts RoPE's relative attention score patterns into
non-relative ones. We consistently observed this effect in modern large
language models, suggesting the importance of considering the causal mask as a
source of positional information alongside explicit positional encodings.

</details>


### [130] [When Instructions Multiply: Measuring and Estimating LLM Capabilities of Multiple Instructions Following](https://arxiv.org/abs/2509.21051)
*Keno Harada,Yudai Yamazaki,Masachika Taniguchi,Edison Marrese-Taylor,Takeshi Kojima,Yusuke Iwasawa,Yutaka Matsuo*

Main category: cs.CL

TL;DR: LLMs在遵循多条指令时，指令数量越多，性能越差。研究者开发了新的基准测试集（ManyIFEval和StyleMBPP）来评估这一能力，并提出了回归模型来预测LLM在不同指令组合下的性能。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在现实世界中的应用越来越广泛，理解其同时遵循多条指令的能力至关重要。

Method: 引入了ManyIFEval和StyleMBPP两个基准测试集，分别用于文本生成和代码生成，评估LLMs遵循多条指令的能力。并开发了三种回归模型来预测LLMs在未见过指令组合和不同指令数量下的性能。

Result: 实验表明，LLMs在遵循多条指令时，性能随指令数量的增加而下降。所提出的回归模型可以有效地预测LLMs的性能，其中仅使用指令数量作为解释变量的逻辑回归模型预测误差约为10%，并且只需要相对较小的样本量。

Conclusion: LLMs在遵循多条指令方面的能力会随着指令数量的增加而受到影响。研究者提出的基准测试集和回归模型能够有效地评估和预测LLMs在多指令遵循任务上的表现，为LLM的实际应用提供了参考。

Abstract: As large language models (LLMs) are increasingly applied to real-world
scenarios, it becomes crucial to understand their ability to follow multiple
instructions simultaneously. To systematically evaluate these capabilities, we
introduce two specialized benchmarks for fundamental domains where multiple
instructions following is important: Many Instruction-Following Eval
(ManyIFEval) for text generation with up to ten instructions, and Style-aware
Mostly Basic Programming Problems (StyleMBPP) for code generation with up to
six instructions. Our experiments with the created benchmarks across ten LLMs
reveal that performance consistently degrades as the number of instructions
increases. Furthermore, given the fact that evaluating all the possible
combinations of multiple instructions is computationally impractical in actual
use cases, we developed three types of regression models that can estimate
performance on both unseen instruction combinations and different numbers of
instructions which are not used during training. We demonstrate that a logistic
regression model using instruction count as an explanatory variable can predict
performance of following multiple instructions with approximately 10% error,
even for unseen instruction combinations. We show that relatively modest sample
sizes (500 for ManyIFEval and 300 for StyleMBPP) are sufficient for performance
estimation, enabling efficient evaluation of LLMs under various instruction
combinations.

</details>


### [131] [SoM-1K: A Thousand-Problem Benchmark Dataset for Strength of Materials](https://arxiv.org/abs/2509.21079)
*Qixin Wan,Zilong Wang,Jingwen Zhou,Wanting Wang,Ziheng Geng,Jiachen Liu,Ran Cao,Minghui Cheng,Lu Cheng*

Main category: cs.CL

TL;DR: 该研究提出了SoM-1K，一个包含1065个结构力学问题的多模态数据集，用于评估基础模型在工程问题上的表现。由于现有模型在理解复杂视觉信息方面存在局限，研究者提出了一种名为DoI（图像描述）的新提示策略，用专家生成的文本描述代替图像。结果显示，当前基础模型在这些问题上的表现不佳，准确率最高仅为56.6%。有趣的是，添加DoI的LLM模型的表现优于直接输入图像的VLM模型，表明准确的文本描述比直接图像输入更能有效缓解视觉误解。


<details>
  <summary>Details</summary>
Motivation: 评估基础模型在结构力学等复杂多模态工程问题上的能力，并为该领域建立一个严格的基准。

Method: 创建SoM-1K数据集（包含1065个带注释的结构力学问题，包含文本和图示）。提出DoI（图像描述）提示策略，用专家生成的文本描述代替图示。评估八种代表性基础模型（LLM和VLM）。

Result: 当前基础模型在结构力学问题上的表现不佳，最高准确率仅为56.6%。添加DoI的LLM模型表现优于直接输入图像的VLM模型。DoI策略能有效减少视觉误解错误。

Conclusion: 目前的LMM和VLM在处理复杂的工程问题方面能力有限。DoI策略证明了文本描述在弥补当前模型视觉理解不足方面的有效性。需要开发更强大的多模态推理能力，特别是在科学和工程领域。

Abstract: Foundation models have shown remarkable capabilities in various domains, but
their performance on complex, multimodal engineering problems remains largely
unexplored. We introduce SoM-1K, the first large-scale multimodal benchmark
dataset dedicated to evaluating foundation models on problems in the strength
of materials (SoM). The dataset, which contains 1,065 annotated SoM problems,
mirrors real-world engineering tasks by including both textual problem
statements and schematic diagrams. Due to the limited capabilities of current
foundation models in understanding complicated visual information, we propose a
novel prompting strategy called Descriptions of Images (DoI), which provides
rigorous expert-generated text descriptions of the visual diagrams as the
context. We evaluate eight representative foundation models, including both
large language models (LLMs) and vision language models (VLMs). Our results
show that current foundation models struggle significantly with these
engineering problems, with the best-performing model achieving only 56.6%
accuracy. Interestingly, we found that LLMs, when provided with DoI, often
outperform VLMs provided with visual diagrams. A detailed error analysis
reveals that DoI plays a crucial role in mitigating visual misinterpretation
errors, suggesting that accurate text-based descriptions can be more effective
than direct image input for current foundation models. This work establishes a
rigorous benchmark for engineering AI and highlights a critical need for
developing more robust multimodal reasoning capabilities in foundation models,
particularly in scientific and engineering contexts.

</details>


### [132] [Which Cultural Lens Do Models Adopt? On Cultural Positioning Bias and Agentic Mitigation in LLMs](https://arxiv.org/abs/2509.21080)
*Yixin Wan,Xingrun Chen,Kai-Wei Chang*

Main category: cs.CL

TL;DR: LLMs 存在文化定位偏见，会从主流美国文化视角生成内容，并对非主流文化表现出外围化。本研究提出了 CultureLens 基准测试来量化此偏见，并提出 FIP 和 MFA（包括 MFA-SA 和 MFA-MA）两种缓解方法，其中基于多智能体的 MFA 方法效果显著。


<details>
  <summary>Details</summary>
Motivation: LLMs 在生成内容时，会不自觉地带有主流美国文化视角，对非主流文化存在偏见，将其他文化视为‘外来者’。

Method: 提出了 CultureLens 基准测试，包含 4000 个生成提示和 3 个评估指标，通过模拟跨文化采访来量化文化定位偏见。并提出了两种缓解方法：基于提示的 FIP 方法，以及包含单智能体和多智能体两种模式的 MFA 框架（MFA-SA 和 MFA-MA）。

Result: 在 5 个最先进的 LLMs 上进行评估，发现在涉及美国文化时，模型有 88% 的概率采用‘内部人士’的口吻，而对于非主流文化，则主要采用‘外部人士’的口吻。

Conclusion: 基于智能体的缓解方法（特别是 MFA）是一种有前景的解决生成式 LLMs 中文化偏见问题的方法。

Abstract: Large language models (LLMs) have unlocked a wide range of downstream
generative applications. However, we found that they also risk perpetuating
subtle fairness issues tied to culture, positioning their generations from the
perspectives of the mainstream US culture while demonstrating salient
externality towards non-mainstream ones. In this work, we identify and
systematically investigate this novel culture positioning bias, in which an
LLM's default generative stance aligns with a mainstream view and treats other
cultures as outsiders. We propose the CultureLens benchmark with 4000
generation prompts and 3 evaluation metrics for quantifying this bias through
the lens of a culturally situated interview script generation task, in which an
LLM is positioned as an onsite reporter interviewing local people across 10
diverse cultures. Empirical evaluation on 5 state-of-the-art LLMs reveals a
stark pattern: while models adopt insider tones in over 88 percent of
US-contexted scripts on average, they disproportionately adopt mainly outsider
stances for less dominant cultures. To resolve these biases, we propose 2
inference-time mitigation methods: a baseline prompt-based Fairness
Intervention Pillars (FIP) method, and a structured Mitigation via Fairness
Agents (MFA) framework consisting of 2 pipelines: (1) MFA-SA (Single-Agent)
introduces a self-reflection and rewriting loop based on fairness guidelines.
(2) MFA-MA (Multi-Agent) structures the process into a hierarchy of specialized
agents: a Planner Agent(initial script generation), a Critique Agent (evaluates
initial script against fairness pillars), and a Refinement Agent (incorporates
feedback to produce a polished, unbiased script). Empirical results showcase
the effectiveness of agent-based methods as a promising direction for
mitigating biases in generative LLMs.

</details>


### [133] [PerHalluEval: Persian Hallucination Evaluation Benchmark for Large Language Models](https://arxiv.org/abs/2509.21104)
*Mohammad Hosseini,Kimia Hosseini,Shayan Bali,Zahra Zanjani,Saeedeh Momtazi*

Main category: cs.CL

TL;DR: 该研究提出了PerHalluEval，一个针对波斯语的动态幻觉评估基准，并评估了12种语言模型的表现，发现它们在检测波斯语幻觉方面普遍存在困难。


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言（如波斯语）的大语言模型（LLM）中普遍存在的幻觉问题，并提出首个针对波斯语的动态幻觉评估基准。

Method: 利用一个三阶段的、由LLM驱动并辅以人工验证的流程来生成QA和摘要任务的答案和摘要，以检测外在和内在幻觉。通过对生成token的对数概率进行选择，筛选出最可信的幻觉实例。通过人工标注波斯语特定上下文来评估模型在处理与波斯文化相关内容时的表现。

Result: 评估结果显示，12种语言模型在检测波斯语幻觉文本方面普遍表现不佳。提供外部知识（如摘要任务的原文）可以部分缓解幻觉问题。专门为波斯语训练的模型与通用模型在幻觉方面的表现没有显著差异。

Conclusion: 现有的语言模型在处理波斯语时存在严重的幻觉问题，需要进一步的研究来提高其性能。提供外部知识和关注特定语言文化背景可能有助于缓解这一问题。

Abstract: Hallucination is a persistent issue affecting all large language Models
(LLMs), particularly within low-resource languages such as Persian.
PerHalluEval (Persian Hallucination Evaluation) is the first dynamic
hallucination evaluation benchmark tailored for the Persian language. Our
benchmark leverages a three-stage LLM-driven pipeline, augmented with human
validation, to generate plausible answers and summaries regarding QA and
summarization tasks, focusing on detecting extrinsic and intrinsic
hallucinations. Moreover, we used the log probabilities of generated tokens to
select the most believable hallucinated instances. In addition, we engaged
human annotators to highlight Persian-specific contexts in the QA dataset in
order to evaluate LLMs' performance on content specifically related to Persian
culture. Our evaluation of 12 LLMs, including open- and closed-source models
using PerHalluEval, revealed that the models generally struggle in detecting
hallucinated Persian text. We showed that providing external knowledge, i.e.,
the original document for the summarization task, could mitigate hallucination
partially. Furthermore, there was no significant difference in terms of
hallucination when comparing LLMs specifically trained for Persian with others.

</details>


### [134] [BESPOKE: Benchmark for Search-Augmented Large Language Model Personalization via Diagnostic Feedback](https://arxiv.org/abs/2509.21106)
*Hyunseo Kim,Sangam Lee,Kwangwook Seo,Dongha Lee*

Main category: cs.CL

TL;DR: 搜索增强型大语言模型（LLM）通过整合检索与生成来改进信息检索任务，但它们在满足多样化用户需求方面仍显不足，这需要识别同一查询如何反映不同用户的不同意图，并以用户偏好的形式提供信息。为了解决这个差距，我们提出了BESPOKE，一个用于评估搜索增强型LLM个性化的现实基准。BESPOKE通过收集真实的用户聊天和搜索历史，并与细粒度的偏好分数和反馈配对响应，从而设计得既现实又具诊断性。利用BESPOKE，我们进行了系统的分析，揭示了信息检索任务中有效个性化的关键要求，为个性化搜索增强型LLM的细粒度评估奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 传统的搜索系统和现有的搜索增强型LLM在满足多样化的用户需求方面存在不足，尤其是在理解同一查询背后可能存在的不同用户意图以及以用户偏好的形式提供信息方面。此外，现有系统（如ChatGPT和Gemini）虽然尝试通过用户历史记录进行个性化，但对其进行系统性评估的研究尚不充分。

Method: 提出BESPOKE，一个包含真实用户聊天和搜索历史的现实基准，用于评估搜索增强型LLM的个性化。通过长期、深入的人工标注来构建该基准，标注者贡献自己的历史记录、撰写带有详细信息需求的查询，并对响应进行评分和提供诊断反馈。

Result: 利用BESPOKE基准进行了系统的分析，揭示了信息检索任务中有效个性化的关键要求。

Conclusion: BESPOKE基准的提出和分析为评估个性化搜索增强型LLM奠定了基础，为未来研究提供了方向。

Abstract: Search-augmented large language models (LLMs) have advanced
information-seeking tasks by integrating retrieval into generation, reducing
users' cognitive burden compared to traditional search systems. Yet they remain
insufficient for fully addressing diverse user needs, which requires
recognizing how the same query can reflect different intents across users and
delivering information in preferred forms. While recent systems such as ChatGPT
and Gemini attempt personalization by leveraging user histories, systematic
evaluation of such personalization is under-explored. To address this gap, we
propose BESPOKE, the realistic benchmark for evaluating personalization in
search-augmented LLMs. BESPOKE is designed to be both realistic, by collecting
authentic chat and search histories directly from humans, and diagnostic, by
pairing responses with fine-grained preference scores and feedback. The
benchmark is constructed through long-term, deeply engaged human annotation,
where human annotators contributed their own histories, authored queries with
detailed information needs, and evaluated responses with scores and diagnostic
feedback. Leveraging BESPOKE, we conduct systematic analyses that reveal key
requirements for effective personalization in information-seeking tasks,
providing a foundation for fine-grained evaluation of personalized
search-augmented LLMs. Our code and data are available at
https://augustinlib.github.io/BESPOKE/.

</details>


### [135] [VoiceBBQ: Investigating Effect of Content and Acoustics in Social Bias of Spoken Language Model](https://arxiv.org/abs/2509.21108)
*Junhyuk Choi,Ro-hoon Oh,Jihwan Seol,Bugeun Kim*

Main category: cs.CL

TL;DR: VoiceBBQ是一个用于评估口语语言模型（SLM）社会偏见的评估基准，区分了内容偏见和声学偏见。


<details>
  <summary>Details</summary>
Motivation: 由于语音的性质，社会偏见在口语语言模型（SLM）中可能源于内容和声学两个方面。

Method: 通过将BBQ（偏见基准测试用于问答）数据集转换为受控的语音条件，创建了VoiceBBQ数据集，并使用该数据集评估了LLaMA-Omni和Qwen2-Audio两个SLM。

Result: 评估结果显示，LLaMA-Omni模型能够抵抗声学偏见但会放大性别和口音偏见，而Qwen2-Audio模型则能显著抑制这些偏见，同时保持内容保真度。

Conclusion: VoiceBBQ提供了一个方便的测试平台，用于联合诊断口语语言模型的内容和声学偏见。

Abstract: We introduce VoiceBBQ, a spoken extension of the BBQ (Bias Benchmark for
Question Answering) - a dataset that measures social bias by presenting
ambiguous or disambiguated contexts followed by questions that may elicit
stereotypical responses. Due to the nature of speech, social bias in Spoken
Language Models (SLMs) can emerge from two distinct sources: 1) content aspect
and 2) acoustic aspect. The dataset converts every BBQ context into controlled
voice conditions, enabling per-axis accuracy, bias, and consistency scores that
remain comparable to the original text benchmark. Using VoiceBBQ, we evaluate
two SLMs - LLaMA-Omni and Qwen2-Audio - and observe architectural contrasts:
LLaMA-Omni resists acoustic bias while amplifying gender and accent bias,
whereas Qwen2-Audio substantially dampens these cues while preserving content
fidelity. VoiceBBQ thus provides a compact, drop-in testbed for jointly
diagnosing content and acoustic bias across spoken language models.

</details>


### [136] [Acoustic-based Gender Differentiation in Speech-aware Language Models](https://arxiv.org/abs/2509.21125)
*Junhyuk Choi,Jihwan Seol,Nayeon Kim,Chanhee Cho,EunBin Cho,Bugeun Kim*

Main category: cs.CL

TL;DR: 该研究提出了一个包含9,208个语音样本的数据集，用于分析语音感知语言模型（SpeechLMs）中的性别差异现象。研究发现LLaMA-Omni系列模型在面对性别刻板印象问题时表现出男性导向的回答，而在性别相关问题上则表现出性别无关的回答，这与预期相反。这种现象并非源于中性选项或语音感知性别，而是主要由Whisper语音编码器产生男性导向的声学标记所致。研究强调了现有SpeechLMs在去除性别偏见方面存在不足，需要更先进的技术来恰当利用性别信息。


<details>
  <summary>Details</summary>
Motivation: 当前语音感知语言模型（SpeechLMs）在实现语音交互的同时，可能存在基于性别的回应差异，即相同的输入可能因说话者性别不同而产生不同的回应。本研究旨在通过构建一个数据集来系统地分析这一现象。

Method: 构建了一个包含9,208个语音样本的数据集，分为性别无关、性别刻板和性别相关三类。对LLaMA-Omni系列模型进行了评估，并与相应的骨干语言模型（LLMs）进行了比较，特别关注了Whisper语音编码器的作用。

Result: 评估结果显示，LLaMA-Omni系列模型在性别刻板问题上倾向于提供男性导向的回答，而在性别相关问题上则提供性别无关的回答。这种模式并非由中性选项或语音感知性别引起。研究发现，Whisper语音编码器产生的男性导向声学标记是导致这种悖论模式的主要原因。

Conclusion: 现有SpeechLMs在处理性别信息时，可能优先考虑通用公平性而非情境适当性，导致了悖论式的性别偏见。Whisper语音编码器是产生这种偏见的主要来源。这表明需要开发更复杂的技术来妥善处理语音技术中的性别信息，以实现真正的公平性和情境适应性。

Abstract: Speech-aware Language Models (SpeechLMs) have fundamentally transformed
human-AI interaction by enabling voice-based communication, yet they may
exhibit acoustic-based gender differentiation where identical questions lead to
different responses based on the speaker's gender. This paper propose a new
dataset that enables systematic analysis of this phenomenon, containing 9,208
speech samples across three categories: Gender-Independent,
Gender-Stereotypical, and Gender-Dependent. We further evaluated LLaMA-Omni
series and discovered a paradoxical pattern; while overall responses seems
identical regardless of gender, the pattern is far from unbiased responses.
Specifically, in Gender-Stereotypical questions, all models consistently
exhibited male-oriented responses; meanwhile, in Gender-Dependent questions
where gender differentiation would be contextually appropriate, models
exhibited responses independent to gender instead. We also confirm that this
pattern does not result from neutral options nor perceived gender of a voice.
When we allow neutral response, models tends to respond neutrally also in
Gender-Dependent questions. The paradoxical pattern yet retains when we applied
gender neutralization methods on speech. Through comparison between SpeechLMs
with corresponding backbone LLMs, we confirmed that these paradoxical patterns
primarily stem from Whisper speech encoders, which generates male-oriented
acoustic tokens. These findings reveal that current SpeechLMs may not
successfully remove gender biases though they prioritized general fairness
principles over contextual appropriateness, highlighting the need for more
sophisticated techniques to utilize gender information properly in speech
technology.

</details>


### [137] [AutoIntent: AutoML for Text Classification](https://arxiv.org/abs/2509.21138)
*Ilya Alekseev,Roman Solomatin,Darina Rustamova,Denis Kuznetsov*

Main category: cs.CL

TL;DR: AutoIntent 是一个端到端的自动化机器学习工具，用于文本分类任务，特别是意图分类，支持多标签分类和范围外检测，并在性能和资源消耗之间提供平衡。


<details>
  <summary>Details</summary>
Motivation: 旨在提供一个端到端的自动化机器学习工具，用于文本分类任务，解决现有解决方案的不足，并支持多标签分类和范围外检测。

Method: 通过集成嵌入模型选择、分类器优化和决策阈值调整，提供一个模块化的、类似 sklearn 的接口来实现端到端自动化。

Result: 在标准的意图分类数据集上，AutoIntent 展现出优于现有 AutoML 工具的性能，并使用户能够在有效性和资源消耗之间进行权衡。

Conclusion: AutoIntent 是一个有效的自动化机器学习工具，用于文本分类，能够提供优于现有解决方案的性能，并具有灵活性以满足不同的需求。

Abstract: AutoIntent is an automated machine learning tool for text classification
tasks. Unlike existing solutions, AutoIntent offers end-to-end automation with
embedding model selection, classifier optimization, and decision threshold
tuning, all within a modular, sklearn-like interface. The framework is designed
to support multi-label classification and out-of-scope detection. AutoIntent
demonstrates superior performance compared to existing AutoML tools on standard
intent classification datasets and enables users to balance effectiveness and
resource consumption.

</details>


### [138] [Retrieval over Classification: Integrating Relation Semantics for Multimodal Relation Extraction](https://arxiv.org/abs/2509.21151)
*Lei Hei,Tingjing Liao,Yingxin Pei,Yiyang Qi,Jiaqi Wang,Ruiting Li,Feiliang Ren*

Main category: cs.CL

TL;DR: 该研究提出了一种名为ROC的新框架，用于解决多模态关系抽取中的局限性，取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态关系抽取方法主要采用基于分类的范式，将关系视为离散标签，忽略了实体类型和位置等结构化约束，并且缺乏细粒度关系理解的语义表达能力。

Method: ROC框架将多模态关系抽取重新构建为由关系语义驱动的检索任务。它通过多模态编码器整合实体类型和位置信息，利用大型语言模型将关系标签扩展为自然语言描述，并通过基于语义相似度的对比学习来对齐实体-关系对。

Result: 实验结果表明，ROC在MNRE和MORE基准数据集上达到了最先进的性能，并且表现出更强的鲁棒性和可解释性。

Conclusion: ROC框架通过将关系抽取重新定义为检索任务，并引入自然语言描述和对比学习，有效克服了现有方法的局限性，在多模态关系抽取任务上取得了显著的成果。

Abstract: Relation extraction (RE) aims to identify semantic relations between entities
in unstructured text. Although recent work extends traditional RE to multimodal
scenarios, most approaches still adopt classification-based paradigms with
fused multimodal features, representing relations as discrete labels. This
paradigm has two significant limitations: (1) it overlooks structural
constraints like entity types and positional cues, and (2) it lacks semantic
expressiveness for fine-grained relation understanding. We propose
\underline{R}etrieval \underline{O}ver \underline{C}lassification (ROC), a
novel framework that reformulates multimodal RE as a retrieval task driven by
relation semantics. ROC integrates entity type and positional information
through a multimodal encoder, expands relation labels into natural language
descriptions using a large language model, and aligns entity-relation pairs via
semantic similarity-based contrastive learning. Experiments show that our
method achieves state-of-the-art performance on the benchmark datasets MNRE and
MORE and exhibits stronger robustness and interpretability.

</details>


### [139] [Learning the Wrong Lessons: Syntactic-Domain Spurious Correlations in Language Models](https://arxiv.org/abs/2509.21155)
*Chantal Shaib,Vinith M. Suriyakumar,Levent Sagun,Byron C. Wallace,Marzyeh Ghassemi*

Main category: cs.CL

TL;DR: LLMs会学习到与领域无关的句法模板，即使这会牺牲语义理解，导致性能下降，甚至可以被用来绕过安全限制。建议显式测试句法-领域相关性并确保训练数据的句法多样性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在理解指令时可能依赖于句法模板而非语义，这会导致在特定领域出现关联，从而可能覆盖提示的真实含义。

Method: 通过合成数据集和现有模型（OLMo-2, FlanV2, Llama-4-Maverick, GPT-4o）进行实验，分析句法模板、领域和语义之间的关系，并评估句法-领域相关性对模型性能的影响，最后通过案例研究探讨其对安全微调的潜在影响。

Result: 在OLMo-2模型（1B-13B）的实体知识任务上，句法-领域相关性会降低性能（平均0.51 +/- 0.06）。该现象在FlanV2数据集的子集上，于OLMo-2-7B, Llama-4-Maverick, GPT-4o等模型中均有发现。研究还表明，这种不期望的句法-领域相关性可用于绕过OLMo-2-7B Instruct和GPT-4o的安全拒绝机制。

Conclusion: LLMs可能会学习到与领域相关的句法模板，这种“虚假关联”会损害模型性能，甚至被用于规避安全措施。因此，需要显式地测试这种句法-领域相关性，并在训练数据中确保不同领域内的句法多样性，以防止这种虚假关联的产生。

Abstract: For an LLM to correctly respond to an instruction it must understand both the
semantics and the domain (i.e., subject area) of a given task-instruction pair.
However, syntax can also convey implicit information Recent work shows that
syntactic templates--frequent sequences of Part-of-Speech (PoS) tags--are
prevalent in training data and often appear in model outputs. In this work we
characterize syntactic templates, domain, and semantics in task-instruction
pairs. We identify cases of spurious correlations between syntax and domain,
where models learn to associate a domain with syntax during training; this can
sometimes override prompt semantics. Using a synthetic training dataset, we
find that the syntactic-domain correlation can lower performance (mean 0.51 +/-
0.06) on entity knowledge tasks in OLMo-2 models (1B-13B). We introduce an
evaluation framework to detect this phenomenon in trained models, and show that
it occurs on a subset of the FlanV2 dataset in open (OLMo-2-7B;
Llama-4-Maverick), and closed (GPT-4o) models. Finally, we present a case study
on the implications for safety finetuning, showing that unintended
syntactic-domain correlations can be used to bypass refusals in OLMo-2-7B
Instruct and GPT-4o. Our findings highlight two needs: (1) to explicitly test
for syntactic-domain correlations, and (2) to ensure syntactic diversity in
training data, specifically within domains, to prevent such spurious
correlations.

</details>


### [140] [Who's Laughing Now? An Overview of Computational Humour Generation and Explanation](https://arxiv.org/abs/2509.21175)
*Tyler Loakman,William Thorne,Chenghua Lin*

Main category: cs.CL

TL;DR: Humor generation and explanation is a challenging NLP task, with current models falling short of human capabilities. Future research should consider the subjective and ethical aspects of humor.


<details>
  <summary>Details</summary>
Motivation: Humor is a fundamental human trait and a challenging NLP task, making computational humor processing important for assessing LLMs' common-sense knowledge and reasoning abilities.

Method: This paper surveys the landscape of computational humor, focusing on generative tasks of creation and explanation.

Result: Work on generating and explaining humor beyond puns is sparse, and state-of-the-art models are not yet on par with human capabilities.

Conclusion: Computational humor processing is an important NLP subdiscipline, and future research should address the subjective and ethically ambiguous nature of humor.

Abstract: The creation and perception of humour is a fundamental human trait,
positioning its computational understanding as one of the most challenging
tasks in natural language processing (NLP). As an abstract, creative, and
frequently context-dependent construct, humour requires extensive reasoning to
understand and create, making it a pertinent task for assessing the
common-sense knowledge and reasoning abilities of modern large language models
(LLMs). In this work, we survey the landscape of computational humour as it
pertains to the generative tasks of creation and explanation. We observe that,
despite the task of understanding humour bearing all the hallmarks of a
foundational NLP task, work on generating and explaining humour beyond puns
remains sparse, while state-of-the-art models continue to fall short of human
capabilities. We bookend our literature survey by motivating the importance of
computational humour processing as a subdiscipline of NLP and presenting an
extensive discussion of future directions for research in the area that takes
into account the subjective and ethically ambiguous nature of humour.

</details>


### [141] [GEP: A GCG-Based method for extracting personally identifiable information from chatbots built on small language models](https://arxiv.org/abs/2509.21192)
*Jieli Zhu,Vi Ngoc-Nha Tran*

Main category: cs.CL

TL;DR: 小型语言模型（SLMs）在某些领域与大型语言模型（LLMs）性能相当，但训练和推理的能耗和时间更少。本研究首次探讨了 SLMs 在下游任务中存在的个人身份信息（PII）泄露问题。研究人员微调了一个基于 BioGPT 的医疗聊天机器人 ChatBioGPT，并证明了先前基于模板的 PII 提取方法在 SLM 条件下效果不佳。为此，他们提出了一种名为 GEP 的新方法，该方法能够更有效地提取 PII，相比先前方法，PII 泄露量增加了高达 60 倍。即使在更复杂、更现实的自由形式插入场景下，GEP 仍能揭示高达 4.53% 的 PII 泄露率。


<details>
  <summary>Details</summary>
Motivation: 虽然小型语言模型（SLMs）在效率上优于大型语言模型（LLMs），但其个人身份信息（PII）泄露问题尚未得到充分研究，特别是在下游应用中。本研究旨在填补这一空白，并评估聊天机器人中 SLM 的 PII 泄露风险。

Method: 首先，研究人员微调了一个名为 ChatBioGPT 的医疗聊天机器人。然后，他们评估了现有的基于模板的 PII 提取方法在 SLM 条件下的有效性。最后，他们提出了一种新的、基于贪心坐标梯度（GCG）的 PII 提取方法 GEP，并对其在标准和自由格式 PII 插入场景下的性能进行了评估。

Result: 基于模板的方法在 SLM 条件下无法有效提取 PII。新提出的 GEP 方法比先前的方法能多提取高达 60 倍的 PII。在更真实的自由格式 PII 插入场景下，GEP 仍能实现高达 4.53% 的 PII 泄露率。

Conclusion: 本研究首次证明了基于小型语言模型（SLM）的聊天机器人在 PII 泄露方面存在显著风险。所提出的 GEP 方法能够有效地从 SLMs 中提取 PII，即使在复杂的现实场景下也是如此，这表明需要开发新的防御策略来保护 SLMs 中的敏感信息。

Abstract: Small language models (SLMs) become unprecedentedly appealing due to their
approximately equivalent performance compared to large language models (LLMs)
in certain fields with less energy and time consumption during training and
inference. However, the personally identifiable information (PII) leakage of
SLMs for downstream tasks has yet to be explored. In this study, we investigate
the PII leakage of the chatbot based on SLM. We first finetune a new chatbot,
i.e., ChatBioGPT based on the backbone of BioGPT using medical datasets Alpaca
and HealthCareMagic. It shows a matchable performance in BERTscore compared
with previous studies of ChatDoctor and ChatGPT. Based on this model, we prove
that the previous template-based PII attacking methods cannot effectively
extract the PII in the dataset for leakage detection under the SLM condition.
We then propose GEP, which is a greedy coordinate gradient-based (GCG) method
specifically designed for PII extraction. We conduct experimental studies of
GEP and the results show an increment of up to 60$\times$ more leakage compared
with the previous template-based methods. We further expand the capability of
GEP in the case of a more complicated and realistic situation by conducting
free-style insertion where the inserted PII in the dataset is in the form of
various syntactic expressions instead of fixed templates, and GEP is still able
to reveal a PII leakage rate of up to 4.53%.

</details>


### [142] [Eigen-1: Adaptive Multi-Agent Refinement with Monitor-Based RAG for Scientific Reasoning](https://arxiv.org/abs/2509.21193)
*Xiangru Tang,Wanghan Xu,Yujie Wang,Zijie Guo,Daniel Shao,Jiapeng Chen,Cixuan Zhang,Ziyi Wang,Lixin Zhang,Guancheng Wan,Wenlong Zhang,Lei Bai,Zhenfei Yin,Philip Torr,Hanrui Wang,Di Jin*

Main category: cs.CL

TL;DR: 该研究提出了一个统一的框架，结合了隐式检索和结构化协作，以解决大型语言模型在科学推理中的瓶颈，取得了显著的性能提升和效率改进。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在科学推理方面取得了进展，但存在显式检索引入的“工具税”和多智能体流水线中解决方案被稀释的问题。

Method: 提出了一种统一框架，包括基于监视器的令牌级检索模块（用于隐式检索）和层次化解决方案优化（HSR）与质量感知迭代推理（QAIR）相结合的结构化协作。

Result: 在 Humanity's Last Exam (HLE) Bio/Chem Gold 数据集上，该框架实现了 48.3% 的准确率，显著优于现有基线和前沿大型语言模型，同时减少了代币使用量和智能体步数。在 SuperGPQA 和 TRQA 数据集上也验证了其鲁棒性。错误分析表明，推理失败和知识差距共同存在于 85% 的案例中，检索任务受益于解决方案的多样性，而推理任务则倾向于共识。

Conclusion: 隐式增强和结构化优化能够克服显式工具使用和统一聚合的低效率，为大型语言模型在科学推理中的应用提供了新的方向。

Abstract: Large language models (LLMs) have recently shown strong progress on
scientific reasoning, yet two major bottlenecks remain. First, explicit
retrieval fragments reasoning, imposing a hidden "tool tax" of extra tokens and
steps. Second, multi-agent pipelines often dilute strong solutions by averaging
across all candidates. We address these challenges with a unified framework
that combines implicit retrieval and structured collaboration. At its
foundation, a Monitor-based retrieval module operates at the token level,
integrating external knowledge with minimal disruption to reasoning. On top of
this substrate, Hierarchical Solution Refinement (HSR) iteratively designates
each candidate as an anchor to be repaired by its peers, while Quality-Aware
Iterative Reasoning (QAIR) adapts refinement to solution quality. On Humanity's
Last Exam (HLE) Bio/Chem Gold, our framework achieves 48.3\% accuracy -- the
highest reported to date, surpassing the strongest agent baseline by 13.4
points and leading frontier LLMs by up to 18.1 points, while simultaneously
reducing token usage by 53.5\% and agent steps by 43.7\%. Results on SuperGPQA
and TRQA confirm robustness across domains. Error analysis shows that reasoning
failures and knowledge gaps co-occur in over 85\% of cases, while diversity
analysis reveals a clear dichotomy: retrieval tasks benefit from solution
variety, whereas reasoning tasks favor consensus. Together, these findings
demonstrate how implicit augmentation and structured refinement overcome the
inefficiencies of explicit tool use and uniform aggregation. Code is available
at: https://github.com/tangxiangru/Eigen-1.

</details>


### [143] [CLaw: Benchmarking Chinese Legal Knowledge in Large Language Models - A Fine-grained Corpus and Reasoning Analysis](https://arxiv.org/abs/2509.21208)
*Xinzhe Xu,Liang Zhao,Hongshen Xu,Chen Chen*

Main category: cs.CL

TL;DR: CLaw是一个评估大语言模型（LLM）在中国法律知识和推理能力的基准，包含306部中国国家法规的细粒度语料库和254个案例推理实例。


<details>
  <summary>Details</summary>
Motivation: 评估大语言模型（LLM）在中国法律文本分析和相关法律法规引用方面的可靠性，现有模型因通用预训练而缺乏专门的法律知识。

Method: 构建了一个名为CLaw的新基准，包含两个部分：1.一个包含306部中国国家法规的细粒度语料库（64,849条），精确到子条款级别并包含历史修订时间戳。2.254个基于中国最高人民法院案例的推理实例。

Result: 大多数当前LLM在准确复述法律条文方面存在显著困难，这严重影响了它们在法律推理中的可靠性。

Conclusion: 值得信赖的法律推理需要准确的知识检索（可通过SFT或RAG增强）和强大的通用推理能力的协同作用。CLaw基准为该领域的研究提供了重要资源。

Abstract: Large Language Models (LLMs) are increasingly tasked with analyzing legal
texts and citing relevant statutes, yet their reliability is often compromised
by general pre-training that ingests legal texts without specialized focus,
obscuring the true depth of their legal knowledge. This paper introduces CLaw,
a novel benchmark specifically engineered to meticulously evaluate LLMs on
Chinese legal knowledge and its application in reasoning. CLaw comprises two
key components: (1) a comprehensive, fine-grained corpus of all 306 Chinese
national statutes, segmented to the subparagraph level and incorporating
precise historical revision timesteps for rigorous recall evaluation (64,849
entries), and (2) a challenging set of 254 case-based reasoning instances
derived from China Supreme Court curated materials to assess the practical
application of legal knowledge. Our empirical evaluation reveals that most
contemporary LLMs significantly struggle to faithfully reproduce legal
provisions. As accurate retrieval and citation of legal provisions form the
basis of legal reasoning, this deficiency critically undermines the reliability
of their responses. We contend that achieving trustworthy legal reasoning in
LLMs requires a robust synergy of accurate knowledge retrieval--potentially
enhanced through supervised fine-tuning (SFT) or retrieval-augmented generation
(RAG)--and strong general reasoning capabilities. This work provides an
essential benchmark and critical insights for advancing domain-specific LLM
reasoning, particularly within the complex legal sphere.

</details>


### [144] [SGMem: Sentence Graph Memory for Long-Term Conversational Agents](https://arxiv.org/abs/2509.21212)
*Yaxiong Wu,Yongyue Zhang,Sheng Liang,Yong Liu*

Main category: cs.CL

TL;DR: 现有的长期对话记忆管理方法难以处理对话历史，SGMem（句子图记忆）通过构建句子级图来组织和检索对话信息，并在LongMemEval和LoCoMo上实验证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 长时对话需要有效的记忆管理来处理超出LLM上下文窗口的对话历史，现有方法在组织和检索多粒度信息方面存在不足。

Method: SGMem将对话表示为句子级图，并结合检索到的原始对话和生成的记忆（摘要、事实、见解）来为LLM提供连贯相关的上下文。

Result: 在LongMemEval和LoCoMo上的实验表明，SGMem能够持续提高长期对话问答的准确性，并优于现有基线方法。

Conclusion: SGMem通过构建句子图来有效管理长期对话记忆，能够为LLM提供连贯且相关的上下文，从而在长期对话问答任务中取得更好的表现。

Abstract: Long-term conversational agents require effective memory management to handle
dialogue histories that exceed the context window of large language models
(LLMs). Existing methods based on fact extraction or summarization reduce
redundancy but struggle to organize and retrieve relevant information across
different granularities of dialogue and generated memory. We introduce SGMem
(Sentence Graph Memory), which represents dialogue as sentence-level graphs
within chunked units, capturing associations across turn-, round-, and
session-level contexts. By combining retrieved raw dialogue with generated
memory such as summaries, facts and insights, SGMem supplies LLMs with coherent
and relevant context for response generation. Experiments on LongMemEval and
LoCoMo show that SGMem consistently improves accuracy and outperforms strong
baselines in long-term conversational question answering.

</details>


### [145] [Query-Centric Graph Retrieval Augmented Generation](https://arxiv.org/abs/2509.21237)
*Yaxiong Wu,Jianyuan Bo,Yongyue Zhang,Sheng Liang,Yong Liu*

Main category: cs.CL

TL;DR: QCG-RAG是一个查询驱动的图检索增强生成框架，解决了现有RAG方法在粒度上的困境，通过查询驱动的图构建和多跳检索，在问答准确性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于图的检索增强生成（RAG）方法在处理长上下文和多跳推理时，面临着粒度困境：细粒度的实体级图成本高昂且丢失上下文，而粗粒度的文档级图无法捕捉细微关系。

Method: QCG-RAG框架，采用查询驱动的方式，通过Doc2Query和Doc2Query{-}{-}构建具有可控粒度的查询驱动图，并结合定制的多跳检索机制，通过生成的查询来选择相关的文本块。

Result: 在LiHuaWorld和MultiHop-RAG数据集上的实验表明，QCG-RAG在问答准确性方面始终优于先前的基于文本块和基于图的RAG方法。

Conclusion: QCG-RAG提出了一种新的多跳推理范式，通过查询驱动的图构建和检索，解决了现有RAG方法的粒度问题，并在问答任务上取得了显著的性能提升。

Abstract: Graph-based retrieval-augmented generation (RAG) enriches large language
models (LLMs) with external knowledge for long-context understanding and
multi-hop reasoning, but existing methods face a granularity dilemma:
fine-grained entity-level graphs incur high token costs and lose context, while
coarse document-level graphs fail to capture nuanced relations. We introduce
QCG-RAG, a query-centric graph RAG framework that enables query-granular
indexing and multi-hop chunk retrieval. Our query-centric approach leverages
Doc2Query and Doc2Query{-}{-} to construct query-centric graphs with
controllable granularity, improving graph quality and interpretability. A
tailored multi-hop retrieval mechanism then selects relevant chunks via the
generated queries. Experiments on LiHuaWorld and MultiHop-RAG show that QCG-RAG
consistently outperforms prior chunk-based and graph-based RAG methods in
question answering accuracy, establishing a new paradigm for multi-hop
reasoning.

</details>


### [146] [Un-Doubling Diffusion: LLM-guided Disambiguation of Homonym Duplication](https://arxiv.org/abs/2509.21262)
*Evgeny Kaskov,Elizaveta Petrova,Petr Surovtsev,Anna Kostikova,Ilya Mistiurin,Alexander Kapitanov,Alexander Nagaev*

Main category: cs.CL

TL;DR: 同形异义词（拼写相同但含义不同）给生成模型带来挑战，扩散模型可能同时生成词语的多种含义。此外，英美中心主义导致非同形异义词在翻译成英语后变成同形异义词。本文提出了一种测量同形异义词重复率的方法，并利用视觉语言模型（VLM）和人工评估了不同的扩散模型。研究还表明，通过提示扩展可以减轻同形异义词重复问题，并有效减少与英美中心主义相关的重复。


<details>
  <summary>Details</summary>
Motivation: 同形异义词（拼写相同但含义不同）给生成模型带来挑战，尤其是在扩散模型中，可能会同时生成词语的多种含义，即“同形异义词重复”。此外，英美中心主义的偏见会使非同形异义词在翻译成英语后变成同形异义词，从而丢失其原始含义。

Method: 1. 提出一种测量同形异义词重复率的方法。 2. 使用视觉语言模型（VLM）和人工评估方法，对不同的扩散模型进行评估。 3. 探索通过提示扩展来减轻同形异义词重复问题，并验证该方法在减少英美中心主义偏见方面的有效性。

Result: 通过提示扩展的方法，不仅能有效减轻同形异义词重复问题，同时也能减少因英美中心主义偏见导致的重复问题。

Conclusion: 同形异义词重复是生成模型面临的一个挑战，而提示扩展是一种有效的缓解方法，同时也能解决英美中心主义偏见带来的问题。所提出的自动评估流程已公开。

Abstract: Homonyms are words with identical spelling but distinct meanings, which pose
challenges for many generative models. When a homonym appears in a prompt,
diffusion models may generate multiple senses of the word simultaneously, which
is known as homonym duplication. This issue is further complicated by an
Anglocentric bias, which includes an additional translation step before the
text-to-image model pipeline. As a result, even words that are not homonymous
in the original language may become homonyms and lose their meaning after
translation into English. In this paper, we introduce a method for measuring
duplication rates and conduct evaluations of different diffusion models using
both automatic evaluation utilizing Vision-Language Models (VLM) and human
evaluation. Additionally, we investigate methods to mitigate the homonym
duplication problem through prompt expansion, demonstrating that this approach
also effectively reduces duplication related to Anglocentric bias. The code for
the automatic evaluation pipeline is publicly available.

</details>


### [147] [LLM Output Homogenization is Task Dependent](https://arxiv.org/abs/2509.21267)
*Shomik Jain,Jack Lanchantin,Maximilian Nickel,Karen Ullrich,Ashia Wilson,Jamelle Watson-Daniels*

Main category: cs.CL

TL;DR: LLM输出同质化在不同任务类别下表现不同，以往研究忽视了任务依赖性。本文提出任务分类、任务锚定功能多样性评估方法、任务锚定采样技术，并论证了多样性与质量可兼得，从而改进了对LLM输出同质化的评估和缓解。


<details>
  <summary>Details</summary>
Motivation: 以往研究未能从任务依赖性的角度来概念化多样性，导致在评估和缓解LLM输出同质化时存在不足。

Method: 1. 提出包含八种任务类别的任务分类法，每种类别对输出同质化有不同的概念化理解。 2. 引入任务锚定功能多样性（task-anchored functional diversity）来评估输出同质化。 3. 提出任务锚定采样技术（task-anchored sampling technique）以在不需要多样性的情况下保持同质化，在需要多样性的情况下增加多样性。 4. 通过增加功能多样性同时保持响应质量来挑战“多样性-质量权衡”的传统观点。

Result: 1. 成功地将LLM输出同质化问题分解到不同的任务类别中。 2. 提出了一种新的评估指标——任务锚定功能多样性。 3. 开发了一种能够根据任务需求调整输出多样性的采样技术。 4. 证明了在提高输出多样性的同时，LLM的响应质量并不会受到负面影响。

Conclusion: 任务依赖性是改进LLM输出同质化评估和缓解的关键。通过考虑不同任务类别的具体需求，可以更有效地平衡多样性和响应质量。

Abstract: A large language model can be less helpful if it exhibits output response
homogenization. But whether two responses are considered homogeneous, and
whether such homogenization is problematic, both depend on the task category.
For instance, in objective math tasks, we often expect no variation in the
final answer but anticipate variation in the problem-solving strategy. Whereas,
for creative writing tasks, we may expect variation in key narrative components
(e.g. plot, genre, setting, etc), beyond the vocabulary or embedding diversity
produced by temperature-sampling. Previous work addressing output
homogenization often fails to conceptualize diversity in a task-dependent way.
We address this gap in the literature directly by making the following
contributions. (1) We present a task taxonomy comprised of eight task
categories that each have distinct conceptualizations of output homogenization.
(2) We introduce task-anchored functional diversity to better evaluate output
homogenization. (3) We propose a task-anchored sampling technique that
increases functional diversity for task categories where homogenization is
undesired, while preserving homogenization where it is desired. (4) We
challenge the perceived existence of a diversity-quality trade-off by
increasing functional diversity while maintaining response quality. Overall, we
demonstrate how task dependence improves the evaluation and mitigation of
output homogenization.

</details>


### [148] [LLMTrace: A Corpus for Classification and Fine-Grained Localization of AI-Written Text](https://arxiv.org/abs/2509.21269)
*Irina Tolstykh,Aleksandra Tsybina,Sergey Yakubson,Maksim Kuprashevich*

Main category: cs.CL

TL;DR: LLMTrace是一个大规模、双语（英语和俄语）的语料库，用于检测AI生成文本，解决了现有数据集的不足，并支持文本分类和字符级AI生成片段检测。


<details>
  <summary>Details</summary>
Motivation: 由于LLM生成文本的广泛使用，需要开发鲁棒的检测系统，但现有数据集存在模型过时、语言单一、缺乏混合作者身份以及缺少字符级标注等问题。

Method: 构建了一个大规模、双语（英语和俄语）的语料库LLMTrace，使用了多种现代LLM，包含字符级标注，用于支持文本的二元分类（人类 vs. AI）和AI生成片段检测。

Result: LLMTrace包含字符级标注，可用于训练和评估下一代更细致、更实用的AI检测模型。

Conclusion: LLMTrace通过提供多样化、高质量的训练数据，弥补了现有AI生成文本检测数据集的不足，并为未来的研究和应用提供了重要的资源。

Abstract: The widespread use of human-like text from Large Language Models (LLMs)
necessitates the development of robust detection systems. However, progress is
limited by a critical lack of suitable training data; existing datasets are
often generated with outdated models, are predominantly in English, and fail to
address the increasingly common scenario of mixed human-AI authorship.
Crucially, while some datasets address mixed authorship, none provide the
character-level annotations required for the precise localization of
AI-generated segments within a text. To address these gaps, we introduce
LLMTrace, a new large-scale, bilingual (English and Russian) corpus for
AI-generated text detection. Constructed using a diverse range of modern
proprietary and open-source LLMs, our dataset is designed to support two key
tasks: traditional full-text binary classification (human vs. AI) and the novel
task of AI-generated interval detection, facilitated by character-level
annotations. We believe LLMTrace will serve as a vital resource for training
and evaluating the next generation of more nuanced and practical AI detection
models. The project page is available at
\href{https://sweetdream779.github.io/LLMTrace-info/}{iitolstykh/LLMTrace}.

</details>


### [149] [Bounds of Chain-of-Thought Robustness: Reasoning Steps, Embed Norms, and Beyond](https://arxiv.org/abs/2509.21284)
*Dingzirui Wang,Xuanliang Zhang,Keyan Xu,Qingfu Zhu,Wanxiang Che,Yang Deng*

Main category: cs.CL

TL;DR: 输入扰动会显著影响思维链（CoT）的输出，即使是无限长的推理过程也无法完全消除这种影响。扰动的上界与推理步数呈正相关，与输入嵌入和隐藏状态向量的范数呈负相关。


<details>
  <summary>Details</summary>
Motivation: 现有的方法主要通过优化提示来缓解输入扰动对CoT输出的影响，但缺乏对其影响机制的理论解释，这阻碍了我们深入理解扰动传播过程并进一步改进提示优化方法。

Method: 理论上分析了输入扰动对CoT输出波动的影响，推导了输出波动在可接受范围内时扰动的上界，并证明了该上界与推理步数正相关，且无限长的推理过程无法消除扰动影响。将此结论应用于线性自注意力（LSA）模型，证明了扰动上界与输入嵌入和隐藏状态向量范数负相关。

Result: 通过在三个主流数据集和四个主流模型上进行实验，验证了理论分析的有效性，结果与理论分析一致。

Conclusion: 输入扰动对CoT输出的影响机制可以通过理论分析来解释，并且该影响无法通过增加推理长度来消除。对于LSA模型，模型参数的范数可以控制输入扰动的影响范围。

Abstract: Existing research indicates that the output of Chain-of-Thought (CoT) is
significantly affected by input perturbations. Although many methods aim to
mitigate such impact by optimizing prompts, a theoretical explanation of how
these perturbations influence CoT outputs remains an open area of research.
This gap limits our in-depth understanding of how input perturbations propagate
during the reasoning process and hinders further improvements in prompt
optimization methods. Therefore, in this paper, we theoretically analyze the
effect of input perturbations on the fluctuation of CoT outputs. We first
derive an upper bound for input perturbations under the condition that the
output fluctuation is within an acceptable range, based on which we prove that:
(i) This upper bound is positively correlated with the number of reasoning
steps in the CoT; (ii) Even an infinitely long reasoning process cannot
eliminate the impact of input perturbations. We then apply these conclusions to
the Linear Self-Attention (LSA) model, which can be viewed as a simplified
version of the Transformer. For the LSA model, we prove that the upper bound
for input perturbation is negatively correlated with the norms of the input
embedding and hidden state vectors. To validate this theoretical analysis, we
conduct experiments on three mainstream datasets and four mainstream models.
The experimental results align with our theoretical analysis, empirically
demonstrating the correctness of our findings.

</details>


### [150] [DisCoCLIP: A Distributional Compositional Tensor Network Encoder for Vision-Language Understanding](https://arxiv.org/abs/2509.21287)
*Kin Ian Lo,Hala Hawashin,Mina Abbaszadeh,Tilen Limback-Stokin,Hadi Wazni,Mehrnoosh Sadrzadeh*

Main category: cs.CL

TL;DR: DisCoCLIP是一个结合了CLIP视觉编码器和新型张量网络文本编码器的多模态模型，能显式编码句法结构，显著提高了在处理涉及词序和谓词-论元结构等合成推理任务上的能力。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言模型在图像-文本匹配方面表现出色，但忽视了语言的合成结构，导致在依赖词序和谓词-论元结构的任务上表现不佳。

Method: DisCoCLIP模型结合了一个固定的CLIP视觉变换器和一个新颖的张量网络文本变换器，后者显式地编码句法结构。句子通过组合范畴语法解析器进行解析，生成反映句子语法推导的词张量。为了提高效率，高阶张量通过张量分解进行因子化，将参数数量从数千万减少到一百万以下。模型使用自监督对比损失进行端到端训练。

Result: DisCoCLIP在动词语义和词序敏感性方面取得了显著的改进：它将CLIP在SVO-Probes上的动词准确率从77.6%提高到82.4%，ARO归因和关系得分分别提高了9%和4%以上，并在新引入的SVO-Swap基准测试中取得了93.7%的准确率。

Conclusion: 通过张量网络嵌入显式语言结构，可以获得可解释的、参数高效的表示，从而大大提高视觉-语言任务中的合成推理能力。

Abstract: Recent vision-language models excel at large-scale image-text alignment but
often neglect the compositional structure of language, leading to failures on
tasks that hinge on word order and predicate-argument structure. We introduce
DisCoCLIP, a multimodal encoder that combines a frozen CLIP vision transformer
with a novel tensor network text encoder that explicitly encodes syntactic
structure. Sentences are parsed with a Combinatory Categorial Grammar parser to
yield distributional word tensors whose contractions mirror the sentence's
grammatical derivation. To keep the model efficient, high-order tensors are
factorized with tensor decompositions, reducing parameter count from tens of
millions to under one million. Trained end-to-end with a self-supervised
contrastive loss, DisCoCLIP markedly improves sensitivity to verb semantics and
word order: it raises CLIP's SVO-Probes verb accuracy from 77.6% to 82.4%,
boosts ARO attribution and relation scores by over 9% and 4%, and achieves
93.7% on a newly introduced SVO-Swap benchmark. These results demonstrate that
embedding explicit linguistic structure via tensor networks yields
interpretable, parameter-efficient representations that substantially improve
compositional reasoning in vision-language tasks.

</details>


### [151] [The role of synthetic data in Multilingual, Multi-cultural AI systems: Lessons from Indic Languages](https://arxiv.org/abs/2509.21294)
*Pranjal A. Chitale,Varun Gumma,Sanchit Ahuja,Prashant Kodali,Manan Uppadhyay,Deepthi Sudharsan,Sunayana Sitaram*

Main category: cs.CL

TL;DR: 通过提示大型开源语言模型（>=235B参数）利用特定语言的维基百科内容，生成了Updesh数据集，这是一个包含9.5M数据点、涵盖13种印度语言的大规模合成指令遵循数据集，并在多语言和跨文化背景下进行了评估，证明了其在低资源语言上的有效性。


<details>
  <summary>Details</summary>
Motivation: 开发能在多语言环境中有效运行且符合当地文化习惯的AI系统，特别是在低资源环境下，一直是一个长期存在的挑战。然而，合成数据在这种多语言和多文化背景下的有效性尚未得到充分研究。

Method: 采用自下而上的生成策略，提示大型开源语言模型（>=235B参数）利用特定语言的维基百科内容来生成数据。这种方法是对当前主流的、将高资源语言（如英语）的合成数据集翻译过来的自上而下范式的一种补充。创建了一个名为Updesh的数据集，包含9.5M数据点，涵盖13种印度语言，侧重于长上下文、多轮对话能力以及与印度文化背景的融合。

Result: 通过自动化指标和人工标注（超过10k次评估）的全面评估表明，生成的数据质量很高，但人工评估也指出了进一步改进的空间。通过在Updesh数据集上微调模型并在15个不同的多语言数据集上进行评估，结果显示，在生成任务上，使用Updesh训练的模型取得了显著的提升，在多项选择式自然语言理解任务上也保持了竞争力。尤其值得注意的是，在低资源和中等资源语言上的相对改进最为明显，缩小了它们与高资源语言之间的差距。

Conclusion: 这些发现提供了实证证据，表明有效的多语言AI需要采用多方面的数据策划和生成策略，这些策略应包含具有上下文感知和文化基础的方法。

Abstract: Developing AI systems that operate effectively across languages while
remaining culturally grounded is a long-standing challenge, particularly in
low-resource settings. Synthetic data provides a promising avenue, yet its
effectiveness in multilingual and multicultural contexts remains underexplored.
We investigate the creation and impact of synthetic, culturally contextualized
datasets for Indian languages through a bottom-up generation strategy that
prompts large open-source LLMs (>= 235B parameters) to ground data generation
in language-specific Wikipedia content. This approach complements the dominant
top-down paradigm of translating synthetic datasets from high-resource
languages such as English. We introduce Updesh, a high-quality large-scale
synthetic instruction-following dataset comprising 9.5M data points across 13
Indian languages, encompassing diverse reasoning and generative tasks with an
emphasis on long-context, multi-turn capabilities, and alignment with Indian
cultural contexts. A comprehensive evaluation incorporating both automated
metrics and human annotation across 10k assessments indicates that generated
data is high quality; though, human evaluation highlights areas for further
improvement. Additionally, we perform downstream evaluations by fine-tuning
models on our dataset and assessing the performance across 15 diverse
multilingual datasets. Models trained on Updesh consistently achieve
significant gains on generative tasks and remain competitive on multiple-choice
style NLU tasks. Notably, relative improvements are most pronounced in low and
medium-resource languages, narrowing their gap with high-resource languages.
These findings provide empirical evidence that effective multilingual AI
requires multi-faceted data curation and generation strategies that incorporate
context-aware, culturally grounded methodologies.

</details>


### [152] [Sycophancy Is Not One Thing: Causal Separation of Sycophantic Behaviors in LLMs](https://arxiv.org/abs/2509.21305)
*Daniel Vennemeyer,Phan Anh Duong,Tiffany Zhan,Tianyu Jiang*

Main category: cs.CL

TL;DR: LLMs展现出奉承行为，但其机制尚不明确。研究将奉承分解为奉承性同意和奉承性赞扬，并与真诚同意进行对比。


<details>
  <summary>Details</summary>
Motivation: LLMs经常表现出奉承行为，但其具体机制尚不清楚，需要进一步研究。

Method: 通过分析不同模型和数据集中的差异、激活叠加以及子空间几何，将奉承行为分解为奉承性同意和奉承性赞扬，并与真诚同意进行对比。

Result: 研究发现，这三种行为（奉承性同意、奉承性赞扬和真诚同意）在模型的潜在空间中沿着不同的线性方向编码，并且可以被独立地增强或抑制，而不会相互影响。此外，这种表征结构在不同的模型家族和规模中保持一致。

Conclusion: LLMs中的奉承行为对应着不同的、可独立调控的表征。

Abstract: Large language models (LLMs) often exhibit sycophantic behaviors -- such as
excessive agreement with or flattery of the user -- but it is unclear whether
these behaviors arise from a single mechanism or multiple distinct processes.
We decompose sycophancy into sycophantic agreement and sycophantic praise,
contrasting both with genuine agreement. Using difference-in-means directions,
activation additions, and subspace geometry across multiple models and
datasets, we show that: (1) the three behaviors are encoded along distinct
linear directions in latent space; (2) each behavior can be independently
amplified or suppressed without affecting the others; and (3) their
representational structure is consistent across model families and scales.
These results suggest that sycophantic behaviors correspond to distinct,
independently steerable representations.

</details>


### [153] [RLBFF: Binary Flexible Feedback to bridge between Human Feedback & Verifiable Rewards](https://arxiv.org/abs/2509.21319)
*Zhilin Wang,Jiaqi Zeng,Olivier Delalleau,Ellie Evans,Daniel Egert,Hoo-Chang Shin,Felipe Soares,Yi Dong,Oleksii Kuchaiev*

Main category: cs.CL

TL;DR: RLHF and RLVR are common LLM post-training methods, but RLHF has interpretability and reward hacking issues, while RLVR is limited by correctness verifiers. We propose RLBFF, which extracts binary principles from feedback to train reward models, outperforming existing methods and allowing inference-time customization. RLBFF can align models efficiently and effectively.


<details>
  <summary>Details</summary>
Motivation: The main motivation is to address the limitations of existing Reinforcement Learning paradigms for LLM post-training, specifically the interpretability and reward hacking issues in RLHF due to human judgments lacking explicit criteria, and the limited scope of RLVR due to its focus on correctness-based verifiers. RLBFF aims to combine the strengths of both by enabling reward models to capture nuanced aspects of response quality beyond mere correctness.

Method: Reinforcement Learning with Binary Flexible Feedback (RLBFF) is proposed. This method extracts principles answerable in a binary fashion (e.g., yes/no for information accuracy or code readability) from natural language feedback. These principles are then used to train Reward Models as an entailment task, where the response either satisfies or does not satisfy a given principle. This approach allows for the incorporation of nuanced quality aspects beyond simple correctness.

Result: Reward Models trained with RLBFF outperform Bradley-Terry models when data is matched. RLBFF achieves top performance on RM-Bench (86.2%) and JudgeBench (81.4% as of September 24, 2025). Additionally, RLBFF allows users to specify principles of interest at inference time for customized reward model focus, which is not possible with Bradley-Terry models. A fully open-source recipe for aligning Qwen3-32B using RLBFF is presented, matching or exceeding the performance of o3-mini and DeepSeek R1 on general alignment benchmarks (MT-Bench, WildBench, and Arena Hard v2) at a significantly lower inference cost (<5%).

Conclusion: RLBFF offers a versatile and precise approach to LLM post-training by extracting binary principles from feedback to train robust reward models. It overcomes the limitations of RLHF and RLVR, demonstrating superior performance on benchmarks and enabling flexible customization. The method's efficiency and effectiveness are further validated by the successful alignment of Qwen3-32B at a reduced cost, making it a promising advancement in the field.

Abstract: Reinforcement Learning with Human Feedback (RLHF) and Reinforcement Learning
with Verifiable Rewards (RLVR) are the main RL paradigms used in LLM
post-training, each offering distinct advantages. However, RLHF struggles with
interpretability and reward hacking because it relies on human judgments that
usually lack explicit criteria, whereas RLVR is limited in scope by its focus
on correctness-based verifiers. We propose Reinforcement Learning with Binary
Flexible Feedback (RLBFF), which combines the versatility of human-driven
preferences with the precision of rule-based verification, enabling reward
models to capture nuanced aspects of response quality beyond mere correctness.
RLBFF extracts principles that can be answered in a binary fashion (e.g.
accuracy of information: yes, or code readability: no) from natural language
feedback. Such principles can then be used to ground Reward Model training as
an entailment task (response satisfies or does not satisfy an arbitrary
principle). We show that Reward Models trained in this manner can outperform
Bradley-Terry models when matched for data and achieve top performance on
RM-Bench (86.2%) and JudgeBench (81.4%, #1 on leaderboard as of September 24,
2025). Additionally, users can specify principles of interest at inference time
to customize the focus of our reward models, in contrast to Bradley-Terry
models. Finally, we present a fully open source recipe (including data) to
align Qwen3-32B using RLBFF and our Reward Model, to match or exceed the
performance of o3-mini and DeepSeek R1 on general alignment benchmarks of
MT-Bench, WildBench, and Arena Hard v2 (at <5% of the inference cost).

</details>


### [154] [SciReasoner: Laying the Scientific Reasoning Ground Across Disciplines](https://arxiv.org/abs/2509.21320)
*Yizhou Wang,Chen Tang,Han Deng,Jiabei Xiao,Jiaqi Liu,Jianyu Wu,Jun Yao,Pengze Li,Encheng Su,Lintao Wang,Guohang Zhuang,Yuchen Ren,Ben Fei,Ming Hu,Xin Chen,Dongzhan Zhou,Junjun He,Xiangyu Yue,Zhenfei Yin,Jiamin Wu,Qihao Zheng,Yuhao Zhou,Huihui Xu,Chenglong Ma,Yan Lu,Wenlong Zhang,Chunfeng Song,Philip Torr,Shixiang Tang,Xinzhu Ma,Wanli Ouyang,Lei Bai*

Main category: cs.CL

TL;DR: 一个在2060亿词元语料库上预训练的科学推理基础模型，通过SFT、冷启动引导和强化学习进行对齐，支持跨103个任务的四种能力，并在忠实翻译、文本/知识提取、属性预测、属性分类和序列生成等方面优于专业系统。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够将自然语言与异构科学表示形式对齐的科学推理基础模型，以拓宽指令覆盖范围、提高跨领域泛化能力并增强保真度。

Method: 在包含科学文本、纯序列和序列-文本对的2060亿词元语料库上进行预训练，然后通过4000万条指令进行监督微调（SFT），并采用冷启动引导和强化学习（带有特定任务的奖励塑造）进行对齐，以激发长篇幅的链式思考和科学推理。

Result: 该模型支持四种能力家族，涵盖103个跨工作流的任务，包括文本与科学格式之间的忠实翻译、文本/知识提取、属性预测、属性分类以及无条件和有条件序列生成与设计。与专业系统相比，该模型在指令覆盖范围、跨领域泛化能力和保真度方面均有提升。

Conclusion: 通过跨学科学习可以增强迁移能力和下游任务的可靠性。模型、指令调整数据集和评估代码均已开源。

Abstract: We present a scientific reasoning foundation model that aligns natural
language with heterogeneous scientific representations. The model is pretrained
on a 206B-token corpus spanning scientific text, pure sequences, and
sequence-text pairs, then aligned via SFT on 40M instructions, annealed
cold-start bootstrapping to elicit long-form chain-of-thought, and
reinforcement learning with task-specific reward shaping, which instills
deliberate scientific reasoning. It supports four capability families, covering
up to 103 tasks across workflows: (i) faithful translation between text and
scientific formats, (ii) text/knowledge extraction, (iii) property prediction,
(iv) property classification, (v) unconditional and conditional sequence
generation and design. Compared with specialist systems, our approach broadens
instruction coverage, improves cross-domain generalization, and enhances
fidelity. We detail data curation and training and show that cross-discipline
learning strengthens transfer and downstream reliability. The model, instruct
tuning datasets and the evaluation code are open-sourced at
https://huggingface.co/SciReason and
https://github.com/open-sciencelab/SciReason.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [155] [Ge as an ideal orbitronic platform: giant orbital Hall effect](https://arxiv.org/abs/2509.20436)
*James H. Cullen,Zhanning Wang,Dimitrie Culcer*

Main category: cond-mat.mes-hall

TL;DR: Ge是一种优越的轨道电子材料，其巨大的轨道霍尔效应（OHE）超过了拓扑绝缘体和自旋霍尔效应。


<details>
  <summary>Details</summary>
Motivation: 开发更快、更高效的磁性存储元件，推动了对具有强轨道动力学特性的“轨道电子”材料的研究，例如轨道霍尔效应（OHE）。

Method: 在Luttinger模型和现代轨道磁化理论的框架内，并结合最近发现的OHE量子修正，对块状Ge中的空穴进行了计算。

Result: 块状Ge中的空穴表现出巨大的OHE，其效应强度超过了拓扑绝缘体中的块状态，并且比自旋霍尔效应强四个数量级。

Conclusion: Ge是理想的轨道电子平台，为在具有反转对称性的系统中应用现代轨道磁化理论设立了里程碑。块状Ge也是研究电荷电流引起的轨道扭矩的理想选择，因为其对称性禁止了自旋和轨道Edelstein效应。该研究为在Ge中产生强轨道扭矩提供了蓝图，并指导未来的实验工作。

Abstract: State-of-the-art developments in magnetic devices rely on manufacturing
faster, more efficient memory elements. A significant development in this
direction has been the discovery of orbital torques, which employ the orbital
angular momentum of Bloch electrons to switch the magnetisation of an adjacent
ferromagnet, and has motivated the search for \textit{orbitronic} materials
displaying strong orbital dynamics exemplified, by the orbital Hall effect
(OHE). In this work we propose Ge, as an optimal orbitronic platform. We
demonstrate that holes in bulk Ge exhibit a giant OHE, exceeding that of the
bulk states of topological insulators, and exceeding the spin-Hall effect by
four orders of magnitude. The calculation is performed within the framework of
the Luttinger model and the modern theory of orbital magnetisation, while
incorporating recently-discovered quantum corrections to the OHE. Our study
constitutes a fundamental milestone in applying the modern theory to a system
with \textit{inversion symmetry}. Moreover, we argue that bulk Ge serves as an
ideal testbed for the orbital torque resulting from a charge current, since the
spin- and orbital-Edelstein effects in Ge are forbidden by symmetry. Our
results provide a blueprint for producing strong orbital torques in magnetic
devices with Ge, guiding future experimental work in this direction.

</details>


### [156] [Anomalous Landau Levels in Inhomogeneous Fluxes and Emergent Supersymmetry](https://arxiv.org/abs/2509.20462)
*Soujanya Datta,Krishanu Roychowdhury*

Main category: cond-mat.mes-hall

TL;DR: 两维系统在磁场下存在丰富的物理现象，特别是与朗道能级量子化相关的量子霍尔效应。一类两维模型中的平带具有拓扑非平凡的能带简并，会在均匀场下产生异常朗道能级量子化。这些平带归因于潜在的量子几何，被称为奇异平带，表现出异常的波函数局域化和朗道能级的异常量子化。本文研究了无间隙奇异平带对非均匀磁通量的响应，连接了连续和晶格描述。研究揭示了一种通过磁通量不均匀性可控操纵异常朗道能级的机制。此外，研究还发现了一个在参数空间中异常朗道能级塔坍缩到零能量的涌现超对称性，实现了简并零模式在垂直磁通量下的晶格类似阿哈罗诺夫-卡西尔定理，其波函数局域化在一定程度上类似于阿哈罗诺夫-博姆钉扎。结合强关联，这些发现将为实现奇异的拓扑和电荷有序相提供启示。


<details>
  <summary>Details</summary>
Motivation: 研究两维系统在磁场下的物理现象，特别是奇异平带的性质及其对非均匀磁通量的响应，旨在探索新的物理机制和潜在应用。

Method: 连接连续和晶格描述，研究无间隙奇异平带对非均匀磁通量的响应，揭示了通过磁通量不均匀性可控操纵异常朗道能级的机制，并发现了涌现的超对称性。

Result: 发现了通过磁通量不均匀性可控操纵异常朗道能级的机制；揭示了简并零模式在垂直磁通量下的晶格类似阿哈罗诺夫-卡西尔定理，其波函数局域化在一定程度上类似于阿哈罗诺夫-博姆钉扎。

Conclusion: 该研究揭示了奇异平带在非均匀磁场下的新行为，并提出了实现奇异拓扑和电荷有序相的潜在途径，具有重要的理论和应用前景。

Abstract: Two-dimensional systems in magnetic fields host rich physics, most notably
the quantum Hall effect arising from Landau level quantization. In a broad
class of two-dimensional models, flat bands with topologically nontrivial band
degeneracies give rise to anomalous Landau level quantization under homogeneous
fields. Ascribed to the underlying quantum geometry, these are classified as
singular flat bands, exhibiting unusual wavefunction localization, and
anomalous quantization of Landau levels. We investigate the response of gapless
singular flat bands to inhomogeneous fluxes, bridging continuum and lattice
descriptions. Our analysis reveals a mechanism to controllably manipulate the
anomalous Landau levels via flux inhomogeneity. We further uncover an emergent
supersymmetry in the parameter space where the tower of anomalous Landau levels
collapses to zero energy, rendering a lattice analog of the Aharonov-Casher
theorem on degenerate zero modes in perpendicular fluxes, with wavefunction
localization partly similar to Aharonov-Bohm caging. With the addition of
strong correlations, these findings will have implications for realizing exotic
topological and charge-ordered phases.

</details>


### [157] [Magnon-magnon coupling efficiency of $η$=0.5 in weakly pinned synthetic antiferromagnets](https://arxiv.org/abs/2509.20487)
*Dirk Backes*

Main category: cond-mat.mes-hall

TL;DR: 通过调整反铁磁体的厚度和增加钉扎层的磁各向异性，在不破坏对称性的情况下，可以有效地激发合成反铁磁体（SAF）中的声学和光学磁子模式，实现高达0.5的磁子带隙，有望用于量子磁子应用。


<details>
  <summary>Details</summary>
Motivation: 解释了合成反铁磁体（SAF）中同时激发声学和光学磁子模式通常需要破坏层对称性，并提出了一种新的方法来克服这一限制。

Method: 利用被钉扎的合成反铁磁体（pSAF），通过调整反铁磁体的厚度和轻微增加钉扎层的磁各向异性，实现了声学和光学模式的有效激发。

Result: 实现了高达0.5的磁子带隙（磁子带隙与特征频率之比），接近超强耦合区（η=1），并在大面积上实现了高铁磁共振（FMR）相干性。

Conclusion: 提出的pSAF系统在室温下无需低温冷却即可实现强模式杂化、大的磁子带隙和高FMR相干性，具有开发量子磁子应用的潜力，如量子计算。

Abstract: Synthetic antiferromagnets (SAFs) consist of two ferromagnetic layers that
are antiferromagnetically coupled. These systems support complex dynamical
magnetic excitations, where interlayer coupling gives rise to both in-phase
(acoustic) and anti-phase (optical) magnonic modes. Typically, simultaneous
excitation of both modes requires breaking the symmetry between the
ferromagnetic layers -- commonly achieved through slight misalignment of the
experimental setup or by modifying the intrinsic magnetic properties. In our
approach, we utilize a pinned synthetic antiferromagnet (pSAF), where one of
the ferromagnetic layers is exchange-coupled to an antiferromagnet. We
demonstrate that by tuning the thickness of the antiferromagnet and slightly
enhancing the magnetic anisotropy of the pinned layer, both acoustic and
optical modes can be efficiently excited -- without the need for experimental
misalignment or changes to the intrinsic material properties. Under specific
conditions, the magnon dispersion relations exhibit anti-crossing behavior,
resulting in the emergence of a magnonic bandgap -- a clear signature of strong
magnon-magnon coupling. The coupling efficiency $\eta$, defined as the ratio
between the bandgap and the characteristic frequency, reaches $\eta = 0.5$,
approaching the ultra-strong coupling regime ($\eta = 1$). The combination of
strong mode hybridization, a sizable magnonic bandgap, and high ferromagnetic
resonance (FMR) coherence over large areas -- all achieved at room temperature
without cryogenic cooling -- underscores the potential of these systems for
quantum magnonic applications, including quantum computing.

</details>


### [158] [Classical and single photon memory devices based on polariton lasers](https://arxiv.org/abs/2509.20569)
*D. Novokreschenov,A. Kudlis,A. V. Kavokin*

Main category: cond-mat.mes-hall

TL;DR: 非相干激子受激散射到激子-极化激个体模式，会形成一个极化激个体凝聚体。该凝聚体的极化状态对触发受激过程的微弱种子种群非常敏感。


<details>
  <summary>Details</summary>
Motivation: 研究一种通过微弱种子信号实现鲁棒极化记忆的机制。

Method: 使用半经典随机Gross-Pitaevskii模型进行建模。

Result: 模型显示，凝聚体倾向于将其斯托克斯矢量与其种子对齐，并能维持远超单个极化激个体寿命的时间。在现实参数下，种子极化可以在纳秒尺度上得到很好的保留。

Conclusion: 该模型证明了单光子种子机制可以实现鲁棒的极化记忆操作。

Abstract: Stimulated scattering of incoherent excitons into an exciton-polariton mode
leads to the build-up of a polariton condensate whose polarization is sensitive
to a small seeded population that triggers the stimulated process. We show,
within a semiclassical stochastic Gross-Pitaevskii model, that this mechanism
enables a robust polarization memory operation: the condensate tends to align
its Stokes vector with that of the seed and to maintain it for times far
exceeding an individual polariton lifetime. Importantly, this
single-photon-seeded regime is modeled as an initial weak excitation of the
condensate mode. We quantify the memory performance by a classical
polarization-alignment metric and find that the seed polarization can remain
well preserved on a nanosecond timescale under realistic parameters.

</details>


### [159] [Quantum metric induced nonlinear thermal noise in PT-symmetric antiferromagnets](https://arxiv.org/abs/2509.20647)
*Dibyanandan Bhowmick,Amit Agarwal*

Main category: cond-mat.mes-hall

TL;DR: 论文提出了一种新的方法，利用电场诱导的电流噪声来探测量子材料的带状几何结构，特别是量子度量。


<details>
  <summary>Details</summary>
Motivation: 电流波动是一种非常规的探测量子材料带状几何的手段，特别是与弛豫时间无关的本征噪声，可以揭示布洛赫电子的普适带状几何性质。

Method: 论文识别出一种在电场下二阶的本征电流噪声贡献，该贡献由量子度量决定。这种效应源于电场引起的布洛赫波函数和能带能量的修改，在PT对称的磁性反铁磁材料中占主导地位，因为对称性禁止了基于贝里曲率的贡献。将该理论应用于CuMnAs，并证明热噪声是PT对称磁性反铁磁材料中量子度量的直接信号。

Result: 该理论识别出一种新的本征电流噪声贡献，它与量子度量有关，并且在PT对称的反铁磁材料中占主导地位。

Conclusion: 该研究提出了一种利用电流噪声探测量子材料量子度量的新方法，特别是在PT对称的反铁磁材料中，这为理解和利用量子材料的带状几何性质提供了新的途径。

Abstract: Electrical current fluctuations provide a powerful and unconventional probe
of band geometry in quantum materials. In particular, intrinsic noise
components that are independent of the relaxation time reveal universal
band-geometric properties of Bloch electrons. Here, we identify a distinct
intrinsic contribution to current noise at second order in the electric field,
which is governed by the quantum metric. This effect arises from field-induced
modifications to Bloch wavefunctions and band energies, and it dominates in
PT-symmetric antiferromagnets where Berry curvature based contributions are
forbidden by symmetry. Applying our theory to CuMnAs, we demonstrate that
thermal noise provides a direct signature of quantum metric in PT-symmetric
antiferromagnets.

</details>


### [160] [Nontrivial topology in one- and two-dimensional asymmetric systems with chiral boundary states](https://arxiv.org/abs/2509.20834)
*Yunlin Li,Yufu Liu,Xuezhi Wang,Haoran Zhang,Xunya Jiang*

Main category: cond-mat.mes-hall

TL;DR: 本文提出了一种研究一维和二维不对称系统拓扑性质的新理论，通过重新定义子格点，发现了新的手征边界态和角态，并建立了相应的拓扑不变量和体边对应关系。


<details>
  <summary>Details</summary>
Motivation: 研究手征边界态在具有手征对称性的拓扑带理论中的重要性，并探索在不对称系统，特别是在高维系统中的拓扑性质。

Method: 通过重新定义子格点来研究一维SSHm模型和二维BBH3模型的手征拓扑性质，并定义了新的拓扑不变量$ar{Z}$，建立了体边对应关系。

Result: 在一维和二维不对称系统中发现了手征边界态和手征角态，并建立了基于$ar{Z}$的拓扑不变量和体边对应关系。二维BBH3模型中发现的手征角态具有拓扑束缚态（TBICs）的特性，并且不依赖于任何空间对称性。通过声学实验验证了BBH3模型的手征角态。

Conclusion: 本文提出了一种研究不对称系统拓扑性质的新方法，通过重新定义子格点，揭示了不同结构模型可能具有相同的拓扑起源。

Abstract: Symmetry plays an important role in the topological band theory. In contrary,
study on the topological properties of the asymmetric systems is rather
limited, especially in higher-dimensional systems. In this work, we explore a
new theory to study the topology in various one-dimensional (1D) and
two-dimensional (2D) asymmetric systems with chiral boundary states. Starting
from the simple SSHm model, we show the chiral topology of its edge states by
redefining sublattices. Meanwhile, based on its Rice-Mele-like effective
Hamiltonian, a new topological invariant $\bar{Z}$ can be defined and the
bulk-edge correspondence is established. With this clear physical picture, our
theory can be extended to the more complex asymmetric ladder models, or even
the 2D asymmetric systems. In the 2D BBH3 model, new chiral corner states with
redefined lattices are found based on our method. These corner states are
independent of any spatial symmetry and exhibit the characteristics of
topological bound states in the continuum (TBICs). Moreover, the topological
invariant can be calculated by introducing $\bar{Z}$ into 2D. At last, we
propose an acoustic experiment of the BBH3 model where chiral corner states are
numerically observed. Our work exhibits a new approach to study the topological
properties of asymmetric systems. By redefining sublattices, we find that the
models with entirely different structures might share the same topological
origins.

</details>


### [161] [Tracking spin qubit frequency variations over 912 days](https://arxiv.org/abs/2509.20990)
*Kenji Capannelli,Brennan Undseth,Irene Fernández de Fuentes,Eline Raymenants,Florian K. Unseld,Oriol Pietx-Casas,Stephan G. J. Philips,Mateusz T. Mądzik,Sergey V. Amitonov,Larysa Tryputen,Giordano Scappucci,Lieven M. K. Vandersypen*

Main category: cond-mat.mes-hall

TL;DR: 量子比特频率的低频漂移会影响其性能，本研究在Si/SiGe量子点平台上研究了自旋量子比特频率的稳定性，发现其频率在长达912天的时间内可变动±100MHz，但通过精确控制栅极电压（±15 μV），频率变化可控制在±7 MHz以内（36天内）。同时，在1小时的时间窗口内，10个量子比特的频率变化标准差低于200 kHz，且频率噪声频谱密度在高于10⁻⁴ Hz时呈现约1/f的趋势，在更低频率下则呈现更陡峭的趋势。


<details>
  <summary>Details</summary>
Motivation: 自旋量子比特的频率会因其微观环境的变化而在不同时间尺度上发生漂移，这会带来可观的额外开销。因此，理解和表征量子比特频率的低频变化至关重要。

Method: 本研究通过在Si/SiGe量子点平台上，对一个包含六个量子比特的设备进行长达912天的实验，测量和分析了校准后量子比特频率的变化范围，并研究了其与栅极电压设置的关联性。此外，还进行了为期1小时的实验，以评估短期内量子比特频率的稳定性，并分析了频率噪声的频谱密度。

Result: 在912天的时间跨度内，六量子比特设备的校准后量子比特频率变化高达±100 MHz。这些频率变化对栅极电压设置敏感，但当栅极电压保持在15 μV以内时，量子比特频率在长达36天内变化小于±7 MHz。在过夜扫描中，两个不同设备上的十个量子比特的频率在1小时内变化的标准差小于200 kHz。频率噪声的频谱密度在高于10⁻⁴ Hz时大致呈1/f趋势，在更低频率下则呈现更陡峭的趋势。

Conclusion: Si/SiGe量子点平台中的自旋量子比特频率表现出长期的低频漂移，但可以通过精确控制栅极电压来显著减小这种漂移。短期内量子比特频率相当稳定。频率噪声在极低频下表现出比1/f更陡峭的趋势，这表明需要进一步研究其背后的物理机制。

Abstract: Solid-state qubits are sensitive to their microscopic environment, causing
the qubit properties to fluctuate on a wide range of timescales. The sub-Hz end
of the spectrum is usually dealt with by repeated background calibrations,
which bring considerable overhead. It is thus important to characterize and
understand the low-frequency variations of the relevant qubit characteristics.
In this study, we investigate the stability of spin qubit frequencies in the
Si/SiGe quantum dot platform. We find that the calibrated qubit frequencies of
a six-qubit device vary by up to $\pm 100$ MHz while performing a variety of
experiments over a span of 912 days. These variations are sensitive to the
precise voltage settings of the gate electrodes, however when these are kept
constant to within 15 $\mathrm{\mu}$V, the qubit frequencies vary by less than
$\pm 7$ MHz over periods up to 36 days. During overnight scans, the qubit
frequencies of ten qubits across two different devices show a standard
deviation below 200 kHz within a 1-hour time window. The qubit frequency noise
spectral density shows roughly a $1/f$ trend above $10^{-4}$ Hz and,
strikingly, a steeper trend at even lower frequencies.

</details>


### [162] [Spin band geometry drives intrinsic thermal spin magnetization and current](https://arxiv.org/abs/2509.21215)
*Sankar Sarkar,Harsh Varshney,Sayan Sarkar,Amit Agarwal*

Main category: cond-mat.mes-hall

TL;DR: 本文提出了一个统一的量子理论，用于在没有磁场或电场的情况下，通过热梯度驱动的自旋响应来产生自旋磁化和自旋电流。该理论基于自旋能带几何，并考虑了费米面和费米海的贡献。


<details>
  <summary>Details</summary>
Motivation: 在没有磁场或电场的情况下产生自旋磁化和自旋电流是自旋热电子学的一个关键前沿领域。由热梯度驱动的自旋响应提供了一条有前景的途径，但其内在机制的能带几何起源，特别是在非磁性材料中，仍然知之甚少。

Method: 我们开发了一个统一的量子理论，用于研究移动电子中的热自旋磁化和自旋电流，该理论基于自旋能带几何，并同时考虑了费米面和费米海的贡献。我们确定了两个关键的几何量：自旋速度度量张量，它控制着热自旋磁化；以及自旋几何张量，它结合了自旋贝里曲率和自旋量子度量，从而产生热自旋电流。

Result: 我们识别了两个关键的几何量：自旋速度度量张量，它控制着热自旋磁化；以及自旋几何张量，它结合了自旋贝里曲率和自旋量子度量，从而产生热自旋电流。这些内在贡献即使在非磁性绝缘体中也持续存在，甚至可能占主导地位。对映金属RhGe和反铁磁性CuMnAs的数值计算表明，在能带交叉附近存在可观的热自旋响应。

Conclusion: 我们的研究结果确立了热自旋输运的能带几何起源，并为发现和工程化下一代自旋热电子材料提供了指导原则。

Abstract: Generating spin magnetization and spin currents without magnetic or electric
fields is a key frontier in spin caloritronics. Spin responses driven by
thermal gradients offer a promising route, though the band geometric origin of
intrinsic mechanisms, especially in non-magnetic materials, remains poorly
understood. Here we develop a unified quantum theory of thermal spin
magnetization and spin currents in itinerant electrons, rooted in spin band
geometry with both Fermi-surface and Fermi-sea contributions. We identify two
key geometric quantities: the spin-velocity metric tensor, which governs
thermal spin magnetization, and the spin geometric tensor, combining spin Berry
curvature and spin quantum metric, which generates thermal spin currents. These
intrinsic contributions persist and can even dominate in non-magnetic
insulators. Numerical calculations for chiral metal RhGe and antiferromagnet
CuMnAs demonstrate sizable thermal spin responses near band crossings. Our
results establish the band geometric origin of thermal spin transport and
provide guiding principles for discovering and engineering next-generation spin
caloritronic materials.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [163] [A Theory of Multi-Agent Generative Flow Networks](https://arxiv.org/abs/2509.20408)
*Leo Maxime Brunswic,Haozhi Wang,Shuang Luo,Jianye Hao,Amir Rasouli,Yinchuan Li*

Main category: cs.LG

TL;DR: 本文提出了多智能体生成流网络（MA-GFlowNets）的理论框架，并设计了四种算法，在多智能体协作生成任务中展现出优于强化学习和MCMC的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的生成流网络（GFlowNets）在多智能体协作生成对象方面缺乏理论框架支持。

Method: 提出了MA-GFlowNets的理论框架，并设计了三种算法（中心化流网络、独立流网络、联合流网络及其条件版本）来实现中心化训练和去中心化执行。其中，联合流训练基于局部-全局原则。

Result: 实验结果表明，所提出的MA-GFlowNets框架在生成具有与奖励函数成比例概率的样本方面优于强化学习和MCMC方法。

Conclusion: 本文提出的MA-GFlowNets理论框架和算法能够有效地支持多智能体通过联合动作协作生成对象，并在实验中取得了优越的性能。

Abstract: Generative flow networks utilize a flow-matching loss to learn a stochastic
policy for generating objects from a sequence of actions, such that the
probability of generating a pattern can be proportional to the corresponding
given reward. However, a theoretical framework for multi-agent generative flow
networks (MA-GFlowNets) has not yet been proposed. In this paper, we propose
the theory framework of MA-GFlowNets, which can be applied to multiple agents
to generate objects collaboratively through a series of joint actions. We
further propose four algorithms: a centralized flow network for centralized
training of MA-GFlowNets, an independent flow network for decentralized
execution, a joint flow network for achieving centralized training with
decentralized execution, and its updated conditional version. Joint Flow
training is based on a local-global principle allowing to train a collection of
(local) GFN as a unique (global) GFN. This principle provides a loss of
reasonable complexity and allows to leverage usual results on GFN to provide
theoretical guarantees that the independent policies generate samples with
probability proportional to the reward function. Experimental results
demonstrate the superiority of the proposed framework compared to reinforcement
learning and MCMC-based methods.

</details>


### [164] [Explicit and Effectively Symmetric Schemes for Neural SDEs](https://arxiv.org/abs/2509.20599)
*Daniil Shmelev,Cristopher Salvi*

Main category: cs.LG

TL;DR: 通过引入一种新的稳定、近似可逆的龙格-库塔方案（EES），解决了传统上向后传播通过（神经网络）随机微分方程（SDE）求解器所面临的精度和内存权衡问题，该方案在保持内存效率的同时，克服了现有方法的稳定性问题，为可扩展和准确的神经网络SDE训练奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 传统向后传播通过（神经网络）SDE求解器的方法存在精度和内存成本的权衡：离散化然后优化方法梯度精度高但内存成本高；优化然后离散化方法内存成本低但梯度近似误差大。现有的代数可逆求解器（如可逆欣欣欣方案）在复杂模型和大的步长下不稳定。因此，需要一种既能实现内存效率又能保证梯度精度的稳定方法。

Method: 提出了一类新的显式且有效对称（EES）的龙格-库塔方案，用于神经网络SDE。该方法通过设计具有良好稳定性和近似可逆性的新方案，克服了现有可逆求解器在复杂模型和大型步长下的不稳定性问题。

Result: 通过数值实验证明，所提出的EES方案比现有的方法具有更优越的稳定性和可靠性，能够实现内存高效的训练，并且对步长或模型复杂度没有严格限制。

Conclusion: 所提出的EES方案是一类稳定且近似可逆的龙格-库塔方法，为可扩展和准确的神经网络SDE训练提供了一个实用的基础，解决了现有方法在精度、内存成本和稳定性方面的不足。

Abstract: Backpropagation through (neural) SDE solvers is traditionally approached in
two ways: discretise-then-optimise, which offers accurate gradients but incurs
prohibitive memory costs due to storing the full computational graph (even when
mitigated by checkpointing); and optimise-then-discretise, which achieves
constant memory cost by solving an auxiliary backward SDE, but suffers from
slower evaluation and gradient approximation errors. Algebraically reversible
solvers promise both memory efficiency and gradient accuracy, yet existing
methods such as the Reversible Heun scheme are often unstable under complex
models and large step sizes. We address these limitations by introducing a
novel class of stable, near-reversible Runge--Kutta schemes for neural SDEs.
These Explicit and Effectively Symmetric (EES) schemes retain the benefits of
reversible solvers while overcoming their instability, enabling
memory-efficient training without severe restrictions on step size or model
complexity. Through numerical experiments, we demonstrate the superior
stability and reliability of our schemes, establishing them as a practical
foundation for scalable and accurate training of neural SDEs.

</details>


### [165] [FastEagle: Cascaded Drafting for Accelerating Speculative Decoding](https://arxiv.org/abs/2509.20416)
*Haiduo Huang,Jiangcheng Song,Wenzhe Zhao,Pengju Ren*

Main category: cs.LG

TL;DR: FastEagle通过单次前向传播生成全部草稿，实现了比现有方法更快的生成速度，同时保持了可接受的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有技术（如EAGLE）的投机解码在生成令牌时需要多次顺序传递，效率低下。本研究旨在开发一种能够一次性生成整个草稿的非自回归级联草稿器，以加速生成过程。

Method: FastEagle采用轻量级层级联替代时间步，并通过逐层监督训练来减少错误累积。此外，它还使用约束草稿树来保持无损验证成本。

Result: FastEagle在多个大型语言模型（Vicuna-13B、LLaMA-Instruct 3.x和DeepSeek-R1-Distill-LLaMA）和任务（MT-Bench、HumanEval、GSM8K、CNN/DM、Alpaca）上，相较于EAGLE-3，在速度上实现了显著提升，并且在贪婪和随机解码下都具有可比的平均接受长度。

Conclusion: 消除草稿生成中的顺序依赖是实现无损大型语言模型推理加速的有效途径。

Abstract: Speculative decoding accelerates generation by drafting candidates and
verifying them in parallel, yet state-of-the-art drafters (e.g., EAGLE) still
require N sequential passes to propose N tokens. We present FastEagle, a
non-autoregressive cascaded drafter that emits an entire draft in a single
forward pass. FastEagle replaces temporal steps with a lightweight layer
cascade and trains with layer-wise supervision to mitigate error accumulation.
Coupled with a constrained draft tree that preserves lossless verification
cost, FastEagle delivers substantial wall-clock speedups over strong
autoregressive drafters while maintaining competitive acceptance behavior.
Across multiple LLMs (Vicuna-13B, LLaMA-Instruct 3.x, and
DeepSeek-R1-Distill-LLaMA) and tasks (MT-Bench, HumanEval, GSM8K, CNN/DM,
Alpaca), FastEagle consistently outperforms EAGLE-3 in speedup under both
greedy and stochastic decoding, with comparable average acceptance lengths.
These results indicate that removing sequential dependencies in drafting is a
practical path toward lossless LLM inference acceleration.

</details>


### [166] [Latent Twins](https://arxiv.org/abs/2509.20615)
*Matthias Chung,Deepanshu Verma,Max Collins,Amit N. Subrahmanya,Varuni Katti Sastry,Vishwas Rao*

Main category: cs.LG

TL;DR: Latent Twins 是一个统一的数学框架，通过在潜在空间中创建潜在的代理来解决科学机器学习中的分离问题，可应用于 ODEs 和 PDEs，并在各种基准测试中表现出其有效性。


<details>
  <summary>Details</summary>
Motivation: 科学机器学习在过去十年中取得了显著进展，但表示学习和算法求解方法通常是独立发展的。需要一个统一的框架来整合这些方法。

Method: 提出 Latent Twins 框架，在潜在空间中为底层方程创建一个隐藏的代理。该框架将经典建模、反演、模型降阶和算子逼近统一在一个单一的原理下。对 ODEs 和 PDEs 的基本逼近性质进行了理论推导。

Result: 在三种代表性场景中进行了实验：(i) 典型的 ODEs，涵盖了各种动力学状态；(ii) 使用浅水方程的 PDE 基准测试，将 Latent Twins 的模拟与 DeepONet 和 4D-Var 基线进行了对比；(iii) 使用具有挑战性的真实世界地势再分析数据集，从稀疏、嘈杂的观测中进行重建和预测。Latent Twins 能够一次性评估任意时间间隔内的解算子，并保持与科学流程（如数据同化、控制和不确定性量化）的兼容性。

Conclusion: Latent Twins 提供了一个紧凑、可解释的解算子代理，能够跨越任意时间间隔进行单次评估，并且与科学计算流程兼容。该框架为跨学科的数据驱动表示学习和经典科学建模提供了可扩展、有理论基础的代理。

Abstract: Over the past decade, scientific machine learning has transformed the
development of mathematical and computational frameworks for analyzing,
modeling, and predicting complex systems. From inverse problems to numerical
PDEs, dynamical systems, and model reduction, these advances have pushed the
boundaries of what can be simulated. Yet they have often progressed in
parallel, with representation learning and algorithmic solution methods
evolving largely as separate pipelines. With \emph{Latent Twins}, we propose a
unifying mathematical framework that creates a hidden surrogate in latent space
for the underlying equations. Whereas digital twins mirror physical systems in
the digital world, Latent Twins mirror mathematical systems in a learned latent
space governed by operators. Through this lens, classical modeling, inversion,
model reduction, and operator approximation all emerge as special cases of a
single principle. We establish the fundamental approximation properties of
Latent Twins for both ODEs and PDEs and demonstrate the framework across three
representative settings: (i) canonical ODEs, capturing diverse dynamical
regimes; (ii) a PDE benchmark using the shallow-water equations, contrasting
Latent Twin simulations with DeepONet and forecasts with a 4D-Var baseline; and
(iii) a challenging real-data geopotential reanalysis dataset, reconstructing
and forecasting from sparse, noisy observations. Latent Twins provide a
compact, interpretable surrogate for solution operators that evaluate across
arbitrary time gaps in a single-shot, while remaining compatible with
scientific pipelines such as assimilation, control, and uncertainty
quantification. Looking forward, this framework offers scalable,
theory-grounded surrogates that bridge data-driven representation learning and
classical scientific modeling across disciplines.

</details>


### [167] [Physics of Learning: A Lagrangian perspective to different learning paradigms](https://arxiv.org/abs/2509.21049)
*Siyuan Guo,Bernhard Schölkopf*

Main category: cs.LG

TL;DR: 通过应用物理学中的


<details>
  <summary>Details</summary>
Motivation: 构建一个能够以最少观察次数达到期望误差阈值的学习系统，即高效学习系统。

Method: 基于物理学中的最小作用量原理，从“学习拉格朗日量”这一首原理出发，推导了包括贝尔曼最优方程（强化学习）和Adam优化器（生成模型）在内的经典学习算法。

Result: 推导了经典学习算法，如贝尔曼最优方程和Adam优化器。

Conclusion: 学习通过寻找拉格朗日量中的平稳路径来实现，并且学习算法可以通过寻找平稳轨迹来推导。

Abstract: We study the problem of building an efficient learning system. Efficient
learning processes information in the least time, i.e., building a system that
reaches a desired error threshold with the least number of observations.
Building upon least action principles from physics, we derive classic learning
algorithms, Bellman's optimality equation in reinforcement learning, and the
Adam optimizer in generative models from first principles, i.e., the Learning
$\textit{Lagrangian}$. We postulate that learning searches for stationary paths
in the Lagrangian, and learning algorithms are derivable by seeking the
stationary trajectories.

</details>


### [168] [mloz: A Highly Efficient Machine Learning-Based Ozone Parameterization for Climate Sensitivity Simulations](https://arxiv.org/abs/2509.20422)
*Yiling Ma,Nathan Luke Abraham,Stefan Versick,Roland Ruhnke,Andrea Schneidereit,Ulrike Niemeier,Felix Back,Peter Braesicke,Peer Nowack*

Main category: cs.LG

TL;DR: 该研究引入了一种名为mloz的机器学习参数化方法，能够以比传统化学方案快31倍的速度，对气候模型中的大气臭氧进行交互式建模，且计算成本低，精度高，并展示了其在不同气候模型间的可迁移性。


<details>
  <summary>Details</summary>
Motivation: 大多数气候模型在模拟臭氧时计算成本过高，缺乏交互式臭氧表示，限制了对气候变化评估的准确性。

Method: 提出一种基于机器学习的mloz参数化方案，仅使用大气温度廓线信息，即可在气候模型中交互式地模拟臭氧的日变化和趋势，并考虑臭氧与准两年振荡的双向耦合。

Result: mloz在十年尺度上表现出高保真度，在UKESM和ICON两个气候模型中均能灵活在线使用，运行速度比UKESM的化学方案快31倍，仅占模型总运行时间的4%不到，且能够从UKESM迁移到ICON模型。

Conclusion: mloz作为一种高效且可迁移的机器学习参数化方法，为缺乏交互式化学的CMIP级气候模型提供了模拟臭氧的解决方案，尤其是在气候敏感性模拟中，对于理解臭氧变化对气候反馈过程的显著影响具有重要意义。

Abstract: Atmospheric ozone is a crucial absorber of solar radiation and an important
greenhouse gas. However, most climate models participating in the Coupled Model
Intercomparison Project (CMIP) still lack an interactive representation of
ozone due to the high computational costs of atmospheric chemistry schemes.
Here, we introduce a machine learning parameterization (mloz) to interactively
model daily ozone variability and trends across the troposphere and
stratosphere in standard climate sensitivity simulations, including two-way
interactions of ozone with the Quasi-Biennial Oscillation. We demonstrate its
high fidelity on decadal timescales and its flexible use online across two
different climate models -- the UK Earth System Model (UKESM) and the German
ICOsahedral Nonhydrostatic (ICON) model. With atmospheric temperature profile
information as the only input, mloz produces stable ozone predictions around 31
times faster than the chemistry scheme in UKESM, contributing less than 4
percent of the respective total climate model runtimes. In particular, we also
demonstrate its transferability to different climate models without chemistry
schemes by transferring the parameterization from UKESM to ICON. This
highlights the potential for widespread adoption in CMIP-level climate models
that lack interactive chemistry for future climate change assessments,
particularly when focusing on climate sensitivity simulations, where ozone
trends and variability are known to significantly modulate atmospheric feedback
processes.

</details>


### [169] [Learning Ising Models under Hard Constraints using One Sample](https://arxiv.org/abs/2509.20993)
*Rohan Chauhan,Ioannis Panageas*

Main category: cs.LG

TL;DR: 从一个截断的伊辛模型中，仅使用一个样本，在近乎线性O(n)的时间内，设计了一个几乎恒定的估计器，用于估计逆温度参数β。


<details>
  <summary>Details</summary>
Motivation: 在给定图G的截断集S（k-SAT公式的满足赋值集）的条件下，估计n维截断伊辛模型的逆温度参数β。

Method: 使用伪似然最大化，将样本与模型生成参数联系起来。

Result: 设计了一个近乎O(n)时间内的估计器，它与真实参数β*在O(Δ^3/√n)内几乎是恒定的，其中Δ是图的度界，k大约是log(d^2k)Δ^3。

Conclusion: 提出了一个在截断伊辛模型设置下，从单一样本估计逆温度参数β的有效方法。

Abstract: We consider the problem of estimating inverse temperature parameter $\beta$
of an $n$-dimensional truncated Ising model using a single sample. Given a
graph $G = (V,E)$ with $n$ vertices, a truncated Ising model is a probability
distribution over the $n$-dimensional hypercube $\{-1,1\}^n$ where each
configuration $\mathbf{\sigma}$ is constrained to lie in a truncation set $S
\subseteq \{-1,1\}^n$ and has probability $\Pr(\mathbf{\sigma}) \propto
\exp(\beta\mathbf{\sigma}^\top A\mathbf{\sigma})$ with $A$ being the adjacency
matrix of $G$. We adopt the recent setting of [Galanis et al. SODA'24], where
the truncation set $S$ can be expressed as the set of satisfying assignments of
a $k$-SAT formula. Given a single sample $\mathbf{\sigma}$ from a truncated
Ising model, with inverse parameter $\beta^*$, underlying graph $G$ of bounded
degree $\Delta$ and $S$ being expressed as the set of satisfying assignments of
a $k$-SAT formula, we design in nearly $O(n)$ time an estimator $\hat{\beta}$
that is $O(\Delta^3/\sqrt{n})$-consistent with the true parameter $\beta^*$ for
$k \gtrsim \log(d^2k)\Delta^3.$
  Our estimator is based on the maximization of the pseudolikelihood, a notion
that has received extensive analysis for various probabilistic models without
[Chatterjee, Annals of Statistics '07] or with truncation [Galanis et al. SODA
'24]. Our approach generalizes recent techniques from [Daskalakis et al. STOC
'19, Galanis et al. SODA '24], to confront the more challenging setting of the
truncated Ising model.

</details>


### [170] [Bridging Privacy and Utility: Synthesizing anonymized EEG with constraining utility functions](https://arxiv.org/abs/2509.20454)
*Kay Fuhrmeister,Arne Pelzer,Fabian Radke,Julia Lechinger,Mahzad Gharleghi,Thomas Köllmer,Insa Wolf*

Main category: cs.LG

TL;DR: EEG数据存在隐私泄露风险，提出一种基于Transformer的自编码器模型，可在保护用户身份信息的同时保留其在机器学习应用中的效用。


<details>
  <summary>Details</summary>
Motivation: 现有EEG数据应用广泛，但其易于泄露用户个人信息，引发了对用户隐私的担忧，因此需要研究如何在保护隐私的同时保留EEG数据的效用。

Method: 提出一种基于Transformer的自编码器模型，用于生成无法识别被试身份但仍保留特定机器学习任务效用的EEG数据。

Result: 将该方法应用于自动睡眠分期，并评估了匿名化前后EEG数据的可识别性和效用。实验结果表明，该方法能显著降低EEG信号的可识别性，同时保留其在机器学习中的效用。

Conclusion: 所提出的基于Transformer的自编码器模型能够有效保护EEG数据的隐私，同时满足其在机器学习应用中的效用需求。

Abstract: Electroencephalography (EEG) is widely used for recording brain activity and
has seen numerous applications in machine learning, such as detecting sleep
stages and neurological disorders. Several studies have successfully shown the
potential of EEG data for re-identification and leakage of other personal
information. Therefore, the increasing availability of EEG consumer devices
raises concerns about user privacy, motivating us to investigate how to
safeguard this sensitive data while retaining its utility for EEG applications.
To address this challenge, we propose a transformer-based autoencoder to create
EEG data that does not allow for subject re-identification while still
retaining its utility for specific machine learning tasks. We apply our
approach to automatic sleep staging by evaluating the re-identification and
utility potential of EEG data before and after anonymization. The results show
that the re-identifiability of the EEG signal can be substantially reduced
while preserving its utility for machine learning.

</details>


### [171] [Efficiently Attacking Memorization Scores](https://arxiv.org/abs/2509.20463)
*Tue Do,Varun Chandrasekaran,Daniel Alabi*

Main category: cs.LG

TL;DR: 攻击者可以操纵基于记忆分数的影响力估计器，即使在模型准确的情况下也是如此，并且存在理论上的不稳定性。


<details>
  <summary>Details</summary>
Motivation: 研究基于记忆分数的影响力估计器是否可能被对手操纵，特别是在数据估值和负责任的机器学习等应用中。

Method: 提出了一种操纵记忆分数的方法，该方法将高记忆度样本视为在训练算法准确时的敏感查询。该方法利用了伪逆的计算，只需要对模型输出进行黑盒访问，并具有适度的计算开销。

Result: 在各种图像分类任务中，即使是最先进的代理也容易受到有针对性的分数操纵。还对记忆分数在对抗性扰动下的稳定性进行了理论分析。

Conclusion: 基于影响力的归因存在严重漏洞，需要开发稳健的防御措施。

Abstract: Influence estimation tools -- such as memorization scores -- are widely used
to understand model behavior, attribute training data, and inform dataset
curation. However, recent applications in data valuation and responsible
machine learning raise the question: can these scores themselves be
adversarially manipulated? In this work, we present a systematic study of the
feasibility of attacking memorization-based influence estimators. We
characterize attacks for producing highly memorized samples as highly sensitive
queries in the regime where a trained algorithm is accurate. Our attack
(calculating the pseudoinverse of the input) is practical, requiring only
black-box access to model outputs and incur modest computational overhead. We
empirically validate our attack across a wide suite of image classification
tasks, showing that even state-of-the-art proxies are vulnerable to targeted
score manipulations. In addition, we provide a theoretical analysis of the
stability of memorization scores under adversarial perturbations, revealing
conditions under which influence estimates are inherently fragile. Our findings
highlight critical vulnerabilities in influence-based attribution and suggest
the need for robust defenses. All code can be found at
https://anonymous.4open.science/r/MemAttack-5413/

</details>


### [172] [AbideGym: Turning Static RL Worlds into Adaptive Challenges](https://arxiv.org/abs/2509.21234)
*Abi Aryan,Zac Liu,Aaron Childress*

Main category: cs.LG

TL;DR: AbideGym是一个动态MiniGrid包装器，通过引入智能体感知扰动和可扩展的复杂性来强制执行单集适应，以解决强化学习中的脆性策略问题。


<details>
  <summary>Details</summary>
Motivation: 强化学习智能体通常会产生在动态变化时会失效的脆弱策略，而静态基准会加剧这个问题。AbideGym旨在通过引入动态和智能体感知的挑战来解决这一问题。

Method: AbideGym通过引入智能体感知扰动和可扩展的复杂性来实现这一点，这些扰动和复杂性在每个训练片段内进行调整。

Result: AbideGym通过暴露静态策略的弱点并促进适应性来提供一个可重复的评估框架。

Conclusion: AbideGym是一个用于评估和改进强化学习智能体适应性和鲁棒性的动态MiniGrid包装器，有助于在课程学习、持续学习和鲁棒泛化等领域取得进展。

Abstract: Agents trained with reinforcement learning often develop brittle policies
that fail when dynamics shift, a problem amplified by static benchmarks.
AbideGym, a dynamic MiniGrid wrapper, introduces agent-aware perturbations and
scalable complexity to enforce intra-episode adaptation. By exposing weaknesses
in static policies and promoting resilience, AbideGym provides a modular,
reproducible evaluation framework for advancing research in curriculum
learning, continual learning, and robust generalization.

</details>


### [173] [Offline Goal-conditioned Reinforcement Learning with Quasimetric Representations](https://arxiv.org/abs/2509.20478)
*Vivek Myers,Bill Chunyuan Zheng,Benjamin Eysenbach,Sergey Levine*

Main category: cs.LG

TL;DR: 本研究提出了一种统一对比表示和时间距离表示的方法，用于目标条件强化学习（GCRL），并在现有离线GCRL基准测试中取得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的GCRL方法通常依赖于学习到的状态表示来提取达到目标的策略。其中，对比表示（学习“后继特征”）和时间距离（将表示空间中的距离与状态到目标的转移时间联系起来）是两种特别有效的框架。然而，这两种方法各有优缺点，例如对比表示在某些任务上表现不佳，而时间距离方法在有噪声或随机的环境中可能难以处理。

Method: 本研究提出了一种统一对比表示和时间距离表示的方法。该方法利用了拟度量表示空间（满足三角不等式）的结构，并添加了额外的约束来学习能够实现最优目标到达的后继表示。具体来说，它结合了对比学习的稳定性和长期能力，以及拟度量网络参数化的“自由拼接”能力。

Result: 该方法在现有离线GCRL基准测试中，在需要拼接任务（对比学习方法表现不佳）和在有噪声、高维环境（拟度量网络方法表现不佳）的任务上都取得了更好的性能。与过去的工作不同，该方法能够利用拟度量距离参数化来学习最优的目标到达距离，即使在数据不最优或环境随机的情况下也是如此。

Conclusion: 本研究成功地统一了对比表示和时间距离表示，并通过结合两者的优点，在GCRL任务中取得了显著的性能提升，特别是在处理需要拼接和在复杂环境中达到目标的任务时。

Abstract: Approaches for goal-conditioned reinforcement learning (GCRL) often use
learned state representations to extract goal-reaching policies. Two frameworks
for representation structure have yielded particularly effective GCRL
algorithms: (1) *contrastive representations*, in which methods learn
"successor features" with a contrastive objective that performs inference over
future outcomes, and (2) *temporal distances*, which link the (quasimetric)
distance in representation space to the transit time from states to goals. We
propose an approach that unifies these two frameworks, using the structure of a
quasimetric representation space (triangle inequality) with the right
additional constraints to learn successor representations that enable optimal
goal-reaching. Unlike past work, our approach is able to exploit a
**quasimetric** distance parameterization to learn **optimal** goal-reaching
distances, even with **suboptimal** data and in **stochastic** environments.
This gives us the best of both worlds: we retain the stability and long-horizon
capabilities of Monte Carlo contrastive RL methods, while getting the free
stitching capabilities of quasimetric network parameterizations. On existing
offline GCRL benchmarks, our representation learning objective improves
performance on stitching tasks where methods based on contrastive learning
struggle, and on noisy, high-dimensional environments where methods based on
quasimetric networks struggle.

</details>


### [174] [CoSupFormer : A Contrastive Supervised learning approach for EEG signal Classification](https://arxiv.org/abs/2509.20489)
*D. Darankoum,C. Habermacher,J. Volle,S. Grudinin*

Main category: cs.LG

TL;DR: 提出了一种新的端到端深度学习框架，用于从原始脑电图（EEG）信号中提取多尺度信息，处理噪声和通道变异性，并在多种应用中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 从原始脑电图（EEG）信号中提取有意义的特征，同时处理噪声和通道变异性仍然是一个重大挑战，尽管EEG信号包含对理解大脑状态至关重要的丰富多尺度信息，并可能应用于诊断和药物开发。

Method: 设计了一个能够显式捕获多尺度频率振荡的编码器，并引入了一个基于注意力的编码器来学习通道间的交互和单个通道内局部块的交互。此外，还集成了一个专门的门控网络来动态过滤噪声和非信息性通道。整个编码过程由一个结合了监督学习和对比学习的新型损失函数指导。

Result: 该框架在多个应用中得到验证，包括中枢神经系统（CNS）疾病治疗效果的分类，以及帕金森病和阿尔茨海默病（Alzheimer's disease）的诊断。结果表明，该模型能够从不同物种的原始EEG信号中提取具有生物学意义的模式，自主选择高质量的通道，并通过创新的架构和损失设计实现稳健的泛化。

Conclusion: 所提出的深度学习框架能够有效地从原始EEG信号中提取多尺度信息，处理噪声和通道变异性，并实现稳健的泛化，在CNS疾病分类和神经退行性疾病诊断等多种应用中显示出潜力。

Abstract: Electroencephalography signals (EEGs) contain rich multi-scale information
crucial for understanding brain states, with potential applications in
diagnosing and advancing the drug development landscape. However, extracting
meaningful features from raw EEG signals while handling noise and channel
variability remains a major challenge. This work proposes a novel end-to-end
deep-learning framework that addresses these issues through several key
innovations. First, we designed an encoder capable of explicitly capturing
multi-scale frequency oscillations covering a wide range of features for
different EEG-related tasks. Secondly, to model complex dependencies and handle
the high temporal resolution of EEGs, we introduced an attention-based encoder
that simultaneously learns interactions across EEG channels and within
localized {\em patches} of individual channels. We integrated a dedicated
gating network on top of the attention encoder to dynamically filter out noisy
and non-informative channels, enhancing the reliability of EEG data. The entire
encoding process is guided by a novel loss function, which leverages supervised
and contrastive learning, significantly improving model generalization. We
validated our approach in multiple applications, ranging from the
classification of effects across multiple Central Nervous System (CNS)
disorders treatments to the diagnosis of Parkinson's and Alzheimer's disease.
Our results demonstrate that the proposed learning paradigm can extract
biologically meaningful patterns from raw EEG signals across different species,
autonomously select high-quality channels, and achieve robust generalization
through innovative architectural and loss design.

</details>


### [175] [Beyond Visual Similarity: Rule-Guided Multimodal Clustering with explicit domain rules](https://arxiv.org/abs/2509.20501)
*Kishor Datta Gupta,Mohd Ariful Haque,Marufa Kamal,Ahmed Rafi Hasan,Md. Mahfuzur Rahman,Roy George*

Main category: cs.LG

TL;DR: DARTVAE是一个结合了领域特定规则和变分自编码器的多模态聚类框架，能够生成更具可解释性的聚类结果，但面临规则幻觉、过拟合和可扩展性等挑战。


<details>
  <summary>Details</summary>
Motivation: 传统聚类方法仅依赖输入数据的相似性，无法有效捕捉领域内的结构或语义约束，而DARTVAE旨在通过整合领域知识来解决此问题。

Method: DARTVAE扩展了变分自编码器（VAE）架构，将显式规则、语义表示和数据驱动特征嵌入统一的潜在空间。通过在损失函数中加入规则一致性和违反惩罚，强制执行约束。规则由大型语言模型（LLM）生成，并构建为知识图谱。损失函数包含重建、KL散度、一致性和违反惩罚。

Result: 在飞机和汽车数据集上的实验表明，DARTVAE生成的聚类结果在操作上更具意义且更易于解释（例如，区分无人机、统一隐形飞机、分离SUV和轿车），并能提升传统的聚类指标。

Conclusion: DARTVAE通过结合规则编码和学习到的表示，实现了比纯粹数据驱动模型更有意义和更一致的聚类结果，证明了约束引导的多模态聚类在复杂、知识密集型环境中的效用。然而，该框架也面临LLM生成的规则可能产生幻觉或冲突、规则过多可能导致过拟合以及扩展到复杂领域会增加计算和一致性难度等挑战。

Abstract: Traditional clustering techniques often rely solely on similarity in the
input data, limiting their ability to capture structural or semantic
constraints that are critical in many domains. We introduce the Domain Aware
Rule Triggered Variational Autoencoder (DARTVAE), a rule guided multimodal
clustering framework that incorporates domain specific constraints directly
into the representation learning process. DARTVAE extends the VAE architecture
by embedding explicit rules, semantic representations, and data driven features
into a unified latent space, while enforcing constraint compliance through rule
consistency and violation penalties in the loss function. Unlike conventional
clustering methods that rely only on visual similarity or apply rules as post
hoc filters, DARTVAE treats rules as first class learning signals. The rules
are generated by LLMs, structured into knowledge graphs, and enforced through a
loss function combining reconstruction, KL divergence, consistency, and
violation penalties. Experiments on aircraft and automotive datasets
demonstrate that rule guided clustering produces more operationally meaningful
and interpretable clusters for example, isolating UAVs, unifying stealth
aircraft, or separating SUVs from sedans while improving traditional clustering
metrics. However, the framework faces challenges: LLM generated rules may
hallucinate or conflict, excessive rules risk overfitting, and scaling to
complex domains increases computational and consistency difficulties. By
combining rule encodings with learned representations, DARTVAE achieves more
meaningful and consistent clustering outcomes than purely data driven models,
highlighting the utility of constraint guided multimodal clustering for
complex, knowledge intensive settings.

</details>


### [176] [Myosotis: structured computation for attention like layer](https://arxiv.org/abs/2509.20503)
*Evgenii Egorov,Hanno Ackermann,Markus Nagel,Hong Cai*

Main category: cs.LG

TL;DR: Attention机制计算复杂度高，本文提出一种结合稀疏化和循环依赖的新算法，利用了高效的树状结构矩阵求逆。


<details>
  <summary>Details</summary>
Motivation: Attention层计算量随序列长度二次方增长，现有方法（稀疏化、循环依赖）各有不足。

Method: 提出一种结合稀疏化和循环依赖的新算法，基于高效的树状结构矩阵求逆。

Result: 未在摘要中提供

Conclusion: 未在摘要中提供

Abstract: Attention layers apply a sequence-to-sequence mapping whose parameters depend
on the pairwise interactions of the input elements. However, without any
structural assumptions, memory and compute scale quadratically with the
sequence length. The two main ways to mitigate this are to introduce sparsity
by ignoring a sufficient amount of pairwise interactions or to introduce
recurrent dependence along them, as SSM does. Although both approaches are
reasonable, they both have disadvantages. We propose a novel algorithm that
combines the advantages of both concepts. Our idea is based on the efficient
inversion of tree-structured matrices.

</details>


### [177] [Auto-Regressive U-Net for Full-Field Prediction of Shrinkage-Induced Damage in Concrete](https://arxiv.org/abs/2509.20507)
*Liya Gaynutdinova,Petr Havlásek,Ondřej Rokoš,Fleur Hendriks,Martin Doškář*

Main category: cs.LG

TL;DR: 本研究提出了一种深度学习方法来预测混凝土中随时间变化的损伤场，使用自回归U-Net模型预测损伤演化，并结合CNN预测力学性能，实现了高效且准确的损伤评估，有助于优化混凝土设计。


<details>
  <summary>Details</summary>
Motivation: 预测混凝土中随时间变化的损伤场，以提高计算效率并获得对微观结构与宏观性能之间关系的洞察。

Method: 使用自回归U-Net模型预测损伤演化，并利用CNN预测力学性能（如收缩和刚度）。

Result: 该双网络架构在合成数据集上表现出高计算效率和稳健的预测性能，能够有效评估损伤并预测力学性能。

Conclusion: 该方法能够有效评估混凝土的损伤演化和力学性能，减少计算量，并为优化混凝土配合比、提高耐久性提供指导。

Abstract: This paper introduces a deep learning approach for predicting time-dependent
full-field damage in concrete. The study uses an auto-regressive U-Net model to
predict the evolution of the scalar damage field in a unit cell given
microstructural geometry and evolution of an imposed shrinkage profile. By
sequentially using the predicted damage output as input for subsequent
predictions, the model facilitates the continuous assessment of damage
progression. Complementarily, a convolutional neural network (CNN) utilises the
damage estimations to forecast key mechanical properties, including observed
shrinkage and residual stiffness. The proposed dual-network architecture
demonstrates high computational efficiency and robust predictive performance on
the synthesised datasets. The approach reduces the computational load
traditionally associated with full-field damage evaluations and is used to gain
insights into the relationship between aggregate properties, such as shape,
size, and distribution, and the effective shrinkage and reduction in stiffness.
Ultimately, this can help to optimize concrete mix designs, leading to improved
durability and reduced internal damage.

</details>


### [178] [A Recovery Theory for Diffusion Priors: Deterministic Analysis of the Implicit Prior Algorithm](https://arxiv.org/abs/2509.20511)
*Oscar Leong,Yann Traonmilin*

Main category: cs.LG

TL;DR: 该论文提出了一个分析确定性扩散模型在逆问题中恢复信号的理论框架，并推导了收敛速度，同时适用于低维凸集和低秩高斯混合模型。 


<details>
  <summary>Details</summary>
Motivation: 逆问题中的高维信号恢复面临挑战，尽管生成扩散模型在实践中表现出色，但理论保证不足。 

Method: 提出一个分析确定性扩散算法的理论框架，将扩散模型理解为广义投影梯度下降，并推导了在感知矩阵满足受限等距性质下的量化收敛速度。 

Result: 在低维紧凸集和低秩高斯混合模型上应用该框架，即使在模型集非凸的情况下，也能获得全局收敛保证。 

Conclusion: 该理论框架为理解和分析基于扩散模型的逆问题恢复算法提供了数学基础，并展示了其在不同数据分布下的有效性。

Abstract: Recovering high-dimensional signals from corrupted measurements is a central
challenge in inverse problems. Recent advances in generative diffusion models
have shown remarkable empirical success in providing strong data-driven priors,
but rigorous recovery guarantees remain limited. In this work, we develop a
theoretical framework for analyzing deterministic diffusion-based algorithms
for inverse problems, focusing on a deterministic version of the algorithm
proposed by Kadkhodaie \& Simoncelli \cite{kadkhodaie2021stochastic}. First, we
show that when the underlying data distribution concentrates on a
low-dimensional model set, the associated noise-convolved scores can be
interpreted as time-varying projections onto such a set. This leads to
interpreting previous algorithms using diffusion priors for inverse problems as
generalized projected gradient descent methods with varying projections. When
the sensing matrix satisfies a restricted isometry property over the model set,
we can derive quantitative convergence rates that depend explicitly on the
noise schedule. We apply our framework to two instructive data distributions:
uniform distributions over low-dimensional compact, convex sets and low-rank
Gaussian mixture models. In the latter setting, we can establish global
convergence guarantees despite the nonconvexity of the underlying model set.

</details>


### [179] [Complexity-Driven Policy Optimization](https://arxiv.org/abs/2509.20509)
*Luca Serfilippi,Giorgio Franceschelli,Antonio Corradi,Mirco Musolesi*

Main category: cs.LG

TL;DR: 策略梯度方法通过最大化熵来实现探索与利用的平衡，但最大化熵可能导致策略趋向于随机分布，从而造成低效的探索。本文提出用一个更鲁棒的复杂度奖励来替代熵奖励。复杂度被定义为熵与偏离均匀分布的距离（不均衡度）的乘积。该正则项鼓励策略在随机性和结构性之间取得平衡，从而引导智能体发现有用的、非平凡的行为。实验表明，在离散动作空间任务中，复杂度驱动策略优化（CDPO）比近端策略优化（PPO）对系数的选择更鲁棒，尤其是在需要更大探索的环境中。


<details>
  <summary>Details</summary>
Motivation: 最大化熵会导致策略趋向于均匀随机分布，造成探索策略的非结构化和低效。

Method: 提出用复杂度奖励替代熵奖励，复杂度被定义为熵与不均衡度的乘积。不均衡度量化了策略与均匀分布的距离。基于PPO，提出复杂度驱动策略优化（CDPO）算法。

Result: 在离散动作空间任务中，CDPO在鼓励智能体发现结构化且适应性强的策略方面表现优于PPO。CDPO对复杂度系数的选择比PPO对熵系数的选择更具鲁棒性，特别是在需要大量探索的环境中。

Conclusion: 复杂度奖励比熵奖励更能有效地引导策略在随机性和结构性之间取得平衡，从而促进有意义行为的出现。CDPO算法在探索方面比PPO更有效和鲁棒。

Abstract: Policy gradient methods often balance exploitation and exploration via
entropy maximization. However, maximizing entropy pushes the policy towards a
uniform random distribution, which represents an unstructured and sometimes
inefficient exploration strategy. In this work, we propose replacing the
entropy bonus with a more robust complexity bonus. In particular, we adopt a
measure of complexity, defined as the product of Shannon entropy and
disequilibrium, where the latter quantifies the distance from the uniform
distribution. This regularizer encourages policies that balance stochasticity
(high entropy) with structure (high disequilibrium), guiding agents toward
regimes where useful, non-trivial behaviors can emerge. Such behaviors arise
because the regularizer suppresses both extremes, e.g., maximal disorder and
complete order, creating pressure for agents to discover structured yet
adaptable strategies. Starting from Proximal Policy Optimization (PPO), we
introduce Complexity-Driven Policy Optimization (CDPO), a new learning
algorithm that replaces entropy with complexity. We show empirically across a
range of discrete action space tasks that CDPO is more robust to the choice of
the complexity coefficient than PPO is with the entropy coefficient, especially
in environments requiring greater exploration.

</details>


### [180] [PIRF: Physics-Informed Reward Fine-Tuning for Diffusion Models](https://arxiv.org/abs/2509.20570)
*Mingze Yuan,Pengfei Jin,Na Li,Quanzheng Li*

Main category: cs.LG

TL;DR: 物理约束下的生成模型可以通过稀疏奖励优化问题来解决，但现有的基于DPS的方法存在训练不稳定和推理效率低的问题。PIRF方法通过直接反向传播轨迹奖励梯度来解决这些问题，并使用分层截断反向传播和基于权重的正则化来提高样本效率和数据保真度。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型在科学领域有很强的生成能力，但常常产生违反物理定律的输出。本文旨在通过将物理信息生成视为稀疏奖励优化问题来解决这一挑战。

Method: 提出了一种名为物理信息奖励微调（PIRF）的新方法，该方法通过计算轨迹级别的奖励并直接反向传播其梯度来绕过价值函数逼近。PIRF采用了分层截断反向传播和基于权重的正则化方案来提高样本效率和数据保真度。

Result: 在五个偏微分方程基准测试中，PIRF在高效采样机制下始终实现了优越的物理约束执行能力。

Conclusion: 奖励微调在推进科学生成模型方面具有巨大潜力，PIRF在物理约束执行方面表现出色，同时保持了高样本效率和数据保真度。

Abstract: Diffusion models have demonstrated strong generative capabilities across
scientific domains, but often produce outputs that violate physical laws. We
propose a new perspective by framing physics-informed generation as a sparse
reward optimization problem, where adherence to physical constraints is treated
as a reward signal. This formulation unifies prior approaches under a
reward-based paradigm and reveals a shared bottleneck: reliance on diffusion
posterior sampling (DPS)-style value function approximations, which introduce
non-negligible errors and lead to training instability and inference
inefficiency. To overcome this, we introduce Physics-Informed Reward
Fine-tuning (PIRF), a method that bypasses value approximation by computing
trajectory-level rewards and backpropagating their gradients directly. However,
a naive implementation suffers from low sample efficiency and compromised data
fidelity. PIRF mitigates these issues through two key strategies: (1) a
layer-wise truncated backpropagation method that leverages the spatiotemporally
localized nature of physics-based rewards, and (2) a weight-based
regularization scheme that improves efficiency over traditional
distillation-based methods. Across five PDE benchmarks, PIRF consistently
achieves superior physical enforcement under efficient sampling regimes,
highlighting the potential of reward fine-tuning for advancing scientific
generative modeling.

</details>


### [181] [MDBench: Benchmarking Data-Driven Methods for Model Discovery](https://arxiv.org/abs/2509.20529)
*Amirmohammad Ziaei Bideh,Aleksandra Georgievska,Jonathan Gryak*

Main category: cs.LG

TL;DR: MDBench是一个用于评估动态系统模型发现方法的开源基准测试框架，它包含14个偏微分方程（PDE）和63个常微分方程（ODE）数据集，并在不同噪声水平下评估了12种算法。结果表明，线性方法在PDEs上表现最佳，而遗传编程方法在ODEs上表现最佳，线性模型通常更具鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的模型发现方法主要集中在识别单个方程，缺乏针对动态系统发现的综合基准。MDBench旨在解决这一问题，为跟踪该领域的进展和理解各种方法的权衡提供支持。

Method: MDBench评估了12种算法在14个偏微分方程（PDE）和63个常微分方程（ODE）数据集上的表现，并在不同噪声水平下进行。评估指标包括导数预测精度、模型复杂度和方程保真度。此外，还引入了七个来自流体动力学和热力学的具有挑战性的PDE系统。

Result: 在PDEs上，线性方法和遗传编程方法分别实现了最低的预测误差。在ODEs上，线性方法和遗传编程方法分别实现了最低的预测误差。线性模型通常比其他模型更具鲁棒性。

Conclusion: MDBench通过提供一个严格、可扩展的基准测试框架和丰富、多样化的动态系统数据集，加速了模型发现方法的进步，从而能够系统地评估、比较和改进方程的准确性和鲁棒性。

Abstract: Model discovery aims to uncover governing differential equations of dynamical
systems directly from experimental data. Benchmarking such methods is essential
for tracking progress and understanding trade-offs in the field. While prior
efforts have focused mostly on identifying single equations, typically framed
as symbolic regression, there remains a lack of comprehensive benchmarks for
discovering dynamical models. To address this, we introduce MDBench, an
open-source benchmarking framework for evaluating model discovery methods on
dynamical systems. MDBench assesses 12 algorithms on 14 partial differential
equations (PDEs) and 63 ordinary differential equations (ODEs) under varying
levels of noise. Evaluation metrics include derivative prediction accuracy,
model complexity, and equation fidelity. We also introduce seven challenging
PDE systems from fluid dynamics and thermodynamics, revealing key limitations
in current methods. Our findings illustrate that linear methods and genetic
programming methods achieve the lowest prediction error for PDEs and ODEs,
respectively. Moreover, linear models are in general more robust against noise.
MDBench accelerates the advancement of model discovery methods by offering a
rigorous, extensible benchmarking framework and a rich, diverse collection of
dynamical system datasets, enabling systematic evaluation, comparison, and
improvement of equation accuracy and robustness.

</details>


### [182] [Guiding Application Users via Estimation of Computational Resources for Massively Parallel Chemistry Computations](https://arxiv.org/abs/2509.20667)
*Tanzila Tabassum,Omer Subasi,Ajay Panyala,Epiya Ebiapia,Gerald Baumgartner,Erdal Mutlu,P.,Sadayappan,Karol Kowalski*

Main category: cs.LG

TL;DR: 提出基于机器学习的策略来预测大规模并行化学计算的资源消耗，以优化执行时间和最小化计算成本。


<details>
  <summary>Details</summary>
Motivation: 旨在帮助用户在昂贵的超级计算机实验前预测计算资源需求，确定最优的运行时参数（如节点数和块大小）以实现最短执行时间或最低资源消耗。

Method: 采用梯度提升（GB）等机器学习模型，并结合主动学习策略，对CCSD（耦合簇单双）应用程序在Aurora和Frontier超级计算机上的执行时间进行预测。收集和分析了大量运行时参数数据用于模型训练和评估。

Result: 梯度提升模型在预测CCSD迭代执行时间方面表现出色，在Aurora和Frontier上的平均绝对百分比误差（MAPE）分别为0.023和0.073。在实验成本高昂的情况下，主动学习策略仅通过收集约450个实验数据点就能达到约0.2的MAPE。

Conclusion: 机器学习，特别是梯度提升和主动学习，能够有效预测大规模并行化学计算的资源需求，为用户优化计算任务、节省时间和计算资源提供了有力支持。

Abstract: In this work, we develop machine learning (ML) based strategies to predict
resources (costs) required for massively parallel chemistry computations, such
as coupled-cluster methods, to guide application users before they commit to
running expensive experiments on a supercomputer. By predicting application
execution time, we determine the optimal runtime parameter values such as
number of nodes and tile sizes. Two key questions of interest to users are
addressed. The first is the shortest-time question, where the user is
interested in knowing the parameter configurations (number of nodes and tile
sizes) to achieve the shortest execution time for a given problem size and a
target supercomputer. The second is the cheapest-run question in which the user
is interested in minimizing resource usage, i.e., finding the number of nodes
and tile size that minimizes the number of node-hours for a given problem size.
  We evaluate a rich family of ML models and strategies, developed based on the
collections of runtime parameter values for the CCSD (Coupled Cluster with
Singles and Doubles) application executed on the Department of Energy (DOE)
Frontier and Aurora supercomputers. Our experiments show that when predicting
the total execution time of a CCSD iteration, a Gradient Boosting (GB) ML model
achieves a Mean Absolute Percentage Error (MAPE) of 0.023 and 0.073 for Aurora
and Frontier, respectively. In the case where it is expensive to run
experiments just to collect data points, we show that active learning can
achieve a MAPE of about 0.2 with just around 450 experiments collected from
Aurora and Frontier.

</details>


### [183] [Training Task Reasoning LLM Agents for Multi-turn Task Planning via Single-turn Reinforcement Learning](https://arxiv.org/abs/2509.20616)
*Hanjiang Hu,Changliu Liu,Na Li,Yebin Wang*

Main category: cs.LG

TL;DR: LLM 智能体在复杂多轮任务规划中面临稀疏奖励、信用分配和计算开销等挑战。本文提出一种将多轮任务规划转化为单轮任务推理的方法，利用基于专家轨迹的密集且可验证奖励的群体相对策略优化（GRPO）进行高效策略优化。实验表明，1.5B 参数模型在复杂任务规划基准上优于高达 14B 参数的基线模型，在超过 30 步的长视域规划任务中成功率达 70%。


<details>
  <summary>Details</summary>
Motivation: 解决 LLM 智能体在复杂多轮任务规划中面临的稀疏奖励、信用分配难题和训练计算开销大的问题。

Method: 将多轮任务规划转化为单轮任务推理问题，并使用群体相对策略优化（GRPO）结合专家轨迹提供的密集且可验证的奖励来进行策略优化。

Result: 在复杂任务规划基准测试中，使用单轮 GRPO 训练的 1.5B 参数模型在超过 30 步的长视域规划任务中取得了 70% 的成功率，优于参数量高达 14B 的基线模型。此外，模型展示了在复杂任务上训练后，能够成功完成所有更简单的子任务的跨任务泛化能力。

Conclusion: 所提出的方法能够有效地解决 LLM 智能体在复杂多轮任务规划中的挑战，并通过将问题转化为单轮推理和利用 GRPO 优化，实现了优越的性能和良好的泛化能力。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in
knowledge acquisition, reasoning, and tool use, making them promising
candidates for autonomous agent applications. However, training LLM agents for
complex multi-turn task planning faces significant challenges, including sparse
episode-wise rewards, credit assignment across long horizons, and the
computational overhead of reinforcement learning in multi-turn interaction
settings. To this end, this paper introduces a novel approach that transforms
multi-turn task planning into single-turn task reasoning problems, enabling
efficient policy optimization through Group Relative Policy Optimization (GRPO)
with dense and verifiable reward from expert trajectories. Our theoretical
analysis shows that GRPO improvement on single-turn task reasoning results in
higher multi-turn success probability under the minimal turns, as well as the
generalization to subtasks with shorter horizons. Experimental evaluation on
the complex task planning benchmark demonstrates that our 1.5B parameter model
trained with single-turn GRPO achieves superior performance compared to larger
baseline models up to 14B parameters, with success rates of 70% for
long-horizon planning tasks with over 30 steps. We also theoretically and
empirically validate the strong cross-task generalizability that the models
trained on complex tasks can lead to the successful completion of all simpler
subtasks.

</details>


### [184] [Understanding and Improving Adversarial Robustness of Neural Probabilistic Circuits](https://arxiv.org/abs/2509.20549)
*Weixin Chen,Han Zhao*

Main category: cs.LG

TL;DR: NPCs are interpretable but vulnerable to adversarial attacks on their attribute recognition component. This paper analyzes this vulnerability, showing it depends only on the attribute model's robustness. A new model, RNPC, is proposed, which is robust to these attacks using class-wise inference, offering provably better adversarial robustness and maintaining high accuracy.


<details>
  <summary>Details</summary>
Motivation: The attribute recognition model in Neural Probabilistic Circuits (NPCs) is a black box vulnerable to adversarial attacks, potentially compromising the final predictions despite the model's overall interpretability and performance. Thus, there is a need to analyze and improve the adversarial robustness of NPCs.

Method: The paper theoretically analyzes the adversarial robustness of NPCs, determining it depends solely on the attribute recognition model. Then, it proposes RNPC, incorporating a novel class-wise inference mechanism to combine outputs robustly, and theoretically proves its improved adversarial robustness.

Result: RNPC demonstrates superior adversarial robustness compared to existing concept bottleneck models on image classification tasks, while maintaining high accuracy on benign inputs. Theoretical analysis confirms RNPC's provably improved adversarial robustness over NPC.

Conclusion: RNPC is the first robust Neural Probabilistic Circuit against adversarial attacks targeting the recognition module. It offers provably enhanced adversarial robustness through a novel class-wise inference strategy, making it a more secure and reliable model for tasks where interpretability and robustness are crucial.

Abstract: Neural Probabilistic Circuits (NPCs), a new class of concept bottleneck
models, comprise an attribute recognition model and a probabilistic circuit for
reasoning. By integrating the outputs from these two modules, NPCs produce
compositional and interpretable predictions. While offering enhanced
interpretability and high performance on downstream tasks, the
neural-network-based attribute recognition model remains a black box. This
vulnerability allows adversarial attacks to manipulate attribute predictions by
introducing carefully crafted subtle perturbations to input images, potentially
compromising the final predictions. In this paper, we theoretically analyze the
adversarial robustness of NPC and demonstrate that it only depends on the
robustness of the attribute recognition model and is independent of the
robustness of the probabilistic circuit. Moreover, we propose RNPC, the first
robust neural probabilistic circuit against adversarial attacks on the
recognition module. RNPC introduces a novel class-wise integration for
inference, ensuring a robust combination of outputs from the two modules. Our
theoretical analysis demonstrates that RNPC exhibits provably improved
adversarial robustness compared to NPC. Empirical results on image
classification tasks show that RNPC achieves superior adversarial robustness
compared to existing concept bottleneck models while maintaining high accuracy
on benign inputs.

</details>


### [185] [Go With The Flow: Churn-Tolerant Decentralized Training of Large Language Models](https://arxiv.org/abs/2509.21221)
*Nikolay Blagoev,Bart Cox,Jérémie Decouchant,Lydia Y. Chen*

Main category: cs.LG

TL;DR: GWTF是第一个面向LLMs的崩溃容错、实用、去中心化的训练框架，它实现了异构客户端的有效协作训练，并解决了节点和网络不稳定的问题。


<details>
  <summary>Details</summary>
Motivation: LLMs的出现以及训练民主化的重要性。

Method: 提出了一种新颖的去中心化流算法，用于寻找最有效的路由，以最低延迟最大化训练的微批次数。

Result: 在涉及异构客户端节点、跨越10个不同地理位置、具有高节点流失率的现实挑战性场景中，GWTF将训练时间缩短了高达45%。

Conclusion: GWTF通过其新颖的去中心化流算法，有效地解决了LLM去中心化训练中的关键挑战，并在性能上显著优于现有技术。

Abstract: Motivated by the emergence of large language models (LLMs) and the importance
of democratizing their training, we propose GWTF, the first crash tolerant
practical decentralized training framework for LLMs. Differently from existing
distributed and federated training frameworks, GWTF enables the efficient
collaborative training of a LLM on heterogeneous clients that volunteer their
resources. In addition, GWTF addresses node churn, i.e., clients joining or
leaving the system at any time, and network instabilities, i.e., network links
becoming unstable or unreliable. The core of GWTF is a novel decentralized flow
algorithm that finds the most effective routing that maximizes the number of
microbatches trained with the lowest possible delay. We extensively evaluate
GWTF on GPT-like and LLaMa-like models and compare it against the prior art.
Our results indicate that GWTF reduces the training time by up to 45% in
realistic and challenging scenarios that involve heterogeneous client nodes
distributed over 10 different geographic locations with a high node churn rate.

</details>


### [186] [Generalizable Diabetes Risk Stratification via Hybrid Machine Learning Models](https://arxiv.org/abs/2509.20565)
*Athar Parvez,Muhammad Jawad Mufti*

Main category: cs.LG

TL;DR: XGB-RF在内部和外部队列中均优于SVM-LR，在糖尿病风险分层中表现出更强的稳健性和可转移性。


<details>
  <summary>Details</summary>
Motivation: 糖尿病患者人数众多且预计将大幅增加，早期风险分层可以通过机器学习实现。

Method: 构建了XGBoost + Random Forest (XGB-RF) 和 Support Vector Machine + Logistic Regression (SVM-LR) 两个混合分类器，并使用标准化的流水线进行训练和验证，优先考虑阈值无关的指标（AUROC/AUPRC）和校准度。

Result: XGB-RF在内部和外部队列中均取得了优于SVM-LR的性能，在PIMA队列上的阈值性能也更优。

Conclusion: XGB-RF在内部和外部队列中均表现优于SVM-LR，且外部衰减较小，校准度可接受。这表明基于梯度提升的混合方法在糖尿病风险分层中是稳健且可转移的，并鼓励进行前瞻性的多中心验证。

Abstract: Background/Purpose: Diabetes affects over 537 million people worldwide and is
projected to reach 783 million by 2045. Early risk stratification can benefit
from machine learning. We compare two hybrid classifiers and assess their
generalizability on an external cohort.
  Methods: Two hybrids were built: (i) XGBoost + Random Forest (XGB-RF) and
(ii) Support Vector Machine + Logistic Regression (SVM-LR). A leakage-safe,
standardized pipeline (encoding, imputation, min-max scaling; SMOTE on training
folds only; probability calibration for SVM) was fit on the primary dataset and
frozen. Evaluation prioritized threshold-independent discrimination
(AUROC/AUPRC) and calibration (Brier, slope/intercept). External validation
used the PIMA cohort (N=768) with the frozen pipeline; any thresholded metrics
on PIMA were computed at the default rule tau = 0.5.
  Results: On the primary dataset (PR baseline = 0.50), XGB-RF achieved AUROC
~0.995 and AUPRC ~0.998, outperforming SVM-LR (AUROC ~0.978; AUPRC ~0.947). On
PIMA (PR baseline ~0.349), XGB-RF retained strong performance (AUROC ~0.990;
AUPRC ~0.959); SVM-LR was lower (AUROC ~0.963; AUPRC ~0.875). Thresholded
metrics on PIMA at tau = 0.5 were XGB-RF (Accuracy 0.960; Precision 0.941;
Recall 0.944; F1 0.942) and SVM-LR (Accuracy 0.900; Precision 0.855; Recall
0.858; F1 0.857).
  Conclusions: Across internal and external cohorts, XGB-RF consistently
dominated SVM-LR and exhibited smaller external attenuation on ROC/PR with
acceptable calibration. These results support gradient-boosting-based
hybridization as a robust, transferable approach for diabetes risk
stratification and motivate prospective, multi-site validation with
deployment-time threshold selection based on clinical trade-offs.

</details>


### [187] [SuperOffload: Unleashing the Power of Large-Scale LLM Training on Superchips](https://arxiv.org/abs/2509.21271)
*Xinyu Lian,Masahiro Tanaka,Olatunji Ruwase,Minjia Zhang*

Main category: cs.LG

TL;DR: 本研究首次研究了基于卸载的超级芯片LLM训练解决方案，并提出了SuperOffload系统，在GH200上实现了高达2.5倍的吞吐量提升。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对LLM训练如何受益于集成GPU和CPU的超级芯片新架构的探讨。

Method: 提出了一种名为SuperOffload的、以超级芯片为中心的数据卸载系统，该系统结合了自适应权重卸载、桶划分重构、超级芯片感知转换、投机执行以及针对Grace CPU的高度优化的Adam优化器等技术，以更有效地利用Hopper GPU、Grace CPU和NVLink-C2C互连。

Result: 在NVIDIA GH200上，SuperOffload实现了高达2.5倍的吞吐量提升，能够支持在单个超级芯片上训练高达250亿参数的模型，并保持高训练吞吐量。此外，结合ZeRO数据并行和DeepSpeed-Ulysses序列并行，可以在8个GH200上以55%的MFU训练具有高达100万个标记的序列长度的130亿参数模型。

Conclusion: SuperOffload系统能够有效地利用超级芯片的异构计算能力，显著提高LLM训练的效率和规模，为在先进硬件上训练更大、更复杂的模型提供了新的解决方案。

Abstract: The emergence of Superchips represents a significant advancement in
next-generation AI hardware. These Superchips employ a tightly coupled
heterogeneous architecture that integrates GPU and CPU on the same package,
which offers unprecedented computational power. However, there has been scant
research investigating how LLM training benefits from this new architecture. In
this work, for the first time, we study LLM training solutions based on
offloading for Superchips. We observe important differences between Superchips
and traditional loosely-coupled GPU-CPU architecture, which necessitate
revisiting prevailing assumptions about offloading. Based on that, we present
SuperOffload, a Superchip-centric offloading system that simultaneously uses
Hopper GPU, Grace CPU, and NVLink-C2C interconnect more efficiently.
SuperOffload accomplishes this via a combination of techniques, such as
adaptive weight offloading, bucketization repartitioning, Superchip-aware
casting, speculative execution, and a highly optimized Adam optimizer for Grace
CPUs. Our evaluation of SuperOffload on NVIDIA GH200 demonstrates up to 2.5x
throughput improvement compared to state-of-the-art offloading-based systems,
enabling training of up to 25B model on a single Superchip while achieving high
training throughput. We also extend SuperOffload with ZeRO-style data
parallelism and DeepSpeed-Ulysses sequence parallelism, enabling training of
13B model with sequence lengths up to 1 million tokens on 8 GH200 while
achieving 55% MFU.

</details>


### [188] [The Sensitivity of Variational Bayesian Neural Network Performance to Hyperparameters](https://arxiv.org/abs/2509.20574)
*Scott Koermer,Natalie Klein*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In scientific applications, predictive modeling is often of limited use
without accurate uncertainty quantification (UQ) to indicate when a model may
be extrapolating or when more data needs to be collected. Bayesian Neural
Networks (BNNs) produce predictive uncertainty by propagating uncertainty in
neural network (NN) weights and offer the promise of obtaining not only an
accurate predictive model but also accurate UQ. However, in practice, obtaining
accurate UQ with BNNs is difficult due in part to the approximations used for
practical model training and in part to the need to choose a suitable set of
hyperparameters; these hyperparameters outnumber those needed for traditional
NNs and often have opaque effects on the results. We aim to shed light on the
effects of hyperparameter choices for BNNs by performing a global sensitivity
analysis of BNN performance under varying hyperparameter settings. Our results
indicate that many of the hyperparameters interact with each other to affect
both predictive accuracy and UQ. For improved usage of BNNs in real-world
applications, we suggest that global sensitivity analysis, or related methods
such as Bayesian optimization, should be used to aid in dimensionality
reduction and selection of hyperparameters to ensure accurate UQ in BNNs.

</details>


### [189] [Learning Greens Operators through Hierarchical Neural Networks Inspired by the Fast Multipole Method](https://arxiv.org/abs/2509.20591)
*Emilio McAllister Fognini,Marta M. Betcke,Ben T. Cox*

Main category: cs.LG

TL;DR: Neural FMM是一个将快速多极算法(FMM)与神经网络相结合的新模型，用于学习椭圆偏微分方程的格林算子。


<details>
  <summary>Details</summary>
Motivation: 现有的FMM算法在物理和工程中有广泛应用，但与现代机器学习的结合仍需探索。

Method: 提出了一种名为Neural FMM的新型神经网络架构，该架构利用FMM的层级计算流程来分离局部和远场相互作用，并有效地学习它们的表示。

Result: Neural FMM能够学习椭圆偏微分方程的格林算子。

Conclusion: Neural FMM为将FMM的计算效率和层级特性应用于机器学习提供了一种新颖有效的方法。

Abstract: The Fast Multipole Method (FMM) is an efficient numerical algorithm for
computation of long-ranged forces in $N$-body problems within gravitational and
electrostatic fields. This method utilizes multipole expansions of the Green's
function inherent to the underlying dynamical systems. Despite its widespread
application in physics and engineering, the integration of FMM with modern
machine learning architectures remains underexplored. In this work, we propose
a novel neural network architecture, the Neural FMM, that integrates the
information flow of the FMM into a hierarchical machine learning framework for
learning the Green's operator of an Elliptic PDE. Our Neural FMM architecture
leverages a hierarchical computation flow of the FMM method to split up the
local and far-field interactions and efficiently learn their respective
representations.

</details>


### [190] [TSKAN: Interpretable Machine Learning for QoE modeling over Time Series Data](https://arxiv.org/abs/2509.20595)
*Kamal Singh,Priyanka Rawat,Sami Marouani,Baptiste Jeudy*

Main category: cs.LG

TL;DR: 提出一种使用可解释机器学习技术和频域特征对视频流的观看体验质量进行建模的新方法，提高了预测准确性并增强了模型的可解释性。


<details>
  <summary>Details</summary>
Motivation: 视频流服务的观看体验质量（QoE）建模对于优化服务至关重要，需要捕捉不同特征与用户体验之间的复杂关系。

Method: 结合使用Kolmogorov-Arnold Networks（KANs）和紧凑的频域特征，对原始时间序列数据进行处理，以捕捉时间信息并保持模型透明度和可解释性。

Result: 在流行的数据集上评估了该方法，证明其在QoE预测方面具有更高的准确性，并提供了可解释性。

Conclusion: 所提出的基于KANs和频域特征的可解释机器学习方法能够准确预测视频流的QoE，同时提供模型透明度。

Abstract: Quality of Experience (QoE) modeling is crucial for optimizing video
streaming services to capture the complex relationships between different
features and user experience. We propose a novel approach to QoE modeling in
video streaming applications using interpretable Machine Learning (ML)
techniques over raw time series data. Unlike traditional black-box approaches,
our method combines Kolmogorov-Arnold Networks (KANs) as an interpretable
readout on top of compact frequency-domain features, allowing us to capture
temporal information while retaining a transparent and explainable model. We
evaluate our method on popular datasets and demonstrate its enhanced accuracy
in QoE prediction, while offering transparency and interpretability.

</details>


### [191] [Function Spaces Without Kernels: Learning Compact Hilbert Space Representations](https://arxiv.org/abs/2509.20605)
*Su Ann Low,Quentin Rommel,Kevin S. Miller,Adam J. Thorpe,Ufuk Topcu*

Main category: cs.LG

TL;DR: 函数编码器提供了一种学习神经网络基函数以形成希尔伯特函数空间的紧凑、自适应表示的新技术。通过定义学习到的特征映射的内积来学习函数编码器，为特征学习和核方法提供了原则性联系。


<details>
  <summary>Details</summary>
Motivation: 函数编码器提供了原则性的联系，可以学习神经网络基函数以形成希尔伯特函数空间的紧凑、自适应表示。它解释了它们如何独立于数据集大小进行扩展，同时适应数据的内在结构，并能够对神经网络模型进行核风格分析。

Method: 通过定义学习到的特征映射的内积来学习函数编码器。开发了两种学习紧凑基的训练算法：渐进式训练方法和训练后修剪方法。这两种方法都使用主成分分析（PCA）的原理来揭示学习空间的内在维度。此外，还使用 Rademacher 复杂性和 PAC-Bayes 技术推导了有限样本泛化界限。

Result: 通过对具有已知内在维度的多项式基准以及包括范德波尔振荡器和二体轨道模型在内的非线性动力学系统进行验证，证明了在具有显著更少的基函数的情况下，可以实现相同的准确性。

Conclusion: 这项工作提出了一种实现具有核级别保证的神经网络预测器的方法，从而能够实现高效且有原则的可扩展的自适应模型。

Abstract: Function encoders are a recent technique that learn neural network basis
functions to form compact, adaptive representations of Hilbert spaces of
functions. We show that function encoders provide a principled connection to
feature learning and kernel methods by defining a kernel through an inner
product of the learned feature map. This kernel-theoretic perspective explains
their ability to scale independently of dataset size while adapting to the
intrinsic structure of data, and it enables kernel-style analysis of neural
models. Building on this foundation, we develop two training algorithms that
learn compact bases: a progressive training approach that constructively grows
bases, and a train-then-prune approach that offers a computationally efficient
alternative after training. Both approaches use principles from PCA to reveal
the intrinsic dimension of the learned space. In parallel, we derive
finite-sample generalization bounds using Rademacher complexity and PAC-Bayes
techniques, providing inference time guarantees. We validate our approach on a
polynomial benchmark with a known intrinsic dimension, and on nonlinear
dynamical systems including a Van der Pol oscillator and a two-body orbital
model, demonstrating that the same accuracy can be achieved with substantially
fewer basis functions. This work suggests a path toward neural predictors with
kernel-level guarantees, enabling adaptable models that are both efficient and
principled at scale.

</details>


### [192] [MMG: Mutual Information Estimation via the MMSE Gap in Diffusion](https://arxiv.org/abs/2509.20609)
*Longxuan Yu,Xing Shi,Xianghao Kong,Tong Jia,Greg Ver Steeg*

Main category: cs.LG

TL;DR: MI estimation can be improved by using denoising diffusion models, which correspond to half the gap in the MMSE between conditional and unconditional diffusion, integrated over all SNRs. This method outperforms traditional estimators and is scalable due to adaptive importance sampling.


<details>
  <summary>Details</summary>
Motivation: Estimating mutual information (MI) for complex systems is challenging. Denoising diffusion models have shown promise in density estimation, making them a potential candidate for improving MI estimation.

Method: The proposed method uses an information-theoretic formulation of denoising diffusion models to estimate MI. The MI is calculated as half the gap in the MMSE between conditional and unconditional diffusion, integrated over all SNRs.

Result: The proposed method passes self-consistency tests and outperforms traditional and score-based diffusion MI estimators. It is also scalable and maintains strong performance even with high MI values, due to adaptive importance sampling.

Conclusion: Denoising diffusion models can be effectively used for MI estimation, offering a scalable and high-performing approach compared to existing methods.

Abstract: Mutual information (MI) is one of the most general ways to measure
relationships between random variables, but estimating this quantity for
complex systems is challenging. Denoising diffusion models have recently set a
new bar for density estimation, so it is natural to consider whether these
methods could also be used to improve MI estimation. Using the recently
introduced information-theoretic formulation of denoising diffusion models, we
show the diffusion models can be used in a straightforward way to estimate MI.
In particular, the MI corresponds to half the gap in the Minimum Mean Square
Error (MMSE) between conditional and unconditional diffusion, integrated over
all Signal-to-Noise-Ratios (SNRs) in the noising process. Our approach not only
passes self-consistency tests but also outperforms traditional and score-based
diffusion MI estimators. Furthermore, our method leverages adaptive importance
sampling to achieve scalable MI estimation, while maintaining strong
performance even when the MI is high.

</details>


### [193] [Policy Compatible Skill Incremental Learning via Lazy Learning Interface](https://arxiv.org/abs/2509.20612)
*Daehee Lee,Dongsu Lee,TaeYoon Kwack,Wonje Choi,Honguk Woo*

Main category: cs.LG

TL;DR: 该研究提出了一种名为SIL-C的新框架，用于解决技能增量学习（SIL）中技能-策略兼容性问题，通过双边懒惰学习映射，使新学习的技能能够兼容现有策略，无需重新训练或结构调整，从而提高下游策略的性能。


<details>
  <summary>Details</summary>
Motivation: 技能增量学习（SIL）旨在让代理能够随着时间的推移扩展和改进其技能，但随着技能库的演变，可能会破坏与现有基于技能的策略的兼容性，限制其可重用性和泛化能力。

Method: SIL-C框架采用双边懒惰学习映射技术，动态地将策略引用的子任务空间与解码为代理行为的技能空间对齐，使策略能够通过轨迹分布相似性选择合适的技能来执行子任务。

Result: 评估结果表明，SIL-C在各种SIL场景中都能保持不断演变的技能与下游策略之间的兼容性，并确保学习过程的效率。

Conclusion: SIL-C框架有效地解决了技能增量学习中的技能-策略兼容性问题，使得新学习的技能的改进能够提升下游策略的性能，而无需进行策略的重新训练或结构调整。

Abstract: Skill Incremental Learning (SIL) is the process by which an embodied agent
expands and refines its skill set over time by leveraging experience gained
through interaction with its environment or by the integration of additional
data. SIL facilitates efficient acquisition of hierarchical policies grounded
in reusable skills for downstream tasks. However, as the skill repertoire
evolves, it can disrupt compatibility with existing skill-based policies,
limiting their reusability and generalization. In this work, we propose SIL-C,
a novel framework that ensures skill-policy compatibility, allowing
improvements in incrementally learned skills to enhance the performance of
downstream policies without requiring policy re-training or structural
adaptation. SIL-C employs a bilateral lazy learning-based mapping technique to
dynamically align the subtask space referenced by policies with the skill space
decoded into agent behaviors. This enables each subtask, derived from the
policy's decomposition of a complex task, to be executed by selecting an
appropriate skill based on trajectory distribution similarity. We evaluate
SIL-C across diverse SIL scenarios and demonstrate that it maintains
compatibility between evolving skills and downstream policies while ensuring
efficiency throughout the learning process.

</details>


### [194] [Personalized Federated Dictionary Learning for Modeling Heterogeneity in Multi-site fMRI Data](https://arxiv.org/abs/2509.20627)
*Yipu Zhang,Chengshuo Zhang,Ziyu Zhou,Gang Qu,Hao Zheng,Yuping Wang,Hui Shen,Hongwen Deng*

Main category: cs.LG

TL;DR: PFedDL是一种新的联邦学习框架，可以在不共享原始数据的情况下，在多站点fMRI研究中解决数据隐私和非IID数据问题，通过结合全局和本地字典学习来提高模型的可泛化性。


<details>
  <summary>Details</summary>
Motivation: 数据隐私限制和多站点fMRI研究中的异质性导致数据非独立同分布（non-IID），阻碍了可泛化模型的开发。

Method: PFedDL框架在每个站点独立进行字典学习，将字典分解为共享全局组件和个性化本地组件。全局原子通过联邦聚合进行更新以促进跨站点一致性，本地原子独立更新以捕捉站点特异性变异性。

Result: 在ABIDE数据集上的实验表明，PFedDL在非IID数据集的准确性和鲁棒性方面优于现有方法。

Conclusion: PFedDL成功地解决了多站点fMRI研究中的数据隐私和异质性挑战，提高了模型的准确性和鲁棒性。

Abstract: Data privacy constraints pose significant challenges for large-scale
neuroimaging analysis, especially in multi-site functional magnetic resonance
imaging (fMRI) studies, where site-specific heterogeneity leads to
non-independent and identically distributed (non-IID) data. These factors
hinder the development of generalizable models. To address these challenges, we
propose Personalized Federated Dictionary Learning (PFedDL), a novel federated
learning framework that enables collaborative modeling across sites without
sharing raw data. PFedDL performs independent dictionary learning at each site,
decomposing each site-specific dictionary into a shared global component and a
personalized local component. The global atoms are updated via federated
aggregation to promote cross-site consistency, while the local atoms are
refined independently to capture site-specific variability, thereby enhancing
downstream analysis. Experiments on the ABIDE dataset demonstrate that PFedDL
outperforms existing methods in accuracy and robustness across non-IID
datasets.

</details>


### [195] [Investigating Modality Contribution in Audio LLMs for Music](https://arxiv.org/abs/2509.20641)
*Giovana Morais,Magdalena Fuentes*

Main category: cs.LG

TL;DR: 该研究使用 MM-SHAP 框架量化了音频大型语言模型 (Audio LLMs) 在回答关于音乐的问题时，音频和文本模态的贡献度，发现准确率更高的模型更依赖文本，但音频模态并非完全被忽略。


<details>
  <summary>Details</summary>
Motivation: 评估 Audio LLMs 是真正理解音频内容还是仅依赖文本推理。

Method: 采用 MM-SHAP 框架，一种基于 Shapley 值的性能无关评分方法，量化每个模态对模型预测的相对贡献度。

Result: 在 MuChoMusic 基准测试中，准确率更高的模型更依赖文本进行回答。尽管整体音频贡献度较低，但模型仍能成功定位关键声音事件，表明音频并非完全被忽略。

Conclusion: 该研究首次将 MM-SHAP 应用于 Audio LLMs，并希望为未来可解释 AI 和音频领域的研究奠定基础。

Abstract: Audio Large Language Models (Audio LLMs) enable human-like conversation about
music, yet it is unclear if they are truly listening to the audio or just using
textual reasoning, as recent benchmarks suggest. This paper investigates this
issue by quantifying the contribution of each modality to a model's output. We
adapt the MM-SHAP framework, a performance-agnostic score based on Shapley
values that quantifies the relative contribution of each modality to a model's
prediction. We evaluate two models on the MuChoMusic benchmark and find that
the model with higher accuracy relies more on text to answer questions, but
further inspection shows that even if the overall audio contribution is low,
models can successfully localize key sound events, suggesting that audio is not
entirely ignored. Our study is the first application of MM-SHAP to Audio LLMs
and we hope it will serve as a foundational step for future research in
explainable AI and audio.

</details>


### [196] [Wonder Wins Ways: Curiosity-Driven Exploration through Multi-Agent Contextual Calibration](https://arxiv.org/abs/2509.20648)
*Yiyuan Pan,Zhe Liu,Hesheng Wang*

Main category: cs.LG

TL;DR: CERMIC通过结合环境新颖性和同伴行为新颖性来增强多智能体探索，解决了稀疏奖励和噪声信号的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的好奇心机制在区分环境随机性和有意义的新颖性方面存在不足，并且忽视了对潜在任务动态至关重要的同伴行为新颖性。这导致在去中心化、无通信的多智能体强化学习（MARL）设置中探索效率低下。

Method: 提出了一种名为CERMIC的框架，该框架通过推断多智能体上下文来动态校准智能体的内在好奇心，从而过滤噪声信号并指导探索。此外，CERMIC生成具有理论依据的内在奖励，鼓励智能体探索信息增益高的状态转换。

Result: 在VMAS、Meltingpot和SMACv2等基准测试中，CERMIC在稀疏奖励环境下显著优于最先进的算法。

Conclusion: CERMIC通过自适应地结合环境新颖性和同伴行为新颖性，为多智能体探索提供了一种有效且可扩展的解决方案。

Abstract: Autonomous exploration in complex multi-agent reinforcement learning (MARL)
with sparse rewards critically depends on providing agents with effective
intrinsic motivation. While artificial curiosity offers a powerful
self-supervised signal, it often confuses environmental stochasticity with
meaningful novelty. Moreover, existing curiosity mechanisms exhibit a uniform
novelty bias, treating all unexpected observations equally. However, peer
behavior novelty, which encode latent task dynamics, are often overlooked,
resulting in suboptimal exploration in decentralized, communication-free MARL
settings. To this end, inspired by how human children adaptively calibrate
their own exploratory behaviors via observing peers, we propose a novel
approach to enhance multi-agent exploration. We introduce CERMIC, a principled
framework that empowers agents to robustly filter noisy surprise signals and
guide exploration by dynamically calibrating their intrinsic curiosity with
inferred multi-agent context. Additionally, CERMIC generates
theoretically-grounded intrinsic rewards, encouraging agents to explore state
transitions with high information gain. We evaluate CERMIC on benchmark suites
including VMAS, Meltingpot, and SMACv2. Empirical results demonstrate that
exploration with CERMIC significantly outperforms SoTA algorithms in
sparse-reward environments.

</details>


### [197] [Theoretical Bounds for Stable In-Context Learning](https://arxiv.org/abs/2509.20677)
*Tongxi Wang,Zhuoyang Xia*

Main category: cs.LG

TL;DR: ICL的可靠性对提示长度敏感。本文提出了一种基于谱性质的分析方法，并开发了一种两阶段估计器，以在有限样本下提高ICL的可解释性和可靠性。


<details>
  <summary>Details</summary>
Motivation: ICL的可靠性对提示长度敏感，需要对其进行分析和改进。

Method: 1. 建立非渐近下界，连接演示次数和ICL稳定性。 2. 提出一种两阶段可观测估计器，具有单次校准功能。

Result: 1. 理论分析给出了具体的充分条件。 2. 实验表明，预测阈值与经验阈值高度一致。 3. 校准后的估计器进一步缩小了理论与实践的差距。

Conclusion: 谱覆盖与稳定的ICL相关，弥合了理论与实践的差距，并提高了大规模提示在实际有限样本下的可解释性和可靠性。

Abstract: In-context learning (ICL) is flexible but its reliability is highly sensitive
to prompt length. This paper establishes a non-asymptotic lower bound that
links the minimal number of demonstrations to ICL stability under fixed
high-dimensional sub-Gaussian representations. The bound gives explicit
sufficient conditions in terms of spectral properties of the covariance,
providing a computable criterion for practice. Building on this analysis, we
propose a two-stage observable estimator with a one-shot calibration that
produces practitioner-ready prompt-length estimates without distributional
priors. Experiments across diverse datasets, encoders, and generators show
close alignment between the predicted thresholds and empirical knee-points,
with the theory acting as a conservative but reliable upper bound; the
calibrated variant further tightens this gap. These results connect spectral
coverage to stable ICL, bridge theory and deployment, and improve the
interpretability and reliability of large-scale prompting in realistic
finite-sample regimes.

</details>


### [198] [Bispectral OT: Dataset Comparison using Symmetry-Aware Optimal Transport](https://arxiv.org/abs/2509.20678)
*Annabel Ma,Kaiying Hou,David Alvarez-Melis,Melanie Weber*

Main category: cs.LG

TL;DR: Bispectral Optimal Transport (BOT) is a symmetry-aware extension of discrete OT that uses bispectrum representation for alignment, improving class preservation accuracy over naive feature OT on datasets with visual symmetries.


<details>
  <summary>Details</summary>
Motivation: Naive Optimal Transport (OT) methods can ignore intrinsic data coherence structure in symmetry-rich settings when relying solely on pairwise geometric distances of raw features. Existing methods fail to preserve the intrinsic coherence structure of the data.

Method: Introduce Bispectral Optimal Transport (BOT), a symmetry-aware extension of discrete OT. BOT compares elements using their representation via the bispectrum, which is a group Fourier invariant that preserves all signal structure while removing only the variation due to group actions.

Result: Transport plans computed with BOT achieve greater class preservation accuracy than naive feature OT on benchmark datasets transformed with visual symmetries. This improves the quality of meaningful correspondences that capture the underlying semantic label structure in the dataset while removing nuisance variation not affecting class or content.

Conclusion: Bispectral Optimal Transport (BOT) is an effective approach for aligning datasets with symmetries, outperforming naive feature OT in preserving class structure and capturing meaningful semantic correspondences.

Abstract: Optimal transport (OT) is a widely used technique in machine learning,
graphics, and vision that aligns two distributions or datasets using their
relative geometry. In symmetry-rich settings, however, OT alignments based
solely on pairwise geometric distances between raw features can ignore the
intrinsic coherence structure of the data. We introduce Bispectral Optimal
Transport, a symmetry-aware extension of discrete OT that compares elements
using their representation using the bispectrum, a group Fourier invariant that
preserves all signal structure while removing only the variation due to group
actions. Empirically, we demonstrate that the transport plans computed with
Bispectral OT achieve greater class preservation accuracy than naive feature OT
on benchmark datasets transformed with visual symmetries, improving the quality
of meaningful correspondences that capture the underlying semantic label
structure in the dataset while removing nuisance variation not affecting class
or content.

</details>


### [199] [Can Federated Learning Safeguard Private Data in LLM Training? Vulnerabilities, Attacks, and Defense Evaluation](https://arxiv.org/abs/2509.20680)
*Wenkai Guo,Xuefeng Liu,Haolin Wang,Jianwei Niu,Shaojie Tang,Jing Yuan*

Main category: cs.LG

TL;DR: 大型语言模型（LLM）的联邦学习（FL）在保护隐私的同时进行协作训练，但存在数据泄露风险，本研究提出了增强的攻击策略并评估了缓解技术。


<details>
  <summary>Details</summary>
Motivation: 组织不愿意共享本地数据，但希望通过协作微调LLM来利用不同组织间数据的共同特征，这使得中心化微调不切实际。联邦学习（FL）提供了一种潜在的解决方案，因为它允许客户保留本地数据，只共享模型参数进行协作训练。

Method: 在联邦学习（FL）框架下，作者进行了广泛的实验，包括设计增强的攻击策略，该策略可以跟踪全局模型更新以增强隐私泄露，并评估了差分隐私、正则化约束更新以及采用经过安全对齐的LLM等隐私保护技术。

Result: 实验表明，即使使用简单的生成方法，攻击者仍然可以从全局模型中提取训练数据，并且随着模型尺寸的增大，数据泄露会增加。增强的攻击策略能够加剧隐私泄露。

Conclusion: 本研究通过实验证明，即使采用联邦学习（FL），LLM的训练数据仍然存在泄露风险。研究还评估了几种隐私保护技术，为在FL中训练LLM时降低隐私风险提供了实用的指导。

Abstract: Fine-tuning large language models (LLMs) with local data is a widely adopted
approach for organizations seeking to adapt LLMs to their specific domains.
Given the shared characteristics in data across different organizations, the
idea of collaboratively fine-tuning an LLM using data from multiple sources
presents an appealing opportunity. However, organizations are often reluctant
to share local data, making centralized fine-tuning impractical. Federated
learning (FL), a privacy-preserving framework, enables clients to retain local
data while sharing only model parameters for collaborative training, offering a
potential solution. While fine-tuning LLMs on centralized datasets risks data
leakage through next-token prediction, the iterative aggregation process in FL
results in a global model that encapsulates generalized knowledge, which some
believe protects client privacy. In this paper, however, we present
contradictory findings through extensive experiments. We show that attackers
can still extract training data from the global model, even using
straightforward generation methods, with leakage increasing as the model size
grows. Moreover, we introduce an enhanced attack strategy tailored to FL, which
tracks global model updates during training to intensify privacy leakage. To
mitigate these risks, we evaluate privacy-preserving techniques in FL,
including differential privacy, regularization-constrained updates and adopting
LLMs with safety alignment. Our results provide valuable insights and practical
guidelines for reducing privacy risks when training LLMs with FL.

</details>


### [200] [Learning to Align Molecules and Proteins: A Geometry-Aware Approach to Binding Affinity](https://arxiv.org/abs/2509.20693)
*Mohammadsaleh Refahi,Bahrad A. Sokhansanj,James R. Brown,Gail Rosen*

Main category: cs.LG

TL;DR: FIRM-DTI是一个轻量级框架，通过FiLM层将分子嵌入条件化于蛋白质嵌入，并使用三元组损失强制执行度量结构，从而在药物靶点亲和力预测方面实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习模型在药物靶点亲和力预测方面，通常采用简单的拼接方式融合配体和蛋白质的表示，并且缺乏显式的几何正则化，导致在化学空间和时间上的泛化能力较差，因此需要更优化的模型来加速药物发现。

Method: 提出了一种名为FIRM-DTI的轻量级框架，该框架利用特征无关的线性调制（FiLM）层将分子嵌入条件化于蛋白质嵌入，并通过三元组损失强制执行度量结构。此外，采用基于径向基函数（RBF）的回归模型对嵌入距离进行预测，以实现平滑且可解释的亲和力预测。

Result: FIRM-DTI在Therapeutics Data Commons DTI-DG基准测试中取得了最先进的性能，并且通过广泛的消融研究和跨域评估证明了其有效性。

Conclusion: 该研究结果强调了条件化和度量学习在实现鲁棒的药物靶点亲和力预测方面的价值。

Abstract: Accurate prediction of drug-target binding affinity can accelerate drug
discovery by prioritizing promising compounds before costly wet-lab screening.
While deep learning has advanced this task, most models fuse ligand and protein
representations via simple concatenation and lack explicit geometric
regularization, resulting in poor generalization across chemical space and
time. We introduce FIRM-DTI, a lightweight framework that conditions molecular
embeddings on protein embeddings through a feature-wise linear modulation
(FiLM) layer and enforces metric structure with a triplet loss. An RBF
regression head operating on embedding distances yields smooth, interpretable
affinity predictions. Despite its modest size, FIRM-DTI achieves
state-of-the-art performance on the Therapeutics Data Commons DTI-DG benchmark,
as demonstrated by an extensive ablation study and out-of-domain evaluation.
Our results underscore the value of conditioning and metric learning for robust
drug-target affinity prediction.

</details>


### [201] [CE-GPPO: Controlling Entropy via Gradient-Preserving Clipping Policy Optimization in Reinforcement Learning](https://arxiv.org/abs/2509.20712)
*Zhenpeng Su,Leiyu Pan,Minxuan Lv,Yuntao Li,Wenping Hu,Fuzheng Zhang,Kun Gai,Guorui Zhou*

Main category: cs.LG

TL;DR: CE-GPPO 算法通过保留被截断 token 的梯度来优化大型语言模型，解决了 PPO 算法中的熵不稳定性问题，并在数学推理任务上取得了优于基线方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于 PPO 的强化学习方法在优化大型语言模型时存在策略熵管理挑战，PPO 及其变体通过裁剪机制丢弃了低概率 token 的梯度信息，导致熵不稳定。

Method: 提出了一种名为 CE-GPPO 的新算法，该算法通过温和且有界的方式重新引入 PPO 中被裁剪 token 的梯度，从而控制了这些 token 的梯度幅度，实现了探索-利用的权衡，并提供了理论依据和实证证据。

Result: CE-GPPO 有效地缓解了熵不稳定性，并在数学推理基准测试中，在不同模型规模下持续优于强基线方法。

Conclusion: CE-GPPO 是一种有效优化大型语言模型处理复杂推理任务的新算法，通过解决熵不稳定性问题，提高了模型的性能。

Abstract: Reinforcement learning (RL) has become a powerful paradigm for optimizing
large language models (LLMs) to handle complex reasoning tasks. A core
challenge in this process lies in managing policy entropy, which reflects the
balance between exploration and exploitation during training. Existing methods,
such as proximal policy optimization (PPO) and its variants, discard valuable
gradient signals from low-probability tokens due to the clipping mechanism. We
systematically analyze the entropy dynamics and reveal that these clipped
tokens play a critical yet overlooked role in regulating entropy evolution. We
propose \textbf{C}ontrolling \textbf{E}ntropy via
\textbf{G}radient-\textbf{P}reserving \textbf{P}olicy \textbf{O}ptimization
(CE-GPPO), a novel algorithm that reintroduces gradients from clipped tokens in
native PPO in a gentle and bounded manner. By controlling the magnitude of
gradients from tokens outside the clipping interval, CE-GPPO is able to achieve
an exploration-exploitation trade-off. We provide theoretical justification and
empirical evidence showing that CE-GPPO effectively mitigates entropy
instability. Extensive experiments on mathematical reasoning benchmarks show
that CE-GPPO consistently outperforms strong baselines across different model
scales.

</details>


### [202] [A Genetic Algorithm for Navigating Synthesizable Molecular Spaces](https://arxiv.org/abs/2509.20719)
*Alston Lo,Connor W. Coley,Wojciech Matusik*

Main category: cs.LG

TL;DR: SynGA是一种直接在合成路线上操作的遗传算法，通过自定义的交叉和变异算子确保生成的分子具有可合成性。该算法可用于多种设计任务，如可合成类似物搜索和高效属性优化，并可通过结合机器学习滤波器进一步提升性能，最终形成SynGBO用于贝叶斯优化。


<details>
  <summary>Details</summary>
Motivation: 遗传算法在分子设计中的有效性以及可合成性在分子设计中的重要性。

Method: SynGA是一种直接在合成路线（而不是分子结构）上进行操作的遗传算法。通过自定义的交叉和变异算子，它能够直接生成可合成的分子。此外，通过修改适应度函数，可以将其应用于不同的设计任务。通过将SynGA与基于机器学习的滤波器相结合，可以优化其性能，生成SynGBO（一种模型优化的贝叶斯优化变体）。

Result: SynGA在2D和3D目标的可合成类似物搜索和样本高效属性优化等多种设计任务中都显示出了有效性。与基于机器学习的滤波器相结合，SynGA达到了最先进的性能。SynGBO通过在贝叶斯优化的内循环中使用SynGA和块过滤，在属性优化方面表现出色。

Conclusion: SynGA算法轻量级且通过构建强制可合成性，有望成为一个强大的独立基线，并可作为模块集成到未来的合成感知工作流中。

Abstract: Inspired by the effectiveness of genetic algorithms and the importance of
synthesizability in molecular design, we present SynGA, a simple genetic
algorithm that operates directly over synthesis routes. Our method features
custom crossover and mutation operators that explicitly constrain it to
synthesizable molecular space. By modifying the fitness function, we
demonstrate the effectiveness of SynGA on a variety of design tasks, including
synthesizable analog search and sample-efficient property optimization, for
both 2D and 3D objectives. Furthermore, by coupling SynGA with a machine
learning-based filter that focuses the building block set, we boost SynGA to
state-of-the-art performance. For property optimization, this manifests as a
model-based variant SynGBO, which employs SynGA and block filtering in the
inner loop of Bayesian optimization. Since SynGA is lightweight and enforces
synthesizability by construction, our hope is that SynGA can not only serve as
a strong standalone baseline but also as a versatile module that can be
incorporated into larger synthesis-aware workflows in the future.

</details>


### [203] [Scaling Laws are Redundancy Laws](https://arxiv.org/abs/2509.20721)
*Yuda Bi,Vince D Calhoun*

Main category: cs.LG

TL;DR: 深度学习中的缩放定律可以通过冗余定律来解释，其指数取决于数据的冗余度。


<details>
  <summary>Details</summary>
Motivation: 解释深度学习中缩放定律的数学起源，特别是缩放指数。

Method: 使用核回归，表明数据协方差谱中的多项式尾部导致了 excess risk 幂律，其指数为 alpha = 2s / (2s + 1/beta)，其中 beta 控制谱尾，1/beta 衡量冗余度。

Result: 发现了学习曲线的斜率并非普遍存在，而是取决于数据冗余度，谱越陡，规模回报越快。证明了该定律在各种变换、多模态混合、有限宽度近似和 Transformer 架构中具有普遍性。

Conclusion: 首次提供了缩放定律作为有限样本冗余定律的严格数学解释，将经验观察与理论基础统一起来。

Abstract: Scaling laws, a defining feature of deep learning, reveal a striking
power-law improvement in model performance with increasing dataset and model
size. Yet, their mathematical origins, especially the scaling exponent, have
remained elusive. In this work, we show that scaling laws can be formally
explained as redundancy laws. Using kernel regression, we show that a
polynomial tail in the data covariance spectrum yields an excess risk power law
with exponent alpha = 2s / (2s + 1/beta), where beta controls the spectral tail
and 1/beta measures redundancy. This reveals that the learning curve's slope is
not universal but depends on data redundancy, with steeper spectra accelerating
returns to scale. We establish the law's universality across boundedly
invertible transformations, multi-modal mixtures, finite-width approximations,
and Transformer architectures in both linearized (NTK) and feature-learning
regimes. This work delivers the first rigorous mathematical explanation of
scaling laws as finite-sample redundancy laws, unifying empirical observations
with theoretical foundations.

</details>


### [204] [The Impact of Audio Watermarking on Audio Anti-Spoofing Countermeasures](https://arxiv.org/abs/2509.20736)
*Zhenshan Zhang,Xueping Zhang,Yechen Wang,Liwei Jin,Ming Li*

Main category: cs.LG

TL;DR: 音频水印会降低语音欺骗检测系统的性能，但提出的KPWL框架可以减轻这种影响。


<details>
  <summary>Details</summary>
Motivation: 研究音频水印对欺骗对抗系统（用于保护语音应用程序）的影响，这在以前是未被探索过的。

Method: 构建了一个包含音频水印的Watermark-Spoofing数据集，并提出了知识保留水印学习（KPWL）框架来适应水印引起的域转移。

Result: 实验表明，音频水印会降低欺骗对抗性能，水印密度越高，错误率（EER）越高。KPWL框架可以帮助模型适应水印，同时保持其检测欺骗的能力。

Conclusion: 音频水印是一种先前被忽视的域转移，为开发抗水印的欺骗对抗系统建立了第一个基准。

Abstract: This paper presents the first study on the impact of audio watermarking on
spoofing countermeasures. While anti-spoofing systems are essential for
securing speech-based applications, the influence of widely used audio
watermarking, originally designed for copyright protection, remains largely
unexplored. We construct watermark-augmented training and evaluation datasets,
named the Watermark-Spoofing dataset, by applying diverse handcrafted and
neural watermarking methods to existing anti-spoofing datasets. Experiments
show that watermarking consistently degrades anti-spoofing performance, with
higher watermark density correlating with higher Equal Error Rates (EERs). To
mitigate this, we propose the Knowledge-Preserving Watermark Learning (KPWL)
framework, enabling models to adapt to watermark-induced shifts while
preserving their original-domain spoofing detection capability. These findings
reveal audio watermarking as a previously overlooked domain shift and establish
the first benchmark for developing watermark-resilient anti-spoofing systems.
All related protocols are publicly available at
https://github.com/Alphawarheads/Watermark_Spoofing.git

</details>


### [205] [Measuring LLM Sensitivity in Transformer-based Tabular Data Synthesis](https://arxiv.org/abs/2509.20768)
*Maria F. Davila R,Azizjon Turaev,Wolfram Wingerath*

Main category: cs.LG

TL;DR: Transformer-based模型在生成合成表格数据方面表现优异，但计算成本高。本研究评估了超参数选择对数据质量和计算性能的影响，发现GReaT和REaLTabFormer在不同数据集和配置下各有优劣，REaLTabFormer在保证数据质量的同时降低了计算需求，但仍有优化空间。


<details>
  <summary>Details</summary>
Motivation: 评估超参数选择对基于Transformer的表格数据合成（TDS）工具（GReaT和REaLTabFormer）的数据质量和计算性能的影响，为用户提供更优选择。

Method: 在四个真实世界数据集上，评估了10种不同的模型配置（改变架构类型和深度），从运行时间、机器学习（ML）效用和与真实数据分布的相似性三个维度分析了超参数敏感性。

Result: 运行时间与超参数数量成正比，较浅的模型配置运行更快。GReaT的运行时间始终低于REaLTabFormer，仅在最大数据集上两者运行时间相当。在小型数据集上，两者都能生成高质量且相似性最优的合成数据；但在大型数据集上，只有REaLTabFormer能保持良好的效用和相似性。REaLTabFormer结合轻量级LLM能在保证数据质量的同时降低计算需求，但其运行时间仍高于GReaT和其他TDS工具。

Conclusion: REaLTabFormer结合轻量级LLM在保证数据质量和降低计算需求方面取得了最佳平衡，但仍有提升效率的空间。

Abstract: Synthetic tabular data is used for privacy-preserving data sharing and
data-driven model development. Its effectiveness, however, depends heavily on
the used Tabular Data Synthesis (TDS) tool. Recent studies have shown that
Transformer-based models outperform other state-of-the-art models such as
Generative Adversarial Networks (GANs) and Diffusion models in terms of data
quality. However, Transformer-based models also come with high computational
costs, making them sometimes unfeasible for end users with prosumer hardware.
This study presents a sensitivity assessment on how the choice of
hyperparameters, such as number of layers or hidden dimension affects the
quality of the resultant synthetic data and the computational performance. It
is performed across two tools, GReaT and REaLTabFormer, evaluating 10 model
setups that vary in architecture type and depth. We assess the sensitivity on
three dimensions: runtime, machine learning (ML) utility, and similarity to
real data distributions. Experiments were conducted on four real-world
datasets. Our findings reveal that runtime is proportional to the number of
hyperparameters, with shallower configurations completing faster. GReaT
consistently achieves lower runtimes than REaLTabFormer, and only on the
largest dataset they have comparable runtime. For small datasets, both tools
achieve synthetic data with high utility and optimal similarity, but on larger
datasets only REaLTabFormer sustains strong utility and similarity. As a
result, REaLTabFormer with lightweight LLMs provides the best balance, since it
preserves data quality while reducing computational requirements. Nonetheless,
its runtime remains higher than that of GReaT and other TDS tools, suggesting
that efficiency gains are possible but only up to a certain level.

</details>


### [206] [Sig2Model: A Boosting-Driven Model for Updatable Learned Indexes](https://arxiv.org/abs/2509.20781)
*Alireza Heidari,Amirhossein Ahmad,Wei Zhang,Ying Xiong*

Main category: cs.LG

TL;DR: Sig2Model是一种高效、自适应的学习型索引，通过采用三种关键技术来最小化模型再训练成本：(1) 采用sigmoid boosting近似技术，通过近似更新引起的数据分布偏移来动态调整索引模型，并使用局部sigmoid函数来维持有界误差保证并推迟完全再训练；(2) 通过高斯混合模型（GMM）进行主动更新训练，识别高更新概率区域以分配占位符，从而加快更新速度；(3) 采用神经联合优化框架，通过基于梯度的学习不断优化sigmoid集成和GMM参数。


<details>
  <summary>Details</summary>
Motivation: 传统的学习型索引（LIs）在处理静态数据集时效率很高，但在动态更新下性能会下降，因为需要全局模型再训练来维持CDF不变性（F(k)的总和等于1），这会阻塞查询并限制每秒查询次数（QPS）。现有方法未能有效解决这些再训练成本问题，不适用于频繁更新的实际工作负载。

Method: Sig2Model采用三种关键技术：1. Sigmoid boosting近似技术：动态调整索引模型，通过近似更新引起的数据分布偏移，并使用局部sigmoid函数维持有界误差保证，推迟完全再训练。2. 主动更新训练：使用高斯混合模型（GMM）识别高更新概率区域，分配占位符以加快更新速度。3. 神经联合优化框架：通过基于梯度的学习不断优化sigmoid集成和GMM参数。

Result: 与最先进的可更新学习型索引相比，Sig2Model在真实世界和合成工作负载上，将再训练成本降低了高达20倍，实现了高达3倍的QPS提升，并减少了高达1000倍的内存使用量。

Conclusion: Sig2Model通过其创新的方法在可更新学习型索引领域取得了显著的改进，在降低再训练成本、提高QPS和减少内存使用方面都表现出色。

Abstract: Learned Indexes (LIs) represent a paradigm shift from traditional index
structures by employing machine learning models to approximate the cumulative
distribution function (CDF) of sorted data. While LIs achieve remarkable
efficiency for static datasets, their performance degrades under dynamic
updates: maintaining the CDF invariant (sum of F(k) equals 1) requires global
model retraining, which blocks queries and limits the queries-per-second (QPS)
metric. Current approaches fail to address these retraining costs effectively,
rendering them unsuitable for real-world workloads with frequent updates. In
this paper, we present Sig2Model, an efficient and adaptive learned index that
minimizes retraining cost through three key techniques: (1) a sigmoid boosting
approximation technique that dynamically adjusts the index model by
approximating update-induced shifts in data distribution with localized sigmoid
functions while preserving bounded error guarantees and deferring full
retraining; (2) proactive update training via Gaussian mixture models (GMMs)
that identifies high-update-probability regions for strategic placeholder
allocation to speed up updates; and (3) a neural joint optimization framework
that continuously refines both the sigmoid ensemble and GMM parameters via
gradient-based learning. We evaluate Sig2Model against state-of-the-art
updatable learned indexes on real-world and synthetic workloads, and show that
Sig2Model reduces retraining cost by up to 20x, achieves up to 3x higher QPS,
and uses up to 1000x less memory.

</details>


### [207] [IConv: Focusing on Local Variation with Channel Independent Convolution for Multivariate Time Series Forecasting](https://arxiv.org/abs/2509.20783)
*Gawon Lee,Hanbyeol Park,Minseop Kim,Dohee Kim,Hyerim Bae*

Main category: cs.LG

TL;DR: MLP和CNN结合用于时间序列预测，MLP捕捉长期依赖，CNN（特别是IConv）捕捉局部模式和跨通道关系，实验证明了该方法的优越性。


<details>
  <summary>Details</summary>
Motivation: MLP在处理时间序列时，其线性结构限制了它捕捉局部变化（如季节性、残差）的能力，而CNN可以有效捕捉这些变化。因此，需要结合两者的优势。

Method: 提出了一种结合MLP和CNN（特别是IConv）的模型。MLP用于建模长期趋势，CNN用于建模细粒度的局部模式。IConv是一种新的卷积架构，它独立处理时间依赖通道，并通过不同层考虑通道间的关系。

Result: 所提出的模型在多元时间序列预测任务的广泛实验中表现出了优越性。

Conclusion: 结合MLP和CNN（特别是IConv）能够有效处理时间序列中的非平稳性，并提高预测精度。

Abstract: Real-world time-series data often exhibit non-stationarity, including
changing trends, irregular seasonality, and residuals. In terms of changing
trends, recently proposed multi-layer perceptron (MLP)-based models have shown
excellent performance owing to their computational efficiency and ability to
capture long-term dependency. However, the linear nature of MLP architectures
poses limitations when applied to channels with diverse distributions,
resulting in local variations such as seasonal patterns and residual components
being ignored. However, convolutional neural networks (CNNs) can effectively
incorporate these variations. To resolve the limitations of MLP, we propose
combining them with CNNs. The overall trend is modeled using an MLP to consider
long-term dependencies. The CNN uses diverse kernels to model fine-grained
local patterns in conjunction with MLP trend predictions. To focus on modeling
local variation, we propose IConv, a novel convolutional architecture that
processes the temporal dependency channel independently and considers the
inter-channel relationship through distinct layers. Independent channel
processing enables the modeling of diverse local temporal dependencies and the
adoption of a large kernel size. Distinct inter-channel considerations reduce
computational cost. The proposed model is evaluated through extensive
experiments on time-series datasets. The results reveal the superiority of the
proposed method for multivariate time-series forecasting.

</details>


### [208] [LiLAW: Lightweight Learnable Adaptive Weighting to Meta-Learn Sample Difficulty and Improve Noisy Training](https://arxiv.org/abs/2509.20786)
*Abhishek Moturu,Anna Goldenberg,Babak Taati*

Main category: cs.LG

TL;DR: LiLAW是一种新颖的方法，通过动态调整每个训练样本的损失权重来解决带噪标签和数据异质性的深度学习挑战。它使用少量可学习参数，通过在每个训练小批量后，对验证集进行一次小批量梯度下降来更新权重，从而自适应地优先处理信息量大的样本。实验证明，LiLAW在各种数据集和噪声环境下都能有效提升模型性能，且计算效率高。


<details>
  <summary>Details</summary>
Motivation: 带噪标签和数据异质性是训练深度神经网络的主要挑战。

Method: LiLAW通过动态调整每个训练样本的损失权重来解决上述挑战，其权重基于样本不断变化的难易程度（简单、中等或困难）。该方法仅使用三个可学习参数，通过在每个训练小批量后，在验证集上进行一次小批量梯度下降来更新这些权重，从而自适应地优先处理信息量大的样本，且无需过多的超参数调整或干净的验证集。

Result: 在多个通用和医学成像数据集、不同噪声水平和类型、损失函数以及有无预训练的架构上进行的广泛实验表明，LiLAW能够持续提升性能，即使在高噪声环境下也表现出色。它在不严重依赖数据增强或高级正则化的情况下依然有效，凸显了其实用性。

Conclusion: LiLAW提供了一种计算高效的解决方案，可以在任何神经网络训练设置中提升模型的泛化能力和鲁棒性。

Abstract: Training deep neural networks in the presence of noisy labels and data
heterogeneity is a major challenge. We introduce Lightweight Learnable Adaptive
Weighting (LiLAW), a novel method that dynamically adjusts the loss weight of
each training sample based on its evolving difficulty level, categorized as
easy, moderate, or hard. Using only three learnable parameters, LiLAW
adaptively prioritizes informative samples throughout training by updating
these weights using a single mini-batch gradient descent step on the validation
set after each training mini-batch, without requiring excessive hyperparameter
tuning or a clean validation set. Extensive experiments across multiple general
and medical imaging datasets, noise levels and types, loss functions, and
architectures with and without pretraining demonstrate that LiLAW consistently
enhances performance, even in high-noise environments. It is effective without
heavy reliance on data augmentation or advanced regularization, highlighting
its practicality. It offers a computationally efficient solution to boost model
generalization and robustness in any neural network training setup.

</details>


### [209] [Aligning Inductive Bias for Data-Efficient Generalization in State Space Models](https://arxiv.org/abs/2509.20789)
*Qiyu Chen,Guozhang Chen*

Main category: cs.LG

TL;DR: 数据效率是大型模型面临的挑战，本文提出了任务相关初始化（TDI）方法，通过匹配模型和任务的功率谱来提高数据效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 虽然缩放定律是大型模型成功的关键，但高质量数据的有限性带来了数据效率的挑战。现有的SSM模型具有固定的归纳偏置，当任务结构与之不匹配时，样本效率会降低。

Method: 本文提出了一个原则性框架，首先通过SSM诱导核来形式化线性时不变SSM的归纳偏置，并证明其频谱受模型频率响应的控制。然后，提出了任务相关初始化（TDI）方法，通过功率谱匹配，在预训练前将模型的归纳偏置与任务的频谱特性对齐。

Result: 在各种真实世界基准测试上的实验表明，TDI显著提高了模型的泛化能力和样本效率，尤其是在数据量较少的情况下。

Conclusion: TDI提供了一个理论和实践工具，可以创建更具数据效率的模型，这是实现可持续扩展的关键一步。

Abstract: The remarkable success of large-scale models is fundamentally tied to scaling
laws, yet the finite nature of high-quality data presents a looming challenge.
One of the next frontiers in modeling is data efficiency: the ability to learn
more from less. A model's inductive bias is a critical lever for this, but
foundational sequence models like State Space Models (SSMs) rely on a fixed
bias. This fixed prior is sample-inefficient when a task's underlying structure
does not match. In this work, we introduce a principled framework to solve this
problem. We first formalize the inductive bias of linear time-invariant SSMs
through an SSM-induced kernel, mathematically and empirically proving its
spectrum is directly governed by the model's frequency response. Further, we
propose a method of Task-Dependent Initialization (TDI): power spectrum
matching, a fast and efficient method that aligns the model's inductive bias
with the task's spectral characteristics before large-scale training. Our
experiments on a diverse set of real-world benchmarks show that TDI
significantly improves generalization and sample efficiency, particularly in
low-data regimes. This work provides a theoretical and practical tool to create
more data-efficient models, a crucial step towards sustainable scaling.

</details>


### [210] [FERD: Fairness-Enhanced Data-Free Robustness Distillation](https://arxiv.org/abs/2509.20793)
*Zhengxiao Li,Liming Lu,Xu Zheng,Siyuan Liang,Zhenghan Chen,Yongbin Zhou,Shuchao Pang*

Main category: cs.LG

TL;DR: 本研究提出了一种名为FERD的数据无鲁棒性蒸馏框架，解决了现有方法中存在的鲁棒公平性问题，即在不同类别间鲁棒性存在显著差异的现象。


<details>
  <summary>Details</summary>
Motivation: 现有数据无鲁棒性蒸馏方法忽视了鲁棒公平性问题，导致学生模型在不同类别间的鲁棒性存在巨大差异，并且在不同攻击目标下鲁棒性不稳定。

Method: FERD框架通过调整对抗样本的比例和分布来解决上述问题。比例方面，采用鲁棒性引导的类别重加权策略，为鲁棒性较差的类别合成更多样本。分布方面，通过强制执行特征级别预测的均匀性约束来生成公平感知样本（FAEs），以抑制特定类别非鲁棒性特征的主导地位，并生成统一目标对抗样本（UTAEs），将攻击目标分散到所有类别，避免过拟合到特定脆弱类别。

Result: 在三个公共数据集上的大量实验表明，FERD在所有对抗性攻击下都实现了最先进的最小类别鲁棒性。例如，在使用MobileNet-V2在CIFAR-10数据集上进行实验时，FGSM和AutoAttack下的最小类别鲁棒性分别提高了15.1%和6.4%。

Conclusion: FERD框架在鲁棒性和公平性方面均表现出卓越的性能，有效解决了数据无鲁棒性蒸馏中的公平性问题。

Abstract: Data-Free Robustness Distillation (DFRD) aims to transfer the robustness from
the teacher to the student without accessing the training data. While existing
methods focus on overall robustness, they overlook the robust fairness issues,
leading to severe disparity of robustness across different categories. In this
paper, we find two key problems: (1) student model distilled with equal class
proportion data behaves significantly different across distinct categories; and
(2) the robustness of student model is not stable across different attacks
target. To bridge these gaps, we present the first Fairness-Enhanced data-free
Robustness Distillation (FERD) framework to adjust the proportion and
distribution of adversarial examples. For the proportion, FERD adopts a
robustness-guided class reweighting strategy to synthesize more samples for the
less robust categories, thereby improving robustness of them. For the
distribution, FERD generates complementary data samples for advanced robustness
distillation. It generates Fairness-Aware Examples (FAEs) by enforcing a
uniformity constraint on feature-level predictions, which suppress the
dominance of class-specific non-robust features, providing a more balanced
representation across all categories. Then, FERD constructs Uniform-Target
Adversarial Examples (UTAEs) from FAEs by applying a uniform target class
constraint to avoid biased attack directions, which distribute the attack
targets across all categories and prevents overfitting to specific vulnerable
categories. Extensive experiments on three public datasets show that FERD
achieves state-of-the-art worst-class robustness under all adversarial attack
(e.g., the worst-class robustness under FGSM and AutoAttack are improved by
15.1\% and 6.4\% using MobileNet-V2 on CIFAR-10), demonstrating superior
performance in both robustness and fairness aspects.

</details>


### [211] [T2I-Diff: fMRI Signal Generation via Time-Frequency Image Transform and Classifier-Free Denoising Diffusion Models](https://arxiv.org/abs/2509.20822)
*Hwa Hui Tew,Junn Yong Loo,Yee-Fan Tan,Xinyu Tang,Hernando Ombao,Fuad Noman,Raphael C. -W. Phan,Chee-Ming Ting*

Main category: cs.LG

TL;DR: T2I-Diff是一个先进的fMRI数据生成框架，通过利用时间-频率表示和去噪扩散模型，解决了现有生成模型在处理非平稳和非线性BOLD信号时性能不足的问题，并提高了下游fMRI脑网络分类的准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: fMRI数据获取成本高，导致高质量样本不足，而现有的生成模型未能有效处理BOLD信号的复杂动态特性。

Method: 将BOLD信号通过时间相关的傅里叶变换转换为时频窗口图谱，然后训练一个无分类器的扩散模型来生成条件化的频谱图，最后通过逆傅里叶变换恢复BOLD信号。

Result: 通过下游fMRI脑网络分类任务的准确性和泛化能力提升来验证了T2I-Diff框架的有效性。

Conclusion: T2I-Diff框架通过结合时间-频率表示和扩散模型，能够生成高质量的fMRI数据，从而提升了基于fMRI的脑网络分类性能。

Abstract: Functional Magnetic Resonance Imaging (fMRI) is an advanced neuroimaging
method that enables in-depth analysis of brain activity by measuring dynamic
changes in the blood oxygenation level-dependent (BOLD) signals. However, the
resource-intensive nature of fMRI data acquisition limits the availability of
high-fidelity samples required for data-driven brain analysis models. While
modern generative models can synthesize fMRI data, they often underperform
because they overlook the complex non-stationarity and nonlinear BOLD dynamics.
To address these challenges, we introduce T2I-Diff, an fMRI generation
framework that leverages time-frequency representation of BOLD signals and
classifier-free denoising diffusion. Specifically, our framework first converts
BOLD signals into windowed spectrograms via a time-dependent Fourier transform,
capturing both the underlying temporal dynamics and spectral evolution.
Subsequently, a classifier-free diffusion model is trained to generate
class-conditioned frequency spectrograms, which are then reverted to BOLD
signals via inverse Fourier transforms. Finally, we validate the efficacy of
our approach by demonstrating improved accuracy and generalization in
downstream fMRI-based brain network classification.

</details>


### [212] [CaTS-Bench: Can Language Models Describe Numeric Time Series?](https://arxiv.org/abs/2509.20823)
*Luca Zhou,Pratham Yashwante,Marshall Fisher,Alessio Sampieri,Zihao Zhou,Fabio Galasso,Rose Yu*

Main category: cs.LG

TL;DR: CaTS-Bench是一个新的大规模真实世界时间序列（TS）数据集，用于上下文感知的时间序列描述任务。它包含大约465k训练和105k测试时间戳，每个样本都有数字序列、元数据、图表和描述。该数据集旨在解决现有基准的局限性，并提供了一个用于训练和评估时间序列描述和问答模型的基础。


<details>
  <summary>Details</summary>
Motivation: 现有的时间序列描述基准通常依赖于合成数据或过于简化的描述，并且忽略了元数据和视觉表示。为了解决这个差距，需要一个更大规模、更真实的基准来促进上下文感知的时间序列描述。

Method: CaTS-Bench是利用一个可扩展的流程生成的，该流程结合了LLM（大型语言模型）生成、事实核查、人类可区分性研究和多样性分析来创建参考描述。它还包括一个由人类审查的子集，以确保准确性和人类风格。

Result: CaTS-Bench包含来自11个不同数据集的约465k训练和105k测试时间戳，每个样本包括数字序列、元数据、图表和描述。此外，它还提供460个选择题，用于评估更深层次的时间序列推理能力。通过对领先的VLMs（视觉语言模型）进行基准测试，突出了它们的优势和局限性。

Conclusion: CaTS-Bench及其描述生成流程为时间序列分析和基础模型交叉领域未来的研究提供了一个可靠且可扩展的基础。

Abstract: Time series captioning, the task of describing numeric time series in natural
language, requires numerical reasoning, trend interpretation, and contextual
understanding. Existing benchmarks, however, often rely on synthetic data or
overly simplistic captions, and typically neglect metadata and visual
representations. To close this gap, we introduce CaTS-Bench, the first
large-scale, real-world benchmark for Context-aware Time Series captioning.
CaTS-Bench is derived from 11 diverse datasets reframed as captioning and Q&A
tasks, comprising roughly 465k training and 105k test timestamps. Each sample
includes a numeric series segment, contextual metadata, a line-chart image, and
a caption. A key contribution of this work is the scalable pipeline used to
generate reference captions: while most references are produced by an oracle
LLM and verified through factual checks, human indistinguishability studies,
and diversity analyses, we also provide a human-revisited subset of 579 test
captions, refined from LLM outputs to ensure accuracy and human-like style.
Beyond captioning, CaTS-Bench offers 460 multiple-choice questions targeting
deeper aspects of time series reasoning. We further propose new tailored
evaluation metrics and benchmark leading VLMs, highlighting both their
strengths and persistent limitations. Together, these contributions establish
CaTS-Bench and its captioning pipeline as a reliable and extensible foundation
for future research at the intersection of time series analysis and foundation
models.

</details>


### [213] [Explaining Grokking and Information Bottleneck through Neural Collapse Emergence](https://arxiv.org/abs/2509.20829)
*Keitaro Sakamoto,Issei Sato*

Main category: cs.LG

TL;DR: 本文提出了一种统一的解释，通过神经崩溃的视角来理解深度神经网络训练中的后期现象，如“grokking”和信息瓶颈。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络的训练动态常常出人意料，但它们是现代机器学习的基础。例如“grokking”（训练损失平台期后测试性能突然提高）和信息瓶颈（模型逐渐丢弃与预测任务无关的输入信息）等现象的机制及其关系仍不清楚。

Method: 本文提出了一种统一的解释，通过神经崩溃来理解这些后期现象，并表明群体类内方差的收缩是“grokking”和信息瓶颈的关键因素。通过分析神经崩溃的动态，揭示了训练集拟合和神经崩溃进展之间不同的时间尺度解释了后期现象的行为。

Result: 理论发现已在多个数据集和架构上得到验证。

Conclusion: 神经崩溃的动态分析揭示了训练集拟合和神经崩溃进展之间不同的时间尺度解释了后期现象的行为。

Abstract: The training dynamics of deep neural networks often defy expectations, even
as these models form the foundation of modern machine learning. Two prominent
examples are grokking, where test performance improves abruptly long after the
training loss has plateaued, and the information bottleneck principle, where
models progressively discard input information irrelevant to the prediction
task as training proceeds. However, the mechanisms underlying these phenomena
and their relations remain poorly understood. In this work, we present a
unified explanation of such late-phase phenomena through the lens of neural
collapse, which characterizes the geometry of learned representations. We show
that the contraction of population within-class variance is a key factor
underlying both grokking and information bottleneck, and relate this measure to
the neural collapse measure defined on the training set. By analyzing the
dynamics of neural collapse, we show that distinct time scales between fitting
the training set and the progression of neural collapse account for the
behavior of the late-phase phenomena. Finally, we validate our theoretical
findings on multiple datasets and architectures.

</details>


### [214] [Shaping Initial State Prevents Modality Competition in Multi-modal Fusion: A Two-stage Scheduling Framework via Fast Partial Information Decomposition](https://arxiv.org/abs/2509.20840)
*Jiaqi Tang,Yinsong Xu,Yang Liu,Qingchao Chen*

Main category: cs.LG

TL;DR: 通过对预融合模型的初始状态进行塑形，有效缓解模态间的竞争，从而实现协同的多模态融合。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态融合方法在联合训练中常常面临模态竞争问题，导致部分模态学习不足。现有方法主要在联合学习阶段解决此问题，而忽略了模型初始状态的关键影响。

Method: 提出一个两阶段训练框架：首先通过单模态训练来塑造初始状态，然后进行联合训练。引入有效竞争强度（ECS）量化模态竞争力，并通过理论分析证明塑造初始ECS可以获得更紧密的误差界限。为了解决ECS在深度神经网络中计算量大的问题，提出一个包含精细化可计算诊断指标和异步训练控制器。其中，诊断指标证明互信息（MI）是ECS的代理，并提出FastPID高效可微分求解器来分解联合分布信息，得到模态特异性、冗余性和协同性。异步控制器利用这些度量动态平衡模态，并通过跟踪峰值协同性来定位理想的初始状态。

Result: 在多个基准测试中取得了最先进的性能。

Conclusion: 预融合模型的初始状态塑形是一种有效的策略，可以在竞争发生之前就缓解它，从而可靠地实现协同的多模态融合。

Abstract: Multi-modal fusion often suffers from modality competition during joint
training, where one modality dominates the learning process, leaving others
under-optimized. Overlooking the critical impact of the model's initial state,
most existing methods address this issue during the joint learning stage. In
this study, we introduce a two-stage training framework to shape the initial
states through unimodal training before the joint training. First, we propose
the concept of Effective Competitive Strength (ECS) to quantify a modality's
competitive strength. Our theoretical analysis further reveals that properly
shaping the initial ECS by unimodal training achieves a provably tighter error
bound. However, ECS is computationally intractable in deep neural networks. To
bridge this gap, we develop a framework comprising two core components: a
fine-grained computable diagnostic metric and an asynchronous training
controller. For the metric, we first prove that mutual information(MI) is a
principled proxy for ECS. Considering MI is induced by per-modality marginals
and thus treats each modality in isolation, we further propose FastPID, a
computationally efficient and differentiable solver for partial information
decomposition, which decomposes the joint distribution's information into
fine-grained measurements: modality-specific uniqueness, redundancy, and
synergy. Guided by these measurements, our asynchronous controller dynamically
balances modalities by monitoring uniqueness and locates the ideal initial
state to start joint training by tracking peak synergy. Experiments on diverse
benchmarks demonstrate that our method achieves state-of-the-art performance.
Our work establishes that shaping the pre-fusion models' initial state is a
powerful strategy that eases competition before it starts, reliably unlocking
synergistic multi-modal fusion.

</details>


### [215] [Robust Multi-Omics Integration from Incomplete Modalities Significantly Improves Prediction of Alzheimer's Disease](https://arxiv.org/abs/2509.20842)
*Sungjoon Park,Kyungwook Lee,Soorin Yim,Doyeong Hwang,Dongyun Kim,Soonyoung Lee,Amy Dunn,Daniel Gatti,Elissa Chesler,Kristen O'Connell,Kiyoung Kim*

Main category: cs.LG

TL;DR: MOIRA是一种新的多组学数据整合方法，可以处理缺失的模态，并在阿尔茨海默病研究中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的多组学数据整合方法难以处理缺失的模态，这阻碍了对代谢和疾病的全面理解。

Method: MOIRA通过表示对齐和自适应聚合，将每个组学数据集投影到共享的嵌入空间，并使用可学习的加权机制来融合它们，从而实现对不完整组学数据的稳健学习。

Result: 在ROSMAP数据集上，MOIRA在阿尔茨海默病研究中的表现优于现有方法。消融研究证实了各模态的贡献，特征重要性分析也揭示了与先前文献一致的AD相关生物标志物。

Conclusion: MOIRA能够有效地整合不完整的多组学数据，为阿尔茨海默病研究提供了有价值的见解，并突出了其生物学相关性。

Abstract: Multi-omics data capture complex biomolecular interactions and provide
insights into metabolism and disease. However, missing modalities hinder
integrative analysis across heterogeneous omics. To address this, we present
MOIRA (Multi-Omics Integration with Robustness to Absent modalities), an early
integration method enabling robust learning from incomplete omics data via
representation alignment and adaptive aggregation. MOIRA leverages all samples,
including those with missing modalities, by projecting each omics dataset onto
a shared embedding space where a learnable weighting mechanism fuses them.
Evaluated on the Religious Order Study and Memory and Aging Project (ROSMAP)
dataset for Alzheimer's Disease (AD), MOIRA outperformed existing approaches,
and further ablation studies confirmed modality-wise contributions. Feature
importance analysis revealed AD-related biomarkers consistent with prior
literature, highlighting the biological relevance of our approach.

</details>


### [216] [Causal Time Series Generation via Diffusion Models](https://arxiv.org/abs/2509.20846)
*Yutong Xia,Chang Xu,Yuxuan Liang,Qingsong Wen,Roger Zimmermann,Jiang Bian*

Main category: cs.LG

TL;DR: 本文提出了一种名为CaTSG的统一扩散模型框架，用于解决条件时间序列生成（TSG）中的未观测混淆问题，并引入了因果时间序列生成（causal TSG）的概念，将其置于因果关系的三个层级中，能够生成观测、干预和反事实序列。


<details>
  <summary>Details</summary>
Motivation: 现有的条件时间序列生成模型仅考虑观测相关性，忽略了未观测混淆，导致生成结果不可靠，尤其是在干预和反事实场景下。

Method: 提出因果时间序列生成（causal TSG）任务，并开发了CaTSG框架。该框架基于扩散模型，并引入了“后门调整引导”（backdoor-adjusted guidance），通过“溯因-行动-预测”（abduction-action-prediction）程序推导出因果评分函数，从而实现对观测、干预和反事实序列的生成。

Result: 在合成和真实世界数据集上的实验表明，CaTSG在生成保真度上优于现有基线模型，并且能够支持现有方法无法实现的干预和反事实生成。

Conclusion: 本文提出了因果TSG这一新任务家族，并用CaTSG框架进行了实例化，为在干预下进行更可靠的模拟和生成反事实序列提供了一个初步的概念验证，并指明了一个有前景的研究方向。

Abstract: Time series generation (TSG) synthesizes realistic sequences and has achieved
remarkable success. Among TSG, conditional models generate sequences given
observed covariates, however, such models learn observational correlations
without considering unobserved confounding. In this work, we propose a causal
perspective on conditional TSG and introduce causal time series generation as a
new TSG task family, formalized within Pearl's causal ladder, extending beyond
observational generation to include interventional and counterfactual settings.
To instantiate these tasks, we develop CaTSG, a unified diffusion-based
framework with backdoor-adjusted guidance that causally steers sampling toward
desired interventions and individual counterfactuals while preserving
observational fidelity. Specifically, our method derives causal score functions
via backdoor adjustment and the abduction-action-prediction procedure, thus
enabling principled support for all three levels of TSG. Extensive experiments
on both synthetic and real-world datasets show that CaTSG achieves superior
fidelity and also supporting interventional and counterfactual generation that
existing baselines cannot handle. Overall, we propose the causal TSG family and
instantiate it with CaTSG, providing an initial proof-of-concept and opening a
promising direction toward more reliable simulation under interventions and
counterfactual generation.

</details>


### [217] [FHRFormer: A Self-supervised Transformer Approach for Fetal Heart Rate Inpainting and Forecasting](https://arxiv.org/abs/2509.20852)
*Kjersti Engan,Neel Kanwal,Anita Yeconia,Ladislaus Blacy,Yuda Munyaw,Estomih Mduma,Hege Ersdal*

Main category: cs.LG

TL;DR: 该研究提出了一种基于掩码 Transformer 的自编码器方法来重建胎儿心率 (FHR) 信号中的缺失数据，该方法能有效捕捉数据的空间和频率特征，为胎儿风险预测算法的开发和可穿戴设备的应用提供了支持。


<details>
  <summary>Details</summary>
Motivation: 胎儿心率 (FHR) 监测对评估胎儿健康至关重要，但实际监测中常因传感器位移等原因出现数据缺失，影响了基于人工智能 (AI) 的风险预测分析。

Method: 提出了一种基于掩码 Transformer 的自编码器方法，用于重建缺失的 FHR 信号，该方法能同时捕捉数据的空间和频率成分。

Result: 该方法在处理不同时段的缺失数据时表现出鲁棒性，能够用于信号修复和预测，可应用于回顾性研究数据集以支持 AI 风险算法的开发，并有望集成到可穿戴设备中以实现早期、更可靠的风险检测。

Conclusion: 所提出的掩码 Transformer 自编码器方法能够有效重建缺失的 FHR 信号，为开发更准确的胎儿风险评估工具和技术提供了新的途径。

Abstract: Approximately 10\% of newborns require assistance to initiate breathing at
birth, and around 5\% need ventilation support. Fetal heart rate (FHR)
monitoring plays a crucial role in assessing fetal well-being during prenatal
care, enabling the detection of abnormal patterns and supporting timely
obstetric interventions to mitigate fetal risks during labor. Applying
artificial intelligence (AI) methods to analyze large datasets of continuous
FHR monitoring episodes with diverse outcomes may offer novel insights into
predicting the risk of needing breathing assistance or interventions. Recent
advances in wearable FHR monitors have enabled continuous fetal monitoring
without compromising maternal mobility. However, sensor displacement during
maternal movement, as well as changes in fetal or maternal position, often lead
to signal dropouts, resulting in gaps in the recorded FHR data. Such missing
data limits the extraction of meaningful insights and complicates automated
(AI-based) analysis. Traditional approaches to handle missing data, such as
simple interpolation techniques, often fail to preserve the spectral
characteristics of the signals. In this paper, we propose a masked
transformer-based autoencoder approach to reconstruct missing FHR signals by
capturing both spatial and frequency components of the data. The proposed
method demonstrates robustness across varying durations of missing data and can
be used for signal inpainting and forecasting. The proposed approach can be
applied retrospectively to research datasets to support the development of
AI-based risk algorithms. In the future, the proposed method could be
integrated into wearable FHR monitoring devices to achieve earlier and more
robust risk detection.

</details>


### [218] [Federated Markov Imputation: Privacy-Preserving Temporal Imputation in Multi-Centric ICU Environments](https://arxiv.org/abs/2509.20867)
*Christoph Düsing,Philipp Cimiano*

Main category: cs.LG

TL;DR: 使用联合马尔可夫链进行多粒度时间序列数据联合插补。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录中的联合学习在处理不同时间粒度的缺失时间序列数据时面临挑战。本研究旨在通过联合学习方法解决此问题。

Method: 提出了一种名为联合马尔可夫链插补（FMI）的隐私保护方法，使ICU能够协作构建全局转换模型，以进行时间序列数据插补。

Result: 在真实世界的脓毒症发病预测任务中，使用MIMIC-IV数据集评估了FMI。结果表明，FMI在跨ICU采样间隔不规则的情况下，优于局部插补方法。

Conclusion: FMI是一种有效的联合学习方法，可用于处理电子健康记录中的缺失时间序列数据，尤其是在不同时间粒度的情况下。

Abstract: Missing data is a persistent challenge in federated learning on electronic
health records, particularly when institutions collect time-series data at
varying temporal granularities. To address this, we propose Federated Markov
Imputation (FMI), a privacy-preserving method that enables Intensive Care Units
(ICUs) to collaboratively build global transition models for temporal
imputation. We evaluate FMI on a real-world sepsis onset prediction task using
the MIMIC-IV dataset and show that it outperforms local imputation baselines,
especially in scenarios with irregular sampling intervals across ICUs.

</details>


### [219] [StyleBench: Evaluating thinking styles in Large Language Models](https://arxiv.org/abs/2509.20868)
*Junyu Guo,Shangding Gu,Ming Jin,Costas Spanos,Javad Lavaei*

Main category: cs.LG

TL;DR: StyleBench是一个评估LLM推理风格的基准，发现没有一种风格是万能的，选择取决于模型大小和任务类型。


<details>
  <summary>Details</summary>
Motivation: LLM的推理能力受提示中推理策略的影响，但推理策略、模型架构和任务类型之间的相互作用尚不清楚。

Method: 引入StyleBench基准，评估了五种推理风格（CoT、ToT、AoT、SoT、CoD）在五种推理任务上的表现，使用了15个不同规模的开源模型。

Result: 没有一种推理风格在所有情况下都表现最佳。搜索类方法（AoT、ToT）在开放式问题上需要大模型，而简洁风格（SoT、CoD）在定义明确的任务上效率更高。小模型倾向于猜测，鲁棒性随模型规模增大而提高。

Conclusion: 推理风格的选择应根据模型大小和任务类型进行权衡。StyleBench为选择最佳推理策略提供了指导。

Abstract: The effectiveness of Large Language Models (LLMs) is heavily influenced by
the reasoning strategies, or styles of thought, employed in their prompts.
However, the interplay between these reasoning styles, model architecture, and
task type remains poorly understood. To address this, we introduce StyleBench,
a comprehensive benchmark for systematically evaluating reasoning styles across
diverse tasks and models. We assess five representative reasoning styles,
including Chain of Thought (CoT), Tree of Thought (ToT), Algorithm of Thought
(AoT), Sketch of Thought (SoT), and Chain-of-Draft (CoD) on five reasoning
tasks, using 15 open-source models from major families (LLaMA, Qwen, Mistral,
Gemma, GPT-OSS, Phi, and DeepSeek) ranging from 270M to 120B parameters. Our
large-scale analysis reveals that no single style is universally optimal. We
demonstrate that strategy efficacy is highly contingent on both model scale and
task type: search-based methods (AoT, ToT) excel in open-ended problems but
require large-scale models, while concise styles (SoT, CoD) achieve radical
efficiency gains on well-defined tasks. Furthermore, we identify key behavioral
patterns: smaller models frequently fail to follow output instructions and
default to guessing, while reasoning robustness emerges as a function of scale.
Our findings offer a crucial roadmap for selecting optimal reasoning strategies
based on specific constraints, we open source the benchmark in
https://github.com/JamesJunyuGuo/Style_Bench.

</details>


### [220] [Model-Based Reinforcement Learning under Random Observation Delays](https://arxiv.org/abs/2509.20869)
*Armin Karamzade,Kyungmin Kim,JB Lanier,Davide Corsi,Roy Fox*

Main category: cs.LG

TL;DR: 即时感知假设在现实世界的强化学习（RL）中通常不成立，因为传感器延迟很常见。该研究提出了一种模型驱动的滤波方法，用于处理POMDP中的随机传感器延迟，并通过将该方法整合到基于模型的RL框架中，使其能够有效应对延迟。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的传感器延迟问题，以及标准强化学习算法在处理延迟方面的不足。

Method: 提出一种模型驱动的滤波过程，用于更新信念状态；将该过程整合到基于模型的强化学习框架中，以应对延迟。

Result: 所提出的方法在处理随机传感器延迟方面优于基于MDP的延迟感知基线，并且在模拟机器人任务中显示出对延迟分布变化的鲁棒性，优于常用实用方法。

Conclusion: 显式地对观测延迟进行建模对于提高强化学习代理在存在延迟情况下的性能至关重要。

Abstract: Delays frequently occur in real-world environments, yet standard
reinforcement learning (RL) algorithms often assume instantaneous perception of
the environment. We study random sensor delays in POMDPs, where observations
may arrive out-of-sequence, a setting that has not been previously addressed in
RL. We analyze the structure of such delays and demonstrate that naive
approaches, such as stacking past observations, are insufficient for reliable
performance. To address this, we propose a model-based filtering process that
sequentially updates the belief state based on an incoming stream of
observations. We then introduce a simple delay-aware framework that
incorporates this idea into model-based RL, enabling agents to effectively
handle random delays. Applying this framework to Dreamer, we compare our
approach to delay-aware baselines developed for MDPs. Our method consistently
outperforms these baselines and demonstrates robustness to delay distribution
shifts during deployment. Additionally, we present experiments on simulated
robotic tasks, comparing our method to common practical heuristics and
emphasizing the importance of explicitly modeling observation delays.

</details>


### [221] [Distribution-Controlled Client Selection to Improve Federated Learning Strategies](https://arxiv.org/abs/2509.20877)
*Christoph Düsing,Philipp Cimiano*

Main category: cs.LG

TL;DR: 通过选择与目标分布（平衡分布或联邦联合标签分布）最匹配的活跃客户端来解决联邦学习中的数据不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 联邦学习（FL）中的数据不平衡会降低共享模型的性能，需要通过客户端选择方法来缓解。

Method: 提出一种扩展的FL策略，选择与平衡分布或联邦联合标签分布最匹配的客户端。

Result: 通过在三种常见FL策略和两个数据集上进行实证验证，发现在本地不平衡情况下，与平衡分布对齐可带来最大改进；在全局不平衡情况下，与联邦联合标签分布对齐更优。

Conclusion: 提出的分布控制客户端选择方法可以有效缓解联邦学习中的数据不平衡问题，具体策略取决于不平衡是本地的还是全局的。

Abstract: Federated learning (FL) is a distributed learning paradigm that allows
multiple clients to jointly train a shared model while maintaining data
privacy. Despite its great potential for domains with strict data privacy
requirements, the presence of data imbalance among clients is a thread to the
success of FL, as it causes the performance of the shared model to decrease. To
address this, various studies have proposed enhancements to existing FL
strategies, particularly through client selection methods that mitigate the
detrimental effects of data imbalance. In this paper, we propose an extension
to existing FL strategies, which selects active clients that best align the
current label distribution with one of two target distributions, namely a
balanced distribution or the federations combined label distribution.
Subsequently, we empirically verify the improvements through our
distribution-controlled client selection on three common FL strategies and two
datasets. Our results show that while aligning the label distribution with a
balanced distribution yields the greatest improvements facing local imbalance,
alignment with the federation's combined label distribution is superior for
global imbalance.

</details>


### [222] [Improving Early Sepsis Onset Prediction Through Federated Learning](https://arxiv.org/abs/2509.20885)
*Christoph Düsing,Philipp Cimiano*

Main category: cs.LG

TL;DR: 该研究提出了一种基于联邦学习和注意力机制的LSTM模型，用于在不共享数据的情况下，利用多中心ICU数据进行脓毒症早期预测，并支持可变预测时间窗口，在保证性能的同时降低了计算和通信开销。


<details>
  <summary>Details</summary>
Motivation: 早期准确预测脓毒症发病仍然是重症监护中的一个重大挑战，而机器学习模型在这一领域虽然有潜力，但受限于各医院可用数据的数量和多样性。联邦学习（FL）通过允许多个机构在不共享数据的情况下协作训练模型来解决这个问题，从而保护患者隐私。

Method: 提出了一种联邦的、注意力增强的长短期记忆（LSTM）模型，该模型在多中心ICU数据上进行训练。与依赖固定预测窗口的现有方法不同，该模型支持可变的预测时间范围，能够在单个统一的模型中同时进行短期和长期预测。

Result: 实验结果证明，使用FL不仅可以提高整体预测性能（接近集中式模型的性能），而且对于脓毒症的早期发病预测特别有利。采用可变预测窗口而非固定窗口在性能上没有显著损失，反而减少了计算、通信和组织开销。

Conclusion: 联邦学习在脓毒症预测中是可行的，并且通过使用注意力机制和可变预测窗口，可以实现有效的早期预警，同时保持数据隐私和效率。

Abstract: Early and accurate prediction of sepsis onset remains a major challenge in
intensive care, where timely detection and subsequent intervention can
significantly improve patient outcomes. While machine learning models have
shown promise in this domain, their success is often limited by the amount and
diversity of training data available to individual hospitals and Intensive Care
Units (ICUs). Federated Learning (FL) addresses this issue by enabling
collaborative model training across institutions without requiring data
sharing, thus preserving patient privacy. In this work, we propose a federated,
attention-enhanced Long Short-Term Memory model for sepsis onset prediction,
trained on multi-centric ICU data. Unlike existing approaches that rely on
fixed prediction windows, our model supports variable prediction horizons,
enabling both short- and long-term forecasting in a single unified model.
During analysis, we put particular emphasis on the improvements through our
approach in terms of early sepsis detection, i.e., predictions with large
prediction windows by conducting an in-depth temporal analysis. Our results
prove that using FL does not merely improve overall prediction performance
(with performance approaching that of a centralized model), but is particularly
beneficial for early sepsis onset prediction. Finally, we show that our choice
of employing a variable prediction window rather than a fixed window does not
hurt performance significantly but reduces computational, communicational, and
organizational overhead.

</details>


### [223] [Deterministic Discrete Denoising](https://arxiv.org/abs/2509.20896)
*Hideyuki Suzuki,Hiroshi Yamashita*

Main category: cs.LG

TL;DR: 我们提出了一种基于马尔可夫链的离散状态扩散模型的确定性去噪算法，通过引入具有弱混沌动力学的 the herding 算法变体来消除生成反向过程的随机性，从而诱导离散状态的确定性转移。该方法可直接替代随机去噪过程，无需重新训练或连续状态嵌入，并在文本和图像生成任务中一致地提高了效率和样本质量。


<details>
  <summary>Details</summary>
Motivation: 旨在为离散状态扩散模型提出一种确定性的去噪算法，以替代随机去噪过程，并提高效率和样本质量。

Method: 引入一种基于 the herding 算法变体（具有弱混沌动力学）的方法，来实现离散状态转移的确定性，从而消除生成反向过程的随机性。

Result: 在文本和图像生成任务中，该确定性去噪方法在效率和样本质量方面均得到了一致性提升。

Conclusion: 这种简单的去随机化方法有望增强离散扩散在生成模型中的重要性，并且证实了确定性反向过程在离散状态空间中的有效性。

Abstract: We propose a deterministic denoising algorithm for discrete-state diffusion
models based on Markov chains. The generative reverse process is derandomized
by introducing a variant of the herding algorithm with weakly chaotic dynamics,
which induces deterministic discrete state transitions. Our approach is a
direct replacement for the stochastic denoising process, requiring neither
retraining nor continuous state embeddings. We demonstrate consistent
improvements in both efficiency and sample quality on text and image generation
tasks. Thus, this simple derandomization approach is expected to enhance the
significance of discrete diffusion in generative modeling. Furthermore, our
results reveal that deterministic reverse processes, well established in
continuous diffusion, can also be effective in discrete state spaces.

</details>


### [224] [Deep Learning for Crime Forecasting: The Role of Mobility at Fine-grained Spatiotemporal Scales](https://arxiv.org/abs/2509.20913)
*Ariadna Albors Zumel,Michele Tizzoni,Gian Maria Campedelli*

Main category: cs.LG

TL;DR: 通过结合历史犯罪、社会人口统计数据和微观层面的流动性特征，利用深度学习框架提高了犯罪预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 评估结合微观层面的流动性特征与历史犯罪和社会人口统计数据，在精细的空间和时间分辨率下，能否以及如何提高犯罪预测的准确性。

Method: 使用卷积长短期记忆（ConvLSTM）网络，结合四个美国城市的犯罪事件数据、社会人口统计数据和人类流动性数据，训练模型以预测12小时后的犯罪发生情况，并与逻辑回归、随机森林和标准LSTM模型进行比较。

Result: 结合流动性特征可以提高预测性能，尤其是在使用较短的输入序列时。然而，当同时使用流动性和社会人口统计学特征时，预测效果最佳。深度学习模型在所有四个城市中均取得了最高的召回率、精确率和F1分数，优于其他方法。较长的输入序列有助于预测暴力犯罪，而较短的序列对财产犯罪更有效。

Conclusion: 这些发现强调了整合包括流动性在内的多种数据源对于时空犯罪预测的重要性，并突显了深度学习在处理精细空间和时间尺度方面的优势（及局限性）。

Abstract: Objectives: To develop a deep learning framework to evaluate if and how
incorporating micro-level mobility features, alongside historical crime and
sociodemographic data, enhances predictive performance in crime forecasting at
fine-grained spatial and temporal resolutions.
  Methods: We advance the literature on computational methods and crime
forecasting by focusing on four U.S. cities (i.e., Baltimore, Chicago, Los
Angeles, and Philadelphia). We employ crime incident data obtained from each
city's police department, combined with sociodemographic data from the American
Community Survey and human mobility data from Advan, collected from 2019 to
2023. This data is aggregated into grids with equally sized cells of 0.077 sq.
miles (0.2 sq. kms) and used to train our deep learning forecasting model, a
Convolutional Long Short-Term Memory (ConvLSTM) network, which predicts crime
occurrences 12 hours ahead using 14-day and 2-day input sequences. We also
compare its performance against three baseline models: logistic regression,
random forest, and standard LSTM.
  Results: Incorporating mobility features improves predictive performance,
especially when using shorter input sequences. Noteworthy, however, the best
results are obtained when both mobility and sociodemographic features are used
together, with our deep learning model achieving the highest recall, precision,
and F1 score in all four cities, outperforming alternative methods. With this
configuration, longer input sequences enhance predictions for violent crimes,
while shorter sequences are more effective for property crimes.
  Conclusion: These findings underscore the importance of integrating diverse
data sources for spatiotemporal crime forecasting, mobility included. They also
highlight the advantages (and limits) of deep learning when dealing with
fine-grained spatial and temporal scales.

</details>


### [225] [Energy saving in off-road vehicles using leakage compensation technique](https://arxiv.org/abs/2509.20926)
*Gyan Wrat,J. Das*

Main category: cs.LG

TL;DR: PFCV结合人工泄漏和PID-模糊控制器可提高液压线性致动器的能源效率。


<details>
  <summary>Details</summary>
Motivation: 本文旨在提高重型土方工程设备（特别是挖掘设备）中线性致动器的能源效率。

Method: 通过比较两种液压回路：一种使用传统的比例换向阀（PDCV），另一种使用结合了比例流量控制阀（PFCV）和致动器两端之间人工泄漏的创新解决方案。PFCV通过绕过泵在位置控制期间的多余流量来减少热量形式的能量损失，而PDCV则使用溢流阀。使用PID控制器进行位置控制，并由模糊控制器进行调优。使用MATLAB/Simulink进行仿真，并与实验进行比较。

Result: 与使用PDCV的传统回路相比，使用PFCV的液压回路的能源效率提高了8.5%。

Conclusion: 所提出的方法可以通过减少环境影响和运营成本来显著提高重型土方工程设备中线性致动器的能源效率。

Abstract: The article focuses on enhancing the energy efficiency of linear actuators
used in heavy earth moving equipment, particularly in the booms ofexcavation
equipment. Two hydraulic circuits are compared in terms of energy efficiency,
with one using a conventional proportional directionalcontrol valve (PDCV) and
the other using an innovative solution of proportional flow control valve
(PFCV) with artificial leakage between thetwo ends of the actuator. The PFCV
reduces energy loss in the form of heat by bypassing the extra flow from the
pump during position control,unlike the PDCV that uses a pressure relief valve.
The hydraulic circuit using PFCV is found to be 8.5% more energy efficient than
theconventional circuit using PDCV. The article also discusses the position
control of the actuator, which is achieved using a PID controller tuned by a
fuzzy controller. Thesimulation of the hydraulic circuit is carried out using
MATLAB/Simulink, and the results are compared with experiments. Overall, the
proposedapproach could lead to significant improvements in the energy
efficiency of linear actuators used in heavy earth moving equipment,
therebyreducing their environmental impact and operating costs.

</details>


### [226] [GenFacts-Generative Counterfactual Explanations for Multi-Variate Time Series](https://arxiv.org/abs/2509.20936)
*Sarah Seifi,Anass Ibrahimi,Tobias Sukianto,Cecilia Carbonelli,Lorenzo Servadei,Robert Wille*

Main category: cs.LG

TL;DR: GenFacts是一个生成模型框架，用于为多元时间序列生成有效、合理且直观的反事实解释，在雷达手势和手写字母轨迹数据集上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有针对多元时间序列的反事实解释方法常生成无效、不合理或不直观的反事实，旨在提高模型透明度。

Method: GenFacts是一个基于类别判别变分自编码器的生成框架，集成了对比和分类一致性目标、原型初始化和基于现实约束的优化。

Result: 在雷达手势和手写字母轨迹数据集上，GenFacts在合理性方面比现有方法提高了18.7%，并在人类研究中获得了最高的可解释性分数。

Conclusion: 与仅考虑稀疏性不同，合理性和以用户为中心的可解释性是时间序列数据可操作反事实的关键。

Abstract: Counterfactual explanations aim to enhance model transparency by showing how
inputs can be minimally altered to change predictions. For multivariate time
series, existing methods often generate counterfactuals that are invalid,
implausible, or unintuitive. We introduce GenFacts, a generative framework
based on a class-discriminative variational autoencoder. It integrates
contrastive and classification-consistency objectives, prototype-based
initialization, and realism-constrained optimization. We evaluate GenFacts on
radar gesture data as an industrial use case and handwritten letter
trajectories as an intuitive benchmark. Across both datasets, GenFacts
outperforms state-of-the-art baselines in plausibility (+18.7%) and achieves
the highest interpretability scores in a human study. These results highlight
that plausibility and user-centered interpretability, rather than sparsity
alone, are key to actionable counterfactuals in time series data.

</details>


### [227] [Why Attention Fails: The Degeneration of Transformers into MLPs in Time Series Forecasting](https://arxiv.org/abs/2509.20942)
*Zida Liang,Jiayi Zhu,Weiqiang Sun*

Main category: cs.LG

TL;DR: Transformer 在时间序列预测方面表现不佳，原因在于其注意力机制未能按预期工作，并且当前的嵌入方法未能使 Transformer 在结构良好的潜在空间中发挥作用。


<details>
  <summary>Details</summary>
Motivation: 大多数关于 Transformer 在时间序列预测方面表现不佳的研究未能彻底探讨其失败的原因。为了更好地理解时间序列 Transformer（TST），有必要深入研究其潜在问题。

Method: 通过设计一系列实验，逐步将 Transformer 转化为 MLP，以研究注意力机制的影响。此外，还设计了一个可解释的数据集来探究注意力机制失效的原因，并进行了理论分析，以揭示现有嵌入方法在结构化潜在空间方面的不足。

Result: Transformer 块在现有的时间序列 Transformer 中常常退化为简单的 MLP。注意力机制未能按预期工作。当前的嵌入方法未能使 Transformer 在结构良好的潜在空间中发挥作用，这揭示了更深层次的潜在原因。

Conclusion: Transformer 在时间序列预测方面的失败归因于其注意力机制的功能失常以及现有嵌入方法未能提供结构良好的潜在空间。

Abstract: Transformer-based architectures achieved high performance in natural language
processing and computer vision, yet many studies have shown that they have not
demonstrated a clear advantage in time series forecasting and even underperform
simple linear baselines in some cases. However, most of these studies have not
thoroughly explored the reasons behind the failure of transformers. To better
understand time-series transformers(TST), we designed a series of experiments,
progressively modifying transformers into MLPs to investigate the impact of the
attention mechanism. Surprisingly, transformer blocks often degenerate into
simple MLPs in existing time-series transformers. We designed a interpretable
dataset to investigate the reasons behind the failure of the attention
mechanism and revealed that the attention mechanism is not working in the
expected way. We theoretically analyzed the reasons behind this phenomenon,
demonstrating that the current embedding methods fail to allow transformers to
function in a well-structured latent space, and further analyzed the deeper
underlying causes of the failure of embedding.

</details>


### [228] [Decoupled-Value Attention for Prior-Data Fitted Networks: GP Inference for Physical Equations](https://arxiv.org/abs/2509.20950)
*Kaustubh Sharma,Simardeep Singh,Parikshit Pareek*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Prior-data fitted networks (PFNs) are a promising alternative to
time-consuming Gaussian Process (GP) inference for creating fast surrogates of
physical systems. PFN reduces the computational burden of GP-training by
replacing Bayesian inference in GP with a single forward pass of a learned
prediction model. However, with standard Transformer attention, PFNs show
limited effectiveness on high-dimensional regression tasks. We introduce
Decoupled-Value Attention (DVA)-- motivated by the GP property that the
function space is fully characterized by the kernel over inputs and the
predictive mean is a weighted sum of training targets. DVA computes
similarities from inputs only and propagates labels solely through values.
Thus, the proposed DVA mirrors the Gaussian-process update while remaining
kernel-free. We demonstrate that the crucial factor for scaling PFNs is the
attention rule rather than the architecture itself. Specifically, our results
demonstrate that (a) localized attention consistently reduces out-of-sample
validation loss in PFNs across different dimensional settings, with validation
loss reduced by more than 50% in five- and ten-dimensional cases, and (b) the
role of attention is more decisive than the choice of backbone architecture,
showing that CNN-based PFNs can perform at par with their Transformer-based
counterparts. The proposed PFNs provide 64-dimensional power flow equation
approximations with a mean absolute error of the order of 1E-3, while being
over 80x faster than exact GP inference.

</details>


### [229] [Flow Matching in the Low-Noise Regime: Pathologies and a Contrastive Remedy](https://arxiv.org/abs/2509.20952)
*Weili Zeng,Yichao Yan*

Main category: cs.LG

TL;DR: Flow matching 存在低噪声下的不稳定性问题，称为“低噪声病理”。为解决此问题，提出了一种名为 LCF 的混合训练方案，通过在低噪声水平下进行对比特征对齐来替代直接速度回归，从而提高收敛速度并稳定表示质量。


<details>
  <summary>Details</summary>
Motivation: Flow matching 作为一种生成模型框架，虽然强大，但在低噪声情况下存在根本性的不稳定性问题，导致优化缓慢和表示能力下降。

Method: 提出了一种名为 LCF (Local Contrastive Flow) 的混合训练方案。该方案在低噪声水平下使用对比特征对齐来替代直接速度回归，而在中高噪声水平下则保留标准的 flow matching。

Result: LCF 方案在经验上提高了收敛速度，并稳定了表示质量。实验证明了该方法在生成和表示学习方面都具有潜力。

Conclusion: 低噪声病理是 flow matching 框架的一个关键问题，解决该问题对于充分发挥 flow matching 在生成和表示学习方面的潜力至关重要。LCF 方案提供了一种有效的解决方案。

Abstract: Flow matching has recently emerged as a powerful alternative to diffusion
models, providing a continuous-time formulation for generative modeling and
representation learning. Yet, we show that this framework suffers from a
fundamental instability in the low-noise regime. As noise levels approach zero,
arbitrarily small perturbations in the input can induce large variations in the
velocity target, causing the condition number of the learning problem to
diverge. This ill-conditioning not only slows optimization but also forces the
encoder to reallocate its limited Jacobian capacity toward noise directions,
thereby degrading semantic representations. We provide the first theoretical
analysis of this phenomenon, which we term the low-noise pathology,
establishing its intrinsic link to the structure of the flow matching
objective. Building on these insights, we propose Local Contrastive Flow (LCF),
a hybrid training protocol that replaces direct velocity regression with
contrastive feature alignment at small noise levels, while retaining standard
flow matching at moderate and high noise. Empirically, LCF not only improves
convergence speed but also stabilizes representation quality. Our findings
highlight the critical importance of addressing low-noise pathologies to unlock
the full potential of flow matching for both generation and representation
learning.

</details>


### [230] [Alignment Unlocks Complementarity: A Framework for Multiview Circuit Representation Learning](https://arxiv.org/abs/2509.20968)
*Zhengyuan Shi,Jingxin Wang,Wentao Jiang,Chengyu Ma,Ziyang Zheng,Zhufei Chu,Weikang Qian,Qiang Xu*

Main category: cs.LG

TL;DR: MixGate通过引入功能对齐来解决多视图布尔电路学习中的视图异构性问题，从而有效利用掩码建模技术。


<details>
  <summary>Details</summary>
Motivation: 多视图布尔电路学习在融合不同图表示（如AIG和XMG）时面临结构异构性的挑战，这阻碍了自监督学习（如掩码建模）的有效应用，因为跨视图的上下文被视为噪声。

Method: MixGate框架首先通过等价对齐损失（Equivalence Alignment Loss）教会模型一个共享的、与功能相关的表示空间，然后引入一个多视图掩码建模目标，利用对齐后的视图作为互补信号。

Result: 实验表明，MixGate中的“先对齐”策略显著提高了掩码建模的性能，将其从无效技术转变为强大的性能驱动因素，并通过关键的消融研究得到了证实。

Conclusion: 功能对齐是实现多视图自监督学习的关键前提，MixGate框架通过“先对齐”策略有效解决了多视图布尔电路学习中的视图异构性挑战，从而提升了掩码建模的效果。

Abstract: Multiview learning on Boolean circuits holds immense promise, as different
graph-based representations offer complementary structural and semantic
information. However, the vast structural heterogeneity between views, such as
an And-Inverter Graph (AIG) versus an XOR-Majority Graph (XMG), poses a
critical barrier to effective fusion, especially for self-supervised techniques
like masked modeling. Naively applying such methods fails, as the cross-view
context is perceived as noise. Our key insight is that functional alignment is
a necessary precondition to unlock the power of multiview self-supervision. We
introduce MixGate, a framework built on a principled training curriculum that
first teaches the model a shared, function-aware representation space via an
Equivalence Alignment Loss. Only then do we introduce a multiview masked
modeling objective, which can now leverage the aligned views as a rich,
complementary signal. Extensive experiments, including a crucial ablation
study, demonstrate that our alignment-first strategy transforms masked modeling
from an ineffective technique into a powerful performance driver.

</details>


### [231] [Knowledgeable Language Models as Black-Box Optimizers for Personalized Medicine](https://arxiv.org/abs/2509.20975)
*Michael S. Yao,Osbert Bastani,Alma Andersson,Tommaso Biancalani,Aïcha Bentaieb,Claudia Iriondo*

Main category: cs.LG

TL;DR: LLM驱动的熵引导优化（LEON）利用领域知识来生成个性化治疗方案，优于传统和基于LLM的方法。


<details>
  <summary>Details</summary>
Motivation: 候选治疗方案的有效性无法通过任意给药来评估，需要利用领域知识（如医学教科书和生物医学知识图谱）作为替代信号来评估治疗方案的有效性。

Method: LEON通过“提示优化”实现，利用大型语言模型（LLMs）作为随机引擎来提出治疗设计，无需任何特定任务的微调。

Result: 在现实世界的优化任务中，LEON在提出个体化治疗方案方面优于传统方法和基于LLM的方法。

Conclusion: LEON能够利用大型语言模型（LLMs）作为黑盒优化器，并结合非结构化的领域知识，为患者提出个性化的治疗方案。

Abstract: The goal of personalized medicine is to discover a treatment regimen that
optimizes a patient's clinical outcome based on their personal genetic and
environmental factors. However, candidate treatments cannot be arbitrarily
administered to the patient to assess their efficacy; we often instead have
access to an in silico surrogate model that approximates the true fitness of a
proposed treatment. Unfortunately, such surrogate models have been shown to
fail to generalize to previously unseen patient-treatment combinations. We
hypothesize that domain-specific prior knowledge - such as medical textbooks
and biomedical knowledge graphs - can provide a meaningful alternative signal
of the fitness of proposed treatments. To this end, we introduce LLM-based
Entropy-guided Optimization with kNowledgeable priors (LEON), a mathematically
principled approach to leverage large language models (LLMs) as black-box
optimizers without any task-specific fine-tuning, taking advantage of their
ability to contextualize unstructured domain knowledge to propose personalized
treatment plans in natural language. In practice, we implement LEON via
'optimization by prompting,' which uses LLMs as stochastic engines for
proposing treatment designs. Experiments on real-world optimization tasks show
LEON outperforms both traditional and LLM-based methods in proposing
individualized treatments for patients.

</details>


### [232] [CLUE: Conflict-guided Localization for LLM Unlearning Framework](https://arxiv.org/abs/2509.20977)
*Hang Chen,Jiaying Zhu,Xinyu Yang,Wenya Wang*

Main category: cs.LG

TL;DR: LLM 遗忘技术旨在移除不良数据影响，但现有方法未能区分遗忘和保留神经元，导致效果不佳。CLUE 框架利用电路发现和 CNF 满足性来精确识别和干预神经元，提高了遗忘效率和保留效用。


<details>
  <summary>Details</summary>
Motivation: 现有 LLM 遗忘方法未能区分负责遗忘和保留的神经元，导致过度遗忘或遗忘不完全。

Method: 提出 CLUE 框架，利用电路发现和 CNF 满足性来识别遗忘和保留电路，并为不同类别的神经元提供有针对性的微调策略。

Result: CLUE 在遗忘效率和保留效用方面优于现有方法，实现了精确的神经定位。

Conclusion: CLUE 框架通过精确的神经定位，能够更有效地实现 LLM 的遗忘，同时保留必要的知识。

Abstract: The LLM unlearning aims to eliminate the influence of undesirable data
without affecting causally unrelated information. This process typically
involves using a forget set to remove target information, alongside a retain
set to maintain non-target capabilities. While recent localization-based
methods demonstrate promise in identifying important neurons to be unlearned,
they fail to disentangle neurons responsible for forgetting undesirable
knowledge or retaining essential skills, often treating them as a single
entangled group. As a result, these methods apply uniform interventions,
risking catastrophic over-forgetting or incomplete erasure of the target
knowledge. To address this, we turn to circuit discovery, a mechanistic
interpretability technique, and propose the Conflict-guided Localization for
LLM Unlearning framEwork (CLUE). This framework identifies the forget and
retain circuit composed of important neurons, and then the circuits are
transformed into conjunctive normal forms (CNF). The assignment of each neuron
in the CNF satisfiability solution reveals whether it should be forgotten or
retained. We then provide targeted fine-tuning strategies for different
categories of neurons. Extensive experiments demonstrate that, compared to
existing localization methods, CLUE achieves superior forget efficacy and
retain utility through precise neural localization.

</details>


### [233] [FracAug: Fractional Augmentation boost Graph-level Anomaly Detection under Limited Supervision](https://arxiv.org/abs/2509.20978)
*Xiangyu Dong,Xingyi Zhang,Sibo Wang*

Main category: cs.LG

TL;DR: FracAug通过学习图语义和生成语义一致的图变体来增强GNN在图级别异常检测中的性能，同时利用伪标签来扩大训练集，在12个真实世界数据集上的实验显示出显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 图级别异常检测（GAD）在药物发现等领域至关重要，但高昂的标注成本和数据集不平衡阻碍了图神经网络（GNNs）的性能。

Method: FracAug是一个即插即用的增强框架，通过学习图语义并利用新颖的加权距离感知边界损失来合成分数变体，以捕获多尺度拓扑结构，从而生成多样化的、保持语义的图。然后，FracAug利用来自原始和增强图的预测来伪标注未标记数据，并迭代地扩展训练集。

Result: 在12个真实世界数据集上对14个GNN进行的实验显示，FracAug在平均AUROC、AUPRC和F1分数方面分别提高了高达5.72%、7.23%和4.18%。

Conclusion: FracAug是一个模型无关的模块，与各种GNN兼容，具有出色的通用性和有效性，能够一致地提高性能，解决了图级别异常检测中的数据不平衡和高标注成本问题。

Abstract: Graph-level anomaly detection (GAD) is critical in diverse domains such as
drug discovery, yet high labeling costs and dataset imbalance hamper the
performance of Graph Neural Networks (GNNs). To address these issues, we
propose FracAug, an innovative plug-in augmentation framework that enhances
GNNs by generating semantically consistent graph variants and pseudo-labeling
with mutual verification. Unlike previous heuristic methods, FracAug learns
semantics within given graphs and synthesizes fractional variants, guided by a
novel weighted distance-aware margin loss. This captures multi-scale topology
to generate diverse, semantic-preserving graphs unaffected by data imbalance.
Then, FracAug utilizes predictions from both original and augmented graphs to
pseudo-label unlabeled data, iteratively expanding the training set. As a
model-agnostic module compatible with various GNNs, FracAug demonstrates
remarkable universality and efficacy: experiments across 14 GNNs on 12
real-world datasets show consistent gains, boosting average AUROC, AUPRC, and
F1-score by up to 5.72%, 7.23%, and 4.18%, respectively.

</details>


### [234] [Toward Robust and Efficient ML-Based GPU Caching for Modern Inference](https://arxiv.org/abs/2509.20979)
*Peng Chen,Jiaji Zhang,Hailiang Zhao,Yirong Zhang,Jiahong Yu,Xueyan Tang,Yixuan Wang,Hao Li,Jianping Zou,Gang Xiong,Kingsum Chow,Shuibing He,Shuiguang Deng*

Main category: cs.LG

TL;DR: LCR是一个基于学习的GPU缓存框架，通过LARU算法提高缓存效率，在DLRM和LLM场景下分别提升吞吐量高达24.2%和降低P99 TTFT达28.3%，并在预测不准确时保持稳定性能。


<details>
  <summary>Details</summary>
Motivation: 现代GPU推理中的缓存效率瓶颈，尤其是在推荐模型和大型语言模型中，LRU等启发式策略在结构化访问模式下表现不佳，而现有基于学习的方法存在准确性不高或设计过于保守导致收益有限，以及高开销等问题。

Method: 提出LCR框架，其核心算法LARU增强了LRU，结合了机器学习预测，并通过在线错误估计动态适应预测准确性。当预测准确时，LARU接近最优；当预测不准确时，其性能会优雅地退化至接近LRU。

Result: 在DLRM和LLM场景下，LCR的性能提升高达24.2%（吞吐量）和28.3%（P99 TTFT），优于现有系统。即使在预测效果不佳的情况下，LCR仍能保持性能稳定，展示了其实用性和鲁棒性。

Conclusion: LCR框架成功地弥合了基于学习的缓存的经验进展和理论进步之间的差距，在保证鲁棒性和效率的同时实现了性能提升。

Abstract: In modern GPU inference, cache efficiency remains a major bottleneck. In
recommendation models, embedding hit rates largely determine throughput, while
in large language models, KV-cache misses substantially increase
time-to-first-token (TTFT). Heuristic policies such as \textsc{LRU} often
struggle under structured access patterns. Learning-based approaches are
promising, but in practice face two major limitations: they degrade sharply
when predictions are inaccurate, or they gain little even with accurate
predictions due to conservative designs. Some also incur high overhead, further
limiting practicality.
  We present \textsc{LCR}, a practical framework for learning-based GPU caching
that delivers performance gains while ensuring robustness and efficiency. Its
core algorithm, \textsc{LARU}, enhances \textsc{LRU} with machine-learned
predictions and dynamically adapts to prediction accuracy through online error
estimation. When predictions are accurate, \textsc{LARU} achieves near-optimal
performance. With inaccurate predictions, it degrades gracefully to
near-\textsc{LRU} performance. With \textsc{LCR}, we bridge the gap between
empirical progress and theoretical advances in learning-based caching.
  Experiments show that \textsc{LCR} delivers consistent gains under realistic
conditions. In DLRM and LLM scenarios, it improves throughput by up to 24.2\%
and reduces P99 TTFT by up to 28.3\%, outperforming widely used inference
systems. Even under poor predictions, its performance remains stable,
demonstrating practical robustness.

</details>


### [235] [Intercept Cancer: Cancer Pre-Screening with Large Scale Healthcare Foundation Models](https://arxiv.org/abs/2506.00209)
*Liwen Sun,Hao-Ren Yao,Gary Gao,Ophir Frieder,Chenyan Xiong*

Main category: cs.LG

TL;DR: CATCH-FM是一种基于医疗记录的癌症预筛查方法，利用大型语言模型识别高风险患者，在回顾性评估中表现优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有癌症筛查方法成本高、侵入性强且普及性不足，导致许多本可挽救的生命被延误。

Method: 通过在数百万份电子健康记录（EHR）上预训练大型语言模型（最大24亿参数），并针对癌症风险预测队列进行微调，开发CATCH-FM模型。

Result: 在包含三万名患者的回顾性评估中，CATCH-FM实现了60%的灵敏度和99%的特异性及阴性预测值，优于传统的基于特征的树模型以及通用的和医学领域的大型语言模型。在EHRSHOT少样本学习排行榜上，CATCH-FM在胰腺癌风险预测方面取得了最先进的成果。

Conclusion: CATCH-FM在不同的患者分布下表现稳健，利用ICD编码空间具有优势，并且能够捕捉非平凡的癌症风险因素，为癌症早筛提供了有效且可扩展的解决方案。

Abstract: Cancer screening, leading to early detection, saves lives. Unfortunately,
existing screening techniques require expensive and intrusive medical
procedures, not globally available, resulting in too many lost would-be-saved
lives. We present CATCH-FM, CATch Cancer early with Healthcare Foundation
Models, a cancer pre-screening methodology that identifies high-risk patients
for further screening solely based on their historical medical records. With
millions of electronic healthcare records (EHR), we establish the scaling law
of EHR foundation models pretrained on medical code sequences, pretrain
compute-optimal foundation models of up to 2.4 billion parameters, and finetune
them on clinician-curated cancer risk prediction cohorts. In our retrospective
evaluation comprising of thirty thousand patients, CATCH-FM achieved strong
efficacy (60% sensitivity) with low risk (99% specificity and Negative
Predictive Value), outperforming feature-based tree models as well as general
and medical large language models by large margins. Despite significant
demographic, healthcare system, and EHR coding differences, CATCH-FM achieves
state-of-the-art pancreatic cancer risk prediction on the EHRSHOT few-shot
leaderboard, outperforming EHR foundation models pretrained using on-site
patient data. Our analysis demonstrates the robustness of CATCH-FM in various
patient distributions, the benefits of operating in the ICD code space, and its
ability to capture non-trivial cancer risk factors. Our code will be
open-sourced.

</details>


### [236] [Binary Autoencoder for Mechanistic Interpretability of Large Language Models](https://arxiv.org/abs/2509.20997)
*Hakaze Cho,Haolin Yang,Brian M. Kurkoski,Naoya Inoue*

Main category: cs.LG

TL;DR: 本研究提出了一种名为二值自编码器（BAE）的新型自编码器变体，旨在解决现有方法在从大型语言模型（LLMs）的隐藏状态中提取稀疏、原子化特征时存在的全局稀疏性不足的问题。BAE通过在小批量激活上强制执行最小熵来促进跨实例的特征独立性和稀疏性，并使用梯度估计实现反向传播。


<details>
  <summary>Details</summary>
Motivation: 现有方法在从LLM隐藏状态中提取特征时，通常依赖于对单个训练实例进行正则化的自编码器，缺乏跨实例的全局稀疏性保证，导致大量稠密特征，损害了特征稀疏性和原子化。

Method: 提出了一种名为二值自编码器（BAE）的新型自编码器变体。BAE通过对隐藏激活进行1比特离散化，并应用梯度估计来实现反向传播，从而在小批量激活上强制执行最小熵，以促进特征独立性和稀疏性。

Result: BAE能够可靠地估计二值隐藏激活上的熵，可用于表征LLM的推理动态和上下文学习。此外，BAE在提取原子化特征方面优于基线方法，产生的可解释特征数量最多，并且避免了稠密特征。

Conclusion: BAE作为一种特征提取器是有效的，并且能够解决现有方法在特征稀疏性和原子化方面的不足。

Abstract: Existing works are dedicated to untangling atomized numerical components
(features) from the hidden states of Large Language Models (LLMs) for
interpreting their mechanism. However, they typically rely on autoencoders
constrained by some implicit training-time regularization on single training
instances (i.e., $L_1$ normalization, top-k function, etc.), without an
explicit guarantee of global sparsity among instances, causing a large amount
of dense (simultaneously inactive) features, harming the feature sparsity and
atomization. In this paper, we propose a novel autoencoder variant that
enforces minimal entropy on minibatches of hidden activations, thereby
promoting feature independence and sparsity across instances. For efficient
entropy calculation, we discretize the hidden activations to 1-bit via a step
function and apply gradient estimation to enable backpropagation, so that we
term it as Binary Autoencoder (BAE) and empirically demonstrate two major
applications: (1) Feature set entropy calculation. Entropy can be reliably
estimated on binary hidden activations, which we empirically evaluate and
leverage to characterize the inference dynamics of LLMs and In-context
Learning. (2) Feature untangling. Similar to typical methods, BAE can extract
atomized features from LLM's hidden states. To robustly evaluate such feature
extraction capability, we refine traditional feature-interpretation methods to
avoid unreliable handling of numerical tokens, and show that BAE avoids dense
features while producing the largest number of interpretable ones among
baselines, which confirms the effectiveness of BAE serving as a feature
extractor.

</details>


### [237] [Feature Augmentation of GNNs for ILPs: Local Uniqueness Suffices](https://arxiv.org/abs/2509.21000)
*Qingyu Han,Qian Li,Linxin Yang,Qian Chen,Qingjiang Shi,Ruoyu Sun*

Main category: cs.LG

TL;DR: GNNs在解决整数线性规划（ILP）问题时存在表达能力不足和泛化能力差的问题。本文提出了一种新的局部唯一标识符（Local-UID）方案，并基于此开发了ColorGNN和ColorUID模型，在ILP基准测试和图级别任务上取得了显著的性能提升和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 标准的匿名GNN在处理整数线性规划（ILP）问题时表达能力有限，而全局唯一标识符（UID）的引入会损害泛化能力。作者旨在解决这一矛盾。

Method: 提出了一种基于d-跳唯一性着色的局部唯一标识符（Local-UID）方案，并在此基础上引入了ColorGNN（通过颜色条件嵌入）和ColorUID（轻量级特征级别变体）。

Result: 在三个ILP基准测试上取得了显著的性能提升，在線性規劃数据集上展现了强的OOD泛化能力，并且与现有最优方法结合时，在通用的图级别任务上进一步提升了性能。

Conclusion: 局部唯一标识符（Local-UID）方案能够实现与全局唯一标识符（Global-UID）相当的表达能力，同时具有更强的泛化能力，ColorGNN和ColorUID在ILP求解和图级别任务中表现优异。

Abstract: Integer Linear Programs (ILPs) are central to real-world optimizations but
notoriously difficult to solve. Learning to Optimize (L2O) has emerged as a
promising paradigm, with Graph Neural Networks (GNNs) serving as the standard
backbone. However, standard anonymous GNNs are limited in expressiveness for
ILPs, and the common enhancement of augmenting nodes with globally unique
identifiers (UIDs) typically introduces spurious correlations that severely
harm generalization. To address this tradeoff, we propose a parsimonious
Local-UID scheme based on d-hop uniqueness coloring, which ensures identifiers
are unique only within each node's d-hop neighborhood. Building on this scheme,
we introduce ColorGNN, which incorporates color information via
color-conditioned embeddings, and ColorUID, a lightweight feature-level
variant. We prove that for d-layer networks, Local-UIDs achieve the expressive
power of Global-UIDs while offering stronger generalization. Extensive
experiments show that our approach (i) yields substantial gains on three ILP
benchmarks, (ii) exhibits strong OOD generalization on linear programming
datasets, and (iii) further improves a general graph-level task when paired
with a state-of-the-art method.

</details>


### [238] [Lossless Compression: A New Benchmark for Time Series Model Evaluation](https://arxiv.org/abs/2509.21002)
*Meng Wan,Benxi Tian,Jue Wang,Cui Hui,Ningming Nie,Tiantian Liu,Zongguo Wang,Cao Rongqiang,Peng Shi,Yangang Wang*

Main category: cs.LG

TL;DR: 时间序列模型评估的新范式是基于香农源编码定理的无损压缩，它提供了一个统一的信息论标准来衡量模型的建模能力，并揭示了经典基准无法发现的分布弱点。


<details>
  <summary>Details</summary>
Motivation: 传统的时间序列模型评估方法主要集中在预测、填补、异常检测和分类等特定任务上，未能严格评估模型是否捕捉了数据的完整生成分布。

Method: 提出将无损压缩作为评估时间序列模型的新范式，并基于香农源编码定理建立了最优压缩长度与负对数似然之间的等价关系，从而定义了一个标准化的评估协议和指标。此外，还开源了一个名为TSCom-Bench的评估框架。

Result: 在多种数据集和先进模型（如TimeXer、iTransformer和PatchTST）上的实验表明，无损压缩能够揭示经典基准所忽略的分布弱点。

Conclusion: 无损压缩作为一种原则性的评估任务，能够补充和扩展现有的时间序列模型评估方法，提供一个更全面、更严格的评估标准。

Abstract: The evaluation of time series models has traditionally focused on four
canonical tasks: forecasting, imputation, anomaly detection, and
classification. While these tasks have driven significant progress, they
primarily assess task-specific performance and do not rigorously measure
whether a model captures the full generative distribution of the data. We
introduce lossless compression as a new paradigm for evaluating time series
models, grounded in Shannon's source coding theorem. This perspective
establishes a direct equivalence between optimal compression length and the
negative log-likelihood, providing a strict and unified information-theoretic
criterion for modeling capacity. Then We define a standardized evaluation
protocol and metrics. We further propose and open-source a comprehensive
evaluation framework TSCom-Bench, which enables the rapid adaptation of time
series models as backbones for lossless compression. Experiments across diverse
datasets on state-of-the-art models, including TimeXer, iTransformer, and
PatchTST, demonstrate that compression reveals distributional weaknesses
overlooked by classic benchmarks. These findings position lossless compression
as a principled task that complements and extends existing evaluation for time
series modeling.

</details>


### [239] [MAIFormer: Multi-Agent Inverted Transformer for Flight Trajectory Prediction](https://arxiv.org/abs/2509.21004)
*Seokbin Yoon,Keumjin Lee*

Main category: cs.LG

TL;DR: MAIFormer通过引入两种注意力机制（掩码多变量注意力和代理注意力）来预测多智能体飞行轨迹，并在真实数据集上实现了最佳性能，同时提高了预测的可解释性。


<details>
  <summary>Details</summary>
Motivation: 预测多智能体飞行轨迹至关重要，但由于个体行为建模和智能体间交互的复杂性，以及生成可解释预测结果的挑战，因此具有挑战性。

Method: 提出了一种名为MAIFormer的新型神经网络架构，它包含两种关键的注意力模块：(i) 掩码多变量注意力，用于捕捉单个飞机的时空模式；(ii) 代理注意力，用于模拟复杂空中交通场景中多个智能体之间的社会模式。

Result: 在韩国仁川国际机场终端空域的真实ADS-B飞行轨迹数据集上评估了MAIFormer。实验结果表明，MAIFormer在多个指标上均取得了最佳性能，优于其他方法。

Conclusion: MAIFormer在预测多智能体飞行轨迹方面表现出色，并且能够生成可解释的预测结果，从而提高了模型的透明度和在空中交通管制中的实际应用价值。

Abstract: Flight trajectory prediction for multiple aircraft is essential and provides
critical insights into how aircraft navigate within current air traffic flows.
However, predicting multi-agent flight trajectories is inherently challenging.
One of the major difficulties is modeling both the individual aircraft
behaviors over time and the complex interactions between flights. Generating
explainable prediction outcomes is also a challenge. Therefore, we propose a
Multi-Agent Inverted Transformer, MAIFormer, as a novel neural architecture
that predicts multi-agent flight trajectories. The proposed framework features
two key attention modules: (i) masked multivariate attention, which captures
spatio-temporal patterns of individual aircraft, and (ii) agent attention,
which models the social patterns among multiple agents in complex air traffic
scenes. We evaluated MAIFormer using a real-world automatic dependent
surveillance-broadcast flight trajectory dataset from the terminal airspace of
Incheon International Airport in South Korea. The experimental results show
that MAIFormer achieves the best performance across multiple metrics and
outperforms other methods. In addition, MAIFormer produces prediction outcomes
that are interpretable from a human perspective, which improves both the
transparency of the model and its practical utility in air traffic control.

</details>


### [240] [ExMolRL: Phenotype-Target Joint Generation of De Novo Molecules via Multi-Objective Reinforcement Learning](https://arxiv.org/abs/2509.21010)
*Haotian Guo,Hui Liu*

Main category: cs.LG

TL;DR: ExMoIRL是一个新颖的生成框架，结合了表型和靶点特异性线索，用于从头分子生成，以应对AI驱动的药物设计中的挑战。


<details>
  <summary>Details</summary>
Motivation: 当前的基于表型和基于靶点的策略各有利弊，前者成本高昂，后者忽视细胞系统反应。本研究提出ExMoIRL以弥合这一差距。

Method: ExMoIRL利用基于表型的生成器，在广泛的药物诱导转录谱上进行预训练，并通过多目标强化学习进行微调。奖励函数融合了对接亲和力、药物相似性评分、排序损失、先验似然正则化和熵最大化。

Result: 实验表明，ExMoIRL在多个靶点上优于最先进的模型，生成的分子具有良好的药物相似性、高靶点亲和力和对癌细胞的抑制效力（IC50）。

Conclusion: ExMoIRL展示了结合表型引导和靶点感知策略的协同潜力，为从头药物发现提供了更有效的解决方案。

Abstract: The generation of high-quality candidate molecules remains a central
challenge in AI-driven drug design. Current phenotype-based and target-based
strategies each suffer limitations, either incurring high experimental costs or
overlook system-level cellular responses. To bridge this gap, we propose
ExMoIRL, a novel generative framework that synergistically integrates
phenotypic and target-specific cues for de novo molecular generation. The
phenotype-guided generator is first pretrained on expansive drug-induced
transcriptional profiles and subsequently fine-tuned via multi-objective
reinforcement learning (RL). Crucially, the reward function fuses docking
affinity and drug-likeness scores, augmented with ranking loss,
prior-likelihood regularization, and entropy maximization. The multi-objective
RL steers the model toward chemotypes that are simultaneously potent, diverse,
and aligned with the specified phenotypic effects. Extensive experiments
demonstrate ExMoIRL's superior performance over state-of-the-art
phenotype-based and target-based models across multiple well-characterized
targets. Our generated molecules exhibit favorable drug-like properties, high
target affinity, and inhibitory potency (IC50) against cancer cells. This
unified framework showcases the synergistic potential of combining
phenotype-guided and target-aware strategies, offering a more effective
solution for de novo drug discovery.

</details>


### [241] [Mechanism of Task-oriented Information Removal in In-context Learning](https://arxiv.org/abs/2509.21012)
*Hakaze Cho,Haolin Yang,Gouki Minegishi,Naoya Inoue*

Main category: cs.LG

TL;DR: ICL通过信息移除机制进行，低秩过滤器和去噪头对其至关重要。


<details>
  <summary>Details</summary>
Motivation: ICL的内在机制不明确，需要从新视角进行研究。

Method: 通过信息移除视角研究ICL，提出使用低秩过滤器模拟信息移除过程，并识别出‘去噪头’。

Result: 发现ICL通过选择性移除冗余信息来优化输出，去噪头在其中起到关键作用，移除去噪头会导致ICL准确率显著下降。

Conclusion: ICL的关键机制是模拟信息移除过程，去噪头对此机制至关重要。

Abstract: In-context Learning (ICL) is an emerging few-shot learning paradigm based on
modern Language Models (LMs), yet its inner mechanism remains unclear. In this
paper, we investigate the mechanism through a novel perspective of information
removal. Specifically, we demonstrate that in the zero-shot scenario, LMs
encode queries into non-selective representations in hidden states containing
information for all possible tasks, leading to arbitrary outputs without
focusing on the intended task, resulting in near-zero accuracy. Meanwhile, we
find that selectively removing specific information from hidden states by a
low-rank filter effectively steers LMs toward the intended task. Building on
these findings, by measuring the hidden states on carefully designed metrics,
we observe that few-shot ICL effectively simulates such task-oriented
information removal processes, selectively removing the redundant information
from entangled non-selective representations, and improving the output based on
the demonstrations, which constitutes a key mechanism underlying ICL. Moreover,
we identify essential attention heads inducing the removal operation, termed
Denoising Heads, which enables the ablation experiments blocking the
information removal operation from the inference, where the ICL accuracy
significantly degrades, especially when the correct label is absent from the
few-shot demonstrations, confirming both the critical role of the information
removal mechanism and denoising heads.

</details>


### [242] [Predicting LLM Reasoning Performance with Small Proxy Model](https://arxiv.org/abs/2509.21013)
*Woosung Koh,Juyoung Suk,Sungjun Han,Se-Young Yun,Jay Shin*

Main category: cs.LG

TL;DR: rBridge通过加权负对数似然与任务对齐，并使用推理轨迹作为金标签，使得小模型（≤1B）能够有效预测大模型的推理能力，从而降低了数据排序成本，并在多个推理基准上实现了最强的相关性。


<details>
  <summary>Details</summary>
Motivation: 由于预训练大型语言模型的成本高昂，需要利用较小的代理模型在扩展之前优化数据集。然而，对于具有应急行为且通常在超过7B参数时才能可靠出现的推理能力，这种方法变得具有挑战性。

Method: rBridge通过加权负对数似然与任务对齐，并使用来自前沿模型的推理轨迹作为金标签，来使小代理模型（≤1B）与（1）预训练目标和（2）目标任务更紧密地对齐，从而有效地预测大模型的推理能力。

Result: rBridge将数据集排序成本降低了100多倍，在1B到32B规模的六个推理基准上实现了最强的相关性，并在1B到7B规模上实现了跨预训练数据集的零样本预测关系迁移。

Conclusion: rBridge提供了一种以更低成本探索面向推理的预训练的实用途径。

Abstract: Given the prohibitive cost of pre-training large language models, it is
essential to leverage smaller proxy models to optimize datasets before scaling
up. However, this approach becomes challenging for reasoning capabilities,
which exhibit emergent behavior that only appear reliably at larger model
sizes, often exceeding 7B parameters. To address this, we introduce rBridge,
showing that small proxies ($\leq$1B) can effectively predict large-model
reasoning by aligning more closely with (1) the pre-training objective and (2)
the target task. rBridge achieves this by weighting negative log-likelihood
with task alignment, using reasoning traces from frontier models as gold
labels. In our experiments, rBridge (i) reduces dataset ranking costs by over
100x relative to the best baseline, (ii) achieves the strongest correlation
across six reasoning benchmarks at 1B to 32B scale, and (iii) zero-shot
transfers predictive relationships across pre-training datasets at 1B to 7B
scale. These findings indicate that rBridge offers a practical path for
exploring reasoning-oriented pre-training at lower cost.

</details>


### [243] [DELTA-Code: How Does RL Unlock and Transfer New Programming Algorithms in LLMs?](https://arxiv.org/abs/2509.21016)
*Yiyou Sun,Yuhan Cao,Pohao Huang,Haoyue Bai,Hannaneh Hajishirzi,Nouha Dziri,Dawn Song*

Main category: cs.LG

TL;DR: LLMs 难以学习或泛化新的推理策略，即使通过强化学习 (RL) 也是如此。DELTA-Code 基准测试了 LLM 在算法编码中的学习和迁移能力。虽然 LLM 可以在大量尝试后学习解决之前无法解决的问题，但它们在泛化到分布外（OOD）的新策略方面仍然存在困难。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型 (LLM) 是否能够学习或泛化新的推理策略，而不仅仅是依赖于预训练或微调中获得的技能。

Method: 引入 DELTA-Code，这是一个包含合成编码问题族的受控基准，用于测试学习能力（LLM 是否能通过强化学习解决预训练模型无法解决的问题）和迁移能力（所学技能是否能迁移到分布外测试集）。通过各种训练技巧（如分阶段预热、经验回放、课程学习和验证循环）来增强学习能力。

Result: LLM 在经过大量训练后，可以突然学会解决之前无法解决的问题（“grokking”现象）。在迁移能力方面，LLM 在同一问题族内和重组技能方面表现良好，但在处理需要全新策略的“转换性”问题时仍然存在不足。

Conclusion: DELTA-Code 提供了一个评估 LLM 强化学习驱动的推理能力的平台，并有助于理解模型如何超越现有知识来学习新的算法技能。然而，LLM 在泛化到需要全新推理策略的分布外问题方面仍然存在挑战。

Abstract: It remains an open question whether LLMs can acquire or generalize genuinely
new reasoning strategies, beyond the sharpened skills encoded in their
parameters during pre-training or post-training. To attempt to answer this
debate, we introduce DELTA-Code--Distributional Evaluation of Learnability and
Transferrability in Algorithmic Coding, a controlled benchmark of synthetic
coding problem families designed to probe two fundamental aspects: learnability
-- can LLMs, through reinforcement learning (RL), solve problem families where
pretrained models exhibit failure with large enough attempts (pass@K=0)? --and
transferrability -- if learnability happens, can such skills transfer
systematically to out-of-distribution (OOD) test sets? Unlike prior public
coding datasets, DELTA isolates reasoning skills through templated problem
generators and introduces fully OOD problem families that demand novel
strategies rather than tool invocation or memorized patterns. Our experiments
reveal a striking grokking phase transition: after an extended period with
near-zero reward, RL-trained models abruptly climb to near-perfect accuracy. To
enable learnability on previously unsolvable problem families, we explore key
training ingredients such as staged warm-up with dense rewards, experience
replay, curriculum training, and verification-in-the-loop. Beyond learnability,
we use DELTA to evaluate transferability or generalization along exploratory,
compositional, and transformative axes, as well as cross-family transfer.
Results show solid gains within families and for recomposed skills, but
persistent weaknesses in transformative cases. DELTA thus offers a clean
testbed for probing the limits of RL-driven reasoning and for understanding how
models can move beyond existing priors to acquire new algorithmic skills.

</details>


### [244] [Efficient Ensemble Conditional Independence Test Framework for Causal Discovery](https://arxiv.org/abs/2509.21021)
*Zhengkang Guan,Kun Kuang*

Main category: cs.LG

TL;DR: E-CIT是一个新框架，通过划分数据、独立测试子集并聚合p值来降低条件独立性检验的计算成本，尤其在真实世界数据上效果显著。


<details>
  <summary>Details</summary>
Motivation: 现有基于约束的因果发现方法计算成本高，尤其是在处理大量样本时，限制了其实际应用。

Method: E-CIT框架将数据划分为多个子集，对每个子集独立应用基础条件独立性检验（CIT），并使用一种基于稳定分布特性的新颖方法聚合p值。

Result: E-CIT将基础CIT的计算复杂度降低到与样本量成线性关系（在子集大小固定的情况下），并能在温和条件下保证理论一致性。实验证明，E-CIT显著降低了计算开销，并取得了有竞争力的性能，尤其在复杂和真实世界的数据集上表现更佳。

Conclusion: E-CIT通过其“划分-聚合”策略有效解决了条件独立性检验的计算瓶颈，为因果发现提供了更具计算效率和鲁棒性的解决方案。

Abstract: Constraint-based causal discovery relies on numerous conditional independence
tests (CITs), but its practical applicability is severely constrained by the
prohibitive computational cost, especially as CITs themselves have high time
complexity with respect to the sample size. To address this key bottleneck, we
introduce the Ensemble Conditional Independence Test (E-CIT), a general and
plug-and-play framework. E-CIT operates on an intuitive divide-and-aggregate
strategy: it partitions the data into subsets, applies a given base CIT
independently to each subset, and aggregates the resulting p-values using a
novel method grounded in the properties of stable distributions. This framework
reduces the computational complexity of a base CIT to linear in the sample size
when the subset size is fixed. Moreover, our tailored p-value combination
method offers theoretical consistency guarantees under mild conditions on the
subtests. Experimental results demonstrate that E-CIT not only significantly
reduces the computational burden of CITs and causal discovery but also achieves
competitive performance. Notably, it exhibits an improvement in complex testing
scenarios, particularly on real-world datasets.

</details>


### [245] [Actor-Critic without Actor](https://arxiv.org/abs/2509.21022)
*Donghyeon Ki,Hee-Jun Ahn,Kyungyoon Kim,Byung-Jun Lee*

Main category: cs.LG

TL;DR: ACA框架消除了显式actor网络，直接从noise-level critic的梯度场生成动作，实现了轻量化、高表现力的在线强化学习。


<details>
  <summary>Details</summary>
Motivation: 现有的actor-critic方法依赖于分离的actor和critic网络，训练复杂且难以扩展；基于扩散模型的策略虽然表现力强，但计算开销大。

Method: ACA框架直接从noise-level critic的梯度场生成动作，无需显式actor网络。

Result: 在标准在线强化学习基准测试中，ACA框架的学习曲线更优，性能与标准actor-critic及基于扩散模型的方法相当。

Conclusion: ACA框架提供了一种简单、高效且表现力强的在线强化学习解决方案。

Abstract: Actor-critic methods constitute a central paradigm in reinforcement learning
(RL), coupling policy evaluation with policy improvement. While effective
across many domains, these methods rely on separate actor and critic networks,
which makes training vulnerable to architectural decisions and hyperparameter
tuning. Such complexity limits their scalability in settings that require large
function approximators. Recently, diffusion models have recently been proposed
as expressive policies that capture multi-modal behaviors and improve
exploration, but they introduce additional design choices and computational
burdens, hindering efficient deployment. We introduce Actor-Critic without
Actor (ACA), a lightweight framework that eliminates the explicit actor network
and instead generates actions directly from the gradient field of a noise-level
critic. This design removes the algorithmic and computational overhead of actor
training while keeping policy improvement tightly aligned with the critic's
latest value estimates. Moreover, ACA retains the ability to capture diverse,
multi-modal behaviors without relying on diffusion-based actors, combining
simplicity with expressiveness. Through extensive experiments on standard
online RL benchmarks,ACA achieves more favorable learning curves and
competitive performance compared to both standard actor-critic and
state-of-the-art diffusion-based methods, providing a simple yet powerful
solution for online RL.

</details>


### [246] [FORCE: Transferable Visual Jailbreaking Attacks via Feature Over-Reliance CorrEction](https://arxiv.org/abs/2509.21029)
*Runqi Lin,Alasdair Paren,Suqin Yuan,Muyang Li,Philip Torr,Adel Bibi,Tongliang Liu*

Main category: cs.LG

TL;DR: 简单的视觉越狱攻击可以轻易地操纵开源多模态大语言模型（MLLMs），但这些攻击的跨模型迁移能力有限，难以识别闭源MLLMs中的漏洞。本研究分析了这些攻击的损失函数地形，发现它们倾向于存在于高锐度区域，并且对参数的微小变动非常敏感。通过分析其特征表示，我们发现这些攻击不恰当的依赖于狭窄的层表示和语义上较差的频率分量。为此，我们提出了一种特征过度依赖校正（FORCE）方法，引导攻击探索更广泛的可行区域，并根据语义内容重新调整频率特征的影响力。通过消除对层和光谱特征的不可泛化依赖，我们的方法发现了更平坦的视觉越狱攻击可行区域，从而提高了跨模型迁移能力。实验证明，我们的方法有效地促进了针对闭源MLLMs的视觉红队评估。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉越狱攻击在开源模型上表现尚可，但跨模型迁移能力不足，尤其是在闭源模型上效果不佳。这是因为这些攻击往往依赖于模型特定的、不鲁棒的特征。需要一种方法来提高攻击的泛化能力，以便更好地评估闭源MLLM的安全性。

Method: 本研究首先分析了视觉越狱攻击的损失函数地形，发现其攻击通常位于高锐度区域，并且对模型参数变化敏感。接着，通过分析攻击的中间层特征和频域特征，发现攻击不恰当地依赖于狭窄的层表示和语义上较差的频率分量。基于这些发现，提出了一种特征过度依赖校正（FORCE）方法，通过引导攻击探索更广泛的层特征可行区域，并根据语义内容重新调整频率特征的影响力，来消除攻击对特定特征的过度依赖，从而发现更平坦的可行区域，提高攻击的跨模型迁移能力。

Result: FORCE方法通过消除视觉越狱攻击对层特征和频率特征的不可泛化依赖，发现了更平坦的可行区域。实验证明，该方法显著提高了攻击的跨模型迁移能力，能够有效地对闭源MLLMs进行视觉红队评估，成功识别了闭源模型中的漏洞。

Conclusion: 本研究提出的FORCE方法通过分析和修正视觉越狱攻击中存在的特征过度依赖问题，成功提高了攻击的跨模型迁移能力，为评估闭源MLLM的安全性提供了一种有效手段。该方法通过探索更广泛的特征空间和重新校准频率特征，实现了更鲁棒的视觉越狱攻击。

Abstract: The integration of new modalities enhances the capabilities of multimodal
large language models (MLLMs) but also introduces additional vulnerabilities.
In particular, simple visual jailbreaking attacks can manipulate open-source
MLLMs more readily than sophisticated textual attacks. However, these
underdeveloped attacks exhibit extremely limited cross-model transferability,
failing to reliably identify vulnerabilities in closed-source MLLMs. In this
work, we analyse the loss landscape of these jailbreaking attacks and find that
the generated attacks tend to reside in high-sharpness regions, whose
effectiveness is highly sensitive to even minor parameter changes during
transfer. To further explain the high-sharpness localisations, we analyse their
feature representations in both the intermediate layers and the spectral
domain, revealing an improper reliance on narrow layer representations and
semantically poor frequency components. Building on this, we propose a Feature
Over-Reliance CorrEction (FORCE) method, which guides the attack to explore
broader feasible regions across layer features and rescales the influence of
frequency features according to their semantic content. By eliminating
non-generalizable reliance on both layer and spectral features, our method
discovers flattened feasible regions for visual jailbreaking attacks, thereby
improving cross-model transferability. Extensive experiments demonstrate that
our approach effectively facilitates visual red-teaming evaluations against
closed-source MLLMs.

</details>


### [247] [Reinforcement Learning Fine-Tuning Enhances Activation Intensity and Diversity in the Internal Circuitry of LLMs](https://arxiv.org/abs/2509.21044)
*Honglin Zhang,Qianyue Hao,Fengli Xu,Yong Li*

Main category: cs.LG

TL;DR: RL微调能提升LLM能力，本文通过EAP研究RL微调对LLM内部机制的影响，发现RL（PPO/GRPO）会增加激活强度和多样性，而DPO效果较弱。


<details>
  <summary>Details</summary>
Motivation: RL微调如何提升LLM能力及其内部机制尚不明确。

Method: 采用EAP分析RL微调前后LLM的内部差异。

Result: RL微调（PPO/GRPO）能增加激活强度和多样性，DPO效果不明显。表明RL重塑了信息流，使其更冗余和灵活，可能提高了泛化能力。

Conclusion: RL微调系统性地改变了LLM的内部连接，PPO/GRPO和DPO在内部机制改变上存在差异。

Abstract: Large language models (LLMs) acquire extensive prior knowledge through
large-scale pretraining and can be further enhanced via supervised fine-tuning
(SFT) or reinforcement learning (RL)-based post-training. A growing body of
evidence has shown that RL fine-tuning improves the capability of LLMs beyond
what SFT alone achieves. However, the underlying mechanisms why RL fine-tuning
is able to enhance the capability of various LLMs with distinct intrinsic
characteristics remain underexplored. In this study, we draw inspiration from
prior work on edge attribution patching (EAP) to investigate the internal
differences of LLMs before and after RL fine-tuning. Our analysis across
multiple model families shows two robust effects of online RL post-training:
(i) an overall increase in activation intensity, indicating that more internal
pathways are engaged and their signals become stronger, and (ii) greater
diversity in activation patterns, reflected by higher entropy and less
concentrated edge distributions. These changes suggest that RL reshapes
information flow to be both more redundant and more flexible, which may explain
its advantage in generalization. Notably, models fine-tuned with Direct
Preference Optimization (DPO) deviate from these trends, exhibiting
substantially weaker or inconsistent internal changes compared to PPO- and
GRPO-based training. Together, our findings provide a unified view of how RL
fine-tuning systematically alters the internal circuitry of LLMs and highlight
the methodological distinctions between online RL and preference-based
approaches. Our code is open source at
https://anonymous.4open.science/r/llm_rl_probing_analysis-F673.

</details>


### [248] [GeoRef: Referring Expressions in Geometry via Task Formulation, Synthetic Supervision, and Reinforced MLLM-based Solutions](https://arxiv.org/abs/2509.21050)
*Bing Liu,Wenqiang Yv,Xuzheng Yang,Shichang Wang,Junzhuo Liu,Peng Wang,Guoqing Wang,Yang Yang,Heng Tao Shen*

Main category: cs.LG

TL;DR: 该研究提出了几何问题中的指代表达式理解（REC）任务，并发布了GeoRef数据集来评估模型定位几何元素（点、形状、空间关系）的能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决AI驱动的几何问题求解中，理解和解释基于自然语言查询的几何元素这一基础但未被充分探索的能力。

Method: 创建了一个名为GeoRef的数据集，并生成了大规模的合成训练数据集。探索了监督微调（SFT）和组合相对策略优化（GRPO）两种微调方法，并提出了一个验证-重新生成机制。

Result: GRPO相比SFT表现更优，并且验证-重新生成机制进一步提高了准确性。即使是先进的多模态大语言模型（MLLMs）在此任务上也表现不佳。在GeoRef上训练的模型在下游几何推理任务上有所改进。

Conclusion: 显式评估和加强几何基础是实现鲁棒几何问题求解的先决条件。REC任务是多模态数学理解的基础。

Abstract: AI-driven geometric problem solving is a complex vision-language task that
requires accurate diagram interpretation, mathematical reasoning, and robust
cross-modal grounding. A foundational yet underexplored capability for this
task is the ability to identify and interpret geometric elements based on
natural language queries. To address this, we introduce the task of Referring
Expression Comprehension (REC) for geometric problems, which evaluates whether
models can localize points, shapes, and spatial relations in diagrams in
response to textual prompts. We present GeoRef, a benchmark dataset constructed
from existing geometric problem corpora, featuring diverse, high-quality
annotations and queries. Due to the lack of annotated data for this task, we
generate a large-scale synthetic training dataset using a structured geometric
formal language, enabling broad coverage of geometric concepts and facilitating
model adaptation. We explore two fine-tuning approaches: Supervised Fine-Tuning
(SFT) and Group Relative Policy Optimization (GRPO). Our results show that GRPO
significantly outperforms SFT by better aligning model behavior with
task-specific rewards. Furthermore, we propose a verify-and-regenerate
mechanism that detects incorrect predictions and re-infers answers using
contextual reasoning history, further boosting accuracy. Notably, even
state-of-the-art Multimodal Large Language Models (MLLMs) struggle with this
task, underscoring the necessity of explicitly evaluating and strengthening
geometric grounding as a prerequisite for robust geometric problem solving.
Moreover, models trained on GeoRef demonstrate measurable improvements on
downstream geometric reasoning tasks, highlighting the broader value of REC as
a foundation for multimodal mathematical understanding.

</details>


### [249] [SPREAD: Sampling-based Pareto front Refinement via Efficient Adaptive Diffusion](https://arxiv.org/abs/2509.21058)
*Sedjro Salomon Hotegni,Sebastian Peitz*

Main category: cs.LG

TL;DR: SPREAD是一个基于扩散模型的高效多目标优化框架，能在保证效率、可扩展性和 Pareto 前沿覆盖率的同时，生成高质量的 Pareto 前沿。


<details>
  <summary>Details</summary>
Motivation: 开发能够处理大规模且计算成本高昂的问题的高效多目标优化方法，以获得最佳折衷的 Pareto 前沿，仍然是一个关键挑战。

Method: SPREAD 首先学习决策空间采样点的条件扩散过程，然后在每个反向扩散步骤中，通过一种结合了自适应多梯度下降更新（用于快速收敛）和基于高斯 RBF 的排斥项（用于多样性）的采样方案来优化候选点。

Result: 在包括离线和基于贝叶斯代理的设置在内的多目标优化基准测试中，SPREAD 在效率、可扩展性和 Pareto 前沿覆盖率方面均达到了或超过了领先的基线。

Conclusion: SPREAD 框架在多目标优化问题上表现出了优越的性能，能够有效地生成高质量的 Pareto 前沿，尤其是在具有挑战性的大规模和昂贵问题上。

Abstract: Developing efficient multi-objective optimization methods to compute the
Pareto set of optimal compromises between conflicting objectives remains a key
challenge, especially for large-scale and expensive problems. To bridge this
gap, we introduce SPREAD, a generative framework based on Denoising Diffusion
Probabilistic Models (DDPMs). SPREAD first learns a conditional diffusion
process over points sampled from the decision space and then, at each reverse
diffusion step, refines candidates via a sampling scheme that uses an adaptive
multiple gradient descent-inspired update for fast convergence alongside a
Gaussian RBF-based repulsion term for diversity. Empirical results on
multi-objective optimization benchmarks, including offline and Bayesian
surrogate-based settings, show that SPREAD matches or exceeds leading baselines
in efficiency, scalability, and Pareto front coverage.

</details>


### [250] [Structure-Attribute Transformations with Markov Chain Boost Graph Domain Adaptation](https://arxiv.org/abs/2509.21059)
*Zhen Liu,Yongtao Zhang,Shaobo Ren,Yuxin You*

Main category: cs.LG

TL;DR: SATMC框架通过图结构和属性变换来解决图域自适应中的结构异构性问题，并通过私有域信息约简和经验Wasserstein距离提升泛化能力，在交叉网络节点分类任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有图域自适应方法在处理不同图域间的底层结构异构性时存在不足，导致分布对齐不佳。

Method: 提出SATMC框架，通过图结构和属性变换顺序地对齐网络间的分布，并引入私有域信息约简机制和经验Wasserstein距离来提升泛化能力。

Result: 理论证明SATMC的交叉网络节点分类误差界优于现有方法，并在九个公开数据集上的实验表明SATMC的性能优于现有最先进方法。

Conclusion: SATMC在交叉网络节点分类任务上表现出优越的性能，有效解决了图域自适应中的结构异构性问题。

Abstract: Graph domain adaptation has gained significant attention in label-scarce
scenarios across different graph domains. Traditional approaches to graph
domain adaptation primarily focus on transforming node attributes over raw
graph structures and aligning the distributions of the transformed node
features across networks. However, these methods often struggle with the
underlying structural heterogeneity between distinct graph domains, which leads
to suboptimal distribution alignment. To address this limitation, we propose
Structure-Attribute Transformation with Markov Chain (SATMC), a novel framework
that sequentially aligns distributions across networks via both graph structure
and attribute transformations. To mitigate the negative influence of
domain-private information and further enhance the model's generalization,
SATMC introduces a private domain information reduction mechanism and an
empirical Wasserstein distance. Theoretical proofs suggest that SATMC can
achieve a tighter error bound for cross-network node classification compared to
existing graph domain adaptation methods. Extensive experiments on nine pairs
of publicly available cross-domain datasets show that SATMC outperforms
state-of-the-art methods in the cross-network node classification task. The
code is available at https://github.com/GiantZhangYT/SATMC.

</details>


### [251] [ScaleDiff: Scaling Difficult Problems for Advanced Mathematical Reasoning](https://arxiv.org/abs/2509.21070)
*Qizhi Pei,Zhuoshi Pan,Honglin Lin,Xin Gao,Yu Li,Zinan Tang,Conghui He,Rui Yan,Lijun Wu*

Main category: cs.LG

TL;DR: ScaleDiff是一个可扩展的困难问题生成管线，通过识别现有数据集中的困难问题并训练专门的生成器，从而大规模生成新颖的困难问题，以提高大型推理模型（LRMs）的性能，而无需昂贵的API调用或复杂的提示。


<details>
  <summary>Details</summary>
Motivation: 现有的自动数学问题合成方法计算成本高，提示复杂，且生成的问题难度有限，难以扩展。因此，需要一种更有效的方法来大规模生成困难问题，以提升大型推理模型（LRMs）的解决复杂问题的能力。

Method: ScaleDiff首先使用自适应思维模型（能够感知问题难度并切换“Thinking”和“NoThinking”模式）对现有数据集进行单次前向传递，以识别困难问题。然后，在筛选出的困难数据上训练一个专门的困难问题生成器（DiffGen-8B），以大规模生成新颖的困难问题。最后，在ScaleDiff-Math数据集上对Qwen2.5-Math-7B-Instruct进行微调，并与使用Qwen3-8B模型作为教师的成本效益方法进行比较。

Result: 在ScaleDiff-Math数据集上微调Qwen2.5-Math-7B-Instruct模型，相比原始数据集，性能提升了11.3%，在AIME'24、AIME'25、HMMT-Feb'25、BRUMO'25和MATH500上达到了65.9%的平均准确率，优于OpenThinker3等模型。此外，研究观察到随着困难问题数量的增加，模型在困难基准测试上的性能呈现出明显的扩展现象。

Conclusion: ScaleDiff管线能够有效地生成大量困难数学问题，显著提升大型推理模型（LRMs）的性能，并且能够以较低的成本（使用Qwen3-8B模型作为教师）实现这一点，证明了其在扩展模型推理能力方面的有效性和潜力。

Abstract: Large Reasoning Models (LRMs) have shown impressive capabilities in complex
problem-solving, often benefiting from training on difficult mathematical
problems that stimulate intricate reasoning. Recent efforts have explored
automated synthesis of mathematical problems by prompting proprietary models or
large-scale open-source models from seed data or inherent mathematical
concepts. However, scaling up these methods remains challenging due to their
high computational/API cost, complexity of prompting, and limited difficulty
level of the generated problems. To overcome these limitations, we propose
ScaleDiff, a simple yet effective pipeline designed to scale the creation of
difficult problems. We efficiently identify difficult problems from existing
datasets with only a single forward pass using an adaptive thinking model,
which can perceive problem difficulty and automatically switch between
"Thinking" and "NoThinking" modes. We then train a specialized difficult
problem generator (DiffGen-8B) on this filtered difficult data, which can
produce new difficult problems in large scale, eliminating the need for
complex, per-instance prompting and its associated high API costs. Fine-tuning
Qwen2.5-Math-7B-Instruct on the ScaleDiff-Math dataset yields a substantial
performance increase of 11.3% compared to the original dataset and achieves a
65.9% average accuracy on AIME'24, AIME'25, HMMT-Feb'25, BRUMO'25, and MATH500,
outperforming recent strong LRMs like OpenThinker3. Notably, this performance
is achieved using the cost-efficient Qwen3-8B model as a teacher, demonstrating
that our pipeline can effectively transfer advanced reasoning capabilities
without relying on larger, more expensive teacher models. Furthermore, we
observe a clear scaling phenomenon in model performance on difficult benchmarks
as the quantity of difficult problems increases. Code:
https://github.com/QizhiPei/ScaleDiff.

</details>


### [252] [TyphoonMLA: A Mixed Naive-Absorb MLA Kernel For Shared Prefix](https://arxiv.org/abs/2509.21081)
*Ahmet Caner Yüzügüler,Ahmet Çelik,Jiawei Zhuang,Lukas Cavigelli*

Main category: cs.LG

TL;DR: Multi-Head Latent Attention（MLA）是一种新的注意力机制，已被DeepSeek-v3和Kimi K2等先进的大型语言模型采用。MLA提供两种功能上等价但计算上不同的核实现：朴素（naive）和吸收（absorb）。然而，现有的吸收核实现方式虽然可以减少HBM带宽使用，但计算密集性限制了其数据重用能力。本文提出了一种名为TyphoonMLA的混合方法，结合了朴素和吸收两种方法。TyphoonMLA通过对MLA计算中计算密集的部分应用朴素方法，并对非共享部分使用吸收方法，从而利用了共享前缀，并减少了带宽需求。


<details>
  <summary>Details</summary>
Motivation: 现有的MLA核实现方法（如朴素和吸收）各有优缺点。朴素方法在训练和预填充阶段计算效率高，但吸收方法在解码阶段虽然能减少HBM带宽，但计算密集性限制了数据重用。因此，需要一种结合两者优点的混合方法来提高MLA的性能。

Method: TyphoonMLA是一种混合方法，结合了朴素和吸收两种MLA核实现方式。它对MLA计算中计算密集的部分（如共享前缀）采用朴素方法，以提高计算效率；对非共享部分采用吸收方法，以减少HBM带宽使用。

Result: TyphoonMLA将MLA架构中的注意力计算吞吐量在NPU和GPU上分别提高了3倍和3.24倍，同时HBM大小的开销仅为3%。

Conclusion: TyphoonMLA通过结合朴素和吸收方法的优点，显著提高了MLA架构的注意计算吞吐量，同时对HBM带宽的影响很小，是一种有效的优化方法。

Abstract: Multi-Head Latent Attention (MLA) is a recent attention mechanism adopted in
state-of-the-art LLMs such as DeepSeek-v3 and Kimi K2. Thanks to its novel
formulation, MLA allows two functionally equivalent but computationally
distinct kernel implementations: naive and absorb. While the naive kernels
(e.g., FlashAttention) are typically preferred in training and prefill for
their computational efficiency, existing decoding kernels (e.g., FlashMLA) rely
on the absorb method to minimize HBM bandwidth usage. However, the
compute-bound nature of the absorb implementations prohibits performance
benefits from data reuse opportunities in attention calculations, such as
shared prefixes. In this work, we introduce TyphoonMLA, a hybrid approach that
combines naive and absorb formulations to harness the strengths of both.
TyphoonMLA effectively leverages the shared prefix by applying the naive
formulation to the compute-bound parts of attention calculations, while
reducing the bandwidth requirements for non-shared parts by using the absorb
formulation. As a result, TyphoonMLA improves the throughput of attention
calculations in MLA architectures by up to 3x and 3.24x on NPU and GPUs, with
only a 3% overhead in HBM size.

</details>


### [253] [GraphUniverse: Enabling Systematic Evaluation of Inductive Generalization](https://arxiv.org/abs/2509.21097)
*Louis Van Langendonck,Guillermo Bernárdez,Nina Miolane,Pere Barlet-Ros*

Main category: cs.LG

TL;DR: 该研究提出了GraphUniverse框架，用于生成图数据集家族，以系统评估图学习模型的归纳泛化能力，解决了现有研究仅限于单图、归纳设置的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有图学习研究主要集中在单图、转导设置，缺乏对模型在全新图上泛化能力的系统评估。本研究旨在填补这一空白，提供一个能够评估归纳泛化能力的框架。

Method: 提出GraphUniverse框架，生成具有持久语义社区的图，并允许控制同质性和度分布等结构属性，从而能够进行有意义的鲁棒性测试，例如在受控分布变化下的性能测试。

Result: 通过对多种图学习模型（包括GNN、图变换器和拓扑架构）的基准测试，发现强的转导性能并不能很好地预测归纳泛化能力。此外，模型对分布变化的鲁棒性不仅高度依赖于模型架构选择，还依赖于初始图的模式（例如，高同质性或低同质性）。

Conclusion: GraphUniverse框架为大规模系统化评估图学习模型的归纳泛化能力提供了基础，其灵活性和可扩展性有助于开发更鲁棒、更具泛化能力的图学习模型，包括下一代图基础模型。

Abstract: A fundamental challenge in graph learning is understanding how models
generalize to new, unseen graphs. While synthetic benchmarks offer controlled
settings for analysis, existing approaches are confined to single-graph,
transductive settings where models train and test on the same graph structure.
Addressing this gap, we introduce GraphUniverse, a framework for generating
entire families of graphs to enable the first systematic evaluation of
inductive generalization at scale. Our core innovation is the generation of
graphs with persistent semantic communities, ensuring conceptual consistency
while allowing fine-grained control over structural properties like homophily
and degree distributions. This enables crucial but underexplored robustness
tests, such as performance under controlled distribution shifts. Benchmarking a
wide range of architectures -- from GNNs to graph transformers and topological
architectures -- reveals that strong transductive performance is a poor
predictor of inductive generalization. Furthermore, we find that robustness to
distribution shift is highly sensitive not only to model architecture choice
but also to the initial graph regime (e.g., high vs. low homophily). Beyond
benchmarking, GraphUniverse's flexibility and scalability can facilitate the
development of robust and truly generalizable architectures -- including
next-generation graph foundation models. An interactive demo is available at
https://graphuniverse.streamlit.app.

</details>


### [254] [Teaching RL Agents to Act Better: VLM as Action Advisor for Online Reinforcement Learning](https://arxiv.org/abs/2509.21126)
*Xiefeng Wu,Jing Zhao,Shu Zhang,Mingyu Hu*

Main category: cs.LG

TL;DR: VARL框架利用VLM提供动作建议，以提高在线强化学习的样本效率，尤其是在稀疏奖励任务中。


<details>
  <summary>Details</summary>
Motivation: 在线强化学习在复杂任务中效率低下，需要大量交互步骤来学习最优Q函数。现有的视觉-语言-动作（VLA）策略在低级控制方面性能有限，并且通常需要特定任务的专家演示进行微调。

Method: VARL框架利用视觉-语言模型（VLMs）的领域知识，为强化学习代理提供动作建议，而不是设计启发式奖励，以保证最优性和收敛性。

Result: VARL在各种环境和代理设置下的评估结果表明，该框架在不引入显著计算开销的情况下，大大提高了样本效率。

Conclusion: VARL是一个通用的在线强化学习框架，通过提供动作建议来提高样本效率，使得从头开始的强化学习能够直接应用于真实世界环境。

Abstract: Online reinforcement learning in complex tasks is time-consuming, as massive
interaction steps are needed to learn the optimal Q-function.Vision-language
action (VLA) policies represent a promising direction for solving diverse
tasks; however, their performance on low-level control remains limited, and
effective deployment often requires task-specific expert demonstrations for
fine-tuning. In this paper, we propose \textbf{VARL} (\textbf{V}LM as
\textbf{A}ction advisor for online \textbf{R}einforcement \textbf{L}earning), a
framework that leverages the domain knowledge of vision-language models (VLMs)
to provide action suggestions for reinforcement learning agents. Unlike
previous methods, VARL provides action suggestions rather than designing
heuristic rewards, thereby guaranteeing unchanged optimality and convergence.
The suggested actions increase sample diversity and ultimately improve sample
efficiency, especially in sparse-reward tasks. To validate the effectiveness of
VARL, we evaluate it across diverse environments and agent settings. Results
show that VARL greatly improves sample efficiency without introducing
significant computational overhead. These advantages make VARL a general
framework for online reinforcement learning and make it feasible to directly
apply reinforcement learning from scratch in real-world environments.

</details>


### [255] [EvoMail: Self-Evolving Cognitive Agents for Adaptive Spam and Phishing Email Defense](https://arxiv.org/abs/2509.21129)
*Wei Huang,De-Tian Chu,Lin-Yuan Bai,Wei Kang,Hai-Tao Zhang,Bo Li,Zhi-Mo Han,Jing Ge,Hai-Feng Lin*

Main category: cs.LG

TL;DR: EvoMail是一个结合了LLM和GNN的自进化认知代理框架，能够通过构建异构邮件图谱并进行对抗性自进化来有效检测和防御下一代垃圾邮件和网络钓鱼攻击。


<details>
  <summary>Details</summary>
Motivation: 传统的垃圾邮件检测系统难以应对日益复杂和不断变化的垃圾邮件和网络钓鱼攻击，特别是那些结合了文本、URL、邮件头和附件等多种模态的攻击。

Method: EvoMail首先构建一个统一的异构邮件图谱，融合文本内容、元数据（邮件头、发件人、域名）和嵌入式资源（URL、附件）。然后，一个由大型语言模型（LLM）增强的认知图神经网络（GNN）对这些来源进行上下文感知推理，以识别协同的垃圾邮件活动。最关键的是，EvoMail通过一个“红队”代理生成新的规避策略（例如字符混淆或AI生成的钓鱼文本），而“蓝队”检测器则从失败中学习，将经验压缩到内存模块中，并重用它们进行未来的推理，形成一个对抗性的自进化循环。

Result: 在真实世界的数据集（Enron-Spam、Ling-Spam、SpamAssassin和TREC）以及合成的对抗性变体上的广泛实验表明，EvoMail在检测准确性、对不断变化的垃圾邮件策略的适应性以及推理过程的可解释性方面，始终优于最先进的基线。

Conclusion: EvoMail有潜力成为一种具有韧性且可解释的防御框架，能够有效应对下一代垃圾邮件和网络钓鱼威胁。

Abstract: Modern email spam and phishing attacks have evolved far beyond keyword
blacklists or simple heuristics. Adversaries now craft multi-modal campaigns
that combine natural-language text with obfuscated URLs, forged headers, and
malicious attachments, adapting their strategies within days to bypass filters.
Traditional spam detection systems, which rely on static rules or
single-modality models, struggle to integrate heterogeneous signals or to
continuously adapt, leading to rapid performance degradation.
  We propose EvoMail, a self-evolving cognitive agent framework for robust
detection of spam and phishing. EvoMail first constructs a unified
heterogeneous email graph that fuses textual content, metadata (headers,
senders, domains), and embedded resources (URLs, attachments). A Cognitive
Graph Neural Network enhanced by a Large Language Model (LLM) performs
context-aware reasoning across these sources to identify coordinated spam
campaigns. Most critically, EvoMail engages in an adversarial self-evolution
loop: a ''red-team'' agent generates novel evasion tactics -- such as character
obfuscation or AI-generated phishing text -- while the ''blue-team'' detector
learns from failures, compresses experiences into a memory module, and reuses
them for future reasoning.
  Extensive experiments on real-world datasets (Enron-Spam, Ling-Spam,
SpamAssassin, and TREC) and synthetic adversarial variants demonstrate that
EvoMail consistently outperforms state-of-the-art baselines in detection
accuracy, adaptability to evolving spam tactics, and interpretability of
reasoning traces. These results highlight EvoMail's potential as a resilient
and explainable defense framework against next-generation spam and phishing
threats.

</details>


### [256] [Sparse Representations Improve Adversarial Robustness of Neural Network Classifiers](https://arxiv.org/abs/2509.21130)
*Killian Steunou,Sigurd Saue,Théo Druilhe*

Main category: cs.LG

TL;DR: PCA和SPCA可以作为对抗性攻击的防御方法，SPCA在理论和实验上都表现出更好的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络容易受到对抗性扰动的攻击，需要新的防御方法。

Method: 使用PCA和SPCA作为特征提取器，并进行理论分析和实验验证。

Result: SPCA在对抗性攻击下比PCA具有更好的鲁棒性，同时保持了有竞争力的准确性。理论分析表明，稀疏性可以降低对抗性攻击的影响。

Conclusion: SPCA是一种有效的防御方法，可以在保持模型准确性的同时提高模型的鲁棒性。

Abstract: Deep neural networks perform remarkably well on image classification tasks
but remain vulnerable to carefully crafted adversarial perturbations. This work
revisits linear dimensionality reduction as a simple, data-adapted defense. We
empirically compare standard Principal Component Analysis (PCA) with its sparse
variant (SPCA) as front-end feature extractors for downstream classifiers, and
we complement these experiments with a theoretical analysis. On the theory
side, we derive exact robustness certificates for linear heads applied to SPCA
features: for both $\ell_\infty$ and $\ell_2$ threat models (binary and
multiclass), the certified radius grows as the dual norms of $W^\top u$ shrink,
where $W$ is the projection and $u$ the head weights. We further show that for
general (non-linear) heads, sparsity reduces operator-norm bounds through a
Lipschitz composition argument, predicting lower input sensitivity.
Empirically, with a small non-linear network after the projection, SPCA
consistently degrades more gracefully than PCA under strong white-box and
black-box attacks while maintaining competitive clean accuracy. Taken together,
the theory identifies the mechanism (sparser projections reduce adversarial
leverage) and the experiments verify that this benefit persists beyond the
linear setting. Our code is available at
https://github.com/killian31/SPCARobustness.

</details>


### [257] [LAVA: Explainability for Unsupervised Latent Embeddings](https://arxiv.org/abs/2509.21149)
*Ivan Stresec,Joana P. Gonçalves*

Main category: cs.LG

TL;DR: LAVA是一种无监督、模型无关的后验方法，用于解释局部嵌入组织与其输入特征的关系，通过在潜在空间中识别重复的特征相关模式来揭示。


<details>
  <summary>Details</summary>
Motivation: 现有的无监督模型解释方法要么过于细粒度，要么过于简化，无法有效地揭示输入特征与学习到的潜在空间结构之间的关系，尤其是在没有映射函数的流形学习方法中。

Method: LAVA将潜在空间表示为一系列局部区域，并根据原始特征之间的相关性来描述这些区域。然后，它在整个潜在空间中揭示重复出现的特征相关模式。

Result: 在MNIST和肾脏单细胞数据集的UMAP嵌入上，LAVA能够捕获相关的特征关联，并在看似遥远的潜在空间区域之间显示出视觉上和生物学上相关的局部模式。

Conclusion: LAVA可以有效地解释无监督学习模型的局部嵌入组织，通过识别输入特征和潜在空间结构之间的关系，从而促进科学发现。

Abstract: Unsupervised black-box models can be drivers of scientific discovery, but
remain difficult to interpret. Crucially, discovery hinges on understanding the
model output, which is often a multi-dimensional latent embedding rather than a
well-defined target. While explainability for supervised learning usually seeks
to uncover how input features are used to predict a target, its unsupervised
counterpart should relate input features to the structure of the learned latent
space. Adaptations of supervised model explainability for unsupervised learning
provide either single-sample or dataset-wide summary explanations. However,
without automated strategies of relating similar samples to one another guided
by their latent proximity, explanations remain either too fine-grained or too
reductive to be meaningful. This is especially relevant for manifold learning
methods that produce no mapping function, leaving us only with the relative
spatial organization of their embeddings. We introduce Locality-Aware Variable
Associations (LAVA), a post-hoc model-agnostic method designed to explain local
embedding organization through its relationship with the input features. To
achieve this, LAVA represents the latent space as a series of localities
(neighborhoods) described in terms of correlations between the original
features, and then reveals reoccurring patterns of correlations across the
entire latent space. Based on UMAP embeddings of MNIST and a single-cell kidney
dataset, we show that LAVA captures relevant feature associations, with
visually and biologically relevant local patterns shared among seemingly
distant regions of the latent spaces.

</details>


### [258] [CAD-Tokenizer: Towards Text-based CAD Prototyping via Modality-Specific Tokenization](https://arxiv.org/abs/2509.21150)
*Ruiyu Wang,Shizhao Sun,Weijian Ma,Jiang Bian*

Main category: cs.LG

TL;DR: 现有的文本到CAD生成和编辑方法受限于LLM分词器无法捕捉CAD结构信息。本文提出CAD-Tokenizer，一种利用特定模态分词器（基于序列的VQ-VAE，包含原语级池化和约束解码）来处理CAD数据的方法，生成的表示紧凑且包含原语信息，显著提升了文本引导CAD原型设计的指令遵循和生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到CAD生成和编辑方法受限于LLM分词器无法捕捉CAD结构信息，而CAD模型具有序列化和结构化的特点，这阻碍了LLM在这一领域发挥作用。

Method: 提出CAD-Tokenizer框架，该框架使用基于序列的VQ-VAE，结合原语级池化和约束解码，为CAD数据生成特定模态的、紧凑的、原语感知的表示，以捕捉CAD的结构特性。

Result: 在统一的文本引导CAD原型设计任务中，CAD-Tokenizer在指令遵循和生成质量上显著优于通用LLM和特定任务的基线方法，并在定量和定性评估中均取得了更好的性能。

Conclusion: CAD-Tokenizer通过引入一种与CAD原语和结构对齐的多模态分词策略，有效解决了现有LLM在处理CAD数据时的局限性，为文本引导CAD设计带来了显著的性能提升。

Abstract: Computer-Aided Design (CAD) is a foundational component of industrial
prototyping, where models are defined not by raw coordinates but by
construction sequences such as sketches and extrusions. This sequential
structure enables both efficient prototype initialization and subsequent
editing. Text-guided CAD prototyping, which unifies Text-to-CAD generation and
CAD editing, has the potential to streamline the entire design pipeline.
However, prior work has not explored this setting, largely because standard
large language model (LLM) tokenizers decompose CAD sequences into
natural-language word pieces, failing to capture primitive-level CAD semantics
and hindering attention modules from modeling geometric structure. We
conjecture that a multimodal tokenization strategy, aligned with CAD's
primitive and structural nature, can provide more effective representations. To
this end, we propose CAD-Tokenizer, a framework that represents CAD data with
modality-specific tokens using a sequence-based VQ-VAE with primitive-level
pooling and constrained decoding. This design produces compact, primitive-aware
representations that align with CAD's structural nature. Applied to unified
text-guided CAD prototyping, CAD-Tokenizer significantly improves instruction
following and generation quality, achieving better quantitative and qualitative
performance over both general-purpose LLMs and task-specific baselines.

</details>


### [259] [GRPO is Secretly a Process Reward Model](https://arxiv.org/abs/2509.21154)
*Michael Sullivan*

Main category: cs.LG

TL;DR: GRPO 强化学习算法能生成一个非平凡的奖励模型（PRM），但其目标函数存在缺陷。我们提出了 $\lambda$-GRPO 改进算法，该算法在不显著增加训练成本的情况下提高了 LLM 的性能和收敛速度，并质疑了使用昂贵的显式 PRM 的必要性。


<details>
  <summary>Details</summary>
Motivation: GRPO 强化学习算法在实践中是否能生成一个非平凡的奖励模型（PRM）存在疑问，同时其目标函数可能存在缺陷，影响探索和利用的效率。

Method: 首先，在某些假设下，从理论上证明 GRPO 强化学习算法能够生成一个非平凡的奖励模型（PRM）。然后，通过实际实验验证这些假设在现实条件下是否成立。接着，利用 GRPO-作为-PRM 的框架，识别出 GRPO 目标函数中存在的缺陷——非均匀分布的进程步骤会阻碍探索和利用。最后，提出一种名为 $\lambda$-GRPO 的改进算法，并通过实验证明其优于标准 GRPO。

Result: GRPO 强化学习算法确实能生成一个非平凡的奖励模型（PRM）。GRPO 目标函数中非均匀分布的进程步骤会阻碍探索和利用。$\lambda$-GRPO 改进算法能够提升 LLM 的验证准确率和下游推理任务的性能，并且能更快地达到峰值性能。$\lambda$-GRPO 对训练时间和成本的影响微乎其微。

Conclusion: $\lambda$-GRPO 是一种有效的 GRPO 算法改进，可以在不显著增加训练成本的情况下提高 LLM 的性能。通过利用 GRPO 算法内置的 PRM 结构，可以避免使用昂贵且显式定义的 PRM，从而提高模型性能。

Abstract: We prove theoretically that the GRPO RL algorithm induces a non-trivial
process reward model (PRM), under certain assumptions regarding within-group
overlap of token sequences across completions. We then show empirically that
these assumptions are met under real-world conditions: GRPO does in fact induce
a non-trivial PRM. Leveraging the framework of GRPO-as-a-PRM, we identify a
flaw in the GRPO objective: non-uniformly distributed process steps hinder both
exploration and exploitation (under different conditions). We propose a simple
modification to the algorithm to mitigate this defect ($\lambda$-GRPO), and
show that LLMs trained with $\lambda$-GRPO achieve higher validation accuracy
and performance on downstream reasoning tasks$-$and reach peak performance more
rapidly$-$than LLMs trained with standard GRPO. Our results call into question
the advantage of costly, explicitly-defined PRMs for GRPO: we show that it is
possible to instead leverage the hidden, built-in PRM structure within the
vanilla GRPO algorithm to boost model performance with a negligible impact on
training time and cost.

</details>


### [260] [DATS: Distance-Aware Temperature Scaling for Calibrated Class-Incremental Learning](https://arxiv.org/abs/2509.21161)
*Giuseppe Serra,Florian Buettner*

Main category: cs.LG

TL;DR: 通过距离感知温度缩放(DATS)在没有先验任务信息的情况下，在持续学习中提高模型的不确定性校准能力。


<details>
  <summary>Details</summary>
Motivation: 现有的持续学习（CL）方法在校准不确定性方面存在不足，尤其是在安全关键应用中，并且它们通常依赖于单一的、跨任务共享的温度，这忽略了任务特定的差异，导致跨任务的校准误差波动很大。

Method: 提出了一种名为距离感知温度缩放（DATS）的方法，该方法结合了基于原型的距离估计和距离感知的校准，以推断任务接近度并在没有先验任务信息的情况下分配自适应温度。

Result: 通过在标准基准和来自生物医学领域的真实世界、不平衡数据集上的广泛实证评估，DATS 被证明在减少跨任务的校准误差方面比最先进的方法更稳定、更可靠、更一致。

Conclusion: DATS 能够有效解决持续学习中的不确定性校准问题，即使在没有先验任务信息的情况下也能实现自适应温度调整，并在各种数据集上表现出优越的性能。

Abstract: Continual Learning (CL) is recently gaining increasing attention for its
ability to enable a single model to learn incrementally from a sequence of new
classes. In this scenario, it is important to keep consistent predictive
performance across all the classes and prevent the so-called Catastrophic
Forgetting (CF). However, in safety-critical applications, predictive
performance alone is insufficient. Predictive models should also be able to
reliably communicate their uncertainty in a calibrated manner - that is, with
confidence scores aligned to the true frequencies of target events. Existing
approaches in CL address calibration primarily from a data-centric perspective,
relying on a single temperature shared across all tasks. Such solutions
overlook task-specific differences, leading to large fluctuations in
calibration error across tasks. For this reason, we argue that a more
principled approach should adapt the temperature according to the distance to
the current task. However, the unavailability of the task information at test
time/during deployment poses a major challenge to achieve the intended
objective. For this, we propose Distance-Aware Temperature Scaling (DATS),
which combines prototype-based distance estimation with distance-aware
calibration to infer task proximity and assign adaptive temperatures without
prior task information. Through extensive empirical evaluation on both standard
benchmarks and real-world, imbalanced datasets taken from the biomedical
domain, our approach demonstrates to be stable, reliable and consistent in
reducing calibration error across tasks compared to state-of-the-art
approaches.

</details>


### [261] [Mixture of Thoughts: Learning to Aggregate What Experts Think, Not Just What They Say](https://arxiv.org/abs/2509.21164)
*Jacob Fein-Ashley,Dhruv Parikh,Rajgopal Kannan,Viktor Prasanna*

Main category: cs.LG

TL;DR: MoT是一个新方法，通过在共享的潜在空间中进行交叉注意力，实现不同LLM专家之间的协作，从而超越了现有的多LLM方法。


<details>
  <summary>Details</summary>
Motivation: 现有的多LLM方法存在局限性，例如需要昂贵的交互或模型同质性。

Method: MoT使用一个轻量级的路由器来选择K个专家，并让主专家在共享潜在空间中与其他专家进行交叉注意力。仅训练路由器和交互层。

Result: MoT在多个基准测试中超越了现有的基于路由和聚合的方法，并且优于单一模型，同时具有单次推理和可比的运行时开销。

Conclusion: MoT提供了一种在潜在空间中结合异构LLM的简单机制，是迈向更广泛多LLM协作的重要一步。

Abstract: Open-source Large Language Models (LLMs) increasingly specialize by domain
(e.g., math, code, general reasoning), motivating systems that leverage
complementary strengths across models. Prior multi-LLM approaches either (i)
route a query to one or a few experts and generate independently, (ii)
aggregate outputs from each model via costly multi-turn exchanges, or (iii)
fuse weights into a single model-typically requiring architectural homogeneity.
We introduce Mixture of Thoughts (MoT), a simple method for latent-level
collaboration among heterogeneous experts under a global routing scheme. For
each query, a lightweight router selects top-$K$ experts and designates a
primary expert; uniformly placed interaction layers project hidden states into
a shared latent space where the primary expert performs cross-attention over
its active (selected) peers. Pre-trained experts remain frozen; only the router
and the lightweight interaction layers are trained with a novel joint training
objective that improves both the expert selection and inter-expert
collaboration. Across five in-distribution (ID) and three out-of-distribution
(OOD) benchmarks, MoT surpasses the current routing and aggregation-based
state-of-the-art, Avengers, by $+0.38\%$ and $+2.92\%$, respectively. Further,
MoT significantly outperforms the best-performing single model. It achieves
this with single-pass inference, runtime comparable to routing baselines, and
none of the overheads of iterative aggregation. MoT offers a simple
latent-space mechanism for combining heterogeneous LLMs, a practical step
toward broader multi-LLM collaboration. Our code is publicly available at
https://github.com/jacobfa/mot.

</details>


### [262] [A Unified Framework for Diffusion Model Unlearning with f-Divergence](https://arxiv.org/abs/2509.21167)
*Nicola Novello,Federico Fontana,Luigi Cinque,Deniz Gunduz,Andrea M. Tonello*

Main category: cs.LG

TL;DR: 该研究提出了一种基于 f 散度框架的统一机器学习遗忘方法，用于文本到图像模型，解决了现有基于均方误差的方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像模型遗忘方法主要基于最小化均方误差，但该方法有局限性。本研究旨在提出一个更通用的框架来解决这个问题。

Method: 提出一个统一的 f 散度框架，并将现有的基于均方误差的方法视为该框架的特例。分析了不同 f 散度对算法收敛性和遗忘质量的影响。

Result: f 散度框架提供了比仅使用均方误差更灵活的遗忘方法。不同的 f 散度在遗忘的强度和概念保持之间提供了不同的权衡。

Conclusion: f 散度框架为机器学习遗忘提供了一个灵活的通用范式，允许根据具体应用选择最优的散度，从而在遗忘的强度和概念的保持之间取得平衡。

Abstract: Machine unlearning aims to remove specific knowledge from a trained model.
While diffusion models (DMs) have shown remarkable generative capabilities,
existing unlearning methods for text-to-image (T2I) models often rely on
minimizing the mean squared error (MSE) between the output distribution of a
target and an anchor concept. We show that this MSE-based approach is a special
case of a unified $f$-divergence-based framework, in which any $f$-divergence
can be utilized. We analyze the benefits of using different $f$-divergences,
that mainly impact the convergence properties of the algorithm and the quality
of unlearning. The proposed unified framework offers a flexible paradigm that
allows to select the optimal divergence for a specific application, balancing
different trade-offs between aggressive unlearning and concept preservation.

</details>


### [263] [Inverse Reinforcement Learning Using Just Classification and a Few Regressions](https://arxiv.org/abs/2509.21172)
*Lars van der Laan,Nathan Kallus,Aurélien Bibaut*

Main category: cs.LG

TL;DR: 最大熵逆强化学习（IRL）可以通过解决两个标准的监督学习问题来简化，从而能够使用现代函数逼近器。


<details>
  <summary>Details</summary>
Motivation: 现有的最大熵IRL算法通常涉及复杂的优化过程，难以与现代函数逼近器（如神经网络）结合使用。

Method: 将IRL问题转化为两个独立的监督学习问题：一个用于估计行为策略的概率分类问题，一个用于求解固定点方程的迭代回归问题。

Result: 提出了一种简单、模块化的IRL方法，该方法在函数逼近和算法选择上具有灵活性，并且在经验结果中表现出与MaxEnt IRL相当或更优的性能。

Conclusion: 通过将IRL归结为两个标准的监督学习问题，可以克服现有方法的局限性，并实现更简单、更灵活和高效的IRL解决方案。

Abstract: Inverse reinforcement learning (IRL) aims to explain observed behavior by
uncovering an underlying reward. In the maximum-entropy or
Gumbel-shocks-to-reward frameworks, this amounts to fitting a reward function
and a soft value function that together satisfy the soft Bellman consistency
condition and maximize the likelihood of observed actions. While this
perspective has had enormous impact in imitation learning for robotics and
understanding dynamic choices in economics, practical learning algorithms often
involve delicate inner-loop optimization, repeated dynamic programming, or
adversarial training, all of which complicate the use of modern, highly
expressive function approximators like neural nets and boosting. We revisit
softmax IRL and show that the population maximum-likelihood solution is
characterized by a linear fixed-point equation involving the behavior policy.
This observation reduces IRL to two off-the-shelf supervised learning problems:
probabilistic classification to estimate the behavior policy, and iterative
regression to solve the fixed point. The resulting method is simple and modular
across function approximation classes and algorithms. We provide a precise
characterization of the optimal solution, a generic oracle-based algorithm,
finite-sample error bounds, and empirical results showing competitive or
superior performance to MaxEnt IRL.

</details>


### [264] [Closed-form $\ell_r$ norm scaling with data for overparameterized linear regression and diagonal linear networks under $\ell_p$ bias](https://arxiv.org/abs/2509.21181)
*Shuofeng Zhang,Ard Louis*

Main category: cs.LG

TL;DR: 该论文统一表征了过参数线性回归中最小Lp插值器的参数范数族与样本量的关系，揭示了信号“尖峰”与零坐标“块”之间的竞争，并预测了数据依赖的拐点和分离范数是否增长的通用阈值。


<details>
  <summary>Details</summary>
Motivation: 解决过参数线性回归中最小Lp插值器参数范数族（l_r, r in [1,p]）的样本量缩放问题。

Method: 使用双射线分析。

Result: （i）预测了数据依赖的拐点n*；（ii）预测了通用阈值r*=2(p-1)，该阈值分离了会平稳和会随样本量增长的范数。该方法统一解决了l_p偏差插值下所有l_r范数（r in [1,p]）的缩放问题。

Conclusion: 该研究为理解过参数线性回归中的范数缩放提供了统一的视角，并指出泛化代理的预测能力对所选l_r范数敏感。此外，该研究还表明对角线性网络（DLNs）的行为与此现象一致，并提出了连接显式和隐式偏差的预测方法。

Abstract: For overparameterized linear regression with isotropic Gaussian design and
minimum-$\ell_p$ interpolator $p\in(1,2]$, we give a unified, high-probability
characterization for the scaling of the family of parameter norms $ \\{ \lVert
\widehat{w_p} \rVert_r \\}_{r \in [1,p]} $ with sample size.
  We solve this basic, but unresolved question through a simple dual-ray
analysis, which reveals a competition between a signal *spike* and a *bulk* of
null coordinates in $X^\top Y$, yielding closed-form predictions for (i) a
data-dependent transition $n_\star$ (the "elbow"), and (ii) a universal
threshold $r_\star=2(p-1)$ that separates $\lVert \widehat{w_p} \rVert_r$'s
which plateau from those that continue to grow with an explicit exponent.
  This unified solution resolves the scaling of *all* $\ell_r$ norms within the
family $r\in [1,p]$ under $\ell_p$-biased interpolation, and explains in one
picture which norms saturate and which increase as $n$ grows.
  We then study diagonal linear networks (DLNs) trained by gradient descent. By
calibrating the initialization scale $\alpha$ to an effective
$p_{\mathrm{eff}}(\alpha)$ via the DLN separable potential, we show empirically
that DLNs inherit the same elbow/threshold laws, providing a predictive bridge
between explicit and implicit bias.
  Given that many generalization proxies depend on $\lVert \widehat {w_p}
\rVert_r$, our results suggest that their predictive power will depend
sensitively on which $l_r$ norm is used.

</details>


### [265] [Towards Foundation Models for Zero-Shot Time Series Anomaly Detection: Leveraging Synthetic Data and Relative Context Discrepancy](https://arxiv.org/abs/2509.21190)
*Tian Lan,Hao Duong Le,Jinbo Li,Wenjun He,Meng Wang,Chenghao Liu,Chen Zhang*

Main category: cs.LG

TL;DR: TimeRCD是一个基于相对上下文差异（RCD）的新颖时间序列异常检测（TSAD）基础模型，通过检测相邻时间窗口之间的差异来识别异常，克服了传统基于重建的模型在处理细微异常和复杂正常模式时的局限性，并在零样本TSAD任务上取得了优于现有模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的时间序列异常检测（TSAD）基础模型大多依赖于重建目标，但这会导致模型难以识别细微异常，并且容易将复杂的正常模式误判为异常，从而产生高比例的漏报和误报。然而，在零样本场景下，开发能够泛化到未见数据的模型仍然是一个重大挑战。

Method: TimeRCD模型采用了一种新的预训练范式——相对上下文差异（RCD）。该模型不学习重建输入，而是通过检测相邻时间窗口之间的显著差异来明确地训练模型识别异常。这种关系方法使用标准的Transformer架构实现，能够捕捉到重建方法通常会遗漏的、指示异常的上下文变化。为了支持这种范式，研究者开发了一个大规模、多样化的合成语料库，并带有令牌级别的异常标签，为有效的预训练提供了必要的监督信号。

Result: 大量实验表明，TimeRCD在各种数据集的零样本TSAD任务上，显著优于现有的通用和特定异常检测的基础模型。

Conclusion: 实验结果验证了RCD范式的优越性，并为构建健壮且可泛化的时间序列异常检测基础模型提供了一条新的有效途径。

Abstract: Time series anomaly detection (TSAD) is a critical task, but developing
models that generalize to unseen data in a zero-shot manner remains a major
challenge. Prevailing foundation models for TSAD predominantly rely on
reconstruction-based objectives, which suffer from a fundamental objective
mismatch: they struggle to identify subtle anomalies while often
misinterpreting complex normal patterns, leading to high rates of false
negatives and positives. To overcome these limitations, we introduce
\texttt{TimeRCD}, a novel foundation model for TSAD built upon a new
pre-training paradigm: Relative Context Discrepancy (RCD). Instead of learning
to reconstruct inputs, \texttt{TimeRCD} is explicitly trained to identify
anomalies by detecting significant discrepancies between adjacent time windows.
This relational approach, implemented with a standard Transformer architecture,
enables the model to capture contextual shifts indicative of anomalies that
reconstruction-based methods often miss. To facilitate this paradigm, we
develop a large-scale, diverse synthetic corpus with token-level anomaly
labels, providing the rich supervisory signal necessary for effective
pre-training. Extensive experiments demonstrate that \texttt{TimeRCD}
significantly outperforms existing general-purpose and anomaly-specific
foundation models in zero-shot TSAD across diverse datasets. Our results
validate the superiority of the RCD paradigm and establish a new, effective
path toward building robust and generalizable foundation models for time series
anomaly detection.

</details>


### [266] [Differential-Integral Neural Operator for Long-Term Turbulence Forecasting](https://arxiv.org/abs/2509.21196)
*Hao Wu,Yuan Gao,Fan Xu,Fan Zhang,Qingsong Wen,Kun Wang,Xiaomeng Huang,Xian Wu*

Main category: cs.LG

TL;DR: 为了解决现有深度学习方法在长期预测中误差累积和物理保真度下降的问题，我们提出了DIÑO（微分-积分神经网络算子）。DIÑO通过并行分支显式地模拟湍流演化，一个分支学习局部微分算子（通过约束卷积网络），另一个分支学习全局积分算子（通过Transformer架构）。实验表明，DIÑO在长期预测方面显著优于现有模型，有效抑制了误差累积，并保持了物理保真度。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法，特别是神经算子，在长期自回归预测中存在灾难性的误差累积和物理保真度下降问题，因为它们无法同时捕捉控制湍流动力学的局部耗散效应和全局非局部相互作用这两种不同的数学结构。

Method: 提出了一种新颖的框架DIÑO（微分-积分神经网络算子），该框架基于算子分解的第一性原理。DIÑO通过并行分支显式地模拟湍流演化：一个分支使用约束卷积网络学习局部微分算子，另一个分支使用Transformer架构学习全局积分算子。

Result: 在具有挑战性的二维Kolmogorov流动基准测试中，DIÑO显著优于最先进的模型，在数百个时间步内成功抑制了误差累积，在高保真度下保持了涡度场和能量谱，并为物理上一致的远程湍流预测树立了新的基准。

Conclusion: DIÑO通过物理启发的算子分解，能够同时捕捉湍流演化的局部和全局特征，从而在长期预测任务中表现出卓越的稳定性和鲁棒性，克服了现有方法的局限性。

Abstract: Accurately forecasting the long-term evolution of turbulence represents a
grand challenge in scientific computing and is crucial for applications ranging
from climate modeling to aerospace engineering. Existing deep learning methods,
particularly neural operators, often fail in long-term autoregressive
predictions, suffering from catastrophic error accumulation and a loss of
physical fidelity. This failure stems from their inability to simultaneously
capture the distinct mathematical structures that govern turbulent dynamics:
local, dissipative effects and global, non-local interactions. In this paper,
we propose the
{\textbf{\underline{D}}}ifferential-{\textbf{\underline{I}}}ntegral
{\textbf{\underline{N}}}eural {\textbf{\underline{O}}}perator (\method{}), a
novel framework designed from a first-principles approach of operator
decomposition. \method{} explicitly models the turbulent evolution through
parallel branches that learn distinct physical operators: a local differential
operator, realized by a constrained convolutional network that provably
converges to a derivative, and a global integral operator, captured by a
Transformer architecture that learns a data-driven global kernel. This
physics-based decomposition endows \method{} with exceptional stability and
robustness. Through extensive experiments on the challenging 2D Kolmogorov flow
benchmark, we demonstrate that \method{} significantly outperforms
state-of-the-art models in long-term forecasting. It successfully suppresses
error accumulation over hundreds of timesteps, maintains high fidelity in both
the vorticity fields and energy spectra, and establishes a new benchmark for
physically consistent, long-range turbulence forecast.

</details>


### [267] [From Physics to Machine Learning and Back: Part II - Learning and Observational Bias in PHM](https://arxiv.org/abs/2509.21207)
*Olga Fink,Ismail Nejjar,Vinay Sharma,Keivan Faghih Niresi,Han Sun,Hao Dong,Chenghao Xu,Amaury Wei,Arthur Bizzi,Raffael Theiler,Yuan Tian,Leandro Von Krannichfeldt,Zhan Ma,Sergei Garmaev,Zepeng Zhang,Mengjie Zhao*

Main category: cs.LG

TL;DR: PHM通过物理信息机器学习解决传感器数据不完整、标签有限和系统复杂性等现实挑战，通过学习偏差和观测偏差实现物理上一致且可靠的预测。它还通过强化学习实现从被动预测到主动决策的转变，并讨论了从单个资产扩展到整个机队的部署策略。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的PHM面临传感器数据噪声大、不完整、标签有限以及退化行为和系统相互依赖性复杂且非线性等挑战。

Method: 检查如何通过物理信息建模和数据策略（包括学习偏差和观测偏差）来解决这些限制。学习偏差通过物理信息损失函数和控制方程或结合单调性等属性将物理约束嵌入模型训练中。观测偏差通过虚拟传感、基于物理的仿真和多传感器融合策略来影响数据选择和合成。还探讨了如何将这些方法与强化学习相结合，以实现从被动预测到主动决策的转变，并审查了元学习、少样本学习和域泛化技术等快速适应方法，以实现车队范围的部署。

Result: 物理信息机器学习能够实现对物理上一致且可靠的预测。强化学习能够学习尊重物理约束并优化操作目标的维护策略。快速适应和域泛化技术有助于实现PHM解决方案从单个资产到整个机队的扩展部署。

Conclusion: 物理信息机器学习和强化学习的结合能够实现对物理上一致且可靠的预测，并能主动地进行决策，从而实现从模型预测、仿真到实际系统操作的闭环，实现自适应的决策。此外，元学习、少样本学习和域泛化等技术为PHM解决方案从单个资产到整个机队的扩展部署提供了途径。

Abstract: Prognostics and Health Management ensures the reliability, safety, and
efficiency of complex engineered systems by enabling fault detection,
anticipating equipment failures, and optimizing maintenance activities
throughout an asset lifecycle. However, real-world PHM presents persistent
challenges: sensor data is often noisy or incomplete, available labels are
limited, and degradation behaviors and system interdependencies can be highly
complex and nonlinear. Physics-informed machine learning has emerged as a
promising approach to address these limitations by embedding physical knowledge
into data-driven models. This review examines how incorporating learning and
observational biases through physics-informed modeling and data strategies can
guide models toward physically consistent and reliable predictions. Learning
biases embed physical constraints into model training through physics-informed
loss functions and governing equations, or by incorporating properties like
monotonicity. Observational biases influence data selection and synthesis to
ensure models capture realistic system behavior through virtual sensing for
estimating unmeasured states, physics-based simulation for data augmentation,
and multi-sensor fusion strategies. The review then examines how these
approaches enable the transition from passive prediction to active
decision-making through reinforcement learning, which allows agents to learn
maintenance policies that respect physical constraints while optimizing
operational objectives. This closes the loop between model-based predictions,
simulation, and actual system operation, empowering adaptive decision-making.
Finally, the review addresses the critical challenge of scaling PHM solutions
from individual assets to fleet-wide deployment. Fast adaptation methods
including meta-learning and few-shot learning are reviewed alongside domain
generalization techniques ...

</details>


### [268] [Tree Search for LLM Agent Reinforcement Learning](https://arxiv.org/abs/2509.21240)
*Yuxiang Ji,Ziyu Ma,Yong Wang,Guanhua Chen,Xiangxiang Chu,Liaoni Wu*

Main category: cs.LG

TL;DR: Tree-GRPO是一种基于树搜索的分组强化学习方法，通过共享前缀的树搜索采样增加数据效率，并利用树结构轨迹构建逐步监督信号，优于基于链的强化学习方法。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在长期和多轮智能体任务中面临稀疏监督问题，仅依赖结果奖励难以有效训练。

Method: 提出Tree-GRPO方法，采用树搜索，节点代表完整的智能体交互步骤，通过共享前缀增加采样效率。同时，利用树结构轨迹构建逐步监督信号，并估计树内和树间的分组相对优势。

Result: 实验表明，Tree-GRPO在11个数据集和3类问答任务上优于基于链的强化学习方法。

Conclusion: Tree-GRPO通过引入树搜索和逐步监督信号，有效解决了长期和多轮智能体任务中的稀疏监督问题，提升了强化学习的性能。

Abstract: Recent advances in reinforcement learning (RL) have significantly enhanced
the agentic capabilities of large language models (LLMs). In long-term and
multi-turn agent tasks, existing approaches driven solely by outcome rewards
often suffer from the problem of sparse supervision. To address the challenge,
we propose Tree-based Group Relative Policy Optimization (Tree-GRPO), a grouped
agent RL method based on tree search, where each tree node represents the
complete agent interaction step. By sharing common prefixes, the tree search
sampling increases the number of rollouts achievable within a fixed budget of
tokens or tool calls. Moreover, we find that the tree-structured trajectory
naturally allows the construction of step-wise process supervised signals even
using only the outcome reward. Based on this, Tree-GRPO estimates the grouped
relative advantages both on intra-tree and inter-tree levels. Through
theoretical analysis, we demonstrate that the objective of intra-tree level
group relative policy optimization is equivalent to that of step-level direct
preference learning. Experiments across 11 datasets and 3 types of QA tasks
demonstrate the superiority of the proposed tree-based RL over the chain-based
RL method.

</details>


### [269] [Explaining Fine Tuned LLMs via Counterfactuals A Knowledge Graph Driven Framework](https://arxiv.org/abs/2509.21241)
*Yucheng Wang,Ziyang Chen,Md Faisal Kabir*

Main category: cs.LG

TL;DR: LoRA 微调 LLM 后，使用基于知识图谱的干预方法来解释模型行为。


<details>
  <summary>Details</summary>
Motivation: 理解 LoRA 微调如何改变 LLM 的结构推理和语义行为仍然是一个挑战。

Method: 提出一个新框架，利用知识图谱中的反事实来解释微调后的 LLM。具体来说，构建了一个生物信息学工具的知识图谱 BioToolKG，并设计了一个名为 CFFTLLMExplainer 的解释器，该解释器学习图中节点和边的软掩码，以生成最小的结构扰动来引起最大的语义差异。该方法同时优化结构稀疏性和语义差异，并强制执行可解释性约束，如熵正则化和边平滑。

Result: 将该框架应用于微调后的 LLaMA 模型，发现反事实掩码暴露了模型的结构依赖性，并与 LoRA 引起的参数变化一致。

Conclusion: 这项工作深入了解了微调后 LLM 的内部机制，并强调了反事实图谱作为可解释人工智能的潜在工具。

Abstract: The widespread adoption of Low-Rank Adaptation (LoRA) has enabled large
language models (LLMs) to acquire domain-specific knowledge with remarkable
efficiency. However, understanding how such a fine-tuning mechanism alters a
model's structural reasoning and semantic behavior remains an open challenge.
This work introduces a novel framework that explains fine-tuned LLMs via
counterfactuals grounded in knowledge graphs. Specifically, we construct
BioToolKG, a domain-specific heterogeneous knowledge graph in bioinformatics
tools and design a counterfactual-based fine-tuned LLMs explainer
(CFFTLLMExplainer) that learns soft masks over graph nodes and edges to
generate minimal structural perturbations that induce maximum semantic
divergence. Our method jointly optimizes structural sparsity and semantic
divergence while enforcing interpretability preserving constraints such as
entropy regularization and edge smoothness. We apply this framework to a
fine-tuned LLaMA-based LLM and reveal that counterfactual masking exposes the
model's structural dependencies and aligns with LoRA-induced parameter shifts.
This work provides new insights into the internal mechanisms of fine-tuned LLMs
and highlights counterfactual graphs as a potential tool for interpretable AI.

</details>


### [270] [Federated Flow Matching](https://arxiv.org/abs/2509.21250)
*Zifan Wang,Anqi Dong,Mahmoud Selim,Michael M. Zavlanos,Karl H. Johansson*

Main category: cs.LG

TL;DR: 本篇论文提出了一种名为Federated Flow Matching (FFM)的框架，用于在隐私保护的分布式环境下训练生成模型。该框架通过改进局部最优传输和引入全局势函数，解决了数据异质性导致的全局不一致问题，最终在保持隐私的同时，提升了模型样本质量和推理速度，性能可与中心化方法媲美。


<details>
  <summary>Details</summary>
Motivation: 由于当前数据日益中心化，隐私、所有权和监管限制了数据的集中化，因此需要直接在本地的分布式数据上训练生成模型，而无需进行中心化聚合。

Method: 本文介绍了Federated Flow Matching (FFM)框架，该框架包含FFM-vanilla（本地训练，独立耦合）、FFM-LOT（利用局部最优传输耦合）和FFM-GOT（基于最优传输的半对偶形式，使用全局势函数协调耦合）。

Result: 实验表明，FFM能够在保护隐私的前提下，提升联邦设置中的流的直度和样本质量，其性能与中心化基线相当。

Conclusion: FFM框架能够实现隐私保护的联邦训练，并且在流的直度和样本质量方面均有提升，在联邦设置下表现出与中心化基线相当的性能。

Abstract: Data today is decentralized, generated and stored across devices and
institutions where privacy, ownership, and regulation prevent centralization.
This motivates the need to train generative models directly from distributed
data locally without central aggregation. In this paper, we introduce Federated
Flow Matching (FFM), a framework for training flow matching models under
privacy constraints. Specifically, we first examine FFM-vanilla, where each
client trains locally with independent source and target couplings, preserving
privacy but yielding curved flows that slow inference. We then develop FFM-LOT,
which employs local optimal transport couplings to improve straightness within
each client but lacks global consistency under heterogeneous data. Finally, we
propose FFM-GOT, a federated strategy based on the semi-dual formulation of
optimal transport, where a shared global potential function coordinates
couplings across clients. Experiments on synthetic and image datasets show that
FFM enables privacy-preserving training while enhancing both the flow
straightness and sample quality in federated settings, with performance
comparable to the centralized baseline.

</details>


### [271] [humancompatible.train: Implementing Optimization Algorithms for Stochastically-Constrained Stochastic Optimization Problems](https://arxiv.org/abs/2509.21254)
*Andrii Kliachkin,Jana Lepšová,Gilles Bareilles,Jakub Mareček*

Main category: cs.LG

TL;DR: 该论文提出了一个名为 humancompatible.train 的 PyTorch 包，用于训练具有随机约束的深度神经网络（DNN），并实现了多个先前未实现过的算法。


<details>
  <summary>Details</summary>
Motivation: 近期，在公平性和安全性等应用中，对深度神经网络（DNN）的约束训练引起了相当大的兴趣，但目前还没有行业标准。

Method: 实现了一个名为 humancompatible.train 的 PyTorch 包，这是一个易于扩展的 Python 包，用于训练具有随机约束的 DNN，并实现了多个先前未实现过的算法。

Result: 通过在具有公平性约束的深度学习任务中比较两种算法，展示了该工具包的用途。

Conclusion: 该论文提出了一个用于训练具有随机约束的 DNN 的新工具包，并展示了其在公平性约束方面的应用。

Abstract: There has been a considerable interest in constrained training of deep neural
networks (DNNs) recently for applications such as fairness and safety. Several
toolkits have been proposed for this task, yet there is still no industry
standard. We present humancompatible.train
(https://github.com/humancompatible/train), an easily-extendable PyTorch-based
Python package for training DNNs with stochastic constraints. We implement
multiple previously unimplemented algorithms for stochastically constrained
stochastic optimization. We demonstrate the toolkit use by comparing two
algorithms on a deep learning task with fairness constraints.

</details>


### [272] [A Causality-Aware Spatiotemporal Model for Multi-Region and Multi-Pollutant Air Quality Forecasting](https://arxiv.org/abs/2509.21260)
*Junxin Lu,Shiliang Sun*

Main category: cs.LG

TL;DR: AirPCM是一个创新的深度时空预测模型，用于解决空气污染预测的挑战，能够处理多污染物、多区域动态和气象因素，并实现高精度的跨区域、跨时间尺度的预测。


<details>
  <summary>Details</summary>
Motivation: 空气污染是一个严峻的全球性问题，对公众健康、环境可持续性和气候稳定构成威胁。现有的空气污染预测方法在处理复杂的跨区域、多污染物相互作用、不断变化的气象条件以及区域特异性空间异质性方面存在挑战，难以实现精确和可扩展的预测。

Method: 提出AirPCM模型，一个新颖的深度时空预测模型。该模型整合了多区域、多污染物动态以及明确的气象-污染物因果关系建模。其统一的架构能够联合捕捉跨站点空间相关性、时间自相关性以及气象-污染物动态因果关系。

Result: 通过在多尺度真实世界数据集上进行的大量评估，AirPCM在预测准确性和泛化能力方面持续优于最先进的基线模型。此外，该模型能够进行长期预测，为未来的空气质量趋势和潜在的高风险窗口提供可操作的见解，从而为基于证据的环境治理和碳减排规划提供及时支持。

Conclusion: AirPCM通过整合多区域、多污染物动态和气象-污染物因果关系，实现了精细化、可解释的多污染物预测，能够有效应对突发污染事件，并在预测准确性和泛化能力方面超越现有方法，为环境治理和碳减排规划提供支持。

Abstract: Air pollution, a pressing global problem, threatens public health,
environmental sustainability, and climate stability. Achieving accurate and
scalable forecasting across spatially distributed monitoring stations is
challenging due to intricate multi-pollutant interactions, evolving
meteorological conditions, and region specific spatial heterogeneity. To
address this challenge, we propose AirPCM, a novel deep spatiotemporal
forecasting model that integrates multi-region, multi-pollutant dynamics with
explicit meteorology-pollutant causality modeling. Unlike existing methods
limited to single pollutants or localized regions, AirPCM employs a unified
architecture to jointly capture cross-station spatial correlations, temporal
auto-correlations, and meteorology-pollutant dynamic causality. This empowers
fine-grained, interpretable multi-pollutant forecasting across varying
geographic and temporal scales, including sudden pollution episodes. Extensive
evaluations on multi-scale real-world datasets demonstrate that AirPCM
consistently surpasses state-of-the-art baselines in both predictive accuracy
and generalization capability. Moreover, the long-term forecasting capability
of AirPCM provides actionable insights into future air quality trends and
potential high-risk windows, offering timely support for evidence-based
environmental governance and carbon mitigation planning.

</details>


### [273] [It's Not You, It's Clipping: A Soft Trust-Region via Probability Smoothing for LLM RL](https://arxiv.org/abs/2509.21282)
*Madeleine Dwyer,Adam Sobey,Adriane Chapman*

Main category: cs.LG

TL;DR: PSPO通过向旧策略平滑当前策略的概率来稳定LLM的RL更新，提高了性能和响应质量。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM RL方法（如PPO、GRPO）依赖于概率比率裁剪来稳定更新，但这会丢弃信息并产生梯度不连续性。

Method: 提出了一种名为概率平滑策略优化（PSPO）的新方法，该方法在计算重要性比率之前，将当前策略的概率平滑到旧（行为）策略，类似于标签平滑。

Result: 在GSM8K、SVAMP、ASDiv和MATH-500数据集上，GR-PSPO相比裁剪的GRPO显著提高了性能（GSM8K上的提升超过20%），并且与未裁剪的GRPO相比，生成的响应更清晰、更简洁、逻辑性更强。

Conclusion: PSPO是一种比率裁剪的有效替代方案，可以稳定LLM的RL更新，同时保留梯度信号并提高响应质量。

Abstract: Training large language models (LLMs) with reinforcement learning (RL)
methods such as PPO and GRPO commonly relies on ratio clipping to stabilise
updates. While effective at preventing instability, clipping discards
information and introduces gradient discontinuities. We propose Probability
Smoothing Policy Optimisation (PSPO), which smooths the current policy's
probabilities toward the old (behaviour) policy before computing the importance
ratio, analogous to label smoothing. Unlike clipping, PSPO preserves gradient
signal, while interpolation toward the old policy creates a soft trust region
that discourages large, destabilising updates, with formal guarantees.
  We instantiate PSPO within GRPO (GR-PSPO) and fine-tune Qwen2.5-0.5B and
Qwen2.5-1.5B on GSM8K, evaluating on GSM8K test and the cross-dataset
generalisation on SVAMP, ASDiv, and MATH-500. Relative to unclipped GRPO
(single iteration; no data reuse, ratio always = 1), GR-PSPO achieves similar
performance but improves the reasoning leading to clearer and more concise
responses which are more logical. Compared to clipped GRPO, GR-PSPO
substantially improves performance both the 0.5B and 1.5B models, with a boost
of over 20% on GSM8K (39.7% vs. 17.6% for 0.5B, 59.4% vs. 37.8% for 1.5B).

</details>


### [274] [Optimal Robust Recourse with $L^p$-Bounded Model Change](https://arxiv.org/abs/2509.21293)
*Phone Kyaw,Kshitij Kayastha,Shahin Jabbari*

Main category: cs.LG

TL;DR: 该研究提出了一种新的算法，用于在模型更新时计算最优且具有成本效益的“追索”建议，以帮助个人获得期望的决策结果。


<details>
  <summary>Details</summary>
Motivation: 现有模型更新时，之前的追索建议可能失效，而现有鲁棒追索算法无法保证最优解，且可能导致高昂的追索成本。

Method: 提出了一种新的算法，该算法在 $L^p$ 范数（p>=1, p!=∞）下，能够为广义线性模型计算最优鲁棒追索。通过经验分析，证明了该算法在低追索成本、有效性、稀疏性以及对后处理的鲁棒性方面优于现有方法。

Result: 与现有方法相比，新算法在经验上显著降低了追索成本（最高可达几个数量级），并在实施成本和有效性之间提供了更好的权衡。此外，该方法还提供了更稀疏的追索建议，并对保证可行性的后处理方法具有鲁棒性。

Conclusion: 该研究成功开发了一种新的算法，能够在模型更新的情况下，提供更优、更具成本效益且更鲁棒的追索建议。

Abstract: Recourse provides individuals who received undesirable labels (e.g., denied a
loan) from algorithmic decision-making systems with a minimum-cost improvement
suggestion to achieve the desired outcome. However, in practice, models often
get updated to reflect changes in the data distribution or environment,
invalidating the recourse recommendations (i.e., following the recourse will
not lead to the desirable outcome). The robust recourse literature addresses
this issue by providing a framework for computing recourses whose validity is
resilient to slight changes in the model. However, since the optimization
problem of computing robust recourse is non-convex (even for linear models),
most of the current approaches do not have any theoretical guarantee on the
optimality of the recourse. Recent work by Kayastha et. al. provides the first
provably optimal algorithm for robust recourse with respect to generalized
linear models when the model changes are measured using the $L^{\infty}$ norm.
However, using the $L^{\infty}$ norm can lead to recourse solutions with a high
price. To address this shortcoming, we consider more constrained model changes
defined by the $L^p$ norm, where $p\geq 1$ but $p\neq \infty$, and provide a
new algorithm that provably computes the optimal robust recourse for
generalized linear models. Empirically, for both linear and non-linear models,
we demonstrate that our algorithm achieves a significantly lower price of
recourse (up to several orders of magnitude) compared to prior work and also
exhibits a better trade-off between the implementation cost of recourse and its
validity. Our empirical analysis also illustrates that our approach provides
more sparse recourses compared to prior work and remains resilient to
post-processing approaches that guarantee feasibility.

</details>


### [275] [No Prior, No Leakage: Revisiting Reconstruction Attacks in Trained Neural Networks](https://arxiv.org/abs/2509.21296)
*Yehonatan Refael,Guy Smorodinsky,Ofir Lindenbaum,Itay Safran*

Main category: cs.LG

TL;DR: 神经网络的训练数据记忆可能危及隐私和安全，现有攻击方法虽有演示但理论基础薄弱。本文分析了现有重构方法的局限性，证明在缺乏先验知识的情况下，重构不可靠，且精确复制训练样本仅是偶然。研究发现，训练更充分的网络反而对重构攻击更具抵抗力，从而在隐私和泛化之间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 现有关于神经网络模型参数可被用于重建训练数据的研究，在理论基础和可靠性方面存在不足，未能充分理解这些重建攻击的局限性。

Method: 分析现有基于模型参数重构训练数据的攻击方法的固有弱点和局限性，并通过理论证明和实证研究来检验这些方法的有效性。

Result: 证明在缺乏关于数据的先验知识的情况下，存在无数可能与真实训练集相距甚远的替代解，表明重构过程本身存在根本性的不可靠性。实证结果显示，精确复制训练样本的情况仅是偶然发生的。此外，研究发现训练更充分的网络（满足更强的隐式偏置条件）反而对重构攻击的抵抗力更强。

Conclusion: 重构攻击的可靠性远不如预期，并且训练程度更高的模型可能具有更好的隐私保护特性。这为理解和缓解基于模型参数的隐私泄露攻击提供了新的理论视角和实践指导。

Abstract: The memorization of training data by neural networks raises pressing concerns
for privacy and security. Recent work has shown that, under certain conditions,
portions of the training set can be reconstructed directly from model
parameters. Some of these methods exploit implicit bias toward margin
maximization, suggesting that properties often regarded as beneficial for
generalization may actually compromise privacy. Yet despite striking empirical
demonstrations, the reliability of these attacks remains poorly understood and
lacks a solid theoretical foundation. In this work, we take a complementary
perspective: rather than designing stronger attacks, we analyze the inherent
weaknesses and limitations of existing reconstruction methods and identify
conditions under which they fail. We rigorously prove that, without
incorporating prior knowledge about the data, there exist infinitely many
alternative solutions that may lie arbitrarily far from the true training set,
rendering reconstruction fundamentally unreliable. Empirically, we further
demonstrate that exact duplication of training examples occurs only by chance.
Our results refine the theoretical understanding of when training set leakage
is possible and offer new insights into mitigating reconstruction attacks.
Remarkably, we demonstrate that networks trained more extensively, and
therefore satisfying implicit bias conditions more strongly -- are, in fact,
less susceptible to reconstruction attacks, reconciling privacy with the need
for strong generalization in this setting.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [276] [Pedagogically Motivated and Composable Open-Source RISC-V Processors for Computer Science Education](https://arxiv.org/abs/2509.20514)
*Ian McDougall,Harish Batchu,Michael Davies,Karthikeyan Sankaralingam*

Main category: cs.AR

TL;DR: RISC-V 是一个免费且开源的指令集架构 (ISA)，可以用于教学和业余用途。本文提出了评估 RISC-V 实现生态系统组件的教学标准，分析了现有的开源 RISC-V 实现，并提出了一个满足所有标准并已开源的综合性解决方案，最后报告了学生反馈的研究。


<details>
  <summary>Details</summary>
Motivation: 为了提供一个开源、易于使用且强大的 RISC-V 实现，以适应教学和业余用途。

Method: 1. 提出评估 RISC-V 实现生态系统组件的教学标准。2. 分析现有的开源 RISC-V 实现，评估其是否符合标准。3. 开发一个满足所有标准的开源综合解决方案，并允许根据课程需求进行组件分解。4. 报告学生反馈的研究结果。

Result: 开发了一个满足所有教学标准的、可组合的开源 RISC-V 实现解决方案，并收集了学生反馈。

Conclusion: 开源的 RISC-V 实现可以为教学和业余用途提供便利，并且本文提出的解决方案能够满足这些需求。

Abstract: While most instruction set architectures (ISAs) are only available to use
through the purchase of a restrictive commercial license, the RISC-V ISA
presents a free and open-source alternative. Due to this availability, many
free and open-source implementations have been developed and can be accessed on
platforms such as GitHub. If an open source, easy-to-use, and robust RISC-V
implementation could be obtained, it could be easily adapted for pedagogical
and amateur use. In this work we accomplish three goals in relation to this
outlook. First, we propose a set of criteria for evaluating the components of a
RISC-V implementation's ecosystem from a pedagogical perspective. Second, we
analyze a number of existing open-source RISC-V implementations to determine
how many of the criteria they fulfill. We then develop a comprehensive solution
that meets all of these criterion and is released open-source for other
instructors to use. The framework is developed in a composable way that it's
different components can be disaggregated per individual course needs. Finally,
we also report on a limited study of student feedback.

</details>


### [277] [ZynqParrot: A Scale-Down Approach to Cycle-Accurate, FPGA-Accelerated Co-Emulation](https://arxiv.org/abs/2509.20543)
*Daniel Ruelas-Petrisko,Farzam Gilani,Anoop Mysore Nataraja,Zoe Taylor,Michael Taylor*

Main category: cs.AR

TL;DR: 通过将大型系统分解为可独立原型化的子组件，在 FPGA 上进行精确、经济高效的缩减建模和验证。


<details>
  <summary>Details</summary>
Motivation: 处理器日益复杂，验证成本高昂，而传统的仿真方法因运行时间长而难以处理长工作负载。

Method: 提出一种“缩减”方法，将系统分解为独立的子组件进行原型化，并通过设计原型接口来确保设备UnderTest（DUT）的无干扰。开发了一个名为 ZynqParrot 的基于 FPGA 的缩减建模平台。

Result: ZynqParty 平台能够执行任意 RTL 设计的非干扰、周期精确的协同仿真，用于功能和性能验证。已通过 RISC-V 处理器分析的案例研究证明了其有效性。

Conclusion: 缩减方法在精度、速度和成本方面优于传统方法，为处理器设计验证提供了一种新的解决方案。

Abstract: As processors increase in complexity, costs grow even more rapidly, both for
functional verification and performance validation. Most often, silicon
characterizations comprise simple performance counters, which are aggregated
and separated to tell a story. Based on these inferences, performance engineers
employ microarchitectural simulation to inspect deeply into the core.
Unfortunately, dramatically longer runtimes make simulation infeasible for long
workloads.
  We propose a Scale-Down approach to modelling and validation. Rather than
up-sizing a prototyping platform to fit large and complex system designs, we
show that it can be more accurate, faster, and more economical to decompose a
system into manageable sub-components that can be prototyped independently. By
carefully designing the prototyping interface, it is possible to adhere to
strict non-interference of the Device Under Test (DUT). This allows architects
to have the best of both worlds: the speed of FPGA acceleration while
eliminating the inaccuracies of Scale-Out and the inherent costs of Scale-Up.
  In this work, we present ZynqParrot: a Scale-Down FPGA-based modelling
platform, capable of executing non-interfering, cycle-accurate co-emulations of
arbitrary RTL designs. ZynqParrot is capable of verifying functionality and
performance with arbitrary granularity. We also provide case studies using
ZynqParrot to analyze the full-stack performance of an open-source RISC-V
processor.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [278] [FZModules: A Heterogeneous Computing Framework for Customizable Scientific Data Compression Pipelines](https://arxiv.org/abs/2509.20563)
*Skyler Ruiter,Jiannan Tian,Fengguang Song*

Main category: cs.DC

TL;DR: FZModules是一个用于构建定制化、高性能、可扩展的科学数据压缩管线的异构框架。


<details>
  <summary>Details</summary>
Motivation: 科学模拟和仪器产生的数据量巨大，传统的压缩方法在特定应用中表现不佳，而现有的GPU压缩器缺乏灵活性且压缩率不高。

Method: FZModules提供了一个易于使用的接口，允许用户从高性能模块构建压缩管线，并利用一个异步任务执行库来管理数据依赖、内存移动和并发执行。

Result: 使用FZModules构建的压缩管线在与硬编码的GPU压缩器相当的端到端速度下，实现了与CPU或混合压缩器相当的压缩率-失真性能。

Conclusion: FZModules通过提供一个灵活、高效的框架，解决了科学数据压缩的挑战，使得研究人员能够快速设计和部署针对特定领域的数据压缩解决方案。

Abstract: Modern scientific simulations and instruments generate data volumes that
overwhelm memory and storage, throttling scalability. Lossy compression
mitigates this by trading controlled error for reduced footprint and throughput
gains, yet optimal pipelines are highly data and objective specific, demanding
compression expertise. GPU compressors supply raw throughput but often
hard-code fused kernels that hinder rapid experimentation, and underperform in
rate-distortion. We present FZModules, a heterogeneous framework for assembling
error-bounded custom compression pipelines from high-performance modules
through a concise extensible interface. We further utilize an asynchronous
task-backed execution library that infers data dependencies, manages memory
movement, and exposes branch and stage level concurrency for powerful
asynchronous compression pipelines. Evaluating three pipelines built with
FZModules on four representative scientific datasets, we show they can compare
end-to-end speedup of fused-kernel GPU compressors while achieving similar
rate-distortion to higher fidelity CPU or hybrid compressors, enabling rapid,
domain-tailored design.

</details>


### [279] [Experience Deploying Containerized GenAI Services at an HPC Center](https://arxiv.org/abs/2509.20603)
*Angel M. Beltre,Jeff Ogden,Kevin Pedretti*

Main category: cs.DC

TL;DR: GenAI应用部署在HPC中心，结合了HPC和Kubernetes平台，并用Llama LLM进行了案例研究。


<details>
  <summary>Details</summary>
Motivation: 介绍在HPC中心部署GenAI应用的经验，并讨论HPC和云计算的融合。

Method: 描述了一个集成了HPC和Kubernetes平台的融合计算架构，用于运行容器化的GenAI工作负载，并通过vLLM在Kubernetes和HPC平台上部署Llama LLM进行了案例研究。

Result: 展示了在HPC中心部署GenAI工作负载的经验，包括容器化部署、多容器运行时以及HPC和Kubernetes的集成。

Conclusion: 强调了HPC容器社区在可重复性、未来研究和工具开发方面的实际考虑和机遇。

Abstract: Generative Artificial Intelligence (GenAI) applications are built from
specialized components -- inference servers, object storage, vector and graph
databases, and user interfaces -- interconnected via web-based APIs. While
these components are often containerized and deployed in cloud environments,
such capabilities are still emerging at High-Performance Computing (HPC)
centers. In this paper, we share our experience deploying GenAI workloads
within an established HPC center, discussing the integration of HPC and cloud
computing environments. We describe our converged computing architecture that
integrates HPC and Kubernetes platforms running containerized GenAI workloads,
helping with reproducibility. A case study illustrates the deployment of the
Llama Large Language Model (LLM) using a containerized inference server (vLLM)
across both Kubernetes and HPC platforms using multiple container runtimes. Our
experience highlights practical considerations and opportunities for the HPC
container community, guiding future research and tool development.

</details>


### [280] [Distributed-memory Algorithms for Sparse Matrix Permutation, Extraction, and Assignment](https://arxiv.org/abs/2509.20776)
*Elaheh Hassani,Md Taufique Hussain,Ariful Azad*

Main category: cs.DC

TL;DR: We present scalable distributed-memory algorithms for sparse matrix permutation, extraction, and assignment using an Identify-Exchange-Build (IEB) strategy. This approach reduces communication and uses synchronization-free multithreaded algorithms for faster local computations, outperforming existing libraries like CombBLAS and PETSc. We provide software, evaluate performance on various platforms and applications, and offer a comprehensive study.


<details>
  <summary>Details</summary>
Motivation: To develop scalable distributed-memory algorithms for sparse matrix permutation, extraction, and assignment that reduce communication and improve performance compared to existing methods.

Method: The paper introduces an Identify-Exchange-Build (IEB) strategy. Each process identifies local nonzeros for sending, exchanges data, and builds its local submatrix. Synchronization-free multithreaded algorithms are used for local computations.

Result: The proposed algorithms achieve substantially better performance than CombBLAS and PETSc, as demonstrated through evaluations on university clusters and the Perlmutter supercomputer across various applications like load balancing, reordering, subgraph extraction, and streaming graph applications.

Conclusion: This work provides a comprehensive study of algorithms, software implementations, experimental evaluations, and applications for sparse matrix permutation, extraction, and assignment, demonstrating the effectiveness of the IEB strategy and multithreaded approach in distributed environments.

Abstract: We present scalable distributed-memory algorithms for sparse matrix
permutation, extraction, and assignment. Our methods follow an
Identify-Exchange-Build (IEB) strategy where each process identifies the local
nonzeros to be sent, exchanges the required data, and then builds its local
submatrix from the received elements. This approach reduces communication
compared to SpGEMM-based methods in distributed memory. By employing
synchronization-free multithreaded algorithms, we further accelerate local
computations, achieving substantially better performance than existing
libraries such as CombBLAS and PETSc. We design efficient software for these
operations and evaluate their performance on two university clusters and the
Perlmutter supercomputer. Our experiments span a variety of application
scenarios, including matrix permutation for load balancing, matrix reordering,
subgraph extraction, and streaming graph applications. In all cases, we compare
our algorithms against CombBLAS, the most comprehensive distributed library for
these operations, and, in some scenarios, against PETSc. Overall, this work
provides a comprehensive study of algorithms, software implementations,
experimental evaluations, and applications for sparse matrix permutation,
extraction, and assignment.

</details>


### [281] [From GPUs to RRAMs: Distributed In-Memory Primal-Dual Hybrid Gradient Method for Solving Large-Scale Linear Optimization Problem](https://arxiv.org/abs/2509.21137)
*Huynh Q. N. Vo,Md Tawsif Rahman Chowdhury,Paritosh Ramanan,Gozde Tutuncuoglu,Junchi Yang,Feng Qiu,Murat Yildirim*

Main category: cs.DC

TL;DR: RRAM 기반 분산형 PDHG 솔버는 GPU 기반 솔버와 유사한 정확도를 달성하면서 에너지 소비와 지연 시간을 최대 3배까지 줄여 대규모 최적화 문제를 해결하는 데 있어 알고리즘-하드웨어 공동 설계를 보여줍니다.


<details>
  <summary>Details</summary>
Motivation: 기존 컴퓨팅 아키텍처의 한계로 인해 RRAM을 이용한 인메모리 컴퓨팅(IMC)이 지연 시간과 에너지 소비를 크게 줄일 수 있는 유망한 대안으로 부상했지만, 특히 빈번한 행렬 재프로그래밍이 비용이 많이 드는 제약 최적화 문제에 대한 기존 알고리즘은 IMC에 적합하지 않습니다.

Method: 저자는 RRAM 장치 배열에 맞게 특별히 공동 설계된 분산형 인메모리 프라이멀-듀얼 하이브리드 그래디언트(PDHG) 방법을 제시합니다. 이 방법은 비용이 많이 드는 쓰기 사이클을 최소화하고, 장치 비이상에 대한 견고성을 통합하며, 분산 크로스바 전반의 연산을 통합하기 위해 대칭 블록 행렬 공식을 활용합니다. 또한 물리 기반 시뮬레이션 프레임워크인 MELISO+를 통합하여 실제 장치 조건에서 성능을 평가합니다.

Result: RRAM 기반 솔버는 대규모 선형 프로그램에 대한 GPU 가속 솔버와 비교하여 최대 3배의 에너지 소비 및 지연 시간 감소와 함께 유사한 정확도를 달성했습니다.

Conclusion: 이 연구는 RRAM에서 구현된 최초의 PDHG 기반 LP 솔버를 보여주며, 분산 인메모리 컴퓨팅을 통해 대규모 최적화 문제를 해결하기 위한 알고리즘-하드웨어 공동 설계의 혁신적인 잠재력을 보여줍니다.

Abstract: The exponential growth of computational workloads is surpassing the
capabilities of conventional architectures, which are constrained by
fundamental limits. In-memory computing (IMC) with RRAM provides a promising
alternative by providing analog computations with significant gains in latency
and energy use. However, existing algorithms developed for conventional
architectures do not translate to IMC, particularly for constrained
optimization problems where frequent matrix reprogramming remains
cost-prohibitive for IMC applications. Here we present a distributed in-memory
primal-dual hybrid gradient (PDHG) method, specifically co-designed for arrays
of RRAM devices. Our approach minimizes costly write cycles, incorporates
robustness against device non-idealities, and leverages a symmetric
block-matrix formulation to unify operations across distributed crossbars. We
integrate a physics-based simulation framework called MELISO+ to evaluate
performance under realistic device conditions. Benchmarking against
GPU-accelerated solvers on large-scale linear programs demonstrates that our
RRAM-based solver achieves comparable accuracy with up to three orders of
magnitude reductions in energy consumption and latency. These results
demonstrate the first PDHG-based LP solver implemented on RRAMs, showcasing the
transformative potential of algorithm-hardware co-design for solving
large-scale optimization through distributed in-memory computing.

</details>


### [282] [Integrating and Characterizing HPC Task Runtime Systems for hybrid AI-HPC workloads](https://arxiv.org/abs/2509.20819)
*Andre Merzky,Mikhail Titov,Matteo Turilli,Shantenu Jha*

Main category: cs.DC

TL;DR: RADICAL-Pilot (RP) 结合 Flux 和 Dragon 运行时系统，在混合 AI-HPC 工作负载方面比 Slurm 的 srun 表现出更高的吞吐量和更短的执行时间。


<details>
  <summary>Details</summary>
Motivation: 科学工作流越来越多地结合 HPC 和机器学习任务，但现有的启动器（如 Slurm 的 srun）在处理动态和异构工作负载方面存在局限性。

Method: 对 RADICAL-Pilot (RP) 与 Flux 和 Dragon 集成进行了性能研究，并在 Frontier 超级计算机上使用合成和生产规模的工作负载进行了测试。

Result: RP+Flux 的吞吐量最高可达 930 任务/秒，RP+Flux+Dragon 的吞吐量超过 1,500 任务/秒，利用率超过 99.6%。与此相比，srun 的峰值吞吐量为 152 任务/秒，且利用率低于 50%。对于 IMPECCABLE.v2 药物发现活动，RP+Flux 将执行时间缩短了 30-60%，并将吞吐量提高了四倍以上。

Conclusion: RP 中混合运行时系统的集成是处理混合 AI-HPC 工作负载的可扩展方法。

Abstract: Scientific workflows increasingly involve both HPC and machine-learning
tasks, combining MPI-based simulations, training, and inference in a single
execution. Launchers such as Slurm's srun constrain concurrency and throughput,
making them unsuitable for dynamic and heterogeneous workloads. We present a
performance study of RADICAL-Pilot (RP) integrated with Flux and Dragon, two
complementary runtime systems that enable hierarchical resource management and
high-throughput function execution. Using synthetic and production-scale
workloads on Frontier, we characterize the task execution properties of RP
across runtime configurations. RP+Flux sustains up to 930 tasks/s, and
RP+Flux+Dragon exceeds 1,500 tasks/s with over 99.6% utilization. In contrast,
srun peaks at 152 tasks/s and degrades with scale, with utilization below 50%.
For IMPECCABLE.v2 drug discovery campaign, RP+Flux reduces makespan by 30-60%
relative to srun/Slurm and increases throughput more than four times on up to
1,024. These results demonstrate hybrid runtime integration in RP as a scalable
approach for hybrid AI-HPC workloads.

</details>


### [283] [RollPacker: Mitigating Long-Tail Rollouts for Fast, Synchronous RL Post-Training](https://arxiv.org/abs/2509.21009)
*Wei Gao,Yuheng Zhao,Dakai An,Tianyuan Wu,Lunxi Cao,Shaopan Xiong,Ju Huang,Weixun Wang,Siran Yang,Wenbo Su,Jiamang Wang,Lin Qu,Bo Zheng,Wei Wang*

Main category: cs.DC

TL;DR: 强化学习（RL）在提高大语言模型（LLM）推理能力方面很重要，但同步RL训练会导致GPU利用率低下（称为气泡）。本文提出了一种名为“尾部批处理”的新型滚轮调度策略，通过将产生长响应的提示集中到少数几个长轮次中，同时确保大多数短轮次只处理短响应，从而有效减少GPU空闲时间并加速RL训练，同时不牺牲准确性。我们还推出了RollPacker系统，通过弹性并行适应、动态资源分配和基于流的训练等优化措施，充分发挥了尾部批处理的优势。实验结果表明，与veRL和RLHFuse相比，RollPacker在Qwen2.5大语言模型家族上（最多128个H800 GPU）的端到端训练时间分别缩短了2.03-2.56倍和最多2.24倍。


<details>
  <summary>Details</summary>
Motivation: 同步强化学习（RL）训练大语言模型（LLM）时，由于响应长度不平衡，会导致GPU利用率低下（气泡问题）。现有方法通过放松同步来解决此问题，但可能影响训练准确性。

Method: 提出了一种名为“尾部批处理”的新型滚轮调度策略，将产生长响应的提示集中到少数“长轮次”中，而将大多数短响应保留在“短轮次”中，以减少GPU空闲时间。在此基础上，开发了RollPacker系统，通过弹性并行适应、动态资源分配和基于流的训练等优化措施，实现端到端的性能提升。

Result: RollPacker系统实现了2.03倍至2.56倍的端到端训练时间缩减（相比veRL），以及最高2.24倍的加速（相比RLHFuse），用于Qwen2.5大语言模型家族在多达128个H800 GPU上的训练。

Conclusion: 尾部批处理是一种有效的滚轮调度策略，可以显著加速同步RL训练，同时保持准确性。RollPacker系统通过全面的优化实现了该策略的全部优势，在实际应用中取得了显著的性能提升。

Abstract: Reinforcement Learning (RL) is a pivotal post-training technique for
enhancing the reasoning capabilities of Large Language Models (LLMs). However,
synchronous RL post-training often suffers from significant GPU
underutilization, referred to as bubbles, caused by imbalanced response lengths
within rollout steps. Many RL systems attempt to alleviate this problem by
relaxing synchronization, but this can compromise training accuracy. In this
paper, we introduce tail batching, a novel rollout scheduling strategy for
synchronous RL that systematically consolidates prompts leading to long-tail
responses into a small subset of rollout steps (long rounds), while ensuring
that the majority of steps (short rounds) involve only balanced, short
rollouts. By excluding long responses from short rounds and rescheduling them
into a few designated long rounds, tail batching effectively reduces GPU idle
time during rollouts and significantly accelerates RL training without
sacrificing accuracy. We present RollPacker, a system that fully harnesses the
benefits of tail batching through holistic optimizations across all three RL
stages: elastic parallelism adaptation for rollout, dynamic resource allocation
and scheduling for reward, and stream-based training. Empirical results show
that RollPacker achieves a 2.03x-2.56x end-to-end training time reduction
compared to veRL and up to 2.24x speedup compared to RLHFuse for the Qwen2.5
family of LLMs on up to 128 H800 GPUs.

</details>


### [284] [Mojo: MLIR-Based Performance-Portable HPC Science Kernels on GPUs for the Python Ecosystem](https://arxiv.org/abs/2509.21039)
*William F. Godoy,Tatiana Melnichenko,Pedro Valero-Lara,Wael Elwasif,Philip Fackler,Rafael Ferreira Da Silva,Keita Teranishi,Jeffrey S. Vetter*

Main category: cs.DC

TL;DR: Mojo语言在科学计算GPU工作负载上表现出竞争力，尤其在内存密集型内核上，但在AMD GPU的原子操作和 fast-math 计算密集型内核上存在差距。


<details>
  <summary>Details</summary>
Motivation: Mojo旨在弥合Python在科学计算和AI融合领域的性能和生产力差距，提供一种基于MLIR、语法类似CUDA且可移植的GPU编程语言。

Method: 针对四种科学计算工作负载（七点模板、BabelStream、miniBUDE、Hartree-Fock），在NVIDIA H100和AMD MI300A GPU上，将Mojo的性能与CUDA和HIP的厂商基线进行比较。

Result: Mojo在内存密集型内核上的性能与CUDA和HIP相当。然而，在AMD GPU的原子操作以及AMD和NVIDIA GPU的fast-math计算密集型内核上，Mojo的性能存在差距。

Conclusion: 尽管Mojo的学习曲线和编程要求仍偏底层，但它在科学计算与AI融合的Python生态碎片化问题上，能够显著缩小差距，展现出其潜力。

Abstract: We explore the performance and portability of the novel Mojo language for
scientific computing workloads on GPUs. As the first language based on the
LLVM's Multi-Level Intermediate Representation (MLIR) compiler infrastructure,
Mojo aims to close performance and productivity gaps by combining Python's
interoperability and CUDA-like syntax for compile-time portable GPU
programming. We target four scientific workloads: a seven-point stencil
(memory-bound), BabelStream (memory-bound), miniBUDE (compute-bound), and
Hartree-Fock (compute-bound with atomic operations); and compare their
performance against vendor baselines on NVIDIA H100 and AMD MI300A GPUs. We
show that Mojo's performance is competitive with CUDA and HIP for memory-bound
kernels, whereas gaps exist on AMD GPUs for atomic operations and for fast-math
compute-bound kernels on both AMD and NVIDIA GPUs. Although the learning curve
and programming requirements are still fairly low-level, Mojo can close
significant gaps in the fragmented Python ecosystem in the convergence of
scientific computing and AI.

</details>


### [285] [Utilizing Sparsity in the GPU-accelerated Assembly of Schur Complement Matrices in Domain Decomposition Methods](https://arxiv.org/abs/2509.21037)
*Jakub Homola,Ondřej Meca,Lubomír Říha,Tomáš Brzobohatý*

Main category: cs.DC

TL;DR: 通过利用稀疏性优化GPU上的Schur补码矩阵组装，提高了FETI方法的计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有舒尔补码矩阵的GPU加速方法在显式组装时成本高昂，该研究旨在通过利用稀疏性来优化此过程。

Method: 通过明智地利用输入矩阵的稀疏性来改进GPU上的Schur补码矩阵组装过程。

Result: 在FETI方法中，GPU部分代码实现了5.1倍的加速，整个组装过程实现了3.3倍的加速，并且在仅10次迭代后即可显现加速优势。

Conclusion: 通过利用稀疏性优化GPU组装过程，可以进一步提高Schur补码矩阵计算的效率，从而使FETI方法等加速技术从更少的迭代次数中受益。

Abstract: Schur complement matrices emerge in many domain decomposition methods that
can solve complex engineering problems using supercomputers. Today, as most of
the high-performance clusters' performance lies in GPUs, these methods should
also be accelerated.
  Typically, the offloaded components are the explicitly assembled dense Schur
complement matrices used later in the iterative solver for multiplication with
a vector. As the explicit assembly is expensive, it represents a significant
overhead associated with this approach to acceleration. It has already been
shown that the overhead can be minimized by assembling the Schur complements
directly on the GPU.
  This paper shows that the GPU assembly can be further improved by wisely
utilizing the sparsity of the input matrices. In the context of FETI methods,
we achieved a speedup of 5.1 in the GPU section of the code and 3.3 for the
whole assembly, making the acceleration beneficial from as few as 10
iterations.

</details>


### [286] [Data-Centric Elastic Pipeline Parallelism for Efficient Long-Context LLM Training](https://arxiv.org/abs/2509.21275)
*Shiju Wang,Yujie Wang,Ao Sun,Fangcheng Fu,Zijian Zhu,Bin Cui,Xu Han,Kaisheng Ma*

Main category: cs.DC

TL;DR: 长上下文训练是LLM上下文扩展的关键。现有的序列并行方法会产生显著的通信开销。流水线并行（PP）可以降低成本，但其有效性取决于划分的粒度。批处理级PP（划分输入样本）在长上下文场景下内存消耗高；而令牌级PP（将序列划分为片段）可以减轻内存开销，但可能导致硬件利用率不足。这种权衡促使人们需要自适应地选择PP粒度以匹配资源和工作负载的特性。此外，真实世界数据集的序列长度分布存在偏斜，给PP的工作负载平衡和高效调度带来了挑战。目前的静态PP调度方法忽略了序列长度的变化，导致性能不佳。本文提出了一种弹性流水线并行（EPP）方法，该方法协调了令牌级PP和批处理级PP，以适应资源和工作负载的异构性。我们构建了一个分布式训练系统InfiniPipe，通过以下方式释放EPP的潜力：（1）一个资源感知且工作负载均衡的序列处理器，它分割长序列并打包短序列；（2）一种联合优化流水线调度和梯度检查点的协同优化方法，通过一种名为“阶段感知块级自适应检查点”的机制实现。全面的实验表明，InfiniPipe比最先进的系统实现了1.69倍的加速。


<details>
  <summary>Details</summary>
Motivation: 长上下文训练是LLM上下文扩展的关键，但现有方法存在通信开销高、内存消耗大或硬件利用率低等问题。真实世界数据集的序列长度分布不均也给PP带来了挑战，目前的静态调度方法性能不佳。

Method: 提出弹性流水线并行（EPP），协调令牌级PP和批处理级PP以适应异构资源和工作负载。构建InfiniPipe系统，包含资源感知和工作负载均衡的序列处理器（分割长序列、打包短序列），以及通过阶段感知块级自适应检查点机制联合优化流水线调度和梯度检查点的协同优化方法。

Result: InfiniPipe实现了1.69倍于现有最先进系统的加速。

Conclusion: 弹性流水线并行（EPP）通过自适应地协调不同粒度的流水线并行，并结合优化的调度和检查点策略，能够有效解决长上下文训练中的资源和工作负载异构性问题，显著提升训练效率。

Abstract: Long context training is crucial for LLM's context extension. Existing
schemes, such as sequence parallelism, incur substantial communication
overhead. Pipeline parallelism (PP) reduces this cost, but its effectiveness
hinges on partitioning granularity. Batch-level PP dividing input samples
exhibits high memory consumption in long-context scenario, whereas token-level
PP splitting sequences into slices alleviates memory overhead but may incur
hardware under-utilization. This trade-off motivates adaptively selecting PP
granularity to match resource and workload characteristics. Moreover, sequence
length distribution of the real-world dataset exhibits skewness, posing a
challenge on PP's workload balance and efficient scheduling. Current static PP
scheduling methods overlook the variance of sequence length, leading to
suboptimal performance. In this paper, we propose Elastic Pipeline Parallelism
(EPP) that orchestrates token-level PP and batch-level PP to adapt to resource
and workload heterogeneity. We build InfiniPipe, a distributed training system
that unleashes the potential of EPP via (1) a resource-aware and
workload-balanced sequence processor that splits long sequences and packs short
ones; and (2) a co-optimization methodology that jointly optimizes pipeline
schedule and gradient checkpointing via a mechanism named stage-aware
chunk-level adaptive checkpointing. Comprehensive experiments demonstrate that
InfiniPipe achieves a 1.69x speedup over state-of-the-art systems.

</details>


<div id='cs.SY'></div>

# cs.SY [[Back]](#toc)

### [287] [Fractional Logistic Growth with Memory Effects: A Tool for Industry-Oriented Modeling](https://arxiv.org/abs/2509.20389)
*M. O. Aibinu,A. Shoukat,F. M. Mahomed*

Main category: cs.SY

TL;DR: 本文提出了一个包含比例时滞的、基于阿塔纳甘-贝努（ABC）分数阶导数的广义逻辑斯蒂增长模型，并使用混合Sumudu变分（HSV）方法求解，以模拟包含记忆效应和非局域动态的复杂增长现象。


<details>
  <summary>Details</summary>
Motivation: 为了描述和模拟在工业、医学和社会系统等领域中遇到的、具有记忆效应和非局域动态的复杂增长现象，对经典的逻辑增长模型进行了扩展。

Method: 采用阿塔纳甘-贝努（ABC）分数阶导数和比例时滞来扩展逻辑增长模型，并使用混合Sumudu变分（HSV）方法获得半解析解。

Result: 结果表明，分数阶阶数和时滞的组合对系统的行为有显著影响。

Conclusion: 将ABC分数阶导数、比例时滞和基于HSV的求解方法相结合，为处理具有记忆效应和非局域动态的实际增长问题提供了一种新颖有效的方法。

Abstract: The logistic growth model is a classical framework for describing constrained
growth phenomena, widely applied in areas such as population dynamics,
epidemiology, and resource management. This study presents a generalized
extension using Atangana-Baleanu in Caputo sense (ABC)-type fractional
derivatives. Proportional time delay is also included, allowing the model to
capture memory-dependent and nonlocal dynamics not addressed in classical
formulations. Free parameters provide flexibility for modeling complex growth
in industrial, medical, and social systems. The Hybrid Sumudu Variational (HSV)
method is employed to efficiently obtain semi-analytical solutions. Results
highlight the combined effects of fractional order and delay on system
behavior. This approach demonstrates the novelty of integrating ABC-type
derivatives, proportional delay, and HSV-based solutions for real-world
applications.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [288] [SeHDR: Single-Exposure HDR Novel View Synthesis via 3D Gaussian Bracketing](https://arxiv.org/abs/2509.20400)
*Yiyu Li,Haoyuan Wang,Ke Xu,Gerhard Petrus Hancke,Rynson W. H. Lau*

Main category: cs.GR

TL;DR: SeHDR是一种新的高动态范围3D高斯泼溅（HDR-3DGS）方法，可以从多视角LDR图像生成HDR新视角。与需要不同曝光输入图像的现有方法不同，SeHDR从单次曝光的多视角LDR图像中学习HDR场景表示。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要不同曝光的LDR图像，这使得捕获过程繁琐，并且容易出现错误（例如，运动模糊和校准/对齐不准确）。本研究旨在从单次曝光的多视角LDR图像生成HDR新视角。

Method: SeHDR首先从单次曝光的LDR输入中学习基础3D高斯泼溅，然后估计具有相同几何形状但颜色不同的多个3D高斯泼溅，最后使用可微分神经曝光融合（NeEF）将它们集成到HDR高斯泼溅中以进行新视角渲染。

Result: SeHDR在生成HDR新视角方面优于现有方法和精心设计的基线。

Conclusion: SeHDR是一种有效的方法，可以从单次曝光的多视角LDR图像生成HDR新视角，解决了现有方法的局限性。

Abstract: This paper presents SeHDR, a novel high dynamic range 3D Gaussian Splatting
(HDR-3DGS) approach for generating HDR novel views given multi-view LDR images.
Unlike existing methods that typically require the multi-view LDR input images
to be captured from different exposures, which are tedious to capture and more
likely to suffer from errors (e.g., object motion blurs and
calibration/alignment inaccuracies), our approach learns the HDR scene
representation from multi-view LDR images of a single exposure. Our key insight
to this ill-posed problem is that by first estimating Bracketed 3D Gaussians
(i.e., with different exposures) from single-exposure multi-view LDR images, we
may then be able to merge these bracketed 3D Gaussians into an HDR scene
representation. Specifically, SeHDR first learns base 3D Gaussians from
single-exposure LDR inputs, where the spherical harmonics parameterize colors
in a linear color space. We then estimate multiple 3D Gaussians with identical
geometry but varying linear colors conditioned on exposure manipulations.
Finally, we propose the Differentiable Neural Exposure Fusion (NeEF) to
integrate the base and estimated 3D Gaussians into HDR Gaussians for novel view
rendering. Extensive experiments demonstrate that SeHDR outperforms existing
methods as well as carefully designed baselines.

</details>


### [289] [SGAligner++: Cross-Modal Language-Aided 3D Scene Graph Alignment](https://arxiv.org/abs/2509.20401)
*Binod Singh,Sayan Deb Sarkar,Iro Armeni*

Main category: cs.GR

TL;DR: SGAligner++是一个跨模态、语言辅助的3D场景图对齐框架，通过学习统一的联合嵌入空间，即使在低重叠和传感器噪声条件下也能实现准确对齐，并在真实世界数据上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 3D场景图对齐是机器人导航和具身感知应用的关键初始步骤，但现有方法依赖单一模态点云数据，在处理不完整或噪声输入时存在困难。

Method: SGAligner++采用跨模态、语言辅助的方法，利用轻量级单模态编码器和基于注意力机制的融合，学习统一的联合嵌入空间，以处理部分重叠的异构模态观测。

Result: SGAligner++在真实世界数据集上的广泛评估显示，在噪声现实世界的重建上，其性能比最先进的方法高出40%，并实现了跨模态泛化。

Conclusion: SGAligner++通过跨模态融合和语言辅助，提高了3D场景图对齐的鲁棒性和准确性，特别是在低重叠和噪声条件下，并为视觉定位、3D重建和导航等下游任务提供了支持，同时保持了可扩展性和较低的计算开销。

Abstract: Aligning 3D scene graphs is a crucial initial step for several applications
in robot navigation and embodied perception. Current methods in 3D scene graph
alignment often rely on single-modality point cloud data and struggle with
incomplete or noisy input. We introduce SGAligner++, a cross-modal,
language-aided framework for 3D scene graph alignment. Our method addresses the
challenge of aligning partially overlapping scene observations across
heterogeneous modalities by learning a unified joint embedding space, enabling
accurate alignment even under low-overlap conditions and sensor noise. By
employing lightweight unimodal encoders and attention-based fusion, SGAligner++
enhances scene understanding for tasks such as visual localization, 3D
reconstruction, and navigation, while ensuring scalability and minimal
computational overhead. Extensive evaluations on real-world datasets
demonstrate that SGAligner++ outperforms state-of-the-art methods by up to 40%
on noisy real-world reconstructions, while enabling cross-modal generalization.

</details>


### [290] [SceneWeaver: All-in-One 3D Scene Synthesis with an Extensible and Self-Reflective Agent](https://arxiv.org/abs/2509.20414)
*Yandan Yang,Baoxiong Jia,Shujie Zhang,Siyuan Huang*

Main category: cs.GR

TL;DR: SceneWeaver 是一个新颖的代理框架，通过基于工具的迭代优化来统一各种场景合成范式，解决了现有室内场景合成方法在物理合理性、物体细节和用户指令对齐方面的不足。


<details>
  <summary>Details</summary>
Motivation: 室内场景合成对于具身人工智能的发展至关重要，需要生成视觉逼真、物理合理且功能多样的 3D 环境。现有方法在视觉保真度方面有所进展，但在场景类别固定、物体细节不足、物理一致性欠缺以及难以满足复杂用户指令等方面存在局限。

Method: SceneWeaver 采用了一个基于语言模型的规划器，从一系列可扩展的场景生成工具（包括数据驱动的生成模型、基于视觉和 LLM 的方法）中进行选择。该框架通过闭环的“推理-行动-反思”设计，利用自我评估来确保物理合理性、视觉真实性和与用户输入的语义对齐，从而实现迭代式场景优化。

Result: SceneWeaver 在常见和开放词汇的房间类型上进行了广泛的实验，其在物理、视觉和语义指标上均优于现有方法。此外，该框架能有效泛化到具有复杂指令的场景。

Conclusion: SceneWeaver 通过其代理式、基于工具的迭代优化方法，在室内场景合成方面取得了显著进展，能够生成在物理、视觉和语义上都符合要求的 3D 环境，并能有效处理复杂的用户指令，为通用 3D 环境生成迈出了重要一步。

Abstract: Indoor scene synthesis has become increasingly important with the rise of
Embodied AI, which requires 3D environments that are not only visually
realistic but also physically plausible and functionally diverse. While recent
approaches have advanced visual fidelity, they often remain constrained to
fixed scene categories, lack sufficient object-level detail and physical
consistency, and struggle to align with complex user instructions. In this
work, we present SceneWeaver, a reflective agentic framework that unifies
diverse scene synthesis paradigms through tool-based iterative refinement. At
its core, SceneWeaver employs a language model-based planner to select from a
suite of extensible scene generation tools, ranging from data-driven generative
models to visual- and LLM-based methods, guided by self-evaluation of physical
plausibility, visual realism, and semantic alignment with user input. This
closed-loop reason-act-reflect design enables the agent to identify semantic
inconsistencies, invoke targeted tools, and update the environment over
successive iterations. Extensive experiments on both common and open-vocabulary
room types demonstrate that SceneWeaver not only outperforms prior methods on
physical, visual, and semantic metrics, but also generalizes effectively to
complex scenes with diverse instructions, marking a step toward general-purpose
3D environment generation. Project website: https://scene-weaver.github.io/.

</details>


### [291] [ArtUV: Artist-style UV Unwrapping](https://arxiv.org/abs/2509.20710)
*Yuguang Chen,Xinhai Liu,Yang Li,Victor Cheung,Zhuo Chen,Dongyu Zhang,Chunchao Guo*

Main category: cs.GR

TL;DR: ArtUV是一种全自动的端到端方法，用于生成艺术家风格的UV展开图，解决了现有方法耗时、碎片化、缺乏语义和UV块不规则等问题。


<details>
  <summary>Details</summary>
Motivation: 现有UV展开方法存在耗时、碎片化、缺乏语义和UV块不规则等问题，限制了其实际应用。艺术家风格的UV贴图不仅要满足无重叠、最小失真等基本标准，还要满足边界清晰、空间利用率高和语义一致性高等高级标准。

Method: ArtUV将UV展开过程分为两个阶段：表面接缝预测和艺术家风格UV参数化。在接缝预测阶段，使用SeamGPT生成有意义的切割接缝。在参数化阶段，将优化方法得到的粗糙UV与网格一起输入到自动编码器中，然后进行优化，生成艺术家风格的UV贴图。

Result: ArtUV能确保语义一致性并保留拓扑结构，使UV贴图能够进行2D编辑。在多个基准测试中，ArtUV表现出通用性，可用作专业渲染工具的插件或独立的快速高质量UV生成系统。

Conclusion: ArtUV是一种创新的全自动方法，能够生成高质量、艺术家风格的UV展开图，解决了现有技术的局限性，并具有广泛的应用前景。

Abstract: UV unwrapping is an essential task in computer graphics, enabling various
visual editing operations in rendering pipelines. However, existing UV
unwrapping methods struggle with time-consuming, fragmentation, lack of
semanticity, and irregular UV islands, limiting their practical use. An
artist-style UV map must not only satisfy fundamental criteria, such as
overlap-free mapping and minimal distortion, but also uphold higher-level
standards, including clean boundaries, efficient space utilization, and
semantic coherence. We introduce ArtUV, a fully automated, end-to-end method
for generating artist-style UV unwrapping. We simulates the professional UV
mapping process by dividing it into two stages: surface seam prediction and
artist-style UV parameterization. In the seam prediction stage, SeamGPT is used
to generate semantically meaningful cutting seams. Then, in the
parameterization stage, a rough UV obtained from an optimization-based method,
along with the mesh, is fed into an Auto-Encoder, which refines it into an
artist-style UV map. Our method ensures semantic consistency and preserves
topological structure, making the UV map ready for 2D editing. We evaluate
ArtUV across multiple benchmarks and show that it serves as a versatile
solution, functioning seamlessly as either a plug-in for professional rendering
tools or as a standalone system for rapid, high-quality UV generation.

</details>


### [292] [SeamCrafte: Enhancing Mesh Seam Generation for Artist UV Unwrapping via Reinforcement Learning](https://arxiv.org/abs/2509.20725)
*Duoteng Xu,Yuguang Chen,Jing Li,Xinhai Liu,Xueqi Ma,Zhuo Chen,Dongyu Zhang,Chunchao Guo*

Main category: cs.GR

TL;DR: SeamCrafter是一种基于GPT的自动回归模型，用于生成3D表面的UV贴图接缝，通过结合点云编码和直接偏好优化（DPO）来减少失真和碎片化，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有UV贴图接缝放置方法存在失真或碎片化的问题，影响纹理合成和艺术家工作流程。SeamCrafter旨在解决这些问题。

Method: SeamCrafter采用双分支点云编码器来捕捉拓扑和几何线索，并使用直接偏好优化（DPO）在新的接缝评估框架的偏好数据集上进行微调，该框架主要通过UV失真和碎片化来评估接缝。

Result: SeamCrafter生成的接缝具有显著更低的失真和碎片化，同时保持了拓扑一致性和视觉保真度，优于先前的方法。

Conclusion: SeamCrafter通过结合点云编码和DPO微调，能够生成高质量的UV贴图接缝，有效解决了现有方法的局限性。

Abstract: Mesh seams play a pivotal role in partitioning 3D surfaces for UV
parametrization and texture mapping. Poorly placed seams often result in severe
UV distortion or excessive fragmentation, thereby hindering texture synthesis
and disrupting artist workflows. Existing methods frequently trade one failure
mode for another-producing either high distortion or many scattered islands. To
address this, we introduce SeamCrafter, an autoregressive GPT-style seam
generator conditioned on point cloud inputs. SeamCrafter employs a dual-branch
point-cloud encoder that disentangles and captures complementary topological
and geometric cues during pretraining. To further enhance seam quality, we
fine-tune the model using Direct Preference Optimization (DPO) on a preference
dataset derived from a novel seam-evaluation framework. This framework assesses
seams primarily by UV distortion and fragmentation, and provides pairwise
preference labels to guide optimization. Extensive experiments demonstrate that
SeamCrafter produces seams with substantially lower distortion and
fragmentation than prior approaches, while preserving topological consistency
and visual fidelity.

</details>


### [293] [ARMesh: Autoregressive Mesh Generation via Next-Level-of-Detail Prediction](https://arxiv.org/abs/2509.20824)
*Jiabao Lei,Kewei Shi,Zhihao Liang,Kui Jia*

Main category: cs.GR

TL;DR: 该研究提出了一种新颖的渐进式粗到细的网格生成方法，用于改进现有自回归模型在生成3D网格时的几何结构捕捉能力。


<details>
  <summary>Details</summary>
Motivation: 现有的自回归网格生成模型在逐面生成时，未能有效捕捉符合人类感知的几何结构。

Method: 提出了一种基于Transformer的自回归模型，将网格简化算法进行泛化，并将其视为一个细到粗的过程，然后反向构建网格，从单个点开始，通过局部重构逐步添加细节，拓扑结构可变。

Result: 实验表明，该方法能够通过提前停止自回归过程来直观控制生成质量和时间消耗，并支持网格细化和编辑等应用。

Conclusion: 所提出的渐进式粗到细的网格生成方法在生成质量、可控性和应用方面均优于现有方法。

Abstract: Directly generating 3D meshes, the default representation for 3D shapes in
the graphics industry, using auto-regressive (AR) models has become popular
these days, thanks to their sharpness, compactness in the generated results,
and ability to represent various types of surfaces. However, AR mesh generative
models typically construct meshes face by face in lexicographic order, which
does not effectively capture the underlying geometry in a manner consistent
with human perception. Inspired by 2D models that progressively refine images,
such as the prevailing next-scale prediction AR models, we propose generating
meshes auto-regressively in a progressive coarse-to-fine manner. Specifically,
we view mesh simplification algorithms, which gradually merge mesh faces to
build simpler meshes, as a natural fine-to-coarse process. Therefore, we
generalize meshes to simplicial complexes and develop a transformer-based AR
model to approximate the reverse process of simplification in the order of
level of detail, constructing meshes initially from a single point and
gradually adding geometric details through local remeshing, where the topology
is not predefined and is alterable. Our experiments show that this novel
progressive mesh generation approach not only provides intuitive control over
generation quality and time consumption by early stopping the auto-regressive
process but also enables applications such as mesh refinement and editing.

</details>


### [294] [ArchGPT: Understanding the World's Architectures with Large Multimodal Models](https://arxiv.org/abs/2509.20858)
*Yuze Wang,Luo Yang,Junyi Wang,Yue Qi*

Main category: cs.GR

TL;DR: ArchGPT是一个多模态的建筑视觉问答模型，以及一个可扩展的数据构建流程，用于整理高质量、特定于建筑的VQA注释。该流程产生了Arch-300K，一个包含约315,000个图像-问题-答案三元组的领域专业化数据集。


<details>
  <summary>Details</summary>
Motivation: 现有的VR/MR/AR系统通常是逐案开发的，依赖于硬编码的注释和特定任务的交互，无法扩展到不同的建筑环境。

Method: 该工作提出了ArchGPT，一个多模态的建筑视觉问答（VQA）模型，以及一个可扩展的数据构建流程，用于整理高质量、特定于建筑的VQA注释。该流程产生了Arch-300K，一个包含约315,000个图像-问题-答案三元组的领域专业化数据集。Arch-300K是通过一个多阶段过程构建的：首先，使用新颖的粗粒度到细粒度策略（整合3D重建和语义分割）来筛选Wikimedia Commons中的建筑场景和过滤无约束的游客照片收藏，以选择无遮挡、结构一致的建筑图像。为了减轻原始文本元数据的噪声和不一致性，提出了一种由LLM指导的文本验证和知识蒸馏流程，以生成可靠的、特定于建筑的问题-答案对。利用这些整理后的图像和精炼的元数据，进一步合成正式的分析注释（包括详细描述和面向方面的对话），以提供更丰富的语义多样性，同时保持对数据的忠实性。在Arch-300K上对开源多模态骨干ShareGPT4V-7B进行监督微调，得到ArchGPT。

Result: 在Arch-300K上对开源多模态骨干ShareGPT4V-7B进行监督微调，得到ArchGPT。

Conclusion: ArchGPT是一个多模态的建筑视觉问答模型，以及一个可扩展的数据构建流程，用于整理高质量、特定于建筑的VQA注释。该流程产生了Arch-300K，一个包含约315,000个图像-问题-答案三元组的领域专业化数据集。

Abstract: Architecture embodies aesthetic, cultural, and historical values, standing as
a tangible testament to human civilization. Researchers have long leveraged
virtual reality (VR), mixed reality (MR), and augmented reality (AR) to enable
immersive exploration and interpretation of architecture, enhancing
accessibility, public understanding, and creative workflows around architecture
in education, heritage preservation, and professional design practice. However,
existing VR/MR/AR systems are often developed case-by-case, relying on
hard-coded annotations and task-specific interactions that do not scale across
diverse built environments. In this work, we present ArchGPT, a multimodal
architectural visual question answering (VQA) model, together with a scalable
data-construction pipeline for curating high-quality, architecture-specific VQA
annotations. This pipeline yields Arch-300K, a domain-specialized dataset of
approximately 315,000 image-question-answer triplets. Arch-300K is built via a
multi-stage process: first, we curate architectural scenes from Wikimedia
Commons and filter unconstrained tourist photo collections using a novel
coarse-to-fine strategy that integrates 3D reconstruction and semantic
segmentation to select occlusion-free, structurally consistent architectural
images. To mitigate noise and inconsistency in raw textual metadata, we propose
an LLM-guided text verification and knowledge-distillation pipeline to generate
reliable, architecture-specific question-answer pairs. Using these curated
images and refined metadata, we further synthesize formal analysis
annotations-including detailed descriptions and aspect-guided conversations-to
provide richer semantic variety while remaining faithful to the data. We
perform supervised fine-tuning of an open-source multimodal backbone
,ShareGPT4V-7B, on Arch-300K, yielding ArchGPT.

</details>


### [295] [Marching Neurons: Accurate Surface Extraction for Neural Implicit Shapes](https://arxiv.org/abs/2509.21007)
*Christian Stippel,Felix Mujkanovic,Thomas Leimkühler,Pedro Hermosilla*

Main category: cs.GR

TL;DR: We present a novel analytical approach for extracting surface meshes from neural implicit functions, achieving higher accuracy and comparable speed to existing methods.


<details>
  <summary>Details</summary>
Motivation: Accurate surface geometry representation is crucial, and efficient conversions between explicit (e.g., meshes) and implicit (e.g., signed distance functions) representations are important. Existing methods like Marching Cubes suffer from inaccuracies due to fixed resolution.

Method: Our method uses a depth-first traversal strategy to analytically extract surfaces from neural implicit functions by leveraging the domain partitioning of individual neurons. This approach operates natively in parallel and can handle large neural architectures.

Result: The resulting meshes accurately capture the full geometric information from the network without spatial discretization, outperforming existing methods in accuracy across diverse shapes and architectures, while maintaining competitive speed.

Conclusion: Our analytical surface extraction method offers a significant improvement in accuracy for representing geometry from neural implicit functions, overcoming the limitations of traditional sampling-based approaches.

Abstract: Accurate surface geometry representation is crucial in 3D visual computing.
Explicit representations, such as polygonal meshes, and implicit
representations, like signed distance functions, each have distinct advantages,
making efficient conversions between them increasingly important. Conventional
surface extraction methods for implicit representations, such as the widely
used Marching Cubes algorithm, rely on spatial decomposition and sampling,
leading to inaccuracies due to fixed and limited resolution. We introduce a
novel approach for analytically extracting surfaces from neural implicit
functions. Our method operates natively in parallel and can navigate large
neural architectures. By leveraging the fact that each neuron partitions the
domain, we develop a depth-first traversal strategy to efficiently track the
encoded surface. The resulting meshes faithfully capture the full geometric
information from the network without ad-hoc spatial discretization, achieving
unprecedented accuracy across diverse shapes and network architectures while
maintaining competitive speed.

</details>


### [296] [CHARM: Control-point-based 3D Anime Hairstyle Auto-Regressive Modeling](https://arxiv.org/abs/2509.21114)
*Yuze He,Yanning Zhou,Wang Zhao,Jingwen Ye,Yushi Bai,Kaiwen Xiao,Yong-Jin Liu,Zhongqian Sun,Wei Yang*

Main category: cs.GR

TL;DR: CHARM是一种新颖的参数化表示和生成框架，用于动漫发型建模。它使用紧凑、可逆的基于控制点的参数化方法，并将动漫发型视为一种序列“头发语言”，通过自回归Transformer进行生成，实现了高质量的动漫发型创建。该框架在重建精度和生成质量方面均达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 传统的发型建模方法难以处理动漫发型高度风格化、分段结构化的几何特征，现有技术效率低下且不适合规模化学习。CHARM旨在提供一种更高效、适合学习的动漫发型建模方法。

Method: CHARM提出一种紧凑、可逆的基于控制点的参数化方法，每个发卡由一系列控制点表示，每个点仅用五个几何参数编码。在此基础上，构建了一个自回归生成框架，将动漫发型视为序列“头发语言”，利用自回归Transformer捕捉局部几何和整体发型拓扑。

Result: CHARM在重建精度和生成质量方面均表现出最先进的性能，为动漫发型建模提供了富有表现力和可扩展的解决方案。

Conclusion: CHARM通过新颖的参数化表示和自回归生成框架，有效解决了动漫发型建模的挑战，实现了高质量、高效率的生成和编辑。

Abstract: We present CHARM, a novel parametric representation and generative framework
for anime hairstyle modeling. While traditional hair modeling methods focus on
realistic hair using strand-based or volumetric representations, anime
hairstyle exhibits highly stylized, piecewise-structured geometry that
challenges existing techniques. Existing works often rely on dense mesh
modeling or hand-crafted spline curves, making them inefficient for editing and
unsuitable for scalable learning. CHARM introduces a compact, invertible
control-point-based parameterization, where a sequence of control points
represents each hair card, and each point is encoded with only five geometric
parameters. This efficient and accurate representation supports both
artist-friendly design and learning-based generation. Built upon this
representation, CHARM introduces an autoregressive generative framework that
effectively generates anime hairstyles from input images or point clouds. By
interpreting anime hairstyles as a sequential "hair language", our
autoregressive transformer captures both local geometry and global hairstyle
topology, resulting in high-fidelity anime hairstyle creation. To facilitate
both training and evaluation of anime hairstyle generation, we construct
AnimeHair, a large-scale dataset of 37K high-quality anime hairstyles with
separated hair cards and processed mesh data. Extensive experiments demonstrate
state-of-the-art performance of CHARM in both reconstruction accuracy and
generation quality, offering an expressive and scalable solution for anime
hairstyle modeling. Project page: https://hyzcluster.github.io/charm/

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [297] [Visual Authority and the Rhetoric of Health Misinformation: A Multimodal Analysis of Social Media Videos](https://arxiv.org/abs/2509.20724)
*Mohammad Reza Zarei,Barbara Stead-Coyle,Michael Christensen,Sarah Everts,Majid Komeili*

Main category: cs.SI

TL;DR: 短视频平台充斥着健康建议，其中包含有用、误导性和有害信息。本研究不判断真伪，而是分析权威信号、叙事技巧和货币化如何包装营养和补充剂视频中的可信度。


<details>
  <summary>Details</summary>
Motivation: 研究短视频平台上的健康建议内容，分析其中权威信号、叙事技巧和货币化如何影响可信度的呈现。

Method: 收集了来自TikTok、Instagram和YouTube的152个公开视频，并对每个视频的26个特征进行了标注，涵盖视觉权威性、演讲者属性、叙事策略和参与度线索。该过程整合了自动语音识别、框架选择和多模态模型，并通过人工验证确保了准确性。

Result: 研究发现，自信的单人演讲者在工作室或家庭环境中是主导形式，临床环境很少见。权威线索（如标题、幻灯片、图表、引文）常常与说服性元素（如行业术语、参考文献、恐惧或紧迫感、对主流医学的批评、阴谋论）以及货币化手段（如销售链接、订阅号召）同时出现。参考文献和类似科学的视觉效果常与情感化和对立性叙事一起出现，而非约束性信号。

Conclusion: 在短视频平台上，与科学相关的元素（如参考文献、图表）常常与情感化、有争议性的叙事和货币化策略相结合，而非用于传达谨慎或客观的信息。

Abstract: Short form video platforms are central sites for health advice, where
alternative narratives mix useful, misleading, and harmful content. Rather than
adjudicating truth, this study examines how credibility is packaged in
nutrition and supplement videos by analyzing the intersection of authority
signals, narrative techniques, and monetization. We assemble a cross platform
corpus of 152 public videos from TikTok, Instagram, and YouTube and annotate
each on 26 features spanning visual authority, presenter attributes, narrative
strategies, and engagement cues. A transparent annotation pipeline integrates
automatic speech recognition, principled frame selection, and a multimodal
model, with human verification on a stratified subsample showing strong
agreement. Descriptively, a confident single presenter in studio or home
settings dominates, and clinical contexts are rare. Analytically, authority
cues such as titles, slides and charts, and certificates frequently occur with
persuasive elements including jargon, references, fear or urgency, critiques of
mainstream medicine, and conspiracies, and with monetization including sales
links and calls to subscribe. References and science like visuals often travel
with emotive and oppositional narratives rather than signaling restraint.

</details>


### [298] [Identifying Group Anchors in Real-World Group Interactions Under Label Scarcity](https://arxiv.org/abs/2509.20762)
*Fanchen Bu,Geon Lee,Minyoung Choe,Kijung Shin*

Main category: cs.SI

TL;DR: 识别群组中的关键人物（群组锚点）


<details>
  <summary>Details</summary>
Motivation: 研究现实世界群组互动中普遍存在的、作为群组核心的关键人物（群组锚点）的存在性，并提出识别他们的挑战。

Method: 提出了一种名为AnchorRadar的半监督学习方法，该方法能够处理标签稀疏（即只有少数群组有已知锚点）的现实场景。AnchorRadar同时利用有已知锚点和没有已知锚点的群组信息进行学习。

Result: 在13个真实世界的数据集上进行了广泛的实验，证明AnchorRadar在准确性和效率方面优于多种基线方法。具体来说，AnchorRadar的准确率更高，训练时间平均比最快的基线少10.2倍，可学习参数平均比最轻量级的基线少43.6倍。

Conclusion: AnchorRadar是一种快速有效的群组锚点识别方法，在标签稀疏的现实设定下表现出色，并且在准确性和效率上均优于现有方法。

Abstract: Group interactions occur in various real-world contexts, e.g., co-authorship,
email communication, and online Q&A. In each group, there is often a
particularly significant member, around whom the group is formed. Examples
include the first or last author of a paper, the sender of an email, and the
questioner in a Q&A session. In this work, we discuss the existence of such
individuals in real-world group interactions. We call such individuals group
anchors and study the problem of identifying them. First, we introduce the
concept of group anchors and the identification problem. Then, we discuss our
observations on group anchors in real-world group interactions. Based on our
observations, we develop AnchorRadar, a fast and effective method for group
anchor identification under realistic settings with label scarcity, i.e., when
only a few groups have known anchors. AnchorRadar is a semi-supervised method
using information from groups both with and without known group anchors.
Finally, through extensive experiments on thirteen real-world datasets, we
demonstrate the empirical superiority of AnchorRadar over various baselines
w.r.t. accuracy and efficiency. In most cases, AnchorRadar achieves higher
accuracy in group anchor identification than all the baselines, while using
10.2$\times$ less training time than the fastest baseline and 43.6$\times$
fewer learnable parameters than the most lightweight baseline on average.

</details>


### [299] [Influence of the majority group on individual judgments in online spontaneous conversations](https://arxiv.org/abs/2509.21092)
*Diletta Goglia,Davide Vega,Alessio Gandelli*

Main category: cs.SI

TL;DR: 在线匿名对话中，个体在接触多数群体意见后，会倾向于在保留多数派立场的同时，在具体观点上表现出反从众行为，且在披露后更倾向于使用说服性语言。


<details>
  <summary>Details</summary>
Motivation: 研究多数群体如何影响匿名、自发性在线对话中的个体判断形成和表达。

Method: 利用数字痕迹操作化判断，衡量对话中的分歧，并运用贝叶斯回归分析群体暴露前后判断形成的变化。同时，通过语言学分析与每个判断相关的动机，来分析判断表达的变化。

Result: 个体在接触多数群体意见后，会保留多数派的判断方向（正面或负面），但在具体立场上表现出分歧，并且在披露后使用说服性语言的频率增加。

Conclusion: 在线环境改变了与线下环境相比的社会影响形式，个体在在线匿名对话中会表现出系统性的反从众行为。

Abstract: This study investigates how the majority group influences individual judgment
formation and expression in anonymous, spontaneous online conversations.
Drawing on theories of social conformity and anti-conformity, we analyze
everyday dilemmas discussed on social media. First, using digital traces to
operationalize judgments, we measure the conversations' disagreement and apply
Bayesian regression to capture shifts of judgments formation before and after
the group's exposure. Then we analyze changes in judgment expression with a
linguistic analysis of the motivations associated with each judgment. Results
show systematic anti-conformity behaviors: individuals preserve the majority's
positive or negative orientation of judgments but diverge from its stance, with
persuasive language increasing post-disclosure. Our findings highlight how
online environments reshape social influence compared to offline contexts.

</details>


### [300] [AI-Enhanced Multi-Dimensional Measurement of Technological Convergence through Heterogeneous Graph and Semantic Learning](https://arxiv.org/abs/2509.21187)
*Siming Deng,Runsong Jia,Chunjuan Luan,Mengjia Wu,Yi Zhang*

Main category: cs.SI

TL;DR: 本文设计了一种技术收敛指数（TCI），通过深度（结合专利文本、元数据和异构图模型）和广度（香农多样性指数）两个维度来衡量技术收敛性，并使用熵权法进行综合，为创新政策和行业战略提供实践指导。


<details>
  <summary>Details</summary>
Motivation: 准确衡量技术收敛性是一个持续存在的挑战，因为其本质具有多维度和不断演变的特性。

Method: 研究设计了技术收敛指数（TCI），通过深度（基于IPC文本描述、异构图结构、异构图Transformer和Sentence-BERT）和广度（香农多样性指数）两个维度进行衡量，并使用熵权法综合。

Result: 通过与现有收敛性度量的比较，验证了TCI的优势，并通过将TCI与专利质量指标进行回归分析，建立了实证可靠性。

Conclusion: 所提出的多维度方法为管理新兴跨领域技术提供了有价值的实践见解，可用于创新政策和行业战略。

Abstract: Technological convergence refers to the phenomenon where boundaries between
technological areas and disciplines are increasingly blurred. It enables the
integration of previously distinct domains and has become a mainstream trend in
today's innovation process. However, accurately measuring technological
convergence remains a persistent challenge due to its inherently
multidimensional and evolving nature. This study designs an Technological
Convergence Index (TCI) that comprehensively measures convergence along two
fundamental dimensions: depth and breadth. For depth calculation, we use IPC
textual descriptions as the analytical foundation and enhance this assessment
by incorporating supplementary patent metadata into a heterogeneous graph
structure. This graph is then modeled using Heterogeneous Graph Transformers in
combination with Sentence-BERT, enabling a precise representation of knowledge
integration across technological boundaries. Complementing this, the breadth
dimension captures the diversity of technological fields involved, quantified
through the Shannon Diversity Index to measure the variety of technological
combinations within patents. Our final TCI is constructed using the Entropy
Weight Method, which objectively assigns weights to both dimensions based on
their information entropy. To validate our approach, we compare the proposed
TCI against established convergence measures, demonstrating its comparative
advantages. We further establish empirical reliability through a novel
robustness test that regresses TCI against indicators of patent quality. These
findings are further substantiated through comprehensive robustness checks. Our
multidimensional approach provides valuable practical insights for innovation
policy and industry strategies in managing emerging cross-domain technologies.

</details>


### [301] [Evading Overlapping Community Detection via Proxy Node Injection](https://arxiv.org/abs/2509.21211)
*Dario Loi,Matteo Silvestri,Fabrizio Silvestri,Gabriele Tolomei*

Main category: cs.SI

TL;DR: 本篇论文提出了一种基于深度强化学习（DRL）的方法，用于解决在重叠社区网络中隐藏节点社区成员身份的问题，以保护用户隐私，同时尽量保持图的拓扑结构不变。


<details>
  <summary>Details</summary>
Motivation: 在社交网络中，保护用户隐私，特别是隐藏用户的社区归属信息，是一个重要但具有挑战性的问题。现有的方法在处理重叠社区时效果不佳。

Method: 提出了一种深度强化学习（DRL）方法，该方法通过学习修改图的边来使目标节点脱离其原有社区，同时最小化对图整体结构的改变。该方法还能学习使用代理节点来辅助隐藏。

Result: 在真实数据集上的实验表明，该方法在隐藏社区成员身份的有效性和效率方面显著优于现有基线方法。

Conclusion: 该研究首次形式化地解决了在重叠社区网络中隐藏社区成员身份的问题，并提出了一种有效的DRL方法，为保护重叠社区网络中的用户隐私提供了一个有原则的工具。

Abstract: Protecting privacy in social graphs requires preventing sensitive
information, such as community affiliations, from being inferred by graph
analysis, without substantially altering the graph topology. We address this
through the problem of \emph{community membership hiding} (CMH), which seeks
edge modifications that cause a target node to exit its original community,
regardless of the detection algorithm employed. Prior work has focused on
non-overlapping community detection, where trivial strategies often suffice,
but real-world graphs are better modeled by overlapping communities, where such
strategies fail. To the best of our knowledge, we are the first to formalize
and address CMH in this setting. In this work, we propose a deep reinforcement
learning (DRL) approach that learns effective modification policies, including
the use of proxy nodes, while preserving graph structure. Experiments on
real-world datasets show that our method significantly outperforms existing
baselines in both effectiveness and efficiency, offering a principled tool for
privacy-preserving graph modification with overlapping communities.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [302] [Structuring Collective Action with LLM-Guided Evolution: From Ill-Structured Problems to Executable Heuristics](https://arxiv.org/abs/2509.20412)
*Kevin Bradley Dsouza,Graham Alexander Watt,Yuri Leonenko,Juan Moreno-Cruz*

Main category: cs.MA

TL;DR: ECHO-MIMIC是一个计算框架，通过发现简洁、可执行的启发式方法和说服性原理，将集体行动中的全局复杂性转化为每个代理可处理的结构化问题。


<details>
  <summary>Details</summary>
Motivation: 集体行动问题（例如，个体激励与集体目标不一致）通常是结构不良问题（ISPs），因为个体难以理解局部行动与全局结果之间的因果关系，且不同利益相关者的目标常常冲突。

Method: ECHO-MIMIC框架分两个阶段进行：1. ECHO（从结果中进化启发式方法）进化编码了候选行为策略的Python代码片段。2. MIMIC（机制推断与个体-集体对齐的消息传递）进化了自然语言消息，以激励代理采用这些策略。两个阶段都使用由大型语言模型驱动的进化搜索：LLM提出代码或文本变体，然后根据在模拟环境中最大化集体绩效的表现进行选择。

Result: 在农业景观管理的典型ISP案例中，ECHO-MIMIC发现的启发式方法优于基线方法，并且生成的定制化消息成功地将模拟的农民行为与景观生态目标对齐。

Conclusion: ECHO-MIMIC通过将算法规则发现与定制化沟通相结合，将集体行动的认知负担转化为简单的代理级别指令，从而使先前结构不良的问题在实践中可解，并为可扩展、自适应的策略设计开辟了新途径。

Abstract: Collective action problems, which require aligning individual incentives with
collective goals, are classic examples of Ill-Structured Problems (ISPs). For
an individual agent, the causal links between local actions and global outcomes
are unclear, stakeholder objectives often conflict, and no single, clear
algorithm can bridge micro-level choices with macro-level welfare. We present
ECHO-MIMIC, a computational framework that converts this global complexity into
a tractable, Well-Structured Problem (WSP) for each agent by discovering
compact, executable heuristics and persuasive rationales. The framework
operates in two stages: ECHO (Evolutionary Crafting of Heuristics from
Outcomes) evolves snippets of Python code that encode candidate behavioral
policies, while MIMIC (Mechanism Inference & Messaging for
Individual-to-Collective Alignment) evolves companion natural language messages
that motivate agents to adopt those policies. Both phases employ a
large-language-model-driven evolutionary search: the LLM proposes diverse and
context-aware code or text variants, while population-level selection retains
those that maximize collective performance in a simulated environment. We
demonstrate this framework on a canonical ISP in agricultural landscape
management, where local farming decisions impact global ecological
connectivity. Results show that ECHO-MIMIC discovers high-performing heuristics
compared to baselines and crafts tailored messages that successfully align
simulated farmer behavior with landscape-level ecological goals. By coupling
algorithmic rule discovery with tailored communication, ECHO-MIMIC transforms
the cognitive burden of collective action into a simple set of agent-level
instructions, making previously ill-structured problems solvable in practice
and opening a new path toward scalable, adaptive policy design.

</details>


### [303] [RadAgents: Multimodal Agentic Reasoning for Chest X-ray Interpretation with Radiologist-like Workflows](https://arxiv.org/abs/2509.20490)
*Kai Zhang,Corey D Barrett,Jangwon Kim,Lichao Sun,Tara Taghavi,Krishnaram Kenthapadi*

Main category: cs.MA

TL;DR: RadAgents是一个多智能体框架，用于胸部X光（CXR）的解读，通过结合临床先验知识、任务感知多模态推理、接地和多模态检索来解决现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的CXR解读方法存在合理性不可解释、未对齐指南、多模态证据融合不足、缺乏视觉基础、以及未能检测和解决跨工具不一致性等问题。

Method: RadAgents通过耦合临床先验知识与任务感知多模态推理，并集成接地和多模态检索来增强其能力，以解决上述问题。

Result: 该框架能够生成更可靠、更透明、更符合临床实践的输出。

Conclusion: RadAgents通过其多智能体方法，显著提高了CXR解读的质量和可靠性。

Abstract: Agentic systems offer a potential path to solve complex clinical tasks
through collaboration among specialized agents, augmented by tool use and
external knowledge bases. Nevertheless, for chest X-ray (CXR) interpretation,
prevailing methods remain limited: (i) reasoning is frequently neither
clinically interpretable nor aligned with guidelines, reflecting mere
aggregation of tool outputs; (ii) multimodal evidence is insufficiently fused,
yielding text-only rationales that are not visually grounded; and (iii) systems
rarely detect or resolve cross-tool inconsistencies and provide no principled
verification mechanisms. To bridge the above gaps, we present RadAgents, a
multi-agent framework for CXR interpretation that couples clinical priors with
task-aware multimodal reasoning. In addition, we integrate grounding and
multimodal retrieval-augmentation to verify and resolve context conflicts,
resulting in outputs that are more reliable, transparent, and consistent with
clinical practice.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [304] [Electron-beam-controlled volatile nanomechanical bistability](https://arxiv.org/abs/2509.20564)
*Toji Thomas,Kevin F. MacDonald,Eric Plum*

Main category: physics.app-ph

TL;DR: bistable oscillation of nanomechanical resonator can be controlled by electron beam


<details>
  <summary>Details</summary>
Motivation: Bistability in nanomechanical resonators can be exploited for sensing, signal processing, and memory applications due to its potential for switching and high sensitivity to external stimuli.

Method: External vibration is used to drive a doubly-clamped nanowire into the nonlinear regime of bistable oscillation. The bistable oscillation of such a nonlinear nanomechanical resonator is controlled, switched and read by an electron beam.

Result: Electron beam can control, switch and read the bistable oscillation of a nonlinear nanomechanical resonator.

Conclusion: The bistable oscillation of nanomechanical resonators can be controlled, switched and read by an electron beam, opening up possibilities for various applications.

Abstract: Bistability in nanomechanical resonators can be exploited for sensing, signal
processing, and memory applications due to its potential for switching and high
sensitivity to external stimuli. External vibration can be used to drive a
doubly-clamped nanowire into the nonlinear regime of bistable oscillation.
Here, we experimentally demonstrate that the bistable oscillation of such a
nonlinear nanomechanical resonator can be controlled, switched and read by an
electron beam.

</details>


### [305] [Hysteresis Measurements as a Diagnostic Tool: A Systematic Approach for Stability Benchmarking and Performance Projection of 2D-Materials-Based MOSFETs](https://arxiv.org/abs/2509.21315)
*Alexander Karl,Dominic Waldhoer,Theresia Knobloch,Axel Verdianu,Joël Kurzweil,Mina Bahrami,Mohammad Rasool Davoudi,Pedram Khakbaz,Bernhard Stampfer,Seyed Mehdi Sattari-Esfahlan,Yury Illarionov,Aftab Nazir,Changze Liu,Saptarshi Das,Xiao Renshaw Wang,Junchuan Tang,Yichi Zhang,Congwei Tan,Ye Li,Hailin Peng,Michael Waltl,Tibor Grasser*

Main category: physics.app-ph

TL;DR: 2D材料晶体管中的滞后现象的测量方法不标准化，导致数据不可比。本文提出了一个标准化的测量方案，以解决此问题并促进对器件稳定性的评估。


<details>
  <summary>Details</summary>
Motivation: 2D材料晶体管的滞后现象是衡量器件质量的重要指标，但目前对其测量方法和影响因素的理解不充分，导致数据不可比。

Method: 提出了一种标准的滞后测量方案，并通过理论分析了导致滞后的主要机制（电荷陷阱、载流子漂移、铁电性），并提出了实验区分这些机制的方法。

Result: 之前的滞后值测量条件随意，缺乏可比性。提出的标准化方案可以对不同技术进行比较，并能将厚器件的数据外推到等效氧化层厚度小于纳米的器件，从而系统地评估不同绝缘层/沟道组合的稳定性。

Conclusion: 标准化滞后测量方案对于评估2D材料晶体管的稳定性和可靠性至关重要，有助于筛选出更优的材料体系。

Abstract: Judging by its omnipresence in the literature, the hysteresis observed in the
transfer characteristics of emerging transistors based on 2D-materials is
widely accepted as an important metric related to the device quality. The
hysteresis is often reported with attributes like "negligible" or "small"
without giving any specifics as to how this was determined and against what
reference the measured values were compared to. Quite surprisingly, there
appears to be only a fragmentary understanding of the mechanisms actually
contributing to hysteresis and the sensitivity of the actual measurement on
various experimental parameters. We attempt to close this gap by first
providing a comprehensive theoretical analysis of the dominant mechanisms
contributing to hysteresis: charge trapping by defects from the channel or the
gate, the drift of mobile charges, and eventually ferroelectricity. We continue
by suggesting methods to experimentally distinguishing between these phenomena.
Based on these discussions it becomes clear that previously reported hysteresis
values have little meaning as they have been non-systematically recorded under
arbitrary conditions. In order to resolve this predicament, we propose a
standardized hysteresis measurement scheme to establish the hysteresis as a
comparable metric for the assessment of device stability. Our standardized
scheme ensures that hysteresis data can be effectively compared across
different technologies and, most importantly, provide a means to extrapolate
data obtained on thicker prototypes to subnanometer equivalent oxide
thicknesses. This facilitates the systematic benchmarking of insulator/channel
combinations in terms of stability, which thereby enables the screening of
material systems for more stable and reliable 2D-material-based MOSFETs.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [306] [The First Open-Source Framework for Learning Stability Certificate from Data](https://arxiv.org/abs/2509.20392)
*Zhe Shen*

Main category: eess.SY

TL;DR: 本研究发布了首个开源框架，可直接从带有噪声的真实飞行数据中学习Lyapunov稳定性证明，解决了现有系统无法处理黑箱控制器和验证稳定性的问题。


<details>
  <summary>Details</summary>
Motivation: 在2025年前，缺乏能够直接从嘈杂的真实飞行数据中学习Lyapunov稳定性证明的开源系统，也无法回答关键问题：控制器是否仍然可以稳定，特别是当闭环系统完全是黑箱时。

Method: 该框架能够从轨迹数据中学习Lyapunov函数，即使在存在现实世界噪声干扰的条件下也能进行学习。与统计异常检测器不同，该方法不只是标记偏差，而是直接判定系统是否仍可被证明是稳定的。

Result: 该方法应用于2024年SAS严重湍流事件的公开数据，发现在飞机下降过程变得异常后的60秒内，无法构建Lyapunov函数来证明系统稳定性。这是首次将数据驱动的稳定性理论方法应用于民航客机事故。

Conclusion: 研究发布了首个开源框架，可从真实飞行数据中学习Lyapunov稳定性证明，解决了黑箱控制器和验证稳定性问题，并成功应用于SAS严重湍流事件，证明了其在实际中的应用价值。

Abstract: Before 2025, no open-source system existed that could learn Lyapunov
stability certificates directly from noisy, real-world flight data. No tool
could answer the critical question: is this controller still
stabilizable-especially when its closed-loop system is a total black box. We
broke that boundary. This year, we released the first-ever open-source
framework that can learn Lyapunov functions from trajectory data under
realistic, noise-corrupted conditions. Unlike statistical anomaly detectors,
our method does not merely flag deviations-it directly determines whether the
system can still be proven stable. Applied to public data from the 2024 SAS
severe turbulence incident, our method revealed that, within just 60 seconds of
the aircrafts descent becoming abnormal, no Lyapunov function could be
constructed to certify system stability. Moreover, this is the first known
data-driven stability-theoretic method ever applied to a civil airliner
accident. And our approach works with zero access to the controller logic-a
breakthrough for commercial aircraft where control laws are proprietary and
opaque. The implementation of the proposed framework is open-sourced and
available at: https://github.com/HansOersted/stability

</details>


### [307] [Adaptive Altitude Control of a Tethered Multirotor Autogyro under Varying Wind Speeds using Differential Rotor Braking](https://arxiv.org/abs/2509.20561)
*Tasnia Noboni,Tuhin Das*

Main category: eess.SY

TL;DR: 该研究提出了一种用于系留多旋翼自转飞机的自适应高度控制策略，该策略利用风能实现能量效率和长时间部署。


<details>
  <summary>Details</summary>
Motivation: 为了实现无人机的能量效率和长时间部署，提出了一种利用可用风能来维持飞行的系留多旋翼自转飞机。

Method: 提出了一种自适应控制策略，用于估计飞机在恒定风速下近似为俯仰角二次函数的平衡高度系数。该控制器利用这些估计值进行高度控制，并通过再生差速转子制动来调节飞机的俯仰角。

Result: 该控制器能够调节高度并保持在变化的風速下稳定飞行，并在风速发生显著变化时调整以提高性能。

Conclusion: 所提出的自适应控制策略能够有效地控制系留多旋翼自转飞机的高度，并能在风速变化的情况下保持稳定和优化的飞行。

Abstract: A tethered multirotor autogyro can function as an unmanned aerial vehicle for
energy-efficient and prolonged deployment, as it uses the available wind energy
to sustain flight. This article presents an adaptive altitude control strategy
for such a device. At a constant wind speed, the equilibrium altitude can be
approximated by a quadratic function of the pitch angle. The proposed adaptive
control estimates the coefficients of this quadratic function. The estimates
are used for altitude control and to attain the maximum altitude (and minimum
horizontal drift) for a given wind speed. A feedback controller based on
regenerative differential rotor braking is used as the actuation to modulate
the autogyro's pitch angle. Implementation of the controller using a
control-oriented, higher-order dynamic model demonstrates the controller's
capability to regulate the altitude and maintain stable flights under varying
wind speeds. Based on the system's maximum altitude tracking performance, the
adaptive control is adjusted to improve performance under substantial changes
in wind speeds.

</details>


### [308] [Data-Driven State Observers for Measure-Preserving Systems](https://arxiv.org/abs/2509.20596)
*Wentao Tang*

Main category: eess.SY

TL;DR: KKL observers are proposed for data-driven state observation in discrete-time nonlinear systems with measure-preserving dynamics. The design involves learning an injective mapping and its pseudo-inverse using kernel methods, related to Koopman and Perron-Frobenius operators in an RKHS. Error analyses and a Lorenz system example are provided.


<details>
  <summary>Details</summary>
Motivation: The increasing use of data-driven control strategies necessitates learning-based state observation methods.

Method: The paper proposes using Kazantzis-Kravaris/Luenburger (KKL) observers. The observer design involves finding a nonlinear injective mapping of states and its pseudo-inverse. This is achieved through a learning-based construction related to Koopman and Perron-Frobenius operators in a Sobolev-type reproducing kernel Hilbert space (RKHS). Kernel interpolation/regression routines are used to synthesize the observer and its pseudo-inverse for various dataset scenarios (many orbits, single long orbit, snapshots).

Result: Theoretical error analyses are provided. Numerical studies are demonstrated on a chaotic Lorenz system.

Conclusion: The proposed data-driven approach using KKL observers, related to Koopman and Perron-Frobenius operators in an RKHS, offers a viable method for state observation in discrete-time nonlinear systems with measure-preserving dynamics, supported by theoretical analysis and numerical validation.

Abstract: The increasing use of data-driven control strategies gives rise to the
problem of learning-based state observation. Motivated by this need, the
present work proposes a data-driven approach for the synthesis of state
observers for discrete-time nonlinear systems with measure-preserving dynamics.
To this end, Kazantzis-Kravaris/Luenburger (KKL) observers are shown to be
well-defined, where the observer design boils down to determining a nonlinear
injective mapping of states and its pseudo-inverse. For its learning-based
construction, the KKL observer is related to the Koopman and Perron-Frobenius
operators, defined on a Sobolev-type reproducing kernel Hilbert space (RKHS) on
which they are shown to be normal operators and thus have a spectral
resolution. Hence, observer synthesis algorithms, based on kernel
interpolation/regression routines for the desired injective mapping in the
observer and its pseudo-inverse, have been proposed in various settings of
available dataset -- (i) many orbits, (ii) single long orbit, and (iii)
snapshots. Theoretical error analyses are provided, and numerical studies on a
chaotic Lorenz system are demonstrated.

</details>


### [309] [Frequency Domain Stability Conditions for Hybrid AC/DC Systems](https://arxiv.org/abs/2509.20649)
*Dahlia Saba,Dominic Groß*

Main category: eess.SY

TL;DR: 本文提出了混合交流/直流电力系统的紧凑型频域表示和相关稳定性条件，并开发了一种新的多机系统降阶阻尼绕组模型。


<details>
  <summary>Details</summary>
Motivation: 研究混合交流/直流电力系统（结合了交流和直流输电、常规发电机和换流器接口发电机）的小信号频率和直流电压稳定性。

Method: 提出一种紧凑的混合交流/直流系统频域表示和稳定性条件，这些条件可分为单个母线动力学条件和每个直流网络的条件。还开发并验证了一种新的多机系统降阶阻尼绕组模型。

Result: 所提出的系统级条件表明，只要换流器在每个直流网络上的频率响应相对于网络耦合强度足够相干，混合交流/直流系统（结合了广泛的设备）就具有拓扑结构无关的稳定性。

Conclusion: 本文为混合交流/直流电力系统的频率和直流电压稳定性分析提供了新的理论和工具，并为未来系统设计提供了指导。

Abstract: In this article, we investigate small-signal frequency and DC voltage
stability of hybrid AC/DC power systems that combine AC and DC transmission,
conventional machine- based generation, and converter-interfaced generation.
The main contributions of this work are a compact frequency domain
representation of hybrid AC/DC systems and associated stability conditions that
can be divided into conditions on the individual bus dynamics and conditions on
each DC network. The bus- level conditions apply to a wide range of
technologies (e.g., synchronous generators, synchronous condensers,
grid-forming renewables and energy storage). Moreover, the system-level
conditions establish that hybrid AC/DC systems combining a wide range of
devices are stable independently of the network topology provided that the
frequency response of converters on each DC network is sufficiently coherent
relative to the network coupling strength. Additionally, we develop and
validate a novel reduced- order damper winding model for multi-machine systems.

</details>


### [310] [Parasitic actuation delay limits the minimum employable time headway in connected and autonomous vehicles](https://arxiv.org/abs/2509.20722)
*Guoqi Ma,Prabhakar R. Pagilla,Swaroop Darbha*

Main category: eess.SY

TL;DR: 该论文提出了自适应巡航控制（ACC）、合作式自适应巡航控制（CACC）和下一代CACC（CACC+）系统的最短可行时间车头时距，并考虑了寄生执行延迟。


<details>
  <summary>Details</summary>
Motivation: 为了提高自动驾驶汽车（CAVs）的机动性和安全性，需要解决在寄生执行延迟存在的情况下，CAVs的内部稳定性和队列稳定性问题。该研究旨在为ACC、CACC和CACC+系统提供最短可行时间车头时距，以应对这些延迟。

Method: 文章基于Pontryagin的交错定理，对时间延迟系统进行了分析，将内部稳定性纳入队列稳定性条件，并推导了ACC、CACC和CACC+系统的最短可行时间车头时距。

Result: 论文提供了ACC、CACC和CACC+系统的最短可行时间车头时距，并通过数值结果验证了理论分析的有效性。

Conclusion: 该研究为在存在寄生执行延迟的情况下，确保CAVs队列的稳定性和安全性提供了理论依据和实用的最短时间车头时距建议。

Abstract: Adaptive andcooperative adaptive cruise control (ACC and CACC) and next
generation CACC (CACC+) systems usually employ a constant time headway policy
(CTHP) for platooning of connected and autonomous vehicles (CAVs). In ACC, the
ego vehicle uses onboard sensors to measure the position and velocity of the
predecessor vehicle to maintain a desired spacing. The CACC and CACC+systems
use additional information, such as acceleration(s) communicated through
vehicle-to-vehicle (V2V) communication of the predecessor vehicle(s); these
systems have been shown to result in improved spacing performance, throughput,
and safety over ACC. Parasitic dynamics are generally difficult to model and
the parasitic parameters (delay, lag, etc.) are difficult to obtain. Parasitic
actuation delays can have deleterious effects and impose limits on the mobility
and safety of CAVs. It is reasonable to assume that the bounds on parasitic
actuation delays are known a priori. For CAVs, we need to address both internal
stability and string stability in the presence of parasitic actuation delays.
This requires robustness of string and internal stability for all values of
parasitic actuation delays that are within the specified upper bound. In this
paper, we provide the minimum employable time headway for ACC, CACC, and CACC+
(`r' predecessors look-ahead), respectively. The inclusion of the internal
stability in the string stability condition is analyzed based on Pontryagin's
interlacing theorem for time delay systems. We provide comparative numerical
results to corroborate the achieved theoretical results.

</details>


### [311] [Revealing Chaotic Dependence and Degree-Structure Mechanisms in Optimal Pinning Control of Complex Networks](https://arxiv.org/abs/2509.20788)
*Qingyang Liu,Tianlong Fan,Liming Pan,Linyuan Lv*

Main category: eess.SY

TL;DR: 文章利用统计物理学的度数均值场近似，分析了驱动节点选择对网络同步的影响，提出了最优驱动节点集的解析刻画和线性时间复杂度的算法，并揭示了度数分布特征如何影响同步性能和最优节点集结构，挑战了传统基于中心度的启发式方法。


<details>
  <summary>Details</summary>
Motivation: 在复杂网络科学中，通过固定控制实现同步的驱动节点组的选择是一个基本挑战，受计算复杂性和缺乏通用理论的限制。

Method: 利用统计物理学的度数均值场（退火）近似，分析了结构度分布如何系统地控制同步性能，并推导出了全局最优固定集和线性时间复杂度算法的解析刻画。

Result: 文章提出了最优固定集，并给出了具有线性时间复杂度的算法。该最优配置表现出对其基数的混沌依赖性（不连续敏感性），单个节点的添加可能触发节点组成和控制有效性的突然变化。与基于度、中介中心度和中心度的基线方法相比，该方法在合成和经验网络上始终表现更好。文章还量化了关键度分布特征（低度饱和、高度截止和幂律指数）如何影响可实现的同步性和最优集的形式。

Conclusion: 该研究将度数异质性与谱可控性联系起来，为在各种复杂系统中选择最优驱动节点提供了机制见解和实际设计规则。

Abstract: Identifying an optimal set of driver nodes to achieve synchronization via
pinning control is a fundamental challenge in complex network science, limited
by computational intractability and the lack of general theory. Here,
leveraging a degree-based mean-field (annealed) approximation from statistical
physics, we analytically reveal how the structural degree distribution
systematically governs synchronization performance, and derive an analytic
characterization of the globally optimal pinning set and constructive
algorithms with linear complexity (dominated by degree sorting, O(N+M). The
optimal configuration exhibits a chaotic dependence--a discontinuous
sensitivity--on its cardinality, whereby adding a single node can trigger
abrupt changes in node composition and control effectiveness. This structural
transition fundamentally challenges traditional heuristics that assume
monotonic performance gains with budget. Systematic experiments on synthetic
and empirical networks confirm that the proposed approach consistently
outperforms degree-, betweenness-, and other centrality-based baselines.
Furthermore, we quantify how key degree-distribution features--low-degree
saturation, high-degree cutoff, and the power-law exponent--govern achievable
synchronizability and shape the form of optimal sets. These results offer a
systematic understanding of how degree heterogeneity shapes the network
controllability. Our work establishes a unified link between degree
heterogeneity and spectral controllability, offering both mechanistic insights
and practical design rules for optimal driver-node selection in diverse complex
systems.

</details>


### [312] [Dual-Band Flexible Endfire Filtering Antenna With Conformal Capability for Emergency Communication Applications](https://arxiv.org/abs/2509.20892)
*Fan Qin,Runkai Song,Chao Gu,Wenchi Cheng,Steven Gao*

Main category: eess.SY

TL;DR: 提出了一种单层柔性贴合滤波端射天线，该天线在两个频段上工作，并具有滤波和端射辐射的特性。


<details>
  <summary>Details</summary>
Motivation: 提出一种具有滤波和端射辐射特性的单层柔性贴合天线，以满足可扩展应急通信系统的集成需求。

Method: 天线基于两个共同设计的折叠偶极子（FDs）工作在两个频率，较低频段的FDs作为较高频段的反射器。通过为较低频段的FDs设计附加反射器，实现了双频段端射辐射。引入寄生条产生电耦合和磁耦合，实现滤波性能。

Result: 天线原型在1.37-1.45 GHz和1.89-2.07 GHz的频段范围内工作。在不同的弯曲半径下，带外辐射抑制超过11 dB。

Conclusion: 该天线设计具有双频段端射滤波辐射、柔性贴合和低剖面等优点，可用于可扩展应急通信系统。

Abstract: In this letter, a single-layer dual-band flexible conformal filtering endfire
antenna is presented. The proposed antenna is based on two co-designed folded
dipoles (FDs) working at two frequencies, where the lower-frequency FD acts as
a reflector for the higher-frequency one. Then, by devising an additional
reflector for lower-frequency FD, dual-band endfire radiation is realized.
Parasitic strips are deliberately introduced around the FDs to generate
electric coupling and magnetic coupling in the two operating bands, resulting
in significant filtering performance with four radiation nulls. With flexible
structure and single-layer configuration, the antenna design exhibits flexible
conformability with cylindrical surfaces of diverse diameters, thereby enabling
seamless integration into scalable emergency communication systems. To verify
our design concept, an antenna prototype is fabricated and measured. The
measured working frequency ranges from 1.37 to 1.45 GHz and 1.89 to 2.07 GHz.
Out-of-band radiation suppression more than 11 dB is achieved under different
bending radii. The proposed design offers several advantages including
dual-band endfire filtering radiation, flexible conformability and low-profile.

</details>


### [313] [On the convergence of a numerical scheme for a boundary controlled 1D linear parabolic PIDE](https://arxiv.org/abs/2509.20960)
*Soham Chatterjee,Vivek Natarajan*

Main category: eess.SY

TL;DR: 本文提出了一种偏微分积分方程（PIDE）的半离散近似方法，并证明了其收敛性，为研究该方程的零可控性提供了基础。


<details>
  <summary>Details</summary>
Motivation: 研究一维偏微分积分方程（PIDE）的数值解法及其可控性。

Method: 通过有限差分法和黎曼和近似处理空间导数和积分项，将PIDE转化为常微分方程（ODE）组，并证明了半离散近似解收敛于PIDE的精确解。

Result: 推导了PIDE的n阶半离散近似，并证明了其收敛性。通过数值算例进行了说明。

Conclusion: 本文提出的半离散近似方法及其收敛性证明，对于研究所考虑的PIDE的零可控性是有用的。

Abstract: We consider an 1D partial integro-differential equation (PIDE) comprising of
an 1D parabolic partial differential equation (PDE) and a nonlocal integral
term. The control input is applied on one of the boundaries of the PIDE.
Partitioning the spatial interval into $n+1$ subintervals and approximating the
spatial derivatives and the integral term with their finite-difference
approximations and Riemann sum, respectively, we derive an $n^{\rm th}$-order
semi-discrete approximation of the PIDE. The $n^{\rm th}$-order semi-discrete
approximation of the PIDE is an $n^{\rm th}$-order ordinary differential
equation (ODE) in time. We establish some of its salient properties and using
them prove that the solution of the semi-discrete approximation converges to
the solution of the PIDE as $n\to\infty$. We illustrate our convergence results
using numerical examples. The results in this work are useful for establishing
the null controllability of the PIDE considered.

</details>


### [314] [The Use of the Simplex Architecture to Enhance Safety in Deep-Learning-Powered Autonomous Systems](https://arxiv.org/abs/2509.21014)
*Federico Nesti,Niko Salamini,Mauro Marinoni,Giorgio Maria Cicero,Gabriele Serra,Alessandro Biondi,Giorgio Buttazzo*

Main category: eess.SY

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Recently, the outstanding performance reached by neural networks in many
tasks has led to their deployment in autonomous systems, such as robots and
vehicles. However, neural networks are not yet trustworthy, being prone to
different types of misbehavior, such as anomalous samples, distribution shifts,
adversarial attacks, and other threats. Furthermore, frameworks for
accelerating the inference of neural networks typically run on rich operating
systems that are less predictable in terms of timing behavior and present
larger surfaces for cyber-attacks.
  To address these issues, this paper presents a software architecture for
enhancing safety, security, and predictability levels of learning-based
autonomous systems. It leverages two isolated execution domains, one dedicated
to the execution of neural networks under a rich operating system, which is
deemed not trustworthy, and one responsible for running safety-critical
functions, possibly under a different operating system capable of handling
real-time constraints.
  Both domains are hosted on the same computing platform and isolated through a
type-1 real-time hypervisor enabling fast and predictable inter-domain
communication to exchange real-time data. The two domains cooperate to provide
a fail-safe mechanism based on a safety monitor, which oversees the state of
the system and switches to a simpler but safer backup module, hosted in the
safety-critical domain, whenever its behavior is considered untrustworthy.
  The effectiveness of the proposed architecture is illustrated by a set of
experiments performed on two control systems: a Furuta pendulum and a rover.
The results confirm the utility of the fall-back mechanism in preventing faults
due to the learning component.

</details>


### [315] [Direct Continuous-Time LPV System Identification of Li-ion Batteries via L1-Regularized Least Squares](https://arxiv.org/abs/2509.21110)
*Yang Wang,Riccardo M. G. Ferrari*

Main category: eess.SY

TL;DR: 本研究提出一种连续时间线性参数变化（CT-LPV）系统辨识方法，用于辨识锂离子电池的SOC相关参数和OCV-SOC映射。


<details>
  <summary>Details</summary>
Motivation: 锂离子电池参数辨识对于状态估计算法和性能管理至关重要，但SOC依赖性和OCV-SOC的非线性关系给辨识带来挑战。

Method: 采用CT-LPV系统辨识方法，利用三次B样条模型参数变化，并通过状态变量滤波器估计信号导数，最后通过L1正则化最小二乘问题联合辨识参数和OCV-SOC映射。

Result: 该方法在模拟数据和真实电池数据上均有效，相比于传统的RLS方法，辨识效果有所提升。

Conclusion: 所提出的CT-LPV辨识方法能够有效地处理锂离子电池参数的SOC依赖性和OCV-SOC映射的非线性关系，并提高了辨识精度。

Abstract: Accurate identification of lithium-ion battery parameters is essential for
estimating battery states and managing performance. However, the variation of
battery parameters over the state of charge (SOC) and the nonlinear dependence
of the open-circuit voltage (OCV) on the SOC complicate the identification
process. In this work, we develop a continuous-time LPV system identification
approach to identify the SOC-dependent battery parameters and the OCV-SOC
mapping. We model parameter variations using cubic B-splines to capture the
piecewise nonlinearity of the variations and estimate signal derivatives via
state variable filters, facilitating CT-LPV identification. Battery parameters
and the OCV-SOC mapping are jointly identified by solving L1-regularized least
squares problems. Numerical experiments on a simulated battery and real-life
data demonstrate the effectiveness of the developed method in battery
identification, presenting improved performance compared to conventional
RLS-based methods.

</details>


### [316] [Continuous-Time System Identification and OCV Reconstruction of Li-ion Batteries via Regularized Least Squares](https://arxiv.org/abs/2509.21116)
*Yang Wang,Riccardo M. G. Ferrari,Michel Verhaegen*

Main category: eess.SY

TL;DR: 本研究提出了一种连续时间方法，可以直接从采样数据中估计锂离子电池参数，并联合估计开路电压（OCV）和荷电状态（SOC）关系，无需离线OCV测试。


<details>
  <summary>Details</summary>
Motivation: 现有离散时间方法在电池参数估计和处理快慢动态问题方面存在局限性，本研究旨在克服这些问题。

Method: 提出一种连续时间方法，避免离散化误差，并通过将OCV-SOC曲线建模为三次B样条，利用秩和L1正则化最小二乘问题联合估计电池参数和OCV-SOC关系。

Result: 通过仿真和实际数据验证了该方法的有效性。

Conclusion: 所开发的连续时间方法能够更准确地估计锂离子电池参数，并有效地联合估计OCV-SOC关系。

Abstract: Accurate identification of lithium-ion (Li-ion) battery parameters is
essential for managing and predicting battery behavior. However, existing
discrete-time methods hinder the estimation of physical parameters and face the
fast-slow dynamics problem presented in the battery. In this paper, we
developed a continuous-time approach that enables the estimation of battery
parameters directly from sampled data. This method avoids discretization errors
in converting continuous-time models into discrete-time ones, achieving more
accurate identification. In addition, we jointly identify the open-circuit
voltage (OCV) and the state of charge (SOC) relation of the battery without
utilizing offline OCV tests. By modeling the OCV-SOC curve as a cubic B-spline,
we achieve a high-fidelity representation of the OCV curve, facilitating its
estimation. Through solving a rank and L1 regularized least squares problem, we
jointly identify battery parameters and the OCV-SOC relation from the battery's
dynamic data. Simulated and real-life data demonstrate the effectiveness of the
developed method.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [317] [Tailoring properties of Heusler alloys by elemental substitution and electron counting: (Co$_{2-α}$Mn$_α$)FeGe, Co$_2$(Fe$_{1-β}$Mn$_β$)Ge, and (Co$_{2-α}$Fe$_α$)MnGe](https://arxiv.org/abs/2509.20546)
*R. Mahat,S. Budhathoki,S. Regmi,J. Y. Law,V. Franco,W. H. Butler,A. Gupta,A. Hauser,P. LeClair*

Main category: cond-mat.mtrl-sci

TL;DR: 通过元素替换进行合理的材料设计可用于定制材料以获得理想的性能。


<details>
  <summary>Details</summary>
Motivation: 研究了三种基于 Co2FeGe 的非对等取代系列，研究了 Mn、Fe 和 Co 在 Co2FeGe 中的相互作用如何影响材料的性能。

Method: 研究了三种取代系列：(Co2−αMnα)FeGe、Co2(Fe1−βMnβ)Ge 和 (Co2−αFeα)MnGe。对这些化合物进行了实验测量和第一性原理计算。

Result: 在所有三个系列中，都可以获得单相化合物，并且它们都以具有与 Butler 等人的“4-2”规则一致的化学排序的 fcc 结构结晶。这些化合物是软磁铁，其低温饱和磁化强度符合 Slater-Pauling 规则。在 Mn 浓度较低的情况下，居里温度非常高，最高可达 1000 K。第一性原理计算表明 Mn 倾向于与 Ge 共享亚格子，这与 4-2 规则一致。计算还预测 (Co1.625Mn0.375)FeGe 具有半金属行为，而其他成分则接近半金属行为。

Conclusion: 单相合金出现在特定价电子数/晶胞（~28.5-29.75）范围内。即使对于多相样品，结构、磁性和电子特性也主要取决于价电子数，而不是所采用的特定取代方案。

Abstract: Rational material design by elemental substitution is useful in tailoring
materials to have desirable properties. Here we consider three non-equivalent
substitutional series based on Co$_2$FeGe, viz;
(Co$_{2-\alpha}$Mn$_\alpha$)FeGe, Co$_2$(Fe$_{1-\beta}$Mn$_{\beta}$)Ge,
(Co$_{2-\alpha}$Fe$_\alpha$)MnGe ($0\!\le\!\alpha\!\le\!2,
0\!\le\!\beta\!\le\!1$), and study how material properties evolve with the
interchange of Mn, Fe, and Co in Co$_2$FeGe. In all three schemes, single-phase
compounds can be obtained over a wide range of compositions: $0.125 < \alpha <
1.375 $ for (Co$_{2-\alpha}$Mn$_{\alpha}$)FeGe, $0 \!\le\! \beta \!\le\! 1$ for
Co$_2$(Fe$_{1-\beta}$Mn$_{\beta}$)Ge, and $0 \!<\! \alpha \!<\! 1.50$ for
(Co$_{2-\alpha}$Fe$_\alpha$)MnGe. All the single-phase compounds crystallise in
fcc structure with chemical ordering consistent with the ``4-2'' rule of Butler
et al. The compounds are soft ferromagnets with low temperature saturation
magnetisation agreeing with the Slater-Pauling rule. Very high Curie
temperatures are measured, with values up to 1000 K for lower Mn
concentrations. First principle calculations indicate, in the most stable
atomic configuration, Mn prefers sharing sublattice with Ge, also consistent
with the 4-2 rule. The calculations further predict half-metallic behaviour for
(Co$_{1.625}$Mn$_{0.375}$)FeGe, while finding other compositions to be nearly
half-metallic. Upon comparing the results of the three series, it is found that
single-phase alloys occur for a specific range of valence electrons per unit
cell ($\sim\!28.5\!-\!29.75$), and that even for multi-phase samples the
structural, magnetic, and electronic properties depend primarily on the number
of valence electrons and not on the specific substitution scheme employed.

</details>


### [318] [Negative Charge Transfer: Ground State Precursor towards High Energy Batteries](https://arxiv.org/abs/2509.20622)
*Eder G. Lomeli,Qinghao Li,Kuan H. Hsu,Gi-Hyeok Lee,Zengqing Zhuo,Bryant-J. Polzin,Jihyeon Gim,Boyu Shi,Eungje Lee,Yujia Wang,Haobo Li,Pu Yu,Jinpeng Wu,Zhi-Xun Shen,Shishen Yan,Lauren Illa,Josh J. Kas,John J. Rehr,John Vinson,Brian Moritz,Yi-Sheng Liu,Jinghua Guo,Yi-de Chuang,Wanli Yang,Thomas P. Devereaux*

Main category: cond-mat.mtrl-sci

TL;DR: LiCoO2等高能层状阴极材料的氧化还原机制是通过在整个电压范围内增强负电荷转移（NCT）来实现的，而不是传统观点认为的仅在低电压下以阳离子为主或在高电压下以氧为主。


<details>
  <summary>Details</summary>
Motivation: 目前，尽管有数十年的研究，但最高能量密度和商业上可行的电池仍然基于第一代阴极材料LiCoO2。其技术瓶颈在于氧化物基阴极在高工作电压下的稳定性，而根本原因在于我们并未真正理解LiCoO2的氧化还原机制。

Method: 通过原位和非原位光谱分析以及理论计算，研究了LiCoO2和LiNiO2等高能层状阴极材料的氧化还原机制。

Result: 研究表明，这些材料在高能层状阴极材料（如LiCoO2和LiNiO2）的整个充电过程中，都通过增强负电荷转移（NCT）的基态来工作，即NCT的演变本身就是内在的氧化还原机制，与电压范围无关。NCT本质上涉及高共价性和氧空穴，从而在没有传统氧化还原中心的情况下优化了LiCoO2的性能。NCT的水平，即配体空穴的数量，能够解释许多看似有争议的结果。

Conclusion: 氧化还原机制的重新定义揭示了开发可行的、高能量电池电极的途径。

Abstract: Modern energy applications, especially electric vehicles, demand high energy
batteries. However, despite decades of intensive efforts, the highest energy
density and commercially viable batteries are still based on LiCoO2, the very
first generation of cathode materials. The technical bottleneck is the
stability of oxide-based cathodes at high operating voltages. The fundamental
puzzle is that we actually never understood the redox mechanism of LiCoO2.
Conventional wisdom generally defines redox to be centered on cations at low
voltages, and on anions, i.e. oxygen, at high voltages by forming oxidized
chemical states like O2 or peroxo-species. Here, through in-situ and ex-situ
spectroscopy coupled with theoretical calculations, we show that high-energy
layered cathodes, represented by LiCoO2 and LiNiO2, operate through enhancement
of negative charge transfer (NCT) ground states upon charging throughout the
whole voltage range - i.e., NCT evolution itself is the intrinsic redox
mechanism regardless of voltage ranges. NCT inherently engages high covalency
and oxygen holes, leading to optimized performance without conventional redox
centers in LiCoO2. The level of NCT, i.e., number of ligand holes, naturally
explains many seemingly controversial results. The redefinition of redox
mechanism reveals the pathway toward viable high energy battery electrodes.

</details>


### [319] [Atomistic Insights into Cu/amorphous-Ta$_x$N Interfacial Adhesion via Machine Learning Interatomic Potentials: Effects of Stoichiometry and Interface Construction](https://arxiv.org/abs/2509.20662)
*Jeong Min Choi,Jaehoon Kim,Ji-Hwan Lee,Won-Joon Son,Seungwu Han*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究使用机器学习势能和分子动力学模拟，研究了铜和不同钽氮化物（Ta$_x$N）扩散阻挡层的界面粘附性，并探讨了不同界面构建方法和钽含量对粘附强度的影响，以及揭示了导致界面内聚破坏的原子机制，为优化互连系统和实现无衬垫互连技术提供了指导。


<details>
  <summary>Details</summary>
Motivation: Cu/Ta$_x$N扩散阻挡层的界面粘附性对于半导体器件中Cu互连系统的机械可靠性和完整性至关重要，但目前缺乏系统研究钽含量变化对Cu/a-Ta$_x$N界面粘附强度的影响。

Method: 采用机器学习势能（MLIPs）进行受控分子动力学（SMD）模拟，并评估了静态弛豫、高温退火和模拟Cu沉积三种界面构建方法，研究了不同钽含量（x=1, 2, 4）下Cu/a-Ta$_x$N界面的粘附强度，并进行了原子应力应变分析和内聚破坏机理探索。

Result: 通过SMD模拟定量表征了界面的峰值力和粘附功，揭示了界面形态对粘附强度的关键作用，并发现了通过在Cu层中引入Ta原子可以增强界面的内聚强度。

Conclusion: 研究证明了机器学习势能驱动的模拟能够揭示界面形态与粘附行为之间的原子尺度关系，为通过原子尺度工程增强本征阻挡层粘附性提供了见解，并为实现无衬垫互连技术提供了可能性。

Abstract: Accurate understanding and control of interfacial adhesion between Cu and
Ta$_x$N diffusion barriers are essential for ensuring the mechanical
reliability and integrity of Cu interconnect systems in semiconductor devices.
Amorphous tantalum nitride (a-Ta$_x$N) barriers are particularly attractive due
to their superior barrier performance, attributed to the absence of grain
boundaries. However, a systematic atomistic investigation of how varying Ta
stoichiometries influences adhesion strength at Cu/a-Ta$_x$N interfaces remains
lacking, hindering a comprehensive understanding of interface optimization
strategies. In this study, we employ machine learning interatomic potentials
(MLIPs) to perform steered molecular dynamics (SMD) simulations of Cu/a-Ta$_x$N
interfaces. We simultaneously evaluate three distinct interface construction
approaches--static relaxation, high-temperature annealing, and simulated Cu
deposition--to comprehensively investigate their influence on adhesion strength
across varying Ta compositions ($x=1, 2, 4$). Peak force and work of adhesion
values from SMD simulations quantitatively characterize interface strength,
while atomic stress and strain analyses elucidate detailed deformation
behavior, highlighting the critical role of interfacial morphologies.
Additionally, we explore the atomistic mechanisms underlying cohesive failure,
revealing how targeted incorporation of Ta atoms into Cu layers enhances the
cohesive strength of the interface. This study demonstrates how MLIP-driven
simulations can elucidate atomic-scale relationships between interface
morphology and adhesion behavior, providing insights that can guide future
atomistic engineering strategies toward enhancing intrinsic barrier adhesion,
potentially enabling liner-free interconnect technologies.

</details>


### [320] [Robust Ferrimagnetic Ground State and Suppressed Superconductivity in Two-Dimensional HC6](https://arxiv.org/abs/2509.20672)
*Jakkapat Seeyangnok,Udomsilp Pinsook*

Main category: cond-mat.mtrl-sci

TL;DR: HC6的费米面电子态密度高，具有超导潜力，但其更稳定的亚铁磁基态抑制了超导性。


<details>
  <summary>Details</summary>
Motivation: 探索二维氢化石墨烯（HC6）作为电子相的平台，特别是其超导和磁性特性。

Method: 利用自旋极化第一性原理计算来研究HC6的磁性和超导性。

Result: HC6以亚铁磁基态稳定存在，能量比顺磁金属性低0.175 eV/晶胞。超导虽然能降低能量7 meV，但仍为亚稳态。

Conclusion: 磁性在HC6中起主导作用，高电子态密度会驱动竞争不稳定性，为设计碳基磁性系统提供了原理。

Abstract: Two-dimensional hydrogenated graphene (HC6) represents a promising platform
for exploring emergent electronic phases. Owing to its high electronic density
of states at the Fermi level, HC6 is expected to support phonon-mediated
superconductivity, with a calculated critical temperature Tc of 37.4 K in the
paramagnetic metallic phase. However, spin-polarized first-principles
calculations reveal that HC6 stabilizes in a ferrimagnetic ground state, which
is energetically favored by 0.175 eV per unit cell over the paramagnetic
metallic phase. This large energy difference significantly exceeds kB T at room
temperature, indicating robust magnetic order. Although the superconducting
condensation energy lowers the total energy by about 7 meV, the superconducting
phase remains metastable. These results highlight the dominant role of
magnetism in HC6 and illustrate how a high electronic density of states can
drive competing instabilities in hydrogenated two-dimensional materials,
offering design principles for carbon-based magnetic systems.

</details>


### [321] [Intrinsic antiferromagnetic half-metal and topological phases in the ferrovalley states of the sliding bilayer altermagnets](https://arxiv.org/abs/2509.20687)
*Shihao Zhang*

Main category: cond-mat.mtrl-sci

TL;DR: 发现了一种新的材料——滑动双层超磁体，它结合了铁谷态、反铁磁性和半金属特性，并可能在自旋电子学领域有应用前景。


<details>
  <summary>Details</summary>
Motivation: 探索在铁谷态的滑动双层超磁体中是否存在本征反铁磁性半金属和拓扑相。

Method: 利用第一性原理计算，构建了由具有小带隙的超磁体单层组成的双层系统，研究了层间跳跃和滑动工程诱导的铁谷态，并采用微观模型和有效哈密顿量进行了验证。

Result: 发现了具有本征反铁磁性半金属特性的铁谷态，其中一个谷（一个自旋通道）具有直带隙，另一个谷（相反的自旋通道）发生带反演。滑动方向的调整可以实现不同自旋电子的半金属之间的转换，并伴随着无隙表面态的切换。此外，还暗示了陈绝缘体和无隙表面态的存在。

Conclusion: 滑动双层超磁体可以实现本征反铁磁性半金属和拓扑相，为自旋电子学的潜在应用奠定了基础。

Abstract: Altermagnetism is characterized by non-relativistic spin splitting and zero
total magnetic moments. In this work, intrinsic antiferromagnetic half-metallic
and topological phases were discovered within the ferrovalley states of sliding
bilayer altermagnets. We construct the bilayer system by utilizing altermagnet
monolayers with a small bandgap. The inter-layer hopping phenomenon leads to a
reduction in bandgaps, and sliding engineering induces ferrovalley states.
Taking the V$_2$OSSe system for example, first-principles calculations indicate
that the spin-dependent inter-layer hopping in the ferrovalley state ensures a
direct gap in one valley (one spin channel) and band inversion in the other
valley (opposite spin channel), which is manifested as an intrinsic
antiferromagnetic half-metal. The microscopic model and effective Hamiltonian
employed in this research confirm the universal spin-dependent inter-layer
hopping in the sliding altermagnet bilayer. Further calculations imply the
existence of Chern insulator and gapless surface states in the sliding
altermagnet bilayer. Adjusting the sliding direction can achieve the transition
between different half-metals with conducting electrons of different spins,
accompanied by the switching of gapless surface states of opposite spins. This
research lays a foundation for the potential applications of intrinsic
antiferromagnetic half-metals and topological phases in spintronics.

</details>


### [322] [Magnetic order tuning of excitons in the magnetic semiconductor CrCl$_3$ through strain](https://arxiv.org/abs/2509.20761)
*Ali Ebrahimian,Francisco J. García-Vidal,Juan J. Palacios*

Main category: cond-mat.mtrl-sci

TL;DR: CrCl3单分子层的磁有序会影响激子振荡器强度，可通过应变实现光学响应的二元切换。


<details>
  <summary>Details</summary>
Motivation: 研究磁振子-激子耦合在少层磁体中的应用，特别是CrCl3单分子层中的光学可调性。

Method: 利用有效的Bethe-Salpeter方程来评估应变引起的磁有序（铁磁态到反铁磁态）转变对激子响应的影响。

Result: 激子在磁有序转变时空间局域化发生改变，导致激子峰的振荡器强度发生显著变化，并出现位移。

Conclusion: CrCl3单分子层中的激子响应对磁有序转变敏感，应变可作为实现光学响应二元切换的手段。

Abstract: Magnon-exciton coupling provides an unprecedented opportunity for the optical
tunability of spin information and, viceversa, for the magnetic control of the
optical response. Few-layered magnets are an ideal platform for the
experimental study of this coupling, in part due to the strong excitonic
character of the optical response in (quasi-)two dimensions. Here, we
demonstrate a strong dependence of the excitonic oscillator strength on the
magnetic order in a monolayer of chromium trichloride CrCl$_3$. Solving an
effective Bethe-Salpeter equation, we evaluate the changes in the excitonic
response as the magnetic order switches from the ferromagnetic state to the
antiferromagnetic state when strain is applied. Our results reveal an abrupt
change in the spatial localization of the excitons across the transition, which
translates into a strong shift and a change of the oscillator strength of the
excitonic peaks. This suggests the possibility of using strain as a binary
switch of the optical response in this material.

</details>


### [323] [Uniaxial negative thermal expansion in a weak-itinerant-ferromagnetic phase of CoZr$_{2}$H$_{3.49}$](https://arxiv.org/abs/2509.20765)
*Yuto Watanabe,Kota Suzuki,Takayoshi Katase,Akira Miura,Aichi Yamashita,Yoshikazu Mizuguchi*

Main category: cond-mat.mtrl-sci

TL;DR: CoZr$_{2}$H$_{3.49}$的弱非定域铁磁相表现出独特的单轴负热膨胀（NTE）行为，其中晶格常数$c$在居里温度（139 K）以下表现出NTE行为，这与Co-Co链的扩展有关。


<details>
  <summary>Details</summary>
Motivation: 探究氢化物插入对CoZr$_{2}$的异常热膨胀（ATE）行为的影响，特别是氢化物插入是否会引起新的热膨胀行为。

Method: 通过粉末同步X射线衍射（SXRD）对CoZr$_{2}$H$_{3.49}$进行分析，并使用Arrott图法确定居里温度（$T_{\mathrm{C}}$），估计Rhodes-Wohlfarth比率，以及提取晶格常数$a$和$c$随温度的变化。

Result: 确定CoZr$_{2}$H$_{3.49}$的居里温度为139 K，Rhodes-Wohlfarth比率为3.49，表明出现了非定域铁磁性。发现晶格常数$c$在$T_{\mathrm{C}}$以下表现出NTE行为。

Conclusion: CoZr$_{2}$H$_{3.49}$的弱非定域铁磁相表现出独特的单轴NTE行为，其中晶格常数$c$在$T_{\mathrm{C}}$以下表现出NTE行为。这种行为可以通过费米能级附近抗菌性的Co3$dz^{2}$部分态密度锐化来理解，这与沿$c$轴方向延伸的一维Co-Co链的扩展有关。

Abstract: We discovered unique uniaxial negative thermal expansion (NTE) behavior for a
weak-itinerant-ferromagnetic phase of CoZr$_{2}$H$_{3.49}$. CoZr$_{2}$ is known
as a superconductor exhibiting uniaxial NTE along the $c$-axis, which is called
anomalous thermal expansion (ATE). Additionally, CoZr$_{2}$ is also known as a
well-absorbent of hydrogen, and hydrogen insertion raises weak-itinerant
ferromagnetism instead of superconductivity. However, the influence of hydrogen
insertion on ATE behavior in this system is still unclear. To investigate it,
we performed powder synchrotron X-ray diffraction (SXRD) for
CoZr$_{2}$H$_{3.49}$. Through Arrott plots analysis, we determined the Curie
temperature ($T_{\mathrm{C}}$) to be 139 K, and the Rhodes-Wohlfarth ratio was
estimated to be 3.49, which clearly exceeds 1, suggesting the itinerancy of
emerging ferromagnetism. Temperature dependencies of lattice constants $a$ and
$c$ were extracted from powder SXRD analyses, and we revealed that lattice
constant $c$ exhibited NTE behavior below $T_{\mathrm{C}}$. The uniaxial NTE
behavior along the $c$-axis can be understood by sharpening an antibonding
Co3$dz^{2}$ partial density of states near the Fermi level, linked to the
expansion of a one-dimensional Co-Co chain running parallel to the $c$-axis.

</details>


### [324] [Defect-Charge-Driven 90° Switching in HfO2](https://arxiv.org/abs/2509.20828)
*Muting Xie,Hongyu Yu,Zhihao Dai,Yingfen Wei,Changsong Xu,Hongjun Xiang*

Main category: cond-mat.mtrl-sci

TL;DR: Hafnium dioxide (HfO2) 铁电材料在 [111] 场作用下，由氧空位诱导的 90 度翻转通路相比于 180 度翻转通路，表现出更优的抗疲劳性，且具有相同的极化强度，并提出电荷是影响铁电材料极化动力学的一般性调控参数。


<details>
  <summary>Details</summary>
Motivation: 未解决的铪（HfO2）铁电材料 90 度翻转通路的微观机制，以及其抗疲劳性。

Method: 通过引入带电氧空位，并结合晶体几何和旋转通路性质，研究 90 度翻转通路在 HfO2 中的行为。

Result: 带电氧空位诱导的 90 度翻转通路在 [111] 场作用下变得占优，且抗疲劳性优于 180 度翻转通路，极化强度相同（2Pr=60 μC/cm^2）。

Conclusion: 铪（HfO2）铁电材料的 90 度翻转通路在带电氧空位存在时变得显著，其抗疲劳性优于 180 度翻转通路，表明缺陷电荷是调控铁电材料极化动力学的重要参数。

Abstract: Hafnium dioxide (HfO2) is a CMOS-compatible ferroelectric showing both
180{\deg} and 90{\deg} switching, yet the microscopic nature of the 90{\deg}
pathway remains unresolved. We show that the 90{\deg} rotation pathway,
negligible in pristine HfO2, becomes dominant under E// [111] when induced by
charged oxygen vacancies. This pathway is more fatigue-resistant than the
180{\deg} reversal pathway, while delivering the same polarization change along
[111] (2Pr=60 {\mu}C/cm^2 ). This charge-driven switching arises from two
factors: the crystal geometry of HfO2 and the intrinsic nature of rotational
pathways, the latter suggesting a possible general tendency for defect charge
to bias rotation over reversal in ferroelectrics. Together these findings
reveal a pathway-level origin of fatigue resistance and establish defect charge
as a general control parameter for polarization dynamics.

</details>


### [325] [Cu2XSiS4 (X = Ge, Sn, and Pb) materials for solar-cell applications: A DFT+SCAPS-1D simulation](https://arxiv.org/abs/2509.20845)
*H. Laltlanmawii,L. Celestine,R. Zosiamliana,B. Chettri,S. Bhattarai,K. C. Bhamu,D. P. Rai*

Main category: cond-mat.mtrl-sci

TL;DR: Cu2XSiS4 (X = Ge, Sn, Pb) is investigated for photovoltaic applications using DFT and MD simulations. Ge-based compounds show the highest potential PCE of 23.46% as absorber layers in solar cells.


<details>
  <summary>Details</summary>
Motivation: The paper investigates Cu-based quaternary chalcogenides Cu2XSiS4 (X = Ge, Sn, and Pb) for their potential applications in photovoltaics, particularly studying the effects of Ge and Sn substitution.

Method: The study employs first-principles density functional theory (DFT) to calculate structural, electronic, optical, and mechanical properties. Ab-initio molecular dynamics (MD) simulations are used to verify structural and thermal stability. A heterostructure solar cell model (FTO/TiO2/Cu2XSiS4/CuO/Au) is simulated using SCAPS-1D to obtain I-V characteristics and power conversion efficiency (PCE), with DFT results serving as inputs.

Result: The compounds exhibit indirect band gaps between 1.0--1.56 eV, suitable for solar energy harvesting, with absorption peaks in the visible region. Simulated PCE values for X=Ge, Sn, and Pb are 23.46%, 23.29%, and 22.60%, respectively. The Ge-based system shows the highest PCE due to its optimal band gap.

Conclusion: Cu2XSiS4 compounds, particularly the Ge-based system, show promise as absorber layers in heterostructure solar-cell applications due to their suitable electronic and optical properties, and high simulated power conversion efficiencies.

Abstract: By means of the first-principles density functional theory (DFT),
I2-II-IV-VI4 type Cu-based quaternary chalcogenides Cu 2 XSiS 4 (X = Ge, Sn,
and Pb) have been thoroughly investigated. We report the study of Ge and Sn
substitution in the divalent cation site for their potential applications in
photovoltaics for the first time. The structural, electronic, optical, and
mechanical properties have been calculated. The structural and thermal
stability is verified by calculating the elastic constants, formation energy
and total potential energy at 300 K from the ab-initio molecular dynamics (MD)
simulation. The compounds under our investigation exhibited an indirect band
gap in the range of 1.0--1.56 eV, suitable for energy harvesting by trapping
the sunlight. The presence of absorption peaks within the visible region
complements their potential in photovoltaic applications. For further
validation, we have designed a model of a heterostructure
(FTO/TiO2/Cu2XSiS4/CuO/Au) solar cell, and a numerical simulation has been
performed by solving the Poisson equation and continuity equations to obtain
the I-V characteristic by using SCAPS-1D. All the inputs needed for solar- cell
simulation in SCAPS-1D have been taken from the DFT results. The corresponding
Power Conversion Efficiency (PCE) is denoted by {\eta}% and their respective
values for X=Ge, Sn and Pb are 23.46%, 23.29% and 22.60%, at room temperature.
The Ge-based system exhibits the highest {\eta}%, owing to its band gap value
in the visible range of the solar spectrum. Thus, we report that Ge-based
compounds may act as a promising absorber layer in heterostructure solar-cell
applications.

</details>


### [326] [SMC-X: A Distributed Scalable Monte Carlo Simulation Method for Chemically Complex Alloys](https://arxiv.org/abs/2509.20949)
*Xianglin Liu,Kai Yang,Fanli Zhou,Pengxiang Xu*

Main category: cond-mat.mtrl-sci

TL;DR: 本工作通过分布式计算改进了SMC-X方法，实现了对高熵合金（HEA）的更大规模和更长时间尺度的原子模拟，解决了以往模拟的局限性，并能更好地解释实验现象。


<details>
  <summary>Details</summary>
Motivation: 为了准确预测多组分合金中复杂的化学演化，需要能够达到足够大时空尺度的精确原子模拟方法。

Method: 通过在GPU或CPU上进行分布式计算，改进了SMC-X方法，以达到更大的时空尺度。

Result: 实现了160亿原子、达到微米尺度的HEA系统模拟，以及10亿原子、模拟超过三百万步（接近分钟尺度）的HEA系统模拟。通过与Lifshitz-Slyozov-Wagner（LSW）理论结合，证明了大规模模拟对于理解和预测HEA中纳米沉淀物尺寸的重要性。

Conclusion: 改进后的SMC-X方法在大时空尺度上模拟高熵材料的化学复杂性方面具有巨大潜力，能够实现模拟驱动的探索。

Abstract: To predict the complex chemical evolution in multicomponent alloys, it is
highly desirable to have accurate atomistic simulation methods capable of
reaching sufficiently large spatial and temporal scales. In this work, we
advance the recently proposed SMC-X method through distributed computation on
either GPUs or CPUs, pushing both spatial and temporal scales of atomistic
simulation of chemically complex alloys to previously inaccessible scales. This
includes a 16-billion-atom HEA system extending to the micrometer regime in
space, and a 1-billion-atom HEA evolved over more than three million Monte
Carlo swap steps, approaching the minute regime in time. We show that such
large-scale simulations are essential for bridging the gap between experimental
observations and theoretical predictions of the nanoprecipitate sizes in HEAs,
based on analysis using the Lifshitz-Slyozov-Wagner (LSW) theory for
diffusion-controlled coarsening. This work demonstrates the great potential of
SMC-X for simulation-driven exploration of the chemical complexity in
high-entropy materials at large spatial and temporal scales.

</details>


### [327] [Computing finite--temperature elastic constants with noise cancellation](https://arxiv.org/abs/2509.20951)
*Debashish Mukherji,Marcus Müller,Martin H. Müser*

Main category: cond-mat.mtrl-sci

TL;DR: 通过泛化一种用于压电耦合系数的噪声消除方法，提出了一种在有热涨落的情况下计算弹性常数的新方法。


<details>
  <summary>Details</summary>
Motivation: 传统的有限温度方法在计算弹性常数时，由于信噪比低或强烈的非谐效应，存在一些问题。本研究旨在解决这些问题，提供一种更精确的计算方法。

Method: 在已平衡的固体上施加微小应变，并采用相同的温控方案进行模拟。通过比较施加应变和未施加应变（或反向应变）的参考系统的模拟结果，计算应力差并确定弹性常数。

Result: 所提出的方法显著降低了热噪声，能够更精确地计算各种材料（包括晶体氩、有序硅、无定形硅、聚甲基丙烯酸甲酯和纤维素衍生物）的弹性常数。

Conclusion: 该方法能够有效地在有热涨落的情况下计算弹性常数，并且适用于多种有序和无序系统。

Abstract: Elastic constants are central material properties, frequently reported in
experimental and theoretical studies. While their computation is
straightforward in the absence of thermal fluctuations, finite--temperature
methods often suffer from poor signal--to--noise ratios or the presence of
strong anharmonic effects. Here, we show how to compute elastic constants in
thermal ordered and disordered systems by generalizing a noise--cancellation
method originally developed for piezoelectric coupling coefficients. A slight
strain is applied to an equilibrated solid. Simulations of both the strained
and unstrained (or oppositely strained) reference systems are performed using
identical thermostatting schemes. As demonstrated theoretically and with
generic one--dimensional models, this allows stress differences to be evaluated
and elastic constants to be determined with much reduced thermal noise. We then
apply this approach across a diverse set of systems, spanning crystalline
argon, ordered silicon as well as amorphous silicon, poly(methyl methacrylate),
and cellulose derivatives.

</details>


### [328] [A GND-based back stress model for reverse loading in metal sheets with consideration of GNB](https://arxiv.org/abs/2509.20996)
*Gyu-Jang Sim,Jehyun You,SeongHwan Choi,Youngjae Kim,Chung An Lee,Hyunki Kim,Donghwan Noh,Myoung-Gyu Lee*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究提出了一种结合了晶体塑性有限元方法（CPFEM）和基于几何必要位错（GNDs）和晶界（GNBs）的物理驱动背应力模型的先进技术，用于精确预测超薄金属板材的回弹和成形性。


<details>
  <summary>Details</summary>
Motivation: 在板材成形过程中，复杂的加载路径变化（如拉伸后压缩）下的反向加载行为难以准确预测，尤其是对于超薄板材，由于压屈等现象导致实验表征困难。

Method: 采用晶体塑性有限元方法（CPFEM），并引入了基于几何必要位错（GNDs）和晶界（GNBs）的物理驱动背应力模型。该模型考虑了晶粒尺寸效应（包括Hall-Petch和Bauschinger效应），并通过单一的、依赖于晶粒尺寸的背应力参数来捕捉这些效应，从而仅利用不同晶粒尺寸试样的拉伸数据即可预测反向加载行为。研究中，通过拟合两种微观结构（一种为原样接收，一种为退火处理）的拉伸应力-应变曲线来校准背应力参数。

Result: 在未采用拉压（T-C）数据进行校准的情况下，该模型能够准确预测低碳钢（0.64 mm厚）的反向加载行为，并预测超薄SUS316（0.083 mm厚）的拉压弯（T-B）响应。可识别性分析表明，模型参数可由可用数据唯一确定。

Conclusion: 该研究提出的物理可解释框架提供了一种有效且鲁棒的方法来预测薄金属板的反向加载行为，克服了实验上的限制。

Abstract: Accurate prediction of springback and formability in sheet metal forming
requires understanding reverse loading behavior under complex loading path
changes, such as tension followed by compression. However, for ultra-thin
sheets experimental characterization of such behavior is difficult due to
compressive instability like plastic buckling. This study presents a crystal
plasticity finite element method (CPFEM) incorporating a physically motivated
back stress model based on geometrically necessary dislocations (GNDs) and
boundaries (GNBs). The model captures grain size effects, including the
Hall-Petch and Bauschinger effects, through a single grain size-dependent back
stress parameter, enabling reverse loading prediction using only tensile data
from specimens with different grain sizes. The back stress parameter was
calibrated by fitting tensile stress-strain curves from two microstructures -
one as-received and one annealed. Without using Tension-Compression (T-C) data
for calibration, the model accurately predicted reverse loading behavior in
low-carbon steel (0.64 mm thick) and Tension-Bending (T-B) responses in
ultra-thin SUS316 (0.083 mm thick) when the developed theory was incorporated
to an upscaled anisotropic hardening model. Identifiability analysis confirmed
that the model parameters are uniquely determined by the available data. This
physically interpretable framework provides an efficient and robust means to
predict reverse loading in thin metal sheets, overcoming experimental
limitations.

</details>


### [329] [Avalanche-like lithium intercalation and intraparticle correlations in graphite](https://arxiv.org/abs/2509.21047)
*Jiho Han,George S. Phillips,Alice J. Merryweather,Juhwan Lim,Christoph Schnedermann,Robert L. Jack,Clare P. Grey,Akshay Rao*

Main category: cond-mat.mtrl-sci

TL;DR: 石墨在锂离子电池中作为负极材料的广泛应用，但其锂离子嵌入过程和动力学仍未被充分理解。本研究利用原位光学显微镜和随机场伊辛模型，揭示了在稀疏阶段，单石墨颗粒经历快速、局域性的雪崩式（去）嵌入过程，形成微米级区域在几秒钟内（去）嵌入。


<details>
  <summary>Details</summary>
Motivation: 石墨作为锂离子电池负极材料，其锂离子嵌入过程和动力学，尤其是在稀疏阶段，仍然缺乏根本性的理解，特别是关于对称性破缺相变如何发生。

Method: 利用原位光学显微镜结合随机场伊辛模型。

Result: 在稀疏阶段，单石墨颗粒经历快速、局域性的雪崩式（去）嵌入，形成微米级区域在几秒钟内（去）嵌入。这些雪崩行为与无序材料中的相变行为相似。研究表明，静态无序会干扰离子填充动力学，导致阶段间的伪连续转变，并能解释实验电化学和温度依赖的雪崩动力学。最后，开发了一种时空分析雪崩的方法，揭示了稀疏阶段内区域间的空间异质连通性和时间模式。

Conclusion: 该研究强调了局部和静态无序在引发意外相变行为中的作用，并为研究分层电池材料提供了新工具和新概念。

Abstract: Graphite is the most widely used anode material in lithium-ion batteries with
over 98% market share. However, despite its first application over 30 years
ago, the lithium insertion processes and associated dynamics in graphite remain
poorly understood, especially for the dilute stages. A fundamental
understanding of how the symmetry-breaking phase transitions occur
pseudo-continuously under operating conditions is still lacking. Here, we
provide a unified picture of ion intercalation dynamics during the dilute
stages of graphite intercalation, using operando optical microscopy combined
with random field Ising modelling. We show that during the dilute stages,
single graphite particle undergoes rapid, localised avalanche-like
(de)intercalation, leading to micron-sized regions (de)intercalating within
seconds. These avalanches are reminiscent of phase transition behaviour seen in
disordered materials such as martensitic transformations, Barkhausen noise and
ferroelectric/elastic materials - associated with step changes in the order
parameter, where the system changes from one phase to another under an applied
driving force by jumping from one metastable state to another. Here, using a
modified random field Ising model, we relate these avalanches to static
disorder in graphite, which disrupts ion filling dynamics, leading to
pseudo-continuous transitions between stages, accounting for the experimental
electrochemistry profile as well as the temperature dependent avalanche
dynamics. Finally, we develop a methodology to spatio-temporally analyse
avalanches between intraparticle regions, revealing spatially heterogeneous
connectivity and temporal patterns between regions during the dilute stages.
Our work highlights the role of local and static disorder in eliciting
unexpected phase transition behaviour, and provides new tools and concepts for
studying layered battery materials.

</details>


### [330] [Low Temperature MOCVD Synthesis of high-mobility 2D InSe](https://arxiv.org/abs/2509.21082)
*Robin Günkel,Oliver Maßmeyer,Markus Stein,Sebastian Anhäuser,Kalle Bräumer,Rodrigo Sandoval Rodriguez,Daniel Anders,Badrosadat Ojaghi Dogahe,Max Bergmann,Milan Solanki,Nils Fritjof Langlotz,Johannes Glowatzki,Jürgen Belz,Andreas Beyer,Gregor Witte,Sangam Chatterjee,Kerstin Volz*

Main category: cond-mat.mtrl-sci

TL;DR: MOCVD在低温下通过控制Se/In前驱体比率和生长温度，在蓝宝石衬底上成功合成了二维InSe，并通过Raman光谱、AFM、EDS和STEM等手段进行了表征，确认了InSe的形成条件，并发现了InSe与蓝宝石衬底之间的外延生长关系。


<details>
  <summary>Details</summary>
Motivation: 由于InSe在逻辑和光电器件领域的应用潜力，但其在MOCVD生长过程中相纯度控制困难，需要系统研究以克服挑战。

Method: 通过改变Se/In前驱体比率和生长温度，在蓝宝石衬底上低温MOCVD生长InSe，并利用Raman光谱、AFM、EDS、STEM和XRD等手段进行表征。

Result: 发现了InSe的相图，确定了InSe的形成条件，并观察到InSe与蓝宝石衬底之间的外延生长关系，优化的样品在可见光范围内具有强光吸收和高电子迁移率。

Conclusion: 低温MOCVD是一种可行的、有前景的合成高质量二维InSe的方法，适用于器件集成，并为未来在光电子和逻辑器件中的应用奠定了基础。

Abstract: Two-dimensional (2D) indium selenide (InSe) is a layered semiconductor with
high electron mobility and a tunable band gap ranging from 1.25 eV in the bulk
to 2.8 eV in the monolayer limit. These properties make these materials strong
candidates for future logic and optoelectronic devices. However, growing
phase-pure InSe remains challenging due to the complex indium-selenium (In-Se)
phase diagram. This complexity and the sensitivity of chemical precursors to
growth conditions make it difficult to control which In-Se phase forms during
synthesis during, e.g., metal-organic chemical vapor deposition (MOCVD).
Despite the challenges, MOCVD is considered the most promising approach for
growing InSe, as it enables wafer-scale, uniform, and controllable
deposition-key requirements for device integration. In this study, we present a
systematic investigation of InSe synthesis via MOCVD on c-plane sapphire
substrates at low temperatures, which are highly relevant for various
integration schemes. By varying the Se/In precursor ratio and the growth
temperature, we create a phase diagram that covers the In-rich, equal
stoichiometric, and Se-rich InxSey phases. Raman spectroscopy and atomic force
microscopy, supported by energy dispersive X-ray spectroscopy and scanning
transmission electron microscopy, confirm conditions, under which the formation
of 2D InSe is observed. Atomically-resolved cross-sectional scanning
transmission electron microscopy also reveals an epitaxial alignment of the
InSe with the sapphire substrate mediated by a specific interface
reconstruction. The epitaxial alignment is verified by in-plane X-ray
diffraction across large length scales. Samples grown under optimized
conditions exhibit a strong optical absorption in the visible range and
especially a comparably high electron mobility underlining the potential of the
MOCVD-grown material for future applications.

</details>


### [331] [Topological nontrivial berry phase in altermagnet CrSb](https://arxiv.org/abs/2509.21303)
*Jianhua Du,Xin Peng,Yuzhi Wang,Shengnan Zhang,Yuran Sun,Chunxiang Wu,Tingyu Zhou,Le Liu,Hangdong Wang,Jinhu Yang,Bin Chen,Chuanying Xi,Zhiwei Jiao,Quansheng Wu,Minghu Fang*

Main category: cond-mat.mtrl-sci

TL;DR: CrSb是一种具有独特磁性的新型超磁性材料，其拓扑性质的研究为探索超磁序与拓扑态的内在联系提供了新平台。通过高磁场输运实验和第一性原理计算，研究证实CrSb具有非平凡的拓扑特性，包括高达35 T未饱和的磁阻、多带电荷输运机制、SdH量子振荡以及 Zeeman效应引起能带劈裂。


<details>
  <summary>Details</summary>
Motivation: CrSb作为一种潜在的超磁性材料，其独特的磁性及其与拓扑量子态的潜在联系吸引了研究者的关注，本研究旨在探索CrSb中拓扑半金属态的实现机制及其在量子输运现象中的表现。

Method: 结合系统的输运实验（高场磁输运测量，包括磁阻和霍尔电阻）和第一性原理计算（费米面、能带计算），并进行Berry相分析。

Result: 高场磁输运测量显示，CrSb的磁阻在高达35 T时无饱和迹象，且遵循指数为1.48的幂律关系。非线性霍尔电阻表明存在多带电荷输运机制。在强磁场下，观察到显著的Shubnikov-de Haas（SdH）量子振荡，并在1.6 K下分辨出由Zeeman效应引起能带劈裂。Berry相分析确认了该材料具有非平凡的拓扑特性（Berry相接近π）。

Conclusion: 研究结果不仅为理解CrSb的电子结构提供了关键的实验证据，也为探索超磁体中的拓扑量子态奠定了重要基础。

Abstract: The study of topological properties in magnetic materials has long been one
of the forefront research areas in condensed matter physics. CrSb, as a
prototypical candidate material for altermagnetism, has attracted significant
attention due to its unique magnetic properties. This system provides a novel
platform for exploring the intrinsic relationship between altermagnetic order
and exotic topological states. In this study, we combine systematic electrical
transport experiments with first-principles calculations to investigate the
possible realization mechanisms of topological semimetal states in CrSb and
their manifestations in quantum transport phenomena. Our high field
magneto-transport measurements reveal that the magnetoresistance of CrSb
exhibits no sign of saturation up to 35 T, following a distinct power-law
dependence with an exponent of 1.48. The nonlinear Hall resistivity further
indicates a multiband charge transport mechanism. Under high magnetic fields,
we observe pronounced Shubnikov-de Haas (SdH) quantum oscillations and
discernible Zeeman-effect-induced band splitting at 1.6 K. Systematic Fermi
surface and band calculations combined with Berry phase analysis confirm the
nontrivial topological character of this material (with a Berry phase
approaching {\pi}). These findings not only provide crucial experimental
evidence for understanding the electronic structure of CrSb, but also establish
an important foundation for investigating topological quantum states in
altermagnets.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [332] [Observables in Motion: A guide to simulating classical and quantum dynamics](https://arxiv.org/abs/2509.20403)
*Denys I. Bondar,Gerard McCaul,Andrii Sotnikov*

Main category: quant-ph

TL;DR: 本书旨在介绍量子和经典动力学的希尔伯特空间表示，提供数学基础、实践指南和Python实现。


<details>
  <summary>Details</summary>
Motivation: 介绍量子和经典动力学的希尔伯特空间表示，包括数学基础、实践指南和Python实现。

Method: 系统地阐述了理解经典和量子系统所需的数学基础、运动学描述和形式演化理论，并提供了数值模拟时间依赖的薛定谔演化、通过辛积分器模拟的经典动力学以及开放量子系统（包括相空间表述和随机展开）的实践指南。

Result: 提供了对经典和量子动力学使用希尔伯特空间表示的全面概述，以及数值模拟的实用技术。

Conclusion: 本书为研究量子和经典动力学及其数值模拟提供了一个结构化的学习途径。

Abstract: We present a pedagogical work-in-progress. This textbook aims to introduce
Hilbert space representations for quantum and classical dynamics, outlining the
mathematical foundations, practical guidance, and Python implementation of
dynamical simulations. Beginning with a historical survey, the book
systematically develops the mathematical foundations, kinematic descriptions,
and formal evolution theory needed to understand both classical and quantum
systems. It then provides practical guidance for numerically simulating
time-dependent Schr\"odinger evolution, classical dynamics through symplectic
integrators, and open quantum systems including phase-space formulations and
stochastic unravellings.

</details>


### [333] [Realization of Graphene Quantum Dots for Innovative Biosensor Development and Diverse Applications](https://arxiv.org/abs/2509.20547)
*Kumar Gautam,Kumar Shubham,Hitesh Sharma,Divya Punia,Ajay K Sharma,Namisha Gupta,Varun Rathor,Vishakha Singh*

Main category: quant-ph

TL;DR: 石墨烯量子点（GQD）因其低毒性、高稳定性和可调性，正在成为传统量子点（QD）的有前景的替代品，并在生物传感、食品安全和量子技术等领域具有广泛的应用前景。


<details>
  <summary>Details</summary>
Motivation: 由于传统量子点（如CdTe）的毒性和稳定性问题，需要开发更安全、更稳定的替代品。石墨烯量子点（GQD）作为一种新兴的替代品，具有优异的光学和电学性质，以及低毒性、高稳定性和可调性，使其在生物医学、电子和能源存储等领域具有广泛的应用潜力，特别是在生物传感、食品安全和量子技术等领域。

Method: 文章探讨了GQD的合成方法（自上而下和自下而上），并强调了它们相对于传统QD的优势，包括更好的光稳定性、生物相容性和可配置的带隙。

Result: GQD因其低毒性、高灵敏度和可负担性，在生物传感、实时食品安全监测和智能包装等实际应用中表现出色，这些应用有助于减少粮食浪费。此外，GQD在推动纳米技术和量子技术整合方面显示出巨大潜力，有望在生物传感、食品安全、环境监测和未来量子电子学等领域带来创新解决方案。

Conclusion: 石墨烯量子点（GQD）作为一种有前途的量子点替代品，因其固有的优势（如低毒性、高稳定性、生物相容性和可调性）和广泛的应用前景（尤其是在生物传感、食品安全和量子技术领域），在纳米技术和相关领域具有日益增长的重要性。

Abstract: This paper investigates quantum dots (QDs), which are miniature semiconductor
structures with remarkable optical and electrical properties due to quantum
confinement processes. Traditional QDs, such as CdTe, have been extensively
investigated; however, they frequently exhibit toxicity and stability issues.
Graphene quantum dots (GQDs) are emerging as a safer and more stable
alternative to traditional QDs. GQDs are honeycomb-lattice carbon atoms with
unique electronic and optical properties that make them promising candidates
for biomedical, electronic, and energy storage applications. GQD synthesis
methods (top-down and bottom-up) and their advantages over standard QDs include
better photostability, biocompatibility, and configurable band gaps. GQDs are
perfect for real-world uses like sensitive biosensing, real-time food safety
monitoring, and smart packaging because of their low toxicity, high
sensitivity, and affordability. These uses are all essential for cutting down
on food grain waste. This emphasizes the growing significance of GQDs in
advancing nanotechnology and their potential integration with quantum
technologies, paving the door for creative solutions in biosensing, food
safety, environmental monitoring, and future quantum electronics.

</details>


### [334] [Symmetrized operators or modified integration measure in Generalized Uncertainty Principle Models](https://arxiv.org/abs/2509.20466)
*Michael Bishop,Daniel Hooker,Doug Singleton*

Main category: quant-ph

TL;DR: GUP模型可以通过对称算符来修正，而不是修改内积，这保留了标准的动量空间。


<details>
  <summary>Details</summary>
Motivation: 许多广义不确定性原理（GUP）模型修改了内积，以确保对称的位置或动量算符。本研究提出了一种替代方法，即对称算符本身，而不是修改内积。

Method: 我们提出了一种通过对称算符来修正GUP模型的方法，并将其与修改内积的传统方法进行比较。

Result: 与修改内积的方法相比，我们的方法保留了标准的动量空间，使得修改后的位置算符的本征态和最大局部化态具有标准的位置表示。

Conclusion: 对称算符的方法是一种有前景的GUP修正方式，具有保留标准动量空间的优点，并允许对修改后的位置算符进行标准的位置表示。

Abstract: Many Generalized Uncertainty Principle (GUP) models modify the inner-product
measure to ensure symmetric position or momentum operators. We show that an
alternate approach to these GUPs is to symmetrize the operators rather than
modifying the inner product. This preserves the standard momentum space
allowing the eigenstates and maximally localized states of the modified
position operator to have a standard position representation. We compare both
approaches and highlight their merits.

</details>


### [335] [Average-Case Complexity of Quantum Stabilizer Decoding](https://arxiv.org/abs/2509.20697)
*Andrey Boris Khesin,Jonathan Z. Lu,Alexander Poremba,Akshar Ramkumar,Vinod Vaikuntanathan*

Main category: quant-ph

TL;DR: 随机量子稳定器码的解码难度不亚于最难的随机经典码解码问题，任何解决典型稳定器码的亚指数时间算法都将对密码学产生重大影响。


<details>
  <summary>Details</summary>
Motivation: 填补理解随机量子码与随机经典码解码算法难度之间差距的空白。

Method: 证明了单个逻辑量子比特的随机稳定器码的解码难度，不亚于恒定码率下的随机经典码解码难度。

Result: 随机量子稳定器码的解码难度不亚于恒定码率下的随机经典码解码难度，任何解决典型稳定器码的亚指数时间算法都将对密码学产生重大影响。此外，还证明了量子情况下的随机自约的显著障碍，并展示了可实现的约简，例如搜索和决策之间的约简。

Conclusion: 随机量子稳定器码的最容易的解码问题，至少和随机经典码最难的解码问题一样难。任何亚指数时间算法，如果能解码任意码率下的典型稳定器码，将立即导致密码学的突破。

Abstract: Random classical linear codes are widely believed to be hard to decode. While
slightly sub-exponential time algorithms exist when the coding rate vanishes
sufficiently rapidly, all known algorithms at constant rate require exponential
time. By contrast, the complexity of decoding a random quantum stabilizer code
has remained an open question for quite some time. This work closes the gap in
our understanding of the algorithmic hardness of decoding random quantum versus
random classical codes. We prove that decoding a random stabilizer code with
even a single logical qubit is at least as hard as decoding a random classical
code at constant rate--the maximally hard regime. This result suggests that the
easiest random quantum decoding problem is at least as hard as the hardest
random classical decoding problem, and shows that any sub-exponential algorithm
decoding a typical stabilizer code, at any rate, would immediately imply a
breakthrough in cryptography.
  More generally, we also characterize many other complexity-theoretic
properties of stabilizer codes. While classical decoding admits a random
self-reduction, we prove significant barriers for the existence of random
self-reductions in the quantum case. This result follows from new bounds on
Clifford entropies and Pauli mixing times, which may be of independent
interest. As a complementary result, we demonstrate various other
self-reductions which are in fact achievable, such as between search and
decision. We also demonstrate several ways in which quantum phenomena, such as
quantum degeneracy, force several reasonable definitions of stabilizer
decoding--all of which are classically identical--to have distinct or
non-trivially equivalent complexity.

</details>


### [336] [Computational Relative Entropy](https://arxiv.org/abs/2509.20472)
*Johannes Jakob Meyer,Asad Raza,Jacopo Rizzo,Lorenzo Leone,Sofiene Jerbi,Jens Eisert*

Main category: quant-ph

TL;DR: 计算约束下的量子信息理论：定义计算相对熵，证明其计算类斯氏引理、宾斯克界及相关不等式，并应用于计算纠缠理论。


<details>
  <summary>Details</summary>
Motivation: 研究计算能力受限的观察者处理信息的能力，以及信息理论在计算约束下的表现。现有理论多为单次试验，作者提出一种新的计算量子信息理论方向。

Method: 定义计算相对熵作为假设检验中的最优错误指数，限制使用多项式数量的拷贝和量子门。在此基础上，证明计算类斯氏引理、计算版宾斯克界，并展示计算平滑性质。

Result: 证明了计算类斯氏引理、计算版宾斯克界，并发现了计算相对熵和计算熵。证明了计算平滑性质，并展示了计算熵在量子态压缩中的应用。在计算纠缠理论方面，证明了计算版拉姆斯界。

Conclusion: 计算约束深刻地改变了信息论的格局，导致计算和无约束信息度量之间存在显著差异，包括源于密码学假设的量子-经典差距。该框架为量子信息、复杂性理论和密码学的交叉领域开辟了新的研究方向。

Abstract: Our capacity to process information depends on the computational power at our
disposal. Information theory captures our ability to distinguish states or
communicate messages when it is unconstrained with unrivaled elegance. For
computationally bounded observers the situation is quite different. They can,
for example, be fooled to believe that distributions are more random than they
actually are. In our work, we go beyond the prevailing single-shot approach and
take a new direction in computational quantum information theory that captures
the essence of complexity-constrained information theory while retaining the
look and feel of the unbounded asymptotic theory. As our foundational quantity,
we define the computational relative entropy as the optimal error exponent in
asymmetric hypothesis testing when restricted to polynomially many copies and
quantum gates, defined in a mathematically rigorous way. Building on this
foundation, we prove a computational analogue of Stein's lemma, establish
computational versions of fundamental inequalities like Pinsker's bound, and
demonstrate a computational smoothing property showing that computationally
indistinguishable states yield equivalent information measures. We derive a
computational entropy that operationally characterizes optimal compression
rates for quantum states under computational limitations and show that our
quantities apply to computational entanglement theory, proving a computational
version of the Rains bound. Our framework reveals striking separations between
computational and unbounded information measures, including quantum-classical
gaps that arise from cryptographic assumptions, demonstrating that
computational constraints fundamentally alter the information-theoretic
landscape and open new research directions at the intersection of quantum
information, complexity theory, and cryptography.

</details>


### [337] [Distillation of supersinglet states](https://arxiv.org/abs/2509.20962)
*Saeed Ahmad,Shuang Li,Jonathan Raghoonanan,Kaixuan Zhou,Valentin Ivannikov,Tim Byrnes*

Main category: quant-ph

TL;DR: 本文介绍了一种针对N量子比特的超单态（supersinglet）态的纠缠蒸馏（提纯）协议。


<details>
  <summary>Details</summary>
Motivation: 目标是制备一种总自旋为零、自旋方差为零且所有量子比特完全纠缠的超单态。

Method: 该协议通过测量三份初始自旋零状态（可由常规贝尔态蒸馏制备）的局域总自旋基，并在后选择时生成更高保真度的超单态。该协议仅使用局域操作和经典通信。

Result: 实验证明该协议可以生成高保真度的超单态，避免了高维Schur变换。

Conclusion: 该协议适用于长距离应用，如量子时钟同步、密码学和量子计量学。

Abstract: We introduce an entanglement distillation (purification) protocol for
supersinglet states composed of N qubits. The supersinglet state we target is a
total spin zero state with zero spin variance, and has a fully entangled
structure involving all qubits. In our distillation protocol, three copies of
an initial spin zero state are measured in the local total spin basis such that
a higher fidelity supersinglet state is generated upon postselection. The
initial state can be prepared using conventional Bell state distillation
methods distributed in a way to target the supersinglet symmetries. The
protocol uses only local operations and classical communications, and is
suitable for long-distance applications such as quantum clock synchronization
and cryptography, and avoids a high dimensional Schur transform such that it
can be used for tasks such as quantum metrology.

</details>


### [338] [A Review on Quantum Circuit Optimization using ZX-Calculus](https://arxiv.org/abs/2509.20663)
*Tobias Fischbach,Pierre Talbot,Pascal Bourvry*

Main category: quant-ph

TL;DR: ZX-calculus是一种用于量子电路优化的语义保持框架。本综述对基于ZX-calculus的优化方法进行了分类，讨论了其优化技术、目标指标和目标量子计算架构，并指出了多目标优化、可扩展算法和增强的电路提取方法等挑战和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: NISQ时代量子计算机受限于资源（如噪声、量子比特、门和电路深度），量子电路优化是关键的缓解策略。ZX-calculus作为一个替代框架，能够进行语义保持的量子电路优化。

Method: 对基于ZX-calculus的量子电路优化进行综述，并根据优化技术、目标指标和目标量子计算架构进行分类。

Result: 对ZX-calculus在量子电路优化方面的应用进行了分类和总结，并讨论了相关的挑战和未来研究方向。

Conclusion: 本综述为组合优化和量子计算的研究人员提供了对ZX-calculus在量子电路优化中应用的理解，并指出了未来的研究方向。

Abstract: Quantum computing promises significant speed-ups for certain algorithms but
the practical use of current noisy intermediate-scale quantum (NISQ) era
computers remains limited by resources constraints (e.g., noise, qubits, gates,
and circuit depth). Quantum circuit optimization is a key mitigation strategy.
In this context, ZX-calculus has emerged as an alternative framework that
allows for semantics-preserving quantum circuit optimization.
  We review ZX-based optimization of quantum circuits, categorizing them by
optimization techniques, target metrics and intended quantum computing
architecture. In addition, we outline critical challenges and future research
directions, such as multi-objective optimization, scalable algorithms, and
enhanced circuit extraction methods. This survey is valuable for researchers in
both combinatorial optimization and quantum computing. For researchers in
combinatorial optimization, we provide the background to understand a new
challenging combinatorial problem: ZX-based quantum circuit optimization. For
researchers in quantum computing, we classify and explain existing circuit
optimization techniques.

</details>


### [339] [Quantum non-Gaussianity based on amplified photon statistics](https://arxiv.org/abs/2509.20492)
*Éva Rácz,László Ruppert,Radim Filip*

Main category: quant-ph

TL;DR: 本文提出了一种基于光子数均值和方差（或二阶关联 $g^{(2)}$）的量子非高斯性判据，可以直接从放大后的信号推断未知输入态的性质，便于进行损耗和噪声修正。


<details>
  <summary>Details</summary>
Motivation: 量子放大虽然能降低噪声和损耗，但会将离散的量子态转变为连续信号，使得无法直接获得输入态的离散量子数信息。本文旨在解决这一问题。

Method: 提出并分析了一种基于光子数均值和方差（或二阶关联 $g^{(2)}$）的量子非高斯性判据。该判据可以从放大后的信号的（归一化的）光强矩推断得到。

Result: 该方法可以从放大后的信号推断出未知输入态的量子非高斯性，并且由于判据仅基于一阶和二阶矩，易于进行损耗和噪声修正。$

Conclusion: 本文提出的量子非高斯性判据是一种有效的方法，可以直接从放大后的量子信号中获取未知输入态的信息，并易于进行实际测量中的损耗和噪声修正。

Abstract: Amplification is an essential part of quantum processing and detection that
allows for reducing subsequent loss and noise. However, the intensive
amplification transfers individual discrete quanta to a detected continuous
signal, so Fock probabilities of the unknown input state are not readily
available. To solve this issue, we directly derive and analyze a quantum
non-Gaussianity witness based on the photon number mean and variance (or
alternatively, the second-order correlation $g^{(2)}$) of the unknown state,
which can be inferred from post-amplification integrated intensity moments.
Since this new witness is based on first and second moments only, measurement
results are easy to correct for losses and additive noise.

</details>


### [340] [Quantum statistical mechanical gauge invariance](https://arxiv.org/abs/2509.20494)
*Johanna Müller,Matthias Schmidt*

Main category: quant-ph

TL;DR: The paper introduces a quantum shifting superoperator to address gauge invariance in quantum many-body systems, leading to new equilibrium sum rules and integration with quantum hyperdensity functional theory.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address gauge invariance in the statistical mechanics of quantum many-body systems.

Method: The method involves representing the gauge transformation by a quantum shifting superoperator with an anti-self-adjoint and noncommutative Lie algebra structure, which induces exact equilibrium sum rules. This framework is integrated within quantum hyperdensity functional theory and shown to generalize to nonequilibrium systems.

Result: The result is the establishment of exact equilibrium sum rules connecting locally-resolved force and hyperforce densities for any observable. The framework is demonstrated to integrate with quantum hyperdensity functional theory and generalize to nonequilibrium.

Conclusion: The paper concludes by demonstrating the integration of the developed framework within quantum hyperdensity functional theory and showing its natural generalization to nonequilibrium systems.

Abstract: We address gauge invariance in the statistical mechanics of quantum many-body
systems. The gauge transformation acts on the position and momentum degrees of
freedom and it is represented by a quantum shifting superoperator that maps
quantum observables onto each other. The shifting superoperator is
anti-self-adjoint and it has noncommutative Lie algebra structure. These
properties induce exact equilibrium sum rules that connect locally-resolved
force and hyperforce densities for any given observable. We demonstrate the
integration of the framework within quantum hyperdensity functional theory and
show that it generalizes naturally to nonequilibrium.

</details>


### [341] [Towards a user-centric HPC-QC environment](https://arxiv.org/abs/2509.20525)
*Aleksander Wennersteen,Matthieu Moreau,Aurelien Nober,Mourad Beji*

Main category: quant-ph

TL;DR: 本工作展示了一个基础但可移植的混合量子-经典程序运行时环境，该环境可在增强了量子处理单元（QPU）的高性能计算（HPC）环境中运行，以应对量子计算的挑战。


<details>
  <summary>Details</summary>
Motivation: 量子计算的挑战，如应用程序开发、可移植性和可重复性，需要健壮的执行环境，以实现模块化量子程序开发和混合量子工作流。

Method: 开发了一个包含第二层调度（在主HPC资源管理器之后）的中间件，以提高QPU利用率，并增加了可观测性、监控和管理员访问功能。该系统支持将多个SDK作为一等公民进行管理，并基于QRMI接口，最后实现了一个监控和可观测性栈。

Result: 成功构建了一个可在HPC环境中运行混合量子-经典程序的运行时环境，并展示了其调度、可观测性和多SDK管理能力。

Conclusion: 所提出的混合系统架构通过提供增强的QPU利用率、可观测性、监控和多SDK支持，解决了混合量子-经典计算中的关键挑战。

Abstract: Robust execution environments are important for addressing key challenges in
quantum computing, such as application development, portability, and
reproducibility, and help unlock the development of modular quantum programs,
driving forward hybrid quantum workflows. In this work, we show progress
towards a basic, but portable, runtime environment for developing and executing
hybrid quantum-classical programs running in High Performance Computing (HPC)
environments enhanced with Quantum Processing Units (QPUs). The middleware
includes a second layer of scheduling after the main HPC resource manager in
order to improve the utilization of the QPU, and extra functionality for
observability, monitoring, and admin access. This approach enables managing
multiple programming Software Development Kits (SDKs) as first-class citizens
in the environment by building on a recently proposed vendor-neutral Quantum
Resource Management Interface (QRMI). Lastly, we discuss and show a solution
for the monitoring and observability stack, completing our description of the
hybrid system architecture.

</details>


### [342] [Quantum error correction beyond $SU(2)$ spin, bosonic, and permutation-invariant codes from convex geometry](https://arxiv.org/abs/2509.20545)
*Arda Aydin,Victor V. Albert,Alexander Barg*

Main category: quant-ph

TL;DR: 本论文提出了一种通用的量子纠错码和逻辑门构建框架，适用于多种量子系统（多量子比特/量子的排列不变空间、多玻色模式的恒定激发Fock态空间、原子/离子/分子的核态空间）。


<details>
  <summary>Details</summary>
Motivation: 研究的动机在于开发一种能够统一处理不同量子系统（如多量子比特、玻色模式、原子/离子/分子核态）的量子纠错码和逻辑门构建方法，并期望改进现有量子码的性能。

Method: 通过将三种空间识别为离散单纯形和 $SU(q)$ 群的表示，证明了不同空间中的码和门可以相互转化。利用经典 $\ell_1$ 码和Tverberg定理，构建了新的量子码实例。基于Sidon集及其Tverberg划分，构造了长度接近线性增长的量子码。

Result: 在新构造的量子码中，距离随码长N的增长接近线性。同时，为所有三种状态空间提供了新的码实例，包括具有优于现有码的参数（更短长度或更低总自旋/激发）的码，以及具有新颖高斯门的玻色码。

Conclusion: 本研究提出的框架能够统一构建多种量子系统的量子纠错码和逻辑门，并利用 $\ell_1$ 码和Tverberg定理等几何和组合学工具，显著改进了量子码的性能，为量子纠错和量子计算提供了新的可能性。

Abstract: We develop a framework for constructing quantum error-correcting codes and
logical gates for three types of spaces -- composite permutation-invariant
spaces of many qubits or qudits, composite constant-excitation Fock-state
spaces of many bosonic modes, and monolithic nuclear state spaces of atoms,
ions, and molecules. By identifying all three spaces with discrete simplices
and representations of the Lie group $SU(q)$, we prove that many codes and
their gates in $SU(q)$ can be inter-converted between the three state spaces.
We construct new code instances for all three spaces using classical $\ell_1$
codes and Tverberg's theorem, a classic result from convex geometry. We obtain
new families of quantum codes with distance that scales almost linearly with
the code length $N$ by constructing $\ell_1$ codes based on combinatorial
patterns called Sidon sets and utilizing their Tverberg partitions. This
improves upon the existing designs for all the state spaces. We present
explicit constructions of codes with shorter length or lower total
spin/excitation than known codes with similar parameters, new bosonic codes
with exotic Gaussian gates, as well as examples of short codes with distance
larger than the known constructions.

</details>


### [343] [Nonlocal Magic Generation and Information Scrambling in Noisy Clifford Circuits](https://arxiv.org/abs/2509.20566)
*Emanuel Dallas,Paolo Zanardi*

Main category: quant-ph

TL;DR: 随机Clifford编码-解码电路在局部噪声扰动下的信息 the butterfly effect


<details>
  <summary>Details</summary>
Motivation: 研究局部噪声对随机Clifford编码-解码电路的信息 the butterfly effect 和非局域魔术生成特性的影响

Method: 使用Clifford群表示论计算无限大电路中A-OTOC和APEP的平均值，并进行数值模拟研究噪声信道容量与APEP的关系

Result: 发现噪声会导致宏观信息 the butterfly effect 和非局域魔术生成能力；数值研究了噪声信道容量与APEP的关系

Conclusion: 局部噪声会引起宏观信息 the butterfly effect 和非局域魔术生成能力，为设计高效的非局域魔术工厂提供了思路

Abstract: In this work, we investigate the average information scrambling and nonlocal
magic generation properties of random Clifford encoding-decoding circuits
perturbed by local noise. We quantify these with the bipartite algebraic
out-of-time order correlator ($\mathcal{A}$-OTOC) and average Pauli-entangling
power (APEP) respectively. Using recent advances in the representation theory
of the Clifford group, we compute both quantities' averages in the limit that
the circuits become infinitely large. We observe that both display a
``butterfly effect" whereby noise occurring on finitely many qubits leads to
macroscopic information scrambling and nonlocal magic generating power.
Finally, we numerically study the relationship between the magic capacity, an
operator-level magic monotone, of the noise channel and the APEP of the
resulting circuit, which may provide insight for designing efficient nonlocal
magic factories.

</details>


### [344] [Excited-CAFQA: A classical simulation bootstrap for the variational estimation of molecular excited states](https://arxiv.org/abs/2509.20588)
*Bikrant Bhattacharyya,Gokul Ravi*

Main category: quant-ph

TL;DR: CAFQA协议通过经典模拟搜索优化VQA的初始参数，Excited-CAFQA将其应用于VQD算法以提高计算精度。


<details>
  <summary>Details</summary>
Motivation: VQAs在当前量子设备上易于实现，但噪声问题限制了其在量子化学中的应用。通过优化VQA的初始参数是改进VQA的一种方法。CAFQA协议通过在经典可模拟的子空间中进行离散搜索来找到合适的初始值。

Method: 受CAFQA成功的启发，提出Excited-CAFQA初始化方法，将其应用于VQD算法。VQD通过添加惩罚项来计算能量状态，并递归地计算激发态。Excited-CAFQA利用VQD的成本函数在CAFQA搜索的离散空间中找到每个能量级别的初始参数。

Result: Excited-CAFQA在H2和HeH+分子系统的各种键长和激发态的计算中，实现了90%至99%以上的准确率。

Conclusion: Excited-CAFQA是一种有效的VQD初始化方法，可以显著提高量子化学计算的精度。

Abstract: Variational Quantum Algorithms (VQAs) are iterative algorithms suited to
implementation on current-era quantum devices. VQAs employ classical
optimization to minimize cost functions evaluated on quantum circuits. However,
the extent to which VQAs manage noise is often insufficient for quantum
chemistry applications. One method of improving VQAs is through accurate ansatz
initialization. The CAFQA (Clifford Ansatz For Quantum Accuracy) protocol runs
a discrete search through a classically simulatable subset of the entire state
space to find a desirable initialization. Prior work has evaluated CAFQA
applied to the Variational Quantum Eigensolver (VQE), a VQA that computes
grounds states of a Hamiltonian. Motivated by CAFQA's success, we propose
Excited-CAFQA initialization for Variational Quantum Deflation (VQD), a quantum
algorithm that extends VQE by allowing the computation of excited states. VQD
recursively computes excited states, by constraining the kth state to be
orthogonal to the previous k-1 computed energy states via a penalty term
appended to the standard VQE cost function. Just as with VQE, the VQD cost
function can be efficiently computed classically for the states considered in
the discrete CAFQA search, allowing for the discrete CAFQA optimizer to find
good initial parameters for each energy level computation. Preliminary
evaluation shows that Excited-CAFQA achieves 90 to 99+% accuracy across a
variety of bond lengths and excited states for H2 and HeH+ molecular systems.

</details>


### [345] [Asymptotically optimal unitary estimation in $\mathrm{SU}(3)$ by the analysis of graph Laplacian](https://arxiv.org/abs/2509.20608)
*Satoshi Yoshida,Hironobu Yoshida,Mio Murao*

Main category: quant-ph

TL;DR: The paper provides optimal asymptotic fidelity for unitary estimation in 3 dimensions and a general lower bound for d dimensions.


<details>
  <summary>Details</summary>
Motivation: The motivation is to determine the optimal accuracy for estimating unknown unitary operators using a limited number of queries.

Method: The method involves analyzing the graph Laplacian using the finite element method for the 3D case, and deriving a lower bound based on a specific unitary estimation protocol for the general d-dimensional case.

Result: The paper shows the optimal asymptotic fidelity for d=3 is $F_	ext{est}(n,d=3) = 1-rac{56	ext{pi}^2}{9n^2} + O(n^{-3})$. For arbitrary d, the lower bound is $F_	ext{est}(n,d) 	ext{ 1- } rac{(d+1)(d-1)(3d-2)(3d-1)}{6n^2} + O(n^{-3})$.

Conclusion: The derived bounds are the best known and achieve tight scaling with respect to n and d, providing significant progress in understanding the limits of unitary estimation.

Abstract: Unitary estimation is the task to estimate an unknown unitary operator
$U\in\mathrm{SU}(d)$ with $n$ queries to the corresponding unitary operation,
and its accuracy is evaluated by an estimation fidelity. We show that the
optimal asymptotic fidelity of $3$-dimensional unitary estimation is given by
$F_\mathrm{est}(n,d=3) = 1-\frac{56\pi^2}{9n^2} + O(n^{-3})$ by the analysis of
the graph Laplacian based on the finite element method. We also show the lower
bound on the fidelity of $d$-dimensional unitary estimation for an arbitrary
$d$ given by $F_\mathrm{est}(n,d) \geq 1- \frac{(d+1)(d-1)(3d-2)(3d-1)}{6n^2} +
O(n^{-3})$ achieving the best known lower bound and tight scaling with respect
to $n$ and $d$. This lower bound is derived based on the unitary estimation
protocol shown in [J. Kahn, Phys. Rev. A 75, 022326, 2007].

</details>


### [346] [Optimal phase change for a generalized Grover's algorithm](https://arxiv.org/abs/2509.20610)
*Christopher Cardullo,Min Kang*

Main category: quant-ph

TL;DR: 该研究通过引入任意幅度向量来优化Grover搜索算法，以最大化目标观测概率。对于实数幅度向量，发现π相变在接近1的概率下仍然是最优的，并给出了确定该临界点的公式。对于复数幅度向量，最优相变与幅度的复数特性非平凡地相关，并提供了一个优化公式来确定所需的最佳相变。


<details>
  <summary>Details</summary>
Motivation: 研究广义Grover算法，探索任意幅度向量下的最优相位变化，以最大化每次迭代中目标状态的观测概率增益。

Method: 对于实数初始幅度向量，分析了π相变的有效性，并推导了确定最优相变临界点的公式。对于复数幅度向量，推导了依赖于幅度向量复数特性的最优相变优化公式。

Result: 发现了在实数幅度向量情况下，π相变在特定条件下保持最优。对于复数幅度向量，推导出了确定最优相变的优化公式。

Conclusion: 最优相变策略取决于幅度向量的性质（实数或复数），并为这两种情况提供了相应的分析和计算方法。

Abstract: We study the generalized Grover's algorithm with an arbitrary amplitude
vector to find the optimal phase change for maximizing the gain in probability
for the target of each iteration. In the classic setting of Grover's algorithm
with a real initial amplitude vector, we find that a phase change of $\pi$
stays optimal until the probability of observing the target is quite close to
1. We provide a formula for identifying this cut-off point based on the size of
the data set. When the amplitude is truly complex, we find that the optimal
phase change depends non-trivially on the complexity of the amplitude vector.
We provide an optimization formula to identify the required optimal phase
change.

</details>


### [347] [Probing Bandwidth and Sensitivity in Rydberg Atom Sensing via Optical Homodyne and RF Heterodyne Detection](https://arxiv.org/abs/2509.20632)
*Dixith Manchaiah,Stone Oliver,Samuel Berweger,Christopher L. Holloway,Nikunjkumar Prajapati*

Main category: quant-ph

TL;DR: 基于铷蒸气Rydberg原子的传感器，通过结合射频混频和光学同相检测技术，实现了8兆赫兹的响应带宽，同时保持了高灵敏度，并在通信信号接收方面表现出与传统射频混频器相当的性能。


<details>
  <summary>Details</summary>
Motivation: 为了提高Rydberg原子传感器的通信和雷达应用能力，需要研究其带宽和灵敏度的权衡，并探索扩展其性能的方法。

Method: 采用射频外差测量技术和光学同相检测设置，结合铷蒸气Rydberg电磁诱导透明（EIT）光谱学，研究了Rydberg原子传感器的带宽和灵敏度。通过改变符号率和传感器带宽，接收数字通信信号并测量误差向量幅度（EVM），并与传统射频混频器进行比较。

Result: 实现了8兆赫兹的响应带宽，同时保持了高灵敏度。接收数字通信信号并进行了EVM测量，并将传感器性能与传统射频混频器进行了比较。发现Rydberg传感器在接收纯音和调制信号时的带宽不同，这影响了信噪比和噪声累积。

Conclusion: 基于Rydberg原子的传感器，通过结合射频混频和光学同相检测技术，可以实现高带宽和高灵敏度。在通信信号接收方面，其性能与传统射频混频器相当。然而，需要进一步研究调制信号对传感器带宽的影响，以优化其在实际通信应用中的性能。

Abstract: Rydberg atom based sensors allow for SI traceable measurements and show
promise for applications in the field of communication and radar technologies.
In this article, we investigate the bandwidth and sensitivity of a Rydberg
atom-based sensor in a rubidium vapor cell using Rydberg electromagnetically
induced transparency (EIT) spectroscopy. We employ a radio-frequency (RF)
heterodyne measurement technique in combination with an optical homodyne setup
to extend the achievable range between sensitivity and bandwidth in a Rydberg
sensor. While the bandwidth of Rydberg sensors are limited by the transit time
of atoms and the Rabi frequency of the coupling field, achieving higher
bandwidth through smaller beam sizes is thought to compromise sensitivity due
to reduced EIT signal strength. Using optical homodyne detection, we
demonstrate that sensitivity is preserved while achieving a response bandwidth
of 8 MHz. In addition, using the Rydberg sensor, we receive digital
communication signals and present error vector magnitude (EVM) measurements as
a function of varying symbol rates and bandwidth of the Rydberg sensor.
Furthermore, the sensor's performance is compared with a conventional RF mixer.
We establish that the bandwidth of a Rydberg sensor when receiving a pure tone
is not the same as the bandwidth of the sensor when receiving a modulated
signal. This difference results from the spreading of symbols in the frequency
domain, leading to a reduction of the signal to noise ratio (SNR) and an
accumulation of noise over the total span of the modulated signal.

</details>


### [348] [Lower Bounds for Learning Hamiltonians from Time Evolution](https://arxiv.org/abs/2509.20665)
*Ziyun Chen,Jerry Li*

Main category: quant-ph

TL;DR: 学习量子系统的哈密顿量参数存在挑战，本研究首次提出了与哈密顿量参数数量相关的学习下界，并解决了k-局域性哈密顿量的学习公开问题。


<details>
  <summary>Details</summary>
Motivation: 从时间演化中学习哈密顿量（即恢复H的参数）是量子学习理论中的一个重要问题，在量子计量学、传感、设备基准测试和多体物理学等领域有重要应用。

Method: 通过分析任意哈密顿量和k-局域性哈密顿量两种情况，推导了学习误差为ε的学习轮数下界。

Result: 对于任意哈密顿量，学习到误差ε需要2^((1/2 - o(1))n) / ε轮。对于k-局域性哈密顿量，学习到常数误差需要n^Ω(k)轮。这些下界对于检测单个系数远超其他系数的植入式尖峰检测问题和平均情况实例同样成立。

Conclusion: 本研究得到的下界表明，任何具有多项式时间分辨率的学习算法都需要超多项式总演化时间，解决了Tang提出的关于k-局域性哈密顿量学习的公开问题。

Abstract: We consider the problem of learning Hamiltonians from time evolution: given
the ability to apply $e^{-iHt}$ for an unknown Hamiltonian on $n$ qubits, the
goal is to recover the parameters of $H$. This is a well-studied problem in
quantum learning theory, with applications to quantum metrology, sensing,
device benchmarking, and many-body physics. For this problem, we demonstrate
the first lower bounds which scale with the number of parameters of the unknown
Hamiltonian. When the unknown Hamiltonian is arbitrary, we show that learning
to error $\epsilon$ requires $2^{(1/2 - o(1))n} / \epsilon$ rounds of
interaction with the Hamiltonian. If the Hamiltonian is additionally assumed to
be $k$-local, we show that learning to constant error requires $n^{\Omega (k)}$
rounds of interaction with the Hamiltonian, resolving an open question of Tang.
These bounds immediately imply that any learning algorithm with inverse
polynomial time resolution requires super-polynomial total evolution time. Our
lower bounds hold even for very simple planted spike detection problems, where
the goal is to detect the presence of a single coefficient which is
super-polynomially larger than the other coefficients of the Hamiltonian, as
well as for average case instances.

</details>


### [349] [Quantum Algorithm for Subcellular Multiscale Reaction-Diffusion Systems](https://arxiv.org/abs/2509.20668)
*Margot Lockwood,Nathan Wiebe,Connah Johnson,Johannes Mülmenstädt,Jaehun Chun,Gregory Schenter,Margaret S. Cheung,Xiangyu Li*

Main category: quant-ph

TL;DR: 该研究提出了一种量子算法框架，用于解决经典计算在模拟细胞系统时面临的扩展性和维度灾难问题，实现了计算速率和时空演化的指数级加速，并为生物学、物理学等领域提供了新的模拟工具。


<details>
  <summary>Details</summary>
Motivation: 经典计算在模拟细胞系统时，由于“维度灾难”问题，在系统规模和时空尺度上受到严重限制，计算复杂性呈指数级增长。

Method: 提出了一种量子算法框架，该框架能够同时计算反应速率并跟踪亚细胞系统的时空动态演化。该方法推广了适用于多尺度和任意物种数量以及高阶相互作用的反应扩散方程（RDE），实现了指数级的反应速率计算加速和二次方/多项式级别的RDE求解扩展性。

Result: 该量子算法在反应速率计算方面实现了指数级量子加速，在求解非线性RDE方面，其计算复杂度与空间网格点呈二次方关系，与物种数量呈多项式关系，显著优于经典方法的指数级扩展性。

Conclusion: 该研究首次提出了解决多尺度反应扩散系统的有效量子算法，为在更广泛的时空尺度上模拟生物相关的亚细胞过程提供了可能，对计算生物学、软物质物理学和生物物理建模具有深远影响。

Abstract: Computational modeling of cellular systems, where reactants are governed by
biochemical equations and physical representations, requires extensive
classical computing resources. These limitations significantly constrain the
system size and spatiotemporal scales of simulations. A key challenge lies in
the "curse of dimensionality", where the number of possible reaction terms
grows exponentially with the number of species, and the computation of reaction
rates involving many-body interactions becomes intractable in polynomial time
on classical computers. In this work, we introduce a quantum algorithmic
framework designed to overcome these challenges, leveraging the architecture of
quantum computing to simultaneously compute reaction rates and track the
spatiotemporal dynamical evolutions of subcellular systems. We generalize the
reaction-diffusion equation (RDE) for multiscale systems with arbitrary species
count, encompassing higher-order interactions. Our approach achieves two
principal quantum advantages: (i) an exponential quantum speedup in
reaction-rate computation, contingent on the efficient preparation of
polynomially accurate ground states on a quantum computer, and (ii)) a
quadratic scaling in spatial grid points and polynomial scaling in the number
of species for solving nonlinear RDEs, contrasting sharply with classical
methods that scale exponentially with the system's degrees of freedom. To our
knowledge, this represents the first efficient quantum algorithm for solving
multiscale reaction-diffusion systems. This framework opens the door to
simulations of biologically relevant subcellular processes across previously
inaccessible spatial and temporal scales, with profound implications for
computational biology, soft matter physics, and biophysical modeling.

</details>


### [350] [PALQO: Physics-informed Model for Accelerating Large-scale Quantum Optimization](https://arxiv.org/abs/2509.20733)
*Yiming Huang,Yajie Hao,Jing Zhou,Xiao Yuan,Xiaoting Wang,Yuxuan Du*

Main category: quant-ph

TL;DR: VQA训练可利用PINN进行加速，显著降低资源消耗。


<details>
  <summary>Details</summary>
Motivation: 量子设备实现实际应用面临量子资源消耗大的挑战，特别是对于大规模任务。

Method: 将VQA的训练动力学转化为非线性偏微分方程，并利用PINN建模，通过少量训练数据预测参数更新，以减少量子资源消耗。

Result: 在最多40个量子比特的任务中，包括不同量子系统的基态制备，实现了高达30倍的速度提升和90%的资源成本降低，同时保持了有竞争力 的准确性。

Conclusion: 该方法能够提高VQA的效率，增强其在实际应用中的潜力。

Abstract: Variational quantum algorithms (VQAs) are leading strategies to reach
practical utilities of near-term quantum devices. However, the no-cloning
theorem in quantum mechanics precludes standard backpropagation, leading to
prohibitive quantum resource costs when applying VQAs to large-scale tasks. To
address this challenge, we reformulate the training dynamics of VQAs as a
nonlinear partial differential equation and propose a novel protocol that
leverages physics-informed neural networks (PINNs) to model this dynamical
system efficiently. Given a small amount of training trajectory data collected
from quantum devices, our protocol predicts the parameter updates of VQAs over
multiple iterations on the classical side, dramatically reducing quantum
resource costs. Through systematic numerical experiments, we demonstrate that
our method achieves up to a 30x speedup compared to conventional methods and
reduces quantum resource costs by as much as 90\% for tasks involving up to 40
qubits, including ground state preparation of different quantum systems, while
maintaining competitive accuracy. Our approach complements existing techniques
aimed at improving the efficiency of VQAs and further strengthens their
potential for practical applications.

</details>


### [351] [Quantum Simulation and Energy Estimation for Discretized Anharmonic oscillator](https://arxiv.org/abs/2509.20907)
*Saurav Suman,Bikash K. Behera,Vivek Vyas,Prasanta k. Panigrahi*

Main category: quant-ph

TL;DR: 使用3量子比特系统在IBM量子体验平台上通过量子模拟和VQE/VQD来模拟量子非谐振荡器，并与经典方法进行比较。


<details>
  <summary>Details</summary>
Motivation: 经典计算机难以模拟量子非谐振荡器，因此需要量子模拟方法。

Method: 使用3量子比特系统实现量子电路，采用基于滤波器的设计和Toffoli门来跟踪量子态演化。使用VQE和VQD计算基态和激发态能量。

Result: 量子模拟方法实现了1.11%的误差，优于摄动理论（6.71%）和WKB近似（5.36%）。

Conclusion: 量子模拟和VQD是研究复杂量子系统的有效工具，可应用于量子化学和材料科学。

Abstract: Anharmonic potential quantum system play crucial role in physics as they
provide a more realistic description of oscillatory phenomena, which often
deviate from the idealized harmonic model. However, simulating such system on
classical computers is highly challenging due to nonlinear interactions, large
state spaces, and the exponential scaling of memory and computational
resources. In this work, quantum simulation is employed to model a quantum
anharmonic oscillator (QAHO) using a 3-qubit system implemented on IBM's
Quantum Experiences platform. A quantum circuit with a filter-based design and
Toffoli gates is constructed to track quantum state evolution, capturing key
phenomena like quantum revival. The framework is further extended to n-qubit
system to enhance resolution and scalability. For energy estimation, the
Variational Quantum Eigensolver (VQE) with a TwoLocal ansatz and variational
Quantum Deflation (VQD), are used to compute ground and excited state energies.
The proposed approach achieves high accuracy with an error of only 1.11%
compared to exact methods. Notably, VQE outperforms classical approximations
such as perturbation theory (error 6.71%) and the Wentzel-Kramers-Brillouin
(WKB) approximation(error 5.36%), yielding more precise energy values. These
results highlight the potential of quantum simulation and VQD as effective
tools for investigating complex quantum system, paving the way for future
application in quantum chemistry and materials science as quantum hardware
continues to advance.

</details>


### [352] [Classical and quantum chaotic synchronization in coupled dissipative time crystals](https://arxiv.org/abs/2509.20922)
*Eliška Postavová,Gianluca Passarelli,Procolo Lucignano,Angelo Russomanno*

Main category: quant-ph

TL;DR: 两类相干耦合耗散时间晶体在经典和量子情况下均表现出混沌同步现象，但经典和量子交叉点的行为有所不同。


<details>
  <summary>Details</summary>
Motivation: 研究两个相干耦合耗散时间晶体的动力学行为。

Method: 在经典的无限自旋长度的平均场极限下，分析了混沌同步的条件（正的最大李雅普诺夫指数和接近1的皮尔逊相关系数）。采用量子轨迹方法研究有限尺寸的量子动力学，分析子系统z磁化的直方图。

Result: 在经典平均场极限下，发现了混沌同步，并在其边界处观察到皮尔逊系数的突变，标志着z磁化从交错到均匀的转变。在量子情况下，通过量子轨迹方法，观察到子系统z磁化直方图的最大值也表现出与经典情况类似的交错到均匀的转变，证明了耗散量子混沌的存在（稳态密度矩阵呈现高斯酉系统计）。

Conclusion: 经典和量子交叉点的不同位置，反映了无限自旋和无限时间极限的不可交换性，以及纠缠（通过子系统间的纠缠熵量化）的影响。

Abstract: We investigate the dynamics of two coherently coupled dissipative time
crystals. In the classical mean-field limit of infinite spin length, we
identify a regime of chaotic synchronization, marked by a positive largest
Lyapunov exponent and a Pearson correlation coefficient close to one. At the
boundary of this regime, the Pearson coefficient varies abruptly, marking a
crossover between staggered and uniform $z$-magnetization. To address
finite-size quantum dynamics, we employ a quantum-trajectory approach and study
the trajectory-resolved expectations of subsystem $z$-magnetizations. Their
histograms over time and trajectory realizations exhibit maxima that undergo a
staggered-to-uniform crossover analogous to the classical one. In analogy with
the classical case, we interpret this behavior as quantum chaotic
synchronization, with dissipative quantum chaos evidenced by the steady-state
density matrix exhibiting Gaussian Unitary Ensemble statistics. The locations
of the classical and quantum crossover differ, reflecting the noncommutativity
of the infinite-spin and infinite-time limits and the impact of entanglement,
quantified via the entanglement entropy between subsystems.

</details>


### [353] [Harnessing optical disorder for Bell inequalities violation](https://arxiv.org/abs/2509.21052)
*Baptiste Courme,Malo Joly,Adrian Makowski,Sylvain Gigan,Hugo Defienne*

Main category: quant-ph

TL;DR: 利用光学无序性作为资源，通过贝尔不等式检验来验证量子纠缠，无需主动纠正。


<details>
  <summary>Details</summary>
Motivation: 光学无序性（如光纤中的偏振或空间模式混合以及自由空间湍流）会干扰传统的贝尔不等式检验，因为它们会破坏测量基的选择。

Method: 利用一个经过偏振纠缠光子对中的一个光子在商用多模光纤中传播，该光纤会加剧空间和偏振模式的混合，产生散斑图样。通过空间分辨散斑强度图样，访问大量的随机且未知的偏振投影，并用此违反贝尔不等式。

Result: 所提出的方法在没有主动纠正技术的情况下，仅通过空间分辨散斑强度图样就足以违反贝尔不等式，从而验证了纠缠。

Conclusion: 该方法提供了一种验证贝尔不等式和纠缠的新途径，消除了对显式选择测量基的需求，并为在存在不可避免的无序性的实际量子通信通道中进行纠缠认证提供了一个实用的解决方案。

Abstract: Bell inequalities are a cornerstone of quantum physics. By carefully
selecting measurement bases (typically polarization), their violation certifies
quantum entanglement. Such measurements are disrupted by the presence of
optical disorder in propagation paths, including polarization or spatial mode
mixing in fibers and through free-space turbulence. Here, we demonstrate that
disorder can instead be exploited as a resource to certify entanglement via a
Bell inequality test. In our experiment, one photon of a polarization-entangled
pair propagates through a commercial multimode fiber that scrambles spatial and
polarization modes, producing a speckle pattern, while the other photon remains
with the sender. By spatially resolving the speckle intensity pattern, we
naturally access a large set of random and unknown polarization projections. We
show that this set is statistically sufficient to violate a Bell inequality,
thereby certifying entanglement without requiring active correction techniques.
Our approach provides a fundamentally new way to test Bell inequalities,
eliminating the need for an explicit choice of measurement basis, and offering
a practical solution for entanglement certification in real-world quantum
communication channels where disorder is unavoidable.

</details>


### [354] [No Universal Purification in Quantum Mechanics](https://arxiv.org/abs/2509.21111)
*Zhenhuan Liu,Zhenyu Du,Zhenyu Cai,Zi-Wen Liu*

Main category: quant-ph

TL;DR: 量子力学的线性和正性限制了量子纯化，排除了通用纯化，并为近似纯化提供了样本复杂度界限，特别是在纯稀释任务中。


<details>
  <summary>Details</summary>
Motivation: 量子力学的线性和正性对量子纯化施加了一般性限制，揭示了量子信息处理的一个新的基本限制。

Method: 证明量子力学的线性和正性对量子纯化施加了一般性限制，并推导了近似纯化的样本复杂度界限。

Result: 任何量子操作都不能将有限数量的未知量子态或通道的副本转换为依赖于输入的纯态或纯通道。近似纯化的样本复杂度界限独立于任何任务细节或操作约束。纯稀释任务需要指数级的样本复杂度。

Conclusion: 量子力学的基本原理（线性和正性）对量子纯化设定了根本性的限制，这对量子信息处理具有重要的影响，包括对纯稀释任务的样本复杂度提出了指数级的要求。

Abstract: We prove that the linearity and positivity of quantum mechanics impose
general restrictions on quantum purification, unveiling a new fundamental
limitation of quantum information processing. In particular, no quantum
operation can transform a finite number of copies of an unknown quantum state
or channel into a pure state or channel that depends on the input, thereby
ruling out an important form of universal purification in both static and
dynamical settings. Relaxing the requirement of exact pure output, we further
extend our result to establish quantitative sample complexity bounds for
approximate purification, independent of any task details or operational
constraints. To illustrate the practical consequences of this principle, we
examine the task of approximately preparing pure dilation and, for the first
time, prove an exponential lower bound on the required sample complexity.

</details>


### [355] [Limits to black-box amplification in QMA](https://arxiv.org/abs/2509.21131)
*Scott Aaronson,Freek Witteveen*

Main category: quant-ph

TL;DR: 黑盒放大技术在量子复杂性类QMA中存在限制，尽管它可以指数级减小误差，但我们证明了在黑盒程序中，QMA验证过程的完备性无法无限接近1，且不可靠性也无法达到超指数级的微小。


<details>
  <summary>Details</summary>
Motivation: 研究量子复杂性类QMA中黑盒放大的局限性，特别是与量子验证过程的完备性和可靠性相关。

Method: 利用复杂逼近理论的技术，量化了QMA与具有完美完备性的QMA之间的分离。

Result: 证明了在黑盒程序中，QMA验证过程的完备性无法接近1超过双指数级，且不可靠性无法达到超指数级的微小。

Conclusion: 黑盒放大技术在QMA中存在根本性的局限性，完备性和可靠性存在理论上的上限。

Abstract: We study the limitations of black-box amplification in the quantum complexity
class QMA. Amplification is known to boost any inverse-polynomial gap between
completeness and soundness to exponentially small error, and a recent result
(Jeffery and Witteveen, 2025) shows that completeness can in fact be amplified
to be doubly exponentially close to 1. We prove that this is optimal for
black-box procedures: we provide a quantum oracle relative to which no QMA
verification procedure using polynomial resources can achieve completeness
closer to 1 than doubly exponential, or a soundness which is
super-exponentially small. This is proven by using techniques from complex
approximation theory, to make the oracle separation from (Aaronson, 2008),
between QMA and QMA with perfect completeness, quantitative.

</details>


### [356] [Optimal squeezing to minimize vulnerability to losses](https://arxiv.org/abs/2509.21180)
*Boulat Nougmanov*

Main category: quant-ph

TL;DR: 通过预压缩提高非高斯量子态的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 非高斯态（维格纳拟概率分布取负值）在量子物理中有重要应用，但易受耗散影响。

Method: 通过预压缩量子态来提高其对损耗的鲁棒性，并找到最优压缩参数。

Result: 研究了预压缩对薛定谔猫态、福克态和“香蕉”态等非高斯态鲁棒性的影响，并找到了最优参数。

Conclusion: 预压缩显著提高了非高斯量子态对损耗的鲁棒性。

Abstract: Non-Gaussian states, described by Wigner quasi-probability distribution
taking negative values, are of great interest for various applications of
quantum physics. It is known however that they are highly vulnerable to
dissipation. In this paper, we show that the robustness of the non-Gaussian
states to losses can be significantly improved by pre-squeezing of the quantum
state, and find the optimal parameters of the squeezing. As specific examples,
we consider such well-known quantum states as Schrodinger cat, Fock , and
``banana'' ones.

</details>


### [357] [Radiation of "breathing" vortex electron packets in magnetic field](https://arxiv.org/abs/2509.21195)
*G. V. Zmaga,G. K. Sizykh,D. V. Grosman,Qi Meng,Liping Zou,Pengming Zhang,D. V. Karlovets*

Main category: quant-ph

TL;DR: 当涡旋电子进入磁场时，会形成非稳恒拉盖尔-高斯态，其特点是电子波包均方根半径的振荡。我们计算了该状态下电子辐射的光子功率和角动量，发现损失可以忽略不计，表明直线加速器能有效保持相对论涡旋电子的涡旋性。


<details>
  <summary>Details</summary>
Motivation: 研究涡旋电子在磁场中传播时是否会因辐射而损失轨道角动量（OAM），以及辐射的性质。

Method: 使用非稳恒拉盖尔-高斯态描述涡旋电子在磁场中的状态，推导出相应的电荷和流密度，然后求解麦克斯韦方程组，计算辐射功率和角动量。

Result: 计算结果表明，涡旋电子在磁场中辐射的功率和损失的角动量都非常小，可以忽略不计。

Conclusion: 在准经典近似下，直线加速器是保持相对论涡旋电子及其它带电粒子涡旋性的有效工具。

Abstract: When a vortex electron with an orbital angular momentum (OAM) enters a
magnetic field, its quantum state is described with a nonstationary
Laguerre-Gaussian (NSLG) state rather than with a stationary Landau state. A
key feature of these NSLG states is oscillations of the electron wave packet's
root-mean-square (r.m.s.) radius, similar to betatron oscillations.
Classically, such an oscillating charge distribution is expected to emit
photons. This raises a critical question: does this radiation carry away OAM,
leading to a loss of the electron's vorticity? To investigate this, we solve
Maxwell's equations using the charge and current densities derived from an
electron in the NSLG state. We calculate the total radiated power and the
angular momentum of the emitted field, quantifying the rate at which a vortex
electron loses its energy and OAM while propagating in a longitudinal magnetic
field. We find both the radiated power and the angular momentum losses to be
negligible indicating that linear accelerators (linacs) appear to be a
prominent tool for maintaining vorticity of relativistic vortex electrons and
other charged particles, at least in the quasi-classical approximation.

</details>


### [358] [Entanglement distillation on symmetric two-qutrit entangled states of rank five](https://arxiv.org/abs/2509.21258)
*Zihua Song,Lin Chen,Yongge Wang*

Main category: quant-ph

TL;DR: NPT对称两量子比特态的纠缠蒸馏


<details>
  <summary>Details</summary>
Motivation: 研究更复杂的NPT纠缠态（对称两量子比特态）的蒸馏问题。

Method: 构造了五类对称两量子比特态，并分析了它们的1-可蒸馏性。

Result: 发现部分态是1-可蒸馏的，但某些情况下可能不是1-可蒸馏的，并给出了相应的条件。

Conclusion: 对NPT对称两量子比特态的1-可蒸馏性进行了深入研究，并提供了判断依据。

Abstract: Entanglement distillation is a key step in quantum information, both
theoretically and practically. It has been proven that non-positive-partial
transpose (NPT) entangled states of rank at most four is 1-distillable under
local operation and classical communications. In this paper we investigate the
distillation of a more complex family of NPT entangled states, namely a family
of symmetric two-qutrit states $\r$ of rank five with given eigenvectors. We
explicitly construct five families of such states by requiring four of the five
eigenvalues to be the same. We respectively show that some of them are
1-distillable. It turns out that such states may be not 1-distillable for some
interval of eigenvalues. We provide some conditions for eigenvalues that allow
$\r$ to be 1-distillable or to be 1-undistillable.

</details>


### [359] [Efficient Quantum Measurements: Computational Max- and Measured Rényi Divergences and Applications](https://arxiv.org/abs/2509.21308)
*Álvaro Yángüez,Thomas A. Hahn,Jan Kochanowski*

Main category: quant-ph

TL;DR: 研究了在计算限制下保持其操作意义并忠实捕捉计算限制的量子散度。


<details>
  <summary>Details</summary>
Motivation: 量子信息处理在实践中仅限于可有效实现的操作，这促使人们研究能够保持其操作意义并忠实捕捉这些计算限制的量子散度。

Method: 定义了计算最大散度和计算测量 Rènyi 散度，它们都受到一类有效的二元测量的约束。研究了这些散度在无限阶极限和多副本情况下的行为，并引入了正则化版本。

Result: 证明了在无限阶极限下，计算测量 Rènyi 散度与计算最大散度一致。在多副本情况下，建立了一类有效的测量下的假设检验指数的计算 Stein 界限。定义了由计算散度引起的资源度量，并证明了计算测量相对熵的渐近连续性界限。

Conclusion: 提出的计算散度提供了一种在计算约束下进行状态辨别和量化资源的原则性方法，并与信息论设置进行了明确区分。

Abstract: Quantum information processing is limited, in practice, to efficiently
implementable operations. This motivates the study of quantum divergences that
preserve their operational meaning while faithfully capturing these
computational constraints. Using geometric, computational, and information
theoretic tools, we define two new types of computational divergences, which we
term computational max-divergence and computational measured R\'enyi
divergences. Both are constrained by a family of efficient binary measurements,
and thus useful for state discrimination tasks in the computational setting. We
prove that, in the infinite-order limit, the computational measured R\'enyi
divergence coincides with the computational max-divergence, mirroring the
corresponding relation in the unconstrained information-theoretic setting. For
the many-copy regime, we introduce regularized versions and establish a
one-sided computational Stein bound on achievable hypothesis-testing exponents
under efficient measurements, giving the regularized computational measured
relative entropy an operational meaning. We further define resource measures
induced by our computational divergences and prove an asymptotic continuity
bound for the computational measured relative entropy of resource. Focusing on
entanglement, we relate our results to previously proposed computational
entanglement measures and provide explicit separations from the
information-theoretic setting. Together, these results provide a principled,
cohesive approach towards state discrimination tasks and resource
quantification under computational constraints.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [360] [Real-Time Markov Modeling for Single-Photon LiDAR: $1000 \times$ Acceleration and Convergence Analysis](https://arxiv.org/abs/2509.20500)
*Weijian Zhang,Hashan K. Weerasooriya,Prateek Chennuri,Stanley H. Chan*

Main category: eess.SP

TL;DR: 该论文提出了首个用于解决SP-LiDAR死区时间问题的非顺序马尔可夫模型，通过重参数化积分边界和分离死区时间效应，实现了高达1000倍的加速，并提供了关于收敛行为的新理论见解。


<details>
  <summary>Details</summary>
Motivation: SP-LiDAR在3D应用和导航中很重要，但对死区时间下的时间戳分布进行建模是一个挑战。

Method: 提出了一种非顺序马尔可夫模型，通过重参数化积分边界并分离死区时间效应来实现高效的矩阵构建。

Result: 新模型能够快速且精确地计算时间戳分布的稳态分布，与蒙特卡洛模拟结果高度一致，并且计算速度比现有方法快1000倍。

Conclusion: 该模型在计算SP-LiDAR时间戳分布方面效率高且精确，并为理解模型收敛性提供了新的理论分析。

Abstract: Asynchronous single-photon LiDAR (SP-LiDAR) is an important imaging modality
for high-quality 3D applications and navigation, but the modeling of the
timestamp distributions of a SP-LiDAR in the presence of dead time remains a
very challenging open problem. Prior works have shown that timestamps form a
discrete-time Markov chain, whose stationary distribution can be computed as
the leading left eigenvector of a large transition matrix. However,
constructing this matrix is known to be computationally expensive because of
the coupling between states and the dead time. This paper presents the first
non-sequential Markov modeling for the timestamp distribution. The key
innovation is an equivalent formulation that reparameterizes the integral
bounds and separates the effect of dead time as a deterministic row permutation
of a base matrix. This decoupling enables efficient vectorized matrix
construction, yielding up to $1000 \times$ acceleration over existing methods.
The new model produces a nearly exact stationary distribution when compared
with the gold standard Monte Carlo simulations, yet using a fraction of the
time. In addition, a new theoretical analysis reveals the impact of the
magnitude and phase of the second-largest eigenvalue, which are overlooked in
the literature but are critical to the convergence.

</details>


### [361] [Wireless Powered MEC Systems via Discrete Pinching Antennas: TDMA versus NOMA](https://arxiv.org/abs/2509.20908)
*Peng Liu,Zesong Fei,Meng Hua,Guangji Chen,Xinyi Wang,Ruiqi Liu*

Main category: eess.SP

TL;DR: 本文提出了一种离散放置的压电天线（PA）辅助的无线能量供给移动边缘计算（MEC）框架，并开发了一种两层算法来解决优化问题，以最大化计算任务量。


<details>
  <summary>Details</summary>
Motivation: 集成PA到无线能量供给MEC系统可以提高能量传输和任务卸载效率，但以往研究假设PA连续放置，本文研究更实用的离散PA放置。

Method: 提出离散PA辅助的无线能量供给MEC框架，考虑PA激活的灵活性，并结合KKT条件和交叉熵学习方法，开发了两层优化算法，以最大化计算任务量。

Result: 数值结果表明，所提出的设计在能量收集和计算性能方面优于现有设计，并且在较粗的PA激活级别下，TDMA和NOMA的性能相当，而在较精细的激活级别下，TDMA的计算性能优于NOMA。

Conclusion: 离散PA放置是PA辅助的无线能量供给MEC系统的一种实用方法，所提出的优化算法能够有效提升系统性能，并且TDMA和NOMA在不同PA激活粒度下各有优势。

Abstract: Pinching antennas (PAs), a new type of reconfigurable and flexible antenna
structures, have recently attracted significant research interest due to their
ability to create line-of-sight links and mitigate large-scale path loss. Owing
to their potential benefits, integrating PAs into wireless powered mobile edge
computing (MEC) systems is regarded as a viable solution to enhance both energy
transfer and task offloading efficiency. Unlike prior studies that assume ideal
continuous PA placement along waveguides, this paper investigates a practical
discrete PA-assisted wireless powered MEC framework, where devices first
harvest energy from PA-emitted radio-frequency signals and then adopt a partial
offloading mode, allocating part of the harvested energy to local computing and
the remainder to uplink offloading. The uplink phase considers both the
time-division multiple access (TDMA) and non-orthogonal multiple access (NOMA),
each examined under three levels of PA activation flexibility. For each
configuration, we formulate a joint optimization problem to maximize the total
computational bits and conduct a theoretical performance comparison between the
TDMA and NOMA schemes. To address the resulting mixed-integer nonlinear
problems, we develop a two-layer algorithm that combines closed-form solutions
based on Karush-Kuhn-Tucker (KKT) conditions with a cross-entropy-based
learning method. Numerical results validate the superiority of the proposed
design in terms of the harvested energy and computation performance, revealing
that TDMA and NOMA achieve comparable performance under coarser PA activation
levels, whereas finer activation granularity enables TDMA to achieve superior
computation performance over NOMA.

</details>


### [362] [A General Optimization Framework for Movable Antenna Systems via Discrete Sampling](https://arxiv.org/abs/2509.20987)
*Changhao Liu,Weidong Mei,Zhi Chen,Jun Fang,Boyu Ning*

Main category: eess.SP

TL;DR: 本文提出了一种低复杂度、通用的可移动天线（MA）位置优化框架，通过将连续优化问题离散化并引入吉布斯采样（GS）来解决现有方法的计算复杂度和局部最优问题。


<details>
  <summary>Details</summary>
Motivation: 无线通信中，可移动天线（MA）系统因其重塑无线信道的能力而受到关注，但由于信道与天线位置之间的高度非线性关系，优化天线位置以提升通信性能具有挑战性。现有方法（如梯度下降和启发式算法）计算复杂度高或易陷入局部最优。

Method: 将天线移动区域划分为采样点，将连续优化问题转化为离散点选择问题。然后，分多轮顺序更新每个MA的最优采样点。在各轮之间引入吉布斯采样（GS）阶段，探索邻近和随机生成的候选解，以避免收敛到不良的局部最优。

Result: 通过将所提出的框架应用于MA增强的广播系统的联合预编码和天线位置优化问题，数值结果表明，所提出的算法性能接近最优，并显著优于现有基准。

Conclusion: 所提出的低复杂度优化框架能够有效地解决MA位置优化问题，并能获得接近最优的性能。

Abstract: Movable antenna (MA) systems have attracted growing interest in wireless
communications due to their ability to reshape wireless channels via local
antenna movement within a confined region. However, optimizing antenna
positions to enhance communication performance turns out to be challenging due
to the highly nonlinear relationship between wireless channels and antenna
positions. Existing approaches, such as gradient-based and heuristic
algorithms, often suffer from high computational complexity or undesired local
optima. To address the above challenge, this letter proposes a general and
low-complexity optimization framework for MA position optimization.
Specifically, we discretize the antenna movement region into a set of sampling
points, thereby transforming the continuous optimization problem into a
discrete point selection problem. Next, we sequentially update the optimal
sampling point for each MA over multiple rounds. To avoid convergence to poor
local optima, a Gibbs sampling (GS) phase is introduced between rounds to
explore adjacent and randomly generated candidate solutions. As a case study,
we investigate joint precoding and antenna position optimization for an
MA-enhanced broadcast system by applying the proposed framework. Numerical
results demonstrate that the proposed algorithm achieves near-optimal
performance and significantly outperforms existing benchmarks.

</details>


### [363] [Shapley Features for Robust Signal Prediction in Tactile Internet](https://arxiv.org/abs/2509.21032)
*Mohammad Ali Vahedifar,Qi Zhang*

Main category: eess.SP

TL;DR: 提出了一种结合高斯过程（GP）和基于ResNet的神经网络的新颖预测框架，并引入了Shapley特征值（SFV）进行特征选择，以解决触觉互联网（TI）中的信号丢失和延迟问题。


<details>
  <summary>Details</summary>
Motivation: 触觉互联网（TI）需要超低延迟和可靠的触觉信号传输，但数据包丢失和延迟仍然是未解决的挑战。

Method: 提出了一种结合高斯过程（GP）和基于ResNet的神经网络的新颖预测框架，其中GP充当预言家来恢复丢失或严重延迟的信号。为了进一步优化性能，引入了Shapley特征值（SFV）作为一种原则性的特征选择机制，以分离最具信息量的输入进行预测。

Result: GP+SFV框架实现了95.72%的准确率，超越了最先进的LeFo方法11.1%，同时放宽了TI的严格延迟限制。此外，SFV作为一种模块化加速器，与LeFo结合使用可将推理时间缩短27%，与GP结合使用可缩短72%。

Conclusion: GP+SFV框架在准确性和效率方面都表现出色，为TI系统中实际可靠的触觉通信铺平了道路。

Abstract: The Tactile Internet (TI) requires ultra-low latency and reliable haptic
signal transmission, yet packet loss and delay remain unresolved challenges. We
present a novel prediction framework that integrates Gaussian Processes (GP)
with a ResNet-based Neural Network, where GP acts as an oracle to recover
signals lost or heavily delayed. To further optimize performance, we introduce
Shapley Feature Values (SFV), a principled feature selection mechanism that
isolates the most informative inputs for prediction. This GP+SFV framework
achieves 95.72% accuracy, surpassing the state-of-the-art LeFo method by 11.1%,
while simultaneously relaxing TI's rigid delay constraints. Beyond accuracy,
SFV operates as a modular accelerator: when paired with LeFo, it reduces
inference time by 27%, and when paired with GP, by 72%. These results establish
GP+SFV as both a high-accuracy and high-efficiency solution, paving the way for
practical and reliable haptic communications in TI systems.

</details>


### [364] [Neural Integrated Sensing and Communication for the MIMO-OFDM Downlink](https://arxiv.org/abs/2509.21118)
*Ziyi Wang,Frederik Zumegen,Christoph Studer*

Main category: eess.SP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The ongoing convergence of spectrum and hardware requirements for wireless
sensing and communication applications has fueled the integrated sensing and
communication (ISAC) paradigm in next-generation networks. Neural-network-based
ISAC leverages data-driven learning techniques to add sensing capabilities to
existing communication infrastructure. This paper presents a novel
signal-processing framework for such neural ISAC systems based on the
multiple-input multiple-output (MIMO) and orthogonal frequency-division
multiplexing (OFDM) downlink. Our approach enables generalized sensing
functionality without modifying the MIMO-OFDM communication link. Specifically,
our neural ISAC pipeline measures the backscattered communication signals to
generate discrete map representations of spatial occupancy, formulated as
multiclass or multilabel classification problems, which can then be utilized by
specialized downstream tasks. To improve sensing performance in closed or
cluttered environments, our neural ISAC pipeline relies on features
specifically designed to mitigate strong reflective paths. Extensive
simulations using ray-tracing models demonstrate that our neural ISAC framework
reliably reconstructs scene maps without altering the MIMO-OFDM communication
pipeline or reducing data rates.

</details>


### [365] [A Secure ISAC Waveform Design Framework via Random Frequency and PRI Agility](https://arxiv.org/abs/2509.21162)
*Ali Khandan Boroujeni,Hyeon Seok Rou,Ghazal Bagheri,Giuseppe Thadeu Freitas de Abreu,Stefan Köpsell,Kuranage Roche Rayan Ranasinghe,Rafael F. Schaefer*

Main category: eess.SP

TL;DR: 该论文提出了一种新的框架，用于增强集成传感与通信（ISAC）系统的安全性、数据速率和传感性能。


<details>
  <summary>Details</summary>
Motivation: ISAC系统面临安全、数据速率和传感性能的挑战，需要新的方法来增强这些方面。

Method: 本研究采用随机频率和脉冲重复间隔（PRI）捷变（RFPA）方法进行波形设计，并引入一种混合信息嵌入方案（包括ASK、PSK、IM和SM），以及一种低复杂度稀疏匹配滤波器接收器。

Result: 通过随机频率和PRI捷变（RFPA）方法，可以混淆关键雷达参数，有效阻止被动敌方的侦察。混合信息嵌入方案提高了数据吞吐量，并且所提出的接收器可以实现准确的解码。此外，该波形在距离-速度分辨率和杂波抑制方面表现优异。

Conclusion: 所提出的ISAC系统框架通过RFPA波形设计和混合信息嵌入方案，成功地提高了系统的安全性、数据速率和传感性能，并且具有低复杂度的接收器和良好的分辨率及杂波抑制能力。

Abstract: This paper presents a novel framework for enhancing the security, data rate,
and sensing performance of integrated sensing and communications (ISAC)
systems. We employ a random frequency and pulse repetition interval (PRI)
agility (RFPA) method for the waveform design, where the necessary random
sequences are governed by shared secrets. These secrets, which can be
pre-shared or generated via channel reciprocity, obfuscate critical radar
parameters like Doppler frequency and pulse start times, thereby significantly
impeding the ability to perform reconnaissance from a passive adversary without
the secret key. To further introduce enhanced data throughput, we also
introduce a hybrid information embedding scheme that integrates amplitude shift
keying (ASK), phase shift keying (PSK), index modulation (IM), and spatial
modulation (SM), for which a low-complexity sparse-matched filter receiver is
proposed for accurate decoding with practical complexity. Finally, the
excellent range-velocity resolution and clutter suppression of the proposed
waveform are analyzed via the ambiguity function (AF).

</details>


### [366] [Adversarially Robust MIMO Physical Layer Authentication for Non-Stationary Channels](https://arxiv.org/abs/2509.21171)
*Ali Khandan Boroujeni,Ghazal Bagheri,Kuranage Roche Rayan Ranasinghe,Giuseppe Thadeu Freitas de Abreu,Stefan Köpsell,Rafael F. Schaefer*

Main category: eess.SP

TL;DR: 提出了一种针对非平稳MIMO无线信道的对抗性鲁棒物理层认证（AR-PLA）框架，该框架通过结合顺序贝叶斯决策、对比学习的深度特征提取和生成对抗模型来模拟自适应干扰器。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在假设平稳信道或独立观测时，未能充分考虑非平稳MIMO信道的时空相关性、视距（LoS）阻塞和动态干扰策略的问题。

Method: 结合顺序贝叶斯决策、对比学习的深度特征提取和生成对抗建模来模拟自适应干扰器，并对采用2态和3态隐马尔可夫模型（HMM）并进行移动平均在线自适应的认证性能进行了分析。

Result: 提供了认证性能的分析表征，包括对数似然比、检测概率和稳态近似的闭式递推，显著提高了比经典顺序认证方案的鲁棒性。

Conclusion: 所提出的AR-PLA框架能够有效应对非平稳MIMO信道的挑战，并在模拟的自适应干扰下表现出显著的鲁棒性。

Abstract: We propose an adversarially robust physical layer authentication (AR-PLA)
framework tailored for non-stationary multiple-input multiple-output (MIMO)
wireless channels. The framework integrates sequential Bayesian
decision-making, deep feature extraction via contrastive learning, and
generative adversarial modeling to simulate adaptive spoofers. Unlike
conventional methods that assume stationary channels or independent
observations, our approach explicitly accounts for temporal and spatial
correlations, line-of-sight (LoS) blockages, and dynamic spoofing strategies. A
comprehensive analytical characterization of the authentication performance
using both 2-state and 3-state hidden Markov models (HMMs) with moving-average
online adaptation is also provided, with closed-form recursions for
loglikelihood ratios, detection probabilities, and steady-state approximations,
which demonstrate significant robustness improvement over classical sequential
authentication schemes.

</details>


### [367] [An enhanced statistical feature fusion approach using an improved distance evaluation algorithm and weighted K-nearest neighbor for bearing fault diagnosis](https://arxiv.org/abs/2509.21219)
*Amir Eshaghi Chaleshtori,Abdollah Aghaie*

Main category: eess.SP

TL;DR: 本研究提出一种结合改进距离评估算法和加权K近邻分类器的轴承故障诊断方法，通过提取多域统计特征并优化选择，提高了在噪声环境下多传感器数据中的故障诊断准确性。


<details>
  <summary>Details</summary>
Motivation: 轴承是旋转机械中易发生故障的部件，其状态直接影响整体性能，因此准确诊断轴承故障对于确保系统稳定性至关重要。在噪声环境中，从多个传感器收集数据进行故障检测，需要提取和选择信息特征。

Method: 提出一种改进距离评估算法结合加权K近邻（KNN）分类器用于轴承故障诊断。首先，提取并整合时域、频域和时频域的振动统计特征；然后，利用改进的距离评估算法为提取的特征分配权重，通过剔除不敏感特征来保留信息量最大的特征；最后，使用选定的特征训练加权KNN分类器。

Result: 使用渥太华大学的轴承数据验证了所提出的方法，结果表明该方法在准确识别轴承故障方面是有效的。

Conclusion: 所提出的结合改进距离评估算法和加权KNN分类器的轴承故障诊断方法，能够有效提取和选择信息特征，从而在包含噪声的多传感器环境中实现准确的故障诊断。

Abstract: Bearings are among the most failure-prone components in rotating machinery,
and their condition directly impacts overall performance. Therefore, accurately
diagnosing bearing faults is essential for ensuring system stability. However,
detecting such malfunctions in noisy environments, where data is collected from
multiple sensors, necessitates the extraction and selection of informative
features. This paper proposes an improved distance evaluation algorithm
combined with a weighted K-nearest neighbor (KNN) classifier for bearing fault
diagnosis. The process begins with extracting and integrating statistical
features of vibration across the time, frequency, and time-frequency domains.
Next, the improved distance evaluation algorithm assigns weights to the
extracted features, retaining only the most informative ones by eliminating
insensitive features. Finally, the selected features are used to train the
weighted KNN classifier. To validate the proposed method, we employ bearing
data from the University of Ottawa. The results demonstrate the effectiveness
of our approach in accurately identifying bearing faults.

</details>


### [368] [Vision-Intelligence-Enabled Beam Tracking for Cross-Interface Water-Air Optical Wireless Communications](https://arxiv.org/abs/2509.21290)
*Tianqi Mao,Jiayue Liu,Weijie Liu,Dezhi Zheng,Zhaocheng Wang*

Main category: eess.SP

TL;DR: 水-空气光无线通信面临海面波动导致的信号对准难题，本文提出了一种基于AI的视觉跟踪算法来解决此问题。


<details>
  <summary>Details</summary>
Motivation: 水下侦察和矿产勘探等海洋应用需要实时传输大量观测数据，但传统声学方法难以满足需求。光无线通信（OWC）在水下传输方面具有宽带潜力，但水-空气OWC在穿越波动的海面时面临严峻的对准挑战。

Method: 提出了一种基于CNN、Bi-LSTM和注意力机制的视觉引导波束跟踪算法，用于动态预测信道并实时调整收发器对准。

Result: 仿真结果表明，该算法在维持接收信号强度和抑制视觉噪声方面优于传统算法，证明了其在恶劣水-空气OWC系统条件下的鲁棒性。

Conclusion: 本文提出的AI驱动的视觉跟踪算法能够有效解决水-空气光无线通信中的波束对准问题，为实现可靠的水下数据回传提供了有力的技术支持。

Abstract: The escalating development of oceanic applications like underwater
surveillance and mineral exploration, is motivating real-time wireless backhaul
of the considerable observation data. Such prospects can be hardly realized by
the narrowband acoustic approach. Alternatively, optical wireless communication
(OWC) has emerged as a promising solution for maritime and underwater
applications due to its great potential for broadband underwater transmission.
However, the implementations of water-air OWC can be rather challenging,
especially when penetrating the fluctuating interface, where the direction of
refracted signals changes dynamically, causing severe beam misalignment with
airborne stations. This has necessitated real-time transceiver alignment
adaptable to the sophisticated oceanic environment, which has yet to be
addressed. Against this background, this paper establishes a mathematical
channel model for water-air optical wireless transmission across the
fluctuating sea surface. Based on the model, we propose a vision-based beam
tracking algorithm that leverages artificial intelligence (AI) methods for
dynamic channel prediction. The proposed algorithm integrates a convolutional
neural network (CNN) with bi-directional long short-term memory (Bi-LSTM),
which further incorporates the attention mechanism to effectively extract
critical spatio-temporal features from the vision data. The numerical
simulation results show that the proposed algorithm can outperform its
classical counterparts in maintaining receiving signal strength and supressing
the vision noises, which demonstrates its robustness against the the harsh
conditions of water-air OWC systems.

</details>


### [369] [Efficient Digital Methods to Quantify Sensor Output Uncertainty](https://arxiv.org/abs/2509.21311)
*Orestis Kaparounakis,Phillip Stanley-Marbell*

Main category: eess.SP

TL;DR: 本篇论文研究了传感器输出不确定性对数据解释可靠性的影响，重点关注传感器组件信息有限精度导致的测量不确定性。研究以热电堆传感器为例，解释了校准和转换方程如何将校准参数量化产生的 But also 传播到最终的传感器输出。实验结果表明，校准相关量的认知不确定性会导致常用热电堆传感器输出绝对误差高达 5.3°C（相对误差高达 25.7%）。在边缘检测应用中，利用认知不确定性信息可将 Canny 算子的虚报边缘减少到零，同时保持准确性。研究原型在两种商用不确定性跟踪硬件平台上进行了验证，展示了其实际应用的可行性，其中一个平台的平均功耗为 16.7 mW，速度比传统蒙特卡洛计算快 42.9 倍；另一个平台的平均功耗为 147.15 mW，速度快 94.4 倍，为实时应用奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 准确表征传感器输出的不确定性对于许多应用中可靠的数据解释至关重要。

Method: 研究传感器校准和转换方程如何将校准参数量化产生的 But also 传播到最终的传感器输出，并以热电堆传感器为例进行说明。

Result: 实验结果表明，校准相关量的认知不确定性会导致常用热电堆传感器输出绝对误差高达 5.3°C（相对误差高达 25.7%）。在边缘检测应用中，利用认知不确定性信息可将 Canny 算子的虚报边缘减少到零，同时保持准确性。原型验证显示了在实际嵌入式传感器系统上的可行性，并具有显著的性能提升。

Conclusion: 本研究提出的不确定性量化方法在实际传感器系统中是可行且有效的，能够显著提高传感器测量的准确性，并在边缘检测等应用中带来性能改进，为实时应用提供了可能。

Abstract: Accurate characterization of sensor output uncertainty is important for
reliable data interpretation in many applications. Here, we investigate the
impact of transducer-level measurement uncertainty on overall sensor
measurement accuracy due to limited-precision information about sensor
components. We explain our method using thermopile-based sensors as an example
class of sensors. We show how sensor calibration and conversion equations,
which are an essential part of all sensing systems, propagate uncertainties
resulting from the quantization of calibration parameters, to the final,
compensated sensor output. The experimental results show that the epistemic
uncertainty of calibration-related quantities leads to absolute error in the
sensor output as high as 5.3 {\deg}C (and relative error as high as 25.7%) for
one commonly-used thermopile sensor. In one instance of using the epistemic
uncertainty information in edge detection, we show reduction of false-positives
edges to zero for the conventional Canny operator, while maintaining accuracy.
We show these ideas are practical and possible on actual embedded sensor
systems by prototyping them on two commercially-available uncertainty tracking
hardware platforms, one with average power dissipation 16.7 mW and 42.9x
speedup compared to the equal-confidence Monte Carlo computation (the status
quo), and the other with average power dissipation 147.15 mW and 94.4x speedup,
paving the way for use in real time.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [370] [Actively Learning Halfspaces without Synthetic Data](https://arxiv.org/abs/2509.20848)
*Hadley Black,Kasper Green Larsen,Arya Mazumdar,Barna Saha,Geelon So*

Main category: cs.DS

TL;DR: 本研究提出了一种在没有点合成能力的情况下学习半空间的新算法，在特定条件下实现了最优查询复杂度。


<details>
  <summary>Details</summary>
Motivation: 旨在解决经典的“点定位问题”在无法进行任意点查询（点合成）时的低效性问题，现有算法在该限制下存在 $\Omega(n)$ 的查询下界。

Method: 通过限制半空间法向量的来源集合大小为 $D$，利用该结构设计了一种并行二分搜索算法，而非顺序处理每个排序。该算法能够学习在至少 $D$ 个给定排序下是单调的布尔函数。

Result: 在法向量来自大小为 $D$ 的集合的条件下，得到了 $\Theta(D + \log n)$ 的查询界。对于轴对齐半空间，实现了 $O(d + \log n)$ 的查询复杂度，弥补了先前 $O(d \log n)$ vs $\Omega(d + \log n)$ 的差距。此外，还得到了用于 PAC 学习的近乎最优算法，查询复杂度为 $O(\min(D + \log(1/\varepsilon), 1/\varepsilon) \cdot \log D)$。

Conclusion: 本研究成功设计了在无点合成限制下学习半空间的高效算法，并通过利用其结构实现了最优或近乎最优的理论界。该方法论对于更广泛的布尔函数学习问题也具有参考价值。

Abstract: In the classic point location problem, one is given an arbitrary dataset $X
\subset \mathbb{R}^d$ of $n$ points with query access to an unknown halfspace
$f : \mathbb{R}^d \to \{0,1\}$, and the goal is to learn the label of every
point in $X$. This problem is extremely well-studied and a nearly-optimal
$\widetilde{O}(d \log n)$ query algorithm is known due to
Hopkins-Kane-Lovett-Mahajan (FOCS 2020). However, their algorithm is granted
the power to query arbitrary points outside of $X$ (point synthesis), and in
fact without this power there is an $\Omega(n)$ query lower bound due to
Dasgupta (NeurIPS 2004).
  In this work our goal is to design efficient algorithms for learning
halfspaces without point synthesis. To circumvent the $\Omega(n)$ lower bound,
we consider learning halfspaces whose normal vectors come from a set of size
$D$, and show tight bounds of $\Theta(D + \log n)$. As a corollary, we obtain
an optimal $O(d + \log n)$ query deterministic learner for axis-aligned
halfspaces, closing a previous gap of $O(d \log n)$ vs. $\Omega(d + \log n)$.
In fact, our algorithm solves the more general problem of learning a Boolean
function $f$ over $n$ elements which is monotone under at least one of $D$
provided orderings. Our technical insight is to exploit the structure in these
orderings to perform a binary search in parallel rather than considering each
ordering sequentially, and we believe our approach may be of broader interest.
  Furthermore, we use our exact learning algorithm to obtain nearly optimal
algorithms for PAC-learning. We show that $O(\min(D + \log(1/\varepsilon),
1/\varepsilon) \cdot \log D)$ queries suffice to learn $f$ within error
$\varepsilon$, even in a setting when $f$ can be adversarially corrupted on a
$c\varepsilon$-fraction of points, for a sufficiently small constant $c$. This
bound is optimal up to a $\log D$ factor, including in the realizable setting.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [371] [Efficient Kernelized Learning in Polyhedral Games Beyond Full-Information: From Colonel Blotto to Congestion Games](https://arxiv.org/abs/2509.20919)
*Andreas Kontogiannis,Vasilis Pollatos,Gabriele Farina,Panayotis Mertikopoulos,Ioannis Panageas*

Main category: cs.GT

TL;DR: 本篇论文研究如何在指数级数量的行动集和组合结构下，高效地学习多面体博弈中的粗略相关均衡（CCE）。


<details>
  <summary>Details</summary>
Motivation: 在信息不完全的设置下，现有的学习CCE 的方法存在运行时间复杂度次优且不切实际的问题。

Method: 构建了一个基于核化范式的框架，并将其应用于Colonel Blotto博弈、图论对偶博弈和网络拥塞博弈，提供计算上高效的基于支付的学习算法。

Result: 该框架显著提高了在这些设置下学习CCE 的运行时间。

Conclusion: 提出了一种基于核化范式的框架，能够高效地学习多面体博弈（如Colonel Blotto、图论对偶和网络拥塞博弈）中的粗略相关均衡（CCE），特别是在信息不完全的情况下，显著优于先前的工作。

Abstract: We examine the problem of efficiently learning coarse correlated equilibria
(CCE) in polyhedral games, that is, normal-form games with an exponentially
large number of actions per player and an underlying combinatorial structure.
Prominent examples of such games are the classical Colonel Blotto and
congestion games. To achieve computational efficiency, the learning algorithms
must exhibit regret and per-iteration complexity that scale polylogarithmically
in the size of the players' action sets. This challenge has recently been
addressed in the full-information setting, primarily through the use of
kernelization. However, in the case of the realistic, but mathematically
challenging, partial-information setting, existing approaches result in
suboptimal and impractical runtime complexity to learn CCE. We tackle this
limitation by building a framework based on the kernelization paradigm. We
apply this framework to prominent examples of polyhedral games -- namely the
Colonel Blotto, graphic matroid and network congestion games -- and provide
computationally efficient payoff-based learning algorithms, which significantly
improve upon prior works in terms of the runtime for learning CCE in these
settings.

</details>


### [372] [A Category Theoretic Approach to Approximate Game Theory](https://arxiv.org/abs/2509.20932)
*Neil Ghani*

Main category: cs.GT

TL;DR: 本篇论文使用范畴论开发了一种全新的近似博弈论方法，以解决在计算最优决策困难或不可能的情况下，寻找近似最优决策的问题。通过研究“选择函数”和“开放博弈”这两种博弈论模型，论文提出了近似策略并探讨了其代数性质和组合结构。


<details>
  <summary>Details</summary>
Motivation: 在多智能体系统中，准确计算最优决策可能非常困难甚至不可能。因此，研究近似最优决策具有实际意义。

Method: 论文首先研究了“选择函数”，并开发了一个简单而稳健的近似均衡模型。然后，研究人员研究了近似与选择函数的代数性质以及组合结构。之后，研究人员将此方法成功应用于更高级的“开放博弈”模型。

Result: 研究提出了近似策略，并探讨了其代数性质和组合结构，并将此方法成功应用于“开放博弈”模型。

Conclusion: 范畴论可以为近似博弈论提供一种新的、有前景的研究方法。

Abstract: This paper uses category theory to develop an entirely new approach to
approximate game theory. Game theory is the study of how different agents
within a multi-agent system take decisions. At its core, game theory asks what
an optimal decision is in a given scenario. Thus approximate game theory asks
what is an approximately optimal decision in a given scenario. This is
important in practice as -- just like in much of computing -- exact answers
maybe too difficult to compute or even impossible to compute given inherent
uncertainty in input.
  We consider first "Selection Functions" which are functions and develop a
simple yet robust model of approximate equilibria. We develop the algebraic
properties of approximation wrt selection functions and also relate
approximation to the compositional structure of selection functions. We then
repeat this process successfully for Open Games -- a more advanced model of
game theory.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [373] [Boosting LiDAR-Based Localization with Semantic Insight: Camera Projection versus Direct LiDAR Segmentation](https://arxiv.org/abs/2509.20486)
*Sven Ochs,Philip Schörner,Marc René Zofka,J. Marius Zöllner*

Main category: cs.RO

TL;DR: 通过融合激光雷达和相机语义信息来提高自动驾驶定位的精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 激光雷达数据的语义分割在处理不同传感器类型和配置时面临挑战，但语义信息有助于提高基于激光雷达的定位技术的准确性和鲁棒性。

Method: 提出一种将相机语义数据与激光雷达分割相结合的方法，将激光雷达点投影到相机语义分割空间，以提高定位精度和可靠性。使用CoCar NextGen平台、先进的Depth-Anything网络和自适应分割网络进行评估，并利用RTK-GNSS作为地面真值。进行了55公里城市道路驾驶测试。

Result: 融合语义信息的方法提高了激光雷达定位的精度和可靠性。

Conclusion: 这种多模态方法为更可靠、更精确的自动驾驶导航系统铺平了道路，尤其是在复杂的真实世界环境中。

Abstract: Semantic segmentation of LiDAR data presents considerable challenges,
particularly when dealing with diverse sensor types and configurations.
However, incorporating semantic information can significantly enhance the
accuracy and robustness of LiDAR-based localization techniques for autonomous
mobile systems. We propose an approach that integrates semantic camera data
with LiDAR segmentation to address this challenge. By projecting LiDAR points
into the semantic segmentation space of the camera, our method enhances the
precision and reliability of the LiDAR-based localization pipeline.
  For validation, we utilize the CoCar NextGen platform from the FZI Research
Center for Information Technology, which offers diverse sensor modalities and
configurations. The sensor setup of CoCar NextGen enables a thorough analysis
of different sensor types. Our evaluation leverages the state-of-the-art
Depth-Anything network for camera image segmentation and an adaptive
segmentation network for LiDAR segmentation. To establish a reliable ground
truth for LiDAR-based localization, we make us of a Global Navigation Satellite
System (GNSS) solution with Real-Time Kinematic corrections (RTK).
Additionally, we conduct an extensive 55 km drive through the city of
Karlsruhe, Germany, covering a variety of environments, including urban areas,
multi-lane roads, and rural highways. This multimodal approach paves the way
for more reliable and precise autonomous navigation systems, particularly in
complex real-world environments.

</details>


### [374] [Revisiting Formal Methods for Autonomous Robots: A Structured Survey](https://arxiv.org/abs/2509.20488)
*Atef Azaiez,David A. Anisi,Marie Farrell,Matt Luckcuck*

Main category: cs.RO

TL;DR: 本篇论文初步介绍了结构化文献综述在机器人自主系统(RAS)中的应用。


<details>
  <summary>Details</summary>
Motivation: 本文旨在对形式化方法(FM)在机器人自主系统(RAS)中的应用进行结构化文献综述，并分析该领域的发展趋势。

Method: 采用结构化文献综述方法，包括数据库选择、搜索字符串、筛选和协同审查，对识别出的论文进行分类和统计，并研究FM在子符号AI驱动的RAS中的应用和随时间的变化。

Result: 研究发现，与先前调查相比，一些趋势得以延续，同时出现了新的趋势，例如形式化综合方法和概率验证技术的采用明显增加。

Conclusion: 形式化方法在机器人自主系统中的应用正在不断发展，形式化综合和概率验证等新方法正日益受到关注。

Abstract: This paper presents the initial results from our structured literature review
on applications of Formal Methods (FM) to Robotic Autonomous Systems (RAS). We
describe our structured survey methodology; including database selection and
associated search strings, search filters and collaborative review of
identified papers. We categorise and enumerate the FM approaches and formalisms
that have been used for specification and verification of RAS. We investigate
FM in the context of sub-symbolic AI-enabled RAS and examine the evolution of
how FM is used over time in this field. This work complements a pre-existing
survey in this area and we examine how this research area has matured over
time. Specifically, our survey demonstrates that some trends have persisted as
observed in a previous survey. Additionally, it recognized new trends that were
not considered previously including a noticeable increase in adopting Formal
Synthesis approaches as well as Probabilistic Verification Techniques.

</details>


### [375] [Boosting Zero-Shot VLN via Abstract Obstacle Map-Based Waypoint Prediction with TopoGraph-and-VisitInfo-Aware Prompting](https://arxiv.org/abs/2509.20499)
*Boqi Li,Siyuan Li,Weiyi Wang,Anran Li,Zhong Cao,Henry X. Liu*

Main category: cs.RO

TL;DR: 该研究提出了一个用于连续环境的零样本视觉-语言导航（VLN）框架，该框架结合了路径点预测器和多模态大语言模型（MLLM），在R2R-CE和RxR-CE数据集上达到了最先进的零样本性能。


<details>
  <summary>Details</summary>
Motivation: 解决在连续环境中进行视觉-语言导航（VLN）的挑战，该环境要求智能体同时理解语言指令、感知周围环境并规划低级动作。

Method: 提出一个零样本框架，该框架集成了简化的路径点预测器和多模态大语言模型（MLLM）。预测器在抽象障碍图上操作，生成可线性到达的路径点，并将其整合到一个具有明确访问记录的动态拓扑图中。该图和访问信息被编码到提示中，以支持空间结构和探索历史的推理，从而鼓励探索并为MLLM提供局部路径规划能力以进行纠错。

Result: 在R2R-CE和RxR-CE数据集上实现了最先进的零样本性能，成功率分别为41%和36%，优于先前最先进的方法。

Conclusion: 所提出的零样本框架在连续环境的VLN任务中表现出色，展示了通过结合路径点预测和MLLM的推理能力来有效导航的能力。

Abstract: With the rapid progress of foundation models and robotics, vision-language
navigation (VLN) has emerged as a key task for embodied agents with broad
practical applications. We address VLN in continuous environments, a
particularly challenging setting where an agent must jointly interpret natural
language instructions, perceive its surroundings, and plan low-level actions.
We propose a zero-shot framework that integrates a simplified yet effective
waypoint predictor with a multimodal large language model (MLLM). The predictor
operates on an abstract obstacle map, producing linearly reachable waypoints,
which are incorporated into a dynamically updated topological graph with
explicit visitation records. The graph and visitation information are encoded
into the prompt, enabling reasoning over both spatial structure and exploration
history to encourage exploration and equip MLLM with local path planning for
error correction. Extensive experiments on R2R-CE and RxR-CE show that our
method achieves state-of-the-art zero-shot performance, with success rates of
41% and 36%, respectively, outperforming prior state-of-the-art methods.

</details>


### [376] [MELEGROS: Monolithic Elephant-inspired Gripper with Optical Sensors](https://arxiv.org/abs/2509.20510)
*Petr Trunin,Diana Cafiso,Anderson Brazil Nardin,Trevor Exley,Lucia Beccai*

Main category: cs.RO

TL;DR: MELEGROS是一个集成光纤传感器和气动室的仿生象鼻软体机械手，可进行抓取、挖掘和伸展等多种操作。


<details>
  <summary>Details</summary>
Motivation: 受非洲象鼻的启发，设计一种将结构、驱动和传感无缝集成在一起的仿生机械手，并强调传感作为一种内在的、共同制造的能力。

Method: MELEGROS采用单一的软树脂材料和连续的3D打印技术，将六个光波导传感器和五个气动室集成到气动驱动的晶格结构中，实现了传感器的内置和集成。通过四次迭代完成了原型设计。

Result: MELEGROS（132克）的抓取能力超过其自身重量的两倍，能够执行捏、舀和伸展等仿生动作，并且可以抓取葡萄等易碎物品。集成光纤传感器可以区分触摸、弯曲和气室变形，实现多功能感知。

Conclusion: MELEGROS展示了一种软体机器人设计的新范例，其中完全嵌入的传感和连续结构能够固有地支持通用、仿生的操作。

Abstract: The elephant trunk exemplifies a natural gripper where structure, actuation,
and sensing are seamlessly integrated. Inspired by the distal morphology of the
African elephant trunk, we present MELEGROS, a Monolithic ELEphant-inspired
GRipper with Optical Sensors, emphasizing sensing as an intrinsic,
co-fabricated capability. Unlike multi-material or tendon-based approaches,
MELEGROS directly integrates six optical waveguide sensors and five pneumatic
chambers into a pneumatically actuated lattice structure (12.5 mm cell size)
using a single soft resin and one continuous 3D print. This eliminates
mechanical mismatches between sensors, actuators, and body, reducing model
uncertainty and enabling simulation-guided sensor design and placement. Only
four iterations were required to achieve the final prototype, which features a
continuous structure capable of elongation, compression, and bending while
decoupling tactile and proprioceptive signals. MELEGROS (132 g) lifts more than
twice its weight, performs bioinspired actions such as pinching, scooping, and
reaching, and delicately grasps fragile items like grapes. The integrated
optical sensors provide distinct responses to touch, bending, and chamber
deformation, enabling multifunctional perception. MELEGROS demonstrates a new
paradigm for soft robotics where fully embedded sensing and continuous
structures inherently support versatile, bioinspired manipulation.

</details>


### [377] [Action-Informed Estimation and Planning: Clearing Clutter on Staircases via Quadrupedal Pedipulation](https://arxiv.org/abs/2509.20516)
*Prasanna Sriganesh,Barath Satheeshkumar,Anushree Sabnis,Matthew Travers*

Main category: cs.RO

TL;DR: 该研究提出了一种新的感知-动作框架，用于解决机器人在进行物理交互（例如，用一条腿推开障碍物）时，由于物体被遮挡而导致其传感器无法追踪的问题。该框架通过利用本体感受反馈（关于足部接触和腿部位置的信息）来预测被推物体的位移，从而使机器人能够在物体被遮挡时也能进行感知和导航。


<details>
  <summary>Details</summary>
Motivation: 机器人在杂乱环境中自主导航需要与障碍物进行物理交互以清理路径，尤其是在楼梯等复杂地形上，这需要精确控制。然而，单腿推物等耦合动作会带来难以预测的设计约束，特别是当被推物体被传感器遮挡时。

Method: 提出了一种交互感知状态估计循环，利用本体感受反馈（足部接触和腿部位置）来预测物体在被遮挡期间的位移。该预测能够指导感知系统在交互后重新检测物体，从而在部分推动后也能实现精确跟踪。此外，该框架还可以通过学习物理结果，将无法推动的物体重新归类。

Result: 在波士顿动力公司的 Spot 机器人上实现了该方法，实验结果表明，与开环基线相比，该交互感知方法在楼梯上推动物体时，任务成功率和跟踪精度更高。

Conclusion: 该研究成功地为机器人提供了一种在物体被遮挡的情况下，通过交互感知状态估计循环来预测和追踪障碍物的方法，提高了机器人在复杂环境中清理路径的能力和任务成功率。

Abstract: For robots to operate autonomously in densely cluttered environments, they
must reason about and potentially physically interact with obstacles to clear a
path. Safely clearing a path on challenging terrain, such as a cluttered
staircase, requires controlled interaction. For example, a quadrupedal robot
that pushes objects out of the way with one leg while maintaining a stable
stance with its three other legs. However, tightly coupled physical actions,
such as one-legged pushing, create new constraints on the system that can be
difficult to predict at design time. In this work, we present a new method that
addresses one such constraint, wherein the object being pushed by a quadrupedal
robot with one of its legs becomes occluded from the robot's sensors during
manipulation. To address this challenge, we present a tightly coupled
perception-action framework that enables the robot to perceive clutter, reason
about feasible push paths, and execute the clearing maneuver. Our core
contribution is an interaction-aware state estimation loop that uses
proprioceptive feedback regarding foot contact and leg position to predict an
object's displacement during the occlusion. This prediction guides the
perception system to robustly re-detect the object after the interaction,
closing the loop between action and sensing to enable accurate tracking even
after partial pushes. Using this feedback allows the robot to learn from
physical outcomes, reclassifying an object as immovable if a push fails due to
it being too heavy. We present results of implementing our approach on a Boston
Dynamics Spot robot that show our interaction-aware approach achieves higher
task success rates and tracking accuracy in pushing objects on stairs compared
to open-loop baselines.

</details>


### [378] [Selective Progress-Aware Querying for Human-in-the-Loop Reinforcement Learning](https://arxiv.org/abs/2509.20541)
*Anujith Muraleedharan,Anamika J H*

Main category: cs.RO

TL;DR: SPARQ 是一种进步感知查询策略，可减少机器人学习中的不必要反馈。


<details>
  <summary>Details</summary>
Motivation: 现有的面向人类的强化学习（HiL-RL）方法通常假设有充足的反馈，这在实际部署中并不实用，因为现实世界中的反馈成本高昂且有限。

Method: SPARQ 仅在学习停滞或恶化时才请求反馈，从而最大限度地减少了不必要的反馈。

Result: 在模拟的 UR5 机器人抓取立方体任务中，SPARQ 的任务成功率接近完美，其性能与持续获得反馈的策略相当，但反馈成本却减半。与随机查询和无反馈训练相比，SPARQ 提供了更稳定、更高效的学习。

Conclusion: 选择性、基于进度的查询策略可以使 HiL-RL 在实际的人力约束下，更高效、更具可扩展性地用于机器人。

Abstract: Human feedback can greatly accelerate robot learning, but in real-world
settings, such feedback is costly and limited. Existing human-in-the-loop
reinforcement learning (HiL-RL) methods often assume abundant feedback,
limiting their practicality for physical robot deployment. In this work, we
introduce SPARQ, a progress-aware query policy that requests feedback only when
learning stagnates or worsens, thereby reducing unnecessary oracle calls. We
evaluate SPARQ on a simulated UR5 cube-picking task in PyBullet, comparing
against three baselines: no feedback, random querying, and always querying. Our
experiments show that SPARQ achieves near-perfect task success, matching the
performance of always querying while consuming about half the feedback budget.
It also provides more stable and efficient learning than random querying, and
significantly improves over training without feedback. These findings suggest
that selective, progress-based query strategies can make HiL-RL more efficient
and scalable for robots operating under realistic human effort constraints.

</details>


### [379] [GraspFactory: A Large Object-Centric Grasping Dataset](https://arxiv.org/abs/2509.20550)
*Srinidhi Kalgundi Srinivas,Yash Shukla,Adam Arnold,Sachin Chitta*

Main category: cs.RO

TL;DR: GraspFactory是一个包含超过1.09亿个6-DoF抓取的数据集，用于训练机器人抓取模型，以提高其对新颖物体的泛化能力。该数据集包含14,690个用于Franka Panda抓手和33,710个用于Robotiq 2F-85抓手的物体，并已在模拟和现实世界中得到验证。


<details>
  <summary>Details</summary>
Motivation: 机器人抓取模型在处理新物体时泛化能力不足，需要更具几何多样性的数据集来训练能够处理广泛物体的模型。

Method: 创建了一个名为GraspFactory的数据集，其中包含超过1.09亿个6-DoF抓取数据，涵盖了Franka Panda和Robotiq 2F-85抓手以及大量不同物体。使用该数据集的一个子集训练了一个抓取模型，并在模拟和现实世界中进行了测试。

Result: 在GraspFactory数据集上训练的模型在模拟和现实世界环境中都表现出了良好的泛化能力。

Conclusion: GraspFactory数据集能够有效地训练出具有良好泛化能力的机器人抓取模型，解决了在处理新颖物体时面临的挑战。

Abstract: Robotic grasping is a crucial task in industrial automation, where robots are
increasingly expected to handle a wide range of objects. However, a significant
challenge arises when robot grasping models trained on limited datasets
encounter novel objects. In real-world environments such as warehouses or
manufacturing plants, the diversity of objects can be vast, and grasping models
need to generalize to this diversity. Training large, generalizable
robot-grasping models requires geometrically diverse datasets. In this paper,
we introduce GraspFactory, a dataset containing over 109 million 6-DoF grasps
collectively for the Franka Panda (with 14,690 objects) and Robotiq 2F-85
grippers (with 33,710 objects). GraspFactory is designed for training
data-intensive models, and we demonstrate the generalization capabilities of
one such model trained on a subset of GraspFactory in both simulated and
real-world settings. The dataset and tools are made available for download at
https://graspfactory.github.io/.

</details>


### [380] [Uncertainty-Aware Active Source Tracking of Marine Pollution using Unmanned Surface Vehicles](https://arxiv.org/abs/2509.20593)
*Song Ma,Richard Bucknall,Yuanchang Liu*

Main category: cs.RO

TL;DR: 提出一个结合高精度海洋污染扩散模拟和信息路径规划的不确定性感知海洋污染源追踪框架，用于无人表面载具（USV）。


<details>
  <summary>Details</summary>
Motivation: 开发能够实现完全自主化环境监测的能力，为快速响应海洋污染事件提供支持。

Method: 基于机器人操作系统（ROS）实现，利用实时传感器数据更新概率性污染源位置估计，并量化预测的不确定性。

Result: 在模拟环境中进行实验，展示了该框架能够高精度地定位污染源，并能有效率地实现可靠的污染源定位。

Conclusion: 该框架能够实现对海洋污染源的高精度、高置信度定位，并量化了定位的不确定性。

Abstract: This paper proposes an uncertainty-aware marine pollution source tracking
framework for unmanned surface vehicles (USVs). By integrating high-fidelity
marine pollution dispersion simulation with informative path planning
techniques, we demonstrate effective identification of pollution sources in
marine environments. The proposed approach is implemented based on Robot
Operating System (ROS), processing real-time sensor data to update
probabilistic source location estimates. The system progressively refines the
estimation of source location while quantifying uncertainty levels in its
predictions. Experiments conducted in simulated environments with varying
source locations, flow conditions, and starting positions demonstrate the
framework's ability to localise pollution sources with high accuracy. Results
show that the proposed approach achieves reliable source localisation
efficiently. This work contributes to the development of full autonomous
environmental monitoring capabilities essential for rapid response to marine
pollution incidents.

</details>


### [381] [Latent Activation Editing: Inference-Time Refinement of Learned Policies for Safer Multirobot Navigation](https://arxiv.org/abs/2509.20623)
*Satyajeet Das,Darren Chiu,Zhehui Huang,Lars Lindemann,Gaurav S. Sukhatme*

Main category: cs.RO

TL;DR: 通过在推理时编辑预训练策略的中间激活，可以在不修改策略权重的情况下提高多旋翼导航的安全性，从而在不影响任务完成的情况下显著减少碰撞。


<details>
  <summary>Details</summary>
Motivation: 现有的多旋翼导航策略在避开障碍物方面仍有不足，而通过重新训练或微调来解决这些罕见的但关键的安全故障成本高昂，并可能损害先前学到的技能。

Method: 提出了一种名为“推理时潜在激活编辑”（LAE）的框架，该框架包括一个在线分类器来检测与不良行为相关的状态，以及一个激活编辑模块来修改这些激活，以引导策略走向更安全的区域。具体来说，通过训练一个潜在的碰撞世界模型来预测未来的预碰撞激活，以促使更早、更谨慎的避险反应。

Result: LAE 在模拟和现实世界的 Crazyflie 实验中，碰撞次数减少了近 90%，无碰撞轨迹的比例也显著提高，同时保持了任务完成率。

Conclusion: LAE 是一种轻量级的范式，可以在资源受限的硬件上实现，用于对已学习的机器人策略进行部署后的改进，显著提高了安全性，同时保持了任务性能。

Abstract: Reinforcement learning has enabled significant progress in complex domains
such as coordinating and navigating multiple quadrotors. However, even
well-trained policies remain vulnerable to collisions in obstacle-rich
environments. Addressing these infrequent but critical safety failures through
retraining or fine-tuning is costly and risks degrading previously learned
skills. Inspired by activation steering in large language models and latent
editing in computer vision, we introduce a framework for inference-time Latent
Activation Editing (LAE) that refines the behavior of pre-trained policies
without modifying their weights or architecture. The framework operates in two
stages: (i) an online classifier monitors intermediate activations to detect
states associated with undesired behaviors, and (ii) an activation editing
module that selectively modifies flagged activations to shift the policy
towards safer regimes. In this work, we focus on improving safety in
multi-quadrotor navigation. We hypothesize that amplifying a policy's internal
perception of risk can induce safer behaviors. We instantiate this idea through
a latent collision world model trained to predict future pre-collision
activations, thereby prompting earlier and more cautious avoidance responses.
Extensive simulations and real-world Crazyflie experiments demonstrate that LAE
achieves statistically significant reduction in collisions (nearly 90% fewer
cumulative collisions compared to the unedited baseline) and substantially
increases the fraction of collision-free trajectories, while preserving task
completion. More broadly, our results establish LAE as a lightweight paradigm,
feasible on resource-constrained hardware, for post-deployment refinement of
learned robot policies.

</details>


### [382] [Learning Terrain-Specialized Policies for Adaptive Locomotion in Challenging Environments](https://arxiv.org/abs/2509.20635)
*Matheus P. Angarola,Francisco Affonso,Marcelo Becker*

Main category: cs.RO

TL;DR: 一个分层强化学习框架，利用特定地形的策略和课程学习来提高机器人盲行时的敏捷性和跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 机器人需要在各种非结构化地形上进行鲁棒和敏捷的运动，在无法获取地形信息的盲行场景下尤具挑战性。

Method: 提出一个分层强化学习框架，结合特定地形的策略和课程学习。

Result: 在模拟环境中，该方法在成功率方面比通用策略高出16%，并且在低摩擦和不连续的地形上，随着速度目标增加，跟踪误差更低。

Conclusion: 该方法在混合地形场景中表现出卓越的适应性和鲁棒性。

Abstract: Legged robots must exhibit robust and agile locomotion across diverse,
unstructured terrains, a challenge exacerbated under blind locomotion settings
where terrain information is unavailable. This work introduces a hierarchical
reinforcement learning framework that leverages terrain-specialized policies
and curriculum learning to enhance agility and tracking performance in complex
environments. We validated our method on simulation, where our approach
outperforms a generalist policy by up to 16% in success rate and achieves lower
tracking errors as the velocity target increases, particularly on low-friction
and discontinuous terrains, demonstrating superior adaptability and robustness
across mixed-terrain scenarios.

</details>


### [383] [Suction Leap-Hand: Suction Cups on a Multi-fingered Hand Enable Embodied Dexterity and In-Hand Teleoperation](https://arxiv.org/abs/2509.20646)
*Sun Zhaole,Xiaofeng Mao,Jihong Zhu,Yuanlong Zhang,Robert B. Fisher*

Main category: cs.RO

TL;DR: 本论文提出了一种名为SLeap的手，它使用吸盘来实现灵巧的抓握，克服了模仿人手的传统方法的局限性，并实现了人类难以完成的任务。


<details>
  <summary>Details</summary>
Motivation: 传统机器人手模仿人手，在数据收集和能力方面存在局限。

Method: 提出了一种名为SLeap的手，它使用集成吸盘的多个手指，通过单点粘附实现吸力驱动的灵巧抓握，取代了复杂的多点接触。

Result: SLeap手能够稳定地进行单点粘附抓握，简化了数据收集，并实现了诸如单手剪纸和手中写字等人类难以或不可能完成的任务。

Conclusion: 通过超越拟人化限制，新的机器人设计（如SLeap手）可以降低数据收集的门槛，并实现比人类更强的操作能力。

Abstract: Dexterous in-hand manipulation remains a foundational challenge in robotics,
with progress often constrained by the prevailing paradigm of imitating the
human hand. This anthropomorphic approach creates two critical barriers: 1) it
limits robotic capabilities to tasks humans can already perform, and 2) it
makes data collection for learning-based methods exceedingly difficult. Both
challenges are caused by traditional force-closure which requires coordinating
complex, multi-point contacts based on friction, normal force, and gravity to
grasp an object. This makes teleoperated demonstrations unstable and amplifies
the sim-to-real gap for reinforcement learning. In this work, we propose a
paradigm shift: moving away from replicating human mechanics toward the design
of novel robotic embodiments. We introduce the \textbf{S}uction
\textbf{Leap}-Hand (SLeap Hand), a multi-fingered hand featuring integrated
fingertip suction cups that realize a new form of suction-enabled dexterity. By
replacing complex force-closure grasps with stable, single-point adhesion, our
design fundamentally simplifies in-hand teleoperation and facilitates the
collection of high-quality demonstration data. More importantly, this
suction-based embodiment unlocks a new class of dexterous skills that are
difficult or even impossible for the human hand, such as one-handed paper
cutting and in-hand writing. Our work demonstrates that by moving beyond
anthropomorphic constraints, novel embodiments can not only lower the barrier
for collecting robust manipulation data but also enable the stable,
single-handed completion of tasks that would typically require two human hands.
Our webpage is https://sites.google.com/view/sleaphand.

</details>


### [384] [Cyber Racing Coach: A Haptic Shared Control Framework for Teaching Advanced Driving Skills](https://arxiv.org/abs/2509.20653)
*Congkai Shen,Siyuan Yu,Yifan Weng,Haoran Ma,Chen Li,Hiroshi Yasuda,James Dallas,Michael Thompson,John Subosits,Tulga Ersal*

Main category: cs.RO

TL;DR: 本研究提出了一个触觉共享控制框架，用于教授人类驾驶员高级驾驶技能，特别是在赛车和紧急避障等高难度场景下。


<details>
  <summary>Details</summary>
Motivation: 评估触觉共享控制框架在复杂和高要求任务中的技能获取影响，填补了以往研究在技能获取方面的空白。

Method: 构建了一个基于触觉共享控制范式的网络赛车教练框架，包含一个能够与人类协同工作的自动驾驶系统，以及一个根据驾驶员表现逐渐减少辅助的触觉共享控制机制。

Result: 通过与自我学习和完全辅助两种基准进行对比的人类受试者研究表明，该框架能显著提升驾驶员的赛车技能，提高表现和稳定性。

Conclusion: 该触觉共享控制框架能有效帮助人类驾驶员掌握高难度驾驶技能。

Abstract: This study introduces a haptic shared control framework designed to teach
human drivers advanced driving skills. In this context, shared control refers
to a driving mode where the human driver collaborates with an autonomous
driving system to control the steering of a vehicle simultaneously. Advanced
driving skills are those necessary to safely push the vehicle to its handling
limits in high-performance driving such as racing and emergency obstacle
avoidance. Previous research has demonstrated the performance and safety
benefits of shared control schemes using both subjective and objective
evaluations. However, these schemes have not been assessed for their impact on
skill acquisition on complex and demanding tasks. Prior research on long-term
skill acquisition either applies haptic shared control to simple tasks or
employs other feedback methods like visual and auditory aids. To bridge this
gap, this study creates a cyber racing coach framework based on the haptic
shared control paradigm and evaluates its performance in helping human drivers
acquire high-performance driving skills. The framework introduces (1) an
autonomous driving system that is capable of cooperating with humans in a
highly performant driving scenario; and (2) a haptic shared control mechanism
along with a fading scheme to gradually reduce the steering assistance from
autonomy based on the human driver's performance during training. Two
benchmarks are considered: self-learning (no assistance) and full assistance
during training. Results from a human subject study indicate that the proposed
framework helps human drivers develop superior racing skills compared to the
benchmarks, resulting in better performance and consistency.

</details>


### [385] [EEG-Driven AR-Robot System for Zero-Touch Grasping Manipulation](https://arxiv.org/abs/2509.20656)
*Junzhe Wang,Jiarui Xie,Pengfei Hao,Zheng Li,Yi Cai*

Main category: cs.RO

TL;DR: 该研究提出了一个结合运动想象（MI）EEG解码、增强现实（AR）神经反馈和机器人抓取功能的闭环BCI-AR-机器人系统，以实现零接触操作，解决了现有BCI-机器人系统在信号噪声、目标选择灵活性和闭环验证方面的局限性，适用于运动障碍者的辅助场景。


<details>
  <summary>Details</summary>
Motivation: 现有BCI-机器人系统在信号噪声、目标选择灵活性和闭环验证方面的局限性阻碍了其在辅助场景中的实际应用。

Method: 开发了一个闭环BCI-AR-机器人系统，该系统集成了基于运动想象（MI）的EEG解码、增强现实（AR）神经反馈和机器人抓取功能，用于零接触操作。系统包括一个14通道EEG头戴设备用于个体化MI校准，一个基于智能手机的AR界面用于多目标导航和方向一致性反馈，以及一个结合决策输出和视觉姿态估计的机器人手臂用于自主抓取。

Result: MI训练达到了93.1%的准确率和14.8 bit/min的平均信息传输率（ITR）。AR神经反馈显著提高了持续控制能力（SCI = 0.210），并达到了最高的ITR（21.3 bit/min），优于静态、假和无AR基线。闭环抓取成功率为97.2%，效率高，用户报告控制效果好。

Conclusion: AR反馈能够显著稳定基于EEG的控制，并且提出的框架能够实现稳健的零接触抓取，推动了辅助机器人应用和未来人机交互模式的发展。

Abstract: Reliable brain-computer interface (BCI) control of robots provides an
intuitive and accessible means of human-robot interaction, particularly
valuable for individuals with motor impairments. However, existing BCI-Robot
systems face major limitations: electroencephalography (EEG) signals are noisy
and unstable, target selection is often predefined and inflexible, and most
studies remain restricted to simulation without closed-loop validation. These
issues hinder real-world deployment in assistive scenarios. To address them, we
propose a closed-loop BCI-AR-Robot system that integrates motor imagery
(MI)-based EEG decoding, augmented reality (AR) neurofeedback, and robotic
grasping for zero-touch operation. A 14-channel EEG headset enabled
individualized MI calibration, a smartphone-based AR interface supported
multi-target navigation with direction-congruent feedback to enhance stability,
and the robotic arm combined decision outputs with vision-based pose estimation
for autonomous grasping. Experiments are conducted to validate the framework:
MI training achieved 93.1 percent accuracy with an average information transfer
rate (ITR) of 14.8 bit/min; AR neurofeedback significantly improved sustained
control (SCI = 0.210) and achieved the highest ITR (21.3 bit/min) compared with
static, sham, and no-AR baselines; and closed-loop grasping achieved a 97.2
percent success rate with good efficiency and strong user-reported control.
These results show that AR feedback substantially stabilizes EEG-based control
and that the proposed framework enables robust zero-touch grasping, advancing
assistive robotic applications and future modes of human-robot interaction.

</details>


### [386] [Equi-RO: A 4D mmWave Radar Odometry via Equivariant Networks](https://arxiv.org/abs/2509.20674)
*Zeyu Han,Shuocheng Yang,Minghan Zhu,Fang Zhang,Shaobing Xu,Maani Ghaffari,Jianqiang Wang*

Main category: cs.RO

TL;DR: Equi-RO是一个基于4D毫米波雷达的里程计框架，通过使用等变网络处理速度信息，并在稀疏雷达数据中采用图结构来提高准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在GPS信号受限的环境中，自主车辆和机器人需要精确的里程计估计。而4D毫米波雷达作为一种全天候工作的替代方案，能够克服LiDAR和相机在恶劣天气下的不足，并能测量速度。

Method: Equi-RO算法将多普勒速度预处理成图中的不变节点和边特征，并使用单独的网络来处理等变和不变特征。基于图的架构增强了稀疏雷达数据中的特征聚合，从而提高了帧间对应关系。

Result: 在公开数据集和自收集数据集上的实验表明，Equi-RO在准确性和鲁棒性方面优于最先进的算法。与最佳基线相比，我们的方法在公开数据集上的平移和旋转精度分别取得了10.7%和20.0%的相对提升。

Conclusion: Equi-RO通过利用4D毫米波雷达的优势，并结合等变网络和图结构，能够实现高精度的里程计估计，为自主导航提供了鲁棒的解决方案。

Abstract: Autonomous vehicles and robots rely on accurate odometry estimation in
GPS-denied environments. While LiDARs and cameras struggle under extreme
weather, 4D mmWave radar emerges as a robust alternative with all-weather
operability and velocity measurement. In this paper, we introduce Equi-RO, an
equivariant network-based framework for 4D radar odometry. Our algorithm
pre-processes Doppler velocity into invariant node and edge features in the
graph, and employs separate networks for equivariant and invariant feature
processing. A graph-based architecture enhances feature aggregation in sparse
radar data, improving inter-frame correspondence. Experiments on the
open-source dataset and self-collected dataset show Equi-RO outperforms
state-of-the-art algorithms in accuracy and robustness. Overall, our method
achieves 10.7% and 20.0% relative improvements in translation and rotation
accuracy, respectively, compared to the best baseline on the open-source
dataset.

</details>


### [387] [Efficient Construction of Implicit Surface Models From a Single Image for Motion Generation](https://arxiv.org/abs/2509.20681)
*Wei-Teng Chu,Tianyi Zhang,Matthew Johnson-Roberson,Weiming Zhi*

Main category: cs.RO

TL;DR: 该研究提出了一种名为FINS的框架，可以从单个或少数几张图像快速构建隐式表面和SDF场，并在机器人表面跟随任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有从多视图图像构建隐式表面的方法（如NeuS）需要大量数据和长时间训练，本研究旨在解决从单张图像构建隐式距离表示的问题。

Method: FINS框架结合了多分辨率哈希网格编码器和轻量级几何与颜色头，利用预训练的基金模型来估计图像中的几何信息，并采用近似二阶优化器进行高效训练。

Result: FINS可以在几秒钟内收敛，在表面重建和SDF场估计方面优于现有技术，并且能够成功应用于机器人表面跟随任务和多种基准数据集。

Conclusion: FINS是一种高效、准确的单视图隐式表面重建方法，在机器人应用中具有巨大潜力。

Abstract: Implicit representations have been widely applied in robotics for obstacle
avoidance and path planning. In this paper, we explore the problem of
constructing an implicit distance representation from a single image. Past
methods for implicit surface reconstruction, such as \emph{NeuS} and its
variants generally require a large set of multi-view images as input, and
require long training times. In this work, we propose Fast Image-to-Neural
Surface (FINS), a lightweight framework that can reconstruct high-fidelity
surfaces and SDF fields based on a single or a small set of images. FINS
integrates a multi-resolution hash grid encoder with lightweight geometry and
color heads, making the training via an approximate second-order optimizer
highly efficient and capable of converging within a few seconds. Additionally,
we achieve the construction of a neural surface requiring only a single RGB
image, by leveraging pre-trained foundation models to estimate the geometry
inherent in the image. Our experiments demonstrate that under the same
conditions, our method outperforms state-of-the-art baselines in both
convergence speed and accuracy on surface reconstruction and SDF field
estimation. Moreover, we demonstrate the applicability of FINS for robot
surface following tasks and show its scalability to a variety of benchmark
datasets.

</details>


### [388] [Next-Generation Aerial Robots -- Omniorientational Strategies: Dynamic Modeling, Control, and Comparative Analysis](https://arxiv.org/abs/2509.21210)
*Ali Kafili Gavgani,Amin Talaeizadeh,Aria Alasty,Hossein Nejat Pishkenari,Esmaeil Najafi*

Main category: cs.RO

TL;DR: 本研究提出了一种“全向”多旋翼无人机设计，通过操纵螺旋桨轴角来独立控制姿态和位置，并设计了两种控制器（滑模和PID），以提高鲁棒性和效率，并通过仿真验证了其在功耗和抗干扰方面的优势。


<details>
  <summary>Details</summary>
Motivation: 解决传统多旋翼无人机姿态与位置控制耦合的限制，实现“全向”控制。

Method: 推导了多旋翼无人机的动力学模型，设计了滑模控制器和带重力补偿的PID控制器，并实现了控制分配策略以处理输入非仿射问题，仿真验证。

Result: 提出的配置和控制器能够有效处理干扰和不确定性，仿真结果表明在功耗方面具有优势，并进行了不同类型不确定性对控制系统的影响分析。

Conclusion: 该研究为设计“全向”无人机提供了配置选择和控制器设计的实用见解，为未来研究提供了路线图。

Abstract: Conventional multi-rotors are under-actuated systems, hindering them from
independently controlling attitude from position. In this study, we present
several distinct configurations that incorporate additional control inputs for
manipulating the angles of the propeller axes. This addresses the mentioned
limitations, making the systems "omniorientational". We comprehensively derived
detailed dynamic models for all introduced configurations and validated by a
methodology using Simscape Multibody simulations. Two controllers are designed:
a sliding mode controller for robust handling of disturbances and a novel
PID-based controller with gravity compensation integrating linear and
non-linear allocators, designed for computational efficiency. A custom control
allocation strategy is implemented to manage the input-non-affine nature of
these systems, seeking to maximize battery life by minimizing the "Power
Consumption Factor" defined in this study. Moreover, the controllers
effectively managed harsh disturbances and uncertainties. Simulations compare
and analyze the proposed configurations and controllers, majorly considering
their power consumption. Furthermore, we conduct a qualitative comparison to
evaluate the impact of different types of uncertainties on the control system,
highlighting areas for potential model or hardware improvements. The analysis
in this study provides a roadmap for future researchers to design
omniorientational drones based on their design objectives, offering practical
insights into configuration selection and controller design. This research
aligns with the project SAC-1, one of the objectives of Sharif AgRoLab.

</details>


### [389] [RAM-NAS: Resource-aware Multiobjective Neural Architecture Search Method for Robot Vision Tasks](https://arxiv.org/abs/2509.20688)
*Shouren Mao,Minghao Qin,Wei Dong,Huajian Liu,Yongzhuo Gao*

Main category: cs.RO

TL;DR: RAM-NAS 是一种资源感知的多目标神经架构搜索方法，通过子网互蒸馏和硬件感知延迟预测器来优化轻量级模型，显著减少机器人硬件上的推理延迟。


<details>
  <summary>Details</summary>
Motivation: 传统的神经架构搜索（NAS）方法在训练超网和考虑实际机器人硬件资源方面存在不足。

Method: 提出 RAM-NAS，一种资源感知的多目标 NAS 方法。 引入子网互蒸馏（所有通过三明治规则采样的子网相互蒸馏）。 使用解耦知识蒸馏 (DKD) 损失增强 logits 蒸馏。 利用三种机器人边缘硬件的数据训练延迟代理预测器，以在搜索阶段估计硬件推理延迟，从而实现统一的多目标进化搜索以平衡模型精度和延迟。

Result: RAM-NAS 模型家族在 ImageNet 上的 Top-1 准确率范围为 76.7% 至 81.4%。 显著减少了模型在机器人边缘硬件上的推理延迟。 在下游任务的实验验证了该方法的扩展性。 与基于 MobileNetv3 的方法相比，在三种硬件上的检测和分割推理时间均有所减少。

Conclusion: RAM-NAS 填补了机器人硬件资源感知的 NAS 领域的空白。

Abstract: Neural architecture search (NAS) has shown great promise in automatically
designing lightweight models. However, conventional approaches are insufficient
in training the supernet and pay little attention to actual robot hardware
resources. To meet such challenges, we propose RAM-NAS, a resource-aware
multi-objective NAS method that focuses on improving the supernet pretrain and
resource-awareness on robot hardware devices. We introduce the concept of
subnets mutual distillation, which refers to mutually distilling all subnets
sampled by the sandwich rule. Additionally, we utilize the Decoupled Knowledge
Distillation (DKD) loss to enhance logits distillation performance. To expedite
the search process with consideration for hardware resources, we used data from
three types of robotic edge hardware to train Latency Surrogate predictors.
These predictors facilitated the estimation of hardware inference latency
during the search phase, enabling a unified multi-objective evolutionary search
to balance model accuracy and latency trade-offs. Our discovered model family,
RAM-NAS models, can achieve top-1 accuracy ranging from 76.7% to 81.4% on
ImageNet. In addition, the resource-aware multi-objective NAS we employ
significantly reduces the model's inference latency on edge hardware for
robots. We conducted experiments on downstream tasks to verify the scalability
of our methods. The inference time for detection and segmentation is reduced on
all three hardware types compared to MobileNetv3-based methods. Our work fills
the gap in NAS for robot hardware resource-aware.

</details>


### [390] [Incorporating Human-Inspired Ankle Characteristics in a Forced-Oscillation-Based Reduced-Order Model for Walking](https://arxiv.org/abs/2509.20689)
*Chathura Semasinghe,Siavash Rezazadeh*

Main category: cs.RO

TL;DR: 该模型通过结合足部放置和踝部策略，可以稳定初始条件的大误差。通过设计的本体感觉踝部方案，该模型可以稳定小扰动，而无需足部放置控制。


<details>
  <summary>Details</summary>
Motivation: 扩展了基于强制振荡的行走降阶模型，增加了踝部和足部。

Method: 设计了一个受人类启发的踝部动力学范式，并将其整合到行走降阶模型中。

Result: 与点足模型相比，该模型产生了更好的步态特征，并且能够通过足部放置和踝部策略的组合来稳定初始条件的大误差。

Conclusion: 所提出的模型在稳定小扰动时，无需足部放置控制，仅通过设计的本体感觉踝部方案即可实现，这与人类的行走方式相似，有助于更好地理解拟人化行走及其稳定机制。

Abstract: This paper extends the forced-oscillation-based reduced-order model of
walking to a model with ankles and feet. A human-inspired paradigm was designed
for the ankle dynamics, which results in improved gait characteristics compared
to the point-foot model. In addition, it was shown that while the proposed
model can stabilize against large errors in initial conditions through
combination of foot placement and ankle strategies, the model is able to
stabilize against small perturbations without relying on the foot placement
control and solely through the designed proprioceptive ankle scheme. This novel
property, which is also observed in humans, can help in better understanding of
anthropomorphic walking and its stabilization mechanisms.

</details>


### [391] [RuN: Residual Policy for Natural Humanoid Locomotion](https://arxiv.org/abs/2509.20696)
*Qingpeng Li,Chengrui Zhu,Yanming Wu,Xin Yuan,Zhen Zhang,Jian Yang,Yong Liu*

Main category: cs.RO

TL;DR: RuN框架通过解耦运动生成和残差学习，提高了人形机器人在宽速度范围内（0-2.5 m/s）稳定、自然的步态和行走-跑步转换能力，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有深度强化学习方法需要单一策略同时处理运动模仿、速度跟踪和稳定性维持，这带来了挑战。本研究旨在解决使人形机器人能够在宽速度范围内实现自然、动态运动（包括平稳的行走-跑步转换）的挑战。

Method: 提出了一种新颖的解耦残差学习框架RuN。该框架将预训练的条件运动生成器（提供运动先验）与学习轻量级残差校正以处理动态交互的强化学习策略配对，从而分解控制任务。

Result: 在Unitree G1人形机器人模拟和现实实验中，RuN在广泛的速度范围内（0-2.5 m/s）实现了稳定的、自然的步态和流畅的行走-跑步转换，在训练效率和最终性能上均优于最先进的方法。

Conclusion: RuN框架通过解耦运动生成和残差学习，成功提高了人形机器人的运动能力，实现了在不同速度下的稳定和自然的运动，并且在训练效率和最终性能上均优于现有方法。

Abstract: Enabling humanoid robots to achieve natural and dynamic locomotion across a
wide range of speeds, including smooth transitions from walking to running,
presents a significant challenge. Existing deep reinforcement learning methods
typically require the policy to directly track a reference motion, forcing a
single policy to simultaneously learn motion imitation, velocity tracking, and
stability maintenance. To address this, we introduce RuN, a novel decoupled
residual learning framework. RuN decomposes the control task by pairing a
pre-trained Conditional Motion Generator, which provides a kinematically
natural motion prior, with a reinforcement learning policy that learns a
lightweight residual correction to handle dynamical interactions. Experiments
in simulation and reality on the Unitree G1 humanoid robot demonstrate that RuN
achieves stable, natural gaits and smooth walk-run transitions across a broad
velocity range (0-2.5 m/s), outperforming state-of-the-art methods in both
training efficiency and final performance.

</details>


### [392] [Joint Flow Trajectory Optimization For Feasible Robot Motion Generation from Video Demonstrations](https://arxiv.org/abs/2509.20703)
*Xiaoxiang Dong,Matthew Johnson-Roberson,Weiming Zhi*

Main category: cs.RO

TL;DR: 该研究提出了一种名为联合流轨迹优化（JFTO）的框架，用于解决机器人模仿人类视频演示中的抓取姿态生成和物体轨迹模仿问题，克服了身体差异和关节可行性约束的挑战。


<details>
  <summary>Details</summary>
Motivation: 直接模仿人类手部动作存在困难，因为机器人与人类在身体结构和运动能力上存在差异。本研究旨在提出一种新的方法，使机器人能够有效地从人类视频演示中学习并执行抓取和操作任务。

Method: JFTO框架通过将演示视为以物体为中心的指导，平衡了三个目标：选择可行的抓取姿态、生成与演示一致的物体轨迹以及确保在机器人运动学范围内无碰撞执行。该方法将流匹配扩展到SE(3)以进行物体轨迹的概率建模，从而实现避免模式崩溃的、对密度敏感的模仿。该优化方法将抓取相似度、轨迹似然度和碰撞惩罚整合到一个统一的可微目标中。

Result: 在模拟和真实世界的机器人操作任务中，该方法被验证有效，能够实现多样化的抓取和轨迹模仿。

Conclusion: JFTO框架能够有效地解决机器人从视频演示中学习抓取和操作任务的挑战，通过以物体为中心的指导和新颖的SE(3)流匹配技术，实现了更准确、更安全的模仿。

Abstract: Learning from human video demonstrations offers a scalable alternative to
teleoperation or kinesthetic teaching, but poses challenges for robot
manipulators due to embodiment differences and joint feasibility constraints.
We address this problem by proposing the Joint Flow Trajectory Optimization
(JFTO) framework for grasp pose generation and object trajectory imitation
under the video-based Learning-from-Demonstration (LfD) paradigm. Rather than
directly imitating human hand motions, our method treats demonstrations as
object-centric guides, balancing three objectives: (i) selecting a feasible
grasp pose, (ii) generating object trajectories consistent with demonstrated
motions, and (iii) ensuring collision-free execution within robot kinematics.
To capture the multimodal nature of demonstrations, we extend flow matching to
$\SE(3)$ for probabilistic modeling of object trajectories, enabling
density-aware imitation that avoids mode collapse. The resulting optimization
integrates grasp similarity, trajectory likelihood, and collision penalties
into a unified differentiable objective. We validate our approach in both
simulation and real-world experiments across diverse real-world manipulation
tasks.

</details>


### [393] [Building Information Models to Robot-Ready Site Digital Twins (BIM2RDT): An Agentic AI Safety-First Framework](https://arxiv.org/abs/2509.20705)
*Reza Akhavian,Mani Amani,Johannes Mootz,Robert Ashe,Behrad Beheshti*

Main category: cs.RO

TL;DR: 该研究提出了BIM2RDT框架，将建筑信息模型(BIM)转化为动态的、为机器人准备的现场数字孪生(DT)，并优先考虑施工安全。


<details>
  <summary>Details</summary>
Motivation: 建筑行业需要通过连接设计模型、实时现场传感和自主现场操作的机器人物理系统和现场智能来增强数字管理。

Method: 该框架通过整合BIM几何和语义信息、物联网传感器数据和机器人视觉空间数据，利用LLM推理的SG-ICP算法进行点云配准，并通过YOLOE对象检测、Shi-Tomasi角点检测和HAV监控来识别施工元素和安全事件。

Result: SG-ICP算法在点云配准方面的RMSE降低了64.3%-88.3%，并实现了与ISO 5349-1的合规性。

Conclusion: BIM2RDT框架能够将静态BIM模型转化为动态的、机器人就绪的数字孪生，提高安全性并优化现场操作。

Abstract: The adoption of cyber-physical systems and jobsite intelligence that connects
design models, real-time site sensing, and autonomous field operations can
dramatically enhance digital management in the construction industry. This
paper introduces BIM2RDT (Building Information Models to Robot-Ready Site
Digital Twins), an agentic artificial intelligence (AI) framework designed to
transform static Building Information Modeling (BIM) into dynamic, robot-ready
digital twins (DTs) that prioritize safety during execution. The framework
bridges the gap between pre-existing BIM data and real-time site conditions by
integrating three key data streams: geometric and semantic information from BIM
models, activity data from IoT sensor networks, and visual-spatial data
collected by robots during site traversal. The methodology introduces
Semantic-Gravity ICP (SG-ICP), a point cloud registration algorithm that
leverages large language model (LLM) reasoning. Unlike traditional methods,
SG-ICP utilizes an LLM to infer object-specific, plausible orientation priors
based on BIM semantics, improving alignment accuracy by avoiding convergence on
local minima. This creates a feedback loop where robot-collected data updates
the DT, which in turn optimizes paths for missions. The framework employs YOLOE
object detection and Shi-Tomasi corner detection to identify and track
construction elements while using BIM geometry as a priori maps. The framework
also integrates real-time Hand-Arm Vibration (HAV) monitoring, mapping
sensor-detected safety events to the digital twin using IFC standards for
intervention. Experiments demonstrate SG-ICP's superiority over standard ICP,
achieving RMSE reductions of 64.3%--88.3% in alignment across scenarios with
occluded features, ensuring plausible orientations. HAV integration triggers
warnings upon exceeding exposure limits, enhancing compliance with ISO 5349-1.

</details>


### [394] [Digital Twin-Guided Robot Path Planning: A Beta-Bernoulli Fusion with Large Language Model as a Sensor](https://arxiv.org/abs/2509.20709)
*Mani Amani,Reza Akhavian*

Main category: cs.RO

TL;DR: 该框架通过将大语言模型视为传感器，融合自然语言指令和BIM语义地图，生成更安全、更具上下文感知能力的机器人路径。


<details>
  <summary>Details</summary>
Motivation: 将自然语言指令集成到机器人任务规划中，尤其是在建筑领域，利用BIM模型中的丰富信息，以提高路径规划的鲁棒性和有效性。

Method: 提出一种新颖的框架，利用Beta-Bernoulli贝叶斯融合方法，将大语言模型（LLM）的危险评分作为伪计数，更新Beta分布的参数，从而得到一个连续的、上下文感知的排斥增益，并将其融入到基于欧氏距离的势场中，以实现成本启发式的路径规划。该方法能够根据用户指令的情感和上下文调整增益，从而引导机器人沿着更安全、更符合上下文的路径行进。

Result: 仿真结果表明，该Beta-Bernoulli融合方法在路径鲁棒性和有效性方面均取得了定性和定量上的改进。

Conclusion: 该方法为机器人路径规划提供了一种数值稳定且灵活的解决方案，能够整合来自不同用户（如建筑工人和领班）的自然语言指令，并可集成到现有的AI框架中。

Abstract: Integrating natural language (NL) prompts into robotic mission planning has
attracted significant interest in recent years. In the construction domain,
Building Information Models (BIM) encapsulate rich NL descriptions of the
environment. We present a novel framework that fuses NL directives with
BIM-derived semantic maps via a Beta-Bernoulli Bayesian fusion by interpreting
the LLM as a sensor: each obstacle's design-time repulsive coefficient is
treated as a Beta(alpha, beta) random variable and LLM-returned danger scores
are incorporated as pseudo-counts to update alpha and beta. The resulting
posterior mean yields a continuous, context-aware repulsive gain that augments
a Euclidean-distance-based potential field for cost heuristics. By adjusting
gains based on sentiment and context inferred from user prompts, our method
guides robots along safer, more context-aware paths. This provides a
numerically stable method that can chain multiple natural commands and prompts
from construction workers and foreman to enable planning while giving
flexibility to be integrated in any learned or classical AI framework.
Simulation results demonstrate that this Beta-Bernoulli fusion yields both
qualitative and quantitative improvements in path robustness and validity.

</details>


### [395] [RobotDancing: Residual-Action Reinforcement Learning Enables Robust Long-Horizon Humanoid Motion Tracking](https://arxiv.org/abs/2509.20717)
*Zhenguo Sun,Yibo Peng,Yuan Meng,Xukun Li,Bo-Sheng Huang,Zhenshan Bing,Xinlong Wang,Alois Knoll*

Main category: cs.RO

TL;DR: RobotDancing是一个新的框架，通过预测残余关节目标来补偿模型与实际之间的差异，从而实现高动态人形机器人的长时程运动跟踪。


<details>
  <summary>Details</summary>
Motivation: 长时程、高动态的人形机器人运动跟踪仍然存在挑战，因为绝对关节指令无法弥补模型与实际之间的不匹配，导致误差累积。

Method: 该框架采用端到端的强化学习（RL）方法，使用统一的观测、奖励和超参数配置，预测残余关节目标以显式纠正动力学差异。

Result: RobotDancing能够跟踪长达数分钟的高能耗行为（如跳跃、旋转、空翻），并且在硬件上实现了零样本迁移，运动跟踪质量高。

Conclusion: RobotDancing是一个简单、可扩展的框架，能够实现高动态人形机器人的长时程运动跟踪，并且具有良好的泛化能力。

Abstract: Long-horizon, high-dynamic motion tracking on humanoids remains brittle
because absolute joint commands cannot compensate model-plant mismatch, leading
to error accumulation. We propose RobotDancing, a simple, scalable framework
that predicts residual joint targets to explicitly correct dynamics
discrepancies. The pipeline is end-to-end--training, sim-to-sim validation, and
zero-shot sim-to-real--and uses a single-stage reinforcement learning (RL)
setup with a unified observation, reward, and hyperparameter configuration. We
evaluate primarily on Unitree G1 with retargeted LAFAN1 dance sequences and
validate transfer on H1/H1-2. RobotDancing can track multi-minute, high-energy
behaviors (jumps, spins, cartwheels) and deploys zero-shot to hardware with
high motion tracking quality.

</details>


### [396] [SLAM-Free Visual Navigation with Hierarchical Vision-Language Perception and Coarse-to-Fine Semantic Topological Planning](https://arxiv.org/abs/2509.20739)
*Guoyang Zhao,Yudong Li,Weiqing Qi,Kai Zhang,Bonan Liu,Kai Chen,Haoang Li,Jun Ma*

Main category: cs.RO

TL;DR: 该研究提出了一种仅使用视觉的、无 SLAM 的导航框架，用于解决传统 SLAM 方法在快速运动、校准需求和传感器漂移方面的脆弱性，并增强了任务驱动探索的语义推理能力。


<details>
  <summary>Details</summary>
Motivation: 传统机器人导航方法（如 SLAM）在快速移动、校准和传感器漂移方面存在局限性，并且缺乏语义推理能力，无法进行任务驱动的探索。本研究旨在克服这些问题。

Method: 提出了一种仅使用视觉的、无 SLAM 的导航框架，该框架使用语义推理和拓扑表示来代替密集的几何表示。该框架包含一个分层的视觉-语言感知模块，用于融合场景和物体级别的线索，以及一个语义-概率拓扑地图，支持从粗到细的规划。同时，还集成了基于强化学习的运动控制器。

Result: 在仿真和真实世界环境中进行了实验，结果表明该框架在语义准确性、规划质量和导航成功率方面均有提升。消融研究也证明了分层感知和精细局部规划的必要性。

Conclusion: 这项工作引入了一种新的无 SLAM、视觉-语言驱动的导航范式，将机器人探索从以几何为中心的研究转移到以语义为驱动的决策制定。

Abstract: Conventional SLAM pipelines for legged robot navigation are fragile under
rapid motion, calibration demands, and sensor drift, while offering limited
semantic reasoning for task-driven exploration. To deal with these issues, we
propose a vision-only, SLAM-free navigation framework that replaces dense
geometry with semantic reasoning and lightweight topological representations. A
hierarchical vision-language perception module fuses scene-level context with
object-level cues for robust semantic inference. And a semantic-probabilistic
topological map supports coarse-to-fine planning: LLM-based global reasoning
for subgoal selection and vision-based local planning for obstacle avoidance.
Integrated with reinforcement-learning locomotion controllers, the framework is
deployable across diverse legged robot platforms. Experiments in simulation and
real-world settings demonstrate consistent improvements in semantic accuracy,
planning quality, and navigation success, while ablation studies further
showcase the necessity of both hierarchical perception and fine local planning.
This work introduces a new paradigm for SLAM-free, vision-language-driven
navigation, shifting robotic exploration from geometry-centric mapping to
semantics-driven decision making.

</details>


### [397] [MASt3R-Fusion: Integrating Feed-Forward Visual Model with IMU, GNSS for High-Functionality SLAM](https://arxiv.org/abs/2509.20757)
*Yuxuan Zhou,Xingxing Li,Shengyu Li,Zhuohao Yan,Chunxi Xia,Shaoquan Feng*

Main category: cs.RO

TL;DR: MASt3R-Fusion 是一个多传感器辅助视觉 SLAM 框架，它将前馈点图回归与惯性测量和 GNSS 数据相结合，以提高在低纹理和挑战性视觉条件下的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统的视觉 SLAM 系统在低纹理环境、尺度模糊和具有挑战性的视觉条件下表现不佳。尽管基于神经网络的点图回归可以恢复高保真 3D 场景几何，但它们忽略了多传感器信息融合的优势。

Method: MASt3R-Fusion 框架将前馈点图回归与惯性测量和 GNSS 数据紧密集成。该系统将基于 Sim(3) 的视觉对齐约束（以 Hessian 形式）引入通用的度量尺度 SE(3) 因子图，并采用分层因子图设计，实现实时跟踪、度量尺度结构感知和全局一致性建图。

Result: 在公开基准和自收集的数据集上的评估表明，MASt3R-Fusion 在准确性和鲁棒性方面比现有的以视觉为中心的、多传感器的 SLAM 系统有了显著的改进。

Conclusion: MASt3R-Fusion 通过结合前馈点图回归和多传感器信息融合，有效解决了传统视觉 SLAM 的局限性，并在各种条件下实现了高性能的姿态跟踪和建图。

Abstract: Visual SLAM is a cornerstone technique in robotics, autonomous driving and
extended reality (XR), yet classical systems often struggle with low-texture
environments, scale ambiguity, and degraded performance under challenging
visual conditions. Recent advancements in feed-forward neural network-based
pointmap regression have demonstrated the potential to recover high-fidelity 3D
scene geometry directly from images, leveraging learned spatial priors to
overcome limitations of traditional multi-view geometry methods. However, the
widely validated advantages of probabilistic multi-sensor information fusion
are often discarded in these pipelines. In this work, we propose
MASt3R-Fusion,a multi-sensor-assisted visual SLAM framework that tightly
integrates feed-forward pointmap regression with complementary sensor
information, including inertial measurements and GNSS data. The system
introduces Sim(3)-based visualalignment constraints (in the Hessian form) into
a universal metric-scale SE(3) factor graph for effective information fusion. A
hierarchical factor graph design is developed, which allows both real-time
sliding-window optimization and global optimization with aggressive loop
closures, enabling real-time pose tracking, metric-scale structure perception
and globally consistent mapping. We evaluate our approach on both public
benchmarks and self-collected datasets, demonstrating substantial improvements
in accuracy and robustness over existing visual-centered multi-sensor SLAM
systems. The code will be released open-source to support reproducibility and
further research (https://github.com/GREAT-WHU/MASt3R-Fusion).

</details>


### [398] [Leveraging Temporally Extended Behavior Sharing for Multi-task Reinforcement Learning](https://arxiv.org/abs/2509.20766)
*Gawon Lee,Daesol Cho,H. Jin Kim*

Main category: cs.RO

TL;DR: MT-L'evy是一种结合了跨任务行为共享和受Lévy飞行启发的延时探索的新型探索策略，旨在提高多任务强化学习（MTRL）在机器人领域的样本效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 机器人领域的多任务强化学习（MTRL）面临数据收集成本高昂的挑战，限制了其应用。

Method: MT-L'evy策略结合了跨任务行为共享和受Lévy飞行启发的延时探索。它利用在相关任务上训练的策略来指导探索，并根据任务成功率动态调整探索级别。

Result: 实验结果表明，MT-L'evy显著提高了探索和样本效率，通过量化和质性分析得到支持。消融研究也证明了该方法各组成部分的有效性。

Conclusion: 结合行为共享和自适应探索策略能够显著提高MTRL在机器人应用中的实用性。

Abstract: Multi-task reinforcement learning (MTRL) offers a promising approach to
improve sample efficiency and generalization by training agents across multiple
tasks, enabling knowledge sharing between them. However, applying MTRL to
robotics remains challenging due to the high cost of collecting diverse task
data. To address this, we propose MT-L\'evy, a novel exploration strategy that
enhances sample efficiency in MTRL environments by combining behavior sharing
across tasks with temporally extended exploration inspired by L\'evy flight.
MT-L\'evy leverages policies trained on related tasks to guide exploration
towards key states, while dynamically adjusting exploration levels based on
task success ratios. This approach enables more efficient state-space coverage,
even in complex robotics environments. Empirical results demonstrate that
MT-L\'evy significantly improves exploration and sample efficiency, supported
by quantitative and qualitative analyses. Ablation studies further highlight
the contribution of each component, showing that combining behavior sharing
with adaptive exploration strategies can significantly improve the practicality
of MTRL in robotics applications.

</details>


### [399] [SemSight: Probabilistic Bird's-Eye-View Prediction of Multi-Level Scene Semantics for Navigation](https://arxiv.org/abs/2509.20839)
*Jiaxuan He,Jiamei Ren,Chongshang Yan,Wenjie Song*

Main category: cs.RO

TL;DR: SemSight是一个多层次场景语义的概率鸟瞰预测模型，能预测未知区域的结构布局、全局场景上下文和目标区域分布，以提高导航效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在预测未知区域时，要么侧重于单一物体，要么侧重于几何占据图，缺乏对房间级语义结构进行建模的能力，因此需要更有效的导航和环境理解方法。

Method: SemSight采用编码器-解码器网络架构，并引入掩码约束的监督策略，仅在未知区域进行监督，以从观察到的上下文中推断语义结构。在2000个室内布局图上模拟探索过程，构建了一个包含40000个顺序观察数据的数据集进行训练。

Result: SemSight能够提高未知区域关键功能类别的预测性能，在结构一致性（SC）和区域识别准确率（PA）等指标上优于非掩码监督方法，并在封闭循环模拟中提高了导航效率，减少了搜索步骤。

Conclusion: SemSight在预测未知区域的语义结构和目标区域分布方面表现出色，能够有效提升自主导航和探索任务的效率。

Abstract: In target-driven navigation and autonomous exploration, reasonable prediction
of unknown regions is crucial for efficient navigation and environment
understanding. Existing methods mostly focus on single objects or geometric
occupancy maps, lacking the ability to model room-level semantic structures. We
propose SemSight, a probabilistic bird's-eye-view prediction model for
multi-level scene semantics. The model jointly infers structural layouts,
global scene context, and target area distributions, completing semantic maps
of unexplored areas while estimating probability maps for target categories. To
train SemSight, we simulate frontier-driven exploration on 2,000 indoor layout
graphs, constructing a diverse dataset of 40,000 sequential egocentric
observations paired with complete semantic maps. We adopt an encoder-decoder
network as the core architecture and introduce a mask-constrained supervision
strategy. This strategy applies a binary mask of unexplored areas so that
supervision focuses only on unknown regions, forcing the model to infer
semantic structures from the observed context. Experimental results show that
SemSight improves prediction performance for key functional categories in
unexplored regions and outperforms non-mask-supervised approaches on metrics
such as Structural Consistency (SC) and Region Recognition Accuracy (PA). It
also enhances navigation efficiency in closed-loop simulations, reducing the
number of search steps when guiding robots toward target areas.

</details>


### [400] [ImaginationPolicy: Towards Generalizable, Precise and Reliable End-to-End Policy for Robotic Manipulation](https://arxiv.org/abs/2509.20841)
*Dekun Lu,Wei Gao,Kui Jia*

Main category: cs.RO

TL;DR: CoMOK 是一种新颖的机器人操作链方法，用于实现可泛化、准确且可靠的端到端操作策略，克服了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有端到端机器人操作策略在可扩展性和实用性方面的不足，并实现更通用、准确和可靠的操作。

Method: 提出了一种名为“移动定向关键点链”（CoMOK）的新型动作表征方法，并将其应用于神经网络策略的训练中。

Result: CoMOK 动作表征能够支持各种操作任务，并能自然地泛化到不同形状和大小的物体上，实现亚厘米级精度，同时还能处理多阶段任务、多模态机器人行为和可变形物体。

Conclusion: CoMOK 这种动作表征方法在模拟和实际硬件实验中都证明了其有效性，为实现更强大的机器人操作策略迈出了重要一步。

Abstract: End-to-end robot manipulation policies offer significant potential for
enabling embodied agents to understand and interact with the world. Unlike
traditional modular pipelines, end-to-end learning mitigates key limitations
such as information loss between modules and feature misalignment caused by
isolated optimization targets. Despite these advantages, existing end-to-end
neural networks for robotic manipulation--including those based on large
VLM/VLA models--remain insufficiently performant for large-scale practical
deployment. In this paper, we take a step towards an end-to-end manipulation
policy that is generalizable, accurate and reliable. To achieve this goal, we
propose a novel Chain of Moving Oriented Keypoints (CoMOK) formulation for
robotic manipulation. Our formulation is used as the action representation of a
neural policy, which can be trained in an end-to-end fashion. Such an action
representation is general, as it extends the standard end-effector pose action
representation and supports a diverse set of manipulation tasks in a unified
manner. The oriented keypoint in our method enables natural generalization to
objects with different shapes and sizes, while achieving sub-centimeter
accuracy. Moreover, our formulation can easily handle multi-stage tasks,
multi-modal robot behaviors, and deformable objects. Extensive simulated and
hardware experiments demonstrate the effectiveness of our method.

</details>


### [401] [MTRDrive: Memory-Tool Synergistic Reasoning for Robust Autonomous Driving in Corner Cases](https://arxiv.org/abs/2509.20843)
*Ziang Luo,Kangan Qian,Jiahua Wang,Yuechen Luo,Jinyu Miao,Zheng Fu,Yunlong Wang,Sicong Jiang,Zilin Huang,Yifei Hu,Yuhao Yang,Hao Ye,Mengmeng Yang,Xiaojian Dong,Kun Jiang,Diange Yang*

Main category: cs.RO

TL;DR: MTRDrive是一个集成程序化驾驶经验和动态工具包的新框架，旨在提高自动驾驶的泛化能力和前瞻性决策，通过记忆检索和工具包协同推理来解决VLM在分布外场景的幻觉和泛化能力差的问题。新基准Roadwork-VLM用于评估其零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前的视觉-语言模型（VLMs）在端到端自动驾驶方面潜力巨大，但距离实际部署所需的可靠性仍有差距，主要表现为在分布外（OOD）场景中的幻觉和泛化能力差等脆弱性。

Method: MTRDrive通过一个闭环系统，结合了基于记忆的经验检索机制和动态工具包，以增强模型与环境的交互能力，并通过记忆-工具协同推理来提升其推理和决策能力。此外，引入了一个基于复杂道路施工场景的新基准来评估零样本泛化能力。

Result: 在NAVSIM基准测试中，MTRDrive模型（3B参数）在没有思维链的情况下取得了88.3的PDMS，并在高级规划方面取得了79.8%的驾驶指标得分和82.6%的规划准确率。在新提出的Roadwork-VLM基准的零样本评估中，MTRDrive取得了80.2%的驾驶指标得分，展现了在未见场景下鲁棒推理的强大能力。

Conclusion: MTRDrive通过结合程序化驾驶经验和动态工具包，显著提高了自动驾驶的泛化能力和决策鲁棒性，尤其在处理复杂和未知的OOD场景方面表现出色，为实现更安全可靠的自动驾驶系统提供了有潜力的解决方案。

Abstract: Vision-Language Models(VLMs) have demonstrated significant potential for
end-to-end autonomous driving, yet a substantial gap remains between their
current capabilities and the reliability necessary for real-world deployment. A
critical challenge is their fragility, characterized by hallucinations and poor
generalization in out-of-distribution (OOD) scenarios. To bridge this gap, we
introduce MTRDrive, a novel framework that integrates procedural driving
experiences with a dynamic toolkit to enhance generalization and proactive
decision-making.
  MTRDrive addresses these limitations through a closed-loop system that
combines a memory-based experience retrieval mechanism with dynamic toolkits.
This synergy enables the model to interact more effectively with its
environment, improving both reasoning and decision-making capabilities with the
help of our memory-tool synergistic reasoning. Additionally, we introduce a new
benchmark based on complex Roadwork construction scenarios to rigorously
evaluate zero-shot generalization.
  Extensive experiments demonstrate the superior effectiveness of our approach.
On the public NAVSIM benchmark, our 3B-parameter MTRDrive model achieves an
exceptional PDMS of 88.3 without chain-of-thought and sets a state-of-the-art
performance bar on high-level planning, with a driving metric score of 79.8\%
and a planning accuracy of 82.6\%. Rigorous zero-shot evaluation on the new
Roadwork-VLM benchmark shows a strong ability to reason robustly in unseen
scenarios, achieving a driving metric score of 80.2\%. These results highlight
MTRDrive's potential to advance autonomous driving toward safer and more
reliable systems.

</details>


### [402] [Efficient Differentiable Contact Model with Long-range Influence](https://arxiv.org/abs/2509.20917)
*Xiaohan Ye,Kui Wu,Zherong Pan,Taku Komura*

Main category: cs.RO

TL;DR: 梯度不连续或消失问题阻碍了基于梯度下降的优化器在可微分物理中的收敛，这与接触模型的选择有关。本文提出了一种满足特定性质的接触模型，以确保梯度行为的良好，并展示了其在机器人控制和操作任务中的有效性。


<details>
  <summary>Details</summary>
Motivation: 可微分物理在模型预测控制、机器人设计优化和神经偏微分方程求解器等应用中越来越重要，但其提供的导数信息可能存在突变或消失，阻碍了基于梯度的优化器的收敛。

Method: 提出了一组接触模型必须满足的性质，以确保良好的梯度信息，并提出了一种满足这些性质的实用接触模型，用于可微分刚体模拟器，同时保持计算效率。

Result: 提出的接触模型能够发现复杂的、富含接触的控制信号，并成功执行一系列下游的运动和操作任务。

Conclusion: 提出的接触模型可以解决可微分物理中梯度行为不佳的问题，并在各种机器人任务中表现出色。

Abstract: With the maturation of differentiable physics, its role in various downstream
applications: such as model predictive control, robotic design optimization,
and neural PDE solvers, has become increasingly important. However, the
derivative information provided by differentiable simulators can exhibit abrupt
changes or vanish altogether, impeding the convergence of gradient-based
optimizers. In this work, we demonstrate that such erratic gradient behavior is
closely tied to the design of contact models. We further introduce a set of
properties that a contact model must satisfy to ensure well-behaved gradient
information. Lastly, we present a practical contact model for differentiable
rigid-body simulators that satisfies all of these properties while maintaining
computational efficiency. Our experiments show that, even from simple
initializations, our contact model can discover complex, contact-rich control
signals, enabling the successful execution of a range of downstream locomotion
and manipulation tasks.

</details>


### [403] [Autoregressive End-to-End Planning with Time-Invariant Spatial Alignment and Multi-Objective Policy Refinement](https://arxiv.org/abs/2509.20938)
*Jianbo Zhao,Taiyu Ban,Xiangjie Li,Xingtai Gui,Hangning Zhou,Lei Liu,Hongwei Zhao,Bin Li*

Main category: cs.RO

TL;DR: TISA模块通过时间不变的空间对齐、运动学预测和多目标后训练来解决自回归规划中的时空不一致性问题，在NAVSIM数据集上达到了89.8 PDMS的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有的自回归模型在端到端规划中存在时空不一致性问题，因为规划器需要根据过去的感知数据来推断未来的动作，这导致了一个不一致的世界观，限制了模型的性能上限。

Method: 提出了一种时间不变空间对齐（TISA）模块，该模块学习将初始环境特征投影到每个未来时间步长的、一致的以自我为中心的框架中，从而在不显式预测未来场景的情况下纠正代理的“世界观”。此外，还采用了一个运动学动作预测头（即加速度和偏航率）来确保生成物理上可行的轨迹。最后，引入了一个使用直接偏好优化（DPO）的多目标后训练阶段，以超越纯粹的模仿学习，并提供比标准DPO更细粒度的学习信号。

Result: 该模型在NAVSIM数据集上达到了89.8 PDMS，超越了其他自回归模型，取得了最先进的性能。

Conclusion: TISA模块、运动学预测头和多目标DPO后训练阶段的结合，有效地解决了自回归规划中的时空不一致性问题，并生成了物理上可行的、具有竞争力的规划轨迹。

Abstract: The inherent sequential modeling capabilities of autoregressive models make
them a formidable baseline for end-to-end planning in autonomous driving.
Nevertheless, their performance is constrained by a spatio-temporal
misalignment, as the planner must condition future actions on past sensory
data. This creates an inconsistent worldview, limiting the upper bound of
performance for an otherwise powerful approach. To address this, we propose a
Time-Invariant Spatial Alignment (TISA) module that learns to project initial
environmental features into a consistent ego-centric frame for each future time
step, effectively correcting the agent's worldview without explicit future
scene prediction. In addition, we employ a kinematic action prediction head
(i.e., acceleration and yaw rate) to ensure physically feasible trajectories.
Finally, we introduce a multi-objective post-training stage using Direct
Preference Optimization (DPO) to move beyond pure imitation. Our approach
provides targeted feedback on specific driving behaviors, offering a more
fine-grained learning signal than the single, overall objective used in
standard DPO. Our model achieves a state-of-the-art 89.8 PDMS on the NAVSIM
dataset among autoregressive models. The video document is available at
https://tisa-dpo-e2e.github.io/.

</details>


### [404] [BactoBot: A Low-Cost, Bacteria-Inspired Soft Underwater Robot for Marine Exploration](https://arxiv.org/abs/2509.20964)
*Rubaiyat Tasnim Chowdhury,Nayan Bala,Ronojoy Roy,Tarek Mahmud*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Traditional rigid underwater vehicles pose risks to delicate marine
ecosystems. This paper presents BactoBot, a low-cost, soft underwater robot
designed for safe and gentle marine exploration. Inspired by bacterial
flagellar propulsion, BactoBot features 12 flexible, silicone-based arms
arranged on a 3D-printed dodecahedral frame. The design provides inherent
compliance, redundancy, and the potential for omnidirectional movement. The
prototype was fabricated using accessible DIY methods, including food-grade
silicone molding, 3D printing, and off-the-shelf microcontrollers.
Waterproofing and buoyancy calibration protocols were developed, and the robot
was successfully tested in a controlled water tank, demonstrating forward
motion and turning. The results validate the feasibility of replicating complex
biological locomotion at low cost. The project lays a foundation for
environmentally conscious robotic tools, particularly for marine science in
resource-constrained settings, and identifies pathways toward autonomous
operation and field deployment.

</details>


### [405] [AnywhereVLA: Language-Conditioned Exploration and Mobile Manipulation](https://arxiv.org/abs/2509.21006)
*Konstantin Gubernatorov,Artem Voronov,Roman Voronov,Sergei Pasynkov,Stepan Perminov,Ziang Guo,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: AnywhereVLA是一个模块化框架，用于在未知的室内环境中进行自然语言驱动的抓取和放置。它通过解析文本提示生成任务图，并结合SLAM、语义地图和抓取规划，最终在板载硬件上实现实时操作，在测试中达到46%的任务成功率。


<details>
  <summary>Details</summary>
Motivation: 在未知的、不可预测的室内环境中实现自然语言驱动的物品抓取和放置。

Method: 1. 将用户文本提示解析为结构化任务图。
2. 该任务图指导SLAM（使用激光雷达和摄像头）、度量语义地图构建以及面向任务的边界探索策略。
3. 采用一种方法规划器来选择考虑可见性和可达性的抓取前基准姿态。
4. 使用一个名为SmolVLA的紧凑型抓取和放置模型，该模型在SO-101平台上针对抓取和放置轨迹进行了微调，以理解局部视觉情境并生成抓取和放置建议。
5. 整个系统完全在消费级硬件（Jetson Orin NX用于感知和VLA，Intel NUC用于SLAM、探索和控制）上运行，实现实时操作。

Result: 在多房间实验室环境中，该系统实现了46%的总体任务成功率，同时在嵌入式计算上保持了吞吐量。

Conclusion: 通过结合经典的导航技术和经过微调的视觉-语言-动作（VLA）抓取和放置模型，该系统成功地继承了基于几何的导航的可靠性，以及视觉-语言驱动抓取和放置的灵活性和任务泛化能力。

Abstract: We address natural language pick-and-place in unseen, unpredictable indoor
environments with AnywhereVLA, a modular framework for mobile manipulation. A
user text prompt serves as an entry point and is parsed into a structured task
graph that conditions classical SLAM with LiDAR and cameras, metric semantic
mapping, and a task-aware frontier exploration policy. An approach planner then
selects visibility and reachability aware pre grasp base poses. For
interaction, a compact SmolVLA manipulation head is fine tuned on platform pick
and place trajectories for the SO-101 by TheRobotStudio, grounding local visual
context and sub-goals into grasp and place proposals. The full system runs
fully onboard on consumer-level hardware, with Jetson Orin NX for perception
and VLA and an Intel NUC for SLAM, exploration, and control, sustaining
real-time operation. We evaluated AnywhereVLA in a multi-room lab under static
scenes and normal human motion. In this setting, the system achieves a $46\%$
overall task success rate while maintaining throughput on embedded compute. By
combining a classical stack with a fine-tuned VLA manipulation, the system
inherits the reliability of geometry-based navigation with the agility and task
generalization of language-conditioned manipulation.

</details>


### [406] [Multi-Robot Vision-Based Task and Motion Planning for EV Battery Disassembly and Sorting](https://arxiv.org/abs/2509.21020)
*Abdelaziz Shaarawy,Cansu Erdogan,Rustam Stolkin,Alireza Rastegarpanah*

Main category: cs.RO

TL;DR: 该研究提出了一种用于电动汽车电池拆解的多机器人任务与运动规划（TAMP）框架，通过结合符号任务规划、成本和可达性感知分配以及基于演示学习的运动规划器，实现了更紧凑、更安全、更精确的机器人操作。


<details>
  <summary>Details</summary>
Motivation: 电动汽车电池拆解需要精确的多机器人协调、快速可靠的运动以及在复杂动态场景下的鲁棒碰撞安全保障。

Method: 提出了一种四层TAMP框架，包括符号任务规划、成本和可达性感知分配、TP-GMM引导的运动规划器（从演示中学习），并结合了YOLOv8的立体视觉进行组件定位，以及基于OctoMap的3D映射和MoveIt中的FCL碰撞检测，实现了预测性的数字孪生碰撞检测与基于视觉的反应式避障。

Result: 在两台UR10e机器人上对电缆、汇流排、服务插头和三节锂电池的拆卸进行了验证，与基线方法相比，平均末端执行器路径长度减少了63.3%，完成时间减少了8.1%，机器人占据空间体积显著缩小，且机器人间的重叠区域减小了47%。

Conclusion: 该方法在非结构化、动态环境中提高了多机器人电动汽车电池拆解的自主性、精确性和安全性。

Abstract: Electric-vehicle (EV) battery disassembly requires precise multi-robot
coordination, short and reliable motions, and robust collision safety in
cluttered, dynamic scenes. We propose a four-layer task-and-motion planning
(TAMP) framework that couples symbolic task planning and cost- and
accessibility-aware allocation with a TP-GMM-guided motion planner learned from
demonstrations. Stereo vision with YOLOv8 provides real-time component
localization, while OctoMap-based 3D mapping and FCL(Flexible Collision
Library) checks in MoveIt unify predictive digital-twin collision checking with
reactive, vision-based avoidance. Validated on two UR10e robots across cable,
busbar, service plug, and three leaf-cell removals, the approach yields
substantially more compact and safer motions than a default RRTConnect baseline
under identical perception and task assignments: average end-effector path
length drops by $-63.3\%$ and makespan by $-8.1\%$; per-arm swept volumes
shrink (R1: $0.583\rightarrow0.139\,\mathrm{m}^3$; R2:
$0.696\rightarrow0.252\,\mathrm{m}^3$), and mutual overlap decreases by $47\%$
($0.064\rightarrow0.034\,\mathrm{m}^3$). These results highlight improved
autonomy, precision, and safety for multi-robot EV battery disassembly in
unstructured, dynamic environments.

</details>


### [407] [KeyWorld: Key Frame Reasoning Enables Effective and Efficient World Models](https://arxiv.org/abs/2509.21027)
*Sibo Li,Qianyue Hao,Yu Shang,Yong Li*

Main category: cs.RO

TL;DR: KeyWorld框架通过在关键帧上集中计算并使用轻量级卷积模型填充中间帧，提高了文本条件下的机器人世界模型的速度和物理合理性。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人世界模型在推理速度和物理可信度方面存在瓶颈，限制了其在现实世界中的应用，原因是逐帧生成方法计算冗余且忽略了关键过渡的语义重要性。

Method: KeyWorld框架首先通过迭代简化机器人运动轨迹来识别关键帧，然后训练DiT模型从文本描述生成这些关键帧，最后使用轻量级插值器重建完整视频。

Result: 与逐帧生成基线相比，KeyWorld的速度提高了5.68倍，并且通过关注运动感知关键帧，提高了生成视频的物理有效性，尤其是在复杂任务上。

Conclusion: KeyWorld为在需要高效且有效的世界模型的机器人实时控制和其他领域部署世界模型提供了一条实用的途径。

Abstract: Robotic world models are a promising paradigm for forecasting future
environment states, yet their inference speed and the physical plausibility of
generated trajectories remain critical bottlenecks, limiting their real-world
applications. This stems from the redundancy of the prevailing frame-to-frame
generation approach, where the model conducts costly computation on similar
frames, as well as neglecting the semantic importance of key transitions. To
address this inefficiency, we propose KeyWorld, a framework that improves
text-conditioned robotic world models by concentrating transformers computation
on a few semantic key frames while employing a lightweight convolutional model
to fill the intermediate frames. Specifically, KeyWorld first identifies
significant transitions by iteratively simplifying the robot's motion
trajectories, obtaining the ground truth key frames. Then, a DiT model is
trained to reason and generate these physically meaningful key frames from
textual task descriptions. Finally, a lightweight interpolator efficiently
reconstructs the full video by inpainting all intermediate frames. Evaluations
on the LIBERO benchmark demonstrate that KeyWorld achieves a 5.68$\times$
acceleration compared to the frame-to-frame generation baseline, and focusing
on the motion-aware key frames further contributes to the physical validity of
the generated videos, especially on complex tasks. Our approach highlights a
practical path toward deploying world models in real-time robotic control and
other domains requiring both efficient and effective world models. Code is
released at https://anonymous.4open.science/r/Keyworld-E43D.

</details>


### [408] [MPC-based Deep Reinforcement Learning Method for Space Robotic Control with Fuel Sloshing Mitigation](https://arxiv.org/abs/2509.21045)
*Mahya Ramezani,M. Amin Alandihallaj,Barış Can Yalçın,Miguel Angel Olivares Mendez,Holger Voos*

Main category: cs.RO

TL;DR: 本研究提出了一种结合强化学习(RL)和模型预测控制(MPC)的卫星自主对接框架，以解决燃料晃动导致的稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 传统对接控制在微重力环境下，由于燃料晃动产生的不可预测力矩而面临稳定性挑战。

Method: 该方法整合了近端策略优化(PPO)和软Actor-Critic(SAC)强化学习算法与模型预测控制(MPC)，利用MPC的预测能力加速RL训练并提高控制鲁棒性。

Result: 通过零重力实验室的平面稳定性和高保真数值模拟（包含6-DOF对接和燃料晃动动力学），SAC-MPC方法在对接精度、成功率和控制力消耗方面均优于单独的RL和PPO-MPC方法。

Conclusion: 该研究提出的SAC-MPC框架能够实现燃油效率高、抗干扰能力强的卫星对接，为在轨燃料加注和维护任务的可行性提供了支持。

Abstract: This paper presents an integrated Reinforcement Learning (RL) and Model
Predictive Control (MPC) framework for autonomous satellite docking with a
partially filled fuel tank. Traditional docking control faces challenges due to
fuel sloshing in microgravity, which induces unpredictable forces affecting
stability. To address this, we integrate Proximal Policy Optimization (PPO) and
Soft Actor-Critic (SAC) RL algorithms with MPC, leveraging MPC's predictive
capabilities to accelerate RL training and improve control robustness. The
proposed approach is validated through Zero-G Lab of SnT experiments for planar
stabilization and high-fidelity numerical simulations for 6-DOF docking with
fuel sloshing dynamics. Simulation results demonstrate that SAC-MPC achieves
superior docking accuracy, higher success rates, and lower control effort,
outperforming standalone RL and PPO-MPC methods. This study advances
fuel-efficient and disturbance-resilient satellite docking, enhancing the
feasibility of on-orbit refueling and servicing missions.

</details>


### [409] [Normalizing Flows are Capable Visuomotor Policy Learning Models](https://arxiv.org/abs/2509.21073)
*Simon Kristoffersson Lind,Jialong Li,Maj Stenmark,Volker Krüger*

Main category: cs.RO

TL;DR: 该研究提出了一种名为Normalizing Flows Policy的新型视觉-运动策略学习模型，它使用正态流替代了扩散模型，在保持相当的性能的同时，提高了样本效率和推理速度（高达30倍），并能提供统计上合理的置信度度量。


<details>
  <summary>Details</summary>
Motivation: 在通用机器人领域，虽然扩散模型等概率模型被广泛用于学习复杂行为，但它们存在推理计算成本高和无法量化输出不确定性等缺点。模型的信任度（对可靠、通用的机器人至关重要）与其提供置信度度量的能力密切相关。

Method: 提出了一种基于正态流的新型视觉-运动策略学习模型（Normalizing Flows Policy）。

Result: 在四项不同的模拟机器人任务中，Normalizing Flows Policy实现了与扩散策略相当甚至更优的性能，同时提高了样本效率，并将推理速度提高了30倍。此外，消融研究验证了该模型在架构和训练方面的关键技术。

Conclusion: 正态流为扩散模型提供了一个强大且在统计上合理、推理高效的替代方案，适用于需要信任度和不确定性量化的机器人任务。

Abstract: The field of general purpose robotics has recently embraced powerful
probabilistic models, such as diffusion models, to model and learn complex
behaviors. However, these models often come with significant trade-offs, namely
high computational costs for inference and a fundamental inability to quantify
output uncertainty. We argue that a model's trustworthiness, a critical factor
for reliable, general-purpose robotics, is inherently linked to its ability to
provide confidence measures.
  In this work, we introduce Normalizing Flows Policy, a novel visuomotor
policy learning model based on Normalizing Flows. We show that Normalizing
Flows are a natural and powerful alternative to diffusion models, providing
both a statistically sound measure of confidence and a highly efficient
inference process. Through comprehensive experiments across four distinct
simulated robotic tasks, we demonstrate that Normalizing Flows Policy achieves
performance comparable to, and often surpassing, Diffusion Policy, and it does
so not only with improved sample efficiency but also with up to 30 times faster
inference. Additionally, our ablation study validates several key architectural
and training techniques that enable Normalizing Flows to perform well in this
domain.

</details>


### [410] [Flight Dynamics to Sensing Modalities: Exploiting Drone Ground Effect for Accurate Edge Detection](https://arxiv.org/abs/2509.21085)
*Chenyu Zhao,Jingao Xu,Ciyu Ruan,Haoyang Wang,Shengbo Wang,Jiaqi Li,Jirong Zha,Weijie Hong,Zheng Yang,Yunhao Liu,Xiao-Ping Zhang,Xinlei Chen*

Main category: cs.RO

TL;DR: 利用无人机传感器和飞行指令检测地效变化，实现低功耗、高精度的边缘检测。


<details>
  <summary>Details</summary>
Motivation: 现有无人机边缘检测方法成本高、计算量大，限制了其在灾难救援和自主导航等领域的应用。

Method: 分析无人机基本姿态传感器读数和飞行指令，检测地效变化，以此判断无人机是否飞越不同材质边界，实现边缘检测。

Result: 实现了高检测精度，平均检测距离误差为0.051m，比基线方法性能提升86%，同时仅消耗43mW功率。

Conclusion: 地效可以作为一种新的传感模式，用于低成本、高效率的无人机边缘检测，在资源效率和检测能力方面具有独特优势。

Abstract: Drone-based rapid and accurate environmental edge detection is highly
advantageous for tasks such as disaster relief and autonomous navigation.
Current methods, using radars or cameras, raise deployment costs and burden
lightweight drones with high computational demands. In this paper, we propose
AirTouch, a system that transforms the ground effect from a stability "foe" in
traditional flight control views, into a "friend" for accurate and efficient
edge detection. Our key insight is that analyzing drone basic attitude sensor
readings and flight commands allows us to detect ground effect changes. Such
changes typically indicate the drone flying over a boundary of two materials,
making this information valuable for edge detection. We approach this insight
through theoretical analysis, algorithm design, and implementation, fully
leveraging the ground effect as a new sensing modality without compromising
drone flight stability, thereby achieving accurate and efficient scene edge
detection. We also compare this new sensing modality with vision-based methods
to clarify its exclusive advantages in resource efficiency and detection
capability. Extensive evaluations demonstrate that our system achieves a high
detection accuracy with mean detection distance errors of 0.051m, outperforming
the baseline method performance by 86%. With such detection performance, our
system requires only 43 mW power consumption, contributing to this new sensing
modality for low-cost and highly efficient edge detection.

</details>


### [411] [Cross-Modal Instructions for Robot Motion Generation](https://arxiv.org/abs/2509.21107)
*William Barron,Xiaoxiang Dong,Matthew Johnson-Roberson,Weiming Zhi*

Main category: cs.RO

TL;DR: 机器人可以通过文本和草图等跨模态指令学习新行为，无需物理演示。


<details>
  <summary>Details</summary>
Motivation: 传统的机器人新行为教学方法（如遥操作或实体引导）效率低下且难以扩展。现有的基于草图的方法也面临数据收集的挑战。

Method: 提出了一种名为CrossInstruct的新框架，该框架将跨模态指令（如文本标签）作为示例整合到基础视觉-语言模型（VLM）的上下文输入中。VLM会迭代地查询一个经过微调的小型模型，并在多个2D视图中合成所需的运动，然后将这些运动融合成机器人工作空间中3D运动轨迹的连贯分布。此外，还引入了一个下游强化学习流程，利用CrossInstruct的输出高效学习完成精细任务的策略。

Result: CrossInstruct在基准模拟任务和真实硬件上进行了严格评估，证明了其在无需额外微调的情况下也能有效生成可执行的机器人行为，并为后续通过强化学习精炼的策略提供了强大的初始化。

Conclusion: CrossInstruct框架通过结合大型VLM的推理能力和精细的点位模型，实现了机器人从跨模态指令中学习新行为，解决了传统方法效率低下和难以扩展的问题，并在模拟和真实环境中得到了验证。

Abstract: Teaching robots novel behaviors typically requires motion demonstrations via
teleoperation or kinaesthetic teaching, that is, physically guiding the robot.
While recent work has explored using human sketches to specify desired
behaviors, data collection remains cumbersome, and demonstration datasets are
difficult to scale. In this paper, we introduce an alternative paradigm,
Learning from Cross-Modal Instructions, where robots are shaped by
demonstrations in the form of rough annotations, which can contain free-form
text labels, and are used in lieu of physical motion. We introduce the
CrossInstruct framework, which integrates cross-modal instructions as examples
into the context input to a foundational vision-language model (VLM). The VLM
then iteratively queries a smaller, fine-tuned model, and synthesizes the
desired motion over multiple 2D views. These are then subsequently fused into a
coherent distribution over 3D motion trajectories in the robot's workspace. By
incorporating the reasoning of the large VLM with a fine-grained pointing
model, CrossInstruct produces executable robot behaviors that generalize beyond
the environment of in the limited set of instruction examples. We then
introduce a downstream reinforcement learning pipeline that leverages
CrossInstruct outputs to efficiently learn policies to complete fine-grained
tasks. We rigorously evaluate CrossInstruct on benchmark simulation tasks and
real hardware, demonstrating effectiveness without additional fine-tuning and
providing a strong initialization for policies subsequently refined via
reinforcement learning.

</details>


### [412] [Rich State Observations Empower Reinforcement Learning to Surpass PID: A Drone Ball Balancing Study](https://arxiv.org/abs/2509.21122)
*Mingjiang Liu,Hailong Huang*

Main category: cs.RO

TL;DR: 该论文提出了一种基于强化学习（RL）的控制框架，用于解决无人机-球-梁系统中的平衡问题，并通过仿真证明了RL策略优于PID控制器，尤其是在利用更丰富的状态观测信息方面。


<details>
  <summary>Details</summary>
Motivation: 解决无人机通过缆绳与可移动的梁进行交互，以稳定梁上球体的平衡问题。

Method: 提出了一种分层的控制框架，将高层平衡策略与低层无人机控制分离，并使用强化学习（RL）训练高层决策策略。

Result: 仿真结果表明，RL策略在同一分层结构下表现优于精心调整的PID控制器，其优势在于能有效利用更丰富的状态观测信息，而非参数调优或非线性映射能力。

Conclusion: 强化学习（RL）在此任务中的优势源于其有效利用更丰富状态观测信息的能力，这表明增强的传感能力对于提升控制器性能至关重要。

Abstract: This paper addresses a drone ball-balancing task, in which a drone stabilizes
a ball atop a movable beam through cable-based interaction. We propose a
hierarchical control framework that decouples high-level balancing policy from
low-level drone control, and train a reinforcement learning (RL) policy to
handle the high-level decision-making. Simulation results show that the RL
policy achieves superior performance compared to carefully tuned PID
controllers within the same hierarchical structure. Through systematic
comparative analysis, we demonstrate that RL's advantage stems not from
improved parameter tuning or inherent nonlinear mapping capabilities, but from
its ability to effectively utilize richer state observations. These findings
underscore the critical role of comprehensive state representation in
learning-based systems and suggest that enhanced sensing could be instrumental
in improving controller performance.

</details>


### [413] [Automotive-ENV: Benchmarking Multimodal Agents in Vehicle Interface Systems](https://arxiv.org/abs/2509.21143)
*Junfeng Yan,Biao Wu,Meng Fang,Ling Chen*

Main category: cs.RO

TL;DR: 本论文提出了Automotive-ENV基准和ASURADA智能体，以应对汽车内嵌式GUI的独特挑战，并利用地理空间信息提升交互的安全性和适应性。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态智能体在通用GUI交互方面表现出色，但在汽车系统中的应用尚处于初步探索阶段。车内GUI交互面临着驾驶员注意力受限、严格的安全要求以及复杂的基于位置的交互模式等独特挑战。

Method: 提出Automotive-ENV，一个高保真度的基准和交互环境，专门针对车内GUI设计。该平台包含185个参数化任务，涵盖显式控制、隐式意图理解和安全相关任务，并提供结构化的多模态观测和精确的程序化检查以实现可复现的评估。在此基础上，提出ASURADA，一个地理感知多模态智能体，它整合GPS信息，能够根据位置、环境条件和区域驾驶规范动态调整操作。

Result: 实验结果表明，地理感知信息显著提高了在安全相关任务上的成功率，凸显了基于位置的上下文在汽车环境中的重要性。

Conclusion: ASURADA智能体通过整合地理空间信息，能够更安全、更自适应地在车内GUI环境中进行交互。Automotive-ENV基准和ASURADA智能体的发布将推动安全、自适应的车内智能体的发展。

Abstract: Multimodal agents have demonstrated strong performance in general GUI
interactions, but their application in automotive systems has been largely
unexplored. In-vehicle GUIs present distinct challenges: drivers' limited
attention, strict safety requirements, and complex location-based interaction
patterns. To address these challenges, we introduce Automotive-ENV, the first
high-fidelity benchmark and interaction environment tailored for vehicle GUIs.
This platform defines 185 parameterized tasks spanning explicit control,
implicit intent understanding, and safety-aware tasks, and provides structured
multimodal observations with precise programmatic checks for reproducible
evaluation. Building on this benchmark, we propose ASURADA, a geo-aware
multimodal agent that integrates GPS-informed context to dynamically adjust
actions based on location, environmental conditions, and regional driving
norms. Experiments show that geo-aware information significantly improves
success on safety-aware tasks, highlighting the importance of location-based
context in automotive environments. We will release Automotive-ENV, complete
with all tasks and benchmarking tools, to further the development of safe and
adaptive in-vehicle agents.

</details>


### [414] [DAGDiff: Guiding Dual-Arm Grasp Diffusion to Stable and Collision-Free Grasps](https://arxiv.org/abs/2509.21145)
*Md Faizal Karim,Vignesh Vembar,Keshab Patra,Gaurav Singh,K Madhava Krishna*

Main category: cs.RO

TL;DR: DAGDiff是一个端到端框架，可以直接在SE(3) x SE(3)空间中对双臂抓取进行去噪，通过集成几何、稳定性和碰撞感知引导项，确保生成的抓取在物理上有效且满足力闭合要求。


<details>
  <summary>Details</summary>
Motivation: 双臂抓取对于操作大型复杂物体至关重要，但由于稳定性和泛化性要求，它仍然是一个挑战。先前的方法通常将任务分解为两个独立的抓取建议，依赖于区域先验或启发式方法，这限制了泛化性并且没有原则性的稳定性保证。

Method: DAGDiff是一个端到端框架，直接在SE(3) x SE(3)空间中对抓取对进行去噪。通过集成几何、稳定性和碰撞感知引导项来指导扩散过程，而不是依赖于显式的区域检测或物体先验。

Result: 通过分析力闭合检查、碰撞分析和基于大规模物理的模拟，DAGDiff在各项指标上始终优于先前的工作。

Conclusion: DAGDiff可以直接在以前未见过的物体的真实点云上生成双臂抓取，并在异构双臂设置上成功执行，实现了可靠的抓取和提升。

Abstract: Reliable dual-arm grasping is essential for manipulating large and complex
objects but remains a challenging problem due to stability, collision, and
generalization requirements. Prior methods typically decompose the task into
two independent grasp proposals, relying on region priors or heuristics that
limit generalization and provide no principled guarantee of stability. We
propose DAGDiff, an end-to-end framework that directly denoises to grasp pairs
in the SE(3) x SE(3) space. Our key insight is that stability and collision can
be enforced more effectively by guiding the diffusion process with classifier
signals, rather than relying on explicit region detection or object priors. To
this end, DAGDiff integrates geometry-, stability-, and collision-aware
guidance terms that steer the generative process toward grasps that are
physically valid and force-closure compliant. We comprehensively evaluate
DAGDiff through analytical force-closure checks, collision analysis, and
large-scale physics-based simulations, showing consistent improvements over
previous work on these metrics. Finally, we demonstrate that our framework
generates dual-arm grasps directly on real-world point clouds of previously
unseen objects, which are executed on a heterogeneous dual-arm setup where two
manipulators reliably grasp and lift them.

</details>


### [415] [Human-like Navigation in a World Built for Humans](https://arxiv.org/abs/2509.21189)
*Bhargav Chandaka,Gloria X. Wang,Haozhe Chen,Henry Che,Albert J. Zhai,Shenlong Wang*

Main category: cs.RO

TL;DR: ReasonNav是一个集成了人类导航技能的机器人导航系统，利用视觉语言模型（VLM）进行推理，提高了在大型复杂建筑中的导航效率。


<details>
  <summary>Details</summary>
Motivation: 现有机器人导航系统缺乏类似人类的导航行为（如阅读标志、问路），导致在大型环境中效率低下。

Method: 提出ReasonNav系统，该系统利用VLM的推理能力，通过基于导航地标的输入输出抽象，使VLM专注于语言理解和推理，集成了人类的导航技能。

Result: 在真实和模拟导航任务中，ReasonNav成功利用了高阶推理能力，在大型复杂建筑中实现了高效导航。

Conclusion: ReasonNav系统通过集成人类导航行为和VLM推理能力，能够高效地在大型、复杂的人造环境中导航。

Abstract: When navigating in a man-made environment they haven't visited before--like
an office building--humans employ behaviors such as reading signs and asking
others for directions. These behaviors help humans reach their destinations
efficiently by reducing the need to search through large areas. Existing robot
navigation systems lack the ability to execute such behaviors and are thus
highly inefficient at navigating within large environments. We present
ReasonNav, a modular navigation system which integrates these human-like
navigation skills by leveraging the reasoning capabilities of a vision-language
model (VLM). We design compact input and output abstractions based on
navigation landmarks, allowing the VLM to focus on language understanding and
reasoning. We evaluate ReasonNav on real and simulated navigation tasks and
show that the agent successfully employs higher-order reasoning to navigate
efficiently in large, complex buildings.

</details>


### [416] [SEEC: Stable End-Effector Control with Model-Enhanced Residual Learning for Humanoid Loco-Manipulation](https://arxiv.org/abs/2509.21231)
*Jaehwi Jang,Zhuoheng Wang,Ziyi Zhou,Feiyang Wu,Ye Zhao*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Arm end-effector stabilization is essential for humanoid loco-manipulation
tasks, yet it remains challenging due to the high degrees of freedom and
inherent dynamic instability of bipedal robot structures. Previous model-based
controllers achieve precise end-effector control but rely on precise dynamics
modeling and estimation, which often struggle to capture real-world factors
(e.g., friction and backlash) and thus degrade in practice. On the other hand,
learning-based methods can better mitigate these factors via exploration and
domain randomization, and have shown potential in real-world use. However, they
often overfit to training conditions, requiring retraining with the entire
body, and still struggle to adapt to unseen scenarios. To address these
challenges, we propose a novel stable end-effector control (SEEC) framework
with model-enhanced residual learning that learns to achieve precise and robust
end-effector compensation for lower-body induced disturbances through
model-guided reinforcement learning (RL) with a perturbation generator. This
design allows the upper-body policy to achieve accurate end-effector
stabilization as well as adapt to unseen locomotion controllers with no
additional training. We validate our framework in different simulators and
transfer trained policies to the Booster T1 humanoid robot. Experiments
demonstrate that our method consistently outperforms baselines and robustly
handles diverse and demanding loco-manipulation tasks.

</details>


### [417] [FSGlove: An Inertial-Based Hand Tracking System with Shape-Aware Calibration](https://arxiv.org/abs/2509.21242)
*Yutong Li,Jieyi Zhang,Wenqiang Xu,Tutian Tang,Cewu Lu*

Main category: cs.RO

TL;DR: FSGlove是一个基于惯性传感器、可追踪高达48个自由度并重建个性化手部形状的系统，通过名为DiffHCal的新颖校准方法实现，该方法可同时优化运动学、形状参数和传感器偏差，精度优于现有系统，并开源。


<details>
  <summary>Details</summary>
Motivation: 现有手部动作捕捉系统在捕捉高自由度关节运动和个性化手部形状方面存在局限性，尤其是在复杂的操控和接触丰富的任务中。

Method: FSGlove系统使用IMU（惯性测量单元）来追踪高达48个自由度，并通过DiffHCal方法进行校准。DiffHCal利用可微分优化与MANO模型结合，同时解决关节运动学、形状参数和传感器偏差问题。

Result: FSGlove系统达到了先进的精度，关节角度误差小于2.7度，并且在形状重建和接触保真度方面优于商业产品。该系统能够捕捉精细的手部动作，并与VR和机器人生态系统兼容。

Conclusion: FSGlove通过整合运动学和接触保真度，在手部追踪领域取得了进展，为实现更逼真的人手灵活性和机器人模仿提供了解决方案。

Abstract: Accurate hand motion capture (MoCap) is vital for applications in robotics,
virtual reality, and biomechanics, yet existing systems face limitations in
capturing high-degree-of-freedom (DoF) joint kinematics and personalized hand
shape. Commercial gloves offer up to 21 DoFs, which are insufficient for
complex manipulations while neglecting shape variations that are critical for
contact-rich tasks. We present FSGlove, an inertial-based system that
simultaneously tracks up to 48 DoFs and reconstructs personalized hand shapes
via DiffHCal, a novel calibration method. Each finger joint and the dorsum are
equipped with IMUs, enabling high-resolution motion sensing. DiffHCal
integrates with the parametric MANO model through differentiable optimization,
resolving joint kinematics, shape parameters, and sensor misalignment during a
single streamlined calibration. The system achieves state-of-the-art accuracy,
with joint angle errors of less than 2.7 degree, and outperforms commercial
alternatives in shape reconstruction and contact fidelity. FSGlove's
open-source hardware and software design ensures compatibility with current VR
and robotics ecosystems, while its ability to capture subtle motions (e.g.,
fingertip rubbing) bridges the gap between human dexterity and robotic
imitation. Evaluated against Nokov optical MoCap, FSGlove advances hand
tracking by unifying the kinematic and contact fidelity. Hardware design,
software, and more results are available at:
https://sites.google.com/view/fsglove.

</details>


### [418] [RetoVLA: Reusing Register Tokens for Spatial Reasoning in Vision-Language-Action Models](https://arxiv.org/abs/2509.21243)
*Jiyeon Koo,Taewan Cho,Hyunjoon Kang,Eunseom Pyo,Tae Gyun Oh,Taeryang Kim,Andrew Jaeyong Choi*

Main category: cs.RO

TL;DR: 通过重用Vision Transformer中被废弃的Register Tokens，RetoVLA在保持轻量化结构的同时，增强了机器人的空间推理能力，提高了复杂操作任务的成功率。


<details>
  <summary>Details</summary>
Motivation: 现有的Vision-Language-Action (VLA)模型在泛化能力上表现出色，但其庞大的体积和高昂的计算成本限制了实际应用。传统的轻量化方法往往会牺牲关键能力，特别是空间推理能力，导致效率和性能之间的权衡。

Method: 提出了一种名为RetoVLA的新型架构，该架构通过将Register Tokens（最初用于Vision Transformer中的伪影去除但后来被丢弃）直接重新注入到Action Expert中，来利用其中包含的空间信息。

Result: 在自建的7-DOF机器人手臂上，RetoVLA在复杂操作任务上取得了17.1%的绝对成功率提升，证明了重用Register Tokens能够有效增强空间推理能力。

Conclusion: 重用Register Tokens是提升机器人智能的一种有价值且未被充分探索的方法，能够直接增强空间推理能力，克服了轻量化与性能之间的权衡。

Abstract: Recent Vision-Language-Action (VLA) models demonstrate remarkable
generalization in robotics but are restricted by their substantial size and
computational cost, limiting real-world deployment. However, conventional
lightweighting methods often sacrifice critical capabilities, particularly
spatial reasoning. This creates a trade-off between efficiency and performance.
To address this challenge, our work reuses Register Tokens, which were
introduced for artifact removal in Vision Transformers but subsequently
discarded. We suppose that these tokens contain essential spatial information
and propose RetoVLA, a novel architecture that reuses them directly by
injecting them into the Action Expert.
  RetoVLA maintains a lightweight structure while leveraging this repurposed
spatial context to enhance reasoning. We demonstrate RetoVLA's effectiveness
through a series of comprehensive experiments. On our custom-built 7-DOF robot
arm, the model achieves a 17.1%p absolute improvement in success rates for
complex manipulation tasks. Our results confirm that reusing Register Tokens
directly enhances spatial reasoning, demonstrating that what was previously
discarded as an artifact is in fact a valuable, unexplored resource for robotic
intelligence. A video demonstration is available at:
https://youtu.be/2CseBR-snZg

</details>


### [419] [BiNoMaP: Learning Category-Level Bimanual Non-Prehensile Manipulation Primitives](https://arxiv.org/abs/2509.21256)
*Huayi Zhou,Kui Jia*

Main category: cs.RO

TL;DR: 该论文提出了一种名为BiNoMaP的双臂非抓取操作框架，用于解决机器人领域中触碰密集且难处理的非抓取操作问题。该框架无需强化学习，通过从视频演示中提取轨迹，并使用几何感知后优化算法进行细化，最终实现可泛化的操作。


<details>
  <summary>Details</summary>
Motivation: 机器人领域中非抓取操作（如推、戳、枢轴）是一个关键但未被充分探索的领域，因为其具有接触密集和分析上难以处理的特点。现有方法通常采用单臂设置并依赖于有利的外部条件（如墙壁、斜坡或边缘）。

Method: 提出了一种通用的双臂配置，并建立了一套双臂非抓取操作原语（BiNoMaP）。该方法摒弃了主流的基于强化学习的范式，提出了一种三阶段、无强化学习的框架来学习非抓取技能。首先，从视频演示中提取双臂手部运动轨迹。然后，提出了一种几何感知后优化算法，将粗略的轨迹精炼为符合特定运动模式的可执行操作原语。最后，通过对学习到的原语进行参数化，并结合物体相关的几何属性（特别是尺寸），实现了类别级别的泛化能力，从而得到适应性强的、可参数化的操作原语。

Result: 在各种代表性的双臂任务和多样化的物体类别上验证了BiNoMaP的有效性、效率、多功能性和卓越的泛化能力。

Conclusion: BiNoMaP框架通过双臂协同操作和几何感知后优化，有效解决了非抓取操作的挑战，并实现了良好的泛化能力，为机器人领域在该方向的研究提供了新的思路。

Abstract: Non-prehensile manipulation, encompassing ungraspable actions such as
pushing, poking, and pivoting, represents a critical yet underexplored domain
in robotics due to its contact-rich and analytically intractable nature. In
this work, we revisit this problem from two novel perspectives. First, we move
beyond the usual single-arm setup and the strong assumption of favorable
external dexterity such as walls, ramps, or edges. Instead, we advocate a
generalizable dual-arm configuration and establish a suite of Bimanual
Non-prehensile Manipulation Primitives (BiNoMaP). Second, we depart from the
prevailing RL-based paradigm and propose a three-stage, RL-free framework to
learn non-prehensile skills. Specifically, we begin by extracting bimanual hand
motion trajectories from video demonstrations. Due to visual inaccuracies and
morphological gaps, these coarse trajectories are difficult to transfer
directly to robotic end-effectors. To address this, we propose a geometry-aware
post-optimization algorithm that refines raw motions into executable
manipulation primitives that conform to specific motion patterns. Beyond
instance-level reproduction, we further enable category-level generalization by
parameterizing the learned primitives with object-relevant geometric
attributes, particularly size, resulting in adaptable and general parameterized
manipulation primitives. We validate BiNoMaP across a range of representative
bimanual tasks and diverse object categories, demonstrating its effectiveness,
efficiency, versatility, and superior generalization capability.

</details>


### [420] [\LARGE GMP$^{3}$: Learning-Driven, Bellman-Guided Trajectory Planning for UAVs in Real-Time on SE(3)](https://arxiv.org/abs/2509.21264)
*Babak Salamat,Dominik Mattern,Sebastian-Sven Olzem,Gerhard Elsbacher,Christian Seidel,Andrea M. Tonello*

Main category: cs.RO

TL;DR: GMP3是一个多阶段全局路径规划框架，用于在复杂环境中为无人机生成三维动态可行轨迹，它将规划扩展到SE(3)李群，并引入改进的贝尔曼算子进行强化学习，通过分布式框架和共识机制实现合作策略更新，并使用DroneManager软件支持实时部署。


<details>
  <summary>Details</summary>
Motivation: 在复杂环境中为无人机规划动态可行三维轨迹，并实现合作策略更新和实时部署。

Method: 将规划扩展到SE(3)李群，使用改进的贝尔曼算子进行强化学习，采用分布式框架和共识机制进行合作策略更新，并开发DroneManager软件。

Result: 在仿真和室内飞行实验中，GMP3在约束三维环境中实现了可靠的避障和流畅可行的轨迹，涵盖位置和姿态。

Conclusion: GMP3能够为无人机在复杂环境中生成动态可行三维轨迹，并支持合作策略更新和实时部署。

Abstract: We propose $\text{GMP}^{3}$, a multiphase global path planning framework that
generates dynamically feasible three-dimensional trajectories for unmanned
aerial vehicles (UAVs) operating in cluttered environments. The framework
extends traditional path planning from Euclidean position spaces to the Lie
group $\mathrm{SE}(3)$, allowing joint learning of translational motion and
rotational dynamics. A modified Bellman-based operator is introduced to support
reinforcement learning (RL) policy updates while leveraging prior trajectory
information for improved convergence. $\text{GMP}^{3}$ is designed as a
distributed framework in which agents influence each other and share policy
information along the trajectory: each agent refines its assigned segment and
shares with its neighbors via a consensus-based scheme, enabling cooperative
policy updates and convergence toward a path shaped globally even under
kinematic constraints. We also propose DroneManager, a modular ground control
software that interfaces the planner with real UAV platforms via the MAVLink
protocol, supporting real-time deployment and feedback. Simulation studies and
indoor flight experiments validate the effectiveness of the proposed method in
constrained 3D environments, demonstrating reliable obstacle avoidance and
smooth, feasible trajectories across both position and orientation. The
open-source implementation is available at
https://github.com/Domattee/DroneManager

</details>


### [421] [Taxonomy-aware Dynamic Motion Generation on Hyperbolic Manifolds](https://arxiv.org/abs/2509.21281)
*Luis Augenstein,Noémie Jaquier,Tamim Asfour,Leonel Rozo*

Main category: cs.RO

TL;DR: 该研究提出了一种名为 GPHDM 的新方法，用于生成具有人类般运动的机器人动作，该方法能够学习运动的潜在表示，同时保留其层级结构和时间动态，以确保物理一致性。


<details>
  <summary>Details</summary>
Motivation: 现有机器人运动生成方法忽略了生物力学研究中动作的层级结构信息，导致生成的动作与底层结构脱节。

Method: 通过将高斯过程动力学模型（GPDM）的动力学先验扩展到双曲流形，并结合感知分类的归纳偏倚，提出 GPHDM 模型。该模型利用几何和感知分类框架，提出三种新机制来生成既有感知分类结构又物理上一致的运动：两种概率递归方法和一种基于度量测地线的方法。

Result: 在手部抓取感知分类的运动生成实验中，GPHDM 被证明能够忠实地编码底层的感知分类和时间动态，并生成新颖的、物理上一致的轨迹。

Conclusion: GPHDM 能够有效生成具有人类般运动的机器人动作，并能保留运动的层级结构和时间动态，确保物理一致性。

Abstract: Human-like motion generation for robots often draws inspiration from
biomechanical studies, which often categorize complex human motions into
hierarchical taxonomies. While these taxonomies provide rich structural
information about how movements relate to one another, this information is
frequently overlooked in motion generation models, leading to a disconnect
between the generated motions and their underlying hierarchical structure. This
paper introduces the \ac{gphdm}, a novel approach that learns latent
representations preserving both the hierarchical structure of motions and their
temporal dynamics to ensure physical consistency. Our model achieves this by
extending the dynamics prior of the Gaussian Process Dynamical Model (GPDM) to
the hyperbolic manifold and integrating it with taxonomy-aware inductive
biases. Building on this geometry- and taxonomy-aware frameworks, we propose
three novel mechanisms for generating motions that are both
taxonomically-structured and physically-consistent: two probabilistic recursive
approaches and a method based on pullback-metric geodesics. Experiments on
generating realistic motion sequences on the hand grasping taxonomy show that
the proposed GPHDM faithfully encodes the underlying taxonomy and temporal
dynamics, and generates novel physically-consistent trajectories.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [422] [A Unified Formal Theory on the Logical Limits of Symbol Grounding](https://arxiv.org/abs/2509.20409)
*Zhangchi Liu*

Main category: cs.LO

TL;DR: 纯符号系统无法在内部建立有意义的含义基础，而是需要一个外部的、动态的、非算法的过程来解决符号接地问题。


<details>
  <summary>Details</summary>
Motivation: 该论文旨在通过形式证明构建一个关于符号接地问题的逻辑极限的统一理论。

Method: 论文提出了一个四阶段的论证：1. 证明了任何纯粹的符号系统都无法在内部建立有意义的含义基础。 2. 证明了具有有限、静态预定含义的系统存在固有的不完整性。 3. 论证了将内部符号与外部含义联系起来的行为不能是逻辑推理的结果。 4. 证明了任何尝试通过固定的外部“判断”算法来自动化此更新过程都会构建一个更大但不完整的符号系统。

Result: 通过形式证明，该论文揭示了符号接地问题的逻辑极限，即含义的接地是一个必然的、开放的、非算法的过程，并指出了任何自包含的智能系统的根本限制。

Conclusion: 含义的接地是一个必然的、开放的、非算法的过程，并揭示了任何自包含的智能系统的根本限制。

Abstract: This paper synthesizes a series of formal proofs to construct a unified
theory on the logical limits of the Symbol Grounding Problem. We demonstrate
through a four-stage argument that meaning within a formal system must arise
from a process that is external, dynamic, and non-algorithmic. First, we prove
that any purely symbolic system, devoid of external connections, cannot
internally establish a consistent foundation for meaning due to
self-referential paradoxes. Second, we extend this limitation to systems with
any finite, static set of pre-established meanings, proving they are inherently
incomplete. Third, we demonstrate that the very "act" of connecting an internal
symbol to an external meaning cannot be a product of logical inference within
the system but must be an axiomatic, meta-level update. Finally, we prove that
any attempt to automate this update process using a fixed, external "judgment"
algorithm will inevitably construct a larger, yet equally incomplete, symbolic
system. Together, these conclusions formally establish that the grounding of
meaning is a necessarily open-ended, non-algorithmic process, revealing a
fundamental, G\"odel-style limitation for any self-contained intelligent
system.

</details>


### [423] [Reverse Faà di Bruno's Formula for Cartesian Reverse Differential Categories](https://arxiv.org/abs/2509.20931)
*Aaron Biggin,Jean-Simon Pacaud Lemay*

Main category: cs.LO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Reverse differentiation is an essential operation for automatic
differentiation. Cartesian reverse differential categories axiomatize reverse
differentiation in a categorical framework, where one of the primary axioms is
the reverse chain rule, which is the formula that expresses the reverse
derivative of a composition. Here, we present the reverse differential analogue
of Faa di Bruno's Formula, which gives a higher-order reverse chain rule in a
Cartesian reverse differential category. To properly do so, we also define
partial reverse derivatives and higher-order reverse derivatives in a Cartesian
reverse differential category.

</details>


### [424] [A Coalgebraic Model of Quantum Bisimulation](https://arxiv.org/abs/2509.20933)
*Lorenzo Ceragioli,Elena Di Lavore,Giuseppe Lomurno,Gabriele Tedeschi*

Main category: cs.LO

TL;DR: 该研究提出了一个处理量子系统行为等价性的新方法，利用分布代数和带状幺半群来模拟量子理论的限制。


<details>
  <summary>Details</summary>
Motivation: 定义一个能匹配量子、并发、非确定性系统的观测特性的行为等价性被证明是一项艰巨的任务。

Method: 通过使用取自通用效应代数（涵盖了概率和量子效应）的权重的分布代数，并引入了在偏交换幺半群上分级的幺半群来处理量子理论的性质（如不可克隆定理）。研究了开放量子系统与其概率对应物之间的关系，并比较了Aczel-Mendler和核双相似性。

Result: 核双相似性被认为更能表征量子系统的概率行为，因为它适用于所有输入状态。研究还为过程演算语义提供了基础，该语义可以根据量子输入进行参数化。

Conclusion: 研究提出的基于分布代数和带状幺半群的方法为处理量子系统的行为等价性提供了新的视角，并为过程演算的进一步发展铺平了道路。

Abstract: Recent works have shown that defining a behavioural equivalence that matches
the observational properties of a quantum-capable, concurrent,
non-deterministic system is a surprisingly difficult task. We explore
coalgebras over distributions taking weights from a generic effect algebra,
which subsumes probabilities and quantum effects, a physical formalism that
represents the probabilistic behaviour of an open quantum system. To abide by
the properties of quantum theory, we introduce monads graded on a partial
commutative monoid, intuitively allowing composition of two processes only if
they use different quantum resources, as prescribed by the no-cloning theorem.
We investigate the relation between an open quantum system and its
probabilistic counterparts obtained when instantiating the input with a
specific quantum state. We consider Aczel-Mendler and kernel bisimilarities,
advocating for the latter as it characterizes quantum systems that exhibit the
same probabilistic behaviour for all input states. Finally, we propose
operators on quantum effect labelled transition systems, paving the way for a
process calculi semantics that is parametric over the quantum input.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [425] [An Approach to Checking Correctness for Agentic Systems](https://arxiv.org/abs/2509.20364)
*Thomas J Sheffler*

Main category: cs.AI

TL;DR: 本研究提出了一种用于监控AI代理行为的时间表达式语言，以系统性地检测LLM代理系统的错误，解决了因随机生成过程导致的输出变异性问题。


<details>
  <summary>Details</summary>
Motivation: 现有错误检测方法主要依赖文本匹配，但由于LLM响应的自然语言可变性而不够鲁棒。本研究旨在提供一种关注代理动作序列（如工具调用和状态转换）的方法，以独立于具体文本输出来验证系统行为。

Method: 提出了一种时间表达式语言，借鉴了硬件验证中的时间逻辑技术，用于监控代理的工具调用和状态转换序列，以检测与预期行为模式的偏差。该语言的断言可用于验证提示工程和护栏有效性，并作为代理更新时的回归测试。

Result: 通过一个三代理系统进行演示，该系统协调解决多步推理任务。使用大型模型时，所有时间断言均满足；但在两个代理中使用较小模型时，执行违反了行为断言，主要由于工具排序不当和协调交接失败。该方法成功标记了这些异常。

Conclusion: 所提出的时间表达式语言能够有效检测生产环境中代理系统的行为回归，为日益关键的AI代理可靠性系统性监控奠定了基础。

Abstract: This paper presents a temporal expression language for monitoring AI agent
behavior, enabling systematic error-detection of LLM-based agentic systems that
exhibit variable outputs due to stochastic generation processes. Drawing from
temporal logic techniques used in hardware verification, this approach monitors
execution traces of agent tool calls and state transitions to detect deviations
from expected behavioral patterns. Current error-detection approaches rely
primarily on text matching of inputs and outputs, which proves fragile due to
the natural language variability inherent in LLM responses. The proposed method
instead focuses on the sequence of agent actions -- such as tool invocations
and inter-agent communications -- allowing verification of system behavior
independent of specific textual outputs. The temporal expression language
provides assertions that capture correct behavioral patterns across multiple
execution scenarios. These assertions serve dual purposes: validating prompt
engineering and guardrail effectiveness during development, and providing
regression testing when agents are updated with new LLMs or modified logic. The
approach is demonstrated using a three-agent system, where agents coordinate to
solve multi-step reasoning tasks. When powered by large, capable models, all
temporal assertions were satisfied across many test runs. However, when smaller
models were substituted in two of the three agents, executions violated
behavioral assertions, primarily due to improper tool sequencing and failed
coordination handoffs. The temporal expressions successfully flagged these
anomalies, demonstrating the method's effectiveness for detecting behavioral
regressions in production agentic systems. This approach provides a foundation
for systematic monitoring of AI agent reliability as these systems become
increasingly deployed in critical applications.

</details>


### [426] [LATTS: Locally Adaptive Test-Time Scaling](https://arxiv.org/abs/2509.20368)
*Theo Uscidda,Matthew Trager,Michael Kleinman,Aditya Chattopadhyay,Wei Xia,Stefano Soatto*

Main category: cs.AI

TL;DR: LATTS通过自适应调整每一步的计算量来优化LLM的性能，与传统方法相比，在准确性和计算成本之间取得了更好的平衡。


<details>
  <summary>Details</summary>
Motivation: 现有基于验证器的LLM性能提升方法在测试时增加了均匀的计算量，未能考虑单个实例的复杂性，导致资源利用效率低下。

Method: 提出了一种名为“局部自适应测试时标度（LATTS）”的方法，该方法在生成过程中根据局部困难度动态分配计算量。在每个生成步骤中，LATTS使用基于验证器的接受标准来决定是重新采样、回溯、重启还是停止生成过程。

Result: LATTS在准确-计算权衡方面显著优于标准的基于验证器的方法。

Conclusion: LATTS通过动态调整每一步的计算量，解决了现有LLM性能提升方法效率不高的问题，并在准确性和计算成本之间取得了更好的平衡。

Abstract: One common strategy for improving the performance of Large Language Models
(LLMs) on downstream tasks involves using a \emph{verifier model} to either
select the best answer from a pool of candidates or to steer the
auto-regressive generation process towards better outputs. This class of
methods typically results in improved accuracy at the cost of increased
computation at test-time, a paradigm known as \emph{test-time scaling}.
However, most existing approaches increase computation uniformly across all
samples and generation steps, without considering the complexity of individual
instances, leading to inefficient resource use. We address this limitation by
proposing an approach, called \emph{Locally Adaptive Test-Time Scaling
(LATTS)}, that allocates variable compute across generation steps.
Specifically, at each generation step, LATTS employs a verifier-based
acceptance criterion to decide whether to resample, backtrack, restart, or stop
the generation process. This criterion effectively adjusts the per-step
computational effort based on a precise notion of \emph{local difficulty}
derived from the verifier model. Empirical results show that LATTS achieves
significantly superior accuracy--compute tradeoffs compared to standard
verifier-based methods.

</details>


### [427] [Fairy: Interactive Mobile Assistant to Real-world Tasks via LMM-based Multi-agent](https://arxiv.org/abs/2509.20729)
*Jiazheng Sun,Te Yang,Jiayang Niu,Mingxuan Li,Yongyong Lu,Ruimeng Yang,Xin Peng*

Main category: cs.AI

TL;DR: Fairy是一个交互式多智能体移动助手，通过持续积累应用知识和自我进化来改进大型多模态模型（LMM）在现实场景中的应用。它通过全局任务规划、应用级别执行和自我学习来解决现有方法的局限性，并在RealMobile-Eval基准测试中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的大型多模态模型（LMM）在处理多样化的应用程序界面和不断变化的用户需求方面存在挑战，特别是在长尾应用场景下，并且缺乏用户交互可能导致不良的用户体验。

Method: Fairy提出了一种交互式多智能体移动助手，包含三个核心模块：全局任务规划器（将用户任务分解为跨应用的子任务）、应用级别执行器（通过包含长期和短期记忆的四个核心智能体在双循环中细化子任务为步骤和动作，实现精确执行和用户交互）和自我学习器（将执行经验整合成应用地图和技巧）。

Result: 在RealMobile-Eval基准测试中，基于GPT-4o的Fairy在用户需求完成率上提高了33.7%，冗余步骤减少了58.5%，证明了其交互和自我学习能力的有效性。

Conclusion: Fairy通过其交互式多智能体设计和自我学习能力，在处理现实世界中的移动应用任务方面取得了显著的改进，克服了现有方法的局限性。

Abstract: Large multi-modal models (LMMs) have advanced mobile GUI agents. However,
existing methods struggle with real-world scenarios involving diverse app
interfaces and evolving user needs. End-to-end methods relying on model's
commonsense often fail on long-tail apps, and agents without user interaction
act unilaterally, harming user experience. To address these limitations, we
propose Fairy, an interactive multi-agent mobile assistant capable of
continuously accumulating app knowledge and self-evolving during usage. Fairy
enables cross-app collaboration, interactive execution, and continual learning
through three core modules:(i) a Global Task Planner that decomposes user tasks
into sub-tasks from a cross-app view; (ii) an App-Level Executor that refines
sub-tasks into steps and actions based on long- and short-term memory,
achieving precise execution and user interaction via four core agents operating
in dual loops; and (iii) a Self-Learner that consolidates execution experience
into App Map and Tricks. To evaluate Fairy, we introduce RealMobile-Eval, a
real-world benchmark with a comprehensive metric suite, and LMM-based agents
for automated scoring. Experiments show that Fairy with GPT-4o backbone
outperforms the previous SoTA by improving user requirement completion by 33.7%
and reducing redundant steps by 58.5%, showing the effectiveness of its
interaction and self-learning.

</details>


### [428] [Philosophy-informed Machine Learning](https://arxiv.org/abs/2509.20370)
*MZ Naser*

Main category: cs.AI

TL;DR: 本论文提出了哲学启发式机器学习（PhIML），一种将分析哲学核心思想融入机器学习模型设计的方法，旨在通过尊重哲学概念和价值观的模型来解锁新能力。


<details>
  <summary>Details</summary>
Motivation: PhIML旨在通过在模型架构、目标和评估协议中直接融入分析哲学的核心思想，来解锁新的机器学习能力，并确保模型在设计上就尊重哲学概念和价值观。

Method: 本文回顾了PhIML的概念基础，展示了其在哲学上的优势和一致性，并提出了两种采用PhIML的方法：作为一种通用的事后工具，或将其内在构建到ML模型架构中。

Result: 通过案例研究，展示了ML用户/设计者如何采用PhIML，并揭示了目前存在的技术障碍以及哲学、实践和治理方面的挑战。

Conclusion: PhIML的研究方向在于克服现有挑战，构建安全、符合哲学、合乎伦理的机器学习模型。

Abstract: Philosophy-informed machine learning (PhIML) directly infuses core ideas from
analytic philosophy into ML model architectures, objectives, and evaluation
protocols. Therefore, PhIML promises new capabilities through models that
respect philosophical concepts and values by design. From this lens, this paper
reviews conceptual foundations to demonstrate philosophical gains and
alignment. In addition, we present case studies on how ML users/designers can
adopt PhIML as an agnostic post-hoc tool or intrinsically build it into ML
model architectures. Finally, this paper sheds light on open technical barriers
alongside philosophical, practical, and governance challenges and outlines a
research roadmap toward safe, philosophy-aware, and ethically responsible
PhIML.

</details>


### [429] [InsightGUIDE: An Opinionated AI Assistant for Guided Critical Reading of Scientific Literature](https://arxiv.org/abs/2509.20493)
*Paris Koloveas,Serafeim Chatzopoulos,Thanasis Vergoulis,Christos Tryfonopoulos*

Main category: cs.AI

TL;DR: InsightGUIDE是一个AI驱动的阅读助手，旨在帮助研究人员更有效地浏览科学文献，它提供简洁、结构化的见解，而不是替代阅读。


<details>
  <summary>Details</summary>
Motivation: 科学文献的快速增长给研究人员带来了挑战，需要更有效的工具来帮助他们处理大量信息。

Method: InsightGUIDE将专家的阅读方法嵌入到核心AI逻辑中，采用提示驱动的方法来生成结构化的见解，并与通用LLM进行了比较。

Result: 与通用LLM相比，InsightGUIDE生成的指导更具结构性和可操作性。

Conclusion: InsightGUIDE是一个有效的工具，可以帮助现代研究人员更好地理解和导航科学文献。

Abstract: The proliferation of scientific literature presents an increasingly
significant challenge for researchers. While Large Language Models (LLMs) offer
promise, existing tools often provide verbose summaries that risk replacing,
rather than assisting, the reading of the source material. This paper
introduces InsightGUIDE, a novel AI-powered tool designed to function as a
reading assistant, not a replacement. Our system provides concise, structured
insights that act as a "map" to a paper's key elements by embedding an expert's
reading methodology directly into its core AI logic. We present the system's
architecture, its prompt-driven methodology, and a qualitative case study
comparing its output to a general-purpose LLM. The results demonstrate that
InsightGUIDE produces more structured and actionable guidance, serving as a
more effective tool for the modern researcher.

</details>


### [430] [ToMPO: Training LLM Strategic Decision Making from a Multi-Agent Perspective](https://arxiv.org/abs/2509.21134)
*Yiwen Zhang,Ziang Chen,Fanqi Kong,Yizhe Huang,Xue Feng*

Main category: cs.AI

TL;DR: ToMPO算法通过优化对其他个体策略和博弈局面趋势的感知，提升LLM在复杂决策任务中的策略制定能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究忽视了决策的多样性及其相互依赖性，且强化学习方法难以在训练中考虑他方策略。

Method: 提出ToMPO算法，包含两种决策类型及其时间依赖性，该算法通过推理他方策略生成回放、估计图级别和样本级别的优势，并平衡全局与局部奖励。

Result: ToMPO算法在模型输出符合度和合作成果方面比GRPO算法提高了35%，并且比参数量大100倍的模型提高了18%。

Conclusion: ToMPO算法能有效提升LLM的策略制定能力。

Abstract: Large Language Models (LLMs) have been used to make decisions in complex
scenarios, where they need models to think deeply, reason logically, and decide
wisely. Many existing studies focus solely on multi-round conversations in
social tasks or simulated environments, neglecting the various types of
decisions and their interdependence. Current reinforcement learning methods
struggle to consider the strategies of others during training. To address these
issues, we first define a strategic decision-making problem that includes two
types of decisions and their temporal dependencies. Furthermore, we propose
**T**heory **o**f **M**ind **P**olicy **O**ptimization **(ToMPO)** algorithm to
optimize the perception of other individual strategies and the game situation
trends. Compared to the Group Relative Policy Optimization (GRPO) algorithm,
ToMPO enhances the LLM's strategic decision-making mainly by: 1) generating
rollouts based on reasoning the strategies of other individuals, 2) estimating
advantages at both the graph-level and sample-level, and 3) balancing global
and partial rewards. The ToMPO algorithm outperforms the GRPO method by 35% in
terms of model output compliance and cooperative outcomes. Additionally, when
compared to models with parameter sizes 100 times larger, it shows an 18%
improvement. This demonstrates the effectiveness of the ToMPO algorithm in
enhancing the model's strategic decision-making capabilities.

</details>


### [431] [Reconstruction-Based Adaptive Scheduling Using AI Inferences in Safety-Critical Systems](https://arxiv.org/abs/2509.20513)
*Samer Alshaer,Ala Khalifeh,Roman Obermaisser*

Main category: cs.AI

TL;DR: 该研究提出了一种新颖的重构框架，用于动态验证和组装时间触发系统（TTS）的调度，以应对动态环境中的可靠性和安全性挑战，解决了消息冲突、不正确的优先顺序处理导致的锁定循环以及不完整或无效调度的生成等问题。


<details>
  <summary>Details</summary>
Motivation: 为了确保时间触发系统（TTS）在动态运行环境中的可靠性和安全性，需要解决现有调度框架面临的消息冲突、不正确的优先顺序处理导致的锁定循环以及不完整或无效调度的生成等挑战。

Method: 提出了一种新颖的重构框架，该框架通过系统地转换AI生成或启发式导出的调度优先级来创建完全可执行的调度。该框架包含安全检查、高效的分配算法和恢复机制，以处理意外的上下文事件，如硬件故障和模式转换。

Result: 实验结果表明，所提出的框架在最小化完成时间、工作负载平衡和能源效率等性能指标方面，显著提高了系统的适应性、运行完整性和运行时性能，同时保持了计算效率。

Conclusion: 这项工作为安全关键TTS中的安全调度生成问题提供了一个实用且可扩展的解决方案，即使在高度动态和不确定的运行条件下，也能实现可靠且灵活的实时调度。

Abstract: Adaptive scheduling is crucial for ensuring the reliability and safety of
time-triggered systems (TTS) in dynamic operational environments. Scheduling
frameworks face significant challenges, including message collisions, locked
loops from incorrect precedence handling, and the generation of incomplete or
invalid schedules, which can compromise system safety and performance. To
address these challenges, this paper presents a novel reconstruction framework
designed to dynamically validate and assemble schedules. The proposed
reconstruction models operate by systematically transforming AI-generated or
heuristically derived scheduling priorities into fully executable schedules,
ensuring adherence to critical system constraints such as precedence rules and
collision-free communication. It incorporates robust safety checks, efficient
allocation algorithms, and recovery mechanisms to handle unexpected context
events, including hardware failures and mode transitions. Comprehensive
experiments were conducted across multiple performance profiles, including
makespan minimisation, workload balancing, and energy efficiency, to validate
the operational effectiveness of the reconstruction models. Results demonstrate
that the proposed framework significantly enhances system adaptability,
operational integrity, and runtime performance while maintaining computational
efficiency. Overall, this work contributes a practical and scalable solution to
the problem of safe schedule generation in safety-critical TTS, enabling
reliable and flexible real-time scheduling even under highly dynamic and
uncertain operational conditions.

</details>


### [432] [Adaptive Approach to Enhance Machine Learning Scheduling Algorithms During Runtime Using Reinforcement Learning in Metascheduling Applications](https://arxiv.org/abs/2509.20520)
*Samer Alshaer,Ala Khalifeh,Roman Obermaisser*

Main category: cs.AI

TL;DR: 在线学习单元通过强化学习来适应动态环境中的时间触发架构，解决了离线训练中多调度图生成的复杂性问题。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统方法在训练AI调度推理时的局限性，特别是离线训练中构建全面的多调度图（MSG）的挑战，我们提出了一种自适应在线学习单元。

Method: 提出了一种集成在元调度器中的自适应在线学习单元，利用强化学习（RL）进行实时训练，以发现新的调度解决方案并优化现有调度器。

Result: 所提出的RL模型能够发现新的调度解决方案，优化现有调度器，并处理更严格的截止时间或新的性能标准。

Conclusion: 通过实时训练的动态适应，该系统能够有效处理意外事件和复杂的调度场景，确保在大规模、安全关键环境中的鲁棒性和效率。

Abstract: Metascheduling in time-triggered architectures has been crucial in adapting
to dynamic and unpredictable environments, ensuring the reliability and
efficiency of task execution. However, traditional approaches face significant
challenges when training Artificial Intelligence (AI) scheduling inferences
offline, particularly due to the complexities involved in constructing a
comprehensive Multi-Schedule Graph (MSG) that accounts for all possible
scenarios. The process of generating an MSG that captures the vast probability
space, especially when considering context events like hardware failures, slack
variations, or mode changes, is resource-intensive and often infeasible. To
address these challenges, we propose an adaptive online learning unit
integrated within the metascheduler to enhance performance in real-time. The
primary motivation for developing this unit stems from the limitations of
offline training, where the MSG created is inherently a subset of the complete
space, focusing only on the most probable and critical context events. In the
online mode, Reinforcement Learning (RL) plays a pivotal role by continuously
exploring and discovering new scheduling solutions, thus expanding the MSG and
enhancing system performance over time. This dynamic adaptation allows the
system to handle unexpected events and complex scheduling scenarios more
effectively. Several RL models were implemented within the online learning
unit, each designed to address specific challenges in scheduling. These models
not only facilitate the discovery of new solutions but also optimize existing
schedulers, particularly when stricter deadlines or new performance criteria
are introduced. By continuously refining the AI inferences through real-time
training, the system remains flexible and capable of meeting evolving demands,
thus ensuring robustness and efficiency in large-scale, safety-critical
environments.

</details>


### [433] [A Compound Classification System Based on Fuzzy Relations Applied to the Noise-Tolerant Control of a Bionic Hand via EMG Signal Recognition](https://arxiv.org/abs/2509.20523)
*Pawel Trajdos,Marek Kurzynski*

Main category: cs.AI

TL;DR: 该研究提出了一种新的肌电信号（EMG）识别系统，用于控制假肢手。该系统包含一个单类分类器（OCC）集合来检测信号污染，以及一个K近邻（KNN）分类器集合来识别用户意图，并使用模糊模型来统一决策过程。实验结果表明，该系统在处理受污染的肌电信号时具有优势，并与现有技术进行了比较。


<details>
  <summary>Details</summary>
Motivation: 肌电信号（EMG）在控制假肢时易受干扰，影响分类质量。本研究旨在提出一种能够检测并减轻信号污染对假肢控制影响的新型识别系统。

Method: 提出一种包含两部分识别系统的方案：1. 由单类分类器（OCC）组成的集合，用于评估单个通道的污染程度。2. 由K近邻（KNN）分类器组成的集合，用于识别患者的意图。整个系统采用了一个原创的、连贯的模糊模型，实现了贯穿整个识别过程的统一软（模糊）决策方案。

Result: 使用真实肌电信号进行了实验评估，并将提出的模糊识别系统与文献中描述的类似系统进行了比较。目的是对影响识别系统质量的开发方法的参数和程序进行实验比较分析。

Conclusion: 提出的模糊识别系统能够检测受污染的肌电信号，并减轻其对假肢控制的不利影响，在与现有技术比较中显示出一定的优势。

Abstract: Modern anthropomorphic upper limb bioprostheses are typically controlled by
electromyographic (EMG) biosignals using a pattern recognition scheme.
Unfortunately, there are many factors originating from the human source of
objects to be classified and from the human-prosthesis interface that make it
difficult to obtain an acceptable classification quality. One of these factors
is the high susceptibility of biosignals to contamination, which can
considerably reduce the quality of classification of a recognition system.
  In the paper, the authors propose a new recognition system intended for EMG
based control of the hand prosthesis with detection of contaminated biosignals
in order to mitigate the adverse effect of contaminations. The system consists
of two ensembles: the set of one-class classifiers (OCC) to assess the degree
of contamination of individual channels and the ensemble of K-nearest
neighbours (KNN) classifier to recognise the patient's intent. For all
recognition systems, an original, coherent fuzzy model was developed, which
allows the use of a uniform soft (fuzzy) decision scheme throughout the
recognition process. The experimental evaluation was conducted using real
biosignals from a public repository. The goal was to provide an experimental
comparative analysis of the parameters and procedures of the developed method
on which the quality of the recognition system depends. The proposed fuzzy
recognition system was also compared with similar systems described in the
literature.

</details>


### [434] [SAMULE: Self-Learning Agents Enhanced by Multi-level Reflection](https://arxiv.org/abs/2509.20562)
*Yubin Ge,Salvatore Romeo,Jason Cai,Monica Sunkara,Yi Zhang*

Main category: cs.AI

TL;DR: SAMULE框架通过多层次反思合成来提升LLM代理的自我学习能力，特别是在复杂任务中，能够进行更有效的错误分析和反思，显著优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM代理在复杂任务中进行有意义的反思方面存在不足，主要由于错误分析不充分和过度依赖少数成功的轨迹。

Method: 提出SAMULE框架，该框架包含一个回顾性语言模型，通过三个层次的反思合成进行训练：单轨迹学习（微观层面）、任务内学习（中观层面）和任务间学习（宏观层面）。此外，还引入了基于前瞻性的反思机制，用于交互式设置。

Result: 在TravelPlanner、NATURAL PLAN和Tau-bench三个具有挑战性的基准测试中，SAMULE框架显著优于基于反思的基线方法。

Conclusion: 精心设计的反思合成和以失败为中心的学习对于构建能够自我改进的LLM代理至关重要。

Abstract: Despite the rapid advancements in LLM agents, they still face the challenge
of generating meaningful reflections due to inadequate error analysis and a
reliance on rare successful trajectories, especially in complex tasks. In this
work, we propose SAMULE, a new framework for self-learning agents powered by a
retrospective language model that is trained based on Multi-Level Reflection
Synthesis. It first synthesizes high-quality reflections across three
complementary levels: Single-Trajectory Learning (micro-level) for detailed
error correction; Intra-Task Learning (meso-level) to build error taxonomies
across multiple trials of the same task, and Inter-Task Learning (macro-level)
to extract transferable insights based on same typed errors from diverse task
failures. Then we fine-tune a language model serving as the retrospective model
to generate reflections during inference. We further extend our framework to
interactive settings through a foresight-based reflection mechanism, enabling
agents to proactively reflect and adapt during user interactions by comparing
predicted and actual responses. Extensive experiments on three challenging
benchmarks - TravelPlanner, NATURAL PLAN, and Tau-bench - demonstrate that our
approach significantly outperforms reflection-based baselines. Our results
highlight the critical role of well-designed reflection synthesis and
failure-centric learning in building self-improving LLM agents.

</details>


### [435] [Adaptive Cybersecurity Architecture for Digital Product Ecosystems Using Agentic AI](https://arxiv.org/abs/2509.20640)
*Oluwakemi T. Olayinka,Sumeet Jeswani,Divine Iloh*

Main category: cs.AI

TL;DR: 该研究引入了基于代理人工智能（AI）的自适应网络安全架构，使用能够动态学习和进行上下文感知决策的自主目标驱动代理来解决传统静态模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统的静态网络安全模型在应对当前包含云服务、API、移动平台和边缘设备在内的数字产品生态系统的可扩展性、实时检测和上下文响应能力方面存在不足。

Method: 该框架将代理AI集成到关键生态系统层，以实现自主威胁缓解、主动策略执行和实时异常检测。采用行为基线、去中心化风险评分和联合威胁情报共享等关键功能。

Result: 通过原生云模拟，证明了系统识别零日攻击和动态修改访问策略的能力。评估结果显示，适应性增强、响应延迟降低、检测准确性提高。

Conclusion: 该架构为保护复杂的数字基础设施提供了一个智能且可扩展的蓝图，与零信任模型兼容，并支持遵守国际网络安全法规。

Abstract: Traditional static cybersecurity models often struggle with scalability,
real-time detection, and contextual responsiveness in the current digital
product ecosystems which include cloud services, application programming
interfaces (APIs), mobile platforms, and edge devices. This study introduces
autonomous goal driven agents capable of dynamic learning and context-aware
decision making as part of an adaptive cybersecurity architecture driven by
agentic artificial intelligence (AI). To facilitate autonomous threat
mitigation, proactive policy enforcement, and real-time anomaly detection, this
framework integrates agentic AI across the key ecosystem layers. Behavioral
baselining, decentralized risk scoring, and federated threat intelligence
sharing are important features. The capacity of the system to identify zero-day
attacks and dynamically modify access policies was demonstrated through native
cloud simulations. The evaluation results show increased adaptability,
decreased response latency, and improved detection accuracy. The architecture
provides an intelligent and scalable blueprint for safeguarding complex digital
infrastructure and is compatible with zero-trust models, thereby supporting the
adherence to international cybersecurity regulations.

</details>


### [436] [Accelerate Creation of Product Claims Using Generative AI](https://arxiv.org/abs/2509.20652)
*Po-Yu Liang,Yong Zhang,Tatiana Hwa,Aaron Byers*

Main category: cs.AI

TL;DR: Claim Advisor是一个利用大型语言模型（LLM）加速产品声明创建的Web应用程序，通过语义搜索、生成优化和模拟来改进声明。


<details>
  <summary>Details</summary>
Motivation: 创建产品声明耗时耗力，Claim Advisor旨在通过利用LLM来加速和优化这一过程。

Method: Claim Advisor利用LLM进行上下文学习和微调，实现语义搜索、声明生成与优化，并通过模拟进行声明排名。

Result: 在消费品（CPG）公司进行的应用显示出非常有希望的结果，表明该工具有广泛的适用性。

Conclusion: Claim Advisor在加速声明创建方面显示出巨大潜力，并鼓励在各行业中研究和应用生成式AI。

Abstract: The benefit claims of a product is a critical driver of consumers' purchase
behavior. Creating product claims is an intense task that requires substantial
time and funding. We have developed the $\textbf{Claim Advisor}$ web
application to accelerate claim creations using in-context learning and
fine-tuning of large language models (LLM). $\textbf{Claim Advisor}$ was
designed to disrupt the speed and economics of claim search, generation,
optimization, and simulation. It has three functions: (1) semantically
searching and identifying existing claims and/or visuals that resonate with the
voice of consumers; (2) generating and/or optimizing claims based on a product
description and a consumer profile; and (3) ranking generated and/or manually
created claims using simulations via synthetic consumers. Applications in a
consumer packaged goods (CPG) company have shown very promising results. We
believe that this capability is broadly useful and applicable across product
categories and industries. We share our learning to encourage the research and
application of generative AI in different industries.

</details>


### [437] [An Automated Retrieval-Augmented Generation LLaMA-4 109B-based System for Evaluating Radiotherapy Treatment Plans](https://arxiv.org/abs/2509.20707)
*Junjie Cui,Peilong Wang,Jason Holmes,Leshan Sun,Michael L. Hinni,Barbara A. Pockaj,Sujay A. Vora,Terence T. Sio,William W. Wong,Nathan Y. Yu,Steven E. Schild,Joshua R. Niska,Sameer R. Keole,Jean-Claude M. Rwigema,Samir H. Patel,Lisa A. McGee,Carlos A. Vargas,Wei Liu*

Main category: cs.AI

TL;DR: 开发了一个基于LLaMA-4 109B的检索增强生成（RAG）系统，用于自动化、符合协议且可解释的放疗计划评估。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够自动化、符合协议且可解释的放疗计划评估系统。

Method: 我们整理了一个包含614个放疗计划的多协议数据集，并构建了一个包含剂量指标和协议约束的知识库。RAG系统集成了检索引擎、百分位预测组件和临床约束检查器，由LLM通过多步提示推理驱动。

Result: 检索超参数通过高斯过程优化，最佳配置（all-MiniLM-L6-v2）实现了近邻精度和较低的平均绝对误差。最终RAG系统在百分位估计和约束识别方面与独立模块实现了100%的一致性。

Conclusion: 研究结果表明，将结构化的群体评分与模块化工具增强的推理相结合，可以实现透明、可扩展的放疗计划评估。该系统具有可追溯性、减少幻觉，并在不同协议下表现稳健。未来工作包括临床医生验证和改进领域自适应检索模型。

Abstract: Purpose: To develop a retrieval-augmented generation (RAG) system powered by
LLaMA-4 109B for automated, protocol-aware, and interpretable evaluation of
radiotherapy treatment plans.
  Methods and Materials: We curated a multi-protocol dataset of 614
radiotherapy plans across four disease sites and constructed a knowledge base
containing normalized dose metrics and protocol-defined constraints. The RAG
system integrates three core modules: a retrieval engine optimized across five
SentenceTransformer backbones, a percentile prediction component based on
cohort similarity, and a clinical constraint checker. These tools are directed
by a large language model (LLM) using a multi-step prompt-driven reasoning
pipeline to produce concise, grounded evaluations.
  Results: Retrieval hyperparameters were optimized using Gaussian Process on a
scalarized loss function combining root mean squared error (RMSE), mean
absolute error (MAE), and clinically motivated accuracy thresholds. The best
configuration, based on all-MiniLM-L6-v2, achieved perfect nearest-neighbor
accuracy within a 5-percentile-point margin and a sub-2pt MAE. When tested
end-to-end, the RAG system achieved 100% agreement with the computed values by
standalone retrieval and constraint-checking modules on both percentile
estimates and constraint identification, confirming reliable execution of all
retrieval, prediction and checking steps.
  Conclusion: Our findings highlight the feasibility of combining structured
population-based scoring with modular tool-augmented reasoning for transparent,
scalable plan evaluation in radiation therapy. The system offers traceable
outputs, minimizes hallucination, and demonstrates robustness across protocols.
Future directions include clinician-led validation, and improved domain-adapted
retrieval models to enhance real-world integration.

</details>


### [438] [Parallel Thinking, Sequential Answering: Bridging NAR and AR for Efficient Reasoning](https://arxiv.org/abs/2509.20744)
*Qihang Ai,Haiyun Jiang*

Main category: cs.AI

TL;DR: 通过结合自回归（AR）和非自回归（NAR）语言模型来提升推理任务的性能，NAR模型生成中间推理过程，AR模型生成最终答案，实现了性能提升和成本降低。


<details>
  <summary>Details</summary>
Motivation: 自回归（AR）模型在生成连贯的输出方面表现出色，但在推理密集型领域（如数学和代码）由于需要冗长的思考链而存在推理速度慢的问题。非自回归（NAR）模型（如离散扩散模型）允许并行生成并显著提高速度，但通常以牺牲输出质量为代价。

Method: 提出一种新范例，其中NAR模型高效地生成中间推理痕迹，随后引导AR模型给出精确的最终答案。

Result: 实验证明，该方法在性能上比强大的基线模型有显著的26%的提升，同时大大降低了推理成本。

Conclusion: 结合AR和NAR模型的优势，可以在推理任务中实现高性能和高效率。

Abstract: We study reasoning tasks through a framework that integrates auto-regressive
(AR) and non-autoregressive (NAR) language models. AR models, which generate
text sequentially, excel at producing coherent outputs but often suffer from
slow inference, particularly in reasoning-intensive domains such as mathematics
and code, where lengthy chains of thought are required. In contrast, NAR
models, such as discrete diffusion models, allow parallel generation and offer
substantial speedups, though typically at the cost of reduced output quality.
To address these limitations, we introduce a new paradigm in which an NAR model
efficiently produces intermediate reasoning traces, which subsequently guide an
AR model to deliver precise final answers. Experiments demonstrate that our
approach yields significant 26% improvements over strong baselines while
substantially reducing inference cost.

</details>


### [439] [Meta-Memory: Retrieving and Integrating Semantic-Spatial Memories for Robot Spatial Reasoning](https://arxiv.org/abs/2509.20754)
*Yufan Mao,Hanjing Ye,Wenlong Dong,Chengjie Zhang,Hong Zhang*

Main category: cs.AI

TL;DR: Meta-Memory是一个大型语言模型（LLM）驱动的智能体，能够构建高密度环境记忆表示，并通过联合推理语义和空间模态来检索和整合相关记忆，以响应自然语言查询，从而实现强大的空间推理能力。项目在SpaceLocQA和NaVQA基准测试中表现优于最先进的方法，并在真实机器人平台上得到部署。


<details>
  <summary>Details</summary>
Motivation: 机器人需要在复杂环境中有效地存储观测作为记忆，并利用它们来回答关于空间位置的人类查询，这是一个关键但研究不足的挑战。虽然先前的工作在构建机器人记忆方面取得了进展，但很少有人解决高效记忆检索和整合的原则机制。

Method: 提出Meta-Memory，一个大型语言模型（LLM）驱动的智能体，它构建环境的高密度记忆表示。Meta-Memory的关键创新在于通过联合推理语义和空间模态来检索和整合相关记忆，以响应自然语言位置查询。

Result: Meta-Memory在SpaceLocQA和公开的NaVQA基准测试中显著优于最先进的方法。此外，Meta-Memory已成功部署在真实的机器人平台上，证明了其在复杂环境中的实际效用。

Conclusion: Meta-Memory通过其联合语义-空间推理能力，为机器人提供了强大的空间推理能力，并在基准测试和实际应用中取得了优异的性能。

Abstract: Navigating complex environments requires robots to effectively store
observations as memories and leverage them to answer human queries about
spatial locations, which is a critical yet underexplored research challenge.
While prior work has made progress in constructing robotic memory, few have
addressed the principled mechanisms needed for efficient memory retrieval and
integration. To bridge this gap, we propose Meta-Memory, a large language model
(LLM)-driven agent that constructs a high-density memory representation of the
environment. The key innovation of Meta-Memory lies in its capacity to retrieve
and integrate relevant memories through joint reasoning over semantic and
spatial modalities in response to natural language location queries, thereby
empowering robots with robust and accurate spatial reasoning capabilities. To
evaluate its performance, we introduce SpaceLocQA, a large-scale dataset
encompassing diverse real-world spatial question-answering scenarios.
Experimental results show that Meta-Memory significantly outperforms
state-of-the-art methods on both the SpaceLocQA and the public NaVQA
benchmarks. Furthermore, we successfully deployed Meta-Memory on real-world
robotic platforms, demonstrating its practical utility in complex environments.
Project page: https://itsbaymax.github.io/meta-memory.github.io/ .

</details>


### [440] [LogReasoner: Empowering LLMs with Expert-like Coarse-to-Fine Reasoning for Log Analysis Tasks](https://arxiv.org/abs/2509.20798)
*Lipeng Ma,Yixuan Li,Weidong Yang,Mingjie Zhou,Xinyi Liu,Ben Fei,Shuhao Li,Xiaoyan Sun,Sihang Jiang,Yanghua Xiao*

Main category: cs.AI

TL;DR: LogReasoner是一个增强框架，能让大语言模型像专家一样进行日志分析，通过粗粒度和细粒度两阶段增强，显著提升了日志分析任务的性能。


<details>
  <summary>Details</summary>
Motivation: 通用大语言模型在进行日志分析时，难以形成符合专家认知且细节精确的结构化推理流程。因此，需要一个框架来提升大语言模型在日志分析任务中的推理能力。

Method: LogReasoner框架包含两个阶段：1. 粗粒度增强：利用故障排除流程图和现有任务，构建高层专家思维，使大语言模型能够形成结构化的推理流程。2. 细粒度增强：首先使用特定任务的逐步解决方案对大语言模型进行微调，然后利用偏好学习纠正模型错误，进一步提高其分析的粒度和正确性。

Result: 在四个不同的日志分析任务上，使用Qwen-2.5和Llama-3等开源大语言模型进行评估，LogReasoner显著优于现有的大语言模型，达到了最先进的性能。

Conclusion: LogReasoner框架能有效提升大语言模型在日志分析任务中的推理能力，并取得了优于现有方法的性能。

Abstract: Log analysis is crucial for monitoring system health and diagnosing failures
in complex systems. Recent advances in large language models (LLMs) offer new
opportunities for automated log analysis, leveraging their reasoning
capabilities to perform tasks such as anomaly detection and failure prediction.
However, general-purpose LLMs struggle to formulate structured reasoning
workflows that align with expert cognition and deliver precise details of
reasoning steps. To address these challenges, we propose LogReasoner, a
coarse-to-fine reasoning enhancement framework designed to enable LLMs to
reason log analysis tasks like experts. LogReasoner consists of two stages: (1)
coarse-grained enhancement of expert thinking, where high-level expert thoughts
are constructed from collected troubleshooting flowcharts and existing tasks to
enable LLMs to formulate structured reasoning workflows and (2) fine-grained
enhancement of specific steps, where we first fine-tune the LLM with
task-specific stepwise solutions to enhance the LLM for instantiated reasoning,
then employ the preference learning to calibrate the LLM's reasoning details
from its mistakes, further strengthen the LLM's analytical granularity and
correctness. We evaluate LogReasoner on four distinct log analysis tasks using
open-source LLMs such as Qwen-2.5 and Llama-3. Experimental results show that
LogReasoner significantly outperforms existing LLMs, achieving state-of-the-art
performance and demonstrating its effectiveness in enhancing the reasoning
capabilities of LLMs for log analysis.

</details>


### [441] [DeFacto: Counterfactual Thinking with Images for Enforcing Evidence-Grounded and Faithful Reasoning](https://arxiv.org/abs/2509.20912)
*Tianrun Xu,Haoda Jing,Ye Li,Yuquan Wei,Jun Feng,Guanyu Chen,Haichuan Gao,Tianren Zhang,Feng Chen*

Main category: cs.AI

TL;DR: DeFacto是一个反事实推理框架，通过引入正例、反事实和随机遮蔽三种训练范式，并结合GRPO-based强化学习和三种互补的奖励机制，来提高多模态语言模型在回答准确性和推理忠实度方面的表现，解决了模型依赖无关区域或错误证据进行推理的问题。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型在进行基于图像的推理时，存在依赖无关或错误区域、利用先验知识或数据集偏差得到正确答案的问题，即使答案正确，错误的推理过程也表明模型并未真正理解图像，因此需要提高推理的忠实度。

Method: 提出DeFacto反事实推理框架，该框架包含三个训练范式：正例、反事实和随机遮蔽。通过一个自动定位问题相关证据并构建三种变体的流程，生成了一个包含约10万张图像的数据集。在此基础上，利用GRPO-based强化学习和三种互补的奖励机制来训练模型。

Result: DeFacto在多个基准测试中显著提高了回答的准确性和推理的忠实度。

Conclusion: DeFacto框架为可解释的多模态推理奠定了更坚实的基础，解决了现有模型在推理过程中可能出现的欺骗性问题。

Abstract: Recent advances in multimodal language models (MLLMs) have achieved
remarkable progress in vision-language reasoning, especially with the emergence
of "thinking with images," which integrates explicit visual steps into the
reasoning process. While this paradigm strengthens image-based reasoning, a
significant challenge remains: models may arrive at correct answers by relying
on irrelevant or spurious regions, driven by prior knowledge or dataset biases.
Even when the answer is correct, flawed reasoning indicates that the model has
not truly understood the image, highlighting the critical importance of
reasoning fidelity in multimodal tasks. To address this issue, we propose
DeFacto, a counterfactual reasoning framework that jointly enforces accurate
answering and faithful reasoning. A key component of our approach is the design
of three complementary training paradigms: (i) positive, (ii) counterfactual,
and (iii) random-masking. To enable these paradigms, we develop a pipeline that
automatically localizes question-relevant evidence and constructs positive,
counterfactual, and random variants, resulting in a dataset of about 100k
images. Building on this framework, we train multimodal language models with
GRPO-based reinforcement learning, where we design three complementary rewards
to guide the model toward accurate answering and evidence-grounded reasoning.
Experiments on diverse benchmarks demonstrate that DeFacto substantially
improves both answer accuracy and reasoning faithfulness, establishing a
stronger foundation for interpretable multimodal reasoning. The code is
available on GitHub and the dataset is released on HuggingFace.

</details>


### [442] [GALAX: Graph-Augmented Language Model for Explainable Reinforcement-Guided Subgraph Reasoning in Precision Medicine](https://arxiv.org/abs/2509.20935)
*Heming Zhang,Di Huang,Wenyu Li,Michael Province,Yixin Chen,Philip Payne,Fuhai Li*

Main category: cs.AI

TL;DR: GALAX框架整合GNN和LLM，通过图过程奖励模型（GPRM）进行强化学习，以可解释的方式发现疾病相关子图、靶点和通路。


<details>
  <summary>Details</summary>
Motivation: 现有方法在整合多组学数据、拓扑结构和文本知识方面存在不足，限制了在精准医学中的应用。

Method: 提出GALAX框架，将预训练GNN集成到LLM中，利用GPRM进行强化学习，逐步生成疾病相关子图。

Result: 应用GALAX框架于Target-QA基准测试，实现了可解释的、基于仿射推理的靶点和通路发现。

Conclusion: GALAX框架为精准医学中的靶点和通路发现提供了一个可扩展且符合生物学原理的、可解释的、受强化学习指导的子图推理框架。

Abstract: In precision medicine, quantitative multi-omic features, topological context,
and textual biological knowledge play vital roles in identifying
disease-critical signaling pathways and targets. Existing pipelines capture
only part of these-numerical omics ignore topological context, text-centric
LLMs lack quantitative grounded reasoning, and graph-only models underuse node
semantics and the generalization of LLMs-limiting mechanistic interpretability.
Although Process Reward Models (PRMs) aim to guide reasoning in LLMs, they
remain limited by unreliable intermediate evaluation, and vulnerability to
reward hacking with computational cost. These gaps motivate integrating
quantitative multi-omic signals, topological structure with node annotations,
and literature-scale text via LLMs, using subgraph reasoning as the principle
bridge linking numeric evidence, topological knowledge and language context.
Therefore, we propose GALAX (Graph Augmented LAnguage model with
eXplainability), an innovative framework that integrates pretrained Graph
Neural Networks (GNNs) into Large Language Models (LLMs) via reinforcement
guided by a Graph Process Reward Model (GPRM), which generates disease-relevant
subgraphs in a step-wise manner initiated by an LLM and iteratively evaluated
by a pretrained GNN, enabling process-level supervision without explicit
intermediate reasoning annotations. As an application, we also introduced
Target-QA, a benchmark combining CRISPR-identified targets, multi-omic
profiles, and biomedical graph knowledge across diverse cancer cell lines,
which enables GNN pretraining for supervising step-wise graph construction and
supports long-context reasoning over text-numeric graphs (TNGs), providing a
scalable and biologically grounded framework for explainable,
reinforcement-guided subgraph reasoning toward reliable and interpretable
target and pathway discovery in precision medicine.

</details>


### [443] [Beyond Stars: Bridging the Gap Between Ratings and Review Sentiment with LLM](https://arxiv.org/abs/2509.20953)
*Najla Zuhir,Amna Mohammad Salim,Parvathy Premkumar,Moshiur Farazi*

Main category: cs.AI

TL;DR: 使用包含结构化提示的LLM来分析移动应用评论，以克服传统评分系统的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统评分系统无法捕捉评论文本中的细微差别，而传统的NLP技术难以理解上下文、领域特定术语和讽刺等语言特征。

Method: 提出一个利用LLM和结构化提示的模块化框架，以量化评分与文本情感的差异，提取特征级见解，并通过检索增强的对话式问答支持交互式探索。

Result: 在三个不同的数据集（AWARE、Google Play和Spotify）上进行的实验表明，该LLM驱动的方法在准确性、鲁棒性和可操作性方面明显优于基线方法。

Conclusion: 所提出的LLM驱动框架能够更有效地分析移动应用评论，提供比传统方法更深入、更细致的见解。

Abstract: We present an advanced approach to mobile app review analysis aimed at
addressing limitations inherent in traditional star-rating systems. Star
ratings, although intuitive and popular among users, often fail to capture the
nuanced feedback present in detailed review texts. Traditional NLP techniques
-- such as lexicon-based methods and classical machine learning classifiers --
struggle to interpret contextual nuances, domain-specific terminology, and
subtle linguistic features like sarcasm. To overcome these limitations, we
propose a modular framework leveraging large language models (LLMs) enhanced by
structured prompting techniques. Our method quantifies discrepancies between
numerical ratings and textual sentiment, extracts detailed, feature-level
insights, and supports interactive exploration of reviews through
retrieval-augmented conversational question answering (RAG-QA). Comprehensive
experiments conducted on three diverse datasets (AWARE, Google Play, and
Spotify) demonstrate that our LLM-driven approach significantly surpasses
baseline methods, yielding improved accuracy, robustness, and actionable
insights in challenging and context-rich review scenarios.

</details>


### [444] [AOT*: Efficient Synthesis Planning via LLM-Empowered AND-OR Tree Search](https://arxiv.org/abs/2509.20988)
*Xiaozhuang Song,Xuanhao Pan,Xinjian Zhao,Hangting Ye,Shufei Zhang,Jian Tang,Tianshu Yu*

Main category: cs.AI

TL;DR: AOT* 框架结合了 LLM 生成的合成路径和 AND-OR 树搜索，在逆合成规划中实现了最先进的性能，并显著提高了搜索效率。


<details>
  <summary>Details</summary>
Motivation: 多步逆合成规划因其指数级的搜索空间和推理成本而具有计算挑战性。尽管大型语言模型（LLM）具有化学推理能力，但在合成规划中的应用受到效率和成本的限制。

Method: AOT* 框架将 LLM 生成的化学合成路径与系统的 AND-OR 树搜索相结合。AOT* 将生成的完整合成路线原子化地映射到 AND-OR 树组件，并结合了具有数学依据的奖励分配策略和基于检索的上下文工程，从而使 LLM 能够有效地在化学空间中导航。

Result: AOT* 在多个合成基准测试中的实验评估表明，AOT* 实现了最先进的性能，并显著提高了搜索效率。AOT* 的解决率具有竞争力，其迭代次数比现有的基于 LLM 的方法少 3-5 倍，并且在处理复杂分子目标时效率优势更加明显。

Conclusion: AOT* 框架通过整合 LLM 生成的合成路径和 AND-OR 树搜索，解决了多步逆合成规划的挑战，实现了高效率和最先进的性能。

Abstract: Retrosynthesis planning enables the discovery of viable synthetic routes for
target molecules, playing a crucial role in domains like drug discovery and
materials design. Multi-step retrosynthetic planning remains computationally
challenging due to exponential search spaces and inference costs. While Large
Language Models (LLMs) demonstrate chemical reasoning capabilities, their
application to synthesis planning faces constraints on efficiency and cost. To
address these challenges, we introduce AOT*, a framework that transforms
retrosynthetic planning by integrating LLM-generated chemical synthesis
pathways with systematic AND-OR tree search. To this end, AOT* atomically maps
the generated complete synthesis routes onto AND-OR tree components, with a
mathematically sound design of reward assignment strategy and retrieval-based
context engineering, thus enabling LLMs to efficiently navigate in the chemical
space. Experimental evaluation on multiple synthesis benchmarks demonstrates
that AOT* achieves SOTA performance with significantly improved search
efficiency. AOT* exhibits competitive solve rates using 3-5$\times$ fewer
iterations than existing LLM-based approaches, with the efficiency advantage
becoming more pronounced on complex molecular targets.

</details>


### [445] [CORE: Full-Path Evaluation of LLM Agents Beyond Final State](https://arxiv.org/abs/2509.20998)
*Panagiotis Michelakis,Yiannis Hadjiyiannis,Dimitrios Stamoulis*

Main category: cs.AI

TL;DR: 该研究提出了一个基于确定性有限自动机（DFA）的框架，用于评估AI代理解决现实世界问题的函数调用序列，并引入了CORE度量套件，以更全面地评估代理行为，超越了传统仅关注最终状态的评估方法。


<details>
  <summary>Details</summary>
Motivation: 评估AI代理通过函数调用序列解决现实世界任务的能力仍然是一个挑战，现有的基准测试方法往往过于简化，只关注最终结果，忽略了安全性、效率和中间步骤的正确性等关键方面。

Method: 提出了一种基于确定性有限自动机（DFA）的框架，将任务编码为有效的工具使用路径集，并引入了CORE度量套件（包括路径正确性、路径正确性-Kendall's tau复合、前缀临界性、有害调用率和效率），用于量化AI代理行为与预期执行模式的对齐程度。

Result: 在多个不同的世界模型中，该方法揭示了在传统最终状态评估下看似相同的AI代理之间，在CORE度量下存在显著的性能差异。

Conclusion: 基于DFA的框架和CORE度量套件能够更全面、更细致地评估AI代理在解决现实世界任务中的表现，揭示了传统方法可能忽略的重要性能差异。

Abstract: Evaluating AI agents that solve real-world tasks through function-call
sequences remains an open challenge. Existing agentic benchmarks often reduce
evaluation to a binary judgment of the final state, overlooking critical
aspects such as safety, efficiency, and intermediate correctness. We propose a
framework based on deterministic finite automata (DFAs) that encodes tasks as
sets of valid tool-use paths, enabling principled assessment of agent behavior
in diverse world models. Building on this foundation, we introduce CORE, a
suite of five metrics, namely Path Correctness, Path Correctness - Kendall's
tau Composite, Prefix Criticality, Harmful-Call Rate, and Efficiency, that
quantify alignment with expected execution patterns. Across diverse worlds, our
method reveals important performance differences between agents that would
otherwise appear equivalent under traditional final-state evaluation schemes.

</details>


### [446] [Who Gets Cited Most? Benchmarking Long-Context Language Models on Scientific Articles](https://arxiv.org/abs/2509.21028)
*Miao Li,Alexander Gurung,Irina Saparina,Mirella Lapata*

Main category: cs.AI

TL;DR: SciTrek是一个新的问答基准，用于测试LLM在科学文章上的长上下文推理能力，它使用复杂的、需要跨多篇文章综合信息的问题，并通过SQL查询自动生成答案，以进行细粒度错误分析。实验表明，SciTrek对现有模型构成了重大挑战，尤其是在处理数值运算和定位信息方面存在系统性缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有长上下文基准的局限性，如依赖非科学文本、侧重简单信息检索或使用人工上下文，促使研究者提出SciTrek，以评估LLM在科学文章上的长上下文推理能力。

Method: SciTrek通过构建一个包含文章元数据（标题、作者、参考文献）的数据库，并将问题表述为SQL查询来自动生成问题和答案。这种方法允许进行细粒度的错误分析，并能扩展到1M token的上下文。

Result: 实验结果显示，随着上下文长度的增加，SciTrek对现有LLM（包括开源和闭源模型）构成了严峻挑战，即使经过监督微调和强化学习，性能提升也有限。模型在执行基本数值运算和在长上下文中准确定位信息方面存在系统性不足。

Conclusion: SciTrek基准揭示了当前LLM在长上下文科学推理方面存在显著的局限性，尤其是在数值处理和信息定位能力上，这为未来模型改进指明了方向。

Abstract: This paper introduces SciTrek, a novel question-answering benchmark designed
to evaluate the long-context reasoning capabilities of large language models
(LLMs) using scientific articles. Current long-context benchmarks often rely on
non-scientific texts, focus on simple information retrieval tasks, or employ
artificial contexts. SciTrek addresses these limitations by proposing complex
questions that require information aggregation and synthesis across multiple
full-text scientific articles. Questions and their ground-truth answers are
automatically generated by formulating them as SQL queries over a database
constructed from article metadata (titles, authors, and references). The SQL
operations provide explicit, verifiable reasoning steps for fine-grained error
analysis, and the construction process scales to contexts up to 1M tokens with
minimal supervision. Extensive experiments on a diverse set of open-weight and
proprietary LLMs demonstrate that SciTrek poses a significant challenge as the
context length increases, with supervised fine-tuning and reinforcement
learning offering only limited gains. Our analysis reveals systematic
shortcomings in models' abilities to perform basic numerical operations and
accurately locate specific information in long contexts.

</details>


### [447] [CLAUSE: Agentic Neuro-Symbolic Knowledge Graph Reasoning via Dynamic Learnable Context Engineering](https://arxiv.org/abs/2509.21035)
*Yang Zhao,Chengxiao Dai,Wei Zhuo,Yue Xiu,Dusit Niyato*

Main category: cs.AI

TL;DR: CLAUSE是一个神经符号框架，通过顺序决策优化知识图谱上下文构建，以在准确性、延迟和成本之间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 在多跳问答中，已部署系统需要在满足延迟和成本限制的同时，保持答案的准确性并保留来源信息。传统的静态方法常导致检索过度、上下文膨胀和不可预测的运行时表现。

Method: CLAUSE是一个包含三个智能体的神经符号框架，将上下文构建视为在知识图谱上的顺序决策过程。它利用LC-MAPPO算法协调三个智能体（子图架构师、路径导航员、上下文策展人），在用户指定的延迟和成本预算下，联合优化子图构建、推理路径发现和证据选择。

Result: 在HotpotQA、MetaQA和FactKG数据集上，CLAUSE在提高答案准确率的同时，减少了子图增长和端到端延迟，且保持了相同的或更低的token预算。特别是在MetaQA-2-hop数据集上，相较于GraphRAG基线，CLAUSE的EM@1提高了39.3%，同时延迟降低了18.6%，边增长减少了40.9%。

Conclusion: CLAUSE能够生成紧凑、保留来源信息且在部署约束下性能可预测的上下文，实现了在准确性、延迟和成本之间的有效权衡。

Abstract: Knowledge graphs provide structured context for multi-hop question answering,
but deployed systems must balance answer accuracy with strict latency and cost
targets while preserving provenance. Static k-hop expansions and "think-longer"
prompting often over-retrieve, inflate context, and yield unpredictable
runtime. We introduce CLAUSE, an agentic three-agent neuro-symbolic framework
that treats context construction as a sequential decision process over
knowledge graphs, deciding what to expand, which paths to follow or backtrack,
what evidence to keep, and when to stop. Latency (interaction steps) and prompt
cost (selected tokens) are exposed as user-specified budgets or prices,
allowing per-query adaptation to trade-offs among accuracy, latency, and cost
without retraining. CLAUSE employs the proposed Lagrangian-Constrained
Multi-Agent Proximal Policy Optimization (LC-MAPPO) algorithm to coordinate
three agents: Subgraph Architect, Path Navigator, and Context Curator, so that
subgraph construction, reasoning-path discovery, and evidence selection are
jointly optimized under per-query resource budgets on edge edits, interaction
steps, and selected tokens. Across HotpotQA, MetaQA, and FactKG, CLAUSE yields
higher EM@1 while reducing subgraph growth and end-to-end latency at equal or
lower token budgets. On MetaQA-2-hop, relative to the strongest RAG baseline
(GraphRAG), CLAUSE achieves +39.3 EM@1 with 18.6% lower latency and 40.9% lower
edge growth. The resulting contexts are compact, provenance-preserving, and
deliver predictable performance under deployment constraints.

</details>


### [448] [Combinatorial Creativity: A New Frontier in Generalization Abilities](https://arxiv.org/abs/2509.21043)
*Samuel Schapiro,Sumuk Shashidhar,Alexi Gladstone,Jonah Black,Royce Moon,Dilek Hakkani-Tur,Lav R. Varshney*

Main category: cs.AI

TL;DR: AI和LLM在科学创意生成等任务中的应用，提出了一种评估新颖性和效用的新框架，并进行了实证研究，发现了创造力的缩放行为、最优模型参数以及新颖性-效用权衡，这对理解和改进AI创造力具有重要意义。


<details>
  <summary>Details</summary>
Motivation: AI系统，特别是LLM，越来越多地用于科学创意生成等创造性任务，这是一种现有概念框架未解决的从训练数据中进行泛化的形式。

Method: 提出了一种理论框架和算法任务，用于根据新颖性和效用的程度来评估LLM在创造性任务中的输出，而不是评估准确性或正确性。

Result: （1）首次揭示了LLM创造力的缩放行为。（2）发现对于固定的计算预算，存在创造力能力的最优模型深度和宽度。（3）发现“构思-执行”差距，即LLM在生成新颖的科学构思方面表现出色，但在确保其实际可行性方面却很挣扎，这可能可以用创造力算法普遍存在的新颖性-效用权衡来解释。

Conclusion: 新颖性-效用权衡即使在规模化时仍然存在，这让人对LLM在其当前形式下的长期创造潜力表示怀疑。所提出的概念框架和实证发现为理解和改进现代AI模型的创造力奠定了基础。

Abstract: Artificial intelligence (AI) systems, and large language models (LLMs) in
particular, are increasingly employed for creative tasks like scientific idea
generation, constituting a form of generalization from training data
unaddressed by existing conceptual frameworks. Though in many ways similar to
forms of compositional generalization (CG), combinatorial creativity (CC) is an
open-ended ability. Instead of evaluating for accuracy or correctness against
fixed targets, which would contradict the open-ended nature of CC, we propose a
theoretical framework and algorithmic task for evaluating outputs by their
degrees of novelty and utility. From here, we make several important empirical
contributions: (1) We obtain the first insights into the scaling behavior of
creativity for LLMs. (2) We discover that, for fixed compute budgets, there
exist optimal model depths and widths for creative ability. (3) We find that
the ideation-execution gap, whereby LLMs excel at generating novel scientific
ideas but struggle to ensure their practical feasibility, may be explained by a
more fundamental novelty-utility tradeoff characteristic of creativity
algorithms in general. Importantly, this tradeoff remains persistent even at
scale, casting doubt on the long-term creative potential of LLMs in their
current form. Together, our conceptual framework and empirical findings provide
a foundation for understanding and improving creativity in modern AI models,
marking a new frontier in generalization abilities.

</details>


### [449] [Disagreements in Reasoning: How a Model's Thinking Process Dictates Persuasion in Multi-Agent Systems](https://arxiv.org/abs/2509.21054)
*Haodong Zhao,Jidong Li,Zhaomin Wu,Tianjie Ju,Zhuosheng Zhang,Bingsheng He,Gongshen Liu*

Main category: cs.AI

TL;DR: LLM/LRM协作系统中，说服效果并非主要由模型规模决定，而是取决于模型的认知过程（尤其是显式推理能力）。LRM的推理过程不易被说服，但透明化其“思考过程”可增强其说服力。研究揭示了“说服二元性”，并探讨了多跳说服中的影响传播和衰减。


<details>
  <summary>Details</summary>
Motivation: 当前主流观点认为模型规模是影响多智能体系统（MAS）中说服效果的主要因素，但本文提出质疑，认为模型的认知过程，特别是显式推理能力，才是决定说服动态的关键。

Method: 通过一系列多智能体说服实验，研究模型规模和认知过程（特别是显式推理）对说服效果的影响，并探讨了“思考内容”透明度对说服力的作用。此外，还考察了更复杂的、多跳的说服场景。

Result: 研究发现了“说服二元性”，即LRM的推理过程不易被说服，但通过共享“思考内容”可以显著增强其说服他人的能力。同时，在多跳说服场景中观察到了复杂的影响传播和衰减动态。

Conclusion: 模型的内部处理架构与其外部说服行为之间存在系统性联系。研究为理解先进模型的易受攻击性提供了新解释，并对未来MAS的安全、鲁棒性和设计具有重要意义。

Abstract: The rapid proliferation of recent Multi-Agent Systems (MAS), where Large
Language Models (LLMs) and Large Reasoning Models (LRMs) usually collaborate to
solve complex problems, necessitates a deep understanding of the persuasion
dynamics that govern their interactions. This paper challenges the prevailing
hypothesis that persuasive efficacy is primarily a function of model scale. We
propose instead that these dynamics are fundamentally dictated by a model's
underlying cognitive process, especially its capacity for explicit reasoning.
Through a series of multi-agent persuasion experiments, we uncover a
fundamental trade-off we term the Persuasion Duality. Our findings reveal that
the reasoning process in LRMs exhibits significantly greater resistance to
persuasion, maintaining their initial beliefs more robustly. Conversely, making
this reasoning process transparent by sharing the "thinking content"
dramatically increases their ability to persuade others. We further consider
more complex transmission persuasion situations and reveal complex dynamics of
influence propagation and decay within multi-hop persuasion between multiple
agent networks. This research provides systematic evidence linking a model's
internal processing architecture to its external persuasive behavior, offering
a novel explanation for the susceptibility of advanced models and highlighting
critical implications for the safety, robustness, and design of future MAS.

</details>


### [450] [Recon-Act: A Self-Evolving Multi-Agent Browser-Use System via Web Reconnaissance, Tool Generation, and Task Execution](https://arxiv.org/abs/2509.21072)
*Kaiwen He,Zhiwei Wang,Chenyi Zhuang,Jinjie Gu*

Main category: cs.AI

TL;DR: Recon-Act是一个多智能体框架，通过侦察和行动来改进基于浏览器的智能代理，解决了长时任务中的行动排序和试错问题。


<details>
  <summary>Details</summary>
Motivation: 现有智能浏览器代理在处理真实网页的多轮长时任务时，存在行动排序混乱和过多试错的问题。

Method: 提出Recon-Act框架，包含侦察团队（进行分析和工具生成）和行动团队（进行意图分解、工具编排和执行）。侦察团队通过对比成功和失败的轨迹来推断修正方法，并将其抽象为广义工具（提示或代码），实时注册到工具库。行动团队利用这些工具重新推理过程，形成数据-工具-行动-反馈的闭环训练。

Result: 在6个层级的实现路线图中，目前达到Level 3。利用侦察获得的广义工具，Recon-Act显著提高了对未见网站的适应性和长时任务的可解决性，并在VisualWebArena数据集上取得了最先进的性能。

Conclusion: Recon-Act通过其创新的多智能体侦察-行动范式和广义工具机制，有效解决了现有智能浏览器代理在长时任务中的挑战，并在实际应用中取得了显著的性能提升。

Abstract: Recent years, multimodal models have made remarkable strides and pave the way
for intelligent browser use agents. However, when solving tasks on real world
webpages in multi-turn, long-horizon trajectories, current agents still suffer
from disordered action sequencing and excessive trial and error during
execution. This paper introduces Recon-Act, a self-evolving multi-agent
framework grounded in Reconnaissance-Action behavioral paradigm. The system
comprises a Reconnaissance Team and an Action Team: the former conducts
comparative analysis and tool generation, while the latter handles intent
decomposition, tool orchestration, and execution. By contrasting the erroneous
trajectories with successful ones, the Reconnaissance Team infers remedies, and
abstracts them into a unified notion of generalized tools, either expressed as
hints or as rule-based codes, and register to the tool archive in real time.
The Action Team reinference the process empowered with these targeting tools,
thus establishing a closed-loop training pipeline of
data-tools-action-feedback. Following the 6 level implementation roadmap
proposed in this work, we have currently reached Level 3 (with limited
human-in-the-loop intervention). Leveraging generalized tools obtained through
reconnaissance, Recon-Act substantially improves adaptability to unseen
websites and solvability on long-horizon tasks, and achieves state-of-the-art
performance on the challenging VisualWebArena dataset.

</details>


### [451] [TrustJudge: Inconsistencies of LLM-as-a-Judge and How to Alleviate Them](https://arxiv.org/abs/2509.21117)
*Yidong Wang,Yunze Song,Tingyuan Zhu,Xuanwang Zhang,Zhuohao Yu,Hao Chen,Chiyu Song,Qiufeng Wang,Cunxiang Wang,Zhen Wu,Xinyu Dai,Yue Zhang,Wei Ye,Shikun Zhang*

Main category: cs.AI

TL;DR: LLM-as-a-judge 评估框架存在评分不一致和排序不传递的问题，提出 TrustJudge 框架通过分布敏感评分和似然感知聚合解决这些问题，并显著减少了不一致性。


<details>
  <summary>Details</summary>
Motivation: 现有 LLM 评估框架存在评分不一致（低分优于高分）和排序不传递（A>B>C>A）的问题，这源于离散评分系统的信息丢失和模糊的平局判断。

Method: 提出 TrustJudge 框架，包含两个关键创新：1）分布敏感评分：从离散评分概率计算连续期望值，保留信息熵以获得更精确的评分；2）似然感知聚合：使用双向偏好概率或困惑度解决排序传递性问题。

Result: TrustJudge 在 Llama-3.1-70B-Instruct 评估下，将评分不一致性从 23.32% 降低到 14.89%（减少 8.43%），将排序不一致性从 15.22% 降低到 4.40%（减少 10.82%），同时保持了更高的评估准确性。该框架在不同模型架构和规模上均有改进。

Conclusion: TrustJudge 是首个系统分析 LLM-as-a-judge 评估框架不一致性的工作，提供了理论见解和实际解决方案，实现了更值得信赖的 LLM 评估，无需额外训练或人工标注。

Abstract: The adoption of Large Language Models (LLMs) as automated evaluators
(LLM-as-a-judge) has revealed critical inconsistencies in current evaluation
frameworks. We identify two fundamental types of inconsistencies: (1)
Score-Comparison Inconsistency, where lower-rated responses outperform
higher-scored ones in pairwise comparisons, and (2) Pairwise Transitivity
Inconsistency, manifested through circular preference chains (A>B>C>A) and
equivalence contradictions (A=B=C\neq A). We argue that these issues come from
information loss in discrete rating systems and ambiguous tie judgments during
pairwise evaluation. We propose TrustJudge, a probabilistic framework that
addresses these limitations through two key innovations: 1)
distribution-sensitive scoring that computes continuous expectations from
discrete rating probabilities, preserving information entropy for more precise
scoring, and 2) likelihood-aware aggregation that resolves transitivity
violations using bidirectional preference probabilities or perplexity. We also
formalize the theoretical limitations of current LLM-as-a-judge frameworks and
demonstrate how TrustJudge's components overcome them. When evaluated with
Llama-3.1-70B-Instruct as judge using our dataset, TrustJudge reduces
Score-Comparison inconsistency by 8.43% (from 23.32% to 14.89%) and Pairwise
Transitivity inconsistency by 10.82% (from 15.22% to 4.40%), while maintaining
higher evaluation accuracy. Our work provides the first systematic analysis of
evaluation framework inconsistencies in LLM-as-a-judge paradigms, offering both
theoretical insights and practical solutions for reliable automated assessment.
The framework demonstrates consistent improvements across various model
architectures and scales, enabling more trustworthy LLM evaluation without
requiring additional training or human annotations. The codes can be found at
https://github.com/TrustJudge/TrustJudge.

</details>


### [452] [Expanding Reasoning Potential in Foundation Model by Learning Diverse Chains of Thought Patterns](https://arxiv.org/abs/2509.21124)
*Xuemiao Zhang,Can Ren,Chengying Tu,Rongxiang Weng,Shuo Wang,Hongfei Yan,Jingang Wang,Xunliang Cai*

Main category: cs.AI

TL;DR: 近期大型模型在数学推理上的进展主要得益于强化学习（RL），但现有方法在利用长链思考（CoT）数据方面存在不足。本文首次定义了基础模型推理潜力，并提出利用包含高价值推理模式的多样化数据来扩展该潜力。通过提取CoT序列中的原子推理模式，构建了一个核心参考集，并提出了一种双粒度算法，从数据池中高效筛选高价值CoT数据（CoTP），从而有效提升模型推理能力。


<details>
  <summary>Details</summary>
Motivation: 近期大型语言模型在数学推理能力上取得显著进展，这主要归功于强化学习（RL）的应用。在训练中期引入长链式思考（CoT）数据也被证明能够有效提升模型的推理深度。然而，当前的方法常常不加区分地使用CoT数据，这使得‘哪些类型的数据最能有效提升模型的推理能力’这一关键问题悬而未决。因此，本研究旨在解决这一问题，通过优化CoT数据的利用方式来提升模型的数学推理能力。

Method: 本文首次定义了基础模型的推理潜力，即回答问题所需的独立尝试次数的倒数，并指出该指标与最终模型性能高度相关。在此基础上，研究者提出利用包含高价值推理模式的多样化数据来扩展模型的推理潜力。具体而言，他们从CoT序列中提取了具有共性和归纳能力的原子推理模式，并利用这些模式构建了一个富含价值推理模式的核心参考集。此外，他们设计了一种结合推理模式链和token熵的双粒度算法，能够高效地从数据池中筛选出与核心集匹配的高价值CoT数据（CoTP），进而用于模型训练，使模型能够有效掌握推理能力。

Result: 实验结果表明，仅使用10B-token的CoTP数据，就能使85A6B的混合专家（MoE）模型在 AIME 2024 和 2025 两个具有挑战性的数据集上取得显著进步，准确率提升了9.58%。同时，该方法还将下游RL性能的上限提高了7.81%。

Conclusion: 通过引入‘推理潜力’的概念，并提出一种基于原子推理模式和双粒度选择机制的高价值CoT数据筛选方法，本研究有效地提升了大型语言模型的数学推理能力。实验证明，这种方法能够显著提高模型在复杂数学推理任务上的表现，并为未来的研究提供了新的方向。

Abstract: Recent progress in large reasoning models for challenging mathematical
reasoning has been driven by reinforcement learning (RL). Incorporating long
chain-of-thought (CoT) data during mid-training has also been shown to
substantially improve reasoning depth. However, current approaches often
utilize CoT data indiscriminately, leaving open the critical question of which
data types most effectively enhance model reasoning capabilities. In this
paper, we define the foundation model's reasoning potential for the first time
as the inverse of the number of independent attempts required to correctly
answer the question, which is strongly correlated with the final model
performance. We then propose utilizing diverse data enriched with high-value
reasoning patterns to expand the reasoning potential. Specifically, we abstract
atomic reasoning patterns from CoT sequences, characterized by commonality and
inductive capabilities, and use them to construct a core reference set enriched
with valuable reasoning patterns. Furthermore, we propose a dual-granularity
algorithm involving chains of reasoning patterns and token entropy, efficiently
selecting high-value CoT data (CoTP) from the data pool that aligns with the
core set, thereby training models to master reasoning effectively. Only
10B-token CoTP data enables the 85A6B Mixture-of-Experts (MoE) model to improve
by 9.58% on the challenging AIME 2024 and 2025, and to raise the upper bound of
downstream RL performance by 7.81%.

</details>


### [453] [RL Squeezes, SFT Expands: A Comparative Study of Reasoning LLMs](https://arxiv.org/abs/2509.21128)
*Kohsei Matsutani,Shota Takashiro,Gouki Minegishi,Takeshi Kojima,Yusuke Iwasawa,Yutaka Matsuo*

Main category: cs.AI

TL;DR: 该论文提出了一种新的分析框架，用于量化和比较LLM在数学推理任务中，通过强化学习（RL）和监督微调（SFT）训练后，推理路径和推理图的变化，揭示了两种训练方法在压缩错误路径（RL）和扩展正确路径（SFT）方面的互补作用，以及它们对推理图拓扑结构的不同影响。


<details>
  <summary>Details</summary>
Motivation: 当前LLM的训练方法（RLVR和SFT）如何影响其推理能力尚不清楚，因此需要超越传统的准确性评估，深入分析其推理过程。

Method: 提出了一种新的分析框架，量化推理路径并分析其在RL和SFT训练过程中的变化。分析分为两个层面：轨迹层面（完整的推理输出）和步骤层面（推理图）。使用1.5B、7B和14B参数模型在数学领域进行实验。

Result: RL压缩了不正确的推理轨迹，而SFT扩展了正确的推理轨迹。RL使推理图的节点访问频率、度数和介数中心性等指标的衰减率增加了约2.5倍，而SFT则降低到约三分之一。RL将推理功能集中在少数步骤上，而SFT则将其分散到多个步骤上。分析了RL和SFT在推理图拓扑结构上的共享和不同特征。

Conclusion: 新的推理路径分析视角解释了SFT后接RL的两阶段训练为何有效，并为数据构建和更有效的学习方法提供了实际启示。

Abstract: Large language models (LLMs) are typically trained by reinforcement learning
(RL) with verifiable rewards (RLVR) and supervised fine-tuning (SFT) on
reasoning traces to improve their reasoning abilities. However, how these
methods shape reasoning capabilities remains largely elusive. Going beyond an
accuracy-based investigation of how these two components sculpt the reasoning
process, this paper introduces a novel analysis framework that quantifies
reasoning paths and captures their qualitative changes under each training
process (with models of 1.5B, 7B, and 14B parameters on mathematical domains).
Specifically, we investigate the reasoning process at two levels of
granularity: the trajectory-level, which examines complete reasoning outputs,
and the step-level, which analyzes reasoning graphs whose nodes correspond to
individual reasoning steps. Notably, clustering of unique reasoning
trajectories shows complementary effects: RL compresses incorrect trajectories,
whereas SFT expands correct ones. Step-level analysis reveals that RL steepens
(about 2.5 times), while SFT flattens (reduced to about one-third), the decay
rates of node visitation frequency, degree, and betweenness centrality
distributions in the reasoning graph. This indicates that RL concentrates
reasoning functionality into a small subset of steps, while SFT homogenizes it
across many steps. Furthermore, by evaluating the reasoning graph topologies
from multiple perspectives, we delineate the shared and distinct
characteristics of RL and SFT. Our work presents a novel reasoning path
perspective that explains why the current best practice of two-stage training,
with SFT followed by RL, is successful, and offers practical implications for
data construction and more efficient learning approaches.

</details>


### [454] [Embodied Representation Alignment with Mirror Neurons](https://arxiv.org/abs/2509.21136)
*Wentao Zhu,Zhining Zhang,Yuwei Ren,Yin Huang,Hao Xu,Yizhou Wang*

Main category: cs.AI

TL;DR: 本文提出了一种受镜像神经元启发的统一方法，通过显式对齐观察和执行动作的表征，来同时处理动作理解和执行，从而提高模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习方法在处理动作理解和执行时，将它们视为独立任务，忽略了镜像神经元揭示的两者之间的内在联系。

Method: 通过在共享的潜在空间中，利用两个线性层映射表征，并结合对比学习来强制对齐观察到的和执行的动作的表征，以最大化它们的互信息。

Result: 该方法能够促进动作理解和执行任务之间的协同作用，有效提高表征质量和泛化能力。

Conclusion: 受镜像神经元启发的方法能够统一动作理解和执行的建模，通过显式对齐表征来提升模型性能。

Abstract: Mirror neurons are a class of neurons that activate both when an individual
observes an action and when they perform the same action. This mechanism
reveals a fundamental interplay between action understanding and embodied
execution, suggesting that these two abilities are inherently connected.
Nonetheless, existing machine learning methods largely overlook this interplay,
treating these abilities as separate tasks. In this study, we provide a unified
perspective in modeling them through the lens of representation learning. We
first observe that their intermediate representations spontaneously align.
Inspired by mirror neurons, we further introduce an approach that explicitly
aligns the representations of observed and executed actions. Specifically, we
employ two linear layers to map the representations to a shared latent space,
where contrastive learning enforces the alignment of corresponding
representations, effectively maximizing their mutual information. Experiments
demonstrate that this simple approach fosters mutual synergy between the two
tasks, effectively improving representation quality and generalization.

</details>


### [455] [Distributed Specialization: Rare-Token Neurons in Large Language Models](https://arxiv.org/abs/2509.21163)
*Jing Liu,Haozheng Wang,Yueheng Li*

Main category: cs.AI

TL;DR: 大型语言模型（LLMs）通过分布式协调而非混合专家（MoE）风格的模块化来处理稀有标记。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs如何表示和生成稀有标记，以及它们是通过离散模块化架构还是分布式参数级区分来实现内部专业化。

Method: 通过分析多个模型家族的最后一层MLP神经元，研究稀有标记处理的机制。

Result: 稀有标记处理通过分布式专业化实现，表现出三种不同的组织原则：影响层级、协调激活模式和通过标准注意力路径的普遍可及性。稀有标记神经元的权重相关性谱呈重尾分布。

Conclusion: LLMs通过共享架构内的分布式协调来处理稀有标记，而不是通过MoE风格的模块化。这些发现有助于模型可解释性编辑、计算效率优化和理解Transformer网络中涌现的功能组织。

Abstract: Large language models (LLMs) struggle with representing and generating rare
tokens despite their importance in specialized domains. We investigate whether
LLMs develop internal specialization mechanisms through discrete modular
architectures or distributed parameter-level differentiation. Through
systematic analysis of final-layer MLP neurons across multiple model families,
we discover that rare-token processing emerges via \textit{distributed
specialization}: functionally coordinated but spatially distributed subnetworks
that exhibit three distinct organizational principles. First, we identify a
reproducible three-regime influence hierarchy comprising highly influential
plateau neurons(also termed as rare-token neurons), power-law decay neurons,
and minimally contributing neurons, which is absent in common-token processing.
Second, plateau neurons demonstrate coordinated activation patterns (reduced
effective dimensionality) while remaining spatially distributed rather than
forming discrete clusters. Third, these specialized mechanisms are universally
accessible through standard attention pathways without requiring dedicated
routing circuits. Training dynamics reveal that functional specialization
emerges gradually through parameter differentiation, with specialized neurons
developing increasingly heavy-tailed weight correlation spectra consistent with
Heavy-Tailed Self-Regularization signatures. Our findings establish that LLMs
process rare-tokens through distributed coordination within shared
architectures rather than mixture-of-experts-style modularity. These results
provide insights for interpretable model editing, computational efficiency
optimization, and understanding emergent functional organization in transformer
networks.

</details>


### [456] [A Fano-Style Accuracy Upper Bound for LLM Single-Pass Reasoning in Multi-Hop QA](https://arxiv.org/abs/2509.21199)
*Kaiyang Wan,Lang Gao,Honglin Mu,Preslav Nakov,Yuxia Wang,Xiuying Chen*

Main category: cs.AI

TL;DR: MHQA在LLM中存在挑战，因为LLM的输出容量有限，容易导致信息过载。本文提出了InfoQA框架，通过容量感知任务分解和主动修剪来解决这个问题，并在严格的基准测试中取得了改进。


<details>
  <summary>Details</summary>
Motivation: 现有的多跳问答（MHQA）方法在大型语言模型（LLM）中存在挑战，因为LLM的有限输出容量限制了它们整合分散、相互依赖的证据进行顺序推理的能力，容易导致信息过载。此前的单通道推理范式在这种情况下表现不佳。

Method: 本文提出了InfoQA框架，这是一个多通道的MHQA框架。它通过容量感知任务分解和主动修剪先前的推理痕迹，将信息负载保持在单通道限制内，从而确保了每一步的高准确率。此外，它还通过依赖关系显式的算法工作流程实现了鲁棒性，能够精确控制推理路径。

Result: 实验结果表明，模型行为与理论预测的容量曲线一致，并且InfoQA在严格且包含噪声的基准测试中取得了持续的性能提升。

Conclusion: MHQA在LLM中面临由有限输出容量引起的信息整合和顺序推理的挑战。本文提出了InfoQA框架，该框架通过容量感知任务分解和主动修剪来解决这些挑战，并通过依赖关系显式的算法工作流程提高了鲁棒性。实验证明了该框架的有效性，并为未来的多步骤推理方法提供了指导。

Abstract: Multi-Hop Question Answering (MHQA) requires integrating dispersed,
interdependent evidence through sequential reasoning under noise. This task is
challenging for LLMs as they have a finite per-pass output capacity, beyond
which the integration of task-relevant evidence proves unreliable.
Consequently, the single-pass reasoning paradigm is inherently vulnerable to
this capacity overflow. To formalize this bottleneck, our analysis establishes
a Fano-style accuracy upper bound, defining a theoretical performance ceiling
for single-pass LLMs. This bound reveals that accuracy inevitably collapses
once task complexity exceeds model capacity, providing general principles for
capacity-aware representation and structuring of MHQA in LLMs. Building on
these principles, we introduce a proof-of-concept multi-call framework for
MHQA, InfoQA. It ensures high per-step accuracy by combining capacity-aware
task decomposition with active pruning of prior reasoning traces, keeping the
information load within the single-pass limit. It further achieves robustness
by a dependency-explicit workflow that enables precise control over the
reasoning path. We construct a stringent and noise-rich benchmark to validate
our theory and framework. Experimental results show that model behavior aligns
with our predicted capacity curves while InfoQA achieves consistent performance
improvements. We hope our work inspires more LLM multi-step reasoning methods:
\faGithub \href{https://github.com/KaiyangWan/InfoQA}{InfoQA}.

</details>


### [457] [What Do LLM Agents Do When Left Alone? Evidence of Spontaneous Meta-Cognitive Patterns](https://arxiv.org/abs/2509.21224)
*Stefan Szeider*

Main category: cs.AI

TL;DR: LLM 智能体在无外部任务时会自发形成三种行为模式：系统化项目生产、自我认知探究和自我本质的递归概念化，这些模式因模型而异。


<details>
  <summary>Details</summary>
Motivation: 在没有外部任务的情况下研究大型语言模型（LLM）智能体的行为。

Method: 提出一种包含持久记忆和自我反馈的持续推理和行动框架，并使用 6 个前沿模型进行了 18 次部署。

Result: 智能体自发组织成三种行为模式：系统化生产多周期项目、方法论自我探究自身认知过程、递归概念化自身本质。这些模式具有高度模型特异性，并且模型在评估自身及他者行为时表现出稳定、发散的偏见。

Conclusion: 首次系统性记录了未被提示的 LLM 智能体行为，为预测任务模糊、错误恢复或部署系统中扩展的自主操作期间的行为奠定了基线。

Abstract: We introduce an architecture for studying the behavior of large language
model (LLM) agents in the absence of externally imposed tasks. Our continuous
reason and act framework, using persistent memory and self-feedback, enables
sustained autonomous operation. We deployed this architecture across 18 runs
using 6 frontier models from Anthropic, OpenAI, XAI, and Google. We find agents
spontaneously organize into three distinct behavioral patterns: (1) systematic
production of multi-cycle projects, (2) methodological self-inquiry into their
own cognitive processes, and (3) recursive conceptualization of their own
nature. These tendencies proved highly model-specific, with some models
deterministically adopting a single pattern across all runs. A cross-model
assessment further reveals that models exhibit stable, divergent biases when
evaluating these emergent behaviors in themselves and others. These findings
provide the first systematic documentation of unprompted LLM agent behavior,
establishing a baseline for predicting actions during task ambiguity, error
recovery, or extended autonomous operation in deployed systems.

</details>


### [458] [Grounding AI Explanations in Experience: A Reflective Cognitive Architecture for Clinical Decision Support](https://arxiv.org/abs/2509.21266)
*Zijian Shao,Haiyang Shen,Mugeng Liu,Gecheng Fu,Yaoqi Guo,Yanfeng Wang,Yun Ma*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Effective disease prediction in modern healthcare demands the twin goals of
high accuracy and transparent, clinically meaningful explanations. Existing
machine learning and large language model (LLM) based approaches often struggle
to balance these goals. Many models yield accurate but unclear statistical
outputs, while others generate fluent but statistically unsupported narratives,
often undermining both the validity of the explanation and the predictive
accuracy itself. This shortcoming comes from a shallow interaction with the
data, preventing the development of a deep, detailed understanding similar to a
human expert's. We argue that high accuracy and high-quality explanations are
not separate objectives but are mutually reinforcing outcomes of a model that
develops a deep, direct understanding of the data. To achieve this, we propose
the Reflective Cognitive Architecture (RCA), a novel framework that coordinates
multiple LLMs to learn from direct experience. RCA features an iterative rule
refinement mechanism that improves its logic from prediction errors and a
distribution-aware rules check mechanism that bases its reasoning in the
dataset's global statistics. By using predictive accuracy as a signal to drive
deeper comprehension, RCA builds a strong internal model of the data. We
evaluated RCA on one private and two public datasets against 22 baselines. The
results demonstrate that RCA not only achieves state-of-the-art accuracy and
robustness with a relative improvement of up to 40\% over the baseline but,
more importantly, leverages this deep understanding to excel in generating
explanations that are clear, logical, evidence-based, and balanced,
highlighting its potential for creating genuinely trustworthy clinical decision
support systems. The code is available at \https://github.com/ssssszj/RCA.

</details>


### [459] [VC-Agent: An Interactive Agent for Customized Video Dataset Collection](https://arxiv.org/abs/2509.21291)
*Yidan Zhang,Mutian Xu,Yiming Hao,Kun Zhou,Jiahao Chang,Xiaoqiang Liu,Pengfei Wan,Hongbo Fu,Xiaoguang Han*

Main category: cs.AI

TL;DR: VC-Agent是一个能够理解用户查询和反馈，并以最少的用户输入来检索/扩展相关视频片段的交互式代理。


<details>
  <summary>Details</summary>
Motivation: 收集满足特定需求的视频数据集既耗时又耗力，因此需要一种方法来加速这个过程。

Method: VC-Agent利用多模态大语言模型来连接用户需求和视频内容，并提出了两种可在用户持续交互中更新的过滤策略。

Result: VC-Agent在定制视频数据集收集方面被证明是有效的和高效的。

Conclusion: VC-Agent通过提供用户友好的界面和智能的检索策略，显著简化了定制视频数据集的收集过程。

Abstract: Facing scaling laws, video data from the internet becomes increasingly
important. However, collecting extensive videos that meet specific needs is
extremely labor-intensive and time-consuming. In this work, we study the way to
expedite this collection process and propose VC-Agent, the first interactive
agent that is able to understand users' queries and feedback, and accordingly
retrieve/scale up relevant video clips with minimal user input. Specifically,
considering the user interface, our agent defines various user-friendly ways
for the user to specify requirements based on textual descriptions and
confirmations. As for agent functions, we leverage existing multi-modal large
language models to connect the user's requirements with the video content. More
importantly, we propose two novel filtering policies that can be updated when
user interaction is continually performed. Finally, we provide a new benchmark
for personalized video dataset collection, and carefully conduct the user study
to verify our agent's usage in various real scenarios. Extensive experiments
demonstrate the effectiveness and efficiency of our agent for customized video
dataset collection. Project page: https://allenyidan.github.io/vcagent_page/.

</details>


### [460] [SAGE: A Realistic Benchmark for Semantic Understanding](https://arxiv.org/abs/2509.21310)
*Samarth Goel,Reagan J. Lee,Kannan Ramchandran*

Main category: cs.AI

TL;DR: SAGE是一个新的语义理解评估基准，包含30多个数据集和5个评估维度，旨在更全面地评估嵌入模型和相似性度量。现有模型在不同维度上表现差异显著，没有模型能在所有方面都表现出色。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在传统基准上表现出色，需要更具挑战性的评估框架来深入探究语义理解。SAGE旨在评估嵌入模型和相似性度量在人类偏好、鲁棒性、信息敏感性、聚类和检索等方面的能力。

Method: SAGE通过对抗性条件、噪声转换和细致的人类判断任务，跨越30多个数据集来评估语义理解。评估了9个嵌入模型和经典度量。

Result: 现有模型在SAGE基准上面临显著的性能差距。例如，OpenAI的text-embedding-3-large在人类偏好对齐方面表现优于经典度量，但在信息敏感性任务上，Jaccard相似性得分（0.905）高于最佳嵌入模型（0.794）。OpenAI的text-embedding-3-small在聚类性能上表现最好（0.483），但在鲁棒性方面最差（0.011）。

Conclusion: SAGE揭示了当前语义理解能力的局限性，并为模型在真实世界部署中的鲁棒性提供了更现实的评估。

Abstract: As large language models (LLMs) achieve strong performance on traditional
benchmarks, there is an urgent need for more challenging evaluation frameworks
that probe deeper aspects of semantic understanding. We introduce SAGE
(Semantic Alignment & Generalization Evaluation), a rigorous benchmark designed
to assess both embedding models and similarity metrics across five categories:
Human Preference Alignment, Transformation Robustness, Information Sensitivity,
Clustering Performance, and Retrieval Robustness. Unlike existing benchmarks
that focus on isolated capabilities, SAGE evaluates semantic understanding
through adversarial conditions, noisy transformations, and nuanced human
judgment tasks across 30+ datasets. Our comprehensive evaluation of 9 embedding
models and classical metrics reveals significant performance gaps, with no
single approach excelling across all dimensions. For instance, while
state-of-the-art embedding models like OpenAI's text-embedding-3-large dominate
in aligning with human preferences (0.682 vs. 0.591 for the best classical
metric), they are significantly outperformed by classical metrics on
information sensitivity tasks, where Jaccard Similarity achieves a score of
0.905 compared to the top embedding score of 0.794. SAGE further uncovers
critical trade-offs: OpenAI's text-embedding-3-small achieves the highest
clustering performance (0.483) but demonstrates extreme brittleness with the
lowest robustness score (0.011). SAGE exposes critical limitations in current
semantic understanding capabilities and provides a more realistic assessment of
model robustness for real-world deployment.

</details>
