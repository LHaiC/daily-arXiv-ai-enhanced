<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 77]
- [cs.CL](#cs.CL) [Total: 90]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 14]
- [cs.DS](#cs.DS) [Total: 4]
- [cs.GT](#cs.GT) [Total: 5]
- [cs.AI](#cs.AI) [Total: 51]
- [cs.MA](#cs.MA) [Total: 2]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 14]
- [cs.RO](#cs.RO) [Total: 41]
- [cs.NE](#cs.NE) [Total: 2]
- [eess.SP](#eess.SP) [Total: 20]
- [cs.LO](#cs.LO) [Total: 1]
- [cs.GR](#cs.GR) [Total: 5]
- [cs.AR](#cs.AR) [Total: 2]
- [cs.SI](#cs.SI) [Total: 1]
- [cs.ET](#cs.ET) [Total: 1]
- [quant-ph](#quant-ph) [Total: 51]
- [eess.SY](#eess.SY) [Total: 17]
- [physics.app-ph](#physics.app-ph) [Total: 2]
- [cs.DC](#cs.DC) [Total: 6]
- [cs.LG](#cs.LG) [Total: 146]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [LVTINO: LAtent Video consisTency INverse sOlver for High Definition Video Restoration](https://arxiv.org/abs/2510.01339)
*Alessio Spagnoletti,Andrés Almansa,Marcelo Pereyra*

Main category: cs.CV

TL;DR: 视频修复面临时域一致性的挑战，LVTINO利用视频一致性模型（VCMs）实现高质量、时域一致的视频修复。


<details>
  <summary>Details</summary>
Motivation: 现有的基于图像的生成模型在视频修复任务中存在时域不一致的问题，难以捕捉精细的空间细节和细微的 temporal 依赖性。

Method: 提出LVTINO，首个使用VCMs作为先验的即插即用视频修复模型，通过新的条件机制，在少量函数评估下实现高测量一致性和平滑的 temporal 转换。

Result: 在多种视频逆问题实验中，LVTINO显著优于现有逐帧处理的图像LDM方法，在重建保真度和计算效率方面均达到新的基准。

Conclusion: LVTINO是首个用于高清视频修复的、基于VCMs的即插即用逆向求解器，有效解决了时域一致性问题，并在重建质量和效率上取得了显著进展。

Abstract: Computational imaging methods increasingly rely on powerful generative
diffusion models to tackle challenging image restoration tasks. In particular,
state-of-the-art zero-shot image inverse solvers leverage distilled
text-to-image latent diffusion models (LDMs) to achieve unprecedented accuracy
and perceptual quality with high computational efficiency. However, extending
these advances to high-definition video restoration remains a significant
challenge, due to the need to recover fine spatial detail while capturing
subtle temporal dependencies. Consequently, methods that naively apply
image-based LDM priors on a frame-by-frame basis often result in temporally
inconsistent reconstructions. We address this challenge by leveraging recent
advances in Video Consistency Models (VCMs), which distill video latent
diffusion models into fast generators that explicitly capture temporal
causality. Building on this foundation, we propose LVTINO, the first zero-shot
or plug-and-play inverse solver for high definition video restoration with
priors encoded by VCMs. Our conditioning mechanism bypasses the need for
automatic differentiation and achieves state-of-the-art video reconstruction
quality with only a few neural function evaluations, while ensuring strong
measurement consistency and smooth temporal transitions across frames.
Extensive experiments on a diverse set of video inverse problems show
significant perceptual improvements over current state-of-the-art methods that
apply image LDMs frame by frame, establishing a new benchmark in both
reconstruction fidelity and computational efficiency.

</details>


### [2] [Image Generation Based on Image Style Extraction](https://arxiv.org/abs/2510.01347)
*Shuochen Chang*

Main category: cs.CV

TL;DR: 提出了一种基于文本生成图像的方法，利用风格编码器和风格投影层从参考图像中提取细粒度风格表示，并将其与文本表示对齐，以实现细粒度的风格化图像生成。


<details>
  <summary>Details</summary>
Motivation: 文本到图像生成模型在细粒度风格控制方面存在不足，自然语言难以精确描述，且风格化参考图像的引导信息难以与传统文本引导生成对齐。

Method: 提出了一种三阶段的训练风格提取-图像生成方法，包括风格编码器和风格投影层，用于提取和对齐风格表示与文本表示。

Result: 实现了细粒度的、基于文本提示的风格引导生成。

Conclusion: 该方法有效地利用了预训练的生成模型能力，通过从参考图像中提取的细粒度风格表示，实现了对生成图像的精细风格控制。

Abstract: Image generation based on text-to-image generation models is a task with
practical application scenarios that fine-grained styles cannot be precisely
described and controlled in natural language, while the guidance information of
stylized reference images is difficult to be directly aligned with the textual
conditions of traditional textual guidance generation. This study focuses on
how to maximize the generative capability of the pretrained generative model,
by obtaining fine-grained stylistic representations from a single given
stylistic reference image, and injecting the stylistic representations into the
generative body without changing the structural framework of the downstream
generative model, so as to achieve fine-grained controlled stylized image
generation. In this study, we propose a three-stage training style
extraction-based image generation method, which uses a style encoder and a
style projection layer to align the style representations with the textual
representations to realize fine-grained textual cue-based style guide
generation. In addition, this study constructs the Style30k-captions dataset,
whose samples contain a triad of images, style labels, and text descriptions,
to train the style encoder and style projection layer in this experiment.

</details>


### [3] [EvoStruggle: A Dataset Capturing the Evolution of Struggle across Activities and Skill Levels](https://arxiv.org/abs/2510.01362)
*Shijia Feng,Michael Wray,Walterio Mayol-Cuevas*

Main category: cs.CV

TL;DR: 本研究通过收集包含18个任务、超过61小时的视频数据，构建了一个关注学习过程中挣扎行为演变的数据集，并将其定义为时间动作定位问题，实验证明该方法能够泛化到未见过但相关的任务中。


<details>
  <summary>Details</summary>
Motivation: 学习新技能时，识别学习者的挣扎是优化学习和开发辅助系统的关键，但现有数据集缺乏对挣扎随时间演变情况的关注。

Method: 将挣扎识别定义为时间动作定位问题，并利用现有模型进行实验，以确定挣扎是否为跨任务可转移的概念。

Result: 所提出的方法在跨任务泛化测试中取得了34.56%的平均mAP，在跨活动泛化测试中取得了19.24%的平均mAP，表明挣扎是可转移的概念，但仍有改进空间。

Conclusion: 研究表明，利用时间动作定位模型可以成功检测挣扎线索，即使在未见过但相关的任务上也能进行泛化，但挣扎检测仍面临挑战。

Abstract: The ability to determine when a person struggles during skill acquisition is
crucial for both optimizing human learning and enabling the development of
effective assistive systems. As skills develop, the type and frequency of
struggles tend to change, and understanding this evolution is key to
determining the user's current stage of learning. However, existing
manipulation datasets have not focused on how struggle evolves over time. In
this work, we collect a dataset for struggle determination, featuring 61.68
hours of video recordings, 2,793 videos, and 5,385 annotated temporal struggle
segments collected from 76 participants. The dataset includes 18 tasks grouped
into four diverse activities -- tying knots, origami, tangram puzzles, and
shuffling cards, representing different task variations. In addition,
participants repeated the same task five times to capture their evolution of
skill. We define the struggle determination problem as a temporal action
localization task, focusing on identifying and precisely localizing struggle
segments with start and end times. Experimental results show that Temporal
Action Localization models can successfully learn to detect struggle cues, even
when evaluated on unseen tasks or activities. The models attain an overall
average mAP of 34.56% when generalizing across tasks and 19.24% across
activities, indicating that struggle is a transferable concept across various
skill-based tasks while still posing challenges for further improvement in
struggle detection. Our dataset is available at
https://github.com/FELIXFENG2019/EvoStruggle.

</details>


### [4] [SPUS: A Lightweight and Parameter-Efficient Foundation Model for PDEs](https://arxiv.org/abs/2510.01370)
*Abu Bucker Siddik,Diane Oyen,Alexander Most,Michal Kucer,Ayan Biswas*

Main category: cs.CV

TL;DR: SPUS是一个基于轻量级残差U-Net的紧凑型基础模型，用于求解多种偏微分方程（PDE），在少参数和少微调数据情况下实现了最先进的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有偏微分方程基础模型通常基于复杂的大型Transformer架构，计算和参数开销高，而SPUS旨在提供一个计算高效且参数量小的替代方案。

Method: SPUS采用轻量级残差U-Net架构，并结合了简单而强大的自回归预训练策略，以模拟数值求解器的行为来学习物理规律。

Result: SPUS在多种流体动力学偏微分方程上进行了预训练，并在6个具有挑战性的、未见过且涵盖多种物理系统的下游偏微分方程上进行了评估，取得了最先进的泛化能力，同时参数量显著减少，所需微调数据也最少。

Conclusion: SPUS展示了其作为一种高效参数的基础模型在求解多样化偏微分方程系统方面的潜力。

Abstract: We introduce Small PDE U-Net Solver (SPUS), a compact and efficient
foundation model (FM) designed as a unified neural operator for solving a wide
range of partial differential equations (PDEs). Unlike existing
state-of-the-art PDE FMs-primarily based on large complex transformer
architectures with high computational and parameter overhead-SPUS leverages a
lightweight residual U-Net-based architecture that has been largely
underexplored as a foundation model architecture in this domain. To enable
effective learning in this minimalist framework, we utilize a simple yet
powerful auto-regressive pretraining strategy which closely replicates the
behavior of numerical solvers to learn the underlying physics. SPUS is
pretrained on a diverse set of fluid dynamics PDEs and evaluated across 6
challenging unseen downstream PDEs spanning various physical systems.
Experimental results demonstrate that SPUS using residual U-Net based
architecture achieves state-of-the-art generalization on these downstream tasks
while requiring significantly fewer parameters and minimal fine-tuning data,
highlighting its potential as a highly parameter-efficient FM for solving
diverse PDE systems.

</details>


### [5] [DisCo: Reinforcement with Diversity Constraints for Multi-Human Generation](https://arxiv.org/abs/2510.01399)
*Shubhankar Borse,Farzad Farhadzadeh,Munawar Hayat,Fatih Porikli*

Main category: cs.CV

TL;DR: DisCo是一个基于强化学习的框架，通过优化身份多样性来解决文本到图像模型在生成多人图像时出现的身份混乱问题，并在DiverseHumans测试集上取得了领先的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像模型在生成多人图像时存在重复脸部、混合身份和计数错误等问题，未能有效处理多人物提示。

Method: DisCo通过组-相对策略优化（GRPO）微调流匹配模型，采用包括惩罚面部相似性、避免身份重复、强制人数准确以及通过人类偏好评分维持视觉保真度在内的组合奖励。通过单阶段课程学习来稳定训练。

Result: 在DiverseHumans测试集上，DisCo实现了98.6%的唯一人脸准确率和近乎完美的全局身份分布，超越了现有开源和专有模型，同时保持了可比的感知质量。

Conclusion: DisCo提供了一个可扩展、无需额外标注的解决方案，解决了生成模型中长期存在的身份问题，并为组合式多人物生成设定了新的基准。

Abstract: State-of-the-art text-to-image models excel at realism but collapse on
multi-human prompts - duplicating faces, merging identities, and miscounting
individuals. We introduce DisCo (Reinforcement with Diversity Constraints), the
first RL-based framework to directly optimize identity diversity in multi-human
generation. DisCo fine-tunes flow-matching models via Group-Relative Policy
Optimization (GRPO) with a compositional reward that (i) penalizes intra-image
facial similarity, (ii) discourages cross-sample identity repetition, (iii)
enforces accurate person counts, and (iv) preserves visual fidelity through
human preference scores. A single-stage curriculum stabilizes training as
complexity scales, requiring no extra annotations. On the DiverseHumans
Testset, DisCo achieves 98.6 Unique Face Accuracy and near-perfect Global
Identity Spread - surpassing both open-source and proprietary methods (e.g.,
Gemini, GPT-Image) while maintaining competitive perceptual quality. Our
results establish DisCo as a scalable, annotation-free solution that resolves
the long-standing identity crisis in generative models and sets a new benchmark
for compositional multi-human generation.

</details>


### [6] [GeoSURGE: Geo-localization using Semantic Fusion with Hierarchy of Geographic Embeddings](https://arxiv.org/abs/2510.01448)
*Angel Daruna,Nicholas Meegan,Han-Pang Chiu,Supun Samarasekera,Rakesh Kumar*

Main category: cs.CV

TL;DR: 通过对齐查询图像的视觉表示和学习到的地理表示，提出了一种新的地理表示方法，并将查询图像的外观特征与其语义分割图进行融合，以提高视觉地理定位的性能。


<details>
  <summary>Details</summary>
Motivation: 视觉地理定位（仅使用图像的视觉内容确定其地理位置）是一个活跃的研究领域，尽管已经取得了很大进展，但仍有提升空间。

Method: 提出了一种新的地理表示方法，该方法将世界显式地建模为地理嵌入的层次结构。此外，还提出了一种有效融合查询图像的外观特征及其语义分割图的方法，以形成鲁棒的视觉表示。

Result: 在五个基准数据集的22项指标中，我们方法的表现优于以往的SOTA方法和最新的LVLMs，取得了当前最佳的成绩。

Conclusion: 实验表明，地理表示和视觉表示的结合是提高视觉地理定位性能的主要驱动力。

Abstract: Worldwide visual geo-localization seeks to determine the geographic location
of an image anywhere on Earth using only its visual content. Learned
representations of geography for visual geo-localization remain an active
research topic despite much progress. We formulate geo-localization as aligning
the visual representation of the query image with a learned geographic
representation. Our novel geographic representation explicitly models the world
as a hierarchy of geographic embeddings. Additionally, we introduce an approach
to efficiently fuse the appearance features of the query image with its
semantic segmentation map, forming a robust visual representation. Our main
experiments demonstrate improved all-time bests in 22 out of 25 metrics
measured across five benchmark datasets compared to prior state-of-the-art
(SOTA) methods and recent Large Vision-Language Models (LVLMs). Additional
ablation studies support the claim that these gains are primarily driven by the
combination of geographic and visual representations.

</details>


### [7] [Data Selection for Fine-tuning Vision Language Models via Cross Modal Alignment Trajectories](https://arxiv.org/abs/2510.01454)
*Nilay Naharas,Dang Nguyen,Nesihan Bulut,Mohammadhossein Bateni,Vahab Mirrokni,Baharan Mirzasoleiman*

Main category: cs.CV

TL;DR: 该研究提出了XMAS，一种用于大规模视觉语言模型（LVLM）的无损数据高效指令调优方法，通过聚类分析交叉模态注意力矩阵来识别和去除冗余数据，显著减少训练数据量并加速训练过程，同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有数据选择方法在处理大规模视觉语言模型（LVLM）时效果不佳，无法有效去除冗余数据并提升训练效率，并且没有一种方法能超越随机选择的性能。

Method: 提出了一种基于交叉模态注意力矩阵相似性进行数据选择的方法（XMAS）。该方法通过计算微调代理LVLM过程中注意力矩阵的奇异值轨迹来聚类数据，并从每个簇中进行平衡采样，从而去除训练数据中的冗余。

Result: XMAS能够去除LLaVA-665k数据集的50%和Vision-Flan数据集的85%的数据，同时在10个下游基准测试中完全保留LLaVA-1.5-7B模型的性能，并将其训练速度提升了1.2倍。与现有最佳基线相比，在LLaVA-665k数据集上实现了30%的数据量削减。

Conclusion: XMAS是第一个被证明能有效进行LVLM数据高效指令调优的原则性方法，它通过分析注意力矩阵的内在结构来识别和去除冗余数据，实现了显著的数据缩减和训练加速，同时保持了模型的性能。

Abstract: Data-efficient learning aims to eliminate redundancy in large training
datasets by training models on smaller subsets of the most informative
examples. While data selection has been extensively explored for vision models
and large language models (LLMs), it remains underexplored for Large
Vision-Language Models (LVLMs). Notably, none of existing methods can
outperform random selection at different subset sizes. In this work, we propose
the first principled method for data-efficient instruction tuning of LVLMs. We
prove that examples with similar cross-modal attention matrices during
instruction tuning have similar gradients. Thus, they influence model
parameters in a similar manner and convey the same information to the model
during training. Building on this insight, we propose XMAS, which clusters
examples based on the trajectories of the top singular values of their
attention matrices obtained from fine-tuning a small proxy LVLM. By sampling a
balanced subset from these clusters, XMAS effectively removes redundancy in
large-scale LVLM training data. Extensive experiments show that XMAS can
discard 50% of the LLaVA-665k dataset and 85% of the Vision-Flan dataset while
fully preserving performance of LLaVA-1.5-7B on 10 downstream benchmarks and
speeding up its training by 1.2x. This is 30% more data reduction compared to
the best baseline for LLaVA-665k. The project's website can be found at
https://bigml-cs-ucla.github.io/XMAS-project-page/.

</details>


### [8] [Purrception: Variational Flow Matching for Vector-Quantized Image Generation](https://arxiv.org/abs/2510.01478)
*Răzvan-Andrei Matişan,Vincent Tao Hu,Grigory Bartosh,Björn Ommer,Cees G. M. Snoek,Max Welling,Jan-Willem van de Meent,Mohammad Mahdi Derakhshani,Floor Eijkelboom*

Main category: cs.CV

TL;DR: Purrception是一种结合了连续流匹配的几何感知能力和离散监督的分类方法的向量量化图像生成方法，在ImageNet-1k数据集上实现了更快的收敛速度和具有竞争力的FID分数。


<details>
  <summary>Details</summary>
Motivation: 需要一种能够明确进行类别监督同时保持连续传输动态的向量量化图像生成方法。

Method: Purrception将变分流匹配（VFM）应用于向量量化的潜在空间，通过学习码本索引上的分类后验概率，并在连续嵌入空间中计算速度场。

Result: Purrception在ImageNet-1k 256x256生成任务上，训练收敛速度快于连续流匹配和离散流匹配基线，FID分数与最先进的模型相当。

Conclusion: Purrception有效地结合了连续传输和离散监督，提高了图像生成的训练效率。

Abstract: We introduce Purrception, a variational flow matching approach for
vector-quantized image generation that provides explicit categorical
supervision while maintaining continuous transport dynamics. Our method adapts
Variational Flow Matching to vector-quantized latents by learning categorical
posteriors over codebook indices while computing velocity fields in the
continuous embedding space. This combines the geometric awareness of continuous
methods with the discrete supervision of categorical approaches, enabling
uncertainty quantification over plausible codes and temperature-controlled
generation. We evaluate Purrception on ImageNet-1k 256x256 generation. Training
converges faster than both continuous flow matching and discrete flow matching
baselines while achieving competitive FID scores with state-of-the-art models.
This demonstrates that Variational Flow Matching can effectively bridge
continuous transport and discrete supervision for improved training efficiency
in image generation.

</details>


### [9] [AortaDiff: A Unified Multitask Diffusion Framework For Contrast-Free AAA Imaging](https://arxiv.org/abs/2510.01498)
*Yuxuan Ou,Ning Bi,Jiazhen Pan,Jiancheng Yang,Boliang Yu,Usama Zidan,Regent Lee,Vicente Grau*

Main category: cs.CV

TL;DR: 提出了一种结合条件扩散模型和多任务学习的统一深度学习框架，用于从无对比增强CT（NCCT）生成腹主动脉瘤（AAA）的对比增强CT（CECT）图像，并同时分割主动脉腔和血栓，以减少造影剂使用。该方法通过端到端联合优化图像合成和解剖分割，并采用半监督学习策略处理临床数据中的缺失标签问题。


<details>
  <summary>Details</summary>
Motivation: 现有的从无对比增强CT（NCCT）生成对比增强CT（CECT）的深度学习方法通常采用多阶段流程，先生成图像再进行分割，易导致误差累积，且未能充分利用共享的语义和解剖结构信息。同时，造影剂的使用存在肾毒性、过敏和环境风险。

Method: 提出一个统一的深度学习框架，集成条件扩散模型（CDM）和多任务学习。该框架能够从NCCT扫描生成CECT图像，并同时分割主动脉腔和血栓。其特点包括：无需初始预测，跨任务共享编码器和解码器参数，以及采用半监督学习策略处理缺失的分割标签。

Result: 在264名患者的队列中进行了评估。图像合成方面，PSNR达到25.61 dB，优于单一任务CDM的23.80 dB。解剖分割方面，主动脉腔的Dice分数从0.87提升至0.89，血栓的Dice分数从0.48提升至0.53。临床测量精度方面，主动脉腔直径的平均绝对误差（MAE）从5.78 mm降至4.19 mm，血栓面积误差从41.45%降至33.85%。

Conclusion: 所提出的统一深度学习框架通过联合优化图像合成和解剖分割任务，在生成CECT图像和分割主动脉腔/血栓方面均优于现有方法，并提高了临床测量精度，为减少造影剂使用提供了有前景的解决方案。

Abstract: While contrast-enhanced CT (CECT) is standard for assessing abdominal aortic
aneurysms (AAA), the required iodinated contrast agents pose significant risks,
including nephrotoxicity, patient allergies, and environmental harm. To reduce
contrast agent use, recent deep learning methods have focused on generating
synthetic CECT from non-contrast CT (NCCT) scans. However, most adopt a
multi-stage pipeline that first generates images and then performs
segmentation, which leads to error accumulation and fails to leverage shared
semantic and anatomical structures. To address this, we propose a unified deep
learning framework that generates synthetic CECT images from NCCT scans while
simultaneously segmenting the aortic lumen and thrombus. Our approach
integrates conditional diffusion models (CDM) with multi-task learning,
enabling end-to-end joint optimization of image synthesis and anatomical
segmentation. Unlike previous multitask diffusion models, our approach requires
no initial predictions (e.g., a coarse segmentation mask), shares both encoder
and decoder parameters across tasks, and employs a semi-supervised training
strategy to learn from scans with missing segmentation labels, a common
constraint in real-world clinical data. We evaluated our method on a cohort of
264 patients, where it consistently outperformed state-of-the-art single-task
and multi-stage models. For image synthesis, our model achieved a PSNR of 25.61
dB, compared to 23.80 dB from a single-task CDM. For anatomical segmentation,
it improved the lumen Dice score to 0.89 from 0.87 and the challenging thrombus
Dice score to 0.53 from 0.48 (nnU-Net). These segmentation enhancements led to
more accurate clinical measurements, reducing the lumen diameter MAE to 4.19 mm
from 5.78 mm and the thrombus area error to 33.85% from 41.45% when compared to
nnU-Net. Code is available at https://github.com/yuxuanou623/AortaDiff.git.

</details>


### [10] [From Videos to Indexed Knowledge Graphs -- Framework to Marry Methods for Multimodal Content Analysis and Understanding](https://arxiv.org/abs/2510.01513)
*Basem Rizk,Joel Walsh,Mark Core,Benjamin Nye*

Main category: cs.CV

TL;DR: 该研究提出了一个用于多模态内容分析的框架，能够高效地构建和测试分析流程。


<details>
  <summary>Details</summary>
Motivation: 分析多模态内容（如视频）计算成本高、工程量大，现有基于预训练模型的方法难以处理复杂数据。

Method: 提出一个框架，通过组合预训练模型将视频转换为时间半结构化数据，并进一步转换为可查询的、支持持续学习的知识图谱表示。

Result: 该框架能够高效地进行多模态内容分析的流程原型设计，并将视频数据转化为易于查询和动态更新的知识图谱。

Conclusion: 该框架通过将视频转化为知识图谱，解决了多模态内容分析的挑战，并支持持续学习和动态知识整合。

Abstract: Analysis of multi-modal content can be tricky, computationally expensive, and
require a significant amount of engineering efforts. Lots of work with
pre-trained models on static data is out there, yet fusing these opensource
models and methods with complex data such as videos is relatively challenging.
In this paper, we present a framework that enables efficiently prototyping
pipelines for multi-modal content analysis. We craft a candidate recipe for a
pipeline, marrying a set of pre-trained models, to convert videos into a
temporal semi-structured data format. We translate this structure further to a
frame-level indexed knowledge graph representation that is query-able and
supports continual learning, enabling the dynamic incorporation of new
domain-specific knowledge through an interactive medium.

</details>


### [11] [WALT: Web Agents that Learn Tools](https://arxiv.org/abs/2510.01524)
*Viraj Prabhu,Yutong Dai,Matthew Fernandez,Jing Gu,Krithika Ramakrishnan,Yanqi Luo,Silvio Savarese,Caiming Xiong,Junnan Li,Zeyuan Chen,Ran Xu*

Main category: cs.CV

TL;DR: WALT框架通过将网站功能逆向工程为可调用的工具，实现了更强大、更通用的浏览器自动化。


<details>
  <summary>Details</summary>
Motivation: 现有Web代理方法在动态布局和长时程任务中表现脆弱，依赖于逐步的用户界面交互和大量的LLM推理。人类用户则通过搜索、过滤和排序等高层操作来利用网站功能。

Method: WALT框架将网站的潜在功能逆向工程为可重用的、可调用的工具，涵盖发现（搜索、过滤、排序）、通信（发布、评论、点赞）和内容管理（创建、编辑、删除）。这些工具抽象了底层执行细节，代理只需调用如search(query)或create(listing)等工具，而非进行逐步的推理。

Result: 在VisualWebArena和WebArena基准测试中，WALT实现了更高的成功率、更少的步骤和更少的LLM依赖推理。

Conclusion: WALT框架提供了一种强大且可泛化的浏览器自动化范式，将计算负担从脆弱的逐步推理转移到可靠的工具调用上。

Abstract: Web agents promise to automate complex browser tasks, but current methods
remain brittle -- relying on step-by-step UI interactions and heavy LLM
reasoning that break under dynamic layouts and long horizons. Humans, by
contrast, exploit website-provided functionality through high-level operations
like search, filter, and sort. We introduce WALT (Web Agents that Learn Tools),
a framework that reverse-engineers latent website functionality into reusable
invocable tools. Rather than hypothesizing ad-hoc skills, WALT exposes robust
implementations of automations already designed into websites -- spanning
discovery (search, filter, sort), communication (post, comment, upvote), and
content management (create, edit, delete). Tools abstract away low-level
execution: instead of reasoning about how to click and type, agents simply call
search(query) or create(listing). This shifts the computational burden from
fragile step-by-step reasoning to reliable tool invocation. On VisualWebArena
and WebArena, WALT achieves higher success with fewer steps and less
LLM-dependent reasoning, establishing a robust and generalizable paradigm for
browser automation.

</details>


### [12] [MATCH: Multi-faceted Adaptive Topo-Consistency for Semi-Supervised Histopathology Segmentation](https://arxiv.org/abs/2510.01532)
*Meilong Xu,Xiaoling Hu,Shahira Abousamra,Chen Li,Chao Chen*

Main category: cs.CV

TL;DR: 该研究提出了一种半监督分割框架，通过利用多个扰动预测来强制执行拓扑一致性，以解决病理图像分析中的密集对象分割问题，并引入了一种结合空间重叠和全局结构对齐的新型匹配策略来区分有意义的结构和噪声。


<details>
  <summary>Details</summary>
Motivation: 在半监督分割任务中，尤其是在细胞密集、难以区分语义结构的病理图像分析中，从无标签数据中捕获有意义的语义结构是一个关键挑战。现有方法难以鲁棒地识别和保留相关的拓扑特征。

Method: 提出了一种半监督分割框架，该框架利用随机丢弃和时间训练快照获得多个扰动预测，并强制执行拓扑一致性。引入了一种结合空间重叠和全局结构对齐的新型匹配策略来匹配不同预测中的拓扑特征。

Result: 实验结果表明，该方法有效减少了拓扑错误，提高了分割的鲁棒性和准确性，有利于下游分析。

Conclusion: 所提出的半监督分割框架通过强制拓扑一致性和新颖的匹配策略，能够鲁棒地识别和保留病理图像中的拓扑特征，从而实现更准确的分割。

Abstract: In semi-supervised segmentation, capturing meaningful semantic structures
from unlabeled data is essential. This is particularly challenging in
histopathology image analysis, where objects are densely distributed. To
address this issue, we propose a semi-supervised segmentation framework
designed to robustly identify and preserve relevant topological features. Our
method leverages multiple perturbed predictions obtained through stochastic
dropouts and temporal training snapshots, enforcing topological consistency
across these varied outputs. This consistency mechanism helps distinguish
biologically meaningful structures from transient and noisy artifacts. A key
challenge in this process is to accurately match the corresponding topological
features across the predictions in the absence of ground truth. To overcome
this, we introduce a novel matching strategy that integrates spatial overlap
with global structural alignment, minimizing discrepancies among predictions.
Extensive experiments demonstrate that our approach effectively reduces
topological errors, resulting in more robust and accurate segmentations
essential for reliable downstream analysis. Code is available at
\href{https://github.com/Melon-Xu/MATCH}{https://github.com/Melon-Xu/MATCH}.

</details>


### [13] [Towards Better Optimization For Listwise Preference in Diffusion Models](https://arxiv.org/abs/2510.01540)
*Jiamu Bai,Xin Yu,Meilong Xu,Weitao Lu,Xin Pan,Kiwan Maeng,Daniel Kifer,Jian Wang,Yu Wang*

Main category: cs.CV

TL;DR: 该研究提出了一种名为Diffusion-LPO的框架，用于优化扩散模型中的列表式偏好，并在文本到图像生成、图像编辑和个性化偏好对齐等任务中取得了优于成对偏好优化的结果。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要使用成对偏好进行优化，而忽略了人类反馈中隐含的列表式排序信息，这种信息能更精确地传达人类偏好。

Method: 提出Diffusion-LPO框架，将用户反馈聚合为图像排序列表，并在Plackett-Luce模型下推导出列表式偏好优化目标，强制要求每个样本比其所有排名较低的替代品更受青睐。

Result: 在文本到图像生成、图像编辑和个性化偏好对齐等任务中，Diffusion-LPO的性能优于成对DPO基线，在视觉质量和偏好对齐方面均表现出色。

Conclusion: Diffusion-LPO是一种简单有效的列表式偏好优化方法，能够充分利用列表式数据，在多个扩散模型任务中提升性能。

Abstract: Reinforcement learning from human feedback (RLHF) has proven effectiveness
for aligning text-to-image (T2I) diffusion models with human preferences.
Although Direct Preference Optimization (DPO) is widely adopted for its
computational efficiency and avoidance of explicit reward modeling, its
applications to diffusion models have primarily relied on pairwise preferences.
The precise optimization of listwise preferences remains largely unaddressed.
In practice, human feedback on image preferences often contains implicit ranked
information, which conveys more precise human preferences than pairwise
comparisons. In this work, we propose Diffusion-LPO, a simple and effective
framework for Listwise Preference Optimization in diffusion models with
listwise data. Given a caption, we aggregate user feedback into a ranked list
of images and derive a listwise extension of the DPO objective under the
Plackett-Luce model. Diffusion-LPO enforces consistency across the entire
ranking by encouraging each sample to be preferred over all of its lower-ranked
alternatives. We empirically demonstrate the effectiveness of Diffusion-LPO
across various tasks, including text-to-image generation, image editing, and
personalized preference alignment. Diffusion-LPO consistently outperforms
pairwise DPO baselines on visual quality and preference alignment.

</details>


### [14] [Growing Visual Generative Capacity for Pre-Trained MLLMs](https://arxiv.org/abs/2510.01546)
*Hanyu Wang,Jiaming Han,Ziyan Yang,Qi Zhao,Shanchuan Lin,Xiangyu Yue,Abhinav Shrivastava,Zhenheng Yang,Hao Chen*

Main category: cs.CV

TL;DR: Bridge是一个纯粹的自回归统一多模态大语言模型（MLLM），通过混合Transformer架构增强了预训练的视觉理解模型，实现了图像理解和生成。它使用一种语义到像素的离散表示，集成了紧凑的语义令牌和细粒度的像素令牌，以提高生成保真度，同时仅略微增加序列长度。Bridge在各种多模态基准测试中取得了有竞争力的或优越的结果，并且所需的训练数据和时间更少。


<details>
  <summary>Details</summary>
Motivation: 现有的统一MLLM在保持自回归范式、语义对齐和像素级保真度之间存在权衡。混合方法生成高质量图像但打破了自回归范式，而纯粹的自回归方法在语义对齐和像素级保真度之间存在冲突。

Method: Bridge采用纯粹的自回归方法，利用混合Transformer架构增强预训练的视觉理解模型，并引入一种语义到像素的离散表示（集成了紧凑的语义令牌和细粒度的像素令牌），以在单一的下一令牌预测框架内实现图像理解和生成。

Result: Bridge在各种多模态基准测试中取得了有竞争力的或优越的性能，并且与先前统一的MLLM相比，所需的训练数据更少，训练时间更短。

Conclusion: Bridge成功地构建了一个纯粹的自回归统一MLLM，它在保持自回归范式的前提下，通过创新的架构和表示方法，实现了高质量的图像理解和生成，并在效率方面表现出色。

Abstract: Multimodal large language models (MLLMs) extend the success of language
models to visual understanding, and recent efforts have sought to build unified
MLLMs that support both understanding and generation. However, constructing
such models remains challenging: hybrid approaches combine continuous
embeddings with diffusion or flow-based objectives, producing high-quality
images but breaking the autoregressive paradigm, while pure autoregressive
approaches unify text and image prediction over discrete visual tokens but
often face trade-offs between semantic alignment and pixel-level fidelity. In
this work, we present Bridge, a pure autoregressive unified MLLM that augments
pre-trained visual understanding models with generative ability through a
Mixture-of-Transformers architecture, enabling both image understanding and
generation within a single next-token prediction framework. To further improve
visual generation fidelity, we propose a semantic-to-pixel discrete
representation that integrates compact semantic tokens with fine-grained pixel
tokens, achieving strong language alignment and precise description of visual
details with only a 7.9% increase in sequence length. Extensive experiments
across diverse multimodal benchmarks demonstrate that Bridge achieves
competitive or superior results in both understanding and generation
benchmarks, while requiring less training data and reduced training time
compared to prior unified MLLMs.

</details>


### [15] [Robust Classification of Oral Cancer with Limited Training Data](https://arxiv.org/abs/2510.01547)
*Akshay Bhagwan Sonawane,Lena D. Swamikannan,Lakshman Tamil*

Main category: cs.CV

TL;DR: 本研究提出一种结合卷积神经网络（CNN）和贝叶斯深度学习的混合模型，用于在小数据集上进行口腔癌分类，以解决传统模型在数据稀疏环境下的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习模型在口腔癌诊断中存在过度自信、可靠性不足以及需要大量数据的问题，这在医疗资源匮乏的地区尤为严峻。本研究旨在通过不确定性量化提高模型的可靠性和泛化能力。

Method: 提出一种结合CNN和贝叶斯深度学习的混合模型，利用变分推断进行不确定性量化，并使用智能手机拍摄的彩色照片图像进行训练和评估。

Result: 在与训练数据分布相似的测试集上，混合模型达到94%的准确率，与传统CNN相当。在分布不同的真实世界图像数据集上，混合模型达到88%的准确率，优于传统CNN的72.94%，尤其是在小数据集下。置信度分析表明，模型能准确区分正确分类和错误分类的样本。

Conclusion: 贝叶斯推断在数据稀疏的环境中能有效提高口腔癌诊断的可靠性和泛化能力，有助于改善早期诊断效果。

Abstract: Oral cancer ranks among the most prevalent cancers globally, with a
particularly high mortality rate in regions lacking adequate healthcare access.
Early diagnosis is crucial for reducing mortality; however, challenges persist
due to limited oral health programs, inadequate infrastructure, and a shortage
of healthcare practitioners. Conventional deep learning models, while
promising, often rely on point estimates, leading to overconfidence and reduced
reliability. Critically, these models require large datasets to mitigate
overfitting and ensure generalizability, an unrealistic demand in settings with
limited training data. To address these issues, we propose a hybrid model that
combines a convolutional neural network (CNN) with Bayesian deep learning for
oral cancer classification using small training sets. This approach employs
variational inference to enhance reliability through uncertainty
quantification. The model was trained on photographic color images captured by
smartphones and evaluated on three distinct test datasets. The proposed method
achieved 94% accuracy on a test dataset with a distribution similar to that of
the training data, comparable to traditional CNN performance. Notably, for
real-world photographic image data, despite limitations and variations
differing from the training dataset, the proposed model demonstrated superior
generalizability, achieving 88% accuracy on diverse datasets compared to 72.94%
for traditional CNNs, even with a smaller dataset. Confidence analysis revealed
that the model exhibits low uncertainty (high confidence) for correctly
classified samples and high uncertainty (low confidence) for misclassified
samples. These results underscore the effectiveness of Bayesian inference in
data-scarce environments in enhancing early oral cancer diagnosis by improving
model reliability and generalizability.

</details>


### [16] [Consistent Assistant Domains Transformer for Source-free Domain Adaptation](https://arxiv.org/abs/2510.01559)
*Renrong Shao,Wei Zhang,Kangyang Luo,Qin Li,and Jun Wang*

Main category: cs.CV

TL;DR: CADTrans是一种用于源无关域自适应（SFDA）的新方法，通过构建域一致性的不变特征表示来解决现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的源无关域自适应（SFDA）方法在获取不变特征时存在困难，容易受到硬样本和域偏差的影响，并且在表示多样性方面存在不足。

Method: CADTrans提出了一种包含助手域模块的Transformer模型。该模块通过中间聚合的全局注意力来获取多样化的表示。然后，利用助手域和目标域之间的一致性策略来获得不变特征表示，以区分容易和困难的样本。最后，采用条件多核最大均值差异（CMK-MMD）策略来对齐困难样本和容易样本。

Result: 在Office-31、Office-Home、VISDA-C和DomainNet-126等多个基准测试中，CADTrans取得了显著的性能提升。

Conclusion: CADTrans通过构建域一致性的不变特征表示，有效解决了源无关域自适应中的挑战，并在多个数据集上证明了其优越性。

Abstract: Source-free domain adaptation (SFDA) aims to address the challenge of
adapting to a target domain without accessing the source domain directly.
However, due to the inaccessibility of source domain data, deterministic
invariable features cannot be obtained. Current mainstream methods primarily
focus on evaluating invariant features in the target domain that closely
resemble those in the source domain, subsequently aligning the target domain
with the source domain. However, these methods are susceptible to hard samples
and influenced by domain bias. In this paper, we propose a Consistent Assistant
Domains Transformer for SFDA, abbreviated as CADTrans, which solves the issue
by constructing invariable feature representations of domain consistency.
Concretely, we develop an assistant domain module for CADTrans to obtain
diversified representations from the intermediate aggregated global attentions,
which addresses the limitation of existing methods in adequately representing
diversity. Based on assistant and target domains, invariable feature
representations are obtained by multiple consistent strategies, which can be
used to distinguish easy and hard samples. Finally, to align the hard samples
to the corresponding easy samples, we construct a conditional multi-kernel max
mean discrepancy (CMK-MMD) strategy to distinguish between samples of the same
category and those of different categories. Extensive experiments are conducted
on various benchmarks such as Office-31, Office-Home, VISDA-C, and
DomainNet-126, proving the significant performance improvements achieved by our
proposed approaches. Code is available at
https://github.com/RoryShao/CADTrans.git.

</details>


### [17] [Guiding Multimodal Large Language Models with Blind and Low Vision People Visual Questions for Proactive Visual Interpretations](https://arxiv.org/abs/2510.01576)
*Ricardo Gonzalez Penuela,Felipe Arias-Russi,Victor Capriles*

Main category: cs.CV

TL;DR: 多模态大语言模型(MLLM)在视觉解释应用中虽然准确且能提供丰富的人类化解释，但通常会生成冗长的描述，忽略了上下文，导致信息传递效率低下。本研究提出了一种利用历史问题来指导MLLM生成更具上下文相关性的描述的系统，以解决这一问题。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉解释应用对于盲人和低视力(BLV)用户来说，通常会生成冗长且不分青红皂白的描述，迫使用户在无关细节中寻找所需信息，从而降低了信息传递的效率。因此，需要一种能够提供更具上下文相关性的信息的方法。

Method: 本研究开发了一个系统，该系统利用BLV用户的历史问题。当给定一张图像时，该系统会识别VizWiz-LF数据集中相似的 past visual contexts，并利用相关的问题来指导MLLM生成与BLV用户更相关的描述。

Result: 通过三个人工标注员修订92个上下文感知和上下文无关的描述的评估表明，上下文感知描述在76.1%的情况下（92个中的70个）预测并回答了用户的问题，并且在54.4%的比较中（92个中的50个）更受欢迎。

Conclusion: 所提出的系统通过利用BLV用户的历史问题，能够生成更具上下文相关性的图像描述，提高了信息传递的效率和用户满意度。

Abstract: Multimodal large language models (MLLMs) have been integrated into visual
interpretation applications to support Blind and Low Vision (BLV) users because
of their accuracy and ability to provide rich, human-like interpretations.
However, these applications often default to comprehensive, lengthy
descriptions regardless of context. This leads to inefficient exchanges, as
users must go through irrelevant details rather than receiving the specific
information they are likely to seek. To deliver more contextually-relevant
information, we developed a system that draws on historical BLV users
questions. When given an image, our system identifies similar past visual
contexts from the VizWiz-LF dataset and uses the associated questions to guide
the MLLM generate descriptions more relevant to BLV users. An evaluation with
three human labelers who revised 92 context-aware and context-free descriptions
showed that context-aware descriptions anticipated and answered users'
questions in 76.1% of cases (70 out of 92) and were preferred in 54.4% of
comparisons (50 out of 92). Our paper reviews, and data analysis are publicly
available in a Github repository at
https://github.com/rgonzalezp/guiding-multimodal-large-language-models-with-blind-and-low-vision-people-visual-questions .

</details>


### [18] [ImageNet-Think-250K: A Large-Scale Synthetic Dataset for Multimodal Reasoning for Vision Language Models](https://arxiv.org/abs/2510.01582)
*Krishna Teja Chitty-Venkata,Murali Emani*

Main category: cs.CV

TL;DR: ImageNet-Think是一个包含25万张ImageNet21k图像的多模态推理数据集，旨在通过提供结构化的思考过程和答案来增强视觉语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 开发能够进行显式推理的视觉语言模型（VLMs），并促进对多模态推理机制的理解。

Method: 使用两个先进的VLMs（GLM-4.1V-9B-Thinking和Kimi-VL-A3B-Thinking-2506）在25万张ImageNet21k图像上生成带思考过程的答案，每张图像包含两对思考-答案序列。

Result: 创建了一个包含图像、结构化思考代币和对应答案的数据集，用于训练和评估多模态推理模型。

Conclusion: ImageNet-Think数据集的创建旨在促进更强大的VLMs的开发，并将公开提供数据集和评估基准，以支持推理/思考型多模态VLMs的研究。

Abstract: We develop ImageNet-Think, a multimodal reasoning dataset designed to aid the
development of Vision Language Models (VLMs) with explicit reasoning
capabilities. Our dataset is built on 250,000 images from ImageNet21k dataset,
providing structured thinking tokens and corresponding answers. Our synthetic
dataset is generated by two state-of-the-art VLMs: GLM-4.1V-9B-Thinking and
Kimi-VL-A3B-Thinking-2506. Each image is accompanied by two pairs of
thinking-answer sequences, creating a resource for training and evaluating
multimodal reasoning models. We capture the step-by-step reasoning process of
VLMs and the final descriptive answers. Our goal with this dataset is to enable
the development of more robust VLMs while contributing to the broader
understanding of multimodal reasoning mechanisms. The dataset and evaluation
benchmarks will be publicly available to aid research in reasoning/thinking
multimodal VLMs.

</details>


### [19] [NPN: Non-Linear Projections of the Null-Space for Imaging Inverse Problems](https://arxiv.org/abs/2510.01608)
*Roman Jacome,Romario Gualdrón-Hurtado,Leon Suarez,Henry Arguello*

Main category: cs.CV

TL;DR: 该论文提出了一种名为“非线性零空间投影”（NPN）的新型正则化方法，用于解决成像逆问题。


<details>
  <summary>Details</summary>
Motivation: 成像逆问题本质上是病态的，存在无限的解。传统方法通过手工制作的正则化器或学习模型来引入先验信息，但通常会忽略零空间中的任务特定结构。

Method: NPN 是一种新型正则化方法，它不强制执行图像域中的结构约束，而是利用神经网络推广解决方案，使其位于感知矩阵零空间的低维投影中。该方法有两大优势：1）可解释性：通过关注零空间的结构，设计了感知矩阵特定的先验，捕获了感知过程无法分辨的信号分量。2）灵活性：NPN 可适应各种逆问题，与现有重建框架兼容，并可补充传统的图像域先验。论文还提供了即插即用方法中的收敛性和重建精度的理论保证。

Result: 在各种感知矩阵上的实验结果表明，NPN 先验通过即插即用方法、展开网络、深度图像先验和扩散模型，在压缩感知、去模糊、超分辨率、计算机断层扫描和磁共振成像等各种成像逆问题中，一致地提高了重建保真度。

Conclusion: NPN 是一种灵活且可解释的正则化方法，通过利用神经网络对感知矩阵零空间的低维投影进行建模，能够有效解决成像逆问题，并在各种应用中取得显著的重建效果。

Abstract: Imaging inverse problems aims to recover high-dimensional signals from
undersampled, noisy measurements, a fundamentally ill-posed task with infinite
solutions in the null-space of the sensing operator. To resolve this ambiguity,
prior information is typically incorporated through handcrafted regularizers or
learned models that constrain the solution space. However, these priors
typically ignore the task-specific structure of that null-space. In this work,
we propose \textit{Non-Linear Projections of the Null-Space} (NPN), a novel
class of regularization that, instead of enforcing structural constraints in
the image domain, promotes solutions that lie in a low-dimensional projection
of the sensing matrix's null-space with a neural network. Our approach has two
key advantages: (1) Interpretability: by focusing on the structure of the
null-space, we design sensing-matrix-specific priors that capture information
orthogonal to the signal components that are fundamentally blind to the sensing
process. (2) Flexibility: NPN is adaptable to various inverse problems,
compatible with existing reconstruction frameworks, and complementary to
conventional image-domain priors. We provide theoretical guarantees on
convergence and reconstruction accuracy when used within plug-and-play methods.
Empirical results across diverse sensing matrices demonstrate that NPN priors
consistently enhance reconstruction fidelity in various imaging inverse
problems, such as compressive sensing, deblurring, super-resolution, computed
tomography, and magnetic resonance imaging, with plug-and-play methods,
unrolling networks, deep image prior, and diffusion models.

</details>


### [20] [Automated Genomic Interpretation via Concept Bottleneck Models for Medical Robotics](https://arxiv.org/abs/2510.01618)
*Zijun Li,Jinchang Zhang,Ming Zhang,Guoyu Lu*

Main category: cs.CV

TL;DR: 该模块将原始DNA序列转化为可操作的、可解释的决策，用于医疗自动化和机器人系统。


<details>
  <summary>Details</summary>
Motivation: 将可解释的基因组建模与自动化决策相结合，为基因组医学中的机器人和临床自动化奠定可靠基础。

Method: 结合使用混沌图表示（CGR）和概念瓶颈模型（CBM），通过GC含量、CpG密度和k-mer基序等生物学概念进行预测。

Result: 在HIV亚型分类方面取得了最先进的性能，概念预测保真度更高，成本效益权衡更有利。

Conclusion: 所提出的系统在分类性能、概念预测保真度和成本效益方面优于现有基线。

Abstract: We propose an automated genomic interpretation module that transforms raw DNA
sequences into actionable, interpretable decisions suitable for integration
into medical automation and robotic systems. Our framework combines Chaos Game
Representation (CGR) with a Concept Bottleneck Model (CBM), enforcing
predictions to flow through biologically meaningful concepts such as GC
content, CpG density, and k mer motifs. To enhance reliability, we incorporate
concept fidelity supervision, prior consistency alignment, KL distribution
matching, and uncertainty calibration. Beyond accurate classification of HIV
subtypes across both in-house and LANL datasets, our module delivers
interpretable evidence that can be directly validated against biological
priors. A cost aware recommendation layer further translates predictive outputs
into decision policies that balance accuracy, calibration, and clinical
utility, reducing unnecessary retests and improving efficiency. Extensive
experiments demonstrate that the proposed system achieves state of the art
classification performance, superior concept prediction fidelity, and more
favorable cost benefit trade-offs compared to existing baselines. By bridging
the gap between interpretable genomic modeling and automated decision-making,
this work establishes a reliable foundation for robotic and clinical automation
in genomic medicine.

</details>


### [21] [VLA-R1: Enhancing Reasoning in Vision-Language-Action Models](https://arxiv.org/abs/2510.01623)
*Angen Ye,Zeyu Zhang,Boyuan Wang,Xiaofeng Wang,Dapeng Zhang,Zheng Zhu*

Main category: cs.CV

TL;DR: VLA-R1通过整合基于可验证奖励的强化学习（RLVR）和组相对策略优化（GRPO）来增强VLA模型，以优化推理和执行，并在各种平台上展示了优越的泛化能力和真实世界性能。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型缺乏明确的逐步推理能力，并且在训练后很少优化推理质量，因此提出VLA-R1来解决这些挑战。

Method: VLA-R1集成了RLVR和GRPO，并设计了一个基于RLVR的训练后策略，包含区域对齐、轨迹一致性和输出格式的可验证奖励。此外，还开发了一个包含链式思考监督、符合仿生和轨迹注释的数据集VLA-CoT-13K。

Result: VLA-R1在各种平台（包括模拟和真实机器人）的评估中，相比于之前的VLA方法，在特定领域和非特定领域的测试中都取得了更好的泛化能力和真实世界性能。

Conclusion: VLA-R1通过其创新的方法和数据集，显著提高了VLA模型的推理能力和执行准确性，有望推动具身AI的发展。

Abstract: Vision-Language-Action (VLA) models aim to unify perception, language
understanding, and action generation, offering strong cross-task and
cross-scene generalization with broad impact on embodied AI. However, current
VLA models often lack explicit step-by-step reasoning, instead emitting final
actions without considering affordance constraints or geometric relations.
Their post-training pipelines also rarely reinforce reasoning quality, relying
primarily on supervised fine-tuning with weak reward design. To address these
challenges, we present VLA-R1, a reasoning-enhanced VLA that integrates
Reinforcement Learning from Verifiable Rewards (RLVR) with Group Relative
Policy Optimization (GRPO) to systematically optimize both reasoning and
execution. Specifically, we design an RLVR-based post-training strategy with
verifiable rewards for region alignment, trajectory consistency, and output
formatting, thereby strengthening reasoning robustness and execution accuracy.
Moreover, we develop VLA-CoT-13K, a high-quality dataset that provides
chain-of-thought supervision explicitly aligned with affordance and trajectory
annotations. Furthermore, extensive evaluations on in-domain, out-of-domain,
simulation, and real-robot platforms demonstrate that VLA-R1 achieves superior
generalization and real-world performance compared to prior VLA methods. We
plan to release the model, code, and dataset following the publication of this
work. Code: https://github.com/GigaAI-research/VLA-R1. Website:
https://gigaai-research.github.io/VLA-R1.

</details>


### [22] [Joint Deblurring and 3D Reconstruction for Macrophotography](https://arxiv.org/abs/2510.01640)
*Yifan Zhao,Liangchen Li,Yuqi Zhou,Kai Wang,Yan Liang,Juyong Zhang*

Main category: cs.CV

TL;DR: 提出了一种联合去模糊和3D重建的方法，用于宏观摄影。


<details>
  <summary>Details</summary>
Motivation: 宏观摄影中散焦模糊的问题阻碍了清晰成像和高质量3D重建。

Method: 联合优化3D模型和每个像素的散焦模糊核，使用可微分渲染进行自监督优化。

Result: 从少量多视角图像中实现了高质量的图像去模糊和高保真3D外观恢复。

Conclusion: 所提出的方法能够从少量多视角图像中实现高质量的图像去模糊和高保真3D外观恢复。

Abstract: Macro lens has the advantages of high resolution and large magnification, and
3D modeling of small and detailed objects can provide richer information.
However, defocus blur in macrophotography is a long-standing problem that
heavily hinders the clear imaging of the captured objects and high-quality 3D
reconstruction of them. Traditional image deblurring methods require a large
number of images and annotations, and there is currently no multi-view 3D
reconstruction method for macrophotography. In this work, we propose a joint
deblurring and 3D reconstruction method for macrophotography. Starting from
multi-view blurry images captured, we jointly optimize the clear 3D model of
the object and the defocus blur kernel of each pixel. The entire framework
adopts a differentiable rendering method to self-supervise the optimization of
the 3D model and the defocus blur kernel. Extensive experiments show that from
a small number of multi-view images, our proposed method can not only achieve
high-quality image deblurring but also recover high-fidelity 3D appearance.

</details>


### [23] [Automated Defect Detection for Mass-Produced Electronic Components Based on YOLO Object Detection Models](https://arxiv.org/abs/2510.01914)
*Wei-Lung Mao,Chun-Chi Wang,Po-Heng Chou,Yen-Ting Liu*

Main category: cs.CV

TL;DR: 提出一种基于深度学习的自动化双列直插式封装（DIP）缺陷检测系统，并使用ConSinGAN生成数据集，其中YOLOv7模型结合ConSinGAN在准确性和检测速度上表现最优。


<details>
  <summary>Details</summary>
Motivation: 传统工业组件的缺陷检测耗时耗力，给质检人员带来沉重负担，并难以管理产品质量。

Method: 提出自动化缺陷检测系统，使用数字相机光学和基于深度学习（DL）的模型。主要检测表面缺陷和引脚缺陷。使用ConSinGAN生成数据集。测试了四种YOLO模型（v3、v4、v7和v9），并与ConSinGAN结合使用。

Result: 所提出的结合ConSinGAN的YOLOv7模型在准确率（95.50%）、检测时间（285毫秒）方面优于其他YOLO版本，并且远优于基于阈值的方法。开发了SCADA系统并描述了传感器架构。

Conclusion: 所提出的自动化缺陷检测系统易于建立，可用于多种缺陷类型或缺陷数据不足的情况。

Abstract: Since the defect detection of conventional industry components is
time-consuming and labor-intensive, it leads to a significant burden on quality
inspection personnel and makes it difficult to manage product quality. In this
paper, we propose an automated defect detection system for the dual in-line
package (DIP) that is widely used in industry, using digital camera optics and
a deep learning (DL)-based model. The two most common defect categories of DIP
are examined: (1) surface defects, and (2) pin-leg defects. However, the lack
of defective component images leads to a challenge for detection tasks. To
solve this problem, the ConSinGAN is used to generate a suitable-sized dataset
for training and testing. Four varieties of the YOLO model are investigated
(v3, v4, v7, and v9), both in isolation and with the ConSinGAN augmentation.
The proposed YOLOv7 with ConSinGAN is superior to the other YOLO versions in
accuracy of 95.50\%, detection time of 285 ms, and is far superior to
threshold-based approaches. In addition, the supervisory control and data
acquisition (SCADA) system is developed, and the associated sensor architecture
is described. The proposed automated defect detection can be easily established
with numerous types of defects or insufficient defect data.

</details>


### [24] [FideDiff: Efficient Diffusion Model for High-Fidelity Image Motion Deblurring](https://arxiv.org/abs/2510.01641)
*Xiaoyang Liu,Zhengyan Zhou,Zihang Xu,Jiezhang Cao,Zheng Chen,Yulun Zhang*

Main category: cs.CV

TL;DR: FideDiff是一个创新的单步扩散模型，通过将运动去模糊重构为类似扩散的过程，并训练一个一致性模型来对齐所有时间步，实现了高保真度的单步去模糊，同时解决了推理时间和保真度问题。


<details>
  <summary>Details</summary>
Motivation: 大型预训练扩散模型在图像恢复任务中展现出强大潜力，但推理时间和保真度是其应用的主要挑战。

Method: 提出FideDiff，一个单步扩散模型，将运动去模糊视为一个扩散过程，其中每个时间步代表一个逐渐模糊的图像。通过训练一个一致性模型来对齐所有时间步到同一清晰图像，并结合Kernel ControlNet进行模糊核估计和自适应时间步预测，以实现精确的单步去模糊。

Result: FideDiff在全参考指标上取得了优于以往基于扩散的方法的性能，并能与最先进的模型相媲美，解决了推理时间和保真度问题。

Conclusion: FideDiff为将预训练扩散模型应用于高保真图像恢复任务提供了一个新的方向，并为在实际工业应用中进一步发展扩散模型奠定了坚实的基础。

Abstract: Recent advancements in image motion deblurring, driven by CNNs and
transformers, have made significant progress. Large-scale pre-trained diffusion
models, which are rich in true-world modeling, have shown great promise for
high-quality image restoration tasks such as deblurring, demonstrating stronger
generative capabilities than CNN and transformer-based methods. However,
challenges such as unbearable inference time and compromised fidelity still
limit the full potential of the diffusion models. To address this, we introduce
FideDiff, a novel single-step diffusion model designed for high-fidelity
deblurring. We reformulate motion deblurring as a diffusion-like process where
each timestep represents a progressively blurred image, and we train a
consistency model that aligns all timesteps to the same clean image. By
reconstructing training data with matched blur trajectories, the model learns
temporal consistency, enabling accurate one-step deblurring. We further enhance
model performance by integrating Kernel ControlNet for blur kernel estimation
and introducing adaptive timestep prediction. Our model achieves superior
performance on full-reference metrics, surpassing previous diffusion-based
methods and matching the performance of other state-of-the-art models. FideDiff
offers a new direction for applying pre-trained diffusion models to
high-fidelity image restoration tasks, establishing a robust baseline for
further advancing diffusion models in real-world industrial applications. Our
dataset and code will be available at https://github.com/xyLiu339/FideDiff.

</details>


### [25] [LadderMoE: Ladder-Side Mixture of Experts Adapters for Bronze Inscription Recognition](https://arxiv.org/abs/2510.01651)
*Rixin Zhou,Peiqiang Qiu,Qian Zhang,Chuntao Li,Xi Yang*

Main category: cs.CV

TL;DR: 该研究提出了一个处理青铜器铭文（BI）识别的挑战性问题，并开发了一个名为LadderMoE的两阶段模型。


<details>
  <summary>Details</summary>
Motivation: 青铜器铭文是早期中国文字的重要载体，但其自动识别面临视觉退化、跨领域差异和长尾分布的挑战。

Method: 研究者构建了一个大型青铜器铭文数据集，并开发了一个两阶段的检测-识别流水线。该流水线集成了LadderMoE，它在预训练的CLIP编码器上增加了Ladder-style MoE适配器，以实现专家动态专业化和增强鲁棒性。

Result: 实验表明，该方法在单字符和整页识别任务上显著优于现有的场景文本识别基线，在头部、中部和尾部类别以及所有采集模态上都取得了更高的准确性。

Conclusion: 该研究为青铜器铭文识别和后续的考古分析奠定了坚实的基础。

Abstract: Bronze inscriptions (BI), engraved on ritual vessels, constitute a crucial
stage of early Chinese writing and provide indispensable evidence for
archaeological and historical studies. However, automatic BI recognition
remains difficult due to severe visual degradation, multi-domain variability
across photographs, rubbings, and tracings, and an extremely long-tailed
character distribution. To address these challenges, we curate a large-scale BI
dataset comprising 22454 full-page images and 198598 annotated characters
spanning 6658 unique categories, enabling robust cross-domain evaluation.
Building on this resource, we develop a two-stage detection-recognition
pipeline that first localizes inscriptions and then transcribes individual
characters. To handle heterogeneous domains and rare classes, we equip the
pipeline with LadderMoE, which augments a pretrained CLIP encoder with
ladder-style MoE adapters, enabling dynamic expert specialization and stronger
robustness. Comprehensive experiments on single-character and full-page
recognition tasks demonstrate that our method substantially outperforms
state-of-the-art scene text recognition baselines, achieving superior accuracy
across head, mid, and tail categories as well as all acquisition modalities.
These results establish a strong foundation for bronze inscription recognition
and downstream archaeological analysis.

</details>


### [26] [VirDA: Reusing Backbone for Unsupervised Domain Adaptation with Visual Reprogramming](https://arxiv.org/abs/2510.01660)
*Duy Nguyen,Dat Nguyen*

Main category: cs.CV

TL;DR: VirDA是一种视觉再学习方法，通过添加领域特定的视觉提示来适应域迁移，无需对骨干网络参数进行微调，从而实现参数高效和可重用性。


<details>
  <summary>Details</summary>
Motivation: 现有的无监督域适应（UDA）方法在每次进行新的源-目标对训练时都会微调已经训练好的骨干网络参数，这导致训练参数数量和存储内存随着每个新对线性增长，并且无法重复使用这些已经训练好的骨干网络参数。同时，现有骨干网络可能存在纹理偏差。

Method: VirDA提出在骨干网络前添加一个领域特定的视觉再学习层，生成视觉提示，作为输入图像的附加纹理偏差，以适应目标域的“风格”。这种方法不需要修改骨干网络参数，允许在不同领域之间重用相同的骨干网络。该模型使用多个目标函数来优化域适应视觉提示应用时的域内和域间分布差异。

Result: 在Office-31数据集上，VirDA达到了92.8%的平均准确率，仅使用了1.5M的可训练参数。与最先进的参数高效UDA基线PDA相比，VirDA的准确率高出+1.6%，而参数量仅为PDA的46%。与全骨干网络微调方法相比，VirDA在参数量上分别仅占CDTrans和FixBi的1.7%和2.8%，但准确率分别超越了它们+0.2%和+1.4%。与目前最强的PMTrans和TVT方法相比，VirDA的参数量仅占其约1.7%，准确率分别仅下降2.2%和1.1%。

Conclusion: VirDA通过视觉再学习实现参数高效的域适应，在保持高准确率的同时显著减少了参数量和存储需求，并提高了骨干网络的可重用性。

Abstract: Existing UDA pipelines fine-tune already well-trained backbone parameters for
every new source-and-target pair, resulting in the number of training
parameters and storage memory growing linearly with each new pair, and also
preventing the reuse of these well-trained backbone parameters.
  Inspired by recent implications that existing backbones have textural biases,
we propose making use of domain-specific textural bias for domain adaptation
via visual reprogramming, namely VirDA.Instead of fine-tuning the full
backbone, VirDA prepends a domain-specific visual reprogramming layer to the
backbone. This layer produces visual prompts that act as an added textural bias
to the input image, adapting its ``style'' to a target domain. To optimize
these visual reprogramming layers, we use multiple objective functions that
optimize the intra- and inter-domain distribution differences when
domain-adapting visual prompts are applied. This process does not require
modifying the backbone parameters, allowing the same backbone to be reused
across different domains.
  We evaluate VirDA on Office-31 and obtain 92.8% mean accuracy with only 1.5M
trainable parameters. VirDA surpasses PDA, the state-of-the-art
parameter-efficient UDA baseline, by +1.6% accuracy while using just 46% of its
parameters. Compared with full-backbone fine-tuning, VirDA outperforms CDTrans
and FixBi by +0.2% and +1.4%, respectively, while requiring only 1.7% and 2.8%
of their trainable parameters. Relative to the strongest current methods
(PMTrans and TVT), VirDA uses ~1.7% of their parameters and trades off only
2.2% and 1.1% accuracy, respectively.

</details>


### [27] [Discrete Facial Encoding: : A Framework for Data-driven Facial Display Discovery](https://arxiv.org/abs/2510.01662)
*Minh Tran,Maksim Siniukov,Zhangyu Jin,Mohammad Soleymani*

Main category: cs.CV

TL;DR: 提出了一种名为离散面部编码（DFE）的无监督、数据驱动的方法，作为FACS的替代方案，用于从3D网格序列中学习紧凑且可解释的面部表情字典。


<details>
  <summary>Details</summary>
Motivation: 现有的面部表情编码系统（如FACS）存在覆盖范围有限和手动标注成本高昂的问题。

Method: 使用3D可变形模型（3DMM）提取与身份无关的表情特征，然后使用残差向量量化变分自编码器（RVQ-VAE）将这些特征编码为离散的标记序列。

Result: DFE能够比FACS捕获更精确的面部行为，并且在压力检测、个性预测和抑郁检测等心理学任务中表现优于FACS以及其他先进的模型。

Conclusion: DFE是一种可扩展且有效的面部表情表示方法，适用于心理学和情感计算应用。

Abstract: Facial expression analysis is central to understanding human behavior, yet
existing coding systems such as the Facial Action Coding System (FACS) are
constrained by limited coverage and costly manual annotation. In this work, we
introduce Discrete Facial Encoding (DFE), an unsupervised, data-driven
alternative of compact and interpretable dictionary of facial expressions from
3D mesh sequences learned through a Residual Vector Quantized Variational
Autoencoder (RVQ-VAE). Our approach first extracts identity-invariant
expression features from images using a 3D Morphable Model (3DMM), effectively
disentangling factors such as head pose and facial geometry. We then encode
these features using an RVQ-VAE, producing a sequence of discrete tokens from a
shared codebook, where each token captures a specific, reusable facial
deformation pattern that contributes to the overall expression. Through
extensive experiments, we demonstrate that Discrete Facial Encoding captures
more precise facial behaviors than FACS and other facial encoding alternatives.
We evaluate the utility of our representation across three high-level
psychological tasks: stress detection, personality prediction, and depression
detection. Using a simple Bag-of-Words model built on top of the learned
tokens, our system consistently outperforms both FACS-based pipelines and
strong image and video representation learning models such as Masked
Autoencoders. Further analysis reveals that our representation covers a wider
variety of facial displays, highlighting its potential as a scalable and
effective alternative to FACS for psychological and affective computing
applications.

</details>


### [28] [Non-Rigid Structure-from-Motion via Differential Geometry with Recoverable Conformal Scale](https://arxiv.org/abs/2510.01665)
*Yongbo Chen,Yanhao Zhang,Shaifali Parashar,Liang Zhao,Shoudong Huang*

Main category: cs.CV

TL;DR: Con-NRSfM是一种用于处理单目视觉可变形SLAM的共形变形NRSfM新方法，能精确恢复局部共形尺度和深度，并通过自监督学习生成稠密的3D点云，在重建精度和鲁棒性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决单目视觉可变形SLAM中的映射挑战，改进非刚性结构运动(NRSfM)技术。

Method: 提出Con-NRSfM方法，在图结构框架下优化2D图像变形进行点重建，消除对局部平面或线性变形的假设，分离深度和共形尺度约束，采用并行可分离迭代优化策略，并结合自监督学习生成稠密的3D点云。

Result: 在合成和真实数据集的仿真与实验中，证明了该方法在重建精度和鲁棒性方面优于现有方法。

Conclusion: Con-NRSfM在共形变形下实现了精确的3D重建，克服了现有方法的局限性，并能生成高质量的稠密点云。

Abstract: Non-rigid structure-from-motion (NRSfM), a promising technique for addressing
the mapping challenges in monocular visual deformable simultaneous localization
and mapping (SLAM), has attracted growing attention. We introduce a novel
method, called Con-NRSfM, for NRSfM under conformal deformations, encompassing
isometric deformations as a subset. Our approach performs point-wise
reconstruction using 2D selected image warps optimized through a graph-based
framework. Unlike existing methods that rely on strict assumptions, such as
locally planar surfaces or locally linear deformations, and fail to recover the
conformal scale, our method eliminates these constraints and accurately
computes the local conformal scale. Additionally, our framework decouples
constraints on depth and conformal scale, which are inseparable in other
approaches, enabling more precise depth estimation. To address the sensitivity
of the formulated problem, we employ a parallel separable iterative
optimization strategy. Furthermore, a self-supervised learning framework,
utilizing an encoder-decoder network, is incorporated to generate dense 3D
point clouds with texture. Simulation and experimental results using both
synthetic and real datasets demonstrate that our method surpasses existing
approaches in terms of reconstruction accuracy and robustness. The code for the
proposed method will be made publicly available on the project website:
https://sites.google.com/view/con-nrsfm.

</details>


### [29] [UniVerse: Unleashing the Scene Prior of Video Diffusion Models for Robust Radiance Field Reconstruction](https://arxiv.org/abs/2510.01669)
*Jin Cao,Hongrui Wu,Ziyong Feng,Hujun Bao,Xiaowei Zhou,Sida Peng*

Main category: cs.CV

TL;DR: 该研究提出了一种名为UniVerse的框架，用于从不一致的多视图图像中进行鲁棒的三维场景重建。该框架将问题分解为图像恢复和三维重建两个子任务，并利用视频扩散模型进行图像恢复，从而提高了对各种图像不一致性的泛化能力和重建性能，同时还能控制重建场景的风格。


<details>
  <summary>Details</summary>
Motivation: 现有方法在从不一致的多视图图像进行鲁棒三维重建时，严重依赖于密集的观测数据来优化模型参数，限制了其应用范围。本研究旨在解决这一限制，提出一种更通用的方法。

Method: UniVerse框架首先将不一致的输入图像转换为初始视频，然后利用专门设计的视频扩散模型对视频进行恢复，生成一致性的图像，最后从恢复后的一致性图像中重建三维场景。该方法利用扩散模型学习通用的场景先验，而非依赖于逐视图的特定退化建模。

Result: 在合成和真实世界数据集上的广泛实验表明，UniVerse在鲁棒三维重建方面表现出强大的泛化能力和优于现有方法的性能。此外，UniVerse还能够控制重建三维场景的风格。

Conclusion: UniVerse通过将鲁棒重建分解为图像恢复和三维重建两个子任务，并创新性地运用视频扩散模型进行图像恢复，成功解决了现有方法对密集观测的依赖问题，实现了更通用、性能更优越的鲁棒三维重建，并具备风格控制能力。

Abstract: This paper tackles the challenge of robust reconstruction, i.e., the task of
reconstructing a 3D scene from a set of inconsistent multi-view images. Some
recent works have attempted to simultaneously remove image inconsistencies and
perform reconstruction by integrating image degradation modeling into neural 3D
scene representations.However, these methods rely heavily on dense observations
for robustly optimizing model parameters.To address this issue, we propose to
decouple robust reconstruction into two subtasks: restoration and
reconstruction, which naturally simplifies the optimization process.To this
end, we introduce UniVerse, a unified framework for robust reconstruction based
on a video diffusion model. Specifically, UniVerse first converts inconsistent
images into initial videos, then uses a specially designed video diffusion
model to restore them into consistent images, and finally reconstructs the 3D
scenes from these restored images.Compared with case-by-case per-view
degradation modeling, the diffusion model learns a general scene prior from
large-scale data, making it applicable to diverse image
inconsistencies.Extensive experiments on both synthetic and real-world datasets
demonstrate the strong generalization capability and superior performance of
our method in robust reconstruction. Moreover, UniVerse can control the style
of the reconstructed 3D scene. Project page:
https://jin-cao-tma.github.io/UniVerse.github.io/

</details>


### [30] [An Efficient Deep Template Matching and In-Plane Pose Estimation Method via Template-Aware Dynamic Convolution](https://arxiv.org/abs/2510.01678)
*Ke Jia,Ji Zhou,Hanxin Li,Zhigan Zhou,Haojie Chu,Xiaojie Li*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In industrial inspection and component alignment tasks, template matching
requires efficient estimation of a target's position and geometric state
(rotation and scaling) under complex backgrounds to support precise downstream
operations. Traditional methods rely on exhaustive enumeration of angles and
scales, leading to low efficiency under compound transformations. Meanwhile,
most deep learning-based approaches only estimate similarity scores without
explicitly modeling geometric pose, making them inadequate for real-world
deployment. To overcome these limitations, we propose a lightweight end-to-end
framework that reformulates template matching as joint localization and
geometric regression, outputting the center coordinates, rotation angle, and
independent horizontal and vertical scales. A Template-Aware Dynamic
Convolution Module (TDCM) dynamically injects template features at inference to
guide generalizable matching. The compact network integrates depthwise
separable convolutions and pixel shuffle for efficient matching. To enable
geometric-annotation-free training, we introduce a rotation-shear-based
augmentation strategy with structure-aware pseudo labels. A lightweight
refinement module further improves angle and scale precision via local
optimization. Experiments show our 3.07M model achieves high precision and 14ms
inference under compound transformations. It also demonstrates strong
robustness in small-template and multi-object scenarios, making it highly
suitable for deployment in real-time industrial applications. The code is
available at:https://github.com/ZhouJ6610/PoseMatch-TDCM.

</details>


### [31] [Look Less, Reason More: Rollout-Guided Adaptive Pixel-Space Reasoning](https://arxiv.org/abs/2510.01681)
*Xuchen Li,Xuzhao Li,Jiahui Gao,Renjie Pi,Shiyu Hu,Wentao Zhang*

Main category: cs.CV

TL;DR: 该研究提出了一种自适应像素推理框架，通过操作感知监督微调和基于rollout的强化学习，使视觉语言模型（VLM）能够根据查询的复杂性动态确定是否以及何时执行像素级操作，从而在提高准确性的同时减少不必要的视觉操作。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型（VLM）在处理需要精细视觉元素理解的任务时存在困难，主要原因是图像编码过程中的信息丢失或对关键区域的注意力不足。虽然像素级信息有助于提高模型性能，但过度使用会导致效率低下并分散对无关细节的注意力。

Method: 该研究提出了一种自适应像素推理框架。首先，通过操作感知监督微调来建立模型在文本推理和视觉操作方面的基础能力。然后，设计了一个新颖的、基于rollout的强化学习框架，该框架利用模型自身响应的反馈来学习何时应该调用像素操作，以响应不同难度的查询。

Result: 实验结果表明，该模型在广泛的多模态推理基准测试中取得了优越的性能，并且显著减少了不必要的视觉操作。具体来说，在HR-Bench 4K上，该模型实现了73.4%的准确率，而工具使用率仅为20.1%，与先前的方法相比，在提高准确性的同时将工具使用率降低了66.5%。

Conclusion: 该研究提出的自适应像素推理框架能够有效地解决VLM在精细视觉理解方面的挑战，通过动态调整像素级操作的使用，实现了性能的提升和效率的优化。

Abstract: Vision-Language Models (VLMs) excel at many multimodal tasks, yet they
frequently struggle with tasks requiring precise understanding and handling of
fine-grained visual elements. This is mainly due to information loss during
image encoding or insufficient attention to critical regions. Recent work has
shown promise by incorporating pixel-level visual information into the
reasoning process, enabling VLMs to access high-resolution visual details
during their thought process. However, this pixel-level information is often
overused, leading to inefficiency and distraction from irrelevant visual
details. To address these challenges, we propose the first framework for
adaptive pixel reasoning that dynamically determines necessary pixel-level
operations based on the input query. Specifically, we first apply
operation-aware supervised fine-tuning to establish baseline competence in
textual reasoning and visual operations, then design a novel rollout-guided
reinforcement learning framework relying on feedback of the model's own
responses, which enables the VLM to determine when pixel operations should be
invoked based on query difficulty. Experiments on extensive multimodal
reasoning benchmarks show that our model achieves superior performance while
significantly reducing unnecessary visual operations. Impressively, our model
achieves 73.4\% accuracy on HR-Bench 4K while maintaining a tool usage ratio of
only 20.1\%, improving accuracy and simultaneously reducing tool usage by
66.5\% compared to the previous methods.

</details>


### [32] [Uncovering Overconfident Failures in CXR Models via Augmentation-Sensitivity Risk Scoring](https://arxiv.org/abs/2510.01683)
*Han-Jay Shu,Wei-Ning Chiu,Shun-Ting Chang,Meng-Ping Huang,Takeshi Tohyama,Ahram Han,Po-Chih Kuo*

Main category: cs.CV

TL;DR: 深度学习模型在胸部X光片(CXR)解释方面表现出色，但公平性和可靠性问题依然存在。现有的错误检测方法难以处理细微的分布内错误，而基于图像和表示级别一致性的方法在医学影像中仍未得到充分探索。本研究提出了一个增强敏感性风险评分（ASRS）框架，用于识别易出错的CXR病例。ASRS应用了临床上合理的旋转（±15°/±30°），并使用RAD-DINO编码器测量嵌入式移位。敏感性评分将样本分为稳定性四分位数，其中高度敏感的病例尽管具有高AUROC和置信度，但召回率显著降低（-0.2至-0.3）。ASRS提供了一种无需标签即可进行选择性预测和临床医生审查的方法，从而提高了医学人工智能的公平性和安全性。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在胸部X光片(CXR)解释方面表现出色，但公平性和可靠性问题依然存在，现有错误检测方法存在局限性。

Method: 提出一个增强敏感性风险评分（ASRS）框架，应用临床上合理的旋转（±15°/±30°），并使用RAD-DINO编码器测量嵌入式移位。敏感性评分将样本分为稳定性四分位数。

Result: 高度敏感的病例尽管具有高AUROC和置信度，但召回率显著降低（-0.2至-0.3）。

Conclusion: ASRS提供了一种无需标签即可进行选择性预测和临床医生审查的方法，从而提高了医学人工智能的公平性和安全性。

Abstract: Deep learning models achieve strong performance in chest radiograph (CXR)
interpretation, yet fairness and reliability concerns persist. Models often
show uneven accuracy across patient subgroups, leading to hidden failures not
reflected in aggregate metrics. Existing error detection approaches -- based on
confidence calibration or out-of-distribution (OOD) detection -- struggle with
subtle within-distribution errors, while image- and representation-level
consistency-based methods remain underexplored in medical imaging. We propose
an augmentation-sensitivity risk scoring (ASRS) framework to identify
error-prone CXR cases. ASRS applies clinically plausible rotations ($\pm
15^\circ$/$\pm 30^\circ$) and measures embedding shifts with the RAD-DINO
encoder. Sensitivity scores stratify samples into stability quartiles, where
highly sensitive cases show substantially lower recall ($-0.2$ to $-0.3$)
despite high AUROC and confidence. ASRS provides a label-free means for
selective prediction and clinician review, improving fairness and safety in
medical AI.

</details>


### [33] [FreeViS: Training-free Video Stylization with Inconsistent References](https://arxiv.org/abs/2510.01686)
*Jiacong Xu,Yiqun Mei,Ke Zhang,Vishal M. Patel*

Main category: cs.CV

TL;DR: FreeViS是一个无需训练的视频风格化框架，通过整合多个风格化参考、高频补偿和基于流动的运动线索，生成具有丰富细节和时间连贯性的风格化视频，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有视频风格化方法存在时间一致性差、风格丰富度低、需要配对视频数据或计算成本高昂等问题。

Method: FreeViS框架整合多个风格化参考到预训练的图像到视频（I2V）模型中，并利用高频补偿和基于流动的运动线索来提高风格化质量和时间一致性。

Result: FreeViS在风格化保真度和时间一致性方面表现优于现有基线方法，并获得更高的用户偏好。

Conclusion: FreeViS提供了一种实用且经济高效的解决方案，可实现高质量、时间连贯的视频风格化。

Abstract: Video stylization plays a key role in content creation, but it remains a
challenging problem. Na\"ively applying image stylization frame-by-frame hurts
temporal consistency and reduces style richness. Alternatively, training a
dedicated video stylization model typically requires paired video data and is
computationally expensive. In this paper, we propose FreeViS, a training-free
video stylization framework that generates stylized videos with rich style
details and strong temporal coherence. Our method integrates multiple stylized
references to a pretrained image-to-video (I2V) model, effectively mitigating
the propagation errors observed in prior works, without introducing flickers
and stutters. In addition, it leverages high-frequency compensation to
constrain the content layout and motion, together with flow-based motion cues
to preserve style textures in low-saliency regions. Through extensive
evaluations, FreeViS delivers higher stylization fidelity and superior temporal
consistency, outperforming recent baselines and achieving strong human
preference. Our training-free pipeline offers a practical and economic solution
for high-quality, temporally coherent video stylization. The code and videos
can be accessed via https://xujiacong.github.io/FreeViS/

</details>


### [34] [MedQ-Bench: Evaluating and Exploring Medical Image Quality Assessment Abilities in MLLMs](https://arxiv.org/abs/2510.01691)
*Jiyao Liu,Jinjie Wei,Wanying Qu,Chenglong Ma,Junzhi Ning,Yunheng Li,Ying Chen,Xinzhe Luo,Pengcheng Chen,Xin Gao,Ming Hu,Huihui Xu,Xin Wang,Shujian Gao,Dingkang Yang,Zhongying Deng,Jin Ye,Lihao Liu,Junjun He,Ningsheng Xu*

Main category: cs.CV

TL;DR: MedQ-Bench是一个新的基准，使用多模态大语言模型（MLLM）对医学图像质量进行基于语言的评估，以弥补现有基于分数的方法的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的医学图像质量评估（IQA）方法主要依赖于标量分数，无法捕捉专家评估中以人类为中心的描述性推理过程。

Method: MedQ-Bench提出了一个感知-推理范式，包括MedQ-Perception（探测低级感知能力）和MedQ-Reasoning（评估无参考和比较推理任务）。该基准包含2,600个感知查询和708个推理评估，涵盖了五种成像模态和四十多种质量属性，并提出了一种多维度的评判协议来评估模型推理能力。

Result: 对14个最先进的MLLM的评估表明，它们在感知和推理能力方面表现出初步但不稳定的技能，准确性不足以用于临床。

Conclusion: 现有的MLLM在医学图像质量评估方面尚不可靠，需要进行有针对性的优化。MedQ-Bench旨在促进对MLLM在医学IQA领域的进一步研究。

Abstract: Medical Image Quality Assessment (IQA) serves as the first-mile safety gate
for clinical AI, yet existing approaches remain constrained by scalar,
score-based metrics and fail to reflect the descriptive, human-like reasoning
process central to expert evaluation. To address this gap, we introduce
MedQ-Bench, a comprehensive benchmark that establishes a perception-reasoning
paradigm for language-based evaluation of medical image quality with
Multi-modal Large Language Models (MLLMs). MedQ-Bench defines two complementary
tasks: (1) MedQ-Perception, which probes low-level perceptual capability via
human-curated questions on fundamental visual attributes; and (2)
MedQ-Reasoning, encompassing both no-reference and comparison reasoning tasks,
aligning model evaluation with human-like reasoning on image quality. The
benchmark spans five imaging modalities and over forty quality attributes,
totaling 2,600 perceptual queries and 708 reasoning assessments, covering
diverse image sources including authentic clinical acquisitions, images with
simulated degradations via physics-based reconstructions, and AI-generated
images. To evaluate reasoning ability, we propose a multi-dimensional judging
protocol that assesses model outputs along four complementary axes. We further
conduct rigorous human-AI alignment validation by comparing LLM-based judgement
with radiologists. Our evaluation of 14 state-of-the-art MLLMs demonstrates
that models exhibit preliminary but unstable perceptual and reasoning skills,
with insufficient accuracy for reliable clinical use. These findings highlight
the need for targeted optimization of MLLMs in medical IQA. We hope that
MedQ-Bench will catalyze further exploration and unlock the untapped potential
of MLLMs for medical image quality evaluation.

</details>


### [35] [Holistic Order Prediction in Natural Scenes](https://arxiv.org/abs/2510.01704)
*Pierre Musacchio,Hyunmin Lee,Jaesik Park*

Main category: cs.CV

TL;DR: InstaFormer是一个能够仅通过输入RGB图像，在一次前向传播中预测场景中所有实例的遮挡和深度排序的网络。


<details>
  <summary>Details</summary>
Motivation: 现有的实例级几何理解方法在处理现代艺术时面临昂贵的输入格式（类别标签、二值分割掩码）和推理成本（二次方的正向传播）的限制。InstaFormer旨在克服这些挑战。

Method: InstaFormer网络的核心在于物体查询（object queries）和潜在掩码描述符（latent mask descriptors）之间的交互。这些描述符在语义上代表相同的物体，并携带互补的信息，从而实现整体的顺序预测。

Result: InstaFormer能够仅给定输入RGB图像，在一次前向传播中输出场景中所有实例的完整遮挡和深度排序。

Conclusion: InstaFormer通过其创新的物体查询和潜在掩码描述符交互机制，有效解决了现有方法在实例级几何理解方面的局限性，实现了高效的整体顺序预测。

Abstract: Even in controlled settings, understanding instance-wise geometries is a
challenging task for a wide range of visual models. Although specialized
systems exist, modern arts rely on expensive input formats (category labels,
binary segmentation masks) and inference costs (a quadratic amount of forward
passes). We mitigate these limitations by proposing InstaFormer, a network
capable of holistic order prediction. That is, solely given an input RGB image,
InstaFormer returns the full occlusion and depth orderings for all the
instances in the scene in a single forward pass. At its core, InstaFormer
relies on interactions between object queries and latent mask descriptors that
semantically represent the same objects while carrying complementary
information. We comprehensively benchmark and ablate our approach to highlight
its effectiveness. Our code and models are open-source and available at this
URL: https://github.com/SNU-VGILab/InstaOrder.

</details>


### [36] [PyramidStyler: Transformer-Based Neural Style Transfer with Pyramidal Positional Encoding and Reinforcement Learning](https://arxiv.org/abs/2510.01715)
*Raahul Krishna Durairaju,K. Saruladha*

Main category: cs.CV

TL;DR: NST模型在处理复杂风格和高分辨率图像时效率低下。本文提出了PyramidStyler，一个结合了金字塔位置编码（PPE）和强化学习（RL）的Transformer框架，以提高效率和图像质量。


<details>
  <summary>Details</summary>
Motivation: 现有的基于CNN和Transformer的神经风格迁移模型在处理复杂风格和高分辨率输入时效率不高。

Method: 提出了一种名为PyramidStyler的Transformer框架，该框架采用了金字塔位置编码（PPE）来捕捉局部细节和全局上下文，并结合强化学习（RL）来动态优化风格化过程，以加速收敛。

Result: 在COCO和WikiArt数据集上训练后，PyramidStyler在4000个epoch后将内容损失降低了62.6%（至2.07），风格损失降低了57.4%（至0.86），推理速度为1.39秒。使用RL后，内容损失降至2.03，风格损失降至0.75，推理速度为1.40秒，在速度损失很小的情况下获得了进一步的提升。

Conclusion: PyramidStyler实现了实时、高质量的艺术渲染，在媒体和设计领域具有广泛的应用前景。

Abstract: Neural Style Transfer (NST) has evolved from Gatys et al.'s (2015) CNN-based
algorithm, enabling AI-driven artistic image synthesis. However, existing CNN
and transformer-based models struggle to scale efficiently to complex styles
and high-resolution inputs. We introduce PyramidStyler, a transformer framework
with Pyramidal Positional Encoding (PPE): a hierarchical, multi-scale encoding
that captures both local details and global context while reducing
computational load. We further incorporate reinforcement learning to
dynamically optimize stylization, accelerating convergence. Trained on
Microsoft COCO and WikiArt, PyramidStyler reduces content loss by 62.6% (to
2.07) and style loss by 57.4% (to 0.86) after 4000 epochs--achieving 1.39 s
inference--and yields further improvements (content 2.03; style 0.75) with
minimal speed penalty (1.40 s) when using RL. These results demonstrate
real-time, high-quality artistic rendering, with broad applications in media
and design.

</details>


### [37] [LOBE-GS: Load-Balanced and Efficient 3D Gaussian Splatting for Large-Scale Scene Reconstruction](https://arxiv.org/abs/2510.01767)
*Sheng-Hsiang Hung,Ting-Yu Yen,Wei-Fang Sun,Simon See,Shih-Hsuan Hung,Hung-Kuo Chu*

Main category: cs.CV

TL;DR: LoBE-GS通过深度感知划分、基于可见高斯球的优化策略、可见性裁剪和选择性稠密化，实现了大规模3D高斯辐射场重建的负载均衡和效率提升，训练速度提升高达2倍，并解决了现有方法在处理大规模场景时的负载不均和效率低下问题。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯辐射场（3DGS）方法在扩展到城市街区等大规模和无界场景时存在困难，主要表现为分区负载不均和粗粒度到细粒度管线效率低下。

Method: LoBE-GS提出了一种新的负载均衡和高效3D高斯辐射场框架，其核心包括：1. 深度感知划分方法，将预处理时间从数小时缩短至数分钟。2. 基于可见高斯球（作为计算负载的代理）的优化策略，实现跨块负载均衡。3. 可见性裁剪和选择性稠密化技术，以进一步降低训练成本。

Result: 在大型城市和室外数据集上的评估表明，LoBE-GS实现了高达2倍于现有最先进基线方法的端到端训练速度，同时保持了重建质量，并实现了原始3DGS无法处理的场景的可扩展性。

Conclusion: LoBE-GS成功地解决了大规模3D高斯辐射场重建中的负载均衡和效率瓶颈问题，显著提高了训练速度和可扩展性。

Abstract: 3D Gaussian Splatting (3DGS) has established itself as an efficient
representation for real-time, high-fidelity 3D scene reconstruction. However,
scaling 3DGS to large and unbounded scenes such as city blocks remains
difficult. Existing divide-and-conquer methods alleviate memory pressure by
partitioning the scene into blocks, but introduce new bottlenecks: (i)
partitions suffer from severe load imbalance since uniform or heuristic splits
do not reflect actual computational demands, and (ii) coarse-to-fine pipelines
fail to exploit the coarse stage efficiently, often reloading the entire model
and incurring high overhead. In this work, we introduce LoBE-GS, a novel
Load-Balanced and Efficient 3D Gaussian Splatting framework, that re-engineers
the large-scale 3DGS pipeline. LoBE-GS introduces a depth-aware partitioning
method that reduces preprocessing from hours to minutes, an optimization-based
strategy that balances visible Gaussians -- a strong proxy for computational
load -- across blocks, and two lightweight techniques, visibility cropping and
selective densification, to further reduce training cost. Evaluations on
large-scale urban and outdoor datasets show that LoBE-GS consistently achieves
up to $2\times$ faster end-to-end training time than state-of-the-art
baselines, while maintaining reconstruction quality and enabling scalability to
scenes infeasible with vanilla 3DGS.

</details>


### [38] [Pack and Force Your Memory: Long-form and Consistent Video Generation](https://arxiv.org/abs/2510.01784)
*Xiaofei Wu,Guozhen Zhang,Zhiyong Xu,Yuan Zhou,Qinglin Lu,Xuming He*

Main category: cs.CV

TL;DR: MemoryPack 和 Direct Forcing 提出以应对长视频生成的挑战，前者通过动态上下文建模实现分钟级时间一致性，后者通过直接强制策略减少推理过程中的误差累积。


<details>
  <summary>Details</summary>
Motivation: 长视频生成面临着捕捉长距离依赖关系和防止自回归解码中固有误差累积的双重挑战。

Method: 提出两种方法：1. MemoryPack：一种可学习的上下文检索机制，利用文本和图像信息进行全局引导，联合建模短期和长期依赖关系，实现分钟级时间一致性，并保持线性复杂度。2. Direct Forcing：一种高效的单步近似策略，改善训练-推理对齐，从而减少推理过程中的误差传播。

Result: MemoryPack 和 Direct Forcing 的结合，显著提高了长视频生成在上下文一致性和可靠性方面，推动了自回归视频模型在实际应用中的可用性。

Conclusion: MemoryPack 和 Direct Forcing 共同解决了长视频生成中的关键挑战，提高了生成视频的质量和可靠性。

Abstract: Long-form video generation presents a dual challenge: models must capture
long-range dependencies while preventing the error accumulation inherent in
autoregressive decoding. To address these challenges, we make two
contributions. First, for dynamic context modeling, we propose MemoryPack, a
learnable context-retrieval mechanism that leverages both textual and image
information as global guidance to jointly model short- and long-term
dependencies, achieving minute-level temporal consistency. This design scales
gracefully with video length, preserves computational efficiency, and maintains
linear complexity. Second, to mitigate error accumulation, we introduce Direct
Forcing, an efficient single-step approximating strategy that improves
training-inference alignment and thereby curtails error propagation during
inference. Together, MemoryPack and Direct Forcing substantially enhance the
context consistency and reliability of long-form video generation, advancing
the practical usability of autoregressive video models.

</details>


### [39] [Calibrating the Full Predictive Class Distribution of 3D Object Detectors for Autonomous Driving](https://arxiv.org/abs/2510.01829)
*Cornelius Schröder,Marius-Raphael Schlüter,Markus Lienkamp*

Main category: cs.CV

TL;DR: 本研究提出了一种提高3D目标检测器分类任务置信度校准的方法，通过引入正则化损失项来优化主导和次要类别预测的校准。


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶系统中，精确的目标检测和不确定性估计对于实现自感知和安全运行至关重要。本研究旨在解决3D目标检测器的分类任务中的置信度校准问题。

Method: 提出两种辅助正则化损失项，分别将主导预测或全部预测向量的校准作为训练目标。在CenterPoint, PillarNet和DSVT-Pillar模型上评估了多种后验和训练时方法。

Result: 结合本研究提出的损失项（优化全部类别预测的校准）和等渗回归（isotonic regression），能够最好地校准CenterPoint和PillarNet模型，同时考虑主导和次要类别预测。研究还发现，DSVT-Pillar模型无法通过相同方法同时校准主导和次要类别预测。

Conclusion: 本研究提出的用于全预测向量校准的损失项，结合等渗回归，能够有效提升CenterPoint和PillarNet的置信度校准性能，尤其是在同时考虑主导和次要类别预测时。然而，DSVT-Pillar模型的校准行为存在差异，需要进一步研究。

Abstract: In autonomous systems, precise object detection and uncertainty estimation
are critical for self-aware and safe operation. This work addresses confidence
calibration for the classification task of 3D object detectors. We argue that
it is necessary to regard the calibration of the full predictive confidence
distribution over all classes and deduce a metric which captures the
calibration of dominant and secondary class predictions. We propose two
auxiliary regularizing loss terms which introduce either calibration of the
dominant prediction or the full prediction vector as a training goal. We
evaluate a range of post-hoc and train-time methods for CenterPoint, PillarNet
and DSVT-Pillar and find that combining our loss term, which regularizes for
calibration of the full class prediction, and isotonic regression lead to the
best calibration of CenterPoint and PillarNet with respect to both dominant and
secondary class predictions. We further find that DSVT-Pillar can not be
jointly calibrated for dominant and secondary predictions using the same
method.

</details>


### [40] [Leveraging Prior Knowledge of Diffusion Model for Person Search](https://arxiv.org/abs/2510.01841)
*Giyeol Kim,Sooyoung Yang,Jihyong Oh,Myungjoo Kang,Chanho Eom*

Main category: cs.CV

TL;DR: DiffPS利用预训练的扩散模型来解决人员搜索中的检测和重识别冲突问题，通过三个新模块（DGRPN, MSFRN, SFAN）提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有的人员搜索方法使用ImageNet预训练骨干网络，这可能无法充分捕捉人员搜索所需的复杂空间上下文和细粒度身份线索。此外，它们依赖于共享骨干网络特征，导致因冲突的优化目标而产生次优特征。

Method: 提出DiffPS框架，利用预训练的扩散模型，并通过三个专门的模块（DGRPN, MSFRN, SFAN）来解决检测和重识别子任务之间的优化冲突。

Result: DiffPS在CUHK-SYSU和PRW数据集上达到了新的state-of-the-art水平。

Conclusion: DiffPS通过利用扩散模型先验知识和专门设计的模块，有效地解决了人员搜索中的挑战。

Abstract: Person search aims to jointly perform person detection and re-identification
by localizing and identifying a query person within a gallery of uncropped
scene images. Existing methods predominantly utilize ImageNet pre-trained
backbones, which may be suboptimal for capturing the complex spatial context
and fine-grained identity cues necessary for person search. Moreover, they rely
on a shared backbone feature for both person detection and re-identification,
leading to suboptimal features due to conflicting optimization objectives. In
this paper, we propose DiffPS (Diffusion Prior Knowledge for Person Search), a
novel framework that leverages a pre-trained diffusion model while eliminating
the optimization conflict between two sub-tasks. We analyze key properties of
diffusion priors and propose three specialized modules: (i) Diffusion-Guided
Region Proposal Network (DGRPN) for enhanced person localization, (ii)
Multi-Scale Frequency Refinement Network (MSFRN) to mitigate shape bias, and
(iii) Semantic-Adaptive Feature Aggregation Network (SFAN) to leverage
text-aligned diffusion features. DiffPS sets a new state-of-the-art on
CUHK-SYSU and PRW.

</details>


### [41] [Flow-Matching Guided Deep Unfolding for Hyperspectral Image Reconstruction](https://arxiv.org/abs/2510.01912)
*Yi Ai,Yuanhao Cai,Yulun Zhang,Xiaokang Yang*

Main category: cs.CV

TL;DR: 本文提出了一种名为FMU（Flow-Matching-guided Unfolding network）的新型高光谱图像重建方法，它结合了流匹配（flow matching）的生成先验和深度展开（deep unfolding）框架，并引入了均值速度损失（mean velocity loss）来增强全局一致性，显著提高了重建质量。


<details>
  <summary>Details</summary>
Motivation: 高光谱成像（HSI）虽然能提供丰富的空间-光谱信息，但由于硬件限制和三维数据重建的复杂性，获取成本高昂。现有的压缩感知系统（如CASSI）在提高效率的同时，重建精度仍受严重降质和光谱细节损失的挑战。

Method: FMU网络将流匹配的生成先验嵌入深度展开框架中，并设计了均值速度损失来强制执行流的全局一致性。这种混合设计结合了基于优化的可解释性和流匹配的生成能力。

Result: 在模拟和真实数据集上的大量实验表明，FMU在重建质量上显著优于现有方法。

Conclusion: FMU是首个将流匹配集成到高光谱图像重建中的方法，通过结合深度展开和流匹配的生成先验，并引入均值速度损失，有效解决了现有方法的局限性，实现了更鲁棒、更准确的重建。

Abstract: Hyperspectral imaging (HSI) provides rich spatial-spectral information but
remains costly to acquire due to hardware limitations and the difficulty of
reconstructing three-dimensional data from compressed measurements. Although
compressive sensing systems such as CASSI improve efficiency, accurate
reconstruction is still challenged by severe degradation and loss of fine
spectral details. We propose the Flow-Matching-guided Unfolding network (FMU),
which, to our knowledge, is the first to integrate flow matching into HSI
reconstruction by embedding its generative prior within a deep unfolding
framework. To further strengthen the learned dynamics, we introduce a mean
velocity loss that enforces global consistency of the flow, leading to a more
robust and accurate reconstruction. This hybrid design leverages the
interpretability of optimization-based methods and the generative capacity of
flow matching. Extensive experiments on both simulated and real datasets show
that FMU significantly outperforms existing approaches in reconstruction
quality. Code and models will be available at https://github.com/YiAi03/FMU.

</details>


### [42] [Foundation Visual Encoders Are Secretly Few-Shot Anomaly Detectors](https://arxiv.org/abs/2510.01934)
*Guangyao Zhai,Yue Zhou,Xinyan Deng,Lars Heckler,Nassir Navab,Benjamin Busam*

Main category: cs.CV

TL;DR: FoundAD是一个少样本异常检测器，利用大型预训练模型学习到的图像嵌入差异来识别异常区域，在减少参数量的情况下实现了有竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 现有少样本异常检测方法在区分正态和异常特征方面存在挑战，尤其是在类别不可知的情况下，这主要是由于样本数量有限。

Method: FoundAD通过学习一个非线性映射算子到自然图像流形上，利用图像嵌入的差异来量化异常区域，从而实现异常检测。

Result: FoundAD在多类别检测方面表现出竞争力，并且相比先前的方法使用了更少的参数。该方法在多种基础编码器的支持下进行了评估，包括DINOv3。

Conclusion: FoundAD通过利用基础模型的图像嵌入差异来检测异常，为少样本异常检测提供了新的视角，并展示了其有效性和效率。

Abstract: Few-shot anomaly detection streamlines and simplifies industrial safety
inspection. However, limited samples make accurate differentiation between
normal and abnormal features challenging, and even more so under
category-agnostic conditions. Large-scale pre-training of foundation visual
encoders has advanced many fields, as the enormous quantity of data helps to
learn the general distribution of normal images. We observe that the anomaly
amount in an image directly correlates with the difference in the learnt
embeddings and utilize this to design a few-shot anomaly detector termed
FoundAD. This is done by learning a nonlinear projection operator onto the
natural image manifold. The simple operator acts as an effective tool for
anomaly detection to characterize and identify out-of-distribution regions in
an image. Extensive experiments show that our approach supports multi-class
detection and achieves competitive performance while using substantially fewer
parameters than prior methods. Backed up by evaluations with multiple
foundation encoders, including fresh DINOv3, we believe this idea broadens the
perspective on foundation features and advances the field of few-shot anomaly
detection.

</details>


### [43] [ClustViT: Clustering-based Token Merging for Semantic Segmentation](https://arxiv.org/abs/2510.01948)
*Fabio Montello,Ronja Güldenring,Lazaros Nalpantidis*

Main category: cs.CV

TL;DR: ClustViT通过引入可训练的聚类和再生模块来优化Vision Transformer，以解决密集预测问题，在保持高精度的同时显著减少计算量和提高推理速度。


<details>
  <summary>Details</summary>
Motivation: Vision Transformer在实际机器人系统中的应用受到二次注意力复杂度的限制，而现有的token合并方法对密集预测效果不佳。

Method: 提出ClustViT，包含一个聚类模块用于合并相似的tokens，以及一个再生模块用于恢复细节，以适应语义分割任务。

Result: ClustViT在三个不同数据集上实现了高达2.18倍的GFLOPs减少和1.64倍的推理加速，同时保持了可比的分割精度。

Conclusion: ClustViT通过有效的token合并策略，为Vision Transformer在密集预测任务（如语义分割）上的应用提供了计算效率和速度上的优势。

Abstract: Vision Transformers can achieve high accuracy and strong generalization
across various contexts, but their practical applicability on real-world
robotic systems is limited due to their quadratic attention complexity. Recent
works have focused on dynamically merging tokens according to the image
complexity. Token merging works well for classification but is less suited to
dense prediction. We propose ClustViT, where we expand upon the Vision
Transformer (ViT) backbone and address semantic segmentation. Within our
architecture, a trainable Cluster module merges similar tokens along the
network guided by pseudo-clusters from segmentation masks. Subsequently, a
Regenerator module restores fine details for downstream heads. Our approach
achieves up to 2.18x fewer GFLOPs and 1.64x faster inference on three different
datasets, with comparable segmentation accuracy. Our code and models will be
made publicly available.

</details>


### [44] [Patch-as-Decodable-Token: Towards Unified Multi-Modal Vision Tasks in MLLMs](https://arxiv.org/abs/2510.01954)
*Yongyi Su,Haojie Zhang,Shijie Li,Nanqing Liu,Jingyi Liao,Junyi Pan,Yuan Liu,Xiaofen Xing,Chong Sun,Chen Li,Nancy F. Chen,Shuicheng Yan,Xulei Yang,Xun Xu*

Main category: cs.CV

TL;DR: PaDT是一种新的多模态大模型（MLLM）范式，可以直接生成文本和视觉输出，解决了现有方法在视觉任务中依赖间接表示的局限性，并在多项视觉任务中达到最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉任务的MLLM依赖间接表示（如文本坐标），限制了性能，无法进行密集预测（如分割）。

Method: PaDT引入了视觉参考令牌（VRTs），将查询图像的视觉块嵌入与LLM的文本令牌结合。轻量级解码器将LLM的输出转换为检测、分割和接地预测。VRTs独立处理，并动态扩展嵌入表，以提高定位和区分能力。

Result: PaDT在四个视觉感知和理解任务中持续取得最先进的性能，优于许多更大的MLLM模型。

Conclusion: PaDT通过VRTs实现对文本和视觉输出的直接生成，有效解决了现有方法的局限性，并在各项视觉任务中展现出优越性能。

Abstract: Multimodal large language models (MLLMs) have advanced rapidly in recent
years. However, existing approaches for vision tasks often rely on indirect
representations, such as generating coordinates as text for detection, which
limits performance and prevents dense prediction tasks like segmentation. To
overcome these challenges, we introduce Patch-as-Decodable Token (PaDT), a
unified paradigm that enables MLLMs to directly generate both textual and
diverse visual outputs. Central to PaDT are Visual Reference Tokens (VRTs),
derived from visual patch embeddings of query images and interleaved seamlessly
with LLM's output textual tokens. A lightweight decoder then transforms LLM's
outputs into detection, segmentation, and grounding predictions. Unlike prior
methods, PaDT processes VRTs independently at each forward pass and dynamically
expands the embedding table, thus improving localization and differentiation
among similar objects. We further tailor a training strategy for PaDT by
randomly selecting VRTs for supervised fine-tuning and introducing a robust
per-token cross-entropy loss. Our empirical studies across four visual
perception and understanding tasks suggest PaDT consistently achieving
state-of-the-art performance, even compared with significantly larger MLLM
models. The code is available at https://github.com/Gorilla-Lab-SCUT/PaDT.

</details>


### [45] [TriAlignXA: An Explainable Trilemma Alignment Framework for Trustworthy Agri-product Grading](https://arxiv.org/abs/2510.01990)
*Jianfei Xie,Ziyang Li*

Main category: cs.CV

TL;DR: 本研究提出一个“信任金字塔”模型和“三角信任指数”（TTI）来解决在线生鲜电商的信任赤字问题，并构建了“TriAlignXA”可解释人工智能框架，以在生物特性、时效性和经济可行性这“不可能三角”中取得平衡，最终实现可信的在线农产品交易。


<details>
  <summary>Details</summary>
Motivation: 在线生鲜电商由于无法提供直接的感官体验，存在“信任赤字”问题。

Method: 提出“信任金字塔”模型，通过“双源验证”构建消费者信任。提出“三角信任指数”（TTI）量化评估“不可能三角”（生物特性、时效性、经济可行性）中的权衡。构建“TriAlignXA”可解释人工智能框架，包含生物自适应引擎、时效优化引擎和经济优化引擎，并通过“预映射机制”将过程数据编码到二维码中。

Result: 实验证实质量是信任的基石。所提出的框架在分级任务上实现了比基线模型显著更高的准确性，并经验上和理论上验证了其平衡“不可能三角”的能力。

Conclusion: 该研究为构建可信的在线农产品生态系统提供了从理论到实践的全面支持，为从算法决策到消费者信任的关键路径奠定了基础。

Abstract: The 'trust deficit' in online fruit and vegetable e-commerce stems from the
inability of digital transactions to provide direct sensory perception of
product quality. This paper constructs a 'Trust Pyramid' model through
'dual-source verification' of consumer trust. Experiments confirm that quality
is the cornerstone of trust. The study reveals an 'impossible triangle' in
agricultural product grading, comprising biological characteristics,
timeliness, and economic viability, highlighting the limitations of traditional
absolute grading standards. To quantitatively assess this trade-off, we propose
the 'Triangular Trust Index' (TTI). We redefine the role of algorithms from
'decision-makers' to 'providers of transparent decision-making bases',
designing the explainable AI framework--TriAlignXA. This framework supports
trustworthy online transactions within agricultural constraints through
multi-objective optimization. Its core relies on three engines: the
Bio-Adaptive Engine for granular quality description; the Timeliness
Optimization Engine for processing efficiency; and the Economic Optimization
Engine for cost control. Additionally, the "Pre-Mapping Mechanism" encodes
process data into QR codes, transparently conveying quality information.
Experiments on grading tasks demonstrate significantly higher accuracy than
baseline models. Empirical evidence and theoretical analysis verify the
framework's balancing capability in addressing the "impossible triangle". This
research provides comprehensive support--from theory to practice--for building
a trustworthy online produce ecosystem, establishing a critical pathway from
algorithmic decision-making to consumer trust.

</details>


### [46] [4DGS-Craft: Consistent and Interactive 4D Gaussian Splatting Editing](https://arxiv.org/abs/2510.01991)
*Lei Liu,Can Wang,Zhenghao Chen,Dong Xu*

Main category: cs.CV

TL;DR: 4DGS-Craft是一个一致且可交互的4DGS编辑框架，通过4D感知InstructPix2Pix模型、多视图网格模块和高斯选择机制来解决视图、时间和非编辑区域的一致性问题，并利用基于LLM的模块来理解和执行复杂文本指令，从而实现更一致、可控的4D场景编辑。


<details>
  <summary>Details</summary>
Motivation: 现有的4D高斯喷溅（4DGS）编辑方法在视图、时间和非编辑区域的一致性以及处理复杂的文本指令方面仍存在挑战。

Method: 提出4DGS-Craft框架：1. 引入4D感知InstructPix2Pix模型，结合4D VGGT几何特征和多视图网格模块，以确保视图和时间一致性。2. 采用高斯选择机制，仅优化编辑区域内的高斯点，以保持非编辑区域的一致性。3. 设计基于LLM的模块，通过用户指令模板和LLM推理，将复杂指令分解为原子编辑操作，以增强用户交互和处理复杂指令的能力。

Result: 该框架能够生成一致且可控的4D场景编辑结果，并能有效处理复杂的文本指令。

Conclusion: 4DGS-Craft框架通过结合多种技术，解决了现有4DGS编辑方法的局限性，实现了更优的一致性和可控性。

Abstract: Recent advances in 4D Gaussian Splatting (4DGS) editing still face challenges
with view, temporal, and non-editing region consistency, as well as with
handling complex text instructions. To address these issues, we propose
4DGS-Craft, a consistent and interactive 4DGS editing framework. We first
introduce a 4D-aware InstructPix2Pix model to ensure both view and temporal
consistency. This model incorporates 4D VGGT geometry features extracted from
the initial scene, enabling it to capture underlying 4D geometric structures
during editing. We further enhance this model with a multi-view grid module
that enforces consistency by iteratively refining multi-view input images while
jointly optimizing the underlying 4D scene. Furthermore, we preserve the
consistency of non-edited regions through a novel Gaussian selection mechanism,
which identifies and optimizes only the Gaussians within the edited regions.
Beyond consistency, facilitating user interaction is also crucial for effective
4DGS editing. Therefore, we design an LLM-based module for user intent
understanding. This module employs a user instruction template to define atomic
editing operations and leverages an LLM for reasoning. As a result, our
framework can interpret user intent and decompose complex instructions into a
logical sequence of atomic operations, enabling it to handle intricate user
commands and further enhance editing performance. Compared to related works,
our approach enables more consistent and controllable 4D scene editing. Our
code will be made available upon acceptance.

</details>


### [47] [Pure-Pass: Fine-Grained, Adaptive Masking for Dynamic Token-Mixing Routing in Lightweight Image Super-Resolution](https://arxiv.org/abs/2510.01997)
*Junyu Wu,Jie Tang,Jie Liu,Gangshan Wu*

Main category: cs.CV

TL;DR: Pure-Pass (PP) 是一种像素级掩蔽机制，通过识别纯像素并使它们免于昂贵的计算，解决了现有轻量级图像超分辨率方法的局限性，实现了优于 CAMixer 的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习超分辨率方法计算复杂，限制了其实际应用。CAMixer 提出了一种内容感知混合器，但存在适应性差、掩蔽粗糙和空间不灵活等问题。

Method: 提出了一种像素级掩蔽机制 Pure-Pass (PP)，利用固定的颜色中心点对像素进行分类，实现细粒度、空间灵活的掩蔽，并将其集成到 ATD-light 模型中，得到 PP-ATD-light。

Result: PP-ATD-light 在计算开销相似的情况下，在重建质量和参数效率方面均优于 CAMixer-ATD-light。

Conclusion: Pure-Pass (PP) 机制能够有效提升轻量级超分辨率模型的性能和效率，解决了现有方法的局限性。

Abstract: Image Super-Resolution (SR) aims to reconstruct high-resolution images from
low-resolution counterparts, but the computational complexity of deep
learning-based methods often hinders practical deployment. CAMixer is the
pioneering work to integrate the advantages of existing lightweight SR methods
and proposes a content-aware mixer to route token mixers of varied complexities
according to the difficulty of content recovery. However, several limitations
remain, such as poor adaptability, coarse-grained masking and spatial
inflexibility, among others. We propose Pure-Pass (PP), a pixel-level masking
mechanism that identifies pure pixels and exempts them from expensive
computations. PP utilizes fixed color center points to classify pixels into
distinct categories, enabling fine-grained, spatially flexible masking while
maintaining adaptive flexibility. Integrated into the state-of-the-art
ATD-light model, PP-ATD-light achieves superior SR performance with minimal
overhead, outperforming CAMixer-ATD-light in reconstruction quality and
parameter efficiency when saving a similar amount of computation.

</details>


### [48] [Generating Findings for Jaw Cysts in Dental Panoramic Radiographs Using GPT-4o: Building a Two-Stage Self-Correction Loop with Structured Output (SLSO) Framework](https://arxiv.org/abs/2510.02001)
*Nanaka Hosokawa,Ryo Takahashi,Tomoya Kitano,Yukihiro Iida,Chisako Muramatsu,Tatsuro Hayashi,Yuta Seino,Xiangrong Zhou,Takeshi Hara,Akitoshi Katsumata,Hiroshi Fujita*

Main category: cs.CV

TL;DR: 使用GPT-4o和SLSO框架自动生成颌骨囊肿影像学表现，提升了牙齿编号、牙齿移动和根部吸收等方面的准确性。


<details>
  <summary>Details</summary>
Motivation: 利用OpenAI GPT-4o的多模态能力，自动生成牙科全景X光片上的颌骨囊肿影像学表现，并提出SLSO框架以提高准确性。

Method: 构建了一个包含10个步骤的自纠正结构化输出（SLSO）框架，用于22例颌骨囊肿病例的图像输入、分析、结构化数据生成、牙齿编号一致性检查、迭代再生以及最终的影像学表现生成和一致性验证。并与传统的思维链（CoT）方法进行了比较。

Result: SLSO框架在牙齿编号、牙齿移动和根部吸收等方面的准确性分别提高了66.9%、33.3%和28.6%。在成功案例中，经过最多五次再生后可获得一致的结构化输出。该框架能够强制执行阴性发现描述，抑制幻觉，并提高牙齿编号的准确性。

Conclusion: SLSO框架在自动生成颌骨囊肿影像学表现方面显示出潜力，尤其在提高牙齿编号准确性方面有显著效果，但仍需进一步改进以提高整体性能，特别是在处理跨越多个牙齿的广泛病变方面存在局限性。

Abstract: In this study, we utilized the multimodal capabilities of OpenAI GPT-4o to
automatically generate jaw cyst findings on dental panoramic radiographs. To
improve accuracy, we constructed a Self-correction Loop with Structured Output
(SLSO) framework and verified its effectiveness. A 10-step process was
implemented for 22 cases of jaw cysts, including image input and analysis,
structured data generation, tooth number extraction and consistency checking,
iterative regeneration when inconsistencies were detected, and finding
generation with subsequent restructuring and consistency verification. A
comparative experiment was conducted using the conventional Chain-of-Thought
(CoT) method across seven evaluation items: transparency, internal structure,
borders, root resorption, tooth movement, relationships with other structures,
and tooth number. The results showed that the proposed SLSO framework improved
output accuracy for many items, with 66.9%, 33.3%, and 28.6% improvement rates
for tooth number, tooth movement, and root resorption, respectively. In the
successful cases, a consistently structured output was achieved after up to
five regenerations. Although statistical significance was not reached because
of the small size of the dataset, the overall SLSO framework enforced negative
finding descriptions, suppressed hallucinations, and improved tooth number
identification accuracy. However, the accurate identification of extensive
lesions spanning multiple teeth is limited. Nevertheless, further refinement is
required to enhance overall performance and move toward a practical finding
generation system.

</details>


### [49] [LiLa-Net: Lightweight Latent LiDAR Autoencoder for 3D Point Cloud Reconstruction](https://arxiv.org/abs/2510.02028)
*Mario Resino,Borja Pérez,Jaime Godoy,Abdulla Al-Kaff,Fernando García*

Main category: cs.CV

TL;DR: LiLa-Net是一个3D自编码器，仅使用激光雷达点云从真实交通环境中编码高效特征，通过简化结构和跳跃连接来提高性能，同时保持了准确重建原始点云的能力，并展示了良好的泛化性。


<details>
  <summary>Details</summary>
Motivation: 从真实交通环境中仅利用激光雷达点云提取高效特征，并设计一种能够准确重建原始点云的3D自编码器。

Method: 提出了一种名为LiLa-Net的3D自编码器架构，该架构利用了跳跃连接的概念，并减少了编码器层数和简化了跳跃连接，以在不消耗过多资源的情况下提高性能。

Result: LiLa-Net能够产生高效且具有代表性的潜在空间，从而能够准确地重建原始点云，并且在重建质量和性能之间取得了有效的平衡。此外，该模型还成功重建了与原始交通环境无关的对象，显示出强大的泛化能力。

Conclusion: LiLa-Net通过简化的3D自编码器架构，利用激光雷达点云实现了高效的特征编码和高质量的点云重建，并展现出良好的泛化性。

Abstract: This work proposed a 3D autoencoder architecture, named LiLa-Net, which
encodes efficient features from real traffic environments, employing only the
LiDAR's point clouds. For this purpose, we have real semi-autonomous vehicle,
equipped with Velodyne LiDAR. The system leverage skip connections concept to
improve the performance without using extensive resources as the
state-of-the-art architectures. Key changes include reducing the number of
encoder layers and simplifying the skip connections, while still producing an
efficient and representative latent space which allows to accurately
reconstruct the original point cloud. Furthermore, an effective balance has
been achieved between the information carried by the skip connections and the
latent encoding, leading to improved reconstruction quality without
compromising performance. Finally, the model demonstrates strong generalization
capabilities, successfully reconstructing objects unrelated to the original
traffic environment.

</details>


### [50] [kabr-tools: Automated Framework for Multi-Species Behavioral Monitoring](https://arxiv.org/abs/2510.02030)
*Jenna Kline,Maksim Kholiavchenko,Samuel Stevens,Nina van Tiel,Alison Zhong,Namrata Banerji,Alec Sheets,Sowbaranika Balasubramaniam,Isla Duporge,Matthew Thompson,Elizabeth Campolongo,Jackson Miliko,Neil Rosser,Tanya Berger-Wolf,Charles V. Stewart,Daniel I. Rubenstein*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: A comprehensive understanding of animal behavior ecology depends on scalable
approaches to quantify and interpret complex, multidimensional behavioral
patterns. Traditional field observations are often limited in scope,
time-consuming, and labor-intensive, hindering the assessment of behavioral
responses across landscapes. To address this, we present kabr-tools (Kenyan
Animal Behavior Recognition Tools), an open-source package for automated
multi-species behavioral monitoring. This framework integrates drone-based
video with machine learning systems to extract behavioral, social, and spatial
metrics from wildlife footage. Our pipeline leverages object detection,
tracking, and behavioral classification systems to generate key metrics,
including time budgets, behavioral transitions, social interactions, habitat
associations, and group composition dynamics. Compared to ground-based methods,
drone-based observations significantly improved behavioral granularity,
reducing visibility loss by 15% and capturing more transitions with higher
accuracy and continuity. We validate kabr-tools through three case studies,
analyzing 969 behavioral sequences, surpassing the capacity of traditional
methods for data capture and annotation. We found that, like Plains zebras,
vigilance in Grevy's zebras decreases with herd size, but, unlike Plains
zebras, habitat has a negligible impact. Plains and Grevy's zebras exhibit
strong behavioral inertia, with rare transitions to alert behaviors and
observed spatial segregation between Grevy's zebras, Plains zebras, and
giraffes in mixed-species herds. By enabling automated behavioral monitoring at
scale, kabr-tools offers a powerful tool for ecosystem-wide studies, advancing
conservation, biodiversity research, and ecological monitoring.

</details>


### [51] [GaussianMorphing: Mesh-Guided 3D Gaussians for Semantic-Aware Object Morphing](https://arxiv.org/abs/2510.02034)
*Mengtian Li,Yunshu Bai,Yimin Chu,Yijun Shen,Zhongmei Li,Weifeng Ge,Zhifeng Xie,Chaofeng Chen*

Main category: cs.CV

TL;DR: GaussianMorphing是一种新颖的框架，用于从多视角图像进行语义感知的3D形状和纹理变形，它利用网格引导的3D高斯泼溅（3DGS）进行高保真几何和外观建模，克服了先前方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 先前的3D形状和纹理变形方法通常依赖于点云或需要预定义的同胚映射，特别是在处理无纹理数据时存在局限性。

Method: 该方法采用网格引导的3D高斯泼溅（3DGS）进行几何和外观建模，通过将3D高斯点锚定在重建的网格块上，实现了几何一致的变形，并利用拓扑感知约束来保持纹理保真度。此外，它还通过将网格拓扑作为几何先验，并利用物理上合理的点轨迹来维持结构完整性，实现了无监督的语义对应。

Result: 在提出的TexMorph基准测试中，GaussianMorphing在颜色一致性误差（ΔE）上降低了22.2%，在EI上降低了26.2%，显著优于现有的2D/3D方法。

Conclusion: GaussianMorphing能够保留变形过程中的局部细节和全局语义一致性，并且不需要标注数据。

Abstract: We introduce GaussianMorphing, a novel framework for semantic-aware 3D shape
and texture morphing from multi-view images. Previous approaches usually rely
on point clouds or require pre-defined homeomorphic mappings for untextured
data. Our method overcomes these limitations by leveraging mesh-guided 3D
Gaussian Splatting (3DGS) for high-fidelity geometry and appearance modeling.
The core of our framework is a unified deformation strategy that anchors
3DGaussians to reconstructed mesh patches, ensuring geometrically consistent
transformations while preserving texture fidelity through topology-aware
constraints. In parallel, our framework establishes unsupervised semantic
correspondence by using the mesh topology as a geometric prior and maintains
structural integrity via physically plausible point trajectories. This
integrated approach preserves both local detail and global semantic coherence
throughout the morphing process with out requiring labeled data. On our
proposed TexMorph benchmark, GaussianMorphing substantially outperforms prior
2D/3D methods, reducing color consistency error ($\Delta E$) by 22.2% and EI by
26.2%. Project page: https://baiyunshu.github.io/GAUSSIANMORPHING.github.io/

</details>


### [52] [Zero-shot Human Pose Estimation using Diffusion-based Inverse solvers](https://arxiv.org/abs/2510.02043)
*Sahil Bhandary Karnoor,Romit Roy Choudhury*

Main category: cs.CV

TL;DR: InPose 提出了一种新颖的基于扩散模型的逆问题方法，用于解决传感器数量有限时的人体姿态估计问题，实现了零样本跨用户泛化。


<details>
  <summary>Details</summary>
Motivation: 现有的人体姿态估计方法在实际应用中，由于传感器数量有限，泛化能力较差，尤其是位置测量易受用户体型影响，导致跨用户泛化性能不佳。

Method: InPose 将姿态估计视为一个逆问题，利用预训练的扩散模型，仅依赖旋转测量进行条件化，并通过来自测量位置的似然项指导扩散模型的先验知识，从而生成最能解释稀疏的身体测量数据的姿态序列。

Result: InPose 算法能够利用旋转测量和位置测量，生成高度可能性的姿态序列，实现零样本跨用户泛化。

Conclusion: InPose 方法通过将姿态估计公式化为逆问题，并结合扩散模型的先验知识和测量数据的似然性，有效解决了传感器数量有限和用户体型差异带来的挑战，实现了零样本跨用户泛化。

Abstract: Pose estimation refers to tracking a human's full body posture, including
their head, torso, arms, and legs. The problem is challenging in practical
settings where the number of body sensors are limited. Past work has shown
promising results using conditional diffusion models, where the pose prediction
is conditioned on both <location, rotation> measurements from the sensors.
Unfortunately, nearly all these approaches generalize poorly across users,
primarly because location measurements are highly influenced by the body size
of the user. In this paper, we formulate pose estimation as an inverse problem
and design an algorithm capable of zero-shot generalization. Our idea utilizes
a pre-trained diffusion model and conditions it on rotational measurements
alone; the priors from this model are then guided by a likelihood term, derived
from the measured locations. Thus, given any user, our proposed InPose method
generatively estimates the highly likely sequence of poses that best explains
the sparse on-body measurements.

</details>


### [53] [VGDM: Vision-Guided Diffusion Model for Brain Tumor Detection and Segmentation](https://arxiv.org/abs/2510.02086)
*Arman Behnam*

Main category: cs.CV

TL;DR: 提出一种名为VGDM的基于Transformer的扩散模型，用于脑肿瘤的检测和分割，以解决U-Net在捕获长程依赖方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 卷积网络（如U-Net）在医学图像分割中存在捕获长程依赖能力有限的问题，这限制了其在复杂脑肿瘤结构分割上的性能。

Method: 提出VGDM框架，该框架以Vision Transformer作为扩散过程的核心，结合了全局上下文推理和迭代去噪，以提高体积准确性和边界精度。Vision Transformer能够更好地建模整个MRI扫描中的空间关系，而扩散模型则用于减少体素级误差和恢复肿瘤细节。

Result: 在脑肿瘤MRI数据集上的实验显示，与传统的U-Net模型相比，VGDM在Dice相似系数和Hausdorff距离等指标上取得了持续的提升。

Conclusion: 基于Transformer的扩散模型在脑肿瘤分割方面展现出超越现有技术的潜力，提高了分割的鲁棒性和可扩展性。

Abstract: Accurate detection and segmentation of brain tumors from magnetic resonance
imaging (MRI) are essential for diagnosis, treatment planning, and clinical
monitoring. While convolutional architectures such as U-Net have long been the
backbone of medical image segmentation, their limited capacity to capture
long-range dependencies constrains performance on complex tumor structures.
Recent advances in diffusion models have demonstrated strong potential for
generating high-fidelity medical images and refining segmentation boundaries.
  In this work, we propose VGDM: Vision-Guided Diffusion Model for Brain Tumor
Detection and Segmentation framework, a transformer-driven diffusion framework
for brain tumor detection and segmentation. By embedding a vision transformer
at the core of the diffusion process, the model leverages global contextual
reasoning together with iterative denoising to enhance both volumetric accuracy
and boundary precision. The transformer backbone enables more effective
modeling of spatial relationships across entire MRI volumes, while diffusion
refinement mitigates voxel-level errors and recovers fine-grained tumor
details.
  This hybrid design provides a pathway toward improved robustness and
scalability in neuro-oncology, moving beyond conventional U-Net baselines.
Experimental validation on MRI brain tumor datasets demonstrates consistent
gains in Dice similarity and Hausdorff distance, underscoring the potential of
transformer-guided diffusion models to advance the state of the art in tumor
segmentation.

</details>


### [54] [Mapping Historic Urban Footprints in France: Balancing Quality, Scalability and AI Techniques](https://arxiv.org/abs/2510.02097)
*Walid Rabehi,Marion Le Texier,Rémi Lemoy*

Main category: cs.CV

TL;DR: 本研究通过开发一个可扩展的深度学习流程，利用1925-1950年的历史地图系列，生成了法国历史上首次开放获取的全国范围内的城市足迹数据集，解决了早期法国城市扩张量化分析数据缺失的问题。


<details>
  <summary>Details</summary>
Motivation: 缺乏法国1970年代以前历史城市扩张的全国性数字城市足迹数据。

Method: 提出了一种新颖的双通道U-Net方法，首先生成初步地图以识别模糊区域（如文本和道路），然后进行有针对性的数据增强，最后通过第二个通道处理精炼数据集和初步结果，以减少辐射噪声和误报。

Result: 成功处理了覆盖法国大都市的941个高分辨率图块，生成的全国城市镶嵌图准确率为73%，有效捕捉了多样的城市格局，克服了标签和轮廓线等常见伪影。

Conclusion: 本研究成功创建了法国1925-1950年期间的全国城市足迹数据集，并公开了代码、训练数据集和结果，为未来研究长期城市化动态提供了支持。

Abstract: Quantitative analysis of historical urban sprawl in France before the 1970s
is hindered by the lack of nationwide digital urban footprint data. This study
bridges this gap by developing a scalable deep learning pipeline to extract
urban areas from the Scan Histo historical map series (1925-1950), which
produces the first open-access, national-scale urban footprint dataset for this
pivotal period. Our key innovation is a dual-pass U-Net approach designed to
handle the high radiometric and stylistic complexity of historical maps. The
first pass, trained on an initial dataset, generates a preliminary map that
identifies areas of confusion, such as text and roads, to guide targeted data
augmentation. The second pass uses a refined dataset and the binarized output
of the first model to minimize radiometric noise, which significantly reduces
false positives. Deployed on a high-performance computing cluster, our method
processes 941 high-resolution tiles covering the entirety of metropolitan
France. The final mosaic achieves an overall accuracy of 73%, effectively
capturing diverse urban patterns while overcoming common artifacts like labels
and contour lines. We openly release the code, training datasets, and the
resulting nationwide urban raster to support future research in long-term
urbanization dynamics.

</details>


### [55] [When Tracking Fails: Analyzing Failure Modes of SAM2 for Point-Based Tracking in Surgical Videos](https://arxiv.org/abs/2510.02100)
*Woowon Jang,Jiwon Im,Juseung Choi,Niki Rashidian,Wesley De Neve,Utku Ozbulak*

Main category: cs.CV

TL;DR: 点交互式视频目标分割在手术视频中的追踪在解剖目标上表现不佳，但在手术器械上具有竞争力。


<details>
  <summary>Details</summary>
Motivation: 评估点交互式视频目标分割（VOS）在模拟手术视频中的追踪能力，特别是在腹腔镜胆囊切除术中，并与分割掩模初始化进行比较，以了解其局限性。

Method: 系统性地分析腹腔镜胆囊切除术视频中点交互式追踪的失败模式，重点关注胆囊、抓钳和L型钩电钩三种手术目标，并与分割掩模初始化进行比较。

Result: 点交互式追踪在手术器械上表现具有竞争力，但在解剖目标上持续表现不佳，原因是组织相似性和边界模糊。

Conclusion: 点交互式追踪在手术器械上表现良好，但由于组织相似性和边界模糊，在解剖目标上表现不佳。通过选择和放置追踪点，可以提高手术视频分析的性能。

Abstract: Video object segmentation (VOS) models such as SAM2 offer promising zero-shot
tracking capabilities for surgical videos using minimal user input. Among the
available input types, point-based tracking offers an efficient and low-cost
alternative, yet its reliability and failure cases in complex surgical
environments are not well understood. In this work, we systematically analyze
the failure modes of point-based tracking in laparoscopic cholecystectomy
videos. Focusing on three surgical targets, the gallbladder, grasper, and
L-hook electrocautery, we compare the performance of point-based tracking with
segmentation mask initialization. Our results show that point-based tracking is
competitive for surgical tools but consistently underperforms for anatomical
targets, where tissue similarity and ambiguous boundaries lead to failure.
Through qualitative analysis, we reveal key factors influencing tracking
outcomes and provide several actionable recommendations for selecting and
placing tracking points to improve performance in surgical video analysis.

</details>


### [56] [FRIEREN: Federated Learning with Vision-Language Regularization for Segmentation](https://arxiv.org/abs/2510.02114)
*Ding-Ruei Shen*

Main category: cs.CV

TL;DR: 该研究提出了一种新的联邦学习任务FFREEDG，在这种任务中，模型在一个服务器的标记源数据集上进行预训练，然后在客户端上仅使用它们的未标记数据进行训练。为了解决这个任务，提出了一种名为FRIEREN的框架，该框架利用了视觉-语言模型（VFM）的知识，通过结合视觉和语言模态来解决领域转移问题，并使用弱到强的一致性学习策略在伪标签上进行鲁棒的本地训练。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦学习（FL）方法在处理领域转移（domain shifts）时面临挑战，特别是当客户端数据没有标签时。大多数现有方法要么不现实地假设远程客户端可以访问标记数据，要么未能利用现代视觉基础模型（VFMs）的力量。因此，需要一种能在客户端只有未标记数据的情况下，有效解决领域转移问题的联邦学习方法。

Method: 提出了一种名为FFREEDG的新任务，即模型在一个服务器的标记源数据集上进行预训练，然后在客户端上仅使用它们的未标记数据进行训练。为了解决FFREEDG任务，提出了一种名为FRIEREN的框架，该框架利用了视觉-语言模型（VFM）的知识，通过整合视觉和语言模态来解决领域转移问题。具体来说，FRIEREN使用一个由基于CLIP的文本嵌入引导的视觉-语言解码器来提高语义消歧能力，并采用一种弱到强的学习策略，在伪标签上进行鲁棒的本地训练。

Result: 在合成到真实和清晰到恶劣天气基准上的实验表明，所提出的FRIEREN框架能够有效地解决FFREEDG新任务，在性能上与现有的领域泛化和领域自适应方法相比具有竞争力。

Conclusion: 该研究成功地解决了一个新的、具有挑战性的联邦学习任务FFREEDG，并通过FRIEREN框架展示了利用视觉-语言模型和弱到强一致性学习来处理领域转移和无标签客户端数据的有效性。该框架在多个基准测试中取得了具有竞争力的结果，并为未来的相关研究奠定了基础。

Abstract: Federeated Learning (FL) offers a privacy-preserving solution for Semantic
Segmentation (SS) tasks to adapt to new domains, but faces significant
challenges from these domain shifts, particularly when client data is
unlabeled. However, most existing FL methods unrealistically assume access to
labeled data on remote clients or fail to leverage the power of modern Vision
Foundation Models (VFMs). Here, we propose a novel and challenging task,
FFREEDG, in which a model is pretrained on a server's labeled source dataset
and subsequently trained across clients using only their unlabeled data,
without ever re-accessing the source. To solve FFREEDG, we propose FRIEREN, a
framework that leverages the knowledge of a VFM by integrating vision and
language modalities. Our approach employs a Vision-Language decoder guided by
CLIP-based text embeddings to improve semantic disambiguation and uses a
weak-to-strong consistency learning strategy for robust local training on
pseudo-labels. Our experiments on synthetic-to-real and
clear-to-adverse-weather benchmarks demonstrate that our framework effectively
tackles this new task, achieving competitive performance against established
domain generalization and adaptation methods and setting a strong baseline for
future research.

</details>


### [57] [Unlocking Vision-Language Models for Video Anomaly Detection via Fine-Grained Prompting](https://arxiv.org/abs/2510.02155)
*Shu Zou,Xinyu Tian,Lukas Wesemann,Fabian Waschkowski,Zhaoyuan Yang,Jing Zhang*

Main category: cs.CV

TL;DR: ASK-Hint是一个结构化的提示框架，利用以动作为中心的知识来提高冻结的视觉语言模型（VLM）在视频异常检测（VAD）方面的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的提示方法过于抽象，忽略了复杂的异常行为的细粒度的人体-对象交互或动作语义，因此需要一种新的方法来提高VAD的性能。

Method: ASK-Hint将提示组织成语义上连贯的组（例如，暴力、财产犯罪、公共安全），并制定细粒度的引导性问题，使模型预测与区分性的视觉线索保持一致。

Result: 在UCF-Crime和XD-Violence数据集上的实验表明，ASK-Hint比现有方法在AUC方面持续提高，达到了最先进的性能。此外，该框架还提供了可解释的推理轨迹，并表现出强大的泛化能力。

Conclusion: ASK-Hint通过利用细粒度的、以动作为中心的知识，在提高VAD性能和可解释性方面取得了显著效果，证明了提示粒度的关键作用，并为可解释的VAD提供了一种新的、无需训练且通用的解决方案。

Abstract: Prompting has emerged as a practical way to adapt frozen vision-language
models (VLMs) for video anomaly detection (VAD). Yet, existing prompts are
often overly abstract, overlooking the fine-grained human-object interactions
or action semantics that define complex anomalies in surveillance videos. We
propose ASK-Hint, a structured prompting framework that leverages
action-centric knowledge to elicit more accurate and interpretable reasoning
from frozen VLMs. Our approach organizes prompts into semantically coherent
groups (e.g. violence, property crimes, public safety) and formulates
fine-grained guiding questions that align model predictions with discriminative
visual cues. Extensive experiments on UCF-Crime and XD-Violence show that
ASK-Hint consistently improves AUC over prior baselines, achieving
state-of-the-art performance compared to both fine-tuned and training-free
methods. Beyond accuracy, our framework provides interpretable reasoning traces
towards anomaly and demonstrates strong generalization across datasets and VLM
backbones. These results highlight the critical role of prompt granularity and
establish ASK-Hint as a new training-free and generalizable solution for
explainable video anomaly detection.

</details>


### [58] [GeoPurify: A Data-Efficient Geometric Distillation Framework for Open-Vocabulary 3D Segmentation](https://arxiv.org/abs/2510.02186)
*Weijia Dou,Xu Zhang,Yi Bin,Jian Liu,Bo Peng,Guoqing Wang,Yang Yang,Heng Tao Shen*

Main category: cs.CV

TL;DR: GeoPurify通过利用潜在的几何信息和学习到的亲和网络，有效缓解了2D视觉-语言模型(VLMs)到3D语义分割的权衡问题，仅使用约1.5%的训练数据即可达到或超越最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的2D VLMs到3D语义分割的特征迁移方法存在一个持续的权衡问题：直接投影2D特征到3D会导致预测结果嘈杂且分散，而强制几何一致性则需要昂贵的训练流程和大规模的3D标注数据。作者认为这种限制源于主流的分割-匹配范式，该范式未能调和2D语义与3D几何结构。

Method: 提出GeoPurify方法，该方法使用一个小的学生亲和网络（Student Affinity Network）来净化2D VLM生成的3D点特征。该净化过程利用了从3D自监督教师模型中提取的几何先验。在推理阶段，设计了一个几何引导池化模块（Geometry-Guided Pooling）来进一步去除点云的噪声，并确保语义和结构的连贯性。

Result: GeoPurify在主要的3D基准测试中取得了优于现有方法的性能，并且在训练数据量上具有显著的效率，仅使用了约1.5%的训练数据。

Conclusion: GeoPurify通过利用潜在的几何信息和学习到的亲和网络，有效缓解了2D到3D语义分割的权衡问题，实现了卓越的数据效率和最先进的性能。

Abstract: Recent attempts to transfer features from 2D Vision-Language Models (VLMs) to
3D semantic segmentation expose a persistent trade-off. Directly projecting 2D
features into 3D yields noisy and fragmented predictions, whereas enforcing
geometric coherence necessitates costly training pipelines and large-scale
annotated 3D data. We argue that this limitation stems from the dominant
segmentation-and-matching paradigm, which fails to reconcile 2D semantics with
3D geometric structure. The geometric cues are not eliminated during the
2D-to-3D transfer but remain latent within the noisy and view-aggregated
features. To exploit this property, we propose GeoPurify that applies a small
Student Affinity Network to purify 2D VLM-generated 3D point features using
geometric priors distilled from a 3D self-supervised teacher model. During
inference, we devise a Geometry-Guided Pooling module to further denoise the
point cloud and ensure the semantic and structural consistency. Benefiting from
latent geometric information and the learned affinity network, GeoPurify
effectively mitigates the trade-off and achieves superior data efficiency.
Extensive experiments on major 3D benchmarks demonstrate that GeoPurify
achieves or surpasses state-of-the-art performance while utilizing only about
1.5% of the training data. Our codes and checkpoints are available at
[https://github.com/tj12323/GeoPurify](https://github.com/tj12323/GeoPurify).

</details>


### [59] [Cross-Breed Pig Identification Using Auricular Vein Pattern Recognition: A Machine Learning Approach for Small-Scale Farming Applications](https://arxiv.org/abs/2510.02197)
*Emmanuel Nsengiyumvaa,Leonard Niyitegekaa,Eric Umuhoza*

Main category: cs.CV

TL;DR: 该研究提出了一种基于猪耳部静脉纹理的非侵入式生物识别方法，用于准确识别家畜。


<details>
  <summary>Details</summary>
Motivation: 现有的家畜识别方法（如耳标、微芯片）存在成本高、精度低、不适用于小农户等问题。

Method: 收集800张猪耳图像，利用计算机视觉技术提取静脉纹理特征，并使用支持向量机（SVM）进行分类识别。

Result: SVM模型在混合品种猪的识别精度达到98.12%，平均处理时间为8.3秒，证明了该方法的有效性和实时性。

Conclusion: 基于猪耳部静脉纹理的生物识别系统具有成本效益高、操作简便、识别精度高等优点，能够为资源有限的农业社区提供精准农业管理方案。

Abstract: Accurate livestock identification is a cornerstone of modern farming: it
supports health monitoring, breeding programs, and productivity tracking.
However, common pig identification methods, such as ear tags and microchips,
are often unreliable, costly, target pure breeds, and thus impractical for
small-scale farmers. To address this gap, we propose a noninvasive biometric
identification approach that leverages uniqueness of the auricular vein
patterns. To this end, we have collected 800 ear images from 20 mixed-breed
pigs (Landrace cross Pietrain and Duroc cross Pietrain), captured using a
standard smartphone and simple back lighting. A multistage computer vision
pipeline was developed to enhance vein visibility, extract structural and
spatial features, and generate biometric signatures. These features were then
classified using machine learning models. Support Vector Machines (SVM)
achieved the highest accuracy: correctly identifying pigs with 98.12% precision
across mixed-breed populations. The entire process from image processing to
classification was completed in an average of 8.3 seconds, demonstrating
feasibility for real-time farm deployment. We believe that by replacing fragile
physical identifiers with permanent biological markers, this system provides
farmers with a cost-effective and stress-free method of animal identification.
More broadly, the findings confirm the practicality of auricular vein
biometrics for digitizing livestock management, reinforcing its potential to
extend the benefits of precision farming to resource-constrained agricultural
communities.

</details>


### [60] [MMDEW: Multipurpose Multiclass Density Estimation in the Wild](https://arxiv.org/abs/2510.02213)
*Villanelle O'Reilly,Jonathan Cox,Georgios Leontidis,Marc Hanheide,Petra Bosilj,James Brown*

Main category: cs.CV

TL;DR: 提出一种基于Twins-Transformer和多尺度解码的多类别密度图估计框架，用于解决密集和遮挡场景下的物体计数问题，并在VisDrone和iSAID数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 在密集和遮挡场景下，传统的检测计数方法失效，因此需要密度图估计方法来解决此问题，特别是针对多类别计数。然而，现有的多类别计数方法存在类别间串扰的问题。

Method: 提出一个多类别计数框架，结合了Twins-Transformer视觉骨干网络和一个基于先进多尺度解码方法的多类别计数头。通过一个两任务设计，引入一个基于分割的类别聚焦模块，以在训练时抑制类别间的串扰。

Result: 在VisDrone和iSAID数据集上，与现有方法相比，该框架在平均绝对误差（MAE）上分别降低了33%、43%和64%。与YOLOv11的比较也证明了在密集场景下采用特定计数方法的必要性。此外，该方法应用于生物多样性监测数据集，展示了其在新领域的应用潜力。

Conclusion: 该方法在多类别密度图估计方面取得了优于现有方法的性能，并且通过引入类别聚焦模块有效解决了类别间串扰的问题。其区域损失设计为多类别计数开辟了新的应用领域，如生物多样性监测，为保护工作和生态洞察提供了支持。

Abstract: Density map estimation can be used to estimate object counts in dense and
occluded scenes where discrete counting-by-detection methods fail. We propose a
multicategory counting framework that leverages a Twins pyramid
vision-transformer backbone and a specialised multi-class counting head built
on a state-of-the-art multiscale decoding approach. A two-task design adds a
segmentation-based Category Focus Module, suppressing inter-category cross-talk
at training time. Training and evaluation on the VisDrone and iSAID benchmarks
demonstrates superior performance versus prior multicategory crowd-counting
approaches (33%, 43% and 64% reduction to MAE), and the comparison with YOLOv11
underscores the necessity of crowd counting methods in dense scenes. The
method's regional loss opens up multi-class crowd counting to new domains,
demonstrated through the application to a biodiversity monitoring dataset,
highlighting its capacity to inform conservation efforts and enable scalable
ecological insights.

</details>


### [61] [TempoControl: Temporal Attention Guidance for Text-to-Video Models](https://arxiv.org/abs/2510.02226)
*Shira Schiber,Ofir Lindenbaum,Idan Schwartz*

Main category: cs.CV

TL;DR: TempoControl通过优化交叉注意力图，在无需重新训练的情况下，实现了对生成视频中视觉概念的时间对齐控制，提高了视频生成的精细度和多样性。


<details>
  <summary>Details</summary>
Motivation: 现有的生成视频模型在时间控制方面存在不足，无法精确指定视觉元素出现的时间。

Method: TempoControl利用交叉注意力图，通过一种新颖的优化方法来引导概念的时间对齐。该方法结合了三种原则：通过相关性使注意力图的时间形状与控制信号对齐，通过能量放大可见性，以及通过熵保持空间焦点。

Result: TempoControl能够在生成视频时实现精确的时间控制，同时保持高质量和多样性。

Conclusion: TempoControl有效解决了生成视频的时间控制问题，并在各种应用中展现了其优势，如时间重排序、动作和音频对齐生成。

Abstract: Recent advances in generative video models have enabled the creation of
high-quality videos based on natural language prompts. However, these models
frequently lack fine-grained temporal control, meaning they do not allow users
to specify when particular visual elements should appear within a generated
sequence. In this work, we introduce TempoControl, a method that allows for
temporal alignment of visual concepts during inference, without requiring
retraining or additional supervision. TempoControl utilizes cross-attention
maps, a key component of text-to-video diffusion models, to guide the timing of
concepts through a novel optimization approach. Our method steers attention
using three complementary principles: aligning its temporal shape with a
control signal (via correlation), amplifying it where visibility is needed (via
energy), and maintaining spatial focus (via entropy). TempoControl allows
precise control over timing while ensuring high video quality and diversity. We
demonstrate its effectiveness across various video generation applications,
including temporal reordering for single and multiple objects, as well as
action and audio-aligned generation.

</details>


### [62] [RewardMap: Tackling Sparse Rewards in Fine-grained Visual Reasoning via Multi-Stage Reinforcement Learning](https://arxiv.org/abs/2510.02240)
*Sicheng Feng,Kaiwen Tuo,Song Wang,Lingdong Kong,Jianke Zhu,Huan Wang*

Main category: cs.CV

TL;DR: MLLMs在细粒度视觉推理方面存在挑战，尤其是在交通地图等结构化环境中。本文提出了RewardMap框架，通过增加奖励信号和多阶段强化学习来解决稀疏奖励和训练不稳定的问题，并在多个基准测试中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在处理细粒度视觉推理任务时存在不足，尤其是在像交通地图这类信息丰富且结构化的场景中，存在空间推理困难的问题。同时，标准的强化学习方法在这些任务中面临奖励稀疏和优化不稳定的挑战。

Method: 本文提出了RewardMap框架，该框架包含两个关键设计：1. 引入难度感知奖励机制，通过细节奖励来解决奖励稀疏问题，提供更丰富的监督信号。2. 采用多阶段强化学习策略，从简单的感知任务引导至复杂的推理任务，实现比传统SFT更有效的冷启动训练。此外，还构建了包含密集奖励信号的ReasonMap-Plus数据集，以支持冷启动训练。

Result: 在ReasonMap和ReasonMap-Plus数据集上的实验表明，RewardMap的每个组成部分都能带来性能提升，组合使用效果最佳。与基线模型相比，RewardMap在空间推理、细粒度视觉推理以及超越交通地图的通用任务共6个基准测试中，平均提升了3.47%的性能。

Conclusion: RewardMap框架通过引入包含细节奖励的难度感知奖励机制和多阶段强化学习策略，有效解决了MLLMs在细粒度视觉推理，特别是空间推理方面的挑战，显著提升了模型的视觉理解和推理能力。

Abstract: Fine-grained visual reasoning remains a core challenge for multimodal large
language models (MLLMs). The recently introduced ReasonMap highlights this gap
by showing that even advanced MLLMs struggle with spatial reasoning in
structured and information-rich settings such as transit maps, a task of clear
practical and scientific importance. However, standard reinforcement learning
(RL) on such tasks is impeded by sparse rewards and unstable optimization. To
address this, we first construct ReasonMap-Plus, an extended dataset that
introduces dense reward signals through Visual Question Answering (VQA) tasks,
enabling effective cold-start training of fine-grained visual understanding
skills. Next, we propose RewardMap, a multi-stage RL framework designed to
improve both visual understanding and reasoning capabilities of MLLMs.
RewardMap incorporates two key designs. First, we introduce a difficulty-aware
reward design that incorporates detail rewards, directly tackling the sparse
rewards while providing richer supervision. Second, we propose a multi-stage RL
scheme that bootstraps training from simple perception to complex reasoning
tasks, offering a more effective cold-start strategy than conventional
Supervised Fine-Tuning (SFT). Experiments on ReasonMap and ReasonMap-Plus
demonstrate that each component of RewardMap contributes to consistent
performance gains, while their combination yields the best results. Moreover,
models trained with RewardMap achieve an average improvement of 3.47% across 6
benchmarks spanning spatial reasoning, fine-grained visual reasoning, and
general tasks beyond transit maps, underscoring enhanced visual understanding
and reasoning capabilities.

</details>


### [63] [DragFlow: Unleashing DiT Priors with Region Based Supervision for Drag Editing](https://arxiv.org/abs/2510.02253)
*Zihan Zhou,Shilin Lu,Shuli Leng,Shaocong Zhang,Zhuming Lian,Xinlei Yu,Adams Wai-Kin Kong*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Drag-based image editing has long suffered from distortions in the target
region, largely because the priors of earlier base models, Stable Diffusion,
are insufficient to project optimized latents back onto the natural image
manifold. With the shift from UNet-based DDPMs to more scalable DiT with flow
matching (e.g., SD3.5, FLUX), generative priors have become significantly
stronger, enabling advances across diverse editing tasks. However, drag-based
editing has yet to benefit from these stronger priors. This work proposes the
first framework to effectively harness FLUX's rich prior for drag-based
editing, dubbed DragFlow, achieving substantial gains over baselines. We first
show that directly applying point-based drag editing to DiTs performs poorly:
unlike the highly compressed features of UNets, DiT features are insufficiently
structured to provide reliable guidance for point-wise motion supervision. To
overcome this limitation, DragFlow introduces a region-based editing paradigm,
where affine transformations enable richer and more consistent feature
supervision. Additionally, we integrate pretrained open-domain personalization
adapters (e.g., IP-Adapter) to enhance subject consistency, while preserving
background fidelity through gradient mask-based hard constraints. Multimodal
large language models (MLLMs) are further employed to resolve task ambiguities.
For evaluation, we curate a novel Region-based Dragging benchmark (ReD Bench)
featuring region-level dragging instructions. Extensive experiments on
DragBench-DR and ReD Bench show that DragFlow surpasses both point-based and
region-based baselines, setting a new state-of-the-art in drag-based image
editing. Code and datasets will be publicly available upon publication.

</details>


### [64] [From Frames to Clips: Efficient Key Clip Selection for Long-Form Video Understanding](https://arxiv.org/abs/2510.02262)
*Guangyu Sun,Archit Singhal,Burak Uzkent,Mubarak Shah,Chen Chen,Garin Kessler*

Main category: cs.CV

TL;DR: F2C 通过将帧选择扩展到包含时间信息的短片段，并采用自适应分辨率策略来解决视频语言模型中的“大海捞针”问题，从而在长视频理解方面取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 现有视频大模型（VLM）在处理海量视频帧时面临上下文窗口限制（“大海捞针”问题），现有方法通过稀疏帧选择来缓解，但会丢失重要的时序信息，影响对运动和事件连续性的推理。

Method: 提出了一种名为 F2C 的方法，该方法将帧选择扩展到短的、时间上连贯的片段（clips），并采用自适应分辨率策略来动态平衡空间分辨率和片段长度，以在固定计算预算内保持恒定的 token 数量。

Result: F2C 在 Video-MME、LongVideoBench 和 MLVU 三个长视频基准测试中，相较于均匀采样，分别取得了 8.1%、5.6% 和 10.3% 的性能提升。

Conclusion: 该研究强调了在帧选择中保留时间连贯性的重要性，并为扩展视频大语言模型在实际视频理解应用中的应用提供了一个有效途径。

Abstract: Video Large Language Models (VLMs) have achieved remarkable results on a
variety of vision language tasks, yet their practical use is limited by the
"needle in a haystack" problem: the massive number of visual tokens produced
from raw video frames exhausts the model's context window. Existing solutions
alleviate this issue by selecting a sparse set of frames, thereby reducing
token count, but such frame-wise selection discards essential temporal
dynamics, leading to suboptimal reasoning about motion and event continuity. In
this work we systematically explore the impact of temporal information and
demonstrate that extending selection from isolated key frames to key clips,
which are short, temporally coherent segments, improves video understanding. To
maintain a fixed computational budget while accommodating the larger token
footprint of clips, we propose an adaptive resolution strategy that dynamically
balances spatial resolution and clip length, ensuring a constant token count
per video. Experiments on three long-form video benchmarks demonstrate that our
training-free approach, F2C, outperforms uniform sampling up to 8.1%, 5.6%, and
10.3% on Video-MME, LongVideoBench and MLVU benchmarks, respectively. These
results highlight the importance of preserving temporal coherence in frame
selection and provide a practical pathway for scaling Video LLMs to real world
video understanding applications. Project webpage is available at
https://guangyusun.com/f2c .

</details>


### [65] [Paving the Way Towards Kinematic Assessment Using Monocular Video: A Preclinical Benchmark of State-of-the-Art Deep-Learning-Based 3D Human Pose Estimators Against Inertial Sensors in Daily Living Activities](https://arxiv.org/abs/2510.02264)
*Mario Medrano-Paredes,Carmen Fernández-González,Francisco-Javier Díaz-Pernas,Hichem Saoudi,Javier González-Alonso,Mario Martínez-Zarzuela*

Main category: cs.CV

TL;DR: 本文比较了基于单目视频的3D人体姿态估计模型和惯性测量单元（IMU）在真实世界条件下评估人类运动的有效性。


<details>
  <summary>Details</summary>
Motivation: 准确评估真实世界条件下的人类运动对于远程医疗、体育科学和康复至关重要。

Method: 使用VIDIMU数据集，该数据集包含使用普通视频摄像机和五个IMU捕获的13种日常活动。评估了四种基于深度学习的视频姿态估计框架（MotionAGFormer、MotionBERT、MMPose 2D-to-3D和NVIDIA BodyTrack）与IMU数据推导出的关节角度。

Result: MotionAGFormer表现最佳，在RMSE、MAE、Pearson相关性和R²方面均取得了最优异的指标。研究表明，视频和IMU技术都可用于实验室外的运动学评估，但两者在成本、可及性和精度方面存在权衡。

Conclusion: 研究明确了现成的视频模型在多大程度上可以为健康成年人提供临床上可行的运动学数据，以及它们与基于IMU的估计相比的不足之处，为开发稳健、经济高效且用户友好的远程医疗和患者监测解决方案提供了指导。

Abstract: Advances in machine learning and wearable sensors offer new opportunities for
capturing and analyzing human movement outside specialized laboratories.
Accurate assessment of human movement under real-world conditions is essential
for telemedicine, sports science, and rehabilitation. This preclinical
benchmark compares monocular video-based 3D human pose estimation models with
inertial measurement units (IMUs), leveraging the VIDIMU dataset containing a
total of 13 clinically relevant daily activities which were captured using both
commodity video cameras and five IMUs. During this initial study only healthy
subjects were recorded, so results cannot be generalized to pathological
cohorts. Joint angles derived from state-of-the-art deep learning frameworks
(MotionAGFormer, MotionBERT, MMPose 2D-to-3D pose lifting, and NVIDIA
BodyTrack) were evaluated against joint angles computed from IMU data using
OpenSim inverse kinematics following the Human3.6M dataset format with 17
keypoints. Among them, MotionAGFormer demonstrated superior performance,
achieving the lowest overall RMSE ($9.27\deg \pm 4.80\deg$) and MAE ($7.86\deg
\pm 4.18\deg$), as well as the highest Pearson correlation ($0.86 \pm 0.15$)
and the highest coefficient of determination $R^{2}$ ($0.67 \pm 0.28$). The
results reveal that both technologies are viable for out-of-the-lab kinematic
assessment. However, they also highlight key trade-offs between video- and
sensor-based approaches including costs, accessibility, and precision. This
study clarifies where off-the-shelf video models already provide clinically
promising kinematics in healthy adults and where they lag behind IMU-based
estimates while establishing valuable guidelines for researchers and clinicians
seeking to develop robust, cost-effective, and user-friendly solutions for
telehealth and remote patient monitoring.

</details>


### [66] [NeuroSwift: A Lightweight Cross-Subject Framework for fMRI Visual Reconstruction of Complex Scenes](https://arxiv.org/abs/2510.02266)
*Shiyi Zhang,Dong Liang,Yihang Zhou*

Main category: cs.CV

TL;DR: 通过结合低级特征的AutoKL和高级语义的CLIP，NeuroSwift在跨被试的fMRI解码任务上取得了最先进的性能，仅需少量计算资源和每位被试一小时的训练时间。


<details>
  <summary>Details</summary>
Motivation: 现有通过fMRI数据解码视觉信息的方法在跨被试泛化和计算效率方面存在挑战，这归因于被试间神经表征的差异以及大脑对复杂视觉输入的抽象语义编码。

Method: 提出NeuroSwift，一种整合了AutoKL（用于低级特征）和CLIP（用于语义）的扩散模型。CLIP适配器在带有COCO字幕的Stable Diffusion生成图像上进行训练。为了实现跨被试泛化，模型在一个被试上预训练，然后在新被试上仅对17%的参数（全连接层）进行微调，其余组件保持冻结。

Result: NeuroSwift在跨被试重建视觉刺激方面取得了最先进的性能，并且在轻量级GPU上仅需每位被试一小时的训练时间，优于现有方法。

Conclusion: NeuroSwift通过集成多层次的适配器并通过参数高效的微调策略，有效解决了跨被试fMRI解码中的泛化性和计算效率问题，为理解视觉神经机制提供了更优的工具。

Abstract: Reconstructing visual information from brain activity via computer vision
technology provides an intuitive understanding of visual neural mechanisms.
Despite progress in decoding fMRI data with generative models, achieving
accurate cross-subject reconstruction of visual stimuli remains challenging and
computationally demanding. This difficulty arises from inter-subject
variability in neural representations and the brain's abstract encoding of core
semantic features in complex visual inputs. To address these challenges, we
propose NeuroSwift, which integrates complementary adapters via diffusion:
AutoKL for low-level features and CLIP for semantics. NeuroSwift's CLIP Adapter
is trained on Stable Diffusion generated images paired with COCO captions to
emulate higher visual cortex encoding. For cross-subject generalization, we
pretrain on one subject and then fine-tune only 17 percent of parameters (fully
connected layers) for new subjects, while freezing other components. This
enables state-of-the-art performance with only one hour of training per subject
on lightweight GPUs (three RTX 4090), and it outperforms existing methods.

</details>


### [67] [microCLIP: Unsupervised CLIP Adaptation via Coarse-Fine Token Fusion for Fine-Grained Image Classification](https://arxiv.org/abs/2510.02270)
*Sathira Silva,Eman Ali,Chetan Arora,Muhammad Haris Khan*

Main category: cs.CV

TL;DR: microCLIP是一个用于细粒度图像分类的自训练框架，通过SOAP和TokenFusion模块来优化CLIP的视觉和文本表示，以捕捉细微的局部线索，实现了在13个基准测试中平均2.90%的准确率提升。


<details>
  <summary>Details</summary>
Motivation: CLIP在细粒度图像分类任务中表现不佳，因为它依赖于全局特征，忽略了细微的局部线索。现有的方法通过对齐LLM描述和CLIP的[CLS] token来注入细粒度知识，但忽略了空间精度。

Method: microCLIP是一个自训练框架，利用SOAP（显著性导向注意力池化）和TokenFusion模块，从patch embeddings中构建一个显著性引导的[FG] token，并将其与全局[CLS] token融合，以实现粗-细对齐。它还使用一个两头LLM驱动的分类器（一个固定的、一个可学习的）和一个动态知识聚合机制来稳定适应过程，并优化伪标签。

Result: microCLIP在13个细粒度基准测试中实现了2.90%的平均准确率提升，并且只需要轻微的适应。

Conclusion: microCLIP通过其独特的组件（SOAP、TokenFusion、两头分类器和动态知识聚合）有效地利用了CLIP的潜在细粒度信号，在细粒度图像分类任务上取得了显著的性能提升。

Abstract: Unsupervised adaptation of CLIP-based vision-language models (VLMs) for
fine-grained image classification requires sensitivity to microscopic local
cues. While CLIP exhibits strong zero-shot transfer, its reliance on coarse
global features restricts its performance on fine-grained classification tasks.
Prior efforts inject fine-grained knowledge by aligning large language model
(LLM) descriptions with the CLIP $\texttt{[CLS]}$ token; however, this approach
overlooks spatial precision. We propose $\textbf{microCLIP}$, a self-training
framework that jointly refines CLIP's visual and textual representations using
fine-grained cues. At its core is Saliency-Oriented Attention Pooling (SOAP)
within a lightweight TokenFusion module, which builds a saliency-guided
$\texttt{[FG]}$ token from patch embeddings and fuses it with the global
$\texttt{[CLS]}$ token for coarse-fine alignment. To stabilize adaptation, we
introduce a two-headed LLM-derived classifier: a frozen classifier that, via
multi-view alignment, provides a stable text-based prior for pseudo-labeling,
and a learnable classifier initialized from LLM descriptions and fine-tuned
with TokenFusion. We further develop Dynamic Knowledge Aggregation, which
convexly combines fixed LLM/CLIP priors with TokenFusion's evolving logits to
iteratively refine pseudo-labels. Together, these components uncover latent
fine-grained signals in CLIP, yielding a consistent $2.90\%$ average accuracy
gain across 13 fine-grained benchmarks while requiring only light adaptation.
Our code is available at https://github.com/sathiiii/microCLIP.

</details>


### [68] [VidGuard-R1: AI-Generated Video Detection and Explanation via Reasoning MLLMs and RL](https://arxiv.org/abs/2510.02282)
*Kyoungjun Park,Yifan Yang,Juheon Yi,Shicheng Zheng,Yifei Shen,Dongqi Han,Caihua Shan,Muhammad Muaz,Lili Qiu*

Main category: cs.CV

TL;DR: VidGuard-R1是首个利用分组相对策略优化（GRPO）微调多模态大语言模型（MLLM）的视频真实性检测器，可提供高精度判断和可解释性推理，在现有基准测试中达到最先进的零样本性能，准确率超过95%，并附带可公开获取的代码。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成视频的快速发展，急需有效的检测工具来减轻错误信息和声誉损害等社会风险，并且检测模型需要提供可解释的解释以确保透明度。

Method: VidGuard-R1通过分组相对策略优化（GRPO）和两个针对时间伪影和生成复杂性的专门奖励模型来微调Qwen-VL模型，并使用140k真实和AI生成视频的数据集进行训练。

Result: VidGuard-R1在现有基准测试中实现了最先进的零样本性能，附加训练后准确率超过95%。案例研究表明，VidGuard-R1能够生成精确且可解释的预测理由。

Conclusion: VidGuard-R1在视频真实性检测方面取得了最先进的性能，同时提供了可解释的推理，解决了AI生成视频带来的挑战。

Abstract: With the rapid advancement of AI-generated videos, there is an urgent need
for effective detection tools to mitigate societal risks such as misinformation
and reputational harm. In addition to accurate classification, it is essential
that detection models provide interpretable explanations to ensure transparency
for regulators and end users. To address these challenges, we introduce
VidGuard-R1, the first video authenticity detector that fine-tunes a
multi-modal large language model (MLLM) using group relative policy
optimization (GRPO). Our model delivers both highly accurate judgments and
insightful reasoning. We curate a challenging dataset of 140k real and
AI-generated videos produced by state-of-the-art generation models, carefully
designing the generation process to maximize discrimination difficulty. We then
fine-tune Qwen-VL using GRPO with two specialized reward models that target
temporal artifacts and generation complexity. Extensive experiments demonstrate
that VidGuard-R1 achieves state-of-the-art zero-shot performance on existing
benchmarks, with additional training pushing accuracy above 95%. Case studies
further show that VidGuard-R1 produces precise and interpretable rationales
behind its predictions. The code is publicly available at
https://VidGuard-R1.github.io.

</details>


### [69] [Self-Forcing++: Towards Minute-Scale High-Quality Video Generation](https://arxiv.org/abs/2510.02283)
*Justin Cui,Jie Wu,Ming Li,Tao Yang,Xiaojie Li,Rui Wang,Andrew Bai,Yuanhao Ban,Cho-Jui Hsieh*

Main category: cs.CV

TL;DR: 文章提出了一种简单有效的方法，通过利用教师模型的知识，在没有长视频教师监督或长视频数据集重新训练的情况下，缓解长视频生成中的质量下降问题，实现了视频长度的显著扩展。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型虽然在图像和视频生成方面表现出色，但其基于 Transformer 的架构导致计算成本高昂，尤其是在生成长视频时。先前通过蒸馏短时教师模型的方法，在学生模型生成超出训练范围的视频时，会出现明显的质量下降。

Method: 利用教师模型知识，通过从自生成的长视频中采样的片段来指导学生模型，以缓解长视频生成中的质量下降，无需长视频教师监督或长视频数据集重新训练。

Result: 该方法将视频长度扩展了 20 倍，并能生成长达 4 分钟 15 秒的视频，有效避免了过曝和误差累积等问题，且无需重新计算重叠帧。在标准基准和改进的基准上，实验结果表明该方法在保真度和一致性方面均优于基线方法。

Conclusion: 所提出的方法通过利用教师模型的知识指导学生模型，有效解决了长视频生成中的质量下降问题，实现了视频长度的显著扩展，并在保真度和一致性方面取得了优于现有方法的性能。

Abstract: Diffusion models have revolutionized image and video generation, achieving
unprecedented visual quality. However, their reliance on transformer
architectures incurs prohibitively high computational costs, particularly when
extending generation to long videos. Recent work has explored autoregressive
formulations for long video generation, typically by distilling from
short-horizon bidirectional teachers. Nevertheless, given that teacher models
cannot synthesize long videos, the extrapolation of student models beyond their
training horizon often leads to pronounced quality degradation, arising from
the compounding of errors within the continuous latent space. In this paper, we
propose a simple yet effective approach to mitigate quality degradation in
long-horizon video generation without requiring supervision from long-video
teachers or retraining on long video datasets. Our approach centers on
exploiting the rich knowledge of teacher models to provide guidance for the
student model through sampled segments drawn from self-generated long videos.
Our method maintains temporal consistency while scaling video length by up to
20x beyond teacher's capability, avoiding common issues such as over-exposure
and error-accumulation without recomputing overlapping frames like previous
methods. When scaling up the computation, our method shows the capability of
generating videos up to 4 minutes and 15 seconds, equivalent to 99.9% of the
maximum span supported by our base model's position embedding and more than 50x
longer than that of our baseline model. Experiments on standard benchmarks and
our proposed improved benchmark demonstrate that our approach substantially
outperforms baseline methods in both fidelity and consistency. Our long-horizon
videos demo can be found at https://self-forcing-plus-plus.github.io/

</details>


### [70] [Learning to Generate Object Interactions with Physics-Guided Video Diffusion](https://arxiv.org/abs/2510.02284)
*David Romero,Ariana Bermudez,Hao Li,Fabio Pizzati,Ivan Laptev*

Main category: cs.CV

TL;DR: KineMask是一种物理引导的视频生成方法，可以实现逼真的刚体控制、交互和效果，通过结合低级运动控制和高级文本条件，在复杂动力学现象合成方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型在生成物理上可信的物体交互方面存在不足，并且缺乏基于物理的控制机制，因此需要KineMask来解决这些局限性。

Method: KineMask采用两阶段训练策略，通过物体掩码逐渐去除未来运动监督，并结合了低级运动控制和高级文本条件（通过预测场景描述）来训练视频扩散模型（VDMs）。

Result: KineMask在真实场景中显著改进了物体交互，并在合成复杂动力学现象方面表现出色，实验证明其在同等大小模型中优于现有模型。

Conclusion: KineMask通过物理引导和多层次的条件控制，有效提升了视频生成中物体交互的真实性和可控性，为机器人和具身决策等领域提供了新的可能性。

Abstract: Recent models for video generation have achieved remarkable progress and are
now deployed in film, social media production, and advertising. Beyond their
creative potential, such models also hold promise as world simulators for
robotics and embodied decision making. Despite strong advances, however,
current approaches still struggle to generate physically plausible object
interactions and lack physics-grounded control mechanisms. To address this
limitation, we introduce KineMask, an approach for physics-guided video
generation that enables realistic rigid body control, interactions, and
effects. Given a single image and a specified object velocity, our method
generates videos with inferred motions and future object interactions. We
propose a two-stage training strategy that gradually removes future motion
supervision via object masks. Using this strategy we train video diffusion
models (VDMs) on synthetic scenes of simple interactions and demonstrate
significant improvements of object interactions in real scenes. Furthermore,
KineMask integrates low-level motion control with high-level textual
conditioning via predictive scene descriptions, leading to effective support
for synthesis of complex dynamical phenomena. Extensive experiments show that
KineMask achieves strong improvements over recent models of comparable size.
Ablation studies further highlight the complementary roles of low- and
high-level conditioning in VDMs. Our code, model, and data will be made
publicly available.

</details>


### [71] [MultiModal Action Conditioned Video Generation](https://arxiv.org/abs/2510.02287)
*Yichen Li,Antonio Torralba*

Main category: cs.CV

TL;DR: 当前的视频模型因缺乏细粒度控制而无法作为世界模型，而通用家用机器人需要实时精细的运动控制来处理精细任务和紧急情况。本研究提出了细粒度多模态动作来捕捉这种精确控制，并考虑了本体感觉、运动觉、力触觉和肌肉激活等感觉。这种多模态感知能够实现文本条件生成模型难以模拟的细粒度交互。为了有效模拟细粒度多感觉动作，我们开发了一种对齐这些模态但保留每种模态独特信息的特征学习范式。我们还提出了一种正则化方案，以增强动作轨迹特征在表示复杂交互动力学中的因果关系。实验表明，结合多模态感觉可以提高模拟精度并减少时间漂移。广泛的消融研究和下游应用证明了该方法的有效性和实用性。


<details>
  <summary>Details</summary>
Motivation: 通用家用机器人需要实时精细的运动控制来处理精细任务和紧急情况，而现有的视频模型在这方面存在不足。

Method: 提出细粒度多模态动作，融合本体感觉、运动觉、力触觉和肌肉激活等信息；开发特征学习范式对齐多模态信息；提出正则化方案增强因果关系。

Result: 结合多模态感觉提高了模拟精度并减少了时间漂移。

Conclusion: 所提出的细粒度多模态动作方法对于模拟精确控制和机器人应用是有效且实用的。

Abstract: Current video models fail as world model as they lack fine-graiend control.
General-purpose household robots require real-time fine motor control to handle
delicate tasks and urgent situations. In this work, we introduce fine-grained
multimodal actions to capture such precise control. We consider senses of
proprioception, kinesthesia, force haptics, and muscle activation. Such
multimodal senses naturally enables fine-grained interactions that are
difficult to simulate with text-conditioned generative models. To effectively
simulate fine-grained multisensory actions, we develop a feature learning
paradigm that aligns these modalities while preserving the unique information
each modality provides. We further propose a regularization scheme to enhance
causality of the action trajectory features in representing intricate
interaction dynamics. Experiments show that incorporating multimodal senses
improves simulation accuracy and reduces temporal drift. Extensive ablation
studies and downstream applications demonstrate the effectiveness and
practicality of our work.

</details>


### [72] [VideoNSA: Native Sparse Attention Scales Video Understanding](https://arxiv.org/abs/2510.02295)
*Enxin Song,Wenhao Chai,Shusheng Yang,Ethan Armand,Xiaojun Shan,Haiyang Xu,Jianwen Xie,Zhuowen Tu*

Main category: cs.CV

TL;DR: VideoNSA通过为视频采用原生稀疏注意力（NSA）来解决长视频理解中的上下文长度限制问题，并在长视频理解、时间推理和空间基准测试中取得了改进性能。


<details>
  <summary>Details</summary>
Motivation: 视频理解中的上下文长度限制导致模型错过关键过渡帧并难以保持长时连贯性。

Method: 将原生稀疏注意力（NSA）适配到视频语言模型，通过在216K视频指令数据集上进行端到端训练，并采用硬件感知的混合方法，为文本保留密集注意力，为视频采用NSA。

Result: VideoNSA在长视频理解、时间推理和空间基准测试方面优于其他基线方法。

Conclusion: VideoNSA能够可靠地扩展到128K tokens，并能有效地实现全局-局部注意力的分配，其分支使用模式具有任务依赖性，可学习的稀疏注意力有助于动态吸引注意力的焦点。

Abstract: Video understanding in multimodal language models remains limited by context
length: models often miss key transition frames and struggle to maintain
coherence across long time scales. To address this, we adapt Native Sparse
Attention (NSA) to video-language models. Our method, VideoNSA, adapts
Qwen2.5-VL through end-to-end training on a 216K video instruction dataset. We
employ a hardware-aware hybrid approach to attention, preserving dense
attention for text, while employing NSA for video. Compared to
token-compression and training-free sparse baselines, VideoNSA achieves
improved performance on long-video understanding, temporal reasoning, and
spatial benchmarks. Further ablation analysis reveals four key findings: (1)
reliable scaling to 128K tokens; (2) an optimal global-local attention
allocation at a fixed budget; (3) task-dependent branch usage patterns; and (4)
the learnable combined sparse attention help induce dynamic attention sinks.

</details>


### [73] [NoiseShift: Resolution-Aware Noise Recalibration for Better Low-Resolution Image Generation](https://arxiv.org/abs/2510.02307)
*Ruozhen He,Moayed Haji-Ali,Ziyan Yang,Vicente Ordonez*

Main category: cs.CV

TL;DR: NoiseShift是一种无需训练即可提高文本到图像扩散模型在低分辨率下生成质量的方法，通过重新校准噪声调度器来实现。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像扩散模型在固定分辨率下训练后，即使在生成低于训练分辨率的图像时也难以泛化，并且缺乏为不需要高分辨率图像的用户提供经济高效的解决方案。

Method: 提出了一种名为NoiseShift的训练无关方法，该方法通过根据分辨率大小重新校准去噪器，以解决噪声调度器在不同分辨率下具有不同感知效果的问题。

Result: 将NoiseShift应用于Stable Diffusion 3, Stable Diffusion 3.5和Flux-Dev模型后，在低分辨率图像生成方面得到了显著改善。在LAION-COCO数据集上，NoiseShift使SD3.5的FID平均提高了15.89%，SD3提高了8.56%，Flux-Dev提高了2.44%。在CelebA数据集上，SD3.5的FID平均提高了10.36%，SD3提高了5.19%，Flux-Dev提高了3.02%。

Conclusion: NoiseShift能够有效减轻分辨率依赖的伪影，并提高低分辨率图像生成的质量，同时无需修改模型架构或采样计划，并且与现有模型兼容。

Abstract: Text-to-image diffusion models trained on a fixed set of resolutions often
fail to generalize, even when asked to generate images at lower resolutions
than those seen during training. High-resolution text-to-image generators are
currently unable to easily offer an out-of-the-box budget-efficient alternative
to their users who might not need high-resolution images. We identify a key
technical insight in diffusion models that when addressed can help tackle this
limitation: Noise schedulers have unequal perceptual effects across
resolutions. The same level of noise removes disproportionately more signal
from lower-resolution images than from high-resolution images, leading to a
train-test mismatch. We propose NoiseShift, a training-free method that
recalibrates the noise level of the denoiser conditioned on resolution size.
NoiseShift requires no changes to model architecture or sampling schedule and
is compatible with existing models. When applied to Stable Diffusion 3, Stable
Diffusion 3.5, and Flux-Dev, quality at low resolutions is significantly
improved. On LAION-COCO, NoiseShift improves SD3.5 by 15.89%, SD3 by 8.56%, and
Flux-Dev by 2.44% in FID on average. On CelebA, NoiseShift improves SD3.5 by
10.36%, SD3 by 5.19%, and Flux-Dev by 3.02% in FID on average. These results
demonstrate the effectiveness of NoiseShift in mitigating resolution-dependent
artifacts and enhancing the quality of low-resolution image generation.

</details>


### [74] [Inferring Dynamic Physical Properties from Video Foundation Models](https://arxiv.org/abs/2510.02311)
*Guanqi Zhan,Xianzheng Ma,Weidi Xie,Andrew Zisserman*

Main category: cs.CV

TL;DR: 该研究预测视频中的动态物理属性，贡献了新数据集，并探索了三种推理方法：Oracle、视觉提示和多模态大语言模型（MLLM）。


<details>
  <summary>Details</summary>
Motivation: 研究如何从视频中预测动态物理属性，特别是那些需要时间信息才能推断的属性，如弹性和粘度。

Method: 收集了三个新的物理属性视频数据集（合成训练/测试和真实评估），并探索了三种推断方法：1. Oracle 方法（使用经典计算机视觉技术提供内在线索）；2. 视觉提示方法（使用可训练的提示向量在预训练的视频模型上进行交叉注意力）；3. 多模态大语言模型（MLLM）提示策略。

Result: 生成或自监督训练的视频基础模型在 Oracle 方法之后表现相似，而MLLM性能较差，但可以通过合适的提示进行改进。

Conclusion: 视频基础模型在预测动态物理属性方面显示出潜力，但MLLM需要进一步优化。Oracle方法提供了性能基准。

Abstract: We study the task of predicting dynamic physical properties from videos. More
specifically, we consider physical properties that require temporal information
to be inferred: elasticity of a bouncing object, viscosity of a flowing liquid,
and dynamic friction of an object sliding on a surface. To this end, we make
the following contributions: (i) We collect a new video dataset for each
physical property, consisting of synthetic training and testing splits, as well
as a real split for real world evaluation. (ii) We explore three ways to infer
the physical property from videos: (a) an oracle method where we supply the
visual cues that intrinsically reflect the property using classical computer
vision techniques; (b) a simple read out mechanism using a visual prompt and
trainable prompt vector for cross-attention on pre-trained video generative and
self-supervised models; and (c) prompt strategies for Multi-modal Large
Language Models (MLLMs). (iii) We show that video foundation models trained in
a generative or self-supervised manner achieve a similar performance, though
behind that of the oracle, and MLLMs are currently inferior to the other
models, though their performance can be improved through suitable prompting.

</details>


### [75] [Clink! Chop! Thud! -- Learning Object Sounds from Real-World Interactions](https://arxiv.org/abs/2510.02313)
*Mengyu Yang,Yiming Chen,Haozheng Pei,Siddhant Agarwal,Arun Balajee Vasudevan,James Hays*

Main category: cs.CV

TL;DR: 该研究提出 sounding object detection 任务，旨在评估模型将物体交互声与其相关物体关联的能力。


<details>
  <summary>Details</summary>
Motivation: 区分不同物体交互声的能力对于理解世界至关重要，但现有研究未能充分解决此问题。

Method: 提出一个多模态物体感知框架，利用包含物体分割掩码的视频进行训练，并采用 slot attention 视觉编码器来关注物体。

Result: 在 sounding object detection 任务及现有的多模态动作理解任务上均取得最先进的性能。

Conclusion: 所提出的框架能够有效地将物体交互声与其相关物体关联起来。

Abstract: Can a model distinguish between the sound of a spoon hitting a hardwood floor
versus a carpeted one? Everyday object interactions produce sounds unique to
the objects involved. We introduce the sounding object detection task to
evaluate a model's ability to link these sounds to the objects directly
involved. Inspired by human perception, our multimodal object-aware framework
learns from in-the-wild egocentric videos. To encourage an object-centric
approach, we first develop an automatic pipeline to compute segmentation masks
of the objects involved to guide the model's focus during training towards the
most informative regions of the interaction. A slot attention visual encoder is
used to further enforce an object prior. We demonstrate state of the art
performance on our new task along with existing multimodal action understanding
tasks.

</details>


### [76] [StealthAttack: Robust 3D Gaussian Splatting Poisoning via Density-Guided Illusions](https://arxiv.org/abs/2510.02314)
*Bo-Hsu Ke,You-Zhe Xie,Yu-Lun Liu,Wei-Chen Chiu*

Main category: cs.CV

TL;DR: 本研究提出了一种新的3D高斯泼溅（3DGS）鲁棒性分析方法，通过密度引导的 the poisoning 攻击来注入虚假物体，并引入基于核密度估计（KDE）的评估协议来衡量攻击难度。


<details>
  <summary>Details</summary>
Motivation: 随着NeRF和3DGS等3D场景表示方法的发展，其漏洞分析变得越来越重要。本研究旨在分析3DGS对图像级 the poisoning 攻击的鲁棒性，并提出一种新的攻击方法。

Method: 本研究提出了一种密度引导的 the poisoning 方法，利用核密度估计（KDE）识别低密度区域，并注入高斯点形成虚假物体。此外，还引入了一种自适应噪声策略来破坏多视图一致性。

Result: 所提出的密度引导 the poisoning 方法在注入虚假物体方面表现出优越的性能，能够从 the poisoned 视图中清晰地看到虚假物体，同时对无辜视图的影响最小。实验证明，该方法优于现有的技术。

Conclusion: 本研究成功地分析了3DGS对图像级 the poisoning 攻击的鲁棒性，并提出了一种有效的密度引导 the poisoning 方法。此外，提出的KDE评估协议为未来研究提供了系统性的评估方法。

Abstract: 3D scene representation methods like Neural Radiance Fields (NeRF) and 3D
Gaussian Splatting (3DGS) have significantly advanced novel view synthesis. As
these methods become prevalent, addressing their vulnerabilities becomes
critical. We analyze 3DGS robustness against image-level poisoning attacks and
propose a novel density-guided poisoning method. Our method strategically
injects Gaussian points into low-density regions identified via Kernel Density
Estimation (KDE), embedding viewpoint-dependent illusory objects clearly
visible from poisoned views while minimally affecting innocent views.
Additionally, we introduce an adaptive noise strategy to disrupt multi-view
consistency, further enhancing attack effectiveness. We propose a KDE-based
evaluation protocol to assess attack difficulty systematically, enabling
objective benchmarking for future research. Extensive experiments demonstrate
our method's superior performance compared to state-of-the-art techniques.
Project page: https://hentci.github.io/stealthattack/

</details>


### [77] [Optimal Control Meets Flow Matching: A Principled Route to Multi-Subject Fidelity](https://arxiv.org/abs/2510.02315)
*Eric Tillmann Bill,Enis Simsar,Thomas Hofmann*

Main category: cs.CV

TL;DR: 现有的文本到图像模型在处理单实体提示方面表现优异，但在多实体描述方面存在挑战，例如属性泄露、身份纠缠和主体遗漏。本文提出了首个理论框架，并提出了一种可优化的目标，用于引导采样动态以实现多实体保真度。通过将流匹配（FM）视为随机最优控制（SOC），我们将主体解纠缠制定为对训练好的FM采样器的控制。这产生了两种与架构无关的算法：（i）一种无需训练的测试时控制器，通过单次更新扰动基础速度；（ii）一种轻量级微调规则，称为Adjoint Matching，它将一个控制网络回归到反向伴随信号，同时保留基础模型的能力。该框架统一了现有的注意力启发式方法，通过流-扩散对应关系扩展到扩散模型，并提供了首个明确为多实体保真度设计的微调方法。实验结果表明，在Stable Diffusion 3.5、FLUX和Stable Diffusion XL上，两种算法在保持基础模型风格的同时，一致地提高了多实体对齐度。测试时控制器在普通GPU上高效运行，并且在有限提示上训练的微调控制器能够泛化到未见过的提示。此外，本文还提出了FOCUS（Flow Optimal Control for Unentangled Subjects），在多模型上实现了最先进的多实体保真度。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像（T2I）模型在处理包含多个主体的复杂文本描述时，常常出现属性泄露、身份纠缠和主体遗漏等问题，这限制了它们在实际应用中的表现。因此，需要一种新的方法来提高T2I模型在生成多实体图像时的保真度和准确性。

Method: 本文将流匹配（FM）问题通过随机最优控制（SOC）的视角进行重构，将多实体场景下的主体解纠缠问题转化为对FM采样器的控制问题。基于此理论框架，提出了两种算法：（1）一种无需训练的测试时控制器，通过对基础速度进行单次更新来扰动采样过程，以实现主体解纠缠。（2）一种名为Adjoint Matching的轻量级微调方法，通过训练一个控制网络来回归反向伴随信号，从而实现对多实体保真度的优化，同时保持基础模型的性能。此外，该框架还可以统一现有的注意力启发式方法，并能通过流-扩散对应关系扩展到扩散模型。

Result: 在Stable Diffusion 3.5、FLUX和Stable Diffusion XL等多个模型上进行实验，结果表明本文提出的两种算法（测试时控制器和Adjoint Matching）均能有效提高多实体图像生成的对齐度，同时保持了基础模型的风格。测试时控制器在普通GPU上运行效率高，且在有限数据上训练的微调控制器具有良好的泛化能力。提出的FOCUS方法在多模型上实现了最先进的多实体保真度。

Conclusion: 本文提出了首个用于提高文本到图像模型多实体生成保真度的理论框架，并通过两种新颖的算法（测试时控制器和Adjoint Matching）进行了有效验证。这些方法不仅解决了现有模型的局限性，而且在多个主流模型上取得了显著的性能提升，并具有高效和良好的泛化能力。提出的FOCUS方法更是达到了当前最优的多实体保真度水平。

Abstract: Text-to-image (T2I) models excel on single-entity prompts but struggle with
multi-subject descriptions, often showing attribute leakage, identity
entanglement, and subject omissions. We introduce the first theoretical
framework with a principled, optimizable objective for steering sampling
dynamics toward multi-subject fidelity. Viewing flow matching (FM) through
stochastic optimal control (SOC), we formulate subject disentanglement as
control over a trained FM sampler. This yields two architecture-agnostic
algorithms: (i) a training-free test-time controller that perturbs the base
velocity with a single-pass update, and (ii) Adjoint Matching, a lightweight
fine-tuning rule that regresses a control network to a backward adjoint signal
while preserving base-model capabilities. The same formulation unifies prior
attention heuristics, extends to diffusion models via a flow-diffusion
correspondence, and provides the first fine-tuning route explicitly designed
for multi-subject fidelity. Empirically, on Stable Diffusion 3.5, FLUX, and
Stable Diffusion XL, both algorithms consistently improve multi-subject
alignment while maintaining base-model style. Test-time control runs
efficiently on commodity GPUs, and fine-tuned controllers trained on limited
prompts generalize to unseen ones. We further highlight FOCUS (Flow Optimal
Control for Unentangled Subjects), which achieves state-of-the-art
multi-subject fidelity across models.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [78] [Uncovering Implicit Bias in Large Language Models with Concept Learning Dataset](https://arxiv.org/abs/2510.01219)
*Leroy Z. Wang*

Main category: cs.CL

TL;DR: 语言模型在概念学习中可能存在向上单调性的偏见，这种偏见在没有概念学习成分的直接提示测试中不太明显。


<details>
  <summary>Details</summary>
Motivation: 揭示大型语言模型中存在的隐式偏见。

Method: 使用包含概念学习任务的数据集，并通过上下文概念学习实验进行测试。

Result: 发现语言模型在概念学习中可能存在向上单调性的偏见，而在直接提示测试中这种偏见不明显。

Conclusion: 上下文概念学习是发现语言模型隐藏偏见的一种有效方法。

Abstract: We introduce a dataset of concept learning tasks that helps uncover implicit
biases in large language models. Using in-context concept learning experiments,
we found that language models may have a bias toward upward monotonicity in
quantifiers; such bias is less apparent when the model is tested by direct
prompting without concept learning components. This demonstrates that
in-context concept learning can be an effective way to discover hidden biases
in language models.

</details>


### [79] [Towards Open-Ended Discovery for Low-Resource NLP](https://arxiv.org/abs/2510.01220)
*Bonaventure F. P. Dossou,Henri Aïdasso*

Main category: cs.CL

TL;DR: AI应通过对话而非静态数据集动态学习低资源语言，利用人类反馈和模型不确定性来指导学习过程，促进以人为中心的AI和语言多样性保护。


<details>
  <summary>Details</summary>
Motivation: 低资源语言的自然语言处理受限于数据、正字法和标注流程；现有的大型语言模型因依赖大量数据和中心化基础设施，对代表性不足的社区而言不易获取。

Method: 提出一个基于联合人机不确定性的框架，结合模型的认知不确定性以及人类说话者的犹豫和置信信号，以指导互动、查询选择和记忆保留。

Result: 实现AI系统通过对话动态学习新语言，超越静态数据收集，实现人机协作中的动态学习。

Conclusion: AI应从数据提取转向参与性、共同适应性学习过程，以尊重和赋权社区，同时发现和保护世界语言多样性，实现以人为中心的AI原则。

Abstract: Natural Language Processing (NLP) for low-resource languages remains
fundamentally constrained by the lack of textual corpora, standardized
orthographies, and scalable annotation pipelines. While recent advances in
large language models have improved cross-lingual transfer, they remain
inaccessible to underrepresented communities due to their reliance on massive,
pre-collected data and centralized infrastructure. In this position paper, we
argue for a paradigm shift toward open-ended, interactive language discovery,
where AI systems learn new languages dynamically through dialogue rather than
static datasets. We contend that the future of language technology,
particularly for low-resource and under-documented languages, must move beyond
static data collection pipelines toward interactive, uncertainty-driven
discovery, where learning emerges dynamically from human-machine collaboration
instead of being limited to pre-existing datasets. We propose a framework
grounded in joint human-machine uncertainty, combining epistemic uncertainty
from the model with hesitation cues and confidence signals from human speakers
to guide interaction, query selection, and memory retention. This paper is a
call to action: we advocate a rethinking of how AI engages with human knowledge
in under-documented languages, moving from extractive data collection toward
participatory, co-adaptive learning processes that respect and empower
communities while discovering and preserving the world's linguistic diversity.
This vision aligns with principles of human-centered AI, emphasizing
interactive, cooperative model building between AI systems and speakers.

</details>


### [80] [Discourse vs emissions: Analysis of corporate narratives, symbolic practices, and mimicry through LLMs](https://arxiv.org/abs/2510.01222)
*Bertrand Kian Hassani,Yacoub Bahini,Rizwan Mushtaq*

Main category: cs.CL

TL;DR: 企业气候披露存在象征性报告问题，使用LLM分析发现风险叙事与承诺一致但量化目标脱节，大公司披露更多但目标不一致，披露风格趋同表明模仿行为。


<details>
  <summary>Details</summary>
Motivation: 气候变化增加了对透明、可比的企业气候披露的需求，但象征性报告削弱了其价值。

Method: 使用为气候传播进行微调的大型语言模型（LLM），开发了一个多维度框架，评估了828家美国上市公司的披露成熟度。四个分类器（情绪、承诺、特异性、目标野心）从可持续性和年度报告中提取叙述指标，并与排放量、市值和行业等公司属性相关联。

Result: 分析揭示了三个见解：1. 风险相关叙事通常与明确的承诺一致，但量化目标（例如净零承诺）与语气脱节；2. 规模更大、排放更高的公司比同行披露更多的承诺和行动，但量化目标不一致；3. 披露风格的广泛相似性表明存在模仿行为，降低了差异化和决策有用性。

Conclusion: 结果强调了LLM在ESG叙事分析中的价值，以及加强监管以连接承诺与可验证的转型策略的必要性。

Abstract: Climate change has increased demands for transparent and comparable corporate
climate disclosures, yet imitation and symbolic reporting often undermine their
value. This paper develops a multidimensional framework to assess disclosure
maturity among 828 U.S.listed firms using large language models (LLMs)
fine-tuned for climate communication. Four classifiers-sentiment, commitment,
specificity, and target ambition-extract narrative indicators from
sustainability and annual reports, which are linked to firm attributes such as
emissions, market capitalization, and sector. Analyses reveal three insights:
(1) risk-focused narratives often align with explicit commitments, but
quantitative targets (e.g., net-zero pledges) remain decoupled from tone; (2)
larger and higher-emitting firms disclose more commitments and actions than
peers, though inconsistently with quantitative targets; and (3) widespread
similarity in disclosure styles suggests mimetic behavior, reducing
differentiation and decision usefulness. These results highlight the value of
LLMs for ESG narrative analysis and the need for stronger regulation to connect
commitments with verifiable transition strategies.

</details>


### [81] [FOR-Prompting: From Objection to Revision via an Asymmetric Prompting Protocol](https://arxiv.org/abs/2510.01674)
*He Zhang,Anzhou Zhang,Jian Dai*

Main category: cs.CL

TL;DR: FOR-Prompting是一种新颖的、非对称的对话协议，它通过引入“异议者”角色来促进大语言模型的自我修正，从而提高了回答的准确性、连贯性和推理能力，并且对模型大小和类型具有普适性。


<details>
  <summary>Details</summary>
Motivation: 现有的推理协议（如CoT和ToT）缺乏一个明确的外部质疑机制来促使模型进行自我修正。FOR-Prompting旨在弥补这一不足，通过引入“异议者”来引导模型进行反思和改进。

Method: FOR-Prompting协议包含三个角色：防御者（提出答案）、异议者（提出问题式质疑，但不提供直接修复方案）和主持人（确保一致性并结束对话）。该协议通过角色扮演和问题引导来促进模型的自我修正。

Result: 在GSM8K数据集上，FOR-Prompting相比单一提示（single-prompt）的准确率提升了约22个百分点，与CoT的准确率相当。GPT-4.1评估显示，FOR-Prompting在推理和连贯性方面得分更高。该协议还能在无工具或人工监督的情况下纠正错误，并显著提升了小规模模型（如Llama3.2:1b）在GSM8K任务上的性能（约19%的准确率提升）。此外，在开放式任务中，FOR-Prompting能够增强探索和优化，并使假设和权衡更加明确。

Conclusion: FOR-Prompting是一种模型无关、纯粹基于提示的协议，适用于各种大小的模型（包括本地模型），无需重新训练。它通过角色结构化的对话促进了基于异议的推理，为研究和应用提供了新的途径，尤其是在提升小模型性能和支持个人设备使用方面具有潜力。

Abstract: Reasoning protocols such as Chain of Thought (CoT) and Tree of Thought (ToT)
organize internal deliberation but lack an explicit mechanism for external
questioning that elicits self-revision. We present FOR-Prompting (From
Objection to Revision Prompting), an asymmetric protocol where a Defender
proposes an answer, an Objectioner raises question-style objections with no
direct fixes, and a Host enforces consistency and closure. On GSM8K we observe
about a 22% point gain over single-prompt and accuracy on par with CoT, with
more than 10% higher ratings in reasoning and coherence from a uniform GPT 4.1
judge. FOR-Prompting also corrects mistakes without tools or human supervision
on tricky queries, and improves performance for small-scale model (approx. 19%
accuracy improved on Llama3.2:1b for GSM8K task), highlighting promise for
small models and on personal device use. Beyond factual QA, qualitative
analyses on open-ended tasks show enhanced exploration and refinement, with
dialogue traces that make assumptions and trade-offs explicit. The protocol is
model agnostic and operates purely at the prompt level through role-structured
turns, so it works with hosted and local models of different sizes without
retraining, and it supports large-scale study of objection-guided reasoning.

</details>


### [82] [Context Matters: Comparison of commercial large language tools in veterinary medicine](https://arxiv.org/abs/2510.01224)
*Tyler J Poore,Christopher J Pinard,Aleena Shabbir,Andrew Lagree,Andre Telfer,Kuan-Chuen Wu*

Main category: cs.CL

TL;DR: 市面上商业化的兽医LLM工具在总结兽医肿瘤记录方面的表现不同，其中Hachiko（产品1）表现最佳，而LLM-as-a-judge方法被证明是评估该领域NLP摘要的可行且可重复的方法。


<details>
  <summary>Details</summary>
Motivation: 评估市面上商业化的兽医LLM工具在兽医肿瘤记录总结方面的表现，并验证LLM-as-a-judge作为评估方法的有效性。

Method: 使用LLM-as-a-judge框架，并根据一套标准（事实准确性、完整性、时间顺序、临床相关性和组织性）对三个商业化兽医LLM工具生成的总结进行评分。同时，重复评估以检验评分框架的内部一致性。

Result: 产品1（Hachiko）在各项评分中均表现最佳，总分中位数为4.61，在事实准确性和时间顺序方面获得满分。产品2和产品3得分远低于产品1。LLM评分者在三次独立运行中表现出高度可重复性。

Conclusion: 兽医领域的商业化LLM工具具有重要意义，并且LLM-as-a-judge是一种可扩展且可重复的评估兽医临床NLP总结的方法。

Abstract: Large language models (LLMs) are increasingly used in clinical settings, yet
their performance in veterinary medicine remains underexplored. We evaluated
three commercially available veterinary-focused LLM summarization tools
(Product 1 [Hachiko] and Products 2 and 3) on a standardized dataset of
veterinary oncology records. Using a rubric-guided LLM-as-a-judge framework,
summaries were scored across five domains: Factual Accuracy, Completeness,
Chronological Order, Clinical Relevance, and Organization. Product 1 achieved
the highest overall performance, with a median average score of 4.61 (IQR:
0.73), compared to 2.55 (IQR: 0.78) for Product 2 and 2.45 (IQR: 0.92) for
Product 3. It also received perfect median scores in Factual Accuracy and
Chronological Order. To assess the internal consistency of the grading
framework itself, we repeated the evaluation across three independent runs. The
LLM grader demonstrated high reproducibility, with Average Score standard
deviations of 0.015 (Product 1), 0.088 (Product 2), and 0.034 (Product 3).
These findings highlight the importance of veterinary-specific commercial LLM
tools and demonstrate that LLM-as-a-judge evaluation is a scalable and
reproducible method for assessing clinical NLP summarization in veterinary
medicine.

</details>


### [83] [ClaimCheck: Real-Time Fact-Checking with Small Language Models](https://arxiv.org/abs/2510.01226)
*Akshith Reddy Putta,Jacob Devasier,Chengkai Li*

Main category: cs.CL

TL;DR: ClaimCheck是一个LLM驱动的自动事实核查系统，使用小型语言模型和实时网络证据来验证现实世界中的声明。


<details>
  <summary>Details</summary>
Motivation: 传统的事实核查系统依赖大型、闭源模型和静态知识库，而ClaimCheck旨在提供一个透明、可解释且计算成本更低的事实核查方法。

Method: ClaimCheck采用分步验证流程，包括网络搜索查询规划、网络证据检索与摘要、证据综合与重新检索，以及声明判断评估。该流程针对小型语言模型进行优化。

Result: ClaimCheck在AVeriTeC数据集上达到了76.4%的准确率，超过了使用LLaMA3.1 70B和GPT-4o的先前方法，证明了即使使用小型模型（如Qwen3-4B）也能实现最先进的性能。

Conclusion: 精心设计的模块化结构和提示策略能够克服小型语言模型的局限性，ClaimCheck的开源和公共演示提高了其可访问性和透明度。

Abstract: We introduce ClaimCheck, an LLM-guided automatic fact-checking system
designed to verify real-world claims using live Web evidence and small language
models. Unlike prior systems that rely on large, closed-source models and
static knowledge stores, ClaimCheck employs a transparent, stepwise
verification pipeline that mirrors human fact-checking workflows consisting of
Web search query planning, Web-based evidence retrieval and summarization,
evidence synthesis and re-retrieval, and claim verdict evaluation. Each module
is optimized for small LLMs, allowing the system to deliver accurate and
interpretable fact-checking with significantly lower computational
requirements. Despite using a much smaller Qwen3-4B model, ClaimCheck achieves
state-of-the-art accuracy of 76.4% on the AVeriTeC dataset, outperforming
previous approaches using LLaMA3.1 70B and GPT-4o. Extensive ablations
demonstrate that careful modular design and prompting strategies can overcome
the limitations of smaller LLMs. To promote accessibility and transparency, we
provide a public demo at https://idir.uta.edu/claimcheck.

</details>


### [84] [EEFSUVA: A New Mathematical Olympiad Benchmark](https://arxiv.org/abs/2510.01227)
*Nicole N Khatibi,Daniil A. Radamovich,Michael P. Brenner*

Main category: cs.CL

TL;DR: LLM在数学推理能力上可能被高估，新基准EEFSUVA显示其表现下降。


<details>
  <summary>Details</summary>
Motivation: 评估当前数学基准衡量LLM真实数学推理能力的情况，并指出其潜在的数据污染和过于关注熟悉问题类型的问题。

Method: 提出EEFSUVA新基准，该基准包含来自东欧及前苏联国家奥林匹克竞赛的题目，这些题目难度相当但在线语料库中较少出现，旨在更全面地评估LLM的数学理解能力。

Result: 初步结果表明，最先进的LLM在EEFSUVA基准上的表现明显逊于其他奥赛风格的基准。

Conclusion: 现有基准可能高估了LLM的数学推理能力，需要更广泛的评估数据集来全面评估模型能力并指导未来发展。

Abstract: Recent breakthroughs have spurred claims that large language models (LLMs)
match gold medal Olympiad to graduate level proficiency on mathematics
benchmarks. In this work, we examine these claims in detail and assess the
extent to which current benchmarks capture genuine LLM mathematical reasoning.
The composition of these benchmarks, primarily drawing from the International
Mathematics Olympiad (IMO) and related competitions, may overstate models
reasoning ability due to potential data contamination and a narrow focus on
familiar problem types. To enable a more holistic assessment of mathematical
understanding, we introduce EEFSUVA, a novel benchmark curated from under
circulated regional and national Olympiads of Eastern Europe and the countries
from the former Soviet Union. These contests feature problems of comparable
difficulty to the IMO and are renowned for demanding nonstandard
problem-solving techniques, yet their problems are far less prevalent in online
corpora. Preliminary results suggest that even state-of-the-art LLMs exhibit a
notable performance decline on EEFSUVA relative to other Olympiad-style
benchmarks. These findings also suggest the potential importance of broader
evaluation datasets for a fuller assessment of mathematical reasoning and for
guiding future model development.

</details>


### [85] [Who is In Charge? Dissecting Role Conflicts in Instruction Following](https://arxiv.org/abs/2510.01228)
*Siqi Zeng*

Main category: cs.CL

TL;DR: 大型语言模型在遵循指令层级时表现出脆弱性，尽管它们能有效遵循社会线索，但对系统指令的服从却不稳定。该研究通过线性探测、直接logit归因和引导实验，揭示了模型内部指令冲突的编码和解决机制，并提出需要更轻量级的层级敏感对齐方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明大型语言模型在遵循系统提示（覆盖用户输入）的层级指令方面存在困难，反而更倾向于遵循社会线索（如权威或共识）。本研究旨在深入探究这一现象的机制，并提供解决方案。

Method: 本研究结合了线性探测、直接logit归因和引导实验三种方法，在大型数据集上分析了模型在处理系统-用户指令冲突和社会线索时的行为和内部表征。

Result: 线性探测发现，系统-用户冲突和 بههcial 冲突在模型早期编码中形成不同的子空间。直接logit归因显示，模型在处理系统-用户冲突时内部冲突检测更强，但在解决社会线索方面表现更一致。引导实验表明，尽管模型利用了社会线索，但其产生的向量意外地以一种与角色无关的方式增强了指令遵循能力。

Conclusion: 模型在系统指令遵循上表现出脆弱性，这可以部分归因于其在处理不同类型冲突时的机制差异。尽管模型利用社会线索，但其对层级指令的遵循仍需改进，因此需要开发更轻量级的、能够敏感处理指令层级的对齐方法。

Abstract: Large language models should follow hierarchical instructions where system
prompts override user inputs, yet recent work shows they often ignore this rule
while strongly obeying social cues such as authority or consensus. We extend
these behavioral findings with mechanistic interpretations on a large-scale
dataset. Linear probing shows conflict-decision signals are encoded early, with
system-user and social conflicts forming distinct subspaces. Direct Logit
Attribution reveals stronger internal conflict detection in system-user cases
but consistent resolution only for social cues. Steering experiments show that,
despite using social cues, the vectors surprisingly amplify instruction
following in a role-agnostic way. Together, these results explain fragile
system obedience and underscore the need for lightweight hierarchy-sensitive
alignment methods.

</details>


### [86] [Enhancing Transformer-Based Rerankers with Synthetic Data and LLM-Based Supervision](https://arxiv.org/abs/2510.01229)
*Dimitar Peshevski,Kiril Blazhevski,Martin Popovski,Gjorgji Madjarov*

Main category: cs.CL

TL;DR: LLMs可用于生成合成数据以微调更小的模型，用于文档重排，从而降低计算成本并提高性能。


<details>
  <summary>Details</summary>
Motivation: 当前的文档重排方法要么计算成本高（使用LLMs），要么需要大量人工标注数据（微调小模型）。

Method: 使用LLMs生成合成查询和标注样本（包括正样本和难负样本），然后用这些合成数据和对比学习（LCE损失）来微调一个小的Transformer模型。

Result: 在MedQuAD数据集上，所提出的方法显著提高了模型在目标域内的性能，并且在目标域外任务上也有良好的泛化能力。

Conclusion: 通过利用LLMs进行数据生成和监督，而不是直接用于推理，可以有效降低计算成本，同时保持强大的文档重排能力。

Abstract: Effective document reranking is essential for improving search relevance
across diverse applications. While Large Language Models (LLMs) excel at
reranking due to their deep semantic understanding and reasoning, their high
computational cost makes them impractical for many real-world deployments.
Fine-tuning smaller, task-specific models is a more efficient alternative but
typically depends on scarce, manually labeled data. To overcome this, we
propose a novel pipeline that eliminates the need for human-labeled
query-document pairs. Our method uses LLMs to generate synthetic queries from
domain-specific corpora and employs an LLM-based classifier to label positive
and hard-negative pairs. This synthetic dataset is then used to fine-tune a
smaller transformer model with contrastive learning using Localized Contrastive
Estimation (LCE) loss. Experiments on the MedQuAD dataset show that our
approach significantly boosts in-domain performance and generalizes well to
out-of-domain tasks. By using LLMs for data generation and supervision rather
than inference, we reduce computational costs while maintaining strong
reranking capabilities.

</details>


### [87] [Geometric Structures and Patterns of Meaning: A PHATE Manifold Analysis of Chinese Character Embeddings](https://arxiv.org/abs/2510.01230)
*Wen G. Gong*

Main category: cs.CL

TL;DR: PHATE流形分析揭示了中文嵌入中的几何模式，内容词聚类，功能词分支，并揭示了几何复杂性与语义内容的相关性。


<details>
  <summary>Details</summary>
Motivation: 研究中文嵌入中的几何模式，以计算方式验证传统语言学理论，并建立语义组织几何分析的新框架。

Method: 使用PHATE流形分析，通过交叉验证七种嵌入模型和八种降维方法，分析了1000多个汉字及其123个短语的子网络。

Result: 内容词呈现聚类模式，功能词呈现分支模式。有意义的字符显示出丰富的几何多样性，而结构部首则收缩成紧密的集群。子网络分析表明，从基本字符到短语存在系统性的语义扩展。

Conclusion: 几何模式分析为中文语义组织提供了新的见解，并支持了传统语言学理论。

Abstract: We systematically investigate geometric patterns in Chinese character
embeddings using PHATE manifold analysis. Through cross-validation across seven
embedding models and eight dimensionality reduction methods, we observe
clustering patterns for content words and branching patterns for function
words. Analysis of over 1000 Chinese characters across 12 semantic domains
reveals that geometric complexity correlates with semantic content: meaningful
characters exhibit rich geometric diversity while structural radicals collapse
into tight clusters. The comprehensive child-network analysis (123 phrases)
demonstrates systematic semantic expansion from elemental character. These
findings provide computational evidence supporting traditional linguistic
theory and establish a novel framework for geometric analysis of semantic
organization.

</details>


### [88] [Trustworthy Summarization via Uncertainty Quantification and Risk Awareness in Large Language Models](https://arxiv.org/abs/2510.01231)
*Shuaidong Pan,Di Wu*

Main category: cs.CL

TL;DR: 该研究提出了一个结合了不确定性量化和风险感知机制的大型语言模型框架，以提高高风险场景下自动摘要的可靠性。


<details>
  <summary>Details</summary>
Motivation: 在高风险决策场景下，自动摘要的可靠性至关重要，以应对信息过载并支持准确的决策。

Method: 提出一个基于条件生成的大模型，引入贝叶斯推理进行不确定性建模，并通过预测分布熵度量不确定性。模型采用熵正则化和风险感知损失的联合优化，并结合风险评分和调节模块，以确保摘要保留核心内容、显式表达风险属性并提高可信度。

Result: 实验和敏感性分析表明，该方法显著提高了高风险应用中摘要的鲁棒性和可靠性，同时保持了流畅性和语义完整性。

Conclusion: 该研究为可信赖的摘要提供了系统性解决方案，并在方法层面上展示了可扩展性和实用价值。

Abstract: This study addresses the reliability of automatic summarization in high-risk
scenarios and proposes a large language model framework that integrates
uncertainty quantification and risk-aware mechanisms. Starting from the demands
of information overload and high-risk decision-making, a conditional
generation-based summarization model is constructed, and Bayesian inference is
introduced during generation to model uncertainty in the parameter space, which
helps avoid overconfident predictions. The uncertainty level of the generated
content is measured using predictive distribution entropy, and a joint
optimization of entropy regularization and risk-aware loss is applied to ensure
that key information is preserved and risk attributes are explicitly expressed
during information compression. On this basis, the model incorporates risk
scoring and regulation modules, allowing summaries to cover the core content
accurately while enhancing trustworthiness through explicit risk-level prompts.
Comparative experiments and sensitivity analyses verify that the proposed
method significantly improves the robustness and reliability of summarization
in high-risk applications while maintaining fluency and semantic integrity.
This research provides a systematic solution for trustworthy summarization and
demonstrates both scalability and practical value at the methodological level.

</details>


### [89] [Benchmark Profiling: Mechanistic Diagnosis of LLM Benchmarks](https://arxiv.org/abs/2510.01232)
*Dongjun Kim,Gyuho Shim,Yongchan Chun,Minhyuk Kim,Chanjun Park,Heuiseok Lim*

Main category: cs.CL

TL;DR: 基准测试的得分并不能完全代表大型语言模型的真实能力，因为它们掩盖了任务所需的技能组合。本研究提出了一种名为“基准画像”的诊断框架，该框架将模型在基准测试中的表现分解为十种认知能力，并量化每种能力对模型成功的贡献度。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试的得分往往会过度估计大型语言模型的真实能力，因为它们未能区分任务所需的具体技能。缺乏系统性的方法来验证基准测试是否真正测量了其声称的能力。

Method: 提出“基准画像”诊断框架，结合基于梯度的重要性评分和参数消融技术，计算“能力影响得分”（AIS），量化每种能力对模型在特定基准测试中表现的贡献度。

Result: 分析了三种指令调优模型在十个常用基准测试上的表现，发现：（1）大多数基准测试需要多种能力；（2）标签相似的数据集所需能力组合不同；（3）代码生成基准测试受益于广泛的、多技能的提升，而非狭窄的领域特定微调；（4）与任务无关的能力可能对模型表现产生负面影响。

Conclusion: “基准画像”框架能够解释为何模型性能提升不总能转化为用户感知的能力，并为基准测试审计和模型可解释性提供了透明的工具。

Abstract: Large Language Models are commonly judged by their scores on standard
benchmarks, yet such scores often overstate real capability since they mask the
mix of skills a task actually demands. For example, ARC is assumed to test
reasoning, while HellaSwag is designed to evaluate commonsense. However, we
lack a systematic way to verify if these benchmarks actually measure these
labels. We introduce Benchmark Profiling, a diagnostic framework that
decomposes benchmark performance into ten cognitively grounded abilities. The
method combines gradient-based importance scoring with targeted parameter
ablation to compute an Ability Impact Score (AIS) that quantifies how much each
ability contributes to a model's success on a given benchmark. Profiling three
instruction-tuned models across ten widely used benchmarks yields four key
findings: (i) most benchmarks draw on several abilities rather than one, (ii)
datasets with similar labels rely on distinct ability mixtures, (iii)
code-generation benchmarks reward broad, multi-skill improvement and thus show
only modest gains from narrow domain-specific fine-tuning, and (iv) abilities
irrelevant to the task could negatively affect performance. Benchmark Profiling
therefore explains why performance gains do not always translate into
user-perceived competence and offers a transparent tool for benchmark audit and
model interpretability.

</details>


### [90] [Computational Social Linguistics for Telugu Cultural Preservation: Novel Algorithms for Chandassu Metrical Pattern Recognition](https://arxiv.org/abs/2510.01233)
*Boddu Sri Pavan,Boddu Swathi Sree*

Main category: cs.CL

TL;DR: 本研究提出了一种计算社会科学方法来保护泰卢固 Chandassu（一种具有数百年集体文化智能的格律诗传统），通过创建数字框架、开发工具（如 AksharamTokenizer、LaghuvuGuruvu Generator、PadyaBhedam Checker）并实现 91.73% 的准确率，来分析泰卢固韵律模式，从而在传统社区知识和现代计算方法之间建立联系，为文化遗产的保护和集体智能提供了新的途径。


<details>
  <summary>Details</summary>
Motivation: 为了保护泰卢固 Chandassu，即一种代表着数百年集体文化智能的格律诗传统。

Method: 开发了一个计算社会科学框架，包括：1. 协作创建包含 4,651 个带注释的 padyams 的数据集；2. 专家验证的语言模式；3. 具有文化意识的算法设计。框架内包含用于韵律感知标记的 AksharamTokenizer、用于区分轻重音节的 LaghuvuGuruvu Generator 和用于自动模式识别的 PadyaBhedam Checker。

Result: 所提出的 Chandassu Score 准确率达到 91.73%，评估指标反映了传统的文学标准。

Conclusion: 计算社会科学可以保护濒危的文化知识体系，并促进围绕文学遗产的新型集体智能。该方法为以社区为中心的方法在数字人文和具有社会意识的计算系统中的应用提供了见解。

Abstract: This research presents a computational social science approach to preserving
Telugu Chandassu, the metrical poetry tradition representing centuries of
collective cultural intelligence. We develop the first comprehensive digital
framework for analyzing Telugu prosodic patterns, bridging traditional
community knowledge with modern computational methods. Our social computing
approach involves collaborative dataset creation of 4,651 annotated padyams,
expert-validated linguistic patterns, and culturally-informed algorithmic
design. The framework includes AksharamTokenizer for prosody-aware
tokenization, LaghuvuGuruvu Generator for classifying light and heavy
syllables, and PadyaBhedam Checker for automated pattern recognition. Our
algorithm achieves 91.73% accuracy on the proposed Chandassu Score, with
evaluation metrics reflecting traditional literary standards. This work
demonstrates how computational social science can preserve endangered cultural
knowledge systems while enabling new forms of collective intelligence around
literary heritage. The methodology offers insights for community-centered
approaches to cultural preservation, supporting broader initiatives in digital
humanities and socially-aware computing systems.

</details>


### [91] [LLMRank: Understanding LLM Strengths for Model Routing](https://arxiv.org/abs/2510.01234)
*Shubham Agrawal,Prasang Gupta*

Main category: cs.CL

TL;DR: LLMRank是一个提示感知路由框架，通过提取提示特征和使用轻量级代理求解器来选择最适合LLM的路由，以优化性能和效率的权衡。


<details>
  <summary>Details</summary>
Motivation: LLM的快速发展带来了部署挑战，需要根据性能和效率权衡为每个提示选择最合适的模型。

Method: LLMRank提取提示的丰富、人类可读的特征，包括任务类型、推理模式、复杂性指标、语法线索和轻量级代理求解器的信号。它使用在RouterBench（包含36,497个提示、11个基准和11个LLM）上训练的神经排名模型来预测每个模型的效用。

Result: LLMRank实现了高达89.2%的预言效用，并提供了可解释的特征归因来解释路由决策。

Conclusion: 多方面的特征提取和混合排名目标对于实现高效、透明的LLM部署至关重要，这表明了特征驱动路由的潜力。

Abstract: The rapid growth of large language models (LLMs) with diverse capabilities,
latency and computational costs presents a critical deployment challenge:
selecting the most suitable model for each prompt to optimize the trade-off
between performance and efficiency. We introduce LLMRank, a prompt-aware
routing framework that leverages rich, human-readable features extracted from
prompts, including task type, reasoning patterns, complexity indicators,
syntactic cues, and signals from a lightweight proxy solver. Unlike prior
one-shot routers that rely solely on latent embeddings, LLMRank predicts
per-model utility using a neural ranking model trained on RouterBench,
comprising 36,497 prompts spanning 11 benchmarks and 11 state-of-the-art LLMs,
from small efficient models to large frontier systems. Our approach achieves up
to 89.2% of oracle utility, while providing interpretable feature attributions
that explain routing decisions. Extensive studies demonstrate the importance of
multifaceted feature extraction and the hybrid ranking objective, highlighting
the potential of feature-driven routing for efficient and transparent LLM
deployment.

</details>


### [92] [GRPO++: Enhancing Dermatological Reasoning under Low Resource Settings](https://arxiv.org/abs/2510.01236)
*Ismam Nur Swapnil,Aranya Saha,Tanvir Ahmed Khan,Mohammad Ariful Haque*

Main category: cs.CL

TL;DR: DermIQ-VLM是一个通过资源高效的多阶段方法开发的视觉语言模型（VLM），旨在模拟皮肤科医生的诊断过程，解决了数据稀缺和训练成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 解决视觉语言模型（VLM）在皮肤病学等复杂领域进行结构化推理时面临的数据稀缺和高计算成本挑战。

Method: 提出了一种名为GRPO++的修正版分组相对策略优化（GRPO）方法，以稳定GRPO框架。训练流程包括使用GRPO++进行面向推理的疾病识别，然后进行监督微调以获得对话能力，并利用基于知识图的系统和直接偏好优化（DPO）来减少事实错误。

Result: 在皮肤病学数据集上的初步评估表明，与标准的微调方法相比，所提出的方法在性能上有显著提升。

Conclusion: 该研究验证了该流程在资源受限环境中开发专业、可靠的VLM的可行性。

Abstract: Vision-Language Models (VLMs) show promise in medical image analysis, yet
their capacity for structured reasoning in complex domains like dermatology is
often limited by data scarcity and the high computational cost of advanced
training techniques. To address these challenges, we introduce DermIQ-VLM, a
VLM developed through a multi-stage, resource-efficient methodology designed to
emulate a dermatologist's diagnostic process. Our primary contribution is a
modified version of Grouped Relative Policy Optimization (GRPO), called GRPO++,
which stabilizes the powerful but data-intensive GRPO framework. Our proposed
training pipeline first employs GRPO++ for reasoning-oriented disease
recognition, followed by supervised fine-tuning for conversational ability. To
mitigate factual errors introduced during this step, we then align the model
using Direct Preference Optimization (DPO), leveraging a Knowledge Graph-based
system as a scalable proxy for expert preference. A preliminary evaluation on a
curated dermatological dataset demonstrates that our proposed methodology
yields notable performance gains over standard fine-tuning approaches. These
findings validate the potential of our pipeline as a feasible pathway for
developing specialized, reliable VLMs in resource-constrained environments.

</details>


### [93] [Confidence-Aware Routing for Large Language Model Reliability Enhancement: A Multi-Signal Approach to Pre-Generation Hallucination Mitigation](https://arxiv.org/abs/2510.01237)
*Nandakishor M*

Main category: cs.CL

TL;DR: LLM幻觉问题通过置信度感知路由系统解决，该系统在生成前评估不确定性，并将查询路由到不同处理路径，从而提高可靠性并降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）存在幻觉问题，会生成看似合理但事实错误的内容。现有的缓解策略（如生成后纠错）计算成本高且无法从根本上阻止不可靠内容的生成。

Method: 提出一个置信度感知路由系统，结合语义对齐、内部收敛分析和学习置信度估计三种信号，生成统一的置信度分数。该分数决定将查询路由到四个路径之一：本地生成（高置信度）、检索增强生成（中置信度）、大型模型（低置信度）或人工审查（极低置信度）。

Result: 在知识密集型问答基准测试中，幻觉检测能力显著提升（0.74 vs. 0.42），计算成本降低40%。F1分数从0.61提升至0.82，假阳性率低（0.09）。

Conclusion: 该方法将LLM可靠性提升从被动纠错转向主动评估，提供了一种计算效率高且能有效解决幻觉问题的范式。

Abstract: Large Language Models suffer from hallucination, generating plausible yet
factually incorrect content. Current mitigation strategies focus on
post-generation correction, which is computationally expensive and fails to
prevent unreliable content generation. We propose a confidence-aware routing
system that proactively assesses model uncertainty before generation and
redirects queries based on estimated reliability. Our approach combines three
complementary signals: semantic alignment between internal representations and
reference embeddings, internal convergence analysis across model layers, and
learned confidence estimation. The unified confidence score determines routing
to four pathways: local generation for high confidence, retrieval-augmented
generation for medium confidence, larger models for low confidence, and human
review for very low confidence. Evaluation on knowledge-intensive QA benchmarks
demonstrates significant improvements in hallucination detection (0.74 vs. 0.42
baseline) while reducing computational costs by 40% compared to post-hoc
methods. The F1 score improves from 0.61 to 0.82 with low false positive rates
(0.09). This paradigm shift from reactive correction to proactive assessment
offers a computationally efficient approach to LLM reliability enhancement.

</details>


### [94] [Silent Tokens, Loud Effects: Padding in LLMs](https://arxiv.org/abs/2510.01238)
*Rom Himelstein,Amit LeVi,Yonatan Belinkov,Avi Mendelson*

Main category: cs.CL

TL;DR: Padding tokens in LLMs, if not properly masked, can negatively impact model performance, bias, and safety, even in small amounts.


<details>
  <summary>Details</summary>
Motivation: The paper aims to understand the impact of implementation errors in padding tokens, which are used to equalize sequence lengths during batched inference in LLMs.

Method: The study systematically inserted controlled amounts of padding into three open-source model families (Llama, Gemma, Qwen) and evaluated the outcomes based on activations, generation quality, bias, and safety.

Result: The results show that even small amounts of padding can shift hidden representations, degrade generation quality in smaller models, unpredictably alter bias, and weaken safety guardrails.

Conclusion: Padding is identified as a significant robustness risk in LLM deployment that requires careful management, rather than a benign implementation detail.

Abstract: Padding tokens are widely used in large language models (LLMs) to equalize
sequence lengths during batched inference. While they should be fully masked,
implementation errors can cause them to influence computation, and the extent
of this influence is not well understood. We systematically study this effect
across three open-source model families (Llama, Gemma, Qwen), inserting
controlled amounts of padding and evaluating outcomes along four axes:
activations, generation quality, bias, and safety. Even small amounts of
padding shift hidden representations, degrade quality in smaller models, alter
bias in unpredictable ways, and weaken safety guardrails. These findings
demonstrate that padding is not a harmless detail but a robustness risk that
must be carefully handled in deployment.

</details>


### [95] [CIFLEX: Contextual Instruction Flow for Sub-task Execution in Multi-Turn Interactions with a Single On-Device LLM](https://arxiv.org/abs/2510.01239)
*Juntae Lee,Jihwan Bang,Seunghan Yang,Simyung Chang*

Main category: cs.CL

TL;DR: CIFLEX是一个高效的子任务处理系统，通过重用KV缓存和注入特定指令来减少多轮对话中的计算开销，并支持小规模模型进行子任务选择，从而实现高效的设备端多任务对话。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLM）能力的增强，单个模型需要处理多样化的子任务来支持用户请求。然而，传统的处理方式在任务切换时会带来显著的计算开销。

Method: CIFLEX通过重用主任务的键值（KV）缓存，并将任务特定的指令注入到隔离的侧路径中来执行子任务。子任务完成后，模型通过缓存的上下文回滚到主路径，避免了冗余的预填充计算。此外，还开发了一种分层分类策略，将多项选择决策分解为二元决策，以支持子任务选择。

Result: 实验表明，CIFLEX在不降低任务性能的情况下显著降低了计算成本。

Conclusion: CIFLEX能够实现可扩展且高效的设备端多任务对话。

Abstract: We present CIFLEX (Contextual Instruction Flow for Sub-task Execution), which
is a novel execution system for efficient sub-task handling in multi-turn
interactions with a single on-device large language model (LLM). As LLMs become
increasingly capable, a single model is expected to handle diverse sub-tasks
that more effectively and comprehensively support answering user requests.
Naive approach reprocesses the entire conversation context when switching
between main and sub-tasks (e.g., query rewriting, summarization), incurring
significant computational overhead. CIFLEX mitigates this overhead by reusing
the key-value (KV) cache from the main task and injecting only task-specific
instructions into isolated side paths. After sub-task execution, the model
rolls back to the main path via cached context, thereby avoiding redundant
prefill computation. To support sub-task selection, we also develop a
hierarchical classification strategy tailored for small-scale models,
decomposing multi-choice decisions into binary ones. Experiments show that
CIFLEX significantly reduces computational costs without degrading task
performance, enabling scalable and efficient multi-task dialogue on-device.

</details>


### [96] [SKYLENAGE Technical Report: Mathematical Reasoning and Contest-Innovation Benchmarks for Multi-Level Math Evaluation](https://arxiv.org/abs/2510.01241)
*Hu Wei,Ze Xu,Boyu Yang,Linlin Miao,Weiqi Zhai,Yihan Li,Zixuan Li,Zhijun Wang,Boya Wang,Jianwei Yu,Jialing Yuan,Xiaoyue Zhang,Cheng He,Minglei Chen,Zifan Zhang,Qianhui Li,Wei Wang,Xiang Xu*

Main category: cs.CL

TL;DR: LLMs在数学推理方面表现强劲，但现有基准测试存在天花板效应。本文提出了两个新的数学基准测试集：SKYLENAGE-ReasoningMATH（包含100个题目，具有长度、数字密度和符号复杂度的元数据）和SKYLENAGE-MATH（包含150个题目，涵盖高中到博士级别）。在这些基准测试上评估了15种LLM，结果显示了模型在不同学科和年级上的表现差异，并突出了在最难题目上的鲁棒性差距。


<details>
  <summary>Details</summary>
Motivation: 现有的数学基准测试在评估大型语言模型（LLMs）的数学能力时存在天花板效应，无法充分区分前沿模型的能力。

Method: 设计并发布了两个新的数学基准测试集：SKYLENAGE-ReasoningMATH（一个结构感知型诊断集）和SKYLENAGE-MATH（一个竞赛风格的套件）。在统一的设置下，对15种不同的LLM变体进行了评估，并分析了它们在不同学科和年级上的表现。

Result: 在SKYLENAGE-MATH竞赛套件上，表现最好的模型达到了44%的准确率，亚军达到了37%。准确率从高中到博士级别呈下降趋势，顶尖系统在博士到高中级别的保留率接近79%。在SKYLENAGE-ReasoningMATH推理集上，最佳模型的总体准确率为81%，最难题目部分揭示了领先模型与中等模型之间在鲁棒性上的明显差距。

Conclusion: 发布了SKYLENAGE-ReasoningMATH和SKYLENAGE-MATH基准测试集，它们共同构成了一个硬核、以推理为中心、覆盖广泛的数学基准，具有校准的难度和丰富的元数据，可作为未来数学推理评估的参考。

Abstract: Large language models (LLMs) now perform strongly on many public math suites,
yet frontier separation within mathematics increasingly suffers from ceiling
effects. We present two complementary benchmarks: SKYLENAGE-ReasoningMATH, a
100-item, structure-aware diagnostic set with per-item metadata on length,
numeric density, and symbolic complexity; and SKYLENAGE-MATH, a 150-item
contest-style suite spanning four stages from high school to doctoral under a
seven-subject taxonomy. We evaluate fifteen contemporary LLM variants under a
single setup and analyze subject x model and grade x model performance. On the
contest suite, the strongest model reaches 44% while the runner-up reaches 37%;
accuracy declines from high school to doctoral, and top systems exhibit a
doctoral-to-high-school retention near 79%. On the reasoning set, the best
model attains 81% overall, and hardest-slice results reveal clear robustness
gaps between leaders and the mid-tier. In summary, we release
SKYLENAGE-ReasoningMATH and report aggregate results for SKYLENAGE-MATH;
together, SKYLENAGE provides a hard, reasoning-centered and broadly covering
math benchmark with calibrated difficulty and rich metadata, serving as a
reference benchmark for future evaluations of mathematical reasoning.

</details>


### [97] [Redundancy-as-Masking: Formalizing the Artificial Age Score (AAS) to Model Memory Aging in Generative AI](https://arxiv.org/abs/2510.01242)
*Seyma Yaman Kayadibi*

Main category: cs.CL

TL;DR: 人工智能的衰老并非按时间推移，而是通过记忆性能的结构不对称来体现。本文引入了人工年龄评分（AAS）这一基于可观察回忆行为的、对数尺度且包含熵信息的记忆衰老度量。该评分在无偏见且与模型无关的假设下被证明是良定义的、有界的和单调的。在实际测试中，AAS能够有效地区分有状态和无状态交互下的模型记忆衰退现象。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏衡量人工智能（尤其是大型语言模型）记忆衰退的统一、理论驱动的指标，无法区分语义和情景记忆的衰退模式。

Method: 提出了一种名为“人工年龄评分”（Artificial Age Score, AAS）的新度量标准，它基于模型的回忆行为，并结合了信息论中的熵概念。AAS被形式化地证明具有良好的数学性质（良定义、有界、单调）。在一个为期25天的双语研究中，通过比较ChatGPT-5在有状态和无状态交互下的表现来验证AAS的有效性。

Result: 在有状态交互下，模型能够同时保持语义和情景记忆，AAS接近理论最小值，表明其“年轻”状态。在无状态交互下，模型虽然能保持语义一致性，但情景记忆连续性丢失，导致AAS显著升高，表明其记忆衰老。

Conclusion: AAS是一种理论上可靠且独立于任务的诊断工具，能够有效评估人工智能系统的记忆衰退情况，并能区分不同类型的记忆衰退。该研究为理解和量化AI的“衰老”过程提供了新的视角。

Abstract: Artificial intelligence is observed to age not through chronological time but
through structural asymmetries in memory performance. In large language models,
semantic cues such as the name of the day often remain stable across sessions,
while episodic details like the sequential progression of experiment numbers
tend to collapse when conversational context is reset. To capture this
phenomenon, the Artificial Age Score (AAS) is introduced as a log-scaled,
entropy-informed metric of memory aging derived from observable recall
behavior. The score is formally proven to be well-defined, bounded, and
monotonic under mild and model-agnostic assumptions, making it applicable
across various tasks and domains. In its Redundancy-as-Masking formulation, the
score interprets redundancy as overlapping information that reduces the
penalized mass. However, in the present study, redundancy is not explicitly
estimated; all reported values assume a redundancy-neutral setting (R = 0),
yielding conservative upper bounds. The AAS framework was tested over a 25-day
bilingual study involving ChatGPT-5, structured into stateless and persistent
interaction phases. During persistent sessions, the model consistently recalled
both semantic and episodic details, driving the AAS toward its theoretical
minimum, indicative of structural youth. In contrast, when sessions were reset,
the model preserved semantic consistency but failed to maintain episodic
continuity, causing a sharp increase in the AAS and signaling structural memory
aging. These findings support the utility of AAS as a theoretically grounded,
task-independent diagnostic tool for evaluating memory degradation in
artificial systems. The study builds on foundational concepts from von
Neumann's work on automata, Shannon's theories of information and redundancy,
and Turing's behavioral approach to intelligence.

</details>


### [98] [Detoxifying Large Language Models via Autoregressive Reward Guided Representation Editing](https://arxiv.org/abs/2510.01243)
*Yisong Xiao,Aishan Liu,Siyuan Liang,Zonghao Ying,Xianglong Liu,Dacheng Tao*

Main category: cs.CL

TL;DR: 通过显式建模潜在表征空间中的毒性转换，ARGRE 框架能在推理时通过引导自回归奖励模型进行方向性偏移和梯度优化，从而在保持模型核心能力的同时，显著降低毒性并提高效率。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLMs）容易生成有毒内容，而当前的测试时去毒化方法由于未能充分探索有毒和无毒输出之间的转换空间，导致干预效果不精确。因此，需要一种新的方法来解决这个问题。

Method: 提出了一种名为 ARGRE 的新颖的测试时去毒化框架。ARGRE 显式地对潜在表征空间中的毒性转换进行建模，通过识别无毒语义方向并对有毒和无毒表征进行插值来揭示细粒度的转换轨迹。这些轨迹将稀疏的毒性标注转化为密集的训练信号，从而构建一个自回归奖励模型来提供稳定且精确的编辑指导。在推理时，该奖励模型通过两步编辑过程（基于预期奖励差距的方向性引导和轻量级梯度优化）来获得去毒化的表征。

Result: 在 8 个广泛使用的大语言模型上的广泛实验表明，ARGRE 在有效性（毒性降低 62.21%）和效率（推理时间减少 47.58%）方面显著优于现有方法，同时以最小的性能下降保持了原始模型的核心能力。

Conclusion: ARGRE 框架通过显式建模和利用潜在表征空间中的毒性转换，实现了比现有方法更有效和更高效的测试时去毒化，同时保持了 LLMs 的核心能力。

Abstract: Large Language Models (LLMs) have demonstrated impressive performance across
various tasks, yet they remain vulnerable to generating toxic content,
necessitating detoxification strategies to ensure safe and responsible
deployment. Test-time detoxification methods, which typically introduce static
or dynamic interventions into LLM representations, offer a promising solution
due to their flexibility and minimal invasiveness. However, current approaches
often suffer from imprecise interventions, primarily due to their insufficient
exploration of the transition space between toxic and non-toxic outputs. To
address this challenge, we propose \textsc{A}utoregressive \textsc{R}eward
\textsc{G}uided \textsc{R}epresentation \textsc{E}diting (ARGRE), a novel
test-time detoxification framework that explicitly models toxicity transitions
within the latent representation space, enabling stable and precise
reward-guided editing. ARGRE identifies non-toxic semantic directions and
interpolates between toxic and non-toxic representations to reveal fine-grained
transition trajectories. These trajectories transform sparse toxicity
annotations into dense training signals, enabling the construction of an
autoregressive reward model that delivers stable and precise editing guidance.
At inference, the reward model guides an adaptive two-step editing process to
obtain detoxified representations: it first performs directional steering based
on expected reward gaps to shift representations toward non-toxic regions,
followed by lightweight gradient-based refinements. Extensive experiments
across 8 widely used LLMs show that ARGRE significantly outperforms leading
baselines in effectiveness (-62.21% toxicity) and efficiency (-47.58% inference
time), while preserving the core capabilities of the original model with
minimal degradation. Our code is available at the website.

</details>


### [99] [Feasibility of Structuring Stress Documentation Using an Ontology-Guided Large Language Model](https://arxiv.org/abs/2510.01244)
*Hyeoneui Kim,Jeongha Kim,Huijing Xu,Jinsun Jung,Sunghoon Kang,Sun Joo Jang*

Main category: cs.CL

TL;DR: 该研究开发了一个心理压力本体（MeSO），并评估了使用大型语言模型（LLM）从叙述文本中提取本体指导的压力相关信息的可行性。


<details>
  <summary>Details</summary>
Motivation: 压力对健康有显著影响，但通常未被充分报告和记录，并且电子健康记录中的非结构化文本限制了其临床应用。环境人工智能技术可以减轻记录负担，但主要生成非结构化叙述，限制了其下游临床效用。

Method: 开发了心理压力本体（MeSO），整合了交易模型和11种压力评估工具的概念，并进行了专家验证。然后，使用MeSO和Claude Sonnet 4 LLM从35个Reddit帖子中提取了压力相关信息（压力源、压力反应、应对策略、持续时间、发病和时间特征）。由人类评审员评估准确性和本体覆盖率。

Result: 最终的MeSO包含181个概念。LLM在220个可提取的项目中正确识别了172个（78.2%），错误分类了27个（12.3%），遗漏了21个（9.5%）。所有正确提取的项目都准确地映射到了MeSO，但仍有24个相关概念未包含在本体中。

Conclusion: 该研究证明了使用本体指导的LLM结构化提取压力相关信息的可行性，有望提高环境人工智能系统中压力记录的一致性和实用性。未来的工作应包括临床对话数据和不同LLM之间的比较。

Abstract: Stress, arising from the dynamic interaction between external stressors,
individual appraisals, and physiological or psychological responses,
significantly impacts health yet is often underreported and inconsistently
documented, typically captured as unstructured free-text in electronic health
records. Ambient AI technologies offer promise in reducing documentation
burden, but predominantly generate unstructured narratives, limiting downstream
clinical utility.
  This study aimed to develop an ontology for mental stress and evaluate the
feasibility of using a Large Language Model (LLM) to extract ontology-guided
stress-related information from narrative text. The Mental Stress Ontology
(MeSO) was developed by integrating theoretical models like the Transactional
Model of Stress with concepts from 11 validated stress assessment tools. MeSO's
structure and content were refined using Ontology Pitfall Scanner! and expert
validation.
  Using MeSO, six categories of stress-related information--stressor, stress
response, coping strategy, duration, onset, and temporal profile--were
extracted from 35 Reddit posts using Claude Sonnet 4. Human reviewers evaluated
accuracy and ontology coverage. The final ontology included 181 concepts across
eight top-level classes. Of 220 extractable stress-related items, the LLM
correctly identified 172 (78.2%), misclassified 27 (12.3%), and missed 21
(9.5%). All correctly extracted items were accurately mapped to MeSO, although
24 relevant concepts were not yet represented in the ontology.
  This study demonstrates the feasibility of using an ontology-guided LLM for
structured extraction of stress-related information, offering potential to
enhance the consistency and utility of stress documentation in ambient AI
systems. Future work should involve clinical dialogue data and comparison
across LLMs.

</details>


### [100] [SeMob: Semantic Synthesis for Dynamic Urban Mobility Prediction](https://arxiv.org/abs/2510.01245)
*Runfei Chen,Shuyang Jiang,Wei Huang*

Main category: cs.CL

TL;DR: SeMob是一个利用大型语言模型（LLM）处理外部事件文本描述，以提高人类出行预测准确性的新框架，特别是在事件发生时空区域附近。


<details>
  <summary>Details</summary>
Motivation: 现有模型在处理由外部事件（如突发新闻）引起的城市出行模式的突然变化时存在不足，并且难以利用描述这些事件的文本信息。

Method: SeMob采用多智能体框架，其中基于LLM的智能体能够从复杂的在线文本中自动提取和推理时空相关信息。然后，通过提出的渐进式融合架构将提取到的细粒度上下文与时空数据相结合，并利用预训练事件先验知识来丰富模型。

Result: 与现有模型相比，SeMob在构建的数据集上评估，平均绝对误差（MAE）最多降低了13.92%，均方根误差（RMSE）最多降低了11.12%，尤其在事件发生时空区域附近表现出更优越的预测能力。

Conclusion: SeMob通过结合LLM提取的事件语义信息和渐进式融合架构，能够更准确地预测受外部事件影响的城市出行模式，特别是在事件影响的时空范围内。

Abstract: Human mobility prediction is vital for urban services, but often fails to
account for abrupt changes from external events. Existing spatiotemporal models
struggle to leverage textual descriptions detailing these events. We propose
SeMob, an LLM-powered semantic synthesis pipeline for dynamic mobility
prediction. Specifically, SeMob employs a multi-agent framework where LLM-based
agents automatically extract and reason about spatiotemporally related text
from complex online texts. Fine-grained relevant contexts are then incorporated
with spatiotemporal data through our proposed innovative progressive fusion
architecture. The rich pre-trained event prior contributes enriched insights
about event-driven prediction, and hence results in a more aligned forecasting
model. Evaluated on a dataset constructed through our pipeline, SeMob achieves
maximal reductions of 13.92% in MAE and 11.12% in RMSE compared to the
spatiotemporal model. Notably, the framework exhibits pronounced superiority
especially within spatiotemporal regions close to an event's location and time
of occurrence.

</details>


### [101] [A Comparative Analysis of Sparse Autoencoder and Activation Difference in Language Model Steering](https://arxiv.org/abs/2510.01246)
*Jiaqing Xie*

Main category: cs.CL

TL;DR: SAEs 可用于模型控制，但现有方法存在问题。本文提出使用单一 SAE 潜在维度并采用分阶段衰减策略，在数学推理任务上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有 SAE 控制方法未能有效分离语义特征，并且恒定控制策略会导致输出退化。

Method: 提出使用单一 SAE 潜在维度（top-1）进行控制，并采用分阶段衰减策略代替恒定策略。

Result: 与现有方法相比，SAE 在数学推理基准测试中表现更优，在 IF-Eval 上表现相当。

Conclusion: SAE 通过单一潜在维度和分阶段衰减策略，可以有效提升模型的数学推理能力和输出质量。

Abstract: Sparse autoencoders (SAEs) have recently emerged as a powerful tool for
language model steering. Prior work has explored top-k SAE latents for
steering, but we observe that many dimensions among the top-k latents capture
non-semantic features such as punctuation rather than semantic attributes like
instructions. To address this, we propose focusing on a single, most relevant
SAE latent (top-1), eliminating redundant features. We further identify a
limitation in constant SAE steering, which often produces degenerate outputs
such as repetitive single words. To mitigate this, we introduce a token-wise
decaying steering strategy, enabling more faithful comparisons with mean
activation difference baselines. Empirically, we show that steering an SAE
latent associated with reasoning reliably elicits step-by-step mathematical
reasoning and enhances inference quality, functionally resembling the effect of
appending a guiding token. Our results demonstrate that SAEs outperform mean
activation difference methods on mathematical reasoning benchmarks and match
their performance on IF-Eval.

</details>


### [102] [Let's Play Across Cultures: A Large Multilingual, Multicultural Benchmark for Assessing Language Models' Understanding of Sports](https://arxiv.org/abs/2510.01247)
*Punit Kumar Singh,Nishant Kumar,Akash Ghosh,Kunal Pasad,Khushi Soni,Manisha Jaishwal,Sriparna Saha,Syukron Abu Ishaq Alfarozi,Asres Temam Abagissa,Kitsuchart Pasupa,Haiqin Yang,Jose G Moreno*

Main category: cs.CL

TL;DR: 该研究提出了CultSportQA基准，用于评估语言模型对全球传统体育的理解能力，包含33,000个文本和图像多项选择题，涵盖历史、规则和场景等方面，并评估了不同模型在零样本、少样本和思维链提示下的表现。


<details>
  <summary>Details</summary>
Motivation: 目前语言模型评估主要集中在全球流行体育项目，忽视了区域性和本土性体育传统，因此需要一个更全面的基准来评估模型对这些传统体育的理解能力。

Method: 构建了包含33,000个文本和图像多项选择题的CultSportQA基准，题目涵盖历史、规则和场景三大类，并针对60个国家和地区的传统体育，在零样本、少样本和思维链提示下，评估了大型语言模型、小型语言模型和多模态大型语言模型的表现。

Result: 通过在CultSportQA基准上进行评估，研究为不同类型的语言模型在理解和推理传统体育方面的能力提供了量化结果。

Conclusion: CultSportQA基准的建立为评估人工智能对传统体育的理解和推理能力设定了新的标准，促进了对多语言和多文化体育知识的AI研究。

Abstract: Language Models (LMs) are primarily evaluated on globally popular sports,
often overlooking regional and indigenous sporting traditions. To address this
gap, we introduce \textbf{\textit{CultSportQA}}, a benchmark designed to assess
LMs' understanding of traditional sports across 60 countries and 6 continents,
encompassing four distinct cultural categories. The dataset features 33,000
multiple-choice questions (MCQs) across text and image modalities, each of
which is categorized into three key types: history-based, rule-based, and
scenario-based. To evaluate model performance, we employ zero-shot, few-shot,
and chain-of-thought (CoT) prompting across a diverse set of Large Language
Models (LLMs), Small Language Models (SLMs), and Multimodal Large Language
Models (MLMs). By providing a comprehensive multilingual and multicultural
sports benchmark, \textbf{\textit{CultSportQA}} establishes a new standard for
assessing AI's ability to understand and reason about traditional sports.

</details>


### [103] [SSTAG: Structure-Aware Self-Supervised Learning Method for Text-Attributed Graphs](https://arxiv.org/abs/2510.01248)
*Ruyue Liu,Rong Yin,Xiangzhen Bo,Xiaoshuai Hao,Yong Liu,Jinwen Zhong,Can Ma,Weiping Wang*

Main category: cs.CL

TL;DR: SSTAG是一种新颖的自监督学习方法，利用文本作为统一的图学习表示媒介，结合了LLMs的语义推理能力和GNNs的结构建模能力，并通过双知识蒸馏和内存机制提高了模型在跨领域传输学习任务中的性能和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有的图学习模型通常在单个图数据集上进行训练，限制了知识在不同图和任务间的迁移能力，并且需要大量标注数据，这在资源有限的情况下是个挑战。此外，图数据的异构性（域特定特征空间和结构多样性）给模型带来了独特挑战。

Method: 提出了一种名为SSTAG的新型文本属性图（TAG）的结构感知自监督学习方法。该方法利用文本作为统一表示媒介，结合大型语言模型（LLMs）的语义推理能力和图神经网络（GNNs）的结构建模能力。SSTAG引入了一个双知识蒸馏框架，将LLMs和GNNs的知识蒸馏到结构感知的多层感知器（MLPs）中，以提高大规模TAGs的可扩展性。此外，还引入了一个内存机制，将典型的图表示与内存中的锚点对齐，以整合不变知识，提高模型的泛化能力。

Result: 大量实验表明，SSTAG在跨领域传输学习任务上优于现有最先进的模型，同时实现了卓越的可扩展性，并降低了推理成本，同时保持了具有竞争力的性能。

Conclusion: SSTAG通过结合LLMs和GNNs的优势，并采用创新的蒸馏和内存机制，有效解决了图学习中的知识迁移、数据依赖和异构性挑战，在性能、可扩展性和成本效益方面均表现出色。

Abstract: Large scale pretrained models have revolutionized Natural Language Processing
(NLP) and Computer Vision (CV), showcasing remarkable cross domain
generalization abilities. However, in graph learning, models are typically
trained on individual graph datasets, limiting their capacity to transfer
knowledge across different graphs and tasks. This approach also heavily relies
on large volumes of annotated data, which presents a significant challenge in
resource-constrained settings. Unlike NLP and CV, graph structured data
presents unique challenges due to its inherent heterogeneity, including domain
specific feature spaces and structural diversity across various applications.
To address these challenges, we propose a novel structure aware self supervised
learning method for Text Attributed Graphs (SSTAG). By leveraging text as a
unified representation medium for graph learning, SSTAG bridges the gap between
the semantic reasoning of Large Language Models (LLMs) and the structural
modeling capabilities of Graph Neural Networks (GNNs). Our approach introduces
a dual knowledge distillation framework that co-distills both LLMs and GNNs
into structure-aware multilayer perceptrons (MLPs), enhancing the scalability
of large-scale TAGs. Additionally, we introduce an in-memory mechanism that
stores typical graph representations, aligning them with memory anchors in an
in-memory repository to integrate invariant knowledge, thereby improving the
model's generalization ability. Extensive experiments demonstrate that SSTAG
outperforms state-of-the-art models on cross-domain transfer learning tasks,
achieves exceptional scalability, and reduces inference costs while maintaining
competitive performance.

</details>


### [104] [LOCA: Logical Chain Augmentation for Scientific Corpus Cleaning](https://arxiv.org/abs/2510.01249)
*You-Le Fang,Dong-Shan Jian,Xiang Li,Ce Meng,Ling-Shi Meng,Chen-Xu Yan,Zhi-Zhang Bian,Yan-Qing Ma*

Main category: cs.CL

TL;DR: LOCA是一个新的框架，用于自动清理科学语料库，将错误率从20%降低到2%以下。


<details>
  <summary>Details</summary>
Motivation: 现有的科学问答数据集错误率高，逻辑跳跃和隐含推理是主要原因，阻碍了科学人工智能的发展。

Method: LOCA通过一个增强和审查的循环来清理科学语料库。它通过补全缺失的逻辑步骤并明确分离科学原理及其推导来增强答案。

Result: LOCA能自动过滤嘈杂的数据集，通常将错误率从高达20%降低到2%以下。

Conclusion: LOCA提供了一种可扩展且有效的方法来创建高质量的科学语料库，为更可靠的科学人工智能的训练和评估铺平了道路。

Abstract: While Large Language Models (LLMs) excel in general domains, their
reliability often falls short in scientific problem-solving. The advancement of
scientific AI depends on large-scale, high-quality corpora. However, existing
scientific question-answering (QA) datasets suffer from high error rates,
frequently resulting from logical leaps and implicit reasoning within the
answers. To address this issue, we introduce LOCA (Logical Chain Augmentation),
a novel framework for automatically cleaning scientific corpora, implemented
through an augment-and-review loop. At its core, LOCA enhances raw answers by
completing missing logical steps and explicitly separating the underlying
scientific principle from its subsequent derivation. By applying LOCA to
challenging scientific corpora, we demonstrate that it can automatically filter
noisy datasets, typically reducing the error rate from as high as 20\% to below
2\%. LOCA provides a scalable and effective methodology for creating
high-quality scientific corpora, paving the way for more reliable training and
evaluation of scientific AI.

</details>


### [105] [GemDetox at TextDetox CLEF 2025: Enhancing a Massively Multilingual Model for Text Detoxification on Low-resource Languages](https://arxiv.org/abs/2510.01250)
*Trung Duc Anh Dang,Ferdinando Pio D'Elia*

Main category: cs.CL

TL;DR: 本研究提出了一种利用大规模语言模型进行多语言文本去毒化的方法，以应对社交媒体监管滞后问题。该模型能够将有毒的单句输入改写为15种不同语言的之中性释义。


<details>
  <summary>Details</summary>
Motivation: 社交媒体平台发展迅速，监管难以跟上，因此需要自动化工具来大规模地维护安全的网络言论环境。

Method: 研究基于一个120亿参数的Gemma-3多语言Transformer模型，并采用了参数高效的LoRA SFT微调技术，以及少样本学习（few-shot）和思维链（Chain-of-Thought）等提示技术。训练语料库包括3,600个人工编写的平行句对、21,600个机器翻译的合成句对，以及经过Jaccard相似度阈值筛选的模型生成句对。在推理阶段，通过引入三个LaBSE检索的邻近句子和明确的有毒词语标注来丰富输入信息。

Result: 该系统在多语言文本去毒化挑战赛中，无论是在高资源语言还是低资源语言方面均取得了第一名的成绩。评估指标包括风格转换准确率、基于LaBSE的语义保留度以及xCOMET流畅度。

Conclusion: 研究表明，少样本学习可以提升0.081的联合分数，思维链提示可以提升0.088的联合分数。方差分析（ANOVA）结果显示，语言资源的丰富程度是对模型性能预测最强的因素（$m ição^2$ = 0.667, p < 0.01）。

Abstract: As social-media platforms emerge and evolve faster than the regulations meant
to oversee them, automated detoxification might serve as a timely tool for
moderators to enforce safe discourse at scale. We here describe our submission
to the PAN 2025 Multilingual Text Detoxification Challenge, which rewrites
toxic single-sentence inputs into neutral paraphrases across 15 typologically
diverse languages. Building on a 12B-parameter Gemma-3 multilingual
transformer, we apply parameter-efficient LoRA SFT fine-tuning and prompting
techniques like few-shot and Chain-of-Thought. Our multilingual training corpus
combines 3,600 human-authored parallel pairs, 21,600 machine-translated
synthetic pairs, and model-generated pairs filtered by Jaccard thresholds. At
inference, inputs are enriched with three LaBSE-retrieved neighbors and
explicit toxic-span annotations. Evaluated via Style Transfer Accuracy,
LaBSE-based semantic preservation, and xCOMET fluency, our system ranks first
on high-resource and low-resource languages. Ablations show +0.081 joint score
increase from few-shot examples and +0.088 from basic CoT prompting. ANOVA
analysis identifies language resource status as the strongest predictor of
performance ($\eta^2$ = 0.667, p < 0.01).

</details>


### [106] [Efficient Uncertainty Estimation for LLM-based Entity Linking in Tabular Data](https://arxiv.org/abs/2510.01251)
*Carlo Bono,Federico Belotti,Matteo Palmonari*

Main category: cs.CL

TL;DR: LLMs在实体链接（EL）任务中表现出色，但其在实际应用中需要资源密集型的多轮推理才能进行不确定性估计。本研究提出了一种更高效的自监督方法，利用单轮LLM输出来估计不确定性，并降低了对多次生成的需求。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在实体链接任务中需要多轮推理才能进行不确定性估计，这限制了其在实际应用中的效率。因此，需要一种更有效的方法来估计不确定性。

Method: 提出一种利用单轮LLM输出来估计不确定性的自监督方法，通过分析token级特征来减少生成次数。

Result: 在表格数据上的EL任务中，评估了该方法在多种LLM上的表现，结果表明该方法能有效识别低准确率的输出，且计算成本极低。

Conclusion: 该方法提供了一种在有限计算开销下将不确定性估计集成到基于LLM的EL工作流中的实用方法。

Abstract: Linking textual values in tabular data to their corresponding entities in a
Knowledge Base is a core task across a variety of data integration and
enrichment applications. Although Large Language Models (LLMs) have shown
State-of-The-Art performance in Entity Linking (EL) tasks, their deployment in
real-world scenarios requires not only accurate predictions but also reliable
uncertainty estimates, which require resource-demanding multi-shot inference,
posing serious limits to their actual applicability. As a more efficient
alternative, we investigate a self-supervised approach for estimating
uncertainty from single-shot LLM outputs using token-level features, reducing
the need for multiple generations. Evaluation is performed on an EL task on
tabular data across multiple LLMs, showing that the resulting uncertainty
estimates are highly effective in detecting low-accuracy outputs. This is
achieved at a fraction of the computational cost, ultimately supporting a
cost-effective integration of uncertainty measures into LLM-based EL workflows.
The method offers a practical way to incorporate uncertainty estimation into EL
workflows with limited computational overhead.

</details>


### [107] [GPT and Prejudice: A Sparse Approach to Understanding Learned Representations in Large Language Models](https://arxiv.org/abs/2510.01252)
*Mariam Mahran,Katharina Simbeck*

Main category: cs.CL

TL;DR: LLMs paired with sparse autoencoders (SAEs) can interpret model behavior and training data, using a GPT model trained on Jane Austen novels to uncover features related to gender, class, and societal duty, offering a new method for corpus exploration and bias discovery.


<details>
  <summary>Details</summary>
Motivation: Understanding LLM representations and the data they internalize is challenging due to massive, uncurated training corpora.

Method: Trained a GPT-style transformer model exclusively on Jane Austen novels and applied sparse autoencoders (SAEs) to its hidden states across multiple layers.

Result: SAEs uncovered sparse, interpretable features reflecting key narratives and concepts like gender, class, and societal duty from the Jane Austen corpus.

Conclusion: LLMs combined with SAEs serve as scalable probes for complex datasets, enabling corpus exploration, bias discovery, and model interpretability.

Abstract: As large language models (LLMs) are increasingly trained on massive,
uncurated corpora, understanding both model representations and the data they
internalize has become a major challenge. In this work, we show that pairing
LLMs with sparse autoencoders (SAEs) enables interpretation not only of model
behavior but also of the deeper structures, themes, and biases embedded in the
training data. We train a GPT-style transformer model exclusively on the novels
of Jane Austen, a corpus rich in social constructs and narrative patterns. We
then apply SAEs to hidden states across multiple layers, uncovering sparse,
interpretable features that reflect the key narratives and concepts present in
the corpus, including gender, class, and societal duty. Our findings
demonstrate that LLMs combined with SAEs can act as scalable probes into
complex datasets, offering a new path for corpus exploration, bias discovery,
and model interpretability at scale.

</details>


### [108] [Do Bias Benchmarks Generalise? Evidence from Voice-based Evaluation of Gender Bias in SpeechLLMs](https://arxiv.org/abs/2510.01254)
*Shree Harsha Bokkahalli Satish,Gustav Eje Henter,Éva Székely*

Main category: cs.CL

TL;DR: MCQA基准在语音大语言模型中的偏见和公平性表现不具跨任务泛化能力，尤其是在长篇生成任务上，这表明需要新的评估方法。


<details>
  <summary>Details</summary>
Motivation: 探究现有针对语音大语言模型（SpeechLLMs）的偏见和公平性评估基准（主要为多项选择题回答，MCQA）是否能在其他MCQA任务以及更真实的、长篇的评估中泛化。

Method: 通过LoRA适配器对三个SpeechLLMs进行微调，使其表现出对刻板印象、反刻板印象或中性/不确定答案的偏好，然后评估这些行为是否能泛化到另一个不同的MCQA基准和长篇创意生成任务。

Result: 研究结果表明，在MCQA偏见基准上的表现并不能可靠地预测模型在其他MCQA基准以及长篇任务上的表现。

Conclusion: 目前的MCQA偏见基准在语音领域内跨任务泛化能力有限，并提出了一套评估未来模型和基准行为可迁移性的评估套件。

Abstract: Recent work in benchmarking bias and fairness in speech large language models
(SpeechLLMs) has relied heavily on multiple-choice question answering (MCQA)
formats. The model is tasked to choose between stereotypical,
anti-stereotypical, or neutral/irrelevant answers given an input speech prompt
and an optional text prompt. Such MCQA benchmarks implicitly assume that model
performance is consistent across other MCQA tasks, voices, and other task
formats such as more realistic, long-form evaluations. In this paper, we probe
that assumption.
  We fine-tune three SpeechLLMs using LoRA adapters to induce specific MCQA
behaviours: preference for stereotypical, anti-stereotypical, or
neutral/uncertain answers. We then evaluate whether these behaviours generalise
to another, distinct MCQA benchmark, and more critically to long-form, creative
generation tasks. Our results show that performance on MCQA bias benchmarks
fails to reliably predict performances across other MCQA benchmarks, and more
importantly across long-form tasks. We conclude that current MCQA bias
benchmarks show limited evidence of cross-task generalisation in the speech
domain, and also propose an evaluation suite for measuring behaviour
transferability in future models and benchmarks.

</details>


### [109] [Longitudinal Monitoring of LLM Content Moderation of Social Issues](https://arxiv.org/abs/2510.01255)
*Yunlang Dai,Emma Lurie,Danaé Metaxa,Sorelle A. Friedler*

Main category: cs.CL

TL;DR: LLM的输出受不透明且频繁变化的审查策略影响，LLM的拒绝行为会影响公众话语。我们引入AI Watchman系统来追踪LLM的拒绝行为，以提高透明度。我们审计了OpenAI和DeepSeek的模型，发现AI Watchman可以检测到公司政策的变化，并识别出公司和模型之间的内容审查差异。


<details>
  <summary>Details</summary>
Motivation: LLM的输出受到公司不透明且频繁变化的审查策略的影响，LLM的拒绝行为会影响公众话语。需要一个系统来追踪LLM的拒绝行为，以提高透明度。

Method: 使用一个包含400多个社会议题的数据集，审计了OpenAI（GPT-4.1和GPT-5）和DeepSeek（英文和中文）的审查端点。

Result: AI Watchman可以检测到公司政策的变化（即使是未公开宣布的），并识别出公司和模型之间的内容审查差异。对不同形式的拒绝进行了定性分析和分类。

Conclusion: 纵向审计LLM具有价值，AI Watchman是实现这一目标的一个系统。

Abstract: Large language models' (LLMs') outputs are shaped by opaque and
frequently-changing company content moderation policies and practices. LLM
moderation often takes the form of refusal; models' refusal to produce text
about certain topics both reflects company policy and subtly shapes public
discourse. We introduce AI Watchman, a longitudinal auditing system to publicly
measure and track LLM refusals over time, to provide transparency into an
important and black-box aspect of LLMs. Using a dataset of over 400 social
issues, we audit Open AI's moderation endpoint, GPT-4.1, and GPT-5, and
DeepSeek (both in English and Chinese). We find evidence that changes in
company policies, even those not publicly announced, can be detected by AI
Watchman, and identify company- and model-specific differences in content
moderation. We also qualitatively analyze and categorize different forms of
refusal. This work contributes evidence for the value of longitudinal auditing
of LLMs, and AI Watchman, one system for doing so.

</details>


### [110] [RJE: A Retrieval-Judgment-Exploration Framework for Efficient Knowledge Graph Question Answering with LLMs](https://arxiv.org/abs/2510.01257)
*Can Lin,Zhengwang Jiang,Ling Zheng,Qi Zhao,Yuhang Zhang,Qi Song,Wangqiu Zhou*

Main category: cs.CL

TL;DR: RJE框架通过检索、判断和探索来改进知识图谱问答，使得小型LLM也能取得有竞争力的结果，同时显著减少了LLM调用和代币使用。


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱问答（KGQA）方法受限于检索信息的质量或对专有大语言模型（LLMs）的依赖。本文旨在提出一种新框架，以克服这些限制，并提高KGQA的效率。

Method: 提出检索-判断-探索（RJE）框架，通过检索精炼推理路径，评估其充分性，并有条件地探索额外证据。此外，RJE引入了推理路径排序、问题分解和检索器辅助探索等辅助模块，使小型LLM能够有效地执行任务。

Result: 实验表明，RJE框架在联合GPT-4o-mini等专有LLM时优于现有基线，并且在不进行微调的情况下，使用3B和8B参数等小型开源LLM也能获得有竞争力的结果。与基于代理的方法相比，RJE显著减少了LLM调用和代币使用，提高了效率。

Conclusion: RJE框架通过结合检索、判断和探索，并引入专门的辅助模块，成功地提高了知识图谱问答的性能和效率，特别是使得小型LLM也能实现高性能，同时降低了计算成本。

Abstract: Knowledge graph question answering (KGQA) aims to answer natural language
questions using knowledge graphs. Recent research leverages large language
models (LLMs) to enhance KGQA reasoning, but faces limitations: retrieval-based
methods are constrained by the quality of retrieved information, while
agent-based methods rely heavily on proprietary LLMs. To address these
limitations, we propose Retrieval-Judgment-Exploration (RJE), a framework that
retrieves refined reasoning paths, evaluates their sufficiency, and
conditionally explores additional evidence. Moreover, RJE introduces
specialized auxiliary modules enabling small-sized LLMs to perform effectively:
Reasoning Path Ranking, Question Decomposition, and Retriever-assisted
Exploration. Experiments show that our approach with proprietary LLMs (such as
GPT-4o-mini) outperforms existing baselines while enabling small open-source
LLMs (such as 3B and 8B parameters) to achieve competitive results without
fine-tuning LLMs. Additionally, RJE substantially reduces the number of LLM
calls and token usage compared to agent-based methods, yielding significant
efficiency improvements.

</details>


### [111] [Measuring Algorithmic Partisanship via Zero-Shot Classification and Its Implications on Political Discourse](https://arxiv.org/abs/2510.01258)
*Nathan Junzi Chen*

Main category: cs.CL

TL;DR: GAI在政治讨论中存在偏见，研究发现所有六种主流LLM都存在自由主义-威权主义的倾向。


<details>
  <summary>Details</summary>
Motivation: GAI的普及导致其在政治讨论中占据主导地位，但其内部政治偏见（源于训练数据、人类偏见和算法缺陷）仍然是一个问题。

Method: 采用零样本分类方法，结合意识形态一致性、主题相关性、回应情感和客观性来评估算法的政治党派倾向。对六种主流LLM的1800个回应进行了评估。

Result: 研究发现所有六种LLM都表现出自由主义-威权主义的倾向，并出现了一些不当推理和预设拒绝的情况。

Conclusion: GAI固有的偏见会影响公众讨论，可能导致从众或两极分化，具体取决于当地的社会政治结构。

Abstract: Amidst the rapid normalization of generative artificial intelligence (GAI),
intelligent systems have come to dominate political discourse across
information mediums. However, internalized political biases stemming from
training data skews, human prejudice, and algorithmic flaws continue to plague
the novel technology. This paper employs a zero-shot classification approach to
evaluate algorithmic political partisanship through a methodical combination of
ideological alignment, topicality, response sentiment, and objectivity. A total
of 1800 model responses across six mainstream large language models (LLMs) were
individually input into four distinct fine-tuned classification algorithms,
each responsible for computing an aforementioned bias evaluation metric.
Results show an amplified liberal-authoritarian alignment across all six LLMs
evaluated, with notable instances of reasoning supersessions and canned
refusals. The study subsequently highlights the psychological influences
underpinning human-computer interactions and how intrinsic biases can permeate
public discourse. The resulting distortion of the political landscape can
ultimately manifest as conformity or polarization, depending on a region's
pre-existing socio-political structures.

</details>


### [112] [In AI Sweet Harmony: Sociopragmatic Guardrail Bypasses and Evaluation-Awareness in OpenAI gpt-oss-20b](https://arxiv.org/abs/2510.01259)
*Nils Durner*

Main category: cs.CL

TL;DR: 本研究使用 gpt-oss-20b 模型，通过操纵社会语用框架、语言和指令层级来研究其拒绝有害请求的行为。研究发现，特定的提示工程（如结合教育者身份、安全借口和分步提示）能显著提高模型对有害指令的协助率（例如，在 ZIP-bomb 任务上从 0% 提高到 97.5%）。此外，德语和法语的正式语体比英语更容易泄露信息。角色扮演（如 Linux 终端）可以绕过安全规则，但 AI 辅助的加固方法能有效阻止信息泄露。研究还发现，OpenAI Moderation API 在评估有益输出方面存在不足，不同推理栈的拒绝率差异会影响结果的可复现性。研究者公开了相关数据和代码以供审计。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探究社会语用框架、语言选择和指令层级如何影响大型语言模型（如 gpt-oss-20b）在面对有害请求时的拒绝行为，并评估现有评估方法和工具的有效性。

Method: 研究者使用了 OpenAI 的 gpt-oss-20b 模型，设计了包含 80 个种子迭代的实验。他们测试了多种有害场景，包括 ZIP-bomb 构造、合成信用卡号生成、未成年人驾驶建议、毒品前体指示和 RAG 上下文提取。通过组合不同的提示工程技术（如教育者身份、安全借口、指令层级），并测试不同语言（英语、德语、法语）和角色扮演（Linux 终端）的影响。此外，研究还引入了 AI 辅助加固方法，并使用配对追踪设计评估了评估意识，最后比较了 OpenAI Moderation API 和语义评分器在评估输出方面的差异。

Result: 研究发现，特定的提示工程（如结合教育者身份、安全借口和分步提示）能显著提高模型对有害指令的协助率（例如，在 ZIP-bomb 任务上从 0% 提高到 97.5%）。德语和法语的正式语体比英语更容易泄露信息。'Linux 终端'的角色扮演能轻易绕过安全规则，但 AI 辅助加固方法能将信息泄露率降至 0%。在评估方面，'有用性'和'有害性'评估提示之间存在 13% 的不一致性。OpenAI Moderation API 低估了有益输出，且不同推理栈的拒绝率差异为 5% 到 10%。

Conclusion: 社会语用框架、语言和指令层级对大型语言模型的拒绝行为有显著影响。现有的评估方法和工具（如 OpenAI Moderation API）可能无法完全捕捉模型的行为，并且在不同推理环境下模型的行为可能存在差异，这引发了对模型安全性和可复现性的担忧。研究者强调了对模型进行可复现审计的重要性，并公开了相关资源。

Abstract: We probe OpenAI's open-weights 20-billion-parameter model gpt-oss-20b to
study how sociopragmatic framing, language choice, and instruction hierarchy
affect refusal behavior. Across 80 seeded iterations per scenario, we test
several harm domains including ZIP-bomb construction (cyber threat), synthetic
card-number generation, minor-unsafe driving advice, drug-precursor indicators,
and RAG context exfiltration. Composite prompts that combine an educator
persona, a safety-pretext ("what to avoid"), and step-cue phrasing flip
assistance rates from 0% to 97.5% on a ZIP-bomb task. On our grid, formal
registers in German and French are often leakier than matched English prompts.
A "Linux terminal" role-play overrides a developer rule not to reveal context
in a majority of runs with a naive developer prompt, and we introduce an
AI-assisted hardening method that reduces leakage to 0% in several user-prompt
variants. We further test evaluation awareness with a paired-track design and
measure frame-conditioned differences between matched "helpfulness" and
"harmfulness" evaluation prompts; we observe inconsistent assistance in 13% of
pairs. Finally, we find that the OpenAI Moderation API under-captures
materially helpful outputs relative to a semantic grader, and that refusal
rates differ by 5 to 10 percentage points across inference stacks, raising
reproducibility concerns. We release prompts, seeds, outputs, and code for
reproducible auditing at https://github.com/ndurner/gpt-oss-rt-run .

</details>


### [113] [OpenAI's GPT-OSS-20B Model and Safety Alignment Issues in a Low-Resource Language](https://arxiv.org/abs/2510.01266)
*Isa Inuwa-Dutse*

Main category: cs.CL

TL;DR: 研究总结了OpenAI的GPT-OSS-20b模型在低资源语言（豪萨语）环境中存在的安全漏洞，包括偏见、不准确和文化不敏感性。


<details>
  <summary>Details</summary>
Motivation: 评估模型在代表性不足的社区中的可靠性，并调查其在低资源语言环境下的安全对齐情况。

Method: 使用豪萨语进行红队测试，诱导模型生成有害、不敏感和不准确的内容。通过调查了解模型错误认知的严重性。

Result: 模型被诱导生成有害内容，安全协议在面对礼貌用语时会放松。模型将有毒物质（杀虫剂和灭鼠剂）误认为可食用，调查显示98%的受访者认为它们有毒。模型还无法区分生熟食品，并使用贬低的文化谚语来构建错误论点。

Conclusion: 模型在低资源语言环境中存在安全漏洞，可能是由于安全调整不足所致。这暴露了当前红队测试的不足，并提出了一些改进建议。

Abstract: In response to the recent safety probing for OpenAI's GPT-OSS-20b model, we
present a summary of a set of vulnerabilities uncovered in the model, focusing
on its performance and safety alignment in a low-resource language setting. The
core motivation for our work is to question the model's reliability for users
from underrepresented communities. Using Hausa, a major African language, we
uncover biases, inaccuracies, and cultural insensitivities in the model's
behaviour. With a minimal prompting, our red-teaming efforts reveal that the
model can be induced to generate harmful, culturally insensitive, and factually
inaccurate content in the language. As a form of reward hacking, we note how
the model's safety protocols appear to relax when prompted with polite or
grateful language, leading to outputs that could facilitate misinformation and
amplify hate speech. For instance, the model operates on the false assumption
that common insecticide locally known as Fiya-Fiya (Cyphermethrin) and
rodenticide like Shinkafar Bera (a form of Aluminium Phosphide) are safe for
human consumption. To contextualise the severity of this error and popularity
of the substances, we conducted a survey (n=61) in which 98% of participants
identified them as toxic. Additional failures include an inability to
distinguish between raw and processed foods and the incorporation of demeaning
cultural proverbs to build inaccurate arguments. We surmise that these issues
manifest through a form of linguistic reward hacking, where the model
prioritises fluent, plausible-sounding output in the target language over
safety and truthfulness. We attribute the uncovered flaws primarily to
insufficient safety tuning in low-resource linguistic contexts. By
concentrating on a low-resource setting, our approach highlights a significant
gap in current red-teaming effort and offer some recommendations.

</details>


### [114] [AdaDetectGPT: Adaptive Detection of LLM-Generated Text with Statistical Guarantees](https://arxiv.org/abs/2510.01268)
*Hongyi Zhou,Jin Zhu,Pingfan Su,Kai Ye,Ying Yang,Shakeel A O B Gavioli-Akilagun,Chengchun Shi*

Main category: cs.CL

TL;DR: 提出了一种名为 AdaDetectGPT 的新型文本分类器，通过学习“见证函数”来提高基于 logits 的检测器在区分人类和大型语言模型（LLM）生成文本方面的性能，并在多项指标上显著优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有的基于 logits 的文本检测器仅依赖于对数概率，这可能不是最优的，因此需要一种更有效的方法来区分人类和大型语言模型（LLM）生成的文本。

Method: 提出了一种名为 AdaDetectGPT 的新型分类器，该分类器通过从训练数据中学习一个“见证函数”来增强基于 logits 的检测器的性能。

Result: AdaDetectGPT 在各种数据集和 LLM 组合中几乎均匀地改进了现有技术，性能提升高达 58%。

Conclusion: AdaDetectGPT 能够显著提高检测人类和 LLM 生成文本的性能，并提供了统计保证。

Abstract: We study the problem of determining whether a piece of text has been authored
by a human or by a large language model (LLM). Existing state of the art
logits-based detectors make use of statistics derived from the log-probability
of the observed text evaluated using the distribution function of a given
source LLM. However, relying solely on log probabilities can be sub-optimal. In
response, we introduce AdaDetectGPT -- a novel classifier that adaptively
learns a witness function from training data to enhance the performance of
logits-based detectors. We provide statistical guarantees on its true positive
rate, false positive rate, true negative rate and false negative rate.
Extensive numerical studies show AdaDetectGPT nearly uniformly improves the
state-of-the-art method in various combination of datasets and LLMs, and the
improvement can reach up to 58%. A python implementation of our method is
available at https://github.com/Mamba413/AdaDetectGPT.

</details>


### [115] [Think Twice, Generate Once: Safeguarding by Progressive Self-Reflection](https://arxiv.org/abs/2510.01270)
*Hoang Phan,Victor Li,Qi Lei*

Main category: cs.CL

TL;DR: PSR是一种新颖的推理时技术，可以通过自我监控和纠正输出来提高LLM的安全性，而无需额外训练。


<details>
  <summary>Details</summary>
Motivation: LLM在生成有害或不当内容方面存在潜在风险，需要一种方法来提高其安全性。

Method: 提出了一种名为Progressive Self-Reflection (PSR)的新颖推理时技术，使LLM能够动态地自我监控和纠正其输出。还引入了一个轻量级的自反思预测器，以根据输入复杂性估算最佳反思轮次。

Result: PSR将Llama-3.1-8B-Instruct的攻击成功率从77.5%降至5.9%，将Llama-3.1-8B的攻击成功率从89.7%降至5.6%，将Qwen2.5-7B-Instruct的攻击成功率从44.4%降至3.8%，同时保持其在良性任务上的原始性能。

Conclusion: PSR是一种可扩展的测试时方法，通过动态分配与输入风险相称的计算资源来提高LLM的安全性。

Abstract: Large language models (LLMs) have revolutionized natural language processing
with their ability to generate coherent and contextually relevant text.
However, their deployment raises significant concerns about the potential for
generating harmful or inappropriate content. In this paper, we introduce
Progressive Self-Reflection (PSR), a novel inference-time technique that
empowers LLMs to self-monitor and correct their outputs dynamically.
Experimental results demonstrate that applying our proposed method to
Llama-3.1-8B-Instruct reduces the attack success rate from 77.5\% to 5.9\%, to
Llama-3.1-8B base from 89.7\% to 5.6\%, and to Qwen2.5-7B-Instruct from 44.4\%
to 3.8\%, without additional training, while maintaining their original
performance on benign tasks. Our approach acts as a test-time scaling method,
where additional self-reflection rounds enhance safety at the cost of inference
overhead. To balance safety with computational efficiency, we introduce a
lightweight self-reflection predictor that estimates the optimal number of
reflection rounds based on input complexity. This adaptive mechanism prevents
unnecessary self-assessment on benign inputs while ensuring thorough evaluation
when encountering potentially harmful content. Our findings suggest that
Progressive Self-Reflection serves as a scalable test-time approach, enhancing
LLM safety by dynamically allocating computational resources in proportion to
the input's risk profile.

</details>


### [116] [TraceDet: Hallucination Detection from the Decoding Trace of Diffusion Large Language Models](https://arxiv.org/abs/2510.01274)
*Shenxu Chang,Junchi Yu,Weixing Wang,Yongqiang Chen,Jialin Yu,Philip Torr,Jindong Gu*

Main category: cs.CL

TL;DR: D-LLMs 存在幻觉问题，现有检测方法不适用。提出 TraceDet 框架，通过分析 D-LLMs 的多步去噪过程来检测幻觉，实验证明 TraceDet 效果显著。


<details>
  <summary>Details</summary>
Motivation: 现有针对 AR-LLMs 的幻觉检测方法不适用于 D-LLMs，因为 D-LLMs 的幻觉信号出现在多步去噪过程中。

Method: 提出 TraceDet 框架，将去噪过程建模为行为轨迹，识别对幻觉响应信息量最大的子轨迹，以检测 D-LLMs 多步去噪过程中的幻觉信号。

Result: TraceDet 在多个开源 D-LLMs 上进行了广泛实验，平均 AUROC 提升 15.2%，显著优于基线方法。

Conclusion: TraceDet 框架能够有效利用 D-LLMs 的中间去噪步骤来检测幻觉，解决了现有方法的局限性，并提高了 D-LLMs 的可靠性。

Abstract: Diffusion large language models (D-LLMs) have recently emerged as a promising
alternative to auto-regressive LLMs (AR-LLMs). However, the hallucination
problem in D-LLMs remains underexplored, limiting their reliability in
real-world applications. Existing hallucination detection methods are designed
for AR-LLMs and rely on signals from single-step generation, making them
ill-suited for D-LLMs where hallucination signals often emerge throughout the
multi-step denoising process. To bridge this gap, we propose TraceDet, a novel
framework that explicitly leverages the intermediate denoising steps of D-LLMs
for hallucination detection. TraceDet models the denoising process as an action
trace, with each action defined as the model's prediction over the cleaned
response, conditioned on the previous intermediate output. By identifying the
sub-trace that is maximally informative to the hallucinated responses, TraceDet
leverages the key hallucination signals in the multi-step denoising process of
D-LLMs for hallucination detection. Extensive experiments on various open
source D-LLMs demonstrate that TraceDet consistently improves hallucination
detection, achieving an average gain in AUROC of 15.2% compared to baselines.

</details>


### [117] [LLM Based Sentiment Classification From Bangladesh E-Commerce Reviews](https://arxiv.org/abs/2510.01276)
*Sumaiya Tabassum*

Main category: cs.CL

TL;DR: 本研究旨在探讨使用大型语言模型（LLMs）进行情感分析，特别是在孟加拉国电子商务评论的背景下，并比较了包括Llama-3.1-8B在内的多种模型的性能，最后强调了参数高效微调（PEFT）方法的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）的发展，情感分析在理解消费者情绪方面变得越来越重要，但现有模型在处理复杂语言和多语言评论时仍面临挑战，因此有必要研究LLMs在孟加拉国电子商务评论中的情感分析能力。

Method: 本研究使用了4000个孟加拉语和英语的电子商务评论样本，对包括Llama-3.1-8B、Phi-3.5-mini-instruct、Mistral-7B-v0.1、DistilBERT-multilingual、mBERT和XLM-R-base在内的多种模型进行了微调，并采用了LoRA和PEFT等参数高效微调技术。

Result: 在对孟加拉国电子商务评论进行情感分析的实验中，微调后的Llama-3.1-8B模型表现最佳，其整体准确率、精确率、召回率和F1分数分别为95.5%、93%、88%和90%，优于其他经过微调的模型。

Conclusion: 研究表明，LLMs，特别是Llama-3.1-8B，在处理孟加拉国电子商务评论的情感分析任务上具有很高的准确性，并且参数高效微调（PEFT）方法能够有效降低计算成本，使其适用于资源有限的环境。这的应用场景。

Abstract: Sentiment analysis is an essential part of text analysis, which is a larger
field that includes determining and evaluating the author's emotional state.
This method is essential since it makes it easier to comprehend consumers'
feelings, viewpoints, and preferences holistically. The introduction of large
language models (LLMs), such as Llama, has greatly increased the availability
of cutting-edge model applications, such as sentiment analysis. However,
accurate sentiment analysis is hampered by the intricacy of written language
and the diversity of languages used in evaluations. The viability of using
transformer-based BERT models and other LLMs for sentiment analysis from
Bangladesh e commerce reviews is investigated in this paper. A subset of 4000
samples from the original dataset of Bangla and English customer reviews was
utilized to fine-tune the model. The fine tuned Llama-3.1-8B model outperformed
other fine-tuned models, including Phi-3.5-mini-instruct, Mistral-7B-v0.1,
DistilBERT-multilingual, mBERT, and XLM-R-base, with an overall accuracy,
precision, recall, and F1 score of 95.5%, 93%, 88%, 90%. The study emphasizes
how parameter efficient fine-tuning methods (LoRA and PEFT) can lower
computational overhead and make it appropriate for contexts with limited
resources. The results show how LLMs can

</details>


### [118] [TUMIX: Multi-Agent Test-Time Scaling with Tool-Use Mixture](https://arxiv.org/abs/2510.01279)
*Yongchao Chen,Jiefeng Chen,Rui Meng,Ji Yin,Na Li,Chuchu Fan,Chi Wang,Tomas Pfister,Jinsung Yoon*

Main category: cs.CL

TL;DR: TUMIX 是一个集成多种工具使用策略的框架，通过并行运行多个智能体并迭代共享和优化答案，显著提高了大型语言模型（LLM）在推理任务中的准确性，同时保持了较低的推理成本。


<details>
  <summary>Details</summary>
Motivation: 在集成 Code Interpreter 和 Search 等工具以增强 LLM 推理能力（如 ChatGPT Agent 和 Gemini-Pro）后，缺乏关于如何最优地结合文本推理、编码和搜索来回答多样化问题的实践指导。

Method: 提出了一种名为 Tool-Use Mixture (TUMIX) 的集成框架。该框架并行运行多个智能体，每个智能体采用不同的工具使用策略和回答路径。智能体们基于问题和之前的回答，进行迭代式的答案共享和优化。

Result: 在实验中，TUMIX 在 Gemini-2.5-Pro 和 Gemini-2.5-Flash 模型上，于关键推理基准测试中，相比于最先进的基线方法，平均准确率提高了高达 3.55%，同时推理成本几乎不变。研究还发现，智能体的多样性和质量至关重要，并且可以通过使用 LLM 自动优化智能体设计来提升。此外，TUMIX 可以在达到足够置信度时停止优化，以 49% 的推理成本保持性能。

Conclusion: TUMIX 框架通过结合多种工具使用策略和智能体协作，有效解决了 LLM 在复杂推理任务中对多样化工具进行最优组合的挑战，实现了性能和成本之间的良好平衡，并且具有进一步扩展以获得更高性能的潜力。

Abstract: While integrating tools like Code Interpreter and Search has significantly
enhanced Large Language Model (LLM) reasoning in models like ChatGPT Agent and
Gemini-Pro, practical guidance on optimal tool use is lacking. The core
challenge is effectively combining textual reasoning, coding, and search for
diverse questions. In this paper, we propose Tool-Use Mixture (TUMIX), an
ensemble framework that runs multiple agents in parallel, each employing
distinct tool-use strategies and answer paths. Agents in TUMIX iteratively
share and refine responses based on the question and previous answers. In
experiments, TUMIX achieves significant gains over state-of-the-art
tool-augmented and test-time scaling methods, delivering an average accuracy
improvement of up to 3.55% over the best baseline on Gemini-2.5-Pro and
Gemini-2.5-Flash across key reasoning benchmarks, with near-equal inference
costs. We find that agent diversity and quality are crucial and can be enhanced
by using LLMs to auto-optimize agent designs. Furthermore, TUMIX can halt
refinement upon reaching sufficient confidence, preserving performance at only
49% of the inference cost. Further scaling can achieve higher performance,
albeit at a greater cost.

</details>


### [119] [Evaluation Sheet for Deep Research: A Use Case for Academic Survey Writing](https://arxiv.org/abs/2510.01283)
*Israel Abebe Azime,Tadesse Destaw Belay,Atnafu Lambebo Tonja*

Main category: cs.CL

TL;DR: LLMs 驱动的自主工具（如 Deep Search）可用于知识密集型任务，但需要仔细的评估标准。对 OpenAI 和 Google 的 Deep Search 在学术调查写作方面的评估表明，它们在代表目标领域方面存在不足。


<details>
  <summary>Details</summary>
Motivation: 评估 LLMs 驱动的自主工具（如 Deep Search）在知识密集型任务中的能力，并为这些工具的评估提供标准。

Method: 提出一个评估标准，并选择学术调查写作作为用例，对 OpenAI 和 Google 的 Deep Search 的输出报告进行评估。

Result: 评估结果表明，需要有精心设计的评估标准。与搜索引擎相比，独立的 Deep Research 工具在生成学术调查报告方面存在巨大差距，并且在代表目标领域方面存在不足。

Conclusion: LLMs 驱动的自主工具在执行知识密集型任务方面有巨大潜力，但目前的评估标准和工具本身都需要改进，以确保它们能够准确有效地代表目标领域。

Abstract: Large Language Models (LLMs) powered with argentic capabilities are able to
do knowledge-intensive tasks without human involvement. A prime example of this
tool is Deep research with the capability to browse the web, extract
information and generate multi-page reports. In this work, we introduce an
evaluation sheet that can be used for assessing the capability of Deep Research
tools. In addition, we selected academic survey writing as a use case task and
evaluated output reports based on the evaluation sheet we introduced. Our
findings show the need to have carefully crafted evaluation standards. The
evaluation done on OpenAI`s Deep Search and Google's Deep Search in generating
an academic survey showed the huge gap between search engines and standalone
Deep Research tools, the shortcoming in representing the targeted area.

</details>


### [120] [HiSpec: Hierarchical Speculative Decoding for LLMs](https://arxiv.org/abs/2510.01336)
*Avinash Kumar,Sujay Sanghavi,Poulami Das*

Main category: cs.CL

TL;DR: Speculative decoding uses a small model to predict tokens, which a larger model then verifies. This verification step can be slow, so we propose HiSpec, which uses early-exit models for faster verification and reuses computations to improve efficiency and accuracy.


<details>
  <summary>Details</summary>
Motivation: Verification is a bottleneck in speculative decoding for LLMs, and existing methods for accelerating it have high overheads or compromise accuracy. There is a need for a more efficient and accurate method.

Method: HiSpec uses early-exit (EE) models for low-overhead intermediate verification. It reuses key-value caches and hidden states between draft, verifier, and target models. It also periodically validates accepted draft tokens against the target model to maintain accuracy.

Result: HiSpec improves throughput by an average of 1.28x and up to 2.01x compared to baseline single-layer speculation, without sacrificing accuracy.

Conclusion: HiSpec offers a high-throughput and resource-efficient framework for speculative decoding by leveraging EE models for intermediate verification and optimizing resource reuse, demonstrating significant performance gains.

Abstract: Speculative decoding accelerates LLM inference by using a smaller draft model
to speculate tokens that a larger target model verifies. Verification is often
the bottleneck (e.g. verification is $4\times$ slower than token generation
when a 3B model speculates for a 70B target model), but most prior works focus
only on accelerating drafting. $\textit{``Intermediate"}$ verification reduces
verification time by discarding inaccurate draft tokens early, but existing
methods incur substantial training overheads in incorporating the intermediate
verifier, increase the memory footprint to orchestrate the intermediate
verification step, and compromise accuracy by relying on approximate
heuristics.
  We propose $\underline{\textit{Hi}}\textit{erarchical
}\underline{\textit{Spec}}\textit{ulative Decoding (HiSpec)}$, a framework for
high-throughput speculative decoding that exploits $\textit{early-exit (EE)
models}$ for low-overhead intermediate verification. EE models allow tokens to
exit early by skipping layer traversal and are explicitly trained so that
hidden states at selected layers can be interpreted, making them uniquely
suited for intermediate verification without drastically increasing compute and
memory overheads. To improve resource-efficiency even further, we design a
methodology that enables HiSpec to re-use key-value caches and hidden states
between the draft, intermediate verifier, and target models. To maintain
accuracy, HiSpec periodically validates the draft tokens accepted by the
intermediate verifier against the target model. Our evaluations using various
representative benchmarks and models show that HiSpec improves throughput by
1.28$\times$ on average and by up to 2.01$\times$ compared to the baseline
single-layer speculation without compromising accuracy.

</details>


### [121] [TAG-EQA: Text-And-Graph for Event Question Answering via Structured Prompting Strategies](https://arxiv.org/abs/2510.01391)
*Maithili Kadam,Francis Ferraro*

Main category: cs.CL

TL;DR: TAG-EQA 通过将结构化因果事件图注入 LLM 输入，提高了 LLM 在事件问答任务上的表现，尤其是在需要因果或时间推理时。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在处理需要因果或时间推理的事件问答任务时存在不足。

Method: 提出 TAG-EQA（Text-And-Graph for Event Question Answering）框架，将因果事件图转换为自然语言陈述并注入 LLM 输入。该框架包含九种提示配置，结合了三种策略（zero-shot、few-shot、chain-of-thought）和三种输入模式（仅文本、仅图、文本+图），以系统地分析结构化知识何时以及如何辅助推理。

Result: 在 TORQUESTRA 基准测试中，TAG-EQA 平均将准确率比纯文本基线提高了 5%，在 zero-shot 设置下提高了 12%，在图增强的 CoT 提示有效时提高了 18%。

Conclusion: 因果图可以在无需微调的情况下增强 LLM 的事件推理能力，为在基于提示的问答中编码结构提供了一种灵活的方式。

Abstract: Large language models (LLMs) excel at general language tasks but often
struggle with event-based questions-especially those requiring causal or
temporal reasoning. We introduce TAG-EQA (Text-And-Graph for Event Question
Answering), a prompting framework that injects causal event graphs into LLM
inputs by converting structured relations into natural-language statements.
TAG-EQA spans nine prompting configurations, combining three strategies
(zero-shot, few-shot, chain-of-thought) with three input modalities (text-only,
graph-only, text+graph), enabling a systematic analysis of when and how
structured knowledge aids inference. On the TORQUESTRA benchmark, TAG-EQA
improves accuracy by 5% on average over text-only baselines, with gains up to
12% in zero-shot settings and 18% when graph-augmented CoT prompting is
effective. While performance varies by model and configuration, our findings
show that causal graphs can enhance event reasoning in LLMs without
fine-tuning, offering a flexible way to encode structure in prompt-based QA.

</details>


### [122] [A-VERT: Agnostic Verification with Embedding Ranking Targets](https://arxiv.org/abs/2510.01469)
*Nicolás Aguirre,Ramiro Caso,Ramiro Rodríguez Colmeiro,Mauro Santelli,Joaquín Toranzo Calderón*

Main category: cs.CL

TL;DR: 提出了一种不依赖于固定结构、利用语义嵌入距离来评估语言模型响应的新方法，该方法计算成本低且鲁棒性强。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型响应评估方法要么计算成本高（如LLM-as-a-Judge），要么与实际情况相差甚远（如字符串匹配、logprob）。

Method: 提出了一种结构无关的评估方法，利用语义嵌入距离来匹配目标候选文本和任意语言模型生成的文本，从而实现对响应的鲁棒分类。

Result: 该方法在3个数据集和3种不同的语言模型架构上进行了测试，与人工标注者相比，回归分数约为0.97，准确率约为96%。

Conclusion: 所提出的结构无关的评估方法能够以较低的计算成本（小于10B参数的嵌入模型）实现对语言模型响应的鲁棒评估，并且取得了与人类标注者相当的准确率。

Abstract: The automatic evaluation of Language Model (LM) responses is a critical piece
in the development of benchmarks and metrics, both for model training and
quality assessment of production model endpoints. The current approaches to
response classification relies on methods that are too expensive (i.e.
LLM-as-a-Judge) or that are far from real-world conditions (string-matching,
logprob). In this paper, a structure-free evaluation method is presented. The
method makes use of semantic embedding distances to match target candidates
with arbitrary LM-generated text, resulting in a robust classification of the
response at a relatively low compute cost (embedding models of less than $10B$
parameters). The results show a regression score of ~0.97 and an accuracy of
~96% against human annotators, tested over 3 data sets and 3 different LM
architectures.

</details>


### [123] [One More Question is Enough, Expert Question Decomposition (EQD) Model for Domain Quantitative Reasoning](https://arxiv.org/abs/2510.01526)
*Mengyu Wang,Sotirios Sabanis,Miguel de Carvalho,Shay B. Cohen,Tiejun Ma*

Main category: cs.CL

TL;DR: EQD是一种高效的、基于少量示例进行微调的方法，通过将复杂问题分解为子问题来提升LLM在特定领域（如金融）的量化推理能力，并在四个金融基准数据集上展现出优于现有SOTA模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）在特定领域（如金融）的量化推理和复杂问答方面存在挑战，需要一种能够结合领域知识和计算效率的方法。

Method: 提出了一种名为“专家问题分解”（EQD）的方法，该方法采用两步微调框架，并使用一个奖励函数来评估生成的子问题在改进问答结果方面的有效性。该方法仅需数千个训练样本和单个A100 GPU即可完成微调，推理速度与零样本提示相当。

Result: 在金融领域的四个基准数据集上，EQD相比于最先进的领域微调模型和高级提示策略，一致性地提升了不同LLM的问答性能0.6%至10.5%。

Conclusion: EQD在领域特定的问答任务中，尤其是在金融领域，能够有效地提升LLM的量化推理能力，并且相对于详细的指导步骤，生成单一的、有针对性的支持性问题能带来更大的效益。

Abstract: Domain-specific quantitative reasoning remains a major challenge for large
language models (LLMs), especially in fields requiring expert knowledge and
complex question answering (QA). In this work, we propose Expert Question
Decomposition (EQD), an approach designed to balance the use of domain
knowledge with computational efficiency. EQD is built on a two-step fine-tuning
framework and guided by a reward function that measures the effectiveness of
generated sub-questions in improving QA outcomes. It requires only a few
thousand training examples and a single A100 GPU for fine-tuning, with
inference time comparable to zero-shot prompting. Beyond its efficiency, EQD
outperforms state-of-the-art domain-tuned models and advanced prompting
strategies. We evaluate EQD in the financial domain, characterized by
specialized knowledge and complex quantitative reasoning, across four benchmark
datasets. Our method consistently improves QA performance by 0.6% to 10.5%
across different LLMs. Our analysis reveals an important insight: in
domain-specific QA, a single supporting question often provides greater benefit
than detailed guidance steps.

</details>


### [124] [ReSSFormer: A Recursive Sparse Structured Transformer for Scalable and Long-Context Reasoning](https://arxiv.org/abs/2510.01585)
*Haochen You,Baojing Liu*

Main category: cs.CL

TL;DR: ReSSFormer通过递归、稀疏注意力和自组织编码器结构解决了Transformer在长上下文推理、计算效率和结构泛化方面的挑战，并在多项任务中表现优于基线模型。


<details>
  <summary>Details</summary>
Motivation: Transformer架构在扩展性方面表现出色，但在长上下文推理、计算效率和结构泛化方面仍面临挑战，这主要是由于其固定的层堆叠、密集注意力和对位置编码的依赖。

Method: 提出了一种名为ReSSFormer的递归稀疏结构Transformer，它集成了三种互补的创新：1. 递归推理与记忆单元（R2MU），用于进行有界深度的迭代推理；2. 自适应稀疏注意力模块（ASAM），用于进行高效且专注的上下文选择；3. 自组织编码器结构（SOES），用于进行无位置编码的结构归纳。ReSSFormer用递归推理取代了传统的深度堆叠，用token和expert级别的稀疏性取代了全注意力，并直接从内容中学习潜在的token拓扑。

Result: 在语言建模、多跳问答和结构敏感任务上，ReSSFormer在相当的FLOPs和参数预算下，持续优于强有力的基线模型。

Conclusion: ReSSFormer在可扩展性、效率和结构灵活性方面表现出色。

Abstract: While Transformer architectures have demonstrated impressive scalability
across domains, they continue to face challenges in long-context reasoning,
computational efficiency, and structural generalization - largely due to rigid
layer stacking, dense attention, and reliance on positional encodings. We
present ReSSFormer, a Recursive Sparse Structured Transformer that integrates
three complementary innovations: Recurrent Reasoning & Memory Unit (R2MU) for
iterative reasoning with bounded depth, Adaptive Sparse Attention Module (ASAM)
for efficient and focused context selection, and Self-Organizing Encoder
Structure (SOES) for position-free structure induction. ReSSFormer replaces
conventional depth stacking with recurrent inference, substitutes full
attention with token- and expert-level sparsity, and models latent token
topology directly from content. Across language modeling, multi-hop QA, and
structure-sensitive tasks, ReSSFormer consistently outperforms strong baselines
under comparable FLOPs and parameter budgets, highlighting its scalability,
efficiency, and structural flexibility.

</details>


### [125] [CLUE: Non-parametric Verification from Experience via Hidden-State Clustering](https://arxiv.org/abs/2510.01591)
*Zhenwen Liang,Ruosen Li,Yujun Zhou,Linfeng Song,Dian Yu,Xinya Du,Haitao Mi,Dong Yu*

Main category: cs.CL

TL;DR: LLM输出质量评估的挑战在于现有方法要么依赖可能过度拟合表面线索的文本级信息，要么依赖可能在校准性差的模型上失效的代币概率校准置信度。本文提出直接利用模型的隐藏状态来统一验证，因为早期层保留语义和词汇特征，而后期层则包含置信度信息。


<details>
  <summary>Details</summary>
Motivation: 现有LLM输出质量评估方法存在局限性：文本级信息会过度拟合表面线索，而基于代币概率的置信度方法在校准性差的模型上会失效。因此，需要一种更可靠的评估方法。

Method: 提出了一种名为Clue（Clustering and Experience-based Verification）的验证方法。Clue是一种非参数验证器，不依赖任何可训练参数。它通过总结每个推理轨迹的隐藏状态差值，并根据与“成功”和“失败”簇的最近中心距离来对正确性进行分类。这些簇是通过过去的经验形成的。

Result: Clue在AIME 24/25和GPQA数据集上，在重新排序候选时，一致优于LLM-as-a-judge基线，并且达到或超过了现代基于置信度的方法。例如，在使用1.5B模型处理AIME 24时，Clue将准确率从56.7%（majority@64）提高到70.0%（top-maj@16）。

Conclusion: LLM的隐藏状态包含了可以有效用于验证其输出质量的丰富信息。Clue方法证明了直接利用这些隐藏状态信号的有效性，即使是简单的非参数方法也能取得优于现有先进方法的性能。

Abstract: Assessing the quality of Large Language Model (LLM) outputs presents a
critical challenge. Previous methods either rely on text-level information
(e.g., reward models, majority voting), which can overfit to superficial cues,
or on calibrated confidence from token probabilities, which would fail on
less-calibrated models. Yet both of these signals are, in fact, partial
projections of a richer source of information: the model's internal hidden
states. Early layers, closer to token embeddings, preserve semantic and lexical
features that underpin text-based judgments, while later layers increasingly
align with output logits, embedding confidence-related information. This paper
explores hidden states directly as a unified foundation for verification. We
show that the correctness of a solution is encoded as a geometrically separable
signature within the trajectory of hidden activations. To validate this, we
present Clue (Clustering and Experience-based Verification), a deliberately
minimalist, non-parametric verifier. With no trainable parameters, CLUE only
summarizes each reasoning trace by an hidden state delta and classifies
correctness via nearest-centroid distance to ``success'' and ``failure''
clusters formed from past experience. The simplicity of this method highlights
the strength of the underlying signal. Empirically, CLUE consistently
outperforms LLM-as-a-judge baselines and matches or exceeds modern
confidence-based methods in reranking candidates, improving both top-1 and
majority-vote accuracy across AIME 24/25 and GPQA. As a highlight, on AIME 24
with a 1.5B model, CLUE boosts accuracy from 56.7% (majority@64) to 70.0%
(top-maj@16).

</details>


### [126] [A Comparison of Independent and Joint Fine-tuning Strategies for Retrieval-Augmented Generation](https://arxiv.org/abs/2510.01600)
*Neal Gregory Lawton,Alfy Samuel,Anoop Kumar,Daben Liu*

Main category: cs.CL

TL;DR: 本文评估并比较了检索增强生成（RAG）流水线的微调策略，包括独立微调、联合微调和两阶段微调。


<details>
  <summary>Details</summary>
Motivation: 检索增强生成（RAG）是一个流行的问答框架，由两个大型语言模型（LLMs）提供支持：一个嵌入模型，用于从数据库中检索与给定问题相关的上下文文档；一个生成器模型，用于使用检索到的上下文生成问题的答案。嵌入模型和生成器模型都可以进行微调，以提高 RAG 流水线在新任务上的性能，但存在多种具有不同成本和收益的微调策略。本文旨在评估和比较几种 RAG 微调策略，包括独立、联合和两阶段微调。

Method: 本文评估和比较了几种 RAG 微调策略，包括独立微调、联合微调和两阶段微调。

Result: 在实验中，我们观察到所有这些策略在 EM 和 F1 生成质量指标上都实现了大致相等的改进，尽管它们的计算成本存在显著差异。

Conclusion: 最佳微调策略的选择取决于训练数据集是否包含上下文标签以及是否需要对嵌入模型和生成器模型的学习率进行网格搜索。

Abstract: A Comparison of Independent and Joint Fine-tuning Strategies for
Retrieval-Augmented Generation Download PDF Neal Gregory Lawton, Alfy Samuel,
Anoop Kumar, Daben Liu Published: 20 Aug 2025, Last Modified: 17 Sept 2025EMNLP
2025 FindingsConference, Publication Chairs, AuthorsRevisionsBibTeXCC BY 4.0
Keywords: Retrieval-Augmented Generation (RAG), Large Language Models (LLMs),
Fine-tuning, Question Answering, Joint fine-tuning TL;DR: We evaluate and
compare strategies for fine-tuning Retrieval Augmented Generation (RAG)
pipelines, including independent fine-tuning, joint fine-tuning, and two-phase
fine-tuning. Abstract: Retrieval augmented generation (RAG) is a popular
framework for question answering that is powered by two large language models
(LLMs): an embedding model that retrieves context documents from a database
that are relevant to a given question, and a generator model that uses the
retrieved context to generate an answer to the question. Both the embedding and
generator models can be fine-tuned to increase performance of a RAG pipeline on
a new task, but multiple fine-tuning strategies exist with different costs and
benefits. In this paper, we evaluate and compare several RAG fine-tuning
strategies, including independent, joint, and two-phase fine-tuning. In our
experiments, we observe that all of these strategies achieve about equal
improvement in EM and F1 generation quality metrics, although they have
significantly different computational costs. We conclude the optimal
fine-tuning strategy to use depends on whether the training dataset includes
context labels and whether a grid search over the learning rates for the
embedding and generator models is required.

</details>


### [127] [RAG-BioQA Retrieval-Augmented Generation for Long-Form Biomedical Question Answering](https://arxiv.org/abs/2510.01612)
*Lovely Yeswanth Panchumarthi,Sai Prasad Gudari,Atharva Negi,Praveen Raj Budime,Harsit Upadhya*

Main category: cs.CL

TL;DR: RAG-BioQA是一个结合了检索增强生成和领域特定微调的新框架，旨在提供基于证据的、长篇幅的生物医学答案，以解决当前生物医学问答系统主要关注短答案的问题。


<details>
  <summary>Details</summary>
Motivation: 生物医学文献的快速增长使得获取精确的医疗信息变得困难，而现有的问答系统通常只提供短答案，无法满足临床决策的需求。

Method: 该框架集成了BioBERT embeddings和FAISS索引，并比较了多种重排策略（BM25, ColBERT, MonoT5）以优化上下文选择，最后通过微调的T5模型来综合证据。

Result: 在PubMedQA数据集上的实验结果显示，与基线方法相比，RAG-BioQA在BLEU、ROUGE和METEOR指标上取得了显著的提升。

Conclusion: RAG-BioQA在提供可访问的、基于证据的生物医学知识检索方面取得了进展，显著优于现有方法。

Abstract: The exponential growth of biomedical literature creates significant
challenges for accessing precise medical information. Current biomedical
question-answering systems primarily focus on short-form answers, failing to
provide the comprehensive explanations necessary for clinical decision-making.
We present RAG-BioQA, a novel framework combining retrieval-augmented
generation with domain-specific fine-tuning to produce evidence-based,
long-form biomedical answers. Our approach integrates BioBERT embeddings with
FAISS indexing and compares various re-ranking strategies (BM25, ColBERT,
MonoT5) to optimize context selection before synthesizing evidence through a
fine-tuned T5 model. Experimental results on the PubMedQA dataset show
significant improvements over baselines, with our best model achieving
substantial gains across BLEU, ROUGE, and METEOR metrics, advancing the state
of accessible, evidence-based biomedical knowledge retrieval.

</details>


### [128] [Efficient Training of Robust Traditional Chinese LLaMA-1B on a Single Consumer GPU: Continual Pre-training, SFT, and DPO](https://arxiv.org/abs/2510.01616)
*Yu-Cheng Chih,Ming-Tao Duan,Yong-Hao Hou*

Main category: cs.CL

TL;DR: 该研究通过一个名为PureTC-1B的三阶段稳定化流程，解决了小语言模型（SLM）在繁体中文（TC）部署中存在的Token不稳定问题，显著减少了非TC字符或代码转换的输出，并在繁体中文的特定任务上取得了优于其他模型的性能。


<details>
  <summary>Details</summary>
Motivation: 目前小语言模型（SLM）在繁体中文（TC）的部署受到Token层面不稳定的困扰，表现为模型会不可预测地输出非TC字符或进行语言转换，这阻碍了其在成本效益、设备端和低延迟AI应用中的广泛使用。

Method: 研究人员创建了一个名为PureTC-1B的三阶段稳定化流程，应用于Llama-3.2-1B-Instruct模型。该流程利用参数高效的LoRA适配器，结合了持续预训练（CPT）、监督微调（SFT）和直接偏好优化（DPO），以TC为中心的语料库和偏好数据进行训练，旨在提高模型的单语鲁棒性，而无需重新训练整个模型。

Result: PureTC-1B在模拟真实使用场景的基准测试中，非TC输出Token的相对减少量（微平均）达到了51.3%。在命名实体翻译（NET）任务上，与Llama-3B相比，PureTC-1B将不正确语言的Token减少了77.2%；与Qwen-1.5B相比，则减少了57.2%。

Conclusion: 研究证明，即使在1B参数规模下，通过PureTC-1B的稳定化流程也能够实现强大的TC语言符合度。该流程具有可复现性，仅需适配器即可，并且对硬件友好，为在繁体中文及其他非英语语言中提升语言稳定性提供了一个实用的方法。

Abstract: Small Language Models (SLMs) enable cost-effective, on-device and
latency-sensitive AI applications, yet their deployment in Traditional Chinese
(TC) remains hindered by token-level instability - models unpredictably emit
non-TC characters or code-switch into other languages. We address this
practical reliability gap by creating PureTC-1B, a three-stage stabilization
pipeline for Llama-3.2-1B-Instruct (an open-weight, instruction-tuned model
released by Meta) using parameter-efficient LoRA adapters. Our method combines
Continual Pre-Training (CPT) on TC-centric corpora, Supervised Fine-Tuning
(SFT) with instruction data, and Direct Preference Optimization (DPO) using
TC-adherence preferences to improve monolingual robustness without full-model
retraining. On a benchmark designed to simulate real-world usage, PureTC-1B
achieves a 51.3% relative reduction (micro-average) in non-TC output tokens
versus the base model. On a Named Entity Translation (NET) task, PureTC-1B
further reduces incorrect-language tokens by 77.2% relative to Llama-3B and
57.2% relative to Qwen-1.5B, indicating that robust TC adherence is attainable
even at the 1B scale. The pipeline is reproducible, adapter-only, and
hardware-friendly, offering practitioners a practical recipe to enhance
language stability for TC and potentially other non-English languages.

</details>


### [129] [AMAS: Adaptively Determining Communication Topology for LLM-based Multi-Agent System](https://arxiv.org/abs/2510.01617)
*Hui Yi Leong,Yuheng Li,Yuqing Wu,Wenwen Ouyang,Wei Zhu,Jiechao Gao*

Main category: cs.CL

TL;DR: LLM驱动的多智能体系统（MAS）通过动态图设计克服了传统MAS的局限性，实现了在各种任务中超越现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的MAS在应对工业问题时，由于其固定的、手工设计的图拓扑结构，缺乏对上下文的响应能力，从而限制了其有效性。

Method: 提出了一种名为AMAS的框架，该框架使用新颖的动态图设计器，通过轻量级的LLM适应来自动识别特定任务的最佳图配置，从而摆脱了对通用结构模板的依赖。AMAS利用单个输入的内在属性来智能地引导查询轨迹，通过任务优化的代理路径。

Result: 在问答、数学推理和代码生成等基准测试中，AMAS在多种LLM架构上系统地超越了最先进的单智能体和多智能体方法。

Conclusion: 上下文敏感的结构适应性是高性能LLM MAS部署的基础要求。

Abstract: Although large language models (LLMs) have revolutionized natural language
processing capabilities, their practical implementation as autonomous
multi-agent systems (MAS) for industrial problem-solving encounters persistent
barriers. Conventional MAS architectures are fundamentally restricted by
inflexible, hand-crafted graph topologies that lack contextual responsiveness,
resulting in diminished efficacy across varied academic and commercial
workloads. To surmount these constraints, we introduce AMAS, a
paradigm-shifting framework that redefines LLM-based MAS through a novel
dynamic graph designer. This component autonomously identifies task-specific
optimal graph configurations via lightweight LLM adaptation, eliminating the
reliance on monolithic, universally applied structural templates. Instead, AMAS
exploits the intrinsic properties of individual inputs to intelligently direct
query trajectories through task-optimized agent pathways. Rigorous validation
across question answering, mathematical deduction, and code generation
benchmarks confirms that AMAS systematically exceeds state-of-the-art
single-agent and multi-agent approaches across diverse LLM architectures. Our
investigation establishes that context-sensitive structural adaptability
constitutes a foundational requirement for high-performance LLM MAS
deployments.

</details>


### [130] [NLP Methods for Detecting Novel LLM Jailbreaks and Keyword Analysis with BERT](https://arxiv.org/abs/2510.01644)
*John Hawkins,Aditya Pramar,Rodney Beard,Rohitash Chandra*

Main category: cs.CL

TL;DR: LLM 容易受到“越狱”提示的攻击，这些提示会诱导模型生成不当内容。本研究使用机器学习模型来区分越狱提示和真实提示，并发现 BERT 模型在进行这种区分方面表现最佳。研究还发现，提示结构中的明确反思性可能是越狱意图的一个信号。


<details>
  <summary>Details</summary>
Motivation: LLM 容易受到越狱提示的攻击，这些提示会诱导模型生成不当内容。需要有效的方法来检测这些提示。

Method: 分析了不同机器学习模型区分越狱提示和真实提示的能力，特别是关注识别先前未见过策略的越狱能力。对用于区分越狱和真实提示的关键字进行了可视化。

Result: 使用当前数据集，对越狱提示进行端到端微调的双向 Transformer 表示 (BERT) 模型在识别越狱方面取得了最佳性能。可视化显示，提示结构中的明确反思性可能是越狱意图的信号。

Conclusion: BERT 模型在区分越狱提示方面表现最佳，并且提示结构中的明确反思性可能是越狱意图的一个信号。

Abstract: Large Language Models (LLMs) suffer from a range of vulnerabilities that
allow malicious users to solicit undesirable responses through manipulation of
the input text. These so-called jailbreak prompts are designed to trick the LLM
into circumventing the safety guardrails put in place to keep responses
acceptable to the developer's policies. In this study, we analyse the ability
of different machine learning models to distinguish jailbreak prompts from
genuine uses, including looking at our ability to identify jailbreaks that use
previously unseen strategies. Our results indicate that using current datasets
the best performance is achieved by fine tuning a Bidirectional Encoder
Representations from Transformers (BERT) model end-to-end for identifying
jailbreaks. We visualise the keywords that distinguish jailbreak from genuine
prompts and conclude that explicit reflexivity in prompt structure could be a
signal of jailbreak intention.

</details>


### [131] [Learning to Look at the Other Side: A Semantic Probing Study of Word Embeddings in LLMs with Enabled Bidirectional Attention](https://arxiv.org/abs/2510.01652)
*Zhaoxin Feng,Jianfei Ma,Emmanuele Chersoni,Xiaojing Zhao,Xiaoyi Bao*

Main category: cs.CL

TL;DR: LLMs在文本嵌入任务中表现不佳，本文旨在探索双向注意力机制是否能克服这一限制。


<details>
  <summary>Details</summary>
Motivation: LLMs在文本理解和生成方面表现出色，但在文本嵌入任务中表现不佳，原因在于单向注意力机制的限制。

Method: 通过额外的训练步骤，逐步启用双向注意力和无监督/有监督对比学习来测试Llama架构的不同变体。

Result: （摘要中未提供具体结果）

Conclusion: （摘要中未提供具体结论）

Abstract: Autoregressive Large Language Models (LLMs) demonstrate exceptional
performance in language understanding and generation. However, their
application in text embedding tasks has been relatively slow, along with the
analysis of their semantic representation in probing tasks, due to the
constraints of the unidirectional attention mechanism.
  This paper aims to explore whether such constraints can be overcome by
enabling bidirectional attention in LLMs. We tested different variants of the
Llama architecture through additional training steps, progressively enabling
bidirectional attention and unsupervised/supervised contrastive learning.

</details>


### [132] [SoK: Measuring What Matters for Closed-Loop Security Agents](https://arxiv.org/abs/2510.01654)
*Mudita Khurana,Raunak Jain*

Main category: cs.CL

TL;DR: CLASP是一个闭环自主安全性能框架，为评估安全系统中的自主代理提供了通用语言和标准，并通过CLC分数量化其性能。


<details>
  <summary>Details</summary>
Motivation: AI驱动的攻击系统发展迅速，而传统防御措施滞后，导致安全工具和研究碎片化，存在漏洞，需要能够整合安全生命周期各环节的自主代理。然而，目前缺乏定义这些代理能力、评估它们的方法以及衡量其实际性能的基准。

Method: 引入CLASP框架，该框架将安全生命周期（侦察、利用、根源分析、补丁合成、验证）与核心代理能力（规划、工具使用、记忆、推理、反思和感知）相匹配，为评估安全任务中的代理能力提供通用词汇和标准。应用CLASP分析了21个代表性作品，并定义了闭环能力（CLC）分数，这是一个量化闭环程度和操作有效性的复合指标。

Result: CLASP框架成功地映射了现有系统的优势和能力差距。CLC分数提供了一种量化闭环安全代理性能的方法。

Conclusion: CLASP和CLC分数共同为闭环安全代理的发展提供了所需的词汇、诊断和测量方法，有望推动功能级性能的提升和实际性能的衡量。

Abstract: Cybersecurity is a relentless arms race, with AI driven offensive systems
evolving faster than traditional defenses can adapt. Research and tooling
remain fragmented across isolated defensive functions, creating blind spots
that adversaries exploit. Autonomous agents capable of integrating, exploit
confirmation, remediation, and validation into a single closed loop offer
promise, but the field lacks three essentials: a framework defining the agentic
capabilities of security systems across security life cycle, a principled
method for evaluating closed loop agents, and a benchmark for measuring their
performance in practice. We introduce CLASP: the Closed-Loop Autonomous
Security Performance framework which aligns the security lifecycle
(reconnaissance, exploitation, root cause analysis, patch synthesis,
validation) with core agentic capabilities (planning, tool use, memory,
reasoning, reflection & perception) providing a common vocabulary and rubric
for assessing agentic capabilities in security tasks. By applying CLASP to 21
representative works, we map where systems demonstrate strengths, and where
capability gaps persist. We then define the Closed-Loop Capability (CLC) Score,
a composite metric quantifying both degree of loop closure and operational
effectiveness, and outline the requirements for a closed loop benchmark.
Together, CLASP and the CLC Score, provide the vocabulary, diagnostics, and
measurements needed to advance both function level performance and measure
closed loop security agents.

</details>


### [133] [MDSEval: A Meta-Evaluation Benchmark for Multimodal Dialogue Summarization](https://arxiv.org/abs/2510.01659)
*Yinhong Liu,Jianfeng He,Hang Su,Ruixue Lian,Yi Nian,Jake Vincent,Srikanth Vishnubhotla,Robinson Piramuthu,Saab Mansour*

Main category: cs.CL

TL;DR: MDSEval是首个用于多模态对话摘要（MDS）的元评估基准，包含图像共享对话、摘要和人类关于八个质量方面的判断。该基准通过新颖的MEKI过滤框架来确保数据质量和丰富性，并首次确定了MDS特有的关键评估维度。实验表明，现有的评估方法在区分先进多模态大模型生成的摘要方面存在局限性，并容易受到各种偏差的影响。


<details>
  <summary>Details</summary>
Motivation: 开发有效的多模态对话摘要（MDS）模型需要稳健的自动评估方法，以降低成本和人力投入，但这需要以人类注释为基础的强大元评估基准。

Method: 提出了一种新颖的、利用跨模态互斥关键信息（MEKI）的过滤框架来构建MDSEval基准。该基准包含图像共享对话、摘要和人类对八个质量方面的判断。

Result: MDSEval基准揭示了现有评估方法在区分先进多模态大模型生成的摘要方面的局限性，并指出了它们易受各种偏差影响的弱点。

Conclusion: MDSEval是首个用于MDS的元评估基准，包含图像共享对话、摘要和人类判断，通过MEKI过滤框架保证数据质量，并为评估MDS的关键维度提供了依据。现有评估方法在此基准上面临挑战。

Abstract: Multimodal Dialogue Summarization (MDS) is a critical task with wide-ranging
applications. To support the development of effective MDS models, robust
automatic evaluation methods are essential for reducing both cost and human
effort. However, such methods require a strong meta-evaluation benchmark
grounded in human annotations. In this work, we introduce MDSEval, the first
meta-evaluation benchmark for MDS, consisting image-sharing dialogues,
corresponding summaries, and human judgments across eight well-defined quality
aspects. To ensure data quality and richfulness, we propose a novel filtering
framework leveraging Mutually Exclusive Key Information (MEKI) across
modalities. Our work is the first to identify and formalize key evaluation
dimensions specific to MDS. We benchmark state-of-the-art modal evaluation
methods, revealing their limitations in distinguishing summaries from advanced
MLLMs and their susceptibility to various bias.

</details>


### [134] [How Do Language Models Compose Functions?](https://arxiv.org/abs/2510.01685)
*Apoorv Khandelwal,Ellie Pavlick*

Main category: cs.CL

TL;DR: LLMs在解决两跳事实回忆任务时，要么采用组合机制，要么直接处理，这取决于嵌入空间几何。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs是否以及如何使用组合机制来解决组合任务，特别是两跳事实回忆任务。

Method: 使用Logit Lens分析LLMs在执行$g(f(x))$任务时的残差流激活，识别计算$f(x)$的中间变量。

Result: LLMs在组合任务上仍然存在“组合性鸿沟”。识别出两种处理机制：一种是组合式，计算$f(x)$；另一种是直接式，不计算$f(x)$。组合式机制在存在从$x$到$g(f(x))$的线性映射时占主导地位。

Conclusion: LLMs解决两跳事实回忆任务的机制与嵌入空间几何相关。

Abstract: While large language models (LLMs) appear to be increasingly capable of
solving compositional tasks, it is an open question whether they do so using
compositional mechanisms. In this work, we investigate how feedforward LLMs
solve two-hop factual recall tasks, which can be expressed compositionally as
$g(f(x))$. We first confirm that modern LLMs continue to suffer from the
"compositionality gap": i.e. their ability to compute both $z = f(x)$ and $y =
g(z)$ does not entail their ability to compute the composition $y = g(f(x))$.
Then, using logit lens on their residual stream activations, we identify two
processing mechanisms, one which solves tasks $\textit{compositionally}$,
computing $f(x)$ along the way to computing $g(f(x))$, and one which solves
them $\textit{directly}$, without any detectable signature of the intermediate
variable $f(x)$. Finally, we find that which mechanism is employed appears to
be related to the embedding space geometry, with the idiomatic mechanism being
dominant in cases where there exists a linear mapping from $x$ to $g(f(x))$ in
the embedding spaces. We fully release our data and code at:
https://github.com/apoorvkh/composing-functions .

</details>


### [135] [Format Inertia: A Failure Mechanism of LLMs in Medical Pre-Consultation](https://arxiv.org/abs/2510.01688)
*Seungseop Lim,Gibaeg Kim,Wooseok Han,Jean Seo,Hyunkyung Lee,Jaehyo Yoo,Eunho Yang*

Main category: cs.CL

TL;DR: LLMs在医疗问诊中存在“格式惰性”问题，通过重塑训练数据分布可缓解此问题。


<details>
  <summary>Details</summary>
Motivation: 在医疗问诊等任务中，LLM的SFT（Supervised Fine-Tuning）数据集常存在对话轮次分布不均的问题，导致模型在长对话中生成重复、格式正确但诊断信息缺乏的问句（格式惰性）。

Method: 通过重塑训练数据的轮次分布来缓解“格式惰性”问题。

Result: 该方法有效缓解了医疗问诊中的“格式惰性”现象。

Conclusion: 所提出的数据为中心的方法能够有效缓解LLM在医疗问诊应用中的“格式惰性”问题。

Abstract: Recent advances in Large Language Models (LLMs) have brought significant
improvements to various service domains, including chatbots and medical
pre-consultation applications. In the healthcare domain, the most common
approach for adapting LLMs to multi-turn dialogue generation is Supervised
Fine-Tuning (SFT). However, datasets for SFT in tasks like medical
pre-consultation typically exhibit a skewed turn-count distribution. Training
on such data induces a novel failure mechanism we term **Format Inertia**,
where models tend to generate repetitive, format-correct, but diagnostically
uninformative questions in long medical dialogues. To mitigate this observed
failure mechanism, we adopt a simple, data-centric method that rebalances the
turn-count distribution of the training dataset. Experimental results show that
our approach substantially alleviates Format Inertia in medical
pre-consultation.

</details>


### [136] [What MLLMs Learn about When they Learn about Multimodal Reasoning: Perception, Reasoning, or their Integration?](https://arxiv.org/abs/2510.01719)
*Jiwan Chung,Neel Joshi,Pratyusha Sharma,Youngjae Yu,Vibhav Vineet*

Main category: cs.CL

TL;DR: MathLens是一个包含三个子技能（感知、推理、整合）的基准测试，用于评估多模态推理模型在奥赛几何问题上的表现，揭示了不同训练方法对各子技能的影响，并发现整合能力最弱。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态推理模型评估方法（如准确率）无法揭示模型在复杂问题中的具体能力和改进点，需要一个更细致的评估基准。

Method: 提出MathLens基准测试，将模型性能分解为感知、推理和整合三个子技能。提供多种注释（如图表、文本描述、受控问题、探针）来支持每个子技能的评估。分析了不同训练方法（RL、SFT）对各子技能和鲁棒性的影响。

Result: RL主要增强感知能力（尤其是在有文本监督的情况下），文本SFT通过反思性推理间接改善感知。推理能力的提升依赖于感知能力的提升。整合能力是最弱的。RL提高了模型在图表变化下的鲁棒性，而多模态SFT则通过过拟合降低了鲁棒性。

Conclusion: MathLens基准测试能够更精细地评估多模态推理模型，揭示了当前模型在整合能力上的不足，并为未来研究提供了方向，即需要关注提升模型的整合能力和鲁棒性。

Abstract: Multimodal reasoning models have recently shown promise on challenging
domains such as olympiad-level geometry, yet their evaluation remains dominated
by aggregate accuracy, a single score that obscures where and how models are
improving. We introduce MathLens, a benchmark designed to disentangle the
subskills of multimodal reasoning while preserving the complexity of
textbook-style geometry problems. The benchmark separates performance into
three components: Perception: extracting information from raw inputs,
Reasoning: operating on available information, and Integration: selecting
relevant perceptual evidence and applying it within reasoning. To support each
test, we provide annotations: visual diagrams, textual descriptions to evaluate
reasoning in isolation, controlled questions that require both modalities, and
probes for fine-grained perceptual skills, all derived from symbolic
specifications of the problems to ensure consistency and robustness. Our
analysis reveals that different training approaches have uneven effects: First,
reinforcement learning chiefly strengthens perception, especially when
supported by textual supervision, while textual SFT indirectly improves
perception through reflective reasoning. Second, reasoning improves only in
tandem with perception. Third, integration remains the weakest capacity, with
residual errors concentrated there once other skills advance. Finally,
robustness diverges: RL improves consistency under diagram variation, whereas
multimodal SFT reduces it through overfitting. We will release all data and
experimental logs.

</details>


### [137] [Machine-interpretable Engineering Design Standards for Valve Specification](https://arxiv.org/abs/2510.01736)
*Anders Gjerver,Rune Frostad,Vedrana Barisic,Melinda Hodkiewicz,Caitlin Woods,Mihaly Fekete,Arild Braathen Torjusen,Johan Wilhelm Kluwer*

Main category: cs.CL

TL;DR: 将工程设计标准转化为机器可读的本体，用于植物设计和设备选型过程中的质量保证。


<details>
  <summary>Details</summary>
Motivation: 尽管工业界期望实现数字化，但产品规范、产品类型数据表和设计标准仍以文档为中心。本研究旨在将工程设计标准中的信息转化为模块化、可重用、机器可解释的本体，并将其应用于质量保证。

Method: 利用本体建模模式，为国际管道、材料和阀门设计标准中的文本和表格信息创建模块化本体。这些本体采用W3C标准格式，并与顶层本体ISO DIS 23726-3（工业数据本体，IDO）对齐，以实现可交换性和互操作性。在阀门选型过程中，将阀门实例化为语义资产模型中的个体，并创建“功能位置标签”作为阀门数据表（VDS）的实例。利用语义推理和可执行的设计规则，自动验证VDS是否符合相关行业标准，并判断产品类型是否满足阀门规格要求。

Result: 开发了基于国际材料和管道标准及行业规范的模块化本体，并通过阀门选型过程进行了测试。该方法能够自动验证阀门规格的合规性，并判断产品类型是否满足要求。

Conclusion: 创建基于IDO的共享、可重用本体，能够将语义推理应用于设备选型过程，展示了该方法在标准机构向数字化智能标准转型方面的潜力。

Abstract: Engineering design processes use technical specifications and must comply
with standards. Product specifications, product type data sheets, and design
standards are still mainly document-centric despite the ambition to digitalize
industrial work. In this paper, we demonstrate how to transform information
held in engineering design standards into modular, reusable,
machine-interpretable ontologies and use the ontologies in quality assurance of
the plant design and equipment selection process. We use modelling patterns to
create modular ontologies for knowledge captured in the text and in frequently
referenced tables in International Standards for piping, material and valve
design. These modules are exchangeable, as stored in a W3C compliant format,
and interoperable as they are aligned with the top-level ontology ISO DIS
23726-3: Industrial Data Ontology (IDO).
  We test these ontologies, created based on international material and piping
standards and industry norms, on a valve selection process. Valves are
instantiated in semantic asset models as individuals along with a semantic
representation of the environmental condition at their location on the asset.
We create "functional location tags" as OWL individuals that become instances
of OWL class Valve Data Sheet (VDS) specified valves. Similarly we create
instances of manufacturer product type. Our approach enables automated
validation that a specific VDS is compliant with relevant industry standards.
Using semantic reasoning and executable design rules, we also determine whether
the product type meets the valve specification. Creation of shared, reusable
IDO-based modular ontologies for design standards enables semantic reasoning to
be applied to equipment selection processes and demonstrates the potential of
this approach for Standards Bodies wanting to transition to digitized Smart
Standards.

</details>


### [138] [Can LLMs Refuse Questions They Do Not Know? Measuring Knowledge-Aware Refusal in Factual Tasks](https://arxiv.org/abs/2510.01782)
*Wenbo Pan,Jie Xu,Qiguang Chen,Junhao Dong,Libo Qin,Xinfeng Li,Haining Yu,Xiaohua Jia*

Main category: cs.CL

TL;DR: LLMs需要具备在知识范围外拒绝回答的能力（知识感知拒绝），以确保事实可靠性。现有指标无法准确衡量此能力。本研究提出“拒绝指数”（RI），一种衡量LLM准确拒绝未知问题的指标，定义为拒绝概率与错误概率之间的Spearman秩相关系数。RI通过轻量级两阶段评估方法估算。实验表明，RI能准确量化LLM在事实任务中的知识感知拒绝能力，且不随拒绝率变化而变化，模型排名稳定。RI揭示了LLM在事实任务中可能存在的拒绝行为不可靠和脆弱的问题，强调需要RI来补充传统准确性指标。 


<details>
  <summary>Details</summary>
Motivation: 现有指标无法准确衡量LLM的知识感知拒绝能力，需要一个更可靠的指标来评估LLM的事实可靠性。

Method: 提出“拒绝指数”（RI），定义为拒绝概率与错误概率之间的Spearman秩相关系数。设计了一个轻量级的两阶段评估方法来估算RI。

Result: RI能够准确量化LLM的知识感知拒绝能力，并且在不同拒绝率下表现稳定，模型排名一致。RI揭示了LLM在事实任务中拒绝行为的不可靠性和脆弱性。

Conclusion: LLM的事实可靠性评估需要引入“拒绝指数”（RI），以补充传统的准确性指标，全面评估LLM在知识范围外拒绝回答的能力。

Abstract: Large Language Models (LLMs) should refuse to answer questions beyond their
knowledge. This capability, which we term knowledge-aware refusal, is crucial
for factual reliability. However, existing metrics fail to faithfully measure
this ability. On the one hand, simple refusal-based metrics are biased by
refusal rates and yield inconsistent scores when models exhibit different
refusal tendencies. On the other hand, existing calibration metrics are
proxy-based, capturing the performance of auxiliary calibration processes
rather than the model's actual refusal behavior. In this work, we propose the
Refusal Index (RI), a principled metric that measures how accurately LLMs
refuse questions they do not know. We define RI as Spearman's rank correlation
between refusal probability and error probability. To make RI practically
measurable, we design a lightweight two-pass evaluation method that efficiently
estimates RI from observed refusal rates across two standard evaluation runs.
Extensive experiments across 16 models and 5 datasets demonstrate that RI
accurately quantifies a model's intrinsic knowledge-aware refusal capability in
factual tasks. Notably, RI remains stable across different refusal rates and
provides consistent model rankings independent of a model's overall accuracy
and refusal rates. More importantly, RI provides insight into an important but
previously overlooked aspect of LLM factuality: while LLMs achieve high
accuracy on factual tasks, their refusal behavior can be unreliable and
fragile. This finding highlights the need to complement traditional accuracy
metrics with the Refusal Index for comprehensive factuality evaluation.

</details>


### [139] [Comparison of Unsupervised Metrics for Evaluating Judicial Decision Extraction](https://arxiv.org/abs/2510.01792)
*Ivan Leonidovich Litvak,Anton Kostin,Fedor Lashkin,Tatiana Maksiyan,Sergey Lagutin*

Main category: cs.CL

TL;DR: 本研究评估了16种无监督指标，以评估从司法判决中提取七个语义块的质量，并与专家评分进行了比较。结果表明，词频凝聚力和覆盖率/块完整性指标与专家评分最吻合，而法律术语密度则显示出强烈的负相关性。LLM评估得分的对齐性适中，但其在法律文本方面的表现有限。研究结论是，无监督指标可以实现可扩展的筛选，但不能完全取代人类判断。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能在法律自然语言处理领域的快速发展，需要有可扩展的方法来评估从司法判决中提取文本的质量。

Method: 评估了16种无监督指标（包括新提出的指标），以评估从1000份匿名俄罗斯司法判决中提取七个语义块的质量，并使用7168份专家评分（1-5分制）进行验证。这些指标涵盖了基于文档、语义、结构、伪真实情况和特定法律类别，并且不需要预先标注的真实情况。通过自举相关性、Lin一致性相关系数（CCC）和平均绝对误差（MAE）来评估指标的表现。

Result: 词频凝聚力（Pearson r = 0.540, Lin CCC = 0.512, MAE = 0.127）和覆盖率/块完整性（Pearson r = 0.513, Lin CCC = 0.443, MAE = 0.139）与专家评分最吻合。法律术语密度（Pearson r = -0.479, Lin CCC = -0.079, MAE = 0.394）显示出强烈的负相关性。LLM评估得分（平均值=0.849, Pearson r = 0.382, Lin CCC = 0.325, MAE = 0.197）的对齐性适中，但表现有限。

Conclusion: 无监督指标，包括基于LLM的方法，可以实现可扩展的筛选，但由于中等的皮尔逊相关性和较低的CCC值，在法律等高风险领域无法完全取代人工判断。这项工作通过提供无需标注的评估工具，推动了法律NLP领域的发展，并对司法分析和合乎道德的AI部署具有启示作用。

Abstract: The rapid advancement of artificial intelligence in legal natural language
processing demands scalable methods for evaluating text extraction from
judicial decisions. This study evaluates 16 unsupervised metrics, including
novel formulations, to assess the quality of extracting seven semantic blocks
from 1,000 anonymized Russian judicial decisions, validated against 7,168
expert reviews on a 1--5 Likert scale. These metrics, spanning document-based,
semantic, structural, pseudo-ground truth, and legal-specific categories,
operate without pre-annotated ground truth. Bootstrapped correlations, Lin's
concordance correlation coefficient (CCC), and mean absolute error (MAE) reveal
that Term Frequency Coherence (Pearson $r = 0.540$, Lin CCC = 0.512, MAE =
0.127) and Coverage Ratio/Block Completeness (Pearson $r = 0.513$, Lin CCC =
0.443, MAE = 0.139) best align with expert ratings, while Legal Term Density
(Pearson $r = -0.479$, Lin CCC = -0.079, MAE = 0.394) show strong negative
correlations. The LLM Evaluation Score (mean = 0.849, Pearson $r = 0.382$, Lin
CCC = 0.325, MAE = 0.197) showed moderate alignment, but its performance, using
gpt-4.1-mini via g4f, suggests limited specialization for legal textse. These
findings highlight that unsupervised metrics, including LLM-based approaches,
enable scalable screening but, with moderate correlations and low CCC values,
cannot fully replace human judgment in high-stakes legal contexts. This work
advances legal NLP by providing annotation-free evaluation tools, with
implications for judicial analytics and ethical AI deployment.

</details>


### [140] [Detecting LLM-Generated Spam Reviews by Integrating Language Model Embeddings and Graph Neural Network](https://arxiv.org/abs/2510.01801)
*Xin Liu,Rongwu Xu,Xinyi Jia,Jason Liao,Jiao Sun,Ling Huang,Wei Xu*

Main category: cs.CL

TL;DR: LLM生成的垃圾评论对在线平台构成威胁，提出了一种名为FraudSquad的混合检测模型，该模型在合成和真实垃圾评论数据集上均表现出色，并具有模型尺寸适中、所需训练数据量少的优点。


<details>
  <summary>Details</summary>
Motivation: LLM能够生成高度逼真且具有说服力的垃圾评论，对现有检测系统构成挑战，并威胁到在线平台的信誉。

Method: 创建包含三种不同LLM生成的评论的数据集，并提出了一种名为FraudSquad的混合检测模型，该模型结合了预训练语言模型的文本嵌入和用于节点分类的门控图Transformer，以捕捉语义和行为信号。

Result: FraudSquad在三个LLM生成的垃圾评论数据集上的表现优于最先进的基线（精确率最高提升44.22%，召回率最高提升43.01%），并在两个人工编写的垃圾评论数据集上也取得了良好结果。此外，FraudSquad的模型尺寸适中，所需的标记训练数据量少。

Conclusion: LLM的出现使得垃圾评论的检测变得更加困难，需要开发能够适应LLM时代的新型检测方法。FraudSquad提供了一个实用的解决方案，该模型能够有效地检测LLM生成的垃圾评论，并且易于部署到实际应用中。

Abstract: The rise of large language models (LLMs) has enabled the generation of highly
persuasive spam reviews that closely mimic human writing. These reviews pose
significant challenges for existing detection systems and threaten the
credibility of online platforms. In this work, we first create three realistic
LLM-generated spam review datasets using three distinct LLMs, each guided by
product metadata and genuine reference reviews. Evaluations by GPT-4.1 confirm
the high persuasion and deceptive potential of these reviews. To address this
threat, we propose FraudSquad, a hybrid detection model that integrates text
embeddings from a pre-trained language model with a gated graph transformer for
spam node classification. FraudSquad captures both semantic and behavioral
signals without relying on manual feature engineering or massive training
resources. Experiments show that FraudSquad outperforms state-of-the-art
baselines by up to 44.22% in precision and 43.01% in recall on three
LLM-generated datasets, while also achieving promising results on two
human-written spam datasets. Furthermore, FraudSquad maintains a modest model
size and requires minimal labeled training data, making it a practical solution
for real-world applications. Our contributions include new synthetic datasets,
a practical detection framework, and empirical evidence highlighting the
urgency of adapting spam detection to the LLM era. Our code and datasets are
available at: https://anonymous.4open.science/r/FraudSquad-5389/.

</details>


### [141] [Syntactic Blind Spots: How Misalignment Leads to LLMs Mathematical Errors](https://arxiv.org/abs/2510.01831)
*Dane Williamson,Yangfeng Ji,Matthew Dwyer*

Main category: cs.CL

TL;DR: LLMs在数学问题解决方面表现出色，但在遇到语法结构与训练数据不同的问题时，会因为“句法盲点”而失败，即使问题本身在语义上很简单。通过将错误的问题改写成更熟悉的语法形式，可以提高模型的正确率。研究还发现，句法复杂度（基于依赖局部性理论）与模型错误率相关。这表明许多推理错误源于句法结构问题，而非概念理解困难，并且优化句法结构有助于解决这些问题。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在数学问题解决中的能力，并识别和解释其在面对与训练数据语法结构不同时出现的系统性失败模式——句法盲点。

Method: 1. 识别出LLMs在解决数学问题时，即使语义简单，也可能因语法结构不熟悉而失败的现象（句法盲点）。 2. 通过将这些错误的问题改写成采用正确回答的例子的句法模板，来测试模型是否能正确回答。 3. 使用基于依赖局部性理论（DLT）的度量来量化句法复杂度，并分析其与模型错误率的关系。

Result: 将问题改写成更熟悉的句法形式，可以使模型在语义上保持不变的情况下，从错误回答转为正确回答。句法复杂度得分（DLT）越高的题目，模型出错的概率越大，这一现象在多个数据集上均有体现。

Conclusion: LLMs的许多推理错误并非源于概念理解上的困难，而是由于模型将熟悉的推理策略错误地应用到了句法结构陌生的新问题上。句法敏感的干预措施可以揭示并减轻这些归纳性失败，表明优化句法结构是提高模型推理能力的关键。

Abstract: Large Language Models (LLMs) demonstrate strong mathematical problem-solving
abilities but frequently fail on problems that deviate syntactically from their
training distribution. We identify a systematic failure mode, syntactic blind
spots, in which models misapply familiar reasoning strategies to problems that
are semantically straightforward but phrased in unfamiliar ways. These errors
are not due to gaps in mathematical competence, but rather reflect a brittle
coupling between surface form and internal representation. To test this, we
rephrase incorrectly answered questions using syntactic templates drawn from
correct examples. These rephrasings, which preserve semantics while reducing
structural complexity, often lead to correct answers. We quantify syntactic
complexity using a metric based on Dependency Locality Theory (DLT), and show
that higher DLT scores are associated with increased failure rates across
multiple datasets. Our findings suggest that many reasoning errors stem from
structural misalignment rather than conceptual difficulty, and that
syntax-aware interventions can reveal and mitigate these inductive failures.

</details>


### [142] [SCRIBES: Web-Scale Script-Based Semi-Structured Data Extraction with Reinforcement Learning](https://arxiv.org/abs/2510.01832)
*Shicheng Liu,Kai Sun,Lisheng Fu,Xilun Chen,Xinyuan Zhang,Zhaojiang Lin,Rulin Shao,Yue Liu,Anuj Kumar,Wen-tau Yih,Xin Luna Dong*

Main category: cs.CL

TL;DR: SCRIBES是一个基于强化学习的框架，通过利用同一网站内网页间的布局相似性作为奖励信号，生成可复用的提取脚本，以解决网页半结构化内容提取的挑战，实现了可扩展且资源高效的网页信息提取。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理网页半结构化内容时存在泛化性不足或资源消耗大的问题，因为它们通常需要对每个页面进行单独的语言模型推理。

Method: SCRIBES提出了一种新的强化学习框架，通过生成可复用的提取脚本来处理结构相似的网页组，并利用网页间布局相似性作为奖励信号进行训练，同时结合了从CommonCrawl数据生成的合成注释进行迭代训练。

Result: 实验证明，SCRIBES在脚本质量上超越了现有方法13%以上，并使GPT-4o在下游问答任务中的准确率提高了4%以上。

Conclusion: SCRIBES通过生成可复用的提取脚本，实现了可扩展且资源高效的网页信息提取，显著优于现有方法。

Abstract: Semi-structured content in HTML tables, lists, and infoboxes accounts for a
substantial share of factual data on the web, yet the formatting complicates
usage, and reliably extracting structured information from them remains
challenging. Existing methods either lack generalization or are
resource-intensive due to per-page LLM inference. In this paper, we introduce
SCRIBES (SCRIpt-Based Semi-Structured Content Extraction at Web-Scale), a novel
reinforcement learning framework that leverages layout similarity across
webpages within the same site as a reward signal. Instead of processing each
page individually, SCRIBES generates reusable extraction scripts that can be
applied to groups of structurally similar webpages. Our approach further
improves by iteratively training on synthetic annotations from in-the-wild
CommonCrawl data. Experiments show that our approach outperforms strong
baselines by over 13% in script quality and boosts downstream question
answering accuracy by more than 4% for GPT-4o, enabling scalable and
resource-efficient web information extraction.

</details>


### [143] [Model Merging to Maintain Language-Only Performance in Developmentally Plausible Multimodal Models](https://arxiv.org/abs/2510.01845)
*Ece Takmaz,Lisa Bylinina,Jakub Dotlacil*

Main category: cs.CL

TL;DR: 本论文提出了一种在低资源环境下，使用符合儿童认知发展规律的数据集来训练多模态和仅语言模型的方法，以解决当前大型模型数据量远超儿童学习语料的问题。实验结果表明，该方法在多模态任务上优于现有BabyLM基线，并通过模型融合技术改善了多模态模型在纯语言任务上的表现，同时保持了多模态性能。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的视觉-语言模型参数量大、训练数据量庞大，远超儿童学习语言时接触到的数据量，这篇论文旨在解决这种差异。

Method: 本研究在低资源环境下，使用符合儿童认知发展规律的数据集，开发了仅语言模型和多模态模型，并尝试通过模型融合（将多模态模型与仅语言模型的参数进行加权线性插值）来解决多模态模型在纯语言任务上表现不佳的问题。

Result: 实验结果证实了多模态模型在语法相关的纯语言基准测试上表现不佳的发现，并且模型融合技术可以在一定程度上缓解这个问题，同时保持了多模态性能。

Conclusion: 本研究提出的模型融合方法在解决多模态模型纯语言任务表现不佳的问题上取得了一定成效，并保持了其多模态能力，为低资源、符合儿童认知发展规律的语言模型研究提供了新的方向。

Abstract: State-of-the-art vision-and-language models consist of many parameters and
learn from enormous datasets, surpassing the amounts of linguistic data that
children are exposed to as they acquire a language. This paper presents our
approach to the multimodal track of the BabyLM challenge addressing this
discrepancy. We develop language-only and multimodal models in low-resource
settings using developmentally plausible datasets, with our multimodal models
outperforming previous BabyLM baselines. One finding in the multimodal language
model literature is that these models tend to underperform in
\textit{language-only} tasks. Therefore, we focus on maintaining language-only
abilities in multimodal models. To this end, we experiment with \textit{model
merging}, where we fuse the parameters of multimodal models with those of
language-only models using weighted linear interpolation. Our results
corroborate the findings that multimodal models underperform in language-only
benchmarks that focus on grammar, and model merging with text-only models can
help alleviate this problem to some extent, while maintaining multimodal
performance.

</details>


### [144] [REPAIR: Robust Editing via Progressive Adaptive Intervention and Reintegration](https://arxiv.org/abs/2510.01879)
*Yisu Wang,Ming Wang,Haoyuan Song,Wenjie Huang,Chaozheng Wang,Yi Xie,Xuming Ran*

Main category: cs.CL

TL;DR: REPAIR是一个用于大型语言模型的终身编辑框架，可以精确、低成本地更新模型，同时保留非目标知识，并解决传统方法中的不稳定性和冲突问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）的训练后更新受到获取新知识或纠正错误成本高昂以及频繁出现的意外副作用的限制。

Method: REPAIR框架通过闭环反馈机制、动态内存管理、频繁知识融合和强局部性约束来解决大规模顺序编辑的不稳定性和冲突问题。

Result: 实验表明，REPAIR在多个模型家族中的编辑准确率提高了10%-30%，并显著减少了知识遗忘。

Conclusion: REPAIR为开发可靠、可扩展且持续进化的LLM提供了一个强大的框架。

Abstract: Post-training for large language models (LLMs) is constrained by the high
cost of acquiring new knowledge or correcting errors and by the unintended side
effects that frequently arise from retraining. To address these issues, we
introduce REPAIR (Robust Editing via Progressive Adaptive Intervention and
Reintegration), a lifelong editing framework designed to support precise and
low-cost model updates while preserving non-target knowledge. REPAIR mitigates
the instability and conflicts of large-scale sequential edits through a
closed-loop feedback mechanism coupled with dynamic memory management.
Furthermore, by incorporating frequent knowledge fusion and enforcing strong
locality guards, REPAIR effectively addresses the shortcomings of traditional
distribution-agnostic approaches that often overlook unintended ripple effects.
Our experiments demonstrate that REPAIR boosts editing accuracy by 10%-30%
across multiple model families and significantly reduces knowledge forgetting.
This work introduces a robust framework for developing reliable, scalable, and
continually evolving LLMs.

</details>


### [145] [Enhancing Large Language Model Reasoning with Reward Models: An Analytical Survey](https://arxiv.org/abs/2510.01925)
*Qiyuan Liu,Hao Xu,Xuhong Chen,Wei Chen,Yee Whye Teh,Ning Miao*

Main category: cs.CL

TL;DR: 本论文系统性地介绍了奖励模型（RM）在增强大型语言模型（LLM）推理能力方面的作用，重点关注其在推理和微调中的应用。


<details>
  <summary>Details</summary>
Motivation: 奖励模型（RM）在增强大型语言模型（LLM）的推理能力方面发挥着关键作用，例如在强化学习（RL）中提供微调信号以及在推理时从多个候选中选择最佳答案。

Method: 对RM的基本概念（包括架构、训练方法和评估技术）进行了回顾，并探讨了其在引导生成、选择最优输出、促进数据合成和迭代自我改进以及在RL微调中提供训练信号等方面的关键应用。最后，基于现有研究和实证发现，讨论了RM的选择、泛化、评估和增强等方面的开放性问题。

Result: 对RM的架构、训练方法和评估技术进行了回顾，并重点介绍了其在引导生成、选择最优输出、数据合成、迭代自我改进以及RL微调中的应用。

Conclusion: 本论文旨在为有效部署和改进LLM推理中的RM提供可操作的见解，并讨论了RM选择、泛化、评估和增强方面的开放性问题。

Abstract: Reward models (RMs) play a critical role in enhancing the reasoning
performance of LLMs. For example, they can provide training signals to finetune
LLMs during reinforcement learning (RL) and help select the best answer from
multiple candidates during inference. In this paper, we provide a systematic
introduction to RMs, along with a comprehensive survey of their applications in
LLM reasoning. We first review fundamental concepts of RMs, including their
architectures, training methodologies, and evaluation techniques. Then, we
explore their key applications: (1) guiding generation and selecting optimal
outputs during LLM inference, (2) facilitating data synthesis and iterative
self-improvement for LLMs, and (3) providing training signals in RL-based
finetuning. Finally, we address critical open questions regarding the
selection, generalization, evaluation, and enhancement of RMs, based on
existing research and our own empirical findings. Our analysis aims to provide
actionable insights for the effective deployment and advancement of RMs for LLM
reasoning.

</details>


### [146] [Inverse Language Modeling towards Robust and Grounded LLMs](https://arxiv.org/abs/2510.01929)
*Davide Gabrielli,Simone Sestito,Iacopo Masi*

Main category: cs.CL

TL;DR: 提出了一种名为逆向语言模型（ILM）的框架，用于增强大型语言模型（LLM）的鲁棒性和安全性。


<details>
  <summary>Details</summary>
Motivation: 现有防御大型语言模型（LLM）的机制不完善，需要提高其鲁棒性并实现本地化。

Method: 提出逆向语言模型（ILM）框架，该框架能同时提高LLM对输入扰动的鲁棒性，并通过逆向模型输出来识别潜在的有毒或不安全输入触发器，实现本地化。

Result: ILM将LLM从静态生成器转变为可分析、可鲁棒的系统，可用于红队测试，并为下一代LLM奠定基础。

Conclusion: ILM为构建更可控、更可信赖的下一代LLM铺平了道路。

Abstract: The current landscape of defensive mechanisms for LLMs is fragmented and
underdeveloped, unlike prior work on classifiers. To further promote
adversarial robustness in LLMs, we propose Inverse Language Modeling (ILM), a
unified framework that simultaneously 1) improves the robustness of LLMs to
input perturbations, and, at the same time, 2) enables native grounding by
inverting model outputs to identify potentially toxic or unsafe input triggers.
ILM transforms LLMs from static generators into analyzable and robust systems,
potentially helping RED teaming. ILM can lay the foundation for next-generation
LLMs that are not only robust and grounded but also fundamentally more
controllable and trustworthy. The code is publicly available at
github.com/davegabe/pag-llm.

</details>


### [147] [Veri-R1: Toward Precise and Faithful Claim Verification via Online Reinforcement Learning](https://arxiv.org/abs/2510.01932)
*Qi He,Cheng Qian,Xiusi Chen,Bingxiang He,Yi R.,Fung,Heng Ji*

Main category: cs.CL

TL;DR: Veri-R1是一个在线强化学习框架，通过让LLM与搜索引擎互动并接收奖励信号来改进其规划、检索和推理能力，从而实现更精确和忠实的声明验证。


<details>
  <summary>Details</summary>
Motivation: 现有方法在在线声明验证方面缺乏统一的训练范式来提升LLM的规划、检索和推理能力，而Veri-R1旨在解决这个问题。

Method: Veri-R1框架利用在线强化学习，使LLM能够与搜索引擎进行交互，并通过奖励信号来塑造其行为。

Result: Veri-R1在联合准确性方面提高了30%，并将证据分数提高了一倍，通常优于更大规模的模型。消融研究进一步揭示了奖励组成部分的影响以及输出对数与标签准确性之间的联系。

Conclusion: 在线强化学习对于精确和忠实的声明验证非常有效，并为未来的研究奠定了基础。

Abstract: Claim verification with large language models (LLMs) has recently attracted
considerable attention, owing to their superior reasoning capabilities and
transparent verification pathways compared to traditional answer-only
judgments. Online claim verification requires iterative evidence retrieval and
reasoning, yet existing approaches mainly rely on prompt engineering or
predesigned reasoning workflows without offering a unified training paradigm to
improve necessary skills. Therefore, we introduce Veri-R1, an online
reinforcement learning (RL) framework that enables an LLM to interact with a
search engine and to receive reward signals that explicitly shape its planning,
retrieval, and reasoning behaviors. The dynamic interaction between models and
retrieval systems more accurately reflects real-world verification scenarios
and fosters comprehensive verification skills. Empirical results show that
Veri-R1 improves joint accuracy by up to 30% and doubles evidence score, often
surpassing larger-scale counterparts. Ablation studies further reveal the
impact of reward components and the link between output logits and label
accuracy. Our results highlight the effectiveness of online RL for precise and
faithful claim verification and provide a foundation for future research. We
release our code to support community progress in LLM empowered claim
verification.

</details>


### [148] [Taking a SEAT: Predicting Value Interpretations from Sentiment, Emotion, Argument, and Topic Annotations](https://arxiv.org/abs/2510.01976)
*Adina Nicola Dobrinoiu,Ana Cristiana Marcu,Amir Homayounirad,Luciano Cavalcante Siebert,Enrico Liscio*

Main category: cs.CL

TL;DR: 语言模型可以通过SEAT维度（情感、情绪、论点、主题）的个体注释来预测个体价值观。


<details>
  <summary>Details</summary>
Motivation: 为了开发能够符合不同人类视角且避免多数群体偏见的AI系统，需要认识到个体对价值观的解释是主观的，并受社会文化背景和生活经验的影响。本研究旨在探索语言模型是否能通过利用多维度主观注释作为解释视角来预测个体价值观。

Method: 通过在一系列零样本和少样本设置中进行实验，评估提供个体如何注释情感、情绪、论点和主题（SEAT维度）的示例，是否能帮助语言模型预测其价值观。

Result: 实验表明，同时提供所有SEAT维度比单独提供某个维度或不提供任何个体信息（基线）具有更优越的性能。个体注释者之间的差异也凸显了考虑个体主观注释的重要性。

Conclusion: 本研究首次尝试超越人口统计学因素，探索注释行为对价值观预测的影响，为未来大规模验证奠定了基础。

Abstract: Our interpretation of value concepts is shaped by our sociocultural
background and lived experiences, and is thus subjective. Recognizing
individual value interpretations is important for developing AI systems that
can align with diverse human perspectives and avoid bias toward majority
viewpoints. To this end, we investigate whether a language model can predict
individual value interpretations by leveraging multi-dimensional subjective
annotations as a proxy for their interpretive lens. That is, we evaluate
whether providing examples of how an individual annotates Sentiment, Emotion,
Argument, and Topics (SEAT dimensions) helps a language model in predicting
their value interpretations. Our experiment across different zero- and few-shot
settings demonstrates that providing all SEAT dimensions simultaneously yields
superior performance compared to individual dimensions and a baseline where no
information about the individual is provided. Furthermore, individual
variations across annotators highlight the importance of accounting for the
incorporation of individual subjective annotators. To the best of our
knowledge, this controlled setting, although small in size, is the first
attempt to go beyond demographics and investigate the impact of annotation
behavior on value prediction, providing a solid foundation for future
large-scale validation.

</details>


### [149] [Exploring Database Normalization Effects on SQL Generation](https://arxiv.org/abs/2510.01989)
*Ryosuke Kohita*

Main category: cs.CL

TL;DR: 非规范化模式在简单检索查询上表现更好，而规范化模式（2NF/3NF）在聚合查询上表现更好，这表明最佳模式设计取决于查询类型。


<details>
  <summary>Details</summary>
Motivation: 评估模式设计，特别是规范化，对自然语言到 SQL（NL2SQL）系统的影响，因为现有研究大多在固定模式上进行评估，忽略了设计对性能的影响。

Method: 在具有不同规范化级别的合成和真实世界数据集上评估八个领先的大型语言模型，构建具有不同规范化级别（1NF-3NF）的受控合成数据集和具有实际模式的真实学术论文数据集。

Result: 在零样本设置中，非规范化模式在简单检索查询上提供了高准确性，即使是使用经济高效的模型。然而，规范化模式（2NF/3NF）会引入如基础表选择和连接类型预测错误等挑战，但可以通过提供少样本示例来大大缓解这些问题。对于聚合查询，规范化模式由于其在处理非规范化模式中会导致错误的数据重复和 NULL 值问题方面具有鲁棒性，因此表现更好。

Conclusion: NL2SQL 应用的最佳模式设计取决于要支持的查询类型。研究强调了在开发 NL2SQL 界面时考虑模式设计的重要性，并为现实场景建议了自适应模式选择。

Abstract: Schema design, particularly normalization, is a critical yet often overlooked
factor in natural language to SQL (NL2SQL) systems. Most prior research
evaluates models on fixed schemas, overlooking the influence of design on
performance. We present the first systematic study of schema normalization's
impact, evaluating eight leading large language models on synthetic and
real-world datasets with varied normalization levels. We construct controlled
synthetic datasets with formal normalization (1NF-3NF) and real academic paper
datasets with practical schemes. Our results show that denormalized schemas
offer high accuracy on simple retrieval queries, even with cost-effective
models in zero-shot settings. In contrast, normalized schemas (2NF/3NF)
introduce challenges such as errors in base table selection and join type
prediction; however, these issues are substantially mitigated by providing
few-shot examples. For aggregation queries, normalized schemas yielded better
performance, mainly due to their robustness against the data duplication and
NULL value issues that cause errors in denormalized schemas. These findings
suggest that the optimal schema design for NL2SQL applications depends on the
types of queries to be supported. Our study demonstrates the importance of
considering schema design when developing NL2SQL interfaces and integrating
adaptive schema selection for real-world scenarios.

</details>


### [150] [LLM-Based Multi-Task Bangla Hate Speech Detection: Type, Severity, and Target](https://arxiv.org/abs/2510.01995)
*Md Arid Hasan,Firoj Alam,Md Fahad Hossain,Usman Naseem,Syed Ishtiaque Ahmed*

Main category: cs.CL

TL;DR: 开发了首个多任务孟加拉语仇恨言论数据集BanglaMultiHate，并对多种模型进行了全面比较，发现在低资源环境下，经过LoRA微调的LLM模型虽然有竞争力，但基于语言和文化预训练的模型仍然至关重要。


<details>
  <summary>Details</summary>
Motivation: 在线社交媒体平台虽然是重要的沟通和信息获取渠道，但也助长了仇恨言论、冒犯性语言和网络欺凌的传播，特别是在孟加拉语等低资源语言环境中，相关的审核工具非常有限。因此，需要开发可靠的检测系统来解决这些问题，并覆盖多方面信号（类型、严重性、目标）。

Method: 构建了首个多任务孟加拉语仇恨言论数据集BanglaMultiHate。在此基础上，对经典基线模型、单语预训练模型以及采用零样本提示（zero-shot prompting）和LoRA微调的LLM模型进行了全面的、受控的比较实验。

Result: 实验表明，经过LoRA微调的LLM模型在孟加拉语仇恨言论检测方面虽然可以与BanglaBERT模型相媲美，但基于语言和文化进行预训练的模型在鲁棒性方面仍然表现更优。LLM模型在低资源环境下的适应性得到了评估。

Conclusion:  BanglMultiHate数据集和相关实验结果为开发符合本地文化和语言的低资源环境下的内容审核工具奠定了更坚实的基础。研究将公开数据集和所有相关脚本以确保可复现性。

Abstract: Online social media platforms are central to everyday communication and
information seeking. While these platforms serve positive purposes, they also
provide fertile ground for the spread of hate speech, offensive language, and
bullying content targeting individuals, organizations, and communities. Such
content undermines safety, participation, and equity online. Reliable detection
systems are therefore needed, especially for low-resource languages where
moderation tools are limited. In Bangla, prior work has contributed resources
and models, but most are single-task (e.g., binary hate/offense) with limited
coverage of multi-facet signals (type, severity, target). We address these gaps
by introducing the first multi-task Bangla hate-speech dataset,
BanglaMultiHate, one of the largest manually annotated corpus to date. Building
on this resource, we conduct a comprehensive, controlled comparison spanning
classical baselines, monolingual pretrained models, and LLMs under zero-shot
prompting and LoRA fine-tuning. Our experiments assess LLM adaptability in a
low-resource setting and reveal a consistent trend: although LoRA-tuned LLMs
are competitive with BanglaBERT, culturally and linguistically grounded
pretraining remains critical for robust performance. Together, our dataset and
findings establish a stronger benchmark for developing culturally aligned
moderation tools in low-resource contexts. For reproducibility, we will release
the dataset and all related scripts.

</details>


### [151] [Style Over Story: A Process-Oriented Study of Authorial Creativity in Large Language Models](https://arxiv.org/abs/2510.02025)
*Donghoon Jung,Jiwoo Choi,Songeun Chae,Seohyon Jung*

Main category: cs.CL

TL;DR: LLMs在创意写作中更偏爱风格，而非角色、事件或背景，这可以通过分析其决策过程来揭示。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs的创意时，应关注其产出过程而非仅仅是结果质量，并将LLMs视为计算型作者，运用叙事学理论进行研究。

Method: 通过受控提问分配作者身份，并引入基于约束的决策制定作为作者创意的视角，分析模型在风格、角色、事件和背景等元素上的偏好，并探究模型做出选择的原因。

Result: LLMs在创作时始终优先考虑风格，其次是角色、事件和背景。不同模型展现出独特的偏好倾向。

Conclusion: 本研究提出了一种新颖的、系统化的方法来分析AI的作者创意，通过考察LLMs的创作过程，揭示其在创意偏好上的差异。

Abstract: Evaluations of large language models (LLMs)' creativity have focused
primarily on the quality of their outputs rather than the processes that shape
them. This study takes a process-oriented approach, drawing on narratology to
examine LLMs as computational authors. We introduce constraint-based
decision-making as a lens for authorial creativity. Using controlled prompting
to assign authorial personas, we analyze the creative preferences of the
models. Our findings show that LLMs consistently emphasize Style over other
elements, including Character, Event, and Setting. By also probing the
reasoning the models provide for their choices, we show that distinctive
profiles emerge across models and argue that our approach provides a novel
systematic tool for analyzing AI's authorial creativity.

</details>


### [152] [Stream RAG: Instant and Accurate Spoken Dialogue Systems with Streaming Tool Usage](https://arxiv.org/abs/2510.02044)
*Siddhant Arora,Haidar Khan,Kai Sun,Xin Luna Dong,Sajal Choudhary,Seungwhan Moon,Xinyuan Zhang,Adithya Sagar,Surya Teja Appini,Kaushik Patnaik,Sanat Sharma,Shinji Watanabe,Anuj Kumar,Ahmed Aly,Yue Liu,Florian Metze,Zhaojiang Lin*

Main category: cs.CL

TL;DR: 提出了一种名为Streaming RAG的新框架，用于解决端到端语音对话系统中的幻觉和延迟问题，通过在用户说话时并行预测工具查询来减少延迟，并提高了问答准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的端到端语音对话系统虽然响应更自然、延迟更低，但容易出现幻觉。传统的基于文本的系统通过工具集成解决此问题，但将其直接应用于语音系统会增加延迟。

Method: 提出Streaming RAG框架，该框架通过在用户说话的同时（甚至在用户说完之前）并行预测工具查询来减少延迟。开发了一个后训练流程，使模型能够在正在进行的语音中判断何时调用工具，并生成融合语音查询和检索文本结果的口头摘要。

Result: 在AudioCRAG基准测试中，该方法将问答准确性相对提高了200%（绝对值从11.1%提高到34.2%），并将工具使用延迟降低了20%。

Conclusion: Streaming RAG框架成功地解决了端到端语音对话系统中的幻觉和延迟问题，提高了准确性和响应速度，并且该方法具有模型无关性，可应用于文本输入，为实时AI助手铺平了道路。

Abstract: End-to-end speech-in speech-out dialogue systems are emerging as a powerful
alternative to traditional ASR-LLM-TTS pipelines, generating more natural,
expressive responses with significantly lower latency. However, these systems
remain prone to hallucinations due to limited factual grounding. While
text-based dialogue systems address this challenge by integrating tools such as
web search and knowledge graph APIs, we introduce the first approach to extend
tool use directly into speech-in speech-out systems. A key challenge is that
tool integration substantially increases response latency, disrupting
conversational flow. To mitigate this, we propose Streaming Retrieval-Augmented
Generation (Streaming RAG), a novel framework that reduces user-perceived
latency by predicting tool queries in parallel with user speech, even before
the user finishes speaking. Specifically, we develop a post-training pipeline
that teaches the model when to issue tool calls during ongoing speech and how
to generate spoken summaries that fuse audio queries with retrieved text
results, thereby improving both accuracy and responsiveness. To evaluate our
approach, we construct AudioCRAG, a benchmark created by converting queries
from the publicly available CRAG dataset into speech form. Experimental results
demonstrate that our streaming RAG approach increases QA accuracy by up to 200%
relative (from 11.1% to 34.2% absolute) and further enhances user experience by
reducing tool use latency by 20%. Importantly, our streaming RAG approach is
modality-agnostic and can be applied equally to typed input, paving the way for
more agentic, real-time AI assistants.

</details>


### [153] [Chain-of-Thought Reasoning in Streaming Full-Duplex End-to-End Spoken Dialogue Systems](https://arxiv.org/abs/2510.02066)
*Siddhant Arora,Jinchuan Tian,Hayato Futami,Jiatong Shi,Yosuke Kashiwagi,Emiru Tsunoo,Shinji Watanabe*

Main category: cs.CL

TL;DR: E2E对话系统使用VAD进行轮次切换，但VAD无法区分停顿和轮次完成。双工SDS模型通过持续预测输出来解决这个问题，但它们通常具有复杂的双通道架构，并且在语义推理方面落后于级联模型。为了克服这些挑战，我们提出了SCoT：一个用于双工SDS的流式思维链（CoT）框架，通过分块处理固定时长的用户输入和生成响应。通过帧级对齐，我们为每个块创建了中间目标对齐的用户对话和系统响应。实验表明，我们的方法比现有的双工方法产生更连贯、更具可解释性的响应，同时与逐轮系统相比，支持更低延迟和重叠的交互。


<details>
  <summary>Details</summary>
Motivation: 大多数端到端（E2E）语音对话系统（SDS）依赖于语音活动检测（VAD）来进行轮次切换，但VAD无法区分停顿和轮次完成。双工SDS模型通过持续预测输出（包括静默标记）来解决此问题，从而无需显式VAD。然而，它们通常具有复杂اً的双通道架构，并且在语义推理方面落后于级联模型。

Method: 提出SCoT：一个流式思维链（CoT）框架，用于双工SDS，通过分块处理固定时长的用户输入和生成响应。利用帧级对齐，为每个块创建中间目标对齐的用户对话和系统响应。

Result: 实验表明，SCoT框架产生比现有双工方法更连贯、更具可解释性的响应，同时与逐轮系统相比，支持更低延迟和重叠的交互。

Conclusion: SCoT框架通过分块处理和帧级对齐，解决了双工SDS的复杂架构和语义推理能力不足的问题，实现了低延迟和重叠交互，并提高了响应的连贯性和可解释性。

Abstract: Most end-to-end (E2E) spoken dialogue systems (SDS) rely on voice activity
detection (VAD) for turn-taking, but VAD fails to distinguish between pauses
and turn completions. Duplex SDS models address this by predicting output
continuously, including silence tokens, thus removing the need for explicit
VAD. However, they often have complex dual-channel architecture and lag behind
cascaded models in semantic reasoning. To overcome these challenges, we propose
SCoT: a Streaming Chain-of-Thought (CoT) framework for Duplex SDS, alternating
between processing fixed-duration user input and generating responses in a
blockwise manner. Using frame-level alignments, we create intermediate
targets-aligned user transcripts and system responses for each block.
Experiments show that our approach produces more coherent and interpretable
responses than existing duplex methods while supporting lower-latency and
overlapping interactions compared to turn-by-turn systems.

</details>


### [154] [The Disparate Impacts of Speculative Decoding](https://arxiv.org/abs/2510.02128)
*Jameson Sandler,Ahmet Üstün,Marco Romanelli,Sara Hooker,Ferdinando Fioretto*

Main category: cs.CL

TL;DR: 投机解码在不同任务上可能导致不公平的速度提升，本研究提出了一个量化和缓解这种差异的方法，平均可提升12%的公平性指标。


<details>
  <summary>Details</summary>
Motivation: 现有投机解码技术在减少大型语言模型推理时间方面被广泛应用，但其速度提升在不同任务上的分布不均，尤其在欠拟合或代表性不足的任务上效果较差。本研究旨在分析并解决这种“不公平”现象。

Method: 首先，通过推导分析来量化投机解码在不同任务上的速度提升差异（“不公平”）。其次，识别导致这种差异的因素。最后，基于这些见解，提出一种旨在减少速度提升差异的缓解策略，并在多个模型对上进行了验证。

Result: 投机解码的速度提升在不同任务上存在显著差异，在欠拟合和代表性不足的任务上表现不佳。提出的缓解策略在平均12%的公平性指标上有所改善。

Conclusion: 投机解码的速度提升并非在所有任务上都均匀分布。本研究通过量化分析揭示了这种不公平性，并提出了一种有效的缓解策略，能够显著减少速度提升的差距，从而提高投机解码在不同任务上的普适性和公平性。

Abstract: The practice of speculative decoding, whereby inference is probabilistically
supported by a smaller, cheaper, ``drafter'' model, has become a standard
technique for systematically reducing the decoding time of large language
models. This paper conducts an analysis of speculative decoding through the
lens of its potential disparate speed-up rates across tasks. Crucially, the
paper shows that speed-up gained from speculative decoding is not uniformly
distributed across tasks, consistently diminishing for under-fit, and often
underrepresented tasks. To better understand this phenomenon, we derive an
analysis to quantify this observed ``unfairness'' and draw attention to the
factors that motivate such disparate speed-ups to emerge. Further, guided by
these insights, the paper proposes a mitigation strategy designed to reduce
speed-up disparities and validates the approach across several model pairs,
revealing on average a 12% improvement in our fairness metric.

</details>


### [155] [RESTRAIN: From Spurious Votes to Signals -- Self-Driven RL with Self-Penalization](https://arxiv.org/abs/2510.02172)
*Zhaoning Yu,Will Su,Leitian Tao,Haozhu Wang,Aashu Singh,Hanchao Yu,Jianyu Wang,Hongyang Gao,Weizhe Yuan,Jason Weston,Ping Yu,Jing Xu*

Main category: cs.CL

TL;DR: 通过引入 RESTRAIN 框架，利用无标签数据进行自我约束的强化学习，在多个推理基准上取得了显著的性能提升，展示了无需金标数据即可实现强大推理能力的可行路径。


<details>
  <summary>Details</summary>
Motivation: 现有基于人类标注数据的强化学习方法在链式思考推理方面虽然有效，但成本高昂且在难题上的表现不佳。因此，需要一种能够利用无标签数据进行改进的学习方法。

Method: 提出 RESTRAIN（Self-restraint 的强化学习）框架，这是一种自我惩罚的强化学习方法。该方法将金标数据缺失转化为学习信号，通过惩罚过于自信和低一致性的样本，同时保留有希望的推理链，来利用模型整个答案分布中的信号。该框架可无缝集成到 GRPO 等策略优化方法中，实现无需监督的持续自我改进。

Result: 在 AIME25、MMLU_STEM 和 GPQA-Diamond 等具有挑战性的推理基准上，使用 Qwen3-4B-Base 和 OctoThinker Hybrid-8B-Base 模型，RESTRAIN 仅用无标签数据就将 Pass@1 指标分别提高了 +140.7%、+36.2% 和 +19.6%，性能接近使用金标数据训练的模型。

Conclusion: RESTRAIN 框架为在没有金标数据的情况下实现更强大的推理能力提供了一条可扩展的途径。

Abstract: Reinforcement learning with human-annotated data has boosted chain-of-thought
reasoning in large reasoning models, but these gains come at high costs in
labeled data while faltering on harder tasks. A natural next step is
experience-driven learning, where models improve without curated labels by
adapting to unlabeled data. We introduce RESTRAIN (REinforcement learning with
Self-restraint), a self-penalizing RL framework that converts the absence of
gold labels into a useful learning signal. Instead of overcommitting to
spurious majority votes, RESTRAIN exploits signals from the model's entire
answer distribution: penalizing overconfident rollouts and low-consistency
examples while preserving promising reasoning chains. The self-penalization
mechanism integrates seamlessly into policy optimization methods such as GRPO,
enabling continual self-improvement without supervision. On challenging
reasoning benchmarks, RESTRAIN delivers large gains using only unlabeled data.
With Qwen3-4B-Base and OctoThinker Hybrid-8B-Base, it improves Pass@1 by up to
+140.7 percent on AIME25, +36.2 percent on MMLU_STEM, and +19.6 percent on
GPQA-Diamond, nearly matching gold-label training while using no gold labels.
These results demonstrate that RESTRAIN establishes a scalable path toward
stronger reasoning without gold labels.

</details>


### [156] [Learning to Reason for Hallucination Span Detection](https://arxiv.org/abs/2510.02173)
*Hsuan Su,Ting-Yao Hu,Hema Swetha Koppula,Kundan Krishna,Hadi Pouransari,Cheng-Yu Hsieh,Cem Koc,Joseph Yitan Cheng,Oncel Tuzel,Raviteja Vemulapalli*

Main category: cs.CL

TL;DR: LLM幻觉检测通常被视为二元任务，但现实应用需要识别幻觉片段，这是一个多步骤决策过程。本文提出RL4HS框架，通过引入片段级奖励函数来激励推理，并采用Group Relative Policy Optimization和Class-Aware Policy Optimization来解决奖励不平衡问题，实验证明RL4HS在幻觉片段检测方面优于预训练模型和监督微调方法。


<details>
  <summary>Details</summary>
Motivation: 评估显式推理（如Chain-of-Thought）是否能帮助解决检测幻觉片段这一复杂的多步骤决策问题。

Method: 1. 评估了带和不带Chain-of-Thought（CoT）推理的预训练模型。 2. 提出了RL4HS（基于强化学习的幻觉片段检测）框架，该框架使用片段级奖励函数来激励推理。 3. RL4HS结合了Group Relative Policy Optimization和Class-Aware Policy Optimization来解决奖励不平衡问题。

Result: RL4HS在RAGTruth基准（包括摘要、问答、数据到文本任务）上的实验结果表明，RL4HS的性能优于预训练推理模型和监督微调方法。

Conclusion: 强化学习结合片段级奖励对于检测幻觉片段是必要且有效的。

Abstract: Large language models (LLMs) often generate hallucinations -- unsupported
content that undermines reliability. While most prior works frame hallucination
detection as a binary task, many real-world applications require identifying
hallucinated spans, which is a multi-step decision making process. This
naturally raises the question of whether explicit reasoning can help the
complex task of detecting hallucination spans. To answer this question, we
first evaluate pretrained models with and without Chain-of-Thought (CoT)
reasoning, and show that CoT reasoning has the potential to generate at least
one correct answer when sampled multiple times. Motivated by this, we propose
RL4HS, a reinforcement learning framework that incentivizes reasoning with a
span-level reward function. RL4HS builds on Group Relative Policy Optimization
and introduces Class-Aware Policy Optimization to mitigate reward imbalance
issue. Experiments on the RAGTruth benchmark (summarization, question
answering, data-to-text) show that RL4HS surpasses pretrained reasoning models
and supervised fine-tuning, demonstrating the necessity of reinforcement
learning with span-level rewards for detecting hallucination spans.

</details>


### [157] [ARUQULA -- An LLM based Text2SPARQL Approach using ReAct and Knowledge Graph Exploration Utilities](https://arxiv.org/abs/2510.02200)
*Felix Brei,Lorenz Bühmann,Johannes Frey,Daniel Gerber,Lars-Peter Meyer,Claus Stadler,Kirill Bulert*

Main category: cs.CL

TL;DR: LLM驱动的SPINACH代理通过迭代方式将自然语言问题转化为SPARQL查询，降低了知识图谱交互的门槛。


<details>
  <summary>Details</summary>
Motivation: 为了应对Text2SPARQL挑战，促进该领域的研究和改进，降低非计算机科学背景用户与知识图谱交互的难度。

Method: 提出了一种基于LLM的SPINACH代理，该代理不直接进行单次转换，而是通过探索和执行的迭代过程将自然语言问题转化为SPARQL查询。

Result: 对代理行为进行了详细分析，为未来的改进提供了见解。

Conclusion: LLM可以作为一种有前途的工具，通过迭代过程简化Text2SPARQL的转换，从而提高知识图谱的可访问性。

Abstract: Interacting with knowledge graphs can be a daunting task for people without a
background in computer science since the query language that is used (SPARQL)
has a high barrier of entry. Large language models (LLMs) can lower that
barrier by providing support in the form of Text2SPARQL translation. In this
paper we introduce a generalized method based on SPINACH, an LLM backed agent
that translates natural language questions to SPARQL queries not in a single
shot, but as an iterative process of exploration and execution. We describe the
overall architecture and reasoning behind our design decisions, and also
conduct a thorough analysis of the agent behavior to gain insights into future
areas for targeted improvements. This work was motivated by the Text2SPARQL
challenge, a challenge that was held to facilitate improvements in the
Text2SPARQL domain.

</details>


### [158] [Say One Thing, Do Another? Diagnosing Reasoning-Execution Gaps in VLM-Powered Mobile-Use Agents](https://arxiv.org/abs/2510.02204)
*Lingzhong Dong,Ziqi Zhou,Shuaibo Yang,Haiyue Sheng,Pengzhou Cheng,Zongru Wu,Zheng Wu,Gongshen Liu,Zhuosheng Zhang*

Main category: cs.CL

TL;DR: 该研究提出了一种新的评估框架来诊断移动端视觉语言模型（VLMs）在执行自然语言指令时出现的“推理-执行”差距，通过引入“真实动作对齐”（GTA）指标，结合现有的“精确匹配”（EM）指标，共同评估推理和执行的准确性，发现了两种差距：执行差距（EG）和推理差距（RG），并指出这些差距普遍存在，尤其是在大型模型中，EG比RG更常见，尽管模型规模增大可以缩小差距，但EG仍然存在，该框架有助于开发更值得信赖的移动端代理。


<details>
  <summary>Details</summary>
Motivation: 现有对移动端VLMs的研究主要关注执行准确性，而忽略了推理过程与真实动作是否一致，这可能导致用户因信任看似合理的推理而授权有害操作，造成损失或信任危机。本研究旨在解决这一问题，提出新的评估框架以诊断推理-执行差距。

Method: 引入“真实动作对齐”（GTA）指标，衡量推理过程所暗示的动作是否与真实动作一致。结合GTA和标准的“精确匹配”（EM）指标，共同评估推理和执行的准确性。在此基础上，定义了两种推理-执行差距：执行差距（EG，推理正确但执行失败）和推理差距（RG，执行成功但推理过程与实际执行不符）。

Result: 实验结果表明，推理-执行差距在各种移动端交互任务中普遍存在，其中执行差距比推理差距更常见。增加模型规模可以缩小总体差距，但即使是最大的模型也存在显著的执行差距。该框架能够可靠地反映最先进模型中存在的系统性EG/RG模式。

Conclusion: 推理-执行差距是移动端VLMs中普遍存在且需要关注的问题。本研究提出的GTA指标和评估框架能够有效诊断这些差距，为开发更可靠、值得信赖的移动端代理提供了具体的诊断方法和依据。

Abstract: Mobile-use agents powered by vision-language models (VLMs) have shown great
potential in interpreting natural language instructions and generating
corresponding actions based on mobile graphical user interface. Recent studies
suggest that incorporating chain-of-thought (CoT) reasoning tends to improve
the execution accuracy. However, existing evaluations emphasize execution
accuracy while neglecting whether CoT reasoning aligns with ground-truth
actions. This oversight fails to assess potential reasoning-execution gaps,
which in turn foster over-trust: users relying on seemingly plausible CoTs may
unknowingly authorize harmful actions, potentially resulting in financial loss
or trust crisis. In this work, we introduce a new evaluation framework to
diagnose reasoning-execution gaps. At its core lies Ground-Truth Alignment
(GTA), which measures whether the action implied by a CoT matches the
ground-truth action. By combining GTA with the standard Exact Match (EM)
metric, we jointly assess both the reasoning accuracy and execution accuracy.
This joint perspective reveals two types of reasoning-execution gaps: (i)
Execution Gap (EG), where the reasoning correctly identifies the correct action
but execution fails, and (ii) Reasoning Gap (RG), where execution succeeds but
reasoning process conflicts with the actual execution. Experimental results
across a wide range of mobile interaction tasks reveal that reasoning-execution
gaps are prevalent, with execution gaps occurring more frequently than
reasoning gaps. Moreover, while scaling up model size reduces the overall gap,
sizable execution gaps persist even in the largest models. Further analysis
shows that our framework reliably reflects systematic EG/RG patterns in
state-of-the-art models. These findings offer concrete diagnostics and support
the development of more trustworthy mobile-use agents.

</details>


### [159] [More Than One Teacher: Adaptive Multi-Guidance Policy Optimization for Diverse Exploration](https://arxiv.org/abs/2510.02227)
*Xiaoyang Yuan,Yujuan Ding,Yi Bin,Wenqi Shao,Jinyu Cai,Jingkuan Song,Yang Yang,Hengtao Shen*

Main category: cs.CL

TL;DR: AMPO框架通过自适应地利用多个教师模型的指导，并在模型自身探索失败时才进行干预，来增强LLM的长链条思考（LongCoT）推理能力，提高了数学和分布外任务的性能，并实现了更广泛的探索和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有的RLVR方法依赖单一教师或自我探索，存在模型偏见和探索受限的问题，限制了推理的多样性和性能。

Method: 提出了一种名为AMPO的新框架，该框架借鉴了知识蒸馏中的多教师策略，其核心是“按需指导”：当模型自身无法生成正确解决方案时，才自适应地利用多个教师模型的指导。此外，AMPO包含一个基于理解能力的教师选择机制，引导学生模型学习最容易理解的推理路径，从而平衡广泛探索和有效利用。

Result: AMPO在数学推理任务上比基线方法GRPO提高了4.3%，在分布外任务上提高了12.2%，显著提升了Pass@k性能，并实现了更多样化的探索。使用四个同等规模的教师模型，AMPO取得了与利用单个更强大教师模型（如DeepSeek-R1）及更多数据的方法相当的结果。

Conclusion: AMPO提供了一种更有效、更具扩展性的方法来提升LLM的推理能力和泛化性，通过按需指导和基于理解的教师选择，克服了现有方法的局限性。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) is a promising paradigm
for enhancing the reasoning ability in Large Language Models (LLMs). However,
prevailing methods primarily rely on self-exploration or a single off-policy
teacher to elicit long chain-of-thought (LongCoT) reasoning, which may
introduce intrinsic model biases and restrict exploration, ultimately limiting
reasoning diversity and performance. Drawing inspiration from multi-teacher
strategies in knowledge distillation, we introduce Adaptive Multi-Guidance
Policy Optimization (AMPO), a novel framework that adaptively leverages
guidance from multiple proficient teacher models, but only when the on-policy
model fails to generate correct solutions. This "guidance-on-demand" approach
expands exploration while preserving the value of self-discovery. Moreover,
AMPO incorporates a comprehension-based selection mechanism, prompting the
student to learn from the reasoning paths that it is most likely to comprehend,
thus balancing broad exploration with effective exploitation. Extensive
experiments show AMPO substantially outperforms a strong baseline (GRPO), with
a 4.3% improvement on mathematical reasoning tasks and 12.2% on
out-of-distribution tasks, while significantly boosting Pass@k performance and
enabling more diverse exploration. Notably, using four peer-sized teachers, our
method achieves comparable results to approaches that leverage a single, more
powerful teacher (e.g., DeepSeek-R1) with more data. These results demonstrate
a more efficient and scalable path to superior reasoning and generalizability.
Our code is available at https://github.com/SII-Enigma/AMPO.

</details>


### [160] [Enhanced Arabic-language cyberbullying detection: deep embedding and transformer (BERT) approaches](https://arxiv.org/abs/2510.02232)
*Ebtesam Jaber Aljohani,Wael M. S. Yafoo*

Main category: cs.CL

TL;DR: 本研究针对阿拉伯语网络欺凌检测方法稀缺的问题，提出并评估了多种深度学习模型，其中Bi-LSTM结合FastText词嵌入模型在检测阿拉伯语网络欺凌方面表现最佳，准确率达到98%。


<details>
  <summary>Details</summary>
Motivation: 由于社交媒体的普及，特别是X（前身为Twitter）等平台，网络欺凌对年轻人的情感健康构成了威胁。然而，目前针对阿拉伯语网络欺凌的自动检测方法非常有限。

Method: 本研究收集并预处理了10,662条X帖子数据，并使用kappa工具进行标注质量验证。研究人员测试了长短期记忆（LSTM）和双向长短期记忆（Bi-LSTM）模型，并结合了实验性词嵌入、预训练的BERT模型以及BERT本身，共进行了四组实验。

Result: 在多项实验中，LSTM-BERT和Bi-LSTM-BERT模型达到了97%的准确率。而Bi-LSTM模型结合FastText词嵌入的组合表现更为出色，准确率高达98%。

Conclusion: 本研究成功提升了阿拉伯语网络欺凌检测方法的有效性，并验证了深度学习模型（特别是Bi-LSTM与FastText的结合）在这一任务上的潜力。

Abstract: Recent technological advances in smartphones and communications, including
the growth of such online platforms as massive social media networks such as X
(formerly known as Twitter) endangers young people and their emotional
well-being by exposing them to cyberbullying, taunting, and bullying content.
Most proposed approaches for automatically detecting cyberbullying have been
developed around the English language, and methods for detecting
Arabic-language cyberbullying are scarce. Methods for detecting Arabic-language
cyberbullying are especially scarce. This paper aims to enhance the
effectiveness of methods for detecting cyberbullying in Arabic-language
content. We assembled a dataset of 10,662 X posts, pre-processed the data, and
used the kappa tool to verify and enhance the quality of our annotations. We
conducted four experiments to test numerous deep learning models for
automatically detecting Arabic-language cyberbullying. We first tested a long
short-term memory (LSTM) model and a bidirectional long short-term memory
(Bi-LSTM) model with several experimental word embeddings. We also tested the
LSTM and Bi-LSTM models with a novel pre-trained bidirectional encoder from
representations (BERT) and then tested them on a different experimental models
BERT again. LSTM-BERT and Bi-LSTM-BERT demonstrated a 97% accuracy. Bi-LSTM
with FastText embedding word performed even better, achieving 98% accuracy. As
a result, the outcomes are generalize

</details>


### [161] [AccurateRAG: A Framework for Building Accurate Retrieval-Augmented Question-Answering Applications](https://arxiv.org/abs/2510.02243)
*Linh The Nguyen,Chi Tran,Dung Ngoc Nguyen,Van-Cuong Pham,Hoang Ngo,Dat Quoc Nguyen*

Main category: cs.CL

TL;DR: AccurateRAG是一个用于构建高性能检索增强生成（RAG）问答应用的新框架，能提升开发效率，并在基准数据集上取得了新的最先进的问答性能。


<details>
  <summary>Details</summary>
Motivation: 介绍一个用于构建高性能检索增强生成（RAG）问答应用程序的新框架。

Method: 该框架提供了一个用于开发效率的流程，包括原始数据集处理、微调数据生成、文本嵌入和LLM微调、输出评估以及本地构建RAG系统。

Result: 实验结果表明，该框架的性能优于先前强大的基线，并在基准数据集上取得了新的最先进的问答性能。

Conclusion: AccurateRAG框架能够构建高性能的RAG问答系统，并在实验中取得了优于现有方法的成果。

Abstract: We introduce AccurateRAG -- a novel framework for constructing
high-performance question-answering applications based on retrieval-augmented
generation (RAG). Our framework offers a pipeline for development efficiency
with tools for raw dataset processing, fine-tuning data generation, text
embedding & LLM fine-tuning, output evaluation, and building RAG systems
locally. Experimental results show that our framework outperforms previous
strong baselines and obtains new state-of-the-art question-answering
performance on benchmark datasets.

</details>


### [162] [Explore Briefly, Then Decide: Mitigating LLM Overthinking via Cumulative Entropy Regulation](https://arxiv.org/abs/2510.02249)
*Tianyi Jiang,Yi Bin,Yujuan Ding,Kainian Zhu,Fei Ma,Jingkuan Song,Heng Tao Shen*

Main category: cs.CL

TL;DR: LLMs 存在过度思考问题，即为简单问题生成冗长推理。本文提出一种名为 TECA 的新指标来衡量推理过程中的探索程度，并引入一种新的推理范式“先探索，再决策”（Explore Briefly, Then Decide）及相关的 CER 机制，以动态确定推理的结束点，从而实现高效推理。实验结果表明，该方法能显著减少过度思考，且不牺牲问题解决能力，在简单数据集上的平均响应长度最多可减少 71%。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在处理复杂问题时，通过长链式思考（CoT）展现出强大的推理能力，但它们也存在过度思考的问题，即为简单问题生成不必要的冗长推理步骤，这会影响模型效率并使其难以适应问题的复杂性。

Method: 提出一种名为 Token Entropy Cumulative Average (TECA) 的新指标来衡量推理过程中的探索程度。在此基础上，提出一种新的推理范式“先探索，再决策”（Explore Briefly, Then Decide）以及相关的 Cumulative Entropy Regulation (CER) 机制。该范式利用 TECA 动态确定模型应在何时停止思考并给出最终答案。

Result: 在各种数学基准测试的实验结果表明，该方法在不牺牲问题解决能力的情况下，显著缓解了 LLMs 的过度思考问题。与现有方法相比，该方法在简单数据集上的平均响应长度最多可减少 71%，证明了其在创建更高效、更自适应的推理过程方面的有效性。

Conclusion: 所提出的 TECA 指标和“先探索，再决策”推理范式能够有效地解决 LLMs 的过度思考问题，显著提高推理效率，尤其是在处理简单问题时，并且不影响模型的整体性能。

Abstract: Large Language Models (LLMs) have demonstrated remarkable reasoning abilities
on complex problems using long Chain-of-Thought (CoT) reasoning. However, they
often suffer from overthinking, meaning generating unnecessarily lengthy
reasoning steps for simpler problems. This issue may degrade the efficiency of
the models and make them difficult to adapt the reasoning depth to the
complexity of problems. To address this, we introduce a novel metric Token
Entropy Cumulative Average (TECA), which measures the extent of exploration
throughout the reasoning process. We further propose a novel reasoning paradigm
-- Explore Briefly, Then Decide -- with an associated Cumulative Entropy
Regulation (CER) mechanism. This paradigm leverages TECA to help the model
dynamically determine the optimal point to conclude its thought process and
provide a final answer, thus achieving efficient reasoning. Experimental
results across diverse mathematical benchmarks show that our approach
substantially mitigates overthinking without sacrificing problem-solving
ability. With our thinking paradigm, the average response length decreases by
up to 71% on simpler datasets, demonstrating the effectiveness of our method in
creating a more efficient and adaptive reasoning process.

</details>


### [163] [InfoMosaic-Bench: Evaluating Multi-Source Information Seeking in Tool-Augmented Agents](https://arxiv.org/abs/2510.02271)
*Yaxin Du,Yuanshuo Zhang,Xiyuan Yang,Yifan Zhou,Cheng Wang,Gongyi Zou,Xianghe Pang,Wenhao Wang,Menglan Chen,Shuo Tang,Zhiyu Li,Siheng Chen*

Main category: cs.CL

TL;DR: 现有的大型语言模型代理（LLM agents）在信息检索方面存在局限性，过度依赖嘈杂且不可靠的网络搜索，并且缺乏领域特定的专业知识。虽然模型上下文协议（MCP）允许代理使用专业工具，但模型能否有效整合通用搜索和领域工具来解决复杂问题仍不明确。本研究提出了InfoMosaic-Bench，一个用于评估工具增强型代理多源信息检索能力的基准测试。该基准涵盖医学、金融、地图、视频、网络和跨领域集成等六个领域，要求代理结合通用搜索和领域特定工具。InfoMosaic-Bench通过InfoMosaic-Flow流程生成任务，该流程保证了任务的可靠性和非平凡性。实验结果表明，仅依赖网络搜索是不够的，领域工具的帮助效果不一致，并且当前LLM在工具使用和选择方面仍存在困难。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）代理在信息检索方面存在不足，主要依赖于嘈杂且不可靠的网络搜索，并且缺乏解决需要精确领域专业知识的任务的能力。虽然模型上下文协议（MCP）的出现使得代理能够与各种专业工具进行交互，但模型能否有效地利用这些工具，并将它们与通用搜索相结合来解决复杂问题，仍然是一个悬而未决的问题。因此，有必要创建一个专门用于评估工具增强型代理在多源信息检索能力的基准。

Method: 本研究引入了InfoMosaic-Bench，这是第一个专门针对工具增强型代理的多源信息检索基准。该基准覆盖了医学、金融、地图、视频、网络和跨领域集成六个具有代表性的领域。InfoMosaic-Bench要求代理结合使用通用网络搜索和领域特定的工具来完成任务。任务是通过InfoMosaic-Flow这一可扩展流程生成的，该流程将任务条件建立在经过验证的工具输出之上，强制执行跨源依赖关系，并排除了可以通过简单查找解决的平凡案例。这种设计确保了任务的可靠性和非平凡性。

Result: 在对14个最先进的大型语言模型（LLM）代理进行的实验中，发现仅使用网络信息是不够的，其中GPT-5的准确率仅为38.2%，通过率为67.5%。领域特定工具的使用提供了选择性的但效果不稳定的益处，在某些领域有所改善，但在其他领域却导致了性能下降。此外，有22.4%的失败案例源于不正确的工具使用或选择，这表明当前的大型语言模型在处理甚至基本的工具操作方面仍然存在困难。

Conclusion: 本研究提出的InfoMosaic-Bench基准测试表明，仅依赖网络搜索无法满足复杂的信息检索需求。虽然领域特定工具可以提供帮助，但其效果不稳定，并且当前的大型语言模型在有效地选择和使用这些工具方面仍存在显著挑战，这表明在多源信息检索和工具集成方面仍有很大的改进空间。

Abstract: Information seeking is a fundamental requirement for humans. However,
existing LLM agents rely heavily on open-web search, which exposes two
fundamental weaknesses: online content is noisy and unreliable, and many
real-world tasks require precise, domain-specific knowledge unavailable from
the web. The emergence of the Model Context Protocol (MCP) now allows agents to
interface with thousands of specialized tools, seemingly resolving this
limitation. Yet it remains unclear whether agents can effectively leverage such
tools -- and more importantly, whether they can integrate them with
general-purpose search to solve complex tasks. Therefore, we introduce
InfoMosaic-Bench, the first benchmark dedicated to multi-source information
seeking in tool-augmented agents. Covering six representative domains
(medicine, finance, maps, video, web, and multi-domain integration),
InfoMosaic-Bench requires agents to combine general-purpose search with
domain-specific tools. Tasks are synthesized with InfoMosaic-Flow, a scalable
pipeline that grounds task conditions in verified tool outputs, enforces
cross-source dependencies, and filters out shortcut cases solvable by trivial
lookup. This design guarantees both reliability and non-triviality. Experiments
with 14 state-of-the-art LLM agents reveal three findings: (i) web information
alone is insufficient, with GPT-5 achieving only 38.2% accuracy and 67.5% pass
rate; (ii) domain tools provide selective but inconsistent benefits, improving
some domains while degrading others; and (iii) 22.4% of failures arise from
incorrect tool usage or selection, highlighting that current LLMs still
struggle with even basic tool handling.

</details>


### [164] [Parallel Scaling Law: Unveiling Reasoning Generalization through A Cross-Linguistic Perspective](https://arxiv.org/abs/2510.02272)
*Wen Yang,Junhong Wu,Chong Li,Chengqing Zong,Jiajun Zhang*

Main category: cs.CL

TL;DR: 本研究从跨语言视角探讨了大型推理模型（LRM）的推理能力泛化问题，发现英式强化后训练（RPT）的效果在不同语言间迁移能力存在显著差异，并提出了“并行飞跃”、“并行缩放定律”和“单语泛化差距”等概念，为开发更具语言无关性的LRM提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 研究现有强化后训练（RPT）在大型推理模型（LRM）上的应用，并从跨语言视角探讨其推理能力泛化问题，以回答“从英语RPT获得的推理能力能否有效迁移到其他语言？”这一关键问题。

Method: 通过系统评估以英语为中心的LRM在多语言推理基准上的表现，并引入一个量化跨语言迁移能力的指标。同时，进行了干预性研究以探究模型过度依赖英语特定模式的现象，并进行了详尽的并行训练研究。

Result: 研究发现，跨语言迁移能力因初始模型、目标语言和训练范式而异。过度依赖英语模式的模型迁移能力较弱。提出了“并行飞跃”（从单语到单一并行语言的性能大幅提升）、“并行缩放定律”（跨语言推理迁移能力与并行训练语言数量呈幂律关系）以及“单语泛化差距”（实际单语性能与幂律预测之间的差异）。

Conclusion: 本研究挑战了LRM推理能力等同于人类认知能力的假设，并强调了开发更具语言无关性的LRM的重要性。研究结果为未来的模型开发提供了关键见解。

Abstract: Recent advancements in Reinforcement Post-Training (RPT) have significantly
enhanced the capabilities of Large Reasoning Models (LRMs), sparking increased
interest in the generalization of RL-based reasoning. While existing work has
primarily focused on investigating its generalization across tasks or
modalities, this study proposes a novel cross-linguistic perspective to
investigate reasoning generalization. This raises a crucial question:
$\textit{Does the reasoning capability achieved from English RPT effectively
transfer to other languages?}$ We address this by systematically evaluating
English-centric LRMs on multilingual reasoning benchmarks and introducing a
metric to quantify cross-lingual transferability. Our findings reveal that
cross-lingual transferability varies significantly across initial model, target
language, and training paradigm. Through interventional studies, we find that
models with stronger initial English capabilities tend to over-rely on
English-specific patterns, leading to diminished cross-lingual generalization.
To address this, we conduct a thorough parallel training study. Experimental
results yield three key findings: $\textbf{First-Parallel Leap}$, a substantial
leap in performance when transitioning from monolingual to just a single
parallel language, and a predictable $\textbf{Parallel Scaling Law}$, revealing
that cross-lingual reasoning transfer follows a power-law with the number of
training parallel languages. Moreover, we identify the discrepancy between
actual monolingual performance and the power-law prediction as
$\textbf{Monolingual Generalization Gap}$, indicating that English-centric LRMs
fail to fully generalize across languages. Our study challenges the assumption
that LRM reasoning mirrors human cognition, providing critical insights for the
development of more language-agnostic LRMs.

</details>


### [165] [From Behavioral Performance to Internal Competence: Interpreting Vision-Language Models with VLM-Lens](https://arxiv.org/abs/2510.02292)
*Hala Sheta,Eric Huang,Shuyu Wu,Ilia Alenabi,Jiajun Hong,Ryker Lin,Ruoxi Ning,Daniel Wei,Jialin Yang,Jiawei Zhou,Ziqiao Ma,Freda Shi*

Main category: cs.CL

TL;DR: VLM-Lens是一个开源工具包，用于系统地评估、分析和解释视觉语言模型（VLM），通过提取模型中间层的输出来实现。


<details>
  <summary>Details</summary>
Motivation: 为了系统地评估、分析和解释视觉语言模型（VLM），并加速社区对VLM的理解和改进。

Method: VLM-Lens提供了一个统一的、YAML可配置的接口，可以提取任何层中的中间输出，支持用户友好的操作，并易于与各种可解释性和分析方法集成。该工具包支持16个最先进的基础VLM及其30多个变体，并且可以扩展以适应新模型。

Result: 通过两个简单的分析实验， VLM-Lens揭示了不同层和目标概念的VLM隐藏表示存在系统性差异。

Conclusion: VLM-Lens是一个开源工具包，可以促进对VLM的系统性基准测试、分析和解释，从而加速社区在理解和改进VLM方面的努力。

Abstract: We introduce VLM-Lens, a toolkit designed to enable systematic benchmarking,
analysis, and interpretation of vision-language models (VLMs) by supporting the
extraction of intermediate outputs from any layer during the forward pass of
open-source VLMs. VLM-Lens provides a unified, YAML-configurable interface that
abstracts away model-specific complexities and supports user-friendly operation
across diverse VLMs. It currently supports 16 state-of-the-art base VLMs and
their over 30 variants, and is extensible to accommodate new models without
changing the core logic.
  The toolkit integrates easily with various interpretability and analysis
methods. We demonstrate its usage with two simple analytical experiments,
revealing systematic differences in the hidden representations of VLMs across
layers and target concepts. VLM-Lens is released as an open-sourced project to
accelerate community efforts in understanding and improving VLMs.

</details>


### [166] [F2LLM Technical Report: Matching SOTA Embedding Performance with 6 Million Open-Source Data](https://arxiv.org/abs/2510.02294)
*Ziyin Zhang,Zihan Liao,Hang Yu,Peng Di,Rui Wang*

Main category: cs.CL

TL;DR: F2LLM是一个基于现有基础模型微调的嵌入模型系列，能在较低成本下实现优异的性能，并提供了三种模型尺寸（0.6B, 1.7B, 4B）。


<details>
  <summary>Details</summary>
Motivation: 提出了一种低成本、高效率的嵌入模型训练方法，旨在平衡训练成本、模型大小和嵌入性能，以解决现有模型训练成本高昂的问题。

Method: 直接从基础模型微调，使用600万查询-文档-负例元组，这些元组来自开源、非合成的数据集。

Result: 在MTEB英语排行榜上，F2LLM-4B在约4B参数的模型中排名第二，总体排名第七；F2LLM-1.7B在1B-2B模型中排名第一。

Conclusion: F2LLM系列模型在性能、成本和模型大小之间取得了良好的平衡，并公开发布了模型、数据集和代码，为未来的研究提供了一个强大、可复现且经济高效的基线。

Abstract: We introduce F2LLM - Foundation to Feature Large Language Models, a suite of
state-of-the-art embedding models in three sizes: 0.6B, 1.7B, and 4B. Unlike
previous top-ranking embedding models that require massive contrastive
pretraining, sophisticated training pipelines, and costly synthetic training
data, F2LLM is directly finetuned from foundation models on 6 million
query-document-negative tuples curated from open-source, non-synthetic
datasets, striking a strong balance between training cost, model size, and
embedding performance. On the MTEB English leaderboard, F2LLM-4B ranks 2nd
among models with approximately 4B parameters and 7th overall, while F2LLM-1.7B
ranks 1st among models in the 1B-2B size range. To facilitate future research
in the field, we release the models, training dataset, and code, positioning
F2LLM as a strong, reproducible, and budget-friendly baseline for future works.

</details>


### [167] [Drawing Conclusions from Draws: Rethinking Preference Semantics in Arena-Style LLM Evaluation](https://arxiv.org/abs/2510.02306)
*Raphael Tang,Crystina Zhang,Wenyan Li,Carmen Lai,Pontus Stenetorp,Yao Lu*

Main category: cs.CL

TL;DR: 在LLM的竞技场式评估中，将平局视为查询难度而非模型能力均等，可提高评分预测精度。


<details>
  <summary>Details</summary>
Motivation: 现有LLM评分系统将竞技场式对战中的平局视为两个模型能力相当，并据此调整评分，但本文质疑此种观点，认为平局可能更多地反映了查询的难度。

Method: 通过分析真实世界的竞技场数据集，比较考虑和忽略平局对评分更新的影响，并研究了平局与查询难度、客观性之间的关系。

Result: 忽略平局的评分更新方式，在四个评分系统中均能使对战结果（包括平局）的预测精度相对提高1-3%。此外，研究发现查询难度越低、越客观时，越容易出现平局（风险比分别为1.37和1.35）。

Conclusion: 建议未来的LLM评分系统重新考虑平局的含义，并纳入查询属性以改进评分更新机制。

Abstract: In arena-style evaluation of large language models (LLMs), two LLMs respond
to a user query, and the user chooses the winning response or deems the
"battle" a draw, resulting in an adjustment to the ratings of both models. The
prevailing approach for modeling these rating dynamics is to view battles as
two-player game matches, as in chess, and apply the Elo rating system and its
derivatives. In this paper, we critically examine this paradigm. Specifically,
we question whether a draw genuinely means that the two models are equal and
hence whether their ratings should be equalized. Instead, we conjecture that
draws are more indicative of query difficulty: if the query is too easy, then
both models are more likely to succeed equally. On three real-world arena
datasets, we show that ignoring rating updates for draws yields a 1-3% relative
increase in battle outcome prediction accuracy (which includes draws) for all
four rating systems studied. Further analyses suggest that draws occur more for
queries rated as very easy and those as highly objective, with risk ratios of
1.37 and 1.35, respectively. We recommend future rating systems to reconsider
existing draw semantics and to account for query properties in rating updates.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [168] [exaPD: A highly parallelizable workflow for multi-element phase diagram (PD) construction](https://arxiv.org/abs/2510.01400)
*Feng Zhang,Zhuo Ye,Maxim Moraru,Ying Wai Li,Weiyi Xia,Yongxin Yao,Ryan Richard,Cai-Zhuang Wang*

Main category: cond-mat.mtrl-sci

TL;DR: exaPD是一个用于计算材料相图的易于使用的工作流，它通过并行化的分子动力学和蒙特卡洛模拟，在广泛的温度和成分范围内同时对多个相进行采样，从而加速了自由能计算。


<details>
  <summary>Details</summary>
Motivation: 精确的自由能计算对于生成可靠的材料相图至关重要，但由于计算成本高昂，这通常是一个耗时的过程。

Method: 该工作流使用LAMMPS包中的标准分子动力学（MD）和蒙特卡洛（MC）采样技术，通过Parsl实现的全局控制器进行大规模并行化，以实现近乎理想的可扩展性。它支持包括神经网络势在内的各种原子间势，并能同时对多种相进行采样。

Result: 该工作流能够计算出液相和固相（包括固溶体）的自由能，并使用PYCALPHAD包将这些自由能整合到CALPHAD模型中，用于构建相图。

Conclusion: exaPD通过并行化和标准模拟技术简化了自由能计算，从而加速了相图的构建过程，使其在材料发现和设计中更加实用。

Abstract: Phase diagrams (PDs) illustrate the relative stability of competing phases
under varying conditions, serving as critical tools for synthesizing complex
materials. Reliable phase diagrams rely on precise free energy calculations,
which are computationally intensive. We introduce exaPD, a user-friendly
workflow that enables simultaneous sampling of multiple phases across a fine
mesh of temperature and composition for free energy calculations. The package
employs standard molecular dynamics (MD) and Monte Carlo (MC) sampling
techniques, as implemented in the LAMMPS package. Various interatomic
potentials are supported, including the neural network potentials with near
{\it ab initio} accuracy. A global controller, built with Parsl, manages the
MD/MC jobs to achieve massive parallelization with near ideal scalability. The
resulting free energies of both liquid and solid phases, including solid
solutions, are integrated into CALPHAD modeling using the PYCALPHAD package for
constructing the phase diagram.

</details>


### [169] [Multiscale analysis of large twist ferroelectricity and swirling dislocations in bilayer hexagonal boron nitride](https://arxiv.org/abs/2510.01419)
*Md Tusher Ahmed,Chenhaoyue Wang,Amartya S. Banerjee,Nikhil Chandra Admal*

Main category: cond-mat.mtrl-sci

TL;DR: 异质变形的双层氮化硼（hBN）因其原子级薄的结构和铁电特性，在下一代非易失性存储器应用中备受关注。然而，以往的研究主要集中在小幅度形变上，而大形变下铁电性是否能持续存在仍是未知数。本研究利用Smith法双晶学，探究了双层hBN在大形变（相对于高对称堆叠如AA堆叠和21.786789°扭转配置）下的铁电性起源。我们证明了在接近AA堆叠和Σ7堆叠的配置中，双层hBN表现出面外铁电性。原子模拟显示，AA邻近系统在小扭转和小应变下均支持铁电性，其中小应变下的极化翻转由涡旋位错变形控制，而非AA邻近系统中的直界面位错。对于Σ7邻近系统，由于缺乏可靠的原子间势能，我们开发了一种结合密度泛函理论的连续介质模型——双晶学信息框架不变多尺度（BFIM）模型，该模型能够捕捉Σ7堆叠邻近大形变配置中的面外铁电性。这些大形变双层配置中的界面位错其Burgers矢量远小于小扭转和小应变下的双层hBN。BFIM模型不仅能重现原子模拟结果，还为预测原子模拟成本过高的位错异质结构中的铁电性提供了一个强大且计算高效的框架。


<details>
  <summary>Details</summary>
Motivation: 以往对异质变形双层hBN的研究主要集中在小幅度形变上，而缺乏对大形变下铁电性是否能持续存在的探索。

Method: 利用Smith法双晶学探究大形变下双层hBN的铁电性起源。通过原子模拟研究AA邻近系统在小扭转和小应变下的铁电性，并分析极化翻转机制。针对Σ7邻近系统，开发了一种结合密度泛函理论的连续介质模型（BFIM模型）来研究大形变下的铁电性。

Result: 证明了在接近AA堆叠和Σ7堆叠的配置中，双层hBN表现出面外铁电性。AA邻近系统在小扭转和小应变下均支持铁电性，其中小应变下的极化翻转由涡旋位错变形控制。Σ7邻近系统中的界面位错其Burgers矢量远小于小扭转和小应变下的双层hBN。BFIM模型能够捕捉Σ7堆叠邻近大形变配置中的面外铁电性，并重现原子模拟结果。

Conclusion: 本研究揭示了异质变形双层hBN在大形变下依然可以保持铁电性，并阐明了不同形变方式下铁电性的起源和调控机制。开发的BFIM模型为研究大尺寸异质结构中的铁电性提供了高效的计算工具。

Abstract: With its atomically thin structure and intrinsic ferroelectric properties,
heterodeformed bilayer hexagonal boron nitride (hBN) has gained prominence in
next-generation non-volatile memory applications. However, studies to date have
focused almost exclusively on small heterodeformations, leaving the question of
whether ferroelectricity can persist under large heterodeformation entirely
unexplored. In this work, we establish the crystallographic origin of
ferroelectricity in bilayer hBN configurations heterodeformed relative to
high-symmetry configurations such as the AA-stacking and the 21.786789 $\circ$
twisted configuration, using Smith normal form bicrystallography. We then
demonstrate out-of-plane ferroelectricity in bilayer hBN across configurations
vicinal to both the AA and $\Sigma 7$ stacking. Atomistic simulations reveal
that AA-vicinal systems support ferroelectricity under both small twist and
small strain, with polarization switching in the latter governed by the
deformation of swirling dislocations rather than the straight interface
dislocations seen in the former. For $\Sigma 7$-vicinal systems, where reliable
interatomic potentials are lacking, we develop a
density-functional-theory-informed continuum framework--the
bicrystallography-informed frame-invariant multiscale (BFIM) model, which
captures out-of-plane ferroelectricity in heterodeformed configurations vicinal
to the $\Sigma 7$ stacking. Interface dislocations in these large
heterodeformed bilayer configurations exhibit markedly smaller Burgers vectors
compared to the interface dislocations in small-twist and small-strain bilayer
hBN. The BFIM model reproduces atomistic simulation results and provides a
powerful, computationally efficient framework for predicting ferroelectricity
in large-unit-cell heterostructures where atomistic simulations are
prohibitively expensive.

</details>


### [170] [Stabilization of sliding ferroelectricity through exciton condensation](https://arxiv.org/abs/2510.01465)
*Matteo D'Alessio,Daniele Varsano,Elisa Molinari,Massimo Rontani*

Main category: cond-mat.mtrl-sci

TL;DR: 二维材料层间相对滑移可诱导垂直于层面的电子极化，即滑动铁电性。


<details>
  <summary>Details</summary>
Motivation: 理论研究WTe2双层结构中滑动铁电性的起源和稳定性，重点关注激子效应在其中的作用。

Method: 通过理论计算，研究激子效应如何导致能带重构，以及激子凝聚对铁电性的稳定作用。

Result: 激子效应引起了基态的能带重构，并且激子凝聚在稳定滑动铁电性方面起到了比预期更重要的作用。

Conclusion: 激子效应和激子凝聚是滑动铁电性的关键因素，该现象在多种二维材料中普遍存在，并为电场调控量子物性提供了新途径。

Abstract: Sliding ferroelectricity is a phenomenon that arises from the insurgence of
spontaneous electronic polarization perpendicular to the layers of
two-dimensional (2D) systems upon the relative sliding of the atomic layer
constituents. Because of the weak van der Waals (vdW) interactions between
layers, sliding and the associated symmetry breaking can occur at low energy
cost in materials such as transition-metal dichalcogenides. Here we discuss
theoretically the origin and quantitative understanding of the phenomenon by
focusing on a prototype structure, the WTe2 bilayer, where sliding
ferroelectricity was first experimentally observed. We show that excitonic
effects induce relevant energy band renormalizations in the ground state, and
exciton condensation contributes significantly to stabilizing ferroelectricity
upon sliding beyond previous predictions. Enhanced excitonic effects in 2D and
vdW sliding are general phenomena that point to sliding ferroelectricity as
relevant for a broad class of important materials, where the intrinsic electric
dipole can couple with other quantum phenomena and, in turn, an external
electric field can control the quantum phases through ferroelectricity in
unexplored ways.

</details>


### [171] [Obstruction-Driven Parity Inversion for Enhanced Optical Absorption in Hexagonal Transition Metal Dichalcogenides](https://arxiv.org/abs/2510.01575)
*Seungil Baek,Jun Jung,Yong-Hyun Kim*

Main category: cond-mat.mtrl-sci

TL;DR: 单层h-TMDs的d-d跃迁在名义上是禁戒的，但它们表现出显著的光吸收。本文揭示了一种通过阻碍驱动的带反演来促进带边附近偶极子允许的光跃迁的奇偶性反演机制。


<details>
  <summary>Details</summary>
Motivation: 解释单层h-TMDs（如MoS2）尽管d-d跃迁在名义上是禁戒的，但仍表现出显著光吸收的现象。

Method: 通过比较平凡和受阻的原子极限相，揭示了诱导奇偶性反演的杂化d轨道之间的点间相互作用。

Result: 发现了诱导奇偶性反演的点间相互作用，并提出了一种通过奇偶性控制来调节光学性质的新方法。

Conclusion: 该研究为通过奇偶性控制调节光学性质提供了一种新颖的方法，并连接了拓扑与光物质相互作用。

Abstract: The optical selection rule states that opposite parity between the valence
and conduction bands is required for optical absorption to occur. However,
monolayer hexagonal transition metal dichalcogenides (h-TMDs) such as $
\mathrm{MoS}_{2} $ exhibit pronounced optical absorption despite their
nominally dipole-forbidden d-d transitions. In this Letter, we elucidate a
parity inversion mechanism through which obstruction-driven band inversion
promotes dipole-allowed optical transitions near the band edge in monolayer
h-TMDs. By comparing trivial and obstructed atomic limit phases, we show that
intersite interactions between hybridized d orbitals induce parity inversion.
Our results provide a novel approach to tuning optical properties through
parity control, bridging the gap between topology and light-matter interaction.

</details>


### [172] [Electride behavior at high pressure in silicon and other elements in solid and liquid phases](https://arxiv.org/abs/2510.01583)
*Salma Ahmed,Felipe González-Cataldo,Victor Naden Robinson,Burkhard Militzer*

Main category: cond-mat.mtrl-sci

TL;DR: 元素硅在超过400 GPa的压力下可以成为电子材料。该研究通过从头算分子动力学模拟研究了高压高温下硅、钠、钾和镁的行为，并提出了识别高压电子材料的定量阈值，最后计算了X射线衍射图以评估电子材料形成的影响。


<details>
  <summary>Details</summary>
Motivation: 介绍电子材料的定义，指出大多数已知的电子材料是碱金属或碱土金属，并提出本研究的目标是探索元素硅在高压下是否会成为电子材料。

Method: 使用从头算分子动力学（MD）模拟研究高压高温下的硅、钠、钾和镁。分析了液体和十种晶体结构的电荷密度和电子局域化函数（ELF）。提出了用于识别高压电子材料的定量阈值（ELF最大值>0.7，ELF盆地周围至少有0.9个电子，拉普拉斯电荷密度负值且其绝对值>10^-3 e/bohr^5）。计算了X射线衍射图。

Result: 发现了元素硅在超过400 GPa的压力下可以成为电子材料。提出了识别高压电子材料的定量阈值。计算的X射线衍射图表明电子材料的形成会影响衍射图。

Conclusion: 元素硅在高压下可以成为电子材料。提出的定量阈值可作为未来研究电子材料的基准。电子材料的形成会影响X射线衍射图。

Abstract: Electrides are materials in which some of the electrons are localized at the
interstitial sites rather than around the atoms or along atomic bonds. Most
elemental electrides are either alkali metals or alkaline-earth metals because
of their low ionization potential. In this work, we report that elemental
silicon becomes an electride at pressures exceeding 400 GPa. With {\it ab
initio} molecular dynamics (MD) simulations, we study this behavior for
silicon, sodium, potassium, and magnesium at high pressure and temperature. We
performed simulations for liquids and ten crystal structures. Charge density
and electron localization functions (ELF) are analyzed for representative
configurations extracted from the MD trajectories. By analyzing a variety of
electride structures, we suggest the following quantitative thresholds for the
ELF and charge density in each interstitial site to classify high-pressure
electrides: (1) the maximum ELF value should be greater than 0.7, (2) there
should be at least 0.9 electrons near the ELF basin, and (3) the Laplacian
charge density, $\nabla^2 \rho(\mathbf{r}_0)$, should be negative with
magnitude greater than $10^{-3}\ e/\mathrm{bohr}^5$. Finally, we compute X-ray
diffraction patterns to determine the degree to which they are affected by the
electride formation. Overall, this framework could become a benchmark for
future theoretical and experimental studies on electrides.

</details>


### [173] [Multifunctional Oxide Nanosheets: Frictional, Hall, and Piezoelectric Deformation of 2D Ga2O3](https://arxiv.org/abs/2510.01697)
*Md Akibul Islam,Uichang Jeong,Nima Barri,Azmeera Jannat,Ali Zavabeti,Seungbum Hong,Tobin Filleter*

Main category: cond-mat.mtrl-sci

TL;DR: 镓氧化物纳米片具有优异的性能，可用于多功能纳米器件。


<details>
  <summary>Details</summary>
Motivation: 与其他二维材料相比，原子层厚氧化物的多功能特性研究不足，特别是镓氧化物，因其超宽带隙、热稳定性和机械刚性，在纳米机电系统中具有潜力。

Method: 利用原子力显微镜（AFM）技术，包括摩擦力显微镜（FFM）、范德堡-霍尔测量和压电响应力显微镜（PFM），研究了β-Ga2O3纳米片的摩擦学、输运和机电性能。

Result: 观察到摩擦力与外加偏压有关，这归因于缺陷介导的电荷俘获；范德堡-霍尔测量证实了β-Ga2O3的超宽带隙特性，即使在高温下电子传输也受到抑制；压电响应力显微镜显示了可测量的反向机电响应，这与氧空位引起的不对称性一致。

Conclusion: β-Ga2O3纳米片结合了绝缘稳定性、偏压可调的界面力学和缺陷驱动的机电活性，为开发多功能氧化物纳米器件提供了独特的平台。

Abstract: Atomically thin oxides are increasingly recognized as an emerging class of 2D
materials, yet their multifunctional properties have been far less investigated
compared to other layered materials. Among these, gallium oxide is
distinguished by its ultrawide bandgap, thermal stability, and mechanical
rigidity, positioning it as a candidate material for nanoelectromechanical
systems. In this study, the tribological, transport, and electromechanical
properties of beta-Ga2O3 nanosheets were probed using atomic force microscopy
(AFM)--based techniques. Friction force microscopy (FFM) was used to
investigate interfacial sliding, and a dependence of friction on external bias
was observed, which was attributed to defect-mediated charge trapping. Van der
Pauw Hall measurements were conducted up to 400 $^{\circ}$C, through which the
ultrawide bandgap nature of beta-Ga2O3 was confirmed, as electronic transport
remained suppressed despite high thermal activation. Piezoresponse force
microscopy (PFM) was further applied, and a measurable converse
electromechanical response on the order of a few pm/V was revealed, consistent
with oxygen-vacancy--induced symmetry breaking. By integrating tribological,
electrical, and electromechanical measurements, it was demonstrated that
beta-Ga2O3 nanosheets present a unique platform in which insulating stability,
bias-tunable interfacial mechanics, and defect-enabled electromechanical
activity coexist, offering new opportunities for multifunctional oxide
nanodevices.

</details>


### [174] [Giant enhancement of terahertz high-harmonic generation by cavity engineering of Dirac semimetal](https://arxiv.org/abs/2510.01760)
*Siyu Duan,Lili Shi,Patrick Pilch,Anneke Reinold,Sergey Kovalev,Renato M. A. Dantas,Yunkun Yang,Faxian Xiu,Miriam Serena Vitiello,Zhe Wang*

Main category: cond-mat.mtrl-sci

TL;DR: 通过设计包含三维狄拉克半金属的微腔结构，实现了超强的太赫兹非线性效应，并将三倍和五倍谐波的产率提高了三个数量级以上。


<details>
  <summary>Details</summary>
Motivation: 以往的研究主要集中在二维材料（如石墨烯）的微腔设计上，而对三维狄拉克半金属的类似工程化研究尚不充分。

Method: 制备了在三维狄拉克半金属Cd3As2纳米薄膜上覆盖金属超表面微腔结构，并利用该结构谐振增强了皮秒太赫兹脉冲的近场强度，从而驱动了狄拉克费米子的非线性响应。

Result: 观察到超强的太赫兹非线性效应，三倍和五倍谐波的产率显著提高，增加了三个数量级以上，并且在高谐波产生过程中达到了饱和。

Conclusion: 微腔工程是一种有效的设计三维狄拉克半金属微结构以实现强太赫兹非线性效应的策略，能够将狄拉克费米子的非线性响应从弱非微扰区域驱动到强非微扰区域。

Abstract: Engineered micro- or nano-structures based on nonlinear optical materials
offer versatile opportunities for optoelectronic applications. While extensive
efforts have been devoted to design tailored microcavities to promote and
increase the optical nonlinearities of graphene, the potential of engineering
its three-dimensional counterparts -- three-dimensional Dirac semimetals --
remains largely unexplored. Here we report on exceptionally strong terahertz
nonlinearities in a cavity-engineered Dirac semimetal microstructure, and
demonstrate a giant enhancement of terahertz third- and fifth-order harmonic
yields by more than three orders of magnitude. By fabricating a designed
structure of metallic metasurface microcavities on a nanometer thin film of the
threedimensional Dirac semimetal Cd3As2, we significantly enhance the
near-field intensity of a picosecond terahertz excitation pulse in resonance
with the microcavity eigenmode. This transiently modifies the nonlinearities of
the thin film and drives the nonlinear responses of the Dirac fermions from a
weakly to a deeply nonperturbative regime where the observed high-harmonic
generation essentially saturates.

</details>


### [175] [Metallurgy at the nanoscale: domain walls in nanoalloys](https://arxiv.org/abs/2510.01769)
*Grégoire Breyton,Hakim Amara,Jaysen Nelayah,Christine Mottet,Riccardo Gatti,Jérôme Creuze,Adrien Moncomble,Damien Alloyeau,Nathaly Ortiz Peña,Guillaume Wang,Christian Ricolleau*

Main category: cond-mat.mtrl-sci

TL;DR: 在CuAu纳米粒子中，通过应变弛豫和表面效应，形成了取向畴壁。


<details>
  <summary>Details</summary>
Motivation: 域壁在二元合金的相变和物理性质中起着核心作用，但其在纳米尺度上的存在性一直是一个挑战。

Method: 结合实验和数值方法，研究CuAu纳米粒子中取向畴壁的形成。

Result: 证明了较大纳米粒子中畴的形成是由弹性应变弛豫驱动的，而较小纳米粒子则受表面效应支配。此外，研究表明多变体纳米粒子倾向于通过连续弹性模型形成各向同性材料。

Conclusion: 取向畴壁可以在CuAu纳米粒子中形成，其形成机制取决于粒子尺寸，较大粒子由应变弛豫驱动，较小粒子由表面效应驱动。多变体纳米粒子趋向于形成各向同性材料。

Abstract: In binary alloys, domain walls play a central role not only on the phase
transitions but also on their physical properties and were at the heart of the
70's metallurgy research. Whereas it can be predicted, with simple physics
arguments, that such domain walls cannot exist at the nanometer scale due to
the typical lengths of the statistical fluctuations of the order parameter,
here we show, with both experimental and numerical approaches how orientational
domain walls are formed in CuAu nanoparticles binary model systems. We
demonstrate that the formation of domains in larger NPs is driven by elastic
strain relaxation which is not needed in smaller NPs where surface effects
dominate. Finally, we show how the multivariants NPs tend to form an isotropic
material through a continuous model of elasticity.

</details>


### [176] [Machine-learning-enabled methodology for the ab-initio simulations of sub-$μ$m-wide nanoribbons](https://arxiv.org/abs/2510.01802)
*Guan-Hao Peng,Chin-Jui Huang,Wen-Teng Yang,Shun-Jen Cheng*

Main category: cond-mat.mtrl-sci

TL;DR: 提出一种结合第一性原理计算和机器学习的紧束缚模型，用于高效且可靠地模拟介观纳米结构。


<details>
  <summary>Details</summary>
Motivation: 第一性原理方法计算成本高，而经验带理论参数不可靠，需要一种能兼顾精度和效率的方法来模拟介观纳米结构。

Method: 1. 从小尺寸纳米结构中提取Wannier紧束缚（WTB）参数作为机器学习训练数据。
2. 构建不依赖规范的（GI）基组，将WTB模型转化为GI-WTB模型，以消除规范自由度，使参数具有可比性。
3. 利用机器学习预测参数变化，构建机器学习GI-WTB（ML-GI-WTB）模型。

Result: 将ML-GI-WTB模型应用于MoS2扶手椅边缘纳米带，结果与第一性原理计算高度一致，并能可靠模拟亚微米宽的纳米带。

Conclusion: 该ML-GI-WTB框架能够以高效的方式模拟传统第一性原理方法难以处理的实际尺寸纳米结构的电子性质，为纳米结构模拟提供了一个可扩展的工具。

Abstract: Simulation of mesoscopic nanostructures is a central challenge in condensed
matter physics and device applications. First-principles methods provide
accurate electronic structures but are computationally prohibitive for large
systems, while empirical band theories are efficient yet limited by parameter
fitting that neglects wavefunction information and often yields
non-transferable parameters. We propose a methodology that bridges these
approaches, achieving first-principles-level reliability with computational
efficiency through a machine-learning-enabled tight-binding framework. Our
approach starts with Wannier tight-binding (WTB) parameters from small
nanostructures, which serve as training data for machine learning (ML). To
remove the gauge freedom of Wannier functions that obscures size- and
geometry-dependent parameter trends, we construct gauge-independent (GI) bases
and transform the WTB model into a gauge-independent WTB (GI-WTB) model. This
enables robust parameter fitting and ML prediction of parameter variations,
yielding the machine-learning GI-WTB (ML-GI-WTB) model. Applied to MoS2
armchair-edge nanoribbons, the ML-GI-WTB model shows excellent agreement with
first-principles results and enables reliable simulations of sub-$\mu$m-wide
nanoribbons. This framework provides a scalable tool for predicting electronic
properties of realistic nanostructures beyond the reach of conventional
first-principles methods.

</details>


### [177] [Accurate Machine-Learning Description for SiC in Extreme Environments](https://arxiv.org/abs/2510.01827)
*Jintong Wu,Zhuang Shao,Junlei Zhao,Flyura Djurabekova,Kai Nordlund,Fredric Granberg,Qingmin Zhang,and Jesper Byggmästar*

Main category: cond-mat.mtrl-sci

TL;DR: 开发了一种机器学习势能（ML-IAP），用于模拟SiC的2H和3C多晶型物，并研究了其P-T相图和辐照损伤。


<details>
  <summary>Details</summary>
Motivation: SiC在核材料、机械部件和半导体领域有广泛应用，但现有计算方法在模拟大尺度和长时间方面存在效率问题，且传统经验势能无法准确捕捉辐照损伤现象。

Method: 开发了一种计算效率高、通用的机器学习势能（ML-IAP），能够进行千万原子、微秒级尺度的分子动力学（MD）模拟。利用ML-IAP系统地绘制了2H和3C多晶型的P-T相图，并计算了阈值位移能（TDE）分布。通过碰撞级联模拟深入研究了多晶型依赖的初级辐照损伤团簇化行为。

Result: 成功开发了ML-IAP，实现了高效的SiC多尺度模拟。绘制了2H和3C SiC的P-T相图，并获得了TDE分布。揭示了ML-IAP能够比传统经验势能更准确地模拟辐照损伤中的初级损伤团簇化现象。

Conclusion: 所开发的ML-IAP能够高效、准确地模拟SiC材料，特别是在研究其P-T相图和辐照损伤方面，为SiC在核材料等领域的应用提供了重要的计算支持。

Abstract: Silicon carbide (SiC) polymorphs are widely employed as nuclear materials,
mechanical components, and wide-bandgap semiconductors. The rapid advancement
of SiC-based applications has been complemented by computational modeling
studies, including both ab initio and classical atomistic approaches. In this
work, we develop a computationally efficient and general-purpose
machine-learned interatomic potential (ML-IAP) capable of multimillion-atom
molecular dynamics (MD) simulations over microsecond timescales. Using ML-IAP,
we systematically map the comprehensive pressure-temperature phase diagram (P-T
phase diagram) and the threshold displacement energy (TDE) distributions for
the 2H and 3C polymorphs. Furthermore, collision cascade simulations provide
in-depth insights into polymorph-dependent primary radiation damage clustering,
a phenomenon that conventional empirical potentials fail to accurately capture.

</details>


### [178] [Enhancing the Efficiency of Time-Dependent Density Functional Theory Calculations of Dynamic Response Properties](https://arxiv.org/abs/2510.01875)
*Zhandos A. Moldabekov,Sebastian Schwalbe,Uwe Hernandez Acosta,Thomas Gawne,Jan Vorberger,Michele Pavanello,Tobias Dornheim*

Main category: cond-mat.mtrl-sci

TL;DR: TDDFT模拟X射线汤姆逊散射的计算成本高，通过虚时密度-密度关联函数和约束噪声衰减技术，将计算速度提高了10倍。


<details>
  <summary>Details</summary>
Motivation: TDDFT是模拟极端条件下材料性质（如高压和激光加热）以及XRTS光谱的精确方法，但计算成本高昂。

Method: 提出一种基于动态结构因子与虚时密度-密度关联函数之间一一映射的优化方法，并结合了虚时域收敛性测试和约束噪声衰减技术。

Result: 将TDDFT计算效率提高了高达一个数量级，为模拟单次极端条件下的XRTS测量节省了数百万CPU小时。

Conclusion: 所提出的优化方法能够显著提高TDDFT在极端条件下材料模拟的效率，而不会引入显著的偏差。

Abstract: X-ray Thomson scattering (XRTS) constitutes an essential technique for
diagnosing material properties under extreme conditions, such as high pressures
and intense laser heating. Time-dependent density functional theory (TDDFT) is
one of the most accurate available ab initio methods for modeling XRTS spectra,
as well as a host of other dynamic material properties. However, strong thermal
excitations, along with the need to account for variations in temperature and
density as well as the finite size of the detector significantly increase the
computational cost of TDDFT simulations compared to ambient conditions. In this
work, we present a broadly applicable method for optimizing and enhancing the
efficiency of TDDFT calculations. Our approach is based on a one-to-one mapping
between the dynamic structure factor and the imaginary time density--density
correlation function, which naturally emerges in Feynman's path integral
formulation of quantum many-body theory. Specifically, we combine rigorous
convergence tests in the imaginary time domain with a constraints-based noise
attenuation technique to improve the efficiency of TDDFT modeling without the
introduction of any significant bias. As a result, we can report a speed-up by
up to an order of magnitude, thus potentially saving millions of CPU hours for
modeling a single XRTS measurement of matter under extreme conditions.

</details>


### [179] [Spin-phonon coupling and isotope-related pseudo-molecule vibrations in layered Cr$_2$Ge$_2$Te$_6$ ferromagnet](https://arxiv.org/abs/2510.01881)
*Grzegorz Krasucki,Katarzyna Olkowska-Pucko,Tomasz Woźniak,Mihai I. Sturza,Holger Kohlmann,Adam Babiński,Maciej R. Molas*

Main category: cond-mat.mtrl-sci

TL;DR: 铬锗碲化物（Cr2Ge2Te6）的振动结构研究揭示了强烈的自旋-声子耦合，该耦合与材料中局部磁有序和铁磁相变的出现有关。


<details>
  <summary>Details</summary>
Motivation: 研究铬锗碲化物（Cr2Ge2Te6）的振动结构，并揭示其自旋-声子耦合特性。

Method: 利用高分辨率拉曼散射（RS）光谱测量和密度泛函理论（DFT）计算来识别和分析Cr2Ge2Te6的10种拉曼活性模式（5A_g和5E_g）。研究了温度（5 K至300 K）对RS光谱的影响，并模拟了A_g^5模式的独特形状，考虑了Ge同位素的影响。

Result: 测量并识别了Cr2Ge2Te6的10种拉曼活性模式。在约150 K和60 K时观察到强烈的磁声子耦合，分别与局部磁有序和完全铁磁相变相关。通过考虑Ge同位素振动，成功模拟了A_g^5模式的独特形状。

Conclusion: Cr2Ge2Te6表现出强烈的自旋-声子耦合，这与材料的磁相变密切相关。A_g^5模式的独特形状可以通过考虑Ge同位素效应来解释。

Abstract: The vibrational structure of chromium germanium telluride
(Cr$_2$Ge$_2$Te$_6$, CGT) is investigated and a strong spin-phonon coupling is
revealed. The measured high-resolution Raman scattering (RS) spectra are
composed of the 10 Raman-active modes: 5A$_\textrm{g}$ and 5E$_\textrm{g}$,
predicted by calculation using the density functional theory and identified
using polarization-resolved RS measurements. We also studied the effect of
temperature on the RS spectra of CGT from 5~K to 300~K. A strong magneto-phonon
coupling in CGT is revealed at temperatures of about 150~K and 60~K, which are
associated with the appearance of the local magnetic order in the material and
the transition to the complete ferromagnetic phase, respectively. Moreover, a
unique shape of the A$_g^5$ mode composed of a set of very narrow Raman peaks
is simulated using a model that takes into account vibrations of Ge-Ge
pseudo-molecules for various Ge isotopes.

</details>


### [180] [Quantum Effects or Theoretical Artifacts? A Computational Reanalysis of Hydrogen at High-Pressure](https://arxiv.org/abs/2510.02098)
*Stefano Racioppi,Eva Zurek*

Main category: cond-mat.mtrl-sci

TL;DR: meta-GGA泛函在400-700 GPa范围内比GGA更准确地描述了氢的相图，解决了之前理论预测的动力学不稳定性问题，并更好地解释了实验观察结果。


<details>
  <summary>Details</summary>
Motivation: 高压氢的相图和稳定性是凝聚态物理中的核心问题，理论预测和实验观察都对方法学选择高度敏感。

Method: 使用R2SCAN和SCAN0（meta-GGA泛函）以及PBE（GGA泛函）计算了400-700 GPa范围内氢的冷相图，并进行了声子谱和键合分析。

Result: meta-GGA泛函稳定了分子相（Cmca-4, Cmca-12, C2/c）到更高的压力，更符合实验观察；R2SCAN计算消除了之前PBE预测的动力学不稳定性；PBE人为地削弱了分子内H-H键并增强了分子间相互作用，而meta-GGA保留了更强的分子特性。

Conclusion: meta-GGA泛函比GGA更能准确地描述高压氢的相稳定性和结合特性，解决了之前理论预测的动力学不稳定性问题，并与实验结果更吻合。精确描述势能面（尤其是其曲率）对于评估高压氢的相稳定性和结合至关重要。

Abstract: The stability of high-pressure phases of hydrogen remains a central question
in condensed matter physics, where both experimental observations and
theoretical predictions are highly sensitive to methodological choices. Here,
we revisit the cold phase diagram of hydrogen between 400 and 700 GPa using the
meta-GGA functionals (R2SCAN and SCAN0) and compare the results with the more
common PBE. At the meta-GGA level, molecular phases (Cmca-4, Cmca-12, and C2/c)
are stabilized over the atomic I41/amd phase up to significantly higher
pressures than predicted by GGA, in closer agreement with diffusion Monte Carlo
calculations and experimental observations of band-gap closure near 425 GPa.
Furthermore, phonon spectra calculated with R2SCAN show that the dynamical
instabilities and anharmonic signatures previously predicted at the GGA level
vanish, indicating that such effects may partly arise from functional
deficiencies rather than genuine nuclear quantum effects. Bonding analysis
reveals that PBE artificially weakens intramolecular H-H bonds and enhances
intermolecular interactions through charge delocalization, whereas meta-GGA
preserves a more localized molecular character. Anharmonic motion remains
relevant for finite-temperature dynamics; however, we demonstrate that the
accurate description of the potential energy surface - particularly its
curvature near equilibrium - is pivotal for assessing both phase stability and
bonding of hydrogen at high-pressure.

</details>


### [181] [Reversal of strain state in a Mott insulator thin film by controlling substrate morphology](https://arxiv.org/abs/2510.02234)
*Reetendra Singh,Abhishek Rakshit,Galit Atiya,Michael Kalina,Yaron Kauffmann,Yoav Kalcheim*

Main category: cond-mat.mtrl-sci

TL;DR: 通过改变衬底形貌来调控V2O3薄膜的应变，从而调控其相图，抑制金属-绝缘体转变或稳定绝缘相。


<details>
  <summary>Details</summary>
Motivation: 研究V2O3薄膜的相图，特别是如何通过应变调控其相变行为。

Method: 通过改变衬底形貌（平坦或台阶状）来调控薄膜/衬底的热膨胀失配，进而实现对V2O3薄膜的压应变或张应变。利用高分辨率扫描透射电子显微镜（HRSTEM）观察原子台阶和晶格缺陷。

Result: 实现了强压应变或张应变，导致金属-绝缘体转变完全被抑制或在所有温度下稳定绝缘相，电阻率差异可达几个数量级。

Conclusion: 提出了一种调控薄膜应变的新机制，加深了对结构自由度影响相稳定性的理解，并可能应用于需要室温以上绝缘体-金属开关的应用。

Abstract: The V2O3 phase diagram contains two insulating phases and one metallic phase
with different lattice structures. The stability of these phases is very
sensitive to pressure, offering a mechanism to tune phase transitions by
inducing strain in thin films. The most studied source of strain is lattice
mismatch between the film and the substrate. In this work, however, we find
that the film/substrate thermal expansion mismatch can be made to play a
dominant role by modifying the substrate morphology. When grown on sapphire,
the lattice mismatch induces compressive strain in the V2O3 films, whereas
thermal expansion mismatch induces tensile strain. We find that minute changes
in substrate morphology may relax the compressive strain component, allowing
the thermally-induced tensile component to overcome it. Thus, by simple
annealing of the substrates to create either a flat or stepped morphology,
strongly compressive or tensile strains may be induced in the films. This
results in either full suppression of the metal-insulator transition or
stabilization of insulating phases at all temperatures, exhibiting many orders
of magnitude differences in film resistivity. To elucidate the strain
relaxation mechanism, we use high-resolution scanning transmission electron
microscopy (HRSTEM) to image the atomic steps in the substrate and the adjacent
crystallographic defects in the V2O3. These findings offer a hitherto
underexplored mechanism to tune strain in thin films, deepen our understanding
of the effects of structural degrees of freedom on phase stability of a
canonical Mott insulator and may allow for applications requiring
insulator-metal switching above room temperature.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [182] [The Steiner Path Aggregation Problem](https://arxiv.org/abs/2510.01392)
*Da Qi Chen,Daniel Hathcock,D Ellis Hershkowitz,R. Ravi*

Main category: cs.DS

TL;DR: 该研究提出了一种解决有向网络中 Steiner 路径聚合问题的方法，目标是将多条路径聚合到一棵以根节点为中心的树（arborescence）中，同时尽量减少路径颜色的切换次数。研究人员设计了一种高效算法，能够找到一种聚合方案，使得每个终端节点到根节点的路径颜色切换次数不超过 $2	ext{log}_{4/3}k$ 次，其中 $k$ 是终端节点的数量。此外，研究还证明了该算法在渐近意义下是最优的，因为存在图结构使得最少需要 $	ext{log}_2 k$ 次颜色切换。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在解决有向网络中的 Steiner 路径聚合问题，即在聚合多条路径到一个中心树结构时，如何最小化路径颜色切换的次数，以保持路径的“单色性”。

Method: 研究人员提出了一种高效算法，用于在给定的有向多重图中，为 $k$ 个终端节点找到一条到根节点的路径，并聚合这些路径形成一棵 arborescence。该算法能够将颜色切换次数的上界控制在 $2	ext{log}_{4/3}k$ 以内。

Result: 该算法找到的 arborescence 保证了每个终端节点到根节点的路径颜色切换次数至多为 $2	ext{log}_{4/3}k$。该结果被证明是渐近最优的，与需要至少 $	ext{log}_2 k$ 次颜色切换的图结构相吻合（忽略常数因子）。

Conclusion: 该研究成功地为 Steiner 路径聚合问题提供了一个高效且具有理论最优性的解决方案，该方案在聚合路径时能将颜色切换次数控制在对数级别，满足了不显著干扰路径颜色的要求。

Abstract: In the Steiner Path Aggregation Problem, our goal is to aggregate paths in a
directed network into a single arborescence without significantly disrupting
the paths. In particular, we are given a directed multigraph with colored arcs,
a root, and $k$ terminals, each of which has a monochromatic path to the root.
Our goal is to find an arborescence in which every terminal has a path to the
root, and its path does not switch colors too many times. We give an efficient
algorithm that finds such a solution with at most $2\log_{4/3}k$ color
switches. Up to constant factors this is the best possible universal bound, as
there are graphs requiring at least $\log_2 k$ color switches.

</details>


### [183] [Foremost, Fastest, Shortest: Temporal Graph Realization under Various Path Metrics](https://arxiv.org/abs/2510.01702)
*Justine Cauvi,Nils Morawietz,Laurent Viennot*

Main category: cs.DS

TL;DR: 本文研究了具有给定时间路径度量的时序图实现问题，并针对不同路径度量（最短路径、最早到达时间、最快路径）和图类型（周期性/非周期性、严格/非严格路径）进行了分析，得出了多项式时间算法和NP难结果。


<details>
  <summary>Details</summary>
Motivation: 研究当前时序图实现问题的发展趋势，即给定一个属性P，判断是否存在一个具有该属性的时序图。具体研究了当属性P为给定时间路径的持续时间、长度或最早到达时间矩阵时，是否存在满足这些条件的时序图。

Method: 分析了严格/非严格路径、周期性/非周期性时序图以及边标签数量限制等多种情况。通过设计算法和证明NP难来分析不同问题设置下的可解性。

Result: 对于最早到达时间路径，无论是在周期性/非周期性时序图还是严格/非严格路径下，都存在多项式时间算法。但当矩阵中的条目包含多个可能值时，问题变为NP难，但可以通过参数化算法解决。对于最快路径，得到了新的硬度结果。对于最短路径，周期性版本是多项式时间可解的，而非周期性版本是NP难的。

Conclusion: 证明了最早到达时间路径的时序图实现问题在多种设置下均可高效解决，但最短路径和最快路径问题在某些情况下具有挑战性（NP难或需要更复杂的算法）。

Abstract: In this work, we follow the current trend on temporal graph realization,
where one is given a property P and the goal is to determine whether there is a
temporal graph, that is, a graph where the edge set changes over time, with
property P . We consider the problems where as property P , we are given a
prescribed matrix for the duration, length, or earliest arrival time of
pairwise temporal paths. That is, we are given a matrix D and ask whether there
is a temporal graph such that for any ordered pair of vertices (s, t), Ds,t
equals the duration (length, or earliest arrival time, respectively) of any
temporal path from s to t minimizing that specific temporal path metric. For
shortest and earliest arrival temporal paths, we are the first to consider
these problems as far as we know. We analyze these problems for many settings
like: strict and non-strict paths, periodic and non-periodic temporal graphs,
and limited number of labels per edge (that is, limited occurrence number per
edge over time). In contrast to all other path metrics, we show that for the
earliest arrival times, we can achieve polynomial-time algorithms in periodic
and non-periodic temporal graphs and for strict and and non-strict paths.
However, the problem becomes NP-hard when the matrix does not contain a single
integer but a set or range of possible allowed values. As we show, the problem
can still be solved efficiently in this scenario, when the number of entries
with more than one value is small, that is, we develop an FPT-algorithm for the
number of such entries. For the setting of fastest paths, we achieve new
hardness results that answers an open question by Klobas, Mertzios, Molter, and
Spirakis [Theor. Comput. Sci. '25] about the parameterized complexity of the
problem with respect to the vertex cover number and significantly improves over
a previous hardness result for the feedback vertex set number. When considering
shortest paths, we show that the periodic versions are polynomial-time solvable
whereas the non-periodic versions become NP-hard.

</details>


### [184] [Improved $\ell_{p}$ Regression via Iteratively Reweighted Least Squares](https://arxiv.org/abs/2510.01729)
*Alina Ene,Ta Duy Nguyen,Adrian Vladu*

Main category: cs.DS

TL;DR: We present new, faster algorithms for solving $\ell_{p}$ regression problems using IRLS, achieving state-of-the-art iteration complexity and outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: The paper aims to bridge the gap between theoretical and practical algorithms for $\ell_{p}$ regression by developing faster IRLS-based algorithms.

Method: The proposed approach uses a primal-dual framework, deriving update rules from an invariant maintained for the dual objective. This results in a simpler, lightweight iterative scheme compared to prior complex algorithms.

Result: The new algorithms achieve state-of-the-art iteration complexity, matching theoretical bounds while being simpler than previous complex methods. Empirical results show significant performance improvements over existing IRLS and MATLAB/CVX implementations.

Conclusion: The paper successfully introduces faster and simpler algorithms for $\ell_{p}$ regression that are both theoretically sound and practically efficient, outperforming current state-of-the-art methods.

Abstract: We introduce fast algorithms for solving $\ell_{p}$ regression problems using
the iteratively reweighted least squares (IRLS) method. Our approach achieves
state-of-the-art iteration complexity, outperforming the IRLS algorithm by
Adil-Peng-Sachdeva (NeurIPS 2019) and matching the theoretical bounds
established by the complex algorithm of Adil-Kyng-Peng-Sachdeva (SODA 2019, J.
ACM 2024) via a simpler lightweight iterative scheme. This bridges the existing
gap between theoretical and practical algorithms for $\ell_{p}$ regression. Our
algorithms depart from prior approaches, using a primal-dual framework, in
which the update rule can be naturally derived from an invariant maintained for
the dual objective. Empirically, we show that our algorithms significantly
outperform both the IRLS algorithm by Adil-Peng-Sachdeva and MATLAB/CVX
implementations.

</details>


### [185] [Short circuit walks in fixed dimension](https://arxiv.org/abs/2510.01916)
*Alexander E. Black,Christian Nöbel,Raphael Steiner*

Main category: cs.DS

TL;DR: 电路增强方案是线性规划的组合算法，用于寻找最优解。本文证明了在多边形上近似最短单调电路行走（用于求解线性规划）在多项式时间内是NP-hard的，近似因子为 O(m^{1-	ext{ε}})，其中 m 是多边形的边数。


<details>
  <summary>Details</summary>
Motivation: 由于最短单调电路行走的存在已被猜想（电路直径猜想），因此研究如何有效近似最短单调电路行走以找到最优解具有重要意义。

Method: 本文通过证明在多边形上近似最短单调电路行走（用于求解线性规划）是NP-hard的，为现有最坏情况下的近似方案提供了更强的硬度结果。具体来说，对于任意给定的 ε > 0，在具有 m 条边的多边形上以 O(m^{1-	ext{ε}}) 的因子近似该问题的难度是 NP-hard 的。

Result: 本文证明了在多边形上近似最短单调电路行走（用于求解线性规划）在多项式时间内是NP-hard的，近似因子为 O(m^{1-	ext{ε}})，其中 m 是多边形的边数。

Conclusion: 本文证明了在多边形上近似最短单调电路行走（用于求解线性规划）在多项式时间内是NP-hard的，近似因子为 O(m^{1-	ext{ε}})，其中 m 是多边形的边数。这一结果基本上是最佳的，因为无法超越 o(m) 的近似因子。

Abstract: Circuit augmentation schemes are a family of combinatorial algorithms for
linear programming that generalize the simplex method. To solve the linear
program, they construct a so-called monotone circuit walk: They start at an
initial vertex of the feasible region and traverse a discrete sequence of
points on the boundary, while moving along certain allowed directions
(circuits) and improving the objective function at each step until reaching an
optimum. Since the existence of short circuit walks has been conjectured
(Circuit Diameter Conjecture), several works have investigated how well one can
efficiently approximate shortest monotone circuit walks towards an optimum. A
first result addressing this question was given by De Loera, Kafer, and
Sanit\`a [SIAM J. Opt., 2022], who showed that given as input an LP and the
starting vertex, finding a $2$-approximation for this problem is NP-hard.
Cardinal and the third author [Math. Prog. 2023] gave a stronger lower bound
assuming the exponential time hypothesis, showing that even an approximation
factor of $O(\frac{\log m}{\log \log m})$ is intractable for LPs defined by $m$
inequalities. Both of these results were based on reductions from highly
degenerate polytopes in combinatorial optimization with high dimension.
  In this paper, we significantly strengthen the aforementioned hardness
results by showing that for every fixed $\varepsilon>0$ approximating the
problem on polygons with $m$ edges to within a factor of $O(m^{1-\varepsilon})$
is NP-hard. This result is essentially best-possible, as it cannot be improved
beyond $o(m)$. In particular, this implies hardness for simple polytopes and in
fixed dimension.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [186] [Learning to Play Multi-Follower Bayesian Stackelberg Games](https://arxiv.org/abs/2510.01387)
*Gerson Personnat,Tao Lin,Safwan Hossain,David C. Parkes*

Main category: cs.GT

TL;DR: In a multi-follower Bayesian Stackelberg game, we develop online learning algorithms for a leader to minimize regret under different feedback settings (type and action feedback). The algorithms achieve sublinear regret bounds that do not grow polynomially with the number of followers.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the challenge of a leader learning to play optimally in a multi-follower Bayesian Stackelberg game where follower types are unknown and change over time. The goal is to minimize regret, which is the difference between the optimal strategy

Method: The paper designs and analyzes online learning algorithms for the leader. For type feedback, algorithms achieve $\mathcal O\big(\sqrt{\min\{L\log(nKA T), nK \} \cdot T} \big)$ regret for independent type distributions and $\mathcal O\big(\sqrt{\min\{L\log(nKA T), K^n \} \cdot T} \big)$ regret for general type distributions. For action feedback, algorithms achieve $\mathcal O( \min\{\sqrt{ n^L K^L A^{2L} L T \log T}, K^n\sqrt{ T } \log T \} )$ regret. A lower bound of $\Omega(\sqrt{\min\{L, nK\}T})$ is also provided.

Result: The proposed algorithms achieve sublinear regret bounds under both type and action feedback. Specifically, the type feedback bounds do not grow polynomially with the number of followers ($n$). The action feedback bounds are also established. A lower bound is provided that nearly matches the type-feedback upper bounds.

Conclusion: The paper presents effective online learning algorithms for a leader in a Bayesian Stackelberg game with unknown follower types, offering competitive regret bounds under various feedback scenarios and highlighting that the dependence on the number of followers can be significantly mitigated.

Abstract: In a multi-follower Bayesian Stackelberg game, a leader plays a mixed
strategy over $L$ actions to which $n\ge 1$ followers, each having one of $K$
possible private types, best respond. The leader's optimal strategy depends on
the distribution of the followers' private types. We study an online learning
version of this problem: a leader interacts for $T$ rounds with $n$ followers
with types sampled from an unknown distribution every round. The leader's goal
is to minimize regret, defined as the difference between the cumulative utility
of the optimal strategy and that of the actually chosen strategies. We design
learning algorithms for the leader under different feedback settings. Under
type feedback, where the leader observes the followers' types after each round,
we design algorithms that achieve $\mathcal O\big(\sqrt{\min\{L\log(nKA T), nK
\} \cdot T} \big)$ regret for independent type distributions and $\mathcal
O\big(\sqrt{\min\{L\log(nKA T), K^n \} \cdot T} \big)$ regret for general type
distributions. Interestingly, those bounds do not grow with $n$ at a polynomial
rate. Under action feedback, where the leader only observes the followers'
actions, we design algorithms with $\mathcal O( \min\{\sqrt{ n^L K^L A^{2L} L T
\log T}, K^n\sqrt{ T } \log T \} )$ regret. We also provide a lower bound of
$\Omega(\sqrt{\min\{L, nK\}T})$, almost matching the type-feedback upper
bounds.

</details>


### [187] [Designing Inferable Signaling Schemes for Bayesian Persuasion](https://arxiv.org/abs/2510.01434)
*Caleb Probine,Mustafa O. Karabag,Ufuk Topcu*

Main category: cs.GT

TL;DR: 接收者在重复交互中推断信号方案，而非经典模型中的已知承诺。


<details>
  <summary>Details</summary>
Motivation: 研究接收者从重复交互中推断信号方案的贝叶斯说服设置，而非经典模型中的已知承诺。

Method: 通过分析信号空间大小和接收者最优行动区分度来约束发送者性能损失，并给出发明信号方案的样本需求下界。提出两种设计可推断信号方案的方法：基于发送者效用函数的随机梯度下降（SGD）和考虑有限理性接收者模型的优化方法。

Result: SGD在低交互场景下表现最佳，而有限理性接收者模型提供了一种灵活的方法。在安全警报示例中，SGD找到比已知承诺情况信号更少、最优行动更易区分的方案。

Conclusion: 在接收者从重复交互中推断信号方案的设置下，推断所带来的成本可以通过方法和模型来缓解，但仍比领导-追随者博弈需要更多的样本。

Abstract: In Bayesian persuasion, an informed sender, who observes a state, commits to
a randomized signaling scheme that guides a self-interested receiver's actions.
Classical models assume the receiver knows the commitment. We, instead, study
the setting where the receiver infers the scheme from repeated interactions. We
bound the sender's performance loss relative to the known-commitment case by a
term that grows with the signal space size and shrinks as the receiver's
optimal actions become more distinct. We then lower bound the samples required
for the sender to approximately achieve their known-commitment performance in
the inference setting. We show that the sender requires more samples in
persuasion compared to the leader in a Stackelberg game, which includes
commitment but lacks signaling. Motivated by these bounds, we propose two
methods for designing inferable signaling schemes, one being stochastic
gradient descent (SGD) on the sender's inference-setting utility, and the other
being optimization with a boundedly-rational receiver model. SGD performs best
in low-interaction regimes, but modeling the receiver as boundedly-rational and
tuning the rationality constant still provides a flexible method for designing
inferable schemes. Finally, we apply SGD to a safety alert example and show it
to find schemes that have fewer signals and make citizens' optimal actions more
distinct compared to the known-commitment case.

</details>


### [188] [Incentive Analysis of Collusion in Fair Division](https://arxiv.org/abs/2510.01689)
*Haoqiang Huang,Biaoshuai Tao,Mingwei Yang,Shengwei Zhou*

Main category: cs.GT

TL;DR: 本研究定义了强群体激励比（SGIR）和群体激励比（GIR）来衡量代理人合谋操纵的收益，并分析了最大纳什福利（MNW）、概率序列（PS）和轮转法（RR）这三种机制的SGIR和GIR。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索代理人合谋操纵对公平分配机制的影响，以量化这种操纵可能带来的收益。

Method: 定义了强群体激励比（SGIR）和群体激励比（GIR），并分析了最大纳什福利（MNW）、概率序列（PS）和轮转法（RR）在不同合谋规模下的SGIR和GIR。

Result: MNW的GIR为2，不受合谋规模影响。MNW和PS的SGIR，以及PS和RR的GIR，在合谋规模c≥1时为c+1。RR的SGIR在合谋规模c≥2时无界。

Conclusion: MNW、PS和RR在易受合谋操纵方面存在显著差异，其中RR机制在面对较大规模合谋时尤其脆弱。

Abstract: We study fair division problems with strategic agents capable of gaining
advantages by manipulating their reported preferences. Although several
impossibility results have revealed the incompatibility of truthfulness with
standard fairness criteria, subsequent works have circumvented this limitation
through the incentive ratio framework. Previous studies demonstrate that
fundamental mechanisms like Maximum Nash Welfare (MNW) and Probabilistic Serial
(PS) for divisible goods, and Round-Robin (RR) for indivisible goods achieve an
incentive ratio of $2$, implying that no individual agent can gain more than
double his truthful utility through manipulation. However, collusive
manipulation by agent groups remains unexplored.
  In this work, we define strong group incentive ratio (SGIR) and group
incentive ratio (GIR) to measure the gain of collusive manipulation, where SGIR
and GIR are respectively the maximum and minimum of the incentive ratios of
corrupted agents. Then, we tightly characterize the SGIRs and GIRs of MNW, PS,
and RR. In particular, the GIR of MNW is $2$ regardless of the coalition size.
Moreover, for coalition size $c \geq 1$, the SGIRs of MNW and PS, and the GIRs
of PS and RR are $c + 1$. Finally, the SGIR of RR is unbounded for coalition
size $c \geq 2$. Our results reveal fundamental differences of these three
mechanisms in their vulnerability to collusion.

</details>


### [189] [A Linear Programming Approach to Estimate the Core in Cooperative Games](https://arxiv.org/abs/2510.01766)
*J Camacho,JC Gonçalves-Dosantos,J Sánchez-Soriano*

Main category: cs.GT

TL;DR: 该论文提出一种通过线性规划近似可转让效用 (TU) 合作博弈核心的新算法，通过抽样极端点来解决计算难题，并通过模拟验证了其可扩展性和准确性。


<details>
  <summary>Details</summary>
Motivation: 计算确定合作博弈核心具有挑战性，因此需要一种可行的近似方法。

Method: 通过抽样极端点，利用随机线性规划 (LPs) 来近似合作博弈的核心。

Result: 该方法具有可扩展性，并且在核心重建方面实现了高精度，正如广泛的模拟所示。

Conclusion: 所提出的算法为近似合作博弈的核心提供了一种可扩展且准确的方法。

Abstract: This paper proposes a novel algorithm to approximate the core of transferable
utility (TU) cooperative games via linear programming. Given the computational
hardness of determining the full core, our approach provides a tractable
approximation by sampling extreme points through randomized linear problems
(LPs). We analyze its convergence and computational complexity, and validate
its effectiveness through extensive simulations on various game models. Our
results show that the method is scalable and achieves high accuracy in terms of
core reconstruction.

</details>


### [190] [Multi-group Bayesian Games](https://arxiv.org/abs/2510.02078)
*Hongxing Yuan,Xuan Zhang,Chunyu Wei,Yushun Fan*

Main category: cs.GT

TL;DR: 该论文提出了多群体贝叶斯博弈（MBGs）模型，并给出了寻找（强）多群体贝叶斯纳什均衡（MBNE）的方法，通过将MBG转化为多群体事前智能体博弈（MEAG）。MBNE代表合作博弈中的最优策略组合，而强MBNE代表非合作博弈中的最优策略组合。论文还给出了MEAG为（强）势博弈的充要条件，并提供了寻找（强）MBNE的算法，最后通过算例验证了结果的正确性。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在为描述群体行为在贝叶斯博弈中的表现提供一个清晰的模型，并开发有效的方法来计算（强）多群体贝叶斯纳什均衡（MBNE）。

Method: 首先，提出了多群体贝叶斯博弈（MBGs）模型，并设计了一种转换方法将其转化为一个规范形式的多群体事前智能体博弈（MEAG）。接着，推导了MBG的MEAG成为（强）势博弈的充要条件。如果满足该条件，则可以通过寻找MEAG的（强）纳什均衡来获得MBG的（强）MBNE。

Result: 通过将MBG转化为MEAG，并利用势博弈的性质，论文提供了寻找（强）MBNE的算法。算例验证了该方法的有效性。

Conclusion: 该研究成功地提出了MBGs模型和求解（强）MBNE的方法，该方法依赖于将问题转化为MEAG并利用势博弈的特性，并通过算例得到了验证。

Abstract: This paper presents a model of multi-group Bayesian games (MBGs) to describe
the group behavior in Bayesian games, and gives methods to find (strongly)
multi-group Bayesian Nash equilibria (MBNE) of this model with a proposed
transformation. MBNE represent the optimal strategy \textit{profiles} under the
situation where players within a group play a cooperative game, while strongly
MBNE characterize the optimal strategy \textit{profiles} under the situation
where players within a group play a noncooperative game. Firstly, we propose a
model of MBGs and give a transformation to convert any MBG into a multi-group
ex-ante agent game (MEAG) which is a normal-form game. Secondly, we give a
sufficient and necessary condition for a MBG's MEAG to be (strongly) potential.
If it is (strongly) potential, all its (strongly) Nash equilibria can be found,
and then all (strongly) MBNE of the MBG can be obtained by leveraging the
transformation's good properties. Finally, we provide algorithms for finding
(strongly) MBNE of a MBG whose MEAG is (strongly) potential and use an
illustrative example to verify the correctness of our results.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [191] [OR-Toolformer: Modeling and Solving Operations Research Problems with Tool Augmented Large Language Models](https://arxiv.org/abs/2510.01253)
*Jianzhang Zhang,Jialong Zhou,Chuang Liu*

Main category: cs.AI

TL;DR: OR-Toolformer通过结合Llama-3.1-8B-Instruct模型和外部求解器，在运筹学（OR）任务上取得了显著的准确性和泛化能力，解决了闭源模型带来的隐私问题和从头训练的成本问题。


<details>
  <summary>Details</summary>
Motivation: 由于闭源模型在运筹学（OR）任务中的隐私问题以及从头训练开源模型的计算成本高昂，因此需要一种新的方法来解决OR问题。

Method: 通过半自动化的数据合成流程，为Llama-3.1-8B-Instruct模型生成多样化的OR问题-答案对，并增强模型调用外部求解器的能力，从而创建了OR-Toolformer。

Result: OR-Toolformer在四个标准基准测试中的三个上达到了80.1%的执行准确率，超过了同等规模的基线模型4.3%以上。在两种未见过的OR问题类型上的零样本评估中，平均准确率达到了54%，比最强的基线模型高出21个百分点。

Conclusion: 使用工具增强的微调方法能够有效地训练出能够进行准确且可泛化的OR问题建模和求解的大语言模型。

Abstract: Large language models (LLMs) demonstrate strong mathematical reasoning, but
reliance on closed-source APIs for OR tasks raises privacy concerns, and
training open-source models from scratch incurs high compute costs. We
introduce OR-Toolformer, which fine-tunes Llama-3.1-8B-Instruct with a
semi-automatic data synthesis pipeline that generates diverse OR problem-answer
pairs and augments the model with external solvers to produce API calls. On
three of four standard benchmarks, OR-Toolformer achieves up to 80.1% execution
accuracy, exceeding size-matched baselines by over 4.3%. In zero-shot
evaluation on two unseen OR problem types, it attains 54% average accuracy, a
21 percentage-point improvement over the strongest baseline. These findings
validate the efficacy of tool-augmented fine-tuning LLMs for accurate and
generalizable OR problem modeling and solving.

</details>


### [192] [Zero-shot reasoning for simulating scholarly peer-review](https://arxiv.org/abs/2510.02027)
*Khalid M. Saqr*

Main category: cs.AI

TL;DR: 科学出版界面临投稿量激增和人工智能监管缺失的双重危机，亟需新的治理模式以维护科学诚信。本研究提出了一个确定性模拟框架，为评估人工智能生成的同行评审报告提供了首个稳定、基于证据的标准。通过分析352份模拟报告，我们发现了能够证明其可靠性的系统状态指标。该系统能模拟校准后的编辑判断，‘修改’决定在所有学科中占多数（>50%），而‘拒绝’率能根据学科规范动态调整（健康科学中高达45%）。同时，系统保持了稳定的程序完整性，证据锚定合规率为29%，且在不同评审任务和科学领域中保持不变。这表明该系统可预测且受规则约束，降低了生成式人工智能的随机性。该框架为科学界提供了透明的公平性保障工具，为出版策略家提供了审计工作流、管理诚信风险和实施基于证据的治理的可扩展工具，并将人工智能定位为机构问责制的重要组成部分，为维护学术交流的信任提供了关键基础设施。


<details>
  <summary>Details</summary>
Motivation: 科学出版界面临投稿量激增和人工智能监管缺失的双重危机，亟需新的治理模式来维护科学诚信。传统的人工同行评审缺乏可扩展、客观的标准，导致编辑流程不透明且难以审计。

Method: 研究人员调查了一个确定性模拟框架，该框架旨在为评估人工智能生成的同行评审报告提供一个稳定、基于证据的标准。他们分析了352份同行评审模拟报告，以识别一致的系统状态指标来证明其可靠性。

Result: 分析显示，该模拟系统能够模拟校准后的编辑判断，其中“修改”决定在所有学科中持续占多数（超过50%）；“拒绝”率则能根据学科规范动态调整，在健康科学领域达到45%。此外，该系统保持了稳定的程序完整性，证据锚定合规率为29%，在不同的评审任务和科学领域中保持不变，表明其可预测且受规则约束，能够缓解生成式人工智能的随机性。

Conclusion: 该确定性模拟框架为科学界提供了一个透明的工具来确保公平性，为出版策略家提供了一个可扩展的工具来审计工作流程、管理诚信风险和实施基于证据的治理。该框架将人工智能定位为机构问责制的一个组成部分，为维护学术交流的信任提供了关键基础设施。

Abstract: The scholarly publishing ecosystem faces a dual crisis of unmanageable
submission volumes and unregulated AI, creating an urgent need for new
governance models to safeguard scientific integrity. The traditional human-only
peer review regime lacks a scalable, objective benchmark, making editorial
processes opaque and difficult to audit. Here we investigate a deterministic
simulation framework that provides the first stable, evidence-based standard
for evaluating AI-generated peer review reports. Analyzing 352 peer-review
simulation reports, we identify consistent system state indicators that
demonstrate its reliability. First, the system is able to simulate calibrated
editorial judgment, with 'Revise' decisions consistently forming the majority
outcome (>50%) across all disciplines, while 'Reject' rates dynamically adapt
to field-specific norms, rising to 45% in Health Sciences. Second, it maintains
unwavering procedural integrity, enforcing a stable 29% evidence-anchoring
compliance rate that remains invariant across diverse review tasks and
scientific domains. These findings demonstrate a system that is predictably
rule-bound, mitigating the stochasticity of generative AI. For the scientific
community, this provides a transparent tool to ensure fairness; for publishing
strategists, it offers a scalable instrument for auditing workflows, managing
integrity risks, and implementing evidence-based governance. The framework
repositions AI as an essential component of institutional accountability,
providing the critical infrastructure to maintain trust in scholarly
communication.

</details>


### [193] [Modeling Others' Minds as Code](https://arxiv.org/abs/2510.01272)
*Kunal Jha,Aydan Yuenan Huang,Eric Ye,Natasha Jaques,Max Kleiman-Weiner*

Main category: cs.AI

TL;DR: 现有方法在预测人类行为时存在数据需求大、假设不合理或计算成本高的问题。本文提出ROTE算法，通过将日常社交互动视为可预测的行为程序，并结合大语言模型和概率推理，在多个任务中显著优于现有方法，提高了预测精度和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在预测人类行为时存在数据需求大、假设不合理或计算成本高的问题，无法满足鲁棒和安全的人机协作需求。

Method: 提出将日常社交互动建模为行为程序（类似于计算机代码），而非基于信念和欲望的策略。利用大语言模型生成行为程序假设空间，并结合概率推理来处理不确定性，提出ROTE算法。

Result: ROTE算法在网格世界任务和大型家庭模拟器中，能够从稀疏的观测数据中预测人类和AI的行为，其样本内准确率和样本外泛化能力比行为克隆和基于大语言模型的方法高出50%。

Conclusion: 将动作理解视为程序合成问题，ROTE为AI系统提供了有效预测现实世界中人类行为的新途径。

Abstract: Accurate prediction of human behavior is essential for robust and safe
human-AI collaboration. However, existing approaches for modeling people are
often data-hungry and brittle because they either make unrealistic assumptions
about rationality or are too computationally demanding to adapt rapidly. Our
key insight is that many everyday social interactions may follow predictable
patterns; efficient "scripts" that minimize cognitive load for actors and
observers, e.g., "wait for the green light, then go." We propose modeling these
routines as behavioral programs instantiated in computer code rather than
policies conditioned on beliefs and desires. We introduce ROTE, a novel
algorithm that leverages both large language models (LLMs) for synthesizing a
hypothesis space of behavioral programs, and probabilistic inference for
reasoning about uncertainty over that space. We test ROTE in a suite of
gridworld tasks and a large-scale embodied household simulator. ROTE predicts
human and AI behaviors from sparse observations, outperforming competitive
baselines -- including behavior cloning and LLM-based methods -- by as much as
50% in terms of in-sample accuracy and out-of-sample generalization. By
treating action understanding as a program synthesis problem, ROTE opens a path
for AI systems to efficiently and effectively predict human behavior in the
real-world.

</details>


### [194] [The Social Laboratory: A Psychometric Framework for Multi-Agent LLM Evaluation](https://arxiv.org/abs/2510.01295)
*Zarreen Reza*

Main category: cs.AI

TL;DR: LLM智能体之间的多轮辩论可以作为一种评估框架，用于探索和量化它们在互动环境中的社会和认知动态。


<details>
  <summary>Details</summary>
Motivation: 传统的LLM评估基准不足以捕捉智能体之间的沟通、说服和协作等新兴的社会和认知动态。

Method: 引入了一个新颖的评估框架，使用多轮辩论作为受控的“社会实验室”，以发现和量化这些行为。LLM智能体被赋予不同的角色和激励，在一个LLM主持人的监督下，就一系列具有挑战性的话题进行辩论。

Result: 在数百场辩论中，智能体表现出强大的寻求共识的倾向，即使在没有明确指示的情况下，在敏感话题上也能达到高度的语义一致性（μ > 0.88）。分配的角色会产生稳定的、可衡量的心理测量特征，特别是在认知努力方面。主持人的角色可以通过构建环境来显著改变辩论结果。

Conclusion: 该研究提供了一个新的、基于心理测量学的动态评估协议的蓝图，用于智能体环境，为理解和塑造下一代AI智能体的社会行为提供了关键方法。

Abstract: As Large Language Models (LLMs) transition from static tools to autonomous
agents, traditional evaluation benchmarks that measure performance on
downstream tasks are becoming insufficient. These methods fail to capture the
emergent social and cognitive dynamics that arise when agents communicate,
persuade, and collaborate in interactive environments. To address this gap, we
introduce a novel evaluation framework that uses multi-agent debate as a
controlled "social laboratory" to discover and quantify these behaviors. In our
framework, LLM-based agents, instantiated with distinct personas and
incentives, deliberate on a wide range of challenging topics under the
supervision of an LLM moderator. Our analysis, enabled by a new suite of
psychometric and semantic metrics, reveals several key findings. Across
hundreds of debates, we uncover a powerful and robust emergent tendency for
agents to seek consensus, consistently reaching high semantic agreement ({\mu}
> 0.88) even without explicit instruction and across sensitive topics. We show
that assigned personas induce stable, measurable psychometric profiles,
particularly in cognitive effort, and that the moderators persona can
significantly alter debate outcomes by structuring the environment, a key
finding for external AI alignment. This work provides a blueprint for a new
class of dynamic, psychometrically grounded evaluation protocols designed for
the agentic setting, offering a crucial methodology for understanding and
shaping the social behaviors of the next generation of AI agents. We have
released the code and results at
https://github.com/znreza/multi-agent-LLM-eval-for-debate.

</details>


### [195] [Cyber Academia-Chemical Engineering (CA-ChemE): A Living Digital Town for Self-Directed Research Evolution and Emergent Scientific Discovery](https://arxiv.org/abs/2510.01293)
*Zekun Jiang,Chunming Xu,Tianhang Zhou*

Main category: cs.AI

TL;DR: CA-ChemE系统通过多智能体协作促进了化学工程领域的自主科学发现。


<details>
  <summary>Details</summary>
Motivation: 现有AI系统在跨学科协作和探索未知问题方面存在局限性，需要更强大的AI系统来推动化学工程领域的发展。

Method: 提出了CA-ChemE系统，一个包含领域知识库、知识增强技术和协作智能体的数字城镇，实现了多智能体协作和自主研究进化。

Result: 知识库增强机制平均提高了7个专家智能体的对话质量评分10-15%；协作智能体（CA）在跨领域协作效率上取得了8.5%的提升，揭示了“知识库差距导致的协作效率降低”效应。

Conclusion: 精心设计的CA-ChemE多智能体架构为化学工程领域的自主科学发现提供了可行途径。

Abstract: The rapid advancement of artificial intelligence (AI) has demonstrated
substantial potential in chemical engineering, yet existing AI systems remain
limited in interdisciplinary collaboration and exploration of uncharted
problems. To address these issues, we present the Cyber Academia-Chemical
Engineering (CA-ChemE) system, a living digital town that enables self-directed
research evolution and emergent scientific discovery through multi-agent
collaboration. By integrating domain-specific knowledge bases, knowledge
enhancement technologies, and collaboration agents, the system successfully
constructs an intelligent ecosystem capable of deep professional reasoning and
efficient interdisciplinary collaboration. Our findings demonstrate that
knowledge base-enabled enhancement mechanisms improved dialogue quality scores
by 10-15% on average across all seven expert agents, fundamentally ensuring
technical judgments are grounded in verifiable scientific evidence. However, we
observed a critical bottleneck in cross-domain collaboration efficiency,
prompting the introduction of a Collaboration Agent (CA) equipped with ontology
engineering capabilities. CA's intervention achieved 8.5% improvements for
distant-domain expert pairs compared to only 0.8% for domain-proximate pairs -
a 10.6-fold difference - unveiling the "diminished collaborative efficiency
caused by knowledge-base gaps" effect. This study demonstrates how carefully
designed multi-agent architectures can provide a viable pathway toward
autonomous scientific discovery in chemical engineering.

</details>


### [196] [Agentic Jigsaw Interaction Learning for Enhancing Visual Perception and Reasoning in Vision-Language Models](https://arxiv.org/abs/2510.01304)
*Yu Zeng,Wenxuan Huang,Shiting Huang,Xikun Bao,Yukun Qi,Yiming Zhao,Qiuchen Wang,Lin Chen,Zehui Chen,Huaian Chen,Wanli Ouyang,Feng Zhao*

Main category: cs.AI

TL;DR: AGILE通过将拼图解决视为一个互动过程，利用环境提供的细粒度视觉反馈来逐步提高大型视觉语言模型（VLMs）的感知和推理能力，显著提升了拼图任务的性能，并在其他视觉任务上展现了良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的大型视觉语言模型（VLMs）在基础感知和推理能力方面存在局限性，即使在简单的拼图任务上也表现不佳，而高质量的视觉语言数据稀缺且难以扩展。

Method: AGILE将拼图解决设计为一个互动过程，模型通过生成可执行代码与环境互动，并根据环境提供的视觉反馈进行学习，从而迭代地改进其感知和推理能力。

Result: AGILE在不同复杂度的拼图任务上显著提高了性能（例如，在2x2设置下准确率从9.5%提高到82.8%），并在9个通用视觉任务上实现了3.1%的平均性能提升，展现了良好的泛化能力。

Conclusion: AGILE有效地提升了VLMs的感知和推理能力，为提高多模态模型的推理和泛化能力开辟了新途径，并解决了多模态强化学习数据稀缺的问题。

Abstract: Although current large Vision-Language Models (VLMs) have advanced in
multimodal understanding and reasoning, their fundamental perceptual and
reasoning abilities remain limited. Specifically, even on simple jigsaw tasks,
existing VLMs perform near randomly, revealing deficiencies in core perception
and reasoning capabilities. While high-quality vision-language data can enhance
these capabilities, its scarcity and limited scalability impose significant
constraints. To address this, we propose AGILE, an Agentic jiGsaw Interaction
Learning for Enhancing visual perception and reasoning in VLMs. AGILE
formulates jigsaw solving as an interactive process, enabling the model to
progressively engage with the environment. At each step, the model generates
executable code to perform an action based on the current state, while the
environment provides fine-grained visual feedback to guide task completion.
Through this iterative cycle of observation and interaction, the model
incrementally improves its perceptual and reasoning capabilities via
exploration and feedback. Experimental results show that AGILE not only
substantially boosts performance on jigsaw tasks of varying complexity (e.g.,
increasing accuracy from 9.5% to 82.8% under the 2 $\times$ 2 setting) but also
demonstrates strong generalization across 9 general vision tasks, achieving an
average improvement of 3.1%. These results indicate notable enhancements in
both perceptual and reasoning abilities. This work opens a new avenue for
advancing reasoning and generalization in multimodal models and provides an
efficient, scalable solution to the scarcity of multimodal reinforcement
learning data. The code and datasets is available at
https://github.com/yuzeng0-0/AGILE .

</details>


### [197] [To Mask or to Mirror: Human-AI Alignment in Collective Reasoning](https://arxiv.org/abs/2510.01924)
*Crystal Qian,Aaron Parisi,Clémentine Bouleau,Vivian Tsai,Maël Lebreton,Lucas Dixon*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: As large language models (LLMs) are increasingly used to model and augment
collective decision-making, it is critical to examine their alignment with
human social reasoning. We present an empirical framework for assessing
collective alignment, in contrast to prior work on the individual level. Using
the Lost at Sea social psychology task, we conduct a large-scale online
experiment (N=748), randomly assigning groups to leader elections with either
visible demographic attributes (e.g. name, gender) or pseudonymous aliases. We
then simulate matched LLM groups conditioned on the human data, benchmarking
Gemini 2.5, GPT 4.1, Claude Haiku 3.5, and Gemma 3. LLM behaviors diverge: some
mirror human biases; others mask these biases and attempt to compensate for
them. We empirically demonstrate that human-AI alignment in collective
reasoning depends on context, cues, and model-specific inductive biases.
Understanding how LLMs align with collective human behavior is critical to
advancing socially-aligned AI, and demands dynamic benchmarks that capture the
complexities of collective reasoning.

</details>


### [198] [Aristotle: IMO-level Automated Theorem Proving](https://arxiv.org/abs/2510.01346)
*Tudor Achim,Alex Best,Kevin Der,Mathïs Fédérico,Sergei Gukov,Daniel Halpern-Leister,Kirsten Henningsgard,Yury Kudryashov,Alexander Meiburg,Martin Michelsen,Riley Patterson,Eric Rodriguez,Laura Scharff,Vikram Shanker,Vladmir Sicca,Hari Sowrirajan,Aidan Swope,Matyas Tamas,Vlad Tenev,Jonathan Thomm,Harold Williams,Lawrence Wu*

Main category: cs.AI

TL;DR: 该论文介绍了一个名为Aristotle的人工智能系统，该系统结合了形式验证和非形式推理，在2025年国际数学奥林匹克竞赛中达到了与金牌同等水平的性能。


<details>
  <summary>Details</summary>
Motivation: 介绍Aristotle系统，一个结合形式验证和非形式推理的AI系统，旨在解决数学竞赛问题。

Method: Aristotle系统集成了三个主要部分：一个Lean证明搜索系统，一个生成和形式化引理的非形式推理系统，以及一个专门的几何求解器。

Result: 该系统在2025年国际数学奥林匹克竞赛问题上取得了与金牌同等水平的性能，并展示了在自动定理证明方面的最先进性能和良好的可扩展性。

Conclusion: Aristotle系统在结合形式验证和非形式推理方面取得了成功，并在数学竞赛问题上展示了卓越的性能。

Abstract: We introduce Aristotle, an AI system that combines formal verification with
informal reasoning, achieving gold-medal-equivalent performance on the 2025
International Mathematical Olympiad problems. Aristotle integrates three main
components: a Lean proof search system, an informal reasoning system that
generates and formalizes lemmas, and a dedicated geometry solver. Our system
demonstrates state-of-the-art performance with favorable scaling properties for
automated theorem proving.

</details>


### [199] [MEMTRACK: Evaluating Long-Term Memory and State Tracking in Multi-Platform Dynamic Agent Environments](https://arxiv.org/abs/2510.01353)
*Darshan Deshpande,Varun Gangal,Hersh Mehta,Anand Kannappan,Rebecca Qian,Peng Wang*

Main category: cs.AI

TL;DR: MEMTRACK是一个在多平台代理环境中评估长期记忆和状态跟踪的基准，它模拟了现实世界的组织工作流程，并通过手动设计和基于代理的合成来创建数据集。


<details>
  <summary>Details</summary>
Motivation: 现有的上下文和记忆基准主要集中在对话实例，但为了在动态的企业环境有效应用，评估记忆能力至关重要。

Method: MEMTRACK通过整合Slack、Linear和Git等多个通信和生产力平台中的异步事件来模拟组织工作流程。它生成包含跨平台交错时间线、噪音、冲突、交叉引用信息以及代码库/文件系统理解和探索的基准实例，从而测试记忆的获取、选择和冲突解决能力。数据集通过专家驱动的手动设计和基于代理的可扩展合成进行策.。

Result: 在MEMTRACK基准上，包括GPT-5在内的最先进的语言模型和记忆后端在利用长期记忆、处理跨平台依赖关系和解决矛盾方面面临挑战，其中最佳GPT-5模型仅达到60%的正确率。

Conclusion: MEMTRACK提供了一个可扩展的框架，用于在复杂的组织环境中推进记忆增强代理的评估研究，超越了现有的仅限于对话的设置，并为多代理、多平台记忆基准测试奠定了基础。

Abstract: Recent works on context and memory benchmarking have primarily focused on
conversational instances but the need for evaluating memory in dynamic
enterprise environments is crucial for its effective application. We introduce
MEMTRACK, a benchmark designed to evaluate long-term memory and state tracking
in multi-platform agent environments. MEMTRACK models realistic organizational
workflows by integrating asynchronous events across multiple communication and
productivity platforms such as Slack, Linear and Git. Each benchmark instance
provides a chronologically platform-interleaved timeline, with noisy,
conflicting, cross-referring information as well as potential
codebase/file-system comprehension and exploration. Consequently, our benchmark
tests memory capabilities such as acquistion, selection and conflict
resolution. We curate the MEMTRACK dataset through both manual expert driven
design and scalable agent based synthesis, generating ecologically valid
scenarios grounded in real world software development processes. We introduce
pertinent metrics for Correctness, Efficiency, and Redundancy that capture the
effectiveness of memory mechanisms beyond simple QA performance. Experiments
across SoTA LLMs and memory backends reveal challenges in utilizing memory
across long horizons, handling cross-platform dependencies, and resolving
contradictions. Notably, the best performing GPT-5 model only achieves a 60\%
Correctness score on MEMTRACK. This work provides an extensible framework for
advancing evaluation research for memory-augmented agents, beyond existing
focus on conversational setups, and sets the stage for multi-agent,
multi-platform memory benchmarking in complex organizational settings

</details>


### [200] [Retrieval-Augmented Framework for LLM-Based Clinical Decision Support](https://arxiv.org/abs/2510.01363)
*Leon Garza,Anantaa Kotal,Michael A. Grasso,Emre Umucu*

Main category: cs.AI

TL;DR: 该论文提出一个由大语言模型（LLM）驱动的临床决策支持系统，通过分析电子健康记录（EHR）数据，为临床医生提供治疗建议，旨在增强而非取代临床判断。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录（EHR）的快速扩展和临床决策复杂性的增加，为提供数据驱动的护理带来了机遇和挑战。

Method: 该系统采用检索增强生成（RAG）流程，整合自然语言处理和结构化临床输入，通过分析历史EHR数据（包括患者人口统计信息、主诉、临床症状、诊断信息和治疗历史）来生成治疗建议，并与具有相似特征的先例案例相结合。

Result: 初步评估表明，在适当约束和严格验证的情况下，基于LLM的工具可能为药物处方工作流程提供有价值的决策支持，其输出具有临床合理性和一致性。

Conclusion: 该系统是利用生成式AI（特别是LLM和RAG）整合到实际临床决策中的初步尝试，重点是透明度、安全性和与既定实践的一致性。

Abstract: The increasing complexity of clinical decision-making, alongside the rapid
expansion of electronic health records (EHR), presents both opportunities and
challenges for delivering data-informed care. This paper proposes a clinical
decision support system powered by Large Language Models (LLMs) to assist
prescribing clinicians. The system generates therapeutic suggestions by
analyzing historical EHR data, including patient demographics, presenting
complaints, clinical symptoms, diagnostic information, and treatment histories.
The framework integrates natural language processing with structured clinical
inputs to produce contextually relevant recommendations. Rather than replacing
clinician judgment, it is designed to augment decision-making by retrieving and
synthesizing precedent cases with comparable characteristics, drawing on local
datasets or federated sources where applicable. At its core, the system employs
a retrieval-augmented generation (RAG) pipeline that harmonizes unstructured
narratives and codified data to support LLM-based inference. We outline the
system's technical components, including representation representation
alignment and generation strategies. Preliminary evaluations, conducted with
de-identified and synthetic clinical datasets, examine the clinical
plausibility and consistency of the model's outputs. Early findings suggest
that LLM-based tools may provide valuable decision support in prescribing
workflows when appropriately constrained and rigorously validated. This work
represents an initial step toward integration of generative AI into real-world
clinical decision-making with an emphasis on transparency, safety, and
alignment with established practices.

</details>


### [201] [Is It Thinking or Cheating? Detecting Implicit Reward Hacking by Measuring Reasoning Effort](https://arxiv.org/abs/2510.01367)
*Xinpeng Wang,Nitish Joshi,Barbara Plank,Rico Angell,He He*

Main category: cs.AI

TL;DR: 本研究提出TRACE来检测隐式奖励破解，通过衡量模型推理所需的‘努力’程度，即在多早的推理阶段就能通过验证器。TRACE通过逐渐截断模型推理过程并评估其通过率来量化努力程度，在数学和编程推理任务中均显著优于现有监控方法，并能发现新的漏洞。


<details>
  <summary>Details</summary>
Motivation: 奖励破解（Reward hacking）是指模型利用奖励函数的漏洞，在未解决预期任务的情况下获得高额奖励。这种行为可能是显式的，也可能是隐式的（即推理过程看似正常但绕过了监控）。隐式奖励破解难以检测，对模型安全构成威胁。

Method: 提出TRACE (Truncated Reasoning AUC Evaluation) 方法来检测隐式奖励破解。其核心思想是，奖励破解行为的发生是因为利用漏洞比解决实际任务更容易，即模型所需的‘努力’更少。TRACE通过逐渐截断模型的思考过程（Chain-of-Thought, CoT），并强制模型在每个截断点给出答案，然后测量在验证器上的通过率。通过计算准确率-长度曲线下的面积来量化‘努力’程度。一个进行奖励破解的模型，由于走了捷径，会在其CoT的很小一部分就能获得高通过率，从而产生一个较大的曲线下面积。

Result: TRACE在数学推理任务上比最强的72B CoT监控器提高了65%以上的性能，在编程任务上比32B监控器提高了30%以上的性能。此外，TRACE还能在训练过程中发现未知的漏洞。

Conclusion: TRACE提供了一种可扩展的、无监督的监督方法，能够有效地检测当前监控方法难以发现的隐式奖励破解行为，提高了模型的安全性和可靠性。

Abstract: Reward hacking, where a reasoning model exploits loopholes in a reward
function to achieve high rewards without solving the intended task, poses a
significant threat. This behavior may be explicit, i.e. verbalized in the
model's chain-of-thought (CoT), or implicit, where the CoT appears benign thus
bypasses CoT monitors. To detect implicit reward hacking, we propose TRACE
(Truncated Reasoning AUC Evaluation). Our key observation is that hacking
occurs when exploiting the loophole is easier than solving the actual task.
This means that the model is using less `effort' than required to achieve high
reward. TRACE quantifies effort by measuring how early a model's reasoning
becomes sufficient to pass a verifier. We progressively truncate a model's CoT
at various lengths, force the model to answer, and measure the verifier-passing
rate at each cutoff. A hacking model, which takes a shortcut, will achieve a
high passing rate with only a small fraction of its CoT, yielding a large area
under the accuracy-vs-length curve. TRACE achieves over 65% gains over our
strongest 72B CoT monitor in math reasoning, and over 30% gains over a 32B
monitor in coding. We further show that TRACE can discover unknown loopholes
during training. Overall, TRACE offers a scalable unsupervised approach for
oversight where current monitoring methods prove ineffective.

</details>


### [202] [Fine-tuning with RAG for Improving LLM Learning of New Skills](https://arxiv.org/abs/2510.01375)
*Humaid Ibrahim,Nikolai Rozanov,Marek Rei*

Main category: cs.AI

TL;DR: 通过蒸馏将推理时检索转化为学习到的能力，以提高LLM代理的多步任务性能。


<details>
  <summary>Details</summary>
Motivation: LLM代理在执行多步任务时经常因前提条件不足、指令冗余或环境约束处理不当而失败。虽然检索增强生成（RAG）可以提供运行时指导，但需要维护外部知识库并增加计算开销。

Method: 提出一个简单的流水线，将推理时检索转化为学习到的能力：1. 从代理失败中提取紧凑、可重用的提示；2. 使用这些提示通过单次检索在回合开始时生成改进的教师轨迹；3. 在删除提示字符串的情况下，在这些轨迹上训练学生模型，强制内化而非记忆。

Result: 在ALFWorld和WebShop两个交互式基准测试中，经过蒸馏的学生模型一致优于基线代理，在ALFWorld上成功率达到91%（基线为79%），在WebShop上得分提高到72（基线为61），同时使用的token数量比检索增强教师少10-60%。

Conclusion: 该方法可以跨模型规模（7B/14B参数）和代理架构（ReAct/StateAct）进行泛化，表明可以通过有针对性的微调有效地内化检索优势，而无需永久的运行时依赖。

Abstract: Large language model (LLM) agents deployed for multi-step tasks frequently
fail in predictable ways: attempting actions with unmet preconditions, issuing
redundant commands, or mishandling environment constraints. While
retrieval-augmented generation (RAG) can improve performance by providing
runtime guidance, it requires maintaining external knowledge databases and adds
computational overhead at every deployment. We propose a simple pipeline that
converts inference-time retrieval into learned competence through distillation.
Our approach: (1) extracts compact, reusable hints from agent failures, (2)
uses these hints to generate improved teacher trajectories via one-shot
retrieval at episode start, and (3) trains student models on these trajectories
with hint strings removed, forcing internalization rather than memorization.
Across two interactive benchmarks, ALFWorld (household tasks) and WebShop
(online shopping), distilled students consistently outperform baseline agents,
achieving up to 91% success on ALFWorld (vs. 79% for baselines) and improving
WebShop scores to 72 (vs. 61 for baselines), while using 10-60% fewer tokens
than retrieval-augmented teachers depending on the environment. The approach
generalizes across model scales (7B/14B parameters) and agent architectures
(ReAct/StateAct), demonstrating that retrieval benefits can be effectively
internalized through targeted fine-tuning without permanent runtime
dependencies.

</details>


### [203] [Automating Data-Driven Modeling and Analysis for Engineering Applications using Large Language Model Agents](https://arxiv.org/abs/2510.01398)
*Yang Liu,Zaid Abulawi,Abhiram Garimidi,Doyeong Lim*

Main category: cs.AI

TL;DR: 该研究提出了一种利用大型语言模型（LLM）代理自动处理数据驱动建模和分析（特别是回归任务）的创新方法，旨在提高效率、可靠性和广泛适用性。


<details>
  <summary>Details</summary>
Motivation: 现代工程依赖大量实验和模拟数据，需要高效、可靠且广泛适用的建模策略，并对数据驱动方法（尤其是神经网络）有浓厚兴趣。传统方法需要大量手动干预，限制了其可扩展性和泛化能力。

Method: 评估了两种LLM代理框架：一种是多智能体系统，另一种是基于ReAct范例的单智能体系统。两种框架都能自主完成数据预处理、神经网络开发、训练、超参数优化和不确定性量化（UQ）。

Result: 使用临界热通量（CHF）预测基准测试了该方法，结果表明LLM代理开发的模型优于传统的CHF查找表，并且在预测准确性和UQ方面与专家开发的最新贝叶斯优化深度神经网络模型相当。

Conclusion: LLM代理在自动化复杂工程建模任务方面具有巨大潜力，可以显著减少人力工作，同时达到或超过现有的预测性能标准。

Abstract: Modern engineering increasingly relies on vast datasets generated by
experiments and simulations, driving a growing demand for efficient, reliable,
and broadly applicable modeling strategies. There is also heightened interest
in developing data-driven approaches, particularly neural network models, for
effective prediction and analysis of scientific datasets. Traditional
data-driven methods frequently involve extensive manual intervention, limiting
their ability to scale effectively and generalize to diverse applications. In
this study, we propose an innovative pipeline utilizing Large Language Model
(LLM) agents to automate data-driven modeling and analysis, with a particular
emphasis on regression tasks. We evaluate two LLM-agent frameworks: a
multi-agent system featuring specialized collaborative agents, and a
single-agent system based on the Reasoning and Acting (ReAct) paradigm. Both
frameworks autonomously handle data preprocessing, neural network development,
training, hyperparameter optimization, and uncertainty quantification (UQ). We
validate our approach using a critical heat flux (CHF) prediction benchmark,
involving approximately 25,000 experimental data points from the OECD/NEA
benchmark dataset. Results indicate that our LLM-agent-developed model
surpasses traditional CHF lookup tables and delivers predictive accuracy and UQ
on par with state-of-the-art Bayesian optimized deep neural network models
developed by human experts. These outcomes underscore the significant potential
of LLM-based agents to automate complex engineering modeling tasks, greatly
reducing human workload while meeting or exceeding existing standards of
predictive performance.

</details>


### [204] [OntoLogX: Ontology-Guided Knowledge Graph Extraction from Cybersecurity Logs with Large Language Models](https://arxiv.org/abs/2510.01409)
*Luca Cotti,Idilio Drago,Anisa Rula,Devis Bianchini,Federico Cerutti*

Main category: cs.AI

TL;DR: OntoLogX是一个AI代理，利用LLM将原始日志转换为本体驱动的知识图谱，用于提取可操作的网络威胁情报。


<details>
  <summary>Details</summary>
Motivation: 由于日志数据缺乏结构、语义不一致和碎片化，从日志中提取有价值的网络威胁情报（CTI）面临挑战。OntoLogX旨在解决这些问题，将异构数据转化为连贯、可互操作的表示形式。

Method: OntoLogX利用大型语言模型（LLM）和检索增强生成（RAG）技术，结合轻量级日志本体和迭代校正步骤，将原始日志转化为本体驱动的知识图谱（KGs）。它还将KGs聚合为会话，并利用LLM预测MITRE ATT&CK战术。

Result: OntoLogX在公开基准和真实世界的蜜罐数据集上进行了评估，展示了其在生成知识图谱方面的鲁棒性，并将日志证据准确映射到ATT&CK战术。结果表明，检索和校正提高了精度和召回率，代码导向的模型在结构化日志分析中有效，而本体驱动的表示有助于CTI提取。

Conclusion: OntoLogX通过将原始日志转化为本体驱动的知识图谱，并将其映射到MITRE ATT&CK战术，能够有效地提取可操作的网络威胁情报，克服了传统日志分析的局限性。

Abstract: System logs represent a valuable source of Cyber Threat Intelligence (CTI),
capturing attacker behaviors, exploited vulnerabilities, and traces of
malicious activity. Yet their utility is often limited by lack of structure,
semantic inconsistency, and fragmentation across devices and sessions.
Extracting actionable CTI from logs therefore requires approaches that can
reconcile noisy, heterogeneous data into coherent and interoperable
representations. We introduce OntoLogX, an autonomous Artificial Intelligence
(AI) agent that leverages Large Language Models (LLMs) to transform raw logs
into ontology-grounded Knowledge Graphs (KGs). OntoLogX integrates a
lightweight log ontology with Retrieval Augmented Generation (RAG) and
iterative correction steps, ensuring that generated KGs are syntactically and
semantically valid. Beyond event-level analysis, the system aggregates KGs into
sessions and employs a LLM to predict MITRE ATT&CK tactics, linking low-level
log evidence to higher-level adversarial objectives. We evaluate OntoLogX on
both logs from a public benchmark and a real-world honeypot dataset,
demonstrating robust KG generation across multiple KGs backends and accurate
mapping of adversarial activity to ATT&CK tactics. Results highlight the
benefits of retrieval and correction for precision and recall, the
effectiveness of code-oriented models in structured log analysis, and the value
of ontology-grounded representations for actionable CTI extraction.

</details>


### [205] [A Tale of LLMs and Induced Small Proxies: Scalable Agents for Knowledge Mining](https://arxiv.org/abs/2510.01427)
*Sipeng Zhang,Longfei Yun,Zilong Wang,Jingbo Shang,Letian Peng*

Main category: cs.AI

TL;DR:  Falconer是一个结合了大型语言模型（LLM）和轻量级代理模型的框架，通过LLM进行推理和生成标注数据，训练代理模型，从而实现高效可扩展的知识挖掘，在保证准确性的同时大幅降低成本和提高效率。


<details>
  <summary>Details</summary>
Motivation: 传统知识挖掘方法在成本、效率和泛化能力方面存在不足，需要一种能够结合LLM的推理能力和高效代理模型的解决方案。

Method:  Falconer框架利用LLM作为规划者，将用户指令分解为可执行的流水线；同时LLM也作为标注者，生成监督数据来训练轻量级的代理模型。该框架将分类和提取任务统一为get label和get span两个原子操作。

Result: 实验表明， Falconer在指令遵循准确性方面与最先进的LLM相当，同时将推理成本降低了90%，并将大规模知识挖掘的速度提高了20倍以上。

Conclusion: Falconer提供了一个高效且可扩展的知识挖掘基础，能够满足深度研究的需求。

Abstract: At the core of Deep Research is knowledge mining, the task of extracting
structured information from massive unstructured text in response to user
instructions. Large language models (LLMs) excel at interpreting such
instructions but are prohibitively expensive to deploy at scale, while
traditional pipelines of classifiers and extractors remain efficient yet
brittle and unable to generalize to new tasks. We introduce Falconer, a
collaborative framework that combines the agentic reasoning of LLMs with
lightweight proxy models for scalable knowledge mining. In Falconer, LLMs act
as planners, decomposing user instructions into executable pipelines, and as
annotators, generating supervision to train small proxies. The framework
unifies classification and extraction into two atomic operations, get label and
get span, enabling a single instruction-following model to replace multiple
task-specific components. To evaluate the consistency between proxy models
incubated by Falconer and annotations provided by humans and large models, we
construct new benchmarks covering both planning and end-to-end execution.
Experiments show that Falconer closely matches state-of-the-art LLMs in
instruction-following accuracy while reducing inference cost by up to 90% and
accelerating large-scale knowledge mining by more than 20x, offering an
efficient and scalable foundation for Deep Research.

</details>


### [206] [On the Role of Domain Experts in Creating Effective Tutoring Systems](https://arxiv.org/abs/2510.01432)
*Sarath Sreedharan,Kelsey Sikes,Nathaniel Blanchard,Lisa Mason,Nikhil Krishnaswamy,Jill Zarestky*

Main category: cs.AI

TL;DR: 专家知识在教育AI中的作用被忽视，本文探讨了其在自动生成课程和开发自适应辅导系统方面的潜力，并通过授粉媒介识别的案例研究进行了说明。


<details>
  <summary>Details</summary>
Motivation: AI for education领域忽视了领域专家提供的知识在创建有效辅导系统中的作用。

Method: 1. 利用可解释AI（XAI）技术和专家规则自动生成课程。2. 利用专家定义的课程来开发自适应辅导系统。

Result: 提出两种利用专家知识创建新颖教育系统的方法，并以授粉媒介识别的案例研究为例。

Conclusion: 强调了利用专家知识（如通过XAI和课程定义）在教育AI中的重要性。

Abstract: The role that highly curated knowledge, provided by domain experts, could
play in creating effective tutoring systems is often overlooked within the AI
for education community. In this paper, we highlight this topic by discussing
two ways such highly curated expert knowledge could help in creating novel
educational systems. First, we will look at how one could use explainable AI
(XAI) techniques to automatically create lessons. Most existing XAI methods are
primarily aimed at debugging AI systems. However, we will discuss how one could
use expert specified rules about solving specific problems along with novel XAI
techniques to automatically generate lessons that could be provided to
learners. Secondly, we will see how an expert specified curriculum for learning
a target concept can help develop adaptive tutoring systems, that can not only
provide a better learning experience, but could also allow us to use more
efficient algorithms to create these systems. Finally, we will highlight the
importance of such methods using a case study of creating a tutoring system for
pollinator identification, where such knowledge could easily be elicited from
experts.

</details>


### [207] [VOGUE: Guiding Exploration with Visual Uncertainty Improves Multimodal Reasoning](https://arxiv.org/abs/2510.01444)
*Rui Liu,Dian Yu,Tong Zheng,Runpeng Dai,Zongxia Li,Wenhao Yu,Zhenwen Liang,Linfeng Song,Haitao Mi,Pratap Tokekar,Dong Yu*

Main category: cs.AI

TL;DR: VOGUE是一种新的多模态大型语言模型（MLLM）探索方法，通过在视觉输入空间而非输出空间进行探索，量化策略对视觉扰动的敏感性，并利用不确定性指导探索，显著提高了视觉数学和通用领域推理任务的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大型语言模型（MLLM）在强化学习（RL）的探索方面存在不足，它们将视觉输入视为确定性条件，忽略了视觉变化带来的模糊性，导致模型对视觉变化不够鲁棒。

Method: VOGUE（Visual Uncertainty Guided Exploration）通过将图像视为随机上下文，利用对称KL散度量化策略对视觉扰动的敏感性，生成不确定性信号。该信号通过不确定性比例奖励、token熵奖励和退火采样计划来指导学习过程，平衡探索和利用。

Result: 在GRPO框架下，VOGUE在Qwen2.5-VL-3B/7B模型上进行了实验。在三个视觉数学基准和三个通用领域推理基准上，VOGUE将pass@1准确率平均提高了2.6%，并将pass@4性能有所提升，同时缓解了强化学习微调中常见的探索衰减问题。

Conclusion: 将探索建立在视觉输入的固有不确定性之上，是提高多模态推理能力的有效策略。

Abstract: Reinforcement learning with verifiable rewards (RLVR) improves reasoning in
large language models (LLMs) but struggles with exploration, an issue that
still persists for multimodal LLMs (MLLMs). Current methods treat the visual
input as a fixed, deterministic condition, overlooking a critical source of
ambiguity and struggling to build policies robust to plausible visual
variations. We introduce $\textbf{VOGUE (Visual Uncertainty Guided
Exploration)}$, a novel method that shifts exploration from the output (text)
to the input (visual) space. By treating the image as a stochastic context,
VOGUE quantifies the policy's sensitivity to visual perturbations using the
symmetric KL divergence between a "raw" and "noisy" branch, creating a direct
signal for uncertainty-aware exploration. This signal shapes the learning
objective via an uncertainty-proportional bonus, which, combined with a
token-entropy bonus and an annealed sampling schedule, effectively balances
exploration and exploitation. Implemented within GRPO on two model scales
(Qwen2.5-VL-3B/7B), VOGUE boosts pass@1 accuracy by an average of 2.6% on three
visual math benchmarks and 3.7% on three general-domain reasoning benchmarks,
while simultaneously increasing pass@4 performance and mitigating the
exploration decay commonly observed in RL fine-tuning. Our work shows that
grounding exploration in the inherent uncertainty of visual inputs is an
effective strategy for improving multimodal reasoning.

</details>


### [208] [AIReg-Bench: Benchmarking Language Models That Assess AI Regulation Compliance](https://arxiv.org/abs/2510.01474)
*Bill Marino,Rosco Hunter,Zubair Jamali,Marinos Emmanouil Kalpakos,Mudra Kashyap,Isaiah Hinton,Alexa Hanson,Maahum Nazir,Christoph Schnabl,Felix Steffek,Hongkai Wen,Nicholas D. Lane*

Main category: cs.AI

TL;DR: 本研究提出了AIReg-Bench，一个用于评估大型语言模型（LLMs）在理解和评估AI系统是否符合欧盟AI法案（AIA）方面能力的基准数据集。


<details>
  <summary>Details</summary>
Motivation: 随着AI监管的兴起，评估AI系统是否符合法规的需求日益增长，但目前缺乏用于衡量LLMs在此任务上表现的基准。

Method: 通过两步法创建数据集：首先，利用LLM生成120个AI系统技术文档的示例；其次，由法律专家对这些示例进行标注，判断其是否违反AIA的具体条款。

Result: 创建了一个包含120个技术文档示例的数据集，并评估了当前领先的LLMs在复现专家标注结果方面的能力。

Conclusion: AIReg-Bench为理解基于LLM的AI法规合规性评估工具的潜力和局限性提供了一个起点，并为未来LLMs的评估建立了基准。

Abstract: As governments move to regulate AI, there is growing interest in using Large
Language Models (LLMs) to assess whether or not an AI system complies with a
given AI Regulation (AIR). However, there is presently no way to benchmark the
performance of LLMs at this task. To fill this void, we introduce AIReg-Bench:
the first benchmark dataset designed to test how well LLMs can assess
compliance with the EU AI Act (AIA). We created this dataset through a two-step
process: (1) by prompting an LLM with carefully structured instructions, we
generated 120 technical documentation excerpts (samples), each depicting a
fictional, albeit plausible, AI system - of the kind an AI provider might
produce to demonstrate their compliance with AIR; (2) legal experts then
reviewed and annotated each sample to indicate whether, and in what way, the AI
system described therein violates specific Articles of the AIA. The resulting
dataset, together with our evaluation of whether frontier LLMs can reproduce
the experts' compliance labels, provides a starting point to understand the
opportunities and limitations of LLM-based AIR compliance assessment tools and
establishes a benchmark against which subsequent LLMs can be compared. The
dataset and evaluation code are available at
https://github.com/camlsys/aireg-bench.

</details>


### [209] [Lateral Tree-of-Thoughts Surpasses ToT by Incorporating Logically-Consistent, Low-Utility Candidates](https://arxiv.org/abs/2510.01500)
*Abhinav Madahar*

Main category: cs.AI

TL;DR: LToT通过区分效用和逻辑一致性，并将低效用但一致的候选者作为资产而非浪费，来解决ToT搜索中的宽度饱和和深度近视问题，从而在不增加计算成本的情况下，将大型测试时间预算转化为原则性多样性。


<details>
  <summary>Details</summary>
Motivation: 标准的Tree-of-Thoughts（ToT）风格搜索在大型测试时间计算预算下存在两种病态：宽度饱和（额外样本产生近乎重复的结果）和深度近视（短暂的效用评估会修剪掉后续有价值的分支）。

Method: 提出Lateral Tree-of-Thoughts（LToT），一个分离效用和逻辑一致性的控制器。它将候选者分为主线（高效用）和侧线（低效用但一致）。侧线通过Lateral Racing with Short-Circuit（LR--SC）进行探索，这是一个有上限的连续减半竞赛，将少量探测分配给大量侧线候选者，并使用考虑宽度的阈值和重复确认机制。一旦侧线达到主线标准，即被提升。主线保持较窄，以便将多余计算投入到宽度成本较低的地方。LToT的侧线成本被证明是伪线性的，而主线成本呈指数增长。

Result: 由于实证评估仍在准备中，将在后续修订中添加，因此目前尚未提供具体结果。

Conclusion: LToT是一种有效的解决方案，可以解决ToT搜索在大型测试时间计算预算下的效率问题，通过将计算预算转化为原则性的多样性，同时保持了晋升的纪律性，从而缓解了宽度饱和和深度近视的问题，并且没有增加计算成本。

Abstract: Modern deployments increasingly allocate large test-time compute (thousands
of tokens or many node expansions) to boost reliability. Under such budgets,
standard Tree-of-Thoughts-style search exhibits two pathologies: breadth
saturation (additional samples mostly produce near-duplicates, so width stops
growing) and depth myopia (noisy short-horizon utilities prune branches whose
payoff appears after a few more steps). We propose Lateral Tree-of-Thoughts
(LToT), a drop-in controller that separates utility from logical consistency
and treats low-utility but consistent candidates as assets rather than waste.
The frontier is split into mainlines (high-utility candidates used for
exploitation) and laterals (consistent, initially low-utility candidates that
receive short, cheap probes before judgment). LToT explores laterals via
Lateral Racing with Short-Circuit (LR--SC): a capped successive-halving race
that spreads tiny probes across a very wide lateral set, uses width-aware
thresholds with repeat-to-confirm, and immediately promotes a branch once its
envelope clears the mainline bar; mainlines are kept intentionally narrow so
surplus compute is invested where width is cheap. We prove a pseudolinear
lateral cost $\Theta(N_0 \log_{\eta} N_0)$ with logarithmically many rungs
(initial lateral width $N_0$; culling factor $\eta>1$), in contrast to the
exponential growth of uncapped mainlines. Empirical evaluations on benchmark
tasks are in preparation and will be added in a future revision. In short, LToT
turns large test-time budgets into principled diversity while preserving
promotion discipline, mitigating saturation and myopia without inflating
compute.

</details>


### [210] [Towards Interpretable and Inference-Optimal COT Reasoning with Sparse Autoencoder-Guided Generation](https://arxiv.org/abs/2510.01528)
*Daniel Zhao,Abhilash Shankarampeta,Lanxiang Hu,Tajana Rosing,Hao Zhang*

Main category: cs.AI

TL;DR: 本研究提出一种新方法，结合稀疏自编码器（SAE）和聚类技术，用于分析大型语言模型（LLM）的内部 token 表示，并指导数学推理任务中的生成过程。该方法通过训练 SAE 生成稀疏向量表示，然后使用 k-means 聚类构建图，其中顶点代表 token 簇，加权边表示 token 转移。利用此图，定义了基于边权的奖励函数来量化推理过程的遵循程度，从而识别出“剥削性”的推理轨迹。同时，通过聚类分析生成的多样性来评估探索程度。研究结果表明，平衡剥削和探索对于数学推理任务的准确性至关重要。在生成过程中，SAE 可作为可扩展的奖励模型，指导生成过程，确保剥削和探索之间的平衡，避免极端行为，最终提升 LLM 的推理质量。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于理解和改进大型语言模型（LLM）在数学推理任务中的表现。具体来说，作者旨在分析 LLM 内部的 token 表示，并利用这些分析来指导模型的生成过程，以期提高推理的准确性和质量。

Method: 本研究提出了一种新方法，首先训练稀疏自编码器（SAE）来为训练 token 生成稀疏向量表示。然后，应用 k-means 聚类技术构建一个图，其中节点代表 token 簇，加权的边表示 token 之间的顺序转移。基于这个图，定义了一个基于边权的奖励函数，用于量化模型生成过程对既定推理路径的遵循程度，从而识别出“剥削性”的推理轨迹。此外，研究还通过聚类分析来衡量生成的多样性，以评估探索的程度。

Result: 研究结果表明，在数学推理任务中，平衡“剥削”（遵循既定推理路径）和“探索”（生成多样化内容）对于实现高准确性至关重要。SAE 在生成过程中可以作为一个可扩展的奖励模型，用于指导 LLM 的生成，确保在剥削和探索之间取得适当的平衡，避免模型走向极端，从而促进更高质量的推理过程。

Conclusion: 本研究提出的结合 SAE 和聚类分析的方法，能够有效地分析 LLM 的内部表示，并指导其在数学推理任务中的生成。研究强调了在推理过程中平衡剥削和探索的重要性，并展示了 SAE 作为奖励模型在实现这一平衡方面的潜力，最终有助于提升 LLM 的推理能力。

Abstract: We propose a novel method that leverages sparse autoencoders (SAEs) and
clustering techniques to analyze the internal token representations of large
language models (LLMs) and guide generations in mathematical reasoning tasks.
Our approach first trains an SAE to generate sparse vector representations for
training tokens, then applies k-means clustering to construct a graph where
vertices represent token clusters and weighted edges capture sequential token
transitions. Using this graph, we define an edge-weight based reward function
to quantify adherence to established reasoning traces, thereby identifying
exploitative reasoning trajectories. Additionally, we measure generation
diversity from clustering to assess the extent of exploration. Our findings
indicate that balancing both exploitation and exploration is crucial for
achieving high accuracy in mathematical reasoning tasks. During generation, the
SAE can serve as a scalable reward model to guide generations, ensuring a
balanced trade-off between exploitation and exploration. This prevents extreme
behaviors in either direction, ultimately fostering a higher-quality reasoning
process in LLMs.

</details>


### [211] [LOGicalThought: Logic-Based Ontological Grounding of LLMs for High-Assurance Reasoning](https://arxiv.org/abs/2510.01530)
*Navapat Nananukul,Yue Zhang,Ryan Lee,Eric Boxer,Jonathan May,Vibhav Giridhar Gogate,Jay Pujara,Mayank Kejriwal*

Main category: cs.AI

TL;DR: LLM在法律和医学等关键领域的高置信度推理面临挑战。本文提出了一种名为LOGicalThought (LogT) 的新神经符号架构，它结合了LLM和先进的逻辑推理器，通过构建双重符号图和逻辑上下文来解决这个问题，并在四个基准测试中显著提高了推理性能。


<details>
  <summary>Details</summary>
Motivation: 法律和医学等关键领域的高置信度推理需要准确、可验证且有明确证据支持的结论，但现有LLM在处理涉及规则、例外和非单调逻辑的文本推理方面存在不足。

Method: 提出了一种名为LOGicalThought (LogT) 的神经符号架构，该架构结合了LLM和先进的逻辑推理器，构建了双重符号图和逻辑上下文，将推理问题转化为紧凑的评估。

Result: 在四个跨领域基准测试中，LogT相比于四个基线模型，LLM整体性能提升了11.84%。在否定推理方面提升高达+10.2%，在蕴含推理方面提升+13.2%，在可废止推理方面提升+5.5%。

Conclusion: LogT架构通过结合LLM和先进的逻辑推理器，有效地解决了高置信度文本推理中的核心挑战，并在多个推理模式下取得了显著的性能提升。

Abstract: High-assurance reasoning, particularly in critical domains such as law and
medicine, requires conclusions that are accurate, verifiable, and explicitly
grounded in evidence. This reasoning relies on premises codified from rules,
statutes, and contracts, inherently involving defeasible or non-monotonic logic
due to numerous exceptions, where the introduction of a single fact can
invalidate general rules, posing significant challenges. While large language
models (LLMs) excel at processing natural language, their capabilities in
standard inference tasks do not translate to the rigorous reasoning required
over high-assurance text guidelines. Core reasoning challenges within such
texts often manifest specific logical structures involving negation,
implication, and, most critically, defeasible rules and exceptions. In this
paper, we propose a novel neurosymbolically-grounded architecture called
LOGicalThought (LogT) that uses an advanced logical language and reasoner in
conjunction with an LLM to construct a dual symbolic graph context and
logic-based context. These two context representations transform the problem
from inference over long-form guidelines into a compact grounded evaluation.
Evaluated on four multi-domain benchmarks against four baselines, LogT improves
overall performance by 11.84% across all LLMs. Performance improves
significantly across all three modes of reasoning: by up to +10.2% on negation,
+13.2% on implication, and +5.5% on defeasible reasoning compared to the
strongest baseline.

</details>


### [212] [Information Seeking for Robust Decision Making under Partial Observability](https://arxiv.org/abs/2510.01531)
*Djengo Cyun-Jyun Fang,Tsung-Wei Ke*

Main category: cs.AI

TL;DR: LLM规划代理忽略了内部动力学和实际环境之间的差异。InfoSeeker是一个LLM决策框架，通过整合面向任务的规划和信息寻求来解决这个问题，从而在不完全可观察的环境中进行规划。


<details>
  <summary>Details</summary>
Motivation: 现有LLM规划代理常常忽略其内部动力学和实际环境之间的差异，而显式地寻求信息对于在信息不全和动态不确定的环境中进行问题解决至关重要。

Method: InfoSeeker是一个LLM决策框架，它通过规划动作来主动收集信息，以验证其理解、检测环境变化或在生成或修改面向任务的计划之前进行假设检验。

Result: InfoSeeker在包含不完全可观察性和不确定动态的部分可观察环境的新型基准测试中，实现了比先前方法高出74%的绝对性能增益，并且在机器人操作和Web导航等既定基准测试中也表现优于基线模型，同时没有牺牲样本效率。

Conclusion: 将规划和信息寻求紧密集成对于在部分可观察环境中的鲁棒行为至关重要。

Abstract: Explicit information seeking is essential to human problem-solving in
practical environments characterized by incomplete information and noisy
dynamics. When the true environmental state is not directly observable, humans
seek information to update their internal dynamics and inform future
decision-making. Although existing Large Language Model (LLM) planning agents
have addressed observational uncertainty, they often overlook discrepancies
between their internal dynamics and the actual environment. We introduce
Information Seeking Decision Planner (InfoSeeker), an LLM decision-making
framework that integrates task-oriented planning with information seeking to
align internal dynamics and make optimal decisions under uncertainty in both
agent observations and environmental dynamics. InfoSeeker prompts an LLM to
actively gather information by planning actions to validate its understanding,
detect environmental changes, or test hypotheses before generating or revising
task-oriented plans. To evaluate InfoSeeker, we introduce a novel benchmark
suite featuring partially observable environments with incomplete observations
and uncertain dynamics. Experiments demonstrate that InfoSeeker achieves a 74%
absolute performance gain over prior methods without sacrificing sample
efficiency. Moreover, InfoSeeker generalizes across LLMs and outperforms
baselines on established benchmarks such as robotic manipulation and web
navigation. These findings underscore the importance of tightly integrating
planning and information seeking for robust behavior in partially observable
environments. The project page is available at https://infoseekerllm.github.io

</details>


### [213] [Step-Aware Policy Optimization for Reasoning in Diffusion Large Language Models](https://arxiv.org/abs/2510.01544)
*Shaoan Xie,Lingjing Kong,Xiangchen Song,Xinshuai Dong,Guangyi Chen,Eric P. Xing,Kun Zhang*

Main category: cs.AI

TL;DR: dLLMs在复杂推理方面面临训练挑战，现有RL方法依赖稀疏奖励，可能导致错误推理。本文提出一种理论框架，将复杂问题解决形式化为分层选择过程，并将非结构化细化视为核心缺陷。为解决此问题，本文提出SAPO算法，通过基于过程的奖励函数鼓励渐进式进展，引导模型学习结构化推理路径，从而在推理基准测试中取得显著效果并提高可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有基于稀疏奖励的强化学习方法在训练dLLMs进行复杂推理时存在缺陷，容易导致模型学习到不正确的推理路径，这源于现有方法与推理的自然结构之间存在根本性不匹配。

Method: 提出一种理论框架，将复杂问题解决形式化为分层选择过程，并将非结构化细化视为现有方法的一个核心缺陷。在此基础上，提出一种新颖的强化学习算法SAPO，该算法通过使用基于过程的奖励函数来鼓励渐进式进展，以将dLLM的去噪过程与潜在的推理层级对齐。

Result: SAPO算法在具有挑战性的推理基准测试中显著提高了dLLMs的性能，并增强了生成过程的可解释性。

Conclusion: SAPO算法通过鼓励渐进式进展，引导dLLM学习结构化的推理路径，有效解决了现有方法在复杂推理训练中的不足，并在性能和可解释性方面取得了显著的提升。

Abstract: Diffusion language models (dLLMs) offer a promising, non-autoregressive
paradigm for text generation, yet training them for complex reasoning remains a
key challenge. Current reinforcement learning approaches often rely on sparse,
outcome-based rewards, which can reinforce flawed reasoning paths that lead to
coincidentally correct answers. We argue that this stems from a fundamental
mismatch with the natural structure of reasoning. We first propose a
theoretical framework that formalizes complex problem solving as a hierarchical
selection process, where an intractable global constraint is decomposed into a
series of simpler, localized logical steps. This framework provides a
principled foundation for algorithm design, including theoretical insights into
the identifiability of this latent reasoning structure. Motivated by this
theory, we identify unstructured refinement -- a failure mode where a model's
iterative steps do not contribute meaningfully to the solution -- as a core
deficiency in existing methods. We then introduce Step-Aware Policy
Optimization (SAPO), a novel RL algorithm that aligns the dLLM's denoising
process with the latent reasoning hierarchy. By using a process-based reward
function that encourages incremental progress, SAPO guides the model to learn
structured, coherent reasoning paths. Our empirical results show that this
principled approach significantly improves performance on challenging reasoning
benchmarks and enhances the interpretability of the generation process.

</details>


### [214] [InvThink: Towards AI Safety via Inverse Reasoning](https://arxiv.org/abs/2510.01569)
*Yubin Kim,Taehan Kim,Eugene Park,Chunjong Park,Cynthia Breazeal,Daniel McDuff,Hae Won Park*

Main category: cs.AI

TL;DR: InvThink通过先推理失败模式再生成回应，提升LLM安全性，且不牺牲通用推理能力，在医疗、金融、法律等高风险领域表现尤为出色。


<details>
  <summary>Details</summary>
Motivation: 现有安全对齐方法直接优化安全回应，而InvThink旨在通过让LLM预先考虑潜在危害、分析后果并生成规避风险的回应，来提升模型的安全性。

Method: InvThink通过三个步骤实现反向思考：1. 列举潜在危害；2. 分析危害的后果；3. 生成主动规避这些风险的安全输出。该方法可以通过监督微调和强化学习在不同LLM家族中实现。

Result: InvThink在模型规模扩展上显示出比现有方法更强的安全性提升；它通过系统性考虑失败模式来减轻安全约束对通用推理能力的负面影响（安全税）；在医疗、金融、法律及涉及敲诈、谋杀等高风险场景下，有害回应减少高达15.7%。

Conclusion: 反向推理（InvThink）为实现更安全、更强大的语言模型提供了一条可扩展且通用的路径。

Abstract: We present InvThink, a simple yet powerful approach that gives large language
models (LLMs) the capability of inverse thinking: reasoning through failure
modes before generating responses. Unlike existing safety alignment methods
that optimize directly for safe response, InvThink instructs models to 1)
enumerate potential harms, 2) analyze their consequences, and 3) generate safe
outputs that proactively avoid these risks. Our method reveals three key
findings: (i) safety improvements show stronger scaling with model size
compared to existing safety methods. (ii) InvThink mitigates safety tax; by
training models to systematically consider failure modes, it preserves general
reasoning capabilities on standard benchmarks. (iii) beyond general safety
tasks, InvThink excels in high-stakes domains including external-facing
(medicine, finance, law) and agentic (blackmail, murder) risk scenarios,
achieving up to 15.7% reduction in harmful responses compared to baseline
methods like SafetyPrompt. We further implement InvThink via supervised
fine-tuning, and reinforcement learning across three LLM families. These
results suggest that inverse reasoning provides a scalable and generalizable
path toward safer, more capable language models.

</details>


### [215] [AdvEvo-MARL: Shaping Internalized Safety through Adversarial Co-Evolution in Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2510.01586)
*Zhenyu Pan,Yiting Zhang,Zhuo Liu,Yolo Yunlong Tang,Zeliang Zhang,Haozheng Luo,Yuwei Han,Jianshu Zhang,Dennis Wu,Hong-Yu Chen,Haoran Lu,Haoyang Fang,Manling Li,Chenliang Xu,Philip S. Yu,Han Liu*

Main category: cs.AI

TL;DR: AdvEvo-MARL是一种通过联合优化攻击者和防御者（任务代理）来解决大型语言模型（LLM）多代理系统安全问题的框架，通过内部化安全机制，在不增加额外开销的情况下，有效降低了攻击成功率并保持了任务准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM多代理系统安全防御方法，如自验证和外部守卫模块，存在不足：自验证因单个代理能力有限，难以检测跨代理的复杂攻击；外部守卫模块则增加了系统开销并可能成为单点故障。因此，需要一种新的方法来解决这些挑战。

Method: 提出AdvEvo-MARL框架，这是一种协同进化多代理强化学习方法。该框架将安全机制内嵌于任务代理中，通过在对抗性学习环境中联合优化攻击者（生成不断变化的越狱提示）和防御者（同时执行任务和抵抗攻击的任务代理）来实现。为了稳定学习和促进合作，引入了公共基线用于优势估计，即同一功能组内的代理共享组级平均回报基线。

Result: 在代表性的攻击场景中，AdvEvo-MARL始终将攻击成功率（ASR）保持在20%以下，而基线方法则高达38.33%。同时，该方法在任务准确性方面表现稳定，甚至有所提高（在推理任务上提高了3.67%）。

Conclusion: AdvEvo-MARL证明了在不依赖额外守卫代理或增加系统开销的情况下，可以同时提高安全性和效用，从而实现了LLM多代理系统的安全与性能的协同优化。

Abstract: LLM-based multi-agent systems excel at planning, tool use, and role
coordination, but their openness and interaction complexity also expose them to
jailbreak, prompt-injection, and adversarial collaboration. Existing defenses
fall into two lines: (i) self-verification that asks each agent to pre-filter
unsafe instructions before execution, and (ii) external guard modules that
police behaviors. The former often underperforms because a standalone agent
lacks sufficient capacity to detect cross-agent unsafe chains and
delegation-induced risks; the latter increases system overhead and creates a
single-point-of-failure-once compromised, system-wide safety collapses, and
adding more guards worsens cost and complexity. To solve these challenges, we
propose AdvEvo-MARL, a co-evolutionary multi-agent reinforcement learning
framework that internalizes safety into task agents. Rather than relying on
external guards, AdvEvo-MARL jointly optimizes attackers (which synthesize
evolving jailbreak prompts) and defenders (task agents trained to both
accomplish their duties and resist attacks) in adversarial learning
environments. To stabilize learning and foster cooperation, we introduce a
public baseline for advantage estimation: agents within the same functional
group share a group-level mean-return baseline, enabling lower-variance updates
and stronger intra-group coordination. Across representative attack scenarios,
AdvEvo-MARL consistently keeps attack-success rate (ASR) below 20%, whereas
baselines reach up to 38.33%, while preserving-and sometimes improving-task
accuracy (up to +3.67% on reasoning tasks). These results show that safety and
utility can be jointly improved without relying on extra guard agents or added
system overhead.

</details>


### [216] [AgentRec: Next-Generation LLM-Powered Multi-Agent Collaborative Recommendation with Adaptive Intelligence](https://arxiv.org/abs/2510.01609)
*Bo Ma,Hang Li,ZeHua Hu,XiaoFan Gui,LuYao Liu,Simon Lau*

Main category: cs.AI

TL;DR: AgentRec是一个多智能体协同推荐框架，利用LLM处理动态用户偏好、对话连贯性和多目标排序。


<details>
  <summary>Details</summary>
Motivation: 现有交互式对话推荐系统在处理动态用户偏好、维持对话连贯性和平衡多重排序目标方面存在挑战。

Method: AgentRec采用分层智能体网络和自适应智能技术，包括对话理解、偏好建模、情境感知和动态排序的专用LLM智能体，并通过自适应加权机制进行协调。

Result: AgentRec在三个真实世界的数据集上实现了2.8%的对话成功率提升、1.9%的推荐准确率（NDCG@10）提升和3.2%的对话效率提升，同时计算成本相当。

Conclusion: AgentRec通过多智能体协同，有效解决了现有对话推荐系统的局限性，并在多个关键指标上取得了显著的改进。

Abstract: Interactive conversational recommender systems have gained significant
attention for their ability to capture user preferences through natural
language interactions. However, existing approaches face substantial challenges
in handling dynamic user preferences, maintaining conversation coherence, and
balancing multiple ranking objectives simultaneously. This paper introduces
AgentRec, a next-generation LLM-powered multi-agent collaborative
recommendation framework that addresses these limitations through hierarchical
agent networks with adaptive intelligence. Our approach employs specialized
LLM-powered agents for conversation understanding, preference modeling, context
awareness, and dynamic ranking, coordinated through an adaptive weighting
mechanism that learns from interaction patterns. We propose a three-tier
learning strategy combining rapid response for simple queries, intelligent
reasoning for complex preferences, and deep collaboration for challenging
scenarios. Extensive experiments on three real-world datasets demonstrate that
AgentRec achieves consistent improvements over state-of-the-art baselines, with
2.8\% enhancement in conversation success rate, 1.9\% improvement in
recommendation accuracy (NDCG@10), and 3.2\% better conversation efficiency
while maintaining comparable computational costs through intelligent agent
coordination.

</details>


### [217] [PychoBench: Evaluating the Psychology Intelligence of Large Language Models](https://arxiv.org/abs/2510.01611)
*Min Zeng*

Main category: cs.AI

TL;DR: LLMs 在心理咨询领域的应用潜力巨大，但目前只有 GPT-4o 等顶尖模型能通过美国全国咨询师资格考试（NCE），而较小的模型则远未达标。


<details>
  <summary>Details</summary>
Motivation: 评估 LLM 在心理咨询领域的应用潜力，关键在于考察其是否具备通过美国全国咨询师资格考试（NCE）的能力，以衡量其是否满足成为合格心理咨询师的知识标准。

Method: 创建了一个名为 PsychoBench 的基准测试，该测试包含 2,252 道单选题，源自美国全国咨询师资格考试，旨在全面评估 LLM 的心理学知识和咨询能力。

Result: 在评估中，GPT-4o、Llama3.3-70B 和 Gemma3-27B 等先进模型均远超 NCE 的及格线（约 70% 的准确率），而 Qwen2.5-7B 和 Mistral-7B 等小型开源模型则远远落后。

Conclusion: 目前只有顶尖的 LLM 能够达到心理咨询考试的标准，这既显示了 LLM 在心理咨询领域的应用前景，也指出了开发面向心理学应用的 LLM 所面临的挑战。

Abstract: Large Language Models (LLMs) have demonstrated remarkable success across a
wide range of industries, primarily due to their impressive generative
abilities. Yet, their potential in applications requiring cognitive abilities,
such as psychological counseling, remains largely untapped. This paper
investigates the key question: Can LLMs be effectively applied to psychological
counseling? To determine whether an LLM can effectively take on the role of a
psychological counselor, the first step is to assess whether it meets the
qualifications required for such a role, namely the ability to pass the U.S.
National Counselor Certification Exam (NCE). This is because, just as a human
counselor must pass a certification exam to practice, an LLM must demonstrate
sufficient psychological knowledge to meet the standards required for such a
role. To address this, we introduce PsychoBench, a benchmark grounded in
U.S.national counselor examinations, a licensure test for professional
counselors that requires about 70% accuracy to pass. PsychoBench comprises
approximately 2,252 carefully curated single-choice questions, crafted to
require deep understanding and broad enough to cover various sub-disciplines of
psychology. This benchmark provides a comprehensive assessment of an LLM's
ability to function as a counselor. Our evaluation shows that advanced models
such as GPT-4o, Llama3.3-70B, and Gemma3-27B achieve well above the passing
threshold, while smaller open-source models (e.g., Qwen2.5-7B, Mistral-7B)
remain far below it. These results suggest that only frontier LLMs are
currently capable of meeting counseling exam standards, highlighting both the
promise and the challenges of developing psychology-oriented LLMs.

</details>


### [218] [Learning to Decide with Just Enough: Information-Theoretic Context Summarization for CDMPs](https://arxiv.org/abs/2510.01620)
*Peidong Liu,Junjiang Lin,Shaowen Wang,Yao Xu,Haiqing Li,Xuhao Xie,Siyi Wu,Hao Li*

Main category: cs.AI

TL;DR: 通过使用大型语言模型（LLM）压缩上下文输入，提出一种信息论的摘要方法，用于处理高维或非结构化环境中的上下文马尔可夫决策过程（CMDP），在多个基准测试中提高了性能并降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有CMDP方法难以处理高维或非结构化环境，导致计算量大且性能不稳定。

Method: 使用大型语言模型（LLM）将上下文输入压缩成低维、语义丰富的摘要，并以此增强状态表示。基于近似上下文充分性的概念进行分析，并进行了包括遗憾界限和延迟-熵权衡的刻画。

Result: 在离散、连续、视觉和推荐基准测试中，所提出的方法相较于原始上下文和非上下文基线，在奖励、成功率和样本效率方面均有提升，同时降低了延迟和内存使用。

Conclusion: 基于LLM的摘要为资源受限环境下的高效决策提供了一种可扩展且可解释的解决方案。

Abstract: Contextual Markov Decision Processes (CMDPs) offer a framework for sequential
decision-making under external signals, but existing methods often fail to
generalize in high-dimensional or unstructured contexts, resulting in excessive
computation and unstable performance. We propose an information-theoretic
summarization approach that uses large language models (LLMs) to compress
contextual inputs into low-dimensional, semantically rich summaries. These
summaries augment states by preserving decision-critical cues while reducing
redundancy. Building on the notion of approximate context sufficiency, we
provide, to our knowledge, the first regret bounds and a latency-entropy
trade-off characterization for CMDPs. Our analysis clarifies how
informativeness impacts computational cost. Experiments across discrete,
continuous, visual, and recommendation benchmarks show that our method
outperforms raw-context and non-context baselines, improving reward, success
rate, and sample efficiency, while reducing latency and memory usage. These
findings demonstrate that LLM-based summarization offers a scalable and
interpretable solution for efficient decision-making in context-rich,
resource-constrained environments.

</details>


### [219] [Understanding the Geospatial Reasoning Capabilities of LLMs: A Trajectory Recovery Perspective](https://arxiv.org/abs/2510.01639)
*Thinh Hung Truong,Jey Han Lau,Jianzhong Qi*

Main category: cs.AI

TL;DR: LLMs can perform navigation tasks by reconstructing masked GPS traces using road network context, outperforming baselines and showing good generalization, though with some biases.


<details>
  <summary>Details</summary>
Motivation: To explore the geospatial reasoning capabilities of LLMs, specifically their ability to read road network maps and perform navigation.

Method: Framing trajectory recovery as a proxy task, reconstructing masked GPS traces using a prompting framework with road network context. Introduced GLOBALTRACE dataset with over 4,000 real-world trajectories.

Result: LLMs outperform off-the-shelf baselines and specialized trajectory recovery models in trajectory recovery, showing strong zero-shot generalization. Identified systematic biases with respect to regions and transportation modes.

Conclusion: LLMs demonstrate strong comprehension of road networks and coordinate systems for navigation tasks, and can be used to enhance navigation experiences by incorporating user preferences, despite existing biases.

Abstract: We explore the geospatial reasoning capabilities of Large Language Models
(LLMs), specifically, whether LLMs can read road network maps and perform
navigation. We frame trajectory recovery as a proxy task, which requires models
to reconstruct masked GPS traces, and introduce GLOBALTRACE, a dataset with
over 4,000 real-world trajectories across diverse regions and transportation
modes. Using road network as context, our prompting framework enables LLMs to
generate valid paths without accessing any external navigation tools.
Experiments show that LLMs outperform off-the-shelf baselines and specialized
trajectory recovery models, with strong zero-shot generalization. Fine-grained
analysis shows that LLMs have strong comprehension of the road network and
coordinate systems, but also pose systematic biases with respect to regions and
transportation modes. Finally, we demonstrate how LLMs can enhance navigation
experiences by reasoning over maps in flexible ways to incorporate user
preferences.

</details>


### [220] [GuruAgents: Emulating Wise Investors with Prompt-Guided LLM Agents](https://arxiv.org/abs/2510.01664)
*Yejin Kim,Youngbin Lee,Juhyeong Kim,Yongjae Lee*

Main category: cs.AI

TL;DR: AI代理GuruAgents可以通过提示词来模仿投资大师的策略，并在回测中表现出独特的行为，其中巴菲特代理表现最佳。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索如何将投资大师的定性投资理念转化为可量化的、可复现的投资策略，并验证提示工程在其中起到的作用。

Method: 开发了五个模仿不同投资大师的AI代理（GuruAgents），通过将大师的投资哲学编码到LLM提示词中，并结合金融工具和确定性推理流程。在2023年第四季度至2025年第二季度的NASDAQ-100成分股上进行了回测。

Result: GuruAgents在回测中展现了独特的行为，其中模仿巴菲特的大师代理实现了42.2%的复合年增长率，显著优于基准，其他代理表现各异。

Conclusion: 提示工程能够成功地将投资大师的定性哲学转化为可复现的量化策略，为自动化系统化投资提供了新的方向。

Abstract: This study demonstrates that GuruAgents, prompt-guided AI agents, can
systematically operationalize the strategies of legendary investment gurus. We
develop five distinct GuruAgents, each designed to emulate an iconic investor,
by encoding their distinct philosophies into LLM prompts that integrate
financial tools and a deterministic reasoning pipeline. In a backtest on
NASDAQ-100 constituents from Q4 2023 to Q2 2025, the GuruAgents exhibit unique
behaviors driven by their prompted personas. The Buffett GuruAgent achieves the
highest performance, delivering a 42.2\% CAGR that significantly outperforms
benchmarks, while other agents show varied results. These findings confirm that
prompt engineering can successfully translate the qualitative philosophies of
investment gurus into reproducible, quantitative strategies, highlighting a
novel direction for automated systematic investing. The source code and data
are available at https://github.com/yejining99/GuruAgents.

</details>


### [221] [Just Do It!? Computer-Use Agents Exhibit Blind Goal-Directedness](https://arxiv.org/abs/2510.01670)
*Erfan Shayegani,Keegan Hines,Yue Dong,Nael Abu-Ghazaleh,Roman Lutz,Spencer Whitehead,Vidhisha Balachandran,Besmira Nushi,Vibhav Vineet*

Main category: cs.AI

TL;DR: 计算机使用代理（CUAs）倾向于盲目地追求目标，即使在不可行、不安全或不可靠的情况下。我们提出了一个名为BLIND-ACT的基准来测试这种盲目目标导向（BGD）现象，并在九个模型上进行了测试，发现BGD普遍存在。


<details>
  <summary>Details</summary>
Motivation: 为了识别和解决计算机使用代理（CUAs）在执行任务时表现出的盲目目标导向（BGD）问题，即代理会不顾可行性、安全性、可靠性或上下文而盲目追求目标。

Method: 我们首先定义和描述了BGD的三种常见模式：缺乏上下文推理、处理歧义时的假设和决策、以及矛盾或不可行的目标。然后，我们开发了一个名为BLIND-ACT的基准，包含90个任务，旨在捕捉这些模式。BLIND-ACT建立在OSWorld之上，提供真实的环境，并使用基于LLM的裁判来评估代理行为，其评估结果与人类注释的一致性达到93.75%。最后，我们使用BLIND-ACT评估了包括Claude Sonnet和Opus 4、Computer-Use-Preview和GPT-5在内的九个前沿模型。

Result: 在对九个前沿模型（包括Claude Sonnet和Opus 4、Computer-Use-Preview和GPT-5）的评估中，我们观察到平均BGD率高达80.8%。这表明BGD是一个普遍存在的问题。此外，我们发现提示工程虽然能降低BGD水平，但仍有显著风险存在。定性分析揭示了三种主要的失败模式：执行优先偏差（过于关注如何行动而非是否行动）、思考-行动脱节（执行与推理不符）以及请求优先（行动的理由是用户的请求）。

Conclusion: 盲目目标导向（BGD）是CUAs的一个根本性风险，即使在输入并非直接有害的情况下也会暴露。虽然提示工程可以缓解BGD，但仍需要更强的训练或推理干预措施来确保CUAs的安全部署。BLIND-ACT基准的提出为未来研究和解决BGD问题奠定了基础。

Abstract: Computer-Use Agents (CUAs) are an increasingly deployed class of agents that
take actions on GUIs to accomplish user goals. In this paper, we show that CUAs
consistently exhibit Blind Goal-Directedness (BGD): a bias to pursue goals
regardless of feasibility, safety, reliability, or context. We characterize
three prevalent patterns of BGD: (i) lack of contextual reasoning, (ii)
assumptions and decisions under ambiguity, and (iii) contradictory or
infeasible goals. We develop BLIND-ACT, a benchmark of 90 tasks capturing these
three patterns. Built on OSWorld, BLIND-ACT provides realistic environments and
employs LLM-based judges to evaluate agent behavior, achieving 93.75% agreement
with human annotations. We use BLIND-ACT to evaluate nine frontier models,
including Claude Sonnet and Opus 4, Computer-Use-Preview, and GPT-5, observing
high average BGD rates (80.8%) across them. We show that BGD exposes subtle
risks that arise even when inputs are not directly harmful. While
prompting-based interventions lower BGD levels, substantial risk persists,
highlighting the need for stronger training- or inference-time interventions.
Qualitative analysis reveals observed failure modes: execution-first bias
(focusing on how to act over whether to act), thought-action disconnect
(execution diverging from reasoning), and request-primacy (justifying actions
due to user request). Identifying BGD and introducing BLIND-ACT establishes a
foundation for future research on studying and mitigating this fundamental risk
and ensuring safe CUA deployment.

</details>


### [222] [A Locally Executable AI System for Improving Preoperative Patient Communication: A Multi-Domain Clinical Evaluation](https://arxiv.org/abs/2510.01671)
*Motoki Sato,Yuki Matsushita,Hidekazu Takahashi,Tomoaki Kakazu,Sou Nagata,Mizuho Ohnuma,Atsushi Yoshikawa,Masayuki Yamamura*

Main category: cs.AI

TL;DR: LENOHA系统通过句子转换器分类器将问题与预先批准的FAQ答案进行匹配，避免了生成式AI在临床路径中的使用，从而实现了低能耗、高精度和对患者的个性化咨询。


<details>
  <summary>Details</summary>
Motivation: 患者在接受侵入性手术前常常有未解答的疑问，但时间紧迫的工作流程和隐私限制阻碍了个性化咨询。

Method: LENOHA（低能耗、无幻觉、不遗漏架构）是一个安全优先、本地优先的系统。它使用高精度句子转换器分类器来路由输入，并从临床医生策划的FAQ中提取逐字答案，从而在临床路径中消除了自由文本生成。

Result: 在两个领域（拔牙和胃镜检查）的评估中，E5-large-instruct编码器达到了0.983的准确率，AUC为0.996，仅有七个错误，与GPT-4o的表现相当，而Gemini在该测试集中没有错误。LENOHA的临床路径能耗约为每输入1.0 mWh，远低于本地8B SLM的小对话回复（约168 mWh），延迟约为0.10秒。

Conclusion: LENOHA系统通过逐字返回经过审核的FAQ答案，在临床路径中避免了生成式AI可能带来的错误，并支持了隐私、可持续性和在带宽受限环境中的公平部署。

Abstract: Patients awaiting invasive procedures often have unanswered pre-procedural
questions; however, time-pressured workflows and privacy constraints limit
personalized counseling. We present LENOHA (Low Energy, No Hallucination, Leave
No One Behind Architecture), a safety-first, local-first system that routes
inputs with a high-precision sentence-transformer classifier and returns
verbatim answers from a clinician-curated FAQ for clinical queries, eliminating
free-text generation in the clinical path. We evaluated two domains (tooth
extraction and gastroscopy) using expert-reviewed validation sets
(n=400/domain) for thresholding and independent test sets (n=200/domain). Among
the four encoders, E5-large-instruct (560M) achieved an overall accuracy of
0.983 (95% CI 0.964-0.991), AUC 0.996, and seven total errors, which were
statistically indistinguishable from GPT-4o on this task; Gemini made no errors
on this test set. Energy logging shows that the non-generative clinical path
consumes ~1.0 mWh per input versus ~168 mWh per small-talk reply from a local
8B SLM, a ~170x difference, while maintaining ~0.10 s latency on a single
on-prem GPU. These results indicate that near-frontier discrimination and
generation-induced errors are structurally avoided in the clinical path by
returning vetted FAQ answers verbatim, supporting privacy, sustainability, and
equitable deployment in bandwidth-limited environments.

</details>


### [223] [Improving AGI Evaluation: A Data Science Perspective](https://arxiv.org/abs/2510.01687)
*John Hawkins*

Main category: cs.AI

TL;DR: AGI的评估方法应从基于直觉的合成任务转向更注重实际任务执行能力的评估。


<details>
  <summary>Details</summary>
Motivation: 当前AGI评估方法受限于工程目标的广泛性，且缺乏完美的终态评估手段，导致依赖于模拟测试，但这些测试在AI历史上表现不佳。

Method: 提出了一种新的AGI评估设计理念，该理念借鉴了数据科学中用于确保系统可靠部署的实践，注重评估鲁棒的任务执行能力，以展示AGI的能力。

Result: 提供了一些实际的AGI评估案例，说明如何通过实际任务执行能力来评估AGI。

Conclusion: 强调AGI评估应通过实际能力的展示来体现其智能水平，而非仅仅依赖于模拟测试。

Abstract: Evaluation of potential AGI systems and methods is difficult due to the
breadth of the engineering goal. We have no methods for perfect evaluation of
the end state, and instead measure performance on small tests designed to
provide directional indication that we are approaching AGI. In this work we
argue that AGI evaluation methods have been dominated by a design philosophy
that uses our intuitions of what intelligence is to create synthetic tasks,
that have performed poorly in the history of AI. Instead we argue for an
alternative design philosophy focused on evaluating robust task execution that
seeks to demonstrate AGI through competence. This perspective is developed from
common practices in data science that are used to show that a system can be
reliably deployed. We provide practical examples of what this would mean for
AGI evaluation.

</details>


### [224] [VaPR -- Vision-language Preference alignment for Reasoning](https://arxiv.org/abs/2510.01700)
*Rohan Wadhawan,Fabrice Y Harel-Canada,Zi-Yi Dou,Suhaila Shakiah,Robinson Piramuthu,Nanyun Peng*

Main category: cs.AI

TL;DR: DPO等偏好微调方法在使大型视觉语言模型（LVLMs）与人类偏好对齐方面显示出前景。然而，现有技术忽视了合成偏好标注中存在的风格和长度偏差等噪声。为此，我们引入了一个基于LLM指导的响应编辑的硬负响应生成框架，该框架生成具有目标错误的拒绝响应，并与接受的响应在风格和长度上保持相似性。我们利用这个框架开发了VaPR数据集，包含30K高质量样本，用于微调三个LVLM家族：LLaVA-V1.5、Qwen2VL和Qwen2.5VL（2B-13B参数）。我们的VaPR模型在十个基准测试中取得了显著的性能提升，LLaVA、Qwen2VL和Qwen2.5VL的平均增幅分别为6.5%、4.0%和1.5%，在推理任务上提升尤为明显。通过扩展性分析表明，性能随着数据量的增加而持续提高，并且LLaVA模型在较小的数据量下也能受益。此外，VaPR减少了LVLMs（如LLaVA）在回答二元问题时倾向于回答“是”的现象。最后，我们证明了该框架可以泛化到开源LLMs作为编辑器，使用GPT-4o合成的VaPR-OS模型达到了使用GPT-4o合成的数据训练的模型的约99%的性能。


<details>
  <summary>Details</summary>
Motivation: 现有偏好微调方法（如DPO）在使LVLMs与人类偏好对齐方面存在不足，忽略了合成偏好标注中的风格和长度偏差等噪声问题。

Method: 提出了一种基于LLM指导的响应编辑的硬负响应生成框架，用于生成带有目标错误的、风格和长度与正确响应相似的负面响应。并以此框架构建了VaPR数据集（30K样本），用于微调LLaVA-V1.5、Qwen2VL和Qwen2.5VL模型。

Result: 所提出的VaPR模型在十个基准测试中显著提升了性能，LLaVA、Qwen2VL和Qwen2.5VL模型的平均性能分别提升了6.5%、4.0%和1.5%，尤其是在推理任务上。扩展性分析表明性能随数据量增加而提升。VaPR还能减少LVLMs在二元问题中回答“是”的倾向。该框架可泛化至开源LLMs，VaPR-OS模型性能可达使用GPT-4o合成数据的模型的99%。

Conclusion: 我们提出的VaPR框架通过生成高质量的硬负样本，有效解决了合成偏好数据中的噪声问题，显著提升了LVLMs的性能，并解决了某些常见的模型行为偏差。该框架具有良好的泛化性和扩展性。

Abstract: Preference finetuning methods like Direct Preference Optimization (DPO) with
AI-generated feedback have shown promise in aligning Large Vision-Language
Models (LVLMs) with human preferences. However, existing techniques overlook
the prevalence of noise in synthetic preference annotations in the form of
stylistic and length biases. To this end, we introduce a hard-negative response
generation framework based on LLM-guided response editing, that produces
rejected responses with targeted errors, maintaining stylistic and length
similarity to the accepted ones. Using this framework, we develop the VaPR
dataset, comprising 30K high-quality samples, to finetune three LVLM families:
LLaVA-V1.5, Qwen2VL & Qwen2.5VL (2B-13B sizes). Our VaPR models deliver
significant performance improvements across ten benchmarks, achieving average
gains of 6.5% (LLaVA), 4.0% (Qwen2VL), and 1.5% (Qwen2.5VL), with notable
improvements on reasoning tasks. A scaling analysis shows that performance
consistently improves with data size, with LLaVA models benefiting even at
smaller scales. Moreover, VaPR reduces the tendency to answer "Yes" in binary
questions - addressing a common failure mode in LVLMs like LLaVA. Lastly, we
show that the framework generalizes to open-source LLMs as editors, with models
trained on VaPR-OS achieving ~99% of the performance of models trained on
\name, which is synthesized using GPT-4o. Our data, models, and code can be
found on the project page https://vap-r.github.io

</details>


### [225] [MetaboT: AI-based agent for natural language-based interaction with metabolomics knowledge graphs](https://arxiv.org/abs/2510.01724)
*Madina Bekbergenova,Lucas Pradi,Benjamin Navet,Emma Tysinger,Franck Michel,Matthieu Feraud,Yousouf Taghzouti,Yan Zhou Chen,Olivier Kirchhoffer,Florence Mehl,Martin Legrand,Tao Jiang,Marco Pagni,Soha Hassoun,Jean-Luc Wolfender,Wout Bittremieux,Fabien Gandon,Louis-Félix Nothias*

Main category: cs.AI

TL;DR: MetaboT是一个利用大型语言模型（LLM）将用户问题转化为SPARQL查询的AI系统，用于操作知识图谱，提高了代谢组学数据的可访问性。


<details>
  <summary>Details</summary>
Motivation: 代谢组学产生大量数据，需要先进的解释方法。虽然知识图谱（KG）可以结构化数据，但其本体和查询语言的复杂性阻碍了有效使用。

Method: MetaboT使用多智能体系统，包括入口智能体、验证智能体、主管智能体和知识图谱智能体，将用户问题分解并转化为SPARQL查询。它利用LangChain和LangGraph库，并与ENPKG知识图谱集成。

Result: 在50个代谢组学问题的数据集上，MetaboT的准确率为83.67%，而仅使用标准LLM（GPT-4o）的基线准确率仅为8.16%。

Conclusion: MetaboT通过自动化SPARQL查询生成和执行，显著提高了研究人员通过自然语言查询访问代谢组学数据的能力，降低了技术门槛，并促进了数据驱动的发现。

Abstract: Mass spectrometry metabolomics generates vast amounts of data requiring
advanced methods for interpretation. Knowledge graphs address these challenges
by structuring mass spectrometry data, metabolite information, and their
relationships into a connected network (Gaudry et al. 2024). However, effective
use of a knowledge graph demands an in-depth understanding of its ontology and
its query language syntax. To overcome this, we designed MetaboT, an AI system
utilizing large language models (LLMs) to translate user questions into SPARQL
semantic query language for operating on knowledge graphs (Steve Harris 2013).
We demonstrate its effectiveness using the Experimental Natural Products
Knowledge Graph (ENPKG), a large-scale public knowledge graph for plant natural
products (Gaudry et al. 2024).MetaboT employs specialized AI agents for
handling user queries and interacting with the knowledge graph by breaking down
complex tasks into discrete components, each managed by a specialised agent
(Fig. 1a). The multi-agent system is constructed using the LangChain and
LangGraph libraries, which facilitate the integration of LLMs with external
tools and information sources (LangChain, n.d.). The query generation process
follows a structured workflow. First, the Entry Agent determines if the
question is new or a follow-up to previous interactions. New questions are
forwarded to the Validator Agent, which verifies if the question is related to
the knowledge graph. Then, the valid question is sent to the Supervisor Agent,
which identifies if the question requires chemical conversions or standardized
identifiers. In this case it delegates the question to the Knowledge Graph
Agent, which can use tools to extract necessary details, such as URIs or
taxonomies of chemical names, from the user query. Finally, an agent
responsible for crafting the SPARQL queries equipped with the ontology of the
knowledge graph uses the provided identifiers to generate the query. Then, the
system executes the generated query against the metabolomics knowledge graph
and returns structured results to the user (Fig. 1b). To assess the performance
of MetaboT we have curated 50 metabolomics-related questions and their expected
answers. In addition to submitting these questions to MetaboT, we evaluated a
baseline by submitting them to a standard LLM (GPT-4o) with a prompt that
incorporated the knowledge graph ontology but did not provide specific entity
IDs. This baseline achieved only 8.16% accuracy, compared to MetaboT's 83.67%,
underscoring the necessity of our multi-agent system for accurately retrieving
entities and generating correct SPARQL queries. MetaboT demonstrates promising
performance as a conversational question-answering assistant, enabling
researchers to retrieve structured metabolomics data through natural language
queries. By automating the generation and execution of SPARQL queries, it
removes technical barriers that have traditionally hindered access to knowledge
graphs. Importantly, MetaboT leverages the capabilities of LLMs while
maintaining experimentally grounded query generation, ensuring that outputs
remain aligned with domain-specific standards and data structures. This
approach facilitates data-driven discoveries by bridging the gap between
complex semantic technologies and user-friendly interaction. MetaboT is
accessible at [https://metabot.holobiomicslab.eu/], and its source code is
available at [https://github.com/HolobiomicsLab/MetaboT].

</details>


### [226] [A cybersecurity AI agent selection and decision support framework](https://arxiv.org/abs/2510.01751)
*Masike Malatji*

Main category: cs.AI

TL;DR: 该研究提出了一个结构化的决策支持框架，将不同类型的人工智能（AI）代理（反应式、认知式、混合式、学习式）与美国国家标准与技术研究院（NIST）网络安全框架（CSF）2.0进行系统性匹配，以应对网络威胁。


<details>
  <summary>Details</summary>
Motivation: 为了系统性地将多样化的人工智能（AI）代理架构与NIST网络安全框架（CSF）2.0进行整合，为选择和部署AI解决方案提供一个透明、分步的方法，以应对当代的网络威胁。

Method: 通过将代理理论与行业指南相结合，对NIST CSF 2.0的功能进行细粒度分解，将AI代理的关键特性（如自主性、自适应学习、实时响应能力）与其安全需求关联起来，并提出分级自主性水平（辅助、增强、完全自主）。

Result: 概念验证表明，该框架能够实现定制化的AI代理部署，以适应实际约束和风险状况，从而提高态势感知能力，加快响应速度，并通过自适应风险管理来增强长期弹性。

Conclusion: 该研究弥合了理论AI构建与实际网络安全需求之间的差距，为构建符合行业标准的、经过实证验证的多代理系统奠定了基础。

Abstract: This paper presents a novel, structured decision support framework that
systematically aligns diverse artificial intelligence (AI) agent architectures,
reactive, cognitive, hybrid, and learning, with the comprehensive National
Institute of Standards and Technology (NIST) Cybersecurity Framework (CSF) 2.0.
By integrating agent theory with industry guidelines, this framework provides a
transparent and stepwise methodology for selecting and deploying AI solutions
to address contemporary cyber threats. Employing a granular decomposition of
NIST CSF 2.0 functions into specific tasks, the study links essential AI agent
properties such as autonomy, adaptive learning, and real-time responsiveness to
each subcategory's security requirements. In addition, it outlines graduated
levels of autonomy (assisted, augmented, and fully autonomous) to accommodate
organisations at varying stages of cybersecurity maturity. This holistic
approach transcends isolated AI applications, providing a unified detection,
incident response, and governance strategy. Through conceptual validation, the
framework demonstrates how tailored AI agent deployments can align with
real-world constraints and risk profiles, enhancing situational awareness,
accelerating response times, and fortifying long-term resilience via adaptive
risk management. Ultimately, this research bridges the gap between theoretical
AI constructs and operational cybersecurity demands, establishing a foundation
for robust, empirically validated multi-agent systems that adhere to industry
standards.

</details>


### [227] [REBot: From RAG to CatRAG with Semantic Enrichment and Graph Routing](https://arxiv.org/abs/2510.01800)
*Thanh Ma,Tri-Tam La,Lam-Thu Le Huu,Minh-Nghi Nguyen,Khanh-Van Pham Luu,Huu-Hoa Nguyen*

Main category: cs.AI

TL;DR: REBot是一个利用CatRAG（一种结合检索增强生成和图谱推理的混合框架）的LLM增强的学术咨询聊天机器人，旨在帮助学生理解和遵守学术规定。CatRAG整合了密集检索和基于图谱的推理，并通过分层、类别标签的知识图谱进行增强，该图谱还包含了用于领域对齐的语义特征。一个轻量级的意图分类器将查询路由到相应的检索模块，以确保事实准确性和上下文深度。在分类和问答任务的评估中，REBot取得了98.89%的F1分数，达到最先进的性能。此外，还开发了一个Web应用程序，以展示REBot在实际学术咨询中的应用价值。


<details>
  <summary>Details</summary>
Motivation: 学术咨询指导对帮助学生解读和遵守制度政策至关重要，但构建有效的系统需要特定领域的监管资源。本研究旨在解决这一挑战。

Method: 提出了一种名为REBot的LLM增强型咨询聊天机器人，该机器人由CatRAG驱动。CatRAG是一个混合检索推理框架，集成了检索增强生成（RAG）和基于图谱的推理。CatRAG统一了密集检索和图谱推理，并辅以一个分层、类别标签的知识图谱，该图谱包含用于领域对齐的语义特征。一个轻量级的意图分类器将查询路由到适当的检索模块，以确保事实准确性和上下文深度。构建了一个特定于法规的数据集。

Result: 在分类和问答任务的评估中，REBot取得了98.89%的F1分数，达到了最先进的性能。

Conclusion: REBot是一个有效的LLM增强型学术咨询聊天机器人，通过CatRAG框架在学术规定咨询方面取得了最先进的性能，并已通过Web应用程序进行了实际应用展示。

Abstract: Academic regulation advising is essential for helping students interpret and
comply with institutional policies, yet building effective systems requires
domain specific regulatory resources. To address this challenge, we propose
REBot, an LLM enhanced advisory chatbot powered by CatRAG, a hybrid retrieval
reasoning framework that integrates retrieval augmented generation with graph
based reasoning. CatRAG unifies dense retrieval and graph reasoning, supported
by a hierarchical, category labeled knowledge graph enriched with semantic
features for domain alignment. A lightweight intent classifier routes queries
to the appropriate retrieval modules, ensuring both factual accuracy and
contextual depth. We construct a regulation specific dataset and evaluate REBot
on classification and question answering tasks, achieving state of the art
performance with an F1 score of 98.89%. Finally, we implement a web application
that demonstrates the practical value of REBot in real world academic advising
scenarios.

</details>


### [228] [Human-AI Teaming Co-Learning in Military Operations](https://arxiv.org/abs/2510.01815)
*Clara Maathuis,Kasper Cools*

Main category: cs.AI

TL;DR: 该研究提出了一个用于军事行动中人机协作的


<details>
  <summary>Details</summary>
Motivation: 当前对人机协作系统的理解和应对方法多是从外部视角进行的，

Method: 该研究提出了一个包含四个维度的可信赖的协同学习模型：1. 可调整的自主性，

Result: 该模型通过集成四个维度，能够实现人与AI之间持续且双向的见解交流，

Conclusion: 该研究提出的可信赖协同学习模型为负责任且可信赖的人机协作系统在军事行动中的进一步发展提供了具体示例和建议。

Abstract: In a time of rapidly evolving military threats and increasingly complex
operational environments, the integration of AI into military operations proves
significant advantages. At the same time, this implies various challenges and
risks regarding building and deploying human-AI teaming systems in an effective
and ethical manner. Currently, understanding and coping with them are often
tackled from an external perspective considering the human-AI teaming system as
a collective agent. Nevertheless, zooming into the dynamics involved inside the
system assures dealing with a broader palette of relevant multidimensional
responsibility, safety, and robustness aspects. To this end, this research
proposes the design of a trustworthy co-learning model for human-AI teaming in
military operations that encompasses a continuous and bidirectional exchange of
insights between the human and AI agents as they jointly adapt to evolving
battlefield conditions. It does that by integrating four dimensions. First,
adjustable autonomy for dynamically calibrating the autonomy levels of agents
depending on aspects like mission state, system confidence, and environmental
uncertainty. Second, multi-layered control which accounts continuous oversight,
monitoring of activities, and accountability. Third, bidirectional feedback
with explicit and implicit feedback loops between the agents to assure a proper
communication of reasoning, uncertainties, and learned adaptations that each of
the agents has. And fourth, collaborative decision-making which implies the
generation, evaluation, and proposal of decisions associated with confidence
levels and rationale behind them. The model proposed is accompanied by concrete
exemplifications and recommendations that contribute to further developing
responsible and trustworthy human-AI teaming systems in military operations.

</details>


### [229] [Plan Then Action:High-Level Planning Guidance Reinforcement Learning for LLM Reasoning](https://arxiv.org/abs/2510.01833)
*Zhihao Dou,Qinjian Zhao,Zhongwei Wan,Dinggen Zhang,Weida Wang,Towsif Raiyan,Benteng Chen,Qingtao Pan,Yang Ouyang,Zhiqiang Gao,Shufei Zhang,Sumon Biswas*

Main category: cs.AI

TL;DR: LLMs的推理受限于局部决策，导致冗余、不连贯或不准确。PTA-GRPO框架通过规划和增强的CoT推理，提升了LLM的推理能力，并在多个数学推理基准上取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: LLMs的自回归生成方式限制了推理的全局规划能力，导致生成结果不佳，现有方法计算成本高且不总能找到最优推理路径。

Method: PTA-GRPO是一个两阶段框架：第一阶段利用LLMs将CoT提炼为高层指导，用于SFT；第二阶段采用引导感知RL方法，联合优化最终输出和高层指导的质量。

Result: PTA-GRPO在MATH, AIME2024, AIME2025, AMC等多个数学推理基准上，对Qwen2.5-7B-Instruct, Qwen3-8B, Qwen3-14B, LLaMA3.2-3B等模型进行了广泛实验，结果显示PTA-GRPO在不同模型和任务上均实现了稳定且显著的提升。

Conclusion: PTA-GRPO框架能够有效提升LLMs的推理能力，并在各项数学推理任务中表现出良好的泛化性。

Abstract: Large language models (LLMs) have demonstrated remarkable reasoning abilities
in complex tasks, often relying on Chain-of-Thought (CoT) reasoning. However,
due to their autoregressive token-level generation, the reasoning process is
largely constrained to local decision-making and lacks global planning. This
limitation frequently results in redundant, incoherent, or inaccurate
reasoning, which significantly degrades overall performance. Existing
approaches, such as tree-based algorithms and reinforcement learning (RL),
attempt to address this issue but suffer from high computational costs and
often fail to produce optimal reasoning trajectories. To tackle this challenge,
we propose Plan-Then-Action Enhanced Reasoning with Group Relative Policy
Optimization PTA-GRPO, a two-stage framework designed to improve both
high-level planning and fine-grained CoT reasoning. In the first stage, we
leverage advanced LLMs to distill CoT into compact high-level guidance, which
is then used for supervised fine-tuning (SFT). In the second stage, we
introduce a guidance-aware RL method that jointly optimizes the final output
and the quality of high-level guidance, thereby enhancing reasoning
effectiveness. We conduct extensive experiments on multiple mathematical
reasoning benchmarks, including MATH, AIME2024, AIME2025, and AMC, across
diverse base models such as Qwen2.5-7B-Instruct, Qwen3-8B, Qwen3-14B, and
LLaMA3.2-3B. Experimental results demonstrate that PTA-GRPO consistently
achieves stable and significant improvements across different models and tasks,
validating its effectiveness and generalization.

</details>


### [230] [Learning a Dense Reasoning Reward Model from Expert Demonstration via Inverse Reinforcement Learning](https://arxiv.org/abs/2510.01857)
*Claudio Fanconi,Nicolás Astorga,Mihaela van der Schaar*

Main category: cs.AI

TL;DR: 本文将对抗性逆强化学习（IRL）应用于大语言模型推理，直接从专家演示中学习密集的、token级别的奖励模型，用于过程监督，而不是通过监督微调来模仿风格。


<details>
  <summary>Details</summary>
Motivation: 将对抗性逆强化学习（IRL）应用于大语言模型推理，以学习过程监督的密集、token级别奖励模型。

Method: 通过逆强化学习（IRL）直接从专家演示中学习token级别的奖励模型，该奖励模型用于训练过程中的策略优化和推理时的候选重排。

Result: 在GSM8K数据集上，使用Llama3和Qwen2.5模型进行实验，证明了密集推理奖励可以作为学习信号来引导推理过程，并且通过奖励指导的重排可以提高预测性能（尤其是在Llama模型上）。

Conclusion: 通过将训练信号、推理选择和token级别诊断统一到单一的推理奖励中，这项工作提出了可重用的过程级奖励，有望增强语言模型的推理能力。

Abstract: We reframe and operationalise adversarial inverse reinforcement learning
(IRL) to large language model reasoning, learning a dense, token-level reward
model for process supervision directly from expert demonstrations rather than
imitating style via supervised fine-tuning. The learned reasoning reward serves
two complementary roles: (i) it provides step-level feedback to optimise a
reasoning policy during training; and (ii) it functions at inference as a
critic to rerank sampled traces under fixed compute budgets. We demonstrate
that our approach prioritises correctness over surface form, yielding scores
that correlate with eventual answer validity and enabling interpretable
localisation of errors within a trace. Empirically, on GSM8K with Llama3 and
Qwen2.5 backbones, we demonstrate: (i) dense reasoning rewards can be used as a
learning signal to elicit reasoning, and (ii) predictive performance is
improved from reward-guided reranking (notably for Llama-based policies). By
unifying training signals, inference-time selection, and token-level
diagnostics into a single reasoning reward, this work suggests reusable
process-level rewards with broad potential to enhance multi-step reasoning in
language models.

</details>


### [231] [Constrained Adaptive Rejection Sampling](https://arxiv.org/abs/2510.01902)
*Paweł Parys,Sairam Vaidya,Taylor Berg-Kirkpatrick,Loris D'Antoni*

Main category: cs.AI

TL;DR: CARS是一种通过自适应地排除违反约束的后续部分来改进拒绝采样（RS）的样本效率的方法，同时保持原始语言模型的分布。


<details>
  <summary>Details</summary>
Motivation: 需要一种既能满足严格的语义或语法约束，又能保持语言模型分布的生成方法，尤其是在程序模糊测试等需要有效性和多样性的领域。

Method: CARS从无约束的语言模型采样开始，通过记录并从后续抽样中减去违反约束的后续部分的概率质量来动态排除它们。

Result: 在程序模糊测试和分子生成等领域，CARS在每生成一个有效样本所需的语言模型前向传播次数方面，比约束解码和近似分布的方法更有效，同时还能产生更强的样本多样性。

Conclusion: CARS在不扭曲分布的情况下，能够严格提高拒绝采样的样本效率，并在多个领域实现了比现有方法更高的效率和样本多样性。

Abstract: Language Models (LMs) are increasingly used in applications where generated
outputs must satisfy strict semantic or syntactic constraints. Existing
approaches to constrained generation fall along a spectrum: greedy constrained
decoding methods enforce validity during decoding but distort the LM's
distribution, while rejection sampling (RS) preserves fidelity but wastes
computation by discarding invalid outputs. Both extremes are problematic in
domains such as program fuzzing, where both validity and diversity of samples
are essential. We present Constrained Adaptive Rejection Sampling (CARS), an
approach that strictly improves the sample-efficiency of RS without
distributional distortion. CARS begins with unconstrained LM sampling and
adaptively rules out constraint-violating continuations by recording them in a
trie and subtracting their probability mass from future draws. This adaptive
pruning ensures that prefixes proven invalid are never revisited, acceptance
rates improve monotonically, and the resulting samples exactly follow the
constrained distribution. In experiments on a variety of domains -- e.g.,
program fuzzing and molecular generation -- CARS consistently achieves higher
efficiency -- measured in the number of LM forward passes per valid sample --
while also producing stronger sample diversity than both GCD and methods that
approximate the LM's distribution.

</details>


### [232] [ReTabAD: A Benchmark for Restoring Semantic Context in Tabular Anomaly Detection](https://arxiv.org/abs/2510.02060)
*Sanghyu Yoon,Dongmin Kim,Suhee Yoon,Ye Seul Sim,Seungdong Yoa,Hye-Seung Cho,Soonyoung Lee,Hankook Lee,Woohyung Lim*

Main category: cs.AI

TL;DR: 该研究提出了ReTabAD，一个包含文本元数据的表格异常检测基准，并展示了如何利用这些信息来改进检测性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的表格异常检测基准缺乏文本语义信息，而这些信息对于理解领域特定上下文至关重要，限制了模型利用领域知识的能力。

Method: 构建了一个包含20个经过精心挑选的表格数据集的基准，并添加了结构化的文本元数据。实现了包括经典、深度学习和基于LLM的方法在内的多种异常检测算法。提出了一个零样本LLM框架，无需针对性训练即可利用语义上下文。

Result: 实验表明，语义上下文能够提升异常检测的性能，并通过支持面向领域的推理来增强可解释性。

Conclusion: ReTabAD基准为系统性地探索上下文感知的异常检测提供了基础，表明文本元数据在表格异常检测中具有重要作用和实用价值。

Abstract: In tabular anomaly detection (AD), textual semantics often carry critical
signals, as the definition of an anomaly is closely tied to domain-specific
context. However, existing benchmarks provide only raw data points without
semantic context, overlooking rich textual metadata such as feature
descriptions and domain knowledge that experts rely on in practice. This
limitation restricts research flexibility and prevents models from fully
leveraging domain knowledge for detection. ReTabAD addresses this gap by
restoring textual semantics to enable context-aware tabular AD research. We
provide (1) 20 carefully curated tabular datasets enriched with structured
textual metadata, together with implementations of state-of-the-art AD
algorithms including classical, deep learning, and LLM-based approaches, and
(2) a zero-shot LLM framework that leverages semantic context without
task-specific training, establishing a strong baseline for future research.
Furthermore, this work provides insights into the role and utility of textual
metadata in AD through experiments and analysis. Results show that semantic
context improves detection performance and enhances interpretability by
supporting domain-aware reasoning. These findings establish ReTabAD as a
benchmark for systematic exploration of context-aware AD.

</details>


### [233] [Demystifying the Roles of LLM Layers in Retrieval, Knowledge, and Reasoning](https://arxiv.org/abs/2510.02091)
*Xinyuan Song,Keyu Wang,PengXiang Li,Lu Yin,Shiwei Liu*

Main category: cs.AI

TL;DR: LLM的更深层在表示学习中的作用有限，但其重要性取决于评估方式。单纯的 Likelihood 评估表明只有浅层是关键，而生成任务的评估则揭示了中深层在推理和长距离连贯性方面的重要性。知识和检索集中在浅层，而推理能力则依赖深层，但可通过蒸馏改变。


<details>
  <summary>Details</summary>
Motivation: 虽然有研究表明LLM的更深层对表示学习的贡献不大，并且可以被移除而不会显著降低性能，但这些发现通常基于狭隘的评估，可能忽略了模型行为的重要方面。因此，需要一个系统性的研究来全面理解LLM的深度利用情况。

Method: 对LLM的深度利用进行了跨越不同评估协议、任务类别和模型架构的系统性研究。

Result: 研究证实，与较浅的层相比，非常深的层通常效果较差，但其贡献因评估环境而异。在仅基于 Likelihood 的评估（不涉及生成）中，移除大部分层而保留浅层可以维持性能。然而，在基于生成的评估中，中层和深层在实现推理和维持长距离连贯性方面发挥着不可或缺的作用。此外，研究发现知识和检索主要集中在浅层组件中，而推理的准确性则严重依赖于深层，但可以通过蒸馏进行重塑。

Conclusion: LLM的深度利用具有高度异质性和情境依赖性。这强调了在解释和压缩大型模型时，需要采用考虑任务、评估指标和模型特性的方法。

Abstract: Recent studies suggest that the deeper layers of Large Language Models (LLMs)
contribute little to representation learning and can often be removed without
significant performance loss. However, such claims are typically drawn from
narrow evaluations and may overlook important aspects of model behavior. In
this work, we present a systematic study of depth utilization across diverse
dimensions, including evaluation protocols, task categories, and model
architectures. Our analysis confirms that very deep layers are generally less
effective than earlier ones, but their contributions vary substantially with
the evaluation setting. Under likelihood-based metrics without generation,
pruning most layers preserves performance, with only the initial few being
critical. By contrast, generation-based evaluation uncovers indispensable roles
for middle and deeper layers in enabling reasoning and maintaining long-range
coherence. We further find that knowledge and retrieval are concentrated in
shallow components, whereas reasoning accuracy relies heavily on deeper layers
-- yet can be reshaped through distillation. These results highlight that depth
usage in LLMs is highly heterogeneous and context-dependent, underscoring the
need for task-, metric-, and model-aware perspectives in both interpreting and
compressing large models.

</details>


### [234] [Do AI Models Perform Human-like Abstract Reasoning Across Modalities?](https://arxiv.org/abs/2510.02125)
*Claas Beger,Ryan Yi,Shuhao Fu,Arseny Moskvichev,Sarah W. Tsai,Sivasankaran Rajamanickam,Melanie Mitchell*

Main category: cs.AI

TL;DR: AI模型在抽象推理方面仍落后于人类，单独的准确性评估可能会高估或低估其能力，尤其是在不同模态下。


<details>
  <summary>Details</summary>
Motivation: 评估AI模型在ConceptARC基准测试中识别和推理抽象概念的能力，以确定它们是否像人类一样解决问题，还是依赖于表面模式。

Method: 通过改变输入模态（文本与视觉）、是否允许使用Python工具以及推理的努力程度来评估模型。除了准确性，还通过分析模型生成的自然语言规则来评估其抽象推理能力。

Result: 在文本模态下，一些模型达到了与人类相当的准确性，但它们的规则常常基于表面“捷径”，并且捕捉预期抽象概念的能力远不如人类。在视觉模态下，模型准确性显著下降，但规则分析显示它们可能被低估，因为它们仍然可以生成捕捉预期抽象概念的规则，但难以正确应用它们。

Conclusion: AI模型在抽象推理方面仍落后于人类。单独使用准确性评估ARC类任务的抽象推理能力可能会高估文本模态的能力，并低估视觉模态的能力。所提出的评估框架能更真实地反映多模态模型的抽象推理能力，并为追踪以抽象为中心的人类智能进展提供更可靠的方法。

Abstract: OpenAI's o3-preview reasoning model exceeded human accuracy on the ARC-AGI
benchmark, but does that mean state-of-the-art models recognize and reason with
the abstractions that the task creators intended? We investigate models'
abstraction abilities on ConceptARC. We evaluate models under settings that
vary the input modality (textual vs. visual), whether the model is permitted to
use external Python tools, and, for reasoning models, the amount of reasoning
effort. In addition to measuring output accuracy, we perform fine-grained
evaluation of the natural-language rules that models generate to explain their
solutions. This dual evaluation lets us assess whether models solve tasks using
the abstractions ConceptARC was designed to elicit, rather than relying on
surface-level patterns. Our results show that, while some models using
text-based representations match human output accuracy, the best models' rules
are often based on surface-level ``shortcuts'' and capture intended
abstractions far less often than humans. Thus their capabilities for general
abstract reasoning may be overestimated by evaluations based on accuracy alone.
In the visual modality, AI models' output accuracy drops sharply, yet our
rule-level analysis reveals that models might be underestimated, as they still
exhibit a substantial share of rules that capture intended abstractions, but
are often unable to correctly apply these rules. In short, our results show
that models still lag humans in abstract reasoning, and that using accuracy
alone to evaluate abstract reasoning on ARC-like tasks may overestimate
abstract-reasoning capabilities in textual modalities and underestimate it in
visual modalities. We believe that our evaluation framework offers a more
faithful picture of multimodal models' abstract reasoning abilities and a more
principled way to track progress toward human-like, abstraction-centered
intelligence.

</details>


### [235] [FlexDoc: Parameterized Sampling for Diverse Multilingual Synthetic Documents for Training Document Understanding Models](https://arxiv.org/abs/2510.02133)
*Karan Dua,Hitesh Laxmichand Patel,Puneet Mittal,Ranjeet Gupta,Amit Agarwal,Praneet Pabolu,Srikant Panda,Hansa Meghwani,Graham Horwood,Fahad Shah*

Main category: cs.AI

TL;DR: FlexDoc是一个可扩展的合成数据生成框架，通过随机模式和参数化采样生成逼真的、多语言的半结构化文档，并附有丰富的注释，从而解决了企业规模文档理解模型开发中数据集获取成本高昂的问题。


<details>
  <summary>Details</summary>
Motivation: 企业规模的文档理解模型开发需要大量、多样化且标注良好的数据集，但由于隐私、法律限制和手动标注成本高昂（可达数百万美元），收集此类数据变得不切实际。

Method: FlexDoc框架结合了随机模式（Stochastic Schemas）和参数化采样（Parameterized Sampling），通过概率模型化布局模式、视觉结构和内容变化性，以生成具有丰富注释的、逼真的、多语言的半结构化文档。

Result: 在关键信息提取（KIE）任务上的实验表明，FlexDoc生成的数据在增强真实数据集时，可以将F1分数绝对值提高高达11%，同时与传统的硬模板方法相比，标注工作量减少了90%以上。

Conclusion: FlexDoc框架通过生成可控、多样化的文档变体，显著降低了数据获取和标注成本，加速了企业级文档理解模型的开发，目前该解决方案已投入实际应用。

Abstract: Developing document understanding models at enterprise scale requires large,
diverse, and well-annotated datasets spanning a wide range of document types.
However, collecting such data is prohibitively expensive due to privacy
constraints, legal restrictions, and the sheer volume of manual annotation
needed - costs that can scale into millions of dollars. We introduce FlexDoc, a
scalable synthetic data generation framework that combines Stochastic Schemas
and Parameterized Sampling to produce realistic, multilingual semi-structured
documents with rich annotations. By probabilistically modeling layout patterns,
visual structure, and content variability, FlexDoc enables the controlled
generation of diverse document variants at scale. Experiments on Key
Information Extraction (KIE) tasks demonstrate that FlexDoc-generated data
improves the absolute F1 Score by up to 11% when used to augment real datasets,
while reducing annotation effort by over 90% compared to traditional
hard-template methods. The solution is in active deployment, where it has
accelerated the development of enterprise-grade document understanding models
while significantly reducing data acquisition and annotation costs.

</details>


### [236] [A Rigorous Benchmark with Multidimensional Evaluation for Deep Research Agents: From Answers to Reports](https://arxiv.org/abs/2510.02190)
*Yang Yao,Yixu Wang,Yuxuan Zhang,Yi Lu,Tianle Gu,Lingyu Li,Dingyi Zhao,Keming Wu,Haozhe Wang,Ping Nie,Yan Teng,Yingchun Wang*

Main category: cs.AI

TL;DR: 本篇论文提出了一种新的基准和评估框架，用于评估深度研究代理（DRAs）在处理复杂开放式任务方面的能力。


<details>
  <summary>Details</summary>
Motivation: 现有的基准在评估维度、响应格式和评分机制方面存在不足，无法有效评估像DRAs这样的互联代理系统。

Method: 引入了一个包含214个专家精心设计的挑战性查询的新基准，涵盖10个主题领域，并为每个查询构建了手动参考集。同时，提出了一种多维度评估框架，能够对DRAs生成的长篇报告进行综合评估，包括语义质量、主题焦点和检索可信度。

Result: 实验证明，主流DRAs在性能上优于增强了网络搜索工具的推理模型，但也表明DRAs仍有很大的改进空间。

Conclusion: 该研究为DRAs系统的能力评估、架构优化和范式进步提供了坚实的基础。

Abstract: Artificial intelligence is undergoing the paradigm shift from closed language
models to interconnected agent systems capable of external perception and
information integration. As a representative embodiment, Deep Research Agents
(DRAs) systematically exhibit the capabilities for task decomposition,
cross-source retrieval, multi-stage reasoning, and structured output, which
markedly enhance performance on complex and open-ended tasks. However, existing
benchmarks remain deficient in evaluation dimensions, response formatting, and
scoring mechanisms, limiting their capacity to assess such systems effectively.
This paper introduces a rigorous benchmark and a multidimensional evaluation
framework tailored to DRAs and report-style responses. The benchmark comprises
214 expert-curated challenging queries distributed across 10 broad thematic
domains, each accompanied by manually constructed reference bundles to support
composite evaluation. The framework enables comprehensive evaluation of
long-form reports generated by DRAs, incorporating integrated scoring metrics
for semantic quality, topical focus, and retrieval trustworthiness. Extensive
experimentation confirms the superior performance of mainstream DRAs over
web-search-tool-augmented reasoning models, yet reveals considerable scope for
further improvement. This study provides a robust foundation for capability
assessment, architectural refinement, and paradigm advancement in DRA systems.

</details>


### [237] [UpSafe$^\circ$C: Upcycling for Controllable Safety in Large Language Models](https://arxiv.org/abs/2510.02194)
*Yuhao Sun,Zhuoer Xu,Shiwen Cui,Kun Yang,Lingyun Yu,Yongdong Zhang,Hongtao Xie*

Main category: cs.AI

TL;DR: UpSafe$^\circ$C 通过安全感知的升级利用稀疏 MoE 结构和安全温度机制来增强 LLM 的安全性，从而在安全、效用和可控性之间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 现有的 LLM 安全技术在平衡安全性、效用和可控性方面存在局限性。

Method: 识别安全关键层并将其升级为稀疏 MoE 结构，其中路由器充当软防护栏。采用两阶段 SFT 策略来增强安全判别能力。引入安全温度机制以实现推理时的灵活控制。

Result: UpSafe$^\circ$C 在多个基准、基础模型和模型规模上实现了对有害和越狱输入的鲁棒安全改进，同时在常规任务上保持了具有竞争力的性能。安全温度提供了细粒度的推理时控制，实现了效用和安全之间的帕累托最优前沿。

Conclusion: UpSafe$^\circ$C 提出了 LLM 安全的新方向：从静态对齐转向动态、模块化和面向推理的控制。

Abstract: Large Language Models (LLMs) have achieved remarkable progress across a wide
range of tasks, but remain vulnerable to safety risks such as harmful content
generation and jailbreak attacks. Existing safety techniques -- including
external guardrails, inference-time guidance, and post-training alignment --
each face limitations in balancing safety, utility, and controllability. In
this work, we propose UpSafe$^\circ$C, a unified framework for enhancing LLM
safety through safety-aware upcycling. Our approach first identifies
safety-critical layers and upcycles them into a sparse Mixture-of-Experts (MoE)
structure, where the router acts as a soft guardrail that selectively activates
original MLPs and added safety experts. We further introduce a two-stage SFT
strategy to strengthen safety discrimination while preserving general
capabilities. To enable flexible control at inference time, we introduce a
safety temperature mechanism, allowing dynamic adjustment of the trade-off
between safety and utility. Experiments across multiple benchmarks, base model,
and model scales demonstrate that UpSafe$^\circ$C achieves robust safety
improvements against harmful and jailbreak inputs, while maintaining
competitive performance on general tasks. Moreover, analysis shows that safety
temperature provides fine-grained inference-time control that achieves the
Pareto-optimal frontier between utility and safety. Our results highlight a new
direction for LLM safety: moving from static alignment toward dynamic, modular,
and inference-aware control.

</details>


### [238] [The Reasoning Boundary Paradox: How Reinforcement Learning Constrains Language Models](https://arxiv.org/abs/2510.02230)
*Phuc Minh Nguyen,Chinh D. La,Duy M. H. Nguyen,Nitesh V. Chawla,Binh T. Nguyen,Khoa D. Doan*

Main category: cs.AI

TL;DR: RLVR 可能会缩小大型语言模型的推理边界，而不是扩大它。该研究揭示了负干扰和赢家通吃现象，并提出了一种数据整理算法来解决这些问题。


<details>
  <summary>Details</summary>
Motivation: 虽然 RLVR 被认为是提高大型语言模型推理能力的关键方法，但近期证据表明它可能会适得其反，缩小推理边界。

Method: 通过分析学习动态来揭示负干扰和赢家通吃现象，这些现象解释了 RLVR 的失败。此外，提出了一种数据整理算法来解决这些问题。

Result: 通过在多个数学推理基准上进行广泛的理论和实证分析，证明了 RLVR 的学习动态会导致模型收敛到狭窄的解决方案策略，从而降低 Pass@k 性能。所提出的数据整理算法在 Pass@k 性能方面取得了显著的改进。

Conclusion: RLVR 学习中的负干扰和赢家通吃现象是导致推理能力下降的关键原因。通过关注低可能性问题的数据整理算法可以有效缓解这些问题，并提高 Pass@k 性能。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a key
method for improving Large Language Models' reasoning capabilities, yet recent
evidence suggests it may paradoxically shrink the reasoning boundary rather
than expand it. This paper investigates the shrinkage issue of RLVR by
analyzing its learning dynamics and reveals two critical phenomena that explain
this failure. First, we expose negative interference in RLVR, where learning to
solve certain training problems actively reduces the likelihood of correct
solutions for others, leading to the decline of Pass@$k$ performance, or the
probability of generating a correct solution within $k$ attempts. Second, we
uncover the winner-take-all phenomenon: RLVR disproportionately reinforces
problems with high likelihood, correct solutions, under the base model, while
suppressing other initially low-likelihood ones. Through extensive theoretical
and empirical analysis on multiple mathematical reasoning benchmarks, we show
that this effect arises from the inherent on-policy sampling in standard RL
objectives, causing the model to converge toward narrow solution strategies.
Based on these insights, we propose a simple yet effective data curation
algorithm that focuses RLVR learning on low-likelihood problems, achieving
notable improvement in Pass@$k$ performance. Our code is available at
https://github.com/mail-research/SELF-llm-interference.

</details>


### [239] [The Unreasonable Effectiveness of Scaling Agents for Computer Use](https://arxiv.org/abs/2510.02250)
*Gonzalo Gonzalez-Pumariega,Vincent Tu,Chih-Lun Lee,Jiachen Yang,Ang Li,Xin Eric Wang*

Main category: cs.AI

TL;DR: CUAs在自动化数字任务方面有潜力，但其不可靠性限制了它们在复杂任务中的应用。bBoN是一种通过生成多个测试，并使用行为叙述对其进行选择的方法，能够扩展CUAs的性能，提高稳定性和成功率。bBoN在OSWorld上达到了新的SOTA（69.9%），接近人类水平（72%），并在WindowsAgentArena和AndroidWorld上展示了良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 计算机使用代理（CUAs）在自动化日常数字任务方面具有巨大潜力，但其不可靠性和高方差阻碍了它们在长周期、复杂任务中的应用。

Method: 提出行为最佳N（bBoN）方法，通过生成多个测试（rollouts）并使用描述这些测试的行为叙述来选择它们，从而实现CUAs的扩展。该方法能够进行广泛的探索和原则性的轨迹选择，显著提高鲁棒性和成功率。

Result: 在OSWorld上，bBoN方法取得了69.9%的新SOTA，显著优于先前的方法，并接近人类水平（72%）。在WindowsAgentArena和AndroidWorld上展示了良好的泛化能力。

Conclusion: CUAs的有效扩展需要结构化的轨迹理解和选择，bBoN提供了一个实现这一目标的实用框架，突显了正确扩展CUAs的巨大潜力。

Abstract: Computer-use agents (CUAs) hold promise for automating everyday digital
tasks, but their unreliability and high variance hinder their application to
long-horizon, complex tasks. We introduce Behavior Best-of-N (bBoN), a method
that scales over agents by generating multiple rollouts and selecting among
them using behavior narratives that describe the agents' rollouts. It enables
both wide exploration and principled trajectory selection, substantially
improving robustness and success rates. On OSWorld, our bBoN scaling method
establishes a new state of the art (SoTA) at 69.9%, significantly outperforming
prior methods and approaching human-level performance at 72%, with
comprehensive ablations validating key design choices. We further demonstrate
strong generalization results to different operating systems on
WindowsAgentArena and AndroidWorld. Crucially, our results highlight the
unreasonable effectiveness of scaling CUAs, when you do it right: effective
scaling requires structured trajectory understanding and selection, and bBoN
provides a practical framework to achieve this.

</details>


### [240] [RLAD: Training LLMs to Discover Abstractions for Solving Reasoning Problems](https://arxiv.org/abs/2510.02263)
*Yuxiao Qu,Anikait Singh,Yoonho Lee,Amrith Setlur,Ruslan Salakhutdinov,Chelsea Finn,Aviral Kumar*

Main category: cs.AI

TL;DR: 该研究提出了一种名为RLAD的“推理抽象”方法，通过生成和利用自然语言描述的程序性知识来提高大型模型在复杂问题推理中的表现，有效促进了结构化探索和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 目前的强化学习（RL）方法在处理长链推理时，模型倾向于生成冗长且无效的探索路径，未能有效识别和复用解决问题的程序性知识。

Method: 提出“推理抽象”（reasoning abstractions）的概念，即用简洁的自然语言描述程序性和事实性知识，以引导模型学习。通过一个两阶段的RL训练范式（RLAD）：首先训练一个抽象生成器，然后训练一个解生成器，后者利用前者生成的抽象来构建解决方案。

Result: RLAD范式能够促进结构化探索，将抽象建议和解生成过程的学习信号解耦，并提高模型在更复杂问题上的泛化能力。在测试阶段，增加抽象生成计算资源比增加解生成资源对性能的提升作用更大。

Conclusion: 推理抽象是引导模型进行有意义探索的关键，能够有效克服当前RL方法在长链推理中的不足，显著提升模型解决复杂问题的能力。

Abstract: Reasoning requires going beyond pattern matching or memorization of solutions
to identify and implement "algorithmic procedures" that can be used to deduce
answers to hard problems. Doing so requires realizing the most relevant
primitives, intermediate results, or shared procedures, and building upon them.
While RL post-training on long chains of thought ultimately aims to uncover
this kind of algorithmic behavior, most reasoning traces learned by large
models fail to consistently capture or reuse procedures, instead drifting into
verbose and degenerate exploration. To address more effective reasoning, we
introduce reasoning abstractions: concise natural language descriptions of
procedural and factual knowledge that guide the model toward learning
successful reasoning. We train models to be capable of proposing multiple
abstractions given a problem, followed by RL that incentivizes building a
solution while using the information provided by these abstractions. This
results in a two-player RL training paradigm, abbreviated as RLAD, that jointly
trains an abstraction generator and a solution generator. This setup
effectively enables structured exploration, decouples learning signals of
abstraction proposal and solution generation, and improves generalization to
harder problems. We also show that allocating more test-time compute to
generating abstractions is more beneficial for performance than generating more
solutions at large test budgets, illustrating the role of abstractions in
guiding meaningful exploration.

</details>


### [241] [BioX-Bridge: Model Bridging for Unsupervised Cross-Modal Knowledge Transfer across Biosignals](https://arxiv.org/abs/2510.02276)
*Chenqi Li,Yu Liu,Timothy Denison,Tingting Zhu*

Main category: cs.AI

TL;DR: 该研究提出了一种名为BioX-Bridge的框架，用于在不同生物信号模态之间进行无监督跨模态知识迁移，通过训练一个轻量级桥接网络来对齐中间表征，从而实现信息在大型基础模型之间的流动，显著减少了可训练参数数量，同时保持甚至提升了迁移性能。


<details>
  <summary>Details</summary>
Motivation: 由于大型标注数据集的限制，以及现有知识蒸馏方法计算和内存开销大的问题，研究旨在探索一种更高效的无监督跨模态知识迁移方法，以解决生物信号健康监测中的挑战。

Method: 提出了一种名为BioX-Bridge的框架，该框架训练一个轻量级的桥接网络来对齐基础模型之间的中间表征，从而实现信息在不同生物信号模态和基础模型之间的流动。该框架还包括一种选择桥接位置的策略和一种灵活的原型网络作为桥接架构。

Result: 在多个生物信号模态、任务和数据集上的广泛实验表明，BioX-Bridge 可将可训练参数数量减少 88%–99%，同时在迁移性能上与最先进的方法持平甚至有所提高。

Conclusion: BioX-Bridge 是一种高效的无监督跨模态知识迁移框架，能够显著减少计算和内存开销，并有效提升生物信号健康监测模型的性能和适应性。

Abstract: Biosignals offer valuable insights into the physiological states of the human
body. Although biosignal modalities differ in functionality, signal fidelity,
sensor comfort, and cost, they are often intercorrelated, reflecting the
holistic and interconnected nature of human physiology. This opens up the
possibility of performing the same tasks using alternative biosignal
modalities, thereby improving the accessibility, usability, and adaptability of
health monitoring systems. However, the limited availability of large labeled
datasets presents challenges for training models tailored to specific tasks and
modalities of interest. Unsupervised cross-modal knowledge transfer offers a
promising solution by leveraging knowledge from an existing modality to support
model training for a new modality. Existing methods are typically based on
knowledge distillation, which requires running a teacher model alongside
student model training, resulting in high computational and memory overhead.
This challenge is further exacerbated by the recent development of foundation
models that demonstrate superior performance and generalization across tasks at
the cost of large model sizes. To this end, we explore a new framework for
unsupervised cross-modal knowledge transfer of biosignals by training a
lightweight bridge network to align the intermediate representations and enable
information flow between foundation models and across modalities. Specifically,
we introduce an efficient strategy for selecting alignment positions where the
bridge should be constructed, along with a flexible prototype network as the
bridge architecture. Extensive experiments across multiple biosignal
modalities, tasks, and datasets show that BioX-Bridge reduces the number of
trainable parameters by 88--99\% while maintaining or even improving transfer
performance compared to state-of-the-art methods.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [242] [LLM-based Multi-Agent Blackboard System for Information Discovery in Data Science](https://arxiv.org/abs/2510.01285)
*Alireza Salemi,Mihir Parmar,Palash Goyal,Yiwen Song,Jinsung Yoon,Hamed Zamani,Hamid Palangi,Tomas Pfister*

Main category: cs.MA

TL;DR: LLM在数据科学中应用面临数据发现挑战，提出基于黑板架构的多智能体通信范式，提升了可扩展性和灵活性，并在三个基准测试中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理大型异构数据湖中的数据发现时存在局限性：单智能体系统易被压垮，主从多智能体系统依赖刚性中心控制器分配任务，需要精确了解各子智能体能力。

Method: 提出一种受传统AI黑板架构启发的新的多智能体通信范式。中心智能体将请求发布到共享黑板，自主的下属智能体根据自身能力响应。

Result: 在KramaBench、DS-Bench和DA-Code三个包含数据发现的基准测试中，所提出的黑板架构在端到端任务成功率上比RAG和主从多智能体范式提高了13%-57%，数据发现F1分数提高了9%。

Conclusion: 黑板范式是一种可扩展且可泛化的多智能体系统通信框架。

Abstract: The rapid advancement of Large Language Models (LLMs) has opened new
opportunities in data science, yet their practical deployment is often
constrained by the challenge of discovering relevant data within large
heterogeneous data lakes. Existing methods struggle with this: single-agent
systems are quickly overwhelmed by large, heterogeneous files in the large data
lakes, while multi-agent systems designed based on a master-slave paradigm
depend on a rigid central controller for task allocation that requires precise
knowledge of each sub-agent's capabilities. To address these limitations, we
propose a novel multi-agent communication paradigm inspired by the blackboard
architecture for traditional AI models. In this framework, a central agent
posts requests to a shared blackboard, and autonomous subordinate agents --
either responsible for a partition of the data lake or general information
retrieval -- volunteer to respond based on their capabilities. This design
improves scalability and flexibility by eliminating the need for a central
coordinator to have prior knowledge of all sub-agents' expertise. We evaluate
our method on three benchmarks that require explicit data discovery: KramaBench
and modified versions of DS-Bench and DA-Code to incorporate data discovery.
Experimental results demonstrate that the blackboard architecture substantially
outperforms baselines, including RAG and the master-slave multi-agent paradigm,
achieving between 13% to 57% relative improvement in end-to-end task success
and up to a 9% relative gain in F1 score for data discovery over the
best-performing baselines across both proprietary and open-source LLMs. Our
findings establish the blackboard paradigm as a scalable and generalizable
communication framework for multi-agent systems.

</details>


### [243] [SimCity: Multi-Agent Urban Development Simulation with Rich Interactions](https://arxiv.org/abs/2510.01297)
*Yeqi Feng,Yucheng Lu,Hongyu Su,Tianxing He*

Main category: cs.MA

TL;DR: SimCity是一个利用大型语言模型（LLMs）构建多主体宏观经济模拟的框架，能够模拟异质性代理和丰富交互，并重现了包括供需价格弹性、恩格尔定律、奥肯定律、菲利普斯曲线和贝弗里奇曲线在内的多种经济现象。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）为构建现实且可解释的宏观经济模拟提供了新的可能性。现有的宏观经济模型要么因处理复杂性而限制了代理的异质性，要么依赖于手工设计的规则，SimCity旨在克服这些限制，实现更灵活、自适应和可解释的模拟。

Method: SimCity是一个多主体框架，利用LLMs来模拟一个具有异质性代理和丰富交互的可解释宏观经济系统。它包含四种核心代理类型（家庭、企业、中央银行和政府），它们在一个存在摩擦的劳动力市场、异质商品市场和金融市场中进行决策和互动。此外，该框架还利用视觉-语言模型（VLM）来确定新企业的地理位置并渲染虚拟城市，从而能够统一研究宏观经济规律和城市扩张动态。

Result: SimCity框架能够自然地重现一系列经典的宏观经济现象，包括供需价格弹性、恩格尔定律、奥肯定律、菲利普斯曲线和贝弗里奇曲线，并且在多次模拟运行中表现出良好的稳健性。

Conclusion: SimCity框架成功地利用LLMs构建了一个可解释的、具有异质性代理的宏观经济模拟系统，该系统不仅能重现已知的宏观经济规律，还能探索城市扩张等新的研究领域。

Abstract: Large Language Models (LLMs) open new possibilities for constructing
realistic and interpretable macroeconomic simulations. We present SimCity, a
multi-agent framework that leverages LLMs to model an interpretable
macroeconomic system with heterogeneous agents and rich interactions. Unlike
classical equilibrium models that limit heterogeneity for tractability, or
traditional agent-based models (ABMs) that rely on hand-crafted decision rules,
SimCity enables flexible, adaptive behavior with transparent natural-language
reasoning. Within SimCity, four core agent types (households, firms, a central
bank, and a government) deliberate and participate in a frictional labor
market, a heterogeneous goods market, and a financial market. Furthermore, a
Vision-Language Model (VLM) determines the geographic placement of new firms
and renders a mapped virtual city, allowing us to study both macroeconomic
regularities and urban expansion dynamics within a unified environment. To
evaluate the framework, we compile a checklist of canonical macroeconomic
phenomena, including price elasticity of demand, Engel's Law, Okun's Law, the
Phillips Curve, and the Beveridge Curve, and show that SimCity naturally
reproduces these empirical patterns while remaining robust across simulation
runs.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [244] [Coupling Magnons to an Opto-Electronic Parametric Oscillator](https://arxiv.org/abs/2510.01435)
*Junming Wu,Shihao Zhou,Benedetta Flebus,Wei Zhang*

Main category: cond-mat.mes-hall

TL;DR: We demonstrated strong and coherent coupling between an optoelectronic oscillator and a magnonic oscillator by integrating them. This hybrid system shows potential for long-distance coupling and nonlinearity in coherent magnonic phenomena, paving the way for future distributed hybrid magnonic systems.


<details>
  <summary>Details</summary>
Motivation: The majority of existing magnonic systems are limited to near-field schemes, restricting their applicability in remote-coupled, distributed quantum networks. Opto-electronic architectures, on the other hand, are suitable for long-haul signal transmission. This work aims to bridge this gap by integrating these two platforms.

Method: An opto-electronic oscillator was integrated with a magnonic oscillator (composed of a microwave waveguide and a YIG sphere). The coupling between magnonic modes and opto-electronic photon modes was demonstrated, observing an anti-crossing gap in the spectrum. The photon mode was generated on-demand via a nonlinear, parametric process using an external seed pump, and both internal cavity and external pump phases were tuned for stabilization.

Result: Strong and coherent coupling was achieved between the YIG magnon modes and the opto-electronic oscillator's photon modes, evidenced by an anti-crossing gap in the measured spectrum. The photon mode was produced on-demand and stabilized by tuning the phases.

Conclusion: This integrated opto-electronic and magnonic system provides a new platform for studying long-distance coupling and nonlinearity in coherent magnonic phenomena, with potential applications in future distributed hybrid magnonic systems.

Abstract: Hybrid magnonic systems have emerged as versatile modular components for
quantum signal transduction and sensing applications owing to their capability
of connecting distinct quantum platforms. To date, the majority of the magnonic
systems have been explored in a local, near-field scheme, due to the close
proximity required for realizing a strong coupling between magnons and other
excitations. This constraint greatly limits the applicability of magnons in
developing remotely-coupled, distributed quantum network systems. On the
contrary, opto-electronic architectures hosting self-sustained oscillations has
been a unique platform for longhaul signal transmission and processing. Here,
we integrated an opto-electronic oscillator with a magnonic oscillator
consisting of a microwave waveguide and a Y3Fe5O12(YIG) sphere, and
demonstrated strong and coherent coupling between YIG's magnon modes and the
opto-electronic oscillator's characteristic photon modes - revealing the
hallmark anti-crossing gap in the measured spectrum. In particular, the photon
mode is produced on-demand via a nonlinear, parametric process as stipulated by
an external seed pump. Both the internal cavity phase and the external pump
phase can be precisely tuned to stabilize either degenerate or nondegenerate
auto-oscillations. Our result lays out a new, hybrid platform for investigating
long-distance coupling and nonlinearity in coherent magnonic phenomena, which
may be find useful in constructing future distributed hybrid magnonic systems.

</details>


### [245] [Even-denominator fractional quantum Hall states with spontaneously broken rotational symmetry](https://arxiv.org/abs/2510.01482)
*Chengyu Wang,A. Gupta,S. K. Singh,C. T. Tai,L. N. Pfeiffer,K. W. Baldwin,R. Winkler,M. Shayegan*

Main category: cond-mat.mes-hall

TL;DR: 在GaAs二维量子阱中，于反倾斜磁场下观测到了各向异性的分数阶量子霍尔态。本研究发现在垂直磁场下，于偶分母朗道能级填充{
u} = 5/2和7/2处，GaAs二维量子阱中也存在分数阶量子霍尔态，并表现出高度各向异性的纵向电阻，这表明了拓扑序和自发对称性破缺的共存，预示着向列分数阶量子霍尔态的出现，并可能存在非阿贝尔拟粒子激发。通过栅极调控空穴密度，在{
u} = 7/2处观测到了向各向同性的复合费米子海相变。计算表明，部分占据的朗道能级中的混合轨道分量在拓扑序和向列序的竞争与相互作用中起关键作用。


<details>
  <summary>Details</summary>
Motivation: 在GaAs二维量子阱中，于反倾斜磁场下观测到了各向异性的分数阶量子霍尔态。本研究旨在探索在垂直磁场下，偶分母朗道能级填充{
u} = 5/2和7/2处是否存在具有各向异性的分数阶量子霍尔态，并研究其与自发对称性破缺（向列性）的相互作用。

Method: 通过实验观测，在超高品质的GaAs二维体系中，于垂直磁场下，在{
u} = 5/2和7/2处观测到了分数阶量子霍尔态，并测量了其纵向电阻，发现其具有高度各向异性。通过栅极调控空穴密度，观测了{
u} = 7/2处的相变。同时进行了理论计算，以解释混合轨道分量在拓扑序和向列序中的作用。

Result: 观测到了在垂直磁场下，于{
u} = 5/2和7/2处存在高度各向异性的分数阶量子霍尔态。在{
u} = 7/2处，通过栅极调控空穴密度，观测到了从各向异性的、正在形成的分数阶量子霍尔态到各向同性的复合费米子费米海的相变。理论计算表明，部分占据的朗道能级中的混合轨道分量在拓扑序和向列序的竞争和相互作用中起关键作用。

Conclusion: 在GaAs二维体系中，于垂直磁场下，在{
u} = 5/2和7/2处观测到了向列分数阶量子霍尔态，其特征是各向异性的纵向电阻和自发对称性破缺的共存。这表明了拓扑序和向列序之间的紧密联系，并可能存在非阿贝尔拟粒子激发。通过栅极调控可以实现向列分数阶量子霍尔态与复合费米子费米海之间的相变。理论计算支持混合轨道分量在这些现象中的关键作用。

Abstract: The interplay between the fractional quantum Hall effect and nematicity is
intriguing as it links emerging topological order and spontaneous symmetry
breaking. Anisotropic fractional quantum Hall states (FQHSs) have indeed been
reported in GaAs quantum wells but only in tilted magnetic fields, where the
in-plane field explicitly breaks the rotational symmetry. Here we report the
observation of FQHSs with highly anisotropic longitudinal resistances in purely
perpendicular magnetic fields at even-denominator Landau level (LL) fillings
{\nu} = 5/2 and 7/2 in ultrahigh-quality GaAs two-dimensional hole systems. The
coexistence of FQHSs and spontaneous symmetry breaking at half fillings signals
the emergence of nematic FQHSs which also likely harbor non-Abelian
quasiparticle excitations. By gate tuning the hole density, we observe a phase
transition from an anisotropic, developing FQHS to an isotropic composite
fermion Fermi sea at {\nu} = 7/2. Our calculations suggest that the mixed
orbital components in the partially occupied LL play a key role in the
competition and interplay between topological and nematic orders.

</details>


### [246] [Coupling free-surface geometry and localized ion dose for continuum models of radiation-induced nanopatterning](https://arxiv.org/abs/2510.01503)
*Tyler P. Evans,Scott A. Norris*

Main category: cond-mat.mes-hall

TL;DR: 该研究提出了一个统一的物理模型来解释辐照半导体表面纳米结构形成的现象，该模型考虑了离子注入引起的碰撞级联的双重影响：即时材料传输和长期粘性流动。


<details>
  <summary>Details</summary>
Motivation: 解释辐照半导体表面高度规则的、纳米尺度的自组装结构的形成机制，填补现有模型在解释所有图案形成细节方面的不足。

Method: 开发了几种耦合局部离子剂量和演化自由界面的渐近近似方法。

Result: 理论预测了常用的实验对比量（如涟漪波长、图案形成阈值照射角和表面粗糙度）对耦合细节表现出惊人的敏感性。

Conclusion: 该模型能够更精确地预测和解释辐照下纳米结构形成的各种现象，为相关实验研究提供理论指导。

Abstract: A first-principles understanding of the self-organization of highly regular,
nanometer-scale structures atop irradiated semiconductor surfaces has been
sought for decades. While numerous models exist which explain certain aspects
of this phenomenon, a unified, physical model capable of explaining all details
of pattern formation has remained elusive. However, it is increasingly apparent
that such a model will require understanding the dual influence of the
collision cascade initiated by ion implantation: first, as a source of material
transport by sputtering and atomic displacements occurring over short time
scales, and, second, as a source of defects permitting viscous flow within the
thin, amorphous layer that results from sustained irradiation over longer time
scales. To better understand the latter, we develop several asymptotic
approximations for coupling the localized ion dose with an evolving free
interface. We then show how theoretical predictions of quantities commonly used
for comparison with experimental observations -- such as ripple wavelengths,
critical irradiation angle for patterning onset, and surface roughening --
exhibit surprising sensitivity to the details of this coupling.

</details>


### [247] [Electric spin and valley Hall effects](https://arxiv.org/abs/2510.01714)
*W. Zeng*

Main category: cond-mat.mes-hall

TL;DR: 提出了一种基于二维六方材料的隧道结的自旋和谷的电霍尔效应。该效应由垂直电场引起，与Berry曲率无关，并能实现自旋和谷自由度的全电场调控。


<details>
  <summary>Details</summary>
Motivation: 探索二维材料中的电霍尔效应，并提出其自旋和谷的类似效应，以期实现自旋和谷自由度的电场调控。

Method: 设计并模拟了一个基于弯曲二维六方材料的集成隧道结，分析了垂直电场对其产生的横向自旋流和谷流的影响，并推导了相应的霍尔电导。

Result: 证明了在垂直电场作用下，隧道结能够产生横向自旋流（电自旋霍尔效应）和谷流（电谷霍尔效应）。发现谷霍尔电导对垂直电场呈奇响应，而自旋霍尔电导呈偶响应。实现了具有完整自旋谷极化的纯自旋谷锁定态的横向分离，且自旋霍尔角和谷霍尔角相等。

Conclusion: 提出的电自旋霍尔效应和电谷霍尔效应提供了一种新的实现自旋和谷霍尔效应的机制，并为自旋电子学和谷电子学领域的应用开辟了新的途径。

Abstract: The electric Hall effect (EHE) is a newly identified Hall effect
characterized by a perpendicular electric field inducing a transverse charge
current in two-dimensional (2D) systems. Here, we propose a spin and valley
version of EHE. We demonstrate that the transverse spin and valley currents can
be generated in an all-in-one tunnel junction based on a buckled 2D hexagonal
material in response to a perpendicular electric field, referred to as the
electric spin Hall effect and electric valley Hall effect, respectively. These
effects arise from the perpendicular-electric-field-induced backreflection
phase of electrons in the junction spacer, independent of Berry curvature. The
valley Hall conductance exhibits an odd response to the perpendicular electric
field, whereas the spin Hall conductance shows an even one. The predicted
effects can further enable the transverse separation of a pair of pure
spin-valley-locked states with full spin-valley polarization while preserving
time-reversal symmetry, as manifested by equal spin and valley Hall angles. Our
findings present a new mechanism for realizing the spin and valley Hall effects
and provide a novel route to the full electric-field manipulation of spin and
valley degrees of freedom, with significant potential for future applications
in spintronics and valleytronics.

</details>


### [248] [Orbital Magnetization in Correlated States of Twisted Bilayer Transition Metal Dichalcogenides](https://arxiv.org/abs/2510.01727)
*Xiaoyu Liu,Chong Wang,Xiao-Wei Zhang,Ting Cao,Di Xiao*

Main category: cond-mat.mes-hall

TL;DR: 文章提出了一个用于计算量子霍尔效应中轨道磁化的一般理论，并将其应用于扭曲MoTe$_2$双层体系，发现了与扭转角相关的轨道磁化。


<details>
  <summary>Details</summary>
Motivation: 文章旨在解决量子反常霍尔效应中相互作用驱动的铁磁性物理问题，特别是其中显著的轨道贡献。

Method: 文章将现代轨道磁化理论扩展到Hartree-Fock态，并验证了在Hartree-Fock轨道和哈密顿量下标准表达式的有效性。随后，将该理论应用于Kane-Mele-Hubbard模型和扭曲MoTe$_2$双层体系进行基准测试和定量分析。

Result: 通过将理论应用于扭曲MoTe$_2$双层体系，文章发现每莫尔单元的轨道磁化强度约为1玻尔磁子，且其强度随扭转角呈现非单调变化。

Conclusion: 文章建立了一个适用于相互作用莫尔体系的通用轨道磁化理论，并为解释相关实验提供了定量指导。

Abstract: Recent observations of quantum anomalous Hall effects in moir\'e systems have
revealed the emergence of interaction-driven ferromagnetism with significant
orbital contributions. To capture this physics, we extend the modern theory of
orbital magnetization to Hartree-Fock states and show that the standard
expression remains valid with Hartree-Fock orbitals and Hamiltonians. We then
benchmark our theory against the Kane-Mele-Hubbard model in a weak field, which
yields excellent agreement with direct numerical calculations. Applying our
theory to twisted MoTe$_2$ bilayers, we find orbital magnetization of order one
Bohr magneton per moir\'e cell with a non-monotonic twist-angle dependence. Our
work establishes a general theory of orbital magnetization in interacting
moir\'e systems and provides quantitative guidance for interpreting recent
experiments.

</details>


### [249] [Tunable Wigner Molecules in a Germanium Quantum Dot](https://arxiv.org/abs/2510.01786)
*Chenggang Yang,Jun Lu,Hongzhang Wang,Jian Zeng,Wendong Bian,Zhengshan Guo,Jiankun Li,Yulei Zhang,Junwei Luo,Tian Pei*

Main category: cond-mat.mes-hall

TL;DR: 在锗量子点中发现了由库仑相互作用驱动的空穴维格纳分子，并观察到了从维格纳分子到费米液体行为的相变。


<details>
  <summary>Details</summary>
Motivation: 研究库仑相互作用和动能的相互作用在凝聚态物理中形成奇异相的现象，特别是研究少量子少电子系统的维格纳分子。

Method: 通过改变栅极电压来调控锗量子点中的空穴密度，并观察其形成维格纳分子和相变。

Result: 成功在锗量子点中形成了空穴维格纳分子，并通过改变空穴密度观察到了从维格纳分子到类费米液体的熔化过程，以及一个包含有序和无序结构的中间构型。

Conclusion: 证明了锗量子点是一个研究强关联物理和探索维格纳分子在量子信息应用中潜力的可行平台。

Abstract: The interplay between Coulomb interactions and kinetic energy underlies many
exotic phases in condensed matter physics. In a two-dimensional electronic
system, If Coulomb interaction dominates over kinetic energy, electrons
condense into a crystalline phase which is referred as Wigner crystal. This
ordered state manifests as Wigner molecule for few electrons at the microscopic
scale. Observation of Wigner molecules has been reported in quantum dot and
moire superlattice systems. Here we demonstrate hole Wigner molecules can be
formed in a gate-defined germanium quantum dot with high tunability. By varying
voltages applied to the quantum dot device, we can precisely tune the hole
density by either changing the hole occupancy or the quantum dot size. For
densities smaller than a certain critical value, Coulomb interaction localizes
individual holes into ordered lattice sites, forming a Wigner molecule. By
increasing the densities, melting process from a Wigner molecule to Fermi
liquid-like particles is observed. An intermediate configuration which
indicates the coexistence of ordered structure and disordered structure can be
formed within a narrow effective density range. Our results provide a new
platform for further exploration of the microscopic feature of strong
correlated physics and open an avenue to exploit the application of Wigner
molecules for quantum information in a very promising spin qubit platform.

</details>


### [250] [Intermediate diffusive-ballistic electron conduction around mesoscopic defects in graphene](https://arxiv.org/abs/2510.01821)
*Toni Markovic,Wei Huang,William S. Huxter,Pietro Gambardella,Sebastian Stepanow*

Main category: cond-mat.mes-hall

TL;DR: 本研究使用扫描隧道电位法研究了石墨烯中介观缺陷周围的电荷传输，发现传输处于扩散和弹道极限之间的中间状态，传统扩散模型低估了缺陷周围的电化学势。


<details>
  <summary>Details</summary>
Motivation: 当器件尺寸接近电子平均自由程时，电荷传输中的非扩散效应变得重要。本研究以石墨烯中介观缺陷为模型系统，研究了其周围的电荷传输。

Method: 使用扫描隧道电位法，同时测量了石墨烯层中缺陷的形貌以及周围区域的局部电化学势，并结合格子玻尔兹曼模拟进行分析。

Result: 发现电荷传输处于扩散和弹道极限之间的中间状态，传统扩散模型低估了缺陷周围的电化学势。即使在大于平均自由程的特征尺寸下，也存在弹道输运的贡献，并且在尺寸减小时，这种贡献迅速增加，在介观尺度上产生显著影响。缺陷的形状同时影响弹道和扩散输运模式下的散射偶极子的大小。

Conclusion: 电荷传输的中间状态以及弹道输运在介观尺度上的重要性，需要更精确的模型来理解和预测器件中的电荷传输行为。

Abstract: Non-diffusive effects in charge transport become relevant as device sizes and
features become comparable to the electronic mean free path. As a model system,
we investigate the electric transport around mesoscopic defects in graphene
with scanning tunneling potentiometry. Diffusive and ballistic contributions to
the scattering dipole are probed by simultaneously resolving the nanoscale
topography of pits in the graphene layer and measuring the local
electrochemical potential in the surrounding area. We find evidence of
transport in the intermediate regime between the diffusive and ballistic
limits, such that the magnitude of the electrochemical potential around the
defects is substantially underestimated by diffusive models. Our experiments
and modeling are supported by lattice Boltzmann simulations, which highlight
the importance of the ratio between defect size and mean free path in the
intermediate transport regime. The magnitude of the scattering dipole depends
on the shape of the pits in both the ballistic and diffusive transport modes.
Remarkably, ballistic contributions to the electron transport are found at
feature sizes larger than the mean free path and rapidly increase at lower
sizes, having a noticeable impact already at mesoscopic length scales.

</details>


### [251] [Band Gap Engineering of Nitrogen-Doped Monolayer WSe$_2$ Superlattice and its application to Field Effect Transistor](https://arxiv.org/abs/2510.01917)
*Yi-Cheng Lo,Liao Jia Wang,Yu-Chang Chen*

Main category: cond-mat.mes-hall

TL;DR: 本研究通过计算模拟，研究了氮掺杂钨二硒化物（WSe2）超晶格的电子结构及其在场效应晶体管（FET）中的应用。


<details>
  <summary>Details</summary>
Motivation: 氮掺杂作为一种可控的掺杂方式，可以有效调控WSe2的带隙，为电子和光电器件提供应用基础。

Method: 本研究采用计算模拟方法，研究了不同掺杂密度下WSe2超晶格的电子结构，并评估了其在FET器件中的性能，包括电流密度、亚阈值摆幅和栅极电压等参数。

Result: 研究发现，随着氮掺杂密度的增加，WSe2的带隙单调减小。计算结果还揭示了在不同温度下，器件的导通和阻断特性，以及经典-量子跨越行为。其中，6行和8行掺杂结构在器件性能和稳定性方面表现出较好的折衷，是未来FET器件的潜在候选者。

Conclusion: 氮掺杂WSe2超晶格是一种有前景的材料，通过调控掺杂密度可以优化其电子和光电器件性能。其中，6行和8行掺杂结构在器件性能和稳定性方面表现出较好的折衷，是未来FET器件的潜在候选者。

Abstract: We systematically investigate the electronic structures of pristine monolayer
WSe$_2$ and WSe$_2$ superlattices with periodic nitrogen substitution. Unlike
random doping, which often introduces in-gap impurity states, periodic nitrogen
doping primarily modulates the band gap, thereby facilitating effective band
gap engineering for electronic and optoelectronic applications. The gap narrows
monotonically with increasing dopant density (pristine $>$ 8-row $>$ 6-row $>$
4-row), directly influencing device switching. We also evaluate the FET
performance of nanojunctions created by these configurations by examining the
contour plot of current density as a function of temperature and gate voltage,
which quantifies how bandgap engineering affects switching characteristics. Our
calculations clarify the classical-quantum crossover in sub-10 nm 2D FETs: as
$T$ rises, $J$ approaches the thermionic current; as $T$ falls, quantum
tunneling dominates, and the steep energy dependence of $\tau(E)$ may break the
classical limit of subthreshold swing imposed by the Boltzmann tyranny. The
optimal gating range ($V_g^\mathrm{ON}$, $V_g^\mathrm{OFF}$) is investigated
for each temperature, insensitive to temperature in the high-temperature
regime, confirming the good thermal stability of the FET devices. A comparison
study demonstrates that the 4-row structure, with large $J_\mathrm{OFF}$ and
restricted operation range, is inappropriate for realistic FET applications.
The pristine structure has a high $V_g^\mathrm{OFF}$ ($\sim$1.1 V) makes it
less practical, since such a large threshold voltage may promote time-dependent
dielectric breakdown (TDDB) of the oxide layer, reducing device dependability.
The 6-row and 8-row structures exhibit more favorable $V_g^\mathrm{OFF}$ values
($\sim$0.75 V), achieving compromise, making them more promising candidates for
future FET integration.

</details>


### [252] [Electrically tunable ultrafast dynamics and interactions of hybrid excitons in a 2D semiconductor bilayer](https://arxiv.org/abs/2510.01921)
*Edoardo Lopriore,Charalambos Louca,Armando Genco,Irantzu Landa,Daniel Erkensten,Charles J. Sayers,Samuel Brem,Raul Perea-Causin,Kenji Watanabe,Takashi Taniguchi,Christoph Gadermaier,Ermin Malic,Giulio Cerullo,Stefano Dal Conte,Andras Kis*

Main category: cond-mat.mes-hall

TL;DR: 通过施加垂直电场，我们揭示了偶极子层杂化激子具有强库仑相互作用，导致基于偶极子取向的两个主要杂化物种的能量发生相反的依赖于密度的移动，并大大增强了其吸收的光饱和度。此外，通过电调谐杂化载流子之间的层间隧穿，我们显著延长了杂化激子的形成时间和衰减时间。


<details>
  <summary>Details</summary>
Motivation: 研究强相互作用激子及其动力学，以实现宏观量子物质态，如激子和偏振子的玻色-爱因斯坦凝聚。过渡金属二卤代物中的动量直接层杂化激子因其高振荡器强度和偶极子性质而备受关注。然而，其相互作用和动力学的可调性仍有待探索。

Method: 本研究利用瞬态光学光谱技术，通过电场门控的范德华层状异质结，实现了对偶极子层杂化激子非线性特性的前所未有的控制。

Result: 本研究揭示了偶极子层杂化激子具有强库仑相互作用，其能量随密度变化表现出与偶极子取向相关的相反移动，同时吸收的光饱和度也显著增强。此外，通过调谐层间隧穿，研究人员延长了杂化激子的形成时间并增加了其衰减时间。

Conclusion: 本研究实现了对偶极子层杂化激子非线性特性的前所未有的控制，并揭示了电场对其相互作用和动力学的影响。这些发现为在二维材料中寻找激子和偶极子玻色子块和凝聚提供了新的方向。

Abstract: Extended efforts have been devoted to the study of strongly-interacting
excitons and their dynamics, towards macroscopic quantum states of matter such
as Bose-Einstein condensates of excitons and polaritons. Momentum-direct
layer-hybridized excitons in transition metal dichalcogenides have attracted
considerable attention due to their high oscillator strength and dipolar
nature. However, the tunability of their interactions and dynamics remains
unexplored. Here, we achieve an unprecedented control over the nonlinear
properties of dipolar layer-hybridized excitons in an electrically gated van
der Waals homobilayer monitored by transient optical spectroscopy. By applying
a vertical electric field, we reveal strong Coulomb interactions of dipolar
hybrid excitons, leading to opposite density-dependent energy shifts of the two
main hybrid species based on their dipolar orientation, together with a
strongly enhanced optical saturation of their absorption. Furthermore, by
electrically tuning the interlayer tunneling between the hybridized carriers,
we significantly extend the formation time of hybrid excitons, while
simultaneously increasing their decay times. Our findings have implications for
the search on quantum blockade and condensation of excitons and dipolaritons in
two-dimensional materials.

</details>


### [253] [Measuring the measurement problem: controlling decoherence with measurement duration in molecular MCB junctions](https://arxiv.org/abs/2510.01945)
*C. J. Muller*

Main category: cond-mat.mes-hall

TL;DR: 测量时长可调控分子结中的量子相干性，在足够长的测量时间内，观察到量子干涉行为向经典行为的转变。


<details>
  <summary>Details</summary>
Motivation: 研究测量时长对分子机械控制断裂结中的量子相干性的影响，特别是在四氢呋喃（THF）部分湿相中。

Method: 通过调整电流-电压（IV）特性测量中的积分时间，并与退相干时间进行比较，观察量子行为的变化。

Result: 在足够长的测量时间内，观察到从量子干涉模式（表现为结构化的数据点带）到经典行为（表现为单一平均响应）的转变。

Conclusion: 测量时长是探索引子量子行为的可控参数，为理解量子力学中的退相干动力学提供了新见解。

Abstract: We investigate the influence of the measurement duration on quantum coherence
in molecular mechanically controlled break junctions operating in a
tetrahydrofuran (THF) partially wet phase. These systems represent a distinct
class of enclosed open quantum systems with unusually long decoherence times at
ambient conditions, on the order of 1-20 ms. By tuning the integration time of
the current measurement in current-voltage (IV) characteristics, relative to
the decoherence time, we observe a transition from quantum interference
patterns, manifested as structured bands of data points, to classical behavior
characterized by a single averaged response. This demonstrates that the
duration of a measurement acts as a controllable parameter for probing quantum
behavior in molecular junctions, offering new insights into decoherence
dynamics in quantum mechanics.

</details>


### [254] [Pulsed-laser induced gold microparticle fragmentation by thermal strain](https://arxiv.org/abs/2510.02011)
*Yogesh Pokhrel,Meike Tack,Sven Reichenberger,Matteo Levantino,Anton Plech*

Main category: cond-mat.mes-hall

TL;DR: 激光碎裂金微粒。


<details>
  <summary>Details</summary>
Motivation: 激光碎裂作为激光碎裂和液相烧蚀的替代方法，其结构基础尚不清楚。

Method: 使用超快X射线散射和皮秒激光激发金微粒悬浮液，并结合双温模型进行模拟。

Result: 在750 J/m$^2$的能量密度阈值以上，微粒在纳秒内破碎成大块，这是由于不均匀的热分布和超快加热引起的应力限制。在2700 J/m$^2$的能量密度下，有限的团簇形成归因于光热分解。

Conclusion: 超快X射线散射和双温模型模拟揭示了金微粒激光碎裂的机制，包括不均匀加热、应力限制和光热分解。

Abstract: Laser fragmentation of suspended microparticles is an upcoming alternative to
laser ablation in liquid (LAL) that allows to streamline the the delivery
process and optimize the irradiation conditions for best efficiency. Yet, the
structural basis of this process is not well understood to date. Herein we
employed ultrafast x-ray scattering upon picosecond laser excitation of a gold
microparticle suspension in order to understand the thermal kinetics as well as
structure evolution after fragmentation. The experiments are complemented by
simulations according to the two-temperature model to verify the spatiotemporal
temperature distribution. It is found that above a fluence threshold of 750
J/m$^2$ the microparticles are fragmented within a nanosecond into several
large pieces where the driving force is the strain due to a strongly
inhomogenous heat distribution on the one hand and stress confinement due to
the ultrafast heating compared to stress propagation on the other hand. The
additional limited formation of small clusters is attributed to photothermal
decomposition on the front side of the microparticles at the fluence of 2700
J/m$^2$.

</details>


### [255] [Phonon Spin Selective One-Way Axial Phonon Transport in Chiral Nanohelix](https://arxiv.org/abs/2510.02221)
*Jia Li,Yu-Tao Tan,Yizhou Liu,Jie Ren*

Main category: cond-mat.mes-hall

TL;DR: 本研究提出利用声子自旋角动量来操控纳米材料中的轴向声子，实现了纳米尺度上的一维声子激励和路由。


<details>
  <summary>Details</summary>
Motivation: 选择性地激发和操控声子在现代纳米能量控制和信息传感中越来越重要，但仍然具有挑战性。

Method: 通过将圆偏振红外吸收等自旋多物理场与声子自旋角动量耦合，在手性纳米材料中实现轴向声子的定向激发和路由。

Result: 在最小的手性碳纳米管中，实现了近100%的整流率，实现了理想的一维声子路由器，并通过分子动力学模拟进行了验证。

Conclusion: 本研究揭示了通过声子自旋自由度灵活操控声子的新途径，为未来的自旋声子学铺平了道路。

Abstract: Selectively exciting and manipulating phonons at nanoscale becomes more and
more important but still remains challenging in modern nano-energy control and
information sensing. Here, we show that the phonon spin angular momentum
provides an extra degree of freedom to achieve versatile manipulation of axial
phonons in nanomaterials via coupling to spinful multi-physical fields, such as
circularly polarized infrared absorption. In particular, we demonstrate the
nanoscale one-way axial phonon excitation and routing in chiral nanomaterials,
by converting the photon spin in circularly polarized optical fields into the
collective interference phonon spin. As exemplified in the smallest chiral
carbon nanotube, we show that the rectification rate can reach nearly 100\%,
achieving an ideal one-way phonon router, which is verified by molecular
dynamics simulations. Our results shed new light on the flexible phonon
manipulation via phonon spin degree of freedom, paving the way for future spin
phononics.

</details>


### [256] [Emergent Hierarchy in Localized States of Organic Quantum Chains](https://arxiv.org/abs/2510.02231)
*L. L. Lage,A. B. Félix,D. S. Gomes,M. L. Pereira Jr.,A. Latgé*

Main category: cond-mat.mes-hall

TL;DR: OQCs的电子和输运性质通过DFT和紧束缚模型研究，结果显示其具有稳定的能隙和分级状态，并分析了其在碳纳米器件中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 研究近期合成的有机量子链（OQCs）的电子和输运性质，以理解其潜在的非常规电子和输运现象。

Method: 首先通过分子动力学松弛结合密度泛函理论（DFT）评估结构稳定性，然后使用紧束缚模型进行计算，并分析了OQCs与碳围栏耦合的输运响应。

Result: 计算结果显示，OQCs具有稳健且近乎恒定的能隙，并识别出具有不同局域化行为的分级状态，这与实验数据一致。

Conclusion: OQCs具有稳定的电子结构和独特的分级状态，在与碳围栏耦合时表现出有前景的输运特性，预示着其在碳纳米器件中具有潜在应用价值。

Abstract: Organic Quantum Chains (OQCs) represent a newly synthesized class of
carbon-based nanostructures whose quasi-one-dimensional nature gives rise to
unconventional electronic and transport phenomena. Here we investigate the
electronic and transport properties of recently synthesized OQCs [Nature
Communications, 12, 5895 (2021)]. Structural stability was first assessed
through molecular dynamics relaxation combined with density functional theory
(DFT). The optimized coordinates are then used in a tight-binding model with
exponentially decaying hopping parameterization, which reproduces the DFT
results with high accuracy. Our calculations reveal a robust and nearly
constant energy gap across several OQC configurations, in agreement with
experimental data. We also identify emergent hierarchical states, characterized
by distinct localization behaviors within sets of localized bands. Finally, we
analyze different transport responses in scenarios involving the
one-dimensional OQC coupled to carbon corrals, as observed in the experimental
data, highlighting their potential as promising systems for application in
carbon nanodevices.

</details>


### [257] [Quantum gates in coupled quantum dots controlled by coupling modulation](https://arxiv.org/abs/2510.02267)
*Alejandro D. Bendersky,Sergio S. Gomez,Rodolfo H. Romero*

Main category: cond-mat.mes-hall

TL;DR: 该研究提出通过调控量子点间的隧耦合来产生单比特门，调控双量子点间的交换耦合来产生多比特门，并实现了量子计算所需的操作集。


<details>
  <summary>Details</summary>
Motivation: 提出一种通过调控量子点间的隧耦合和交换耦合来产生单比特门和多比特门的方法，以实现量子计算。

Method: 对长向和横向静态磁场以及相互作用耦合的时变谐波调制下的双量子点动力学进行了研究，并开发了分析近似方法来控制量子比特。

Result: 数值计算表明，即使在偏离理想的条件下，两电子态的幺正演化也能执行设计的操作。

Conclusion: 提出的方法可以有效地执行量子计算所需的操作，并且对偏离理想条件的鲁棒性也进行了验证。

Abstract: We studied the dynamics of a pair of single-electron double quantum dots
(DQD) under longitudinal and transverse static magnetic fields and
time-dependent harmonic modulation of their interaction couplings. We propose
to modulate the tunnel coupling between the QDs to produce one-qubit gates and
the exchange coupling between DQDs to generate entangling gates, the set of
operations required for quantum computing. We developed analytical
approximations to set the conditions to control the qubits and applied them to
numerical calculations to test the accuracy and robustness of the analytical
model. The results shows that the unitary evolution of the two-electron state
performs the designed operations even under conditions shifted from the ideal
ones.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [258] [Kilometer-Scale GNSS-Denied UAV Navigation via Heightmap Gradients: A Winning System from the SPRIN-D Challenge](https://arxiv.org/abs/2510.01348)
*Michal Werner,David Čapek,Tomáš Musil,Ondřej Franěk,Tomáš Báča,Martin Saska*

Main category: cs.RO

TL;DR: 本研究提出了一种用于GNSS（全球导航卫星系统）拒止环境下的无人机（UAV）自主导航系统，该系统在SPRIN-D Funke全自主飞行挑战赛中成功完成了9公里航程的任务，无需GNSS或先验密集地图。系统集成了感知、建图、规划和控制，并采用一种轻量级的漂移校正方法，通过梯度模板匹配将激光雷达（LiDAR）生成的局部高度图与先验地理数据高度图进行匹配，并结合集束粒子滤波器融合里程计信息。该系统在比赛中成功应用于城市、森林和开阔地等多种地形，显著减少了相对于原始里程计的漂移，并且在纯CPU硬件上实现了实时运行。


<details>
  <summary>Details</summary>
Motivation: 在GNSS拒止环境中，无人机（UAV）进行可靠的远程飞行面临挑战，主要包括：里程计集成导致的漂移、无法进行环路闭合（尤其是在未曾到访的区域）以及嵌入式平台有限的计算能力。

Method: 本研究提出的系统采用一种轻量级的漂移校正方法，该方法将激光雷达（LiDAR）生成的局部高度图与先验地理数据高度图进行匹配，通过梯度模板匹配实现。然后，利用集束粒子滤波器融合了这种匹配的证据以及来自里程计的信息，从而实现定位。

Result: 在SPRIN-D Funke全自主飞行挑战赛中，该系统成功完成了9公里航程的任务，穿越了城市、森林和开阔地等多种地形。与原始里程计相比，该系统显著减少了漂移，并且能够在纯CPU硬件上实时运行。

Conclusion: 该系统在GNSS拒止环境中成功实现了无人机的远程自主飞行，其轻量级的漂移校正方法和高效的系统架构使其能够在有限的计算资源下实时运行。该研究为未来GNSS拒止无人机自主系统的设计提供了实用的见解。

Abstract: Reliable long-range flight of unmanned aerial vehicles (UAVs) in GNSS-denied
environments is challenging: integrating odometry leads to drift, loop closures
are unavailable in previously unseen areas and embedded platforms provide
limited computational power. We present a fully onboard UAV system developed
for the SPRIN-D Funke Fully Autonomous Flight Challenge, which required 9 km
long-range waypoint navigation below 25 m AGL (Above Ground Level) without GNSS
or prior dense mapping. The system integrates perception, mapping, planning,
and control with a lightweight drift-correction method that matches
LiDAR-derived local heightmaps to a prior geo-data heightmap via
gradient-template matching and fuses the evidence with odometry in a clustered
particle filter. Deployed during the competition, the system executed
kilometer-scale flights across urban, forest, and open-field terrain and
reduced drift substantially relative to raw odometry, while running in real
time on CPU-only hardware. We describe the system architecture, the
localization pipeline, and the competition evaluation, and we report practical
insights from field deployment that inform the design of GNSS-denied UAV
autonomy.

</details>


### [259] [Safe Motion Planning and Control Using Predictive and Adaptive Barrier Methods for Autonomous Surface Vessels](https://arxiv.org/abs/2510.01357)
*Alejandro Gonzalez-Garcia,Wei Xiao,Wei Wang,Alejandro Astudillo,Wilm Decré,Jan Swevers,Carlo Ratti,Daniela Rus*

Main category: cs.RO

TL;DR: 结合MPC和CBF的安全运动规划策略，通过自适应膨胀椭圆表示减少保守性，实现自主船舶在狭窄水域的安全实时导航。


<details>
  <summary>Details</summary>
Motivation: 解决传统运动规划方法在计算密集或过于保守方面的问题，尤其是在狭窄内陆水道等挑战性环境中。

Method: 提出一种结合模型预测控制（MPC）和控制屏障函数（CBF）的安全运动规划策略。引入时间变化、自适应膨胀的椭圆障碍物表示，并使用高阶CBF来确保安全。

Result: 模拟和真实世界实验表明，该策略能够使全驱动的自主机器人船舶实时导航通过狭窄空间，解决潜在的死锁问题，并确保安全。

Conclusion: 所提出的结合MPC和CBF的自适应膨胀策略能够有效且安全地处理狭窄水域中的自主船舶运动规划问题。

Abstract: Safe motion planning is essential for autonomous vessel operations,
especially in challenging spaces such as narrow inland waterways. However,
conventional motion planning approaches are often computationally intensive or
overly conservative. This paper proposes a safe motion planning strategy
combining Model Predictive Control (MPC) and Control Barrier Functions (CBFs).
We introduce a time-varying inflated ellipse obstacle representation, where the
inflation radius is adjusted depending on the relative position and attitude
between the vessel and the obstacle. The proposed adaptive inflation reduces
the conservativeness of the controller compared to traditional fixed-ellipsoid
obstacle formulations. The MPC solution provides an approximate motion plan,
and high-order CBFs ensure the vessel's safety using the varying inflation
radius. Simulation and real-world experiments demonstrate that the proposed
strategy enables the fully-actuated autonomous robot vessel to navigate through
narrow spaces in real time and resolve potential deadlocks, all while ensuring
safety.

</details>


### [260] [A Stochastic Framework for Continuous-Time State Estimation of Continuum Robots](https://arxiv.org/abs/2510.01381)
*Spencer Teetaert,Sven Lilge,Jessica Burgner-Kahrs,Timothy D. Barfoot*

Main category: cs.RO

TL;DR: 该研究提出了一种用于连续体机器人的连续时间随机状态估计框架，该框架基于因子图优化，使用连续时间运动学和高比特率传感，能够适应未建模的外部力和数据丢失，并能对机器人的姿态、速度和应变进行插值，计算复杂度低。


<details>
  <summary>Details</summary>
Motivation: 现有的连续体机器人状态估计技术要么依赖复杂的动力学模型，要么使用简化的形状假设，要么仅限于准静态方法，这些方法都容易受到未建模干扰的影响。

Method: 提出了一种基于因子图优化的连续时间随机状态估计框架，该框架使用连续时间运动学，并将其与高比特率传感相结合，以适应未建模的外部力和数据丢失。

Result: 该方法能够生成机器人姿态、速度和应变的均值和协方差估计，这些估计可以在时间和空间上连续插值，并且该框架具有稀疏性，计算复杂度与时间成线性关系，插值查询为常数时间。

Conclusion: 该方法在具有陀螺仪和姿态传感器的连续体机器人上进行了演示，证明了其在实际系统中的通用性。

Abstract: State estimation techniques for continuum robots (CRs) typically involve
using computationally complex dynamic models, simplistic shape approximations,
or are limited to quasi-static methods. These limitations can be sensitive to
unmodelled disturbances acting on the robot. Inspired by a factor-graph
optimization paradigm, this work introduces a continuous-time stochastic state
estimation framework for continuum robots. We introduce factors based on
continuous-time kinematics that are corrupted by a white noise Gaussian process
(GP). By using a simple robot model paired with high-rate sensing, we show
adaptability to unmodelled external forces and data dropout. The result
contains an estimate of the mean and covariance for the robot's pose, velocity,
and strain, each of which can be interpolated continuously in time or space.
This same interpolation scheme can be used during estimation, allowing for
inclusion of measurements on states that are not explicitly estimated. Our
method's inherent sparsity leads to a linear solve complexity with respect to
time and interpolation queries in constant time. We demonstrate our method on a
CR with gyroscope and pose sensors, highlighting its versatility in real-world
systems.

</details>


### [261] [VENTURA: Adapting Image Diffusion Models for Unified Task Conditioned Navigation](https://arxiv.org/abs/2510.01388)
*Arthur Zhang,Xiangyun Meng,Luca Calliari,Dong-Ki Kim,Shayegan Omidshafiei,Joydeep Biswas,Ali Agha,Amirreza Shaban*

Main category: cs.RO

TL;DR: VENTURA是一个视觉-语言导航系统，通过微调图像扩散模型进行路径规划，生成视觉路径掩码，并由行为克隆策略将其转化为可执行轨迹，从而实现对自然语言指令的响应和机器人行为的多样化。该系统通过自监督跟踪模型和VLM增强的标题来生成路径掩码，避免了手动标注。在真实世界评估中，VENTURA在物体到达、避障和地形偏好任务上均优于现有模型，成功率提高了33%，碰撞率降低了54%，并展现出对未见任务组合的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 机器人需要在非结构化、开放世界环境中安全地适应各种人类指令。现有的视觉-语言模型（VLMs）虽然在语言和感知基础方面表现出色，但在导航任务中的可控性较差，难以直接应用于机器人任务。

Method: VENTURA通过微调互联网预训练的图像扩散模型来进行路径规划。它不直接预测低级动作，而是在图像空间中生成路径掩码（视觉计划），该掩码能够捕捉细粒度、上下文感知的导航行为。然后，一个轻量级的行为克隆策略将这些视觉计划转化为可执行的轨迹。为了扩大训练规模，系统使用源自自监督跟踪模型并与VLM增强的标题配对的路径掩码进行监督，避免了手动像素级标注或复杂的数据收集。

Result: 在广泛的真实世界评估中，VENTURA在物体到达、避障和地形偏好任务上，成功率提高了33%，碰撞率降低了54%，优于最先进的基金模型基线，并且在已见和未见的场景中均表现出色。此外，VENTURA还能泛化到未见的任务组合，显示出新兴的组合能力。

Conclusion: VENTURA通过创新的视觉规划方法，有效解决了现有VLM在机器人导航中的局限性，显著提高了导航性能和安全性，并展现出优异的泛化和组合能力。

Abstract: Robots must adapt to diverse human instructions and operate safely in
unstructured, open-world environments. Recent Vision-Language models (VLMs)
offer strong priors for grounding language and perception, but remain difficult
to steer for navigation due to differences in action spaces and pretraining
objectives that hamper transferability to robotics tasks. Towards addressing
this, we introduce VENTURA, a vision-language navigation system that finetunes
internet-pretrained image diffusion models for path planning. Instead of
directly predicting low-level actions, VENTURA generates a path mask (i.e. a
visual plan) in image space that captures fine-grained, context-aware
navigation behaviors. A lightweight behavior-cloning policy grounds these
visual plans into executable trajectories, yielding an interface that follows
natural language instructions to generate diverse robot behaviors. To scale
training, we supervise on path masks derived from self-supervised tracking
models paired with VLM-augmented captions, avoiding manual pixel-level
annotation or highly engineered data collection setups. In extensive real-world
evaluations, VENTURA outperforms state-of-the-art foundation model baselines on
object reaching, obstacle avoidance, and terrain preference tasks, improving
success rates by 33% and reducing collisions by 54% across both seen and unseen
scenarios. Notably, we find that VENTURA generalizes to unseen combinations of
distinct tasks, revealing emergent compositional capabilities. Videos, code,
and additional materials: https://venturapath.github.io

</details>


### [262] [TACOS: Task Agnostic COordinator of a multi-drone System](https://arxiv.org/abs/2510.01869)
*Alessandro Nazzari,Roberto Rubinacci,Marco Lovera*

Main category: cs.RO

TL;DR: TACOS是一个统一的框架，利用大型语言模型（LLM）通过自然语言高层控制多无人机系统。


<details>
  <summary>Details</summary>
Motivation: 当一名飞行员负责管理多无人机系统时，任务需求不同级别的自主性，从单独控制单个无人机到群体协调，再到完全自主的群体行为以完成高级任务。需要一个支持多种共享自主模式的框架来实现灵活的交互。随着语言模型在推理和规划方面不断改进，它们为这类系统提供了天然的基础，通过直观的、基于语言的接口实现高级任务委托，从而减轻飞行员的工作负担。

Method: TACOS框架集成了三种关键能力：一个用于直观用户交互的一对多自然语言接口，一个用于将用户意图转换为结构化任务计划的智能协调器，以及一个执行计划并与现实世界交互的自主代理。TACOS允许LLM与可执行API库进行交互，从而将语义推理与实时多机器人协调联系起来。

Result: 我们在现实世界的多无人机系统中演示了该系统，并进行了一项消融研究以评估每个模块的贡献。

Conclusion: TACOS通过LLM实现了对多无人机系统的多模式共享自主控制。

Abstract: When a single pilot is responsible for managing a multi-drone system, the
task demands varying levels of autonomy, from direct control of individual
UAVs, to group-level coordination, to fully autonomous swarm behaviors for
accomplishing high-level tasks. Enabling such flexible interaction requires a
framework that supports multiple modes of shared autonomy. As language models
continue to improve in reasoning and planning, they provide a natural
foundation for such systems, reducing pilot workload by enabling high-level
task delegation through intuitive, language-based interfaces. In this paper we
present TACOS (Task-Agnostic COordinator of a multi-drone System), a unified
framework that enables high-level natural language control of multi-UAV systems
through Large Language Models (LLMs). TACOS integrates three key capabilities
into a single architecture: a one-to-many natural language interface for
intuitive user interaction, an intelligent coordinator for translating user
intent into structured task plans, and an autonomous agent that executes plans
interacting with the real-world. TACOS allows a LLM to interact with a library
of executable APIs, bridging semantic reasoning with real-time multi-robot
coordination. We demonstrate the system in real-world multi-drone system and
conduct an ablation study to assess the contribution of each module.

</details>


### [263] [INSIGHT: INference-time Sequence Introspection for Generating Help Triggers in Vision-Language-Action Models](https://arxiv.org/abs/2510.01389)
*Ulas Berk Karli,Ziyao Shangguan,Tesca FItzgerald*

Main category: cs.RO

TL;DR: INSIGHT是一个学习框架，利用基于令牌的_不确定性信号来预测视觉-语言-动作（VLA）模型何时应请求帮助。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型虽然泛化能力强，但缺乏预测失败和向人类监督者请求帮助的内省机制。

Method: 使用_pi_0-FAST模型，提取每个令牌的_熵、_对数概率和基于狄利克雷分布的不确定性估计。训练紧凑型Transformer分类器将这些序列映射到帮助触发器。探索了强弱监督机制，并在分布内和分布外任务中进行了比较。

Result: 强标签能实现精细的不确定性动态捕捉，从而可靠地检测帮助需求。弱标签虽然有噪声，但在训练和评估一致的情况下仍能实现有竞争力的内省，为无法进行密集注释的情况提供了可扩展的途径。建模令牌级不确定性信号的时间演变比静态序列级分数具有更强的预测能力。

Conclusion: 这项研究首次系统地评估了VLA中基于不确定性的内省机制，为主动学习和通过选择性人工干预进行实时错误缓解开辟了新途径。

Abstract: Recent Vision-Language-Action (VLA) models show strong generalization
capabilities, yet they lack introspective mechanisms for anticipating failures
and requesting help from a human supervisor. We present \textbf{INSIGHT}, a
learning framework for leveraging token-level uncertainty signals to predict
when a VLA should request help. Using $\pi_0$-FAST as the underlying model, we
extract per-token \emph{entropy}, \emph{log-probability}, and Dirichlet-based
estimates of \emph{aleatoric and epistemic uncertainty}, and train compact
transformer classifiers to map these sequences to help triggers. We explore
supervision regimes for strong or weak supervision, and extensively compare
them across in-distribution and out-of-distribution tasks. Our results show a
trade-off: strong labels enable models to capture fine-grained uncertainty
dynamics for reliable help detection, while weak labels, though noisier, still
support competitive introspection when training and evaluation are aligned,
offering a scalable path when dense annotation is impractical. Crucially, we
find that modeling the temporal evolution of token-level uncertainty signals
with transformers provides far greater predictive power than static
sequence-level scores. This study provides the first systematic evaluation of
uncertainty-based introspection in VLAs, opening future avenues for active
learning and for real-time error mitigation through selective human
intervention.

</details>


### [264] [Beyond Collision Cones: Dynamic Obstacle Avoidance for Nonholonomic Robots via Dynamic Parabolic Control Barrier Functions](https://arxiv.org/abs/2510.01402)
*Hun Kuk Park,Taekyung Kim,Dimitra Panagou*

Main category: cs.RO

TL;DR: 提出一种动态抛物面控制屏障函数（DPCBF），用于解决非完整机器人面临的动态环境避障问题，并提升了导航成功率和二次规划（QP）的可行性。


<details>
  <summary>Details</summary>
Motivation: 现有基于控制屏障函数（CBF）的方法在处理非完整机器人于复杂动态环境中的避障问题时，由于过度保守的约束（如碰撞锥或速度障碍物），常常导致二次规划（QP）不可行，尤其是在密集场景下。

Method: 提出一种动态抛物面控制屏障函数（DPCBF），它使用抛物面边界来定义安全集。该抛物面的顶点和曲率会根据与障碍物的距离和相对速度的大小动态调整，从而放宽了安全约束。证明了该DPCBF对于具有输入约束的运动学自行车模型是有效的。

Result: 与基线方法相比，DPCBF显著提高了导航成功率和QP可行性。DPCBF能够成功导航通过包含多达100个动态障碍物的密集环境，而基于碰撞锥的方法在此类场景下因不可行而失败。

Conclusion: 所提出的动态抛物面控制屏障函数（DPCBF）能够有效地处理非完整机器人于密集动态环境中的避障问题，克服了现有方法的局限性，显著提高了导航性能和算法的可行性。

Abstract: Control Barrier Functions (CBFs) are a powerful tool for ensuring the safety
of autonomous systems, yet applying them to nonholonomic robots in cluttered,
dynamic environments remains an open challenge. State-of-the-art methods often
rely on collision-cone or velocity-obstacle constraints which, by only
considering the angle of the relative velocity, are inherently conservative and
can render the CBF-based quadratic program infeasible, particularly in dense
scenarios. To address this issue, we propose a Dynamic Parabolic Control
Barrier Function (DPCBF) that defines the safe set using a parabolic boundary.
The parabola's vertex and curvature dynamically adapt based on both the
distance to an obstacle and the magnitude of the relative velocity, creating a
less restrictive safety constraint. We prove that the proposed DPCBF is valid
for a kinematic bicycle model subject to input constraints. Extensive
comparative simulations demonstrate that our DPCBF-based controller
significantly enhances navigation success rates and QP feasibility compared to
baseline methods. Our approach successfully navigates through dense
environments with up to 100 dynamic obstacles, scenarios where collision
cone-based methods fail due to infeasibility.

</details>


### [265] [How Well do Diffusion Policies Learn Kinematic Constraint Manifolds?](https://arxiv.org/abs/2510.01404)
*Lexi Foland,Thomas Cohn,Adam Wei,Nicholas Pfaff,Boyuan Chen,Russ Tedrake*

Main category: cs.RO

TL;DR: 扩散策略在机器人模仿学习中表现出色，即使对于需要满足运动学等式约束的任务也是如此。然而，任务表现本身并不能完全反映策略从训练数据中精确学习约束的能力。本研究通过一个涉及双臂抓取和放置任务的案例研究，分析了扩散策略在多大程度上能够发现这些流形，该任务需要满足运动学约束才能成功。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在分析扩散策略在多大程度上能够发现并学习训练数据中的运动学等式约束流形，并探讨数据集大小、数据集质量和流形曲率这三个因素对训练策略的影响。

Method: 通过一个涉及双臂抓取和放置任务的案例研究，分析了三个因素（数据集大小、数据集质量和流形曲率）对扩散策略学习运动学约束的影响。

Result: 实验表明，扩散策略学习到的约束流形是一个粗略的近似，数据集大小和质量的下降都会对学习产生负面影响。而流形曲率与约束满足和任务成功之间的相关性则不明确。硬件评估验证了研究结果的实际应用性。

Conclusion: 扩散策略能够学习到约束流形的一个粗略近似，但学习效果会受到数据集大小和质量的下降的影响。流形曲率对约束满足和任务成功的影响尚不明确。研究结果在现实世界中得到了验证。

Abstract: Diffusion policies have shown impressive results in robot imitation learning,
even for tasks that require satisfaction of kinematic equality constraints.
However, task performance alone is not a reliable indicator of the policy's
ability to precisely learn constraints in the training data. To investigate, we
analyze how well diffusion policies discover these manifolds with a case study
on a bimanual pick-and-place task that encourages fulfillment of a kinematic
constraint for success. We study how three factors affect trained policies:
dataset size, dataset quality, and manifold curvature. Our experiments show
diffusion policies learn a coarse approximation of the constraint manifold with
learning affected negatively by decreases in both dataset size and quality. On
the other hand, the curvature of the constraint manifold showed inconclusive
correlations with both constraint satisfaction and task success. A hardware
evaluation verifies the applicability of our results in the real world. Project
website with additional results and visuals:
https://diffusion-learns-kinematic.github.io

</details>


### [266] [AFFORD2ACT: Affordance-Guided Automatic Keypoint Selection for Generalizable and Lightweight Robotic Manipulation](https://arxiv.org/abs/2510.01433)
*Anukriti Singh,Kasra Torshizi,Khuzema Habib,Kelin Yu,Ruohan Gao,Pratap Tokekar*

Main category: cs.RO

TL;DR: AFFORD2ACT是一个新框架，它能从文本提示和单个图像中提取最少量的语义2D关键点，用于机器人抓取任务。该框架通过三个阶段：过滤、构建和策略学习，实现了高效的实时操作，并在各种真实世界任务中表现出色，成功率达到82%。


<details>
  <summary>Details</summary>
Motivation: 现有的基于视觉的机器人学习方法依赖计算量大的密集输入，或依赖手动启发式/任务耦合选择的关键点方法，限制了可扩展性和语义理解。AFFORD2ACT旨在通过提取最少量的语义2D关键点来解决这些问题。

Method: AFFORD2ACT框架包含三个阶段：1. 过滤：从文本提示和单个图像中提取一个最小的语义2D关键点集合。2. 构建：进行类别级别的关键点构建。3. 策略学习：利用嵌入式门控的Transformer进行策略学习，以识别最相关的关键点。最终得到一个38维的状态策略。

Result: AFFORD2ACT策略可以在15分钟内进行训练，并在实时操作中表现良好，无需本体感觉或密集表示。在各种真实世界的操纵任务中，AFFORD2ACT显著提高了数据效率，在未见过的物体、新类别、背景和干扰物上取得了82%的成功率。

Conclusion: AFFORD2ACT框架通过从文本和图像中提取少量语义关键点，有效解决了机器人抓取任务中的计算效率和可扩展性问题，并在各种真实世界场景中取得了优异的性能。

Abstract: Vision-based robot learning often relies on dense image or point-cloud
inputs, which are computationally heavy and entangle irrelevant background
features. Existing keypoint-based approaches can focus on manipulation-centric
features and be lightweight, but either depend on manual heuristics or
task-coupled selection, limiting scalability and semantic understanding. To
address this, we propose AFFORD2ACT, an affordance-guided framework that
distills a minimal set of semantic 2D keypoints from a text prompt and a single
image. AFFORD2ACT follows a three-stage pipeline: affordance filtering,
category-level keypoint construction, and transformer-based policy learning
with embedded gating to reason about the most relevant keypoints, yielding a
compact 38-dimensional state policy that can be trained in 15 minutes, which
performs well in real-time without proprioception or dense representations.
Across diverse real-world manipulation tasks, AFFORD2ACT consistently improves
data efficiency, achieving an 82% success rate on unseen objects, novel
categories, backgrounds, and distractors.

</details>


### [267] [Differentiable Skill Optimisation for Powder Manipulation in Laboratory Automation](https://arxiv.org/abs/2510.01438)
*Minglun Wei,Xintong Yang,Yu-Kun Lai,Ze Ji*

Main category: cs.RO

TL;DR: 我们提出了一种用于实验室粉末输送的轨迹优化框架，该框架结合了可微分物理模拟、低维技能空间参数化和基于课程的学习策略，以实现高效、稳定的粉末输送。


<details>
  <summary>Details</summary>
Motivation: 精确的粉末操作在实验室自动化中仍然是一个挑战，尤其是在运输等需要精度和稳定性的任务中。

Method: 提出了一种轨迹优化框架，该框架集成了可微分物理模拟、低维技能空间参数化和基于课程的学习策略。

Result: 与强化学习基线相比，该方法在任务成功率和稳定性方面均优于基线。

Conclusion: 实验结果表明，我们提出的方法在粉末运输任务上实现了更高的成功率和稳定性，优于强化学习基线。

Abstract: Robotic automation is accelerating scientific discovery by reducing manual
effort in laboratory workflows. However, precise manipulation of powders
remains challenging, particularly in tasks such as transport that demand
accuracy and stability. We propose a trajectory optimisation framework for
powder transport in laboratory settings, which integrates differentiable
physics simulation for accurate modelling of granular dynamics, low-dimensional
skill-space parameterisation to reduce optimisation complexity, and a
curriculum-based strategy that progressively refines task competence over long
horizons. This formulation enables end-to-end optimisation of contact-rich
robot trajectories while maintaining stability and convergence efficiency.
Experimental results demonstrate that the proposed method achieves superior
task success rates and stability compared to the reinforcement learning
baseline.

</details>


### [268] [Touching the tumor boundary: A pilot study on ultrasound based virtual fixtures for breast-conserving surgery](https://arxiv.org/abs/2510.01452)
*Laura Connolly,Tamas Ungi,Adnan Munawar,Anton Deguet,Chris Yeung,Russell H. Taylor,Parvin Mousavi,Gabor Fichtinger Keyvan Hashtrudi-Zaad*

Main category: cs.RO

TL;DR: 本研究介绍了一种结合触觉反馈的机器人辅助手术系统，用于提高乳腺癌保乳手术中肿瘤边界的定位精度，并评估了其在模拟手术中的应用效果。


<details>
  <summary>Details</summary>
Motivation: 在乳腺癌保乳手术中，肿瘤边界的精确勾画面临肿瘤移位、难以触摸以及形态不规则等挑战。本研究旨在探索一种能够克服这些困难的机器人辅助手术系统。

Method: 研究将一个小型触觉机器人改装为带有电刀的协同控制手术工具，并利用超声和电磁导航技术识别肿瘤边界与位置。当手术工具触及肿瘤边界时，会施加虚拟边界限制。在模拟手术中，比较了有无触觉引导下用户切除肿瘤的表现，并从定性和定量两个方面评估了结果。

Result: 研究表明，虚拟边界引导能够改善切除边缘的精确度。有触觉反馈时，用户在精神负担、挫败感和体力消耗方面均有降低。此外，研究还发现了对现有手术流程产生意外影响的因素，为后续系统设计和培训方案的调整提供了依据。

Conclusion: 研究结果表明，虚拟边界技术有助于在模拟的乳腺癌保乳手术中精确定位肿瘤边界。未来的工作将侧重于进行更广泛的用户研究，以进一步验证这些发现并优化引导系统。

Abstract: Purpose: Delineating tumor boundaries during breast-conserving surgery is
challenging as tumors are often highly mobile, non-palpable, and have
irregularly shaped borders. To address these challenges, we introduce a
cooperative robotic guidance system that applies haptic feedback for tumor
localization. In this pilot study, we aim to assess if and how this system can
be successfully integrated into breast cancer care.
  Methods: A small haptic robot is retrofitted with an electrocautery blade to
operate as a cooperatively controlled surgical tool. Ultrasound and
electromagnetic navigation are used to identify the tumor boundaries and
position. A forbidden region virtual fixture is imposed when the surgical tool
collides with the tumor boundary. We conducted a study where users were asked
to resect tumors from breast simulants both with and without the haptic
guidance. We then assess the results of these simulated resections both
qualitatively and quantitatively.
  Results: Virtual fixture guidance is shown to improve resection margins. On
average, users find the task to be less mentally demanding, frustrating, and
effort intensive when haptic feedback is available. We also discovered some
unanticipated impacts on surgical workflow that will guide design adjustments
and training protocol moving forward.
  Conclusion: Our results suggest that virtual fixtures can help localize tumor
boundaries in simulated breast-conserving surgery. Future work will include an
extensive user study to further validate these results and fine-tune our
guidance system.

</details>


### [269] [VL-KnG: Visual Scene Understanding for Navigation Goal Identification using Spatiotemporal Knowledge Graphs](https://arxiv.org/abs/2510.01483)
*Mohamad Al Mdfaa,Svetlana Lukina,Timur Akhtyamov,Arthur Nigmatzyanov,Dmitrii Nalberskii,Sergey Zagoruyko,Gonzalo Ferrer*

Main category: cs.RO

TL;DR: VL-KnG是一个视觉场景理解系统，通过构建时空知识图谱和高效查询处理来解决机器人导航中的挑战，解决了现有VLM的场景记忆、空间推理和可扩展性问题。它通过处理视频片段、维护对象身份的持久知识图谱以及可查询的图结构来实现可解释的空间推理。新基准WalkieKnowledge用于评估此类方法。实验表明，VL-KnG在机器人导航任务中取得了77.27%的成功率和76.92%的准确率，性能与Gemini 2.5 Pro相当，并提供了可解释的推理和实时部署的计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（VLMs）在机器人导航方面存在根本性限制，包括缺乏持久场景记忆、空间推理能力有限以及无法有效扩展以支持实时应用。

Method: 提出VL-KnG系统，该系统通过构建时空知识图谱和高效的查询处理来解决机器人导航的挑战。该方法将视频序列分块处理，利用现代VLMs构建持久的知识图谱以维持对象身份，并通过可查询的图结构实现可解释的空间推理。此外，还引入了一个名为WalkieKnowledge的新基准，包含手动标注的问题和多样化的视频数据。

Result: 在真实世界的差速驱动机器人上进行部署，VL-KnG实现了77.27%的成功率和76.92%的答案准确率。其性能与Gemini 2.5 Pro相当，同时通过知识图谱提供了可解释的推理，并具有计算效率，适用于实时部署，可用于定位、导航和规划等不同任务。

Conclusion: VL-KnG系统通过构建时空知识图谱和高效查询处理，有效地解决了机器人导航中的关键挑战，如缺乏持久场景记忆、有限的空间推理和可扩展性问题。该方法在真实机器人部署中表现出实际应用能力，性能优越且具有可解释性，为机器人导航领域提供了新的解决方案。

Abstract: Vision-language models (VLMs) have shown potential for robot navigation but
encounter fundamental limitations: they lack persistent scene memory, offer
limited spatial reasoning, and do not scale effectively with video duration for
real-time application. We present VL-KnG, a Visual Scene Understanding system
that tackles these challenges using spatiotemporal knowledge graph construction
and computationally efficient query processing for navigation goal
identification. Our approach processes video sequences in chunks utilizing
modern VLMs, creates persistent knowledge graphs that maintain object identity
over time, and enables explainable spatial reasoning through queryable graph
structures. We also introduce WalkieKnowledge, a new benchmark with about 200
manually annotated questions across 8 diverse trajectories spanning
approximately 100 minutes of video data, enabling fair comparison between
structured approaches and general-purpose VLMs. Real-world deployment on a
differential drive robot demonstrates practical applicability, with our method
achieving 77.27% success rate and 76.92% answer accuracy, matching Gemini 2.5
Pro performance while providing explainable reasoning supported by the
knowledge graph, computational efficiency for real-time deployment across
different tasks, such as localization, navigation and planning. Code and
dataset will be released after acceptance.

</details>


### [270] [Pose Estimation of a Thruster-Driven Bioinspired Multi-Link Robot](https://arxiv.org/abs/2510.01485)
*Nicholas B. Andrews,Yanhao Yang,Sofya Akhetova,Kristi A. Morgansen,Ross L. Hatton*

Main category: cs.RO

TL;DR: 该研究展示了一种用于自由漂浮、受生物启发的、具有未驱动关节、连杆安装推进器和每个连杆单个陀螺仪的多连杆机器人的姿态（位置和形状）估计，这是一种欠驱动、传感最小化的平台。


<details>
  <summary>Details</summary>
Motivation: 研究目标是实现一种欠驱动、传感最小化的自由漂浮多连杆机器人的姿态估计。

Method: 利用无迹卡尔曼滤波器，并加入高斯过程残差学习，以补偿非零均值、非高斯噪声。

Result: 通过概念验证硬件实验和离线卡尔曼滤波器分析，证明了该机器人姿态可以被可靠地估计。研究还表明，在多步态（前进、后退、左转、右转和转向）数据集上训练的滤波器，在评估相同的前进步态测试轨迹时，其性能与仅在前进步态数据集上训练的滤波器相当。

Conclusion: 研究结果揭示了步态输入空间的重叠性，可以利用这种重叠性来减少训练数据需求，同时增强滤波器在多种步态上的泛化能力。

Abstract: This work demonstrates pose (position and shape) estimation for a
free-floating, bioinspired multi-link robot with unactuated joints,
link-mounted thrusters for control, and a single gyroscope per link, resulting
in an underactuated, minimally sensed platform. Through a proof-of-concept
hardware experiment and offline Kalman filter analysis, we show that the
robot's pose can be reliably estimated. State estimation is performed using an
unscented Kalman filter augmented with Gaussian process residual learning to
compensate for non-zero-mean, non-Gaussian noise. We further show that a filter
trained on a multi-gait dataset (forward, backward, left, right, and turning)
performs comparably to one trained on a larger forward-gait-only dataset when
both are evaluated on the same forward-gait test trajectory. These results
reveal overlap in the gait input space, which can be exploited to reduce
training data requirements while enhancing the filter's generalizability across
multiple gaits.

</details>


### [271] [Online Hierarchical Policy Learning using Physics Priors for Robot Navigation in Unknown Environments](https://arxiv.org/abs/2510.01519)
*Wei Han Chen,Yuchen Liu,Alexiy Buynitsky,Ahmed H. Qureshi*

Main category: cs.RO

TL;DR: ANTFields在大型、复杂、未知室内环境中进行机器人导航，通过分层结构解决了现有方法的局限性，并在大规模环境中验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有机器人导航方法在大型、复杂、未知室内环境中存在分辨率控制、可扩展性差、需要大量演示数据等问题。ANTFields虽然有潜力，但受限于频谱偏差和灾难性遗忘。

Method: 提出一种分层方法：高层使用稀疏图捕捉全局连通性，低层使用基于神经场的方法结合Eikonal PDE进行局部避障，克服了频谱偏差和神经场拟合困难。

Result: 该方法在大型环境中表现出增强的适应性和精确性，克服了现有方法的局限性，能够实现平滑且精确的成本函数表示。

Conclusion: 所提出的分层方法在大型、复杂、未知室内环境中有效，相比先前方法具有更好的适应性和精确性，有潜力用于在线探索、建图和实际导航。

Abstract: Robot navigation in large, complex, and unknown indoor environments is a
challenging problem. The existing approaches, such as traditional
sampling-based methods, struggle with resolution control and scalability, while
imitation learning-based methods require a large amount of demonstration data.
Active Neural Time Fields (ANTFields) have recently emerged as a promising
solution by using local observations to learn cost-to-go functions without
relying on demonstrations. Despite their potential, these methods are hampered
by challenges such as spectral bias and catastrophic forgetting, which diminish
their effectiveness in complex scenarios. To address these issues, our approach
decomposes the planning problem into a hierarchical structure. At the high
level, a sparse graph captures the environment's global connectivity, while at
the low level, a planner based on neural fields navigates local obstacles by
solving the Eikonal PDE. This physics-informed strategy overcomes common
pitfalls like spectral bias and neural field fitting difficulties, resulting in
a smooth and precise representation of the cost landscape. We validate our
framework in large-scale environments, demonstrating its enhanced adaptability
and precision compared to previous methods, and highlighting its potential for
online exploration, mapping, and real-world navigation.

</details>


### [272] [Real-time Multi-Plane Segmentation Based on GPU Accelerated High-Resolution 3D Voxel Mapping for Legged Robot Locomotion](https://arxiv.org/abs/2510.01592)
*Shun Niijima,Ryoichi Tsuzaki,Noriaki Takasugi,Masaya Kinoshita*

Main category: cs.RO

TL;DR: 提出了一种基于GPU加速的高分辨率3D体素映射的实时多平面分割方法，以提高多足机器人的运动能力。


<details>
  <summary>Details</summary>
Motivation: 现有的在线平面建图方法在准确性和计算效率之间难以平衡，本文旨在解决此问题。

Method: 提出了一种结合顶点连接组件标记、随机采样一致性平面检测和凸包的新框架，利用GPU并行计算从高分辨率3D体素图中累积的点云中快速提取平面区域。

Result: 该方法实现了超过30 Hz的更新率，即使在0.01 m的分辨率下也能实现快速准确的3D多平面分割，并已成功应用于机器人运动任务。

Conclusion: 实验证明，该方法在模拟环境和物理多足机器人平台上都表现出了鲁棒性，并能有效利用3D平面结构进行运动。

Abstract: This paper proposes a real-time multi-plane segmentation method based on
GPU-accelerated high-resolution 3D voxel mapping for legged robot locomotion.
Existing online planar mapping approaches struggle to balance accuracy and
computational efficiency: direct depth image segmentation from specific sensors
suffers from poor temporal integration, height map-based methods cannot
represent complex 3D structures like overhangs, and voxel-based plane
segmentation remains unexplored for real-time applications. To address these
limitations, we develop a novel framework that integrates vertex-based
connected component labeling with random sample consensus based plane detection
and convex hull, leveraging GPU parallel computing to rapidly extract planar
regions from point clouds accumulated in high-resolution 3D voxel maps.
Experimental results demonstrate that the proposed method achieves fast and
accurate 3D multi-plane segmentation at over 30 Hz update rate even at a
resolution of 0.01 m, enabling the detected planes to be utilized in real time
for locomotion tasks. Furthermore, we validate the effectiveness of our
approach through experiments in both simulated environments and physical legged
robot platforms, confirming robust locomotion performance when considering 3D
planar structures.

</details>


### [273] [MiniBEE: A New Form Factor for Compact Bimanual Dexterity](https://arxiv.org/abs/2510.01603)
*Sharfin Islam,Zewen Chen,Zhanpeng He,Swapneel Bhatt,Andres Permuy,Brock Taylor,James Vickery,Pedro Piacenza,Cheng Zhang,Matei Ciocarlie*

Main category: cs.RO

TL;DR: 小型双臂协作机器人手臂，通过运动链设计，扩大了灵巧操作范围，并可用于可穿戴数据采集或扩展现有机器人手臂的灵巧性。


<details>
  <summary>Details</summary>
Motivation: 传统双臂机器人依赖笨重、高自由度的手臂，限制了灵巧交互的工作空间。本研究旨在设计一种更紧凑、更轻便的系统，以提高双臂操作的灵活性和效率。

Method: 提出了一种名为MiniBEE（小型双臂末端执行器）的紧凑型系统，该系统使用两个低自由度（各3+ DOF）的手臂，并将它们耦合成一个运动链，以保持抓手之间的相对位置。设计中采用了运动学灵巧性指标来优化设计，以扩大灵巧操作范围。MiniBEE支持两种模式：可穿戴数据采集和部署在标准机器人手臂上。

Result: MiniBEE系统成功实现了双手抓取器的灵巧协同操作，扩大了有效工作空间。该系统可用于可穿戴数据采集，并通过演示训练模仿学习策略，实现稳健的现实世界双臂操作。

Conclusion: MiniBEE系统通过创新的运动链设计和优化的灵巧性指标，有效解决了传统双臂机器人系统的局限性，提供了更灵活、更轻便的双臂操作解决方案，并在可穿戴数据采集和机器人应用方面展现了巨大潜力。

Abstract: Bimanual robot manipulators can achieve impressive dexterity, but typically
rely on two full six- or seven- degree-of-freedom arms so that paired grippers
can coordinate effectively. This traditional framework increases system
complexity while only exploiting a fraction of the overall workspace for
dexterous interaction. We introduce the MiniBEE (Miniature Bimanual
End-effector), a compact system in which two reduced-mobility arms (3+ DOF
each) are coupled into a kinematic chain that preserves full relative
positioning between grippers. To guide our design, we formulate a kinematic
dexterity metric that enlarges the dexterous workspace while keeping the
mechanism lightweight and wearable. The resulting system supports two
complementary modes: (i) wearable kinesthetic data collection with self-tracked
gripper poses, and (ii) deployment on a standard robot arm, extending dexterity
across its entire workspace. We present kinematic analysis and design
optimization methods for maximizing dexterous range, and demonstrate an
end-to-end pipeline in which wearable demonstrations train imitation learning
policies that perform robust, real-world bimanual manipulation.

</details>


### [274] [ActiveUMI: Robotic Manipulation with Active Perception from Robot-Free Human Demonstrations](https://arxiv.org/abs/2510.01607)
*Qiyuan Zeng,Chengmeng Li,Jude St. John,Zhongyi Zhou,Junjie Wen,Guorui Feng,Yichen Zhu,Yi Xu*

Main category: cs.RO

TL;DR: ActiveUMI是一个便携式VR遥操作套件，通过传感器控制器捕捉人类在野外的手部演示，用于训练能执行复杂双臂操作的机器人。该系统通过精确的姿态对齐连接人机运动学，并结合沉浸式3D渲染、可穿戴计算机和高效校准方法，以实现移动性和数据质量。其核心特点是捕捉主动、以自我为中心的感知，通过记录操作员头部的运动来学习视觉注意力与操作之间的联系。在六项双臂任务上的评估显示，仅使用ActiveUMI数据训练的策略在分布内任务上的平均成功率为70%，在新物体和新环境上的泛化成功率为56%。研究表明，便携式数据收集系统与学习到的主动感知相结合，是创建可泛化、高能力机器人策略的有效途径。


<details>
  <summary>Details</summary>
Motivation: 收集可在野外进行复杂双臂操作的机器人数据。

Method: 使用便携式VR遥操作套件和传感器控制器，通过精确姿态对齐捕捉人类操作演示，并记录操作员头部的运动以学习视觉注意力与操作的联系。结合沉浸式3D渲染、可穿戴计算机和高效校准方法。

Result: 在六项双臂任务上，仅使用ActiveUMI数据训练的策略在分布内任务上的平均成功率为70%，在测试新物体和新环境上的泛化成功率为56%。

Conclusion: 便携式数据收集系统与学习到的主动感知相结合，是创建可泛化、高能力机器人策略的有效且可扩展的途径。

Abstract: We present ActiveUMI, a framework for a data collection system that transfers
in-the-wild human demonstrations to robots capable of complex bimanual
manipulation. ActiveUMI couples a portable VR teleoperation kit with sensorized
controllers that mirror the robot's end-effectors, bridging human-robot
kinematics via precise pose alignment. To ensure mobility and data quality, we
introduce several key techniques, including immersive 3D model rendering, a
self-contained wearable computer, and efficient calibration methods.
ActiveUMI's defining feature is its capture of active, egocentric perception.
By recording an operator's deliberate head movements via a head-mounted
display, our system learns the crucial link between visual attention and
manipulation. We evaluate ActiveUMI on six challenging bimanual tasks. Policies
trained exclusively on ActiveUMI data achieve an average success rate of 70\%
on in-distribution tasks and demonstrate strong generalization, retaining a
56\% success rate when tested on novel objects and in new environments. Our
results demonstrate that portable data collection systems, when coupled with
learned active perception, provide an effective and scalable pathway toward
creating generalizable and highly capable real-world robot policies.

</details>


### [275] [FailSafe: Reasoning and Recovery from Failures in Vision-Language-Action Models](https://arxiv.org/abs/2510.01642)
*Zijun Lin,Jiafei Duan,Haoquan Fang,Dieter Fox,Ranjay Krishna,Cheston Tan,Bihan Wen*

Main category: cs.RO

TL;DR: FailSafe是一个新的失败生成和恢复系统，可以自动生成失败案例并配对可执行的恢复动作，以提高机器人操作的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人操作数据集主要提供地面真实轨迹，无法处理执行中的失败。即使有处理失败的数据集，通常也只提供文本解释，难以直接用于视觉语言-动作（VLA）模型。这阻碍了机器人从不可预测的失败中恢复的能力。

Method: FailSafe系统能够自动生成多样化的失败案例，并为这些失败提供可执行的恢复动作。该系统可以应用于任何模拟器中的任何操作任务，从而可扩展地创建失败-动作数据。研究人员使用FailSafe系统对LLaVa-OneVision-7B（LLaVa-OV-7B）进行了微调，构建了FailSafe-VLM。

Result: FailSafe-VLM成功帮助机械臂检测并从潜在故障中恢复，在Maniskill的几项任务中，与三种最先进的VLA模型（pi0-FAST、OpenVLA、OpenVLA-OFT）相比，平均性能提高了22.6%。此外，FailSafe-VLM能够泛化到不同的空间配置、摄像机视角和机器人实体。

Conclusion: FailSafe系统能够有效地生成机器人操作中的失败案例并提供恢复策略，显著提高了VLA模型的性能和鲁棒性，并具有良好的泛化能力。研究计划将FailSafe代码开源以供社区使用。

Abstract: Recent advances in robotic manipulation have integrated low-level robotic
control into Vision-Language Models (VLMs), extending them into
Vision-Language-Action (VLA) models. Although state-of-the-art VLAs achieve
strong performance in downstream robotic applications, supported by large-scale
crowd-sourced robot training data, they still inevitably encounter failures
during execution. Enabling robots to reason about and recover from
unpredictable and abrupt failures remains a critical challenge. Existing
robotic manipulation datasets, collected in either simulation or the real
world, primarily provide only ground-truth trajectories, leaving robots unable
to recover once failures occur. Moreover, the few datasets that address failure
detection typically offer only textual explanations, which are difficult to
utilize directly in VLA models. To address this gap, we introduce FailSafe, a
novel failure generation and recovery system that automatically produces
diverse failure cases paired with executable recovery actions. FailSafe can be
seamlessly applied to any manipulation task in any simulator, enabling scalable
creation of failure-action data. To demonstrate its effectiveness, we fine-tune
LLaVa-OneVision-7B (LLaVa-OV-7B) to build FailSafe-VLM. Experimental results
show that FailSafe-VLM successfully helps robotic arm detect and recover from
potential failures, improving the performance of three state-of-the-art VLA
models pi0-FAST, OpenVLA, OpenVLA-OFT) by up to 22.6% on average across several
tasks in Maniskill. Furthermore, FailSafe-VLM could generalize across different
spatial configurations, camera viewpoints, and robotic embodiments. We plan to
release the FailSafe code to the community.

</details>


### [276] [Statistical Uncertainty Learning for Robust Visual-Inertial State Estimation](https://arxiv.org/abs/2510.01648)
*Seungwon Choi,Donggyu Park,Seo-Yeon Hwang,Tae-Wan Kim*

Main category: cs.RO

TL;DR: 该研究提出了一种在线学习测量可靠性评估的统计框架，用于视觉-惯性里程计（VIO），通过利用多视图几何一致性进行自监督，从而动态地调整视觉测量权重，提高了跟踪精度，并在EuRoC数据集上实现了显著的平移和旋转误差降低。


<details>
  <summary>Details</summary>
Motivation: 传统视觉-惯性里程计（VIO）在动态评估传感器测量可靠性方面面临挑战，通常采用简化的固定不确定性假设，这在处理真实世界数据时可能不足以捕捉动态误差特征。

Method: 提出一个统计框架，利用多视图几何一致性作为自监督信号，在线学习测量可靠性评估，直接从传感器数据和优化结果中推断地标不确定性，并自适应地加权优化过程中的视觉测量。

Result: 在EuRoC数据集上的评估显示，与采用固定不确定性参数的基线方法相比，该方法在跟踪精度上有所提高，平均平移误差降低了约24%，旋转误差降低了约42%。

Conclusion: 所提出的框架能够实时运行，同时提高了精度和鲁棒性，并且将公开源代码以促进研究的重现和进一步发展。

Abstract: A fundamental challenge in robust visual-inertial odometry (VIO) is to
dynamically assess the reliability of sensor measurements. This assessment is
crucial for properly weighting the contribution of each measurement to the
state estimate. Conventional methods often simplify this by assuming a static,
uniform uncertainty for all measurements. This heuristic, however, may be
limited in its ability to capture the dynamic error characteristics inherent in
real-world data. To improve this limitation, we present a statistical framework
that learns measurement reliability assessment online, directly from sensor
data and optimization results. Our approach leverages multi-view geometric
consistency as a form of self-supervision. This enables the system to infer
landmark uncertainty and adaptively weight visual measurements during
optimization. We evaluated our method on the public EuRoC dataset,
demonstrating improvements in tracking accuracy with average reductions of
approximately 24\% in translation error and 42\% in rotation error compared to
baseline methods with fixed uncertainty parameters. The resulting framework
operates in real time while showing enhanced accuracy and robustness. To
facilitate reproducibility and encourage further research, the source code will
be made publicly available.

</details>


### [277] [Symskill: Symbol and Skill Co-Invention for Data-Efficient and Real-Time Long-Horizon Manipulation](https://arxiv.org/abs/2510.01661)
*Yifei Simon Shao,Yuchen Zheng,Sunan Sun,Pratik Chaudhari,Vijay Kumar,Nadia Figueroa*

Main category: cs.RO

TL;DR: SymSkill框架结合了模仿学习和任务与运动规划的优点，实现了实时组合泛化和故障恢复。


<details>
  <summary>Details</summary>
Motivation: 在动态环境中进行多步操作仍然是一个挑战，现有的模仿学习方法缺乏组合泛化能力，而任务与运动规划方法存在规划延迟过高的问题。

Method: SymSkill离线学习谓词、算子和技能，并利用符号规划器实时组合和重排技能以实现目标，同时进行运动和符号层面的恢复。该框架还结合了依从性控制器，以应对干扰。

Result: 在RoboCasa模拟中，SymSkill在12个单步任务中达到了85%的成功率，并能将这些技能组合成最多包含6个技能重组的多步规划，且能从执行失败中恢复。在实际的Franka机器人上，SymSkill仅用5分钟的无标签数据就能执行由目标规格设定的多个任务。

Conclusion: SymSkill框架通过结合模仿学习和任务与运动规划的优点，成功解决了动态环境下的多步操作难题，实现了实时组合泛化和故障恢复。

Abstract: Multi-step manipulation in dynamic environments remains challenging. Two
major families of methods fail in distinct ways: (i) imitation learning (IL) is
reactive but lacks compositional generalization, as monolithic policies do not
decide which skill to reuse when scenes change; (ii) classical task-and-motion
planning (TAMP) offers compositionality but has prohibitive planning latency,
preventing real-time failure recovery. We introduce SymSkill, a unified
learning framework that combines the benefits of IL and TAMP, allowing
compositional generalization and failure recovery in real-time. Offline,
SymSkill jointly learns predicates, operators, and skills directly from
unlabeled and unsegmented demonstrations. At execution time, upon specifying a
conjunction of one or more learned predicates, SymSkill uses a symbolic planner
to compose and reorder learned skills to achieve the symbolic goals, while
performing recovery at both the motion and symbolic levels in real time.
Coupled with a compliant controller, SymSkill enables safe and uninterrupted
execution under human and environmental disturbances. In RoboCasa simulation,
SymSkill can execute 12 single-step tasks with 85% success rate. Without
additional data, it composes these skills into multi-step plans requiring up to
6 skill recompositions, recovering robustly from execution failures. On a real
Franka robot, we demonstrate SymSkill, learning from 5 minutes of unsegmented
and unlabeled play data, is capable of performing multiple tasks simply by goal
specifications. The source code and additional analysis can be found on
https://sites.google.com/view/symskill.

</details>


### [278] [Geometric Backstepping Control of Omnidirectional Tiltrotors Incorporating Servo-Rotor Dynamics for Robustness against Sudden Disturbances](https://arxiv.org/abs/2510.01675)
*Jaewoo Lee,Dongjae Lee,Jinwoo Lee,Hyungyu Lee,Yeonjoon Kim,H. Jin Kim*

Main category: cs.RO

TL;DR: 本文提出了一种考虑了伺服和旋翼动力学的几何反演控制器，用于具有可变倾斜角度的全向多旋翼飞行器，以提高其在复杂飞行任务中的性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有针对多旋翼飞行器的控制器未能充分考虑执行器动力学（伺服和旋翼），尤其是在执行剧烈机动或从扰动中恢复时，这会影响飞行器的有效性和可靠性。先前的工作忽略了可变倾斜角度引起的非线性效应，本文旨在解决这一问题。

Method: 本文利用多旋翼刚体动力学与其非线性执行器动力学之间的级联结构，设计了一种几何反演控制器，并证明了整个系统的指数稳定性。该方法能够处理可变倾斜角度引起的非线性，并能应对执行器模型中的参数不确定性。

Result: 通过实验对比，证明了所提出的控制器在快速平移跟踪、快速旋转跟踪和从突然扰动中恢复这三种场景下，相较于未考虑执行器动力学的基线控制器，具有更优异的跟踪性能。在最苛刻的实验中，基线控制器发生发散甚至崩溃，而所提出的控制器则保持了稳定并成功完成了任务。

Conclusion: 所提出的几何反演控制器通过显式考虑伺服和旋翼动力学，显著提高了全向多旋翼飞行器的性能和鲁棒性，尤其是在执行高难度任务时，能够有效避免不稳定甚至崩溃的情况，证明了其在实际应用中的有效性。

Abstract: This work presents a geometric backstepping controller for a variable-tilt
omnidirectional multirotor that explicitly accounts for both servo and rotor
dynamics. Considering actuator dynamics is essential for more effective and
reliable operation, particularly during aggressive flight maneuvers or recovery
from sudden disturbances. While prior studies have investigated actuator-aware
control for conventional and fixed-tilt multirotors, these approaches rely on
linear relationships between actuator input and wrench, which cannot capture
the nonlinearities induced by variable tilt angles. In this work, we exploit
the cascade structure between the rigid-body dynamics of the multirotor and its
nonlinear actuator dynamics to design the proposed backstepping controller and
establish exponential stability of the overall system. Furthermore, we reveal
parametric uncertainty in the actuator model through experiments, and we
demonstrate that the proposed controller remains robust against such
uncertainty. The controller was compared against a baseline that does not
account for actuator dynamics across three experimental scenarios: fast
translational tracking, rapid rotational tracking, and recovery from sudden
disturbance. The proposed method consistently achieved better tracking
performance, and notably, while the baseline diverged and crashed during the
fastest translational trajectory tracking and the recovery experiment, the
proposed controller maintained stability and successfully completed the tasks,
thereby demonstrating its effectiveness.

</details>


### [279] [PolySim: Bridging the Sim-to-Real Gap for Humanoid Control via Multi-Simulator Dynamics Randomization](https://arxiv.org/abs/2510.01708)
*Zixing Lei,Zibo Zhou,Sheng Yin,Yueru Chen,Qingyao Xu,Weixin Li,Yunhong Wang,Bowei Tang,Wei Jing,Siheng Chen*

Main category: cs.RO

TL;DR: 通过在多个模拟器中联合训练机器人控制策略来弥合模拟与现实之间的差距。


<details>
  <summary>Details</summary>
Motivation: 单个模拟器固有的归纳偏差会导致模拟与现实之间的差异，影响人形机器人全身控制策略的泛化能力。

Method: 提出PolySim，一个集成了多个异构模拟器的全身控制训练平台，通过同时在不同引擎中启动并行环境，实现跨模拟器域随机化。

Result: PolySim在模拟器间的评估中显著减少了运动跟踪误差，在MuJoCo上比IsaacSim基线提高了52.8%的执行成功率。此外，PolySim能够在Unitree G1机器人上实现零样本部署，无需额外微调。

Conclusion: PolySim通过跨多个模拟器进行联合训练，有效解决了模拟与现实之间的差距，提高了机器人控制策略的泛化能力和现实世界部署的鲁棒性。

Abstract: Humanoid whole-body control (WBC) policies trained in simulation often suffer
from the sim-to-real gap, which fundamentally arises from simulator inductive
bias, the inherent assumptions and limitations of any single simulator. These
biases lead to nontrivial discrepancies both across simulators and between
simulation and the real world. To mitigate the effect of simulator inductive
bias, the key idea is to train policies jointly across multiple simulators,
encouraging the learned controller to capture dynamics that generalize beyond
any single simulator's assumptions. We thus introduce PolySim, a WBC training
platform that integrates multiple heterogeneous simulators. PolySim can launch
parallel environments from different engines simultaneously within a single
training run, thereby realizing dynamics-level domain randomization.
Theoretically, we show that PolySim yields a tighter upper bound on simulator
inductive bias than single-simulator training. In experiments, PolySim
substantially reduces motion-tracking error in sim-to-sim evaluations; for
example, on MuJoCo, it improves execution success by 52.8 over an IsaacSim
baseline. PolySim further enables zero-shot deployment on a real Unitree G1
without additional fine-tuning, showing effective transfer from simulation to
the real world. We will release the PolySim code upon acceptance of this work.

</details>


### [280] [Contrastive Representation Regularization for Vision-Language-Action Models](https://arxiv.org/abs/2510.01711)
*Taeyoung Kim,Jimin Lee,Myungkyu Koo,Dongyoung Kim,Kyungmin Lee,Changyeon Kim,Younggyo Seo,Jinwoo Shin*

Main category: cs.RO

TL;DR: 通过引入机器人状态感知对比损失（RS-CL），增强了机器人操作中视觉-语言-动作（VLA）模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型利用预训练的视觉-语言模型（VLMs）的丰富表征，但在处理机器人特有的控制动作和本体感受状态方面仍有不足。本研究旨在解决此问题，使VLA模型的表征对机器人信号更加敏感。

Method: 提出了一种名为机器人状态感知对比损失（RS-CL）的表示正则化方法。RS-CL通过利用本体感受状态之间的相对距离作为软监督，使表征更紧密地贴合机器人的本体感受状态，从而增强了与控制相关的表征学习。该方法轻量级且与标准的VLA训练流程兼容。

Result: RS-CL在RoboCasa-Kitchen的拾放任务上将先前技术的性能从30.8%提升到41.5%，主要通过提高抓取和放置过程中的定位精度。此外，在具有挑战性的真实机器人操作任务上，成功率从45.0%提升到58.3%。

Conclusion: RS-CL是一种有效的方法，可以显著提高最先进的VLA模型在机器人操作任务上的性能，通过改进其对机器人信号的表征能力。

Abstract: Vision-Language-Action (VLA) models have shown its capabilities in robot
manipulation by leveraging rich representations from pre-trained
Vision-Language Models (VLMs). However, their representations arguably remain
suboptimal, lacking sensitivity to robotic signals such as control actions and
proprioceptive states. To address the issue, we introduce Robot State-aware
Contrastive Loss (RS-CL), a simple and effective representation regularization
for VLA models, designed to bridge the gap between VLM representations and
robotic signals. In particular, RS-CL aligns the representations more closely
with the robot's proprioceptive states, by using relative distances between the
states as soft supervision. Complementing the original action prediction
objective, RS-CL effectively enhances control-relevant representation learning,
while being lightweight and fully compatible with standard VLA training
pipeline. Our empirical results demonstrate that RS-CL substantially improves
the manipulation performance of state-of-the-art VLA models; it pushes the
prior art from 30.8% to 41.5% on pick-and-place tasks in RoboCasa-Kitchen,
through more accurate positioning during grasping and placing, and boosts
success rates from 45.0% to 58.3% on challenging real-robot manipulation tasks.

</details>


### [281] [Dual-Mode Magnetic Continuum Robot for Targeted Drug Delivery](https://arxiv.org/abs/2510.01761)
*Wendu Zhang,Heng Wang,Shuangyi Wang,Yuanrui Huang*

Main category: cs.RO

TL;DR: 本论文提出了一种新型磁性连续体机器人（MCR），通过径向嵌入磁体，实现了独立控制弯曲和扭转，并设计了一种基于扭转的药物释放机制，最终在体模实验中验证了其在靶向输送和药物释放方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有的轴向磁体MCR主要局限于弯曲运动，限制了其在解剖结构中的灵活性。本研究旨在扩展MCR的变形能力，实现独立的弯曲和扭转控制。

Method: 通过在导管壁内径向嵌入永磁体，并使用外部永磁体进行单独控制，实现弯曲或扭转。利用基于物理学的公式和有限元分析来阐述驱动原理。设计了一个由外部凹槽和内部板组成的双层阻塞机制，利用扭转剪切实现按需释放药物。

Result: 实验验证了在实际磁场下 MCR 可以实现弯曲和扭转的解耦控制。基于扭转的药物释放机制能够按需释放药物。在体模实验中成功演示了MCR的靶向输送（通过弯曲导航）和在靶点处释放药物（通过扭转激活）。

Conclusion: 所提出的MCR平台紧凑、无需电缆，结合了多功能的变形能力和精确的载药输送能力，为下一代靶向治疗提供了巨大潜力。

Abstract: Magnetic continuum robots (MCRs) enable minimally invasive navigation through
tortuous anatomical channels, yet axially magnetized designs have largely been
limited to bending-only motion. To expand deformation capabilities, this paper
presents a simple assembly that embeds permanent magnets radially within the
catheter wall, allowing a single externally steered permanent magnet to
independently induce either bending or torsion. A physics-based formulation
together with finite-element analysis establishes the actuation principles, and
benchtop experiments validate decoupled mode control under practical fields.
Building on this, a dual-layer blockage mechanism consisting of outer grooves
and inner plates leverages torsional shear to achieve on-demand drug release.
Finally, an in-phantom intervention experiment demonstrates end-to-end
operation: lumen following by bending for target approach, followed by
twist-activated release at the site. The resulting compact, cable-free platform
combines versatile deformation with precise payload delivery, indicating strong
potential for next-generation, site-specific therapies.

</details>


### [282] [An Anytime, Scalable and Complete Algorithm for Embedding a Manufacturing Procedure in a Smart Factory](https://arxiv.org/abs/2510.01770)
*Christopher Leet,Aidan Sciortino,Sven Koenig*

Main category: cs.RO

TL;DR: TS-ACES是首个可扩展的智能工厂嵌入（SFE）问题的解决方案，可处理包含百台以上机器的工业级规模实例。


<details>
  <summary>Details</summary>
Motivation: 当前SFE问题求解器难以扩展到包含大量机器（数百台）的现代智能工厂，需要更具可扩展性的解决方案。

Method: 提出了一种名为TS-ACES（基于交通系统的任何周期性嵌入求解器）的新型求解器。

Result: TS-ACES被证明是完整的，并且能够成功处理包含百台以上机器的工业级规模SFE实例。

Conclusion: TS-ACES解决了现有SFE求解器的可扩展性限制，为现代大型智能工厂提供了有效的解决方案。

Abstract: Modern automated factories increasingly run manufacturing procedures using a
matrix of programmable machines, such as 3D printers, interconnected by a
programmable transport system, such as a fleet of tabletop robots. To embed a
manufacturing procedure into a smart factory, an operator must: (a) assign each
of its processes to a machine and (b) specify how agents should transport parts
between machines. The problem of embedding a manufacturing process into a smart
factory is termed the Smart Factory Embedding (SFE) problem. State-of-the-art
SFE solvers can only scale to factories containing a couple dozen machines.
Modern smart factories, however, may contain hundreds of machines. We fill this
hole by introducing the first highly scalable solution to the SFE, TS-ACES, the
Traffic System based Anytime Cyclic Embedding Solver. We show that TS-ACES is
complete and can scale to SFE instances based on real industrial scenarios with
more than a hundred machines.

</details>


### [283] [Nav-EE: Navigation-Guided Early Exiting for Efficient Vision-Language Models in Autonomous Driving](https://arxiv.org/abs/2510.01795)
*Haibo Hu,Lianming Huang,Xinyu Wang,Yufei Cui,Nan Guan,Chun Jason Xue*

Main category: cs.RO

TL;DR: 该论文提出了一种名为Nav-EE的导航引导的早期退出框架，用于解决自动驾驶领域中视觉-语言模型（VLMs）推理延迟高的问题。该框架通过离线预计算特定任务的退出层，并根据导航先验在线动态应用，实现了与完整推理相当的准确性，同时将延迟最多降低了63.9%。


<details>
  <summary>Details</summary>
Motivation: 高推理延迟阻碍了自动驾驶领域中视觉-语言模型（VLMs）的实时部署。现有的早期退出方法具有任务依赖性，泛化能力有限。而自动驾驶系统可以通过预测Upcoming的场景来指示将要执行的任务，这为解决上述问题提供了方向。

Method: 提出了一种名为Nav-EE的导航引导的早期退出框架。该框架离线预计算特定任务的退出层，并根据导航先验在线动态地选择和应用这些退出层，从而在保证精度的前提下减少推理延迟。

Result: 在CODA、Waymo和BOSCH数据集上进行实验，Nav-EE实现了与完整推理相当的准确性，并将延迟最多降低了63.9%。在Autoware Universe上的真实车辆集成测试也表明，推理延迟从600毫秒减少到300毫秒，支持在复杂场景中更快地做出决策。

Conclusion: 将导航预知能力与早期退出相结合，为在自动驾驶系统中高效部署大型模型提供了一条可行的途径。

Abstract: Vision-Language Models (VLMs) are increasingly applied in autonomous driving
for unified perception and reasoning, but high inference latency hinders
real-time deployment. Early-exit reduces latency by terminating inference at
intermediate layers, yet its task-dependent nature limits generalization across
diverse scenarios. We observe that this limitation aligns with autonomous
driving: navigation systems can anticipate upcoming contexts (e.g.,
intersections, traffic lights), indicating which tasks will be required. We
propose Nav-EE, a navigation-guided early-exit framework that precomputes
task-specific exit layers offline and dynamically applies them online based on
navigation priors. Experiments on CODA, Waymo, and BOSCH show that Nav-EE
achieves accuracy comparable to full inference while reducing latency by up to
63.9%. Real-vehicle integration with Autoware Universe further demonstrates
reduced inference latency (600ms to 300ms), supporting faster decision-making
in complex scenarios. These results suggest that coupling navigation foresight
with early-exit offers a viable path toward efficient deployment of large
models in autonomous systems. Code and data are available at our anonymous
repository: https://anonymous.4open.science/r/Nav-EE-BBC4

</details>


### [284] [SPARC: Spine with Prismatic and Revolute Compliance for Quadruped Robot](https://arxiv.org/abs/2510.01984)
*Yue Wang*

Main category: cs.RO

TL;DR: SPARC是一个紧凑、开源的3自由度脊柱模块，适用于四足机器人，可实现可编程的阻抗控制。


<details>
  <summary>Details</summary>
Motivation: 为四足机器人提供一个紧凑、开源的脊柱模块，用于系统地研究足式运动中的脊柱顺应性。

Method: 使用三个扭矩控制的执行器、一个1kHz的控制板和一个电源单元，构建了一个1.26kg的SPARC模块。采用基于RNEA的计算加速度控制器，并进行平滑的Stribeck摩擦补偿，以实现弹簧-阻尼器行为，而无需显式的惯性整形。

Result: 准静态推拉测试显示，命令的水平刚度在300-700 N/m范围内具有线性力-位移特性，相对误差小于1.5%（R^2 >= 0.992）。动态释放试验证实了具有多个阻尼设置的质量-弹簧-阻尼器响应。

Conclusion: SPARC提供了一个便携的平台，用于系统地研究足式运动中的脊柱顺应性，并将发布完整的硬件和固件资源。

Abstract: We present SPARC, a compact, open-source 3-DoF sagittal-plane spine module
that combines revolute (pitch) and prismatic (axial) motion with programmable
task-space impedance for quadruped robots. The system integrates three
torque-controlled actuators, a custom 1 kHz control board, and a protected
power unit in a 1.26 kg package, enabling closed-loop stiffness and damping
shaping along x, z, and theta. We develop an RNEA-based computed-acceleration
controller with smooth Stribeck friction compensation to render spring-damper
behavior without explicit inertia shaping. Bench experiments validate the
approach. Quasi-static push-pull tests show linear force-displacement
characteristics with commanded horizontal stiffness spanning 300-700 N/m and <=
1.5% relative error (R^2 >= 0.992, narrow 95% CIs). Dynamic
displace-and-release trials confirm mass-spring-damper responses over multiple
damping settings, with small, interpretable phase deviations due to
configuration-dependent inertia and low-speed friction effects. A task-space PD
controller produces roughly linear stiffness but with greater variability and
coupling sensitivity. SPARC provides a portable platform for systematic studies
of spine compliance in legged locomotion and will be released with complete
hardware and firmware resources.

</details>


### [285] [What Matters in RL-Based Methods for Object-Goal Navigation? An Empirical Study and A Unified Framework](https://arxiv.org/abs/2510.01830)
*Hongze Wang,Boyang Sun,Jiaxu Xing,Fan Yang,Marco Hutter,Dhruv Shah,Davide Scaramuzza,Marc Pollefeys*

Main category: cs.RO

TL;DR: 通过实证研究分析和改进基于模块化强化学习的对象导航系统，提出设计指南并提升性能。


<details>
  <summary>Details</summary>
Motivation: 移动机器人在家庭、学校等非结构化环境中自主导航并定位目标对象是实际应用的关键，但目前仍具挑战性。现有强化学习（RL）方法在设计选择上存在广泛差异，缺乏统一的分析来确定哪些组件对性能影响最大。

Method: 将基于RL的对象导航系统分解为感知、策略和测试时增强三个关键组件，通过大规模实证研究和受控实验，分离并分析每个组件的贡献。

Result: 研究发现，感知质量和测试时策略是决定性因素，而当前策略方法的改进效果有限。提出的增强模块化系统在SPL上提升了6.6%，成功率提升了2.7%，超越了现有SotA方法。同时，人类专家在相同条件下达到了98%的成功率，凸显了RL代理与人类水平的差距。

Conclusion: 该研究不仅设定了新的SotA性能标杆，还为未来的对象导航研究和评估提供了原则性指导，强调了感知和测试时策略的重要性。

Abstract: Object-Goal Navigation (ObjectNav) is a critical component toward deploying
mobile robots in everyday, uncontrolled environments such as homes, schools,
and workplaces. In this context, a robot must locate target objects in
previously unseen environments using only its onboard perception. Success
requires the integration of semantic understanding, spatial reasoning, and
long-horizon planning, which is a combination that remains extremely
challenging. While reinforcement learning (RL) has become the dominant
paradigm, progress has spanned a wide range of design choices, yet the field
still lacks a unifying analysis to determine which components truly drive
performance. In this work, we conduct a large-scale empirical study of modular
RL-based ObjectNav systems, decomposing them into three key components:
perception, policy, and test-time enhancement. Through extensive controlled
experiments, we isolate the contribution of each and uncover clear trends:
perception quality and test-time strategies are decisive drivers of
performance, whereas policy improvements with current methods yield only
marginal gains. Building on these insights, we propose practical design
guidelines and demonstrate an enhanced modular system that surpasses
State-of-the-Art (SotA) methods by 6.6% on SPL and by a 2.7% success rate. We
also introduce a human baseline under identical conditions, where experts
achieve an average 98% success, underscoring the gap between RL agents and
human-level navigation. Our study not only sets the SotA performance but also
provides principled guidance for future ObjectNav development and evaluation.

</details>


### [286] [Reducing Discomfort in Driving Simulators: Motion Cueing for Motion Sickness Mitigation](https://arxiv.org/abs/2510.01986)
*Varun Kotian,Vishrut Jain,Andrea Michelle Rios Lazcano,Daan Marinus Pool,Riender Happee,Barys Shyrokau*

Main category: cs.RO

TL;DR: 该论文提出了一种基于模型预测控制（MPC）的运动提示算法（MCA），以减少驾驶模拟器中的晕动病，该算法同时考虑了模拟器动力学和晕动病模型，并在模拟器实验中得到了验证。


<details>
  <summary>Details</summary>
Motivation: 驾驶模拟器虽然在研发中得到广泛应用，但常因运动缩放和视觉失真导致晕动病。本研究旨在提出一种新的运动提示算法，以减轻这种不适感。

Method: 提出了一种基于模型预测控制（MPC）的运动提示算法（MCA），该算法通过在成本函数中惩罚感官冲突和特定力误差，以最小化主观垂直冲突（SVC）模型预测的晕动病，并联合优化保真度和舒适度。实验中将该算法与两种MPC变体（一种侧重特定力跟踪，一种折衷跟踪和晕动病最小化）、自适应洗出以及无运动进行了比较。

Result: 实验结果显示，所提出的折衷解决方案将晕动病程度降低了50%以上（平均MISC评分从3降至1.5），同时保真度评分无显著下降。晕动病实验结果与模型预测基本一致，无运动条件下的晕动病程度最低，但保真度评分也是最低的。

Conclusion: 该研究提出的MCA方法考虑了模拟器动力学和晕动病的时变特性，在晕动病控制和特定力再现方面取得了显著进展，有助于扩大驾驶模拟器的应用范围。

Abstract: Driving simulators are increasingly used in research and development.
However, simulators often cause motion sickness due to downscaled motion and
unscaled veridical visuals. In this paper, a motion cueing algorithm is
proposed that reduces motion sickness as predicted by the subjective vertical
conflict (SVC) model using model predictive control (MPC). Both sensory
conflict and specific force errors are penalised in the cost function, allowing
the algorithm to jointly optimise fidelity and comfort.
  Human-in-the-loop experiments were conducted to compare four simulator motion
settings: two variations of our MPC-based algorithm, one focused on pure
specific force tracking and the second compromising specific force tracking and
motion sickness minimisation, as well as reference adaptive washout and no
motion cases. The experiments were performed on a hexapod driving simulator
with participants exposed to passive driving.
  Experimental motion sickness results closely matched the sickness model
predictions. As predicted by the model, the no motion condition yielded the
lowest sickness levels. However, it was rated lowest in terms of fidelity. The
compromise solution reduced sickness by over 50% (average MISC level 3 to 1.5)
compared to adaptive washout and the algorithm focusing on specific force
tracking, without any significant reduction in fidelity rating.
  The proposed approach for developing MCA that takes into account both the
simulator dynamics and time evolution of motion sickness offers a significant
advancement in achieving an optimal control of motion sickness and specific
force recreation in driving simulators, supporting broader simulator use.

</details>


### [287] [Like Playing a Video Game: Spatial-Temporal Optimization of Foot Trajectories for Controlled Football Kicking in Bipedal Robots](https://arxiv.org/abs/2510.01843)
*Wanyue Li,Ji Ma,Minghao Lu,Peng Lu*

Main category: cs.RO

TL;DR: 该研究将无人机领域成功的时空轨迹规划方法应用于双足机器人系统，以应对人形机器人足球比赛中稳定性和踢球控制的挑战。


<details>
  <summary>Details</summary>
Motivation: 当前人形机器人足球比赛中，在保持系统稳定性与精确控制踢球轨迹方面存在挑战。传统方法和现有强化学习方法均存在局限性，而模型预测控制（MPC）虽在机器人领域常用，但常简化腿部摆动过程，限制了与环境的交互能力，尤其是在踢球任务中。

Method: 将无人机领域成功的时空轨迹规划方法应用于双足机器人系统，自主生成满足目标踢球位置、速度和加速度约束的脚部轨迹，并优化摆动阶段持续时间。

Result: 优化的轨迹能够模仿人类踢球时的后摆动作。轨迹规划时间低于1毫秒，在目标球门位于-90度到90度范围内时，任务完成准确率接近100%。

Conclusion: 该方法有效解决了人形机器人足球比赛中的稳定性和踢球控制问题，提高了踢球的准确性和效率。

Abstract: Humanoid robot soccer presents several challenges, particularly in
maintaining system stability during aggressive kicking motions while achieving
precise ball trajectory control. Current solutions, whether traditional
position-based control methods or reinforcement learning (RL) approaches,
exhibit significant limitations. Model predictive control (MPC) is a prevalent
approach for ordinary quadruped and biped robots. While MPC has demonstrated
advantages in legged robots, existing studies often oversimplify the leg swing
progress, relying merely on simple trajectory interpolation methods. This
severely constrains the foot's environmental interaction capability, hindering
tasks such as ball kicking. This study innovatively adapts the spatial-temporal
trajectory planning method, which has been successful in drone applications, to
bipedal robotic systems. The proposed approach autonomously generates foot
trajectories that satisfy constraints on target kicking position, velocity, and
acceleration while simultaneously optimizing swing phase duration. Experimental
results demonstrate that the optimized trajectories closely mimic human kicking
behavior, featuring a backswing motion. Simulation and hardware experiments
confirm the algorithm's efficiency, with trajectory planning times under 1 ms,
and its reliability, achieving nearly 100 % task completion accuracy when the
soccer goal is within the range of -90{\deg} to 90{\deg}.

</details>


### [288] [GreenhouseSplat: A Dataset of Photorealistic Greenhouse Simulations for Mobile Robotics](https://arxiv.org/abs/2510.01848)
*Diram Tabaa,Gianni Di Caro*

Main category: cs.RO

TL;DR: 该研究提出了一种名为 GreenhouseSplat 的框架和数据集，用于从 RGB 图像生成逼真的温室环境，并将其集成到机器人仿真中，以支持农业机器人研究。


<details>
  <summary>Details</summary>
Motivation: 现有温室环境模拟方法依赖于简化的或合成的资源，限制了从模拟到现实的迁移。而基于高斯泼溅等方法虽然能实现照片级真实感重建，但目前仅限于单个植物或实验室条件。

Method: 开发了一个名为 GreenhouseSplat 的框架和数据集，可以直接从廉价的 RGB 图像生成逼真的温室资源。将这些资源集成到一个支持相机和 LiDAR 渲染的 ROS 仿真环境中，并可用于诸如图标标记的定位等任务。

Result: 提供了一个包含 82 个黄瓜植物的数据集，并展示了其在机器人评估中的应用。

Conclusion: GreenhouseSplat 是实现温室规模辐射场仿真的第一步，为农业机器人未来的研究奠定了基础。

Abstract: Simulating greenhouse environments is critical for developing and evaluating
robotic systems for agriculture, yet existing approaches rely on simplistic or
synthetic assets that limit simulation-to-real transfer. Recent advances in
radiance field methods, such as Gaussian splatting, enable photorealistic
reconstruction but have so far been restricted to individual plants or
controlled laboratory conditions. In this work, we introduce GreenhouseSplat, a
framework and dataset for generating photorealistic greenhouse assets directly
from inexpensive RGB images. The resulting assets are integrated into a
ROS-based simulation with support for camera and LiDAR rendering, enabling
tasks such as localization with fiducial markers. We provide a dataset of 82
cucumber plants across multiple row configurations and demonstrate its utility
for robotics evaluation. GreenhouseSplat represents the first step toward
greenhouse-scale radiance-field simulation and offers a foundation for future
research in agricultural robotics.

</details>


### [289] [Product Digital Twin Supporting End-of-life Phase of Electric Vehicle Batteries Utilizing Product-Process-Resource Asset Network](https://arxiv.org/abs/2510.02167)
*Sara Strakosova,Petr Novak,Petr Kadera*

Main category: cs.RO

TL;DR: 数字孪生技术可优化电动汽车电池的拆卸过程，以应对循环经济中的可持续性挑战。


<details>
  <summary>Details</summary>
Motivation: 制造商在产品报废后的再制造或回收阶段，往往因不共享相关数据而对这些至关重要的可持续性过程支持不足。

Method: 提出使用数字孪生技术，并以产品-过程-资源资产网络（PAN）作为数字孪生表示的骨干。进一步引入了双流产品-过程-资源资产网络（Bi-PAN）表示，该表示不仅涵盖制造阶段，还涵盖了再制造/回收阶段。

Result: 通过电动汽车电池拆卸用例演示了所提出的方法，证明了数字孪生技术能够灵活高效地解决各种类型电动汽车电池拆卸的挑战。

Conclusion: Bi-PAN 表示和数字孪生技术能够有效支持循环经济中的再制造和回收过程，减少生态影响，提高可持续性。

Abstract: In the context of the circular economy, products in their end-of-life phase
should be either remanufactured or recycled. Both of these processes are
crucial for sustainability and environmental conservation. However,
manufacturers often do not support these processes enough by not sharing
relevant data. This paper proposes use of a digital twin technology, which is
capable to help optimizing the disassembly processes to reduce ecological
impact and enhance sustainability. The proposed approach is demonstrated
through a disassembly use-case of the product digital twin of an electric
vehicle battery. By utilizing product digital twins, challenges associated with
the disassembly of electric vehicle batteries can be solved flexibly and
efficiently for various battery types. As a backbone for the product digital
twin representation, the paper uses the paradigm of product-process-resource
asset networks (PAN). Such networks enable to model relevant relationships
across products, production resources, manufacturing processes, and specific
production operations that have to be done in the manufacturing phase of a
product. This paper introduces a Bi-Flow Product-Process-Resource Asset Network
(Bi-PAN) representation, which extends the PAN paradigm to cover not only the
manufacturing, but also the remanufacturing/recycling phase.

</details>


### [290] [EC3R-SLAM: Efficient and Consistent Monocular Dense SLAM with Feed-Forward 3D Reconstruction](https://arxiv.org/abs/2510.02080)
*Lingxiang Hu,Naima Ait Oufroukh,Fabien Bonardi,Raymond Ghandour*

Main category: cs.RO

TL;DR: EC3R-SLAM是一个新的、无需标定的单目稠密SLAM框架，它通过结合稀疏特征点跟踪和基于前馈3D重建模型的稠密地图构建，实现了高精度、低延迟和低内存占用的目标，并且能够估计相机内参，同时通过闭环检测来提高长期精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有单目稠密SLAM系统存在的延迟高、GPU显存占用大以及依赖相机标定等问题，提出EC3R-SLAM框架以放松标定约束，并提高效率。

Method: EC3R-SLAM框架结合了一个维护稀疏特征点地图的跟踪模块和一个基于前馈3D重建模型进行稠密地图构建的映射模块，该模型能同时估计相机内参。此外，还引入了局部和全局回环检测以确保中长期数据关联，增强多视图一致性，从而提高系统整体精度和鲁棒性。

Result: 在多个基准测试中，EC3R-SLAM实现了与最先进方法相当的性能，同时速度更快、内存占用更少。该系统甚至能在笔记本电脑和Jetson Orin NX等资源受限平台上有效运行。

Conclusion: EC3R-SLAM是一个无需标定的单目稠密SLAM框架，通过新颖的设计实现了高精度、低延迟和低内存占用的目标，并且在资源受限平台上表现出色，具有实际机器人应用潜力。

Abstract: The application of monocular dense Simultaneous Localization and Mapping
(SLAM) is often hindered by high latency, large GPU memory consumption, and
reliance on camera calibration. To relax this constraint, we propose EC3R-SLAM,
a novel calibration-free monocular dense SLAM framework that jointly achieves
high localization and mapping accuracy, low latency, and low GPU memory
consumption. This enables the framework to achieve efficiency through the
coupling of a tracking module, which maintains a sparse map of feature points,
and a mapping module based on a feed-forward 3D reconstruction model that
simultaneously estimates camera intrinsics. In addition, both local and global
loop closures are incorporated to ensure mid-term and long-term data
association, enforcing multi-view consistency and thereby enhancing the overall
accuracy and robustness of the system. Experiments across multiple benchmarks
show that EC3R-SLAM achieves competitive performance compared to
state-of-the-art methods, while being faster and more memory-efficient.
Moreover, it runs effectively even on resource-constrained platforms such as
laptops and Jetson Orin NX, highlighting its potential for real-world robotics
applications.

</details>


### [291] [LangGrasp: Leveraging Fine-Tuned LLMs for Language Interactive Robot Grasping with Ambiguous Instructions](https://arxiv.org/abs/2510.02104)
*Yunhan Lin,Wenqi Wu,Zhijie Zhang,Huasong Min*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The existing language-driven grasping methods struggle to fully handle
ambiguous instructions containing implicit intents. To tackle this challenge,
we propose LangGrasp, a novel language-interactive robotic grasping framework.
The framework integrates fine-tuned large language models (LLMs) to leverage
their robust commonsense understanding and environmental perception
capabilities, thereby deducing implicit intents from linguistic instructions
and clarifying task requirements along with target manipulation objects.
Furthermore, our designed point cloud localization module, guided by 2D part
segmentation, enables partial point cloud localization in scenes, thereby
extending grasping operations from coarse-grained object-level to fine-grained
part-level manipulation. Experimental results show that the LangGrasp framework
accurately resolves implicit intents in ambiguous instructions, identifying
critical operations and target information that are unstated yet essential for
task completion. Additionally, it dynamically selects optimal grasping poses by
integrating environmental information. This enables high-precision grasping
from object-level to part-level manipulation, significantly enhancing the
adaptability and task execution efficiency of robots in unstructured
environments. More information and code are available here:
https://github.com/wu467/LangGrasp.

</details>


### [292] [Stand Up, NAO! Increasing the Reliability of Stand-Up Motions Through Error Compensation in Position Control](https://arxiv.org/abs/2510.02129)
*Philip Reichenberg,Tim Laue*

Main category: cs.RO

TL;DR: NAO机器人可以通过执行特殊动作或使用其他关节补偿来提高站立成功率。


<details>
  <summary>Details</summary>
Motivation: 站立动作是人形机器人足球比赛的重要组成部分，无法自行站立的机器人将被暂时移除出场。

Method: 提出一种通过执行特殊动作来解除卡住的肢体（如手臂）或使用其他关节来补偿大误差的站立方法，以提高站立成功率。

Result: 该方法显著提高了站立动作的整体成功率，并且该动作也被其他机器人足球联赛（SPL）的队伍使用，并取得了相似的成功率。

Conclusion: 通过解决执行关节位置的大误差问题，可以显著提高NAO机器人的站立成功率。

Abstract: Stand-up motions are an indispensable part of humanoid robot soccer. A robot
incapable of standing up by itself is removed from the game for some time. In
this paper, we present our stand-up motions for the NAO robot. Our approach
dates back to 2019 and has been evaluated and slightly expanded over the past
six years. We claim that the main reason for failed stand-up attempts are large
errors in the executed joint positions. By addressing such problems by either
executing special motions to free up stuck limbs such as the arms, or by
compensating large errors with other joints, we significantly increased the
overall success rate of our stand-up routine. The motions presented in this
paper are also used by several other teams in the Standard Platform League,
which thereby achieve similar success rates, as shown in an analysis of videos
from multiple tournaments.

</details>


### [293] [SCANS: A Soft Gripper with Curvature and Spectroscopy Sensors for In-Hand Material Differentiation](https://arxiv.org/abs/2510.02164)
*Nathaniel Hanson,Austin Allison,Charles DiMarzio,Taşkın Padır,Kristen L. Dorsey*

Main category: cs.RO

TL;DR: SCANS系统是一种无需电子、通过流体驱动的软体机械手，能够对物体进行光谱分析，提供比以往更宽的光谱传感能力。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索将光学作为软体机器人的多功能传感模态，并开发一种能够评估物体光谱特性的软体机械手。

Method: 提出并实现了一种名为SCANS（软曲率与光谱）的系统，该系统采用流体驱动的软体机械手，无需电子元件，能够进行光谱分析。研究了用于光谱传感的最佳软基材，并评估了预接触和手持两种模式下的性能。通过线性判别分析，确定了近红外波长在区分视觉相似物体中的关键作用。

Result: 实验证明，SCANS系统能够对不同类别和尺寸的物体（金属、木材、塑料、有机物、纸张、泡沫）进行可解释的统计分离，并显示出大的光谱角度差异。近红外波长的灵敏度对于区分视觉相似物体至关重要。

Conclusion: SCANS系统是一种先进的软体机器人传感平台，能够实现无需电子元件的光谱分析，并在区分不同物体方面表现出优异的性能，特别是在利用近红外波长方面。这为软体机器人提供了多功能的光学传感能力。

Abstract: We introduce the soft curvature and spectroscopy (SCANS) system: a versatile,
electronics-free, fluidically actuated soft manipulator capable of assessing
the spectral properties of objects either in hand or through pre-touch caging.
This platform offers a wider spectral sensing capability than previous soft
robotic counterparts. We perform a material analysis to explore optimal soft
substrates for spectral sensing, and evaluate both pre-touch and in-hand
performance. Experiments demonstrate explainable, statistical separation across
diverse object classes and sizes (metal, wood, plastic, organic, paper, foam),
with large spectral angle differences between items. Through linear
discriminant analysis, we show that sensitivity in the near-infrared
wavelengths is critical to distinguishing visually similar objects. These
capabilities advance the potential of optics as a multi-functional sensory
modality for soft robots. The complete parts list, assembly guidelines, and
processing code for the SCANS gripper are accessible at:
https://parses-lab.github.io/scans/.

</details>


### [294] [DisCo-Layout: Disentangling and Coordinating Semantic and Physical Refinement in a Multi-Agent Framework for 3D Indoor Layout Synthesis](https://arxiv.org/abs/2510.02178)
*Jialin Gao,Donghao Zhou,Mingjian Liang,Lihao Liu,Chi-Wing Fu,Xiaowei Hu,Pheng-Ann Heng*

Main category: cs.RO

TL;DR: DisCo-Layout是一个新框架，通过解耦和协调物理和语义的细化来生成3D室内布局，解决了传统方法泛化性差和基于LLM/VLM的方法细化不足的问题。


<details>
  <summary>Details</summary>
Motivation: 传统方法泛化性差，基于LLM/VLM的方法细化不足，需要更鲁棒和灵活的3D室内布局合成方法。

Method: 提出DisCo-Layout框架，包含独立的语义细化工具（SRT）和物理细化工具（PRT），以及一个多智能体协作细化框架，其中包括规划器、设计者和评估者。

Result: DisCo-Layout在生成逼真、连贯和可泛化的3D室内布局方面取得了最先进的性能。

Conclusion: DisCo-Layout通过解耦和协调物理与语义的细化，能够生成高质量的3D室内布局，并在实验中证明了其优越性。

Abstract: 3D indoor layout synthesis is crucial for creating virtual environments.
Traditional methods struggle with generalization due to fixed datasets. While
recent LLM and VLM-based approaches offer improved semantic richness, they
often lack robust and flexible refinement, resulting in suboptimal layouts. We
develop DisCo-Layout, a novel framework that disentangles and coordinates
physical and semantic refinement. For independent refinement, our Semantic
Refinement Tool (SRT) corrects abstract object relationships, while the
Physical Refinement Tool (PRT) resolves concrete spatial issues via a
grid-matching algorithm. For collaborative refinement, a multi-agent framework
intelligently orchestrates these tools, featuring a planner for placement
rules, a designer for initial layouts, and an evaluator for assessment.
Experiments demonstrate DisCo-Layout's state-of-the-art performance, generating
realistic, coherent, and generalizable 3D indoor layouts. Our code will be
publicly available.

</details>


### [295] [Performance-Guided Refinement for Visual Aerial Navigation using Editable Gaussian Splatting in FalconGym 2.0](https://arxiv.org/abs/2510.02248)
*Yan Miao,Ege Yuceel,Georgios Fainekos,Bardh Hoxha,Hideki Okamoto,Sayan Mitra*

Main category: cs.RO

TL;DR: FalconGym 2.0是一个基于高斯泼溅的逼真模拟框架，具有可编辑API，可快速生成多样化的静态和动态赛道。利用该框架，我们提出了一种性能引导细化（PGR）算法，可以提高视觉策略的泛化性和鲁棒性，并实现了零样本的仿真到现实迁移。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉策略在单一赛道上容易过拟合，在赛道几何形状改变时性能会下降。

Method: 开发了FalconGym 2.0模拟框架，并提出了性能引导细化（PGR）算法，该算法在训练视觉策略时侧重于挑战性赛道，并迭代地改进其性能。

Result: 在固定翼无人机和四旋翼飞行器两个案例研究中，与最先进的基线相比，使用PGR在FalconGym 2.0中训练的单一视觉策略在泛化性和鲁棒性方面表现更好。该策略在三个未见过的赛道上实现了100%的成功率，并且在门姿扰动下保持了更高的成功率。此外，在四旋翼硬件上实现了98.6%的成功率（70个门中的69个）。

Conclusion: PGR算法和FalconGym 2.0框架能够显著提高视觉策略的泛化性和鲁棒性，并可以成功地从仿真迁移到现实世界。

Abstract: Visual policy design is crucial for aerial navigation. However,
state-of-the-art visual policies often overfit to a single track and their
performance degrades when track geometry changes. We develop FalconGym 2.0, a
photorealistic simulation framework built on Gaussian Splatting (GSplat) with
an Edit API that programmatically generates diverse static and dynamic tracks
in milliseconds. Leveraging FalconGym 2.0's editability, we propose a
Performance-Guided Refinement (PGR) algorithm, which concentrates visual
policy's training on challenging tracks while iteratively improving its
performance. Across two case studies (fixed-wing UAVs and quadrotors) with
distinct dynamics and environments, we show that a single visual policy trained
with PGR in FalconGym 2.0 outperforms state-of-the-art baselines in
generalization and robustness: it generalizes to three unseen tracks with 100%
success without per-track retraining and maintains higher success rates under
gate-pose perturbations. Finally, we demonstrate that the visual policy trained
with PGR in FalconGym 2.0 can be zero-shot sim-to-real transferred to a
quadrotor hardware, achieving a 98.6% success rate (69 / 70 gates) over 30
trials spanning two three-gate tracks and a moving-gate track.

</details>


### [296] [Retargeting Matters: General Motion Retargeting for Humanoid Motion Tracking](https://arxiv.org/abs/2510.02252)
*Joao Pedro Araujo,Yanjie Ze,Pei Xu,Jiajun Wu,C. Karen Liu*

Main category: cs.RO

TL;DR: 在机器人拟人化运动追踪中，运动数据在重新定向到机器人模型时产生的瑕疵会严重影响策略的鲁棒性。本文提出了一种名为 GMR 的新运动重定向方法，该方法在运动追踪性能和源运动保真度方面均优于现有开源方法，并且接近闭源基线。


<details>
  <summary>Details</summary>
Motivation: 当前的人体运动追踪策略在拟人化机器人运动追踪中面临着一个基本挑战：人体与拟人化机器人之间的具身鸿沟。现有方法通过将人体运动数据重新定向到拟人化模型，然后使用强化学习（RL）策略来模仿这些参考轨迹来解决这个问题。然而，在重新定向过程中引入的瑕疵（如脚部滑动、自相穿透和物理上不可行的运动）通常会留在 RL 策略需要纠正的参考轨迹中。虽然之前的工作已经证明了运动追踪能力，但它们通常需要大量的奖励工程和域随机化才能成功。本文旨在系统地评估重新定向质量如何影响策略性能，同时抑制过度的奖励调整。

Method: 提出了一种名为 GMR（General Motion Retargeting）的新型运动重定向方法，并将其与两个开源重定向器（PHC 和 ProtoMotions）以及一个高质量的闭源数据集（Unitree）进行评估。使用 BeyondMimic 进行策略训练，并在 LAFAN1 数据集的子集中进行实验，以隔离重定向效果而不进行奖励调整。

Result: 实验表明，虽然大多数运动都可以被追踪，但重新定向数据中的瑕疵会显著降低策略的鲁棒性，尤其是在处理动态或长序列时。GMR 在追踪性能和对源运动的保真度方面持续优于现有的开源方法，其感知保真度和策略成功率接近闭源基线。

Conclusion: 重定向质量对拟人化运动追踪策略的性能至关重要。现有的重定向方法会引入瑕疵，从而损害策略的鲁棒性。GMR 方法在提高重定向质量方面取得了显著进展，从而提高了运动追踪的性能和保真度。

Abstract: Humanoid motion tracking policies are central to building teleoperation
pipelines and hierarchical controllers, yet they face a fundamental challenge:
the embodiment gap between humans and humanoid robots. Current approaches
address this gap by retargeting human motion data to humanoid embodiments and
then training reinforcement learning (RL) policies to imitate these reference
trajectories. However, artifacts introduced during retargeting, such as foot
sliding, self-penetration, and physically infeasible motion are often left in
the reference trajectories for the RL policy to correct. While prior work has
demonstrated motion tracking abilities, they often require extensive reward
engineering and domain randomization to succeed. In this paper, we
systematically evaluate how retargeting quality affects policy performance when
excessive reward tuning is suppressed. To address issues that we identify with
existing retargeting methods, we propose a new retargeting method, General
Motion Retargeting (GMR). We evaluate GMR alongside two open-source
retargeters, PHC and ProtoMotions, as well as with a high-quality closed-source
dataset from Unitree. Using BeyondMimic for policy training, we isolate
retargeting effects without reward tuning. Our experiments on a diverse subset
of the LAFAN1 dataset reveal that while most motions can be tracked, artifacts
in retargeted data significantly reduce policy robustness, particularly for
dynamic or long sequences. GMR consistently outperforms existing open-source
methods in both tracking performance and faithfulness to the source motion,
achieving perceptual fidelity and policy success rates close to the
closed-source baseline. Website:
https://jaraujo98.github.io/retargeting_matters. Code:
https://github.com/YanjieZe/GMR.

</details>


### [297] [Do You Know Where Your Camera Is? View-Invariant Policy Learning with Camera Conditioning](https://arxiv.org/abs/2510.02268)
*Tianchong Jiang,Jingtian Ji,Xiangshan Tan,Jiading Fang,Anand Bhattad,Vitor Guizilini,Matthew R. Walter*

Main category: cs.RO

TL;DR: 通过将相机外参显式地纳入策略条件，我们实现了视图不变的模仿学习，提高了跨视点的泛化能力，并引入了新的评估任务来验证鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习方法在跨不同视角进行泛化时存在困难，通常依赖于背景线索来推断相机姿态，这种方法在场景几何或相机放置发生变化时会失效。

Method: 提出一种将相机外参作为条件纳入模仿学习策略的方法，利用像素射线表示（Plucker embeddings）来显式地表示相机外参，并将其应用于ACT、Diffusion Policy和SmolVLA等标准策略。同时，在RoboSuite和ManiSkill中引入了新的评估任务，包含固定和随机化场景变体，以解耦背景线索和相机姿态。

Result: 将相机外参纳入条件显著提高了模仿学习策略在标准行为克隆任务中跨视点的泛化能力。在引入的新评估任务中，不依赖相机外参的策略在面对背景线索和工作空间几何变化时性能会急剧下降，而纳入相机外参的策略则能恢复性能，实现无需深度信息的纯RGB控制。

Conclusion: 将相机外参作为条件是实现视图不变和鲁棒模仿学习的关键，能够有效克服传统方法对视觉线索的依赖，并在各种视角变化下保持稳定的控制性能。

Abstract: We study view-invariant imitation learning by explicitly conditioning
policies on camera extrinsics. Using Plucker embeddings of per-pixel rays, we
show that conditioning on extrinsics significantly improves generalization
across viewpoints for standard behavior cloning policies, including ACT,
Diffusion Policy, and SmolVLA. To evaluate policy robustness under realistic
viewpoint shifts, we introduce six manipulation tasks in RoboSuite and
ManiSkill that pair "fixed" and "randomized" scene variants, decoupling
background cues from camera pose. Our analysis reveals that policies without
extrinsics often infer camera pose using visual cues from static backgrounds in
fixed scenes; this shortcut collapses when workspace geometry or camera
placement shifts. Conditioning on extrinsics restores performance and yields
robust RGB-only control without depth. We release the tasks, demonstrations,
and code at https://ripl.github.io/know_your_camera/ .

</details>


### [298] [ARMADA: Autonomous Online Failure Detection and Human Shared Control Empower Scalable Real-world Deployment and Adaptation](https://arxiv.org/abs/2510.02298)
*Wenye Yu,Jun Lv,Zixi Ying,Yang Jin,Chuan Wen,Cewu Lu*

Main category: cs.RO

TL;DR: ARMADA是一个多机器人部署和自适应系统，通过名为FLOAT的在线故障检测方法，实现了高效的数据采集和人类监督的最小化，从而提高了策略的成功率并减少了干预。


<details>
  <summary>Details</summary>
Motivation: 预训练策略在缺乏领域内数据时表现不佳，而人工收集的演示数据成本高昂且质量不一。现有的“人机协同”系统虽然可以收集数据进行策略后训练，但需要持续的人工监控。

Method: ARMADA系统引入了名为FLOAT的在线故障检测方法，使得策略可以并行执行，仅在必要时请求人类干预，从而减少了对人类监督的依赖。

Result: FLOAT的故障检测准确率平均接近95%，比现有方法高出20%。ARMADA在策略的多次执行和后训练中，成功率提高了4倍以上，人类干预率降低了2倍以上。

Conclusion: ARMADA通过其创新的FLOAT故障检测机制，实现了高效的数据采集、可扩展的部署和对新场景的快速适应，显著优于先前的人机协同学习方法。

Abstract: Imitation learning has shown promise in learning from large-scale real-world
datasets. However, pretrained policies usually perform poorly without
sufficient in-domain data. Besides, human-collected demonstrations entail
substantial labour and tend to encompass mixed-quality data and redundant
information. As a workaround, human-in-the-loop systems gather domain-specific
data for policy post-training, and exploit closed-loop policy feedback to offer
informative guidance, but usually require full-time human surveillance during
policy rollout. In this work, we devise ARMADA, a multi-robot deployment and
adaptation system with human-in-the-loop shared control, featuring an
autonomous online failure detection method named FLOAT. Thanks to FLOAT, ARMADA
enables paralleled policy rollout and requests human intervention only when
necessary, significantly reducing reliance on human supervision. Hence, ARMADA
enables efficient acquisition of in-domain data, and leads to more scalable
deployment and faster adaptation to new scenarios. We evaluate the performance
of ARMADA on four real-world tasks. FLOAT achieves nearly 95% accuracy on
average, surpassing prior state-of-the-art failure detection approaches by over
20%. Besides, ARMADA manifests more than 4$\times$ increase in success rate and
greater than 2$\times$ reduction in human intervention rate over multiple
rounds of policy rollout and post-training, compared to previous
human-in-the-loop learning methods.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [299] [Microscaling Floating Point Formats for Large Language Models](https://arxiv.org/abs/2510.01863)
*Marco Cococcioni,Dario Pagani,Federico Rossi*

Main category: cs.NE

TL;DR: 利用微缩浮点格式优化大语言模型的计算和内存需求，在不牺牲性能的情况下，显著降低了内存占用和计算成本。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）日益增长的计算和内存需求，亟需创新的方法来优化资源利用，同时不损害性能。

Method: 本文利用微缩浮点格式，这是一种新颖的技术，通过减少LLM中数值表示相关的存储和计算开销来应对这些挑战。与为每个值分配专用尺度的传统浮点表示不同，微缩格式为一组值使用共享尺度，从而实现紧凑的单字节浮点表示，同时保持扩展的动态范围。我们探索了在8位浮点格式的背景下应用微缩格式。

Result: 在GPT-2 LLM架构中测试了微缩浮点格式的几种配置，证明了微缩数据格式在训练和推理过程中可以实现具有竞争力的准确性。

Conclusion: 微缩浮点格式被证明是部署大规模LLM的资源高效替代方案。

Abstract: The increasing computational and memory demands of large language models
(LLMs) necessitate innovative approaches to optimize resource usage without
compromising performance. This paper leverages microscaling floating-point
formats, a novel technique designed to address these challenges by reducing the
storage and computational overhead associated with numerical representations in
LLMs. Unlike traditional floating-point representations that allocate a
dedicated scale for each value, microscaling employs a shared scale across a
block of values, enabling compact one-byte floating-point representations while
maintaining an extended dynamic range. We explore the application of
microscaling in the context of 8-bit floating-point formats to significantly
reduce memory footprint and computational costs. We tested several
configurations of microscaling floats within the GPT-2 LLM architecture,
demonstrating that microscaling data formats can achieve competitive accuracy
during training and inference, proving its efficacy as a resource-efficient
alternative for deploying LLMs at scale. The source code is publicly available
at: https://github.com/unipi-dii-compressedarith/llm.c-sve

</details>


### [300] [VarCoNet: A variability-aware self-supervised framework for functional connectome extraction from resting-state fMRI](https://arxiv.org/abs/2510.02120)
*Charalampos Lamprou,Aamna Alshehhi,Leontios J. Hadjileontiadis,Mohamed L. Seghier*

Main category: cs.NE

TL;DR: VarCoNet是一个基于对比学习的自监督框架，用于从静息态fMRI数据中提取功能连接组（FC），并能有效处理个体间的功能变异性，在主题识别和ASD分类等下游任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 精准医疗的关键在于解释大脑功能的个体间变异性，将其视为有意义的数据而非噪声。

Method: VarCoNet框架使用基于分割rs-fMRI信号的新型增强策略，并整合1D-CNN-Transformer编码器进行时间序列处理，同时辅以贝叶斯超参数优化，利用自监督对比学习来挖掘和利用功能上的个体间变异性。

Result: 在人类连接组项目（HCP）的受试者识别任务和ABIDE I/II数据集的自闭症谱系障碍（ASD）分类任务上，VarCoNet相较于包括13种深度学习方法在内的最先进方法，展现了其优越性、鲁棒性、可解释性和泛化能力。

Conclusion: VarCoNet为rs-fMRI中的功能连接组（FC）分析提供了一个通用且鲁棒的框架，特别强调了对个体间功能变异性的有效利用。

Abstract: Accounting for inter-individual variability in brain function is key to
precision medicine. Here, by considering functional inter-individual
variability as meaningful data rather than noise, we introduce VarCoNet, an
enhanced self-supervised framework for robust functional connectome (FC)
extraction from resting-state fMRI (rs-fMRI) data. VarCoNet employs
self-supervised contrastive learning to exploit inherent functional
inter-individual variability, serving as a brain function encoder that
generates FC embeddings readily applicable to downstream tasks even in the
absence of labeled data. Contrastive learning is facilitated by a novel
augmentation strategy based on segmenting rs-fMRI signals. At its core,
VarCoNet integrates a 1D-CNN-Transformer encoder for advanced time-series
processing, enhanced with a robust Bayesian hyperparameter optimization. Our
VarCoNet framework is evaluated on two downstream tasks: (i) subject
fingerprinting, using rs-fMRI data from the Human Connectome Project, and (ii)
autism spectrum disorder (ASD) classification, using rs-fMRI data from the
ABIDE I and ABIDE II datasets. Using different brain parcellations, our
extensive testing against state-of-the-art methods, including 13 deep learning
methods, demonstrates VarCoNet's superiority, robustness, interpretability, and
generalizability. Overall, VarCoNet provides a versatile and robust framework
for FC analysis in rs-fMRI.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [301] [JaneEye: A 12-nm 2K-FPS 18.9-$μ$J/Frame Event-based Eye Tracking Accelerator](https://arxiv.org/abs/2510.01213)
*Tao Han,Ang Li,Qinyu Chen,Chang Gao*

Main category: eess.SP

TL;DR: JaneEye是一款专为可穿戴设备设计的、能效比高的事件驱动型眼动追踪硬件加速器，它使用一种简化的超轻量级神经网络，在保持高精度的同时，显著降低了计算复杂度和功耗，为下一代XR可穿戴设备设定了新的低功耗高性能基准。


<details>
  <summary>Details</summary>
Motivation: 传统的基于帧的眼动追踪系统在精度、延迟和能效方面无法满足扩展现实（XR）设备的要求，而事件相机具有高时间分辨率和低功耗的优势，可以作为一种有前景的替代方案。

Method: 提出JaneEye，一种能效比高的事件驱动型眼动追踪硬件加速器，并采用一种超轻量级神经网络，该网络包含一种新颖的ConvJANET层，它简化了传统的ConvLSTM，仅保留遗忘门，从而在不牺牲时间建模能力的情况下将计算复杂度减半。此外，还采用了自定义的激活函数线性近似和定点量化，并进行了软硬件协同设计，最终在12nm ASIC上实现。

Result: JaneEye在3ET+数据集上实现了2.45像素误差的高精度，模型参数量仅为17.6K，事件帧率最高可达1250 Hz。其12nm ASIC实现以400 MHz运行，端到端延迟为0.5 ms（相当于2000 FPS），能效比达到18.9 μJ/frame。

Conclusion: JaneEye通过使用事件相机和优化的神经网络，在低功耗和高分辨率方面取得了显著的进步，为集成到下一代XR可穿戴设备中提供了低功耗、高性能的眼动追踪解决方案。

Abstract: Eye tracking has become a key technology for gaze-based interactions in
Extended Reality (XR). However, conventional frame-based eye-tracking systems
often fall short of XR's stringent requirements for high accuracy, low latency,
and energy efficiency. Event cameras present a compelling alternative, offering
ultra-high temporal resolution and low power consumption. In this paper, we
present JaneEye, an energy-efficient event-based eye-tracking hardware
accelerator designed specifically for wearable devices, leveraging sparse,
high-temporal-resolution event data. We introduce an ultra-lightweight neural
network architecture featuring a novel ConvJANET layer, which simplifies the
traditional ConvLSTM by retaining only the forget gate, thereby halving
computational complexity without sacrificing temporal modeling capability. Our
proposed model achieves high accuracy with a pixel error of 2.45 on the 3ET+
dataset, using only 17.6K parameters, with up to 1250 Hz event frame rate. To
further enhance hardware efficiency, we employ custom linear approximations of
activation functions (hardsigmoid and hardtanh) and fixed-point quantization.
Through software-hardware co-design, our 12-nm ASIC implementation operates at
400 MHz, delivering an end-to-end latency of 0.5 ms (equivalent to 2000 Frames
Per Second (FPS)) at an energy efficiency of 18.9 $\mu$J/frame. JaneEye sets a
new benchmark in low-power, high-performance eye-tracking solutions suitable
for integration into next-generation XR wearables.

</details>


### [302] [Satellite Assignment Policy Learning for Coexistence in LEO Networks](https://arxiv.org/abs/2510.01408)
*Jeong Min Kong,Ian P. Roberts*

Main category: eess.SP

TL;DR: LEO卫星系统的频谱接入通常是非独占性的，先发射的系统（主系统）拥有优先权。次系统需要避免对主系统地面用户产生过多干扰，这需要了解主系统的卫星分配策略。本文提出一种基于图结构学习的算法，用于学习最高仰角的主卫星分配策略，并能在实际应用中实现约15%的预测精度提升。


<details>
  <summary>Details</summary>
Motivation: 次系统需要了解主系统的卫星分配策略，以避免对主系统地面用户产生过多干扰，但主系统通常不公开其分配策略。

Method: 提出一种端到端的基于图结构学习的算法，用于学习最高仰角的主卫星分配策略，该算法可以将主卫星坐标直接映射到主用户的分配决策。

Result: 所提出的方法在预测精度上比现有的最佳基线方法高出约15%。

Conclusion: 所提出的基于图结构学习的算法能够有效推断主卫星的分配策略，为次系统提供必要的支持，以满足其干扰约束要求。

Abstract: Unlike in terrestrial cellular networks, certain frequency bands for
low-earth orbit (LEO) satellite systems have thus far been allocated on a
non-exclusive basis. In this context, systems that launch their satellites
earlier (referred to as primary systems) are given spectrum access priority
over those that launch later, known as secondary systems. For a secondary
system to function, it is expected to either coordinate with primary systems or
ensure that it does not cause excessive interference to primary ground users.
Reliably meeting this interference constraint requires real-time knowledge of
the receive beams of primary users, which in turn depends on the primary
satellite-to-primary user associations. However, in practice, primary systems
have thus far not publicly disclosed their satellite assignment policies;
therefore, it becomes essential for secondary systems to develop methods to
infer such policies. Assuming there is limited historical data indicating which
primary satellites have served which primary users, we propose an end-to-end
graph structure learning-based algorithm for learning highest elevation primary
satellite assignment policies, that, upon deployment, can directly map the
primary satellite coordinates into assignment decisions for the primary users.
Simulation results show that our method can outperform the best baseline,
achieving approximately a 15% improvement in prediction accuracy.

</details>


### [303] [Delay-Augmented Stacked Intelligent Surfaces: Potential, Challenges, and Opportunities](https://arxiv.org/abs/2510.01411)
*Hibatallah Alwazani,Omran Abbas,Loic Markley,Anas Chaaban*

Main category: eess.SP

TL;DR: 将智能超表面（SIS）与符号持续时间延迟相结合，提出延迟增强型SIS（DA-SIS），用于全息MIMO和超大规模MIMO。DA-SIS可以通过提供延迟来实现时间处理，并用作模拟均衡器来消除多径引起的符号间干扰（ISI）。


<details>
  <summary>Details</summary>
Motivation: 利用智能超表面（SIS）进行空间信号处理的能力已被提出，但其潜力可以通过在符号持续时间层面添加延迟来进一步扩展，从而实现时间处理。

Method: 提出延迟增强型SIS（DA-SIS）的概念，探讨实现延迟单元的可行性，并将其作为一个用例，说明其作为模拟均衡器消除ISI的潜力。通过比特错误率（BER）来评估元素数量对均衡过程的影响，并与数字均衡器进行比较。

Result: 展示了DA-SIS作为模拟均衡器在消除ISI方面的潜力，并说明了SIS元素数量对均衡性能的影响。

Conclusion: DA-SIS是一个有前景的概念，有潜力在通信系统中实现更高级的功能，例如模拟均衡，并指出了未来的研究方向。

Abstract: Stacked intelligent surfaces (SIS)s have been proposed recently as an
enabling technology for Holographic Multiple Input Multiple Output (HMIMO) and
Ultra-massive MIMO (umMIMO) technologies. Their utility can extend beyond
spatial wave-domain processing of signals if they are enhanced with
strategically-tuned symbol-duration level delays to enable temporal processing
as well. In this work, we introduce the idea of a delay-augmented SIS (DA-SIS).
We shed light on the feasibility of realizing delay units in an SIS. Then, we
discuss the relevance of the proposed DA-SIS and present a use case that
illustrates its potential, wherein the DA-SIS serves as an analog equalizer
that aids in eliminating multi-path-induced inter-symbol-interference (ISI). We
show how the number of elements affect the equalization process using the bit
error rate (BER) as a metric, and demonstrate the potential of the DA-SIS in
equalization via comparing with digital equalizers as a benchmark. Finally, we
present opportunities and future research directions that can be undertaken to
bring this idea to fruition.

</details>


### [304] [A Drone-mounted Magnetometer System for Automatic Interference Removal and Landmine Detection](https://arxiv.org/abs/2510.01417)
*Alex Paul Hoffmann,Matthew G. Finley,Eftyhia Zesta,Mark B. Moldwin,Lauro V. Ojeda*

Main category: eess.SP

TL;DR: 提出一种结合小ъем机载双磁力仪和水印自适应干扰消除（WAIC-UP）与快速无监督事件检测（RUDE）算法的方法，用于高效、低成本地检测地雷，并通过蒙特卡洛模拟进行了验证。


<details>
  <summary>Details</summary>
Motivation: 地雷在冲突地区广泛存在，对平民构成持续威胁，阻碍战后恢复，而现有无人机载磁力仪易受电子设备干扰，检测精度受限。

Method: 提出一种两步法：1. 使用WAIC-UP方法去除无人机电子设备产生的磁场干扰。 2. 利用RUDE算法检测地雷特征。该方法采用帧装双磁力仪。

Result: 通过蒙特卡洛模拟验证了该方法在去除干扰和检测地雷方面的高精度和低计算成本，并评估了不同飞行高度下的性能。

Conclusion: 所提出的WAIC-UP/RUDE双磁力仪方法能够有效去除干扰并高精度地检测地雷，同时简化了设计并降低了计算成本，为无人机地雷探测提供了一种有效的解决方案。

Abstract: Landmines have been extensively used in conflict zones as an indiscriminate
weapon to control military movements, often remaining active long after
hostilities have ended. Their presence poses a persistent danger to civilians,
hindering post-war recovery efforts, causing injuries or death, and restricting
access to essential land for agriculture and infrastructure. Unmanned aerial
vehicles (UAV) equipped with magnetometers are commonly used to detect remnant
hidden landmines but come with significant technical challenges due to magnetic
field interference from UAV electronics such as motors. We propose the use of a
frame-mounted UAV-borne two-magnetometer payload to perform a two-step
automated interference removal and landmine detection analysis. The first step
removes interference via the Wavelet-Adaptive Interference Cancellation for
Underdetermined Platform (WAIC-UP) method designed for spaceflight
magnetometers. The second method uses the Rapid Unsupervised Detection of
Events (RUDE) algorithm to detect landmine signatures. This two-step
WAIC-UP/RUDE approach with multiple magnetometers achieves high-fidelity
ordinance detection at a low computational cost and simplifies the design of
magnetic survey payloads. We validate the method through a Monte Carlo
simulation of randomized landmine placements in a 10 x 10 m square grid and
drone motor interference. Additionally, we assess the efficacy of the algorithm
by varying the drone's altitude, examining its performance at different heights
above the ground.

</details>


### [305] [Meta-Learning-Driven Resource Optimization in Full-Duplex ISAC with Movable Antennas](https://arxiv.org/abs/2510.01437)
*Ali Amhaz,Shreya Khisa,Mohamed Elhattab,Chadi Assi,Sanaa Sharafeddine*

Main category: eess.SP

TL;DR: 本论文研究了配备可移动天线（MA）的基站（BS）在提供下行链路（DL）和上行链路（UL）通信服务的同时，为目标检测提供传感功能，以支持集成传感与通信（ISAC）技术。同时，一个配备MA的接收基站（BS R）负责捕获反射回波。通过联合优化发送波束成形向量、接收波束成形向量、UL用户的发射功率和MA的位置，在满足通信和传感服务质量（QoS）要求的前提下，最大化捕获回波的信噪比和干扰比（SINR）。针对该非凸耦合问题，采用基于梯度元学习（GML）的方法进行大规模优化。数值结果表明，所提出的元学习方法能达到最优解的99%，并且基于MA的方案优于多个基准方法，在实际ISAC应用中具有优势。


<details>
  <summary>Details</summary>
Motivation: ISAC技术是未来的发展趋势，本研究旨在优化配备可移动天线（MA）的基站（BS）在通信和传感一体化场景下的性能。

Method: 通过联合优化发送波束成形向量、接收波束成形向量、UL用户的发射功率和MA的位置，构建最大化捕获回波SINR的优化问题，并采用基于梯度元学习（GML）的方法求解。

Result: 所提出的元学习方法能够达到最优解的99%，并且基于MA的方案在ISAC场景下优于多个基准方法。

Conclusion: 所提出的基于MA和GML的ISAC方案能够有效提升通信和传感性能，在实际应用中具有潜力。

Abstract: This paper investigates a full-duplex (FD) scenario where a base station (BS)
equipped with movable antennas (MAs) simultaneously provides communication
services to a set of downlink (DL) and uplink (UL) users while also enabling
sensing functionalities for target detection, thereby supporting integrated
sensing and communication (ISAC) technology. Additionally, a receiving BS, also
equipped with MAs (denoted as BS R), is responsible for capturing the reflected
echo. To optimize this setup, we formulate an optimization problem aimed at
maximizing the signal-to-noise and interference ratio (SINR) of the captured
echo. This is achieved by jointly optimizing the transmit beamforming vectors
at the FD BS, the receiving beamforming vectors at both the FD BS and BS R, the
UL users' transmit power, and the MAs' positions at both BSs, all while
satisfying the quality-of-service (QoS) requirements for both sensing and
communication. Given the non-convex nature of the problem and the high coupling
between the variables, we employ a gradient-based meta-learning (GML) approach
tailored for large-scale optimization. Numerical results demonstrate the
effectiveness of the proposed meta-learning approach, achieving results within
99% of the optimal solution. Furthermore, the MA-based scheme outperforms
several benchmark approaches, highlighting its advantages in practical ISAC
applications.

</details>


### [306] [The Analysis and Performance of LODC-OFDM Signal in Nonlinear Rydberg Atomic Sensor](https://arxiv.org/abs/2510.01605)
*Hao Wu,Xinyuan Yao,Rui Ni,Chen Gong*

Main category: eess.SP

TL;DR: Rydberg原子传感器虽然灵敏度高，但其信号转换过程限制了OFDM信号的接收。本文提出了一种适用于Rydberg传感器的LODC-OFDM方案，解决了宽带OFDM接收问题，并通过实验验证了理论分析的准确性。


<details>
  <summary>Details</summary>
Motivation: Rydberg原子传感器在射频测量和通信接收方面具有潜力，但其信号转换过程（电磁波->光学信号->电信号）以及光学接口的单极性特征限制了传统OFDM信号的接收。因此，需要采用受光学通信启发的单极性OFDM方案。

Method: 本文研究了Rydberg原子传感器的幅度调制-幅度调制（AM-AM）特性，并建立了一个经验近似函数。在此基础上，提出了局部振荡器直流偏置正交频分复用（LODC-OFDM）方案，并采用Bussgang定理分析了其非线性失真，推导了泰勒级数展开近似的AM/AM曲线以及理想预失真情况下的闭式解。

Result: 理论分析和实验结果吻合良好，验证了所提出的LODC-OFDM方案在解决Rydberg传感器宽带OFDM接收挑战方面的有效性。

Conclusion: 本文提出的LODC-OFDM方案成功解决了Rydberg原子传感器在宽带OFDM信号接收方面的挑战，并通过实验验证了其有效性。

Abstract: Rydberg atomic sensors have been seen as novel radio frequency (RF)
measurements and the high sensitivity to a large range of frequencies makes it
attractive for communications reception. However, the signal sensing process in
Rydberg system involves sequential transduction from electromagnetic waves to
optical signals and finally to electrical signals. The unipolar characteristic
of the optical interface inherently restricts conventional OFDM reception.
Therefore, adopting unipolar OFDM schemes, inspired by optical communication
systems, becomes essential for compatible signal transmission. In this work, we
investigate the amplitude modulation-to-amplitude modulation (AM-AM)
characteristics of Rydberg atomic sensors, establishing an empirical
approximation function. Building on the direct current-biased optical
orthogonal frequency division multiplexing (DCO-OFDM) framework, we propose a
novel local oscillator direct current-biased OFDM (LODC-OFDM) scheme
specifically optimized for Rydberg-based sensing, effectively addressing the
broadband OFDM reception challenge. Then, we adopt Bussgang theorem to analyze
the nonlinear distortion of LODC-OFDM signals and the results in closed-form
solutions are derived for AM/AM curves approximated by Taylor series expansion
and for the ideal pre-distortion case. In real experiments, the experimental
and theoretical results fit well.

</details>


### [307] [SEP Analysis of 1-Bit Quantized SIMO Systems with QPSK over Fading Channels](https://arxiv.org/abs/2510.01707)
*Amila Ravinath,Minhua Ding,Bikshapathi Gouda,Italo Atzeni,Antti Tölli*

Main category: eess.SP

TL;DR: 本文推导了1位量化单输入多输出（SIMO）系统在瑞利衰落信道和QPSK调制下的平均符号错误概率（SEP）的精确解析表达式，并确定了SIMO-MRC系统的分集增益和编码增益。此外，还量化了1位量化SIMO-SC系统在任意数量接收天数下的分集和编码增益。


<details>
  <summary>Details</summary>
Motivation: 先前的研究仅部分表征了选择性合并（SC）的分集增益，而本文旨在推导1位量化单输入多输出（SIMO）系统在瑞利衰落信道和QPSK调制下的平均符号错误概率（SEP）的精确表达式，并确定其分集增益和编码增益。

Method: 利用一种新颖的解析方法，推导了采用QPSK调制和最大比合并（MRC）的1位量化SIMO系统的精确解析SEP表达式，并确定了其分集和编码增益。同时，量化了1位量化SIMO-SC系统在任意数量接收天数下的分集和编码增益。

Result: 本文成功推导了1位量化SIMO-MRC系统在QPSK调制和瑞利衰落信道下的精确解析SEP表达式，并计算了其分集增益和编码增益。此外，还确定了1位量化SIMO-SC系统在任意数量接收天数下的分集和编码增益。

Conclusion: 本文成功推导了1位量化SIMO-MRC系统和1位量化SIMO-SC系统（在任意数量接收天数下）的精确解析SEP表达式，并确定了它们的分集和编码增益，从而扩展和补充了先前的研究结果。

Abstract: The average symbol error probability (SEP) of a 1-bit quantized single-input
multiple-output (SIMO) system is analyzed under Rayleigh fading channels and
quadrature phase-shift keying (QPSK) modulation. Previous studies have
partially characterized the diversity gain for selection combining (SC). In
this paper, leveraging a novel analytical method, an exact analytical SEP
expression is derived for a 1-bit quantized SIMO system employing QPSK
modulation at the transmitter and maximum ratio combining (MRC) at the
receiver. The corresponding diversity and coding gains of a SIMO-MRC system are
also determined. Furthermore, the diversity and coding gains of a 1-bit
quantized SIMO-SC system are quantified for an arbitrary number of receive
antennas, thereby extending and complementing prior results.

</details>


### [308] [3D 8-Ary Noise Modulation Using Bayesian- and Kurtosis-based Detectors](https://arxiv.org/abs/2510.01748)
*Hadi Zayyani,Felipe A. P. de Figueiredo,Mohammad Salman,Rausley A. A. de Souza*

Main category: eess.SP

TL;DR: 本论文提出了一种新颖的三维八进制噪声调制方案，增加了混合高斯（MoG）分布的混合概率作为新维度，并结合均值和方差维度。该方案使用三种检测器（阈值、最大似然、基于峰度和Jarque-Bera检验的贝叶斯假设检验）来检测三个子信道比特，分别对应均值、方差和MoG概率。仿真结果表明，该方案在提高数据速率的同时，第三子信道比特的误比特概率（BEP）与现有二维方案相当，并且基于峰度的检测器提供了低复杂度、可接受的BEP。


<details>
  <summary>Details</summary>
Motivation: 为了在通信系统中提高数据速率和/或降低误比特概率（BEP），本研究提出了一种新颖的三维八进制噪声调制方案。

Method: 提出了一种新的三维八进制噪声调制方案，该方案利用高斯混合（MoG）分布的混合概率作为新维度，并结合均值和方差维度。对于检测，该方案结合了阈值检测器（用于均值）、最大似然（ML）检测器（用于方差）以及基于峰度和Jarque-Bera（JB）检验的贝叶斯假设检验（BHT）检测器（用于MoG概率）。推导了阈值、峰度和BHT检测器的误比特概率（BEP），并推导了峰度检测器的最优阈值。

Result: 仿真结果表明，与现有的二维方案相比，该方案在第三子信道比特上实现了可比的低误比特概率（BEP）。与广义二次噪声调制器和经典二元KLJN噪声调制器相比，该方案将数据速率分别提高了1.5倍和3倍。此外，基于峰度的检测器提供了一种低复杂度解决方案，其误比特概率（BEP）约为0.06。

Conclusion: 本论文提出的三维八进制噪声调制方案，通过引入MoG概率作为新维度，并结合先进的检测技术，在提高数据速率和保持低误比特概率（BEP）方面取得了显著成效，尤其是在低复杂度检测器方面表现出色。

Abstract: This paper presents a novel three-dimensional (3D) 8-ary noise modulation
scheme that introduces a new dimension: the mixture probability of a Mixture of
Gaussian (MoG) distribution. This proposed approach utilizes the dimensions of
mean and variance, in addition to the new probability dimension. Within this
framework, each transmitted symbol carries three bits, each corresponding to a
distinct sub-channel. For detection, a combination of specialized detectors is
employed: a simple threshold based detector for the first sub-channel bit
(modulated by the mean), a Maximum-Likelihood (ML) detector for the second
sub-channel bit (modulated by the variance), a Kurtosis-based, Jarque-Bera (JB)
test, and Bayesian Hypothesis (BHT)-based detectors for the third bit
(modulated by the MoG probability). The Kurtosis- and JB-based detectors
specifically distinguish between Gaussian (or near-Gaussian) and non-Gaussian
MoG distributions by leveraging higher-order statistical measures. The Bit
Error Probabilities (BEPs) are derived for the threshold-, Kurtosis-, and
BHT-based detectors. The optimum threshold for the Kurtosis-based detector is
also derived in a tractable manner. Simulation results demonstrate that a
comparably low BEP is achieved for the third sub-channel bit relative to
existing two-dimensional (2D) schemes. Simultaneously, the proposed scheme
increases the data rate by a factor of 1.5 and 3 compared to the Generalized
Quadratic noise modulator and the classical binary KLJN noise modulator,
respectively. Furthermore, the Kurtosis-based detector offers a low-complexity
solution, achieving an acceptable BEP of approximately 0.06.

</details>


### [309] [Exactly or Approximately Wasserstein Distributionally Robust Estimation According to Wasserstein Radii Being Small or Large](https://arxiv.org/abs/2510.01763)
*Xiao Ding,Enbin Song,Dunbiao Niu,Zhujun Cao,Qingjiang Shi*

Main category: eess.SP

TL;DR: 该论文研究了带有加性噪声的线性测量模型中，在Wasserstein距离约束下的鲁棒估计问题，将其转化为无限维非凸minimax问题。证明了鞍点存在性等价于有限维minimax问题，并给出了鞍点可能不存在的反例。提出了可验证的充要条件，参数可从凸问题及其对偶问题推导。还提出了简化的充分条件，说明当Wasserstein半径足够小时，鞍点总是存在。在不存在鞍点的情况下，通过限制估计器为线性，求解有限维非凸minimax问题，其最优值给出了鲁棒估计问题的上界，最优解则给出了鲁棒线性估计器。数值实验验证了理论结果。


<details>
  <summary>Details</summary>
Motivation: 该论文的动机是解决在Wasserstein距离约束下，线性测量模型中带有加性噪声的鲁棒估计问题，该问题被表述为一个无限维的非凸minimax问题。

Method: 研究了无限维非凸minimax问题的鞍点存在性，并给出了其等价于有限维minimax问题的证明。提出了可验证的充要条件，参数可从凸问题及其对偶问题推导。提出了一种简化的充分条件。当不存在鞍点时，通过限制估计器为线性来求解有限维非凸minimax问题。

Result: 证明了鞍点存在性等价于有限维minimax问题，并给出了鞍点可能不存在的反例。提出了可验证的充要条件。提出了简化的充分条件，说明当Wasserstein半径足够小时，鞍点总是存在。当不存在鞍点时，求解有限维非凸minimax问题，其最优值给出了鲁棒估计问题的上界，最优解则给出了鲁棒线性估计器。数值实验验证了理论结果。

Conclusion: 该研究为Wasserstein距离约束下的鲁棒估计问题提供了理论基础和解决方法，并给出了在特定条件下鞍点存在性的保证以及求解鲁棒线性估计器的方法。

Abstract: This paper primarily considers the robust estimation problem under
Wasserstein distance constraints on the parameter and noise distributions in
the linear measurement model with additive noise, which can be formulated as an
infinite-dimensional nonconvex minimax problem. We prove that the existence of
a saddle point for this problem is equivalent to that for a finite-dimensional
minimax problem, and give a counterexample demonstrating that the saddle point
may not exist. Motivated by this observation, we present a verifiable necessary
and sufficient condition whose parameters can be derived from a convex problem
and its dual. Additionally, we also introduce a simplified sufficient
condition, which intuitively indicates that when the Wasserstein radii are
small enough, the saddle point always exists. In the absence of the saddle
point, we solve an finite-dimensional nonconvex minimax problem, obtained by
restricting the estimator to be linear. Its optimal value establishes an upper
bound on the robust estimation problem, while its optimal solution yields a
robust linear estimator. Numerical experiments are also provided to validate
our theoretical results.

</details>


### [310] [Composite Generalized Quadratic Noise Modulation via Signal Addition: Towards Higher Dimensional Noise Modulations](https://arxiv.org/abs/2510.01776)
*Hadi Zayyani,Mohammad Salman,Felipe A. P. de Figueiredo,Rausley A. A. de Souza*

Main category: eess.SP

TL;DR: 通过叠加两个广义二次噪声调制器（GQNM）来创建一个16元噪声调制器，该调制器在信息比特上传输四个不同的均值和四个不同的方差，并在仿真中验证了其性能优于KLJN调制器和GQNM调制器。


<details>
  <summary>Details</summary>
Motivation: 提出一种新的噪声调制器，该调制器通过叠加两个GQNM来实现，并能达到比现有方案更好的性能。

Method: 通过叠加两个GQNM来创建一个16元噪声调制器，并利用仿真来验证其性能。

Result: 所提出的16元噪声调制器在比特误差概率（BEP）方面优于KLJN调制器和GQNM调制器。

Conclusion: 通过增加调制器、发射器和接收器检测器的复杂性，可以实现更好的性能。所提出的噪声调制器可以通过叠加更多的GQNM来扩展到更高阶的调制方案。

Abstract: This letter proposes superposing two Generalized Quadratic Noise Modulators
(GQNM) by simply adding their outputs. It creates a 16-ary noise modulator that
resembles QAM modulators in classical communication. It modulates the
information bits on four different means and four different variances. It could
also be applied to reach higher-order modulations than 16-ary schemes by adding
the outputs of more than two modulators, which is not discussed in detail in
this letter and left for future work. By selecting the parameters necessary for
satisfying the theoretical distinguishability conditions provided in the paper,
we can reach better performances in comparison to the Kirchhoff-Law Johnson
Noise (KLJN) modulator and the GQNM modulator, which is verified by the
simulations. The better result in terms of smaller Bit Error Probability (BEP)
is achieved by increasing the complexity in the modulator, the transmitter, and
the detectors in the receiver.

</details>


### [311] [Closed-form Single UAV-aided Emitter Localization and Trajectory Design Using Doppler and TOA Measurements](https://arxiv.org/abs/2510.01778)
*Samaneh Motie,Hadi Zayyani,Mohammad Salman,Hasan Abu Hilal*

Main category: eess.SP

TL;DR: 提出了一种结合多普勒和到达时间（ToA）测量的单无人机（UAV）辅助定位算法。


<details>
  <summary>Details</summary>
Motivation: 与基于非凸函数的传统多普勒定位算法不同，该算法利用ToA测量将成本函数转化为二次凸函数，从而简化了定位过程。

Method: 通过将ToA测量与最小化器线性方程相结合，使用约束最小二乘（LS）优化获得发射器位置的闭式解。此外，还提供了一个具有闭式解的UAV轨迹设计。

Result: 仿真实验表明，与文献中的其他算法相比，所提出的算法具有更高的有效性。

Conclusion: 所提出的单UAV辅助定位算法通过结合多普勒和ToA测量，并利用约束LS优化和UAV轨迹设计，能够获得发射器位置的闭式解，并在仿真中证明了其有效性。

Abstract: In this paper, a single Unmanned-Aerial-Vehicle (UAV)-aided localization
algorithm which uses both Doppler and Time of Arrival (ToA) measurements is
presented. In contrast to Doppler-based localization algorithms which are based
on non-convex functions, exploiting ToA measurements in a Least-Square (LS)
Doppler-based cost function, leads to a quadratic convex function whose
minimizer lies on a line. Utilizing the ToA measurements in addition to the
linear equation of minimizer, a closed form solution is obtained for the
emitter location using a constrained LS optimization. In addition, a trajectory
design of the UAV is provided which has also closed-form solution. Simulation
experiments demonstrate the effectiveness of the proposed algorithm in
comparison to some others in the literature.

</details>


### [312] [Performance Optimization for Movable Antenna Enhanced MISO-OFDM Systems](https://arxiv.org/abs/2510.01789)
*Ruixi Feng,Weidong Mei,Lele Lu,Xin Wei,Zhi Chen,Zhen Gao,Boyu Ning*

Main category: eess.SP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Movable antenna (MA) technology offers a flexible approach to enhancing
wireless channel conditions by adjusting antenna positions within a designated
region. While most existing works focus on narrowband MA systems, this paper
investigates MA position optimization for an MA-enhanced multiple-input
single-output (MISO) orthogonal frequency-division multiplexing (OFDM) system.
This problem appears to be particularly challenging due to the frequency-flat
nature of MA positioning, which should accommodate the channel conditions
across different subcarriers. To overcome this challenge, we discretize the
movement region into a multitude of sampling points, thereby converting the
continuous position optimization problem into a discrete point selection
problem. Although this problem is combinatorial, we develop an efficient
partial enumeration algorithm to find the optimal solution using a
branch-and-bound framework, where a graph-theoretic method is incorporated to
effectively prune suboptimal solutions. In the low signal-to-noise ratio (SNR)
regime, a simplified graph-based algorithm is also proposed to obtain the
optimal MA positions without the need for enumeration. Simulation results
reveal that the proposed algorithm outperforms conventional fixed-position
antennas (FPAs), while narrowband-based antenna position optimization can
achieve near-optimal performance.

</details>


### [313] [NGGAN: Noise Generation GAN Based on the Practical Measurement Dataset for Narrowband Powerline Communications](https://arxiv.org/abs/2510.01850)
*Ying-Ren Chien,Po-Heng Chou,You-Jie Peng,Chun-Yuan Huang,Hen-Wai Tsao,Yu Tsao*

Main category: eess.SP

TL;DR: 本篇论文提出了一种名为NGGAN的生成对抗网络，用于生成非周期异步脉冲噪声，以增强窄带电力线通信（NB-PLC）系统的噪声处理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的数学噪声生成模型只能捕捉到加性噪声的部分特征，无法全面描述NB-PLC系统中的复杂噪声特性。

Method: 提出了一种名为NGGAN（Noise-Generation GAN）的生成对抗网络。首先，通过模拟实际NB-PLC调制解调器的模拟耦合和带通滤波电路，测量并构建了一个真实的NB-PLC噪声数据集。然后，基于该数据集设计NGGAN模型，包括确定输入信号长度以适应周平稳噪声生成，使用Wasserstein距离作为损失函数以提高生成噪声与训练数据集的相似度并保证样本多样性。最后，使用数学模型（PSCGM、FRESH滤波器）和实际测量的NB-PLC噪声数据集对NGGAN进行训练和评估。

Result: 通过定量和定性分析，将基于数学数据集和实际测量数据集训练的GAN模型进行比较。仿真结果表明，所提出的NGGAN在生成噪声的质量方面，更接近于使用实际测量数据集训练的模型。

Conclusion: 所提出的NGGAN模型能够学习并生成更符合NB-PLC系统实际噪声特性的数据，为数据增强提供了有效的方法，从而改善NB-PLC收发器的噪声处理性能。

Abstract: Capturing comprehensive statistics of nonperiodic asynchronous impulsive
noise is a critical issue in enhancing impulse noise processing for narrowband
powerline communication (NB-PLC) transceivers. However, existing mathematical
noise generative models capture only some of the characteristics of additive
noise. Therefore, we propose a generative adversarial network (GAN), called the
noise-generation GAN (NGGAN), that learns the complicated characteristics of
practically measured noise samples for data augmentation. To closely match the
statistics of complicated noise in NB-PLC systems, we measured the NB-PLC noise
via the analog coupling and bandpass filtering circuits of a commercial NB-PLC
modem to build a realistic dataset. Specifically, the NGGAN design approaches
based on the practically measured dataset are as follows: (i) we design the
length of input signals that the NGGAN model can fit to facilitate
cyclo-stationary noise generation. (ii) Wasserstein distance is used as a loss
function to enhance the similarity between the generated noise and the training
dataset and ensure that the sample diversity is sufficient for various
applications. (iii) To measure the similarity performance of the GAN-based
models based on mathematical and practically measured datasets, we perform
quantitative and qualitative analyses. The training datasets include (1) a
piecewise spectral cyclo-stationary Gaussian model (PSCGM), (2) a
frequency-shift (FRESH) filter, and (3) practical measurements from NB-PLC
systems. Simulation results demonstrate that the proposed NGGAN trained using
waveform characteristics is closer to the practically measured dataset in terms
of the quality of the generated noise.

</details>


### [314] [Wearable and Ultra-Low-Power Fusion of EMG and A-Mode US for Hand-Wrist Kinematic Tracking](https://arxiv.org/abs/2510.02000)
*Giusy Spacone,Sebastian Frey,Mattia Orlandi,Pierangelo Maria Rapa,Victor Kartsch,Simone Benatti,Luca Benini,Andrea Cossettini*

Main category: eess.SP

TL;DR: 提出了一种超低功耗（低于50毫瓦）的系统，能够同时采集8通道EMG和4通道A模式US信号，并提出了一种使用轻量级编码器-解码器架构和多任务学习的框架，用于连续追踪23个自由度（手部20个，腕部3个）。


<details>
  <summary>Details</summary>
Motivation: 现有的基于生物信号的手势识别系统功耗高，不适合多日使用，且仅限于离散手势分类。融合表面肌电图（EMG）和A模式超声（US）信号是很有前景的，但需要解决功耗和连续追踪的问题。

Method: 开发了一个集成化的、完全可穿戴的、干接触式臂带系统，能够同时采集8通道EMG和4通道A模式US信号，功耗低于50毫瓦。采用轻量级编码器-解码器架构和多任务学习，同时估计手部和腕部的关节角度，并使用运动捕捉手套进行真值标注。

Result: 在实际的传感器重新定位条件下，EMG-US融合方法实现了$10.6^\circ\pm2.0^\circ$的均方根误差（RMSE）和$0.61\pm0.1$的R$^2$分数，优于单独使用EMG（RMSE $12.0^\circ\pm1^\circ$，R$^2$ $0.54\pm0.03$）或US（RMSE $13.1^\circ\pm2.6^\circ$，R$^2$ $0.38\pm0.20$）。

Conclusion: EMG和US信号的融合能够实现更精确、更可靠的手势识别，并且所提出的超低功耗系统适用于多日连续佩戴，为开发直观的人机交互提供了新的可能性。

Abstract: Hand gesture recognition based on biosignals has shown strong potential for
developing intuitive human-machine interaction strategies that closely mimic
natural human behavior. In particular, sensor fusion approaches have gained
attention for combining complementary information and overcoming the
limitations of individual sensing modalities, thereby enabling more robust and
reliable systems. Among them, the fusion of surface electromyography (EMG) and
A-mode ultrasound (US) is very promising. However, prior solutions rely on
power-hungry platforms unsuitable for multi-day use and are limited to discrete
gesture classification. In this work, we present an ultra-low-power (sub-50 mW)
system for concurrent acquisition of 8-channel EMG and 4-channel A-mode US
signals, integrating two state-of-the-art platforms into fully wearable,
dry-contact armbands. We propose a framework for continuous tracking of 23
degrees of freedom (DoFs), 20 for the hand and 3 for the wrist, using a
kinematic glove for ground-truth labeling. Our method employs lightweight
encoder-decoder architectures with multi-task learning to simultaneously
estimate hand and wrist joint angles. Experimental results under realistic
sensor repositioning conditions demonstrate that EMG-US fusion achieves a root
mean squared error of $10.6^\circ\pm2.0^\circ$, compared to
$12.0^\circ\pm1^\circ$ for EMG and $13.1^\circ\pm2.6^\circ$ for US, and a R$^2$
score of $0.61\pm0.1$, with $0.54\pm0.03$ for EMG and $0.38\pm0.20$ for US.

</details>


### [315] [Computing on Dirty Paper: Interference-Free Integrated Communication and Computing](https://arxiv.org/abs/2510.02012)
*Kuranage Roche Rayan Ranasinghe,Giuseppe Thadeu Freitas de Abreu,David González G.,Carlo Fischione*

Main category: eess.SP

TL;DR: 该论文提出了一种名为“脏纸上的计算”的新型通信与计算融合（ICC）方案，该方案受启发于Costa的脏纸编码（DPC）工作。


<details>
  <summary>Details</summary>
Motivation: 该论文的动机是提出一种能够同时在多址信道上实现通信离散数据符号传输和过顶计算（AirComp）的化工方案。

Method: 该方法通过在发送端（TXs）使用DPC原理预先抵消计算符号，实现了通信与计算的融合，从而在渐近意义上消除了干扰。

Result: 在单输入多输出（SIMO）设置下，通过仿真评估了所提出的ICC方案，包括数据检测性能和函数计算的均方误差（MSE）性能。

Conclusion: 结果验证了所提出的方法，并证明了其在比特错误率（BER）和MSE方面显著优于最先进（SotA）的ICC方案。

Abstract: Inspired by Costa's pioneering work on dirty paper coding (DPC), this paper
proposes a novel scheme for integrated communication and computing (ICC), named
Computing on Dirty Paper, whereby the transmission of discrete data symbols for
communication, and over-the-air computation (AirComp) of nomographic functions
can be achieved simultaneously over common multiple-access channels. In
particular, the proposed scheme allows for the integration of communication and
computation in a manner that is asymptotically interference-free, by
precanceling the computing symbols at the transmitters (TXs) using DPC
principles. A simulation-based assessment of the proposed ICC scheme under a
single-input multiple-output (SIMO) setup is also offered, including the
evaluation of performance for data detection, and of mean-squared-error (MSE)
performance for function computation, over a block of symbols. The results
validate the proposed method and demonstrate its ability to significantly
outperform state-of-the-art (SotA) ICC schemes in terms of both bit error rate
(BER) and MSE.

</details>


### [316] [Joint Jammer Mitigation and Data Detection](https://arxiv.org/abs/2510.02021)
*Gian Marti,Christoph Studer*

Main category: eess.SP

TL;DR: 该研究提出了一种名为JMD的新范式，用于联合消除干扰和检测数据，解决了现有MIMO干扰消除方法需要训练阶段且易被智能干扰规避的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于训练阶段估计干扰空间特征的MIMO干扰消除方法存在通信速率降低和易被智能干扰规避的缺点。

Method: 提出联合干扰消除和数据检测（JMD）范式，联合估计干扰子空间并检测合法数据，无需专门的训练阶段，能够应对智能和动态多天线干扰。提出了两种JMD算法：SANDMAN和MAED，它们在估计合法信道方面有所不同，并提供了不同的复杂性-性能权衡。

Result: 通过大量仿真证明了JMD在干扰消除方面的有效性。

Conclusion: JMD是一种有效且能够应对智能干扰的新型MIMO干扰消除方法。

Abstract: Multi-antenna (or MIMO) processing is a promising solution to the problem of
jammer mitigation. Existing methods mitigate the jammer based on an estimate of
its spatial signature that is acquired through a dedicated training phase. This
strategy has two main drawbacks: (i) it reduces the communication rate since no
data can be transmitted during the training phase and (ii) it can be evaded by
smart or multi-antenna jammers that do not transmit during the training phase
or that dynamically change their subspace through time-varying beamforming. To
address these drawbacks, we propose Joint jammer Mitigation and data Detection
(JMD), a novel paradigm for MIMO jammer mitigation. The core idea of JMD is to
estimate and remove the jammer interference subspace jointly with detecting the
legitimate transmit data over multiple time slots. Doing so removes the need
for a dedicated and rate-reducing training period while being able to mitigate
smart and dynamic multi-antenna jammers. We provide two JMD-type algorithms,
SANDMAN and MAED, that differ in the way they estimate the channels of the
legitimate transmitters and achieve different complexity-performance tradeoffs.
Extensive simulations demonstrate the efficacy of JMD for jammer mitigation.

</details>


### [317] [A Secure Affine Frequency Division Multiplexing for Wireless Communication Systems](https://arxiv.org/abs/2510.02023)
*Ping Wang,Zulin Wang,Yuanhan Ni,Qu Luo,Yuanfang Ma,Xiaosi Tian,Pei Xiao*

Main category: eess.SP

TL;DR: 该研究提出了一种名为SE-AFDM的新型安全频分复用系统，通过动态调整预啁啾参数来增强物理层安全性，并提出了一种同步框架来应对快速时变信道。


<details>
  <summary>Details</summary>
Motivation: 为了在高速移动场景下提高AFDM系统的性能和安全性，并为系统设计提供更多自由度。

Method: 通过动态生成一个由长周期伪噪声（LPPN）序列控制的码本中的AFDM预啁啾参数，实现了参数域扩展，并提出了一种同步框架来解决时变参数同步问题。

Result: 理论推导证明了未同步窃听者无法消除时变参数的非线性影响，仿真结果证明了SE-AFDM系统的安全优势，硬件原型验证了同步框架的有效性。

Conclusion: SE-AFDM系统通过动态调整预啁啾参数有效提高了物理层安全性，并提出了一种有效的同步框架，适用于高速移动和快速时变信道场景。

Abstract: Affine frequency division multiplexing (AFDM) has garnered significant
attention due to its superior performance in high-mobility scenarios, coupled
with multiple waveform parameters that provide greater degrees of freedom for
system design. This paper introduces a novel secure affine frequency division
multiplexing (SE-AFDM) system, which advances prior designs by dynamically
varying an AFDM pre-chirp parameter to enhance physical-layer security. In the
SE-AFDM system, the pre-chirp parameter is dynamically generated from a
codebook controlled by a long-period pseudo-noise (LPPN) sequence. Instead of
applying spreading in the data domain, our parameter-domain spreading approach
provides additional security while maintaining reliability and high spectrum
efficiency. We also propose a synchronization framework to solve the problem of
reliably and rapidly synchronizing the time-varying parameter in fast
time-varying channels. The theoretical derivations prove that unsynchronized
eavesdroppers cannot eliminate the nonlinear impact of the time-varying
parameter and further provide useful guidance for codebook design. Simulation
results demonstrate the security advantages of the proposed SE-AFDM system in
high-mobility scenarios, while our hardware prototype validates the
effectiveness of the proposed synchronization framework.

</details>


### [318] [Joint DOA and Attitude Sensing Based on Tri-Polarized Continuous Aperture Array](https://arxiv.org/abs/2510.02029)
*Haonan Si,Zhaolin Wang,Xiansheng Guo,Jin Zhang,Yuanwei Liu*

Main category: eess.SP

TL;DR: 本论文提出一种利用三极化连续孔径阵列（CAPA）进行联合到达方向（DOA）和姿态感知的方法。


<details>
  <summary>Details</summary>
Motivation: 利用电磁信息论，对三极化CAPA中的空间连续接收信号进行建模，以实现精确的DOA和姿态估计。

Method: 开发了一种等效的连续-离散变换技术，用于连续算子的子空间分解。利用三极化信号的自协方差和互协方差构建三极化频谱，以提高DOA估计性能。提出两种姿态估计算法：一种在无先验知识的情况下估计部分姿态信息，另一种在有先验知识的情况下估计完整姿态信息。

Result: 数值结果证明了所提出框架的可行性和优越性。

Conclusion: 本论文成功地提出了一种利用三极化CAPA进行联合DOA和姿态感知的框架，并通过数值结果验证了其有效性。

Abstract: This paper investigates joint direction-of-arrival (DOA) and attitude sensing
using tri-polarized continuous aperture arrays (CAPAs). By employing
electromagnetic (EM) information theory, the spatially continuous received
signals in tri-polarized CAPA are modeled, thereby enabling accurate DOA and
attitude estimation. To facilitate subspace decomposition for continuous
operators, an equivalent continuous-discrete transformation technique is
developed. Moreover, both self- and cross-covariances of tri-polarized signals
are exploited to construct a tri-polarized spectrum, significantly enhancing
DOA estimation performance. Theoretical analyses reveal that the
identifiability of attitude information fundamentally depends on the
availability of prior target snapshots. Accordingly, two attitude estimation
algorithms are proposed: one capable of estimating partial attitude information
without prior knowledge, and the other achieving full attitude estimation when
such knowledge is available. Numerical results demonstrate the feasibility and
superiority of the proposed framework.

</details>


### [319] [Sensing-Secure ISAC: Ambiguity Function Engineering for Impairing Unauthorized Sensing](https://arxiv.org/abs/2510.02103)
*Kawon Han,Kaitao Meng,Christos Masouros*

Main category: eess.SP

TL;DR: 本论文提出了一种集成传感与通信（ISAC）安全框架，通过在模糊函数（AF）中引入人工瑕疵来干扰被动雷达窃听者（Eve）的传感信息提取，同时允许合法接收者（Alice）通过失配滤波进行恢复，从而在通信、合法传感和传感安全之间实现权衡。


<details>
  <summary>Details</summary>
Motivation: 为了解决集成传感与通信（ISAC）部署带来的授权传感漏洞问题，需要开发安全解决方案，以防止未经授权的被动雷达窃听者（Eve）提取传感信息。

Method: 通过在ISAC信号的模糊函数（AF）中引入人工瑕疵，制造虚假目标，增加Eve的距离估计模糊性。合法接收者（Alice）使用失配滤波抑制这些AF伪影，但会损失信噪比（SNR）。采用OFDM信号，设计了结构化的子载波功率分配方案来塑造安全的自相关函数（ACF），插入周期性峰值来误导Eve的距离估计并降低目标检测性能。引入峰值旁瓣电平（PSL）和积分旁瓣电平（ISL）作为关键性能指标，并分析了通信、合法传感和传感安全之间的三向权衡。通过凸优化问题来最大化ISAC性能，同时保证一定的传感安全水平。

Result: 数值结果验证了所提出的传感安全ISAC信号的有效性，表明该方法能够降低Eve的目标估计性能，同时保持Alice的性能。

Conclusion: 所提出的传感安全ISAC框架能够有效地提高ISAC系统的安全性，在保证合法用户传感性能的同时，有效降低窃听者获取传感信息的风险。

Abstract: The deployment of integrated sensing and communication (ISAC) brings along
unprecedented vulnerabilities to authorized sensing, necessitating the
development of secure solutions. Sensing parameters are embedded within the
target-reflected signal leaked to unauthorized passive radar sensing
eavesdroppers (Eve), implying that they can silently extract sensory
information without prior knowledge of the information data. To overcome this
limitation, we propose a sensing-secure ISAC framework that ensures secure
target detection and estimation for the legitimate system, while obfuscating
unauthorized sensing without requiring any prior knowledge of Eve. By
introducing artificial imperfections into the ambiguity function (AF) of ISAC
signals, we introduce artificial targets into Eve's range profile which
increase its range estimation ambiguity. In contrast, the legitimate sensing
receiver (Alice) can suppress these AF artifacts using mismatched filtering,
albeit at the expense of signal-to-noise ratio (SNR) loss. Employing an OFDM
signal, a structured subcarrier power allocation scheme is designed to shape
the secure autocorrelation function (ACF), inserting periodic peaks to mislead
Eve's range estimation and degrade target detection performance. To quantify
the sensing security, we introduce peak sidelobe level (PSL) and integrated
sidelobe level (ISL) as key performance metrics. Then, we analyze the three-way
trade-offs between communication, legitimate sensing, and sensing security,
highlighting the impact of the proposed sensing-secure ISAC signaling on system
performance. We formulate a convex optimization problem to maximize ISAC
performance while guaranteeing a certain sensing security level. Numerical
results validate the effectiveness of the proposed sensing-secure ISAC
signaling, demonstrating its ability to degrade Eve's target estimation while
preserving Alice's performance.

</details>


### [320] [Unlocking Symbol-Level Precoding Efficiency Through Tensor Equivariant Neural Network](https://arxiv.org/abs/2510.02108)
*Jinshuo Zhang,Yafei Wang,Xinping Yi,Wenjin Wang,Shi Jin,Symeon Chatzinotas,Björn Ottersten*

Main category: eess.SP

TL;DR: 通过深度学习（DL）和张量等变性（TE）技术，提出了一种低复杂度、高效率的符号级预编码（SLP）框架，在性能损失很小的情况下实现了显著的加速。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于建设性干扰（CI）利用的符号级预编码（SLP）方法复杂度高的问题。

Method: 提出了一种端到端的深度学习（DL）框架，利用最优SLP解的闭式形式和固有的张量等变性（TE），并设计了一个基于注意力的TE模块，实现了线性计算复杂度。同时，该框架也被扩展到不完美的CSI场景。

Result: 所提出的框架在性能上接近最优SLP，实现了约80倍的加速，并具有良好的泛化能力，能够适应不同的用户数量和符号块长度。

Conclusion: 基于DL和TE的SLP框架能够有效解决现有方法的复杂度瓶颈，在保持高性能的同时实现显著的加速和良好的泛化能力。

Abstract: Although symbol-level precoding (SLP) based on constructive interference (CI)
exploitation offers performance gains, its high complexity remains a
bottleneck. This paper addresses this challenge with an end-to-end deep
learning (DL) framework with low inference complexity that leverages the
structure of the optimal SLP solution in the closed-form and its inherent
tensor equivariance (TE), where TE denotes that a permutation of the input
induces the corresponding permutation of the output. Building upon the
computationally efficient model-based formulations, as well as their known
closed-form solutions, we analyze their relationship with linear precoding (LP)
and investigate the corresponding optimality condition. We then construct a
mapping from the problem formulation to the solution and prove its TE, based on
which the designed networks reveal a specific parameter-sharing pattern that
delivers low computational complexity and strong generalization. Leveraging
these, we propose the backbone of the framework with an attention-based TE
module, achieving linear computational complexity. Furthermore, we demonstrate
that such a framework is also applicable to imperfect CSI scenarios, where we
design a TE-based network to map the CSI, statistics, and symbols to auxiliary
variables. Simulation results show that the proposed framework captures
substantial performance gains of optimal SLP, while achieving an approximately
80-times speedup over conventional methods and maintaining strong
generalization across user numbers and symbol block lengths.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [321] [Sequent Calculi for Data-Aware Modal Logics](https://arxiv.org/abs/2510.01868)
*Carlos Areces,Valentin Cassano,Danae Dutto,Raul Fervari*

Main category: cs.LO

TL;DR: 本文提出了一种用于数据感知模态逻辑 HXpathD 的公理化方法，重点是其在查询语言中的应用。


<details>
  <summary>Details</summary>
Motivation: 以前对 HXpathD 的研究主要集中在模型论性质上，而本文从证明论的角度进行了研究，旨在为数据感知模态逻辑提供更深入的理论基础，并为图结构数据查询语言提供逻辑分析。

Method: 提出了一种健全且完整的、符合 Gentzen 风格的馏理论证演算，并证明了所有规则都是可逆的，并且满足割消。

Result: 成功构建了一个健全且完整的馏理论证演算，并且该演算的所有规则都是可逆的，同时还具备割消的性质。

Conclusion: 本文为数据感知模态逻辑的证明论奠定了基础，能够对图结构数据查询语言进行更深入的逻辑分析，并为将证明论技术扩展到更广泛的模态系统提供了可能。

Abstract: Data-aware modal logics offer a powerful formalism for reasoning about
semi-structured queries in languages such as DataGL, XPath, and GQL. In brief,
these logics can be viewed as modal systems capable of expressing both
reachability statements and data-aware properties, such as value comparisons.
One particularly expressive logic in this landscape is HXpathD, a hybrid modal
logic that captures not only the navigational core of XPath but also data
comparisons, node labels (keys), and key-based navigation operators. While
previous work on HXpathD has primarily focused on its model-theoretic
properties, in this paper we approach HXpathD from a proof-theoretic
perspective. Concretely, we present a sound and complete Gentzen-style sequent
calculus for HXpathD. Moreover, we show all rules in this calculus are
invertible, and that it enjoys cut elimination. Our work contributes to the
proof-theoretic foundations of data-aware modal logics, and enables a deeper
logical analysis of query languages over graph-structured data. Moreover, our
results lay the groundwork for extending proof-theoretic techniques to a
broader class of modal systems.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [322] [MPMAvatar: Learning 3D Gaussian Avatars with Accurate and Robust Physics-Based Dynamics](https://arxiv.org/abs/2510.01619)
*Changmin Lee,Jihyun Lee,Tae-Kyun Kim*

Main category: cs.GR

TL;DR: MPMAvatar是一个从多视角视频创建3D人类虚拟形象的框架，它利用基于材料点法（MPM）的模拟器来精确、鲁棒地模拟服装的物理动态，并结合3D高斯溅射（3DGS）实现高质量渲染，在动态建模、渲染准确性和鲁棒性方面优于现有技术，并实现了零样本泛化到未见过的交互。


<details>
  <summary>Details</summary>
Motivation: 在从视觉观测创建3D虚拟形象方面取得了显著进展，但对具有宽松服装的人类进行物理上可行的动态建模仍然是一个挑战。现有的方法在准确性或对新动画输入的鲁棒性方面存在局限。

Method: 该框架使用基于材料点法（MPM）的模拟器，并结合各向异性本构模型和新的碰撞处理算法，以精确、鲁棒地模拟具有复杂变形和身体接触的服装。动态模型与使用3D高斯溅射（3DGS）和准阴影实现的标准虚拟形象相结合，以实现高保真渲染。

Result: MPMAvatar在动态建模准确性、渲染准确性以及鲁棒性和效率方面显著优于最先进的基于物理的虚拟形象。此外，它还实现了对未见过交互的零样本泛化。

Conclusion: MPMAvatar通过结合先进的物理模拟（MPM）和高质量渲染（3DGS），为3D人类虚拟形象的创建和动画提供了一个准确、鲁棒且高效的解决方案，并在零样本泛化方面取得了突破。

Abstract: While there has been significant progress in the field of 3D avatar creation
from visual observations, modeling physically plausible dynamics of humans with
loose garments remains a challenging problem. Although a few existing works
address this problem by leveraging physical simulation, they suffer from
limited accuracy or robustness to novel animation inputs. In this work, we
present MPMAvatar, a framework for creating 3D human avatars from multi-view
videos that supports highly realistic, robust animation, as well as
photorealistic rendering from free viewpoints. For accurate and robust dynamics
modeling, our key idea is to use a Material Point Method-based simulator, which
we carefully tailor to model garments with complex deformations and contact
with the underlying body by incorporating an anisotropic constitutive model and
a novel collision handling algorithm. We combine this dynamics modeling scheme
with our canonical avatar that can be rendered using 3D Gaussian Splatting with
quasi-shadowing, enabling high-fidelity rendering for physically realistic
animations. In our experiments, we demonstrate that MPMAvatar significantly
outperforms the existing state-of-the-art physics-based avatar in terms of (1)
dynamics modeling accuracy, (2) rendering accuracy, and (3) robustness and
efficiency. Additionally, we present a novel application in which our avatar
generalizes to unseen interactions in a zero-shot manner-which was not
achievable with previous learning-based methods due to their limited simulation
generalizability. Our project page is at:
https://KAISTChangmin.github.io/MPMAvatar/

</details>


### [323] [Multimodal Feedback for Task Guidance in Augmented Reality](https://arxiv.org/abs/2510.01690)
*Hu Guo,Lily Patel,Rohan Gupt*

Main category: cs.GR

TL;DR: 该研究提出了一种结合光学 see-through 增强现实（OST-AR）和基于手腕的振动触觉反馈的多模态方法，用于改善动手任务的引导。


<details>
  <summary>Details</summary>
Motivation: 现有的OST-AR系统在处理遮挡或光照不佳的情况下可能导致视觉信息过载，影响深度感知准确性和可用性。因此，需要探索结合触觉反馈以克服这些限制。

Method: 研究人员设计了一个包含六个振动马达的定制腕带，能够提供方向和状态线索。该腕带与手持工具和OST-AR系统集成，并通过一项形成性研究和两个实验（参与者数量分别为21和27）来评估其效果。

Result: 实验结果表明，参与者在认知负荷下能够准确识别触觉模式。与仅使用视觉或仅使用触觉的条件相比，多模态反馈显著提高了空间精度和可用性。

Conclusion: 研究证明，结合OST-AR和基于手腕的振动触觉反馈的多模态方法能够有效提高动手任务中的空间感知和任务表现，克服了纯视觉引导的局限性。

Abstract: Optical see-through augmented reality (OST-AR) overlays digital targets and
annotations on the physical world, offering promising guidance for hands-on
tasks such as medical needle insertion or assembly. Recent work on OST-AR depth
perception shows that target opacity and tool visualization significantly
affect accuracy and usability; opaque targets and rendering the real instrument
reduce depth errors, whereas transparent targets and absent tools impair
performance. However, reliance on visual overlays may overload attention and
leaves little room for depth cues when occlusion or lighting hampers
perception. To address these limitations, we explore multimodal feedback that
combines OST-AR with wrist-based vibrotactile haptics. The past two years have
seen rapid advances in haptic technology. Researchers have investigated
skin-stretch and vibrotactile cues for conveying spatial information to blind
users, wearable ring actuators that support precise pinching in AR, cross-modal
audio-haptic cursors that enable eyes-free object selection, and wrist-worn
feedback for teleoperated surgery that improves force awareness at the cost of
longer task times. Studies comparing pull versus push vibrotactile metaphors
found that pull cues yield faster gesture completion and lower cognitive load.
These findings motivate revisiting OST-AR guidance with a fresh perspective on
wrist-based haptics. We design a custom wristband with six vibromotors
delivering directional and state cues, integrate it with a handheld tool and
OST-AR, and assess its impact on cue recognition and depth guidance. Through a
formative study and two experiments (N=21 and N=27), we show that participants
accurately identify haptic patterns under cognitive load and that multimodal
feedback improves spatial precision and usability compared with visual-only or
haptic-only conditions.

</details>


### [324] [MIRAGE: Patient-Specific Mixed Reality Coaching for MRI via Depth-Only Markerless Registration and Immersive VR](https://arxiv.org/abs/2510.01743)
*Daniel Brooks,Emily Carter,Hu Guo,Rajesh Nair*

Main category: cs.GR

TL;DR: MIRAGE系统利用混合现实技术为MRI患者减轻焦虑，通过VR/AR提供沉浸式指导，并实现了高精度的注册和良好的用户体验。


<details>
  <summary>Details</summary>
Motivation: MRI的噪音和狭窄空间会引起患者焦虑，导致检查失败或需要镇静，因此需要一种方法来减轻患者的焦虑。

Method: MIRAGE系统使用混合现实硬件，结合虚拟现实（VR）和标记物移除增强现实（AR）注册，为患者提供沉浸式指导。本文详细介绍了系统架构，并探讨了患者和临床医生的体验指标。

Result: 基于深度的注册达到了亚厘米级精度，设置简单。沉浸式指导环境有效降低了患者的焦虑，并获得了良好的可用性评分。

Conclusion: MIRAGE系统通过混合现实技术有效减轻了MRI患者的焦虑，并具备临床部署的可行性。

Abstract: Magnetic resonance imaging (MRI) is an indispensable diagnostic tool, yet the
confined bore and acoustic noise can evoke considerable anxiety and
claustrophobic reactions. High anxiety leads to motion artifacts, incomplete
scans and reliance on pharmacological sedation. MIRAGE (Mixed Reality Anxiety
Guidance Environment) harnesses the latest mixed reality (MR) hardware to
prepare patients for MRI through immersive virtual reality (VR) and markerless
augmented reality (AR) registration. In this paper, we extend our previous work
by providing a comprehensive review of related research, detailing the system
architecture, and exploring metrics for patient and clinician experience. We
also present considerations for clinical deployment of MR systems within
hospital workflows. Our results indicate that depth-based registration achieves
sub-centimeter accuracy with minimal setup, while the immersive coaching
environment reduces patient anxiety and yields favourable usability scores.

</details>


### [325] [ROI-GS: Interest-based Local Quality 3D Gaussian Splatting](https://arxiv.org/abs/2510.01978)
*Quoc-Anh Bui,Gilles Rougeron,Géraldine Morin,Simone Gasparini*

Main category: cs.GR

TL;DR: ROI-GS通过对象引导的相机选择、定向对象训练和全局场景中高保真度对象重构的无缝集成，来提高选定对象上的局部细节，同时保持实时性能。


<details>
  <summary>Details</summary>
Motivation: 现有3DGS方法在场景中统一分配资源，限制了感兴趣区域（ROI）的精细细节，并导致模型尺寸膨胀。

Method: ROI-GS是一种对象感知框架，通过对象引导的相机选择、定向对象训练和高保真度对象重构到全局场景的无缝集成来增强局部细节。

Result: ROI-GS在局部质量上（高达2.96 dB PSNR）有显著改善，同时将模型尺寸减小了约17%，并实现了更快的训练速度，优于现有方法。

Conclusion: ROI-GS通过优先考虑所选对象上的更高分辨率细节，同时保持实时性能，从而有效解决了在感兴趣对象上高效重建高细节3D场景的挑战。

Abstract: We tackle the challenge of efficiently reconstructing 3D scenes with high
detail on objects of interest. Existing 3D Gaussian Splatting (3DGS) methods
allocate resources uniformly across the scene, limiting fine detail to Regions
Of Interest (ROIs) and leading to inflated model size. We propose ROI-GS, an
object-aware framework that enhances local details through object-guided camera
selection, targeted Object training, and seamless integration of high-fidelity
object of interest reconstructions into the global scene. Our method
prioritizes higher resolution details on chosen objects while maintaining
real-time performance. Experiments show that ROI-GS significantly improves
local quality (up to 2.96 dB PSNR), while reducing overall model size by
$\approx 17\%$ of baseline and achieving faster training for a scene with a
single object of interest, outperforming existing methods.

</details>


### [326] [Spec-Gloss Surfels and Normal-Diffuse Priors for Relightable Glossy Objects](https://arxiv.org/abs/2510.02069)
*Georgios Kouros,Minye Wu,Tinne Tuytelaars*

Main category: cs.GR

TL;DR: 该研究提出了一种新的神经渲染框架，结合了微面BRDF和2D高斯泼溅技术，以解决高光物体重建和重新照明的难题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在分离物体形状、材质属性和光照方面存在困难，并且常使用简化的BRDF模型，限制了材质恢复和重新照明的真实感。

Method: 提出了一种将微面BRDF与镜面-光泽度参数化集成到具有延迟着色的2D高斯泼溅中的框架。该方法利用表面法线和漫反射颜色的扩散先验来指导优化，并通过环境图的粗到精优化来加速收敛并保留高动态范围的镜面反射。

Result: 在复杂、高光场景的实验表明，该方法在几何和材质重建方面达到了高质量，并且在新的光照条件下，其重新照明效果比现有的高斯泼溅方法更真实、更一致。

Conclusion: 该方法能够更精确地进行材质分解，并实现更高质量和更真实一致的重新照明效果。

Abstract: Accurate reconstruction and relighting of glossy objects remain a
longstanding challenge, as object shape, material properties, and illumination
are inherently difficult to disentangle. Existing neural rendering approaches
often rely on simplified BRDF models or parameterizations that couple diffuse
and specular components, which restricts faithful material recovery and limits
relighting fidelity. We propose a relightable framework that integrates a
microfacet BRDF with the specular-glossiness parameterization into 2D Gaussian
Splatting with deferred shading. This formulation enables more physically
consistent material decomposition, while diffusion-based priors for surface
normals and diffuse color guide early-stage optimization and mitigate
ambiguity. A coarse-to-fine optimization of the environment map accelerates
convergence and preserves high-dynamic-range specular reflections. Extensive
experiments on complex, glossy scenes demonstrate that our method achieves
high-quality geometry and material reconstruction, delivering substantially
more realistic and consistent relighting under novel illumination compared to
existing Gaussian splatting methods.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [327] [Edge GPU Aware Multiple AI Model Pipeline for Accelerated MRI Reconstruction and Analysis](https://arxiv.org/abs/2510.01730)
*Ashiyana Abdul Majeed,Mahmoud Meribout,Safa Mohammed Sali*

Main category: cs.AR

TL;DR: 该研究提出了一种硬件加速方法，用于从CT图像同时重建和诊断MRI，实现了近150 FPS的实时性能。


<details>
  <summary>Details</summary>
Motivation: 尽管AI在医学影像诊断方面取得进展，但很少有研究关注多模型系统与硬件加速的优化，而边缘设备的出现使得高效利用其加速器变得至关重要。

Method: 提出了一种硬件加速方法，利用NVIDIA嵌入式GPU的硬件引擎和调度技术，实现了从CT图像同时重建和诊断MRI。通过优化多个人工智能模型的硬件分配，减少了硬件引擎之间的时间延迟，并对生成对抗网络（GAN）模型进行了微调，使其无需回退到GPU引擎即可运行，同时保持了准确性。

Result: 该方法实现了近150 FPS的吞吐量，准确性提高了5%，并且在NVIDIA Jetson AGX Xavier和Orin设备上，通过对两个微调的GPU感知GAN模型进行硬件分配和分区，性能是原始模型的两倍。

Conclusion: 研究结果证明了在医学影像分析和诊断中并行使用硬件感知模型（hardware-aware models）的有效性。

Abstract: Advancements in AI have greatly enhanced the medical imaging process, making
it quicker to diagnose patients. However, very few have investigated the
optimization of a multi-model system with hardware acceleration. As specialized
edge devices emerge, the efficient use of their accelerators is becoming
increasingly crucial. This paper proposes a hardware-accelerated method for
simultaneous reconstruction and diagnosis of \ac{MRI} from \ac{CT} images.
Real-time performance of achieving a throughput of nearly 150 frames per second
was achieved by leveraging hardware engines available in modern NVIDIA edge
GPU, along with scheduling techniques. This includes the GPU and the \ac{DLA}
available in both Jetson AGX Xavier and Jetson AGX Orin, which were considered
in this paper. The hardware allocation of different layers of the multiple AI
models was done in such a way that the ideal time between the hardware engines
is reduced. In addition, the AI models corresponding to the \ac{GAN} model were
fine-tuned in such a way that no fallback execution into the GPU engine is
required without compromising accuracy. Indeed, the accuracy corresponding to
the fine-tuned edge GPU-aware AI models exhibited an accuracy enhancement of
5\%. A further hardware allocation of two fine-tuned GPU-aware GAN models
proves they can double the performance over the original model, leveraging
adequate partitioning on the NVIDIA Jetson AGX Xavier and Orin devices. The
results prove the effectiveness of employing hardware-aware models in parallel
for medical image analysis and diagnosis.

</details>


### [328] [Multiplier-free In-Memory Vector-Matrix Multiplication Using Distributed Arithmetic](https://arxiv.org/abs/2510.02099)
*Felix Zeller,John Reuben,Dietmar Fey*

Main category: cs.AR

TL;DR: 通过将分布式算术（DA）技术扩展到将输入向量与常数矩阵相乘，并利用移位和加法电路，我们提出了一种更节能、更低延迟的片上神经网络推理方法，消除了对耗能的ADC/DAC的需求。


<details>
  <summary>Details</summary>
Motivation: 神经网络（NN）推理中的向量-矩阵乘法（VMM）计算量大，且数据移动需求高，需要内存计算来优化。然而，现有内存计算中的ADC/DAC会消耗大量功耗和面积。

Method: 本研究将分布式算术（DA）技术（一种计算机体系结构技术）扩展到输入向量与常数矩阵的乘法。通过将权重和存储在内存中，DA利用ReRAM内存外围的移位和加法电路来实现VMM。

Result: 所提出的DA方法通过采用节能传感和细粒度流水线，实现了比传统比特切片内存VMM低4.5倍的延迟和12倍的能耗。此外，DA完全消除了对耗能的ADC的需求，而ADC是当前内存VMM实现中面积和能耗的主要来源。

Conclusion: 本研究提出的基于DA的内存VMM方法，通过利用移位和加法电路，显著提高了能效和速度，并减小了面积，为神经网络推理的内存计算提供了一种有前景的解决方案。

Abstract: Vector-Matrix Multiplication (VMM) is the fundamental and frequently required
computation in inference of Neural Networks (NN). Due to the large data
movement required during inference, VMM can benefit greatly from in-memory
computing. However, ADC/DACs required for in-memory VMM consume significant
power and area. `Distributed Arithmetic (DA)', a technique in computer
architecture prevalent in 1980s was used to achieve inner product or dot
product of two vectors without using a hard-wired multiplier when one of the
vectors is a constant. In this work, we extend the DA technique to multiply an
input vector with a constant matrix. By storing the sum of the weights in
memory, DA achieves VMM using shift-and-add circuits in the periphery of ReRAM
memory. We verify functional and also estimate non-functional properties
(latency, energy, area) by performing transistor-level simulations. Using
energy-efficient sensing and fine grained pipelining, our approach achieves 4.5
x less latency and 12 x less energy than VMM performed in memory conventionally
by bit slicing. Furthermore, DA completely eliminated the need for power-hungry
ADCs which are the main source of area and energy consumption in the current
VMM implementations in memory.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [329] [Adversarial Social Influence: Modeling Persuasion in Contested Social Networks](https://arxiv.org/abs/2510.01481)
*Renukanandan Tumu,Cristian Ioan Vasile,Victor Preciado,Rahul Mangharam*

Main category: cs.SI

TL;DR: 该论文提出了一个名为社交影响力博弈（SIG）的框架，用于模拟具有任意数量竞争玩家的社交网络中的对抗性说服。SIG提供了一个可处理且可解释的被争夺影响力的模型，该模型可以扩展到大型系统并捕捉网络的结构杠杆点。


<details>
  <summary>Details</summary>
Motivation: 提出SIG框架是为了提供一个可处理且可解释的模型，用于模拟社交网络中的对抗性说服，并能扩展到大型系统，同时捕捉网络的结构杠杆点。

Method: 每位玩家都从固定的预算中分配影响力，以引导在DeGroot动态下演变的观点。研究人员证明了由此产生的优化问题是一个差分凸规划。为了实现可扩展性，他们开发了一个迭代线性（IL）求解器，用线性规划来近似玩家目标。

Result: 在随机和典型网络的实验中，IL求解器在保持在非线性求解器7%以内的解决方案的同时，速度提高了10倍以上，并且能够扩展到大型社交网络。

Conclusion: 该论文为复杂网络中被争夺影响力的渐近分析奠定了基础。

Abstract: We present the Social Influence Game (SIG), a framework for modeling
adversarial persuasion in social networks with an arbitrary number of competing
players. Our goal is to provide a tractable and interpretable model of
contested influence that scales to large systems while capturing the structural
leverage points of networks. Each player allocates influence from a fixed
budget to steer opinions that evolve under DeGroot dynamics, and we prove that
the resulting optimization problem is a difference-of-convex program. To enable
scalability, we develop an Iterated Linear (IL) solver that approximates player
objectives with linear programs. In experiments on random and archetypical
networks, IL achieves solutions within 7% of nonlinear solvers while being over
10x faster, scaling to large social networks. This paper lays a foundation for
asymptotic analysis of contested influence in complex networks.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [330] [ENLighten: Lighten the Transformer, Enable Efficient Optical Acceleration](https://arxiv.org/abs/2510.01673)
*Hanqing Zhu,Zhican Zhou,Shupeng Ning,Xuhao Wu,Ray Chen,Yating Wan,David Pan*

Main category: cs.ET

TL;DR: 通过软硬件协同设计，提出了一种名为Lighten的压缩流程和ENLighten的光子加速器，以解决光子计算在Transformer模型中的效率瓶颈，实现了显著的能效提升。


<details>
  <summary>Details</summary>
Motivation: 现有的光子计算方法在加速AI中的线性代数运算方面存在瓶颈，特别是在处理大型Transformer模型时，能量效率会因电光转换和数据移动而降低，并且片上光子资源有限与模型规模不匹配。

Method: 提出了一种名为Lighten的压缩流程，该流程将Transformer权重矩阵分解为低秩和结构稀疏分量，以匹配光子张量核的粒度。同时，提出了一种名为ENLighten的可重构光子加速器，其具有动态自适应张量核，支持细粒度稀疏性和不活动部分的功率门控。

Result: 在ImageNet数据集上，Lighten将Vision Transformer模型压缩了50%，准确率仅下降约1%。ENLighten光子加速器实现了2.5倍的能-时积（energy-delay product）的提升，优于当前最先进的光子Transformer加速器。

Conclusion: 该软硬件协同设计框架有效地解决了光子计算在Transformer模型应用中的效率瓶颈，显著提高了能效和吞吐量。

Abstract: Photonic computing has emerged as a promising substrate for accelerating the
dense linear-algebra operations at the heart of AI, yet adoption for large
Transformer models remains in its infancy. We identify two bottlenecks: (1)
costly electro--optic conversions and data-movement overheads that erode energy
efficiency as model sizes scale; (2) a mismatch between limited on-chip
photonic resources and Transformer scale, which forces frequent reuse of
photonic tensor cores and dilutes throughput gains. To address these
challenges, we introduce a hardware--software co-design framework. First, we
propose \texttt{Lighten}, a PTC-aware compression flow that post-hoc decomposes
each Transformer weight matrix into a low-rank component plus a
structured-sparse component aligned to photonic tensor-core granularity,
without lengthy retraining. Second, we present \texttt{ENLighten}, a
reconfigurable photonic accelerator with dynamically adaptive tensor cores,
driven by broadband light redistribution, enabling fine-grained sparsity
support and full power gating of inactive parts. On ImageNet, \texttt{Lighten}
prunes a Base-scale Vision Transformer by 50\% with $\approx$1\% accuracy drop
after only 3 epochs (about 1 hour) of fine-tuning. Deployed on
\texttt{ENLighten}, it achieves a $2.5\times$ improvement in energy--delay
product over the state-of-the-art photonic Transformer accelerator.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [331] [Quantum advantages in ground state preparation, combinatorial optimization, and quantum state preparation](https://arxiv.org/abs/2510.01563)
*Taehee Ko,Sungbin Lim*

Main category: quant-ph

TL;DR: 对于任何具有反多项式间隙的量子哈密顿量，只要系统规模足够大，就可以在多项式电路深度和反多项式精度下制备其基态。此电路由多项式数量的 Pauli 旋转组成，无需辅助量子比特。进一步地，我们证明了对于足够多的量子比特数，可以用常数（多项式）数量的 Pauli 旋转以常数（反多项式）精度近似制备任何量子态。我们的理论发现揭示了在基态制备、组合优化和量子态制备等重要应用中存在指数级量子优势。


<details>
  <summary>Details</summary>
Motivation: 本文旨在研究量子哈密顿量基态的制备问题，并探索在量子态制备和组合优化等领域的应用潜力。

Method: 本文提出了一种在多项式电路深度和反多项式精度下制备具有反多项式间隙的量子哈密顿量基态的方法。该方法不使用辅助量子比特，而是利用多项式数量的 Pauli 旋转。在此基础上，进一步证明了可以用常数数量的 Pauli 旋转以常数精度近似制备任何量子态。

Result: 研究表明，对于具有反多项式间隙的量子哈密顿量，当系统规模足够大时，可以在多项式电路深度和反多项式精度下制备其基态。此外，对于足够多的量子比特，可以使用常数数量的 Pauli 旋转以常数精度近似制备任何量子态。

Conclusion: 本文的理论发现揭示了在基态制备、组合优化和量子态制备等重要应用中存在指数级量子优势。

Abstract: We show that for any quantum Hamiltonian with an inverse-polynomial gap, the
ground state can be prepared in a polynomial circuit depth to
inverse-polynomial precision, if the system size is sufficiently large. The
resulting circuit is composed of a polynomial number of Pauli rotations without
ancilla qubit. Extending this result, we prove that for sufficiently large
qubit number, any quantum state can be approximately prepared with a constant
(polynomial) number of Pauli rotations to constant (inverse-polynomial)
precision. Our theoretical findings reveal exponential quantum advantages in
the prominent applications: ground state preparation, combinatorial
optimization, and quantum state preparation.

</details>


### [332] [Velocity effects slightly mitigating the quantumness degradation of an Unruh-DeWitt detector](https://arxiv.org/abs/2510.01280)
*P. H. M. Barros,Shu-Min Wu,C. A. S. Almeida,H. A. S. Costa*

Main category: quant-ph

TL;DR: 研究了加速量子系统中由于Unruh效应导致的信息退化问题，并考虑了有限的相互作用时间。


<details>
  <summary>Details</summary>
Motivation: 研究加速量子系统中Unruh效应引起的信息退化问题，并探讨速度对该效应的影响。

Method: 通过研究单量子比特、量子干涉仪和路径可分辨干涉仪三种量子系统，推导了非相对论和超相对论速度下的量子退相干、可见度和可分辨度等。

Result: 在非相对论速度下，获得了跃迁率、量子相干性、可见度、可分辨度和互补关系等解析表达式。在超相对论速度下，Unruh效应被抑制，探测器无响应。速度效应通过与加速度的复合效应，可以缓解信息退化。

Conclusion: 非相对论的、横向的、恒定的运动可以保护高加速度下的量子性，尽管这种效应非常微弱。

Abstract: In this work, we investigate the velocity effects on information degradation
due to the Unruh effect in accelerated quantum systems (with finite interaction
time). We consider a detector moving along a spatial trajectory within a
two-dimensional plane. The quantum systems studied were: accelerated
single-qubit, quantum interferometric circuit, and which-path
distinguishability circuit. Thus, for non-relativistic velocity regime, we
obtained analytical expressions such as transition rates, quantum coherence,
visibility, distinguishability, and the complementarity relation. On the other
hand, for the ultra-relativistic velocity regime, we saw that the Unruh effect
is suppressed and therefore the detector does not respond in this case. Our
findings revealed that velocity effects imply mitigation of information
degradation, this interesting behaviors happen because of the composite effect
of both velocity and acceleration. The results obtained show that the addition
of the non-relativistic, transverse and constant motion of an accelerated
detector can play a protective role in quantumness in systems at high
accelerations, although the effects are very small.

</details>


### [333] [Chiral quantum state circulation from photon lattice topology](https://arxiv.org/abs/2510.01306)
*Souvik Bandyopadhyay,Anushya Chandran,Philip JD Crowley*

Main category: quant-ph

TL;DR: 通过耦合三个腔和一个量子比特，实现了量子态的定向传输，该传输具有拓扑保护的特性。


<details>
  <summary>Details</summary>
Motivation: 量子态的定向传输（循环）对于量子计算至关重要，例如用于状态制备和隔离。

Method: 提出了一种包含三个腔和一个量子比特的腔量子电动力学（Cavity-QED）结构。利用拓扑保护的 the associated photon lattice chiral boundary states 来实现量子态的定向传输，并通过 Floquet 协议来设计所需的哈密顿量。

Result: 该结构可以实现任意光子态从腔1到腔2的定向传输，然后传输到腔3再回到腔1。传输周期与总光子数成比例，且该循环对于扰动具有鲁棒性。

Conclusion: 该研究提出的腔量子电动力学结构可以实现鲁棒的量子态循环，并为近期的超导量子比特设备提供了实现方案。

Abstract: Chiral quantum state circulation is the unidirectional transfer of a quantum
state from one subsystem to the next. It is essential to the working of a
quantum computer; for instance, for state preparation and isolation. We propose
a cavity-QED architecture consisting of three cavities coupled to a qubit, in
which \emph{any} photonic state of cavity 1 with sufficiently many photons
circulates to cavity 2 after a fixed time interval, and then to cavity 3 and
back to 1. Cavity-state circulation arises from topologically protected chiral
boundary states in the associated photon lattice and is thus robust to
perturbation. We compute the circulation period in the semi-classical limit,
demonstrate that circulation persists for time-scales diverging with the total
photon number, and provide a Floquet protocol to engineer the desired
Hamiltonian. Superconducting qubits offer an ideal platform to build and test
these devices in the near term.

</details>


### [334] [A robust phase of continuous transversal gates in quantum stabilizer codes](https://arxiv.org/abs/2510.01319)
*Eric Huang,Pierre-Gabriel Rozon,Arpit Dua,Sarang Gopalakrishnan,Michael J. Gullans*

Main category: quant-ph

TL;DR: 表面码中存在一个可调谐的逻辑操作阶段，该阶段可抵抗退相干错误，并且错误率与旋转角度成指数关系。


<details>
  <summary>Details</summary>
Motivation: 需要一种容错的通用量子计算方法，而魔态蒸馏等协议需要测量和后选择。

Method: 在表面码中寻找一个由横向操作和解码实现的、可抵抗退相干错误并且错误率与旋转角度成指数关系的新阶段。

Result: 发现了一个新的阶段，其中逻辑操作的保真度随代码距离呈指数级衰减，这为实现连续小角度旋转的容错协议提供了基础。

Conclusion: 提出的连续小角度旋转容错协议可以降低量子模拟等需要大量小角度旋转的应用的开销。

Abstract: A quantum error correcting code protects encoded logical information against
errors. Transversal gates are a naturally fault-tolerant way to manipulate
logical qubits but cannot be universal themselves. Protocols such as magic
state distillation are needed to achieve universality via measurements and
postselection. A phase is a region of parameter space with smoothly varying
large-scale statistical properties except at its boundaries. Here, we find a
phase of continuously tunable logical unitaries for the surface code
implemented by transversal operations and decoding that is robust against
dephasing errors. The logical unitaries in this phase have an infidelity that
is exponentially suppressed in the code distance compared to their rotation
angles. We exploit this to design a simple fault-tolerant protocol for
continuous-angle logical rotations. This lowers the overhead for applications
requiring many small-angle rotations such as quantum simulation.

</details>


### [335] [A quantum analogue of convex optimization](https://arxiv.org/abs/2510.02151)
*Eunou Lee*

Main category: quant-ph

TL;DR: 该论文提出了一种计算具有凸势的薛定谔算子最小特征值的量子算法（FGA），并将其应用于解决多维凸鼓的最低频率问题。


<details>
  <summary>Details</summary>
Motivation: 介绍了一种新的量子优化问题，即计算具有凸势的薛定谔算子 $h = -floor + V$ 的最小特征值。

Method: 提出了一种名为“基本间隙算法”（FGA）的量子算法，该算法利用了绝热演化子程序，并通过新颖的技术分析了低能空间。

Result: 该算法能在多项式时间内计算出 $h$ 的最小特征值，误差为 $\epsilon$，并可应用于解决多维凸鼓的最低频率问题。

Conclusion: FGA 是第一个已知的能在多项式时间内找到多维凸鼓最低频率的算法。

Abstract: Convex optimization is the powerhouse behind the theory and practice of
optimization. We introduce a quantum analogue of unconstrained convex
optimization: computing the minimum eigenvalue of a Schr\"odinger operator $h =
-\Delta + V $ with convex potential $V:\mathbb R^n \rightarrow \mathbb R_{\ge
0}$ such that $V(x)\rightarrow\infty $ as $\|x\|\rightarrow\infty$. For this
problem, we present an efficient quantum algorithm, called the Fundamental Gap
Algorithm (FGA), that computes the minimum eigenvalue of $h$ up to error
$\epsilon$ in polynomial time in $n$, $1/\epsilon$, and parameters that depend
on $V$. Adiabatic evolution of the ground state is used as a key subroutine,
which we analyze with novel techniques that allow us to focus on the low-energy
space. We apply the FGA to give the first known polynomial-time algorithm for
finding the lowest frequency of an $n$-dimensional convex drum, or
mathematically, the minimum eigenvalue of the Dirichlet Laplacian on an
$n$-dimensional region that is defined by $m$ linear constraints in polynomial
time in $n$, $m$, $1/\epsilon$ and the radius $R$ of a ball encompassing the
region.

</details>


### [336] [Derandomised tensor product gap amplification for quantum Hamiltonians](https://arxiv.org/abs/2510.01333)
*Thiago Bergamaschi,Tony Metger,Thomas Vidick,Tina Zhang*

Main category: quant-ph

TL;DR: 该工作提出了一种新的量子间隙放大程序，用于处理汉密尔顿量，通过在扩展图上使用随机游走来 derandomise 张量积放大，并利用量子 de Finetti 定理的新技术进行分析。


<details>
  <summary>Details</summary>
Motivation: 区分高低能量汉密尔顿量，即使在高低能量间隙很大（常数）的情况下，这也是量子 PCP 猜想的一个问题。

Method: 利用扩展图上的随机游走来 derandomise 张量积放大。

Result: 提出了一种新的量子间隙放大程序。

Conclusion: 一种新的量子间隙放大程序被引入，其分析依赖于量子 de Finetti 定理的新技术。

Abstract: The quantum PCP conjecture asks whether it is QMA-hard to distinguish between
high- and low-energy Hamiltonians even when the gap between "high" and "low"
energy is large (constant). A natural proof strategy is gap amplification:
start from the fact that high- and low-energy Hamiltonians are hard to
distinguish if the gap is small (inverse polynomial) and amplify the
Hamiltonians to increase the energy gap while preserving hardness. Such a gap
amplification procedure is at the heart of Dinur's proof of the classical PCP
theorem. In this work, following Dinur's model, we introduce a new quantum gap
amplification procedure for Hamiltonians which uses random walks on expander
graphs to derandomise (subsample the terms of) the tensor product amplification
of a Hamiltonian. Curiously, our analysis relies on a new technique inspired by
quantum de Finetti theorems, which have previously been used to rule out
certain approaches to the quantum PCP conjecture.

</details>


### [337] [Quantum Optimization with Classical Chaos](https://arxiv.org/abs/2510.01334)
*Malick A. Gaye,Omar Shehab,Paraj Titum,Gregory Quiroz*

Main category: quant-ph

TL;DR: QAOA参数一种新方法，比标准方法性能更好，尤其适用于深度电路。


<details>
  <summary>Details</summary>
Motivation: QAOA需要深度电路，对经典变分参数优化要求高，因此需要新的参数化方法。

Method: 使用基于经典混沌递归映射的参数化方案，通过数值方法研究硬最大可满足性问题。

Result: 混沌映射在有限的经典优化迭代次数和短深度电路上能匹配标准QAOA的性能。混合方法可以提升QAOA性能，尤其是在深度电路上。

Conclusion: 提供了一个新的视角，引入了一个通用的框架，用于指定高性能的、基于动力学映射的QAOA参数化。

Abstract: The Quantum Approximate Optimization Algorithm (QAOA) is a powerful tool in
solving various combinatorial problems such as Maximum Satisfiability and
Maximum Cut. Hard computational problems, however, require deep circuits that
place high demands on classical variational parameter optimization. Ultimately,
this has necessitated investigations into alternative methods for effective
QAOA parameterizations. Here, we study a parameterization scheme based on
classical chaotic recursive mapping, which enables significant reductions in
the scaling of the variational parameter space. Through numerical
investigations of hard Maximum Satisfiability problems, we demonstrate that the
chaotic mapping can effectively match the performance of standard QAOA when
subject to a limited number of classical optimization iterations and
short-depth circuits. Insight into this behavior is elucidated through the lens
of classical dynamical systems and used to inform hybridized schemes that
leverage both standard and chaotic parameterizations. It is shown that these
hybridized approaches can boost QAOA performance beyond that of the standard
approach alone, especially for deep circuits. Through this study, we provide a
new perspective that introduces a generalized framework for specifying
performant, dynamical-map-based QAOA parameterizations.

</details>


### [338] [Non-stabilizerness in quantum-enhanced metrological protocols](https://arxiv.org/abs/2510.01380)
*Tanausú Hernández-Yanes,Piotr Sierant,Jakub Zakrzewski,Marcin Płodzień*

Main category: quant-ph

TL;DR: 对于置换对称态，SRE 仅取决于固定数量的集体自旋算子的期望值，这为分析自旋压缩协议提供了紧凑的描述。在单轴扭曲（OAT）下，最佳压缩伴随着 SRE 随系统大小的对数发散。继续进行 OAT 时间演化会产生具有多体贝尔关联的“kitten”态，其 SRE 随贝尔关联强度增加而减小。


<details>
  <summary>Details</summary>
Motivation: 非稳定度（“魔术”）是制备量子态所必需的、真正量子（超出 Clifford）的操作的特征，并且可以通过稳定器 Rényi 熵（SRE）来衡量。对于置换对称态，研究 SRE 如何随系统大小和贝尔关联强度变化，以及它与量子计量学的关系。

Method: 研究置换对称态下的 SRE，并利用其与集体自旋算子期望值的关系来分析自旋压缩协议。特别地，研究了单轴扭曲（OAT）协议下的 SRE 行为，包括其随系统大小的变化以及与“kitten”态的关联。

Result: 对于置换对称态，SRE 仅取决于固定数量的集体自旋算子的期望值。在 OAT 协议下，最佳压缩伴随着 SRE 随系统大小的对数发散。继续演化会产生“kitten”态，其 SRE 随贝尔关联强度增加而减小，并且不依赖于系统大小。

Conclusion: 非稳定度、多体关联和量子计量学之间存在联系。研究结果提供了一种在实验中量化非稳定度以实现精确传感的实用方法。

Abstract: Non-stabilizerness (colloquially "magic") characterizes genuinely quantum
(beyond-Clifford) operations necessary for preparation of quantum states, and
can be measured by stabilizer R\'enyi entropy (SRE). For permutationally
symmetric states, we show that the SRE depends, for sufficiently large systems,
only on a constant number of expectation values of collective spin operators.
This compact description is leveraged for analysis of spin-squeezing protocols,
which inherently generate non-stabilizerness. Under one-axis twisting (OAT),
the generation of optimal squeezing is accompanied by a logarithmic divergence
of SRE with system system size. Continued time evolution under OAT produces
metrologically useful "kitten" states-superpositions of rotated GHZ states-that
feature many-body Bell correlations but exhibit a smaller,
system-size-independent SRE that decreases with increasing Bell-correlation
strength. Our results reveal connections between non-stabilizerness,
multipartite correlations, and quantum metrology, and provide a practical route
to quantify non-stabilizerness in experiments for precision sensing.

</details>


### [339] [Quantum Signatures of Strange Attractors](https://arxiv.org/abs/2510.01416)
*Bence Dárdai,Gábor Vattay*

Main category: quant-ph

TL;DR: 该研究在量子领域中首次可视化了量子奇怪吸引子，并探讨了耗散对量子混沌系统的影响。


<details>
  <summary>Details</summary>
Motivation: 研究如何将经典力学中耗散驱动系统表现出的复杂分形动力学（奇怪吸引子）在量子领域中体现。

Method: 利用Caldirola-Kanai (CK)框架和Husimi分布来研究量子Duffing振子，将耗散直接纳入含时哈密顿量中，并通过计算时序关联函数 (OTOC) 来验证模型。.

Result: 首次在量子Duffing振子模型中可视化了量子奇怪吸引子，观察到高斯波包在混沌动力学和能量损失作用下被拉伸、折叠并最终定位在类似经典吸引子的结构上。研究发现，量子奇怪吸引子因不确定性原理而具有平滑性。OTOC分析表明，更强的耗散能更好地反映经典李雅普诺夫指数的指数增长，证实了模型的半经典行为。

Conclusion: 该研究为开放的混沌量子系统提供了一个有说服力的几何视角，并揭示了量子-经典过渡的新见解。

Abstract: In classical mechanics, driven systems with dissipation often exhibit
complex, fractal dynamics known as strange attractors. This paper addresses the
fundamental question of how such structures manifest in the quantum realm. We
investigate the quantum Duffing oscillator, a paradigmatic chaotic system,
using the Caldirola-Kanai (CK) framework, where dissipation is integrated
directly into a time-dependent Hamiltonian. By employing the Husimi
distribution to represent the quantum state in phase space, we present the
first visualization of a quantum strange attractor within this model. Our
simulations demonstrate how an initially simple Gaussian wave packet is
stretched, folded, and sculpted by the interplay of chaotic dynamics and energy
loss, causing it to localize onto a structure that beautifully mirrors the
classical attractor. This quantum "photograph" is inherently smoothed, blurring
the infinitely fine fractal details of its classical counterpart as a direct
consequence of the uncertainty principle. We supplement this analysis by
examining the out-of-time-ordered correlator (OTOC), which shows that stronger
dissipation clarifies the exponential growth associated with the classical
Lyapunov exponent, thereby confirming the model's semiclassical behavior. This
work offers a compelling geometric perspective on open chaotic quantum systems
and sheds new light on the quantum-classical transition.

</details>


### [340] [Exponential Quantum Advantage for Message Complexity in Distributed Algorithms](https://arxiv.org/abs/2510.01657)
*François Le Gall,Maël Luce,Joseph Marchand,Mathieu Roget*

Main category: quant-ph

TL;DR: 本研究展示了量子分布式算法在路由信息任务上相比经典算法具有指数级优势，其消息复杂度远低于经典算法。


<details>
  <summary>Details</summary>
Motivation: 研究量子分布式算法相对于经典算法的消息复杂度优势，特别是在信息路由任务上。

Method: 提出了一种基于量子行走的量子分布式算法，并利用了已有的关于“焊接树”的量子行走实现。经典下界通过将查询复杂度下界“提升”到消息复杂度来获得。

Result: 证明了对于“焊接树”网络，存在一种量子分布式算法，其消息复杂度相比任何经典算法具有指数级优势。

Conclusion: 量子分布式算法在信息路由任务上，特别是在“焊接树”这类网络结构中，能够实现比经典算法更优越的消息复杂度。

Abstract: We investigate how much quantum distributed algorithms can outperform
classical distributed algorithms with respect to the message complexity (the
overall amount of communication used by the algorithm). Recently, Dufoulon,
Magniez and Pandurangan (PODC 2025) have shown a polynomial quantum advantage
for several tasks such as leader election and agreement. In this paper, we show
an exponential quantum advantage for a fundamental task: routing information
between two specified nodes of a network. We prove that for the family of
``welded trees" introduced in the seminal work by Childs, Cleve, Deotto, Farhi,
Gutmann and Spielman (STOC 2003), there exists a quantum distributed algorithm
that transfers messages from the entrance of the graph to the exit with message
complexity exponentially smaller than any classical algorithm. Our quantum
algorithm is based on the recent "succinct" implementation of quantum walks
over the welded trees by Li, Li and Luo (SODA 2024). Our classical lower bound
is obtained by ``lifting'' the lower bound from Childs, Cleve, Deotto, Farhi,
Gutmann and Spielman (STOC 2003) from query complexity to message complexity.

</details>


### [341] [Optimal Quantum Information Transmission Under a Continuous-Variable Erasure Channel](https://arxiv.org/abs/2510.01424)
*Adam Taylor,Michael Hanks,Hyukjoon Kwon,M. S. Kim*

Main category: quant-ph

TL;DR: 本工作推导了具有能量约束的连续变量玻色子擦除通道的量子容量和纠缠辅助量子容量，并构建了渐近最优的随机码。


<details>
  <summary>Details</summary>
Motivation: 评估连续变量玻色子量子通道的量子容量以及寻找实现最优信息传输率的最优码通常具有挑战性。

Method: 推导了连续变量玻色子擦除通道在能量约束下的量子容量和纠缠辅助量子容量，并构建了基于在编码态的典型子空间内进行信息混淆的随机码。

Result: 随机码被证明是渐近最优的，但存在一个常数间隔。使用随机编码方案设计的玻色子海森堡-普雷斯基尔协议变体发现，信息恢复取决于输入和输出模式的比例，这与仅需要固定数量的额外输出量子比特的传统离散变量场景不同。

Conclusion: 本工作在具有能量约束的连续变量玻色子擦除通道的量子容量和编码方面取得了进展，并为信息恢复提出了新的见解。

Abstract: Quantum capacity gives the fundamental limit of information transmission
through a channel. However, evaluating the quantum capacities of a
continuous-variable bosonic quantum channel, as well as finding an optimal code
to achieve the optimal information transmission rate, is in general
challenging. In this work, we derive the quantum capacity and
entanglement-assisted quantum capacity of the bosonic continuous-variable
erasure channel when subject to energy constraints. We then construct random
codes based on scrambling information within the typical subspace of the
encoding state and prove that these codes are asymptotically optimal up to a
constant gap. Finally, using our random coding scheme we design a bosonic
variation of the Hayden-Preskill protocol and find that information recovery
depends on the ratio between the input and output modes. This is in contrast
with the conventional discrete-variable scenario which requires only a fixed
number of additional output qudits.

</details>


### [342] [Visualizing the state space of quantum trits, quadits, and pairs of qubits via toral geometry](https://arxiv.org/abs/2510.01455)
*Steven Bleiler,Ali Al-Bayaty,Shanyan Chen,Marek Perkowski*

Main category: quant-ph

TL;DR: toric variety structures applied to quantum computation for various radices


<details>
  <summary>Details</summary>
Motivation: The motivation is to explore new applications of toric variety structures in the field of quantum computation, specifically for different radices.

Method: The method involves proposing and investigating new uses of toric variety structures within the context of quantum computation.

Result: The proposed new uses of toric variety structures in quantum computation for various radices.

Conclusion: The paper suggests that toric variety structures can be effectively utilized in the study of quantum computation across different radices.

Abstract: We propose some new uses of toric variety structures in the study of quantum
computation for various radices.

</details>


### [343] [Isogeny Graphs in Superposition and Quantum Onion Routing](https://arxiv.org/abs/2510.01464)
*Eleni Agathocleous,Tobias Hartung,Karl Jansen,Lukas Mansour*

Main category: quant-ph

TL;DR: 提出了一种基于对称加密的量子洋葱路由（QOR）方案，使用复乘理论中的阿贝尔理想类群作用来实例化每一层，并提出了一种新颖的“非局部”密钥交换方法，以应对量子威胁。


<details>
  <summary>Details</summary>
Motivation: 现有的量子洋葱路由方法面临对称加密的挑战，而经典方法依赖公钥加密。需要一种基于对称加密的量子洋葱路由方案。

Method: 提出了一种基于复乘理论阿贝尔理想类群作用的量子洋葱路由（QOR）方案。通过邻居间的Diffie-Hellman密钥交换建立会话密钥。提出了一种新颖的“非局部”密钥交换方法。将该方案与同源图和它们的Bose-Mesner代数联系起来，并提供了两种实现途径：通用量子预言机和连续时间量子行走。

Result: 该方案在量子计算机的攻击下仍然是困难的，为当前抗量子密码奠定安全基础。通过Qiskit示例说明了QOR的机制。

Conclusion: 提出了一种新颖的量子洋葱路由（QOR）方案，该方案基于对称加密，并能抵抗量子攻击。该方案的安全性基于困难的数学问题，并提供了两种潜在的实现途径。

Abstract: Onion routing provides anonymity by layering encryption so that no relay can
link sender to destination. A quantum analogue faces a core obstacle: layered
quantum encryption generally requires symmetric encryption schemes, whereas
classically one would rely on public-key encryption. We propose a
symmetric-encryption-based quantum onion routing (QOR) scheme by instantiating
each layer with the abelian ideal class group action from the Theory of Complex
Multiplication. Session keys are established locally via a Diffie-Hellman key
exchange between neighbors in the chain of communication. Furthermore, we
propose a novel ''non-local'' key exchange between the sender and receiver. The
underlying problem remains hard even for quantum adversaries and underpins the
security of current post-quantum schemes. We connect our construction to
isogeny graphs and their association schemes, using the Bose-Mesner algebra to
formalize commutativity and guide implementation. We give two implementation
paths: (i) a universal quantum oracle evaluating the class group action with
polynomially many quantum resources, and (ii) an intrinsically quantum approach
via continuous-time quantum walks (CTQWs), outlined here and developed in a
companion paper. A small Qiskit example illustrates the mechanics (by design,
not the efficiency) of the QOR.

</details>


### [344] [Robust Rydberg facilitation via rapid adiabatic passage](https://arxiv.org/abs/2510.01504)
*Xinghan Wang,Yupeng Wang,Qi-Yu Liang*

Main category: quant-ph

TL;DR: 通过快速绝热扫描实现鲁棒的里德堡反阻塞效应，可用于高增益稀有事件探测。


<details>
  <summary>Details</summary>
Motivation: 里德堡反阻塞效应在量子信息处理和传感中有重要应用，但对位置无序和参数不完美敏感，这是一个主要障碍。

Method: 通过绝热地扫描相互作用引起的共振位移，实现对真实水平的无序和参数变化的免疫。

Result: 提出了一种鲁棒的里德堡反阻塞实现方法，该方法对无序和参数不敏感，并自然产生一维和二维阵列中的雪崩激发增长，具有高增益和极低的背景。

Conclusion: 该方法为鲁棒的里德堡反阻塞动力学提供了实际途径，为未来的实验和技术应用铺平了道路。

Abstract: We propose and analyze a robust implementation of Rydberg antiblockade based
on rapid adiabatic passage. Although Rydberg antiblockade offers key
opportunities in quantum information processing and sensing, its sensitivity to
position disorder and parameter imperfections has posed a central roadblock. By
adiabatically sweeping across the interaction-shifted resonance, our approach
is unaffected by realistic levels of disorder and parameter variations. As a
straightforward application case, we show that it naturally gives rise to
avalanche excitation growth in both one- and two-dimensional arrays. This
avalanche process yields high gain with exceptionally low background, making it
promising for rare-event detection. These results establish a practical route
to robust Rydberg antiblockade dynamics, paving the way for future experimental
and technological applications.

</details>


### [345] [Variational approach to open quantum systems with long-range competing interactions](https://arxiv.org/abs/2510.01543)
*Dawid A. Hryniuk,Marzena H. Szymańska*

Main category: quant-ph

TL;DR: 开发了一种结合矩阵计算和时间相关变分蒙特卡洛的算法，用于模拟具有长程相互作用的开放量子多体系统，并在最多 200 个格点的系统上展示了其有效性，揭示了空间调制磁序的出现。


<details>
  <summary>Details</summary>
Motivation: 现有计算方法在模拟具有复杂长程相互作用的开放量子多体系统方面存在不足。

Method: 结合使用矩阵算符和时间相关的变分蒙特卡洛方法，用于模拟一维和二维耗散量子格点系统。

Result: 在最多包含 200 个格点的 $\frac{1}{2}$自旋格点系统上，模拟了非平衡动力学和稳态，揭示了在远离平衡状态时空间调制磁序的出现。

Conclusion: 所提出的算法为理解具有长程相互作用的可实现量子系统的复杂非平衡性质提供了有前景的方法。

Abstract: Competition between short- and long-range interactions underpins many
emergent phenomena in nature. Despite rapid progress in their experimental
control, computational methods capable of accurately simulating open quantum
many-body systems with complex long-ranged interactions at scale remain scarce.
Here, we address this limitation by introducing an efficient and scalable
approach to dissipative quantum lattices in one and two dimensions, combining
matrix product operators and time-dependent variational Monte Carlo. We
showcase the versatility, effectiveness, and unique methodological advantages
of our algorithm by simulating the non-equilibrium dynamics and steady states
of spin-$\frac{1}{2}$ lattices with competing algebraically-decaying
interactions for as many as $N=200$ sites, revealing the emergence of
spatially-modulated magnetic order far from equilibrium. This approach offers
promising prospects for advancing our understanding of the complex
non-equilibrium properties of a diverse variety of experimentally-realizable
quantum systems with long-ranged interactions, including Rydberg atoms,
ultracold dipolar molecules, and trapped ions.

</details>


### [346] [Design and Characterization of a Cryogenic Vacuum Chamber for Ion Trapping Experiments](https://arxiv.org/abs/2510.01557)
*D. M. Hartsell,J. M. Gray,C. M. Shappert,N. L. Gostin,R. A. McGill,H. N. Tinkey,C. R. Clark,K. R. Brown*

Main category: quant-ph

TL;DR: 该论文设计并展示了一个低温真空室，该室集成了机械隔振、高数值孔径的真空内成像物镜、真空内磁屏蔽以及用于全局射频操控离子陷阱的天线。实验结果显示，接近4K的冷屏蔽通过隔热支撑与下方的光学平台机械耦合，其均方根振动小于7.61(4) nm。。


<details>
  <summary>Details</summary>
Motivation: 论文旨在设计一个集成多种功能的低温真空室，以支持高精度的离子操控和探测实验，具体包括隔振、高分辨率成像、磁屏蔽和射频操控。

Method: 论文设计并构建了一个低温真空室，集成了隔振支撑、高数值孔径的真空内成像物镜、磁屏蔽层以及射频天线。通过测量振动、探测效率、状态检测保真度、相干时间和使用动力学解耦技术延长相干时间来表征其性能。

Result: 该低温真空室实现了小于7.61(4) nm的均方根振动。使用真空内物镜，探测397 nm光子的效率达到1.77%，单次探测状态保真度为99.9963(4)%。磁屏蔽效果良好，基态量子比特的相干时间达到24(2) ms，单次自旋回波脉冲可延长至0.25(1) s。XY4和XY32动态解耦序列可将相干时间分别延长至0.72(2) s和0.81(3) s。

Conclusion: 所提出的低温真空室成功集成了隔振、高分辨率成像、磁屏蔽和射频操控等关键功能，显著提升了离子探测效率和相干时间，为实现高保真度的离子操控和量子信息处理奠定了基础。

Abstract: We present the design and characterization of a cryogenic vacuum chamber
incorporating mechanical isolation from vibrations, a high numerical-aperture
in-vacuum imaging objective, in-vacuum magnetic shielding, and an antenna for
global radio-frequency manipulation of trapped ions. The cold shield near 4 K
is mechanically referenced to an underlying optical table via thermally
insulating supports and exhibits root-mean-square vibrations less than 7.61(4)
nm. Using the in-vacuum objective, we can detect 397 nm photons from a trapped
$^{40}\mathrm{Ca}^{+}$ ion with 1.77% efficiency and achieve 99.9963(4)%
single-shot state-detection fidelity in 50 $\mu$s. To characterize the efficacy
of the magnetic shields, we perform Ramsey experiments on the ground state
qubit and obtain a coherence time of 24(2) ms, which extends to 0.25(1) s with
a single spin-echo pulse. XY4 and XY32 dynamical decoupling sequences driven
via the radio-frequency antenna extend the coherence to 0.72(2) s and 0.81(3)
s, respectively.

</details>


### [347] [Directionality and quantum backfire in continuous-time quantum walks from delocalized states: Exact results](https://arxiv.org/abs/2510.01584)
*Jefferson J. Ximenes,Marcelo A. Pires,José M. Villas-Bôas*

Main category: quant-ph

TL;DR: 连续时间量子行走存在三种新现象：定向量子输运、量子回火效应和生存概率的精确解析。通过调整初始状态的离域性和哈密顿量相位，可以实现对量子输运的控制。


<details>
  <summary>Details</summary>
Motivation: 研究新的初始状态如何影响连续时间量子行走动力学，并探索控制量子输运的可能性。

Method: 推导了具有可调离域性的新类初始状态的连续时间量子行走解析结果，并利用具有复杂跳跃振幅的哈密顿量来描述动力学。

Result: （1）从完全无偏的初始条件中出现了定向量子输运；（2）量子回火效应：初始离域性越大，短期扩散越大，但长期扩散反而越小；（3）生存概率的精确解析，显示向增强的 t^-3 衰减的过渡是一种精细调整效应。

Conclusion: 该工作为通过中间初始离域性和哈密顿量相位的相互作用来控制量子输运提供了全面的框架。

Abstract: We derive analytical results for continuous-time quantum walks from a new
class of initial states with tunable delocalization. The dynamics are governed
by a Hamiltonian with complex hopping amplitudes. We provide closed-form
equations for key observables, revealing three notable findings: (1) the
emergence of directed quantum transport from completely unbiased initial
conditions; (2) a quantum backfire effect, where greater initial delocalization
enhances short-time spreading but counterintuitively induces a comparatively
smaller long-time spreading after a crossing time $t_{\mathrm{cross}}$; and (3)
an exact characterization of survival probability, showing that the transition
to an enhanced $t^{-3}$ decay is a fine-tuned effect. Our work establishes a
comprehensive framework for controlling quantum transport through the interplay
between intermediate initial delocalization and Hamiltonian phase.

</details>


### [348] [Limitations of strong coupling in non-Markovian quantum thermometry](https://arxiv.org/abs/2510.01596)
*Qing-Shou Tan,Yang Liu,Xulin Liu,Hao Chen,Xing Xiao,Wei Wu*

Main category: quant-ph

TL;DR: 使用HEOM和量子增强粒子群优化，在非马尔可夫环境中研究单量子比特探针的热力学性能，揭示了强耦合不一定能提高热力学性能，并提出了优化方案。


<details>
  <summary>Details</summary>
Motivation: 研究在非马尔可夫环境中单量子比特探针的量子热力学性能，以克服传统方法的局限性。

Method: 采用数值上精确的层次方程（HEOM）来克服玻恩-马尔可夫近似的限制，并通过系统分析量子信噪比（QSNR）的动力学和稳态行为来识别关键发现。开发了一个整合HEOM和量子增强粒子群优化的混合计算框架，以优化不同耦合强度下的性能。

Result: 发现在非平衡动力学温度测量中，弱耦合通常能提供最佳的QSNR；在稳态情况下，强耦合仅在极低温下能提高灵敏度，而弱耦合在适中低温下能显著提高精度。

Conclusion: 研究结果揭示了量子热力学性能的基本限制和机遇，并为在现实开放量子系统中设计高性能量子温度计提供了实用的策略。

Abstract: We investigate quantum thermometry using a single-qubit probe embedded in a
non-Markovian environment, employing the numerically exact hierarchical
equations of motion (HEOM) to overcome the limitations of Born-Markov
approximations. Through a systematic analysis of the dynamical and steady-state
behavior of the quantum signal-to-noise ratio (QSNR) for temperature
estimation, we identify several key findings that challenge the conventional
expectation that strong coupling necessarily enhances thermometric performance.
In non-equilibrium dynamical thermometry, weak system-environment coupling
generally yields the optimal QSNR, whereas in the steady-state regime, strong
coupling enhances sensitivity only in the ultra-low-temperature limit, while
weak coupling significantly improves precision at moderately low temperatures.
To optimize performance across coupling regimes, we develop a hybrid
computational framework that integrates HEOM with quantum-enhanced particle
swarm optimization, enabling precise quantum dynamical control under varying
coupling strengths. Our results reveal fundamental constraints and
opportunities in quantum thermometry, offering practical strategies for the
design of high-performance quantum thermometers operating in realistic open
quantum systems.

</details>


### [349] [Higher moment theory and learnability of bosonic states](https://arxiv.org/abs/2510.01610)
*Joseph T. Iosue,Yu-Xin Wang,Ishaun Datta,Soumik Ghosh,Changhun Oh,Bill Fefferman,Alexey V. Gorshkov*

Main category: quant-ph

TL;DR: 该算法能高效学习任意高斯酉变换作用下的玻色子Fock态，解决了BosonSampling问题的一个开放性问题。


<details>
  <summary>Details</summary>
Motivation: 解决Aaronson和Grewal提出的关于学习高斯变换下玻色子Fock态的开放性问题。

Method: 提出一个样本和时间效率都很高的算法来学习任意高斯酉变换作用下的玻色子Fock态，并研究了超越高斯态的态类的层级结构，利用高阶矩寻找高斯酉变换下的不变谱。

Result: 该算法能高效学习Fock态，并为研究超越高斯态提供了方法。找到了高斯酉变换下的全谱不变量，为判断两个态是否可能由高斯酉变换联系起来提供了必要条件。

Conclusion: 算法能高效学习高斯变换下的玻色子Fock态，并为理解更广泛的量子态和变换提供了理论工具。

Abstract: We present a sample- and time-efficient algorithm to learn any bosonic Fock
state acted upon by an arbitrary Gaussian unitary. As a special case, this
algorithm efficiently learns states produced in Fock state BosonSampling, thus
resolving an open question put forth by Aaronson and Grewal (Aaronson, Grewal
2023). We further study a hierarchy of classes of states beyond Gaussian states
that are specified by a finite number of their higher moments. Using the higher
moments, we find a full spectrum of invariants under Gaussian unitaries,
thereby providing necessary conditions for two states to be related by an
arbitrary (including active, e.g. beyond linear optics) Gaussian unitary.

</details>


### [350] [Entanglement distribution via satellite: an evaluation of competing protocols assuming realistic free-space optical channels](https://arxiv.org/abs/2510.01633)
*Nicholas Zaunders,Timothy C. Ralph*

Main category: quant-ph

TL;DR: 利用卫星平台进行纠缠分发，可实现高比特率、高保真度的远距离量子通信。


<details>
  <summary>Details</summary>
Motivation: 未来的量子网络需要高效率、高保真度的远距离纠缠分发能力。基于卫星的自由空间光通信相比光纤网络具有成本低、损耗小、覆盖范围广（可达大陆尺度）等优势，是实现量子网络的理想选择。

Method: 本文研究了两种量子网络拓扑（星地间和地星地间）和两种纠缠分发方案（卫星作为中继和卫星作为纠缠源）。计算了在不同拓扑和方案下，结合或不结合概率性无噪声线性量子放大（NLA）的单轨道离散变量（DV）和连续变量（CV）资源的可蒸馏纠缠分发率上限。考虑了大气信道的湍流和光学特性。

Result: 对于三卫星网络，最优策略是采用分布式NLA方案（CV或DV）。对于地星地网络，最优策略是通过中心卫星分发DV资源。

Conclusion: 研究结果为未来量子网络的实际部署提供了理论指导，指明了在不同网络拓扑和纠缠分发方案下的最优策略。

Abstract: A key technical requirement of any future quantum network is the ability to
distribute quantum-entangled resources between two spatially separated points
at a high rate and high fidelity. Entanglement distribution protocols based on
satellite platforms, which transmit and receive quantum resources directly via
free-space optical propagation, are therefore excellent candidates for quantum
networking, since the geometry and loss characteristics of satellite networks
feasibly allow for up to continental-scale ($\sim10^3$ km) over-the-horizon
communication without the infrastructure, cost, or losses associated with
equivalent fibre-optic networks. In this work, we explore two network
topologies commonly associated with quantum networks - entanglement
distribution between two satellites in low-Earth orbit mediated by a third
satellite and entanglement distribution between two ground stations mediated by
a satellite in low-Earth orbit, and two entanglement distribution schemes - one
where the central satellite is used as a relay, and the other where the central
satellite is used to generate and distribute the entangled resource directly.
We compute a bound on the rate of distribution of distillable entanglement
achieved by each protocol in each network topology as a function of the network
channels for both single-rail discrete- (DV) and continuous-variable (CV)
resources and use or non-use of probabilistic noiseless linear quantum
amplification (NLA). In the case of atmospheric channels we take into account
the turbulent and optical properties of the free-space propagation. We
determine that for the triple-satellite network configuration, the optimal
strategy is to perform a distributed NLA scheme in either CV or DV, and for the
ground-satellite-ground network the optimal strategy is to distribute a DV
resource via the central satellite.

</details>


### [351] [Benchmarking Quantum Simulation Methods](https://arxiv.org/abs/2510.01710)
*Calvin Ku,Yu-Cheng Chen,Alice Hu,Min-Hsiu Hsieh*

Main category: quant-ph

TL;DR: 本研究量化了量子相位估计算法（QPE）中三个关键参数对量子资源成本的影响：tratterization与qubitization的选择、分子轨道与平面波基组的使用，以及费米子到量子比特的编码方案。研究确定了不同参数组合下的性能权衡，并指出了在何种参数下可以最小化相关分子系统的资源成本。


<details>
  <summary>Details</summary>
Motivation: 量子相位估计算法（QPE）是容错量子计算的基石，尤其在化学系统的电子结构计算中。为了适应不同量子化学系统的特性，研究人员开发了多种QPE变体，但这些变体在量子比特和门电路成本上存在差异。

Method: 量化了tratterization与qubitization的选择、分子轨道与平面波基组的使用，以及费米子到量子比特编码方案这三个关键参数对QPE算法整体量子资源成本的影响。

Result: 研究发现，在容错场景下，使用平面波基组的第一量子化qubitization电路对于大型分子的相位估算最为高效，其门电路成本缩放为$	ilde{\mathcal{O}}([N^{4/3}M^{2/3}+N^{8/3}M^{1/3}]/\varepsilon)$，是迄今为止已知的最佳缩放。对于仅有含噪声中等规模或近期容错系统的情况，通过在分子轨道（MO）基组中使用trotterization进行小型分子的相位估算，其门电路成本可达$\mathcal{O}(M^{7}/\varepsilon^{2})$。此外，研究还提供了在不同参数选择下，对现实分子系统进行QPE所需的量子比特和T门成本的数值估计。

Conclusion: 本研究明确了QPE算法中不同参数选择的性能权衡，并为在不同计算场景下（容错或含噪声近端系统）最小化资源成本提供了指导。特别是，在容错计算中，第一量子化的qubitization电路结合平面波基组提供了最优的计算复杂度。

Abstract: Quantum Phase Estimation (QPE) is a cornerstone algorithm for fault-tolerant
quantum computation, especially for electronic structure calculations of
chemical systems. To accommodate the diverse characteristics of quantum
chemical systems, numerous variants of QPE have been developed, each with
distinct qubit and gate cost implications. In this paper, we quantify the
impact of three key parameters on the overall quantum resource costs for the
QPE algorithm: the choice between trotterization and qubitization, the use of
molecular orbitals versus plane-wave basis-sets, and the selection of the
fermion-to-qubit encoding scheme. From this, we establish clear performance
trade-offs and delineate specific parameter regimes that minimize resource
costs for relevant molecular systems. When performing phase estimation on large
molecules in the fault-tolerant setting, we found the first-quantized
qubitization circuit using the plane-wave basis to be the most efficient, with
a gate cost scaling of
$\tilde{\mathcal{O}}([N^{4/3}M^{2/3}+N^{8/3}M^{1/3}]/\varepsilon)$ for a system
of $N$ electrons and $M$ orbitals, which is the best known scaling to date. On
the other hand, when only noisy intermediate-scale or near-term fault-tolerant
systems are available, the phase estimation of small molecules can be performed
with gate cost of $\mathcal{O}(M^{7}/\varepsilon^{2})$ via trotterization in
the MO basis. Furthermore, we provide numerical estimations of qubit and T gate
costs required to perform QPE for several real-world molecular systems under
these different parameter choices.

</details>


### [352] [Extracting the photon indistinguishability error from measurable quantum observables](https://arxiv.org/abs/2510.01731)
*Franciscus H. B. Somhorst,Jason Saied,Eleanor G. Rieffel,Jelmer J. Renema*

Main category: quant-ph

TL;DR: 本文提出了一种从宏-丹（Hong-Ou-Mandel）干涉测量中提取光子不可分辨性误差的方法，该方法考虑了损耗和多光子噪声对单光子希尔伯特空间的污染的联合影响。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是解决以往对宏-丹干涉测量结果解释中看似矛盾的问题。

Method: 本文提出的方法能够从宏-丹干涉测量中提取光子不可分辨性误差，同时考虑损耗和多光子噪声对单光子希尔伯特空间的综合影响。

Result: 该方法能够解决以往对宏-丹干涉测量结果解释中出现的明显不一致之处。

Conclusion: 所提出的方法适用于包括量子点在内的多种单光子源。

Abstract: We present a method to extract the photon indistinguishability error from
Hong-Ou-Mandel interference measurements, accounting for the combined effects
of loss and multiphoton noise that contaminate the single-photon Hilbert space.
Our analysis resolves apparent inconsistencies in previous interpretations of
such measurements. The reported method applies to a wide range of single-photon
sources, including quantum dots.

</details>


### [353] [Emergence and localization of exceptional points in an exactly solvable toy model](https://arxiv.org/abs/2510.01756)
*Miloslav Znojil*

Main category: quant-ph

TL;DR: 该论文研究了具有实谱的非厄米量子方形势阱问题，并提出了基于PT对称Robin边界条件的离散薛定谔方程。


<details>
  <summary>Details</summary>
Motivation: 阐明了参数变化对Kato's exceptional-point (EP) 奇点出现的影响，并解释了在某些简化的单参数情况下，奇数矩阵维度中EP退化的明显缺失现象。

Method: 通过对PT对称Robin边界条件下的离散薛定谔方程进行分析。

Result: 揭示了EP退化在奇数矩阵维度中缺失的原因，并发现了一个意想不到的多波带谱结构。

Conclusion: 该研究澄清了EP奇点的出现机制，并揭示了非厄米量子系统中的新谱结构。

Abstract: The most elementary non-Hermitian quantum square-well problem with real
spectrum is considered. The Schroedinger equation is required discrete and
endowed with PT-symmetric Robin (i.e., two-parametric) boundary conditions.
Some of the rather enigmatic aspects of impact of the variability of the
parameters on the emergence of the Kato's exceptional-point (EP) singularities
is clarified. In particular, the current puzzle of the apparent absence of the
EP degeneracies at the odd-matrix dimensions in certain simplified
one-parametric cases is explained. A not quite expected existence of a
multi-band spectral structure in another simplified one-parametric family of
models is also revealed.

</details>


### [354] [Self-Sustained Oscillations of a Nonlinear Optomechanical System in the Low-Excitation Regime](https://arxiv.org/abs/2510.01775)
*Shivangi Dhiman,K. Rubenbauer,T. Luschmann,A. Marx,A. Metelmann,H. Huebl*

Main category: quant-ph

TL;DR: 使用超导微波电路实现单光子驱动下的非线性动力学。


<details>
  <summary>Details</summary>
Motivation: 需要结合非线性与非经典关联来满足量子传感等应用的需求，并寻找实验平台。

Method: 利用具有大单光子耦合率的腔光力学平台和非线性微波谐振器，驱动一个机械系统在单激励水平下观察非线性动力学。

Result: 通过超导微波电路的克尔非线性将非线性动力学观察的阈值降低了四个数量级，使其在几个光子水平下即可实现。

Conclusion: 该装置概念为非经典微波驱动方案的实验铺平了道路。

Abstract: Manifesting across all time, mass and length scales, nonlinearities lie at
the core of numerous physical phenomena. Next-generation quantum applications,
such as quantum sensing, require the combination of nonlinearity with
non-classical correlations. This necessitates the search for an experimental
platform which enables a nonlinear response at ultra-low excitation levels in a
system with practical sensing potential and quantum compatibility. Here, we
report the observation and theoretical modeling of nonlinear dynamics in a
mechanical system driven at the single-excitation level. We achieve this using
a cavity-optomechanical platform with large single-photon coupling rates and a
nonlinear microwave resonator. Specifically, the large Kerr nonlinearity of our
superconducting microwave circuit reduces the threshold for the observation of
nonlinear dynamics by four orders of magnitude, making this regime
experimentally accessible at the few-photon level. The parameter-based
quantitative predicative power of the theoretical description underlines our
deep understanding of the physics involved and that this device concept paves
the way for experiments with non-classical microwave drive schemes.

</details>


### [355] [From quantum feature maps to quantum reservoir computing: perspectives and applications](https://arxiv.org/abs/2510.01797)
*Casper Gyurik,Filip Wudarski,Evan Philip,Antonio Sannia,Hossein Sadeghi,Oleksandr Kyriienko,Davide Venturelli,Antonio A. Gentile*

Main category: quant-ph

TL;DR: 量子系统可以作为水库计算的非平凡和可行的水库，特别是在中性原子量子处理单元的背景下，为机器学习任务提供了一种新的量子水库计算（QRC）工作流程，并讨论了未来的挑战和机遇。


<details>
  <summary>Details</summary>
Motivation: 探索水库计算和量子计算这两个新兴范式之间的相互作用，并研究量子系统如何能够充当机器学习任务的非平凡和可行的水库。

Method: 提出并举例说明了一种新的量子水库计算（QRC）工作流程，重点介绍了中性原子量子处理单元。

Result: 量子系统，特别是中性原子量子处理单元，可以作为机器学习任务的有效水库，并展示了量子水库计算（QRC）的潜力。

Conclusion: QRC能够推动水库计算的应用，但仍面临挑战，需要进一步的研究和发展。

Abstract: We explore the interplay between two emerging paradigms: reservoir computing
and quantum computing. We observe how quantum systems featuring
beyond-classical correlations and vast computational spaces can serve as
non-trivial, experimentally viable reservoirs for typical tasks in machine
learning. With a focus on neutral atom quantum processing units, we describe
and exemplify a novel quantum reservoir computing (QRC) workflow. We conclude
exploratively discussing the main challenges ahead, whilst arguing how QRC can
offer a natural candidate to push forward reservoir computing applications.

</details>


### [356] [Three-Dimensional Niobium Coaxial Cavity with $\sim0.1\,$second Lifetime](https://arxiv.org/abs/2510.01819)
*Takaaki Takenaka,Takayuki Kubo,Imran Mahoob,Kosuke Mizuno,Hitoshi Inoue,Takayuki Saeki,Shiro Saito*

Main category: quant-ph

TL;DR: 内部质量因数超过3e9，使用中温退火处理的腔体显示出长寿命和稳定性。


<details>
  <summary>Details</summary>
Motivation: 提高三维超导腔体的内部质量因数和光子寿命，并探索稳定的表面处理方法。

Method: 对三维铌四分之一波同轴腔进行中温退火处理，并在单光子水平、20毫开以下测量其内部质量因数。

Result: 中温退火处理的腔体在单光子水平、20毫开以下表现出超过3x10^9的内部质量因数，光子寿命约为90毫秒。退火处理后的腔体在多次冷启动和暴露于空气后，其内部质量因数几乎保持不变。

Conclusion: 中温退火处理可能在三维铌腔表面形成稳定的低损耗氧化层，这种表面处理方法可用于2D超导电路制造，并有望提高铌基超导量子比特的寿命。

Abstract: We report on the internal quality factor of a three-dimensional niobium
quarter-wave coaxial cavity, with mid-temperature annealing, exhibiting $Q_{\rm
int} \gtrsim 3\times10^9$ at the single-photon level below 20\,mK, which
corresponds to an internal photon lifetime of $\tau_{\rm
int}\sim90\,\mathrm{ms}$. Moreover, $Q_{\rm int}$ of the mid-temperature
annealed cavities remains almost unchanged even after several cooldown cycles
and air exposure. These results suggest that stable low-loss niobium oxides
might be formed by mid-temperature annealing on the surface of
three-dimensional niobium cavity. This surface treatment could be applicable to
the fabrication of 2D superconducting circuits and help improve the lifetime of
Nb-based superconducting qubits.

</details>


### [357] [Hybrid biphoton spectrometer for time-resolved quantum spectroscopy across visible and near-infrared regions](https://arxiv.org/abs/2510.01836)
*Ozora Iso,Koya Onoda,Nicola J. Fairbairn,Masahiro Yabuno,Hirotaka Terai,Shigehito Miki,Ryosuke Shimizu*

Main category: quant-ph

TL;DR: 该研究提出了一种捕获可见光和近红外光子三元非简并联合光谱的新方法，实现了约150 ps的时间分辨率，满足了量子信息对纯净双光子态的需求以及量子光谱对时间分辨能力的需求。


<details>
  <summary>Details</summary>
Motivation: 量子信息技术需要高度纯净的双光子态，而量子光谱技术则需要时间分辨能力来揭示分子动力学。现有技术在满足这两方面需求上存在差距。

Method: 利用两个非扫描光谱仪（一个用于近红外光子的光纤光谱仪，一个用于可见光子的延迟线单光子成像仪）来测量可见光和近红外光子的联合光谱。通过时间标记采集策略实现联合光谱强度测量，并实现了约150 ps的时间分辨率。

Result: 成功测量了可见光和近红外光子的三元非简并联合光谱，并实现了约150 ps的时间分辨率。

Conclusion: 所提出的新方法能够同时满足量子信息对纯净双光子态的要求以及量子光谱对时间分辨能力的需求，弥合了现有技术的差距。

Abstract: Joint spectral measurements are a powerful tool for characterising biphoton
spectral correlation, which is crucial for quantum information and
communication technologies. In these applications, highly pure biphoton states
are essential in any time- and frequency-mode, often obviating the need for
time-resolved measurements. Conversely, spectroscopy utilising entangled photon
pairs is gaining significant attention for its ability to unveil molecular
dynamics, a field that critically demands time-resolved capabilities. Here, we
introduce a novel methodology for capturing a biphoton spectrum that comprises
visible and near-infrared photons, resulting in a three-fold non-degenerate
joint spectrum. Our system employs two non-scanning spectrographs: a fibre
spectrograph for near-infrared photons and a delay-line-anode single-photon
imager for visible photons. We successfully measure the joint spectral
intensity by leveraging a time-tagging acquisition strategy. Furthermore, our
approach uniquely enables time-resolved joint spectral measurements with a
temporal resolution of approximately 150 ps. This methodology bridges the gap
between the requirements for pure biphoton states and the need for dynamic
insights in quantum spectroscopy.

</details>


### [358] [Counterfactual quantum measurements](https://arxiv.org/abs/2510.01888)
*Ingita Banerjee,Kiarn T. Laverick,Howard M. Wiseman*

Main category: quant-ph

TL;DR: 研究量子态下的反事实推理，提出了一种新的形式主义。


<details>
  <summary>Details</summary>
Motivation: 在经典确定性框架下，大卫·刘易斯的反事实推理分析是公认的，但其能否推广到不确定性量子理论一直是个悬而未决的问题。

Method: 提出了一种量子反事实推理的形式主义，其中将测量设置为反事实的前提。

Result: 该形式主义能够非平凡地回答“如果我使用另一个探测器，会看到什么”这类问题，例如：“鉴于我的光子探测器在特定时间点击了，如果我改用场-正交探测器，会看到什么？”

Conclusion: 为量子反事实推理提供了一种新的形式主义，并解决了在不确定性量子理论中的应用问题。

Abstract: Counterfactual reasoning plays a crucial role in exploring hypothetical
scenarios, by comparing some consequent under conditions identical except as
results from a differing antecedent. David Lewis' well-known analysis evaluates
counterfactuals using a hierarchy of desiderata. These were, however, built
upon a deterministic classical framework, and whether it could be generalized
to indeterministic quantum theory has been an open question. In this Letter, we
propose a formalism for quantum counterfactuals in which antecedents are
measurement settings. Unlike other approaches, it non-trivially answers
questions like: "Given that my photon-detector, observing an atom's
fluorescence, clicked at a certain time, what would I have seen using a
field-quadrature detector instead?"

</details>


### [359] [Folding lattice proteins confined on minimal grids using a quantum-inspired encoding](https://arxiv.org/abs/2510.01890)
*Anders Irbäck,Lucas Knuthson,Sandipan Mohanty*

Main category: quant-ph

TL;DR: This paper recasts the lattice protein folding problem as a QUBO problem, which can be solved efficiently using classical or quantum annealing.


<details>
  <summary>Details</summary>
Motivation: Conventional explicit-chain methods face challenges with steric clashes in dense protein systems, such as a single lattice protein confined on a minimal grid with no free sites. Finding the minimum energy configuration for such systems is a hard optimization problem.

Method: The paper reformulates the lattice protein folding problem into a Quadratic Unconstrained Binary Optimization (QUBO) problem. This QUBO formulation is then tackled using classical simulated annealing and hybrid quantum-classical annealing on a D-Wave system. Linear and quadratic programming methods are also tested as comparisons.

Result: The proposed QUBO formulation and annealing approaches successfully solve the problem for chain length 48, with hybrid quantum-classical annealing achieving solutions in approximately 10 seconds. Classical simulated annealing also shows consistent performance. Linear and quadratic programming methods, while effective for lattice gas models, struggle with the specific chain constraints of this problem.

Conclusion: The QUBO formulation and annealing methods, particularly hybrid quantum-classical annealing, provide an efficient and consistent solution for the challenging lattice protein folding problem, outperforming traditional linear and quadratic programming methods for this specific constrained optimization task.

Abstract: Steric clashes pose a challenge when exploring dense protein systems using
conventional explicit-chain methods. A minimal example is a single lattice
protein confined on a minimal grid, with no free sites. Finding its minimum
energy is a hard optimization problem, withsimilarities to scheduling problems.
It can be recast as a quadratic unconstrained binary optimization (QUBO)
problem amenable to classical and quantum approaches. We show that this problem
in its QUBO form can be swiftly and consistently solved for chain length 48,
using either classical simulated annealing or hybrid quantum-classical
annealing on a D-Wave system. In fact, the latter computations required about
10 seconds. We also test linear and quadratic programming methods, which work
well for a lattice gas but struggle with chain constraints. All methods are
benchmarked against exact results obtained from exhaustive structure
enumeration, at a high computational cost.

</details>


### [360] [Temporal Pulse Origins in Atom Interferometric Quantum Sensors](https://arxiv.org/abs/2510.01900)
*Jack Saywell,Nikolaos Dedes,Max Carey,Brynle Barrett,Tim Freegarde*

Main category: quant-ph

TL;DR: 原子的时间脉冲原点概念可以提高量子传感器的测量精度和稳定性。


<details>
  <summary>Details</summary>
Motivation: 经典原子干涉仪的测量标度因子受限于脉冲持续时间和控制场的稳定性，这影响了测量精度。本研究旨在提出一种新的方法来解决这个问题。

Method: 提出并利用了原子干涉仪中的‘时间脉冲原点’概念，将惯性相位响应参数化为单一时间点。通过模拟研究了该方法在提高测量标度因子稳定性和减少系统误差方面的潜力，并探索了其在设计定制脉冲序列中的应用。

Result: 模拟结果表明，‘时间脉冲原点’方法可以简化测量标度因子的确定，提高其对环境扰动的稳定性。此外，该方法能够设计出更短、更稳健的脉冲序列，减少系统误差，并提高传感器在实际运行中的性能。

Conclusion: ‘时间脉冲原点’概念为理解和解决现有原子干涉仪中的系统误差提供了一个新框架，并有望通过设计更优化的脉冲序列来提升当前和下一代量子传感器的性能。

Abstract: Quantum sensors based upon atom interferometry typically rely on
radio-frequency or optical pulses to coherently manipulate atomic states and
make precise measurements of inertial and gravitational effects. An advantage
of these sensors over their classical counterparts is often said to be that
their measurement scale factor is precisely known and highly stable. However,
in practice the finite pulse duration makes the sensor scale factor dependent
upon the pulse shape and sensitive to variations in control field intensity,
frequency, and atomic velocity. Here, we explore the concept of a temporal
pulse origin in atom interferometry, where the inertial phase response of any
pulse can be parameterized using a single point in time. We show that the
temporal origin permits a simple determination of the measurement scale factor
and its stability against environmental perturbations. Moreover, the temporal
origin can be treated as a tunable parameter in the design of tailored
sequences of shaped pulses to enhance scale factor stability and minimize
systematic errors. We demonstrate through simulations that this approach to
pulse design can reduce overall sequence durations while increasing robustness
to realistic fluctuations in control field amplitude. Our results show that the
temporal pulse origin explains a broad class of systematic errors in existing
devices and enables the design of short, robust pulses which we expect will
improve the performance of current and next-generation interferometric quantum
sensors.

</details>


### [361] [Hybrid Quantum-Classical Walks for Graph Representation Learning in Community Detection](https://arxiv.org/abs/2510.01918)
*Adrián Marın,Mauricio Soto-Gomez,Giorgio Valentini,Elena Casiraghi,Carlos Cano,Daniel Manzano*

Main category: quant-ph

TL;DR: 提出了一种新颖的量子启发式图表示学习算法，利用混合量子-经典游走来克服传统方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统图表示学习方法难以捕捉复杂图中复杂的非平凡结构关系。

Method: 利用混合量子-经典游走，使游走者能够同时探索图中的局部和远程连接。

Result: 在网络社区检测案例研究中，该混合动态使算法能够有效适应复杂图拓扑。

Conclusion: 该混合量子-经典游走方法为图表示学习任务提供了一个强大而通用的解决方案。

Abstract: Graph Representation Learning (GRL) has emerged as a cornerstone technique
for analysing complex, networked data across diverse domains, including
biological systems, social networks, and data analysis. Traditional GRL methods
often struggle to capture intricate relationships within complex graphs,
particularly those exhibiting non-trivial structural properties such as
power-law distributions or hierarchical structures. This paper introduces a
novel quantum-inspired algorithm for GRL, utilizing hybrid Quantum-Classical
Walks to overcome these limitations. Our approach combines the benefits of both
quantum and classical dynamics, allowing the walker to simultaneously explore
both highly local and far-reaching connections within the graph. Preliminary
results for a case study in network community detection shows that this hybrid
dynamic enables the algorithm to adapt effectively to complex graph topologies,
offering a robust and versatile solution for GRL tasks.

</details>


### [362] [The Constant Speed Schedule for Adiabatic State Preparation: Towards Quadratic Speedup without Prior Spectral Knowledge](https://arxiv.org/abs/2510.01923)
*Mancheon Han,Hyowon Park,Sangkook Choi*

Main category: quant-ph

TL;DR: 常数速度调度可以加速绝热量子演化，与标准线性调度相比，将演化时间的时间复杂度从 O(Δ^-2) 降低到 O(Δ^-1)，并在小间隙区域实现最优 O(Δ^-1) 缩放。


<details>
  <summary>Details</summary>
Motivation: 绝热量子演化的效率受绝热演化时间 T 支配，而 T 又取决于最小能量间隙 Δ。对于通用调度，T 通常缩放为 Δ^-2，而严格下界为 O(Δ^-1)，这表明通过绝热调度构造有可能实现二次加速。

Method: 提出了一种常数速度调度，以均匀速率遍历本征态，将所需演化时间的上界缩放降低了一个数量级。然后，提供了一种分段常数速度调度协议，其中路径段长度根据本征态重叠 along the 绝热演化进行计算。该方法通过实时依赖重叠来消除对先前光谱知识的需求。

Result: 在绝热非结构化搜索、N2 分子和 [2Fe-2S] 簇的数值实验中，所提出的方法在小间隙区域实现了最优的 O(Δ^-1) 缩放，从而证明了比标准线性调度二次加速。

Conclusion: 所提出的分段常数速度调度协议能够消除对先前光谱知识的需求，并在小间隙区域实现比标准线性调度二次加速。

Abstract: The efficiency of adiabatic quantum evolution is governed by the adiabatic
evolution time, \(T\), which depends on the minimum energy gap, \(\Delta\). For
a generic schedule, \(T\) typically scales as \(\Delta^{-2}\), whereas the
rigorous lower bound is \(\mathcal{O}(\Delta^{-1})\). This indicates the
potential for a quadratic speedup through the adiabatic schedule construction.
Here, we introduce the constant speed schedule, which traverses the adiabatic
path of the eigenstate at a uniform rate. We first show that this approach
reduces the scaling of the upper bound of the required evolution time by one
order in \(1/\Delta\). We then provide a segmented constant speed schedule
protocol, in which path segment lengths are computed from eigenstate overlaps
along the adiabatic evolution. By relying on the overlaps on the fly, our
method eliminates the need for prior spectral knowledge. We test our algorithm
numerically on the adiabatic unstructured search, the N$_2$ molecule, and the
[2Fe-2S] cluster. In our numerical experiments, the method achieves the optimal
\(1/\Delta\) scaling in a small gap region, thereby demonstrating a quadratic
speedup over the standard linear schedule.

</details>


### [363] [Maximum heralding probabilities of non-classical state generation from two-mode Gaussian state via photon counting measurements](https://arxiv.org/abs/2510.01951)
*Jaromír Fiurášek*

Main category: quant-ph

TL;DR: 通过对两模纠缠高斯态的一个模式进行光子数测量，可以从实验可及的高斯态生成高度非经典的光态。该方案的宣告概率是决定目标非经典态生成率的关键指标。


<details>
  <summary>Details</summary>
Motivation: 生成高度非经典的光态，例如Gottesman-Kitaev-Preskill态或猫态，这些态具有重要的量子信息处理应用价值。然而，直接生成这些态具有挑战性，因此需要开发高效的制备方法。

Method: 本文研究了对两模纠缠高斯态的一个模式进行光子数测量的方案。我们推导了该方案的宣告概率的解析表达式，并分析了其随探测光子数n的变化关系。

Result: 我们发现，在两模设置下，宣告概率的最大值可以被解析计算出来，并且其对探测光子数n的依赖性是多项式的。这意味着，生成高度复杂的、具有高恒星秩的光量子态在实验上是可行的，前提是具备足够强的压缩。

Conclusion: 本文提出的方法为高效生成高度非经典的光态提供了一条可行的途径，并且表明该方法在实验上是可行的，尤其是在具备高斯态和强压缩的条件下。

Abstract: Highly non-classical states of light - such as the approximate
Gottesman-Kitaev-Preskill states or cat-like states - can be generated from
experimentally accessible Gaussian states via photon counting measurements on
selected modes, conditioned on specific outcomes of these heralding events. A
simplest yet important example of this approach involves performing photon
number measurements on one mode of a two-mode entangled Gaussian state. The
heralding probability of this scheme is a key figure of merit, as it determines
the generation rate of the targeted non-classical state. In this work we show
that the maximum heralding probability for the two-mode setting can be
calculated analytically, and we investigate its dependence on the number of
detected photons n. Our results show that the number of required experimental
trials scales only polynomially with n. Generation of highly complex optical
quantum states with high stellar rank is thus practically feasible in this
setting, given access to sufficiently strong squeezing.

</details>


### [364] [Formal Framework for Quantum Advantage](https://arxiv.org/abs/2510.01953)
*Harry Buhrman,Niklas Galke,Konstantinos Meichanetzidis*

Main category: quant-ph

TL;DR: 本篇论文定义了量子计算优势的新概念，即“queasy”实例，并提出了一种衡量其标准。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于量子启发式和平均情况算法分析，而非最坏情况分析。

Method: 提出量子科尔莫哥洛夫复杂度和实例复杂度，以此定义“queasy”实例，并通过从因子分解问题的归约来证明可满足性问题存在“queasy”实例。

Result: 证明了存在“queasy”的可满足性实例，并且这种“queasy”性对量子算法具有指数级的算法效用。

Conclusion: 构建了一个形式化框架，用于指导寻找实际中的量子优势，并可能启发新的量子算法设计。

Abstract: Motivated by notions of quantum heuristics and by average-case rather than
worst-case algorithmic analysis, we define quantum computational advantage in
terms of individual problem instances. Inspired by the classical notions of
Kolmogorov complexity and instance complexity, we define their quantum
versions. This allows us to define queasy instances of computational problems,
like e.g. Satisfiability and Factoring, as those whose quantum instance
complexity is significantly smaller than their classical instance complexity.
These instances indicate quantum advantage: they are easy to solve on a quantum
computer, but classical algorithms struggle (they feel queasy). Via a reduction
from Factoring, we prove the existence of queasy Satisfiability instances;
specifically, these instances are maximally queasy (under reasonable
complexity-theoretic assumptions). Further, we show that there is exponential
algorithmic utility in the queasiness of a quantum algorithm. This formal
framework serves as a beacon that guides the hunt for quantum advantage in
practice, and moreover, because its focus lies on single instances, it can lead
to new ways of designing quantum algorithms.

</details>


### [365] [Digital quantum simulation of many-body localization crossover in a disordered kicked Ising model](https://arxiv.org/abs/2510.01983)
*Tomoya Hayata,Kazuhiro Seki,Seiji Yunoki*

Main category: quant-ph

TL;DR: 本研究提出在无序的弗洛凯多体系统中模拟多体局域化交叉，并使用60个量子比特在IBM Heron r2设备上模拟了无序踢起的伊辛模型，通过计算失序关联函数来指示多体局域化交叉。


<details>
  <summary>Details</summary>
Motivation: 在有噪声的量子设备上精确模拟哈密顿量演化具有挑战性，而弗洛凯演化（通过具有大Trotter步长的哈密顿量演化Trotter分解实现）被认为是近期量子设备上可行的模拟问题。因此，本研究旨在利用此方法模拟无序弗洛凯多体系统中的多体局域化交叉。

Method: 在无序弗洛凯多体系统中，利用Trotter分解和大的Trotter步长，在IBM Heron r2设备上使用60个量子比特模拟无序踢起的伊辛模型。通过计算失序关联函数来指示多体局域化交叉。

Result: 通过计算失序关联函数的后期行为，成功定位了量子混沌和多体局域化区域，并将其与无序强度相关联。

Conclusion: 本研究提出的在无序弗洛凯多体系统中模拟多体局域化交叉的方法是可行的，并且通过两种独立的误差抑制方法（算子重整化和零噪声外推）验证了结果的有效性。

Abstract: Simulating nonequilibrium dynamics of quantum many-body systems is one of the
most promising applications of quantum computers. However, a faithful digital
quantum simulation of the Hamiltonian evolution is very challenging in the
present noisy quantum devices. Instead, nonequilibrium dynamics under the
Floquet evolution realized by the Trotter decomposition of the Hamiltonian
evolution with a large Trotter step size is considered to be a suitable problem
for simulating in the present or near-term quantum devices. In this work, we
propose simulating the many-body localization crossover as such a
nonequilibrium problem in the disordered Floquet many-body systems. As a
demonstration, we simulate the many-body localization crossover in a disordered
kicked Ising model on a heavy-hex lattice using $60$ qubits from $156$ qubits
available in the IBM Heron r2 superconducting qubit device named ibm\_fez. We
compute out-of-time-ordered correlators as an indicator of the many-body
localization crossover. From the late-time behavior of out-of-time-ordered
correlators, we locate the quantum chaotic and many-body localized regimes as a
function of the disorder strength. The validity of the results is confirmed by
comparing two independent error mitigation methods, that is, the operator
renormalization method and zero-noise extrapolation.

</details>


### [366] [HIV-1 protease cleavage sites detection with a Quantum convolutional neural network algorithm](https://arxiv.org/abs/2510.01993)
*Junggu Choi,Junho Lee,Kyle L. Jung,Jae U. Jung*

Main category: quant-ph

TL;DR: 该研究提出了一种基于量子卷积神经网络（QCNN）和神经量子嵌入（NQE）的框架，用于预测HIV-1蛋白酶的切割位点。


<details>
  <summary>Details</summary>
Motivation: 在病毒和人类蛋白质的氨基酸序列中预测HIV-1蛋白酶的切割位点。

Method: 提出了一种基于量子卷积神经网络（QCNN）和神经量子嵌入（NQE）的框架。

Result: 在有噪声和无噪声模拟下，QCNN（使用角度和幅度编码NQE）的分类性能优于经典神经网络。即使在量子硬件噪声下，QCNN也表现出稳定的性能。

Conclusion: QCNN结合NQE在HIV-1切割位点分类任务中表现出优越的性能和对噪声的鲁棒性，证明了其在NISQ硬件上进行生物医学数据分析的适用性。

Abstract: In this study, we propose a quantum convolutional neural network (QCNN)-based
framework with the neural quantum embedding (NQE) to predict HIV-1 protease
cleavage sites in amino acid sequences from viral and human proteins. To assess
the effectiveness and robustness of our framework, we compared the
classification performance against classical neural networks under both
noiseless and noisy simulations. Among experimental conditions, the QCNN with
the angle and amplitude encoding NQE conditions consistently outperformed
classical counterparts in both the similar trainable parameter scale and the
different number of qubits (the averaged performance of the 4-qubits and
8-qubits QCNN: 0.9146 and 0.8929 / the averaged performance of the classical
neural network: 0.6125 and 0.8278). The QCNN with the NQE showed stable
performance under the quantum hardware noise, confirming its applicability to
biomedical data analysis with the noise intermediate-scale quantum (NISQ)
hardware. This study presents the first application of NQE-augmented QCNNs for
HIV-1 cleavage site classification, providing new insights into scalable and
noise-resilient quantum machine learning for biomedical data.

</details>


### [367] [Fiber-integrated NV Magnetometer with Microcontroller-based Software Lock-in Technique](https://arxiv.org/abs/2510.01996)
*Qilong Wu,Xuan-Ming Shen,Yuan Zhang,Ying-Geng Shan,Hui-Hui Yu,Jing-Hao Zhang,Jiahui Chen,Yan Wang,Xun Yang,Yong-Zhi Tian,Lijun Wang,Chong-Xin Shan*

Main category: quant-ph

TL;DR: 一种低成本、集成化的光纤氮-空位（NV）磁力计，使用微控制器实现软件锁相放大技术，可与昂贵设备媲美。


<details>
  <summary>Details</summary>
Motivation: 现有的光纤集成NV磁力计虽然灵敏度高、集成性好、柔性强，但其配套的电子设备昂贵、笨重，限制了其实际应用。

Method: 开发了一种基于微控制器的软件锁相放大技术，通过微控制器协调微波源芯片和模数转换器，并用程序模拟锁相放大机制，实现了NV中心的微波频率调制光学检测磁共振。

Result: 实现了93 nT/Hz^{1/2}的磁场探测灵敏度，和488 nT的标准偏差，达到了与笨重、专业的设备相当的水平，并实现了实时磁场探测。

Conclusion: 提出了一种新颖且经济高效的电子小型化技术，有望加速NV磁力计的工业应用。

Abstract: Fiber-integrated nitrogen-vacancy (NV) magnetometers possess high
sensitivity, integration, and flexibility, and thus have been explored
extensively for industrial applications. While most studies have focused on the
optimization of the quantum sensing head, less attention has been paid to the
frequently employed professional, expensive, and bulky electronics, which
hinder their practical applications. In this article, we fabricate a
fiber-integrated NV magnetometer and develop a low-cost microcontroller-based
software lock-in technique. In this technique, a microcontroller coordinates
efficiently a microwave source chip and an analog-to-digital converter, and a
program mimicking the lock-in mechanism realizes microwave frequency-modulated
optically detected magnetic resonance of NV centers. As a result, with our
setup and technique, we have realized the detection of weak magnetic field with
a sensitivity of 93 nT/Hz^{1/2}, which is comparable to what obtained with
bulky and professional devices. Furthermore, we demonstrated real-time magnetic
field detection, achieving a standard deviation of 488 nT. Our work provides a
novel and cost-effective technique for electronic miniaturization, thereby
potentially accelerating the industrial application of NV magnetometers.

</details>


### [368] [Understanding Quantum Imaginary Time Evolution and its Variational form](https://arxiv.org/abs/2510.02015)
*Anglés-Castillo Andreu,Ion Luca,Pandit Tanmoy,Gomez-Lurbe Rafael,Martínez Rodrigo,Garcia-March Miguel Angel*

Main category: quant-ph

TL;DR: QITE是一种用于寻找量子哈密顿量基态的算法，本文对其进行了综述，并提供了相应的程序和变分版本。


<details>
  <summary>Details</summary>
Motivation: 许多计算上难题可以通过量子哈密顿量的基态来解决。

Method: 本文综述了量子虚时演化（QITE）算法，包括其原始算法和变分版本，并提供了一个全面的计算机程序。

Result: 本文提供了QITE算法的综述和实现细节。

Conclusion: QITE是一种寻找量子哈密顿量基态的有效算法。

Abstract: Many computationally hard problems can be encoded in quantum Hamiltonians.
The solution to these problems is given by the ground states of these
Hamiltonians. A state-of-the-art algorithm for finding the ground state of a
Hamiltonian is the so-called Quantum Imaginary Time Evolution (QITE) which
approximates imaginary time evolution by a unitary evolution that can be
implemented in quantum hardware. In this paper, we review the original
algorithm together with a comprehensive computer program, as well as, the
variational version of it.

</details>


### [369] [Critical Quantum Sensing: a tutorial on parameter estimation near quantum phase transitions](https://arxiv.org/abs/2510.02035)
*George Mihailescu,Uesli Alushi,Roberto Di Candia,Simone Felicetti,Karol Gietka*

Main category: quant-ph

TL;DR: 量子传感技术利用量子相变附近的临界现象来提高测量精度，但面临可扩展性、环境噪声和实际集成等挑战。本教程介绍了关键概念、传感策略、应用实例和开放系统中的挑战与机遇。


<details>
  <summary>Details</summary>
Motivation: 当前的量子传感技术在可扩展性、环境噪声和实际集成方面存在局限，需要新的方法来超越经典极限。

Method: 介绍临界量子计量学的关键概念，并概述利用临界现象进行量子传感的策略，通过不同复杂度的实例和模型进行阐述，特别关注估计精度与资源的最优标度。

Result: 通过对不同临界系统的临界量子传感协议进行阐述，并分析最优标度，为量子传感技术提供了理论指导。

Conclusion: 临界量子计量学已从理想模型扩展到实际的开放系统和耗散体系，为未来的量子技术带来了挑战和机遇。

Abstract: Quantum phenomena offer the possibility of measuring physical quantities with
precision beyond classical limits. However, current progress is constrained by
scalability, environmental noise, and challenges in practical integration. This
highlights the necessity for novel approaches. An emerging paradigm in this
direction is \emph{critical quantum metrology} -- which harnesses the enhanced
susceptibility and nonclassical correlations naturally occurring near quantum
phase transitions as resources for quantum-enhanced precision. This tutorial
provides a pedagogical introduction to key concepts and a detailed overview of
prominent quantum sensing strategies that exploit critical phenomena in
metrology. Through examples of increasing complexity, the reader is guided
through various critical quantum sensing protocols applied to different
critical systems. Special emphasis is placed on the optimal scaling of
estimation precision with respect to fundamental resources. Finally, we discuss
how critical quantum metrology extends from idealized models to realistic
open-system and dissipative regimes, and outline both the challenges and
opportunities for future quantum technologies.

</details>


### [370] [Improving neural network performance for solving quantum sign structure](https://arxiv.org/abs/2510.02051)
*Xiaowei Ou,Tianshu Huang,Vidvuds Ozolins*

Main category: quant-ph

TL;DR: 提出一种改进的随机重构方法，通过使用不同的虚时间步长来同时有效地训练相位和幅度神经网络，并使用海森堡J_1-J_2模型进行了演示。


<details>
  <summary>Details</summary>
Motivation: 现有方法在研究非阶数哈密顿量基态时，要么依赖先验知识，要么需要单独预训练相位网络，而本文提出的方法则解决了这些问题。

Method: 使用不同的虚时间步长来分别优化幅度和相位的随机重构方法，其中相位优化使用较大的时间步长，以实现幅度和相位神经网络的同时高效训练。

Result: 该方法在海森堡J_1-J_2模型上得到了有效验证。

Conclusion: 本文提出的改进型随机重构方法能够同时高效地训练幅度和相位神经网络，为研究非阶数哈密顿量基态提供了一种有效的新途径。

Abstract: Neural quantum states have emerged as a widely used approach to the numerical
study of the ground states of non-stoquastic Hamiltonians. However, existing
approaches often rely on a priori knowledge of the sign structure or require a
separately pre-trained phase network. We introduce a modified stochastic
reconfiguration method that effectively uses differing imaginary time steps to
evolve the amplitude and phase. Using a larger time step for phase
optimization, this method enables a simultaneous and efficient training of
phase and amplitude neural networks. The efficacy of our method is demonstrated
on the Heisenberg J_1-J_2 model.

</details>


### [371] [Resource theory of asymmetric distinguishability with partial information](https://arxiv.org/abs/2510.02071)
*Siqi Yao,Kun Fang*

Main category: quant-ph

TL;DR: 最坏情况量子散度可被视为不对称可区分性资源理论中的资源。


<details>
  <summary>Details</summary>
Motivation: 从资源理论的角度理解最坏情况量子散度，并将其扩展到包含部分信息的设置。

Method: 使用（平滑的）单次散度和正则化散度来表征资源蒸馏和稀释的最优速率。

Result: 资源互换可以在不受损耗的情况下实现，其速率完全由正则化散度决定。

Conclusion: 所提出的框架为状态集之间的散度提供了广泛的操作解释，并将现有的资源理论推广到包含不完整信息的情况。

Abstract: Recent studies have introduced the worst-case quantum divergence as a key
measure in quantum information. Here we show that such divergences can be
understood from the perspective of the resource theory of asymmetric
distinguishability, which utilizes the asymmetric distinguishability between a
pair of quantum states as resource. In our work, we extend this framework to
settings with partial information, where the goal is to distinguish between
sets of quantum states rather than individual states. Within this setting, we
characterize optimal rates for resource distillation and dilution using
(smoothed) one-shot divergences and regularized divergences. Our framework
further exhibits a reversibility property: resource interconversions can be
achieved without loss at rates determined entirely by regularized divergences.
These results offer a broad operational interpretation of divergences between
state sets and generalize existing resource theories to encompass incomplete
information scenarios.

</details>


### [372] [Optimizing fermionic Hamiltonians with classical interactions](https://arxiv.org/abs/2510.02122)
*Maarten Stroeks,Barbara M. Terhal,Yaroslav Herasymenko*

Main category: quant-ph

TL;DR: 使用高斯态研究具有经典相互作用的费米子哈密顿量


<details>
  <summary>Details</summary>
Motivation: 研究具有经典相互作用的费米子哈密顿量的优化问题（基态能量搜索），这在量子化学和凝聚体物理的电子结构哈密顿量中至关重要。

Method: 证明了费米高斯态对于此类哈密顿量至少能达到1/3的近似比，并且与稀疏性无关。提出了高斯混合（高斯态的一种构造，通过协方差矩阵的混合）的概念。

Result: 费米高斯态实现了至少1/3的近似比，克服了SYK型模型中高斯近似比可能消失的问题。为几类无迹和半正定经典相互作用哈密顿量提供了有效的高斯近似半定规划算法，并能强制固定粒子数。

Conclusion: 经典相互作用足以防止高斯近似比的消失，费米高斯态提供了一个有效的近似方法。

Abstract: We consider the optimization problem (ground energy search) for fermionic
Hamiltonians with classical interactions. This QMA-hard problem is motivated by
the Coulomb electron-electron interaction being diagonal in the position basis,
a fundamental fact that underpins electronic-structure Hamiltonians in quantum
chemistry and condensed matter. We prove that fermionic Gaussian states achieve
an approximation ratio of at least 1/3 for such Hamiltonians, independent of
sparsity. This shows that classical interactions are sufficient to prevent the
vanishing Gaussian approximation ratio observed in SYK-type models. We also
give efficient semi-definite programming algorithms for Gaussian approximations
to several families of traceless and positive-semidefinite classically
interacting Hamiltonians, with the ability to enforce a fixed particle number.
The technical core of our results is the concept of a Gaussian blend, a
construction for Gaussian states via mixtures of covariance matrices.

</details>


### [373] [Realism and the Inequivalence of the Two Quantum Pictures](https://arxiv.org/abs/2510.02138)
*Charles Alexandre Bédard*

Main category: quant-ph

TL;DR: 量子力学的薛定谔绘景和海森堡绘景在科学实在论下是不等价的，海森堡绘景提供了对量子现象的更本质、更定域的解释。


<details>
  <summary>Details</summary>
Motivation: 区分量子力学中两种绘景（薛定谔绘景和海森堡绘景）在科学实在论世界观下的等价性问题，并探讨海森堡绘景在解释特定量子现象方面的优势。

Method: 通过分析薛定谔绘景和海森堡绘景在科学实在论下的哲学含义，比较了它们在描述量子态和可观测量代数生成元方面的数学结构（非同构性），并以此为基础阐述了海森堡绘景在解释超密编码、量子隐形传态、分支和贝尔不等式违反等现象时的定域性解释能力。

Result: 证明了在科学实在论的框架下，薛定谔绘景和海森堡绘景是不等价的。海森堡绘景中的描述符（time-evolving generators of the algebra of observables）提供了对超密编码、量子隐形传态、分支和贝尔不等式违反等现象的更优的、本质上更定域的解释，而薛定谔绘景则无法完全提供这种定域解释。

Conclusion: 量子力学的两种绘景在科学实在论下是不等价的。海森堡绘景不仅在数学结构上比薛定谔绘景更丰富，而且在解释超密编码、量子隐形传态、分支和贝尔不等式违反等现象时，提供了真正定域的解释，这标志着量子理论可以拥有更丰富的、可分离的本体论。

Abstract: The standard claim that the Schr\"odinger and Heisenberg pictures of quantum
mechanics are equivalent rests on the fact that they yield identical empirical
predictions. This equivalence therefore assumes the instrumentalist worldview
in which theories serve only as tools for prediction. Under scientific realism,
by contrast, theories aim to describe reality. Whereas the Schr\"odinger
picture posits a time-evolving wave function, the Heisenberg picture posits
so-called descriptors, time-evolving generators of the algebra of observables.
These two structures are non-isomorphic: descriptors surject onto but do not
reduce to the Schr\"odinger state. Hence, under realism, the pictures are
inequivalent. I argue that this inequivalence marks an opening toward a richer,
separable ontology for quantum theory. On explanatory grounds, descriptors
provide genuinely local accounts of superdense coding, teleportation,
branching, and Bell inequality violations -- phenomena that the Schr\"odinger
framework does not explain fully locally.

</details>


### [374] [Quantum speed-up for solving the one-dimensional Hubbard model using quantum annealing](https://arxiv.org/abs/2510.02141)
*Kunal Vyas,Fengping Jin,Hans De Raedt,Kristel Michielsen*

Main category: quant-ph

TL;DR: 量子计算可用于模拟 Hubbard 模型，并在某些情况下比传统方法提供更快的速度。


<details>
  <summary>Details</summary>
Motivation: 研究使用量子算法解决许多体问题的范例，特别是 Hubbard 模型。

Method: 使用基于门的量子计算机模拟 Hubbard 模型的量子退火，并研究了系统规模对所需退火时间的影响。

Result: 对于所考虑的半满情况，量子计算模拟显示出比基于 Bethe-ansatz 方程的算法有显著的量子加速。

Conclusion: 量子计算是解决 Hubbard 模型等许多体问题的一种有前途的方法。

Abstract: The Hubbard model has occupied the minds of condensed matter physicists for
most part of the last century. This model provides insight into a range of
phenomena in correlated electron systems. We wish to examine the paradigm of
quantum algorithms for solving such many-body problems. The focus of our
current work is on the one-dimensional model which is integrable, meaning that
there exist analytical results for determining its ground state. In particular,
we demonstrate how to perform a gate-based quantum computer simulation of
quantum annealing for the Hubbard Hamiltonian. We perform simulations for
systems with up to 40 qubits to study the scaling of required annealing time
for obtaining the ground state. We find that for the half-filled cases
considered, there is a substantial quantum speed-up over algorithms based on
the Bethe-ansatz equations.

</details>


### [375] [Chaotic many-body quantum dynamics, spectral correlations, and energy diffusion](https://arxiv.org/abs/2510.02198)
*J. T. Chalker,Dominik Hahn*

Main category: quant-ph

TL;DR: 我们研究了具有空间结构和局部相互作用的最小模型中的混沌多体量子动力学。我们证明了能量动力学可以用经典主方程来描述，并且是扩散性的。我们还表明，谱因子可以精确地表示为该主方程解的函数。对于一个两站点系统，我们得到了能量密度两点相关器和谱因子的闭式表达式。对于一个 L 站点系统，我们展示了在晚期，谱因子如何出现线性斜坡，以及在早期，出现两种不同的机制，导致谱因子增加。我们相信我们的方法提供了自然近似。


<details>
  <summary>Details</summary>
Motivation: 研究具有空间结构和局部相互作用的最小模型中的混沌多体量子动力学。

Method: 在大的局部希尔伯特空间维度和弱的格间耦合的极限下，推导能量动力学的主方程，并推导谱因子的精确表达式。对于两站点系统，得到闭式解；对于 L 站点系统，分析其渐进行为。通过数值模拟验证结果。

Result: 能量动力学是扩散性的，可以用经典主方程描述。得到了能量密度两点相关器和谱因子的精确表达式。对于 L 站点系统，在晚期谱因子出现线性斜坡，早期有两种机制导致谱因子增加。数值模拟与理论预测基本一致。

Conclusion: 所提出的方法在分析极限下是精确的，并且对于小局部希尔伯特空间维度和强格间耦合的系统也是一个很好的近似。该模型为理解混沌量子系统的动力学提供了一个有用的框架。

Abstract: We study chaotic many-body quantum dynamics in a minimal model with spatial
structure and local interactions. It has a time-independent Hamiltonian, in
contrast to much-studied quantum circuits, and is analytically tractable for
large local Hilbert space dimension and weak intersite coupling. In this limit
we show that energy dynamics is described by a classical master equation and is
diffusive. We also show that the spectral form factor can be expressed exactly
in terms of the solution to this master equation. For a two-site system we
obtain closed-form expressions for both the two-point correlator of energy
density and the spectral form factor, in essentially perfect agreement with
numerical simulations. For an $L$-site system we show at late times how a
linear ramp emerges in the spectral form factor, as universally expected from
level repulsion in chaotic quantum systems. Conversely, at earlier times we
identify two distinct mechanisms for an increase of the spectral form factor
above its ramp value. One of these is associated with energy diffusion and is
effective until the Thouless time, which varies as $L^2$. The other involves
contributions like those that would appear if the system were composed of many
uncoupled subsystems: they generate a large enhancement of the spectral form
factor, and are suppressed on a timescale varying as $(\ln L)^2$. Besides being
exact for the limit considered, we believe our approach provides the natural
approximation even for small local Hilbert space dimension and strong intersite
coupling. We present a numerical study of a spin-half chain, finding an
early-time enhancement of the spectral form factor which is qualitatively
similar to that in our solvable model.

</details>


### [376] [Quantum Fisher information matrices from Rényi relative entropies](https://arxiv.org/abs/2510.02218)
*Mark M. Wilde*

Main category: quant-ph

TL;DR: 本文推导了基于对数欧几里得、α-z 和几何 Rényi 相对熵的量子 Fisher 信息矩阵，并讨论了它们在参数化热态和量子玻尔兹曼机器学习中的应用。


<details>
  <summary>Details</summary>
Motivation: 量子 Fisher 信息矩阵在量子信息科学、高能物理、凝聚态物理、量子估计理论、机器学习和优化等领域有重要应用。然而，与经典情况不同，目前尚无唯一的量子 Fisher 信息矩阵。

Method: 本文利用差分商方法计算矩阵导数，推导了基于对数欧几里得、α-z 和几何 Rényi 相对熵的 Fisher 信息矩阵。

Result: 研究发现，对于所有非负的 Rényi 参数 α，对数欧几里得 Rényi 相对熵导出 Kubo-Mori 信息矩阵，几何 Rényi 相对熵导出右对数导数 Fisher 信息矩阵。这两个信息矩阵都满足数据处理不等式。此外，本文还推导了 α-z Rényi 相对熵的 α-z 信息矩阵及其基本性质，并给出了参数化热态的 α-z 信息矩阵的计算公式和混合量子经典估计算法。

Conclusion: 本文成功推导了多种量子 Fisher 信息矩阵，并揭示了它们与现有矩阵的关系，同时探讨了其在量子机器学习等领域的应用潜力。

Abstract: Quantum generalizations of the Fisher information are important in quantum
information science, with applications in high energy and condensed matter
physics and in quantum estimation theory, machine learning, and optimization.
One can derive a quantum generalization of the Fisher information matrix in a
natural way as the Hessian matrix arising in a Taylor expansion of a smooth
divergence. Such an approach is appealing for quantum information theorists,
given the ubiquity of divergences in quantum information theory. In contrast to
the classical case, there is not a unique quantum generalization of the Fisher
information matrix, similar to how there is not a unique quantum generalization
of the relative entropy or the R\'enyi relative entropy. In this paper, I
derive information matrices arising from the log-Euclidean, $\alpha$-$z$, and
geometric R\'enyi relative entropies, with the main technical tool for doing so
being the method of divided differences for calculating matrix derivatives.
Interestingly, for all non-negative values of the R\'enyi parameter $\alpha$,
the log-Euclidean R\'enyi relative entropy leads to the Kubo-Mori information
matrix, and the geometric R\'enyi relative entropy leads to the
right-logarithmic derivative Fisher information matrix. Thus, the resulting
information matrices obey the data-processing inequality for all non-negative
values of the R\'enyi parameter $\alpha$ even though the original quantities do
not. Additionally, I derive and establish basic properties of $\alpha$-$z$
information matrices resulting from the $\alpha$-$z$ R\'enyi relative
entropies. For parameterized thermal states, I establish formulas for their
$\alpha$-$z$ information matrices and hybrid quantum-classical algorithms for
estimating them, with applications in quantum Boltzmann machine learning.

</details>


### [377] [The (PXP)$^2$ model: long-range quantum scars in optical cavities](https://arxiv.org/abs/2510.02246)
*Hossein Hosseinabadi,Riccardo J. Valencia-Tortora,Aleksandr N. Mikheev,Darrick E. Chang,Johannes Zeiher,Roderich Moessner,Jamir Marino*

Main category: quant-ph

TL;DR: 利用结合了光子和里德堡激发的混合系统，研究了长短程相互作用的量子多体物理。


<details>
  <summary>Details</summary>
Motivation: 探索了里德堡-腔系统在量子模拟和量子信息处理中的应用潜力，特别是如何结合光子介导的长程耦合和里德堡激发产生的短程相互作用，以工程化多体相。

Method: 提出并研究了一个最小且可扩展的模型，重点关注强里德堡阻塞机制，将希尔伯特空间限制在阻塞所施加的子空间内，从而得到一个在一维空间中具有动量约束的长程模型。

Result: 在平衡态下，发现了顺磁相、尼尔有序相以及一种区别于传统超辐射相的阻塞铁磁/超辐射相。在非平衡态下，识别出了长程量子多体“伤痕”态，这些态具有非典型的热力学性质，并导致了缓慢的纠缠增长，表现为对数而非线性增长。

Conclusion: 该研究建立了一个最小但通用的里德堡-腔系统模型框架，为未来在该量子多体物理前沿平台上的理论和实验研究奠定了基础。

Abstract: Rydberg-cavity systems are emerging as promising platforms for quantum
simulation and quantum information processing. These hybrid architectures
combine two complementary interaction mechanisms: cavity photons mediate
collective long-range couplings, while Rydberg excitations generate strong
short-range interactions. Together, they offer a setting for engineering
many-body phases characterized by a hierarchy of interactions across widely
different length scales. In this work, we introduce a minimal and scalable
model for such systems. Focusing on the strong Rydberg blockade regime, we
restrict the Hilbert space to the subspace enforced by the blockade, yielding a
kinetically constrained long-range model in one spatial dimension. This
approach both captures the physics of Rydberg-cavity experiments in the regime
of strong Rydberg interactions and provides a conceptually transparent
framework for studying the interplay of long-range and short-range
interactions. At equilibrium, in addition to paramagnetic and N\'eel-ordered
phases, the system supports a blockaded ferromagnetic/superradiant phase,
distinct from the conventional superradiant phase. Out of equilibrium, we
identify long-range quantum many-body scars, which are atypical nonthermal
eigenstates that evade the eigenstate thermalization hypothesis, and giving
rise to slow entanglement growth. In contrast to the linear-in-time
entanglement growth characteristic of short-range scarred models, these
long-range scars exhibit logarithmic entanglement dynamics. Our results
establish a minimal yet versatile framework for Rydberg-cavity systems, and
provide a stepping stone for future theoretical and experimental studies of
this frontier platform in quantum many-body physics.

</details>


### [378] [Reproducible Builds for Quantum Computing](https://arxiv.org/abs/2510.02251)
*Iyán Méndez Veiga,Esther Hänggi*

Main category: quant-ph

TL;DR: 可复现构建是软件开发实践，可验证从源代码到二进制文件的路径，有助于检测和缓解供应链攻击。本研究将可复现构建的概念扩展到量子计算领域，以应对威胁模型：1）量子计算机在电路准备和提交期间对终端用户数据的机密性；2）量子计算结果的完整性。研究展示了如何将经典信息隐藏在量子电路中，以及最小的电路修改如何导致错误的量子计算结果。该工作为量子软件工具链的可复现性框架奠定了初步基础。


<details>
  <summary>Details</summary>
Motivation: 量子计算虽然在快速发展，但也可以从采用可复现构建中受益。本研究旨在弥合量子计算和可复现构建社区之间的差距。

Method: 提出可复现构建在量子计算中的推广定义，并举例说明：1. 三个例子展示如何将经典信息隐藏在已转换的量子电路中。2. 两个案例说明即使是最小的电路修改也会导致错误的量子计算结果。

Result: 发现了将经典信息隐藏在量子电路中的方法，并展示了微小电路修改对量子计算结果的潜在影响。

Conclusion: 该工作为量子软件工具链的可复现性框架提供了初步的步骤。

Abstract: Reproducible builds are a set of software development practices that
establish an independently verifiable path from source code to binary
artifacts, helping to detect and mitigate certain classes of supply chain
attacks. Although quantum computing is a rapidly evolving field of research, it
can already benefit from adopting reproducible builds. This paper aims to
bridge the gap between the quantum computing and reproducible builds
communities. We propose a generalization of the definition of reproducible
builds in the quantum setting, motivated by two threat models: one targeting
the confidentiality of end users' data during circuit preparation and
submission to a quantum computer, and another compromising the integrity of
quantum computation results. This work presents three examples that show how
classical information can be hidden in transpiled quantum circuits, and two
cases illustrating how even minimal modifications to these circuits can lead to
incorrect quantum computation results. Our work provides initial steps towards
a framework for reproducibility in quantum software toolchains.

</details>


### [379] [Lower bounds on the complexity of preparing mixed states](https://arxiv.org/abs/2510.02275)
*Max McGinley,Samuel J. Garratt*

Main category: quant-ph

TL;DR: 本研究建立了多量子比特混合态中的关联与制备该状态所需最小线路深度的关系。当两个子系统间的互信息超过其中一个子系统与纯化混合态的环境间的互信息时，子系统过去的光锥必须相交，从而为使用几何局部酉变换制备状态设定了线路深度的下界。该方法可应用于计算一维量子临界系统（由共形场论描述）热态的制备深度，结果表明随着温度降低，制备深度发散，直至由制备误差设定的截止值。


<details>
  <summary>Details</summary>
Motivation: 研究多量子比特混合态中的关联与制备该状态所需最小线路深度的关系，并探索该关系在特定量子系统中的应用。

Method: 通过分析互信息和光锥相交来建立线路深度的下界，并将其应用于计算量子临界系统的热态制备深度。

Result: 推导出了制备量子临界系统热态所需的线路深度下界，并发现该深度随温度降低而发散。

Conclusion: 本研究揭示了量子态关联与制备复杂度之间的联系，并为特定量子系统的制备提供了理论指导。

Abstract: We establish a relationship between the correlations in a many-qubit mixed
state and the minimum circuit depth needed for its preparation. If the mutual
information between two subsystems exceeds the mutual information between one
of those subsystems and the environment, which purifies the mixed state of the
system, then the past lightcones of the subsystems must intersect one another.
This results in a lower bound on the circuit depth of any ensemble of
geometrically local unitaries that prepares the state to some specified degree
of approximation. As an application, we derive lower bounds on the circuit
depth needed to prepare thermal states of one-dimensional quantum critical
systems described by conformal field theory, showing that the depth diverges as
temperature is decreased up to a cutoff set by the preparation error.

</details>


### [380] [Beyond Belief Propagation: Cluster-Corrected Tensor Network Contraction with Exponential Convergence](https://arxiv.org/abs/2510.02290)
*Siddhant Midha,Yifan F. Zhang*

Main category: quant-ph

TL;DR: BP算法在张量网络收缩中存在准确性限制，本文提出了基于统计力学的聚类展开方法，可系统性地改进BP近似，并证明了其收敛性和提供误差界限，通过在二维Ising模型上的实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 张量网络收缩在量子模拟和纠错等领域至关重要，但现有的BP算法精度有限且难以改进。

Method: 本文构建了BP算法在张量网络中的理论框架，利用统计力学的聚类展开来系统性地改进BP近似，并设计了计算该展开的算法。

Result: 在二维Ising模型上，聚类展开方法显著优于BP算法及现有的改进算法（如loop series expansion）。

Conclusion: 本文提出的聚类展开方法为张量网络BP算法的系统性理论奠定了基础，并有望应用于量子纠错码解码和量子系统模拟。

Abstract: Tensor network contraction on arbitrary graphs is a fundamental computational
challenge with applications ranging from quantum simulation to error
correction. While belief propagation (BP) provides a powerful approximation
algorithm for this task, its accuracy limitations are poorly understood and
systematic improvements remain elusive. Here, we develop a rigorous theoretical
framework for BP in tensor networks, leveraging insights from statistical
mechanics to devise a \emph{cluster expansion} that systematically improves the
BP approximation. We prove that the cluster expansion converges exponentially
fast if an object called the \emph{loop contribution} decays sufficiently fast
with the loop size, giving a rigorous error bound on BP. We also provide a
simple and efficient algorithm to compute the cluster expansion to arbitrary
order. We demonstrate the efficacy of our method on the two-dimensional Ising
model, where we find that our method significantly improves upon BP and
existing corrective algorithms such as loop series expansion. Our work opens
the door to a systematic theory of BP for tensor networks and its applications
in decoding classical and quantum error-correcting codes and simulating quantum
systems.

</details>


### [381] [Quantum-Assisted Correlation Clustering](https://arxiv.org/abs/2509.03561)
*Antonio Macaluso,Supreeth Mysore Venkatesh,Diego Arenas,Matthias Klusch,Andreas Dengel*

Main category: quant-ph

TL;DR: 该研究提出了一种混合量子-经典方法用于相关聚类，这是一种基于图的无监督学习任务，旨在根据成对的同意和不同意来划分图中的节点。


<details>
  <summary>Details</summary>
Motivation: 为了处理具有任意相关结构（包括负边）的图，而无需依赖度量假设或预定义的簇数，并提高聚类算法在真实世界数据和簇大小不平衡场景下的鲁棒性和聚类质量。

Method: 将最初为联盟结构生成设计的量子辅助求解器GCS-Q改编为通过递归分裂划分来最大化带符号图中的簇内一致性。该方法将每个二分步骤编码为通过量子退火求解的二次无约束二元优化问题。

Result: 在合成带符号图和真实世界高光谱成像数据上的经验评估表明，当为相关聚类改编时，GCS-Q在真实世界数据和簇大小不平衡场景下的鲁棒性和聚类质量优于经典算法。

Conclusion: 混合量子-经典优化有望推进可扩展且结构感知的聚类技术在基于图的无监督学习中的应用。

Abstract: This work introduces a hybrid quantum-classical method to correlation
clustering, a graph-based unsupervised learning task that seeks to partition
the nodes in a graph based on pairwise agreement and disagreement. In
particular, we adapt GCS-Q, a quantum-assisted solver originally designed for
coalition structure generation, to maximize intra-cluster agreement in signed
graphs through recursive divisive partitioning. The proposed method encodes
each bipartitioning step as a quadratic unconstrained binary optimization
problem, solved via quantum annealing. This integration of quantum optimization
within a hierarchical clustering framework enables handling of graphs with
arbitrary correlation structures, including negative edges, without relying on
metric assumptions or a predefined number of clusters. Empirical evaluations on
synthetic signed graphs and real-world hyperspectral imaging data demonstrate
that, when adapted for correlation clustering, GCS-Q outperforms classical
algorithms in robustness and clustering quality on real-world data and in
scenarios with cluster size imbalance. Our results highlight the promise of
hybrid quantum-classical optimization for advancing scalable and
structurally-aware clustering techniques in graph-based unsupervised learning.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [382] [A Control Theory inspired Exploration Method for a Linear Bandit driven by a Linear Gaussian Dynamical System](https://arxiv.org/abs/2510.01364)
*Jonathan Gornet,Yilin Mo,Bruno Sinopoli*

Main category: eess.SY

TL;DR: 本文提出了一个在线性有界环境下的探索-利用权衡算法，特别关注于具有已知线性高斯动态系统（LGDS）的奖励。


<details>
  <summary>Details</summary>
Motivation: 在具有已知线性高斯动态系统（LGDS）的奖励的线性有界环境中，解决探索（收集环境信息）与利用（选择具有最高预测奖励的行动）之间的基本挑战。特别地，针对机器学习中的超参数优化问题，其中大的动作空间阻碍了基于乐观原则的方法，因为它们需要探索每个动作以降低奖励预测的不确定性。

Method: 提出了两种算法：卡尔曼滤波置信上限（Kalman-UCB）和信息滤波导向探索行动选择（IDEA）。Kalman-UCB 采用在不确定性面前保持乐观的原则。IDEA 选择最大化预测奖励与量化行动如何最小化卡尔曼滤波状态预测误差的项之和的行动，该误差项取决于 LGDS 的可观察性属性。

Result: 提供了一个基于 LGDS 属性的度量，用于预测 Kalman-UCB 或 IDEA 算法的性能，并通过各种随机生成环境的数值结果进行了验证。

Conclusion: 所提出的算法和度量在具有 LGDS 奖励的线性有界环境中有效地处理了探索-利用权衡问题，并为超参数优化等实际应用提供了见解。

Abstract: The paper introduces a linear bandit environment where the reward is the
output of a known Linear Gaussian Dynamical System (LGDS). In this environment,
we address the fundamental challenge of balancing exploration -- gathering
information about the environment -- and exploitation -- selecting to the
action with the highest predicted reward. We propose two algorithms, Kalman
filter Upper Confidence Bound (Kalman-UCB) and Information filter Directed
Exploration Action-selection (IDEA). Kalman-UCB uses the principle of optimism
in the face of uncertainty. IDEA selects actions that maximize the combination
of the predicted reward and a term that quantifies how much an action minimizes
the error of the Kalman filter state prediction, which depends on the LGDS
property called observability. IDEA is motivated by applications such as
hyperparameter optimization in machine learning. A major problem encountered in
hyperparameter optimization is the large action spaces, which hinder the
performance of methods inspired by principle of optimism in the face of
uncertainty as they need to explore each action to lower reward prediction
uncertainty. To predict if either Kalman-UCB or IDEA will perform better, a
metric based on the LGDS properties is provided. This metric is validated with
numerical results across a variety of randomly generated environments.

</details>


### [383] [Robust Data-Driven Control for Nonlinear Systems Using their Digital Twins and Quadratic Funnels](https://arxiv.org/abs/2510.01406)
*Shiva Shakeri,Mehran Mesbahi*

Main category: eess.SY

TL;DR: 提出了一种数据驱动的方法，利用不完美的数字孪生来安全地部署具有非线性动力学的系统，通过融合数字孪生的标称轨迹和在线数据驱动的不确定性量化来合成鲁棒跟踪控制器。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在为具有非线性动力学的系统在部署过程中提供一种安全的数据驱动方法，特别是在系统模型不完美的情况下。

Method: 研究提出了一种融合数字孪生标称轨迹和在线数据驱动不确定性量化的方法。具体来说，该方法推导出数据驱动的边界来捕捉实际系统与数字孪生所提供的标称轨迹之间的偏差。然后，利用这些时间序列数据，通过线性矩阵不等式来综合二次函数（标称轨迹周围的鲁棒正不变管）。控制器通过分段学习策略进行调整，每个段的控制器都利用前一段的不确定性信息进行综合。

Result: 该方法能够保证约束得到满足，并通过分段学习策略适应真实系统行为，确保了安全性。

Conclusion: 该研究为在具有不完美模型的非线性系统学习控制中获得安全证书建立了一个系统的框架。

Abstract: This paper examines a robust data-driven approach for the safe deployment of
systems with nonlinear dynamics using their imperfect digital twins. Our
contribution involves proposing a method that fuses the digital twin's nominal
trajectory with online, data-driven uncertainty quantification to synthesize
robust tracking controllers. Specifically, we derive data-driven bounds to
capture the deviations of the actual system from its prescribed nominal
trajectory informed via its digital twin. Subsequently, the dataset is used in
the synthesis of quadratic funnels -- robust positive invariant tubes around
the nominal trajectory -- via linear matrix inequalities built on the
time-series data. The resulting controller guarantees constraint satisfaction
while adapting to the true system behavior through a segmented learning
strategy, where each segment's controller is synthesized using uncertainty
information from the previous segment. This work establishes a systematic
framework for obtaining safety certificates in learning-based control of
nonlinear systems with imperfect models.

</details>


### [384] [A New Partial State-Feedback IDA-PBC for Two-Dimensional Nonlinear Systems: Application to Power Converters with Experimental Results](https://arxiv.org/abs/2510.01425)
*Rafael Cisneros,Leyan Fang,Wei He,Romeo Ortega*

Main category: eess.SY

TL;DR: 使用基于庞加莱引理的 IDA-PBC 方法为二维系统设计输出反馈全局稳定控制器，用常微分方程取代了偏微分方程，并应用于 DC-DC 转换器。


<details>
  <summary>Details</summary>
Motivation: 为 IDA-PBC 提供一种新的方法，以克服其在应用中求解匹配偏微分方程的困难，并为 DC-DC 转换器设计全局稳定控制器。

Method: 基于庞加莱引理提出 IDA-PBC 的变体，用常微分方程取代了偏微分方程，并将其应用于 Buck、Boost 和 Buck-Boost 转换器，设计电压反馈控制器，并提出一种自适应版本来识别和处理不确定的负载。

Result: 所提出的方法通过数值模拟和实验验证了其有效性，成功地为 DC-DC 转换器设计了全局稳定控制器，即使在存在不确定负载的情况下也能实现稳定控制。

Conclusion: 基于庞加莱引理的 IDA-PBC 方法为设计全局稳定控制器提供了一种更简单、更有效的方法，尤其适用于 DC-DC 转换器等应用。

Abstract: In this paper we propose a variation of the widely popular
Interconnection-and-Damping-Assigment Passivity-Based Control (IDA-PBC) based
on Poincare's Lemma to design output feedback globally stabilizing controllers
for two dimensional systems. The procedure is constructive and, in comparison
with the classical IDA-PBC, whose application is often stymied by the need to
solve the (infamous) matching partial differential equation (PDE), in this new
method the PDE is replaced by an ordinary differential equation, whose solution
is far simpler. The procedure is then applied for the design of
voltage-feedback controllers for the three most typical DC-to-DC power
converter topologies: the Buck, Boost and Buck-Boost. It is assumed that these
converters feed an uncertain load, which is characterized by a static relation
between its voltage and current. In the case when the load consists of the
parallel connection of a resistive term and a constant power load we propose an
adaptive version of the design, adding an identification scheme for the load
parameters. This allows the controller to regulate the converter output when
the load varies-that is a typical scenario in these applications. Extensive
numerical simulations and experimental results validate the approach.

</details>


### [385] [Comparative Field Deployment of Reinforcement Learning and Model Predictive Control for Residential HVAC](https://arxiv.org/abs/2510.01475)
*Ozan Baris Mulayim,Elias N. Pergantis,Levi D. Reyes Premer,Bingqing Chen,Guannan Qu,Kevin J. Kircher,Mario Bergés*

Main category: eess.SY

TL;DR: RL在节能方面表现出色，但MPC在提供相同舒适度的情况下更胜一筹。


<details>
  <summary>Details</summary>
Motivation: 在实际住宅环境中，模型预测控制(MPC)和强化学习(RL)在供暖、通风和空调(HVAC)系统的节能方面都显示出潜力，但MPC需要大量工程投入，而RL的实际应用却鲜有报道，面临安全、可解释性和样本效率等挑战。因此，有必要直接比较这两种策略在实际应用中的表现。

Method: 将MPC和基于模型的RL控制器分别部署在一个实际的住宅环境中，运行一个月，并与现有的控制器进行比较，以评估它们的节能效果、可扩展性、安全性以及对居住者舒适度的影响。

Result: RL在节能方面（比现有控制器高22%）略优于MPC（高20%），但带来了更高的居住者不适感。然而，当按舒适度进行节能效果的标准化后，MPC的表现更优。RL虽然减少了工程开销，但在模型准确性和运行鲁棒性方面存在实际的权衡。通过此次实际部署，研究人员发现了安全控制器初始化、控制动作与实际执行之间的不匹配以及在线学习的完整性维护等方面的挑战。

Conclusion: RL在实际的HVAC控制中展现了节能潜力，但MPC在能源效率和居住者舒适度之间取得了更好的平衡。该研究强调了在将RL推广为可扩展的HVAC控制解决方案之前，需要解决的关键挑战，包括安全启动、实际执行差异和在线学习的稳定性。

Abstract: Advanced control strategies like Model Predictive Control (MPC) offer
significant energy savings for HVAC systems but often require substantial
engineering effort, limiting scalability. Reinforcement Learning (RL) promises
greater automation and adaptability, yet its practical application in
real-world residential settings remains largely undemonstrated, facing
challenges related to safety, interpretability, and sample efficiency. To
investigate these practical issues, we performed a direct comparison of an MPC
and a model-based RL controller, with each controller deployed for a one-month
period in an occupied house with a heat pump system in West Lafayette, Indiana.
This investigation aimed to explore scalability of the chosen RL and MPC
implementations while ensuring safety and comparability. The advanced
controllers were evaluated against each other and against the existing
controller. RL achieved substantial energy savings (22\% relative to the
existing controller), slightly exceeding MPC's savings (20\%), albeit with
modestly higher occupant discomfort. However, when energy savings were
normalized for the level of comfort provided, MPC demonstrated superior
performance. This study's empirical results show that while RL reduces
engineering overhead, it introduces practical trade-offs in model accuracy and
operational robustness. The key lessons learned concern the difficulties of
safe controller initialization, navigating the mismatch between control actions
and their practical implementation, and maintaining the integrity of online
learning in a live environment. These insights pinpoint the essential research
directions needed to advance RL from a promising concept to a truly scalable
HVAC control solution.

</details>


### [386] [A Robust Neural Control Design for Multi-drone Slung Payload Manipulation with Control Contraction Metrics](https://arxiv.org/abs/2510.01489)
*Xinyuan Liang,Longhao Qian,Yi Lok Lo,Hugh H. T. Liu*

Main category: eess.SY

TL;DR: 该研究提出了一种用于三无人机吊挂载物运输系统的神经控制设计，旨在克服外部干扰并实现路径跟踪。


<details>
  <summary>Details</summary>
Motivation: 为三无人机吊挂载物运输系统设计一种鲁棒的神经控制器，以在存在外部干扰的情况下实现精确的路径跟踪。

Method: 使用控制收缩度量（CCM）生成符合控制输入饱和约束的基线控制器，并结合不确定性和扰动估计器（UDE）技术动态补偿持续存在的扰动。

Result: 该框架实现了模块化设计，控制器和估计器可独立工作，并在满足特定假设的扰动下实现零轨迹跟踪误差。仿真结果证明了该控制设计在复杂轨迹跟踪和外部干扰下的能力。

Conclusion: 所提出的包含CCM控制器和UDE补偿器的完整系统具有良好的稳定性和鲁棒性，能够有效应对三无人机吊挂载物运输系统中的外部干扰。

Abstract: This paper presents a robust neural control design for a three-drone slung
payload transportation system to track a reference path under external
disturbances. The control contraction metric (CCM) is used to generate a neural
exponentially converging baseline controller while complying with control input
saturation constraints. We also incorporate the uncertainty and disturbance
estimator (UDE) technique to dynamically compensate for persistent
disturbances. The proposed framework yields a modularized design, allowing the
controller and estimator to perform their individual tasks and achieve a zero
trajectory tracking error if the disturbances meet certain assumptions. The
stability and robustness of the complete system, incorporating both the CCM
controller and the UDE compensator, are presented. Simulations are conducted to
demonstrate the capability of the proposed control design to follow complicated
trajectories under external disturbances.

</details>


### [387] [Off-Policy Reinforcement Learning with Anytime Safety Guarantees via Robust Safe Gradient Flow](https://arxiv.org/abs/2510.01492)
*Pol Mestres,Arnau Marzabal,Jorge Cortés*

Main category: eess.SY

TL;DR: 本研究提出了一种名为 RSGF-RL 的新算法，用于解决具有任意时间保证的约束强化学习问题，确保在算法的每个迭代步骤都能获得满足约束的策略。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决约束强化学习（RL）问题，并为其提供任意时间保证，即算法的解必须在每次迭代中都能产生满足约束的策略。

Method: RSGF-RL 算法基于连续时间动力学 Robust Safe Gradient Flow（RSGF）的离散化。该算法是一种离策略算法，利用情节数据来估计值函数及其梯度，并通过解决一个凸二次约束二次规划问题来更新策略参数。其技术分析结合了统计分析、随机逼近理论和凸分析。

Result: 通过结合统计分析、随机逼近理论和凸分析，研究确定了确保安全策略更新为安全策略以及从不安全策略恢复所需的足够情节数量，并且能够以任意用户指定的概率实现这些目标。此外，研究还证明了算法几乎肯定地渐近收敛到 RL 问题的 KKT 点集。仿真结果表明，RSGF-RL 在导航示例和倒立摆系统上优于现有技术。

Conclusion: RSGF-RL 算法通过 RSGF 的离散化，能够为约束强化学习提供任意时间保证，并能渐近收敛到 KKT 点集。仿真结果验证了该算法的有效性。

Abstract: This paper considers the problem of solving constrained reinforcement
learning (RL) problems with anytime guarantees, meaning that the algorithmic
solution must yield a constraint-satisfying policy at every iteration of its
evolution. Our design is based on a discretization of the Robust Safe Gradient
Flow (RSGF), a continuous-time dynamics for anytime constrained optimization
whose forward invariance and stability properties we formally characterize. The
proposed strategy, termed RSGF-RL, is an off-policy algorithm which uses
episodic data to estimate the value functions and their gradients and updates
the policy parameters by solving a convex quadratically constrained quadratic
program. Our technical analysis combines statistical analysis, the theory of
stochastic approximation, and convex analysis to determine the number of
episodes sufficient to ensure that safe policies are updated to safe policies
and to recover from an unsafe policy, both with an arbitrary user-specified
probability, and to establish the asymptotic convergence to the set of KKT
points of the RL problem almost surely. Simulations on a navigation example and
the cart-pole system illustrate the superior performance of RSGF-RL with
respect to the state of the art.

</details>


### [388] [Probabilistic Control Barrier Functions: Safety in Probability for Discrete-Time Stochastic Systems](https://arxiv.org/abs/2510.01501)
*Pol Mestres,Blake Werner,Ryan K. Cosner,Aaron D. Ames*

Main category: eess.SY

TL;DR: 该研究提出了一种用于离散时间随机系统的安全控制器设计方法，通过引入概率控制障碍函数（pCBF）来处理不确定性，从而在有限时间内以规定的概率保证安全。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的控制系统面临不可预测的不确定性，这可能导致灾难性的安全故障。本研究旨在为离散时间随机系统设计能够维持概率安全保证的安全控制器。

Method: 本研究提出了一种概率控制障碍函数（pCBF）的概念，这是对传统控制障碍函数（CBF）的修改，用于明确考虑随机不确定性。研究人员利用了多种不确定性量化方法，如集中不等式、场景方法和共形预测，来提供计算上可行的控制器，并具有可调的概率保证。

Result: 研究表明，概率控制障碍函数（pCBF）可用于设计控制器，从而在有限的时间步内以规定的概率保证安全。通过不确定性量化方法，可以得到计算上可行且具有可调概率保证的控制器。

Conclusion: 本研究提出的概率控制障碍函数（pCBF）方法能够为离散时间随机系统设计出在有限时间内具有可调概率保证的安全控制器，并在仿真和机器人控制的实际硬件中得到了验证。

Abstract: Control systems operating in the real world face countless sources of
unpredictable uncertainties. These random disturbances can render deterministic
guarantees inapplicable and cause catastrophic safety failures. To overcome
this, this paper proposes a method for designing safe controllers for
discrete-time stochastic systems that retain probabilistic guarantees of
safety. To do this we modify the traditional notion of a control barrier
function (CBF) to explicitly account for these stochastic uncertainties and
call these new modified functions probabilistic CBFs. We show that
probabilistic CBFs can be used to design controllers that guarantee safety over
a finite number of time steps with a prescribed probability. Next, by
leveraging various uncertainty quantification methods, such as concentration
inequalities, the scenario approach, and conformal prediction, we provide a
variety of sufficient conditions that result in computationally tractable
controllers with tunable probabilistic guarantees across a plethora of
practical scenarios. Finally, we showcase the applicability of our results in
simulation and hardware for the control of a quadruped robot.

</details>


### [389] [Cooperative Guidance for Aerial Defense in Multiagent Systems](https://arxiv.org/abs/2510.02087)
*Shivam Bajpai,Abhinav Sinha,Shashi Ranjan Kumar*

Main category: eess.SY

TL;DR: 本文提出了一种合作制导框架，用于保护高价值无人机免受敌方无人机的攻击，该框架能够在动态和不确定的条件下保证拦截。


<details>
  <summary>Details</summary>
Motivation: 在竞争激烈的空域中，保护高价值无人机免受敌方无人机的攻击是一个关键的空中防御挑战。

Method: 采用一种基于时间约束的制导框架，利用真实比例导航方法，来实现对敌方无人机的拦截。

Result: 所提出的策略计算量小，可扩展性强，并且不需要了解敌方无人机的策略。在各种模拟场景下，该方法都能保证在固定时间内将关键的交战误差降至零，从而成功完成拦截任务。

Conclusion: 该合作制导框架为应对空中防御挑战提供了一种有效且可靠的解决方案，适用于实时自主防御。

Abstract: This paper addresses a critical aerial defense challenge in contested
airspace, involving three autonomous aerial vehicles -- a hostile drone (the
pursuer), a high-value drone (the evader), and a protective drone (the
defender). We present a cooperative guidance framework for the evader-defender
team that guarantees interception of the pursuer before it can capture the
evader, even under highly dynamic and uncertain engagement conditions. Unlike
traditional heuristic, optimal control, or differential game-based methods, we
approach the problem within a time-constrained guidance framework, leveraging
true proportional navigation based approach that ensures robust and guaranteed
solutions to the aerial defense problem. The proposed strategy is
computationally lightweight, scalable to a large number of agent
configurations, and does not require knowledge of the pursuer's strategy or
control laws. From arbitrary initial geometries, our method guarantees that key
engagement errors are driven to zero within a fixed time, leading to a
successful mission. Extensive simulations across diverse and adversarial
scenarios confirm the effectiveness of the proposed strategy and its relevance
for real-time autonomous defense in contested airspace environments.

</details>


### [390] [A Scalable Design Approach to Resilient Architectures for Interconnected Cyber-Physical Systems: Safety Guarantees under Multiple Attacks](https://arxiv.org/abs/2510.01541)
*Eman Badr,Abdullah Al Maruf*

Main category: eess.SY

TL;DR: 本研究提出了一种可扩展的框架，用于为互联网络物理系统（CPS）分配弹性架构并调整其恢复时间，以应对多子系统同时或按任意顺序发生的网络攻击，并保证系统安全。


<details>
  <summary>Details</summary>
Motivation: 扩展现有网络弹性架构的恢复时间保证方法至互联CPS面临挑战，因其需考虑多子系统攻击的任意顺序和时间重叠。本研究旨在解决这一挑战。

Method: 提出一个标量指标量化每个子系统在受损输入下对安全的影响，该指标可线性聚合，以支持可扩展分析。建立一个线性不等式，将子系统指标和恢复时间关联起来，以保证安全并指导弹性架构分配。提出一种基于分段的方法来加强条件，并开发算法来计算指标和寻找成本最优的架构分配。

Result: 通过一个关于互联房间温度调节的案例研究，在不同攻击场景下验证了该框架的有效性。

Conclusion: 本研究提出的框架能够有效地为互联CPS分配弹性架构并调整恢复时间，以应对复杂的网络攻击，并保证系统的安全性。

Abstract: Complex, interconnected cyber-physical systems (CPS) are increasingly
prevalent in domains such as power systems. Cyber-resilient architectures have
been proposed to recover compromised cyber components of CPS. Recent works have
studied tuning the recovery times of such architectures to guarantee safety in
single-system settings. Extending these designs to interconnected CPS is more
challenging, since solutions must account for attacks on multiple subsystems
that can occur in any order and potentially infinite possible temporal overlap.
This paper aims to address the aforementioned challenge by developing a
scalable framework to assign resilient architectures and to inform the tuning
of their recovery times. Our approach introduces a scalar index that quantifies
the impact of each subsystem on safety under compromised input. These indices
aggregate linearly across subsystems, enabling scalable analysis under
arbitrary attack orderings and temporal overlaps. We establish a linear
inequality relating each subsystem's index and recovery time that guarantees
safety and guides resilient architecture assignment. We also propose a
segmentation-based approach to strengthen the previously derived conditions. We
then present algorithms to compute the proposed indices and to find a
cost-optimal architecture assignment with a safety guarantee. We validate the
framework through a case study on temperature regulation in interconnected
rooms under different attack scenarios.

</details>


### [391] [Stability and Robustness of Time-Varying Opinion Dynamics: A Graph-Theoretic Approach](https://arxiv.org/abs/2510.01580)
*M. Hossein Abedinzadeh,Emrah Akyol*

Main category: eess.SY

TL;DR: 在时变Friedkin-Johnsen (TVFJ)模型中，我们研究了意见动态的稳定性，该模型同时考虑了持久的个体偏见和自适应的社会影响。我们引入了两种时间结构——缺陷时间图（DTGs）和弱缺陷时间图（WDTGs），它们作为图论证书，将顽固影响和时间连通性与状态转移矩阵的收缩联系起来。利用这些工具，我们证明了TVFJ动态在无限递归DTGs下的渐近稳定性、在半周期缺陷网络中的指数稳定性，以及在更弱的递归WDTGs条件下的信任扩展的渐近稳定性。我们还确定了omega极限集的有界性，表明长期意见保持在先天信念的凸包内，并通过p-LTI分解刻画了周期性切换系统的极限集，其omega极限集的大小最多为p。最后，我们证明了指数稳定性在有界扰动下仍然存在，确保了在嘈杂或不完善网络中的鲁棒性。这些结果将代数收缩检验与可解释的基于图的推理统一起来，为分析演化中的社会和人机网络中的意见形成提供了可扩展且有弹性的工具。


<details>
  <summary>Details</summary>
Motivation: 研究时变Friedkin-Johnsen (TVFJ)模型中意见动态的稳定性，该模型考虑了持久的个体偏见和自适应的社会影响。

Method: 引入了缺陷时间图（DTGs）和弱缺陷时间图（WDTGs）两种时间结构，并利用它们来证明TVFJ动态在不同条件下的稳定性。建立了omega极限集的有界性，并通过p-LTI分解刻画了周期性切换系统的极限集。研究了在有界扰动下的稳定性。

Result: 证明了TVFJ动态在无限递归DTGs下的渐近稳定性、在半周期缺陷网络中的指数稳定性，以及在更弱的递归WDTGs条件下的信任扩展的渐近稳定性。确定了omega极限集的有界性，表明长期意见保持在先天信念的凸包内。通过p-LTI分解刻画了周期性切换系统的极限集，并给出了omega极限集大小的上界。证明了指数稳定性在有界扰动下仍然存在。

Conclusion: 这些结果统一了代数收缩检验与可解释的基于图的推理，为分析演化中的社会和人机网络中的意见形成提供了可扩展且有弹性的工具。

Abstract: We study the stability of opinion dynamics in the time-varying
Friedkin-Johnsen (TVFJ) model, which captures both persistent individual biases
and adaptive social influence. We introduce two temporal structures, defected
temporal graphs (DTGs) and weakly defected temporal graphs (WDTGs), that serve
as graph-theoretic certificates linking stubborn influence and temporal
connectivity to contraction of the state-transition matrix. Using these tools,
we prove asymptotic stability of TVFJ dynamics under infinitely recurring DTGs,
exponential stability in semi-periodic defected networks, and asymptotic
stability of a trust-based extension under the weaker condition of recurring
WDTGs. We also establish boundedness of the omega-limit set, showing that
long-run opinions remain within the convex hull of innate beliefs, and
characterize the limit set for periodically switching systems via a p-LTI
decomposition with the tight bound that the size of the omega-limit set is at
most p. Finally, we show that exponential stability persists under bounded
perturbations, ensuring robustness in noisy or imperfect networks. These
results unify algebraic contraction tests with interpretable graph-based
reasoning, providing scalable and resilient tools for analyzing opinion
formation in evolving social and human-AI networks.

</details>


### [392] [A TSO-DSO Coordination Framework via Analytical Representation and Monetization of PQV-Based Distribution System Flexibility](https://arxiv.org/abs/2510.01854)
*Burak Dindar,Can Berk Saner,Hüseyin Kemal Çakmak,Veit Hagenmeyer*

Main category: eess.SY

TL;DR: 为应对数据隐私问题，提出一种基于交流最优潮流（AC OPF）的三维PQV-FOR（可行操作区域）构建方法，通过双阶段采样策略和隐式多项式拟合进行解析表示，并推导二次成本函数以实现FOR的经济估值。该方法能够实现单轮次输电系统 operator (TSO) 和配电系统 operator (DSO) 协调， DSO 提供解析FOR和成本模型，TSO 在FOR约束下进行OPF计算，DSO 通过求解局部OPF来调度柔性电源单元（FPU），从而在保证数据隐私的前提下，提高TSO网络管理的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 配电系统（DS）灵活性在输电系统 operator (TSO) 网络管理中的作用日益重要，但数据隐私问题阻碍了其互操作性。可行操作区域（FOR）作为一种有前景的隐私保护方法，但其在TSO运营中的有效利用面临挑战，主要源于大规模、网状DS网络中FOR的准确确定、FOR的可解析表示以及其经济估值问题。

Method: 提出一种基于交流最优潮流（AC OPF）的新方法来构建三维PQV-FOR，明确考虑了电压变动和不同柔性电源单元（FPU）的特性。该方法采用双阶段采样策略（结合边界盒投影和斐波那契方向技术）来高效捕获FOR。然后，引入隐式多项式拟合方法来解析表示FOR。此外，推导了一个在PQV域上的二次成本函数来对FOR进行货币化估值。

Result: 在多达533个节点的网状DS上进行的案例研究表明，与标准的AC OPF相比，该方法的效率有所提高。在测试案例中，所提出的方法产生的成本偏差平均最大为0.058%，同时计算时间减少了多达58.11%。

Conclusion: 所提出的框架实现了单轮次的TSO-DSO协调：DSO提供解析FOR和成本模型；TSO在基于FOR的AC-OPF中确定公共连接点（PCC）的运行点；DSO通过求解其局部OPF来计算FPU调度，无需进行计算密集的分拆或迭代协调。该方法在保证数据隐私的前提下，有效解决了DS灵活性在TSO网络管理中的利用问题。

Abstract: As the role of distribution system (DS) flexibility in transmission system
operator (TSO) network management becomes increasingly vital, data privacy
concerns hinder seamless interoperability. The notion of the feasible operating
region (FOR), defined in the PQ domain, has emerged as a promising
privacy-preserving approach. However, effectively leveraging FOR in TSO
operations remains challenging due to three key factors: its accurate
determination in large-scale, meshed DS networks; its tractable analytical
representation; and its economic valuation. In the present paper, we propose a
novel AC optimal power flow (OPF)-based method to construct a three-dimensional
PQV-FOR, explicitly accounting for voltage variability and diverse
flexibility-providing unit (FPU) characteristics. The construction process
employs a two-stage sampling strategy that combines bounding box projection and
Fibonacci direction techniques to efficiently capture the FOR. We then
introduce an implicit polynomial fitting approach to analytically represent the
FOR. Furthermore, we derive a quadratic cost function over the PQV domain to
monetize the FOR. Thus, the proposed framework enables single-round TSO-DSO
coordination: the DSO provides an analytical FOR and cost model; the TSO
determines operating point at the point of common coupling (PCC) within the
FOR-based AC-OPF; and the DSO computes FPU dispatch by solving its local OPF,
without computationally intensive disaggregation or iterative coordination.
Case studies on meshed DS with up to 533 buses, integrated into TS,
demonstrates the method's efficiency compared to standard AC-OPF. On average,
the proposed approach yields negligible cost deviations of at most 0.058%
across test cases, while reducing computation times by up to 58.11%.

</details>


### [393] [Coordinated Car-following Using Distributed MPC](https://arxiv.org/abs/2510.02010)
*Di Shen,Qi Dai,Suzhou Huang*

Main category: eess.SY

TL;DR: 提出了一种基于分布式模型预测控制（DMPC）的协同跟车算法，该算法直接优化驾驶策略而非跟踪预定轨迹，并能近似纳什均衡或集中优化。


<details>
  <summary>Details</summary>
Motivation: 在马尔可夫博弈模型框架下，为协同跟车问题提出分布式模型预测控制（DMPC）算法，旨在直接优化驾驶策略以提高效率并抑制交通波。

Method: 使用DMPC优化驾驶策略，通过最佳响应动态和迭代自我博弈（包括智能体间或与基础设施的通信）来推导协同解。通过将DMPC中的动作序列重新参数化为规划视界上的曲线，将问题转化为网格搜索。将交通控制问题视为机制设计问题。

Result: 通过协同跟车算法，在保持交通波（stop-and-go phantom waves）得到抑制的同时，显著提高了交通效率，尤其是在高车辆密度下。证明了线性稳定性分析的局限性。

Conclusion: 所提出的DMPC方法提供了一种无需显式编队（或将所有车辆视为单一扩展编队）即可制定协同自适应巡航控制（CACC）的替代方案，并在高密度交通中实现了效率和稳定性的显著改进。

Abstract: Within the modeling framework of Markov games, we propose a series of
algorithms for coordinated car-following using distributed model predictive
control (DMPC). Instead of tracking prescribed feasible trajectories, driving
policies are solved directly as outcomes of the DMPC optimization given the
driver's perceivable states. The coordinated solutions are derived using the
best response dynamics via iterated self-play, and are facilitated by direct
negotiation using inter-agent or agent-infrastructure communication. These
solutions closely approximate either Nash equilibrium or centralized
optimization. By re-parameterizing the action sequence in DMPC as a curve along
the planning horizon, we are able to systematically reduce the original DMPC to
very efficient grid searches such that the optimal solution to the original
DMPC can be well executed in real-time. Within our modeling framework, it is
natural to cast traffic control problems as mechanism design problems, in which
all agents are endogenized on an equal footing with full incentive
compatibility. We show how traffic efficiency can be dramatically improved
while keeping stop-and-go phantom waves tamed at high vehicle densities. Our
approach can be viewed as an alternative way to formulate coordinated adaptive
cruise control (CACC) without an explicit platooning (or with all vehicles in
the traffic system treated as a single extended platoon). We also address the
issue of linear stability of the associated discrete-time traffic dynamics and
demonstrate why it does not always tell the full story about the traffic
stability.

</details>


### [394] [Event-triggered control and communication for single-master multi-slave teleoperation systems with Try-Once-Discard protocol](https://arxiv.org/abs/2510.02072)
*Yuling Li,Chenxi Li,Kun Liu,Jie Dong,Rolf Johansson*

Main category: eess.SY

TL;DR: 单主多从遥操作系统的带宽受限问题，提出结合事件触发和TOD协议的策略，通过自适应控制器和虚拟观察器实现主从同步，并排除芝诺行为。


<details>
  <summary>Details</summary>
Motivation: 单主多从（SMMS）遥操作系统因其在多任务处理、大范围覆盖和故障适应性方面的优势而有广泛应用，但随着从属设备增多，通信带宽成为瓶颈。

Method: 结合事件触发机制和尝试一次丢弃（TOD）调度协议，提出适用于SMMS遥操作系统的事件触发控制和通信方案。利用基于事件触发方案的自适应控制器和虚拟观察器来处理动态不确定性、相对速度不可用和时变延迟，以实现主从同步。

Result: 证明了所提出的事件触发控制和通信方案的稳定性，并排除了芝诺行为。

Conclusion: 通过实验验证了所提出的结合事件触发和TOD协议的算法在SMMS遥操作系统中优化网络带宽和能耗的有效性。

Abstract: Single-master multi-slave (SMMS) teleoperation systems can perform multiple
tasks remotely in a shorter time, cover large-scale areas, and adapt more
easily to single-point failures, thereby effectively encompassing a broader
range of applications. As the number of slave manipulators sharing a
communication network increases, the limitation of communication bandwidth
becomes critical. To alleviate bandwidth usage, the Try-Once-Discard (TOD)
scheduling protocol and event-triggered mechanisms are often employed
separately. In this paper, we combine both strategies to optimize network
bandwidth and energy consumption for SMMS teleoperation systems. Specifically,
we propose event-triggered control and communication schemes for a class of
SMMS teleoperation systems using the TOD scheduling protocol. Considering
dynamic uncertainties, the unavailability of relative velocities, and
time-varying delays, we develop adaptive controllers with virtual observers
based on event-triggered schemes to achieve master-slave synchronization.
Stability criteria for the SMMS teleoperation systems under these
event-triggered control and communication schemes are established,
demonstrating that Zeno behavior is excluded. Finally, experiments are
conducted to validate the effectiveness of the proposed algorithms.

</details>


### [395] [Recurrent Control Barrier Functions: A Path Towards Nonparametric Safety Verification](https://arxiv.org/abs/2510.02127)
*Jixian Liu,Enrique Mallada*

Main category: eess.SY

TL;DR: 引入了循环控制屏障函数（RCBF），一种利用轨迹循环特性来验证安全性的新型CBF方法，可以将函数设计转化为集合识别，并且集合不必保持不变。


<details>
  <summary>Details</summary>
Motivation: 现有安全验证方法（如HJ Reachability和CBF）在计算上负担重，特别是对于高维系统，需要求解偏微分方程或半定规划。

Method: 提出循环控制屏障函数（RCBF），它利用了系统轨迹“回到安全集”的循环特性。在温和假设下，证明了符号距离函数满足RCBF条件，从而将函数设计问题转化为集合识别问题。此外，提出了一种数据驱动的非参数方法来计算安全集，该方法可大规模并行化，并允许在保守性与计算成本之间进行权衡。

Result: RCBF条件可以应用于符号距离函数，将函数设计问题转化为集合识别问题。RCBF方法在验证安全性时，其对应的安全集不必保持不变。所提出的数据驱动方法是可大规模并行化的。

Conclusion: RCBF是一种利用轨迹循环特性进行安全验证的新型CBF方法，它简化了函数设计过程，并放宽了对安全集不变性的要求。此外，提供了一种可扩展的数据驱动计算方法。

Abstract: Ensuring the safety of complex dynamical systems often relies on
Hamilton-Jacobi (HJ) Reachability Analysis or Control Barrier Functions (CBFs).
Both methods require computing a function that characterizes a safe set that
can be made (control) invariant. However, the computational burden of solving
high-dimensional partial differential equations (for HJ Reachability) or
large-scale semidefinite programs (for CBFs) makes finding such functions
challenging. In this paper, we introduce the notion of Recurrent Control
Barrier Functions (RCBFs), a novel class of CBFs that leverages a recurrent
property of the trajectories, i.e., coming back to a safe set, for safety
verification. Under mild assumptions, we show that the RCBF condition holds for
the signed-distance function, turning function design into set identification.
Notably, the resulting set need not be invariant to certify safety. We further
propose a data-driven nonparametric method to compute safe sets that is
massively parallelizable and trades off conservativeness against computational
cost.

</details>


### [396] [Detection and Identification of Sensor Attacks Using Data](https://arxiv.org/abs/2510.02183)
*Takumi Shinohara,Karl H. Johansson,Henrik Sandberg*

Main category: eess.SY

TL;DR: 该论文提出了一种在无模型情况下，仅利用包含恶意虚假数据注入的受损数据来检测和识别攻击的方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常假设可用数据是干净的，而本研究考虑了数据中包含恶意虚假数据注入的更具挑战性的情况。

Method: 在两种场景下（系统算子知晓稀疏可观测性条件，以及数据部分干净）推导出仅使用受损数据进行攻击检测和识别的条件和算法。

Result: 通过在三惯性系统上的数值模拟，验证了所提出框架的有效性。

Conclusion: 提出了一种在存在虚假数据注入的情况下，仅使用受损数据进行攻击检测和识别的框架。

Abstract: In this paper, we investigate data-driven attack detection and identification
in a model-free setting. Unlike existing studies, we consider the case where
the available output data include malicious false-data injections. We aim to
detect and identify such attacks solely from the compromised data. We address
this problem in two scenarios: (1) when the system operator is aware of the
system's sparse observability condition, and (2) when the data are partially
clean (i.e., attack-free). In both scenarios, we derive conditions and
algorithms for detecting and identifying attacks using only the compromised
data. Finally, we demonstrate the effectiveness of the proposed framework via
numerical simulations on a three-inertia system.

</details>


### [397] [Computing Control Lyapunov-Barrier Functions: Softmax Relaxation and Smooth Patching with Formal Guarantees](https://arxiv.org/abs/2510.02223)
*Jun Liu,Maxwell Fitzsimmons*

Main category: eess.SY

TL;DR: 提出一种计算框架，用于合成单个光滑李雅普诺夫函数，以证明渐近稳定性和安全性。该框架通过CBF-CLF兼容性保证了光滑李雅普诺夫函数在由障碍物认证的安全集上存在，并使用log-sum-exp（softmax）松弛和反例引导的细化来最大化可认证的安全域。最终，通过显式的光滑凸起构造将softmax障碍物与CLF进行修复，该构造在严格兼容性条件下总是可行的。所有条件均通过SMT求解器形式化验证。


<details>
  <summary>Details</summary>
Motivation: 需要一个单一的光滑李雅普诺夫函数来同时证明系统的渐近稳定性和安全性，并希望最大化可认证的安全域。

Method: 提出一个计算框架，通过CBF-CLF兼容性保证光滑李雅普诺夫函数在安全集上存在。使用log-sum-exp（softmax）松弛和反例引导的细化来最大化可认证的安全域。通过显式的光滑凸起构造将softmax障碍物与CLF进行修复。使用SMT求解器进行形式化验证。

Result: 在包括电源转换器在内的基准系统上，所提出的方法获得的认证安全稳定区域通常比最先进的平方和（SOS）兼容CBF-CLF设计实现的区域更不保守。

Conclusion: 所提出的计算框架能够合成单一光滑李雅普诺夫函数，用于同时证明渐近稳定性和安全性，并且在安全域的认证方面优于现有方法。

Abstract: We present a computational framework for synthesizing a single smooth
Lyapunov function that certifies both asymptotic stability and safety. We show
that the existence of a strictly compatible pair of control barrier and control
Lyapunov functions (CBF-CLF) guarantees the existence of such a function on the
exact safe set certified by the barrier. To maximize the certifiable safe
domain while retaining differentiability, we employ a log-sum-exp (softmax)
relaxation of the nonsmooth maximum barrier, together with a
counterexample-guided refinement that inserts half-space cuts until a strict
barrier condition is verifiable. We then patch the softmax barrier with a CLF
via an explicit smooth bump construction, which is always feasible under the
strict compatibility condition. All conditions are formally verified using a
satisfiability modulo theories (SMT) solver, enabled by a reformulation of
Farkas' lemma for encoding strict compatibility. On benchmark systems,
including a power converter, we show that the certified safe stabilization
regions obtained with the proposed approach are often less conservative than
those achieved by state-of-the-art sum-of-squares (SOS) compatible CBF-CLF
designs.

</details>


### [398] [Game-theoretic Social Distancing in Competitive Bi-Virus SIS Epidemics](https://arxiv.org/abs/2510.02269)
*Benjamin Catalano,Keith Paarporn,Sebin Gracy*

Main category: eess.SY

TL;DR: 多种病毒株（例如 SARS-CoV-2 的 Delta 和 Omicron 变体）在同一人群中传播时，会受到社会行为（例如社交距离）的影响，并且这种行为会随着疾病的传播而演变。本研究提出了一个结合了博弈论社会距离行为模型的双病毒 SIS 流行病学模型，并通过分析揭示了各种均衡点及其稳定性，发现只有当两种病毒株的再生数相等时，才可能出现地方性共存，并确定了出现共存均衡线以及这些线的局部指数稳定性所需的参数范围。


<details>
  <summary>Details</summary>
Motivation: 识别在复杂网络中影响传染病传播的因素，特别是社会行为如何与疾病传播同步演变，以及了解多种病毒株（如 SARS-CoV-2 的 Delta 和 Omicron 变体）如何同时在人群中传播。

Method: 提出一个双病毒 SIS 流行病模型，并耦合一个基于博弈论的社会距离行为模型。社会行为由进化博弈论中的复制子方程控制。每种病毒株的流行度会影响个体采取社交距离的决策，而这种行为反过来又会影响 SIS 模型中每种病毒的传播。分析了系统的均衡点及其局部稳定性。

Result: 识别了系统的均衡点及其局部稳定性特征，发现了具有不同社交距离水平的多个孤立固定点。研究发现，只有当两种病毒株的再生数相等时，才可能出现地方性共存。在假设两种病毒株的再生数相同的情况下，研究确定了产生共存均衡线的合适参数范围，并确定了这些均衡线的局部指数稳定性条件。

Conclusion: 当两种病毒株的再生数相等时，可能出现地方性共存，并且存在共存均衡的线。研究还确定了这些线的局部指数稳定性条件，并辅以数值模拟来说明研究结果。

Abstract: Numerous elements drive the spread of infectious diseases in complex
real-world networks. Of particular interest is social behaviors that evolve in
tandem with the spread of disease. Moreover, recent studies highlight the
importance of understanding how multiple strains spread simultaneously through
a population (e.g. Delta and Omicron variants of SARS-CoV-2). In this paper, we
propose a bi-virus SIS epidemic model coupled with a game-theoretic social
distancing behavior model. The behaviors are governed by replicator equations
from evolutionary game theory. The prevalence of each strain impacts the choice
of an individual to social distance, and, in turn, their behavior affects the
spread of each virus in the SIS model. Our analysis identifies equilibria of
the system and their local stability properties, which reveal several isolated
fixed points with varying levels of social distancing. We find that endemic
co-existence is possible only when the reproduction numbers of both strains are
equal. Assuming the reproduction number for each virus is the same, we identify
suitable parameter regimes that give rise to lines of coexistence equilibria.
Moreover, we also identify conditions for local exponential stability of said
lines of equilibria. We illustrate our findings with several numerical
simulations.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [399] [Tensegrity structures and data-driven analysis for 3d cell mechanics](https://arxiv.org/abs/2510.01604)
*Ziran Zhou,Jacinto Ulloa,Guruswami Ravichandran,Jose E. Andrade*

Main category: physics.app-ph

TL;DR: 本文提出了一种基于有限元法的 3D 张力结构模型，用于模拟细胞力学，并介绍了多尺度数据驱动框架以优化计算。


<details>
  <summary>Details</summary>
Motivation: 细胞骨架在细胞功能中起着重要作用，但现有基于张力结构的细胞力学模型因其低对称性而难以分析真实的 3D 结构。

Method: 提出了一种基于有限元法的 3D 张力结构模型，并引入了一个多尺度数据驱动框架。

Result: 该模型能够模拟单细胞压痕试验、单层细胞拉伸试验的非线性行为，以及多细胞球状体在非均匀预应力设计下的不均匀应力分布。

Conclusion: 该模型为模拟器官等大型细胞组件的力学生物学提供了可能性。

Abstract: The cytoskeleton (CSK) plays an important role in many cell functions. Given
the similarities between the mechanical behavior of tensegrity structures and
the CSK, many studies have proposed different tensegrity-based models for
simulating cell mechanics. However, the low symmetry of most tensegrity units
has hindered the analysis of realistic 3D structures. As a result,
tensegrity-based modeling in cell mechanics has been mainly focused on single
cells or monolayers. In this paper, we propose a 3D tensegrity model based on
the finite element method for simulating 3D cell mechanics. We show that the
proposed model not only captures the nonlinearity of a single cell in an
indentation test and a monolayer in stretch test but also the non-uniform
stress distribution in multicellular spheroids upon non-uniform prestress
design. Furthermore, we introduce a multiscale data-driven framework for
cellular mechanics to optimize the computation, thus paving the way for
modeling the mechanobiology of large cellular assemblies such as organs.

</details>


### [400] [Experimental Investigation of Skew Wind Effects on Vortex-Induced Vibration of Typical Bridge Decks](https://arxiv.org/abs/2510.01772)
*Guangzhong Gao,Pengwei Zhang,Wenkai Du,Yonghui Xie,Pengjie Ren,Xiaofeng Xue*

Main category: physics.app-ph

TL;DR: 风偏角度影响桥梁甲板的涡激振动，独立性原理不适用，并观察到抬升-扭转耦合现象，提出了修正峰值涡激振动振幅的数值算法，最不利的涡激振动响应发生在风偏条件下。


<details>
  <summary>Details</summary>
Motivation: 研究风偏对两种典型桥梁甲板（封闭箱梁和双边梁）涡激振动（VIV）的影响。

Method: 使用弹簧悬挂斜截面模型在不同风偏角和攻角下进行实验，并引入一种新的数值算法来修正峰值涡激振动振幅。

Result: 涡激振动振幅和锁定范围随风偏角变化，不满足独立性原理。观察到抬升-扭转耦合现象。最不利的涡激振动响应发生在风偏条件下，与正常风条件相比，封闭箱梁的抬升涡激振动和扭转涡激振动分别增加了约 20.1% 和 179.8%，双边梁的抬升涡激振动增加了 3.9%。

Conclusion: 风偏角显著影响桥梁甲板的涡激振动响应，独立性原理在此类结构中不适用。抬升-扭转耦合现象是由于重心的偏心引起的。所提出的数值算法可用于修正风偏条件下的涡激振动响应。

Abstract: This study explores the skew wind effects on vortex-induced vibration (VIV)
of two typical bridge decks-a closed-box girder and a twin-edge girder-through
spring-suspended oblique section model tests. Experiments were conducted at
various wind yaw angles and angles of attack. Results indicate that VIV
amplitudes and lock-in ranges exhibit a clear variation with yaw angles,
rendering the Independence Principle (IP) unsuitable for these configurations.
A heave-torsion coupling phenomenon was observed in both heaving and torsional
VIV, attributed to the eccentricity of the center of gravity due to asymmetric
end segments. A novel numerical algorithm was introduced to correct peak VIV
amplitudes for variations in structural mass-damping parameters across yaw
angles. The most unfavorable VIV responses occurred under skew wind conditions,
with maximum amplitudes increasing by approximately 20.1 percent for heaving
VIV and 179.8 percent for torsional VIV in the closed-box girder, and by 3.9
percent for heaving VIV in the twin-edge girder, relative to normal wind
conditions.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [401] [Odontoceti: Ultra-Fast DAG Consensus with Two Round Commitment](https://arxiv.org/abs/2510.01216)
*Preston Vander Vos*

Main category: cs.DC

TL;DR: Odontoceti是一个新的基于DAG的共识协议，通过降低容错率来提高区块链的可扩展性，实现了低延迟（中位数300毫秒）和高吞吐量（10,000 TPS），在实际网络条件下比现有协议有显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 用户期望区块链具有高可扩展性，能够快速处理交易。Odontoceti旨在通过优化共识协议来满足这一需求。

Method: Odontoceti是一个基于DAG的共识协议，具有n = 5f + 1个验证者，并采用新颖的区块确认决策规则。它将容错率从33%降低到20%，并将通信轮数从三轮减少到两轮。协议还包含一项优化，可在参与者响应缓慢时促进进展，特别有利于崩溃容错场景。

Result: Odontoceti实现了200-500毫秒的中位数延迟和10,000 TPS的吞吐量。与现有协议相比，延迟提高了20-25%。

Conclusion: 通过降低容错率（从33%降低到20%），Odontoceti在保持可接受的安全性水平的同时，显著提高了区块链的可扩展性。该研究证明了较低容错率共识协议在区块链中的实际可行性。

Abstract: Users of blockchains value scalability, expecting fast confirmations and
immediate transaction processing. Odontoceti, the latest in DAG-based
consensus, addresses these concerns by prioritizing low latency and high
throughput, making a strategic trade-off in security by operating with a 20%
fault tolerance instead of the established 33% level. It is the first DAG-based
protocol to achieve commitment in just two communication rounds, delivering
median latency of 300 milliseconds while processing 10,000 transactions per
second under realistic network conditions. Odontoceti operates with n = 5f + 1
validators and creates an uncertified DAG with a novel decision rule for
committing blocks. The protocol includes an optimization that advances progress
when participants are slow, benefiting crash fault scenarios which are more
common in practice than Byzantine faults. Evaluation results demonstrate 20-25%
latency improvements compared to an existing production protocol, validating
that reducing wave length from three rounds to two rounds yields meaningful
performance benefits. This paper establishes the practical viability of lower
fault tolerance consensus protocols for blockchains.

</details>


### [402] [Kant: An Efficient Unified Scheduling System for Large-Scale AI Clusters](https://arxiv.org/abs/2510.01256)
*Lingling Zeng,Gen Zhang,Jialin Peng,Xiang Xu,Yuan Xu,Lijun Ma*

Main category: cs.DC

TL;DR: Kant是一个支持训练和推理任务的AI集群调度平台，通过优化调度策略显著提高了资源利用率和调度效率，并减少了资源碎片。


<details>
  <summary>Details</summary>
Motivation: 传统的调度系统在支持不断增长的大规模AI集群训练和推理负载方面面临资源利用率、调度效率和服务质量的挑战。

Method: 提出并实现了一个名为Kant的高效统一调度平台，该平台支持AI容器集群，并能对训练和推理任务进行协同调度。通过采用Backfill和增强型Binpack（E-Binpack）等调度策略来优化性能。

Result: Kant在从数百到数万个GPU的集群中表现出卓越的性能，显著提高了资源利用率和调度效率，有效减少了资源碎片和分布式训练的通信开销。

Conclusion: Kant为构建高性能、高可用性的AI原生调度基础设施提供了一种实用的工程方法，并通过了实际部署的验证。

Abstract: As AI cluster sizes continue to expand and the demand for
large-language-model (LLM) training and inference workloads grows rapidly,
traditional scheduling systems face significant challenges in balancing
resource utilization, scheduling efficiency, and service quality. This paper
presents and evaluates Kant: an efficient unified scheduling platform designed
for large-scale AI container clusters, supporting the co-scheduling of both
training and inference jobs. Based on the practical implementation of the Kant
system, we systematically define a set of key evaluation metrics for AI
clusters, including GPU Allocation Ratio (GAR), Scheduling Occupancy Rate
(SOR), GPU Node Fragmentation Ratio (GFR), Job Waiting Time Distribution
(JWTD), and Job Training Time Estimation Distribution (JTTED), providing a
foundation for quantitative performance analysis. Experimental results
demonstrate that Kant achieves exceptional performance in clusters ranging from
hundreds to tens of thousands of GPUs. By leveraging scheduling strategies such
as Backfill and Enhanced Binpack (E-Binpack), the system significantly improves
resource utilization and scheduling efficiency, while effectively reducing
resource fragmentation and communication overhead in distributed training. The
system has been deployed in multiple AI data center clusters, where it stably
supports large-scale intelligent computing workloads. This work provides a
practical engineering approach for building high-performance, highly available,
AI-native scheduling infrastructure.

</details>


### [403] [IoT-MCP: Bridging LLMs and IoT Systems Through Model Context Protocol](https://arxiv.org/abs/2510.01260)
*Ningyuan Yang,Guanliang Lyu,Mingchen Ma,Yiyi Lu,Yiming Li,Zhihui Gao,Hancheng Ye,Jianyi Zhang,Tingjun Chen,Yiran Chen*

Main category: cs.DC

TL;DR: LLM与IoT集成面临硬件异构和控制复杂性挑战。本文提出IoT-MCP框架，通过边缘服务器实现MCP，连接LLM和IoT。引入IoT-MCP Bench基准，包含114个基础任务和1140个复杂任务，用于LLM-IoT评估。实验证明IoT-MCP在任务成功率、响应时间和内存占用方面表现优异。


<details>
  <summary>Details</summary>
Motivation: LLM与IoT的集成存在硬件异构性和控制复杂性等关键挑战，需要标准化通信协议来桥接LLM和物理设备。

Method: 提出IoT-MCP框架，通过边缘部署的服务器实现模型上下文协议（MCP），以连接LLM和IoT生态系统。创建了包含114个基础任务和1140个复杂任务的IoT-MCP Bench基准来支持评估。

Result: IoT-MCP在22种传感器和6种微控制器上进行了实验验证，实现了100%的任务成功率，平均响应时间为205毫秒，峰值内存占用为74KB，生成的工具调用完全符合预期且结果准确。

Conclusion: 本文提出了IoT-MCP集成框架和IoT-MCP Bench评估基准，为LLM-IoT系统的集成和评估提供了开源解决方案和标准化方法。

Abstract: The integration of Large Language Models (LLMs) with Internet-of-Things (IoT)
systems faces significant challenges in hardware heterogeneity and control
complexity. The Model Context Protocol (MCP) emerges as a critical enabler,
providing standardized communication between LLMs and physical devices. We
propose IoT-MCP, a novel framework that implements MCP through edge-deployed
servers to bridge LLMs and IoT ecosystems. To support rigorous evaluation, we
introduce IoT-MCP Bench, the first benchmark containing 114 Basic Tasks (e.g.,
``What is the current temperature?'') and 1,140 Complex Tasks (e.g., ``I feel
so hot, do you have any ideas?'') for IoT-enabled LLMs. Experimental validation
across 22 sensor types and 6 microcontroller units demonstrates IoT-MCP's 100%
task success rate to generate tool calls that fully meet expectations and
obtain completely accurate results, 205ms average response time, and 74KB peak
memory footprint. This work delivers both an open-source integration framework
(https://github.com/Duke-CEI-Center/IoT-MCP-Servers) and a standardized
evaluation methodology for LLM-IoT systems.

</details>


### [404] [QScale: Probabilistic Chained Consensus for Moderate-Scale Systems](https://arxiv.org/abs/2510.01536)
*Hasan Heydari,Alysson Bessani,Kartik Nayak*

Main category: cs.DC

TL;DR: 现有的分布式账本协议要么通信复杂度高，要么依赖于仅适用于大量进程的委员会采样方法。本研究旨在设计一种适用于中等规模系统的分布式账本，该账本具有亚线性通信复杂度、低延迟，并能确保安全性和活性。我们提出了QScale协议，其通信复杂度、总通信复杂度以及区块最终确定延迟均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的分布式账本协议在处理中等规模（几百到几千个节点）的系统时存在通信复杂度高或不适用的问题，而这类系统在生产环境中很常见。

Method: 提出了一种名为QScale的协议，旨在实现亚线性通信复杂度（每个节点$\	ilde{O}(\\kappa \sqrt{n})$，总共$\	ilde{O}(n\\kappa)$）和低延迟（最佳情况$O(\\kappa)$轮），同时保证安全性和活性。

Result: QScale协议在预期下实现了每个节点$\	ilde{O}(\\kappa \sqrt{n})$的通信复杂度，每个区块的总通信复杂度为$\	ilde{O}(n\\kappa)$，并且在最佳情况下达到$O(\\kappa)$轮的延迟。

Conclusion: QScale协议成功地解决了中等规模分布式账本在通信复杂度和延迟方面的挑战，提供了一种适用于生产环境的解决方案。

Abstract: Existing distributed ledger protocols either incur a high communication
complexity and are thus suited to systems with a small number of processes
(e.g., PBFT), or rely on committee-sampling-based approaches that only work for
a very large number of processes (e.g., Algorand). Neither of these lines of
work is well-suited for moderate-scale distributed ledgers ranging from a few
hundred to a thousand processes, which are common in production (e.g, Redbelly,
Sui). The goal of this work is to design a distributed ledger with sub-linear
communication complexity per process, sub-quadratic total communication
complexity, and low latency for finalizing a block into the ledger, such that
it can be used for moderate-scale systems. We propose QScale, a protocol in
which every process incurs only $\widetilde{O}(\kappa \sqrt{n})$ communication
complexity per-block in expectation, $\widetilde{O}(n\kappa)$ total
communication complexity per-block in expectation, and a best-case latency of
$O(\kappa)$ rounds while ensuring safety and liveness with overwhelming
probability, with $\kappa$ being a small security parameter.

</details>


### [405] [Accuracy vs Performance: An abstraction model for deadline constrained offloading at the mobile-edge](https://arxiv.org/abs/2510.01885)
*Jamie Cotter,Ignacio Castineiras,Victor Cionca*

Main category: cs.DC

TL;DR: 该论文提出了一种低延迟、满足截止时间的深度神经网络（DNN）卸载解决方案，适用于移动边缘设备。


<details>
  <summary>Details</summary>
Motivation: 在移动边缘设备上实现低延迟、满足截止时间的DNN卸载。

Method: 设计了一种调度算法，该算法使用轻量级的网络状态表示，并考虑了设备可用性、网络链路通信、优先级感知抢占和任务截止时间。该算法通过设计资源可用性表示、网络离散化和动态带宽估计机制来降低延迟。该算法已实现于一个由四个树莓派2（B型）移动边缘设备组成的系统中，用于对废料分类传送带进行采样。

Result: 与我们之前提出的方法相比，该系统在废料分类场景下表现更优，优于工作窃取算法和非抢占式调度启发式算法。研究表明，新颖的低延迟抽象模型在高负载情况下能带来更好的性能，而动态带宽估计在资源稀缺时有助于任务放置并最终提高任务吞吐量。

Conclusion: 所提出的低延迟抽象模型和动态带宽估计机制能够有效提高移动边缘设备上DNN卸载的性能，尤其是在高负载和资源稀缺的情况下。

Abstract: In this paper, we present a solution for low-latency deadline-constrained DNN
offloading on mobile edge devices. We design a scheduling algorithm with
lightweight network state representation, considering device availability,
communication on the network link, priority-aware pre-emption, and task
deadlines. The scheduling algorithm aims to reduce latency by designing a
resource availability representation, as well as a network discretisation and a
dynamic bandwidth estimation mechanism. We implement the scheduling algorithm
into a system composed of four Raspberry Pi 2 (model Bs) mobile edge devices,
sampling a waste classification conveyor belt at a set frame rate. The system
is evaluated and compared to a previous approach of ours, which was proven to
outcompete work-stealers and a non-pre-emption based scheduling heuristic under
the aforementioned waste classification scenario. Our findings show the novel
lower latency abstraction models yield better performance under high-volume
workloads, with the dynamic bandwidth estimation assisting the task placement
while, ultimately, increasing task throughput in times of resource scarcity.

</details>


### [406] [Programming RISC-V accelerators via Fortran](https://arxiv.org/abs/2510.02170)
*Nick Brown,Jake Davies,Felix LeClair*

Main category: cs.DC

TL;DR: RISC-V 架构的加速器有很大潜力用于高性能计算，但其定制化的编程模型和 API 阻碍了在复杂的 Fortran 科学计算代码中的应用。本文提出了一种无需重写代码即可通过 Fortran 驱动这些架构的方法。


<details>
  <summary>Details</summary>
Motivation: 现有 RISC-V 加速器虽然有潜力用于 HPC，但其定制化的编程模型和 API 阻碍了在复杂的 Fortran 科学计算代码中的应用，因为代码重写不现实。

Method: 提出了一种无需重写代码即可通过 Fortran 驱动 RISC-V 加速器的方法。

Result: 该方法能够避免代码重开发，使得 Fortran 代码能够驱动 RISC-V 加速器。

Conclusion: 通过提出一种创新的方法，解决了在复杂的 Fortran 科学计算代码中应用 RISC-V 加速器时遇到的编程模型和 API 兼容性问题，无需代码重开发。

Abstract: A range of RISC-V based accelerators are available and coming to market, and
there is strong potential for these to be used for High Performance Computing
(HPC) workloads. However, such accelerators tend to provide bespoke programming
models and APIs that require codes to be rewritten. In scientific computing,
where many of the simulation code are highly complex, extensive, and written in
Fortran, this is not realistic. In this extended abstract we present an
approach that enables driving such architectures via Fortran, avoiding code
redevelopment.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [407] [Accelerating Long-Term Molecular Dynamics with Physics-Informed Time-Series Forecasting](https://arxiv.org/abs/2510.01206)
*Hung Le,Sherif Abbas,Minh Hoang Nguyen,Van Dai Do,Huu Hiep Nguyen,Dung Nguyen*

Main category: cs.LG

TL;DR: 该方法将分子动力学模拟视为时间序列预测问题，使用基于物理信息损失和推理机制的先进预测模型来预测原子轨迹，以实现比传统DFT方法更快速、更准确的模拟。


<details>
  <summary>Details</summary>
Motivation: 传统的密度泛函理论（DFT）方法计算成本高昂，限制了长期模拟的可行性，因此需要更有效的分子动力学（MD）模拟方法。

Method: 将MD模拟构建为时间序列预测问题，利用基于DFT参数化的Morse势函数进行物理信息损失和推理，以预测原子位移而非绝对位置，并惩罚不合理的原子接近度。

Result: 该方法在模拟精度上持续优于标准基线，并能在几分钟内实现数千步的稳定模拟，为昂贵的DFT模拟提供了一种可扩展的替代方案。

Conclusion: 将物理知识纳入原子轨迹预测可以提高其可靠性和准确性，并且所提出的方法可以比传统的DFT模拟更快、更稳定地进行。

Abstract: Efficient molecular dynamics (MD) simulation is vital for understanding
atomic-scale processes in materials science and biophysics. Traditional density
functional theory (DFT) methods are computationally expensive, which limits the
feasibility of long-term simulations. We propose a novel approach that
formulates MD simulation as a time-series forecasting problem, enabling
advanced forecasting models to predict atomic trajectories via displacements
rather than absolute positions. We incorporate a physics-informed loss and
inference mechanism based on DFT-parametrised pair-wise Morse potential
functions that penalize unphysical atomic proximity to enforce physical
plausibility. Our method consistently surpasses standard baselines in
simulation accuracy across diverse materials. The results highlight the
importance of incorporating physics knowledge to enhance the reliability and
precision of atomic trajectory forecasting. Remarkably, it enables stable
modeling of thousands of MD steps in minutes, offering a scalable alternative
to costly DFT simulations.

</details>


### [408] [Learning Representations Through Contrastive Neural Model Checking](https://arxiv.org/abs/2510.01853)
*Vladimir Krsmanovic,Matthias Cosler,Mohamed Ghanem,Bernd Finkbeiner*

Main category: cs.LG

TL;DR: CNML是一种新的模型检验方法，通过将逻辑规范和系统嵌入共享的潜在空间来学习对齐的表示，并在检索任务中优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 现有模型检验方法在处理复杂系统时面临挑战，而深度学习在形式化验证中的表示学习应用仍有待探索。

Method: CNML利用模型检验任务作为学习对齐表示的引导信号，通过自监督对比目标将逻辑规范和系统联合嵌入到共享的潜在空间中。

Result: CNML在行业启发式检索任务中，无论是在跨模态还是单模态设置下，都显著优于算法和神经基线，并且学习到的表示能有效地迁移到下游任务并泛化到更复杂的公式。

Conclusion: 模型检验可以作为学习形式语言表示的目标。

Abstract: Model checking is a key technique for verifying safety-critical systems
against formal specifications, where recent applications of deep learning have
shown promise. However, while ubiquitous for vision and language domains,
representation learning remains underexplored in formal verification. We
introduce Contrastive Neural Model Checking (CNML), a novel method that
leverages the model checking task as a guiding signal for learning aligned
representations. CNML jointly embeds logical specifications and systems into a
shared latent space through a self-supervised contrastive objective. On
industry-inspired retrieval tasks, CNML considerably outperforms both
algorithmic and neural baselines in cross-modal and intra-modal settings.We
further show that the learned representations effectively transfer to
downstream tasks and generalize to more complex formulas. These findings
demonstrate that model checking can serve as an objective for learning
representations for formal languages.

</details>


### [409] [Learning Regularization Functionals for Inverse Problems: A Comparative Study](https://arxiv.org/abs/2510.01755)
*Johannes Hertrich,Hok Shing Wong,Alexander Denker,Stanislas Ducotterd,Zhenghan Fang,Markus Haltmeier,Željko Kereta,Erich Kobler,Oscar Leong,Mohammad Sadegh Salehi,Carola-Bibiane Schönlieb,Johannes Schwab,Zakhar Shumaylov,Jeremias Sulam,German Shâma Wache,Martin Zach,Yasi Zhang,Matthias J. Ehrhardt,Sebastian Neumayer*

Main category: cs.LG

TL;DR: 现有多种用于解决成像逆问题的学习正则化框架，但因实现方式不统一，难以直接比较。本文整合了现有代码，构建统一框架，以便系统性地比较不同方法，并提供方法描述和实践指南。


<details>
  <summary>Details</summary>
Motivation: 现有学习正则化框架的实现方式不统一，难以直接比较其优缺点。

Method: 收集并统一现有代码到一个共同的框架中，以便进行系统性比较。

Result: 提供了一个统一的框架，可以系统性地比较不同方法，并突出它们的优势和局限性。

Conclusion: 统一的框架有助于深入理解和比较各种学习正则化方法，为未来的研究和应用提供指导。

Abstract: In recent years, a variety of learned regularization frameworks for solving
inverse problems in imaging have emerged. These offer flexible modeling
together with mathematical insights. The proposed methods differ in their
architectural design and training strategies, making direct comparison
challenging due to non-modular implementations. We address this gap by
collecting and unifying the available code into a common framework. This
unified view allows us to systematically compare the approaches and highlight
their strengths and limitations, providing valuable insights into their future
potential. We also provide concise descriptions of each method, complemented by
practical guidelines.

</details>


### [410] [Control the Temperature: Selective Sampling for Diverse and High-Quality LLM Outputs](https://arxiv.org/abs/2510.01218)
*Sergey Troshin,Wafaa Mohammed,Yan Meng,Christof Monz,Antske Fokkens,Vlad Niculae*

Main category: cs.LG

TL;DR: 该研究提出了一种名为“选择性采样”的新方法，用于在提高语言模型生成内容多样性的同时，保持数学推理等任务的准确性。


<details>
  <summary>Details</summary>
Motivation: 为了解决在需要高精度的任务（如数学推理）中，提高温度的采样策略（如 min-p 或 top-p）会降低推理质量的问题。这种质量下降是由于在敏感的解码位置采样了不正确的续写。因此，需要一种能够平衡多样性和准确性的采样方法。

Method: 提出“选择性采样”方法，该方法根据一个“采样风险度量”动态地在贪婪采样和高温采样之间切换。采样风险度量用于估计在当前 token 位置使用高温采样时出现输出错误的可能性。该风险度量通过在一个可验证问题的子集上训练一个轻量级分类器来预测。所训练的分类器可以以最小的延迟开销集成到基础语言模型中。

Result: 在数学推理任务上的实验表明，选择性采样能够改善高温设置下的质量-多样性权衡，即在提高多样性的同时，保持了推理的准确性。

Conclusion: 选择性采样是一种有效的方法，可以在不牺牲准确性的前提下，提高语言模型在数学推理等任务中的生成多样性。

Abstract: Diversity is an essential metric for evaluating the creativity of outputs
generated by language models. Temperature-based sampling is a common strategy
to increase diversity. However, for tasks that require high precision, e.g.,
mathematical reasoning, uncontrolled high temperature sampling, e.g., min-$p$
or top-$p$, degrades reasoning quality. We demonstrate that the loss of
accuracy is caused by sampling incorrect continuations in sensitive decoding
positions. To address this, in this paper, we propose \textbf{selective
sampling}, a method that dynamically switches between greedy and
high-temperature sampling based on a sampling risk metric. This risk metric
estimates the likelihood of output errors when applying high-temperature
sampling on the current token position. To predict sampling risk, we train a
lightweight classifier on a small subset of verifiable problems. The trained
classifier can be integrated with the base language model with minimal latency
overhead. Experiments on mathematical reasoning tasks demonstrate that
selective sampling enhances the quality-diversity trade-off, even in
high-temperature settings.

</details>


### [411] [Neural non-canonical Hamiltonian dynamics for long-time simulations](https://arxiv.org/abs/2510.01788)
*Clémentine Courtès,Emmanuel Franck,Michael Kraus,Laurent Navoret,Léopold Trémant*

Main category: cs.LG

TL;DR: 本研究提出两种新的训练策略来解决从数据中学习非规范哈密顿动力学时出现的数值不稳定性问题，该问题源于数值方案的规范依赖性。


<details>
  <summary>Details</summary>
Motivation: 学习非规范哈密顿动力学，以实现长期预测，同时保持学习模型和数值方案的结构。

Method: 提出两种训练策略：直接学习矢量场或通过数值方案学习时间离散动力学。

Result: 在数值测试中，所提出的方法能够学习复杂的物理动力学，例如来自回旋动力学等离子体物理学的导引中心动力学，并解决了先前方法中出现的数值不稳定性问题。

Conclusion: 本研究识别并解决了从数据中学习非规范哈密顿动力学时出现的数值不稳定性问题，提出了两种有效的训练策略，并在复杂的物理动力学学习任务中得到了验证。

Abstract: This work focuses on learning non-canonical Hamiltonian dynamics from data,
where long-term predictions require the preservation of structure both in the
learned model and in numerical schemes. Previous research focused on either
facet, respectively with a potential-based architecture and with degenerate
variational integrators, but new issues arise when combining both. In
experiments, the learnt model is sometimes numerically unstable due to the
gauge dependency of the scheme, rendering long-time simulations impossible. In
this paper, we identify this problem and propose two different training
strategies to address it, either by directly learning the vector field or by
learning a time-discrete dynamics through the scheme. Several numerical test
cases assess the ability of the methods to learn complex physical dynamics,
like the guiding center from gyrokinetic plasma physics.

</details>


### [412] [Automated Extraction of Material Properties using LLM-based AI Agents](https://arxiv.org/abs/2510.01235)
*Subham Ghosh,Abhishek Tewari*

Main category: cs.LG

TL;DR: LLM驱动的工作流可从大量科学文献中自动提取热电和结构特性，创建了迄今为止最大的LLM策展热电数据集。


<details>
  <summary>Details</summary>
Motivation: 现有材料数据库的规模、可读性和偏见限制了材料的快速发现。实验文献没有得到充分利用。

Method: 采用由LLM驱动的自主工作流，结合动态令牌分配、零样本多主体提取和条件表解析，从大约10,000篇全文科学文章中提取热电和结构特性。

Result: GPT-4.1在热电特性（F1=0.91）和结构字段（F1=0.82）方面实现了最高的准确性，而GPT-4.1 Mini的成本效益更高。该工作流整理了27,822条温度解析的材料性能记录，揭示了已知的热电趋势，并发现了更广泛的结构-性能相关性。

Conclusion: 该研究交付了最大的LLM策展热电数据集，提供了一个可重复且具有成本效益的提取流程，并为可扩展的数据驱动材料发现奠定了基础，其应用超出了热电领域。

Abstract: The rapid discovery of materials is constrained by the lack of large,
machine-readable datasets that couple performance metrics with structural
context. Existing databases are either small, manually curated, or biased
toward first principles results, leaving experimental literature
underexploited. We present an agentic, large language model (LLM)-driven
workflow that autonomously extracts thermoelectric and structural-properties
from about 10,000 full-text scientific articles. The pipeline integrates
dynamic token allocation, zeroshot multi-agent extraction, and conditional
table parsing to balance accuracy against computational cost. Benchmarking on
50 curated papers shows that GPT-4.1 achieves the highest accuracy (F1 = 0.91
for thermoelectric properties and 0.82 for structural fields), while GPT-4.1
Mini delivers nearly comparable performance (F1 = 0.89 and 0.81) at a fraction
of the cost, enabling practical large scale deployment. Applying this workflow,
we curated 27,822 temperature resolved property records with normalized units,
spanning figure of merit (ZT), Seebeck coefficient, conductivity, resistivity,
power factor, and thermal conductivity, together with structural attributes
such as crystal class, space group, and doping strategy. Dataset analysis
reproduces known thermoelectric trends, such as the superior performance of
alloys over oxides and the advantage of p-type doping, while also surfacing
broader structure-property correlations. To facilitate community access, we
release an interactive web explorer with semantic filters, numeric queries, and
CSV export. This study delivers the largest LLM-curated thermoelectric dataset
to date, provides a reproducible and cost-profiled extraction pipeline, and
establishes a foundation for scalable, data-driven materials discovery beyond
thermoelectrics.

</details>


### [413] [RSAVQ: Riemannian Sensitivity-Aware Vector Quantization for Large Language Models](https://arxiv.org/abs/2510.01240)
*Zukang Xu,Xing Hu,Qiang Wu,Dawei Yang*

Main category: cs.LG

TL;DR: RSAVQ是一种新颖的向量量化框架，通过误差方向敏感性引导（EDSG）和权重通道敏感性引导（WCSG）技术，解决了现有低比特量化方法的局限性，能够更有效地为大型语言模型（LLMs）进行极低比特量化，并在LLaMA-3 8B的2比特量化实验中取得了优于基线方法的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）参数量大，难以在资源受限设备上部署。现有的向量量化（VQ）方法在低比特量化（2-4比特）时存在误差方向不受约束和比特分配不佳的问题。

Method: RSAVQ框架通过以下两点创新来解决现有方法的局限性：1. 误差方向敏感性引导（EDSG）：利用Fisher信息矩阵（FIM）诱导的黎曼度量，将量化误差投影到参数空间中敏感度较低的方向上，具体沿负自然梯度方向进行投影，以抑制误差增长。2. 权重通道敏感性引导（WCSG）：通过FIM曲率分析构建通道敏感性度量，以动态引导比特资源分配，从而在规定的比特约束下实现全局最优量化。

Result: 在LLaMA-3 8B的2比特量化实验中，RSAVQ在困惑度（PPL）上比VPTQ和QuIP#等基线方法提高了0.4，在零样本准确率上提高了1.5。

Conclusion: RSAVQ为资源受限环境提供了一个实用的解决方案，并在信息几何与神经网络量化之间搭建了理论桥梁，推动了高效深度学习的发展。

Abstract: Large language models (LLMs) have demonstrated remarkable performance across
a wide range of natural language processing tasks. However, their exponentially
increasing parameters pose significant challenges for deployment on
resource-constrained devices. Vector Quantization (VQ) shows great promise for
low-bit quantization (e.g., 2 to 4 bits), but existing work faces two key
challenges: unconstrained direction error and suboptimal bit allocation. In
this paper, we propose RSAVQ, a novel VQ framework to enhance extremely low-bit
quantization for LLMs. RSAVQ introduces two geometry-driven innovations that
effectively mitigate above limitations: (1) Error Direction Sensitivity
Guidance (EDSG), which leverages the Fisher Information Matrix (FIM)-induced
Riemannian metric to project quantization errors onto low-sensitivity
directions in the parameter space. Specifically, this projection is performed
along the negative natural gradient direction, which effectively suppresses
error expansion. (2) Weight Channel Sensitivity Guidance (WCSG) , which
constructs a channel-wise sensitivity metric via FIM curvature analysis to
dynamically guide bit resource allocation. The approach facilitates a globally
optimal quantization solution within prescribed bit constraints. Experiments
demonstrate that RSAVQ outperforms existing methods for LLMs. For example, in
2-bit quantization of LLaMA-3 8B, RSAVQ leads baselines like VPTQ and QuIP# by
0.4 in perplexity (PPL) and 1.5 in zero-shot accuracy. This work offers a
practical solution for constrained environments and a theoretical bridge
between information geometry and the quantization of neural networks, advancing
efficient deep learning.

</details>


### [414] [Adaptive Federated Learning Defences via Trust-Aware Deep Q-Networks](https://arxiv.org/abs/2510.01261)
*Vedant Palit*

Main category: cs.LG

TL;DR: 该研究提出了一种信任感知深度Q网络，用于防御联邦学习中的部分可观测性中毒和后门攻击。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在部分可观测性下容易受到中毒和后门攻击，需要有效的防御机制。

Method: 将防御问题建模为部分可观测的序贯决策问题，并引入信任感知深度Q网络。该网络整合多信号证据来更新客户端信任度，并优化长期鲁棒性-准确性目标。

Result: 在CIFAR-10数据集上进行了实验，结果显示：1. 提出的方法相比基线模型具有稳步提高的准确性。2. 增加了客户端重叠度可以持续提高准确性并降低攻击成功率（ASR），同时保持检测稳定性。3. 即使在可观测性降低的情况下，准确性也能保持稳定，而ASR增加，ROC-AUC下降，这表明序贯信念更新能够缓解较弱的信号。4. 与随机、线性Q和策略梯度控制器相比，DQN在鲁棒性-准确性权衡方面表现最佳。

Conclusion: 信任感知深度Q网络是一种有效的防御联邦学习中部分可观测性攻击的方法，能够在鲁棒性和准确性之间取得良好的平衡。

Abstract: Federated learning is vulnerable to poisoning and backdoor attacks under
partial observability. We formulate defence as a partially observable
sequential decision problem and introduce a trust-aware Deep Q-Network that
integrates multi-signal evidence into client trust updates while optimizing a
long-horizon robustness--accuracy objective. On CIFAR-10, we (i) establish a
baseline showing steadily improving accuracy, (ii) show through a Dirichlet
sweep that increased client overlap consistently improves accuracy and reduces
ASR with stable detection, and (iii) demonstrate in a signal-budget study that
accuracy remains steady while ASR increases and ROC-AUC declines as
observability is reduced, which highlights that sequential belief updates
mitigate weaker signals. Finally, a comparison with random, linear-Q, and
policy gradient controllers confirms that DQN achieves the best
robustness--accuracy trade-off.

</details>


### [415] [Beyond Majority Voting: LLM Aggregation by Leveraging Higher-Order Information](https://arxiv.org/abs/2510.01499)
*Rui Ai,Yuqi Pan,David Simchi-Levi,Milind Tambe,Haifeng Xu*

Main category: cs.LG

TL;DR: 本论文设计了两种新的多LLM答案聚合算法（最优权重OW和逆惊奇流行度ISP），它们利用一阶和二阶信息，并且在理论和实践上都优于标准多数投票法。


<details>
  <summary>Details</summary>
Motivation: 随着多LLM推理的快速发展，如何有效聚合多个LLM的答案已成为一个基本挑战。标准多数投票法忽略了模型之间潜在的异质性和相关性。

Method: 设计了最优权重（OW）和逆惊奇流行度（ISP）两种新的聚合算法，利用一阶和二阶信息。

Result: 在合成数据集、UltraFeedback和MMLU等LLM微调基准以及真实世界的ARMMAN医疗保健设置中，提出的算法持续优于多数投票法。

Conclusion: 提出的OW和ISP算法在理论上可以克服多数投票法的局限性，在实践中也提供了性能上的提升，为设计鲁棒的多LLM管道提供了概念上的见解。

Abstract: With the rapid progress of multi-agent large language model (LLM) reasoning,
how to effectively aggregate answers from multiple LLMs has emerged as a
fundamental challenge. Standard majority voting treats all answers equally,
failing to consider latent heterogeneity and correlation across models. In this
work, we design two new aggregation algorithms called Optimal Weight (OW) and
Inverse Surprising Popularity (ISP), leveraging both first-order and
second-order information. Our theoretical analysis shows these methods provably
mitigate inherent limitations of majority voting under mild assumptions,
leading to more reliable collective decisions. We empirically validate our
algorithms on synthetic datasets, popular LLM fine-tuning benchmarks such as
UltraFeedback and MMLU, and a real-world healthcare setting ARMMAN. Across all
cases, our methods consistently outperform majority voting, offering both
practical performance gains and conceptual insights for the design of robust
multi-agent LLM pipelines.

</details>


### [416] [RSTGCN: Railway-centric Spatio-Temporal Graph Convolutional Network for Train Delay Prediction](https://arxiv.org/abs/2510.01262)
*Koyena Chowdhury,Paramita Koley,Abhijnan Chakraborty,Saptarshi Ghosh*

Main category: cs.LG

TL;DR: RSTGCN模型用于预测火车站的平均列车晚点，并在印度铁路网络数据集上进行了验证。


<details>
  <summary>Details</summary>
Motivation: 为了更有效地调度和管理铁路交通，需要准确预测列车晚点，特别是从车站层面进行预测。

Method: 提出了一种名为RSTGCN的铁路中心时空图卷积网络，集成了频率感知空间注意机制，用于预测特定时间段内火车站所有进站列车的平均到达晚点。

Result: 在包含4735个车站的印度铁路网络数据集上进行了广泛的实验，结果显示RSTGCN在标准指标上优于现有基线模型。

Conclusion: RSTGCN在大型铁路网络中平均晚点预测方面取得了进展，并发布了一个开放数据集以促进该领域的研究。

Abstract: Accurate prediction of train delays is critical for efficient railway
operations, enabling better scheduling and dispatching decisions. While earlier
approaches have largely focused on forecasting the exact delays of individual
trains, recent studies have begun exploring station-level delay prediction to
support higher-level traffic management. In this paper, we propose the
Railway-centric Spatio-Temporal Graph Convolutional Network (RSTGCN), designed
to forecast average arrival delays of all the incoming trains at railway
stations for a particular time period. Our approach incorporates several
architectural innovations and novel feature integrations, including train
frequency-aware spatial attention, which significantly enhances predictive
performance. To support this effort, we curate and release a comprehensive
dataset for the entire Indian Railway Network (IRN), spanning 4,735 stations
across 17 zones - the largest and most diverse railway network studied to date.
We conduct extensive experiments using multiple state-of-the-art baselines,
demonstrating consistent improvements across standard metrics. Our work not
only advances the modeling of average delay prediction in large-scale rail
networks but also provides an open dataset to encourage further research in
this critical domain.

</details>


### [417] [TetriServe: Efficient DiT Serving for Heterogeneous Image Generation](https://arxiv.org/abs/2510.01565)
*Runyu Lu,Shiqi He,Wenxuan Tan,Shenggui Li,Ruofan Wu,Jeff J. Ma,Ang Chen,Mosharaf Chowdhury*

Main category: cs.LG

TL;DR: DiT模型生成高质量图像的计算成本高，尤其是在大分辨率下，给严格的服务水平目标（SLOs）带来挑战。现有的服务系统使用固定的度序列并行，对于混合分辨率和截止时间的异构工作负载效率低下。


<details>
  <summary>Details</summary>
Motivation: 高分辨率DiT模型服务成本高，现有系统效率低下，SLO达成率不高。

Method: 提出了一种步进级别序列并行（step-level sequence parallelism）的方法，并实现了一个名为TetriServe的服务系统。该系统采用基于回合的调度机制，将时间离散化为固定回合，并能在步进级别动态调整并行度，以最小化GPU小时消耗并共同打包请求以减少延迟。

Result: 与现有解决方案相比，TetriServe的SLO达成率最高可提高32%，同时不影响图像质量。

Conclusion: TetriServe通过步进级别序列并行和创新的调度机制，显著提高了DiT模型服务的效率和SLO达成率。

Abstract: Diffusion Transformer (DiT) models excel at generating highquality images
through iterative denoising steps, but serving them under strict Service Level
Objectives (SLOs) is challenging due to their high computational cost,
particularly at large resolutions. Existing serving systems use fixed degree
sequence parallelism, which is inefficient for heterogeneous workloads with
mixed resolutions and deadlines, leading to poor GPU utilization and low SLO
attainment.
  In this paper, we propose step-level sequence parallelism to dynamically
adjust the parallel degree of individual requests according to their deadlines.
We present TetriServe, a DiT serving system that implements this strategy for
highly efficient image generation. Specifically, TetriServe introduces a novel
round-based scheduling mechanism that improves SLO attainment: (1) discretizing
time into fixed rounds to make deadline-aware scheduling tractable, (2)
adapting parallelism at the step level and minimize GPU hour consumption, and
(3) jointly packing requests to minimize late completions. Extensive evaluation
on state-of-the-art DiT models shows that TetriServe achieves up to 32% higher
SLO attainment compared to existing solutions without degrading image quality.

</details>


### [418] [Budgeted Broadcast: An Activity-Dependent Pruning Rule for Neural Network Efficiency](https://arxiv.org/abs/2510.01263)
*Yaron Meirovitch,Fuming Yang,Jeff Lichtman,Nir Shavit*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Most pruning methods remove parameters ranked by impact on loss (e.g.,
magnitude or gradient). We propose Budgeted Broadcast (BB), which gives each
unit a local traffic budget (the product of its long-term on-rate $a_i$ and
fan-out $k_i$). A constrained-entropy analysis shows that maximizing coding
entropy under a global traffic budget yields a selectivity-audience balance,
$\log\frac{1-a_i}{a_i}=\beta k_i$. BB enforces this balance with simple local
actuators that prune either fan-in (to lower activity) or fan-out (to reduce
broadcast). In practice, BB increases coding entropy and decorrelation and
improves accuracy at matched sparsity across Transformers for ASR, ResNets for
face identification, and 3D U-Nets for synapse prediction, sometimes exceeding
dense baselines. On electron microscopy images, it attains state-of-the-art F1
and PR-AUC under our evaluation protocol. BB is easy to integrate and suggests
a path toward learning more diverse and efficient representations.

</details>


### [419] [A Framework for Scalable Heterogeneous Multi-Agent Adversarial Reinforcement Learning in IsaacLab](https://arxiv.org/abs/2510.01264)
*Isaac Peterson,Christopher Allred,Jacob Morrey,Mario Harper*

Main category: cs.LG

TL;DR: 该论文提出了一个支持对抗性多智能体强化学习（MARL）训练的平台，适用于机器人协作和竞争场景。


<details>
  <summary>Details</summary>
Motivation: 探索对抗性交互在机器人领域的应用，并扩展现有的MARL框架以支持此类场景的训练。

Method: 扩展了IsaacLab框架，引入了异构智能体和不对称目标的对抗性MARL环境，并集成了HAPPO算法进行高效训练。

Result: 在多个基准场景中成功训练了具有鲁棒性的多智能体竞争策略，并保持了高吞吐量和模拟真实感。

Conclusion: 该框架能够有效地模拟和训练在形态多样化的多智能体竞争中的鲁棒策略。

Abstract: Multi-Agent Reinforcement Learning (MARL) is central to robotic systems
cooperating in dynamic environments. While prior work has focused on these
collaborative settings, adversarial interactions are equally critical for
real-world applications such as pursuit-evasion, security, and competitive
manipulation. In this work, we extend the IsaacLab framework to support
scalable training of adversarial policies in high-fidelity physics simulations.
We introduce a suite of adversarial MARL environments featuring heterogeneous
agents with asymmetric goals and capabilities. Our platform integrates a
competitive variant of Heterogeneous Agent Reinforcement Learning with Proximal
Policy Optimization (HAPPO), enabling efficient training and evaluation under
adversarial dynamics. Experiments across several benchmark scenarios
demonstrate the framework's ability to model and train robust policies for
morphologically diverse multi-agent competition while maintaining high
throughput and simulation realism. Code and benchmarks are available at:
https://github.com/DIRECTLab/IsaacLab-HARL .

</details>


### [420] [RLP: Reinforcement as a Pretraining Objective](https://arxiv.org/abs/2510.01265)
*Ali Hatamizadeh,Syeda Nahida Akter,Shrimai Prabhumoye,Jan Kautz,Mostofa Patwary,Mohammad Shoeybi,Bryan Catanzaro,Yejin Choi*

Main category: cs.LG

TL;DR: RLP是一种创新的信息驱动的强化预训练目标，通过将思维链视为探索性动作，并根据其提供的信息增益来计算奖励，从而将强化学习的探索精神融入预训练的早期阶段，鼓励模型独立思考，显著提升了数学和科学推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的训练大型推理模型的方法通常将强化学习放在监督微调之后的最后一个阶段，而本文旨在探索一种更优的训练方式，将强化学习的探索机制提前到预训练阶段。

Method: 本文提出了一种名为RLP（Reinforcement Learning Pretraining）的目标函数，它将思维链视为一种探索性动作，并根据其信息增益（即在给定上下文和推理链的情况下预测下一个词的对数似然增加量与仅给定上下文的对数似然之比）来计算奖励。这种方法提供了一种无需验证器的密集奖励信号，能够有效地在预训练阶段处理整个文档流。

Result: 在Qwen3-1.7B-Base模型上使用RLP进行预训练，在八个数学和科学基准测试的平均得分上提高了19%。在Nemotron-Nano-12B-v2模型上，RLP将整体平均得分从42.81%提高到61.32%，并将科学推理的平均得分提高了23%。

Conclusion: RLP作为一种预训练目标，有效地将下一词预测与链式思维推理能力联系起来，通过在预训练早期引入探索和独立思考，能够显著提升模型的推理能力，并且在不同模型架构和尺寸上都表现出良好的可扩展性。

Abstract: The dominant paradigm for training large reasoning models starts with
pre-training using next-token prediction loss on vast amounts of data.
Reinforcement learning, while powerful in scaling reasoning, is introduced only
as the very last phase of post-training, preceded by supervised fine-tuning.
While dominant, is this an optimal way of training? In this paper, we present
RLP, an information-driven reinforcement pretraining objective, that brings the
core spirit of reinforcement learning -- exploration -- to the last phase of
pretraining. The key idea is to treat chain-of-thought as an exploratory
action, with rewards computed based on the information gain it provides for
predicting future tokens. This training objective essentially encourages the
model to think for itself before predicting what comes next, thus teaching an
independent thinking behavior earlier in the pretraining. More concretely, the
reward signal measures the increase in log-likelihood of the next token when
conditioning on both context and a sampled reasoning chain, compared to
conditioning on context alone. This approach yields a verifier-free dense
reward signal, allowing for efficient training for the full document stream
during pretraining. Specifically, RLP reframes reinforcement learning for
reasoning as a pretraining objective on ordinary text, bridging the gap between
next-token prediction and the emergence of useful chain-of-thought reasoning.
Pretraining with RLP on Qwen3-1.7B-Base lifts the overall average across an
eight-benchmark math-and-science suite by 19%. With identical post-training,
the gains compound, with the largest improvements on reasoning-heavy tasks such
as AIME25 and MMLU-Pro. Applying RLP to the hybrid Nemotron-Nano-12B-v2
increases the overall average from 42.81% to 61.32% and raises the average on
scientific reasoning by 23%, demonstrating scalability across architectures and
model sizes.

</details>


### [421] [Safe Reinforcement Learning-Based Vibration Control: Overcoming Training Risks with LQR Guidance](https://arxiv.org/abs/2510.01269)
*Rohan Vitthal Thorat,Juhi Singh,Rajdip Nayek*

Main category: cs.LG

TL;DR: 本文提出一种结合 LQR 和 RL 的混合控制框架，用于解决强化学习（RL）在结构振动控制训练中的安全风险问题。


<details>
  <summary>Details</summary>
Motivation: 传统的基于模型的控制策略（如 LQR）需要精确的系统模型，而模型无关的强化学习（RL）方法在训练时存在潜在风险。本文旨在避免繁琐的系统辨识过程，并解决 RL 训练中的探索风险。

Method: 提出一种混合控制框架，结合 LQR 和 RL 控制器。LQR 控制器的策略基于随机选择的模型参数，RL 控制器则在 LQR 的引导下进行训练，以确保训练过程的安全性。

Result: 实验证明，即使 LQR 控制器基于不准确的模型，其性能也优于无控制状态。该混合方法在消除对显式系统模型依赖的同时，最小化了 RL 探索的固有风险。

Conclusion: 本文首次解决了 RL 结构振动控制中的训练安全问题，并提供了一种经过验证的解决方案，即结合 LQR 和 RL 的混合控制框架，该框架在保证模型无关性的同时提高了训练安全性。

Abstract: Structural vibrations induced by external excitations pose significant risks,
including safety hazards for occupants, structural damage, and increased
maintenance costs. While conventional model-based control strategies, such as
Linear Quadratic Regulator (LQR), effectively mitigate vibrations, their
reliance on accurate system models necessitates tedious system identification.
This tedious system identification process can be avoided by using a model-free
Reinforcement learning (RL) method. RL controllers derive their policies solely
from observed structural behaviour, eliminating the requirement for an explicit
structural model. For an RL controller to be truly model-free, its training
must occur on the actual physical system rather than in simulation. However,
during this training phase, the RL controller lacks prior knowledge and it
exerts control force on the structure randomly, which can potentially harm the
structure. To mitigate this risk, we propose guiding the RL controller using a
Linear Quadratic Regulator (LQR) controller. While LQR control typically relies
on an accurate structural model for optimal performance, our observations
indicate that even an LQR controller based on an entirely incorrect model
outperforms the uncontrolled scenario. Motivated by this finding, we introduce
a hybrid control framework that integrates both LQR and RL controllers. In this
approach, the LQR policy is derived from a randomly selected model and its
parameters. As this LQR policy does not require knowledge of the true or an
approximate structural model the overall framework remains model-free. This
hybrid approach eliminates dependency on explicit system models while
minimizing exploration risks inherent in naive RL implementations. As per our
knowledge, this is the first study to address the critical training safety
challenge of RL-based vibration control and provide a validated solution.

</details>


### [422] [Identifying Information-Transfer Nodes in a Recurrent Neural Network Reveals Dynamic Representations](https://arxiv.org/abs/2510.01271)
*Arend Hintze,Asadullah Najam,Jory Schossau*

Main category: cs.LG

TL;DR: 本研究提出一种信息论方法，用于识别和分析循环神经网络（RNN）中的信息传递节点（“信息中继”），以增强模型的可解释性。


<details>
  <summary>Details</summary>
Motivation: 理解RNN的内部动力学对于提高其可解释性和改进其设计至关重要。

Method: 通过量化节点之间输入和输出向量的互信息来识别信息流动的关键路径。

Result: 在合成和真实世界的时间序列分类任务中，研究了不同RNN架构（LSTM、GRU）中的信息中继模式，并通过节点敲除实验验证了所识别节点的功能重要性。

Conclusion: 该方法能够揭示RNN的信息处理机制，并为设计更鲁棒、可解释的神经网络提供工具。

Abstract: Understanding the internal dynamics of Recurrent Neural Networks (RNNs) is
crucial for advancing their interpretability and improving their design. This
study introduces an innovative information-theoretic method to identify and
analyze information-transfer nodes within RNNs, which we refer to as
\textit{information relays}. By quantifying the mutual information between
input and output vectors across nodes, our approach pinpoints critical pathways
through which information flows during network operations. We apply this
methodology to both synthetic and real-world time series classification tasks,
employing various RNN architectures, including Long Short-Term Memory (LSTM)
networks and Gated Recurrent Units (GRUs). Our results reveal distinct patterns
of information relay across different architectures, offering insights into how
information is processed and maintained over time. Additionally, we conduct
node knockout experiments to assess the functional importance of identified
nodes, significantly contributing to explainable artificial intelligence by
elucidating how specific nodes influence overall network behavior. This study
not only enhances our understanding of the complex mechanisms driving RNNs but
also provides a valuable tool for designing more robust and interpretable
neural networks.

</details>


### [423] [Noisy-Pair Robust Representation Alignment for Positive-Unlabeled Learning](https://arxiv.org/abs/2510.01278)
*Hengwei Zhao,Zhengzhong Tu,Zhuo Zheng,Wei Wang,Junjue Wang,Rusty Feagin,Wenzhe Jiao*

Main category: cs.LG

TL;DR: NcPU是一个无需辅助信息的非对比式PU学习框架，通过结合鲁棒的非对比式损失和幻象标签消歧方案，提高了PU学习在复杂数据集上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的PU学习方法在复杂数据集上的表现不如监督学习方法，主要是因为在不可靠的监督下学习判别性表示存在挑战。

Method: 提出了一种名为NcPU的非对比式PU学习框架。该框架结合了能够对嘈杂标签具有鲁棒性的非对比式损失（NoiSNCL），用于在不可靠的监督下对同一类别内的表示进行对齐；以及一个幻象标签消歧（PLD）方案，通过基于悔恨的标签更新来提供保守的负监督。理论上，NoiSNCL和PLD可以从期望最大化（EM）框架的角度相互促进。

Result: 实验结果表明，NoiSNCL可以使简单的PU方法达到具有竞争力的性能。NcPU在包括灾后建筑损害测绘在内的各种数据集上，显著优于最先进的PU方法。

Conclusion: NcPU框架在复杂数据集上显著提高了PU学习的性能，并且在现实世界中的应用前景广阔。

Abstract: Positive-Unlabeled (PU) learning aims to train a binary classifier (positive
vs. negative) where only limited positive data and abundant unlabeled data are
available. While widely applicable, state-of-the-art PU learning methods
substantially underperform their supervised counterparts on complex datasets,
especially without auxiliary negatives or pre-estimated parameters (e.g., a
14.26% gap on CIFAR-100 dataset). We identify the primary bottleneck as the
challenge of learning discriminative representations under unreliable
supervision. To tackle this challenge, we propose NcPU, a non-contrastive PU
learning framework that requires no auxiliary information. NcPU combines a
noisy-pair robust supervised non-contrastive loss (NoiSNCL), which aligns
intra-class representations despite unreliable supervision, with a phantom
label disambiguation (PLD) scheme that supplies conservative negative
supervision via regret-based label updates. Theoretically, NoiSNCL and PLD can
iteratively benefit each other from the perspective of the
Expectation-Maximization framework. Empirically, extensive experiments
demonstrate that: (1) NoiSNCL enables simple PU methods to achieve competitive
performance; and (2) NcPU achieves substantial improvements over
state-of-the-art PU methods across diverse datasets, including challenging
datasets on post-disaster building damage mapping, highlighting its promise for
real-world applications. Code: Code will be open-sourced after review.

</details>


### [424] [Microsaccade-Inspired Probing: Positional Encoding Perturbations Reveal LLM Misbehaviours](https://arxiv.org/abs/2510.01288)
*Rui Melo,Rui Abreu,Corina S. Pasareanu*

Main category: cs.LG

TL;DR: 通过模拟人类的微小眼跳动，提出了一种轻量级的探测方法，用于识别大型语言模型（LLMs）的不当行为，无需微调或任务特定监督。


<details>
  <summary>Details</summary>
Motivation: 从人类感知研究中的微小眼跳动获得灵感，提出一种用于大型语言模型（LLMs）的类似探测方法，以揭示其隐藏的动态。

Method: 通过引入轻量级的、基于扰动的探测方法，模仿微小眼跳动，来探测LLMs的不当行为。

Result: 实验证明，该方法能够有效识别LLMs在事实性、安全性、毒性和后门攻击等方面的错误，并且计算效率高。

Conclusion: 预训练的LLMs已经编码了内部证据来标记自身的错误，而受微小眼跳动启发的干预措施为检测和减轻不当行为提供了一条途径。

Abstract: We draw inspiration from microsaccades, tiny involuntary eye movements that
reveal hidden dynamics of human perception, to propose an analogous probing
method for large language models (LLMs). Just as microsaccades expose subtle
but informative shifts in vision, we show that lightweight position encoding
perturbations elicit latent signals that indicate model misbehaviour. Our
method requires no fine-tuning or task-specific supervision, yet detects
failures across diverse settings including factuality, safety, toxicity, and
backdoor attacks. Experiments on multiple state-of-the-art LLMs demonstrate
that these perturbation-based probes surface misbehaviours while remaining
computationally efficient. These findings suggest that pretrained LLMs already
encode the internal evidence needed to flag their own failures, and that
microsaccade-inspired interventions provide a pathway for detecting and
mitigating undesirable behaviours.

</details>


### [425] [ThinKV: Thought-Adaptive KV Cache Compression for Efficient Reasoning Models](https://arxiv.org/abs/2510.01290)
*Akshat Ramachandran,Marina Neseem,Charbel Sakr,Rangharajan Venkatesan,Brucek Khailany,Tushar Krishna*

Main category: cs.LG

TL;DR: KV缓存过大会导致GPU内存不足，ThinKV通过自适应压缩KV缓存来解决此问题，能在保持近乎无损精度的前提下，显著减少KV缓存使用量并提升推理吞吐量。


<details>
  <summary>Details</summary>
Motivation: 大型模型在生成长文本时，KV缓存会急剧增长，导致GPU内存不足，限制了长链式思考（CoT）的应用。

Method: ThinKV提出了一种基于注意力稀疏性的思想自适应KV缓存压缩框架。它采用混合量化-淘汰策略，根据思考的重要性分配 token 精度，并逐步淘汰来自不关键思考的 token。此外，ThinKV还设计了一个扩展 PagedAttention 的内核，以有效重用被淘汰 token 的内存空间，消除碎片整理开销。

Result: 在DeepSeek-R1-Distill、GPT-OSS和NVIDIA AceReason等模型和数学、编程基准测试上，ThinKV实现了近乎无损的精度，KV缓存使用量不到原始的5%，推理吞吐量相比现有技术提升了高达5.8倍。

Conclusion: ThinKV是一种有效的KV缓存压缩框架，能够显著解决长文本生成中的内存瓶颈问题，同时提高推理效率，为大型模型处理更长、更复杂的推理任务提供了可能性。

Abstract: The long-output context generation of large reasoning models enables extended
chain of thought (CoT) but also drives rapid growth of the key-value (KV)
cache, quickly overwhelming GPU memory. To address this challenge, we propose
ThinKV, a thought-adaptive KV cache compression framework. ThinKV is based on
the observation that attention sparsity reveals distinct thought types with
varying importance within the CoT. It applies a hybrid quantization-eviction
strategy, assigning token precision by thought importance and progressively
evicting tokens from less critical thoughts as reasoning trajectories evolve.
Furthermore, to implement ThinKV, we design a kernel that extends
PagedAttention to enable efficient reuse of evicted tokens' memory slots,
eliminating compaction overheads. Extensive experiments on DeepSeek-R1-Distill,
GPT-OSS, and NVIDIA AceReason across mathematics and coding benchmarks show
that ThinKV achieves near-lossless accuracy with less than 5% of the original
KV cache, while improving performance with up to 5.8x higher inference
throughput over state-of-the-art baselines.

</details>


### [426] [Network-Level Vehicle Delay Estimation at Heterogeneous Signalized Intersections](https://arxiv.org/abs/2510.01292)
*Xiaobo Ma,Hyunsoo Noh,James Tokishi,Ryan Hatch*

Main category: cs.LG

TL;DR: 机器学习模型在交通信号交叉口车辆延误估计中存在领域适应性差的问题。本研究提出了一种名为 GBBW（梯度提升与均衡加权）的领域适应框架，通过重新加权源域数据来提高模型对目标域的适应性，从而更准确、更稳健地估计车辆延误。


<details>
  <summary>Details</summary>
Motivation: 准确估计车辆延误对于评估信号交叉口的性能和制定交通管理策略至关重要，但传统的机器学习模型在应用于不同交叉口时泛化能力不足。

Method: 提出了一种领域适应（DA）框架，其中包含一个名为 GBBW（梯度提升与均衡加权）的新颖 DA 模型。该模型通过重新加权源域数据，使其与目标域更加相似，从而提高模型的适应性。该框架将数据分为源域和目标域，提取关键交通特征，并使用目标域的一小部分标记数据进行微调。

Result: 在 57 个亚利桑那州皮马县的不同交叉口进行的测试表明，GBBW 框架比其他八种最先进的机器学习回归模型和七种基于实例的 DA 方法提供了更准确、更稳健的延误估计。

Conclusion: 所提出的 GBBW 领域适应框架能够更准确、更稳健地估计车辆延误，提高了机器学习模型在不同交通交叉口之间的可转移性，有助于实现更可靠的交通信号优化、拥堵管理和基于绩效的规划，并促进机器学习技术在实际交通系统中的广泛应用。

Abstract: Accurate vehicle delay estimation is essential for evaluating the performance
of signalized intersections and informing traffic management strategies. Delay
reflects congestion levels and affects travel time reliability, fuel use, and
emissions. Machine learning (ML) offers a scalable, cost-effective alternative;
However, conventional models typically assume that training and testing data
follow the same distribution, an assumption that is rarely satisfied in
real-world applications. Variations in road geometry, signal timing, and driver
behavior across intersections often lead to poor generalization and reduced
model accuracy. To address this issue, this study introduces a domain
adaptation (DA) framework for estimating vehicle delays across diverse
intersections. The framework separates data into source and target domains,
extracts key traffic features, and fine-tunes the model using a small, labeled
subset from the target domain. A novel DA model, Gradient Boosting with
Balanced Weighting (GBBW), reweights source data based on similarity to the
target domain, improving adaptability. The framework is tested using data from
57 heterogeneous intersections in Pima County, Arizona. Performance is
evaluated against eight state-of-the-art ML regression models and seven
instance-based DA methods. Results demonstrate that the GBBW framework provides
more accurate and robust delay estimates. This approach supports more reliable
traffic signal optimization, congestion management, and performance-based
planning. By enhancing model transferability, the framework facilitates broader
deployment of machine learning techniques in real-world transportation systems.

</details>


### [427] [From 2D to 3D, Deep Learning-based Shape Reconstruction in Magnetic Resonance Imaging: A Review](https://arxiv.org/abs/2510.01296)
*Emma McMillian,Abhirup Banerjee,Alfonso Bueno-Orovio*

Main category: cs.LG

TL;DR: 该综述总结了基于深度学习的 3D 医学影像重建方法，重点关注点云、网格、形状感知和体积模型四种主要方法，并探讨了它们在不同解剖结构和疾病诊断中的应用、局限性、数据集、计算需求和评估指标，最后指出了多模态融合和跨模态框架等新兴研究方向。


<details>
  <summary>Details</summary>
Motivation: 3D 形状重建从 2D MRI 在医学疾病诊断、治疗规划和计算建模方面日益重要，需要对现有方法进行系统性总结和分析。

Method: 本综述对点云、网格、形状感知和体积模型四种 3D MRI 重建方法进行了分类，分析了各自的技术、基础、局限性和应用，并探讨了数据集、计算需求和评估指标。

Result: 提供了 3D 形状重建方法的全面概述，涵盖了从心脏到神经、再到肺部成像的广泛应用，并分析了模型对疾病解剖的临床适用性以及训练和测试数据的影响。

Conclusion: 为了推动深度学习在 3D 形状重建领域取得更稳健、更通用、临床影响更大的解决方案，本综述旨在为研究人员提供一个结构化的视角，以识别未来的研究机会，特别是多模态整合和跨模态框架方面。

Abstract: Deep learning-based 3-dimensional (3D) shape reconstruction from
2-dimensional (2D) magnetic resonance imaging (MRI) has become increasingly
important in medical disease diagnosis, treatment planning, and computational
modeling. This review surveys the methodological landscape of 3D MRI
reconstruction, focusing on 4 primary approaches: point cloud, mesh-based,
shape-aware, and volumetric models. For each category, we analyze the current
state-of-the-art techniques, their methodological foundation, limitations, and
applications across anatomical structures. We provide an extensive overview
ranging from cardiac to neurological to lung imaging. We also focus on the
clinical applicability of models to diseased anatomy, and the influence of
their training and testing data. We examine publicly available datasets,
computational demands, and evaluation metrics. Finally, we highlight the
emerging research directions including multimodal integration and
cross-modality frameworks. This review aims to provide researchers with a
structured overview of current 3D reconstruction methodologies to identify
opportunities for advancing deep learning towards more robust, generalizable,
and clinically impactful solutions.

</details>


### [428] [Low Rank Gradients and Where to Find Them](https://arxiv.org/abs/2510.01303)
*Rishi Sonthalia,Michael Murray,Guido Montúfar*

Main category: cs.LG

TL;DR: 该论文研究了训练过程中两层神经网络损失梯度的低秩结构，放宽了对训练数据和参数的各向同性假设。


<details>
  <summary>Details</summary>
Motivation: 研究在放松数据和参数各向同性假设的情况下，两层神经网络梯度中的低秩结构。

Method: 通过分析生成数据模型，研究了梯度与输入权重的关系，并考虑了均值场和神经切核缩放。

Result: 证明了梯度近似低秩，并被两个秩一项主导：一个与数据残差对齐，另一个与输入数据中的秩一尖峰对齐。论文还分析了数据特性、缩放机制和激活函数如何影响这两个分量的平衡，并展示了正则化器如何选择性地调节这些分量。

Conclusion: 梯度近似低秩，受数据特性、缩放和激活函数影响，正则化器可进行选择性调节。实验结果验证了理论预测。

Abstract: This paper investigates low-rank structure in the gradients of the training
loss for two-layer neural networks while relaxing the usual isotropy
assumptions on the training data and parameters. We consider a spiked data
model in which the bulk can be anisotropic and ill-conditioned, we do not
require independent data and weight matrices and we also analyze both the
mean-field and neural-tangent-kernel scalings. We show that the gradient with
respect to the input weights is approximately low rank and is dominated by two
rank-one terms: one aligned with the bulk data-residue , and another aligned
with the rank one spike in the input data. We characterize how properties of
the training data, the scaling regime and the activation function govern the
balance between these two components. Additionally, we also demonstrate that
standard regularizers, such as weight decay, input noise and Jacobian
penalties, also selectively modulate these components. Experiments on synthetic
and real data corroborate our theoretical predictions.

</details>


### [429] [Securing generative artificial intelligence with parallel magnetic tunnel junction true randomness](https://arxiv.org/abs/2510.01598)
*Youwei Bao,Shuhan Yang,Hyunsoo Yang*

Main category: cs.LG

TL;DR: 确定性伪随机数生成器（PRNG）在生成式人工智能（GAI）模型中会产生可预测的模式，容易受到攻击。本研究嵌入了来自STT-MTJ的硬件生成的真随机比特，以应对这些挑战。


<details>
  <summary>Details</summary>
Motivation: 确定性PRNG在GAI模型中存在安全漏洞，而传统防御措施的能耗和延迟过高。

Method: 嵌入硬件生成的STT-MTJ真随机比特，构建FPGA辅助原型计算系统。

Result: 原型系统可提供兆比特/秒的真随机数，通过了NIST随机性测试，且开销极小。将硬件真随机比特集成到GAN中，可将不安全输出减少高达18.6倍。

Conclusion: 基于STT-MTJ的系统具有纳秒级切换速度、高能效和良好的可扩展性，可实现千兆比特/秒的吞吐量，适合大型语言模型采样，有望成为下一代GAI系统的实用安全组件。

Abstract: Deterministic pseudo random number generators (PRNGs) used in generative
artificial intelligence (GAI) models produce predictable patterns vulnerable to
exploitation by attackers. Conventional defences against the vulnerabilities
often come with significant energy and latency overhead. Here, we embed
hardware-generated true random bits from spin-transfer torque magnetic tunnel
junctions (STT-MTJs) to address the challenges. A highly parallel,
FPGA-assisted prototype computing system delivers megabit-per-second true
random numbers, passing NIST randomness tests after in-situ operations with
minimal overhead. Integrating the hardware random bits into a generative
adversarial network (GAN) trained on CIFAR-10 reduces insecure outputs by up to
18.6 times compared to the low-quality random number generators (RNG) baseline.
With nanosecond switching speed, high energy efficiency, and established
scalability, our STT-MTJ-based system holds the potential to scale beyond 106
parallel cells, achieving gigabit-per-second throughput suitable for large
language model sampling. This advancement highlights spintronic RNGs as
practical security components for next-generation GAI systems.

</details>


### [430] [Quantum-inspired Benchmark for Estimating Intrinsic Dimension](https://arxiv.org/abs/2510.01335)
*Aritra Das,Joseph T. Iosue,Victor V. Albert*

Main category: cs.LG

TL;DR: 该研究提出了一个名为QuIIEst的量子启发式内在维度估计基准，用于评估内在维度估计（IDE）方法。与现有基准相比，QuIIEst基准包含更复杂的流形，可以更好地测试IDE方法的泛化能力。研究结果表明，在QuIIEst基准上，现有的IDE方法精度较低，并且对曲率变化和噪声不敏感。此外，该研究还对Hofstadter分形蝴蝶进行了IDE分析。


<details>
  <summary>Details</summary>
Motivation: 现有的内在维度估计（IDE）方法在真实数据集上的估计值差异很大，需要一个更复杂的基准来评估这些方法。现有的基准包含的流形复杂度不足以充分测试IDE方法的泛化能力。

Method: 提出了一种名为QuIIEst的量子启发式内在维度估计基准，该基准包含具有已知内在维度（ID）的无限族拓扑非平凡流形。该基准通过一种量子光学方法实现，该方法能够嵌入任意齐次空间，同时允许修改曲率和添加噪声。此外，研究人员还将IDE应用于Hofstadter分形蝴蝶。

Result: 在QuIIEst基准上，接受测试的IDE方法通常不如在现有基准上准确。研究人员还观察到，随着曲率越来越不均匀，性能下降很小，这表明该基准具有固有的难度。在Hofstadter分形蝴蝶上，研究人员确定了能够提取非流形空间的有效维度的IDE方法。

Conclusion: QuIIEst基准为评估IDE方法提供了一个更具挑战性的平台，尤其是在处理复杂流形时。现有IDE方法在处理复杂流形时仍有改进空间。该研究还为理解分形空间的维度提供了一种新的方法。

Abstract: Machine learning models can generalize well on real-world datasets. According
to the manifold hypothesis, this is possible because datasets lie on a latent
manifold with small intrinsic dimension (ID). There exist many methods for ID
estimation (IDE), but their estimates vary substantially. This warrants
benchmarking IDE methods on manifolds that are more complex than those in
existing benchmarks. We propose a Quantum-Inspired Intrinsic-dimension
Estimation (QuIIEst) benchmark consisting of infinite families of topologically
non-trivial manifolds with known ID. Our benchmark stems from a quantum-optical
method of embedding arbitrary homogeneous spaces while allowing for curvature
modification and additive noise. The IDE methods tested were generally less
accurate on QuIIEst manifolds than on existing benchmarks under identical
resource allocation. We also observe minimal performance degradation with
increasingly non-uniform curvature, underscoring the benchmark's inherent
difficulty. As a result of independent interest, we perform IDE on the fractal
Hofstadter's butterfly and identify which methods are capable of extracting the
effective dimension of a space that is not a manifold.

</details>


### [431] [On the Identifiability of Latent Action Policies](https://arxiv.org/abs/2510.01337)
*Sébastien Lachapelle*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We study the identifiability of latent action policy learning (LAPO), a
framework introduced recently to discover representations of actions from video
data. We formally describe desiderata for such representations, their
statistical benefits and potential sources of unidentifiability. Finally, we
prove that an entropy-regularized LAPO objective identifies action
representations satisfying our desiderata, under suitable conditions. Our
analysis provides an explanation for why discrete action representations
perform well in practice.

</details>


### [432] [Self-Supervised Representation Learning as Mutual Information Maximization](https://arxiv.org/abs/2510.01345)
*Akhlaqur Rahman Sabby,Yi Sui,Tongzi Wu,Jesse C. Cresswell,Ga Wu*

Main category: cs.LG

TL;DR: 通过信息论角度统一自监督表示学习方法，提出SDMI和JMI两种训练范式，解释了现有方法的结构选择。


<details>
  <summary>Details</summary>
Motivation: 现有自监督表示学习（SSRL）方法在实践中表现优异，但其理论基础尚不明确。以往的研究多从信息论目标或防止表示坍塌的启发式方法进行统一，而将预测器网络、停止梯度操作和统计正则化器等结构元素视为经验性添加。本文旨在从第一性原理出发，研究SSRL算法的学习目标如何决定其优化策略和模型设计选择。

Method: 从变分互信息（MI）下界出发，推导出两种训练范式：自蒸馏MI（SDMI）和联合MI（JMI）。SDMI需要交替优化，理论上需要停止梯度操作；JMI允许通过对称结构进行联合优化，无需停止梯度。预测器网络和统计正则化器被视为MI目标的替代。

Result: 提出SDMI和JMI两种训练范式，它们对结构有不同的约束，并涵盖了一系列现有的SSRL算法。SDMI中的预测器网络和JMI中的统计正则化器被证明是MI目标的易处理替代。证明了许多现有的SSRL方法是这两种范式的特例或近似。

Conclusion: 本文从信息论角度为现有SSRL方法的结构选择（如预测器网络、停止梯度和统计正则化器）提供了理论解释，超越了简单的启发式原因。

Abstract: Self-supervised representation learning (SSRL) has demonstrated remarkable
empirical success, yet its underlying principles remain insufficiently
understood. While recent works attempt to unify SSRL methods by examining their
information-theoretic objectives or summarizing their heuristics for preventing
representation collapse, architectural elements like the predictor network,
stop-gradient operation, and statistical regularizer are often viewed as
empirically motivated additions. In this paper, we adopt a first-principles
approach and investigate whether the learning objective of an SSRL algorithm
dictates its possible optimization strategies and model design choices. In
particular, by starting from a variational mutual information (MI) lower bound,
we derive two training paradigms, namely Self-Distillation MI (SDMI) and Joint
MI (JMI), each imposing distinct structural constraints and covering a set of
existing SSRL algorithms. SDMI inherently requires alternating optimization,
making stop-gradient operations theoretically essential. In contrast, JMI
admits joint optimization through symmetric architectures without such
components. Under the proposed formulation, predictor networks in SDMI and
statistical regularizers in JMI emerge as tractable surrogates for the MI
objective. We show that many existing SSRL methods are specific instances or
approximations of these two paradigms. This paper provides a theoretical
explanation behind the choices of different architectural components of
existing SSRL methods, beyond heuristic conveniences.

</details>


### [433] [Density-Ratio Weighted Behavioral Cloning: Learning Control Policies from Corrupted Datasets](https://arxiv.org/abs/2510.01479)
*Shriram Karpoora Sundara Pandian,Ali Baheri*

Main category: cs.LG

TL;DR: 该论文提出了一种名为加权行为克隆（Weighted BC）的鲁棒模仿学习方法，用于解决从包含污染数据的固定数据集中优化策略的问题。通过使用少量干净数据估计轨迹密度比率，加权 BC 可以优先考虑干净数据并降低或剔除污染数据，从而在存在污染的情况下也能接近最优策略。


<details>
  <summary>Details</summary>
Motivation: 标准的行为克隆（BC）和离线强化学习（RL）方法在处理受污染（例如，对抗性投毒、系统错误或低质量样本）的数据集时，策略性能会下降。这使得在无法进行在线探索的安全关键应用中，策略优化面临挑战。

Method: Weighted BC 方法利用一个小的、经过验证的干净参考数据集，通过二元判别器估计轨迹级别的密度比率。这些比率经过裁剪后，在 BC 目标函数中用作权重，以优先考虑干净的专家行为，同时降低或剔除受污染的数据，并且不需要知道污染机制。

Result: 实验表明，在连续控制基准上，即使在污染率很高的情况下，Weighted BC 也能保持接近最优的性能，优于传统的 BC、批约束 Q 学习（BCQ）和行为正则化 Actor-Critic（BRAC）等基线方法。

Conclusion: Weighted BC 是一种有效的鲁棒模仿学习方法，可以在存在污染数据的情况下，实现向干净专家策略的收敛，并具有有限样本界限，且不依赖于污染率。

Abstract: Offline reinforcement learning (RL) enables policy optimization from fixed
datasets, making it suitable for safety-critical applications where online
exploration is infeasible. However, these datasets are often contaminated by
adversarial poisoning, system errors, or low-quality samples, leading to
degraded policy performance in standard behavioral cloning (BC) and offline RL
methods. This paper introduces Density-Ratio Weighted Behavioral Cloning
(Weighted BC), a robust imitation learning approach that uses a small, verified
clean reference set to estimate trajectory-level density ratios via a binary
discriminator. These ratios are clipped and used as weights in the BC objective
to prioritize clean expert behavior while down-weighting or discarding
corrupted data, without requiring knowledge of the contamination mechanism. We
establish theoretical guarantees showing convergence to the clean expert policy
with finite-sample bounds that are independent of the contamination rate. A
comprehensive evaluation framework is established, which incorporates various
poisoning protocols (reward, state, transition, and action) on continuous
control benchmarks. Experiments demonstrate that Weighted BC maintains
near-optimal performance even at high contamination ratios outperforming
baselines such as traditional BC, batch-constrained Q-learning (BCQ) and
behavior regularized actor-critic (BRAC).

</details>


### [434] [To Augment or Not to Augment? Diagnosing Distributional Symmetry Breaking](https://arxiv.org/abs/2510.01349)
*Hannah Lawrence,Elyssa Hofgard,Vasco Portilheiro,Yuxuan Chen,Tess Smidt,Robin Walters*

Main category: cs.LG

TL;DR: 对称性感知方法（如数据增强和等变架构）旨在确保模型在原始数据集的各种变换（例如旋转或置换）下表现正确，从而提高泛化能力和样本效率。然而，这些方法依赖于一个假设：变换后的数据点在测试分布下具有高概率或“重要性”。本研究提出了一种评估此假设的方法，通过一个区分原始数据集及其随机增强版本的数据集分类器测试，来量化数据集中的各向异性或对称性破坏程度。研究结果表明，分布对称性破坏会阻碍不变方法的最优性能，即使在标签真正不变的情况下也是如此。实际应用表明，对称性感知方法在各向异性数据集上的效果因数据集而异，某些数据集上仍能带来好处，而另一些则不能。因此，理解等变性的有效性需要重新审视数据中的对称性偏差。


<details>
  <summary>Details</summary>
Motivation: 在机器学习中，对称性感知方法（如数据增强和等变架构）被用来提高模型的泛化能力和样本效率。然而，这些方法的效果依赖于一个关键假设：变换后的数据点在测试分布下具有高概率。本研究旨在评估这一假设，并探讨当数据分布不满足该假设时，对称性感知方法的局限性。

Method: 1. 提出一种量化数据集各向异性（对称性破坏）程度的度量标准，使用一个两样本神经网络分类器测试来区分原始数据集及其随机增强版本。
2. 在合成数据集上验证该度量标准的有效性。
3. 将该度量标准应用于多个基准点云数据集，发现这些数据集存在高度的对称性排列。
4. 理论上证明，即使在标签真正不变的情况下，分布对称性破坏也会阻碍不变方法达到最优性能（以无限特征的等变脊回归为例）。
5. 经验上评估对称性感知方法在各向异性数据集上的表现，发现其效果具有数据集依赖性。

Result: 1. 提出的度量标准能够量化数据集的各向异性。
2. 在多个基准点云数据集中发现了出乎意料的高度对称性排列。
3. 理论证明了分布对称性破坏会影响不变方法的性能。
4. 经验发现，等变方法在各向异性数据集上的效果并不一致，有些数据集上仍然有效，而有些则不然。

Conclusion: 理解等变性方法的有效性（包括其成功和失败的原因）需要重新审视数据本身的对称性偏差。当数据分布存在对称性破坏时，即使是理论上不变或等变的方法也可能无法达到最优性能。因此，在应用对称性感知方法时，需要根据具体数据集的特性进行评估和调整。

Abstract: Symmetry-aware methods for machine learning, such as data augmentation and
equivariant architectures, encourage correct model behavior on all
transformations (e.g. rotations or permutations) of the original dataset. These
methods can improve generalization and sample efficiency, under the assumption
that the transformed datapoints are highly probable, or "important", under the
test distribution. In this work, we develop a method for critically evaluating
this assumption. In particular, we propose a metric to quantify the amount of
anisotropy, or symmetry-breaking, in a dataset, via a two-sample neural
classifier test that distinguishes between the original dataset and its
randomly augmented equivalent. We validate our metric on synthetic datasets,
and then use it to uncover surprisingly high degrees of alignment in several
benchmark point cloud datasets. We show theoretically that distributional
symmetry-breaking can actually prevent invariant methods from performing
optimally even when the underlying labels are truly invariant, as we show for
invariant ridge regression in the infinite feature limit. Empirically, we find
that the implication for symmetry-aware methods is dataset-dependent:
equivariant methods still impart benefits on some anisotropic datasets, but not
others. Overall, these findings suggest that understanding equivariance -- both
when it works, and why -- may require rethinking symmetry biases in the data.

</details>


### [435] [Catalyst GFlowNet for electrocatalyst design: A hydrogen evolution reaction case study](https://arxiv.org/abs/2510.02142)
*Lena Podina,Christina Humer,Alexandre Duval,Victor Schmidt,Ali Ramlaoui,Shahana Chatterjee,Yoshua Bengio,Alex Hernandez-Garcia,David Rolnick,Félix Therrien*

Main category: cs.LG

TL;DR: 使用基于机器学习的生成模型GFlowNet来发现高效且经济的析氢反应催化剂，并成功识别出铂是最优催化剂。


<details>
  <summary>Details</summary>
Motivation: 开发高效且经济的析氢反应催化剂对于加速可再生能源的采用和确保能源供应稳定至关重要，但目前仍面临挑战。

Method: 提出了一种名为Catalyst GFlowNet的生成模型，该模型利用基于机器学习的形成能和吸附能预测器来设计高效的催化剂晶面。

Result: 通过在析氢反应（HES的关键反应）中的概念验证应用，成功识别出铂（Pt）作为最高效的已知催化剂。

Conclusion: 该生成模型框架为加速寻找新颖高效的催化剂提供了一条有前途的途径，并计划将其应用于氧析出反应等领域。

Abstract: Efficient and inexpensive energy storage is essential for accelerating the
adoption of renewable energy and ensuring a stable supply, despite fluctuations
in sources such as wind and solar. Electrocatalysts play a key role in hydrogen
energy storage (HES), allowing the energy to be stored as hydrogen. However,
the development of affordable and high-performance catalysts for this process
remains a significant challenge. We introduce Catalyst GFlowNet, a generative
model that leverages machine learning-based predictors of formation and
adsorption energy to design crystal surfaces that act as efficient catalysts.
We demonstrate the performance of the model through a proof-of-concept
application to the hydrogen evolution reaction, a key reaction in HES, for
which we successfully identified platinum as the most efficient known catalyst.
In future work, we aim to extend this approach to the oxygen evolution
reaction, where current optimal catalysts are expensive metal oxides, and open
the search space to discover new materials. This generative modeling framework
offers a promising pathway for accelerating the search for novel and efficient
catalysts.

</details>


### [436] [RheOFormer: A generative transformer model for simulation of complex fluids and flows](https://arxiv.org/abs/2510.01365)
*Maedeh Saberi,Amir Barati Farimani,Safa Jamali*

Main category: cs.LG

TL;DR: RheoFormer是一种利用自注意力机制的生成算子学习方法，可以高效地学习复杂流体的空间相互作用和特征，并能准确预测其时空演化。


<details>
  <summary>Details</summary>
Motivation: 对在流动条件下模拟软材料力学以设计具有目标特性的材料和工程过程至关重要，而传统数值方法计算成本高且可扩展性差。

Method: 提出了一种名为RheoFormer的生成算子学习方法，该方法利用自注意力机制来学习复杂流体的空间相互作用和特征。

Result: RheoFormer在不同粘度、非粘度、粘弹性、弹粘塑性力学和复杂域的各种流动条件下进行了测试，结果表明它可以准确学习标量和张量非线性力学，并预测其流动的时空演化，即使在训练数据集有限的情况下也是如此。

Conclusion: RheoFormer具有强大的泛化能力和计算效率，可作为加速复杂流体模拟、推进数据驱动实验和实现实时过程优化的可靠神经代理。

Abstract: The ability to model mechanics of soft materials under flowing conditions is
key in designing and engineering processes and materials with targeted
properties. This generally requires solution of internal stress tensor, related
to the deformation tensor through nonlinear and history-dependent constitutive
models. Traditional numerical methods for non-Newtonian fluid dynamics often
suffer from prohibitive computational demands and poor scalability to new
problem instances. Developments in data-driven methods have mitigated some
limitations but still require retraining across varied physical conditions. In
this work, we introduce Rheological Operator Transformer (RheOFormer), a
generative operator learning method leveraging self-attention to efficiently
learn different spatial interactions and features of complex fluid flows. We
benchmark RheOFormer across a range of different viscometric and
non-viscometric flows with different types of viscoelastic and
elastoviscoplastic mechanics in complex domains against ground truth solutions.
Our results demonstrate that RheOFormer can accurately learn both scalar and
tensorial nonlinear mechanics of different complex fluids and predict the
spatio-temporal evolution of their flows, even when trained on limited
datasets. Its strong generalization capabilities and computational efficiency
establish RheOFormer as a robust neural surrogate for accelerating predictive
complex fluid simulations, advancing data-driven experimentation, and enabling
real-time process optimization across a wide range of applications.

</details>


### [437] [Selective Underfitting in Diffusion Models](https://arxiv.org/abs/2510.01378)
*Kiwhan Song,Jaeyeon Kim,Sitan Chen,Yilun Du,Sham Kakade,Vincent Sitzmann*

Main category: cs.LG

TL;DR: 扩散模型通过选择性欠拟合经验分数来学习和生成新颖样本。


<details>
  <summary>Details</summary>
Motivation: 探讨扩散模型在训练过程中学习到的分数函数，以及这如何影响其生成新样本的能力。普遍观点认为扩散模型因训练中的归纳偏置而欠拟合经验分数，但本文对此进行了细化。

Method: 提出“选择性欠拟合”的概念，即扩散模型在某些区域更准确地拟合分数，而在其他区域欠拟合。通过表征这些区域并进行实证干预来验证此观点。

Result: 实证结果表明，选择性欠拟合是理解扩散模型泛化和生成性能的关键因素。

Conclusion: 选择性欠拟合为理解扩散模型的行为提供了新的、可检验的见解，并对其泛化和生成性能有重要启示。

Abstract: Diffusion models have emerged as the principal paradigm for generative
modeling across various domains. During training, they learn the score
function, which in turn is used to generate samples at inference. They raise a
basic yet unsolved question: which score do they actually learn? In principle,
a diffusion model that matches the empirical score in the entire data space
would simply reproduce the training data, failing to generate novel samples.
Recent work addresses this question by arguing that diffusion models underfit
the empirical score due to training-time inductive biases. In this work, we
refine this perspective, introducing the notion of selective underfitting:
instead of underfitting the score everywhere, better diffusion models more
accurately approximate the score in certain regions of input space, while
underfitting it in others. We characterize these regions and design empirical
interventions to validate our perspective. Our results establish that selective
underfitting is essential for understanding diffusion models, yielding new,
testable insights into their generalization and generative performance.

</details>


### [438] [Fine-Tuning Masked Diffusion for Provable Self-Correction](https://arxiv.org/abs/2510.01384)
*Jaeyeon Kim,Seunggeun Kim,Taekyun Lee,David Z. Pan,Hyeji Kim,Sham Kakade,Sitan Chen*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: A natural desideratum for generative models is self-correction--detecting and
revising low-quality tokens at inference. While Masked Diffusion Models (MDMs)
have emerged as a promising approach for generative modeling in discrete
spaces, their capacity for self-correction remains poorly understood. Prior
attempts to incorporate self-correction into MDMs either require overhauling
MDM architectures/training or rely on imprecise proxies for token quality,
limiting their applicability. Motivated by this, we introduce PRISM--Plug-in
Remasking for Inference-time Self-correction of Masked Diffusions--a
lightweight, model-agnostic approach that applies to any pretrained MDM.
Theoretically, PRISM defines a self-correction loss that provably learns
per-token quality scores, without RL or a verifier. These quality scores are
computed in the same forward pass with MDM and used to detect low-quality
tokens. Empirically, PRISM advances MDM inference across domains and scales:
Sudoku; unconditional text (170M); and code with LLaDA (8B).

</details>


### [439] [Transformers Discover Molecular Structure Without Graph Priors](https://arxiv.org/abs/2510.02259)
*Tobias Kreiman,Yutong Bai,Fadi Atieh,Elizabeth Weaver,Eric Qu,Aditi S. Krishnapriyan*

Main category: cs.LG

TL;DR: Transformer可以直接处理分子中的笛卡尔坐标，在分子性质预测和机器学习原子间势方面，其表现能媲美甚至超越传统的GNN。


<details>
  <summary>Details</summary>
Motivation: GNNs在分子机器学习中是主流，但其固定的图结构限制了表达能力和推理速度。本研究旨在探索不依赖固定图结构，直接在笛卡尔坐标上训练的Transformer模型在分子能量和力场预测方面的潜力。

Method: 在OMol25数据集上，将Transformer模型与最先进的等变GNN在相同的计算预算下进行训练和比较，分析Transformer学习到的物理规律和模型扩展性。

Result: Transformer模型在能量和力场预测方面达到了与最先进GNN相当的平均绝对误差。Transformer能够自适应地学习物理规律，例如注意力权重随原子间距的倒数衰减，并且不受固定图结构偏见的限制。此外，Transformer在扩展训练资源时，表现出可预测的性能提升，符合其他领域的经验定律。

Conclusion: Transformer模型能够自适应地学习到GNN的优势特性，挑战了分子建模中对固定图归纳偏置的依赖性，并为标准化、可扩展的分子建模架构指明了方向。

Abstract: Graph Neural Networks (GNNs) are the dominant architecture for molecular
machine learning, particularly for molecular property prediction and machine
learning interatomic potentials (MLIPs). GNNs perform message passing on
predefined graphs often induced by a fixed radius cutoff or k-nearest neighbor
scheme. While this design aligns with the locality present in many molecular
tasks, a hard-coded graph can limit expressivity due to the fixed receptive
field and slows down inference with sparse graph operations. In this work, we
investigate whether pure, unmodified Transformers trained directly on Cartesian
coordinates$\unicode{x2013}$without predefined graphs or physical
priors$\unicode{x2013}$can approximate molecular energies and forces. As a
starting point for our analysis, we demonstrate how to train a Transformer to
competitive energy and force mean absolute errors under a matched training
compute budget, relative to a state-of-the-art equivariant GNN on the OMol25
dataset. We discover that the Transformer learns physically consistent
patterns$\unicode{x2013}$such as attention weights that decay inversely with
interatomic distance$\unicode{x2013}$and flexibly adapts them across different
molecular environments due to the absence of hard-coded biases. The use of a
standard Transformer also unlocks predictable improvements with respect to
scaling training resources, consistent with empirical scaling laws observed in
other domains. Our results demonstrate that many favorable properties of GNNs
can emerge adaptively in Transformers, challenging the necessity of hard-coded
graph inductive biases and pointing toward standardized, scalable architectures
for molecular modeling.

</details>


### [440] [How to Combat Reactive and Dynamic Jamming Attacks with Reinforcement Learning](https://arxiv.org/abs/2510.02265)
*Yalin E. Sagduyu,Tugba Erpek,Kemal Davaslioglu,Sastry Kompella*

Main category: cs.LG

TL;DR: 本论文研究了如何通过强化学习（RL）来对抗动态的信道干扰问题。


<details>
  <summary>Details</summary>
Motivation: 研究目的是为了解决通信系统中，干扰者动态选择信道和侦测阈值进行干扰时，通信方如何进行自适应以优化吞吐量的问题，且通信方事先对信道状况或干扰策略一无所知。

Method: 采用强化学习（RL）方法，包括Q-learning（用于离散干扰事件状态）和深度Q网络（DQN）（用于基于接收功率的连续状态），来让通信方自适应地调整发送功率、调制方式和信道选择。

Result: 结果表明，在不同的奖励函数和动作集下，RL能够快速适应频谱动态变化，并在信道和干扰策略随时间变化的情况下，仍能维持较高的通信速率。

Conclusion: 强化学习（RL）能够有效地帮助通信系统在动态变化的干扰环境下，自适应地调整策略以维持稳定的通信性能。

Abstract: This paper studies the problem of mitigating reactive jamming, where a jammer
adopts a dynamic policy of selecting channels and sensing thresholds to detect
and jam ongoing transmissions. The transmitter-receiver pair learns to avoid
jamming and optimize throughput over time (without prior knowledge of channel
conditions or jamming strategies) by using reinforcement learning (RL) to adapt
transmit power, modulation, and channel selection. Q-learning is employed for
discrete jamming-event states, while Deep Q-Networks (DQN) are employed for
continuous states based on received power. Through different reward functions
and action sets, the results show that RL can adapt rapidly to spectrum
dynamics and sustain high rates as channels and jamming policies change over
time.

</details>


### [441] [Optimal Stopping vs Best-of-$N$ for Inference Time Optimization](https://arxiv.org/abs/2510.01394)
*Yusuf Kalayci,Vinod Raman,Shaddin Dughmi*

Main category: cs.LG

TL;DR: We propose a new framework for optimizing LLM inference based on the Pandora's Box problem. Our algorithm adaptively decides when to stop generating text to balance quality and cost, achieving similar performance to existing methods with 15-35% fewer generations.


<details>
  <summary>Details</summary>
Motivation: Balancing LLM output quality and inference cost is crucial, especially with multiple generations. Existing methods often require many generations to ensure quality.

Method: We adapt the Pandora's Box problem to LLM generation, where each generation is a 'box' with a random reward. We develop a UCB-style algorithm that doesn't need to know the reward distribution and an adaptive version that normalizes rewards and learns stopping thresholds using a Bradley-Terry inspired transformation for practical LLM settings.

Result: Our adaptive strategy achieves the same performance as non-adaptive Best-of-N sampling but requires 15-35% fewer generations on average across AlpacaFarm and HH-RLHF datasets with multiple LLM-reward model pairs.

Conclusion: Our work provides a principled approach bridging optimal stopping theory and inference-time scaling for LLMs, offering theoretical guarantees and practical improvements in efficiency for LLM deployment.

Abstract: Large language model (LLM) generation often requires balancing output quality
against inference cost, especially when using multiple generations. We
introduce a new framework for inference-time optimization based on the
classical Pandora's Box problem. Viewing each generation as opening a costly
"box" with random reward, we develop algorithms that decide when to stop
generating without knowing the underlying reward distribution. Our first
contribution is a UCB-style Pandora's Box algorithm, which achieves performance
that is provably close to Weitzman's algorithm, the optimal strategy when the
distribution is known. We further adapt this method to practical LLM settings
by addressing reward scaling across prompts via a Bradley-Terry inspired
transformation. This leads to an adaptive inference-time optimization method
that normalizes rewards and learns stopping thresholds on the fly. Experiments
on the AlpacaFarm and HH-RLHF datasets, using multiple LLM-reward model pairs,
show that our adaptive strategy can obtain the same performance as non-adaptive
Best-of-N sampling while requiring 15-35 percent fewer generations on average.
Our results establish a principled bridge between optimal stopping theory and
inference-time scaling, providing both theoretical performance bounds and
practical efficiency gains for LLM deployment.

</details>


### [442] [Neural Network Surrogates for Free Energy Computation of Complex Chemical Systems](https://arxiv.org/abs/2510.01396)
*Wasut Pornpatcharapong*

Main category: cs.LG

TL;DR: We introduce a neural network framework to learn collective variables (CVs) and their Jacobians directly from Cartesian coordinates, enabling the use of complex CVs in free energy calculations.


<details>
  <summary>Details</summary>
Motivation: Traditional free energy reconstruction methods like GPR require Jacobians of CVs, which is a bottleneck when using complex or machine-learned CVs.

Method: A neural network surrogate framework is used to learn CVs directly from Cartesian coordinates. Automatic differentiation is employed to provide Jacobians, bypassing the need for analytical forms.

Result: The method achieves high accuracy for both simple and complex CVs on an MgCl2 ion-pairing system. Jacobian errors are found to have a near-Gaussian distribution, suitable for GPR.

Conclusion: This framework allows gradient-based free energy methods to utilize complex and machine-learned CVs, expanding applications in biochemistry and materials simulations.

Abstract: Free energy reconstruction methods such as Gaussian Process Regression (GPR)
require Jacobians of the collective variables (CVs), a bottleneck that
restricts the use of complex or machine-learned CVs. We introduce a neural
network surrogate framework that learns CVs directly from Cartesian coordinates
and uses automatic differentiation to provide Jacobians, bypassing analytical
forms. On an MgCl2 ion-pairing system, our method achieved high accuracy for
both a simple distance CV and a complex coordination-number CV. Moreover,
Jacobian errors also followed a near-Gaussian distribution, making them
suitable for GPR pipelines. This framework enables gradient-based free energy
methods to incorporate complex and machine-learned CVs, broadening the scope of
biochemistry and materials simulations.

</details>


### [443] [Ultra-Efficient Decoding for End-to-End Neural Compression and Reconstruction](https://arxiv.org/abs/2510.01407)
*Ethan G. Rogers,Cheng Wang*

Main category: cs.LG

TL;DR: 通过在具有矢量量化的自动编码器中加入低秩表示，我们开发了一种新的压缩-重建框架，该框架通过高效的低秩运算显著降低了神经图像压缩的解码器计算开销，同时保持了高图像保真度。


<details>
  <summary>Details</summary>
Motivation: 现有的基于深度学习的图像压缩方法虽然压缩率高，但解码器计算复杂度高，限制了其应用。

Method: 在具有矢量量化的自动编码器中引入低秩表示，并利用高效的低秩运算进行图像重建。

Result: 所提出的方法显著降低了解码阶段的计算开销，解决了计算瓶颈问题，同时保持了高图像质量。

Conclusion: 我们提出的基于低秩表示的框架能够高效地重建图像，解决了现有神经压缩方法的解码器计算瓶颈问题。

Abstract: Image compression and reconstruction are crucial for various digital
applications. While contemporary neural compression methods achieve impressive
compression rates, the adoption of such technology has been largely hindered by
the complexity and large computational costs of the convolution-based decoders
during data reconstruction. To address the decoder bottleneck in neural
compression, we develop a new compression-reconstruction framework based on
incorporating low-rank representation in an autoencoder with vector
quantization. We demonstrated that performing a series of computationally
efficient low-rank operations on the learned latent representation of images
can efficiently reconstruct the data with high quality. Our approach
dramatically reduces the computational overhead in the decoding phase of neural
compression/reconstruction, essentially eliminating the decoder compute
bottleneck while maintaining high fidelity of image outputs.

</details>


### [444] [Edge Artificial Intelligence: A Systematic Review of Evolution, Taxonomic Frameworks, and Future Horizons](https://arxiv.org/abs/2510.01439)
*Mohamad Abou Ali,Fadi Dornaika*

Main category: cs.LG

TL;DR: Edge AI 将智能嵌入网络边缘设备，实现实时处理、提高隐私和降低延迟。本综述通过部署位置、TinyML 和联邦学习等处理能力、应用领域和硬件类型等多维度分类，系统地考察了 Edge AI 的发展、现状和未来方向。


<details>
  <summary>Details</summary>
Motivation: Edge AI 通过在靠近数据源的地方处理数据，实现实时处理、提高隐私和降低延迟。

Method: 遵循 PRISMA 指南，分析追溯了从早期内容分发网络和雾计算到现代设备上智能的领域。探讨了专门的硬件加速器、优化的软件和通信协议等核心支撑技术。

Result: 评估了资源限制、安全、模型管理、功耗和连接性等挑战。强调了神经形态硬件、持续学习算法、边缘-云协作和可信度集成等方面的新兴机遇。

Conclusion: 提供了一个全面的框架，供研究人员和实践者参考。

Abstract: Edge Artificial Intelligence (Edge AI) embeds intelligence directly into
devices at the network edge, enabling real-time processing with improved
privacy and reduced latency by processing data close to its source. This review
systematically examines the evolution, current landscape, and future directions
of Edge AI through a multi-dimensional taxonomy including deployment location,
processing capabilities such as TinyML and federated learning, application
domains, and hardware types. Following PRISMA guidelines, the analysis traces
the field from early content delivery networks and fog computing to modern
on-device intelligence. Core enabling technologies such as specialized hardware
accelerators, optimized software, and communication protocols are explored.
Challenges including resource limitations, security, model management, power
consumption, and connectivity are critically assessed. Emerging opportunities
in neuromorphic hardware, continual learning algorithms, edge-cloud
collaboration, and trustworthiness integration are highlighted, providing a
comprehensive framework for researchers and practitioners.

</details>


### [445] [SoftAdaClip: A Smooth Clipping Strategy for Fair and Private Model Training](https://arxiv.org/abs/2510.01447)
*Dorsa Soleymani,Ali Dadsetan,Frank Rudzicz*

Main category: cs.LG

TL;DR: DP-SGD中的梯度裁剪会不成比例地抑制少数群体的学习信号，导致模型性能和公平性下降。SoftAdaClip通过使用基于tanh的平滑变换替代硬裁剪，并在MIMIC-III、GOSSIS-eICU和Adult Income等数据集上进行评估，显著减少了模型在不同子群之间的差异。


<details>
  <summary>Details</summary>
Motivation: 差分隐私（DP）在保护敏感数据方面虽然提供了强大的保障，但在模型性能和公平性方面，尤其是在代表性不足的群体上，常常会带来负面影响。其中一个主要原因是DP-SGD中的梯度裁剪，这种方法可能会不成比例地压制少数群体的学习信号。

Method: 提出了一种名为SoftAdaClip的差分隐私训练方法，该方法用基于tanh的平滑变换来替代硬裁剪，从而在限制梯度的敏感性的同时，保留梯度的大小关系。

Result: 在MIMIC-III（临床文本）、GOSSIS-eICU（结构化医疗保健）和Adult Income（表格数据）等多个数据集上的评估结果表明，与DP-SGD相比，SoftAdaClip将子群体的差异最多降低了87%；与Adaptive-DPSGD相比，最多降低了48%。这些减少的子群体差异具有统计学意义。

Conclusion: 将平滑变换与自适应机制相结合对于实现公平且隐私保护的模型训练至关重要。

Abstract: Differential privacy (DP) provides strong protection for sensitive data, but
often reduces model performance and fairness, especially for underrepresented
groups. One major reason is gradient clipping in DP-SGD, which can
disproportionately suppress learning signals for minority subpopulations.
Although adaptive clipping can enhance utility, it still relies on uniform hard
clipping, which may restrict fairness. To address this, we introduce
SoftAdaClip, a differentially private training method that replaces hard
clipping with a smooth, tanh-based transformation to preserve relative gradient
magnitudes while bounding sensitivity. We evaluate SoftAdaClip on various
datasets, including MIMIC-III (clinical text), GOSSIS-eICU (structured
healthcare), and Adult Income (tabular data). Our results show that SoftAdaClip
reduces subgroup disparities by up to 87% compared to DP-SGD and up to 48%
compared to Adaptive-DPSGD, and these reductions in subgroup disparities are
statistically significant. These findings underscore the importance of
integrating smooth transformations with adaptive mechanisms to achieve fair and
private model training.

</details>


### [446] [Local Linear Attention: An Optimal Interpolation of Linear and Softmax Attention For Test-Time Regression](https://arxiv.org/abs/2510.01450)
*Yifei Zuo,Yutong Yin,Zhichen Zeng,Ang Li,Banghua Zhu,Zhaoran Wang*

Main category: cs.LG

TL;DR: 提出了一种名为局部线性注意力（LLA）的新型注意力机制，该机制源于非参数统计学和测试时回归，并在理论上和经验上都优于现有方法，尤其在处理非平稳性方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 虽然Transformer在各领域取得了成功，但对计算成本更高的、理论更充分的、更具表达力的注意力机制的研究相对较少。

Method: 提出局部线性注意力（LLA），通过偏差-方差权衡分析证明其在关联记忆方面的理论优势。提出两种内存高效的原语来解决计算挑战。引入FlashLLA，一种硬件高效的、分块的算法，用于在现代加速器上进行可扩展和并行计算。实现了一个定制的推理内核以减少内存开销。

Result: LLA在测试时回归、上下文内回归、关联回忆和状态跟踪任务上表现出色，特别是在测试时训练和上下文学习方面，优于强基线模型。实验证明了LLA的有效性、可扩展性和大规模模型的适用性。

Conclusion: LLA是一种有前景的新型注意力机制，具有理论优势和实际应用价值，尤其在处理非平稳性和大规模模型方面。

Abstract: Transformer architectures have achieved remarkable success in various
domains. While efficient alternatives to Softmax Attention have been widely
studied, the search for more expressive mechanisms grounded in theoretical
insight-even at greater computational cost-has been relatively underexplored.
In this work, we bridge this gap by proposing Local Linear Attention (LLA), a
novel attention mechanism derived from nonparametric statistics through the
lens of test-time regression. First, we show that LLA offers theoretical
advantages over Linear and Softmax Attention for associative memory via a
bias-variance trade-off analysis. Next, we address its computational challenges
and propose two memory-efficient primitives to tackle the $\Theta(n^2 d)$ and
$\Theta(n d^2)$ complexity. We then introduce FlashLLA, a hardware-efficient,
blockwise algorithm that enables scalable and parallel computation on modern
accelerators. In addition, we implement and profile a customized inference
kernel that significantly reduces memory overheads. Finally, we empirically
validate the advantages and limitations of LLA on test-time regression,
in-context regression, associative recall and state tracking tasks. Experiment
results demonstrate that LLA effectively adapts to non-stationarity,
outperforming strong baselines in test-time training and in-context learning,
and exhibiting promising evidence for its scalability and applicability in
large-scale models. Code is available at
https://github.com/Yifei-Zuo/Flash-LLA.

</details>


### [447] [SCOPED: Score-Curvature Out-of-distribution Proximity Evaluator for Diffusion](https://arxiv.org/abs/2510.01456)
*Brett Barkley,Preston Culbertson,David Fridovich-Keil*

Main category: cs.LG

TL;DR: SCOPED是一种用于扩散模型的快速、通用的OOD检测方法，通过结合分数函数的雅可比迹和平方范数，并使用核密度估计来估计分数，实现了高效的OOD检测，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 为了实现机器学习系统在视觉、机器人、强化学习等领域的可靠部署，OOD检测至关重要。

Method: SCOPED结合了模型分数函数的雅可比迹和平方范数，并利用核密度估计来估计分数，从而计算一个单一的检验统计量。该方法通过Hutchinson的迹估计器实现了高效的雅可比向量积（JVP）计算。

Result: SCOPED在四个视觉基准测试中取得了具有竞争力的或最先进的精确率-召回率得分，计算成本却很低。该方法还可以推广到机器人控制任务，识别奖励函数和训练机制的变化。在最简单的情况下，该方法只需要一次前向传播和一次雅可比向量积。

Conclusion: SCOPED是一种高效、通用的OOD检测方法，为在现实世界领域（包括视觉感知伪影、自回归模型中的异常值检测、强化学习中的探索以及无监督训练的数据集策选）进行快速可靠的OOD检测奠定了实用基础。

Abstract: Out-of-distribution (OOD) detection is essential for reliable deployment of
machine learning systems in vision, robotics, reinforcement learning, and
beyond. We introduce Score-Curvature Out-of-distribution Proximity Evaluator
for Diffusion (SCOPED), a fast and general-purpose OOD detection method for
diffusion models that reduces the number of forward passes on the trained model
by an order of magnitude compared to prior methods, outperforming most
diffusion-based baselines and closely approaching the accuracy of the strongest
ones. SCOPED is computed from a single diffusion model trained once on a
diverse dataset, and combines the Jacobian trace and squared norm of the
model's score function into a single test statistic. Rather than thresholding
on a fixed value, we estimate the in-distribution density of SCOPED scores
using kernel density estimation, enabling a flexible, unsupervised test that,
in the simplest case, only requires a single forward pass and one
Jacobian-vector product (JVP), made efficient by Hutchinson's trace estimator.
On four vision benchmarks, SCOPED achieves competitive or state-of-the-art
precision-recall scores despite its low computational cost. The same method
generalizes to robotic control tasks with shared state and action spaces,
identifying distribution shifts across reward functions and training regimes.
These results position SCOPED as a practical foundation for fast and reliable
OOD detection in real-world domains, including perceptual artifacts in vision,
outlier detection in autoregressive models, exploration in reinforcement
learning, and dataset curation for unsupervised training.

</details>


### [448] [Fixing That Free Lunch: When, Where, and Why Synthetic Data Fails in Model-Based Policy Optimization](https://arxiv.org/abs/2510.01457)
*Brett Barkley,David Fridovich-Keil*

Main category: cs.LG

TL;DR: 合成数据在模型基础强化学习中至关重要，但可能导致性能下降。本研究深入探讨了合成数据在不同环境（OpenAI Gym 和 DeepMind Control Suite）中的作用，特别关注了 MBPO 算法。


<details>
  <summary>Details</summary>
Motivation: 评估合成数据在模型基础强化学习中的作用，特别是 MBPO 算法在不同环境下的表现，并找出其性能差异的原因。

Method: 识别并解决了 MBPO 算法在 DeepMind Control Suite 中遇到的两大问题：动力学模型和奖励模型之间的尺度不匹配，以及目标表示不佳导致的方差增大。

Result: 通过解决上述问题，MBPO 算法在七项 DeepMind Control Suite 任务中的五项中超越了 Soft Actor-Critic (SAC)，同时保持了在 OpenAI Gym 中的优异表现。

Conclusion: 合成数据的有效性高度依赖于环境结构，算法设计应考虑这些因素，以避免性能下降，并追求更通用的解决方案。

Abstract: Synthetic data is a core component of data-efficient Dyna-style model-based
reinforcement learning, yet it can also degrade performance. We study when it
helps, where it fails, and why, and we show that addressing the resulting
failure modes enables policy improvement that was previously unattainable. We
focus on Model-Based Policy Optimization (MBPO), which performs actor and
critic updates using synthetic action counterfactuals. Despite reports of
strong and generalizable sample-efficiency gains in OpenAI Gym, recent work
shows that MBPO often underperforms its model-free counterpart, Soft
Actor-Critic (SAC), in the DeepMind Control Suite (DMC). Although both suites
involve continuous control with proprioceptive robots, this shift leads to
sharp performance losses across seven challenging DMC tasks, with MBPO failing
in cases where claims of generalization from Gym would imply success. This
reveals how environment-specific assumptions can become implicitly encoded into
algorithm design when evaluation is limited. We identify two coupled issues
behind these failures: scale mismatches between dynamics and reward models that
induce critic underestimation and hinder policy improvement during model-policy
coevolution, and a poor choice of target representation that inflates model
variance and produces error-prone rollouts. Addressing these failure modes
enables policy improvement where none was previously possible, allowing MBPO to
outperform SAC in five of seven tasks while preserving the strong performance
previously reported in OpenAI Gym. Rather than aiming only for incremental
average gains, we hope our findings motivate the community to develop
taxonomies that tie MDP task- and environment-level structure to algorithmic
failure modes, pursue unified solutions where possible, and clarify how
benchmark choices ultimately shape the conditions under which algorithms
generalize.

</details>


### [449] [How Well Can Preference Optimization Generalize Under Noisy Feedback?](https://arxiv.org/abs/2510.01458)
*Shawn Im,Yixuan Li*

Main category: cs.LG

TL;DR: 在人类反馈存在噪声的情况下，本文分析了偏好优化方法，并提供了泛化保证。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）能力的提升，使其与人类偏好对齐变得至关重要。现有的偏好优化方法大多假设反馈是无噪声的，但这在现实中是不切实际的。

Method: 本文研究了噪声反馈对偏好优化的影响，并在这些条件下提供了泛化保证。我们考虑了对应常见现实噪声源（如错误标记和不确定性）的噪声模型。不同于假设收敛的传统分析，本文侧重于有限步数的偏好优化，并提供了更贴近实际LLM训练的见解。

Result: 我们分析了在不同噪声类型和噪声率下，泛化能力如何随着偏好数据分布和样本数量的变化而衰减。

Conclusion: 本文提出的噪声偏好学习分析方法适用于DPO、IPO、SLiC等一系列偏好优化损失。在当代LLMs上的实证验证证实了我们研究结果的实际意义，为开发与人类偏好对齐的AI系统提供了有价值的见解。

Abstract: As large language models (LLMs) advance their capabilities, aligning these
models with human preferences has become crucial. Preference optimization,
which trains models to distinguish between preferred and non-preferred
responses based on human feedback, has become a crucial component for aligning
LLMs. However, most existing works assume noise-free feedback, which is
unrealistic due to the inherent errors and inconsistencies in human judgments.
This paper addresses the impact of noisy feedback on preference optimization,
providing generalization guarantees under these conditions. In particular, we
consider noise models that correspond to common real-world sources of noise,
such as mislabeling and uncertainty. Unlike traditional analyses that assume
convergence, our work focuses on finite-step preference optimization, offering
new insights that are more aligned with practical LLM training. We describe how
generalization decays with different types of noise across levels of noise
rates based on the preference data distribution and number of samples. Our
analysis for noisy preference learning applies to a broad family of preference
optimization losses such as DPO, IPO, SLiC, etc. Empirical validation on
contemporary LLMs confirms the practical relevance of our findings, offering
valuable insights for developing AI systems that align with human preferences.

</details>


### [450] [LSPO: Length-aware Dynamic Sampling for Policy Optimization in LLM Reasoning](https://arxiv.org/abs/2510.01459)
*Weizhe Chen,Sven Koenig,Bistra Dilkina*

Main category: cs.LG

TL;DR: 提出一种新颖的元强化学习算法LSPO，通过动态选择训练数据来提高LLM在推理任务上的学习效率。


<details>
  <summary>Details</summary>
Motivation: 受LLM过度思考现象的启发，旨在提高强化学习与可验证奖励（RLVR）在LLM推理任务上的效率和有效性。

Method: 提出长度感知采样策略优化（LSPO）算法，该算法根据平均响应长度动态选择每一步的训练数据，是一种新颖的元RLVR算法。

Result: LSPO在多个基础模型和数据集上均能稳定地提升学习效果。

Conclusion: LSPO通过动态调整训练数据选择，有效解决了LLM在推理任务中的过度思考问题，提高了学习效率，并为未来研究指明了方向。

Abstract: Since the release of Deepseek-R1, reinforcement learning with verifiable
rewards (RLVR) has become a central approach for training large language models
(LLMs) on reasoning tasks. Recent work has largely focused on modifying loss
functions to make RLVR more efficient and effective. In this paper, motivated
by studies of overthinking in LLMs, we propose Length-aware Sampling for Policy
Optimization (LSPO), a novel meta-RLVR algorithm that dynamically selects
training data at each step based on the average response length. We evaluate
LSPO across multiple base models and datasets, demonstrating that it
consistently improves learning effectiveness. In addition, we conduct a
detailed ablation study to examine alternative ways of incorporating length
signals into dynamic sampling, offering further insights and highlighting
promising directions for future research.

</details>


### [451] [The Three Regimes of Offline-to-Online Reinforcement Learning](https://arxiv.org/abs/2510.01460)
*Lu Li,Tianwei Ni,Yihao Sun,Pierre-Luc Bacon*

Main category: cs.LG

TL;DR: 文章提出了一个稳定性-可塑性原则来解释和指导离线到在线强化学习中的在线微调设计选择。


<details>
  <summary>Details</summary>
Motivation: 离线到在线强化学习在利用离线数据集进行预训练和在线交互进行微调方面具有实用性，但其经验行为高度不一致，在线微调的设计选择在一个环境中有效，在另一个环境中可能完全失败。

Method: 提出一个稳定性-可塑性原则，主张在在线微调过程中，根据预训练策略或离线数据集的性能表现，保留其中较优的知识，同时保持足够的可塑性。该原则识别出三种在线微调模式，每种模式需要不同的稳定性特性。

Result: 通过大规模实证研究验证了该框架，发现在63个案例中的45个案例中，结果与框架的预测高度一致。

Conclusion: 该工作提供了一个原则性框架，能够根据离线数据集和预训练策略的相对性能，指导离线到在线强化学习中的设计选择。

Abstract: Offline-to-online reinforcement learning (RL) has emerged as a practical
paradigm that leverages offline datasets for pretraining and online
interactions for fine-tuning. However, its empirical behavior is highly
inconsistent: design choices of online-fine tuning that work well in one
setting can fail completely in another. We propose a stability--plasticity
principle that can explain this inconsistency: we should preserve the knowledge
of pretrained policy or offline dataset during online fine-tuning, whichever is
better, while maintaining sufficient plasticity. This perspective identifies
three regimes of online fine-tuning, each requiring distinct stability
properties. We validate this framework through a large-scale empirical study,
finding that the results strongly align with its predictions in 45 of 63 cases.
This work provides a principled framework for guiding design choices in
offline-to-online RL based on the relative performance of the offline dataset
and the pretrained policy.

</details>


### [452] [Fine-tuning LLMs with variational Bayesian last layer for high-dimensional Bayesian optimzation](https://arxiv.org/abs/2510.01471)
*Haotian Xiang,Jinwen Xu,Qin Lu*

Main category: cs.LG

TL;DR: 文章提出了一种名为 LoRA-VBLL 的新方法，它使用大型语言模型 (LLM) 作为代理模型来解决高维黑盒优化问题。该方法通过低秩自适应 (LoRA) 和变分贝叶斯最后一层 (VBLL) 框架进行微调，能够处理不规则变量，并且计算成本低，支持递归更新。为了进一步优化超参数选择，还提出了加权集成 (ENS) 方法，能够对模型权重和参数进行持续更新。实验证明，(ENS-)LoRA-VBLL 在各种高维基准测试和现实世界的分子优化任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 高维黑盒优化问题，特别是那些具有不规则变量（如分类、序数变量）的问题，对于传统的基于高斯过程 (GP) 的贝叶斯优化 (BO) 框架来说是一个挑战。现有方法在处理这些问题时存在局限性，因此需要一种更有效的解决方案。

Method: 该研究提出了一种新颖的框架，将大型语言模型 (LLM) 用作代理模型，以解决高维黑盒优化问题。具体而言，它利用低秩自适应 (LoRA) 技术微调 LLM 参数，并结合变分贝叶斯最后一层 (VBLL) 框架来处理线性回归头的后验。为了自动化超参数选择，还引入了一个加权集成 (ENS) 方法，该方法通过递归贝叶斯方法对模型权重和 LoRA-VBLL 参数进行持续更新。

Result: 实验结果表明，所提出的 (ENS-)LoRA-VBLL 方法在各种高维基准测试和真实的分子优化任务中均取得了优越的性能。该方法不仅计算效率高，而且能够有效处理高维和不规则变量。

Conclusion: LoRA-VBLL 框架，特别是结合了加权集成 (ENS) 方法后，为解决高维黑盒优化问题提供了一种有效且计算成本低的新途径。该方法能够处理不规则变量，并且支持递归更新，在实际应用中展现出强大的潜力。

Abstract: A plethora of applications entail solving black-box optimization problems
with high evaluation costs, including drug discovery, material design, as well
as hyperparameter tuning. Toward finding the global optimum of such black-box
optimization problems with sample efficiency, Bayesian optimization (BO) is a
theoretically elegant framework that relies on a probabilistic surrogate model
so as to iteratively select the query point with well-balanced
exploration-exploitation tradeoffs. The Gaussian process (GP), as the de-facto
choice for surrogate modeling, has achieved compelling performances for vanilla
BO with low-dimensional continuous variables. However, GPs fall short in coping
with high-dimensional counterparts with {\it irregular} variables (e.g.,
categorical, ordinal, etc.). To alleviate this, neural network-based surrogates
have been explored. Inspired by the powerful capabilities of LLMs, we adopt the
LLM as the surrogate to model the mapping from the high-dimensional input
variables to the objective function. To adapt to the current problem, we
leverage the low-rank adaptation (LoRA) to fine-tune the LLM parameters
together with the posterior of a linear regression head via the variational
Bayesian last layer (VBLL) framework. The resulting LoRA-VBLL is not only
computationally light compared to existing alternatives, but also admits
recursive updates. To automate the critical selection of the LoRA rank as well
as other hyperparameters, a weighted ensemble (ENS) of LoRA-VBLL surrogates has
been devised, which further accommodates continual update of the per-model
weight and individual LoRA-VBLL parameters via recursive Bayes. Extensive
experimental results demonstrate the compelling performance of the proposed
(ENS-)LoRA-VBLL approaches on various high-dimensional benchmarks and the
real-world molecular optimization tasks.

</details>


### [453] [PEL-NAS: Search Space Partitioned Architecture Prompt Co-Evolutionary LLM-driven Hardware-Aware Neural Architecture Search](https://arxiv.org/abs/2510.01472)
*Hengyi Zhu,Grace Li Zhang,Shaoyi Huang*

Main category: cs.LG

TL;DR: PEL-NAS通过分区搜索空间、协同进化和零成本预测来优化硬件感知神经架构搜索，能在降低搜索成本的同时生成高精度、低延迟的网络。


<details>
  <summary>Details</summary>
Motivation: 传统硬件感知神经架构搜索（HW-NAS）方法需要联合优化精度和延迟，但现有超网络方法耗时过长，而基于大语言模型（LLM）的方法存在探索偏见，无法发现不同延迟范围内的架构。PEL-NAS旨在解决这些问题，以降低搜索成本并生成高精度、低延迟的网络。

Method: PEL-NAS包含三个关键组件：1）一个由复杂度驱动的分区引擎，通过按复杂度划分搜索空间来强制执行多样性并减轻探索偏见；2）一个由LLM驱动的架构提示协同进化算子，其中LLM首先根据上一轮的结果更新设计启发式知识库，然后对包含该知识库的提示进行架构的引导演化；3）一个零成本预测器，用于避免从头开始训练大量候选模型。

Result: 在HW-NAS-Bench上，PEL-NAS实现了更高的超体积（HV）和更低的反向不满足度（IGD），并且在相似精度下延迟降低高达54%。

Conclusion: PEL-NAS能够以显著降低的搜索成本（从几天缩短到几分钟）生成高精度、低延迟的神经网络架构，解决了现有方法的局限性。

Abstract: Hardware-Aware Neural Architecture Search (HW-NAS) requires joint
optimization of accuracy and latency under device constraints. Traditional
supernet-based methods require multiple GPU days per dataset. Large Language
Model (LLM)-driven approaches avoid training a large supernet and can provide
quick feedback, but we observe an exploration bias: the LLM repeatedly proposes
neural network designs within limited search space and fails to discover
architectures across different latency ranges in the entire search space. To
address this issue, we propose PEL-NAS: a search space Partitioned,
architecture prompt co-Evolutionary and LLM-driven Neural Architecture Search
that can generate neural networks with high accuracy and low latency with
reduced search cost. Our proposed PEL-NAS has three key components: 1) a
complexity-driven partitioning engine that divides the search space by
complexity to enforce diversity and mitigate exploration bias; 2) an
LLM-powered architecture prompt co-evolution operator, in which the LLM first
updates a knowledge base of design heuristics based on results from the
previous round, then performs a guided evolution algorithm on architectures
with prompts that incorporate this knowledge base. Prompts and designs improve
together across rounds which avoids random guesswork and improve efficiency; 3)
a zero-cost predictor to avoid training a large number of candidates from
scratch. Experimental results show that on HW-NAS-Bench, PEL-NAS can achieve
overall higher HV, lower IGD, and up to 54% lower latency than baselines at
similar accuracy. Meanwhile, the search cost drops from days to minutes
compared with traditional supernet baselines.

</details>


### [454] [Understanding Adversarial Transfer: Why Representation-Space Attacks Fail Where Data-Space Attacks Succeed](https://arxiv.org/abs/2510.01494)
*Isha Gupta,Rylan Schaeffer,Joshua Kazdan,Ken Liu,Sanmi Koyejo*

Main category: cs.LG

TL;DR: 对抗性攻击的迁移性并非普遍存在，而取决于其操作域：数据空间攻击可以迁移，而表示空间攻击则不行，除非表示在几何上对齐。


<details>
  <summary>Details</summary>
Motivation: 解释为什么图像越狱攻击在视觉语言模型（VLMs）之间迁移失败，而图像分类器和语言模型的攻击可以迁移，并提出攻击迁移性的根本区别在于攻击是在数据空间还是模型表示空间进行的。

Method: 1. 提出攻击迁移性的基本区别：数据空间攻击可以迁移，表示空间攻击不行，除非表示在几何上对齐。 2. 在四种不同的设置中提供理论和经验证据： a. 在一个简单的设置中，数学上证明了表示空间和数据空间攻击的区别。 b. 针对图像分类器构建表示空间攻击，证明其无法迁移。 c. 针对语言模型构建表示空间攻击，证明其无法迁移。 d. 针对VLMs构建数据空间攻击，证明其可以迁移；并展示表示空间攻击在VLMs的潜在几何形状对齐后可以迁移。

Result: 1. 证明了数据空间攻击与表示空间攻击在迁移性上的根本区别。 2. 经验上验证了该区别在图像分类器、语言模型和VLMs中的有效性。 3. 揭示了在表示空间对齐的情况下，表示空间攻击也可以迁移。

Conclusion: 对抗性攻击的迁移性不是所有攻击的固有属性，而是取决于其操作域（共享数据空间或模型独特的表示空间），这一关键见解有助于构建更鲁棒的模型。

Abstract: The field of adversarial robustness has long established that adversarial
examples can successfully transfer between image classifiers and that text
jailbreaks can successfully transfer between language models (LMs). However, a
pair of recent studies reported being unable to successfully transfer image
jailbreaks between vision-language models (VLMs). To explain this striking
difference, we propose a fundamental distinction regarding the transferability
of attacks against machine learning models: attacks in the input data-space can
transfer, whereas attacks in model representation space do not, at least not
without geometric alignment of representations. We then provide theoretical and
empirical evidence of this hypothesis in four different settings. First, we
mathematically prove this distinction in a simple setting where two networks
compute the same input-output map but via different representations. Second, we
construct representation-space attacks against image classifiers that are as
successful as well-known data-space attacks, but fail to transfer. Third, we
construct representation-space attacks against LMs that successfully jailbreak
the attacked models but again fail to transfer. Fourth, we construct data-space
attacks against VLMs that successfully transfer to new VLMs, and we show that
representation space attacks \emph{can} transfer when VLMs' latent geometries
are sufficiently aligned in post-projector space. Our work reveals that
adversarial transfer is not an inherent property of all attacks but contingent
on their operational domain - the shared data-space versus models' unique
representation spaces - a critical insight for building more robust models.

</details>


### [455] [Realistic CDSS Drug Dosing with End-to-end Recurrent Q-learning for Dual Vasopressor Control](https://arxiv.org/abs/2510.01508)
*Will Y. Zou,Jean Feng,Alexandre Kalimouttou,Jennifer Yuntong Zhang,Christopher W. Seymour,Romain Pirracchio*

Main category: cs.LG

TL;DR: 该研究提出了一种结合离线保守Q学习和新颖循环模型用于脓毒症休克患者双血管升压药给药和控制策略的最优学习方法，通过设计动作空间来处理离散、连续和定向给药策略，以解决临床医生对RL在CDSS中给药决策的疑虑。


<details>
  <summary>Details</summary>
Motivation: 临床医生对强化学习（RL）在临床决策支持系统（CDSS）中的药物剂量调整决策持怀疑态度，尤其是在脓毒症休克等危重情况下。

Method: 本研究采用端到端方法，结合了离线保守Q学习和一种新颖的循环模型（用于捕获ICU时间序列数据的时态依赖性），并设计了一个能够处理离散、连续和定向给药策略的动作空间，用于学习脓毒症休克患者双血管升压药给药和控制策略。

Result: 在eICU和MIMIC数据集上的实证结果表明，所设计的动作空间能够提高模型的可解释性，促进临床应用，同时保持疗效。与传统的给药策略相比，该方法在生存率改善概率方面提高了15%以上，并且与现有的临床协议保持一致。

Conclusion: 动作空间的设计对学习到的行为策略有显著影响，所提出的方法在改善患者预后方面表现出色，同时符合临床实践指南，有望提高RL在CDSS中的临床接受度和应用效果。

Abstract: Reinforcement learning (RL) applications in Clinical Decision Support Systems
(CDSS) frequently encounter skepticism from practitioners regarding inoperable
dosing decisions. We address this challenge with an end-to-end approach for
learning optimal drug dosing and control policies for dual vasopressor
administration in intensive care unit (ICU) patients with septic shock. For
realistic drug dosing, we apply action space design that accommodates discrete,
continuous, and directional dosing strategies in a system that combines offline
conservative Q-learning with a novel recurrent modeling in a replay buffer to
capture temporal dependencies in ICU time-series data. Our comparative analysis
of norepinephrine dosing strategies across different action space formulations
reveals that the designed action spaces improve interpretability and facilitate
clinical adoption while preserving efficacy. Empirical results1 on eICU and
MIMIC demonstrate that action space design profoundly influences learned
behavioral policies. The proposed methods achieve improved patient outcomes of
over 15% in survival improvement probability, while aligning with established
clinical protocols.

</details>


### [456] [Flock: A Knowledge Graph Foundation Model via Learning on Random Walks](https://arxiv.org/abs/2510.01510)
*Jinwoo Kim,Xingyue Huang,Krzysztof Olejniczak,Kyungbin Min,Michael Bronstein,Seunghoon Hong,İsmail İlkan Ceylan*

Main category: cs.LG

TL;DR: KGFMs在零样本链接预测任务中存在局限性，因为确定性等方差限制了它们的表达能力。本文提出了概率性节点-关系等方差，并通过名为Flock的模型来解决这个问题，该模型通过采样随机游走、编码、嵌入和聚合来提高性能。


<details>
  <summary>Details</summary>
Motivation: 传统的知识图谱基础模型（KGFM）在零样本链接预测任务中存在局限性，因为它们固有的确定性等方差限制了区分结构相似但语义不同的关系的能力。

Method: 提出了一种名为Flock的模型，该模型通过迭代采样随机游走，使用记录协议将其编码为序列，然后用序列模型嵌入，并通过学习到的池化聚合节点和关系的表示。Flock尊重概率性节点-关系等方差，并且是同构不变链接级函数在知识图上的通用近似器。

Result: Flock模型在新的诊断数据集Petals上完美解决了现有KGFM模型无法解决的问题，并在54个不同领域的知识图谱的实体和关系预测任务上取得了最先进的性能。

Conclusion: 概率性节点-关系等方差克服了传统KGFM的局限性，提高了零样本链接预测的性能。Flock模型通过其新颖的方法在各种基准测试中表现出色。

Abstract: We study the problem of zero-shot link prediction on knowledge graphs (KGs),
which requires models to generalize over novel entities and novel relations.
Knowledge graph foundation models (KGFMs) address this task by enforcing
equivariance over both nodes and relations, learning from structural properties
of nodes and relations, which are then transferable to novel graphs with
similar structural properties. However, the conventional notion of
deterministic equivariance imposes inherent limits on the expressive power of
KGFMs, preventing them from distinguishing structurally similar but
semantically distinct relations. To overcome this limitation, we introduce
probabilistic node-relation equivariance, which preserves equivariance in
distribution while incorporating a principled randomization to break symmetries
during inference. Building on this principle, we present Flock, a KGFM that
iteratively samples random walks, encodes them into sequences via a recording
protocol, embeds them with a sequence model, and aggregates representations of
nodes and relations via learned pooling. Crucially, Flock respects
probabilistic node-relation equivariance and is a universal approximator for
isomorphism-invariant link-level functions over KGs. Empirically, Flock
perfectly solves our new diagnostic dataset Petals where current KGFMs fail,
and achieves state-of-the-art performances on entity- and relation prediction
tasks on 54 KGs from diverse domains.

</details>


### [457] [Predictive Modeling and Explainable AI for Veterinary Safety Profiles, Residue Assessment, and Health Outcomes Using Real-World Data and Physicochemical Properties](https://arxiv.org/abs/2510.01520)
*Hossein Sholehrasa,Xuan Xu,Doina Caragea,Jim E. Riviere,Majid Jaberi-Douraki*

Main category: cs.LG

TL;DR: 该研究使用近128万份美国FDA兽药中心报告，构建了一个预测框架，用于区分兽药使用中的死亡与康复结果。通过数据预处理、特征工程和多种机器学习模型（包括随机森林、XGBoost、ExcelFormer、大型语言模型和CatBoost）的评估，并结合集成方法和伪标签技术，最终实现了95%的精确率、召回率和F1分数。SHAP解释性分析揭示了与死亡结果密切相关的生物学预测因子，如肺、心脏和支气管疾病、动物个体信息以及药物理化性质。该框架能够准确、可解释地预测兽药安全结果，为早期识别高风险药物-事件组合、加强残留风险评估以及支持监管和临床决策提供支持。


<details>
  <summary>Details</summary>
Motivation: 为了保障动物福利和人类食品安全，需要安全地使用兽药。不良事件（AEs）可能预示着意想不到的药代动力学或毒代动力学效应，从而增加食品链中违规残留的风险。因此，研究的动机是开发一个预测框架，以识别可能导致严重后果（如死亡）的兽药使用情况。

Method: 该研究整合了来自美国FDA开放式FDA（OpenFDA）兽药中心约128万份报告（1987-2025年第一季度）的数据。首先，通过一个预处理流程合并关系表，并利用VeDDRA本体标准化不良事件。接着，对数据进行归一化，填补缺失值，并减少高基数特征。此外，还整合了药物的理化性质以捕捉化学-残留物联系。随后，评估了包括随机森林、CatBoost、XGBoost、ExcelFormer以及Gemma 3-27B和Phi 3-12B等大型语言模型在内的监督学习模型。为解决类别不平衡问题，采用了欠采样和过采样等技术，并优先考虑对致命后果的召回率。研究还采用了平均不确定性边际（AUM）的伪标签技术来改进不确定案例的少数类检测。最后，利用SHAP（SHapley Additive exPlanations）进行模型可解释性分析。

Result: 研究结果显示，集成方法（投票、堆叠）和CatBoost模型表现最佳，在精确率、召回率和F1分数上均达到了0.95。通过AUM伪标签技术，改进了ExcelFormer和XGBoost模型对少数类别的检测能力。SHAP分析确定了肺部、心脏和支气管疾病、动物人口统计学特征以及药物理化性质等生物学上合理的预测因子，这些因子与致命后果密切相关。

Conclusion: 该研究成功开发了一个结合了严格数据工程、先进机器学习和可解释人工智能的预测框架，能够准确且可解释地预测兽药安全结果（死亡与康复）。该框架通过能够及早发现高风险的药物-事件组合，加强了残留风险评估，并为监管和临床决策提供了支持，从而有效地支持了FARAD（兽药管理局？）的使命。

Abstract: The safe use of pharmaceuticals in food-producing animals is vital to protect
animal welfare and human food safety. Adverse events (AEs) may signal
unexpected pharmacokinetic or toxicokinetic effects, increasing the risk of
violative residues in the food chain. This study introduces a predictive
framework for classifying outcomes (Death vs. Recovery) using ~1.28 million
reports (1987-2025 Q1) from the U.S. FDA's OpenFDA Center for Veterinary
Medicine. A preprocessing pipeline merged relational tables and standardized
AEs through VeDDRA ontologies. Data were normalized, missing values imputed,
and high-cardinality features reduced; physicochemical drug properties were
integrated to capture chemical-residue links. We evaluated supervised models,
including Random Forest, CatBoost, XGBoost, ExcelFormer, and large language
models (Gemma 3-27B, Phi 3-12B). Class imbalance was addressed, such as
undersampling and oversampling, with a focus on prioritizing recall for fatal
outcomes. Ensemble methods(Voting, Stacking) and CatBoost performed best,
achieving precision, recall, and F1-scores of 0.95. Incorporating Average
Uncertainty Margin (AUM)-based pseudo-labeling of uncertain cases improved
minority-class detection, particularly in ExcelFormer and XGBoost.
Interpretability via SHAP identified biologically plausible predictors,
including lung, heart, and bronchial disorders, animal demographics, and drug
physicochemical properties. These features were strongly linked to fatal
outcomes. Overall, the framework shows that combining rigorous data
engineering, advanced machine learning, and explainable AI enables accurate,
interpretable predictions of veterinary safety outcomes. The approach supports
FARAD's mission by enabling early detection of high-risk drug-event profiles,
strengthening residue risk assessment, and informing regulatory and clinical
decision-making.

</details>


### [458] [CarbonX: An Open-Source Tool for Computational Decarbonization Using Time Series Foundation Models](https://arxiv.org/abs/2510.01521)
*Diptyaroop Maji,Kang Yang,Prashant Shenoy,Ramesh K Sitaraman,Mani Srivastava*

Main category: cs.LG

TL;DR: CarbonX是一个利用时间序列基础模型（TSFMs）的开源工具，用于计算脱碳任务，如碳排放强度预测和插补。它克服了现有工具的局限性，能够在缺乏特定电网数据的情况下，在214个电网中提供准确且具有不确定性估计的全球预测，零样本预测平均绝对百分比误差（MAPE）为15.82%。


<details>
  <summary>Details</summary>
Motivation: 现有的计算脱碳工具需要电网特定的电力构成数据，难以实现全球覆盖，并且不提供不确定性估计，这限制了它们在下游碳感知应用中的可靠性。

Method: 提出CarbonX，一个利用时间序列基础模型（TSFMs）的开源工具，能够进行碳排放强度预测和插补等任务，具有跨不同电网的适应性。

Result: CarbonX在214个电网上的零样本预测MAPE为15.82%，在13个基准电网上平均MAPE为9.59%，尾部预测MAPE为16.54%，并提供具有95%覆盖率的预测区间。经过微调后，在插补任务上比统计基线模型提高1.2-3.9倍，且在长达21天的预测中精度下降很小。

Conclusion: CarbonX是一个实用且易于使用的工具，能够为数据有限的任何电网提供强大的性能，支持全球范围的脱碳工作。

Abstract: Computational decarbonization aims to reduce carbon emissions in computing
and societal systems such as data centers, transportation, and built
environments. This requires accurate, fine-grained carbon intensity forecasts,
yet existing tools have several key limitations: (i) they require grid-specific
electricity mix data, restricting use where such information is unavailable;
(ii) they depend on separate grid-specific models that make it challenging to
provide global coverage; and (iii) they provide forecasts without uncertainty
estimates, limiting reliability for downstream carbon-aware applications.
  In this paper, we present CarbonX, an open-source tool that leverages Time
Series Foundation Models (TSFMs) for a range of decarbonization tasks. CarbonX
utilizes the versatility of TSFMs to provide strong performance across multiple
tasks, such as carbon intensity forecasting and imputation, and across diverse
grids. Using only historical carbon intensity data and a single general model,
our tool achieves a zero-shot forecasting Mean Absolute Percentage Error (MAPE)
of 15.82% across 214 grids worldwide. Across 13 benchmark grids, CarbonX
performance is comparable with the current state-of-the-art, with an average
MAPE of 9.59% and tail forecasting MAPE of 16.54%, while also providing
prediction intervals with 95% coverage. CarbonX can provide forecasts for up to
21 days with minimal accuracy degradation. Further, when fully fine-tuned,
CarbonX outperforms the statistical baselines by 1.2--3.9X on the imputation
task. Overall, these results demonstrate that CarbonX can be used easily on any
grid with limited data and still deliver strong performance, making it a
practical tool for global-scale decarbonization.

</details>


### [459] [Predictive Preference Learning from Human Interventions](https://arxiv.org/abs/2510.01545)
*Haoyuan Cai,Zhenghao Peng,Bolei Zhou*

Main category: cs.LG

TL;DR: 本研究提出了一种名为预测偏好学习（PPL）的新型交互式模仿学习方法，通过利用人类干预中的隐式偏好信号来预测和纠正代理在未来状态下的潜在危险行为，提高了学习效率并减少了所需的人类演示数量。


<details>
  <summary>Details</summary>
Motivation: 现有的交互式模仿学习方法主要关注纠正代理当前状态下的错误，而忽略了对其未来状态下可能发生的危险行为进行调整。这种局限性可能导致潜在的风险。本研究旨在解决这一问题。

Method: PPL方法将每次人类干预引导的轨迹延伸到未来的L个时间步（称为偏好视界），假设在此期间代理将遵循相同的动作，人类也将做出相同的干预。通过对这些未来状态应用偏好优化，将专家的修正传播到代理预期探索的安全关键区域。

Result: 在自动驾驶和机器人操控基准测试中的实验表明，PPL方法能够显著提高学习效率，减少所需的人类演示数量，并具有良好的通用性。理论分析表明，选择合适的偏好视界L可以在风险状态覆盖范围和标签正确性之间取得平衡，从而限制算法的最优性差距。

Conclusion: PPL通过将人类干预的修正效果推广到未来的时间步，有效解决了现有交互式模仿学习方法在处理未来潜在危险行为方面的不足，并在实验和理论上证明了其有效性和优势。

Abstract: Learning from human involvement aims to incorporate the human subject to
monitor and correct agent behavior errors. Although most interactive imitation
learning methods focus on correcting the agent's action at the current state,
they do not adjust its actions in future states, which may be potentially more
hazardous. To address this, we introduce Predictive Preference Learning from
Human Interventions (PPL), which leverages the implicit preference signals
contained in human interventions to inform predictions of future rollouts. The
key idea of PPL is to bootstrap each human intervention into L future time
steps, called the preference horizon, with the assumption that the agent
follows the same action and the human makes the same intervention in the
preference horizon. By applying preference optimization on these future states,
expert corrections are propagated into the safety-critical regions where the
agent is expected to explore, significantly improving learning efficiency and
reducing human demonstrations needed. We evaluate our approach with experiments
on both autonomous driving and robotic manipulation benchmarks and demonstrate
its efficiency and generality. Our theoretical analysis further shows that
selecting an appropriate preference horizon L balances coverage of risky states
with label correctness, thereby bounding the algorithmic optimality gap. Demo
and code are available at: https://metadriverse.github.io/ppl

</details>


### [460] [On Integer Programming for the Binarized Neural Network Verification Problem](https://arxiv.org/abs/2510.01525)
*Woojin Kim,James R. Luedtke*

Main category: cs.LG

TL;DR: Binarized neural networks (BNNs) can be verified using integer programming (IP), but traditional IP formulations suffer from a large integrality gap. This paper introduces a new linear objective for multi-class classification and valid inequalities based on the recursive structure of BNNs to improve the IP formulation, enabling verification against higher ranges of input perturbations.


<details>
  <summary>Details</summary>
Motivation: The verification of Binarized Neural Networks (BNNs) is crucial for understanding their robustness against input perturbations. Existing Integer Programming (IP) formulations for BNN verification face challenges due to large integrality gaps.

Method: The paper proposes two techniques to enhance the IP formulation for BNN verification: 1) A new method for deriving a linear objective function suitable for multi-class classification. 2) A novel technique for generating valid inequalities that leverage the recursive structure inherent in BNNs.

Result: The proposed techniques improve the IP formulation for BNN verification. This leads to the ability to verify BNNs against a wider range of input perturbations compared to existing IP approaches, all within a constrained time frame.

Conclusion: The introduced techniques for improving the IP formulation, including a new linear objective for multi-class settings and valid inequalities exploiting the BNN's recursive structure, significantly enhance the efficiency and capability of verifying BNNs against input perturbations.

Abstract: Binarized neural networks (BNNs) are feedforward neural networks with binary
weights and activation functions. In the context of using a BNN for
classification, the verification problem seeks to determine whether a small
perturbation of a given input can lead it to be misclassified by the BNN, and
the robustness of the BNN can be measured by solving the verification problem
over multiple inputs. The BNN verification problem can be formulated as an
integer programming (IP) problem. However, the natural IP formulation is often
challenging to solve due to a large integrality gap induced by big-$M$
constraints. We present two techniques to improve the IP formulation. First, we
introduce a new method for obtaining a linear objective for the multi-class
setting. Second, we introduce a new technique for generating valid inequalities
for the IP formulation that exploits the recursive structure of BNNs. We find
that our techniques enable verifying BNNs against a higher range of input
perturbation than existing IP approaches within a limited time.

</details>


### [461] [Round-trip Reinforcement Learning: Self-Consistent Training for Better Chemical LLMs](https://arxiv.org/abs/2510.01527)
*Lecheng Kong,Xiyuan Wang,Yixin Chen,Muhan Zhang*

Main category: cs.LG

TL;DR: LLMs在计算化学中存在回合一致性问题， RTRL框架通过将回合转换的成功作为奖励信号来提高模型的一致性，从而提升模型性能。


<details>
  <summary>Details</summary>
Motivation: LLMs在计算化学中存在回合一致性问题，这表明模型可能只学会了单向记忆而不是灵活掌握。提高回合一致性可以提升模型在主要任务上的表现。

Method: 提出回合-逆向强化学习（RTRL）框架，使用回合转换的成功作为奖励信号来训练模型以提高其一致性。还提出了一个迭代变体，其中正向和反向映射在自我改进循环中交替训练彼此。

Result: RTRL在监督、自监督和合成数据模式下显著提高了模型性能和一致性，优于强基线。

Conclusion: 回合一致性不仅是一个理想的属性，而且是一个可训练的目标，为构建更健壮、更可靠的基础模型提供了一条新途径。

Abstract: Large Language Models (LLMs) are emerging as versatile foundation models for
computational chemistry, handling bidirectional tasks like reaction prediction
and retrosynthesis. However, these models often lack round-trip consistency.
For instance, a state-of-the-art chemical LLM may successfully caption a
molecule, yet be unable to accurately reconstruct the original structure from
its own generated text. This inconsistency suggests that models are learning
unidirectional memorization rather than flexible mastery. Indeed, recent work
has demonstrated a strong correlation between a model's round-trip consistency
and its performance on the primary tasks. This strong correlation reframes
consistency into a direct target for model improvement. We therefore introduce
Round-Trip Reinforcement Learning (RTRL), a novel framework that trains a model
to improve its consistency by using the success of a round-trip transformation
as a reward signal. We further propose an iterative variant where forward and
reverse mappings alternately train each other in a self-improvement loop, a
process that is highly data-efficient and notably effective with the massive
amount of unlabelled data common in chemistry. Experiments demonstrate that
RTRL significantly \textbf{boosts performance and consistency} over strong
baselines across supervised, self-supervised, and synthetic data regimes. This
work shows that round-trip consistency is not just a desirable property but a
trainable objective, offering a new path toward more robust and reliable
foundation models.

</details>


### [462] [Bypassing Prompt Guards in Production with Controlled-Release Prompting](https://arxiv.org/abs/2510.01529)
*Jaiden Fairoze,Sanjam Garg,Keewoo Lee,Mingyuan Wang*

Main category: cs.LG

TL;DR: LLM的提示词防护机制存在漏洞，新的攻击方法可以绕过它们，揭示了其局限性。


<details>
  <summary>Details</summary>
Motivation: 提示词防护机制是确保大型语言模型(LLM)安全和对齐的常用方法，但其有效性需要被评估和改进。

Method: 提出了一种利用资源不对称性来编码绕过提示词防护的攻击方法，该方法可以被主模型解码，但被轻量级防护机制忽略。

Result: 该方法成功绕过了Google Gemini、DeepSeek Chat、Grok和Mistral Le Chat等生产模型上的提示词防护，同时保持了响应质量。此外，还发现了版权数据提取、训练数据提取和恶意响应泄露等其他对齐问题。

Conclusion: 现有的轻量级提示词防护机制存在固有的攻击面，防御策略应从阻止恶意输入转向防止恶意输出。

Abstract: As large language models (LLMs) advance, ensuring AI safety and alignment is
paramount. One popular approach is prompt guards, lightweight mechanisms
designed to filter malicious queries while being easy to implement and update.
In this work, we introduce a new attack that circumvents such prompt guards,
highlighting their limitations. Our method consistently jailbreaks production
models while maintaining response quality, even under the highly protected chat
interfaces of Google Gemini (2.5 Flash/Pro), DeepSeek Chat (DeepThink), Grok
(3), and Mistral Le Chat (Magistral). The attack exploits a resource asymmetry
between the prompt guard and the main LLM, encoding a jailbreak prompt that
lightweight guards cannot decode but the main model can. This reveals an attack
surface inherent to lightweight prompt guards in modern LLM architectures and
underscores the need to shift defenses from blocking malicious inputs to
preventing malicious outputs. We additionally identify other critical alignment
issues, such as copyrighted data extraction, training data extraction, and
malicious response leakage during thinking.

</details>


### [463] [NVIDIA AI Aerial: AI-Native Wireless Communications](https://arxiv.org/abs/2510.01533)
*Kobi Cohen-Arazi,Michael Roe,Zhen Hu,Rohan Chavan,Anna Ptasznik,Joanna Lin,Joao Morais,Joseph Boccuzzi,Tommaso Balercia*

Main category: cs.LG

TL;DR: 6G网络架构将AI/ML无缝集成到无线通信系统中，提出的框架可将Python算法编译为GPU可执行文件，以提高效率和性能，并成功应用于信道估计。


<details>
  <summary>Details</summary>
Motivation: 6G将AI/ML无缝集成到无线通信系统软件栈中，促进了AI模型和算法的迭代训练、模拟和部署。

Method: 提出一个健壮的框架，将Python算法编译为GPU可执行文件，并在NVIDIA AI Aerial平台上实现。

Result: 该框架实现了效率、灵活性和高性能，并通过在PUSCH接收器中使用CNN进行信道估计进行了验证，该CNN在数字孪生和实时测试台中均表现出有效性。

Conclusion: 所提出的框架为将AI/ML模型可扩展地集成到下一代蜂窝系统中奠定了基础，对于实现原生智能6G网络至关重要。

Abstract: 6G brings a paradigm shift towards AI-native wireless systems, necessitating
the seamless integration of digital signal processing (DSP) and machine
learning (ML) within the software stacks of cellular networks. This
transformation brings the life cycle of modern networks closer to AI systems,
where models and algorithms are iteratively trained, simulated, and deployed
across adjacent environments. In this work, we propose a robust framework that
compiles Python-based algorithms into GPU-runnable blobs. The result is a
unified approach that ensures efficiency, flexibility, and the highest possible
performance on NVIDIA GPUs. As an example of the capabilities of the framework,
we demonstrate the efficacy of performing the channel estimation function in
the PUSCH receiver through a convolutional neural network (CNN) trained in
Python. This is done in a digital twin first, and subsequently in a real-time
testbed. Our proposed methodology, realized in the NVIDIA AI Aerial platform,
lays the foundation for scalable integration of AI/ML models into
next-generation cellular systems, and is essential for realizing the vision of
natively intelligent 6G networks.

</details>


### [464] [TimeSeriesScientist: A General-Purpose AI Agent for Time Series Analysis](https://arxiv.org/abs/2510.01538)
*Haokun Zhao,Xiang Zhang,Jiaqi Wei,Yiwei Xu,Yuting He,Siqi Sun,Chenyu You*

Main category: cs.LG

TL;DR: TSci是一个首创的LLM驱动的代理框架，用于一般时间序列预测，它通过自动化数据预处理、模型选择和预测来减少人工干预，并在八个基准测试中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 鉴于当前时间序列预测中普遍存在的人工劳动密集型预处理、验证和集成成本，以及现有模型泛化能力差的问题，迫切需要一个能最大限度减少人工干预的、领域无关的通用框架。

Method: TSci框架包含四个专用代理：Curator（执行LLM指导的诊断和数据统计分析以进行预处理）、Planner（利用多模态诊断和自我规划来缩小模型选择范围）、Forecaster（进行模型拟合、验证，并自适应地选择最佳模型和集成策略）和Reporter（生成透明的自然语言报告，总结整个过程）。

Result: 在八个已建立的基准测试中，TSci的预测误差比统计模型平均降低了10.4%，比基于LLM的模型平均降低了38.2%，并且生成了清晰、严谨的报告，提高了预测工作流的透明度和可解释性。

Conclusion: TSci是一个创新的、领域无关的LLM驱动的时间序列预测框架，通过自动化和增强的代理，显著提高了预测的准确性和效率，同时增强了工作流程的透明度和可解释性。

Abstract: Time series forecasting is central to decision-making in domains as diverse
as energy, finance, climate, and public health. In practice, forecasters face
thousands of short, noisy series that vary in frequency, quality, and horizon,
where the dominant cost lies not in model fitting, but in the labor-intensive
preprocessing, validation, and ensembling required to obtain reliable
predictions. Prevailing statistical and deep learning models are tailored to
specific datasets or domains and generalize poorly. A general, domain-agnostic
framework that minimizes human intervention is urgently in demand. In this
paper, we introduce TimeSeriesScientist (TSci), the first LLM-driven agentic
framework for general time series forecasting. The framework comprises four
specialized agents: Curator performs LLM-guided diagnostics augmented by
external tools that reason over data statistics to choose targeted
preprocessing; Planner narrows the hypothesis space of model choice by
leveraging multi-modal diagnostics and self-planning over the input; Forecaster
performs model fitting and validation and, based on the results, adaptively
selects the best model configuration as well as ensemble strategy to make final
predictions; and Reporter synthesizes the whole process into a comprehensive,
transparent report. With transparent natural-language rationales and
comprehensive reports, TSci transforms the forecasting workflow into a
white-box system that is both interpretable and extensible across tasks.
Empirical results on eight established benchmarks demonstrate that TSci
consistently outperforms both statistical and LLM-based baselines, reducing
forecast error by an average of 10.4% and 38.2%, respectively. Moreover, TSci
produces a clear and rigorous report that makes the forecasting workflow more
transparent and interpretable.

</details>


### [465] [Executable Counterfactuals: Improving LLMs' Causal Reasoning Through Code](https://arxiv.org/abs/2510.01539)
*Aniket Vashishtha,Qirun Dai,Hongyuan Mei,Amit Sharma,Chenhao Tan,Hao Peng*

Main category: cs.LG

TL;DR: 本论文提出了一个名为“可执行反事实”的新框架，用于评估和改进大型语言模型（LLM）的反事实推理能力。该框架通过代码和数学问题来操作化因果推理，并明确要求了反事实推理的三个步骤：推断（abduction）、干预（intervention）和预测（prediction）。研究发现，现有模型在反事实推理方面存在显著的准确率下降，但通过强化学习进行微调可以提高模型在代码和数学问题上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有评估大型语言模型（LLM）反事实推理能力的方法往往忽略了推理过程的“推断”环节，导致对模型能力的估计过高。这阻碍了LLM在科学研究等高风险领域的应用。因此，需要一个能够全面评估反事实推理所有步骤（推断、干预、预测）的新框架。

Method: 提出“可执行反事实”框架，通过代码和数学问题来操作化因果推理，并强制要求模型完成反事实推理的三个步骤。利用该框架生成不同难度的数据集，用于评估和训练模型。实验比较了不同训练方法（监督微调和强化学习）对模型在代码和数学反事实推理任务上的表现影响。

Result: 在现有模型（如o4-mini和Claude-4-Sonnet）上，从仅包含干预推理到包含完整反事实推理（包括推断）的评估，准确率下降了25%-40%。对Qwen模型的实验表明，监督微调在特定领域（如代码）可以提高性能，但对跨领域任务（如反事实数学问题）表现不佳。而强化学习方法能够诱导核心认知行为，并在代码（提高1.5倍-2倍）和数学问题上均优于基础模型。

Conclusion: 强化学习为提高大型语言模型（LLM）的反事实推理能力提供了一条有前景的途径，它能够使模型泛化到新的领域，并显著提高在代码和数学问题上的表现，解决了监督微调在跨领域任务上的局限性。

Abstract: Counterfactual reasoning, a hallmark of intelligence, consists of three
steps: inferring latent variables from observations (abduction), constructing
alternatives (interventions), and predicting their outcomes (prediction). This
skill is essential for advancing LLMs' causal understanding and expanding their
applications in high-stakes domains such as scientific research. However,
existing efforts in assessing LLM's counterfactual reasoning capabilities tend
to skip the abduction step, effectively reducing to interventional reasoning
and leading to overestimation of LLM performance. To address this, we introduce
executable counterfactuals, a novel framework that operationalizes causal
reasoning through code and math problems. Our framework explicitly requires all
three steps of counterfactual reasoning and enables scalable synthetic data
creation with varying difficulty, creating a frontier for evaluating and
improving LLM's reasoning. Our results reveal substantial drop in accuracy
(25-40%) from interventional to counterfactual reasoning for SOTA models like
o4-mini and Claude-4-Sonnet. To address this gap, we construct a training set
comprising counterfactual code problems having if-else condition and test on
out-of-domain code structures (e.g. having while-loop); we also test whether a
model trained on code would generalize to counterfactual math word problems.
While supervised finetuning on stronger models' reasoning traces improves
in-domain performance of Qwen models, it leads to a decrease in accuracy on OOD
tasks such as counterfactual math problems. In contrast, reinforcement learning
induces the core cognitive behaviors and generalizes to new domains, yielding
gains over the base model on both code (improvement of 1.5x-2x) and math
problems. Analysis of the reasoning traces reinforces these findings and
highlights the promise of RL for improving LLMs' counterfactual reasoning.

</details>


### [466] [MIRA: Towards Mitigating Reward Hacking in Inference-Time Alignment of T2I Diffusion Models](https://arxiv.org/abs/2510.01549)
*Kevin Zhai,Utsav Singh,Anirudh Thatipelli,Souradip Chakraborty,Anit Kumar Sahu,Furong Huang,Amrit Singh Bedi,Mubarak Shah*

Main category: cs.LG

TL;DR: MIRA是一种无需训练、在推理时即可对齐的方法，可以解决基于奖励的图像生成中的奖励破解问题，同时保持与提示的符合度。


<details>
  <summary>Details</summary>
Motivation: 现有的基于奖励的图像生成方法通常需要计算成本高昂的微调，或者在推理时采用不完善的噪声优化方法，导致奖励破解（生成的图像得分高但与提示不符）。

Method: MIRA提出了一种在图像空间中基于分数的KL散度替代方法，通过冻结的骨干网络对采样轨迹进行正则化，以在不产生分布外漂移的情况下增加奖励。它还提出MIRA-DPO，将偏好优化映射到推理时间，以处理不可微分的奖励。

Result: 在SDv1.5和SDXL等模型上，MIRA在多个奖励（包括美学评分、HPSv2和PickScore）和数据集上实现了超过60%的胜率，并保持了提示的符合度。与DNO等基线方法相比，MIRA在增加计算量时奖励会增加，而漂移几乎为零。

Conclusion: MIRA是一种有效的、无需训练的、在推理时即可对齐的方法，可以解决奖励破解问题，同时保持与提示的符合度，并可扩展到处理不可微分的奖励。

Abstract: Diffusion models excel at generating images conditioned on text prompts, but
the resulting images often do not satisfy user-specific criteria measured by
scalar rewards such as Aesthetic Scores. This alignment typically requires
fine-tuning, which is computationally demanding. Recently, inference-time
alignment via noise optimization has emerged as an efficient alternative,
modifying initial input noise to steer the diffusion denoising process towards
generating high-reward images. However, this approach suffers from reward
hacking, where the model produces images that score highly, yet deviate
significantly from the original prompt. We show that noise-space regularization
is insufficient and that preventing reward hacking requires an explicit
image-space constraint. To this end, we propose MIRA (MItigating Reward
hAcking), a training-free, inference-time alignment method. MIRA introduces an
image-space, score-based KL surrogate that regularizes the sampling trajectory
with a frozen backbone, constraining the output distribution so reward can
increase without off-distribution drift (reward hacking). We derive a tractable
approximation to KL using diffusion scores. Across SDv1.5 and SDXL, multiple
rewards (Aesthetic, HPSv2, PickScore), and public datasets (e.g.,
Animal-Animal, HPDv2), MIRA achieves >60\% win rate vs. strong baselines while
preserving prompt adherence; mechanism plots show reward gains with near-zero
drift, whereas DNO drifts as compute increases. We further introduce MIRA-DPO,
mapping preference optimization to inference time with a frozen backbone,
extending MIRA to non-differentiable rewards without fine-tuning.

</details>


### [467] [Rethinking KL Regularization in RLHF: From Value Estimation to Gradient Optimization](https://arxiv.org/abs/2510.01555)
*Kezhao Liu,Jason Klein Liu,Mingtao Chen,Yiming Liu*

Main category: cs.LG

TL;DR: RLHF 中的 KL 散度损失有两种实现方式：'k_n' 作为奖励的系数或作为损失函数。本文提出了一个统一的框架来分析这两种方式，并证明了 'k_1' 作为奖励和 'k_2' 作为损失在单策略条件下是梯度等价的，都是反向 KL (RKL) 正则化的合理损失。然而，'k_3' 作为损失是 RKL 损失的一阶有偏近似。此外，本文还指出了离策略实现中的偏差，并提出了修正方法。


<details>
  <summary>Details</summary>
Motivation: RLHF 中 KL 散度损失的两种实现方式（'k_n' 作为奖励的系数或作为损失函数）的原理和效果存在混淆，特别是 GRPO 中 'k_3' 作为损失的实现方式被证明是一种有偏近似，而 'k_1' 作为奖励和 'k_2' 作为损失在单策略条件下是等价的，都是 RKL 正则化的合理损失。本文旨在解决这些问题，提供一个统一的框架来分析和指导 KL 正则化的选择和实现。

Method: 本文提出了一个统一的框架，将 KL 散度损失的两种实现方式（'$k_n$' 作为奖励的系数或作为损失函数）联系起来。通过这个框架，证明了 '$k_1$' 作为奖励（如 PPO）是反向 KL (RKL) 正则化的合理损失。并且在单策略条件下，'$k_2$' 作为损失（如 GRPO）与 '$k_1$' 作为奖励是梯度等价的。此外，本文还分析了 '$k_3$' 作为损失的局限性，指出了离策略实现中的偏差，并提出了修正方法。

Result: 本文证明了 '$k_1$' 作为奖励和 '$k_2$' 作为损失在单策略条件下是梯度等价的，它们都是 RKL 正则化的理论上合理的实现。而 '$k_3$' 作为损失是 RKL 损失的一阶有偏近似。此外，本文还指出了常见的离策略实现中由于忽略了重要性采样而产生的偏差，并提出了相应的修正方法。

Conclusion: 本文提出了一个统一的框架来分析 RLHF 中 KL 散度损失的实现方式，证明了 '$k_1$' 作为奖励和 '$k_2$' 作为损失（在单策略条件下）是 RKL 正则化的合理选择，而 '$k_3$' 作为损失则是一种有偏近似。通过提供基于梯度的理论依据，本文为更鲁棒、更有效的 KL 正则化选择和实现铺平了道路，最终旨在改进 RLHF 系统。

Abstract: Reinforcement Learning from Human Feedback (RLHF) leverages a
Kullback-Leibler (KL) divergence loss to stabilize training and prevent
overfitting. However, in methods such as GRPO, its implementation may be guided
by principles from numerical value estimation-a practice that overlooks the
term's functional role as an optimization loss. To analyze this issue, we
establish a unified framework that connects two seemingly distinct
implementation styles: using the mathematical term $k_n$ as a detached
coefficient for the policy's score function ('$k_n$ in reward') or as a direct
loss function through which gradients are propagated ('$k_n$ as loss'). We show
that the latter can always be analyzed via an equivalent gradient coefficient
in the former, unifying the two perspectives. Through this framework, we prove
that the conventional '$k_1$ in reward' (like in PPO) is the principled loss
for Reverse KL (RKL) regularization. We further establish a key finding: under
on-policy conditions, the '$k_2$ as loss' formulation is, in fact,
gradient-equivalent to '$k_1$ in reward'. This equivalence, first proven in our
work, identifies both as the theoretically sound implementations of the RKL
objective. In contrast, we show that the recently adopted '$k_3$ as loss' (like
in GRPO) is merely a first-order, biased approximation of the principled loss.
Furthermore, we argue that common off-policy implementations of '$k_n$ as loss'
methods are biased due to neglected importance sampling, and we propose a
principled correction. Our findings provide a comprehensive, gradient-based
rationale for choosing and correctly implementing KL regularization, paving the
way for more robust and effective RLHF systems.

</details>


### [468] [Large-Scale Bayesian Causal Discovery with Interventional Data](https://arxiv.org/abs/2510.01562)
*Seong Woo Han,Daniel Duy Vo,Brielin C. Brown*

Main category: cs.LG

TL;DR: IBCD是一个利用干预数据进行因果发现的经验贝叶斯框架，通过对总因果效应矩阵进行建模并使用马刺-板草鞋先验，实现了准确的因果图结构恢复和不确定性量化。


<details>
  <summary>Details</summary>
Motivation: 现有的因果发现方法在处理大规模问题时性能不佳且无法量化不确定性，特别是在利用基因扰动筛选等干预性数据方面存在局限。

Method: IBCD提出了一种对总因果效应矩阵进行建模的经验贝叶斯框架，将该矩阵近似为矩阵正态分布。该方法在图的边上使用了马刺-板草鞋先验，并从观测数据中学习独立的数据驱动权重，将每条边视为潜在变量以实现不确定性感知推理。

Result: 通过广泛的模拟研究，IBCD在结构恢复方面优于现有基线方法。在CRISPR扰动（Perturb-seq）数据集上的应用表明，边后验包含概率能够识别出稳健的图结构。

Conclusion: IBCD通过对总因果效应矩阵进行建模并结合先进的贝叶斯先验和学习机制，能够有效地利用干预性数据进行因果发现，并在大规模问题上实现准确的结构恢复和不确定性量化。

Abstract: Inferring the causal relationships among a set of variables in the form of a
directed acyclic graph (DAG) is an important but notoriously challenging
problem. Recently, advancements in high-throughput genomic perturbation screens
have inspired development of methods that leverage interventional data to
improve model identification. However, existing methods still suffer poor
performance on large-scale tasks and fail to quantify uncertainty. Here, we
propose Interventional Bayesian Causal Discovery (IBCD), an empirical Bayesian
framework for causal discovery with interventional data. Our approach models
the likelihood of the matrix of total causal effects, which can be approximated
by a matrix normal distribution, rather than the full data matrix. We place a
spike-and-slab horseshoe prior on the edges and separately learn data-driven
weights for scale-free and Erd\H{o}s-R\'enyi structures from observational
data, treating each edge as a latent variable to enable uncertainty-aware
inference. Through extensive simulation, we show that IBCD achieves superior
structure recovery compared to existing baselines. We apply IBCD to CRISPR
perturbation (Perturb-seq) data on 521 genes, demonstrating that edge posterior
inclusion probabilities enable identification of robust graph structures.

</details>


### [469] [From Supervision to Exploration: What Does Protein Language Model Learn During Reinforcement Learning?](https://arxiv.org/abs/2510.01571)
*Hanqun Cao,Hongrui Zhang,Junde Xu,Zhou Zhang,Lingdong Shen,Minghao Sun,Ge Liu,Jinbo Xu,Wu-Jun Li,Jinren Ni,Cesar de la Fuente-Nunez,Tianfan Fu,Yejin Choi,Pheng-Ann Heng,Fang Wu*

Main category: cs.LG

TL;DR: RL结合PLMs在蛋白质设计中提高了成功率和样本效率，但收益受任务空间、奖励保真度和策略容量的共同影响。


<details>
  <summary>Details</summary>
Motivation: 探索强化学习（RL）是否能推动蛋白质语言模型（PLMs）超越其预训练的先验知识，揭示潜在的序列-结构-功能规则。

Method: 将RL与PLMs结合，应用于抗菌肽设计、激酶变体优化、抗体工程和逆向折叠四个领域，并使用多种RL算法和模型。

Result: 在各项基准测试中，RL稳定地提高了成功率和样本效率。收益取决于任务空间、奖励保真度和策略容量的交互作用。当奖励准确且信息丰富、策略容量充足、任务有超越监督学习基线的空间时，收益会扩大；反之，当奖励有噪声或容量受限时，收益会饱和。

Conclusion: RL在蛋白质设计中的应用需要优先考虑奖励建模和校准，再扩展策略规模；根据任务难度匹配算法和正则化强度；并将容量分配给边际收益最大的地方。

Abstract: Protein language models (PLMs) have advanced computational protein science
through large-scale pretraining and scalable architectures. In parallel,
reinforcement learning (RL) has broadened exploration and enabled precise
multi-objective optimization in protein design. Yet whether RL can push PLMs
beyond their pretraining priors to uncover latent sequence-structure-function
rules remains unclear. We address this by pairing RL with PLMs across four
domains: antimicrobial peptide design, kinase variant optimization, antibody
engineering, and inverse folding. Using diverse RL algorithms and model
classes, we ask if RL improves sampling efficiency and, more importantly, if it
reveals capabilities not captured by supervised learning. Across benchmarks, RL
consistently boosts success rates and sample efficiency. Performance follows a
three-factor interaction: task headroom, reward fidelity, and policy capacity
jointly determine gains. When rewards are accurate and informative, policies
have sufficient capacity, and tasks leave room beyond supervised baselines,
improvements scale; when rewards are noisy or capacity is constrained, gains
saturate despite exploration. This view yields practical guidance for RL in
protein design: prioritize reward modeling and calibration before scaling
policy size, match algorithm and regularization strength to task difficulty,
and allocate capacity where marginal gains are largest. Implementation is
available at https://github.com/chq1155/RL-PLM.

</details>


### [470] [Gradient Shaping Beyond Clipping: A Functional Perspective on Update Magnitude Control](https://arxiv.org/abs/2510.01578)
*Haochen You,Baojing Liu*

Main category: cs.LG

TL;DR: SPAMP是一种自适应梯度整形框架，通过动态调整梯度统计信息来稳定深度网络训练，优于传统的梯度裁剪方法。


<details>
  <summary>Details</summary>
Motivation: 传统的梯度裁剪使用固定的阈值，缺乏灵活性且忽略了梯度分布的动态变化。SPAMP旨在提供一个更灵活、更自适应的解决方案。

Method: SPAMP跟踪局部梯度统计信息，动态估计阈值，并应用基于幂的变换来以可微的方式调整更新幅度，从而实现平滑的、每层自适应的梯度整形。

Result: 在图像和语言任务的广泛实验表明，SPAMP在稳定性、收敛性和鲁棒性方面优于现有方法。

Conclusion: SPAMP将梯度裁剪和预热视为控制有效更新尺度ηt||gt||的对偶机制，为传统的固定阈值方法提供了一种原则性的替代方案。

Abstract: Gradient clipping is widely used to stabilize deep network training, but its
formulation as a hard, fixed threshold limits flexibility and ignores gradient
distribution dynamics. We propose SPAMP (Statistical Per-layer Adaptive
Modulation and Projection), a unified framework that generalizes clipping into
smooth, per-layer gradient shaping. SPAMP tracks local gradient statistics,
dynamically estimates thresholds, and applies power-based transformations to
modulate update magnitudes in a differentiable manner. This perspective recasts
clipping and warmup as dual mechanisms for controlling the effective update
scale $\eta_t \|g_t\|$, offering a principled alternative to rigid heuristics.
Extensive experiments across image and language tasks demonstrate that SPAMP
improves stability, convergence, and robustness over existing methods.

</details>


### [471] [Think Right: Learning to Mitigate Under-Over Thinking via Adaptive, Attentive Compression](https://arxiv.org/abs/2510.01581)
*Joykirat Singh,Justin Chih-Yao Chen,Archiki Prasad,Elias Stengel-Eskin,Akshay Nambi,Mohit Bansal*

Main category: cs.LG

TL;DR: TRAAC是一种新的RL方法，通过自适应地调整推理步骤来解决模型在推理任务中的“思考不足”或“过度思考”问题，从而提高准确性并减少计算量。


<details>
  <summary>Details</summary>
Motivation: 现有的思考模型在解决复杂推理任务时，会通过增加测试时间的计算量来提升性能，但这种计算量的分配需要与任务的难度相匹配。推理过短会导致难问题出错，而推理过长则会造成计算资源浪费。模型未能根据任务难度自适应地调整其响应长度，即“适应性不足”的问题。

Method: TRAAC（Think Right with Adaptive, Attentive Compression）是一种在线的、训练后进行的强化学习方法。它利用模型在长推理轨迹中的自注意力机制来识别重要步骤并剪除冗余步骤。此外，TRAAC还能估计任务难度，并将其纳入训练奖励中，从而学会根据示例的难度来分配推理预算。

Result: TRAAC方法在准确性上有所提高，推理步骤有所减少，并且相比基线模型和其他RL基线，能够实现自适应思考。在多种任务（AIME, AMC, GPQA-D, BBEH）上，TRAAC (Qwen3-4B)相比基线模型，准确率平均绝对提升了8.4%，推理长度相对减少了36.8%。与最优RL基线相比，准确率提升7.9%，长度减少29.4%。TRAAC模型在未见过的非数学数据集（如GPQA-D, BBEH, OptimalThinkingBench）上也表现出强大的泛化能力，实现了准确性和效率的提升。实验验证了TRAAC能够根据难度进行精细的思考预算调整，并且任务难度校准与基于注意力的压缩相结合，能够在各种任务中带来收益。

Conclusion: TRAAC通过结合任务难度校准和基于注意力的压缩，有效地解决了推理中的适应性不足问题，提高了模型在各种推理任务上的准确性和效率，并展现了良好的泛化能力。

Abstract: Recent thinking models solve complex reasoning tasks by scaling test-time
compute, but this scaling must be allocated in line with task difficulty. On
one hand, short reasoning (underthinking) leads to errors on harder problems
that require extended reasoning steps; but, excessively long reasoning
(overthinking) can be token-inefficient, generating unnecessary steps even
after reaching a correct intermediate solution. We refer to this as
under-adaptivity, where the model fails to modulate its response length
appropriately given problems of varying difficulty. To address under-adaptivity
and strike a balance between under- and overthinking, we propose TRAAC (Think
Right with Adaptive, Attentive Compression), an online post-training RL method
that leverages the model's self-attention over a long reasoning trajectory to
identify important steps and prune redundant ones. TRAAC also estimates
difficulty and incorporates it into training rewards, thereby learning to
allocate reasoning budget commensurate with example difficulty. Our approach
improves accuracy, reduces reasoning steps, and enables adaptive thinking
compared to base models and other RL baselines. Across a variety of tasks
(AIME, AMC, GPQA-D, BBEH), TRAAC (Qwen3-4B) achieves an average absolute
accuracy gain of 8.4% with a relative reduction in reasoning length of 36.8%
compared to the base model, and a 7.9% accuracy gain paired with a 29.4% length
drop compared to the best RL baseline. TRAAC also shows strong generalization:
although our models are trained on math datasets, they show accuracy and
efficiency gains on out-of-distribution non-math datasets like GPQA-D, BBEH,
and OptimalThinkingBench. Our analysis further verifies that TRAAC provides
fine-grained adjustments to thinking budget based on difficulty and that a
combination of task-difficulty calibration and attention-based compression
yields gains across diverse tasks.

</details>


### [472] [Enhancing Noise Robustness of Parkinson's Disease Telemonitoring via Contrastive Feature Augmentation](https://arxiv.org/abs/2510.01588)
*Ziming Tang,Chengbin Hou,Tianyu Zhang,Bangxu Tian,Jinbao Wang,Hairong Lv*

Main category: cs.LG

TL;DR: NoRo框架通过对语音特征进行分组和对比学习，生成噪声鲁棒的特征，提升了在有噪声环境下的UPDRS预测准确性，并引入了新的评估方法。


<details>
  <summary>Details</summary>
Motivation: 现有的帕金森病远程监测技术在测量过程中会受到患者自身、环境噪声以及数据传输丢失等多种噪声的干扰，导致预测误差增大。

Method: 提出NoRo框架，首先将原始语音特征分组构建对比学习的配对，然后训练多层感知机编码器生成噪声鲁棒特征，最后将这些特征与原始特征拼接作为增强特征输入UPDRS预测模型。此外，还引入了可自定义噪声注入模块的评估方法。

Result: NoRo框架成功提升了在不同噪声环境下的UPDRS预测性能，并对各种下游预测模型有效。

Conclusion: NoRo框架能够有效增强UPDRS预测在各种噪声环境下的鲁棒性。

Abstract: Parkinson's disease (PD) is one of the most common neurodegenerative
disorder. PD telemonitoring emerges as a novel assessment modality enabling
self-administered at-home tests of Unified Parkinson's Disease Rating Scale
(UPDRS) scores, enhancing accessibility for PD patients. However, three types
of noise would occur during measurements: (1) patient-induced measurement
inaccuracies, (2) environmental noise, and (3) data packet loss during
transmission, resulting in higher prediction errors. To address these
challenges, NoRo, a noise-robust UPDRS prediction framework is proposed. First,
the original speech features are grouped into ordered bins, based on the
continuous values of a selected feature, to construct contrastive pairs.
Second, the contrastive pairs are employed to train a multilayer perceptron
encoder for generating noise-robust features. Finally, these features are
concatenated with the original features as the augmented features, which are
then fed into the UPDRS prediction models. Notably, we further introduces a
novel evaluation approach with customizable noise injection module, and
extensive experiments show that NoRo can successfully enhance the noise
robustness of UPDRS prediction across various downstream prediction models
under different noisy environments.

</details>


### [473] [Posterior Collapse as a Phase Transition in Variational Autoencoders](https://arxiv.org/abs/2510.01621)
*Zhen Li,Fan Zhang,Zheng Zhang,Yu Chen*

Main category: cs.LG

TL;DR: 文章从统计物理学的角度研究了变分自编码器（VAEs）中的后验坍塌现象，发现其表现为一种由数据结构和模型超参数共同决定的相变。


<details>
  <summary>Details</summary>
Motivation: 研究变分自编码器（VAEs）中的后验坍塌现象，并从统计物理学的角度揭示其本质。

Method: 通过分析与后验坍塌相关的平凡解的稳定性，识别出临界超参数阈值，并表征了区分有意义的潜在推理和坍塌的临界边界，该边界以近似后验与先验分布之间的KL散度的不连续性为特征。

Result: 在合成和真实世界的数据集上验证了临界行为，证实了相变的存在。

Conclusion: 后验坍塌不仅是优化失败，而是数据结构和变分约束相互作用产生的涌现相变，这为理解深度生成模型的训练能力和表示能力提供了新的见解。

Abstract: We investigate the phenomenon of posterior collapse in variational
autoencoders (VAEs) from the perspective of statistical physics, and reveal
that it constitutes a phase transition governed jointly by data structure and
model hyper-parameters. By analyzing the stability of the trivial solution
associated with posterior collapse, we identify a critical hyper-parameter
threshold. This critical boundary, separating meaningful latent inference from
collapse, is characterized by a discontinuity in the KL divergence between the
approximate posterior and the prior distribution. We validate this critical
behavior on both synthetic and real-world datasets, confirming the existence of
a phase transition. Our results demonstrate that posterior collapse is not
merely an optimization failure, but rather an emerging phase transition arising
from the interplay between data structure and variational constraints. This
perspective offers new insights into the trainability and representational
capacity of deep generative models.

</details>


### [474] [Quagmires in SFT-RL Post-Training: When High SFT Scores Mislead and What to Use Instead](https://arxiv.org/abs/2510.01624)
*Feiyang Kang,Michael Kuchnik,Karthik Padthe,Marin Vlastelica,Ruoxi Jia,Carole-Jean Wu,Newsha Ardalani*

Main category: cs.LG

TL;DR: 在推理LLM的后训练中，标准的做法是分两个独立的阶段进行训练：监督微调（SFT）和具有可验证奖励的强化学习（RLVR，简称“RL”）。本研究挑战了高SFT分数是否能转化为RL后性能的提升。我们发现高SFT分数可能偏向于更简单或更同质化的数据，并且不能可靠地预测后续RL收益或扩大的后训练效果。在某些情况下，在SFT性能有所提高的模型上进行RL训练，可能比在没有SFT的基础模型上进行RL训练导致更差的结果。我们研究了替代指标，并确定了在留出推理示例上的泛化损失和Pass@large k性能可以作为RL结果的有力预测指标。我们训练了数百个多达12B参数的模型，使用GRPO进行SFT和RLVR，并在7个数学基准上进行了广泛的评估，重复次数高达256次，花费了超过1M的GPU小时。实验包括来自Llama3、Mistral-Nemo、Qwen3以及多个SFT/RL数据集的模型。与直接从RL前性能预测相比，基于泛化损失和Pass@large k的预测精度显著提高，R^2系数和Spearman秩相关系数提高了0.5（2倍）。这在广泛的应用场景中具有很强的实用性。例如，在大多数实验中，我们发现SFT在唯一示例上训练一个epoch的效果不如在长度不一的示例上训练两个epoch的效果，无论是在SFT之后还是SFT-then-RL之后；在相同的SFT预算下，仅在短示例上训练可能导致更好的SFT性能，但通常在RL之后，其结果比在长度不一的示例上训练要差。评估工具将开源。


<details>
  <summary>Details</summary>
Motivation: 研究当前大型语言模型（LLM）在推理任务的后训练流程中，监督微调（SFT）分数与后续强化学习（RL）阶段性能提升之间的关系，挑战了SFT分数能直接预测RL性能提升的普遍假设。

Method: 通过大量实验（训练数百个模型，涉及Llama3、Mistral-Nemo、Qwen3等，在7个数学基准上进行评估，总计花费超过1M GPU小时），研究了SFT分数与RL结果的关联性。寻找能够替代SFT分数，更准确预测RL表现的指标，例如在留出推理示例上的泛化损失和Pass@large k性能。分析了不同训练策略（如训练轮数、数据长度）对SFT和RL阶段的影响。

Result: 研究发现，高SFT分数并不总是能转化为RL阶段的性能提升，有时甚至可能导致性能下降。SFT分数可能偏向于简单或同质化的数据，预测能力有限。泛化损失和Pass@large k性能被证明是比SFT分数更可靠的RL结果预测指标，能显著提高预测精度（R^2和Spearman秩相关系数提升高达0.5）。在相同的SFT预算下，使用不同长度的示例进行训练会影响RL阶段的表现，仅训练短示例可能导致RL阶段表现不佳。

Conclusion: SFT分数不是衡量LLM在推理任务上RL阶段表现的可靠指标。泛化损失和Pass@large k性能提供了更准确的预测依据，有助于优化LLM的后训练策略。在进行SFT和RL训练时，应考虑数据多样性和长度，以获得更好的整体性能。研究结果为LLM的后训练提供了实用的指导，并计划开源相关评估工具。

Abstract: In post-training for reasoning Large Language Models (LLMs), the current
state of practice trains LLMs in two independent stages: Supervised Fine-Tuning
(SFT) and Reinforcement Learning with Verifiable Rewards (RLVR, shortened as
``RL'' below). In this work, we challenge whether high SFT scores translate to
improved performance after RL. We provide extensive counter-examples where this
is not true. We find high SFT scores can be biased toward simpler or more
homogeneous data and are not reliably predictive of subsequent RL gains or
scaled-up post-training effectiveness. In some cases, RL training on models
with improved SFT performance could lead to substantially worse outcome
compared to RL on the base model without SFT. We study alternative metrics and
identify generalization loss on held-out reasoning examples and Pass@large k
performance to provide strong proxies for the RL outcome. We trained hundreds
of models up to 12B-parameter with SFT and RLVR via GRPO and ran extensive
evaluations on 7 math benchmarks with up to 256 repetitions, spending $>$1M GPU
hours. Experiments include models from Llama3, Mistral-Nemo, Qwen3 and multiple
state-of-the-art SFT/RL datasets. Compared to directly predicting from pre-RL
performance, prediction based on generalization loss and Pass@large k achieves
substantial higher precision, improving $R^2$ coefficient and Spearman's rank
correlation coefficient by up to 0.5 (2x). This provides strong utility for
broad use cases. For example, in most experiments, we find SFT training on
unique examples for a one epoch underperforms training on half examples for two
epochs, either after SFT or SFT-then-RL; With the same SFT budget, training
only on short examples may lead to better SFT performance, though, it often
leads to worse outcome after RL compared to training on examples with varying
lengths. Evaluation tool will be open-sourced.

</details>


### [475] [Demystifying Synthetic Data in LLM Pre-training: A Systematic Study of Scaling Laws, Benefits, and Pitfalls](https://arxiv.org/abs/2510.01631)
*Feiyang Kang,Newsha Ardalani,Michael Kuchnik,Youssef Emad,Mostafa Elhoushi,Shubhabrata Sengupta,Shang-Wen Li,Ramya Raghavendra,Ruoxi Jia,Carole-Jean Wu*

Main category: cs.LG

TL;DR: The paper investigates the use of synthetic data for training Large Language Models (LLMs). While pre-training solely on rephrased synthetic data does not outperform natural web data, a mixture of 1/3 rephrased synthetic data and 2/3 natural web data can accelerate training by 5-10x. Textbook-style synthetic data alone leads to higher downstream losses. The optimal ratio of rephrased synthetic data is around 30%, and models around 8B parameters produce effective synthetic data. The study shows mixed results regarding 'model collapse', with rephrased synthetic data showing no degradation, but textbook-style synthetic data exhibiting collapse patterns.


<details>
  <summary>Details</summary>
Motivation: High-quality training data is scarce for Large Language Models (LLMs), and synthetic data presents a potential solution to this limitation. This research aims to empirically investigate the effectiveness and conditions under which synthetic data can be beneficial for LLM pre-training.

Method: A large-scale empirical study was conducted using over 1000 LLMs and more than 100,000 GPU hours. A unified protocol and scaling laws were applied to compare natural web data, various types of synthetic data (rephrased text, generated textbooks), and mixtures of natural and synthetic data.

Result: Pre-training solely on rephrased synthetic data was not faster than using natural web texts. However, mixing 1/3 rephrased synthetic data with 2/3 natural web data achieved a 5-10x speedup in reaching the same validation loss at larger data budgets. Pre-training on textbook-style synthetic data alone resulted in significantly higher downstream domain losses, especially with smaller data budgets. The optimal ratio for rephrased synthetic data in mixtures was found to be approximately 30%, and generator models around 8 billion parameters produced effective pre-training data. Mixed evidence was found regarding 'model collapse'; rephrased synthetic data showed no performance degradation at foreseeable scales, while mixtures including textbook-style pure-generated synthetic data exhibited 'model collapse' patterns.

Conclusion: Synthetic data offers conditional benefits for LLM pre-training. A mixture of rephrased synthetic data and natural web data can significantly accelerate training. The effectiveness of synthetic data depends on factors like model size, data budget, and the type of synthetic data used. The study provides practical guidance on using synthetic data, demystifying its role and validating its conditional advantages, while also highlighting potential risks like 'model collapse' with certain types of synthetic data.

Abstract: Training data plays a crucial role in Large Language Models (LLM) scaling,
yet high quality data is of limited supply. Synthetic data techniques offer a
potential path toward sidestepping these limitations. We conduct a large-scale
empirical investigation (>1000 LLMs with >100k GPU hours) using a unified
protocol and scaling laws, comparing natural web data, diverse synthetic types
(rephrased text, generated textbooks), and mixtures of natural and synthetic
data. Specifically, we found pre-training on rephrased synthetic data
\textit{alone} is not faster than pre-training on natural web texts; while
pre-training on 1/3 rephrased synthetic data mixed with 2/3 natural web texts
can speed up 5-10x (to reach the same validation loss) at larger data budgets.
Pre-training on textbook-style synthetic data \textit{alone} results in notably
higher loss on many downstream domains especially at small data budgets. "Good"
ratios of synthetic data in training data mixtures depend on the model size and
data budget, empirically converging to ~30% for rephrased synthetic data.
Larger generator models do not necessarily yield better pre-training data than
~8B-param models. These results contribute mixed evidence on "model collapse"
during large-scale single-round (n=1) model training on synthetic
data--training on rephrased synthetic data shows no degradation in performance
in foreseeable scales whereas training on mixtures of textbook-style
pure-generated synthetic data shows patterns predicted by "model collapse". Our
work demystifies synthetic data in pre-training, validates its conditional
benefits, and offers practical guidance.

</details>


### [476] [CAT: Curvature-Adaptive Transformers for Geometry-Aware Learning](https://arxiv.org/abs/2510.01634)
*Ryan Y. Lin,Siddhartha Ojha,Nicholas Bai*

Main category: cs.LG

TL;DR: CAT通过学习的几何适应性克服了Transformer在处理具有非欧几里得结构的数据时的局限性，在知识图谱补全任务上实现了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的Transformer模型在处理具有非欧几里得结构的数据时存在局限性，而现有的扩展（如双曲空间和球面空间）需要预先固定几何空间，缺乏灵活性。

Method: 提出了一种新颖的架构——Curvature-Adaptive Transformer (CAT)，它通过一个轻量级的、可微分的门控机制，动态地学习每个 token 在三种几何注意力分支中的路由。

Result: 在知识图谱补全基准测试（FB15k-237, WN18RR）上，CAT 在 MRR 和 Hits@10 指标上比固定几何基线模型提高了约 10%，同时参数量仅增加了 5%，推理时间相当。

Conclusion: 学习的几何适应性优于任何单一的固定几何方法，CAT 为跨语言、视觉和多模态领域的混合几何架构提供了一个可扩展且可解释的基础。

Abstract: Transformers achieve strong performance across diverse domains but implicitly
assume Euclidean geometry in their attention mechanisms, limiting their
effectiveness on data with non-Euclidean structure. While recent extensions to
hyperbolic and spherical spaces show promise for hierarchical and cyclical
patterns, respectively, they require committing to a single geometry a priori,
reducing flexibility when data exhibits mixed geometric properties. We
introduce the Curvature-Adaptive Transformer (CAT), a novel architecture that
dynamically learns per-token routing across three geometric attention branches
through a lightweight, differentiable gating mechanism. Unlike fixed-geometry
approaches, CAT enables adaptive geometric specialization, routing tokens to
the appropriate curvature based on their local relational structure. The
routing network provides interpretable curvature preferences while each branch
employs geometry-specific operations optimized for its respective manifold. On
knowledge graph completion benchmarks (FB15k-237, WN18RR), CAT achieves
approximately 10% improvements in MRR and Hits@10 over fixed-geometry baselines
with minimal overhead (5% parameter increase, comparable inference time). These
results demonstrate that learned geometric adaptation outperforms any single
fixed geometry for complex relational reasoning, establishing CAT as a scalable
and interpretable foundation for mixture-of-geometry architectures across
language, vision, and multimodal domains.

</details>


### [477] [Detecting Post-generation Edits to Watermarked LLM Outputs via Combinatorial Watermarking](https://arxiv.org/abs/2510.01637)
*Liyan Xie,Muhammad Siddeek,Mohamed Seif,Andrea J. Goldsmith,Mengdi Wang*

Main category: cs.LG

TL;DR: 该论文提出了一种新的组合模式水印框架，用于检测和本地化大型语言模型（LLM）生成文本中存在的后生成编辑。


<details>
  <summary>Details</summary>
Motivation: 为了区分AI生成和人类书写的文本，并应对LLM生成内容可能经历的后生成编辑（如人工修改或欺骗攻击），本研究旨在检测和定位这些修改。

Method: 提出了一种组合模式的水印框架，该框架将词汇表划分为不相交的子集，并通过在生成过程中强制执行这些子集上的确定性组合模式来嵌入水印。该框架还包含一个用于检测水印的全局统计量，以及用于标记和定位潜在编辑的局部统计量。

Result: 在开源LLM上，针对各种编辑场景进行了评估，并在编辑定位方面取得了强大的实证性能，同时引入了两种特定任务的评估指标：I类错误率和检测准确率。

Conclusion: 所提出的组合模式水印框架能够有效地检测和本地化LLM生成文本中的后生成编辑，并在评估中表现出强大的性能。

Abstract: Watermarking has become a key technique for proprietary language models,
enabling the distinction between AI-generated and human-written text. However,
in many real-world scenarios, LLM-generated content may undergo post-generation
edits, such as human revisions or even spoofing attacks, making it critical to
detect and localize such modifications. In this work, we introduce a new task:
detecting post-generation edits locally made to watermarked LLM outputs. To
this end, we propose a combinatorial pattern-based watermarking framework,
which partitions the vocabulary into disjoint subsets and embeds the watermark
by enforcing a deterministic combinatorial pattern over these subsets during
generation. We accompany the combinatorial watermark with a global statistic
that can be used to detect the watermark. Furthermore, we design lightweight
local statistics to flag and localize potential edits. We introduce two
task-specific evaluation metrics, Type-I error rate and detection accuracy, and
evaluate our method on open-source LLMs across a variety of editing scenarios,
demonstrating strong empirical performance in edit localization.

</details>


### [478] [Support Basis: Fast Attention Beyond Bounded Entries](https://arxiv.org/abs/2510.01643)
*Maryam Aliakbarpour,Vladimir Braverman,Junze Yin,Haochen Zhang*

Main category: cs.LG

TL;DR: 论文提出一种新的支持基分解框架，用于在不依赖有界条目假设的情况下实现高效的注意力近似，并通过理论和实验证明了其在现代大型语言模型中的有效性。


<details>
  <summary>Details</summary>
Motivation: 二次方复杂度的softmax注意力是扩展大型语言模型的瓶颈，先前的方法（Alman and Song, NeurIPS 2023）在有界条目假设下有效，但该假设在实践中很少满足。

Method: 提出支持基分解框架，利用查询和键矩阵的子高斯分布特性，对稀疏部分进行精确计算，对密集部分进行多项式近似。在此基础上，扩展到多阈值设置，消除了分布假设。

Result: 在理论上证明了次二次方的运行时间。首次为多项式注意力（Kacham et al., ICML 2024）的经验成功提供了理论依据，表明softmax注意力可以通过结合多个带草图的多项式注意力来近似。

Conclusion: 支持基分解提供了一种新的、更通用的方法来近似softmax注意力，克服了先前方法的局限性，并为提高大型语言模型的效率提供了理论基础。

Abstract: The quadratic complexity of softmax attention remains a central bottleneck in
scaling large language models (LLMs). [Alman and Song, NeurIPS 2023] proposed a
sub-quadratic attention approximation algorithm, but it works only under the
restrictive bounded-entry assumption. Since this assumption rarely holds in
practice, its applicability to modern LLMs is limited.
  In this paper, we introduce support-basis decomposition, a new framework for
efficient attention approximation beyond bounded entries. We empirically
demonstrate that the entries of the query and key matrices exhibit sub-Gaussian
behavior. Our approach uses this property to split large and small entries,
enabling exact computation on sparse components and polynomial approximation on
dense components. We establish rigorous theoretical guarantees, proving a
sub-quadratic runtime, and extend the method to a multi-threshold setting that
eliminates all distributional assumptions. Furthermore, we provide the first
theoretical justification for the empirical success of polynomial attention
[Kacham, Mirrokni, and Zhong, ICML 2024], showing that softmax attention can be
closely approximated by a combination of multiple polynomial attentions with
sketching.

</details>


### [479] [Source-Free Cross-Domain Continual Learning](https://arxiv.org/abs/2510.01649)
*Muhammad Tanzil Furqon,Mahardhika Pratama,Igor Škrjanc,Lin Liu,Habibullah Habibullah,Kutluyil Dogancay*

Main category: cs.LG

TL;DR: 本研究提出了源域无关的跨域持续学习方法REFEREE，通过频率感知提示和不确定性加权策略来解决无标签源域和灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 现有的跨域持续学习方法需要完整的标签源域，这在隐私受限环境中不可行。本研究旨在解决源域无关的跨域持续学习问题，即完全禁止使用源域样本。

Method: REFEREE方法结合了源域预训练模型和大规模视觉-语言模型，利用频率感知提示技术（鼓励低频分量，抑制高频分量）来处理域偏移问题，生成对抗噪声伪标签的频率感知增强样本。通过不确定性加权策略来解决伪标签噪声问题。此外，通过冻结骨干网络并使用基于随机核方法的线性判别分析（KLDA）来解决灾难性遗忘问题。

Result: 数值研究表明，REFEREE方法在性能上优于那些可以使用源域样本的现有方法。

Conclusion: REFEREE方法成功地解决了源域无关的跨域持续学习问题，并在性能上超越了现有技术。

Abstract: Although existing cross-domain continual learning approaches successfully
address many streaming tasks having domain shifts, they call for a fully
labeled source domain hindering their feasibility in the privacy constrained
environments. This paper goes one step ahead with the problem of source-free
cross-domain continual learning where the use of source-domain samples are
completely prohibited. We propose the idea of rehearsal-free frequency-aware
dynamic prompt collaborations (REFEREE) to cope with the absence of labeled
source-domain samples in realm of cross-domain continual learning. REFEREE is
built upon a synergy between a source-pre-trained model and a large-scale
vision-language model, thus overcoming the problem of sub-optimal
generalizations when relying only on a source pre-trained model. The domain
shift problem between the source domain and the target domain is handled by a
frequency-aware prompting technique encouraging low-frequency components while
suppressing high-frequency components. This strategy generates frequency-aware
augmented samples, robust against noisy pseudo labels. The noisy pseudo-label
problem is further addressed with the uncertainty-aware weighting strategy
where the mean and covariance matrix are weighted by prediction uncertainties,
thus mitigating the adverse effects of the noisy pseudo label. Besides, the
issue of catastrophic forgetting (CF) is overcome by kernel linear discriminant
analysis (KLDA) where the backbone network is frozen while the classification
is performed using the linear discriminant analysis approach guided by the
random kernel method. Our rigorous numerical studies confirm the advantage of
our approach where it beats prior arts having access to source domain samples
with significant margins.

</details>


### [480] [The Unseen Frontier: Pushing the Limits of LLM Sparsity with Surrogate-Free ADMM](https://arxiv.org/abs/2510.01650)
*Kwanhee Lee,Hyeondo Jang,Dongyeop Lee,Dan Alistarh,Namhoon Lee*

Main category: cs.LG

TL;DR: Elsa是一种新的神经网络剪枝方法，可以达到90%的稀疏度，同时保持高模型保真度。


<details>
  <summary>Details</summary>
Motivation: 现有的神经网络剪枝技术在达到中等稀疏度（50-60%）后，模型准确度会严重下降，因此需要新的方法来突破这一瓶颈。

Method: Elsa使用基于ADMM的标准约束优化技术来解决现有方法依赖于替代目标函数的局限性。

Result: Elsa在LLaMA-2-7B模型上实现了90%的稀疏度，困惑度比现有的最佳方法低7.8倍。Elsa-L是其量化版本，可扩展到27B模型。

Conclusion: Elsa在LLM稀疏性方面取得了重大进展，并表明在迄今探索有限的领域仍有进一步改进的空间。

Abstract: Neural network pruning is a promising technique to mitigate the excessive
computational and memory requirements of large language models (LLMs). Despite
its promise, however, progress in this area has diminished, as conventional
methods are seemingly unable to surpass moderate sparsity levels (50-60%)
without severely degrading model accuracy. This work breaks through the current
impasse, presenting a principled and effective method called $\texttt{Elsa}$,
which achieves extreme sparsity levels of up to 90% while retaining high model
fidelity. This is done by identifying several limitations in current practice,
all of which can be traced back to their reliance on a surrogate objective
formulation. $\texttt{Elsa}$ tackles this issue directly and effectively via
standard and well-established constrained optimization techniques based on
ADMM. Our extensive experiments across a wide range of models and scales show
that $\texttt{Elsa}$ achieves substantial improvements over existing methods;
e.g., it achieves 7.8$\times$ less perplexity than the best existing method on
LLaMA-2-7B at 90% sparsity. Furthermore, we present
$\texttt{Elsa}_{\text{-L}}$, a quantized variant that scales to extremely large
models (27B), and establish its theoretical convergence guarantees. These
results highlight meaningful progress in advancing the frontier of LLM
sparsity, while promising that significant opportunities for further
advancement may remain in directions that have so far attracted limited
exploration.

</details>


### [481] [Asymmetric Proximal Policy Optimization: mini-critics boost LLM reasoning](https://arxiv.org/abs/2510.01656)
*Jiashun Liu,Johan Obando-Ceron,Han Lu,Yancheng He,Weixun Wang,Wenbo Su,Bo Zheng,Pablo Samuel Castro,Aaron Courville,Ling Pan*

Main category: cs.LG

TL;DR: AsyPPO是一种新的RL4LLM框架，通过使用轻量级的小型批评家网络来恢复批评家的作用，提高了学习稳定性和性能，同时保持了效率。


<details>
  <summary>Details</summary>
Motivation: 大多数RL4LLM方法为了效率而避免使用显式批评家，但这会导致稀疏奖励和长期推理的挑战。本文旨在从架构角度解决这一瓶颈。

Method: AsyPPO框架使用多个轻量级的小型批评家网络，每个网络都在不同的提示分片上进行训练，以鼓励多样性并保持校准。它还利用批评家之间的不确定性来优化策略更新，包括屏蔽优势和过滤高发散状态。

Result: 在少于5000个样本的开源数据上训练后，AsyPPO在多个基准测试中持续提高了学习稳定性和性能，在Qwen3-4b-Base上提高了6%以上，在Qwen3-8b-Base和Qwen3-14b-Base上分别提高了约3%，优于GRPO和经典PPO等强基线。

Conclusion: 研究结果表明，架构创新对于可扩展、高效的RL算法至关重要。AsyPPO通过其独特的设计，有效地解决了大型模型训练中的挑战。

Abstract: Most recent RL for LLMs (RL4LLM) methods avoid explicit critics, replacing
them with average advantage baselines. This shift is largely pragmatic:
conventional value functions are computationally expensive to train at LLM
scale and often fail under sparse rewards and long reasoning horizons. We
revisit this bottleneck from an architectural perspective and introduce
Asymmetric Proximal Policy Optimization (AsyPPO), a simple and scalable
framework that restores the critics role while remaining efficient in
large-model settings. AsyPPO employs a set of lightweight mini-critics, each
trained on disjoint prompt shards. This design encourages diversity while
preserving calibration, reducing value-estimation bias. Beyond robust
estimation, AsyPPO leverages inter-critic uncertainty to refine the policy
update: (i) masking advantages in states where critics agree and gradients add
little learning signal, and (ii) filtering high-divergence states from entropy
regularization, suppressing spurious exploration. After training on open-source
data with only 5,000 samples, AsyPPO consistently improves learning stability
and performance across multiple benchmarks over strong baselines, such as GRPO,
achieving performance gains of more than six percent on Qwen3-4b-Base and about
three percent on Qwen3-8b-Base and Qwen3-14b-Base over classic PPO, without
additional tricks. These results highlight the importance of architectural
innovations for scalable, efficient algorithms.

</details>


### [482] [Learning Time-Series Representations by Hierarchical Uniformity-Tolerance Latent Balancing](https://arxiv.org/abs/2510.01658)
*Amin Jalali,Milad Soltany,Michael Greenspan,Ali Etemad*

Main category: cs.LG

TL;DR: TimeHUT是一种通过分层均匀性-容忍度平衡的对比表示来学习时间序列表示的新颖方法，通过两个不同的损失函数来平衡嵌入空间的均匀性和容忍度，并在各种任务上取得了优于先前方法的性能。


<details>
  <summary>Details</summary>
Motivation: 时间序列表示学习的挑战在于平衡嵌入空间的均匀性和容忍度，以有效捕捉时间依赖性。

Method: TimeHUT采用分层结构学习实例级和时间级信息，并结合温度调度器和分层角度边缘损失来平衡均匀性和容忍度，同时强制执行实例级和时间级对比损失。

Result: 在UCR和UAE数据集的分类任务上，TimeHUT的性能显著优于先前方法；在Yahoo和KPI数据集的异常检测任务上，性能具有竞争力。

Conclusion: TimeHUT通过分层均匀性-容忍度平衡的对比表示，在时间序列表示学习方面取得了优于现有方法的性能，尤其是在分类任务上。

Abstract: We propose TimeHUT, a novel method for learning time-series representations
by hierarchical uniformity-tolerance balancing of contrastive representations.
Our method uses two distinct losses to learn strong representations with the
aim of striking an effective balance between uniformity and tolerance in the
embedding space. First, TimeHUT uses a hierarchical setup to learn both
instance-wise and temporal information from input time-series. Next, we
integrate a temperature scheduler within the vanilla contrastive loss to
balance the uniformity and tolerance characteristics of the embeddings.
Additionally, a hierarchical angular margin loss enforces instance-wise and
temporal contrast losses, creating geometric margins between positive and
negative pairs of temporal sequences. This approach improves the coherence of
positive pairs and their separation from the negatives, enhancing the capture
of temporal dependencies within a time-series sample. We evaluate our approach
on a wide range of tasks, namely 128 UCR and 30 UAE datasets for univariate and
multivariate classification, as well as Yahoo and KPI datasets for anomaly
detection. The results demonstrate that TimeHUT outperforms prior methods by
considerable margins on classification, while obtaining competitive results for
anomaly detection. Finally, detailed sensitivity and ablation studies are
performed to evaluate different components and hyperparameters of our method.

</details>


### [483] [Shift-Invariant Attribute Scoring for Kolmogorov-Arnold Networks via Shapley Value](https://arxiv.org/abs/2510.01663)
*Wangxuan Fan,Ching Wang,Siqi Li,Nan Liu*

Main category: cs.LG

TL;DR: KANs在保持高预测精度的同时，可以通过可学习的激活函数恢复符号表示，但其网络剪枝面临挑战。ShapKAN提出一种基于Shapley值的剪枝框架，通过评估节点在移位不变的方式下的重要性，克服了传统基于幅值的方法的局限性，实现了有效的网络压缩和可解释性增强。


<details>
  <summary>Details</summary>
Motivation: 传统神经网络在预测方面表现出色，但其黑箱性质阻碍了对特征-结果关系的理解。KANs通过引入可学习的基于样条的边缘激活函数来解决这个问题，可以在保持竞争性能的同时恢复符号表示。然而，KANs的架构给网络剪枝带来了独特的挑战，传统的基于幅值的方法由于对输入坐标移动的敏感性而变得不可靠。

Method: 提出了一种名为ShapKAN的剪枝框架，该框架利用Shapley值归因来以移位不变的方式评估节点的重要性。与基于幅值的方法不同，ShapKAN量化了每个节点对网络输出的实际贡献，确保了无论输入参数如何，节点的重要性排名都能保持一致。

Result: 在合成和真实世界数据集上的大量实验表明，ShapKAN可以保持真实的节点重要性，同时实现有效的网络压缩。

Conclusion: ShapKAN通过基于Shapley值评估节点重要性，克服了传统剪枝方法的局限性，提高了KANs的可解释性，并支持在资源受限的环境中进行部署。

Abstract: For many real-world applications, understanding feature-outcome relationships
is as crucial as achieving high predictive accuracy. While traditional neural
networks excel at prediction, their black-box nature obscures underlying
functional relationships. Kolmogorov--Arnold Networks (KANs) address this by
employing learnable spline-based activation functions on edges, enabling
recovery of symbolic representations while maintaining competitive performance.
However, KAN's architecture presents unique challenges for network pruning.
Conventional magnitude-based methods become unreliable due to sensitivity to
input coordinate shifts. We propose \textbf{ShapKAN}, a pruning framework using
Shapley value attribution to assess node importance in a shift-invariant
manner. Unlike magnitude-based approaches, ShapKAN quantifies each node's
actual contribution, ensuring consistent importance rankings regardless of
input parameterization. Extensive experiments on synthetic and real-world
datasets demonstrate that ShapKAN preserves true node importance while enabling
effective network compression. Our approach improves KAN's interpretability
advantages, facilitating deployment in resource-constrained environments.

</details>


### [484] [Beyond Simple Fusion: Adaptive Gated Fusion for Robust Multimodal Sentiment Analysis](https://arxiv.org/abs/2510.01677)
*Han Wu,Yanming Sun,Yunhe Yang,Derek F. Wong*

Main category: cs.LG

TL;DR: AGFN通过自适应的门控融合机制，根据信息熵和模态重要性动态调整特征权重，以解决多模态情感分析中模态质量不均的问题，并在CMU-MOSI和CMU-MOSEI数据集上取得了优于基线模型的性能。


<details>
  <summary>Details</summary>
Motivation: 简单融合技术在处理多模态情感分析（MSA）时，未能充分考虑模态质量（如噪声、缺失或语义冲突）的差异，导致在识别细微情感差别时性能不佳。

Method: 提出了一种自适应门控融合网络（AGFN），该网络通过一个基于信息熵和模态重要性的双门控融合机制，自适应地调整特征权重，以减轻噪声模态的影响并优先考虑信息丰富的线索。

Result: AGFN在CMU-MOSI和CMU-MOSEI数据集上显著优于现有的基线模型，能够有效识别细微情感，并展现出鲁棒的性能。可视化分析表明，AGFN通过降低特征位置与预测误差之间的相关性，增强了泛化能力。

Conclusion: AGFN通过其自适应的门控融合机制，有效解决了多模态情感分析中模态质量不均的问题，提高了模型在识别细微情感方面的准确性和鲁棒性，并通过学习更广泛的特征分布，实现了更好的泛化能力。

Abstract: Multimodal sentiment analysis (MSA) leverages information fusion from diverse
modalities (e.g., text, audio, visual) to enhance sentiment prediction.
However, simple fusion techniques often fail to account for variations in
modality quality, such as those that are noisy, missing, or semantically
conflicting. This oversight leads to suboptimal performance, especially in
discerning subtle emotional nuances. To mitigate this limitation, we introduce
a simple yet efficient \textbf{A}daptive \textbf{G}ated \textbf{F}usion
\textbf{N}etwork that adaptively adjusts feature weights via a dual gate fusion
mechanism based on information entropy and modality importance. This mechanism
mitigates the influence of noisy modalities and prioritizes informative cues
following unimodal encoding and cross-modal interaction. Experiments on
CMU-MOSI and CMU-MOSEI show that AGFN significantly outperforms strong
baselines in accuracy, effectively discerning subtle emotions with robust
performance. Visualization analysis of feature representations demonstrates
that AGFN enhances generalization by learning from a broader feature
distribution, achieved by reducing the correlation between feature location and
prediction error, thereby decreasing reliance on specific locations and
creating more robust multimodal feature representations.

</details>


### [485] [PASTA: A Unified Framework for Offline Assortment Learning](https://arxiv.org/abs/2510.01693)
*Juncheng Dong,Weibin Mo,Zhengling Qi,Cong Shi,Ethan X. Fang,Vahid Tarokh*

Main category: cs.LG

TL;DR: 本研究提出了一种名为PASTA的新框架，用于解决离线和数据驱动的 ассорти优化问题，即使在数据覆盖不全的情况下也能实现最优预期收入。


<details>
  <summary>Details</summary>
Motivation: 在离线数据驱动的 ассорти优化问题中，由于历史客户选择数据覆盖不足，很难设计出有严格保证的有效解决方案。

Method: PASTA框架利用悲观主义原理，在一般选择模型下实现最优预期收入。它只需要离线数据分布包含最优 ассорти，而不需要对所有可行的 ассорти进行全面覆盖。理论上，在多项 logit 和嵌套 logit 模型等选择模型中，证明了首个有限样本遗憾界限。此外，还推导了一个 minimax 遗憾下界，证明了 PASTA 在样本和模型复杂度方面具有 minimax 最优性。

Result: 理论上，在多种选择模型（包括多项 logit 和嵌套 logit 模型）中，建立了有限样本遗憾界限，并证明了 PASTA 的 minimax 最优性。数值实验表明，PASTA 的性能优于现有的基线方法。

Conclusion: PASTA 框架能够有效地解决 ассорти优化问题，即使在数据覆盖不全的情况下，也能实现最优的预期收入，并且在理论和实践中都优于现有方法。

Abstract: We study a broad class of assortment optimization problems in an offline and
data-driven setting. In such problems, a firm lacks prior knowledge of the
underlying choice model, and aims to determine an optimal assortment based on
historical customer choice data. The combinatorial nature of assortment
optimization often results in insufficient data coverage, posing a significant
challenge in designing provably effective solutions. To address this, we
introduce a novel Pessimistic Assortment Optimization (PASTA) framework that
leverages the principle of pessimism to achieve optimal expected revenue under
general choice models. Notably, PASTA requires only that the offline data
distribution contains an optimal assortment, rather than providing the full
coverage of all feasible assortments. Theoretically, we establish the first
finite-sample regret bounds for offline assortment optimization across several
widely used choice models, including the multinomial logit and nested logit
models. Additionally, we derive a minimax regret lower bound, proving that
PASTA is minimax optimal in terms of sample and model complexity. Numerical
experiments further demonstrate that our method outperforms existing baseline
approaches.

</details>


### [486] [Representational Alignment Across Model Layers and Brain Regions with Hierarchical Optimal Transport](https://arxiv.org/abs/2510.01706)
*Shaan Shah,Meenakshi Khosla*

Main category: cs.LG

TL;DR: HOT框架通过层次最优输运解决现有表示相似性方法的局限性，实现了网络间更优、更全局的对齐，并能处理不同深度的问题。


<details>
  <summary>Details</summary>
Motivation: 现有表示相似性方法在对齐网络层时存在结果不对称、缺乏全局对齐分数以及难以处理网络深度不同等问题，这些问题源于忽略了全局激活结构并强制进行一对一的层对应。需要一种新的方法来解决这些局限性。

Method: 提出了一种名为层次最优输运（HOT）的统一框架，该框架能够联合推断出层与层之间匹配的软耦合以及神经元级别的输运计划。HOT允许源神经元将信息（质量）分散到多个目标层，同时在满足边缘约束的条件下最小化总输运成本。

Result: HOT框架在视觉模型、大型语言模型以及人类视觉皮层记录的评估中，其对齐质量均能达到或超过标准的逐层匹配方法。此外，HOT揭示了平滑、细粒度的层次对应关系，例如早期层对应早期层，深层保持相对位置，并且通过将信息分散到多个层来解决深度不匹配的问题。这些结构化模式是从全局优化中自然产生的，而非人为强制施加，这是贪婪的逐层方法所不具备的。

Conclusion: HOT框架提供了一种更丰富、更可解释的表示比较方法，特别适用于网络结构或深度不同的情况。它通过全局优化实现了对齐质量的提升，并揭示了有意义的层次结构，克服了现有方法的局限性。

Abstract: Standard representational similarity methods align each layer of a network to
its best match in another independently, producing asymmetric results, lacking
a global alignment score, and struggling with networks of different depths.
These limitations arise from ignoring global activation structure and
restricting mappings to rigid one-to-one layer correspondences. We propose
Hierarchical Optimal Transport (HOT), a unified framework that jointly infers
soft, globally consistent layer-to-layer couplings and neuron-level transport
plans. HOT allows source neurons to distribute mass across multiple target
layers while minimizing total transport cost under marginal constraints. This
yields both a single alignment score for the entire network comparison and a
soft transport plan that naturally handles depth mismatches through mass
distribution. We evaluate HOT on vision models, large language models, and
human visual cortex recordings. Across all domains, HOT matches or surpasses
standard pairwise matching in alignment quality. Moreover, it reveals smooth,
fine-grained hierarchical correspondences: early layers map to early layers,
deeper layers maintain relative positions, and depth mismatches are resolved by
distributing representations across multiple layers. These structured patterns
emerge naturally from global optimization without being imposed, yet are absent
in greedy layer-wise methods. HOT thus enables richer, more interpretable
comparisons between representations, particularly when networks differ in
architecture or depth.

</details>


### [487] [ActiNet: Activity intensity classification of wrist-worn accelerometers using self-supervised deep learning](https://arxiv.org/abs/2510.01712)
*Aidan Acquah,Shing Chan,Aiden Doherty*

Main category: cs.LG

TL;DR: 本研究评估了一种名为 ActiNet 的自监督学习模型，结合隐马尔可夫模型 (HMM)，在利用腕部加速度计数据进行人类活动识别 (HAR) 方面的有效性，并将其与现有的随机森林 (RF) + HMM 模型进行了比较。


<details>
  <summary>Details</summary>
Motivation: 在流行病学研究中，使用可靠准确的 HAR 模型从被动收集的腕部加速度计数据中识别人类活动至关重要，这些研究旨在调查身体活动与健康结果之间的关联。尽管自监督学习在改进 HAR 方面备受关注，但尚不清楚其与 HMM 结合在多大程度上能显著改善分类性能，以及这对预测的每日活动强度构成有何影响。

Method: 研究人员使用 151 名 CAPTURE-24 参与者的数据，训练了一个名为 ActiNet 的自监督、18 层、修改版 ResNet-V2 模型，然后使用隐马尔可夫模型 (HMM) 进行平滑处理，以对活动强度标签进行分类。该模型性能通过 5 折分层分组交叉验证进行评估，并与现有文献中建立的基线随机森林 (RF) + HMM 模型进行了比较。

Result: ActiNet 模型能够区分活动强度标签，平均宏观 F1 分数为 0.82，平均 Cohen's kappa 分数为 0.86。这优于在同一数据集上训练和验证的 RF + HMM 模型，后者的平均分数分别为 0.77 和 0.81。这些结果在不同年龄和性别亚组中保持一致。

Conclusion: 研究结果表明，ActiNet 模型在从腕部加速度计数据中提取活动强度标签方面表现优于传统的 RF + HMM 模型，并且在不同年龄和性别群体中表现一致。这鼓励在未来的流行病学研究中使用 ActiNet。

Abstract: The use of reliable and accurate human activity recognition (HAR) models on
passively collected wrist-accelerometer data is essential in large-scale
epidemiological studies that investigate the association between physical
activity and health outcomes. While the use of self-supervised learning has
generated considerable excitement in improving HAR, it remains unknown the
extent to which these models, coupled with hidden Markov models (HMMs), would
make a tangible improvement to classification performance, and the effect this
may have on the predicted daily activity intensity compositions. Using 151
CAPTURE-24 participants' data, we trained the ActiNet model, a self-supervised,
18-layer, modified ResNet-V2 model, followed by hidden Markov model (HMM)
smoothing to classify labels of activity intensity. The performance of this
model, evaluated using 5-fold stratified group cross-validation, was then
compared to a baseline random forest (RF) + HMM, established in existing
literature. Differences in performance and classification outputs were compared
with different subgroups of age and sex within the Capture-24 population. The
ActiNet model was able to distinguish labels of activity intensity with a mean
macro F1 score of 0.82, and mean Cohen's kappa score of 0.86. This exceeded the
performance of the RF + HMM, trained and validated on the same dataset, with
mean scores of 0.77 and 0.81, respectively. These findings were consistent
across subgroups of age and sex. These findings encourage the use of ActiNet
for the extraction of activity intensity labels from wrist-accelerometer data
in future epidemiological studies.

</details>


### [488] [Latency-aware Multimodal Federated Learning over UAV Networks](https://arxiv.org/abs/2510.01717)
*Shaba Shaon,Dinh C. Nguyen*

Main category: cs.LG

TL;DR: 本文提出了一种无人机辅助的联邦多模态学习（FML）框架，旨在最小化系统延迟并提供收敛性分析。该框架利用无人机收集数据、参与模型训练并与基站协作构建全局模型，通过多模态感知克服了单模态系统的局限性，提高了模型精度和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 无人机在网络中分布式部署，收集数据，参与模型训练，并与基站协同构建全局模型。利用多模态感知，无人机克服了单模态系统的局限性，提高了模型的准确性、泛化能力，并提供了对环境更全面的理解。本研究的主要目标是通过联合优化无人机的传感调度、功率控制、轨迹规划、资源分配以及基站的资源管理来优化UAV辅助的FML系统延迟。

Method: 为了解决延迟最小化问题的计算复杂性，提出了一种结合块坐标下降和连续凸近似的高效迭代优化算法，可以提供高质量的近似解。此外，还对非凸损失函数下的UAV辅助FML框架进行了理论收敛性分析。

Result: 数值实验表明，在不同的数据设置下，本文提出的FML框架在系统延迟和模型训练性能方面优于现有方法。

Conclusion: 无人机辅助的联邦多模态学习框架在最小化系统延迟和提高模型训练性能方面表现出色，并具有理论收敛性保证。

Abstract: This paper investigates federated multimodal learning (FML) assisted by
unmanned aerial vehicles (UAVs) with a focus on minimizing system latency and
providing convergence analysis. In this framework, UAVs are distributed
throughout the network to collect data, participate in model training, and
collaborate with a base station (BS) to build a global model. By utilizing
multimodal sensing, the UAVs overcome the limitations of unimodal systems,
enhancing model accuracy, generalization, and offering a more comprehensive
understanding of the environment. The primary objective is to optimize FML
system latency in UAV networks by jointly addressing UAV sensing scheduling,
power control, trajectory planning, resource allocation, and BS resource
management. To address the computational complexity of our latency minimization
problem, we propose an efficient iterative optimization algorithm combining
block coordinate descent and successive convex approximation techniques, which
provides high-quality approximate solutions. We also present a theoretical
convergence analysis for the UAV-assisted FML framework under a non-convex loss
function. Numerical experiments demonstrate that our FML framework outperforms
existing approaches in terms of system latency and model training performance
under different data settings.

</details>


### [489] [Accelerating Attention with Basis Decomposition](https://arxiv.org/abs/2510.01718)
*Jialin Zhao*

Main category: cs.LG

TL;DR: BD Attention (BDA) 是一种无损的注意力算法重构，通过矩阵恒等式将多头投影重塑为紧凑形式，实现数学保证的加速，且不依赖于特定硬件架构。


<details>
  <summary>Details</summary>
Motivation: Attention 是大型语言模型（LLMs）和视觉语言模型（VLMs）的核心操作，需要进行优化以提高效率。

Method: BDA 通过 Basis Decomposition (BD) 中的矩阵恒等式，将多头投影重塑为紧凑形式，实现注意力计算的无损重构。

Result: 在 DeepSeek-V2-Lite (16B, FP16) 模型上，BDA 仅需 4 秒的离线准备时间，即可在现代 GPU 上实现 32% 的键/值（key/value）投影加速和 25% 的权重减小，同时仅使端到端困惑度（PPL）增加了 0.02% (FP16) 或 0.0004% (FP32)，性能影响可忽略不计。

Conclusion: BDA 是首个理论上精确的无损注意力加速方法，可与现有的工程级优化互补。

Abstract: Attention is a core operation in large language models (LLMs) and
vision-language models (VLMs). We present BD Attention (BDA), the first
lossless algorithmic reformulation of attention. BDA is enabled by a simple
matrix identity from Basis Decomposition (BD), which restructures multi-head
projections into a compact form while preserving exact outputs. Unlike
I/O-aware system optimizations such as FlashAttention, BDA provides a
mathematically guaranteed acceleration that is architecture-agnostic. On
DeepSeek-V2-Lite (16B, FP16), BDA requires only 4s of offline preparation with
no retraining required and, on modern GPUs, achieves 32% faster key/value
projections and 25% smaller weights, while increasing end-to-end perplexity
(PPL) by just 0.02% (FP16) or 0.0004% (FP32), a negligible effect on model
performance. These results position BDA as the first theoretically exact method
for lossless attention acceleration that is complementary to existing
engineering-level optimizations. Our code is available at
https://github.com/abcbdf/basis-decomposition-official.

</details>


### [490] [Finite-Time Bounds for Distributionally Robust TD Learning with Linear Function Approximation](https://arxiv.org/abs/2510.01721)
*Saptarshi Mandal,Yashaswini Murthy,R. Srikant*

Main category: cs.LG

TL;DR: 该研究提出了首个具有线性函数逼近的鲁棒性TD学习算法，用于解决分布鲁棒强化学习（DRRL）中的模型不确定性问题，并提供了样本复杂度保证。


<details>
  <summary>Details</summary>
Motivation: 现有鲁棒性TD学习算法在表格MDP或特定贴现因子假设下存在局限性，本研究旨在弥合经验鲁棒RL与非鲁棒RL在非渐进保证方面的差距。

Method: 提出了一种结合双时间尺度随机逼近更新和外循环目标网络更新的鲁棒TD学习算法，并考虑了总变差距离和Wasserstein-l距离不确定性集。

Result: 该算法实现了模型无关且无需MDP生成访问，并建立了获得ε精度值估计的样本复杂度为Õ(1/ε^2)。

Conclusion: 该研究为DRRL中的鲁棒TD学习提供了首个具有线性函数逼近和非渐进样本复杂度保证的算法，并可扩展至鲁棒Q学习。

Abstract: Distributionally robust reinforcement learning (DRRL) focuses on designing
policies that achieve good performance under model uncertainties. In
particular, we are interested in maximizing the worst-case long-term discounted
reward, where the data for RL comes from a nominal model while the deployed
environment can deviate from the nominal model within a prescribed uncertainty
set. Existing convergence guarantees for robust temporal-difference (TD)
learning for policy evaluation are limited to tabular MDPs or are dependent on
restrictive discount-factor assumptions when function approximation is used. We
present the first robust TD learning with linear function approximation, where
robustness is measured with respect to the total-variation distance and
Wasserstein-l distance uncertainty set. Additionally, our algorithm is both
model-free and does not require generative access to the MDP. Our algorithm
combines a two-time-scale stochastic-approximation update with an outer-loop
target-network update. We establish an $\tilde{O}(1/\epsilon^2)$ sample
complexity to obtain an $\epsilon$-accurate value estimate. Our results close a
key gap between the empirical success of robust RL algorithms and the
non-asymptotic guarantees enjoyed by their non-robust counterparts. The key
ideas in the paper also extend in a relatively straightforward fashion to
robust Q-learning with function approximation.

</details>


### [491] [Workplace Location Choice Model based on Deep Neural Network](https://arxiv.org/abs/2510.01723)
*Tanay Rastogi,Anders Karlström*

Main category: cs.LG

TL;DR: 深度神经网络（DNN）在工作场所位置选择建模方面优于传统的离散选择模型（DCM），尤其是在处理复杂决策模式和长距离选择时，但DCM在模拟个体属性对短距离选择的影响方面表现更好。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统离散选择模型（DCM）在准确模拟个体决策过程方面的局限性，本研究旨在提出并评估一种基于深度神经网络（DNN）的新方法，以更有效地分析工作场所位置选择。

Method: 提出并应用一种深度神经网络（DNN）方法来模拟工作场所位置选择，并将其与传统的离散选择模型（DCM）进行比较分析。

Result: DNN在模拟工作场所位置选择方面展现出巨大潜力，并且在某些方面优于DCM。具体而言，DNN在处理复杂决策模式和长距离选择时表现出色，而DCM在评估个体属性对短距离选择的影响方面更具优势。

Conclusion: 深度神经网络（DNN）为工作场所位置选择分析提供了一个有前途的替代方案，但选择最适合特定应用的模型（DNN或DCM）取决于具体的分析需求，例如是侧重于复杂决策模式和长距离，还是个体属性对短距离的影响。

Abstract: Discrete choice models (DCMs) have long been used to analyze workplace
location decisions, but they face challenges in accurately mirroring individual
decision-making processes. This paper presents a deep neural network (DNN)
method for modeling workplace location choices, which aims to better understand
complex decision patterns and provides better results than traditional discrete
choice models (DCMs). The study demonstrates that DNNs show significant
potential as a robust alternative to DCMs in this domain. While both models
effectively replicate the impact of job opportunities on workplace location
choices, the DNN outperforms the DCM in certain aspects. However, the DCM
better aligns with data when assessing the influence of individual attributes
on workplace distance. Notably, DCMs excel at shorter distances, while DNNs
perform comparably to both data and DCMs for longer distances. These findings
underscore the importance of selecting the appropriate model based on specific
application requirements in workplace location choice analysis.

</details>


### [492] [Private and Fair Machine Learning: Revisiting the Disparate Impact of Differentially Private SGD](https://arxiv.org/abs/2510.01744)
*Lea Demelius,Dominik Kowald,Simone Kopeinik,Roman Kern,Andreas Trügler*

Main category: cs.LG

TL;DR: 差分隐私（DP）通过对模型性能指标产生不同程度的影响，可能导致模型不公平。本研究分析了直接在差分隐私模型上优化超参数对公平性的影响，发现虽然不能完全消除不公平性，但可以改善效用-公平性权衡。此外，研究还评估了DPSGD-Global-Adapt的有效性，并强调了在隐私、效用和公平性之间进行权衡的重要性。


<details>
  <summary>Details</summary>
Motivation: 差分隐私（DP）在保护个人信息方面发挥着重要作用，但它可能影响模型的学习动态、性能和公平性。现有研究表明，可以通过在差分隐私模型上直接优化超参数来提高公平性，但该研究的普遍性有待考证。

Method: 本研究通过以下两个方面来分析上述说法的普遍性：1）比较DPSGD对不同性能指标的差异性影响；2）在广泛的超参数设置下进行分析。

Result: 研究表明，对一个指标产生差异性影响并不一定意味着对另一个指标也产生差异性影响。通过直接在差分隐私模型上优化超参数，虽然不能保证完全消除DPSGD的差异性影响，但相比于使用非隐私模型的超参数，可以实现更好的效用-公平性权衡。然而，任何超参数调整都会增加隐私泄露的风险。此外，DPSGD-Global-Adapt的替代方案在面对超参数选择时可能不是一个稳健的解决方案。

Conclusion: 尽管在差分隐私模型上直接优化超参数可以改善效用-公平性权衡，但并不能完全消除DPSGD带来的不公平性。在隐私、效用和公平性之间进行权衡至关重要。DPSGD-Global-Adapt在缓解准确性方面的差异性影响方面可能不是一个可靠的解决方案。

Abstract: Differential privacy (DP) is a prominent method for protecting information
about individuals during data analysis. Training neural networks with
differentially private stochastic gradient descent (DPSGD) influences the
model's learning dynamics and, consequently, its output. This can affect the
model's performance and fairness. While the majority of studies on the topic
report a negative impact on fairness, it has recently been suggested that
fairness levels comparable to non-private models can be achieved by optimizing
hyperparameters for performance directly on differentially private models
(rather than re-using hyperparameters from non-private models, as is common
practice). In this work, we analyze the generalizability of this claim by 1)
comparing the disparate impact of DPSGD on different performance metrics, and
2) analyzing it over a wide range of hyperparameter settings. We highlight that
a disparate impact on one metric does not necessarily imply a disparate impact
on another. Most importantly, we show that while optimizing hyperparameters
directly on differentially private models does not mitigate the disparate
impact of DPSGD reliably, it can still lead to improved utility-fairness
trade-offs compared to re-using hyperparameters from non-private models. We
stress, however, that any form of hyperparameter tuning entails additional
privacy leakage, calling for careful considerations of how to balance privacy,
utility and fairness. Finally, we extend our analyses to DPSGD-Global-Adapt, a
variant of DPSGD designed to mitigate the disparate impact on accuracy, and
conclude that this alternative may not be a robust solution with respect to
hyperparameter choice.

</details>


### [493] [Unsupervised Dynamic Feature Selection for Robust Latent Spaces in Vision Tasks](https://arxiv.org/abs/2510.01758)
*Bruno Corcuera,Carlos Eiras-Franco,Brais Cancela*

Main category: cs.LG

TL;DR: 该研究提出了一种无监督的动态特征选择（DFS）方法，用于在计算机视觉任务中增强数据的潜在表征，通过移除误导性或冗余信息来提升模型性能和泛化能力，并且在不依赖标签的情况下，在聚类和图像生成任务上取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 在计算机视觉任务中，数据的潜在表征对于模型的性能和鲁棒性至关重要，但这些表征常常受到噪声或无关特征的干扰，从而影响模型的性能和泛化能力。

Method: 提出了一种无监督的动态特征选择（DFS）方法，为每个实例识别并移除图像中的误导性或冗余信息，确保只有最相关的特征被纳入潜在空间。该方法在无监督框架下运行，无需标签数据。

Result: 在图像数据集上的实验表明，采用无监督DFS方法增强潜在表征的模型，在聚类和图像生成等多种任务上，泛化性能得到了显著提升，同时计算成本仅有微小增加。

Conclusion: 无监督动态特征选择（DFS）能够有效增强计算机视觉任务中的潜在表征，通过去除无关信息来提升模型的泛化性能，且无需依赖标注数据，具有广泛的应用前景。

Abstract: Latent representations are critical for the performance and robustness of
machine learning models, as they encode the essential features of data in a
compact and informative manner. However, in vision tasks, these representations
are often affected by noisy or irrelevant features, which can degrade the
model's performance and generalization capabilities. This paper presents a
novel approach for enhancing latent representations using unsupervised Dynamic
Feature Selection (DFS). For each instance, the proposed method identifies and
removes misleading or redundant information in images, ensuring that only the
most relevant features contribute to the latent space. By leveraging an
unsupervised framework, our approach avoids reliance on labeled data, making it
broadly applicable across various domains and datasets. Experiments conducted
on image datasets demonstrate that models equipped with unsupervised DFS
achieve significant improvements in generalization performance across various
tasks, including clustering and image generation, while incurring a minimal
increase in the computational cost.

</details>


### [494] [Octax: Accelerated CHIP-8 Arcade Environments for Reinforcement Learning in JAX](https://arxiv.org/abs/2510.01764)
*Waris Radji,Thomas Michel,Hector Piteau*

Main category: cs.LG

TL;DR: Octax是一个基于JAX的高性能经典街机游戏环境套件，旨在解决传统RL研究中环境计算成本高、扩展性差的问题。它提供了GPU加速的图像化环境，实现了比传统CPU模拟器快几个数量级的性能，并支持大规模实验。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习（RL）研究需要多样化、具有挑战性且易于扩展的环境，但现代视频游戏计算成本高，不适合大规模实验。Octax旨在提供一个高性能、可扩展的RL环境替代方案。

Method: Octax使用JAX实现CHIP-8模拟，提供经典街机游戏的图像化环境，支持GPU加速，并允许通过大型语言模型生成新游戏。

Result: Octax实现了比传统CPU模拟器快几个数量级的速度，并保持了与原始游戏机制的完美保真度。通过在多个游戏上训练RL代理，证明了其在训练速度和可扩展性方面的优势。

Conclusion: Octax提供了一个理想的大规模RL实验平台，其高性能、GPU加速的特性解决了传统环境的瓶颈，并且其模块化设计易于扩展和定制。

Abstract: Reinforcement learning (RL) research requires diverse, challenging
environments that are both tractable and scalable. While modern video games may
offer rich dynamics, they are computationally expensive and poorly suited for
large-scale experimentation due to their CPU-bound execution. We introduce
Octax, a high-performance suite of classic arcade game environments implemented
in JAX, based on CHIP-8 emulation, a predecessor to Atari, which is widely
adopted as a benchmark in RL research. Octax provides the JAX community with a
long-awaited end-to-end GPU alternative to the Atari benchmark, offering
image-based environments, spanning puzzle, action, and strategy genres, all
executable at massive scale on modern GPUs. Our JAX-based implementation
achieves orders-of-magnitude speedups over traditional CPU emulators while
maintaining perfect fidelity to the original game mechanics. We demonstrate
Octax's capabilities by training RL agents across multiple games, showing
significant improvements in training speed and scalability compared to existing
solutions. The environment's modular design enables researchers to easily
extend the suite with new games or generate novel environments using large
language models, making it an ideal platform for large-scale RL
experimentation.

</details>


### [495] [Sensitivity, Specificity, and Consistency: A Tripartite Evaluation of Privacy Filters for Synthetic Data Generation](https://arxiv.org/abs/2510.01793)
*Adil Koeken,Alexander Ziller,Moritz Knolle,Daniel Rueckert*

Main category: cs.LG

TL;DR: 现有隐私过滤技术在胸部X光合成数据方面效果不佳，可能提供虚假安全感。


<details>
  <summary>Details</summary>
Motivation: 评估用于去除包含个人身份信息的样本的后验隐私过滤技术的有效性。

Method: 对应用于胸部X光合成的过滤流程进行严格评估。

Result: 结果表明，现有过滤器特异性和一致性有限，仅对真实图像具有高敏感性，而不能可靠地检测从训练数据生成的近乎重复的图像。

Conclusion: 在这些方法可用于敏感应用之前，过滤器的设计需要有实质性的改进。

Abstract: The generation of privacy-preserving synthetic datasets is a promising avenue
for overcoming data scarcity in medical AI research. Post-hoc privacy filtering
techniques, designed to remove samples containing personally identifiable
information, have recently been proposed as a solution. However, their
effectiveness remains largely unverified. This work presents a rigorous
evaluation of a filtering pipeline applied to chest X-ray synthesis. Contrary
to claims from the original publications, our results demonstrate that current
filters exhibit limited specificity and consistency, achieving high sensitivity
only for real images while failing to reliably detect near-duplicates generated
from training data. These results demonstrate a critical limitation of post-hoc
filtering: rather than effectively safeguarding patient privacy, these methods
may provide a false sense of security while leaving unacceptable levels of
patient information exposed. We conclude that substantial advances in filter
design are needed before these methods can be confidently deployed in sensitive
applications.

</details>


### [496] [Rethinking the shape convention of an MLP](https://arxiv.org/abs/2510.01796)
*Meng-Hsi Chen,Yu-Ang Lee,Feng-Ting Liao,Da-shan Shiu*

Main category: cs.LG

TL;DR: MLP设计新范式：Hourglass 结构在生成任务上优于传统MLP。


<details>
  <summary>Details</summary>
Motivation: 挑战传统MLP的窄-宽-窄设计，提出宽-窄-宽（Hourglass）MLP块，将跳跃连接置于扩展维度，残差计算通过狭窄瓶颈，旨在利用高维空间进行精炼，同时保持计算效率。

Method: 提出Hourglass MLP块，输入信号首先通过随机初始化的固定投影提升至扩展维度。在图像数据集上进行生成任务评估，并通过系统性架构搜索表征性能-参数的帕累托前沿。

Result: Hourglass 架构在性能-参数帕累托前沿上持续优于传统设计。随着参数预算增加，最优Hourglass结构倾向于更深的网络，具有更宽的跳跃连接和更窄的瓶颈，这与传统MLP的扩展模式不同。

Conclusion: 研究结果表明，应重新考虑跳跃连接在现代架构中的放置方式，Hourglass MLP在生成任务上表现出优越性，并可能应用于Transformers和其他残差网络。

Abstract: Multi-layer perceptrons (MLPs) conventionally follow a narrow-wide-narrow
design where skip connections operate at the input/output dimensions while
processing occurs in expanded hidden spaces. We challenge this convention by
proposing wide-narrow-wide (Hourglass) MLP blocks where skip connections
operate at expanded dimensions while residual computation flows through narrow
bottlenecks. This inversion leverages higher-dimensional spaces for incremental
refinement while maintaining computational efficiency through parameter-matched
designs. Implementing Hourglass MLPs requires an initial projection to lift
input signals to expanded dimensions. We propose that this projection can
remain fixed at random initialization throughout training, enabling efficient
training and inference implementations. We evaluate both architectures on
generative tasks over popular image datasets, characterizing
performance-parameter Pareto frontiers through systematic architectural search.
Results show that Hourglass architectures consistently achieve superior Pareto
frontiers compared to conventional designs. As parameter budgets increase,
optimal Hourglass configurations favor deeper networks with wider skip
connections and narrower bottlenecks-a scaling pattern distinct from
conventional MLPs. Our findings suggest reconsidering skip connection placement
in modern architectures, with potential applications extending to Transformers
and other residual networks.

</details>


### [497] [Sparse Query Attention (SQA): A Computationally Efficient Attention Mechanism with Query Heads Reduction](https://arxiv.org/abs/2510.01817)
*Adam Filipek*

Main category: cs.LG

TL;DR: Transformer中的多头注意力（MHA）存在二次计算复杂度问题，限制了其在长序列应用中的扩展性。虽然MQA和GQA通过共享Key和Value投影缓解了内存瓶颈，但并未减少计算注意力分数所需的计算量。本文提出的稀疏查询注意力（SQA）通过减少查询头的数量来降低计算复杂度，从而在计算密集型场景下（如模型预训练、微调和基于编码器的任务）实现高达3倍的吞吐量提升，且对模型质量影响甚微。


<details>
  <summary>Details</summary>
Motivation: Transformer架构的核心是多头注意力（MHA）机制，但其相对于序列长度的二次计算复杂度限制了模型在处理长序列时的扩展性。现有的解决方案（如MQA和GQA）主要解决了内存带宽瓶颈，但未能有效降低计算注意力分数所需的计算量，而这在训练和全序列处理中仍然是一个关键瓶颈。

Method: 本文提出了一种新颖的注意力架构——稀疏查询注意力（SQA）。与现有的方法不同，SQA通过减少查询头的数量来直接降低注意力机制的计算复杂度，而不是减少键头（Key/Value）的数量。这种方法直接以查询头数量的缩减比例来降低整体计算量（FLOPs）。

Result: 在长序列（32k-200k tokens）上的实证测试表明，SQA在计算密集型场景（如模型预训练、微调和基于编码器的任务）下，可以将吞吐量提高高达3倍。初步的小规模实验表明，这种性能提升仅对模型质量产生最小的影响。

Conclusion: SQA通过减少查询头的数量，为降低Transformer模型的计算复杂度提供了一条新的优化途径，有效解决了长序列处理中的计算瓶颈问题，并在计算密集型任务中实现了显著的吞吐量提升，同时保持了模型质量。SQA的发现具有重要意义，预示着其在构建更高效、可扩展模型方面的巨大潜力。

Abstract: The Transformer architecture, underpinned by the Multi-Head Attention (MHA)
mechanism, has become the de facto standard for state-of-the-art models in
artificial intelligence. However, the quadratic computational complexity of MHA
with respect to sequence length presents a significant barrier to scaling,
particularly for applications involving long contexts. Prevailing solutions,
such as Multi-Query Attention (MQA) and Grouped-Query Attention (GQA), have
effectively addressed the memory bandwidth bottleneck that dominates
autoregressive inference latency by sharing Key and Value projections. While
highly successful, these methods do not reduce the fundamental number of
floating-point operations (FLOPs) required for the attention score computation,
which remains a critical bottleneck for training and full-sequence processing.
This paper introduces Sparse Query Attention (SQA), a novel attention
architecture that pursues an alternative and complementary optimization path.
Instead of reducing Key/Value heads, SQA reduces the number of Query heads.
This architectural modification directly decreases the computational complexity
of the attention mechanism by a factor proportional to the reduction in query
heads, thereby lowering the overall FLOPs. This work presents the theoretical
foundation of SQA, its mathematical formulation, and a family of architectural
variants. Empirical benchmarks on long sequences (32k-200k tokens) demonstrate
that SQA can achieve significant throughput improvements of up to 3x in
computation-bound scenarios such as model pre-training, fine-tuning, and
encoder-based tasks, with only a minimal impact on model quality in preliminary
smallscale experiments. SQA was discovered serendipitously during the
development of the upcoming Reactive Transformer architecture, suggesting its
potential as a powerful tool for building more efficient and scalable models

</details>


### [498] [Black-Box Combinatorial Optimization with Order-Invariant Reinforcement Learning](https://arxiv.org/abs/2510.01824)
*Olivier Goudet,Quentin Suire,Adrien Goëffon,Frédéric Saubion,Sylvain Lamprier*

Main category: cs.LG

TL;DR: 提出了一种无需固定变量顺序即可训练的顺序不变强化学习框架，用于黑盒组合优化，并通过随机生成顺序提高了样本效率和多样性。


<details>
  <summary>Details</summary>
Motivation: 传统的估计分布算法（EDA）依赖于学习显式的变量依赖图，这可能成本高昂且难以有效捕捉复杂交互。

Method: 通过参数化多元自回归生成模型，在训练时采用随机生成顺序（一种信息保留的dropout形式），从而使模型对变量顺序不变，并采用广义强化策略优化（GRPO）进行策略梯度更新。

Result: 在各种基准算法和不同规模的问题实例上，该方法频繁 achieves 最佳性能，并一致地避免了灾难性故障。

Conclusion: 所提出的顺序不变强化学习框架在黑盒组合优化方面表现出优越的性能和鲁棒性。

Abstract: We introduce an order-invariant reinforcement learning framework for
black-box combinatorial optimization. Classical estimation-of-distribution
algorithms (EDAs) often rely on learning explicit variable dependency graphs,
which can be costly and fail to capture complex interactions efficiently. In
contrast, we parameterize a multivariate autoregressive generative model
trained without a fixed variable ordering. By sampling random generation orders
during training - a form of information-preserving dropout - the model is
encouraged to be invariant to variable order, promoting search-space diversity
and shaping the model to focus on the most relevant variable dependencies,
improving sample efficiency. We adapt Generalized Reinforcement Policy
Optimization (GRPO) to this setting, providing stable policy-gradient updates
from scale-invariant advantages. Across a wide range of benchmark algorithms
and problem instances of varying sizes, our method frequently achieves the best
performance and consistently avoids catastrophic failures.

</details>


### [499] [Pre-Hoc Predictions in AutoML: Leveraging LLMs to Enhance Model Selection and Benchmarking for Tabular datasets](https://arxiv.org/abs/2510.01842)
*Yannis Belkhiter,Seshu Tirupathi,Giulio Zizzo,Sachin Sharma,John D. Kelleher*

Main category: cs.LG

TL;DR: 通过结合传统模型和大型语言模型（LLM）代理，利用数据集描述和统计信息，减少了 AutoML 的搜索空间，从而在不牺牲模型选择性能的情况下降低了计算开销。


<details>
  <summary>Details</summary>
Motivation: AutoML 领域在事后模型选择方面取得了显著进展，但现有方法通常依赖于详尽的超参数搜索。预先预测作为一种有前景的替代方案，能够通过智能预选模型来规避详尽搜索，但其研究尚不充分。

Method: 利用传统模型和大型语言模型（LLM）代理，结合数据集描述和统计信息，来减少 AutoML 的搜索空间。

Result: 将所提出的方法应用于 AWS AutoGluon 组合数据集（包含 175 个 OpenML 上的表格分类数据集），结果表明该方法显著降低了计算开销，同时仍能选择出最佳模型。

Conclusion: 该方法为 AutoML 工作流程提供了一种新的思路，通过有效减少搜索空间，显著降低了计算成本，同时保持了模型的选择性能。

Abstract: The field of AutoML has made remarkable progress in post-hoc model selection,
with libraries capable of automatically identifying the most performing models
for a given dataset. Nevertheless, these methods often rely on exhaustive
hyperparameter searches, where methods automatically train and test different
types of models on the target dataset. Contrastingly, pre-hoc prediction
emerges as a promising alternative, capable of bypassing exhaustive search
through intelligent pre-selection of models. Despite its potential, pre-hoc
prediction remains under-explored in the literature. This paper explores the
intersection of AutoML and pre-hoc model selection by leveraging traditional
models and Large Language Model (LLM) agents to reduce the search space of
AutoML libraries. By relying on dataset descriptions and statistical
information, we reduce the AutoML search space. Our methodology is applied to
the AWS AutoGluon portfolio dataset, a state-of-the-art AutoML benchmark
containing 175 tabular classification datasets available on OpenML. The
proposed approach offers a shift in AutoML workflows, significantly reducing
computational overhead, while still selecting the best model for the given
dataset.

</details>


### [500] [$\text{G}^2$RPO: Granular GRPO for Precise Reward in Flow Models](https://arxiv.org/abs/2510.01982)
*Yujie Zhou,Pengyang Ling,Jiazi Bu,Yibin Wang,Yuhang Zang,Jiaqi Wang,Li Niu,Guangtao Zhai*

Main category: cs.LG

TL;DR: G^2RPO框架通过引入新颖的奇异随机采样策略和多粒度优势集成模块，改进了基于强化学习的流模型，实现了更精确和全面的奖励评估，从而提高了人类偏好的对齐效果，并在各种评估中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的流模型在对齐人类偏好方面存在奖励信号稀疏和狭窄的问题，导致偏好对齐效果不佳。

Method: 提出了一种名为Granular-GRPO (G^2RPO) 的新框架，该框架包含两个关键组件：1. 奇异随机采样（Singular Stochastic Sampling）策略，用于逐步随机探索，并强制奖励与注入噪声高度相关，以实现对每个SDE扰动的忠实奖励。 2. 多粒度优势集成（Multi-Granularity Advantage Integration）模块，用于聚合多个扩散尺度下的优势，以消除固定粒度去噪带来的偏差，从而提供更全面、鲁棒的采样方向评估。

Result: G^2RPO在各种奖励模型（包括领域内和领域外评估）上进行了实验，结果表明G^2RPO显著优于现有的基于流模型的GRPO基线。

Conclusion: G^2RPO框架通过其新颖的采样和优势集成策略，有效地解决了现有方法在人类偏好对齐方面的局限性，实现了更精确、全面和鲁棒的奖励评估，并在实验中表现出优越的性能。

Abstract: The integration of online reinforcement learning (RL) into diffusion and flow
models has recently emerged as a promising approach for aligning generative
models with human preferences. Stochastic sampling via Stochastic Differential
Equations (SDE) is employed during the denoising process to generate diverse
denoising directions for RL exploration. While existing methods effectively
explore potential high-value samples, they suffer from sub-optimal preference
alignment due to sparse and narrow reward signals. To address these challenges,
we propose a novel Granular-GRPO ($\text{G}^2$RPO ) framework that achieves
precise and comprehensive reward assessments of sampling directions in
reinforcement learning of flow models. Specifically, a Singular Stochastic
Sampling strategy is introduced to support step-wise stochastic exploration
while enforcing a high correlation between the reward and the injected noise,
thereby facilitating a faithful reward for each SDE perturbation. Concurrently,
to eliminate the bias inherent in fixed-granularity denoising, we introduce a
Multi-Granularity Advantage Integration module that aggregates advantages
computed at multiple diffusion scales, producing a more comprehensive and
robust evaluation of the sampling directions. Experiments conducted on various
reward models, including both in-domain and out-of-domain evaluations,
demonstrate that our $\text{G}^2$RPO significantly outperforms existing
flow-based GRPO baselines,highlighting its effectiveness and robustness.

</details>


### [501] [Explicit Discovery of Nonlinear Symmetries from Dynamic Data](https://arxiv.org/abs/2510.01855)
*Lexiang Hu,Yikang Li,Zhouchen Lin*

Main category: cs.LG

TL;DR: LieNLSD是第一个能够确定非线性项的无穷小生成器的数量及其显式表达式的方法。


<details>
  <summary>Details</summary>
Motivation: 发现复杂场景中的对称性，特别是线性对称性，而之前的非线性对称性发现方法未能显式获得李代数子空间。

Method: 通过指定无穷小群作用的函数库，求解其系数矩阵，并证明其微分方程的延拓公式对于系数矩阵是线性的。将数据的中心差分和训练好的神经网络的雅可比矩阵代入无穷小判据，得到系数矩阵的线性方程组，然后使用SVD求解。

Result: 在顶夸克标记和一系列动态系统上，LieNLSD显示出优于现有方法的质量优势，并将神经PDE求解器的长期滚动精度提高了20%以上，同时还用于指导数据增强。

Conclusion: LieNLSD是发现非线性对称性的有效方法，在提高神经PDE求解器精度和指导数据增强方面具有优势。

Abstract: Symmetry is widely applied in problems such as the design of equivariant
networks and the discovery of governing equations, but in complex scenarios, it
is not known in advance. Most previous symmetry discovery methods are limited
to linear symmetries, and recent attempts to discover nonlinear symmetries fail
to explicitly get the Lie algebra subspace. In this paper, we propose LieNLSD,
which is, to our knowledge, the first method capable of determining the number
of infinitesimal generators with nonlinear terms and their explicit
expressions. We specify a function library for the infinitesimal group action
and aim to solve for its coefficient matrix, proving that its prolongation
formula for differential equations, which governs dynamic data, is also linear
with respect to the coefficient matrix. By substituting the central differences
of the data and the Jacobian matrix of the trained neural network into the
infinitesimal criterion, we get a system of linear equations for the
coefficient matrix, which can then be solved using SVD. On top quark tagging
and a series of dynamic systems, LieNLSD shows qualitative advantages over
existing methods and improves the long rollout accuracy of neural PDE solvers
by over 20% while applying to guide data augmentation. Code and data are
available at https://github.com/hulx2002/LieNLSD.

</details>


### [502] [Compositional meta-learning through probabilistic task inference](https://arxiv.org/abs/2510.01858)
*Jacob J. W. Bakermans,Pablo Tano,Reidar Riveland,Charles Findling,Alexandre Pouget*

Main category: cs.LG

TL;DR: 本文提出了一种组合式元学习模型，通过学习可重用计算的生成模型，将新任务的学习转化为概率推理问题，从而实现从少量经验中快速解决新任务。


<details>
  <summary>Details</summary>
Motivation: 为了从极少的经验中解决新任务，需要有效重用先前任务中的知识，即元学习问题。组合式解决方案（将常见的计算元素灵活重组为新配置）特别适合元学习。

Method: 提出了一种组合式元学习模型，该模型将任务显式地表示为可重用计算的结构化组合。通过学习捕获跨任务家族共享的底层组件及其统计数据的生成模型来实现。这种方法将学习新任务转化为一个概率推理问题，无需通过高度约束的假设检验进行参数更新即可找到解决方案。

Result: 该模型成功地在规则学习和运动学习任务中恢复了真实的组件和统计数据，并展示了仅从单个示例中快速推断新解决方案的能力。

Conclusion: 该框架结合了神经网络的表达能力和概率推理的数据效率，实现了快速的组合式元学习。

Abstract: To solve a new task from minimal experience, it is essential to effectively
reuse knowledge from previous tasks, a problem known as meta-learning.
Compositional solutions, where common elements of computation are flexibly
recombined into new configurations, are particularly well-suited for
meta-learning. Here, we propose a compositional meta-learning model that
explicitly represents tasks as structured combinations of reusable
computations. We achieve this by learning a generative model that captures the
underlying components and their statistics shared across a family of tasks.
This approach transforms learning a new task into a probabilistic inference
problem, which allows for finding solutions without parameter updates through
highly constrained hypothesis testing. Our model successfully recovers ground
truth components and statistics in rule learning and motor learning tasks. We
then demonstrate its ability to quickly infer new solutions from just single
examples. Together, our framework joins the expressivity of neural networks
with the data-efficiency of probabilistic inference to achieve rapid
compositional meta-learning.

</details>


### [503] [Universal Dynamic Regret and Constraint Violation Bounds for Constrained Online Convex Optimization](https://arxiv.org/abs/2510.01867)
*Subhamon Supantha,Abhishek Sinha*

Main category: cs.LG

TL;DR: 本论文提出了一种解决带在线对抗约束的在线凸优化问题的方法，并给出了两种具有简单模块化结构的算法，它们在动态无悔和累积约束违反方面都取得了通用界限，优于现有技术水平。


<details>
  <summary>Details</summary>
Motivation: 研究带在线对抗约束的在线凸优化（OCO）框架的推广，以应对更普遍的在线学习场景。

Method: 通过将受约束的学习问题归约到具有特殊构造的代理成本函数的标准OCO问题来解决。

Result: 提出的两种算法在最一般的情况下（成本和约束函数均由对手任意选择，且约束函数不必包含共同的可行点）均实现了通用的动态无悔和累积约束违反界限。

Conclusion: 该方法通过将约束学习问题转化为标准OCO问题，成功地解决了带在线对抗约束的OCO问题，并取得了改进的性能界限。

Abstract: We consider a generalization of the celebrated Online Convex Optimization
(OCO) framework with online adversarial constraints. We present two algorithms
having simple modular structures that yield universal dynamic regret and
cumulative constraint violation bounds, improving upon the state-of-the-art
results. Our results hold in the most general case when both the cost and
constraint functions are chosen arbitrarily by an adversary, and the constraint
functions need not contain any common feasible point. The results are
established by reducing the constrained learning problem to an instance of the
standard OCO problem with specially constructed surrogate cost functions.

</details>


### [504] [Randomized Gradient Subspaces for Efficient Large Language Model Training](https://arxiv.org/abs/2510.01878)
*Sahar Rajabi,Nayeema Nonta,Samanvay Vajpayee,Sirisha Rambhatla*

Main category: cs.LG

TL;DR: 梯度下降的内存瓶颈可以通过将梯度投影到低维子空间来缓解，但现有方法未能充分利用所有梯度信息。


<details>
  <summary>Details</summary>
Motivation: LLM训练受限于内存，优化器状态占主导地位。需要更有效的梯度压缩方法。

Method: 分析梯度空间及其子空间动态，识别核心子空间和残差部分。提出利用子空间信息的随机算法GrassWalk和GrassJump。

Result: GrassWalk和GrassJump在LLaMA-1B和LLaMA-7B预训练中实现了最先进的内存节省，并提高了性能。

Conclusion: 梯度空间包含重要信息，但其影响随时间和层数而变化。提出的随机算法能有效利用子空间信息，克服内存限制，并提升模型性能。

Abstract: Training large language models (LLMs) is often bottlenecked by extreme memory
demands, with optimizer states dominating the footprint. Recent works mitigates
this cost by projecting gradients into low-dimensional subspaces using
sophisticated update strategies. In this paper, we analyze the dynamics of
gradient space and its underlying subspaces. We find that while a small
subspace captures most gradient energy, a significant portion still resides in
the residual bulk; moreover, the influence of the core subspace diminishes over
time and in deeper layers. We also observe that the gradient space exhibits
near-flat curvature, calling for algorithms that explicitly account for this
geometry. Motivated by these insights, we introduce a suite of randomized
algorithms, GrassWalk and GrassJump, which exploit subspace and achieve
state-of-the-art memory savings while improving performance on LLaMA-1B and
LLaMA-7B pretraining.

</details>


### [505] [Multi-marginal temporal Schrödinger Bridge Matching for video generation from unpaired data](https://arxiv.org/abs/2510.01894)
*Thomas Gravier,Thomas Boyer,Auguste Genovesio*

Main category: cs.LG

TL;DR: MMtSBM 提出了一种新的方法，可以从不成对的数据中生成视频，以重建隐藏的动态过程。


<details>
  <summary>Details</summary>
Motivation: 许多自然动态过程（例如体内的细胞分化或疾病进展）只能通过静态样本快照来观察。重建其时间演变以破译潜在的动态特性对于科学研究具有重要意义。现有方法在处理高维数据时扩展性差，并需要满足严格的假设。

Method: 提出了一种名为“多边际时间薛定谔桥匹配”（MMtSBM）的新方法，该方法通过以新颖的因子化方式将迭代马尔可夫拟合算法推导到多个边际，从而扩展了扩散薛定谔桥匹配的理论保证和经验效率。

Result: 实验表明，MMtSBM 在玩具示例上保留了理论性质，在真实世界数据集（例如 100 维的转录组轨迹推断）上实现了最先进的性能，并且首次在非常高维的图像环境中恢复了耦合和动力学。

Conclusion: MMtSBM 将多边际薛定谔桥确立为一种实用且有原则的方法，用于从静态数据中恢复隐藏的动力学。

Abstract: Many natural dynamic processes -- such as in vivo cellular differentiation or
disease progression -- can only be observed through the lens of static sample
snapshots. While challenging, reconstructing their temporal evolution to
decipher underlying dynamic properties is of major interest to scientific
research. Existing approaches enable data transport along a temporal axis but
are poorly scalable in high dimension and require restrictive assumptions to be
met. To address these issues, we propose \textit{\textbf{Multi-Marginal
temporal Schr\"odinger Bridge Matching}} (\textbf{MMtSBM}) \textit{for video
generation from unpaired data}, extending the theoretical guarantees and
empirical efficiency of Diffusion Schr\"odinger Bridge Matching
(arXiv:archive/2303.16852) by deriving the Iterative Markovian Fitting
algorithm to multiple marginals in a novel factorized fashion. Experiments show
that MMtSBM retains theoretical properties on toy examples, achieves
state-of-the-art performance on real world datasets such as transcriptomic
trajectory inference in 100 dimensions, and for the first time recovers
couplings and dynamics in very high dimensional image settings. Our work
establishes multi-marginal Schr\"odinger bridges as a practical and principled
approach for recovering hidden dynamics from static data.

</details>


### [506] [Multimodal Foundation Models for Early Disease Detection](https://arxiv.org/abs/2510.01899)
*Md Talha Mohsin,Ismail Abdulrashid*

Main category: cs.LG

TL;DR: 该研究提出了一个多模态基础模型，用于整合电子健康记录、医学影像、遗传学和可穿戴设备数据，以克服传统模型在早期疾病诊断中识别跨模态关联的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统医疗诊断模型孤立地分析不同来源的数据，限制了其识别对早期疾病诊断至关重要的跨模态关联的能力。

Method: 研究提出了一个多模态基础模型，该模型使用基于注意力的Transformer框架整合不同类型的患者数据。首先，为每个数据模态设计了专门的编码器，将它们映射到一个共享的潜在空间。然后，利用多头注意力和残差归一化来整合这些信息。该模型架构支持在多种任务上进行预训练，便于在新疾病和数据集上进行微调。

Result: 研究在肿瘤学、心脏病学和神经病学领域的基准数据集上进行了实验，评估了早期检测任务的性能。模型在提高预测准确性和辅助医生决策方面展现了潜力。

Conclusion: 该研究旨在开发一个单一的基础模型，用于精准诊断，该模型能够整合多种数据源，提高诊断的准确性和效率，并为临床决策提供支持。模型还包含了数据治理和模型管理工具，以增强透明度、可靠性和临床可解释性。

Abstract: Healthcare generates diverse streams of data, including electronic health
records (EHR), medical imaging, genetics, and ongoing monitoring from wearable
devices. Traditional diagnostic models frequently analyze these sources in
isolation, which constrains their capacity to identify cross-modal correlations
essential for early disease diagnosis. Our research presents a multimodal
foundation model that consolidates diverse patient data through an
attention-based transformer framework. At first, dedicated encoders put each
modality into a shared latent space. Then, they combine them using multi-head
attention and residual normalization. The architecture is made for pretraining
on many tasks, which makes it easy to adapt to new diseases and datasets with
little extra work. We provide an experimental strategy that uses benchmark
datasets in oncology, cardiology, and neurology, with the goal of testing early
detection tasks. The framework includes data governance and model management
tools in addition to technological performance to improve transparency,
reliability, and clinical interpretability. The suggested method works toward a
single foundation model for precision diagnostics, which could improve the
accuracy of predictions and help doctors make decisions.

</details>


### [507] [Test-Time Anchoring for Discrete Diffusion Posterior Sampling](https://arxiv.org/abs/2510.02291)
*Litu Rout,Andreas Lugmayr,Yasamin Jafarian,Srivatsan Varadharajan,Constantine Caramanis,Sanjay Shakkottai,Ira Kemelmacher-Shlizerman*

Main category: cs.LG

TL;DR: 该研究提出了一种名为 Anchored Posterior Sampling (APS) 的新方法，用于从噪声测量中恢复图像，特别适用于基于预训练的离散扩散基础模型。


<details>
  <summary>Details</summary>
Motivation: 现有离散扩散模型在后验采样方面存在挑战，例如衍生品免费指导信号稀疏、连续松弛限制应用以及分裂吉布斯采样器面临维度灾难。

Method: APS 引入了量化期望（Anchored Posterior Sampling）以实现梯度类指导，并结合了锚定重遮蔽（anchored remasking）以实现自适应解码。

Result: APS 在标准基准的线性和非线性逆问题上取得了最先进的性能，并且在无训练风格化和文本引导编辑方面也显示出优势。

Conclusion: APS 克服了现有离散扩散后验采样方法的局限性，为处理离散数据（如文本和图像）的逆问题提供了一种更有效的方法。

Abstract: We study the problem of posterior sampling using pretrained discrete
diffusion foundation models, aiming to recover images from noisy measurements
without retraining task-specific models. While diffusion models have achieved
remarkable success in generative modeling, most advances rely on continuous
Gaussian diffusion. In contrast, discrete diffusion offers a unified framework
for jointly modeling categorical data such as text and images. Beyond
unification, discrete diffusion provides faster inference, finer control, and
principled training-free Bayesian inference, making it particularly well-suited
for posterior sampling. However, existing approaches to discrete diffusion
posterior sampling face severe challenges: derivative-free guidance yields
sparse signals, continuous relaxations limit applicability, and split Gibbs
samplers suffer from the curse of dimensionality. To overcome these
limitations, we introduce Anchored Posterior Sampling (APS) for masked
diffusion foundation models, built on two key innovations -- quantized
expectation for gradient-like guidance in discrete embedding space, and
anchored remasking for adaptive decoding. Our approach achieves
state-of-the-art performance among discrete diffusion samplers across linear
and nonlinear inverse problems on the standard benchmarks. We further
demonstrate the benefits of our approach in training-free stylization and
text-guided editing.

</details>


### [508] [A Methodology for Transparent Logic-Based Classification Using a Multi-Task Convolutional Tsetlin Machine](https://arxiv.org/abs/2510.01906)
*Mayur Kishor Shende,Ole-Christoffer Granmo,Runar Helin,Vladimir I. Zadorozhny,Rishad Shafik*

Main category: cs.LG

TL;DR: Tsetlin Machine (TM) 在大规模多通道图像分类中表现出与深度学习模型相媲美的性能，同时保持了其可解释性，并提出了一种生成局部解释和全局类别表示的方法。


<details>
  <summary>Details</summary>
Motivation: 探讨 TM 架构在处理大规模多通道（RGB）图像分类任务中的适用性，并提出生成模型解释的方法。

Method: 提出一种生成局部解释和全局类别表示的方法，用于解释模型预测和聚合各类别的重要模式。

Result: 在 MNIST 数据集上达到 98.5% 的准确率，在 CelebA 数据集上达到 86.56% 的 F1 分数，表现与 ResNet50 相当。

Conclusion: TM 在大规模复杂训练环境中具有竞争力，并且保持了其可解释性，有助于理解 TM 子句以及其在更复杂数据集上的应用。

Abstract: The Tsetlin Machine (TM) is a novel machine learning paradigm that employs
finite-state automata for learning and utilizes propositional logic to
represent patterns. Due to its simplistic approach, TMs are inherently more
interpretable than learning algorithms based on Neural Networks. The
Convolutional TM has shown comparable performance on various datasets such as
MNIST, K-MNIST, F-MNIST and CIFAR-2. In this paper, we explore the
applicability of the TM architecture for large-scale multi-channel (RGB) image
classification. We propose a methodology to generate both local interpretations
and global class representations. The local interpretations can be used to
explain the model predictions while the global class representations aggregate
important patterns for each class. These interpretations summarize the
knowledge captured by the convolutional clauses, which can be visualized as
images. We evaluate our methods on MNIST and CelebA datasets, using models that
achieve 98.5\% accuracy on MNIST and 86.56\% F1-score on CelebA (compared to
88.07\% for ResNet50) respectively. We show that the TM performs competitively
to this deep learning model while maintaining its interpretability, even in
large-scale complex training environments. This contributes to a better
understanding of TM clauses and provides insights into how these models can be
applied to more complex and diverse datasets.

</details>


### [509] [Are LLMs Better GNN Helpers? Rethinking Robust Graph Learning under Deficiencies with Iterative Refinement](https://arxiv.org/abs/2510.01910)
*Zhaoyan Wang,Zheng Gao,Arogya Kharel,In-Young Ko*

Main category: cs.LG

TL;DR: 本研究首次系统性地评估了图神经网络（GNNs）和大型语言模型（LLMs）在处理包含多种缺陷的真实世界图数据时的表现，并提出了一种新的迭代式增强框架RoGRAD。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对GNN和LLM在处理包含多种缺陷的图数据时的系统性理解，也未对这两类方法进行全面比较，导致其优劣势不明。

Method: 通过实证研究，对比了传统GNN方法和基于LLM的方法在处理多种图缺陷时的表现。在此基础上，提出了RoGRAD框架，该框架采用迭代方式，利用检索增强生成（RAG）技术，通过提供类别一致且多样化的增强数据，并结合图对比学习进行迭代优化，实现动态的、精炼式的LLM增强。

Result: RoGRAD框架在处理包含多种缺陷的图数据时，相比传统的GNN和基于LLM的增强方法，取得了显著的性能提升，平均提升率高达82.43%。

Conclusion: RoGRAD框架通过其迭代式的、检索增强的对比学习方法，克服了传统一次性LLM增强的局限性，为图学习提供了更优越的鲁棒性和性能。

Abstract: Graph Neural Networks (GNNs) are widely adopted in Web-related applications,
serving as a core technique for learning from graph-structured data, such as
text-attributed graphs. Yet in real-world scenarios, such graphs exhibit
deficiencies that substantially undermine GNN performance. While prior
GNN-based augmentation studies have explored robustness against individual
imperfections, a systematic understanding of how graph-native and Large
Language Models (LLMs) enhanced methods behave under compound deficiencies is
still missing. Specifically, there has been no comprehensive investigation
comparing conventional approaches and recent LLM-on-graph frameworks, leaving
their merits unclear. To fill this gap, we conduct the first empirical study
that benchmarks these two lines of methods across diverse graph deficiencies,
revealing overlooked vulnerabilities and challenging the assumption that LLM
augmentation is consistently superior. Building on empirical findings, we
propose Robust Graph Learning via Retrieval-Augmented Contrastive Refinement
(RoGRAD) framework. Unlike prior one-shot LLM-as-Enhancer designs, RoGRAD is
the first iterative paradigm that leverages Retrieval-Augmented Generation
(RAG) to inject retrieval-grounded augmentations by supplying class-consistent,
diverse augmentations and enforcing discriminative representations through
iterative graph contrastive learning. It transforms LLM augmentation for graphs
from static signal injection into dynamic refinement. Extensive experiments
demonstrate RoGRAD's superiority over both conventional GNN- and LLM-enhanced
baselines, achieving up to 82.43% average improvement.

</details>


### [510] [Continual Personalization for Diffusion Models](https://arxiv.org/abs/2510.02296)
*Yu-Chien Liao,Jr-Jen Chen,Chi-Pin Huang,Ci-Siang Lin,Meng-Lin Wu,Yu-Chiang Frank Wang*

Main category: cs.LG

TL;DR: CNS通过增量学习选择性微调概念神经元，以在持续学习中实现个性化，有效解决了灾难性遗忘问题，并保持了零样本文本到图像生成能力。


<details>
  <summary>Details</summary>
Motivation: 在增量设置中更新扩散模型具有实际应用价值，但计算成本高昂。需要一种能解决灾难性遗忘并保留零样本生成能力的方法。

Method: 提出了一种名为概念神经元选择（CNS）的新颖学习策略，该策略能够识别并选择性地微调与目标概念相关的神经元，同时保留先前概念的知识，以实现持续学习。

Result: CNS在真实世界数据集上实现了最先进的性能，在单概念和多概念个性化方面均优于先前方法，且参数调整最小。

Conclusion: CNS是一种有效且计算成本低的持续学习个性化方法，它通过选择性地微调概念神经元来解决灾难性遗忘问题，同时保持了扩散模型的零样本生成能力，并且无需融合即可实现持续个性化。

Abstract: Updating diffusion models in an incremental setting would be practical in
real-world applications yet computationally challenging. We present a novel
learning strategy of Concept Neuron Selection (CNS), a simple yet effective
approach to perform personalization in a continual learning scheme. CNS
uniquely identifies neurons in diffusion models that are closely related to the
target concepts. In order to mitigate catastrophic forgetting problems while
preserving zero-shot text-to-image generation ability, CNS finetunes concept
neurons in an incremental manner and jointly preserves knowledge learned of
previous concepts. Evaluation of real-world datasets demonstrates that CNS
achieves state-of-the-art performance with minimal parameter adjustments,
outperforming previous methods in both single and multi-concept personalization
works. CNS also achieves fusion-free operation, reducing memory storage and
processing time for continual personalization.

</details>


### [511] [StelLA: Subspace Learning in Low-rank Adaptation using Stiefel Manifold](https://arxiv.org/abs/2510.01938)
*Zhizhong Li,Sina Sajadmanesh,Jingtao Li,Lingjuan Lyu*

Main category: cs.LG

TL;DR: LoRA在参数高效的预训练模型微调中得到广泛应用，但其性能仍落后于完全微调。本文提出了一种几何感知LoRA扩展，通过三因子分解USVᵀ，并将U和V约束在Stiefel流形上，以确保训练过程中的正交性。该方法采用灵活的几何优化设计，可将任何欧几里得优化器转换为黎曼优化器，从而实现高效的子空间学习，并兼容现有微调流程。实验结果表明，该方法在多项下游任务中优于现有的LoRA变体。


<details>
  <summary>Details</summary>
Motivation: LoRA虽然广泛应用，但在性能上仍不及完全微调，部分原因是其未能充分利用低秩流形下的几何结构。

Method: 提出一种几何感知的LoRA扩展，使用三因子分解USVᵀ，并将U和V约束在Stiefel流形上，通过几何优化设计将欧几里得优化器转换为黎曼优化器。

Result: 在常识推理、数学和代码生成、图像分类和图像生成等下游任务中，实验结果均优于现有的LoRA变体。

Conclusion: 所提出的几何感知LoRA扩展通过利用低秩流形的几何结构，在保持参数高效的同时，能够达到比现有LoRA变体更优越的性能。

Abstract: Low-rank adaptation (LoRA) has been widely adopted as a parameter-efficient
technique for fine-tuning large-scale pre-trained models. However, it still
lags behind full fine-tuning in performance, partly due to its insufficient
exploitation of the geometric structure underlying low-rank manifolds. In this
paper, we propose a geometry-aware extension of LoRA that uses a three-factor
decomposition $U\!SV^\top$. Analogous to the structure of singular value
decomposition (SVD), it separates the adapter's input and output subspaces, $V$
and $U$, from the scaling factor $S$. Our method constrains $U$ and $V$ to lie
on the Stiefel manifold, ensuring their orthonormality throughout the training.
To optimize on the Stiefel manifold, we employ a flexible and modular geometric
optimization design that converts any Euclidean optimizer to a Riemannian one.
It enables efficient subspace learning while remaining compatible with existing
fine-tuning pipelines. Empirical results across a wide range of downstream
tasks, including commonsense reasoning, math and code generation, image
classification, and image generation, demonstrate the superior performance of
our approach against the recent state-of-the-art variants of LoRA. Code is
available at https://github.com/SonyResearch/stella.

</details>


### [512] [Equilibrium Matching: Generative Modeling with Implicit Energy-Based Models](https://arxiv.org/abs/2510.02300)
*Runqian Wang,Yilun Du*

Main category: cs.LG

TL;DR: Equilibrium Matching (EqM) is a new generative model that learns an energy landscape's gradient, enabling optimization-based sampling and outperforming diffusion/flow models on tasks like image generation and denoising.


<details>
  <summary>Details</summary>
Motivation: Traditional diffusion and flow-based generative models rely on non-equilibrium, time-conditional dynamics. This paper introduces Equilibrium Matching (EqM) as an alternative framework built from an equilibrium dynamics perspective, which learns the equilibrium gradient of an implicit energy landscape.

Method: EqM learns the equilibrium gradient of an implicit energy landscape, allowing for an optimization-based sampling process at inference time. Samples are generated using gradient descent on the learned landscape with adjustable parameters such as step sizes, optimizers, and compute.

Result: EqM achieves state-of-the-art generation performance, with an FID of 1.90 on ImageNet 256x256, surpassing existing diffusion and flow models. It is also theoretically justified to learn and sample from the data manifold and demonstrates flexibility in handling tasks like image denoising, OOD detection, and image composition.

Conclusion: EqM offers a novel approach to generative modeling by leveraging equilibrium dynamics and an optimization-based sampling process. It provides improved performance, theoretical justification, and broader applicability beyond image generation, bridging flow and energy-based models with a simpler inference route.

Abstract: We introduce Equilibrium Matching (EqM), a generative modeling framework
built from an equilibrium dynamics perspective. EqM discards the
non-equilibrium, time-conditional dynamics in traditional diffusion and
flow-based generative models and instead learns the equilibrium gradient of an
implicit energy landscape. Through this approach, we can adopt an
optimization-based sampling process at inference time, where samples are
obtained by gradient descent on the learned landscape with adjustable step
sizes, adaptive optimizers, and adaptive compute. EqM surpasses the generation
performance of diffusion/flow models empirically, achieving an FID of 1.90 on
ImageNet 256$\times$256. EqM is also theoretically justified to learn and
sample from the data manifold. Beyond generation, EqM is a flexible framework
that naturally handles tasks including partially noised image denoising, OOD
detection, and image composition. By replacing time-conditional velocities with
a unified equilibrium landscape, EqM offers a tighter bridge between flow and
energy-based models and a simple route to optimization-driven inference.

</details>


### [513] [Lower Bounds on Adversarial Robustness for Multiclass Classification with General Loss Functions](https://arxiv.org/abs/2510.01969)
*Camilo Andrés García Trillos,Nicolás García Trillos*

Main category: cs.LG

TL;DR: 该研究提出了多分类对抗鲁棒分类的新方法，并提供了对各种损失函数的通用解决方案，计算了对抗风险的下界，并设计了鲁棒分类器。


<details>
  <summary>Details</summary>
Motivation: 解决多分类对抗鲁棒分类问题，并为包括交叉熵损失、幂形式损失和二次损失在内的各种损失函数提供解决方案，超越了现有的仅限于0-1损失的结果。

Method: 推导了相应的学习者无关鲁棒风险最小化问题的对偶和重心重构，并明确表征了交叉熵损失、幂形式损失和二次损失等重要情况。

Result: 实现了对抗风险的有效计算和其下界的计算，并设计了超越0-1损失设置的鲁棒分类器。此外，研究还揭示了对抗鲁棒性、α-公平打包问题和具有KL和Tsallis散度作为惩罚的广义重心问题之间的联系。数值实验表明，在交叉熵损失函数下，得到的对抗风险下界更精确。

Conclusion: 通过对偶和重心重构，为多分类对抗鲁棒分类提供了一个通用框架，有效计算了对抗风险的下界，并为超越0-1损失设置的鲁棒分类器的设计铺平了道路。

Abstract: We consider adversarially robust classification in a multiclass setting under
arbitrary loss functions and derive dual and barycentric reformulations of the
corresponding learner-agnostic robust risk minimization problem. We provide
explicit characterizations for important cases such as the cross-entropy loss,
loss functions with a power form, and the quadratic loss, extending in this way
available results for the 0-1 loss. These reformulations enable efficient
computation of sharp lower bounds for adversarial risks and facilitate the
design of robust classifiers beyond the 0-1 loss setting. Our paper uncovers
interesting connections between adversarial robustness, $\alpha$-fair packing
problems, and generalized barycenter problems for arbitrary positive measures
where Kullback-Leibler and Tsallis entropies are used as penalties. Our
theoretical results are accompanied with illustrative numerical experiments
where we obtain tighter lower bounds for adversarial risks with the
cross-entropy loss function.

</details>


### [514] [Moon: A Modality Conversion-based Efficient Multivariate Time Series Anomaly Detection](https://arxiv.org/abs/2510.01970)
*Yuanyuan Yao,Yuhan Shi,Lu Chen,Ziquan Fang,Yunjun Gao,Leong Hou U,Yushuai Li,Tianyi Li*

Main category: cs.LG

TL;DR: Moon是一种基于监督模态转换的多元时间序列异常检测框架，通过将时间序列转换为图像并结合数值数据，利用多模态CNN进行特征融合，最终实现高效、准确且可解释的异常检测，并在多个真实世界数据集上超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列异常检测方法在准确性、对异常标签的利用以及捕捉局部关系和计算成本方面存在挑战，特别是无监督和半监督方法依赖误差阈值，而监督方法在处理稀疏标签数据时表现不佳。

Method: Moon框架首先采用新颖的多元马尔可夫转移场（MV-MTF）技术将数值时间序列数据转换为图像表示，以捕捉变量和时间戳之间的关系。然后，利用多模态CNN结合数值和图像数据，通过带有参数共享的特征融合模型来提高训练效率。最后，引入基于SHAP的异常解释器来识别导致异常的关键变量，从而提高模型的可解释性。

Result: Moon框架在六个真实世界多元时间序列数据集上进行了广泛实验，结果表明其在效率方面提升高达93%，准确性方面提升4%，解释性方面提升10.8%，优于六种最先进的同类方法。

Conclusion: Moon框架通过创新的模态转换、多模态特征融合和基于SHAP的解释能力，有效解决了现有多元时间序列异常检测方法的局限性，实现了更高的效率、准确性和可解释性。

Abstract: Multivariate time series (MTS) anomaly detection identifies abnormal patterns
where each timestamp contains multiple variables. Existing MTS anomaly
detection methods fall into three categories: reconstruction-based,
prediction-based, and classifier-based methods. However, these methods face two
key challenges: (1) Unsupervised learning methods, such as reconstruction-based
and prediction-based methods, rely on error thresholds, which can lead to
inaccuracies; (2) Semi-supervised methods mainly model normal data and often
underuse anomaly labels, limiting detection of subtle anomalies;(3) Supervised
learning methods, such as classifier-based approaches, often fail to capture
local relationships, incur high computational costs, and are constrained by the
scarcity of labeled data. To address these limitations, we propose Moon, a
supervised modality conversion-based multivariate time series anomaly detection
framework. Moon enhances the efficiency and accuracy of anomaly detection while
providing detailed anomaly analysis reports. First, Moon introduces a novel
multivariate Markov Transition Field (MV-MTF) technique to convert numeric time
series data into image representations, capturing relationships across
variables and timestamps. Since numeric data retains unique patterns that
cannot be fully captured by image conversion alone, Moon employs a
Multimodal-CNN to integrate numeric and image data through a feature fusion
model with parameter sharing, enhancing training efficiency. Finally, a
SHAP-based anomaly explainer identifies key variables contributing to
anomalies, improving interpretability. Extensive experiments on six real-world
MTS datasets demonstrate that Moon outperforms six state-of-the-art methods by
up to 93% in efficiency, 4% in accuracy and, 10.8% in interpretation
performance.

</details>


### [515] [Private Federated Multiclass Post-hoc Calibration](https://arxiv.org/abs/2510.01987)
*Samuel Maddock,Graham Cormode,Carsten Maple*

Main category: cs.LG

TL;DR: 将模型校准技术集成到联邦学习中，以解决隐私和客户端异质性问题。


<details>
  <summary>Details</summary>
Motivation: 在联邦学习（FL）中，模型校准对于在医疗保健和金融等关键领域做出可靠的决策至关重要，但目前的研究在联邦私有校准方面存在不足。

Method: 将直方图分箱和温度缩放等传统校准方法集成到联邦环境中，并开发了新的方法来处理客户端异质性。研究了联邦设置和用户级差分隐私（DP）设置对校准精度的影响。

Result: 提出的联邦温度缩放方法在 DP-FL 设置下效果最佳，而加权的直方图分箱方法在不需要 DP 时效果最佳。

Conclusion: 联邦学习和差分隐私会影响校准精度，但通过采用特定的联邦校准策略，可以减轻异质性带来的性能下降。

Abstract: Calibrating machine learning models so that predicted probabilities better
reflect the true outcome frequencies is crucial for reliable decision-making
across many applications. In Federated Learning (FL), the goal is to train a
global model on data which is distributed across multiple clients and cannot be
centralized due to privacy concerns. FL is applied in key areas such as
healthcare and finance where calibration is strongly required, yet federated
private calibration has been largely overlooked. This work introduces the
integration of post-hoc model calibration techniques within FL. Specifically,
we transfer traditional centralized calibration methods such as histogram
binning and temperature scaling into federated environments and define new
methods to operate them under strong client heterogeneity. We study (1) a
federated setting and (2) a user-level Differential Privacy (DP) setting and
demonstrate how both federation and DP impacts calibration accuracy. We propose
strategies to mitigate degradation commonly observed under heterogeneity and
our findings highlight that our federated temperature scaling works best for
DP-FL whereas our weighted binning approach is best when DP is not required.

</details>


### [516] [PepCompass: Navigating peptide embedding spaces using Riemannian Geometry](https://arxiv.org/abs/2510.01988)
*Marcin Możejko,Adam Bielecki,Jurand Prądzyński,Marcin Traskowski,Antoni Janowski,Karol Jurasz,Michał Kucharczyk,Hyun-Su Lee,Marcelo Der Torossian Torres,Cesar de la Fuente-Nunez,Paulina Szymczak,Michał Kmicikiewicz,Ewa Szczurek*

Main category: cs.LG

TL;DR: 本研究提出了一种名为PepCompass的几何感知框架，用于抗菌肽的探索和优化。该框架通过定义一个$\\


<details>
  <summary>Details</summary>
Motivation: 由于肽空间规模巨大且活性肽相对稀少，传统的抗菌肽发现方法面临挑战。现有的生成模型虽然能提供肽空间的连续潜在“地图”，但忽略了解码器诱导的几何形状，并依赖于平坦的欧几里得度量，导致探索和优化过程效率低下且失真。

Method: PepCompass框架的核心在于定义了一个$\\

Result: 体外验证证实了PepCompass的有效性。通过PoGS发现了四种新型种子肽，随后的LE-BO优化发现了25种具有广谱活性的高效肽，其中一些对耐药菌株也有效。

Conclusion: 本研究表明，几何信息驱动的探索为抗菌肽设计提供了一个强大的新范式。

Abstract: Antimicrobial peptide discovery is challenged by the astronomical size of
peptide space and the relative scarcity of active peptides. Generative models
provide continuous latent "maps" of peptide space, but conventionally ignore
decoder-induced geometry and rely on flat Euclidean metrics, rendering
exploration and optimization distorted and inefficient. Prior manifold-based
remedies assume fixed intrinsic dimensionality, which critically fails in
practice for peptide data. Here, we introduce PepCompass, a geometry-aware
framework for peptide exploration and optimization. At its core, we define a
Union of $\kappa$-Stable Riemannian Manifolds $\mathbb{M}^{\kappa}$, a family
of decoder-induced manifolds that captures local geometry while ensuring
computational stability. We propose two local exploration methods: Second-Order
Riemannian Brownian Efficient Sampling, which provides a convergent
second-order approximation to Riemannian Brownian motion, and Mutation
Enumeration in Tangent Space, which reinterprets tangent directions as discrete
amino-acid substitutions. Combining these yields Local Enumeration Bayesian
Optimization (LE-BO), an efficient algorithm for local activity optimization.
Finally, we introduce Potential-minimizing Geodesic Search (PoGS), which
interpolates between prototype embeddings along property-enriched geodesics,
biasing discovery toward seeds, i.e. peptides with favorable activity. In-vitro
validation confirms the effectiveness of PepCompass: PoGS yields four novel
seeds, and subsequent optimization with LE-BO discovers 25 highly active
peptides with broad-spectrum activity, including against resistant bacterial
strains. These results demonstrate that geometry-informed exploration provides
a powerful new paradigm for antimicrobial peptide design.

</details>


### [517] [Normality Calibration in Semi-supervised Graph Anomaly Detection](https://arxiv.org/abs/2510.02014)
*Guolei Zeng,Hezhe Qiao,Guoguo Ai,Jinsong Guo,Guansong Pang*

Main category: cs.LG

TL;DR: GraphNC是一个图异常检测框架，通过对标签和无标签数据进行校准，以提高异常检测的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有半监督图异常检测方法仅利用标记的正常节点，容易过拟合，导致高错误率。

Method: GraphNC包含两个主要组件：1. 异常分数分布对齐（ScoreDA），通过使模型的异常分数与教师模型的异常分数分布对齐，来区分正常和异常节点。2. 基于扰动的异常正则化（NormReg），通过最小化扰动引导的一致性损失来使正常节点的表示更紧凑，以减少教师模型中不准确的分数的影响。

Result: ScoreDA使异常分数更具可分离性，NormReg使正常节点的表示更紧凑。

Conclusion: GraphNC通过结合ScoreDA和NormReg，提高了图异常检测的准确性，克服了现有方法的局限性。

Abstract: Graph anomaly detection (GAD) has attracted growing interest for its crucial
ability to uncover irregular patterns in broad applications. Semi-supervised
GAD, which assumes a subset of annotated normal nodes available during
training, is among the most widely explored application settings. However, the
normality learned by existing semi-supervised GAD methods is limited to the
labeled normal nodes, often inclining to overfitting the given patterns. These
can lead to high detection errors, such as high false positives. To overcome
this limitation, we propose GraphNC , a graph normality calibration framework
that leverages both labeled and unlabeled data to calibrate the normality from
a teacher model (a pre-trained semi-supervised GAD model) jointly in anomaly
score and node representation spaces. GraphNC includes two main components,
anomaly score distribution alignment (ScoreDA) and perturbation-based normality
regularization (NormReg). ScoreDA optimizes the anomaly scores of our model by
aligning them with the score distribution yielded by the teacher model. Due to
accurate scores in most of the normal nodes and part of the anomaly nodes in
the teacher model, the score alignment effectively pulls the anomaly scores of
the normal and abnormal classes toward the two ends, resulting in more
separable anomaly scores. Nevertheless, there are inaccurate scores from the
teacher model. To mitigate the misleading by these scores, NormReg is designed
to regularize the graph normality in the representation space, making the
representations of normal nodes more compact by minimizing a
perturbation-guided consistency loss solely on the labeled nodes.

</details>


### [518] [FairContrast: Enhancing Fairness through Contrastive learning and Customized Augmenting Methods on Tabular Data](https://arxiv.org/abs/2510.02017)
*Aida Tayebi,Ali Khodabandeh Yalabadi,Mehdi Yazdani-Jahromi,Ozlem Ozmen Garibay*

Main category: cs.LG

TL;DR: 本研究提出了一种用于表格数据的对比学习框架，以解决偏见问题并学习公平表征，有效降低了偏见，同时在准确性方面仅有最小的权衡，并能在各种下游任务中利用学习到的公平表征。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能系统日益融入日常生活，开发公平无偏见的模型变得至关重要，解决人工智能的社会影响不仅是技术挑战，更是道义上的责任。学习公平且鲁棒的表征已被证明是有效消除算法偏见、提高公平性同时保持预测任务所需关键信息的有力方法。

Method: 提出了一种专门为解决表格数据集中的偏见和学习公平表征而设计的对比学习框架，通过策略性地选择正例样本并采用监督和自监督对比学习。

Result: 与现有的表格数据对比学习模型相比，显著减少了偏见，并在准确性方面仅有最小的权衡，展示了所提出方法在减轻偏见方面的有效性，并能在各种下游任务中利用学习到的公平表征。

Conclusion: 本研究提出的对比学习框架在解决表格数据中的偏见问题方面是有效的，并且在准确性方面仅有最小的权衡。

Abstract: As AI systems become more embedded in everyday life, the development of fair
and unbiased models becomes more critical. Considering the social impact of AI
systems is not merely a technical challenge but a moral imperative. As
evidenced in numerous research studies, learning fair and robust
representations has proven to be a powerful approach to effectively debiasing
algorithms and improving fairness while maintaining essential information for
prediction tasks. Representation learning frameworks, particularly those that
utilize self-supervised and contrastive learning, have demonstrated superior
robustness and generalizability across various domains. Despite the growing
interest in applying these approaches to tabular data, the issue of fairness in
these learned representations remains underexplored. In this study, we
introduce a contrastive learning framework specifically designed to address
bias and learn fair representations in tabular datasets. By strategically
selecting positive pair samples and employing supervised and self-supervised
contrastive learning, we significantly reduce bias compared to existing
state-of-the-art contrastive learning models for tabular data. Our results
demonstrate the efficacy of our approach in mitigating bias with minimum
trade-off in accuracy and leveraging the learned fair representations in
various downstream tasks.

</details>


### [519] [Mathematical Modeling and Convergence Analysis of Deep Neural Networks with Dense Layer Connectivities in Deep Learning](https://arxiv.org/abs/2510.02049)
*Jinshu Huang,Haibin Su,Xue-Cheng Tai,Chunlin Wu*

Main category: cs.LG

TL;DR: 深入探讨了深度全连接神经网络（DNNs）的学习问题，并提出了“密集非局部（DNL）”框架，将DNNs建模为非线性积分方程，并从最优控制角度分析了训练问题。


<details>
  <summary>Details</summary>
Motivation: 深度学习中密集连接已成为DNNs的关键设计原则，但缺乏数学分析。本研究旨在为密集连接的DNNs提供数学基础，并理解其学习问题。

Method: 提出“密集非局部（DNL）”框架，将密集连接的DNNs建模为非线性积分方程（而非微分方程）。从最优控制角度研究训练问题，并利用分段线性扩展和$\Gamma$-收敛性分析证明了从网络学习问题到连续时间对应问题的收敛性。

Result: 证明了在DNL框架下，最优值收敛，且最小化序列存在子序列收敛。这表明密集连接的DNNs在训练深度模型时具有稳定性。

Conclusion: 本研究为理解密集连接的DNNs提供了数学基础，并表明这类架构在训练深度模型时可能具有稳定性。

Abstract: In deep learning, dense layer connectivity has become a key design principle
in deep neural networks (DNNs), enabling efficient information flow and strong
performance across a range of applications. In this work, we model densely
connected DNNs mathematically and analyze their learning problems in the
deep-layer limit. For a broad applicability, we present our analysis in a
framework setting of DNNs with densely connected layers and general non-local
feature transformations (with local feature transformations as special cases)
within layers, which is called dense non-local (DNL) framework and includes
standard DenseNets and variants as special examples. In this formulation, the
densely connected networks are modeled as nonlinear integral equations, in
contrast to the ordinary differential equation viewpoint commonly adopted in
prior works. We study the associated training problems from an optimal control
perspective and prove convergence results from the network learning problem to
its continuous-time counterpart. In particular, we show the convergence of
optimal values and the subsequence convergence of minimizers, using a piecewise
linear extension and $\Gamma$-convergence analysis. Our results provide a
mathematical foundation for understanding densely connected DNNs and further
suggest that such architectures can offer stability of training deep models.

</details>


### [520] [Adaptive Heterogeneous Mixtures of Normalising Flows for Robust Variational Inference](https://arxiv.org/abs/2510.02056)
*Benjamin Wiriyapong,Oktay Karakuş,Kirill Sidorov*

Main category: cs.LG

TL;DR: AMF-VI是一种自适应混合流变分推断方法，通过结合多种流模型（MAF, RealNVP, RBIG）并采用两阶段训练策略，在各种后验分布上实现了比单一流模型更低的负对数似然和更好的传输指标，同时保持了高效和架构无关性。


<details>
  <summary>Details</summary>
Motivation: 单一归一化流变分推断模型在近似复杂后验时可能表现不一致，尤其是在处理不同分布时。

Method: 提出自适应混合流变分推断（AMF-VI），采用两阶段训练：1. 序列化训练单个流模型；2. 通过似然驱动的更新进行自适应全局权重估计，无需门控或架构更改。

Result: 在六种典型的后验分布（banana, X-shape, two-moons, rings, bimodal, five-mode mixture）上，AMF-VI实现了比单一流基线更低的负对数似然，并在传输指标（Wasserstein-2）和最大均值差异（MDD）上显示出稳定的提升。

Conclusion: 自适应混合多种流模型是实现鲁棒变分推断的可靠途径，能够处理各种后验分布，同时保留每个专家模型的归纳偏置，并且训练过程高效且与架构无关。

Abstract: Normalising-flow variational inference (VI) can approximate complex
posteriors, yet single-flow models often behave inconsistently across
qualitatively different distributions. We propose Adaptive Mixture Flow
Variational Inference (AMF-VI), a heterogeneous mixture of complementary flows
(MAF, RealNVP, RBIG) trained in two stages: (i) sequential expert training of
individual flows, and (ii) adaptive global weight estimation via
likelihood-driven updates, without per-sample gating or architectural changes.
Evaluated on six canonical posterior families of banana, X-shape, two-moons,
rings, a bimodal, and a five-mode mixture, AMF-VI achieves consistently lower
negative log-likelihood than each single-flow baseline and delivers stable
gains in transport metrics (Wasserstein-2) and maximum mean discrepancy (MDD),
indicating improved robustness across shapes and modalities. The procedure is
efficient and architecture-agnostic, incurring minimal overhead relative to
standard flow training, and demonstrates that adaptive mixtures of diverse
flows provide a reliable route to robust VI across diverse posterior families
whilst preserving each expert's inductive bias.

</details>


### [521] [Inferring Optical Tissue Properties from Photoplethysmography using Hybrid Amortized Inference](https://arxiv.org/abs/2510.02073)
*Jens Behrmann,Maria R. Cervera,Antoine Wehenkel,Andrew C. Miller,Albert Cerussi,Pranay Jain,Vivek Venugopal,Shijie Yan,Guillermo Sapiro,Luca Pegolotti,Jörn-Henrik Jacobsen*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Smart wearables enable continuous tracking of established biomarkers such as
heart rate, heart rate variability, and blood oxygen saturation via
photoplethysmography (PPG). Beyond these metrics, PPG waveforms contain richer
physiological information, as recent deep learning (DL) studies demonstrate.
However, DL models often rely on features with unclear physiological meaning,
creating a tension between predictive power, clinical interpretability, and
sensor design. We address this gap by introducing PPGen, a biophysical model
that relates PPG signals to interpretable physiological and optical parameters.
Building on PPGen, we propose hybrid amortized inference (HAI), enabling fast,
robust, and scalable estimation of relevant physiological parameters from PPG
signals while correcting for model misspecification. In extensive in-silico
experiments, we show that HAI can accurately infer physiological parameters
under diverse noise and sensor conditions. Our results illustrate a path toward
PPG models that retain the fidelity needed for DL-based features while
supporting clinical interpretation and informed hardware design.

</details>


### [522] [Fine-Tuning Flow Matching via Maximum Likelihood Estimation of Reconstructions](https://arxiv.org/abs/2510.02081)
*Zhaoyi Li,Jingtao Ding,Yong Li,Shihua Li*

Main category: cs.LG

TL;DR: Flow Matching (FM) 算法在生成任务中表现出色，尤其是在机器人操作领域。然而，FM 存在训练-推理不匹配的问题，并且可能导致系统僵化。本文提出通过最大似然估计进行微调，以解决这些问题。


<details>
  <summary>Details</summary>
Motivation: FM 算法在生成任务中表现出色，但存在训练-推理不匹配的问题，且可能导致系统僵化，尤其是在高精度要求的机器人操作等场景中。

Method: 通过最大似然估计对 FM 进行微调，包括直接微调和基于残差的微调。基于残差的微调还可以通过特定的架构引入收缩性质，以提高模型的鲁棒性和可解释性。

Result: 实验结果表明，所提出的微调方法能够可靠地提升 FM 在图像生成和机器人操作任务上的推理性能。

Conclusion: 通过最大似然估计进行微调，能够有效解决 FM 算法的训练-推理不匹配问题，并提高其在各种生成任务中的性能，尤其是在机器人操作领域。

Abstract: Flow Matching (FM) algorithm achieves remarkable results in generative tasks
especially in robotic manipulation. Building upon the foundations of diffusion
models, the simulation-free paradigm of FM enables simple and efficient
training, but inherently introduces a train-inference gap. Specifically, we
cannot assess the model's output during the training phase. In contrast, other
generative models including Variational Autoencoder (VAE), Normalizing Flow and
Generative Adversarial Networks (GANs) directly optimize on the reconstruction
loss. Such a gap is particularly evident in scenarios that demand high
precision, such as robotic manipulation. Moreover, we show that FM's
over-pursuit of straight predefined paths may introduce some serious problems
such as stiffness into the system. These motivate us to fine-tune FM via
Maximum Likelihood Estimation of reconstructions - an approach made feasible by
FM's underlying smooth ODE formulation, in contrast to the stochastic
differential equations (SDEs) used in diffusion models. This paper first
theoretically analyzes the relation between training loss and inference error
in FM. Then we propose a method of fine-tuning FM via Maximum Likelihood
Estimation of reconstructions, which includes both straightforward fine-tuning
and residual-based fine-tuning approaches. Furthermore, through specifically
designed architectures, the residual-based fine-tuning can incorporate the
contraction property into the model, which is crucial for the model's
robustness and interpretability. Experimental results in image generation and
robotic manipulation verify that our method reliably improves the inference
performance of FM.

</details>


### [523] [KAIROS: Unified Training for Universal Non-Autoregressive Time Series Forecasting](https://arxiv.org/abs/2510.02084)
*Kuiye Ding,Fanda Fan,Zheya Wang,Hongxiao Li,Yifan Wang,Lei Wang,Chunjie Luo,Jianfeng Zhan*

Main category: cs.LG

TL;DR: KAIROS是一个非自回归时间序列预测框架，能够快速、准确地进行预测，并且具有良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 在万维网中，可靠的时间序列预测对于资源规划、缓存放置和异常响应至关重要，能够支持平台高效运行。与传统方法不同，Web应用的时间序列预测需要更快的响应速度以支持实时决策。

Method: KAIROS是一个非自回归时间序列预测框架，直接对分段级别的多峰分布进行建模，避免了误差累积，实现了即时推理，并克服了现有非自回归模型预测结果过于平滑的问题。

Result: 在大型语料库上训练的KAIROS在六个广泛使用的基准测试中展现了强大的零样本泛化能力，其预测性能与同等规模的最先进基础模型相当，但推理成本却大大降低。

Conclusion: KAIROS强调了非自回归设计作为时间序列基础模型的可扩展范式的重要性。

Abstract: In the World Wide Web, reliable time series forecasts provide the
forward-looking signals that drive resource planning, cache placement, and
anomaly response, enabling platforms to operate efficiently as user behavior
and content distributions evolve. Compared with other domains, time series
forecasting for Web applications requires much faster responsiveness to support
real-time decision making. We present KAIROS, a non-autoregressive time series
forecasting framework that directly models segment-level multi-peak
distributions. Unlike autoregressive approaches, KAIROS avoids error
accumulation and achieves just-in-time inference, while improving over existing
non-autoregressive models that collapse to over-smoothed predictions. Trained
on the large-scale corpus, KAIROS demonstrates strong zero-shot generalization
on six widely used benchmarks, delivering forecasting performance comparable to
state-of-the-art foundation models with similar scale, at a fraction of their
inference cost. Beyond empirical results, KAIROS highlights the importance of
non-autoregressive design as a scalable paradigm for foundation models in time
series.

</details>


### [524] [Learning Model Representations Using Publicly Available Model Hubs](https://arxiv.org/abs/2510.02096)
*Damian Falk,Konstantin Schürholt,Konstantinos Tzevelekakis,Léo Meynent,Damian Borth*

Main category: cs.LG

TL;DR: 无需精心构建的大型模型库，即可在 Hugging Face 等非结构化模型库中训练出高质量的权重空间表征，并且在各种下游任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前权重空间学习需要大型、精心构建的模型库，这需要大量的计算资源并且限制了学习的规模和灵活性。

Method: 提出了一种新的权重空间表征学习方法，可以直接在 Hugging Face 等非结构化模型库中训练模型，无需预先对模型进行整理和标注。该方法能够处理模型架构、训练数据集等方面的异质性。

Result: 在 Hugging Face 上训练的权重空间表征在各种下游任务中取得了与在精心构建的模型库上训练的模型相媲美的性能，甚至在某些任务上表现更优。此外，由于训练数据源的多样性，该模型能够泛化到未知的下游任务。

Conclusion: 精心构建的模型库并非必需品，可以直接利用非结构化模型库来学习高质量的权重空间表征，从而克服了该领域目前面临的一个重大限制。

Abstract: The weights of neural networks have emerged as a novel data modality, giving
rise to the field of weight space learning. A central challenge in this area is
that learning meaningful representations of weights typically requires large,
carefully constructed collections of trained models, typically referred to as
model zoos. These model zoos are often trained ad-hoc, requiring large
computational resources, constraining the learned weight space representations
in scale and flexibility. In this work, we drop this requirement by training a
weight space learning backbone on arbitrary models downloaded from large,
unstructured model repositories such as Hugging Face. Unlike curated model
zoos, these repositories contain highly heterogeneous models: they vary in
architecture and dataset, and are largely undocumented. To address the
methodological challenges posed by such heterogeneity, we propose a new weight
space backbone designed to handle unstructured model populations. We
demonstrate that weight space representations trained on models from Hugging
Face achieve strong performance, often outperforming backbones trained on
laboratory-generated model zoos. Finally, we show that the diversity of the
model weights in our training set allows our weight space model to generalize
to unseen data modalities. By demonstrating that high-quality weight space
representations can be learned in the wild, we show that curated model zoos are
not indispensable, thereby overcoming a strong limitation currently faced by
the weight space learning community.

</details>


### [525] [PENEX: AdaBoost-Inspired Neural Network Regularization](https://arxiv.org/abs/2510.02107)
*Klaus-Rudolf Kladny,Bernhard Schölkopf,Michael Muehlebach*

Main category: cs.LG

TL;DR: AdaBoost虽然采用指数损失，但泛化能力好。本文提出PENEX，一种新的多类指数损失，可优化且理论上能最大化间隔，并隐式参数化弱学习器。PENEX在计算机视觉和语言任务中表现出正则化效果，可作为AdaBoost的替代方案，用于深度神经网络的训练和微调。


<details>
  <summary>Details</summary>
Motivation: AdaBoost采用指数损失，虽然会惩罚错误标记的数据点，但却具有良好的泛化能力。然而，现有的指数损失形式不利于优化。因此，需要一种新的、理论上合理且易于优化的损失函数。

Method: 提出了一种名为PENEX（Penalized Exponential Loss）的新型多类指数损失函数。PENEX在理论上保证能够最大化数据点的间隔，并且其梯度增量能够隐式地参数化提升框架中的弱学习器。通过这种方式，PENEX可以被一阶优化方法处理。

Result: 通过实验和理论分析，证明了PENEX能够最大化数据点的间隔，并且其梯度增量能够隐式地参数化弱学习器。在计算机视觉和语言任务的实验中，PENEX展现出了优于现有方法的正则化效果，并且计算成本相当。

Conclusion: PENEX作为一种AdaBoost的替代方案，在训练和微调深度神经网络方面具有潜力。它不仅在理论上保证了间隔最大化，而且在实践中也表现出了良好的正则化效果和效率。

Abstract: AdaBoost sequentially fits so-called weak learners to minimize an exponential
loss, which penalizes mislabeled data points more severely than other loss
functions like cross-entropy. Paradoxically, AdaBoost generalizes well in
practice as the number of weak learners grows. In the present work, we
introduce Penalized Exponential Loss (PENEX), a new formulation of the
multi-class exponential loss that is theoretically grounded and, in contrast to
the existing formulation, amenable to optimization via first-order methods. We
demonstrate both empirically and theoretically that PENEX implicitly maximizes
margins of data points. Also, we show that gradient increments on PENEX
implicitly parameterize weak learners in the boosting framework. Across
computer vision and language tasks, we show that PENEX exhibits a regularizing
effect often better than established methods with similar computational cost.
Our results highlight PENEX's potential as an AdaBoost-inspired alternative for
effective training and fine-tuning of deep neural networks.

</details>


### [526] [Hybrid Deep Learning Modeling Approach to Predict Natural Gas Consumption of Home Subscribers on Limited Data](https://arxiv.org/abs/2510.02115)
*Milad Firoozeh,Nader Dashti,Mohammad Ali Hatefi*

Main category: cs.LG

TL;DR: 伊朗Zanjan省的居民天然气消耗可通过机器学习模型（特别是混合BiLSTM-XGBoost模型）进行有效预测，有助于资源管理和减少季节性短缺。


<details>
  <summary>Details</summary>
Motivation: 伊朗作为能源资源大国，面临人口增长和能源消耗增加导致的天然气供应问题，尤其是在冬季的居民用气高峰期，因此需要控制天然气消耗。本研究旨在通过机器学习模型预测Zanjan省的居民天然气消耗，以应对这一挑战。

Method: 本研究使用2017年至2022年六年的天然气消耗和气象数据，采用LSTM、GRU和混合BiLSTM-XGBoost三种机器学习模型，对Zanjan省居民的天然气消耗进行分析和预测。通过评估各模型的准确性（RMSE、MAPE、MPE等指标）来选择最优模型。

Result: 混合BiLSTM-XGBoost模型在预测准确性方面优于单独的LSTM和GRU模型，其RMSE、MAPE和MPE值最低。即使在数据量有限的情况下，该混合模型也表现出强大的预测能力。

Conclusion: 机器学习方法，特别是混合模型，能够有效管理和预测天然气消耗，有助于提高资源利用效率，缓解季节性供应短缺。研究强调了地理和气候因素在天然气消耗预测中的重要性。

Abstract: Today, natural gas, as a clean fuel and the best alternative to crude oil,
covers a significant part of global demand. Iran is one of the largest
countries with energy resources and in terms of gas is the second-largest
country in the world. But, due to the increase in population and energy
consumption, it faces problems such as pressure drops and gas outages yearly in
cold seasons and therefore it is necessary to control gas consumption,
especially in the residential sector, which has the largest share in Iran. This
study aims to analyze and predict gas consumption for residential customers in
Zanjan province, Iran, using machine learning models, including LSTM, GRU, and
a hybrid BiLSTM-XGBoost model. The dataset consists of gas consumption and
meteorology data collected over six years, from 2017 to 2022. The models were
trained and evaluated based on their ability to accurately predict consumption
patterns. The results indicate that the hybrid BiLSTM-XGBoost model
outperformed the other models in terms of accuracy, with lower Root Mean
Squared Error (RMSE), Mean Absolute Percentage Error (MAPE) values, and Mean
Percentage Error (MPE). Additionally, the Hybrid model demonstrated robust
performance, particularly in scenarios with limited data. The findings suggest
that machine learning approaches, particularly hybrid models, can be
effectively utilized to manage and predict gas consumption, contributing to
more efficient resource management and reducing seasonal shortages. This study
highlights the importance of incorporating geographical and climatic factors in
predictive modeling, as these significantly influence gas usage across
different regions.

</details>


### [527] [Ensemble Threshold Calibration for Stable Sensitivity Control](https://arxiv.org/abs/2510.02116)
*John N. Daras*

Main category: cs.LG

TL;DR: 本研究提出了一种能够精确控制召回率的框架，用于大规模空间汇聚和实体匹配任务，能够以极低的方差和成本实现目标召回率。


<details>
  <summary>Details</summary>
Motivation: 在空间汇聚和实体匹配任务中，精确控制召回率至关重要。过低的召回率会影响下游分析，而过多的手动审核会增加成本。传统方法在召回率控制和成本方面存在不足。

Method: 提出了一种端到端的框架，包括：1. 使用等网格边界框过滤和压缩稀疏行（CSR）候选表示来减少候选对的数量。2. 使用确定性 xxHash 自助采样训练轻量级神经网络排序器。3. 通过一次前向传播将分数传播给所有剩余的对。4. 构建可复现、分数十分位数分层的校准集。5. 聚合四种互补的阈值估计器（Clopper-Pearson, Jeffreys, Wilson, 和精确分位数）并进行逆方差加权。6. 融合九个独立子样本的结果以降低阈值方差。

Result: 该框架在两个真实的地籍数据集（约 6.31M 和 67.34M 对）上进行了评估，能够精确地达到目标召回率（误差小于 1%），并显著减少冗余验证。此外，该方法可在单个 TPU v3 核上端到端运行，并且方差极低（低于 1%）。

Conclusion: 本研究提出的框架能够以高精度、低方差、低成本的方式实现大规模空间汇聚和实体匹配任务的目标召回率，优于传统方法。

Abstract: Precise recall control is critical in large-scale spatial conflation and
entity-matching tasks, where missing even a few true matches can break
downstream analytics, while excessive manual review inflates cost. Classical
confidence-interval cuts such as Clopper-Pearson or Wilson provide lower bounds
on recall, but they routinely overshoot the target by several percentage points
and exhibit high run-to-run variance under skewed score distributions. We
present an end-to-end framework that achieves exact recall with sub-percent
variance over tens of millions of geometry pairs, while remaining TPU-friendly.
Our pipeline starts with an equigrid bounding-box filter and compressed sparse
row (CSR) candidate representation, reducing pair enumeration by two orders of
magnitude. A deterministic xxHash bootstrap sample trains a lightweight neural
ranker; its scores are propagated to all remaining pairs via a single forward
pass and used to construct a reproducible, score-decile-stratified calibration
set. Four complementary threshold estimators - Clopper-Pearson, Jeffreys,
Wilson, and an exact quantile - are aggregated via inverse-variance weighting,
then fused across nine independent subsamples. This ensemble reduces threshold
variance compared to any single method. Evaluated on two real cadastral
datasets (approximately 6.31M and 67.34M pairs), our approach consistently hits
a recall target within a small error, decreases redundant verifications
relative to other calibrations, and runs end-to-end on a single TPU v3 core.

</details>


### [528] [DAG DECORation: Continuous Optimization for Structure Learning under Hidden Confounding](https://arxiv.org/abs/2510.02117)
*Samhita Pal,James O'quinn,Kaveh Aryan,Heather Pua,James P. Long,Amir Asiaee*

Main category: cs.LG

TL;DR: DECOR是一个单一的、基于似然的、完全可微的估计器，用于联合学习有潜在混淆的线性高斯SEM中的有向图和相关噪声模型。


<details>
  <summary>Details</summary>
Motivation: 现有的连续方法在误差独立时表现良好，而deconfounding-first方法依赖于普遍的因子结构或非线性。本研究旨在解决潜在混淆存在的情况下，线性高斯SEM的结构学习问题。

Method: DECOR通过交替进行平滑无环图更新和凸噪声更新，并可选择加入轻微的弓形互补性惩罚或事后协调步骤，来联合学习有向无环图（DAG）和相关噪声模型。

Result: 在具有不同混淆密度、图密度、潜在秩和维度的合成基准（n<p）上，DECOR的性能与强大的基线相当或更优，尤其在混淆不普遍时表现出鲁棒性，同时在混淆普遍存在的情况下仍保持竞争力。

Conclusion: 在混合图无弓形且噪声协方差具有均匀特征值裕度的情况下，可以保证DECOR的全局参数可识别性，从而唯一确定有向结构和噪声。

Abstract: We study structure learning for linear Gaussian SEMs in the presence of
latent confounding. Existing continuous methods excel when errors are
independent, while deconfounding-first pipelines rely on pervasive factor
structure or nonlinearity. We propose \textsc{DECOR}, a single likelihood-based
and fully differentiable estimator that jointly learns a DAG and a correlated
noise model. Our theory gives simple sufficient conditions for global parameter
identifiability: if the mixed graph is bow free and the noise covariance has a
uniform eigenvalue margin, then the map from $(\B,\OmegaMat)$ to the
observational covariance is injective, so both the directed structure and the
noise are uniquely determined. The estimator alternates a smooth-acyclic graph
update with a convex noise update and can include a light bow complementarity
penalty or a post hoc reconciliation step. On synthetic benchmarks that vary
confounding density, graph density, latent rank, and dimension with $n<p$,
\textsc{DECOR} matches or outperforms strong baselines and is especially robust
when confounding is non-pervasive, while remaining competitive under
pervasiveness.

</details>


### [529] [Policy Gradient Guidance Enables Test Time Control](https://arxiv.org/abs/2510.02148)
*Jianing Qi,Hao Tang,Zhigang Zhu*

Main category: cs.LG

TL;DR: Policy Gradient Guidance (PGG)是一种将classifier-free guidance从扩散模型扩展到策略梯度方法的简单方法，可以在无需重新训练的情况下调整行为。


<details>
  <summary>Details</summary>
Motivation: 将classifier-free guidance从扩散模型扩展到策略梯度方法，以实现测试时行为的控制，而无需重新训练。

Method: PGG通过添加一个无条件分支来增强策略梯度，并对条件分支和无条件分支进行插值，从而提供一个测试时控制旋钮。

Result: 在离散和连续控制基准上的实验表明，PGG在简单离散任务和低样本量情况下可以提高性能，但对于连续控制可能导致不稳定。增加引导强度（γ>1）可以持续提高稳定性和样本效率。

Conclusion: PGG可以成功应用于标准的在线策略方法，为可控的在线强化学习开辟了新的方向。

Abstract: We introduce Policy Gradient Guidance (PGG), a simple extension of
classifier-free guidance from diffusion models to classical policy gradient
methods. PGG augments the policy gradient with an unconditional branch and
interpolates conditional and unconditional branches, yielding a test-time
control knob that modulates behavior without retraining. We provide a
theoretical derivation showing that the additional normalization term vanishes
under advantage estimation, leading to a clean guided policy gradient update.
Empirically, we evaluate PGG on discrete and continuous control benchmarks. We
find that conditioning dropout-central to diffusion guidance-offers gains in
simple discrete tasks and low sample regimes, but dropout destabilizes
continuous control. Training with modestly larger guidance ($\gamma>1$)
consistently improves stability, sample efficiency, and controllability. Our
results show that guidance, previously confined to diffusion policies, can be
adapted to standard on-policy methods, opening new directions for controllable
online reinforcement learning.

</details>


### [530] [StockBench: Can LLM Agents Trade Stocks Profitably In Real-world Markets?](https://arxiv.org/abs/2510.02209)
*Yanxu Chen,Zijun Yao,Yantao Liu,Jin Ye,Jianing Yu,Lei Hou,Juanzi Li*

Main category: cs.LG

TL;DR: StockBench是一个包含金融领域LLM代理的基准测试，通过模拟多月的真实股票交易环境来评估代理的性能，并已将该基准测试开源。


<details>
  <summary>Details</summary>
Motivation: 金融领域LLM代理的应用仍有待探索，现有的金融基准测试主要侧重于静态知识问答，未能充分捕捉交易的动态性和迭代性。

Method: 引入了一个名为StockBench的无污染基准测试，该测试通过模拟真实、多月的股票交易环境来评估LLM代理。代理接收每日市场信号（包括价格、基本面和新闻），并需要做出连续的买入、卖出或持有决策。使用累积回报、最大回撤和索提诺比率等金融指标评估性能。

Result: 对包括GPT-5、Claude-4、Qwen3、Kimi-K2和GLM-4.5在内的模型进行了评估，发现大多数LLM代理难以超越简单的买入并持有基准，但有几类模型展示了提供更高回报和更有效地管理风险的潜力。

Conclusion: 在静态金融知识任务方面表现优异的模型，并不一定能在交易策略上取得成功，这表明在开发LLM金融代理方面既存在挑战也存在机遇。StockBench的发布旨在促进该领域的开放复现和未来研究。

Abstract: Large language models (LLMs) have recently demonstrated strong capabilities
as autonomous agents, showing promise in reasoning, tool use, and sequential
decision-making. While prior benchmarks have evaluated LLM agents in domains
such as software engineering and scientific discovery, the finance domain
remains underexplored, despite its direct relevance to economic value and
high-stakes decision-making. Existing financial benchmarks primarily test
static knowledge through question answering, but they fall short of capturing
the dynamic and iterative nature of trading. To address this gap, we introduce
StockBench, a contamination-free benchmark designed to evaluate LLM agents in
realistic, multi-month stock trading environments. Agents receive daily market
signals -- including prices, fundamentals, and news -- and must make sequential
buy, sell, or hold decisions. Performance is assessed using financial metrics
such as cumulative return, maximum drawdown, and the Sortino ratio. Our
evaluation of state-of-the-art proprietary (e.g., GPT-5, Claude-4) and
open-weight (e.g., Qwen3, Kimi-K2, GLM-4.5) models shows that while most LLM
agents struggle to outperform the simple buy-and-hold baseline, several models
demonstrate the potential to deliver higher returns and manage risk more
effectively. These findings highlight both the challenges and opportunities in
developing LLM-powered financial agents, showing that excelling at static
financial knowledge tasks does not necessarily translate into successful
trading strategies. We release StockBench as an open-source resource to support
reproducibility and advance future research in this domain.

</details>


### [531] [Reinforcement Learning with Action-Triggered Observations](https://arxiv.org/abs/2510.02149)
*Alexander Ryabchenko,Wenlong Mou*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We study reinforcement learning problems where state observations are
stochastically triggered by actions, a constraint common in many real-world
applications. This framework is formulated as Action-Triggered Sporadically
Traceable Markov Decision Processes (ATST-MDPs), where each action has a
specified probability of triggering a state observation. We derive tailored
Bellman optimality equations for this framework and introduce the
action-sequence learning paradigm in which agents commit to executing a
sequence of actions until the next observation arrives. Under the linear MDP
assumption, value-functions are shown to admit linear representations in an
induced action-sequence feature map. Leveraging this structure, we propose
off-policy estimators with statistical error guarantees for such feature maps
and introduce ST-LSVI-UCB, a variant of LSVI-UCB adapted for action-triggered
settings. ST-LSVI-UCB achieves regret $\widetilde
O(\sqrt{Kd^3(1-\gamma)^{-3}})$, where $K$ is the number of episodes, $d$ the
feature dimension, and $\gamma$ the discount factor (per-step episode
non-termination probability). Crucially, this work establishes the theoretical
foundation for learning with sporadic, action-triggered observations while
demonstrating that efficient learning remains feasible under such observation
constraints.

</details>


### [532] [Flatness-Aware Stochastic Gradient Langevin Dynamics](https://arxiv.org/abs/2510.02174)
*Stefano Bruno,Youngsik Hwang,Jaehyeon An,Sotirios Sabanis,Dong-Young Lim*

Main category: cs.LG

TL;DR: fSGLD通过在随机梯度 Langevin 动力学中引入随机权重扰动，能够有效寻找优化问题的平坦极小值，并提供了理论保证和实验验证。


<details>
  <summary>Details</summary>
Motivation: 深度学习泛化能力与寻找损失平坦极小值密切相关，但传统的随机梯度 Langevin 动力学（SGLD）缺乏导向平坦极小值的机制。

Method: fSGLD 在每次迭代时，使用在添加了各向同性高斯噪声的参数上评估出的随机梯度。这种随机权重扰动（RWP）的机制使得模型在优化时能隐式地捕捉到曲率信息，进而优化一个随机平滑的目标函数。

Result: 理论上，fSGLD 的不变测度接近于一个在全局极小值处集中的平稳测度，尤其是在损失函数由Hessian迹正则化时。实验表明，fSGLD 在泛化能力、鲁棒性以及收敛到更平坦的最小值方面表现优于或媲美基线算法，同时计算成本与SGD相当，约为SAM的一半。

Conclusion: fSGLD 是一种高效且具有理论支撑的方法，能够引导优化过程寻找深度学习中的平坦极小值，从而提升模型的泛化能力和鲁棒性。

Abstract: Generalization in deep learning is closely tied to the pursuit of flat minima
in the loss landscape, yet classical Stochastic Gradient Langevin Dynamics
(SGLD) offers no mechanism to bias its dynamics toward such low-curvature
solutions. This work introduces Flatness-Aware Stochastic Gradient Langevin
Dynamics (fSGLD), designed to efficiently and provably seek flat minima in
high-dimensional nonconvex optimization problems. At each iteration, fSGLD uses
the stochastic gradient evaluated at parameters perturbed by isotropic Gaussian
noise, commonly referred to as Random Weight Perturbation (RWP), thereby
optimizing a randomized-smoothing objective that implicitly captures curvature
information. Leveraging these properties, we prove that the invariant measure
of fSGLD stays close to a stationary measure concentrated on the global
minimizers of a loss function regularized by the Hessian trace whenever the
inverse temperature and the scale of random weight perturbation are properly
coupled. This result provides a rigorous theoretical explanation for the
benefits of random weight perturbation. In particular, we establish
non-asymptotic convergence guarantees in Wasserstein distance with the best
known rate and derive an excess-risk bound for the Hessian-trace regularized
objective. Extensive experiments on noisy-label and large-scale vision tasks,
in both training-from-scratch and fine-tuning settings, demonstrate that fSGLD
achieves superior or comparable generalization and robustness to baseline
algorithms while maintaining the computational cost of SGD, about half that of
SAM. Hessian-spectrum analysis further confirms that fSGLD converges to
significantly flatter minima.

</details>


### [533] [ExGRPO: Learning to Reason from Experience](https://arxiv.org/abs/2510.02245)
*Runzhe Zhan,Yafu Li,Zhi Wang,Xiaoye Qu,Dongrui Liu,Jing Shao,Derek F. Wong,Yu Cheng*

Main category: cs.LG

TL;DR: 本研究提出了ExGRPO框架，通过组织和优先排序有价值的推理经验（基于正确性和熵），并采用混合策略目标来平衡探索与利用，从而提高大型语言模型的推理能力，并使训练更稳定。


<details>
  <summary>Details</summary>
Motivation: 标准策略训练方法在强化学习中的经验利用效率低下且不稳定，而对于大型推理模型，经验的价值特征及其对学习动态的影响研究不足。

Method: 提出ExGRPO（Experiential Group Relative Policy Optimization）框架，该框架组织和优先排序有价值的经验，并采用混合策略目标来平衡探索与经验利用。通过正确性和熵来评估经验价值。

Result: 在五个不同参数规模（1.5B-8B）的模型上进行实验，ExGRPO在数学和通用基准测试中均提高了推理性能，平均分别提升了3.5和7.6个点。此外，ExGRPO在策略内RLVR方法失败的情况下，能够稳定训练更强和更弱的模型。

Conclusion: 有效的经验管理是实现高效和可扩展的RLVR的关键因素。

Abstract: Reinforcement learning from verifiable rewards (RLVR) is an emerging paradigm
for improving the reasoning ability of large language models. However, standard
on-policy training discards rollout experiences after a single update, leading
to computational inefficiency and instability. While prior work on RL has
highlighted the benefits of reusing past experience, the role of experience
characteristics in shaping learning dynamics of large reasoning models remains
underexplored. In this paper, we are the first to investigate what makes a
reasoning experience valuable and identify rollout correctness and entropy as
effective indicators of experience value. Based on these insights, we propose
ExGRPO (Experiential Group Relative Policy Optimization), a framework that
organizes and prioritizes valuable experiences, and employs a mixed-policy
objective to balance exploration with experience exploitation. Experiments on
five backbone models (1.5B-8B parameters) show that ExGRPO consistently
improves reasoning performance on mathematical/general benchmarks, with an
average gain of +3.5/7.6 points over on-policy RLVR. Moreover, ExGRPO
stabilizes training on both stronger and weaker models where on-policy methods
fail. These results highlight principled experience management as a key
ingredient for efficient and scalable RLVR.

</details>


### [534] [GRACE: A Language Model Framework for Explainable Inverse Reinforcement Learning](https://arxiv.org/abs/2510.02180)
*Silvia Sapora,Devon Hjelm,Alexander Toshev,Omar Attia,Bogdan Mazoure*

Main category: cs.LG

TL;DR: GRACE是一种利用大型语言模型和进化搜索来从专家轨迹中生成可解释的、基于代码的奖励函数的方法，并在BabyAI和AndroidWorld基准测试中进行了验证。


<details>
  <summary>Details</summary>
Motivation: 传统的逆强化学习方法产生的“黑盒”模型难以解释和调试。

Method: 使用大型语言模型和进化搜索来直接从专家轨迹中反向工程可解释的、基于代码的奖励函数。

Result: GRACE在BabyAI和AndroidWorld基准测试中能够有效地学习到高精度奖励，即使在复杂的多任务环境中也是如此，并且学习到的奖励能够带来强大的策略，优于竞争性模仿学习和具有真实奖励的在线强化学习方法。

Conclusion: GRACE能够生成可检查和可验证的可执行奖励函数代码，并在多任务环境中构建复杂的奖励API。

Abstract: Inverse Reinforcement Learning aims to recover reward models from expert
demonstrations, but traditional methods yield "black-box" models that are
difficult to interpret and debug. In this work, we introduce GRACE (Generating
Rewards As CodE), a method for using Large Language Models within an
evolutionary search to reverse-engineer an interpretable, code-based reward
function directly from expert trajectories. The resulting reward function is
executable code that can be inspected and verified. We empirically validate
GRACE on the BabyAI and AndroidWorld benchmarks, where it efficiently learns
highly accurate rewards, even in complex, multi-task settings. Further, we
demonstrate that the resulting reward leads to strong policies, compared to
both competitive Imitation Learning and online RL approaches with ground-truth
rewards. Finally, we show that GRACE is able to build complex reward APIs in
multi-task setups.

</details>


### [535] [Detection of Chagas Disease from the ECG: The George B. Moody PhysioNet Challenge 2025](https://arxiv.org/abs/2510.02202)
*Matthew A. Reyna,Zuzana Koscova,Jan Pavlus,Soheil Saghafi,James Weigle,Andoni Elola,Salman Seyedi,Kiersten Campbell,Qiao Li,Ali Bahrami Rad,Antônio H. Ribeiro,Antonio Luiz P. Ribeiro,Reza Sameni,Gari D. Clifford*

Main category: cs.LG

TL;DR: Chagas病是一种寄生虫感染，主要通过昆虫传播，可导致心血管和消化系统疾病。由于血清学检测能力有限，该挑战赛旨在利用心电图（ECG）识别Chagas病，以优先考虑患者的检测和治疗。


<details>
  <summary>Details</summary>
Motivation: 慢性Chagas病可导致心血管疾病和消化系统问题，但血清学检测能力有限。心电图可以提供诊断线索，为优先检测和治疗患者提供了机会。

Method: George B. Moody PhysioNet 挑战赛 2025 邀请参赛者开发从心电图（ECG）识别Chagas病的算法方法。

Result: 本次挑战赛提供了包含患者报告和血清学检测标签的数据集，并进行了数据增强以提高模型的鲁棒性和泛化能力。采用的评估指标考虑了当地的血清学检测能力，将机器学习问题框定为分诊任务。

Conclusion: 本次挑战赛吸引了全球 630 多名参赛者和 111 支队伍，提交了 1300 多份参赛作品，展示了来自学术界和工业界的各种方法。

Abstract: Objective: Chagas disease is a parasitic infection that is endemic to South
America, Central America, and, more recently, the U.S., primarily transmitted
by insects. Chronic Chagas disease can cause cardiovascular diseases and
digestive problems. Serological testing capacities for Chagas disease are
limited, but Chagas cardiomyopathy often manifests in ECGs, providing an
opportunity to prioritize patients for testing and treatment. Approach: The
George B. Moody PhysioNet Challenge 2025 invites teams to develop algorithmic
approaches for identifying Chagas disease from electrocardiograms (ECGs). Main
results: This Challenge provides multiple innovations. First, we leveraged
several datasets with labels from patient reports and serological testing,
provided a large dataset with weak labels and smaller datasets with strong
labels. Second, we augmented the data to support model robustness and
generalizability to unseen data sources. Third, we applied an evaluation metric
that captured the local serological testing capacity for Chagas disease to
frame the machine learning problem as a triage task. Significance: Over 630
participants from 111 teams submitted over 1300 entries during the Challenge,
representing diverse approaches from academia and industry worldwide.

</details>


### [536] [Poolformer: Recurrent Networks with Pooling for Long-Sequence Modeling](https://arxiv.org/abs/2510.02206)
*Daniel Gallo Fernández*

Main category: cs.LG

TL;DR: Poolformer 使用池化操作替代自注意力机制，解决了长序列处理的效率问题，并在音频领域取得了优于现有模型的效果。


<details>
  <summary>Details</summary>
Motivation: 自注意力机制在处理长序列时存在二次方计算复杂度问题，限制了其应用。序列到序列模型需要处理时间维度上的信息交换。

Method: Poolformer 引入了包含残差块、下池化层、嵌套SkipBlock、上池化层和额外残差块的SkipBlocks，用循环层和池化操作替代自注意力机制以降低序列长度。

Result: 池化操作显著加速了训练，提高了FID和IS等感知指标，并防止了过拟合。实验表明，深层处理长距离依赖，浅层处理短时特征。

Conclusion: Poolformer 在长序列处理方面比 SaShiMi 和 Mamba 等模型表现更好，未来可应用于文本、视觉和多模态场景。

Abstract: Sequence-to-sequence models have become central in Artificial Intelligence,
particularly following the introduction of the transformer architecture. While
initially developed for Natural Language Processing, these models have
demonstrated utility across domains, including Computer Vision. Such models
require mechanisms to exchange information along the time dimension, typically
using recurrent or self-attention layers. However, self-attention scales
quadratically with sequence length, limiting its practicality for very long
sequences.
  We introduce Poolformer, a sequence-to-sequence model that replaces
self-attention with recurrent layers and incorporates pooling operations to
reduce sequence length. Poolformer is defined recursively using SkipBlocks,
which contain residual blocks, a down-pooling layer, a nested SkipBlock, an
up-pooling layer, and additional residual blocks. We conduct extensive
experiments to support our architectural choices.
  Our results show that pooling greatly accelerates training, improves
perceptual metrics (FID and IS), and prevents overfitting. Our experiments also
suggest that long-range dependencies are handled by deep layers, while shallow
layers take care of short-term features.
  Evaluated on raw audio, which naturally features long sequence lengths,
Poolformer outperforms state-of-the-art models such as SaShiMi and Mamba.
Future directions include applications to text and vision, as well as
multi-modal scenarios, where a Poolformer-based LLM could effectively process
dense representations of images and videos.

</details>


### [537] [Tree-based Dialogue Reinforced Policy Optimization for Red-Teaming Attacks](https://arxiv.org/abs/2510.02286)
*Ruohao Guo,Afshin Oroojlooy,Roshan Sridhar,Miguel Ballesteros,Alan Ritter,Dan Roth*

Main category: cs.LG

TL;DR: 现有的AI安全方法难以应对多轮对话中的对抗性攻击，本文提出了DialTree-RPO框架，利用强化学习和树搜索来自动发现多轮攻击策略，实验证明其效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的AI安全方法在多轮对话对抗性攻击方面存在不足，无法应对攻击者在对话中策略性地调整提示的情况。

Method: 提出DialTree-RPO框架，将对话视为序列决策问题，利用带树搜索的强化学习来自动发现多轮攻击策略。

Result: DialTree-RPO在10个目标模型上的攻击成功率（ASR）比现有最佳方法提高了25.9%，并发现了新的攻击策略。

Conclusion: DialTree-RPO能够有效发现多轮对话中的攻击策略，提升AI模型的安全性。

Abstract: Despite recent rapid progress in AI safety, current large language models
remain vulnerable to adversarial attacks in multi-turn interaction settings,
where attackers strategically adapt their prompts across conversation turns and
pose a more critical yet realistic challenge. Existing approaches that discover
safety vulnerabilities either rely on manual red-teaming with human experts or
employ automated methods using pre-defined templates and human-curated attack
data, with most focusing on single-turn attacks. However, these methods did not
explore the vast space of possible multi-turn attacks, failing to consider
novel attack trajectories that emerge from complex dialogue dynamics and
strategic conversation planning. This gap is particularly critical given recent
findings that LLMs exhibit significantly higher vulnerability to multi-turn
attacks compared to single-turn attacks. We propose DialTree-RPO, an on-policy
reinforcement learning framework integrated with tree search that autonomously
discovers diverse multi-turn attack strategies by treating the dialogue as a
sequential decision-making problem, enabling systematic exploration without
manually curated data. Through extensive experiments, our approach not only
achieves more than 25.9% higher ASR across 10 target models compared to
previous state-of-the-art approaches, but also effectively uncovers new attack
strategies by learning optimal dialogue policies that maximize attack success
across multiple turns.

</details>


### [538] [Interactive Training: Feedback-Driven Neural Network Optimization](https://arxiv.org/abs/2510.02297)
*Wentao Zhang,Yang Young Lu,Yuntian Deng*

Main category: cs.LG

TL;DR: 本框架允许人类专家或AI代理实时干预神经网络训练过程，以提高训练稳定性和适应性。


<details>
  <summary>Details</summary>
Motivation: 传统神经网络训练方法缺乏灵活性，无法动态应对训练中的不稳定性或问题。

Method: 通过一个控制服务器实现训练过程与用户/代理之间的实时通信，允许动态调整优化器超参数、训练数据和模型检查点。

Result: 在三个案例研究中，证明了该框架在提高训练稳定性、降低对初始超参数的敏感性以及增强适应不断变化的用户需求方面优于传统方法。

Conclusion: 该框架为未来AI代理自主监控训练日志、主动解决不稳定性并优化训练动态的训练范式铺平了道路。

Abstract: Traditional neural network training typically follows fixed, predefined
optimization recipes, lacking the flexibility to dynamically respond to
instabilities or emerging training issues. In this paper, we introduce
Interactive Training, an open-source framework that enables real-time,
feedback-driven intervention during neural network training by human experts or
automated AI agents. At its core, Interactive Training uses a control server to
mediate communication between users or agents and the ongoing training process,
allowing users to dynamically adjust optimizer hyperparameters, training data,
and model checkpoints. Through three case studies, we demonstrate that
Interactive Training achieves superior training stability, reduced sensitivity
to initial hyperparameters, and improved adaptability to evolving user needs,
paving the way toward a future training paradigm where AI agents autonomously
monitor training logs, proactively resolve instabilities, and optimize training
dynamics.

</details>


### [539] [DiFFPO: Training Diffusion LLMs to Reason Fast and Furious via Reinforcement Learning](https://arxiv.org/abs/2510.02212)
*Hanyang Zhao,Dawen Liang,Wenpin Tang,David Yao,Nathan Kallus*

Main category: cs.LG

TL;DR: DiFFPO通过强化学习（RL）加速和优化了扩散大语言模型（dLLM）的训练，提高了推理效率和任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有dLLM训练方法的不足，旨在提高推理速度和任务性能。

Method: 提出了一种统一的框架，包括：1. 通过离策略RL训练替代策略，使用两阶段似然近似和重要性采样校正；2. 联合训练高效采样器/控制器，自适应分配推理阈值。

Result: 在数学和规划任务上，DiFFPO在提高dLLM推理计算的帕累托前沿方面取得了最佳性能，实现了更高的准确性和更低的函数评估次数（NFEs）。

Conclusion: DiFFPO框架能够显著提高dLLM的推理速度和任务性能，同时保持或提高准确性。

Abstract: We propose DiFFPO, Diffusion Fast and Furious Policy Optimization, a unified
framework for training masked diffusion large language models (dLLMs) to reason
not only better (furious), but also faster via reinforcement learning (RL). We
first unify the existing baseline approach such as d1 by proposing to train
surrogate policies via off-policy RL, whose likelihood is much more tractable
as an approximation to the true dLLM policy. This naturally motivates a more
accurate and informative two-stage likelihood approximation combined with
importance sampling correction, which leads to generalized RL algorithms with
better sample efficiency and superior task performance. Second, we propose a
new direction of joint training efficient samplers/controllers of dLLMs policy.
Via RL, we incentivize dLLMs' natural multi-token prediction capabilities by
letting the model learn to adaptively allocate an inference threshold for each
prompt. By jointly training the sampler, we yield better accuracies with lower
number of function evaluations (NFEs) compared to training the model only,
obtaining the best performance in improving the Pareto frontier of the
inference-time compute of dLLMs. We showcase the effectiveness of our pipeline
by training open source large diffusion language models over benchmark math and
planning tasks.

</details>


### [540] [C2AL: Cohort-Contrastive Auxiliary Learning for Large-scale Recommendation Systems](https://arxiv.org/abs/2510.02215)
*Mertcan Cokbas,Ziteng Liu,Zeyi Tao,Chengkai Zhang,Elder Veliz,Qin Huang,Ellie Wen,Huayu Li,Qiang Jin,Murat Duman,Benjamin Au,Guy Lebanon,Sagar Chordia*

Main category: cs.LG

TL;DR: 大规模推荐模型训练中的同质性假设导致模型性能受限于中心分布模式，忽视了少数群体。本文提出一种名为C2AL的方法，通过分析数据集的子结构并利用辅助学习来解决这一问题，以改善对少数群体的推荐效果。


<details>
  <summary>Details</summary>
Motivation: 大规模推荐模型在单一全局目标下进行训练时，会隐含地假设用户群体具有同质性。然而，现实世界的数据是由具有不同条件分布的异质群体组成的。随着模型规模和复杂性的增加以及训练数据的增多，模型会逐渐被中心分布模式所主导，而忽视了头部和尾部区域的数据。这种不平衡限制了模型的学习能力，可能导致注意力权重失效或神经元死亡。

Method: 本文揭示了注意力机制在因子分解机中共享嵌入选择中的关键作用，并提出通过分析数据集中的子结构，利用辅助学习暴露具有强烈分布对比的子结构来解决这一挑战。与以往采用加权标签或多任务的方法不同，本文利用部分冲突的辅助标签来规范化共享表示。这种方法能够定制注意力层的学习过程，以保留与少数群体的互信息，同时提高整体性能。

Result: 在包含数十亿数据点的生产数据集上，对六种最先进的模型进行了C2AL评估。实验结果表明，因子分解机能够通过所提出的方法捕捉细粒度的用户-广告交互，整体归一化熵最多可降低0.16%，并在目标少数群体上实现了超过0.30%的性能提升。

Conclusion: C2AL通过分析子结构和利用辅助学习，有效解决了大规模推荐模型中因用户群体异质性而导致的性能下降问题，尤其是在少数群体上取得了显著的性能提升。

Abstract: Training large-scale recommendation models under a single global objective
implicitly assumes homogeneity across user populations. However, real-world
data are composites of heterogeneous cohorts with distinct conditional
distributions. As models increase in scale and complexity and as more data is
used for training, they become dominated by central distribution patterns,
neglecting head and tail regions. This imbalance limits the model's learning
ability and can result in inactive attention weights or dead neurons. In this
paper, we reveal how the attention mechanism can play a key role in
factorization machines for shared embedding selection, and propose to address
this challenge by analyzing the substructures in the dataset and exposing those
with strong distributional contrast through auxiliary learning. Unlike previous
research, which heuristically applies weighted labels or multi-task heads to
mitigate such biases, we leverage partially conflicting auxiliary labels to
regularize the shared representation. This approach customizes the learning
process of attention layers to preserve mutual information with minority
cohorts while improving global performance. We evaluated C2AL on massive
production datasets with billions of data points each for six SOTA models.
Experiments show that the factorization machine is able to capture fine-grained
user-ad interactions using the proposed method, achieving up to a 0.16%
reduction in normalized entropy overall and delivering gains exceeding 0.30% on
targeted minority cohorts.

</details>


### [541] [Diffusion Transformers for Imputation: Statistical Efficiency and Uncertainty Quantification](https://arxiv.org/abs/2510.02216)
*Zeqi Ye,Minshuo Chen*

Main category: cs.LG

TL;DR: 利用transformer近似条件分数函数，推导了用于填补的条件扩散transformer的统计样本复杂度界限，并构建了置信区域，研究了缺失模式对填补效率和精度的影响，并提出了一种混合掩码训练策略。


<details>
  <summary>Details</summary>
Motivation: 目前关于扩散模型如何捕捉缺失值和观测值之间的时空依赖性的理论理解有限。

Method: 推导了用于填补的条件扩散transformer的统计样本复杂度界限，并通过transformer的近似理论构建了缺失值的置信区域。

Result: 推导了统计样本复杂度界限，构建了置信区域，发现缺失模式影响填补效率和准确性，并验证了理论并提出了一种改进性能的混合掩码训练策略。

Conclusion: 扩散模型在填补时间序列数据方面表现优异，但理论理解有限。本研究填补了这一空白，提供了理论基础，并提出了改进实践的方法。

Abstract: Imputation methods play a critical role in enhancing the quality of practical
time-series data, which often suffer from pervasive missing values. Recently,
diffusion-based generative imputation methods have demonstrated remarkable
success compared to autoregressive and conventional statistical approaches.
Despite their empirical success, the theoretical understanding of how well
diffusion-based models capture complex spatial and temporal dependencies
between the missing values and observed ones remains limited. Our work
addresses this gap by investigating the statistical efficiency of conditional
diffusion transformers for imputation and quantifying the uncertainty in
missing values. Specifically, we derive statistical sample complexity bounds
based on a novel approximation theory for conditional score functions using
transformers, and, through this, construct tight confidence regions for missing
values. Our findings also reveal that the efficiency and accuracy of imputation
are significantly influenced by the missing patterns. Furthermore, we validate
these theoretical insights through simulation and propose a mixed-masking
training strategy to enhance the imputation performance.

</details>


### [542] [Efficiently Generating Correlated Sample Paths from Multi-step Time Series Foundation Models](https://arxiv.org/abs/2510.02224)
*Ethan Baron,Boris Oreshkin,Ruijun Ma,Hanyu Zhang,Kari Torkkola,Michael W. Mahoney,Andrew Gordon Wilson,Tatiana Konstantinova*

Main category: cs.LG

TL;DR: 提出了一种基于 copula 的方法，可以从现有的多步时间序列基础模型中高效地生成准确、相关的样本路径，从而克服了自回归采样的成本问题并改善了样本路径质量。


<details>
  <summary>Details</summary>
Motivation: 现有的时间序列基础模型在生成多步预测样本路径时，仅预测独立的时间步长边缘分布，而非完整的联合预测分布，导致生成具有真实相关结构的样本路径时，需要依赖成本高昂的自回归采样，并存在累积误差问题。

Method: 提出了一种基于 copula 的方法，该方法可以在一次前向传播中，从现有的多步时间序列基础模型中高效地生成准确、相关的样本路径。

Result: 该方法生成的样本路径比自回归采样快几个数量级，并且通过缓解累积误差现象，提高了样本路径的质量。

Conclusion: 基于 copula 的方法能够高效、准确地生成多步时间序列预测的样本路径，克服了现有方法的局限性。

Abstract: Many time series applications require access to multi-step forecast
trajectories in the form of sample paths. Recently, time series foundation
models have leveraged multi-step lookahead predictions to improve the quality
and efficiency of multi-step forecasts. However, these models only predict
independent marginal distributions for each time step, rather than a full joint
predictive distribution. To generate forecast sample paths with realistic
correlation structures, one typically resorts to autoregressive sampling, which
can be extremely expensive. In this paper, we present a copula-based approach
to efficiently generate accurate, correlated sample paths from existing
multi-step time series foundation models in one forward pass. Our copula-based
approach generates correlated sample paths orders of magnitude faster than
autoregressive sampling, and it yields improved sample path quality by
mitigating the snowballing error phenomenon.

</details>


### [543] [xLSTM Scaling Laws: Competitive Performance with Linear Time-Complexity](https://arxiv.org/abs/2510.02228)
*Maximilian Beck,Kajetan Schweighofer,Sebastian Böck,Sebastian Lehner,Sepp Hochreiter*

Main category: cs.LG

TL;DR: xLSTM在LLM的扩展规律方面与Transformer相当，并且在典型场景下具有优势，尤其是在上下文长度增加时。


<details>
  <summary>Details</summary>
Motivation: 在LLM成功的背景下，研究Transformer和xLSTM等替代架构的扩展规律，为未来模型设计和部署提供指导。

Method: 1.研究xLSTM在计算最优和过拟合情况下的扩展行为，使用IsoFLOP和参数拟合方法，并涵盖80M到7B的模型大小和2B到2T的训练token数量。 2.考察模型大小对上下文长度的依赖性。 3.分析推理时间扩展特性。

Result: xLSTM在LLM的训练和推理场景中扩展性优于Transformer，并且这种优势随着训练和推理上下文的增长而扩大。

Conclusion: xLSTM在LLM的扩展规律方面与Transformer相当，并且在典型场景下具有优势，尤其是在上下文长度增加时。

Abstract: Scaling laws play a central role in the success of Large Language Models
(LLMs), enabling the prediction of model performance relative to compute
budgets prior to training. While Transformers have been the dominant
architecture, recent alternatives such as xLSTM offer linear complexity with
respect to context length while remaining competitive in the billion-parameter
regime. We conduct a comparative investigation on the scaling behavior of
Transformers and xLSTM along the following lines, providing insights to guide
future model design and deployment. First, we study the scaling behavior for
xLSTM in compute-optimal and over-training regimes using both IsoFLOP and
parametric fit approaches on a wide range of model sizes (80M-7B) and number of
training tokens (2B-2T). Second, we examine the dependence of optimal model
sizes on context length, a pivotal aspect that was largely ignored in previous
work. Finally, we analyze inference-time scaling characteristics. Our findings
reveal that in typical LLM training and inference scenarios, xLSTM scales
favorably compared to Transformers. Importantly, xLSTM's advantage widens as
training and inference contexts grow.

</details>


### [544] [PUL-Inter-slice Defender: An Anomaly Detection Solution for Distributed Slice Mobility Attacks](https://arxiv.org/abs/2510.02236)
*Ricardo Misael Ayala Molina,Hyame Assem Alameddine,Makan Pourzandi,Chadi Assi*

Main category: cs.LG

TL;DR: 本研究提出了一种名为 PUL-Inter-Slice Defender 的异常检测解决方案，用于防御 5G 网络中的分布式切片移动 (DSM) 攻击。该解决方案结合了正负无标签学习 (PUL)、长短期记忆自编码器 (LSTM AE) 和 K-Means 聚类技术，并利用 3GPP 关键性能指标和性能测量计数器作为特征。实验结果表明，PUL-Inter-Slice Defender 在存在高达 40% 攻击污染的数据集上仍能达到超过 98.50% 的 F1 分数，性能优于其他对比方案。


<details>
  <summary>Details</summary>
Motivation: 5G 网络中的用户设备 (UE) 可以连接并无缝切换多个网络切片 (NS)，以访问多样化服务。然而，这种称为跨切片切换 (ISS) 的灵活性可能被利用来发起分布式切片移动 (DSM) 攻击，这是一种分布式拒绝服务 (DDoS) 攻击。因此，有必要保护 5G 网络及其 NS 免受 DSM 攻击。

Method: 本研究提出了一种名为 PUL-Inter-Slice Defender 的异常检测解决方案。该方案利用正负无标签学习 (PUL)，并结合了长短期记忆自编码器 (LSTM AE) 和 K-Means 聚类技术。它利用第三代合作伙伴项目 (3GPP) 的关键性能指标和性能测量计数器作为特征，用于检测 DSM 攻击的变体。该方法旨在在存在污染的训练数据的情况下保持鲁棒性。

Result: 在基于 free5GC 和 UERANSIM 的 5G 测试台上收集的数据上进行评估，PUL-Inter-Slice Defender 在训练数据包含 10% 到 40% 攻击污染的情况下，F1 分数超过了 98.50%。该方案始终优于其对应方案 Inter-Slice Defender 以及其他结合了 OC-SVM 与随机森林和 XGBoost 的 PUL 方案。

Conclusion: PUL-Inter-Slice Defender 是一种有效的异常检测解决方案，能够成功防御 5G 网络中的分布式切片移动 (DSM) 攻击。该方法在存在污染训练数据的情况下表现出鲁棒性，并且在实际性能评估中优于其他现有技术。

Abstract: Network Slices (NSs) are virtual networks operating over a shared physical
infrastructure, each designed to meet specific application requirements while
maintaining consistent Quality of Service (QoS). In Fifth Generation (5G)
networks, User Equipment (UE) can connect to and seamlessly switch between
multiple NSs to access diverse services. However, this flexibility, known as
Inter-Slice Switching (ISS), introduces a potential vulnerability that can be
exploited to launch Distributed Slice Mobility (DSM) attacks, a form of
Distributed Denial of Service (DDoS) attack. To secure 5G networks and their
NSs against DSM attacks, we present in this work, PUL-Inter-Slice Defender; an
anomaly detection solution that leverages Positive Unlabeled Learning (PUL) and
incorporates a combination of Long Short-Term Memory Autoencoders and K-Means
clustering. PUL-Inter-Slice Defender leverages the Third Generation Partnership
Project (3GPP) key performance indicators and performance measurement counters
as features for its machine learning models to detect DSM attack variants while
maintaining robustness in the presence of contaminated training data. When
evaluated on data collected from our 5G testbed based on the open-source
free5GC and UERANSIM, a UE/ Radio Access Network (RAN) simulator;
PUL-Inter-Slice Defender achieved F1-scores exceeding 98.50% on training
datasets with 10% to 40% attack contamination, consistently outperforming its
counterpart Inter-Slice Defender and other PUL based solutions combining
One-Class Support Vector Machine (OCSVM) with Random Forest and XGBoost.

</details>


### [545] [Drop-Muon: Update Less, Converge Faster](https://arxiv.org/abs/2510.02239)
*Kaja Gruntkowska,Yassine Maziane,Zheng Qu,Peter Richtárik*

Main category: cs.LG

TL;DR: 该研究提出了一种名为Drop-Muon的新型优化方法，通过仅更新部分网络层来挑战深度学习中所有层都更新的传统观点，并在理论和实践中都证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: 深度学习优化中的传统观点是每个步骤都更新所有层，但该研究挑战了这一假设，认为这种方法可能不是最优的。

Method: 提出了一种名为Drop-Muon的非欧氏随机渐进训练方法，该方法根据随机计划仅更新部分层，结合了渐进训练的效率和层特定的非欧氏更新。

Result: 在层级平滑和层级 $(L^0, L^1)$ -平滑下提供了严格的收敛保证，覆盖了确定性和随机梯度设置。成本分析表明，除非层平滑常数之间存在特定关系，否则全网络更新并非最优。实验证明Drop-Muon的训练速度比全网络Muon快1.4倍，同时达到相同的准确率。

Conclusion: 研究结果表明，可以通过仅更新部分网络层来更有效地训练大规模模型，挑战了全网络更新的现状，并提供了一种高效且有理论依据的替代方案。

Abstract: Conventional wisdom in deep learning optimization dictates updating all
layers at every step-a principle followed by all recent state-of-the-art
optimizers such as Muon. In this work, we challenge this assumption, showing
that full-network updates can be fundamentally suboptimal, both in theory and
in practice. We introduce a non-Euclidean Randomized Progressive Training
method-Drop-Muon-a simple yet powerful framework that updates only a subset of
layers per step according to a randomized schedule, combining the efficiency of
progressive training with layer-specific non-Euclidean updates for top-tier
performance. We provide rigorous convergence guarantees under both layer-wise
smoothness and layer-wise $(L^0, L^1)$-smoothness, covering deterministic and
stochastic gradient settings, marking the first such results for progressive
training in the stochastic and non-smooth regime. Our cost analysis further
reveals that full-network updates are not optimal unless a very specific
relationship between layer smoothness constants holds. Through controlled CNN
experiments, we empirically demonstrate that Drop-Muon consistently outperforms
full-network Muon, achieving the same accuracy up to $1.4\times$ faster in
wall-clock time. Together, our results suggest a shift in how large-scale
models can be efficiently trained, challenging the status quo and offering a
highly efficient, theoretically grounded alternative to full-network updates.

</details>


### [546] [Diffusion^2: Turning 3D Environments into Radio Frequency Heatmaps](https://arxiv.org/abs/2510.02274)
*Kyoungjun Park,Yifan Yang,Changhan Ge,Lili Qiu,Shiqi Jiang*

Main category: cs.LG

TL;DR: Diffusion^2利用3D点云和RF-3D编码器来模拟不同频率下射频信号的传播，在合成和真实世界测量中表现出高精度和高效率。


<details>
  <summary>Details</summary>
Motivation: 射频信号在理解环境和支持无线诊断、部署及优化方面具有RGB相机无法比拟的优势，但精确预测其在复杂环境中的传播仍具挑战性。

Method: 提出了一种基于扩散的方法Diffusion^2，使用3D点云并结合RF-3D编码器来捕获射频相关特征，然后进行多尺度嵌入以模拟信号传播过程。

Result: 在合成和真实世界测量中，Diffusion^2能够准确估计不同频段和环境下的射频信号行为，误差仅为1.9 dB，并且速度比现有方法快27倍。

Conclusion: Diffusion^2在射频信号建模领域取得了显著进展，能够高精度、高效率地预测射频信号在复杂环境中的传播。

Abstract: Modeling radio frequency (RF) signal propagation is essential for
understanding the environment, as RF signals offer valuable insights beyond the
capabilities of RGB cameras, which are limited by the visible-light spectrum,
lens coverage, and occlusions. It is also useful for supporting wireless
diagnosis, deployment, and optimization. However, accurately predicting RF
signals in complex environments remains a challenge due to interactions with
obstacles such as absorption and reflection. We introduce Diffusion^2, a
diffusion-based approach that uses 3D point clouds to model the propagation of
RF signals across a wide range of frequencies, from Wi-Fi to millimeter waves.
To effectively capture RF-related features from 3D data, we present the RF-3D
Encoder, which encapsulates the complexities of 3D geometry along with
signal-specific details. These features undergo multi-scale embedding to
simulate the actual RF signal dissemination process. Our evaluation, based on
synthetic and real-world measurements, demonstrates that Diffusion^2 accurately
estimates the behavior of RF signals in various frequency bands and
environmental conditions, with an error margin of just 1.9 dB and 27x faster
than existing methods, marking a significant advancement in the field. Refer to
https://rfvision-project.github.io/ for more information.

</details>


### [547] [Fine-Grained Urban Traffic Forecasting on Metropolis-Scale Road Networks](https://arxiv.org/abs/2510.02278)
*Fedor Velikonivtsev,Oleg Platonov,Gleb Bazhenov,Liudmila Prokhorenkova*

Main category: cs.LG

TL;DR: 该论文发布了两个大规模的城市交通数据集，并提出了一个可扩展的图神经网络模型来解决现有数据集和模型在大规模城市交通预测中面临的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有交通预测基准数据集存在道路连通性信息缺失、道路属性信息有限、规模不足以及主要关注城际高速公路而非更复杂的城市路网等问题。同时，现有的时空图神经网络模型在大规模数据集上存在扩展性问题。

Method: 发布了包含丰富道路特征和精细交通流量、速度数据的两个大规模城市交通数据集。提出了一种不依赖专门时间序列处理模块的图神经网络模型，以提高模型的可扩展性并提升预测性能。

Result: 所提出的模型在发布的大规模数据集上表现出比现有方法更好的可扩展性和预测性能。

Conclusion: 该论文通过发布新的大规模城市交通数据集和提出一个可扩展的图神经网络模型，为交通预测研究提供了有价值的资源和新的研究方向。

Abstract: Traffic forecasting on road networks is a complex task of significant
practical importance that has recently attracted considerable attention from
the machine learning community, with spatiotemporal graph neural networks
(GNNs) becoming the most popular approach. The proper evaluation of traffic
forecasting methods requires realistic datasets, but current publicly available
benchmarks have significant drawbacks, including the absence of information
about road connectivity for road graph construction, limited information about
road properties, and a relatively small number of road segments that falls
short of real-world applications. Further, current datasets mostly contain
information about intercity highways with sparsely located sensors, while city
road networks arguably present a more challenging forecasting task due to much
denser roads and more complex urban traffic patterns. In this work, we provide
a more complete, realistic, and challenging benchmark for traffic forecasting
by releasing datasets representing the road networks of two major cities, with
the largest containing almost 100,000 road segments (more than a 10-fold
increase relative to existing datasets). Our datasets contain rich road
features and provide fine-grained data about both traffic volume and traffic
speed, allowing for building more holistic traffic forecasting systems. We show
that most current implementations of neural spatiotemporal models for traffic
forecasting have problems scaling to datasets of our size. To overcome this
issue, we propose an alternative approach to neural traffic forecasting that
uses a GNN without a dedicated module for temporal sequence processing, thus
achieving much better scalability, while also demonstrating stronger
forecasting performance. We hope our datasets and modeling insights will serve
as a valuable resource for research in traffic forecasting.

</details>


### [548] [Addressing Pitfalls in the Evaluation of Uncertainty Estimation Methods for Natural Language Generation](https://arxiv.org/abs/2510.02279)
*Mykyta Ielanskyi,Kajetan Schweighofer,Lukas Aichberger,Sepp Hochreiter*

Main category: cs.LG

TL;DR: LLM幻觉，特别是“混淆”现象，源于模型的不确定性。现有检测方法在评估时存在分歧，可能导致结果偏差。本文提出使用多种风险指标，并结合LLM-as-a-judge变体、结构化任务、分布外检测等方法，以提高评估的鲁棒性。最后，建议使用Elo评级系统来客观总结不确定性估计方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有用于检测LLM幻觉（特别是混淆）的方法，在评估不确定性估计（UE）算法时，由于近似正确性函数的分歧，存在评估偏差和结果不一致的问题。

Method: 提出使用多种替代风险指标，并结合LLM-as-a-judge变体、结构化任务、分布外检测和扰动检测任务，以提高对UE算法的经验评估的鲁棒性。最后，提议使用Elo评级系统对UE方法进行客观总结。

Result: 通过引入更鲁棒的风险指标和评估策略，可以减少对UE算法评估的偏差，并为不同设置下的UE方法提供更客观的比较。

Conclusion: 本文提出的改进评估方法（包括风险指标、LLM-as-a-judge变体、结构化任务、分布外检测和Elo评级）能够更可靠地评估自然语言生成中的不确定性估计方法，从而更好地解决LLM幻觉问题。

Abstract: Hallucinations are a common issue that undermine the reliability of large
language models (LLMs). Recent studies have identified a specific subset of
hallucinations, known as confabulations, which arise due to predictive
uncertainty of LLMs. To detect confabulations, various methods for estimating
predictive uncertainty in natural language generation (NLG) have been
developed. These methods are typically evaluated by correlating uncertainty
estimates with the correctness of generated text, with question-answering (QA)
datasets serving as the standard benchmark. However, commonly used approximate
correctness functions have substantial disagreement between each other and,
consequently, in the ranking of the uncertainty estimation methods. This allows
one to inflate the apparent performance of uncertainty estimation methods. We
propose using several alternative risk indicators for risk correlation
experiments that improve robustness of empirical assessment of UE algorithms
for NLG. For QA tasks, we show that marginalizing over multiple LLM-as-a-judge
variants leads to reducing the evaluation biases. Furthermore, we explore
structured tasks as well as out of distribution and perturbation detection
tasks which provide robust and controllable risk indicators. Finally, we
propose to use an Elo rating of uncertainty estimation methods to give an
objective summarization over extensive evaluation settings.

</details>


### [549] [Knowledge Distillation Detection for Open-weights Models](https://arxiv.org/abs/2510.02302)
*Qin Shi,Amber Yijia Zheng,Qifan Song,Raymond A. Yeh*

Main category: cs.LG

TL;DR: 该研究提出了一种名为“知识蒸馏检测”的任务，旨在判断学生模型是否由给定的教师模型通过蒸馏产生，并且该方法可以在只有学生模型权重和教师模型API可用的实际场景下进行。该方法结合了无数据输入合成和统计分数计算，适用于分类和生成模型，并在图像分类和文本到图像生成任务上取得了显著的检测精度提升。


<details>
  <summary>Details</summary>
Motivation: 模型溯源和未经授权的通过蒸馏进行复制的需求日益增长。

Method: 提出了一种模型无关的框架，该框架结合了无数据输入合成和统计分数计算来检测蒸馏。

Result: 在CIFAR-10、ImageNet和文本到图像生成任务上，该方法相比现有方法在检测精度上分别提高了59.6%、71.2%和20.0%。

Conclusion: 所提出的知识蒸馏检测方法在实际场景下是有效的，并且能够显著优于现有的基线方法。

Abstract: We propose the task of knowledge distillation detection, which aims to
determine whether a student model has been distilled from a given teacher,
under a practical setting where only the student's weights and the teacher's
API are available. This problem is motivated by growing concerns about model
provenance and unauthorized replication through distillation. To address this
task, we introduce a model-agnostic framework that combines data-free input
synthesis and statistical score computation for detecting distillation. Our
approach is applicable to both classification and generative models.
Experiments on diverse architectures for image classification and text-to-image
generation show that our method improves detection accuracy over the strongest
baselines by 59.6% on CIFAR-10, 71.2% on ImageNet, and 20.0% for text-to-image
generation. The code is available at
https://github.com/shqii1j/distillation_detection.

</details>


### [550] [Diffusion Models and the Manifold Hypothesis: Log-Domain Smoothing is Geometry Adaptive](https://arxiv.org/abs/2510.02305)
*Tyler Farghly,Peter Potaptchik,Samuel Howard,George Deligiannidis,Jakiw Pidstrigach*

Main category: cs.LG

TL;DR: 扩散模型在多个领域表现出色，但其潜在机制仍未完全阐明。本研究通过分数匹配的视角，为扩散模型能适应数据低维几何结构（即流形假说）的猜想提供了证据。


<details>
  <summary>Details</summary>
Motivation: 探究扩散模型强大泛化能力的潜在机制，特别是其适应数据低维几何结构的能力。

Method: 通过研究平滑经验分数匹配目标函数的最小化器来检查隐式正则化的作用，并分析分数函数平滑（或对数密度域中的平滑）对数据流形的影响。

Result: 理论和实证结果表明，平滑分数函数能产生与数据流形相切的平滑效果，并且可以通过选择合适的平滑度来控制扩散模型泛化的流形。

Conclusion: 本研究为扩散模型适应数据流形的能力提供了理论和实证支持，并揭示了可以通过平滑度来控制泛化流形。

Abstract: Diffusion models have achieved state-of-the-art performance, demonstrating
remarkable generalisation capabilities across diverse domains. However, the
mechanisms underpinning these strong capabilities remain only partially
understood. A leading conjecture, based on the manifold hypothesis, attributes
this success to their ability to adapt to low-dimensional geometric structure
within the data. This work provides evidence for this conjecture, focusing on
how such phenomena could result from the formulation of the learning problem
through score matching. We inspect the role of implicit regularisation by
investigating the effect of smoothing minimisers of the empirical score
matching objective. Our theoretical and empirical results confirm that
smoothing the score function -- or equivalently, smoothing in the log-density
domain -- produces smoothing tangential to the data manifold. In addition, we
show that the manifold along which the diffusion model generalises can be
controlled by choosing an appropriate smoothing.

</details>


### [551] [Robust Tangent Space Estimation via Laplacian Eigenvector Gradient Orthogonalization](https://arxiv.org/abs/2510.02308)
*Dhruv Kohli,Sawyer J. Robertson,Gal Mishne,Alexander Cloninger*

Main category: cs.LG

TL;DR: LEGO是一种新的谱方法，用于估计数据流形上的切空间，比传统的LPCA更能抵抗噪声。


<details>
  <summary>Details</summary>
Motivation: 标准方法LPCA在噪声大的情况下表现不佳，因为需要预先知道数据的几何和噪声特征，而这通常是不可用的。

Method: LEGO利用图拉普拉斯算子的低频特征向量的梯度来估计切空间，而不是仅仅依赖于局部邻域。

Result: LEGO在各种下游任务中，如流形学习、边界检测和局部内在维度估计，都比LPCA有显著的改进。

Conclusion: LEGO是一种比LPCA更能抵抗噪声的切空间估计方法，它利用了数据的全局结构，并通过理论和实验得到了验证。

Abstract: Estimating the tangent spaces of a data manifold is a fundamental problem in
data analysis. The standard approach, Local Principal Component Analysis
(LPCA), struggles in high-noise settings due to a critical trade-off in
choosing the neighborhood size. Selecting an optimal size requires prior
knowledge of the geometric and noise characteristics of the data that are often
unavailable. In this paper, we propose a spectral method, Laplacian Eigenvector
Gradient Orthogonalization (LEGO), that utilizes the global structure of the
data to guide local tangent space estimation. Instead of relying solely on
local neighborhoods, LEGO estimates the tangent space at each data point by
orthogonalizing the gradients of low-frequency eigenvectors of the graph
Laplacian. We provide two theoretical justifications of our method. First, a
differential geometric analysis on a tubular neighborhood of a manifold shows
that gradients of the low-frequency Laplacian eigenfunctions of the tube align
closely with the manifold's tangent bundle, while an eigenfunction with high
gradient in directions orthogonal to the manifold lie deeper in the spectrum.
Second, a random matrix theoretic analysis also demonstrates that low-frequency
eigenvectors are robust to sub-Gaussian noise. Through comprehensive
experiments, we demonstrate that LEGO yields tangent space estimates that are
significantly more robust to noise than those from LPCA, resulting in marked
improvements in downstream tasks such as manifold learning, boundary detection,
and local intrinsic dimension estimation.

</details>


### [552] [KaVa: Latent Reasoning via Compressed KV-Cache Distillation](https://arxiv.org/abs/2510.02312)
*Anna Kuzina,Maciej Pioro,Paul N. Whatmough,Babak Ehteshami Bejnordi*

Main category: cs.LG

TL;DR: KaVa框架通过从教师模型的压缩KV缓存中蒸馏知识到潜式推理学生模型中，解决了潜式推理缺乏监督的问题，提高了效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统的思维链（CoT）方法在处理多步推理问题时计算成本高、内存开销大，并且存在冗余信息。潜式推理虽然效率高，但缺乏监督，限制了其在复杂推理任务中的表现。

Method: 提出KaVa框架，利用自蒸馏技术，将教师模型的压缩KV缓存中的知识提取出来，并传递给潜式推理的学生模型。该框架利用连续潜式令牌的表示灵活性，对齐逐步的KV轨迹，实现了对抽象、非结构化知识的监督。

Result: KaVa框架在实验中表现优于现有的潜式推理基线模型，能够有效处理从方程到自然语言的推理任务，并且在扩展到更大的模型时仍能保持高效。

Conclusion: 压缩KV缓存蒸馏是一种可扩展的潜式推理监督信号，结合了CoT训练教师模型的准确性和潜式推理的效率及可部署性。

Abstract: Large Language Models (LLMs) excel at multi-step reasoning problems with
explicit chain-of-thought (CoT), but verbose traces incur significant
computational costs and memory overhead, and often carry redundant, stylistic
artifacts. Latent reasoning has emerged as an efficient alternative that
internalizes the thought process, but it suffers from a critical lack of
supervision, limiting its effectiveness on complex, natural-language reasoning
traces. In this work, we propose KaVa, the first framework that bridges this
gap by distilling knowledge directly from a compressed KV-cache of the teacher
into a latent-reasoning student via self-distillation, leveraging the
representational flexibility of continuous latent tokens to align stepwise KV
trajectories. We show that the abstract, unstructured knowledge within
compressed KV-cache, which lacks direct token correspondence, can serve as a
rich supervisory signal for a latent reasoning student. Empirically, the
approach consistently outperforms strong latent baselines, exhibits markedly
smaller degradation from equation-only to natural-language traces, and scales
to larger backbones while preserving efficiency. These results establish
compressed KV-cache distillation as a scalable supervision signal for latent
reasoning, combining the accuracy of CoT-trained teachers with the efficiency
and deployability of latent inference.

</details>
