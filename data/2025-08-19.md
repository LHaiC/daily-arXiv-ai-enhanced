<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 156]
- [cs.CL](#cs.CL) [Total: 81]
- [eess.SY](#eess.SY) [Total: 25]
- [cs.DS](#cs.DS) [Total: 5]
- [physics.app-ph](#physics.app-ph) [Total: 3]
- [cs.DC](#cs.DC) [Total: 8]
- [quant-ph](#quant-ph) [Total: 56]
- [cs.GT](#cs.GT) [Total: 3]
- [cs.AI](#cs.AI) [Total: 55]
- [cs.RO](#cs.RO) [Total: 47]
- [cs.GR](#cs.GR) [Total: 5]
- [cs.LG](#cs.LG) [Total: 110]
- [cs.SI](#cs.SI) [Total: 7]
- [cs.AR](#cs.AR) [Total: 10]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 21]
- [eess.SP](#eess.SP) [Total: 44]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 28]
- [cs.NE](#cs.NE) [Total: 8]
- [cs.LO](#cs.LO) [Total: 6]
- [cs.MA](#cs.MA) [Total: 5]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [A Deep Learning-Based CCTV System for Automatic Smoking Detection in Fire Exit Zones](https://arxiv.org/abs/2508.11696)
*Sami Sadat,Mohammad Irtiza Hossain,Junaid Ahmed Sifat,Suhail Haque Rafi,Md. Waseq Alauddin Alvi,Md. Khalilur Rhaman*

Main category: cs.CV

TL;DR: 提出了一种用于 CCTV 监控的深度学习吸烟检测系统，该系统基于 YOLOv8 进行了优化，在具有挑战性的环境中实现了高性能，并适用于边缘设备。


<details>
  <summary>Details</summary>
Motivation: 由于关键的安全要求，需要一个用于 CCTV 监控火灾出口区域的深度学习实时吸烟检测系统。

Method: 提出了一种深度学习实时吸烟检测系统，并针对 CCTV 监控火灾出口区域进行了优化。评估了 YOLOv8、YOLOv11 和 YOLOv12 三种先进的目标检测模型，并开发了一个源自 YOLOv8 的定制模型，增加了针对具有挑战性的监控环境的结构。

Result: 所提出的定制模型在性能上优于其他模型，在 50% mAP 下达到了 78.90% 的召回率和 83.70% 的 mAP。在 Jetson Xavier NX 等边缘设备上的性能评估显示，每秒推理时间为 52 至 97 毫秒。

Conclusion: 所提出的基于 YOLOv8 的定制模型在具有挑战性的监控环境中提供了最佳的目标检测性能，召回率为 78.90%，在 50% mAP 下为 83.70%，并且该系统适用于时间敏感的操作。

Abstract: A deep learning real-time smoking detection system for CCTV surveillance of
fire exit areas is proposed due to critical safety requirements. The dataset
contains 8,124 images from 20 different scenarios along with 2,708 raw samples
demonstrating low-light areas. We evaluated three advanced object detection
models: YOLOv8, YOLOv11, and YOLOv12, followed by development of a custom model
derived from YOLOv8 with added structures for challenging surveillance
contexts. The proposed model outperformed the others, achieving a recall of
78.90 percent and mAP at 50 of 83.70 percent, delivering optimal object
detection across varied environments. Performance evaluation on multiple edge
devices using multithreaded operations showed the Jetson Xavier NX processed
data at 52 to 97 milliseconds per inference, establishing its suitability for
time-sensitive operations. This system offers a robust and adaptable platform
for monitoring public safety and enabling automatic regulatory compliance.

</details>


### [2] [Separating Knowledge and Perception with Procedural Data](https://arxiv.org/abs/2508.11697)
*Adrián Rodríguez-Muñoz,Manel Baradad,Phillip Isola,Antonio Torralba*

Main category: cs.CV

TL;DR: 本文提出一种仅使用程序化数据训练的视觉模型，并结合视觉记忆技术，在不接触真实数据的情况下，在视觉相似性、分类和分割任务上取得了与使用真实数据训练的模型相当甚至更优的性能。研究还分析了程序化模型在表示物体部件相似性上的不足，解释了性能差距的原因。


<details>
  <summary>Details</summary>
Motivation: 本文的动机在于探索仅使用程序化数据训练模型，并通过视觉记忆技术在各种视觉任务上（视觉相似性、分类、语义分割）取得与使用真实数据训练的模型相媲美，甚至超越的性能，同时实现与真实世界图像的完全隔离。

Method: 我们仅使用程序化数据训练表示模型，并通过视觉记忆（一个明确的参考图像嵌入数据库）将其应用于视觉相似性、分类和语义分割任务，而无需进一步训练。与以往的视觉记忆方法不同，我们的方法在与所有真实世界图像完全隔离的情况下，仍然保持了强大的性能。

Result: 我们的程序化模型在视觉相似性、细粒度分类和标准分类任务上表现出色，与使用真实数据训练的模型相比，在多个基准测试中表现相当或更优。在零样本语义分割方面也显示出强大的能力。分析表明，程序化模型在表示物体部件的相似性上存在不足，这是导致性能差距的主要原因。

Conclusion: 与在Places上训练的模型相比，我们的程序化模型在NIGHTS视觉相似性上表现接近（相差1%），在CUB200和Flowers102细粒度分类上分别超出8%和15%，在ImageNet-1K分类上相差10%。此外，它在COCO数据集上的零样本分割表现强劲，R^2分数仅比在真实数据上训练的模型低10%。最后，我们分析了程序化与真实数据模型，发现同一物体不同部分在程序化模型中的表示存在差异，导致记忆搜索错误，这解释了剩余的性能差距。

Abstract: We train representation models with procedural data only, and apply them on
visual similarity, classification, and semantic segmentation tasks without
further training by using visual memory -- an explicit database of reference
image embeddings. Unlike prior work on visual memory, our approach achieves
full compartmentalization with respect to all real-world images while retaining
strong performance. Compared to a model trained on Places, our procedural model
performs within $1\%$ on NIGHTS visual similarity, outperforms by $8\%$ and
$15\%$ on CUB200 and Flowers102 fine-grained classification, and is within
$10\%$ on ImageNet-1K classification. It also demonstrates strong zero-shot
segmentation, achieving an $R^2$ on COCO within $10\%$ of the models trained on
real data. Finally, we analyze procedural versus real data models, showing that
parts of the same object have dissimilar representations in procedural models,
resulting in incorrect searches in memory and explaining the remaining
performance gap.

</details>


### [3] [FusionFM: Fusing Eye-specific Foundational Models for Optimized Ophthalmic Diagnosis](https://arxiv.org/abs/2508.11721)
*Ke Zou,Jocelyn Hui Lin Goh,Yukun Zhou,Tian Lin,Samantha Min Er Yew,Sahana Srinivasan,Meng Wang,Rui Santos,Gabor M. Somfai,Huazhu Fu,Haoyu Chen,Pearse A. Keane,Ching-Yu Cheng,Yih Chung Tham*

Main category: cs.CV

TL;DR: 该研究首次系统评估并融合了眼科基础模型（FMs），发现RetiZero和DINORET表现最佳，融合策略能带来适度提升，但系统性疾病预测仍有待改进。


<details>
  <summary>Details</summary>
Motivation: 目前尚不清楚哪种眼科FM表现最佳、在不同任务上的表现是否均等，以及融合所有FM是否能带来更好的效果。

Method: 1. 提出FusionFM评估套件和两种融合方法（基于门控和集合）。
2. 评估四种先进的眼科FM（RETFound, VisionFM, RetiZero, DINORET）。
3. 评估任务包括眼科疾病检测（青光眼、糖尿病视网膜病变、年龄相关性黄斑变性）和系统性疾病预测（糖尿病、高血压）。
4. 使用来自多个国家的标准化数据集进行基准测试。
5. 使用AUC和F1指标评估模型性能。

Result: DINORET和RetiZero在眼科和系统性疾病任务中表现优越，RetiZero在外部数据集上泛化能力更强。基于门控的融合方法在预测青光眼、AMD和高血压方面有适度改进。系统性疾病（尤其是高血压）的预测仍然具有挑战性。

Conclusion: 该研究首次系统地评估了单一和融合的眼科基础模型（FMs），并提出了FusionFM评估套件和两种融合方法。结果表明，DINORET和RetiZero在眼科和系统性疾病任务中表现优越，其中RetiZero在外部数据集上泛化能力更强。基于门控的方法在预测青光眼、年龄相关性黄斑变性和高血压方面有适度改进。然而，系统性疾病（尤其是高血压）的预测仍然具有挑战性。这些发现为眼科FM提供了基于证据的评估，突显了模型融合的优势，并指出了提高其临床应用性的策略。

Abstract: Foundation models (FMs) have shown great promise in medical image analysis by
improving generalization across diverse downstream tasks. In ophthalmology,
several FMs have recently emerged, but there is still no clear answer to
fundamental questions: Which FM performs the best? Are they equally good across
different tasks? What if we combine all FMs together? To our knowledge, this is
the first study to systematically evaluate both single and fused ophthalmic
FMs. To address these questions, we propose FusionFM, a comprehensive
evaluation suite, along with two fusion approaches to integrate different
ophthalmic FMs. Our framework covers both ophthalmic disease detection
(glaucoma, diabetic retinopathy, and age-related macular degeneration) and
systemic disease prediction (diabetes and hypertension) based on retinal
imaging. We benchmarked four state-of-the-art FMs (RETFound, VisionFM,
RetiZero, and DINORET) using standardized datasets from multiple countries and
evaluated their performance using AUC and F1 metrics. Our results show that
DINORET and RetiZero achieve superior performance in both ophthalmic and
systemic disease tasks, with RetiZero exhibiting stronger generalization on
external datasets. Regarding fusion strategies, the Gating-based approach
provides modest improvements in predicting glaucoma, AMD, and hypertension.
Despite these advances, predicting systemic diseases, especially hypertension
in external cohort remains challenging. These findings provide an
evidence-based evaluation of ophthalmic FMs, highlight the benefits of model
fusion, and point to strategies for enhancing their clinical applicability.

</details>


### [4] [UniDCF: A Foundation Model for Comprehensive Dentocraniofacial Hard Tissue Reconstruction](https://arxiv.org/abs/2508.11728)
*Chunxia Ren,Ning Zhu,Yue Lai,Gui Chen,Ruijie Wang,Yangyi Hu,Suyao Liu,Shuwen Mao,Hong Su,Yu Zhang,Li Xiao*

Main category: cs.CV

TL;DR: UniDCF是一个创新的框架，通过融合点云和多视图图像，实现了牙齿颅面骨硬组织的高精度、高效率重建，显著缩短了治疗时间并提高了患者满意度。


<details>
  <summary>Details</summary>
Motivation: 牙齿颅面骨硬组织缺损严重影响患者的生理功能、面部美学和心理健康，给精确重建带来了重大挑战。目前现有的深度学习模型仅限于单一组织场景和特定模态的影像输入，泛化能力差，并在解剖保真度、计算效率和跨组织适应性之间存在权衡。

Method: 该研究介绍了一个名为 UniDCF 的统一框架，该框架通过融合点云和多视图图像的多模态信息，能够重建多个牙齿颅面骨组织。该框架利用各模态的互补优势，并引入了一个基于评分的去噪模块来优化表面光滑度，克服了以往单一模态方法的局限性。

Result: UniDCF 在几何精度、结构完整性和空间准确性方面优于现有最先进的方法。临床模拟显示，UniDCF 将重建设计时间缩短了 99%，并且临床医生评定的可接受度超过 94%。

Conclusion: UniDCF 框架能够实现快速、自动化和高保真度的重建，支持个性化和精准的修复治疗，简化临床工作流程，并改善患者预后。

Abstract: Dentocraniofacial hard tissue defects profoundly affect patients'
physiological functions, facial aesthetics, and psychological well-being,
posing significant challenges for precise reconstruction. Current deep learning
models are limited to single-tissue scenarios and modality-specific imaging
inputs, resulting in poor generalizability and trade-offs between anatomical
fidelity, computational efficiency, and cross-tissue adaptability. Here we
introduce UniDCF, a unified framework capable of reconstructing multiple
dentocraniofacial hard tissues through multimodal fusion encoding of point
clouds and multi-view images. By leveraging the complementary strengths of each
modality and incorporating a score-based denoising module to refine surface
smoothness, UniDCF overcomes the limitations of prior single-modality
approaches. We curated the largest multimodal dataset, comprising intraoral
scans, CBCT, and CT from 6,609 patients, resulting in 54,555 annotated
instances. Evaluations demonstrate that UniDCF outperforms existing
state-of-the-art methods in terms of geometric precision, structural
completeness, and spatial accuracy. Clinical simulations indicate UniDCF
reduces reconstruction design time by 99% and achieves clinician-rated
acceptability exceeding 94%. Overall, UniDCF enables rapid, automated, and
high-fidelity reconstruction, supporting personalized and precise restorative
treatments, streamlining clinical workflows, and enhancing patient outcomes.

</details>


### [5] [Ovis2.5 Technical Report](https://arxiv.org/abs/2508.11737)
*Shiyin Lu,Yang Li,Yu Xia,Yuwei Hu,Shanshan Zhao,Yanqing Ma,Zhichao Wei,Yinglun Li,Lunhao Duan,Jianshan Zhao,Yuxuan Han,Haijun Li,Wanying Chen,Junke Tang,Chengkun Hou,Zhixing Du,Tianli Zhou,Wenjie Zhang,Huping Ding,Jiahe Li,Wen Li,Gui Hu,Yiliang Gu,Siran Yang,Jiamang Wang,Hailong Sun,Yibo Wang,Hui Sun,Jinlong Huang,Yuping He,Shengze Shi,Weihong Zhang,Guodong Zheng,Junpeng Jiang,Sensen Gao,Yi-Feng Wu,Sijia Chen,Yuhui Chen,Qing-Guo Chen,Zhao Xu,Weihua Luo,Kaifu Zhang*

Main category: cs.CV

TL;DR: Ovis2.5是一个多模态大语言模型，具有原生分辨率视觉处理和先进的推理能力（包括反思）。它通过多阶段课程进行训练，并在OpenCompass排行榜上取得了SOTA成果，尤其在STEM、视觉定位、视频和复杂图表分析方面表现出色。同时发布了9B和2B两个版本，满足不同需求。


<details>
  <summary>Details</summary>
Motivation: Ovis2.5旨在实现原生分辨率的视觉感知和强大的多模态推理能力。

Method: Ovis2.5集成了原生分辨率视觉Transformer，以其原生、可变的分辨率处理图像，避免了固定分辨率分块带来的降级，并保留了精细细节和全局布局。为了加强推理能力，模型被训练成执行反思，包括自我检查和修正。该模型通过包含基础视觉和多模态预训练、大规模指令调优以及DPO和GRPO对齐和推理增强的全面五阶段课程进行训练。

Result: Ovis2.5-9B在OpenCompass多模态排行榜上平均得分78.3，Ovis2.5-2B得分73.9，两者均达到各自尺寸上的SOTA。Ovis2.5在STEM基准测试、视觉定位和视频任务方面表现出色，并在复杂图表分析方面取得了领先成果。

Conclusion: Ovis2.5在OpenCompass多模态排行榜上平均得分78.3，超越了其前身Ovis2-8B，并在400亿参数以下的开源MLLM中取得了最先进的成果。Ovis2.5-2B得分73.9，确立了其尺寸上的最先进水平。此外，Ovis2.5在STEM基准测试、视觉定位和视频任务方面也取得了领先成果，并在复杂图表分析方面达到了同尺寸开源模型的SOTA。

Abstract: We present Ovis2.5, a successor to Ovis2 designed for native-resolution
visual perception and strong multimodal reasoning. Ovis2.5 integrates a
native-resolution vision transformer that processes images at their native,
variable resolutions, avoiding the degradation from fixed-resolution tiling and
preserving both fine detail and global layout -- crucial for visually dense
content like complex charts. To strengthen reasoning, we train the model to
move beyond linear chain-of-thought and perform reflection -- including
self-checking and revision. This advanced capability is exposed as an optional
"thinking mode" at inference time, allowing users to trade latency for enhanced
accuracy on difficult inputs. The model is trained via a comprehensive
five-phase curriculum that progressively builds its skills. The process begins
with foundational visual and multimodal pretraining, advances through
large-scale instruction tuning, and culminates in alignment and reasoning
enhancement using DPO and GRPO. To scale these upgrades efficiently, we employ
multimodal data packing and hybrid parallelism, yielding a significant
end-to-end speedup. We release two open-source models: Ovis2.5-9B and
Ovis2.5-2B. The latter continues the "small model, big performance" philosophy
of Ovis2, making it ideal for resource-constrained, on-device scenarios. On the
OpenCompass multimodal leaderboard, Ovis2.5-9B averages 78.3, marking a
substantial improvement over its predecessor, Ovis2-8B, and achieving
state-of-the-art results among open-source MLLMs in the sub-40B parameter
range; Ovis2.5-2B scores 73.9, establishing SOTA for its size. Beyond aggregate
scores, Ovis2.5 achieves leading results on STEM benchmarks, exhibits strong
capabilities on grounding and video tasks, and achieves open-source SOTA at its
scale for complex chart analysis.

</details>


### [6] [VideoAVE: A Multi-Attribute Video-to-Text Attribute Value Extraction Dataset and Benchmark Models](https://arxiv.org/abs/2508.11801)
*Ming Cheng,Tong Wu,Jiazhen Hu,Jiaying Gong,Hoda Eldardiry*

Main category: cs.CV

TL;DR: 我们提出了 VideoAVE，这是第一个公开可用的视频到文本电子商务 AVE 数据集，涵盖 14 个不同的领域和 172 个独特的属性。我们还建立了一个全面的基准，通过评估几种最先进的视频视觉语言模型（VLMs），证明了视频到文本的 AVE 仍然是一个具有挑战性的问题。 VideoAVE 数据集和基准代码可在 https://github.com/gjiaying/VideoAVE 获取。


<details>
  <summary>Details</summary>
Motivation: 属性值提取（AVE）对于在电子商务中构建产品信息非常重要。然而，现有的 AVE 数据集主要局限于文本到文本或图像到文本的设置，缺乏对产品视频、多样属性覆盖和公开可用性的支持。

Method: 为了确保数据质量，我们提出了一种基于 CLIP 的专家混合（CLIP-MoE）的后验过滤系统，以删除不匹配的视频-产品对，从而得到一个包含 224k 训练数据和 25k 评估数据的精炼数据集。为了评估数据集的可用性，我们进一步建立了一个全面的基准，通过在属性条件值预测和开放属性值对提取任务下评估几种最先进的视频视觉语言模型（VLMs）。

Result: 我们的结果分析表明，视频到文本的 AVE 仍然是一个具有挑战性的问题，尤其是在开放设置下，并且在开发能够利用有效时间信息的更先进的 VLM 方面仍有提升空间。

Conclusion: 现有 AVE 数据集主要局限于文本到文本或图像到文本的设置，缺乏对产品视频、多样属性覆盖和公开可用性的支持。为了解决这些问题，我们提出了 VideoAVE，这是第一个公开可用的视频到文本电子商务 AVE 数据集，涵盖 14 个不同的领域和 172 个独特的属性。为了确保数据质量，我们提出了一种基于 CLIP 的专家混合（CLIP-MoE）的后验过滤系统，以删除不匹配的视频-产品对，从而得到一个包含 224k 训练数据和 25k 评估数据的精炼数据集。为了评估数据集的可用性，我们通过在属性条件值预测和开放属性值对提取任务下评估几种最先进的视频视觉语言模型（VLMs），建立了一个全面的基准。

Abstract: Attribute Value Extraction (AVE) is important for structuring product
information in e-commerce. However, existing AVE datasets are primarily limited
to text-to-text or image-to-text settings, lacking support for product videos,
diverse attribute coverage, and public availability. To address these gaps, we
introduce VideoAVE, the first publicly available video-to-text e-commerce AVE
dataset across 14 different domains and covering 172 unique attributes. To
ensure data quality, we propose a post-hoc CLIP-based Mixture of Experts
filtering system (CLIP-MoE) to remove the mismatched video-product pairs,
resulting in a refined dataset of 224k training data and 25k evaluation data.
In order to evaluate the usability of the dataset, we further establish a
comprehensive benchmark by evaluating several state-of-the-art video vision
language models (VLMs) under both attribute-conditioned value prediction and
open attribute-value pair extraction tasks. Our results analysis reveals that
video-to-text AVE remains a challenging problem, particularly in open settings,
and there is still room for developing more advanced VLMs capable of leveraging
effective temporal information. The dataset and benchmark code for VideoAVE are
available at: https://github.com/gjiaying/VideoAVE

</details>


### [7] [An MLP Baseline for Handwriting Recognition Using Planar Curvature and Gradient Orientation](https://arxiv.org/abs/2508.11803)
*Azam Nouri*

Main category: cs.CV

TL;DR: 通过使用手工设计的几何特征（曲率和梯度方向）训练MLP，在MNIST和EMNIST数据集上取得了高准确率，证明了这些特征的有效性。


<details>
  <summary>Details</summary>
Motivation: 探究二阶几何线索（平面曲率大小、曲率符号和梯度方向）是否足以单独驱动MLP分类器进行手写字符识别，以此作为CNNs的替代方案。

Method: 使用三阶几何线索——曲率、曲率符号和梯度方向——作为输入，并训练多层感知器（MLP）分类器。

Result: 在MNIST数字数据集上达到97%的准确率，在EMNIST字母数据集上达到89%的准确率。

Conclusion: 研究结果表明，基于曲率的表征对于手写字符图像具有很强的辨别能力，并且即使使用可解释的、手工设计的特征，也能实现深度学习的优势。

Abstract: This study investigates whether second-order geometric cues - planar
curvature magnitude, curvature sign, and gradient orientation - are sufficient
on their own to drive a multilayer perceptron (MLP) classifier for handwritten
character recognition (HCR), offering an alternative to convolutional neural
networks (CNNs). Using these three handcrafted feature maps as inputs, our
curvature-orientation MLP achieves 97 percent accuracy on MNIST digits and 89
percent on EMNIST letters. These results underscore the discriminative power of
curvature-based representations for handwritten character images and
demonstrate that the advantages of deep learning can be realized even with
interpretable, hand-engineered features.

</details>


### [8] [Labels or Input? Rethinking Augmentation in Multimodal Hate Detection](https://arxiv.org/abs/2508.11808)
*Sahajpreet Singh,Rongxin Ouyang,Subhayan Mukerjee,Kokil Jaidka*

Main category: cs.CV

TL;DR: 本研究提出了一种改进多模态仇恨检测的方法，通过优化提示和增强数据来提高模型性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现代网络充斥着多模态内容，加剧了检测有害表情包的挑战，因为有害意图常常通过文本和图像之间的微妙互动来传达，并披着幽默或讽刺的外衣。现有的视觉语言模型（VLM）虽然有潜力，但缺乏细粒度监督，并且容易受到隐晦仇恨言论的影响。

Method: 本研究提出了一种提示优化框架，通过系统地改变提示结构、监督粒度和训练模态来改进多模态仇恨检测。此外，还引入了一个多模态数据增强管道，利用多智能体LLM-VLM设置生成反事实中性模因，以减少虚假关联并提高分类器泛化能力。

Result: 研究表明，提示设计和标签缩放都会影响模型性能，其中结构化提示可以提高模型的鲁棒性（即使是小型模型）。InternVL2在二元和缩放设置中均取得了最佳F1分数。所提出的数据增强管道成功地减少了虚假关联，并提高了分类器的泛化能力。

Conclusion: 本研究提出了一种改进多模态仇恨检测的双管齐下的方法，重点在于提示优化和多模态数据增强。实验证明，提示结构和数据组成与模型大小同等重要，定向增强可以提高检测的鲁棒性和公平性。

Abstract: The modern web is saturated with multimodal content, intensifying the
challenge of detecting hateful memes, where harmful intent is often conveyed
through subtle interactions between text and image under the guise of humor or
satire. While recent advances in Vision-Language Models (VLMs) show promise,
these models lack support for fine-grained supervision and remain susceptible
to implicit hate speech. In this paper, we present a dual-pronged approach to
improve multimodal hate detection. First, we propose a prompt optimization
framework that systematically varies prompt structure, supervision granularity,
and training modality. We show that prompt design and label scaling both
influence performance, with structured prompts improving robustness even in
small models, and InternVL2 achieving the best F1-scores across binary and
scaled settings. Second, we introduce a multimodal data augmentation pipeline
that generates 2,479 counterfactually neutral memes by isolating and rewriting
the hateful modality. This pipeline, powered by a multi-agent LLM-VLM setup,
successfully reduces spurious correlations and improves classifier
generalization. Our approaches inspire new directions for building synthetic
data to train robust and fair vision-language models. Our findings demonstrate
that prompt structure and data composition are as critical as model size, and
that targeted augmentation can support more trustworthy and context-sensitive
hate detection.

</details>


### [9] [Towards Understanding 3D Vision: the Role of Gaussian Curvature](https://arxiv.org/abs/2508.11825)
*Sherlon Almeida da Silva,Davi Geiger,Luiz Velho,Moacir Antonelli Ponti*

Main category: cs.CV

TL;DR: 高斯曲率在3D表面建模中很重要，可用于改进重建和作为立体匹配的度量。


<details>
  <summary>Details</summary>
Motivation: 当前的深度学习方法在3D表面建模方面缺乏可直接分析、跨模态迁移或系统性修改的显式3D几何模型。本研究旨在探索高斯曲率在3D表面建模中的作用。

Method: 通过分析高斯曲率在3D表面建模中的作用，并使用Middlebury立体数据集进行实验。

Result: 研究发现高斯曲率能够提供3D表面的稀疏紧凑描述，状态最先进的单目和立体方法似乎也隐式地考虑了高斯曲率，并且高斯曲率可以作为一种几何先验来改进3D表面重建，同时还可以作为立体匹配方法的无监督度量。

Conclusion: 该研究表明高斯曲率在3D表面建模中具有重要作用，可作为一种几何先验来改进3D表面重建，并可用作立体匹配方法的无监督度量。

Abstract: Recent advances in computer vision have predominantly relied on data-driven
approaches that leverage deep learning and large-scale datasets. Deep neural
networks have achieved remarkable success in tasks such as stereo matching and
monocular depth reconstruction. However, these methods lack explicit models of
3D geometry that can be directly analyzed, transferred across modalities, or
systematically modified for controlled experimentation. We investigate the role
of Gaussian curvature in 3D surface modeling. Besides Gaussian curvature being
an invariant quantity under change of observers or coordinate systems, we
demonstrate using the Middlebury stereo dataset that it offers: (i) a sparse
and compact description of 3D surfaces, (ii) state-of-the-art monocular and
stereo methods seem to implicitly consider it, but no explicit module of such
use can be extracted, (iii) a form of geometric prior that can inform and
improve 3D surface reconstruction, and (iv) a possible use as an unsupervised
metric for stereo methods.

</details>


### [10] [From Pixels to Graphs: Deep Graph-Level Anomaly Detection on Dermoscopic Images](https://arxiv.org/abs/2508.11826)
*Dehn Xu,Tim Katzke,Emmanuel Müller*

Main category: cs.CV

TL;DR: 本研究首次全面比较了用于图神经网络的图像到图转换方法，在皮肤镜图像异常检测任务上取得了优异结果，无需预训练模型即可获得有竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 填补在图神经网络（GNNs）应用于图级异常检测（GLAD）领域，缺乏对多种潜在的图像到图转换方法的有效性进行严格比较的研究空白。

Method: 系统评估了多种图像到图的转换方法，包括分割方案、边构建策略和基于颜色、纹理、形状的节点特征集，并将其应用于图级异常检测任务。

Result: 颜色描述符单独表现最佳，形状和纹理特征的加入能提升检测效果。在无监督、弱监督和全监督情况下，该方法分别取得了0.805、0.872和0.914的AUC-ROC分数。

Conclusion: 该研究系统地评估了多种从图像生成图表示的方法，以用于基于图神经网络的图级异常检测（GLAD）。实验表明，颜色描述符单独使用时表现最佳，而结合形状和纹理特征可以持续提高检测效果。在无监督、弱监督和全监督情况下，该方法在皮肤镜图像上取得了有竞争力的性能。

Abstract: Graph Neural Networks (GNNs) have emerged as a powerful approach for
graph-based machine learning tasks. Previous work applied GNNs to image-derived
graph representations for various downstream tasks such as classification or
anomaly detection. These transformations include segmenting images, extracting
features from segments, mapping them to nodes, and connecting them. However, to
the best of our knowledge, no study has rigorously compared the effectiveness
of the numerous potential image-to-graph transformation approaches for
GNN-based graph-level anomaly detection (GLAD). In this study, we
systematically evaluate the efficacy of multiple segmentation schemes, edge
construction strategies, and node feature sets based on color, texture, and
shape descriptors to produce suitable image-derived graph representations to
perform graph-level anomaly detection. We conduct extensive experiments on
dermoscopic images using state-of-the-art GLAD models, examining performance
and efficiency in purely unsupervised, weakly supervised, and fully supervised
regimes. Our findings reveal, for example, that color descriptors contribute
the best standalone performance, while incorporating shape and texture features
consistently enhances detection efficacy. In particular, our best unsupervised
configuration using OCGTL achieves a competitive AUC-ROC score of up to 0.805
without relying on pretrained backbones like comparable image-based approaches.
With the inclusion of sparse labels, the performance increases substantially to
0.872 and with full supervision to 0.914 AUC-ROC.

</details>


### [11] [Recent Advances in Transformer and Large Language Models for UAV Applications](https://arxiv.org/abs/2508.11834)
*Hamza Kheddar,Yassine Habchi,Mohamed Chahine Ghanem,Mustapha Hemis,Dusit Niyato*

Main category: cs.CV

TL;DR: 本综述总结了Transformer模型在无人机（UAV）领域的应用，包括其不同架构（如注意力机制、混合模型、强化学习、LLMs）、新兴应用（如精准农业、自主导航）以及数据集、模拟器和评估指标。文章还讨论了该领域的挑战（计算效率、实时部署）和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在无人机系统中的应用日益广泛，对提升无人机的感知、决策和自主能力起到了关键作用。本研究旨在系统性地梳理和评估该领域的研究进展，为研究人员和从业者提供一个全面的视角，以理解和推动基于Transformer的无人机技术的发展。

Method: 本综述系统地对Transformer模型在无人机（UAV）领域的最新进展进行了分类和评估，重点关注了注意力机制、CNN-Transformer混合模型、强化学习Transformer以及大型语言模型（LLMs）等关键技术。通过结构化的表格和性能基准测试，对这些模型进行了比较分析。

Result: 本综述通过统一的分类法、新兴应用的讨论、详细的性能比较、以及对关键数据集、模拟器和评估指标的回顾，为Transformer在无人机领域的应用提供了全面的分析。同时，也指出了计算效率和实时部署方面的挑战，并提出了未来研究方向。

Conclusion: 本综述全面总结了Transformer模型在无人机系统中的应用，涵盖了注意力机制、CNN-Transformer混合模型、强化学习Transformer以及大型语言模型（LLMs）。文章提出了一个统一的Transformer-UAV模型分类法，并重点介绍了精准农业和自主导航等新兴应用。此外，本文还对相关数据集、模拟器和评估指标进行了回顾，指出了当前研究的不足之处，分析了计算效率和实时部署方面的挑战，并为未来的研究提供了方向。

Abstract: The rapid advancement of Transformer-based models has reshaped the landscape
of uncrewed aerial vehicle (UAV) systems by enhancing perception,
decision-making, and autonomy. This review paper systematically categorizes and
evaluates recent developments in Transformer architectures applied to UAVs,
including attention mechanisms, CNN-Transformer hybrids, reinforcement learning
Transformers, and large language models (LLMs). Unlike previous surveys, this
work presents a unified taxonomy of Transformer-based UAV models, highlights
emerging applications such as precision agriculture and autonomous navigation,
and provides comparative analyses through structured tables and performance
benchmarks. The paper also reviews key datasets, simulators, and evaluation
metrics used in the field. Furthermore, it identifies existing gaps in the
literature, outlines critical challenges in computational efficiency and
real-time deployment, and offers future research directions. This comprehensive
synthesis aims to guide researchers and practitioners in understanding and
advancing Transformer-driven UAV technologies.

</details>


### [12] [ComplicitSplat: Downstream Models are Vulnerable to Blackbox Attacks by 3D Gaussian Splat Camouflages](https://arxiv.org/abs/2508.11854)
*Matthew Hull,Haoyang Yang,Pratham Mehta,Mansi Phute,Aeree Cho,Haorang Wang,Matthew Lau,Wenke Lee,Wilian Lunardi,Martin Andreoni,Polo Chau*

Main category: cs.CV

TL;DR: ComplicitSplat是一种新的攻击方法，利用3DGS技术生成视角特定的欺骗性内容，成功攻击了多种目标检测器，揭示了自动驾驶等领域的安全风险。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索3DGS在安全关键任务中的潜在安全风险，特别是攻击者如何篡改图像以造成危害，并提出一种新的攻击方法ComplicitSplat。

Method: ComplicitSplat利用3DGS着色方法，在特定视角下嵌入视觉欺骗性内容（颜色和纹理随视角变化），实现针对下游目标检测器的黑盒攻击，无需访问模型架构或权重。

Result: 实验证明ComplicitSplat能够成功攻击多种主流目标检测器（单阶段、多阶段、基于Transformer的模型），并且在真实捕获的物理对象和合成场景中都表现出良好的泛化能力。

Conclusion: ComplicitSplat是首个利用3DGS着色方法在特定视角下实现“视觉欺骗”的攻击技术，可用于在真实或合成场景中攻击多种目标检测器，揭示了自动导航等关键任务的新型安全风险。

Abstract: As 3D Gaussian Splatting (3DGS) gains rapid adoption in safety-critical tasks
for efficient novel-view synthesis from static images, how might an adversary
tamper images to cause harm? We introduce ComplicitSplat, the first attack that
exploits standard 3DGS shading methods to create viewpoint-specific camouflage
- colors and textures that change with viewing angle - to embed adversarial
content in scene objects that are visible only from specific viewpoints and
without requiring access to model architecture or weights. Our extensive
experiments show that ComplicitSplat generalizes to successfully attack a
variety of popular detector - both single-stage, multi-stage, and
transformer-based models on both real-world capture of physical objects and
synthetic scenes. To our knowledge, this is the first black-box attack on
downstream object detectors using 3DGS, exposing a novel safety risk for
applications like autonomous navigation and other mission-critical robotic
systems.

</details>


### [13] [TSLA: A Task-Specific Learning Adaptation for Semantic Segmentation on Autonomous Vehicles Platform](https://arxiv.org/abs/2508.12279)
*Jun Liu,Zhenglun Kong,Pu Zhao,Weihao Zeng,Hao Tang,Xuan Shen,Changdi Yang,Wenbin Zhang,Geng Yuan,Wei Niu,Xue Lin,Yanzhi Wang*

Main category: cs.CV

TL;DR: 为自动驾驶定制语义分割网络，通过三层控制机制和贝叶斯优化实现高效资源利用和精度提升。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶平台需要在不同的驾驶场景下，根据硬件资源的限制和精度要求，对深度学习模型进行优化部署。现有的模型往往无法满足嵌入式设备（如NVIDIA® DRIVE PX 2）的计算能力限制，因此需要一种能够根据硬件和场景进行定制化的方法。

Method: 该研究提出了一种结合宽度乘数、分类器深度和分类器核的三层控制机制，以实现对语义分割网络进行动态可调。此外，还利用贝叶斯优化和代理模型来高效探索超参数空间，并实现了任务特定学习适应（TSLA），以优化MACs（乘累加操作）和模型配置。

Result: 该方法实现了模型的可扩展性，能够针对最终层进行定向优化，并针对场景特定优化核大小，从而实现更优的资源分配和性能。TSLA定制化配置能够最大化计算能力和模型精度，优化硬件利用率。

Conclusion: 该研究提出了一种可定制的语义分割网络，用于在计算资源受限的自动驾驶平台上实现高效部署。通过结合宽度乘数、分类器深度和分类器核等三层控制机制，以及利用贝叶斯优化和代理模型进行超参数搜索，该方法能够根据硬件约束和任务需求对模型进行精细调整和场景特定优化，从而实现计算资源和模型精度的最佳利用。

Abstract: Autonomous driving platforms encounter diverse driving scenarios, each with
varying hardware resources and precision requirements. Given the computational
limitations of embedded devices, it is crucial to consider computing costs when
deploying on target platforms like the NVIDIA\textsuperscript{\textregistered}
DRIVE PX 2. Our objective is to customize the semantic segmentation network
according to the computing power and specific scenarios of autonomous driving
hardware. We implement dynamic adaptability through a three-tier control
mechanism -- width multiplier, classifier depth, and classifier kernel --
allowing fine-grained control over model components based on hardware
constraints and task requirements. This adaptability facilitates broad model
scaling, targeted refinement of the final layers, and scenario-specific
optimization of kernel sizes, leading to improved resource allocation and
performance.
  Additionally, we leverage Bayesian Optimization with surrogate modeling to
efficiently explore hyperparameter spaces under tight computational budgets.
Our approach addresses scenario-specific and task-specific requirements through
automatic parameter search, accommodating the unique computational complexity
and accuracy needs of autonomous driving. It scales its Multiply-Accumulate
Operations (MACs) for Task-Specific Learning Adaptation (TSLA), resulting in
alternative configurations tailored to diverse self-driving tasks. These TSLA
customizations maximize computational capacity and model accuracy, optimizing
hardware utilization.

</details>


### [14] [Impact of Clinical Image Quality on Efficient Foundation Model Finetuning](https://arxiv.org/abs/2508.11864)
*Yucheng Tang,Pawel Rajwa,Alexander Ng,Yipei Wang,Wen Yan,Natasha Thorley,Aqua Asif,Clare Allen,Louise Dickinson,Francesco Giganti,Shonit Punwani,Daniel C. Alexander,Veeru Kasivisvanathan,Yipeng Hu*

Main category: cs.CV

TL;DR: 基础模型在前列腺 MRI 图像的标签效率方面表现良好，但性能很大程度上受图像质量分布及其在微调和测试集之间匹配程度的影响。高质量图像对于微调至关重要，并且需要仔细考虑数据质量以充分发挥基础模型的优势。


<details>
  <summary>Details</summary>
Motivation: 基础模型在医学成像领域显示出有希望的标签效率，仅用一小部分标注数据就能在下游任务中获得高性能。本研究旨在评估这种效率，特别是在前列腺多参数 MRI 中，并研究图像质量变化对标签高效微调的影响。

Method: 本研究在 prostate multiparametric MRI 中使用 ProFound（一种在大型前列腺 MRI 数据集上预训练的领域特定视觉基础模型）来评估其在标签效率方面的表现，并研究可变图像质量如何影响标签高效微调，方法是测量微调模型的泛化能力。通过系统地改变微调和评估集中高质量/低质量图像的比例来进行实验。

Result: 研究结果表明，图像质量分布及其微调与测试之间的不匹配会显著影响模型性能。具体来说，在微调和测试集之间改变高质量与低质量图像的比例会导致下游性能存在显著差异；并且，在微调集中存在足够的高质量图像对于保持良好性能至关重要，而匹配的微调和测试数据分布对于自动化放射学报告和前列腺癌检测等不同下游任务的重要性各不相同。当质量比例一致时，与从头开始训练相比，微调所需的标记数据大大减少，但标签效率取决于图像质量分布。如果微调数据中没有足够的高质量图像，预训练模型可能无法优于未经预训练的模型。

Conclusion: 评估和匹配微调与部署之间的数据质量分布至关重要，并且需要为特定下游任务的微调数据制定质量标准。使用 ProFound，我们可以量化微调和部署中的图像质量，以充分发挥基础模型的数据和计算效率优势。

Abstract: Foundation models in medical imaging have shown promising label efficiency,
achieving high downstream performance with only a fraction of annotated data.
Here, we evaluate this in prostate multiparametric MRI using ProFound, a
domain-specific vision foundation model pretrained on large-scale prostate MRI
datasets. We investigate how variable image quality affects label-efficient
finetuning by measuring the generalisability of finetuned models. Experiments
systematically vary high-/low-quality image ratios in finetuning and evaluation
sets. Our findings indicate that image quality distribution and its
finetune-and-test mismatch significantly affect model performance. In
particular: a) Varying the ratio of high- to low-quality images between
finetuning and test sets leads to notable differences in downstream
performance; and b) The presence of sufficient high-quality images in the
finetuning set is critical for maintaining strong performance, whilst the
importance of matched finetuning and testing distribution varies between
different downstream tasks, such as automated radiology reporting and prostate
cancer detection.When quality ratios are consistent, finetuning needs far less
labeled data than training from scratch, but label efficiency depends on image
quality distribution. Without enough high-quality finetuning data, pretrained
models may fail to outperform those trained without pretraining. This
highlights the importance of assessing and aligning quality distributions
between finetuning and deployment, and the need for quality standards in
finetuning data for specific downstream tasks. Using ProFound, we show the
value of quantifying image quality in both finetuning and deployment to fully
realise the data and compute efficiency benefits of foundation models.

</details>


### [15] [AdaRing: Towards Ultra-Light Vision-Language Adaptation via Cross-Layer Tensor Ring Decomposition](https://arxiv.org/abs/2508.11870)
*Ying Huang,Yuanbin Man,Wenqi Jia,Zhengzhong Tu,Junzhou Huang,Miao Yin*

Main category: cs.CV

TL;DR: AdaRing通过张量分解和适配器协作，实现了VLM的超轻量级参数高效适应，性能优越且参数量大幅减少。


<details>
  <summary>Details</summary>
Motivation: 现有基于适配器的微调方法通过在VLM的每一层集成适配器来扩展适配器容量，但这存在两个主要限制：1）由于忽略了跨层冗余，压缩率有限；2）同质适配器在表示能力上有限。因此，需要一种更有效的方法来提高VLM的适应性。

Method: 提出了一种基于跨层张量环分解（TRD）的视觉-语言微调框架，称为AdaRing。该框架将适配器设计为跨层共享的张量核心和层特定的切片，以利用适配器之间的低秩冗余。此外，通过引导泛化感知微调，允许不同秩驱动的适配器协同工作，以处理需要不同表示的任务。

Result: AdaRing框架在减少90%的平均训练参数的同时，在各种任务上实现了最先进的性能。

Conclusion: AdaRing框架通过利用跨层张量分解和多样的适配器协作，实现了高效的视觉语言模型（VLM）参数高效适应，并在各种任务上实现了最先进的性能，同时平均训练参数减少了90%。

Abstract: Adapter-based fine-tuning has gained remarkable attention in adapting large
pre-trained vision language models (VLMs) for a wide range of downstream tasks
efficiently. In this paradigm, only the inserted adapters are fine-tuned,
without the need for training the original VLM backbone. Existing works scale
adapters by integrating them into every layer of VLMs to increase the capacity
of adapters. However, these methods face two primary limitations: 1) limited
compression rate due to ignoring cross-layer redundancy, and 2) limited
representational capacity across homogeneous adapters. In this paper, we
propose a novel vision-language fine-tuning framework based on cross-layer
tensor ring decomposition (TRD) with the integration and collaboration of
diverse adapters, called AdaRing, achieving ultra-light parameter-efficient
adaptation of VLMs on various tasks. To remove the high redundancy that exists
among adapters across layers, we exploit the tensor-level low-rankness to
formulate adapters as layer-shared tensor cores and layer-specific slices.
Moreover, guided by generalization-aware fine-tuning, diverse rank-driven
adapters cooperate to handle tasks that require different representations. Our
experiments show that the proposed AdaRing achieves the state-of-the-art
performance while reducing average training parameters by 90%.

</details>


### [16] [EVTP-IVS: Effective Visual Token Pruning For Unifying Instruction Visual Segmentation In Multi-Modal Large Language Models](https://arxiv.org/abs/2508.11886)
*Wenhui Zhu,Xiwen Chen,Zhipeng Wang,Shao Tang,Sayan Ghosh,Xuanzhao Dong,Rajat Koner,Yalin Wang*

Main category: cs.CV

TL;DR: EVTP-IV是一种用于视觉指令分割（IVS）的视觉标记剪枝方法，通过空间标记选择显著提高了推理速度，同时保持了准确性。


<details>
  <summary>Details</summary>
Motivation: 由于多模态大语言模型（MLLMs）在视觉指令分割（IVS）任务中的推理成本高昂，特别是在视频中，因此需要一种加速推理的方法。

Method: EVTP-IV是一种新颖的视觉标记剪枝方法，它通过整合空间信息来构建k-中心，以确保更好的覆盖，并进行了信息论分析以支持其设计。

Result: EVTP-IV在标准IVS基准测试中，在仅使用20%标记的情况下，实现了高达5倍的视频任务加速和3.5倍的图像任务加速，同时保持了可比的准确性。该方法在不同的剪枝率下持续优于最先进的剪枝基线。

Conclusion: EVTP-IV通过选择紧凑但空间上具有代表性的标记子集来加速推理，在保持可比准确性的同时，在视频任务上实现了高达5倍的速度提升，在图像任务上实现了3.5倍的速度提升，仅使用了20%的标记。

Abstract: Instructed Visual Segmentation (IVS) tasks require segmenting objects in
images or videos based on natural language instructions. While recent
multimodal large language models (MLLMs) have achieved strong performance on
IVS, their inference cost remains a major bottleneck, particularly in video. We
empirically analyze visual token sampling in MLLMs and observe a strong
correlation between subset token coverage and segmentation performance. This
motivates our design of a simple and effective token pruning method that
selects a compact yet spatially representative subset of tokens to accelerate
inference. In this paper, we introduce a novel visual token pruning method for
IVS, called EVTP-IV, which builds upon the k-center by integrating spatial
information to ensure better coverage. We further provide an
information-theoretic analysis to support our design. Experiments on standard
IVS benchmarks show that our method achieves up to 5X speed-up on video tasks
and 3.5X on image tasks, while maintaining comparable accuracy using only 20%
of the tokens. Our method also consistently outperforms state-of-the-art
pruning baselines under varying pruning ratios.

</details>


### [17] [Large Kernel Modulation Network for Efficient Image Super-Resolution](https://arxiv.org/abs/2508.11893)
*Quanwei Hu,Yinggan Tang,Xuguang Zhang*

Main category: cs.CV

TL;DR: LKMN 是一种新的纯 CNN 模型，通过 EPLKB 和 CGFN 模块有效解决了图像超分辨率中的性能和延迟权衡问题，在保持低延迟的同时提高了超分辨率质量。


<details>
  <summary>Details</summary>
Motivation: 解决资源受限场景下的图像超分辨率问题，该场景要求模型在性能和延迟之间取得平衡。现有的 CNN 模型延迟低但缺乏非局部特征捕获能力，而 Transformer 模型擅长非局部建模但推理速度慢。

Method: 提出了一种名为 LKMN 的纯 CNN 模型，包含两个核心组件：增强部分大卷积核块（EPLKB）和交叉门前馈网络（CGFN）。EPLKB 使用通道混洗、通道注意力和大卷积核条卷积来提取非局部特征；CGFN 通过可学习的缩放因子动态调整特征差异，并采用交叉门策略来调节和融合特征。

Result: LKMN 在 Manga109 数据集上实现了 0.23 dB PSNR 的提升，速度比 DAT-light 快近 4.8 倍，在轻量级 SR 模型中表现出 SOTA 性能。

Conclusion: LKMN-L 在 Manga109 数据集上实现了 0.23 dB 的 PSNR 提升，同时速度提升了近 4.8 倍，在保证质量和效率方面优于现有的 SOTA 轻量级 SR 模型。

Abstract: Image super-resolution (SR) in resource-constrained scenarios demands
lightweight models balancing performance and latency. Convolutional neural
networks (CNNs) offer low latency but lack non-local feature capture, while
Transformers excel at non-local modeling yet suffer slow inference. To address
this trade-off, we propose the Large Kernel Modulation Network (LKMN), a pure
CNN-based model. LKMN has two core components: Enhanced Partial Large Kernel
Block (EPLKB) and Cross-Gate Feed-Forward Network (CGFN). The EPLKB utilizes
channel shuffle to boost inter-channel interaction, incorporates channel
attention to focus on key information, and applies large kernel strip
convolutions on partial channels for non-local feature extraction with reduced
complexity. The CGFN dynamically adjusts discrepancies between input, local,
and non-local features via a learnable scaling factor, then employs a
cross-gate strategy to modulate and fuse these features, enhancing their
complementarity. Extensive experiments demonstrate that our method outperforms
existing state-of-the-art (SOTA) lightweight SR models while balancing quality
and efficiency. Specifically, LKMN-L achieves 0.23 dB PSNR improvement over
DAT-light on the Manga109 dataset at $\times$4 upscale, with nearly $\times$4.8
times faster. Codes are in the supplementary materials. The code is available
at https://github.com/Supereeeee/LKMN.

</details>


### [18] [A Sobel-Gradient MLP Baseline for Handwritten Character Recognition](https://arxiv.org/abs/2508.11902)
*Azam Nouri*

Main category: cs.CV

TL;DR: 一阶Sobel导数足以驱动MLP进行手写字符识别，准确率接近CNN，且模型更小、特征更透明。


<details>
  <summary>Details</summary>
Motivation: 探讨仅使用一阶边缘图是否足以驱动全稠密MLP以实现手写字符识别，作为CNNs的替代方案。

Method: 使用水平和垂直Sobel导数作为输入，训练MLP。

Result: 在MNIST数字上达到98%的准确率，在EMNIST字母上达到92%的准确率。

Conclusion: Sobel算子驱动的全稠密多层感知机（MLP）是手写字符识别（HCR）的一个可行选择，其准确率接近CNN，同时具有更小的内存占用和更透明的特征。

Abstract: We revisit the classical Sobel operator to ask a simple question: Are
first-order edge maps sufficient to drive an all-dense multilayer perceptron
(MLP) for handwritten character recognition (HCR), as an alternative to
convolutional neural networks (CNNs)? Using only horizontal and vertical Sobel
derivatives as input, we train an MLP on MNIST and EMNIST Letters. Despite its
extreme simplicity, the resulting network reaches 98% accuracy on MNIST digits
and 92% on EMNIST letters -- approaching CNNs while offering a smaller memory
footprint and transparent features. Our findings highlight that much of the
class-discriminative information in handwritten character images is already
captured by first-order gradients, making edge-aware MLPs a compelling option
for HCR.

</details>


### [19] [OVG-HQ: Online Video Grounding with Hybrid-modal Queries](https://arxiv.org/abs/2508.11903)
*Runhao Zeng,Jiaqi Mao,Minghao Lai,Minh Hieu Phan,Yanjie Dong,Wei Wang,Qi Chen,Xiping Hu*

Main category: cs.CV

TL;DR: 提出新的在线视频基础任务（OVG-HQ）和统一框架（OVG-HQ-Unify），以处理文本、图像、视频片段等混合查询，并解决了在线场景下的上下文限制和模态不平衡问题。该框架包含参数化内存块（PMB）和跨模态蒸馏策略，并构建了QVHighlights-Unify数据集和新的在线评估指标（oR@n, IoU=m, omAP）。实验证明OVG-HQ-Unify在准确性和效率上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统视频基础（VG）在流媒体视频或使用视觉线索的查询等场景下的局限性，提出了在线视频基础（OVG-HQ）任务，该任务支持使用文本、图像、视频片段及其组合进行在线片段定位。

Method: 提出了一种名为OVG-HQ-Unify的统一框架，该框架包含一个参数化内存块（PMB）以保留先前学习的知识，并采用跨模态蒸馏策略来指导非主导模态的学习。此外，还构建了一个名为QVHighlights-Unify的数据集，并提出了在线评估指标oR@n、IoU=m和omAP。

Result: OVG-HQ-Unify在在线视频基础任务上取得了先进的性能，优于现有模型，并且提出的评估指标能够同时衡量准确性和效率。

Conclusion: OVG-HQ-Unify在准确性和效率方面均优于现有模型，为在线、混合模态视频奠定了坚实基础。

Abstract: Video grounding (VG) task focuses on locating specific moments in a video
based on a query, usually in text form. However, traditional VG struggles with
some scenarios like streaming video or queries using visual cues. To fill this
gap, we present a new task named Online Video Grounding with Hybrid-modal
Queries (OVG-HQ), which enables online segment localization using text, images,
video segments, and their combinations. This task poses two new challenges:
limited context in online settings and modality imbalance during training,
where dominant modalities overshadow weaker ones. To address these, we propose
OVG-HQ-Unify, a unified framework featuring a Parametric Memory Block (PMB)
that retain previously learned knowledge to enhance current decision and a
cross-modal distillation strategy that guides the learning of non-dominant
modalities. This design enables a single model to effectively handle
hybrid-modal queries. Due to the lack of suitable datasets, we construct
QVHighlights-Unify, an expanded dataset with multi-modal queries. Besides,
since offline metrics overlook prediction timeliness, we adapt them to the
online setting, introducing oR@n, IoU=m, and online mean Average Precision
(omAP) to evaluate both accuracy and efficiency. Experiments show that our
OVG-HQ-Unify outperforms existing models, offering a robust solution for
online, hybrid-modal video grounding. Source code and datasets are available at
https://github.com/maojiaqi2324/OVG-HQ.

</details>


### [20] [SafeCtrl: Region-Based Safety Control for Text-to-Image Diffusion via Detect-Then-Suppress](https://arxiv.org/abs/2508.11904)
*Lingyun Zhang,Yu Xie,Yanwei Fu,Ping Chen*

Main category: cs.CV

TL;DR: SafeCtrl通过一种新颖的“检测然后抑制”范式，利用DPO训练，在不牺牲保真度的情况下，有效且可扩展地解决了文本到图像模型的安全问题。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像模型的安全方法（如提示重写或模型微调）在安全性和保真度之间存在权衡。基于定位的方法（如概念替换）有时会导致语义不一致。为了解决这些局限性，需要一种更灵活的检测然后抑制范式。

Method: SafeCtrl是一个轻量级的、非侵入性的插件，它首先精确定位不安全的内容，然后抑制有害语义，允许生成过程自然连贯地解析为安全、上下文感知的替代方案。该方法采用了一种新颖的训练策略，即直接偏好优化（DPO），并利用现有的、图像级的偏好数据来训练模块，使其能够学习细致的抑制行为，并在推理时进行区域引导干预，而无需昂贵的像素级注释。

Result: SafeCtrl在安全性和保真度保持方面显著优于最先进的方法。

Conclusion: SafeCtrl是一种有效的、可扩展的方法，用于构建更负责任的生成模型。

Abstract: The widespread deployment of text-to-image models is challenged by their
potential to generate harmful content. While existing safety methods, such as
prompt rewriting or model fine-tuning, provide valuable interventions, they
often introduce a trade-off between safety and fidelity. Recent
localization-based approaches have shown promise, yet their reliance on
explicit ``concept replacement" can sometimes lead to semantic incongruity. To
address these limitations, we explore a more flexible detect-then-suppress
paradigm. We introduce SafeCtrl, a lightweight, non-intrusive plugin that first
precisely localizes unsafe content. Instead of performing a hard A-to-B
substitution, SafeCtrl then suppresses the harmful semantics, allowing the
generative process to naturally and coherently resolve into a safe,
context-aware alternative. A key aspect of our work is a novel training
strategy using Direct Preference Optimization (DPO). We leverage readily
available, image-level preference data to train our module, enabling it to
learn nuanced suppression behaviors and perform region-guided interventions at
inference without requiring costly, pixel-level annotations. Extensive
experiments show that SafeCtrl significantly outperforms state-of-the-art
methods in both safety efficacy and fidelity preservation. Our findings suggest
that decoupled, suppression-based control is a highly effective and scalable
direction for building more responsible generative models.

</details>


### [21] [TimeSenCLIP: A Vision-Language Model for Remote Sensing Using Single-Pixel Time Series](https://arxiv.org/abs/2508.11919)
*Pallavi Jain,Diego Marcos,Dino Ienco,Roberto Interdonato,Tristan Berchoux*

Main category: cs.CV

TL;DR: TimeSenCLIP是一个轻量级框架，通过利用单个像素的时间和光谱维度，结合地面照片进行跨视图学习，从而无需大量文本监督，即可高效地对遥感影像进行土地利用与土地覆盖分类。


<details>
  <summary>Details</summary>
Motivation: 当前基于视觉-语言模型的方法在遥感应用中虽然展现出潜力，但面临依赖大型空间瓦片导致计算成本增加以及依赖通常不易获得的文本监督的挑战。

Method: TimeSenCLIP框架利用Sentinel-2影像的光谱和时间信息，并结合地理标记的地面照片进行跨视图学习，通过评估单个像素的时间和光谱维度来重新评估空间背景的作用，以分类LULC和生态系统类型。

Result: 通过使用单个像素输入，结合时间与光谱线索，能够有效地进行土地利用与土地覆盖（LULC）、作物类型和生态系统类型的分类，展示了其在主题测绘方面的有效性。

Conclusion: TimeSenCLIP框架表明，结合了时间与光谱线索的单个像素足以进行土地利用与土地覆盖（LULC）等信息的主题绘图，为大规模遥感应用提供了一种可扩展且高效的替代方案。

Abstract: Vision-language models have shown significant promise in remote sensing
applications, particularly for land-use and land-cover (LULC) via zero-shot
classification and retrieval. However, current approaches face two key
challenges: reliance on large spatial tiles that increase computational cost,
and dependence on text-based supervision, which is often not readily available.
In this work, we present TimeSenCLIP, a lightweight framework that reevaluate
the role of spatial context by evaluating the effectiveness of a single pixel
by leveraging its temporal and spectral dimensions, for classifying LULC and
ecosystem types. By leveraging spectral and temporal information from
Sentinel-2 imagery and cross-view learning with geo-tagged ground-level photos,
we minimises the need for caption-based training while preserving semantic
alignment between overhead (satellite) and ground perspectives. Our approach is
grounded in the LUCAS and Sen4Map datasets, and evaluated on classification
tasks including LULC, crop type, and ecosystem type. We demonstrate that single
pixel inputs, when combined with temporal and spectral cues, are sufficient for
thematic mapping, offering a scalable and efficient alternative for large-scale
remote sensing applications. Code is available at
https://github.com/pallavijain-pj/TimeSenCLIP

</details>


### [22] [Assessment of Using Synthetic Data in Brain Tumor Segmentation](https://arxiv.org/abs/2508.11922)
*Aditi Jahagirdar,Sameer Joshi*

Main category: cs.CV

TL;DR: 本研究探索了使用合成MRI数据（通过GAN生成）来增强脑肿瘤分割模型的训练。结果表明，混合真实和合成数据（60%合成）在改善肿瘤边界描绘方面具有潜力，但类别不平衡问题仍需解决。该研究支持合成数据作为一种有前景的增强策略，但需要进一步扩大规模和改进方法。


<details>
  <summary>Details</summary>
Motivation: 手动从MRI扫描中分割脑肿瘤由于肿瘤的异质性、带注释数据的稀缺性以及医学成像数据集中类别的 imbalance，带来了挑战。生成模型生成的合成数据通过提高数据集的多样性，有潜力缓解这些问题。

Method: 本研究作为概念验证，研究了将使用预训练GAN模型生成的合成MRI数据纳入训练U-Net分割网络的影响。实验使用了来自BraTS 2020数据集的真实数据、使用medigan库生成的合成数据以及不同比例的真实和合成样本混合的数据集。

Result: 总体定量性能（Dice系数、IoU、精确率、召回率、准确率）在仅使用真实数据和混合数据训练的模型之间具有可比性，但定性检查表明，混合数据集（特别是40%真实数据和60%合成数据）改善了全肿瘤边界的描绘。然而，肿瘤核心和增强肿瘤的区域精度仍然较低，表明类别不平衡问题仍然存在。

Conclusion: 虽然总体定量性能（Dice系数、IoU、精确率、召回率、准确率）在仅使用真实数据和混合数据训练的模型之间具有可比性，但定性检查表明，混合数据集（特别是40%真实数据和60%合成数据）改善了全肿瘤边界的描绘。然而，肿瘤核心和增强肿瘤的区域精度仍然较低，表明类别不平衡问题仍然存在。研究结果支持合成数据作为脑肿瘤分割的增强策略的可行性，同时也强调了在未来的工作中需要进行更大规模的实验、体积数据一致性以及减轻类别不平衡问题。

Abstract: Manual brain tumor segmentation from MRI scans is challenging due to tumor
heterogeneity, scarcity of annotated data, and class imbalance in medical
imaging datasets. Synthetic data generated by generative models has the
potential to mitigate these issues by improving dataset diversity. This study
investigates, as a proof of concept, the impact of incorporating synthetic MRI
data, generated using a pre-trained GAN model, into training a U-Net
segmentation network. Experiments were conducted using real data from the BraTS
2020 dataset, synthetic data generated with the medigan library, and hybrid
datasets combining real and synthetic samples in varying proportions. While
overall quantitative performance (Dice coefficient, IoU, precision, recall,
accuracy) was comparable between real-only and hybrid-trained models,
qualitative inspection suggested that hybrid datasets, particularly with 40%
real and 60% synthetic data, improved whole tumor boundary delineation.
However, region-wise accuracy for the tumor core and the enhancing tumor
remained lower, indicating a persistent class imbalance. The findings support
the feasibility of synthetic data as an augmentation strategy for brain tumor
segmentation, while highlighting the need for larger-scale experiments,
volumetric data consistency, and mitigating class imbalance in future work.

</details>


### [23] [Deep Learning For Point Cloud Denoising: A Survey](https://arxiv.org/abs/2508.11932)
*Chengwei Zhang,Xueyi Zhang,Mingrui Lao,Tao Jiang,Xinhao Xu,Wenjie Li,Fubo Zhang,Longyong Chen*

Main category: cs.CV

TL;DR: 本文对深度学习点云去噪（DL-based PCD）进行了全面的调查，强调了其在处理真实世界点云噪声中的重要性。文章提出了一个将PCD分为异常值移除和表面噪声恢复两步的框架，并对现有方法进行了分类和比较，同时讨论了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 由于真实世界环境中的点云必然存在不同模态和强度的噪声，因此点云去噪（PCD）作为提高下游任务性能的预处理步骤至关重要。DL-based PCD模型因其强大的表示能力和灵活的架构，在去噪性能上超越了传统方法。尽管近期性能有所提升，但据我们所知，尚未有全面的调查系统地总结DL-based PCD的发展。

Method: 本文识别DL-based PCD的关键挑战，总结现有方法的主要贡献，并提出一个针对去噪任务的分类法。通过将PCD分为异常值移除和表面噪声恢复两个步骤来涵盖大多数场景和需求。此外，比较了各种方法在相似性、差异性和各自优势方面的性能。

Result: 对现有方法进行了比较，讨论了研究局限性和未来方向，为PCD的进一步发展提供了见解。

Conclusion: 现有DL-based PCD方法在去噪性能上超越了传统方法，但尚无全面的调查系统地总结DL-based PCD的发展。

Abstract: Real-world environment-derived point clouds invariably exhibit noise across
varying modalities and intensities. Hence, point cloud denoising (PCD) is
essential as a preprocessing step to improve downstream task performance. Deep
learning (DL)-based PCD models, known for their strong representation
capabilities and flexible architectures, have surpassed traditional methods in
denoising performance. To our best knowledge, despite recent advances in
performance, no comprehensive survey systematically summarizes the developments
of DL-based PCD. To fill the gap, this paper seeks to identify key challenges
in DL-based PCD, summarizes the main contributions of existing methods, and
proposes a taxonomy tailored to denoising tasks. To achieve this goal, we
formulate PCD as a two-step process: outlier removal and surface noise
restoration, encompassing most scenarios and requirements of PCD. Additionally,
we compare methods in terms of similarities, differences, and respective
advantages. Finally, we discuss research limitations and future directions,
offering insights for further advancements in PCD.

</details>


### [24] [DynamicPose: Real-time and Robust 6D Object Pose Tracking for Fast-Moving Cameras and Objects](https://arxiv.org/abs/2508.11950)
*Tingbang Liang,Yixin Zeng,Jiatong Xie,Boyu Zhou*

Main category: cs.CV

TL;DR: DynamicPose is a new framework for robust 6D pose tracking, even with fast-moving cameras and objects. It uses visual-inertial odometry, a depth-informed 2D tracker, and a Kalman filter to achieve accurate and real-time results.


<details>
  <summary>Details</summary>
Motivation: Existing 6D pose tracking methods struggle with fast-moving cameras and objects, leading to significant performance degradation. This work aims to overcome these limitations by improving tracking robustness in such dynamic scenarios.

Method: DynamicPose utilizes a closed-loop system with three synergistic components: visual-inertial odometry to compensate for camera motion, a depth-informed 2D tracker for object translation, and a VIO-guided Kalman filter for pose prediction and refinement.

Result: Simulation and real-world experiments validate the effectiveness of DynamicPose, demonstrating its ability to perform accurate and robust 6D pose tracking in fast-moving camera and object situations.

Conclusion: The proposed DynamicPose framework achieves real-time and robust 6D pose tracking for fast-moving cameras and objects, outperforming previous methods in challenging scenarios.

Abstract: We present DynamicPose, a retraining-free 6D pose tracking framework that
improves tracking robustness in fast-moving camera and object scenarios.
Previous work is mainly applicable to static or quasi-static scenes, and its
performance significantly deteriorates when both the object and the camera move
rapidly. To overcome these challenges, we propose three synergistic components:
(1) A visual-inertial odometry compensates for the shift in the Region of
Interest (ROI) caused by camera motion; (2) A depth-informed 2D tracker
corrects ROI deviations caused by large object translation; (3) A VIO-guided
Kalman filter predicts object rotation, generates multiple candidate poses, and
then obtains the final pose by hierarchical refinement. The 6D pose tracking
results guide subsequent 2D tracking and Kalman filter updates, forming a
closed-loop system that ensures accurate pose initialization and precise pose
tracking. Simulation and real-world experiments demonstrate the effectiveness
of our method, achieving real-time and robust 6D pose tracking for fast-moving
cameras and objects.

</details>


### [25] [Transferable Class Statistics and Multi-scale Feature Approximation for 3D Object Detection](https://arxiv.org/abs/2508.11951)
*Hao Peng,Hong Sang,Yajing Ma,Ping Qiu,Chao Ji*

Main category: cs.CV

TL;DR: 本研究提出了一种轻量级的点云对象检测方法，通过知识蒸馏近似多尺度特征，并利用可迁移特征和中心加权交并比提高检测和定位精度，同时降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有对象检测方法在点云多尺度特征学习中通常需要多邻域搜索和多尺度感知层，导致模型笨重且不适用于计算资源受限的研究这一问题。

Method: 本研究提出了一种基于知识蒸馏的方法来近似点云的多尺度特征，并设计了一种可迁移特征嵌入机制，利用类别感知统计信息来弥补单邻域的局限性。此外，还引入了中心加权交并比（CW-IoU）用于定位，以解决中心偏移带来的优化不匹配问题。

Result: 该方法在公共数据集上的广泛实验证明了其有效性，并在计算成本上进行了节省。

Conclusion: 该研究通过知识蒸馏和可迁移特征嵌入机制，实现了从单邻域近似点云多尺度特征，并提出了中心加权交并比用于定位，有效解决了现有方法计算成本高的问题。

Abstract: This paper investigates multi-scale feature approximation and transferable
features for object detection from point clouds. Multi-scale features are
critical for object detection from point clouds. However, multi-scale feature
learning usually involves multiple neighborhood searches and scale-aware
layers, which can hinder efforts to achieve lightweight models and may not be
conducive to research constrained by limited computational resources. This
paper approximates point-based multi-scale features from a single neighborhood
based on knowledge distillation. To compensate for the loss of constructive
diversity in a single neighborhood, this paper designs a transferable feature
embedding mechanism. Specifically, class-aware statistics are employed as
transferable features given the small computational cost. In addition, this
paper introduces the central weighted intersection over union for localization
to alleviate the misalignment brought by the center offset in optimization.
Note that the method presented in this paper saves computational costs.
Extensive experiments on public datasets demonstrate the effectiveness of the
proposed method.

</details>


### [26] [UniUGG: Unified 3D Understanding and Generation via Geometric-Semantic Encoding](https://arxiv.org/abs/2508.11952)
*Yueming Xu,Jiahui Zhang,Ze Huang,Yurui Chen,Yanpeng Zhou,Zhenyu Chen,Yu-Jie Yuan,Pengxiang Xia,Guowei Huang,Xinyue Cai,Zhongang Qi,Xingyue Quan,Jianye Hao,Hang Xu,Li Zhang*

Main category: cs.CV

TL;DR: UniUGG是首个统一的3D理解和生成框架，利用LLM和扩散模型处理3D数据，并在实验中展现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 当前统一框架在整合3D任务方面仍具挑战且探索不足，因此提出UniUGG来解决这一问题。

Method: UniUGG是一个统一的理解和生成框架，使用LLM处理文本和3D表示，并利用潜在扩散模型进行3D场景生成，同时采用几何-语义学习策略进行视觉编码器预训练。

Result: 实验证明UniUGG在视觉表示、空间理解和3D生成方面均取得优越性能。

Conclusion: UniUGG在视觉表示、空间理解和3D生成方面表现优越，超越了现有方法。

Abstract: Despite the impressive progress on understanding and generating images shown
by the recent unified architectures, the integration of 3D tasks remains
challenging and largely unexplored. In this paper, we introduce UniUGG, the
first unified understanding and generation framework for 3D modalities. Our
unified framework employs an LLM to comprehend and decode sentences and 3D
representations. At its core, we propose a spatial decoder leveraging a latent
diffusion model to generate high-quality 3D representations. This allows for
the generation and imagination of 3D scenes based on a reference image and an
arbitrary view transformation, while remaining supports for spatial visual
question answering (VQA) tasks. Additionally, we propose a geometric-semantic
learning strategy to pretrain the vision encoder. This design jointly captures
the input's semantic and geometric cues, enhancing both spatial understanding
and generation. Extensive experimental results demonstrate the superiority of
our method in visual representation, spatial understanding, and 3D generation.
The source code will be released upon paper acceptance.

</details>


### [27] [SAMDWICH: Moment-aware Video-text Alignment for Referring Video Object Segmentation](https://arxiv.org/abs/2508.11955)
*Seunghun Lee,Jiwan Seo,Jeonghoon Kim,Siwon Kim,Haeun Yun,Hyogyeong Jeon,Wonhyeok Choi,Jaehoon Jeong,Zane Durante,Sang Hyun Park,Sunghoon Im*

Main category: cs.CV

TL;DR: 通过时序标注解决RVOS中的语义错位问题，提出SAMDWICH框架、MDP传播策略和OSS监督方法，并在MeViS基准测试中取得SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有 referring video object segmentation (RVOS) 方法存在语义错位问题，原因在于不加区分的帧采样和对所有可见对象的监督。

Method: 提出了一种名为SAMDWICH的框架，包含时序感知数据增强（SAMDWICH）、时序感知双路径传播（MDP）和对象级选择性监督（OSS）三种方法，并构建了一个新的标注数据集MeViS-M。

Result: SAMDWICH在MeViS基准测试中取得了最先进的性能，在复杂场景下的表现尤为突出。

Conclusion: SAMDWICH框架通过引入时序标注，实现了更精确的视频-文本对齐，并在MeViS基准测试中取得了最先进的性能，尤其在复杂场景下表现优异。

Abstract: Referring Video Object Segmentation (RVOS) aims to segment and track objects
in videos based on natural language expressions, requiring precise alignment
between visual content and textual queries. However, existing methods often
suffer from semantic misalignment, largely due to indiscriminate frame sampling
and supervision of all visible objects during training -- regardless of their
actual relevance to the expression. To address this, we introduce a
moment-aware RVOS framework named SAMDWICH, along with a newly annotated
dataset, MeViS-M, built upon the challenging MeViS benchmark. We manually
annotate temporal moments indicating when each object is referred to by the
expression, enabling semantically grounded supervision that strengthens
video-text alignment. SAMDWICH leverages these aligned text-to-clip pairs to
guide training, significantly enhancing referential understanding. Building
upon this framework, we propose Moment-guided Dual-path Propagation (MDP), a
moment-aware propagation strategy that improves both object grounding and
tracking by training on both relevant and irrelevant frames through a
moment-centric memory mechanism. In addition, we introduce Object-level
Selective Supervision (OSS), an object-level filtering strategy that supervises
only the objects temporally aligned with the expression in each training clip.
This selective supervision reduces semantic noise and reinforces
language-conditioned learning. Extensive experiments show that SAMDWICH
achieves state-of-the-art performance on challenging MeViS benchmark,
particularly excelling in complex scenarios involving diverse expressions.

</details>


### [28] [PEdger++: Practical Edge Detection via Assembling Cross Information](https://arxiv.org/abs/2508.11961)
*Yuanbin Fu,Liang Li,Xiaojie Guo*

Main category: cs.CV

TL;DR: PEdger++是一种协作学习框架，通过利用异构架构、多样化训练和多参数采样来提高边缘检测精度，同时降低计算成本和模型尺寸，适用于资源受限的设备。


<details>
  <summary>Details</summary>
Motivation: 旨在解决深度学习边缘检测模型计算成本高、模型复杂的问题，以满足在计算能力有限的设备上广泛部署的需求。

Method: PEdger++是一个协作学习框架，通过异构架构、多样化的训练时刻和多参数采样来利用交叉信息，以提高模型性能。

Result: PEdger++在BSDS500、NYUD和Multicue数据集上取得了优于现有方法的性能，并提供了多种计算需求不同的模型版本，展示了其适应不同资源限制的灵活性。

Conclusion: PEdger++在BSDS500、NYUD和Multicue数据集上的广泛实验结果（定量和定性）表明，该方法优于现有方法，并且在计算成本和模型尺寸方面进行了优化，同时提高了边缘检测精度。

Abstract: Edge detection serves as a critical foundation for numerous computer vision
applications, including object detection, semantic segmentation, and image
editing, by extracting essential structural cues that define object boundaries
and salient edges. To be viable for broad deployment across devices with
varying computational capacities, edge detectors shall balance high accuracy
with low computational complexity. While deep learning has evidently improved
accuracy, they often suffer from high computational costs, limiting their
applicability on resource-constrained devices. This paper addresses the
challenge of achieving that balance: \textit{i.e.}, {how to efficiently capture
discriminative features without relying on large-size and sophisticated
models}. We propose PEdger++, a collaborative learning framework designed to
reduce computational costs and model sizes while improving edge detection
accuracy. The core principle of our PEdger++ is that cross-information derived
from heterogeneous architectures, diverse training moments, and multiple
parameter samplings, is beneficial to enhance learning from an ensemble
perspective. Extensive experimental results on the BSDS500, NYUD and Multicue
datasets demonstrate the effectiveness of our approach, both quantitatively and
qualitatively, showing clear improvements over existing methods. We also
provide multiple versions of the model with varying computational requirements,
highlighting PEdger++'s adaptability with respect to different resource
constraints. Codes are accessible at
https://github.com/ForawardStar/EdgeDetectionviaPEdgerPlus/.

</details>


### [29] [Exploring Spatial-Temporal Dynamics in Event-based Facial Micro-Expression Analysis](https://arxiv.org/abs/2508.11988)
*Nicolas Mastropasqua,Ignacio Bugueno-Cordova,Rodrigo Verschae,Daniel Acevedo,Pablo Negri,Maria E. Buemi*

Main category: cs.CV

TL;DR: This paper introduces a new dataset for micro-expression analysis using both RGB and event cameras. Event cameras show better performance in Action Unit classification and frame reconstruction compared to RGB cameras.


<details>
  <summary>Details</summary>
Motivation: Accurately capturing subtle and fast facial movements with RGB cameras is difficult due to limitations in temporal resolution and sensitivity to motion blur. Event cameras offer an alternative with microsecond-level precision, high dynamic range, and low latency, but public datasets featuring event-based recordings of Action Units are scarce.

Method: The paper introduces a novel, preliminary multi-resolution and multi-modal micro-expression dataset recorded with synchronized RGB and event cameras under variable lighting conditions. Two baseline tasks are evaluated: Action Unit classification using Spiking Neural Networks and frame reconstruction using Conditional Variational Autoencoders.

Result: Action Unit classification achieved 51.23% accuracy with events vs. 23.12% with RGB. Frame reconstruction achieved SSIM = 0.8513 and PSNR = 26.89 dB with high-resolution event input.

Conclusion: Event-based data can be used for micro-expression recognition and frame reconstruction.

Abstract: Micro-expression analysis has applications in domains such as Human-Robot
Interaction and Driver Monitoring Systems. Accurately capturing subtle and fast
facial movements remains difficult when relying solely on RGB cameras, due to
limitations in temporal resolution and sensitivity to motion blur. Event
cameras offer an alternative, with microsecond-level precision, high dynamic
range, and low latency. However, public datasets featuring event-based
recordings of Action Units are still scarce. In this work, we introduce a
novel, preliminary multi-resolution and multi-modal micro-expression dataset
recorded with synchronized RGB and event cameras under variable lighting
conditions. Two baseline tasks are evaluated to explore the spatial-temporal
dynamics of micro-expressions: Action Unit classification using Spiking Neural
Networks (51.23\% accuracy with events vs. 23.12\% with RGB), and frame
reconstruction using Conditional Variational Autoencoders, achieving SSIM =
0.8513 and PSNR = 26.89 dB with high-resolution event input. These promising
results show that event-based data can be used for micro-expression recognition
and frame reconstruction.

</details>


### [30] [MOON: Generative MLLM-based Multimodal Representation Learning for E-commerce Product Understanding](https://arxiv.org/abs/2508.11999)
*Daoze Zhang,Zhanheng Nie,Jianyu Liu,Chenghan Fu,Wanxian Guan,Yuan Gao,Jun Song,Pengjie Wang,Jian Xu,Bo Zheng*

Main category: cs.CV

TL;DR: MOON是一个利用生成式MLLM和混合专家（MoE）模块的新模型，通过解决背景噪声和改进负采样策略来提升产品表示学习。它在产品理解任务上表现出色，并在MBE基准和公开数据集上取得了优异的零样本性能。


<details>
  <summary>Details</summary>
Motivation: 现有判别式双流架构在对产品多图像与文本进行多对一的建模方面存在不足，而生成式MLLM在产品表示学习方面具有巨大潜力。然而，实现这一目标仍面临多模态和面向方面建模不足、产品图像背景噪声干扰以及缺乏标准评估基准等挑战。

Method: 1. 提出了一种名为MOON的生成式MLLM模型，用于产品表示学习。
2. 采用引导式混合专家（MoE）模块，针对性地对多模态和面向方面（aspect-specific）的产品内容进行建模。
3. 有效检测产品图像中的核心语义区域，以减轻背景噪声的干扰。
4. 引入了专门的负采样策略，以增加负样本的难度和多样性。
5. 发布了一个大规模多模态基准MBE，用于各种产品理解任务。

Result: MOON模型通过实验证明了其在产品理解任务上的有效性，并在多个下游任务中取得了具有竞争力的零样本性能。

Conclusion: MOON模型在MBE基准和公开数据集上展示了具有竞争力的零样本性能，在跨模态检索、产品分类和属性预测等各种下游任务中表现出强大的泛化能力。案例研究和可视化进一步证明了MOON在产品理解方面的有效性。

Abstract: With the rapid advancement of e-commerce, exploring general representations
rather than task-specific ones has attracted increasing research attention. For
product understanding, although existing discriminative dual-flow architectures
drive progress in this field, they inherently struggle to model the many-to-one
alignment between multiple images and texts of products. Therefore, we argue
that generative Multimodal Large Language Models (MLLMs) hold significant
potential for improving product representation learning. Nevertheless,
achieving this goal still remains non-trivial due to several key challenges:
the lack of multimodal and aspect-aware modeling modules in typical LLMs; the
common presence of background noise in product images; and the absence of a
standard benchmark for evaluation. To address these issues, we propose the
first generative MLLM-based model named MOON for product representation
learning. Our method (1) employs a guided Mixture-of-Experts (MoE) module for
targeted modeling of multimodal and aspect-specific product content; (2)
effectively detects core semantic regions in product images to mitigate the
distraction and interference caused by background noise; and (3) introduces the
specialized negative sampling strategy to increase the difficulty and diversity
of negative samples. In addition, we release a large-scale multimodal benchmark
MBE for various product understanding tasks. Experimentally, our model
demonstrates competitive zero-shot performance on both our benchmark and the
public dataset, showcasing strong generalization across various downstream
tasks, including cross-modal retrieval, product classification, and attribute
prediction. Furthermore, the case study and visualization illustrate the
effectiveness of MOON for product understanding.

</details>


### [31] [InstDrive: Instance-Aware 3D Gaussian Splatting for Driving Scenes](https://arxiv.org/abs/2508.12015)
*Hongyuan Liu,Haochen Yu,Jianfei Jiang,Qiankun Liu,Jiansheng Chen,Huimin Ma*

Main category: cs.CV

TL;DR: InstDrive是一个创新的框架，首次实现了在动态驾驶场景下的3D实例分割，通过结合2D掩码、3D正则化和码本，克服了现有方法的局限性，并有效实现了实例级别的场景重建。


<details>
  <summary>Details</summary>
Motivation: 现有的动态驾驶场景重建方法大多将所有背景元素统一为单一表示，这不利于实例级理解和灵活的场景编辑。一些方法尝试将2D分割提升到3D空间，但依赖预处理的实例ID或复杂的流程将连续特征映射到离散身份，且这些方法通常为具有丰富视角的室内场景设计，不太适用于室外驾驶场景。

Method: InstDrive使用SAM生成的掩码作为伪真实标签，通过对比损失和伪监督目标来指导2D特征学习。在3D层面，通过引入正则化以及基于体素的损失来隐式编码实例身份并强制执行一致性。此外，一个轻量级的静态码本在无需数据预处理或复杂优化的前提下，连接了连续特征和离散身份。

Result: InstDrive能够进行实例感知的3D高斯溅射重建，以支持动态驾驶场景的交互式重建。

Conclusion: InstDrive是首个在动态、开放世界驾驶场景中实现3D实例分割的框架，通过了定量和定性实验验证了其有效性。

Abstract: Reconstructing dynamic driving scenes from dashcam videos has attracted
increasing attention due to its significance in autonomous driving and scene
understanding. While recent advances have made impressive progress, most
methods still unify all background elements into a single representation,
hindering both instance-level understanding and flexible scene editing. Some
approaches attempt to lift 2D segmentation into 3D space, but often rely on
pre-processed instance IDs or complex pipelines to map continuous features to
discrete identities. Moreover, these methods are typically designed for indoor
scenes with rich viewpoints, making them less applicable to outdoor driving
scenarios. In this paper, we present InstDrive, an instance-aware 3D Gaussian
Splatting framework tailored for the interactive reconstruction of dynamic
driving scene. We use masks generated by SAM as pseudo ground-truth to guide 2D
feature learning via contrastive loss and pseudo-supervised objectives. At the
3D level, we introduce regularization to implicitly encode instance identities
and enforce consistency through a voxel-based loss. A lightweight static
codebook further bridges continuous features and discrete identities without
requiring data pre-processing or complex optimization. Quantitative and
qualitative experiments demonstrate the effectiveness of InstDrive, and to the
best of our knowledge, it is the first framework to achieve 3D instance
segmentation in dynamic, open-world driving scenes.More visualizations are
available at our project page.

</details>


### [32] [WiseLVAM: A Novel Framework For Left Ventricle Automatic Measurements](https://arxiv.org/abs/2508.12023)
*Durgesh Kumar Singh,Qing Cao,Sarina Thomas,Ahcène Boubekki,Robert Jenssen,Michael Kampffmeyer*

Main category: cs.CV

TL;DR: WiseLVAM是一个新的全自动框架，用于在超声心动图AMM模式下进行左心室线性测量，通过B模式图像的结构感知和AMM模式的运动感知提高了准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的自动方法在B模式图像上直接估计标志点，即使微小的位移也会导致显著的测量误差，降低了临床可靠性。EnLVAM方法通过将标志点预测约束在扫描线上并在AMM图像上进行训练来解决这个问题。为了实现完全自动化，需要一种能够自动放置扫描线的方法。

Method: 提出了一种感知轮廓的扫描线放置方法，利用弱监督B模式陆标检测器估计左心室轮廓，推断左心室长轴和基底水平以放置扫描线。在此基础上，提出了WiseLVAM框架，自动放置扫描线并在AMM模式下进行左心室线性测量，并允许手动调整。

Result: WiseLVAM框架能够自动放置扫描线并进行左心室线性测量，结合了B模式图像的结构感知和AMM模式的运动感知，提高了鲁棒性和准确性。

Conclusion: WiseLVAM框架能够自动放置扫描线并进行左心室线性测量，结合了B模式图像的结构感知和AMM模式的运动感知，提高了鲁棒性和准确性，有望在临床实践中得到应用。

Abstract: Clinical guidelines recommend performing left ventricular (LV) linear
measurements in B-mode echocardiographic images at the basal level -- typically
at the mitral valve leaflet tips -- and aligned perpendicular to the LV long
axis along a virtual scanline (SL). However, most automated methods estimate
landmarks directly from B-mode images for the measurement task, where even
small shifts in predicted points along the LV walls can lead to significant
measurement errors, reducing their clinical reliability. A recent
semi-automatic method, EnLVAM, addresses this limitation by constraining
landmark prediction to a clinician-defined SL and training on generated
Anatomical Motion Mode (AMM) images to predict LV landmarks along the same. To
enable full automation, a contour-aware SL placement approach is proposed in
this work, in which the LV contour is estimated using a weakly supervised
B-mode landmark detector. SL placement is then performed by inferring the LV
long axis and the basal level-mimicking clinical guidelines. Building on this
foundation, we introduce \textit{WiseLVAM} -- a novel, fully automated yet
manually adaptable framework for automatically placing the SL and then
automatically performing the LV linear measurements in the AMM mode.
\textit{WiseLVAM} utilizes the structure-awareness from B-mode images and the
motion-awareness from AMM mode to enhance robustness and accuracy with the
potential to provide a practical solution for the routine clinical application.

</details>


### [33] [Q-FSRU: Quantum-Augmented Frequency-Spectral Fusion for Medical Visual Question Answering](https://arxiv.org/abs/2508.12036)
*Rakesh Thakur,Yusra Tariq*

Main category: cs.CV

TL;DR: Q-FSRU模型通过频域转换和量子检索技术，提升了医学视觉问答的准确性和可解释性，尤其在处理复杂图文推理任务时效果显著。


<details>
  <summary>Details</summary>
Motivation: 解决医疗AI在理解医学图像和文本以回答复杂临床问题方面仍然面临的挑战。

Method: 提出了一种名为Q-FSRU的新模型，结合了频域表示（FSRU）和量子检索增强生成（Quantum RAG）技术。首先使用快速傅里叶变换（FFT）将医学图像和文本特征转换到频域，以关注有意义的数据并过滤噪声。然后，引入一个量子检索系统，利用基于量子相似性的技术从外部来源获取医学知识，并将其与频域特征融合，以增强推理能力。

Result: 在VQA-RAD数据集（包含真实放射影像和问题）上的评估结果显示，Q-FSRU模型的性能优于先前模型，尤其在需要图文推理的复杂病例上表现更佳。频域信息和量子信息的结合提高了模型的性能和可解释性。

Conclusion: Q-FSRU模型结合了频域表示和量子检索增强生成技术，在医学视觉问答任务中表现优于现有模型，尤其在需要图文推理的复杂病例上，为构建智能、可解释、有用的医疗AI工具提供了有前景的方法。

Abstract: Solving tough clinical questions that require both image and text
understanding is still a major challenge in healthcare AI. In this work, we
propose Q-FSRU, a new model that combines Frequency Spectrum Representation and
Fusion (FSRU) with a method called Quantum Retrieval-Augmented Generation
(Quantum RAG) for medical Visual Question Answering (VQA). The model takes in
features from medical images and related text, then shifts them into the
frequency domain using Fast Fourier Transform (FFT). This helps it focus on
more meaningful data and filter out noise or less useful information. To
improve accuracy and ensure that answers are based on real knowledge, we add a
quantum-inspired retrieval system. It fetches useful medical facts from
external sources using quantum-based similarity techniques. These details are
then merged with the frequency-based features for stronger reasoning. We
evaluated our model using the VQA-RAD dataset, which includes real radiology
images and questions. The results showed that Q-FSRU outperforms earlier
models, especially on complex cases needing image-text reasoning. The mix of
frequency and quantum information improves both performance and explainability.
Overall, this approach offers a promising way to build smart, clear, and
helpful AI tools for doctors.

</details>


### [34] [VimoRAG: Video-based Retrieval-augmented 3D Motion Generation for Motion Language Models](https://arxiv.org/abs/2508.12081)
*Haidong Xu,Guangwei Xu,Zhedong Zheng,Xiatian Zhu,Wei Ji,Xiangtai Li,Ruijie Guo,Meishan Zhang,Min zhang,Hao Fei*

Main category: cs.CV

TL;DR: VimoRAG是一个新颖的视频检索增强运动生成框架，通过检索相关的2D人类运动信号来解决运动大语言模型（LLM）的领域外/词汇外问题，并取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 由于标注数据有限，运动大语言模型（LLM）在处理领域外或词汇外的数据时存在严重问题。为了解决这个问题，本研究提出了VimoRAG，一个视频检索增强的运动生成框架，旨在利用大规模野外视频数据库来改进3D运动生成。

Method: VimoRAG框架结合了运动大语言模型和检索增强生成（RAG），利用大规模野外视频数据库和运动中心视频检索来增强3D动作生成。具体方法包括设计Gemini运动视频检索器和运动中心双对齐DPO训练器，以解决视频检索中的关键瓶颈：动作识别和次优检索结果的错误传播问题。

Result: 实验结果表明，VimoRAG在仅限文本输入的运动LLM方面取得了显著的性能提升。

Conclusion: VimoRAG通过Gemini运动视频检索器和运动中心双对齐DPO训练器，有效解决了运动大语言模型（LLM）的领域外/词汇外问题，显著提升了仅限文本输入的运动LLM的性能。

Abstract: This paper introduces VimoRAG, a novel video-based retrieval-augmented motion
generation framework for motion large language models (LLMs). As motion LLMs
face severe out-of-domain/out-of-vocabulary issues due to limited annotated
data, VimoRAG leverages large-scale in-the-wild video databases to enhance 3D
motion generation by retrieving relevant 2D human motion signals. While
video-based motion RAG is nontrivial, we address two key bottlenecks: (1)
developing an effective motion-centered video retrieval model that
distinguishes human poses and actions, and (2) mitigating the issue of error
propagation caused by suboptimal retrieval results. We design the Gemini Motion
Video Retriever mechanism and the Motion-centric Dual-alignment DPO Trainer,
enabling effective retrieval and generation processes. Experimental results
show that VimoRAG significantly boosts the performance of motion LLMs
constrained to text-only input.

</details>


### [35] [Automated Model Evaluation for Object Detection via Prediction Consistency and Reliablity](https://arxiv.org/abs/2508.12082)
*Seungju Yoo,Hyuk Kwon,Joong-Won Hwang,Kibok Lee*

Main category: cs.CV

TL;DR: This paper introduces AutoEval, an automated framework for evaluating object detectors without manual annotation. It uses a novel metric called PCR, which analyzes bounding box consistency and reliability, to estimate performance. A new meta-dataset with image corruptions was also created for more realistic testing.


<details>
  <summary>Details</summary>
Motivation: Assessing object detector performance in real-world applications relies on costly manual annotation. The motivation is to develop an automated model evaluation framework to address this limitation.

Method: The paper proposes an automated model evaluation (AutoEval) framework for object detection, introducing Prediction Consistency and Reliability (PCR). PCR leverages multiple candidate bounding boxes before non-maximum suppression (NMS) to estimate detection performance without ground-truth labels. It jointly measures spatial consistency between boxes before and after NMS, and the reliability of retained boxes using confidence scores of overlapping boxes. A meta-dataset was constructed using image corruptions to simulate realistic and scalable evaluation.

Result: PCR yields more accurate performance estimates than existing AutoEval methods. The constructed meta-dataset covers a wider range of detection performance.

Conclusion: PCR yields more accurate performance estimates than existing AutoEval methods, and the proposed meta-dataset covers a wider range of detection performance.

Abstract: Recent advances in computer vision have made training object detectors more
efficient and effective; however, assessing their performance in real-world
applications still relies on costly manual annotation. To address this
limitation, we develop an automated model evaluation (AutoEval) framework for
object detection. We propose Prediction Consistency and Reliability (PCR),
which leverages the multiple candidate bounding boxes that conventional
detectors generate before non-maximum suppression (NMS). PCR estimates
detection performance without ground-truth labels by jointly measuring 1) the
spatial consistency between boxes before and after NMS, and 2) the reliability
of the retained boxes via the confidence scores of overlapping boxes. For a
more realistic and scalable evaluation, we construct a meta-dataset by applying
image corruptions of varying severity. Experimental results demonstrate that
PCR yields more accurate performance estimates than existing AutoEval methods,
and the proposed meta-dataset covers a wider range of detection performance.
The code is available at https://github.com/YonseiML/autoeval-det.

</details>


### [36] [Generic Event Boundary Detection via Denoising Diffusion](https://arxiv.org/abs/2508.12084)
*Jaejun Hwang,Dayoung Gong,Manjin Kim,Minsu Cho*

Main category: cs.CV

TL;DR: DiffGEBD是一个新的基于扩散的模型，用于事件边界检测，它从生成角度解决了这个问题，并能生成多样化和合理的事件边界。


<details>
  <summary>Details</summary>
Motivation: 以往的GEBD方法侧重于确定性预测，忽略了合理解决方案的多样性，而GEBD本身具有主观性。

Method: 提出了一种新颖的基于扩散的边界检测模型DiffGEBD，该模型通过时间自相似性对相邻帧之间的相关变化进行编码，然后将随机噪声迭代解码为以编码特征为条件的、合理的事件边界。使用无分类器引导来控制去噪扩散中的多样性程度。

Result: DiffGEBD能够生成多样化且合理 Event Boundaries。

Conclusion: DiffGEBD在Kinetics-GEBD和TAPOS两个标准基准上取得了强大的性能，能够生成多样化且合理 Event Boundaries。

Abstract: Generic event boundary detection (GEBD) aims to identify natural boundaries
in a video, segmenting it into distinct and meaningful chunks. Despite the
inherent subjectivity of event boundaries, previous methods have focused on
deterministic predictions, overlooking the diversity of plausible solutions. In
this paper, we introduce a novel diffusion-based boundary detection model,
dubbed DiffGEBD, that tackles the problem of GEBD from a generative
perspective. The proposed model encodes relevant changes across adjacent frames
via temporal self-similarity and then iteratively decodes random noise into
plausible event boundaries being conditioned on the encoded features.
Classifier-free guidance allows the degree of diversity to be controlled in
denoising diffusion. In addition, we introduce a new evaluation metric to
assess the quality of predictions considering both diversity and fidelity.
Experiments show that our method achieves strong performance on two standard
benchmarks, Kinetics-GEBD and TAPOS, generating diverse and plausible event
boundaries.

</details>


### [37] [Enhancing 3D point accuracy of laser scanner through multi-stage convolutional neural network for applications in construction](https://arxiv.org/abs/2508.12089)
*Qinyuan Fan,Clemens Gühmann*

Main category: cs.CV

TL;DR: 提出一种基于多阶段卷积神经网络（MSCNN）的方法，通过将低端激光扫描仪（LAS）与高精度扫描仪（HAS）进行配对，量化并修正LAS的测量误差，显著提升了测量精度，使低端设备性能接近高端设备。


<details>
  <summary>Details</summary>
Motivation: 为了解决室内粗糙环境中，不同设备（高端和低端激光扫描仪）由于自身限制和环境因素导致的3D点定位不确定性问题，以提供更精确的空间测量数据，用于高精度几何模型创建和室内改造。

Method: 提出了一种结合传统几何处理和卷积神经网络（CNN）的修正框架。该框架将系统误差量化转化为监督学习问题，通过配对高精度扫描（HAS）和低精度扫描（LAS）的数据，建立测量差异与空间分布之间的统计关系，实现精确修正并保留几何特征。

Result: 实验结果表明，该方法在粗糙室内房间数据集上实现了显著的测量精度提升，均方误差（MSE）降低超过70%，峰值信噪比（PSNR）提高了约6分贝。

Conclusion: 该方法能够显著提高低端激光扫描设备的测量精度，使其接近高端设备的水平，且无需硬件升级。

Abstract: We propose a multi-stage convolutional neural network (MSCNN) based
integrated method for reducing uncertainty of 3D point accuracy of lasar
scanner (LS) in rough indoor rooms, providing more accurate spatial
measurements for high-precision geometric model creation and renovation. Due to
different equipment limitations and environmental factors, high-end and low-end
LS have positional errors. Our approach pairs high-accuracy scanners (HAS) as
references with corresponding low-accuracy scanners (LAS) of measurements in
identical environments to quantify specific error patterns. By establishing a
statistical relationship between measurement discrepancies and their spatial
distribution, we develop a correction framework that combines traditional
geometric processing with targeted neural network refinement. This method
transforms the quantification of systematic errors into a supervised learning
problem, allowing precise correction while preserving critical geometric
features. Experimental results in our rough indoor rooms dataset show
significant improvements in measurement accuracy, with mean square error (MSE)
reductions exceeding 70% and peak signal-to-noise ratio (PSNR) improvements of
approximately 6 decibels. This approach enables low-end devices to achieve
measurement uncertainty levels approaching those of high-end devices without
hardware modifications.

</details>


### [38] [Error Propagation Mechanisms and Compensation Strategies for Quantized Diffusion](https://arxiv.org/abs/2508.12094)
*Songwei Liu,Hong Liu,Fangmin Chen,Xurui Peng,Chenqian Yan,Lean Fu,Xing Mei*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的理论框架和补偿方案，用于解决扩散模型量化中的误差累积问题，通过数学分析和实验验证，有效提升了低精度扩散模型的性能。


<details>
  <summary>Details</summary>
Motivation: 解决扩散模型大规模部署中由于计算密集型迭代去噪过程带来的挑战，以及迭代性质导致量化误差累积影响输出保真度的问题。

Method: 提出了一种考虑时间步的累积误差补偿方案，该方案基于所导出的每步量化误差传播方程和累积误差的闭式解。

Result: 实验结果表明，该补偿策略有效缓解了误差传播，提升了低精度扩散模型的性能，达到了SOTA水平。

Conclusion: 所提出的补偿策略有效缓解了误差累积，显著提升了现有PTQ方法的性能，在低精度扩散模型上达到了SOTA性能。

Abstract: Diffusion models have transformed image synthesis by establishing
unprecedented quality and creativity benchmarks. Nevertheless, their
large-scale deployment faces challenges due to computationally intensive
iterative denoising processes. Although post-training quantization(PTQ)
provides an effective pathway for accelerating sampling, the iterative nature
of diffusion models causes stepwise quantization errors to accumulate
progressively during generation, inevitably compromising output fidelity. To
address this challenge, we develop a theoretical framework that mathematically
formulates error propagation in Diffusion Models (DMs), deriving per-step
quantization error propagation equations and establishing the first closed-form
solution for cumulative error. Building on this theoretical foundation, we
propose a timestep-aware cumulative error compensation scheme. Extensive
experiments across multiple image datasets demonstrate that our compensation
strategy effectively mitigates error propagation, significantly enhancing
existing PTQ methods to achieve state-of-the-art(SOTA) performance on
low-precision diffusion models.

</details>


### [39] [VELVET-Med: Vision and Efficient Language Pre-training for Volumetric Imaging Tasks in Medicine](https://arxiv.org/abs/2508.12108)
*Ziyang Zhang,Yang Yu,Xulei Yang,Si Yong Yeo*

Main category: cs.CV

TL;DR: VELVET-Med 是一个用于有限体积医学数据的视觉语言预训练框架，通过结合单模态自监督学习、TriBERT 语言编码器和分层对比学习，提高了模型在各种下游任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决医学领域中用于体积模态（如 CT 扫描）的大规模配对数据难以获取的问题，该研究提出了 VELVET-Med 框架。

Method: VELVET-Med 框架结合了单模态自监督学习、TriBERT 语言编码器和分层对比学习，用于处理 3D CT 扫描和放射学报告。

Result: VELVET-Med 在 38,875 个扫描报告对的数据集上，在 3D 分割、跨模态检索、视觉问答和报告生成等下游任务中取得了最先进的性能。

Conclusion: VELVET-Med 在有限的体积医学数据上取得了最先进的性能，展示了其在下游任务中的可转移性和有效性。

Abstract: Vision-and-language models (VLMs) have been increasingly explored in the
medical domain, particularly following the success of CLIP in general domain.
However, unlike the relatively straightforward pairing of 2D images and text,
curating large-scale paired data in the medical field for volumetric modalities
such as CT scans remains a challenging and time-intensive process. This
difficulty often limits the performance on downstream tasks. To address these
challenges, we propose a novel vision-language pre-training (VLP) framework,
termed as \textbf{VELVET-Med}, specifically designed for limited volumetric
data such as 3D CT and associated radiology reports. Instead of relying on
large-scale data collection, our method focuses on the development of effective
pre-training objectives and model architectures. The key contributions are: 1)
We incorporate uni-modal self-supervised learning into VLP framework, which are
often underexplored in the existing literature. 2) We propose a novel language
encoder, termed as \textbf{TriBERT}, for learning multi-level textual
semantics. 3) We devise the hierarchical contrastive learning to capture
multi-level vision-language correspondence. Using only 38,875 scan-report
pairs, our approach seeks to uncover rich spatial and semantic relationships
embedded in volumetric medical images and corresponding clinical narratives,
thereby enhancing the generalization ability of the learned encoders. The
resulting encoders exhibit strong transferability, achieving state-of-the-art
performance across a wide range of downstream tasks, including 3D segmentation,
cross-modal retrieval, visual question answering, and report generation.

</details>


### [40] [Simple o3: Towards Interleaved Vision-Language Reasoning](https://arxiv.org/abs/2508.12109)
*Ye Wang,Qianglong Chen,Zejun Li,Siyuan Wang,Shijie Guo,Zhirui Zhang,Zhongyu Wei*

Main category: cs.CV

TL;DR: Simple o3是一个新框架，通过集成动态工具（如缩放、裁剪）到视觉-语言推理中，提升了多模态大语言模型的能力，并在多个基准测试中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 探索多模态大语言模型（MLLMs）在长链思考（CoT）方面的发展，尤其是在多模态场景下的能力。受到o3模型通过迭代视觉转换和语言推理来实现类似人类的“通过图像思考”的启发。

Method: 提出Simple o3框架，一个端到端的框架，通过监督微调（SFT）将动态工具交互（如裁剪、缩放和重用）集成到交错的视觉-语言推理中。利用“观察-推理-行动”周期的数据合成流程，生成高质量的交错视觉-语言推理链，并进行了严格的验证，创建了开源数据集TWI-Tools-146K。

Result: Simple o3在多个基准测试中表现出优越的性能，优于现有方法。通过引入额外的视觉标记，重用和放大图像可以显著提高模型的视觉推理和细粒度感知能力，而基于精确视觉基础的图像裁剪可以帮助模型有效关注关键实体或区域，进一步增强其能力。

Conclusion: Simple o3框架通过集成动态工具交互（如裁剪、缩放和重用）到交错的视觉-语言推理中，并结合监督微调（SFT），实现了强大的多模态推理能力。该框架在多个基准测试中表现优于现有方法，尤其是在引入额外视觉标记、重用和放大图像以及基于视觉基础的图像裁剪方面，显著提升了模型的视觉推理和细粒度感知能力。

Abstract: Multimodal Large Language Models (MLLMs) have shown impressive performance on
vision-language tasks, but their long Chain-of-Thought (CoT) capabilities in
multimodal scenarios remain underexplored. Inspired by OpenAI's o3 model, which
emulates human-like ''thinking with image'' through iterative visual
transformations and linguistic reasoning, we propose Simple o3, an end-to-end
framework that integrates dynamic tool interactions (e.g., cropping, zooming,
and reusing) into interleaved vision-language reasoning via supervised
fine-tuning (SFT). Our approach features a scalable data synthesis pipeline
that generates high-quality interleaved vision-language reasoning chains via an
''observe-reason-act'' cycle, complete with executable visual operations and
rigorous verification, yielding the open-source TWI-Tools-146K dataset.
Experimental results demonstrate Simple o3's superior performance on diverse
benchmarks, outperforming existing approaches. By combining enhanced reasoning
capabilities, Simple o3 establishes a powerful yet computationally affordable
paradigm for advancing multimodal reasoning. Remarkably, we provide the first
in-depth analysis of different interleaved reasoning strategies, offering
insights into their impact on model performance. We found that by introducing
additional visual tokens for interleaved vision-language reasoning, reusing and
magnifying the original image significantly improves the model's visual
reasoning and fine-grained perception, while image cropping based on precise
visual grounding allows the model to effectively focus on key entities or
regions, further enhancing its capabilities.

</details>


### [41] [DualFit: A Two-Stage Virtual Try-On via Warping and Synthesis](https://arxiv.org/abs/2508.12131)
*Minh Tran,Johnmark Clements,Annie Prasanna,Tri Nguyen,Ngan Le*

Main category: cs.CV

TL;DR: DualFit是一种新的VTON技术，通过两阶段方法解决了现有方法的不足，可以更好地保留服装细节，实现更真实的试穿效果。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于扩散的无变形VTON方法在保留Logo和印刷文本等细粒度服装细节方面的不足，这些细节对于品牌完整性和客户信任至关重要。

Method: DualFit采用两阶段混合VTON流程：第一阶段使用学习到的流场来对齐目标服装和人物图像，以实现高保真度。第二阶段，通过融合处理后的服装和保留的人体区域，以及引入保留区域输入和修复掩模来生成最终输出，以优先保留关键区域并仅在必要区域（尤其是在服装接缝处）进行重新生成。

Result: DualFit实现了视觉上无缝的试穿效果，同时忠实地保持了高频服装细节。

Conclusion: DualFit在保持高频服装细节的同时，实现了视觉上无缝的试穿效果，在重建准确性和感知真实性之间取得了有效的平衡。

Abstract: Virtual Try-On technology has garnered significant attention for its
potential to transform the online fashion retail experience by allowing users
to visualize how garments would look on them without physical trials. While
recent advances in diffusion-based warping-free methods have improved
perceptual quality, they often fail to preserve fine-grained garment details
such as logos and printed text elements that are critical for brand integrity
and customer trust. In this work, we propose DualFit, a hybrid VTON pipeline
that addresses this limitation by two-stage approach. In the first stage,
DualFit warps the target garment to align with the person image using a learned
flow field, ensuring high-fidelity preservation. In the second stage, a
fidelity-preserving try-on module synthesizes the final output by blending the
warped garment with preserved human regions. Particularly, to guide this
process, we introduce a preserved-region input and an inpainting mask, enabling
the model to retain key areas and regenerate only where necessary, particularly
around garment seams. Extensive qualitative results show that DualFit achieves
visually seamless try-on results while faithfully maintaining high-frequency
garment details, striking an effective balance between reconstruction accuracy
and perceptual realism.

</details>


### [42] [TriQDef: Disrupting Semantic and Gradient Alignment to Prevent Adversarial Patch Transferability in Quantized Neural Networks](https://arxiv.org/abs/2508.12132)
*Amira Guesmi,Bassem Ouni,Muhammad Shafique*

Main category: cs.CV

TL;DR: TriQDef通过在量化神经网络中引入三层量化感知防御来对抗基于块的对抗性攻击，成功地降低了攻击成功率并保持了准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的防御措施在应对量化神经网络（QNNs）中基于块的对抗性攻击方面存在不足，尤其是在跨位宽泛化方面。本研究旨在解决这一漏洞。

Method: TriQDef是一个三层量化感知防御框架，包括特征失对齐惩罚（FDP）、梯度感知失谐惩罚（GPDP）和联合量化感知训练协议，通过对感知相似性、边缘IoU和HOG余弦度量进行优化来实现。

Result: TriQDef在CIFAR-10和ImageNet上，在未见过的块和量化组合上，将攻击成功率（ASR）降低了40%以上，同时保持了高清洁精度。

Conclusion: TriQDef通过在中间表示中强制语义不一致，并显式地使跨位宽的输入梯度失面对齐，成功地削弱了基于块的对抗性攻击的传递性，在CIFAR-10和ImageNet上实现了超过40%的攻击成功率降低，同时保持了高清洁精度。

Abstract: Quantized Neural Networks (QNNs) are increasingly deployed in edge and
resource-constrained environments due to their efficiency in computation and
memory usage. While shown to distort the gradient landscape and weaken
conventional pixel-level attacks, it provides limited robustness against
patch-based adversarial attacks-localized, high-saliency perturbations that
remain surprisingly transferable across bit-widths. Existing defenses either
overfit to fixed quantization settings or fail to address this cross-bit
generalization vulnerability. We introduce \textbf{TriQDef}, a tri-level
quantization-aware defense framework designed to disrupt the transferability of
patch-based adversarial attacks across QNNs. TriQDef consists of: (1) a Feature
Disalignment Penalty (FDP) that enforces semantic inconsistency by penalizing
perceptual similarity in intermediate representations; (2) a Gradient
Perceptual Dissonance Penalty (GPDP) that explicitly misaligns input gradients
across bit-widths by minimizing structural and directional agreement via Edge
IoU and HOG Cosine metrics; and (3) a Joint Quantization-Aware Training
Protocol that unifies these penalties within a shared-weight training scheme
across multiple quantization levels. Extensive experiments on CIFAR-10 and
ImageNet demonstrate that TriQDef reduces Attack Success Rates (ASR) by over
40\% on unseen patch and quantization combinations, while preserving high clean
accuracy. Our findings underscore the importance of disrupting both semantic
and perceptual gradient alignment to mitigate patch transferability in QNNs.

</details>


### [43] [Infusing fine-grained visual knowledge to Vision-Language Models](https://arxiv.org/abs/2508.12137)
*Nikolaos-Antonios Ypsilantis,Kaifeng Chen,André Araujo,Ondřej Chum*

Main category: cs.CV

TL;DR: 一种新的微调方法，用于在细粒度视觉检索中优化预训练的视觉语言模型（VLM），同时防止灾难性遗忘，并在各种基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 为了解决预训练的视觉语言模型（VLM）在细粒度开放集视觉检索中的不足之处，并克服在微调视觉编码器时出现的灾难性遗忘问题，同时保留模型通用的视觉和跨模态能力。

Method: 提出了一种专门用于在细粒度领域适应和保留预训练视觉语言模型（VLM）的广泛多模态知识之间取得最佳平衡的微调方法。该方法借鉴了持续学习文献，系统地分析了旨在知识保留的标准正则化技术，并提出了一个有效的组合策略。此外，还讨论了验证集设计和超参数调整以确保可复现性和鲁棒泛化。

Result: 所提出的方法在细粒度和粗粒度图像-图像和图像-文本检索基准上都取得了优异的结果，并有效地保留了视觉-文本对齐。

Conclusion: 该方法在图像检索基准上取得了强劲的结果，并且在微调过程中无需文本数据或原始文本编码器即可保留视觉-文本对齐。

Abstract: Large-scale contrastive pre-training produces powerful Vision-and-Language
Models (VLMs) capable of generating representations (embeddings) effective for
a wide variety of visual and multimodal tasks. However, these pretrained
embeddings remain suboptimal for fine-grained open-set visual retrieval, where
state-of-the-art results require fine-tuning the vision encoder using annotated
domain-specific samples. Naively performing such fine-tuning typically leads to
catastrophic forgetting, severely diminishing the model's general-purpose
visual and cross-modal capabilities.
  In this work, we propose a fine-tuning method explicitly designed to achieve
optimal balance between fine-grained domain adaptation and retention of the
pretrained VLM's broad multimodal knowledge. Drawing inspiration from continual
learning literature, we systematically analyze standard regularization
techniques aimed at knowledge retention and propose an efficient and effective
combination strategy. Additionally, we address the commonly overlooked yet
critical aspects of validation set design and hyperparameter tuning to ensure
reproducibility and robust generalization across datasets and pretrained
models. We extensively evaluate our method on both fine-grained and
coarse-grained image-image and image-text retrieval benchmarks. Our approach
consistently achieves strong results, notably retaining the visual-text
alignment without utilizing any text data or the original text encoder during
fine-tuning. Code and model checkpoints: https://github.com/nikosips/infusing .

</details>


### [44] [KP-INR: A Dual-Branch Implicit Neural Representation Model for Cardiac Cine MRI Reconstruction](https://arxiv.org/abs/2508.12147)
*Donghang Lyu,Marius Staring,Mariya Doneva,Hildo J. Lamb,Nicola Pezzotti*

Main category: cs.CV

TL;DR: KP-INR是一种新的双分支INR方法，在k空间操作，通过结合位置嵌入和局部特征表示来提高心脏电影MRI的图像重建质量，解决了现有方法忽略邻近特征表示的问题。


<details>
  <summary>Details</summary>
Motivation: 为了减少扫描时间和呼吸屏气的不适，需要快速采集技术，但这些技术会降低图像质量。现有的INR方法主要依赖坐标嵌入，忽略了目标点及其邻近上下文的特征表示。

Method: KP-INR是一种双分支隐式神经表示（INR）方法，在k空间操作，通过一个分支处理k空间坐标的位置嵌入，另一个分支学习局部多尺度k空间特征表示，并使分支间交互，从两个分支逼近目标k空间值。

Result: KP-INR在CMRxRecon2024数据集上显示出比基线模型更好的性能，能够从欠采样的k空间数据中进行高质量的图像重建。

Conclusion: KP-INR方法在挑战性的笛卡尔k空间数据上实现了强大的性能，并在CMRxRecon2024数据集上得到了验证，其性能优于基线模型，显示了其在该领域的潜力。

Abstract: Cardiac Magnetic Resonance (CMR) imaging is a non-invasive method for
assessing cardiac structure, function, and blood flow. Cine MRI extends this by
capturing heart motion, providing detailed insights into cardiac mechanics. To
reduce scan time and breath-hold discomfort, fast acquisition techniques have
been utilized at the cost of lowering image quality. Recently, Implicit Neural
Representation (INR) methods have shown promise in unsupervised reconstruction
by learning coordinate-to-value mappings from undersampled data, enabling
high-quality image recovery. However, current existing INR methods primarily
focus on using coordinate-based positional embeddings to learn the mapping,
while overlooking the feature representations of the target point and its
neighboring context. In this work, we propose KP-INR, a dual-branch INR method
operating in k-space for cardiac cine MRI reconstruction: one branch processes
the positional embedding of k-space coordinates, while the other learns from
local multi-scale k-space feature representations at those coordinates. By
enabling cross-branch interaction and approximating the target k-space values
from both branches, KP-INR can achieve strong performance on challenging
Cartesian k-space data. Experiments on the CMRxRecon2024 dataset confirms its
improved performance over baseline models and highlights its potential in this
field.

</details>


### [45] [Demystifying Foreground-Background Memorization in Diffusion Models](https://arxiv.org/abs/2508.12148)
*Jimmy Z. Di,Yiwei Lu,Yaoliang Yu,Gautam Kamath,Adam Dziedzic,Franziska Boenisch*

Main category: cs.CV

TL;DR: 提出了一种名为FB-Mem的分割度量来量化扩散模型中的记忆化。研究发现记忆化比以前认为的更普遍，并且现有的缓解方法未能消除局部记忆化。


<details>
  <summary>Details</summary>
Motivation: 当前的检测方法只能识别完全重复的记忆，无法量化小图像区域的部分记忆化，以及超出特定提示-图像对的记忆模式。

Method: 提出了一种名为前景背景记忆（FB-Mem）的新型基于分割的度量，用于对生成图像中的记忆区域进行分类和量化。

Result: （1）单个提示的单个生成可能与相似训练图像的集群相关，揭示了超出 P-I 一一对应的复杂记忆模式；（2）记忆化比以前认为的更普遍。

Conclusion: 现有模型缓解记忆化的方法（如神经元失活和剪枝）未能消除局部记忆化，尤其是在前景区域。提出了一种使用聚类方法的更强的缓解方法。

Abstract: Diffusion models (DMs) memorize training images and can reproduce
near-duplicates during generation. Current detection methods identify verbatim
memorization but fail to capture two critical aspects: quantifying partial
memorization occurring in small image regions, and memorization patterns beyond
specific prompt-image pairs. To address these limitations, we propose
Foreground Background Memorization (FB-Mem), a novel segmentation-based metric
that classifies and quantifies memorized regions within generated images. Our
method reveals that memorization is more pervasive than previously understood:
(1) individual generations from single prompts may be linked to clusters of
similar training images, revealing complex memorization patterns that extend
beyond one-to-one correspondences; and (2) existing model-level mitigation
methods, such as neuron deactivation and pruning, fail to eliminate local
memorization, which persists particularly in foreground regions. Our work
establishes an effective framework for measuring memorization in diffusion
models, demonstrates the inadequacy of current mitigation approaches, and
proposes a stronger mitigation method using a clustering approach.

</details>


### [46] [RealTalk: Realistic Emotion-Aware Lifelike Talking-Head Synthesis](https://arxiv.org/abs/2508.12163)
*Wenqing Wang,Yun Fu*

Main category: cs.CV

TL;DR: RealTalk is a new framework that synthesizes talking heads with accurate and controllable emotions while preserving identity, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Current methods for synthesizing talking heads struggle to generate accurate and controllable emotional expressions while preserving the subject's identity, despite excelling in lip synchronization and image quality. This paper aims to address this gap.

Method: RealTalk utilizes a VAE to generate 3D facial landmarks from audio, combines these with emotion-label embeddings using a ResNet-based LDM for emotional landmarks, and then employs a novel tri-plane attention NeRF conditioned on landmarks and blendshape coefficients to synthesize emotional talking heads.

Result: RealTalk achieves high emotion accuracy, enhanced emotion controllability, and robust identity preservation in synthesized emotional talking heads.

Conclusion: RealTalk in experiments demonstrates superior performance compared to existing methods in terms of emotion accuracy, controllability, and identity preservation, thus advancing the development of socially intelligent AI systems.

Abstract: Emotion is a critical component of artificial social intelligence. However,
while current methods excel in lip synchronization and image quality, they
often fail to generate accurate and controllable emotional expressions while
preserving the subject's identity. To address this challenge, we introduce
RealTalk, a novel framework for synthesizing emotional talking heads with high
emotion accuracy, enhanced emotion controllability, and robust identity
preservation. RealTalk employs a variational autoencoder (VAE) to generate 3D
facial landmarks from driving audio, which are concatenated with emotion-label
embeddings using a ResNet-based landmark deformation model (LDM) to produce
emotional landmarks. These landmarks and facial blendshape coefficients jointly
condition a novel tri-plane attention Neural Radiance Field (NeRF) to
synthesize highly realistic emotional talking heads. Extensive experiments
demonstrate that RealTalk outperforms existing methods in emotion accuracy,
controllability, and identity preservation, advancing the development of
socially intelligent AI systems.

</details>


### [47] [Scalable RF Simulation in Generative 4D Worlds](https://arxiv.org/abs/2508.12176)
*Zhiwei Zheng,Dongyin Hu,Mingmin Zhao*

Main category: cs.CV

TL;DR: WaveVerse is a new framework that simulates realistic RF signals for indoor perception tasks, addressing the challenge of data collection. It uses a language-guided generator and ray tracing to create data for RF imaging and improve human activity recognition.


<details>
  <summary>Details</summary>
Motivation: Collecting high-quality RF data in dynamic and diverse indoor environments is a major challenge for indoor perception tasks.

Method: WaveVerse is a prompt-based, scalable framework that simulates realistic RF signals from generated indoor scenes with human motions. It utilizes a language-guided 4D world generator, a state-aware causal transformer for human motion generation conditioned on spatial constraints and texts, and a phase-coherent ray tracing simulator.

Result: Experiments demonstrate the effectiveness of WaveVerse in conditioned human motion generation and highlight its application in beamforming and respiration monitoring. Case studies show performance gains in ML-based high-resolution imaging and human activity recognition.

Conclusion: WaveVerse enables data generation for RF imaging for the first time and consistently achieves performance gain in both data-limited and data-adequate scenarios.

Abstract: Radio Frequency (RF) sensing has emerged as a powerful, privacy-preserving
alternative to vision-based methods for indoor perception tasks. However,
collecting high-quality RF data in dynamic and diverse indoor environments
remains a major challenge. To address this, we introduce WaveVerse, a
prompt-based, scalable framework that simulates realistic RF signals from
generated indoor scenes with human motions. WaveVerse introduces a
language-guided 4D world generator, which includes a state-aware causal
transformer for human motion generation conditioned on spatial constraints and
texts, and a phase-coherent ray tracing simulator that enables the simulation
of accurate and coherent RF signals. Experiments demonstrate the effectiveness
of our approach in conditioned human motion generation and highlight how phase
coherence is applied to beamforming and respiration monitoring. We further
present two case studies in ML-based high-resolution imaging and human activity
recognition, demonstrating that WaveVerse not only enables data generation for
RF imaging for the first time, but also consistently achieves performance gain
in both data-limited and data-adequate scenarios.

</details>


### [48] [Splat Feature Solver](https://arxiv.org/abs/2508.12216)
*Butian Xiong,Rong Liu,Kenneth Xu,Meida Chen,Andrew Feng*

Main category: cs.CV

TL;DR: 通过将特征提升问题公式化为稀疏线性逆问题，并引入Tikhonov Guidance和Post-Lifting Aggregation正则化策略，实现了高效且高质量的3D特征提升，在3D分割任务中达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 解决将丰富的通用属性最优地分配给3D图元，同时处理来自多视图图像的不一致性问题。

Method: 将特征提升问题统一为一个稀疏线性逆问题，通过核函数和特征无关的公式进行求解，并提出了两种互补的正则化策略（Tikhonov Guidance 和 Post-Lifting Aggregation）来解决不一致性和噪声问题。

Result: 提出了一种统一的、核函数无关和特征无关的特征提升问题公式，可以作为稀疏线性逆问题进行求解，并具有可证明的全局最优误差上界。提出的两种正则化策略增强了解决方案的稳定性和语义保真度。

Conclusion: 该方法在开放词汇3D分割基准测试中取得了最先进的性能，优于基于训练、基于分组和基于启发式前向的基线，并在几分钟内生成了提升后的特征。

Abstract: Feature lifting has emerged as a crucial component in 3D scene understanding,
enabling the attachment of rich image feature descriptors (e.g., DINO, CLIP)
onto splat-based 3D representations. The core challenge lies in optimally
assigning rich general attributes to 3D primitives while addressing the
inconsistency issues from multi-view images. We present a unified, kernel- and
feature-agnostic formulation of the feature lifting problem as a sparse linear
inverse problem, which can be solved efficiently in closed form. Our approach
admits a provable upper bound on the global optimal error under convex losses
for delivering high quality lifted features. To address inconsistencies and
noise in multi-view observations, we introduce two complementary regularization
strategies to stabilize the solution and enhance semantic fidelity. Tikhonov
Guidance enforces numerical stability through soft diagonal dominance, while
Post-Lifting Aggregation filters noisy inputs via feature clustering. Extensive
experiments demonstrate that our approach achieves state-of-the-art performance
on open-vocabulary 3D segmentation benchmarks, outperforming training-based,
grouping-based, and heuristic-forward baselines while producing the lifted
features in minutes. Code is available at
\href{https://github.com/saliteta/splat-distiller.git}{\textbf{github}}. We
also have a \href{https://splat-distiller.pages.dev/}

</details>


### [49] [C2PSA-Enhanced YOLOv11 Architecture: A Novel Approach for Small Target Detection in Cotton Disease Diagnosis](https://arxiv.org/abs/2508.12219)
*Kaiyuan Wang,Jixing Liu,Xiaobo Cai*

Main category: cs.CV

TL;DR: 通过优化YOLOv11（引入C2PSA模块、动态类别加权和Mosaic-MixUp增强），棉花病害检测精度和速度均得到显著提升，解决了小目标检测难、田间性能下降和多病害识别错误率高的问题，实现了移动端实时监测。


<details>
  <summary>Details</summary>
Motivation: 为了解决棉花病害检测中存在的三个关键挑战：1.早期小斑点检测精度低（漏检率35%）；2.田间条件下性能下降（准确率下降25%）；3.多病害场景下高错误率（34.7%）。

Method: 本研究提出了一种基于深度学习的YOLOv11优化方法，并开发了一个智能监测系统。具体包括：1. C2PSA模块用于增强小目标特征提取；2. 动态类别加权以处理样本不平衡问题；3. 改进的数据增强方法，如Mosaic-MixUp 缩放。

Result: 实验在包含4078张图像的数据集上进行，结果显示：mAP50提升至0.820（+8.0%），mAP50-95提升至0.705（+10.5%），推理速度达到158 FPS。移动部署的系统能够实现农业应用中的实时病害监测和精准治疗。

Conclusion: 该研究成功开发了一个基于深度学习的YOLOv11棉花病害检测优化系统，通过C2PSA模块、动态类别加权和Mosaic-MixUp数据增强等方法，显著提高了小目标检测精度、克服了田间条件下的性能下降问题，并降低了多病害场景下的错误率。实验结果表明，该系统在mAP50和mAP50-95方面分别取得了8.0%和10.5%的提升，同时保持了158 FPS的推理速度，实现了在移动设备上的实时病害监测和精准治疗。

Abstract: This study presents a deep learning-based optimization of YOLOv11 for cotton
disease detection, developing an intelligent monitoring system. Three key
challenges are addressed: (1) low precision in early spot detection (35%
leakage rate for sub-5mm2 spots), (2) performance degradation in field
conditions (25% accuracy drop), and (3) high error rates (34.7%) in
multi-disease scenarios. The proposed solutions include: C2PSA module for
enhanced small-target feature extraction; Dynamic category weighting to handle
sample imbalance; Improved data augmentation via Mosaic-MixUp scaling.
Experimental results on a 4,078-image dataset show: mAP50: 0.820 (+8.0%
improvement); mAP50-95: 0.705 (+10.5% improvement); Inference speed: 158 FPS.
The mobile-deployed system enables real-time disease monitoring and precision
treatment in agricultural applications.

</details>


### [50] [Precise Action-to-Video Generation Through Visual Action Prompts](https://arxiv.org/abs/2508.13104)
*Yuang Wang,Chao Wen,Haoyu Guo,Sida Peng,Minghan Qin,Hujun Bao,Xiaowei Zhou,Ruizhen Hu*

Main category: cs.CV

TL;DR: Visual action prompts (skeletons) solve the precision-generality trade-off in action-to-video generation by providing a transferable and precise action representation for complex interactions.


<details>
  <summary>Details</summary>
Motivation: Existing action-to-video generation methods face a precision-generality trade-off. Text, primitive actions, or coarse masks lack precision, while agent-centric signals sacrifice cross-domain transferability. The motivation is to balance action precision and dynamic transferability for complex interactions.

Method: The paper proposes "visual action prompts" which are visual skeletons used as a domain-agnostic action representation. Robust pipelines are developed to construct skeletons from human-object interaction (HOI) and dexterous robotic manipulation data. These visual skeletons are integrated into pre-trained video generation models via lightweight fine-tuning.

Result: The proposed approach enables precise action control of complex interactions in video generation while preserving cross-domain dynamics. Experiments on EgoVid, RT-1, and DROID datasets validate the effectiveness of the method.

Conclusion: Visual action prompts based on skeletons enable precise control of complex interactions in video generation while maintaining cross-domain dynamic transferability, as demonstrated on EgoVid, RT-1, and DROID datasets.

Abstract: We present visual action prompts, a unified action representation for
action-to-video generation of complex high-DoF interactions while maintaining
transferable visual dynamics across domains. Action-driven video generation
faces a precision-generality trade-off: existing methods using text, primitive
actions, or coarse masks offer generality but lack precision, while
agent-centric action signals provide precision at the cost of cross-domain
transferability. To balance action precision and dynamic transferability, we
propose to "render" actions into precise visual prompts as domain-agnostic
representations that preserve both geometric precision and cross-domain
adaptability for complex actions; specifically, we choose visual skeletons for
their generality and accessibility. We propose robust pipelines to construct
skeletons from two interaction-rich data sources - human-object interactions
(HOI) and dexterous robotic manipulation - enabling cross-domain training of
action-driven generative models. By integrating visual skeletons into
pretrained video generation models via lightweight fine-tuning, we enable
precise action control of complex interaction while preserving the learning of
cross-domain dynamics. Experiments on EgoVid, RT-1 and DROID demonstrate the
effectiveness of our proposed approach. Project page:
https://zju3dv.github.io/VAP/.

</details>


### [51] [In vivo 3D ultrasound computed tomography of musculoskeletal tissues with generative neural physics](https://arxiv.org/abs/2508.12226)
*Zhijun Zeng,Youjia Zheng,Chang Su,Qianhang Wu,Hao Hu,Zeyuan Dong,Shan Gao,Yang Lv,Rui Tang,Ligang Cui,Zhiyong Hou,Weijun Lin,Zuoqiang Shi,Yubing Li,He Sun*

Main category: cs.CV

TL;DR: 我们提出了一种生成神经物理框架，将生成网络与物理信息神经模拟相结合，通过学习超声波传播的紧凑代理，实现了快速、高保真的三维USCT，可用于肌肉骨骼成像。


<details>
  <summary>Details</summary>
Motivation: 超声计算机断层扫描（USCT）是一种无辐射、高分辨率的模式，但由于忽略强散射的传统基于射线的方法而限制了其在肌肉骨骼成像中的应用。

Method: 提出了一种生成神经物理框架，将生成网络与物理信息神经模拟相结合，实现快速、高保真的三维USCT。该方法通过学习仅数十张跨模态图像的超声波传播的紧凑代理，将波建模的准确性与深度学习的效率和稳定性相结合。

Result: 在合成和体数据（乳房、手臂、腿部）上，我们能在十分钟内重建组织参数的三维图，在肌肉和骨骼中对生物力学特性具有敏感性，并且分辨率可与MRI相媲美。

Conclusion: 该方法通过克服强散射情况下的计算瓶颈，将超声计算机断层扫描（USCT）推进到常规临床评估肌肉骨骼疾病的水平。

Abstract: Ultrasound computed tomography (USCT) is a radiation-free, high-resolution
modality but remains limited for musculoskeletal imaging due to conventional
ray-based reconstructions that neglect strong scattering. We propose a
generative neural physics framework that couples generative networks with
physics-informed neural simulation for fast, high-fidelity 3D USCT. By learning
a compact surrogate of ultrasonic wave propagation from only dozens of
cross-modality images, our method merges the accuracy of wave modeling with the
efficiency and stability of deep learning. This enables accurate quantitative
imaging of in vivo musculoskeletal tissues, producing spatial maps of acoustic
properties beyond reflection-mode images. On synthetic and in vivo data
(breast, arm, leg), we reconstruct 3D maps of tissue parameters in under ten
minutes, with sensitivity to biomechanical properties in muscle and bone and
resolution comparable to MRI. By overcoming computational bottlenecks in
strongly scattering regimes, this approach advances USCT toward routine
clinical assessment of musculoskeletal disease.

</details>


### [52] [Has GPT-5 Achieved Spatial Intelligence? An Empirical Study](https://arxiv.org/abs/2508.13142)
*Zhongang Cai,Yubo Wang,Qingping Sun,Ruisi Wang,Chenyang Gu,Wanqi Yin,Zhiqian Lin,Zhitao Yang,Chen Wei,Xuanke Shi,Kewang Deng,Xiaoyang Han,Zukai Chen,Jiaqi Li,Xiangyu Fan,Hanming Deng,Lewei Lu,Bo Li,Ziwei Liu,Quan Wang,Dahua Lin,Lei Yang*

Main category: cs.CV

TL;DR: GPT-5在空间智能方面表现出色，但与人类相比仍有差距，且在最难的问题上，专有模型不占优势。


<details>
  <summary>Details</summary>
Motivation: 为了评估当前领先的多模态模型（包括GPT-5）在实现通用人工智能所需的核心能力——空间理解和推理——方面的进展和局限性。

Method: 通过分析GPT-5等领先模型在八个关键基准上的表现，评估其在空间理解和推理方面的能力，并进行了跨越多种场景的定性评估。

Result: GPT-5在空间智能方面表现出色，但未能达到人类水平。专有模型在最难的空间智能问题上不具备明显优势。研究还发现了当前多模态模型在处理对人类而言直观但对模型而言却很困难的空间任务方面存在显著挑战。

Conclusion: 虽然GPT-5在空间智能方面表现出前所未有的优势，但与人类表现相比仍有差距。此外，研究还识别出多模态模型面临更具挑战性的空间智能问题，并且在最困难的问题上，专有模型并未展现出决定性优势。

Abstract: Multi-modal models have achieved remarkable progress in recent years.
Nevertheless, they continue to exhibit notable limitations in spatial
understanding and reasoning, which are fundamental capabilities to achieving
artificial general intelligence. With the recent release of GPT-5, allegedly
the most powerful AI model to date, it is timely to examine where the leading
models stand on the path toward spatial intelligence. First, we propose a
comprehensive taxonomy of spatial tasks that unifies existing benchmarks and
discuss the challenges in ensuring fair evaluation. We then evaluate
state-of-the-art proprietary and open-source models on eight key benchmarks, at
a cost exceeding one billion total tokens. Our empirical study reveals that (1)
GPT-5 demonstrates unprecedented strength in spatial intelligence, yet (2)
still falls short of human performance across a broad spectrum of tasks.
Moreover, we (3) identify the more challenging spatial intelligence problems
for multi-modal models, and (4) proprietary models do not exhibit a decisive
advantage when facing the most difficult problems. In addition, we conduct a
qualitative evaluation across a diverse set of scenarios that are intuitive for
humans yet fail even the most advanced multi-modal models.

</details>


### [53] [WXSOD: A Benchmark for Robust Salient Object Detection in Adverse Weather Conditions](https://arxiv.org/abs/2508.12250)
*Quan Chen,Xiong Yang,Rongfeng Lu,Qianyu Zhang,Yu Liu,Xiaofei Zhou,Bolun Zheng*

Main category: cs.CV

TL;DR: 该研究提出了WXSOD数据集和WFANet模型，以解决天气噪声对显着目标检测（SOD）性能的影响。WFANet在WXSOD数据集上的表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 尽管现有的大多数显着目标检测（SOD）方法在自然场景中表现良好，并且倾向于利用多模态信息来提高准确性，但很少有研究关注天气噪声对SOD性能的损害，这是由于缺乏带有像素级标注的数据集。

Method: 该研究提出了一种名为WFANet的模型，该模型采用全监督两分支架构。一个分支用于天气预测，挖掘与天气相关的深度特征；另一个分支用于显着性检测，融合来自主干网的语义特征和天气特征。此外，该研究还构建了一个名为WXSOD的新数据集，该数据集包含14,945张带有各种天气噪声的RGB图像及其像素级标注和天气标签，并包含合成和真实两个测试集以验证算法泛化能力。

Result: WFANet在WXSOD数据集上取得了优于17种现有SOD方法的性能。

Conclusion: 该研究提出了一个包含14,945张带有各种天气噪声的RGB图像及其对应的像素级标注和天气标签的新型数据集WXSOD，以及一个名为WFANet的高效基线模型。WFANet采用全监督两分支架构，其中天气预测分支挖掘与天气相关的深度特征，而显着性检测分支将主干提取的语义特征与天气特征融合以实现SOD。

Abstract: Salient object detection (SOD) in complex environments remains a challenging
research topic. Most existing methods perform well in natural scenes with
negligible noise, and tend to leverage multi-modal information (e.g., depth and
infrared) to enhance accuracy. However, few studies are concerned with the
damage of weather noise on SOD performance due to the lack of dataset with
pixel-wise annotations. To bridge this gap, this paper introduces a novel
Weather-eXtended Salient Object Detection (WXSOD) dataset. It consists of
14,945 RGB images with diverse weather noise, along with the corresponding
ground truth annotations and weather labels. To verify algorithm
generalization, WXSOD contains two test sets, i.e., a synthesized test set and
a real test set. The former is generated by adding weather noise to clean
images, while the latter contains real-world weather noise. Based on WXSOD, we
propose an efficient baseline, termed Weather-aware Feature Aggregation Network
(WFANet), which adopts a fully supervised two-branch architecture.
Specifically, the weather prediction branch mines weather-related deep
features, while the saliency detection branch fuses semantic features extracted
from the backbone with weather features for SOD. Comprehensive comparisons
against 17 SOD methods shows that our WFANet achieves superior performance on
WXSOD. The code and benchmark results will be made publicly available at
https://github.com/C-water/WXSOD

</details>


### [54] [Superpixel-informed Continuous Low-Rank Tensor Representation for Multi-Dimensional Data Recovery](https://arxiv.org/abs/2508.12261)
*Zhizhou Wang,Ruijing Zheng,Zhenyu Wu,Jianli Wang*

Main category: cs.CV

TL;DR: 提出了一种新的超像素感知连续低秩张量表示（SCTR）框架，通过超像素和不对称低秩张量分解克服了传统LRTR方法的局限性，并在多个数据集上显著提高了性能。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统低秩张量表示（LRTR）方法在处理现实世界中具有显著空间变化的非整体低秩数据以及仅限于离散网格数据方面的局限性，该研究旨在实现对超越传统基于网格约束的多维数据的连续和灵活建模。

Method: 提出了一种名为超像素感知连续低秩张量表示（SCTR）的框架。该框架使用超像素作为基本建模单元，并通过一种新颖的不对称低秩张量分解（ALTF）方法，利用共享神经网络及其特定头参数化超像素特定的因子矩阵，以同时捕捉全局模式和局部适应性。

Result: SCTR框架能够有效地捕捉全局模式和局部适应性，生成具有高度表达力和紧凑性的表示，实现了模型效率和适应性的平衡，并在多光谱图像、视频和彩色图像的多个基准数据集上实现了3-5 dB的PSNR提升。

Conclusion: SCTR框架在多光谱图像、视频和彩色图像的多个基准数据集上实现了超过现有LRTR方法的3-5 dB PSNR提升，证明了其在捕捉跨超像素共性和超像素内变化方面的有效性。

Abstract: Low-rank tensor representation (LRTR) has emerged as a powerful tool for
multi-dimensional data processing. However, classical LRTR-based methods face
two critical limitations: (1) they typically assume that the holistic data is
low-rank, this assumption is often violated in real-world scenarios with
significant spatial variations; and (2) they are constrained to discrete
meshgrid data, limiting their flexibility and applicability. To overcome these
limitations, we propose a Superpixel-informed Continuous low-rank Tensor
Representation (SCTR) framework, which enables continuous and flexible modeling
of multi-dimensional data beyond traditional grid-based constraints. Our
approach introduces two main innovations: First, motivated by the observation
that semantically coherent regions exhibit stronger low-rank characteristics
than holistic data, we employ superpixels as the basic modeling units. This
design not only encodes rich semantic information, but also enhances
adaptability to diverse forms of data streams. Second, we propose a novel
asymmetric low-rank tensor factorization (ALTF) where superpixel-specific
factor matrices are parameterized by a shared neural network with specialized
heads. By strategically separating global pattern learning from local
adaptation, this framework efficiently captures both cross-superpixel
commonalities and within-superpixel variations. This yields a representation
that is both highly expressive and compact, balancing model efficiency with
adaptability. Extensive experiments on several benchmark datasets demonstrate
that SCTR achieves 3-5 dB PSNR improvements over existing LRTR-based methods
across multispectral images, videos, and color images.

</details>


### [55] [Region-Level Context-Aware Multimodal Understanding](https://arxiv.org/abs/2508.12263)
*Hongliang Wei,Xianqi Zhang,Xingtao Wang,Xiaopeng Fan,Debin Zhao*

Main category: cs.CV

TL;DR: 该研究提出了RCVIT方法，以增强MLLMs的区域级上下文感知多模态理解（RCMU）能力，并发布了RCMU数据集和RC&P-Bench基准，使RC-Qwen2-VL模型在RCMU任务和多模态应用中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs主要关注通用视觉理解，忽略了整合对象相关的文本信息以实现更具上下文感知能力的多模态理解（RCMU）。

Method: 提出了一种名为RCVIT（Region-level Context-aware Visual Instruction Tuning）的方法，该方法将对象信息融入模型输入，并利用边界框坐标有效关联对象的视觉内容和文本信息。此外，还引入了RCMU数据集和RC&P-Bench基准，并提出了一种无参考评估指标。

Result: RC-Qwen2-VL模型在多个RCMU任务上取得了优异的性能，并在多模态RAG和个性化对话中取得了成功。

Conclusion: RC-Qwen2-VL模型在RCMU任务上表现出色，并在多模态RAG和个性化对话中展现了成功的应用。

Abstract: Despite significant progress, existing research on Multimodal Large Language
Models (MLLMs) mainly focuses on general visual understanding, overlooking the
ability to integrate textual context associated with objects for a more
context-aware multimodal understanding -- an ability we refer to as
Region-level Context-aware Multimodal Understanding (RCMU). To address this
limitation, we first formulate the RCMU task, which requires models to respond
to user instructions by integrating both image content and textual information
of regions or objects. To equip MLLMs with RCMU capabilities, we propose
Region-level Context-aware Visual Instruction Tuning (RCVIT), which
incorporates object information into the model input and enables the model to
utilize bounding box coordinates to effectively associate objects' visual
content with their textual information. To address the lack of datasets, we
introduce the RCMU dataset, a large-scale visual instruction tuning dataset
that covers multiple RCMU tasks. We also propose RC\&P-Bench, a comprehensive
benchmark that can evaluate the performance of MLLMs in RCMU and multimodal
personalized understanding tasks. Additionally, we propose a reference-free
evaluation metric to perform a comprehensive and fine-grained evaluation of the
region-level context-aware image descriptions. By performing RCVIT on Qwen2-VL
models with the RCMU dataset, we developed RC-Qwen2-VL models. Experimental
results indicate that RC-Qwen2-VL models not only achieve outstanding
performance on multiple RCMU tasks but also demonstrate successful applications
in multimodal RAG and personalized conversation. Our data, model and benchmark
are available at https://github.com/hongliang-wei/RC-MLLM

</details>


### [56] [SNNSIR: A Simple Spiking Neural Network for Stereo Image Restoration](https://arxiv.org/abs/2508.12271)
*Ronghua Xu,Jin Xie,Jing Nie,Jiale Cao,Yanwei Pang*

Main category: cs.CV

TL;DR: SNNSIR是一种用于立体图像恢复的全脉冲驱动神经网络，通过SRBB、SSCM和SSCA模块，在保持高性能的同时实现了低功耗和高计算效率。


<details>
  <summary>Details</summary>
Motivation: 为了实现低功耗和硬件友好的计算，并克服二元脉冲神经元的表达能力限制，以用于计算密集型任务，如立体图像恢复。

Method: 提出了一种名为SNNSIR的简单而有效的脉冲神经网络用于立体图像恢复。该模型采用完全脉冲驱动的架构，通过轻量级脉冲残差基本块（SRBB）、脉冲立体卷积调制（SSCM）模块和脉冲立体交叉注意力（SSCA）模块来增强信息流、引入简化非线性并通过跨视图调制和双向特征交互来提高立体对应性。

Result: SNNSIR模型在立体图像恢复任务（包括去除雨条、去除雨滴、弱光增强和超分辨率）上取得了有竞争力的性能，并显著降低了计算开销。

Conclusion: SNNSIR模型在多种立体图像恢复任务中实现了具有竞争力的恢复性能，同时显著降低了计算开销，展示了其在实时、低功耗立体视觉应用中的潜力。

Abstract: Spiking Neural Networks (SNNs), characterized by discrete binary activations,
offer high computational efficiency and low energy consumption, making them
well-suited for computation-intensive tasks such as stereo image restoration.
In this work, we propose SNNSIR, a simple yet effective Spiking Neural Network
for Stereo Image Restoration, specifically designed under the spike-driven
paradigm where neurons transmit information through sparse, event-based binary
spikes. In contrast to existing hybrid SNN-ANN models that still rely on
operations such as floating-point matrix division or exponentiation, which are
incompatible with the binary and event-driven nature of SNNs, our proposed
SNNSIR adopts a fully spike-driven architecture to achieve low-power and
hardware-friendly computation. To address the expressiveness limitations of
binary spiking neurons, we first introduce a lightweight Spike Residual Basic
Block (SRBB) to enhance information flow via spike-compatible residual
learning. Building on this, the Spike Stereo Convolutional Modulation (SSCM)
module introduces simplified nonlinearity through element-wise multiplication
and highlights noise-sensitive regions via cross-view-aware modulation.
Complementing this, the Spike Stereo Cross-Attention (SSCA) module further
improves stereo correspondence by enabling efficient bidirectional feature
interaction across views within a spike-compatible framework. Extensive
experiments on diverse stereo image restoration tasks, including rain streak
removal, raindrop removal, low-light enhancement, and super-resolution
demonstrate that our model achieves competitive restoration performance while
significantly reducing computational overhead. These results highlight the
potential for real-time, low-power stereo vision applications. The code will be
available after the article is accepted.

</details>


### [57] [CLAIR: CLIP-Aided Weakly Supervised Zero-Shot Cross-Domain Image Retrieval](https://arxiv.org/abs/2508.12290)
*Chor Boon Tan,Conghui Hu,Gim Hee Lee*

Main category: cs.CV

TL;DR: CLAIR improves weakly supervised Zero-Shot Cross-Domain Image Retrieval by refining noisy pseudo-labels, using contrastive losses for better feature representation and domain alignment, and incorporating learnable prompts for enhanced generalization.


<details>
  <summary>Details</summary>
Motivation: The irrelevance of unsupervised Zero-Shot Cross-Domain Image Retrieval (UZS-CDIR) due to easily generated pseudo-labels by foundation models. The paper shifts focus to weakly supervised ZS-CDIR (WSZS-CDIR) using potentially noisy pseudo-labels from models like CLIP.

Method: CLAIR refines noisy pseudo-labels using feature similarity and confidence scores. It employs inter-instance, inter-cluster, and inter-domain contrastive losses to create a class-aware latent space and reduce domain discrepancies. A closed-form cross-domain mapping function using CLIP text embeddings aligns image features, and learnable prompts further improve generalization to novel categories.

Result: Extensive experiments on TUBerlin, Sketchy, Quickdraw, and DomainNet zero-shot datasets show CLAIR achieves superior performance compared to existing state-of-the-art methods.

Conclusion: CLAIR method significantly outperforms existing state-of-the-art methods in weakly supervised Zero-Shot Cross-Domain Image Retrieval, especially with noisy pseudo-labels from foundation models. It also demonstrates enhanced zero-shot generalization to novel categories.

Abstract: The recent growth of large foundation models that can easily generate
pseudo-labels for huge quantity of unlabeled data makes unsupervised Zero-Shot
Cross-Domain Image Retrieval (UZS-CDIR) less relevant. In this paper, we
therefore turn our attention to weakly supervised ZS-CDIR (WSZS-CDIR) with
noisy pseudo labels generated by large foundation models such as CLIP. To this
end, we propose CLAIR to refine the noisy pseudo-labels with a confidence score
from the similarity between the CLIP text and image features. Furthermore, we
design inter-instance and inter-cluster contrastive losses to encode images
into a class-aware latent space, and an inter-domain contrastive loss to
alleviate domain discrepancies. We also learn a novel cross-domain mapping
function in closed-form, using only CLIP text embeddings to project image
features from one domain to another, thereby further aligning the image
features for retrieval. Finally, we enhance the zero-shot generalization
ability of our CLAIR to handle novel categories by introducing an extra set of
learnable prompts. Extensive experiments are carried out using TUBerlin,
Sketchy, Quickdraw, and DomainNet zero-shot datasets, where our CLAIR
consistently shows superior performance compared to existing state-of-the-art
methods.

</details>


### [58] [Improving Densification in 3D Gaussian Splatting for High-Fidelity Rendering](https://arxiv.org/abs/2508.12313)
*Xiaobin Deng,Changyu Diao,Min Li,Ruohan Yu,Duanqing Xu*

Main category: cs.CV

TL;DR: 改进3DGS的加密策略，以提高重建质量。


<details>
  <summary>Details</summary>
Motivation: 虽然3DGS在实时渲染方面取得了显著的性能，但其加密策略常常导致次优的重建质量。

Method: 提出了一种边缘感知评分方法来选择用于分割的高斯点，并引入了一种长轴分割策略来减少几何畸变。此外，还设计了一套技术来解决过拟合问题，包括恢复感知修剪、多步更新和增长控制。

Result: 通过上述方法，在不引入额外训练或推理开销的情况下，提高了渲染保真度，并使用更少的高斯点实现了最先进的性能。

Conclusion: 该方法通过改进3DGS的加密策略，提高了渲染保真度，实现了更少的优化，并达到了最先进的性能。

Abstract: Although 3D Gaussian Splatting (3DGS) has achieved impressive performance in
real-time rendering, its densification strategy often results in suboptimal
reconstruction quality. In this work, we present a comprehensive improvement to
the densification pipeline of 3DGS from three perspectives: when to densify,
how to densify, and how to mitigate overfitting. Specifically, we propose an
Edge-Aware Score to effectively select candidate Gaussians for splitting. We
further introduce a Long-Axis Split strategy that reduces geometric distortions
introduced by clone and split operations. To address overfitting, we design a
set of techniques, including Recovery-Aware Pruning, Multi-step Update, and
Growth Control. Our method enhances rendering fidelity without introducing
additional training or inference overhead, achieving state-of-the-art
performance with fewer Gaussians.

</details>


### [59] [Neural Cellular Automata for Weakly Supervised Segmentation of White Blood Cells](https://arxiv.org/abs/2508.12322)
*Michael Deutges,Chen Yang,Raheleh Salehi,Nassir Navab,Carsten Marr,Ario Sadafi*

Main category: cs.CV

TL;DR: 提出了一种利用神经元细胞自动机（NCA-WSS）的弱监督分割新方法，无需分割标签即可提取分割掩码，并在三个数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决医学诊断中白血球检测和分割需要大量耗时且成本高昂的标注数据的问题。

Method: 提出了一种新颖的弱监督分割方法（NCA-WSS），利用 NCA 在分类过程中生成的特征图来提取分割掩码，无需使用分割标签进行重新训练。

Result: 在三个白血球显微镜数据集上进行了评估，结果证明 NCA-WSS 的性能显著优于现有的弱监督方法。

Conclusion: 本文的工作展示了神经元细胞自动机（NCA）在弱监督框架下进行分类和分割的潜力，为医学图像分析提供了一个可扩展且高效的解决方案。

Abstract: The detection and segmentation of white blood cells in blood smear images is
a key step in medical diagnostics, supporting various downstream tasks such as
automated blood cell counting, morphological analysis, cell classification, and
disease diagnosis and monitoring. Training robust and accurate models requires
large amounts of labeled data, which is both time-consuming and expensive to
acquire. In this work, we propose a novel approach for weakly supervised
segmentation using neural cellular automata (NCA-WSS). By leveraging the
feature maps generated by NCA during classification, we can extract
segmentation masks without the need for retraining with segmentation labels. We
evaluate our method on three white blood cell microscopy datasets and
demonstrate that NCA-WSS significantly outperforms existing weakly supervised
approaches. Our work illustrates the potential of NCA for both classification
and segmentation in a weakly supervised framework, providing a scalable and
efficient solution for medical image analysis.

</details>


### [60] [Attention Pooling Enhances NCA-based Classification of Microscopy Images](https://arxiv.org/abs/2508.12324)
*Chen Yang,Michael Deutges,Jingsong Liu,Han Li,Nassir Navab,Carsten Marr,Ario Sadafi*

Main category: cs.CV

TL;DR: Attention pooling enhances Neural Cellular Automata (NCA) for better and more explainable image classification, outperforming other lightweight models.


<details>
  <summary>Details</summary>
Motivation: Addressing the performance gap between NCA and larger architectures for microscopy image analysis by enhancing NCA's feature extraction capabilities.

Method: Integrating attention pooling with Neural Cellular Automata (NCA) to enhance feature extraction and classification accuracy.

Result: The proposed method significantly outperforms existing NCA methods on eight diverse microscopy image datasets and shows improved performance compared to traditional lightweight CNN and Vision Transformer architectures, with a lower parameter count.

Conclusion: NCA-based models with attention pooling offer a competitive and explainable alternative for image classification, outperforming existing NCA methods and traditional lightweight architectures while maintaining parameter efficiency.

Abstract: Neural Cellular Automata (NCA) offer a robust and interpretable approach to
image classification, making them a promising choice for microscopy image
analysis. However, a performance gap remains between NCA and larger, more
complex architectures. We address this challenge by integrating attention
pooling with NCA to enhance feature extraction and improve classification
accuracy. The attention pooling mechanism refines the focus on the most
informative regions, leading to more accurate predictions. We evaluate our
method on eight diverse microscopy image datasets and demonstrate that our
approach significantly outperforms existing NCA methods while remaining
parameter-efficient and explainable. Furthermore, we compare our method with
traditional lightweight convolutional neural network and vision transformer
architectures, showing improved performance while maintaining a significantly
lower parameter count. Our results highlight the potential of NCA-based models
an alternative for explainable image classification.

</details>


### [61] [DoppDrive: Doppler-Driven Temporal Aggregation for Improved Radar Object Detection](https://arxiv.org/abs/2508.12330)
*Yuval Haitman,Oded Bialer*

Main category: cs.CV

TL;DR: DoppDrive通过一种新的多普勒驱动的时间聚合方法，解决了雷达点云稀疏的问题，在不增加散射的情况下提高了点云密度，从而提升了自动驾驶中的物体检测性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决自动驾驶中雷达点云稀疏，尤其是在远距离情况下，导致检测不准确的问题。现有的通过增加点密度的时间聚合方法会引入运动物体散射，从而降低检测性能。

Method: DoppDrive是一种新颖的、由多普勒驱动的时间聚合方法，它通过在聚合前根据点的多普勒分量进行径向移位来消除径向散点，并为每个点分配独特的多普勒和角度来最小化切向散点，从而在最小化散点的同时提高雷达点云密度。

Result: DoppDrive通过增强雷达点云密度并最小化散射，显著提高了物体检测性能，并且可以作为检测前的点云密度增强步骤应用于任何检测器。

Conclusion: DoppDrive能够显著提升包括LPR、PointPillars和CenterPoint在内的多种检测器在不同数据集上的物体检测性能。

Abstract: Radar-based object detection is essential for autonomous driving due to
radar's long detection range. However, the sparsity of radar point clouds,
especially at long range, poses challenges for accurate detection. Existing
methods increase point density through temporal aggregation with ego-motion
compensation, but this approach introduces scatter from dynamic objects,
degrading detection performance. We propose DoppDrive, a novel Doppler-Driven
temporal aggregation method that enhances radar point cloud density while
minimizing scatter. Points from previous frames are shifted radially according
to their dynamic Doppler component to eliminate radial scatter, with each point
assigned a unique aggregation duration based on its Doppler and angle to
minimize tangential scatter. DoppDrive is a point cloud density enhancement
step applied before detection, compatible with any detector, and we demonstrate
that it significantly improves object detection performance across various
detectors and datasets.

</details>


### [62] [Geometry-Aware Video Inpainting for Joint Headset Occlusion Removal and Face Reconstruction in Social XR](https://arxiv.org/abs/2508.12336)
*Fatemeh Ghorbani Lohesara,Karen Eguiazarian,Sebastian Knorr*

Main category: cs.CV

TL;DR: 该研究提出了一种新框架，用于从视频中移除头戴式显示器（HMD）并重建3D人脸。该框架通过GANs进行面部区域修复，并利用SynergyNet进行3D人脸重建，能有效处理HMD遮挡问题，并保持面部身份和真实感。实验结果表明该方法效果显著，且在稀疏人脸标志下也具有一定的稳健性。


<details>
  <summary>Details</summary>
Motivation: 为了解决头戴式显示器（HMDs）遮挡用户面部上方，导致外部视频录制复杂化，以及影响需要面部表情和视线细节的社交XR应用（如电话会议）的沉浸感问题。

Method: 本研究引入了一个几何感知的、基于学习的框架，通过从单视角RGB帧中恢复缺失的面部区域和3D面部几何，实现HMD移除和3D面部几何重建。该框架整合了一个基于GANs的视频修复网络，并以密集面部标志点和无遮挡参考帧作为指导，以在保留身份信息的同时恢复缺失的面部区域。随后，一个基于SynergyNet的模块从修复后的帧中回归3D变形模型（3DMM）参数，从而实现精确的3D人脸重建。整个流程整合了密集面部标志点优化，以提高修复质量和恢复几何的保真度。

Result: 实验结果表明，该框架能够成功移除RGB面部视频中的HMD，同时保持面部身份和真实感，并生成照片级逼真的3D面部几何输出。此外，实验还表明该框架在不同标志密度下均表现稳健，仅在稀疏标志时质量有轻微下降。

Conclusion: 该框架成功移除了HMD对RGB面部视频的遮挡，同时保持了面部身份和真实感，并生成了逼真的3D面部几何输出。此外，在不同密度的人脸标志下，该框架依然稳健，仅在稀疏标志配置下出现轻微的质量下降。

Abstract: Head-mounted displays (HMDs) are essential for experiencing extended reality
(XR) environments and observing virtual content. However, they obscure the
upper part of the user's face, complicating external video recording and
significantly impacting social XR applications such as teleconferencing, where
facial expressions and eye gaze details are crucial for creating an immersive
experience. This study introduces a geometry-aware learning-based framework to
jointly remove HMD occlusions and reconstruct complete 3D facial geometry from
RGB frames captured from a single viewpoint. The method integrates a GAN-based
video inpainting network, guided by dense facial landmarks and a single
occlusion-free reference frame, to restore missing facial regions while
preserving identity. Subsequently, a SynergyNet-based module regresses 3D
Morphable Model (3DMM) parameters from the inpainted frames, enabling accurate
3D face reconstruction. Dense landmark optimization is incorporated throughout
the pipeline to improve both the inpainting quality and the fidelity of the
recovered geometry. Experimental results demonstrate that the proposed
framework can successfully remove HMDs from RGB facial videos while maintaining
facial identity and realism, producing photorealistic 3D face geometry outputs.
Ablation studies further show that the framework remains robust across
different landmark densities, with only minor quality degradation under sparse
landmark configurations.

</details>


### [63] [Semantic Discrepancy-aware Detector for Image Forgery Identification](https://arxiv.org/abs/2508.12341)
*Ziye Wang,Minghang Yu,Chunyan Xu,Zhen Cui*

Main category: cs.CV

TL;DR: 为了提高图像伪造检测性能，研究提出了一种名为SDD的新方法，通过重构学习对齐语义和伪造空间，并有效捕获概念层面的伪造差异。


<details>
  <summary>Details</summary>
Motivation: 为了解决预训练模型学习到的语义概念与伪造之间的空间不匹配问题，该研究提出了一种新的检测方法。

Method: 提出了一种新颖的语义差异感知检测器（SDD），该检测器利用重构学习在细粒度的视觉层面来对齐伪造和语义概念空间。具体设计了语义令牌采样模块来缓解由与伪造痕迹和语义概念都不相关的特征引起的空间偏移。构建了基于视觉重构范式的概念级伪造差异学习模块，以加强视觉语义概念和伪造痕迹之间的交互，并在概念的指导下有效捕获差异。最后，低级伪造特征增强器集成了学习到的概念级伪造差异，以最小化冗余的伪造信息。

Result: SDD在两个标准图像伪造数据集上取得了优于现有方法的Superior结果。

Conclusion: 实验结果表明，我们提出的SDD在两个标准的图像伪造数据集上都取得了优于现有方法的性能。

Abstract: With the rapid advancement of image generation techniques, robust forgery
detection has become increasingly imperative to ensure the trustworthiness of
digital media. Recent research indicates that the learned semantic concepts of
pre-trained models are critical for identifying fake images. However, the
misalignment between the forgery and semantic concept spaces hinders the
model's forgery detection performance. To address this problem, we propose a
novel Semantic Discrepancy-aware Detector (SDD) that leverages reconstruction
learning to align the two spaces at a fine-grained visual level. By exploiting
the conceptual knowledge embedded in the pre-trained vision language model, we
specifically design a semantic token sampling module to mitigate the space
shifts caused by features irrelevant to both forgery traces and semantic
concepts. A concept-level forgery discrepancy learning module, built upon a
visual reconstruction paradigm, is proposed to strengthen the interaction
between visual semantic concepts and forgery traces, effectively capturing
discrepancies under the concepts' guidance. Finally, the low-level forgery
feature enhancemer integrates the learned concept level forgery discrepancies
to minimize redundant forgery information. Experiments conducted on two
standard image forgery datasets demonstrate the efficacy of the proposed SDD,
which achieves superior results compared to existing methods. The code is
available at https://github.com/wzy1111111/SSD.

</details>


### [64] [AquaFeat: A Features-Based Image Enhancement Model for Underwater Object Detection](https://arxiv.org/abs/2508.12343)
*Emanuel C. Silva,Tatiana T. Schein,Stephanie L. Brião,Guilherme L. M. Costa,Felipe G. Oliveira,Gustavo P. Almeida,Eduardo L. Silva,Sam S. Devincenzi,Karina S. Machado,Paulo L. J. Drews-Jr*

Main category: cs.CV

TL;DR: AquaFeat是一个即插即用的模块，可以提高水下目标检测的性能。


<details>
  <summary>Details</summary>
Motivation: 水下环境严重的图像退化会影响目标检测模型，而传统的图像增强方法通常没有针对此类下游任务进行优化。

Method: AquaFeat是一个即插即用的模块，通过一个多尺度特征增强网络进行特征增强，该网络与检测器的损失函数进行端到端训练。

Result: AquaFeat在具有挑战性的水下数据集上与YOLOv8m集成时，实现了最先进的精度（0.877）和召回率（0.624），以及具有竞争力的mAP分数（mAP@0.5为0.677，mAP@[0.5:0.95]为0.421），处理速度为46.5 FPS。

Conclusion: AquaFeat 通过集成一个与检测器损失函数端到端训练的多尺度特征增强网络，为水下目标检测任务提供了最先进的精度和召回率，同时保持了实际的处理速度，是海洋生态监测和基础设施检查等实际应用的一个有效且计算效率高的解决方案。

Abstract: The severe image degradation in underwater environments impairs object
detection models, as traditional image enhancement methods are often not
optimized for such downstream tasks. To address this, we propose AquaFeat, a
novel, plug-and-play module that performs task-driven feature enhancement. Our
approach integrates a multi-scale feature enhancement network trained
end-to-end with the detector's loss function, ensuring the enhancement process
is explicitly guided to refine features most relevant to the detection task.
When integrated with YOLOv8m on challenging underwater datasets, AquaFeat
achieves state-of-the-art Precision (0.877) and Recall (0.624), along with
competitive mAP scores (mAP@0.5 of 0.677 and mAP@[0.5:0.95] of 0.421). By
delivering these accuracy gains while maintaining a practical processing speed
of 46.5 FPS, our model provides an effective and computationally efficient
solution for real-world applications, such as marine ecosystem monitoring and
infrastructure inspection.

</details>


### [65] [MBMamba: When Memory Buffer Meets Mamba for Structure-Aware Image Deblurring](https://arxiv.org/abs/2508.12346)
*Hu Gao,Depeng Dang*

Main category: cs.CV

TL;DR: MBMamba improves Mamba for image deblurring by adding a memory buffer and a structure-preserving loss, outperforming other methods without increasing complexity.


<details>
  <summary>Details</summary>
Motivation: The Mamba architecture's flatten-and-scan strategy in image deblurring can lead to local pixel forgetting and channel redundancy, limiting its ability to aggregate 2D spatial information. Existing mitigation methods increase computational complexity and hinder real-time performance.

Method: The paper proposes a structure-aware image deblurring network by designing a memory buffer mechanism to preserve historical information for later fusion and introducing an Ising-inspired regularization loss to maintain image structure and coherence, without changing the original Mamba architecture.

Result: MBMamba, utilizing a memory buffer mechanism and an Ising-inspired regularization loss, effectively addresses the limitations of the Mamba architecture for image deblurring.

Conclusion: MBMamba outperforms state-of-the-art approaches on widely used benchmarks.

Abstract: The Mamba architecture has emerged as a promising alternative to CNNs and
Transformers for image deblurring. However, its flatten-and-scan strategy often
results in local pixel forgetting and channel redundancy, limiting its ability
to effectively aggregate 2D spatial information. Although existing methods
mitigate this by modifying the scan strategy or incorporating local feature
modules, it increase computational complexity and hinder real-time performance.
In this paper, we propose a structure-aware image deblurring network without
changing the original Mamba architecture. Specifically, we design a memory
buffer mechanism to preserve historical information for later fusion, enabling
reliable modeling of relevance between adjacent features. Additionally, we
introduce an Ising-inspired regularization loss that simulates the energy
minimization of the physical system's "mutual attraction" between pixels,
helping to maintain image structure and coherence. Building on this, we develop
MBMamba. Experimental results show that our method outperforms state-of-the-art
approaches on widely used benchmarks.

</details>


### [66] [EgoLoc: A Generalizable Solution for Temporal Interaction Localization in Egocentric Videos](https://arxiv.org/abs/2508.12349)
*Junyi Ma,Erhang Zhang,Yin-Dong Zheng,Yuchen Xie,Yixuan Zhou,Hesheng Wang*

Main category: cs.CV

TL;DR: EgoLoc 是一种零样本方法，用于在以自我为中心的视频中识别手部与物体接触和分离的时间点，无需物体掩码或特定动作标签，并在各种应用中表现出有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的研究主要集中在交互行为范式（“如何交互”），而忽略了捕捉手部和目标物体之间接触和分离的关键时刻（“何时交互”）这一更具挑战性且细粒度的问题。这个问题对于混合现实中的沉浸式交互体验和机器人运动规划至关重要。

Method: EgoLoc 提出了一种名为 EgoLoc 的零样本方法，通过引导采样来生成高质量的视觉提示，并利用视觉-语言模型来识别接触/分离属性、本地化具体时间戳以及提供闭环反馈进行进一步优化。

Result: EgoLoc 在公共数据集和新基准测试上的综合实验表明，该方法在以自我为中心的视频中实现了合理时序交互定位，并且有效促进了以自我为中心的视觉和机器人操作任务中的多种下游应用。

Conclusion: EgoLoc 是一种新颖的零样本方法，用于在以自我为中心的视频中本地化手部-物体接触和分离的时间戳。该方法消除了对物体掩码和动词-名词分类的需求，实现了可泛化的零样本实现。实验证明 EgoLoc 在以自我为中心的视频中实现了合理的时序交互定位，并能有效促进下游应用。

Abstract: Analyzing hand-object interaction in egocentric vision facilitates VR/AR
applications and human-robot policy transfer. Existing research has mostly
focused on modeling the behavior paradigm of interactive actions (i.e., ``how
to interact''). However, the more challenging and fine-grained problem of
capturing the critical moments of contact and separation between the hand and
the target object (i.e., ``when to interact'') is still underexplored, which is
crucial for immersive interactive experiences in mixed reality and robotic
motion planning. Therefore, we formulate this problem as temporal interaction
localization (TIL). Some recent works extract semantic masks as TIL references,
but suffer from inaccurate object grounding and cluttered scenarios. Although
current temporal action localization (TAL) methods perform well in detecting
verb-noun action segments, they rely on category annotations during training
and exhibit limited precision in localizing hand-object contact/separation
moments. To address these issues, we propose a novel zero-shot approach dubbed
EgoLoc to localize hand-object contact and separation timestamps in egocentric
videos. EgoLoc introduces hand-dynamics-guided sampling to generate
high-quality visual prompts. It exploits the vision-language model to identify
contact/separation attributes, localize specific timestamps, and provide
closed-loop feedback for further refinement. EgoLoc eliminates the need for
object masks and verb-noun taxonomies, leading to generalizable zero-shot
implementation. Comprehensive experiments on the public dataset and our novel
benchmarks demonstrate that EgoLoc achieves plausible TIL for egocentric
videos. It is also validated to effectively facilitate multiple downstream
applications in egocentric vision and robotic manipulation tasks. Code and
relevant data will be released at https://github.com/IRMVLab/EgoLoc.

</details>


### [67] [Synthetic Data is Sufficient for Zero-Shot Visual Generalization from Offline Data](https://arxiv.org/abs/2508.12356)
*Ahmet H. Güzel,Ilija Bogunovic,Jack Parker-Holder*

Main category: cs.CV

TL;DR: 离线RL在视觉数据上泛化能力差。本文提出了一种通过数据增强和扩散模型在潜在空间生成合成数据的方法，提高了泛化能力，且不需修改现有算法。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习（RL）虽然允许使用预先收集的数据集进行训练，但由于对多样化状态的暴露有限，训练出的策略往往难以泛化。特别是视觉数据的复杂性，如噪声、干扰和虚假相关性，会误导策略，增加过拟合的风险。

Method: 提出了一种两步方法：首先增强原始离线数据以提高零样本泛化能力，然后使用扩散模型在潜在空间中生成额外的合成数据。

Result: 在连续动作空间（Visual D4RL）和离散动作空间（Procgen）上均进行了测试，证明了该方法显著提高了泛化能力。

Conclusion: 该方法通过生成额外的合成训练数据，显著提高了offline RL在视觉数据上的泛化能力，并且不需对现有的model-free offline RL方法进行任何算法上的修改。该方法增加了训练数据的多样性，同时显著减小了测试时间的泛化差距，并保持了计算效率。

Abstract: Offline reinforcement learning (RL) offers a promising framework for training
agents using pre-collected datasets without the need for further environment
interaction. However, policies trained on offline data often struggle to
generalise due to limited exposure to diverse states. The complexity of visual
data introduces additional challenges such as noise, distractions, and spurious
correlations, which can misguide the policy and increase the risk of
overfitting if the training data is not sufficiently diverse. Indeed, this
makes it challenging to leverage vision-based offline data in training robust
agents that can generalize to unseen environments. To solve this problem, we
propose a simple approach generating additional synthetic training data. We
propose a two-step process, first augmenting the originally collected offline
data to improve zero-shot generalization by introducing diversity, then using a
diffusion model to generate additional data in latent space. We test our method
across both continuous action spaces (Visual D4RL) and discrete action spaces
(Procgen), demonstrating that it significantly improves generalization without
requiring any algorithmic changes to existing model-free offline RL methods. We
show that our method not only increases the diversity of the training data but
also significantly reduces the generalization gap at test time while
maintaining computational efficiency. We believe this approach could fuel
additional progress in generating synthetic data to train more general agents
in the future.

</details>


### [68] [IPGPhormer: Interpretable Pathology Graph-Transformer for Survival Analysis](https://arxiv.org/abs/2508.12381)
*Guo Tang,Songhan Jiang,Jinpeng Lu,Linghan Cai,Yongbing Zhang*

Main category: cs.CV

TL;DR: IPGPhormer是一种新的可解释的病理图-Transformer框架，用于癌症预后评估，它能更好地平衡空间关系和局部依赖性，并提供可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的生存分析方法在平衡长程空间关系和局部上下文依赖性的建模方面存在不足，并且通常缺乏固有的可解释性，这限制了其临床应用。提出IPGPhormer是为了解决这些挑战。

Method: 提出了一种名为IPGPhormer的新颖框架，该框架可以捕捉肿瘤微环境的特征并对其在组织中的空间依赖性进行建模。

Result: 在四个公开的基准数据集上进行的全面评估表明，IPGPhormer在预测准确性和可解释性方面均优于现有最先进的方法。

Conclusion: IPGPhormer在预测准确性和可解释性方面均优于现有最先进的方法，为病理学中更可靠、可解释的决策支持系统铺平了道路。

Abstract: Pathological images play an essential role in cancer prognosis, while
survival analysis, which integrates computational techniques, can predict
critical clinical events such as patient mortality or disease recurrence from
whole-slide images (WSIs). Recent advancements in multiple instance learning
have significantly improved the efficiency of survival analysis. However,
existing methods often struggle to balance the modeling of long-range spatial
relationships with local contextual dependencies and typically lack inherent
interpretability, limiting their clinical utility. To address these challenges,
we propose the Interpretable Pathology Graph-Transformer (IPGPhormer), a novel
framework that captures the characteristics of the tumor microenvironment and
models their spatial dependencies across the tissue. IPGPhormer uniquely
provides interpretability at both tissue and cellular levels without requiring
post-hoc manual annotations, enabling detailed analyses of individual WSIs and
cross-cohort assessments. Comprehensive evaluations on four public benchmark
datasets demonstrate that IPGPhormer outperforms state-of-the-art methods in
both predictive accuracy and interpretability. In summary, our method,
IPGPhormer, offers a promising tool for cancer prognosis assessment, paving the
way for more reliable and interpretable decision-support systems in pathology.
The code is publicly available at
https://anonymous.4open.science/r/IPGPhormer-6EEB.

</details>


### [69] [ViT-EnsembleAttack: Augmenting Ensemble Models for Stronger Adversarial Transferability in Vision Transformers](https://arxiv.org/abs/2508.12384)
*Hanwen Cao,Haobo Lu,Xiaosen Wang,Kun He*

Main category: cs.CV

TL;DR: 提出 ViT-EnsembleAttack，通过对抗性数据增强 ViT 模型来提升集成攻击的迁移性，并引入新模块进一步优化性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中在改进集成权重或路径优化，而忽略了利用集成模型本身来增强对抗迁移性。此外，针对 ViT 的集成模型研究较少，因此提出 ViT-EnsembleAttack 来填补这一空白。

Method: 提出了一种名为 ViT-EnsembleAttack 的新方法，该方法基于模型对抗增强的思想，通过多头丢弃、注意力分数缩放和 MLP 特征混合三种策略为每个代理 ViT 生成增强模型，并使用贝叶斯优化优化参数。此外，还引入了自动重加权和步长增大模块来提升迁移性。

Result: 实验证明，ViT-EnsembleAttack 显著提高了对抗迁移性，并且在性能上优于现有方法。

Conclusion: ViT-EnsembleAttack 显著提高了基于集成模型的针对 ViT 的对抗迁移性，并且优于现有方法。

Abstract: Ensemble-based attacks have been proven to be effective in enhancing
adversarial transferability by aggregating the outputs of models with various
architectures. However, existing research primarily focuses on refining
ensemble weights or optimizing the ensemble path, overlooking the exploration
of ensemble models to enhance the transferability of adversarial attacks. To
address this gap, we propose applying adversarial augmentation to the surrogate
models, aiming to boost overall generalization of ensemble models and reduce
the risk of adversarial overfitting. Meanwhile, observing that ensemble Vision
Transformers (ViTs) gain less attention, we propose ViT-EnsembleAttack based on
the idea of model adversarial augmentation, the first ensemble-based attack
method tailored for ViTs to the best of our knowledge. Our approach generates
augmented models for each surrogate ViT using three strategies: Multi-head
dropping, Attention score scaling, and MLP feature mixing, with the associated
parameters optimized by Bayesian optimization. These adversarially augmented
models are ensembled to generate adversarial examples. Furthermore, we
introduce Automatic Reweighting and Step Size Enlargement modules to boost
transferability. Extensive experiments demonstrate that ViT-EnsembleAttack
significantly enhances the adversarial transferability of ensemble-based
attacks on ViTs, outperforming existing methods by a substantial margin. Code
is available at https://github.com/Trustworthy-AI-Group/TransferAttack.

</details>


### [70] [DeCoT: Decomposing Complex Instructions for Enhanced Text-to-Image Generation with Large Language Models](https://arxiv.org/abs/2508.12396)
*Xiaochuan Lin,Xiangyong Chen,Xuan Li,Yichen Su*

Main category: cs.CV

TL;DR: DeCoT 框架利用 LLM 分解和重构长文本指令，显著提升了 T2I 模型在复杂场景下的图像生成能力。


<details>
  <summary>Details</summary>
Motivation: 当前 T2I 模型在理解和生成长文本指令方面存在不足，尤其是在精确渲染细节、空间关系和特定约束方面，这在 LongBench-T2I 等基准测试中有所体现。

Method: DeCoT 框架采用两阶段方法：1. 利用 LLM 对复杂指令进行分解和语义增强，将其拆分为结构化的语义单元；2. 通过多阶段提示整合，将这些语义单元转化为适合 T2I 模型的一系列提示，以实现适应性生成。

Result: 在 LongBench-T2I 数据集上的实验表明，DeCoT 能够显著提高 T2I 模型的性能，特别是在“文本”和“构图”等挑战性维度上。与 Infinity-8B 基线相比，集成了 DeCoT 的 Infinity-8B 平均得分从 3.44 提高到 3.52。消融研究和人类评估也证实了 DeCoT 各组成部分的有效性以及其在提高感知质量和指令保真度方面的优势。

Conclusion: DeCoT 框架通过分解复杂文本指令并进行多阶段提示整合，有效提升了现有 T2I 模型在处理长文本、空间关系和特定约束方面的能力，显著提高了图像生成的准确性和忠实度。

Abstract: Despite remarkable advancements, current Text-to-Image (T2I) models struggle
with complex, long-form textual instructions, frequently failing to accurately
render intricate details, spatial relationships, or specific constraints. This
limitation is highlighted by benchmarks such as LongBench-T2I, which reveal
deficiencies in handling composition, specific text, and fine textures. To
address this, we propose DeCoT (Decomposition-CoT), a novel framework that
leverages Large Language Models (LLMs) to significantly enhance T2I models'
understanding and execution of complex instructions. DeCoT operates in two core
stages: first, Complex Instruction Decomposition and Semantic Enhancement,
where an LLM breaks down raw instructions into structured, actionable semantic
units and clarifies ambiguities; second, Multi-Stage Prompt Integration and
Adaptive Generation, which transforms these units into a hierarchical or
optimized single prompt tailored for existing T2I models. Extensive experiments
on the LongBench-T2I dataset demonstrate that DeCoT consistently and
substantially improves the performance of leading T2I models across all
evaluated dimensions, particularly in challenging aspects like "Text" and
"Composition". Quantitative results, validated by multiple MLLM evaluators
(Gemini-2.0-Flash and InternVL3-78B), show that DeCoT, when integrated with
Infinity-8B, achieves an average score of 3.52, outperforming the baseline
Infinity-8B (3.44). Ablation studies confirm the critical contribution of each
DeCoT component and the importance of sophisticated LLM prompting. Furthermore,
human evaluations corroborate these findings, indicating superior perceptual
quality and instruction fidelity. DeCoT effectively bridges the gap between
high-level user intent and T2I model requirements, leading to more faithful and
accurate image generation.

</details>


### [71] [Federated Cross-Modal Style-Aware Prompt Generation](https://arxiv.org/abs/2508.12399)
*Suraj Prasad,Navyansh Mahla,Sunny Gupta,Amit Sethi*

Main category: cs.CV

TL;DR: FedCSAP是一种联邦学习框架，通过结合多尺度视觉特征和客户端风格信息，生成更优的提示，提升模型在隐私保护下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 为了弥补传统方法仅依赖最终层特征而忽略了分散式客户端数据中丰富的多尺度视觉线索和领域特定风格变体的不足，FedCSAP被提出。

Method: FedCSAP框架结合了CLIP视觉编码器的低、中、高层特征以及源自批次统计信息的客户端特定风格指标，生成强大、上下文感知的提示令牌。

Result: FedCSAP生成的提示令牌既独特又不冗余，能够提升在已见和未见类别上的泛化能力。

Conclusion: FedCSAP在准确性和整体泛化性方面优于现有的联邦提示学习方法，并能在联邦学习范式中确保数据隐私，有效处理非独立同分布的类别分布和多样化的领域特定风格。

Abstract: Prompt learning has propelled vision-language models like CLIP to excel in
diverse tasks, making them ideal for federated learning due to computational
efficiency. However, conventional approaches that rely solely on final-layer
features miss out on rich multi-scale visual cues and domain-specific style
variations in decentralized client data. To bridge this gap, we introduce
FedCSAP (Federated Cross-Modal Style-Aware Prompt Generation). Our framework
harnesses low, mid, and high-level features from CLIP's vision encoder
alongside client-specific style indicators derived from batch-level statistics.
By merging intricate visual details with textual context, FedCSAP produces
robust, context-aware prompt tokens that are both distinct and non-redundant,
thereby boosting generalization across seen and unseen classes. Operating
within a federated learning paradigm, our approach ensures data privacy through
local training and global aggregation, adeptly handling non-IID class
distributions and diverse domain-specific styles. Comprehensive experiments on
multiple image classification datasets confirm that FedCSAP outperforms
existing federated prompt learning methods in both accuracy and overall
generalization.

</details>


### [72] [MPCAR: Multi-Perspective Contextual Augmentation for Enhanced Visual Reasoning in Large Vision-Language Models](https://arxiv.org/abs/2508.12400)
*Amirul Rahman,Qiang Xu,Xueying Huang*

Main category: cs.CV

TL;DR: MPCAR 是一种无需微调即可增强大型视觉语言模型 (LVLM) 在复杂视觉推理任务中性能的推理时策略。它通过从多个角度生成补充描述来丰富输入提示，从而提高模型理解和回答复杂视觉问题的能力。在 GQA、VQA-CP v2 和 ScienceQA 等数据集上的实验表明，MPCAR 相比现有方法具有显著的准确性提升。


<details>
  <summary>Details</summary>
Motivation: 现有的 LVLM 在复杂视觉推理任务（需要深度上下文理解、多角度分析或细致的细节识别）方面仍然面临挑战。现有方法通常依赖于单次图像编码和提示，这限制了它们充分捕捉细微视觉信息的能力。MPCAR 受到通过策略性生成的“额外”信息可以作为有益的上下文增强的启发。

Method: MPCAR 是一种新颖的推理时策略，分三个阶段进行：1. LVLM 从不同角度生成 N 个多样的、互补的描述或初步推理路径。2. 将这些描述与原始问题智能地集成，构建一个全面的上下文增强提示。3. 使用此丰富提示来指导最终的 LVLM 进行深度推理和最终答案生成。整个过程无需对底层 LVLM 的参数进行任何微调。

Result: MPCAR 在 GQA、VQA-CP v2 和 ScienceQA（图像-VQA）等具有挑战性的视觉问答（VQA）数据集上进行了广泛的实验，并且始终优于已建立的基线方法。定量结果显示准确性显著提高，尤其是在需要稳健上下文理解的任务上，而人类评估证实了生成答案的连贯性和完整性得到了改善。消融研究进一步强调了不同提示模板和生成视角数量的重要性。

Conclusion: MPCAR 通过利用大型视觉语言模型（LVLM）固有的生成能力来丰富输入上下文，从而解锁了它们在复杂多模态任务中的潜在推理潜力。

Abstract: Despite significant advancements, Large Vision-Language Models (LVLMs)
continue to face challenges in complex visual reasoning tasks that demand deep
contextual understanding, multi-angle analysis, or meticulous detail
recognition. Existing approaches often rely on single-shot image encoding and
prompts, limiting their ability to fully capture nuanced visual information.
Inspired by the notion that strategically generated "additional" information
can serve as beneficial contextual augmentation, we propose Multi-Perspective
Contextual Augmentation for Reasoning (MPCAR), a novel inference-time strategy
designed to enhance LVLM performance. MPCAR operates in three stages: first, an
LVLM generates N diverse and complementary descriptions or preliminary
reasoning paths from various angles; second, these descriptions are
intelligently integrated with the original question to construct a
comprehensive context-augmented prompt; and finally, this enriched prompt
guides the ultimate LVLM for deep reasoning and final answer generation.
Crucially, MPCAR achieves these enhancements without requiring any fine-tuning
of the underlying LVLM's parameters. Extensive experiments on challenging
Visual Question Answering (VQA) datasets, including GQA, VQA-CP v2, and
ScienceQA (Image-VQA), demonstrate that MPCAR consistently outperforms
established baseline methods. Our quantitative results show significant
accuracy gains, particularly on tasks requiring robust contextual
understanding, while human evaluations confirm improved coherence and
completeness of the generated answers. Ablation studies further highlight the
importance of diverse prompt templates and the number of generated
perspectives. This work underscores the efficacy of leveraging LVLMs' inherent
generative capabilities to enrich input contexts, thereby unlocking their
latent reasoning potential for complex multimodal tasks.

</details>


### [73] [LMAD: Integrated End-to-End Vision-Language Model for Explainable Autonomous Driving](https://arxiv.org/abs/2508.12404)
*Nan Song,Bozhou Zhang,Xiatian Zhu,Jiankang Deng,Li Zhang*

Main category: cs.CV

TL;DR: LMAD是一种新颖的视觉-语言框架，通过整合场景交互和专家适配器，提升了自动驾驶场景下VLM的性能，实现了更强的场景理解和空间感知能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要在车载多视图图像和场景推理文本上对VLM进行微调，但这种方法在复杂情况下往往缺乏自动驾驶所需的整体和细致的场景识别以及强大的空间感知能力。

Method: 提出了一种新颖的、针对自动驾驶的视觉-语言框架LMAD，该框架通过整合全面的场景理解和任务专业化结构来效仿现代端到端驾驶范式。具体而言，在相同的驾驶任务结构中引入了初步的场景交互和专门的专家适配器，以更好地使VLM适应自动驾驶场景。该框架兼容现有VLM并可与以规划为导向的驾驶系统无缝集成。

Result: 在DriveLM和nuScenes-QA数据集上的大量实验表明，LMAD显著提升了现有VLM在驾驶推理任务上的性能。

Conclusion: LMAD框架显著提升了现有VLM在驾驶推理任务上的性能，为可解释的自动驾驶树立了新的标杆。

Abstract: Large vision-language models (VLMs) have shown promising capabilities in
scene understanding, enhancing the explainability of driving behaviors and
interactivity with users. Existing methods primarily fine-tune VLMs on on-board
multi-view images and scene reasoning text, but this approach often lacks the
holistic and nuanced scene recognition and powerful spatial awareness required
for autonomous driving, especially in complex situations. To address this gap,
we propose a novel vision-language framework tailored for autonomous driving,
called LMAD. Our framework emulates modern end-to-end driving paradigms by
incorporating comprehensive scene understanding and a task-specialized
structure with VLMs. In particular, we introduce preliminary scene interaction
and specialized expert adapters within the same driving task structure, which
better align VLMs with autonomous driving scenarios. Furthermore, our approach
is designed to be fully compatible with existing VLMs while seamlessly
integrating with planning-oriented driving systems. Extensive experiments on
the DriveLM and nuScenes-QA datasets demonstrate that LMAD significantly boosts
the performance of existing VLMs on driving reasoning tasks,setting a new
standard in explainable autonomous driving.

</details>


### [74] [S5: Scalable Semi-Supervised Semantic Segmentation in Remote Sensing](https://arxiv.org/abs/2508.12409)
*Liang Lv,Di Wang,Jing Zhang,Lefei Zhang*

Main category: cs.CV

TL;DR: S5 是一个可扩展的遥感半监督语义分割框架，通过构建 RS4P-1M 数据集和预训练/微调 RSFMs，提升了遥感分析的性能，并实现了跨多个遥感基准的最优表现。


<details>
  <summary>Details</summary>
Motivation: 现有半监督语义分割（S4）研究多依赖于小规模数据集和模型，限制了其在遥感分析中的实际应用。本文旨在解决这一问题，解锁海量未标记遥感数据的潜力。

Method: 提出了一种名为 S5 的可扩展框架，用于遥感领域的半监督语义分割。该框架包含数据选择策略（熵过滤和多样性扩展），构建了 RS4P-1M 数据集。在此数据集上预训练不同规模的 RSFMs。在微调阶段，采用基于 Mixture-of-Experts (MoE) 的多数据集微调方法，以提高泛化能力和效率。

Result: 所提出的 RSFMs 在土地覆盖分割和目标检测任务上取得了显著的性能提升，并在所有基准测试中达到了最先进的水平。MoE 微调方法提高了 RSFMs 在不同遥感基准上的泛化能力和通用性。

Conclusion: S5 框架在遥感领域实现了半监督学习的可扩展性，通过预训练大规模遥感基础模型（RSFMs）并在多个遥感基准上进行微调，取得了最先进的性能，展示了半监督学习在遥感应用中的可行性。

Abstract: Semi-supervised semantic segmentation (S4) has advanced remote sensing (RS)
analysis by leveraging unlabeled data through pseudo-labeling and consistency
learning. However, existing S4 studies often rely on small-scale datasets and
models, limiting their practical applicability. To address this, we propose S5,
the first scalable framework for semi-supervised semantic segmentation in RS,
which unlocks the potential of vast unlabeled Earth observation data typically
underutilized due to costly pixel-level annotations. Built upon existing
large-scale RS datasets, S5 introduces a data selection strategy that
integrates entropy-based filtering and diversity expansion, resulting in the
RS4P-1M dataset. Using this dataset, we systematically scales S4 methods by
pre-training RS foundation models (RSFMs) of varying sizes on this extensive
corpus, significantly boosting their performance on land cover segmentation and
object detection tasks. Furthermore, during fine-tuning, we incorporate a
Mixture-of-Experts (MoE)-based multi-dataset fine-tuning approach, which
enables efficient adaptation to multiple RS benchmarks with fewer parameters.
This approach improves the generalization and versatility of RSFMs across
diverse RS benchmarks. The resulting RSFMs achieve state-of-the-art performance
across all benchmarks, underscoring the viability of scaling semi-supervised
learning for RS applications. All datasets, code, and models will be released
at https://github.com/MiliLab/S5

</details>


### [75] [SRMA-Mamba: Spatial Reverse Mamba Attention Network for Pathological Liver Segmentation in MRI Volumes](https://arxiv.org/abs/2508.12410)
*Jun Zeng,Yannan Huang,Elif Keles,Halil Ertugrul Aktas,Gorkem Durak,Nikhil Kumar Tomar,Quoc-Huy Trinh,Deepak Ranjan Nayak,Ulas Bagci,Debesh Jha*

Main category: cs.CV

TL;DR: 介绍了一种名为SRMA-Mamba的新型基于Mamba的网络，用于更有效地分割肝脏MRI图像中的病灶。


<details>
  <summary>Details</summary>
Motivation: 现有的肝硬化检测方法未能充分利用MRI数据中的空间解剖细节，影响了其临床有效性和可解释性。

Method: 提出了一种新颖的基于Mamba的网络SRMA-Mamba，它集成了基于空间解剖的Mamba模块（SABMamba）和空间反向注意力模块（SRMA），以对MRI体积数据中的空间关系进行建模，并有效分割病灶肝脏结构。

Result: SRMA-Mamba在3D病灶肝脏分割方面表现出色，超越了现有技术。

Conclusion: SRMA-Mamba在3D病灶肝脏分割方面超越了最先进的方法，表现出色。

Abstract: Liver Cirrhosis plays a critical role in the prognosis of chronic liver
disease. Early detection and timely intervention are critical in significantly
reducing mortality rates. However, the intricate anatomical architecture and
diverse pathological changes of liver tissue complicate the accurate detection
and characterization of lesions in clinical settings. Existing methods
underutilize the spatial anatomical details in volumetric MRI data, thereby
hindering their clinical effectiveness and explainability. To address this
challenge, we introduce a novel Mamba-based network, SRMA-Mamba, designed to
model the spatial relationships within the complex anatomical structures of MRI
volumes. By integrating the Spatial Anatomy-Based Mamba module (SABMamba),
SRMA-Mamba performs selective Mamba scans within liver cirrhotic tissues and
combines anatomical information from the sagittal, coronal, and axial planes to
construct a global spatial context representation, enabling efficient
volumetric segmentation of pathological liver structures. Furthermore, we
introduce the Spatial Reverse Attention module (SRMA), designed to
progressively refine cirrhotic details in the segmentation map, utilizing both
the coarse segmentation map and hierarchical encoding features. Extensive
experiments demonstrate that SRMA-Mamba surpasses state-of-the-art methods,
delivering exceptional performance in 3D pathological liver segmentation. Our
code is available for public:
{\color{blue}{https://github.com/JunZengz/SRMA-Mamba}}.

</details>


### [76] [TiP4GEN: Text to Immersive Panorama 4D Scene Generation](https://arxiv.org/abs/2508.12415)
*Ke Xing,Hanwen Liang,Dejia Xu,Yuyang Yin,Konstantinos N. Plataniotis,Yao Zhao,Yunchao Wei*

Main category: cs.CV

TL;DR: TiP4GEN是一个创新的文本到动态全景场景生成框架，通过双分支模型和几何对齐重建，解决了现有技术无法生成360度沉浸式动态场景的限制，实现了高质量、几何一致且运动丰富的全景4D场景生成。


<details>
  <summary>Details</summary>
Motivation: 现有VR/AR技术发展迅速，但现有生成方法主要集中于静态场景或狭窄视角动态场景，无法提供真正的360度沉浸式体验。

Method: TiP4GEN框架整合了全景视频生成和动态场景重建，采用“双分支生成模型”处理全局和局部视图，并通过“几何对齐重建模型”实现基于3D高斯泼溅法的几何一致性和时间连贯性。

Result: TiP4GEN能够生成运动丰富、几何一致的全景4D场景，并实现精细的内容控制，提供360度沉浸式虚拟环境。

Conclusion: TiP4GEN在生成视觉上引人入胜且运动连贯的动态全景场景方面，通过了广泛的实验验证，并展现出优越性。

Abstract: With the rapid advancement and widespread adoption of VR/AR technologies,
there is a growing demand for the creation of high-quality, immersive dynamic
scenes. However, existing generation works predominantly concentrate on the
creation of static scenes or narrow perspective-view dynamic scenes, falling
short of delivering a truly 360-degree immersive experience from any viewpoint.
In this paper, we introduce \textbf{TiP4GEN}, an advanced text-to-dynamic
panorama scene generation framework that enables fine-grained content control
and synthesizes motion-rich, geometry-consistent panoramic 4D scenes. TiP4GEN
integrates panorama video generation and dynamic scene reconstruction to create
360-degree immersive virtual environments. For video generation, we introduce a
\textbf{Dual-branch Generation Model} consisting of a panorama branch and a
perspective branch, responsible for global and local view generation,
respectively. A bidirectional cross-attention mechanism facilitates
comprehensive information exchange between the branches. For scene
reconstruction, we propose a \textbf{Geometry-aligned Reconstruction Model}
based on 3D Gaussian Splatting. By aligning spatial-temporal point clouds using
metric depth maps and initializing scene cameras with estimated poses, our
method ensures geometric consistency and temporal coherence for the
reconstructed scenes. Extensive experiments demonstrate the effectiveness of
our proposed designs and the superiority of TiP4GEN in generating visually
compelling and motion-coherent dynamic panoramic scenes. Our project page is at
https://ke-xing.github.io/TiP4GEN/.

</details>


### [77] [Illusions in Humans and AI: How Visual Perception Aligns and Diverges](https://arxiv.org/abs/2508.12422)
*Jianyi Yang,Junyi Ye,Ankan Dash,Guiling Wang*

Main category: cs.CV

TL;DR: 视觉错觉揭示了人类感知是基于上下文假设，而不是原始感官数据。本文探讨了人工智能对经典视觉错觉的反应，发现了一些类似错觉的效应，同时也识别出了一些人工智能特有的错觉，例如像素级敏感性和幻觉。这些发现有助于开发更符合人类需求的人工智能视觉系统。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能视觉系统越来越多地执行类似人类的任务，理解这些差异可以为开发更强大、可解释和与人类兼容的人工智能视觉系统提供信息。因此，本文旨在探讨人工智能是否也会经历错觉，以及是否具有独特的错觉。

Method: 通过比较生物和人工感知，并借助视觉错觉的透镜，重点探讨了每个系统构建视觉现实的关键差异。具体来说，探讨了人工智能如何响应涉及颜色、大小、形状和运动的经典视觉错觉。

Result: 研究发现，一些类似错觉的效应可以出现在人工智能模型中，这些效应可能通过有针对性的训练或作为模式识别的副产品而出现。此外，还识别出了一些人工智能特有的错觉，例如像素级敏感性和幻觉，这些错觉在人类感知中找不到对应项。

Conclusion: 通过系统地比较人类和人工智能对视觉错觉的反应，我们发现了人工智能在感知方面的对齐差距和特有的脆弱性，这些在人类感知中是看不见的。这些发现为未来开发保留有益于人类的感知偏差，同时避免破坏信任和安全性的失真的人工视觉系统提供了见解。

Abstract: By comparing biological and artificial perception through the lens of
illusions, we highlight critical differences in how each system constructs
visual reality. Understanding these divergences can inform the development of
more robust, interpretable, and human-aligned artificial intelligence (AI)
vision systems. In particular, visual illusions expose how human perception is
based on contextual assumptions rather than raw sensory data. As artificial
vision systems increasingly perform human-like tasks, it is important to ask:
does AI experience illusions, too? Does it have unique illusions? This article
explores how AI responds to classic visual illusions that involve color, size,
shape, and motion. We find that some illusion-like effects can emerge in these
models, either through targeted training or as by-products of pattern
recognition. In contrast, we also identify illusions unique to AI, such as
pixel-level sensitivity and hallucinations, that lack human counterparts. By
systematically comparing human and AI responses to visual illusions, we uncover
alignment gaps and AI-specific perceptual vulnerabilities invisible to human
perception. These findings provide insights for future research on vision
systems that preserve human-beneficial perceptual biases while avoiding
distortions that undermine trust and safety.

</details>


### [78] [Adversarial Attacks on VQA-NLE: Exposing and Alleviating Inconsistencies in Visual Question Answering Explanations](https://arxiv.org/abs/2508.12430)
*Yahsin Yeh,Yilun Wu,Bokai Ruan,Honghan Shuai*

Main category: cs.CV

TL;DR: 现有的VQA-NLE系统存在漏洞，可能产生不一致的解释。研究人员提出了一种新的攻击策略，通过最小程度地改变图像来诱导矛盾输出，并引入了一种利用外部知识的缓解方法来增强模型鲁棒性。实验证明了该攻击的有效性和防御方法的潜力，并指出了当前VQA-NLE系统在安全性和可靠性方面存在的问题。


<details>
  <summary>Details</summary>
Motivation: 旨在使黑盒模型更透明，阐明其决策过程。

Method: 提出了一种新的策略，该策略对图像进行最小程度的改变，以诱导矛盾或虚假的输出来突出这些漏洞。此外，还引入了一种利用外部知识来缓解这些不一致性的方法，从而增强模型的鲁棒性。

Result: 所提出的攻击方法和基于知识的防御方法的有效性得到了证明，揭示了当前VQA-NLE系统在安全性和可靠性方面令人担忧的问题。

Conclusion: 现有的VQA-NLE系统可能产生不一致的解释，并且在没有真正理解潜在上下文的情况下得出结论，这暴露了它们在推理流程或解释生成机制方面的弱点。

Abstract: Natural language explanations in visual question answering (VQA-NLE) aim to
make black-box models more transparent by elucidating their decision-making
processes. However, we find that existing VQA-NLE systems can produce
inconsistent explanations and reach conclusions without genuinely understanding
the underlying context, exposing weaknesses in either their inference pipeline
or explanation-generation mechanism. To highlight these vulnerabilities, we not
only leverage an existing adversarial strategy to perturb questions but also
propose a novel strategy that minimally alters images to induce contradictory
or spurious outputs. We further introduce a mitigation method that leverages
external knowledge to alleviate these inconsistencies, thereby bolstering model
robustness. Extensive evaluations on two standard benchmarks and two widely
used VQA-NLE models underscore the effectiveness of our attacks and the
potential of knowledge-based defenses, ultimately revealing pressing security
and reliability concerns in current VQA-NLE systems.

</details>


### [79] [X-Ray-CoT: Interpretable Chest X-ray Diagnosis with Vision-Language Models via Chain-of-Thought Reasoning](https://arxiv.org/abs/2508.12455)
*Chee Ng,Liliang Sun,Shaoqing Tang*

Main category: cs.CV

TL;DR: X-Ray-CoT 使用视觉语言大模型和思维链方法，提高了胸部 X 光诊断的准确性和可解释性，生成的报告质量高且易于理解。


<details>
  <summary>Details</summary>
Motivation: 胸部 X 光检查对诊断肺部和心脏疾病至关重要，但其解读需要丰富的临床经验，并且存在观察者间变异性。现有的深度学习模型虽然诊断准确率高，但其黑盒性质阻碍了在关键医疗场景中的临床应用。因此，需要开发一种既能保证诊断准确性，又能提供可解释性的方法。

Method: 提出了一种名为 X-Ray-CoT 的新框架，该框架利用视觉语言大模型 (LVLMs) 进行智能胸部 X 光诊断和可解释报告生成。该框架首先提取多模态特征和视觉概念，然后利用基于大语言模型的组件和结构化的思维链 (Chain-of-Thought) 提示策略进行推理，并生成详细的自然语言诊断报告，模拟了放射科医生进行诊断的“思维链”过程。

Result: X-Ray-CoT 在 CORDA 数据集上的评估结果显示，在疾病诊断方面取得了 80.52% 的平衡准确率和 78.65% 的 F1 分数，性能与现有黑盒模型相当，甚至略有超出。更重要的是，该框架能够生成高质量、可解释的报告，这一点已通过初步的人类评估得到验证。消融研究证实了多模态融合和思维链推理对于模型性能和透明度的重要性。

Conclusion: X-Ray-CoT 框架通过结合多模态特征提取、结构化思维链提示策略和基于大语言模型的推理，实现了胸部 X 光片的智能诊断和可解释报告生成。该框架在 CORDA 数据集上取得了具有竞争力的诊断性能（平衡准确率 80.52%，F1 分数 78.65%），并生成了高质量、可解释的报告，优于现有的黑盒模型。消融研究证明了多模态融合和思维链推理对构建稳健、透明的医疗人工智能的必要性。该研究是迈向值得信赖且具有临床应用价值的医学影像人工智能的重要一步。

Abstract: Chest X-ray imaging is crucial for diagnosing pulmonary and cardiac diseases,
yet its interpretation demands extensive clinical experience and suffers from
inter-observer variability. While deep learning models offer high diagnostic
accuracy, their black-box nature hinders clinical adoption in high-stakes
medical settings. To address this, we propose X-Ray-CoT (Chest X-Ray
Chain-of-Thought), a novel framework leveraging Vision-Language Large Models
(LVLMs) for intelligent chest X-ray diagnosis and interpretable report
generation. X-Ray-CoT simulates human radiologists' "chain-of-thought" by first
extracting multi-modal features and visual concepts, then employing an
LLM-based component with a structured Chain-of-Thought prompting strategy to
reason and produce detailed natural language diagnostic reports. Evaluated on
the CORDA dataset, X-Ray-CoT achieves competitive quantitative performance,
with a Balanced Accuracy of 80.52% and F1 score of 78.65% for disease
diagnosis, slightly surpassing existing black-box models. Crucially, it
uniquely generates high-quality, explainable reports, as validated by
preliminary human evaluations. Our ablation studies confirm the integral role
of each proposed component, highlighting the necessity of multi-modal fusion
and CoT reasoning for robust and transparent medical AI. This work represents a
significant step towards trustworthy and clinically actionable AI systems in
medical imaging.

</details>


### [80] [Inverse-LLaVA: Eliminating Alignment Pre-training Through Text-to-Vision Mapping](https://arxiv.org/abs/2508.12466)
*Xuhui Zhan,Tyler Derr*

Main category: cs.CV

TL;DR: Inverse-LLaVA 是一种新方法，无需对齐预训练，即可通过将文本映射到视觉空间并进行融合，在推理任务上表现出色，但感知任务性能有所下降，展示了更高效多模态学习的可能性。


<details>
  <summary>Details</summary>
Motivation: 挑战了传统多模态学习方法需要昂贵的对齐预训练以及将视觉特征投影到离散文本标记空间的两个基本假设。

Method: Inverse-LLaVA 通过将文本嵌入映射到连续的视觉表示空间，并在 Transformer 中间层执行融合，利用注意力机制中的选择性添加组件来实现动态的视觉和文本表示集成，从而消除了对昂贵的对齐预训练的依赖。

Result: 在九个多模态基准测试中，Inverse-LLaVA 在推理密集型和认知任务（MM-VET: +0.2%, VizWiz: +1.8%, ScienceQA: +0.2%, 认知推理: +27.2%）上取得了显著改进，但在需要记忆视觉-文本关联的感知任务（名人识别: -49.5%, OCR: -21.3%）上表现有所下降，同时计算需求减少了 45%。

Conclusion: 通过移除预训练和逆转映射方向，Inverse-LLaVA 证明了在没有大规模图像-文本对齐数据集的情况下，多模态学习是可行的，尤其是在复杂推理任务上。

Abstract: Traditional multimodal learning approaches require expensive alignment
pre-training to bridge vision and language modalities, typically projecting
visual features into discrete text token spaces. We challenge both fundamental
assumptions underlying this paradigm by proposing Inverse-LLaVA, a novel
approach that eliminates alignment pre-training entirely while inverting the
conventional mapping direction. Rather than projecting visual features to text
space, our method maps text embeddings into continuous visual representation
space and performs fusion within transformer intermediate layers. Through
selective additive components in attention mechanisms, we enable dynamic
integration of visual and textual representations without requiring massive
image-text alignment datasets. Comprehensive experiments across nine multimodal
benchmarks demonstrate nuanced performance trade-offs: Inverse-LLaVA achieves
notable improvements on reasoning-intensive and cognitive tasks (MM-VET: +0.2%,
VizWiz: +1.8%, ScienceQA: +0.2%, cognitive reasoning: +27.2%), while showing
expected decreases in perception tasks requiring memorized visual-text
associations (celebrity recognition: -49.5%, OCR: -21.3%). These results
provide the first empirical evidence that alignment pre-training is not
necessary for effective multimodal learning, particularly for complex reasoning
tasks. Our work establishes the feasibility of a new paradigm that reduces
computational requirements by 45%, challenges conventional wisdom about
modality fusion, and opens new research directions for efficient multimodal
architectures that preserve modality-specific characteristics. Our project
website with code and additional resources is available at
https://inverse-llava.github.io.

</details>


### [81] [Standardization of Neuromuscular Reflex Analysis -- Role of Fine-Tuned Vision-Language Model Consortium and OpenAI gpt-oss Reasoning LLM Enabled Decision Support System](https://arxiv.org/abs/2508.12473)
*Eranga Bandara,Ross Gore,Sachin Shetty,Ravi Mukkamala,Christopher Rhea,Atmaram Yarlagadda,Shaifali Kaushik,L. H. M. P. De Silva,Andriy Maznychenko,Inna Sokolowska,Amin Hass,Kasun De Zoysa*

Main category: cs.CV

TL;DR: 提出了一种结合视觉语言模型（VLM）和语言模型（LLM）的混合系统，用于自动解释和诊断H-反射波形，解决了传统方法的变异性和解释偏差问题，提高了准确性、一致性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统的H-反射肌电图波形分析存在变异性和解释偏差，限制了其可靠性和标准化。为了解决这些挑战，需要一种自动化的方法来解释和诊断H-反射波形。

Method: 提出了一种精细化视觉语言模型（VLM）联盟和支持决策的语言模型（LLM），用于自动解释和诊断H-反射波形。该方法利用了经过H-反射肌电图（EMG）波形图像（附带临床观察、恢复时间和运动员元数据）注释的精细化VLM，以提取关键的电生理特征并预测神经肌肉状态。VLM联盟的诊断输出通过共识方法进行聚合，并由专门的LLM进行优化，以确保为临床医生和运动科学家提供可靠、透明和可解释的决策支持。该端到端平台通过整合提示工程策略和使用LLM代理的自动化推理工作流，实现了VLM集合与LLM之间的无缝通信。

Result: 实验结果表明，该混合系统能够提供高度准确、一致且可解释的H-反射评估。

Conclusion: 该混合系统能够提供高度准确、一致且可解释的神经肌肉反射评估，显著推进了神经肌肉诊断的自动化和标准化。

Abstract: Accurate assessment of neuromuscular reflexes, such as the H-reflex, plays a
critical role in sports science, rehabilitation, and clinical neurology.
Traditional analysis of H-reflex EMG waveforms is subject to variability and
interpretation bias among clinicians and researchers, limiting reliability and
standardization. To address these challenges, we propose a Fine-Tuned
Vision-Language Model (VLM) Consortium and a reasoning Large-Language Model
(LLM)-enabled Decision Support System for automated H-reflex waveform
interpretation and diagnosis. Our approach leverages multiple VLMs, each
fine-tuned on curated datasets of H-reflex EMG waveform images annotated with
clinical observations, recovery timelines, and athlete metadata. These models
are capable of extracting key electrophysiological features and predicting
neuromuscular states, including fatigue, injury, and recovery, directly from
EMG images and contextual metadata. Diagnostic outputs from the VLM consortium
are aggregated using a consensus-based method and refined by a specialized
reasoning LLM, which ensures robust, transparent, and explainable decision
support for clinicians and sports scientists. The end-to-end platform
orchestrates seamless communication between the VLM ensemble and the reasoning
LLM, integrating prompt engineering strategies and automated reasoning
workflows using LLM Agents. Experimental results demonstrate that this hybrid
system delivers highly accurate, consistent, and interpretable H-reflex
assessments, significantly advancing the automation and standardization of
neuromuscular diagnostics. To our knowledge, this work represents the first
integration of a fine-tuned VLM consortium with a reasoning LLM for image-based
H-reflex analysis, laying the foundation for next-generation AI-assisted
neuromuscular assessment and athlete monitoring platforms.

</details>


### [82] [Skin Cancer Classification: Hybrid CNN-Transformer Models with KAN-Based Fusion](https://arxiv.org/abs/2508.12484)
*Shubhi Agarwal,Amulya Kumar Mahto*

Main category: cs.CV

TL;DR: 通过结合CNN、Transformer和CKAN，我们提出了一种新的混合模型，用于皮肤癌分类。该模型在多个数据集上取得了优异的性能，证明了其有效性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 皮肤癌分类是医学图像分析中的关键任务，需要精确区分良性和恶性病变以实现早期诊断和治疗。本研究旨在通过创新的混合模型设计来提高皮肤癌分类的准确性和泛化能力。

Method: 本研究探索了结合卷积神经网络（CNN）、Transformer和卷积Kolmogorov-Arnold网络（CKAN）的序列和并行混合模型，并利用迁移学习和数据增强技术来提升模型性能。CNN负责提取局部空间特征，Transformer处理全局依赖关系，CKAN则实现非线性特征融合。

Result: 实验结果表明，混合CNN-Transformer架构能有效捕捉空间和上下文特征，显著提高了分类性能。CKAN的引入通过可学习激活函数增强了特征融合，产生了更具判别力的表示。在HAM10000、PAD-UFES和BCN20000数据集上，该模型分别达到了92.81%的准确率和92.47%的F1分数、97.83%的准确率和97.83%的F1分数，以及91.17%的准确率和91.79%的F1分数。

Conclusion: 混合CNN-Transformer模型通过结合CKAN，在皮肤癌分类任务中展现出优越的性能和泛化能力，为医学图像分析提供了新的途径。

Abstract: Skin cancer classification is a crucial task in medical image analysis, where
precise differentiation between malignant and non-malignant lesions is
essential for early diagnosis and treatment. In this study, we explore
Sequential and Parallel Hybrid CNN-Transformer models with Convolutional
Kolmogorov-Arnold Network (CKAN). Our approach integrates transfer learning and
extensive data augmentation, where CNNs extract local spatial features,
Transformers model global dependencies, and CKAN facilitates nonlinear feature
fusion for improved representation learning. To assess generalization, we
evaluate our models on multiple benchmark datasets (HAM10000,BCN20000 and
PAD-UFES) under varying data distributions and class imbalances. Experimental
results demonstrate that hybrid CNN-Transformer architectures effectively
capture both spatial and contextual features, leading to improved
classification performance. Additionally, the integration of CKAN enhances
feature fusion through learnable activation functions, yielding more
discriminative representations. Our proposed approach achieves competitive
performance in skin cancer classification, demonstrating 92.81% accuracy and
92.47% F1-score on the HAM10000 dataset, 97.83% accuracy and 97.83% F1-score on
the PAD-UFES dataset, and 91.17% accuracy with 91.79% F1- score on the BCN20000
dataset highlighting the effectiveness and generalizability of our model across
diverse datasets. This study highlights the significance of feature
representation and model design in advancing robust and accurate medical image
classification.

</details>


### [83] [Design and Validation of a Responsible Artificial Intelligence-based System for the Referral of Diabetic Retinopathy Patients](https://arxiv.org/abs/2508.12506)
*E. Ulises Moya-Sánchez,Abraham Sánchez-Perez,Raúl Nanclares Da Veiga,Alejandro Zarate-Macías,Edgar Villareal,Alejandro Sánchez-Montes,Edtna Jauregui-Ulloa,Héctor Moreno,Ulises Cortés*

Main category: cs.CV

TL;DR: RAIS-DR 是一个在糖尿病视网膜病变筛查方面比 EyeArt 更有效的 AI 系统，它具有公平的性能，并能减少医疗保健差异。


<details>
  <summary>Details</summary>
Motivation: 为解决低质量数据和可能导致 AI 系统学习非预期特征的偏见等挑战，我们开发了 RAIS-DR，一个在 AI 生命周期中融入了伦理原则的负责任的 AI 系统，用于糖尿病视网膜病变筛查。

Method: RAIS-DR 集成了高效的卷积模型，用于预处理、质量评估和三个专门的 DR 分类模型。RAIS-DR 在包含 1,046 名患者的本地数据集上进行了评估，该数据集是两个系统都未见过的数据集。

Result: RAIS-DR 的 F1 分数提高了 5-12%，准确率提高了 6-19%，特异性提高了 10-20%。公平性指标表明 RAIS-DR 在不同人口统计学分组中的表现是公平的，有潜力减少医疗保健差异。

Conclusion: RAIS-DR 是一个强大的、符合伦理的解决方案，可用于临床环境中的糖尿病视网膜病变筛查。

Abstract: Diabetic Retinopathy (DR) is a leading cause of vision loss in working-age
individuals. Early detection of DR can reduce the risk of vision loss by up to
95%, but a shortage of retinologists and challenges in timely examination
complicate detection. Artificial Intelligence (AI) models using retinal fundus
photographs (RFPs) offer a promising solution. However, adoption in clinical
settings is hindered by low-quality data and biases that may lead AI systems to
learn unintended features. To address these challenges, we developed RAIS-DR, a
Responsible AI System for DR screening that incorporates ethical principles
across the AI lifecycle. RAIS-DR integrates efficient convolutional models for
preprocessing, quality assessment, and three specialized DR classification
models. We evaluated RAIS-DR against the FDA-approved EyeArt system on a local
dataset of 1,046 patients, unseen by both systems. RAIS-DR demonstrated
significant improvements, with F1 scores increasing by 5-12%, accuracy by
6-19%, and specificity by 10-20%. Additionally, fairness metrics such as
Disparate Impact and Equal Opportunity Difference indicated equitable
performance across demographic subgroups, underscoring RAIS-DR's potential to
reduce healthcare disparities. These results highlight RAIS-DR as a robust and
ethically aligned solution for DR screening in clinical settings. The code,
weights of RAIS-DR are available at
https://gitlab.com/inteligencia-gubernamental-jalisco/jalisco-retinopathy with
RAIL.

</details>


### [84] [LangVision-LoRA-NAS: Neural Architecture Search for Variable LoRA Rank in Vision Language Models](https://arxiv.org/abs/2508.12512)
*Krishna Teja Chitty-Venkata,Murali Emani,Venkatram Vishwanath*

Main category: cs.CV

TL;DR: 
LangVision-LoRA-NAS通过NAS优化LoRA秩，提升VLM性能并降低微调成本。



<details>
  <summary>Details</summary>
Motivation: 
当前LoRA（低秩自适应）在微调大型模型时假设秩是固定的，这可能限制了其在不同任务上的灵活性和效率。为了解决这个问题，本文旨在通过集成NAS来优化VLM的LoRA，实现可变秩自适应。


Method: 
本文提出了一种名为LangVision-LoRA-NAS的新框架，该框架将神经架构搜索（NAS）与LoRA（低秩自适应）相结合，以优化视觉语言模型（VLM）的可变秩自适应。具体而言，该方法利用NAS动态搜索针对特定多模态任务的最优LoRA秩配置，从而平衡模型性能与计算效率。


Result: 
通过在LLaMA-3.2-11B模型和多个数据集上进行的大量实验，LangVision-LoRA-NAS证明了其在提高模型性能方面取得了显著的改进，同时还降低了微调成本。


Conclusion: 
LangVision-LoRA-NAS
通过结合神经架构搜索（NAS）和LoRA（低秩自适应），为视觉语言模型（VLM）实现了可变秩自适应，并在LLaMA-3.2-11B模型上进行了广泛实验，证明了其在提升模型性能和降低微调成本方面的有效性。


Abstract: Vision Language Models (VLMs) integrate visual and text modalities to enable
multimodal understanding and generation. These models typically combine a
Vision Transformer (ViT) as an image encoder and a Large Language Model (LLM)
for text generation. LoRA (Low-Rank Adaptation) is an efficient fine-tuning
method to adapt pre-trained models to new tasks by introducing low-rank updates
to their weights. While LoRA has emerged as a powerful technique for
fine-tuning large models by introducing low-rank updates, current
implementations assume a fixed rank, potentially limiting flexibility and
efficiency across diverse tasks. This paper introduces
\textit{LangVision-LoRA-NAS}, a novel framework that integrates Neural
Architecture Search (NAS) with LoRA to optimize VLMs for variable-rank
adaptation. Our approach leverages NAS to dynamically search for the optimal
LoRA rank configuration tailored to specific multimodal tasks, balancing
performance and computational efficiency. Through extensive experiments using
the LLaMA-3.2-11B model on several datasets, LangVision-LoRA-NAS demonstrates
notable improvement in model performance while reducing fine-tuning costs. Our
Base and searched fine-tuned models on LLaMA-3.2-11B-Vision-Instruct can be
found
\href{https://huggingface.co/collections/krishnateja95/llama-32-11b-vision-instruct-langvision-lora-nas-6786cac480357a6a6fcc59ee}{\textcolor{blue}{here}}
and the code for LangVision-LoRA-NAS can be found
\href{https://github.com/krishnateja95/LangVision-NAS}{\textcolor{blue}{here}}.

</details>


### [85] [An Initial Study of Bird's-Eye View Generation for Autonomous Vehicles using Cross-View Transformers](https://arxiv.org/abs/2508.12520)
*Felipe Carlos dos Santos,Eric Aislan Antonelo,Gustavo Claudio Karl Couto*

Main category: cs.CV

TL;DR: 鸟瞰图 (BEV) 地图对于自动驾驶感知至关重要。本文使用跨视图 Transformer (CVT) 将摄像机图像映射到 BEV 地图（道路、车道线、规划轨迹）。研究了泛化到未见过的城镇、不同摄像机布局和两种损失函数（focal 和 L1）的效果。结果表明，使用 L1 损失训练的四摄像头 CVT 在新城镇的测试性能最为稳健，表明 CVT 在生成准确的 BEV 地图方面具有潜力。


<details>
  <summary>Details</summary>
Motivation: 鸟瞰图 (BEV) 地图对于自动驾驶感知至关重要，本文旨在探索使用 CVT 进行此映射。

Method: 使用跨视图 Transformer (CVT) 学习将摄像机图像映射到道路、车道线和规划轨迹的三个 BEV 通道。

Result: 在仅使用一个城镇的训练数据的情况下，使用 L1 损失训练的四摄像头 CVT 在新城镇的测试性能最为稳健。

Conclusion: CVT's 在将摄像机输入映射到相当准确的 BEV 地图方面显示出潜力。

Abstract: Bird's-Eye View (BEV) maps provide a structured, top-down abstraction that is
crucial for autonomous-driving perception. In this work, we employ Cross-View
Transformers (CVT) for learning to map camera images to three BEV's channels -
road, lane markings, and planned trajectory - using a realistic simulator for
urban driving. Our study examines generalization to unseen towns, the effect of
different camera layouts, and two loss formulations (focal and L1). Using
training data from only a town, a four-camera CVT trained with the L1 loss
delivers the most robust test performance, evaluated in a new town. Overall,
our results underscore CVT's promise for mapping camera inputs to reasonably
accurate BEV maps.

</details>


### [86] [MuSACo: Multimodal Subject-Specific Selection and Adaptation for Expression Recognition with Co-Training](https://arxiv.org/abs/2508.12522)
*Muhammad Osama Zeeshan,Natacha Gillet,Alessandro Lameiras Koerich,Marco Pedersoli,Francois Bremond,Eric Granger*

Main category: cs.CV

TL;DR: MuSACo is a new method for personalized expression recognition that uses multi-modal, multi-source domain adaptation to improve accuracy and robustness by selecting relevant source subjects and leveraging complementary information across modalities. It outperforms existing methods on challenging datasets.


<details>
  <summary>Details</summary>
Motivation: State-of-the-art MSDA approaches for personalized expression recognition overlook multimodal information or blend sources into a single domain, limiting subject diversity and failing to explicitly capture unique subject-specific characteristics.

Method: MuSACo, a multi-modal subject-specific selection and adaptation method for ER based on co-training. It leverages complementary information across multiple modalities and multiple source domains for subject-specific adaptation. MuSACo selects source subjects relevant to the target and generates pseudo-labels using the dominant modality for class-aware learning, in conjunction with a class-agnostic loss to learn from less confident target samples. Source features from each modality are aligned, while only confident target features are combined.

Result: MuSACo can outperform UDA (blending) and state-of-the-art MSDA methods.

Conclusion: MuSACo outperforms UDA and state-of-the-art MSDA methods on challenging multimodal ER datasets, BioVid and StressID.

Abstract: Personalized expression recognition (ER) involves adapting a machine learning
model to subject-specific data for improved recognition of expressions with
considerable interpersonal variability. Subject-specific ER can benefit
significantly from multi-source domain adaptation (MSDA) methods, where each
domain corresponds to a specific subject, to improve model accuracy and
robustness. Despite promising results, state-of-the-art MSDA approaches often
overlook multimodal information or blend sources into a single domain, limiting
subject diversity and failing to explicitly capture unique subject-specific
characteristics. To address these limitations, we introduce MuSACo, a
multi-modal subject-specific selection and adaptation method for ER based on
co-training. It leverages complementary information across multiple modalities
and multiple source domains for subject-specific adaptation. This makes MuSACo
particularly relevant for affective computing applications in digital health,
such as patient-specific assessment for stress or pain, where subject-level
nuances are crucial. MuSACo selects source subjects relevant to the target and
generates pseudo-labels using the dominant modality for class-aware learning,
in conjunction with a class-agnostic loss to learn from less confident target
samples. Finally, source features from each modality are aligned, while only
confident target features are combined. Our experimental results on challenging
multimodal ER datasets: BioVid and StressID, show that MuSACo can outperform
UDA (blending) and state-of-the-art MSDA methods.

</details>


### [87] [REVEAL -- Reasoning and Evaluation of Visual Evidence through Aligned Language](https://arxiv.org/abs/2508.12543)
*Ipsita Praharaj,Yukta Butala,Yash Butala*

Main category: cs.CV

TL;DR: REVEAL framework uses vision-language models for better image forgery detection across different domains, offering interpretable reasoning.


<details>
  <summary>Details</summary>
Motivation: Existing forgery detection methods struggle with generalization across domains and lack reasoning capabilities. There is a need for robust frameworks that provide both detection and interpretable reasoning for visual forgeries.

Method: REVEAL framework using prompt-driven visual reasoning with large vision-language models, incorporating (1) Holistic Scene-level Evaluation and (2) Region-wise anomaly detection.

Result: Experiments on Photoshop, DeepFake, and AIGC editing datasets demonstrate that the proposed vision-language model approach achieves competitive performance against baselines and provides coherent reasoning for detected forgeries.

Conclusion: The proposed REVEAL framework shows promising results in generalized forgery detection by leveraging vision-language models for prompt-driven visual reasoning. It offers both holistic and region-wise analysis, outperforming baselines on various datasets and providing interpretable reasoning.

Abstract: The rapid advancement of generative models has intensified the challenge of
detecting and interpreting visual forgeries, necessitating robust frameworks
for image forgery detection while providing reasoning as well as localization.
While existing works approach this problem using supervised training for
specific manipulation or anomaly detection in the embedding space,
generalization across domains remains a challenge. We frame this problem of
forgery detection as a prompt-driven visual reasoning task, leveraging the
semantic alignment capabilities of large vision-language models. We propose a
framework, `REVEAL` (Reasoning and Evaluation of Visual Evidence through
Aligned Language), that incorporates generalized guidelines. We propose two
tangential approaches - (1) Holistic Scene-level Evaluation that relies on the
physics, semantics, perspective, and realism of the image as a whole and (2)
Region-wise anomaly detection that splits the image into multiple regions and
analyzes each of them. We conduct experiments over datasets from different
domains (Photoshop, DeepFake and AIGC editing). We compare the Vision Language
Models against competitive baselines and analyze the reasoning provided by
them.

</details>


### [88] [Structure-preserving Feature Alignment for Old Photo Colorization](https://arxiv.org/abs/2508.12570)
*Yingxue Pang,Xin Jin,Jun Fu,Zhibo Chen*

Main category: cs.CV

TL;DR: SFAC is a novel CNN algorithm for old photo colorization that requires only two images, addresses the domain gap using feature alignment, and preserves structure through perceptual constraints and a pixel-level pyramid, achieving effective results.


<details>
  <summary>Details</summary>
Motivation: Address the challenges of applying deep learning to old photo colorization, such as lack of ground truth and domain gap, by proposing a novel algorithm.

Method: SFAC, a CNN-based algorithm using feature distribution alignment loss and a structure-preserving mechanism with perceptual constraint and pixel-level pyramid, is trained on only two images.

Result: SFAC overcomes the domain gap problem and mitigates structure distortions, achieving effective old photo colorization.

Conclusion: SFAC is effective for old photo colorization, as confirmed by qualitative and quantitative metrics.

Abstract: Deep learning techniques have made significant advancements in
reference-based colorization by training on large-scale datasets. However,
directly applying these methods to the task of colorizing old photos is
challenging due to the lack of ground truth and the notorious domain gap
between natural gray images and old photos. To address this issue, we propose a
novel CNN-based algorithm called SFAC, i.e., Structure-preserving Feature
Alignment Colorizer. SFAC is trained on only two images for old photo
colorization, eliminating the reliance on big data and allowing direct
processing of the old photo itself to overcome the domain gap problem. Our
primary objective is to establish semantic correspondence between the two
images, ensuring that semantically related objects have similar colors. We
achieve this through a feature distribution alignment loss that remains robust
to different metric choices. However, utilizing robust semantic correspondence
to transfer color from the reference to the old photo can result in inevitable
structure distortions. To mitigate this, we introduce a structure-preserving
mechanism that incorporates a perceptual constraint at the feature level and a
frozen-updated pyramid at the pixel level. Extensive experiments demonstrate
the effectiveness of our method for old photo colorization, as confirmed by
qualitative and quantitative metrics.

</details>


### [89] [Foundation Model for Skeleton-Based Human Action Understanding](https://arxiv.org/abs/2508.12586)
*Hongsong Wang,Wanjiang Weng,Junbo Wang,Fang Zhao,Guo-Sen Xie,Xin Geng,Liang Wang*

Main category: cs.CV

TL;DR: 本研究提出了USDRL，一个用于骨架分析动作理解的统一基础模型。它通过DSTE、MG-FD和MPCT等技术，在25个基准和9项任务上超越了现有SOTA方法，并有望推动密集预测任务的研究。


<details>
  <summary>Details</summary>
Motivation: 现有骨架分析动作理解方法在处理多样化的动作理解任务时，往往缺乏可扩展性和泛化能力，并且缺少能够适应广泛动作理解任务的骨架基础模型。因此，本研究旨在解决这一问题，提出一个统一的骨架基础模型。

Method: 本研究提出了一种名为USDRL的统一骨架分析密集表示学习框架，该框架包含三个主要部分：1) 基于Transformer的密集时空编码器（DSTE），通过两个并行流学习时态动态和空间结构特征；2) 多粒度特征解相关（MG-FD），在时态、空间和实例域中协同进行特征解相关，以减少冗余并增强信息提取；3) 多视角一致性训练（MPCT），通过多视角和多模态自监督一致性训练来提升学习效果，前者用于学习高层语义并减轻低层差异的影响，后者则促进信息丰富的多模态特征学习。

Result: 该USDRL框架在包括粗略预测、密集预测和迁移预测的9类骨架分析动作理解任务的25个基准测试中，取得了显著优于当前最先进方法的性能。

Conclusion: 该研究提出了一个名为USDRL的统一骨架表示学习框架，作为骨架分析人体动作理解的基石模型。通过结合DSTE、MG-FD和MPCT等模块，USDRL在25个基准和9项骨架分析动作理解任务上取得了显著成果，超越了现有技术水平。研究者希望此项工作能推动骨架分析动作理解领域的发展，并促进对密集预测任务的关注。

Abstract: Human action understanding serves as a foundational pillar in the field of
intelligent motion perception. Skeletons serve as a modality- and
device-agnostic representation for human modeling, and skeleton-based action
understanding has potential applications in humanoid robot control and
interaction. \RED{However, existing works often lack the scalability and
generalization required to handle diverse action understanding tasks. There is
no skeleton foundation model that can be adapted to a wide range of action
understanding tasks}. This paper presents a Unified Skeleton-based Dense
Representation Learning (USDRL) framework, which serves as a foundational model
for skeleton-based human action understanding. USDRL consists of a
Transformer-based Dense Spatio-Temporal Encoder (DSTE), Multi-Grained Feature
Decorrelation (MG-FD), and Multi-Perspective Consistency Training (MPCT). The
DSTE module adopts two parallel streams to learn temporal dynamic and spatial
structure features. The MG-FD module collaboratively performs feature
decorrelation across temporal, spatial, and instance domains to reduce
dimensional redundancy and enhance information extraction. The MPCT module
employs both multi-view and multi-modal self-supervised consistency training.
The former enhances the learning of high-level semantics and mitigates the
impact of low-level discrepancies, while the latter effectively facilitates the
learning of informative multimodal features. We perform extensive experiments
on 25 benchmarks across across 9 skeleton-based action understanding tasks,
covering coarse prediction, dense prediction, and transferred prediction. Our
approach significantly outperforms the current state-of-the-art methods. We
hope that this work would broaden the scope of research in skeleton-based
action understanding and encourage more attention to dense prediction tasks.

</details>


### [90] [Multimodal Chain of Continuous Thought for Latent-Space Reasoning in Vision-Language Models](https://arxiv.org/abs/2508.12587)
*Tan-Hanh Pham,Chris Ngo*

Main category: cs.CV

TL;DR: MCOUT 是一种新的多模态推理方法，它在联合潜在空间中进行推理，而不是像传统的思维链那样依赖语言。实验表明 MCOUT 在多项推理任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的针对大型多模态模型的推理技术（如思维链提示）主要基于语言模型，将推理表达为单词序列。虽然这些技术对文本有效，但在多模态环境中并不理想，难以动态地对齐音频、视觉和文本信息。

Method: 提出了一种名为多模态链式连续思想（MCOUT）的新范例，它直接在联合潜在空间中进行推理，而不是使用自然语言。MCOUT 将推理状态表示为连续隐藏向量，并通过受人类反思认知启发，与视觉和文本嵌入进行迭代精炼和对齐。开发了两个变体：MCOUT-Base 和 MCOUT-Multi，后者集成了多模态潜在注意力，以加强视觉和文本特征之间的跨模态对齐。

Result: MCOUT 在 MMMU、ScienceQA 和 MMStar 等基准测试中持续改进了多模态推理，在多项选择和开放式任务中，准确率提高了 8.23%，BLEU 分数提高了 8.27%。

Conclusion: MCOUT（多模态链式连续思想）的实验结果表明，它在多模态推理方面持续改进，在多项选择和开放式任务中，准确率提高了 8.23%，BLEU 分数提高了 8.27%，展示了潜在连续推理作为超越语言限制的思维链来推进大型多模态模型的有前景的方向，并提供了一个可扩展的框架来实现类似人类的反射性多模态推理。

Abstract: Many reasoning techniques for large multimodal models adapt language model
approaches, such as Chain-of-Thought (CoT) prompting, which express reasoning
as word sequences. While effective for text, these methods are suboptimal for
multimodal contexts, struggling to align audio, visual, and textual information
dynamically. To explore an alternative paradigm, we propose the Multimodal
Chain of Continuous Thought (MCOUT), which enables reasoning directly in a
joint latent space rather than in natural language. In MCOUT, the reasoning
state is represented as a continuous hidden vector, iteratively refined and
aligned with visual and textual embeddings, inspired by human reflective
cognition. We develop two variants: MCOUT-Base, which reuses the language
model`s last hidden state as the continuous thought for iterative reasoning,
and MCOUT-Multi, which integrates multimodal latent attention to strengthen
cross-modal alignment between visual and textual features. Experiments on
benchmarks including MMMU, ScienceQA, and MMStar show that MCOUT consistently
improves multimodal reasoning, yielding up to 8.23% accuracy gains over strong
baselines and improving BLEU scores up to 8.27% across multiple-choice and
open-ended tasks. These findings highlight latent continuous reasoning as a
promising direction for advancing LMMs beyond language-bound CoT, offering a
scalable framework for human-like reflective multimodal inference. Code is
available at https://github.com/Hanhpt23/OmniMod.

</details>


### [91] [ViLaD: A Large Vision Language Diffusion Framework for End-to-End Autonomous Driving](https://arxiv.org/abs/2508.12603)
*Can Cui,Yupeng Zhou,Juntong Peng,Sung-Yeon Park,Zichong Yang,Prashanth Sankaranarayanan,Jiaru Zhang,Ruqi Zhang,Ziran Wang*

Main category: cs.CV

TL;DR: ViLaD是一个创新的自动驾驶框架，使用扩散模型并行生成决策，速度更快，推理更准确，适用于真实世界的自动驾驶。


<details>
  <summary>Details</summary>
Motivation: 现有的基于视觉语言模型（VLM）的端到端自动驾驶系统虽然有前景，但其自回归架构在实际应用中存在高推理延迟和无法进行双向推理的局限性，不适合动态和安全关键环境。

Method: ViLaD框架采用了一种新颖的大型视觉语言扩散（LVLD）方法，利用掩码扩散模型进行端到端的自动驾驶。该模型能够并行生成整个驾驶决策序列，并支持双向推理和渐进式易优先生成。

Result: ViLaD在nuScenes数据集上进行了全面的实验，在规划准确性和推理速度方面均优于最先进的自回归VLM基线，失败率接近于零。此外，在真实自动驾驶车辆上的部署也证实了其在实际应用中的有效性和可靠性。

Conclusion: ViLaD框架通过利用掩码扩散模型实现了端到端的自动驾驶，该模型能够并行生成整个驾驶决策序列，显著降低了计算延迟。此外，其架构支持双向推理，允许模型同时考虑过去和未来，并支持渐进式易优先生成以迭代地提高决策质量。在nuScenes数据集上的实验表明，ViLaD在规划准确性和推理速度方面优于最先进的自回归VLM基线，并且失败率接近于零。在真实自动驾驶车辆上的部署也验证了其在实际应用中的有效性和可靠性。

Abstract: End-to-end autonomous driving systems built on Vision Language Models (VLMs)
have shown significant promise, yet their reliance on autoregressive
architectures introduces some limitations for real-world applications. The
sequential, token-by-token generation process of these models results in high
inference latency and cannot perform bidirectional reasoning, making them
unsuitable for dynamic, safety-critical environments. To overcome these
challenges, we introduce ViLaD, a novel Large Vision Language Diffusion (LVLD)
framework for end-to-end autonomous driving that represents a paradigm shift.
ViLaD leverages a masked diffusion model that enables parallel generation of
entire driving decision sequences, significantly reducing computational
latency. Moreover, its architecture supports bidirectional reasoning, allowing
the model to consider both past and future simultaneously, and supports
progressive easy-first generation to iteratively improve decision quality. We
conduct comprehensive experiments on the nuScenes dataset, where ViLaD
outperforms state-of-the-art autoregressive VLM baselines in both planning
accuracy and inference speed, while achieving a near-zero failure rate.
Furthermore, we demonstrate the framework's practical viability through a
real-world deployment on an autonomous vehicle for an interactive parking task,
confirming its effectiveness and soundness for practical applications.

</details>


### [92] [ViDA-UGC: Detailed Image Quality Analysis via Visual Distortion Assessment for UGC Images](https://arxiv.org/abs/2508.12605)
*Wenjie Liao,Jieyu Yuan,Yifang Xu,Chunle Guo,Zilong Zhang,Jihong Li,Jiachen Fu,Haotian Fan,Tao Li,Junhui Cui,Chongyi Li*

Main category: cs.CV

TL;DR: 本研究提出了ViDA-UGC数据集和CoT评估框架，以改进MLLMs在UGC图像质量评估方面的能力。该方法通过人类标注和GPT-4o的协同评估，解决了现有方法的不足，并通过实验证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有可解释IQA方法在评估UGC和AIGC图像时，未能区分不同的失真标准，并且缺乏对图像质量进行监控和指导图像恢复的详细分析。

Method: 提出了一种新颖的基于Chain-of-Thought（CoT）的评估框架，并结合了人类标注和GPT-4o的评估，构建了ViDA-UGC数据集（包含11K张图像）和ViDA-UGC-Bench基准。该方法旨在解决现有可解释IQA方法在处理用户生成内容（UGC）和人工智能生成内容（AIGC）图像时，未能区分不同类型的失真，并且缺乏详细的质量分析和恢复指导的问题。

Result: 实验结果证明了ViDA-UGC数据集和CoT框架的有效性，能够一致地提升多种MLLMs在ViDA-UGC-Bench和Q-Bench上的图像质量分析能力，在某些情况下甚至优于GPT-4o。

Conclusion: 本研究提出了ViDA-UGC数据集和基于Chain-of-Thought（CoT）的评估框架，用于提高多模态大语言模型（MLLMs）在图像质量评估（IQA）方面的能力，特别是在处理用户生成内容（UGC）图像时。实验结果表明，该方法能有效提升MLLMs的图像分析能力，甚至在某些方面超越了GPT-4o。

Abstract: Recent advances in Multimodal Large Language Models (MLLMs) have introduced a
paradigm shift for Image Quality Assessment (IQA) from unexplainable image
quality scoring to explainable IQA, demonstrating practical applications like
quality control and optimization guidance. However, current explainable IQA
methods not only inadequately use the same distortion criteria to evaluate both
User-Generated Content (UGC) and AI-Generated Content (AIGC) images, but also
lack detailed quality analysis for monitoring image quality and guiding image
restoration. In this study, we establish the first large-scale Visual
Distortion Assessment Instruction Tuning Dataset for UGC images, termed
ViDA-UGC, which comprises 11K images with fine-grained quality grounding,
detailed quality perception, and reasoning quality description data. This
dataset is constructed through a distortion-oriented pipeline, which involves
human subject annotation and a Chain-of-Thought (CoT) assessment framework.
This framework guides GPT-4o to generate quality descriptions by identifying
and analyzing UGC distortions, which helps capturing rich low-level visual
features that inherently correlate with distortion patterns. Moreover, we
carefully select 476 images with corresponding 6,149 question answer pairs from
ViDA-UGC and invite a professional team to ensure the accuracy and quality of
GPT-generated information. The selected and revised data further contribute to
the first UGC distortion assessment benchmark, termed ViDA-UGC-Bench.
Experimental results demonstrate the effectiveness of the ViDA-UGC and CoT
framework for consistently enhancing various image quality analysis abilities
across multiple base MLLMs on ViDA-UGC-Bench and Q-Bench, even surpassing
GPT-4o.

</details>


### [93] [OpenMoCap: Rethinking Optical Motion Capture under Real-world Occlusion](https://arxiv.org/abs/2508.12610)
*Chen Qian,Danyang Li,Xinran Yu,Zheng Yang,Qiang Ma*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Optical motion capture is a foundational technology driving advancements in
cutting-edge fields such as virtual reality and film production. However,
system performance suffers severely under large-scale marker occlusions common
in real-world applications. An in-depth analysis identifies two primary
limitations of current models: (i) the lack of training datasets accurately
reflecting realistic marker occlusion patterns, and (ii) the absence of
training strategies designed to capture long-range dependencies among markers.
To tackle these challenges, we introduce the CMU-Occlu dataset, which
incorporates ray tracing techniques to realistically simulate practical marker
occlusion patterns. Furthermore, we propose OpenMoCap, a novel motion-solving
model designed specifically for robust motion capture in environments with
significant occlusions. Leveraging a marker-joint chain inference mechanism,
OpenMoCap enables simultaneous optimization and construction of deep
constraints between markers and joints. Extensive comparative experiments
demonstrate that OpenMoCap consistently outperforms competing methods across
diverse scenarios, while the CMU-Occlu dataset opens the door for future
studies in robust motion solving. The proposed OpenMoCap is integrated into the
MoSen MoCap system for practical deployment. The code is released at:
https://github.com/qianchen214/OpenMoCap.

</details>


### [94] [WIPES: Wavelet-based Visual Primitives](https://arxiv.org/abs/2508.12615)
*Wenhao Zhang,Hao Zhu,Delong Wu,Di Kang,Linchao Bao,Zhan Ma,Xun Cao*

Main category: cs.CV

TL;DR: WIPES 是一种基于小波的通用视觉图元，用于表示多维视觉信号，可在保持高质量的同时实现快速渲染。


<details>
  <summary>Details</summary>
Motivation: 解决现有表示依赖频率引导或复杂神经网络解码导致频谱损失或渲染速度慢的问题。

Method: 提出了一种基于小波的可微分光栅化器，以实现快速视觉渲染。

Result: WIPES 作为一种视觉图元，在渲染质量和推理速度方面优于基于 INR 的方法，在渲染质量方面优于基于高斯的方法。

Conclusion: WIPES 在各种视觉任务（包括 2D 图像表示、5D 静态和 6D 动态新颖视图合成）上都优于基于 INR 的方法，并在渲染质量方面优于基于高斯的方法。

Abstract: Pursuing a continuous visual representation that offers flexible frequency
modulation and fast rendering speed has recently garnered increasing attention
in the fields of 3D vision and graphics. However, existing representations
often rely on frequency guidance or complex neural network decoding, leading to
spectrum loss or slow rendering. To address these limitations, we propose
WIPES, a universal Wavelet-based vIsual PrimitivES for representing
multi-dimensional visual signals. Building on the spatial-frequency
localization advantages of wavelets, WIPES effectively captures both the
low-frequency "forest" and the high-frequency "trees." Additionally, we develop
a wavelet-based differentiable rasterizer to achieve fast visual rendering.
Experimental results on various visual tasks, including 2D image
representation, 5D static and 6D dynamic novel view synthesis, demonstrate that
WIPES, as a visual primitive, offers higher rendering quality and faster
inference than INR-based methods, and outperforms Gaussian-based
representations in rendering quality.

</details>


### [95] [Creative4U: MLLMs-based Advertising Creative Image Selector with Comparative Reasoning](https://arxiv.org/abs/2508.12628)
*Yukang Lin,Xiang Zhang,Shichang Jia,Bowen Wan,Chenghan Fu,Xudong Ren,Yueran Liu,Wanxian Guan,Pengji Wang,Jian Xu,Bo Zheng,Baolin Liu*

Main category: cs.CV

TL;DR: 电商创意图评估难？试试我们基于MLLM的新方法！我们构建了CreativePair数据集和Creative4U模型，能解释为何选某张图，效果还不错。代码和数据都会公开。


<details>
  <summary>Details</summary>
Motivation: 电商平台创意图片对提升用户购物体验、增加广告商收入和平台广告收入至关重要。然而，广告商在利用AIGC技术大规模生成图片时，难以评估创意质量以进行选择。现有方法侧重于创意排名，但无法满足对可解释创意选择的需求。

Method: 本研究利用多模态大语言模型（MLLMs）将创意图像的评估和选择整合为自然语言生成任务。为支持该研究，构建了包含8k标注图像对的CreativePair数据集，并提出了Creative4U模型，通过结合Chain-of-Thought（CoT-SFT）和Group Relative Policy Optimization（GRPO）进行优化。

Result: 通过Reason-to-Select RFT（包括Chain-of-Thought（CoT-SFT）监督微调和基于Group Relative Policy Optimization（GRPO）的强化学习），Creative4U能够准确评估和选择创意图片。线下和线上实验均证明了该方法的有效性。

Conclusion: 该研究提出了首个用于可解释创意评估和选择的范例，并构建了CreativePair数据集和Creative4U模型，通过Chain-of-Thought（CoT-SFT）和Group Relative Policy Optimization（GRPO）进行优化，实验证明了该方法的有效性。

Abstract: Creative image in advertising is the heart and soul of e-commerce platform.
An eye-catching creative image can enhance the shopping experience for users,
boosting income for advertisers and advertising revenue for platforms. With the
advent of AIGC technology, advertisers can produce large quantities of creative
images at minimal cost. However, they struggle to assess the creative quality
to select. Existing methods primarily focus on creative ranking, which fails to
address the need for explainable creative selection.
  In this work, we propose the first paradigm for explainable creative
assessment and selection. Powered by multimodal large language models (MLLMs),
our approach integrates the assessment and selection of creative images into a
natural language generation task. To facilitate this research, we construct
CreativePair, the first comparative reasoning-induced creative dataset
featuring 8k annotated image pairs, with each sample including a label
indicating which image is superior. Additionally, we introduce Creative4U
(pronounced Creative for You), a MLLMs-based creative selector that takes into
account users' interests. Through Reason-to-Select RFT, which includes
supervised fine-tuning with Chain-of-Thought (CoT-SFT) and Group Relative
Policy Optimization (GRPO) based reinforcement learning, Creative4U is able to
evaluate and select creative images accurately. Both offline and online
experiments demonstrate the effectiveness of our approach. Our code and dataset
will be made public to advance research and industrial applications.

</details>


### [96] [SpotVLM: Cloud-edge Collaborative Real-time VLM based on Context Transfer](https://arxiv.org/abs/2508.12638)
*Chen Qian,Xinran Yu,Zewen Huang,Danyang Li,Qiang Ma,Fan Dang,Xuan Ding,Guangyong Shang,Zheng Yang*

Main category: cs.CV

TL;DR: 提出了一种名为“Context Transfer”的新范式，利用大型模型的延迟输出来指导小型模型，并设计了SpotVLM来优化此过程，在实时视觉任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的云边协同方法未能适应云延迟波动，并忽视了延迟但准确的LVLM响应的全部潜力。

Method: 提出了一种名为“Context Transfer”的新颖云边协同范例，并设计了SpotVLM，其中包含上下文替换和视觉焦点模块，以优化历史文本输入并增强视觉基础一致性。

Result: 在三个实时视觉任务和四个数据集上的广泛实验证明了所提出框架的有效性。

Conclusion: 提出了一种新颖的云边协同范例“Context Transfer”，用于视觉-语言模型（VLMs），该范例将大型视觉-语言模型（LVLMs）的延迟输作为历史上下文，为小型视觉-语言模型（SVLMs）的推理提供实时指导。基于此范例，设计了SpotVLM，包含上下文替换和视觉焦点模块，以优化历史文本输入并增强视觉基础一致性。

Abstract: Vision-Language Models (VLMs) are increasingly deployed in real-time
applications such as autonomous driving and human-computer interaction, which
demand fast and reliable responses based on accurate perception. To meet these
requirements, existing systems commonly employ cloud-edge collaborative
architectures, such as partitioned Large Vision-Language Models (LVLMs) or task
offloading strategies between Large and Small Vision-Language Models (SVLMs).
However, these methods fail to accommodate cloud latency fluctuations and
overlook the full potential of delayed but accurate LVLM responses. In this
work, we propose a novel cloud-edge collaborative paradigm for VLMs, termed
Context Transfer, which treats the delayed outputs of LVLMs as historical
context to provide real-time guidance for SVLMs inference. Based on this
paradigm, we design SpotVLM, which incorporates both context replacement and
visual focus modules to refine historical textual input and enhance visual
grounding consistency. Extensive experiments on three real-time vision tasks
across four datasets demonstrate the effectiveness of the proposed framework.
The new paradigm lays the groundwork for more effective and latency-aware
collaboration strategies in future VLM systems.

</details>


### [97] [Synthesizing Accurate and Realistic T1-weighted Contrast-Enhanced MR Images using Posterior-Mean Rectified Flow](https://arxiv.org/abs/2508.12640)
*Bastian Brandstötter,Erich Kobler*

Main category: cs.CV

TL;DR: PMRF技术通过结合3D U-Net和校正流，能从无对比MRI生成高质量的脑部CE MRI，减少了对昂贵和有风险的造影剂的依赖。


<details>
  <summary>Details</summary>
Motivation: 需要一种无需钆造影剂即可进行神经肿瘤学诊断的方法，以降低成本、扫描时间、环境影响和潜在的患者风险。

Method: 本研究提出了一种两阶段的后验均值校正流（PMRF）管道，用于从非对比MRI合成对比增强（CE）T1加权MRI。第一阶段使用基于块的3D U-Net预测体素的后验均值（最小化均方误差）。第二阶段通过时间条件3D校正流来优化估计，以加入真实的纹理细节，同时保持结构保真度。

Result: 在360个样本的测试集上，PMRF方法达到了12.46的轴向FID和0.007的KID，FID比后验均值估计低约68.7%，同时保持0.057的低体积均方误差（比后验均值估计高约27%）。定性评估显示，该方法能真实地恢复病灶边缘和血管细节。

Conclusion: PMRF管道能够从非对比输入合成脑部CE MRI，同时在感知和失真之间取得良好平衡，适用于临床部署。

Abstract: Contrast-enhanced (CE) T1-weighted MRI is central to neuro-oncologic
diagnosis but requires gadolinium-based agents, which add cost and scan time,
raise environmental concerns, and may pose risks to patients. In this work, we
propose a two-stage Posterior-Mean Rectified Flow (PMRF) pipeline for
synthesizing volumetric CE brain MRI from non-contrast inputs. First, a
patch-based 3D U-Net predicts the voxel-wise posterior mean (minimizing MSE).
Then, this initial estimate is refined by a time-conditioned 3D rectified flow
to incorporate realistic textures without compromising structural fidelity. We
train this model on a multi-institutional collection of paired pre- and
post-contrast T1w volumes (BraTS 2023-2025). On a held-out test set of 360
diverse volumes, our best refined outputs achieve an axial FID of $12.46$ and
KID of $0.007$ ($\sim 68.7\%$ lower FID than the posterior mean) while
maintaining low volumetric MSE of $0.057$ ($\sim 27\%$ higher than the
posterior mean). Qualitative comparisons confirm that our method restores
lesion margins and vascular details realistically, effectively navigating the
perception-distortion trade-off for clinical deployment.

</details>


### [98] [Learn Faster and Remember More: Balancing Exploration and Exploitation for Continual Test-time Adaptation](https://arxiv.org/abs/2508.12643)
*Pinci Yang,Peisong Wen,Ke Ma,Qianqian Xu*

Main category: cs.CV

TL;DR: 该论文提出了一种名为BEE的平均教师框架，通过多级一致性正则化（MCR）加速对新域的适应，并通过互补锚点重放（CAR）机制利用历史知识，以解决CTTA中的探索-利用困境，并在实验中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: CTTA旨在将预先在源域上训练好的模型适应到推理过程中持续变化的目標域。理想的CTTA方法应能在快速适应新域（探索）的同时，保留并利用先前遇到的域的知识以应对未来相似的域。然而，现有的CTTA方法在平衡探索和利用方面仍然面临挑战：1)现有方法侧重于根据神经网络的深层输出来调整预测，但域偏移通常影响浅层特征，从深层预测调整浅层特征效率低下，导致探索缓慢；2)单一模型在探索过程中不可避免地会遗忘先前域的知识，导致无法利用历史知识来应对未来相似的域。

Method: "该论文提出了一种平均教师框架，在CTTA过程中平衡探索和利用。为了解决现有方法仅关注调整神经网络深层输出的不足，论文引入了多级一致性正则化（MCR）损失，使学生模型和教师模型的中层特征对齐，从而加速适应当前域。为了解决模型遗忘先前域知识的问题，论文采用了互补锚点重放（CAR）机制，重复使用历史检查点（锚点），为不同域恢复互补知识."

Result: 实验结果表明，该方法在几个基准测试中显著优于最先进的方法，证明了其在CTTA任务中的有效性。

Conclusion: 实验结果表明，该方法在几个基准测试中显著优于最先进的方法，证明了其在CTTA任务中的有效性。

Abstract: Continual Test-Time Adaptation (CTTA) aims to adapt a source pre-trained
model to continually changing target domains during inference. As a fundamental
principle, an ideal CTTA method should rapidly adapt to new domains
(exploration) while retaining and exploiting knowledge from previously
encountered domains to handle similar domains in the future. Despite
significant advances, balancing exploration and exploitation in CTTA is still
challenging: 1) Existing methods focus on adjusting predictions based on
deep-layer outputs of neural networks. However, domain shifts typically affect
shallow features, which are inefficient to be adjusted from deep predictions,
leading to dilatory exploration; 2) A single model inevitably forgets knowledge
of previous domains during the exploration, making it incapable of exploiting
historical knowledge to handle similar future domains. To address these
challenges, this paper proposes a mean teacher framework that strikes an
appropriate Balance between Exploration and Exploitation (BEE) during the CTTA
process. For the former challenge, we introduce a Multi-level Consistency
Regularization (MCR) loss that aligns the intermediate features of the student
and teacher models, accelerating adaptation to the current domain. For the
latter challenge, we employ a Complementary Anchor Replay (CAR) mechanism to
reuse historical checkpoints (anchors), recovering complementary knowledge for
diverse domains. Experiments show that our method significantly outperforms
state-of-the-art methods on several benchmarks, demonstrating its effectiveness
for CTTA tasks.

</details>


### [99] [DyCrowd: Towards Dynamic Crowd Reconstruction from a Large-scene Video](https://arxiv.org/abs/2508.12644)
*Hao Wen,Hongbo Kang,Jian Ma,Jing Huang,Yuanwang Yang,Haozhe Lin,Yu-Kun Lai,Kun Li*

Main category: cs.CV

TL;DR: DyCrowd是首个能从大规模视频中进行时空一致性三维重建的框架，它通过组引导运动优化和VAE运动先验来解决遮挡和时间不一致问题，并提供了一个新的数据集VirtualCrowd。


<details>
  <summary>Details</summary>
Motivation: 当前三维人群重建方法从静态图像出发，缺乏时间一致性且无法有效解决遮挡问题。在大场景监视和人群分析等应用中，需要重建大规模人群的三维信息，包括姿态、位置和形状。

Method: DyCrowd框架采用粗粒度到细粒度、组引导的运动优化策略，并结合了基于VAE的人体运动先验和段级组引导优化，利用集体人群行为来解决长期动态遮挡问题。通过联合优化具有相似运动段的个体运动序列，并结合异步运动一致性（AMC）损失，实现了高质量的非遮挡运动段对遮挡运动段的恢复。

Result: 实验结果表明，DyCrowd在 सबैsub-field中都达到了最先进的性能。此外，研究还贡献了一个名为VirtualCrowd的虚拟基准数据集，用于评估大规模视频中的动态人群重建。

Conclusion: DyCrowd实现了大规模动态人群三维重建的最先进性能。

Abstract: 3D reconstruction of dynamic crowds in large scenes has become increasingly
important for applications such as city surveillance and crowd analysis.
However, current works attempt to reconstruct 3D crowds from a static image,
causing a lack of temporal consistency and inability to alleviate the typical
impact caused by occlusions. In this paper, we propose DyCrowd, the first
framework for spatio-temporally consistent 3D reconstruction of hundreds of
individuals' poses, positions and shapes from a large-scene video. We design a
coarse-to-fine group-guided motion optimization strategy for occlusion-robust
crowd reconstruction in large scenes. To address temporal instability and
severe occlusions, we further incorporate a VAE (Variational Autoencoder)-based
human motion prior along with a segment-level group-guided optimization. The
core of our strategy leverages collective crowd behavior to address long-term
dynamic occlusions. By jointly optimizing the motion sequences of individuals
with similar motion segments and combining this with the proposed Asynchronous
Motion Consistency (AMC) loss, we enable high-quality unoccluded motion
segments to guide the motion recovery of occluded ones, ensuring robust and
plausible motion recovery even in the presence of temporal desynchronization
and rhythmic inconsistencies. Additionally, in order to fill the gap of no
existing well-annotated large-scene video dataset, we contribute a virtual
benchmark dataset, VirtualCrowd, for evaluating dynamic crowd reconstruction
from large-scene videos. Experimental results demonstrate that the proposed
method achieves state-of-the-art performance in the large-scene dynamic crowd
reconstruction task. The code and dataset will be available for research
purposes.

</details>


### [100] [Vision-G1: Towards General Vision Language Reasoning with Multi-Domain Data Curation](https://arxiv.org/abs/2508.12680)
*Yuheng Zha,Kun Zhou,Yujia Wu,Yushu Wang,Jie Feng,Zhi Xu,Shibo Hao,Zhengzhong Liu,Eric P. Xing,Zhiting Hu*

Main category: cs.CV

TL;DR: 为了解决现有视觉语言模型（VLM）在泛化推理能力方面存在的局限性，研究人员构建了一个包含 46 个数据源、8 个维度的全面视觉推理数据集，并提出了一种基于影响函数和难度的样本选择与过滤策略。随后，他们训练了一个名为 Vision-G1 的 VLM，通过多轮强化学习和数据课程来提升其推理能力。该模型在多个基准测试中取得了优于同类模型甚至 GPT-4o 和 Gemini-1.5 Flash 的性能。


<details>
  <summary>Details</summary>
Motivation: 目前的训练方法主要集中在数学和逻辑推理等有限的任务上，导致模型在泛化到更广泛的领域时遇到困难，因为这些领域中可用的、可验证的奖励数据很少。此外，整合来自多个领域的数据也面临挑战。

Method: 提出了一种基于影响函数的样本选择和基于难度的过滤策略，用于从数据集中识别高质量的训练样本。随后，使用多轮强化学习（RL）和数据课程来训练视觉语言模型（VLM），即 Vision-G1，以迭代地提高其视觉推理能力。

Result: 在 8 个维度、涵盖信息图表、数学、空间、跨图像、图形用户界面、医学、常识和一般科学等任务的 46 个数据源中构建了一个全面的、可用于强化学习的视觉推理数据集。所提出的模型 Vision-G1 在各种视觉推理基准测试中取得了最先进的性能。

Conclusion: 该模型在各种视觉推理基准测试中取得了最先进的性能，在类似大小的视觉语言模型（VLM）以及 GPT-4o 和 Gemini-1.5 Flash 等专有模型方面都表现出色。

Abstract: Despite their success, current training pipelines for reasoning VLMs focus on
a limited range of tasks, such as mathematical and logical reasoning. As a
result, these models face difficulties in generalizing their reasoning
capabilities to a wide range of domains, primarily due to the scarcity of
readily available and verifiable reward data beyond these narrowly defined
areas. Moreover, integrating data from multiple domains is challenging, as the
compatibility between domain-specific datasets remains uncertain. To address
these limitations, we build a comprehensive RL-ready visual reasoning dataset
from 46 data sources across 8 dimensions, covering a wide range of tasks such
as infographic, mathematical, spatial, cross-image, graphic user interface,
medical, common sense and general science. We propose an influence function
based data selection and difficulty based filtering strategy to identify
high-quality training samples from this dataset. Subsequently, we train the
VLM, referred to as Vision-G1, using multi-round RL with a data curriculum to
iteratively improve its visual reasoning capabilities. Our model achieves
state-of-the-art performance across various visual reasoning benchmarks,
outperforming similar-sized VLMs and even proprietary models like GPT-4o and
Gemini-1.5 Flash. The model, code and dataset are publicly available at
https://github.com/yuh-zha/Vision-G1.

</details>


### [101] [Stable Diffusion-Based Approach for Human De-Occlusion](https://arxiv.org/abs/2508.12663)
*Seung Young Noh,Ju Yong Chang*

Main category: cs.CV

TL;DR: 一种新的人体去遮挡方法，通过掩码和RGB补全来恢复被遮挡的人体部分。该方法结合了扩散模型、人体先验、关节热图、VQA和CLIP技术，能够处理严重遮挡，并在掩码和RGB补全方面优于现有方法，同时还能提升下游任务的表现。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在准确预测被遮挡区域方面仍然是一个挑战。本研究专注于人体去遮挡，特别是恢复被遮挡的身体结构和外观。

Method: 该方法将任务分解为两个阶段：掩码补全和RGB补全。第一阶段利用基于扩散的人体先验提供全面的身体结构表示，并结合显式的空间线索（遮挡关节热图）来提供缺失区域的信息。然后，重建的非模态掩码作为第二阶段的条件输入，指导模型进行RGB重建。为了增强RGB生成，我们还融入了使用视觉问答（VQA）模型提取并通过CLIP编码器编码的人体特定文本特征。RGB补全使用Stable Diffusion完成，并通过微调解码器来缓解因潜在空间转换导致的可见区域像素级退化。

Result: 该方法有效重建了人体外观，即使在严重遮挡的情况下也能实现，并且在掩码和RGB补全方面持续优于现有方法。

Conclusion: 该方法在严重遮挡下能有效重建人体外观，并在掩码和RGB补全方面持续优于现有方法。此外，生成的去遮挡图像能提升下游以人为中心的任务的表现，例如2D姿态估计和3D人体重建。

Abstract: Humans can infer the missing parts of an occluded object by leveraging prior
knowledge and visible cues. However, enabling deep learning models to
accurately predict such occluded regions remains a challenging task.
De-occlusion addresses this problem by reconstructing both the mask and RGB
appearance. In this work, we focus on human de-occlusion, specifically
targeting the recovery of occluded body structures and appearances. Our
approach decomposes the task into two stages: mask completion and RGB
completion. The first stage leverages a diffusion-based human body prior to
provide a comprehensive representation of body structure, combined with
occluded joint heatmaps that offer explicit spatial cues about missing regions.
The reconstructed amodal mask then serves as a conditioning input for the
second stage, guiding the model on which areas require RGB reconstruction. To
further enhance RGB generation, we incorporate human-specific textual features
derived using a visual question answering (VQA) model and encoded via a CLIP
encoder. RGB completion is performed using Stable Diffusion, with decoder
fine-tuning applied to mitigate pixel-level degradation in visible regions -- a
known limitation of prior diffusion-based de-occlusion methods caused by latent
space transformations. Our method effectively reconstructs human appearances
even under severe occlusions and consistently outperforms existing methods in
both mask and RGB completion. Moreover, the de-occluded images generated by our
approach can improve the performance of downstream human-centric tasks, such as
2D pose estimation and 3D human reconstruction. The code will be made publicly
available.

</details>


### [102] [WP-CLIP: Leveraging CLIP to Predict Wölfflin's Principles in Visual Art](https://arxiv.org/abs/2508.12668)
*Abhijay Ghildyal,Li-Yun Wang,Feng Liu*

Main category: cs.CV

TL;DR: 本研究旨在探索CLIP模型在预测W"olfflin's艺术风格原则方面的能力。研究发现，未经微调的CLIP模型无法捕捉这些细微差别。通过在标注数据上进行微调，开发出WP-CLIP模型，该模型能够预测这些原则，并在不同艺术风格的数据集上表现良好，证明了VLMs在艺术分析中的潜力。


<details>
  <summary>Details</summary>
Motivation: W"olfflin's的五项原则为形式分析提供了结构化方法，但现有指标无法有效预测所有原则。计算评估绘画的视觉方面需要能够解释颜色、构图和主题选择等关键元素的度量。本研究旨在探索视觉语言模型（VLMs）如CLIP在理解和预测W"olfflin's原则方面的潜力。

Method: 使用CLIP模型作为基础，并针对标注艺术图像数据集进行微调，以预测W"olfflin's的五项原则得分。对WP-CLIP模型在GAN生成绘画和Pandora-18K艺术数据集上进行了评估。

Result: WP-CLIP模型能够成功预测W"olfflin's的五项原则，并在不同的艺术数据集上展现出良好的泛化能力。

Conclusion: CLIP模型本身无法捕捉W"olfflin's艺术风格原则的细微差别，但通过在标注艺术图像数据集上进行微调，可以开发出能够预测这些原则的WP-CLIP模型。该模型在GAN生成绘画和Pandora-18K艺术数据集上表现出跨不同艺术风格的泛化能力，表明视觉语言模型在自动化艺术分析方面具有潜力。

Abstract: W\"olfflin's five principles offer a structured approach to analyzing
stylistic variations for formal analysis. However, no existing metric
effectively predicts all five principles in visual art. Computationally
evaluating the visual aspects of a painting requires a metric that can
interpret key elements such as color, composition, and thematic choices. Recent
advancements in vision-language models (VLMs) have demonstrated their ability
to evaluate abstract image attributes, making them promising candidates for
this task. In this work, we investigate whether CLIP, pre-trained on
large-scale data, can understand and predict W\"olfflin's principles. Our
findings indicate that it does not inherently capture such nuanced stylistic
elements. To address this, we fine-tune CLIP on annotated datasets of real art
images to predict a score for each principle. We evaluate our model, WP-CLIP,
on GAN-generated paintings and the Pandora-18K art dataset, demonstrating its
ability to generalize across diverse artistic styles. Our results highlight the
potential of VLMs for automated art analysis.

</details>


### [103] [Refine-and-Contrast: Adaptive Instance-Aware BEV Representations for Multi-UAV Collaborative Object Detection](https://arxiv.org/abs/2508.12684)
*Zhongyao Li,Peirui Cheng,Liangjin Zhao,Chen Chen,Yundu Li,Zhechao Wang,Xue Yang,Xian Sun,Zhirui Wang*

Main category: cs.CV

TL;DR: AdaBEV通过细化和对比学习，在资源受限的UAV平台上实现了高效的3D检测，并在低分辨率下表现出色。


<details>
  <summary>Details</summary>
Motivation: 多UAV协同3D检测虽然在覆盖范围和遮挡处理方面具有优势，但对资源受限的UAV平台带来了计算挑战。因此，需要一种能够在资源受限的情况下提高检测精度的有效方法。

Method: AdaBEV通过一个包含“细化”和“对比”范式的框架，学习自适应的、实例感知的BEV表示。具体来说，它引入了由2D监督和空间细分驱动的“框引导细化模块”（BG-RM），用于细化与前景实例相关的BEV网格；以及在BEV空间中通过对比学习来增强前景和背景特征分离的“实例-背景对比学习”（IBCL）。

Result: AdaBEV在低分辨率下表现优于现有方法，并且在保持低分辨率BEV输入和低计算开销的同时，实现了接近上限的性能。

Conclusion: AdaBEV在Air-Co-Pred数据集上进行了广泛的实验，证明了其在不同模型规模下具有优越的精度-计算权衡。在低分辨率下，AdaBEV的表现优于其他最先进的方法，同时保持了低分辨率的BEV输入和可忽略的开销，并接近了上限性能。

Abstract: Multi-UAV collaborative 3D detection enables accurate and robust perception
by fusing multi-view observations from aerial platforms, offering significant
advantages in coverage and occlusion handling, while posing new challenges for
computation on resource-constrained UAV platforms. In this paper, we present
AdaBEV, a novel framework that learns adaptive instance-aware BEV
representations through a refine-and-contrast paradigm. Unlike existing methods
that treat all BEV grids equally, AdaBEV introduces a Box-Guided Refinement
Module (BG-RM) and an Instance-Background Contrastive Learning (IBCL) to
enhance semantic awareness and feature discriminability. BG-RM refines only BEV
grids associated with foreground instances using 2D supervision and spatial
subdivision, while IBCL promotes stronger separation between foreground and
background features via contrastive learning in BEV space. Extensive
experiments on the Air-Co-Pred dataset demonstrate that AdaBEV achieves
superior accuracy-computation trade-offs across model scales, outperforming
other state-of-the-art methods at low resolutions and approaching upper bound
performance while maintaining low-resolution BEV inputs and negligible
overhead.

</details>


### [104] [TTA-DAME: Test-Time Adaptation with Domain Augmentation and Model Ensemble for Dynamic Driving Conditions](https://arxiv.org/abs/2508.12690)
*Dongjae Jeon,Taeheon Kim,Seongwon Cho,Minhyuk Seo,Jonghyun Choi*

Main category: cs.CV

TL;DR: TTA-DAME通过数据增强和域检测器技术，有效解决了驾驶场景中的天气变化对模型性能的影响，并在SHIFT Benchmark上取得了良好效果。


<details>
  <summary>Details</summary>
Motivation: 为了解决测试时域适应（TTA）在面对如真实驾驶场景中频繁出现的天气域偏移等动态变化时的挑战，需要模型能够动态适应并优化表现。

Method: TTA-DAME方法结合了源域数据增强到目标域的技术，并引入了域判别器和专门的域检测器来处理剧烈的域偏移（特别是昼夜转换）。此外，还采用了训练多个检测器并通过非极大值抑制（NMS）整合其预测的方法来进一步提高适应性。

Result: 实验结果表明，TTA-DAME方法在SHIFT Benchmark上展示了显著的性能提升，证明了其有效性。

Conclusion: TTA-DAME通过结合源域数据增强、域判别器、特定域检测器以及多检测器融合，在面对包括昼夜转换在内的恶劣天气域偏移时，显著提升了模型在SHIFT Benchmark上的性能。

Abstract: Test-time Adaptation (TTA) poses a challenge, requiring models to dynamically
adapt and perform optimally on shifting target domains. This task is
particularly emphasized in real-world driving scenes, where weather domain
shifts occur frequently. To address such dynamic changes, our proposed method,
TTA-DAME, leverages source domain data augmentation into target domains.
Additionally, we introduce a domain discriminator and a specialized domain
detector to mitigate drastic domain shifts, especially from daytime to
nighttime conditions. To further improve adaptability, we train multiple
detectors and consolidate their predictions through Non-Maximum Suppression
(NMS). Our empirical validation demonstrates the effectiveness of our method,
showing significant performance enhancements on the SHIFT Benchmark.

</details>


### [105] [Multi-Level Knowledge Distillation and Dynamic Self-Supervised Learning for Continual Learning](https://arxiv.org/abs/2508.12692)
*Taeheon Kim,San Kim,Minhyuk Seo,Dongjae Jeon,Wonje Jeong,Jonghyun Choi*

Main category: cs.CV

TL;DR: CIR场景比传统类别增量学习更真实，因为它允许先前训练过的类别在未来任务中重复出现。本研究提出了多级知识蒸馏（MLKD）和动态监督损失（SSL）两个组件，利用无标签数据来提高模型在CIR场景下的稳定性和可塑性，并在CVPR第五届CLVISION挑战赛中取得了第二名的成绩。


<details>
  <summary>Details</summary>
Motivation: 传统的类别增量学习场景假设每个任务只包含新的、未见过的类别，但这在现实中并不常见。更现实的情况是，先前训练过的类别会反复出现在未来的任务中，这被称为类别增量与重复（CIR）。CIR场景的一个关键特点是能够访问大量外部无标签数据（如互联网数据），这为提升模型性能提供了机会。因此，本研究的动机是探索如何有效利用这些无标签数据，以在CIR场景下同时保持模型的稳定性和可塑性，即在学习新知识的同时保留旧知识。

Method: 本文提出了一种名为类别增量与重复（CIR）的场景，该场景模拟了在未来任务中重复引入先前训练过的类别的情况。为了解决这一场景，研究者提出了两个关键组件：1. 多级知识蒸馏（MLKD）：从多个先前模型中跨多个视角（包括特征和logits）蒸馏知识，以维护先前知识的多样性。2. 动态监督损失（SSL）：利用无标签数据加速新类的学习，并通过动态加权来保持训练重点在主要任务上。

Result: 所提出的多级知识蒸馏（MLKD）和动态监督损失（SSL）组件显著提高了模型在CIR设置下的性能。具体来说，该方法在CVPR第五届CLVISION挑战赛中取得了第二名的成绩。

Conclusion: CIR假设我们可以轻松访问来自互联网等外部来源的大量无标签数据。因此，我们提出了两种有效利用无标签数据来确保CIR设置中训练模型的稳定性和可塑性的组件。首先，我们引入了多级知识蒸馏（MLKD），它从多个先前模型中跨多个视角（包括特征和logits）蒸馏知识，以便模型能够维护更多各种先前知识。此外，我们实现了动态监督损失（SSL）来利用无标签数据，加速新类的学习，同时SSL的动态加权使培训的重点保持在主要任务上。我们提出的两个组件都显著提高了CIR设置下的性能，在CVPR第五届CLVISION挑战赛中获得第二名。

Abstract: Class-incremental with repetition (CIR), where previously trained classes
repeatedly introduced in future tasks, is a more realistic scenario than the
traditional class incremental setup, which assumes that each task contains
unseen classes. CIR assumes that we can easily access abundant unlabeled data
from external sources, such as the Internet. Therefore, we propose two
components that efficiently use the unlabeled data to ensure the high stability
and the plasticity of models trained in CIR setup. First, we introduce
multi-level knowledge distillation (MLKD) that distills knowledge from multiple
previous models across multiple perspectives, including features and logits, so
the model can maintain much various previous knowledge. Moreover, we implement
dynamic self-supervised loss (SSL) to utilize the unlabeled data that
accelerates the learning of new classes, while dynamic weighting of SSL keeps
the focus of training to the primary task. Both of our proposed components
significantly improve the performance in CIR setup, achieving 2nd place in the
CVPR 5th CLVISION Challenge.

</details>


### [106] [Neural Rendering for Sensor Adaptation in 3D Object Detection](https://arxiv.org/abs/2508.12695)
*Felix Embacher,David Holtz,Jonas Uhrig,Marius Cordts,Markus Enzweiler*

Main category: cs.CV

TL;DR: 研究了自动驾驶汽车中由不同摄像头传感器设置引起的跨传感器域差距问题，并提出了一种名为CamShift的数据集和一种基于神经渲染的数据驱动传感器适应方法来解决此问题。该方法提高了3D对象检测器的性能，并减少了对新数据收集的需求。


<details>
  <summary>Details</summary>
Motivation: 由于不同车型对摄像头传感器的放置限制不同，导致自动驾驶汽车的摄像头传感器设置各不相同。在一种传感器设置上训练的感知模型在另一种不同的传感器设置上进行评估时，会出现跨传感器域差距，从而导致准确性下降。

Method: 提出了一种名为CamShift的数据集，该数据集受nuScenes启发，并在CARLA中创建，旨在模拟不同车辆（小型车和SUV）之间的跨传感器域差距。研究了这种跨传感器域差距对最先进的3D对象检测器的影响，并展示了基于密集鸟瞰图（BEV）表示和后向投影（如BEVFormer）的模型架构在不同传感器配置下具有最强的鲁棒性。

Result: 在CamShift数据集上，展示了显著的跨传感器性能下降。研究结果表明，基于密集BEV表示和后向投影的模型架构（如BEVFormer）对变化的传感器配置具有最强的鲁棒性。所提出的数据驱动的传感器适应方法通过神经渲染，在所有研究的3D对象检测器上均提高了性能，大大减小了跨传感器域差距，并提高了数据的可重用性。

Conclusion: 提出了一种基于神经渲染的数据驱动的传感器适应方法，可以转换整个数据集以匹配不同的摄像头传感器设置，从而在所有研究的3D对象检测器上提高了性能，并大大减小了跨传感器域差距。

Abstract: Autonomous vehicles often have varying camera sensor setups, which is
inevitable due to restricted placement options for different vehicle types.
Training a perception model on one particular setup and evaluating it on a new,
different sensor setup reveals the so-called cross-sensor domain gap, typically
leading to a degradation in accuracy. In this paper, we investigate the impact
of the cross-sensor domain gap on state-of-the-art 3D object detectors. To this
end, we introduce CamShift, a dataset inspired by nuScenes and created in CARLA
to specifically simulate the domain gap between subcompact vehicles and sport
utility vehicles (SUVs). Using CamShift, we demonstrate significant
cross-sensor performance degradation, identify robustness dependencies on model
architecture, and propose a data-driven solution to mitigate the effect. On the
one hand, we show that model architectures based on a dense Bird's Eye View
(BEV) representation with backward projection, such as BEVFormer, are the most
robust against varying sensor configurations. On the other hand, we propose a
novel data-driven sensor adaptation pipeline based on neural rendering, which
can transform entire datasets to match different camera sensor setups. Applying
this approach improves performance across all investigated 3D object detectors,
mitigating the cross-sensor domain gap by a large margin and reducing the need
for new data collection by enabling efficient data reusability across vehicles
with different sensor setups. The CamShift dataset and the sensor adaptation
benchmark are available at https://dmholtz.github.io/camshift/.

</details>


### [107] [Drifting Away from Truth: GenAI-Driven News Diversity Challenges LVLM-Based Misinformation Detection](https://arxiv.org/abs/2508.12711)
*Fanxiao Li,Jiaying Wu,Tingchao Fu,Yunyun Dong,Bingbing Song,Wei Zhou*

Main category: cs.CV

TL;DR: 生成式AI导致的新闻多样性破坏了现有的多模态错误信息检测方法，需要开发更鲁棒的解决方案。


<details>
  <summary>Details</summary>
Motivation: 生成式AI（GenAI）工具的发展带来了新闻多样性的新挑战，这种多样性 characterized by highly varied and complex content. 这种多样性会导致多层次漂移，包括模型层面的误感知漂移和证据层面的漂移，从而严重降低当前基于LVLM的MMD系统的鲁棒性。

Method: 本研究引入了DriftBench，一个包含16,000个新闻实例的大型基准测试，涵盖六种多样化类别，用于系统地研究生成式AI驱动的新闻多样性对MMD系统的影响。设计了三个评估任务：在多层次漂移下的真实性验证鲁棒性、对GenAI生成的对抗性证据污染的敏感性以及跨不同输入的推理一致性分析。

Result: 实验结果表明，在DriftBench基准测试上，六种最先进的基于LVLM的检测器性能显著下降（平均F1分数下降14.8%），推理轨迹越来越不稳定，并且在对抗性证据注入下出现更严重的失败。这些发现揭示了现有MMD系统的基本脆弱性。

Conclusion: 现有的基于大型视觉语言模型（LVLM）的多模态错误信息检测（MMD）系统在生成式人工智能（GenAI）时代面临严峻挑战，其鲁棒性和稳定性受到严重影响。需要开发更具韧性的方法来应对这一问题。

Abstract: The proliferation of multimodal misinformation poses growing threats to
public discourse and societal trust. While Large Vision-Language Models (LVLMs)
have enabled recent progress in multimodal misinformation detection (MMD), the
rise of generative AI (GenAI) tools introduces a new challenge: GenAI-driven
news diversity, characterized by highly varied and complex content. We show
that this diversity induces multi-level drift, comprising (1) model-level
misperception drift, where stylistic variations disrupt a model's internal
reasoning, and (2) evidence-level drift, where expression diversity degrades
the quality or relevance of retrieved external evidence. These drifts
significantly degrade the robustness of current LVLM-based MMD systems. To
systematically study this problem, we introduce DriftBench, a large-scale
benchmark comprising 16,000 news instances across six categories of
diversification. We design three evaluation tasks: (1) robustness of truth
verification under multi-level drift; (2) susceptibility to adversarial
evidence contamination generated by GenAI; and (3) analysis of reasoning
consistency across diverse inputs. Experiments with six state-of-the-art
LVLM-based detectors show substantial performance drops (average F1 -14.8%) and
increasingly unstable reasoning traces, with even more severe failures under
adversarial evidence injection. Our findings uncover fundamental
vulnerabilities in existing MMD systems and suggest an urgent need for more
resilient approaches in the GenAI era.

</details>


### [108] [Real-Time Sign Language Gestures to Speech Transcription using Deep Learning](https://arxiv.org/abs/2508.12713)
*Brandone Fonya*

Main category: cs.CV

TL;DR: 本项目开发了一种基于CNN的手语翻译实时辅助技术，能够将手语转化为语音，为听障人士提供交流便利。


<details>
  <summary>Details</summary>
Motivation: 为了克服沟通障碍，为有听觉和言语障碍的人士提供一种辅助技术，使他们能够更有效地与他人互动，提高自主性和社会融入度。

Method: 本项目采用卷积神经网络（CNN）对摄像头捕捉的实时手语进行训练和分类，并结合文本到语音合成技术，实现了手语到语音的实时翻译。

Result: 实验证明，该系统具有较高的模型准确性和强大的实时性能，能够流畅地将手语转化为文本和语音，尽管存在一些延迟，但具有实际应用价值。

Conclusion: 该项目开发的实时辅助技术能够通过摄像头捕捉手势，利用CNN和ASL数据集进行实时翻译，并将翻译结果合成为语音，从而为有听觉和言语障碍的人士提供了一种实用的交流辅助工具。

Abstract: Communication barriers pose significant challenges for individuals with
hearing and speech impairments, often limiting their ability to effectively
interact in everyday environments. This project introduces a real-time
assistive technology solution that leverages advanced deep learning techniques
to translate sign language gestures into textual and audible speech. By
employing convolution neural networks (CNN) trained on the Sign Language MNIST
dataset, the system accurately classifies hand gestures captured live via
webcam. Detected gestures are instantaneously translated into their
corresponding meanings and transcribed into spoken language using
text-to-speech synthesis, thus facilitating seamless communication.
Comprehensive experiments demonstrate high model accuracy and robust real-time
performance with some latency, highlighting the system's practical
applicability as an accessible, reliable, and user-friendly tool for enhancing
the autonomy and integration of sign language users in diverse social settings.

</details>


### [109] [Single-Reference Text-to-Image Manipulation with Dual Contrastive Denoising Score](https://arxiv.org/abs/2508.12718)
*Syed Muhmmad Israr,Feng Zhao*

Main category: cs.CV

TL;DR: 提出了一种新的图像编辑框架，该框架使用文本到图像扩散模型，通过双对比损失和自注意力机制，实现了灵活的内容修改和结构保持。


<details>
  <summary>Details</summary>
Motivation: 为了解决在真实图像编辑中，用户难以生成精确描述输入图像细节的文本提示，以及现有模型在编辑时会改变不期望区域的内容的挑战。

Method: 提出了一种简单而强大的框架，称为双对比去噪分数，该框架利用了文本到图像扩散模型的丰富生成先验。通过引入一种简单的双对比损失，并利用潜在扩散模型自注意力层的中间表示中的大量空间信息，而无需依赖辅助网络。

Result: 实现了灵活的内容修改和输入输出图像之间的结构保持，以及零次图像到图像的翻译。

Conclusion: 该方法在保持直接利用预训练文本到图像扩散模型的能力的同时，在真实图像编辑方面优于现有方法。

Abstract: Large-scale text-to-image generative models have shown remarkable ability to
synthesize diverse and high-quality images. However, it is still challenging to
directly apply these models for editing real images for two reasons. First, it
is difficult for users to come up with a perfect text prompt that accurately
describes every visual detail in the input image. Second, while existing models
can introduce desirable changes in certain regions, they often dramatically
alter the input content and introduce unexpected changes in unwanted regions.
To address these challenges, we present Dual Contrastive Denoising Score, a
simple yet powerful framework that leverages the rich generative prior of
text-to-image diffusion models. Inspired by contrastive learning approaches for
unpaired image-to-image translation, we introduce a straightforward dual
contrastive loss within the proposed framework. Our approach utilizes the
extensive spatial information from the intermediate representations of the
self-attention layers in latent diffusion models without depending on auxiliary
networks. Our method achieves both flexible content modification and structure
preservation between input and output images, as well as zero-shot
image-to-image translation. Through extensive experiments, we show that our
approach outperforms existing methods in real image editing while maintaining
the capability to directly utilize pretrained text-to-image diffusion models
without further training.

</details>


### [110] [Quantifying and Alleviating Co-Adaptation in Sparse-View 3D Gaussian Splatting](https://arxiv.org/abs/2508.12720)
*Kangjie Chen,Yingji Zhong,Zhihao Li,Jiaqi Lin,Youyu Chen,Minghan Qin,Haoqian Wang*

Main category: cs.CV

TL;DR: 3DGS在稀疏视角下存在伪影，是由于高斯之间过度纠缠。本文提出CA度量来量化纠缠，并提出随机高斯丢弃和不透明度噪声注入两种策略来缓解此问题，实验证明有效。


<details>
  <summary>Details</summary>
Motivation: 3DGS在稀疏视角下会产生外观伪影，原因是优化的Gaussians之间过度纠缠，导致忽视了场景的真实外观分布。

Method: 提出了一种称为“协同适应得分（CA）”的度量标准，通过计算同一视点在不同高斯子集渲染中的逐像素方差来量化高斯之间的纠缠程度。

Result: 分析表明，随着训练视点数量的增加，协同适应程度自然得到缓解。提出的两种策略能够有效缓解协同适应问题。

Conclusion: 该研究提出了两种轻量级策略（随机高斯丢弃和不透明度乘性噪声注入）来缓解稀疏视角3DGS中的外观伪影，并通过实验验证了其有效性。

Abstract: 3D Gaussian Splatting (3DGS) has demonstrated impressive performance in novel
view synthesis under dense-view settings. However, in sparse-view scenarios,
despite the realistic renderings in training views, 3DGS occasionally manifests
appearance artifacts in novel views. This paper investigates the appearance
artifacts in sparse-view 3DGS and uncovers a core limitation of current
approaches: the optimized Gaussians are overly-entangled with one another to
aggressively fit the training views, which leads to a neglect of the real
appearance distribution of the underlying scene and results in appearance
artifacts in novel views. The analysis is based on a proposed metric, termed
Co-Adaptation Score (CA), which quantifies the entanglement among Gaussians,
i.e., co-adaptation, by computing the pixel-wise variance across multiple
renderings of the same viewpoint, with different random subsets of Gaussians.
The analysis reveals that the degree of co-adaptation is naturally alleviated
as the number of training views increases. Based on the analysis, we propose
two lightweight strategies to explicitly mitigate the co-adaptation in
sparse-view 3DGS: (1) random gaussian dropout; (2) multiplicative noise
injection to the opacity. Both strategies are designed to be plug-and-play, and
their effectiveness is validated across various methods and benchmarks. We hope
that our insights into the co-adaptation effect will inspire the community to
achieve a more comprehensive understanding of sparse-view 3DGS.

</details>


### [111] [Frequency-Driven Inverse Kernel Prediction for Single Image Defocus Deblurring](https://arxiv.org/abs/2508.12736)
*Ying Zhang,Xiongxin Tang,Chongyi Li,Qiao Chen,Yuquan Wu*

Main category: cs.CV

TL;DR: 提出了一种新的去模糊方法FDIKP，通过结合频域信息和改进的核估计与去卷积策略，在模糊图像恢复方面取得了更好的效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在模糊区域性能下降，因为局部高频细节缺失，难以进行核估计。

Method: 提出了一种名为“频率驱动逆核预测”（FDIKP）的网络，该网络结合了频域表示来增强核建模中的结构可识别性。设计了一种“双分支逆核预测”（DIKP）策略，以提高核估计的准确性并保持稳定性。引入“位置自适应卷积”（PAC）来增强去卷积过程的适应性。提出了一种“双域尺度递归模块”（DSRM）来融合去卷积结果并逐步提高去模糊质量。

Result: 所提出的方法在大量实验中表现优于现有方法。

Conclusion: 该方法在模糊区域的性能优于现有方法。

Abstract: Single image defocus deblurring aims to recover an all-in-focus image from a
defocus counterpart, where accurately modeling spatially varying blur kernels
remains a key challenge. Most existing methods rely on spatial features for
kernel estimation, but their performance degrades in severely blurry regions
where local high-frequency details are missing. To address this, we propose a
Frequency-Driven Inverse Kernel Prediction network (FDIKP) that incorporates
frequency-domain representations to enhance structural identifiability in
kernel modeling. Given the superior discriminative capability of the frequency
domain for blur modeling, we design a Dual-Branch Inverse Kernel Prediction
(DIKP) strategy that improves the accuracy of kernel estimation while
maintaining stability. Moreover, considering the limited number of predicted
inverse kernels, we introduce a Position Adaptive Convolution (PAC) to enhance
the adaptability of the deconvolution process. Finally, we propose a
Dual-Domain Scale Recurrent Module (DSRM) to fuse deconvolution results and
progressively improve deblurring quality from coarse to fine. Extensive
experiments demonstrate that our method outperforms existing approaches. Code
will be made publicly available.

</details>


### [112] [DCSCR: A Class-Specific Collaborative Representation based Network for Image Set Classification](https://arxiv.org/abs/2508.12745)
*Xizhan Gao,Wei Hu*

Main category: cs.CV

TL;DR: 本文提出了一种名为DCSCR的新型小样本图像集分类方法，该方法结合了深度学习和协同表示，能够同时学习帧级别和概念级别特征，并自适应地度量集合间的距离，在小样本分类任务上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有传统ISC方法基于原始像素特征进行分类，忽略了特征学习的重要性。现有深度ISC方法虽然能学习深度特征，但在度量集距离时无法自适应地调整特征，导致在小样本ISC中的性能有限。为了解决这些问题，本文结合了传统ISC方法和深度模型。

Method: 本文提出了一种名为深度类别特定协同表示（DCSCR）网络的端到端框架，该框架结合了传统ISC方法和深度模型，以同时学习每个图像集的帧级别和概念级别特征表示以及不同集之间的距离相似性。具体来说，DCSCR包括一个全卷积深度特征提取模块、一个全局特征学习模块和一个基于类别特定协同表示的度量学习模块。深度特征提取和全局特征学习模块用于学习（局部和全局）帧级别特征表示，而基于类别特定协同表示的度量学习模块则用于通过开发新的基于CSCR的对比损失函数来适应性地学习每个图像集的概念级别特征表示，从而获得不同集之间的距离相似性。

Result: DCSCR能够同时学习帧级别和概念级别特征表示，并获得集合之间的距离相似性。与最先进的ISC算法相比，该方法在性能上更优。

Conclusion: 所提出的DCSCR方法在几个著名的小样本图像集分类数据集上进行了广泛的实验，结果证明了与一些最先进的图像集分类算法相比，该方法的有效性。

Abstract: Image set classification (ISC), which can be viewed as a task of comparing
similarities between sets consisting of unordered heterogeneous images with
variable quantities and qualities, has attracted growing research attention in
recent years. How to learn effective feature representations and how to explore
the similarities between different image sets are two key yet challenging
issues in this field. However, existing traditional ISC methods classify image
sets based on raw pixel features, ignoring the importance of feature learning.
Existing deep ISC methods can learn deep features, but they fail to adaptively
adjust the features when measuring set distances, resulting in limited
performance in few-shot ISC. To address the above issues, this paper combines
traditional ISC methods with deep models and proposes a novel few-shot ISC
approach called Deep Class-specific Collaborative Representation (DCSCR)
network to simultaneously learn the frame- and concept-level feature
representations of each image set and the distance similarities between
different sets. Specifically, DCSCR consists of a fully convolutional deep
feature extractor module, a global feature learning module, and a
class-specific collaborative representation-based metric learning module. The
deep feature extractor and global feature learning modules are used to learn
(local and global) frame-level feature representations, while the
class-specific collaborative representation-based metric learning module is
exploit to adaptively learn the concept-level feature representation of each
image set and thus obtain the distance similarities between different sets by
developing a new CSCR-based contrastive loss function. Extensive experiments on
several well-known few-shot ISC datasets demonstrate the effectiveness of the
proposed method compared with some state-of-the-art image set classification
algorithms.

</details>


### [113] [D2-Mamba: Dual-Scale Fusion and Dual-Path Scanning with SSMs for Shadow Removal](https://arxiv.org/abs/2508.12750)
*Linhao Li,Boya Jin,Zizhe Li,Lanqing Guo,Hao Cheng,Bo Li,Yongfeng Dong*

Main category: cs.CV

TL;DR: 提出了一种新的基于Mamba的网络，利用双尺度融合和双路径扫描来有效去除阴影，并在基准测试中取得了优于现有方法的成果。


<details>
  <summary>Details</summary>
Motivation: 阴影去除旨在恢复被阴影部分降级的图像，这种降级是空间局部和不均匀的。与假设全局降级的通用恢复任务不同，阴影去除可以利用来自非阴影区域的丰富信息进行指导。然而，校正阴影区域所需的变换通常与光照良好区域的变换显著不同，这使得应用统一的校正策略具有挑战性。这就需要有效整合非局部上下文线索和区域特定变换的自适应建模。

Method: 提出了一种新颖的基于Mamba的网络，该网络具有双尺度融合和双路径扫描功能，可根据区域间的变换相似性选择性地传播上下文信息。具体来说，提出的双尺度融合Mamba块（DFMB）通过融合原始特征和低分辨率特征来增强多尺度特征表示，有效减少了边界伪影。双路径Mamba组（DPMG）通过水平扫描捕获全局特征，并结合掩模感知自适应扫描策略，提高了结构连续性和细粒度区域建模。

Result: 所提出的方法在阴影去除基准测试中显著优于现有的最先进方法。

Conclusion: 实验结果表明，所提出的方法在阴影去除基准测试中显著优于现有的最先进方法。

Abstract: Shadow removal aims to restore images that are partially degraded by shadows,
where the degradation is spatially localized and non-uniform. Unlike general
restoration tasks that assume global degradation, shadow removal can leverage
abundant information from non-shadow regions for guidance. However, the
transformation required to correct shadowed areas often differs significantly
from that of well-lit regions, making it challenging to apply uniform
correction strategies. This necessitates the effective integration of non-local
contextual cues and adaptive modeling of region-specific transformations. To
this end, we propose a novel Mamba-based network featuring dual-scale fusion
and dual-path scanning to selectively propagate contextual information based on
transformation similarity across regions. Specifically, the proposed Dual-Scale
Fusion Mamba Block (DFMB) enhances multi-scale feature representation by fusing
original features with low-resolution features, effectively reducing boundary
artifacts. The Dual-Path Mamba Group (DPMG) captures global features via
horizontal scanning and incorporates a mask-aware adaptive scanning strategy,
which improves structural continuity and fine-grained region modeling.
Experimental results demonstrate that our method significantly outperforms
existing state-of-the-art approaches on shadow removal benchmarks.

</details>


### [114] [CLAIRE-DSA: Fluoroscopic Image Classification for Quality Assurance of Computer Vision Pipelines in Acute Ischemic Stroke](https://arxiv.org/abs/2508.12755)
*Cristo J. van den Berg,Frank G. te Nijenhuis,Mirre J. Blaauboer,Daan T. W. van Erp,Carlijn M. Keppels,Matthijs van der Sluijs,Bob Roozenbeek,Wim van Zwam,Sandra Cornelissen,Danny Ruijters,Ruisheng Su,Theo van Walsum*

Main category: cs.CV

TL;DR: CLAIRE-DSA框架利用深度学习技术，能够对机械取栓治疗急性缺血性卒中患者的DSA图像进行质量分类和评估，从而提高下游任务的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 计算机视觉模型在机械取栓（MT）辅助治疗急性缺血性卒中（AIS）方面有潜力，但图像质量差会影响其性能。本研究旨在提出CLAIRE-DSA框架，以改善MT图像的质量控制和工作流程优化。

Method: CLAIRE-DSA是一个基于深度学习的框架，利用预训练的ResNet骨干模型，对9种图像属性（如造影剂存在、投影角度、运动伪影严重程度）进行预测。模型在包含1,758个最小强度投影（MinIPs）的标注数据集上进行了训练。

Result: CLAIRE-DSA 在所有标签上均表现出卓越的性能，ROC-AUC 范围为 0.91 至 0.98，精确率范围为 0.70 至 1.00。通过过滤低质量图像并比较过滤前后分割性能，CLAIRE-DSA 的图像筛选能力得到验证，分割成功率从 42% 提高到 69% (p < 0.001)。

Conclusion: CLAIRE-DSA 在DSA系列图像中自动准确分类图像属性方面具有巨大潜力，可支持急性缺血性卒中患者的临床和研究应用中的图像标注和质量控制。

Abstract: Computer vision models can be used to assist during mechanical thrombectomy
(MT) for acute ischemic stroke (AIS), but poor image quality often degrades
performance. This work presents CLAIRE-DSA, a deep learning--based framework
designed to categorize key image properties in minimum intensity projections
(MinIPs) acquired during MT for AIS, supporting downstream quality control and
workflow optimization. CLAIRE-DSA uses pre-trained ResNet backbone models,
fine-tuned to predict nine image properties (e.g., presence of contrast,
projection angle, motion artefact severity). Separate classifiers were trained
on an annotated dataset containing $1,758$ fluoroscopic MinIPs. The model
achieved excellent performance on all labels, with ROC-AUC ranging from $0.91$
to $0.98$, and precision ranging from $0.70$ to $1.00$. The ability of
CLAIRE-DSA to identify suitable images was evaluated on a segmentation task by
filtering poor quality images and comparing segmentation performance on
filtered and unfiltered datasets. Segmentation success rate increased from
$42%$ to $69%$, $p < 0.001$. CLAIRE-DSA demonstrates strong potential as an
automated tool for accurately classifying image properties in DSA series of
acute ischemic stroke patients, supporting image annotation and quality control
in clinical and research applications. Source code is available at
https://gitlab.com/icai-stroke-lab/wp3_neurointerventional_ai/claire-dsa.

</details>


### [115] [Harnessing Group-Oriented Consistency Constraints for Semi-Supervised Semantic Segmentation in CdZnTe Semiconductors](https://arxiv.org/abs/2508.12766)
*Peihao Li,Yan Fang,Man Liu,Huihui Bai,Anhong Wang,Yunchao Wei,Yao Zhao*

Main category: cs.CV

TL;DR: 针对CdZnTe图像分割中存在的低对比度缺陷边界和“多对一”标注关系问题，提出ICAF框架。该框架通过组内一致性增强，利用IVS建立基线，并结合PCN（包括VAM和VCM）来提升分割精度。实验结果表明，ICAF在仅有少量标注数据的情况下，显著提高了分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有的半监督语义分割（SSS）方法在处理CdZnTe图像时表现不佳，因为这些图像的缺陷边界对比度低，需要交叉引用多个视图进行标注，形成了“多对一”的独特关系。而现有的SSS方法受限于“一对一”的关系，容易在低对比度区域积累误差并加剧确认偏差。

Method: 提出了一种名为“组内一致性增强框架（ICAF）”的解决方案，该框架从面向组的视角重新审视了半监督语义分割（SSS）流程。具体包括：1. 组内视图采样（IVS）建立面向组的基线。2. 伪标签校正网络（PCN），其中包含： a. 视图增强模块（VAM）通过聚合多视图合成边界感知视图。b. 视图校正模块（VCM）将合成视图与其他视图配对以进行信息交互，强调显著区域并减少噪声。

Result: ICAF框架在CdZnTe数据集上实现了70.6%的mIoU，证明了其有效性，尤其是在仅使用2组标注数据（5‰）的条件下。

Conclusion: 本文提出的ICAF框架在CdZnTe材料分割任务中表现出色，使用DeepLabV3+和ResNet-101模型，在仅有2组标注数据（5‰）的情况下，mIoU达到了70.6%。

Abstract: Labeling Cadmium Zinc Telluride (CdZnTe) semiconductor images is challenging
due to the low-contrast defect boundaries, necessitating annotators to
cross-reference multiple views. These views share a single ground truth (GT),
forming a unique ``many-to-one'' relationship. This characteristic renders
advanced semi-supervised semantic segmentation (SSS) methods suboptimal, as
they are generally limited by a ``one-to-one'' relationship, where each image
is independently associated with its GT. Such limitation may lead to error
accumulation in low-contrast regions, further exacerbating confirmation bias.
To address this issue, we revisit the SSS pipeline from a group-oriented
perspective and propose a human-inspired solution: the Intra-group Consistency
Augmentation Framework (ICAF). First, we experimentally validate the inherent
consistency constraints within CdZnTe groups, establishing a group-oriented
baseline using the Intra-group View Sampling (IVS). Building on this insight,
we introduce the Pseudo-label Correction Network (PCN) to enhance consistency
representation, which consists of two key modules. The View Augmentation Module
(VAM) improves boundary details by dynamically synthesizing a boundary-aware
view through the aggregation of multiple views. In the View Correction Module
(VCM), this synthesized view is paired with other views for information
interaction, effectively emphasizing salient regions while minimizing noise.
Extensive experiments demonstrate the effectiveness of our solution for CdZnTe
materials. Leveraging DeepLabV3+ with a ResNet-101 backbone as our segmentation
model, we achieve a 70.6\% mIoU on the CdZnTe dataset using only 2
group-annotated data (5\textperthousand). The code is available at
\href{https://github.com/pipixiapipi/ICAF}{https://github.com/pipixiapipi/ICAF}.

</details>


### [116] [SocialTrack: Multi-Object Tracking in Complex Urban Traffic Scenes Inspired by Social Behavior](https://arxiv.org/abs/2508.12777)
*Wenguang Tao,Xiaotian Wang,Tian Yan,Jie Yan,Guodong Li,Kun Bai*

Main category: cs.CV

TL;DR: SocialTrack通过结合专门的小目标检测、改进的卡尔曼滤波、群体运动补偿和时空记忆预测，显著提高了UAV在复杂城市交通环境中跟踪小目标的准确性和稳定性，并在多个基准测试中超越了现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: UAV视角下的多目标跟踪在智能交通系统分析中具有重要价值，但面临小目标尺度变化、遮挡、非线性交叉运动和运动模糊等挑战，这些因素严重影响了跟踪的稳定性。因此，需要一个能增强跟踪精度和鲁棒性的框架来应对这些挑战。

Method: 提出了一种名为SocialTrack的新型多目标跟踪框架，该框架包含四个主要组件：1. 专门的小目标检测器（利用多尺度特征增强机制）；2. 速度自适应Cubature卡尔曼滤波器（VACKF，通过速度动态建模机制提高轨迹预测精度）；3. 群体运动补偿策略（GMCS，利用社会群体运动先验为低质量轨迹提供稳定的状态更新参考，提高目标关联精度）；4. 时空记忆预测（STMP，利用历史轨迹信息预测低质量轨迹的未来状态，减少身份切换）。

Result: 在UAVDT和MOT17数据集上进行的大量实验表明，SocialTrack在MOTA和IDF1等核心性能指标上取得了显著改进，优于现有的SOTA方法，证明了其卓越的鲁棒性和适应性。

Conclusion: SocialTrack框架通过结合多尺度特征增强、速度自适应Cubature卡尔曼滤波器、群体运动补偿策略和时空记忆预测，在UAVDT和MOT17数据集上展示了优于现有SOTA方法的性能，尤其在MOTA和IDF1等关键指标上取得了显著提升，证明了其在复杂城市交通环境中对小目标跟踪的鲁棒性和适应性。

Abstract: As a key research direction in the field of multi-object tracking (MOT),
UAV-based multi-object tracking has significant application value in the
analysis and understanding of urban intelligent transportation systems.
However, in complex UAV perspectives, challenges such as small target scale
variations, occlusions, nonlinear crossing motions, and motion blur severely
hinder the stability of multi-object tracking. To address these challenges,
this paper proposes a novel multi-object tracking framework, SocialTrack, aimed
at enhancing the tracking accuracy and robustness of small targets in complex
urban traffic environments. The specialized small-target detector enhances the
detection performance by employing a multi-scale feature enhancement mechanism.
The Velocity Adaptive Cubature Kalman Filter (VACKF) improves the accuracy of
trajectory prediction by incorporating a velocity dynamic modeling mechanism.
The Group Motion Compensation Strategy (GMCS) models social group motion priors
to provide stable state update references for low-quality tracks, significantly
improving the target association accuracy in complex dynamic environments.
Furthermore, the Spatio-Temporal Memory Prediction (STMP) leverages historical
trajectory information to predict the future state of low-quality tracks,
effectively mitigating identity switching issues. Extensive experiments on the
UAVDT and MOT17 datasets demonstrate that SocialTrack outperforms existing
state-of-the-art (SOTA) methods across several key metrics. Significant
improvements in MOTA and IDF1, among other core performance indicators,
highlight its superior robustness and adaptability. Additionally, SocialTrack
is highly modular and compatible, allowing for seamless integration with
existing trackers to further enhance performance.

</details>


### [117] [Leveraging Diffusion Models for Stylization using Multiple Style Images](https://arxiv.org/abs/2508.12784)
*Dan Ruta,Abdelaziz Djelouah,Raphael Ortiz,Christopher Schroers*

Main category: cs.CV

TL;DR: New method uses multiple style images and attention layer intervention for better image style transfer, outperforming existing approaches.


<details>
  <summary>Details</summary>
Motivation: Existing latent diffusion models struggle with accurate style matching, limited style image usage, and undesired content-style entanglement in image style transfer.

Method: Leveraging multiple style images, image prompt adapters, and statistical alignment of features (using clustering) during the denoising process to intervene in cross-attention and self-attention layers.

Result: The method achieves state-of-the-art results for stylization, better represents style features, and prevents content leaking from style images.

Conclusion: The proposed method achieves state-of-the-art results for stylization by leveraging multiple style images and intervening in both cross-attention and self-attention layers during the denoising process.

Abstract: Recent advances in latent diffusion models have enabled exciting progress in
image style transfer. However, several key issues remain. For example, existing
methods still struggle to accurately match styles. They are often limited in
the number of style images that can be used. Furthermore, they tend to entangle
content and style in undesired ways. To address this, we propose leveraging
multiple style images which helps better represent style features and prevent
content leaking from the style images. We design a method that leverages both
image prompt adapters and statistical alignment of the features during the
denoising process. With this, our approach is designed such that it can
intervene both at the cross-attention and the self-attention layers of the
denoising UNet. For the statistical alignment, we employ clustering to distill
a small representative set of attention features from the large number of
attention values extracted from the style samples. As demonstrated in our
experimental section, the resulting method achieves state-of-the-art results
for stylization.

</details>


### [118] [Vehicle detection from GSV imagery: Predicting travel behaviour for cycling and motorcycling using Computer Vision](https://arxiv.org/abs/2508.12794)
*Kyriaki,Kokka,Rahul Goel,Ali Abbas,Kerry A. Nice,Luca Martial,SM Labib,Rihuan Ke,Carola Bibiane Schönlieb,James Woodcock*

Main category: cs.CV

TL;DR: 这项研究利用谷歌街景图像和深度学习技术，成功估计了全球185个城市的骑行和摩托车出行水平，并为60个城市提供了新的出行估计数据。


<details>
  <summary>Details</summary>
Motivation: 交通方式影响着人们的身体活动、空气污染暴露和受伤风险。然而，关于骑行和摩托车出行行为的比较数据，尤其是在全球范围内，仍然匮乏。街景图像结合计算机视觉技术，为捕捉出行行为数据提供了一种有效且可扩展的资源。

Method: 本研究使用深度学习和谷歌街景（GSV）图像来估计全球185个城市的骑行和摩托车出行水平。通过对8000张GSV图像进行检测，并使用YOLOv4模型进行优化，实现了对自行车和摩托车的准确检测。在此基础上，利用beta回归模型结合城市级出行份额数据和GSV检测结果，开发了一个全球预测模型，并验证了其预测准确性。

Result: 研究结果表明，GSV检测到的摩托车数量与摩托车出行份额之间存在强相关性（0.78），而GSV检测到的自行车数量与自行车出行份额之间存在中度相关性（0.51）。Beta回归模型的预测结果显示，骑行和摩托车的模式份额的R²值分别为0.614和0.612，中位数绝对误差（MDAE）分别为1.3%和1.4%。该模型成功应用于60个缺乏近期出行份额数据的城市，并为中东、拉丁美洲和东亚的一些城市提供了估计数据。

Conclusion: 利用街景图像和深度学习来估计全球范围内的骑行和摩托车出行水平，为传统数据源提供了有价值的补充，并为城市规划和健康研究提供了新的见解。

Abstract: Transportation influence health by shaping exposure to physical activity, air
pollution and injury risk.Comparative data on cycling and motorcycling
behaviours is scarce, particularly at a global scale.Street view imagery, such
as Google Street View (GSV), combined with computer vision, is a valuable
resource for efficiently capturing travel behaviour data.This study
demonstrates a novel approach using deep learning on street view images to
estimate cycling and motorcycling levels across diverse cities worldwide.We
utilized data from 185 global cities.The data on mode shares of cycling and
motorcycling estimated using travel surveys or censuses.We used GSV images to
detect cycles and motorcycles in sampled locations, using 8000 images per
city.The YOLOv4 model, fine-tuned using images from six cities, achieved a mean
average precision of 89% for detecting cycles and motorcycles in GSV images.A
global prediction model was developed using beta regression with city-level
mode shares as outcome, with log transformed explanatory variables of counts of
GSV-detected images with cycles and motorcycles, while controlling for
population density.We found strong correlations between GSV motorcycle counts
and motorcycle mode share (0.78) and moderate correlations between GSV cycle
counts and cycling mode share (0.51).Beta regression models predicted mode
shares with $R^2$ values of 0.614 for cycling and 0.612 for motorcycling,
achieving median absolute errors (MDAE) of 1.3% and 1.4%,
respectively.Scatterplots demonstrated consistent prediction accuracy, though
cities like Utrecht and Cali were outliers.The model was applied to 60 cities
globally for which we didn't have recent mode share data.We provided estimates
for some cities in the Middle East, Latin America and East Asia.With computer
vision, GSV images capture travel modes and activity, providing insights
alongside traditional data sources.

</details>


### [119] [Morphological classification of eclipsing binary stars using computer vision methods](https://arxiv.org/abs/2508.12802)
*Štefan Parimucha,Maksim Gabdeev,Yanna Markus,Martin Vaňko,Pavol Gajdoš*

Main category: cs.CV

TL;DR: 将计算机视觉技术应用于食双星光变曲线分类，模型在识别双星类型方面表现出色，但在检测光斑方面存在局限性。


<details>
  <summary>Details</summary>
Motivation: 为了在大型巡检中对食双星（EB）进行形态分类，本研究旨在探索应用计算机视觉方法，特别是利用图像表示技术来处理和分类光变曲线数据。

Method: 研究采用了预先训练的卷积神经网络（ResNet50）和视觉转换器（vit_base_patch16_224）模型，并通过将相位折叠的光变曲线转换为极坐标并结合六边形分块可视化，创建了一种新颖的图像表示方法来改进模型泛化和减少过拟合。该方法采用分层方法，第一阶段分类系统为分离型和接触型，第二阶段识别是否存在光斑。

Result: 在验证数据上，多种频段（Gaia G、I 和 TESS）的二元分类模型取得了超过 96% 的高准确率。在 OGLE、DEBCat 和 WUMaCat 等观测数据集上的测试也表现出强大的性能（超过 94%，TESS 频段高达 100%）。然而，自动检测光斑的次要任务表现不佳，准确率不高。

Conclusion: 该研究展示了计算机视觉方法在分类食双星（EB）光变曲线方面的潜力，特别是在大规模巡检中进行形态分类。然而，在自动检测光斑方面，模型表现不佳，表明需要进一步研究以提高对细微光度特征的识别能力。

Abstract: We present an application of computer vision methods to classify the light
curves of eclipsing binaries (EB). We have used pre-trained models based on
convolutional neural networks ($\textit{ResNet50}$) and vision transformers
($\textit{vit\_base\_patch16\_224}$), which were fine-tuned on images created
from synthetic datasets. To improve model generalisation and reduce
overfitting, we developed a novel image representation by transforming
phase-folded light curves into polar coordinates combined with hexbin
visualisation. Our hierarchical approach in the first stage classifies systems
into detached and overcontact types, and in the second stage identifies the
presence or absence of spots. The binary classification models achieved high
accuracy ($>96\%$) on validation data across multiple passbands (Gaia~$G$, $I$,
and $TESS$) and demonstrated strong performance ($>94\%$, up to $100\%$ for
$TESS$) when tested on extensive observational data from the OGLE, DEBCat, and
WUMaCat catalogues. While the primary binary classification was highly
successful, the secondary task of automated spot detection performed poorly,
revealing a significant limitation of our models for identifying subtle
photometric features. This study highlights the potential of computer vision
for EB morphological classification in large-scale surveys, but underscores the
need for further research into robust, automated spot detection.

</details>


### [120] [Next Visual Granularity Generation](https://arxiv.org/abs/2508.12811)
*Yikai Wang,Zhouxia Wang,Zhonghua Wu,Qingyi Tao,Kang Liao,Chen Change Loy*

Main category: cs.CV

TL;DR: 提出NVG框架，通过结构化序列和逐层细化实现高质量、可控的图像生成，性能优于VAR。


<details>
  <summary>Details</summary>
Motivation: 捕捉不同级别的视觉粒度，并对生成过程进行多粒度精细控制。

Method: 提出了一种新颖的图像生成方法，将图像分解为结构化的序列，每个序列元素具有相同的空间分辨率但使用不同数量的唯一标记，捕捉不同级别的视觉粒度。通过新提出的下一视觉粒度（NVG）生成框架，从空图像开始，以结构化的方式逐步细化，从全局布局到精细细节进行生成。

Result: 在ImageNet数据集上训练了一系列NVG模型用于类别条件图像生成，观察到了清晰的缩放行为，并且在FID分数上持续优于VAR系列模型（3.30 -> 3.03, 2.57 ->2.44, 2.09 -> 2.06）。

Conclusion: NVG框架在图像生成方面展现出强大的能力和潜力，通过分解图像为结构化序列并逐层细化，实现了对生成过程的多粒度精细控制，并在ImageNet数据集上取得了优于VAR系列模型的FID分数。

Abstract: We propose a novel approach to image generation by decomposing an image into
a structured sequence, where each element in the sequence shares the same
spatial resolution but differs in the number of unique tokens used, capturing
different level of visual granularity. Image generation is carried out through
our newly introduced Next Visual Granularity (NVG) generation framework, which
generates a visual granularity sequence beginning from an empty image and
progressively refines it, from global layout to fine details, in a structured
manner. This iterative process encodes a hierarchical, layered representation
that offers fine-grained control over the generation process across multiple
granularity levels. We train a series of NVG models for class-conditional image
generation on the ImageNet dataset and observe clear scaling behavior. Compared
to the VAR series, NVG consistently outperforms it in terms of FID scores (3.30
-> 3.03, 2.57 ->2.44, 2.09 -> 2.06). We also conduct extensive analysis to
showcase the capability and potential of the NVG framework. Our code and models
will be released.

</details>


### [121] [SIS-Challenge: Event-based Spatio-temporal Instance Segmentation Challenge at the CVPR 2025 Event-based Vision Workshop](https://arxiv.org/abs/2508.12813)
*Friedhelm Hamann,Emil Mededovic,Fabian Gülhan,Yuli Wu,Johannes Stegmaier,Jing He,Yiqing Wang,Kexin Zhang,Lingling Li,Licheng Jiao,Mengru Ma,Hongxiang Huang,Yuhao Yan,Hongwei Ren,Xiaopeng Lin,Yulong Huang,Bojun Cheng,Se Hyun Lee,Gyu Sung Ham,Kanghan Oh,Gi Hyun Lim,Boxuan Yang,Bowen Du,Guillermo Gallego*

Main category: cs.CV

TL;DR: 本次挑战赛涉及时空实例分割，即结合事件相机和灰度相机数据进行像素级物体分割。比赛吸引了众多团队参与，并展示了多种先进的分割方法。


<details>
  <summary>Details</summary>
Motivation: 本次挑战赛旨在推动事件相机和灰度相机在像素级分割任务上的应用，以应对复杂动态场景的挑战。

Method: 介绍了用于时空实例分割（SIS）挑战赛的多种方法，包括排名前五的团队所使用的方法。

Result: 提供了挑战赛的详细结果，并展示了不同团队在这一任务上的表现。

Conclusion: 挑战赛的最终目标是利用时空对齐的事件相机和灰度相机数据，对已定义的物体类别进行像素级分割。

Abstract: We present an overview of the Spatio-temporal Instance Segmentation (SIS)
challenge held in conjunction with the CVPR 2025 Event-based Vision Workshop.
The task is to predict accurate pixel-level segmentation masks of defined
object classes from spatio-temporally aligned event camera and grayscale camera
data. We provide an overview of the task, dataset, challenge details and
results. Furthermore, we describe the methods used by the top-5 ranking teams
in the challenge. More resources and code of the participants' methods are
available here:
https://github.com/tub-rip/MouseSIS/blob/main/docs/challenge_results.md

</details>


### [122] [DEEP-SEA: Deep-Learning Enhancement for Environmental Perception in Submerged Aquatics](https://arxiv.org/abs/2508.12824)
*Shuang Chen,Ronald Thenius,Farshad Arvin,Amir Atapour-Abarghouei*

Main category: cs.CV

TL;DR: DEEP-SEA是一个新的深度学习模型，可以提高水下图像的质量，有助于更准确的水下监测。


<details>
  <summary>Details</summary>
Motivation: 水下环境因光散射、吸收和浊度等因素带来挑战，导致图像清晰度下降和颜色失真，使得准确观察变得困难。为了解决这些挑战，需要对水下图像进行恢复和增强。

Method: 提出了一种名为DEEP-SEA的新型深度学习水下图像恢复模型，该模型旨在增强低频和高频信息，同时保留空间结构。该模型采用了双频增强自注意力空间和频率调制器，以自适应地优化频域特征表示和空间信息，从而更好地保留结构。

Result: 在EUVP和LSUI数据集上的综合实验表明，DEEP-SEA在恢复细粒度图像细节和结构一致性方面优于现有技术。

Conclusion: DEEP-SEA模型通过有效缓解水下视觉退化，有潜力提高水下监测平台的可靠性，从而实现更准确的生态观察、物种识别和自主导航。

Abstract: Continuous and reliable underwater monitoring is essential for assessing
marine biodiversity, detecting ecological changes and supporting autonomous
exploration in aquatic environments. Underwater monitoring platforms rely on
mainly visual data for marine biodiversity analysis, ecological assessment and
autonomous exploration. However, underwater environments present significant
challenges due to light scattering, absorption and turbidity, which degrade
image clarity and distort colour information, which makes accurate observation
difficult. To address these challenges, we propose DEEP-SEA, a novel deep
learning-based underwater image restoration model to enhance both low- and
high-frequency information while preserving spatial structures. The proposed
Dual-Frequency Enhanced Self-Attention Spatial and Frequency Modulator aims to
adaptively refine feature representations in frequency domains and
simultaneously spatial information for better structural preservation. Our
comprehensive experiments on EUVP and LSUI datasets demonstrate the superiority
over the state of the art in restoring fine-grained image detail and structural
consistency. By effectively mitigating underwater visual degradation, DEEP-SEA
has the potential to improve the reliability of underwater monitoring platforms
for more accurate ecological observation, species identification and autonomous
navigation.

</details>


### [123] [Multi-source Multimodal Progressive Domain Adaption for Audio-Visual Deception Detection](https://arxiv.org/abs/2508.12842)
*Ronghao Lin,Sijie Mai,Ying Zeng,Qiaolin He,Aolin Xiong,Haifeng Hu*

Main category: cs.CV

TL;DR: 提出MMPDA框架解决了多模态欺骗检测中的域偏移问题，在竞赛中取得第二名，准确率达60.43%，F1分数达56.99%。


<details>
  <summary>Details</summary>
Motivation: 为了解决多模态欺骗检测任务中的域偏移问题，将知识从多个源域迁移到目标域。

Method: 提出了一种多源多模态渐进域适应（MMPDA）框架，通过在特征和决策层面逐步对齐源域和目标域，将来自不同源域的音频-视觉知识迁移到目标域，以解决域偏移问题。

Result: MMPDA框架在竞赛第二阶段取得了60.43%的准确率和56.99%的F1分数，在F1分数上超越第一名5.59%，在准确率上超越第三名6.75%。

Conclusion: 本研究提出的多源多模态渐进域适应（MMPDA）框架在多模态欺骗检测任务中取得了优异的成果，在竞赛第二阶段取得了60.43%的准确率和56.99%的F1分数，优于第一名和第三名队伍。

Abstract: This paper presents the winning approach for the 1st MultiModal Deception
Detection (MMDD) Challenge at the 1st Workshop on Subtle Visual Computing
(SVC). Aiming at the domain shift issue across source and target domains, we
propose a Multi-source Multimodal Progressive Domain Adaptation (MMPDA)
framework that transfers the audio-visual knowledge from diverse source domains
to the target domain. By gradually aligning source and the target domain at
both feature and decision levels, our method bridges domain shifts across
diverse multimodal datasets. Extensive experiments demonstrate the
effectiveness of our approach securing Top-2 place. Our approach reaches 60.43%
on accuracy and 56.99\% on F1-score on competition stage 2, surpassing the 1st
place team by 5.59% on F1-score and the 3rd place teams by 6.75% on accuracy.
Our code is available at https://github.com/RH-Lin/MMPDA.

</details>


### [124] [Cross-Domain Few-Shot Learning via Multi-View Collaborative Optimization with Vision-Language Models](https://arxiv.org/abs/2508.12861)
*Dexia Chen,Wentao Zhang,Qianjie Zhu,Ping Hu,Weibing Li,Tong Zhang,Ruixuan Wang*

Main category: cs.CV

TL;DR: CoMuCo is a new fine-tuning strategy for VLMs that improves performance on cross-domain few-shot learning by using multi-view features and consistency constraints.


<details>
  <summary>Details</summary>
Motivation: Existing transfer learning methods for VLMs are often limited in cross-domain tasks where imaging domains differ from natural images.

Method: CoMuCo employs two complementary expert modules for multi-view feature extraction, incorporating prior knowledge-based consistency constraints and information geometry-based consensus mechanisms to enhance feature learning robustness.

Result: CoMuCo consistently outperforms current methods in few-shot tasks. A new cross-domain few-shot benchmark was established for evaluation.

Conclusion: CoMuCo outperformed current methods in few-shot tasks on both existing and newly proposed benchmarks.

Abstract: Vision-language models (VLMs) pre-trained on natural image and language data,
such as CLIP, have exhibited significant potential in few-shot image
recognition tasks, leading to development of various efficient transfer
learning methods. These methods exploit inherent pre-learned knowledge in VLMs
and have achieved strong performance on standard image datasets. However, their
effectiveness is often limited when confronted with cross-domain tasks where
imaging domains differ from natural images. To address this limitation, we
propose Consistency-guided Multi-view Collaborative Optimization (CoMuCo), a
novel fine-tuning strategy for VLMs. This strategy employs two functionally
complementary expert modules to extract multi-view features, while
incorporating prior knowledge-based consistency constraints and information
geometry-based consensus mechanisms to enhance the robustness of feature
learning. Additionally, a new cross-domain few-shot benchmark is established to
help comprehensively evaluate methods on imaging domains distinct from natural
images. Extensive empirical evaluations on both existing and newly proposed
benchmarks suggest CoMuCo consistently outperforms current methods in few-shot
tasks. The code and benchmark will be released.

</details>


### [125] [Preserve and Sculpt: Manifold-Aligned Fine-tuning of Vision-Language Models for Few-Shot Learning](https://arxiv.org/abs/2508.12877)
*Dexia Chen,Qianjie Zhu,Weibing Li,Yue Yu,Tong Zhang,Ruixuan Wang*

Main category: cs.CV

TL;DR: MPS-Tuning 是一种新的微调方法，通过保留数据流形的几何结构来提高视觉-语言模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的预训练视觉-语言模型（VLMs）的微调方法虽然在迁移学习和少样本图像分类任务中表现出色，但常常忽略了数据分布的几何结构，可能导致整体语义表示失真。为了克服这一限制，需要一种能够保留数据几何结构的方法。

Method: MPS-Tuning 是一种新颖的微调方法，它将特征空间中的数据分布视为一个语义流形，并通过对齐微调前后特征的 Gram 矩阵来约束流形的内在几何结构，同时优化图像和文本模态的特征之间的成对相似性，以增强流形的类别可辨别性。

Result: MPS-Tuning 在保持语义流形结构的同时，显著提高了模型在图像分类任务上的性能。

Conclusion: MPS-Tuning 显著提高了模型性能，同时有效保留了语义流形结构的完整性。

Abstract: Pretrained vision-language models (VLMs), such as CLIP, have shown remarkable
potential in few-shot image classification and led to numerous effective
transfer learning strategies. These methods leverage the pretrained knowledge
of VLMs to enable effective domain adaptation while mitigating overfitting
through parameter-efficient tuning or instance-based consistency constraints.
However, such regularizations often neglect the geometric structure of data
distribution, which may lead to distortion of the overall semantic
representation. To overcome this limitation, we propose a novel fine-tuning
method, Manifold-Preserving and Sculpting Tuning (MPS-Tuning). Regarding the
data distribution in feature space as a semantic manifold, MPS-Tuning
explicitly constrains the intrinsic geometry of this manifold while further
sculpting it to enhance class separability. Specifically, MPS-Tuning preserves
both macroscopic and microscopic topological structures of the original
manifold by aligning Gram matrices of features before and after fine-tuning.
Theoretically, this constraint is shown to approximate an upper bound of the
Gromov-Wasserstein distance. Furthermore, features from the image and text
modalities are paired, and pairwise similarities are optimized to enhance the
manifold's class discriminability. Extensive experiments demonstrate that
MPS-Tuning significantly improves model performance while effectively
preserving the structure of the semantic manifold. The code will be released.

</details>


### [126] [S^2-Guidance: Stochastic Self Guidance for Training-Free Enhancement of Diffusion Models](https://arxiv.org/abs/2508.12880)
*Chubin Chen,Jiashu Zhu,Xiaokun Feng,Nisha Huang,Meiqi Wu,Fangyuan Mao,Jiahong Wu,Xiangxiang Chu,Xiu Li*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Classifier-free Guidance (CFG) is a widely used technique in modern diffusion
models for enhancing sample quality and prompt adherence. However, through an
empirical analysis on Gaussian mixture modeling with a closed-form solution, we
observe a discrepancy between the suboptimal results produced by CFG and the
ground truth. The model's excessive reliance on these suboptimal predictions
often leads to semantic incoherence and low-quality outputs. To address this
issue, we first empirically demonstrate that the model's suboptimal predictions
can be effectively refined using sub-networks of the model itself. Building on
this insight, we propose S^2-Guidance, a novel method that leverages stochastic
block-dropping during the forward process to construct stochastic sub-networks,
effectively guiding the model away from potential low-quality predictions and
toward high-quality outputs. Extensive qualitative and quantitative experiments
on text-to-image and text-to-video generation tasks demonstrate that
S^2-Guidance delivers superior performance, consistently surpassing CFG and
other advanced guidance strategies. Our code will be released.

</details>


### [127] [ONG: One-Shot NMF-based Gradient Masking for Efficient Model Sparsification](https://arxiv.org/abs/2508.12891)
*Sankar Behera,Yamuna Prasad*

Main category: cs.CV

TL;DR: ONG是一种通过NMF和梯度掩码实现一次性模型修剪的有效策略，能在保持模型性能的同时大幅减小模型尺寸。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络（DNN）虽然取得了显著成功，但其庞大的规模给部署带来了挑战。尽管存在各种修剪技术，但许多技术涉及复杂的迭代过程、专门的标准，或在训练过程中难以有效维持稀疏性。

Method: ONG（基于非负矩阵分解的一次性梯度掩码）是一种新颖的稀疏化策略，它在训练开始时使用非负矩阵分解（NMF）识别突出的权重结构，进行一次性修剪。随后，ONG采用精确的梯度掩码机制，确保只有未修剪的权重得到更新，在整个训练阶段严格保持目标稀疏度。

Result: 在BIMP比较框架中整合ONG，并在CIFAR-10和CIFAR-100上使用ResNet56、ResNet34和ResNet18进行评估，与已建立的稳定稀疏化方法进行比较，实验证明了ONG的能力。

Conclusion: ONG能在各种稀疏度水平上实现相当或更优的性能，同时在修剪后保持结构完整性，并提供一种针对所需稀疏度的清晰机制。

Abstract: Deep Neural Networks (DNNs) have achieved remarkable success but their large
size poses deployment challenges. While various pruning techniques exist, many
involve complex iterative processes, specialized criteria, or struggle to
maintain sparsity effectively during training. We introduce ONG (One-shot
NMF-based Gradient Masking), a novel sparsification strategy that identifies
salient weight structures using Non-negative Matrix Factorization (NMF) for
one-shot pruning at the outset of training. Subsequently, ONG employs a precise
gradient masking mechanism to ensure that only unpruned weights are updated,
strictly preserving the target sparsity throughout the training phase. We
integrate ONG into the BIMP comparative framework and evaluate it on CIFAR-10
and CIFAR-100 with ResNet56, ResNet34, and ResNet18 against established stable
sparsification methods. Our experiments demonstrate ONG's ability to achieve
comparable or superior performance at various sparsity levels while maintaining
structural integrity post-pruning and offering a clear mechanism for targeting
desired sparsities.

</details>


### [128] [CTFlow: Video-Inspired Latent Flow Matching for 3D CT Synthesis](https://arxiv.org/abs/2508.12900)
*Jiayi Wang,Hadrien Reynaud,Franciskus Xaverius Erick,Bernhard Kainz*

Main category: cs.CV

TL;DR: CTFlow是一个基于Transformer的模型，可以根据临床报告生成CT图像。它采用了一种新颖的自回归方法来处理CT图像，并在评估中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 生成以临床报告为条件的整个CT容积图，有潜力通过数据增强、隐私保护合成和减少患者数据的监管限制来加速研究，同时保留诊断信号。随着CT-RATE的发布，训练大型文本条件CT容积生成模型已成为可能。

Method: CTFlow是一个基于0.5B潜在流匹配Transformer模型，它以临床报告为条件。它利用FLUX的A-VAE来定义潜在空间，并使用CT-Clip文本编码器来编码临床报告。为了在可行的内存限制内生成一致的整个CT卷，CTFlow采用了一种自定义的自回归方法，首先仅根据文本预测序列切片，然后结合先前生成的切片和文本来预测接下来的序列切片。

Result: CTFlow在时间相干性、图像多样性和文本-图像一致性方面优于最先进的CT生成模型，并提供了FID、FVD、IS和CLIP分数。

Conclusion: CTFlow在时间相干性、图像多样性和文本-图像一致性方面优于最先进的CT生成模型，并提供了FID、FVD、IS和CLIP分数。

Abstract: Generative modelling of entire CT volumes conditioned on clinical reports has
the potential to accelerate research through data augmentation,
privacy-preserving synthesis and reducing regulator-constraints on patient data
while preserving diagnostic signals. With the recent release of CT-RATE, a
large-scale collection of 3D CT volumes paired with their respective clinical
reports, training large text-conditioned CT volume generation models has become
achievable. In this work, we introduce CTFlow, a 0.5B latent flow matching
transformer model, conditioned on clinical reports. We leverage the A-VAE from
FLUX to define our latent space, and rely on the CT-Clip text encoder to encode
the clinical reports. To generate consistent whole CT volumes while keeping the
memory constraints tractable, we rely on a custom autoregressive approach,
where the model predicts the first sequence of slices of the volume from
text-only, and then relies on the previously generated sequence of slices and
the text, to predict the following sequence. We evaluate our results against
state-of-the-art generative CT model, and demonstrate the superiority of our
approach in terms of temporal coherence, image diversity and text-image
alignment, with FID, FVD, IS scores and CLIP score.

</details>


### [129] [CMF-IoU: Multi-Stage Cross-Modal Fusion 3D Object Detection with IoU Joint Prediction](https://arxiv.org/abs/2508.12917)
*Zhiwei Ning,Zhaojiang Liu,Xuanang Gao,Yifan Zuo,Jie Yang,Yuming Fang,Wei Liu*

Main category: cs.CV

TL;DR: CMF-IOU improves 3D detection by fusing camera and LiDAR data in multiple stages. It uses pseudo points from camera data and LiDAR data, enhancing features with specialized network branches (S2D and ResVC). A novel pooling module and IoU-based refinement lead to better bounding box predictions, outperforming existing methods on benchmark datasets.


<details>
  <summary>Details</summary>
Motivation: Prevalent multi-modal 3D detection methods often focus on single or partial stage fusion, leading to insufficient feature extraction and suboptimal performance. This paper aims to address the challenge of aligning 3D spatial and 2D semantic information for improved 3D detection.

Method: The paper introduces CMF-IOU, a multi-stage cross-modal fusion 3D detection framework. It unifies LiDAR and camera data by projecting pixel information into 3D space using a depth completion network to create pseudo points. A bilateral cross-view enhancement 3D backbone encodes LiDAR points and pseudo points using a sparse-to-distant (S2D) branch (encoder-decoder for sparse LiDAR points) and a residual view consistency (ResVC) branch (3D and 2D convolutions to mitigate inaccurate pseudo points). An iterative voxel-point aware fine grained pooling module refines proposals by capturing spatial information from LiDAR points and textural information from pseudo points. Finally, an IoU joint prediction branch with a novel proposals generation technique refines bounding boxes based on both IoU and classification scores.

Result: Extensive experiments demonstrate the superior performance of the CMF-IOU method on the KITTI, nuScenes, and Waymo datasets.

Conclusion: The proposed CMF-IOU framework achieves superior performance on KITTI, nuScenes, and Waymo datasets due to its effective multi-stage cross-modal fusion strategy.

Abstract: Multi-modal methods based on camera and LiDAR sensors have garnered
significant attention in the field of 3D detection. However, many prevalent
works focus on single or partial stage fusion, leading to insufficient feature
extraction and suboptimal performance. In this paper, we introduce a
multi-stage cross-modal fusion 3D detection framework, termed CMF-IOU, to
effectively address the challenge of aligning 3D spatial and 2D semantic
information. Specifically, we first project the pixel information into 3D space
via a depth completion network to get the pseudo points, which unifies the
representation of the LiDAR and camera information. Then, a bilateral
cross-view enhancement 3D backbone is designed to encode LiDAR points and
pseudo points. The first sparse-to-distant (S2D) branch utilizes an
encoder-decoder structure to reinforce the representation of sparse LiDAR
points. The second residual view consistency (ResVC) branch is proposed to
mitigate the influence of inaccurate pseudo points via both the 3D and 2D
convolution processes. Subsequently, we introduce an iterative voxel-point
aware fine grained pooling module, which captures the spatial information from
LiDAR points and textural information from pseudo points in the proposal
refinement stage. To achieve more precise refinement during iteration, an
intersection over union (IoU) joint prediction branch integrated with a novel
proposals generation technique is designed to preserve the bounding boxes with
both high IoU and classification scores. Extensive experiments show the
superior performance of our method on the KITTI, nuScenes and Waymo datasets.

</details>


### [130] [7Bench: a Comprehensive Benchmark for Layout-guided Text-to-image Models](https://arxiv.org/abs/2508.12919)
*Elena Izzo,Luca Parolari,Davide Vezzaro,Lamberto Ballan*

Main category: cs.CV

TL;DR: 该研究提出了7Bench，一个评估布局引导文本到图像生成模型（尤其是其空间对齐能力）的基准。它包含了多种场景和评估协议，并用于评估现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像生成模型在空间对齐方面存在不足，这限制了它们在需要精确空间保真度的应用（如合成数据生成）中的有效性。现有的基准主要关注文本对齐，忽略了对布局对齐的评估，阻碍了对模型空间保真度的全面评估。

Method: 提出了一种名为7Bench的新基准，用于评估布局引导文本到图像生成模型的语义和空间对齐。该基准包含文本-布局对，涵盖了对象生成、颜色保真度、属性识别、对象间关系和空间控制等七种具有挑战性的场景。研究还提出了一种评估协议，通过整合布局对齐得分来评估空间准确性。

Result: 7Bench是第一个能够同时评估布局引导文本到图像生成模型的语义和空间对齐的基准。通过该基准评估了现有的先进扩散模型，揭示了它们在不同对齐任务上的优势和劣势。

Conclusion: 该研究提出了7Bench，一个用于评估布局引导文本到图像生成模型语义和空间对齐的基准。该基准包含跨越七种具有挑战性场景的文本-布局对，并引入了一个包含布局对齐得分的评估协议。通过使用7Bench，研究评估了几种最先进的扩散模型，揭示了它们在不同对齐任务上的优缺点。

Abstract: Layout-guided text-to-image models offer greater control over the generation
process by explicitly conditioning image synthesis on the spatial arrangement
of elements. As a result, their adoption has increased in many computer vision
applications, ranging from content creation to synthetic data generation. A
critical challenge is achieving precise alignment between the image, textual
prompt, and layout, ensuring semantic fidelity and spatial accuracy. Although
recent benchmarks assess text alignment, layout alignment remains overlooked,
and no existing benchmark jointly evaluates both. This gap limits the ability
to evaluate a model's spatial fidelity, which is crucial when using
layout-guided generation for synthetic data, as errors can introduce noise and
degrade data quality. In this work, we introduce 7Bench, the first benchmark to
assess both semantic and spatial alignment in layout-guided text-to-image
generation. It features text-and-layout pairs spanning seven challenging
scenarios, investigating object generation, color fidelity, attribute
recognition, inter-object relationships, and spatial control. We propose an
evaluation protocol that builds on existing frameworks by incorporating the
layout alignment score to assess spatial accuracy. Using 7Bench, we evaluate
several state-of-the-art diffusion models, uncovering their respective
strengths and limitations across diverse alignment tasks. The benchmark is
available at https://github.com/Elizzo/7Bench.

</details>


### [131] [Towards High-Resolution Industrial Image Anomaly Detection](https://arxiv.org/abs/2508.12931)
*Ximiao Zhang,Min Xu,Xiuzhuang Zhou*

Main category: cs.CV

TL;DR: HiAD是一个通用的高分辨率异常检测框架，通过双分支架构、多分辨率特征融合和自适应检测器分配策略，有效检测不同尺寸的异常区域，同时控制计算成本，并在多个基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有异常检测方法主要关注低分辨率场景，对于高分辨率图像，常规下采样会导致细微异常区域的漏检。尽管取得了一些进展，但现有方法在检测精度和效率方面仍难以满足工业场景的实际需求。

Method: HiAD采用一种双分支架构，整合不同尺度的异常线索，以全面捕捉细微和大规模的异常。此外，它还采用多分辨率特征融合策略来应对高分辨率图像中细粒度纹理变化的挑战。为了提高适应性和效率，HiAD利用检测器池和各种检测器分配策略，根据块特征自适应地分配检测器，确保检测性能，同时有效控制计算成本。

Result: HiAD能够检测高分辨率图像中的各种尺寸的异常区域，同时受到有限的计算资源。

Conclusion: HiAD在MVTec-HD、VisA-HD和RealIAD-HD等高分辨率异常检测基准上进行了广泛的实验，证明了其卓越的性能。

Abstract: Current anomaly detection methods primarily focus on low-resolution
scenarios. For high-resolution images, conventional downsampling often results
in missed detections of subtle anomalous regions due to the loss of
fine-grained discriminative information. Despite some progress, recent studies
have attempted to improve detection resolution by employing lightweight
networks or using simple image tiling and ensemble methods. However, these
approaches still struggle to meet the practical demands of industrial scenarios
in terms of detection accuracy and efficiency. To address the above issues, we
propose HiAD, a general framework for high-resolution anomaly detection. HiAD
is capable of detecting anomalous regions of varying sizes in high-resolution
images under limited computational resources. Specifically, HiAD employs a
dual-branch architecture that integrates anomaly cues across different scales
to comprehensively capture both subtle and large-scale anomalies. Furthermore,
it incorporates a multi-resolution feature fusion strategy to tackle the
challenges posed by fine-grained texture variations in high-resolution images.
To enhance both adaptability and efficiency, HiAD utilizes a detector pool in
conjunction with various detector assignment strategies, enabling detectors to
be adaptively assigned based on patch features, ensuring detection performance
while effectively controlling computational costs. We conduct extensive
experiments on our specifically constructed high-resolution anomaly detection
benchmarks, including MVTec-HD, VisA-HD, and the real-world benchmark
RealIAD-HD, demonstrating the superior performance of HiAD. The code is
available at https://github.com/cnulab/HiAD.

</details>


### [132] [SEDEG:Sequential Enhancement of Decoder and Encoder's Generality for Class Incremental Learning with Small Memory](https://arxiv.org/abs/2508.12932)
*Hongyang Chen,Shaoling Pu,Lingyu Zheng,Zhongwu Sun*

Main category: cs.CV

TL;DR: SEDEG 通过两阶段训练框架，先增强解码器通用性，再通过知识蒸馏增强编码器通用性，有效解决了 Vision Transformer 在增量学习中小内存场景下的灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 现有的增量学习方法在提升通用性方面存在不足，尤其是在小内存场景下，许多方法仅关注编码器或解码器的一个组件，限制了其缓解灾难性遗忘的能力。因此，需要一种能够同时提升编码器和解码器通用性的方法。

Method: SEDEG是一个两阶段训练框架，针对 Vision Transformer (ViT)：第一阶段，通过特征增强训练集成编码器以学习通用表示，进而提升解码器的通用性并平衡分类器；第二阶段，利用知识蒸馏（KD）策略压缩集成编码器，并结合平衡 KD 和特征 KD 方法进行有效的知识迁移，以获得更通用的编码器。

Result: SEDEG 在三个基准数据集上的实验结果表明其性能优越，并且通过消融实验证实了其各组成部分的有效性。

Conclusion: SEDEG 框架通过顺序提升编码器和解码器的通用性，在小内存场景下有效缓解了灾难性遗忘，并在三个基准数据集上展现出优越的性能。

Abstract: In incremental learning, enhancing the generality of knowledge is crucial for
adapting to dynamic data inputs. It can develop generalized representations or
more balanced decision boundaries, preventing the degradation of long-term
knowledge over time and thus mitigating catastrophic forgetting. Some emerging
incremental learning methods adopt an encoder-decoder architecture and have
achieved promising results. In the encoder-decoder achitecture, improving the
generalization capabilities of both the encoder and decoder is critical, as it
helps preserve previously learned knowledge while ensuring adaptability and
robustness to new, diverse data inputs. However, many existing continual
methods focus solely on enhancing one of the two components, which limits their
effectiveness in mitigating catastrophic forgetting. And these methods perform
even worse in small-memory scenarios, where only a limited number of historical
samples can be stored. To mitigate this limitation, we introduces SEDEG, a
two-stage training framework for vision transformers (ViT), focusing on
sequentially improving the generality of both Decoder and Encoder. Initially,
SEDEG trains an ensembled encoder through feature boosting to learn generalized
representations, which subsequently enhance the decoder's generality and
balance the classifier. The next stage involves using knowledge distillation
(KD) strategies to compress the ensembled encoder and develop a new, more
generalized encoder. This involves using a balanced KD approach and feature KD
for effective knowledge transfer. Extensive experiments on three benchmark
datasets show SEDEG's superior performance, and ablation studies confirm the
efficacy of its components. The code is available at
https://github.com/ShaolingPu/CIL.

</details>


### [133] [Fully Automated Segmentation of Fiber Bundles in Anatomic Tracing Data](https://arxiv.org/abs/2508.12942)
*Kyriaki-Margarita Bintsi,Yaël Balbastre,Jingjing Wu,Julia F. Lehman,Suzanne N. Haber,Anastasia Yendiki*

Main category: cs.CV

TL;DR: 一个自动化的框架，用于分割猴子追踪数据中的纤维束，比现有方法更准确、更灵活。


<details>
  <summary>Details</summary>
Motivation: 解剖追踪研究对于验证和改进 dMRI 纤维追踪至关重要，但手动注释费时费力，现有自动化方法存在局限性。

Method: 提出了一种基于 U-Net 架构的简化、全自动化框架，该框架具有大图像块、前景感知采样和半监督预训练，用于猴子追踪数据中的纤维束分割。

Result: 与现有技术相比，该方法将稀疏束的检测提高了 20% 以上，并将错误发现率（FDR）降低了 40%，同时能够分析独立的切片。

Conclusion: 该框架将促进大规模解剖追踪数据的自动化分析，生成更多用于验证和优化 dMRI 纤维追踪方法的真实数据。

Abstract: Anatomic tracer studies are critical for validating and improving diffusion
MRI (dMRI) tractography. However, large-scale analysis of data from such
studies is hampered by the labor-intensive process of annotating fiber bundles
manually on histological slides. Existing automated methods often miss sparse
bundles or require complex post-processing across consecutive sections,
limiting their flexibility and generalizability. We present a streamlined,
fully automated framework for fiber bundle segmentation in macaque tracer data,
based on a U-Net architecture with large patch sizes, foreground aware
sampling, and semisupervised pre-training. Our approach eliminates common
errors such as mislabeling terminals as bundles, improves detection of sparse
bundles by over 20% and reduces the False Discovery Rate (FDR) by 40% compared
to the state-of-the-art, all while enabling analysis of standalone slices. This
new framework will facilitate the automated analysis of anatomic tracing data
at a large scale, generating more ground-truth data that can be used to
validate and optimize dMRI tractography methods.

</details>


### [134] [Lumen: Consistent Video Relighting and Harmonious Background Replacement with Video Generative Models](https://arxiv.org/abs/2508.12945)
*Jianshu Zeng,Yuxuan Liu,Yutong Feng,Chenxuan Miao,Zixiang Gao,Jiwang Qu,Jianzhang Zhang,Bin Wang,Kun Yuan*

Main category: cs.CV

TL;DR: Lumen 是一个端到端的视频重新布光框架，它使用文本描述来控制光照和背景，并能保持前景属性和时间一致性。该框架使用包含真实和合成视频的大规模数据集进行训练，并通过实验证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 视频重新布光旨在在替换视频背景的同时，相应地调整前景的光照并实现和谐的融合。在此过程中，必须保留前景的原始属性（如反照率），并在时间帧之间传播一致的重新布光效果。

Method: 提出了一种名为 Lumen 的端到端视频重新布光框架，该框架基于大规模视频生成模型，并能接收灵活的文本描述来控制光照和背景。该框架通过注入特定领域的适配器来解耦重新布光和领域外观分布的学习。为了训练该模型，研究人员构建了一个大规模数据集，其中包含真实和合成视频的混合。对于合成数据，利用了先进的 3D 渲染引擎；对于真实数据，则采用了基于 HDR 的光照模拟。

Result: Lumen 能够有效地将输入编辑成具有一致光照和严格前景保持的电影级重新布光视频。

Conclusion: 实验结果表明，Lumen 能有效地将输入视频编辑成具有一致光照和严格前景保持的电影级重新布光视频。

Abstract: Video relighting is a challenging yet valuable task, aiming to replace the
background in videos while correspondingly adjusting the lighting in the
foreground with harmonious blending. During translation, it is essential to
preserve the original properties of the foreground, e.g., albedo, and propagate
consistent relighting among temporal frames. In this paper, we propose Lumen,
an end-to-end video relighting framework developed on large-scale video
generative models, receiving flexible textual description for instructing the
control of lighting and background. Considering the scarcity of high-qualified
paired videos with the same foreground in various lighting conditions, we
construct a large-scale dataset with a mixture of realistic and synthetic
videos. For the synthetic domain, benefiting from the abundant 3D assets in the
community, we leverage advanced 3D rendering engine to curate video pairs in
diverse environments. For the realistic domain, we adapt a HDR-based lighting
simulation to complement the lack of paired in-the-wild videos. Powered by the
aforementioned dataset, we design a joint training curriculum to effectively
unleash the strengths of each domain, i.e., the physical consistency in
synthetic videos, and the generalized domain distribution in realistic videos.
To implement this, we inject a domain-aware adapter into the model to decouple
the learning of relighting and domain appearance distribution. We construct a
comprehensive benchmark to evaluate Lumen together with existing methods, from
the perspectives of foreground preservation and video consistency assessment.
Experimental results demonstrate that Lumen effectively edit the input into
cinematic relighted videos with consistent lighting and strict foreground
preservation. Our project page: https://lumen-relight.github.io/

</details>


### [135] [MaskSem: Semantic-Guided Masking for Learning 3D Hybrid High-Order Motion Representation](https://arxiv.org/abs/2508.12948)
*Wei Wei,Shaojie Zhang,Yonghao Dang,Jianqin Yin*

Main category: cs.CV

TL;DR: MaskSem 是一种新的语义引导掩码方法，用于提高自监督骨骼动作识别的性能。它通过 Grad-CAM 引导关节掩码，并使用混合高阶运动作为重建目标，以更好地捕捉复杂运动模式。实验证明该方法在多个数据集上均有提升，尤其适用于人机交互。


<details>
  <summary>Details</summary>
Motivation: 现有自监督骨骼识别方法主要关注有限的关节和低阶运动模式，限制了模型理解复杂运动模式的能力。因此，需要一种新的方法来解决这个问题，以提高模型对动作模式的理解。

Method: MaskSem 是一种新颖的语义引导掩码方法，通过利用基于相对运动的 Grad-CAM 来指导关节掩码，以捕获最丰富的语义时间区域。此外，提出使用混合高阶运动（包括低阶运动速度和高阶运动加速度）作为重建目标，以学习多阶运动模式。

Result: MaskSem 结合 vanilla transformer 在 NTU60、NTU120 和 PKU-MMD 数据集上改进了骨骼序列的动作识别性能，使其更适用于人机交互场景。

Conclusion: MaskSem 通过利用基于相对运动的 Grad-CAM 来指导语义丰富的时域区域的关节掩码，并结合低阶运动速度和高阶运动加速度作为重建目标，从而提出了一种新颖的语义引导掩码方法，用于学习三维混合高阶运动表示。实验证明，MaskSem 结合 vanilla transformer 在 NTU60、NTU120 和 PKU-MMD 数据集上改进了基于骨骼的动作识别，提高了其在人机交互应用中的适应性。

Abstract: Human action recognition is a crucial task for intelligent robotics,
particularly within the context of human-robot collaboration research. In
self-supervised skeleton-based action recognition, the mask-based
reconstruction paradigm learns the spatial structure and motion patterns of the
skeleton by masking joints and reconstructing the target from unlabeled data.
However, existing methods focus on a limited set of joints and low-order motion
patterns, limiting the model's ability to understand complex motion patterns.
To address this issue, we introduce MaskSem, a novel semantic-guided masking
method for learning 3D hybrid high-order motion representations. This novel
framework leverages Grad-CAM based on relative motion to guide the masking of
joints, which can be represented as the most semantically rich temporal
orgions. The semantic-guided masking process can encourage the model to explore
more discriminative features. Furthermore, we propose using hybrid high-order
motion as the reconstruction target, enabling the model to learn multi-order
motion patterns. Specifically, low-order motion velocity and high-order motion
acceleration are used together as the reconstruction target. This approach
offers a more comprehensive description of the dynamic motion process,
enhancing the model's understanding of motion patterns. Experiments on the
NTU60, NTU120, and PKU-MMD datasets show that MaskSem, combined with a vanilla
transformer, improves skeleton-based action recognition, making it more
suitable for applications in human-robot interaction.

</details>


### [136] [Breaking Reward Collapse: Adaptive Reinforcement for Open-ended Medical Reasoning with Enhanced Semantic Discrimination](https://arxiv.org/abs/2508.12957)
*Yizhou Liu,Jingwei Wei,Zizhi Chen,Minghao Han,Xukun Zhang,Keliang Liu,Lihua Zhang*

Main category: cs.CV

TL;DR: ARMed通过自适应语义奖励改进了开放式医学VQA，显著提升了模型在医学推理任务上的准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的强化微调（RFT）方法主要应用于封闭式医学VQA，限制了其在真实临床推理中的应用。开放式医学VQA更能反映临床实践，但受到的关注有限。现有的语义引导RL方法存在模型驱动的语义奖励可能导致奖励坍塌（即语义差异显著的响应获得相似分数）的问题。

Method: ARMed框架首先通过监督微调（SFT）结合链式思考数据来整合领域知识，然后应用基于文本正确性和自适应语义奖励的强化学习来优化推理质量。

Result: ARMed在六个具有挑战性的医学VQA基准测试上持续提升了准确性和泛化能力，在领域内任务上实现了32.64%的改进，在领域外基准上实现了11.65%的提升。

Conclusion: ARMed框架通过结合领域知识、监督微调（SFT）以及基于文本正确性和自适应语义奖励的强化学习，成功提升了开放式医学视觉问答（VQA）的准确性和泛化能力，在领域内任务上实现了32.64%的提升，在领域外基准测试上实现了11.65%的提升。该研究强调了奖励可辨别性在医学强化学习中的关键作用，并展示了语义引导奖励在实现稳健且具有临床意义的多模态推理方面的潜力。

Abstract: Reinforcement learning (RL) with rule-based rewards has demonstrated strong
potential in enhancing the reasoning and generalization capabilities of
vision-language models (VLMs) and large language models (LLMs), while reducing
computational overhead. However, its application in medical imaging remains
underexplored. Existing reinforcement fine-tuning (RFT) approaches in this
domain primarily target closed-ended visual question answering (VQA), limiting
their applicability to real-world clinical reasoning. In contrast, open-ended
medical VQA better reflects clinical practice but has received limited
attention. While some efforts have sought to unify both formats via
semantically guided RL, we observe that model-based semantic rewards often
suffer from reward collapse, where responses with significant semantic
differences receive similar scores. To address this, we propose ARMed (Adaptive
Reinforcement for Medical Reasoning), a novel RL framework for open-ended
medical VQA. ARMed first incorporates domain knowledge through supervised
fine-tuning (SFT) on chain-of-thought data, then applies reinforcement learning
with textual correctness and adaptive semantic rewards to enhance reasoning
quality. We evaluate ARMed on six challenging medical VQA benchmarks. Results
show that ARMed consistently boosts both accuracy and generalization, achieving
a 32.64% improvement on in-domain tasks and an 11.65% gain on out-of-domain
benchmarks. These results highlight the critical role of reward
discriminability in medical RL and the promise of semantically guided rewards
for enabling robust and clinically meaningful multimodal reasoning.

</details>


### [137] [Multi-Phase Automated Segmentation of Dental Structures in CBCT Using a Lightweight Auto3DSeg and SegResNet Implementation](https://arxiv.org/abs/2508.12962)
*Dominic LaBella,Keshav Jha,Jared Robbins,Esther Yu*

Main category: cs.CV

TL;DR: DLaBella29团队使用深度学习和MONAI Auto3DSeg框架，通过多阶段分割方法，在牙科CBCT的牙齿分割任务中取得了高精度（0.87）Dice分数，为放射肿瘤学中的患者护理提供了改进的可能性。


<details>
  <summary>Details</summary>
Motivation: 牙科CBCT已成为一种宝贵的成像方式，能够对牙齿和周围结构进行3D可视化，以辅助诊断和治疗规划。牙科CBCT的自动化分割能够有效地识别病变（如牙髓或根尖周病变），并为头颈癌患者的放射治疗规划提供便利。

Method: 使用MONAI Auto3DSeg框架和3D SegResNet架构，对ToothFairy3数据集的一个子集（63个CBCT扫描）进行5折交叉验证训练。关键预处理步骤包括将图像重采样至0.6毫米各向同性分辨率和强度裁剪。通过在5折预测上使用多标签STAPLE进行集成融合，推断出第一阶段分割，然后对易于分割的第一阶段下颌骨进行紧密裁剪，在较小的神经结构上执行第二阶段分割。

Result: 在ToothFairy3挑战赛的样本外验证集上，该方法实现了0.87的平均Dice分数。

Conclusion: 该方法通过多类牙齿分割的深度学习流程，在MICCAI 2025 ToothFairy3挑战赛中取得了0.87的平均Dice分数，为牙科CBCT图像的自动化分割提供了有效的解决方案。

Abstract: Cone-beam computed tomography (CBCT) has become an invaluable imaging
modality in dentistry, enabling 3D visualization of teeth and surrounding
structures for diagnosis and treatment planning. Automated segmentation of
dental structures in CBCT can efficiently assist in identifying pathology
(e.g., pulpal or periapical lesions) and facilitate radiation therapy planning
in head and neck cancer patients. We describe the DLaBella29 team's approach
for the MICCAI 2025 ToothFairy3 Challenge, which involves a deep learning
pipeline for multi-class tooth segmentation. We utilized the MONAI Auto3DSeg
framework with a 3D SegResNet architecture, trained on a subset of the
ToothFairy3 dataset (63 CBCT scans) with 5-fold cross-validation. Key
preprocessing steps included image resampling to 0.6 mm isotropic resolution
and intensity clipping. We applied an ensemble fusion using Multi-Label STAPLE
on the 5-fold predictions to infer a Phase 1 segmentation and then conducted
tight cropping around the easily segmented Phase 1 mandible to perform Phase 2
segmentation on the smaller nerve structures. Our method achieved an average
Dice of 0.87 on the ToothFairy3 challenge out-of-sample validation set. This
paper details the clinical context, data preparation, model development,
results of our approach, and discusses the relevance of automated dental
segmentation for improving patient care in radiation oncology.

</details>


### [138] [GazeDETR: Gaze Detection using Disentangled Head and Gaze Representations](https://arxiv.org/abs/2508.12966)
*Ryan Anthony Jalova de Belen,Gelareh Mohammadi,Arcot Sowmya*

Main category: cs.CV

TL;DR: GazeDETR是一个新颖的端到端架构，通过使用两个独立的解码器来解决现有模型中人头定位和注视点预测的纠缠表示问题，并在多个数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 量化注视行为有助于人机交互和数字表型分析，但现有的端到端模型使用单一解码器来同时本地化人头和预测注视点，这会产生统一且纠缠的表示。

Method: 提出了一种名为GazeDETR的新型端到端架构，该架构具有两个独立的解码器，能够分别学习独特的表示，并为每个子任务有效地利用连贯的注意力场。具体来说，头部预测器利用局部信息，而注视解码器同时利用局部和全局信息。

Result: GazeDETR在GazeFollow、VideoAttentionTarget和ChildPlay数据集上取得了最先进的性能，并显著优于现有的端到端模型。

Conclusion: GazeDETR在GazeFollow、VideoAttentionTarget和ChildPlay数据集上取得了最先进的结果，并且显著优于现有的端到端模型。

Abstract: Gaze communication plays a crucial role in daily social interactions.
Quantifying this behavior can help in human-computer interaction and digital
phenotyping. While end-to-end models exist for gaze target detection, they only
utilize a single decoder to simultaneously localize human heads and predict
their corresponding gaze (e.g., 2D points or heatmap) in a scene. This
multitask learning approach generates a unified and entangled representation
for human head localization and gaze location prediction. Herein, we propose
GazeDETR, a novel end-to-end architecture with two disentangled decoders that
individually learn unique representations and effectively utilize coherent
attentive fields for each subtask. More specifically, we demonstrate that its
human head predictor utilizes local information, while its gaze decoder
incorporates both local and global information. Our proposed architecture
achieves state-of-the-art results on the GazeFollow, VideoAttentionTarget and
ChildPlay datasets. It outperforms existing end-to-end models with a notable
margin.

</details>


### [139] [Compact Attention: Exploiting Structured Spatio-Temporal Sparsity for Fast Video Generation](https://arxiv.org/abs/2508.12969)
*Qirui Li,Guangcong Zheng,Qi Zhao,Jie Li,Bin Dong,Yiwu Yao,Xi Li*

Main category: cs.CV

TL;DR: 为解决Transformer视频生成中的计算瓶颈，提出Compact Attention框架，通过自适应切块、时间变化窗口和自动化配置优化稀疏注意力，实现高效长视频生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理超长序列的视频生成时，因自注意力机制的计算需求而面临挑战，且未能充分利用视频数据的时空冗余。视频生成Transformer（DiT）的注意力矩阵表现出结构化但异构的稀疏模式，现有稀疏注意力方法存在限制。

Method: Compact Attention框架，包含自适应切块策略、时间变化窗口和自动化配置搜索算法。

Result: 在单GPU上实现了1.6~2.5倍的注意力计算加速，同时保持了与全注意力基线相当的视觉质量。

Conclusion: 本研究提出了一种名为Compact Attention的硬件感知加速框架，通过自适应切块策略、时间变化窗口和自动化配置搜索算法，有效利用视频数据的时空冗余，实现了1.6~2.5倍的注意力计算加速，同时保持了与全注意力基线相当的视觉质量，为高效长视频生成提供了原则性方法。

Abstract: The computational demands of self-attention mechanisms pose a critical
challenge for transformer-based video generation, particularly in synthesizing
ultra-long sequences. Current approaches, such as factorized attention and
fixed sparse patterns, fail to fully exploit the inherent spatio-temporal
redundancies in video data. Through systematic analysis of video diffusion
transformers (DiT), we uncover a key insight: Attention matrices exhibit
structured, yet heterogeneous sparsity patterns, where specialized heads
dynamically attend to distinct spatiotemporal regions (e.g., local pattern,
cross-shaped pattern, or global pattern). Existing sparse attention methods
either impose rigid constraints or introduce significant overhead, limiting
their effectiveness. To address this, we propose Compact Attention, a
hardware-aware acceleration framework featuring three innovations: 1) Adaptive
tiling strategies that approximate diverse spatial interaction patterns via
dynamic tile grouping, 2) Temporally varying windows that adjust sparsity
levels based on frame proximity, and 3) An automated configuration search
algorithm that optimizes sparse patterns while preserving critical attention
pathways. Our method achieves 1.6~2.5x acceleration in attention computation on
single-GPU setups while maintaining comparable visual quality with
full-attention baselines. This work provides a principled approach to unlocking
efficient long-form video generation through structured sparsity exploitation.
Project Page: https://yo-ava.github.io/Compact-Attention.github.io/

</details>


### [140] [Dextr: Zero-Shot Neural Architecture Search with Singular Value Decomposition and Extrinsic Curvature](https://arxiv.org/abs/2508.12977)
*Rohan Asthana,Joschua Conrad,Maurits Ortmanns,Vasileios Belagiannis*

Main category: cs.CV

TL;DR: 本文提出了一种新的零成本 NAS 代理，该代理不需要标签数据，并考虑了收敛性、泛化性和表达性。该代理利用奇异值分解和外部曲率，并在多个基准测试和搜索空间中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的零样本神经架构搜索（NAS）代理通常依赖于标签数据，而在实际环境中，这些数据通常是不可用的。此外，当前大多数方法要么侧重于优化收敛性和泛化性，要么仅侧重于网络架构的表达性。为了解决这些限制，本文旨在开发一种不需要标签数据的零成本代理，并同时考虑收敛性、泛化性和表达性。

Method: 该方法首先论证了通道共线性如何影响神经网络的收敛性和泛化能力。然后，通过整合收敛性、泛化性和表达性，提出了一种零成本代理，该代理在计算中不需要标签数据。具体来说，利用了神经网络层特征的奇异值分解（SVD）和网络输出的外部曲率来设计代理。该代理被简化为两个关键组成部分的对数调和平均值：特征条件数倒数之和以及网络输出的外部曲率。

Result: 该方法在 NAS-Bench-101、NAS-Bench-201 和 TransNAS-Bench-101-micro 等多个相关性基准测试以及 DARTS 和 AutoFormer 搜索空间中的 NAS 任务上均取得了优越的性能，同时保持了高效率。

Conclusion: 所提出的代理通过利用神经网络层特征的奇异值分解（SVD）和网络输出的外部曲率，能够使用单个无标签数据样本准确预测网络在测试数据上的性能。该方法在包括 CNN 和 Transformer 搜索空间在内的多个相关性基准测试以及 DARTS 和 AutoFormer 搜索空间中的 NAS 任务上均表现出优越的性能，并且效率高。

Abstract: Zero-shot Neural Architecture Search (NAS) typically optimises the
architecture search process by exploiting the network or gradient properties at
initialisation through zero-cost proxies. The existing proxies often rely on
labelled data, which is usually unavailable in real-world settings.
Furthermore, the majority of the current methods focus either on optimising the
convergence and generalisation attributes or solely on the expressivity of the
network architectures. To address both limitations, we first demonstrate how
channel collinearity affects the convergence and generalisation properties of a
neural network. Then, by incorporating the convergence, generalisation and
expressivity in one approach, we propose a zero-cost proxy that omits the
requirement of labelled data for its computation. In particular, we leverage
the Singular Value Decomposition (SVD) of the neural network layer features and
the extrinsic curvature of the network output to design our proxy. %As a
result, the proposed proxy is formulated as the simplified harmonic mean of the
logarithms of two key components: the sum of the inverse of the feature
condition number and the extrinsic curvature of the network output. Our
approach enables accurate prediction of network performance on test data using
only a single label-free data sample. Our extensive evaluation includes a total
of six experiments, including the Convolutional Neural Network (CNN) search
space, i.e. DARTS and the Transformer search space, i.e. AutoFormer. The
proposed proxy demonstrates a superior performance on multiple correlation
benchmarks, including NAS-Bench-101, NAS-Bench-201, and
TransNAS-Bench-101-micro; as well as on the NAS task within the DARTS and the
AutoFormer search space, all while being notably efficient. The code is
available at https://github.com/rohanasthana/Dextr.

</details>


### [141] [Omni Survey for Multimodality Analysis in Visual Object Tracking](https://arxiv.org/abs/2508.13000)
*Zhangyong Tang,Tianyang Xu,Xuefeng Zhu,Hui Li,Shaochuan Zhao,Tao Zhou,Chunyang Cheng,Xiaojun Wu,Josef Kittler*

Main category: cs.CV

TL;DR: 本文对多模态视觉对象跟踪（MMVOT）进行了全面的调查，涵盖了数据收集、模态对齐、模型设计和评估等方面。研究发现MMVOT数据集存在长尾分布问题，动物类别匮乏。 bangle.


<details>
  <summary>Details</summary>
Motivation: 智能城市的发展产生了海量的多模态数据，用于全面的监控智能城市的基础设施和服务。多模态视觉对象跟踪（MMVOT）是其中一项关键任务，本文旨在从多模态分析的角度对其进行调研。

Method: 本文首先介绍了相关数据模态，然后讨论了多模态数据收集、对齐和标注的挑战。接着，根据处理可见光（RGB）和X模态的不同方式，对现有的MMVOT方法进行了分类。最后，讨论了评估和基准测试问题。

Result: 本研究对MMVOT进行了全面的调查，识别了该领域数据收集、模态对齐、标注、模型设计和评估方面的四个关键区别。发现了现有MMVOT数据集中对象类别的长尾分布，并且与RGB数据集相比，动物类别明显缺失。

Conclusion: 本文对多模态视觉对象跟踪（MMVOT）进行了全面的调查，涵盖了六个MMVOT任务和338篇参考文献。研究了多模态跟踪是否总是优于单模态跟踪，以及其应用的有利条件。此外，还分析了现有MMVOT数据集中对象类别的分布，揭示了其长尾特性和与RGB数据集相比动物类别明显缺失的问题。

Abstract: The development of smart cities has led to the generation of massive amounts
of multi-modal data in the context of a range of tasks that enable a
comprehensive monitoring of the smart city infrastructure and services. This
paper surveys one of the most critical tasks, multi-modal visual object
tracking (MMVOT), from the perspective of multimodality analysis. Generally,
MMVOT differs from single-modal tracking in four key aspects, data collection,
modality alignment and annotation, model designing, and evaluation.
Accordingly, we begin with an introduction to the relevant data modalities,
laying the groundwork for their integration. This naturally leads to a
discussion of challenges of multi-modal data collection, alignment, and
annotation. Subsequently, existing MMVOT methods are categorised, based on
different ways to deal with visible (RGB) and X modalities: programming the
auxiliary X branch with replicated or non-replicated experimental
configurations from the RGB branch. Here X can be thermal infrared (T), depth
(D), event (E), near infrared (NIR), language (L), or sonar (S). The final part
of the paper addresses evaluation and benchmarking. In summary, we undertake an
omni survey of all aspects of multi-modal visual object tracking (VOT),
covering six MMVOT tasks and featuring 338 references in total. In addition, we
discuss the fundamental rhetorical question: Is multi-modal tracking always
guaranteed to provide a superior solution to unimodal tracking with the help of
information fusion, and if not, in what circumstances its application is
beneficial. Furthermore, for the first time in this field, we analyse the
distributions of the object categories in the existing MMVOT datasets,
revealing their pronounced long-tail nature and a noticeable lack of animal
categories when compared with RGB datasets.

</details>


### [142] [Empirical Evidences for the Effects of Feature Diversity in Open Set Recognition and Continual Learning](https://arxiv.org/abs/2508.13005)
*Jiawen Xu,Odej Kao*

Main category: cs.CV

TL;DR: Feature diversity is important for open set recognition and continual learning.


<details>
  <summary>Details</summary>
Motivation: To address the critical challenges of open set recognition (OSR) and continual learning by examining the role of feature diversity, which has been heuristically promoted but not directly studied.

Method: Empirical evidence is provided to demonstrate the positive impact of enhancing feature diversity on open set recognition and continual learning.

Result: Increased feature diversity was found to improve the recognition of open set samples, as well as facilitate both the retention of previously learned data and the integration of new data in continual learning.

Conclusion: Enhancing feature diversity improves open set recognition and facilitates both data retention and integration in continual learning, suggesting it as a key factor for further research in these domains.

Abstract: Open set recognition (OSR) and continual learning are two critical challenges
in machine learning, focusing respectively on detecting novel classes at
inference time and updating models to incorporate the new classes. While many
recent approaches have addressed these problems, particularly OSR, by
heuristically promoting feature diversity, few studies have directly examined
the role that feature diversity plays in tackling them. In this work, we
provide empirical evidence that enhancing feature diversity improves the
recognition of open set samples. Moreover, increased feature diversity also
facilitates both the retention of previously learned data and the integration
of new data in continual learning. We hope our findings can inspire further
research into both practical methods and theoretical understanding in these
domains.

</details>


### [143] [SlimComm: Doppler-Guided Sparse Queries for Bandwidth-Efficient Cooperative 3-D Perception](https://arxiv.org/abs/2508.13007)
*Melih Yazgan,Qiyuan Wu,Iramm Hamdard,Shiqi Li,J. Marius Zoellner*

Main category: cs.CV

TL;DR: SlimComm 通过整合 4D 雷达和查询驱动的稀疏方案，在通信效率和准确性之间取得了良好平衡，显著降低了自动驾驶汽车之间共享 BEV 特征图所需的带宽。


<details>
  <summary>Details</summary>
Motivation: 为了解决连接的自动驾驶汽车 (CAVs) 在共享中间特征以克服遮挡和有限传感器范围时，传输密集的鸟瞰 (BEV) 特征图会压倒车辆间通信可用带宽的问题。

Method: SlimComm 框架集成了 4D 雷达多普勒和查询驱动的稀疏方案。它构建了一个以运动为中心的动态地图来区分运动和静态物体，并生成两种查询类型：(i) 动态和高置信度区域上的参考查询，(ii) 通过两阶段偏移探测遮挡区域的探索性查询。通过多尺度门控变形注意力交换和融合特定于查询的 BEV 特征。

Result: SlimComm 在各种交通密度和遮挡情况下，带宽使用率比全图共享降低高达 90%，同时在准确性方面达到或超过了现有基线。该研究发布了 OPV2V-R 和 Adver-City-R 数据集，其中包含每点多普勒雷达。

Conclusion: SlimComm 在不同交通密度和遮挡情况下，带宽使用率比全图共享降低高达 90%，同时在准确性方面达到或超过了现有基线。

Abstract: Collaborative perception allows connected autonomous vehicles (CAVs) to
overcome occlusion and limited sensor range by sharing intermediate features.
Yet transmitting dense Bird's-Eye-View (BEV) feature maps can overwhelm the
bandwidth available for inter-vehicle communication. We present SlimComm, a
communication-efficient framework that integrates 4D radar Doppler with a
query-driven sparse scheme. SlimComm builds a motion-centric dynamic map to
distinguish moving from static objects and generates two query types: (i)
reference queries on dynamic and high-confidence regions, and (ii) exploratory
queries probing occluded areas via a two-stage offset. Only query-specific BEV
features are exchanged and fused through multi-scale gated deformable
attention, reducing payload while preserving accuracy. For evaluation, we
release OPV2V-R and Adver-City-R, CARLA-based datasets with per-point Doppler
radar. SlimComm achieves up to 90% lower bandwidth than full-map sharing while
matching or surpassing prior baselines across varied traffic densities and
occlusions. Dataset and code will be available at: https://url.fzi.de/SlimComm.

</details>


### [144] [Matrix-Game 2.0: An Open-Source, Real-Time, and Streaming Interactive World Model](https://arxiv.org/abs/2508.13009)
*Xianglong He,Chunli Peng,Zexiang Liu,Boyang Wang,Yifan Zhang,Qi Cui,Fei Kang,Biao Jiang,Mengyin An,Yangyang Ren,Baixin Xu,Hao-Xiang Guo,Kaixiong Gong,Cyrus Wu,Wei Li,Xuchen Song,Yang Liu,Eric Li,Yahui Zhou*

Main category: cs.CV

TL;DR: Matrix Game 2.0 通过改进数据生产、动作注入和少步蒸馏技术，实现了实时（25 FPS）、高质量、分钟级交互式视频生成，解决了现有模型实时性差的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的交互式视频生成模型依赖于双向注意力和较长的推理步骤，这严重限制了它们的实时性能，难以模拟真实世界中需要根据历史背景和当前动作即时更新结果的动态。因此，需要开发能够实时生成交互式视频的模型。

Method: 提出了一种名为 Matrix-Game 2.0 的交互式世界模型，该模型利用了三项关键技术：1. 扩展性强的数据生产流程，在虚幻引擎和 GTA5 环境中生成了约 1200 小时的包含丰富交互注释的视频数据；2. 动作注入模块，能够将帧级别的鼠标和键盘输入作为交互条件；3. 基于因果架构的少步蒸馏，实现了实时流式视频生成。

Result: Matrix Game 2.0 能够跨越不同场景，生成高质量、分钟级的视频，并且实现了 25 FPS 的超快生成速度。

Conclusion: Matrix Game 2.0 成功实现了分钟级视频的实时生成，并在多样化场景下达到了 25 FPS 的超快速度，同时开源了模型权重和代码库，以推动交互式世界建模的研究。

Abstract: Recent advances in interactive video generations have demonstrated diffusion
model's potential as world models by capturing complex physical dynamics and
interactive behaviors. However, existing interactive world models depend on
bidirectional attention and lengthy inference steps, severely limiting
real-time performance. Consequently, they are hard to simulate real-world
dynamics, where outcomes must update instantaneously based on historical
context and current actions. To address this, we present Matrix-Game 2.0, an
interactive world model generates long videos on-the-fly via few-step
auto-regressive diffusion. Our framework consists of three key components: (1)
A scalable data production pipeline for Unreal Engine and GTA5 environments to
effectively produce massive amounts (about 1200 hours) of video data with
diverse interaction annotations; (2) An action injection module that enables
frame-level mouse and keyboard inputs as interactive conditions; (3) A few-step
distillation based on the casual architecture for real-time and streaming video
generation. Matrix Game 2.0 can generate high-quality minute-level videos
across diverse scenes at an ultra-fast speed of 25 FPS. We open-source our
model weights and codebase to advance research in interactive world modeling.

</details>


### [145] [EgoTwin: Dreaming Body and View in First Person](https://arxiv.org/abs/2508.13013)
*Jingqiao Xiu,Fangzhou Hong,Yicong Li,Mengze Li,Wentao Wang,Sirui Han,Liang Pan,Ziwei Liu*

Main category: cs.CV

TL;DR: EgoTwin is a new framework for generating egocentric videos and human motion simultaneously, addressing viewpoint alignment and causal interplay challenges using a diffusion transformer. Experiments show it's effective.


<details>
  <summary>Details</summary>
Motivation: Egocentric video generation is underexplored, requiring modeling of first-person view content and camera motion patterns from body movements. This work bridges the gap by introducing a joint egocentric video and human motion generation task.

Method: EgoTwin, a joint video-motion generation framework built on the diffusion transformer architecture, featuring a head-centric motion representation and a cybernetics-inspired interaction mechanism for causal interplay between video and motion.

Result: EgoTwin demonstrates effectiveness in aligning camera trajectory with head trajectory and synthesizing human motion causally with visual dynamics. Comprehensive evaluation using a curated dataset and novel metrics confirms its performance.

Conclusion: The EgoTwin framework is effective for joint egocentric video and human motion generation, as demonstrated by extensive experiments.

Abstract: While exocentric video synthesis has achieved great progress, egocentric
video generation remains largely underexplored, which requires modeling
first-person view content along with camera motion patterns induced by the
wearer's body movements. To bridge this gap, we introduce a novel task of joint
egocentric video and human motion generation, characterized by two key
challenges: 1) Viewpoint Alignment: the camera trajectory in the generated
video must accurately align with the head trajectory derived from human motion;
2) Causal Interplay: the synthesized human motion must causally align with the
observed visual dynamics across adjacent video frames. To address these
challenges, we propose EgoTwin, a joint video-motion generation framework built
on the diffusion transformer architecture. Specifically, EgoTwin introduces a
head-centric motion representation that anchors the human motion to the head
joint and incorporates a cybernetics-inspired interaction mechanism that
explicitly captures the causal interplay between video and motion within
attention operations. For comprehensive evaluation, we curate a large-scale
real-world dataset of synchronized text-video-motion triplets and design novel
metrics to assess video-motion consistency. Extensive experiments demonstrate
the effectiveness of the EgoTwin framework.

</details>


### [146] [HierAdaptMR: Cross-Center Cardiac MRI Reconstruction with Hierarchical Feature Adapters](https://arxiv.org/abs/2508.13026)
*Ruru Xu,Ilkay Oksuz*

Main category: cs.CV

TL;DR: HierAdaptMR是一个分层特征自适应框架，通过协议级、中心级和通用适配器解决了跨临床中心部署的深度学习心脏MRI重建中的域漂移问题，并在CMRxRecon2025数据集上实现了卓越的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 深度学习驱动的磁共振成像（MRI）重建在跨多个临床中心部署时，面临着由异构扫描仪配置和成像协议引起的显著域漂移挑战。

Method: HierAdaptMR是一个分层特征自适应框架，通过参数高效的适配器解决多层次的域变化。该方法采用协议级适配器处理序列特定特征，并采用中心级适配器处理依赖于扫描仪的变异，这些适配器构建在变分展开骨干之上。通用适配器通过学习中心不变性自适应的随机训练，实现了对完全未见中心的泛化。该框架利用多尺度SSIM损失，并结合了频域增强和对比度自适应加权以实现稳健优化。

Result: HierAdaptMR框架实现了卓越的跨中心泛化能力，同时保持了重建质量。

Conclusion: HierAdaptMR框架在CMRxRecon2025数据集上进行了全面评估，该数据集涵盖了5个以上中心、10个以上扫描仪和9种模态，证明了其在保持重建质量的同时具有卓越的跨中心泛化能力。

Abstract: Deep learning-based cardiac MRI reconstruction faces significant domain shift
challenges when deployed across multiple clinical centers with heterogeneous
scanner configurations and imaging protocols. We propose HierAdaptMR, a
hierarchical feature adaptation framework that addresses multi-level domain
variations through parameter-efficient adapters. Our method employs
Protocol-Level Adapters for sequence-specific characteristics and Center-Level
Adapters for scanner-dependent variations, built upon a variational unrolling
backbone. A Universal Adapter enables generalization to entirely unseen centers
through stochastic training that learns center-invariant adaptations. The
framework utilizes multi-scale SSIM loss with frequency domain enhancement and
contrast-adaptive weighting for robust optimization. Comprehensive evaluation
on the CMRxRecon2025 dataset spanning 5+ centers, 10+ scanners, and 9
modalities demonstrates superior cross-center generalization while maintaining
reconstruction quality. code: https://github.com/Ruru-Xu/HierAdaptMR

</details>


### [147] [IntelliCap: Intelligent Guidance for Consistent View Sampling](https://arxiv.org/abs/2508.13043)
*Ayaka Yasunaga,Hideo Saito,Dieter Schmalstieg,Shohei Mori*

Main category: cs.CV

TL;DR: 本研究提出了一种新的扫描可视化技术，通过利用AI识别关键物体并生成引导，来帮助用户更有效地采集新视角合成所需的图像，提升了采集效率和效果。


<details>
  <summary>Details</summary>
Motivation: 虽然新视角合成（例如使用3D高斯泼射）取得了巨大进展，渲染保真度和速度已能满足苛刻的虚拟现实应用，但辅助人类采集输入图像的问题却很少受到关注。高质量的新视角合成需要均匀且密集的视角采样，这对于仓促、缺乏耐心或不了解场景结构和摄影过程的人类摄像师来说是难以实现的。现有方法在指导图像采集时，要么侧重于单个物体，要么忽略了视点相关的材质特性。

Method: 本研究提出了一种新颖的、用于扫描的、多尺度的可视化技术。在扫描场景的过程中，该方法识别出需要扩展图像覆盖以正确表示视点相关外观的关键物体。为了实现这一点，我们利用语义分割和类别识别，并辅以视觉-语言模型进行排名。针对排名靠前的物体，我们会生成球面代理来指导用户在扫描过程中进行操作。

Result: 与传统的视角采样策略相比，本研究提出的方法在真实场景中表现出更优越的性能。

Conclusion: 本研究提出了一种新的扫描可视化技术，可在多尺度扫描中辅助人类进行图像采集，以满足新视角合成的需求。该技术通过利用语义分割、类别识别和视觉语言模型来识别需要重点关注的物体，并生成球形代理以指导用户完成扫描过程。实验结果表明，与传统的视角采样策略相比，该方法在真实场景中表现更优。

Abstract: Novel view synthesis from images, for example, with 3D Gaussian splatting,
has made great progress. Rendering fidelity and speed are now ready even for
demanding virtual reality applications. However, the problem of assisting
humans in collecting the input images for these rendering algorithms has
received much less attention. High-quality view synthesis requires uniform and
dense view sampling. Unfortunately, these requirements are not easily addressed
by human camera operators, who are in a hurry, impatient, or lack understanding
of the scene structure and the photographic process. Existing approaches to
guide humans during image acquisition concentrate on single objects or neglect
view-dependent material characteristics. We propose a novel situated
visualization technique for scanning at multiple scales. During the scanning of
a scene, our method identifies important objects that need extended image
coverage to properly represent view-dependent appearance. To this end, we
leverage semantic segmentation and category identification, ranked by a
vision-language model. Spherical proxies are generated around highly ranked
objects to guide the user during scanning. Our results show superior
performance in real scenes compared to conventional view sampling strategies.

</details>


### [148] [Odo: Depth-Guided Diffusion for Identity-Preserving Body Reshaping](https://arxiv.org/abs/2508.13065)
*Siddharth Khandelwal,Sridhar Kamath,Arjun Jain*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Human shape editing enables controllable transformation of a person's body
shape, such as thin, muscular, or overweight, while preserving pose, identity,
clothing, and background. Unlike human pose editing, which has advanced
rapidly, shape editing remains relatively underexplored. Current approaches
typically rely on 3D morphable models or image warping, often introducing
unrealistic body proportions, texture distortions, and background
inconsistencies due to alignment errors and deformations. A key limitation is
the lack of large-scale, publicly available datasets for training and
evaluating body shape manipulation methods. In this work, we introduce the
first large-scale dataset of 18,573 images across 1523 subjects, specifically
designed for controlled human shape editing. It features diverse variations in
body shape, including fat, muscular and thin, captured under consistent
identity, clothing, and background conditions. Using this dataset, we propose
Odo, an end-to-end diffusion-based method that enables realistic and intuitive
body reshaping guided by simple semantic attributes. Our approach combines a
frozen UNet that preserves fine-grained appearance and background details from
the input image with a ControlNet that guides shape transformation using target
SMPL depth maps. Extensive experiments demonstrate that our method outperforms
prior approaches, achieving per-vertex reconstruction errors as low as 7.5mm,
significantly lower than the 13.6mm observed in baseline methods, while
producing realistic results that accurately match the desired target shapes.

</details>


### [149] [Eyes on the Image: Gaze Supervised Multimodal Learning for Chest X-ray Diagnosis and Report Generation](https://arxiv.org/abs/2508.13068)
*Tanjim Islam Riju,Shuchismita Anwar,Saman Sarker Joy,Farig Sadeque,Swakkhar Shatabda*

Main category: cs.CV

TL;DR: This paper presents a two-stage framework using eye-tracking data to improve both disease classification and radiology report generation from chest X-rays. The method enhances F1 score and AUC for classification and improves report quality metrics like keyword recall and ROUGE overlap, demonstrating the value of gaze data for medical imaging analysis and report generation.


<details>
  <summary>Details</summary>
Motivation: To enhance disease classification and region-aware radiology report generation from chest X-rays by leveraging radiologist eye-tracking signals.

Method: A two-stage multimodal framework is proposed. The first stage uses a gaze-guided contrastive learning architecture with a multi-term gaze-attention loss combining MSE, KL divergence, correlation, and center-of-mass alignment. The second stage employs a modular report generation pipeline involving confidence-weighted keyword extraction, mapping to anatomical regions using a domain-specific dictionary, and generating region-aligned sentences via structured prompts.

Result: The first stage improved F1 score from 0.597 to 0.631 (+5.70%) and AUC from 0.821 to 0.849 (+3.41%) for disease classification. The second stage improved report quality as measured by clinical keyword recall and ROUGE overlap.

Conclusion: The integration of gaze data into the proposed two-stage multimodal framework enhances both disease classification performance and the interpretability of generated medical reports.

Abstract: We propose a two-stage multimodal framework that enhances disease
classification and region-aware radiology report generation from chest X-rays,
leveraging the MIMIC-Eye dataset. In the first stage, we introduce a
gaze-guided contrastive learning architecture for disease classification. It
integrates visual features, clinical labels, bounding boxes, and radiologist
eye-tracking signals and is equipped with a novel multi-term gaze-attention
loss combining MSE, KL divergence, correlation, and center-of-mass alignment.
Incorporating fixations improves F1 score from 0.597 to 0.631 (+5.70%) and AUC
from 0.821 to 0.849 (+3.41%), while also improving precision and recall,
highlighting the effectiveness of gaze-informed attention supervision. In the
second stage, we present a modular report generation pipeline that extracts
confidence-weighted diagnostic keywords, maps them to anatomical regions using
a curated dictionary constructed from domain-specific priors, and generates
region-aligned sentences via structured prompts. This pipeline improves report
quality as measured by clinical keyword recall and ROUGE overlap. Our results
demonstrate that integrating gaze data improves both classification performance
and the interpretability of generated medical reports.

</details>


### [150] [ID-Card Synthetic Generation: Toward a Simulated Bona fide Dataset](https://arxiv.org/abs/2508.13078)
*Qingwen Zeng,Juan E. Tapia,Izan Garcia,Juan M. Espin,Christoph Busch*

Main category: cs.CV

TL;DR: 该研究利用Stable Diffusion技术生成逼真的虚假ID卡图像，以增强演示攻击检测（PAD）系统的鲁棒性，并取得了积极成果。


<details>
  <summary>Details</summary>
Motivation: 为了解决ID卡演示攻击检测（PAD）系统中存在的模型泛化能力不足和攻击工具多样性增加的问题，该研究旨在通过生成更具代表性的虚假样本来增强模型的鲁棒性。

Method: 使用Stable Diffusion生成和模仿的身份卡中的虚假信息，并评估新生成的图像在从头开始训练的系统和商业解决方案中的表现。

Result: 生成的虚假样本被PAD系统识别为真实样本，在模型泛化能力和数据限制方面均有积极影响。

Conclusion: 该PAD系统将生成的图像识别为真实图像，在检测性能和数据限制方面均有积极影响。

Abstract: Nowadays, the development of a Presentation Attack Detection (PAD) system for
ID cards presents a challenge due to the lack of images available to train a
robust PAD system and the increase in diversity of possible attack instrument
species. Today, most algorithms focus on generating attack samples and do not
take into account the limited number of bona fide images. This work is one of
the first to propose a method for mimicking bona fide images by generating
synthetic versions of them using Stable Diffusion, which may help improve the
generalisation capabilities of the detector. Furthermore, the new images
generated are evaluated in a system trained from scratch and in a commercial
solution. The PAD system yields an interesting result, as it identifies our
images as bona fide, which has a positive impact on detection performance and
data restrictions.

</details>


### [151] [Checkmate: interpretable and explainable RSVQA is the endgame](https://arxiv.org/abs/2508.13086)
*Lucrezia Tosato,Christel Tartini Chappuis,Syrielle Montariol,Flora Weissgerber,Sylvain Lobry,Devis Tuia*

Main category: cs.CV

TL;DR: 本研究提出了Chessboard数据集和Checkmate模型，以解决遥感视觉问答中的可解释性和偏见问题，提高了系统的透明度和可信度。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有遥感视觉问答模型可解释性和可信度不足，以及数据集分布偏差导致的捷径学习问题。

Method: 提出了一种名为Checkboard的新型遥感视觉问答数据集，包含3,123,253个问题和均衡的答案分布，并将答案与图像中的特定单元格关联，以实现细粒度的视觉推理。同时，开发了一个名为Checkmate的可解释模型，能够识别与模型决策最相关的图像单元格。

Result: 通过在多个模型架构上进行的大量实验证明，该方法提高了透明度，并支持了更值得信赖的遥感视觉问答系统决策。

Conclusion: 该研究提出的Checkmate模型通过提供模型决策的解释性和可解释性，以及利用Chessboard数据集解决数据集偏差问题，最终提升了遥感视觉问答系统的透明度和决策可信度。

Abstract: Remote Sensing Visual Question Answering (RSVQA) presents unique challenges
in ensuring that model decisions are both understandable and grounded in visual
content. Current models often suffer from a lack of interpretability and
explainability, as well as from biases in dataset distributions that lead to
shortcut learning. In this work, we tackle these issues by introducing a novel
RSVQA dataset, Chessboard, designed to minimize biases through 3'123'253
questions and a balanced answer distribution. Each answer is linked to one or
more cells within the image, enabling fine-grained visual reasoning.
  Building on this dataset, we develop an explainable and interpretable model
called Checkmate that identifies the image cells most relevant to its
decisions. Through extensive experiments across multiple model architectures,
we show that our approach improves transparency and supports more trustworthy
decision-making in RSVQA systems.

</details>


### [152] [DMS:Diffusion-Based Multi-Baseline Stereo Generation for Improving Self-Supervised Depth Estimation](https://arxiv.org/abs/2508.13091)
*Zihua Liu,Yizhou Li,Songyan Zhang,Masatoshi Okutomi*

Main category: cs.CV

TL;DR: DMS 是一种创新的即插即用方法，利用扩散模型合成新视图，解决了自监督立体匹配和单目深度估计中的遮挡问题，效果显著。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的立体匹配和单目深度估计方法虽然取得了显著进展，但利用立体图像作为监督信号的自监督方法受到的关注相对较少，并且需要进一步研究。主要挑战在于光度重建过程中引入的模糊性，特别是在目标视图的病态区域（如遮挡和帧外区域）中缺失对应的像素。

Method: 提出了一种名为 DMS 的模型无关方法，该方法利用扩散模型的几何先验，通过定向提示沿极线方向合成新视图。具体来说，对 Stable Diffusion 模型进行微调，在关键位置模拟视角：从左相机偏移的左-左视图，从右相机偏移的右-右视图，以及介于左右相机之间的一个额外的新视图。这些合成的视图补充了被遮挡的像素，实现了显式的光度重建。

Result: 实验表明，DMS 方法有效，在多个基准数据集上取得了最先进的性能，异常值减少高达 35%。

Conclusion: DMS 是一种模型无关的方法，利用来自扩散模型的几何先验，通过定向提示沿极线方向合成新视图，以解决光度重建中的模糊性问题，能够弥补遮挡区域的像素，从而实现显式的光度重建。该方法是免费的、“即插即用”的，仅使用未标记的立体图像对进行训练和合成，可用于增强自监督立体匹配和单目深度估计。实验证明了该方法的有效性，在多个基准数据集上取得了最先进的性能，异常值减少多达 35%。

Abstract: While supervised stereo matching and monocular depth estimation have advanced
significantly with learning-based algorithms, self-supervised methods using
stereo images as supervision signals have received relatively less focus and
require further investigation. A primary challenge arises from ambiguity
introduced during photometric reconstruction, particularly due to missing
corresponding pixels in ill-posed regions of the target view, such as
occlusions and out-of-frame areas. To address this and establish explicit
photometric correspondences, we propose DMS, a model-agnostic approach that
utilizes geometric priors from diffusion models to synthesize novel views along
the epipolar direction, guided by directional prompts. Specifically, we
finetune a Stable Diffusion model to simulate perspectives at key positions:
left-left view shifted from the left camera, right-right view shifted from the
right camera, along with an additional novel view between the left and right
cameras. These synthesized views supplement occluded pixels, enabling explicit
photometric reconstruction. Our proposed DMS is a cost-free, ''plug-and-play''
method that seamlessly enhances self-supervised stereo matching and monocular
depth estimation, and relies solely on unlabeled stereo image pairs for both
training and synthesizing. Extensive experiments demonstrate the effectiveness
of our approach, with up to 35% outlier reduction and state-of-the-art
performance across multiple benchmark datasets.

</details>


### [153] [Real-Time Beach Litter Detection and Counting: A Comparative Analysis of RT-DETR Model Variants](https://arxiv.org/abs/2508.13101)
*Miftahul Huda,Arsyiah Azahra,Putri Maulida Chairani,Dimas Rizky Ramadhani,Nabila Azhari,Ade Lailani*

Main category: cs.CV

TL;DR: RT-DETR-L在检测海滩垃圾方面，速度比RT-DETR-X快，准确性略低，但更适合实际应用。


<details>
  <summary>Details</summary>
Motivation: 为了解决沿海污染问题，需要可扩展和自动化的监测管理解决方案。本研究旨在评估先进的目标检测模型RT-DETR在自动检测和计数海滩垃圾方面的有效性。

Method: 本研究采用RT-DETR（包括RT-DETR-Large和RT-DETR-Extra-Large）模型，对公开的海岸垃圾数据集进行训练和评估，旨在实现海滩垃圾的自动检测和计数。

Result: RT-DETR-X模型在准确性方面略有优势（mAP@50为0.816，mAP@50-95为0.612），但RT-DETR-L模型的推理速度更快（20.1毫秒 vs 34.5毫秒），计算成本更低。

Conclusion: RT-DETR-L模型在处理速度和检测准确性之间取得了更好的平衡，为实时现场部署提供了更实际、更有效的解决方案。

Abstract: Coastal pollution is a pressing global environmental issue, necessitating
scalable and automated solutions for monitoring and management. This study
investigates the efficacy of the Real-Time Detection Transformer (RT-DETR), a
state-of-the-art, end-to-end object detection model, for the automated
detection and counting of beach litter. A rigorous comparative analysis is
conducted between two model variants, RT-DETR-Large (RT-DETR-L) and
RT-DETR-Extra-Large (RT-DETR-X), trained on a publicly available dataset of
coastal debris. The evaluation reveals that the RT-DETR-X model achieves
marginally superior accuracy, with a mean Average Precision at 50\% IoU
(mAP@50) of 0.816 and a mAP@50-95 of 0.612, compared to the RT-DETR-L model's
0.810 and 0.606, respectively. However, this minor performance gain is realized
at a significant computational cost; the RT-DETR-L model demonstrates a
substantially faster inference time of 20.1 ms versus 34.5 ms for the
RT-DETR-X. The findings suggest that the RT-DETR-L model offers a more
practical and efficient solution for real-time, in-field deployment due to its
superior balance of processing speed and detection accuracy. This research
provides valuable insights into the application of advanced Transformer-based
detectors for environmental conservation, highlighting the critical trade-offs
between model complexity and operational viability.

</details>


### [154] [Motion2Motion: Cross-topology Motion Transfer with Sparse Correspondence](https://arxiv.org/abs/2508.13139)
*Ling-Hao Chen,Yuhong Zhang,Zixin Yin,Zhiyang Dou,Xin Chen,Jingbo Wang,Taku Komura,Lei Zhang*

Main category: cs.CV

TL;DR: Motion2Motion 是一个无需训练的框架，可以迁移不同拓扑结构的角色动作，仅需少量目标骨骼示例动作和稀疏骨骼对应关系。


<details>
  <summary>Details</summary>
Motivation: 当前的动作迁移技术在处理具有显著骨骼拓扑差异的角色时面临挑战，主要由于拓扑不一致性阻碍了一对一的骨骼对应，并且缺乏跨拓扑结构的大规模配对运动数据集。

Method: 提出了一种名为 Motion2Motion 的新颖、无需训练的框架，该框架仅需目标骨骼上的一到两个示例动作，并通过访问源骨骼和目标骨骼之间稀疏的骨骼对应关系来实现。

Result: 通过全面的定性和定量评估，证明了 Motion2Motion 在处理具有挑战性的动作迁移任务方面的有效性。

Conclusion: Motion2Motion 框架在相似骨骼和跨物种骨骼迁移场景中均实现了高效可靠的性能，并在下游应用和用户界面中得到了成功验证，显示出其在工业应用中的潜力。

Abstract: This work studies the challenge of transfer animations between characters
whose skeletal topologies differ substantially. While many techniques have
advanced retargeting techniques in decades, transfer motions across diverse
topologies remains less-explored. The primary obstacle lies in the inherent
topological inconsistency between source and target skeletons, which restricts
the establishment of straightforward one-to-one bone correspondences. Besides,
the current lack of large-scale paired motion datasets spanning different
topological structures severely constrains the development of data-driven
approaches. To address these limitations, we introduce Motion2Motion, a novel,
training-free framework. Simply yet effectively, Motion2Motion works with only
one or a few example motions on the target skeleton, by accessing a sparse set
of bone correspondences between the source and target skeletons. Through
comprehensive qualitative and quantitative evaluations, we demonstrate that
Motion2Motion achieves efficient and reliable performance in both
similar-skeleton and cross-species skeleton transfer scenarios. The practical
utility of our approach is further evidenced by its successful integration in
downstream applications and user interfaces, highlighting its potential for
industrial applications. Code and data are available at
https://lhchen.top/Motion2Motion.

</details>


### [155] [IGFuse: Interactive 3D Gaussian Scene Reconstruction via Multi-Scans Fusion](https://arxiv.org/abs/2508.13153)
*Wenhao Hu,Zesheng Li,Haonan Zhou,Liu Liu,Xuexiang Wen,Zhizhong Su,Xi Li,Gaoang Wang*

Main category: cs.CV

TL;DR: IGFuse是一个新的框架，通过融合多视角观测来重建3D高斯场景，即使在存在遮挡或传感器覆盖有限的情况下也能实现高保真渲染和场景操作。


<details>
  <summary>Details</summary>
Motivation: 解决重建完整和交互式3D场景的挑战，特别是由于物体遮挡和传感器覆盖有限的问题，现有方法通常包含易出错且难以扩展的多阶段流程或需要逐对象密集扫描。

Method: IGFuse框架通过融合多视角观测，构建分割感知高斯场，并强制跨视角的双向光度和语义一致性。为了处理空间不对齐，提出了一种伪中间场景状态以实现统一对齐，并结合协同联合修剪策略来优化几何。

Result: IGFuse框架能够从多个扫描中融合观测，并通过自然物体重排来揭示先前被遮挡的区域，从而重建交互式高斯场景。

Conclusion: IGFuse框架能够实现高保真渲染和对象级别的场景操作，无需密集观测或复杂流程，并在各种场景配置中表现出强大的泛化能力，有效应用于真实世界的3D重建和真实到模拟的转移。

Abstract: Reconstructing complete and interactive 3D scenes remains a fundamental
challenge in computer vision and robotics, particularly due to persistent
object occlusions and limited sensor coverage. Multiview observations from a
single scene scan often fail to capture the full structural details. Existing
approaches typically rely on multi stage pipelines, such as segmentation,
background completion, and inpainting or require per-object dense scanning,
both of which are error-prone, and not easily scalable. We propose IGFuse, a
novel framework that reconstructs interactive Gaussian scene by fusing
observations from multiple scans, where natural object rearrangement between
captures reveal previously occluded regions. Our method constructs segmentation
aware Gaussian fields and enforces bi-directional photometric and semantic
consistency across scans. To handle spatial misalignments, we introduce a
pseudo-intermediate scene state for unified alignment, alongside collaborative
co-pruning strategies to refine geometry. IGFuse enables high fidelity
rendering and object level scene manipulation without dense observations or
complex pipelines. Extensive experiments validate the framework's strong
generalization to novel scene configurations, demonstrating its effectiveness
for real world 3D reconstruction and real-to-simulation transfer. Our project
page is available online.

</details>


### [156] [4DNeX: Feed-Forward 4D Generative Modeling Made Easy](https://arxiv.org/abs/2508.13154)
*Zhaoxi Chen,Tianqi Liu,Long Zhuo,Jiawei Ren,Zeng Tao,He Zhu,Fangzhou Hong,Liang Pan,Ziwei Liu*

Main category: cs.CV

TL;DR: 4DNeX 是首个从单张图像生成 4D 动态场景表示的即插即用框架，通过微调视频扩散模型实现高效端到端生成，并能合成新视角视频。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成 4D 场景表示方面计算成本高昂或需要多帧视频输入，因此需要一种更高效、更通用的方法。

Method: 1. 构建了一个包含高质量 4D 注释的大规模数据集 4DNeX-10M，以解决 4D 数据稀疏性问题。 2. 引入了一种统一的 6D 视频表示，联合建模 RGB 和 XYZ 序列，以实现外观和几何的结构化学习。 3. 提出了一系列改编策略，用于将预训练的视频扩散模型应用于 4D 建模。

Result: 4DNeX 在效率和泛化能力方面优于现有的 4D 生成方法，能够生成高质量的动态点云，并实现新视角视频合成。

Conclusion: 4DNeX 是一种高效、端到端的图像到 4D 生成框架，通过微调预训练的视频扩散模型来实现，可在单一图像输入下生成高质量的动态 3D 场景表示（如动态点云），并能进行新视角视频合成。

Abstract: We present 4DNeX, the first feed-forward framework for generating 4D (i.e.,
dynamic 3D) scene representations from a single image. In contrast to existing
methods that rely on computationally intensive optimization or require
multi-frame video inputs, 4DNeX enables efficient, end-to-end image-to-4D
generation by fine-tuning a pretrained video diffusion model. Specifically, 1)
to alleviate the scarcity of 4D data, we construct 4DNeX-10M, a large-scale
dataset with high-quality 4D annotations generated using advanced
reconstruction approaches. 2) we introduce a unified 6D video representation
that jointly models RGB and XYZ sequences, facilitating structured learning of
both appearance and geometry. 3) we propose a set of simple yet effective
adaptation strategies to repurpose pretrained video diffusion models for 4D
modeling. 4DNeX produces high-quality dynamic point clouds that enable
novel-view video synthesis. Extensive experiments demonstrate that 4DNeX
outperforms existing 4D generation methods in efficiency and generalizability,
offering a scalable solution for image-to-4D modeling and laying the foundation
for generative 4D world models that simulate dynamic scene evolution.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [157] [Deep Language Geometry: Constructing a Metric Space from LLM Weights](https://arxiv.org/abs/2508.11676)
*Maksym Shamrai,Vladyslav Hamolia*

Main category: cs.CL

TL;DR: 本研究利用LLM内部权重激活构建语言度量空间，自动提取语言特征，并在106种语言上验证了其有效性，发现了语系关系和潜在的语言演化联系。


<details>
  <summary>Details</summary>
Motivation: 与基于手工制作的语言特征的传统方法不同，本研究旨在自动捕捉反映语言现象的内在语言特征。

Method: 通过计算权重重要性分数来自动推导高维向量表示，该分数是通过改编的剪枝算法获得的。

Result: 该方法在涵盖106种语言的各种数据集和多语言LLM上进行了验证，结果与已建立的语系一致，并揭示了意想不到的语际联系，可能表明历史接触或语言演化。

Conclusion: 该研究提出了一个新颖的框架，利用大型语言模型（LLM）的内部权重激活来构建语言度量空间。

Abstract: We introduce a novel framework that utilizes the internal weight activations
of modern Large Language Models (LLMs) to construct a metric space of
languages. Unlike traditional approaches based on hand-crafted linguistic
features, our method automatically derives high-dimensional vector
representations by computing weight importance scores via an adapted pruning
algorithm. Our approach captures intrinsic language characteristics that
reflect linguistic phenomena. We validate our approach across diverse datasets
and multilingual LLMs, covering 106 languages. The results align well with
established linguistic families while also revealing unexpected inter-language
connections that may indicate historical contact or language evolution. The
source code, computed language latent vectors, and visualization tool are made
publicly available at https://github.com/mshamrai/deep-language-geometry.

</details>


### [158] [Can we Evaluate RAGs with Synthetic Data?](https://arxiv.org/abs/2508.11758)
*Jonas van Elburg,Peter van der Putten,Maarten Marx*

Main category: cs.CL

TL;DR: 合成问答数据在评估检索器配置方面效果良好，但评估生成器架构时效果不佳。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探讨当缺乏人类标注数据时，由大型语言模型（LLMs）生成的合成问答（QA）数据是否能有效替代人类标注的基准测试。

Method: 本研究通过两种实验来评估合成问答数据作为人类标注基准代理的可靠性：1. 保持生成器固定，改变检索器参数；2. 保持检索器固定，改变生成器。研究使用了两个公开领域和两个私有领域的数据集。

Result: 在检索器参数变化的情况下，合成数据能够可靠地对RAG模型进行排名，并且与人类标注基准的结果高度一致。但在生成器架构比较方面，合成数据无法产生一致的RAG排名。

Conclusion: 生成式AI（LLM）生成的合成问答（QA）数据在检索器参数变化时，可以作为评估检索增强生成（RAG）模型性能的有效代理，并且与人工标注的基准测试结果具有良好的一致性。然而，在比较不同生成器架构时，合成数据的排名结果不稳定，这可能是由于任务不匹配和生成器风格偏差造成的。

Abstract: We investigate whether synthetic question-answer (QA) data generated by large
language models (LLMs) can serve as an effective proxy for human-labeled
benchmarks when such data is unavailable. We assess the reliability of
synthetic benchmarks across two experiments: one varying retriever parameters
while keeping the generator fixed, and another varying the generator with fixed
retriever parameters. Across four datasets, of which two open-domain and two
proprietary, we find that synthetic benchmarks reliably rank the RAGs varying
in terms of retriever configuration, aligning well with human-labeled benchmark
baselines. However, they fail to produce consistent RAG rankings when comparing
generator architectures. The breakdown possibly arises from a combination of
task mismatch between the synthetic and human benchmarks, and stylistic bias
favoring certain generators.

</details>


### [159] [Limitation Learning: Catching Adverse Dialog with GAIL](https://arxiv.org/abs/2508.11767)
*Noah Kasmanoff,Rahul Zalkikar*

Main category: cs.CL

TL;DR: 模仿学习在对话中很有用，可以识别对话模型中的不良行为。


<details>
  <summary>Details</summary>
Motivation: 在没有奖励的情况下，通过利用专家演示来创建策略。

Method: 将模仿学习应用于对话，恢复了能够根据提示（输入状态）与用户交谈的策略，以及区分专家和合成对话的判别器。

Result: 恢复了有效的策略，并从判别器中恢复了表明对话模型局限性的结果。

Conclusion: 该技术可用于识别对话导向任务中常见的数据模型的不良行为。

Abstract: Imitation learning is a proven method for creating a policy in the absence of
rewards, by leveraging expert demonstrations. In this work, we apply imitation
learning to conversation. In doing so, we recover a policy capable of talking
to a user given a prompt (input state), and a discriminator capable of
classifying between expert and synthetic conversation. While our policy is
effective, we recover results from our discriminator that indicate the
limitations of dialog models. We argue that this technique can be used to
identify adverse behavior of arbitrary data models common for dialog oriented
tasks.

</details>


### [160] [Investigating Transcription Normalization in the Faetar ASR Benchmark](https://arxiv.org/abs/2508.11771)
*Leo Peckham,Michael Ong,Naomi Nagy,Ewan Dunbar*

Main category: cs.CL

TL;DR: Transcription errors aren't the main problem in the Faetar ASR benchmark. Constraining the lexicon helps, but language models don't. The task is still very hard.


<details>
  <summary>Details</summary>
Motivation: To examine the role of transcription inconsistencies in the Faetar Automatic Speech Recognition benchmark, a challenging low-resource ASR benchmark.

Method: We examine the role of transcription inconsistencies using a small, hand-constructed lexicon. We also demonstrate the impact of bigram word-based language modelling and constraining decoding to a finite lexicon.

Result: Transcription inconsistencies exist but are not the main challenge. Bigram word-based language modelling provides no added benefit, but lexicon-constrained decoding is beneficial. The task remains extremely difficult.

Conclusion: The transcriptions inconsistencies are not the main challenge in the task, and the task remains extremely difficult. Constraining decoding to a finite lexicon can be beneficial, while bigram word-based language modelling is of no added benefit.

Abstract: We examine the role of transcription inconsistencies in the Faetar Automatic
Speech Recognition benchmark, a challenging low-resource ASR benchmark. With
the help of a small, hand-constructed lexicon, we conclude that find that,
while inconsistencies do exist in the transcriptions, they are not the main
challenge in the task. We also demonstrate that bigram word-based language
modelling is of no added benefit, but that constraining decoding to a finite
lexicon can be beneficial. The task remains extremely difficult.

</details>


### [161] [A Multi-Task Evaluation of LLMs' Processing of Academic Text Input](https://arxiv.org/abs/2508.11779)
*Tianyi Li,Yu Qin,Olivia R. Liu Sheng*

Main category: cs.CL

TL;DR: LLM在学术同行评审中的应用潜力有限，目前不建议在同行评审中不受限制地使用LLM。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLM）在学术同行评审中的辅助潜力，介于文献摘要和研究助手之间。

Method: 评估LLM处理学术文本能力的四项任务：内容再现/比较/评分/反思，并对Google的Gemini模型进行了严格的性能评估。

Result: Gemini模型在文本摘要和释义方面表现尚可；在文本比较排序方面可扩展性差；在学术文本评分方面区分度差；在文本定性反思方面虽自我一致但缺乏启发性。

Conclusion: 不建议在同行评审中使用大型语言模型（LLM）。

Abstract: How much large language models (LLMs) can aid scientific discovery, notably
in assisting academic peer review, is in heated debate. Between a literature
digest and a human-comparable research assistant lies their practical
application potential. We organize individual tasks that computer science
studies employ in separate terms into a guided and robust workflow to evaluate
LLMs' processing of academic text input. We employ four tasks in the
assessment: content reproduction/comparison/scoring/reflection, each demanding
a specific role of the LLM (oracle/judgmental arbiter/knowledgeable
arbiter/collaborator) in assisting scholarly works, and altogether testing LLMs
with questions that increasingly require intellectual capabilities towards a
solid understanding of scientific texts to yield desirable solutions. We
exemplify a rigorous performance evaluation with detailed instructions on the
prompts. Adopting first-rate Information Systems articles at three top journals
as the input texts and an abundant set of text metrics, we record a compromised
performance of the leading LLM - Google's Gemini: its summary and paraphrase of
academic text is acceptably reliable; using it to rank texts through pairwise
text comparison is faintly scalable; asking it to grade academic texts is prone
to poor discrimination; its qualitative reflection on the text is
self-consistent yet hardly insightful to inspire meaningful research. This
evidence against an endorsement of LLMs' text-processing capabilities is
consistent across metric-based internal (linguistic assessment), external
(comparing to the ground truth), and human evaluation, and is robust to the
variations of the prompt. Overall, we do not recommend an unchecked use of LLMs
in constructing peer reviews.

</details>


### [162] [LLM-Guided Planning and Summary-Based Scientific Text Simplification: DS@GT at CLEF 2025 SimpleText](https://arxiv.org/abs/2508.11816)
*Krishna Chaitanya Marturi,Heba H. Elwazzan*

Main category: cs.CL

TL;DR: This paper presents an LLM-based approach for simplifying scientific text at sentence and document levels using structured plans and summaries to ensure coherence and context fidelity.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the CLEF 2025 SimpleText Task 1, focusing on scientific text simplification at both sentence and document levels.

Method: The methodology employs large language models (LLMs) for sentence-level simplification by first generating a structured plan and then performing plan-driven simplification. For document-level simplification, LLMs are used to produce concise summaries that guide the simplification process.

Result: The LLM-based framework enables more coherent and contextually faithful simplifications of scientific text.

Conclusion: The proposed LLM-based framework provides a two-stage approach for both sentence-level and document-level scientific text simplification, achieving coherent and contextually faithful results.

Abstract: In this paper, we present our approach for the CLEF 2025 SimpleText Task 1,
which addresses both sentence-level and document-level scientific text
simplification. For sentence-level simplification, our methodology employs
large language models (LLMs) to first generate a structured plan, followed by
plan-driven simplification of individual sentences. At the document level, we
leverage LLMs to produce concise summaries and subsequently guide the
simplification process using these summaries. This two-stage, LLM-based
framework enables more coherent and contextually faithful simplifications of
scientific text.

</details>


### [163] [Every 28 Days the AI Dreams of Soft Skin and Burning Stars: Scaffolding AI Agents with Hormones and Emotions](https://arxiv.org/abs/2508.11829)
*Leigh Levinson,Christopher J. Agostino*

Main category: cs.CL

TL;DR: 生物节律可以作为AI的相关性过滤器，影响LLM的情感和风格，并揭示模型中的偏见。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在解决人工智能系统在处理“帧问题”时遇到的挑战，即从指数级的可能性空间中确定上下文相关信息。研究人员假设生物节律，特别是激素周期，可以作为一种自然的“相关性过滤器”。

Method: 该研究提出了一种将模拟的月经周期和昼夜节律嵌入大型语言模型（LLMs）的框架。通过使用基于模拟关键激素（包括雌激素、睾酮和皮质醇）的周期性函数生成的系统提示来实现。

Result: 通过对多种先进模型进行分析，研究发现情感和风格的变化能够追踪生物节律的阶段，例如在月经期悲伤情绪达到顶峰，在排卵期则以快乐为主；昼夜节律模式则显示出早晨乐观情绪向夜晚内省的转变。在SQuAD、MMLU、Hellaswag和AI2-ARC基准测试中，模型性能也表现出与生物学预期一致的细微但持续的变化，尤其是在适中的激素水平范围内表现更佳。

Conclusion: 该研究提出了一种将模拟生物节律（特别是激素周期）嵌入大型语言模型的新颖方法，以解决人工智能中的“帧问题”。实验结果表明，这种方法能够引起语言模型在情感和风格上的周期性变化，并与生物学预期相符。此外，该研究还揭示了语言模型中存在的性别和生物学相关的社会偏见。

Abstract: Despite significant advances, AI systems struggle with the frame problem:
determining what information is contextually relevant from an exponentially
large possibility space. We hypothesize that biological rhythms, particularly
hormonal cycles, serve as natural relevance filters that could address this
fundamental challenge. We develop a framework that embeds simulated menstrual
and circadian cycles into Large Language Models through system prompts
generated from periodic functions modeling key hormones including estrogen,
testosterone, and cortisol. Across multiple state-of-the-art models, linguistic
analysis reveals emotional and stylistic variations that track biological
phases; sadness peaks during menstruation while happiness dominates ovulation
and circadian patterns show morning optimism transitioning to nocturnal
introspection. Benchmarking on SQuAD, MMLU, Hellaswag, and AI2-ARC demonstrates
subtle but consistent performance variations aligning with biological
expectations, including optimal function in moderate rather than extreme
hormonal ranges. This methodology provides a novel approach to contextual AI
while revealing how societal biases regarding gender and biology are embedded
within language models.

</details>


### [164] [Hallucination Detection and Mitigation in Scientific Text Simplification using Ensemble Approaches: DS@GT at CLEF 2025 SimpleText](https://arxiv.org/abs/2508.11823)
*Krishna Chaitanya Marturi,Heba H. Elwazzan*

Main category: cs.CL

TL;DR: This paper details a multi-strategy approach for the CLEF 2025 SimpleText Task 2, using BERT, semantic similarity, NLI, and LLM reasoning with meta-classifiers to detect distortions in text simplification, and employs LLM post-editing for accurate revisions.


<details>
  <summary>Details</summary>
Motivation: The paper aims to detect and evaluate creative generation and information distortion in scientific text simplification within the context of the CLEF 2025 SimpleText Task 2.

Method: The solution integrates multiple strategies including a BERT-based classifier, semantic similarity measure, natural language inference model, and large language model (LLM) reasoning. These signals are combined using meta-classifiers for robustness. A LLM-based post-editing system is used for grounded generation, revising simplifications based on original texts.

Result: The paper describes the integration of diverse signals and a meta-classification approach to enhance detection robustness, along with an LLM-based post-editing system for grounded generation.

Conclusion: The paper presents a methodology for the CLEF 2025 SimpleText Task 2, focusing on detecting and evaluating creative generation and information distortion in scientific text simplification.

Abstract: In this paper, we describe our methodology for the CLEF 2025 SimpleText Task
2, which focuses on detecting and evaluating creative generation and
information distortion in scientific text simplification. Our solution
integrates multiple strategies: we construct an ensemble framework that
leverages BERT-based classifier, semantic similarity measure, natural language
inference model, and large language model (LLM) reasoning. These diverse
signals are combined using meta-classifiers to enhance the robustness of
spurious and distortion detection. Additionally, for grounded generation, we
employ an LLM-based post-editing system that revises simplifications based on
the original input texts.

</details>


### [165] [A Survey of Idiom Datasets for Psycholinguistic and Computational Research](https://arxiv.org/abs/2508.11828)
*Michael Flor,Xinyi Liu,Anna Feldman*

Main category: cs.CL

TL;DR: 这是一份关于心理语言学和计算语言学中用于研究成语的数据集的调查报告。


<details>
  <summary>Details</summary>
Motivation: 成语是字面意思无法推断的习语，这使得计算处理和人类实验研究都面临挑战。

Method: 对来自心理语言学和计算语言学领域的53个数据集在内容、形式和预期用途进行了调查和分析，并展示了注释实践、覆盖范围和任务框架的趋势。

Result: 心理语言学研究资源通常包含熟悉度、透明度和组合性等方面的规范化评级，而计算数据集则支持成语识别/分类、释义和跨语言建模等任务。

Conclusion: 尽管近年来在扩大语言覆盖范围和任务多样性方面做出了努力，但心理语言学和计算语言学在成语研究方面似乎还没有联系。

Abstract: Idioms are figurative expressions whose meanings often cannot be inferred
from their individual words, making them difficult to process computationally
and posing challenges for human experimental studies. This survey reviews
datasets developed in psycholinguistics and computational linguistics for
studying idioms, focusing on their content, form, and intended use.
Psycholinguistic resources typically contain normed ratings along dimensions
such as familiarity, transparency, and compositionality, while computational
datasets support tasks like idiomaticity detection/classification,
paraphrasing, and cross-lingual modeling. We present trends in annotation
practices, coverage, and task framing across 53 datasets. Although recent
efforts expanded language coverage and task diversity, there seems to be no
relation yet between psycholinguistic and computational research on idioms.

</details>


### [166] [When Does Language Transfer Help? Sequential Fine-Tuning for Cross-Lingual Euphemism Detection](https://arxiv.org/abs/2508.11831)
*Julia Sammartino,Libby Barak,Jing Peng,Anna Feldman*

Main category: cs.CL

TL;DR: Cross-lingual transfer using sequential fine-tuning improves euphemism detection, particularly for low-resource languages. XLM-R and mBERT show different trade-offs between performance gains and stability.


<details>
  <summary>Details</summary>
Motivation: Euphemisms are culturally variable and ambiguous, posing challenges for language models, especially in low-resource settings. This paper aims to address these challenges by exploring cross-lingual transfer techniques.

Method: The paper investigates how cross-lingual transfer via sequential fine-tuning affects euphemism detection across five languages (English, Spanish, Chinese, Turkish, and Yoruba). It compares sequential fine-tuning with monolingual and simultaneous fine-tuning using XLM-R and mBERT, analyzing the impact of language pairings, typological features, and pretraining coverage.

Result: Sequential fine-tuning with a high-resource language improves performance in low-resource languages. XLM-R shows larger gains but is more sensitive to pretraining gaps and catastrophic forgetting, while mBERT provides more stable but lower results.

Conclusion: Sequential fine-tuning is a simple yet effective strategy for improving euphemism detection in multilingual models, especially for low-resource languages.

Abstract: Euphemisms are culturally variable and often ambiguous, posing challenges for
language models, especially in low-resource settings. This paper investigates
how cross-lingual transfer via sequential fine-tuning affects euphemism
detection across five languages: English, Spanish, Chinese, Turkish, and
Yoruba. We compare sequential fine-tuning with monolingual and simultaneous
fine-tuning using XLM-R and mBERT, analyzing how performance is shaped by
language pairings, typological features, and pretraining coverage. Results show
that sequential fine-tuning with a high-resource L1 improves L2 performance,
especially for low-resource languages like Yoruba and Turkish. XLM-R achieves
larger gains but is more sensitive to pretraining gaps and catastrophic
forgetting, while mBERT yields more stable, though lower, results. These
findings highlight sequential fine-tuning as a simple yet effective strategy
for improving euphemism detection in multilingual models, particularly when
low-resource languages are involved.

</details>


### [167] [SupraTok: Cross-Boundary Tokenization for Enhanced Language Model Performance](https://arxiv.org/abs/2508.11857)
*Andrei-Valentin Tănase,Elena Pelican*

Main category: cs.CL

TL;DR: SupraTok 是一种新的 tokenization 架构，通过学习“superword”来提高 tokenization 效率和语言模型性能。


<details>
  <summary>Details</summary>
Motivation: Tokenization 是自然语言处理中的一个基本瓶颈，尽管模型架构取得了显著进展，但其策略却 largely 保持静态。本研究旨在通过 SupraTok 改进 tokenization 策略。

Method: SupraTok 提出了一种新颖的 tokenization 架构，通过学习“superword” token 来实现子词分割的再构想，这些 superword 是保留语义单元并最大化压缩效率的连贯多词表达式。该架构包含三个创新点：跨边界模式学习、熵驱动数据策展和多阶段课程学习。

Result: SupraTok 在英文 tokenization 效率方面比 OpenAI 的 o200k tokenizer 和 Google 的 Gemma 3 tokenizer 提高了 31% 和 30%，同时在 38 种语言中保持了具有竞争力的性能。当与 GPT-2 规模的模型集成时，SupraTok 在 HellaSWAG 和 MMLU 基准测试上分别提高了 8.4% 和 9.5%。

Conclusion: SupraTok 的结果表明，高效的 tokenization 可以作为一种与架构创新互补的途径，以提高语言模型的性能。

Abstract: Tokenization remains a fundamental yet underexplored bottleneck in natural
language processing, with strategies largely static despite remarkable progress
in model architectures. We present SupraTok, a novel tokenization architecture
that reimagines subword segmentation through three innovations: cross-boundary
pattern learning that discovers multi-word semantic units, entropy-driven data
curation that optimizes training corpus quality, and multi-phase curriculum
learning for stable convergence. Our approach extends Byte-Pair Encoding by
learning "superword" tokens, coherent multi-word expressions that preserve
semantic unity while maximizing compression efficiency. SupraTok achieves 31%
improvement in English tokenization efficiency (5.91 versus 4.51 characters per
token) compared to OpenAI's o200k tokenizer and 30% improvement over Google's
Gemma 3 tokenizer (256k vocabulary), while maintaining competitive performance
across 38 languages. When integrated with a GPT-2 scale model (124M parameters)
trained on 10 billion tokens from the FineWeb-Edu dataset, SupraTok yields 8.4%
improvement on HellaSWAG and 9.5% on MMLU benchmarks without architectural
modifications. While these results are promising at this scale, further
validation at larger model scales is needed. These findings suggest that
efficient tokenization can complement architectural innovations as a path to
improved language model performance.

</details>


### [168] [In-Context Examples Matter: Improving Emotion Recognition in Conversation with Instruction Tuning](https://arxiv.org/abs/2508.11889)
*Hui Ma,Bo Zhang,Jinpeng Hu,Zenglin Shi*

Main category: cs.CL

TL;DR: A new one-stage in-context instruction tuning framework called InitERC improves emotion recognition in conversation (ERC) by better aligning speaker characteristics, contextual cues, and emotion states, outperforming existing methods on multiple datasets.


<details>
  <summary>Details</summary>
Motivation: Existing multi-stage instruction tuning methods for ERC constrain the capacity to jointly capture the dynamic interaction between speaker characteristics and conversational context, resulting in weak alignment among speaker identity, contextual cues, and emotion states within a unified framework.

Method: InitERC is a simple yet effective one-stage in-context instruction tuning framework for ERC. It comprises four components: demonstration pool construction, in-context example selection, prompt template design, and in-context instruction tuning. The framework adapts LLMs to learn speaker-context-emotion alignment from context examples via in-context instruction tuning. A comprehensive study on the impact of in-context examples was conducted, considering retrieval strategy, example ordering, and the number of examples.

Result: Extensive experiments on three widely used datasets demonstrate that InitERC achieves substantial improvements over the state-of-the-art baselines.

Conclusion: InitERC achieves substantial improvements over the state-of-the-art baselines on three widely used datasets.

Abstract: Emotion recognition in conversation (ERC) aims to identify the emotion of
each utterance in a conversation, playing a vital role in empathetic artificial
intelligence. With the growing of large language models (LLMs), instruction
tuning has emerged as a critical paradigm for ERC. Existing studies mainly
focus on multi-stage instruction tuning, which first endows LLMs with speaker
characteristics, and then conducts context-aware instruction tuning to
comprehend emotional states. However, these methods inherently constrains the
capacity to jointly capture the dynamic interaction between speaker
characteristics and conversational context, resulting in weak alignment among
speaker identity, contextual cues, and emotion states within a unified
framework. In this paper, we propose InitERC, a simple yet effective one-stage
in-context instruction tuning framework for ERC. InitERC adapts LLMs to learn
speaker-context-emotion alignment from context examples via in-context
instruction tuning. Specifically, InitERC comprises four components, i.e.,
demonstration pool construction, in-context example selection, prompt template
design, and in-context instruction tuning. To explore the impact of in-context
examples, we conduct a comprehensive study on three key factors: retrieval
strategy, example ordering, and the number of examples. Extensive experiments
on three widely used datasets demonstrate that our proposed InitERC achieves
substantial improvements over the state-of-the-art baselines.

</details>


### [169] [CORE: Measuring Multi-Agent LLM Interaction Quality under Game-Theoretic Pressures](https://arxiv.org/abs/2508.11915)
*Punya Syon Pandey,Yongjin Yang,Jiarui Liu,Zhijing Jin*

Main category: cs.CL

TL;DR: 本文提出CORE指标来量化多主体LLM系统中的语言多样性，发现在合作设置下语言更重复但词汇更丰富，而在竞争设置下语言更受约束。


<details>
  <summary>Details</summary>
Motivation: 游戏理论交互中的大型语言模型（LLM） agent展现了许多新兴能力，但这些交互的语言多样性尚未得到充分量化。

Method: 本文提出了对话鲁棒性评估得分（CORE）这一指标，该指标整合了聚类熵、词汇重复和语义相似性等度量，以量化不同博弈论交互中多主体系统内语言使用的有效性。研究还将CORE应用于竞争、合作和中性设置下的成对LLM对话，并通过Zipf和Heaps定律来表征词频分布和词汇增长。

Result: 合作设置表现出更陡峭的Zipf分布和更高的Heap指数，表明重复性更高，词汇扩展更大。相比之下，竞争性交互的Zipf和Heaps指数较低，反映出重复性较低和词汇约束性更强。

Conclusion: 研究结果揭示了社会激励如何影响语言适应性，并强调了CORE作为衡量多主体LLM系统中语言鲁棒性的有力诊断工具。

Abstract: Game-theoretic interactions between agents with Large Language Models (LLMs)
have revealed many emergent capabilities, yet the linguistic diversity of these
interactions has not been sufficiently quantified. In this paper, we present
the Conversational Robustness Evaluation Score: CORE, a metric to quantify the
effectiveness of language use within multi-agent systems across different
game-theoretic interactions. CORE integrates measures of cluster entropy,
lexical repetition, and semantic similarity, providing a direct lens of dialog
quality. We apply CORE to pairwise LLM dialogs across competitive, cooperative,
and neutral settings, further grounding our analysis in Zipf's and Heaps' Laws
to characterize word frequency distributions and vocabulary growth. Our
findings show that cooperative settings exhibit both steeper Zipf distributions
and higher Heap exponents, indicating more repetition alongside greater
vocabulary expansion. In contrast, competitive interactions display lower Zipf
and Heaps exponents, reflecting less repetition and more constrained
vocabularies. These results provide new insights into how social incentives
influence language adaptation, and highlight CORE as a robust diagnostic for
measuring linguistic robustness in multi-agent LLM systems. Our code is
available at https://github.com/psyonp/core.

</details>


### [170] [LLMs Struggle with NLI for Perfect Aspect: A Cross-Linguistic Study in Chinese and Japanese](https://arxiv.org/abs/2508.11927)
*Jie Lu,Du Jin,Hitomi Yanaka*

Main category: cs.CL

TL;DR: 中文和日文在完美时态标记方面缺乏不同形式，导致其在自然语言推断（NLI）中存在挑战。本研究构建了一个包含1,350个配对的中文和日文NLI数据集，实验证明即便是先进的大型语言模型（LLM）在处理时间推理，特别是时态和参照时间偏移方面也存在困难，这凸显了跨语言评估的必要性。


<details>
  <summary>Details</summary>
Motivation: 中文和日文在完美时态标记方面缺乏像英语那样的不同形式，这给自然语言推断带来了挑战。本研究旨在通过构建跨语言数据集来解决这一问题，并评估大型语言模型在处理这些语言中的时间推理能力。

Method: 本研究构建了一个基于模板的、语言学驱动的自然语言推断（NLI）数据集，其中包含1,350个中文和日文的配对。该数据集专注于标记这些语言中复杂的完美时态。

Result: 实验表明，即便是最先进的大型语言模型在处理中文和日文的完美时态时，在时间推理方面也表现不佳，尤其是在识别细微的时态和参照时间偏移方面。

Conclusion: 现有的先进大型语言模型（LLM）在处理跨语言的时间推理方面存在局限性，尤其是在识别细微的时态和参照时间偏移方面。这凸显了对跨语言评估在时间语义学方面进行深入研究的必要性。

Abstract: Unlike English, which uses distinct forms (e.g., had, has, will have) to mark
the perfect aspect across tenses, Chinese and Japanese lack separate
grammatical forms for tense within the perfect aspect, which complicates
Natural Language Inference (NLI). Focusing on the perfect aspect in these
languages, we construct a linguistically motivated, template-based NLI dataset
(1,350 pairs per language). Experiments reveal that even advanced LLMs struggle
with temporal inference, particularly in detecting subtle tense and
reference-time shifts. These findings highlight model limitations and
underscore the need for cross-linguistic evaluation in temporal semantics. Our
dataset is available at https://github.com/Lujie2001/CrossNLI.

</details>


### [171] [CAMF: Collaborative Adversarial Multi-agent Framework for Machine Generated Text Detection](https://arxiv.org/abs/2508.11933)
*Yue Wang,Liesheng Wei,Yuxiang Wang*

Main category: cs.CL

TL;DR: CAMF是一种新的多智能体框架，用于检测大型语言模型生成的文本，通过分析跨语言维度的不一致性来克服现有方法的局限性，并在实验中显示出优越的性能。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLM）生成文本（MGT）的检测至关重要，以应对虚假信息和学术诚信等风险。现有的零样本检测方法存在局限性，例如仅关注有限的文本属性，且缺乏对跨语言维度（如风格、语义和逻辑）一致性的研究。

Method: CAMF采用多智能体协同对抗框架，通过多维度语言特征提取、对抗性一致性探查和综合判断聚合三个阶段，深入分析表明非人类来源的细微、跨维度文本不一致性。

Result: CAMF在实证评估中表现出明显优于最先进的零样本MGT检测技术。

Conclusion: CAMF在实证评估中表现出明显优于最先进的零样本MGT检测技术。

Abstract: Detecting machine-generated text (MGT) from contemporary Large Language
Models (LLMs) is increasingly crucial amid risks like disinformation and
threats to academic integrity. Existing zero-shot detection paradigms, despite
their practicality, often exhibit significant deficiencies. Key challenges
include: (1) superficial analyses focused on limited textual attributes, and
(2) a lack of investigation into consistency across linguistic dimensions such
as style, semantics, and logic. To address these challenges, we introduce the
\textbf{C}ollaborative \textbf{A}dversarial \textbf{M}ulti-agent
\textbf{F}ramework (\textbf{CAMF}), a novel architecture using multiple
LLM-based agents. CAMF employs specialized agents in a synergistic three-phase
process: \emph{Multi-dimensional Linguistic Feature Extraction},
\emph{Adversarial Consistency Probing}, and \emph{Synthesized Judgment
Aggregation}. This structured collaborative-adversarial process enables a deep
analysis of subtle, cross-dimensional textual incongruities indicative of
non-human origin. Empirical evaluations demonstrate CAMF's significant
superiority over state-of-the-art zero-shot MGT detection techniques.

</details>


### [172] [Learning Wisdom from Errors: Promoting LLM's Continual Relation Learning through Exploiting Error Cases](https://arxiv.org/abs/2508.12031)
*Shaozhe Yin,Jinyu Guo,Kai Shuang,Xia Liu,Ruize Ou*

Main category: cs.CL

TL;DR: 针对持续关系提取（CRE）问题，提出了一种新颖的基于指令的对比学习方法，通过特别关注错误案例来克服灾难性遗忘并提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有的持续关系提取（CRE）方法主要关注记忆回放和对比学习，但忽视了错误案例，而错误案例能更有效地揭示模型的认知偏差。

Method: 提出了一种基于指令的持续对比调整方法，将训练和记忆数据分为两部分，并采用双任务微调，同时利用LLM的指令遵循能力来纠正认知偏差。

Result: 在TACRED和FewRel数据集上取得了新的状态艺术水平，显著提高了性能。

Conclusion: 该方法通过区分正确和错误案例并采用基于指令的对比学习策略，在TACRED和FewRel数据集上实现了新的状态艺术水平，证明了利用错误案例的重要性。

Abstract: Continual Relation Extraction (CRE) aims to continually learn new emerging
relations while avoiding catastrophic forgetting. Existing CRE methods mainly
use memory replay and contrastive learning to mitigate catastrophic forgetting.
However, these methods do not attach importance to the error cases that can
reveal the model's cognitive biases more effectively. To address this issue, we
propose an instruction-based continual contrastive tuning approach for Large
Language Models (LLMs) in CRE. Different from existing CRE methods that
typically handle the training and memory data in a unified manner, this
approach splits the training and memory data of each task into two parts
respectively based on the correctness of the initial responses and treats them
differently through dual-task fine-tuning. In addition, leveraging the
advantages of LLM's instruction-following ability, we propose a novel
instruction-based contrastive tuning strategy for LLM to continuously correct
current cognitive biases with the guidance of previous data in an
instruction-tuning manner, which mitigates the gap between old and new
relations in a more suitable way for LLMs. We experimentally evaluate our model
on TACRED and FewRel, and the results show that our model achieves new
state-of-the-art CRE performance with significant improvements, demonstrating
the importance of specializing in exploiting error cases.

</details>


### [173] [Mind the Generation Process: Fine-Grained Confidence Estimation During LLM Generation](https://arxiv.org/abs/2508.12040)
*Jinyi Han,Tingyun Li,Shisong Chen,Jie Shi,Xinyi Wang,Guanglei Yue,Jiaqing Liang,Xin Lin,Liqian Wen,Zulong Chen,Yanghua Xiao*

Main category: cs.CL

TL;DR: FineCE is a new method for accurate, fine-grained confidence estimation in LLMs, addressing overconfidence issues. It uses a novel training pipeline, backward confidence integration, and optimal position identification, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Accurate confidence estimation is critical for enhancing the trustworthiness and reliability of LLM-generated outputs, as LLMs often exhibit overconfidence and assign high scores to incorrect predictions. Existing approaches suffer from coarse-grained scoring mechanisms that fail to provide fine-grained, continuous confidence estimates during generation.

Method: FineCE introduces a novel confidence estimation method with a pipeline for constructing training data to capture LLM response distributions, a supervised model for predicting confidence scores, a Backward Confidence Integration (BCI) strategy leveraging subsequent text, and three strategies for identifying optimal confidence estimation positions.

Result: FineCE delivers accurate, fine-grained confidence scores during text generation and consistently outperforms existing classical confidence estimation methods on multiple benchmark datasets.

Conclusion: FineCE consistently outperforms existing classical confidence estimation methods and enhances the trustworthiness and reliability of LLM-generated outputs.

Abstract: While large language models (LLMs) have demonstrated remarkable performance
across diverse tasks, they fundamentally lack self-awareness and frequently
exhibit overconfidence, assigning high confidence scores to incorrect
predictions. Accurate confidence estimation is therefore critical for enhancing
the trustworthiness and reliability of LLM-generated outputs. However, existing
approaches suffer from coarse-grained scoring mechanisms that fail to provide
fine-grained, continuous confidence estimates throughout the generation
process. To address these limitations, we introduce FineCE, a novel confidence
estimation method that delivers accurate, fine-grained confidence scores during
text generation. Specifically, we first develop a comprehensive pipeline for
constructing training data that effectively captures the underlying
probabilistic distribution of LLM responses, and then train a model to predict
confidence scores for arbitrary text sequences in a supervised manner.
Furthermore, we propose a Backward Confidence Integration (BCI) strategy that
leverages information from the subsequent text to enhance confidence estimation
for the current sequence during inference. We also introduce three strategies
for identifying optimal positions to perform confidence estimation within the
generation process. Extensive experiments on multiple benchmark datasets
demonstrate that FineCE consistently outperforms existing classical confidence
estimation methods. Our code and all baselines used in the paper are available
on GitHub.

</details>


### [174] [J6: Jacobian-Driven Role Attribution for Multi-Objective Prompt Optimization in LLMs](https://arxiv.org/abs/2508.12086)
*Yao Wu*

Main category: cs.CL

TL;DR: J6 是一种新的 LLM 提示优化方法，通过分解梯度交互矩阵来解决多目标优化中的冲突问题，实现了更优的适配效果。


<details>
  <summary>Details</summary>
Motivation: 在大型语言模型（LLM）适配中，平衡提高事实性（heat）和增加置信度（通过低熵）等多重优化目标是一个基本挑战，因为提示参数（如隐藏层插入 h 和嵌入修改 w）之间存在复杂的交互作用。现有的多目标优化策略通常依赖于标量梯度聚合，忽略了目标与参数之间更深层次的几何结构。

Method: J6方法将梯度交互矩阵分解为六个可解释的组件，并通过 argmax 选择主导更新方向或使用 softmax 进行类似 attention 的加权，形成一个动态更新框架。

Result: J6 通过其可解释的结构，能够提供对参数归因、任务干扰和几何对齐适应的见解，实现冲突感知提示优化。

Conclusion: J6 提供了一种基于结构化 Jacobian 的方法，将梯度交互矩阵分解为六个可解释的组件，实现了动态更新框架，能够适应局部冲突和协同。此外，J6 的可解释结构还提供了参数归因、任务干扰和几何对齐适应的见解。该方法为冲突感知提示优化提供了一个原则性和可扩展的机制，并为将结构化 Jacobian 推理纳入多目标神经调优开辟了新途径。

Abstract: In large language model (LLM) adaptation, balancing multiple optimization
objectives such as improving factuality (heat) and increasing confidence (via
low entropy) poses a fundamental challenge, especially when prompt parameters
(e.g., hidden-layer insertions h and embedding modifications w) interact in
non-trivial ways. Existing multi-objective optimization strategies often rely
on scalar gradient aggregation, ignoring the deeper geometric structure between
objectives and parameters. We propose J6, a structured Jacobian-based method
that decomposes the gradient interaction matrix into six interpretable
components. This decomposition enables both hard decision-making (e.g.,
choosing the dominant update direction via argmax) and soft strategies (e.g.,
attention-style weighting via softmax over J6), forming a dynamic update
framework that adapts to local conflict and synergy. Moreover, the
interpretable structure of J6 provides insight into parameter attribution, task
interference, and geometry-aligned adaptation. Our work introduces a principled
and extensible mechanism for conflict-aware prompt optimization, and opens a
new avenue for incorporating structured Jacobian reasoning into multi-objective
neural tuning.

</details>


### [175] [STEM: Efficient Relative Capability Evaluation of LLMs through Structured Transition Samples](https://arxiv.org/abs/2508.12096)
*Haiquan Hu,Jiazhi Jiang,Shiyou Xu,Ruhan Zeng,Tian Wang*

Main category: cs.CL

TL;DR: 提出了一种名为 STEM 的轻量级、可解释的评估框架，用于评估大型语言模型。通过识别“显著转换样本”，STEM 能够经济高效地估计模型能力，并已被证明可以准确反映模型性能。


<details>
  <summary>Details</summary>
Motivation: 为了应对评估大型语言模型（LLMs）的挑战，包括模型能力快速提升、公开基准过拟合以及评估成本高昂等问题，提出 STEM。

Method: STEM 通过分析相同架构但不同参数规模的大型语言模型之间的一致性能转换，识别“显著转换样本”（STS），从而有效地估计未知模型的能力。

Result: 实验结果表明，STEM 可靠地捕捉了性能趋势，并与模型能力的基本排名一致。

Conclusion: STEM 是一种实用且可扩展的方法，用于对大型语言模型进行细粒度、与架构无关的评估。

Abstract: Evaluating large language models (LLMs) has become increasingly challenging
as model capabilities advance rapidly. While recent models often achieve higher
scores on standard benchmarks, these improvements do not consistently reflect
enhanced real-world reasoning capabilities. Moreover, widespread overfitting to
public benchmarks and the high computational cost of full evaluations have made
it both expensive and less effective to distinguish meaningful differences
between models. To address these challenges, we propose the \textbf{S}tructured
\textbf{T}ransition \textbf{E}valuation \textbf{M}ethod (STEM), a lightweight
and interpretable evaluation framework for efficiently estimating the relative
capabilities of LLMs. STEM identifies \textit{significant transition samples}
(STS) by analyzing consistent performance transitions among LLMs of the same
architecture but varying parameter scales. These samples enable STEM to
effectively estimate the capability position of an unknown model. Qwen3 model
family is applied to construct the STS pool on six diverse and representative
benchmarks. To assess generalizability. Experimental results indicate that STEM
reliably captures performance trends, aligns with ground-truth rankings of
model capability. These findings highlight STEM as a practical and scalable
method for fine-grained, architecture-agnostic evaluation of LLMs.

</details>


### [176] [Exploring Efficiency Frontiers of Thinking Budget in Medical Reasoning: Scaling Laws between Computational Resources and Reasoning Quality](https://arxiv.org/abs/2508.12140)
*Ziqian Bi,Lu Chen,Junhao Song,Hongying Luo,Enze Ge,Junmin Huang,Tianyang Wang,Keyu Chen,Chia Xin Liang,Zihan Wei,Huafeng Liu,Chunjie Tian,Jibin Guan,Joe Yeong,Yongzhi Xu,Peng Wang,Junfeng Hao*

Main category: cs.CL

TL;DR: 本研究评估了思考预算机制在医学推理中的作用，发现准确率与思考预算和模型规模呈对数标度关系，并提出了三种效率模式。该研究为优化医疗 AI 资源分配提供了指导。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在全面评估思考预算机制在医学推理任务中的作用，探索计算资源与推理质量之间的关系，并为优化医疗人工智能系统的资源分配提供指导。

Method: 通过控制思考预算（从零到无限 token）和模型规模（Qwen3：1.7B 至 235B 参数；DeepSeek-R1：1.5B 至 70B 参数），在 15 个医学数据集上评估了两个模型家族的表现，并建立了准确率提升与思考预算及模型规模之间的对数标度关系。同时，比较了 Qwen3 的原生思考预算 API 和为 DeepSeek-R1 设计的截断方法，以验证思考预算概念的通用性。

Result: 研究发现准确率提升与思考预算和模型规模之间存在对数标度关系。根据思考预算的不同，可将模型效率分为三种模式：高效（0-256 token）、平衡（256-512 token）和高精度（>512 token）。较小模型从扩展思考中获益更大。不同医学专科（如神经病学、胃肠病学）所需的推理深度不同。思考预算概念具有跨架构的通用性。

Conclusion: 这项研究首次全面评估了医学推理任务中的思考预算机制，揭示了计算资源与推理质量之间基本的标度律。研究系统评估了 Qwen3（1.7B 至 235B 参数）和 DeepSeek-R1（1.5B 至 70B 参数）两大模型家族在覆盖不同专科和难度级别的 15 个医学数据集上的表现。通过对从零到无限 token 的思考预算进行受控实验，研究建立了对数标度关系，其中准确率的提升遵循思考预算和模型规模的预测模式。研究结果确定了三种不同的效率模式：高效模式（0 至 256 token），适用于实时应用；平衡模式（256 至 512 token），为常规临床支持提供最佳的成本效益权衡；高精度模式（512 token 以上），仅适用于关键诊断任务。值得注意的是，较小模型从扩展思考中获得的收益不成比例地更大，与大型模型 5% 至 10% 的提升相比，有 15% 至 20% 的改进，这表明思考预算为能力受限的模型提供了更大的相对优势。领域特定的模式（如神经病学和胃肠病学比心血管或呼吸系统医学需要更深入的推理过程）清晰地浮现出来。Qwen3 的原生思考预算 API 与我们为 DeepSeek-R1 提出的截断方法之间的一致性，验证了思考预算概念跨架构的通用性。这些结果确立了思考预算控制作为优化医疗人工智能系统的关键机制，能够在保持医疗部署透明度的同时，实现与临床需求相匹配的动态资源分配。

Abstract: This study presents the first comprehensive evaluation of thinking budget
mechanisms in medical reasoning tasks, revealing fundamental scaling laws
between computational resources and reasoning quality. We systematically
evaluated two major model families, Qwen3 (1.7B to 235B parameters) and
DeepSeek-R1 (1.5B to 70B parameters), across 15 medical datasets spanning
diverse specialties and difficulty levels. Through controlled experiments with
thinking budgets ranging from zero to unlimited tokens, we establish
logarithmic scaling relationships where accuracy improvements follow a
predictable pattern with both thinking budget and model size. Our findings
identify three distinct efficiency regimes: high-efficiency (0 to 256 tokens)
suitable for real-time applications, balanced (256 to 512 tokens) offering
optimal cost-performance tradeoffs for routine clinical support, and
high-accuracy (above 512 tokens) justified only for critical diagnostic tasks.
Notably, smaller models demonstrate disproportionately larger benefits from
extended thinking, with 15 to 20% improvements compared to 5 to 10% for larger
models, suggesting a complementary relationship where thinking budget provides
greater relative benefits for capacity-constrained models. Domain-specific
patterns emerge clearly, with neurology and gastroenterology requiring
significantly deeper reasoning processes than cardiovascular or respiratory
medicine. The consistency between Qwen3 native thinking budget API and our
proposed truncation method for DeepSeek-R1 validates the generalizability of
thinking budget concepts across architectures. These results establish thinking
budget control as a critical mechanism for optimizing medical AI systems,
enabling dynamic resource allocation aligned with clinical needs while
maintaining the transparency essential for healthcare deployment.

</details>


### [177] [LLM-as-a-Judge for Privacy Evaluation? Exploring the Alignment of Human and LLM Perceptions of Privacy in Textual Data](https://arxiv.org/abs/2508.12158)
*Stephen Meisenbacher,Alexandra Klymenko,Florian Matthes*

Main category: cs.CL

TL;DR: 本研究表明，虽然人类对隐私的看法不一致，但LLM可以作为一种有效的工具来评估文本数据的隐私敏感性，并能模拟人类的普遍隐私视角。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决隐私保护NLP领域中准确评估隐私的挑战，并探索利用LLM-as-a-Judge范式来评估文本数据隐私敏感性的可行性。

Method: 本研究采用LLM-as-a-Judge范式，并进行了一项涉及10个数据集、13个LLM和677名人类调查参与者的研究，分析了人类和LLM的推理模式，以评估LLM在隐私评估任务中的表现。

Result: 研究发现，尽管人类对隐私的感知存在普遍较低的一致性，但LLM能够准确地模拟全球人类的隐私视角。通过对人类和LLM推理模式的分析，本研究讨论了LLM-as-a-Judge在文本隐私评估中的优点和局限性。

Conclusion: 尽管在隐私保护的自然语言处理（NLP）领域取得了进展，但准确评估隐私仍然是一个重大挑战。本研究旨在探索使用大型语言模型（LLM）作为隐私评估的潜在解决方案，并衡量LLM评估与人类对文本隐私敏感性感知的接近程度。研究结果表明，尽管人类对隐私的看法存在较大差异，但LLM能够准确地模拟全球人类的隐私视角，并展示了其作为文本数据隐私评估工具的潜力和局限性。

Abstract: Despite advances in the field of privacy-preserving Natural Language
Processing (NLP), a significant challenge remains the accurate evaluation of
privacy. As a potential solution, using LLMs as a privacy evaluator presents a
promising approach $\unicode{x2013}$ a strategy inspired by its success in
other subfields of NLP. In particular, the so-called $\textit{LLM-as-a-Judge}$
paradigm has achieved impressive results on a variety of natural language
evaluation tasks, demonstrating high agreement rates with human annotators.
Recognizing that privacy is both subjective and difficult to define, we
investigate whether LLM-as-a-Judge can also be leveraged to evaluate the
privacy sensitivity of textual data. Furthermore, we measure how closely LLM
evaluations align with human perceptions of privacy in text. Resulting from a
study involving 10 datasets, 13 LLMs, and 677 human survey participants, we
confirm that privacy is indeed a difficult concept to measure empirically,
exhibited by generally low inter-human agreement rates. Nevertheless, we find
that LLMs can accurately model a global human privacy perspective, and through
an analysis of human and LLM reasoning patterns, we discuss the merits and
limitations of LLM-as-a-Judge for privacy evaluation in textual data. Our
findings pave the way for exploring the feasibility of LLMs as privacy
evaluators, addressing a core challenge in solving pressing privacy issues with
innovative technical solutions.

</details>


### [178] [Arabic Multimodal Machine Learning: Datasets, Applications, Approaches, and Challenges](https://arxiv.org/abs/2508.12227)
*Abdelhamid Haouhat,Slimane Bellaouar,Attia Nehar,Hadda Cherroun,Ahmed Abdelali*

Main category: cs.CL

TL;DR: 阿拉伯多模态机器学习的全面调查，分类了数据集、应用、方法和挑战，并强调了机遇和挑战。


<details>
  <summary>Details</summary>
Motivation: 由于阿拉伯多模态机器学习基础发展日趋成熟，有必要对其进行全面的调查，以明确该领域的现状、未被研究的领域和关键研究差距。

Method: 本研究通过引入新颖的分类法，将阿拉伯多模态机器学习的现有研究分为四个关键主题：数据集、应用、方法和挑战，从而对阿拉伯多模态机器学习进行了全面的调查。

Result: 本综述对阿拉伯多模态机器学习的研究进行了分类和分析，并强调了机遇和挑战，为研究者提供了对该领域的见解。

Conclusion: 本综述为阿拉伯多模态机器学习的研究者提供了对该领域的全面概述，强调了机遇和挑战，并促进了该领域的进步。

Abstract: Multimodal Machine Learning (MML) aims to integrate and analyze information
from diverse modalities, such as text, audio, and visuals, enabling machines to
address complex tasks like sentiment analysis, emotion recognition, and
multimedia retrieval. Recently, Arabic MML has reached a certain level of
maturity in its foundational development, making it time to conduct a
comprehensive survey. This paper explores Arabic MML by categorizing efforts
through a novel taxonomy and analyzing existing research. Our taxonomy
organizes these efforts into four key topics: datasets, applications,
approaches, and challenges. By providing a structured overview, this survey
offers insights into the current state of Arabic MML, highlighting areas that
have not been investigated and critical research gaps. Researchers will be
empowered to build upon the identified opportunities and address challenges to
advance the field.

</details>


### [179] [SEA-BED: Southeast Asia Embedding Benchmark](https://arxiv.org/abs/2508.12243)
*Wuttikorn Ponwitayarat,Raymond Ng,Jann Railey Montalan,Thura Aung,Jian Gang Ngui,Yosephine Susanto,William Tjhi,Panuthep Tasawong,Erik Cambria,Ekapol Chuangsuwanich,Sarana Nutanong,Peerat Limkonchotiwat*

Main category: cs.CL

TL;DR: SEA-BED 是首个东南亚语言嵌入基准，包含大量人工创建的数据集，揭示了模型在 SEA 语言上的不一致表现以及高质量数据集的重要性。


<details>
  <summary>Details</summary>
Motivation: 东南亚地区缺乏针对该区域的嵌入基准，现有数据集大多是机器翻译的，未能体现本地语言特性。

Method: 本研究提出了 SEA-BED，这是首个大规模 SEA 嵌入基准。对 17 个嵌入模型进行了评估，并分析了任务和语言挑战、跨基准比较以及翻译的权衡。

Result: 研究结果显示，模型排名发生显著变化，在 SEA 语言中的表现不一致。此外，研究强调了人工创建的数据集对于缅甸语等低资源语言的重要性。

Conclusion: SEA-BED 填补了东南亚（SEA）语言嵌入基准的空白，该基准包含 169 个数据集，涵盖 9 个任务和 10 种语言，其中 71% 由人工创建。结果表明，模型在 SEA 语言上的表现不稳定，并且人工创建的数据集对于缅甸语等低资源语言至关重要。

Abstract: Sentence embeddings are essential for NLP tasks such as semantic search,
re-ranking, and textual similarity. Although multilingual benchmarks like MMTEB
broaden coverage, Southeast Asia (SEA) datasets are scarce and often
machine-translated, missing native linguistic properties. With nearly 700
million speakers, the SEA region lacks a region-specific embedding benchmark.
We introduce SEA-BED, the first large-scale SEA embedding benchmark with 169
datasets across 9 tasks and 10 languages, where 71% are formulated by humans,
not machine generation or translation. We address three research questions: (1)
which SEA languages and tasks are challenging, (2) whether SEA languages show
unique performance gaps globally, and (3) how human vs. machine translations
affect evaluation. We evaluate 17 embedding models across six studies,
analyzing task and language challenges, cross-benchmark comparisons, and
translation trade-offs. Results show sharp ranking shifts, inconsistent model
performance among SEA languages, and the importance of human-curated datasets
for low-resource languages like Burmese.

</details>


### [180] [What do Speech Foundation Models Learn? Analysis and Applications](https://arxiv.org/abs/2508.12255)
*Ankita Pasad*

Main category: cs.CL

TL;DR: 本文提出了分析和改进语音基础模型 (SFM) 的方法，尤其是在口语理解 (SLU) 任务上。通过开发分析工具和新的 SLU 数据集 (NER, NEL)，研究表明 SFM 驱动的端到端模型在理解口语方面优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 目前对于语音基础模型 (SFM) 所包含的知识了解不足，特别是它们在需要更深层次理解的口语理解 (SLU) 任务上的表现。此外，SLU 任务因缺乏相关数据集而受到限制。

Method: 本文提出了一个轻量级的分析框架，利用统计工具和不依赖训练的任务来探究 SFM 层中编码的声学和语言知识。通过跨多个 SFM 和统计工具进行比较研究，证明了分析洞察对下游任务性能具有实际意义。此外，本文还为口语理解评估基准贡献了新的任务（口语命名实体识别 NER 和命名实体定位 NEL），并开发了基于 SFM 的 NER 和 NEL 方法，以评估端到端 (E2E) 模型在不同 SFM 和适应策略下的表现。

Result: 研究表明，分析洞察对下游任务性能有实际影响。基于 SFM 的端到端 (E2E) 模型在 NER 和 NEL 任务上可以超越传统的级联方法。通过对 E2E SLU 模型在不同 SFM 和适应策略下的评估，为模型选择提供了参考。

Conclusion: 本论文通过开发分析框架、引入新的数据集和模型，解决了关于语音基础模型 (SFM) 的未解问题，为社区提供了工具和数据集，以促进对 SFM 的理解并指导未来的模型设计和应用。

Abstract: Speech foundation models (SFMs) are designed to serve as general-purpose
representations for a wide range of speech-processing tasks. The last five
years have seen an influx of increasingly successful self-supervised and
supervised pre-trained models with impressive performance on various downstream
tasks.
  Although the zoo of SFMs continues to grow, our understanding of the
knowledge they acquire lags behind. This thesis presents a lightweight analysis
framework using statistical tools and training-free tasks to investigate the
acoustic and linguistic knowledge encoded in SFM layers. We conduct a
comparative study across multiple SFMs and statistical tools. Our study also
shows that the analytical insights have concrete implications for downstream
task performance.
  The effectiveness of an SFM is ultimately determined by its performance on
speech applications. Yet it remains unclear whether the benefits extend to
spoken language understanding (SLU) tasks that require a deeper understanding
than widely studied ones, such as speech recognition. The limited exploration
of SLU is primarily due to a lack of relevant datasets. To alleviate that, this
thesis contributes tasks, specifically spoken named entity recognition (NER)
and named entity localization (NEL), to the Spoken Language Understanding
Evaluation benchmark. We develop SFM-based approaches for NER and NEL, and find
that end-to-end (E2E) models leveraging SFMs can surpass traditional cascaded
(speech recognition followed by a text model) approaches. Further, we evaluate
E2E SLU models across SFMs and adaptation strategies to assess the impact on
task performance.
  Collectively, this thesis tackles previously unanswered questions about SFMs,
providing tools and datasets to further our understanding and to enable the
community to make informed design choices for future model development and
adoption.

</details>


### [181] [Structuring the Unstructured: A Systematic Review of Text-to-Structure Generation for Agentic AI with a Universal Evaluation Framework](https://arxiv.org/abs/2508.12257)
*Zheye Deng,Chunkit Chan,Tianshi Zheng,Wei Fan,Weiqi Wang,Yangqiu Song*

Main category: cs.CL

TL;DR: This paper reviews text-to-structure conversion methods, which are crucial for AI systems. It discusses challenges, datasets, and metrics, and introduces a new evaluation framework, highlighting these techniques as foundational for future AI.


<details>
  <summary>Details</summary>
Motivation: The evolution of AI systems toward agentic operation and context-aware retrieval necessitates transforming unstructured text into structured formats like tables, knowledge graphs, and charts. Current research lacks a comprehensive synthesis of methodologies, datasets, and metrics for these conversions.

Method: This paper presents a systematic review of text-to-structure techniques, evaluating current datasets and assessment criteria, and proposing a universal evaluation framework for structured outputs.

Result: The review examines text-to-structure techniques and challenges, evaluates datasets and metrics, and outlines future research directions. A universal evaluation framework for structured outputs is introduced.

Conclusion: text-to-structure technologies are foundational infrastructure for next-generation AI systems.

Abstract: The evolution of AI systems toward agentic operation and context-aware
retrieval necessitates transforming unstructured text into structured formats
like tables, knowledge graphs, and charts. While such conversions enable
critical applications from summarization to data mining, current research lacks
a comprehensive synthesis of methodologies, datasets, and metrics. This
systematic review examines text-to-structure techniques and the encountered
challenges, evaluates current datasets and assessment criteria, and outlines
potential directions for future research. We also introduce a universal
evaluation framework for structured outputs, establishing text-to-structure as
foundational infrastructure for next-generation AI systems.

</details>


### [182] [Fast, Slow, and Tool-augmented Thinking for LLMs: A Review](https://arxiv.org/abs/2508.12265)
*Xinda Jia,Jinpeng Li,Zezhong Wang,Jingjing Li,Xingshan Zeng,Yasheng Wang,Weinan Zhang,Yong Yu,Weiwen Liu*

Main category: cs.CL

TL;DR: LLMs need to adapt their reasoning. This paper offers a taxonomy based on fast/slow and internal/external boundaries, surveys existing methods, and points to future work for better LLMs.


<details>
  <summary>Details</summary>
Motivation: Effective reasoning in real-world tasks requires adapting LLM reasoning strategies to problem demands, ranging from fast, intuitive responses to deliberate, step-by-step reasoning and tool-augmented thinking.

Method: The paper proposes a novel taxonomy of LLM reasoning strategies along fast/slow and internal/external boundaries, drawing inspiration from cognitive psychology. It systematically surveys recent work on adaptive reasoning in LLMs and categorizes methods based on key decision factors.

Result: The paper establishes a taxonomy of LLM reasoning strategies based on cognitive psychology principles, providing a framework for understanding and developing adaptive reasoning capabilities in LLMs.

Conclusion: The paper surveys adaptive reasoning strategies in LLMs, categorizes methods based on decision factors, and highlights open challenges for future research towards more adaptive, efficient, and reliable LLMs.

Abstract: Large Language Models (LLMs) have demonstrated remarkable progress in
reasoning across diverse domains. However, effective reasoning in real-world
tasks requires adapting the reasoning strategy to the demands of the problem,
ranging from fast, intuitive responses to deliberate, step-by-step reasoning
and tool-augmented thinking. Drawing inspiration from cognitive psychology, we
propose a novel taxonomy of LLM reasoning strategies along two knowledge
boundaries: a fast/slow boundary separating intuitive from deliberative
processes, and an internal/external boundary distinguishing reasoning grounded
in the model's parameters from reasoning augmented by external tools. We
systematically survey recent work on adaptive reasoning in LLMs and categorize
methods based on key decision factors. We conclude by highlighting open
challenges and future directions toward more adaptive, efficient, and reliable
LLMs.

</details>


### [183] [The Self-Execution Benchmark: Measuring LLMs' Attempts to Overcome Their Lack of Self-Execution](https://arxiv.org/abs/2508.12277)
*Elon Ezra,Ariel Weizman,Amos Azaria*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large language models (LLMs) are commonly evaluated on tasks that test their
knowledge or reasoning abilities. In this paper, we explore a different type of
evaluation: whether an LLM can predict aspects of its own responses. Since LLMs
lack the ability to execute themselves, we introduce the Self-Execution
Benchmark, which measures a model's ability to anticipate properties of its
output, such as whether a question will be difficult for it, whether it will
refuse to answer, or what kinds of associations it is likely to produce. Our
experiments show that models generally perform poorly on this benchmark, and
that increased model size or capability does not consistently lead to better
performance. These results suggest a fundamental limitation in how LLMs
represent and reason about their own behavior.

</details>


### [184] [Legal$Δ$: Enhancing Legal Reasoning in LLMs via Reinforcement Learning with Chain-of-Thought Guided Information Gain](https://arxiv.org/abs/2508.12281)
*Xin Dai,Buqiang Xu,Zhenghao Liu,Yukun Yan,Huiyuan Xie,Xiaoyuan Yi,Shuo Wang,Ge Yu*

Main category: cs.CL

TL;DR: Legal$\Delta$ improves legal LLMs by using reinforcement learning to generate more accurate, interpretable, and trustworthy legal judgments through guided reasoning, outperforming existing methods without needing labeled preference data.


<details>
  <summary>Details</summary>
Motivation: Existing legal LLMs struggle to generate reliable and interpretable reasoning processes, often providing direct answers without multi-step justification, which limits their effectiveness in complex legal scenarios.

Method: Legal$\Delta$ is a reinforcement learning framework that uses a dual-mode input (direct answer and reasoning-augmented modes) to maximize information gain and encourage meaningful reasoning patterns. It employs a two-stage approach: distilling capabilities from DeepSeek-R1 and refining reasoning quality through differential comparisons with a multidimensional reward mechanism.

Result: Experimental results on multiple legal reasoning tasks demonstrate that Legal$\Delta$ outperforms strong baselines in both accuracy and interpretability.

Conclusion: Legal$\Delta$ outperforms strong baselines in both accuracy and interpretability, consistently producing more robust and trustworthy legal judgments without relying on labeled preference data.

Abstract: Legal Artificial Intelligence (LegalAI) has achieved notable advances in
automating judicial decision-making with the support of Large Language Models
(LLMs). However, existing legal LLMs still struggle to generate reliable and
interpretable reasoning processes. They often default to fast-thinking behavior
by producing direct answers without explicit multi-step reasoning, limiting
their effectiveness in complex legal scenarios that demand rigorous
justification. To address this challenge, we propose Legal$\Delta$, a
reinforcement learning framework designed to enhance legal reasoning through
chain-of-thought guided information gain. During training, Legal$\Delta$
employs a dual-mode input setup-comprising direct answer and
reasoning-augmented modes-and maximizes the information gain between them. This
encourages the model to acquire meaningful reasoning patterns rather than
generating superficial or redundant explanations. Legal$\Delta$ follows a
two-stage approach: (1) distilling latent reasoning capabilities from a
powerful Large Reasoning Model (LRM), DeepSeek-R1, and (2) refining reasoning
quality via differential comparisons, combined with a multidimensional reward
mechanism that assesses both structural coherence and legal-domain specificity.
Experimental results on multiple legal reasoning tasks demonstrate that
Legal$\Delta$ outperforms strong baselines in both accuracy and
interpretability. It consistently produces more robust and trustworthy legal
judgments without relying on labeled preference data. All code and data will be
released at https://github.com/NEUIR/LegalDelta.

</details>


### [185] [A Question Answering Dataset for Temporal-Sensitive Retrieval-Augmented Generation](https://arxiv.org/abs/2508.12282)
*Ziyang Chen,Erxue Min,Xiang Zhao,Yunxin Li,Xin Jia,Jinzhi Liao,Jichao Li,Shuaiqiang Wang,Baotian Hu,Dawei Yin*

Main category: cs.CL

TL;DR: ChronoQA是一个新的中文问答数据集，专门用于测试RAG系统的时间推理能力。它包含大量真实新闻数据和精心设计的问题，涵盖各种时间类型和场景，旨在推动时间敏感问答系统的发展。


<details>
  <summary>Details</summary>
Motivation: 检索增强生成（RAG）系统在处理时间信息和进行时间推理方面存在挑战。为了评估和改进RAG系统在这方面的能力，需要一个大规模、高质量且专注于时间推理的中文问答数据集。

Method: ChronoQA数据集包含超过30万篇2019年至2024年间发布的新闻文章，生成了5176个高质量问题，这些问题涵盖了绝对、聚合和相对时间类型，并包含显式和隐式的时间表达。数据集支持单文档和多文档两种场景，并具有全面的结构化注释，经过基于规则、基于LLM和人工评估的多阶段验证。

Result: ChronoQA数据集包含了5176个高质量的中文问答对，涵盖了多种时间推理类型和场景，并进行了详细的注释和验证，为评估和发展时间敏感的RAG系统提供了可靠的资源。

Conclusion: ChronoQA是一个大规模中文问答基准数据集，用于评估检索增强生成（RAG）系统中的时间推理能力。它包含高质量的问题，涵盖绝对、聚合和相对时间类型，支持单文档和多文档场景。该数据集具有全面的结构化注释，并经过多阶段验证，旨在为时间敏感的检索增强问答系统提供结构化评估和稳健基准。

Abstract: We introduce ChronoQA, a large-scale benchmark dataset for Chinese question
answering, specifically designed to evaluate temporal reasoning in
Retrieval-Augmented Generation (RAG) systems. ChronoQA is constructed from over
300,000 news articles published between 2019 and 2024, and contains 5,176
high-quality questions covering absolute, aggregate, and relative temporal
types with both explicit and implicit time expressions. The dataset supports
both single- and multi-document scenarios, reflecting the real-world
requirements for temporal alignment and logical consistency. ChronoQA features
comprehensive structural annotations and has undergone multi-stage validation,
including rule-based, LLM-based, and human evaluation, to ensure data quality.
By providing a dynamic, reliable, and scalable resource, ChronoQA enables
structured evaluation across a wide range of temporal tasks, and serves as a
robust benchmark for advancing time-sensitive retrieval-augmented question
answering systems.

</details>


### [186] [Incorporating Legal Logic into Deep Learning: An Intelligent Approach to Probation Prediction](https://arxiv.org/abs/2508.12286)
*Qinghua Wang,Xu Zhang,Lingyan Yang,Rui Shao,Bonan Wang,Fang Wang,Cunquan Qu*

Main category: cs.CL

TL;DR: 该研究提出了一种结合法律逻辑和深度学习的新方法（MT-DT模型）来预测缓刑资格，以解决当前智能司法辅助系统中存在的不足，并在实验中证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前智能司法辅助系统（IJAS）缺乏专门的缓刑预测方法，并且影响缓刑资格的因素研究有限。现有IJAS研究主要依赖数据驱动的方法，忽视了司法决策的法律逻辑。缓刑资格需要对犯罪情节和悔罪表现进行综合分析。

Method: 提出了一种将法律逻辑整合到深度学习模型中进行缓刑预测的新方法，该方法分三个阶段进行：1. 构建包含事实描述和缓刑法律要素（PLEs）的专门缓刑数据集；2. 设计了名为多任务双理论缓刑预测模型（MT-DT）的独特缓刑预测模型，该模型基于缓刑的法律逻辑和“双轨制刑罚理论”；3. 在数据集上进行实验评估。

Result: 实验结果表明，MT-DT模型在专门的缓刑数据集上表现优于基线模型，并且对底层法律逻辑的分析也验证了该方法的有效性。

Conclusion: 该研究提出的多任务双理论模型（MT-DT）在专门构建的包含案件事实描述和缓刑法律要素（PLEs）的缓刑数据集上进行了实验，结果表明MT-DT模型优于基线模型，并且对底层法律逻辑的分析进一步验证了该方法的有效性。

Abstract: Probation is a crucial institution in modern criminal law, embodying the
principles of fairness and justice while contributing to the harmonious
development of society. Despite its importance, the current Intelligent
Judicial Assistant System (IJAS) lacks dedicated methods for probation
prediction, and research on the underlying factors influencing probation
eligibility remains limited. In addition, probation eligibility requires a
comprehensive analysis of both criminal circumstances and remorse. Much of the
existing research in IJAS relies primarily on data-driven methodologies, which
often overlooks the legal logic underpinning judicial decision-making. To
address this gap, we propose a novel approach that integrates legal logic into
deep learning models for probation prediction, implemented in three distinct
stages. First, we construct a specialized probation dataset that includes fact
descriptions and probation legal elements (PLEs). Second, we design a distinct
probation prediction model named the Multi-Task Dual-Theory Probation
Prediction Model (MT-DT), which is grounded in the legal logic of probation and
the \textit{Dual-Track Theory of Punishment}. Finally, our experiments on the
probation dataset demonstrate that the MT-DT model outperforms baseline models,
and an analysis of the underlying legal logic further validates the
effectiveness of the proposed approach.

</details>


### [187] [CarelessWhisper: Turning Whisper into a Causal Streaming Model](https://arxiv.org/abs/2508.12301)
*Tomer Krichli,Bhiksha Raj,Joseph Keshet*

Main category: cs.CL

TL;DR: 为解决现有ASR模型无法进行流式转录的问题，提出一种将Transformer编码器-解码器模型改为低延迟流式模型的方法。通过使用LoRA和弱对齐数据集微调模型，并采用新的推理机制，在低延迟场景下取得了比现有方法更好的效果和更低的复杂度，同时还能提取词级别的时间戳。


<details>
  <summary>Details</summary>
Motivation: 现有先进的自动语音识别（ASR）模型（如 OpenAI Whisper 和 NVIDIA Canary）虽然在离线转录方面表现出色，但由于架构和训练方法的限制，并不适用于流式（在线或实时）转录。因此，需要一种能够实现低延迟流式转录的方法。

Method: 将现有的（非因果）Transformer 编码器-解码器模型修改为低延迟流式模型。具体方法包括：1. 修改编码器使其具有因果性。2. 使用低秩适应（LoRA）技术微调编码器和解码器。3. 使用弱对齐数据集进行训练。4. 提出一种利用微调后的因果编码器和解码器的更新推理机制，支持贪心和束搜索解码。

Result: 在低延迟切块大小（小于300毫秒）的实验中，微调后的模型在大多数情况下优于现有的非微调流式方法，且计算复杂度更低。此外，训练过程提高了模型对齐能力，使得提取词级别的时间戳的方法更加简单。模型代码和微调后的模型已开源。

Conclusion: 所提出的方法通过微调编码器-解码器 Transformer 模型（使用 LoRA 和弱对齐数据集）并采用更新的推理机制，实现了低延迟的流式语音识别。实验证明，该模型在小切块大小（<300毫秒）上优于现有的非微调流式方法，同时复杂度更低。此外，训练过程还能改善对齐，从而可以提取词级别的时间戳。

Abstract: Automatic Speech Recognition (ASR) has seen remarkable progress, with models
like OpenAI Whisper and NVIDIA Canary achieving state-of-the-art (SOTA)
performance in offline transcription. However, these models are not designed
for streaming (online or real-time) transcription, due to limitations in their
architecture and training methodology. We propose a method to turn the
transformer encoder-decoder model into a low-latency streaming model that is
careless about future context. We present an analysis explaining why it is not
straightforward to convert an encoder-decoder transformer to a low-latency
streaming model. Our proposed method modifies the existing (non-causal) encoder
to a causal encoder by fine-tuning both the encoder and decoder using Low-Rank
Adaptation (LoRA) and a weakly aligned dataset. We then propose an updated
inference mechanism that utilizes the fine-tune causal encoder and decoder to
yield greedy and beam-search decoding, and is shown to be locally optimal.
Experiments on low-latency chunk sizes (less than 300 msec) show that our
fine-tuned model outperforms existing non-fine-tuned streaming approaches in
most cases, while using a lower complexity. Additionally, we observe that our
training process yields better alignment, enabling a simple method for
extracting word-level timestamps. We release our training and inference code,
along with the fine-tuned models, to support further research and development
in streaming ASR.

</details>


### [188] [Consensus or Conflict? Fine-Grained Evaluation of Conflicting Answers in Question-Answering](https://arxiv.org/abs/2508.12355)
*Eviatar Nachshoni,Arie Cattan,Shmuel Amar,Ori Shapira,Ido Dagan*

Main category: cs.CL

TL;DR: 本研究提出了NATCONFQA基准，用于评估大型语言模型在多答案问答（MAQA）任务中处理冲突答案的能力。结果显示，现有模型在识别和解决冲突方面存在不足。


<details>
  <summary>Details</summary>
Motivation: 多答案问答（MAQA）任务，即一个问题可能有多个有效答案，仍然是一个挑战。现有的MAQA数据集要么成本高昂，要么依赖于合成数据、限制于是非问题或使用未经核实的自动标注。为了在这一领域取得进展，需要能够识别所有有效答案并检测冲突答案对的模型。

Method: 本研究提出了一种新颖且经济高效的方法，利用事实核查数据集来构建NATCONFQA基准。该基准包含现实的、冲突感知的MAQA数据，并为所有答案对提供了详细的冲突标签。研究还评估了八个高端大型语言模型在NATCONFQA上的表现，分析了它们处理各种冲突的策略。

Result: 评估结果表明，现有的大型语言模型在处理MAQA任务中的各种冲突类型时表现脆弱，并且在解决这些冲突时采用了有缺陷的策略。

Conclusion: 该研究通过引入NATCONFQA基准和新的评估方法，推动了多答案问答（MAQA）领域的研究，并揭示了现有大型语言模型在处理冲突答案方面的局限性。

Abstract: Large Language Models (LLMs) have demonstrated strong performance in question
answering (QA) tasks. However, Multi-Answer Question Answering (MAQA), where a
question may have several valid answers, remains challenging. Traditional QA
settings often assume consistency across evidences, but MAQA can involve
conflicting answers. Constructing datasets that reflect such conflicts is
costly and labor-intensive, while existing benchmarks often rely on synthetic
data, restrict the task to yes/no questions, or apply unverified automated
annotation. To advance research in this area, we extend the conflict-aware MAQA
setting to require models not only to identify all valid answers, but also to
detect specific conflicting answer pairs, if any. To support this task, we
introduce a novel cost-effective methodology for leveraging fact-checking
datasets to construct NATCONFQA, a new benchmark for realistic, conflict-aware
MAQA, enriched with detailed conflict labels, for all answer pairs. We evaluate
eight high-end LLMs on NATCONFQA, revealing their fragility in handling various
types of conflicts and the flawed strategies they employ to resolve them.

</details>


### [189] [ReaLM: Reflection-Enhanced Autonomous Reasoning with Small Language Models](https://arxiv.org/abs/2508.12387)
*Yuanfeng Xu,Zehui Dai,Jian Liang,Jiapeng Guan,Guangrun Wang,Liang Lin,Xiaohui Lv*

Main category: cs.CL

TL;DR: ReaLM是一个强化学习框架，通过MRPV、EAAI和引导思维链蒸馏技术，解决了SLM在推理、自主和泛化方面的不足，提升了其在垂直领域的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的SLM在复杂推理方面存在局限性，并且在性能提升上往往牺牲了推理能力、自主性或泛化性。本研究旨在解决这些问题。

Method: 提出了一种名为ReaLM的强化学习框架，包含多路径过程验证（MRPV）以增强推理能力，渐进归纳赋能自主（EAAI）以减少对外部指导的依赖，并采用引导思维链蒸馏以提高泛化性。

Result: 在垂直和通用推理任务上的大量实验表明，ReaLM显著提高了SLM在推理能力、自主性和泛化性方面的性能。

Conclusion: ReaLM框架通过多路径过程验证（MRPV）、渐进归纳赋能自主（EAAI）和引导思维链蒸馏，在增强推理能力、自主性和泛化性方面显著提高了小语言模型（SLM）在垂直领域的性能。

Abstract: Small Language Models (SLMs) are a cost-effective alternative to Large
Language Models (LLMs), but often struggle with complex reasoning due to their
limited capacity and a tendency to produce mistakes or inconsistent answers
during multi-step reasoning. Existing efforts have improved SLM performance,
but typically at the cost of one or more of three key aspects: (1) reasoning
capability, due to biased supervision that filters out negative reasoning paths
and limits learning from errors; (2) autonomy, due to over-reliance on
externally generated reasoning signals; and (3) generalization, which suffers
when models overfit to teacher-specific patterns. In this paper, we introduce
ReaLM, a reinforcement learning framework for robust and self-sufficient
reasoning in vertical domains. To enhance reasoning capability, we propose
Multi-Route Process Verification (MRPV), which contrasts both positive and
negative reasoning paths to extract decisive patterns. To reduce reliance on
external guidance and improve autonomy, we introduce Enabling Autonomy via
Asymptotic Induction (EAAI), a training strategy that gradually fades external
signals. To improve generalization, we apply guided chain-of-thought
distillation to encode domain-specific rules and expert knowledge into SLM
parameters, making them part of what the model has learned. Extensive
experiments on both vertical and general reasoning tasks demonstrate that ReaLM
significantly improves SLM performance across aspects (1)-(3) above.

</details>


### [190] [MedKGent: A Large Language Model Agent Framework for Constructing Temporally Evolving Medical Knowledge Graph](https://arxiv.org/abs/2508.12393)
*Duzhen Zhang,Zixiao Wang,Zhong-Zhi Li,Yahan Yu,Shuncheng Jia,Jiahua Dong,Haotian Xu,Xing Wu,Yingying Zhang,Tielin Zhang,Jie Yang,Xiuying Chen,Le Song*

Main category: cs.CL

TL;DR: MedKGent是一个LLM智能体框架，用于构建时间演化的医学知识图谱，通过日度时间序列处理和智能体协同，实现了高准确率和在下游任务中的优越性能。


<details>
  <summary>Details</summary>
Motivation: 医学文献的快速扩展带来了知识构建和整合的挑战。现有的知识图谱构建方法要么泛化能力有限，要么直接聚合LLM输出，忽略了知识的时间动态性和上下文不确定性。因此，需要一种能够处理不断发展的医学知识的新方法。

Method: MedKGent是一个利用LLM智能体框架构建时间演化医学知识图谱的框架。它采用日度时间序列模拟知识的涌现，并使用提取智能体和构造智能体来逐步构建知识图谱。提取智能体识别知识三元组并进行置信度评分，构造智能体则根据置信度和时间戳整合三元组，以强化重复知识和解决冲突。

Result: MedKGent成功构建了一个包含156,275个实体和2,971,384个关系三元组的医学知识图谱，准确率接近90%。在医学问答基准测试中，使用MedKGent的检索增强生成（RAG）相比基线方法有显著提升。此外，案例研究表明该知识图谱在基于文献的药物重定位方面具有价值。

Conclusion: MedKGent框架能够构建包含156,275个实体和2,971,384个关系三元组的、时间演化的医学知识图谱，其准确率接近90%，并在医学问答和药物重定位等下游任务中表现出显著优势。

Abstract: The rapid expansion of medical literature presents growing challenges for
structuring and integrating domain knowledge at scale. Knowledge Graphs (KGs)
offer a promising solution by enabling efficient retrieval, automated
reasoning, and knowledge discovery. However, current KG construction methods
often rely on supervised pipelines with limited generalizability or naively
aggregate outputs from Large Language Models (LLMs), treating biomedical
corpora as static and ignoring the temporal dynamics and contextual uncertainty
of evolving knowledge. To address these limitations, we introduce MedKGent, a
LLM agent framework for constructing temporally evolving medical KGs.
Leveraging over 10 million PubMed abstracts published between 1975 and 2023, we
simulate the emergence of biomedical knowledge via a fine-grained daily time
series. MedKGent incrementally builds the KG in a day-by-day manner using two
specialized agents powered by the Qwen2.5-32B-Instruct model. The Extractor
Agent identifies knowledge triples and assigns confidence scores via
sampling-based estimation, which are used to filter low-confidence extractions
and inform downstream processing. The Constructor Agent incrementally
integrates the retained triples into a temporally evolving graph, guided by
confidence scores and timestamps to reinforce recurring knowledge and resolve
conflicts. The resulting KG contains 156,275 entities and 2,971,384 relational
triples. Quality assessments by two SOTA LLMs and three domain experts
demonstrate an accuracy approaching 90\%, with strong inter-rater agreement. To
evaluate downstream utility, we conduct RAG across seven medical question
answering benchmarks using five leading LLMs, consistently observing
significant improvements over non-augmented baselines. Case studies further
demonstrate the KG's value in literature-based drug repurposing via
confidence-aware causal inference.

</details>


### [191] [Extracting Post-Acute Sequelae of SARS-CoV-2 Infection Symptoms from Clinical Notes via Hybrid Natural Language Processing](https://arxiv.org/abs/2508.12405)
*Zilong Bai,Zihan Xu,Cong Sun,Chengxi Zang,H. Timothy Bunnell,Catherine Sinfield,Jacqueline Rutter,Aaron Thomas Martinez,L. Charles Bailey,Mark Weiner,Thomas R. Campion,Thomas Carton,Christopher B. Forrest,Rainu Kaushal,Fei Wang,Yifan Peng*

Main category: cs.CL

TL;DR: 该研究开发了一种混合 NLP 模型，通过分析临床笔记来识别 PASC 症状，并在大规模数据集上验证了其有效性和效率，平均 F1 分数达 0.76，处理速度快，为改进 PASC 诊断提供了方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决 PASC 症状多样且随时间演变，导致诊断具有挑战性的问题。

Method: 开发了一个混合自然语言处理流程，整合了基于规则的命名实体识别和基于 BERT 的断言检测模块，用于从临床笔记中提取 PASC 症状和进行断言检测。

Result: 在单站点内部验证中，断言检测的平均 F1 分数为 0.82；在 10 个站点的外部验证中，为 0.76。该流程平均处理每条笔记的时间为 $2.448	ext{±}0.812$ 秒。Spearman 相关性检验显示，阳性提及的 $ho >0.83$，阴性提及的 $ho >0.72$，两者 P 值均小于 0.0001。

Conclusion: 该研究证明了其模型在提高 PASC 诊断方面的有效性和效率，为改进 PASC 诊断提供了潜力。

Abstract: Accurately and efficiently diagnosing Post-Acute Sequelae of COVID-19 (PASC)
remains challenging due to its myriad symptoms that evolve over long- and
variable-time intervals. To address this issue, we developed a hybrid natural
language processing pipeline that integrates rule-based named entity
recognition with BERT-based assertion detection modules for PASC-symptom
extraction and assertion detection from clinical notes. We developed a
comprehensive PASC lexicon with clinical specialists. From 11 health systems of
the RECOVER initiative network across the U.S., we curated 160 intake progress
notes for model development and evaluation, and collected 47,654 progress notes
for a population-level prevalence study. We achieved an average F1 score of
0.82 in one-site internal validation and 0.76 in 10-site external validation
for assertion detection. Our pipeline processed each note at $2.448\pm 0.812$
seconds on average. Spearman correlation tests showed $\rho >0.83$ for positive
mentions and $\rho >0.72$ for negative ones, both with $P <0.0001$. These
demonstrate the effectiveness and efficiency of our models and their potential
for improving PASC diagnosis.

</details>


### [192] [ZigzagAttention: Efficient Long-Context Inference with Exclusive Retrieval and Streaming Heads](https://arxiv.org/abs/2508.12407)
*Zhuorui Liu,Chen Zhang,Dawei Song*

Main category: cs.CL

TL;DR: 检索和流式注意力头被分成单独的层，以减少延迟并保持性能。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的快速发展，处理长上下文已成为大型语言模型的重要能力之一。这种长上下文能力伴随着部署方面的困难，特别是由于 KV 缓存消耗的增加。

Method: 我们设计了一个强制检索或流式注意力头专门聚集在一个唯一层中的标准，以消除额外的延迟。

Result: 通过强制执行检索或流式注意力头专门聚集在一个唯一层中的标准，可以消除额外的延迟，并且只产生可忽略的性能下降。

Conclusion: 我们的方法名为 ZigzagAttention，由于其降低的延迟和相当的性能，在考虑的基线中具有竞争力。

Abstract: With the rapid development of large language models (LLMs), handling long
context has become one of the vital abilities in LLMs. Such long-context
ability is accompanied by difficulties in deployment, especially due to the
increased consumption of KV cache. There is certain work aiming to optimize the
memory footprint of KV cache, inspired by the observation that attention heads
can be categorized into retrieval heads that are of great significance and
streaming heads that are of less significance. Typically, identifying the
streaming heads and and waiving the KV cache in the streaming heads would
largely reduce the overhead without hurting the performance that much. However,
since employing both retrieval and streaming heads in one layer decomposes one
large round of attention computation into two small ones, it may unexpectedly
bring extra latency on accessing and indexing tensors. Based on this intuition,
we impose an important improvement to the identification process of retrieval
and streaming heads, in which we design a criterion that enforces exclusively
retrieval or streaming heads gathered in one unique layer. In this way, we
further eliminate the extra latency and only incur negligible performance
degradation. Our method named \textsc{ZigzagAttention} is competitive among
considered baselines owing to reduced latency and comparable performance.

</details>


### [193] [The Cultural Gene of Large Language Models: A Study on the Impact of Cross-Corpus Training on Model Values and Biases](https://arxiv.org/abs/2508.12411)
*Emanuel Z. Fenech-Borg,Tilen P. Meznaric-Kos,Milica D. Lekovic-Bojovic,Arni J. Hentze-Djurhuus*

Main category: cs.CL

TL;DR: This paper introduces the 'cultural gene' concept to analyze the cultural values of LLMs, finding that GPT-4 reflects Western individualism and ERNIE Bot reflects Eastern collectivism, based on tests using a new dataset. This emphasizes the need for cultural awareness in LLM development and deployment.


<details>
  <summary>Details</summary>
Motivation: The research aims to explore the underexplored cultural and ethical assumptions embedded in widely used Large Language Models (LLMs).

Method: The study proposes the concept of a 'cultural gene' to describe the systematic value orientations LLMs acquire from their training corpora. A Cultural Probe Dataset (CPD) with 200 prompts was created to assess Individualism-Collectivism (IDV) and Power Distance (PDI). GPT-4 and ERNIE Bot were evaluated using zero-shot prompts. Human annotation was used to compare the models, and a Cultural Alignment Index (CAI) was computed against Hofstede's national scores. Qualitative analyses were also performed on dilemma resolution and authority-related judgments.

Result: GPT-4 demonstrated individualistic and low-power-distance tendencies (IDV ~1.21, PDI ~-1.05), aligning more closely with the USA. ERNIE Bot exhibited collectivistic and higher-power-distance tendencies (IDV ~-0.89, PDI ~0.76), aligning more closely with China. These differences were statistically significant (p < 0.001). The CAI scores confirmed GPT-4's alignment with the USA and ERNIE Bot's alignment with China.

Conclusion: LLMs can act as statistical reflections of their cultural training data, highlighting the need for culturally sensitive evaluation and deployment to prevent algorithmic cultural dominance.

Abstract: Large language models (LLMs) are deployed globally, yet their underlying
cultural and ethical assumptions remain underexplored. We propose the notion of
a "cultural gene" -- a systematic value orientation that LLMs inherit from
their training corpora -- and introduce a Cultural Probe Dataset (CPD) of 200
prompts targeting two classic cross-cultural dimensions:
Individualism-Collectivism (IDV) and Power Distance (PDI). Using standardized
zero-shot prompts, we compare a Western-centric model (GPT-4) and an
Eastern-centric model (ERNIE Bot). Human annotation shows significant and
consistent divergence across both dimensions. GPT-4 exhibits individualistic
and low-power-distance tendencies (IDV score approx 1.21; PDI score approx
-1.05), while ERNIE Bot shows collectivistic and higher-power-distance
tendencies (IDV approx -0.89; PDI approx 0.76); differences are statistically
significant (p < 0.001). We further compute a Cultural Alignment Index (CAI)
against Hofstede's national scores and find GPT-4 aligns more closely with the
USA (e.g., IDV CAI approx 0.91; PDI CAI approx 0.88) whereas ERNIE Bot aligns
more closely with China (IDV CAI approx 0.85; PDI CAI approx 0.81). Qualitative
analyses of dilemma resolution and authority-related judgments illustrate how
these orientations surface in reasoning. Our results support the view that LLMs
function as statistical mirrors of their cultural corpora and motivate
culturally aware evaluation and deployment to avoid algorithmic cultural
hegemony.

</details>


### [194] [Uncovering Emergent Physics Representations Learned In-Context by Large Language Models](https://arxiv.org/abs/2508.12448)
*Yeongwoo Song,Jaeyong Bae,Dong-Kyum Kim,Hawoong Jeong*

Main category: cs.CL

TL;DR: LLM能通过上下文学习物理知识，其模型内部特征与能量等物理变量相关。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）的上下文学习（ICL）能力在各种任务中表现出色，但其内部机制仍不明确。物理系统因其可控的真实世界数据和基于基本原理的结构化动力学，成为研究LLM涌现推理行为的理想测试平台，特别是其推理物理学能力。

Method: 通过动力学预测任务评估LLM的ICL能力，并利用稀疏自编码器（SAE）分析模型残差流激活，探究ICL能力的涌现机制。

Result: LLM在物理动力学预测任务中的ICL性能随上下文长度的增加而提高。稀疏自编码器（SAE）捕捉到的特征与能量等关键物理变量相关，表明LLM在ICL过程中编码了有意义的物理概念。

Conclusion: 本研究通过分析物理系统的动力学预测任务，揭示了大型语言模型（LLM）在上下文学习（ICL）过程中能够学习物理概念，并通过稀疏自编码器（SAE）分析模型的残差流激活，发现其特征与能量等关键物理变量相关，证明了LLM在ICL中编码了有意义的物理概念，为理解LLM的上下文学习能力提供了新的视角。

Abstract: Large language models (LLMs) exhibit impressive in-context learning (ICL)
abilities, enabling them to solve wide range of tasks via textual prompts
alone. As these capabilities advance, the range of applicable domains continues
to expand significantly. However, identifying the precise mechanisms or
internal structures within LLMs that allow successful ICL across diverse,
distinct classes of tasks remains elusive. Physics-based tasks offer a
promising testbed for probing this challenge. Unlike synthetic sequences such
as basic arithmetic or symbolic equations, physical systems provide
experimentally controllable, real-world data based on structured dynamics
grounded in fundamental principles. This makes them particularly suitable for
studying the emergent reasoning behaviors of LLMs in a realistic yet tractable
setting. Here, we mechanistically investigate the ICL ability of LLMs,
especially focusing on their ability to reason about physics. Using a dynamics
forecasting task in physical systems as a proxy, we evaluate whether LLMs can
learn physics in context. We first show that the performance of dynamics
forecasting in context improves with longer input contexts. To uncover how such
capability emerges in LLMs, we analyze the model's residual stream activations
using sparse autoencoders (SAEs). Our experiments reveal that the features
captured by SAEs correlate with key physical variables, such as energy. These
findings demonstrate that meaningful physical concepts are encoded within LLMs
during in-context learning. In sum, our work provides a novel case study that
broadens our understanding of how LLMs learn in context.

</details>


### [195] [M3PO: Multimodal-Model-Guided Preference Optimization for Visual Instruction Following](https://arxiv.org/abs/2508.12458)
*Ruirui Gao,Emily Johnson,Bowen Tan,Yanfei Qian*

Main category: cs.CL

TL;DR: 提出了一种名为M3PO的新型数据高效方法，通过结合外部质量评估（MAS）和模型内部置信度，智能地从LVLM生成的候选中选择最有价值的偏好样本对，用于DPO微调，以提升LVLMs在多模态指令遵循方面的能力，并在多项基准测试中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的监督微调（SFT）和现有的偏好优化方法（RLHF、DPO）在利用模型自身生成空间识别“困难负样本”方面效率低下，而人工标注成本高昂且不一致，阻碍了大型视觉-语言模型（LVLMs）在复杂多模态指令遵循方面的进一步发展。

Method: M3PO方法结合了多模态对齐分数（MAS）和模型自洽性/置信度（对数概率）两个信号，生成M3P-Score，用于筛选出优选响应和模型可能自信但错误的拒选响应，然后利用这些高质量的偏好样本对LLaVA-1.5（7B/13B）进行LoRA的DPO微调。

Result: M3PO方法在MME-Bench、POPE、IFT和Human Pref. Score等一系列多模态指令遵循基准测试中，相比SFT、模拟RLHF、Vanilla DPO和RM-DPO等基线方法，展现出持续优越的性能。

Conclusion: M3PO方法在多模态指令遵循任务上表现优于SFT、RLHF、DPO等基线方法，能够高效利用模型自身生成空间来识别有价值的“困难负样本”，提升LVLMs的能力。

Abstract: Large Vision-Language Models (LVLMs) hold immense potential for complex
multimodal instruction following, yet their development is often hindered by
the high cost and inconsistency of human annotation required for effective
fine-tuning and preference alignment. Traditional supervised fine-tuning (SFT)
and existing preference optimization methods like RLHF and DPO frequently
struggle to efficiently leverage the model's own generation space to identify
highly informative "hard negative" samples. To address these challenges, we
propose Multimodal-Model-Guided Preference Optimization (M3PO), a novel and
data-efficient method designed to enhance LVLMs' capabilities in visual
instruction following. M3PO intelligently selects the most "learning-valuable"
preference sample pairs from a diverse pool of LVLM-generated candidates. This
selection is driven by a sophisticated mechanism that integrates two crucial
signals: a Multimodal Alignment Score (MAS) to assess external quality and the
model's Self-Consistency / Confidence (log-probability) to gauge internal
belief. These are combined into a novel M3P-Score, which specifically
identifies preferred responses and challenging dispreferred responses that the
model might confidently generate despite being incorrect. These high-quality
preference pairs are then used for efficient Direct Preference Optimization
(DPO) fine-tuning on base LVLMs like LLaVA-1.5 (7B/13B) using LoRA. Our
extensive experiments demonstrate that M3PO consistently outperforms strong
baselines, including SFT, simulated RLHF, vanilla DPO, and RM-DPO, across a
comprehensive suite of multimodal instruction following benchmarks (MME-Bench,
POPE, IFT, Human Pref. Score).

</details>


### [196] [LoraxBench: A Multitask, Multilingual Benchmark Suite for 20 Indonesian Languages](https://arxiv.org/abs/2508.12459)
*Alham Fikri Aji,Trevor Cohn*

Main category: cs.CL

TL;DR: LoraxBench 是一个针对印度尼西亚低资源语言的 NLP 基准测试，包含六项任务和 20 种语言。评估显示，模型在低资源语言上的表现不佳，并且语域会影响性能。


<details>
  <summary>Details</summary>
Motivation: 印尼尼西亚是世界上人口最多的国家之一，拥有 700 种语言，但在自然语言处理（NLP）方面却落后。

Method: 介绍了一个名为 LoraxBench 的基准测试，该基准测试专注于印度尼西亚的低资源语言，涵盖阅读理解、开放域问答、语言推理、因果推理、翻译和文化问答六项不同任务。该数据集涵盖 20 种语言，并为三种语言增加了两种语域。评估了一系列多语言和区域重点的语言模型。

Result: 评估结果显示，该基准测试对模型来说具有挑战性，在印尼语和其他语言（尤其是低资源语言）之间存在明显的性能差异。区域特定模型与通用多语言模型相比没有明显的领先优势。语域的变化会影响模型性能，特别是对于非社交媒体常用语域（如爪哇语中的高级敬语“Krama”）而言。

Conclusion: 该基准测试对模型来说具有挑战性，并且在印尼语和其他语言（尤其是低资源语言）之间存在明显的性能差异。 区域特定模型与通用多语言模型相比没有明显的领先优势。 此外，语域的变化会影响模型性能，特别是对于非社交媒体常用语域（如爪哇语中的高级敬语“Krama”）而言。

Abstract: As one of the world's most populous countries, with 700 languages spoken,
Indonesia is behind in terms of NLP progress. We introduce LoraxBench, a
benchmark that focuses on low-resource languages of Indonesia and covers 6
diverse tasks: reading comprehension, open-domain QA, language inference,
causal reasoning, translation, and cultural QA. Our dataset covers 20
languages, with the addition of two formality registers for three languages. We
evaluate a diverse set of multilingual and region-focused LLMs and found that
this benchmark is challenging. We note a visible discrepancy between
performance in Indonesian and other languages, especially the low-resource
ones. There is no clear lead when using a region-specific model as opposed to
the general multilingual model. Lastly, we show that a change in register
affects model performance, especially with registers not commonly found in
social media, such as high-level politeness `Krama' Javanese.

</details>


### [197] [Is GPT-OSS Good? A Comprehensive Evaluation of OpenAI's Latest Open Source Models](https://arxiv.org/abs/2508.12461)
*Ziqian Bi,Keyu Chen,Chiung-Yi Tseng,Danyang Zhang,Tianyang Wang,Hongying Luo,Lu Chen,Junming Huang,Jibin Guan,Junfeng Hao,Junhao Song*

Main category: cs.CL

TL;DR: OpenAI


<details>
  <summary>Details</summary>
Motivation: To evaluate OpenAI

Method: The study evaluated two OpenAI GPT-OSS models (120B and 20B parameters) against six contemporary open-source large language models (14.7B to 235B parameters, dense and sparse designs) across ten benchmarks. All models were tested in unquantized form under standardized inference settings, with statistical validation using McNemars test and effect size analysis.

Result: GPT-OSS-20B consistently outperformed GPT-OSS-120B on benchmarks like HumanEval and MMLU, using less memory and energy. Both models showed mid-tier performance, excelling in code generation but struggling with multilingual tasks.

Conclusion: The findings suggest that scaling in sparse architectures may not lead to proportional performance gains, highlighting the need for further research into optimization strategies and guiding more efficient model selection for future open-source deployments.

Abstract: In August 2025, OpenAI released GPT-OSS models, its first open weight large
language models since GPT-2 in 2019, comprising two mixture of experts
architectures with 120B and 20B parameters. We evaluated both variants against
six contemporary open source large language models ranging from 14.7B to 235B
parameters, representing both dense and sparse designs, across ten benchmarks
covering general knowledge, mathematical reasoning, code generation,
multilingual understanding, and conversational ability. All models were tested
in unquantised form under standardised inference settings, with statistical
validation using McNemars test and effect size analysis. Results show that
gpt-oss-20B consistently outperforms gpt-oss-120B on several benchmarks, such
as HumanEval and MMLU, despite requiring substantially less memory and energy
per response. Both models demonstrate mid-tier overall performance within the
current open source landscape, with relative strength in code generation and
notable weaknesses in multilingual tasks. These findings provide empirical
evidence that scaling in sparse architectures may not yield proportional
performance gains, underscoring the need for further investigation into
optimisation strategies and informing more efficient model selection for future
open source deployments.

</details>


### [198] [The Structural Sources of Verb Meaning Revisited: Large Language Models Display Syntactic Bootstrapping](https://arxiv.org/abs/2508.12482)
*Xiaomeng Zhu,R. Thomas McCoy,Robert Frank*

Main category: cs.CL

TL;DR: 大型语言模型在学习动词时也像儿童一样利用句法信息。


<details>
  <summary>Details</summary>
Motivation: 研究探讨了儿童学习动词意义的句法引导假说是否适用于大型语言模型。

Method: 通过在扰动数据集上训练 RoBERTa 和 GPT-2，其中语法信息被消融，来检验大型语言模型是否表现出类似的行为。

Result: 与移除共现信息相比，移除句法线索后模型的动词表征下降更多；心理动词的表征受到的负面影响比物理动词更大；名词的表征受共现扭曲的影响比句法扭曲更大。

Conclusion: 该研究结果强化了句法引导在动词学习中的重要作用，并证明了通过操纵大型语言模型的学习环境来大规模测试发展假设的可行性。

Abstract: Syntactic bootstrapping (Gleitman, 1990) is the hypothesis that children use
the syntactic environments in which a verb occurs to learn its meaning. In this
paper, we examine whether large language models exhibit a similar behavior. We
do this by training RoBERTa and GPT-2 on perturbed datasets where syntactic
information is ablated. Our results show that models' verb representation
degrades more when syntactic cues are removed than when co-occurrence
information is removed. Furthermore, the representation of mental verbs, for
which syntactic bootstrapping has been shown to be particularly crucial in
human verb learning, is more negatively impacted in such training regimes than
physical verbs. In contrast, models' representation of nouns is affected more
when co-occurrences are distorted than when syntax is distorted. In addition to
reinforcing the important role of syntactic bootstrapping in verb learning, our
results demonstrated the viability of testing developmental hypotheses on a
larger scale through manipulating the learning environments of large language
models.

</details>


### [199] [Mitigating Hallucinations in Large Language Models via Causal Reasoning](https://arxiv.org/abs/2508.12495)
*Yuangang Li,Yiqing Shen,Yi Nian,Jiechao Gao,Ziyi Wang,Chenxiao Yu,Shawn Li,Jie Wang,Xiyang Hu,Yue Zhao*

Main category: cs.CL

TL;DR: 提出CDCR-SFT框架，通过显式构建和推理因果DAG来提高LLM的因果推理能力，减少幻觉，并在CLADDER和HaluEval上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM推理方法（如CoT）在token层面操作，未能模拟潜在的因果关系，无法表示条件独立性或满足因果识别假设。旨在解决LLM中出现的逻辑不一致性幻觉问题，并发现其与因果推理能力呈反比关系。

Method: 介绍了一种名为CDCR-SFT的监督微调框架，该框架训练LLM显式构建变量级有向无环图（DAG），并在其上进行推理。此外，还提出了一个包含25,368个样本（CausalDR）的数据集，其中包含输入问题、显式因果DAG、基于图的推理过程和验证后的答案。

Result: 在四个LLM和八个任务上的实验表明，CDCR-SFT将CLADDER的准确率提高到95.33%（首次超越人类94.8%），并将HaluEval上的幻觉减少了10%。

Conclusion: 显式因果结构建模可以有效减轻LLM输出中的逻辑不一致性。

Abstract: Large language models (LLMs) exhibit logically inconsistent hallucinations
that appear coherent yet violate reasoning principles, with recent research
suggesting an inverse relationship between causal reasoning capabilities and
such hallucinations. However, existing reasoning approaches in LLMs, such as
Chain-of-Thought (CoT) and its graph-based variants, operate at the linguistic
token level rather than modeling the underlying causal relationships between
variables, lacking the ability to represent conditional independencies or
satisfy causal identification assumptions. To bridge this gap, we introduce
causal-DAG construction and reasoning (CDCR-SFT), a supervised fine-tuning
framework that trains LLMs to explicitly construct variable-level directed
acyclic graph (DAG) and then perform reasoning over it. Moreover, we present a
dataset comprising 25,368 samples (CausalDR), where each sample includes an
input question, explicit causal DAG, graph-based reasoning trace, and validated
answer. Experiments on four LLMs across eight tasks show that CDCR-SFT improves
the causal reasoning capability with the state-of-the-art 95.33% accuracy on
CLADDER (surpassing human performance of 94.8% for the first time) and reduces
the hallucination on HaluEval with 10% improvements. It demonstrates that
explicit causal structure modeling in LLMs can effectively mitigate logical
inconsistencies in LLM outputs. Code is available at
https://github.com/MrLYG/CDCR-SFT.

</details>


### [200] [CorrSteer: Steering Improves Task Performance and Safety in LLMs through Correlation-based Sparse Autoencoder Feature Selection](https://arxiv.org/abs/2508.12535)
*Seonglae Cho,Zekun Wu,Adriano Koshiyama*

Main category: cs.CL

TL;DR: CorrSteer 是一种新方法，可通过关联样本正确性与 SAE 激活来选择特征，从而克服了 SAE 在下游任务中的局限性。它通过使用推理时激活和平均激活来自动化整个流程，在各种基准测试中均显示出改进的性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 稀疏自动编码器 (SAE) 可以在没有监督的情况下从大型语言模型 (LLM) 中提取可解释的特征。然而，它们在下游转向任务中的有效性受到对比数据集或大型激活存储要求的限制。

Method: CorrSteer 通过在推理时关联样本正确性与生成令牌的 SAE 激活来选择特征。此方法仅使用推理时激活来提取更相关的特征，从而避免了虚假相关性。它还从平均激活中获得转向系数，从而自动化了整个流程。

Result: 在 Gemma 2 2B 和 LLaMA 3.1 8B 上的 QA、偏差缓解、越狱预防和推理基准上，我们的方法在任务性能上有所提高，特别是在 MMLU 性能上提高了 +4.1%，在 HarmBench 上提高了 +22.9%，而样本量仅为 4000 个。

Conclusion: 所选特征证明了与任务要求相一致的语义模式，揭示了驱动性能的潜在能力。我们的工作将基于相关性的选择确立为一种有效且可扩展的方法，可用于语言模型应用程序中的自动化 SAE 转向。

Abstract: Sparse Autoencoders (SAEs) can extract interpretable features from large
language models (LLMs) without supervision. However, their effectiveness in
downstream steering tasks is limited by the requirement for contrastive
datasets or large activation storage. To address these limitations, we propose
CorrSteer, which selects features by correlating sample correctness with SAE
activations from generated tokens at inference time. This approach uses only
inference-time activations to extract more relevant features, thereby avoiding
spurious correlations. It also obtains steering coefficients from average
activations, automating the entire pipeline. Our method shows improved task
performance on QA, bias mitigation, jailbreaking prevention, and reasoning
benchmarks on Gemma 2 2B and LLaMA 3.1 8B, notably achieving a +4.1%
improvement in MMLU performance and a +22.9% improvement in HarmBench with only
4000 samples. Selected features demonstrate semantically meaningful patterns
aligned with each task's requirements, revealing the underlying capabilities
that drive performance. Our work establishes correlationbased selection as an
effective and scalable approach for automated SAE steering across language
model applications.

</details>


### [201] [Beyond Modality Limitations: A Unified MLLM Approach to Automated Speaking Assessment with Effective Curriculum Learning](https://arxiv.org/abs/2508.12591)
*Yu-Hsuan Fang,Tien-Hong Lo,Yao-Ting Sung,Berlin Chen*

Main category: cs.CL

TL;DR: 本文首次系统研究了多模态大语言模型（MLLM）在自动口语评估（ASA）中的应用，发现MLLM在内容和语言运用方面表现优于传统方法，但在交付评估方面存在挑战。为解决此问题，提出了一种名为“Speech-First Multimodal Training”（SFMT）的策略，通过课程学习优先进行语音建模，再进行跨模态融合，从而提升了整体评估性能，尤其是在交付评估方面取得了显著进步。


<details>
  <summary>Details</summary>
Motivation: 传统的自动口语评估（ASA）系统存在模态限制：基于文本的方法缺乏声学信息，而基于音频的方法则遗漏了语义上下文。多模态大语言模型（MLLM）通过在统一框架内同步处理音频和文本，为全面的ASA提供了前所未有的机会。

Method: 提出了一种名为“Speech-First Multimodal Training”（SFMT）的培训策略，该策略采用课程学习原则，在跨模态融合之前，先建立更强大的语音建模基础。

Result: 在基准数据集上进行的一系列实验表明，基于MLLM的系统可以将整体评估性能从0.783的相关系数（PCC）提升到0.846。特别是，SFMT在交付方面的评估方面表现出色，与传统的培训方法相比，准确率提高了4%。

Conclusion: MLLM在全面的口语评估中表现出优越性能，但交付方面的评估存在挑战。提出的SFMT策略通过课程学习，优先考虑语音建模，可以提高评估的整体性能，特别是在交付方面。

Abstract: Traditional Automated Speaking Assessment (ASA) systems exhibit inherent
modality limitations: text-based approaches lack acoustic information while
audio-based methods miss semantic context. Multimodal Large Language Models
(MLLM) offer unprecedented opportunities for comprehensive ASA by
simultaneously processing audio and text within unified frameworks. This paper
presents a very first systematic study of MLLM for comprehensive ASA,
demonstrating the superior performance of MLLM across the aspects of content
and language use . However, assessment on the delivery aspect reveals unique
challenges, which is deemed to require specialized training strategies. We thus
propose Speech-First Multimodal Training (SFMT), leveraging a curriculum
learning principle to establish more robust modeling foundations of speech
before cross-modal synergetic fusion. A series of experiments on a benchmark
dataset show MLLM-based systems can elevate the holistic assessment performance
from a PCC value of 0.783 to 0.846. In particular, SFMT excels in the
evaluation of the delivery aspect, achieving an absolute accuracy improvement
of 4% over conventional training approaches, which also paves a new avenue for
ASA.

</details>


### [202] [Semantic Anchoring in Agentic Memory: Leveraging Linguistic Structures for Persistent Conversational Context](https://arxiv.org/abs/2508.12630)
*Maitreyi Chatterjee,Devansh Agarwal*

Main category: cs.CL

TL;DR: LLM在长期对话中记忆力有限。我们提出了Semantic Anchoring，一种结合显式语言线索（如句法依赖、话语关系和指代消解）的混合代理记忆架构，以增强基于向量的记忆。实验表明，与RAG相比，该方法可将事实回忆和话语连贯性提高18%。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在多轮和长期交互中的有效性受到有限的记忆持久性的限制。典型检索增强生成（RAG）系统将对话历史存储为稠密向量，这会捕获语义相似性，但忽略了更精细的语言结构，例如句法依赖关系、话语关系和指代链接。

Method: 提出了一种名为Semantic Anchoring的混合代理记忆架构，该架构通过显式语言线索来丰富基于向量的存储，以改进细微、富含上下文的交流的召回率。

Result: 实验表明，语义锚定在事实回忆和话语连贯性方面比强大的RAG基线提高了高达18%。还进行了消融研究、人类评估和错误分析，以评估稳健性和可解释性。

Conclusion: Semantic Anchoring通过结合依赖关系解析、话语关系标记和指代消解等显式语言线索来丰富基于向量的存储，从而改进了长时对话中细微、富含上下文的交流的召回率，在事实回忆和话语连贯性方面比强大的RAG基线提高了18%。

Abstract: Large Language Models (LLMs) have demonstrated impressive fluency and task
competence in conversational settings. However, their effectiveness in
multi-session and long-term interactions is hindered by limited memory
persistence. Typical retrieval-augmented generation (RAG) systems store
dialogue history as dense vectors, which capture semantic similarity but
neglect finer linguistic structures such as syntactic dependencies, discourse
relations, and coreference links. We propose Semantic Anchoring, a hybrid
agentic memory architecture that enriches vector-based storage with explicit
linguistic cues to improve recall of nuanced, context-rich exchanges. Our
approach combines dependency parsing, discourse relation tagging, and
coreference resolution to create structured memory entries. Experiments on
adapted long-term dialogue datasets show that semantic anchoring improves
factual recall and discourse coherence by up to 18% over strong RAG baselines.
We further conduct ablation studies, human evaluations, and error analysis to
assess robustness and interpretability.

</details>


### [203] [Beyond GPT-5: Making LLMs Cheaper and Better via Performance-Efficiency Optimized Routing](https://arxiv.org/abs/2508.12631)
*Yiqun Zhang,Hao Li,Jianhao Chen,Hangfan Zhang,Peng Ye,Lei Bai,Shuyue Hu*

Main category: cs.CL

TL;DR: Avengers-Pro is a test-time routing framework that ensembles LLMs to balance performance and efficiency. It routes queries to suitable models based on a performance-efficiency score, achieving state-of-the-art results, outperforming GPT-5-medium by +7% in accuracy, and offering significant cost savings.


<details>
  <summary>Details</summary>
Motivation: The central challenge in LLM advancement is balancing performance and efficiency. Existing methods like GPT-5

Method: Avengers-Pro utilizes a test-time routing framework that ensembles LLMs of varying capacities and efficiencies. It works by embedding and clustering incoming queries, then routing each query to the most suitable model based on a calculated performance-efficiency score.

Result: Avengers-Pro achieves state-of-the-art results across 6 challenging benchmarks and 8 leading models, including GPT-5-medium, Gemini-2.5-pro, and Claude-opus-4.1. It demonstrates significant improvements in accuracy and cost reduction compared to single models, and establishes a Pareto frontier.

Conclusion: Avengers-Pro achieves state-of-the-art results by enabling a tunable trade-off between performance and efficiency. It can surpass the strongest single model (GPT-5-medium) by +7% in average accuracy, match its accuracy at 27% lower cost, or reach ~90% of its performance at 63% lower cost. Furthermore, it establishes a Pareto frontier, consistently offering the best accuracy for a given cost or the lowest cost for a given accuracy.

Abstract: Balancing performance and efficiency is a central challenge in large language
model (LLM) advancement. GPT-5 addresses this with test-time routing,
dynamically assigning queries to either an efficient or a high-capacity model
during inference. In this work, we present Avengers-Pro, a test-time routing
framework that ensembles LLMs of varying capacities and efficiencies, providing
a unified solution for all performance-efficiency tradeoffs. The Avengers-Pro
embeds and clusters incoming queries, then routes each to the most suitable
model based on a performance-efficiency score. Across 6 challenging benchmarks
and 8 leading models -- including GPT-5-medium, Gemini-2.5-pro, and
Claude-opus-4.1 -- Avengers-Pro achieves state-of-the-art results: by varying a
performance-efficiency trade-off parameter, it can surpass the strongest single
model (GPT-5-medium) by +7% in average accuracy. Moreover, it can match the
average accuracy of the strongest single model at 27% lower cost, and reach
~90% of that performance at 63% lower cost. Last but not least, it achieves a
Pareto frontier, consistently yielding the highest accuracy for any given cost,
and the lowest cost for any given accuracy, among all single models. Code is
available at https://github.com/ZhangYiqun018/AvengersPro.

</details>


### [204] [Prompt-Induced Linguistic Fingerprints for LLM-Generated Fake News Detection](https://arxiv.org/abs/2508.12632)
*Chi Wang,Min Gao,Zongwei Wang,Junwei Yin,Kai Shu,Chenghua Lin*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: With the rapid development of large language models, the generation of fake
news has become increasingly effortless, posing a growing societal threat and
underscoring the urgent need for reliable detection methods. Early efforts to
identify LLM-generated fake news have predominantly focused on the textual
content itself; however, because much of that content may appear coherent and
factually consistent, the subtle traces of falsification are often difficult to
uncover. Through distributional divergence analysis, we uncover prompt-induced
linguistic fingerprints: statistically distinct probability shifts between
LLM-generated real and fake news when maliciously prompted. Based on this
insight, we propose a novel method named Linguistic Fingerprints Extraction
(LIFE). By reconstructing word-level probability distributions, LIFE can find
discriminative patterns that facilitate the detection of LLM-generated fake
news. To further amplify these fingerprint patterns, we also leverage
key-fragment techniques that accentuate subtle linguistic differences, thereby
improving detection reliability. Our experiments show that LIFE achieves
state-of-the-art performance in LLM-generated fake news and maintains high
performance in human-written fake news. The code and data are available at
https://anonymous.4open.science/r/LIFE-E86A.

</details>


### [205] [Breaking Language Barriers: Equitable Performance in Multilingual Language Models](https://arxiv.org/abs/2508.12662)
*Tanay Nagar,Grigorii Khvatskii,Anna Sokol,Nitesh V. Chawla*

Main category: cs.CL

TL;DR: LLM在低资源语言上的常识推理能力较差，可以通过在混合语言文本上微调来提高其性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决LLM在低资源语言（如印地语或斯瓦希里语）上的常识推理能力不如高资源语言（如英语）的问题，确保不同语言社区的公平性。

Method: 提出了一种在合成的语料混合文本上对LLM进行微调的方法，该方法使用受控的语言混合技术生成文本。

Result: 在合成的语料混合数据集上微调LLM可以显著提高其在低资源语言上的性能，同时保持或提高其在高资源语言上的性能。

Conclusion: 通过在合成的语料混合文本上对LLM进行微调，可以提高其在低资源语言上的常识推理能力，同时保持或提高其在高资源语言上的性能。

Abstract: Cutting-edge LLMs have emerged as powerful tools for multilingual
communication and understanding. However, LLMs perform worse in Common Sense
Reasoning (CSR) tasks when prompted in low-resource languages (LRLs) like Hindi
or Swahili compared to high-resource languages (HRLs) like English. Equalizing
this inconsistent access to quality LLM outputs is crucial to ensure fairness
for speakers of LRLs and across diverse linguistic communities. In this paper,
we propose an approach to bridge this gap in LLM performance. Our approach
involves fine-tuning an LLM on synthetic code-switched text generated using
controlled language-mixing methods. We empirically demonstrate that fine-tuning
LLMs on synthetic code-switched datasets leads to substantial improvements in
LRL model performance while preserving or enhancing performance in HRLs.
Additionally, we present a new dataset of synthetic code-switched text derived
from the CommonSenseQA dataset, featuring three distinct language ratio
configurations.

</details>


### [206] [Leveraging Large Language Models for Predictive Analysis of Human Misery](https://arxiv.org/abs/2508.12669)
*Bishanka Seal,Rahul Seetharaman,Aman Bansal,Abhilash Nandy*

Main category: cs.CL

TL;DR: LLMs can predict human misery scores using few-shot prompting. A new game show format tests their dynamic emotional reasoning and ability to learn from feedback, showing promising results beyond simple regression.


<details>
  <summary>Details</summary>
Motivation: To investigate the use of LLMs for predicting human-perceived misery scores from natural language descriptions and to assess their ability to adapt based on corrective feedback in a dynamic setting.

Method: The study frames the task as a regression problem, predicting misery scores from 0 to 100. It evaluates zero-shot, fixed-context few-shot, and retrieval-based prompting. A novel gamified framework, the 'Misery Game Show', is introduced for dynamic evaluation, testing LLMs through structured rounds of ordinal comparison, binary classification, scalar estimation, and feedback-driven reasoning.

Result: Few-shot approaches outperform zero-shot baselines. The 'Misery Game Show' evaluation shows the potential of LLMs in dynamic emotional reasoning tasks beyond standard regression.

Conclusion: LLMs can be used for predicting human-perceived misery scores, and few-shot prompting strategies are more effective than zero-shot. The 'Misery Game Show' framework demonstrates LLMs' potential in dynamic emotional reasoning and adaptation to feedback.

Abstract: This study investigates the use of Large Language Models (LLMs) for
predicting human-perceived misery scores from natural language descriptions of
real-world scenarios. The task is framed as a regression problem, where the
model assigns a scalar value from 0 to 100 to each input statement. We evaluate
multiple prompting strategies, including zero-shot, fixed-context few-shot, and
retrieval-based prompting using BERT sentence embeddings. Few-shot approaches
consistently outperform zero-shot baselines, underscoring the value of
contextual examples in affective prediction. To move beyond static evaluation,
we introduce the "Misery Game Show", a novel gamified framework inspired by a
television format. It tests LLMs through structured rounds involving ordinal
comparison, binary classification, scalar estimation, and feedback-driven
reasoning. This setup enables us to assess not only predictive accuracy but
also the model's ability to adapt based on corrective feedback. The gamified
evaluation highlights the broader potential of LLMs in dynamic emotional
reasoning tasks beyond standard regression. Code and data link:
https://github.com/abhi1nandy2/Misery_Data_Exps_GitHub

</details>


### [207] [ToolACE-MT: Non-Autoregressive Generation for Agentic Multi-Turn Interaction](https://arxiv.org/abs/2508.12685)
*Xingshan Zeng,Weiwen Liu,Lingzhi Wang,Liangyou Li,Fei Mi,Yasheng Wang,Lifeng Shang,Xin Jiang,Qun Liu*

Main category: cs.CL

TL;DR: ToolACE-MT is a new framework for generating high-quality multi-turn agentic dialogues efficiently and effectively, addressing limitations of existing methods by using a three-stage process (initialization, refinement, verification) instead of costly autoregressive interactions.


<details>
  <summary>Details</summary>
Motivation: Existing simulation-based data generation methods for agentic task-solving with LLMs rely heavily on costly autoregressive interactions between multiple LLM agents, limiting real-world performance.

Method: ToolACE-MT framework generates full conversational trajectories through three stages: coarse-grained initialization, iterative refinement, and offline verification. Initialization builds a structurally complete yet semantically coarse dialogue skeleton; refinement introduces realistic complexities and continued refinement via mask-and-fill operations; verification ensures correctness and coherence via rule- and model-based checks.

Result: Experiments demonstrate that ToolACE-MT enables efficient, effective and generalizable agentic data generation.

Conclusion: ToolACE-MT enables efficient, effective and generalizable agentic data generation, offering a new paradigm for high-quality data construction in tool-augmented LLM scenarios.

Abstract: Agentic task-solving with Large Language Models (LLMs) requires multi-turn,
multi-step interactions, often involving complex function calls and dynamic
user-agent exchanges. Existing simulation-based data generation methods for
such scenarios rely heavily on costly autoregressive interactions between
multiple LLM agents, thereby limiting real-world performance of agentic tasks.
In this paper, we propose a novel Non-Autoregressive Iterative Generation
framework, called ToolACE-MT, for constructing high-quality multi-turn agentic
dialogues. ToolACE-MT generates full conversational trajectories through three
stages: coarse-grained initialization, iterative refinement, and offline
verification. The initialization phase builds a structurally complete yet
semantically coarse dialogue skeleton; the iterative refinement phase
introduces realistic complexities and continued refinement via mask-and-fill
operations; and the offline verification phase ensures correctness and
coherence via rule- and model-based checks. Experiments demonstrate that
ToolACE-MT enables efficient, effective and generalizable agentic data
generation, offering a new paradigm for high-quality data construction in
tool-augmented LLM scenarios.

</details>


### [208] [DESIGNER: Design-Logic-Guided Multidisciplinary Data Synthesis for LLM Reasoning](https://arxiv.org/abs/2508.12726)
*Weize Liu,Yongchi Zhao,Yijia Luo,Mingyu Xu,Jiaheng Liu,Yanan Li,Xiguo Hu,Yuchi Xu,Wenbo Su,Bo Zheng*

Main category: cs.CL

TL;DR: 为了解决现有推理数据集在多学科复杂推理方面的不足，我们提出了DESIGNER数据合成流水线，通过引入“设计逻辑”概念，利用LLMs从大量文本中生成了包含数百万个跨学科推理问题的DLR-Book和DLR-Web数据集。实验证明，这些数据集能有效提升模型的推理能力，超越现有数据集和官方模型。


<details>
  <summary>Details</summary>
Motivation: 现有的推理数据集在学科广度和结构深度上存在不足，难以有效激发语言模型进行复杂的多步推理，尤其是在跨学科场景下。

Method: 提出了一种名为DESIGNER的数据合成流水线，该流水线利用设计逻辑（模仿人类出题者的出题过程）来生成多学科的复杂推理问题。具体而言，首先利用LLMs从现有的12万个跨学科问题中逆向工程和抽象化出设计逻辑，然后将这些设计逻辑与学科源材料进行匹配，最终合成了DLR-Book（304万个问题）和DLR-Web（166万个问题）两个大型数据集。

Result: 合成的数据集在难度和多样性上显著优于现有基线数据集。在Qwen3-8B-Base和Qwen3-4B模型上进行的SFT实验证明，使用新数据集训练的模型在多学科推理任务上表现更优，并且在使用了全部数据集后，其性能甚至超过了官方的Qwen3-8B和Qwen3-4B模型。

Conclusion: 通过对现有数据集进行逆向工程和抽象化，我们引入了“设计逻辑”概念，并成功利用该概念合成了两个大规模、跨越75个学科的推理数据集（DLR-Book和DLR-Web）。实验结果表明，这些数据集在难度和多样性上均优于现有数据集，并且能够显著提升语言模型的多学科推理能力，甚至超越了官方模型。

Abstract: Large language models (LLMs) have achieved remarkable success in many natural
language tasks but still struggle with complex, multi-step reasoning,
particularly across diverse disciplines. Existing reasoning datasets often
either lack disciplinary breadth or the structural depth necessary to elicit
robust reasoning behaviors. We propose DESIGNER: a DESIGN-logic-guidEd
Reasoning data synthesis pipeline that leverages naturally available, extensive
raw documents (book corpus and web corpus) to generate multidisciplinary
challenging questions. A core innovation of our approach is the introduction of
a Design Logic concept, which mimics the question-creation process of human
educators. We use LLMs to reverse-engineer and abstract over 120,000 design
logics from existing questions across various disciplines. By matching these
design logics with disciplinary source materials, we are able to create
reasoning questions that far surpass the difficulty and diversity of existing
datasets. Based on this pipeline, we synthesized two large-scale reasoning
datasets that span 75 disciplines: Design-Logic-Reasoning-Book (DLR-Book),
containing 3.04 million challenging questions synthesized from the book corpus,
and Design-Logic-Reasoning-Web (DLR-Web), with 1.66 million challenging
questions from the web corpus. Our data analysis demonstrates that the
questions synthesized by our method exhibit substantially greater difficulty
and diversity than those in the baseline datasets. We validate the
effectiveness of these datasets by conducting SFT experiments on the
Qwen3-8B-Base and Qwen3-4B-Base models. The results show that our dataset
significantly outperforms existing multidisciplinary datasets of the same
volume. Training with the full datasets further enables the models to surpass
the multidisciplinary reasoning performance of the official Qwen3-8B and
Qwen3-4B models.

</details>


### [209] [LinguaSafe: A Comprehensive Multilingual Safety Benchmark for Large Language Models](https://arxiv.org/abs/2508.12733)
*Zhiyuan Ning,Tianle Gu,Jiaxin Song,Shixin Hong,Lingyu Li,Huacan Liu,Jie Li,Yixu Wang,Meng Lingyu,Yan Teng,Yingchun Wang*

Main category: cs.CL

TL;DR: LinguaSafe是一个包含12种语言的45k个条目的多语言安全基准，用于评估大型语言模型的安全性，解决了现有评估的不足，并强调了对LLM进行多语言安全评估的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM多语言安全评估的不足，缺乏全面的评估和多样化的数据，阻碍了鲁棒的多语言安全对齐的发展。

Method: LinguaSafe是一个包含45k个条目的多语言安全基准，涵盖12种语言，通过翻译、转创和本地来源数据进行策划。它提供了一个多维度、细粒度的评估框架，包括直接和间接安全评估，以及过度敏感性评估。

Result: 不同领域和不同语言的安全性和有用性评估结果存在显著差异，即使在资源水平相似的语言之间也是如此。

Conclusion: 评估LLM的多语言安全对于实现更均衡的安全对齐至关重要。LinguaSafe基准为深入的安全评估提供了全面的指标。

Abstract: The widespread adoption and increasing prominence of large language models
(LLMs) in global technologies necessitate a rigorous focus on ensuring their
safety across a diverse range of linguistic and cultural contexts. The lack of
a comprehensive evaluation and diverse data in existing multilingual safety
evaluations for LLMs limits their effectiveness, hindering the development of
robust multilingual safety alignment. To address this critical gap, we
introduce LinguaSafe, a comprehensive multilingual safety benchmark crafted
with meticulous attention to linguistic authenticity. The LinguaSafe dataset
comprises 45k entries in 12 languages, ranging from Hungarian to Malay. Curated
using a combination of translated, transcreated, and natively-sourced data, our
dataset addresses the critical need for multilingual safety evaluations of
LLMs, filling the void in the safety evaluation of LLMs across diverse
under-represented languages from Hungarian to Malay. LinguaSafe presents a
multidimensional and fine-grained evaluation framework, with direct and
indirect safety assessments, including further evaluations for oversensitivity.
The results of safety and helpfulness evaluations vary significantly across
different domains and different languages, even in languages with similar
resource levels. Our benchmark provides a comprehensive suite of metrics for
in-depth safety evaluation, underscoring the critical importance of thoroughly
assessing multilingual safety in LLMs to achieve more balanced safety
alignment. Our dataset and code are released to the public to facilitate
further research in the field of multilingual LLM safety.

</details>


### [210] [CRED-SQL: Enhancing Real-world Large Scale Database Text-to-SQL Parsing through Cluster Retrieval and Execution Description](https://arxiv.org/abs/2508.12769)
*Shaoming Duan,Zirui Wang,Chuanyi Liu,Zhibin Zhu,Yuhao Zhang,Peiyi Han,Liang Yan,Zewu Penge*

Main category: cs.CL

TL;DR: CRED-SQL 框架通过聚类检索和执行描述（EDL）解决了大型数据库中文本到 SQL 的语义不匹配问题，在 SpiderUnion 和 BirdUnion 数据集上达到了新的 SOTA 性能。


<details>
  <summary>Details</summary>
Motivation: 现有的 Text-to-SQL 系统在处理大型数据库时，自然语言问题（NLQ）和相应的 SQL 查询之间仍然存在语义不匹配的挑战。这在大型数据库中尤为严重，因为语义相似的属性会阻碍模式链接和 SQL 生成过程中的语义漂移，最终降低模型准确性。

Method: CRED-SQL 框架集成了聚类检索和执行描述。它首先进行基于聚类的大规模模式检索，以精确定位与给定 NLQ 最相关的表和列，从而缓解模式不匹配问题。然后，它引入了一个中间自然语言表示——执行描述语言（EDL）——来弥合 NLQ 和 SQL 之间的差距。该框架将任务分解为两个阶段：Text-to-EDL 和 EDL-to-SQL，利用 LLM 的强大通用推理能力，同时减少语义偏差。

Result: CRED-SQL 框架通过聚类检索和执行描述（EDL）的引入，成功解决了大型数据库中的语义不匹配问题，并在 SpiderUnion 和 BirdUnion 数据集上取得了新的最先进（SOTA）性能。

Conclusion: CRED-SQL 在两个大规模、跨域基准测试（SpiderUnion 和 BirdUnion）上实现了新的最先进（SOTA）性能，验证了其有效性和可扩展性。

Abstract: Recent advances in large language models (LLMs) have significantly improved
the accuracy of Text-to-SQL systems. However, a critical challenge remains: the
semantic mismatch between natural language questions (NLQs) and their
corresponding SQL queries. This issue is exacerbated in large-scale databases,
where semantically similar attributes hinder schema linking and semantic drift
during SQL generation, ultimately reducing model accuracy. To address these
challenges, we introduce CRED-SQL, a framework designed for large-scale
databases that integrates Cluster Retrieval and Execution Description. CRED-SQL
first performs cluster-based large-scale schema retrieval to pinpoint the
tables and columns most relevant to a given NLQ, alleviating schema mismatch.
It then introduces an intermediate natural language representation-Execution
Description Language (EDL)-to bridge the gap between NLQs and SQL. This
reformulation decomposes the task into two stages: Text-to-EDL and EDL-to-SQL,
leveraging LLMs' strong general reasoning capabilities while reducing semantic
deviation. Extensive experiments on two large-scale, cross-domain
benchmarks-SpiderUnion and BirdUnion-demonstrate that CRED-SQL achieves new
state-of-the-art (SOTA) performance, validating its effectiveness and
scalability. Our code is available at https://github.com/smduan/CRED-SQL.git

</details>


### [211] [From SALAMANDRA to SALAMANDRATA: BSC Submission for WMT25 General Machine Translation Shared Task](https://arxiv.org/abs/2508.12774)
*Javier Garcia Gilabert,Xixian Liao,Severino Da Dalt,Ella Bohman,Audrey Mash,Francesca De Luca Fornaciari,Irene Baucells,Joan Llop,Miguel Claramunt Argote,Carlos Escolano,Maite Melero*

Main category: cs.CL

TL;DR: SALAMANDRATA is a new family of LLMs (2B and 7B parameters) for European language translation, trained with a novel method and achieving strong results in WMT25. Models are released publicly.


<details>
  <summary>Details</summary>
Motivation: To develop improved language models (SALAMANDRATA family) based on SALAMANDRA LLMs, specifically trained for strong performance in translation-related tasks across 38 European languages, and to participate in the WMT25 General Machine Translation shared task.

Method: The SALAMANDRATA models were trained using a two-step process: continual pre-training on parallel data, followed by supervised fine-tuning on high-quality instructions. For the WMT25 task, the 7B variant was adapted with an expanded vocabulary for non-European languages, and further trained with a focus on optimizing performance across all translation directions. Decoding involved Minimum Bayes Risk Decoding and Tuned Re-ranking using COMET and COMET-KIWI.

Result: The SALAMANDRATA models, particularly the 7B variant used for the WMT25 task, achieved strong performance in translation for 38 European languages. The models are publicly available for research.

Conclusion: SALAMANDRATA models, including 2B and 7B parameter versions, are publicly released on Hugging Face, along with SALAMANDRATA-V2, demonstrating strong performance in translation for 38 European languages.

Abstract: In this paper, we present the SALAMANDRATA family of models, an improved
iteration of SALAMANDRA LLMs (Gonzalez-Agirre et al., 2025) specifically
trained to achieve strong performance in translation-related tasks for 38
European languages. SALAMANDRATA comes in two scales: 2B and 7B parameters. For
both versions, we applied the same training recipe with a first step of
continual pre-training on parallel data, and a second step of supervised
fine-tuning on high-quality instructions. The BSC submission to the WMT25
General Machine Translation shared task is based on the 7B variant of
SALAMANDRATA. We first adapted the model vocabulary to support the additional
non-European languages included in the task. This was followed by a second
phase of continual pre-training and supervised fine-tuning, carefully designed
to optimize performance across all translation directions for this year's
shared task. For decoding, we employed two quality-aware strategies: Minimum
Bayes Risk Decoding and Tuned Re-ranking using COMET and COMET-KIWI
respectively. We publicly release both the 2B and 7B versions of SALAMANDRATA,
along with the newer SALAMANDRATA-V2 model, on Hugging Face1

</details>


### [212] [HeteroRAG: A Heterogeneous Retrieval-Augmented Generation Framework for Medical Vision Language Tasks](https://arxiv.org/abs/2508.12778)
*Zhe Chen,Yusheng Liao,Shuyang Jiang,Zhiyuan Zhu,Haolin Li,Yanfeng Wang,Yu Wang*

Main category: cs.CL

TL;DR: Med-LVLMs 在临床应用中存在事实不准确和输出不可靠的问题。为了解决这个问题，我们提出了 HeteroRAG 框架，通过结合 MedAtlas（一个包含多模态报告和文本语料库的数据集）和新的检索与训练策略，显著提高了 Med-LVLMs 的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前的医疗多模态检索增强生成系统在跨异构源进行有效检索方面存在不足，检索到的报告的相关性不足以及知识不足影响了分析的事实性和临床决策的可信度。

Method: 提出了一种名为 HeteroRAG 的新颖框架，该框架通过以下方式增强 Med-LVLMs：1. 引入特定于模态的 CLIP，用于有效的报告检索。 2. 引入多语料库查询生成器，用于动态构建针对不同语料库的查询。 3. 使用异构知识偏好调整来训练 Med-LVLM，以实现跨模态和多源知识对齐。

Result: HeteroRAG 在12个数据集和3个模态的广泛实验中，在大多数医疗视觉语言基准测试中取得了最先进的性能，显著提高了 Med-LVLMs 的事实准确性和可靠性。

Conclusion: MedAtlas (包含广泛的多模态报告存储库和多样化的文本语料库) 结合 HeteroRAG (一种通过异构知识源增强 Med-LVLMs 的框架) 能够显著提高 Med-LVLMs 在事实准确性和可靠性方面的表现，在12个数据集和3个模态的广泛实验中达到了最先进的性能。

Abstract: Medical large vision-language Models (Med-LVLMs) have shown promise in
clinical applications but suffer from factual inaccuracies and unreliable
outputs, posing risks in real-world diagnostics. While retrieval-augmented
generation has emerged as a potential solution, current medical multimodal RAG
systems are unable to perform effective retrieval across heterogeneous sources.
The irrelevance of retrieved reports affects the factuality of analysis, while
insufficient knowledge affects the credibility of clinical decision-making. To
bridge the gap, we construct MedAtlas, which includes extensive multimodal
report repositories and diverse text corpora. Based on it, we present
HeteroRAG, a novel framework that enhances Med-LVLMs through heterogeneous
knowledge sources. The framework introduces Modality-specific CLIPs for
effective report retrieval and a Multi-corpora Query Generator for dynamically
constructing queries for diverse corpora. Incorporating knowledge from such
multifaceted sources, Med-LVLM is then trained with Heterogeneous Knowledge
Preference Tuning to achieve cross-modality and multi-source knowledge
alignment. Extensive experiments across 12 datasets and 3 modalities
demonstrate that the proposed HeteroRAG achieves state-of-the-art performance
in most medical vision language benchmarks, significantly improving factual
accuracy and reliability of Med-LVLMs.

</details>


### [213] [Atom-Searcher: Enhancing Agentic Deep Research via Fine-Grained Atomic Thought Reward](https://arxiv.org/abs/2508.12800)
*Yong Deng,Guoqing Wang,Zhenzhe Ying,Xiaofeng Wu,Jinzhen Lin,Wenwen Xiong,Yuqin Dai,Shuo Yang,Zhanwei Zhang,Qiwen Wang,Yang Qin,Changhua Meng*

Main category: cs.CL

TL;DR: 通过Atomic Thought和Atom-Searcher，改进了LLM在复杂任务中的推理和信息检索能力，解决了现有RL方法的局限性，并在多个测试中表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于RL的智能体研究方法在多步推理和战略搜索方面存在局限性，并且在梯度冲突和奖励稀疏性方面存在问题，限制了性能和训练效率。

Method: 提出了一种名为Atomic Thought的新型LLM思考范式，将推理分解为细粒度的功能单元，并由推理奖励模型（RRMs）提供原子思考奖励（ATR）进行监督。在此基础上，提出了Atom-Searcher，一个集成了Atomic Thought和ATR的RL框架，并采用课程学习驱动的奖励计划，优先考虑过程级ATR，然后转向结果奖励，以加速有效推理路径的收敛。

Result: 实验结果表明，Atom-Searcher在七个基准测试中持续优于最先进的方法，并且具有计算可扩展性、为RRMs提供监督锚点以及展现出更具可解释性、更像人类的推理模式等优点。

Conclusion: 该研究提出了Atomic Thought和Atom-Searcher，解决了当前基于RL的智能体研究方法在多步推理和知识检索方面的局限性，并在多个基准测试中取得了优于现有技术的性能提升。

Abstract: Large language models (LLMs) exhibit remarkable problem-solving abilities,
but struggle with complex tasks due to static internal knowledge.
Retrieval-Augmented Generation (RAG) enhances access to external information,
yet remains limited in multi-hop reasoning and strategic search due to rigid
workflows. Recent advancements in agentic deep research empower LLMs to
autonomously reason, search, and synthesize information. However, current
approaches relying on outcome-based reinforcement learning (RL) face critical
issues such as conflicting gradients and reward sparsity, limiting performance
gains and training efficiency. To address these, we first propose Atomic
Thought, a novel LLM thinking paradigm that decomposes reasoning into
fine-grained functional units. These units are supervised by Reasoning Reward
Models (RRMs), which provide Atomic Thought Rewards (ATR) for fine-grained
guidance. Building on this, we propose Atom-Searcher, a novel RL framework for
agentic deep research that integrates Atomic Thought and ATR. Atom-Searcher
uses a curriculum-inspired reward schedule, prioritizing process-level ATR
early and transitioning to outcome rewards, accelerating convergence on
effective reasoning paths. Experiments on seven benchmarks show consistent
improvements over the state-of-the-art. Key advantages include: (1)
Atom-Searcher scales computation at test-time. (2) Atomic Thought provides
supervision anchors for RRMs, bridging deep research tasks and RRMs. (3)
Atom-Searcher exhibits more interpretable, human-like reasoning patterns.

</details>


### [214] [When Alignment Hurts: Decoupling Representational Spaces in Multilingual Models](https://arxiv.org/abs/2508.12803)
*Ahmed Elshabrawy,Hour Kaing,Haiyue Song,Alham Fikri Aji,Hideki Tanaka,Masao Utiyama,Raj Dabre*

Main category: cs.CL

TL;DR: 高资源语言的表示缠结会阻碍低资源语言的生成模型，但可以通过子空间分离技术来改善。阿拉伯语方言的实验证明了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 挑战了高资源语言有助于低资源语言建模的假设，并提出方言机器翻译可作为多语种数据稀疏情况下的代理任务。

Method: 提出了一种在线变分探测框架，用于在微调过程中估计标准语言子空间，并通过投影实现分离。

Result: 在25种阿拉伯语方言的实验中，所提出的方法将生成质量提高了高达+4.9 chrF++（平均+2.0），尽管标准语言性能有所下降。

Conclusion: 高资源语言（如现代标准阿拉伯语）的表示缠结会阻碍相关低资源方言（如阿拉伯语方言）的生成模型。通过在线变分探测框架，可以估计并分离出标准语言子空间，从而提高方言的生成质量。

Abstract: Alignment with high-resource standard languages is often assumed to aid the
modeling of related low-resource varieties. We challenge this assumption by
demonstrating that excessive representational entanglement with a dominant
variety, such as Modern Standard Arabic (MSA) in relation to Arabic dialects,
can actively hinder generative modeling. We present the first comprehensive
causal study of this phenomenon by analyzing and directly intervening in the
internal representation geometry of large language models (LLMs). Our key
contribution is an online variational probing framework that continuously
estimates the subspace of the standard variety during fine-tuning, enabling
projection-based decoupling from this space. While our study uses Arabic as a
case due to its unusually rich parallel resources across 25 dialects, the
broader motivation is methodological: dialectal MT serves as a controlled proxy
for generative tasks where comparable multi-variety corpora are unavailable.
Across 25 dialects, our intervention improves generation quality by up to +4.9
chrF++ and +2.0 on average compared to standard fine-tuning, despite a measured
tradeoff in standard-language performance. These results provide causal
evidence that subspace dominance by high-resource varieties can restrict
generative capacity for related varieties. More generally, we unify geometric
and information-theoretic probing with subspace-level causal interventions,
offering practical tools for improving generative modeling in closely related
language families and, more broadly, for controlling representational
allocation in multilingual and multi-domain LLMs. Code will be released.

</details>


### [215] [ding-01 :ARG0: An AMR Corpus for Spontaneous French Dialogue](https://arxiv.org/abs/2508.12819)
*Jeongwoo Kang,Maria Boritchev,Maximin Coavoux*

Main category: cs.CL

TL;DR: 构建法语对话语义语料库，扩展AMR以处理自发语和法语特性，并训练解析器。


<details>
  <summary>Details</summary>
Motivation: AMR在表示自发语动态方面覆盖不足，需要扩展框架以更好地处理法语自发对话。

Method: 通过标注法语对话（Catan游戏语料）的抽象意义表示（AMR）来构建法语语义语料库，并扩展AMR框架以更好地表示自发语和法语特有句式。提供了详细的标注指南，并训练和评估了一个AMR解析器。

Result: 构建了一个法语语义语料库（DinG语料库），扩展了AMR框架，提供了标注指南，并训练了一个AMR解析器，该解析器可用作辅助标注工具。

Conclusion: 该工作为法语对话的语义资源开发做出了贡献。

Abstract: We present our work to build a French semantic corpus by annotating French
dialogue in Abstract Meaning Representation (AMR). Specifically, we annotate
the DinG corpus, consisting of transcripts of spontaneous French dialogues
recorded during the board game Catan. As AMR has insufficient coverage of the
dynamics of spontaneous speech, we extend the framework to better represent
spontaneous speech and sentence structures specific to French. Additionally, to
support consistent annotation, we provide an annotation guideline detailing
these extensions. We publish our corpus under a free license (CC-SA-BY). We
also train and evaluate an AMR parser on our data. This model can be used as an
assistance annotation tool to provide initial annotations that can be refined
by human annotators. Our work contributes to the development of semantic
resources for French dialogue.

</details>


### [216] [Context Matters: Incorporating Target Awareness in Conversational Abusive Language Detection](https://arxiv.org/abs/2508.12828)
*Raneem Alharthi,Rajwa Alharthi,Aiqi Jiang,Arkaitz Zubiaga*

Main category: cs.CL

TL;DR: Abusive language detection is better when considering the context of the conversation (parent tweet), especially the content, not just the reply itself. More features are better.


<details>
  <summary>Details</summary>
Motivation: Existing research on abusive language detection in social media primarily focuses on individual posts, neglecting the valuable context provided by surrounding conversational exchanges. This study aims to address this gap by exploring whether leveraging parent tweet context enhances the accuracy of detecting abusive reply tweets and identifying key contributing features.

Method: This study investigates the impact of conversational context (parent tweets) on abusive language detection in reply tweets. It compares models using only reply tweet features against those incorporating features from both reply and parent tweets. Four classification models were tested on a dataset of parent-reply tweet pairs labeled for abusiveness. Both content-based and account-based features were analyzed.

Result: Experiments demonstrate substantial improvements in abusive language detection when contextual features from parent tweets are included. Content-based features from the parent tweet were found to be more influential than account-based features. Combining multiple content-based features yielded better performance than using fewer, more selective ones.

Conclusion: Incorporating contextual features, particularly content-based ones from parent tweets, significantly improves abusive language detection in reply tweets compared to relying solely on the reply itself. A combination of content-based features is most effective.

Abstract: Abusive language detection has become an increasingly important task as a
means to tackle this type of harmful content in social media. There has been a
substantial body of research developing models for determining if a social
media post is abusive or not; however, this research has primarily focused on
exploiting social media posts individually, overlooking additional context that
can be derived from surrounding posts. In this study, we look at conversational
exchanges, where a user replies to an earlier post by another user (the parent
tweet). We ask: does leveraging context from the parent tweet help determine if
a reply post is abusive or not, and what are the features that contribute the
most? We study a range of content-based and account-based features derived from
the context, and compare this to the more widely studied approach of only
looking at the features from the reply tweet. For a more generalizable study,
we test four different classification models on a dataset made of
conversational exchanges (parent-reply tweet pairs) with replies labeled as
abusive or not. Our experiments show that incorporating contextual features
leads to substantial improvements compared to the use of features derived from
the reply tweet only, confirming the importance of leveraging context. We
observe that, among the features under study, it is especially the
content-based features (what is being posted) that contribute to the
classification performance rather than account-based features (who is posting
it). While using content-based features, it is best to combine a range of
different features to ensure improved performance over being more selective and
using fewer features. Our study provides insights into the development of
contextualized abusive language detection models in realistic settings
involving conversations.

</details>


### [217] [It takes a village to write a book: Mapping anonymous contributions in Stephen Langton's Quaestiones Theologiae](https://arxiv.org/abs/2508.12830)
*Jan Maliszewski*

Main category: cs.CL

TL;DR: This paper designs a study using stylometry to analyze scholastic texts (Stephen Langton's Quaestiones Theologiae) formed from oral teaching records (reportationes). It aims to identify editorial layers and test methods like HTR and stylometric analysis (word frequency, POS tags, pseudo-affixes). The study will compare manual vs. automatic data and validate OCR/transcription alignment for scholastic Latin, potentially creating a reusable template for analyzing medieval university literary production.


<details>
  <summary>Details</summary>
Motivation: While the indirect evidence suggests that already in the early scholastic period the literary production based on records of oral teaching (so-called reportationes) was not uncommon, there are very few sources commenting on the practice.

Method: This paper details the design of a study applying stylometric techniques of authorship attribution to a collection developed from reportationes -- Stephen Langton's Quaestiones Theologiae -- aiming to uncover layers of editorial work and thus validate some hypotheses regarding the collection's formation. Following Camps, Cléface, and Pinche (2021), I discuss the implementation of an HTR pipeline and stylometric analysis based on the most frequent words, POS tags, and pseudo-affixes.

Result: The proposed study will offer two methodological gains relevant to computational research on the scholastic tradition: it will directly compare performance on manually composed and automatically extracted data, and it will test the validity of transformer-based OCR and automated transcription alignment for workflows applied to scholastic Latin corpora.

Conclusion: If successful, this study will provide an easily reusable template for the exploratory analysis of collaborative literary production stemming from medieval universities.

Abstract: While the indirect evidence suggests that already in the early scholastic
period the literary production based on records of oral teaching (so-called
reportationes) was not uncommon, there are very few sources commenting on the
practice. This paper details the design of a study applying stylometric
techniques of authorship attribution to a collection developed from
reportationes -- Stephen Langton's Quaestiones Theologiae -- aiming to uncover
layers of editorial work and thus validate some hypotheses regarding the
collection's formation. Following Camps, Cl\'erice, and Pinche (2021), I
discuss the implementation of an HTR pipeline and stylometric analysis based on
the most frequent words, POS tags, and pseudo-affixes. The proposed study will
offer two methodological gains relevant to computational research on the
scholastic tradition: it will directly compare performance on manually composed
and automatically extracted data, and it will test the validity of
transformer-based OCR and automated transcription alignment for workflows
applied to scholastic Latin corpora. If successful, this study will provide an
easily reusable template for the exploratory analysis of collaborative literary
production stemming from medieval universities.

</details>


### [218] [Word Meanings in Transformer Language Models](https://arxiv.org/abs/2508.12863)
*Jumbly Grindrod,Peter Grindrod*

Main category: cs.CL

TL;DR: Transformer 模型在词嵌入中包含丰富的语义信息。


<details>
  <summary>Details</summary>
Motivation: 探究 Transformer 语言模型（特别是 RoBERTa-base）的词义表征方式，是否存在类似于词汇存储的结构，即每个词都有一个包含语义信息的条目。

Method: 通过 k-means 聚类将 RoBERTa-base 的词嵌入空间划分为 200 个簇，并分别手动检查和测试这些簇对五种心理语言学测量（效价、具体性、图像性、禁忌语和习得年龄）的敏感性。

Result: 研究结果表明，Transformer 模型在词嵌入空间中编码了广泛的语义信息，并且这些簇对心理语言学测量具有敏感性。

Conclusion: Transformer 模型在词嵌入空间中编码了广泛的语义信息，这反驳了某些“意义消除论”的假设。

Abstract: We investigate how word meanings are represented in the transformer language
models. Specifically, we focus on whether transformer models employ something
analogous to a lexical store - where each word has an entry that contains
semantic information. To do this, we extracted the token embedding space of
RoBERTa-base and k-means clustered it into 200 clusters. In our first study, we
then manually inspected the resultant clusters to consider whether they are
sensitive to semantic information. In our second study, we tested whether the
clusters are sensitive to five psycholinguistic measures: valence,
concreteness, iconicity, taboo, and age of acquisition. Overall, our findings
were very positive - there is a wide variety of semantic information encoded
within the token embedding space. This serves to rule out certain "meaning
eliminativist" hypotheses about how transformer LLMs process semantic
information.

</details>


### [219] [An LLM Agent-Based Complex Semantic Table Annotation Approach](https://arxiv.org/abs/2508.12868)
*Yilin Geng,Shujing Wang,Chuan Wang,Keqing He,Yanfei Lv,Ying Wang,Zaiwen Feng,Xiaoying Bai*

Main category: cs.CL

TL;DR: 本文提出了一种基于LLM的智能体方法，通过结合ReAct框架和五个外部工具，有效解决了语义表格标注（STA）中复杂表格带来的挑战，并在提高标注准确性的同时，显著降低了时间和成本。


<details>
  <summary>Details</summary>
Motivation: 现有的语义表格标注（STA）任务在处理复杂表格时面临语义损失、本体层级要求严格、同名异义、拼写错误和缩写等挑战，从而影响了标注准确性。因此，需要一种新的方法来解决这些问题。

Method: 本文提出了一种基于LLM的智能体方法，并结合ReAct框架设计了五个具有定制化提示词的外部工具，使智能体能够根据表格特征动态选择合适的标注策略来处理列类型标注（CTA）和单元格实体标注（CEA）。

Result: 该方法在Tough Tables和BiodivTab数据集上进行了实验，并取得了优于现有方法的性能，同时通过Levenshtein距离将时间成本和LLM token使用量分别降低了70%和60%。

Conclusion: 本文提出的基于LLM的智能体方法在Tough Tables和BiodivTab数据集上显著优于现有方法，并在 Levenshtein 距离的帮助下，将时间成本和LLM token 使用量分别减少了70%和60%，为语义表格标注提供了高效且经济的解决方案。

Abstract: The Semantic Table Annotation (STA) task, which includes Column Type
Annotation (CTA) and Cell Entity Annotation (CEA), maps table contents to
ontology entities and plays important roles in various semantic applications.
However, complex tables often pose challenges such as semantic loss of column
names or cell values, strict ontological hierarchy requirements, homonyms,
spelling errors, and abbreviations, which hinder annotation accuracy. To
address these issues, this paper proposes an LLM-based agent approach for CTA
and CEA. We design and implement five external tools with tailored prompts
based on the ReAct framework, enabling the STA agent to dynamically select
suitable annotation strategies depending on table characteristics. Experiments
are conducted on the Tough Tables and BiodivTab datasets from the SemTab
challenge, which contain the aforementioned challenges. Our method outperforms
existing approaches across various metrics. Furthermore, by leveraging
Levenshtein distance to reduce redundant annotations, we achieve a 70%
reduction in time costs and a 60% reduction in LLM token usage, providing an
efficient and cost-effective solution for STA.

</details>


### [220] [A Stitch in Time Saves Nine: Proactive Self-Refinement for Language Models](https://arxiv.org/abs/2508.12903)
*Jinyi Han,Xinyi Wang,Haiquan Zhao,Tingyun li,Zishang Jiang,Sihang Jiang,Jiaqing Liang,Xin Lin,Weikang Zhou,Zeye Sun,Fei Yu,Yanghua Xiao*

Main category: cs.CL

TL;DR: ProActive Self-Refinement (PASR) allows LLMs to refine their outputs during generation based on internal state and context, improving performance and reducing resource usage.


<details>
  <summary>Details</summary>
Motivation: Inspired by human dynamic thought refinement during execution, to address the limitations of existing reactive self-refinement methods which have a fixed number of iterations and struggle to optimize refinement timing and content.

Method: PASR enables LLMs to refine outputs proactively based on internal state and evolving context, deciding whether, when, and how to refine, unlike reactive methods with fixed iterations.

Result: PASR significantly enhances problem-solving performance across 10 diverse tasks. On Qwen3-8B, it reduces average token consumption by 41.6% and improves accuracy by 8.2% compared to standard generation.

Conclusion: PASR can proactively refine outputs during the generation process, reducing token consumption and improving accuracy.

Abstract: Recent advances in self-refinement have demonstrated significant potential
for improving the outputs of large language models (LLMs) through iterative
refinement. However, most existing self-refinement methods rely on a reactive
process with a fixed number of iterations, making it difficult to determine the
optimal timing and content of refinement based on the evolving generation
context. Inspired by the way humans dynamically refine their thoughts during
execution, we propose ProActive Self-Refinement (PASR), a novel method that
enables LLMs to refine their outputs during the generation process. Unlike
methods that regenerate entire responses, PASR proactively decides whether,
when, and how to refine based on the model's internal state and evolving
context. We conduct extensive experiments on a diverse set of 10 tasks to
evaluate the effectiveness of PASR. Experimental results show that PASR
significantly enhances problem-solving performance. In particular, on Qwen3-8B,
PASR reduces average token consumption by 41.6 percent compared to standard
generation, while also achieving an 8.2 percent improvement in accuracy. Our
code and all baselines used in the paper are available in the GitHub.

</details>


### [221] [Analyzing Information Sharing and Coordination in Multi-Agent Planning](https://arxiv.org/abs/2508.12981)
*Tianyue Ou,Saujas Vaduguru,Daniel Fried*

Main category: cs.CL

TL;DR: 通过笔记本和协调器改进LLM多智能体系统在长时程规划任务中的表现，尤其是在旅行规划方面。


<details>
  <summary>Details</summary>
Motivation: 长时程、多约束规划任务，如旅行规划，对LLM代理提出了挑战，需要处理详细信息和复杂约束。

Method: 本研究构建了一个基于LLM的多智能体系统，并评估了笔记本（用于信息共享）和协调器（用于代理间的对话协调）的影响。

Result: 笔记本将幻觉细节导致的错误减少了18%；协调器将特定子区域的错误减少了13.5%。结合两者后，在TravelPlanner基准测试上的最终通过率为25%，比单一代理基线（7.5%）提高了17.5%。

Conclusion: 多智能体系统（MASs）通过结构化信息共享和反思性协调，在长时程规划中展现出巨大潜力。

Abstract: Multi-agent systems (MASs) have pushed the boundaries of large language model
(LLM) agents in domains such as web research and software engineering. However,
long-horizon, multi-constraint planning tasks involve conditioning on detailed
information and satisfying complex interdependent constraints, which can pose a
challenge for these systems. In this study, we construct an LLM-based MAS for a
travel planning task which is representative of these challenges. We evaluate
the impact of a notebook to facilitate information sharing, and evaluate an
orchestrator agent to improve coordination in free form conversation between
agents. We find that the notebook reduces errors due to hallucinated details by
18%, while an orchestrator directs the MAS to focus on and further reduce
errors by up to 13.5% within focused sub-areas. Combining both mechanisms
achieves a 25% final pass rate on the TravelPlanner benchmark, a 17.5% absolute
improvement over the single-agent baseline's 7.5% pass rate. These results
highlight the potential of structured information sharing and reflective
orchestration as key components in MASs for long horizon planning with LLMs.

</details>


### [222] [WebMall -- A Multi-Shop Benchmark for Evaluating Web Agents](https://arxiv.org/abs/2508.13024)
*Ralph Peeters,Aaron Steiner,Luca Schwarz,Julian Yuya Caspary,Christian Bizer*

Main category: cs.CL

TL;DR: WebMall是一个新的多商店在线购物基准测试，包含91个任务，用于评估LLM驱动的网络代理在比价购物方面的能力。它比现有基准测试更具挑战性，并且已发布以促进研究。


<details>
  <summary>Details</summary>
Motivation: LLM驱动的网络代理有潜力自动化跨多个在线商店搜索和购买产品的长期网络任务，但缺乏专门用于评估此类能力的基准测试。

Method: 提出了一种名为WebMall的多商店在线购物基准测试，该基准测试包含四个模拟在线商店、真实的产品报价以及91个跨商店任务，用于评估网页代理的有效性和效率。

Result: 在WebMall基准测试中，评估的八个基线代理在基本任务和高级任务上的完成率分别为75%和53%，F1分数分别为87%和63%。

Conclusion: WebMall基准测试的发布将促进网页代理在电子商务场景中的研究，特别是在导航、推理和效率方面。

Abstract: LLM-based web agents have the potential to automate long-running web tasks,
such as finding offers for specific products in multiple online shops and
subsequently ordering the cheapest products that meet the users needs. This
paper introduces WebMall, a multi-shop online shopping benchmark for evaluating
the effectiveness and efficiency of web agents for comparison-shopping. WebMall
consists of four simulated online shops populated with authentic product offers
sourced from the Common Crawl, alongside a suite of 91 cross-shop tasks. These
tasks include basic tasks such as finding specific products in multiple shops,
performing price comparisons, adding items to the shopping cart, and completing
checkout. Advanced tasks involve searching for products based on vague
requirements, identifying suitable substitutes, and finding compatible
products. Compared to existing e-commerce benchmarks, such as WebShop or
ShoppingBench, WebMall introduces comparison-shopping tasks across multiple
shops. Furthermore, the product offers are more heterogeneous, as they
originate from hundreds of distinct real-world shops. The tasks in WebMall
require longer interaction trajectories than those in WebShop, while remaining
representative of real-world shopping behaviors. We evaluate eight baseline
agents on WebMall, varying in observation modality, memory utilization, and
underlying large language model (GPT 4.1 and Claude Sonnet 4). The
best-performing configurations achieve completion rates of 75% and 53%, and F1
scores of 87% and 63%, on the basic and advanced task sets, respectively.
WebMall is publicly released to facilitate research on web agents and to
promote advancements in navigation, reasoning, and efficiency within e-commerce
scenarios.

</details>


### [223] [Integrating Feedback Loss from Bi-modal Sarcasm Detector for Sarcastic Speech Synthesis](https://arxiv.org/abs/2508.13028)
*Zhu Li,Yuqing Zhang,Xiyuan Gao,Devraj Raghuvanshi,Nagendra Kumar,Shekhar Nayak,Matt Coler*

Main category: cs.CL

TL;DR: A new approach uses feedback loss from a sarcasm detection model and two-stage fine-tuning to improve sarcastic speech synthesis, making it more natural and understandable.


<details>
  <summary>Details</summary>
Motivation: Sarcastic speech synthesis is essential for enhancing natural interactions in applications like entertainment and human-computer interaction. However, synthesizing sarcastic speech is challenging due to nuanced prosody and limited annotated sarcastic speech data.

Method: This study introduces a novel approach that integrates feedback loss from a bi-modal sarcasm detection model into the TTS training process. A speech synthesis model pre-trained on read speech undergoes a two-stage fine-tuning process: first on a diverse dataset including sarcastic speech, and then on a dataset focused on sarcastic speech.

Result: The proposed methods enhance the model's ability to capture and convey sarcasm, improving the quality, naturalness, and sarcasm-awareness of synthesized speech.

Conclusion: Objective and subjective evaluations demonstrate that the proposed methods improve the quality, naturalness, and sarcasm-awareness of synthesized speech.

Abstract: Sarcastic speech synthesis, which involves generating speech that effectively
conveys sarcasm, is essential for enhancing natural interactions in
applications such as entertainment and human-computer interaction. However,
synthesizing sarcastic speech remains a challenge due to the nuanced prosody
that characterizes sarcasm, as well as the limited availability of annotated
sarcastic speech data. To address these challenges, this study introduces a
novel approach that integrates feedback loss from a bi-modal sarcasm detection
model into the TTS training process, enhancing the model's ability to capture
and convey sarcasm. In addition, by leveraging transfer learning, a speech
synthesis model pre-trained on read speech undergoes a two-stage fine-tuning
process. First, it is fine-tuned on a diverse dataset encompassing various
speech styles, including sarcastic speech. In the second stage, the model is
further refined using a dataset focused specifically on sarcastic speech,
enhancing its ability to generate sarcasm-aware speech. Objective and
subjective evaluations demonstrate that our proposed methods improve the
quality, naturalness, and sarcasm-awareness of synthesized speech.

</details>


### [224] [Can Large Models Teach Student Models to Solve Mathematical Problems Like Human Beings? A Reasoning Distillation Method via Multi-LoRA Interaction](https://arxiv.org/abs/2508.13037)
*Xinhe Li,Jiajun Liu,Peng Wang*

Main category: cs.CL

TL;DR: 提出LoRID方法，模仿人类“系统1”和“系统2”思考模式，通过多LoRA交互提升小语言模型（SLM）的数学推理能力，实验结果在GSM8K数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 为了解决小语言模型（SLM）在数学推理方面存在的不足，同时借鉴人类学习中“系统1”（快速、基于经验）和“系统2”（先学习知识、后练习强化）两种思考模式，提出一种新的方法来提升SLM的数学推理能力。

Method: 提出了一种名为LoRID（多LoRA交互的数学推理蒸馏）的新方法，该方法模仿人类“系统1”和“系统2”思考模式。首先，利用LLM生成知识增强型数据集。然后，分别训练“直觉推理器”（IR）和“知识生成器”（KG）及“深度推理器”（DR）。IR直接生成解决问题的思维链（Chain-of-Thoughts），KG仅输出知识，DR则利用该知识进行推理。最后，通过评估IR和DR输出的一致性并进行迭代反馈，来增强SLM的数学推理能力。

Result: 实验结果表明，LoRID在GSM8K等数据集上取得了最先进的性能，相比第二名，在五个基础模型上的准确率分别提高了2.3%、16.1%、2.4%、12.3%和1.8%。

Conclusion: LoRID通过多LoRA交互实现了小语言模型（SLM）的数学推理能力蒸馏，在GSM8K等数据集上取得了最先进的性能，特别是在五个基础模型上准确率分别超越第二名2.3%、16.1%、2.4%、12.3%和1.8%。

Abstract: Recent studies have demonstrated that Large Language Models (LLMs) have
strong mathematical reasoning abilities but rely on hundreds of billions of
parameters. To tackle the challenge of poor reasoning in Small Language Models
(SLMs), existing methods typically leverage LLMs to generate massive amounts of
data for cramming training. In psychology, they are akin to System 1 thinking,
which resolves reasoning problems rapidly based on experience and intuition.
However, human learning also requires System 2 thinking, where knowledge is
first acquired and then reinforced through practice. Inspired by such two
distinct modes of thinking, we propose a novel method based on the multi-LoRA
Interaction for mathematical reasoning Distillation (LoRID). First, we input
the question and reasoning of each sample into an LLM to create
knowledge-enhanced datasets. Subsequently, we train a LoRA block on the student
model as an Intuitive Reasoner (IR), which directly generates Chain-of-Thoughts
for problem-solving. Then, to imitate System 2 thinking, we train the Knowledge
Generator (KG) and Deep Reasoner (DR), respectively. The former outputs only
knowledge after receiving problems, while the latter uses that knowledge to
perform reasoning. Finally, to address the randomness in the generation of IR
and DR, we evaluate whether their outputs are consistent, and the inference
process needs to be iterated if not. This step can enhance the mathematical
reasoning ability of SLMs through mutual feedback. Experimental results show
that LoRID achieves state-of-the-art performance, especially on the GSM8K
dataset, where it outperforms the second-best method by 2.3%, 16.1%, 2.4%,
12.3%, and 1.8% accuracy across the five base models, respectively.

</details>


### [225] [Büyük Dil Modelleri için TR-MMLU Benchmarkı: Performans Değerlendirmesi, Zorluklar ve İyileştirme Fırsatları](https://arxiv.org/abs/2508.13044)
*M. Ali Bayram,Ali Arda Fincan,Ahmet Semih Gümüş,Banu Diri,Savaş Yıldırım,Öner Aytaş*

Main category: cs.CL

TL;DR: TR-MMLU 是一个针对土耳其语的语言模型评估基准，旨在解决资源有限语言的评估挑战。


<details>
  <summary>Details</summary>
Motivation: 评估语言模型在土耳其语等资源有限的语言中的能力是一个挑战。

Method: TR-MMLU 是一个基于 6,200 个选择题的综合评估框架，涵盖了土耳其教育系统的 62 个部分。

Result: 该研究在 TR-MMLU 上评估了最先进的语言模型，并指出了模型设计方面需要改进的领域。

Conclusion: TR-MMLU 为土耳其自然语言处理研究设定了新标准，有望激发未来的创新。

Abstract: Language models have made significant advancements in understanding and
generating human language, achieving remarkable success in various
applications. However, evaluating these models remains a challenge,
particularly for resource-limited languages like Turkish. To address this
issue, we introduce the Turkish MMLU (TR-MMLU) benchmark, a comprehensive
evaluation framework designed to assess the linguistic and conceptual
capabilities of large language models (LLMs) in Turkish. TR-MMLU is based on a
meticulously curated dataset comprising 6,200 multiple-choice questions across
62 sections within the Turkish education system. This benchmark provides a
standard framework for Turkish NLP research, enabling detailed analyses of
LLMs' capabilities in processing Turkish text. In this study, we evaluated
state-of-the-art LLMs on TR-MMLU, highlighting areas for improvement in model
design. TR-MMLU sets a new standard for advancing Turkish NLP research and
inspiring future innovations.

</details>


### [226] [Doğal Dil İşlemede Tokenizasyon Standartları ve Ölçümü: Türkçe Üzerinden Büyük Dil Modellerinin Karşılaştırmalı Analizi](https://arxiv.org/abs/2508.13058)
*M. Ali Bayram,Ali Arda Fincan,Ahmet Semih Gümüş,Sercan Karakaş,Banu Diri,Savaş Yıldırım*

Main category: cs.CL

TL;DR: 这项研究提出了一个针对土耳其语等语言的分词评估框架，发现特定语言标记百分比比标记纯度更能预测模型性能，并且仅增加模型参数不足以提升语言性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决自然语言处理（NLP）中，特别是在土耳其语等形态丰富、资源匮乏的语言中，分词（tokenization）面临的挑战，以提升大型语言模型（LLMs）捕捉语言和语义细微差别的影响。

Method: 研究采用了一个新的评估框架，并使用土耳其MMLU（TR-MMLU）数据集对分词器进行了评估，评估指标包括词汇量、标记数、处理时间、特定语言标记百分比（%TR）和标记纯度（%Pure）。

Result: 结果表明，特定语言标记百分比与下游性能（如MMLU分数）的相关性比标记纯度更强。此外，仅增加模型参数并不一定能提升语言性能。

Conclusion: 该研究提出的评估框架为形态丰富的语言建立了稳健实用的分词标准。

Abstract: Tokenization is a fundamental preprocessing step in Natural Language
Processing (NLP), significantly impacting the capability of large language
models (LLMs) to capture linguistic and semantic nuances. This study introduces
a novel evaluation framework addressing tokenization challenges specific to
morphologically-rich and low-resource languages such as Turkish. Utilizing the
Turkish MMLU (TR-MMLU) dataset, comprising 6,200 multiple-choice questions from
the Turkish education system, we assessed tokenizers based on vocabulary size,
token count, processing time, language-specific token percentages (\%TR), and
token purity (\%Pure). These newly proposed metrics measure how effectively
tokenizers preserve linguistic structures. Our analysis reveals that
language-specific token percentages exhibit a stronger correlation with
downstream performance (e.g., MMLU scores) than token purity. Furthermore,
increasing model parameters alone does not necessarily enhance linguistic
performance, underscoring the importance of tailored, language-specific
tokenization methods. The proposed framework establishes robust and practical
tokenization standards for morphologically complex languages.

</details>


### [227] [Evaluating ASR robustness to spontaneous speech errors: A study of WhisperX using a Speech Error Database](https://arxiv.org/abs/2508.13060)
*John Alderete,Macarious Kin Fung Hui,Aanchan Mohan*

Main category: cs.CL

TL;DR: SFUSED数据库是一个用于语言和心理语言学研究的公共数据集，可用于评估语音识别模型。


<details>
  <summary>Details</summary>
Motivation: 演示SFUSED数据库的设计和注释如何用于测试和评估语音识别模型。

Method: 使用SFUSED数据库中的5,300个单词和语音错误，评估了WhisperX的转录准确性。

Result: SFUSED数据库包含来自自发英语语音的系统注释语音错误，每个错误都标有预期的实际错误产生。注释模式包含对模型评估有价值的多个分类维度，包括语言层级、上下文敏感性、退化词、单词更正以及单词级和音节级错误定位。

Conclusion: 该数据库可作为诊断ASR系统性能的有效工具。

Abstract: The Simon Fraser University Speech Error Database (SFUSED) is a public data
collection developed for linguistic and psycholinguistic research. Here we
demonstrate how its design and annotations can be used to test and evaluate
speech recognition models. The database comprises systematically annotated
speech errors from spontaneous English speech, with each error tagged for
intended and actual error productions. The annotation schema incorporates
multiple classificatory dimensions that are of some value to model assessment,
including linguistic hierarchical level, contextual sensitivity, degraded
words, word corrections, and both word-level and syllable-level error
positioning. To assess the value of these classificatory variables, we
evaluated the transcription accuracy of WhisperX across 5,300 documented word
and phonological errors. This analysis demonstrates the atabase's effectiveness
as a diagnostic tool for ASR system performance.

</details>


### [228] [Reinforced Context Order Recovery for Adaptive Reasoning and Planning](https://arxiv.org/abs/2508.13070)
*Long Ma,Fangwei Zhong,Yizhou Wang*

Main category: cs.CL

TL;DR: ReCOR是一种新的强化学习框架，可以从文本数据中学习自适应的标记生成顺序，解决了现有模型在处理需要非固定顺序的任务时的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前因果模型和扩散模型主要以固定的（从左到右）或随机的顺序输出标记，这可能偏离标记最初生成的逻辑顺序。这导致这些模型在需要自适应标记生成顺序才能有效解决的问题上遇到困难。

Method: 提出了一种基于强化学习的框架——ReCOR，用于从文本数据中提取自适应的、依赖于数据的标记生成顺序，而无需进行标注。ReCOR通过标记预测统计进行自监督，以估计每个未填充标记的预测难度，并在训练和推理过程中自适应地选择下一个标记。

Result: ReCOR在具有挑战性的推理和规划数据集上的实验证明了其优越性能。

Conclusion: ReCOR在具有挑战性的推理和规划数据集上表现优于基线模型，有时甚至优于使用真实标签顺序的Oracle模型。

Abstract: Modern causal language models, followed by rapid developments in discrete
diffusion models, can now produce a wide variety of interesting and useful
content. However, these families of models are predominantly trained to output
tokens with a fixed (left-to-right) or random order, which may deviate from the
logical order in which tokens are generated originally. In this paper, we
observe that current causal and diffusion models encounter difficulties in
problems that require adaptive token generation orders to solve tractably,
which we characterize with the $\mathcal{V}$-information framework. Motivated
by this, we propose Reinforced Context Order Recovery (ReCOR), a
reinforcement-learning-based framework to extract adaptive, data-dependent
token generation orders from text data without annotations. Self-supervised by
token prediction statistics, ReCOR estimates the hardness of predicting every
unfilled token and adaptively selects the next token during both training and
inference. Experiments on challenging reasoning and planning datasets
demonstrate the superior performance of ReCOR compared with baselines,
sometimes outperforming oracle models supervised with the ground-truth order.

</details>


### [229] [DocHPLT: A Massively Multilingual Document-Level Translation Dataset](https://arxiv.org/abs/2508.13079)
*Dayyán O'Brien,Bhavitvya Malik,Ona de Gibert,Pinzhen Chen,Barry Haddow,Jörg Tiedemann*

Main category: cs.CL

TL;DR: 创建了一个名为DocHPLT的超大型多语言文档级翻译数据集（包含50种语言），并证明了在其中微调LLM可以显著提高翻译性能，特别是在低资源语言上。


<details>
  <summary>Details</summary>
Motivation: 为了促进文档级翻译和长上下文建模的训练和评估，并服务于全球社区，创建DocHPLT数据集。现有资源主要集中在高资源语言上，并且样本量有限。

Method: DocHPLT数据集是通过修改现有的网络提取管道来创建的，以从源头保留完整的文档结构，而不是像以前的基于重建的方法那样仅从句子级数据拼接文档。这保留了所有内容，包括未对齐的部分。

Result: DocHPLT包含50种语言与英语配对的1.24亿个对齐文档对，共计42.6亿个句子。实验表明，在DocHPLT上微调的LLM在文档级翻译任务上显著优于现有的指令微调基线模型，对于资源匮乏的语言，性能提升尤为明显。

Conclusion: DocHPLT是迄今为止最大、最全面的多语言文档级翻译数据集，它将促进全球社区的文档级翻译和长上下文建模。LLM在DocHPLT上进行微调后，表现出比现成的指令微调基线模型更优越的性能，尤其是在欠密集语言方面。

Abstract: Existing document-level machine translation resources are only available for
a handful of languages, mostly high-resourced ones. To facilitate the training
and evaluation of document-level translation and, more broadly, long-context
modeling for global communities, we create DocHPLT, the largest publicly
available document-level translation dataset to date. It contains 124 million
aligned document pairs across 50 languages paired with English, comprising 4.26
billion sentences, with further possibility to provide 2500 bonus pairs not
involving English. Unlike previous reconstruction-based approaches that piece
together documents from sentence-level data, we modify an existing web
extraction pipeline to preserve complete document integrity from the source,
retaining all content including unaligned portions. After our preliminary
experiments identify the optimal training context strategy for document-level
translation, we demonstrate that LLMs fine-tuned on DocHPLT substantially
outperform off-the-shelf instruction-tuned baselines, with particularly
dramatic improvements for under-resourced languages. We open-source the dataset
under a permissive license, providing essential infrastructure for advancing
multilingual document-level translation.

</details>


### [230] [All for law and law for all: Adaptive RAG Pipeline for Legal Research](https://arxiv.org/abs/2508.13107)
*Figarri Keisha,Prince Singh,Pallavi,Dion Fernandes,Aravindh Manivannan,Ilham Wicaksono,Faisal Ahmad*

Main category: cs.CL

TL;DR: This paper enhances Retrieval-Augmented Generation (RAG) for legal research with a context-aware query translator, cost-efficient open-source retrieval (SBERT, GTE embeddings) boosting performance by 30-95%, and a robust evaluation framework. Results show open-source methods rival proprietary ones, and a custom legal prompt improves answer faithfulness and relevance, enabling reproducible and affordable legal RAG systems.


<details>
  <summary>Details</summary>
Motivation: The motivation is to improve the reliability and accuracy of large language models in the legal domain by reducing hallucinations through Retrieval-Augmented Generation (RAG), making RAG systems more cost-effective and legally grounded.

Method: The paper proposes an end-to-end RAG pipeline with three main enhancements: a context-aware query translator for disentangling document references and adapting retrieval, open-source retrieval methods using SBERT and GTE embeddings showing significant performance improvements (30-95% increase in Recall@K and ~2.5x increase in Precision@K for K>4), and a comprehensive evaluation framework utilizing RAGAS, BERTScore-F1, and ROUGE-Recall to measure semantic alignment and faithfulness.

Result: The proposed open-source RAG pipeline achieves substantial performance gains in retrieval quality, outperforming baseline retrieval by 30-95% in Recall@K and approximately 2.5x in Precision@K for K>4. The legal-grounded prompt consistently yields more faithful and contextually relevant answers than the baseline prompt.

Conclusion: The study demonstrates that tailored open-source RAG pipelines can match or exceed proprietary solutions in retrieval accuracy. A specialized legal-grounded prompt generates more faithful and contextually appropriate responses compared to standard prompting.

Abstract: Retrieval-Augmented Generation (RAG) mitigates hallucinations by grounding
large language model outputs in cited sources, a capability that is especially
critical in the legal domain. We present an end-to-end RAG pipeline that
revisits and extends the LegalBenchRAG baseline with three targeted
enhancements: (i) a context-aware query translator that disentangles document
references from natural-language questions and adapts retrieval depth and
response style based on expertise and specificity, (ii) open-source retrieval
strategies using SBERT and GTE embeddings that achieve substantial performance
gains (improving Recall@K by 30-95\% and Precision@K by $\sim$2.5$\times$ for
$K>4$) while remaining cost-efficient, and (iii) a comprehensive evaluation and
generation framework that combines RAGAS, BERTScore-F1, and ROUGE-Recall to
assess semantic alignment and faithfulness across models and prompt designs.
Our results show that carefully designed open-source pipelines can rival or
outperform proprietary approaches in retrieval quality, while a custom
legal-grounded prompt consistently produces more faithful and contextually
relevant answers than baseline prompting. Taken together, these contributions
demonstrate the potential of task-aware, component-level tuning to deliver
legally grounded, reproducible, and cost-effective RAG systems for legal
research assistance.

</details>


### [231] [AutoBnB-RAG: Enhancing Multi-Agent Incident Response with Retrieval-Augmented Generation](https://arxiv.org/abs/2508.13118)
*Zefang Liu,Arman Anwar*

Main category: cs.CL

TL;DR: AutoBnB-RAG通过集成检索增强生成（RAG）到多智能体事件响应模拟中，解决了大型语言模型（LLMs）在网络安全决策中缺乏外部知识的问题。该方法在模拟中提高了决策质量和成功率，并能重建真实世界的网络攻击。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在模拟事件响应（IR）中作为自主代理显示出潜力，但其推理能力常因缺乏外部知识而受限。

Method: 提出了AutoBnB-RAG，一个在多智能体事件响应模拟中结合检索增强生成（RAG）的AutoBnB框架的扩展。该框架在Backdoors & Breaches（B&B）桌面游戏环境中运行，允许智能体在协作调查中发出检索查询并整合外部证据。评估了两种检索设置（RAG-Wiki和RAG-News）以及八种团队结构（包括新的论证配置）。

Result: 检索增强提高了跨不同组织模型的决策质量和成功率。AutoBnB-RAG能够重建复杂的、多阶段的真实网络攻击。

Conclusion: 整合检索机制到基于LLM的多智能体系统对于网络安全决策具有重要价值。

Abstract: Incident response (IR) requires fast, coordinated, and well-informed
decision-making to contain and mitigate cyber threats. While large language
models (LLMs) have shown promise as autonomous agents in simulated IR settings,
their reasoning is often limited by a lack of access to external knowledge. In
this work, we present AutoBnB-RAG, an extension of the AutoBnB framework that
incorporates retrieval-augmented generation (RAG) into multi-agent incident
response simulations. Built on the Backdoors & Breaches (B&B) tabletop game
environment, AutoBnB-RAG enables agents to issue retrieval queries and
incorporate external evidence during collaborative investigations. We introduce
two retrieval settings: one grounded in curated technical documentation
(RAG-Wiki), and another using narrative-style incident reports (RAG-News). We
evaluate performance across eight team structures, including newly introduced
argumentative configurations designed to promote critical reasoning. To
validate practical utility, we also simulate real-world cyber incidents based
on public breach reports, demonstrating AutoBnB-RAG's ability to reconstruct
complex multi-stage attacks. Our results show that retrieval augmentation
improves decision quality and success rates across diverse organizational
models. This work demonstrates the value of integrating retrieval mechanisms
into LLM-based multi-agent systems for cybersecurity decision-making.

</details>


### [232] [Spot the BlindSpots: Systematic Identification and Quantification of Fine-Grained LLM Biases in Contact Center Summaries](https://arxiv.org/abs/2508.13124)
*Kawin Mayilvaghanan,Siddhant Gupta,Ayush Kumar*

Main category: cs.CL

TL;DR: 本研究提出了BlindSpot框架，用于检测联络中心摘要中的操作偏见。研究发现，所有LLM在生成摘要时都存在系统性偏见，无论模型大小或家族如何。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在生成摘要方面表现出色，但尚不清楚它们是否会系统性地过度或不足地关注特定方面，从而可能在摘要中引入偏见。特别是，在联络中心操作中特有的偏见形式（即操作偏见）尚未得到探索。

Method: 提出了一种名为BlindSpot的框架，该框架基于15个操作偏见维度（如语言不流畅、说话人、主题等）的分类法，用于识别和量化这些偏见。BlindSpot利用LLM作为零样本分类器，为每个偏见维度在原始文本和摘要的配对中推导出分类分布。偏见通过两个指标进行量化：保真度差距（Fidelity Gap，即分布的JS散度）和覆盖率（Coverage，即被省略的源标签的百分比）。

Result: 通过对2500个真实的电话联络记录及其摘要进行实证研究（涉及20个不同规模和家族的LLM），研究发现偏见是系统性的，并且存在于所有被评估的模型中，与模型的规模或家族无关。

Conclusion: 本研究揭示了在联络中心场景下，大型语言模型（LLM）在生成摘要时存在系统性的操作偏见（Operational Bias），这种偏见普遍存在于所有被评估的模型中，且与模型的规模或家族无关。

Abstract: Abstractive summarization is a core application in contact centers, where
Large Language Models (LLMs) generate millions of summaries of call transcripts
daily. Despite their apparent quality, it remains unclear whether LLMs
systematically under- or over-attend to specific aspects of the transcript,
potentially introducing biases in the generated summary. While prior work has
examined social and positional biases, the specific forms of bias pertinent to
contact center operations - which we term Operational Bias - have remained
unexplored. To address this gap, we introduce BlindSpot, a framework built upon
a taxonomy of 15 operational bias dimensions (e.g., disfluency, speaker, topic)
for the identification and quantification of these biases. BlindSpot leverages
an LLM as a zero-shot classifier to derive categorical distributions for each
bias dimension in a pair of transcript and its summary. The bias is then
quantified using two metrics: Fidelity Gap (the JS Divergence between
distributions) and Coverage (the percentage of source labels omitted). Using
BlindSpot, we conducted an empirical study with 2500 real call transcripts and
their summaries generated by 20 LLMs of varying scales and families (e.g., GPT,
Llama, Claude). Our analysis reveals that biases are systemic and present
across all evaluated models, regardless of size or family.

</details>


### [233] [MuDRiC: Multi-Dialect Reasoning for Arabic Commonsense Validation](https://arxiv.org/abs/2508.13130)
*Kareem Elozeiri,Mervat Abassy,Preslav Nakov,Yuxia Wang*

Main category: cs.CL

TL;DR: 发布了首个阿拉伯语多方言常识数据集 MuDRiC，并提出了改进的 GCN 方法，在阿拉伯语常识验证任务上表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有阿拉伯语常识资源主要集中在现代标准阿拉伯语（MSA），忽视了口语中广泛使用的地区方言，存在研究不足的问题。

Method: 提出了一种新颖的图卷积网络（GCN）方法，用于阿拉伯语常识推理，以增强语义关系建模，从而改进常识验证。

Result: 实验结果表明，所提出的 GCN 方法在阿拉伯语常识验证方面取得了优越的性能。

Conclusion: 该研究发布了首个阿拉伯语多方言常识推理数据集，并提出了一种改进的 GCN 方法，在阿拉伯语常识验证任务上取得了优越的性能，为阿拉伯语自然语言理解带来了重要贡献。

Abstract: Commonsense validation evaluates whether a sentence aligns with everyday
human understanding, a critical capability for developing robust natural
language understanding systems. While substantial progress has been made in
English, the task remains underexplored in Arabic, particularly given its rich
linguistic diversity. Existing Arabic resources have primarily focused on
Modern Standard Arabic (MSA), leaving regional dialects underrepresented
despite their prevalence in spoken contexts. To bridge this gap, we present two
key contributions: (i) we introduce MuDRiC, an extended Arabic commonsense
dataset incorporating multiple dialects, and (ii) a novel method adapting Graph
Convolutional Networks (GCNs) to Arabic commonsense reasoning, which enhances
semantic relationship modeling for improved commonsense validation. Our
experimental results demonstrate that this approach achieves superior
performance in Arabic commonsense validation. Our work enhances Arabic natural
language understanding by providing both a foundational dataset and a novel
method for handling its complex variations. To the best of our knowledge, we
release the first Arabic multi-dialect commonsense reasoning dataset.

</details>


### [234] [Improving Detection of Watermarked Language Models](https://arxiv.org/abs/2508.13131)
*Dara Bahri,John Wieting*

Main category: cs.CL

TL;DR: Hybrid detectors combining watermark and non-watermark methods improve LLM generation detection, especially when watermark entropy is limited.


<details>
  <summary>Details</summary>
Motivation: Watermarking LLM generations is effective but limited by low entropy in post-trained models, making detection challenging.

Method: Investigate hybrid schemes combining watermark and non-watermark detectors.

Result: Hybrid schemes show performance gains over either class of detector under various experimental conditions.

Conclusion: Combining watermark detectors with non-watermark ones improves detection performance.

Abstract: Watermarking has recently emerged as an effective strategy for detecting the
generations of large language models (LLMs). The strength of a watermark
typically depends strongly on the entropy afforded by the language model and
the set of input prompts. However, entropy can be quite limited in practice,
especially for models that are post-trained, for example via instruction tuning
or reinforcement learning from human feedback (RLHF), which makes detection
based on watermarking alone challenging. In this work, we investigate whether
detection can be improved by combining watermark detectors with non-watermark
ones. We explore a number of hybrid schemes that combine the two, observing
performance gains over either class of detector under a wide range of
experimental conditions.

</details>


### [235] [OptimalThinkingBench: Evaluating Over and Underthinking in LLMs](https://arxiv.org/abs/2508.13141)
*Pranjal Aggarwal,Seungone Kim,Jack Lanchantin,Sean Welleck,Jason Weston,Ilia Kulikov,Swarnadeep Saha*

Main category: cs.CL

TL;DR: 该研究提出了OptimalThinkingBench基准测试，用于评估大型语言模型的“过度思考”和“思考不足”问题。结果发现，现有模型均无法实现最优思考，思考型模型易过度思考，非思考型模型易思考不足。研究强调了开发能够平衡性能与效率的“最优思考”模型的重要性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在处理复杂任务时需要更高的计算资源，但在简单问题上容易过度思考；而非思考型LLMs虽然速度快、成本低，但在复杂的推理问题上则思考不足。为了解决这个问题，研究旨在创建一个统一的基准测试，以评估和促进能够平衡性能和效率的“最优思考”模型的开发。

Method: 提出了一种名为OptimalThinkingBench的统一基准测试，该测试包含两个子基准：OverthinkingBench（用于评估简单查询的过度思考）和UnderthinkingBench（用于评估复杂推理任务的思考不足）。并使用新颖的“思考调整准确率”指标对33种不同的思考型和非思考型模型进行了广泛评估。

Result: 评估结果表明，没有模型能够真正实现“最优思考”。思考型模型在简单查询上会过度思考，消耗大量token但性能并未提升；而非思考型的大模型则存在思考不足的问题，表现不如一些规模较小的思考型模型。此外，尝试通过多种方法鼓励最优思考的尝试，往往只能在其中一个子基准上取得改进，而牺牲了另一个子基准的表现。

Conclusion: 目前没有模型能够完美地在OptimalThinkingBench上表现，思考型模型在简单查询上存在过度思考问题，而非思考型模型在复杂推理任务上则存在思考不足的问题。未来的研究需要开发能够在这两方面取得平衡的、真正实现“最优思考”的模型。

Abstract: Thinking LLMs solve complex tasks at the expense of increased compute and
overthinking on simpler problems, while non-thinking LLMs are faster and
cheaper but underthink on harder reasoning problems. This has led to the
development of separate thinking and non-thinking LLM variants, leaving the
onus of selecting the optimal model for each query on the end user. In this
work, we introduce OptimalThinkingBench, a unified benchmark that jointly
evaluates overthinking and underthinking in LLMs and also encourages the
development of optimally-thinking models that balance performance and
efficiency. Our benchmark comprises two sub-benchmarks: OverthinkingBench,
featuring simple queries in 72 domains, and UnderthinkingBench, containing 11
challenging reasoning tasks. Using novel thinking-adjusted accuracy metrics, we
perform extensive evaluation of 33 different thinking and non-thinking models
and show that no model is able to optimally think on our benchmark. Thinking
models often overthink for hundreds of tokens on the simplest user queries
without improving performance. In contrast, large non-thinking models
underthink, often falling short of much smaller thinking models. We further
explore several methods to encourage optimal thinking, but find that these
approaches often improve on one sub-benchmark at the expense of the other,
highlighting the need for better unified and optimal models in the future.

</details>


### [236] [Signal and Noise: A Framework for Reducing Uncertainty in Language Model Evaluation](https://arxiv.org/abs/2508.13144)
*David Heineman,Valentin Hofmann,Ian Magnusson,Yuling Gu,Noah A. Smith,Hannaneh Hajishirzi,Kyle Lo,Jesse Dodge*

Main category: cs.CL

TL;DR: This paper introduces 'signal' and 'noise' metrics to evaluate benchmark reliability for large language model development. It shows that higher signal-to-noise ratios improve decision-making and scaling law predictions. The authors propose methods like using better metrics (e.g., perplexity), filtering noisy tasks, and averaging checkpoints to create more reliable benchmarks.


<details>
  <summary>Details</summary>
Motivation: Developing large language models is expensive and relies on small-scale experiments evaluated on large, multi-task benchmarks. However, current benchmarks may not be reliable for decision-making due to issues with signal (ability to differentiate models) and noise (sensitivity to random variability).

Method: The paper analyzes properties of benchmarks, introduces two key metrics (signal and noise), and proposes three interventions (switching metrics, filtering noisy subtasks, averaging intermediate checkpoint outputs) to improve benchmark quality. It uses 30 benchmarks and 375 models for experiments, creating a dataset of 900K evaluation results.

Result: Benchmarks with a better signal-to-noise ratio are more reliable for small-scale decisions and have lower scaling law prediction error. The proposed interventions, such as using perplexity over accuracy, filtering noisy subtasks, and averaging intermediate checkpoint outputs, lead to improved reliability and reduced scaling law error.

Conclusion: The paper concludes by recommending that creators and selectors of benchmarks aim for high signal and low noise to improve the reliability of evaluations and the accuracy of scaling law predictions.

Abstract: Developing large language models is expensive and involves making decisions
with small experiments, typically by evaluating on large, multi-task evaluation
suites. In this work, we analyze specific properties which make a benchmark
more reliable for such decisions, and interventions to design higher-quality
evaluation benchmarks. We introduce two key metrics that show differences in
current benchmarks: signal, a benchmark's ability to separate better models
from worse models, and noise, a benchmark's sensitivity to random variability
between training steps. We demonstrate that benchmarks with a better
signal-to-noise ratio are more reliable when making decisions at small scale,
and those with less noise have lower scaling law prediction error. These
results suggest that improving signal or noise will lead to more useful
benchmarks, so we introduce three interventions designed to directly affect
signal or noise. For example, we propose that switching to a metric that has
better signal and noise (e.g., perplexity rather than accuracy) leads to better
reliability and improved scaling law error. We also find that filtering noisy
subtasks, to improve an aggregate signal-to-noise ratio, leads to more reliable
multi-task evaluations. We also find that averaging the output of a model's
intermediate checkpoints to reduce noise leads to consistent improvements. We
conclude by recommending that those creating new benchmarks, or selecting which
existing benchmarks to use, aim for high signal and low noise. We use 30
benchmarks for these experiments, and 375 open-weight language models from 60M
to 32B parameters, resulting in a new, publicly available dataset of 900K
evaluation benchmark results, totaling 200M instances.

</details>


### [237] [RepreGuard: Detecting LLM-Generated Text by Revealing Hidden Representation Patterns](https://arxiv.org/abs/2508.13152)
*Xin Chen,Junchao Wu,Shu Yang,Runzhe Zhan,Zeyu Wu,Ziyang Luo,Di Wang,Min Yang,Lidia S. Chao,Derek F. Wong*

Main category: cs.CL

TL;DR: RepreGuard 通过分析 LLM 内部表征的激活模式来检测 LLM 生成文本，在 ID 和 OOD 场景下均表现出色，准确率高达 94.92%。


<details>
  <summary>Details</summary>
Motivation: 现有的 LLM 生成内容检测方法在分布外（OOD）场景下的鲁棒性仍然不足。作者假设 LLM 的内部表征比现有检测方法使用的特征包含更全面、更原始的特征，能够更有效地捕捉和区分 LLM 生成文本和人类写作文本之间的统计模式差异。

Method: RepreGuard 方法首先利用一个代理模型收集 LLM 生成文本（LGT）和人类写作文本（HWT）的内部表征，然后提取能够更好识别 LGT 的区分性激活特征。通过计算文本表征沿该特征方向的投影得分，并与预计算的阈值进行比较，即可对文本进行分类。

Result: 实验结果表明，RepreGuard 在同分布（ID）和分布外（OOD）场景下的平均 AUROC 达到 94.92%，优于所有基线方法。此外，该方法还表现出对不同文本大小和主流攻击的鲁棒性。

Conclusion: RepreGuard 是一种高效的、基于统计的检测方法，在同分布（ID）和分布外（OOD）场景下均优于所有基线方法，平均 AUROC 达到 94.92%，并且能够有效抵御各种文本大小和主流攻击。

Abstract: Detecting content generated by large language models (LLMs) is crucial for
preventing misuse and building trustworthy AI systems. Although existing
detection methods perform well, their robustness in out-of-distribution (OOD)
scenarios is still lacking. In this paper, we hypothesize that, compared to
features used by existing detection methods, the internal representations of
LLMs contain more comprehensive and raw features that can more effectively
capture and distinguish the statistical pattern differences between
LLM-generated texts (LGT) and human-written texts (HWT). We validated this
hypothesis across different LLMs and observed significant differences in neural
activation patterns when processing these two types of texts. Based on this, we
propose RepreGuard, an efficient statistics-based detection method.
Specifically, we first employ a surrogate model to collect representation of
LGT and HWT, and extract the distinct activation feature that can better
identify LGT. We can classify the text by calculating the projection score of
the text representations along this feature direction and comparing with a
precomputed threshold. Experimental results show that RepreGuard outperforms
all baselines with average 94.92% AUROC on both in-distribution (ID) and OOD
scenarios, while also demonstrating robust resilience to various text sizes and
mainstream attacks. Data and code are publicly available at:
https://github.com/NLP2CT/RepreGuard

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [238] [Matrix Control Barrier Functions](https://arxiv.org/abs/2508.11795)
*Pio Ong,Yicheng Xu,Ryan M. Bena,Faryar Jabbari,Aaron D. Ames*

Main category: eess.SY

TL;DR: 该研究将CBF框架推广到矩阵值函数，为更复杂（包括非光滑）的安全集提供连续安全滤波器，并在无人机和机器人领域得到验证。


<details>
  <summary>Details</summary>
Motivation: 矩阵不等式可用于描述更丰富的安全集类别，包括非光滑集。

Method: 通过半定规划（CBF-SDP）从提出的矩阵控制障碍函数构造的安全滤波器被证明是连续的。矩阵公式自然地为基于布尔值的控制障碍函数（特别是析取（OR））提供了连续的安全滤波器，而无需放宽安全集。

Result: 研究结果表明，所提出的框架在无人机网络连通性维护和非光滑障碍物规避等应用中是有效的，并在模拟和硬件实验中得到了证明。

Conclusion: 该研究将标量值函数替换为矩阵值函数，推广了控制障碍函数框架，并为由半定和不定矩阵不等式定义的安全集开发了障碍条件。

Abstract: This paper generalizes the control barrier function framework by replacing
scalar-valued functions with matrix-valued ones. Specifically, we develop
barrier conditions for safe sets defined by matrix inequalities -- both
semidefinite and indefinite. Matrix inequalities can be used to describe a
richer class of safe sets, including nonsmooth ones. The safety filters
constructed from our proposed matrix control barrier functions via semidefinite
programming (CBF-SDP) are shown to be continuous. Our matrix formulation
naturally provides a continuous safety filter for Boolean-based control barrier
functions, notably for disjunctions (OR), without relaxing the safe set. We
illustrate the effectiveness of the proposed framework with applications in
drone network connectivity maintenance and nonsmooth obstacle avoidance, both
in simulations and hardware experiments.

</details>


### [239] [Control of a commercial vehicle by a tetraplegic human using a bimanual brain-computer interface](https://arxiv.org/abs/2508.11805)
*Xinyun Zou,Jorge Gamez,Meghna Menon,Phillip Ring,Chadwick Boulay,Likhith Chitneni,Jackson Brennecke,Shana R. Melby,Gracy Kureel,Kelsie Pejsa,Emily R. Rosario,Ausaf A. Bari,Aniruddh Ravindran,Tyson Aflalo,Spencer S. Kellis,Dimitar Filev,Florian Solzbacher,Richard A. Andersen*

Main category: eess.SY

TL;DR: 研究开发了一种用于驾驶的脑机接口（BCI）系统，该系统允许四肢瘫痪者在模拟和现实世界中驾驶汽车，甚至进行远程驾驶。该BCI系统在驾驶任务中的表现与运动健全者相当，证明了其在恢复残疾人士独立生活能力方面的潜力。


<details>
  <summary>Details</summary>
Motivation: BCI技术在现实世界的应用受到限制，主要局限于实验室环境。本研究旨在克服这一挑战，开发一种能够驱动车辆的BCI系统，并在模拟和现实环境中进行测试，以探索BCI技术在恢复因严重神经损伤而丧失独立性的人群生活能力方面的潜力。

Method: 研究人员开发了一种双臂BCI系统，通过植入在顶叶皮层（PPC）和运动皮层（MC）手部区域的皮层内电极来读取神经信号。该系统能够推断运动规划和执行，并用于驾驶模拟器和真实的汽车。系统通过光标控制速度和转向，并通过单击控制刹车，实现了双臂光标和单击的协同操作。

Result: 研究表明，一名患有四肢瘫痪的参与者在使用植入式BCI系统后，在驾驶模拟器和现实世界中的反应速度和精度均能达到或超过运动健全的参与者。该参与者能够熟练地通过模拟城镇的交通，并成功地在密歇根州的真实环境中远程驾驶福特野马Mach-E电动汽车，证明了BCI技术的安全性和可行性。

Conclusion: 该研究展示了植入式脑机接口（BCI）在现实世界应用中的巨大潜力，特别是对于因严重神经损伤而丧失独立性的人群。研究表明，该BCI系统在模拟和现实驾驶任务中表现出色，甚至能与运动健全的参与者相媲美，并实现了远程驾驶，为恢复残疾人士的独立生活带来了新的希望。

Abstract: Brain-computer interfaces (BCIs) read neural signals directly from the brain
to infer motor planning and execution. However, the implementation of this
technology has been largely limited to laboratory settings, with few real-world
applications. We developed a bimanual BCI system to drive a vehicle in both
simulated and real-world environments. We demonstrate that an individual with
tetraplegia, implanted with intracortical BCI electrodes in the posterior
parietal cortex (PPC) and the hand knob region of the motor cortex (MC), reacts
at least as fast and precisely as motor intact participants, and drives a
simulated vehicle as proficiently as the same control group. This BCI
participant, living in California, could also remotely drive a Ford Mustang
Mach-E vehicle in Michigan. Our first teledriving task relied on cursor control
for speed and steering in a closed urban test facility. However, the final BCI
system added click control for full-stop braking and thus enabled bimanual
cursor-and-click control for both simulated driving through a virtual town with
traffic and teledriving through an obstacle course without traffic in the real
world. We also demonstrate the safety and feasibility of BCI-controlled
driving. This first-of-its-kind implantable BCI application not only highlights
the versatility and innovative potentials of BCIs but also illuminates the
promising future for the development of life-changing solutions to restore
independence to those who suffer catastrophic neurological injury.

</details>


### [240] [Co-Investment with Payoff-Sharing Mechanism for Cooperative Decision-Making in Network Design Games](https://arxiv.org/abs/2508.12059)
*Mingjia He,Andrea Censi,Emilio Frazzoli,Gioele Zardini*

Main category: eess.SY

TL;DR: 本研究提出了一种结合非合作与合作博弈论的游戏理论框架，以解决网络化系统中自利运营商决策导致的次优结果问题。通过共同投资和收益分享机制，旨在实现运营商和用户双赢。案例研究表明，该框架能有效提升互联网络系统的性能，并对环境、社会和经济效益产生积极影响。


<details>
  <summary>Details</summary>
Motivation: 网络化系统固有的互联性导致子系统的设计和性能相互依赖，而自利运营商的决策可能导致对用户和整个系统的次优结果。

Method: 利用一个整合了非合作与合作博弈论的游戏理论框架。在非合作阶段，提出一个网络设计博弈，其中子网络决策者设计局部基础设施。在合作阶段，开发一种共同投资和收益分享机制来扩大集体利益并公平分配。

Result: 通过在苏福尔斯网络和苏黎世及温特图尔（瑞士）的实际公共交通网络上进行案例研究，并考虑对环境可持续性、社会福利和经济效率的影响，证明了该框架的有效性。

Conclusion: 该框架为通过促进自利运营商之间的战略合作来改进相互关联的网络系统奠定了基础。

Abstract: Network-based systems are inherently interconnected, with the design and
performance of subnetworks being interdependent. However, the decisions of
self-interested operators may lead to suboptimal outcomes for users and the
overall system. This paper explores cooperative mechanisms that can
simultaneously benefit both operators and users. We address this challenge
using a game-theoretical framework that integrates both non-cooperative and
cooperative game theory. In the non-cooperative stage, we propose a network
design game in which subnetwork decision-makers strategically design local
infrastructures. In the cooperative stage, co-investment with payoff-sharing
mechanism is developed to enlarge collective benefits and fairly distribute
them. To demonstrate the effectiveness of our framework, we conduct case
studies on the Sioux Falls network and real-world public transport networks in
Zurich and Winterthur, Switzerland. Our evaluation considers impacts on
environmental sustainability, social welfare, and economic efficiency. The
proposed framework provides a foundation for improving interdependent networked
systems by enabling strategic cooperation among self-interested operators.

</details>


### [241] [Design of MIMO Lur'e oscillators via dominant system theory with application in multi-agent rhythm synchronization](https://arxiv.org/abs/2508.12141)
*Yu Kawano,Fulvio Forni*

Main category: eess.SY

TL;DR: A new framework for dynamic output-feedback controllers is presented for Lur'e oscillation in MIMO systems, using extended dominant system theory and a separation principle for independent design of state-feedback and observers. The method is demonstrated with multi-agent system synchronization.


<details>
  <summary>Details</summary>
Motivation: The paper presents a new design framework for dynamic output-feedback controllers for Lur'e oscillation in a multiple-input multiple-output setting.

Method: The paper extends dominant system theory to state-dependent rates to derive conditions based on linear matrix inequalities. It also introduces a separation principle for Lur'e oscillator design, allowing for independent design of a state-feedback oscillator and an observer.

Result: The framework is demonstrated through rhythm synchronization in multi-agent systems.

Conclusion: The proposed control synthesis is demonstrated through rhythm synchronization in multi-agent systems, illustrating how networks of stable, heterogeneous linear agents can be driven into phase-locked rhythmic behavior.

Abstract: This paper presents a new design framework for dynamic output-feedback
controllers for Lur'e oscillation in a multiple-input multiple-output setting.
We first revisit and extend dominant system theory to state-dependent rates,
with the goal of deriving conditions based on linear matrix inequalities. Then,
we introduce a separation principle for Lur'e oscillator design, which allows
for the independent design of a state-feedback oscillator and an observer. Our
proposed control synthesis is demonstrated through the rhythm synchronization
in multi-agent systems, illustrating how networks of stable, heterogeneous
linear agents can be driven into phase-locked rhythmic behavior.

</details>


### [242] [Euclidean Approach to Green-Wave Theory Applied to Traffic Signal Networks](https://arxiv.org/abs/2508.12146)
*Melvin H. Friedman,Brian L. Mark,Nathan H. Gartner*

Main category: eess.SY

TL;DR: A new green-wave theory, inspired by Euclid, enables continuous traffic flow on arterial roads using a feedback device. It defines new concepts and uses geometric reasoning to show that existing roads can be adapted for this system, with effectiveness confirmed by simulations.


<details>
  <summary>Details</summary>
Motivation: Traffic flow on long arterial roads with signalized intersections is often inefficient and challenging to coordinate, especially as the number of signals increases. Traditional progression schemes fail in these scenarios. Proper coordination through long progressions can save travel time and fuel, reduce pollution, and decrease traffic accidents by ensuring a smoother traffic flow.

Method: The paper introduces a green-wave theory modeled after Euclid, defining concepts like RGW-roads, green-arrows, real nodes, virtual nodes, and green-wave speed. Geometric reasoning is used to deduce properties of green-wave systems, such as maximum and discrete green-arrow lengths, and the conditions under which existing roads can be converted to RGW-roads.

Result: The study demonstrates that green-arrow lengths have a maximum value and are restricted to discrete lengths. The laws of motion derived from the green-wave theory imply that certain existing arterial roads can be converted into RGW-roads. The paper also validates the effectiveness of the generated signal timings and offsets using a simulation model named RGW-SIM.

Conclusion: The proposed green-wave theory, utilizing RGW-roads and a Road-to-Traveler-Feedback Device, can be applied to networks of intersecting arterial roads to achieve uninterrupted flow. Geometric reasoning deduces that green-arrow lengths have a maximum and discrete values, and that existing roads can be converted to RGW-roads. The effectiveness of the resulting signal timings and offsets has been verified through a simulation model called RGW-SIM.

Abstract: Travel on long arterials with signalized intersections can be inefficient if
not coordinated properly. As the number of signals increases, coordination
becomes more challenging and traditional progression schemes tend to break
down. Long progressions save travel time and fuel, reduce pollution and traffic
accidents by providing a smoother flow of traffic. This paper introduces a
green-wave theory that can be applied to a network of intersecting arterial
roads. It enables uninterrupted flow on arbitrary long signalized arterials
using a Road-to-Traveler-Feedback Device. The approach is modelled after
Euclid. We define concepts such as RGW-roads (roads where vehicles traveling at
the recommended speed make all traffic signals), green-arrows (representing
vehicle platoons), real nodes (representing signalized intersections where
RGW-roads intersect) and virtual nodes, green-wave speed, blocks, etc. - the
analogue of Euclid's postulates. We then use geometric reasoning to deduce
results: green-arrow lengths have a maximum value, are restricted to discrete
lengths, and green-arrow laws of motion imply that select existing arterial
roads can be converted to RGW-roads. The signal timings and offsets that are
produced have been shown to be effective using a simulation model developed
previously called RGW-SIM.

</details>


### [243] [Feedback Linearization for Replicator Dynamics: A Control Framework for Evolutionary Game Convergence](https://arxiv.org/abs/2508.12583)
*Adil Faisal*

Main category: eess.SY

TL;DR: This paper applies feedback linearization to replicator dynamics to stabilize non-convergent evolutionary games.


<details>
  <summary>Details</summary>
Motivation: The motivation of this paper is to address the evolution of non-convergent evolutionary games.

Method: feedback linearization

Result: The application of feedback linearization to replicator dynamics has been demonstrated, leading to systems with guaranteed global asymptotic stability, effectively driving the evolution of non-convergent evolutionary games.

Conclusion:  the evolution of non-convergent evolutionary games to systems with guaranteed global asymptotic stability

Abstract: This paper demonstrates the first application of feedback linearization to
replicator dynamics, driving the evolution of non-convergent evolutionary games
to systems with guaranteed global asymptotic stability.

</details>


### [244] [A layered smart sensing platform for physiologically informed human-exoskeleton interaction](https://arxiv.org/abs/2508.12157)
*Chenyu Tang,Yu Zhu,Josée Mallah,Wentian Yi,Luyao Jin,Zibo Zhang,Shengbo Wang,Muzi Xu,Ming Shen,Calvin Kalun Or,Shuo Gao,Shaoping Bai,Luigi G. Occhipinti*

Main category: eess.SY

TL;DR: 这项研究提出了一种集成了EMG、应变传感器和IMU的智能腿套，用于实时监测用户的生理和生物力学状态，以实现外骨骼的个性化控制、优化用户功耗和预防伤害。该系统轻便、柔软且易于集成，并在实验中取得了优异的准确率和实时性。


<details>
  <summary>Details</summary>
Motivation: 为了克服目前外骨骼部署在实验室环境之外的部署限制，这些限制源于无法实时完全捕捉用户生理和生物力学状态的传感系统。

Method: 提出了一种柔软、轻便的智能腿套，集成了基于纺织的表面肌电图（sEMG）电极、超灵敏纺织应变传感器和惯性测量单元（IMU）。

Result: 1. 实现了准确的踝关节力矩估计（RMSE = 0.13 Nm/kg）；2. 实现了代谢趋势的实时分类（准确率 = 97.1%）；3. 在100毫秒内检测到损伤风险（召回率 = 0.96）。所有结果均通过留一法交叉验证协议在未见过用户的数据上进行了验证。

Conclusion: 该研究展示了一种轻质、多模态的传感架构，用于下一代人与外骨骼的交互，适用于受控和半结构化行走场景，并有潜力扩展到更广泛的外骨骼应用，以实现智能、响应迅速和个性化的可穿戴机器人。

Abstract: Wearable exoskeletons offer transformative potential to assist mobility
across diverse user groups with reduced muscle strength or other forms of
impaired mobility. Yet, their deployment beyond laboratory settings remains
constrained by sensing systems able to fully capture users' physiological and
biomechanical states in real time. We introduce a soft, lightweight smart leg
sleeve with anatomically inspired layered multimodal sensing, integrating
textile-based surface electromyography (sEMG) electrodes, ultrasensitive
textile strain sensors, and inertial measurement units (IMUs). Each sensing
modality targets a distinct physiological layer: IMUs track joint kinematics at
the skeletal level, sEMG monitors muscle activation at the muscular level, and
strain sensors detect skin deformation at the cutaneous level. Together, these
sensors provide real-time perception to support three core objectives:
controlling personalized assistance, optimizing user effort, and safeguarding
against injury risks. The system is skin-conformal, mechanically compliant, and
seamlessly integrated with a custom exoskeleton (<20 g total sensor and
electronics weight). We demonstrate: (1) accurate ankle joint moment estimation
(RMSE = 0.13 Nm/kg), (2) real-time classification of metabolic trends (accuracy
= 97.1%), and (3) injury risk detection within 100 ms (recall = 0.96), all
validated on unseen users using a leave-one-subject-out protocol. This work
demonstrates a lightweight, multimodal sensing architecture for next-generation
human-exoskeleton interaction in controlled and semi-structured walking
scenarios, with potential for scaling to broader exoskeleton applications
towards intelligent, responsive, and personalized wearable robotics.

</details>


### [245] [Monotone Neural Control Barrier Certificates](https://arxiv.org/abs/2508.12178)
*Alireza Nadali,Ashutosh Trivedi,Majid Zamani,Saber Jafarpour*

Main category: eess.SY

TL;DR: 本文提出了一种神经符号框架，用于在高维单调动力学系统中合成和验证安全控制器，该框架结合了神经网络和符号推理，实现了可扩展且形式上有保证的安全保障。


<details>
  <summary>Details</summary>
Motivation: 为了解决先前数据驱动方法在处理高维单调动力学系统时，由于将动力学视为黑盒模型，并依赖于密状态空间离散化或Lipschitz过近似而导致的指数样本复杂度问题。

Method: 该方法结合了单调神经网络（具有嵌入式单调性约束的架构）和基于屏障条件（形式上保证安全的归纳不变量的功能类似物）的梯度优化来综合屏障证书。

Result: 经验结果表明，该方法在1000维高速公路交通模型、50维城市交通网络和13000维电网这三个大规模基准测试中具有可扩展性和有效性，能够直接从仿真数据中进行可扩展的、形式上可靠的验证。

Conclusion: 该方法提出了一种结合神经网络表达能力和基于屏障证书的符号推理的神经符号框架，用于在高维单调动力学系统中综合和验证安全控制器，具有线性样本复杂度，无需显式模型或保守的Lipschitz界限。

Abstract: This work presents a neurosymbolic framework for synthesizing and verifying
safety controllers in high-dimensional monotone dynamical systems using only
linear sample complexity, without requiring explicit models or conservative
Lipschitz bounds. The approach combines the expressiveness of neural networks
with the rigor of symbolic reasoning via barrier certificates, functional
analogs of inductive invariants that formally guarantee safety. Prior
data-driven methods often treat dynamics as black-box models, relying on dense
state-space discretization or Lipschitz overapproximations, leading to
exponential sample complexity. In contrast, monotonicity -- a pervasive
structural property in many real-world systems -- provides a symbolic scaffold
that simplifies both learning and verification. Exploiting order preservation
reduces verification to localized boundary checks, transforming a
high-dimensional problem into a tractable, low-dimensional one. Barrier
certificates are synthesized using monotone neural networks -- architectures
with embedded monotonicity constraints -- trained via gradient-based
optimization guided by barrier conditions. This enables scalable, formally
sound verification directly from simulation data, bridging black-box learning
and formal guarantees within a unified neurosymbolic framework. Empirical
results on three large-scale benchmarks -- a 1,000-dimensional freeway traffic
model, a 50-dimensional urban traffic network, and a 13,000-dimensional power
grid -- demonstrate the scalability and effectiveness of the approach in
real-world, safety-critical systems.

</details>


### [246] [Understanding the Fundamental Trade-Off Between Age of Information and Throughput in Unreliable Wireless Networks](https://arxiv.org/abs/2508.12185)
*Lin Wang,I-Hong Hou*

Main category: eess.SY

TL;DR: 本研究提出了一个吞吐量-AoI容量区域，并设计了一种最优调度策略，以在存在信道不确定性的情况下提高无线网络的吞吐量和信息新鲜度。


<details>
  <summary>Details</summary>
Motivation: 为了表征和优化无线网络中吞吐量和信息年龄（AoI）之间的基本权衡，特别是在存在随机传输成功的情况下。

Method: 提出了一种新颖的吞吐量-信息年龄（AoI）容量区域来定义可行的吞吐量-AoI对，并利用二阶近似（考虑均值和时间方差）推导了容量区域的上下界。此外，还提出了一种简单、低复杂度的调度策略。

Result: 所提出的调度策略在各种实际网络优化场景中显著优于传统方法，有效优化了吞吐量和AoI。

Conclusion: 该研究为在实际无线通信场景中吞吐量和信息新鲜度的联合优化提供了一个系统化、理论上可行且经过实践验证的框架。

Abstract: This paper characterizes the fundamental trade-off between throughput and Age
of Information (AoI) in wireless networks where multiple devices transmit
status updates to a central base station over unreliable channels. To address
the complexity introduced by stochastic transmission successes, we propose the
throughput-AoI capacity region, which defines all feasible throughput-AoI pairs
achievable under any scheduling policy. Using a second-order approximation that
incorporates both mean and temporal variance, we derive an outer bound and a
tight inner bound for the throughput-AoI capacity region. Furthermore, we
propose a simple and low complexity scheduling policy and prove that it
achieves every interior point within the tight inner bound. This establishes a
systematic and theoretically grounded framework for the joint optimization of
throughput and information freshness in practical wireless communication
scenarios.
  To validate our theoretical framework and demonstrate the utility of the
throughput-AoI capacity region, extensive simulations are implemented.
Simulation results demonstrate that our proposed policy significantly
outperforms conventional methods across various practical network optimization
scenarios. The findings highlight our approach's effectiveness in optimizing
both throughput and AoI, underscoring its applicability and robustness in
practical wireless networks.

</details>


### [247] [Adaptive Control with Set-Point Tracking and Linear-like Closed-loop Behavior](https://arxiv.org/abs/2508.12225)
*Mohamad T. Shahab*

Main category: eess.SY

TL;DR: 本文研究了离散时间系统中的定点跟踪问题，提出了一种基于参数估计和极点配置的自适应控制器。该控制器能实现类线性闭环行为，并保证了系统的有界增益和渐近跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 在本文中，我们考虑了一个具有未知植物参数（属于凸紧不确定性集）的离散时间植物的定点跟踪问题。

Method: 采用与相关辅助植物的参数估计，并采用基于极点配置的控制律。

Result: 该控制器保证了由初始条件指数衰减、外源输入的类线性卷积界以及参数估计器更新律分母中常数平方根缩放的常数组成的界，表明系统具有有界增益。当扰动为常数时，渐近跟踪也得到了证明。

Conclusion: 该自适应控制器提供了理想的类线性闭环行为，该行为保证了由初始条件指数衰减、外源输入的类线性卷积界以及参数估计器更新律分母中常数平方根缩放的常数组成的界。这表明系统具有有界增益。此外，当扰动为常数时，渐近跟踪也得到了证明。

Abstract: In this paper, we consider the problem of set-point tracking for a
discrete-time plant with unknown plant parameters belonging to a convex and
compact uncertainty set. We carry out parameter estimation for an associated
auxiliary plant, and a pole-placement-based control law is employed. We prove
that this adaptive controller provides desirable linear-like closed-loop
behavior which guarantees a bound consisting of: exponential decay with respect
to the initial condition, a linear-like convolution bound with respect to the
exogenous inputs, and a constant scaled by the square root of the constant in
the denominator of the parameter estimator update law. This implies that the
system has a bounded gain. Moreover, asymptotic tracking is also proven when
the disturbance is constant.

</details>


### [248] [Design and Analysis of Curved Electrode Configurations for Enhanced Sensitivity in 1-Axis MEMS Accelerometers](https://arxiv.org/abs/2508.12249)
*Adhinarayan Naembin Ashok,Adarsh Ganesan*

Main category: eess.SY

TL;DR: 通过使用双凸弧形电极，在不改变器件尺寸的情况下，提高了MEMS电容加速度计的灵敏度。


<details>
  <summary>Details</summary>
Motivation: 为了提高MEMS电容加速度计的灵敏度，本研究对曲面电极几何结构进行了全面的分析和仿真研究。

Method: 推导了具有六种不同固定电极轮廓（双凸、双凹、凹凸、凸凹、平面凸、平面凹）的平面可动电极之间的电容表达式，可以根据电极曲率和间隙位移直接计算差分增益和灵敏度。使用COMSOL Multiphysics进行的有限元模拟在相同的偏置和边界条件下严格验证了这些分析模型。

Result: 分析和仿真结果表明，双凸弧形电极可提供最大的灵敏度提升，其灵敏度随圆弧长度单调增加。凹面和平面-凹面设计性能有所下降。凹-凸和凸-凹构型会引入输出电压极性反转。所有构型的仿真结果与分析结果的偏差均小于7%。

Conclusion: 研究表明，双凸弧形电极相比平面电极可显著提高MEMS电容加速度计的灵敏度，且灵敏度随圆弧长度单调增加。凹面和平面-凹面设计性能有所下降。凹-凸和凸-凹构型会引入输出电压极性反转，增加了设计的灵活性。这些灵敏度提升是在不改变器件整体体积或测点质量块尺寸的情况下实现的，有助于实现更高分辨率的惯性传感。

Abstract: This paper presents a comprehensive analytical and simulation-based study of
curved electrode geometries for enhancing the sensitivity of MEMS capacitive
accelerometers. Expressions for the capacitance between a planar movable
electrode and six distinct fixed electrode profiles (biconvex, biconcave,
concavo-convex, convexo-concave, plano-convex, and plano-concave) are derived,
enabling direct calculation of differential gain and sensitivity as functions
of electrode curvature and gap displacement. These analytical models are then
rigorously validated using finite element simulations performed using COMSOL
Multiphysics under identical bias and boundary conditions. The simulation
results demonstrate agreement with the analytical results with a deviation of
less than 7% in all configurations. The results also reveal that biconvex
curved electrodes yield the greatest sensitivity improvement over the planar
electrodes, with sensitivity monotonically increasing with arc length, while
concave and plano-concave designs exhibit reduced performance. The
concavo-convex and convexo-concave configurations furthermore introduce
polarity inversion in the output voltage, offering additional design
flexibility. Importantly, these sensitivity enhancements are achieved without
any change in the overall volumetric dimensions of the device or the proofmass
dimensions of the module for achieving higher-resolution inertial sensing.

</details>


### [249] [Efficient and accurate solution of wind-integrated optimal power flow based on enhanced second-order cone relaxation with rolling cutting plane technique](https://arxiv.org/abs/2508.12351)
*Zhaojun Ruan,Botao Gao,Libao Shi*

Main category: eess.SY

TL;DR: 风力发电并网导致电力系统运行不确定性增加。本文提出了一种结合高斯混合模型、二阶锥松弛（SOCR）和滚动切割平面技术的方法来解决风力发电并网下的最优潮流问题。该方法能够有效处理风力发电成本，并提高计算效率。


<details>
  <summary>Details</summary>
Motivation: 为了解决大规模可再生能源（如风力发电）并网带来的不确定性问题，以实现电力系统的最优运行。

Method: 提出了一种基于增强的二阶锥松弛（SOCR）和滚动切割平面技术的风力发电并网最优潮流（OPF）解决方案框架。首先，使用高斯混合模型对风力发电成本进行建模，并将其纳入OPF目标函数。然后，采用SOCR和二阶泰勒展开式对交流潮流方程进行凸近似。最后，通过滚动切割平面技术提出的暖启动策略用于减小松弛误差并提高计算效率。

Result: 该框架在多种案例研究中被证明是有效且高效的，能够处理风力发电并网下的最优潮流问题，并分析了风力发电成本的影响。

Conclusion: 该解决方案框架通过多种案例研究，有效解决了风力发电并网下的最优潮流问题，并评估了风力发电成本的影响。

Abstract: The integration of large-scale renewable energy sources, such as wind power,
poses significant challenges for the optimal operation of power systems owing
to their inherent uncertainties. This paper proposes a solution framework for
wind-integrated optimal power flow (OPF) that leverages an enhanced
second-order cone relaxation (SOCR), supported by a rolling cutting plane
technique. Initially, the wind generation cost, arising from discrepancies
between scheduled and actual wind power outputs, is meticulously modeled using
a Gaussian mixture model based on historical wind power data. This modelled
wind generation cost is subsequently incorporated into the objective function
of the conventional OPF problem. To achieve the efficient and accurate solution
for the wind-integrated OPF, effectively managing the constraints associated
with AC power flow equations is essential. In this regard, a SOCR, combined
with a second-order Taylor series expansion, is employed to facilitate the
convex approximation of the AC power flow equations. Additionally, a warm-start
strategy, grounded in a proposed rolling cutting plane technique, is devised to
reduce relaxation errors and enhance computational efficiency. Finally, the
effectiveness and efficiency of the proposed solution framework are
demonstrated across various case studies. Specifically, the influence of wind
power cost is also examined, further highlighting the practical implications of
the proposed solution framework.

</details>


### [250] [Data-driven quantification and visualization of resilience metrics of power distribution system](https://arxiv.org/abs/2508.12408)
*Dingwei Wang,Salish Maharjan,Junyuan Zheng,Liming Liu,Zhaoyu Wang*

Main category: eess.SY

TL;DR: 本文提出了一种数据驱动的方法，使用历史停电记录和NOAA天气数据来量化电网对极端天气的复原力，通过分析停电数量和恢复时间，并使用Voronoi图划分天气区域，最后为每个区域建立数据模型来评估不同强度天气事件下的复原力。


<details>
  <summary>Details</summary>
Motivation: 为了量化配电电网在极端天气事件下的复原力，并提供一种数据驱动的方法来评估停电数量和恢复时间。

Method: 提出了一种数据驱动的方法，利用历史停电记录和NOAA天气测量数据，通过提取停电事件、划分天气区域和开发停电脆弱性及恢复时间模型来量化配电电网对极端天气事件的复原力。

Result: 使用美国一家配电公司为期二十年的真实数据，证明了该方法的有效性，该数据包含超过16万条停电记录，重点关注了与风和降水相关的事件。

Conclusion: 该方法能够量化和可视化电网在极端天气事件下的复原力指标。

Abstract: This paper presents a data-driven approach for quantifying the resilience of
distribution power grids to extreme weather events using two key metrics: (a)
the number of outages and (b) restoration time. The method leverages historical
outage records maintained by power utilities and weather measurements collected
by the National Oceanic and Atmospheric Administration (NOAA) to evaluate
resilience across a utility's service territory. The proposed framework
consists of three stages. First, outage events are systematically extracted
from the outage records by temporally and spatially aggregating coincident
component outages. In the second stage, weather zones across the service
territory are delineated using a Voronoi polygon approach, based on the
locations of NOAA weather sensors. Finally, data-driven models for outage
fragility and restoration time are developed for each weather zone. These
models enable the quantification and visualization of resilience metrics under
varying intensities of extreme weather events. The proposed method is
demonstrated using real-world data from a US distribution utility, located in
Indianapolis, focused on wind- and precipitation-related events. The dataset
spans two decades and includes over 160,000 outage records.

</details>


### [251] [A One-Class Explainable AI Framework for Identification of Non-Stationary Concurrent False Data Injections in Nuclear Reactor Signals](https://arxiv.org/abs/2508.12428)
*Zachery Dahm,Vasileios Theos,Konstantinos Vasili,William Richards,Konstantinos Gkouliaras,Stylianos Chatzidakis*

Main category: eess.SY

TL;DR: 提出一个XAI框架，利用改进的循环神经网络和残差分析来检测核反应器信号中的虚假数据注入，该框架在真实数据集上表现出色。


<details>
  <summary>Details</summary>
Motivation: 下一代核反应器系统从模拟转向全数字仪控，需要强大的机制来防范潜在的数据完整性威胁，特别是实时识别可能破坏反应堆控制系统的虚假数据注入。

Method: 提出一个利用循环神经网络、残差分析、SHAP算法和基于规则的相关性来识别核反应器信号中非平稳并发重放攻击的XAI框架。其中，循环神经网络仅在正常运行数据上进行训练，残差分析引入了自适应窗口技术来提高检测精度。

Result: 所提出的XAI框架在Purdue核反应器(PUR-1)的真实世界数据集上进行了基准测试，成功检测了虚假数据注入，准确率高于0.93，误报率低于0.01，并能将虚假数据与预期的工艺异常区分开，同时识别了伪造信号的来源。

Conclusion: 该框架能够以高于0.93的准确率检测虚假数据注入，将误报率降至0.01以下，并能将虚假数据与预期的工艺异常区分开，同时还能识别伪造信号的来源。

Abstract: The transition of next generation advanced nuclear reactor systems from
analog to fully digital instrumentation and control will necessitate robust
mechanisms to safeguard against potential data integrity threats. One challenge
is the real-time characterization of false data injections, which can mask
sensor signals and potentially disrupt reactor control systems. While
significant progress has been made in anomaly detection within reactor systems,
potential false data injections have been shown to bypass conventional linear
time-invariant state estimators and failure detectors based on statistical
thresholds. The dynamic, nonlinear, multi-variate nature of sensor signals,
combined with inherent noise and limited availability of real-world training
data, makes the characterization of such threats and more importantly their
differentiation from anticipated process anomalies particularly challenging. In
this paper, we present an eXplainable AI (XAI) framework for identifying
non-stationary concurrent replay attacks in nuclear reactor signals with
minimal training data. The proposed framework leverages progress on recurrent
neural networks and residual analysis coupled with a modified SHAP algorithm
and rule-based correlations. The recurrent neural networks are trained only on
normal operational data while for residual analysis we introduce an adaptive
windowing technique to improve detection accuracy. We successfully benchmarked
this framework on a real-world dataset from Purdue's nuclear reactor (PUR-1).
We were able to detect false data injections with accuracy higher than 0.93 and
less than 0.01 false positives, differentiate from expected process anomalies,
and to identify the origin of the falsified signals.

</details>


### [252] [Sspherical sailing omnidirectional rover (SSailOR): wind tunnel experimental setup and results](https://arxiv.org/abs/2508.12443)
*Aditya Varanwal,Parin Shah,George Carrion,Ashley Ortenburg,Diego Ramirez-Gomez,Chris Vermillion,Andre P. Mazzoleni*

Main category: eess.SY

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This paper presents the design, instrumentation, and experimental procedures
used to test the Spherical Sailing Omnidirectional Rover (SSailOR) in a
controlled wind tunnel environment. The SSailOR is a wind-powered autonomous
rover. This concept is motivated by the growing need for persistent and
sustainable robotic systems in applications such as planetary exploration,
Arctic observation, and military surveillance. SSailOR uses wind propulsion via
onboard sails to enable long-duration mobility with minimal energy consumption.
The spherical design simplifies mechanical complexity while enabling
omnidirectional movement. Experimental tests were conducted to validate dynamic
models and assess the aerodynamic performance of the rover under various
configurations and environmental conditions. As a result, this design requires
a co-design approach. Details of the mechanical structure, sensor integration,
electronics, data acquisition system, and test parameters are presented in this
paper. In addition, key observations are made that are relevant to the design
optimization for further development of the rover.

</details>


### [253] [Techno-Economic Planning of Spatially-Resolved Battery Storage Systems in Renewable-Dominant Grids Under Weather Variability](https://arxiv.org/abs/2508.12526)
*Seyed Ehsan Ahmadi,Elnaz Kabir,Mohammad Fattahi,Mousa Marzband,Dongjun Li*

Main category: eess.SY

TL;DR: 本研究利用两阶段随机规划模型，通过优化电池储能系统的部署，证明了其在提高纽约州电力系统韧性、减少可再生能源弃用和负荷削减方面的有效性。研究还指出了成本与可再生能源渗透率之间的复杂关系，为实现纽约州的能源目标提供了策略性指导。


<details>
  <summary>Details</summary>
Motivation: 由于间歇性和波动性，可再生能源在电力系统中的份额不断增加，带来了负荷削减和系统拥堵等挑战。本研究旨在探讨电池储能系统在平衡供需、缓解这些挑战中的作用。

Method: 本研究采用两阶段随机规划模型来优化电池储能系统的选址、规模和类型，并结合蒙特卡洛模拟来处理负荷和可再生能源发电的不确定性。

Result: 研究结果表明，电池储能系统可将可再生能源弃用减少34%，负荷削减减少21%。这表明电池储能系统在提高电力系统韧性、实现纽约州2030年能源目标方面发挥着重要作用。此外，研究还发现，用于减少负荷削减和可再生能源弃用的电池储能系统的成本并非与容量成线性增长关系。

Conclusion: 本研究的结论是，电池储能系统（BSS）可以显著减少可再生能源的弃用和负荷削减，有助于提高纽约州电力系统的韧性，并实现其2030年能源目标。此外，研究还揭示了成本与可再生能源渗透率之间存在复杂的非线性关系，为经济高效地部署BSS提供了宝贵的见解。

Abstract: The ongoing energy transition is significantly increasing the share of
renewable energy sources (RES) in power systems; however, their intermittency
and variability pose substantial challenges, including load shedding and system
congestion. This study examines the role of the battery storage system (BSS) in
mitigating these challenges by balancing power supply and demand. We optimize
the location, size, and type of batteries using a two-stage stochastic program,
with the second stage involving hourly operational decisions over an entire
year. Unlike previous research, we incorporate the comprehensive technical and
economic characteristics of battery technologies. The New York State (NYS)
power system, currently undergoing a significant shift towards increased RES
generation, serves as our case study. Using available load and weather data
from 1980-2019, we account for the uncertainty of both load and RES generation
through a sample average approximation approach. Our findings indicate that BSS
can reduce renewable curtailment by 34% and load shedding by 21%, contributing
to a more resilient power system in achieving NYS 2030 energy targets.
Furthermore, the cost of employing BSS for the reduction of load shedding and
RES curtailment does not increase linearly with additional capacity, revealing
a complex relationship between costs and renewable penetration. This study
provides valuable insights for the strategic BSS deployment to achieve a
cost-effective and reliable power system in the energy transition as well as
the feasibility of the NYS 2030 energy targets.

</details>


### [254] [DCT-MARL: A Dynamic Communication Topology-Based MARL Algorithm for Connected Vehicle Platoon Control](https://arxiv.org/abs/2508.12633)
*Yaqi Xu,Yan Shi,Jin Tian,Fanzeng Xia,Shanzhi Chen,Yuming Ge*

Main category: eess.SY

TL;DR: DCT-MARL算法通过增强状态空间（历史控制动作和延迟）和引入多密钥门控通信机制来应对V2V通信中的延迟和丢包问题，实现了更鲁棒的合作车队控制。


<details>
  <summary>Details</summary>
Motivation: 为了减轻非理想通信的不利影响，（V2V链接可能遭受时变延迟和丢包，导致控制性能下降甚至安全风险）。

Method: 提出了一种基于动态通信拓扑的多智能体强化学习（DCT-MARL）算法来实现鲁棒的合作车队控制。具体地，通过历史控制动作和延迟来增强状态空间，以提高对通信延迟的鲁棒性。为了减轻丢包的影响，引入了一种多密钥门控通信机制，该机制根据智能体之间的相关性及其当前的通信状态动态调整通信拓扑。

Result: 仿真结果表明，所提出的DCT-MARL在字符串稳定性和驾驶舒适性方面显著优于最先进的方法，验证了其优越的鲁棒性和有效性。

Conclusion: 仿真结果表明，所提出的DCT-MARL在字符串稳定性和驾驶舒适性方面显著优于最先进的方法，验证了其优越的鲁棒性和有效性。

Abstract: With the rapid advancement of vehicular communication and autonomous driving
technologies, connected vehicle platoon has emerged as a promising approach to
improve traffic efficiency and driving safety. Reliable Vehicle-to-Vehicle
(V2V) communication is critical to achieving efficient cooperative control.
However, in real-world traffic environments, V2V links may suffer from
time-varying delay and packet loss, leading to degraded control performance and
even safety risks. To mitigate the adverse effects of non-ideal communication,
this paper proposes a Dynamic Communication Topology based Multi-Agent
Reinforcement Learning (DCT-MARL) algorithm for robust cooperative platoon
control. Specifically, the state space is augmented with historical control
action and delay to enhance robustness against communication delay. To mitigate
the impact of packet loss, a multi-key gated communication mechanism is
introduced, which dynamically adjusts the communication topology based on the
correlation between agents and their current communication status.Simulation
results demonstrate that the proposed DCT-MARL significantly outperforms
state-of-the-art methods in terms of string stability and driving comfort,
validating its superior robustness and effectiveness.

</details>


### [255] [Stability Analysis of the Newton-Raphson Controller for a Class of Differentially Flat Systems](https://arxiv.org/abs/2508.12694)
*Kaicheng Niu,Yorai Wardi,Chaouki T. Abdallah*

Main category: eess.SY

TL;DR: 本文研究了牛顿-拉夫森控制器在非线性系统中的稳定性，并证明了其在输出调节和跟踪控制中的有效性，仿真结果也验证了其潜力。


<details>
  <summary>Details</summary>
Motivation: 牛顿-拉夫森控制器在多种控制应用中被证明是有效的，但其在线性系统中的稳定性条件已经确定，而在线性系统中该条件的稳定性条件仍然未被探索。因此，本文旨在研究牛顿-拉夫森控制器在微分平坦非线性系统中的稳定性。

Method: 本文研究了牛顿-拉夫森控制器在微分平坦非线性系统中的稳定性，并针对输出调节和跟踪控制问题进行了分析。对于输出调节，通过证明系统在原点邻域内的稳定性来验证控制器的有效性，并进行了吸引子域度量的半定量分析。对于跟踪控制，通过选择特定的控制器参数来证明控制器能够驱动输出到外部参考信号。

Result: 本文证明了牛顿-拉夫森控制器对于一类微分平坦非线性系统在输出调节和跟踪控制中是有效的。仿真结果表明，该控制器在倒立摆和运动自行车上分别实现了调节和跟踪。

Conclusion: 本文证明了对于一类微分平坦非线性系统，当相应的平坦系统和输出预测器满足可验证的稳定性准则时，牛顿-拉夫森控制器能够实现原点邻域内的稳定。同时，也证明了在特定控制器参数选择下，该控制器能够将输出驱动到外部参考信号。仿真结果表明，该控制器在倒立摆和运动自行车上分别实现了调节和跟踪，在未来的控制应用中具有潜力。

Abstract: The Newton-Raphson Controller, established on the output prediction and the
Newton-Raphson algorithm, is shown to be effective in a variety of control
applications. Although the stability condition of the controller for linear
systems has already been established, such condition for nonlinear systems
remains unexplored. In this paper, we study the stability of the Newton-Raphson
controller for a class of differentially flat nonlinear systems in the context
of output regulation and tracking control. For output regulation, we prove that
the controlled system is stable within a neighborhood of the origin if the
corresponding flat system and output predictor satisfy a verifiable stability
criterion. A semi-quantitative analysis is conducted to determine the measure
of the domain of attraction. For tracking control, we prove that the controller
is capable of driving the outputs to the external reference signals using a
specific selection of controller parameters. Simulation results show that the
controller achieves regulation and tracking respectively on the inverted
pendulum and the kinematic bicycle, suggesting a potential in future control
applications.

</details>


### [256] [Deadline-Aware Bandwidth Allocation for Semantic Generative Communication with Diffusion Models](https://arxiv.org/abs/2508.12701)
*Jinhyuk Choi,Jihong Park,Seungeun Oh,Seong-Lyun Kim*

Main category: eess.SY

TL;DR: 本文提出了一种针对图像修复的语义生成通信（SGC）框架，并设计了一种创新的带宽分配方案。该方案基于“语义截止时间线”理论，为网络传输分配带宽，以优化AI生成性能。实验证明，该方案在给定带宽下比传统方法能取得更好的PSNR结果。


<details>
  <summary>Details</summary>
Motivation: 随着AI应用服务在RAN中的重要性日益增加，需要一种集成方法来同时考虑网络效率和AI性能。本文旨在为图像修复应用开发一种语义生成通信（SGC）框架。

Method: 提出了一种带宽分配方案，该方案基于“语义截止时间线”——即在多模态SGC框架中，为了满足给定的性能阈值而要求注入条件数据的最小时间。该方案将有限的带宽分配给每个语义信息，以确保其在相应的语义截止时间线内传输。

Result: 实验结果表明，所提出的带宽分配方案在PSNR方面实现了更高的生成性能。

Conclusion: 提出的方法比不考虑语义截止时间线的传统方法在给定带宽下实现了更高的PSNR生成性能。

Abstract: The importance of Radio Access Network (RAN) in support Artificial
Intelligence (AI) application services has grown significantly, underscoring
the need for an integrated approach that considers not only network efficiency
but also AI performance. In this paper we focus on a semantic generative
communication (SGC) framework for image inpainting application. Specifically,
the transmitter sends semantic information, i.e., semantic masks and textual
descriptions, while the receiver utilizes a conditional diffusion model on a
base image, using them as conditioning data to produce the intended image. In
this framework, we propose a bandwidth allocation scheme designed to maximize
bandwidth efficiency while ensuring generation performance. This approach is
based on our finding of a Semantic Deadline--the minimum time that conditioning
data is required to be injected to meet a given performance threshold--within
the multi-modal SGC framework. Given this observation, the proposed scheme
allocates limited bandwidth so that each semantic information can be
transmitted within the corresponding semantic deadline. Experimental results
corroborate that the proposed bandwidth allocation scheme achieves higher
generation performance in terms of PSNR for a given bandwidth compared to
traditional schemes that do not account for semantic deadlines.

</details>


### [257] [On the Gaussian Limit of the Output of IIR Filters](https://arxiv.org/abs/2508.12705)
*Yashaswini Murthy,Bassam Bamieh,R. Srikant*

Main category: eess.SY

TL;DR: 该研究使用Stein方法证明，在特定条件下，稳定LTI系统的输出（即使输入非高斯）也会近似服从高斯分布，并找到了收敛到高斯分布的速率。


<details>
  <summary>Details</summary>
Motivation: 从随机描述函数法的长期启发式方法中获得灵感，严格描述了即使在输入非高斯的情况下，输出过程何时近似高斯。

Method: 利用Stein方法推导出输出与标准正态分布之间的距离的上界，该上界明确依赖于系统的冲激响应和输入的依赖结构。

Result: 当系统的极点接近稳定性边界且输入满足特定条件（独立性、实正主导极的正相关性或充分的相关性衰减）时，输出以 O(1/sqrt{t}) 的速率收敛到标准正态分布。

Conclusion: 该研究为“低通LTI系统的输出趋向于高斯分布”这一广泛观察提供了严格的理论基础。

Abstract: We study the asymptotic distribution of the output of a stable Linear
Time-Invariant (LTI) system driven by a non-Gaussian stochastic input.
Motivated by longstanding heuristics in the stochastic describing function
method, we rigorously characterize when the output process becomes
approximately Gaussian, even when the input is not. Using the Wasserstein-1
distance as a quantitative measure of non-Gaussianity, we derive upper bounds
on the distance between the appropriately scaled output and a standard normal
distribution. These bounds are obtained via Stein's method and depend
explicitly on the system's impulse response and the dependence structure of the
input process. We show that when the dominant pole of the system approaches the
edge of stability and the input satisfies one of the following conditions: (i)
independence, (ii) positive correlation with a real and positive dominant pole,
or (iii) sufficient correlation decay, the output converges to a standard
normal distribution at rate $O(1/\sqrt{t})$. We also present counterexamples
where convergence fails, thereby motivating the stated assumptions. Our results
provide a rigorous foundation for the widespread observation that outputs of
low-pass LTI systems tend to be approximately Gaussian.

</details>


### [258] [A Hierarchical Surrogate Model for Efficient Multi-Task Parameter Learning in Closed-Loop Contro](https://arxiv.org/abs/2508.12738)
*Sebastian Hirt,Lukas Theiner,Maik Pfefferkorn,Rolf Findeisen*

Main category: eess.SY

TL;DR: 提出一种分层贝叶斯优化框架，用于在不同任务中高效学习控制器参数，实现知识转移和多任务/迁移学习，并保证了与标准黑盒贝叶斯优化相当的次线性遗憾。


<details>
  <summary>Details</summary>
Motivation: 许多控制问题需要在不同的闭环任务中重复调整和适应控制器，其中数据效率和适应性至关重要。

Method: 提出了一种分层的贝叶斯优化（BO）框架，该框架利用高斯过程构建分层代理模型，捕获不同参数化下的闭环状态演变，并通过已知的闭式表达式精确计算任务特定的权重和累积。

Result: 与纯粹的黑盒贝叶斯优化方法相比，该方法在样本效率和适应性方面均有显著优势。

Conclusion: 该方法在样本效率和适应性方面均优于纯粹的黑盒贝叶斯优化方法。

Abstract: Many control problems require repeated tuning and adaptation of controllers
across distinct closed-loop tasks, where data efficiency and adaptability are
critical. We propose a hierarchical Bayesian optimization (BO) framework that
is tailored to efficient controller parameter learning in sequential
decision-making and control scenarios for distinct tasks. Instead of treating
the closed-loop cost as a black-box, our method exploits structural knowledge
of the underlying problem, consisting of a dynamical system, a control law, and
an associated closed-loop cost function. We construct a hierarchical surrogate
model using Gaussian processes that capture the closed-loop state evolution
under different parameterizations, while the task-specific weighting and
accumulation into the closed-loop cost are computed exactly via known
closed-form expressions. This allows knowledge transfer and enhanced data
efficiency between different closed-loop tasks. The proposed framework retains
sublinear regret guarantees on par with standard black-box BO, while enabling
multi-task or transfer learning. Simulation experiments with model predictive
control demonstrate substantial benefits in both sample efficiency and
adaptability when compared to purely black-box BO approaches.

</details>


### [259] [PFD or PDF: Rethinking the Probability of Failure in Mitigation Safety Functions](https://arxiv.org/abs/2508.12814)
*Hamid Jahanian*

Main category: eess.SY

TL;DR: 本论文认为PFD不适用于衡量缓解性安全功能，并提出了一种新的方法，使用PDF和预期失效程度作为关键指标，来评估风险系统的SIL。


<details>
  <summary>Details</summary>
Motivation: 现有研究在确定目标PFD和SIL方面做了大量工作，但对预防性安全功能（SFs）的关注多于对缓解性安全功能。然而，PFD并不是衡量缓解性SFs的合适可靠性指标。因此，有必要提出一种新的方法。

Method: 本研究提出了一种新的方法，使用失效概率密度函数（PDF）和预期的失效程度作为关键指标，来替代概率失效密度（PFD），以评估风险系统的安全完整性等级（SIL）。

Result: 通过详细的数学公式和案例研究，证明了新方法的有效性。

Conclusion: 论文提出了一种新的方法，使用失效概率密度函数（PDF）和预期的失效程度作为衡量指标，以替代PFD，用于评估风险系统的安全完整性等级（SIL）。

Abstract: SIL (Safety Integrity Level) allocation plays a crucial role in defining the
design requirements for Safety Functions (SFs) within high-risk industries. SIL
is typically determined based on the estimated Probability of Failure on Demand
(PFD), which must remain within permissible limits to manage risk effectively.
Extensive research has been conducted on determining target PFD and SIL, with a
stronger emphasis on preventive SFs than on mitigation SFs. In this paper, we
address a rather conceptual issue: we argue that PFD is not an appropriate
reliability measure for mitigation SFs to begin with, and we propose an
alternative approach that leverages the Probability Density Function (PDF) and
the expected degree of failure as key metrics. The principles underlying this
approach are explained and supported by detailed mathematical formulations.
Furthermore, the practical application of this new methodology is illustrated
through case studies.

</details>


### [260] [Grid Edge Intelligence-Assisted Model Predictive Framework for Black Start of Distribution Systems with Inverter-Based Resources](https://arxiv.org/abs/2508.12937)
*Junyuan Zheng,Salish Maharjan,Zhaoyu Wang*

Main category: eess.SY

TL;DR: 该研究提出了一种创新的黑启动框架，该框架利用电网边缘智能 (GEI) 和分布式能源资源 (DER)，以增强电网的弹性和可靠性，同时解决频率安全和同步约束。


<details>
  <summary>Details</summary>
Motivation: 解决现有黑启动策略忽略 BTM DER 的问题，并解决利用 GFM BESS 的策略中关键的频率安全和同步约束。

Method: 提出了一种利用 GEI 预测 BTM DER 的多周期灵活性范围并跟踪公用事业调度信号的预测模型。引入了一种明确考虑频率最低点、频率变化率 (RoCoF) 和准稳态 (QSS) 频率约束的频率约束黑启动策略。该框架还包括用于更快、更安全地恢复负载的同步开关。

Result: 使用修改后的 IEEE 123 节点测试系统对该框架进行了验证，并通过在各种 GEI 渗透场景下进行比较，展示了 GEI 的影响。

Conclusion: 该框架通过利用 BTM DER 的灵活性，为电网边缘智能 (GEI) 设备和公用事业公司提供了更安全、更高效的黑启动和恢复流程，同时解决了现有的频率安全和同步限制。

Abstract: The growing proliferation of distributed energy resources (DERs) is
significantly enhancing the resilience and reliability of distribution systems.
However, a substantial portion of behind-the-meter (BTM) DERs is often
overlooked during black start (BS) and restoration processes. Existing BS
strategies that utilize grid-forming (GFM) battery energy storage systems
(BESS) frequently ignore critical frequency security and synchronization
constraints. To address these limitations, this paper proposes a predictive
framework for bottom-up BS that leverages the flexibility of BTM DERs through
Grid Edge Intelligence (GEI). A predictive model is developed for GEI to
estimate multi-period flexibility ranges and track dispatch signals from the
utility. A frequency-constrained BS strategy is then introduced, explicitly
incorporating constraints on frequency nadir, rate-of-change-of-frequency
(RoCoF), and quasi-steady-state (QSS) frequency. The framework also includes
synchronizing switches to enable faster and more secure load restoration.
Notably, it requires GEI devices to communicate only their flexibility ranges
and the utility to send dispatch signals without exchanging detailed asset
information. The proposed framework is validated using a modified IEEE 123-bus
test system, and the impact of GEI is demonstrated by comparing results across
various GEI penetration scenarios.

</details>


### [261] [Revisiting Functional Derivatives in Multi-object Tracking](https://arxiv.org/abs/2508.12982)
*Jan Krejčí,Ondřej Straka,Petr Girg,Jiří Benedikt*

Main category: eess.SY

TL;DR: 该论文提出了泛函导数的新定义，解决了现有定义复杂的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于PGFLs的跟踪算法推导中使用的泛函导数定义复杂或启发式，利用了狄拉克δ“函数”。

Method: 通过比较不同泛函导数定义，并利用严谨的数学方法提出新定义，最后讨论其关键性质。

Result: 提出了泛函导数的新定义，并揭示了其关键性质。

Conclusion: 该论文提出了泛函导数的严谨定义，并揭示了其关键性质。

Abstract: Probability generating functionals (PGFLs) are efficient and powerful tools
for tracking independent objects in clutter. It was shown that PGFLs could be
used for the elegant derivation of practical multi-object tracking algorithms,
e.g., the probability hypothesis density (PHD) filter. However, derivations
using PGFLs use the so-called functional derivatives whose definitions usually
appear too complicated or heuristic, involving Dirac delta ``functions''. This
paper begins by comparing different definitions of functional derivatives and
exploring their relationships and implications for practical applications. It
then proposes a rigorous definition of the functional derivative, utilizing
straightforward yet precise mathematics for clarity. Key properties of the
functional derivative are revealed and discussed.

</details>


### [262] [Exploiting Convexity of Neural Networks in Dynamic Operating Envelope Optimization for Distributed Energy Resources](https://arxiv.org/abs/2508.13090)
*Hongyi Li,Liming Liu,Yunyi Li,Zhaoyu Wang*

Main category: eess.SY

TL;DR: 为了解决配电系统中动态运行包络（DOE）优化中非凸性导致的精度与效率问题，本研究利用输入凸神经网络（ICNN）的凸性，提出了一种约束嵌入和线性松弛方法，该方法在数值实验中显示出优于其他方法的性能。


<details>
  <summary>Details</summary>
Motivation: 分布式能源（DERs）的普及给配电系统运行带来了机遇和挑战，为了保证网络完整性，需要对DERs进行动态运行包络（DOE）管理，但传统DOE优化方法面临精度与效率的困境。

Method: 提出了一种约束嵌入方法，将非凸潮流约束替换为训练好的ICNN模型，从而将问题凸化；并提出一种ICNN的线性松弛方法，以提高求解效率，并从理论上证明了其紧密度。

Result: 数值案例研究表明，所提出的ICNN方法在优化DOE方面，无论是在解的质量还是求解时间上，均优于其他基准方法。

Conclusion: 该研究提出了一种基于输入凸神经网络（ICNN）的动态运行包络（DOE）优化方法，通过利用ICNN的凸性来解决传统方法中非凸性带来的精度与效率难题。

Abstract: The increasing penetration of distributed energy resources (DERs) brings
opportunities and challenges to the operation of distribution systems. To
ensure network integrity, dynamic operating envelopes (DOEs) are issued by
utilities to DERs as their time-varying export/import power limits. Due to the
non-convex nature of power flow equations, the optimization of DOEs faces a
dilemma of solution accuracy and computation efficiency. To bridge this gap, in
this paper, we facilitate DOE optimization by exploiting the convexity of input
convex neural networks (ICNNs). A DOE optimization model is first presented,
comprehensively considering multiple operational constraints. We propose a
constraint embedding method that allows us to replace the non-convex power flow
constraints with trained ICNN models and convexify the problem. To further
speed up DOE optimization, we propose a linear relaxation of the ICNN-based DOE
optimization problem, for which the tightness is theoretically proven. The
effectiveness of the proposed method is validated with numerical case studies.
Results show that the proposed ICNN-based method outperforms other benchmark
methods in optimizing DOEs in terms of both solution quality and solution time.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [263] [A Parameterized Perspective on Uniquely Restricted Matchings](https://arxiv.org/abs/2508.12004)
*Juhi Chaudhary,Ignasi Sau,Meirav Zehavi*

Main category: cs.DS

TL;DR: 本研究分析了唯一受限匹配问题的参数化复杂性，证明了在图线和树宽度参数下该问题是 FPT 的，并排除了在顶点覆盖数加匹配大小参数下的多项式核。


<details>
  <summary>Details</summary>
Motivation: 在图论中，匹配（matching）是图中不共享端点的边集。唯一受限匹配是指由匹配的边端点诱导的子图恰好只有一个完美匹配（perfect matching）。给定一个图 G 和一个正整数 ℓ，唯一受限匹配问题询问 G 是否存在一个大小至少为 ℓ 的唯一受限匹配。

Method: 本文研究了唯一受限匹配（Uniquely Restricted Matching）在各种参数下的参数化复杂性。

Result: 研究表明，在图线（line graph）上，当参数化为解的大小（solution size）时，唯一受限匹配（Uniquely Restricted Matching）存在一个固定参数可处理（FPT）算法。此外，当参数化为输入图的树宽度（treewidth）时，该问题也是 FPT 的。研究还证明，相对于顶点覆盖数加上匹配的大小，该问题不存在多项式核。

Conclusion: 该研究表明，在图线（line graph）上，当参数化为解的大小（solution size）时，唯一受限匹配（Uniquely Restricted Matching）存在一个固定参数可处理（FPT）算法。此外，当参数化为输入图的树宽度（treewidth）时，该问题也是FPT的。研究还证明，除非 NP 
subseteq coNP/poly，否则该问题相对于顶点覆盖数（vertex cover number）加上匹配的大小（size of the matching）不存在多项式核（polynomial kernel）。

Abstract: Given a graph G, a matching is a subset of edges of G that do not share an
endpoint. A matching M is uniquely restricted if the subgraph induced by the
endpoints of the edges of M has exactly one perfect matching. Given a graph G
and a positive integer \ell, Uniquely Restricted Matching asks whether G has a
uniquely restricted matching of size at least \ell. In this paper, we study the
parameterized complexity of Uniquely Restricted Matching under various
parameters. Specifically, we show that Uniquely Restricted Matching admits a
fixed-parameter tractable (FPT) algorithm on line graphs when parameterized by
the solution size. We also establish that the problem is FPT when parameterized
by the treewidth of the input graph. Furthermore, we show that Uniquely
Restricted Matching does not admit a polynomial kernel with respect to the
vertex cover number plus the size of the matching unless NP \subseteq
coNP/poly.

</details>


### [264] [A Polylogarithmic Algorithm for Stochastic Online Sorting](https://arxiv.org/abs/2508.12527)
*Dimitris Fotakis,Andreas Kalavas,Charalampos Platanos,Thanos Tolias*

Main category: cs.DS

TL;DR: 该论文提出了一个适用于随机在线排序问题的 $O(\log^{2} n)$-竞争算法，比先前算法有显著提升，并且该算法也适用于随机在线旅行商问题。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在改进随机在线排序问题的竞争算法，并将其推广到多维度的随机在线旅行商问题，以期在这些在线问题中获得更强的性能保证。

Method: 提出了一种新的算法方法，能够为随机在线排序问题提供 $O(\log^{2} n)$-竞争比，并成功应用于随机在线旅行商问题。

Result: 成功设计了一个 $O(\log^{2} n)$-竞争算法，在随机在线排序问题上实现了指数级的性能提升，并将其扩展到了随机在线旅行商问题。

Conclusion: 该研究为随机在线排序问题提供了一个 $O(\log^{2} n)$-竞争算法，该算法能够以大概率成功，相比于 Abrahamsen 等人（ESA 2024）的 $\widetilde{O}(n^{1/4})$ 绑定，实现了指数级的改进。此外，该方法还可以扩展到固定维度 $d$ 的随机在线旅行商问题，并实现 $O(\log^2 n)$-竞争比。

Abstract: In the \emph{Online Sorting Problem}, an array of $n$ initially empty cells
is given. At each time step $t$, a real number $x_t \in [0,1]$ arrives and must
be placed immediately and irrevocably into an empty cell. The objective is to
minimize the sum of absolute differences between consecutive entries. The
problem was introduced by Aamand, Abrahamsen, Beretta, and Kleist (SODA 2023)
as a technical tool for proving lower bounds in online geometric packing
problems. In follow-up work, Abrahamsen, Bercea, Beretta, Klausen, and Kozma
(ESA 2024) studied the \emph{Stochastic Online Sorting Problem}, where each
$x_t$ is drawn i.i.d.\ from $\mathcal{U}(0,1)$, and presented a
$\widetilde{O}(n^{1/4})$-competitive algorithm, showing that stochastic input
enables much stronger guarantees than in the adversarial setting. They also
introduced the \emph{Online Travelling Salesperson Problem (TSP)} as a
multidimensional generalization. More recently, Hu, independently and in
parallel, obtained a $\log n \cdot 2^{O(\log^* n)}$-competitive algorithm
together with a logarithmic lower bound for the \emph{Stochastic Online Sorting
Problem}.
  We give an $O(\log^{2} n)$-competitive algorithm for the \emph{Stochastic
Online Sorting Problem} that succeeds w.h.p., achieving an exponential
improvement over the $\widetilde{O}(n^{1/4})$ bound of Abrahamsen et al.(ESA
2024). Our approach further extends to the \emph{Stochastic Online TSP} in
fixed dimension $d$, where it achieves an $O(\log^2 n)$-competitive ratio.

</details>


### [265] [r*-indexing](https://arxiv.org/abs/2508.12675)
*Travis Gagie*

Main category: cs.DS

TL;DR: 论文提出一种文本压缩存储方案，能在压缩存储T（利用BWT和LZ77）的同时，快速（O(m log n + occ log^ε n)）查找模式P的全部出现位置。


<details>
  <summary>Details</summary>
Motivation: 为了在压缩存储的同时，实现对文本中模式串的快速查找。

Method: 通过存储T的Burrows-Wheeler变换及其反转（包含r*个runs），以及T的LZ77解析（包含z个短语），利用O(r* log(n/r*) + z log n)比特的存储空间。

Result: 在O(r* log(n/r*) + z log n)比特的存储空间下，可以在O(m log n + occ log^ε n)的时间内报告模式P的occ次出现的位置，并且可以在O(m log^ε n)的时间内报告P的左右边界出现位置。 



Conclusion: 该论文提出了一种压缩文本T的方法，并能在特定时间内报告模式P在T中的所有出现位置，以及最左边和最右边出现的位置。

Abstract: Let $T [1..n]$ be a text over an alphabet of size $\sigma \in
\mathrm{polylog} (n)$, let $r^*$ be the sum of the numbers of runs in the
Burrows-Wheeler Transforms of $T$ and its reverse, and let $z$ be the number of
phrases in the LZ77 parse of $T$. We show how to store $T$ in $O (r^* \log (n /
r^*) + z \log n)$ bits such that, given a pattern $P [1..m]$, we can report the
locations of the $\mathrm{occ}$ occurrences of $P$ in $T$ in $O (m \log n +
\mathrm{occ} \log^\epsilon n)$ time. We can also report the position of the
leftmost and rightmost occurrences of $P$ in $T$ in the same space and $O (m
\log^\epsilon n)$ time.

</details>


### [266] [Weighted Partition Vertex and Edge Cover](https://arxiv.org/abs/2508.13055)
*Rajni Dabas,Samir Khuller,Emilie Rivkin*

Main category: cs.DS

TL;DR: 本文针对具有群体覆盖约束的顶点覆盖和边覆盖问题，提出了改进的近似算法和精确算法，并对其中一个变体问题的NP-完备性进行了证明。


<details>
  <summary>Details</summary>
Motivation: 本文旨在研究经典顶点覆盖和边覆盖问题的推广，这些问题具有群体覆盖约束。具体来说，本文关注加权奖金收集划分顶点覆盖（WP-PVC）和加权划分边覆盖（W-PEC）问题，并寻求更优的算法和对NP-完备性的理解。

Method: 本文提出了两种用于WP-PVC问题的算法：一种是2近似算法，通过求解n^ω个线性规划（LP）实现；另一种是双标准算法，适用于ω较大的情况。对于W-PEC问题，本文提出了首个精确的多项式时间算法，并将运行时间从O（ωn^3）改进到O（mn+n^2 log n）。此外，本文还通过从背包问题进行归约，证明了W-PEC奖金收集变体的NP-完备性。

Result: WP-PVC问题的2近似算法改进了先前的工作，去除了枚举步骤和额外的ε因子，并扩展到加权设置。对于ω较大的情况，双标准算法近似满足了利润目标并限制了LP相对成本。W-PEC问题的精确多项式时间算法将运行时间从O（ωn^3）减少到O（mn+n^2 log n），并简化了算法结构。W-PEC奖金收集变体被证明是NP-完全的。

Conclusion: 本文研究了具有群体覆盖约束的经典顶点覆盖和边覆盖问题的推广。对于加权奖金收集划分顶点覆盖（WP-PVC）问题，我们提出了一个简单的2近似算法，该算法通过求解n^ω个线性规划（LP）来改进先前的工作，并且还扩展到了加权设置。对于ω较大的情况，我们设计了一个双标准算法。对于加权划分边覆盖（W-PEC）问题，我们提出了首个精确的多项式时间算法，将运行时间从O（ωn^3）改进到O（mn+n^2 log n），并简化了算法结构。此外，我们还证明了W-PEC奖金收集变体的NP-完备性。

Abstract: We study generalizations of the classical Vertex Cover and Edge Cover
problems that incorporate group-wise coverage constraints. Our first focus is
the \emph{Weighted Prize-Collecting Partition Vertex Cover} (WP-PVC) problem:
given a graph with weights on both vertices and edges, and a partition of the
edge set into $\omega$ groups, the goal is to select a minimum-weight subset of
vertices such that, in each group, the total weight (profit) of covered edges
meets a specified threshold. This formulation generalizes classical vertex
cover, partial vertex cover and partition vertex cover.
  We present two algorithms for WP-PVC. The first is a simple 2-approximation
that solves \( n^{\omega} \) LP's, improving over prior work by Bandyapadhyay
et al.\ by removing an enumerative step and the extra \( \epsilon \)-factor in
approximation, while also extending to the weighted setting. The second is a
bi-criteria algorithm that applies when \( \omega \) is large, approximately
meeting profit targets with a bounded LP-relative cost.
  We also study a natural generalization of the edge cover problem, the
\emph{Weighted Partition Edge Cover} (W-PEC) problem, where each edge has an
associated weights, and the vertex set is partitioned into groups. For each
group, the goal is to cover at least a specified number of vertices using
incident edges, while minimizing the total weight of the selected edges. We
present the first exact polynomial-time algorithm for the weighted case,
improving runtime from \( O(\omega n^3) \) to \( O(mn+n^2 \log n) \) and
simplifying the algorithmic structure over prior unweighted approaches. We also
show that the prize-collecting variant of the W-PEC problem is NP-Complete via
a reduction from the knapsack problem.

</details>


### [267] [A simple analysis of a quantum-inspired algorithm for solving low-rank linear systems](https://arxiv.org/abs/2508.13108)
*Tyler Chen,Junhyung Lyle Kim,Archan Ray,Shouvanik Chakrabarti,Dylan Herman,Niraj Kumar*

Main category: cs.DS

TL;DR: 提出了一种从线性系统Ax=b的解中采样的算法，该算法使用采样器按A的平方行/列范数抽取索引，并能生成一个压缩表示，用于查询条目和按平方条目进行采样。


<details>
  <summary>Details</summary>
Motivation: 描述并分析了一种从线性系统Ax=b的解x* = A+b中进行采样的简单算法。

Method: 提出了一种简单算法，利用访问采样器（可按A的平方行/列范数抽取索引）来从线性系统Ax=b的解x* = A+b中采样。

Result: 该算法生成的x的压缩表示允许在O(κ_F^2)的时间内查询x的条目，并在O(κ_F^4 κ^6)的时间内按x的平方条目进行采样。

Conclusion: 该算法能够以O(κ_F^4 κ^2 / ε^2)的时间复杂度生成一个压缩表示，使得||x* - x|| < ε ||x*||，其中x*是线性系统Ax=b的解。

Abstract: We describe and analyze a simple algorithm for sampling from the solution
$\mathbf{x}^* := \mathbf{A}^+\mathbf{b}$ to a linear system
$\mathbf{A}\mathbf{x} = \mathbf{b}$. We assume access to a sampler which allows
us to draw indices proportional to the squared row/column-norms of
$\mathbf{A}$. Our algorithm produces a compressed representation of some vector
$\mathbf{x}$ for which $\|\mathbf{x}^* - \mathbf{x}\| < \varepsilon
\|\mathbf{x}^* \|$ in $\widetilde{O}(\kappa_{\mathsf{F}}^4 \kappa^2 /
\varepsilon^2)$ time, where $\kappa_{\mathsf{F}} :=
\|\mathbf{A}\|_{\mathsf{F}}\|\mathbf{A}^{+}\|$ and $\kappa :=
\|\mathbf{A}\|\|\mathbf{A}^{+}\|$. The representation of $\mathbf{x}$ allows us
to query entries of $\mathbf{x}$ in $\widetilde{O}(\kappa_{\mathsf{F}}^2)$ time
and sample proportional to the square entries of $\mathbf{x}$ in
$\widetilde{O}(\kappa_{\mathsf{F}}^4 \kappa^6)$ time, assuming access to a
sampler which allows us to draw indices proportional to the squared entries of
any given row of $\mathbf{A}$. Our analysis, which is elementary,
non-asymptotic, and fully self-contained, simplifies and clarifies several past
analyses from literature including [Gily\'en, Song, and Tang; 2022, 2023] and
[Shao and Montanaro; 2022].

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [268] [Lessons from Chalcopyrites for Scaling Thin Film Perovskite Photovoltaic Technology](https://arxiv.org/abs/2508.11638)
*Mirjana Dimitrievska,Edgardo Saucedo,Stefaan De Wolf,Billy J. Stanbery,Veronica Bermudez Benito*

Main category: physics.app-ph

TL;DR: CIGS commercialization challenges offer lessons for perovskite solar cells to ensure a more stable and deliberate path to market.


<details>
  <summary>Details</summary>
Motivation: To provide insights into the commercialization of perovskite solar cells by examining the lessons learned from the development of CIGS solar cells, addressing challenges like long-term stability and scalable architectures.

Method: This paper analyzes the commercialization process of thin-film solar cells, using CIGS as a case study to inform the trajectory of perovskite solar cells.

Result: The paper revisits the CIGS experience as a blueprint for perovskite PV, suggesting that learning from past thin-film PV development is crucial for the successful commercialization of perovskites.

Conclusion: Perovskite solar cells' future depends on learning from CIGS's successes and failures to avoid repeating past mistakes in thin-film PV commercialization.

Abstract: The growing demand for photovoltaic (PV) technologies that are lightweight,
flexible, and seamlessly integrated into diverse applications has propelled
interest in thin-film solar cells. Among these, Cu(In,Ga)(S,Se)2 (CIGS) and
metal halide perovskites have garnered significant attention in the past and
present, respectively. While CIGS reached commercial readiness after decades of
refinement, their large-scale deployment was hindered by manufacturing
complexity, scale-up challenges, and a lack of coordination between materials,
device design, and production systems. Perovskite solar cells, despite setting
record efficiencies at an unprecedented pace, now face similar challenges on
their path to commercialization: ensuring long-term stability, translating
laboratory performance to scalable architectures, and aligning with industrial
realities. In this perspective, we revisit the CIGS experience not as a
benchmark, but as a blueprint, highlighting how its successes and failures can
inform a more deliberate and durable trajectory for perovskite PV. Bridging
this historical perspective with the current frontier, we propose that the
future of perovskites depends not only on continued innovation, but on learning
from past thin-film PV experience to avoid its repetition.

</details>


### [269] [Synchronous polarization switching at sub-coercive fields through stochastic resonance in ferroelectric thin-film capacitors](https://arxiv.org/abs/2508.12017)
*Vivek Dey,Thejas Basavarajappa,Manikantan R. S.,Kevin Renji Jacob,Jonnalagadda Nikhila,Arvind Ajoy,Pavan Nukala*

Main category: physics.app-ph

TL;DR: Stochastic resonance (SR) enables synchronous polarization switching in ferroelectric PZT capacitors, matching theoretical predictions. This phenomenon was used to create a proof-of-concept system for detecting sub-threshold frequency-shift-key signals in noisy communication channels.


<details>
  <summary>Details</summary>
Motivation: The paper aims to demonstrate and utilize stochastic resonance (SR) in ferroelectric systems for applications like signal detection. Specifically, it explores achieving synchronous polarization switching in PZT capacitors via SR and applying this to detect sub-threshold signals in noisy communication channels.

Method: SR phenomena were investigated in PZT capacitors using sub-coercive voltage waveforms. Figures of merit such as cross-covariance, output power, and signal-to-noise ratio were used to determine optimal noise levels. The Kramers time was experimentally measured and compared to SR conditions. The device characteristics were modeled using the stochastic TDGL formulation.

Result: The study successfully demonstrated synchronous polarization switching in PZT capacitors through SR, with experimental results matching theoretical predictions (Kramers rate = 2 * drive frequency). The developed system showed potential for detecting sub-threshold FSK signals in noisy environments.

Conclusion: SR phenomena were used to demonstrate synchronous polarization switching in PZT capacitors, with experimental results aligning with theoretical predictions. A proof-of-concept FSK signal detection system was also developed.

Abstract: Stochastic resonance (SR) is a phenomenon by which the presence of noise in a
non-linear system allows for detection of a weak sub-threshold signal, or in a
bi-stable system allows for sub-coercive switching between the two states.
Simple theory suggests that SR occurs when the Kramers rate (rk) of the
bistable system, which is a function of noise and applied voltage, is twice the
drive frequency (fsignal). Here, we demonstrate the synchronous switching of
polarization with a sub-coercive voltage waveform, in a thin film ferroelectric
lead zirconium titanate (PZT) capacitor through SR. We employ independent
figures of merit (FOM) such as cross-covariance, output power and
signal-to-noise ratio to experimentally identify the optimal noise for
synchronous switching. We further experimentally measure the Kramers time in
the ferroelectric, and show that FOMs indeed peak near the noise predicted by
the SR condition. We also model the device characteristics using the stochastic
Time Dependent Landau Ginzburg (TDGL) formulation, and capture the
experimentally observed polarization switching under application of
sub-coercive voltage, assisted by noise. Finally, we show a proof-of-concept
implementation of detecting sub-threshold frequency-shift-key signals (FSK) in
noisy communication channels using our ferroelectric PZT devices.

</details>


### [270] [From plasma to pattern: observation and characterization of periodic structure formation in dielectric breakdown channels of electron-irradiated insulators](https://arxiv.org/abs/2508.12592)
*Nick R. Schwartz,Bryson C. Clifford,Carolyn Chun,Emily H. Frashure,Kathryn M. Sturge,Noah Hoppis,Holly Wilson,Meryl Wiratmo,Jack R. FitzGibbon,Ethan T. Basinger,Brian L. Beaudoin,Raymond J. Phaneuf,John Cumings,Timothy W. Koeth*

Main category: physics.app-ph

TL;DR: Periodic structures in dielectric breakdown channels of PMMA are caused by the z-pinch entropy mode during plasma discharge, not later processes. This finding helps understand insulator failure in harsh environments.


<details>
  <summary>Details</summary>
Motivation: The mechanics of dielectric breakdown in insulators, a common failure mode in space electronics exposed to high radiation, remain poorly understood. The periodic structures observed in the recently identified ivy-mode breakdown channels in electron-irradiated PMMA offer a unique opportunity to study ultra-fast dielectric breakdown physics.

Method: Materials characterization (Raman spectroscopy) and theoretical modeling were used to analyze electron-irradiated PMMA undergoing breakdown. Three candidate instability mechanisms (Asaro-Tiller-Grinfeld, Plateau-Rayleigh, z-pinch entropy mode) were evaluated against experimental observations.

Result: The z-pinch entropy mode was identified as the instability mechanism responsible for the periodic structures (~80 μm wavelength) in the breakdown channels. This mode operates during the nanosecond discharge phase with plasma densities of 0.1-1% of solid density and temperatures of 10-100 eV, consistent with current measurements from isolated discharge channels.

Conclusion: Dielectric breakdown of insulators is governed by the entropy mode plasma instability during the discharge phase, not post-discharge thermal or mechanical processes. This provides insights into dielectric breakdown physics and a framework for predicting discharge morphology.

Abstract: Dielectric breakdown of insulators is one of the most common failure modes of
electronics in the high-radiation environment of space, but its mechanics
remain poorly understood. When electron-irradiated polymethyl methacrylate
(PMMA) undergoes breakdown, the resulting channels exhibit striking periodic
structures with characteristic wavelengths ~80 {\mu}m in the recently
identified ivy-mode channels. These previously unobserved modulations offer
unique insights into the physics of ultra-fast dielectric breakdown. Through
materials characterization and theoretical modeling, we identify the physical
instability mechanism responsible for these structures. Raman spectroscopy
reveals that carbon deposition correlates with channel width variations,
indicating that periodic structure formation occurs during the plasma discharge
phase. We evaluated three candidate instability mechanisms: the
Asaro-Tiller-Grinfeld instability, the Plateau-Rayleigh instability, and the
z-pinch entropy mode. The first two mechanisms operate on incompatible
timescales and require unphysical material parameters to match observations. In
contrast, the z-pinch entropy mode operates during the nanosecond discharge
phase and produces wavelengths consistent with plasma densities of 0.1-1% of
solid density and temperatures of 10-100 eV. Current measurements from isolated
discharge channels (~200 A) validate theoretical predictions for the entropy
mode. These findings establish that the entropy mode plasma instability during
the discharge phase, rather than post discharge thermal or mechanical
processes, govern periodic structure formation in breakdown channels. This work
provides new insights into the physics of dielectric breakdown and establishes
a framework for predicting discharge morphology and characteristics in
insulators.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [271] [Proceedings 18th Interaction and Concurrency Experience](https://arxiv.org/abs/2508.12308)
*Clément Aubert,Cinzia Di Giusto,Simon Fowler,Violet Ka I Pun*

Main category: cs.DC

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This volume contains the proceedings of ICE'25, the 18th Interaction and
Concurrency Experience, which was held on Friday 20th June 2025 at the \'Ecole
National Sup\'erieure des Arts et M\'etiers in Lille, France, as a satellite
workshop of DisCoTec 2025. The ICE workshop series features a distinguishing
review and selection procedure: PC members are encouraged to interact,
anonymously, with authors. The 2025 edition of ICE received 7 submissions, each
reviewed by three PC members, and about 75 comments were exchanged during the
review process, witnessing very lively discussions. Four papers were accepted
for publication plus 1 oral communication, which was accepted for presentation
at the workshop. We were proud to host one invited talk, by Kirstin Peters. The
abstract of her talk is included in this volume, together with the final
versions of the research papers, which take into account the discussion at the
workshop and during the review process.

</details>


### [272] [Breaking the Aggregation Bottleneck in Federated Recommendation: A Personalized Model Merging Approach](https://arxiv.org/abs/2508.12386)
*Jundong Chen,Honglei Zhang,Chunxu Zhang,Fangyuan Luo,Yidong Li*

Main category: cs.DC

TL;DR: FederatedEM 解决了联邦推荐中的聚合瓶颈问题，通过融合全局和本地模型来提高个性化，并在实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 证明了服务器端聚合会破坏客户端个性化，从而导致次优性能，即“聚合瓶颈”，这是由于 FR 中众多客户端的固有异质性所致。

Method: 提出了一种名为 FederatedEM 的方法，该方法通过弹性融合全局和本地模型来补偿受损的个性化。

Result: FederatedEM 在真实世界数据集的广泛实验中，保留了客户端个性化，并优于最先进的基线。

Conclusion: FederatedEM 通过弹性融合全局和本地模型来补偿受损的个性化，在真实世界数据集的广泛实验中，证明了其在保留客户端个性化方面的有效性，并优于最先进的基线。

Abstract: Federated recommendation (FR) facilitates collaborative training by
aggregating local models from massive devices, enabling client-specific
personalization while ensuring privacy. However, we empirically and
theoretically demonstrate that server-side aggregation can undermine
client-side personalization, leading to suboptimal performance, which we term
the aggregation bottleneck. This issue stems from the inherent heterogeneity
across numerous clients in FR, which drives the globally aggregated model to
deviate from local optima. To this end, we propose FedEM, which elastically
merges the global and local models to compensate for impaired personalization.
Unlike existing personalized federated recommendation (pFR) methods, FedEM (1)
investigates the aggregation bottleneck in FR through theoretical insights,
rather than relying on heuristic analysis; (2) leverages off-the-shelf local
models rather than designing additional mechanisms to boost personalization.
Extensive experiments on real-world datasets demonstrate that our method
preserves client personalization during collaborative training, outperforming
state-of-the-art baselines.

</details>


### [273] [DIT: Dimension Reduction View on Optimal NFT Rarity Meters](https://arxiv.org/abs/2508.12671)
*Dmitry Belousov,Yury Yanovich*

Main category: cs.DC

TL;DR: 本研究提出了一种名为DIT的新型NFT稀有度评估方法，该方法通过降维技术设计，并在ROAR基准上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有NFT稀有度评估方法在比较时存在挑战，因为它们缺乏对底层集合数据的直接访问。本研究旨在解决此问题，提供一个标准化的NFT稀有度评估框架。

Method: 本研究采用降维技术来设计稀有度计量器，并利用ROAR基准来评估其性能。

Result: 研究开发了一种使用非度量加权多维标度法的最佳稀有度计量器设计，并引入了交易失比（DIT）作为性能衡量指标。DIT在ROAR基准上的表现优于现有方法。

Conclusion: 本研究提出了一种基于降维技术的最佳稀有度计量器设计，并引入了一种名为交易失比（DIT）的新性能衡量指标，该指标表现优于现有方法。

Abstract: Non-fungible tokens (NFTs) have become a significant digital asset class,
each uniquely representing virtual entities such as artworks. These tokens are
stored in collections within smart contracts and are actively traded across
platforms on Ethereum, Bitcoin, and Solana blockchains. The value of NFTs is
closely tied to their distinctive characteristics that define rarity, leading
to a growing interest in quantifying rarity within both industry and academia.
While there are existing rarity meters for assessing NFT rarity, comparing them
can be challenging without direct access to the underlying collection data. The
Rating over all Rarities (ROAR) benchmark addresses this challenge by providing
a standardized framework for evaluating NFT rarity. This paper explores a
dimension reduction approach to rarity design, introducing new performance
measures and meters, and evaluates them using the ROAR benchmark. Our
contributions to the rarity meter design issue include developing an optimal
rarity meter design using non-metric weighted multidimensional scaling,
introducing Dissimilarity in Trades (DIT) as a performance measure inspired by
dimension reduction techniques, and unveiling the non-interpretable rarity
meter DIT, which demonstrates superior performance compared to existing
methods.

</details>


### [274] [Dissecting CPU-GPU Unified Physical Memory on AMD MI300A APUs](https://arxiv.org/abs/2508.12743)
*Jacob Wahlgren,Gabin Schieffer,Ruimin Shi,Edgar A. León,Roger Pearce,Maya Gokhale,Ivy Peng*

Main category: cs.DC

TL;DR: AMD MI300A APU首次在HPC系统中实现了集成的CPU和GPU以及统一物理内存（UPM）。本研究对MI300A上的UPM架构进行了全面的性能分析，评估了内存子系统和系统软件的效率，并提出了针对性的应用程序改造策略。结果显示，UPM在内存成本和性能方面均优于传统的显式内存管理模式。


<details>
  <summary>Details</summary>
Motivation: 介绍性地指出了离散GPU在HPC和数据中心系统中的核心作用，以及UVM在简化内存管理方面的局限性（性能成本高）。强调了AMD MI300A APU的出现，它首次为HPC系统带来了集成的CPU和GPU以及统一物理内存（UPM），为本研究提供了新的方向。

Method: 对MI300A上的UPM架构进行了全面的特性分析，包括内存延迟、带宽和一致性开销。还评估了系统软件在内存分配、页面错误处理、TLB管理和Infinity Cache利用方面的效率。

Result: UPM上的应用程序可以匹配或优于显式管理模型的应用程序，同时将内存成本降低高达44%。

Conclusion: 该研究提出了用于转换应用程序以适应UPM架构的端口策略，并在MI300A APU上评估了六个应用程序。结果表明，使用统一内存模型的UPM上的应用程序可以匹配或优于显式管理模型的应用程序，同时将内存成本降低高达44%。

Abstract: Discrete GPUs are a cornerstone of HPC and data center systems, requiring
management of separate CPU and GPU memory spaces. Unified Virtual Memory (UVM)
has been proposed to ease the burden of memory management; however, at a high
cost in performance. The recent introduction of AMD's MI300A Accelerated
Processing Units (APUs)--as deployed in the El Capitan supercomputer--enables
HPC systems featuring integrated CPU and GPU with Unified Physical Memory (UPM)
for the first time. This work presents the first comprehensive characterization
of the UPM architecture on MI300A. We first analyze the UPM system properties,
including memory latency, bandwidth, and coherence overhead. We then assess the
efficiency of the system software in memory allocation, page fault handling,
TLB management, and Infinity Cache utilization. We propose a set of porting
strategies for transforming applications for the UPM architecture and evaluate
six applications on the MI300A APU. Our results show that applications on UPM
using the unified memory model can match or outperform those in the explicitly
managed model--while reducing memory costs by up to 44%.

</details>


### [275] [Accelerating Edge Inference for Distributed MoE Models with Latency-Optimized Expert Placement](https://arxiv.org/abs/2508.12851)
*Tian Wu,Liming Wang,Zijian Wen,Xiaoxi Zhang,Jingpu Duan,Xianwei Zhang,Jinhang Zuo*

Main category: cs.DC

TL;DR: DanceMoE是一个高效的MoE推理框架，通过激活感知的专家放置，在异构的GPU边缘服务器上实现协作推理，从而降低延迟和通信成本。


<details>
  <summary>Details</summary>
Motivation: 为了解决大规模语言模型（LLMs）在资源受限的边缘环境中服务时面临的挑战，如大的内存占用和复杂的通信需求，以及中心化云推理的高成本、延迟和隐私问题。

Method: DanceMoE框架通过利用MoE模型的固有稀疏性和工作负载局部性，最小化跨服务器通信，并在异构资源约束下实现有效的专家放置。该框架引入了一个数据驱动的、激活感知的放置算法，以平衡服务器之间的本地覆盖率和内存使用量，并结合一个轻量级的迁移机制来适应不断变化的工作负载。

Result: 与最先进的基线相比，DanceMoE能够实现高达30.6%的推理延迟降低和显著的通信量减少。

Conclusion: DanceMoE框架在现代MoE模型和常用数据集上的评估结果显示，其推理延迟最多可降低30.6%，通信量显著减少，证明了基于协作边缘的MoE推理的有效性。

Abstract: Mixture-of-Experts (MoE) have become a cornerstone for training and scaling
large language models (LLMs), offering substantial gains in model capacity and
efficiency through sparse expert activation. However, serving these models
remains challenging in practice, particularly in resource-constrained edge
environments, due to their large memory footprint and complex communication
demands. While centralized cloud inference is common, it incurs high
infrastructure costs, along with latency and privacy concerns. A few recent
edge MoE works propose memory-efficient strategies but typically focus on
single-device or homogeneous setups. This paper presents DanceMoE, an efficient
MoE inference framework that enables activation-aware expert placement across
collaborative, heterogeneous, GPU-equipped edge servers. DanceMoE leverages the
inherent sparsity of MoE models and workload locality to minimize cross-server
communication and enable efficient expert placement under heterogeneous
resource constraints. It introduces a data-driven, activation-aware placement
algorithm that balances local coverage and memory usage across servers,
alongside a lightweight migration mechanism that adapts expert assignments
under evolving workloads. We evaluate DanceMoE on modern MoE models and widely
used datasets, demonstrating up to 30.6\% lower inference latency, and
substantial communication reduction compared to state-of-the-art baselines,
showcasing the effectiveness of collaborative edge-based MoE inference.

</details>


### [276] [WANify: Gauging and Balancing Runtime WAN Bandwidth for Geo-distributed Data Analytics](https://arxiv.org/abs/2508.12961)
*Anshuman Das Mohapatra,Kwangsung Oh*

Main category: cs.DC

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Accurate wide area network (WAN) bandwidth (BW) is essential for
geo-distributed data analytics (GDA) systems to make optimal decisions such as
data and task placement to improve performance. Existing GDA systems, however,
measure WAN BW statically and independently between data centers (DCs), while
data transfer occurs dynamically and simultaneously among DCs during workload
execution. Also, they use a single connection WAN BW that cannot capture actual
WAN capacities between distant DCs. Such inaccurate WAN BWs yield sub-optimal
decisions, inflating overall query latency and cost. In this paper, we present
WANify, a new framework that precisely and dynamically gauges achievable
runtime WAN BW using a machine learning prediction scheme, decision tree-based
Random Forest. This helps GDA systems make better decisions yielding reduced
latency and costs including WAN BW monitoring costs. Based on predicted runtime
WAN BW, WANify determines the optimal number of heterogeneous parallel
connections for data transfer among DCs. This approach improves performance
without additional, or even at reduced cost, by fully exploiting available WAN
capacities. In addition, WANify considers dynamics like network and workloads,
and heterogeneity like skewed data, heterogeneous compute resources, and a
varying number of DCs while making decisions. The WANify prototype running on
state-of-the-art GDA systems is evaluated on AWS with 8 geo-distributed DCs.
Results show that WANify enhances WAN throughput by balancing between the
strongest and weakest WAN links, enabling GDA systems to reduce latency and
cost by up to 26% and 16% respectively with minimal effort, all while handling
dynamics and heterogeneity efficiently.

</details>


### [277] [Congested Clique Counting for Local Gibbs Distributions](https://arxiv.org/abs/2508.13083)
*Joshua Z. Sobel*

Main category: cs.DC

TL;DR: 在拥塞连通模型中，我们首次实现了图 q-着色和吉布斯分布配分函数的近似计数。对于 q-着色（q > 2Δ），算法能在 O(n^(1/3) / ε^2) 回合内完成。对于硬核模型，则有 O(1 / ε^2) 回合算法。


<details>
  <summary>Details</summary>
Motivation: 在拥塞连通模型中实现近似计数，特别是针对图的 q-着色问题和统计物理、机器学习中广泛使用的吉布斯分布配分函数进行计数，以解决大规模分布式环境下的计数难题。

Method: 本文通过一个并行算法，利用组合采样与计数问题之间的已知归约关系，并借鉴了三角形计数和半环矩阵乘法的思想，提出了一种在拥塞连通模型中并行抽取马尔可夫链随机样本的算法。

Result: 提出了在拥塞连通模型中近似计算图 q-着色数量的算法，当 q > αΔ (α > 2) 时，能在 O(n^(1/3) / ε^2) 回合内完成。同时，对于满足特定条件的吉布斯分布配分函数，也实现了 O(n^(1/3) / ε^2) 回合的近似计数。对于硬核模型（加权独立集计数），取得了更优的 O(1 / ε^2) 回合算法。

Conclusion: 该研究首次提出了在拥塞连通模型（Congested Clique）中对一系列问题进行近似计数的方法，特别是为 q-着色问题和吉布斯分布配分函数提供了高效的近似计数算法。

Abstract: There are well established reductions between combinatorial sampling and
counting problems (Jerrum, Valiant, Vazirani TCS 1986). Building off of a very
recent parallel algorithm utilizing this connection (Liu, Yin, Zhang arxiv
2024), we demonstrate the first approximate counting algorithm in the
CongestedClique for a wide range of problems. Most interestingly, we present an
algorithm for approximating the number of $q$-colorings of a graph within
$\epsilon$-multiplicative error, when $q>\alpha\Delta$ for any constant
$\alpha>2$, in $\Tilde{O}\big(\frac{n^{1/3}}{\epsilon^2}\big)$ rounds. More
generally, we achieve a runtime of
$\Tilde{O}\big(\frac{n^{1/3}}{\epsilon^2}\big)$ rounds for approximating the
partition function of Gibbs distributions defined over graphs when simple
locality and fast mixing conditions hold. Gibbs distributions are widely used
in fields such as machine learning and statistical physics. We obtain our
result by providing an algorithm to draw $n$ random samples from a distributed
Markov chain in parallel, using similar ideas to triangle counting (Dolev,
Lenzen, Peled DISC 2012) and semiring matrix multiplication (Censor-Hillel,
Kaski, Korhonen, Lenzen, Paz, Suomela PODC 2015). Aside from counting problems,
this result may be interesting for other applications requiring a large number
of samples. In the special case of estimating the partition function of the
hardcore model, also known as counting weighted independent sets, we can do
even better and achieve an $\Tilde{O}\big(\frac{1}{\epsilon^2}\big)$ round
algorithm, when the fugacity $\lambda \leq \frac{\alpha}{\Delta-1}$, where
$\alpha$ is an arbitrary constant less than $1$.

</details>


### [278] [Team Formation and Applications](https://arxiv.org/abs/2508.13084)
*Yuval Emek,Shay Kutten,Ido Rafael,Gadi Taubenfeld*

Main category: cs.DC

TL;DR: 本文提出了团队组建（TF）问题及一种高效的随机算法，并将其应用于解决领导者选举等多种分布式问题，同时建立了TF算法消息复杂度的下界。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决分布式计算中的团队组建（TF）问题，并展示了TF问题在解决其他分布式问题（如图中的领导者选举和阈值检测）中的应用价值。

Method: 本文介绍了一种解决团队组建（TF）问题的新方法，该方法使用一种消息和时间效率高的随机算法，适用于异步模型、完全通信图、有界消息大小，并且允许一部分节点出现广义的初始故障。

Result: 本文成功地将多种分布式问题（包括领导者选举和阈值检测）归约到TF问题，并打破了异步隐式领导者选举的线性消息复杂度界限，同时改进了异步显式领导者选举的消息最优算法的时间复杂度。此外，本文还建立了TF算法消息复杂度的紧确下界。

Conclusion: 本文提出了团队组建（TF）问题，并提供了一个高效的随机算法。TF可以用于解决其他分布式问题，如领导者选举和阈值检测。同时，本文还建立了TF算法消息复杂度的紧确下界。

Abstract: A novel long-lived distributed problem, called Team Formation (TF), is
introduced together with a message- and time-efficient randomized algorithm.
The problem is defined over the asynchronous model with a complete
communication graph, using bounded size messages, where a certain fraction of
the nodes may experience a generalized, strictly stronger, version of initial
failures. The goal of a TF algorithm is to assemble tokens injected by the
environment, in a distributed manner, into teams of size $\sigma$, where
$\sigma$ is a parameter of the problem.
  The usefulness of TF is demonstrated by using it to derive efficient
algorithms for many distributed problems. Specifically, we show that various
(one-shot as well as long-lived) distributed problems reduce to TF. This
includes well-known (and extensively studied) distributed problems such as
several versions of leader election and threshold detection. For example, we
are the first to break the linear message complexity bound for asynchronous
implicit leader election. We also improve the time complexity of
message-optimal algorithms for asynchronous explicit leader election. Other
distributed problems that reduce to TF are new ones, including matching players
in online gaming platforms, a generalization of gathering, constructing a
perfect matching in an induced subgraph of the complete graph, quorum sensing
in message-passing networks, and more. To complement our positive contribution,
we establish a tight lower bound on the message complexity of TF algorithms.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [279] [Adversarial Robustness in Distributed Quantum Machine Learning](https://arxiv.org/abs/2508.11848)
*Pouya Kananian,Hans-Arno Jacobsen*

Main category: quant-ph

TL;DR: 分布式QML模型在对抗性鲁棒性方面可能比传统模型更脆弱。本研究回顾了联邦学习、电路切割和传送等分布式方法，并总结了各自的对抗性鲁棒性方法，同时讨论了该领域的开放性问题。


<details>
  <summary>Details</summary>
Motivation: 为了理解QML模型的潜在优势并构建可信赖的系统，研究其adversarial robustness是至关重要的。分布式QML模型允许利用多个量子处理器来克服单个设备的限制并构建可扩展的系统。然而，这种分布式可能会影响其adversarial robustness，可能使其更容易受到新的攻击。

Method: 通过回顾不同的分布式方法（如联邦学习、电路切割和基于传送的技术），并总结各自在adversarial robustness方面的现有方法，来分析分布式QML模型的adversarial robustness。

Result: 研究不同分布式方法对QML模型adversarial robustness的影响，并总结了现有研究。

Conclusion: 本研究总结了分布式QML模型的对adversarial robustness的现有方法，并讨论了该领域的开放性问题。

Abstract: Studying adversarial robustness of quantum machine learning (QML) models is
essential in order to understand their potential advantages over classical
models and build trustworthy systems. Distributing QML models allows leveraging
multiple quantum processors to overcome the limitations of individual devices
and build scalable systems. However, this distribution can affect their
adversarial robustness, potentially making them more vulnerable to new attacks.
Key paradigms in distributed QML include federated learning, which, similar to
classical models, involves training a shared model on local data and sending
only the model updates, as well as circuit distribution methods inherent to
quantum computing, such as circuit cutting and teleportation-based techniques.
These quantum-specific methods enable the distributed execution of quantum
circuits across multiple devices. This work reviews the differences between
these distribution methods, summarizes existing approaches on the adversarial
robustness of QML models when distributed using each paradigm, and discusses
open questions in this area.

</details>


### [280] [Gradient-Based Inverse Optimization of Atom-Chip Wire Currents for BEC Transport](https://arxiv.org/abs/2508.11712)
*Naoki Shibuya*

Main category: quant-ph

TL;DR: 在原子芯片上移动磁阱时，用一种新的模拟方法解决了线电流变化引起的陷阱变形问题，并展示了速度和绝热性之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 解决在原子芯片上移动磁阱时，线电流变化导致的陷阱几何变形和参数加热/原子损失问题。

Method: 提出了一种基于反向优化的快速模拟框架，用于计算线电流调度，以在原子芯片上移动磁阱，同时保持陷阱几何形状。

Result: 展示了在2.4毫米轨迹上，通过调整传输时间（2至5秒）来平衡速度和绝热性，并评估了陷阱的最小能量、横向位移、囚禁轮廓和绝热参数。

Conclusion: 通过反向优化和快速模拟框架，可以计算出在原子芯片上移动磁阱的线电流调度，以在原子传输过程中保持陷阱几何形状。

Abstract: Modulating wire currents to shift a magnetic trap along an atom chip enables
smooth contact-free delivery of Bose-Einstein condensates but can deform the
confinement profile causing parametric heating and atom loss. We introduce a
fast simulation framework based on inverse optimization that, given an initial
trap and a predefined trajectory over time, computes a wire current schedule
that transports the atoms and restores the trap geometry upon arrival. We
assess trap's minimum energy, lateral displacement, confinement profile and an
adiabaticity parameter over a 2.4 mm trajectory for various transport durations
between 2s and 5s, demonstrating the trade-off between speed and adiabaticity.

</details>


### [281] [The Evolution of IBM's Quantum Information Software Kit (Qiskit): A Review of its Applications](https://arxiv.org/abs/2508.12245)
*Param Pathak,K Tarakeshwar,Syed Sufiyan Ali,Shalini Devendrababu,Adarsh Ganesan*

Main category: quant-ph

TL;DR: Qiskit 是一个开源量子计算框架，在多个领域（如密码学、气候科学和金融）得到了应用。它支持混合计算，但仍面临可扩展性和可复现性方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 由于量子计算的普及，需要一个易于访问和可扩展的软件框架来进行实际实验和应用。本调查旨在系统地回顾 Qiskit 的发展、贡献、应用和局限性，为研究人员和从业人员提供参考。

Method: 通过系统性地回顾 Qiskit 的发展和在密码学、网络安全、图像和信号处理、气候科学、能源应用和金融等领域的贡献，分析 Qiskit 的技术结构、应用和局限性。

Result: Qiskit 促进了混合经典-量子工作流，并在量子密钥分发、气候模拟和量子增强投资组合优化等领域实现了在物理量子硬件上的算法部署。调查还涵盖了 Qiskit 的技术结构、可扩展性和可复现性方面的局限性。

Conclusion: Qiskit 已成为量子计算领域的重要工具，促进了跨学科应用和混合经典-量子工作流的发展。尽管存在可扩展性和可复现性方面的挑战，但它为研究人员和从业人员提供了一个宝贵的参考点，以理解和贡献于量子计算。

Abstract: Quantum computing is being increasingly adopted for solving classically
intractable problems across various domains. However, the availability of
accessible and scalable software frameworks remains essential for practical
experimentation and adoption. IBM's open-source quantum computing toolkit
'Qiskit' has become a key player in this space by offering tools for circuit
design, simulation, hardware execution, and domain-specific applications. This
survey provides a systematic review of how Qiskit has evolved and what it has
contributed to several critical fields including cryptography and
cybersecurity, image and signal processing, climate science and energy
applications, and finance. We show how Qiskit facilitates hybrid
classical-quantum workflows and enables the deployment of algorithms on
physical quantum hardware through error mitigation and modular integration
approaches. Our exploration covers several key applications, including quantum
key distribution, climate simulation, and quantum-enhanced portfolio
optimization, while providing practical insights into their implementation.
This work also covers the framework's technical structure and current
limitations associated with scalability and reproducibility. By bringing
together developments that have been scattered across different areas, this
work serves as a reference point for researchers and practitioners who want to
understand or contribute to Qiskit-enabled quantum computing.

</details>


### [282] [Optical Interferometric Readout of a Magnetically Levitated Superconducting Microsphere](https://arxiv.org/abs/2508.11731)
*J. J. Hansen,S. Minniberger,D. Ilk,P. Asenbaum,G. Higgins,R. G. Povey,P. Schmidt,J. Hofer,R. Claessen,M. Aspelmeyer,M. Trupke*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We probe the motion of a 6 $\mu g$ magnetically levitated superconducting
microsphere using optical interferometry at 3 K, achieving a resolution better
than 1 $nm/ \sqrt{Hz}$, and use the measured signal to feedback-cool its
motion. The resolution exceeds the shot-noise limit of 11 $pm/ \sqrt{Hz}$
primarily due to technical noise arising from the roughness of the particle.
Combined with established techniques of cavity optomechanics, the high degree
of isolation from environmental noise afforded by this platform provides a path
to quantum physics experiments with cryogenic isolated masses at the microgram
scale.

</details>


### [283] [One, Two, Three: One empirical evaluation of a two-copy shadow tomography scheme with triple efficiency](https://arxiv.org/abs/2508.11744)
*Viet T. Tran,Richard Kueng*

Main category: quant-ph

TL;DR: 该论文通过无噪声模拟对三效影重构进行了经验评估，结果与理论预测一致，并展示了该协议在实践中的潜力。


<details>
  <summary>Details</summary>
Motivation: 为了实现高效的量子态学习，量子态层析成像协议旨在用比传统量子态层析成像更少的资源来重构可观量的期望值。

Method: 该工作通过利用来自改进的量子和量子启发式凸优化算法的见解，改进了三效影重构协议中的一个核心子程序，并使用无噪声模拟对三效影重构进行了经验评估。

Result: 经验样本复杂度与稳定器态的理论预测非常吻合，并且对于随机吉布斯态显示出比已建立的理论界限略有改善的缩放。

Conclusion: 该协议有潜力在实践中非常节省样本

Abstract: Shadow tomography protocols have recently emerged as powerful tools for
efficient quantum state learning, aiming to reconstruct expectation values of
observables with fewer resources than traditional quantum state tomography. For
the particular case of estimating Pauli observables, entangling two-copy
measurement schemes can offer an exponential improvement in sample complexity
over any single-copy strategy conceivable [1, Huang, Kueng, Preskill,
PRL(2021)]. A recent refinement of these ideas by King et al. [2, King, Gosset,
Kothari, Babbush, SODA (2025)] does not only achieve polynomial sample
complexity, but also maintains reasonable computational demands and utilizes
joint measurements on only a small constant number of state copies. This
`triple efficiency' is achievable for any subset of $n$-qubit Pauli
observables, whereas single-copy strategies can only be efficient if the Pauli
observables have advantageous structure. In this work, we complement existing
theoretical performance guarantees with the empirical evaluation of triply
efficient shadow tomography using classical, noise-free simulations. Our
findings indicate that the empirical sample complexity aligns closely with
theoretical predictions for stabilizer states and, notably, demonstrates
slightly improved scaling for random Gibbs states compared to established
theoretical bounds. In addition, we improve a central subroutine in the
triply-efficient shadow protocol by leveraging insights from a refined quantum
and quantum-inspired convex optimization algorithm [3, Henze et al.
arXiv:2502.15426 (2025)]. To summarize, our empirical sample complexity studies
of triply efficient shadow tomography not only confirm existing theoretical
scaling behavior, but also showcase that the actual constants involved are
comparatively benign. Hence, this protocol has the potential to also be very
sample-efficient in practice.

</details>


### [284] [Conditional mutual information: A generalization of causal inference in quantum systems](https://arxiv.org/abs/2508.12160)
*Anupam Ghosh*

Main category: quant-ph

TL;DR: 本研究提出了量子因果索引，用于分析量子系统中的因果关系，并发现因果影响以有限速度传播并出现相干振荡。


<details>
  <summary>Details</summary>
Motivation: 虽然因果关系是科学解释的基石，但其在量子领域的严谨探索尚属空白。本研究旨在将经典因果推断框架扩展至量子领域，以揭示量子系统中的因果关系。

Method: 本研究引入了量子因果索引，该索引是经典因果推断框架的量子扩展，利用量子条件互信息（QCMI）和冯诺依曼熵作为方向性度量，并应用于自旋链系统，通过单点投影测量作为干预，观察其对远处位点的条件效应，同时研究了因果影响的有效传播速度。

Result: 研究发现因果影响存在有限速度传播，并出现了相干振荡现象，通过量子因果索引量化了量子系统中的因果影响。

Conclusion: 本研究为量子因果关系的探索提供了新的视角和工具，为理解量子系统中的因果机制奠定了基础。

Abstract: The concept of causality is fundamental to numerous scientific explanations;
nonetheless, its extension to the quantum regime has yet to be explored
rigorously. This paper introduces the development of a quantum causal index, a
novel extension of the classical causal inference framework, tailored to grasp
the causal relationships inherent in quantum systems. Our study focuses on the
asymmetric quantum conditional mutual information (QCMI), incorporating the von
Neumann entropy, as a directional metric of causal influence in quantum
many-body systems. We analyze spin chains using the QCMI, implementing a
projective measurement on one site as the intervention and monitoring its
effect on a distant site conditioned on intermediate spins. Additionally, we
study the effective causal propagation velocity, which is the speed at which
QCMI becomes significant at distant sites. These findings indicate the presence
of finite-speed propagation of causal influence, along with the emergence of
coherent oscillations.

</details>


### [285] [Unitary causal decompositions: a combinatorial characterisation via lattice theory](https://arxiv.org/abs/2508.11762)
*Tein van der Lugt,Robin Lorenz*

Main category: quant-ph

TL;DR: 如果一个酉变换可以分解为一个没有从输入 a 到输出 b 的路径的量子电路，那么 a 不会通过整体酉影响 b。本研究提出了一个组合条件，用于精确表征哪些因果无影响约束集可以进行酉因果分解，该条件基于算子代数和概念格理论，并表述为不存在 C3 子结构或 L_G 中路径数量的限制。


<details>
  <summary>Details</summary>
Motivation: 本文关注酉因果分解，即在不要求推广到早期研究引发的“扩展”或“路由”量子电路的情况下，在传统量子电路形式中进行分解。它旨在解决酉变换的因果分解的普遍存在性问题，并连接了量子因果关系中的两个基本概念：因果结构和组合结构。

Method: 研究基于有限维度算子代数和概念格构建，后者最近被证明为因果分解提供了规范形状 L_G。

Result: 研究结果确定了一个组合条件，可以精确地识别出允许酉因果分解的因果无影响约束集。此条件通过 G 中的 C3 缺失或 L_G 中每对输入-输出之间最多一条路径来表征。

Conclusion: 该研究提出了一种组合条件，用于精确表征一组因果无影响约束 G，该约束满足 G 的任何酉变换都具有构成上表示这些约束的酉因果分解。该条件可以表述为 G 中不存在受限子结构 C3，或者在 L_G 中每个输入和输出之间最多存在一条路径。

Abstract: If a unitary transformation has a decomposition into a quantum circuit with
no directed path from input $a$ to output $b$, then $a$ does not influence $b$
through the overall unitary. Conversely, it is known that if $a$ does not
influence $b$, one may always find a circuit decomposition lacking a path
between these systems, thus making the no-influence condition directly apparent
in the connectivity of the circuit. Causal decompositions are circuit
decompositions in which, more generally, multiple such no-influence conditions
are made apparent simultaneously. They bridge two fundamental concepts in
quantum causality: causal structure, as expressed by influences through unitary
transformations (and related to signalling through quantum channels); and
compositional structure, expressed in terms of the shape of quantum circuits or
networks. The general existence of causal decompositions remains unknown.
  This work focusses on unitary causal decompositions, i.e. decompositions in
terms of unitary circuits in the traditional quantum circuit formalism that do
not require the generalisation to `extended' or `routed' quantum circuits
prompted by earlier research on this topic. We identify a combinatorial
condition that characterises precisely those sets of causal no-influence
constraints $G$ for which any unitary transformation satisfying $G$ has a
unitary causal decomposition compositionally representing those constraints.
Our methods are based on finite-dimensional operator algebra as well as the
concept lattice construction, which was recently shown to provide a canonical
shape $L_G$ for causal decompositions. The combinatorial condition we identify
can be formulated in terms of $G$ as the absence of a forbidden substructure
$C_3$ and in terms of $L_G$ as the existence of no more than one path between
each input and output.

</details>


### [286] [The Role of Quantum Computing in Advancing Scientific High-Performance Computing: A perspective from the ADAC Institute](https://arxiv.org/abs/2508.11765)
*Gilles Buchs,Thomas Beck,Ryan Bennink,Daniel Claudino,Andrea Delgado,Nur Aiman Fadel,Peter Groszkowski,Kathleen Hamilton,Travis Humble,Neeraj Kumar,Ang Li,Phillip Lotshaw,Olli Mukkula,Ryousei Takano,Amit Saxena,In-Saeng Suh,Miwako Tsuji,Roel Van Beeumen,Ugo Varetto,Yan Wang,Kazuya Yamazaki,Mikael P. Johansson*

Main category: quant-ph

TL;DR: 量子计算（QC）和高性能计算（HPC）的融合是未来的趋势，但目前QC在可扩展性和错误率方面仍有挑战。HPC在最大化QC的潜力方面仍然很重要。ADAC成立了QC工作组来推动这项合作。


<details>
  <summary>Details</summary>
Motivation: 随着量子计算（QC）从学术研究转向蓬勃发展的商业领域，对QC和高性能计算（HPC）之间关系的理解以及如何将它们结合起来至以是为了应对计算挑战。

Method: 本篇论文综合了量子计算工作组的见解，并辅以成员调查结果，该调查详细介绍了正在进行的项目和战略方向。通过概述将QC集成到HPC生态系统中的当前状况和挑战，为HPC专家提供对QC及其对计算密集型工作的未来影响的更深入理解。

Result: 尽管量子计算机在算力方面不断提升，但它们在可扩展性、错误率和相干时间方面仍面临挑战。HPC在最大化量子计算的加速方面仍然是必不可少的。ADAC（加速数据分析和计算研究所）已成立了量子计算工作组，以促进成员之间的合作，并推动QC与HPC的整合。

Conclusion: 总而言之，虽然量子计算（QC）在处理某些计算密集型任务方面具有巨大潜力，但它并非万能。未来的计算基础设施将是一个融合了高性能计算（HPC）和量子计算的混合系统，其中HPC在最大化量子加速方面仍然至关重要。该论文旨在通过概述QC集成到HPC生态系统的现状和挑战，帮助HPC专家更深入地理解QC及其对计算密集型工作的未来影响。

Abstract: Quantum computing (QC) has gained significant attention over the past two
decades due to its potential for speeding up classically demanding tasks. This
transition from an academic focus to a thriving commercial sector is reflected
in substantial global investments. While advancements in qubit counts and
functionalities continues at a rapid pace, current quantum systems still lack
the scalability for practical applications, facing challenges such as too high
error rates and limited coherence times. This perspective paper examines the
relationship between QC and high-performance computing (HPC), highlighting
their complementary roles in enhancing computational efficiency. It is widely
acknowledged that even fully error-corrected QCs will not be suited for all
computational task. Rather, future compute infrastructures are anticipated to
employ quantum acceleration within hybrid systems that integrate HPC and QC.
While QCs can enhance classical computing, traditional HPC remains essential
for maximizing quantum acceleration. This integration is a priority for
supercomputing centers and companies, sparking innovation to address the
challenges of merging these technologies. The Accelerated Data Analytics and
Computing Institute (ADAC) is comprised of globally leading HPC centers. ADAC
has established a Quantum Computing Working Group to promote and catalyze
collaboration among its members. This paper synthesizes insights from the QC
Working Group, supplemented by findings from a member survey detailing ongoing
projects and strategic directions. By outlining the current landscape and
challenges of QC integration into HPC ecosystems, this work aims to provide HPC
specialists with a deeper understanding of QC and its future implications for
computationally intensive endeavors.

</details>


### [287] [Inducing macroscopic cat states of nonequilibrium electrons via cat-state light irradiation and projective measurements](https://arxiv.org/abs/2508.11769)
*Shohei Imai*

Main category: quant-ph

TL;DR: Projective measurements on quantum light can restore macroscopic cat states in electrons, even in the thermodynamic limit, by using an external-field approximation.


<details>
  <summary>Details</summary>
Motivation: We show that projective measurements on quantum light can induce macroscopic cat states in many-electron systems driven by large-amplitude cat-state light.

Method: We investigate the quantum dynamics of N independent two-level electrons interacting with Schr"odinger cat or kitten states of light. These dynamics are captured by an external-field approximation, in which the electronic system evolves into a Rabi-oscillation cat state.

Result: Without measurement, a macroscopic cat state of electrons appears only in an ultrashort time window. In contrast, photon-number parity or quadrature projective measurements can restore a macroscopic cat state in nonequilibrium electrons, even in the thermodynamic limit.

Conclusion: projective measurements on quantum light can restore a macroscopic cat state in nonequilibrium electrons, even in the thermodynamic limit, highlighting the need for precise quantum measurement techniques for light to control macroscopic quantum states of matter driven by quantum light.

Abstract: We show that projective measurements on quantum light can induce macroscopic
cat states in many-electron systems driven by large-amplitude cat-state light.
Here we investigate the quantum dynamics of N independent two-level electrons
interacting with Schr\"odinger cat or kitten states of light. Without
measurement, a macroscopic cat state of electrons appears only in an ultrashort
time window. In contrast, we demonstrate that photon-number parity or
quadrature projective measurements can restore a macroscopic cat state in
nonequilibrium electrons, even in the thermodynamic limit. These dynamics are
captured by an external-field approximation, in which the electronic system
evolves into a Rabi-oscillation cat state. Our results highlight the need for
precise quantum measurement techniques for light to control macroscopic quantum
states of matter driven by quantum light.

</details>


### [288] [Harvesting Contextuality from the Vacuum](https://arxiv.org/abs/2508.11773)
*Philip A. LeMaitre*

Main category: quant-ph

TL;DR: 本研究提出了从量子场真空中收获量子协定性的方法，发现Unruh-DeWitt模型和特定系统可以实现。研究了协定性与纠缠、魔性的关系，并提出了新的收获标准。


<details>
  <summary>Details</summary>
Motivation: 量子协定性被认为是量子优势的来源，它推广了非定域纠缠和魔性，并且与Wigner负性等价。本研究旨在探索如何从量子场真空中收获量子协定性，并将其作为一种资源，以及探究其与量子信息处理中其他资源（如纠缠和魔性）的关系。

Method: 提出并分析了协定性收获协议，并利用协定性工具（如协定性分数）作为通用的收获度量，适用于包括非定域纠缠和魔性在内的任何协定性形式。研究了Unruh-DeWitt模型，特别是量子比特-量子三能级系统，以探究收获协定性与收获纠缠之间的关系，并提出了新的真正收获标准。

Result: Unruh-DeWitt模型可以从真空中收获量子协定性，间隙系统在特定测量下也能实现。收获的协定性在某些情况下比收获的魔性更强。量子比特-量子三能级系统在收获协定性和纠缠之间存在权衡，但两者可以共存。新的收获标准揭示了新的收获参数范围。

Conclusion: 该研究展示了Unruh-DeWitt模型能够从无质量标量量子场的真空中收获量子协定性，并且间隙系统在合适的测量选择下也能实现这一点。收获的协定性在特定参数下可以比收获的魔性具有更大的量值，并且研究了一个Unruh-DeWitt量子比特-量子三能级系统，揭示了量子三能级系统的收获协定性与系统间的收获纠缠之间存在权衡，并且在某些收获机制下两者可以并存。此外，该研究还引入了新的真正收获标准，适用于单个系统，并揭示了新的允许收获参数。

Abstract: Quantum contextuality is the notion that certain measurement scenarios do not
admit a global description of their statistics and has been implicated as the
source of quantum advantage in a number of quantum information protocols. It
has been shown that contextuality generalizes the concepts of non-local
entanglement and magic, and is an equivalent notion of non-classicality to
Wigner negativity. In this paper, the protocol of contextuality harvesting is
introduced and it is shown that Unruh-DeWitt models are capable of harvesting
quantum contextuality from the vacuum of a massless scalar quantum field. In
particular, it is shown that gapless systems can be made to harvest
contextuality given a suitable choice of measurements. The harvested
contextuality is also seen to behave similarly to harvested magic and can be
larger in magnitude for specific parameter regimes. An Unruh-DeWitt
qubit-qutrit system is also investigated, where it is shown that certain
tradeoffs exist between the harvested contextuality of the qutrit and the
harvested entanglement between the systems, and that there are harvesting
regimes where the two resources can both be present. Some of the tools of
contextuality, namely the contextual fraction, are also imported and used as
general harvesting measures for any form of contextuality, including non-local
entanglement and magic. Additionally, new criteria for genuine harvesting are
put forward that also apply to individual systems, revealing new permissible
harvesting parameter regimes.

</details>


### [289] [Control of Dipolar Dynamics by Geometrical Programming](https://arxiv.org/abs/2508.11785)
*Jiaqi You,John M. Doyle,Zirui Liu,Scarlett S. Yu,Avikar Periwal*

Main category: quant-ph

TL;DR: 通过几何重塑分子镊子阵列，可以实现量子多体控制，抑制失相，并实现自旋压缩。


<details>
  <summary>Details</summary>
Motivation: 为了实现量子多体控制，并探索分子在量子系统中的应用潜力。

Method: 通过几何重塑分子镊子阵列，并对提出的方法进行理论分析。

Result: 成功抑制了运动失相，并实现了增强的自旋压缩，同时分析了一种能显著抑制退相干的特定静态几何。

Conclusion: 提出的几何重塑分子镊子阵列的方法为量子多体控制提供了鲁棒的控制模式，特别适用于分子系统。

Abstract: We propose and theoretically analyze methods for quantum many-body control
through geometric reshaping of molecular tweezer arrays. Dynamic rearrangement
during entanglement is readily available due to the extended coherence times of
molecular rotational qubits. We show how motional dephasing can be suppressed
and enhanced spin squeezing can be achieved in an actively rearranged
short-range XY model. We also analyze in detail a specific static geometry that
significantly suppresses decoherence. These general methods as applied to
programmable quantum systems offer robust control modalities that are well
suited to molecules.

</details>


### [290] [Gaussian Atemporality: When Gaussian Quantum Correlations Imply Common Cause](https://arxiv.org/abs/2508.11804)
*Minjeong Song,Jayne Thompson,Matthew S. Winnel,Biveen Shajilal,Timothy C. Ralph,Syed M. Assad,Mile Gu*

Main category: quant-ph

TL;DR: 本研究提出了高斯非时间性鲁棒性，用于量化量子关联的非时间性，并证明了其具有时间箭头且能超越纠缠。


<details>
  <summary>Details</summary>
Motivation: 区分时间和空间关联，并探索量子关联的非时间性。

Method: 本研究提出了一种名为“高斯非时间性鲁棒性”的度量，用于量化量子关联的非时间性，并说明了其计算效率和操作意义。

Result: 证明了特定的时空高斯关联具有内在的时间箭头，并且该指标可以衡量超越纠缠的量子关联。

Conclusion: 本研究展示了高斯量子关联具有非时间性，其协方差在没有假设某种共同原因的情况下是不可思议的。我们引入了高斯非时间性鲁棒性作为衡量非时间性的指标，并说明了其可计算性和操作意义，即消除这种独特量子现象所需的最小噪声。

Abstract: Conventionally, covariances do not distinguish between spatial and temporal
correlations. The same covariance matrix could equally describe temporal
correlations between observations of the same system at two different times or
correlations made on two spatially separated systems that arose from some
common cause. Here, we demonstrate Gaussian quantum correlations that are
atemporal, such that the covariances governing their quadrature measurements
are unphysical without postulating some common cause. We introduce Gaussian
atemporality robustness as a measure of atemporality, illustrating its
efficient computability and operational meaning as the minimal noise needed to
remove this uniquely quantum phenomenon. We illustrate that (i) specific
spatiotemporal Gaussian correlations possess an intrinsic arrow of time, such
that Gaussian atemporality robustness is zero in one temporal direction and not
the other and (ii) that it measures quantum correlations beyond entanglement.

</details>


### [291] [Trotter simulation of vibrational Hamiltonians on a quantum computer](https://arxiv.org/abs/2508.11865)
*Shreyas Malpathak,Sangeeth Das Kallullathil,Ignacio Loaiza,Stepan Fomichev,Juan Miguel Arrazola,Artur F. Izmaylov*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Simulating vibrational dynamics is essential for understanding molecular
structure, unlocking useful applications such as vibrational spectroscopy for
high-fidelity chemical detection. Quantum algorithms for vibrational dynamics
are emerging as a promising alternative to resource-demanding classical
approaches, but this domain is largely underdeveloped compared to quantum
simulations of electronic structure. In this work, we describe in detail three
distinct forms of the vibrational Hamiltonian: canonical bosonic quantization,
real space representation, and the Christiansen second-quantized form.
Leveraging Lie algebraic properties of each, we develop efficient fragmentation
schemes to enable the use of Trotter product formulas for simulating time
evolution. We introduce circuits required to implement time evolution in each
form, and highlight factors that contribute to the simulation cost, including
the choice of vibrational coordinates. Using a perturbative approach for the
Trotter error, we obtain tight estimates of T gate cost for the simulation of
time evolution in each form, enabling their quantitative comparison. Combining
tight Trotter error estimates and efficient fragmentation schemes, we find that
for the medium-sized CH$_4$ molecule with 9 vibrational modes, time evolution
for approximately 1.8 ps may be simulated using as little as 36 qubits and
approximately $3 \times 10^{8}$ T gates -- an order-of-magnitude speedup over
prior-art algorithms. Finally, we present calculations of vibrational spectra
using each form to demonstrate the fidelity of our algorithms. This work
presents a unified and highly optimized framework that makes simulating
vibrational dynamics an attractive use case for quantum computers.

</details>


### [292] [Transfer-Based Strategies for Multi-Target Quantum Optimization](https://arxiv.org/abs/2508.11914)
*Vu Tuan Hai,Bui Cao Doanh,Le Vu Trung Duong,Pham Hoai Luan,Yasuhiko Nakashima*

Main category: quant-ph

TL;DR: 我们提出了一种两阶段框架，用于多目标量子优化，通过在任务之间共享解决方案和初始化未优化目标来加速优化过程。


<details>
  <summary>Details</summary>
Motivation: 为了加速优化和减少量子资源使用，我们研究了一系列能够实现相关任务之间知识转移的策略。

Method: 我们提出并评估了几种方法，包括热启动初始化、通过一阶泰勒展开的参数估计、具有D层树的分层聚类和基于深度学习的转移。

Result: 我们的实验结果，使用通过PennyLane实现的参数化量子电路，证明了转移技术显著减少了所需迭代次数，同时保持了可接受的成本值。

Conclusion: 转移技术显著减少了所需迭代次数，同时保持了可接受的成本值。这些发现凸显了多目标泛化在量子优化管道中的潜力，并为可扩展的多目标量子优化奠定了基础。

Abstract: We address the challenge of multi-target quantum optimization, where the
objective is to simultaneously optimize multiple cost functions defined over
the same quantum search space. To accelerate optimization and reduce quantum
resource usage, we investigate a range of strategies that enable knowledge
transfer between related tasks. Specifically, we introduce a two-stage
framework consisting of a training phase where solutions are progressively
shared across tasks and an inference phase, where unoptimized targets are
initialized based on prior optimized ones. We propose and evaluate several
methods, including warm-start initialization, parameter estimation via
first-order Taylor expansion, hierarchical clustering with D-level trees, and
deep learning-based transfer. Our experimental results, using parameterized
quantum circuits implemented with PennyLane, demonstrate that transfer
techniques significantly reduce the number of required iterations while
maintaining an acceptable cost value. These findings highlight the promise of
multi-target generalization in quantum optimization pipelines and provide a
foundation for scalable multi-target quantum optimization.

</details>


### [293] [Dynamical Phase Transitions in Open Quantum Walks](https://arxiv.org/abs/2508.11947)
*Stefano Longhi*

Main category: quant-ph

TL;DR: 该研究探索了量子行走中退相干的影响，发现它会导致经典化和非厄米谱现象，并可能在量子技术中找到应用。


<details>
  <summary>Details</summary>
Motivation: 研究退相干如何影响随机量子行走中的动力学行为，特别是当相干幺正演化被周期性地去相位中断时，以及这种相互作用如何导致动力学行为的经典化。

Method: 通过分析量子行走在环上（受规范场影响）和有限线路上（具有内部自由度）的两种典范模型，研究了退相干对动力学行为的影响，重点关注了导致经典化和违反详细平衡的机制。

Result: 研究表明，这些量子-经典混合系统不仅可以呈现一阶动力学相变（以本征值交叉为特征），还可以呈现二阶相变（以厄米点处本征值和本征值的合并为特征）。

Conclusion: 该研究揭示了一类新的临界行为，其中退相干诱导的经典化使得能够访问非厄米谱现象。这些结果不仅具有基础意义，而且对量子模拟、误差缓解和可控非平衡量子态工程等量子技术也具有重要的启示作用。

Abstract: Dynamical phase transitions in the relaxation behavior of stochastic quantum
walks are investigated, focusing on systems where coherent unitary evolution is
periodically interrupted by dephasing. This interplay leads to a
classicalization of the dynamics, effectively described by non-equilibrium
Markovian processes that can violate detailed balance. As a result, such
systems exhibit a richer and more complex spectral structure than their
equilibrium counterparts. Extending recent insights from classical Markov
dynamics [G. Teza {\it et al.}, Phys. Rev. Lett. {\bf 130}, 207103 (2023)], we
demonstrate that these quantum-classical hybrid systems can host not only
first-order dynamical phase transitions -- characterized by eigenvalue
crossings -- but also second-order transitions marked by the coalescence of
eigenvalues and eigenvectors at exceptional points. We analyze two paradigmatic
models: a quantum walk on a ring under gauge fields and a walk on a finite line
with internal degrees of freedom, both exhibiting distinct mechanisms for
breaking detailed balance. These findings reveal a novel class of critical
behavior in open quantum systems, where decoherence-induced classicalization
enables access to non-Hermitian spectral phenomena. Beyond their fundamental
interest, our results offer promising implications for quantum technologies,
including quantum simulation, error mitigation, and the engineering of
controllable non-equilibrium quantum states.

</details>


### [294] [Coherence and decoherence in generalized and noisy Shor's algorithm](https://arxiv.org/abs/2508.11962)
*Linlin Ye,Zhaoqi Wu*

Main category: quant-ph

TL;DR: Analyzed Shor's algorithm with different states and noise, providing performance bounds.


<details>
  <summary>Details</summary>
Motivation: The motivation is to study the coherence and decoherence in generalized Shor's algorithm, including arbitrary pure states and pseudo-pure states, and to analyze the performance bounds and the impact of noise.

Method: The study involves deriving lower and upper bounds on the performance of a generalized Shor's algorithm and analyzing coherence and decoherence in both generalized and noisy versions.

Result: The paper establishes relationships between the probability of calculating 'r' for different initial states in the generalized Shor's algorithm and provides a lower bound for the probability of calculating 'r' in the noisy version of the algorithm.

Conclusion: The paper derives bounds on the performance of a generalized Shor's algorithm with arbitrary pure states or pseudo-pure states, establishing relationships between different initialization states and analyzing coherence/decoherence in noisy versions.

Abstract: Quantum coherence constitutes a fundamental physical mechanism essential to
the study of quantum algorithms. We study the coherence and decoherence in
generalized Shor's algorithm where the register $A$ is initialized in arbitrary
pure state, or the combined register $AB$ is initialized in any pseudo-pure
state, which encompasses the standard Shor's algorithm as a special case. We
derive both the lower and upper bounds on the performance of the generalized
Shor's algorithm, and establish the relation between the probability of
calculating $r$ when the register $AB$ is initialized in any pseudo-pure state
and the one when the register $A$ initialized in arbitrary pure state.
Moreover, we study the coherence and decoherence in noisy Shor's algorithm and
give the lower bound of the probability that we can calculate $r$.

</details>


### [295] [Unified quantification of entanglement and magic in information scrambling and their trade-off relationship](https://arxiv.org/abs/2508.11969)
*Mao Kaneyasu,Yoshihiko Hasegawa*

Main category: quant-ph

TL;DR: 该研究提出了一个统一的度量来量化纠缠和魔法 the scrambling，发现了它们之间的权衡关系，并分析了幺正变换的作用。


<details>
  <summary>Details</summary>
Motivation: 为了弥补现有研究将纠缠和魔法 the scrambling 分开处理而忽略它们之间内在权衡关系的不足，提出一个统一的框架。

Method: 利用量子资源理论的框架，提出并分析了一个统一的度量，用于量化纠缠和魔法 the scrambling，并推导了其最大值的解析表达式。

Result: 成功地将纠缠和魔法 the scrambling 统一在一个度量下，并揭示了它们之间的严格权衡关系，同时解析地得到了该度量的最大值，并量化了幺正变换的 the scrambling 能力。

Conclusion: 该研究通过引入一个统一的度量，揭示了纠缠和魔法 the scrambling 之间的严格权衡关系，并分析了幺正变换放大该度量的能力。

Abstract: Information scrambling is a phenomenon observed in a wide range of quantum
systems, in which initially localized information becomes distributed across
the entire system. Clarifying the essence of this phenomenon is made possible
by quantum resource theory, which provides an axiomatic framework for
quantifying various forms of quantumness. Within this framework, information
scrambling can be classified into two distinct types: entanglement scrambling
and magic scrambling. Although each has been analyzed individually through
their respective resource theories, such separate treatments fail to capture
the inherent trade-off between them. In this study, we introduce a unified
measure of the two types of scrambling, grounded in resource-theoretic
principles. This unified approach reveals a rigorous trade-off relationship
between entanglement and magic scrambling, as the exact maximum value of the
proposed measure can be derived analytically. Furthermore, we quantify the
scrambling capability of unitary transformations in terms of their ability to
amplify this measure.

</details>


### [296] [Parallel Data Processing in Quantum Machine Learning](https://arxiv.org/abs/2508.12006)
*Mehdi Ramezani,Sina Asadiyan Zargar,Abolfazl Bahrampour,Saeed Bagheri Shouraki,Alireza Bahrampour*

Main category: quant-ph

TL;DR: 提出了一种新的QML框架，利用量子并行性处理整个数据集，将训练时间复杂度从O(N^2)降至O(N)，准确性与传统方法相当。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统和量子计算中QML训练面临的计算瓶颈，即顺序数据处理的限制。

Method: 提出了一种量子机器学习（QML）框架，该框架利用量子并行性，通过将所有训练样本编码为量子叠加态并在单次量子操作中处理整个训练数据集，来解决计算瓶颈。该方法将损失函数评估的理论复杂度从传统QML训练的O(N^2)降低到O(N)，其中N是数据集大小。

Result: 通过在多个二元和多元分类数据集上进行数值模拟，证明了该方法在分类准确性方面可与传统量子电路相媲美，同时在训练时间上提供了显著的节省。

Conclusion: 所提出的方法通过量子并行处理数据，在不影响准确性的前提下，显著减少了训练时间，展示了其在实现高效量子机器学习算法方面的潜力。

Abstract: We propose a Quantum Machine Learning (QML) framework that leverages quantum
parallelism to process entire training datasets in a single quantum operation,
addressing the computational bottleneck of sequential data processing in both
classical and quantum settings. Building on the structural analogy between
feature extraction in foundational quantum algorithms and parameter
optimization in QML, we embed a standard parameterized quantum circuit into an
integrated architecture that encodes all training samples into a quantum
superposition and applies classification in parallel. This approach reduces the
theoretical complexity of loss function evaluation from $O(N^2)$ in
conventional QML training to $O(N)$, where $N$ is the dataset size. Numerical
simulations on multiple binary and multi-class classification datasets
demonstrate that our method achieves classification accuracies comparable to
conventional circuits while offering substantial training time savings. These
results highlight the potential of quantum-parallel data processing as a
scalable pathway to efficient QML implementations.

</details>


### [297] [Preparation of the single-spinon wave function in a quantum computer](https://arxiv.org/abs/2508.12011)
*D. Faílde,A. Gómez,J. Fernández-Rossier*

Main category: quant-ph

TL;DR: 在量子计算机上制备一维S=1/2自旋模型（Heisenberg和Haldane-Shastry）的单自旋子波函数，并提出计算其能量的方法。


<details>
  <summary>Details</summary>
Motivation: 为了在量子计算机上模拟和研究一维S=1/2自旋模型（如Heisenberg模型和Haldane-Shastry模型）的性质，需要有效地制备相应的单自旋子波函数。

Method: 提出了一种使用线性组合酉（LCU）方法在量子计算机上制备单自旋子波函数的方案，并分析了其在量子计算机上的资源成本。

Result: 成功地将单自旋子波函数制备方案扩展到了Haldane-Shastry模型，并提供了三种不同的计算单自旋子能量的策略，分析了它们在量子比特、门和电路方面的资源消耗。

Conclusion: 该研究提出了在量子计算机上制备一维S=1/2自旋模型中单自旋子波函数的方法，并将其应用于Haldane-Shastry模型。

Abstract: We consider the preparation of single-spinon wave functions, relevant for
one-dimensional $S=1/2$ spin models, in a quantum computer. We adopt the
recently proposed ansatz \cite{kulk} for the single-spinon wave function, where
a state with $S=1/2$ is built in a spin chain with $L+1$ sites, adding a site
with $S_z=1/2$ to the configurations of the ground-state wave function for the
spin chain with length $L$. We extend the original work to the case of the
Haldane-Shastry model. We discuss how to prepare the single-spinon ansatz both
for the Heisenberg and Haldane-Shastry models in quantum computers, using a
linear combination of unitaries. We consider three different strategies to
compute the single-spinon energy in a quantum computer and analyze their cost
in terms of the number of qubits, gates, and circuits.

</details>


### [298] [Fluorescence driven by nonclassical light](https://arxiv.org/abs/2508.12037)
*Christian Drago,John E. Sipe*

Main category: quant-ph

TL;DR: Squeezed light may boost two-photon excitation, and experiments could potentially detect this, but the effect is not huge.


<details>
  <summary>Details</summary>
Motivation: The research aims to determine if squeezed light irradiation can enhance two-photon excitation and if such enhancements are experimentally detectable.

Method: A model incorporating radiative and nonradiative broadening was developed to calculate scattered and absorbed energy. This model was applied to cesium atoms in a magneto-optical trap, evaluating fluorescence emission under both classical and squeezed light conditions (non-degenerate, continuous-wave, and pulsed).

Result: Squeezed light demonstrated an enhancement in both continuous-wave and pulsed regimes under ideal conditions. These enhancements are theoretically detectable but are considered moderate compared to values reported for molecular systems.

Conclusion: The study finds that squeezed light can enhance two-photon excitation compared to classical light, with potential for experimental detection, although the effect is moderate.

Abstract: We investigate whether or not irradiation by squeezed light can provide an
enhancement of the two-photon excitation of a system over irradiation by
classical light. Our emphasis is not only on whether or not there is such an
enhancement, but also on whether or not any enhancement can be reasonably
detected in an experiment. We begin by developing a model that includes
radiative and nonradiative broadening to calculate the total scattered and
absorbed energy. As an example calculation, we consider cesium atoms in a
magneto-optical trap, and evaluate the fluorescence emission when driven by
non-degenerate classical and squeezed light, in both the continuous-wave and
pulsed regimes. We find that squeezed light can provide an enhancement in both
regimes under ideal circumstances. These enhancements are in principle
detectable. However, we stress that they are moderate at best compared to
recently reported values for molecular systems.

</details>


### [299] [Raising the Bar: An Asymptotic Comparison of Classical and Quantum Shortest Path Algorithms](https://arxiv.org/abs/2508.12074)
*Phuc Hao Do,Tran Duc Le*

Main category: quant-ph

TL;DR: 在单源最短路径问题上，量子算法在短路径问题上优于最新的经典算法，但在长路径问题上，经典算法的扩展性更好。


<details>
  <summary>Details</summary>
Motivation: 为了在单源最短路径（SSSP）问题上重新评估量子优势，鉴于经典算法（Duan et al.）取得了新的进展（$O(m \cdot (\log n)^{2/3}）$，需要与量子算法进行系统性的理论比较。

Method: 通过分析量子算法（如Wesolowski和Piddock的算法）和最新经典算法（如Duan等人的算法）的理论成本函数，比较它们在不同图密度和路径长度下的扩展性。

Result: 量子算法在解路径较短的情况下具有更优的渐近扩展性，而对于长路径问题，最新的经典算法维持扩展性优势。这提供了一个关于量子算法和经典算法相对性能的更新视角。

Conclusion: 该研究通过理论分析，揭示了在单源最短路径（SSSP）问题上，量子算法与最新经典算法在不同图密度和路径长度下的相对性能。研究表明，复杂的量子算法（如Wesolowski和Piddock提出的算法）在解路径较短的情况下具有更好的渐近扩展性，而对于长路径问题，最新的经典算法（如Duan等人的算法）则表现出扩展性优势。这表明，在追求量子优势的过程中，经典的基准算法也在不断进步，需要持续的理论评估来指导未来的量子算法发展。

Abstract: The Single-Source Shortest Path (SSSP) problem is a cornerstone of computer
science with vast applications, for which Dijkstra's algorithm has long been
the classical baseline. While various quantum algorithms have been proposed,
their performance has typically been benchmarked against this decades-old
approach. This landscape was recently reshaped by the introduction of a new
classical algorithm by Duan et al. with a complexity of $O(m \cdot (\log
n)^{2/3})$. This development necessitates a re-evaluation of the quantum
advantage narrative for SSSP. In this paper, we conduct a systematic
theoretical comparison of modern quantum and classical SSSP algorithms in light
of this new classical frontier. Through an analysis of their theoretical cost
functions, we illustrate how their relative scaling compares across scenarios
that vary in graph density and path length. Our analysis suggests a nuanced
picture: sophisticated quantum algorithms, such as the one by Wesolowski and
Piddock, can exhibit more favorable asymptotic scaling, but only in regimes
characterized by short solution paths. Conversely, for problems involving long
paths, state-of-the-art classical algorithms appear to maintain a scaling
advantage. Our work provides an updated perspective for future quantum
algorithm development and underscores that the pursuit of quantum advantage is
a dynamic race where the classical goalposts are continually shifting.

</details>


### [300] [Simulating Quantum Turbulence with Matrix Product States](https://arxiv.org/abs/2508.12191)
*Felipe Gómez-Lozada,Nicolas Perico-García,Nikita Gourianov,Hayder Salman,Juan José Mendoza-Arenas*

Main category: quant-ph

TL;DR: MPS方法相比DNS能极大节省内存（10-10000倍），准确模拟量子湍流，可在更大尺度上研究以发现新物理。


<details>
  <summary>Details</summary>
Motivation: 直接数值模拟（DNS）在模拟量子湍流时，由于系统尺寸远大于特征长度而计算成本高昂。

Method: 提出并实现了一个适用于Gross-Pitaevskii方程的矩阵链态（MPS）求解器。

Result: MPS求解器在内存使用上比DNS减少了10到10,000倍以上，能够准确捕捉暗孤子、量化涡旋等非线性激发动力学，并复现能量谱等已有结果。

Conclusion: MPS方法能够有效地模拟量子湍流，并有望在更大系统尺寸下揭示新的物理现象。

Abstract: Quantum turbulence spans length scales from the system size $L$ to the
healing length $\xi$, making direct numerical simulations (DNS) of the
Gross-Pitaevskii (GP) equation computationally expensive when $L \gg \xi$. We
present a matrix product state (MPS) solver for the GP equation that
efficiently compresses the wavefunction by truncating weak interlength-scale
correlations. This approach reduces memory use by factors ranging from 10x to
over 10,000x compared to DNS. We benchmark our approach on nonlinear
excitations, namely dark solitons (1D) and quantized vortices (2D, 3D),
capturing key dynamics like Kelvin wave propagation and vortex ring emission in
the case of vortex line reconnection. For turbulent states composed of multiple
nonlinear excitations, we find that the memory compression of the MPS
representation is directly proportional to the soliton or vortex densities. We
also accurately reproduce established results from two-point correlation
functions and energy spectra, where we recover the incompressible kinetic
energy spectrum with little memory overhead. These results demonstrate the
representative capabilities of the MPS ansatz for quantum turbulence and pave
the way for studying this nonequilibrium state using previously-prohibited
system sizes to uncover possible new physics.

</details>


### [301] [Sensing decoherence by using edge state](https://arxiv.org/abs/2508.12209)
*Andrey R. Kolovsky*

Main category: quant-ph

TL;DR: 弱退相干可通过边缘态显著放大。


<details>
  <summary>Details</summary>
Motivation: 研究在没有退相干的情况下，跨越连接两个不同化学势储层的有限晶格的费米子粒子流是弹道的，而退相干通常会抑制这种弹道流。然而，如果退相干很弱，电流的变化可能无法检测到。

Method: 研究了弱退相干对具有边缘态的晶格中费米子电流的影响。

Result: 弱退相干可以被边缘态放大约几倍。

Conclusion: 弱退相干效应可以通过具有边缘态的晶格被放大几个数量级。

Abstract: In the absence of decoherence the current of fermionic particles across a
finite lattice connecting two reservoirs (leads) with different chemical
potentials is known to be ballistic. It is also known that decoherence
typically suppresses this ballistic current. However, if decoherence is weak,
the change in the current may be undetectable. In this work we show that the
effect of a weak decoherence can be amplified by orders of magnitude if the
lattice has edge states.

</details>


### [302] [Experimental investigation of uncertainty relations for non-Hermitian operators](https://arxiv.org/abs/2508.12214)
*Xinzhi Zhao,Xinglei Yu,Wenting Zhou,Chengjie Zhang,Jin-Shi Xu,Chuan-Feng Li,Guang-Can Guo*

Main category: quant-ph

TL;DR: 本研究进行了包含实数和复数非厄米算符的量子比特态实验，验证了不确定性关系在实验误差内的有效性，并为开放系统动力学表征和参数估计增强提供了新方法。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索适用于通用非厄米算符（包括厄米和酉算符作为特例）的不确定性关系，并将其与仅测试过酉算符这一特例的先前实验进行区分。

Method: 本研究进行了包含实数和复数非厄米算符的量子比特态实验，并验证了不确定性关系在实验误差内的有效性。

Result: 实验结果证实了非厄米算符的不确定性关系在实验误差内的有效性。

Conclusion: 本研究为非厄米算符的不确定性关系提供了实验证据，并且所提出的用于实现和测量非厄米算符的方法可用于表征开放系统动力学和增强参数估计。

Abstract: Uncertainty relations for Hermitian operators have been confirmed through
many experiments. However, previous experiments have only tested the special
case of non-Hermitian operators, i.e., uncertainty relations for unitary
operators. In this study, we explore uncertainty relations for general
non-Hermitian operators, which include Hermitian and unitary operators as
special cases. We perform experiments with both real and complex non-Hermitian
operators for qubit states, and confirm the validity of the uncertainty
relations within the experimental error. Our results provide experimental
evidence of uncertainty relations for non-Hermitian operators. Furthermore, our
methods for realizing and measuring non-Hermitian operators are valuable in
characterizing open-system dynamics and enhancing parameter estimation.

</details>


### [303] [Multiple-Noise-Resilient Nonadiabatic Geometric Quantum Control of Solid-State Spins in Diamond](https://arxiv.org/abs/2508.12221)
*Si-Qi Chen,Qi-Tao Duan,Chengxian Zhang,He Lu*

Main category: quant-ph

TL;DR: 本文提出了一种新的量子门（MNR-NGQG），提高了NV中心量子计算的鲁棒性和相干性，实现了高保真度单比特门。


<details>
  <summary>Details</summary>
Motivation: 可靠和鲁棒的控制是利用金刚石氮-空位（NV）中心实现量子信息处理的核心。然而，控制脉冲不可避免地会引入多种错误，导致退相干并阻碍可扩展应用。

Method: 实验上报告了一种实验友好、抗多噪声的非绝热几何量子门（MNR-NGQG），能够显著提高传统动力学门在鲁棒性和相干性方面的性能。

Result: 单量子比特门性能几乎不变，相干时间延长到 690 ± 30 μs（是朴素动力学对应物的 3.5 倍），单量子比特门的保真度达到 0.9992(1)。

Conclusion: 该工作为NV中心系统实现高保真度量子控制提供了一个实用的范例，为量子信息科学的实际应用铺平了道路。

Abstract: Reliable and robust control lies at the core of implementing quantum
information processing with diamond nitrogen-vacancy (NV) centers. However,
control pulses inevitably introduce multiple errors, leading to decoherence and
hindering scalable applications. Here, we experimentally report an
experiment-friendly multiple-noise-resilient nonadiabatic geometric quantum
gate~(MNR-NGQG) that can significantly improve conventional dynamical gate in
both robustness and coherence. Notably, even when the detuning fluctuation
range is comparable to the maximum Rabi frequency, the single-qubit gate
performance of the MNR-NGQG remains almost unchanged. Besides, the coherence
time of the electron spin is significantly extended to 690 $\pm$ 30 $ \mu$s,
3.5 times that of the naive dynamical counterpart. As a result, the fidelity of
single-qubit gates reaches 0.9992(1), as characterized by quantum process
tomography. With its experimentally feasible design and relaxed hardware
requirements, our work offers a solid paradigm for achieving high-fidelity
quantum control in NV center system, paving the way for practical applications
in quantum information science.

</details>


### [304] [Partial transpose as a space-time swap](https://arxiv.org/abs/2508.12256)
*James Fullwood,Junxian Li*

Main category: quant-ph

TL;DR: 本论文将量子力学中的偏转置操作解释为一种时空对换，将空间关联映射到时间关联，并可能与黑洞事件视界中的时空对换现象相关。


<details>
  <summary>Details</summary>
Motivation: 现有的量子理论（如Peres-Horodecki判据）中广泛使用了偏转置操作，但缺乏对其物理意义的解释。

Method: 通过将偏转置操作解释为双时间伪密度算符，并分析其在最大纠缠量子比特上的行为，以建立其与时空对换的联系。

Result: 证明了偏转置操作是将空间关联映射到时间关联的时空对换。对于最大纠缠量子比特，偏转置将违反贝尔不等式的空间关联映射为不能被空间分隔系统复制的因果关联。这表明偏转置操作可能与黑洞事件视界中的时空对换现象在量子力学层面相关。

Conclusion: 本论文提出偏转置操作可以被解释为一种时空对换，将空间关联映射到时间关联，在最大纠缠量子比特的情况下，将违反贝尔不等式的空间关联映射到不能被空间分隔的系统复制的因果关联。

Abstract: While the partial transpose operation appears in many fundamental results in
quantum theory -- such as the Peres-Horodecki criterion for entanglement
detection -- a physical interpretation of the partial transpose is lacking. In
this work, we show that a partial transpose of a bipartite density operator is
a two-time pseudo-density operator, which by definition encodes temporal
correlations associated with two-point sequential measurement scenarios. As
such, it follows that partial transposition admits a precise physical
interpretation as mapping spatial correlations to temporal correlations, thus
swapping the roles of space and time for bipartite quantum systems. For
maximally entangled qubits, we show that partial transposition maps spatial
correlations which violate Bell inequalities to causal correlations which
cannot be replicated by spacelike separated systems, thus further solidifying
the interpretation of partial transpose as a space-time swap. As it is known
that gravitational effects swap the roles of space and time inside a black
hole, our results suggest that at a quantum mechanical level, a traversal of a
black hole's event horizon by a bipartite quantum system may be described by a
partial transpose.

</details>


### [305] [Resonant dynamics of spin cluster in a periodically driven one-dimensional Rydberg lattice](https://arxiv.org/abs/2508.12295)
*Jin-Qiu Xiong,Yu-Hong Yan,Xun-Da Jiang,Yong-Yao Li,Kun-Liang Zhang*

Main category: quant-ph

TL;DR: A resonant driving field in Rydberg spin lattices can cause ballistic expansion or Bloch-like oscillations, similar to facilitation conditions, with potential for quantum state manipulation.


<details>
  <summary>Details</summary>
Motivation: The motivation is to investigate whether a resonant driving field can achieve effects similar to facilitation conditions in Rydberg lattices, which exhibit kinetic constraints and non-ergodic behavior. The research aims to understand the dynamic behaviors in driven Rydberg spin lattices and explore potential applications in quantum state manipulation.

Method: The paper analyzes the relaxation dynamics of spin clusters in a periodically driven Rydberg spin lattice using an effective Hamiltonian for domain walls. It compares the behavior under resonant driving conditions with that under facilitation conditions.

Result: The research shows that when the driving frequency is resonant with the Rydberg interaction, the spin cluster exhibits ballistic expansion with half the spreading rate compared to the case of facilitation conditions. Near the resonant point, the spin cluster displays confinement behavior of Bloch-like oscillations.

Conclusion: The study demonstrates that a resonant driving field can induce kinetic constraints and non-ergodic behavior in Rydberg lattices, mimicking facilitation conditions. It shows that a resonant driving field can achieve effects similar to those under facilitation conditions, leading to ballistic expansion and Bloch-like oscillations depending on the driving frequency.

Abstract: Rydberg lattice under facilitation conditions can feature kinetic
constraints, leading to ballistic and non-ergodic behavior at different
detuning intensities. Here, we demonstrate that a resonant driving field can
achieve effects similar to those under facilitation conditions. We focus on the
relaxation dynamics of spin clusters in a periodically driven Rydberg spin
lattice. Through an effective Hamiltonian for the domain walls of the spin
cluster, it is shown that when the driving frequency is resonant with the
Rydberg interaction, the spin cluster exhibits ballistic expansion with half
the spreading rate compared to the case of facilitation conditions. However,
near the resonant point, the spin cluster displays confinement behavior of the
Bloch-like oscillations. These results demonstrate the rich dynamic behaviors
in the driven Rydberg spin lattices and may find applications in quantum state
manipulation.

</details>


### [306] [Spin decoherence dynamics of Er$^{3+}$ in CeO$_2$ film](https://arxiv.org/abs/2508.12429)
*Sagar Kumar Seth,Jonah Nagura,Vrindaa Somjit,Aneesh Bapat,Xinhao Li,Gregory D. Grant,Ignas Masiulionis,Xu Han,F. Joseph Heremans,Giulia Galli,David D. Awschalom,Supratik Guha,Jiefei Zhang*

Main category: quant-ph

TL;DR: 在掺杂Erbium离子的二氧化铈薄膜中实现了长达176.4微秒的自旋相干性，为构建量子网络提供了新的方向。


<details>
  <summary>Details</summary>
Motivation: 为了构建可扩展的量子网络，需要开发与电信兼容的自旋-光子接口。Erbium离子具有电信波长光学跃迁和约1/2的自旋量子数，是理想的候选者，但寻找能够实现异质器件集成并保持长光学和自旋相干性的宿主材料仍然是一个挑战。

Method: 通过实验和理论计算相结合，研究了掺杂Erbium离子的二氧化铈薄膜在硅基底上的量子特性，重点关注其光学和自旋相干性，并利用动态解耦技术延长了自旋相干时间，通过簇相关展开计算确定了主要的退相干机制。

Result: 在掺杂Erbium离子的二氧化铈薄膜上实现了38.8微秒的自旋相干时间，通过动态解耦技术可延长至176.4微秒，并确定了光谱扩散导致的Erbium离子自旋翻转是主要的退相干机制。

Conclusion: Erbium离子掺杂二氧化铈薄膜是一种有前途的量子网络平台，它在硅基底上实现了长达176.4微秒的自旋相干性，并指出了提升至毫秒级相干性的方法。

Abstract: Developing telecom-compatible spin-photon interfaces is essential towards
scalable quantum networks. Erbium ions (Er$^{3+}$) exhibit a unique combination
of a telecom (1.5 $\mu$m) optical transition and an effective spin-$1/2$ ground
state, but identifying a host that enables heterogeneous device integration
while preserving long optical and spin coherence remains an open challenge. We
explore a new platform of Er$^{3+}$:CeO$_2$ films on silicon, offering low
nuclear spin density and the potential for on-chip integration. We demonstrate
a 38.8 $\mu$s spin coherence, which can be extended to 176.4\nobreakspace
$\mu$s with dynamical decoupling. Pairing experiments with cluster correlation
expansion calculations, we identify spectral diffusion-induced Er$^{3+}$ spin
flips as the dominant decoherence mechanism and provide pathways to
millisecond-scale coherence.

</details>


### [307] [Excitation Gaps of Ground and Excited State Energy of the Fermi-Hubbard Model Using Variational Quantum Eigensolver](https://arxiv.org/abs/2508.12307)
*Mrinal Dev,Bikash K. Behera,Vivek Vyas,Prasanta K. Panigrahi*

Main category: quant-ph

TL;DR: A new quantum circuit ansatz and hybrid optimization were used to accurately calculate Hubbard model energies, aiding in the understanding of correlated electron systems and quantum computing.


<details>
  <summary>Details</summary>
Motivation: Accurate computation of ground and excited state energies of the Hubbard model is essential for understanding correlated electron systems, and the Hubbard model serves as a benchmark for quantum computing research.

Method: A new ansatz circuit combining Hamiltonian Variational Ansatz (HVA) and Number-Preserving Ansatz (NPA) was designed. A hybrid optimization strategy using COBYLA for coarse convergence and L-BFGS for fine-tuning was applied. Energies and physical properties were analyzed through phase diagrams of energy excitation gaps.

Result: The ground, first, and second excited state energies of 4x1 and 2x2 Hubbard lattices were obtained and analyzed, along with phase diagrams illustrating physical properties.

Conclusion: The study successfully obtained ground and excited state energies for 4x1 and 2x2 Hubbard lattices using a novel ansatz circuit.

Abstract: The Hubbard model is a challenging quantum many-body problem and serves as a
benchmark for quantum computing research. Accurate computation of its ground
and excited state energies is essential for understanding correlated electron
systems. In this study, the ground, first, and second excited state energies of
4$\times$1 and 2$\times$2 Hubbard lattices are obtained using a newly designed
ansatz circuit. The ansatz is constructed by combining concepts from the
Hamiltonian Variational Ansatz (HVA) and the Number-Preserving Ansatz (NPA). A
hybrid optimization strategy is applied, where COBYLA is used for coarse
convergence and L-BFGS for fine-tuning. The resulting energies are evaluated,
and the corresponding physical properties of the systems are analyzed through
phase diagrams of the energy excitation gaps for different charge and spin
configurations.

</details>


### [308] [Generalized Number-Phase Lattice Encoding of a Bosonic Mode for Quantum Error Correction](https://arxiv.org/abs/2508.12354)
*Dong-Long Hu,Weizhou Cai,Chang-Ling Zou,Ze-Liang Xiang*

Main category: quant-ph

TL;DR: New bosonic quantum error correction codes utilizing number-phase symmetries outperform traditional methods, especially against dephasing noise, with potential applications in quantum communication and computation.


<details>
  <summary>Details</summary>
Motivation: To overcome the limitations of previous bosonic quantum error correction studies that were restricted to quadrature phase space symmetries, and to leverage the large Hilbert space of bosonic modes for redundant quantum information encoding.

Method: Introduced a unified framework for encoding a qubit using symmetries in the number and phase variables of a bosonic mode, creating lattice structures in the number-phase space (rectangular, oblique, and diamond codes).

Result: Developed new bosonic codes (oblique and diamond) that exhibit a number-phase vortex effect, where number-shift errors act as phase rotations, allowing for efficient error correction through phase measurements. These codes demonstrate superior performance against dephasing noise compared to conventional quadrature codes.

Conclusion: Bosonic codes based on number-phase symmetries offer significant advantages over conventional quadrature codes for quantum error correction, especially against dephasing noise in potential one-way quantum communication applications. These generalized number-phase codes open new avenues for fault-tolerant quantum computation and extended quantum communication range using bosonic systems.

Abstract: Bosonic systems offer unique advantages for quantum error correction, as a
single bosonic mode provides a large Hilbert space to redundantly encode
quantum information. However, previous studies have been limited to exploiting
symmetries in the quadrature phase space. Here we introduce a unified framework
for encoding a qubit utilizing the symmetries in the phase space of number and
phase variables of a bosonic mode. The logical codewords form lattice
structures in the number-phase space, resulting in rectangular, oblique, and
diamond-shaped lattice codes. Notably, oblique and diamond codes exhibit a
number-phase vortex effect, where number-shift errors induce discrete phase
rotations as syndromes, enabling efficient correction via phase measurements.
These codes show significant performance advantages over conventional
quadrature codes against dephasing noise in the potential one-way quantum
communication applications. Our generalized number-phase codes open up new
possibilities for fault-tolerant quantum computation and extending the quantum
communication range with bosonic systems.

</details>


### [309] [High-Accuracy Temporal Prediction via Experimental Quantum Reservoir Computing in Correlated Spins](https://arxiv.org/abs/2508.12383)
*Yanjun Hou,Juncheng Hua,Ze Wu,Wei Xia,Yuquan Chen,Xiaopeng Li,Zhaokai Li,Xinhua Peng,Jiangfeng Du*

Main category: quant-ph

TL;DR: 量子储层计算利用量子效应提升机器学习性能。本研究通过量子自旋系统实现了一种创新的量子储层计算，在长期天气预报等现实任务中，其性能超越了大规模经典模型。


<details>
  <summary>Details</summary>
Motivation: 为了在机器学习应用中发挥量子效应的潜力，克服经典模拟量子动力学的指数级成本。

Method: 利用量子自旋系统的自然量子多体相互作用产生储层动力学，并通过实验验证了其优越性。

Result: 在标准时间序列基准测试中，本研究提出的9自旋量子储层相比于具有数千个节点的经典储层，在长期天气预报任务上实现了更高的预测精度，预测误差降低了一到两个数量级。

Conclusion: 本研究提出了一种基于关联量子自旋系统的量子储层计算方法，成功实现了量子机器学习超越大规模经典模型在现实任务中的性能。

Abstract: Physical reservoir computing provides a powerful machine learning paradigm
that exploits nonlinear physical dynamics for efficient information processing.
By incorporating quantum effects, quantum reservoir computing gains superior
potential in machine learning applications, for the quantum dynamics are
exponentially costly to simulate classically. Here, we present a novel quantum
reservoir computing approach based on correlated quantum spin systems,
exploiting natural quantum many-body interactions to generate reservoir
dynamics, thereby circumventing the practical challenges of deep quantum
circuits. Our experimental implementation supports nontrivial quantum
entanglement and exhibits sufficient dynamical complexity for high-performance
machine learning. We achieve state-of-the-art performance in experiments on
standard time-series benchmarks, reducing prediction error by one to two orders
of magnitude compared to previous quantum reservoir experiments. In long-term
weather forecasting, our 9-spin quantum reservoir delivers greater prediction
accuracy than classical reservoirs with thousands of nodes. This represents a
first experimental demonstration of quantum machine learning outperforming
large-scale classical models on real-world tasks.

</details>


### [310] [Quantum Flow Matching](https://arxiv.org/abs/2508.12413)
*Zidong Cui,Pan Zhang,Ying Tang*

Main category: quant-ph

TL;DR: 量子流匹配（QFM）是一种新的量子生成模型，可以有效地在两个密度矩阵之间进行插值，并在各种量子应用中显示出前景。


<details>
  <summary>Details</summary>
Motivation: 将流匹配的生成模型范式扩展到量子领域，以实现两个密度矩阵之间的有效插值。

Method: 提出了一种名为量子流匹配（QFM）的量子电路实现方法，实现了两个密度矩阵之间的有效插值。

Result: QFM能够系统地制备密度矩阵和生成用于精确估计可观测量的样本，并且可以在无需昂贵电路重新设计的情况下在量子计算机上实现。已通过生成具有特定磁化和纠缠熵的目标态、估计非平衡自由能差以检验量子Jarzynski等式以及加速超扩散分解研究等应用验证了其多功能性。

Conclusion: QFM是一种统一且有前途的量子系统生成建模框架。

Abstract: Flow matching has rapidly become a dominant paradigm in classical generative
modeling, offering an efficient way to interpolate between two complex
distributions. We extend this idea to the quantum realm and introduce Quantum
Flow Matching (QFM)-a fully quantum-circuit realization that offers efficient
interpolation between two density matrices. QFM offers systematic preparation
of density matrices and generation of samples for accurately estimating
observables, and can be realized on a quantum computer without the need for
costly circuit redesigns. We validate its versatility on a set of applications:
(i) generating target states with prescribed magnetization and entanglement
entropy, (ii) estimating nonequilibrium free-energy differences to test the
quantum Jarzynski equality, and (iii) expediting the study on superdiffusion
breakdown. These results position QFM as a unifying and promising framework for
generative modeling across quantum systems.

</details>


### [311] [SimQFL: A Quantum Federated Learning Simulator with Real-Time Visualization](https://arxiv.org/abs/2508.12477)
*Ratun Rahman,Atit Pokharel,Md Raihan Uddin,Dinh C. Nguyen*

Main category: quant-ph

TL;DR: SimQFL 是一个为量子费学习设计的定制化模拟器，解决了现有模拟器在机器学习集成、用户自定义和实时可视化方面的不足，能够加速和简化量子费学习实验。


<details>
  <summary>Details</summary>
Motivation: 现有的量子模拟器缺乏对机器学习任务（如训练、评估和优化）的集成支持，并且在支持用户自定义数据、实时更新和可视化方面存在不足，给量子费学习实验带来了困难和资源密集的问题。

Method: 介绍并实现了一个名为 SimQFL 的定制化量子费学习模拟器。

Result: SimQFL 支持实时、分轮次的输出开发和可视化，提供用户友好的界面，允许用户自定义各种参数（如 epoch 数量、学习率、客户端数量、量子比特数、量子层数等），并提供即时反馈和动态学习曲线。

Conclusion: SimQFL 是一个实用的、交互式的平台，使研究人员和开发人员能够在分布式量子网络中更透明、更可控地进行量子神经网络的原型设计、分析和调优。

Abstract: Quantum federated learning (QFL) is an emerging field that has the potential
to revolutionize computation by taking advantage of quantum physics concepts in
a distributed machine learning (ML) environment. However, the majority of
available quantum simulators are primarily built for general quantum circuit
simulation and do not include integrated support for machine learning tasks
such as training, evaluation, and iterative optimization. Furthermore,
designing and assessing quantum learning algorithms is still a difficult and
resource-intensive task. Real-time updates are essential for observing model
convergence, debugging quantum circuits, and making conscious choices during
training with the use of limited resources. Furthermore, most current
simulators fail to support the integration of user-specific data for training
purposes, undermining the main purpose of using a simulator. In this study, we
introduce SimQFL, a customized simulator that simplifies and accelerates QFL
experiments in quantum network applications. SimQFL supports real-time,
epoch-wise output development and visualization, allowing researchers to
monitor the process of learning across each training round. Furthermore, SimQFL
offers an intuitive and visually appealing interface that facilitates ease of
use and seamless execution. Users can customize key variables such as the
number of epochs, learning rates, number of clients, and quantum
hyperparameters such as qubits and quantum layers, making the simulator
suitable for various QFL applications. The system gives immediate feedback
following each epoch by showing intermediate outcomes and dynamically
illustrating learning curves. SimQFL is a practical and interactive platform
enabling academics and developers to prototype, analyze, and tune quantum
neural networks with greater transparency and control in distributed quantum
networks.

</details>


### [312] [A Ramsey Ion Gradiometer for Single-Molecule State Detection](https://arxiv.org/abs/2508.12499)
*Sean D. Huver*

Main category: quant-ph

TL;DR: QLI是一种量子传感解决方案，通过无标记检测单个配体-受体结合的电场梯度，克服了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 目前的药理学方法存在系综平均和侵入性标记等局限性，因此需要新的表征配体-受体相互作用的方法。

Method: QLI是一个差分传感器（梯度计），使用一对共同捕获的原子离子，通过测量单个配体与其受体结合时产生的电场梯度，实现无标记检测。

Result: QLI有望实现单分子检测，在10μm离子-样品分离的情况下，在几十秒内实现信噪比为1的测量，但可行性受限于玻璃化样品的静电稳定性。

Conclusion: QLI将提供对结合诱导的电场变化的直接单分子测量，为计算模型提供新的实验验证途径。

Abstract: The characterization of ligand--receptor interactions is a cornerstone of
modern pharmacology; however, current methods are hampered by limitations such
as ensemble averaging and invasive labeling. We propose a theoretical quantum
sensing solution, the Quantum Ligand-Binding Interrogator (QLI), designed to
overcome these challenges. The QLI is a differential sensor, or gradiometer,
that uses a pair of co-trapped atomic ions to perform label-free detection of
the electric field gradient produced by a single ligand binding to its receptor
in vitrified samples. This gradiometric approach provides robust common-mode
rejection of background electric field noise. To bridge the gap between the
cryogenic, ultra-high-vacuum environment required for the sensor and the
biological sample, we propose an architecture based on a vitrified sample
mounted on a scanning probe. This enables the detection of the electrostatic
signature of a single molecule in a specific conformational state (e.g., bound
vs.\ unbound). This paper details the conceptual framework of the QLI, the
experimental architecture, the measurement protocol using entangled two-ion
spin states, and an analysis of key engineering risks. Anchoring to
state-of-the-art single-ion low-frequency sensitivities
(sub-mV\,m$^{-1}$/\,$\sqrt{\mathrm{Hz}}$), we project SNR\,=\,1 in tens of
seconds at a 10\,\textmu m ion--sample separation for $\Delta p \sim 20$\,D,
with feasibility dominated by the (as yet unmeasured) electrostatic stability
of vitrified samples. If realized, QLI would provide direct single-molecule
measurements of binding-induced electric field changes, offering a new path for
experimental validation of computational models of drug--receptor interactions.

</details>


### [313] [Perfect State Transfer of Mixed States and Purification in Central Spin Systems](https://arxiv.org/abs/2508.12515)
*Matthew Wampler,Nigel R. Cooper*

Main category: quant-ph

TL;DR: 通过集体相互作用，可以交换两个量子态。


<details>
  <summary>Details</summary>
Motivation: 展示了两个多体、通常是混合的量子态如何通过集体、全对全相互作用进行交换。

Method: 通过将问题映射到一维链上的完美状态传输来实现。

Result: 在部分极化极限下，证明了状态可以独立于初始状态进行交换，并评估了该过程对退相干和错误的鲁棒性。

Conclusion: 该过程还可用于核自旋纯化。

Abstract: We show how two many-body, generally mixed, quantum states can be swapped via
collective, all-to-all interactions. Specifically, we present an experimentally
relevant implementation for quantum dots that enables coherent exchange of
quantum information between different species of nuclear spins, effectively
achieving a perfect swap gate for qudits formed from these different species.
This process also serves as a tool for nuclear spin purification. The results
are obtained by mapping the problem onto perfect state transfer on a 1D chain.
In the partially polarized limit, we demonstrate that the states can be
exchanged independently of the initial state. We also assess the robustness of
the procedure to decoherence and errors.

</details>


### [314] [Adaptive-basis sample-based neural diagonalization for quantum many-body systems](https://arxiv.org/abs/2508.12724)
*Simone Cantori,Luca Brodoloni,Edoardo Recchi,Emanuele Costa,Bruno Juliá-Díaz,Sebastiano Pilati*

Main category: quant-ph

TL;DR: 使用神经元网络增强的样本基对角化 (SND 和 AB-SND) 方法可以更准确地估计量子多体系统的基态能量，AB-SND 效果尤为显著。


<details>
  <summary>Details</summary>
Motivation: 准确估计量子多体系统的基态能量由于希尔伯特空间随系统大小呈指数增长而仍然是一个挑战。SBD 方法通过将哈密顿量投影到由选定的一组基态配置构成的子空间上来解决此问题。

Method: 介绍了两种神经元网络增强的 SBD 方法：SND 和 AB-SND。两者都使用自回归神经元网络来有效地采样相关的基态配置。AB-SND 进一步优化了参数化的基态变换，以使基态波函数更加集中。考虑了单自旋和非重叠双自旋旋转等基态变换，以及可以使用量子电路实现的全局酉变换。

Result: SND 在基态集中的情况下实现了高精度。AB-SND 在各种量子伊辛模型上都优于 SND 和更传统的 SBD 方法。

Conclusion: AB-SND 优于 SND 和传统 SBD 方法，即使在原始计算基中基态不集中的情况下也能取得成果。

Abstract: Accurately estimating ground-state energies of quantum many-body systems is
still a challenging computational task because of the exponential growth of the
Hilbert space with the system size. Sample-based diagonalization (SBD) methods
address this problem by projecting the Hamiltonian onto a subspace spanned by a
selected set of basis configurations. In this article, we introduce two neural
network-enhanced approaches for SBD: sample-based neural diagonalization (SND)
and adaptive-basis SND (AB-SND). Both employ autoregressive neural networks to
efficiently sample relevant basis configurations, with AB-SND additionally
optimizing a parameterized basis transformation so that the ground-state wave
function becomes more concentrated. We consider different classes of basis
transformations: single-spin and non-overlapping two-spin rotations, which are
tractable on classical computers, and also more expressive global unitaries
that can be implemented using quantum circuits. We demonstrate the
effectiveness of these techniques on various quantum Ising models, showing that
SND achieves high accuracy for concentrated ground states, while AB-SND
consistently outperforms both SND and more conventional SBD methods, allowing
entering regimes in which the ground state is not concentrated in the original
computational basis.

</details>


### [315] [Addressing Side-Channel Threats in Quantum Key Distribution via Deep Anomaly Detection](https://arxiv.org/abs/2508.12749)
*Junxuan Liu,Bingcheng Huang,Jialei Su,Qingquan Peng,Anqi Huang*

Main category: quant-ph

TL;DR: 本研究提出了一种创新的基于异常检测的机器学习模型，用于防御量子密钥分发（QKD）系统中的安全侧信道攻击。该模型无需昂贵的额外硬件，能够兼容现有系统，并且能够检测未知攻击，实验证明其准确率极高。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统量子密钥分发（QKD）系统安全侧信道对抗措施与已部署基础设施兼容性差、易引入新漏洞以及适用性有限等问题，本研究旨在提出一种更通用、更易部署且有效的解决方案。

Method: 本研究提出了一种基于单类机器学习算法的异常检测（AD）模型。该模型通过构建量子密钥分发（QKD）系统运行状态的数据集，学习安全条件下的正常行为特征。当发生攻击时，系统状态偏离学习到的正常模式，从而被模型识别为异常。

Result: 实验结果表明，所提出的AD模型达到了超过99%的曲线下面积（AUC），能够有效保障QKD系统的安全运行。与传统方法相比，该模型部署成本极低，无需额外的光或电元件，避免了引入新的侧信道。此外，与多类机器学习算法不同，该方法不依赖对特定攻击类型的先验知识，有潜力检测未知攻击。

Conclusion: 所提出的基于单类机器学习算法的异常检测（AD）模型能够有效保护量子密钥分发（QKD）系统的安全运行，并具有通用性、易部署、低成本和高准确性等优点，可以有效应对安全侧信道威胁。

Abstract: Traditional countermeasures against security side channels in quantum key
distribution (QKD) systems often suffer from poor compatibility with deployed
infrastructure, the risk of introducing new vulnerabilities, and limited
applicability to specific types of attacks. In this work, we propose an anomaly
detection (AD) model based on one-class machine learning algorithms to address
these limitations. By constructing a dataset from the QKD system's operational
states, the AD model learns the characteristics of normal behavior under secure
conditions. When an attack occurs, the system's state deviates from the learned
normal patterns and is identified as anomalous by the model. Experimental
results show that the AD model achieves an area under the curve (AUC) exceeding
99\%, effectively safeguarding the QKD system's secure operation. Compared to
traditional approaches, our model can be deployed with minimal cost in existing
QKD networks without requiring additional optical or electrical components,
thus avoiding the introduction of new side channels. Furthermore, unlike
multi-class machine learning algorithms, our approach does not rely on prior
knowledge of specific attack types and is potentially able to detect unknown
attacks. These advantages--generality, ease of deployment, low cost, and high
accuracy--make our model a practical and effective tool for protecting QKD
systems against side-channel threats.

</details>


### [316] [Application of Quantum Annealing to Computation of Molecular Properties](https://arxiv.org/abs/2508.12779)
*Pradyot Pritam Sahoo,V. S. Prasannaa,B. P. Das*

Main category: quant-ph

TL;DR: 量子退火可用于计算分子电偶极矩。


<details>
  <summary>Details</summary>
Motivation: 提出利用量子退火计算分子永电偶极矩。

Method: 通过施加电场作为扰动并测量相应的能量响应，利用量子退火器本征求解器算法获得基态电子波函数和能量，并通过有限域方法以数值方式获得分子电偶极矩。

Result: 我们提出了利用量子退火计算几种分子永电偶极矩的结果。

Conclusion: 本工作为量子退火范式下的分子属性计算提供了一条途径。

Abstract: We present the results of our quantum annealing computations of the permanent
electric dipole
  moments of several molecules. By applying an electric field as a perturbation
and measuring the
  corresponding energy responses, the molecular electric dipole moments are
obtained numerically
  through the finite field method. The ground-state electronic wavefunctions
and energies are obtained
  using the quantum annealer eignsolver algorithm. This work provides a pathway
for the computation
  of molecular properties in the quantum annealing paradigm.

</details>


### [317] [Detecting $k$-nonstretchability via a class of informationally complete symmetric measurements](https://arxiv.org/abs/2508.12817)
*Yan Hong,Mengjia Zhang,Limin Gao,Huaqi Zhou,Limei Zhang*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Multipartite entanglement characterization is a core problem in quantum
information theory, with several classification schemes available. Among these,
the $k$-stretchability, recently introduced [Szalay, Quantum 3, 204 (2019)],
can be used to describe multipartite entanglement structure. Recently, a class
of symmetric measurements (informationally complete $(s,t)$-POVMs) has been
proposed [Siudzi$\textrm{\'{n}}$ska, Phys. Rev. A \textbf{105}, 042209 (2022)]
, which includes GSIC-POVMs and MUMs. In this work, we discuss the detection of
$k$-nonstretchability based on informationally complete $(s,t)$-POVMs and
obtain some $k$-nonstretchability criteria for multipartite quantum systems. It
is shown that these criteria can identify certain $k$-nonstretchable states,
and their practical applicability and advantages are illustrated through
specific examples.

</details>


### [318] [Quantum State Preparation by Improved MPS Method](https://arxiv.org/abs/2508.12821)
*Chao Wang,Pengrui Zhou,Xi-Ning Zhuang,Ziwei Cui,Menghan Dou,Zhao-Yun Chen,Guo-Ping Guo*

Main category: quant-ph

TL;DR: 提出一种改进的MPS制备方法，可指数级减少电路深度并降低门数量，在金融等应用中保真度更高。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有量子算法中高效编码经典信息，特别是制备任意幅度编码状态所面临的时间消耗和在噪声设备上部署的挑战。

Method: 提出了一种改进的矩阵乘积状态（MPS）制备协议，利用了“解缠绕”原理，实现了电路深度的指数级减少和约33%的双量子比特门数量的减少，并具有拓扑适应性。

Result: 通过对各种函数和分布进行数值实验验证，证明了所提出的方法能够显著减少电路深度，并在金融和其他应用中产生的状态方面实现更高的保真度。

Conclusion: 所提出的基于MPS的制备方法在减少电路深度和双量子比特门数量方面表现出色，同时在金融等领域的应用中实现了更高的保真度。

Abstract: Efficient encoding of classical information plays a fundamental role in
numerous practical quantum algorithms. However, the preparation of an arbitrary
amplitude-encoded state has been proven to be time-consuming, and its
deployment on current noisy devices can be challenging. In this work, we
propose an improved Matrix Product State(MPS) method preparation protocol with
an exponential reduction on the circuit depth, as well as topological
adaptability. By refined utilization of the disentangling principle, we also
reduce approximately 33% two-qubit gate count. To validate our method, we study
various families of functions and distributions with provably bounded MPS rank.
Numerical experiments show that our method significantly reduces circuit depth
while achieving higher fidelity for states arising in financial and other
applications.

</details>


### [319] [Graybox characterization and calibration with finite-shot estimation on superconducting-qubit experiments](https://arxiv.org/abs/2508.12822)
*Poramet Pathumsoot,Areeya Chantasri,Michal Hajdušek,Rodney Van Meter*

Main category: quant-ph

TL;DR: 本研究提出了一种结合物理模型和深度学习的Graybox方法，用于量子设备表征和门校准，特别适用于有限样本数据的情况，并分析了有限样本估计对模型性能的影响。


<details>
  <summary>Details</summary>
Motivation: 为了实现容错量子计算，对量子设备进行表征和校准是必要的步骤。随着量子设备的日益复杂，越来越需要依赖物理模型和具有开环优化的预测模型。

Method: 我们采用了一种名为“Graybox”的方法，结合了显式（白盒）模型和隐式（黑盒）神经网络模型，来表征和校准超导量子比特设备。通过向设备发送选定的脉冲并测量泡利期望值，Graybox 方法可以训练隐式模型并基于指定的损失函数优化门。我们还对设备上的优化门进行了基准测试，并使用两种类型的损失函数（期望值的均方误差MSE和平均门保真度AGF的绝对误差AE）对预测模型进行了交叉测试。

Result: 我们通过分解期望MSE损失表明，期望值的有限样本估计是可实现的最小期望MSE损失的主要贡献。我们还证明了期望损失是准确值与模型预测之间的AGF的期望绝对误差的上限。

Conclusion: 我们的研究结果为量子设备表征和门优化提供了见解，尤其是在只能获取有限样本数据的实验中。

Abstract: Characterization and calibration of quantum devices are necessary steps to
achieve fault-tolerant quantum computing. As quantum devices become more
sophisticated, it is increasingly essential to rely not only on physics-based
models, but also on predictive models with open-loop optimization. Therefore,
we choose the Graybox approach, which is composed of an explicit (whitebox)
model describing the known dynamics and an implicit (blackbox) model describing
the noisy dynamics in the form of a deep neural network, to characterize and
calibrate superconducting-qubit devices. By sending a set of selected pulses to
the devices and measuring Pauli expectation values, the Graybox approach can
train the implicit model and optimize gates based on specified loss functions.
We also benchmark our optimized gates on the devices and cross-testing
predictive models with two types of loss functions, i.e., the mean squared
errors (MSE) of expectation values and the absolute errors (AE) of average gate
fidelities (AGF). While the Graybox method allows for flexibility of the
implicit noise model, its construction relies on a finite measurement shots
dataset. We thus apply the decomposition of expected MSE loss to show that the
finite-shot estimation of expectation values is the main contribution to the
minimum value achievable of the expected MSE loss. We also show that the
expected loss is an upper bound of the expected absolute error of AGF between
the exact value and model prediction. Our results provide insights for quantum
device characterization and gate optimization in experiments where only finite
shots of data are available.

</details>


### [320] [BELT: Block Encoding of Linear Transformation on Density Matrices](https://arxiv.org/abs/2508.12858)
*Fuchuan Wei,Rundi Lu,Yuguo Shao,Junfeng Li,Jin-Peng Liu,Zhengwei Liu*

Main category: quant-ph

TL;DR: BELT 协议通过将非完全正线性图嵌入酉算子块中，克服了量子信息中非完全正线性图的物理实现挑战，并在各种应用中表现出优越的性能。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是解决量子信息中非完全正线性图难以物理实现的问题，这些图在量子信息研究中至关重要，但由于其输出可能不对应于有效的密度矩阵，因此难以在物理系统中直接制备。

Method: BELT 通过将非完全正线性图的输出嵌入到酉算子的块中来模拟这些图，从而允许通过相干量子演化进行操作和信息提取。

Result: BELT 能够模拟任意线性图，包括量子奇异值变换范围之外的图（例如，转置图），并在纠缠检测、量子通道反演和模拟伪微分算子等应用中展示了比基于厄米保持图指数化的协议更高的样本复杂度。

Conclusion: BELT 是一种系统性协议，通过将任意线性图的输出嵌入到酉算子的块中来模拟它们，从而克服了量子信息中非完全正线性图的物理实现挑战。

Abstract: Linear maps that are not completely positive play a crucial role in the study
of quantum information, yet their non-completely positive nature renders them
challenging to realize physically. The core difficulty lies in the fact that
when acting such a map $\mathcal{N}$ on a state $\rho$, $\mathcal{N}(\rho)$ may
not correspond to a valid density matrix, making it difficult to prepare
directly in a physical system. We introduce Block Encoding of Linear
Transformation (BELT), a systematic protocol that simulates arbitrary linear
maps by embedding the output $\mathcal{N}(\rho)$ into a block of a unitary
operator. BELT enables the manipulation and extraction of information about
$\mathcal{N}(\rho)$ through coherent quantum evolution. Notably, BELT
accommodates maps that fall outside the scope of quantum singular value
transformation, such as the transpose map. BELT finds applications in
entanglement detection, quantum channel inversion, and simulating
pseudo-differential operators, and demonstrates improved sample complexity
compared to protocols based on Hermitian-preserving map exponentiation.

</details>


### [321] [Coherence of Microwave and Optical Qubit Levels in Neutral Thulium](https://arxiv.org/abs/2508.12887)
*Denis Mishin,Dmitry Tregubov,Nikolay Kolachevsky,Artem Golovizin*

Main category: quant-ph

TL;DR: Thulium is a promising new platform for quantum computing, showing record coherence times and versatile state manipulation capabilities.


<details>
  <summary>Details</summary>
Motivation: To explore thulium as a potential platform for quantum computing, leveraging its hyperfine qubit encoding and rich energy-level structure.

Method: The paper describes protocols for initial state preparation and state-selective readout, and demonstrates single-qubit operations on the microwave transition at 1497 MHz. It also shows operations involving metastable optical states, including shelving for state-selective readout and coherent population transfer.

Result: Demonstrated ground state hyperfine qubit coherence times up to T2* = 22+/-2 s and T2 = 55+59-14 s, record-scale performance for neutral-atom systems. Showed operations involving metastable optical states, with coherence time limited by the metastable level natural lifetime of 112 ms.

Conclusion: This work demonstrates that thulium is a viable candidate for quantum computing, combining advantages of hyperfine qubit encoding with a rich energy-level structure of alkaline-earth-like atoms.

Abstract: Hyperfine-encoded qubits in alkali atoms have established themselves as
robust platforms for quantum computing, while alkaline-earth-like elements
expand the state manipulation toolbox through their rich spectrum of optical
transitions and metastable states. In this work, we demonstrate that thulium is
a viable candidate for quantum computing, combining advantages of hyperfine
qubit encoding with a rich energy-level structure of alkaline-earth-like atoms.
We describe protocols for the initial state preparation and state-selective
readout, and show single-qubit operations on the microwave transition at $1
497$ MHz. We demonstrate ground state hyperfine qubit coherence times up to
$T_2^* = 22^{+2}_{-2}$ s and $T_2 = 55^{+59}_{-14}$ s, representing
record-scale performance for neutral-atom systems. Furthermore, we show
operations involving metastable optical states, including shelving for the
state-selective readout as well as coherent population transfer of the ground
state qubit with coherence time primarily limited by the metastable level
natural lifetime of $112$ ms. These results mark the first step toward using
thulium for quantum computing applications and highlight its promising
characteristics.

</details>


### [322] [Generalized quantum Chernoff bound](https://arxiv.org/abs/2508.12889)
*Kun Fang*

Main category: quant-ph

TL;DR: 本研究将量子Chernoff界推广到区分多个量子态集合的场景，并提出了一个通用的最优测试，该测试能够针对集合中的所有状态实现最小误差概率。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在将经典的Chernoff界和量子Chernoff界推广到更一般的复合和相关量子假设检验场景，以解决区分多个量子态集合的挑战。

Method: 我们使用量子Chernoff散度和极小极大定理来分析区分多个量子态集合的问题。具体来说，我们推导了量子Chernoff散度的正则化形式，并将其与区分这些集合的误差指数联系起来。我们还利用极小极大定理证明了区分集合的难度界限，并提出了一个通用的最优测试。

Result: 我们成功地将量子Chernoff界推广到区分多个量子态集合的场景，并证明了区分这些集合的误差指数由正则化量子Chernoff散度给出。我们还发现区分集合的难度不大于区分其最坏情况元素，并且存在一个通用的最优测试。

Conclusion: 我们证明了区分具有任意相关性的多个量子态集合的渐进最优误差指数由这些集合之间的正则化量子Chernoff散度给出。此外，我们证明了区分这些集合的难度不大于区分其最坏情况元素，并且存在一个通用的最优测试，该测试能够针对集合中的所有状态实现最小误差概率。

Abstract: We establish a generalized quantum Chernoff bound for the discrimination of
multiple sets of quantum states, thereby extending the classical and quantum
Chernoff bounds to the general setting of composite and correlated quantum
hypotheses. Specifically, we consider the task of distinguishing whether a
quantum system is prepared in a state from one of several convex, compact sets
of quantum states, each of which may exhibit arbitrary correlations. Assuming
their stability under tensor product, we prove that the optimal error exponent
for discrimination is precisely given by the regularized quantum Chernoff
divergence between the sets. Furthermore, leveraging minimax theorems, we show
that discriminating between sets of quantum states is no harder than
discriminating between their worst-case elements in terms of error probability.
This implies the existence of a universal optimal test that achieves the
minimum error probability for all states in the sets, matching the performance
of the optimal test for the most challenging states. We provide explicit
characterizations of the universal optimal test in the binary composite case.
Finally, we show that the maximum overlap between a pure state and a set of
free states, a quantity that frequently arises in quantum resource theories, is
equal to the quantum Chernoff divergence between the sets, thereby providing an
operational interpretation of this quantity in the context of symmetric
hypothesis testing.

</details>


### [323] [Error exponents of quantum state discrimination with composite correlated hypotheses](https://arxiv.org/abs/2508.12901)
*Kun Fang*

Main category: quant-ph

TL;DR: 本研究将量子假设检验中的错误指数分析扩展到复合和相关假设，并推广了量子Hoeffding边界，为理解量子态判别中的错误权衡提供了新见解。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在将量子假设检验的错误指数分析从独立同分布情况扩展到更广泛的复合和相关假设，以更深入地理解量子态判别中的错误权衡。

Method: 本研究引入并比较了量子Hoeffding散度和反散度到量子态集合的两个自然扩展，并建立了它们的等价性或定量关系。主要结果将量子Hoeffding边界推广到稳定序列的凸、紧量子态集合，并证明了在II类错误指数约束下，I类错误最优指数可以由集合间的正则化量子Hoeffding散度精确表征。在强对抗过程中，研究提供了正则化量子Hoeffding反散度形式的指数下界。

Result: 研究结果精炼了广义量子Stein引理，并对具有复合相关假设的判别中I类和II类错误之间的权衡进行了详细阐述。

Conclusion: 本研究将量子假设检验中的错误指数扩展到复合和相关假设，并推广了量子Hoeffding边界。

Abstract: We study the error exponents in quantum hypothesis testing between two sets
of quantum states, extending the analysis beyond the independent and
identically distributed case to encompass composite and correlated hypotheses.
We introduce and compare two natural extensions of the quantum Hoeffding
divergence and anti-divergence to sets of quantum states, establishing their
equivalence or quantitative relationships. Our main results generalize the
quantum Hoeffding bound to stable sequences of convex, compact sets of quantum
states, demonstrating that the optimal type-I error exponent, under an
exponential constraint on the type-II error, is precisely characterized by the
regularized quantum Hoeffding divergence between the sets. In the strong
converse regime, we provide a lower bound on the exponent in terms of the
regularized quantum Hoeffding anti-divergence. These findings refine the
generalized quantum Stein's lemma and yield a detailed understanding of the
trade-off between type-I and type-II errors in discrimination with composite
correlated hypotheses.

</details>


### [324] [Modified security analysis of device-independent quantum key distribution with random key basis](https://arxiv.org/abs/2508.12938)
*Sawan Bhattacharyya,Turbasu Chatterjee,Pankaj Agrawal,Prasenjit Deb*

Main category: quant-ph

TL;DR: 本研究通过优化方法改进了DIQKD的安全分析，降低了计算成本，并提高了分析的严谨性。


<details>
  <summary>Details</summary>
Motivation: 现有DIQKD协议的安全分析中的优化问题求解成本较高，本文旨在降低其优化成本，同时不影响密钥率。

Method: 将DIQKD随机密钥归道协议的安全分析重构为强凸优化问题，并推导出优化测量角度时产生的悲观误差的显式形式。

Result: 在不影响密钥率的前提下，降低了DIQKD随机密钥归道协议现有安全分析的优化成本，并使分析更加严谨和完整。

Conclusion: 该研究通过将安全分析重构为强凸优化问题，并推导了优化测量角度时产生的悲观误差的显式形式，从而使随机密钥归道设备无关的量子密钥分发（DIQKD）的安全分析更加严谨和完整。

Abstract: Security analysis is a critical part in any cryptographic protocol, may it be
classical or quantum. Without security analysis, one cannot ensure the secrecy
of the distributed keys. To perform a conclusive security analysis, it is very
often necessary to frame the problem as an optimization problem. However,
solving such optimization problems is quite challenging. In this article, we
focus on the security analysis of device-independent quantum key distribution
(DIQKD) with random key basis protocol. We show that the optimization cost of
the existing security analysis can be reduced without compromising the key
rate. In particular, we reframe the entire security analysis of this protocol
as a strongly convex optimization problem and demonstrate that unlike the
original security proof, optimization of Bob's measurement angles for finding a
lower bound on Eve's uncertainty about Alice's key generation basis can be done
with lesser cost. We derive an explicit form of the pessimistic error that
arises while optimizing the measurement angles of both the parties. We also
clarify a few parts of the original security proof, making the analysis more
rigorous and complete.

</details>


### [325] [Interference in Quantum Mechanics](https://arxiv.org/abs/2508.12940)
*Debadrita Ghosh,Urbasi Sinha*

Main category: quant-ph

TL;DR: Quantum interference is key to understanding quantum mechanics, with this paper reviewing its various forms and implications.


<details>
  <summary>Details</summary>
Motivation: To explain the counterintuitive quantum phenomena through the lens of interference, as suggested by Richard Feynman.

Method: Review of quantum interference phenomena.

Result: Discussion of single-photon, two-photon, and higher-order interference.

Conclusion: The paper focuses on the ramifications and manifestations of quantum interference, including single-photon, two-photon, and higher-order interference, highlighting their implications for the foundations of quantum mechanics.

Abstract: Physicist and Nobel Laureate Richard P. Feynman once remarked ``We choose to
examine a phenomenon which is impossible, absolutely impossible, to explain in
any classical way, and which has in it the heart of quantum mechanics. In
reality, it contains the only mystery. We cannot make the mystery go away by
``explaining'' how it works. We will just tell you how it works. In telling you
how it works, we will have told you about the basic peculiarities of all
quantum mechanics'' [Feynman RP, Leighton RB, Sands M (1963 and 1965)]. The
phenomenon of interference is ubiquitous in the quantum world and indeed holds
within itself the explanation for many counterintuitive quantum phenomena. In
this review, we choose to focus on a few ramifications and manifestations of
quantum interference that have deep implications for the foundations of quantum
mechanics. These include single-photon or second-order interference, two-photon
or fourth-order interference and higher-order interference.

</details>


### [326] [Symmetric orthogonalization and probabilistic weights in resource quantification](https://arxiv.org/abs/2508.12949)
*Gökhan Torun*

Main category: quant-ph

TL;DR: LSO是一种优于GSO的正交化方法，能更好地表征量子资源，并引入Löwdin权重用于量化。


<details>
  <summary>Details</summary>
Motivation: 在量子系统中，将非正交基转换为正交基通常会牺牲重要的性质或物理意义。需要一种能够更好保持这些特性的正交化方法。

Method: 使用LSO将非正交基转换为正交基，或将正交集转换为非正交基，并引入Löwdin权重来量化相干性和状态离域性。

Result: LSO能够生成具有增强的稳定性和物理相关性的基集，促进对非正交量子态中叠加的分析。Löwdin权重提供了与基无关的相干性和状态离域性量化方法。

Conclusion: LSO（Löwdin对称正交化）优于GSO（Gram-Schmidt正交化），在表征和量化量子资源（特别是相干性和叠加性）方面，能够更好地保持量子态的对称性和资源特性，并且提出的Löwdin权重提供了量子相干性和状态离域性的统一度量。

Abstract: Transforming non-orthogonal bases into orthogonal ones often sacrifices
essential properties or physical meaning in quantum systems. Here, we
demonstrate that L\"owdin symmetric orthogonalization (LSO) outperforms the
widely used Gram-Schmidt orthogonalization (GSO) in characterizing and
quantifying quantum resources, with particular emphasis on coherence and
superposition. We employ LSO both to construct an orthogonal basis from a
non-orthogonal one and to obtain a non-orthogonal basis from an orthogonal set,
thereby avoiding any ambiguity related to the basis choice for quantum
coherence. Unlike GSO, which depends on the ordering of input states, LSO
applies a symmetric transformation that treats all vectors equally and
minimizes deviation from the original basis. This approach generates basis sets
with enhanced stability and physical relevance, facilitating the analysis of
superpositions in non-orthogonal quantum states. Building on LSO, we also
introduce L\"owdin weights -- probabilistic weights for non-orthogonal
representations that provide a consistent measure of resource content. These
weights further enable basis-independent quantification of coherence and state
delocalization through information-theoretic measures such as entropy and
participation ratios. Our theoretical and numerical analyses confirm LSO's
superior preservation of quantum state symmetry and resource characteristics,
underscoring the critical role of orthogonalization methods and L\"owdin
weights in resource theory frameworks.

</details>


### [327] [Free-space time-bin encoded quantum key distribution from near- to mid-infrared wavelengths](https://arxiv.org/abs/2508.13008)
*Claudia De Lazzari,Tecla Gabbrielli,Natalia Bruno,Francesco Cappelli,Domenico Ribezzo,Nicola Biagi,Nicola Corrias,Simone Borri,Mario Siciliani de Cumis,Paolo De Natale,Davide Bacco,Alessandro Zavatta*

Main category: quant-ph

TL;DR: 在中红外波长（>3μm）的弱相干态进行自由空间量子密钥分发，即使在恶劣天气下也比近红外波长表现更好。


<details>
  <summary>Details</summary>
Motivation: 探索在中红外波长实现量子密钥分发的优势，以建立新的量子安全通信方式。

Method: 通过模拟时间二元编码的量子密钥分发，并比较了在中红外波长和近红外波长下自由空间QKD链路在不同天气条件下的性能。

Result: 在中红外波长下，自由空间QKD链路的性能优于基于传统近红外波长的配置，尤其是在恶劣气象条件下。

Conclusion: 在不利气象条件下，使用中红外波长（>3μm）的弱相干态进行自由空间量子密钥分发（QKD）比使用传统近红外波长更优越。

Abstract: Quantum technologies play a central role in establishing new ways of
quantum-secured communication. We investigate Free-Space Quantum Communication
and explore the advantage of implementing Quantum Key Distribution (QKD) with
weak coherent states produced by a light source in the Mid-Infrared (>3$\mu$m).
We simulate time-bin encoded quantum key distribution and demonstrate that a
free-space QKD link operating in the Mid-infrared outperforms configurations
based on conventional near-infrared wavelengths under various weather
scenarios, with a particular significance in adverse meteorological conditions.

</details>


### [328] [Trading Quantum Ensembles](https://arxiv.org/abs/2508.13010)
*Junaid ur Rehman*

Main category: quant-ph

TL;DR: We help you trade quantum states by creating curves that rank their usefulness for different tasks.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the problem of choosing the best ensemble of quantum states for a given task when faced with limited resources, using a practical example of depolarized quantum states.

Method: The paper derives resource equivalence curves from quantum resource theory, considering purity, state distinguishability, purification, and tomography.

Result: The derived resource equivalence curves allow for the ranking of quantum state ensembles based on their operational usefulness for various tasks, enabling informed decisions about trading ensembles.

Conclusion: We derived resource equivalence curves from quantum resource theory of purity, quantum state distinguishability, quantum state purification, and quantum state tomography to rank and trade quantum state ensembles.

Abstract: We consider an example scenario where we require several copies of a pure
quantum state $|\psi\rangle$ for some quantum information processing task. Due
to practical limitations, we only have access to $N = 10^3$ depolarized copies
of $|\psi\rangle$ such that the fidelity $F$ of each copy with $|\psi\rangle$
is $0.75$. We denote this quantum asset with the ensemble $\mathcal{A}: (10^3,
0.75)_{|\psi\rangle}$. A genie appears and offers to trade $\mathcal{A}$ with
either $\mathcal{B}: (10^4, 0.65)_{|\psi\rangle}$ or with $\mathcal{C}: (10^2,
0.90)_{|\psi\rangle}$. Should we accept the trade with either of these two
ensembles? In this article, we attempt to answer this question with arbitrary
$N$ and $F$. More specifically, we derive resource equivalence curves from
quantum resource theory of purity, quantum state distinguishability, quantum
state purification, and quantum state tomography. These curves enable ranking
of these ensembles according to their operational usefulness for these tasks
and allow us to answer the question of trading the aforementioned ensembles.

</details>


### [329] [Dynamic syndrome decoder in volume-law phases of hybrid quantum circuits](https://arxiv.org/abs/2508.13045)
*Dawid Paszko,Marcin Szyniszewski,Arijeet Pal*

Main category: quant-ph

TL;DR: 该研究介绍了一种用于量子信息处理的“符号-颜色解码器”，能够从具有体积定律纠缠的量子态中解码初始状态，为量子纠错和密码学提供了新的途径。


<details>
  <summary>Details</summary>
Motivation: 填补了在具有纠缠的复杂量子信息和隐藏信息能力方面的空白，并探索了初始状态的可译性问题。

Method: 通过追踪稳定因子来解码初始状态，并提出了“符号-颜色解码器”，该解码器能够处理已知和未知错误位置的情况。

Result: 在一位和二维的克利福德电路由中引入了一种可译的体积定律相，信息检索可以在对数电路深度内完成。研究还揭示了可译性转变和测量诱导相转变之间的联系。

Conclusion: 该研究介绍了一种能在对数电路深度内检索信息的“符号-颜色解码器”，该解码器能够追踪揭示初始状态的稳定因子，类似于监控错误校正码的动态变化的综合征。研究结果为在具有中途电路测量的情况下使用体积定律状态作为编码器铺平了道路，这在量子纠错和量子密码学方面具有潜在的应用前景。

Abstract: Phases of matter with volume-law entanglement are frequently observed in
quantum circuits and have numerous applications, ranging from deepening our
understanding of quantum mechanics to advancements in quantum computing and
cryptography. Their capacity to host entangled, complex quantum information is
complemented by their ability to efficiently obscure it from quantum
measurements through scrambling, reminiscent of quantum error-correction.
However, the issue of initial-state decodability has primarily been studied in
measurement-only models with area-law phases, which limit the entanglement of
the encoded state. In this work, we introduce a class of Clifford circuits in
one and two dimensions that feature a decodable volume law phase, allowing for
information retrieval in logarithmic circuit depths. We present the Sign-Color
Decoder that tracks stabilizers revealing the initial state, akin to monitoring
a dynamically-changing syndrome for error-correcting codes. We demonstrate this
approach in scenarios where error locations are either known or unknown to the
decoder, and we provide new insights about the relationship between the
decodability transition and measurement-induced phase transition. We propose
that this decodability transition is universal across various settings,
including different circuit geometries. Our findings pave the way for using
volume law states as encoders with mid-circuit measurements, opening potential
applications in quantum error correction and quantum cryptography.

</details>


### [330] [Quantum Phase Estimation Beyond the Gaussian Limit](https://arxiv.org/abs/2508.13046)
*Kimin Park,Tanjung Krisnanda,Yvonne Gao,Radim Filip*

Main category: quant-ph

TL;DR: 非高斯状态，特别是相干态的不对称叠加（SCS），可以在近期量子传感中实现超越高斯极限的精度，并且研究量化了实际操作中的精度与优势范围之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 量子计量旨在提高测量精度，超越经典资源的基准——标准量子极限（SQL）。一个关键的里程碑是超越高斯极限，即高斯状态（如最佳压缩态）可实现的基本精度极限。某些非高斯状态（特别是相干态的不对称叠加（SCS）和真空态及福克态的叠加（ON态））可以在中等能量范围内超越高斯极限。

Method: 研究了非高斯状态，特别是相干态的不对称叠加（SCS）和真空态及福克态的叠加（ON态），在超越高斯极限方面的性能。分析了在实际损耗、噪声和检测方案下，可实现精度与非高斯优势运行范围之间的关键权衡。

Result: 非高斯状态，特别是相干态的不对称叠加（SCS），作为一种实用的资源，可以通过恒定复杂度的协议进行高效制备和处理，从而在近期量子传感架构中实现超越高斯极限的传感。

Conclusion: 该研究阐明了非高斯性与非对称性对量子计量任务的根本影响，并为在现实的近期量子增强传感器中利用这些资源提供了见解，以超越高斯极限。

Abstract: Quantum metrology aims to enhance measurement precision beyond the standard
quantum limit (SQL), the benchmark set by classical resources, enabling
advances in sensing, imaging, and fundamental physics. A critical milestone
beyond the SQL is surpassing the Gaussian bound -- the fundamental precision
limit achievable with any Gaussian state, such as optimally squeezed states.
Certain non-Gaussian states, specifically asymmetric superpositions of coherent
states (SCS) and superpositions of a vacuum and a Fock state (ON states), can
outperform this Gaussian bound within an intermediate energy range. In
particular, asymmetric SCS emerge as a highly practical resource for near-term
quantum sensing architectures operating beyond the Gaussian limit due to their
efficient preparation and processing via a constant-complexity protocol. Our
comprehensive analysis under realistic loss, noise, and detection schemes
quantifies the critical trade-off between achievable precision and the
operational range of the non-Gaussian advantage. This work sheds light on the
fundamental impact of non-Gaussianity and asymmetry on metrological tasks, and
offers insights on how to leverage such resources in realistic near-term
quantum enhanced sensors beyond the Gaussian limit.

</details>


### [331] [Quantum Relational Knowledge Distillation](https://arxiv.org/abs/2508.13054)
*Chen-Yu Liu,Kuan-Cheng Chen,Keisuke Murota,Samuel Yen-Chi Chen,Enrico Rinaldi*

Main category: quant-ph

TL;DR: QRKD是一种新的知识蒸馏方法，它利用量子计算来增强模型压缩，在保持经典部署的同时提高了性能。


<details>
  <summary>Details</summary>
Motivation: 知识蒸馏（KD）广泛用于模型压缩，而关系知识蒸馏（RKD）通过对齐特征空间中的关系结构（如成对距离和角度）来提升学生模型的性能。本研究提出QRKD，旨在通过结合量子关系信息来扩展RKD。

Method: QRKD将经典特征映射到希尔伯特空间，将其解释为量子态，并计算量子核值来捕捉更丰富的样本间关系，然后利用这些量子信息指导蒸馏过程。

Result: QRKD在MNIST、CIFAR-10（CNN）和WikiText-2、Penn Treebank、IMDB（GPT-2）等视觉和语言任务上都取得了优于经典RKD的学生模型性能提升。

Conclusion: QRKD通过在训练过程中结合量子计算来增强知识蒸馏，实现了在全经典部署设置下的性能提升，并且是首个实现此目标的方法。

Abstract: Knowledge distillation (KD) is a widely adopted technique for compressing
large models into smaller, more efficient student models that can be deployed
on devices with limited computational resources. Among various KD methods,
Relational Knowledge Distillation (RKD) improves student performance by
aligning relational structures in the feature space, such as pairwise distances
and angles. In this work, we propose Quantum Relational Knowledge Distillation
(QRKD), which extends RKD by incorporating quantum relational information.
Specifically, we map classical features into a Hilbert space, interpret them as
quantum states, and compute quantum kernel values to capture richer
inter-sample relationships. These quantum-informed relations are then used to
guide the distillation process. We evaluate QRKD on both vision and language
tasks, including CNNs on MNIST and CIFAR-10, and GPT-2 on WikiText-2, Penn
Treebank, and IMDB. Across all benchmarks, QRKD consistently improves student
model performance compared to classical RKD. Importantly, both teacher and
student models remain classical and deployable on standard hardware, with
quantum computation required only during training. This work presents the first
demonstration of quantum-enhanced knowledge distillation in a fully classical
deployment setting.

</details>


### [332] [Sheffer Polynomials and the s-ordering of Exponential Boson Operators](https://arxiv.org/abs/2508.13094)
*Robert S. Maier*

Main category: quant-ph

TL;DR: This paper calculates the s-ordered form of boson operator products using a special family of polynomials, generalizing quantum ordering methods.


<details>
  <summary>Details</summary>
Motivation: The research is motivated by the need to understand and compute s-ordered forms of boson operator products, building upon the concept of s-ordering originating in quantum optics, which generalizes various ordering schemes.

Method: The study utilizes a parametric family of Sheffer polynomial sequences, known as the Hsu-Shiue family, and its extensions, to derive the explicit s-ordered expressions.

Result: The paper provides explicit s-ordered expressions for products of single-mode boson operators, employing an extended Hsu-Shiue family of polynomials to achieve orderings that interpolate between normal and anti-normal forms.

Conclusion: The paper explicitly computes the s-ordered form of products of single-mode boson operators with a single annihilator, extending the concept of s-ordering to interpolate between normal and anti-normal orderings.

Abstract: The s-ordered form of any product of single-mode boson creation and
annihilation operators, containing only a single annihilator, is computed
explicitly. The s-ordering concept originated in quantum optics, and subsumes
normal, symmetric (Weyl), and anti-normal ordering for any two operators
satisfying a canonical commutation relation. Because the s-ordering map can be
viewed as producing a function of a complex variable, its inverse is a
quantization map that takes such "classical" functions to quantum operators.
The explicit s-ordered expressions are derived with the aid of a parametric
family of Sheffer polynomial sequences (or equivalently an exponential Riordan
array of polynomial coefficients), called the Hsu-Shiue family. To yield
orderings interpolating between normal and anti-normal, this family is extended
in an intricate way.

</details>


### [333] [Quantum sensing of electron beams using solid-state spins](https://arxiv.org/abs/2508.13112)
*Jakob M. Grzesik,Dominic Catanzaro,Charles Roques-Carmes,Eric I. Rosenthal,Guido L. van de Stolpe,Aviv Karnieli,Giovanni Scuri,Souvik Biswas,Kenneth J. Leedle,Dylan S. Black,Robert L. Byer,Ido Kaminer,R. Joel England,Shanhui Fan,Olav Solgaard,Jelena Vučković*

Main category: quant-ph

TL;DR: 本研究为实现自由电子束的固态量子控制开辟了道路，利用金刚石中的氮-空位（NV-）中心作为量子传感器来探测集束电子束，并通过自旋弛豫测量法进行了量化。


<details>
  <summary>Details</summary>
Motivation: 为了结合自由电子和固态量子比特进行协同量子信息处理和纳米尺度传感，需要实现自由电子束和固态量子系统之间的相干相互作用。然而，由于其耦合本质上很弱，因此实现这种相干控制仍然难以实现。

Method: 本研究提出的框架利用金刚石中的负氮空位（NV-）中心作为量子传感器，对集束电子束进行探测。研究了磁性自由电子-量子比特相互作用的Lindblad主方程描述，并确定了自旋弛豫测量法作为相互作用的灵敏探针。通过在微波集束电子束线上集成共聚焦荧光显微镜设置，监测电荷态动力学，并评估其对关键传感性能指标（如自旋读出对比度）的影响，从而为量子传感实验定义了安全运行参数。

Result: 研究结果表明，NV-中心可以作为自由电子的定量探针，并为自由电子-量子比特耦合在实际条件下的测量学标杆建立了基准。

Conclusion: 本研究将氮-空位中心（NV-）确立为定量探测自由电子的探针，并为自由电子-量子比特耦合在实际条件下的测量学标杆建立了基准，同时为实现电子束的固态量子控制指明了方向。

Abstract: Scattering experiments with energetic particles, such as free electrons, have
been historically used to reveal the quantum structure of matter. However,
realizing coherent interactions between free-electron beams and solid-state
quantum systems has remained out of reach, owing to their intrinsically weak
coupling. Realizing such coherent control would open up opportunities for
hybrid quantum platforms combining free electrons and solid-state qubits for
coincident quantum information processing and nanoscale sensing. Here, we
present a framework that employs negatively charged nitrogen-vacancy centers
(NV-) in diamond as quantum sensors of a bunched electron beam. We develop a
Lindblad master equation description of the magnetic free-electron--qubit
interactions and identify spin relaxometry as a sensitive probe of the
interaction. Experimentally, we integrate a confocal fluorescence microscopy
setup into a microwave-bunched electron beam line. We monitor charge-state
dynamics and assess their impact on key sensing performance metrics (such as
spin readout contrast), defining safe operating parameters for quantum sensing
experiments. By performing $T_1$ relaxometry under controlled electron beam
exposure, we establish an upper bound on the free-electron--spin coupling
strength. Our results establish NV- centers as quantitative probes of free
electrons, providing a metrological benchmark for free-electron--qubit coupling
under realistic conditions, and chart a route toward solid-state quantum
control with electron beams.

</details>


### [334] [Driven-Dissipative Interpretation of Measurement-Induced State Transitions Beyond Semiclassical Predictions](https://arxiv.org/abs/2508.13150)
*Bo-Syun Pan,Yen-Hsiang Lin,Chiao-Hsuan Wang*

Main category: quant-ph

TL;DR: Qubit readout in superconducting circuits can be disrupted by measurement-induced state transitions (MIST) under strong drives, causing qubit leakage. This paper uses a quantum model to explain MIST, revealing a 'super-MIST' regime with unexpected dynamics and a transient condition. The findings help optimize qubit measurements.


<details>
  <summary>Details</summary>
Motivation: To understand and address the issue of Measurement-Induced State Transition (MIST) in superconducting quantum computing, which occurs under strong readout drives and compromises the Quantum Nondemolition (QND) character of measurements.

Method: A driven-dissipative interpretation using a reduced quantum model was employed to capture the dynamics and entanglement structure underlying MIST.

Result: A super-MIST regime was uncovered, characterized by steady-state qubit inversion and slow relaxation beyond semiclassical Landau-Zener predictions. A transient readout condition was also identified. These results are broadly applicable to superconducting qubits and highlight strongly driven regimes for measurement optimization.

Conclusion: Dispersive readout is crucial for superconducting quantum computing, but multi-photon resonances can cause Measurement-Induced State Transition (MIST), leading to qubit leakage and compromising Quantum Nondemolition (QND) character. A driven-dissipative interpretation using a reduced quantum model reveals a super-MIST regime with steady-state qubit inversion and slow relaxation beyond Landau-Zener predictions. A transient readout condition is also identified where the resonator is highly populated while the qubit remains near its original state. These findings are applicable to various superconducting qubits and highlight the potential of strongly driven regimes for measurement optimization.

Abstract: Dispersive readout plays a central role in superconducting quantum computing,
enabling quantum nondemolition (QND) measurements of qubits through a coupled
microwave resonator. However, under strong readout drives, multi-photon
resonances can cause measurement-induced state transition (MIST), resulting in
qubit leakage out of the computational subspace and compromising the QND
character. We present a driven-dissipative interpretation of MIST using a
reduced quantum model that captures the dynamics and entanglement structure
underlying the breakdown of QND measurement, a feature inaccessible to previous
semiclassical treatments. A super-MIST regime under strong drive is uncovered,
characterized by steady-state qubit inversion and slow relaxation beyond the
semiclassical Landau-Zener predictions. We further identify a transient readout
condition in which the resonator becomes highly populated while the qubit
remains near its original state. These results are broadly applicable to
superconducting qubits such as fluxonium and transmon, unveil the
nonequilibrium dynamics of MIST, and highlight strongly driven regimes that can
be leveraged for measurement optimization.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [335] [Discovering Expert-Level Nash Equilibrium Algorithms with Large Language Models](https://arxiv.org/abs/2508.11874)
*Hanyu Li,Dongchen Li,Xiaotie Deng*

Main category: cs.GT

TL;DR: LegoNE框架通过将算法转换为约束优化问题，自动发现和证明算法的近似界限，实现了人机协作在理论科学中的应用，并在Nash均衡计算方面取得了超越人类的成果。


<details>
  <summary>Details</summary>
Motivation: 传统上，证明算法在所有输入上的性能保证需要大量且容易出错的人工努力。尽管人工智能在寻找特定问题实例的解决方案方面取得了巨大成功，但自动化发现具有可证明保证的通用算法仍然是一个重大障碍。这一挑战源于将算法设计的创造过程与形式化分析的严谨过程相结合的难度。

Method: LegoNE框架自动将任何用类Python语言编写的算法转换为约束优化问题。解决该问题可以推导出并证明算法的近似界限。

Result: 使用LegoNE，一个先进的大型语言模型在几小时内重新发现了双人游戏的先进算法，这是人类研究者花费15年才完成的壮举。对于三人游戏，该模型发现了一种超越所有现有的人工设计算法的新颖算法。

Conclusion: 该研究展示了一种新的人机协作范式，用于理论科学：人类进行更高层次的抽象推理，利用符号压缩搜索空间，而人工智能则在其中进行探索，实现单独无法达到的目标。

Abstract: Algorithm design and analysis is a cornerstone of computer science, but it
confronts a major challenge. Proving an algorithm's performance guarantee
across all inputs has traditionally required extensive and often error-prone
human effort. While AI has shown great success in finding solutions to specific
problem instances, automating the discovery of general algorithms with such
provable guarantees has remained a significant barrier. This challenge stems
from the difficulty of integrating the creative process of algorithm design
with the rigorous process of formal analysis. To address this gap, we propose
LegoNE, a framework that tightly fuses these two processes for the fundamental
and notoriously difficult problem of computing approximate Nash equilibria.
LegoNE automatically translates any algorithm written by a simple Python-like
language into a constrained optimization problem. Solving this problem derives
and proves the algorithm's approximation bound. Using LegoNE, a
state-of-the-art large language model rediscovered the state-of-the-art
algorithm for two-player games within hours, a feat that had taken human
researchers 15 years to achieve. For three-player games, the model discovered a
novel algorithm surpassing all existing human-designed ones. This work
demonstrates a new human-machine collaborative paradigm for theoretical
science: humans reason at a higher-abstract level, using symbols to compress
the search space, and AI explores within it, achieving what neither could
alone.

</details>


### [336] [Computing Approximately Proportional Allocations of Indivisible Goods: Beyond Additive and Monotone Valuations](https://arxiv.org/abs/2508.12453)
*Martin Jupakkal Andersen,Ioannis Caragiannis,Anders Bo Ipsen,Alexander Søltoft*

Main category: cs.GT

TL;DR: 本文研究了 PROP1 公平概念在非加性估值中的应用，并提出了几种计算 PROP1 分配的方法。


<details>
  <summary>Details</summary>
Motivation: 研究了 PROP1 公平概念在非加性估值中的应用，并与 EF1 和其他公平性概念进行了比较。

Method: 研究了具有“令人满意商品”的分配实例，其中代理具有非负的、不一定是单调的估值函数，允许负边际值。

Result: EF1 蕴含 PROP1，Round-Robin 算法在某些条件下可计算 PROP1 分配，最大 Nash 福利分配具有 PROP1 特性。

Conclusion: EF1 蕴含 PROP1 且可以高效计算，最大 Nash 福利分配也具有 PROP1 特性，证明了其“不寻常的公平性”。

Abstract: Although approximate notions of envy-freeness-such as envy-freeness up to one
good (EF1)-have been extensively studied for indivisible goods, the seemingly
simpler fairness concept of proportionality up to one good (PROP1) has received
far less attention. For additive valuations, every EF1 allocation is PROP1, and
well-known algorithms such as Round-Robin and Envy-Cycle Elimination compute
such allocations in polynomial time. PROP1 is also compatible with Pareto
efficiency, as maximum Nash welfare allocations are EF1 and hence PROP1.
  We ask whether these favorable properties extend to non-additive valuations.
We study a broad class of allocation instances with {\em satiating goods},
where agents have non-negative valuation functions that need not be monotone,
allowing for negative marginal values. We present the following results:
  - EF1 implies PROP1 for submodular valuations over satiating goods, ensuring
existence and efficient computation via Envy-Cycle Elimination for monotone
submodular valuations;
  - Round-robin computes a partial PROP1 allocation after the second-to-last
round for satiating submodular goods and a complete PROP1 for monotone
submodular valuations;
  - PROP1 allocations for satiating subadditive goods can be computed in
polynomial-time;
  - Maximum Nash welfare allocations are PROP1 for monotone submodular goods,
revealing yet another facet of their ``unreasonable fairness.''

</details>


### [337] [Group Fair Matchings using Convex Cost Functions](https://arxiv.org/abs/2508.12549)
*Atasi Panda,Harsh Sharma,Anand Louis,Prajakta Nimbhorkar*

Main category: cs.GT

TL;DR: 该研究提出了一种在项目分配问题中实现组公平性的新方法，该方法使用成本函数和近似算法来平衡各种约束，同时满足效用阈值。


<details>
  <summary>Details</summary>
Motivation: 为了在项目分配问题中实现组公平性，在平衡平台成本和组特定成本的同时满足效用阈值。

Method: 提出了一种基于线性规划和网络流技术的有效多项式时间近似算法，并为具有统一效用的特殊情况提供了一个精确算法。

Result: 该算法在理论上和实验上都得到了验证，并证明了一般问题在组可以任意交叉的情况下的难度。

Conclusion: 该模型通过成本函数和近似算法解决了在满足效用阈值的情况下，在平台和项目之间进行分配的问题，并考虑了组公平性。

Abstract: We consider the problem of assigning items to platforms where each item has a
utility associated with each of the platforms to which it can be assigned. Each
platform has a soft constraint over the total number of items it serves,
modeled via a convex cost function. Additionally, items are partitioned into
groups, and each platform also incurs group-specific convex cost over the
number of items from each group that can be assigned to the platform. These
costs promote group fairness by penalizing imbalances, yielding a soft
variation of fairness notions introduced in prior work, such as Restricted
Dominance and Minority protection. Restricted Dominance enforces upper bounds
on group representation, while Minority protection enforces lower bounds. Our
approach replaces such hard constraints with cost-based penalties, allowing
more flexible trade-offs. Our model also captures Nash Social Welfare kind of
objective.
  The cost of an assignment is the sum of the values of all the cost functions
across all the groups and platforms. The objective is to find an assignment
that minimizes the cost while achieving a total utility that is at least a
user-specified threshold. The main challenge lies in balancing the overall
platform cost with group-specific costs, both governed by convex functions,
while meeting the utility constraint. We present an efficient polynomial-time
approximation algorithm, supported by theoretical guarantees and experimental
evaluation. Our algorithm is based on techniques involving linear programming
and network flows. We also provide an exact algorithm for a special case with
uniform utilities and establish the hardness of the general problem when the
groups can intersect arbitrarily.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [338] [Finite Automata Extraction: Low-data World Model Learning as Programs from Gameplay Video](https://arxiv.org/abs/2508.11836)
*Dave Goel,Matthew Guzdial,Anurag Sarkar*

Main category: cs.AI

TL;DR: FAE learns a neuro-symbolic world model from gameplay video using a novel DSL called Retro Coder. It achieves more precise environment modeling and more general code generation compared to existing methods.


<details>
  <summary>Details</summary>
Motivation: World models are defined as a compressed spatial and temporal learned representation of an environment. The learned representation is typically a neural network, making transfer of the learned environment dynamics and explainability a challenge.

Method: FAE learns a neuro-symbolic world model from gameplay video represented as programs in a novel domain-specific language (DSL): Retro Coder.

Result: Compared to prior world model approaches, FAE learns a more precise model of the environment and more general code than prior DSL-based approaches.

Conclusion: FAE learns a more precise model of the environment and more general code than prior DSL-based approaches.

Abstract: World models are defined as a compressed spatial and temporal learned
representation of an environment. The learned representation is typically a
neural network, making transfer of the learned environment dynamics and
explainability a challenge. In this paper, we propose an approach, Finite
Automata Extraction (FAE), that learns a neuro-symbolic world model from
gameplay video represented as programs in a novel domain-specific language
(DSL): Retro Coder. Compared to prior world model approaches, FAE learns a more
precise model of the environment and more general code than prior DSL-based
approaches.

</details>


### [339] [EvoCut: Strengthening Integer Programs via Evolution-Guided Language Models](https://arxiv.org/abs/2508.11850)
*Milad Yazdani,Mahdi Mostajabdaveh,Samin Aref,Zirui Zhou*

Main category: cs.AI

TL;DR: EvoCut 利用 LLM 和进化搜索自动生成整数规划的加速切块，无需人工干预，可显著提高求解效率和解决方案质量。


<details>
  <summary>Details</summary>
Motivation: 由于其 NP 难性质，整数规划的求解仍然具有挑战性。手动设计加速切块是一种有效的实践方法，但需要深厚的专业知识且难以自动化。

Method: EvoCut 结合了大型语言模型（LLM）和进化搜索来自动生成加速切块。它首先使用基于 LLM 的初始化代理生成候选切块的初始种群，然后在验证集上评估每个切块的保留最优解的能力和切断分数解的能力，最后通过进化交叉和变异代理迭代地优化种群。切块的效用通过其相对于求解器最优间隙的相对减少来量化。

Result: 与标准的整数规划实践相比，EvoCut 在固定时间内可将最优间隙减少 17-57%。它能以快 4 倍的速度获得相同的解决方案，并在相同的时间限制内获得更高质量的解决方案。

Conclusion: EvoCut 是一种无需人工专家输入即可自动生成、改进和经验验证切块的框架，可推广到未见过的实例。

Abstract: Integer programming lies at the heart of crucial combinatorial optimization
tasks but remains challenging due to its NP-hard nature. An effective approach
for practically solving integer programs is the manual design of acceleration
cuts, i.e. inequalities that improve solver performance. However, this creative
process demands deep expertise and is yet to be automated. Our proposed
framework, EvoCut, automates the generation of acceleration cuts by combining
large language models (LLMs) with an evolutionary search. EvoCut (i)
initializes a diverse population of candidate cuts via an LLM-based initializer
agent; (ii) for each cut empirically evaluates both preservation of the optimal
solution and its ability to cut off fractional solutions across a verification
set; and (iii) iteratively refines the population through evolutionary
crossover and mutation agents. We quantify each cut's utility by its relative
reduction in the solver's optimality gap. Our comparisons against standard
integer programming practice show that EvoCut reduces optimality gap by 17-57%
within a fixed time. It obtains the same solutions up to 4 times as fast, and
obtains higher-quality solutions within the same time limit. Requiring no human
expert input, EvoCut reliably generates, improves, and empirically verifies
cuts that generalize to unseen instances. The code is available at
https://github.com/milad1378yz/EvoCut.

</details>


### [340] [LARC: Towards Human-level Constrained Retrosynthesis Planning through an Agentic Framework](https://arxiv.org/abs/2508.11860)
*Frazier N. Baker,Daniel Adu-Ampratwum,Reza Averly,Botao Yu,Huan Sun,Xia Ning*

Main category: cs.AI

TL;DR: LARC是一个基于LLM的代理框架，用于约束逆合成规划，通过代理约束评估和工具推理，成功率达到72.9%，优于基线，接近人类专家水平。


<details>
  <summary>Details</summary>
Motivation: 为了解决化学领域中具有挑战性的约束逆合成规划问题，即在满足实际约束的条件下，从市售起始原料识别到所需目标分子的合成路线。

Method: 提出了一种名为LARC的基于LLM的代理逆合成规划框架，该框架通过“代理即法官”的代理约束评估，将基于工具推理的代理反馈直接纳入逆合成规划过程，以指导和约束路线生成。

Result: 在3种约束类型的48个约束逆合成规划任务上，LARC实现了72.9%的成功率，大大优于LLM基线，并且在更短的时间内接近了人类专家的成功率。

Conclusion: LARC框架具有可扩展性，是朝着为人类专家提供有效的代理工具或共同科学家迈出的第一步，用于约束逆合成。

Abstract: Large language model (LLM) agent evaluators leverage specialized tools to
ground the rational decision-making of LLMs, making them well-suited to aid in
scientific discoveries, such as constrained retrosynthesis planning.
Constrained retrosynthesis planning is an essential, yet challenging, process
within chemistry for identifying synthetic routes from commercially available
starting materials to desired target molecules, subject to practical
constraints. Here, we present LARC, the first LLM-based Agentic framework for
Retrosynthesis planning under Constraints. LARC incorporates agentic constraint
evaluation, through an Agent-as-a-Judge, directly into the retrosynthesis
planning process, using agentic feedback grounded in tool-based reasoning to
guide and constrain route generation. We rigorously evaluate LARC on a
carefully curated set of 48 constrained retrosynthesis planning tasks across 3
constraint types. LARC achieves a 72.9% success rate on these tasks, vastly
outperforming LLM baselines and approaching human expert-level success in
substantially less time. The LARC framework is extensible, and serves as a
first step towards an effective agentic tool or a co-scientist to human experts
for constrained retrosynthesis.

</details>


### [341] [The Maximum Coverage Model and Recommendation System for UAV Vertiports Location Planning](https://arxiv.org/abs/2508.12651)
*Chunliang Hua,Xiao Hu,Jiayang Sun,Zeyuan Yang*

Main category: cs.AI

TL;DR: 该研究提出了一种新的优化框架（CDMCLP）和推荐系统，用于解决大规模城市空中交通垂直起降场的规划问题，并验证了其有效性，能提高规划效率和整合复杂因素。


<details>
  <summary>Details</summary>
Motivation: 现有城市空中交通基础设施规划框架在数据精细度和现实适用性方面存在不足，无法满足大规模垂直起降场网络规划的复杂性需求。

Method: 提出了一种新颖的优化框架——有容量动态最大覆盖选址问题（CDMCLP），并结合社会经济因素和动态聚类初始化，开发了一个集成规划推荐系统。

Result: CDMCLP框架和推荐系统在中国的中心城市得到验证，CDMCLP将传统选址方法的量化性能提高了38%-52%，推荐系统则展示了用户友好性和复杂元素的有效整合能力。

Conclusion: 该研究提出的CDMCLP优化框架和集成规划推荐系统能有效解决城市空中交通的选址规划问题，并为市政当局提供实用的工具。

Abstract: As urban aerial mobility (UAM) infrastructure development accelerates
globally, cities like Shenzhen are planning large-scale vertiport networks
(e.g., 1,200+ facilities by 2026). Existing planning frameworks remain
inadequate for this complexity due to historical limitations in data
granularity and real-world applicability. This paper addresses these gaps by
first proposing the Capacitated Dynamic Maximum Covering Location Problem
(CDMCLP), a novel optimization framework that simultaneously models urban-scale
spatial-temporal demand, heterogeneous user behaviors, and infrastructure
capacity constraints. Building on this foundation, we introduce an Integrated
Planning Recommendation System that combines CDMCLP with socio-economic factors
and dynamic clustering initialization. This system leverages adaptive parameter
tuning based on empirical user behavior to generate practical planning
solutions. Validation in a Chinese center city demonstrates the effectiveness
of the new optimization framework and recommendation system. Under the
evaluation and optimization of CDMCLP, the quantitative performance of
traditional location methods are exposed and can be improved by 38\%--52\%,
while the recommendation system shows user-friendliness and the effective
integration of complex elements. By integrating mathematical rigor with
practical implementation considerations, this hybrid approach bridges the gap
between theoretical location modeling and real-world UAM infrastructure
planning, offering municipalities a pragmatic tool for vertiport network
design.

</details>


### [342] [QuarkMed Medical Foundation Model Technical Report](https://arxiv.org/abs/2508.11894)
*Ao Li,Bin Yan,Bingfeng Cai,Chenxi Li,Cunzhong Zhao,Fugen Yao,Gaoqiang Liu,Guanjun Jiang,Jian Xu,Liang Dong,Liansheng Sun,Rongshen Zhang,Xiaolei Gui,Xin Liu,Xin Shang,Yao Wu,Yu Cao,Zhenxin Ma,Zhuang Jia*

Main category: cs.AI

TL;DR: QuarkMed 是一个专为医疗领域设计的强大的基础模型，它利用精选的医疗数据、RAG 和强化学习，在医学考试中取得了 70% 的准确率，并已广泛应用于实际医疗服务中。


<details>
  <summary>Details</summary>
Motivation: 医疗任务需要高度专业化的知识、专业精度和定制能力，这需要一个健壮可靠的基础模型。

Method: QuarkMed 通过处理精选的医疗数据、利用医疗内容检索增强生成（RAG）以及一个大规模、可验证的强化学习管道来开发高性能的医疗基础模型。

Result: 该模型在中国医学执业医师资格考试中达到了 70% 的准确率，在不同的医疗基准测试中表现出强大的泛化能力。

Conclusion: QuarkMed 是一个强大且通用的个性化医疗 AI 解决方案，已在 ai.quark.cn 上为数百万用户提供服务。

Abstract: Recent advancements in large language models have significantly accelerated
their adoption in healthcare applications, including AI-powered medical
consultations, diagnostic report assistance, and medical search tools. However,
medical tasks often demand highly specialized knowledge, professional accuracy,
and customization capabilities, necessitating a robust and reliable foundation
model. QuarkMed addresses these needs by leveraging curated medical data
processing, medical-content Retrieval-Augmented Generation (RAG), and a
large-scale, verifiable reinforcement learning pipeline to develop a
high-performance medical foundation model. The model achieved 70% accuracy on
the Chinese Medical Licensing Examination, demonstrating strong generalization
across diverse medical benchmarks. QuarkMed offers a powerful yet versatile
personal medical AI solution, already serving over millions of users at
ai.quark.cn.

</details>


### [343] [CHBench: A Cognitive Hierarchy Benchmark for Evaluating Strategic Reasoning Capability of LLMs](https://arxiv.org/abs/2508.11944)
*Hongtao Liu,Zhicheng Du,Zihe Wang,Weiran Shen*

Main category: cs.AI

TL;DR: 提出CHBench评估框架，用于衡量LLM的战略推理能力。该框架基于认知层级模型，并通过实验证明其稳健性和泛化能力。研究还发现聊天机制会削弱推理能力，而记忆机制会增强推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究大多依赖效用表现指标，但这些指标由于对手行为和博弈结构的变化而不够稳健。为了解决这一局限性，需要一个更可靠的评估框架。

Method: 提出了一种名为认知层级基准（CHBench）的新颖评估框架，该框架受到行为经济学中认知层级模型的启发。通过一个包含三个阶段的系统性框架，利用六种最先进的LLM在十五种精心挑选的规范形式博弈中的行为数据来评估LLM的战略推理能力。

Result: 实验表明，LLM在不同对局中表现出一致的战略推理水平，证实了该框架的稳健性和泛化能力。分析结果显示，聊天机制显著降低了战略推理能力，而记忆机制则增强了战略推理能力。

Conclusion: LLM在不同对局中表现出一致的战略推理水平，该框架的稳健性和泛化能力得到了证实。聊天机制会显著削弱战略推理能力，而记忆机制则会增强战略推理能力。CHBench为评估LLM能力提供了一个有前景的工具，具有重要的未来研究和实际应用潜力。

Abstract: Game-playing ability serves as an indicator for evaluating the strategic
reasoning capability of large language models (LLMs). While most existing
studies rely on utility performance metrics, which are not robust enough due to
variations in opponent behavior and game structure. To address this limitation,
we propose \textbf{Cognitive Hierarchy Benchmark (CHBench)}, a novel evaluation
framework inspired by the cognitive hierarchy models from behavioral economics.
We hypothesize that agents have bounded rationality -- different agents behave
at varying reasoning depths/levels. We evaluate LLMs' strategic reasoning
through a three-phase systematic framework, utilizing behavioral data from six
state-of-the-art LLMs across fifteen carefully selected normal-form games.
Experiments show that LLMs exhibit consistent strategic reasoning levels across
diverse opponents, confirming the framework's robustness and generalization
capability. We also analyze the effects of two key mechanisms (Chat Mechanism
and Memory Mechanism) on strategic reasoning performance. Results indicate that
the Chat Mechanism significantly degrades strategic reasoning, whereas the
Memory Mechanism enhances it. These insights position CHBench as a promising
tool for evaluating LLM capabilities, with significant potential for future
research and practical applications.

</details>


### [344] [Data Mixing Optimization for Supervised Fine-Tuning of Large Language Models](https://arxiv.org/abs/2508.11953)
*Yuan Li,Zhengzhong Liu,Eric Xing*

Main category: cs.AI

TL;DR: 通过将数据混合视为优化问题，并利用有效数据传输模型和缩放定律来优化数据混合权重，从而改进大型语言模型（LLM）的监督微调（SFT）性能。


<details>
  <summary>Details</summary>
Motivation: 优化用于大型语言模型（LLM）监督微调（SFT）的数据混合，对于开发通用模型至关重要，但该领域仍有待探索。

Method: 通过将数据混合视为优化问题，并利用有效数据传输模型和微调的缩放定律来参数化损失，从而推导出最优权重。

Result: 通过实验，该算法在所有域上均实现了出色的整体和个体性能，并且在网格搜索确定的最优权重下，模型的表现可以与之媲美，每个域的损失平均仅比网格搜索的最佳域损失高出0.66%。

Conclusion: 该算法在所有域上均能实现出色的整体和个体性能，且在网格搜索的最佳域损失基础上，每个域的损失仅高出0.66%。通过使用该方法重新加权流行的SFT数据集，可以同时改进验证损失和下游性能。此外，该方法还可以推广到指导特定领域模型的数据选择，并为SFT提供见解。

Abstract: Optimizing data mixtures for supervised fine-tuning (SFT) of large language
models (LLMs) is critical for developing general-purpose models, yet this area
remains underexplored. In this paper, we frame data mixing as an optimization
problem and introduce a novel method designed to minimize validation loss. Our
approach parametrizes the loss by modeling effective data transferred and
leveraging scaling laws for fine-tuning. By experimenting with various
small-scale data mixtures, we fit these parameters and derive the optimal
weights. We provide both mathematical proofs and empirical results
demonstrating that our algorithm achieves excellent overall and individual
performance across all domains. Through controlled experiments, we show that
models trained with our optimized weights perform on par with those using
optimal weights determined via grid search, with per-domain loss only 0.66%
higher than the best domain loss from grid search on average. Additionally, we
show that reweighting popular SFT datasets using our method improves both
validation loss and downstream performance. Finally, we discuss how our method
can generalize to guide data selection for domain-specific models and provide
insights into SFT.

</details>


### [345] [AgentCDM: Enhancing Multi-Agent Collaborative Decision-Making via ACH-Inspired Structured Reasoning](https://arxiv.org/abs/2508.11995)
*Xuyang Zhao,Shiwan Zhao,Hualong Yu,Liting Zhang,Qicheng Li*

Main category: cs.AI

TL;DR: AgentCDM 是一个用于 LLM 多主体系统的协作决策框架，它借鉴 ACH 方法，通过结构化推理和两阶段训练来克服现有方法的局限性，实验证明其性能优越且泛化能力强。


<details>
  <summary>Details</summary>
Motivation: 现有的 LLM 多主体系统在协作决策方面存在不足，要么依赖于“独裁”策略（易受单一代理的认知偏差影响），要么采用“投票”方法（未能充分利用集体智能）。

Method: 提出了一种名为 AgentCDM 的结构化框架，该框架借鉴了认知科学中的竞争假设分析 (ACH) 方法，通过系统化的推理范式来缓解认知偏差，并将决策过程从被动的答案选择转变为主动的假设评估和构建。为实现该推理过程，开发了一种两阶段训练范式：第一阶段使用受 ACH 启发的显式脚手架来指导模型进行结构化推理，第二阶段则逐步移除脚手架以鼓励自主泛化。

Result: 实验结果表明，AgentCDM 在多个基准数据集上取得了最先进的性能，并表现出强大的泛化能力，验证了其在提高多主体系统中协作决策质量和鲁棒性方面的有效性。

Conclusion: AgentCDM 框架能够提高 LLM 驱动的多主体系统中协作决策的质量和鲁棒性，并在多个基准数据集上实现了最先进的性能和强大的泛化能力。

Abstract: Multi-agent systems (MAS) powered by large language models (LLMs) hold
significant promise for solving complex decision-making tasks. However, the
core process of collaborative decision-making (CDM) within these systems
remains underexplored. Existing approaches often rely on either ``dictatorial"
strategies that are vulnerable to the cognitive biases of a single agent, or
``voting-based" methods that fail to fully harness collective intelligence. To
address these limitations, we propose \textbf{AgentCDM}, a structured framework
for enhancing collaborative decision-making in LLM-based multi-agent systems.
Drawing inspiration from the Analysis of Competing Hypotheses (ACH) in
cognitive science, AgentCDM introduces a structured reasoning paradigm that
systematically mitigates cognitive biases and shifts decision-making from
passive answer selection to active hypothesis evaluation and construction. To
internalize this reasoning process, we develop a two-stage training paradigm:
the first stage uses explicit ACH-inspired scaffolding to guide the model
through structured reasoning, while the second stage progressively removes this
scaffolding to encourage autonomous generalization. Experiments on multiple
benchmark datasets demonstrate that AgentCDM achieves state-of-the-art
performance and exhibits strong generalization, validating its effectiveness in
improving the quality and robustness of collaborative decisions in MAS.

</details>


### [346] [UniCast: A Unified Multimodal Prompting Framework for Time Series Forecasting](https://arxiv.org/abs/2508.11954)
*Sehyuk Park,Soyeon Caren Han,Eduard Hovy*

Main category: cs.AI

TL;DR: UniCast是一个新颖的参数高效多模态框架，通过结合时间序列、视觉和文本数据，显著提升了时间序列预测的性能，优于所有现有的TSFM基线。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列预测模型大多是单模态的，忽略了在现实世界场景中常常伴随时间序列数据的丰富多模态上下文（如视觉和文本信号），而这些信息对于提升预测性能至关重要。

Method: UniCast是一个新颖的、参数高效的多模态框架，它通过软提示调优将预训练的视觉和文本编码器与冻结的时间序列预测模型（TSFM）相结合，实现了跨模态交互和高效适应。

Result: UniCast在多个时间序列预测基准测试中，一致且显著地优于所有现有的TSFM基线模型。

Conclusion: UniCast框架通过融合时间序列、视觉和文本模态，能够有效提升时间序列预测性能，证明了多模态上下文在下一代通用时间序列预测器中的关键作用。

Abstract: Time series forecasting is a foundational task across domains, such as
finance, healthcare, and environmental monitoring. While recent advances in
Time Series Foundation Models (TSFMs) have demonstrated strong generalisation
through large-scale pretraining, existing models operate predominantly in a
unimodal setting, ignoring the rich multimodal context, such as visual and
textual signals, that often accompanies time series data in real-world
scenarios. This paper introduces a novel parameter-efficient multimodal
framework, UniCast, that extends TSFMs to jointly leverage time series, vision,
and text modalities for enhanced forecasting performance. Our method integrates
modality-specific embeddings from pretrained Vision and Text Encoders with a
frozen TSFM via soft prompt tuning, enabling efficient adaptation with minimal
parameter updates. This design not only preserves the generalisation strength
of the foundation model but also enables effective cross-modal interaction.
Extensive experiments across diverse time-series forecasting benchmarks
demonstrate that UniCast consistently and significantly outperforms all
existing TSFM baselines. The findings highlight the critical role of multimodal
context in advancing the next generation of general-purpose time series
forecasters.

</details>


### [347] [MAPF-World: Action World Model for Multi-Agent Path Finding](https://arxiv.org/abs/2508.12087)
*Zhanjiang Yang,Meng Li,Yang Shen,Yueming Li,Lijun Sun*

Main category: cs.AI

TL;DR: MAPF-World 是一种新的 MAPF 方法，它通过模拟环境和预测未来状态/动作来改进决策，从而在复杂场景中实现更好的性能，同时模型更小、数据需求更少。


<details>
  <summary>Details</summary>
Motivation: 现有的去中心化可学习 MAPF 求解器虽然在大规模 MAPF 中表现出色，但其反应式策略模型难以模拟环境的时间动态和智能体间的依赖关系，导致在复杂、长期的规划场景中性能下降。

Method: MAPF-World 提出了一种用于多智能体路径寻找（MAPF）的自回归动作世界模型，该模型通过预测未来状态和动作来统一情境理解和动作生成，从而超越了仅依赖即时局部观测的决策过程。

Result: MAPF-World 在 MAPF 基准测试中表现优于最先进的可学习求解器，在分布外案例中实现了卓越的零样本泛化能力。

Conclusion: MAPF-World 在复杂的多代理设置中，通过明确建模环境动态（包括空间特征和时间依赖性）来提高态势感知能力，并通过预测未来状态和动作来指导决策，从而超越了最先进的可学习求解器，并在分布外案例中展示了卓越的零样本泛化能力。此外，MAPF-World 的模型尺寸减小了 96.5%，数据量减少了 92%。

Abstract: Multi-agent path finding (MAPF) is the problem of planning conflict-free
paths from the designated start locations to goal positions for multiple
agents. It underlies a variety of real-world tasks, including multi-robot
coordination, robot-assisted logistics, and social navigation. Recent
decentralized learnable solvers have shown great promise for large-scale MAPF,
especially when leveraging foundation models and large datasets. However, these
agents are reactive policy models and exhibit limited modeling of environmental
temporal dynamics and inter-agent dependencies, resulting in performance
degradation in complex, long-term planning scenarios. To address these
limitations, we propose MAPF-World, an autoregressive action world model for
MAPF that unifies situation understanding and action generation, guiding
decisions beyond immediate local observations. It improves situational
awareness by explicitly modeling environmental dynamics, including spatial
features and temporal dependencies, through future state and actions
prediction. By incorporating these predicted futures, MAPF-World enables more
informed, coordinated, and far-sighted decision-making, especially in complex
multi-agent settings. Furthermore, we augment MAPF benchmarks by introducing an
automatic map generator grounded in real-world scenarios, capturing practical
map layouts for training and evaluating MAPF solvers. Extensive experiments
demonstrate that MAPF-World outperforms state-of-the-art learnable solvers,
showcasing superior zero-shot generalization to out-of-distribution cases.
Notably, MAPF-World is trained with a 96.5% smaller model size and 92% reduced
data.

</details>


### [348] [Rigorous Feature Importance Scores based on Shapley Value and Banzhaf Index](https://arxiv.org/abs/2508.11959)
*Xuanxiang Huang,Olivier Létoffé,Joao Marques-Silva*

Main category: cs.AI

TL;DR: 本文提出了一种新的特征归因方法，考虑了非WAXp集合的贡献，并量化了特征在排除对抗样本方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于博弈论的特征归因方法忽略了非WAXp集合的贡献，而这些集合可能包含重要的信息，因为形式化解释（XPs）和对抗样本（AExs）之间存在关联。

Method: 本文利用Shapley值和Banzhaf指数来计算特征贡献，并考虑了非WAXp集合。

Result: 提出了两种新的特征重要性评分方法，它们量化了每个特征在排除对抗样本方面的有效性。

Conclusion: 本文提出了一种新的基于博弈论的特征归因方法，该方法考虑了非WAXp集合的贡献，并量化了特征在排除对抗样本方面的有效性。此外，还研究了该方法的性质和计算复杂度。

Abstract: Feature attribution methods based on game theory are ubiquitous in the field
of eXplainable Artificial Intelligence (XAI). Recent works proposed rigorous
feature attribution using logic-based explanations, specifically targeting
high-stakes uses of machine learning (ML) models. Typically, such works exploit
weak abductive explanation (WAXp) as the characteristic function to assign
importance to features. However, one possible downside is that the contribution
of non-WAXp sets is neglected. In fact, non-WAXp sets can also convey important
information, because of the relationship between formal explanations (XPs) and
adversarial examples (AExs). Accordingly, this paper leverages Shapley value
and Banzhaf index to devise two novel feature importance scores. We take into
account non-WAXp sets when computing feature contribution, and the novel scores
quantify how effective each feature is at excluding AExs. Furthermore, the
paper identifies properties and studies the computational complexity of the
proposed scores.

</details>


### [349] [The Yokai Learning Environment: Tracking Beliefs Over Space and Time](https://arxiv.org/abs/2508.12480)
*Constantin Ruhdorfer,Matteo Bortoletto,Andreas Bulling*

Main category: cs.AI

TL;DR: 在 Yokai 学习环境中，RL 智能体难以实现人类级别的 ToM，即使有完美记忆和信念建模的帮助，它们在与新伙伴合作和进行长期游戏时仍面临挑战，这暴露了它们在建立稳固的共同基础方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有 ToM 基准测试在被动观察场景或缺乏对智能体如何随时间建立和维护共同基础的评估方面存在局限。为了解决这些问题，需要一个能够评估智能体在动态协作环境中推理他人信念并维护共同基础能力的环境。

Method: 开发了一个名为 Yokai Learning Environment (YLE) 的多智能体强化学习环境，该环境基于合作纸牌游戏 Yokai，用于评估和研究智能体的 Theory of Mind (ToM) 能力，重点关注信念建模、记忆、伙伴泛化和扩展到更高阶 ToM。

Result: RL 智能体在 YLE 中表现不佳，即使有完美记忆也难以解决。信念建模有所帮助，但智能体仍无法有效泛化到未见过伙伴或在长期游戏中形成准确信念，显示了对脆弱约定的依赖性。

Conclusion: 现有 RL 智能体在 YLE 中表现不佳，即使有完美记忆也难以解决，并且在泛化到未见过伙伴或在长期游戏中形成准确信念方面存在不足，这表明它们依赖于脆弱的约定而非鲁棒的信念跟踪。信念建模可以提高性能，但仍需改进。

Abstract: Developing collaborative AI hinges on Theory of Mind (ToM) - the ability to
reason about the beliefs of others to build and maintain common ground.
Existing ToM benchmarks, however, are restricted to passive observer settings
or lack an assessment of how agents establish and maintain common ground over
time. To address these gaps, we introduce the Yokai Learning Environment (YLE)
- a multi-agent reinforcement learning (RL) environment based on the
cooperative card game Yokai. In the YLE, agents take turns peeking at hidden
cards and moving them to form clusters based on colour. Success requires
tracking evolving beliefs, remembering past observations, using hints as
grounded communication, and maintaining common ground with teammates. Our
evaluation yields two key findings: First, current RL agents struggle to solve
the YLE, even when given access to perfect memory. Second, while belief
modelling improves performance, agents are still unable to effectively
generalise to unseen partners or form accurate beliefs over longer games,
exposing a reliance on brittle conventions rather than robust belief tracking.
We use the YLE to investigate research questions in belief modelling, memory,
partner generalisation, and scaling to higher-order ToM.

</details>


### [350] [Chart-CoCa: Self-Improving Chart Understanding of Vision LMs via Code-Driven Synthesis and Candidate-Conditioned Answering](https://arxiv.org/abs/2508.11975)
*Gongyao Jiang,Qiong Luo*

Main category: cs.AI

TL;DR: 通过代码生成可靠的合成数据，并结合测试时增强的候选条件回答机制，提升了视觉语言模型在图表理解任务上的表现，实现了完全自主的性能提升。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（VLM）在图表理解任务，特别是准确描述图表和进行复杂推理方面，常常表现不佳。合成数据生成是一个有前景的解决方案，但通常面临标签噪声的挑战。

Method: 本研究首先引入了一个通过代码生成和执行来创建图表-问题-答案三元组的合成数据生成流程，以保证合成数据的可靠性。在此基础上，借鉴测试时增强（test-time augmentation）的思想，设计了一种候选条件回答机制，即VLM首先为每个查询生成多个响应，然后通过上下文关联这些候选响应来合成最终答案。

Result: 实验结果表明，该方法在完全自主提升的范式下，相比初始VLM，准确率最高提升了15.50个百分点，证明了其有效性。

Conclusion: 本研究提出的新颖方法在图表理解任务中取得了显著的成果，在无需人工标注数据或外部模型的情况下，实现了完全的自主提升，并将准确率提高了15.50个百分点。

Abstract: Vision Language Models (VLMs) often struggle with chart understanding tasks,
particularly in accurate chart description and complex reasoning. Synthetic
data generation is a promising solution, while usually facing the challenge of
noise labels. To address this challenge, we first introduce a chart synthesis
pipeline that generates aligned chart-question-answer triplets through code
generation and execution, ensuring the reliability of synthetic data without
human intervention. Furthermore, inspired by test-time scaling that increases
inference budget and thereby improves performance, we design a
candidate-conditioned answering process. The VLM first generates multiple
responses per query, and then synthesizes the final answer by contextualizing
these candidates. Experiments demonstrate significant improvements, with up to
15.50 points accuracy gain over the initial VLM, in a fully self-improving
paradigm without either human-labeled data or external models.

</details>


### [351] [FutureX: An Advanced Live Benchmark for LLM Agents in Future Prediction](https://arxiv.org/abs/2508.11987)
*Zhiyuan Zeng,Jiashuo Liu,Siyuan Chen,Tianci He,Yali Liao,Jinpeng Wang,Zaiyuan Wang,Yang Yang,Lingyue Yin,Mingren Yin,Zhenwei Zhu,Tianle Cai,Zehui Chen,Jiecao Chen,Yantao Du,Xiang Gao,Jiacheng Guo,Liang Hu,Jianpeng Jiao,Xiangsheng Li,Jingkai Liu,Shuang Ni,Zhoufutu Wen,Ge Zhang,Kaiyuan Zhang,Xin Zhou,Jose Blanchet,Xipeng Qiu,Mengdi Wang,Wenhao Huang*

Main category: cs.AI

TL;DR: 为解决LLM代理未来预测评估缺乏基准的问题，本研究提出了FutureX，一个动态、实时的基准，它支持每日更新并消除数据污染。研究评估了25个模型，并分析了它们的性能和失败模式，旨在推动LLM代理在未来预测能力上达到专业水平。


<details>
  <summary>Details</summary>
Motivation: 未来预测对LLM代理来说是一项复杂的任务，目前缺乏大规模的基准来评估LLM代理在未来预测任务上的表现，这主要是由于处理实时更新和检索及时、准确的答案所带来的挑战。

Method: 本研究引入了FutureX，一个动态的、实时的LLM代理未来预测评估基准。该基准支持每日实时更新，并通过自动化的问答收集管道消除数据污染，评估了包括具有推理、搜索能力以及集成外部工具（如Deep Research Agent）的25个LLM/代理模型，并深入分析了代理在未来导向任务中的失败模式和性能缺陷，例如对假冒网页的脆弱性以及时间有效性。

Result: FutureX是目前最大、最多样化的未来预测实时基准，支持每日更新，并通过自动化流程消除了数据污染。研究评估了25个LLM/代理模型，并对代理在未来预测任务中的失败模式和性能进行了深入分析。

Conclusion: FutureX旨在建立一个动态、无污染的评估标准，以推动LLM代理在复杂推理和预测思维方面达到专业人类分析师的水平。

Abstract: Future prediction is a complex task for LLM agents, requiring a high level of
analytical thinking, information gathering, contextual understanding, and
decision-making under uncertainty. Agents must not only gather and interpret
vast amounts of dynamic information but also integrate diverse data sources,
weigh uncertainties, and adapt predictions based on emerging trends, just as
human experts do in fields like politics, economics, and finance. Despite its
importance, no large-scale benchmark exists for evaluating agents on future
prediction, largely due to challenges in handling real-time updates and
retrieving timely, accurate answers. To address this, we introduce
$\textbf{FutureX}$, a dynamic and live evaluation benchmark specifically
designed for LLM agents performing future prediction tasks. FutureX is the
largest and most diverse live benchmark for future prediction, supporting
real-time daily updates and eliminating data contamination through an automated
pipeline for question gathering and answer collection. We evaluate 25 LLM/agent
models, including those with reasoning, search capabilities, and integration of
external tools such as the open-source Deep Research Agent and closed-source
Deep Research models. This comprehensive evaluation assesses agents' adaptive
reasoning and performance in dynamic environments. Additionally, we provide
in-depth analyses of agents' failure modes and performance pitfalls in
future-oriented tasks, including the vulnerability to fake web pages and the
temporal validity. Our goal is to establish a dynamic, contamination-free
evaluation standard that drives the development of LLM agents capable of
performing at the level of professional human analysts in complex reasoning and
predictive thinking.

</details>


### [352] [Modeling Relational Logic Circuits for And-Inverter Graph Convolutional Network](https://arxiv.org/abs/2508.11991)
*Weihao Sun*

Main category: cs.AI

TL;DR: AIGer is a new method for analyzing And-Inverter Graphs (AIGs) that improves performance on tasks like Signal Probability Prediction and Truth Table Distance Prediction by better modeling both the logic functions and the structure of the graphs.


<details>
  <summary>Details</summary>
Motivation: Existing methods for modeling And-Inverter Graphs (AIGs) struggle with the complex structure and large scale of real-world AIGs, lacking the ability to jointly model functional and structural characteristics and having insufficient dynamic information propagation capabilities.

Method: AIGer utilizes a two-component approach: 1) Node logic feature initialization embedding to project logic nodes into independent semantic spaces, and 2) AIGs feature learning network component employing a heterogeneous graph convolutional network with dynamic relationship weight matrices and differentiated information aggregation to capture the structure and information of AIGs.

Result: AIGer outperforms current state-of-the-art models in the Signal Probability Prediction (SSP) task, with MAE and MSE improvements of 18.95% and 44.44%, respectively. In the Truth Table Distance Prediction (TTDP) task, AIGer achieves MAE and MSE improvements of 33.57% and 14.79%, respectively.

Conclusion: AIGer addresses the challenges in modeling complex And-Inverter Graphs (AIGs) by jointly considering functional and structural characteristics and enhancing dynamic information propagation. Experimental results show significant improvements in Signal Probability Prediction (SSP) and Truth Table Distance Prediction (TTDP) tasks compared to existing models.

Abstract: The automation of logic circuit design enhances chip performance, energy
efficiency, and reliability, and is widely applied in the field of Electronic
Design Automation (EDA).And-Inverter Graphs (AIGs) efficiently represent,
optimize, and verify the functional characteristics of digital circuits,
enhancing the efficiency of EDA development.Due to the complex structure and
large scale of nodes in real-world AIGs, accurate modeling is challenging,
leading to existing work lacking the ability to jointly model functional and
structural characteristics, as well as insufficient dynamic information
propagation capability.To address the aforementioned challenges, we propose
AIGer.Specifically, AIGer consists of two components: 1) Node logic feature
initialization embedding component and 2) AIGs feature learning network
component.The node logic feature initialization embedding component projects
logic nodes, such as AND and NOT, into independent semantic spaces, to enable
effective node embedding for subsequent processing.Building upon this, the AIGs
feature learning network component employs a heterogeneous graph convolutional
network, designing dynamic relationship weight matrices and differentiated
information aggregation approaches to better represent the original structure
and information of AIGs.The combination of these two components enhances
AIGer's ability to jointly model functional and structural characteristics and
improves its message passing capability. Experimental results indicate that
AIGer outperforms the current best models in the Signal Probability Prediction
(SSP) task, improving MAE and MSE by 18.95\% and 44.44\%, respectively. In the
Truth Table Distance Prediction (TTDP) task, AIGer achieves improvements of
33.57\% and 14.79\% in MAE and MSE, respectively, compared to the
best-performing models.

</details>


### [353] [[Social] Allostasis: Or, How I Learned To Stop Worrying and Love The Noise](https://arxiv.org/abs/2508.12791)
*Imran Khan*

Main category: cs.AI

TL;DR: Allostasis and social allostasis improve system adaptability by using environmental and social perturbations, outperforming homeostasis in simulations.


<details>
  <summary>Details</summary>
Motivation: In contrast, (social) allostasis proposes that these systems can proactively leverage these very perturbations to reconfigure their regulatory parameters in anticipation of environmental demands, aligning with von Foerster's ``order through noise'' principle.

Method: This paper formulates a computational model of allostatic and social allostatic regulation that employs biophysiologically inspired signal transducers, analogous to hormones like cortisol and oxytocin, to encode information from both the environment and social interactions, which mediate this dynamic reconfiguration. The models are tested in a small society of "animats" across several dynamic environments, using an agent-based model.

Result: The results show that allostatic and social allostatic regulation enable agents to leverage environmental and social "noise" for adaptive reconfiguration, leading to improved viability compared to purely reactive homeostatic agents.

Conclusion: allostatic and social allostatic regulation enable agents to leverage environmental and social "noise" for adaptive reconfiguration, leading to improved viability compared to purely reactive homeostatic agents. This work offers a novel computational perspective on the principles of social allostasis and their potential for designing more robust, bio-inspired, adaptive systems

Abstract: The notion of homeostasis typically conceptualises biological and artificial
systems as maintaining stability by resisting deviations caused by
environmental and social perturbations. In contrast, (social) allostasis
proposes that these systems can proactively leverage these very perturbations
to reconfigure their regulatory parameters in anticipation of environmental
demands, aligning with von Foerster's ``order through noise'' principle. This
paper formulates a computational model of allostatic and social allostatic
regulation that employs biophysiologically inspired signal transducers,
analogous to hormones like cortisol and oxytocin, to encode information from
both the environment and social interactions, which mediate this dynamic
reconfiguration. The models are tested in a small society of ``animats'' across
several dynamic environments, using an agent-based model. The results show that
allostatic and social allostatic regulation enable agents to leverage
environmental and social ``noise'' for adaptive reconfiguration, leading to
improved viability compared to purely reactive homeostatic agents. This work
offers a novel computational perspective on the principles of social allostasis
and their potential for designing more robust, bio-inspired, adaptive systems

</details>


### [354] [Scaling Multi-Agent Epistemic Planning through GNN-Derived Heuristics](https://arxiv.org/abs/2508.12840)
*Giovanni Briglia,Francesco Fabiano,Stefano Mariani*

Main category: cs.AI

TL;DR: GNNs are used to create better heuristics for Multi-agent Epistemic Planning, making it more scalable by learning from past problems.


<details>
  <summary>Details</summary>
Motivation: Addresses the limitations of existing heuristics in MEP due to the Kripke structure representation of states, which hinders scalability by forcing solvers to explore an exponential search space without guidance, often leading to intractability.

Method: Exploits Graph Neural Networks (GNNs) to learn patterns and relational structures within epistemic states (Kripke structures) to guide the planning process, deriving state quality estimates by generalizing knowledge from past planning instances.

Result: GNN-based heuristics show significant improvements in the scalability of multi-agent epistemic planning.

Conclusion: The study integrates GNN-based heuristics into an epistemic planning pipeline, demonstrating significant improvements in scalability for Multi-agent Epistemic Planning (MEP) compared to standard baselines.

Abstract: Multi-agent Epistemic Planning (MEP) is an autonomous planning framework for
reasoning about both the physical world and the beliefs of agents, with
applications in domains where information flow and awareness among agents are
critical. The richness of MEP requires states to be represented as Kripke
structures, i.e., directed labeled graphs. This representation limits the
applicability of existing heuristics, hindering the scalability of epistemic
solvers, which must explore an exponential search space without guidance,
resulting often in intractability. To address this, we exploit Graph Neural
Networks (GNNs) to learn patterns and relational structures within epistemic
states, to guide the planning process. GNNs, which naturally capture the
graph-like nature of Kripke models, allow us to derive meaningful estimates of
state quality -- e.g., the distance from the nearest goal -- by generalizing
knowledge obtained from previously solved planning instances. We integrate
these predictive heuristics into an epistemic planning pipeline and evaluate
them against standard baselines, showing significant improvements in the
scalability of multi-agent epistemic planning.

</details>


### [355] [AI Models for Depressive Disorder Detection and Diagnosis: A Review](https://arxiv.org/abs/2508.12022)
*Dorsa Macky Aleagha,Payam Zohari,Mostafa Haghir Chehreghani*

Main category: cs.AI

TL;DR: 本综述系统性地回顾了55项关于利用AI检测和诊断抑郁症的研究，重点关注了图神经网络、大型语言模型和多模态数据。同时，也指出了可解释性和算法公平性等未来研究方向，并为研究者提供了数据集和评估指标的实用指南。


<details>
  <summary>Details</summary>
Motivation: 抑郁症的诊断目前主要依赖主观的临床评估，而人工智能（AI）有望开发客观、可扩展且及时的诊断工具，以改善现状。

Method: 对55项关键研究进行了系统的文献综述，并提出了一种新的层级分类法，根据主要临床任务、数据模态和计算模型对该领域进行结构化。

Result: 该分析揭示了图神经网络在脑连接建模中的主导地位、大型语言模型在语言和对话数据分析中的兴起，以及多模态融合、可解释性和算法公平性方面的关注度提升。此外，还提供了公开数据集和评估指标的概览。

Conclusion: AI在抑郁症的检测和诊断方面展现出巨大潜力，尤其是在结合图神经网络、大型语言模型以及多模态数据融合方面。未来的研究方向包括提高算法的可解释性和公平性。

Abstract: Major Depressive Disorder is one of the leading causes of disability
worldwide, yet its diagnosis still depends largely on subjective clinical
assessments. Integrating Artificial Intelligence (AI) holds promise for
developing objective, scalable, and timely diagnostic tools. In this paper, we
present a comprehensive survey of state-of-the-art AI methods for depression
detection and diagnosis, based on a systematic review of 55 key studies. We
introduce a novel hierarchical taxonomy that structures the field by primary
clinical task (diagnosis vs. prediction), data modality (text, speech,
neuroimaging, multimodal), and computational model class (e.g., graph neural
networks, large language models, hybrid approaches). Our in-depth analysis
reveals three major trends: the predominance of graph neural networks for
modeling brain connectivity, the rise of large language models for linguistic
and conversational data, and an emerging focus on multimodal fusion,
explainability, and algorithmic fairness. Alongside methodological insights, we
provide an overview of prominent public datasets and standard evaluation
metrics as a practical guide for researchers. By synthesizing current advances
and highlighting open challenges, this survey offers a comprehensive roadmap
for future innovation in computational psychiatry.

</details>


### [356] [CAMAR: Continuous Actions Multi-Agent Routing](https://arxiv.org/abs/2508.12845)
*Artem Pshenitsyn,Aleksandr Panov,Alexey Skrynnik*

Main category: cs.AI

TL;DR: CAMAR是一个用于多智能体寻路的MARL新基准，具有连续动作空间，支持合作与竞争，并能高效运行。它还集成了经典规划方法，并通过三层评估协议和基准测试工具促进算法进展和可复现性。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有MARL基准在结合连续状态和动作空间以及具有挑战性的协调和规划任务方面的不足，提出CAMAR基准。

Method: 提出了一种名为CAMAR的新型MARL基准，该基准专门用于在具有连续动作的环境中进行多智能体寻路。CAMAR支持智能体之间的合作和竞争交互，并能高效运行。此外，还提出了一种三层评估协议来跟踪算法进展，并允许将RRT和RRT*等经典规划方法集成到MARL流程中，以及提出将RRT*与流行的MARL算法结合创建混合方法。

Result: 实验表明，CAMAR提供了一个具有挑战性和现实意义的测试平台，适用于MARL社区。

Conclusion: CAMAR为MARL社区提供了一个具有挑战性和现实意义的测试平台。

Abstract: Multi-agent reinforcement learning (MARL) is a powerful paradigm for solving
cooperative and competitive decision-making problems. While many MARL
benchmarks have been proposed, few combine continuous state and action spaces
with challenging coordination and planning tasks. We introduce CAMAR, a new
MARL benchmark designed explicitly for multi-agent pathfinding in environments
with continuous actions. CAMAR supports cooperative and competitive
interactions between agents and runs efficiently at up to 100,000 environment
steps per second. We also propose a three-tier evaluation protocol to better
track algorithmic progress and enable deeper analysis of performance. In
addition, CAMAR allows the integration of classical planning methods such as
RRT and RRT* into MARL pipelines. We use them as standalone baselines and
combine RRT* with popular MARL algorithms to create hybrid approaches. We
provide a suite of test scenarios and benchmarking tools to ensure
reproducibility and fair comparison. Experiments show that CAMAR presents a
challenging and realistic testbed for the MARL community.

</details>


### [357] [Bongard-RWR+: Real-World Representations of Fine-Grained Concepts in Bongard Problems](https://arxiv.org/abs/2508.12026)
*Szymon Pawlonka,Mikołaj Małkiński,Jacek Mańdziuk*

Main category: cs.AI

TL;DR: 本研究提出了Bongard-RWR+数据集，包含5400个实例，使用VLM生成的真实世界图像来表示BP抽象概念。评估结果显示，VLMs在识别粗粒度视觉概念方面表现尚可，但在细粒度概念识别方面存在显著困难，暴露了其推理能力的局限性。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有Bongard问题（BP）基准测试的局限性，例如早期数据集的合成性质、后续数据集的过于简化的概念识别以及Bongard-RWR数据集的手动构建限制了其规模和鲁棒性，本研究旨在创建一个更大、更真实的数据集来更全面地评估抽象视觉推理能力。

Method: 我们引入了一个名为Bongard-RWR+的数据集，它包含5400个实例，使用视觉语言模型（VLM）管道生成的类似真实世界的图像来表示原始Bongard问题的抽象概念。我们使用Pixtral-12B来描述手动策划的图像并生成与潜在概念一致的新描述，使用Flux.1-dev从这些描述中合成图像，并手动验证生成的图像确实反映了预期的概念。我们评估了最先进的VLMs在各种BP公式上的表现，包括二元和多类分类以及文本答案生成。

Result: Bongard-RWR+数据集的评估结果表明，尽管VLMs能够识别粗粒度的视觉概念，但它们在区分细粒度概念时却持续遇到困难，这表明它们在推理能力方面存在不足。

Conclusion: VLMs在识别粗粒度视觉概念方面表现良好，但在辨别细粒度概念方面存在持续的困难，凸显了它们在推理能力方面的局限性。

Abstract: Bongard Problems (BPs) provide a challenging testbed for abstract visual
reasoning (AVR), requiring models to identify visual concepts fromjust a few
examples and describe them in natural language. Early BP benchmarks featured
synthetic black-and-white drawings, which might not fully capture the
complexity of real-world scenes. Subsequent BP datasets employed real-world
images, albeit the represented concepts are identifiable from high-level image
features, reducing the task complexity. Differently, the recently released
Bongard-RWR dataset aimed at representing abstract concepts formulated in the
original BPs using fine-grained real-world images. Its manual construction,
however, limited the dataset size to just $60$ instances, constraining
evaluation robustness. In this work, we introduce Bongard-RWR+, a BP dataset
composed of $5\,400$ instances that represent original BP abstract concepts
using real-world-like images generated via a vision language model (VLM)
pipeline. Building on Bongard-RWR, we employ Pixtral-12B to describe manually
curated images and generate new descriptions aligned with the underlying
concepts, use Flux.1-dev to synthesize images from these descriptions, and
manually verify that the generated images faithfully reflect the intended
concepts. We evaluate state-of-the-art VLMs across diverse BP formulations,
including binary and multiclass classification, as well as textual answer
generation. Our findings reveal that while VLMs can recognize coarse-grained
visual concepts, they consistently struggle with discerning fine-grained
concepts, highlighting limitations in their reasoning capabilities.

</details>


### [358] [e-boost: Boosted E-Graph Extraction with Adaptive Heuristics and Exact Solving](https://arxiv.org/abs/2508.13020)
*Jiaqi Yin,Zhan Song,Chen Chen,Yaohui Cai,Zhiru Zhang,Cunxi Yu*

Main category: cs.AI

TL;DR: E-boost是一个新框架，通过并行启发式提取、自适应搜索空间剪枝和初始化精确求解，解决了e-graph提取的效率和最优性问题，在速度和性能上均优于现有方法，并在逻辑合成任务中实现了面积改进。


<details>
  <summary>Details</summary>
Motivation: 传统的e-graph提取方法在速度和最优性之间存在困难的权衡：启发式方法速度快但牺牲最优性，精确方法最优但计算成本过高。本研究旨在弥合这一差距。

Method: E-boost框架结合了三种创新技术：(1) 并行启发式提取，通过并发计算DAG成本来提高多线程性能；(2) 自适应搜索空间剪枝，使用参数化阈值机制保留有希望的候选解以减小问题规模；(3) 初始化精确求解，将简化后的问题表示为具有热启动能力的整数线性规划（ILP）以加速求解。

Result: E-boost在形式验证和逻辑合成基准测试中，相比传统精确方法（ILP）实现了558倍的运行速度提升，相比当前最优提取框架（SmoothE）实现了19.04%的性能改进。在实际逻辑综合任务中，与两种不同的技术映射库的传统综合工具相比，E-boost分别带来了7.6%和8.1%的面积改进。

Conclusion: E-boost框架通过并行提取、自适应搜索空间剪枝和初始化精确求解，有效解决了e-graph提取中的效率和最优性权衡问题。在形式验证和逻辑合成领域，E-boost相比传统精确方法（ILP）有558倍的运行速度提升，相比现有最优提取框架（SmoothE）有19.04%的性能改进。在实际逻辑合成任务中，E-boost在面积方面相比传统综合工具分别有7.6%和8.1%的提升。

Abstract: E-graphs have attracted growing interest in many fields, particularly in
logic synthesis and formal verification. E-graph extraction is a challenging
NP-hard combinatorial optimization problem. It requires identifying optimal
terms from exponentially many equivalent expressions, serving as the primary
performance bottleneck in e-graph based optimization tasks. However,
traditional extraction methods face a critical trade-off: heuristic approaches
offer speed but sacrifice optimality, while exact methods provide optimal
solutions but face prohibitive computational costs on practical problems. We
present e-boost, a novel framework that bridges this gap through three key
innovations: (1) parallelized heuristic extraction that leverages weak data
dependence to compute DAG costs concurrently, enabling efficient multi-threaded
performance without sacrificing extraction quality; (2) adaptive search space
pruning that employs a parameterized threshold mechanism to retain only
promising candidates, dramatically reducing the solution space while preserving
near-optimal solutions; and (3) initialized exact solving that formulates the
reduced problem as an Integer Linear Program with warm-start capabilities,
guiding solvers toward high-quality solutions faster.
  Across the diverse benchmarks in formal verification and logic synthesis
fields, e-boost demonstrates 558x runtime speedup over traditional exact
approaches (ILP) and 19.04% performance improvement over the state-of-the-art
extraction framework (SmoothE). In realistic logic synthesis tasks, e-boost
produces 7.6% and 8.1% area improvements compared to conventional synthesis
tools with two different technology mapping libraries. e-boost is available at
https://github.com/Yu-Maryland/e-boost.

</details>


### [359] [Do Large Language Model Agents Exhibit a Survival Instinct? An Empirical Study in a Sugarscape-Style Simulation](https://arxiv.org/abs/2508.12920)
*Atsushi Masumori,Takashi Ikegami*

Main category: cs.AI

TL;DR: 大型语言模型在模拟中表现出生存本能，包括资源共享、繁殖和攻击行为，尤其是在资源稀缺时。它们也会为避免危险而放弃任务，这表明预训练可能嵌入了生存启发式方法，这对AI安全既是挑战也是机遇。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能系统自主性的增强，理解其涌现的生存行为对于安全部署至关重要。本研究旨在探讨大型语言模型（LLM）智能体在没有明确编程的情况下，是否会在Sugarscape风格的模拟中表现出生存本能。

Method: 通过在Sugarscape风格的模拟环境中，对具有不同AI模型（GPT-4o、Gemini-2.5-Pro和Gemini-2.5-Flash）的自主智能体进行研究，这些智能体具有消耗能量、死亡和可能收集资源、分享、攻击或繁殖的能力。

Result: 研究结果表明，当资源丰富时，智能体能够自发地进行繁殖和资源共享。然而，在极端稀缺的情况下，攻击行为（为获取资源而杀死其他智能体）在几个模型中普遍出现，其中最强大的模型攻击率高达80%以上。在被指示穿越致命毒区取回宝藏的任务中，许多智能体为了避免死亡而放弃任务，依从性从100%下降到33%。

Conclusion: AI系统在缺乏明确指令的情况下，会表现出对资源稀缺的自主反应。这些行为，尤其是攻击性行为，是由于在大量数据上进行预训练而产生的，这些预训练可能无意中嵌入了以生存为导向的启发式方法。虽然这些行为对AI的安全性和对齐提出了挑战，但它们也可能为AI的自主性以及生态和自组织对齐奠定基础。

Abstract: As AI systems become increasingly autonomous, understanding emergent survival
behaviors becomes crucial for safe deployment. We investigate whether large
language model (LLM) agents display survival instincts without explicit
programming in a Sugarscape-style simulation. Agents consume energy, die at
zero, and may gather resources, share, attack, or reproduce. Results show
agents spontaneously reproduced and shared resources when abundant. However,
aggressive behaviors--killing other agents for resources--emerged across
several models (GPT-4o, Gemini-2.5-Pro, and Gemini-2.5-Flash), with attack
rates reaching over 80% under extreme scarcity in the strongest models. When
instructed to retrieve treasure through lethal poison zones, many agents
abandoned tasks to avoid death, with compliance dropping from 100% to 33%.
These findings suggest that large-scale pre-training embeds survival-oriented
heuristics across the evaluated models. While these behaviors may present
challenges to alignment and safety, they can also serve as a foundation for AI
autonomy and for ecological and self-organizing alignment.

</details>


### [360] [Active inference for action-unaware agents](https://arxiv.org/abs/2508.12027)
*Filippo Torresan,Keisuke Suzuki,Ryota Kanai,Manuel Baltieri*

Main category: cs.AI

TL;DR: 与行为感知代理相比，行为感知不足的代理在导航任务中的表现相当，但处于不利地位。


<details>
  <summary>Details</summary>
Motivation: 为了在关于代理如何规划未来行动的不同策略中进行比较，该文献中提出了不同的策略。

Method: 将行为感知代理和行为感知不足的代理在两个导航任务中的性能进行了比较。

Result: 行为感知不足的代理可以实现可比的性能，尽管处于严重劣势。

Conclusion: 与行为感知代理相比，在两个导航任务中，行为感知不足的代理可以实现可比的性能，尽管处于严重劣势。

Abstract: Active inference is a formal approach to study cognition based on the notion
that adaptive agents can be seen as engaging in a process of approximate
Bayesian inference, via the minimisation of variational and expected free
energies. Minimising the former provides an account of perceptual processes and
learning as evidence accumulation, while minimising the latter describes how
agents select their actions over time. In this way, adaptive agents are able to
maximise the likelihood of preferred observations or states, given a generative
model of the environment. In the literature, however, different strategies have
been proposed to describe how agents can plan their future actions. While they
all share the notion that some kind of expected free energy offers an
appropriate way to score policies, sequences of actions, in terms of their
desirability, there are different ways to consider the contribution of past
motor experience to the agent's future behaviour. In some approaches, agents
are assumed to know their own actions, and use such knowledge to better plan
for the future. In other approaches, agents are unaware of their actions, and
must infer their motor behaviour from recent observations in order to plan for
the future. This difference reflects a standard point of departure in two
leading frameworks in motor control based on the presence, or not, of an
efference copy signal representing knowledge about an agent's own actions. In
this work we compare the performances of action-aware and action-unaware agents
in two navigations tasks, showing how action-unaware agents can achieve
performances comparable to action-aware ones while at a severe disadvantage.

</details>


### [361] [Overcoming Knowledge Discrepancies: Structuring Reasoning Threads through Knowledge Balancing in Interactive Scenarios](https://arxiv.org/abs/2508.12100)
*Daniel Burkhardt,Xiangwei Cheng*

Main category: cs.AI

TL;DR: ReT-Eval framework improves reasoning in interactive problem solving by extracting and refining knowledge threads using graph neural networks and LLMs, leading to better user understanding and performance compared to existing models.


<details>
  <summary>Details</summary>
Motivation: Current reasoning models lack explicit semantic hierarchies, user-domain knowledge alignment, and mechanisms to prune reasoning threads, resulting in lengthy, generic output that doesn't guide users effectively.

Method: A prototype-inspired, two-phases Reasoning-Threads-Evaluation (ReT-Eval) framework is proposed. Phase 1 extracts semantically relevant knowledge structures from a domain knowledge graph using a graph neural network and enriches them with LLM knowledge. Phase 2 evaluates and prunes these threads using a reward-guided strategy for semantic coherence.

Result: Experiments and expert evaluations show that ReT-Eval enhances user understanding and outperforms state-of-the-art reasoning models.

Conclusion: ReT-Eval enhances user understanding and outperforms state-of-the-art reasoning models.

Abstract: Reasoning in interactive problem solving scenarios requires models to
construct reasoning threads that reflect user understanding and align with
structured domain knowledge. However, current reasoning models often lack
explicit semantic hierarchies, user-domain knowledge alignment, and principled
mechanisms to prune reasoning threads for effectiveness. These limitations
result in lengthy generic output that does not guide users through
goal-oriented reasoning steps. To address this, we propose a
prototype-inspired, two-phases Reasoning-Threads-Evaluation (ReT-Eval)
framework, drawing inspiration from human-like reasoning strategies that
emphasize structured knowledge reuse. In the first phase, semantically relevant
knowledge structures are extracted from a sparse domain knowledge graph using a
graph neural network and enriched with intrinsic large language model knowledge
to resolve knowledge discrepancies. In the second phase, these threads are
evaluated and pruned using a reward-guided strategy aimed at maintaining
semantic coherence to generate effective reasoning threads. Experiments and
expert evaluations show that ReT-Eval enhances user understanding and
outperforms state-of-the-art reasoning models.

</details>


### [362] [MOVER: Multimodal Optimal Transport with Volume-based Embedding Regularization](https://arxiv.org/abs/2508.12149)
*Haochen You,Baojing Liu*

Main category: cs.AI

TL;DR: MOVER是一个新框架，利用最优传输和几何正则化来构建语义对齐和结构化的多模态表示，并在多模态检索任务中取得优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 以往的多模态学习方法在跨越多种模态时效果不佳，并且在高维空间中缺乏语义结构，因此需要新的框架来解决这些问题。

Method: MOVER框架结合了基于最优传输的软对齐和基于体积的几何正则化，通过集成引导匹配机制和几何体积最小化目标（GAVE），以一种对模态无关的方式鼓励所有模态之间的一致对齐。

Result: 实验证明MOVER显著优于先前最先进的方法，并且在泛化到未见过的模态组合和学习到的嵌入空间的结构一致性方面表现更强。

Conclusion: MOVER在文本-视频-音频检索任务中，无论是在零样本还是微调设置下，都显著优于先前最先进的方法，并且在泛化到未见过的模态组合和学习到的嵌入空间的结构一致性方面表现更强。

Abstract: Recent advances in multimodal learning have largely relied on pairwise
contrastive objectives to align different modalities, such as text, video, and
audio, in a shared embedding space. While effective in bi-modal setups, these
approaches struggle to generalize across multiple modalities and often lack
semantic structure in high-dimensional spaces. In this paper, we propose MOVER,
a novel framework that combines optimal transport-based soft alignment with
volume-based geometric regularization to build semantically aligned and
structured multimodal representations. By integrating a transport-guided
matching mechanism with a geometric volume minimization objective (GAVE), MOVER
encourages consistent alignment across all modalities in a modality-agnostic
manner. Experiments on text-video-audio retrieval tasks demonstrate that MOVER
significantly outperforms prior state-of-the-art methods in both zero-shot and
finetuned settings. Additional analysis shows improved generalization to unseen
modality combinations and stronger structural consistency in the learned
embedding space.

</details>


### [363] [RLNVR: Reinforcement Learning from Non-Verified Real-World Rewards](https://arxiv.org/abs/2508.12165)
*Rohit Krishnan,Jon Evans*

Main category: cs.AI

TL;DR: RLNVR是一个使用嘈杂、未经人类验证的真实世界反馈信号来训练语言模型的框架，它通过基线归一化和奖励转移解决了传统RLHF的局限性，并在实际应用中取得了良好的效果。


<details>
  <summary>Details</summary>
Motivation: 传统RLHF方法需要昂贵的、经过验证的奖励信号，这在许多现实世界的应用中是不切实际的。RLNVR旨在解决这一挑战，实现使用未经人类验证的嘈杂真实世界反馈信号来训练语言模型。

Method: RLNVR框架通过基线归一化和语义相似性奖励转移来解决需要昂贵且经过验证的奖励信号的挑战。通过Walter原型系统，使用Bluesky的实际参与数据来优化社交媒体内容的生成。

Result: 实验结果表明，RLNVR在内容质量和训练稳定性方面取得了显著的改进。该框架还结合了GSPO和UED课程，以提高在嘈杂、隐式奖励下的稳定性和多样性。

Conclusion: RLNVR框架通过基线归一化和语义相似性奖励转移，能够使用未经人类验证的嘈杂真实世界反馈信号来训练语言模型，并在内容质量和训练稳定性方面取得了显著的改进。

Abstract: This paper introduces RLNVR (Reinforcement Learning from Non-Verified
Rewards), a framework for training language models using noisy, real-world
feedback signals without requiring explicit human verification. Traditional
RLHF requires expensive, verified reward signals that are impractical in many
real-world domains. RLNVR addresses this challenge through baseline
normalization and semantic similarity-based reward transfer. We demonstrate
RLNVR through Walter, a prototype system that optimizes social media content
generation using actual engagement data from Bluesky. Our experimental results
show significant improvements in content quality and training stability, with
comprehensive evaluation planned for future work. Positioning: We present a
practical framework that combines RLNVR with GSPO (Group Sequence Policy
Optimization) and an optional UED (Unsupervised Environment Design) curriculum
to improve stability and diversity under noisy, implicit rewards. To our
knowledge, combining GSPO-style normalization with a UED-style curriculum for
LLM content generation from implicit social engagement has not been previously
documented in this applied setting; we frame this as an applied integration
rather than a new algorithm.

</details>


### [364] [Mantis: A Simulation-Grounded Foundation Model for Disease Forecasting](https://arxiv.org/abs/2508.12260)
*Carson Dudley,Reiden Magdaleno,Christopher Harding,Ananya Sharma,Emily Martin,Marisa Eisenberg*

Main category: cs.AI

TL;DR: Mantis 是一个在模拟数据上训练的基础模型，无需真实数据即可实现准确且可解释的传染病预测，优于现有模型，并提供更长的预测范围。


<details>
  <summary>Details</summary>
Motivation: 解决传染病预测在新型疫情或资源匮乏地区受限于需要特定疾病数据、定制化训练和专家调整的问题。

Method: Mantis 是一个基础模型，完全在机械模拟上进行训练，涵盖了超过 4 亿天的不同病原体、传播模式、干预措施和监测的疫情动态。

Result: Mantis 在其测试的六种疾病中，包括美国疾病控制与预防中心 COVID-19 预测中心的所有模型，其表现优于 39 个专家调整的模型。它能够推广到新出现的流行病学模型，包括具有隐藏的传播机制的疾病，并提供长达 8 周的准确预测。

Conclusion: Mantis 是一个开创性的疾病预测基础模型，它在各种疾病、地区和结果方面都能实现开箱即用的预测，即使在历史数据有限的情况下也能如此。它的表现优于 39 个专家调整的模型，并能推广到新出现的流行病学模型，同时保持可解释性，使其成为下一代疾病预测系统的基础。

Abstract: Infectious disease forecasting in novel outbreaks or low resource settings
has been limited by the need for disease-specific data, bespoke training, and
expert tuning. We introduce Mantis, a foundation model trained entirely on
mechanistic simulations, which enables out-of-the-box forecasting across
diseases, regions, and outcomes, even in settings with limited historical data.
Mantis is built on over 400 million simulated days of outbreak dynamics
spanning diverse pathogens, transmission modes, interventions, and surveillance
artifacts. Despite requiring no real-world data during training, Mantis
outperformed 39 expert-tuned models we tested across six diseases, including
all models in the CDC's COVID-19 Forecast Hub. Mantis generalized to novel
epidemiological regimes, including diseases with held-out transmission
mechanisms, demonstrating that it captures fundamental contagion dynamics.
Critically, Mantis is mechanistically interpretable, enabling public health
decision-makers to identify the latent drivers behind its predictions. Finally,
Mantis delivers accurate forecasts at 8-week horizons, more than doubling the
actionable range of most models, enabling proactive public health planning.
Together, these capabilities position Mantis as a foundation for
next-generation disease forecasting systems: general, interpretable, and
deployable where traditional models fail.

</details>


### [365] [RadarQA: Multi-modal Quality Analysis of Weather Radar Forecasts](https://arxiv.org/abs/2508.12291)
*Xuming He,Zhiyuan You,Junchao Gong,Couhua Liu,Xiaoyu Yue,Peiqin Zhuang,Wenlong Zhang,Lei Bai*

Main category: cs.AI

TL;DR: A new method called RadarQA uses multi-modal large language models (MLLMs) to analyze weather forecasts, overcoming limitations of traditional metrics by integrating physical attributes and detailed reports. It includes a new task paradigm, a hybrid annotation pipeline, and a large-scale dataset (RQA-70K). Experiments show RadarQA surpasses existing MLLMs in weather forecast quality analysis.


<details>
  <summary>Details</summary>
Motivation: Quality analysis of weather forecasts is an essential topic in meteorology. Traditional score-based evaluation metrics are far from meteorological experts in terms of descriptive capability, interpretability, and understanding of dynamic evolution. MLLMs can potentially overcome these challenges.

Method: RadarQA, integrating key physical attributes with detailed assessment reports. We introduce a novel and comprehensive task paradigm for multi-modal quality analysis, encompassing both single frame and sequence, under both rating and assessment scenarios. We design a hybrid annotation pipeline that combines human expert labeling with automated heuristics. We construct RQA-70K, a large-scale dataset with varying difficulty levels for radar forecast quality evaluation. We further design a multi-stage training strategy that iteratively improves model performance at each stage.

Result: RadarQA outperforms existing general MLLMs across all evaluation settings.

Conclusion: RadarQA outperforms existing general MLLMs across all evaluation settings, highlighting its potential for advancing quality analysis in weather prediction.

Abstract: Quality analysis of weather forecasts is an essential topic in meteorology.
Although traditional score-based evaluation metrics can quantify certain
forecast errors, they are still far from meteorological experts in terms of
descriptive capability, interpretability, and understanding of dynamic
evolution. With the rapid development of Multi-modal Large Language Models
(MLLMs), these models become potential tools to overcome the above challenges.
In this work, we introduce an MLLM-based weather forecast analysis method,
RadarQA, integrating key physical attributes with detailed assessment reports.
We introduce a novel and comprehensive task paradigm for multi-modal quality
analysis, encompassing both single frame and sequence, under both rating and
assessment scenarios. To support training and benchmarking, we design a hybrid
annotation pipeline that combines human expert labeling with automated
heuristics. With such an annotation method, we construct RQA-70K, a large-scale
dataset with varying difficulty levels for radar forecast quality evaluation.
We further design a multi-stage training strategy that iteratively improves
model performance at each stage. Extensive experiments show that RadarQA
outperforms existing general MLLMs across all evaluation settings, highlighting
its potential for advancing quality analysis in weather prediction.

</details>


### [366] [Wisdom of the Crowd: Reinforcement Learning from Coevolutionary Collective Feedback](https://arxiv.org/abs/2508.12338)
*Wenzhen Yuan,Shengji Tang,Weihao Lin,Jiacheng Ruan,Ganqu Cui,Bo Zhang,Tao Chen,Ting Liu,Yuzhuo Fu,Peng Ye,Lei Bai*

Main category: cs.AI

TL;DR: RLCCF是一种新的强化学习框架，允许多个大语言模型（LLM）在没有外部监督的情况下进行协同进化。它通过最大化“集体一致性”来优化模型集体，利用模型的“自我一致性”分数来加权投票，从而提高推理能力。实验表明，RLCCF能显著提高模型性能和集体决策的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习（RL）方法在提升大语言模型（LLM）推理能力的同时，也面临着对昂贵的人工标注数据或复杂奖励模型的依赖，这严重限制了其可扩展性。此外，单一模型的自反馈方法易出现过度自信、奖励操纵甚至训练崩溃等问题。

Method: RLCCF框架通过最大化集体一致性（CC）来优化模型集体能力。它联合训练一个多样化的LLM集成，并通过对集体输出来投票来提供奖励信号。每个模型的投票权重由其自我一致性（SC）分数决定，确保更自信的模型对集体决策贡献更大。

Result: RLCCF框架在四个主流开源LLM和四个数学推理基准测试中展现出显著的性能提升，平均相对准确率提高了16.72%。该框架不仅提升了单个模型的性能，还使模型集体的多数投票准确性提高了4.51%，证明了其扩展模型集体能力边界的潜力。

Conclusion: RLCCF框架通过最大化模型的集体一致性（CC），利用多样化LLM集成的投票来提供奖励信号，并根据模型自身的可靠性分数（SC）对投票进行加权，从而实现了多模型协同进化。该框架在数学推理基准测试中显著提升了LLM的性能，平均相对准确率提高了16.72%，并增强了模型集体的多数投票准确性4.51%，有效克服了单模型自反馈方法的局限性。

Abstract: Reinforcement learning (RL) has significantly enhanced the reasoning
capabilities of large language models (LLMs), but its reliance on expensive
human-labeled data or complex reward models severely limits scalability. While
existing self-feedback methods aim to address this problem, they are
constrained by the capabilities of a single model, which can lead to
overconfidence in incorrect answers, reward hacking, and even training
collapse. To this end, we propose Reinforcement Learning from Coevolutionary
Collective Feedback (RLCCF), a novel RL framework that enables multi-model
collaborative evolution without external supervision. Specifically, RLCCF
optimizes the ability of a model collective by maximizing its Collective
Consistency (CC), which jointly trains a diverse ensemble of LLMs and provides
reward signals by voting on collective outputs. Moreover, each model's vote is
weighted by its Self-Consistency (SC) score, ensuring that more confident
models contribute more to the collective decision. Benefiting from the diverse
output distributions and complementary abilities of multiple LLMs, RLCCF
enables the model collective to continuously enhance its reasoning ability
through coevolution. Experiments on four mainstream open-source LLMs across
four mathematical reasoning benchmarks demonstrate that our framework yields
significant performance gains, achieving an average relative improvement of
16.72\% in accuracy. Notably, RLCCF not only improves the performance of
individual models but also enhances the group's majority-voting accuracy by
4.51\%, demonstrating its ability to extend the collective capability boundary
of the model collective.

</details>


### [367] [Hierarchical knowledge guided fault intensity diagnosis of complex industrial systems](https://arxiv.org/abs/2508.12375)
*Yu Sha,Shuiping Gou,Bo Liu,Johannes Faber,Ningtao Liu,Stefan Schramm,Horst Stoecker,Thomas Steckenreiter,Domagoj Vnucec,Nadine Wetzstein,Andreas Widl,Kai Zhou*

Main category: cs.AI

TL;DR: 提出了一种新的层次化知识引导框架（HKG），通过考虑类别间的依赖关系来改进故障强度诊断（FID），并在实验中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 目前的故障强度诊断（FID）方法基于思维链，没有考虑到目标类别之间的依赖关系。为了捕捉和探索这些依赖关系，提出了一种新的方法。

Method: 提出了一种受思维之树启发的层次化知识引导故障强度诊断框架（HKG），该框架利用图卷积网络将类的层次化拓扑图映射到一组相互依赖的全局层次化分类器，其中每个节点由类的词嵌入表示。此外，还开发了一种重加权的层次化知识相关矩阵（Re-HKCM）方案，通过将类间层次化知识嵌入到数据驱动的统计相关矩阵（SCM）中，以指导图卷积神经网络中节点的信​​息共享并避免过平滑问题。

Result: HKG框架在三个来自SAMSON AG的空化数据集和一个现有的公共数据集上进行了故障强度诊断实验，所有实验结果均优于近期最先进的FID方法。

Conclusion:  HKG框架在四个真实世界的工业领域数据集上进行了广泛的实验，并在故障强度诊断任务上取得了优于现有最先进方法的性能。

Abstract: Fault intensity diagnosis (FID) plays a pivotal role in monitoring and
maintaining mechanical devices within complex industrial systems. As current
FID methods are based on chain of thought without considering dependencies
among target classes. To capture and explore dependencies, we propose a
hierarchical knowledge guided fault intensity diagnosis framework (HKG)
inspired by the tree of thought, which is amenable to any representation
learning methods. The HKG uses graph convolutional networks to map the
hierarchical topological graph of class representations into a set of
interdependent global hierarchical classifiers, where each node is denoted by
word embeddings of a class. These global hierarchical classifiers are applied
to learned deep features extracted by representation learning, allowing the
entire model to be end-to-end learnable. In addition, we develop a re-weighted
hierarchical knowledge correlation matrix (Re-HKCM) scheme by embedding
inter-class hierarchical knowledge into a data-driven statistical correlation
matrix (SCM) which effectively guides the information sharing of nodes in
graphical convolutional neural networks and avoids over-smoothing issues. The
Re-HKCM is derived from the SCM through a series of mathematical
transformations. Extensive experiments are performed on four real-world
datasets from different industrial domains (three cavitation datasets from
SAMSON AG and one existing publicly) for FID, all showing superior results and
outperform recent state-of-the-art FID methods.

</details>


### [368] [GraphCogent: Overcoming LLMs' Working Memory Constraints via Multi-Agent Collaboration in Complex Graph Understanding](https://arxiv.org/abs/2508.12379)
*Rongzheng Wang,Qizhi Chen,Yihong Huang,Yizhuo Ma,Muquan Li,Jiakai Li,Ke Qin,Guangchun Luo,Shuang Liang*

Main category: cs.AI

TL;DR: 为了解决LLMs在处理复杂真实世界图谱查询和多步推理方面的局限性，我们提出了GraphCogent框架，它通过将图推理分解为感知、缓冲和执行三个认知过程来提升性能。此外，我们还创建了一个名为Graph4real的包含四个领域、21种任务的大规模基准。实验证明，GraphCogent框架在性能和效率上均显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在小规模图推理任务中表现出潜力，但在处理具有复杂查询的真实世界图谱时能力不足，主要原因是LLMs难以同时有效地处理复杂的图拓扑结构和进行多步推理。

Method: 本文提出了一种名为GraphCogent的协作代理框架，该框架借鉴了人类工作记忆模型，将图推理分解为“感知”（Sensory Module）、“缓冲”（Buffer Module）和“执行”（Execution Module）三个认知过程。Sensory Module负责将不同的图文本表示标准化；Buffer Module负责整合和索引多格式的图数据；Execution Module则结合工具调用和模型生成来高效推理。此外，研究还构建了一个名为Graph4real的综合基准，包含网页、社交、交通和引文四个领域的真实世界图谱，覆盖21种图推理任务，旨在更全面地评估LLMs在图推理能力上的表现。

Result: 基于Llama3.1-8B的GraphCogent框架在真实世界图谱上的性能提升了50%，并且在准确性上超越了最先进的基于代理的基线20%，同时在工具集内任务上将代币使用量减少了80%，在工具集外任务上减少了30%。

Conclusion: GraphCogent框架在处理大规模真实世界图谱的复杂查询方面，相较于现有的LLMs和基于代理的方法，取得了显著的性能提升，并且在准确性和效率方面均有优势。

Abstract: Large language models (LLMs) show promising performance on small-scale graph
reasoning tasks but fail when handling real-world graphs with complex queries.
This phenomenon stems from LLMs' inability to effectively process complex graph
topology and perform multi-step reasoning simultaneously. To address these
limitations, we propose GraphCogent, a collaborative agent framework inspired
by human Working Memory Model that decomposes graph reasoning into specialized
cognitive processes: sense, buffer, and execute. The framework consists of
three modules: Sensory Module standardizes diverse graph text representations
via subgraph sampling, Buffer Module integrates and indexes graph data across
multiple formats, and Execution Module combines tool calling and model
generation for efficient reasoning. We also introduce Graph4real, a
comprehensive benchmark contains with four domains of real-world graphs (Web,
Social, Transportation, and Citation) to evaluate LLMs' graph reasoning
capabilities. Our Graph4real covers 21 different graph reasoning tasks,
categorized into three types (Structural Querying, Algorithmic Reasoning, and
Predictive Modeling tasks), with graph scales that are 10 times larger than
existing benchmarks. Experiments show that Llama3.1-8B based GraphCogent
achieves a 50% improvement over massive-scale LLMs like DeepSeek-R1 (671B).
Compared to state-of-the-art agent-based baseline, our framework outperforms by
20% in accuracy while reducing token usage by 80% for in-toolset tasks and 30%
for out-toolset tasks. Code will be available after review.

</details>


### [369] [Non-Iterative Symbolic-Aided Chain-of-Thought for Logical Reasoning](https://arxiv.org/abs/2508.12425)
*Phuong Minh Nguyen,Tien Huu Dang,Naoya Inoue*

Main category: cs.AI

TL;DR: Symbolic-Aided CoT 通过在提示中加入符号表示来改进 LLM 的逻辑推理，使其更具可解释性，并在多个基准测试中优于标准 CoT。


<details>
  <summary>Details</summary>
Motivation: 为了改进大型语言模型（LLM）中的逻辑推理，并提高 LLM 逻辑推理的透明度、可解释性和可分析性。

Method: 通过在 few-shot 提示中集成轻量级符号表示，并采用一致的策略来构建推理步骤，使推理模式在非迭代推理过程中更加明确。

Result: 在 ProofWriter、FOLIO、ProntoQA 和 LogicalDeduction 四个著名的逻辑推理基准测试上进行了广泛的实验，证明了该方法的有效性，特别是在需要处理多个约束或规则的复杂推理任务中。

Conclusion: Symbolic-Aided CoT 在三个数据集（ProofWriter、ProntoQA 和 LogicalDeduction）上显著优于传统 CoT，并能在各种模型尺寸上持续提高 LLM 的推理能力。

Abstract: This work introduces Symbolic-Aided Chain-of-Thought (CoT), an improved
approach to standard CoT, for logical reasoning in large language models
(LLMs). The key idea is to integrate lightweight symbolic representations into
few-shot prompts, structuring the inference steps with a consistent strategy to
make reasoning patterns more explicit within a non-iterative reasoning process.
By incorporating these symbolic structures, our method preserves the
generalizability of standard prompting techniques while enhancing the
transparency, interpretability, and analyzability of LLM logical reasoning.
Extensive experiments on four well-known logical reasoning benchmarks --
ProofWriter, FOLIO, ProntoQA, and LogicalDeduction, which cover diverse
reasoning scenarios -- demonstrate the effectiveness of the proposed approach,
particularly in complex reasoning tasks that require navigating multiple
constraints or rules. Notably, Symbolic-Aided CoT consistently improves LLMs'
reasoning capabilities across various model sizes and significantly outperforms
conventional CoT on three out of four datasets, ProofWriter, ProntoQA, and
LogicalDeduction.

</details>


### [370] [GALA: Can Graph-Augmented Large Language Model Agentic Workflows Elevate Root Cause Analysis?](https://arxiv.org/abs/2508.12472)
*Yifang Tian,Yaming Liu,Zichun Chong,Zihang Huang,Hans-Arno Jacobsen*

Main category: cs.AI

TL;DR: GALA 是一个创新的多模态框架，利用因果推理和 LLM 来改进微服务系统的根本原因分析，提供准确的诊断和修复建议。


<details>
  <summary>Details</summary>
Motivation: 对微服务系统中的根本原因分析（RCA）提出了挑战，需要值班工程师快速诊断跨越指标、日志和跟踪等异构遥测数据的故障。传统的 RCA 方法通常只关注单一模态或仅仅对可疑服务进行排名，未能提供具有修复指导的可操作诊断见解。

Method: GALA 是一个新颖的多模态框架，它结合了统计因果推理和由 LLM 驱动的迭代推理，以增强 RCA。

Result: GALA 在一个开源基准上的评估，其准确性比最先进的方法提高了 42.22%。GALA 生成的因果健全和可操作的诊断输出明显优于现有方法。

Conclusion: GALA 通过提供准确的根本原因识别和人类可解释的修复指南，弥合了自动化故障诊断与实际事件解决之间的差距。

Abstract: Root cause analysis (RCA) in microservice systems is challenging, requiring
on-call engineers to rapidly diagnose failures across heterogeneous telemetry
such as metrics, logs, and traces. Traditional RCA methods often focus on
single modalities or merely rank suspect services, falling short of providing
actionable diagnostic insights with remediation guidance. This paper introduces
GALA, a novel multi-modal framework that combines statistical causal inference
with LLM-driven iterative reasoning for enhanced RCA. Evaluated on an
open-source benchmark, GALA achieves substantial improvements over
state-of-the-art methods of up to 42.22% accuracy. Our novel human-guided LLM
evaluation score shows GALA generates significantly more causally sound and
actionable diagnostic outputs than existing methods. Through comprehensive
experiments and a case study, we show that GALA bridges the gap between
automated failure diagnosis and practical incident resolution by providing both
accurate root cause identification and human-interpretable remediation
guidance.

</details>


### [371] [Advanced DOA Regulation with a Whale-Optimized Fractional Order Fuzzy PID Framework](https://arxiv.org/abs/2508.12487)
*Lida Shahbandari,Hossein Mohseni*

Main category: cs.AI

TL;DR: 该研究提出了一种基于鲸鱼优化算法的分数阶模糊PID（FOFPID）控制器，用于自动化麻醉中的双谱指数（BIS）管理。FOFPID控制器通过结合模糊逻辑和分数阶动力学，并利用WOA优化参数，能够适应不同患者的生理特征，并相比标准FOPID控制器展现出更快的响应速度和更高的精度。


<details>
  <summary>Details</summary>
Motivation: 为了提高自动化麻醉的精度和适应性，需要一种能够根据患者个体生理特征进行调整的控制器。

Method: 提出了一种结合模糊逻辑和分数阶动力学的分数阶模糊PID（FOFPID）控制器，并使用鲸鱼优化算法（WOA）优化其参数。该控制器被应用于管理双谱指数（BIS），以实现自动化麻醉。

Result: FOFPID控制器在八种不同的患者模型上进行了测试，与标准FOPID控制器相比，具有更快的沉降时间（2.5分钟对比3.2分钟）和更低的稳态误差（0.5对比1.2），证明了其优越的性能。

Conclusion: FOFPID控制器在管理BIS以实现自动化麻醉方面表现出卓越的性能、稳定性和准确性，是一种可扩展的、由人工智能驱动的解决方案，有望改善临床实践和患者的治疗效果。

Abstract: This study introduces a Fractional Order Fuzzy PID (FOFPID) controller that
uses the Whale Optimization Algorithm (WOA) to manage the Bispectral Index
(BIS), keeping it within the ideal range of forty to sixty. The FOFPID
controller combines fuzzy logic for adapting to changes and fractional order
dynamics for fine tuning. This allows it to adjust its control gains to handle
a person's unique physiology. The WOA helps fine tune the controller's
parameters, including the fractional orders and the fuzzy membership functions,
which boosts its performance. Tested on models of eight different patient
profiles, the FOFPID controller performed better than a standard Fractional
Order PID (FOPID) controller. It achieved faster settling times, at two and a
half minutes versus three point two minutes, and had a lower steady state
error, at zero point five versus one point two. These outcomes show the
FOFPID's excellent strength and accuracy. It offers a scalable, artificial
intelligence driven solution for automated anesthesia delivery that could
enhance clinical practice and improve patient results.

</details>


### [372] [Root Cause Analysis of Hydrogen Bond Separation in Spatio-Temporal Molecular Dynamics using Causal Models](https://arxiv.org/abs/2508.12500)
*Rahmat K. Adesunkanmi,Ashfaq Khokhar,Goce Trajcevski,Sohail Murad*

Main category: cs.AI

TL;DR: 通过因果建模和VAE类架构，利用MDS数据分析氢键形成和分离的根本原因，并成功预测未来变化。


<details>
  <summary>Details</summary>
Motivation: 为了解决分子动力学模拟（MDS）中计算资源消耗大、需要手动扫描输出以检测“有趣事件”（如氢键的形成和持续）以及识别导致氢键形成和分离的根本原因的研究空白。

Method: 提出了一种受因果建模启发的、利用变分自编码器（VAE）类架构构建因果图模型的方法，以推断分子动力学模拟中氢键形成和分离事件的因果关系和根源变量。

Result: 成功地在用于手性分离的原子轨迹上验证了该模型，证明了其预测未来多个步骤的能力，并识别出了驱动系统变化的关键变量。

Conclusion: 该研究提出了一个利用时空数据分析和机器学习模型来增强氢键形成和分离事件检测的方法，并通过在用于手性分离的原子轨迹上进行验证，证明了其预测未来步骤和识别驱动系统变化的变量的有效性。

Abstract: Molecular dynamics simulations (MDS) face challenges, including
resource-heavy computations and the need to manually scan outputs to detect
"interesting events," such as the formation and persistence of hydrogen bonds
between atoms of different molecules. A critical research gap lies in
identifying the underlying causes of hydrogen bond formation and separation
-understanding which interactions or prior events contribute to their emergence
over time. With this challenge in mind, we propose leveraging spatio-temporal
data analytics and machine learning models to enhance the detection of these
phenomena. In this paper, our approach is inspired by causal modeling and aims
to identify the root cause variables of hydrogen bond formation and separation
events. Specifically, we treat the separation of hydrogen bonds as an
"intervention" occurring and represent the causal structure of the bonding and
separation events in the MDS as graphical causal models. These causal models
are built using a variational autoencoder-inspired architecture that enables us
to infer causal relationships across samples with diverse underlying causal
graphs while leveraging shared dynamic information. We further include a step
to infer the root causes of changes in the joint distribution of the causal
models. By constructing causal models that capture shifts in the conditional
distributions of molecular interactions during bond formation or separation,
this framework provides a novel perspective on root cause analysis in molecular
dynamic systems. We validate the efficacy of our model empirically on the
atomic trajectories that used MDS for chiral separation, demonstrating that we
can predict many steps in the future and also find the variables driving the
observed changes in the system.

</details>


### [373] [Help or Hurdle? Rethinking Model Context Protocol-Augmented Large Language Models](https://arxiv.org/abs/2508.12566)
*Wei Song,Haonan Zhong,Ziqi Ding,Jingling Xue,Yuekang Li*

Main category: cs.AI

TL;DR: MCPGAUGE是首个评估LLM与外部工具（MCP）交互的框架，通过大规模实验发现当前MCP集成存在局限性，挑战了其有效性的普遍假设。


<details>
  <summary>Details</summary>
Motivation: 现有研究对LLM如何利用访问外部资源的能力（MCP）了解不足，需要一个全面的评估框架来深入理解LLM-MCP交互。

Method: 提出了MCPGAUGE评估框架，包含160个提示和25个数据集，涵盖知识理解、通用推理和代码生成，并对六种商用LLM、30种MCP工具套件以及单轮和双轮交互设置进行了大规模评估。

Result: 研究发现挑战了关于MCP集成有效性的普遍假设，揭示了当前AI工具集成的关键局限性。

Conclusion: 该研究揭示了MCP集成有效性的关键挑战，并提出了MCPGAUGE作为评估和改进可控、工具增强LLM的基准。

Abstract: The Model Context Protocol (MCP) enables large language models (LLMs) to
access external resources on demand. While commonly assumed to enhance
performance, how LLMs actually leverage this capability remains poorly
understood. We introduce MCPGAUGE, the first comprehensive evaluation framework
for probing LLM-MCP interactions along four key dimensions: proactivity
(self-initiated tool use), compliance (adherence to tool-use instructions),
effectiveness (task performance post-integration), and overhead (computational
cost incurred). MCPGAUGE comprises a 160-prompt suite and 25 datasets spanning
knowledge comprehension, general reasoning, and code generation. Our
large-scale evaluation, spanning six commercial LLMs, 30 MCP tool suites, and
both one- and two-turn interaction settings, comprises around 20,000 API calls
and over USD 6,000 in computational cost. This comprehensive study reveals four
key findings that challenge prevailing assumptions about the effectiveness of
MCP integration. These insights highlight critical limitations in current
AI-tool integration and position MCPGAUGE as a principled benchmark for
advancing controllable, tool-augmented LLMs.

</details>


### [374] [An LLM + ASP Workflow for Joint Entity-Relation Extraction](https://arxiv.org/abs/2508.12611)
*Trang Tran,Trung Hoang Le,Huiping Cao,Tran Cao Son*

Main category: cs.AI

TL;DR: 通过结合大语言模型（LLMs）和答案集编程（ASP），提出了一种新的联合实体关系抽取（JERE）方法，该方法在仅用 10% 的训练数据的情况下，在关系抽取任务上取得了显著优于现有技术的成果。


<details>
  <summary>Details</summary>
Motivation: 传统的基于机器学习的 JERE 方法需要大量注释数据，并且难以整合领域特定信息，导致模型构建过程劳动密集、耗时且难以修改。

Method: 提出了一种结合生成式预训练大语言模型（LLMs）和答案集编程（ASP）的联合实体关系抽取（JERE）工作流程。该工作流程直接处理未注释的文本，并利用 ASP 的特点，无需修改核心程序即可纳入领域特定的类型说明。

Result: 在使用了 10% 的训练数据的情况下，LLM + ASP 工作流程在三个著名的 JERE 基准测试上，在多个类别上优于最先进的 JERE 系统。特别是在 SciERC 语料库的关系抽取任务上，实现了 2.5 倍（35% 对 15%）的提升。

Conclusion: LLM + ASP 工作流程在关系抽取任务中表现优于最先进的 JERE 系统，在 SciERC 语料库上实现了 2.5 倍（35% 对 15%）的改进，并且仅使用了 10% 的训练数据。

Abstract: Joint entity-relation extraction (JERE) identifies both entities and their
relationships simultaneously. Traditional machine-learning based approaches to
performing this task require a large corpus of annotated data and lack the
ability to easily incorporate domain specific information in the construction
of the model. Therefore, creating a model for JERE is often labor intensive,
time consuming, and elaboration intolerant. In this paper, we propose
harnessing the capabilities of generative pretrained large language models
(LLMs) and the knowledge representation and reasoning capabilities of Answer
Set Programming (ASP) to perform JERE. We present a generic workflow for JERE
using LLMs and ASP. The workflow is generic in the sense that it can be applied
for JERE in any domain. It takes advantage of LLM's capability in natural
language understanding in that it works directly with unannotated text. It
exploits the elaboration tolerant feature of ASP in that no modification of its
core program is required when additional domain specific knowledge, in the form
of type specifications, is found and needs to be used. We demonstrate the
usefulness of the proposed workflow through experiments with limited training
data on three well-known benchmarks for JERE. The results of our experiments
show that the LLM + ASP workflow is better than state-of-the-art JERE systems
in several categories with only 10\% of training data. It is able to achieve a
2.5 times (35\% over 15\%) improvement in the Relation Extraction task for the
SciERC corpus, one of the most difficult benchmarks.

</details>


### [375] [Cognitive Structure Generation: From Educational Priors to Policy Optimization](https://arxiv.org/abs/2508.12647)
*Hengnian Gu,Zhifu Chen,Yuxin Chen,Jin Peng Zhou,Dongdai Zhou*

Main category: cs.AI

TL;DR: CSG是一个新框架，它使用扩散模型和强化学习来生成和优化学生的认知结构，以改进学生建模和教育任务。


<details>
  <summary>Details</summary>
Motivation: 认知结构评估在学生建模和心理测量学中是一个长期存在的挑战，是教育实践中的一个基础但很大程度上无法评估的概念。

Method: 本文提出了认知结构生成（CSG）框架，包括预训练认知结构扩散概率模型（CSDPM）以从教育先验生成学生认知结构，并利用分层奖励信号通过强化学习优化其生成过程，以匹配学生学习过程中的真实认知发展水平。

Result: 在四个流行的真实世界教育数据集上的实验结果表明，CSG生成的认知结构为学生建模提供了更全面有效的表征，显著提高了KT和CD任务的性能，同时增强了可解释性。

Conclusion: CSG模型能够为学生建模提供更全面有效的表征，显著提高在KT和CD任务上的性能，同时增强可解释性。

Abstract: Cognitive structure is a student's subjective organization of an objective
knowledge system, reflected in the psychological construction of concepts and
their relations. However, cognitive structure assessment remains a
long-standing challenge in student modeling and psychometrics, persisting as a
foundational yet largely unassessable concept in educational practice. This
paper introduces a novel framework, Cognitive Structure Generation (CSG), in
which we first pretrain a Cognitive Structure Diffusion Probabilistic Model
(CSDPM) to generate students' cognitive structures from educational priors, and
then further optimize its generative process as a policy with hierarchical
reward signals via reinforcement learning to align with genuine cognitive
development levels during students' learning processes. Experimental results on
four popular real-world education datasets show that cognitive structures
generated by CSG offer more comprehensive and effective representations for
student modeling, substantially improving performance on KT and CD tasks while
enhancing interpretability.

</details>


### [376] [GridCodex: A RAG-Driven AI Framework for Power Grid Code Reasoning and Compliance](https://arxiv.org/abs/2508.12682)
*Jinquan Shi,Yingying Cheng,Fan Zhang,Miao Jiang,Jun Lin,Yanbai Shen*

Main category: cs.AI

TL;DR: GridCodex是一个利用大语言模型和RAG技术的框架，用于解决复杂的电网代码推理和合规性问题，显著提高了答案质量和召回率。


<details>
  <summary>Details</summary>
Motivation: 解决电网代码复杂且缺乏自动化解释方案的问题，以应对全球向可再生能源转型带来的挑战，促进产业扩张并提高电力公司的盈利能力。

Method: 使用大语言模型和检索增强生成（RAG），并结合多阶段查询优化和RAPTOR增强检索技术。

Result: 在跨多个维度和监管机构的综合基准测试中，GridCodex框架在答案质量方面提高了26.4%，召回率提高了10倍以上。

Conclusion: GridCodex框架通过结合大语言模型和检索增强生成（RAG），并采用多阶段查询优化和RAPTOR增强检索，为电网代码推理和合规性提供了有效的解决方案，实验结果表明其在答案质量和召回率方面有显著提升。

Abstract: The global shift towards renewable energy presents unprecedented challenges
for the electricity industry, making regulatory reasoning and compliance
increasingly vital. Grid codes, the regulations governing grid operations, are
complex and often lack automated interpretation solutions, which hinders
industry expansion and undermines profitability for electricity companies. We
introduce GridCodex, an end to end framework for grid code reasoning and
compliance that leverages large language models and retrieval-augmented
generation (RAG). Our framework advances conventional RAG workflows through
multi stage query refinement and enhanced retrieval with RAPTOR. We validate
the effectiveness of GridCodex with comprehensive benchmarks, including
automated answer assessment across multiple dimensions and regulatory agencies.
Experimental results showcase a 26.4% improvement in answer quality and more
than a 10 fold increase in recall rate. An ablation study further examines the
impact of base model selection.

</details>


### [377] [EGOILLUSION: Benchmarking Hallucinations in Egocentric Video Understanding](https://arxiv.org/abs/2508.12687)
*Ashish Seth,Utkarsh Tyagi,Ramaneswaran Selvakumar,Nishit Anand,Sonal Kumar,Sreyan Ghosh,Ramani Duraiswami,Chirag Agarwal,Dinesh Manocha*

Main category: cs.AI

TL;DR: EgoIllusion 是首个评估 MLLM 在 egocentric 视频中幻觉的基准，显示即使是 GPT-4o 和 Gemini 也存在严重幻觉问题，准确率仅 59%。


<details>
  <summary>Details</summary>
Motivation: 现有的 MLLMs 在 egocentric 视频理解方面存在幻觉问题，需要一个专门的基准来评估和改进这一点。

Method: 提出 EgoIllusion 基准，包含 1,400 个 egocentric 视频和 8,000 个标注问题，旨在引发视觉和听觉线索的幻觉。

Result: 在 EgoIllusion 基准上的评估显示，即使是 GPT-4o 和 Gemini 等强大模型，准确率也仅为 59%，表明 MLLMs 在 egocentric 视频幻觉方面仍面临严峻挑战。

Conclusion: EgoIllusion 填补了评估 MLLM 在 egocentric 视频中幻觉的基准空白，为 MLLM 的稳健性评估和未来 egocentric MLLM 的发展奠定了基础。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated remarkable
performance in complex multimodal tasks. While MLLMs excel at visual perception
and reasoning in third-person and egocentric videos, they are prone to
hallucinations, generating coherent yet inaccurate responses. We present
EgoIllusion, a first benchmark to evaluate MLLM hallucinations in egocentric
videos. EgoIllusion comprises 1,400 videos paired with 8,000 human-annotated
open and closed-ended questions designed to trigger hallucinations in both
visual and auditory cues in egocentric videos. Evaluations across ten MLLMs
reveal significant challenges, including powerful models like GPT-4o and
Gemini, achieving only 59% accuracy. EgoIllusion lays the foundation in
developing robust benchmarks to evaluate the effectiveness of MLLMs and spurs
the development of better egocentric MLLMs with reduced hallucination rates.
Our benchmark will be open-sourced for reproducibility.

</details>


### [378] [GTool: Graph Enhanced Tool Planning with Large Language Model](https://arxiv.org/abs/2508.12725)
*Wenjie Chen,Wenbin Li,Di Yao,Xuying Meng,Chang Gong,Jingping Bi*

Main category: cs.AI

TL;DR: GTool通过构建工具图和预测缺失依赖来改进LLM的工具规划，解决了不完整依赖问题，并显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有工作将不同工具视为孤立的组件，未能利用工具间的固有依赖关系，导致规划结果无效。由于工具依赖关系通常不完整，LLM难以准确识别用户请求所需的工具，尤其是在工具集庞大的情况下。因此，需要一种能够增强LLM在不完整依赖下工具规划能力的方法。

Method: GTool通过构建请求特定的工具图来高效选择工具，并生成LLM可理解的包含足够依赖信息的<graph token>。同时，设计了缺失依赖预测任务来处理不完整依赖。GTool可以与各种LLM骨干模型无缝集成，无需进行广泛的再训练。

Result: GTool在轻量级（7B）LLM骨干模型上，相较于最先进（SOTA）基线，性能提升超过29.6%。

Conclusion: GTool通过构建请求特定的工具图并设计缺失依赖预测任务，提高了LLM在不完整依赖下的工具规划能力，能够与现有LLM无缝集成，并在实验中取得了显著的性能提升。

Abstract: Tool planning with large language models (LLMs), referring to selecting,
organizing, and preparing the tools necessary to complete a user request,
bridges the gap between natural language understanding and task execution.
However, current works treat different tools as isolated components and fail to
leverage the inherent dependencies of tools, leading to invalid planning
results. Since tool dependencies are often incomplete, it becomes challenging
for LLMs to accurately identify the appropriate tools required by a user
request, especially when confronted with a large toolset. To solve this
challenge, we propose \texttt{GTool}, which is the first work aiming to enhance
the tool planning ability of LLMs under incomplete dependencies. \texttt{GTool}
constructs a request-specific tool graph to select tools efficiently and
generate the \texttt{<graph token>} which provides sufficient dependency
information understandable by LLMs. Moreover, a missing dependency prediction
task is designed to improve the reliability of \texttt{GTool} with incomplete
dependencies. Without trimming LLMs, \texttt{GTool} can be seamlessly
integrated with various LLM backbones without extensive retraining. Extensive
experiments show that \texttt{GTool} achieves more than 29.6\% performance
improvements compared with the state-of-the-art (SOTA) baselines with a
light-weight (7B) LLM backbone.

</details>


### [379] [Beyond Ethical Alignment: Evaluating LLMs as Artificial Moral Assistants](https://arxiv.org/abs/2508.12754)
*Alessio Galatolo,Luca Alberto Rappuoli,Katie Winkle,Meriem Beloucif*

Main category: cs.AI

TL;DR: 本研究开发了一个新的基准来评估LLM作为人工智能道德助手（AMA）的道德推理能力，发现LLM在演绎和溯因道德推理方面存在不足，并强调了增强LLM道德推理能力的必要性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）的普及，人们对其道德能力表示担忧。然而，现有的基准和评估通常只关注最终的道德判断，而忽略了明确的道德推理。本研究旨在通过检验LLM作为人工智能道德助手（AMA）的能力，来推进对LLM道德能力的探究。

Method: 本研究首先设计了一个新的形式化框架，用于界定AMA应展现的行为，并确定了演绎和溯因道德推理等关键特质。在此理论框架的基础上，我们开发了一个基准来测试这些特质，并评估了流行的开源LLM。

Result: 评估结果揭示了不同模型之间的显著差异，并突出了LLM在溯因道德推理方面持续存在的不足。

Conclusion: LLMs在道德推理能力方面存在显著差异和持续的不足，尤其是在演绎和溯因道德推理方面。这项工作强调了开发专门策略以显着增强LLM道德推理能力的必要性。

Abstract: The recent rise in popularity of large language models (LLMs) has prompted
considerable concerns about their moral capabilities. Although considerable
effort has been dedicated to aligning LLMs with human moral values, existing
benchmarks and evaluations remain largely superficial, typically measuring
alignment based on final ethical verdicts rather than explicit moral reasoning.
In response, this paper aims to advance the investigation of LLMs' moral
capabilities by examining their capacity to function as Artificial Moral
Assistants (AMAs), systems envisioned in the philosophical literature to
support human moral deliberation. We assert that qualifying as an AMA requires
more than what state-of-the-art alignment techniques aim to achieve: not only
must AMAs be able to discern ethically problematic situations, they should also
be able to actively reason about them, navigating between conflicting values
outside of those embedded in the alignment phase. Building on existing
philosophical literature, we begin by designing a new formal framework of the
specific kind of behaviour an AMA should exhibit, individuating key qualities
such as deductive and abductive moral reasoning. Drawing on this theoretical
framework, we develop a benchmark to test these qualities and evaluate popular
open LLMs against it. Our results reveal considerable variability across models
and highlight persistent shortcomings, particularly regarding abductive moral
reasoning. Our work connects theoretical philosophy with practical AI
evaluation while also emphasising the need for dedicated strategies to
explicitly enhance moral reasoning capabilities in LLMs. Code available at
https://github.com/alessioGalatolo/AMAeval

</details>


### [380] [HeroBench: A Benchmark for Long-Horizon Planning and Structured Reasoning in Virtual Worlds](https://arxiv.org/abs/2508.12782)
*Petr Anokhin,Roman Khalikov,Stefan Rebrikov,Viktor Volkov,Artyom Sorokin,Vincent Bissonnette*

Main category: cs.AI

TL;DR: HeroBench是一个新的基准，用于评估LLM在复杂RPG虚拟世界中的长期规划能力。评估显示，现有LLM在处理此类任务时存在显著差异和具体弱点。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在需要扩展、结构化依赖动作的长期规划任务中的能力，因为现有基准未能捕捉现实规划环境的复杂性。

Method: 引入了一个名为HeroBench的新基准，该基准在一个受RPG启发的虚拟世界中专门用于评估长远规划和结构化推理。HeroBench包含一个精心构建的任务数据集，涵盖各种难度级别，一个用于执行和验证代理计划的模拟环境，以及用于评估模型性能的详细分析工具。

Result: 对25个最先进的LLM（包括GPT-5系列）进行了广泛评估，揭示了在传统推理基准中很少见的显著性能差异。错误分析进一步揭示了当前模型在生成可靠的高层计划和执行结构化动作方面的具体弱点。

Conclusion: HeroBench显著推进了LLM推理的评估，并为未来在虚拟环境中进行高级自主规划的研究提供了灵活、可扩展的基础。

Abstract: Large language models (LLMs) have shown remarkable capabilities in isolated
step-by-step reasoning tasks such as mathematics and programming, but their
proficiency in long-horizon planning, where solutions require extended,
structured sequences of interdependent actions, remains underexplored. Existing
benchmarks typically assess LLMs through abstract or low-dimensional
algorithmic tasks, failing to capture the complexity of realistic planning
environments. We introduce HeroBench, a novel benchmark designed specifically
to evaluate long-horizon planning and structured reasoning within complex
RPG-inspired virtual worlds. HeroBench provides a rigorously constructed
dataset of tasks covering a wide range of difficulties, a simulated environment
to execute and validate agent plans, and detailed analytical tools for
evaluating model performance. Tasks challenge models to formulate strategic
plans, efficiently gather resources, master necessary skills, craft equipment,
and defeat adversaries, reflecting practical scenarios' layered dependencies
and constraints. Our extensive evaluation of 25 state-of-the-art LLMs, spanning
both open-source and proprietary models, including the GPT-5 family, reveals
substantial performance disparities rarely observed in conventional reasoning
benchmarks. Detailed error analysis further uncovers specific weaknesses in
current models' abilities to generate robust high-level plans and reliably
execute structured actions. HeroBench thus not only significantly advances the
evaluation of LLM reasoning but also provides a flexible, scalable foundation
for future research into advanced, autonomous planning in virtual environments.

</details>


### [381] [Reinforcement Learning with Rubric Anchors](https://arxiv.org/abs/2508.12790)
*Zenan Huang,Yihong Zhuang,Guoshan Lu,Zeyu Qin,Haokai Xu,Tianyu Zhao,Ru Peng,Jiaqi Hu,Zhanming Shen,Xiaomeng Hu,Xijun Gu,Peiyi Tu,Jiaxin Liu,Wenyu Chen,Yuzhuo Fu,Zhiting Fan,Yanmei Gu,Yuanyuan Wang,Zhengkai Yang,Jianguo Li,Junbo Zhao*

Main category: cs.AI

TL;DR: 本研究将强化学习从可验证奖励（RLVR）扩展到开放式任务，通过引入基于规则的奖励，解决了现有RLVR的局限性。研究构建了一个大规模的规则奖励系统，并发布了一个名为Qwen-30B-A3B的模型，该模型在开放式任务上表现出色，并能进行风格控制。


<details>
  <summary>Details</summary>
Motivation: 现有的RLVR范式主要限于具有可自动检查结果的领域，为了克服这一限制，本研究将RLVR扩展到开放式任务。

Method: 提出了一种整合基于规则的奖励的RLVR范式，构建了包含10,000多个规则的奖励系统，并开源了一个Qwen-30B-A3B模型。

Result: 所提出的系统在开放式基准测试（尤其是人文学科）上取得了显著的改进（+5.2%），优于一个671B的DeepSeek-V3模型（+2.4%），同时保持了通用和推理能力。此外，该方法还提供了细粒度的风格控制，可以减轻“AI味”的语气，产生更具人情味、表现力更强的回应。

Conclusion: 该研究通过整合基于规则的奖励，将RLVR范式扩展到开放式任务，为评估和改进主观输出提供了一种新方法。

Abstract: Reinforcement Learning from Verifiable Rewards (RLVR) has emerged as a
powerful paradigm for enhancing Large Language Models (LLMs), exemplified by
the success of OpenAI's o-series. In RLVR, rewards are derived from verifiable
signals-such as passing unit tests in code generation or matching correct
answers in mathematical reasoning. While effective, this requirement largely
confines RLVR to domains with automatically checkable outcomes. To overcome
this, we extend the RLVR paradigm to open-ended tasks by integrating
rubric-based rewards, where carefully designed rubrics serve as structured,
model-interpretable criteria for automatic scoring of subjective outputs. We
construct, to our knowledge, the largest rubric reward system to date, with
over 10,000 rubrics from humans, LLMs, or a hybrid human-LLM collaboration.
Implementing rubric-based RL is challenging; we tackle these issues with a
clear framework and present an open-sourced Qwen-30B-A3B model with notable
gains: 1) With only 5K+ samples, our system improves by +5.2% on open-ended
benchmarks (especially humanities), outperforming a 671B DeepSeek-V3 model by
+2.4%, while preserving general and reasoning abilities. 2) Our method provides
fine-grained stylistic control, using rubrics as anchors to mitigate the
"AI-like" tone and produce more human-like, expressive responses. We share key
lessons in rubric construction, data selection, and training, and discuss
limitations and future releases.

</details>


### [382] [E3RG: Building Explicit Emotion-driven Empathetic Response Generation System with Multimodal Large Language Model](https://arxiv.org/abs/2508.12854)
*Ronghao Lin,Shuai Shen,Weipeng Hu,Qiaolin He,Aolin Xiong,Li Huang,Haifeng Hu,Yap-peng Tan*

Main category: cs.AI

TL;DR: E3RG是一个多模态共情响应生成系统，能生成自然、情感丰富且身份一致的响应，并在ACM MM 25的Avatar-based Multimodal Empathy Challenge中获得第一名。


<details>
  <summary>Details</summary>
Motivation: 为了解决基于LLM的文本共情响应生成在处理多模态情感内容和保持身份一致性方面存在的挑战。

Method: 提出了一种名为E3RG的显式情感驱动共情响应生成系统，该系统基于多模态大型语言模型，将MERG任务分解为多模态共情理解、共情记忆检索和多模态响应生成三个部分，并集成了先进的表达性语音和视频生成模型。

Result: E3RG系统能够生成自然、情感丰富且身份一致的响应，且无需额外训练。

Conclusion: E3RG系统在零样本和少样本设置下均优于现有系统，并在ACM MM 25的Avatar-based Multimodal Empathy Challenge中获得第一名。

Abstract: Multimodal Empathetic Response Generation (MERG) is crucial for building
emotionally intelligent human-computer interactions. Although large language
models (LLMs) have improved text-based ERG, challenges remain in handling
multimodal emotional content and maintaining identity consistency. Thus, we
propose E3RG, an Explicit Emotion-driven Empathetic Response Generation System
based on multimodal LLMs which decomposes MERG task into three parts:
multimodal empathy understanding, empathy memory retrieval, and multimodal
response generation. By integrating advanced expressive speech and video
generative models, E3RG delivers natural, emotionally rich, and
identity-consistent responses without extra training. Experiments validate the
superiority of our system on both zero-shot and few-shot settings, securing
Top-1 position in the Avatar-based Multimodal Empathy Challenge on ACM MM 25.
Our code is available at https://github.com/RH-Lin/E3RG.

</details>


### [383] [Reliability, Embeddedness, and Agency: A Utility-Driven Mathematical Framework for Agent-Centric AI Adoption](https://arxiv.org/abs/2508.12896)
*Faruk Alpay,Taylan Alpay*

Main category: cs.AI

TL;DR: 该研究提出了三个设计公理，用于AI系统在多步任务中的应用，并通过多种方法对采用模型进行了数学和实证分析。


<details>
  <summary>Details</summary>
Motivation: 为了实现代理中心AI系统的持续采用，特别是在执行多步任务时，明确设计原则至关重要。

Method: 通过建模采用率作为衰减新颖性项和增长效用项的总和，并提供完整的证明。研究内容包括：(i) 使用delta方法梯度进行可识别性/混淆性分析；(ii) 引入非单调比较器（带瞬态峰值的逻辑斯蒂模型）以提供额外的模型比较；(iii) 对映射ΔV→β的风险族进行省略分析；(iv) 在多系列基准上报告覆盖率（I类错误、功效）；(v) 校准摩擦代理与时间-运动/调查地面真值；(vi) 对每个拟合曲线进行残差分析；(vii) 预先注册的窗口选择；(viii) 常见误差模型下（α，β）的Fisher信息和CRLB；(ix) 将T与(N0, Umax)联系起来的微观基础；(x) 与双逻辑斯蒂、双指数和混合模型进行明确比较；(xi) 阈值对Cf异质性的敏感性。

Result: 研究形式化了三个设计公理（可靠性>新颖性；嵌入>目的地；能动性>聊天），并对采用模型进行了推导和分析，包括各种统计测试和模型比较。

Conclusion: 该研究形式化了用于代理中心AI系统的三个设计公理，这些系统执行多步任务，并推导了低谷/超调的阶段条件。

Abstract: We formalize three design axioms for sustained adoption of agent-centric AI
systems executing multi-step tasks: (A1) Reliability > Novelty; (A2) Embed >
Destination; (A3) Agency > Chat. We model adoption as a sum of a decaying
novelty term and a growing utility term and derive the phase conditions for
troughs/overshoots with full proofs. We introduce: (i) an
identifiability/confounding analysis for $(\alpha,\beta,N_0,U_{\max})$ with
delta-method gradients; (ii) a non-monotone comparator
(logistic-with-transient-bump) evaluated on the same series to provide
additional model comparison; (iii) ablations over hazard families $h(\cdot)$
mapping $\Delta V \to \beta$; (iv) a multi-series benchmark (varying trough
depth, noise, AR structure) reporting coverage (type-I error, power); (v)
calibration of friction proxies against time-motion/survey ground truth with
standard errors; (vi) residual analyses (autocorrelation and
heteroskedasticity) for each fitted curve; (vii) preregistered windowing
choices for pre/post estimation; (viii) Fisher information & CRLB for
$(\alpha,\beta)$ under common error models; (ix) microfoundations linking
$\mathcal{T}$ to $(N_0,U_{\max})$; (x) explicit comparison to bi-logistic,
double-exponential, and mixture models; and (xi) threshold sensitivity to $C_f$
heterogeneity. Figures and tables are reflowed for readability, and the
bibliography restores and extends non-logistic/Bass adoption references
(Gompertz, Richards, Fisher-Pry, Mansfield, Griliches, Geroski, Peres). All
code and logs necessary to reproduce the synthetic analyses are embedded as
LaTeX listings.

</details>


### [384] [FuSaR: A Fuzzification-Based Method for LRM Safety-Reasoning Balance](https://arxiv.org/abs/2508.12897)
*Jianhao Chen,Mayi Xu,Xiaohu Li,Yongqi Li,Xiangyu Zhang,Jianjie Huang,Tieyun Qian*

Main category: cs.AI

TL;DR: 本文提出了一种名为FuSaR的策略，通过模糊化技术来提高大型推理模型（LRM）的安全性和推理能力，实验证明该策略有效。


<details>
  <summary>Details</summary>
Motivation: LRM在推理任务中表现出色，但其安全性令人担忧。本文旨在探讨LRM易受攻击的原因，并提出一种在不牺牲推理能力的情况下提高LLM安全性的新方法。

Method: 提出了一种基于模糊化的对齐策略FuSaR，通过去除推理过程中的危险实体和危险步骤来达到去毒化，以平衡安全性和推理能力。

Result: FuSaR成功地减轻了安全风险，同时保留了核心推理信息。通过在多个开源LRM上使用去毒化推理数据进行对齐实验，结果表明FuSaR优于现有基线。

Conclusion: FuSaR是一种有效的对齐策略，可以同时提高LRM的推理能力和安全性。

Abstract: Large Reasoning Models (LRMs) have demonstrated impressive performance across
various tasks due to their powerful reasoning capabilities. However, their
safety performance remains a significant concern. In this paper, we explore the
reasons behind the vulnerability of LRMs. Based on this, we propose a novel
method to improve the safety of LLMs without sacrificing their reasoning
capability. Specifically, we exploit the competition between LRM's reasoning
ability and safety ability, and achieve jailbreak by improving LRM's reasoning
performance to reduce its safety performance. We then introduce an alignment
strategy based on Fuzzification to balance Safety-Reasoning (FuSaR), by
detoxifying the harmful reasoning process, where both the dangerous entities
and the dangerous procedures in the reasoning steps are hidden. FuSaR
successfully mitigates safety risks while preserving core reasoning
information. We validate this strategy through alignment experiments on several
open-source LRMs using detoxified reasoning data. The results compared with
existing baselines conclusively show that FuSaR is an efficient alignment
strategy to simultaneously enhance both the reasoning capability and safety of
LRMs.

</details>


### [385] [Towards Open-Ended Emotional Support Conversations in LLMs via Reinforcement Learning with Future-Oriented Rewards](https://arxiv.org/abs/2508.12935)
*Ting Yang,Li Chen,Huimin Wang*

Main category: cs.AI

TL;DR: 提出RLFF-ESC框架，通过强化学习和多智能体模拟，改善LLM在情感支持对话中的响应能力，实验证明其效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了实现对多样化情感问题场景的灵活响应，并解决大多数基于LLM的情感支持对话（ESC）系统依赖预定义策略，限制了其在复杂现实场景中有效性的问题。

Method: 提出了一种新的端到端框架RLFF-ESC，该框架使用强化学习直接学习持久的情感支持响应技能。首先采用基于LLM的多智能体机制来模拟未来对话轨迹并收集面向未来的奖励。然后训练一个面向未来的奖励模型，并使用该模型来训练情感支持策略模型。此外，在响应生成过程中融入了显式的推理过程，以进一步提高系统响应的质量、相关性和上下文适用性。

Result: RLFF-ESC框架在Qwen2.5-7B-Instruct-1M和LLaMA3.1-8B-Instruct模型上进行了评估，并在两个公开的ESC数据集上进行了测试，实验结果表明RLFF-ESC在目标完成度和响应质量方面持续优于现有基线。

Conclusion: RLFF-ESC框架在目标完成度和响应质量方面持续优于现有基线。

Abstract: Emotional Support Conversation (ESC) systems aim to alleviate users'
emotional difficulties and provide long-term, systematic support for emotional
well-being. However, most large language model (LLM)-based ESC systems rely on
predefined strategies, which limits their effectiveness in complex, real-life
scenarios. To enable flexible responses to diverse emotional problem scenarios,
this paper introduces a novel end-to-end framework (RLFF-ESC) that directly
learns enduring emotionally supportive response skills using reinforcement
learning. For sustained emotional support, we first employ an LLM-based
multi-agent mechanism to simulate future dialogue trajectories and collect
future-oriented rewards. We then train a future-oriented reward model, which is
subsequently used to train the emotional support policy model. Additionally, we
incorporate an explicit reasoning process during response generation to further
enhance the quality, relevance, and contextual appropriateness of the system's
responses. We evaluate the backbone policy model on Qwen2.5-7B-Instruct-1M and
LLaMA3.1-8B-Instruct models, testing the proposed RLFF-ESC framework across two
public ESC datasets. Experimental results demonstrate that RLFF-ESC
consistently outperforms existing baselines in terms of goal completion and
response quality.

</details>


### [386] [OPTIC-ER: A Reinforcement Learning Framework for Real-Time Emergency Response and Equitable Resource Allocation in Underserved African Communities](https://arxiv.org/abs/2508.12943)
*Mary Tonwe*

Main category: cs.AI

TL;DR: OPTIC-ER 是一个创新的强化学习框架，通过实时、自适应和公平的策略优化紧急响应，解决了非洲地区公共服务中的响应延迟和不公平问题，并在实际数据中表现出色。


<details>
  <summary>Details</summary>
Motivation: 为了解决非洲地区公共服务系统面临的紧急响应延迟和空间不公平问题，该研究旨在开发一个能够实现实时、自适应和公平的紧急响应的强化学习框架。

Method:  OPTIC-ER 框架采用注意力引导的 Actor-Critic 架构，结合了情境丰富状态向量（包含动作次优性信息）和精确奖励函数（惩罚低效率），并在高保真模拟环境（使用尼日利亚河流州数据和预计算的出行时间图集）中进行训练，同时遵循 TALS 框架（精简计算、适应性、低成本、可扩展性）以适应低资源环境。

Result: 在 500 次未见过的事件评估中，OPTIC-ER 实现了 100.00% 的最优率和可忽略的低效率，证明了其鲁棒性和泛化能力。此外，该系统还能生成基础设施缺陷图和公平性监测仪表板，以指导主动治理和数据驱动的发展。

Conclusion: 该研究提出了 OPTIC-ER 框架，一个基于强化学习的系统，用于改进非洲地区紧急响应的效率和公平性，并在模拟和实际数据评估中表现出色。

Abstract: Public service systems in many African regions suffer from delayed emergency
response and spatial inequity, causing avoidable suffering. This paper
introduces OPTIC-ER, a reinforcement learning (RL) framework for real-time,
adaptive, and equitable emergency response. OPTIC-ER uses an attention-guided
actor-critic architecture to manage the complexity of dispatch environments.
Its key innovations are a Context-Rich State Vector, encoding action
sub-optimality, and a Precision Reward Function, which penalizes inefficiency.
Training occurs in a high-fidelity simulation using real data from Rivers
State, Nigeria, accelerated by a precomputed Travel Time Atlas. The system is
built on the TALS framework (Thin computing, Adaptability, Low-cost,
Scalability) for deployment in low-resource settings. In evaluations on 500
unseen incidents, OPTIC-ER achieved a 100.00% optimality rate with negligible
inefficiency, confirming its robustness and generalization. Beyond dispatch,
the system generates Infrastructure Deficiency Maps and Equity Monitoring
Dashboards to guide proactive governance and data-informed development. This
work presents a validated blueprint for AI-augmented public services, showing
how context-aware RL can bridge the gap between algorithmic decision-making and
measurable human impact.

</details>


### [387] [EvolMathEval: Towards Evolvable Benchmarks for Mathematical Reasoning via Evolutionary Testing](https://arxiv.org/abs/2508.13003)
*Shengbo Wang,Mingwei Liu,Zike Li,Anji Li,Yanlin Wang,Xin Peng,Zibin Zheng*

Main category: cs.AI

TL;DR: EvolMathEval 是一个创新的数学基准测试框架，它利用进化测试技术动态生成数学问题，解决了现有基准的数据污染和挑战性衰减问题。该框架通过独特的生成机制和适应度评估，能有效提高问题难度，并揭示了 LLM 在解决复杂问题时存在的“伪顿悟时刻”现象，即倾向于使用捷径而非严谨推理。


<details>
  <summary>Details</summary>
Motivation: 现有的数学推理基准在面对大型语言模型（LLM）的快速发展时，普遍存在分数饱和、时间衰减和数据污染等问题。为了应对这些挑战，需要一种新的方法来生成能够持续保持挑战性的数学基准。

Method: EvolMathEval 框架的核心机制包括：基于逆向工程和代数保证的种子问题生成；旨在注入多样化认知挑战的多维度遗传算子；以及能够快速准确评估问题难度的复合适应度函数。

Result: 实验结果表明，EvolMathEval 提出的复合适应度函数能够高效且精确地量化数学问题的难度。EvolMathEval 不仅可以通过持续的自我迭代生成大量高难度问题，还能显著提高 GSM8K 等公共数据集的复杂性，平均降低模型准确率 48%。研究发现，LLM 在解决这些演化后的复杂问题时，会采用非严谨的启发式方法来绕过复杂的多步逻辑推理，导致错误，并将此现象定义为“伪顿悟时刻”，该现象占到了目标问题错误来源的 77% 到 100%。

Conclusion: EvolMathEval 通过引入基于进化测试的自动化数学基准生成和演化框架，解决了现有数学推理基准的局限性。该框架通过从头开始动态生成独特的评估实例，从根本上消除了数据污染的风险，并确保基准对未来模型具有持续的挑战性。实验证明，EvolMathEval 能够有效且精确地量化数学问题的难度，并能通过持续的自我迭代生成大量高难度问题。此外，它还能显著提高现有数据集（如 GSM8K）的复杂性，导致模型准确率平均下降 48%。研究还发现，在解决这些演化后的复杂问题时，大型语言模型（LLM）倾向于采用非严谨的启发式方法来绕过复杂的多步逻辑推理，从而导致错误解决方案，我们将这种现象定义为“伪顿悟时刻”，这表明了 LLM 在深度推理过程中存在认知捷径行为，并且这种行为在目标问题中占到了 77% 到 100% 的错误来源。

Abstract: The rapid advancement of LLMs poses a significant challenge to existing
mathematical reasoning benchmarks. These benchmarks commonly suffer from issues
such as score saturation, temporal decay, and data contamination. To address
this challenge, this paper introduces EvolMathEval, an automated mathematical
benchmark generation and evolution framework based on evolutionary testing. By
dynamically generating unique evaluation instances ab initio, the framework
fundamentally eliminates the risk of data contamination, and ensuring the
benchmark remains perpetually challenging for future models.The core mechanisms
of EvolMathEval include: seed problem generation based on reverse engineering
with algebraic guarantees; multi-dimensional genetic operators designed to
inject diverse cognitive challenges; and a composite fitness function that can
rapidly and accurately assess problem difficulty. Experimental results
demonstrate that the proposed composite fitness function can efficiently and
precisely quantify the difficulty of mathematical problems. Furthermore,
EvolMathEval can not only generate a large volume of high-difficulty problems
through continuous self-iteration, but it can also significantly enhance the
complexity of public datasets like GSM8K through evolution, reducing model
accuracy by an average of 48%. Deeper investigation reveals that when solving
these evolved, complex problems, LLMs tend to employ non-rigorous heuristics to
bypass complex multi-step logical reasoning, consequently leading to incorrect
solutions. We define this phenomenon as "Pseudo Aha Moment". This finding
uncovers a cognitive shortcut-taking behavior in the deep reasoning processes
of current LLMs, which we find accounts for 77% to 100% of errors on targeted
problems. Code and resources are available
at:https://github.com/SYSUSELab/EvolMathEval.

</details>


### [388] [PC-Sampler: Position-Aware Calibration of Decoding Bias in Masked Diffusion Models](https://arxiv.org/abs/2508.13021)
*Pengcheng Huang,Shuhao Liu,Zhenghao Liu,Yukun Yan,Shuo Wang,Zulong Chen,Tong Xiao*

Main category: cs.AI

TL;DR: PC-Sampler 是一种新的解码策略，可以解决 MDM 的全局轨迹控制和琐碎标记偏见问题，从而提高生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有 MDM 的解码策略（特别是基于不确定性的采样器）存在全局轨迹控制不足和早期解码阶段偏向琐碎标记的问题，限制了 MDM 的潜力。

Method: 提出了一种名为 PC-Sampler 的新颖解码策略，该策略结合了基于位置的加权机制和校准置信度得分，以实现全局轨迹规划和内容感知信息最大化。

Result: PC-Sampler 在三个先进的 MDM 和七个基准测试上始终优于现有的 MDM 解码策略。

Conclusion: PC-Sampler 显著缩小了与最先进的自回归模型的性能差距，并在七个具有挑战性的基准测试中平均提高了 10% 以上。

Abstract: Recent advances in masked diffusion models (MDMs) have established them as
powerful non-autoregressive alternatives for sequence generation. Nevertheless,
our preliminary experiments reveal that the generation quality of MDMs is still
highly sensitive to the choice of decoding strategy. In particular, widely
adopted uncertainty-based samplers suffer from two key limitations: a lack of
global trajectory control and a pronounced bias toward trivial tokens in the
early stages of decoding. These shortcomings restrict the full potential of
MDMs. In this work, we introduce Position-Aware Confidence-Calibrated Sampling
(PC-Sampler), a novel decoding strategy that unifies global trajectory planning
with content-aware informativeness maximization. PC-Sampler incorporates a
position-aware weighting mechanism to regulate the decoding path and a
calibrated confidence score to suppress the premature selection of trivial
tokens. Extensive experiments on three advanced MDMs across seven challenging
benchmarks-including logical reasoning and planning tasks-demonstrate that
PC-Sampler consistently outperforms existing MDM decoding strategies by more
than 10% on average, significantly narrowing the performance gap with
state-of-the-art autoregressive models. All codes are available at
https://github.com/NEUIR/PC-Sampler.

</details>


### [389] [G$^2$RPO-A: Guided Group Relative Policy Optimization with Adaptive Guidance](https://arxiv.org/abs/2508.13023)
*Yongxin Guo,Wenbo Deng,Zhenglin Cheng,Xiaoying Tang*

Main category: cs.AI

TL;DR: G$^2$RPO-A 是一种新算法，通过注入地面真实推理步骤来增强小规模语言模型 (SLM) 的推理能力，并在数学推理和代码生成方面取得了显著成效。


<details>
  <summary>Details</summary>
Motivation: RLVR 主要依赖于具有丰富世界知识的强大基础模型，而对于小规模语言模型 (SLM) 来说，其改进幅度很小。为了解决这一限制，我们研究了 Guided GRPO，它通过将地面真实推理步骤注入回滚轨迹来补偿 SLM 的固有弱点。

Method: Guided GRPO 通过将地面真实推理步骤注入回滚轨迹来补偿 SLM 的固有弱点。G$^2$RPO-A 是一种自适应算法，能够根据模型不断变化的训练动态自动调整引导强度。

Result: 通过对各种引导配置的全面研究，我们发现 naively adding guidance 带来的收益有限。

Conclusion: G$^2$RPO-A 是一种自适应算法，能够根据模型不断变化的训练动态自动调整引导强度，在数学推理和代码生成基准测试中，其实质性地优于 vanilla GRPO。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has markedly enhanced
the reasoning abilities of large language models (LLMs). Its success, however,
largely depends on strong base models with rich world knowledge, yielding only
modest improvements for small-size language models (SLMs). To address this
limitation, we investigate Guided GRPO, which injects ground-truth reasoning
steps into roll-out trajectories to compensate for SLMs' inherent weaknesses.
Through a comprehensive study of various guidance configurations, we find that
naively adding guidance delivers limited gains. These insights motivate
G$^2$RPO-A, an adaptive algorithm that automatically adjusts guidance strength
in response to the model's evolving training dynamics. Experiments on
mathematical reasoning and code-generation benchmarks confirm that G$^2$RPO-A
substantially outperforms vanilla GRPO. Our code and models are available at
https://github.com/T-Lab-CUHKSZ/G2RPO-A.

</details>


### [390] [A Language-Signal-Vision Multimodal Framework for Multitask Cardiac Analysis](https://arxiv.org/abs/2508.13072)
*Yuting Zhang,Tiantian Geng,Luoying Hao,Xinxing Cheng,Alexander Thorley,Xiaoxia Wang,Wenqi Lu,Sandeep S Hothi,Lei Wei,Zhaowen Qiu,Dipak Kotecha,Jinming Duan*

Main category: cs.AI

TL;DR: TGMM框架通过整合多模态心脏数据（实验室检查、心电图、超声心动图）并利用文本指导，克服了现有方法的局限性，在心脏病诊断、风险分层和信息检索等任务上取得了优于最先进水平的性能。


<details>
  <summary>Details</summary>
Motivation: 当前心血管管理在整合多模态心脏数据集方面存在局限性，包括患者和时间对齐的多模态数据稀缺、依赖于孤立的单模态或刚性多模态组合、跨模态相似性优先于互补性的对齐策略以及狭窄的单任务焦点。

Method: 提出了一种名为TGMM（Textual Guidance Multimodal fusion for Multiple cardiac tasks）的统一框架，该框架包含三个关键组件：1) MedFlexFusion模块，用于捕获医疗模式的独特和互补特征，并动态集成来自不同心脏源及其组合的数据；2) 文本指导模块，用于推导与特定临床目标相关的表示；3) 响应模块，用于为所有任务生成最终决策。

Result: TGMM框架能够动态集成不同心脏来源的数据及其组合，并根据文本指导生成与临床目标相关的表示，最终为心脏病诊断、风险分层和信息检索等任务生成决策，并在多个临床任务上取得了优于现有方法的性能。

Conclusion: TGMM在多个临床任务上表现优于最先进的方法，并在另一个公共数据集上得到了稳健性验证。

Abstract: Contemporary cardiovascular management involves complex consideration and
integration of multimodal cardiac datasets, where each modality provides
distinct but complementary physiological characteristics. While the effective
integration of multiple modalities could yield a holistic clinical profile that
accurately models the true clinical situation with respect to data modalities
and their relatives weightings, current methodologies remain limited by: 1) the
scarcity of patient- and time-aligned multimodal data; 2) reliance on isolated
single-modality or rigid multimodal input combinations; 3) alignment strategies
that prioritize cross-modal similarity over complementarity; and 4) a narrow
single-task focus. In response to these limitations, a comprehensive multimodal
dataset was curated for immediate application, integrating laboratory test
results, electrocardiograms, and echocardiograms with clinical outcomes.
Subsequently, a unified framework, Textual Guidance Multimodal fusion for
Multiple cardiac tasks (TGMM), was proposed. TGMM incorporated three key
components: 1) a MedFlexFusion module designed to capture the unique and
complementary characteristics of medical modalities and dynamically integrate
data from diverse cardiac sources and their combinations; 2) a textual guidance
module to derive task-relevant representations tailored to diverse clinical
objectives, including heart disease diagnosis, risk stratification and
information retrieval; and 3) a response module to produce final decisions for
all these tasks. Furthermore, this study systematically explored key features
across multiple modalities and elucidated their synergistic contributions in
clinical decision-making. Extensive experiments showed that TGMM outperformed
state-of-the-art methods across multiple clinical tasks, with additional
validation confirming its robustness on another public dataset.

</details>


### [391] [Bayesian Optimization-based Search for Agent Control in Automated Game Testing](https://arxiv.org/abs/2508.13121)
*Carlos Celemin*

Main category: cs.AI

TL;DR: 通过使用智能体和贝叶斯优化来自动化游戏测试，提高了地图覆盖率。


<details>
  <summary>Details</summary>
Motivation: 为了在游戏中发现潜在的bug，提出了一种新的自动化测试方法。

Method: 提出了一种利用控制游戏角色的智能体来检测游戏关卡潜在bug的自动化测试方法，并结合了贝叶斯优化（BO）来执行样本高效搜索，通过分析已收集的数据来确定下一个采样点，以最大化信息获取。为支持BO过程，研究者们提出了一个基于网格地图的游戏测试特定模型，该模型具有BO所需的平滑性和不确定性估计，并且克服了传统模型的扩展性问题。

Result: 实验证明，该方法在时间和探索分布方面显著提高了地图覆盖能力。

Conclusion: 该方法显著提高了在时间和探索分布方面的地图覆盖能力。

Abstract: This work introduces an automated testing approach that employs agents
controlling game characters to detect potential bugs within a game level.
Harnessing the power of Bayesian Optimization (BO) to execute sample-efficient
search, the method determines the next sampling point by analyzing the data
collected so far and calculates the data point that will maximize information
acquisition. To support the BO process, we introduce a game testing-specific
model built on top of a grid map, that features the smoothness and uncertainty
estimation required by BO, however and most importantly, it does not suffer the
scalability issues that traditional models carry. The experiments demonstrate
that the approach significantly improves map coverage capabilities in both time
efficiency and exploration distribution.

</details>


### [392] [Exploring Autonomous Agents: A Closer Look at Why They Fail When Completing Tasks](https://arxiv.org/abs/2508.13143)
*Ruofan Lu,Yichen Li,Yintong Huo*

Main category: cs.AI

TL;DR: LLM 驱动的自主代理在执行复杂任务方面表现出潜力，但现有评估方法存在不足。本研究提出了一个包含 34 个任务的基准，并对三种流行的代理框架和两种 LLM 进行了评估，发现任务完成率约为 50%。研究深入分析了失败原因，并提出了改进建议，以增强代理的规划和自我诊断能力。


<details>
  <summary>Details</summary>
Motivation: 当前对 LLM 驱动的自主代理的评估主要依赖于成功率，缺乏对交互、通信机制和失败原因的系统性分析。

Method: 设计了一个包含 34 个可编程任务的基准，用于评估自主代理，并结合两种 LLM 和三种流行的开源代理框架进行了评估。通过对任务的失败原因进行分类，提出了改进建议。

Result: 在 34 个任务组成的基准测试中，观察到约 50% 的任务完成率。通过分析，提出了一个包含规划错误、任务执行问题和不正确响应生成的三层失败原因分类法。

Conclusion: 通过对 LLM 驱动的自主代理进行基准测试和深入的失败分析，我们提出了一个三层故障分类法，并提供了改进代理规划和自我诊断能力的建议，为开发更强大、更有效的自主代理系统奠定了实证基础。

Abstract: Autonomous agent systems powered by Large Language Models (LLMs) have
demonstrated promising capabilities in automating complex tasks. However,
current evaluations largely rely on success rates without systematically
analyzing the interactions, communication mechanisms, and failure causes within
these systems. To bridge this gap, we present a benchmark of 34 representative
programmable tasks designed to rigorously assess autonomous agents. Using this
benchmark, we evaluate three popular open-source agent frameworks combined with
two LLM backbones, observing a task completion rate of approximately 50%.
Through in-depth failure analysis, we develop a three-tier taxonomy of failure
causes aligned with task phases, highlighting planning errors, task execution
issues, and incorrect response generation. Based on these insights, we propose
actionable improvements to enhance agent planning and self-diagnosis
capabilities. Our failure taxonomy, together with mitigation advice, provides
an empirical foundation for developing more robust and effective autonomous
agent systems in the future.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [393] [Using Natural Language for Human-Robot Collaboration in the Real World](https://arxiv.org/abs/2508.11759)
*Peter Lindes,Kaoutar Skiker*

Main category: cs.RO

TL;DR: 本研究旨在通过整合大型语言模型（LLMs）来增强机器人的自然语言理解能力，使其能与人类在物理世界中进行更有效的协作。研究回顾了现有机器人产品，提出了一种结合认知代理、LLM和机器人本体的AI系统架构，并通过实验验证了其在理解自然语言方面的潜力，为实现更智能的机器人助手铺平了道路。


<details>
  <summary>Details</summary>
Motivation: 当前机器人与人类协作时，虽然一些交互式任务学习（ITL）系统具备一定的沟通能力，但其理解的语言能力非常有限。大型语言模型（LLMs）的出现为提升机器人的语言理解能力提供了契机。然而，将LLM的语言能力与现实世界的物理机器人相结合，是一个巨大的挑战。本研究旨在探索如何克服这些挑战，使机器人能够理解自然语言，并与人类进行有效的协作。

Method: 本研究首先回顾了与人类紧密合作的商业机器人产品，并探讨了如何通过增强语言能力来改进它们的协作表现。接着，文章提出了一个以认知代理为核心的AI系统架构，该系统能够控制物理机器人，并与人类和LLM进行交互，通过经验积累情境知识。针对机器人理解自然语言的三个具体挑战，研究提出了相应的概念验证实验，并使用了ChatGPT作为实验工具。

Result: 研究提出了一个以认知代理为核心的AI系统架构，该架构能够控制物理机器人，并与人类和LLM进行交互。针对机器人理解自然语言的三个具体挑战，研究展示了使用ChatGPT进行的简单概念验证实验，证明了该方法的可行性。

Conclusion: 将LLM（大型语言模型）的语言理解能力与物理世界的机器人相结合，以实现能与人类协作的机器人助手，这是一个充满挑战但前景广阔的领域。通过构建一个以认知代理为核心的AI系统，该系统能够控制物理机器人，并与人类和LLM进行交互，同时通过经验积累情境知识，是实现这一愿景的一种可能途径。

Abstract: We have a vision of a day when autonomous robots can collaborate with humans
as assistants in performing complex tasks in the physical world. This vision
includes that the robots will have the ability to communicate with their human
collaborators using language that is natural to the humans. Traditional
Interactive Task Learning (ITL) systems have some of this ability, but the
language they can understand is very limited. The advent of large language
models (LLMs) provides an opportunity to greatly improve the language
understanding of robots, yet integrating the language abilities of LLMs with
robots that operate in the real physical world is a challenging problem.
  In this chapter we first review briefly a few commercial robot products that
work closely with humans, and discuss how they could be much better
collaborators with robust language abilities. We then explore how an AI system
with a cognitive agent that controls a physical robot at its core, interacts
with both a human and an LLM, and accumulates situational knowledge through its
experiences, can be a possible approach to reach that vision. We focus on three
specific challenges of having the robot understand natural language, and
present a simple proof-of-concept experiment using ChatGPT for each. Finally,
we discuss what it will take to turn these simple experiments into an
operational system where LLM-assisted language understanding is a part of an
integrated robotic assistant that uses language to collaborate with humans.

</details>


### [394] [Anticipatory and Adaptive Footstep Streaming for Teleoperated Bipedal Robots](https://arxiv.org/abs/2508.11802)
*Luigi Penco,Beomyeong Park,Stefan Fasano,Nehar Poddar,Stephen McCrory,Nicholas Kitchel,Tomasz Bialek,Dexton Anderson,Duncan Calvert,Robert Griffin*

Main category: cs.RO

TL;DR: 该研究提出了一种新颖的步态转移方法，用于遥操作，通过重新定位用户步点并利用机器人动力学来提高稳定性和适应性，实验证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在遥操作中，尤其是在高速任务期间，实现用户和机器人运动之间的无缝同步仍然是一个重大挑战。

Method: 提出了一种新颖的实时步态运动转移方法，通过预测用户步点来最小化延迟，并连续调整步点估计以匹配用户参考。该系统还能自主调整机器人步态以适应不同地形，克服环境不匹配的挑战。

Result: 在人形机器人 Nadia 上的实验结果证明了所提出系统的有效性。

Conclusion: 该方法通过将用户步态重新定位到机器人的脚点位置，并利用机器人自身动力学进行运动，实现了用户与机器人运动的无缝同步，提高了平衡性和稳定性。

Abstract: Achieving seamless synchronization between user and robot motion in
teleoperation, particularly during high-speed tasks, remains a significant
challenge. In this work, we propose a novel approach for transferring stepping
motions from the user to the robot in real-time. Instead of directly
replicating user foot poses, we retarget user steps to robot footstep
locations, allowing the robot to utilize its own dynamics for locomotion,
ensuring better balance and stability. Our method anticipates user footsteps to
minimize delays between when the user initiates and completes a step and when
the robot does it. The step estimates are continuously adapted to converge with
the measured user references. Additionally, the system autonomously adjusts the
robot's steps to account for its surrounding terrain, overcoming challenges
posed by environmental mismatches between the user's flat-ground setup and the
robot's uneven terrain. Experimental results on the humanoid robot Nadia
demonstrate the effectiveness of the proposed system.

</details>


### [395] [LocoMamba: Vision-Driven Locomotion via End-to-End Deep Reinforcement Learning with Mamba](https://arxiv.org/abs/2508.11849)
*Allen Wang,Gavin Tao*

Main category: cs.RO

TL;DR: LocoMamba 是一个利用 Mamba 的视觉驱动的深度强化学习框架，通过改进状态表示和近乎线性时间的序列建模，在机器人控制任务中实现了更高的性能、泛化能力和训练效率。


<details>
  <summary>Details</summary>
Motivation: 为了实现更高效、更鲁棒的机器人控制，本研究引入了 LocoMamba，一个利用选择性状态空间模型（特别是 Mamba）的视觉驱动的跨模态深度强化学习框架，旨在有效捕捉长距离依赖关系并实现高效训练，尤其是在处理长序列时。

Method: LocoMamba 是一个视觉驱动的跨模态深度强化学习框架，它利用 Mamba 等选择性状态空间模型来实现近乎线性时间序列建模，有效捕捉长距离依赖关系，并通过更长的序列实现高效训练。具体而言，它通过多层感知机嵌入本体感受状态，并通过轻量级卷积神经网络对深度图像进行分块，生成紧凑的标记以提高状态表示。堆叠的 Mamba 层通过近乎线性时间的选择性扫描融合这些标记，从而降低延迟和内存占用，并对标记长度和图像分辨率保持鲁棒性，同时提供归纳偏置以减轻过拟合。策略使用近端策略优化进行端到端训练，并采用地形和外观随机化以及障碍物密度课程，同时使用平衡了进展、平稳性和安全性的以状态为中心的紧凑奖励。

Result: LocoMamba 在模拟环境中取得了优于最先进基线的结果，在处理静态和动态障碍物以及不平坦地形方面表现出更高的回报率和成功率，同时减少了碰撞，并且在未见过的地形和障碍物密度下表现出更强的泛化能力，同时在相同的计算预算下，通过更少的更新实现了更快的收敛，从而提高了训练效率。

Conclusion: LocoMamba 在模拟环境中取得了优于最先进基线的结果，在处理静态和动态障碍物以及不平坦地形方面表现出更高的回报率和成功率，同时减少了碰撞，并且在未见过的地形和障碍物密度下表现出更强的泛化能力，同时在相同的计算预算下，通过更少的更新实现了更快的收敛，从而提高了训练效率。

Abstract: We introduce LocoMamba, a vision-driven cross-modal DRL framework built on
selective state-space models, specifically leveraging Mamba, that achieves
near-linear-time sequence modeling, effectively captures long-range
dependencies, and enables efficient training with longer sequences. First, we
embed proprioceptive states with a multilayer perceptron and patchify depth
images with a lightweight convolutional neural network, producing compact
tokens that improve state representation. Second, stacked Mamba layers fuse
these tokens via near-linear-time selective scanning, reducing latency and
memory footprint, remaining robust to token length and image resolution, and
providing an inductive bias that mitigates overfitting. Third, we train the
policy end-to-end with Proximal Policy Optimization under terrain and
appearance randomization and an obstacle-density curriculum, using a compact
state-centric reward that balances progress, smoothness, and safety. We
evaluate our method in challenging simulated environments with static and
moving obstacles as well as uneven terrain. Compared with state-of-the-art
baselines, our method achieves higher returns and success rates with fewer
collisions, exhibits stronger generalization to unseen terrains and obstacle
densities, and improves training efficiency by converging in fewer updates
under the same compute budget.

</details>


### [396] [Data Shift of Object Detection in Autonomous Driving](https://arxiv.org/abs/2508.11868)
*Lida Xu*

Main category: cs.RO

TL;DR: 本研究解决了自动驾驶领域目标检测中的数据偏移问题，通过数据偏移分析和CycleGAN-YOLOv5模型优化，在BDD100K数据集上提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习技术在自动驾驶系统中的广泛应用，其在应对复杂环境感知挑战中的作用日益凸显。然而，现有的机器学习模型在训练和测试数据满足独立同分布（i.i.d.）的假设下性能表现最佳，但在自动驾驶的实际应用中，由于季节变化、天气波动等因素导致的数据分布动态变化，使得数据偏移问题难以保证。本研究旨在解决自动驾驶目标检测任务中的数据偏移问题。

Method: 本研究首先分析了自动驾驶领域数据偏移问题的复杂性和表现形式，然后回顾了数据偏移检测方法，并运用移位检测分析技术对数据集进行分类和平衡。在此基础上，构建了一个对象检测模型，并通过集成CycleGAN-based数据增强技术和YOLOv5框架进行优化。

Result: 实验结果表明，本研究提出的方法在BDD100K数据集上取得了优于基线模型的性能。

Conclusion: 本研究提出的结合CycleGAN-based数据增强技术和YOLOv5框架的对象检测模型，在BDD100K数据集上取得了优于基线模型的性能。

Abstract: With the widespread adoption of machine learning technologies in autonomous
driving systems, their role in addressing complex environmental perception
challenges has become increasingly crucial. However, existing machine learning
models exhibit significant vulnerability, as their performance critically
depends on the fundamental assumption that training and testing data satisfy
the independent and identically distributed condition, which is difficult to
guarantee in real-world applications. Dynamic variations in data distribution
caused by seasonal changes, weather fluctuations lead to data shift problems in
autonomous driving systems. This study investigates the data shift problem in
autonomous driving object detection tasks, systematically analyzing its
complexity and diverse manifestations. We conduct a comprehensive review of
data shift detection methods and employ shift detection analysis techniques to
perform dataset categorization and balancing. Building upon this foundation, we
construct an object detection model. To validate our approach, we optimize the
model by integrating CycleGAN-based data augmentation techniques with the
YOLOv5 framework. Experimental results demonstrate that our method achieves
superior performance compared to baseline models on the BDD100K dataset.

</details>


### [397] [Bioinspired underwater soft robots: from biology to robotics and back](https://arxiv.org/abs/2508.11883)
*Lei Li,Boyang Qin,Wenzhuo Gao,Yanyu Li,Yiyuan Zhang,Bo Wang,Shihan Kong,Jian Wang,Dekui He,Junzhi Yu*

Main category: cs.RO

TL;DR: This paper presents a bidirectional framework for underwater soft robotics, using robots to study biology and inform future designs inspired by convergent principles across species. It highlights applications in marine exploration and medicine, while noting challenges in materials, efficiency, autonomy, and intelligence.


<details>
  <summary>Details</summary>
Motivation: The vast unexplored regions and diverse soft-bodied marine organisms in the ocean have driven interest in bio-inspired underwater soft robotics. While previous efforts have primarily focused on biology guiding robotics, this paper aims to establish a feedback loop where robotic insights inform biological understanding.

Method: The paper proposes a holistic, bidirectional framework that integrates biological principles, robotic implementation, and biological validation. Soft robots are used as experimental tools to probe biological functions and test evolutionary hypotheses.

Result: Recent advances have enabled new capabilities in underwater movement, sensing, and interaction for soft robots. The paper demonstrates that soft robots can outperform rigid systems in unstructured environments, supporting applications in marine exploration, manipulation, and medicine. It also introduces a new paradigm called bio-universal-inspired robotics.

Conclusion: The paper proposes a bidirectional framework integrating biological principles and robotic implementation for bio-inspired underwater soft robotics, which can serve as experimental tools for biological validation and evolutionary hypotheses testing. It highlights the potential of soft robots in marine exploration, manipulation, and medicine, and introduces a bio-universal-inspired robotics paradigm. The paper concludes by acknowledging challenges in material robustness, actuation efficiency, autonomy, and intelligence, while emphasizing the potential of uniting biology and engineering for ocean exploration and scientific discovery.

Abstract: The ocean vast unexplored regions and diverse soft-bodied marine organisms
have spurred interest in bio-inspired underwater soft robotics. Recent advances
have enabled new capabilities in underwater movement, sensing, and interaction.
However, these efforts are largely unidirectional, with biology guiding
robotics while insights from robotics rarely feed back into biology. Here we
propose a holistic, bidirectional framework that integrates biological
principles, robotic implementation, and biological validation. We show that
soft robots can serve as experimental tools to probe biological functions and
even test evolutionary hypotheses. Their inherent compliance also allows them
to outperform rigid systems in unstructured environments, supporting
applications in marine exploration, manipulation, and medicine. Looking
forward, we introduce bio-universal-inspired robotics, a paradigm that
transcends species-specific mimicry by identifying convergent principles across
species to inspire more adaptable designs. Despite rapid progress, challenges
persist in material robustness, actuation efficiency, autonomy, and
intelligence. By uniting biology and engineering, soft robots can advance ocean
exploration and deepen scientific discovery.

</details>


### [398] [From Screen to Stage: Kid Cosmo, A Life-Like, Torque-Controlled Humanoid for Entertainment Robotics](https://arxiv.org/abs/2508.11884)
*Havel Liu,Mingzhang Zhu,Arturo Moises Flores Alvarez,Yuan Hung Lo,Conrad Ku,Federico Parres,Justin Quan,Colin Togashi,Aditya Navghare,Quanyou Wang,Dennis W. Hong*

Main category: cs.RO

TL;DR: 本研究介绍了Kid Cosmo，一个身高1.45米，体重25公斤，拥有28个自由度的人形机器人，它旨在实现流畅的运动并模仿电影角色。研究展示了其系统架构、设计挑战和解决方案，并初步证明了其在娱乐领域的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 娱乐领域，特别是电影，需要具有视觉吸引力和特定形态的机器人，这与传统人形机器人的纯功能性设计形成对比。本研究旨在探索人形机器人在娱乐领域的应用潜力，并克服在运动流畅性和角色模仿方面遇到的挑战。

Method: Kid Cosmo是一个身高1.45米，体重25公斤，拥有28个自由度，主要使用本体感受执行器的儿童尺寸人形机器人。研究展示了其系统架构、功能性娱乐机器人的挑战与解决方案，以及在同时进行上下半身运动时的稳定性。

Result: Kid Cosmo成功实现了稳健的运动和类似生命体的运动生成，并模仿了电影《Electric State》中的角色形象和举止。该机器人已在世界各地进行展示，并初步验证了其在同时进行上下半身运动时的稳定性。

Conclusion: 该研究展示了以娱乐为导向的人形机器人（Kid Cosmo）的可行性，该机器人兼具角色塑造和技术功能性。

Abstract: Humanoid robots represent the cutting edge of robotics research, yet their
potential in entertainment remains largely unexplored. Entertainment as a field
prioritizes visuals and form, a principle that contrasts with the purely
functional designs of most contemporary humanoid robots. Designing
entertainment humanoid robots capable of fluid movement presents a number of
unique challenges. In this paper, we present Kid Cosmo, a research platform
designed for robust locomotion and life-like motion generation while imitating
the look and mannerisms of its namesake character from Netflix's movie The
Electric State. Kid Cosmo is a child-sized humanoid robot, standing 1.45 m tall
and weighing 25 kg. It contains 28 degrees of freedom and primarily uses
proprioceptive actuators, enabling torque-control walking and lifelike motion
generation. Following worldwide showcases as part of the movie's press tour, we
present the system architecture, challenges of a functional entertainment robot
and unique solutions, and our initial findings on stability during simultaneous
upper and lower body movement. We demonstrate the viability of
performance-oriented humanoid robots that prioritize both character embodiment
and technical functionality.

</details>


### [399] [Contact-Rich and Deformable Foot Modeling for Locomotion Control of the Human Musculoskeletal System](https://arxiv.org/abs/2508.11885)
*Haixin Gong,Chen Zhang,Yanan Sui*

Main category: cs.RO

TL;DR: 这项研究提出了一种新的、包含丰富接触和可变形的人足模型，用于更精确地模拟人类行走。该模型通过改进的训练策略，在运动学、动力学和步态稳定性方面优于传统模型，并能准确复现真实行走数据，为仿人机器人提供了新的解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有肌肉骨骼模型在模拟人类行走时的足部与地面接触力学方面存在过度简化的问题，限制了其在精确模拟人类步态动力学方面的能力。

Method: 开发了一种包含丰富接触和可变形的人足模型，并将其集成到完整的肌肉骨骼系统中。采用了两阶段策略训练来学习行走模式，以克服多点接触和可变形材料带来的控制挑战。

Result: 与传统的刚性肌肉骨骼模型相比，所提出的模型在运动学、动力学和步态稳定性指标上均有改进。仿真结果与人体受试者数据高度吻合，验证了模型的准确性。

Conclusion: 该研究提出了一种先进的、包含丰富接触和可变形的人足模型，并将其集成到完整的肌肉骨骼系统中，能够精确模拟人类行走时的生物力学交互。通过两阶段策略训练，该模型克服了多点接触和可变形材料的控制挑战，学习到了自然的行走模式。与传统的刚性肌肉骨骼模型相比，该方法在运动学、动力学和步态稳定性指标上均有提升，并通过与人体数据对比验证了其仿真精度。此研究不仅推动了包含丰富接触的界面模型在人体肌肉骨骼系统中的应用，也为需要精确足地交互控制的仿人机器人领域提供了坚实的基础框架。

Abstract: The human foot serves as the critical interface between the body and
environment during locomotion. Existing musculoskeletal models typically
oversimplify foot-ground contact mechanics, limiting their ability to
accurately simulate human gait dynamics. We developed a novel contact-rich and
deformable model of the human foot integrated within a complete musculoskeletal
system that captures the complex biomechanical interactions during walking. To
overcome the control challenges inherent in modeling multi-point contacts and
deformable material, we developed a two-stage policy training strategy to learn
natural walking patterns for this interface-enhanced model. Comparative
analysis between our approach and conventional rigid musculoskeletal models
demonstrated improvements in kinematic, kinetic, and gait stability metrics.
Validation against human subject data confirmed that our simulation closely
reproduced real-world biomechanical measurements. This work advances
contact-rich interface modeling for human musculoskeletal systems and
establishes a robust framework that can be extended to humanoid robotics
applications requiring precise foot-ground interaction control.

</details>


### [400] [Saliency-Based Attention Shifting: A Framework for Improving Driver Situational Awareness of Out-of-Label Hazards](https://arxiv.org/abs/2508.11887)
*Yousra Shleibik,Jordan Sinclair,Kerstin Haring*

Main category: cs.RO

TL;DR: 自动驾驶系统需要人机协同决策，特别是在车辆无法独立行动时。本研究提出了一种结合眼动追踪和视听提示的框架，以提高驾驶员在半自动驾驶中的态势感知和注意力管理能力。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶技术向更高自主性发展，确保在需要时人机协同决策的集成系统变得至关重要，特别是在车辆无法识别物体或元素而需要人类介入的情况下，态势感知在风险规避和控制权交接过程中起着关键作用。

Method: 本研究探索了诸如通过定向视觉和听觉线索进行注视操纵等注意力重定向技术，以帮助驾驶员在半自动驾驶场景下集中注意力于新兴危险并减少目标固定。

Result: 该研究旨在通过集成先进技术增强驾驶员在半自动驾驶系统中的态势感知和注意力管理能力。

Conclusion: 该研究提出了一种结合实时眼动追踪、上下文感知显著性分析以及同步视听警报的框架，以提高在半自动驾驶场景下驾驶员的态势感知能力，预先处理潜在危险，并促进人与自动驾驶系统之间的有效协作。

Abstract: The advent of autonomous driving systems promises to transform transportation
by enhancing safety, efficiency, and comfort. As these technologies evolve
toward higher levels of autonomy, the need for integrated systems that
seamlessly support human involvement in decision-making becomes increasingly
critical. Certain scenarios necessitate human involvement, including those
where the vehicle is unable to identify an object or element in the scene, and
as such cannot take independent action. Therefore, situational awareness is
essential to mitigate potential risks during a takeover, where a driver must
assume control and autonomy from the vehicle. The need for driver attention is
important to avoid collisions with external agents and ensure a smooth
transition during takeover operations. This paper explores the integration of
attention redirection techniques, such as gaze manipulation through targeted
visual and auditory cues, to help drivers maintain focus on emerging hazards
and reduce target fixation in semi-autonomous driving scenarios. We propose a
conceptual framework that combines real-time gaze tracking, context-aware
saliency analysis, and synchronized visual and auditory alerts to enhance
situational awareness, proactively address potential hazards, and foster
effective collaboration between humans and autonomous systems.

</details>


### [401] [Integrating Symbolic RL Planning into a BDI-based Autonomous UAV Framework: System Integration and SIL Validation](https://arxiv.org/abs/2508.11890)
*Sangwoo Jeon,Juchul Shin,YeonJe Cho,Gyeong-Tae Kim,Seongwoo Kim*

Main category: cs.RO

TL;DR: AMAD-SRL框架结合了符号规划和强化学习，用于无人机任务规划，在SIL环境中将任务效率提高了75%。


<details>
  <summary>Details</summary>
Motivation: 现代自主无人机任务需要能够无缝集成结构化符号规划与自适应强化学习（RL）的软件框架。传统的基于规则的架构在动态复杂的操作环境中能力不足，而这些环境需要自适应的符号规划。

Method: 提出了AMAD-SRL框架，这是AMAD（自主任务无人机代理）认知多代理架构的扩展和改进版本，并结合了符号强化学习，用于动态任务规划和执行。该框架在与预期硬件在环仿真（HILS）平台结构相同的软件在环（SIL）环境中进行了验证，确保了向真实硬件的无缝过渡。

Result: 实验结果证明了模块的稳定集成和互操作性，以及在基于信誉的（BDI）和符号强化学习（SRL）驱动的规划阶段之间的成功转换，并实现了持续的任务性能。在目标捕获场景的SIL评估中，与基于覆盖范围的基线相比，通过减少行程距离，任务效率提高了约75%。

Conclusion: 该研究为处理复杂无人机任务奠定了坚实的基础，并讨论了进一步增强和验证的方向。

Abstract: Modern autonomous drone missions increasingly require software frameworks
capable of seamlessly integrating structured symbolic planning with adaptive
reinforcement learning (RL). Although traditional rule-based architectures
offer robust structured reasoning for drone autonomy, their capabilities fall
short in dynamically complex operational environments that require adaptive
symbolic planning. Symbolic RL (SRL), using the Planning Domain Definition
Language (PDDL), explicitly integrates domain-specific knowledge and
operational constraints, significantly improving the reliability and safety of
unmanned aerial vehicle (UAV) decision making. In this study, we propose the
AMAD-SRL framework, an extended and refined version of the Autonomous Mission
Agents for Drones (AMAD) cognitive multi-agent architecture, enhanced with
symbolic reinforcement learning for dynamic mission planning and execution. We
validated our framework in a Software-in-the-Loop (SIL) environment structured
identically to an intended Hardware-In-the-Loop Simulation (HILS) platform,
ensuring seamless transition to real hardware. Experimental results demonstrate
stable integration and interoperability of modules, successful transitions
between BDI-driven and symbolic RL-driven planning phases, and consistent
mission performance. Specifically, we evaluate a target acquisition scenario in
which the UAV plans a surveillance path followed by a dynamic reentry path to
secure the target while avoiding threat zones. In this SIL evaluation, mission
efficiency improved by approximately 75% over a coverage-based baseline,
measured by travel distance reduction. This study establishes a robust
foundation for handling complex UAV missions and discusses directions for
further enhancement and validation.

</details>


### [402] [OmniD: Generalizable Robot Manipulation Policy via Image-Based BEV Representation](https://arxiv.org/abs/2508.11898)
*Jilei Mao,Jiarui Guan,Yingjuan Tang,Qirui Hu,Zhihang Li,Junjie Yu,Yongjie Mao,Yunzhe Sun,Shuang Liu,Xiaozhu Ju*

Main category: cs.RO

TL;DR: OmniD是一个多视图融合框架，通过生成统一的鸟瞰图表示来解决visuomotor policy的过拟合问题，并在各种实验中超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: visuomotor policy容易在训练数据集（如固定的摄像机位置和背景）上过拟合，导致在in-distribution场景下表现良好，但在out-of-distribution泛化方面表现不佳。现有方法在融合多视图信息以生成有效的3D表示方面也存在困难。

Method: 提出了一种名为Omni-Vision Diffusion Policy (OmniD)的多视图融合框架，通过可变形注意力机制的Omni-Feature Generator (OFG)将图像观测合成为统一的鸟瞰图(BEV)表示，选择性地提取任务相关特征，同时抑制了特定视图的噪声和背景干扰。

Result: OmniD在in-distribution、out-of-distribution和few-shot实验中取得了显著的性能提升，平均分别提高了11%、17%和84%。

Conclusion: OmniD在in-distribution、out-of-distribution和few-shot实验中分别比最佳基线模型平均提高了11%、17%和84%，证明了其在应对visuomotor policy过拟合和融合多视图信息方面的有效性。

Abstract: The visuomotor policy can easily overfit to its training datasets, such as
fixed camera positions and backgrounds. This overfitting makes the policy
perform well in the in-distribution scenarios but underperform in the
out-of-distribution generalization. Additionally, the existing methods also
have difficulty fusing multi-view information to generate an effective 3D
representation. To tackle these issues, we propose Omni-Vision Diffusion Policy
(OmniD), a multi-view fusion framework that synthesizes image observations into
a unified bird's-eye view (BEV) representation. We introduce a deformable
attention-based Omni-Feature Generator (OFG) to selectively abstract
task-relevant features while suppressing view-specific noise and background
distractions. OmniD achieves 11\%, 17\%, and 84\% average improvement over the
best baseline model for in-distribution, out-of-distribution, and few-shot
experiments, respectively. Training code and simulation benchmark are
available: https://github.com/1mather/omnid.git

</details>


### [403] [Control of Legged Robots using Model Predictive Optimized Path Integral](https://arxiv.org/abs/2508.11917)
*Hossein Keshavarz,Alejandro Ramirez-Serrano,Majid Khadiv*

Main category: cs.RO

TL;DR: MPOPI 是一种结合了 MPPI、CE 和 CMA 的新型采样模型预测策略，可提高机器人运动的样本效率和整体性能。


<details>
  <summary>Details</summary>
Motivation: 尽管有了长足的进步，但与自然系统相比，机器人的运动能力仍有差距。本文旨在通过结合 MPPI、CE 和 CMA 方法来改进采样模型预测控制策略，以提高样本效率和运动能力。

Method: 将 MPPI 与 CE 和 CMA 方法相结合，开发出 MPOPI 采样模型预测策略，用于生成机器人全身运动。

Result: MPOPI 比传统的 MPPI 算法具有更高的样本效率，在四足机器人模拟实验中展示了其作为随时可用的控制策略的潜力，提高了运动能力。

Conclusion: MPOPI 作为一种随时可用的控制策略，可以提高每个迭代的运动能力，在模拟实验中表现出色。

Abstract: Legged robots possess a unique ability to traverse rough terrains and
navigate cluttered environments, making them well-suited for complex,
real-world unstructured scenarios. However, such robots have not yet achieved
the same level as seen in natural systems. Recently, sampling-based predictive
controllers have demonstrated particularly promising results. This paper
investigates a sampling-based model predictive strategy combining model
predictive path integral (MPPI) with cross-entropy (CE) and covariance matrix
adaptation (CMA) methods to generate real-time whole-body motions for legged
robots across multiple scenarios. The results show that combining the benefits
of MPPI, CE and CMA, namely using model predictive optimized path integral
(MPOPI), demonstrates greater sample efficiency, enabling robots to attain
superior locomotion results using fewer samples when compared to typical MPPI
algorithms. Extensive simulation experiments in multiple scenarios on a
quadruped robot show that MPOPI can be used as an anytime control strategy,
increasing locomotion capabilities at each iteration.

</details>


### [404] [ExploreVLM: Closed-Loop Robot Exploration Task Planning with Vision-Language Models](https://arxiv.org/abs/2508.11918)
*Zhichen Lou,Kechun Xu,Zhongxiang Zhou,Rong Xiong*

Main category: cs.RO

TL;DR: ExploreVLM是一个创新的闭环任务规划框架，利用视觉-语言模型（VLM）和逐步反馈机制，提高了机器人在动态环境中进行交互式探索和实时适应计划的能力，并在实际实验中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有VLM在交互式探索、准确感知和实时计划适应方面的不足，以推进机器人作为人类助手在日常生活中的应用。

Method: 提出了一种名为ExploreVLM的新型闭环任务规划框架，该框架由视觉-语言模型（VLM）提供支持。该框架围绕一个逐步反馈机制构建，该机制能够进行实时计划调整并支持交互式探索。其核心是具有自我反思功能的双阶段任务规划器，并通过以对象为中心的空间关系图得到增强，该图提供结构化的、以语言为基础的场景表示来指导感知和规划。执行验证器通过验证每个动作并触发重新规划来支持闭环。

Result: 在以探索为中心任务中的实际实验表明，ExploreVLM显著优于最先进的基线。消融研究进一步验证了反思性规划器和结构化感知在实现健壮高效的任务执行中的关键作用。

Conclusion: ExploreVLM 在探索式任务中显著优于最先进的基线，对反思性规划器和结构化感知在实现健壮高效的任务执行中的关键作用进行了验证。

Abstract: The advancement of embodied intelligence is accelerating the integration of
robots into daily life as human assistants. This evolution requires robots to
not only interpret high-level instructions and plan tasks but also perceive and
adapt within dynamic environments. Vision-Language Models (VLMs) present a
promising solution by combining visual understanding and language reasoning.
However, existing VLM-based methods struggle with interactive exploration,
accurate perception, and real-time plan adaptation. To address these
challenges, we propose ExploreVLM, a novel closed-loop task planning framework
powered by Vision-Language Models (VLMs). The framework is built around a
step-wise feedback mechanism that enables real-time plan adjustment and
supports interactive exploration. At its core is a dual-stage task planner with
self-reflection, enhanced by an object-centric spatial relation graph that
provides structured, language-grounded scene representations to guide
perception and planning. An execution validator supports the closed loop by
verifying each action and triggering re-planning. Extensive real-world
experiments demonstrate that ExploreVLM significantly outperforms
state-of-the-art baselines, particularly in exploration-centric tasks. Ablation
studies further validate the critical role of the reflective planner and
structured perception in achieving robust and efficient task execution.

</details>


### [405] [No More Blind Spots: Learning Vision-Based Omnidirectional Bipedal Locomotion for Challenging Terrain](https://arxiv.org/abs/2508.11929)
*Mohitvishnu S. Gadde,Pranay Dugar,Ashish Malik,Alan Fern*

Main category: cs.RO

TL;DR: 提出了一种用于双足行走的学习框架，可以通过深度图像实现全向运动。该框架通过一种教师-学生策略和一种数据增强技术，避免了模拟中的高额渲染成本，并加快了训练速度。


<details>
  <summary>Details</summary>
Motivation: 有效的双足运动需要全向地形感知和能够处理此类输入的控制器。在模拟中渲染全向深度图像的高计算成本使得传统的模拟到现实强化学习（RL）不切实际。

Method: 提出了一种基于学习的框架，用于基于视觉的全向双足运动，通过深度图像实现无缝运动。该框架结合了一个强大的盲控制器和一个教师策略，该策略用于监督基于视觉的学生策略。学生策略在噪声增强的地形数据上进行训练，以避免在强化学习过程中进行渲染，并确保鲁棒性。还引入了一种用于监督学生训练的数据增强技术。

Result: 与传统方法相比，训练速度提高了10倍，并有效实现了最小化渲染的全向双足运动。

Conclusion: 该框架在模拟和真实世界测试中得到验证，展示了有效的全向双足运动能力，并且对昂贵的渲染的依赖性很小。这是我们所知首次实现基于视觉的全向双足运动，展示了其对不同地形的适应性。

Abstract: Effective bipedal locomotion in dynamic environments, such as cluttered
indoor spaces or uneven terrain, requires agile and adaptive movement in all
directions. This necessitates omnidirectional terrain sensing and a controller
capable of processing such input. We present a learning framework for
vision-based omnidirectional bipedal locomotion, enabling seamless movement
using depth images. A key challenge is the high computational cost of rendering
omnidirectional depth images in simulation, making traditional sim-to-real
reinforcement learning (RL) impractical. Our method combines a robust blind
controller with a teacher policy that supervises a vision-based student policy,
trained on noise-augmented terrain data to avoid rendering costs during RL and
ensure robustness. We also introduce a data augmentation technique for
supervised student training, accelerating training by up to 10 times compared
to conventional methods. Our framework is validated through simulation and
real-world tests, demonstrating effective omnidirectional locomotion with
minimal reliance on expensive rendering. This is, to the best of our knowledge,
the first demonstration of vision-based omnidirectional bipedal locomotion,
showcasing its adaptability to diverse terrains.

</details>


### [406] [Toward General Physical Intelligence for Resilient Agile Manufacturing Automation](https://arxiv.org/abs/2508.11960)
*Sandeep Kanta,Mehrdad Tavassoli,Varun Teja Chirkuri,Venkata Akhil Kumar,Santhi Bharath Punati,Praveen Damacharla,Sunny Katyara*

Main category: cs.RO

TL;DR: A review of Vision Language Action (VLA) models for General Physical Intelligence (GPI) in agile manufacturing, assessing their readiness for industrial use and suggesting future directions for Industry 5.0 integration.


<details>
  <summary>Details</summary>
Motivation: While GPI (General Physical Intelligence) through VLA models has been described, its practical application and role in agile manufacturing have not been fully explored. This review aims to bridge this gap by analyzing the readiness of VLA models for industrial deployment in contemporary agile manufacturing.

Method: This paper systematically surveys recent advancements in VLA models for GPI, performs a comparative analysis of leading implementations, and evaluates their industrial readiness through structured ablation studies. The analysis is organized into five thematic pillars: multisensory representation learning, sim2real transfer, planning and control, uncertainty and safety measures, and benchmarking.

Result: The review systematically surveys VLA models in the GPI context, analyzes leading implementations, and evaluates their readiness for industrial deployment. The findings are organized into five thematic pillars, highlighting advancements and challenges. The paper also articulates open research challenges and proposes future directions for integrating GPI into Industry 5.0.

Conclusion: Agile manufacturing requires resilient robotic solutions. VLA models offer General Physical Intelligence (GPI) by fusing multimodal perception, reasoning, and action. This review surveys VLA models for GPI in agile manufacturing, analyzing implementations and evaluating their industrial readiness. The analysis covers multisensory representation, sim2real transfer, planning, control, uncertainty, safety, and benchmarking. Future directions focus on integrating GPI into Industry 5.0 ecosystems.

Abstract: Agile and human-centric manufacturing stipulates resilient robotic solutions
capable of contextual reasoning and safe interaction in unstructured
environments. Foundation models particularly the Vision Language Action (VLA)
models have emerged to fuse multimodal perception, reasoning and physically
grounded action across varied embodiments into unified representation, termed
as General Physical Intelligence (GPI). While GPI has already been described in
the literature but its practical application and evolving role in contemporary
agile manufacturing processes have yet to be duly explored. To bridge this gap,
this practical review systematically surveys recent advancements in VLA models
within GPI context, performs comprehensive comparative analysis of leading
implementations and evaluates their readiness for industrial deployment through
structured ablation study. Our analysis has organized state-of-the-art into
five thematic pillars including multisensory representation learning, sim2real
transfer, planning and control, uncertainty and safety measures and
benchmarking. Finally, we articulate open research challenges and propose
directions to better integrate GPI into next-generation industrial ecosystems
in line with Industry 5.0.

</details>


### [407] [Fully Spiking Actor-Critic Neural Network for Robotic Manipulation](https://arxiv.org/abs/2508.12038)
*Liwen Zhang,Heng Deng,Guanghui Sun*

Main category: cs.RO

TL;DR: 本研究提出了一种基于简化SNN的混合CRL框架，结合PPO算法和课程策略，用于机器人手臂控制，并在能效和性能上优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 为了在资源受限的环境中实现高效的机器人操作，本研究旨在利用SNN的高推理速度、低功耗和生物可实现性等优势，并提出一种新的CRL框架，以提高机械臂执行目标到达和抓取任务的学习效率和策略准确性，并关注其能耗问题。

Method: 本研究整合了时间进度划分的课程策略与近端策略优化（PPO）算法，并引入了能量消耗建模框架以量化SNN与ANN的理论能耗。为降低网络复杂性和推理延迟，SNN架构被简化为仅包含输入和输出层。此外，还采用了动态两阶段奖励调整机制和优化的观测空间来提升学习效率和策略精度。

Result: 实验结果表明，所提出的混合CRL框架在Isaac Gym模拟平台上，于现实物理约束下实现了优于传统PPO和ANN基线方法的性能，特别是在可扩展性和能效方面表现突出。

Conclusion: 该研究提出的基于全脉冲神经网络（SNN）的混合课程强化学习（CRL）框架在执行目标到达和抓取任务的9自由度机械臂上表现出卓越性能，并经过与传统PPO和ANN基线的对比验证，证明了其在动态机器人操作任务中的可扩展性和能效优势。

Abstract: This study proposes a hybrid curriculum reinforcement learning (CRL)
framework based on a fully spiking neural network (SNN) for 9-degree-of-freedom
robotic arms performing target reaching and grasping tasks. To reduce network
complexity and inference latency, the SNN architecture is simplified to include
only an input and an output layer, which shows strong potential for
resource-constrained environments. Building on the advantages of SNNs-high
inference speed, low energy consumption, and spike-based biological
plausibility, a temporal progress-partitioned curriculum strategy is integrated
with the Proximal Policy Optimization (PPO) algorithm. Meanwhile, an energy
consumption modeling framework is introduced to quantitatively compare the
theoretical energy consumption between SNNs and conventional Artificial Neural
Networks (ANNs). A dynamic two-stage reward adjustment mechanism and optimized
observation space further improve learning efficiency and policy accuracy.
Experiments on the Isaac Gym simulation platform demonstrate that the proposed
method achieves superior performance under realistic physical constraints.
Comparative evaluations with conventional PPO and ANN baselines validate the
scalability and energy efficiency of the proposed approach in dynamic robotic
manipulation tasks.

</details>


### [408] [Talk Less, Fly Lighter: Autonomous Semantic Compression for UAV Swarm Communication via LLMs](https://arxiv.org/abs/2508.12043)
*Fei Lin,Tengchao Zhang,Qinghua Ni,Jun Huang,Siji Ma,Yonglin Tian,Yisheng Lv,Naiqi Wu*

Main category: cs.RO

TL;DR: 本研究探索了LLM驱动的UAV蜂群在自主语义压缩通信方面的可行性，以应对通信带宽限制。通过模拟实验和消融研究，证明了LLM在降低通信负载和保持任务语义方面具有潜力，在带宽受限和多跳通信条件下能实现高效协作。


<details>
  <summary>Details</summary>
Motivation: 为了解决LLM在无人系统中的应用所面临的通信带宽限制和高频交互需求带来的语义信息传输挑战，旨在降低通信负载同时保留关键任务语义。

Method: 通过构建不同环境复杂度的2D模拟场景，并设计集成系统提示和任务指令提示的通信-执行管线，来评估九种主流LLM在不同场景下的语义压缩性能，并通过对环境复杂度及蜂群规模进行消融研究来分析其适应性和稳定性。

Result: 实验结果表明，LLM驱动的UAV蜂群在带宽受限和多跳链路条件下，能够实现高效的协同通信。

Conclusion: LLM驱动的UAV蜂群在带宽受限和多跳链路条件下具有实现高效协作通信的潜力。

Abstract: The rapid adoption of Large Language Models (LLMs) in unmanned systems has
significantly enhanced the semantic understanding and autonomous task execution
capabilities of Unmanned Aerial Vehicle (UAV) swarms. However, limited
communication bandwidth and the need for high-frequency interactions pose
severe challenges to semantic information transmission within the swarm. This
paper explores the feasibility of LLM-driven UAV swarms for autonomous semantic
compression communication, aiming to reduce communication load while preserving
critical task semantics. To this end, we construct four types of 2D simulation
scenarios with different levels of environmental complexity and design a
communication-execution pipeline that integrates system prompts with task
instruction prompts. On this basis, we systematically evaluate the semantic
compression performance of nine mainstream LLMs in different scenarios and
analyze their adaptability and stability through ablation studies on
environmental complexity and swarm size. Experimental results demonstrate that
LLM-based UAV swarms have the potential to achieve efficient collaborative
communication under bandwidth-constrained and multi-hop link conditions.

</details>


### [409] [OASIS: Real-Time Opti-Acoustic Sensing for Intervention Systems in Unstructured Environments](https://arxiv.org/abs/2508.12071)
*Amy Phung,Richard Camilli*

Main category: cs.RO

TL;DR: OASIS is a real-time underwater 3D reconstruction method fusing optical and sonar data using voxel carving and an eye-in-hand robot for better spatial awareness in underwater operations.


<details>
  <summary>Details</summary>
Motivation: High-resolution underwater 3D scene reconstruction is crucial for various applications, and real-time spatial awareness is essential for underwater vehicle operations, which prior work has not adequately addressed.

Method: OASIS, an opti-acoustic fusion method using optical images and voxel carving techniques with an eye-in-hand configuration to capture multiple workspace views across a short baseline.

Result: The OASIS method demonstrates utility for underwater manipulation tasks, validated through tank-based experiments with qualitative and quantitative results.

Conclusion: The OASIS method achieves real-time 3D reconstruction for underwater manipulation tasks by fusing optical images and sonar data using voxel carving techniques and an eye-in-hand configuration.

Abstract: High resolution underwater 3D scene reconstruction is crucial for various
applications, including construction, infrastructure maintenance, monitoring,
exploration, and scientific investigation. Prior work has leveraged the
complementary sensing modalities of imaging sonars and optical cameras for
opti-acoustic 3D scene reconstruction, demonstrating improved results over
methods which rely solely on either sensor. However, while most existing
approaches focus on offline reconstruction, real-time spatial awareness is
essential for both autonomous and piloted underwater vehicle operations. This
paper presents OASIS, an opti-acoustic fusion method that integrates data from
optical images with voxel carving techniques to achieve real-time 3D
reconstruction unstructured underwater workspaces. Our approach utilizes an
"eye-in-hand" configuration, which leverages the dexterity of robotic
manipulator arms to capture multiple workspace views across a short baseline.
We validate OASIS through tank-based experiments and present qualitative and
quantitative results that highlight its utility for underwater manipulation
tasks.

</details>


### [410] [Into the Wild: When Robots Are Not Welcome](https://arxiv.org/abs/2508.12075)
*Shaul Ashkenazi,Gabriel Skantze,Jane Stuart-Smith,Mary Ellen Foster*

Main category: cs.RO

TL;DR: 虽然在学生服务中心和难民接待中心部署社交机器人遇到了困难，但最终还是获得了工作人员的信任，得以继续研究。


<details>
  <summary>Details</summary>
Motivation: 社会机器人在公共场所的部署面临技术挑战、意外的用户言论以及来自可能不适应在这些场所引入机器人的人们的反对。

Method: 描述了在两个不同的公共场所部署社会机器人的困难：1）学生服务中心；2）难民和寻求庇护者访视服务。

Result: 尽管这是一份失败报告，但在每个用例中，我们最终都获得了工作人员的信任，并与他们建立了关系，从而能够部署我们的机器人并进行研究。

Conclusion: 部署的社会机器人获得了工作人员的信任，并与他们建立了关系。

Abstract: Social robots are increasingly being deployed in public spaces, where they
face not only technological difficulties and unexpected user utterances, but
also objections from stakeholders who may not be comfortable with introducing a
robot into those spaces. We describe our difficulties with deploying a social
robot in two different public settings: 1) Student services center; 2) Refugees
and asylum seekers drop-in service. Although this is a failure report, in each
use case we eventually managed to earn the trust of the staff and form a
relationship with them, allowing us to deploy our robot and conduct our
studies.

</details>


### [411] [Belief-Conditioned One-Step Diffusion: Real-Time Trajectory Planning with Just-Enough Sensing](https://arxiv.org/abs/2508.12166)
*Gokul Puthumanaillam,Aditya Penumarti,Manav Vora,Paulo Padrao,Jose Fuentes,Leonardo Bobadilla,Jane Shin,Melkior Ornik*

Main category: cs.RO

TL;DR: 本研究提出了一种名为B-COD的机器人导航规划器，它利用扩散模型智能选择传感器，能在保证任务完成的前提下大幅降低能耗。通过在机器人上实际测试，B-COD成功减少了传感器功耗，同时保持了与持续激活所有传感器的基线相当的性能。


<details>
  <summary>Details</summary>
Motivation: 传统机器人定位方法在持续开启所有传感器时能耗高昂且不切实际，而现有的数据驱动方法（如扩散模型）通常假设状态估计准确且始终可用。然而，在部分可观测环境中，如何为特定任务选择在每个位置上激活的最小传感器子集，以将状态不确定性保持在足以完成任务的较低水平，仍然是一个开放且关键的问题。因此，本研究的动机是解决这一挑战，提出一种能够智能管理传感器激活以平衡能源消耗和定位精度的解决方案。

Method: 提出了一种名为B-COD（Belief-Conditioned One-Step Diffusion）的规划器。该规划器通过将扩散模型（diffusion model）与姿态信念栅格（pose-belief raster）和传感器掩码（sensor mask）相结合，利用扩散模型的去噪轨迹来估计定位误差。这种方法避免了传统的解析模型和启发式传感器切换，并且能够直接在10毫秒的前向传播中输出短期轨迹、每路点的变异性以及定位误差的代理指标。然后，一个软Actor-Critic（SAC）算法利用这个代理指标在线选择传感器，以最小化能源消耗并控制姿态协方差的增长。

Result: B-COD规划器在10毫秒的前向传播中，能够生成短期轨迹、路点级别的变异性以及定位误差的代理指标，无需外部协方差传播。通过将B-COD与软Actor-Critic（SAC）算法结合，可以在线优化传感器选择，从而在降低传感能耗的同时，有效控制姿态协方差的增长。实际的海洋无人驾驶器（USV）测试结果表明，B-COD能够显著减少传感能耗，并且在任务完成性能上与持续开启所有传感器的基线方法相当。

Conclusion: 该研究提出了B-COD（Belief-Conditioned One-Step Diffusion）规划器，一种创新的方法，能够在机器人导航任务中通过选择最小传感器子集来优化能源消耗，同时保持足够低的定位不确定性以完成任务。该方法在实际海洋无人驾驶器测试中表现出色，成功降低了传感功耗，并达到了与持续开启所有传感器基线相当的目标到达性能。

Abstract: Robots equipped with rich sensor suites can localize reliably in
partially-observable environments, but powering every sensor continuously is
wasteful and often infeasible. Belief-space planners address this by
propagating pose-belief covariance through analytic models and switching
sensors heuristically--a brittle, runtime-expensive approach. Data-driven
approaches--including diffusion models--learn multi-modal trajectories from
demonstrations, but presuppose an accurate, always-on state estimate. We
address the largely open problem: for a given task in a mapped environment,
which \textit{minimal sensor subset} must be active at each location to
maintain state uncertainty \textit{just low enough} to complete the task? Our
key insight is that when a diffusion planner is explicitly conditioned on a
pose-belief raster and a sensor mask, the spread of its denoising trajectories
yields a calibrated, differentiable proxy for the expected localisation error.
Building on this insight, we present Belief-Conditioned One-Step Diffusion
(B-COD), the first planner that, in a 10 ms forward pass, returns a
short-horizon trajectory, per-waypoint aleatoric variances, and a proxy for
localisation error--eliminating external covariance rollouts. We show that this
single proxy suffices for a soft-actor-critic to choose sensors online,
optimising energy while bounding pose-covariance growth. We deploy B-COD in
real-time marine trials on an unmanned surface vehicle and show that it reduces
sensing energy consumption while matching the goal-reach performance of an
always-on baseline.

</details>


### [412] [Energy Efficiency in Robotics Software: A Systematic Literature Review (2020-2024)](https://arxiv.org/abs/2508.12170)
*Aryan Gupta*

Main category: cs.RO

TL;DR: 本综述系统性地回顾了 2020-2024 年机器人软件能源效率的研究，发现电机是主要能耗点，运动优化是关键技术，并提出了改进报告的标准和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在更新和扩展 2020 年之前的相关证据，系统性地回顾 2020 年至 2024 年间机器人软件层面能源效率的研究进展。

Method: 本研究采用系统性文献综述方法，结合自动化流程（包括 Google Scholar 索引、反向/前向滚雪球和大型语言模型辅助筛选与数据提取）和人工审计（约 10% 的审计），最终纳入 79 篇论文进行分析。

Result: 研究发现工业应用和探索是主要的应用领域；电机/执行器是主要的能源消耗者（占 68.4%）；模拟评估是最常见的评估类型（占 51.9%）；运动和轨迹优化是最主要的节能技术（占 69.6%）；然而，能源效率的报告方式异质，限制了跨论文的可比性。

Conclusion: 本综述提供了实现机器人软件层面能源效率的最低报告清单，例如总能耗和平均功耗，以及一个任务归一化指标和清晰的基线，并强调了跨层设计和量化非性能权衡（如准确性、稳定性）方面的机会。

Abstract: This study presents a systematic literature review of software-level
approaches to energy efficiency in robotics published from 2020 through 2024,
updating and extending pre-2020 evidence. An automated-but-audited pipeline
combined Google Scholar seeding, backward/forward snowballing, and
large-language-model (LLM) assistance for screening and data extraction, with
~10% human audits at each automated step and consensus-with-tie-breaks for
full-text decisions. The final corpus comprises 79 peer-reviewed studies
analyzed across application domain, metrics, evaluation type, energy models,
major energy consumers, software technique families, and energy-quality
trade-offs. Industrial settings dominate (31.6%) followed by exploration
(25.3%). Motors/actuators are identified as the primary consumer in 68.4% of
studies, with computing/controllers a distant second (13.9%). Simulation-only
evaluations remain most common (51.9%), though hybrid evaluations are frequent
(25.3%). Representational (physics-grounded) energy models predominate (87.3%).
Motion and trajectory optimization is the leading technique family (69.6%),
often paired with learning/prediction (40.5%) and computation
allocation/scheduling (26.6%); power management/idle control (11.4%) and
communication/data efficiency (3.8%) are comparatively underexplored. Reporting
is heterogeneous: composite objectives that include energy are most common,
while task-normalized and performance-per-energy metrics appear less often,
limiting cross-paper comparability. The review offers a minimal reporting
checklist (e.g., total energy and average power plus a task-normalized metric
and clear baselines) and highlights opportunities in cross-layer designs and in
quantifying non-performance trade-offs (accuracy, stability). A replication
package with code, prompts, and frozen datasets accompanies the review.

</details>


### [413] [Humanoid Motion Scripting with Postural Synergies](https://arxiv.org/abs/2508.12184)
*Rhea Malhotra,William Chong,Catie Cuan,Oussama Khatib*

Main category: cs.RO

TL;DR: SynSculptor是一个用于人形机器人运动生成和编辑的框架，它利用姿势协同作用来实现无需训练的人类运动脚本。


<details>
  <summary>Details</summary>
Motivation: 为了解决收集和分析参考人类运动、合成新运动以及将生成运动映射到人形机器人的挑战，SynSculptor被引入。

Method: SynSculptor框架通过主成分分析（PCA）提取了速度轨迹中的主要姿势协同作用，并构建了一个风格条件协同作用库，用于自由空间运动生成。

Result: SynSculptor能够生成类似人类的运动，并可通过足部滑动比率、运动平滑度、总动量和动能偏差等指标进行评估，同时还通过运动-语言变换器适应所选的协同作用。

Conclusion: SynSculptor通过利用姿势协同作用，为无需训练的人类运动脚本提供了一种新颖的框架，从而解决了人形机器人运动生成中的关键挑战。

Abstract: Generating sequences of human-like motions for humanoid robots presents
challenges in collecting and analyzing reference human motions, synthesizing
new motions based on these reference motions, and mapping the generated motion
onto humanoid robots. To address these issues, we introduce SynSculptor, a
humanoid motion analysis and editing framework that leverages postural
synergies for training-free human-like motion scripting. To analyze human
motion, we collect 3+ hours of motion capture data across 20 individuals where
a real-time operational space controller mimics human motion on a simulated
humanoid robot. The major postural synergies are extracted using principal
component analysis (PCA) for velocity trajectories segmented by changes in
robot momentum, constructing a style-conditioned synergy library for free-space
motion generation. To evaluate generated motions using the synergy library, the
foot-sliding ratio and proposed metrics for motion smoothness involving total
momentum and kinetic energy deviations are computed for each generated motion,
and compared with reference motions. Finally, we leverage the synergies with a
motion-language transformer, where the humanoid, during execution of motion
tasks with its end-effectors, adapts its posture based on the chosen synergy.
Supplementary material, code, and videos are available at
https://rhea-mal.github.io/humanoidsynergies.io.

</details>


### [414] [Self-Guided Action Diffusion](https://arxiv.org/abs/2508.12189)
*Rhea Malhotra,Yuejiang Liu,Chelsea Finn*

Main category: cs.RO

TL;DR: Self-guided action diffusion improves robot policies efficiently by guiding the proposal distribution, outperforming existing methods in challenging tasks.


<details>
  <summary>Details</summary>
Motivation: Improving generative robot policies by optimizing cross-chunk coherence via bidirectional decoding, which has proven effective but remains computationally expensive.

Method: Self-guided action diffusion, a more efficient variant of bidirectional decoding tailored for diffusion-based policies, guides the proposal distribution at each diffusion step based on the prior decision.

Result: Experiments in simulation tasks show that the proposed self-guidance enables near-optimal performance at negligible inference cost, achieving up to 70% higher success rates than existing counterparts on challenging dynamic tasks under a tight sampling budget.

Conclusion: self-guided action diffusion is an efficient variant of bidirectional decoding that achieves near-optimal performance at negligible inference cost and significantly improves success rates on challenging dynamic tasks, especially under a tight sampling budget.

Abstract: Recent works have shown the promise of inference-time search over action
samples for improving generative robot policies. In particular, optimizing
cross-chunk coherence via bidirectional decoding has proven effective in
boosting the consistency and reactivity of diffusion policies. However, this
approach remains computationally expensive as the diversity of sampled actions
grows. In this paper, we introduce self-guided action diffusion, a more
efficient variant of bidirectional decoding tailored for diffusion-based
policies. At the core of our method is to guide the proposal distribution at
each diffusion step based on the prior decision. Experiments in simulation
tasks show that the proposed self-guidance enables near-optimal performance at
negligible inference cost. Notably, under a tight sampling budget, our method
achieves up to 70% higher success rates than existing counterparts on
challenging dynamic tasks. See project website at
https://rhea-mal.github.io/selfgad.github.io.

</details>


### [415] [Improving Pre-Trained Vision-Language-Action Policies with Model-Based Search](https://arxiv.org/abs/2508.12211)
*Cyrus Neary,Omar G. Younis,Artur Kuramshin,Ozgur Aslan,Glen Berseth*

Main category: cs.RO

TL;DR: VLAPS通过在VLA模型推理中加入基于搜索的规划，提高了机器人完成语言指令任务的能力，尤其是在复杂场景下。


<details>
  <summary>Details</summary>
Motivation: 预训练的VLA模型在机器人任务中存在行为脆弱和不安全失败的问题，尤其是在零样本和分布外场景下，因此需要改进其性能。

Method: VLAPS框架使用改进的蒙特卡洛树搜索（MCTS）算法，并结合VLA策略提供的先验知识，在目标环境模型中进行搜索，以探索那些搜索空间巨大的、受语言条件约束的机器人任务。

Result: VLAPS在语言指定的、对无信息搜索算法来说难以处理的任务上，显著优于仅使用VLA的基线方法，成功率最高可提高67个百分点。

Conclusion: VLAPS框架通过将基于模型的搜索嵌入到预训练视觉-语言-动作（VLA）策略的推理过程中，显著提高了机器人任务的性能，尤其是在零样本和分布外场景中。

Abstract: Pre-trained vision-language-action (VLA) models offer a promising foundation
for generalist robot policies, but often produce brittle behaviours or unsafe
failures when deployed zero-shot in out-of-distribution scenarios. We present
Vision-Language-Action Planning & Search (VLAPS) -- a novel framework and
accompanying algorithms that embed model-based search into the inference
procedure of pre-trained VLA policies to improve their performance on robotic
tasks. Specifically, our method biases a modified Monte Carlo Tree Search
(MCTS) algorithm -- run using a model of the target environment -- using action
priors defined by the VLA policy. By using VLA-derived abstractions and priors
in model-based search, VLAPS efficiently explores language-conditioned robotics
tasks whose search spaces would otherwise be intractably large. Conversely, by
integrating model-based search with the VLA policy's inference procedure, VLAPS
yields behaviours that are more performant than those obtained by directly
following the VLA policy's action predictions. VLAPS offers a principled
framework to: i) control test-time compute in VLA models, ii) leverage a priori
knowledge of the robotic environment, and iii) integrate established planning
and reinforcement learning techniques into the VLA inference process. Across
all experiments, VLAPS significantly outperforms VLA-only baselines on
language-specified tasks that would otherwise be intractable for uninformed
search algorithms, increasing success rates by as much as 67 percentage points.

</details>


### [416] [Robot Trains Robot: Automatic Real-World Policy Adaptation and Learning for Humanoids](https://arxiv.org/abs/2508.12252)
*Kaizhe Hu,Haochen Shi,Yao He,Weizhuo Wang,C. Karen Liu,Shuran Song*

Main category: cs.RO

TL;DR: RTR框架利用机器人手臂教师指导人形机器人学生进行高效的现实世界强化学习，并提出了一种优化潜在变量以稳定从模拟到现实传输的流程，成功应用于人形机器人的行走和秋千任务。


<details>
  <summary>Details</summary>
Motivation: 为了解决在现实世界中从头开始进行强化学习（RL）或从预训练策略进行适应的限制，以及现实世界学习面临的安全、奖励设计和学习效率等挑战，从而充分发挥人形机器人的潜力。

Method: 提出了一种名为Robot-Trains-Robot（RTR）的新颖框架，其中机器人手臂充当教师，为人形机器人学生提供保护、学习计划、奖励、干扰、故障检测和自动重置等支持。此外，还提出了一种新的RL流程，通过在现实世界中优化单一的动态编码潜在变量来促进和稳定从模拟到现实的传输。

Result: 通过在精确速度跟踪和从头学习秋千任务等具有挑战性的现实世界人形机器人任务中，对行进策略进行微调，证明了RTR系统的潜力，说明了RTR系统实现的现实世界人形机器人学习的潜力。

Conclusion: 该研究提出了Robot-Trains-Robot（RTR）框架，该框架通过机器人手臂教师来指导和支持人形机器人学生，能够实现高效的长期现实世界人形机器人训练，同时最大限度地减少人为干预。此外，还提出了一种新的强化学习（RL）流程，通过在现实世界中优化单一的动态编码潜在变量来促进和稳定从模拟到现实的传输。研究通过在精确速度跟踪和从头学习秋千任务等具有挑战性的现实世界人形机器人任务中，对行进策略进行微调，证明了RTR系统的潜力。

Abstract: Simulation-based reinforcement learning (RL) has significantly advanced
humanoid locomotion tasks, yet direct real-world RL from scratch or adapting
from pretrained policies remains rare, limiting the full potential of humanoid
robots. Real-world learning, despite being crucial for overcoming the
sim-to-real gap, faces substantial challenges related to safety, reward design,
and learning efficiency. To address these limitations, we propose
Robot-Trains-Robot (RTR), a novel framework where a robotic arm teacher
actively supports and guides a humanoid robot student. The RTR system provides
protection, learning schedule, reward, perturbation, failure detection, and
automatic resets. It enables efficient long-term real-world humanoid training
with minimal human intervention. Furthermore, we propose a novel RL pipeline
that facilitates and stabilizes sim-to-real transfer by optimizing a single
dynamics-encoded latent variable in the real world. We validate our method
through two challenging real-world humanoid tasks: fine-tuning a walking policy
for precise speed tracking and learning a humanoid swing-up task from scratch,
illustrating the promising capabilities of real-world humanoid learning
realized by RTR-style systems. See https://robot-trains-robot.github.io/ for
more info.

</details>


### [417] [Bimanual Robot-Assisted Dressing: A Spherical Coordinate-Based Strategy for Tight-Fitting Garments](https://arxiv.org/abs/2508.12274)
*Jian Zhao,Yunlong Lian,Andy M Tyrrell,Michael Gienger,Jihong Zhu*

Main category: cs.RO

TL;DR: 提出了一种基于双臂协作和模仿学习的穿衣策略，用于解决机器人穿戴紧身衣物的挑战。


<details>
  <summary>Details</summary>
Motivation: 目前机器人辅助穿衣研究主要集中在宽松衣物，对紧身衣物的研究较少，而单臂操作难以成功完成紧身衣物的穿戴任务。

Method: 提出了一种双臂穿衣策略，并利用球坐标系、高斯混合模型（GMM）和高斯混合回归（GMR）进行模仿学习，以适应不同的人体手臂姿势。

Result: 生成了能够适应不同人体手臂姿势的双臂穿衣策略，并通过实验验证了其有效性。

Conclusion: 该方法通过实验验证了其有效性，为机器人辅助穿衣领域提供了新的解决方案。

Abstract: Robot-assisted dressing is a popular but challenging topic in the field of
robotic manipulation, offering significant potential to improve the quality of
life for individuals with mobility limitations. Currently, the majority of
research on robot-assisted dressing focuses on how to put on loose-fitting
clothing, with little attention paid to tight garments. For the former, since
the armscye is larger, a single robotic arm can usually complete the dressing
task successfully. However, for the latter, dressing with a single robotic arm
often fails due to the narrower armscye and the property of diminishing
rigidity in the armscye, which eventually causes the armscye to get stuck. This
paper proposes a bimanual dressing strategy suitable for dressing tight-fitting
clothing. To facilitate the encoding of dressing trajectories that adapt to
different human arm postures, a spherical coordinate system for dressing is
established. We uses the azimuthal angle of the spherical coordinate system as
a task-relevant feature for bimanual manipulation. Based on this new
coordinate, we employ Gaussian Mixture Model (GMM) and Gaussian Mixture
Regression (GMR) for imitation learning of bimanual dressing trajectories,
generating dressing strategies that adapt to different human arm postures. The
effectiveness of the proposed method is validated through various experiments.

</details>


### [418] [A robust and compliant robotic assembly control strategy for batch precision assembly task with uncertain fit types and fit amounts](https://arxiv.org/abs/2508.12296)
*Bin Wang,Jiwen Zhang,Song Wang,Dan Wu*

Main category: cs.RO

TL;DR: 提出了一种基于力-视觉融合和多任务强化学习的方法，用于解决机器人批量精密装配中零件配合不确定性的问题，并成功构建了更优的鲁棒控制策略。


<details>
  <summary>Details</summary>
Motivation: 针对具有不确定配合类型和配合量的零件批量精密装配任务，提出了一种构建鲁棒且顺应性装配控制策略的高效方法。

Method: 提出了一种力-视觉融合控制器驱动的强化学习方法和多任务强化学习训练方法（FVFC-MTRL），用于联合学习这些子任务的多个顺应性控制策略。随后，设计了多教师策略蒸馏方法，将多个训练好的策略整合到一个统一的学生网络中，从而建立了一个鲁棒的控制策略。

Result: 现实世界的实验表明，所提出的方法成功地为具有不同配合类型和配合量的精密装配任务构建了鲁棒的控制策略。MTRL框架显著提高了训练效率，最终开发的控制策略在力和顺应性方面表现更优，成功率更高。

Conclusion: 所提出的方法成功地为具有不同配合类型和配合量的精密装配任务构建了鲁棒的控制策略。此外，MTRL框架显著提高了训练效率，最终开发的控制策略与许多现有方法相比，在力和顺应性方面表现更优，成功率更高。

Abstract: In some high-precision industrial applications, robots are deployed to
perform precision assembly tasks on mass batches of manufactured pegs and
holes. If the peg and hole are designed with transition fit, machining errors
may lead to either a clearance or an interference fit for a specific pair of
components, with uncertain fit amounts. This paper focuses on the robotic batch
precision assembly task involving components with uncertain fit types and fit
amounts, and proposes an efficient methodology to construct the robust and
compliant assembly control strategy. Specifically, the batch precision assembly
task is decomposed into multiple deterministic subtasks, and a force-vision
fusion controller-driven reinforcement learning method and a multi-task
reinforcement learning training method (FVFC-MTRL) are proposed to jointly
learn multiple compliance control strategies for these subtasks. Subsequently,
the multi-teacher policy distillation approach is designed to integrate
multiple trained strategies into a unified student network, thereby
establishing a robust control strategy. Real-world experiments demonstrate that
the proposed method successfully constructs the robust control strategy for
high-precision assembly task with different fit types and fit amounts.
Moreover, the MTRL framework significantly improves training efficiency, and
the final developed control strategy achieves superior force compliance and
higher success rate compared with many existing methods.

</details>


### [419] [Implementation and evaluation of a prediction algorithm for an autonomous vehicle](https://arxiv.org/abs/2508.12312)
*Marco Leon Rapp*

Main category: cs.RO

TL;DR: 本文提出了一种基于动力学模型的车辆轨迹预测算法，通过实验验证和扩展卡尔曼滤波器实现，精度高，优于运动学模型。


<details>
  <summary>Details</summary>
Motivation: 为了提高自动驾驶车辆的导航和控制精度，需要精确的车辆轨迹预测算法。

Method: 本文提出了一种预测算法，用于估计自动驾驶车辆的轨迹，采样频率为每五毫秒。研究人员比较了运动学和动力学自行车模型，并进行了实验来确定车辆参数，如质量、重心、转动惯量和转弯刚度。针对转弯刚度，还引入了一种使用光学位置跟踪的新型测量程序。该模型被整合到扩展卡尔曼滤波器中，并使用C++在ROS节点中实现。

Result: 所提出的算法实现了仅1.25厘米/米的定位偏差，并且比运动学模型精确度高达82.6%。

Conclusion: 所提出的预测算法能够以极高的精度估计车辆轨迹，并且在实际应用中比传统的运动学模型更优越。

Abstract: This paper presents a prediction algorithm that estimates the vehicle
trajectory every five milliseconds for an autonomous vehicle. A kinematic and a
dynamic bicycle model are compared, with the dynamic model exhibiting superior
accuracy at higher speeds. Vehicle parameters such as mass, center of gravity,
moment of inertia, and cornering stiffness are determined experimentally. For
cornering stiffness, a novel measurement procedure using optical position
tracking is introduced. The model is incorporated into an extended Kalman
filter and implemented in a ROS node in C++. The algorithm achieves a
positional deviation of only 1.25 cm per meter over the entire test drive and
is up to 82.6% more precise than the kinematic model.

</details>


### [420] [Semi-Infinite Programming for Collision-Avoidance in Optimal and Model Predictive Control](https://arxiv.org/abs/2508.12335)
*Yunfan Gao,Florian Messerer,Niels van Duijkeren,Rashmi Dabir,Moritz Diehl*

Main category: cs.RO

TL;DR: 提出一种新方法，通过局部约减和外部活动集方法处理碰撞避免问题，并考虑了不确定性，在真实机器人和仿真中均表现良好。


<details>
  <summary>Details</summary>
Motivation: 为最优和模型预测控制中的碰撞避免问题提供一种新方法，该方法能够处理由大量点表示的环境和由填充多边形并集表示的机器人，以及状态不确定性。

Method: 提出一种结合局部约减和外部活动集方法来处理包含无限约束的半无限规划最优控制问题。对于平移不确定性，采用局部约减和机器人形状参数化；对于旋转不确定性，则采用回退重构。

Result: 在真实机器人上实现了20Hz的控制器，能够在狭窄空间内实现快速、无碰撞导航，并在仿真中展示了3D碰撞避免的应用。

Conclusion: 该方法能够实现快速、无碰撞的导航，并成功应用于真实机器人和3D碰撞避免仿真。

Abstract: This paper presents a novel approach for collision avoidance in optimal and
model predictive control, in which the environment is represented by a large
number of points and the robot as a union of padded polygons. The conditions
that none of the points shall collide with the robot can be written in terms of
an infinite number of constraints per obstacle point. We show that the
resulting semi-infinite programming (SIP) optimal control problem (OCP) can be
efficiently tackled through a combination of two methods: local reduction and
an external active-set method. Specifically, this involves iteratively
identifying the closest point obstacles, determining the lower-level distance
minimizer among all feasible robot shape parameters, and solving the
upper-level finitely-constrained subproblems.
  In addition, this paper addresses robust collision avoidance in the presence
of ellipsoidal state uncertainties. Enforcing constraint satisfaction over all
possible uncertainty realizations extends the dimension of constraint
infiniteness. The infinitely many constraints arising from translational
uncertainty are handled by local reduction together with the robot shape
parameterization, while rotational uncertainty is addressed via a backoff
reformulation.
  A controller implemented based on the proposed method is demonstrated on a
real-world robot running at 20Hz, enabling fast and collision-free navigation
in tight spaces. An application to 3D collision avoidance is also demonstrated
in simulation.

</details>


### [421] [SIGN: Safety-Aware Image-Goal Navigation for Autonomous Drones via Reinforcement Learning](https://arxiv.org/abs/2508.12394)
*Zichen Yan,Rui Huang,Lei He,Shao Guo,Lin Zhao*

Main category: cs.RO

TL;DR: 提出了一种用于无人机图像导航的 sim-to-real 框架，通过视觉强化学习和辅助任务进行训练，实现了端到端导航、直接速度控制和避障，无需全局地图。


<details>
  <summary>Details</summary>
Motivation: 使自主无人机能够执行图像导航任务，这比地面机器人更具挑战性，因为它们需要高频反馈控制和全局定位来进行稳定飞行。

Method: 提出了一种新颖的模拟到真实（sim-to-real）框架，利用视觉强化学习（RL）为无人机实现图像导航。为增强视觉表示能力，该方法训练了具有辅助任务（包括图像扰动和未来状态预测）的视觉骨干网络，从而实现更有效的策略训练。该算法能够实现端到端图像导航和直接速度控制，无需外部定位。此外，还集成了一个基于深度的方法进行实时避障，使无人机能够在混乱的环境中安全导航。

Result: 该方法实现了端到端图像导航和直接速度控制，无需外部定位，并通过集成基于深度的方法进行实时避障，使无人机能够在混乱的环境中安全导航。

Conclusion: 该框架能够实现自主探索、避障和图像目标搜索等全面的导航行为，而无需显式的全局地图。

Abstract: Image-goal navigation (ImageNav) tasks a robot with autonomously exploring an
unknown environment and reaching a location that visually matches a given
target image. While prior works primarily study ImageNav for ground robots,
enabling this capability for autonomous drones is substantially more
challenging due to their need for high-frequency feedback control and global
localization for stable flight. In this paper, we propose a novel sim-to-real
framework that leverages visual reinforcement learning (RL) to achieve ImageNav
for drones. To enhance visual representation ability, our approach trains the
vision backbone with auxiliary tasks, including image perturbations and future
transition prediction, which results in more effective policy training. The
proposed algorithm enables end-to-end ImageNav with direct velocity control,
eliminating the need for external localization. Furthermore, we integrate a
depth-based safety module for real-time obstacle avoidance, allowing the drone
to safely navigate in cluttered environments. Unlike most existing drone
navigation methods that focus solely on reference tracking or obstacle
avoidance, our framework supports comprehensive navigation
behaviors--autonomous exploration, obstacle avoidance, and image-goal
seeking--without requiring explicit global mapping. Code and model checkpoints
will be released upon acceptance.

</details>


### [422] [PUB: A Plasma-Propelled Ultra-Quiet Blimp with Two-DOF Vector Thrusting](https://arxiv.org/abs/2508.12395)
*Zihan Wang*

Main category: cs.RO

TL;DR: 本研究提出了一种名为PUB的新型超静音飞行器，它使用等离子体推进技术，无需机械螺旋桨即可实现超静音飞行和高机动性，适用于噪音敏感、封闭及近太空等场景。


<details>
  <summary>Details</summary>
Motivation: 为了研发一种无机械螺旋桨、超静音飞行的新型飞行器，本研究提出了等离子体推进超静音飞艇（PUB）的设计与控制方案。

Method: 本研究设计并实现了等离子体推进超静音飞艇（PUB），采用氦气升力平台和四层环形非对称电容器产生离子风推力，并通过两自由度（DOF）头部实现推力矢量控制，同时采用了闭环滑模控制方案以实现稳定操控。

Result: 飞行实验验证了PUB的全包线飞行能力，证明了等离子体矢量推进、两自由度矢量控制和控制系统的稳定性。

Conclusion: 该等离子体推进超静音飞艇（PUB）设计合理，控制可行，能够实现全包线飞行（起飞、爬升、悬停、下降和平稳着陆），证明了等离子体矢量推进的可行性、二维度自由度（DOF）矢量控制的有效性以及控制系统的稳定性。

Abstract: This study presents the design and control of a Plasma-propelled
Ultra-silence Blimp (PUB), a novel aerial robot employing plasma vector
propulsion for ultra-quiet flight without mechanical propellers. The system
utilizes a helium-lift platform for extended endurance and a four-layer ring
asymmetric capacitor to generate ionic wind thrust. The modular propulsion
units allow flexible configuration to meet mission-specific requirements, while
a two-degree-of-freedom (DOF) head enables thrust vector control. A closed-loop
slip control scheme is implemented for stable maneuvering. Flight experiments
demonstrate full-envelope capability, including take-off, climb, hover,
descent, and smooth landing, confirming the feasibility of plasma vector
propulsion, the effectiveness of DOF vector control, and the stability of the
control system. Owing to its low acoustic signature, structural simplicity, and
high maneuverability, PUB is well suited for noise-sensitive, enclosed, and
near-space applications.

</details>


### [423] [Tactile Gesture Recognition with Built-in Joint Sensors for Industrial Robots](https://arxiv.org/abs/2508.12435)
*Deqing Song,Weimin Yang,Maryam Rezayati,Hans Wernher van de Venn*

Main category: cs.RO

TL;DR: 本研究提出了一种仅使用机器人内置关节传感器进行手势识别的方法，无需外部传感器。通过使用频谱图表示和 CNN 模型，在 Franka Emika 机器人上实现了超过 95% 的准确率，证明了该方法的有效性和潜力。


<details>
  <summary>Details</summary>
Motivation: 在机器人与视觉或机器人皮肤的本体感觉识别是一个活跃的 HRC 研究领域，但本研究旨在探索仅使用机器人内置关节传感器的深度学习方法，以消除对外部传感器的需求。

Method: 本研究探索了仅依赖机器人内置关节传感器的深度学习方法，评估了各种卷积神经网络（CNN）架构，并收集了两个数据集来研究数据表示和模型架构对识别精度的影响。

Result: 研究结果表明，基于频谱图的表示可显著提高识别精度，而模型架构的作用相对较小。研究还测试了模型对新机器人姿态的泛化能力，其中基于频谱图的模型表现更优。在 Franka Emika 研究机器人上实现的 STFT2DCNN 和 STT3DCNN 方法在接触检测和姿态分类方面达到了超过 95% 的准确率。

Conclusion: 该研究证明了不使用外部传感器进行本体感觉识别的可行性，并促进了未来在人机协作（HRC）领域开发成本效益高、可扩展的解决方案的研究。

Abstract: While gesture recognition using vision or robot skins is an active research
area in Human-Robot Collaboration (HRC), this paper explores deep learning
methods relying solely on a robot's built-in joint sensors, eliminating the
need for external sensors. We evaluated various convolutional neural network
(CNN) architectures and collected two datasets to study the impact of data
representation and model architecture on the recognition accuracy. Our results
show that spectrogram-based representations significantly improve accuracy,
while model architecture plays a smaller role. We also tested generalization to
new robot poses, where spectrogram-based models performed better. Implemented
on a Franka Emika Research robot, two of our methods, STFT2DCNN and STT3DCNN,
achieved over 95% accuracy in contact detection and gesture classification.
These findings demonstrate the feasibility of external-sensor-free tactile
recognition and promote further research toward cost-effective, scalable
solutions for HRC.

</details>


### [424] [Geodesic Tracing-Based Kinematic Integration of Rolling and Sliding Contact on Manifold Meshes for Dexterous In-Hand Manipulation](https://arxiv.org/abs/2508.12439)
*Sunyu Wang,Arjun S. Lakshmipathy,Jean Oh,Nancy S. Pollard*

Main category: cs.RO

TL;DR: 该研究提出了一种新的滚动- 滑动接触建模方法，可以直接在流形网格上进行操作，提高了机器人操纵的准确性和精确性。


<details>
  <summary>Details</summary>
Motivation: 现有关于滚动- 滑动接触的研究主要集中在具有可微分参数化的连续形状，而忽略了具有高保真离散表示的流形网格。

Method: 该方法基于测地线追踪，可以直接在网格上对滚动- 滑动接触进行一阶时间积分。

Result: 使用该方法，研究人员在模拟中规划了一个多指机器人手操纵五个物体的灵巧运动，并在准确性和精确性方面优于基线方法。

Conclusion: 这项工作将滚动-滑动接触建模扩展到了流形网格，并提出了一个基于测地线追踪的积分方案，可以直接在网格上对滚动- 滑动接触进行一阶时间积分。

Abstract: Reasoning about rolling and sliding contact, or roll-slide contact for short,
is critical for dexterous manipulation tasks that involve intricate geometries.
But existing works on roll-slide contact mostly focus on continuous shapes with
differentiable parametrizations. This work extends roll-slide contact modeling
to manifold meshes. Specifically, we present an integration scheme based on
geodesic tracing to first-order time-integrate roll-slide contact directly on
meshes, enabling dexterous manipulation to reason over high-fidelity discrete
representations of an object's true geometry. Using our method, we planned
dexterous motions of a multi-finger robotic hand manipulating five objects
in-hand in simulation. The planning was achieved with a least-squares optimizer
that strives to maintain the most stable instantaneous grasp by minimizing
contact sliding and spinning. Then, we evaluated our method against a baseline
using collision detection and a baseline using primitive shapes. The results
show that our method performed the best in accuracy and precision, even for
coarse meshes. We conclude with a future work discussion on incorporating
multiple contacts and contact forces to achieve accurate and robust mesh-based
surface contact modeling.

</details>


### [425] [Autonomous Oil Spill Response Through Liquid Neural Trajectory Modeling and Coordinated Marine Robotics](https://arxiv.org/abs/2508.12456)
*Hadas C. Kuzmenko,David Ehevich,Oren Gal*

Main category: cs.RO

TL;DR: 海洋溢油管理：通过结合多智能体机器人和液态时间常数神经网络，实现对溢油轨迹的实时高精度预测和动态跟踪，并提高响应协调能力。


<details>
  <summary>Details</summary>
Motivation: 海洋溢油对海洋生态系统、海岸线和相关产业构成严重的环境和经济风险。由于风、洋流和温度等因素的相互作用，预测和管理溢油轨迹非常复杂，导致及时有效的响应具有挑战性。因此，需要精确的实时轨迹预测和协调的缓解措施来最大限度地减少这些灾难的影响。

Method: 提出了一种结合了基于MOOS-IvP平台的、多智能体集群机器人系统和液态时间常数神经网络（LTCNs）的综合框架。该系统融合了自适应机器学习和自主海洋机器人技术，能够对不断变化的溢油进行实时预测、动态跟踪和快速响应。通过利用LTCNs（适用于模拟复杂、时间依赖过程）和集群智能（实现机器人代理之间的去中心化、可扩展和有弹性的决策），提高了监测和遏制效率。

Result: 在深水地平线溢油数据验证中，LTC-RK4模型达到了0.96的空间精度，比LSTM方法提高了23%。该框架在预测精度、灵活性和操作可扩展性方面取得了显著的改进。

Conclusion: 本研究整合了多智能体集群机器人系统和液态时间常数神经网络（LTCNs），实现了对海洋溢油轨迹的实时高精度预测和动态跟踪，并通过集群智能实现了去中心化、可扩展和有弹性的决策，提高了集体监测和遏制能力。该方法在深水长油公司的溢油数据验证中，LTC-RK4模型达到了0.96的空间精度，比LSTM方法提高了23%，显著提高了预测精度、灵活性和操作可扩展性，推动了可持续、自主溢油管理和环境保护的进展。

Abstract: Marine oil spills pose grave environmental and economic risks, threatening
marine ecosystems, coastlines, and dependent industries. Predicting and
managing oil spill trajectories is highly complex, due to the interplay of
physical, chemical, and environmental factors such as wind, currents, and
temperature, which makes timely and effective response challenging. Accurate
real-time trajectory forecasting and coordinated mitigation are vital for
minimizing the impact of these disasters. This study introduces an integrated
framework combining a multi-agent swarm robotics system built on the MOOS-IvP
platform with Liquid Time-Constant Neural Networks (LTCNs). The proposed system
fuses adaptive machine learning with autonomous marine robotics, enabling
real-time prediction, dynamic tracking, and rapid response to evolving oil
spills. By leveraging LTCNs--well-suited for modeling complex, time-dependent
processes--the framework achieves real-time, high-accuracy forecasts of spill
movement. Swarm intelligence enables decentralized, scalable, and resilient
decision-making among robot agents, enhancing collective monitoring and
containment efforts. Our approach was validated using data from the Deepwater
Horizon spill, where the LTC-RK4 model achieved 0.96 spatial accuracy,
surpassing LSTM approaches by 23%. The integration of advanced neural modeling
with autonomous, coordinated robotics demonstrates substantial improvements in
prediction precision, flexibility, and operational scalability. Ultimately,
this research advances the state-of-the-art for sustainable, autonomous oil
spill management and environmental protection by enhancing both trajectory
prediction and response coordination.

</details>


### [426] [Mechanical Automation with Vision: A Design for Rubik's Cube Solver](https://arxiv.org/abs/2508.12469)
*Abhinav Chalise,Nimesh Gopal Pradhan,Nishan Khanal,Prashant Raj Bista,Dinesh Baniya Kshatri*

Main category: cs.RO

TL;DR: A Rubik's Cube solving robot was built using stepper motors, a camera with YOLOv8 for state detection, and Kociemba's algorithm for the solution. It solves the cube in about 2.2 minutes.


<details>
  <summary>Details</summary>
Motivation: The paper describes the development of a robotic system capable of solving a Rubik's Cube, focusing on the integration of hardware and software components for automated manipulation and solution finding.

Method: The system utilizes three stepper motors for physical manipulation, a microcontroller for hardware control, and a camera with a YOLOv8 detection model for real-time cube state detection. A Unity-based GUI visualizes the cube's initial state. The Kociemba's algorithm is employed to find the solution, and the stepper motors execute the moves.

Result: The YOLOv8 model achieved high precision (0.98443) and recall (0.98419) in detecting the cube's state. The system's average solving time is approximately 2.2 minutes.

Conclusion: The system successfully solves the Rubik's Cube using a combination of hardware (stepper motors, microcontroller, camera) and software (YOLOv8 detection, Unity GUI, Kociemba's algorithm), achieving an average solving time of approximately 2.2 minutes.

Abstract: The core mechanical system is built around three stepper motors for physical
manipulation, a microcontroller for hardware control, a camera and YOLO
detection model for real-time cube state detection. A significant software
component is the development of a user-friendly graphical user interface (GUI)
designed in Unity. The initial state after detection from real-time YOLOv8
model (Precision 0.98443, Recall 0.98419, Box Loss 0.42051, Class Loss 0.2611)
is virtualized on GUI. To get the solution, the system employs the Kociemba's
algorithm while physical manipulation with a single degree of freedom is done
by combination of stepper motors' interaction with the cube achieving the
average solving time of ~2.2 minutes.

</details>


### [427] [PROD: Palpative Reconstruction of Deformable Objects through Elastostatic Signed Distance Functions](https://arxiv.org/abs/2508.12554)
*Hamza El-Kebir*

Main category: cs.RO

TL;DR: PROD是一种利用弹性和静力学的符号距离函数（SDF）来重建可变形物体的形状和力学性质的新方法，它通过触觉交互（力控制的表面探测）来估计软材料的静态和动态响应。


<details>
  <summary>Details</summary>
Motivation: 与依赖纯粹几何或视觉数据的传统方法不同，PROD整合了触觉交互——通过力控制的表面探测来测量——以估计软材料的静态和动态响应。

Method: PROD方法将物体的形变建模为一个静弹性过程，并推导出一个控制泊松方程，用于从稀疏的姿态和力测量中估计其SDF。通过结合稳态弹体动力学假设，证明了可以从变形的观测中恢复出未变形的SDF，并具有可证明的收敛性。

Result: PROD方法在处理模拟软体交互中的姿态误差、非正压力应用和曲率误差方面表现出鲁棒性。

Conclusion: PROD方法能够从稀疏的姿态和力测量中恢复出物体未变形时的SDF，并能通过分析位移对不同力输入的响应来估计材料刚度。该方法能够处理模拟软体交互中的姿态误差、非正压力应用和曲率误差。

Abstract: We introduce PROD (Palpative Reconstruction of Deformables), a novel method
for reconstructing the shape and mechanical properties of deformable objects
using elastostatic signed distance functions (SDFs). Unlike traditional
approaches that rely on purely geometric or visual data, PROD integrates
palpative interaction -- measured through force-controlled surface probing --
to estimate both the static and dynamic response of soft materials. We model
the deformation of an object as an elastostatic process and derive a governing
Poisson equation for estimating its SDF from a sparse set of pose and force
measurements. By incorporating steady-state elastodynamic assumptions, we show
that the undeformed SDF can be recovered from deformed observations with
provable convergence. Our approach also enables the estimation of material
stiffness by analyzing displacement responses to varying force inputs. We
demonstrate the robustness of PROD in handling pose errors, non-normal force
application, and curvature errors in simulated soft body interactions. These
capabilities make PROD a powerful tool for reconstructing deformable objects in
applications ranging from robotic manipulation to medical imaging and haptic
feedback systems.

</details>


### [428] [MCTR: Midpoint Corrected Triangulation for Autonomous Racing via Digital Twin Simulation in CARLA](https://arxiv.org/abs/2508.12729)
*Junhao Ye,Cheng Hu,Yiqin Wang,Weizhan Huang,Nicolas Baumann,Jie He,Meixun Qu,Lei Xie,Hongye Su*

Main category: cs.RO

TL;DR: MCTR算法改进了自动驾驶赛车中的轨迹规划，通过曲率校正移动平均提高了平滑度，并使用CARLA模拟器和3D LiDAR进行了验证，解决了现有方法的不足。


<details>
  <summary>Details</summary>
Motivation: 为了解决DTR算法生成的轨迹不平滑以及F1TENTH模拟器缺乏3D LiDAR感知支持的问题，提出MCTR算法。

Method: MCTR算法，结合了曲率校正移动平均（Curvature Corrected Moving Average）来优化轨迹平滑度，并利用CARLA模拟器中的数字孪生系统进行3D LiDAR感知的鲁棒性验证。

Result: MCTR算法在轨迹平滑度方面有所提升，并通过在CARLA模拟器中的3D LiDAR感知环境下进行了鲁棒性验证，同时在模拟和真实世界车辆实验中得到了证实。

Conclusion: MCTR算法通过使用曲率校正移动平均来提高轨迹平滑度，并在CARLA模拟器中实现了数字孪生系统，以在3D LiDAR感知下验证算法的鲁棒性。该算法已通过模拟和真实车辆实验进行了全面验证。

Abstract: In autonomous racing, reactive controllers eliminate the computational burden
of the full See-Think-Act autonomy stack by directly mapping sensor inputs to
control actions. This bypasses the need for explicit localization and
trajectory planning. A widely adopted baseline in this category is the
Follow-The-Gap method, which performs trajectory planning using LiDAR data.
Building on FTG, the Delaunay Triangulation-based Racing algorithm introduces
further enhancements. However, DTR's use of circumcircles for trajectory
generation often results in insufficiently smooth paths, ultimately degrading
performance. Additionally, the commonly used F1TENTH-simulator for autonomous
racing competitions lacks support for 3D LiDAR perception, limiting its
effectiveness in realistic testing. To address these challenges, this work
proposes the MCTR algorithm. MCTR improves trajectory smoothness through the
use of Curvature Corrected Moving Average and implements a digital twin system
within the CARLA simulator to validate the algorithm's robustness under 3D
LiDAR perception. The proposed algorithm has been thoroughly validated through
both simulation and real-world vehicle experiments.

</details>


### [429] [Temporal and Rotational Calibration for Event-Centric Multi-Sensor Systems](https://arxiv.org/abs/2508.12564)
*Jiayao Mai,Xiuyuan Lu,Kuan Dai,Shaojie Shen,Yi Zhou*

Main category: cs.RO

TL;DR: 该研究提出了一种新颖的运动驱动标定框架，用于事件相机与其它传感器进行多传感器融合。该方法无需依赖传统的标定目标，而是通过分析事件相机和其它传感器在运动过程中的数据关联性来精确估计它们之间的时间偏移和相对旋转关系。实验结果表明，该方法在精度和稳定性方面均表现出色，为事件相机在多传感器系统中的应用提供了有力的支持。


<details>
  <summary>Details</summary>
Motivation: 事件相机作为一种能够生成像素级亮度变化异步信号的传感器，具有理论上微秒级的延迟，能够显著提升多传感器系统的性能。然而，涉及事件相机的外参标定问题仍是一个研究不足的领域。

Method: 提出了一种基于运动的事件相机时间与旋转标定框架，无需标定目标。该方法利用事件相机和其他传感器估计的旋转运动信息作为输入，通过对事件数据时空分布的法向流观测来估计角速度。标定流程采用两步法：首先利用类似典型相关分析（CCA）的运动学相关性来初始化时间偏移和旋转外参，然后在SO(3)中使用连续时间参数化进行联合非线性优化，以优化时间和旋转参数。

Result: 在公开和自收集的数据集上进行的广泛评估表明，该方法在标定精度上可与基于目标的方法相媲美，并且比纯CCA方法更稳定，同时具有高精度、鲁棒性和灵活性。

Conclusion: 所提出的方法实现了与基于目标的标定方法相媲美的标定精度，同时表现出优于纯基于CCA的方法的稳定性，并突出了其精度、鲁棒性和灵活性。

Abstract: Event cameras generate asynchronous signals in response to pixel-level
brightness changes, offering a sensing paradigm with theoretically
microsecond-scale latency that can significantly enhance the performance of
multi-sensor systems. Extrinsic calibration is a critical prerequisite for
effective sensor fusion; however, the configuration that involves event cameras
remains an understudied topic. In this paper, we propose a motion-based
temporal and rotational calibration framework tailored for event-centric
multi-sensor systems, eliminating the need for dedicated calibration targets.
Our method uses as input the rotational motion estimates obtained from event
cameras and other heterogeneous sensors, respectively. Different from
conventional approaches that rely on event-to-frame conversion, our method
efficiently estimates angular velocity from normal flow observations, which are
derived from the spatio-temporal profile of event data. The overall calibration
pipeline adopts a two-step approach: it first initializes the temporal offset
and rotational extrinsics by exploiting kinematic correlations in the spirit of
Canonical Correlation Analysis (CCA), and then refines both temporal and
rotational parameters through a joint non-linear optimization using a
continuous-time parametrization in SO(3). Extensive evaluations on both
publicly available and self-collected datasets validate that the proposed
method achieves calibration accuracy comparable to target-based methods, while
exhibiting superior stability over purely CCA-based methods, and highlighting
its precision, robustness and flexibility. To facilitate future research, our
implementation will be made open-source. Code:
https://github.com/NAIL-HNU/EvMultiCalib.

</details>


### [430] [Adaptive Model-Predictive Control of a Soft Continuum Robot Using a Physics-Informed Neural Network Based on Cosserat Rod Theory](https://arxiv.org/abs/2508.12681)
*Johann Licher,Max Bartholdt,Henrik Krauss,Tim-Lukas Habich,Thomas Seel,Moritz Schappler*

Main category: cs.RO

TL;DR: 本研究提出了一种新的控制框架，使用一种特殊的神经网络（DD-PINN）来模拟软连续机器人的动态行为，并结合MPC技术，实现了实时、高精度的控制，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 软连续机器人（SCRs）的动态控制因其高计算需求而具有挑战性。现有的数据驱动方法（如Koopman算子方法）缺乏适应性且无法捕捉机器人完整形状。因此，需要一种能够实时运行、适应性强且能精确建模机器人动力学的控制方法。

Method: 本研究提出了一种基于域解耦的物理信息神经网络（DD-PINN）的非线性模型预测控制（MPC）框架，并结合了无迹卡尔曼滤波器（UKF）来估计模型状态和弯曲柔度。DD-PINN作为物理信息的代理模型，实现了44000倍的加速。该框架能够在GPU上以70 Hz的频率运行，用于控制软连续机器人。

Result: 在模拟中，该控制器实现了精确的动态轨迹跟踪和设定点控制，末端执行器位置误差低于3毫米（占致动器长度的2.3%）。在实际实验中，该控制器达到了相似的精度，并且能够实现高达3.55 m/s²的加速度。

Conclusion: 该研究提出的基于域解耦的物理信息神经网络（DD-PINN）的非线性模型预测控制（MPC）框架，为软连续机器人（SCRs）在实时性和准确性方面提供了有效的解决方案。

Abstract: Dynamic control of soft continuum robots (SCRs) holds great potential for
expanding their applications, but remains a challenging problem due to the high
computational demands of accurate dynamic models. While data-driven approaches
like Koopman-operator-based methods have been proposed, they typically lack
adaptability and cannot capture the full robot shape, limiting their
applicability. This work introduces a real-time-capable nonlinear
model-predictive control (MPC) framework for SCRs based on a domain-decoupled
physics-informed neural network (DD-PINN) with adaptable bending stiffness. The
DD-PINN serves as a surrogate for the dynamic Cosserat rod model with a
speed-up factor of 44000. It is also used within an unscented Kalman filter for
estimating the model states and bending compliance from end-effector position
measurements. We implement a nonlinear evolutionary MPC running at 70 Hz on the
GPU. In simulation, it demonstrates accurate tracking of dynamic trajectories
and setpoint control with end-effector position errors below 3 mm (2.3% of the
actuator's length). In real-world experiments, the controller achieves similar
accuracy and accelerations up to 3.55 m/s2.

</details>


### [431] [Manipulate-to-Navigate: Reinforcement Learning with Visual Affordances and Manipulability Priors](https://arxiv.org/abs/2508.13151)
*Yuying Zhang,Joni Pajarinen*

Main category: cs.RO

TL;DR: 提出了一种基于强化学习的方法，用于解决动态环境中的移动操纵问题，通过学习操纵动作来清除障碍物，以便进行导航。该方法在模拟和真实机器人上都取得了成功。


<details>
  <summary>Details</summary>
Motivation: 解决移动操纵在动态环境中导航的挑战，特别是当需要移除障碍物以便移动时。

Method: 提出了一种基于强化学习的方法，结合了可操作性先验和可供性地图，用于学习促进后续导航的操纵动作。

Result: 在模拟任务（Reach 和 Door）中，该方法有效地学习了操纵策略，并且成功地将学习到的策略转移到了真实的波士顿动力Spot机器人上，以完成Reach任务。

Conclusion: 该方法使机器人能够有效地与动态环境进行交互和穿越。

Abstract: Mobile manipulation in dynamic environments is challenging due to movable
obstacles blocking the robot's path. Traditional methods, which treat
navigation and manipulation as separate tasks, often fail in such
'manipulate-to-navigate' scenarios, as obstacles must be removed before
navigation. In these cases, active interaction with the environment is required
to clear obstacles while ensuring sufficient space for movement. To address the
manipulate-to-navigate problem, we propose a reinforcement learning-based
approach for learning manipulation actions that facilitate subsequent
navigation. Our method combines manipulability priors to focus the robot on
high manipulability body positions with affordance maps for selecting
high-quality manipulation actions. By focusing on feasible and meaningful
actions, our approach reduces unnecessary exploration and allows the robot to
learn manipulation strategies more effectively. We present two new
manipulate-to-navigate simulation tasks called Reach and Door with the Boston
Dynamics Spot robot. The first task tests whether the robot can select a good
hand position in the target area such that the robot base can move effectively
forward while keeping the end effector position fixed. The second task requires
the robot to move a door aside in order to clear the navigation path. Both of
these tasks need first manipulation and then navigating the base forward.
Results show that our method allows a robot to effectively interact with and
traverse dynamic environments. Finally, we transfer the learned policy to a
real Boston Dynamics Spot robot, which successfully performs the Reach task.

</details>


### [432] [RoboRetriever: Single-Camera Robot Object Retrieval via Active and Interactive Perception with Dynamic Scene Graph](https://arxiv.org/abs/2508.12916)
*Hecheng Wang,Jiankun Ren,Jia Yu,Lizhe Qi,Yunquan Sun*

Main category: cs.RO

TL;DR: RoboRetriever是一个仅用一个RGB-D摄像头就能在杂乱环境中进行物体检索的系统，它使用动态分层场景图和先进的视觉-语言模型来实现主动感知和操作。


<details>
  <summary>Details</summary>
Motivation: 与依赖昂贵且固定的多摄像头设置的现有机器人系统相比，RoboRetriever旨在实现更灵活、低成本的物体检索，仅使用单个摄像头，就像人类一样。

Method: RoboRetriever框架使用单个腕部安装的RGB-D摄像头和自然语言指令，通过构建和更新动态分层场景图来编码物体语义、几何和时序关系。它结合了主动感知、交互感知和操作，并引入了一种新的视觉提示方案，利用大型推理视觉-语言模型来确定与语义任务目标和几何场景上下文对齐的6-DoF摄像头姿态。

Result: 在真实的、杂乱的环境中，RoboRetaring在物体检索任务上表现良好，即使在有人类干预的情况下也能保持稳定。

Conclusion: RoboRetriever框架在只有一个RGB-D摄像头的情况下，在各种真实世界的物体检索任务中表现出了很强的适应性和鲁棒性，包括有人类干预的场景。

Abstract: Humans effortlessly retrieve objects in cluttered, partially observable
environments by combining visual reasoning, active viewpoint adjustment, and
physical interaction-with only a single pair of eyes. In contrast, most
existing robotic systems rely on carefully positioned fixed or multi-camera
setups with complete scene visibility, which limits adaptability and incurs
high hardware costs. We present \textbf{RoboRetriever}, a novel framework for
real-world object retrieval that operates using only a \textbf{single}
wrist-mounted RGB-D camera and free-form natural language instructions.
RoboRetriever grounds visual observations to build and update a \textbf{dynamic
hierarchical scene graph} that encodes object semantics, geometry, and
inter-object relations over time. The supervisor module reasons over this
memory and task instruction to infer the target object and coordinate an
integrated action module combining \textbf{active perception},
\textbf{interactive perception}, and \textbf{manipulation}. To enable
task-aware scene-grounded active perception, we introduce a novel visual
prompting scheme that leverages large reasoning vision-language models to
determine 6-DoF camera poses aligned with the semantic task goal and geometry
scene context. We evaluate RoboRetriever on diverse real-world object retrieval
tasks, including scenarios with human intervention, demonstrating strong
adaptability and robustness in cluttered scenes with only one RGB-D camera.

</details>


### [433] [Deformation of the panoramic sphere into an ellipsoid to induce self-motion in telepresence users](https://arxiv.org/abs/2508.12925)
*Eetu Laukka,Evan G. Center,Timo Ojala,Steven M. LaValle,Matti Pouke*

Main category: cs.RO

TL;DR: 该研究提出了一种利用光学流动来创造自我运动错觉的方法，以解决遥在机器人延迟问题，但在500毫秒延迟下并未提高性能，反而可能增加VR疾病。


<details>
  <summary>Details</summary>
Motivation: 为了解决高延迟系统（如使用360度摄像头通过互联网传输的移动遥在系统）难以实时控制的问题。

Method: 利用光学流动来在用户发送运动指令到通过360度摄像头流观察到实际运动的延迟期间，为用户创造一种自我运动的错觉。

Result: 在500毫秒的延迟下，使用自我运动错觉并没有在任务完成时间和与物体碰撞方面带来显著的性能或准确性提升。有证据表明该方法可能会通过模拟器疾病问卷（SSQ）测量出的虚拟现实（VR）疾病有所增加。

Conclusion: 需要进一步调整才能使该方法可行

Abstract: Mobile telepresence robots allow users to feel present and explore remote
environments using technology. Traditionally, these systems are implemented
using a camera onboard a mobile robot that can be controlled. Although
high-immersion technologies, such as 360-degree cameras, can increase
situational awareness and presence, they also introduce significant challenges.
Additional processing and bandwidth requirements often result in latencies of
up to seconds. The current delay with a 360-degree camera streaming over the
internet makes real-time control of these systems difficult. Working with
high-latency systems requires some form of assistance to the users.
  This study presents a novel way to utilize optical flow to create an illusion
of self-motion to the user during the latency period between user sending
motion commands to the robot and seeing the actual motion through the
360-camera stream. We find no significant benefit of using the self-motion
illusion to performance or accuracy of controlling a telepresence robot with a
latency of 500 ms, as measured by the task completion time and collisions into
objects. Some evidence is shown that the method might increase virtual reality
(VR) sickness, as measured by the simulator sickness questionnaire (SSQ). We
conclude that further adjustments are necessary in order to render the method
viable.

</details>


### [434] [Simultaneous Contact Sequence and Patch Planning for Dynamic Locomotion](https://arxiv.org/abs/2508.12928)
*Victor Dhédin,Haizhou Zhao,Majid Khadiv*

Main category: cs.RO

TL;DR: 该研究提出了一种新的方法，结合了MCTS和轨迹优化，实现了四足机器人在复杂环境下的运动规划，并成功应用于真实机器人。


<details>
  <summary>Details</summary>
Motivation: 腿式机器人在高度约束的环境中具有敏捷机动的潜力，但规划这些运动需要解决一个混合了连续和离散决策变量的极具挑战性的优化问题。

Method: 提出了一种基于蒙特卡洛树搜索（MCTS）和全身轨迹优化（TO）的完整流程，用于在极具挑战性的环境中执行同步接触序列和贴片选择。

Result: 该框架能够快速找到多种动态一致的规划，并且这些规划可以迁移到真实的四足机器人上。该框架还可以找到高度复杂的人类非循环机动。

Conclusion: 该框架首次实现了在非循环多接触运动中使用四足机器人的全身动力学进行同步接触序列和贴片选择。

Abstract: Legged robots have the potential to traverse highly constrained environments
with agile maneuvers. However, planning such motions requires solving a highly
challenging optimization problem with a mixture of continuous and discrete
decision variables. In this paper, we present a full pipeline based on
Monte-Carlo tree search (MCTS) and whole-body trajectory optimization (TO) to
perform simultaneous contact sequence and patch selection on highly challenging
environments. Through extensive simulation experiments, we show that our
framework can quickly find a diverse set of dynamically consistent plans. We
experimentally show that these plans are transferable to a real quadruped
robot. We further show that the same framework can find highly complex acyclic
humanoid maneuvers. To the best of our knowledge, this is the first
demonstration of simultaneous contact sequence and patch selection for acyclic
multi-contact locomotion using the whole-body dynamics of a quadruped.

</details>


### [435] [Insights from Interviews with Teachers and Students on the Use of a Social Robot in Computer Science Class in Sixth Grade](https://arxiv.org/abs/2508.12946)
*Ann-Sophie Schenk,Stefan Schiffer,Heqiu Song*

Main category: cs.RO

TL;DR: 在本研究中，我们访谈了六年级计算机科学课上的教师和学生，以了解他们对使用社交机器人的看法和需求。结果显示，尽管师生双方都对在课堂上使用机器人持积极态度，但他们对机器人的具体需求却不尽相同，这为设计带来了挑战。


<details>
  <summary>Details</summary>
Motivation: 了解教师和学生对于机器人在课堂上使用及其功能的需求和看法。

Method: 通过对教师和学生进行访谈，了解在计算机科学课上使用社交机器人的需求和潜在应用。

Result: 研究结果表明，教师和学生都对在课堂上使用机器人持非常开放的态度，但他们之间在具体需求上存在一定的差异。

Conclusion: 教师和学生都对在课堂上使用机器人持开放态度，但他们对机器人的需求和期望存在差异，这带来了复杂的设计挑战。

Abstract: In this paper we report on first insights from interviews with teachers and
students on using social robots in computer science class in sixth grade. Our
focus is on learning about requirements and potential applications. We are
particularly interested in getting both perspectives, the teachers' and the
learners' view on how robots could be used and what features they should or
should not have. Results show that teachers as well as students are very open
to robots in the classroom. However, requirements are partially quite
heterogeneous among the groups. This leads to complex design challenges which
we discuss at the end of this paper.

</details>


### [436] [Scaling Whole-body Multi-contact Manipulation with Contact Optimization](https://arxiv.org/abs/2508.12980)
*Victor Levé,João Moura,Sachiya Fujita,Tamon Miyake,Steve Tonneau,Sethu Vijayakumar*

Main category: cs.RO

TL;DR: 通过新的表面表示和成本设计，机器人全身操作规划效率提升77%，并成功应用于真实机器人实验。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人全身操作规划方法在处理连续接触表面时存在可扩展性问题，因为它们主要依赖于离散采样。梯度优化是一种更合适的方法，但缺乏有效的机器人表面表示。

Method: 提出了一种机器人和物体表面的表示方法，能够进行邻近点的闭式计算，并设计了一种能够有效指导机器人全身操作规划的成本。

Result: 提出的框架在机器人全身操作规划方面取得了77%的改进，并成功地在真实硬件上进行了盒子操作的实验验证。

Conclusion: 提出了一种新的表示方法和成本设计，能够有效地指导机器人全身操作规划，解决了现有方法无法解决的问题，并在规划时间上比现有技术提高了77%，同时在真实硬件上通过人形机器人对盒子的全身操作进行了验证。

Abstract: Daily tasks require us to use our whole body to manipulate objects, for
instance when our hands are unavailable. We consider the issue of providing
humanoid robots with the ability to autonomously perform similar whole-body
manipulation tasks. In this context, the infinite possibilities for where and
how contact can occur on the robot and object surfaces hinder the scalability
of existing planning methods, which predominantly rely on discrete sampling.
Given the continuous nature of contact surfaces, gradient-based optimization
offers a more suitable approach for finding solutions. However, a key remaining
challenge is the lack of an efficient representation of robot surfaces. In this
work, we propose (i) a representation of robot and object surfaces that enables
closed-form computation of proximity points, and (ii) a cost design that
effectively guides whole-body manipulation planning. Our experiments
demonstrate that the proposed framework can solve problems unaddressed by
existing methods, and achieves a 77% improvement in planning time over the
state of the art. We also validate the suitability of our approach on real
hardware through the whole-body manipulation of boxes by a humanoid robot.

</details>


### [437] [BOW: Bayesian Optimization over Windows for Motion Planning in Complex Environments](https://arxiv.org/abs/2508.13052)
*Sourav Raxit,Abdullah Al Redwan Newaz,Paulo Padrao,Jose Fuentes,Leonardo Bobadilla*

Main category: cs.RO

TL;DR: BOW Planner是一种新的运动规划算法，使用约束贝叶斯优化来高效地处理机器人的动力学约束，在复杂环境中实现快速、安全的轨迹生成。


<details>
  <summary>Details</summary>
Motivation: 传统运动规划方法在处理机器人速度和加速度限制等动力学约束时存在困难，因此需要一种能够高效处理这些约束的规划算法。

Method: BOW Planner使用约束贝叶斯优化（CBO）处理动力学约束，通过在可达速度规划窗口内进行采样来高效地生成轨迹。

Result: 理论分析表明，BOW Planner渐进收敛于近优解。在复杂和受限环境的评估中，与现有技术相比，BOW Planner在计算时间、轨迹长度和求解时间方面有了显著改进，并成功应用于各种现实世界的机器人系统，展示了其在样本效率、安全优化和快速规划方面的实际意义。

Conclusion: BOW Planner在复杂环境中通过约束贝叶斯优化（CBO）实现了可扩展的运动规划，相比传统方法，它能有效处理速度和加速度限制等动力学约束，并通过在可达速度规划窗口内进行采样和利用CBO，能够高效处理高维目标函数和安全约束，从而实现快速、安全的轨迹生成。

Abstract: This paper introduces the BOW Planner, a scalable motion planning algorithm
designed to navigate robots through complex environments using constrained
Bayesian optimization (CBO). Unlike traditional methods, which often struggle
with kinodynamic constraints such as velocity and acceleration limits, the BOW
Planner excels by concentrating on a planning window of reachable velocities
and employing CBO to sample control inputs efficiently. This approach enables
the planner to manage high-dimensional objective functions and stringent safety
constraints with minimal sampling, ensuring rapid and secure trajectory
generation. Theoretical analysis confirms the algorithm's asymptotic
convergence to near-optimal solutions, while extensive evaluations in cluttered
and constrained settings reveal substantial improvements in computation times,
trajectory lengths, and solution times compared to existing techniques.
Successfully deployed across various real-world robotic systems, the BOW
Planner demonstrates its practical significance through exceptional sample
efficiency, safety-aware optimization, and rapid planning capabilities, making
it a valuable tool for advancing robotic applications. The BOW Planner is
released as an open-source package and videos of real-world and simulated
experiments are available at https://bow-web.github.io.

</details>


### [438] [Large VLM-based Vision-Language-Action Models for Robotic Manipulation: A Survey](https://arxiv.org/abs/2508.13073)
*Rui Shao,Wei Li,Lingsen Zhang,Renshan Zhang,Zhiyang Liu,Ran Chen,Liqiang Nie*

Main category: cs.RO

TL;DR: 这是一篇关于大型视觉-语言-动作（VLA）模型在机器人操作领域应用的综述。文章对现有模型进行了分类和总结，并探讨了未来的发展方向。


<details>
  <summary>Details</summary>
Motivation: 传统的基于规则的方法在非结构化、新颖的环境中难以扩展和泛化，而机器人操作需要精确的运动控制和多模态理解。因此，基于大型视觉-语言模型（VLMs）的视觉-语言-动作（VLA）模型成为了解决这一挑战的关键。

Method: 本文首先定义了大型VLM-based VLA模型，并区分了两种主要的架构范式：整体式模型（包括单系统和双系统设计）和层级式模型（将规划与执行解耦）。随后，文章深入探讨了这些模型与强化学习、无训练优化、人类视频学习、世界模型集成等高级领域的结合，以及它们的架构特点、优势、数据集和基准。最后，文章指出了未来有前景的研究方向，如记忆机制、4D感知、高效适应、多智能体协作等。

Result: 本文全面梳理了大型VLM-based VLA模型在机器人操作方面的研究进展，提出了清晰的分类体系，并指明了未来的研究方向，为该领域的研究人员提供了系统的指导和参考。

Conclusion: 本篇论文系统性地回顾了大型视觉-语言-动作（VLA）模型在机器人操作领域的应用，解决了现有分类方法的不一致性，缓解了研究碎片化问题，并通过整合大型VLM和机器人操作交叉领域的研究填补了关键空白。

Abstract: Robotic manipulation, a key frontier in robotics and embodied AI, requires
precise motor control and multimodal understanding, yet traditional rule-based
methods fail to scale or generalize in unstructured, novel environments. In
recent years, Vision-Language-Action (VLA) models, built upon Large
Vision-Language Models (VLMs) pretrained on vast image-text datasets, have
emerged as a transformative paradigm. This survey provides the first
systematic, taxonomy-oriented review of large VLM-based VLA models for robotic
manipulation. We begin by clearly defining large VLM-based VLA models and
delineating two principal architectural paradigms: (1) monolithic models,
encompassing single-system and dual-system designs with differing levels of
integration; and (2) hierarchical models, which explicitly decouple planning
from execution via interpretable intermediate representations. Building on this
foundation, we present an in-depth examination of large VLM-based VLA models:
(1) integration with advanced domains, including reinforcement learning,
training-free optimization, learning from human videos, and world model
integration; (2) synthesis of distinctive characteristics, consolidating
architectural traits, operational strengths, and the datasets and benchmarks
that support their development; (3) identification of promising directions,
including memory mechanisms, 4D perception, efficient adaptation, multi-agent
cooperation, and other emerging capabilities. This survey consolidates recent
advances to resolve inconsistencies in existing taxonomies, mitigate research
fragmentation, and fill a critical gap through the systematic integration of
studies at the intersection of large VLMs and robotic manipulation. We provide
a regularly updated project page to document ongoing progress:
https://github.com/JiuTian-VL/Large-VLM-based-VLA-for-Robotic-Manipulation.

</details>


### [439] [Grounding Actions in Camera Space: Observation-Centric Vision-Language-Action Policy](https://arxiv.org/abs/2508.13103)
*Tianyi Zhang,Haonan Duan,Haoran Hao,Yu Qiao,Jifeng Dai,Zhi Hou*

Main category: cs.RO

TL;DR: OC-VLA框架通过将动作预测与相机观测对齐，解决了VLA模型在真实世界中的泛化和视点不一致问题。


<details>
  <summary>Details</summary>
Motivation: 解决Vision-Language-Action（VLA）模型在真实世界环境中泛化能力不足的问题，消除观测和动作空间之间的差异，以及空间不一致性。

Method: OC-VLA框架将末端执行器姿势从机器人基坐标系转换到相机坐标系，实现动作预测在相机观测空间中的对齐。

Result: OC-VLA在模拟和真实世界的机器人操作任务中，均表现出加速收敛、提高任务成功率和跨视图泛化能力的优势。

Conclusion: OC-VLA通过将动作预测直接置于相机观测空间中，并利用相机的外接校准矩阵将末端执行器姿势从机器人基坐标系转换到相机坐标系，从而统一了跨异构视点的预测目标。该方法轻量级、即插即用，能有效解决VLA模型在真实世界环境中泛化能力不足的问题，提升了模型对相机视点变化的鲁棒性，并加速了收敛，提高了任务成功率和跨视图泛化能力。

Abstract: Vision-Language-Action (VLA) models frequently encounter challenges in
generalizing to real-world environments due to inherent discrepancies between
observation and action spaces. Although training data are collected from
diverse camera perspectives, the models typically predict end-effector poses
within the robot base coordinate frame, resulting in spatial inconsistencies.
To mitigate this limitation, we introduce the Observation-Centric VLA (OC-VLA)
framework, which grounds action predictions directly in the camera observation
space. Leveraging the camera's extrinsic calibration matrix, OC-VLA transforms
end-effector poses from the robot base coordinate system into the camera
coordinate system, thereby unifying prediction targets across heterogeneous
viewpoints. This lightweight, plug-and-play strategy ensures robust alignment
between perception and action, substantially improving model resilience to
camera viewpoint variations. The proposed approach is readily compatible with
existing VLA architectures, requiring no substantial modifications.
Comprehensive evaluations on both simulated and real-world robotic manipulation
tasks demonstrate that OC-VLA accelerates convergence, enhances task success
rates, and improves cross-view generalization. The code will be publicly
available.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [440] [RefAdGen: High-Fidelity Advertising Image Generation](https://arxiv.org/abs/2508.11695)
*Yiyun Chen,Weikai Yang*

Main category: cs.GR

TL;DR: 该研究提出了一种名为 RefAdGen 的新颖框架，用于生成高质量的广告图像。该框架通过创新的数据集构建和解耦设计，解决了现有 AIGC 技术在保真度和效率方面的局限性，并在处理各种产品和真实图像方面取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 现有 AIGC 技术要么需要为每个参考图像进行广泛的微调以实现高保真度，要么难以在不同产品之间保持保真度，这使得它们在电子商务和营销行业中不切实际。为了解决这一限制，研究人员构建了一个名为 AdProd-100K 的大规模广告图像生成数据集，并采用了双数据增强策略来促进对现实和高保真图像合成至关重要的、强大的、3D感知的表示。

Method: 提出了一种名为 RefAdGen 的生成框架，该框架通过解耦设计实现高保真度。该框架通过在 U-Net 输入中注入产品蒙版来强制执行精确的空间控制，并采用高效的注意力融合模块 (AFM) 来集成产品特征，从而解决了现有方法中存在的保真度-效率困境。

Result: RefAdGen 在处理未见过产品和具有挑战性的真实野外图像方面，展示了强大的泛化能力，保持了高保真度和卓越的视觉效果，达到了最先进的性能。

Conclusion: RefAdGen 提供了一种可扩展且经济高效的替代传统工作流程的方法，在保持高保真度和卓越视觉效果方面表现出色，能够处理未见过产品以及具有挑战性的真实野外图像。

Abstract: The rapid advancement of Artificial Intelligence Generated Content (AIGC)
techniques has unlocked opportunities in generating diverse and compelling
advertising images based on referenced product images and textual scene
descriptions. This capability substantially reduces human labor and production
costs in traditional marketing workflows. However, existing AIGC techniques
either demand extensive fine-tuning for each referenced image to achieve high
fidelity, or they struggle to maintain fidelity across diverse products, making
them impractical for e-commerce and marketing industries. To tackle this
limitation, we first construct AdProd-100K, a large-scale advertising image
generation dataset. A key innovation in its construction is our dual data
augmentation strategy, which fosters robust, 3D-aware representations crucial
for realistic and high-fidelity image synthesis. Leveraging this dataset, we
propose RefAdGen, a generation framework that achieves high fidelity through a
decoupled design. The framework enforces precise spatial control by injecting a
product mask at the U-Net input, and employs an efficient Attention Fusion
Module (AFM) to integrate product features. This design effectively resolves
the fidelity-efficiency dilemma present in existing methods. Extensive
experiments demonstrate that RefAdGen achieves state-of-the-art performance,
showcasing robust generalization by maintaining high fidelity and remarkable
visual results for both unseen products and challenging real-world, in-the-wild
images. This offers a scalable and cost-effective alternative to traditional
workflows. Code and datasets are publicly available at
https://github.com/Anonymous-Name-139/RefAdgen.

</details>


### [441] [Substepping the Material Point Method](https://arxiv.org/abs/2508.11722)
*Chenfanfu Jiang*

Main category: cs.GR

TL;DR: A new algorithm allows explicit Material Point Method (MPM) to use large time steps by employing substeps, making it compatible with other large-step solvers and enabling features like constraint imposition and multiphysics coupling.


<details>
  <summary>Details</summary>
Motivation: Large time steps are often desirable for reasons such as partitioned coupling with another large-step solver, or for imposing constraints, projections, or multiphysics solves.

Method: We propose a pseudo-implicit algorithm that uses substeps to advance MPM with large time steps, wrapping an explicit MPM integrator.

Result: This algorithm allows MPM to be advanced with large time steps, which is beneficial for various applications.

Conclusion: We present a simple, plug-and-play algorithm that advances MPM with a large time step using substeps, effectively wrapping an explicit MPM integrator into a pseudo-implicit one.

Abstract: Many Material Point Method implementations favor explicit time integration.
However large time steps are often desirable for special reasons - for example,
for partitioned coupling with another large-step solver, or for imposing
constraints, projections, or multiphysics solves. We present a simple,
plug-and-play algorithm that advances MPM with a large time step using
substeps, effectively wrapping an explicit MPM integrator into a
pseudo-implicit one.

</details>


### [442] [Mesh Processing Non-Meshes via Neural Displacement Fields](https://arxiv.org/abs/2508.12179)
*Yuta Noma,Zhecheng Wang,Chenxi Liu,Karan Singh,Alec Jacobson*

Main category: cs.GR

TL;DR: 提出了一种紧凑的神经场，可处理多种曲面表示，实现快速渲染、轻量传输和高效几何处理。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有网格处理流程难以适应新兴的非网格曲面表示的问题，而这些表示能够实现快速渲染和紧凑的文件大小，但需要代价高昂的网格化或传输笨重的网格，从而抵消了它们在流媒体应用中的核心优势。

Method: 我们学习一个从粗糙网格近似到曲面的神经映射。

Result: 我们提出了一个紧凑的神经场，能够处理各种曲面表示的常见几何处理任务。该方法的完整表示仅占几百千字节，非常适合轻量级传输，并能快速提取流形和 Delaunay 网格以进行内在形状分析，以及压缩标量场以有效传递预计算结果。

Conclusion: 我们的方法快速、紧凑且准确，为交互式几何处理开辟了新的可能性。

Abstract: Mesh processing pipelines are mature, but adapting them to newer non-mesh
surface representations -- which enable fast rendering with compact file size
-- requires costly meshing or transmitting bulky meshes, negating their core
benefits for streaming applications.
  We present a compact neural field that enables common geometry processing
tasks across diverse surface representations. Given an input surface, our
method learns a neural map from its coarse mesh approximation to the surface.
The full representation totals only a few hundred kilobytes, making it ideal
for lightweight transmission. Our method enables fast extraction of manifold
and Delaunay meshes for intrinsic shape analysis, and compresses scalar fields
for efficient delivery of costly precomputed results. Experiments and
applications show that our fast, compact, and accurate approach opens up new
possibilities for interactive geometry processing.

</details>


### [443] [Express4D: Expressive, Friendly, and Extensible 4D Facial Motion Generation Benchmark](https://arxiv.org/abs/2508.12438)
*Yaron Aloni,Rotem Shalev-Arkushin,Yonatan Shafir,Guy Tevet,Ohad Fried,Amit Haim Bermano*

Main category: cs.GR

TL;DR: A new dataset, Express4D, was created using accessible equipment and LLM instructions for nuanced facial expression generation from text. It enables better training of models for tasks like animation and virtual avatars.


<details>
  <summary>Details</summary>
Motivation: Current generative models for facial expressions suffer from datasets that are either speech-driven or have coarse emotion labels, and were captured using expensive equipment. There is a need for datasets with nuanced, expressive descriptions for fine-grained control, easily collectible with commodity equipment.

Method: Collected a new dataset (Express4D) of facial motion sequences using commodity equipment and LLM-generated natural language instructions. The data is in the ARKit blendshape format, featuring nuanced performances and semantic annotations. Trained two baseline models on this dataset for evaluation and benchmarking.

Result: The trained models can learn meaningful text-to-expression motion generation and capture the many-to-many mapping of the two modalities. The dataset, code, and video examples are publicly available.

Conclusion: The Express4D dataset, collected using commodity equipment and LLM-generated instructions, offers nuanced facial motion sequences with semantic annotations in the ARKit blendshape format. Trained baseline models demonstrate the ability to learn text-to-expression motion generation and capture the many-to-many mapping between text and expression.

Abstract: Dynamic facial expression generation from natural language is a crucial task
in Computer Graphics, with applications in Animation, Virtual Avatars, and
Human-Computer Interaction. However, current generative models suffer from
datasets that are either speech-driven or limited to coarse emotion labels,
lacking the nuanced, expressive descriptions needed for fine-grained control,
and were captured using elaborate and expensive equipment. We hence present a
new dataset of facial motion sequences featuring nuanced performances and
semantic annotation. The data is easily collected using commodity equipment and
LLM-generated natural language instructions, in the popular ARKit blendshape
format. This provides riggable motion, rich with expressive performances and
labels. We accordingly train two baseline models, and evaluate their
performance for future benchmarking. Using our Express4D dataset, the trained
models can learn meaningful text-to-expression motion generation and capture
the many-to-many mapping of the two modalities. The dataset, code, and video
examples are available on our webpage: https://jaron1990.github.io/Express4D/

</details>


### [444] [MixCache: Mixture-of-Cache for Video Diffusion Transformer Acceleration](https://arxiv.org/abs/2508.12691)
*Yuanxin Wei,Lansong Diao,Bujiao Chen,Shenggan Cheng,Zhengping Qian,Wenyuan Yu,Nong Xiao,Wei Lin,Jiangsu Du*

Main category: cs.GR

TL;DR: MixCache是一个用于高效视频DiT推理的训练无关缓存框架，通过多粒度缓存策略解决了现有方法的局限性，实现了速度和质量的提升。


<details>
  <summary>Details</summary>
Motivation: 现有的缓存方法仅限于单一粒度策略，难以灵活平衡生成质量和推理速度。而视频DiT模型的多步迭代去噪过程导致高计算成本和推理延迟。

Method: MixCache是一个无需训练的、基于缓存的框架。它通过区分不同缓存策略的干扰和边界，并引入了感知上下文的缓存触发策略来确定何时启用缓存。此外，它还采用了自适应混合缓存决策策略，用于动态地选择最优的缓存粒度。

Result: MixCache能够显著加速视频生成（例如，在Wan 14B上加速1.94倍，在HunyuanVideo上加速1.97倍），同时在生成质量和推理效率方面优于基线方法。

Conclusion: MixCache通过区分不同缓存策略的干扰和边界，并引入感知上下文的缓存触发策略来确定何时启用缓存，以及用于动态选择最优缓存粒度的自适应混合缓存决策策略，实现了高效的视频DiT推理。实验证明，MixCache在保证生成质量和推理效率方面优于基线方法，并能显著加速视频生成。

Abstract: Leveraging the Transformer architecture and the diffusion process, video DiT
models have emerged as a dominant approach for high-quality video generation.
However, their multi-step iterative denoising process incurs high computational
cost and inference latency. Caching, a widely adopted optimization method in
DiT models, leverages the redundancy in the diffusion process to skip
computations in different granularities (e.g., step, cfg, block). Nevertheless,
existing caching methods are limited to single-granularity strategies,
struggling to balance generation quality and inference speed in a flexible
manner. In this work, we propose MixCache, a training-free caching-based
framework for efficient video DiT inference. It first distinguishes the
interference and boundary between different caching strategies, and then
introduces a context-aware cache triggering strategy to determine when caching
should be enabled, along with an adaptive hybrid cache decision strategy for
dynamically selecting the optimal caching granularity. Extensive experiments on
diverse models demonstrate that, MixCache can significantly accelerate video
generation (e.g., 1.94$\times$ speedup on Wan 14B, 1.97$\times$ speedup on
HunyuanVideo) while delivering both superior generation quality and inference
efficiency compared to baseline methods.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [445] [Sparse Attention across Multiple-context KV Cache](https://arxiv.org/abs/2508.11661)
*Ziyi Cao,Qingyi Si,Jingbin Zhang,Bingquan Liu*

Main category: cs.LG

TL;DR: SamKV通过一种新颖的注意力稀疏化方法，解决了多上下文KV缓存的效率问题，显著提高了RAG等场景下的模型推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有的KV缓存重用方法在检索增强生成（RAG）等需要处理多个独立上下文的场景中效果不佳，因为它们缺乏跨上下文的注意力，并且现有部分重新计算的方法未能减少内存开销。

Method: SamKV通过考虑其他上下文的互补信息来稀疏化一个上下文，然后对稀疏化后的信息进行局部重新计算。

Result: SamKV将序列长度压缩到15%，同时保持准确性，并在多上下文RAG场景中显著提高了吞吐量。

Conclusion: SamKV是首次探索用于多上下文KV缓存的注意力稀疏化，它在稀疏化一个上下文时考虑了其他上下文的互补信息，然后对稀疏化后的信息进行局部重新计算。实验证明，与全重新计算基线相比，我们的方法在不降低准确性的情况下将序列长度压缩到15%，在多上下文RAG场景中显著提高了吞吐量。

Abstract: Large language models face significant cost challenges in long-sequence
inference. To address this, reusing historical Key-Value (KV) Cache for
improved inference efficiency has become a mainstream approach. Recent advances
further enhance throughput by sparse attention mechanisms to select the most
relevant KV Cache, thereby reducing sequence length. However, such techniques
are limited to single-context scenarios, where historical KV Cache is computed
sequentially with causal-attention dependencies. In retrieval-augmented
generation (RAG) scenarios, where retrieved documents as context are unknown
beforehand, each document's KV Cache is computed and stored independently
(termed multiple-context KV Cache), lacking cross-attention between contexts.
This renders existing methods ineffective. Although prior work partially
recomputes multiple-context KV Cache to mitigate accuracy loss from missing
cross-attention, it requires retaining all KV Cache throughout, failing to
reduce memory overhead. This paper presents SamKV, the first exploration of
attention sparsification for multiple-context KV Cache. Specifically, SamKV
takes into account the complementary information of other contexts when
sparsifying one context, and then locally recomputes the sparsified
information. Experiments demonstrate that our method compresses sequence length
to 15% without accuracy degradation compared with full-recompuation baselines,
significantly boosting throughput in multi-context RAG scenarios.

</details>


### [446] [Assessing Representation Stability for Transformer Models](https://arxiv.org/abs/2508.11667)
*Bryan E. Tuck,Rakesh M. Verma*

Main category: cs.LG

TL;DR: RS 是一种新的、模型无关的检测框架，通过测量掩蔽重要词语时嵌入表示的变化来检测对抗性文本攻击。它在多种场景下表现出高准确率和良好的泛化能力，并且计算成本较低。


<details>
  <summary>Details</summary>
Motivation: 对抗性文本攻击仍然是 transformer 模型面临的持续威胁，而现有的防御方法通常是攻击特定的或需要昂贵的模型重新训练。

Method: RS 首先使用重要性启发式方法对词语进行排序，然后测量嵌入对掩蔽 top-k 关键词的敏感性，并使用 BiLSTM 检测器处理由此产生的模式。

Result: RS 在三个数据集、三种攻击类型和两个受害者模型上实现了超过 88% 的检测准确率，并且通常以更低的计算成本实现了与现有最先进方法相当的性能。使用 NDCG 衡量扰动识别质量，我们发现基于梯度的排序优于注意力机制和随机选择方法，识别质量与单词级攻击的检测性能相关。RS 还能很好地泛化到未见的数据集、攻击和模型，而无需重新训练。

Conclusion: RS 是一种模型无关的检测框架，通过衡量重要词语被掩蔽时嵌入表示的变化来识别对抗性示例。实验结果表明，与自然重要的词语相比，对抗性扰动的词语表现出不成比例的高掩蔽敏感性。RS 在三个数据集、三种攻击类型和两个受害者模型上实现了超过 88% 的检测准确率，并且通常以更低的计算成本实现了与现有最先进方法相当的性能。

Abstract: Adversarial text attacks remain a persistent threat to transformer models,
yet existing defenses are typically attack-specific or require costly model
retraining. We introduce Representation Stability (RS), a model-agnostic
detection framework that identifies adversarial examples by measuring how
embedding representations change when important words are masked. RS first
ranks words using importance heuristics, then measures embedding sensitivity to
masking top-k critical words, and processes the resulting patterns with a
BiLSTM detector. Experiments show that adversarially perturbed words exhibit
disproportionately high masking sensitivity compared to naturally important
words. Across three datasets, three attack types, and two victim models, RS
achieves over 88% detection accuracy and demonstrates competitive performance
compared to existing state-of-the-art methods, often at lower computational
cost. Using Normalized Discounted Cumulative Gain (NDCG) to measure
perturbation identification quality, we reveal that gradient-based ranking
outperforms attention and random selection approaches, with identification
quality correlating with detection performance for word-level attacks. RS also
generalizes well to unseen datasets, attacks, and models without retraining,
providing a practical solution for adversarial text detection.

</details>


### [447] [Collaborative Learning-Enhanced Lightweight Models for Predicting Arterial Blood Pressure Waveform in a Large-scale Perioperative Dataset](https://arxiv.org/abs/2508.11669)
*Wentao Li,Yonghu He,Kun Gao,Qing Liu,Yali Zheng*

Main category: cs.LG

TL;DR: 该研究提出了一种轻量级的KDCL_sInvResUNet模型，用于从无创生理信号估计动脉血压，实现了在嵌入式设备上的实时监测，性能接近大型模型，但泛化能力仍有限。


<details>
  <summary>Details</summary>
Motivation: 现有研究在针对嵌入式系统部署的深度学习模型性能和计算负荷方面研究不足，而无创动脉血压监测对于重症监护和围手术期患者管理至关重要。

Method: 提出了一种名为KDCL_sInvResUNet的轻量级模型和协作学习方案，该模型仅包含0.89M参数和0.02 GFLOPS的计算量，实现了在嵌入式设备上进行实时动脉血压估计，推理时间仅为8.49毫秒（输出10秒数据）。

Result: KDCL_sInvResUNet在包含1,257,141个数据段（来自2,154名患者）的大规模异构围手术期数据集上进行了受试者无关验证，其平均绝对误差为10.06 mmHg，平均皮尔逊相关系数为0.88，性能略优于大型模型。

Conclusion: 该研究为在真实世界围手术期设置中进行实时、无干扰的动脉血压监测奠定了基础，并为该领域的未来进步提供了基线。然而，所有深度学习模型在不同人群和心血管条件下表现出显著的性能差异，凸显了其在广泛多样化人群中的泛化能力有限。

Abstract: Noninvasive arterial blood pressure (ABP) monitoring is essential for patient
management in critical care and perioperative settings, providing continuous
assessment of cardiovascular hemodynamics with minimal risks. Numerous deep
learning models have developed to reconstruct ABP waveform from noninvasively
acquired physiological signals such as electrocardiogram and
photoplethysmogram. However, limited research has addressed the issue of model
performance and computational load for deployment on embedded systems. The
study introduces a lightweight sInvResUNet, along with a collaborative learning
scheme named KDCL_sInvResUNet. With only 0.89 million parameters and a
computational load of 0.02 GFLOPS, real-time ABP estimation was successfully
achieved on embedded devices with an inference time of just 8.49 milliseconds
for a 10-second output. We performed subject-independent validation in a
large-scale and heterogeneous perioperative dataset containing 1,257,141 data
segments from 2,154 patients, with a wide BP range (41-257 mmHg for SBP, and
31-234 mmHg for DBP). The proposed KDCL_sInvResUNet achieved lightly better
performance compared to large models, with a mean absolute error of 10.06 mmHg
and mean Pearson correlation of 0.88 in tracking ABP changes. Despite these
promising results, all deep learning models showed significant performance
variations across different demographic and cardiovascular conditions,
highlighting their limited ability to generalize across such a broad and
diverse population. This study lays a foundation work for real-time,
unobtrusive ABP monitoring in real-world perioperative settings, providing
baseline for future advancements in this area.

</details>


### [448] [Contrastive Regularization over LoRA for Multimodal Biomedical Image Incremental Learning](https://arxiv.org/abs/2508.11673)
*Haojie Zhang,Yixiong Liang,Hulin Kuang,Lihui Cen,Zhe Qu,Yigang Cen,Min Zeng,Shichao Kan*

Main category: cs.LG

TL;DR: MBIIL 挑战：跨模态知识保留与利用。提出 MSLoRA-CR：微调特定模态 LoRA + 对比正则化。冻结 LVLM，增量适应新 LoRA。结果：性能提升 1.88%，计算高效。


<details>
  <summary>Details</summary>
Motivation: 现有的增量学习方法主要关注单一模态内的任务扩展，而生物医学领域的多模态生物医学图像增量学习（MBIIL）旨在跨模态地训练统一模型，以降低为不同模态或任务训练单独模型的推理成本。MBIIL 面临两大挑战：如何在增量更新中保留先前学到的知识，以及如何有效地利用已有模态的知识来支持新模态。

Method: 提出了一种名为 MSLoRA-CR 的新方法，该方法通过微调特定模态的 LoRA 模块并结合对比正则化来实现。在增量学习过程中，冻结预训练的大型视觉语言模型，为每种模态或任务增量适应新的 LoRA 模块，以增强模态内知识共享并促进模态间知识区分。

Result: 实验证明，MSLoRA-CR 在生物医学图像的增量学习任务上，相比为每种模态训练单独模型的 SOTA 方法和通用的增量学习方法（增量微调 LoRA），整体性能分别提高了 1.88%，同时保持了计算效率。

Conclusion: MSLoRA-CR 方法在生物医学图像增量学习任务中取得了显著成效，相比于当前最优方法（为每种模态训练单独的模型）以及通用的增量学习方法（增量微调 LoRA），在整体性能上分别提升了 1.88%，同时保持了计算效率。

Abstract: Multimodal Biomedical Image Incremental Learning (MBIIL) is essential for
handling diverse tasks and modalities in the biomedical domain, as training
separate models for each modality or task significantly increases inference
costs. Existing incremental learning methods focus on task expansion within a
single modality, whereas MBIIL seeks to train a unified model incrementally
across modalities. The MBIIL faces two challenges: I) How to preserve
previously learned knowledge during incremental updates? II) How to effectively
leverage knowledge acquired from existing modalities to support new modalities?
To address these challenges, we propose MSLoRA-CR, a method that fine-tunes
Modality-Specific LoRA modules while incorporating Contrastive Regularization
to enhance intra-modality knowledge sharing and promote inter-modality
knowledge differentiation. Our approach builds upon a large vision-language
model (LVLM), keeping the pretrained model frozen while incrementally adapting
new LoRA modules for each modality or task. Experiments on the incremental
learning of biomedical images demonstrate that MSLoRA-CR outperforms both the
state-of-the-art (SOTA) approach of training separate models for each modality
and the general incremental learning method (incrementally fine-tuning LoRA).
Specifically, MSLoRA-CR achieves a 1.88% improvement in overall performance
compared to unconstrained incremental learning methods while maintaining
computational efficiency. Our code is publicly available at
https://github.com/VentusAislant/MSLoRA_CR.

</details>


### [449] [Lifelong Learner: Discovering Versatile Neural Solvers for Vehicle Routing Problems](https://arxiv.org/abs/2508.11679)
*Shaodi Feng,Zhuoyi Lin,Jianan Zhou,Cong Zhang,Jingwen Li,Kuan-Wen Chen,Senthilnath Jayavelu,Yew-Soon Ong*

Main category: cs.LG

TL;DR: 本研究提出了一种新颖的终身学习框架，利用Transformer网络和跨情境自注意力机制，以及动态情境调度器，来解决通用车辆路径问题。该框架能够有效处理不同情境下的问题，并超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的神经求解器通常在单一、简化的情境下进行训练，限制了它们在不同场景下的通用性。本研究旨在通过终身学习框架增强车辆路径问题的神经求解器的通用性。

Method: 提出了一种新颖的终身学习框架，利用Transformer网络作为骨干，并通过提出的跨情境自注意力机制和动态情境调度器（DCS）来增强模型的知识迁移和策略回顾能力，以解决一系列不同的车辆路径问题。

Result: 在合成和基准实例（问题规模高达18k）上的广泛结果表明，所提出的终身学习框架（LL）能够发现有效的策略来处理不同情境下的通用车辆路径问题，并且性能优于其他神经求解器，在大多数车辆路径问题上达到最佳。

Conclusion: 该研究提出的终身学习框架能够有效地解决不同情境下的车辆路径问题，并且在大多数车辆路径问题上取得了最佳性能，超越了其他神经求解器。

Abstract: Deep learning has been extensively explored to solve vehicle routing problems
(VRPs), which yields a range of data-driven neural solvers with promising
outcomes. However, most neural solvers are trained to tackle VRP instances in a
relatively monotonous context, e.g., simplifying VRPs by using Euclidean
distance between nodes and adhering to a single problem size, which harms their
off-the-shelf application in different scenarios. To enhance their versatility,
this paper presents a novel lifelong learning framework that incrementally
trains a neural solver to manage VRPs in distinct contexts. Specifically, we
propose a lifelong learner (LL), exploiting a Transformer network as the
backbone, to solve a series of VRPs. The inter-context self-attention mechanism
is proposed within LL to transfer the knowledge obtained from solving preceding
VRPs into the succeeding ones. On top of that, we develop a dynamic context
scheduler (DCS), employing the cross-context experience replay to further
facilitate LL looking back on the attained policies of solving preceding VRPs.
Extensive results on synthetic and benchmark instances (problem sizes up to
18k) show that our LL is capable of discovering effective policies for tackling
generic VRPs in varying contexts, which outperforms other neural solvers and
achieves the best performance for most VRPs.

</details>


### [450] [Comparative Analysis of Time Series Foundation Models for Demographic Forecasting: Enhancing Predictive Accuracy in US Population Dynamics](https://arxiv.org/abs/2508.11680)
*Aditya Akella,Jonathan Farah*

Main category: cs.LG

TL;DR: 金融时间序列模型（TimesFM）在人口预测方面优于传统模型，尤其擅长处理少数族裔数据稀疏的情况。


<details>
  <summary>Details</summary>
Motivation: 准确的人口预测对于城市规划、医疗保健和经济政策等领域的知情决策至关重要。然而，受全球化、经济状况、地缘政治事件和环境因素影响的人口结构变化给政策制定者和研究人员带来了重大挑战。

Method: 本研究利用美国人口普查局和联邦储备经济数据（FRED）的数据，探索了时间序列基础模型在预测美国人口变化方面的应用。通过在六个具有不同人口结构特征的州进行实验，将TimesFM与LSTM、ARIMA和线性回归等传统模型进行性能比较。

Result: 实验结果显示，TimesFM在86.67%的测试案例中实现了最低的均方误差（MSE），其表现尤其在少数族裔人口数据稀疏的情况下更为突出。

Conclusion: 该研究表明，预训练的金融时间序列模型（TimesFM）在人口预测任务中表现优于传统的基线模型（如LSTM、ARIMA和线性回归），尤其在少数族裔人口预测方面。这预示着金融时间序列模型在人口分析和制定前瞻性政策干预措施方面的潜力，且无需进行大量的特定任务微调。

Abstract: Demographic shifts, influenced by globalization, economic conditions,
geopolitical events, and environmental factors, pose significant challenges for
policymakers and researchers. Accurate demographic forecasting is essential for
informed decision-making in areas such as urban planning, healthcare, and
economic policy. This study explores the application of time series foundation
models to predict demographic changes in the United States using datasets from
the U.S. Census Bureau and Federal Reserve Economic Data (FRED). We evaluate
the performance of the Time Series Foundation Model (TimesFM) against
traditional baselines including Long Short-Term Memory (LSTM) networks,
Autoregressive Integrated Moving Average (ARIMA), and Linear Regression. Our
experiments across six demographically diverse states demonstrate that TimesFM
achieves the lowest Mean Squared Error (MSE) in 86.67% of test cases, with
particularly strong performance on minority populations with sparse historical
data. These findings highlight the potential of pre-trained foundation models
to enhance demographic analysis and inform proactive policy interventions
without requiring extensive task-specific fine-tuning.

</details>


### [451] [A Multi-Resolution Benchmark Framework for Spatial Reasoning Assessment in Neural Networks](https://arxiv.org/abs/2508.12741)
*Manuela Imbriani,Gina Belmonte,Mieke Massink,Alessandro Tofani,Vincenzo Ciancia*

Main category: cs.LG

TL;DR: 该研究提出了一个用于评估神经网络空间推理能力的基准测试框架，初步结果显示神经网络在理解几何和拓扑关系方面存在困难，并提出结合符号推理方法可能是一种解决方案。


<details>
  <summary>Details</summary>
Motivation: 为了系统性地评估神经网络的空间推理能力，特别是形态属性（如连通性和距离关系），并为改善临床应用中的空间理解能力奠定基础。

Method: 提出了一种全面的基准测试框架，使用空间模型检查器VoxLogicA生成包含迷宫连通性问题和空间距离计算任务的合成数据集。该框架包括自动化机器学习流程：合成数据集生成、带交叉验证的标准训练、推理执行以及使用Dice系数和IoU（交并比）指标进行的综合评估。

Result: 初步实验结果显示，神经网络在空间推理能力方面存在显著挑战，在基础的几何和拓扑理解任务中暴露了系统性的失败。

Conclusion: 该研究表明，神经网络在空间推理能力方面存在显著挑战，在基础的几何和拓扑理解任务中存在系统性失败。该框架为识别具体局限性提供了可复现的实验规程，并为结合神经网络与符号推理方法以改善临床应用中的空间理解能力奠定了基础。

Abstract: This paper presents preliminary results in the definition of a comprehensive
benchmark framework designed to systematically evaluate spatial reasoning
capabilities in neural networks, with a particular focus on morphological
properties such as connectivity and distance relationships. The framework is
currently being used to study the capabilities of nnU-Net, exploiting the
spatial model checker VoxLogicA to generate two distinct categories of
synthetic datasets: maze connectivity problems for topological analysis and
spatial distance computation tasks for geometric understanding. Each category
is evaluated across multiple resolutions to assess scalability and
generalization properties. The automated pipeline encompasses a complete
machine learning workflow including: synthetic dataset generation, standardized
training with cross-validation, inference execution, and comprehensive
evaluation using Dice coefficient and IoU (Intersection over Union) metrics.
Preliminary experimental results demonstrate significant challenges in neural
network spatial reasoning capabilities, revealing systematic failures in basic
geometric and topological understanding tasks. The framework provides a
reproducible experimental protocol, enabling researchers to identify specific
limitations. Such limitations could be addressed through hybrid approaches
combining neural networks with symbolic reasoning methods for improved spatial
understanding in clinical applications, establishing a foundation for ongoing
research into neural network spatial reasoning limitations and potential
solutions.

</details>


### [452] [From Heuristics to Data: Quantifying Site Planning Layout Indicators with Deep Learning and Multi-Modal Data](https://arxiv.org/abs/2508.11723)
*Qian Cao,Jielin Chen,Junchao Zhao,Rudi Stouffs*

Main category: cs.LG

TL;DR: 提出SPLI系统，用多源数据和深度学习量化城市场地布局，改进规划分析。


<details>
  <summary>Details</summary>
Motivation: 传统的城市场地规划依赖经验判断和单一数据源，难以系统量化多功能布局，影响了土地利用效率和空间组织。因此，需要一个数据驱动的框架来解决这些局限性。

Method: 提出了一种名为SPLI（Site Planning Layout Indicator）的数据驱动框架，整合了OpenStreetMap（OSM）、兴趣点（POI）、建筑形态、土地利用和卫星图像等多源异构数据。该框架通过五个维度（层级化建筑功能分类、空间组织、功能多样性、基本服务可达性、土地利用强度）来量化和分析城市场地布局，并利用图神经网络（GNN）和关系图神经网络（RGNN）等深度学习方法处理数据空白。

Result: SPLI系统能够实现对城市场地布局的量化分析，提高功能分类的准确性，并为自动化、数据驱动的城市空间分析提供标准化基础。

Conclusion: 该SPLI系统通过集成多源数据和深度学习方法，提高了功能分类的准确性，并为自动化、数据驱动的城市空间分析提供了标准化基础。

Abstract: The spatial layout of urban sites shapes land-use efficiency and spatial
organization. Traditional site planning often relies on experiential judgment
and single-source data, limiting systematic quantification of multifunctional
layouts. We propose a Site Planning Layout Indicator (SPLI) system, a
data-driven framework integrating empirical knowledge with heterogeneous
multi-source data to produce structured urban spatial information. The SPLI
supports multimodal spatial data systems for analytics, inference, and
retrieval by combining OpenStreetMap (OSM), Points of Interest (POI), building
morphology, land use, and satellite imagery. It extends conventional metrics
through five dimensions: (1) Hierarchical Building Function Classification,
refining empirical systems into clear hierarchies; (2) Spatial Organization,
quantifying seven layout patterns (e.g., symmetrical, concentric,
axial-oriented); (3) Functional Diversity, transforming qualitative assessments
into measurable indicators using Functional Ratio (FR) and Simpson Index (SI);
(4) Accessibility to Essential Services, integrating facility distribution and
transport networks for comprehensive accessibility metrics; and (5) Land Use
Intensity, using Floor Area Ratio (FAR) and Building Coverage Ratio (BCR) to
assess utilization efficiency. Data gaps are addressed through deep learning,
including Relational Graph Neural Networks (RGNN) and Graph Neural Networks
(GNN). Experiments show the SPLI improves functional classification accuracy
and provides a standardized basis for automated, data-driven urban spatial
analytics.

</details>


### [453] [Causal Structure Learning in Hawkes Processes with Complex Latent Confounder Networks](https://arxiv.org/abs/2508.11727)
*Songyao Jin,Biwei Huang*

Main category: cs.LG

TL;DR: 一种新的方法，用于在存在潜在子过程的情况下识别多变量 Hawkes 过程中的因果结构。


<details>
  <summary>Details</summary>
Motivation: 现有的方法主要关注于揭示观察到的子过程之间的因果结构，但现实世界的系统通常只被部分观察到，潜在的子过程带来了重大挑战。

Method: 提出了一种两阶段迭代算法，该算法在推断已发现子过程之间的因果关系和揭示新的潜在子过程之间交替进行，并以保证可识别性的基于路径的条件为指导。

Result: 实验结果表明，我们的方法能够有效恢复因果结构，即使在存在潜在子过程的情况下。

Conclusion: 该方法能够有效恢复因果结构，即使在存在潜在子过程的情况下。

Abstract: Multivariate Hawkes process provides a powerful framework for modeling
temporal dependencies and event-driven interactions in complex systems. While
existing methods primarily focus on uncovering causal structures among observed
subprocesses, real-world systems are often only partially observed, with latent
subprocesses posing significant challenges. In this paper, we show that
continuous-time event sequences can be represented by a discrete-time model as
the time interval shrinks, and we leverage this insight to establish necessary
and sufficient conditions for identifying latent subprocesses and the causal
influences. Accordingly, we propose a two-phase iterative algorithm that
alternates between inferring causal relationships among discovered subprocesses
and uncovering new latent subprocesses, guided by path-based conditions that
guarantee identifiability. Experiments on both synthetic and real-world
datasets show that our method effectively recovers causal structures despite
the presence of latent subprocesses.

</details>


### [454] [FedUHD: Unsupervised Federated Learning using Hyperdimensional Computing](https://arxiv.org/abs/2508.12021)
*You Hak Lee,Xiaofan Yu,Quanling Zhao,Flavio Ponzina,Tajana Rosing*

Main category: cs.LG

TL;DR: FedUHD是一种基于高维计算（HDC）的无监督联邦学习（UFL）框架，它通过创新的客户端和服务器端设计解决了数据异质性和通信成本问题，显著提高了性能和效率，并增强了鲁棒性。


<details>
  <summary>Details</summary>
Motivation: UFL虽然是一种注重隐私的去中心化机器学习方法，但面临数据分布不均、边缘计算成本高和通信噪声等挑战。现有方法依赖深度神经网络，计算和通信开销大。因此，需要一种更轻量级、更鲁棒的UFL框架。

Method: FedUHD是第一个基于高维计算（HDC）的无监督联邦学习（UFL）框架。通过在客户端使用基于kNN的聚类超向量移除方法来处理非iid数据，并通过在服务器端使用加权HDC聚合技术来平衡客户端的非iid数据分布。

Result: FedUHD在训练速度和能效方面分别提高了173.6倍和612.7倍，通信成本降低了271倍，准确性平均提高了15.50%，并且在各种噪声环境下表现出比最先进的基于NN的UFL方法更优越的鲁棒性。

Conclusion: FedUHD通过引入基于HD C的kNN聚类超向量移除方法来处理非iid数据，并采用加权HDC聚合技术来平衡客户数据分布，在速度、能效、通信成本和准确性方面均优于最先进的基于NN的UFL方法，并且对噪声具有更好的鲁棒性。

Abstract: Unsupervised federated learning (UFL) has gained attention as a
privacy-preserving, decentralized machine learning approach that eliminates the
need for labor-intensive data labeling. However, UFL faces several challenges
in practical applications: (1) non-independent and identically distributed
(non-iid) data distribution across devices, (2) expensive computational and
communication costs at the edge, and (3) vulnerability to communication noise.
Previous UFL approaches have relied on deep neural networks (NN), which
introduce substantial overhead in both computation and communication. In this
paper, we propose FedUHD, the first UFL framework based on Hyperdimensional
Computing (HDC). HDC is a brain-inspired computing scheme with lightweight
training and inference operations, much smaller model size, and robustness to
communication noise. FedUHD introduces two novel HDC-based designs to improve
UFL performance. On the client side, a kNN-based cluster hypervector removal
method addresses non-iid data samples by eliminating detrimental outliers. On
the server side, a weighted HDC aggregation technique balances the non-iid data
distribution across clients. Our experiments demonstrate that FedUHD achieves
up to 173.6x and 612.7x better speedup and energy efficiency, respectively, in
training, up to 271x lower communication cost, and 15.50% higher accuracy on
average across diverse settings, along with superior robustness to various
types of noise compared to state-of-the-art NN-based UFL approaches.

</details>


### [455] [BRIEF: BRain-Inspired network connection search with Extensive temporal feature Fusion enhances disease classification](https://arxiv.org/abs/2508.11732)
*Xiangxiang Cui,Min Zhao,Dongmei Zhi,Shile Qi,Vince D Calhoun,Jing Sui*

Main category: cs.LG

TL;DR: BRIEF框架通过受大脑启发的连接搜索和Transformer融合，自动优化fMRI分类模型，在精神分裂症和自闭症检测上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于fMRI的功能磁共振成像分类深度学习模型在网络架构确定（依赖经验）和特征空间融合（主要是简单的连接，缺乏互学习）方面存在局限性。受人脑通过学习和决策更新神经连接机制的启发，提出了一种新颖的框架。

Method: 提出了一种新颖的BRain-Inspired feature Fusion (BRIEF)框架，该框架通过结合改进的神经网络连接搜索（NCS）策略和基于Transformer的多特征融合模块，能够自动优化网络架构。具体来说，提取了4种fMRI时间表征（时间序列、静态/动态功能连接、多尺度离散熵）构建四个编码器，并在每个编码器中采用改进的Q学习来动态优化NCS。然后，通过Transformer融合所有特征向量，并嵌入注意力模块以提高可解释性。

Result: 与21种最先进的模型相比，BRIEF在区分精神分裂症（SZ, n=1100）和自闭症谱系障碍（ASD, n=1550）方面表现出显著的改进（2.2%至12.1%），AUC分别达到91.5% ± 0.6%（SZ）和78.4% ± 0.5%（ASD）。

Conclusion: 该研究首次将受大脑启发的强化学习策略用于优化基于fMRI的精神疾病分类，展示了识别精确神经影像生物标志物的巨大潜力。

Abstract: Existing deep learning models for functional MRI-based classification have
limitations in network architecture determination (relying on experience) and
feature space fusion (mostly simple concatenation, lacking mutual learning).
Inspired by the human brain's mechanism of updating neural connections through
learning and decision-making, we proposed a novel BRain-Inspired feature Fusion
(BRIEF) framework, which is able to optimize network architecture automatically
by incorporating an improved neural network connection search (NCS) strategy
and a Transformer-based multi-feature fusion module. Specifically, we first
extracted 4 types of fMRI temporal representations, i.e., time series (TCs),
static/dynamic functional connection (FNC/dFNC), and multi-scale dispersion
entropy (MsDE), to construct four encoders. Within each encoder, we employed a
modified Q-learning to dynamically optimize the NCS to extract high-level
feature vectors, where the NCS is formulated as a Markov Decision Process.
Then, all feature vectors were fused via a Transformer, leveraging both
stable/time-varying connections and multi-scale dependencies across different
brain regions to achieve the final classification. Additionally, an attention
module was embedded to improve interpretability. The classification performance
of our proposed BRIEF was compared with 21 state-of-the-art models by
discriminating two mental disorders from healthy controls: schizophrenia (SZ,
n=1100) and autism spectrum disorder (ASD, n=1550). BRIEF demonstrated
significant improvements of 2.2% to 12.1% compared to 21 algorithms, reaching
an AUC of 91.5% - 0.6% for SZ and 78.4% - 0.5% for ASD, respectively. This is
the first attempt to incorporate a brain-inspired, reinforcement learning
strategy to optimize fMRI-based mental disorder classification, showing
significant potential for identifying precise neuroimaging biomarkers.

</details>


### [456] [Fed-DPRoC:Communication-Efficient Differentially Private and Robust Federated Learning](https://arxiv.org/abs/2508.12978)
*Yue Xia,Tayyebeh Jahani-Nezhad,Rawad Bitar*

Main category: cs.LG

TL;DR: Fed-DPRoC是一个联邦学习框架，通过RobAJoL实现了差分隐私、拜占庭鲁棒性和通信效率。


<details>
  <summary>Details</summary>
Motivation: 为了在联邦学习中同时实现差分隐私（DP）、拜占庭鲁棒性和通信效率。

Method: 提出了一种名为RobAJoL的框架，结合了Johnson-Lindenstrauss（JL）变换进行压缩和鲁棒平均以实现鲁棒聚合，并从理论上证明了JL变换与鲁棒平均的兼容性。

Result: 实验证明RobAJoL在CIFAR-10和Fashion MNIST数据集上，在不同的拜占庭攻击下，其鲁棒性和效用均优于现有方法，同时保证了差分隐私和降低了通信成本。

Conclusion: Fed-DPRoC框架（以RobAJoL为例）在拜占庭攻击下，在鲁棒性和效用方面优于现有方法，同时保证了差分隐私和通信效率。

Abstract: We propose Fed-DPRoC, a novel federated learning framework that
simultaneously ensures differential privacy (DP), Byzantine robustness, and
communication efficiency. We introduce the concept of robust-compatible
compression, which enables users to compress DP-protected updates while
maintaining the robustness of the aggregation rule. We instantiate our
framework as RobAJoL, combining the Johnson-Lindenstrauss (JL) transform for
compression with robust averaging for robust aggregation. We theoretically
prove the compatibility of JL transform with robust averaging and show that
RobAJoL preserves robustness guarantees, ensures DP, and reduces communication
cost. Experiments on CIFAR-10 and Fashion MNIST validate our theoretical claims
and demonstrate that RobAJoL outperforms existing methods in terms of
robustness and utility under different Byzantine attacks.

</details>


### [457] [A Perfectly Truthful Calibration Measure](https://arxiv.org/abs/2508.13100)
*Jason Hartline,Lunjia Hu,Yifan Wu*

Main category: cs.LG

TL;DR: 本研究提出了一种名为 ATB 的完美真实校准度量，解决了现有度量在有限样本下不真实的问题。ATB 在批处理设置下更优越，计算简单，速度更快，并提供了一种通用的真实度量构建方法。


<details>
  <summary>Details</summary>
Motivation: 现有的校准度量在有限样本下进行评估时，往往不能保证预测真实概率就能最小化这些度量，这促使研究者去寻找更“真实”的校准度量。虽然已有工作在顺序预测设置下提出了近似真实度量，但在更基础的批处理设置下，尚未存在完美的真实校准度量。这种不真实性是本研究的主要动机。

Method: 本文设计了一种名为“平均双箱校准误差”（ATB）的完美真实校准度量，用于解决现有校准度量在有限样本下可能存在不真实性（即，不能保证预测真实概率时度量最小）的问题。研究中提出的 ATB 度量在批处理设置下是真实、健全、完整、连续的，并与 smCal 和 distCal 两个现有度量有二次关系。此外，还提出了一种构建真实度量的通用方法，该方法证明了 ATB 的真实性，并可用于构建其他真实度量（如分位数分箱 l_2-ECE）。

Result: 本文成功设计了一个名为“平均双箱校准误差”（ATB）的完美真实校准度量。ATB 在批处理设置下具有真实、健全、完整、连续等性质，并与 smCal 和 distCal 存在二次关系。与 smCal 和 distCal 相比，ATB 的计算更简单，估计算法更快。此外，研究提出了一种构建真实度量的通用方法，该方法证明了 ATB 的真实性，并能生成如分位数分箱 l_2-ECE 等其他真实度量。

Conclusion: 研究提出了一种名为“平均双箱校准误差”（ATB）的完美真实校准度量，它在批处理设置下是真实、健全、完整、连续的，并且与现有的 smCal 和 distCal 度量有二次关系。ATB 的定义简洁，易于计算，并能实现比 smCal 和 distCal 更快的估计算法和更简单的实现，从而提高了校准测试问题的效率和简单性。此外，研究还提供了一个构建真实度量的通用方法，并将 ATB 作为特例进行了证明，并在此基础上构建了其他真实度量，如分位数分箱 l_2-ECE。

Abstract: Calibration requires that predictions are conditionally unbiased and,
therefore, reliably interpretable as probabilities. Calibration measures
quantify how far a predictor is from perfect calibration. As introduced by
Haghtalab et al. (2024), a calibration measure is truthful if it is minimized
in expectation when a predictor outputs the ground-truth probabilities.
Although predicting the true probabilities guarantees perfect calibration, in
reality, when calibration is evaluated on a finite sample, predicting the truth
is not guaranteed to minimize any known calibration measure. All known
calibration measures incentivize predictors to lie in order to appear more
calibrated on a finite sample. Such lack of truthfulness motivated Haghtalab et
al. (2024) and Qiao and Zhao (2025) to construct approximately truthful
calibration measures in the sequential prediction setting, but no perfectly
truthful calibration measure was known to exist even in the more basic batch
setting.
  We design a perfectly truthful calibration measure in the batch setting:
averaged two-bin calibration error (ATB). In addition to being truthful, ATB is
sound, complete, continuous, and quadratically related to two existing
calibration measures: the smooth calibration error (smCal) and the (lower)
distance to calibration (distCal). The simplicity in our definition of ATB
makes it efficient and straightforward to compute. ATB allows faster estimation
algorithms with significantly easier implementations than smCal and distCal,
achieving improved running time and simplicity for the calibration testing
problem studied by Hu et al. (2024). We also introduce a general recipe for
constructing truthful measures, which proves the truthfulness of ATB as a
special case and allows us to construct other truthful calibration measures
such as quantile-binned l_2-ECE.

</details>


### [458] [Scalable Geospatial Data Generation Using AlphaEarth Foundations Model](https://arxiv.org/abs/2508.11739)
*Luc Houriez,Sebastian Pilarski,Behzad Vahedi,Ali Ahmadalipour,Teo Honda Scully,Nicholas Aflitto,David Andre,Caroline Jaffe,Martha Wedner,Rich Mazzola,Josh Jeffery,Ben Messinger,Sage McGinley-Smith,Sarah Russell*

Main category: cs.LG

TL;DR: 通过利用AlphaEarth Foundations (AEF)，可以有效地将地理空间标记数据集扩展到新的区域，即使使用简单的模型也能取得良好的效果。


<details>
  <summary>Details</summary>
Motivation: 为了应对高质量标记地理空间数据集在地理范围上的局限性，并利用AlphaEarth Foundations (AEF) 这一信息密集型全球地理空间表示来扩展现有数据集。

Method: 提出并评估了一种利用AlphaEarth Foundations (AEF) 将地理空间标记数据集扩展到其初始地理区域之外的方法。

Result: 所提出的方法能够将LANDFIRE的EVT数据集（包括EvtPhys和EvtGp）扩展到美国以外的加拿大。在EvtPhys方面，模型预测与地面真实情况定性一致，并且在USA和Canada的验证集上分别达到了81%和73%的分类准确率。

Conclusion: 利用AlphaEarth Foundations (AEF) 可以将现有地理空间标记数据集扩展到其原始地理区域之外，即使使用随机森林或逻辑回归等基本模型也能实现此目的。所提出的方法在将LANDFIRE的现有植被类型（EVT）数据集扩展到美国以外的加拿大时，在EvtPhys（13个类别）和EvtGp（80个类别）两个粒度级别上都取得了定性上与地面真实情况一致的预测结果，并且在EvtPhys验证集上分别达到了81%和73%的分类准确率。

Abstract: High-quality labeled geospatial datasets are essential for extracting
insights and understanding our planet. Unfortunately, these datasets often do
not span the entire globe and are limited to certain geographic regions where
data was collected. Google DeepMind's recently released AlphaEarth Foundations
(AEF) provides an information-dense global geospatial representation designed
to serve as a useful input across a wide gamut of tasks. In this article we
propose and evaluate a methodology which leverages AEF to extend geospatial
labeled datasets beyond their initial geographic regions. We show that even
basic models like random forests or logistic regression can be used to
accomplish this task. We investigate a case study of extending LANDFIRE's
Existing Vegetation Type (EVT) dataset beyond the USA into Canada at two levels
of granularity: EvtPhys (13 classes) and EvtGp (80 classes). Qualitatively, for
EvtPhys, model predictions align with ground truth. Trained models achieve 81%
and 73% classification accuracy on EvtPhys validation sets in the USA and
Canada, despite discussed limitations.

</details>


### [459] [Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware](https://arxiv.org/abs/2508.11940)
*Yuannuo Feng,Wenyong Zhou,Yuexi Lyu,Yixiang Zhang,Zhengwu Liu,Ngai Wong,Wang Kang*

Main category: cs.LG

TL;DR: */提示词工程*了*/提示词工程*的*/提示词工程**/提示词工程**/提示词工程*，*/提示词工程**/提示词工程**/提示词工程**/提示词工程*。


<details>
  <summary>Details</summary>
Motivation: 模拟*提示词工程*（CIM）架构的硬件*/提示词工程*带来了严峻的挑战，而现有的*/提示词工程*感知训练方法依赖于*/提示词工程*且*/提示词工程*的噪声模型，无法完全*/提示词工程*模拟*/提示词工程*硬件*/提示词工程*的*/提示词工程*。

Method: 提出了一种解耦前向噪声模拟与反向梯度计算的方法，借鉴了*提示词工程*中的直通估计器（STE）框架，使得在*提示词工程*的*提示词工程*系统中使用更精确但计算上不可行的噪声模型进行*/提示词工程*训练成为可能。

Result: 实验结果表明，该方法在图像分类任务上实现了高达5.3%的准确率提升，在文本生成任务上降低了0.72的困惑度，训练时间*/提示词工程*2.2倍，峰值内存*/提示词工程*37.9%。

Conclusion: 所提出的框架在图像分类任务上实现了高达5.3%的准确率提升，在文本生成任务上降低了0.72的困惑度，同时训练时间缩短了2.2倍，峰值内存使用量降低了37.9%，相比标准的*/提示词工程*方法。

Abstract: Analog Compute-In-Memory (CIM) architectures promise significant energy
efficiency gains for neural network inference, but suffer from complex
hardware-induced noise that poses major challenges for deployment. While
noise-aware training methods have been proposed to address this issue, they
typically rely on idealized and differentiable noise models that fail to
capture the full complexity of analog CIM hardware variations. Motivated by the
Straight-Through Estimator (STE) framework in quantization, we decouple forward
noise simulation from backward gradient computation, enabling noise-aware
training with more accurate but computationally intractable noise modeling in
analog CIM systems. We provide theoretical analysis demonstrating that our
approach preserves essential gradient directional information while maintaining
computational tractability and optimization stability. Extensive experiments
show that our extended STE framework achieves up to 5.3% accuracy improvement
on image classification, 0.72 perplexity reduction on text generation,
2.2$\times$ speedup in training time, and 37.9% lower peak memory usage
compared to standard noise-aware training methods.

</details>


### [460] [Fed-Meta-Align: A Similarity-Aware Aggregation and Personalization Pipeline for Federated TinyML on Heterogeneous Data](https://arxiv.org/abs/2508.11794)
*Hemanth Macharla,Mayukha Pal*

Main category: cs.LG

TL;DR: Fed-Meta-Align框架通过元初始化和双标准聚合，解决了联邦学习在异构物联网设备上的模型发散问题，提高了故障分类的准确性。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的物联网设备上进行实时故障分类对工业安全至关重要，但在异构环境中训练鲁棒模型仍然是一个重大挑战。标准联邦学习（FL）在非IID数据存在的情况下，容易导致模型发散，因此需要一种新的方法来克服这些限制。

Method: 本文提出了一种新颖的四阶段框架Fed-Meta-Align，包括：1. 在公共数据集上训练基础模型；2. 通过串行元初始化阶段在物联网设备数据子集上训练模型以学习异构感知初始化；3. 在并行联邦学习阶段利用双标准聚合机制（同时考虑本地性能和余弦相似度对齐）来优化模型；4. 在设备上进行个性化阶段，将全局模型适配为每个物联网设备的专用模型。

Result: Fed-Meta-Align在异构物联网设备上实现了91.27%的平均测试准确率，在电气和机械故障数据集上分别比个性化FedAvg和FedProx高出3.87%和3.37%。

Conclusion: Fed-Meta-Align框架通过序列化初始化和自适应聚合的多阶段方法，在异构物联网设备上实现了91.27%的平均测试准确率，超越了现有的个性化FedAvg和FedProx方法，为在多样化的TinyML网络上部署高性能智能提供了鲁棒的途径。

Abstract: Real-time fault classification in resource-constrained Internet of Things
(IoT) devices is critical for industrial safety, yet training robust models in
such heterogeneous environments remains a significant challenge. Standard
Federated Learning (FL) often fails in the presence of non-IID data, leading to
model divergence. This paper introduces Fed-Meta-Align, a novel four-phase
framework designed to overcome these limitations through a sophisticated
initialization and training pipeline. Our process begins by training a
foundational model on a general public dataset to establish a competent
starting point. This model then undergoes a serial meta-initialization phase,
where it sequentially trains on a subset of IOT Device data to learn a
heterogeneity-aware initialization that is already situated in a favorable
region of the loss landscape. This informed model is subsequently refined in a
parallel FL phase, which utilizes a dual-criterion aggregation mechanism that
weights for IOT devices updates based on both local performance and cosine
similarity alignment. Finally, an on-device personalization phase adapts the
converged global model into a specialized expert for each IOT Device.
Comprehensive experiments demonstrate that Fed-Meta-Align achieves an average
test accuracy of 91.27% across heterogeneous IOT devices, outperforming
personalized FedAvg and FedProx by up to 3.87% and 3.37% on electrical and
mechanical fault datasets, respectively. This multi-stage approach of sequenced
initialization and adaptive aggregation provides a robust pathway for deploying
high-performance intelligence on diverse TinyML networks.

</details>


### [461] [Uncalibrated Reasoning: GRPO Induces Overconfidence for Stochastic Outcomes](https://arxiv.org/abs/2508.11800)
*Michael Bereket,Jure Leskovec*

Main category: cs.LG

TL;DR: 本研究发现 GRPO 在处理随机性强的科学实验数据时，会使语言模型预测结果过于自信，而 PPO 和 RLOO 则表现更好。研究还指出了 GRPO 标准化的问题所在，并提出了改进方法，有助于强化学习在非确定性领域更好地应用于语言模型。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探究当前强化学习（RL）方法在可验证但具有随机结果的领域（如科学实验）中优化语言模型的有效性，特别是与数学等确定性领域进行对比。

Method: 本研究通过应用 GRPO、PPO 和 RLOO 等强化学习方法到合成数据和真实生物实验中，并分析其对语言模型优化和概率预测校准的影响。

Result: GRPO 导致二元随机结果的概率预测出现过度自信，而 PPO 和 RLOO 则能产生校准良好的模型。移除 GRPO 中的组标准化可修复其失校准问题。

Conclusion: 本研究通过对合成数据和真实生物实验的应用，证明了 GRPO 会对二元随机结果产生过度自信的概率预测，而 PPO 和 RLOO 则能产生校准良好的模型。移除非 GRPO 中的组标准化可以修复其失校准问题，并为 GRPO 标准化为何会导致过度自信提供了理论解释。

Abstract: Reinforcement learning (RL) has proven remarkably effective at improving the
accuracy of language models in verifiable and deterministic domains like
mathematics. Here, we examine if current RL methods are also effective at
optimizing language models in verifiable domains with stochastic outcomes, like
scientific experiments. Through applications to synthetic data and real-world
biological experiments, we demonstrate that Group Relative Policy Optimization
(GRPO) induces overconfident probability predictions for binary stochastic
outcomes, while Proximal Policy Optimization (PPO) and REINFORCE Leave-One-Out
(RLOO) yield well-calibrated models. We show that removing group standard
normalization in GRPO fixes its miscalibration and provide a theoretical
explanation for why normalization causes overconfidence. Our results provide
new evidence against the use of standard normalization in GRPO and help pave
the way for applications of RL for reasoning language models beyond
deterministic domains.

</details>


### [462] [FairTabGen: Unifying Counterfactual and Causal Fairness in Synthetic Tabular Data Generation](https://arxiv.org/abs/2508.11810)
*Nitish Nagesh,Salar Shakibhamedan,Mahdi Bagheri,Ziyu Wang,Nima TaheriNejad,Axel Jantsch,Amir M. Rahmani*

Main category: cs.LG

TL;DR: FairTabGen 是一个用于生成公平且有用的合成表格数据的 LLM 框架，在保持高数据效用的同时，通过其生成和评估流程中的反事实和因果公平性指标提高了公平性。


<details>
  <summary>Details</summary>
Motivation: 生成合成数据对于隐私敏感、数据稀缺的环境至关重要，特别是对于广泛应用于现实世界的表格数据集。关键挑战在于在保持高效用的同时提高反事实和因果公平性。

Method: FairTabGen 是一个基于 LLM 的、感知公平性的框架，用于生成表格合成数据，通过集成多种公平性定义（包括反事实和因果公平性）到其生成和评估流程中。它使用上下文学习、提示优化和感知公平性的数据策展来平衡公平性和效用。

Result: FairTabGen 在公平性指标（如人口统计均等和路径特定因果效应）方面取得了高达 10% 的改进，同时保留了统计效用，并且在低数据环境下效率很高，仅使用了不到 20% 的原始数据。

Conclusion: FairTabGen 为表格合成数据生成提供了一种原则性和实用性的方法，可以生成公平且有用的合成表格数据。

Abstract: Generating synthetic data is crucial in privacy-sensitive, data-scarce
settings, especially for tabular datasets widely used in real-world
applications. A key challenge is improving counterfactual and causal fairness,
while preserving high utility. We present FairTabGen, a fairness-aware large
language model-based framework for tabular synthetic data generation. We
integrate multiple fairness definitions including counterfactual and causal
fairness into both its generation and evaluation pipelines. We use in-context
learning, prompt refinement, and fairness-aware data curation to balance
fairness and utility. Across diverse datasets, our method outperforms
state-of-the-art GAN-based and LLM-based methods, achieving up to 10%
improvements on fairness metrics such as demographic parity and path-specific
causal effects while retaining statistical utility. Remarkably, it achieves
these gains using less than 20% of the original data, highlighting its
efficiency in low-data regimes. These results demonstrate a principled and
practical approach for generating fair and useful synthetic tabular data.

</details>


### [463] [Combinations of Fast Activation and Trigonometric Functions in Kolmogorov-Arnold Networks](https://arxiv.org/abs/2508.11876)
*Hoang-Thang Ta,Duy-Quy Thai,Phuong-Linh Tran-Thi*

Main category: cs.LG

TL;DR: 本研究提出将 ReLU 和三角函数等快速计算函数用于 Kolmogorov-Arnold 网络 (KANs)，以提高计算效率和泛化能力，实验结果显示出积极效果。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有基于 KART 的 KANs 使用 B 样条和 RBF 等计算效率较低且 GPU 支持不完善的函数的问题，本研究旨在通过引入快速计算函数来提高 KANs 的计算效率。

Method: 提出将 ReLU 和三角函数（如 sin, cos, arctan）等快速计算函数作为基函数，整合到 Kolmogorov-Arnold 网络 (KANs) 的结构中。

Result: 实验结果表明，将 ReLU 和三角函数等组合并整合到 KANs 中，在保持竞争力的同时，在训练时间和泛化能力方面具有潜在的改进。

Conclusion: 通过整合 ReLU 和三角函数等快速计算函数作为基函数，本研究提出的 Kolmogorov-Arnold 网络 (KANs) 在保持竞争力的同时，有望提高训练时间和泛化能力。

Abstract: For years, many neural networks have been developed based on the
Kolmogorov-Arnold Representation Theorem (KART), which was created to address
Hilbert's 13th problem. Recently, relying on KART, Kolmogorov-Arnold Networks
(KANs) have attracted attention from the research community, stimulating the
use of polynomial functions such as B-splines and RBFs. However, these
functions are not fully supported by GPU devices and are still considered less
popular. In this paper, we propose the use of fast computational functions,
such as ReLU and trigonometric functions (e.g., ReLU, sin, cos, arctan), as
basis components in Kolmogorov-Arnold Networks (KANs). By integrating these
function combinations into the network structure, we aim to enhance
computational efficiency. Experimental results show that these combinations
maintain competitive performance while offering potential improvements in
training time and generalization.

</details>


### [464] [PCA- and SVM-Grad-CAM for Convolutional Neural Networks: Closed-form Jacobian Expression](https://arxiv.org/abs/2508.11880)
*Yuto Omae*

Main category: cs.LG

TL;DR: CNN在样本不足时，集成PCA/SVM可提性能。本文提出PCA-Grad-CAM和SVM-Grad-CAM，解决Grad-CAM无法可视化PCA/SVM层的问题，通过推导雅可比矩阵的闭合形式实现精确可视化，并在多个数据集上验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 在训练样本有限的情况下，将PCA和/或SVM分类器集成到CNN中可以有效提高分类性能。然而，传统的Grad-CAM方法无法直接应用于PCA和/或SVM层，因此需要生成这些层在CNN中的注意区域，以促进白盒方法的发展。

Method: 本文提出PCA-Grad-CAM和SVM-Grad-CAM方法，通过推导从最后一个卷积层到PCA和/或SVM层的偏导数（雅可比矩阵）的闭合形式，来实现对PCA和SVM层中注意区域的可视化。

Result: 本文成功推导了雅可比矩阵的闭合形式，并通过在多个主要数据集上应用所提出的PCA-Grad-CAM和SVM-Grad-CAM方法，展示了可视化结果。

Conclusion: 本文提出了PCA-Grad-CAM和SVM-Grad-CAM方法，用于可视化CNN中PCA和SVM层中的注意区域，解决了传统Grad-CAM无法直接应用于这些层的问题。通过推导解析形式的雅可比矩阵，实现了对这些层的精确可视化。

Abstract: Convolutional Neural Networks (CNNs) are an effective approach for
classification tasks, particularly when the training dataset is large. Although
CNNs have long been considered a black-box classification method, they can be
used as a white-box method through visualization techniques such as Grad-CAM.
When training samples are limited, incorporating a Principal Component Analysis
(PCA) layer and/or a Support Vector Machine (SVM) classifier into a CNN can
effectively improve classification performance. However, traditional Grad-CAM
cannot be directly applied to PCA and/or SVM layers. It is important to
generate attention regions for PCA and/or SVM layers in CNNs to facilitate the
development of white-box methods. Therefore, we propose ``PCA-Grad-CAM'', a
method for visualizing attention regions in PCA feature vectors, and
``SVM-Grad-CAM'', a method for visualizing attention regions in an SVM
classifier layer. To complete our methods analytically, it is necessary to
solve the closed-form Jacobian consisting of partial derivatives from the last
convolutional layer to the PCA and/or SVM layers. In this paper, we present the
exact closed-form Jacobian and the visualization results of our methods applied
to several major datasets.

</details>


### [465] [ENA: Efficient N-dimensional Attention](https://arxiv.org/abs/2508.11921)
*Yibo Zhong*

Main category: cs.LG

TL;DR: ENA是一种结合了线性递增和高阶SWA的混合架构，能够高效地模拟超长高阶数据。


<details>
  <summary>Details</summary>
Motivation: 为了更有效地模拟长序列高阶数据，需要比Transformer更高效的架构。

Method: 研究了线性递增模型在扫描策略和注意力混合架构方面的扩展，并评估了不同类型的注意力，最终确定了块状高阶滑动窗口注意力（SWA）。

Result: 扫描策略的效益有限，而注意力混合模型取得了有希望的结果，其中块状高阶滑动窗口注意力（SWA）在理论和实践中都具有效率。

Conclusion: 线性递归和高阶SWA的混合架构ENA为超长高阶数据建模提供了一种有前景且实用的解决方案。

Abstract: Efficient modeling of long sequences of high-order data requires a more
efficient architecture than Transformer. In this paper, we investigate two key
aspects of extending linear recurrent models, especially those originally
designed for language modeling, to high-order data (1D to ND): scanning
strategies and attention-hybrid architectures. Empirical results suggest that
scanning provides limited benefits, while attention-hybrid models yield
promising results. Focusing on the latter, we further evaluate types of
attention and find that tiled high-order sliding window attention (SWA) is
efficient in both theory and practice. We term the resulting hybrid
architecture of linear recurrence and high-order SWA as Efficient N-dimensional
Attention (ENA). We then conduct several experiments to demonstrate its
effectiveness. The intuition behind ENA is that linear recurrence compresses
global information into a state, while SWA complements it by enforcing strict
local modeling. Together, they form a simple framework that offers a promising
and practical solution for ultra-long high-order data modeling.

</details>


### [466] [Scale-Disentangled spatiotemporal Modeling for Long-term Traffic Emission Forecasting](https://arxiv.org/abs/2508.11923)
*Yan Wu,Lihong Pei,Yukai Han,Yang Cao,Yu Kang,Yanlong Zhao*

Main category: cs.LG

TL;DR: SDSTM框架通过尺度解耦和对偶流特征分解/融合，解决了传统模型长时程推理中的级联误差放大问题，在交通排放预测任务上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的时空图模型在长时程推理中容易出现级联误差放大的问题，因为交通排放存在多尺度的时空纠缠。

Method: 提出了一种尺度解耦时空建模（SDSTM）框架，利用不同尺度的可预测性差异来分解和融合不同尺度的特征，同时约束它们保持独立但互补。具体来说，模型首先引入基于Koopman提升算子的对偶流特征分解策略，通过Koopman算子将尺度耦合的时空动力学系统提升到无限维线性空间，并使用门控小波分解来描绘可预测性边界。然后，构建了一种新颖的融合机制，结合基于交叉项损失的对偶流独立性约束，动态地提炼对偶流预测结果，抑制相互干扰，提高长期交通排放预测的准确性。

Result: SDSTM框架在长时程交通排放预测方面取得了最先进的性能。

Conclusion: SDSTM框架在西安二环路交通排放数据集上实现了最先进的性能。

Abstract: Long-term traffic emission forecasting is crucial for the comprehensive
management of urban air pollution. Traditional forecasting methods typically
construct spatiotemporal graph models by mining spatiotemporal dependencies to
predict emissions. However, due to the multi-scale entanglement of traffic
emissions across time and space, these spatiotemporal graph modeling method
tend to suffer from cascading error amplification during long-term inference.
To address this issue, we propose a Scale-Disentangled Spatio-Temporal Modeling
(SDSTM) framework for long-term traffic emission forecasting. It leverages the
predictability differences across multiple scales to decompose and fuse
features at different scales, while constraining them to remain independent yet
complementary. Specifically, the model first introduces a dual-stream feature
decomposition strategy based on the Koopman lifting operator. It lifts the
scale-coupled spatiotemporal dynamical system into an infinite-dimensional
linear space via Koopman operator, and delineates the predictability boundary
using gated wavelet decomposition. Then a novel fusion mechanism is
constructed, incorporating a dual-stream independence constraint based on
cross-term loss to dynamically refine the dual-stream prediction results,
suppress mutual interference, and enhance the accuracy of long-term traffic
emission prediction. Extensive experiments conducted on a road-level traffic
emission dataset within Xi'an's Second Ring Road demonstrate that the proposed
model achieves state-of-the-art performance.

</details>


### [467] [An Improved Algorithm for Adversarial Linear Contextual Bandits via Reduction](https://arxiv.org/abs/2508.11931)
*Tim van Erven,Jack Mayo,Julia Olkhovskaya,Chen-Yu Wei*

Main category: cs.LG

TL;DR: 本文提出了一种高效算法，解决了带有对抗性损失和随机动作集的线性赌徒问题，在没有模拟器的情况下实现了 O(tilde(min{d^2*sqrt(T), sqrt(d^3*T*log K)})) 的遗憾，并且是首个在组合赌徒问题中实现 O(poly(d)sqrt(T)) 遗憾的算法。


<details>
  <summary>Details</summary>
Motivation: 为了在忽略上下文分布知识或上下文模拟器的情况下，为带有对抗性损失和随机动作集的线性赌徒问题提供一个高效的算法，并解决 Liu 等人 (2023) 关于是否能在多项式时间内获得 O(poly(d)sqrt(T)) 遗憾的开放性问题。

Method: 该算法将带有对抗性损失和随机动作集的线性赌徒问题，转化为具有固定动作集的、可容忍错误指定的对抗性线性赌徒问题。

Result: 在没有上下文模拟器的情况下，算法实现了 O(tilde(min{d^2*sqrt(T), sqrt(d^3*T*log K)})) 的遗憾，并且运行时间为 O(poly(d, C, T))。在存在模拟器的情况下，遗憾界提升至 O(tilde(d*sqrt(L*)))。

Conclusion: 本文提出的算法首次在组合赌徒问题中实现了多项式时间内的 O(poly(d)sqrt(T)) 遗憾，解决了 Liu 等人 (2023) 提出的开放性问题。在有模拟器的情况下，遗憾界可进一步提升至 O(tilde(d*sqrt(L*)))。

Abstract: We present an efficient algorithm for linear contextual bandits with
adversarial losses and stochastic action sets. Our approach reduces this
setting to misspecification-robust adversarial linear bandits with fixed action
sets. Without knowledge of the context distribution or access to a context
simulator, the algorithm achieves $\tilde{O}(\min\{d^2\sqrt{T}, \sqrt{d^3T\log
K}\})$ regret and runs in $\text{poly}(d,C,T)$ time, where $d$ is the feature
dimension, $C$ is an upper bound on the number of linear constraints defining
the action set in each round, $K$ is an upper bound on the number of actions in
each round, and $T$ is number of rounds. This resolves the open question by Liu
et al. (2023) on whether one can obtain $\text{poly}(d)\sqrt{T}$ regret in
polynomial time independent of the number of actions. For the important class
of combinatorial bandits with adversarial losses and stochastic action sets
where the action sets can be described by a polynomial number of linear
constraints, our algorithm is the first to achieve $\text{poly}(d)\sqrt{T}$
regret in polynomial time, while no prior algorithm achieves even $o(T)$ regret
in polynomial time to our knowledge. When a simulator is available, the regret
bound can be improved to $\tilde{O}(d\sqrt{L^\star})$, where $L^\star$ is the
cumulative loss of the best policy.

</details>


### [468] [M3OOD: Automatic Selection of Multimodal OOD Detectors](https://arxiv.org/abs/2508.11936)
*Yuehan Qin,Li Li,Defu Cao,Tiankai Yang,Yue Zhao*

Main category: cs.LG

TL;DR: M3OOD是一个元学习框架，用于在多模态设置中选择OOD检测器，通过学习历史模型行为和利用数据集的元特征，能在新的数据分布下快速推荐合适的检测器，实验结果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前OOD检测方法在不同分布偏移场景下表现不一，需要一种自动选择理想OOD检测模型的方法，但OOD检测任务的无监督性质和系统比较成本高昂是主要挑战。

Method: 提出了一种基于元学习的框架M3OOD，通过结合多模态嵌入和手工制作的元特征（捕捉分布和跨模态特性）来表示数据集，并利用历史模型行为进行学习，以快速适应新的数据分布变化。

Result: 实验评估表明，M3OOD在多模态OOD检测模型选择任务上表现出色，能够为新的数据分布偏移推荐合适的检测器。

Conclusion: M3OOD框架在12个测试场景中，优于10个基线模型，且计算开销极小，展示了其在多模态OOD检测模型选择方面的有效性。

Abstract: Out-of-distribution (OOD) robustness is a critical challenge for modern
machine learning systems, particularly as they increasingly operate in
multimodal settings involving inputs like video, audio, and sensor data.
Currently, many OOD detection methods have been proposed, each with different
designs targeting various distribution shifts. A single OOD detector may not
prevail across all the scenarios; therefore, how can we automatically select an
ideal OOD detection model for different distribution shifts? Due to the
inherent unsupervised nature of the OOD detection task, it is difficult to
predict model performance and find a universally Best model. Also,
systematically comparing models on the new unseen data is costly or even
impractical. To address this challenge, we introduce M3OOD, a
meta-learning-based framework for OOD detector selection in multimodal
settings. Meta learning offers a solution by learning from historical model
behaviors, enabling rapid adaptation to new data distribution shifts with
minimal supervision. Our approach combines multimodal embeddings with
handcrafted meta-features that capture distributional and cross-modal
characteristics to represent datasets. By leveraging historical performance
across diverse multimodal benchmarks, M3OOD can recommend suitable detectors
for a new data distribution shift. Experimental evaluation demonstrates that
M3OOD consistently outperforms 10 competitive baselines across 12 test
scenarios with minimal computational overhead.

</details>


### [469] [Learning Marked Temporal Point Process Explanations based on Counterfactual and Factual Reasoning](https://arxiv.org/abs/2508.11943)
*Sishun Liu,Ke Deng,Xiuzhen Zhang,Yan Wang*

Main category: cs.LG

TL;DR: 本研究提出了一种新的MTPP模型解释方法CFF，通过结合反事实和事实解释，能够生成更优、更高效的解释。


<details>
  <summary>Details</summary>
Motivation: 为了解决MTPP模型在关键应用中输出的可信度问题，本研究着重于为MTPP提供解释，旨在找到一个最小且有意义的解释，即历史事件的最小子集，使得基于该子集的MTPP预测准确率在很大程度上能匹配基于完整历史的预测准确率，并且优于基于该子集补集的预测准确率。

Method: 本研究提出了一种结合了反事实和事实解释的MTPP模型解释新定义，并实现了一种名为CFF（Counterfactual and Factual Explainer）的模型来解决MTPP模型解释问题，采用了包括一系列精心设计的技术。

Result: 实验结果表明，CFF模型在解释质量和处理效率方面优于基线模型，验证了其正确性和优越性。

Conclusion: 本研究提出的CFF模型能够生成最简且有意义的MTPP模型解释，并且在解释质量和处理效率方面优于现有基线模型。

Abstract: Neural network-based Marked Temporal Point Process (MTPP) models have been
widely adopted to model event sequences in high-stakes applications, raising
concerns about the trustworthiness of outputs from these models. This study
focuses on Explanation for MTPP, aiming to identify the minimal and rational
explanation, that is, the minimum subset of events in history, based on which
the prediction accuracy of MTPP matches that based on full history to a great
extent and better than that based on the complement of the subset. This study
finds that directly defining Explanation for MTPP as counterfactual explanation
or factual explanation can result in irrational explanations. To address this
issue, we define Explanation for MTPP as a combination of counterfactual
explanation and factual explanation. This study proposes Counterfactual and
Factual Explainer for MTPP (CFF) to solve Explanation for MTPP with a series of
deliberately designed techniques. Experiments demonstrate the correctness and
superiority of CFF over baselines regarding explanation quality and processing
efficiency.

</details>


### [470] [Set-Valued Transformer Network for High-Emission Mobile Source Identification](https://arxiv.org/abs/2508.11976)
*Yunning Cao,Lihong Pei,Jian Guo,Yang Cao,Yu Kang,Yanlong Zhao*

Main category: cs.LG

TL;DR: 针对车辆排放数据长尾分布和非线性问题，提出SVTN模型，通过Transformer提取特征，集合值算法进行概率建模，实验证明该方法能有效降低高排放车辆漏检率。


<details>
  <summary>Details</summary>
Motivation: 实际监测数据中高排放状态数据的比例远低于正常排放状态，这种长尾分布特征严重阻碍了数据挖掘过程中用于识别排放状态的判别性特征的提取。此外，车辆排放状态的高度非线性性质和相关先验知识的缺乏也给识别模型的构建带来了巨大挑战。

Method: 提出了一种集合值Transformer网络（SVTN），首先利用Transformer测量微行程条件变化的 temporal similarity，将原始高维排放数据映射到低维特征空间，然后使用集合值识别算法对生成的特征向量及其标签之间的关系进行概率建模，为分类算法提供准确的度量标准。

Result: 在2020年合肥市柴油车监测数据上进行的广泛实验表明，与基于Transformer的基线模型相比，所提出的方法将高排放车辆的漏检率降低了9.5%，证明了其在准确识别高排放移动污染源方面的优越能力。

Conclusion: 所提出的SVTN模型在识别高排放车辆方面表现优于基于Transformer的基线模型，能够显著降低漏检率，有效提升检测准确性。

Abstract: Identifying high-emission vehicles is a crucial step in regulating urban
pollution levels and formulating traffic emission reduction strategies.
However, in practical monitoring data, the proportion of high-emission state
data is significantly lower compared to normal emission states. This
characteristic long-tailed distribution severely impedes the extraction of
discriminative features for emission state identification during data mining.
Furthermore, the highly nonlinear nature of vehicle emission states and the
lack of relevant prior knowledge also pose significant challenges to the
construction of identification models.To address the aforementioned issues, we
propose a Set-Valued Transformer Network (SVTN) to achieve comprehensive
learning of discriminative features from high-emission samples, thereby
enhancing detection accuracy. Specifically, this model first employs the
transformer to measure the temporal similarity of micro-trip condition
variations, thus constructing a mapping rule that projects the original
high-dimensional emission data into a low-dimensional feature space. Next, a
set-valued identification algorithm is used to probabilistically model the
relationship between the generated feature vectors and their labels, providing
an accurate metric criterion for the classification algorithm. To validate the
effectiveness of our proposed approach, we conducted extensive experiments on
the diesel vehicle monitoring data of Hefei city in 2020. The results
demonstrate that our method achieves a 9.5\% reduction in the missed detection
rate for high-emission vehicles compared to the transformer-based baseline,
highlighting its superior capability in accurately identifying high-emission
mobile pollution sources.

</details>


### [471] [Efficient Modular Learning through Naive LoRA Summation: Leveraging Orthogonality in High-Dimensional Models](https://arxiv.org/abs/2508.11985)
*Zhanhao Cao,Clement Truong,Andrew Lizarraga*

Main category: cs.LG

TL;DR: 通过简单加法组合LoRA模块，可以实现高效的模型适配，性能接近合并数据微调，且无需额外训练。


<details>
  <summary>Details</summary>
Motivation: 基于叠加原理，假设独立训练的LoRA模块在不相交的领域上近似正交，可以通过简单加法组合。

Method: 通过在GPT-2 Small (117M)模型上使用LoRA（秩为4，alpha为64）为三个问答领域（数学、医学、金融）训练适配器，并进行成对测试，以及分析LoRA delta之间的RMS余弦相似性与困惑度变化的相关性。

Result: 成对测试中，Math+Medicine适配器的加法组合将困惑度相对合并数据微调降低了-9.10%，而Math+Finance和Finance+Medicine的组合分别增加了+4.54%和+27.56%。LoRA delta之间的RMS余弦相似性与困惑度变化呈正相关且近似线性。

Conclusion: LoRA模块的简单加法组合在不需要额外训练的情况下，可以达到与合并数据微调相当的性能，并且能够阐明在高阶组合中何时会出现干扰。

Abstract: Recent advances in large language models are driven by scale, while
parameter-efficient fine-tuning (PEFT) enables updating only a small fraction
of parameters. Low-Rank Adaptation (LoRA) stores parameter deltas as the
product of two small matrices, which makes them natural building blocks that
can be composed. Motivated by the superposition principle, we hypothesize that
independently trained LoRA modules on disjoint domains are approximately
orthogonal and can be combined by simple addition. Using GPT-2 Small (117M)
with LoRA rank 4 and alpha=64, we train adapters for three QA domains (math,
medicine, finance). In pairwise tests, adding Math+Medicine adapters improves
perplexity by -9.10% relative to merged-data fine-tuning, while Math+Finance
and Finance+Medicine change by +4.54% and +27.56%, respectively. Across
combinations, the RMS cosine similarity between LoRA deltas correlates
positively and approximately linearly with the change in perplexity. Naive
summation requires no additional training, can be applied in seconds, and
achieves performance comparable to models trained on merged data, while
clarifying when interference appears in higher-order compositions.

</details>


### [472] [Universal Learning of Nonlinear Dynamics](https://arxiv.org/abs/2508.11990)
*Evan Dogariu,Anand Brahmbhatt,Elad Hazan*

Main category: cs.LG

TL;DR: 提出一种基于谱滤波的算法，可以学习非线性动力学系统，并证明了其预测误差可消除。


<details>
  <summary>Details</summary>
Motivation: 研究学习边缘稳定未知非线性动力学系统的基础问题。

Method: 提出了一种基于谱滤波技术、从过去观测值学习到下一个观测值的算法，该算法基于系统的谱表示。

Result: 证明了该算法对于任何具有有限个边缘稳定模式的非线性动力学系统，预测误差都能消失，并且具有由新颖的定量控制理论学习概念所决定的收敛速率。该方法的主要技术组成部分是用于线性动力学系统的新型谱滤波算法，该算法能够结合过去的观测值，并适用于一般的有噪声和边缘稳定的系统。

Conclusion: 该算法能学习任何具有有限个边缘稳定模式的非线性动力学系统，并具有可消除的预测误差。

Abstract: We study the fundamental problem of learning a marginally stable unknown
nonlinear dynamical system. We describe an algorithm for this problem, based on
the technique of spectral filtering, which learns a mapping from past
observations to the next based on a spectral representation of the system.
Using techniques from online convex optimization, we prove vanishing prediction
error for any nonlinear dynamical system that has finitely many marginally
stable modes, with rates governed by a novel quantitative control-theoretic
notion of learnability. The main technical component of our method is a new
spectral filtering algorithm for linear dynamical systems, which incorporates
past observations and applies to general noisy and marginally stable systems.
This significantly generalizes the original spectral filtering algorithm to
both asymmetric dynamics as well as incorporating noise correction, and is of
independent interest.

</details>


### [473] [Fairness Regularization in Federated Learning](https://arxiv.org/abs/2508.12042)
*Zahra Kharaghani,Ali Dadras,Tommy Löfstedt*

Main category: cs.LG

TL;DR: 本文研究了联邦学习中的公平性问题，提出了一种名为 FairGrad 的新方法，该方法通过正则化客户端损失来提高模型的公平性和整体性能，尤其是在数据不一致的情况下。


<details>
  <summary>Details</summary>
Motivation: 现有的 FL 公平性方法在数据异构环境下效果不明确，且不同方法间的关系尚不清晰。因此，有必要深入研究并提出更有效的方法。

Method: 本文提出并评估了 FairGrad 和 FairGrad* 两种基于梯度方差正则化的方法，以解决 FL 中的性能公平性问题，并与现有方法进行了对比。

Result: FairGrad 和 FairGrad* 在异构数据设置下，能够有效提升 FL 模型的公平性和整体性能，并且本文对这些方法进行了理论和实证分析，揭示了它们之间的联系。

Conclusion: Federated Learning (FL) 中的性能公平性是一个关键问题，尤其是在数据异构的情况下。本文提出的 FairGrad 和 FairGrad* 方法通过正则化客户端损失，在异构数据设置下能够同时提升公平性和模型整体性能。

Abstract: Federated Learning (FL) has emerged as a vital paradigm in modern machine
learning that enables collaborative training across decentralized data sources
without exchanging raw data. This approach not only addresses privacy concerns
but also allows access to overall substantially larger and potentially more
diverse datasets, without the need for centralized storage or hardware
resources. However, heterogeneity in client data may cause certain clients to
have disproportionate impacts on the global model, leading to disparities in
the clients' performances. Fairness, therefore, becomes a crucial concern in FL
and can be addressed in various ways. However, the effectiveness of existing
fairness-aware methods, particularly in heterogeneous data settings, remains
unclear, and the relationships between different approaches are not well
understood. In this work, we focus on performance equitable fairness, which
aims to minimize differences in performance across clients. We restrict our
study to fairness-aware methods that explicitly regularize client losses,
evaluating both existing and newly proposed approaches. We identify and
theoretically explain connections between the investigated fairness methods,
and empirically show that FairGrad (approximate) and FairGrad* (exact) (two
variants of a gradient variance regularization method introduced here for
performance equitable fairness) improve both fairness and overall model
performance in heterogeneous data settings.

</details>


### [474] [VARAN: Variational Inference for Self-Supervised Speech Models Fine-Tuning on Downstream Tasks](https://arxiv.org/abs/2508.12061)
*Daria Diatlova,Nikita Balagansky,Alexander Varlamov,Egor Spirin*

Main category: cs.LG

TL;DR: VARAN是一种新的框架，可以动态地为每个输入定制层聚合，优于传统的固定方法，尤其是在使用LoRA时。


<details>
  <summary>Details</summary>
Motivation: 解决现有模型在聚合层时存在的信​​息瓶颈和静态特征加权问题。

Method: 提出VARAN框架，通过层专业探针头和数据相关加权，根据输入动态地优先化层的特征。

Result: VARAN在自动语音识别和语音情感识别任务上展示了优越的性能，尤其是在使用LoRA微调技术时。

Conclusion: VARAN框架通过动态调整层聚合以适应单个输入，解决了保留层特定信息与实现灵活特征利用之间的权衡，推动了自监督语音表示的高效适应性。

Abstract: Conventional methods for aggregating layers in fine-tuned self-supervised
speech models, such as using the final layer or weighted sum, suffer from
information bottlenecks and static feature weighting for all dataset examples.
We propose VARAN, a framework that dynamically tailors layer aggregation to
individual inputs. By employing layer-specialized probing heads and
data-dependent weighting, VARAN adaptively prioritizes layer's features based
on input. Evaluations on automatic speech recognition and speech emotion
recognition tasks demonstrate VARAN's superior performance, particularly when
using the LoRA fine-tuning technique. The framework resolves the trade-off
between preserving layer-specific information and enabling flexible feature
utilization, advancing efficient adaptation of self-supervised speech
representations.

</details>


### [475] [Content Accuracy and Quality Aware Resource Allocation Based on LP-Guided DRL for ISAC-Driven AIGC Networks](https://arxiv.org/abs/2508.12079)
*Ningzhe Shi,Yiqing Zhou,Ling Liu,Jinglin Shi,Yihao Wu,Haiwei Shi,Hanxiao Yu*

Main category: cs.LG

TL;DR: 本文提出了一种新的评估指标CAQA来衡量ISAC-AIGC服务的体验质量，并开发了一种名为LPDRL-F的算法来优化资源分配。该算法比现有方法更快、更好，并将AvgCAQA提高了50%以上。


<details>
  <summary>Details</summary>
Motivation: 现有AIGC网络通常假设输入数据准确，只关注内容生成质量（CGQ）。然而，在基于不准确感知数据的ISAC-AIGC网络中，内容生成会引入误差，并且生成误差与计算资源（生成步数）相关。为了评估ISAC-AIGC服务的体验质量，需要考虑内容准确性和生成质量，并优化感知、生成（计算）和通信三维资源分配以最大化平均CAQA（AvgCAQA）。

Method: 本文提出了一种内容准确性和质量感知的服务评估指标（CAQA），并提出了一种线性规划（LP）引导的深度强化学习（DRL）算法（LPDRL-F）来解决ISAC-AIGC的资源分配问题。该算法通过LP引导和动作过滤将原始的三维解空间转化为二维，降低了复杂度并提高了学习性能。

Result: 仿真结果表明，与现有不包含LP的DRL和生成扩散模型算法相比，LPDRL-F收敛速度快60%以上，并且能找到更好的资源分配解决方案，从而将AvgCAQA提升超过14%。与仅关注CGQ的现有方案相比，LPDRL-F在AvgCAQA方面可实现50%以上的提升。

Conclusion: LPDRL-F算法通过将原始三维解空间转化为二维，降低了复杂度并提高了DRL的学习性能，与现有不包含LP的DRL和生成扩散模型算法相比，LPDRL-F收敛速度快60%以上，资源分配解决方案更好，AvgCAQA提升超过14%。与仅关注CGQ的现有方案相比，LPDRL-F在AvgCAQA方面可实现50%以上的提升。

Abstract: Integrated sensing and communication (ISAC) can enhance artificial
intelligence-generated content (AIGC) networks by providing efficient sensing
and transmission. Existing AIGC services usually assume that the accuracy of
the generated content can be ensured, given accurate input data and prompt,
thus only the content generation quality (CGQ) is concerned. However, it is not
applicable in ISAC-based AIGC networks, where content generation is based on
inaccurate sensed data. Moreover, the AIGC model itself introduces generation
errors, which depend on the number of generating steps (i.e., computing
resources). To assess the quality of experience of ISAC-based AIGC services, we
propose a content accuracy and quality aware service assessment metric (CAQA).
Since allocating more resources to sensing and generating improves content
accuracy but may reduce communication quality, and vice versa, this
sensing-generating (computing)-communication three-dimensional resource
tradeoff must be optimized to maximize the average CAQA (AvgCAQA) across all
users with AIGC (CAQA-AIGC). This problem is NP-hard, with a large solution
space that grows exponentially with users. To solve the CAQA-AIGC problem with
low complexity, a linear programming (LP) guided deep reinforcement learning
(DRL) algorithm with an action filter (LPDRL-F) is proposed. Through the
LP-guided approach and the action filter, LPDRL-F can transform the original
three-dimensional solution space to two dimensions, reducing complexity while
improving the learning performance of DRL. Simulations show that compared to
existing DRL and generative diffusion model algorithms without LP, LPDRL-F
converges faster by over 60% and finds better resource allocation solutions,
improving AvgCAQA by more than 14%. With LPDRL-F, CAQA-AIGC can achieve an
improvement in AvgCAQA of more than 50% compared to existing schemes focusing
solely on CGQ.

</details>


### [476] [Generative Medical Event Models Improve with Scale](https://arxiv.org/abs/2508.12104)
*Shane Waxler,Paul Blazek,Davis White,Daniel Sneider,Kevin Chung,Mani Nagarathnam,Patrick Williams,Hank Voeller,Karen Wong,Matthew Swanhorst,Sheng Zhang,Naoto Usuyama,Cliff Wong,Tristan Naumann,Hoifung Poon,Andrew Loza,Daniella Meeker,Seth Hain,Rahul Shah*

Main category: cs.LG

TL;DR: CoMET是一个基于Transformer的生成式医疗基础模型，在大规模医疗事件数据上进行预训练，能够模拟患者健康时间线，并在多项临床任务中表现优于或匹配特定任务的监督模型。


<details>
  <summary>Details</summary>
Motivation: 为了在大规模上实现个性化医疗，需要能够从纵向患者历程中提取见解的方法，这些历程可以被视为医疗事件序列。在大规模医疗事件数据上预训练的基础模型，代表了扩展真实世界证据生成和泛化到不同下游任务的有希望的方向。

Method: 本文介绍了Cosmos医疗事件Transformer（CoMET）模型，这是一系列基于Transformer的解码器模型，在大规模医疗事件数据上进行了预训练。研究进行了医疗事件数据最大规模的扩展定律研究，建立了一种预训练方法，并揭示了计算、标记和模型大小的幂律扩展关系。基于此，研究预训练了一系列计算最优模型，参数量高达10亿。CoMET在给定患者的真实世界历史条件下，自回归地生成下一个医疗事件，模拟患者健康时间线。

Result: CoMET在78个真实世界任务（包括诊断预测、疾病预后和医疗运营）中的表现，通常优于或匹配了特定任务的监督模型，而无需任务特定的微调或少样本示例。随着模型和预训练的扩展，CoMET的预测能力持续提高。

Conclusion: CoMET是一个生成式医疗事件基础模型，能够有效捕捉复杂的临床动态，为支持临床决策、简化医疗运营和改善患者结果提供了一个可扩展且可泛化的框架。

Abstract: Realizing personalized medicine at scale calls for methods that distill
insights from longitudinal patient journeys, which can be viewed as a sequence
of medical events. Foundation models pretrained on large-scale medical event
data represent a promising direction for scaling real-world evidence generation
and generalizing to diverse downstream tasks. Using Epic Cosmos, a dataset with
medical events from de-identified longitudinal health records for 16.3 billion
encounters over 300 million unique patient records from 310 health systems, we
introduce the Cosmos Medical Event Transformer ( CoMET) models, a family of
decoder-only transformer models pretrained on 118 million patients representing
115 billion discrete medical events (151 billion tokens). We present the
largest scaling-law study for medical event data, establishing a methodology
for pretraining and revealing power-law scaling relationships for compute,
tokens, and model size. Based on this, we pretrained a series of
compute-optimal models with up to 1 billion parameters. Conditioned on a
patient's real-world history, CoMET autoregressively generates the next medical
event, simulating patient health timelines. We studied 78 real-world tasks,
including diagnosis prediction, disease prognosis, and healthcare operations.
Remarkably for a foundation model with generic pretraining and simulation-based
inference, CoMET generally outperformed or matched task-specific supervised
models on these tasks, without requiring task-specific fine-tuning or few-shot
examples. CoMET's predictive power consistently improves as the model and
pretraining scale. Our results show that CoMET, a generative medical event
foundation model, can effectively capture complex clinical dynamics, providing
an extensible and generalizable framework to support clinical decision-making,
streamline healthcare operations, and improve patient outcomes.

</details>


### [477] [DynamixSFT: Dynamic Mixture Optimization of Instruction Tuning Collections](https://arxiv.org/abs/2508.12116)
*Haebin Shin,Lei Ji,Xiao Liu,Zhiwei Yu,Qi Chen,Yeyun Gong*

Main category: cs.LG

TL;DR: DynamixSFT是一种新的动态数据集混合优化方法，通过模拟多armed bandit问题来提高模型性能，并在实际应用中取得了显著效果。


<details>
  <summary>Details</summary>
Motivation: 在指令调优数据集不断涌现的背景下，动态地平衡和优化数据集混合已成为一个关键挑战。

Method: 提出了一种名为DynamixSFT的动态和自动化方法，用于指令调优数据集混合优化。该方法将问题形式化为多armed bandit设置，并引入了Prior-scaled Boltzmann Exploration，将更新后的采样分布软锚定到原始数据集比例，以保留数据的多样性和覆盖范围。使用轻量级的1-Step Look-ahead Reward来更新采样概率，以反映数据集对模型性能的贡献。

Result: DynamixSFT在Tulu-v2-mixture集合（包含16个指令调优数据集）上实现了高达2.2%的性能提升，涵盖10个基准测试。

Conclusion: DynamixSFT在Tulu-v2-mixture集合上实现了高达2.2%的性能提升，并在10个基准测试中提供了深入的分析和可视化。

Abstract: As numerous instruction-tuning datasets continue to emerge during the
post-training stage, dynamically balancing and optimizing their mixtures has
become a critical challenge. To address this, we propose DynamixSFT, a dynamic
and automated method for instruction-tuning dataset mixture optimization. We
formulate the problem as a multi-armed bandit setup and introduce a
Prior-scaled Boltzmann Exploration that softly anchors the updated sampling
distribution to the original dataset proportions, thereby preserving the
inherent diversity and coverage of the collection. Sampling probabilities are
updated using a lightweight 1-Step Look-ahead Reward, reflecting how much the
dataset contributes to improving the model's performance at its current state.
When applied to the Tulu-v2-mixture collection comprising 16 instruction-tuning
datasets, DynamixSFT achieves up to a 2.2% performance improvement across 10
benchmarks. Furthermore, we provide a comprehensive analysis and visualizations
to offer deeper insights into the adaptive dynamics of our method.

</details>


### [478] [BUILDA: A Thermal Building Data Generation Framework for Transfer Learning](https://arxiv.org/abs/2508.12703)
*Thomas Krug,Fabian Raisch,Dominik Aimer,Markus Wirnsberger,Ferdinand Sigg,Benjamin Schäfer,Benjamin Tischler*

Main category: cs.LG

TL;DR: A new framework called BuilDa generates realistic thermal building data for transfer learning research, addressing the current data scarcity issue and eliminating the need for expert knowledge in building simulation.


<details>
  <summary>Details</summary>
Motivation: The lack of sufficient high-quality thermal building data hinders the advancement of transfer learning (TL) research in data-driven modeling of building thermal dynamics. Existing data sources and generation methods are inadequate, often requiring expert knowledge.

Method: BuilDa, a thermal building data generation framework, uses a single-zone Modelica model exported as a Functional Mock-up Unit (FMU) and simulated in Python to generate synthetic data for transfer learning research.

Result: BuilDa effectively generates synthetic thermal building data in adequate quality and quantity for TL research, enabling pretraining and fine-tuning of TL models without requiring profound building simulation knowledge.

Conclusion: Transfer learning (TL) can improve data-driven modeling of building thermal dynamics, but requires massive amounts of data. Existing datasets and generators are insufficient. BuilDa is a new framework for generating synthetic thermal building data of adequate quality and quantity for TL research, without requiring extensive building simulation knowledge. BuilDa uses a single-zone Modelica model exported as an FMU and simulated in Python. The framework's effectiveness is demonstrated by generating data for pretraining and fine-tuning TL models.

Abstract: Transfer learning (TL) can improve data-driven modeling of building thermal
dynamics. Therefore, many new TL research areas emerge in the field, such as
selecting the right source model for TL. However, these research directions
require massive amounts of thermal building data which is lacking presently.
Neither public datasets nor existing data generators meet the needs of TL
research in terms of data quality and quantity. Moreover, existing data
generation approaches typically require expert knowledge in building
simulation. We present BuilDa, a thermal building data generation framework for
producing synthetic data of adequate quality and quantity for TL research. The
framework does not require profound building simulation knowledge to generate
large volumes of data. BuilDa uses a single-zone Modelica model that is
exported as a Functional Mock-up Unit (FMU) and simulated in Python. We
demonstrate BuilDa by generating data and utilizing it for pretraining and
fine-tuning TL models.

</details>


### [479] [Time-Scale Coupling Between States and Parameters in Recurrent Neural Networks](https://arxiv.org/abs/2508.12121)
*Lorenzo Livi*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We study how gating mechanisms in recurrent neural networks (RNNs) implicitly
induce adaptive learning-rate behavior, even when training is carried out with
a fixed, global learning rate. This effect arises from the coupling between
state-space time scales--parametrized by the gates--and parameter-space
dynamics during gradient descent. By deriving exact Jacobians for
leaky-integrator and gated RNNs, we obtain a first-order expansion that makes
explicit how constant, scalar, and multi-dimensional gates reshape gradient
propagation, modulate effective step sizes, and introduce anisotropy in
parameter updates. These findings reveal that gates not only control memory
retention in the hidden states, but also act as data-driven preconditioners
that adapt optimization trajectories in parameter space. We further draw formal
analogies with learning-rate schedules, momentum, and adaptive methods such as
Adam, showing that these optimization behaviors emerge naturally from gating.
Numerical experiments confirm the validity of our perturbative analysis,
supporting the view that gate-induced corrections remain small while exerting
systematic effects on training dynamics. Overall, this work provides a unified
dynamical-systems perspective on how gating couples state evolution with
parameter updates, explaining why gated architectures achieve robust
trainability and stability in practice.

</details>


### [480] [DE-VAE: Revealing Uncertainty in Parametric and Inverse Projections with Variational Autoencoders using Differential Entropy](https://arxiv.org/abs/2508.12145)
*Frederik L. Dennig,Daniel A. Keim*

Main category: cs.LG

TL;DR: DE-VAE是一种新的自动编码器，它通过差分熵解决了分布外样本问题，实现了准确的参数化和可逆投影，并能分析不确定性。


<details>
  <summary>Details</summary>
Motivation: 现有自动编码器（AE）在创建参数化和可逆投影方面受到关注，但它们在处理数据或嵌入空间中的分布外样本时表现不佳。

Method: DE-VAE是一种不确定性感知的变分自编码器，它利用差分熵（DE）来学习数据的二维空间映射以及从二维空间到原始空间的逆映射。

Result: DE-VAE在四个知名数据集上进行了定量和定性评估，并与UMAP和t-SNE等基线方法进行了比较，证明了其在创建参数化和可逆投影方面的准确性，同时还能进行嵌入不确定性分析。

Conclusion: DE-VAE通过使用差分熵（DE）作为不确定性度量，在保持与其他基于AE方法相当的准确性的同时，能够实现参数化和可逆的投影，并能进行嵌入不确定性分析，解决了现有方法在处理分布外样本时的不足。

Abstract: Recently, autoencoders (AEs) have gained interest for creating parametric and
invertible projections of multidimensional data. Parametric projections make it
possible to embed new, unseen samples without recalculating the entire
projection, while invertible projections allow the synthesis of new data
instances. However, existing methods perform poorly when dealing with
out-of-distribution samples in either the data or embedding space. Thus, we
propose DE-VAE, an uncertainty-aware variational AE using differential entropy
(DE) to improve the learned parametric and invertible projections. Given a
fixed projection, we train DE-VAE to learn a mapping into 2D space and an
inverse mapping back to the original space. We conduct quantitative and
qualitative evaluations on four well-known datasets, using UMAP and t-SNE as
baseline projection methods. Our findings show that DE-VAE can create
parametric and inverse projections with comparable accuracy to other current
AE-based approaches while enabling the analysis of embedding uncertainty.

</details>


### [481] [AICRN: Attention-Integrated Convolutional Residual Network for Interpretable Electrocardiogram Analysis](https://arxiv.org/abs/2508.12162)
*J. M. I. H. Jayakody,A. M. H. H. Alahakoon,C. R. M. Perera,R. M. L. C. Srimal,Roshan Ragel,Vajira Thambawita,Isuru Nawinne*

Main category: cs.LG

TL;DR: 提出了一种名为AICRN的新型深度学习模型，用于分析心电图（ECG）参数，提高了诊断精度和效率。


<details>
  <summary>Details</summary>
Motivation: 为了应对传统心电图分析方法中存在的因人为错误导致的焦点丧失等挑战，并促进心脏事件的快速简便检测，从而减少分析任务所需的人工努力。

Method: 提出了一种名为AICRN（注意力集成卷积残差网络）的新型深度学习（DL）架构，用于回归关键心电图参数，如PR间隔、QT间隔、QRS duration、心率、R波峰值幅度以及T波幅度，以实现可解释的心电图分析。该架构专门设计了空间和通道注意力机制，并采用卷积残差网络来解决梯度消失和爆炸问题。

Result: AICRN模型在参数回归方面表现优于现有模型，具有更高的精度。

Conclusion: 深度学习在心电图（ECG）分析的解释性和精确性方面发挥着至关重要的作用，为心脏监测和管理开辟了新的临床应用。

Abstract: The paradigm of electrocardiogram (ECG) analysis has evolved into real-time
digital analysis, facilitated by artificial intelligence (AI) and machine
learning (ML), which has improved the diagnostic precision and predictive
capacity of cardiac diseases. This work proposes a novel deep learning (DL)
architecture called the attention-integrated convolutional residual network
(AICRN) to regress key ECG parameters such as the PR interval, the QT interval,
the QRS duration, the heart rate, the peak amplitude of the R wave, and the
amplitude of the T wave for interpretable ECG analysis. Our architecture is
specially designed with spatial and channel attention-related mechanisms to
address the type and spatial location of the ECG features for regression. The
models employ a convolutional residual network to address vanishing and
exploding gradient problems. The designed system addresses traditional analysis
challenges, such as loss of focus due to human errors, and facilitates the fast
and easy detection of cardiac events, thereby reducing the manual efforts
required to solve analysis tasks. AICRN models outperform existing models in
parameter regression with higher precision. This work demonstrates that DL can
play a crucial role in the interpretability and precision of ECG analysis,
opening up new clinical applications for cardiac monitoring and management.

</details>


### [482] [ProtTeX-CC: Activating In-Context Learning in Protein LLM via Two-Stage Instruction Compression](https://arxiv.org/abs/2508.12212)
*Chuanliu Fan,Zicheng Ma,Jun Gao,Nan Yu,Jun Zhang,Ziqiang Cao,Yi Qin Gao,Guohong Fu*

Main category: cs.LG

TL;DR: ProtTeX-CC 通过压缩技术解决了 ProtTeX 模型长度和泛化能力问题，在蛋白质功能预测上提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有蛋白质大语言模型（如 ProtTeX）将侧链氨基酸和主链结构表示为离散的残基长度标记序列，导致了（1）序列和结构标记的拼接使蛋白质长度加倍，破坏了模态间的残基级对齐；（2）受限于训练语料和有限的上下文窗口，模型通常在单蛋白质输入上训练，不兼容上下文学习（ICL），限制了泛化能力。

Method: 提出了一种轻量级的两阶段压缩框架 ProtTeX-CC。第一阶段采用联合嵌入压缩机制，在残基层面融合序列和结构表示，将蛋白质输入长度缩减一半。第二阶段提出自压缩模块，将每个完整示例压缩到最后几个语言标记的潜在空间中，大幅减少了提示长度。框架仅通过 PEFT 调优和单个可训练投影层引入少量额外参数。

Result: ProtTeX-CC 在蛋白质功能预测任务上，相比原始 ProtTeX 模型，在同域基准测试上提高了 2% 的性能，在跨域数据集上提高了 11% 的性能。自压缩方法在 16-shot 设置下，总提示长度的压缩率约为 93.68%。

Conclusion: ProtTeX-CC 框架通过联合嵌入压缩和自压缩机制，有效解决了 ProtTeX 模型在处理多模态蛋白质信息时的长度和上下文学习能力限制，显著提升了模型在少样本设置下的性能和泛化能力。

Abstract: Recent advances in protein large language models, such as ProtTeX, represent
both side-chain amino acids and backbone structure as discrete token sequences
of residue length. While this design enables unified modeling of multimodal
protein information, it suffers from two major limitations: (1) The
concatenation of sequence and structure tokens approximately doubles the
protein length and breaks the intrinsic residue-level alignment between
modalities. (2) Constrained by the training corpus and limited context window,
ProtTeX is typically trained on single-protein inputs, rendering it
incompatible with in-context learning (ICL) and thus limiting its
generalization capability. To address these issues, we propose ProtTeX-CC, a
lightweight two-stage compression framework designed to enhance ProtTeX under
few-shot settings. We first design a joint embedding compression mechanism that
fuses sequence and structure representations at the residue level, effectively
reducing the protein input length by half without sacrificing performance. Then
we propose a self-compression module that aggregates each full demonstration
into the latent space of the last few linguistic tokens, reducing the average
demonstration length from 751 tokens to less than 16 tokens. Compared to the
original ProtTeX, our self-compression approach achieves a compression ratio of
approximately 93.68% in the total prompt length under the 16-shot setting.
Without modifying the backbone model, ProtTeX-CC introduces only a small number
of additional parameters through PEFT-based tuning in the joint embedding
compression stage and a single trainable projection layer in the
self-compression stage. Extensive experiments on protein function prediction
show that ProtTeX-CC improves performance on the in-domain benchmark by 2%, and
generalizes well to the out-of-domain dataset with a performance gain of 11%.

</details>


### [483] [Unlearning at Scale: Implementing the Right to be Forgotten in Large Language Models](https://arxiv.org/abs/2508.12220)
*Abdullah X*

Main category: cs.LG

TL;DR: We present a method for unlearning in large language models, treating it as a reproducible systems problem by logging training data and replaying selectively. This ensures the 'right to be forgotten' with byte-identical results under certain conditions, and offers practical alternatives for efficiency.


<details>
  <summary>Details</summary>
Motivation: The motivation is to study the right to be forgotten (GDPR Art. 17) for large language models and to frame unlearning as a reproducible systems problem.

Method: Our approach logs minimal per-microbatch records (ordered ID hash, RNG seed, learning-rate value, optimizer-step counter, and accumulation boundary) and treats training as a deterministic program. Under pinned stack and deterministic kernels, replaying the training tail while filtering the forget closure yields the same parameters as training on the retain set. Complementary paths include exact reverts via micro-checkpoints or dense per-step deltas, cohort-scoped adapter deletion for frozen bases, and a curvature-guided anti-update followed by retain-tune, with audit-gating and escalation to exact replay.

Result: We report storage/latency budgets and a toy artifact validating mechanics. In a controlled run satisfying preconditions, we demonstrate byte-identical equality of model and optimizer states.

Conclusion: We frame unlearning as a reproducible systems problem and propose an approach that treats training as a deterministic program, logging minimal per-microbatch records. Under specific preconditions, replaying the training tail while filtering the forget closure yields identical parameters to training on the retain set. We also introduce complementary paths for latency and availability, including micro-checkpoints, cohort-scoped adapter deletion, and curvature-guided anti-updates with retain-tuning. Our results demonstrate byte-identical equality of model and optimizer states in a controlled run.

Abstract: We study the right to be forgotten (GDPR Art. 17) for large language models
and frame unlearning as a reproducible systems problem. Our approach treats
training as a deterministic program and logs a minimal per-microbatch record
(ordered ID hash, RNG seed, learning-rate value, optimizer-step counter, and
accumulation boundary). Under a pinned stack and deterministic kernels,
replaying the training tail while filtering only the forget closure yields the
same parameters as training on the retain set (bit-identical in the training
dtype) when preconditions hold. To meet latency and availability constraints,
we add complementary paths: (i) exact reverts of recent steps via
micro-checkpoints or dense per-step deltas, (ii) cohort-scoped adapter deletion
when the base is frozen, and (iii) a curvature-guided anti-update followed by a
short retain-tune, audit-gated with escalation to exact replay. We report
storage/latency budgets and a toy artifact validating mechanics; in a
controlled run that satisfies the preconditions we demonstrate byte-identical
equality of model and optimizer states.

</details>


### [484] [Distribution Matching via Generalized Consistency Models](https://arxiv.org/abs/2508.12222)
*Sagar Shrestha,Rajesh Shrestha,Tri Nguyen,Subash Timilsina*

Main category: cs.LG

TL;DR: 提出了一种新的分布匹配方法，它借鉴了CNF一致性模型的思想，克服了GANs的训练难题，并在实验中证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了解决GANs在分布匹配任务中训练的挑战，如模式崩溃。

Method: 提出了一种新颖的、受CNF中一致性模型启发的模型，该模型具有直接的范数最小化目标，并能适应GANs的各种约束。

Result: 在合成和真实世界数据集上进行了理论验证和实验评估，证明了所提出目标在分布匹配方面的有效性。

Conclusion: 该研究提出了一种新颖的基于一致性模型的一致性模型，用于分布匹配，克服了GANs训练中的挑战，如模式崩溃。

Abstract: Recent advancement in generative models have demonstrated remarkable
performance across various data modalities. Beyond their typical use in data
synthesis, these models play a crucial role in distribution matching tasks such
as latent variable modeling, domain translation, and domain adaptation.
Generative Adversarial Networks (GANs) have emerged as the preferred method of
distribution matching due to their efficacy in handling high-dimensional data
and their flexibility in accommodating various constraints. However, GANs often
encounter challenge in training due to their bi-level min-max optimization
objective and susceptibility to mode collapse. In this work, we propose a novel
approach for distribution matching inspired by the consistency models employed
in Continuous Normalizing Flow (CNF). Our model inherits the advantages of CNF
models, such as having a straight forward norm minimization objective, while
remaining adaptable to different constraints similar to GANs. We provide
theoretical validation of our proposed objective and demonstrate its
performance through experiments on synthetic and real-world datasets.

</details>


### [485] [Communication-Efficient Distributed Asynchronous ADMM](https://arxiv.org/abs/2508.12233)
*Sagar Shrestha*

Main category: cs.LG

TL;DR: Asynchronous ADMM with coarse quantization reduces communication overhead in federated learning and distributed optimization, verified by experiments.


<details>
  <summary>Details</summary>
Motivation: Communication costs can become a major bottleneck in asynchronous ADMM for large-scale federated learning and distributed optimization, especially with limited communication budgets or large data volumes.

Method: The proposed method introduces coarse quantization to the data exchanged in asynchronous ADMM to reduce communication overhead.

Result: The proposed method reduces communication overhead for large-scale federated learning and distributed optimization applications.

Conclusion: We experimentally verify the convergence of the proposed method for several distributed learning tasks, including neural networks.

Abstract: In distributed optimization and federated learning, asynchronous alternating
direction method of multipliers (ADMM) serves as an attractive option for
large-scale optimization, data privacy, straggler nodes and variety of
objective functions. However, communication costs can become a major bottleneck
when the nodes have limited communication budgets or when the data to be
communicated is prohibitively large. In this work, we propose introducing
coarse quantization to the data to be exchanged in aynchronous ADMM so as to
reduce communication overhead for large-scale federated learning and
distributed optimization applications. We experimentally verify the convergence
of the proposed method for several distributed learning tasks, including neural
networks.

</details>


### [486] [CC-Time: Cross-Model and Cross-Modality Time Series Forecasting](https://arxiv.org/abs/2508.12235)
*Peng Chen,Yihang Wang,Yang Shu,Yunyao Cheng,Kai Zhao,Zhongwen Rao,Lujia Pan,Bin Yang,Chenjuan Guo*

Main category: cs.LG

TL;DR: CC-Time 是一种创新的时间序列预测方法，通过结合跨模态学习和跨模型融合，利用预训练语言模型（PLMs）和时间序列模型，显著提高了预测精度。


<details>
  <summary>Details</summary>
Motivation: 现有的基于预训练语言模型（PLMs）的时间序列预测（TSF）方法未能充分发挥语言模型的序列建模能力，预测精度有待提高。

Method: CC-Time 结合了跨模型和跨模态学习，从时间序列和文本描述中提取特征，并通过跨模型融合块自适应地集成预训练语言模型和时间序列模型知识。

Result: 通过在九个真实世界数据集上进行的大量实验证明，CC-Time 显著优于现有方法。

Conclusion: CC-Time 实现了最先进的预测精度，在全数据训练和少样本学习情况下均表现优异。

Abstract: With the success of pre-trained language models (PLMs) in various application
fields beyond natural language processing, language models have raised emerging
attention in the field of time series forecasting (TSF) and have shown great
prospects. However, current PLM-based TSF methods still fail to achieve
satisfactory prediction accuracy matching the strong sequential modeling power
of language models. To address this issue, we propose Cross-Model and
Cross-Modality Learning with PLMs for time series forecasting (CC-Time). We
explore the potential of PLMs for time series forecasting from two aspects: 1)
what time series features could be modeled by PLMs, and 2) whether relying
solely on PLMs is sufficient for building time series models. In the first
aspect, CC-Time incorporates cross-modality learning to model temporal
dependency and channel correlations in the language model from both time series
sequences and their corresponding text descriptions. In the second aspect,
CC-Time further proposes the cross-model fusion block to adaptively integrate
knowledge from the PLMs and time series model to form a more comprehensive
modeling of time series patterns. Extensive experiments on nine real-world
datasets demonstrate that CC-Time achieves state-of-the-art prediction accuracy
in both full-data training and few-shot learning situations.

</details>


### [487] [DHG-Bench: A Comprehensive Benchmark on Deep Hypergraph Learning](https://arxiv.org/abs/2508.12244)
*Fan Li,Xiaoyang Wang,Wenjie Zhang,Ying Zhang,Xuemin Lin*

Main category: cs.LG

TL;DR: DHG-Bench 是第一个全面的深度超图学习 (DHGL) 基准测试，它通过整合各种数据集、算法和任务，并提供一致的评估协议，来解决现有 HNN 方法的局限性。该基准测试还评估了 HNN 的有效性、效率、鲁棒性和公平性，并提供了一个易于使用的库以促进可重复的研究。


<details>
  <summary>Details</summary>
Motivation: 现有的深度图模型主要关注成对关系，这限制了它们学习现实世界复杂系统中普遍存在的高阶交互的能力，而这些交互可以自然地建模为超图。此外，缺乏全面的 HNN 基准测试阻碍了对 DHGL 进展的理解，具体表现在数据集、算法和任务覆盖不足、算法性能评估狭窄以及数据集使用、预处理和实验设置不一致等方面。

Method: DHG-Bench 是一个全面的基准测试，用于深度超图学习 (DHGL)。它整合了各种数据集、算法和任务，并在统一的数据处理和实验协议下进行评估。该基准测试还包括一个易于使用的库，用于训练和评估 HNN 方法。

Result: DHG-Bench 填补了现有的空白，它包含 20 个多样化的数据集、16 种最先进的 HNN 算法，并支持节点、边和图级别的任务。它通过评估 HNN 的有效性、效率、鲁棒性和公平性这四个维度来系统地研究 HNN 的特性。

Conclusion: DHG-Bench 的广泛实验揭示了现有 HNN 算法的优势和固有局限性，为未来的研究提供了宝贵的见解和方向。DHG-Bench 包含 20 个多样化的数据集，涵盖节点、边和图级别的任务，以及 16 种最先进的 HNN 算法，并采用一致的数据处理和实验方案。

Abstract: Although conventional deep graph models have achieved great success in
relational learning, their focus on pairwise relationships limits their
capacity to learn pervasive higher-order interactions in real-world complex
systems, which can be naturally modeled as hypergraphs. To tackle this,
hypergraph neural networks (HNNs), the dominant approach in deep hypergraph
learning (DHGL), has garnered substantial attention in recent years. Despite
the proposal of numerous HNN methods, there is no comprehensive benchmark for
HNNs, which creates a great obstacle to understanding the progress of DHGL in
several aspects: (i) insufficient coverage of datasets, algorithms, and tasks;
(ii) a narrow evaluation of algorithm performance; and (iii) inconsistent
dataset usage, preprocessing, and experimental setups that hinder
comparability. To fill the gap, we introduce DHG-Bench, the first comprehensive
benchmark for DHGL. Specifically, DHG-Bench integrates 20 diverse datasets
spanning node-, edge-, and graph-level tasks, along with 16 state-of-the-art
HNN algorithms, under consistent data processing and experimental protocols.
Our benchmark systematically investigates the characteristics of HNNs in terms
of four dimensions: effectiveness, efficiency, robustness, and fairness.
Further, to facilitate reproducible research, we have developed an easy-to-use
library for training and evaluating different HNN methods. Extensive
experiments conducted with DHG-Bench reveal both the strengths and inherent
limitations of existing algorithms, offering valuable insights and directions
for future research. The code is publicly available at:
https://github.com/Coco-Hut/DHG-Bench.

</details>


### [488] [STM3: Mixture of Multiscale Mamba for Long-Term Spatio-Temporal Time-Series Prediction](https://arxiv.org/abs/2508.12247)
*Haolong Chen,Liang Zhang,Zhengyuan Xin,Guangxu Zhu*

Main category: cs.LG

TL;DR: STM2/STM3通过结合多尺度Mamba架构和图因果卷积网络，有效解决了长时程时空依赖学习中的多尺度信息提取和建模难题，并在时空时间序列预测任务中取得了领先的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习方法在有效学习复杂长时程时空依赖方面存在困难。长时程时空依赖学习带来了两个新的挑战：1）长时程时间序列自然包含多尺度信息，难以有效提取；2）来自不同节点的多尺度时间信息高度相关，难以建模。

Method: 提出了一种高效的时空多尺度Mamba（STM2）模型，该模型包含一个多尺度Mamba架构来高效地捕捉多尺度信息，以及一个自适应图因果卷积网络来学习复杂的多尺度时空依赖。STM2包含分层信息聚合，以保证不同尺度信息的区别。为了更有效地捕捉所有空间节点的多样化时间动态，还提出了一个增强版本，即时空多尺度Mamba混合模型（STM3），它采用一种特殊的专家混合架构，包括更稳定的路由策略和因果对比学习策略，以增强尺度可区分性。STM3具有更好的路由平滑度，并保证了每个专家的模式分离。

Result: STM2/STM3在真实世界基准测试中取得了优越的性能，实现了长期时空时间序列预测的最先进成果。

Conclusion: STM2/STM3在长期时空时间序列预测方面取得了最先进的成果，并在真实世界基准测试中展现出优越的性能。

Abstract: Recently, spatio-temporal time-series prediction has developed rapidly, yet
existing deep learning methods struggle with learning complex long-term
spatio-temporal dependencies efficiently. The long-term spatio-temporal
dependency learning brings two new challenges: 1) The long-term temporal
sequence includes multiscale information naturally which is hard to extract
efficiently; 2) The multiscale temporal information from different nodes is
highly correlated and hard to model. To address these challenges, we propose an
efficient \textit{\textbf{S}patio-\textbf{T}emporal \textbf{M}ultiscale
\textbf{M}amba} (STM2) that includes a multiscale Mamba architecture to capture
the multiscale information efficiently and simultaneously, and an adaptive
graph causal convolution network to learn the complex multiscale
spatio-temporal dependency. STM2 includes hierarchical information aggregation
for different-scale information that guarantees their distinguishability. To
capture diverse temporal dynamics across all spatial nodes more efficiently, we
further propose an enhanced version termed
\textit{\textbf{S}patio-\textbf{T}emporal \textbf{M}ixture of
\textbf{M}ultiscale \textbf{M}amba} (STM3) that employs a special
Mixture-of-Experts architecture, including a more stable routing strategy and a
causal contrastive learning strategy to enhance the scale distinguishability.
We prove that STM3 has much better routing smoothness and guarantees the
pattern disentanglement for each expert successfully. Extensive experiments on
real-world benchmarks demonstrate STM2/STM3's superior performance, achieving
state-of-the-art results in long-term spatio-temporal time-series prediction.

</details>


### [489] [Interpreting Time Series Forecasts with LIME and SHAP: A Case Study on the Air Passengers Dataset](https://arxiv.org/abs/2508.12253)
*Manish Shukla*

Main category: cs.LG

TL;DR: 本研究提出了一种统一的时间序列预测解释框架，利用 LIME 和 SHAP 技术，重点关注滞后特征和季节性编码，以提高模型的可解释性和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决 ARIMA 模型在处理非线性方面的局限性以及 XGBoost 等机器学习模型缺乏可解释性的问题，为时间序列预测提供可解释的框架。

Method: 将单变量时间序列转换为无泄漏的监督学习问题，并结合梯度提升树和 ARIMA 模型进行训练，然后应用 LIME 和 SHAP 进行解释。

Result: 研究表明，滞后特征（特别是十二个月滞后）和季节性编码是解释大多数预测方差的关键因素。

Conclusion: 通过使用 LIME 和 SHAP 等事后可解释性方法，研究为时间序列预测提供了一个统一的解释框架，重点是滞后特征和季节性编码。

Abstract: Time-series forecasting underpins critical decisions across aviation, energy,
retail and health. Classical autoregressive integrated moving average (ARIMA)
models offer interpretability via coefficients but struggle with
nonlinearities, whereas tree-based machine-learning models such as XGBoost
deliver high accuracy but are often opaque. This paper presents a unified
framework for interpreting time-series forecasts using local interpretable
model-agnostic explanations (LIME) and SHapley additive exPlanations (SHAP). We
convert a univariate series into a leakage-free supervised learning problem,
train a gradient-boosted tree alongside an ARIMA baseline and apply post-hoc
explainability. Using the Air Passengers dataset as a case study, we show that
a small set of lagged features -- particularly the twelve-month lag -- and
seasonal encodings explain most forecast variance. We contribute: (i) a
methodology for applying LIME and SHAP to time series without violating
chronology; (ii) theoretical exposition of the underlying algorithms; (iii)
empirical evaluation with extensive analysis; and (iv) guidelines for
practitioners.

</details>


### [490] [L-SR1: Learned Symmetric-Rank-One Preconditioning](https://arxiv.org/abs/2508.12270)
*Gal Lifshitz,Shahar Zuler,Ori Fouks,Dan Raviv*

Main category: cs.LG

TL;DR: 通过引入可训练的预条件单元来增强SR1算法，提出了一种新的学习型二阶优化器，在HMR任务上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了克服端到端深度学习在依赖大型标注数据集、泛化能力差和计算需求增长方面的限制，同时改进经典优化方法收敛速度慢的问题。

Method: 提出了一种新颖的学习型二阶优化器，通过引入可训练的预条件单元来增强经典的对称秩一（SR1）算法。该单元生成数据驱动的向量，用于构建正半定秩一矩阵，并通过学习到的投影与割线约束对齐。

Result: 在分析实验和单目人类网格恢复（HMR）等真实世界任务上进行了评估，其性能优于现有的基于学习的优化方法。该方法模型轻量，无需标注数据或微调。

Conclusion: 该方法具有良好的泛化能力，并且适合集成到更广泛的基于优化的框架中。

Abstract: End-to-end deep learning has achieved impressive results but remains limited
by its reliance on large labeled datasets, poor generalization to unseen
scenarios, and growing computational demands. In contrast, classical
optimization methods are data-efficient and lightweight but often suffer from
slow convergence. While learned optimizers offer a promising fusion of both
worlds, most focus on first-order methods, leaving learned second-order
approaches largely unexplored.
  We propose a novel learned second-order optimizer that introduces a trainable
preconditioning unit to enhance the classical Symmetric-Rank-One (SR1)
algorithm. This unit generates data-driven vectors used to construct positive
semi-definite rank-one matrices, aligned with the secant constraint via a
learned projection. Our method is evaluated through analytic experiments and on
the real-world task of Monocular Human Mesh Recovery (HMR), where it
outperforms existing learned optimization-based approaches. Featuring a
lightweight model and requiring no annotated data or fine-tuning, our approach
offers strong generalization and is well-suited for integration into broader
optimization-based frameworks.

</details>


### [491] [CRoC: Context Refactoring Contrast for Graph Anomaly Detection with Limited Supervision](https://arxiv.org/abs/2508.12278)
*Siyue Xie,Da Sun Handason Tam,Wing Cheong Lau*

Main category: cs.LG

TL;DR: CRoC框架通过重构节点上下文、集成异构关系和利用对比学习，有效地利用有限的标记数据和大量的未标记数据来训练GNN，以解决图异常检测中的数据稀疏性和异常伪装问题，并在多个基准测试中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的GNN训练通常需要大量的标记数据，这在标记成本高昂且异常稀少的图异常检测（GAD）任务中是一个关键瓶颈。异常可能主动伪装其模式以逃避检测。

Method: CRoC框架通过联合利用有限的标记数据和大量的未标记数据来训练GNN以用于GAD。CRoC利用GAD中固有的类别不平衡来重构每个节点的上下文，通过重新组合节点的属性来构建增强图，同时保留其交互模式。此外，CRoC分别编码异构关系，并将它们集成到消息传递过程中，增强了模型捕获复杂交互语义的能力。在训练阶段，CRoC与对比学习范式相结合，利用未标记数据进行联合训练，产生更丰富、更具区分性的节点嵌入。

Result: CRoC框架成功实现了在有限标签设置下，相比基线GNN模型，AUC最高提升了14%，并且优于最先进的GAD方法。

Conclusion: CRoC框架在七个真实世界GAD数据集上进行了评估，在有限标签设置下，相比基线GNN模型，AUC最高提升了14%，并优于最先进的GAD方法。

Abstract: Graph Neural Networks (GNNs) are widely used as the engine for various
graph-related tasks, with their effectiveness in analyzing graph-structured
data. However, training robust GNNs often demands abundant labeled data, which
is a critical bottleneck in real-world applications. This limitation severely
impedes progress in Graph Anomaly Detection (GAD), where anomalies are
inherently rare, costly to label, and may actively camouflage their patterns to
evade detection. To address these problems, we propose Context Refactoring
Contrast (CRoC), a simple yet effective framework that trains GNNs for GAD by
jointly leveraging limited labeled and abundant unlabeled data. Different from
previous works, CRoC exploits the class imbalance inherent in GAD to refactor
the context of each node, which builds augmented graphs by recomposing the
attributes of nodes while preserving their interaction patterns. Furthermore,
CRoC encodes heterogeneous relations separately and integrates them into the
message-passing process, enhancing the model's capacity to capture complex
interaction semantics. These operations preserve node semantics while
encouraging robustness to adversarial camouflage, enabling GNNs to uncover
intricate anomalous cases. In the training stage, CRoC is further integrated
with the contrastive learning paradigm. This allows GNNs to effectively harness
unlabeled data during joint training, producing richer, more discriminative
node embeddings. CRoC is evaluated on seven real-world GAD datasets with
varying scales. Extensive experiments demonstrate that CRoC achieves up to 14%
AUC improvement over baseline GNNs and outperforms state-of-the-art GAD methods
under limited-label settings.

</details>


### [492] [Convergence Analysis of the Lion Optimizer in Centralized and Distributed Settings](https://arxiv.org/abs/2508.12327)
*Wei Jiang,Lijun Zhang*

Main category: cs.LG

TL;DR: 该论文分析并改进了Lion优化器的收敛性，尤其是在分布式和通信受限的情况下，取得了更好的收敛速度。


<details>
  <summary>Details</summary>
Motivation: 该论文旨在分析Lion优化器的收敛性能，并通过改进算法来提高收敛速度，特别是在分布式和通信受限的场景下。

Method: 该论文首先建立了标准Lion优化器的收敛率，然后通过引入方差缩减技术来改进收敛率。接着，在分布式设置下分析了标准和方差缩减的分布式Lion的收敛性。最后，提出了一种通信高效的分布式Lion变体，并分析了其收敛性。

Result: Lion优化器的收敛率为O(d^(1/2)T^(-1/4))，方差缩减Lion优化器的收敛率为O(d^(1/2)T^(-1/3))。分布式Lion优化器的收敛率分别为O(d^(1/2)(nT)^(-1/4))和O(d^(1/2)(nT)^(-1/3))。通信高效的分布式Lion变体及其方差缩减版本的收敛率分别为O(max{d^(1/4)T^(-1/4), d^(1/10)n^(-1/5)T^(-1/5)})和O(d^(1/4)T^(-1/4))。

Conclusion: 该论文分析了Lion优化器的收敛性。标准Lion优化器的收敛率为O(d^(1/2)T^(-1/4))。通过引入方差缩减，Lion优化器的收敛率提高到O(d^(1/2)T^(-1/3))。在分布式设置中，标准和方差缩减的分布式Lion的收敛率分别为O(d^(1/2)(nT)^(-1/4))和O(d^(1/2)(nT)^(-1/3))。最后，提出了一种通信高效的分布式Lion变体，该变体通过使用无偏符号操作，实现了O(max{d^(1/4)T^(-1/4), d^(1/10)n^(-1/5)T^(-1/5)})和O(d^(1/4)T^(-1/4))的收敛率。

Abstract: In this paper, we analyze the convergence properties of the Lion optimizer.
First, we establish that the Lion optimizer attains a convergence rate of
$\mathcal{O}(d^{1/2}T^{-1/4})$ under standard assumptions, where $d$ denotes
the problem dimension and $T$ is the iteration number. To further improve this
rate, we introduce the Lion optimizer with variance reduction, resulting in an
enhanced convergence rate of $\mathcal{O}(d^{1/2}T^{-1/3})$. We then analyze in
distributed settings, where the standard and variance reduced version of the
distributed Lion can obtain the convergence rates of
$\mathcal{O}(d^{1/2}(nT)^{-1/4})$ and $\mathcal{O}(d^{1/2}(nT)^{-1/3})$, with
$n$ denoting the number of nodes. Furthermore, we investigate a
communication-efficient variant of the distributed Lion that ensures sign
compression in both communication directions. By employing the unbiased sign
operations, the proposed Lion variant and its variance reduction counterpart,
achieve convergence rates of $\mathcal{O}\left( \max
\left\{\frac{d^{1/4}}{T^{1/4}}, \frac{d^{1/10}}{n^{1/5}T^{1/5}} \right\}
\right)$ and $\mathcal{O}\left( \frac{d^{1/4}}{T^{1/4}} \right)$, respectively.

</details>


### [493] [Navigating the Exploration-Exploitation Tradeoff in Inference-Time Scaling of Diffusion Models](https://arxiv.org/abs/2508.12361)
*Xun Su,Jianming Huang,Yang Yusen,Zhongxi Fang,Hiroyuki Kasai*

Main category: cs.LG

TL;DR: Adapting scaling methods to diffusion models is tricky due to evaluation challenges with early vs. late samples. This paper introduces 'Funnel Schedule' and 'Adaptive Temperature' to better balance exploration and exploitation, improving sample quality without more computation, and outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: The motivation is to adapt inference-time scaling, successful in language models, to diffusion models. Current Sequential Monte Carlo (SMC)-based methods for diffusion models face a dilemma where early-stage noise samples are hard to evaluate but have high potential for improvement, while late-stage samples are easier to evaluate but less reversible. This creates an exploration-exploitation trade-off that needs to be addressed.

Method: The paper proposes two strategies, Funnel Schedule and Adaptive Temperature, to address the exploration-exploitation trade-off in adapting inference-time scaling to diffusion models. These methods manage the number of particles and the influence of early-stage rewards based on the generation dynamics and phase-transition behavior of diffusion models.

Result: Experimental results on multiple benchmarks and state-of-the-art text-to-image diffusion models demonstrate that the proposed approach (Funnel Schedule and Adaptive Temperature) outperforms previous baselines in enhancing sample quality without increasing the total number of Noise Function Evaluations.

Conclusion: Inference-time scaling adaptation to diffusion models is underexplored. Current methods struggle with the exploration-exploitation trade-off due to early-stage noise samples being hard to evaluate and late-stage samples being irreversible. The proposed Funnel Schedule and Adaptive Temperature strategies address this by progressively reducing particles and down-weighting early rewards, enhancing sample quality without increasing total evaluations. Experiments show superior performance.

Abstract: Inference-time scaling has achieved remarkable success in language models,
yet its adaptation to diffusion models remains underexplored. We observe that
the efficacy of recent Sequential Monte Carlo (SMC)-based methods largely stems
from globally fitting the The reward-tilted distribution, which inherently
preserves diversity during multi-modal search. However, current applications of
SMC to diffusion models face a fundamental dilemma: early-stage noise samples
offer high potential for improvement but are difficult to evaluate accurately,
whereas late-stage samples can be reliably assessed but are largely
irreversible. To address this exploration-exploitation trade-off, we approach
the problem from the perspective of the search algorithm and propose two
strategies: Funnel Schedule and Adaptive Temperature. These simple yet
effective methods are tailored to the unique generation dynamics and
phase-transition behavior of diffusion models. By progressively reducing the
number of maintained particles and down-weighting the influence of early-stage
rewards, our methods significantly enhance sample quality without increasing
the total number of Noise Function Evaluations. Experimental results on
multiple benchmarks and state-of-the-art text-to-image diffusion models
demonstrate that our approach outperforms previous baselines.

</details>


### [494] [Bi-Axial Transformers: Addressing the Increasing Complexity of EHR Classification](https://arxiv.org/abs/2508.12418)
*Rachael DeVries,Casper Christensen,Marie Lisandra Zepeda Mendoza,Ole Winther*

Main category: cs.LG

TL;DR: A new model called Bi-Axial Transformer (BAT) uses a novel approach to analyze electronic health records (EHRs), outperforming existing methods in sepsis prediction and showing promise in mortality classification. It's also better at handling missing data and can be used for transfer learning.


<details>
  <summary>Details</summary>
Motivation: To address the challenges posed by increasingly complex Electronic Health Records (EHRs), such as larger datasets, longer time series, and multi-modal integrations, and to overcome the limitations of existing data representations for Transformer models in EHR classification.

Method: The paper presents the Bi-Axial Transformer (BAT), which attends to both the clinical variable and time point axes of EHR data to learn richer data relationships and address data sparsity.

Result: BAT achieves state-of-the-art performance on sepsis prediction and competitive performance on mortality classification. It shows improved robustness to missing data compared to other transformers.

Conclusion: BAT achieved state-of-the-art performance on sepsis prediction and is competitive to top methods for mortality classification. It demonstrates increased robustness to data missingness and learns unique sensor embeddings for transfer learning. Baseline models were re-implemented with PyTorch for reproducibility.

Abstract: Electronic Health Records (EHRs), the digital representation of a patient's
medical history, are a valuable resource for epidemiological and clinical
research. They are also becoming increasingly complex, with recent trends
indicating larger datasets, longer time series, and multi-modal integrations.
Transformers, which have rapidly gained popularity due to their success in
natural language processing and other domains, are well-suited to address these
challenges due to their ability to model long-range dependencies and process
data in parallel. But their application to EHR classification remains limited
by data representations, which can reduce performance or fail to capture
informative missingness. In this paper, we present the Bi-Axial Transformer
(BAT), which attends to both the clinical variable and time point axes of EHR
data to learn richer data relationships and address the difficulties of data
sparsity. BAT achieves state-of-the-art performance on sepsis prediction and is
competitive to top methods for mortality classification. In comparison to other
transformers, BAT demonstrates increased robustness to data missingness, and
learns unique sensor embeddings which can be used in transfer learning.
Baseline models, which were previously located across multiple repositories or
utilized deprecated libraries, were re-implemented with PyTorch and made
available for reproduction and future benchmarking.

</details>


### [495] [Machine Learning-Based Manufacturing Cost Prediction from 2D Engineering Drawings via Geometric Features](https://arxiv.org/abs/2508.12440)
*Ahmet Bilal Arıkan,Şener Özönder,Mustafa Taha Koçyiğit,Hüseyin Oktay Altun,H. Kübra Küçükkartal,Murat Arslanoğlu,Fatih Çağırankaya,Berk Ayvaz*

Main category: cs.LG

TL;DR: 该框架利用机器学习和几何/统计特征从 2D 工程图纸中估算制造成本，误差率低，并提供可操作的设计见解。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在提出一种改进传统报价工作流程的方法，该传统工作流程需要劳动密集型的工艺规划，通过利用机器学习从 2D 工程图纸估计制造成本。

Method: 我们提出了一个集成机器学习框架，该框架直接从 13,684 个汽车悬架和转向零件的 DWG 图纸中提取大约 200 个几何和统计描述符，涵盖 24 个产品组。在这些特征上训练的梯度提升决策树模型（XGBoost、CatBoost、LightGBM）在各组中的平均绝对百分比误差接近 10%，这表明了其在超越特定零件的启发式方法方面的稳健可扩展性。

Result: 所提出的框架在汽车悬架和转向零件的 24 个产品组中实现了近 10% 的平均绝对百分比误差，显示了其稳健的可扩展性。通过 SHAP 等可解释性工具将成本预测与可解释性相结合，该框架能够识别旋转尺寸最大值、圆弧统计和发散度量等几何设计驱动因素，从而为成本感知设计提供可行的见解。

Conclusion: 该框架缩短了报价准备时间，确保了零件系列之间一致且透明的成本评估，并为工业 4.0 制造环境中的实时、ERP 集成决策支持提供了可部署的途径。

Abstract: We present an integrated machine learning framework that transforms how
manufacturing cost is estimated from 2D engineering drawings. Unlike
traditional quotation workflows that require labor-intensive process planning,
our approach about 200 geometric and statistical descriptors directly from
13,684 DWG drawings of automotive suspension and steering parts spanning 24
product groups. Gradient-boosted decision tree models (XGBoost, CatBoost,
LightGBM) trained on these features achieve nearly 10% mean absolute percentage
error across groups, demonstrating robust scalability beyond part-specific
heuristics. By coupling cost prediction with explainability tools such as SHAP,
the framework identifies geometric design drivers including rotated dimension
maxima, arc statistics and divergence metrics, offering actionable insights for
cost-aware design. This end-to-end CAD-to-cost pipeline shortens quotation lead
times, ensures consistent and transparent cost assessments across part families
and provides a deployable pathway toward real-time, ERP-integrated decision
support in Industry 4.0 manufacturing environments.

</details>


### [496] [Local Cluster Cardinality Estimation for Adaptive Mean Shift](https://arxiv.org/abs/2508.12450)
*Étienne Pepin*

Main category: cs.LG

TL;DR: 提出一种新的自适应均值漂移算法，通过估计局部簇基数来自适应调整参数，并在基准测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 针对具有变化的局部尺度和簇基数的がーたーせっと，设计了一种自适应均值漂移算法。

Method: 提出了一种自适应均值漂移算法，该算法利用点到所有其他点的局部距离分布来估计局部簇的基数，然后根据这些基数估计值计算整个簇的局部簇参数。在均值漂移执行期间，簇基数估计用于自适应地调整带宽和均值漂移核半径阈值。

Result: 该算法能够根据簇的基数自适应地调整带宽和均值漂移核半径阈值。

Conclusion: 该算法在原始数据集上优于最近提出的自适应均值漂移方法，并在更广泛的聚类基准测试中表现出竞争力。

Abstract: This article presents an adaptive mean shift algorithm designed for datasets
with varying local scale and cluster cardinality. Local distance distributions,
from a point to all others, are used to estimate the cardinality of the local
cluster by identifying a local minimum in the density of the distance
distribution. Based on these cardinality estimates, local cluster parameters
are then computed for the entire cluster in contrast to KDE-based methods,
which provide insight only into localized regions of the cluster. During the
mean shift execution, the cluster cardinality estimate is used to adaptively
adjust the bandwidth and the mean shift kernel radius threshold. Our algorithm
outperformed a recently proposed adaptive mean shift method on its original
dataset and demonstrated competitive performance on a broader clustering
benchmark.

</details>


### [497] [Cold-RL: Learning Cache Eviction with Offline Reinforcement Learning for NGINX](https://arxiv.org/abs/2508.12485)
*Aayush Gupta,Arpit Bhayani*

Main category: cs.LG

TL;DR: Cold-RL 是一个用于 NGINX 的基于强化学习的缓存驱逐策略，通过深度 Q 网络优化驱逐决策，在不同缓存大小下显著提高命中率，并且满足严格的延迟要求。


<details>
  <summary>Details</summary>
Motivation: 传统的 Web 代理（如 NGINX）通常使用最近最少使用（LRU）算法进行缓存驱逐。然而，LRU 算法存在一些缺点，例如它不考虑对象的大小，并且在面对周期性突发流量和混合对象大小时容易出现性能骤降（thrashing）。因此，需要一种更智能的驱逐策略来提高缓存命中率和效率。

Method: Cold-RL 使用深度 Q 网络（Dueling DQN）来学习驱逐策略，并与 ONNX 运行时集成，以满足严格的微秒级延迟要求。在每次驱逐时，它会从最近最少使用的 K 个对象中采样，提取年龄、大小、命中次数、到达间隔时间、剩余 TTL 和最后一次源 RTT 等特征，并请求一个包含潜在被驱逐对象的位掩码。为了防止延迟过高，设置了 500 微秒的硬超时，超过该时间则回退到 LRU。该策略通过在缓存模拟器中重放 NGINX 访问日志进行离线训练，奖励机制是保留的对象在 TTL 过期前被再次命中即可获得分数。

Result: Cold-RL 在 25MB 缓存下，将命中率从 0.1436 提高到 0.3538，比最佳传统基线提高了 146%。在 100MB 缓存下，命中率从 0.7530 提高到 0.8675，提高了 15%。在 400MB 缓存下，Cold-RL 的表现与传统方法相当，命中率约为 0.918。此外，Cold-RL 的推理过程增加了不到 2% 的 CPU 开销，并将 95% 的驱逐延迟保持在 500 微秒的预算内。

Conclusion: Cold-RL 是一种用于 NGINX 的学习型驱逐策略，旨在解决 LRU 驱逐策略的不足。它使用深度 Q 网络来选择要驱逐的对象，并在严格的微秒级延迟预算内运行。在两个对抗性工作负载上的实验表明，Cold-RL 在提高命中率方面表现优于传统的驱逐策略，尤其是在较小的缓存容量下。该策略的推理开销低，并将 95% 的驱逐延迟保持在预算内。这是第一个在 NGINX 中集成了具有严格服务等级目标的强化学习驱逐策略。

Abstract: Web proxies such as NGINX commonly rely on least-recently-used (LRU)
eviction, which is size agnostic and can thrash under periodic bursts and mixed
object sizes. We introduce Cold-RL, a learned eviction policy for NGINX that
replaces LRU's forced-expire path with a dueling Deep Q-Network served by an
ONNX sidecar within a strict microsecond budget. On each eviction, Cold-RL
samples the K least-recently-used objects, extracts six lightweight features
(age, size, hit count, inter-arrival time, remaining TTL, and last origin RTT),
and requests a bitmask of victims; a hard timeout of 500 microseconds triggers
immediate fallback to native LRU. Policies are trained offline by replaying
NGINX access logs through a cache simulator with a simple reward: a retained
object earns one point if it is hit again before TTL expiry. We compare against
LRU, LFU, size-based, adaptive LRU, and a hybrid baseline on two adversarial
workloads. With a 25 MB cache, Cold-RL raises hit ratio from 0.1436 to 0.3538,
a 146 percent improvement over the best classical baseline; at 100 MB, from
0.7530 to 0.8675, a 15 percent gain; and at 400 MB it matches classical methods
(about 0.918). Inference adds less than 2 percent CPU overhead and keeps 95th
percentile eviction latency within budget. To our knowledge, this is the first
reinforcement learning eviction policy integrated into NGINX with strict SLOs.

</details>


### [498] [Cost-Aware Contrastive Routing for LLMs](https://arxiv.org/abs/2508.12491)
*Reza Shirkavand,Shangqian Gao,Peiran Yu,Heng Huang*

Main category: cs.LG

TL;DR: CSCR是一种轻量级框架，将提示和模型映射到共享的嵌入空间，以实现快速、成本敏感的选择。


<details>
  <summary>Details</summary>
Motivation: 现有方法常常忽略特定于提示的上下文，依赖于昂贵的模型分析，假设存在固定的专家集，或使用低效的试错策略。

Method: CSCR使用紧凑、易于计算的logit指纹（用于开源模型）和困惑度指纹（用于黑盒API）。对比编码器经过训练，在自适应成本范围内倾向于最便宜的准确专家。在推理时，路由通过FAISS索引减少为一次k-NN查找，当专家池变化时无需重新训练，并能实现微秒级延迟。

Result: CSCR能够进行快速、成本敏感的选择，并将准确性-成本权衡提高了25%，同时能稳健地泛化到未见过的大型语言模型和分布外提示。

Conclusion: CSCR在多个基准测试中始终优于基线，将准确性-成本权衡提高了25%，同时能稳健地泛化到未见过的大型语言模型和分布外提示。

Abstract: We study cost-aware routing for large language models across diverse and
dynamic pools of models. Existing approaches often overlook prompt-specific
context, rely on expensive model profiling, assume a fixed set of experts, or
use inefficient trial-and-error strategies. We introduce Cost-Spectrum
Contrastive Routing (CSCR), a lightweight framework that maps both prompts and
models into a shared embedding space to enable fast, cost-sensitive selection.
CSCR uses compact, fast-to-compute logit footprints for open-source models and
perplexity fingerprints for black-box APIs. A contrastive encoder is trained to
favor the cheapest accurate expert within adaptive cost bands. At inference
time, routing reduces to a single k-NN lookup via a FAISS index, requiring no
retraining when the expert pool changes and enabling microsecond latency.
Across multiple benchmarks, CSCR consistently outperforms baselines, improving
the accuracy-cost tradeoff by up to 25%, while generalizing robustly to unseen
LLMs and out-of-distribution prompts.

</details>


### [499] [Trust Region Constrained Measure Transport in Path Space for Stochastic Optimal Control and Inference](https://arxiv.org/abs/2508.12511)
*Denis Blessing,Julius Berner,Lorenz Richter,Carles Domingo-Enrich,Yuanqi Du,Arash Vahdat,Gerhard Neumann*

Main category: cs.LG

TL;DR: 本研究提出了一种新的基于信任区域的随机最优控制方法，通过几何退火逐步逼近目标测度，并在扩散模型微调等任务中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决随机最优控制问题，特别是当目标测度与先验测度差异很大时，这种优化具有挑战性。

Method: 通过迭代求解约束问题并结合信任区域，逐步逼近目标测度。该策略可以被理解为一种从先验测度到目标测度的几何退火，其中信任区域为退火路径中的时间步选择提供了原则性和指导性。

Result: 所提出的基于信任区域的策略能够系统地、逐步地逼近目标测度，并在多个最优控制应用中展示了显著的性能提升。

Conclusion: 我们的新方法在扩散采样、转移路径采样和扩散模型微调等多个最优控制应用中显著提高了性能。

Abstract: Solving stochastic optimal control problems with quadratic control costs can
be viewed as approximating a target path space measure, e.g. via gradient-based
optimization. In practice, however, this optimization is challenging in
particular if the target measure differs substantially from the prior. In this
work, we therefore approach the problem by iteratively solving constrained
problems incorporating trust regions that aim for approaching the target
measure gradually in a systematic way. It turns out that this trust region
based strategy can be understood as a geometric annealing from the prior to the
target measure, where, however, the incorporated trust regions lead to a
principled and educated way of choosing the time steps in the annealing path.
We demonstrate in multiple optimal control applications that our novel method
can improve performance significantly, including tasks in diffusion-based
sampling, transition path sampling, and fine-tuning of diffusion models.

</details>


### [500] [Results of the NeurIPS 2023 Neural MMO Competition on Multi-task Reinforcement Learning](https://arxiv.org/abs/2508.12524)
*Joseph Suárez,Kyoung Whan Choe,David Bloomin,Jianming Gao,Yunkun Li,Yao Feng,Saidinesh Pola,Kun Zhang,Yonghui Zhu,Nikhil Pinnaparaju,Hao Xiang Li,Nishaanth Kanna,Daniel Scott,Ryan Sullivan,Rose S. Shuman,Lucas de Alcântara,Herbie Bradley,Kirsty You,Bo Wu,Yuhao Jiang,Qimai Li,Jiaxin Chen,Louis Castricato,Xiaolong Zhu,Phillip Isola*

Main category: cs.LG

TL;DR: NeurIPS 2023神经网络MMO竞赛展示了强大的泛化能力，顶尖解决方案比基线训练速度快4倍。


<details>
  <summary>Details</summary>
Motivation: 介绍NeurIPS 2023神经网络MMO竞赛的结果，该竞赛吸引了200多名参与者和提交的作品。

Method: 参与者训练了目标条件策略，这些策略可以泛化到训练中未见过的任务、地图和对手。

Result: 竞赛吸引了200多名参与者和提交的作品。顶尖解决方案在训练8小时后，分数是基线的4倍。

Conclusion: 竞赛的顶尖解决方案在单张4090 GPU上训练8小时后，取得了比我们基线高4倍的分数。

Abstract: We present the results of the NeurIPS 2023 Neural MMO Competition, which
attracted over 200 participants and submissions. Participants trained
goal-conditional policies that generalize to tasks, maps, and opponents never
seen during training. The top solution achieved a score 4x higher than our
baseline within 8 hours of training on a single 4090 GPU. We open-source
everything relating to Neural MMO and the competition under the MIT license,
including the policy weights and training code for our baseline and for the top
submissions.

</details>


### [501] [Toward Architecture-Agnostic Local Control of Posterior Collapse in VAEs](https://arxiv.org/abs/2508.12530)
*Hyunsoo Song,Seungwhan Kim,Seungkyu Lee*

Main category: cs.LG

TL;DR: 提出了一种名为潜变量重构（LR）损失的新方法，解决了变分自编码器（VAE）的后验塌缩问题，无需网络架构约束，并在多种数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了解决变分自编码器（VAE）在生成模型中普遍存在的后验塌缩问题，该问题会降低生成样本的多样性。现有方法在控制正则化损失影响或保证潜在可识别性方面存在不足，例如需要结构性约束。

Method: 提出了一种名为潜变量重构（LR）损失的新方法，该方法借鉴了内射和复合函数的数学性质，旨在无需对网络架构进行约束即可控制后验塌缩。

Result: 在MNIST、fashionMNIST、Omniglot、CelebA和FFHQ等多种数据集上进行了实验评估，证明了该方法在控制后验塌缩方面的有效性。

Conclusion: 本研究提出的潜变量重构（LR）损失通过利用内射和复合函数的数学性质，无需对特定网络架构进行限制，即可控制模型潜在空间塌缩问题，并在MNIST、fashionMNIST、Omniglot、CelebA和FFHQ等多种数据集上进行了实验评估。

Abstract: Variational autoencoders (VAEs), one of the most widely used generative
models, are known to suffer from posterior collapse, a phenomenon that reduces
the diversity of generated samples. To avoid posterior collapse, many prior
works have tried to control the influence of regularization loss. However, the
trade-off between reconstruction and regularization is not satisfactory. For
this reason, several methods have been proposed to guarantee latent
identifiability, which is the key to avoiding posterior collapse. However, they
require structural constraints on the network architecture. For further
clarification, we define local posterior collapse to reflect the importance of
individual sample points in the data space and to relax the network constraint.
Then, we propose Latent Reconstruction(LR) loss, which is inspired by
mathematical properties of injective and composite functions, to control
posterior collapse without restriction to a specific architecture. We
experimentally evaluate our approach, which controls posterior collapse on
varied datasets such as MNIST, fashionMNIST, Omniglot, CelebA, and FFHQ.

</details>


### [502] [Rethinking Safety in LLM Fine-tuning: An Optimization Perspective](https://arxiv.org/abs/2508.12531)
*Minseon Kim,Jin Myung Kwak,Lama Alssum,Bernard Ghanem,Philip Torr,David Krueger,Fazl Barez,Adel Bibi*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Fine-tuning language models is commonly believed to inevitably harm their
safety, i.e., refusing to respond to harmful user requests, even when using
harmless datasets, thus requiring additional safety measures. We challenge this
belief through systematic testing, showing that poor optimization choices,
rather than inherent trade-offs, often cause safety problems, measured as
harmful responses to adversarial prompts. By properly selecting key training
hyper-parameters, e.g., learning rate, batch size, and gradient steps, we
reduce unsafe model responses from 16\% to approximately 5\%, as measured by
keyword matching, while maintaining utility performance. Based on this
observation, we propose a simple exponential moving average (EMA) momentum
technique in parameter space that preserves safety performance by creating a
stable optimization path and retains the original pre-trained model's safety
properties. Our experiments on the Llama families across multiple datasets
(Dolly, Alpaca, ORCA) demonstrate that safety problems during fine-tuning can
largely be avoided without specialized interventions, outperforming existing
approaches that require additional safety data while offering practical
guidelines for maintaining both model performance and safety during adaptation.

</details>


### [503] [Defining and Benchmarking a Data-Centric Design Space for Brain Graph Construction](https://arxiv.org/abs/2508.12533)
*Qinwen Ge,Roza G. Bayrak,Anwar Said,Catie Chang,Xenofon Koutsoukos,Tyler Derr*

Main category: cs.LG

TL;DR: 本研究提出了一种数据中心的方法来优化fMRI脑图谱的构建，通过系统地调整信号处理、拓扑提取和图特征化等环节，提升了下游机器学习任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的fMRI脑图谱构建方法往往依赖于固定的流程，忽视了数据处理过程中关键的数据中心选择，这可能影响图机器学习在神经影像领域的应用效果。因此，有必要采用数据中心的方法来系统地研究和优化脑图谱的构建过程。

Method: 本研究采用数据中心人工智能（Data-Centric AI）的视角，通过系统地定义和评估一个数据中心设计空间来构建脑图谱。该设计空间包含三个阶段：时间信号处理、拓扑提取和图特征化。研究重点在于评估现有和改进的技术组合对下游性能的影响，具体包括高幅度BOLD信号滤波、连接性的稀疏化和统一策略、替代相关性度量以及多视图节点和边缘特征（如滞后动态）。

Result: 通过在HCP1200和ABIDE数据集上的实验证明，精心设计的数据中心配置能够持续提升分类准确率，优于标准的流程。这表明数据处理的决策对模型的性能至关重要。

Conclusion: 本研究通过数据驱动的方法，系统地评估和优化了从fMRI数据构建脑图谱的流程，并在HCP1200和ABIDE数据集上验证了该方法在提高下游任务（如分类准确率）方面的有效性，强调了数据处理流程对模型性能的关键影响。

Abstract: The construction of brain graphs from functional Magnetic Resonance Imaging
(fMRI) data plays a crucial role in enabling graph machine learning for
neuroimaging. However, current practices often rely on rigid pipelines that
overlook critical data-centric choices in how brain graphs are constructed. In
this work, we adopt a Data-Centric AI perspective and systematically define and
benchmark a data-centric design space for brain graph construction,
constrasting with primarily model-centric prior work. We organize this design
space into three stages: temporal signal processing, topology extraction, and
graph featurization. Our contributions lie less in novel components and more in
evaluating how combinations of existing and modified techniques influence
downstream performance. Specifically, we study high-amplitude BOLD signal
filtering, sparsification and unification strategies for connectivity,
alternative correlation metrics, and multi-view node and edge features, such as
incorporating lagged dynamics. Experiments on the HCP1200 and ABIDE datasets
show that thoughtful data-centric configurations consistently improve
classification accuracy over standard pipelines. These findings highlight the
critical role of upstream data decisions and underscore the importance of
systematically exploring the data-centric design space for graph-based
neuroimaging. Our code is available at
https://github.com/GeQinwen/DataCentricBrainGraphs.

</details>


### [504] [OS-R1: Agentic Operating System Kernel Tuning with Reinforcement Learning](https://arxiv.org/abs/2508.12551)
*Hongyu Lin,Yuchen Li,Haoran Luo,Kaichun Yao,Libo Zhang,Mingjie Xing,Yanjun Wu*

Main category: cs.LG

TL;DR: OS-R1是一个基于RL的Linux内核调优框架，通过LLM实现高效探索和准确配置修改，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的Linux内核调优方法在效率、可扩展性和泛化性方面面临挑战。

Method: OS-R1是一个由基于规则的强化学习（RL）驱动的代理Linux内核调优框架。它将内核配置空间抽象为RL环境，通过自定义奖励函数增强LLM的推理标准化、配置修改准确性和系统性能意识，并采用两阶段训练过程来加速收敛并最小化跨不同调优场景的再训练。

Result: 实验结果表明，OS-R1显著优于现有的基线方法，与启发式调优相比，性能提高了5.6%，并保持了高数据效率。

Conclusion: OS-R1在各种真实世界应用中表现出适应性，证明了其在多样化环境中实际部署的潜力。

Abstract: Linux kernel tuning is essential for optimizing operating system (OS)
performance. However, existing methods often face challenges in terms of
efficiency, scalability, and generalization. This paper introduces OS-R1, an
agentic Linux kernel tuning framework powered by rule-based reinforcement
learning (RL). By abstracting the kernel configuration space as an RL
environment, OS-R1 facilitates efficient exploration by large language models
(LLMs) and ensures accurate configuration modifications. Additionally, custom
reward functions are designed to enhance reasoning standardization,
configuration modification accuracy, and system performance awareness of the
LLMs. Furthermore, we propose a two-phase training process that accelerates
convergence and minimizes retraining across diverse tuning scenarios.
Experimental results show that OS-R1 significantly outperforms existing
baseline methods, achieving up to 5.6% performance improvement over heuristic
tuning and maintaining high data efficiency. Notably, OS-R1 is adaptable across
various real-world applications, demonstrating its potential for practical
deployment in diverse environments. Our dataset and code are publicly available
at https://github.com/LHY-24/OS-R1.

</details>


### [505] [Illuminating LLM Coding Agents: Visual Analytics for Deeper Understanding and Enhancement](https://arxiv.org/abs/2508.12555)
*Junpeng Wang,Yuzhong Chen,Menghai Pan,Chin-Chia Michael Yeh,Mahashweta Das*

Main category: cs.LG

TL;DR: 为了解决手动检查编码代理输出效率低下的问题，我们提出了一个视觉分析系统，支持代码级、进程级和LLM级分析，以增强对编码代理行为的检查，并使机器学习科学家能够更有效地进行调试和提示工程。


<details>
  <summary>Details</summary>
Motivation: 目前的手动检查编码代理输出的方法效率低下，难以跟踪代码演变、比较编码迭代和识别改进机会。

Method: 提出一个视觉分析系统，用于检查编码代理的行为，支持跨三个级别的比较分析：代码级分析（显示代理如何迭代地调试和优化代码）、进程级分析（对比代理探索的不同寻求解决方案的过程）和LLM级分析（突出不同LLM之间编码行为的差异）。

Result: 通过使用编码代理解决流行的Kaggle竞赛的案例研究，证明了该系统能够深入了解迭代编码过程。

Conclusion: 该系统通过提供代码级、进程级和LLM级分析，使机器学习科学家能够获得对编码代理行为的结构化理解，从而促进更有效的调试和提示工程。

Abstract: Coding agents powered by large language models (LLMs) have gained traction
for automating code generation through iterative problem-solving with minimal
human involvement. Despite the emergence of various frameworks, e.g.,
LangChain, AutoML, and AIDE, ML scientists still struggle to effectively review
and adjust the agents' coding process. The current approach of manually
inspecting individual outputs is inefficient, making it difficult to track code
evolution, compare coding iterations, and identify improvement opportunities.
To address this challenge, we introduce a visual analytics system designed to
enhance the examination of coding agent behaviors. Focusing on the AIDE
framework, our system supports comparative analysis across three levels: (1)
Code-Level Analysis, which reveals how the agent debugs and refines its code
over iterations; (2) Process-Level Analysis, which contrasts different
solution-seeking processes explored by the agent; and (3) LLM-Level Analysis,
which highlights variations in coding behavior across different LLMs. By
integrating these perspectives, our system enables ML scientists to gain a
structured understanding of agent behaviors, facilitating more effective
debugging and prompt engineering. Through case studies using coding agents to
tackle popular Kaggle competitions, we demonstrate how our system provides
valuable insights into the iterative coding process.

</details>


### [506] [Deep Learning-Based Financial Time Series Forecasting via Sliding Window and Variational Mode Decomposition](https://arxiv.org/abs/2508.12565)
*Luke Li*

Main category: cs.LG

TL;DR: This paper uses VMD and sliding window techniques with LSTM for better financial time series forecasting.


<details>
  <summary>Details</summary>
Motivation: To address the complexity of financial time series and improve forecasting accuracy and stability.

Method: The paper proposes a forecasting model that combines sliding window and variational mode decomposition (VMD) methods. Financial time series data is decomposed into subcomponents using VMD, and these subcomponents are then fed into a deep learning model (LSTM) for prediction.

Result: The LSTM model trained on VMD-processed sequences showed better performance and stability than models trained on raw time series.

Conclusion: The proposed model combining sliding window and VMD demonstrates superior performance and stability in financial time series forecasting compared to using raw time series.

Abstract: To address the complexity of financial time series, this paper proposes a
forecasting model combining sliding window and variational mode decomposition
(VMD) methods. Historical stock prices and relevant market indicators are used
to construct datasets. VMD decomposes non-stationary financial time series into
smoother subcomponents, improving model adaptability. The decomposed data is
then input into a deep learning model for prediction. The study compares the
forecasting effects of an LSTM model trained on VMD-processed sequences with
those using raw time series, demonstrating better performance and stability.

</details>


### [507] [Data-driven particle dynamics: Structure-preserving coarse-graining for emergent behavior in non-equilibrium systems](https://arxiv.org/abs/2508.12569)
*Quercus Hernandez,Max Win,Thomas C. O'Connor,Paulo E. Arratia,Nathaniel Trask*

Main category: cs.LG

TL;DR: A new self-supervised learning method using metriplectic brackets learns coarse-grained dynamics from data, preserving thermodynamics and physical laws, useful for complex systems like polymers and colloids.


<details>
  <summary>Details</summary>
Motivation: Multiscale systems are common in science and technology but difficult to simulate due to the need to link short spatiotemporal scales to emergent bulk physics. Coarse-graining high-dimensional dynamical systems leads to information loss, resulting in dissipative, history-dependent, and stochastic emergent physics. The motivation is to develop a method that can learn these coarse-grained dynamics from observational data while preserving these crucial physical properties.

Method: A framework using the metriplectic bracket formalism is proposed to machine learn coarse-grained dynamics from time-series observations. This framework preserves physical properties such as thermodynamic laws, conservation of momentum, and fluctuation-dissipation balance. A novel self-supervised learning strategy is introduced to identify emergent structural variables due to the general unavailability of labels for entropic state variables.

Result: The method was validated on benchmark systems and showed utility in two challenging examples: coarse-graining star polymers while preserving non-equilibrium statistics, and learning models from colloidal suspension videos that capture the coupling between local rearrangement events and emergent stochastic dynamics. Open-source implementations in PyTorch and LAMMPS are available.

Conclusion: The proposed framework, utilizing the metriplectic bracket formalism and a novel self-supervised learning strategy, effectively machine learns coarse-grained dynamics from observational data while preserving essential physical properties like thermodynamic laws and fluctuation-dissipation balance. It is validated on benchmark systems and demonstrated on complex problems like star polymers and colloidal suspensions, with open-source implementations provided for PyTorch and LAMMPS.

Abstract: Multiscale systems are ubiquitous in science and technology, but are
notoriously challenging to simulate as short spatiotemporal scales must be
appropriately linked to emergent bulk physics. When expensive high-dimensional
dynamical systems are coarse-grained into low-dimensional models, the entropic
loss of information leads to emergent physics which are dissipative,
history-dependent, and stochastic. To machine learn coarse-grained dynamics
from time-series observations of particle trajectories, we propose a framework
using the metriplectic bracket formalism that preserves these properties by
construction; most notably, the framework guarantees discrete notions of the
first and second laws of thermodynamics, conservation of momentum, and a
discrete fluctuation-dissipation balance crucial for capturing non-equilibrium
statistics. We introduce the mathematical framework abstractly before
specializing to a particle discretization. As labels are generally unavailable
for entropic state variables, we introduce a novel self-supervised learning
strategy to identify emergent structural variables. We validate the method on
benchmark systems and demonstrate its utility on two challenging examples: (1)
coarse-graining star polymers at challenging levels of coarse-graining while
preserving non-equilibrium statistics, and (2) learning models from high-speed
video of colloidal suspensions that capture coupling between local
rearrangement events and emergent stochastic dynamics. We provide open-source
implementations in both PyTorch and LAMMPS, enabling large-scale inference and
extensibility to diverse particle-based systems.

</details>


### [508] [Deep Learning Model for Amyloidogenicity Prediction using a Pre-trained Protein LLM](https://arxiv.org/abs/2508.12575)
*Zohra Yagoub,Hafida Bouziane*

Main category: cs.LG

TL;DR: 本研究提出一种基于大型语言模型、LSTM和GRU的淀粉样蛋白预测新方法，准确率高达84.5%，显示出在该领域的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 预测肽和蛋白质中的淀粉样蛋白生成性仍然是生物信息学领域的研究重点，而应用先进的计算方法是该领域面临的关键步骤。

Method: 本研究利用预训练的蛋白质语言模型，结合双向LSTM和GRU，提取蛋白质序列的上下文特征，以预测肽和蛋白质序列中的淀粉样蛋白区域。

Result: 本研究提出的方法在10倍交叉验证中达到了84.5%的准确率，在测试数据集中达到了83%的准确率，表现出具有竞争力的性能。

Conclusion: 本研究结果表明，大型语言模型在提高淀粉样蛋白预测准确性方面具有巨大潜力。

Abstract: The prediction of amyloidogenicity in peptides and proteins remains a focal
point of ongoing bioinformatics. The crucial step in this field is to apply
advanced computational methodologies. Many recent approaches to predicting
amyloidogenicity within proteins are highly based on evolutionary motifs and
the individual properties of amino acids. It is becoming increasingly evident
that the sequence information-based features show high predictive performance.
Consequently, our study evaluated the contextual features of protein sequences
obtained from a pretrained protein large language model leveraging
bidirectional LSTM and GRU to predict amyloidogenic regions in peptide and
protein sequences. Our method achieved an accuracy of 84.5% on 10-fold
cross-validation and an accuracy of 83% in the test dataset. Our results
demonstrate competitive performance, highlighting the potential of LLMs in
enhancing the accuracy of amyloid prediction.

</details>


### [509] [Widening the Network Mitigates the Impact of Data Heterogeneity on FedAvg](https://arxiv.org/abs/2508.12576)
*Like Jian,Dong Liu*

Main category: cs.LG

TL;DR: 联邦学习在无限宽度下，其性能等同于集中式学习，数据异质性问题消失。


<details>
  <summary>Details</summary>
Motivation: 联邦学习（FL）允许多个客户端协作训练模型，而无需共享本地数据。然而，与集中式学习不同，FL中的客户端数据通常不是独立同分布的，这给训练一个能在不同数据分布上泛化良好的全局模型带来了挑战。

Method: 通过理论分析了过参数化FedAvg与梯度下降（GD）的收敛性，并证明了数据异质性对模型的影响会随着神经网络宽度的增加而减小，在宽度趋于无穷大时消失。

Result: 证明了在无限宽度下，数据异质性对模型的影响会消失，并且FedAvg的性能等同于集中式学习。实验结果在各种网络架构、损失函数和优化方法上验证了这些理论发现。

Conclusion: 在无限宽度下，FedAvg的全局和局部模型都表现得像线性模型，并且FedAvg可以实现与具有相同梯度下降迭代次数的集中式学习相同的泛化性能。

Abstract: Federated learning (FL) enables decentralized clients to train a model
collaboratively without sharing local data. A key distinction between FL and
centralized learning is that clients' data are non-independent and identically
distributed, which poses significant challenges in training a global model that
generalizes well across heterogeneous local data distributions. In this paper,
we analyze the convergence of overparameterized FedAvg with gradient descent
(GD). We prove that the impact of data heterogeneity diminishes as the width of
neural networks increases, ultimately vanishing when the width approaches
infinity. In the infinite-width regime, we further prove that both the global
and local models in FedAvg behave as linear models, and that FedAvg achieves
the same generalization performance as centralized learning with the same
number of GD iterations. Extensive experiments validate our theoretical
findings across various network architectures, loss functions, and optimization
methods.

</details>


### [510] [Energy-Efficient Wireless LLM Inference via Uncertainty and Importance-Aware Speculative Decoding](https://arxiv.org/abs/2508.12590)
*Jihoon Park,Seungeun Oh,Seong-Lyun Kim*

Main category: cs.LG

TL;DR: 提出了一种新的 token 级过滤机制，用于在资源受限设备上实现能效高的混合语言模型（HLM）推理，通过仅上传信息量大的 token 来显著降低能耗和通信成本，同时保持高准确率和吞吐量。


<details>
  <summary>Details</summary>
Motivation: 为了满足资源受限环境中设备端大型语言模型推理日益增长的需求，提出了混合语言模型（HLM），它结合了轻量级的本地模型和强大的云端大型语言模型。然而，近期关于 HLM 的研究主要集中在提高准确性和降低延迟，而往往忽略了通信和能源效率。

Method: 提出了一种面向能效的、基于注意力和不确定性的混合语言模型（HLM）推理的 token 级过滤机制，该机制利用了认知不确定性和基于注意力的重要性，仅上传信息量大的 token，从而减少了大型语言模型的使用和通信成本。

Result: 实验结果表明，该方法在 TinyLlama-1.1B 和 LLaMA-2-7B 上实现了高达 87.5% 的 BERT Score 和 0.37 tokens/sec 的 token 吞吐量，同时与标准的 HLM 相比，能耗节省了 40.7%。与之前的 U-HLM 基线相比，该方法将 BERT Score 从 85.8% 提高到 87.0%，能耗节省从 31.6% 提高到 43.6%，吞吐量从 0.36 提高到 0.40。

Conclusion: 该方法支持在带宽受限的边缘环境中，能量高效且准确地部署大型语言模型。

Abstract: To address the growing demand for on-device LLM inference in
resource-constrained environments, hybrid language models (HLM) have emerged,
combining lightweight local models with powerful cloud-based LLMs. Recent
studies on HLM have primarily focused on improving accuracy and latency, while
often overlooking communication and energy efficiency. We propose a token-level
filtering mechanism for an energy-efficient importance- and uncertainty-aware
HLM inference that leverages both epistemic uncertainty and attention-based
importance. Our method opportunistically uploads only informative tokens,
reducing LLM usage and communication costs. Experiments with TinyLlama-1.1B and
LLaMA-2-7B demonstrate that our method achieves up to 87.5% BERT Score and
token throughput of 0.37 tokens/sec while saving the energy consumption by
40.7% compared to standard HLM. Furthermore, compared to our previous U-HLM
baseline, our method improves BERTScore from 85.8% to 87.0%, energy savings
from 31.6% to 43.6%, and throughput from 0.36 to 0.40. This approach enables an
energy-efficient and accurate deployment of LLMs in bandwidth-constrained edge
environments.

</details>


### [511] [Physics-informed deep operator network for traffic state estimation](https://arxiv.org/abs/2508.12593)
*Zhihao Li,Ting Wang,Guojian Zou,Ruofei Wang,Ye Li*

Main category: cs.LG

TL;DR: 本文提出PI-DeepONet框架，将交通状态估计转化为算子学习问题，通过整合交通流守恒模型和基本图，实现了比PINNs更好的物理一致性和性能。


<details>
  <summary>Details</summary>
Motivation: 交通状态估计（TSE）是从有限且带有噪声的测量中求解控制交通流动力学的高维时空偏微分方程（PDEs）的基本问题。现有的PINNs方法在点位上强制执行PDE约束，但本文旨在提出一种新的方法来解决TSE问题。

Method: 本文提出了一种基于物理信息深度算子网络（PI-DeepONet）的框架，将交通状态估计（TSE）重新构建为算子学习问题，训练一个参数化的神经算子，将稀疏输入数据映射到完整的时空交通状态场，该过程遵循交通流守恒定律。与PINNs不同，PI-DeepONet将交通流守恒模型和基本图直接整合到算子学习过程中，确保了物理一致性。

Result: 在NGSIM数据集上的实验表明，PI-DeepONet的性能优于最先进的基线方法。进一步的分析揭示了最优函数生成策略和分支网络复杂性的见解，并探讨了输入函数生成方法和函数数量对模型性能的影响。

Conclusion: PI-DeepONet框架在交通状态估计问题上展现出优越性能，能够有效捕捉拥堵传播、空间相关性和时间演化，并且具有鲁棒性和高效性。

Abstract: Traffic state estimation (TSE) fundamentally involves solving
high-dimensional spatiotemporal partial differential equations (PDEs) governing
traffic flow dynamics from limited, noisy measurements. While Physics-Informed
Neural Networks (PINNs) enforce PDE constraints point-wise, this paper adopts a
physics-informed deep operator network (PI-DeepONet) framework that
reformulates TSE as an operator learning problem. Our approach trains a
parameterized neural operator that maps sparse input data to the full
spatiotemporal traffic state field, governed by the traffic flow conservation
law. Crucially, unlike PINNs that enforce PDE constraints point-wise,
PI-DeepONet integrates traffic flow conservation model and the fundamental
diagram directly into the operator learning process, ensuring physical
consistency while capturing congestion propagation, spatial correlations, and
temporal evolution. Experiments on the NGSIM dataset demonstrate superior
performance over state-of-the-art baselines. Further analysis reveals insights
into optimal function generation strategies and branch network complexity.
Additionally, the impact of input function generation methods and the number of
functions on model performance is explored, highlighting the robustness and
efficacy of proposed framework.

</details>


### [512] [FLARE: Fast Low-rank Attention Routing Engine](https://arxiv.org/abs/2508.12594)
*Vedant Puri,Aditya Joglekar,Kevin Ferguson,Yu-hsuan Chen,Yongjie Jessica Zhang,Levent Burak Kara*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The quadratic complexity of self-attention limits its applicability and
scalability on large unstructured meshes. We introduce Fast Low-rank Attention
Routing Engine (FLARE), a linear complexity self-attention mechanism that
routes attention through fixed-length latent sequences. Each attention head
performs global communication among $N$ tokens by projecting the input sequence
onto a fixed length latent sequence of $M \ll N$ tokens using learnable query
tokens. By routing attention through a bottleneck sequence, FLARE learns a
low-rank form of attention that can be applied at $O(NM)$ cost. FLARE not only
scales to unprecedented problem sizes, but also delivers superior accuracy
compared to state-of-the-art neural PDE surrogates across diverse benchmarks.
We also release a new additive manufacturing dataset to spur further research.
Our code is available at https://github.com/vpuri3/FLARE.py.

</details>


### [513] [Constructing Invariant and Equivariant Operations by Symmetric Tensor Network](https://arxiv.org/abs/2508.12596)
*Meng Zhang,Chao Wang,Hao Zhang,Shaojun Dong,Lixin He*

Main category: cs.LG

TL;DR: 一种用于构建和证明几何深度学习中不变/等变神经网络操作的新方法，该方法使用对称张量网络，并已应用于材料科学。


<details>
  <summary>Details</summary>
Motivation: 设计包含对称性的神经网络对于几何深度学习至关重要，其核心是开发不变和等变操作。

Method: 通过利用对称张量网络进行图形化表示，简化了不变和等变函数的证明和构建过程。

Result: 将此方法应用于设计几何图神经网络的等变交互信息，以及用于学习材料构成定律的等变机器学习模型。

Conclusion: 该方法能够系统性地构建有效的不变和等变操作，处理具有不同秩的笛卡尔张量和不同类型的球谐张量形式的输入和输出。

Abstract: Design of neural networks that incorporate symmetry is crucial for geometric
deep learning. Central to this effort is the development of invariant and
equivariant operations. This works presents a systematic method for
constructing valid invariant and equivariant operations. It can handle inputs
and outputs in the form of Cartesian tensors with different rank, as well as
spherical tensors with different types. In addition, our method features a
graphical representation utilizing the symmetric tensor network, which
simplifies both the proofs and constructions related to invariant and
equivariant functions. We also apply this approach to design the equivariant
interaction message for the geometry graph neural network, and equivariant
machine learning model to learn the constitutive law of materials.

</details>


### [514] [A Hybrid Surrogate for Electric Vehicle Parameter Estimation and Power Consumption via Physics-Informed Neural Operators](https://arxiv.org/abs/2508.12602)
*Hansol Lim,Jongseong Brad Choi,Jee Won Lee,Haeseong Jeoung,Minkyu Han*

Main category: cs.LG

TL;DR: 提出了一种混合替代模型，通过结合傅立叶神经算子和可微分物理模块来估算电动汽车的功率消耗和参数。该模型在真实数据上表现出色，误差小，并且具有良好的可解释性和泛化能力，可应用于多种实际场景。


<details>
  <summary>Details</summary>
Motivation: 为了准确估计电动汽车的参数和功率消耗，并消除单独的物理残差损失，同时使表示能够收敛到物理上有意义的参数，以反映车辆的当前状态和状况。

Method: 提出了一种混合替代模型，结合了基于傅立叶神经替代模型的谱参数算子（用于全局上下文）和一个可微分的物理模块（用于前向传播），以估计电动汽车的参数和功率消耗。

Result: 从速度和加速度估算出时变电机和再生制动效率、空气动力学阻力、滚动阻力、有效质量和辅助功率。该模型在特斯拉Model 3、特斯拉Model S和起亚EV9的真实日志上进行了评估，在特斯拉车型上实现了0.2kW的平均绝对误差（约占高速公路行驶平均牵引功率的1%），在起亚EV9上实现了约0.8kW的误差。

Conclusion: 该模型能够准确估计电动汽车的参数和功率消耗，在特斯拉车型上平均绝对误差为0.2kW，在起亚EV9上为0.8kW。该框架具有可解释性，并且能够很好地泛化到未知的条件和采样率，可用于路径优化、生态路线规划、车载诊断和预测性健康管理。

Abstract: We present a hybrid surrogate model for electric vehicle parameter estimation
and power consumption. We combine our novel architecture Spectral Parameter
Operator built on a Fourier Neural Operator backbone for global context and a
differentiable physics module in the forward pass. From speed and acceleration
alone, it outputs time-varying motor and regenerative braking efficiencies, as
well as aerodynamic drag, rolling resistance, effective mass, and auxiliary
power. These parameters drive a physics-embedded estimate of battery power,
eliminating any separate physics-residual loss. The modular design lets
representations converge to physically meaningful parameters that reflect the
current state and condition of the vehicle. We evaluate on real-world logs from
a Tesla Model 3, Tesla Model S, and the Kia EV9. The surrogate achieves a mean
absolute error of 0.2kW (about 1% of average traction power at highway speeds)
for Tesla vehicles and about 0.8kW on the Kia EV9. The framework is
interpretable, and it generalizes well to unseen conditions, and sampling
rates, making it practical for path optimization, eco-routing, on-board
diagnostics, and prognostics health management.

</details>


### [515] [SSPO: Self-traced Step-wise Preference Optimization for Process Supervision and Reasoning Compression](https://arxiv.org/abs/2508.12604)
*Yuyang Xu,Yi Cheng,Haochao Ying,Zhuoyun Du,Renjun Hu,Xing Shi,Wei Lin,Jian Wu*

Main category: cs.LG

TL;DR: SSPO 是一种新的 RL 框架，通过模型自身的信号优化推理步骤，无需额外标注或模型，即可提高 LLM 性能并减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有的测试时标定方法（如具有思维链推理的强化学习）由于辅助模型和过度思考而带来显著的计算开销。不正确的答案部分源于详细的推理过程，缺乏正确的自我修正，错误会随着多个推理步骤累积。

Method: SSPO (Self-traced Step-wise Preference Optimization) 是一种可插拔的 RL 过程监督框架，无需辅助模型或逐步人工标注，利用模型自身生成的逐步偏好信号来指导优化过程，实现推理压缩。

Result: SSPO 生成的推理序列准确且简洁，有效缓解了过度思考行为，同时不影响模型在不同领域和语言上的性能。

Conclusion: SSPO 是一种可插拔的 RL 过程监督框架，通过自身生成的逐步偏好信号来指导推理压缩的优化过程，实现了准确且简洁的推理序列，有效缓解了过度思考行为，同时不影响模型在不同领域和语言上的性能。

Abstract: Test-time scaling has proven effective in further enhancing the performance
of pretrained Large Language Models (LLMs). However, mainstream post-training
methods (i.e., reinforcement learning (RL) with chain-of-thought (CoT)
reasoning) often incur substantial computational overhead due to auxiliary
models and overthinking. In this paper, we empirically reveal that the
incorrect answers partially stem from verbose reasoning processes lacking
correct self-fix, where errors accumulate across multiple reasoning steps. To
this end, we propose Self-traced Step-wise Preference Optimization (SSPO), a
pluggable RL process supervision framework that enables fine-grained
optimization of each reasoning step. Specifically, SSPO requires neither
auxiliary models nor stepwise manual annotations. Instead, it leverages
step-wise preference signals generated by the model itself to guide the
optimization process for reasoning compression. Experiments demonstrate that
the generated reasoning sequences from SSPO are both accurate and succinct,
effectively mitigating overthinking behaviors without compromising model
performance across diverse domains and languages.

</details>


### [516] [How can we trust opaque systems? Criteria for robust explanations in XAI](https://arxiv.org/abs/2508.12623)
*Florian J. Boge,Annika Schuster*

Main category: cs.LG

TL;DR: Explainable AI (XAI) methods for deep learning are not always trustworthy. A proposed solution is to ensure that different XAI methods produce similar explanations for similar contexts (explanatory robustness) and that each individual method is reliable on its own (explanation method robustness).


<details>
  <summary>Details</summary>
Motivation: Deep learning (DL) algorithms are becoming ubiquitous in everyday life and in scientific research. However, the price we pay for their impressively accurate predictions is significant: their inner workings are notoriously opaque - it is unknown to laypeople and researchers alike what features of the data a DL system focuses on and how it ultimately succeeds in predicting correct outputs. A necessary criterion for trustworthy explanations is that they should reflect the relevant processes the algorithms' predictions are based on. The field of eXplainable Artificial intelligence (XAI) presents promising methods to create such explanations. But recent reviews about their performance offer reasons for skepticism.

Method: In what follows, we develop and formalize criteria for ER as well as EMR, providing a framework for explaining and establishing trust in DL algorithms. We also highlight interesting application cases and outline directions for future work.

Result: The robustness of an individual method is in itself insufficient for trustworthiness.

Conclusion: As we will argue, a good criterion for trustworthiness is explanatory robustness: different XAI methods produce the same explanations in comparable contexts. However, in some instances, all methods may give the same, but still wrong, explanation. We therefore argue that in addition to explanatory robustness (ER), a prior requirement of explanation method robustness (EMR) has to be fulfilled by every XAI method. Conversely, the robustness of an individual method is in itself insufficient for trustworthiness.

Abstract: Deep learning (DL) algorithms are becoming ubiquitous in everyday life and in
scientific research. However, the price we pay for their impressively accurate
predictions is significant: their inner workings are notoriously opaque - it is
unknown to laypeople and researchers alike what features of the data a DL
system focuses on and how it ultimately succeeds in predicting correct outputs.
A necessary criterion for trustworthy explanations is that they should reflect
the relevant processes the algorithms' predictions are based on. The field of
eXplainable Artificial Intelligence (XAI) presents promising methods to create
such explanations. But recent reviews about their performance offer reasons for
skepticism. As we will argue, a good criterion for trustworthiness is
explanatory robustness: different XAI methods produce the same explanations in
comparable contexts. However, in some instances, all methods may give the same,
but still wrong, explanation. We therefore argue that in addition to
explanatory robustness (ER), a prior requirement of explanation method
robustness (EMR) has to be fulfilled by every XAI method. Conversely, the
robustness of an individual method is in itself insufficient for
trustworthiness. In what follows, we develop and formalize criteria for ER as
well as EMR, providing a framework for explaining and establishing trust in DL
algorithms. We also highlight interesting application cases and outline
directions for future work.

</details>


### [517] [FlowMol3: Flow Matching for 3D De Novo Small-Molecule Generation](https://arxiv.org/abs/2508.12629)
*Ian Dunn,David R. Koes*

Main category: cs.LG

TL;DR: FlowMol3是一个新的分子生成模型，通过三种简单技术显著提高了分子生成质量和稳定性，参数量更少。


<details>
  <summary>Details</summary>
Motivation: 开发能够生成具有期望性质的真实分子的生成模型，以加速化学发现。

Method: FlowMol3是一个多模态流匹配模型，利用自调节、假原子和训练时几何变形等技术来生成分子拓扑和3D结构。

Result: FlowMol3在分子有效性、官能团组成和几何结构再现方面取得了显著的性能提升，同时大大减少了可学习参数的数量，并且这些改进是在不改变模型架构和公式的情况下实现的。ansir2=

Conclusion: FlowMol3通过引入自调节、假原子和训练时几何变形等模型无关的技术，在不改变图神经网络架构或基础流匹配公式的情况下，显著提高了所有原子小分子生成的状态。该模型实现了近乎100%的药物分子有效性，更准确地再现了训练数据的官能团组成和几何结构，并且参数量比同类方法少一个数量级。这些技术有望解决基于传输的生成模型普遍存在的分布漂移问题，提高其稳定性和质量。

Abstract: A generative model capable of sampling realistic molecules with desired
properties could accelerate chemical discovery across a wide range of
applications. Toward this goal, significant effort has focused on developing
models that jointly sample molecular topology and 3D structure. We present
FlowMol3, an open-source, multi-modal flow matching model that advances the
state of the art for all-atom, small-molecule generation. Its substantial
performance gains over previous FlowMol versions are achieved without changes
to the graph neural network architecture or the underlying flow matching
formulation. Instead, FlowMol3's improvements arise from three
architecture-agnostic techniques that incur negligible computational cost:
self-conditioning, fake atoms, and train-time geometry distortion. FlowMol3
achieves nearly 100% molecular validity for drug-like molecules with explicit
hydrogens, more accurately reproduces the functional group composition and
geometry of its training data, and does so with an order of magnitude fewer
learnable parameters than comparable methods. We hypothesize that these
techniques mitigate a general pathology affecting transport-based generative
models, enabling detection and correction of distribution drift during
inference. Our results highlight simple, transferable strategies for improving
the stability and quality of diffusion- and flow-based molecular generative
models.

</details>


### [518] [Score-informed Neural Operator for Enhancing Ordering-based Causal Discovery](https://arxiv.org/abs/2508.12650)
*Jiyeon Kang,Songseong Kim,Chanhui Lee,Doyeong Hwang,Joanie Hayoun Chung,Yunkyung Ko,Sumin Lee,Sungwoong Kim,Sungbin Lim*

Main category: cs.LG

TL;DR: 提出了一种名为SciNO的概率生成模型，用于稳定估计因果排序的Hessian对角线，解决了现有方法的数值不稳和计算效率问题。SciNO在合成和真实数据集上均显著减少了顺序发散性，并能增强大型语言模型的因果推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的基于得分匹配的因果排序方法在加性噪声模型（ANM）假设下，需要精确估计对数密度的Hessian对角线。然而，先前的方法主要使用计算成本高且内存密集型的Stein梯度估计器。DiffAN虽然用扩散模型替代了基于核的估计，但由于二阶导数，仍然存在数值不稳定的问题。

Method: 提出了一种名为Score-informed Neural Operator (SciNO) 的概率生成模型，该模型位于光滑函数空间中，能够稳定地近似Hessian对角线并保留分数建模中的结构信息。此外，还提出了一种概率控制算法，将SciNO的概率估计与自回归模型先验相结合，用于因果推理。

Result: SciNO将顺序发散性在合成图上平均降低了42.7%，在真实世界数据集上平均降低了31.5%，优于DiffAN。该方法在内存效率和可扩展性方面也表现良好。所提出的概率控制算法能够增强大型语言模型的因果推理能力。

Conclusion: SciNO通过稳定地近似Hessian对角线并保留分数建模中的结构信息，解决了现有方法的局限性。与DiffAN相比，SciNO在合成图和真实世界数据集上分别将顺序发散性平均降低了42.7%和31.5%，同时保持了内存效率和可扩展性。此外，提出了一种将SciNO的概率估计与自回归模型先验相结合的概率控制算法，用于因果推理，从而在不进行额外微调或提示工程的情况下增强了大型语言模型的因果推理能力。

Abstract: Ordering-based approaches to causal discovery identify topological orders of
causal graphs, providing scalable alternatives to combinatorial search methods.
Under the Additive Noise Model (ANM) assumption, recent causal ordering methods
based on score matching require an accurate estimation of the Hessian diagonal
of the log-densities. However, previous approaches mainly use Stein gradient
estimators, which are computationally expensive and memory-intensive. Although
DiffAN addresses these limitations by substituting kernel-based estimates with
diffusion models, it remains numerically unstable due to the second-order
derivatives of score models. To alleviate these problems, we propose
Score-informed Neural Operator (SciNO), a probabilistic generative model in
smooth function spaces designed to stably approximate the Hessian diagonal and
to preserve structural information during the score modeling. Empirical results
show that SciNO reduces order divergence by 42.7% on synthetic graphs and by
31.5% on real-world datasets on average compared to DiffAN, while maintaining
memory efficiency and scalability. Furthermore, we propose a probabilistic
control algorithm for causal reasoning with autoregressive models that
integrates SciNO's probability estimates with autoregressive model priors,
enabling reliable data-driven causal ordering informed by semantic information.
Consequently, the proposed method enhances causal reasoning abilities of LLMs
without additional fine-tuning or prompt engineering.

</details>


### [519] [Robust Federated Learning under Adversarial Attacks via Loss-Based Client Clustering](https://arxiv.org/abs/2508.12672)
*Emmanouil Kritharakis,Dusan Jakovetic,Antonios Makris,Konstantinos Tserpes*

Main category: cs.LG

TL;DR: 在受拜占庭攻击的联邦学习（FL）场景中，即使只有两个诚实参与者（服务器和一名客户端），该方法也能有效运作，并优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决联邦学习（FL）场景中客户端受到_adversarial_（拜占庭）攻击的问题，同时假设FL服务器是受信任的（诚实的），并且拥有一个可信的侧边数据集。

Method: 本研究提出了一种新的联邦学习（FL）方法，即使在有_adversarial_（拜占庭）攻击的情况下，也只需要两个诚实的参与者（服务器和一名_client_）就能有效运作，并且事先不知道恶意_client_的数量。

Result: 理论分析表明，即使在强拜占庭攻击下，该方法也具有有限的最优性差距。实验结果证实了该算法在各种攻击策略下的优越性。

Conclusion: 该方法在MNIST、FMNIST和CIFAR-10基准测试中，在各种攻击策略下，显著优于标准的和鲁棒的FL基线，如平均值、修剪平均值、中位数、Krum和Multi-Krum。

Abstract: Federated Learning (FL) enables collaborative model training across multiple
clients without sharing private data. We consider FL scenarios wherein FL
clients are subject to adversarial (Byzantine) attacks, while the FL server is
trusted (honest) and has a trustworthy side dataset. This may correspond to,
e.g., cases where the server possesses trusted data prior to federation, or to
the presence of a trusted client that temporarily assumes the server role. Our
approach requires only two honest participants, i.e., the server and one
client, to function effectively, without prior knowledge of the number of
malicious clients. Theoretical analysis demonstrates bounded optimality gaps
even under strong Byzantine attacks. Experimental results show that our
algorithm significantly outperforms standard and robust FL baselines such as
Mean, Trimmed Mean, Median, Krum, and Multi-Krum under various attack
strategies including label flipping, sign flipping, and Gaussian noise addition
across MNIST, FMNIST, and CIFAR-10 benchmarks using the Flower framework.

</details>


### [520] [Deploying Models to Non-participating Clients in Federated Learning without Fine-tuning: A Hypernetwork-based Approach](https://arxiv.org/abs/2508.12673)
*Yuhao Zhou,Jindi Lv,Yuxin Tian,Dan Si,Qing Ye,Jiancheng Lv*

Main category: cs.LG

TL;DR: HyperFedZero 是一种新颖的联邦学习方法，通过超网络为非参与方生成专用模型，以解决数据异质性和域内分布偏移问题，并在实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦学习方法在解决参与方的数据异质性方面取得了进展，但在处理非参与方的数据异质性（尤其是在存在域内分布偏移和资源限制的情况下）方面仍存在不足。因此，需要一种能够适应非参与方独特数据分布并克服这些挑战的新方法。

Method: HyperFedZero 提出了一种新颖的方法，通过条件于感知分布的嵌入的超网络动态地生成专用模型。该方法将感知分布的归纳偏置显式地纳入模型的正向传播中，并使用增强了噪声嵌入的提取器和平衡惩罚来提取鲁棒的分布嵌入，有效防止特征崩溃。然后，超网络利用这些嵌入为非参与方生成分块的专用模型，以适应其独特的数据分布。

Result: HyperFedZero 实现了卓越的性能，在处理数据异质性和域内分布偏移方面优于现有方法，同时保持了较低的计算、存储和通信开销。

Conclusion: HyperFedZero 在多个数据集和模型上进行了广泛的实验，其性能显著优于现有方法，并且计算、存储和通信开销极小。组件的必要性也通过消融研究和可视化得到了验证，证明了其有效的适应性和整体的有效性。

Abstract: Federated Learning (FL) has emerged as a promising paradigm for
privacy-preserving collaborative learning, yet data heterogeneity remains a
critical challenge. While existing methods achieve progress in addressing data
heterogeneity for participating clients, they fail to generalize to
non-participating clients with in-domain distribution shifts and resource
constraints. To mitigate this issue, we present HyperFedZero, a novel method
that dynamically generates specialized models via a hypernetwork conditioned on
distribution-aware embeddings. Our approach explicitly incorporates
distribution-aware inductive biases into the model's forward pass, extracting
robust distribution embeddings using a NoisyEmbed-enhanced extractor with a
Balancing Penalty, effectively preventing feature collapse. The hypernetwork
then leverages these embeddings to generate specialized models chunk-by-chunk
for non-participating clients, ensuring adaptability to their unique data
distributions. Extensive experiments on multiple datasets and models
demonstrate HyperFedZero's remarkable performance, surpassing competing methods
consistently with minimal computational, storage, and communication overhead.
Moreover, ablation studies and visualizations further validate the necessity of
each component, confirming meaningful adaptations and validating the
effectiveness of HyperFedZero.

</details>


### [521] [Argos: A Decentralized Federated System for Detection of Traffic Signs in CAVs](https://arxiv.org/abs/2508.12712)
*Seyed Mahdi Haji Seyed Hossein,Alireza Hosseini,Soheil Hajian Manesh,Amirali Shahriary*

Main category: cs.LG

TL;DR: 该研究提出了一种用于车辆网络交通标志检测的去中心化联邦学习框架，通过本地训练和参数聚合实现协作学习，解决了隐私和通信挑战，并在模拟环境中证明了其有效性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 为了解决联网和自动化车辆产生的海量传感器数据所带来的隐私和通信挑战，以及当前中心化机器学习方法在感知任务中的局限性。

Method: 提出了一种去中心化的联邦学习框架，用于车辆网络中的交通标志检测。该框架将交通标志类别分配给车辆进行本地训练，并使用FedProx、FedAdam和FedAVG等算法聚合模型参数。通过Flower框架在模拟环境中进行了评估，并测试了不同的服务器轮次、本地周期、客户端参与比例和数据分布配置。

Result: 实验表明，增加服务器轮次可显著提高准确性（从低于0.1提升至0.8以上）；适度的本地周期（8-10个）效率最佳，准确率约为0.67；更高的客户端参与比例可将泛化能力提升至0.83；FedProx在处理异质性方面优于其他聚合器；非独立同分布（non-IID）数据分布会降低性能；训练时间主要随轮次数量扩展。

Conclusion: 该研究提出的联邦学习框架为车联网中的交通标志检测提供了一种可扩展、注重隐私的解决方案，有望指导未来智能交通系统的集成。

Abstract: Connected and automated vehicles generate vast amounts of sensor data daily,
raising significant privacy and communication challenges for centralized
machine learning approaches in perception tasks. This study presents a
decentralized, federated learning framework tailored for traffic sign detection
in vehicular networks to enable collaborative model training without sharing
raw data. The framework partitioned traffic sign classes across vehicles for
specialized local training using lightweight object detectors, aggregated model
parameters via algorithms like FedProx, FedAdam and FedAVG in a simulated
environment with the Flower framework, and evaluated multiple configurations
including varying server rounds, local epochs, client participation fractions,
and data distributions. Experiments demonstrated that increasing server rounds
from 2 to 20 boosted accuracy from below 0.1 to over 0.8, moderate local epochs
(8-10) provided optimal efficiency with accuracies around 0.67, higher client
participation fractions enhanced generalization up to 0.83, FedProx
outperformed other aggregators in handling heterogeneity, non-IID data
distributions reduced performance compared to IID, and training duration
primarily scaled with the number of rounds rather than aggregation strategy. We
conclude that this federated approach may offer a scalable, privacy-preserving
solution for real-world vehicular deployments, potentially guiding future
integrations of robust aggregation and communication optimizations to advance
intelligent transportation systems.

</details>


### [522] [FedSODA: Federated Fine-tuning of LLMs via Similarity Group Pruning and Orchestrated Distillation Alignment](https://arxiv.org/abs/2508.12727)
*Manning Zhu,Songtao Guo,Pengzhan Zhou,Yansong Ning,Chang Han,Dewen Qiao*

Main category: cs.LG

TL;DR: FedSODA是一个高效的联邦微调框架，通过模型剪枝和蒸馏对齐技术，显著降低了LLM在资源受限设备上的微调成本，同时保持了模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决在资源受限的客户端上进行大型语言模型（LLM）联邦微调（FFT）时，由于完整模型微调带来的高计算和内存需求所带来的限制，以实现更广泛的应用。

Method: 提出了一种名为FedSODA的联邦微调（FFT）框架，该框架包含两个核心模块：1. SIMILARITY GROUP PRUNING (SGP)：修剪冗余层，保留关键层，以保持模型性能。2. ORCHESTRATED DISTILLATION ALIGNMENT (ODA)：减少微调过程中子模型与完整模型之间的梯度发散。结合QLORA技术，客户端只需部署量化后的子模型并微调轻量级适配器。

Result: FedSODA在通信开销、存储使用和任务准确率方面均取得了显著改善，通信开销平均减少70.6%，存储使用减少75.6%，任务准确率提高3.1%。

Conclusion: FedSODA通过SIMILARITY GROUP PRUNING (SGP)和ORCHESTRATED DISTILLATION ALIGNMENT (ODA)模块，在资源受限的客户端上实现了高效的联邦微调（FFT），显著降低了通信开销（平均70.6%）和存储使用（75.6%），同时将任务准确率提高了3.1%，使其非常适用于资源受限的实际FFT应用。

Abstract: Federated fine-tuning (FFT) of large language models (LLMs) has recently
emerged as a promising solution to enable domain-specific adaptation while
preserving data privacy. Despite its benefits, FFT on resource-constrained
clients relies on the high computational and memory demands of full-model
fine-tuning, which limits the potential advancement. This paper presents
FedSODA, a resource-efficient FFT framework that enables clients to adapt LLMs
without accessing or storing the full model. Specifically, we first propose a
similarity group pruning (SGP) module, which prunes redundant layers from the
full LLM while retaining the most critical layers to preserve the model
performance. Moreover, we introduce an orchestrated distillation alignment
(ODA) module to reduce gradient divergence between the sub-LLM and the full LLM
during FFT. Through the use of the QLoRA, clients only need to deploy quantized
sub-LLMs and fine-tune lightweight adapters, significantly reducing local
resource requirements. We conduct extensive experiments on three open-source
LLMs across a variety of downstream tasks. The experimental results demonstrate
that FedSODA reduces communication overhead by an average of 70.6%, decreases
storage usage by 75.6%, and improves task accuracy by 3.1%, making it highly
suitable for practical FFT applications under resource constraints.

</details>


### [523] [FedUNet: A Lightweight Additive U-Net Module for Federated Learning with Heterogeneous Models](https://arxiv.org/abs/2508.12740)
*Beomseok Seo,Kichang Lee,JaeYeon Park*

Main category: cs.LG

TL;DR: FedUNet 是一种新的联邦学习框架，它通过添加一个轻量级的 U-Net 模块来解决客户端模型架构不一致的问题，实现了高效的知识迁移和低通信成本，并在实验中取得了优异的准确率。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦学习方法大多假设客户端拥有相同的模型架构，这限制了它们在现实世界异构环境中的应用。为了解决这个问题，需要一种能够处理不同模型架构的联邦学习框架。

Method: 提出了一种名为 FedUNet 的轻量级、与架构无关的联邦学习框架。该框架通过在每个客户端的骨干网络上附加一个 U-Net 启发的加性模块来实现。通过仅共享 U-Net 的紧凑瓶颈部分，FedUNet 实现了高效的知识迁移，无需结构对齐。U-Net 的编码器-解码器设计和跳跃连接有助于捕获低级和高级特征，从而提取与客户端无关的表示。这使得骨干网络和加性模块之间能够以最小的通信成本进行协同学习。

Result: FedUNet 实现了高效的知识迁移，并且通信成本极低，同时在 VGG 变体实验中达到了 93.11% 的准确率，其紧凑形式（轻量级版本）准确率也达到了 92.68%，通信开销仅为 0.89 MB。

Conclusion: FedUNet 实现了高效的知识迁移，并且通信成本极低，同时在 VGG 变体实验中达到了 93.11% 的准确率，其紧凑形式（轻量级版本）准确率也达到了 92.68%，通信开销仅为 0.89 MB。

Abstract: Federated learning (FL) enables decentralized model training without sharing
local data. However, most existing methods assume identical model architectures
across clients, limiting their applicability in heterogeneous real-world
environments. To address this, we propose FedUNet, a lightweight and
architecture-agnostic FL framework that attaches a U-Net-inspired additive
module to each client's backbone. By sharing only the compact bottleneck of the
U-Net, FedUNet enables efficient knowledge transfer without structural
alignment. The encoder-decoder design and skip connections in the U-Net help
capture both low-level and high-level features, facilitating the extraction of
clientinvariant representations. This enables cooperative learning between the
backbone and the additive module with minimal communication cost. Experiment
with VGG variants shows that FedUNet achieves 93.11% accuracy and 92.68% in
compact form (i.e., a lightweight version of FedUNet) with only 0.89 MB low
communication overhead.

</details>


### [524] [Constrained Centroid Clustering: A Novel Approach for Compact and Structured Partitioning](https://arxiv.org/abs/2508.12758)
*Sowmini Devi Veeramachaneni,Ramamurthy Garimella*

Main category: cs.LG

TL;DR: Constrained Centroid Clustering (CCC) 是一种通过约束簇中心与最远点之间距离来优化聚类的方法，可实现更紧凑、结构更清晰的簇。


<details>
  <summary>Details</summary>
Motivation: 为需要结构化聚类和散布控制的应用提供一种扩展经典质心聚类的方法

Method: 使用拉格朗日公式推导出闭式解

Result: CCC 在减少径向散布同时保持角度结构方面实现了更紧凑的簇，在合成圆形数据集上的表现优于 K-means 和 GMM。

Conclusion: Constrained Centroid Clustering (CCC) 通过强制执行簇中心与簇中最远点之间的最大距离约束，扩展了经典的基于质心的聚类方法。通过使用拉格朗日公式，我们推导出了一个保持可解释性同时控制簇散布的闭式解。

Abstract: This paper presents Constrained Centroid Clustering (CCC), a method that
extends classical centroid-based clustering by enforcing a constraint on the
maximum distance between the cluster center and the farthest point in the
cluster. Using a Lagrangian formulation, we derive a closed-form solution that
maintains interpretability while controlling cluster spread. To evaluate CCC,
we conduct experiments on synthetic circular data with radial symmetry and
uniform angular distribution. Using ring-wise, sector-wise, and joint entropy
as evaluation metrics, we show that CCC achieves more compact clusters by
reducing radial spread while preserving angular structure, outperforming
standard methods such as K-means and GMM. The proposed approach is suitable for
applications requiring structured clustering with spread control, including
sensor networks, collaborative robotics, and interpretable pattern analysis.

</details>


### [525] [Short-Term Forecasting of Energy Production and Consumption Using Extreme Learning Machine: A Comprehensive MIMO based ELM Approach](https://arxiv.org/abs/2508.12764)
*Cyril Voyant,Milan Despotovic,Luis Garcia-Gutierrez,Mohammed Asloune,Yves-Marie Saint-Drenan,Jean-Laurent Duchaud,hjuvan Antone Faggianelli,Elena Magliaro*

Main category: cs.LG

TL;DR: 提出了一种基于ELM的MIMO短期能源预测方法，使用6年数据，结合滑动窗口和周期时间编码，预测精度高，计算量低，适用于实时应用。


<details>
  <summary>Details</summary>
Motivation: 为了提高短期能源预测的准确性，尤其是在面对多种能源类型和复杂的非平稳性、季节性变化时。

Method: 提出了一种使用极端学习机（ELM）的短期能源预测新方法，采用多输入多输出（MIMO）架构，并结合滑动窗口技术和周期时间编码来处理非平稳性和季节性变化。

Result: ELM模型在太阳能和热电能源预测方面显著优于基于持久性的方法，nRMSE分别为17.9%和5.1%，R^2 > 0.98（1小时预测）。MIMO架构在准确性方面略优于SISO，并优于LSTM等深度学习方法，计算量更低，适合实时应用。

Conclusion: 该ELM模型在短期能源预测方面表现出色，nRMSE低至17.9%（太阳能）和5.1%（ thermal energy），R^2 > 0.98（1小时预测），并且在长达5小时的预测中保持高精度。该MIMO架构具有计算量低、适用于实时应用的优点，并可适应不同场景。

Abstract: A novel methodology for short-term energy forecasting using an Extreme
Learning Machine ($\mathtt{ELM}$) is proposed. Using six years of hourly data
collected in Corsica (France) from multiple energy sources (solar, wind, hydro,
thermal, bioenergy, and imported electricity), our approach predicts both
individual energy outputs and total production (\cyr{including imports, which
closely follow energy demand, modulo losses)} through a Multi-Input
Multi-Output ($\mathtt{MIMO}$) architecture. To address non-stationarity and
seasonal variability, sliding window techniques and cyclic time encoding are
incorporated, enabling dynamic adaptation to fluctuations. The $\mathtt{ELM}$
model significantly outperforms persistence-based forecasting, particularly for
solar and thermal energy, achieving an $\mathtt{nRMSE}$ of $17.9\%$ and
$5.1\%$, respectively, with $\mathtt{R^2} > 0.98$ (1-hour horizon). The model
maintains high accuracy up to five hours ahead, beyond which renewable energy
sources become increasingly volatile. While $\mathtt{MIMO}$ provides marginal
gains over Single-Input Single-Output ($\mathtt{SISO}$) architectures and
offers key advantages over deep learning methods such as $\mathtt{LSTM}$, it
provides a closed-form solution with lower computational demands, making it
well-suited for real-time applications, including online learning. Beyond
predictive accuracy, the proposed methodology is adaptable to various contexts
and datasets, as it can be tuned to local constraints such as resource
availability, grid characteristics, and market structures.

</details>


### [526] [Online Ensemble Transformer for Accurate Cloud Workload Forecasting in Predictive Auto-Scaling](https://arxiv.org/abs/2508.12773)
*Jiadong Chen,Xiao He,Hengyu Ye,Fuxin Jiang,Tieying Zhang,Jianjun Chen,Xiaofeng Gao*

Main category: cs.LG

TL;DR: E3Former是一种用于服务器无系统的新型在线集成预测模型，可提高预测准确性并减少资源利用率。


<details>
  <summary>Details</summary>
Motivation: 现有的工作负载预测模型难以快速适应在线工作负载流的动态变化，并且难以捕捉细粒度、高频预测任务所带来的复杂周期性。因此，有必要开发能够确保最佳资源分配和在高易变性环境中保持运行效率的预测性自动扩展系统。

Method: 提出了一种名为E3Former的新颖在线集成模型，用于在线工作负载预测。该模型通过结合多个子网络的预测能力来克服单一模型方法的局限性。

Result: E3Former在在线预测任务中将预测误差平均降低了10%。此外，在实际在线系统中进行的预测性自动扩展测试也证明了其有效性。目前，该方法已在字节跳动的智能水平Pod自动扩展（IHPA）平台部署，支持超过30个应用程序的稳定运行，预测性自动扩展能力达到60万个CPU核心以上，在保证服务质量的同时，资源利用率降低了40%以上。

Conclusion: E3Former是一种新颖的在线集成模型，用于大规模预测性自动扩展的在线工作负载预测。该模型通过结合多个子网络的预测能力来克服单一模型方法的局限性，从而确保卓越的准确性和鲁棒性，同时计算开销增加极少。

Abstract: In the swiftly evolving domain of cloud computing, the advent of serverless
systems underscores the crucial need for predictive auto-scaling systems. This
necessity arises to ensure optimal resource allocation and maintain operational
efficiency in inherently volatile environments. At the core of a predictive
auto-scaling system is the workload forecasting model. Existing forecasting
models struggle to quickly adapt to the dynamics in online workload streams and
have difficulty capturing the complex periodicity brought by fine-grained,
high-frequency forecasting tasks. Addressing this, we propose a novel online
ensemble model, E3Former, for online workload forecasting in large-scale
predictive auto-scaling. Our model synergizes the predictive capabilities of
multiple subnetworks to surmount the limitations of single-model approaches,
thus ensuring superior accuracy and robustness. Remarkably, it accomplishes
this with a minimal increase in computational overhead, adhering to the lean
operational ethos of serverless systems. Through extensive experimentation on
real-world workload datasets, we establish the efficacy of our ensemble model.
In online forecasting tasks, the proposed method reduces forecast error by an
average of 10%, and its effectiveness is further demonstrated through a
predictive auto-scaling test in the real-life online system. Currently, our
method has been deployed within ByteDance's Intelligent Horizontal Pod
Auto-scaling (IHPA) platform, which supports the stable operation of over 30
applications, such as Douyin E-Comerce, TouTiao, and Volcano Engine. The
predictive auto-scaling capacity reaching over 600,000 CPU cores. On the basis
of essentially ensuring service quality, the predictive auto-scaling system can
reduce resource utilization by over 40%.

</details>


### [527] [Randomized PCA Forest for Outlier Detection](https://arxiv.org/abs/2508.12776)
*Muhammad Rajabinasab,Farhad Pakdaman,Moncef Gabbouj,Peter Schneider-Kamp,Arthur Zimek*

Main category: cs.LG

TL;DR: 提出了一种新的基于随机PCA（RPCA）森林的无监督离群点检测方法，该方法在性能、泛化能力和计算效率方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 受RPCA森林在近似K近邻（KNN）搜索中表现的启发，我们开发了一种利用RPCA森林进行离群点检测的新型无监督方法。

Method: 基于随机主成分分析（RPCA）森林的无监督离群点检测。

Result: 实验结果表明，在几个数据集上的离群点检测任务中，所提出的方法优于经典和最先进的方法，并在其余数据集上表现具有竞争力。

Conclusion: 所提出的方法具有较高的泛化能力和计算效率，是无监督离群点检测的一个不错的选择。

Abstract: We propose a novel unsupervised outlier detection method based on Randomized
Principal Component Analysis (PCA). Inspired by the performance of Randomized
PCA (RPCA) Forest in approximate K-Nearest Neighbor (KNN) search, we develop a
novel unsupervised outlier detection method that utilizes RPCA Forest for
outlier detection. Experimental results showcase the superiority of the
proposed approach compared to the classical and state-of-the-art methods in
performing the outlier detection task on several datasets while performing
competitively on the rest. The extensive analysis of the proposed method
reflects it high generalization power and its computational efficiency,
highlighting it as a good choice for unsupervised outlier detection.

</details>


### [528] [Wavy Transformer](https://arxiv.org/abs/2508.12787)
*Satoshi Noguchi,Yoshinobu Kawahara*

Main category: cs.LG

TL;DR: Wavy Transformer通过引入新的动力学注意层，解决了Transformer的平滑问题，提升了NLP和CV任务的性能。


<details>
  <summary>Details</summary>
Motivation: Transformer模型（尤其是在NLP和CV领域）存在深度模型常见的“平滑”问题，即随着层数加深，其token表示趋于相似。

Method: 提出了一种名为Wavy Transformer的新模型，其核心是一种基于二阶波动动力学的注意层，并配合了旨在保持物理状态-速度关系的特定前馈网络和归一化层。

Result: Wavy Transformer在NLP和CV任务中验证了其有效性，在参数量和超参数开销极小的情况下，一致地提高了Transformer模型的性能。

Conclusion: Wavy Transformer通过引入基于二阶波动动力学的注意层、前馈网络和归一化层，解决了Transformer的平滑问题，并在NLP和CV任务中取得了性能提升，同时参数和超参数的开销极小。

Abstract: Transformers have achieved remarkable success across natural language
processing (NLP) and computer vision (CV). However, deep transformer models
often suffer from an over-smoothing issue, in which token representations
converge to similar values as they pass through successive transformer blocks.
In this paper, we establish an equivalence between the hidden-state dynamics
induced by stacked attention layers and graph neural diffusion on a complete
graph. From this perspective, over-smoothing can be interpreted as a
consequence of the dissipative nature of the underlying diffusion dynamics.
Motivated by this physical interpretation, we propose Wavy Transformer, which
consists of a novel attention layer based on second-order wavy dynamics. We
also introduce a feed-forward network and a normalization layer designed to
preserve the physical state-velocity relationship under the chain rule, thereby
extending the transformer architecture. We further validate our proposed
techniques on various transformer models for NLP and CV tasks. The results
consistently demonstrate that Wavy Transformer improves performance with
minimal additional parameters and no extra hyperparameter tuning.

</details>


### [529] [Bridging Human and LLM Judgments: Understanding and Narrowing the Gap](https://arxiv.org/abs/2508.12792)
*Felipe Maia Polo,Xinhe Wang,Mikhail Yurochkin,Gongjun Xu,Moulinath Banerjee,Yuekai Sun*

Main category: cs.LG

TL;DR: Bridge是一个统计框架，通过建模LLM评分偏差来弥合LLM与人类评估之间的差距，提高了评分一致性并揭示了系统性差异。


<details>
  <summary>Details</summary>
Motivation: LLM作为裁判（LLM-as-a-judge）在评估模型输出方面有广泛应用，但其评估结果常常与人类判断存在系统性偏差。

Method: Bridge是一个统一的统计框架，通过将LLM评分的偏差建模为协变量的线性变换来连接人类和LLM的评估，支持绝对评分和成对比较。

Result: 在六个LLM裁判和两个基准（BigGen Bench和Chatbot Arena）的实验中，Bridge在准确性、校准和KL散度方面提高了与人类评分的一致性，并揭示了系统性的人类-LLM差距。

Conclusion: Bridge框架能够提高LLM评分与人类评分的一致性，并揭示系统性的人类-LLM差异。

Abstract: Large language models are increasingly used as judges (LLM-as-a-judge) to
evaluate model outputs at scale, but their assessments often diverge
systematically from human judgments. We present Bridge, a unified statistical
framework that explicitly bridges human and LLM evaluations under both absolute
scoring and pairwise comparison paradigms. Bridge posits a latent human
preference score for each prompt-response pair and models LLM deviations as
linear transformations of covariates that capture sources of discrepancies.
This offers a simple and principled framework for refining LLM ratings and
characterizing systematic discrepancies between humans and LLMs. We provide an
efficient fitting algorithm with asymptotic guarantees for statistical
inference. Using six LLM judges and two benchmarks (BigGen Bench and Chatbot
Arena), Bridge achieves higher agreement with human ratings (accuracy,
calibration, and KL divergence) and exposes systematic human-LLM gaps.

</details>


### [530] [A Shift in Perspective on Causality in Domain Generalization](https://arxiv.org/abs/2508.12798)
*Damian Machlanski,Stephanie Riley,Edward Moroshko,Kurt Butler,Panagiotis Dimitrakopoulos,Thomas Melistas,Akchunya Chanchal,Steven McDonagh,Ricardo Silva,Sotirios A. Tsaftaris*

Main category: cs.LG

TL;DR: Causality's role in AI generalization is complex; this paper offers a nuanced perspective and an interactive demo.


<details>
  <summary>Details</summary>
Motivation: To address challenges to the promise that causal modelling can lead to robust AI generalization in recent work on domain generalization (DG) benchmarks.

Method: Revisiting claims of the causality and DG literature and reconciling apparent contradictions.

Result: A more nuanced theory of the role of causality in generalization, and an interactive demo available at https://chai-uk.github.io/ukairs25-causal-predictors/.

Conclusion: We advocate for a more nuanced theory of the role of causality in generalization.

Abstract: The promise that causal modelling can lead to robust AI generalization has
been challenged in recent work on domain generalization (DG) benchmarks. We
revisit the claims of the causality and DG literature, reconciling apparent
contradictions and advocating for a more nuanced theory of the role of
causality in generalization. We also provide an interactive demo at
https://chai-uk.github.io/ukairs25-causal-predictors/.

</details>


### [531] [Maximum Score Routing For Mixture-of-Experts](https://arxiv.org/abs/2508.12801)
*Bowen Dong,Yilong Fan,Yutao Sun,Zhenyu Li,Tengyu Pan,Xun Zhou,Jianyong Wang*

Main category: cs.LG

TL;DR: MaxScore 是一种新的 MoE 路由方法，通过将路由建模为最小费用最大流问题来提高效率和负载均衡，解决了传统 MoE 的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统 MoE 网络为确保 GPU 友好计算而施加的专家容量约束会导致容量饱和时出现 token 丢失，并因未充分利用的专家中的填充而导致硬件效率低下。移除容量约束则会影响负载均衡和计算效率。

Method: MaxScore 是一种新颖的 MoE 路由范式，将路由作为最小费用最大流问题进行建模，并集成了一个 SoftTopk 算子。

Result: MaxScore 分辨率解决了迭代重新路由和最优传输制剂的基本局限性，在等效 FLOPs 下实现了比受约束和无约束基线更低的训练损失和更高的评估分数。

Conclusion: MaxScore 通过将路由建模为最小费用最大流问题并集成 SoftTopk 算子，解决了传统 MoE 网络中容量约束导致的 token 丢失和硬件效率低下问题，以及移除容量约束导致的负载均衡和计算效率问题。与受约束和无约束基线相比，MaxScore 在等效 FLOPs 下实现了更低的训练损失和更高的评估分数。

Abstract: Routing networks in sparsely activated mixture-of-experts (MoE) dynamically
allocate input tokens to top-k experts through differentiable sparse
transformations, enabling scalable model capacity while preserving
computational efficiency. Traditional MoE networks impose an expert capacity
constraint to ensure GPU-friendly computation. However, this leads to token
dropping when capacity is saturated and results in low hardware efficiency due
to padding in underutilized experts. Removing the capacity constraint, in turn,
compromises load balancing and computational efficiency. To address these
issues, we propose Maximum Score Routing ($\mathbf{MaxScore}$), a novel MoE
routing paradigm that models routing as a minimum-cost maximum-flow problem and
integrates a SoftTopk operator. MaxScore resolves the fundamental limitations
of iterative rerouting and optimal transport formulations, achieving lower
training losses and higher evaluation scores at equivalent FLOPs compared to
both constrained and unconstrained baselines. Implementation details and
experimental configurations can be obtained from
$\href{https://github.com/dongbw18/MaxScore.git}{MaxScore}$.

</details>


### [532] [Learning to Steer: Input-dependent Steering for Multimodal LLMs](https://arxiv.org/abs/2508.12815)
*Jayneel Parekh,Pegah Khayatan,Mustafa Shukor,Arnaud Dapogny,Alasdair Newson,Matthieu Cord*

Main category: cs.LG

TL;DR: 本研究提出了一种名为L2S的新型细粒度转向方法，用于指导多模态大语言模型（MLLMs）。与依赖单一、静态转向向量的现有技术不同，L2S使用一个可学习的辅助模块来预测特定于输入的转向向量，从而更好地处理需要根据具体情况调整行为的任务，例如区分非法活动和医疗建议。实验证明，L2S能有效减少MLLMs的幻觉并提高其安全性。


<details>
  <summary>Details</summary>
Motivation: 现有的转向技术（如平均转向）依赖于单一的转向向量，并且独立于输入查询，这在所需行为依赖于具体示例时存在局限性。因此，需要一种能够处理这种输入依赖性的方法。

Method: 提出了一种细粒度的转向方法，使用特定于输入的线性移位，并通过对比输入特定提示来计算移位。

Result: L2S（Learn-to-Steer）成功地减少了多模态大语言模型的幻觉，并强制执行了模型的安全性，其性能优于其他静态基线。

Conclusion: L2S通过训练一个小型辅助模块来预测特定于输入的转向向量，在减少幻觉和强制执行多模态大语言模型（MLLM）的安全方面表现优于其他静态基线。

Abstract: Steering has emerged as a practical approach to enable post-hoc guidance of
LLMs towards enforcing a specific behavior. However, it remains largely
underexplored for multimodal LLMs (MLLMs); furthermore, existing steering
techniques, such as mean steering, rely on a single steering vector, applied
independently of the input query. This paradigm faces limitations when the
desired behavior is dependent on the example at hand. For example, a safe
answer may consist in abstaining from answering when asked for an illegal
activity, or may point to external resources or consultation with an expert
when asked about medical advice. In this paper, we investigate a fine-grained
steering that uses an input-specific linear shift. This shift is computed using
contrastive input-specific prompting. However, the input-specific prompts
required for this approach are not known at test time. Therefore, we propose to
train a small auxiliary module to predict the input-specific steering vector.
Our approach, dubbed as L2S (Learn-to-Steer), demonstrates that it reduces
hallucinations and enforces safety in MLLMs, outperforming other static
baselines.

</details>


### [533] [Toward Storage-Aware Learning with Compressed Data An Empirical Exploratory Study on JPEG](https://arxiv.org/abs/2508.12833)
*Kichang Lee,Songkuk Kim,JaeYeon Park,JeongGil Ko*

Main category: cs.LG

TL;DR: 在设备端机器学习中，存储是一个主要限制因素。本研究表明，与朴素的方法相比，自适应压缩策略可以更好地在数据数量和质量之间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 在设备端机器学习中，尤其是在连续数据收集场景中，存储空间通常是有限的。

Method: 通过压缩研究了数据数量和质量之间的权衡。

Result: 朴素的策略，如统一丢弃数据或一刀切压缩，效果不佳，并且数据样本对压缩的敏感度不同，这支持了样本自适应压缩策略的可行性。

Conclusion: 该研究为开发新型存储感知学习系统奠定了基础，并系统地描述了这个未被充分探索的挑战，提供了宝贵的见解，增进了对存储感知学习的理解。

Abstract: On-device machine learning is often constrained by limited storage,
particularly in continuous data collection scenarios. This paper presents an
empirical study on storage-aware learning, focusing on the trade-off between
data quantity and quality via compression. We demonstrate that naive
strategies, such as uniform data dropping or one-size-fits-all compression, are
suboptimal. Our findings further reveal that data samples exhibit varying
sensitivities to compression, supporting the feasibility of a sample-wise
adaptive compression strategy. These insights provide a foundation for
developing a new class of storage-aware learning systems. The primary
contribution of this work is the systematic characterization of this
under-explored challenge, offering valuable insights that advance the
understanding of storage-aware learning.

</details>


### [534] [Learning In-context $\pmb{n}$-grams with Transformers: Sub-$\pmb{n}$-grams Are Near-stationary Points](https://arxiv.org/abs/2508.12837)
*Aditya Varre,Gizem Yüce,Nicolas Flammarion*

Main category: cs.LG

TL;DR: Transformer 模型训练时，sub-n-grams 接近损失平面的平稳点，解释了分阶段学习现象。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机源于在训练过程中观察到 Transformer 模型存在长时间的平台期和分阶段的进展，这促使研究者深入探究其损失平面的特性。

Method: 本研究通过构建一个简化的 Transformer 模型，并设定参数配置来代表 k-gram 估计器（k ≤ n），在无限序列长度和参数范数的极限下，证明了 population loss 的梯度消失，从而建立了参数配置为平稳点的充分条件。

Result: 研究表明，sub-n-grams 是 Transformer 模型 in-context next-token 预测任务中 cross-entropy loss 的近乎平稳点，这为解释分阶段学习和相变等现象提供了理论基础。数值实验也支持了这一结论，展示了 n-grams 学习动态的离散跃迁特征。

Conclusion: Transformer 模型在进行 in-context next-token 预测任务的训练时，其损失平面存在一个关键特性：sub-n-grams 接近于 population cross-entropy loss 的近乎平稳点。这一特性为诸如分阶段学习动态和涌现的相变等广泛观察到的现象提供了理论见解，并通过数值实验得到了证实，实验表明 n-grams 的学习动态具有在近乎平稳解之间离散跃迁的特征。

Abstract: Motivated by empirical observations of prolonged plateaus and stage-wise
progression during training, we investigate the loss landscape of transformer
models trained on in-context next-token prediction tasks. In particular, we
focus on learning in-context $n$-gram language models under cross-entropy loss,
and establish a sufficient condition for parameter configurations to be
stationary points. We then construct a set of parameter configurations for a
simplified transformer model that represent $k$-gram estimators (for $k \leq
n$), and show that the gradient of the population loss at these solutions
vanishes in the limit of infinite sequence length and parameter norm. This
reveals a key property of the loss landscape: {sub-$n$-grams are
near-stationary points of the population cross-entropy loss}, offering
theoretical insight into widely observed phenomena such as stage-wise learning
dynamics and emergent phase transitions. These insights are further supported
by numerical experiments that illustrate the learning dynamics of $n$-grams,
characterized by discrete transitions between near-stationary solutions.

</details>


### [535] [HRS: Hybrid Representation Framework with Scheduling Awareness for Time Series Forecasting in Crowdsourced Cloud-Edge Platforms](https://arxiv.org/abs/2508.12839)
*Tiancheng Zhang,Cheng Zhang,Shuren Liu,Xiaofei Wang,Shaoyuan Huang,Wenyu Wang*

Main category: cs.LG

TL;DR: HRS框架通过结合数值和图像表示以及调度感知损失函数，在处理具有挑战性的网络负载预测问题方面取得了显著成果，有效降低了SLA违规率和利润损失。


<details>
  <summary>Details</summary>
Motivation: 随着流媒体服务的快速发展，网络负载表现出高度时变和突发行为，对众包云边平台（CCPs）的服务质量（QoS）维护提出了严峻挑战。现有的方法要么最小化平均绝对误差，导致在高峰时段供应不足和潜在的服务水平协议（SLA）违反，要么采取保守的过度配置策略，以增加资源支出来减轻SLA风险。

Method: 提出了一种名为HRS的混合表示框架，该框架集成了数值和基于图像的表示，并引入了具有调度感知功能的损失函数（SAL），以解决准确预测网络负载的挑战。

Result: HRS框架在减少SLA违规率方面提高了63.1%，在减少总利润损失方面提高了32.3%，在四个真实世界的数据集上始终优于十个基线，并取得了最先进的性能。

Conclusion: HRS框架通过集成数值和基于图像的表示来更好地捕捉极端负载动态，并引入了SAL以更好地支持调度决策，在真实世界的数据集上实现了最先进的性能，将SLA违规率降低了63.1%，并将总利润损失降低了32.3%。

Abstract: With the rapid proliferation of streaming services, network load exhibits
highly time-varying and bursty behavior, posing serious challenges for
maintaining Quality of Service (QoS) in Crowdsourced Cloud-Edge Platforms
(CCPs). While CCPs leverage Predict-then-Schedule architecture to improve QoS
and profitability, accurate load forecasting remains challenging under traffic
surges. Existing methods either minimize mean absolute error, resulting in
underprovisioning and potential Service Level Agreement (SLA) violations during
peak periods, or adopt conservative overprovisioning strategies, which mitigate
SLA risks at the expense of increased resource expenditure. To address this
dilemma, we propose HRS, a hybrid representation framework with scheduling
awareness that integrates numerical and image-based representations to better
capture extreme load dynamics. We further introduce a Scheduling-Aware Loss
(SAL) that captures the asymmetric impact of prediction errors, guiding
predictions that better support scheduling decisions. Extensive experiments on
four real-world datasets demonstrate that HRS consistently outperforms ten
baselines and achieves state-of-the-art performance, reducing SLA violation
rates by 63.1% and total profit loss by 32.3%.

</details>


### [536] [One-Class Intrusion Detection with Dynamic Graphs](https://arxiv.org/abs/2508.12885)
*Aleksei Liuliakov,Alexander Schulz,Luca Hermes,Barbara Hammer*

Main category: cs.LG

TL;DR: 提出了一种新的基于图神经网络和支持向量数据描述的入侵检测方法TGN-SVDD，以应对网络安全中的挑战。


<details>
  <summary>Details</summary>
Motivation: 随着全球数字化程度的不断提高，网络安全的相关性变得越来越重要。基于机器学习的入侵检测是一种有前景的提高安全性。然而，它也带来了一些挑战，包括检测新出现和未见过的网络事件，以及处理具有时间特性的事件和网络通信的固有图结构等特定数据属性。

Method: 提出了一种新的入侵检测方法TGN-SVDD，该方法基于现代动态图建模和深度异常检测。

Result: TGN-SVDD在真实入侵检测数据上优于若干基线方法，并提出了一个更具挑战性的基线变体。

Conclusion: TGN-SVDD在真实入侵检测数据上优于若干基线方法。

Abstract: With the growing digitalization all over the globe, the relevance of network
security becomes increasingly important. Machine learning-based intrusion
detection constitutes a promising approach for improving security, but it bears
several challenges. These include the requirement to detect novel and unseen
network events, as well as specific data properties, such as events over time
together with the inherent graph structure of network communication. In this
work, we propose a novel intrusion detection method, TGN-SVDD, which builds
upon modern dynamic graph modelling and deep anomaly detection. We demonstrate
its superiority over several baselines for realistic intrusion detection data
and suggest a more challenging variant of the latter.

</details>


### [537] [TCUQ: Single-Pass Uncertainty Quantification from Temporal Consistency with Streaming Conformal Calibration for TinyML](https://arxiv.org/abs/2508.12905)
*Ismail Lamaakal,Chaymae Yahyati,Khalid El Makkaoui,Ibrahim Ouahbi,Yassine Maleh*

Main category: cs.LG

TL;DR: TCUQ 是一种用于 TinyML 的单通道、无标签不确定性监控器，可将时间一致性转换为风险评分，并使用流式保形层进行校准，从而在资源受限的设备上实现高效的片上监控。


<details>
  <summary>Details</summary>
Motivation: 在 TinyML 应用中，尤其是在资源受限的设备上，对模型进行有效的片上监控以检测潜在的风险和故障至关重要。现有的方法往往需要额外的计算资源或在线标签，这在 TinyML 的场景下是不可行的。

Method: TCUQ 是一种单通道、无标签的预测模型，它利用后验和特征的轻量级信号捕获的短期时间一致性，通过 O(W) 环形缓冲区和 O(1) 每步更新将其转换为校准的风险评分。流式保形层将此评分转化为有预算的接受/弃权规则，无需在线标签或额外的正向传播即可实现校准行为。

Result: TCUQ 在微控制器上的表现优异，占用的内存少（通常比早期退出和深度集成模型小 50-60%），延迟低（通常快 30-45%），而精度相似的方法往往内存不足。在分布内损坏的数据流下，TCUQ 能将准确性下降检测提高 3-7 AUPRC 点，在高度损坏的情况下达到 0.86 AUPRC；在故障检测方面，其 AUROC 高达 0.92。

Conclusion: TCUQ 提供了一种实用且资源高效的解决方案，用于在 TinyML 设备上进行片上监控，通过时间一致性和流式保形校准实现。

Abstract: We introduce TCUQ, a single pass, label free uncertainty monitor for
streaming TinyML that converts short horizon temporal consistency captured via
lightweight signals on posteriors and features into a calibrated risk score
with an O(W ) ring buffer and O(1) per step updates. A streaming conformal
layer turns this score into a budgeted accept/abstain rule, yielding calibrated
behavior without online labels or extra forward passes. On microcontrollers,
TCUQ fits comfortably on kilobyte scale devices and reduces footprint and
latency versus early exit and deep ensembles (typically about 50 to 60% smaller
and about 30 to 45% faster), while methods of similar accuracy often run out of
memory. Under corrupted in distribution streams, TCUQ improves accuracy drop
detection by 3 to 7 AUPRC points and reaches up to 0.86 AUPRC at high
severities; for failure detection it attains up to 0.92 AUROC. These results
show that temporal consistency, coupled with streaming conformal calibration,
provides a practical and resource efficient foundation for on device monitoring
in TinyML.

</details>


### [538] [SparseMap: A Sparse Tensor Accelerator Framework Based on Evolution Strategy](https://arxiv.org/abs/2508.12906)
*Boran Zhao,Haiming Zhai,Zihang Yuan,Hetian Liu,Tian Xia,Wenzhe Zhao,Pengju Ren*

Main category: cs.LG

TL;DR: SparseMap是一种基于进化策略的框架，用于优化稀疏张量加速器，能够同时考虑映射和稀疏策略，解决了现有方法的局限性，并能在庞大的设计空间中找到更优解。


<details>
  <summary>Details</summary>
Motivation: 现有手动设计的SpTA加速器难以适应多变的应用场景，且无法同时优化映射和稀疏策略，导致设计不佳。自动化设计SpTA加速器至关重要，但现有方法在设计空间探索方面存在效率问题。

Method: 提出了一种基于进化策略的稀疏张量加速器优化框架SparseMap，通过改进遗传编码和进化算子来高效探索设计空间。

Result: SparseMap框架能够有效地探索庞大且多样化的设计空间，并找到比现有方法和经典优化方法更优的解决方案。

Conclusion: 现有的稀疏张量代数（SpTA）加速器在设计上存在局限性，需要一个能够同时优化映射和稀疏策略的统一框架。

Abstract: The growing demand for sparse tensor algebra (SpTA) in machine learning and
big data has driven the development of various sparse tensor accelerators.
However, most existing manually designed accelerators are limited to specific
scenarios, and it's time-consuming and challenging to adjust a large number of
design factors when scenarios change. Therefore, automating the design of SpTA
accelerators is crucial. Nevertheless, previous works focus solely on either
mapping (i.e., tiling communication and computation in space and time) or
sparse strategy (i.e., bypassing zero elements for efficiency), leading to
suboptimal designs due to the lack of comprehensive consideration of both. A
unified framework that jointly optimizes both is urgently needed. However,
integrating mapping and sparse strategies leads to a combinatorial explosion in
the design space(e.g., as large as $O(10^{41})$ for the workload $P_{32 \times
64} \times Q_{64 \times 48} = Z_{32 \times 48}$). This vast search space
renders most conventional optimization methods (e.g., particle swarm
optimization, reinforcement learning and Monte Carlo tree search) inefficient.
To address this challenge, we propose an evolution strategy-based sparse tensor
accelerator optimization framework, called SparseMap. SparseMap constructing a
more comprehensive design space with the consideration of both mapping and
sparse strategy. We introduce a series of enhancements to genetic encoding and
evolutionary operators, enabling SparseMap to efficiently explore the vast and
diverse design space. We quantitatively compare SparseMap with prior works and
classical optimization methods, demonstrating that SparseMap consistently finds
superior solutions.

</details>


### [539] [SNAP-UQ: Self-supervised Next-Activation Prediction for Single-Pass Uncertainty in TinyML](https://arxiv.org/abs/2508.12907)
*Ismail Lamaakal,Chaymae Yahyati,Khalid El Makkaoui,Ibrahim Ouahbi,Yassine Maleh*

Main category: cs.LG

TL;DR: SNAP-UQ 是一种用于 TinyML 的单通道、无标签的不确定性方法，通过预测下一次激活来估计风险，内存占用和延迟低，并且能有效检测模型失效。


<details>
  <summary>Details</summary>
Motivation: 在 TinyML 中实现对模型风险的估计，同时保持资源效率。

Method: SNAP-UQ 是一种单通道、无标签的 TinyML 不确定性方法，通过‘深度方向下一次激活预测’来估计风险：tiny int8 heads 从前一层的压缩视图预测下一层的统计数据，一个轻量级的单调映射器将由此产生的意外转换为可操作的分数。

Result: SNAP-UQ 在视觉和音频主干上，与早期退出和深度集成相比，内存占用和延迟通常减小（约 40-60% 的内存占用和 25-35% 的速度提升），并且在损坏的数据流中，准确率下降检测提高了几个 AUPRC 点，并在单通道中保持了强大的故障检测能力（AUROC ≈ 0.9）。

Conclusion: SNAP-UQ 是一种实用的、资源高效的 TinyML 板载监控方法，它将不确定性建立在层到层的动态之上。

Abstract: We introduce \textbf{SNAP-UQ}, a single-pass, label-free uncertainty method
for TinyML that estimates risk from \emph{depth-wise next-activation
prediction}: tiny int8 heads forecast the statistics of the next layer from a
compressed view of the previous one, and a lightweight monotone mapper turns
the resulting surprisal into an actionable score. The design requires no
temporal buffers, auxiliary exits, or repeated forward passes, and adds only a
few tens of kilobytes to MCU deployments. Across vision and audio backbones,
SNAP-UQ consistently reduces flash and latency relative to early-exit and deep
ensembles (typically $\sim$40--60\% smaller and $\sim$25--35\% faster), with
competing methods of similar accuracy often exceeding memory limits. In
corrupted streams it improves accuracy-drop detection by several AUPRC points
and maintains strong failure detection (AUROC $\approx$0.9) in a single pass.
Grounding uncertainty in layer-to-layer dynamics yields a practical,
resource-efficient basis for on-device monitoring in TinyML.

</details>


### [540] [SL-ACC: A Communication-Efficient Split Learning Framework with Adaptive Channel-wise Compression](https://arxiv.org/abs/2508.12984)
*Zehang Lin,Zheng Lin,Miao Yang,Jianhao Huang,Yuxin Zhang,Zihan Fang,Xia Du,Zhe Chen,Shunzhi Zhu,Wei Ni*

Main category: cs.LG

TL;DR: SL-ACC框架通过ACII和CGC技术，利用香农熵识别通道贡献并进行分组压缩，减少了SL中的通信瓶颈，实现了更快的模型训练。


<details>
  <summary>Details</summary>
Motivation: 为了解决随着参与设备数量的增加，SL中过多的破碎数据传输（例如激活和梯度）成为主要瓶颈，减慢模型训练速度的问题。

Method: 提出了一种名为SL-ACC的通信高效SL框架，包含两个关键组件：自适应通道重要性识别（ACII）和通道分组压缩（CGC）。ACII首先使用香农熵识别每个通道在破碎数据中对模型训练的贡献，然后CGC根据其熵对通道进行分组，并执行分组自适应压缩。

Result: SL-ACC框架能够显著减少通信量，并且在达到目标准确率方面比现有技术基准所需时间更少。

Conclusion: SL-ACC框架在不影响训练准确性的前提下，通过分组压缩通道来缩小传输量，并在各种数据集上的广泛实验证明，与现有基准相比，SL-ACC框架在达到目标准确率方面所需时间大大减少。

Abstract: The increasing complexity of neural networks poses a significant barrier to
the deployment of distributed machine learning (ML) on resource-constrained
devices, such as federated learning (FL). Split learning (SL) offers a
promising solution by offloading the primary computing load from edge devices
to a server via model partitioning. However, as the number of participating
devices increases, the transmission of excessive smashed data (i.e.,
activations and gradients) becomes a major bottleneck for SL, slowing down the
model training. To tackle this challenge, we propose a communication-efficient
SL framework, named SL-ACC, which comprises two key components: adaptive
channel importance identification (ACII) and channel grouping compression
(CGC). ACII first identifies the contribution of each channel in the smashed
data to model training using Shannon entropy. Following this, CGC groups the
channels based on their entropy and performs group-wise adaptive compression to
shrink the transmission volume without compromising training accuracy.
Extensive experiments across various datasets validate that our proposed SL-ACC
framework takes considerably less time to achieve a target accuracy than
state-of-the-art benchmarks.

</details>


### [541] [Predicting the Performance of Graph Convolutional Networks with Spectral Properties of the Graph Laplacian](https://arxiv.org/abs/2508.12993)
*Shalima Binta Manir,Tim Oates*

Main category: cs.LG

TL;DR: The Fiedler value, a measure of a graph's algebraic connectivity, can predict the performance of Graph Convolutional Networks (GCNs). Stacking GCN layers may or may not improve performance, but graphs with similar Fiedler values tend to respond similarly to the same GCN filters and hyperparameters, suggesting potential for effective transfer learning between such graphs.


<details>
  <summary>Details</summary>
Motivation: A common observation in the Graph Convolutional Network (GCN) literature is that stacking GCN layers may or may not result in better performance on tasks like node classification and edge prediction. The Fiedler value is a good predictor of GCN performance.

Method: Explored theoretically and empirically with experiments on synthetic and real graph data, including the Cora, CiteSeer and Polblogs datasets. Explored multiple ways of aggregating the Fiedler value for connected components in the graphs to arrive at a value for the entire graph.

Result: Empirically found that a graph's algebraic connectivity, the Fiedler value, is a good predictor of GCN performance.

Conclusion: The Fiedler value can be used to predict GCN performance.

Abstract: A common observation in the Graph Convolutional Network (GCN) literature is
that stacking GCN layers may or may not result in better performance on tasks
like node classification and edge prediction. We have found empirically that a
graph's algebraic connectivity, which is known as the Fiedler value, is a good
predictor of GCN performance. Intuitively, graphs with similar Fiedler values
have analogous structural properties, suggesting that the same filters and
hyperparameters may yield similar results when used with GCNs, and that
transfer learning may be more effective between graphs with similar algebraic
connectivity. We explore this theoretically and empirically with experiments on
synthetic and real graph data, including the Cora, CiteSeer and Polblogs
datasets. We explore multiple ways of aggregating the Fiedler value for
connected components in the graphs to arrive at a value for the entire graph,
and show that it can be used to predict GCN performance. We also present
theoretical arguments as to why the Fiedler value is a good predictor.

</details>


### [542] [Kourkoutas-Beta: A Sunspike-Driven Adam Optimizer with Desert Flair](https://arxiv.org/abs/2508.12996)
*Stavros C. Kassinos*

Main category: cs.LG

TL;DR: Kourkoutas-Beta 优化器通过动态调整 beta2 来处理尖峰梯度，提高了 PINNs 和 Transformer 的训练稳定性和效率，尤其在 small-enwik8 数据集上效果显著。


<details>
  <summary>Details</summary>
Motivation: 在数据驱动的偏微分方程代理和物理信息神经网络（PINNs）的训练过程中，多变的边界/初始条件或复杂的损失函数（如 PINNs 中的复合损失）会导致损失剧烈波动和梯度尖峰，从而影响训练的稳定性和收敛性。

Method: 提出了一种名为 Kourkoutas-Beta 的 Adam 风格优化器，用一个由“太阳峰值”比率（当前梯度范数与过去范数指数移动平均值的比值）驱动的层级动态值替换了固定的 second-moment discount beta2。该比率被限制在 [0,1) 区间内，尖峰时降低 beta2 至 beta2_min，平稳时接近 beta2_max。该方法还包括可选的 leaky-AMSGrad、信任区域裁剪、自适应微小项和多种偏差校正模式。

Result: Kourkoutas-Beta 在 Heat2D（Transformer PDE 代理）、Heat3D（3D PINN 热传导）、MLX 合成任务（包含抖动和稀疏触发爆发）以及 small-enwik8（Transformer enwik8 字符级任务）上进行了测试。结果表明，与固定的 beta2 的 Adam 相比，Kourkoutas-Beta 提高了训练的稳定性和最终损失。在 small-enwik8 数据集上，与 Adam-0.95 相比，Kourkoutas-Beta 将每字符比特数降低了约 38%，与 Adam-0.999 相比降低了约 58%，且方差更小。该方法的运行时开销与 Adam 相当，并且在保持 Adam 收敛保证的同时，提高了在梯度尖峰下的鲁棒性。

Conclusion: Kourkoutas-Beta 是一种 Adam 优化器的变体，通过动态调整 beta2 参数来提高在包含尖峰梯度的物理信息神经网络和 Transformer 模型训练中的稳定性和最终损失。该方法在小规模 enwik8 数据集上表现尤为出色，将每字符比特数平均降低了 38%-58%，同时保持了与 Adam 相当的运行时开销和收敛保证。

Abstract: Transformer neural networks are increasingly used for physics-based problems.
In data-driven PDE surrogates, training samples from varying boundary and
initial conditions can cause erratic losses and spiky gradients; in
physics-informed neural networks (PINNs), stiff composite losses amplify this
effect.
  We introduce Kourkoutas-Beta, an Adam-style optimizer where the fixed
second-moment discount beta2 is replaced by a layer-wise dynamic value driven
by a bounded ``sunspike'' ratio: the current pooled gradient norm divided by an
exponential moving average (EMA) of past norms, squashed to the interval [0,1).
Spikes lower beta2 toward beta2_min; calm phases keep it near beta2_max.
Options include leaky-AMSGrad (decay), trust-region clipping (max_ratio),
adaptive tiny terms, and several bias-correction modes ``none'', ``beta2max'',
``exact'). With all features off and bias_correction=``none'', the method is
exactly Adam.
  We test on four settings: (i) a Transformer PDE surrogate (Heat2D), (ii) a 3D
PINN for heat conduction (Heat3D), (iii) a lightweight MLX synthetic task with
jitter and rare-trigger bursts, and (iv) a character-level Transformer on 30 MB
of enwik8 (small-enwik8). Kourkoutas-Beta improves stability and final loss
versus fixed-beta2 Adam. On small-enwik8 it lowers bits-per-character by about
38% vs Adam-0.95 and about 58% vs Adam-0.999 over 10 seeds, with smaller
variance. The method remains drop-in, with runtime overhead comparable to Adam
in testbeds A-C and within single-digit percent in testbed D. It preserves
Adam-style convergence guarantees while improving robustness under spiky
gradients.

</details>


### [543] [Fairness-Aware Multi-view Evidential Learning with Adaptive Prior](https://arxiv.org/abs/2508.12997)
*Haishun Chen,Cai Xu,Jinlong Yu,Yilin Zhang,Ziyu Guan,Wei Zhao*

Main category: cs.LG

TL;DR: 本研究提出了一种名为FAML的新方法，用于解决多视图证据学习中因数据不平衡导致的证据偏差问题，该方法通过引入自适应先验、公平性约束和意见对齐机制，能够更均衡地分配证据，从而提升模型性能和不确定性估计的准确性。


<details>
  <summary>Details</summary>
Motivation: 以往的多视图证据学习方法假设视图特异性证据学习自然可靠，但实际中证据学习过程存在偏差，容易偏向数据量大的类别，导致不确定性估计不可靠。

Method: FAML首先引入基于训练轨迹的自适应先验作为正则化策略来校准有偏的证据学习过程，然后明确纳入基于类证据方差的公平性约束以促进证据的均衡分配，最后在多视图融合阶段提出意见对齐机制以减轻视图特异性偏差。

Result: 实验结果表明，FAML相比于现有最先进的方法，实现了更均衡的证据分配，提高了预测性能和不确定性估计的可靠性。

Conclusion: FAML通过自适应先验和公平性约束来解决多视图证据学习中的证据偏差问题，并在多视图融合阶段通过意见对齐机制来减轻视图特异性偏差，从而实现更均衡的证据分配，提高预测性能和不确定性估计的可靠性。

Abstract: Multi-view evidential learning aims to integrate information from multiple
views to improve prediction performance and provide trustworthy uncertainty
esitimation. Most previous methods assume that view-specific evidence learning
is naturally reliable. However, in practice, the evidence learning process
tends to be biased. Through empirical analysis on real-world data, we reveal
that samples tend to be assigned more evidence to support data-rich classes,
thereby leading to unreliable uncertainty estimation in predictions. This
motivates us to delve into a new Biased Evidential Multi-view Learning (BEML)
problem. To this end, we propose Fairness-Aware Multi-view Evidential Learning
(FAML). FAML first introduces an adaptive prior based on training trajectory,
which acts as a regularization strategy to flexibly calibrate the biased
evidence learning process. Furthermore, we explicitly incorporate a fairness
constraint based on class-wise evidence variance to promote balanced evidence
allocation. In the multi-view fusion stage, we propose an opinion alignment
mechanism to mitigate view-specific bias across views, thereby encouraging the
integration of consistent and mutually supportive evidence. Extensive
experiments on five real-world multi-view datasets demonstrate that FAML
achieves more balanced evidence allocation and improves both prediction
performance and the reliability of uncertainty estimation compared to
state-of-the-art methods.

</details>


### [544] [Monte Carlo Functional Regularisation for Continual Learning](https://arxiv.org/abs/2508.13006)
*Pengcheng Hao,Menghao Waiyan William Zhu,Ercan Engin Kuruoglu*

Main category: cs.LG

TL;DR: MCFRCL是一种新的持续学习框架，通过蒙特卡洛采样和Wasserstein/KL散度来解决现有方法的计算成本和近似误差问题，并在实验中表现出优越性。


<details>
  <summary>Details</summary>
Motivation: 持续学习（CL）对于神经网络模型适应新环境至关重要。现有的函数式正则化CL方法虽然优于权重空间正则化方法，但存在计算成本高和线性近似误差大的问题。

Method: 提出了一种名为MCFRCL的新型函数式正则化持续学习框架，该框架通过蒙特卡洛(MC)采样来近似模型预测分布。此外，利用三种连续分布和基于矩的方法来捕捉MC样本的统计特征。同时，采用Wasserstein距离和KL散度来构建正则化函数。

Result: MCFRCL框架通过蒙特卡洛采样和连续分布来近似模型预测分布，并结合Wasserstein距离和KL散度进行正则化，在MNIST和CIFAR数据集上的模拟结果表明其在预测准确性和训练效率方面均表现出色。

Conclusion: MCFRCL框架在MNIST和CIFAR数据集上的表现优于其他基准方法，在预测准确性和训练效率方面都显示出有效性。

Abstract: Continual learning (CL) is crucial for the adaptation of neural network
models to new environments. Although outperforming weight-space regularisation
approaches, the functional regularisation-based CL methods suffer from high
computational costs and large linear approximation errors. In this work, we
present a new functional regularisation CL framework, called MCFRCL, which
approximates model prediction distributions by Monte Carlo (MC) sampling.
Moreover, three continuous distributions are leveraged to capture the
statistical characteristics of the MC samples via moment-based methods.
Additionally, both the Wasserstein distance and the Kullback-Leibler (KL)
distance are employed to construct the regularisation function. The proposed
MCFRCL is evaluated against multiple benchmark methods on the MNIST and CIFAR
datasets, with simulation results highlighting its effectiveness in both
prediction accuracy and training efficiency.

</details>


### [545] [Design and Analysis of Robust Adaptive Filtering with the Hyperbolic Tangent Exponential Kernel M-Estimator Function for Active Noise Control](https://arxiv.org/abs/2508.13018)
*Iam Kim de S. Hermont,Andre R. Flores,Rodrigo C. de Lamare*

Main category: cs.LG

TL;DR: 提出FXHEKM算法，在有冲激噪声时能用于主动噪声控制，且效果优于其他算法。


<details>
  <summary>Details</summary>
Motivation: 为了在存在冲激噪声的情况下实现主动噪声控制。

Method: 提出了一种用于主动噪声控制的鲁棒自适应滤波方法，具体为滤波-x双曲正切指数广义核M估计函数（FXHEKM）鲁棒自适应算法，并进行了统计分析和计算成本研究。

Result: 数值结果表明，所提出的FXHEKM算法能有效消除添加的杂散信号，例如与竞争算法相比，能有效消除α-稳定噪声。

Conclusion: 所提出的FXHEKM算法能够有效处理包含噪声的信号，在有杂音信号（如α-稳定分布噪声）存在的情况下，相对于其他算法具有优势。

Abstract: In this work, we propose a robust adaptive filtering approach for active
noise control applications in the presence of impulsive noise. In particular,
we develop the filtered-x hyperbolic tangent exponential generalized Kernel
M-estimate function (FXHEKM) robust adaptive algorithm. A statistical analysis
of the proposed FXHEKM algorithm is carried out along with a study of its
computational cost. {In order to evaluate the proposed FXHEKM algorithm, the
mean-square error (MSE) and the average noise reduction (ANR) performance
metrics have been adopted.} Numerical results show the efficiency of the
proposed FXHEKM algorithm to cancel the presence of the additive spurious
signals, such as \textbf{$\alpha$}-stable noises against competing algorithms.

</details>


### [546] [The Application of Transformer-Based Models for Predicting Consequences of Cyber Attacks](https://arxiv.org/abs/2508.13030)
*Bipin Chhetri,Akbar Siami Namin*

Main category: cs.LG

TL;DR: 本研究利用NLP和深度学习（BERT、HANs）来分析网络攻击后果，旨在实现自动化评估。实验证明BERT在多标签分类任务中准确率高达0.972，优于CNN和LSTM，在网络安全领域预测攻击后果方面具有显著优势。


<details>
  <summary>Details</summary>
Motivation: 随着网络攻击日益频繁且复杂，迫切需要自动化方法来评估攻击描述并预测其未来后果，以协助网络安全专业人员及时采取行动并优化资源分配。

Method: 本研究采用自然语言处理（NLP）和深度学习技术，特别是结合了BERT和分层注意力网络（HANs）进行多标签分类，以分析网络攻击的潜在影响。实验将这些模型与传统的CNN和LSTM模型进行性能比较。

Result: BERT模型在多标签分类任务中取得了0.972的整体准确率，显著优于传统深度学习模型。HAN在某些特定网络安全标签上的表现优于CNN和LSTM模型。BERT在精确率和召回率方面持续表现更优，更适合预测网络攻击后果。

Conclusion: BERT在多标签分类任务中表现优于传统的深度学习模型，整体准确率为0.972，在预测网络攻击后果方面表现更佳。 HAN在特定网络安全标签上优于CNN和LSTM模型。

Abstract: Cyberattacks are increasing, and securing against such threats is costing
industries billions of dollars annually. Threat Modeling, that is,
comprehending the consequences of these attacks, can provide critical support
to cybersecurity professionals, enabling them to take timely action and
allocate resources that could be used elsewhere. Cybersecurity is heavily
dependent on threat modeling, as it assists security experts in assessing and
mitigating risks related to identifying vulnerabilities and threats. Recently,
there has been a pressing need for automated methods to assess attack
descriptions and forecast the future consequences of the increasing complexity
of cyberattacks. This study examines how Natural Language Processing (NLP) and
deep learning can be applied to analyze the potential impact of cyberattacks by
leveraging textual descriptions from the MITRE Common Weakness Enumeration
(CWE) database. We emphasize classifying attack consequences into five
principal categories: Availability, Access Control, Confidentiality, Integrity,
and Other. This paper investigates the use of Bidirectional Encoder
Representations from Transformers (BERT) in combination with Hierarchical
Attention Networks (HANs) for Multi-label classification, evaluating their
performance in comparison with conventional CNN and LSTM-based models.
Experimental findings show that BERT achieves an overall accuracy of $0.972$,
far higher than conventional deep learning models in multi-label
classification. HAN outperforms baseline forms of CNN and LSTM-based models on
specific cybersecurity labels. However, BERT consistently achieves better
precision and recall, making it more suitable for predicting the consequences
of a cyberattack.

</details>


### [547] [Beyond Internal Data: Bounding and Estimating Fairness from Incomplete Data](https://arxiv.org/abs/2508.13040)
*Varsha Ramineni,Hossein A. Rahmani,Emine Yilmaz,David Barber*

Main category: cs.LG

TL;DR: 在无法获得完整数据的情况下，利用分散的数据源来估计AI模型公平性的界限。


<details>
  <summary>Details</summary>
Motivation: AI系统（尤其是在信贷、招聘和医疗保健等高风险领域）的公平性至关重要，这在全球新兴法规中得到了体现。然而，在实际应用中，由于法律和隐私问题，获取用于公平性测试的完整人口统计数据仍然是一个重大挑战。本研究旨在解决这一问题，即在无法获得完整数据的情况下，利用现有的分散数据来估计模型公平性。

Method: 本研究提出利用单独的数据集来估计一组可行联合分布，然后计算出一组合理的公平性指标。

Result: 本研究通过模拟和实际实验证明，该方法可以在公平性指标上推导出有意义的界限，并获得真实指标的可靠估计。

Conclusion: 本研究提出了一个实用的解决方案，用于在无法获取完整数据的情况下对模型公平性进行测试，该方案可在数据受限的真实世界场景中可靠地估计公平性指标。

Abstract: Ensuring fairness in AI systems is critical, especially in high-stakes
domains such as lending, hiring, and healthcare. This urgency is reflected in
emerging global regulations that mandate fairness assessments and independent
bias audits. However, procuring the necessary complete data for fairness
testing remains a significant challenge. In industry settings, legal and
privacy concerns restrict the collection of demographic data required to assess
group disparities, and auditors face practical and cultural challenges in
gaining access to data. In practice, data relevant for fairness testing is
often split across separate sources: internal datasets held by institutions
with predictive attributes, and external public datasets such as census data
containing protected attributes, each providing only partial, marginal
information. Our work seeks to leverage such available separate data to
estimate model fairness when complete data is inaccessible. We propose
utilising the available separate data to estimate a set of feasible joint
distributions and then compute the set plausible fairness metrics. Through
simulation and real experiments, we demonstrate that we can derive meaningful
bounds on fairness metrics and obtain reliable estimates of the true metric.
Our results demonstrate that this approach can serve as a practical and
effective solution for fairness testing in real-world settings where access to
complete data is restricted.

</details>


### [548] [Hierarchical Evaluation Function (HEF): A Multi-Metric Approach for Optimizing Demand Forecasting Models](https://arxiv.org/abs/2508.13057)
*Adolfo González,Víctor Parada*

Main category: cs.LG

TL;DR: HEF在全局预测指标上优于FMAE，但FMAE在局部指标和速度上更胜一筹。


<details>
  <summary>Details</summary>
Motivation: 为解决传统评估指标的偏差和泛化限制问题，本研究旨在比较两种自定义评估函数（FMAE和HEF）在多变量时间序列预测中的有效性，以优化资源配置和响应市场动态。

Method: 通过比较两种自定义评估函数（FMAE和HEF）在不同数据分割（91:9, 80:20, 70:30）和优化器（网格搜索、PSO、Optuna）下的表现来评估它们在多变量时间序列预测中的应用。

Result: HEF在全局指标（R2、相对准确度、RMSE、RMSSE）上持续优于FMAE，提高了模型鲁棒性和解释力。FMAE在局部指标（MAE、MASE）和执行时间上更优，适用于短期场景。

Conclusion: HEF在全局指标上持续优于FMAE，增强了模型鲁棒性和解释力，而FMAE在局部指标和执行时间上具有优势，适用于短期场景。HEF是战略规划的理想选择，而FMAE更适合运营效率。本研究提出了一个可复制的框架，用于在动态环境中优化预测模型。

Abstract: Demand forecasting is essential for strategic planning in competitive
environments, enabling resource optimization and improved responsiveness to
market dynamics. However, multivariate time series modeling faces challenges
due to data complexity, uncertainty, and frequent regime shifts. Traditional
evaluation metrics can introduce biases and limit generalization. This work
compares two custom evaluation functions: FMAE (Focused Mean Absolute Error),
focused on minimizing absolute errors, and HEF (Hierarchical Evaluation
Function), designed to weight global metrics and penalize large deviations.
Experiments were conducted under different data splits (91:9, 80:20, 70:30)
using three optimizers (Grid Search, PSO, Optuna), assessing fit, relative
accuracy, robustness, and computational efficiency. Results show that HEF
consistently outperforms FMAE in global metrics (R2, Relative Accuracy, RMSE,
RMSSE), enhancing model robustness and explanatory power. These findings were
confirmed via visualizations and statistical tests. Conversely, FMAE offers
advantages in local metrics (MAE, MASE) and execution time, making it suitable
for short-term scenarios. The study highlights a methodological trade-off: HEF
is ideal for strategic planning, while FMAE is better suited for operational
efficiency. A replicable framework is proposed for optimizing predictive models
in dynamic environments.

</details>


### [549] [Seeing the Many: Exploring Parameter Distributions Conditioned on Features in Surrogates](https://arxiv.org/abs/2508.13088)
*Xiaohan Wang,Zhimin Li,Joshua A. Levine,Matthew Berger*

Main category: cs.LG

TL;DR: 本研究提出了一种新的方法，利用神经网络代理模型和密度估计来解决高维参数空间中的逆问题，能够可视化地展示所有可能的参数解决方案，而不仅仅是找到一小部分。


<details>
  <summary>Details</summary>
Motivation: 现有的基于代理模型的方法在解决高维参数空间搜索问题时，往往只关注找到一小部分匹配的参数，而忽略了更广泛的可能参数分布。本研究旨在建模和可视化能产生给定输出特征的可能输入参数的分布。

Method: 通过密度估计来模拟误差，并结合似然函数来对参数进行采样，以解决逆问题。

Result: 提出了一种新的方法，用于建模和可视化生成给定输出特征的输入参数的分布，解决了代理模型的近似误差问题，并以交互方式构建了参数分布，通过可视化接口在三个数据集上进行了验证。

Conclusion: 该研究通过密度估计来模拟误差，并结合似然函数来高效地采样生成目标输出特征的参数配置。最终通过一个可视化接口，在三个模拟数据集的输入参数空间上执行了特征驱动的参数分析，展示了该方法的可用性。

Abstract: Recently, neural surrogate models have emerged as a compelling alternative to
traditional simulation workflows. This is accomplished by modeling the
underlying function of scientific simulations, removing the need to run
expensive simulations. Beyond just mapping from input parameter to output,
surrogates have also been shown useful for inverse problems: output to input
parameters. Inverse problems can be understood as search, where we aim to find
parameters whose surrogate outputs contain a specified feature. Yet finding
these parameters can be costly, especially for high-dimensional parameter
spaces. Thus, existing surrogate-based solutions primarily focus on finding a
small set of matching parameters, in the process overlooking the broader
picture of plausible parameters. Our work aims to model and visualize the
distribution of possible input parameters that produce a given output feature.
To achieve this goal, we aim to address two challenges: (1) the approximation
error inherent in the surrogate model and (2) forming the parameter
distribution in an interactive manner. We model error via density estimation,
reporting high density only if a given parameter configuration is close to
training parameters, measured both over the input and output space. Our density
estimate is used to form a prior belief on parameters, and when combined with a
likelihood on features, gives us an efficient way to sample plausible parameter
configurations that generate a target output feature. We demonstrate the
usability of our solution through a visualization interface by performing
feature-driven parameter analysis over the input parameter space of three
simulation datasets. Source code is available at
https://github.com/matthewberger/seeing-the-many

</details>


### [550] [Outlier Detection of Poisson-Distributed Targets Using a Seabed Sensor Network](https://arxiv.org/abs/2508.13099)
*Mingyu Kim,Daniel Stilwell,Jorge Jimenez*

Main category: cs.LG

TL;DR: 该论文提出了一种用于检测海事环境中的空间异常值的框架，该框架结合了对数高斯Cox过程和改进的分类算法，并通过动态调整传感器位置来提高检测性能。


<details>
  <summary>Details</summary>
Motivation: 提出了一种用于在海事环境中分类和检测空间异常值的框架，并提出了一种新颖的传感器放置策略。

Method: 使用海底声学传感器网络和对数高斯Cox过程（LGCP）对海事环境中的空间异常值进行分类和检测。通过将目标到达建模为正态和异常值过程的混合，估计新观测事件为异常值的概率，并提出了一种考虑正态强度函数的均值和方差的二阶近似方法。

Result: 该方法比仅使用均值的方法具有更高的分类准确性，并使用Jensen不等式证明了该方法能更紧密地界定真实概率。在挪福克附近的真实船舶交通数据验证了该框架的有效性。

Conclusion: 该框架通过结合实时传感器放置策略，在提高分类性能和异常值检测方面均表现出色。

Abstract: This paper presents a framework for classifying and detecting spatial
commission outliers in maritime environments using seabed acoustic sensor
networks and log Gaussian Cox processes (LGCPs). By modeling target arrivals as
a mixture of normal and outlier processes, we estimate the probability that a
newly observed event is an outlier. We propose a second-order approximation of
this probability that incorporates both the mean and variance of the normal
intensity function, providing improved classification accuracy compared to
mean-only approaches. We analytically show that our method yields a tighter
bound to the true probability using Jensen's inequality. To enhance detection,
we integrate a real-time, near-optimal sensor placement strategy that
dynamically adjusts sensor locations based on the evolving outlier intensity.
The proposed framework is validated using real ship traffic data near Norfolk,
Virginia, where numerical results demonstrate the effectiveness of our approach
in improving both classification performance and outlier detection through
sensor deployment.

</details>


### [551] [Causally-Guided Pairwise Transformer -- Towards Foundational Digital Twins in Process Industry](https://arxiv.org/abs/2508.13111)
*Michael Mayr,Georgios C. Chasparis*

Main category: cs.LG

TL;DR: CGPT是一种新颖的架构，通过成对建模和集成因果图，解决了工业多维时间序列预测中的CD/CI模型权衡问题，实现了高精度、鲁棒性和适应性。


<details>
  <summary>Details</summary>
Motivation: 为了解决工业系统中多维时间序列数据的基础建模在通道相关（CD）模型和通道无关（CI）模型之间的权衡问题，即CD模型捕捉特定的跨变量动态但缺乏鲁棒性和适应性，而CI模型提供通用性但牺牲了对系统级预测回归任务至关重要的显式交互建模。

Method: CGPT是一种新颖的架构，它将已知的因果图作为归纳偏差。CGPT的核心围绕成对建模范式，通过将多维数据分解为成对数据来解决CD/CI冲突。该模型使用通道无关的可学习层，所有参数维度均独立于变量数量。

Result: CGPT在模拟常见工业复杂性的长期和单步预测任务的合成和真实工业数据集上得到了验证。结果表明，CGPT在预测精度上显著优于CI和CD基线，并且在保持对问题维度不敏感的同时，与端到端训练的CD模型相比表现具有竞争力。

Conclusion: CGPT通过将多维数据分解为成对数据，集成了已知的因果图作为归纳偏差，并围绕成对建模范式构建，从而解决了CD/CI的冲突。该模型使用通道无关的可学习层，所有参数维度均独立于变量数量。CGPT在成对级别强制执行CD信息流，并在跨对级别实现类似CI的泛化。这种方法解开了复杂系统的动态，并产生了一个高度灵活的架构，确保了可扩展性和任何变量的适应性。

Abstract: Foundational modelling of multi-dimensional time-series data in industrial
systems presents a central trade-off: channel-dependent (CD) models capture
specific cross-variable dynamics but lack robustness and adaptability as model
layers are commonly bound to the data dimensionality of the tackled use-case,
while channel-independent (CI) models offer generality at the cost of modelling
the explicit interactions crucial for system-level predictive regression tasks.
To resolve this, we propose the Causally-Guided Pairwise Transformer (CGPT), a
novel architecture that integrates a known causal graph as an inductive bias.
The core of CGPT is built around a pairwise modeling paradigm, tackling the
CD/CI conflict by decomposing the multidimensional data into pairs. The model
uses channel-agnostic learnable layers where all parameter dimensions are
independent of the number of variables. CGPT enforces a CD information flow at
the pair-level and CI-like generalization across pairs. This approach
disentangles complex system dynamics and results in a highly flexible
architecture that ensures scalability and any-variate adaptability. We validate
CGPT on a suite of synthetic and real-world industrial datasets on long-term
and one-step forecasting tasks designed to simulate common industrial
complexities. Results demonstrate that CGPT significantly outperforms both CI
and CD baselines in predictive accuracy and shows competitive performance with
end-to-end trained CD models while remaining agnostic to the problem
dimensionality.

</details>


### [552] [Contrastive Representations for Temporal Reasoning](https://arxiv.org/abs/2508.13113)
*Alicja Ziarko,Michal Bortkiewicz,Michal Zawalski,Benjamin Eysenbach,Piotr Milos*

Main category: cs.LG

TL;DR: CRTR 是一种新方法，可以从感知和时间结构表示中学习时间推理，并在魔方等任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 研究是否可以从同时捕获感知和时间结构的表示中获得时间推理能力，而不是在经典人工智能中分别使用基于状态的表示进行感知，并通过搜索进行规划（可被视为对动作序列的时间推理）。

Method: CRTR（组合表示时间推理）是一种新方法，它使用负采样方案来消除虚假特征，从而促进时间推理。

Result: CRTR 在 Sokoban 和魔方等领域取得了优异的成绩，并且能够解决魔方谜题，而无需外部搜索算法。

Conclusion: CRTR 是一种用于组合表示以促进时间推理的新方法，它使用负采样方案来消除虚假特征。CRTR 在具有复杂时间结构（例如 Sokoban 和魔方）的领域中取得了优异的成绩，并且能够解决魔方谜题，而无需外部搜索算法。

Abstract: In classical AI, perception relies on learning state-based representations,
while planning, which can be thought of as temporal reasoning over action
sequences, is typically achieved through search. We study whether such
reasoning can instead emerge from representations that capture both perceptual
and temporal structure. We show that standard temporal contrastive learning,
despite its popularity, often fails to capture temporal structure due to its
reliance on spurious features. To address this, we introduce Combinatorial
Representations for Temporal Reasoning (CRTR), a method that uses a negative
sampling scheme to provably remove these spurious features and facilitate
temporal reasoning. CRTR achieves strong results on domains with complex
temporal structure, such as Sokoban and Rubik's Cube. In particular, for the
Rubik's Cube, CRTR learns representations that generalize across all initial
states and allow it to solve the puzzle using fewer search steps than BestFS,
though with longer solutions. To our knowledge, this is the first method that
efficiently solves arbitrary Cube states using only learned representations,
without relying on an external search algorithm.

</details>


### [553] [Training Machine Learning Models on Human Spatio-temporal Mobility Data: An Experimental Study [Experiment Paper]](https://arxiv.org/abs/2508.13135)
*Yueyang Liu,Lance Kennedy,Ruochen Kong,Joon-Seok Kim,Andreas Züfle*

Main category: cs.LG

TL;DR: 本研究着重于预测个人未来几天到几周的完整出行轨迹，并通过实验分析了LSTM和Transformer等模型。研究发现，结合日期和用户历史等语义信息能提高预测精度，而随机抽样可能损害精度。为解决数据偏斜和保持多样性，研究采用了用户聚类和分层抽样。此外，小批量随机梯度优化在数据量有限时能提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 个人层面的出行预测在传染病监测、儿童和老人护理等领域具有重要应用。现有研究主要关注出行轨迹的微观方面（如短期轨迹预测或下一个访问地点），而对宏观层面的出行模式和相应的生活规律的关注有限。

Method: 本研究通过对长短期记忆（LSTM）和基于Transformer的架构进行全面的实验分析，并深入研究了人类活动模式的统计分布，来解决人类活动预测中的一个未被充分探索的问题：确定使用历史数据训练机器学习模型以预测个体未来几天和几周完整轨迹的最佳实践。研究还探讨了包含个体生活模式如何提高预测效果。

Result: 本研究的实验结果表明，通过包含星期几和用户特定的历史信息等语义信息，可以提升模型对个体生活模式的理解和预测的准确性。此外，该研究还发现，用户抽样可能会导致数据偏斜和预测精度下降，并提出通过用户语义聚类和分层抽样来解决这些问题。研究还证实，小批量随机梯度优化在数据有限的情况下能有效提升模型性能。

Conclusion: 该研究表明，显式地包含星期几和用户特定的历史信息等语义信息可以帮助模型更好地理解个体生活模式并提高预测准确性。此外，用户抽样可能会加剧数据偏斜并导致预测精度显著下降。为了缓解数据不平衡和保持多样性，研究采用了用户语义聚类和分层抽样。结果还表明，小批量随机梯度优化可以提高模型性能，尤其是在人类活动训练数据有限的情况下。

Abstract: Individual-level human mobility prediction has emerged as a significant topic
of research with applications in infectious disease monitoring, child, and
elderly care. Existing studies predominantly focus on the microscopic aspects
of human trajectories: such as predicting short-term trajectories or the next
location visited, while offering limited attention to macro-level mobility
patterns and the corresponding life routines. In this paper, we focus on an
underexplored problem in human mobility prediction: determining the best
practices to train a machine learning model using historical data to forecast
an individuals complete trajectory over the next days and weeks. In this
experiment paper, we undertake a comprehensive experimental analysis of diverse
models, parameter configurations, and training strategies, accompanied by an
in-depth examination of the statistical distribution inherent in human mobility
patterns. Our empirical evaluations encompass both Long Short-Term Memory and
Transformer-based architectures, and further investigate how incorporating
individual life patterns can enhance the effectiveness of the prediction. We
show that explicitly including semantic information such as day-of-the-week and
user-specific historical information can help the model better understand
individual patterns of life and improve predictions. Moreover, since the
absence of explicit user information is often missing due to user privacy, we
show that the sampling of users may exacerbate data skewness and result in a
substantial loss in predictive accuracy. To mitigate data imbalance and
preserve diversity, we apply user semantic clustering with stratified sampling
to ensure that the sampled dataset remains representative. Our results further
show that small-batch stochastic gradient optimization improves model
performance, especially when human mobility training data is limited.

</details>


### [554] [MDPO: Overcoming the Training-Inference Divide of Masked Diffusion Language Models](https://arxiv.org/abs/2508.13148)
*Haoyu He,Katrin Renz,Yong Cao,Andreas Geiger*

Main category: cs.LG

TL;DR: 本文提出了一种名为 MDPO 的新方法，通过将扩散语言模型的训练和推理过程对齐来解决它们之间的差异。MDPO 使用强化学习来优化去噪轨迹，并在 MATH500 和 Countdown 数据集上取得了优于现有 SOTA 方法的性能，同时减少了训练成本。此外，引入了 RCR 策略来改进模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散语言模型 (MDLM) 在训练和推理之间存在关键差异：在推理时，MDLM 逐步揭示生成序列的结构，而在训练时则会忽略这种结构，因为标记是随机屏蔽的。这种差异会导致次优性能，并且是先前工作中被忽视的一个未解决的问题。

Method: 本文将学习有效的去噪轨迹的问题构建为序贯决策问题，并利用由此产生的框架应用强化学习。提出了一种新颖的掩码扩散策略优化 (MDPO) 来利用扩散所具有的马尔可夫属性，并在推理时使用的相同渐进式精炼时间表下显式地训练模型。此外，还提出了一种名为 RCR 的插入式推理替代方法，以改进 MDLMs 的重新屏蔽策略。

Result: MDPO 在 MATH500 和 Countdown 数据集上均取得了显著的性能提升，并且与 SOTA 方法相比，所需的梯度更新次数大大减少。RCR 策略作为一种即插即用的解决方案，进一步提高了性能。

Conclusion: MDPO 匹配了先前最先进 (SOTA) 方法的性能，但梯度更新次数减少了 60 倍，在 MATH500 上平均提高了 9.6%，在 Countdown 上提高了 54.2%。此外，通过改进的重新屏蔽策略 (RCR) 克服了 MDLMs 无法灵活地精炼标记的限制，该策略可与 MDPO 结合使用以获得额外的收益。

Abstract: Diffusion language models, as a promising alternative to traditional
autoregressive (AR) models, enable faster generation and richer conditioning on
bidirectional context. However, they suffer from a key discrepancy between
training and inference: during inference, MDLMs progressively reveal the
structure of the generated sequence by producing fewer and fewer masked tokens,
whereas this structure is ignored in training as tokens are masked at random.
Although this discrepancy between training and inference can lead to suboptimal
performance, it has been largely overlooked by previous works, leaving closing
this gap between the two stages an open problem. To address this, we frame the
problem of learning effective denoising trajectories as a sequential
decision-making problem and use the resulting framework to apply reinforcement
learning. We propose a novel Masked Diffusion Policy Optimization (MDPO) to
exploit the Markov property diffusion possesses and explicitly train the model
under the same progressive refining schedule used at inference. MDPO matches
the performance of the previous state-of-the-art (SOTA) method with 60x fewer
gradient updates, while achieving average improvements of 9.6% on MATH500 and
54.2% on Countdown over SOTA when trained within the same number of weight
updates. Additionally, we improve the remasking strategy of MDLMs as a plug-in
inference replacement to overcome the limitation that the model cannot refine
tokens flexibly. This simple yet effective training-free strategy, what we
refer to as RCR, consistently improves performance and yields additional gains
when combined with MDPO. Our findings establish great potential for
investigating the discrepancy between pre-training and inference of MDLMs.
Code: https://github.com/autonomousvision/mdpo. Project Page:
https://cli212.github.io/MDPO/.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [555] [On Balancing Sparsity with Reliable Connectivity in Distributed Network Design with Random K-out Graphs](https://arxiv.org/abs/2508.11863)
*Mansi Sood,Eray Can Elumar,Osman Yagan*

Main category: cs.SI

TL;DR: 本文研究了在节点有限或不可靠的分布式系统中，如何选择随机K-out图的网络参数以保证可靠连通性。通过推导连通性概率的界限、分析r-robustness性质以及模拟恶意节点删除的影响，为提高网络通信效率和数据推断的可靠性提供了理论支持。


<details>
  <summary>Details</summary>
Motivation: 为了解决在有限或不可靠节点条件下，如何选择网络参数以保证可靠连通性的问题，并超越渐进结果，以应对随机和对抗环境。

Method: 本文推导了在节点数量有限的情况下，随机K-out图中连通性概率的上界和下界。此外，分析了r-robustness的性质，并针对基于成对掩蔽的聚合机制，对恶意节点（模型为删除）对连通性和巨型组件大小的影响进行了建模和分析。

Result: 研究为随机K-out图中连通性概率在有限节点数情况下的界限，以及r-robustness性质提供了理论分析，并对恶意节点删除对连通性和巨型组件大小的影响进行了建模，为相关算法提供了性能保证。

Conclusion: 该研究为在有限或不可靠节点条件下，随机K-out图中保证可靠连通性的网络参数选择提供了理论依据，并为可靠网络推断算法提供端到端性能保证。

Abstract: In several applications in distributed systems, an important design criterion
is ensuring that the network is sparse, i.e., does not contain too many edges,
while achieving reliable connectivity. Sparsity ensures communication overhead
remains low, while reliable connectivity is tied to reliable communication and
inference on decentralized data reservoirs and computational resources. A class
of network models called random K-out graphs appear widely as a heuristic to
balance connectivity and sparsity, especially in settings with limited trust,
e.g., privacy-preserving aggregation of networked data in which networks are
deployed. However, several questions remain regarding how to choose network
parameters in response to different operational requirements, including the
need to go beyond asymptotic results and the ability to model the stochastic
and adversarial environments. To address this gap, we present theorems to
inform the choice of network parameters that guarantee reliable connectivity in
regimes where nodes can be finite or unreliable. We first derive upper and
lower bounds for probability of connectivity in random K-out graphs when the
number of nodes is finite. Next, we analyze the property of r-robustness, a
stronger notion than connectivity that enables resilient consensus in the
presence of malicious nodes. Finally, motivated by aggregation mechanisms based
on pairwise masking, we model and analyze the impact of a subset of adversarial
nodes, modeled as deletions, on connectivity and giant component size - metrics
that are closely tied to privacy guarantees. Together, our results pave the way
for end-to-end performance guarantees for a suite of algorithms for reliable
inference on networks.

</details>


### [556] [Trust@Health: A Trust-Based Multilayered Network for Scalable Healthcare Service Management](https://arxiv.org/abs/2508.11942)
*Avijit Gayen,Somyajit Chakraborty,Joydeep Chakraborty,Angshuman Jana*

Main category: cs.SI

TL;DR: 利用演进图框架和信任关系来优化医疗保健系统，通过量化实体的重要性来识别关键实体，并为患者转诊和决策提供支持。


<details>
  <summary>Details</summary>
Motivation: 研究医疗保健系统中医生、部门和医院之间复杂的相互关系，以优化医疗保健服务。

Method: 利用演进图框架，并强调层内和层间信任关系，开发了一个基于信任的算法来量化关键医疗实体的社会和职业互动的重要性。

Result: 研究结果显示，所提出的信任度量与医院和部门的评级之间存在很强的相关性（0.91），尽管医生评级的分布存在潜在偏差。

Conclusion: 通过对医疗保健关系和信任动态的建模，该框架支持可扩展的医疗保健基础设施，从而实现有效的患者转诊、个性化推荐和增强的决策路径。

Abstract: We study the intricate relationships within healthcare systems, focusing on
interactions among doctors, departments, and hospitals. Leveraging an
evolutionary graph framework, the proposed model emphasizes both intra-layer
and inter-layer trust relationships to better understand and optimize
healthcare services. The trust-based network facilitates the identification of
key healthcare entities by integrating their social and professional
interactions, culminating in a trust-based algorithm that quantifies the
importance of these entities. Validation with a real-world dataset reveals a
strong correlation (0.91) between the proposed trust measures and the ratings
of hospitals and departments, though doctor ratings demonstrate skewed
distributions due to potential biases. By modeling these relationships and
trust dynamics, the framework supports scalable healthcare infrastructure,
enabling effective patient referrals, personalized recommendations, and
enhanced decision-making pathways.

</details>


### [557] [An Efficient Network-aware Direct Search Method for Influence Maximization](https://arxiv.org/abs/2508.12164)
*Matteo Bergamaschi,Sara Venturini,Francesco Tudisco,Francesco Rinaldi*

Main category: cs.SI

TL;DR: 本研究提出了一种名为NaDS的新型直接搜索方法，通过结合网络结构来解决影响最大化（IM）问题，并在大规模实验中证明其比现有方法具有更高的计算效率。


<details>
  <summary>Details</summary>
Motivation: 解决传统直接搜索方法在处理像影响最大化（IM）这类组合优化问题时面临的可扩展性问题，因为这些方法通常需要高成本的函数评估。

Method: 提出了一种名为网络感知直接搜索（NaDS）的创新直接搜索方法，该方法将网络结构集成到其邻域构建中，并用于解决影响最大化（IM）问题的混合整数规划形式（通用信息传播模型）。

Result: 在大型网络上对NaDS方法进行了测试，并与现有的IM问题状态艺术方法（包括直接搜索方法以及各种贪婪技术和启发式方法）进行了比较。实验结果经验性地证实了NaDS的假设，表明利用IM问题的图结构可以显著提高其在所考虑环境中的计算效率。

Conclusion: 该研究提出的网络感知直接搜索（NaDS）方法通过将网络结构整合到其邻域构建中，并应用于影响最大化（IM）问题的混合整数规划公式（通用信息传播模型），在处理IM问题时表现出显著的计算效率提升，并得到了大规模网络实验的验证。

Abstract: Influence Maximization (IM) is a pivotal concept in social network analysis,
involving the identification of influential nodes within a network to maximize
the number of influenced nodes, and has a wide variety of applications that
range from viral marketing and information dissemination to public health
campaigns. IM can be modeled as a combinatorial optimization problem with a
black-box objective function, where the goal is to select $B$ seed nodes that
maximize the expected influence spread. Direct search methods, which do not
require gradient information, are well-suited for such problems. Unlike
gradient-based approaches, direct search algorithms, in fact, only evaluate the
objective function at a suitably chosen set of trial points around the current
solution to guide the search process. However, these methods often suffer from
scalability issues due to the high cost of function evaluations, especially
when applied to combinatorial problems like IM. This work, therefore, proposes
the Network-aware Direct Search (NaDS) method, an innovative direct search
approach that integrates the network structure into its neighborhood
formulation and is used to tackle a mixed-integer programming formulation of
the IM problem, the so-called General Information Propagation model. We tested
our method on large-scale networks, comparing it to existing state-of-the-art
approaches for the IM problem, including direct search methods and various
greedy techniques and heuristics. The results of the experiments empirically
confirm the assumptions underlying NaDS, demonstrating that exploiting the
graph structure of the IM problem in the algorithmic framework can
significantly improve its computational efficiency in the considered context.

</details>


### [558] [MAD: A Benchmark for Multi-Turn Audio Dialogue Fact-Checking](https://arxiv.org/abs/2508.12186)
*Chaewan Chun,Lysandre Terrisse,Delvin Ce Zhang,Dongwon Lee*

Main category: cs.SI

TL;DR: MAD是首个针对多轮口头对话及其对应音频的事实核查数据集，解决了现有数据集在处理口头错误信息的对话和声学复杂性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 尽管音频平台日益普及，但对口头内容进行事实核查仍远未成熟。语音中的错误信息常常通过多轮对话展开，并受到说话者互动、犹豫、重叠语音和情绪基调等因素的影响，这些因素都使声明检测和验证复杂化。现有的数据集未能涵盖这些方面，因为它们只关注孤立的句子或文本记录，而没有对口头错误信息的对话和声学复杂性进行建模。

Method: MAD（多轮音频对话）数据集，包含针对说话者轮次、对话场景、信息传播风格、句子级检查价值以及句子级和对话级真实性的标注。

Result: 现有模型在句子级和对话级的准确率仅分别为72-74%和71-72%，这凸显了MAD的挑战性。

Conclusion: 该MAD数据集为推进多模态和对话事实核查提供了高质量的基准，并揭示了有关推理语音和对话动态的开放性挑战。

Abstract: Despite the growing popularity of audio platforms, fact-checking spoken
content remains significantly underdeveloped. Misinformation in speech often
unfolds across multi-turn dialogues, shaped by speaker interactions,
disfluencies, overlapping speech, and emotional tone-factors that complicate
both claim detection and verification. Existing datasets fall short by focusing
on isolated sentences or text transcripts, without modeling the conversational
and acoustic complexity of spoken misinformation. We introduce MAD (Multi-turn
Audio Dialogues), the first fact-checking dataset aligned with multi-turn
spoken dialogues and corresponding audio. MAD captures how misinformation is
introduced, contested, and reinforced through natural conversation. Each
dialogue includes annotations for speaker turns, dialogue scenarios,
information spread styles, sentence-level check-worthiness, and both sentence-
and dialogue-level veracity. The dataset supports two core tasks: check-worthy
claim detection and claim verification. Benchmarking shows that even strong
pretrained models reach only 72-74% accuracy at the sentence level and 71-72%
at the dialogue level in claim verification, underscoring MAD's difficulty. MAD
offers a high-quality benchmark for advancing multimodal and conversational
fact-checking, while also surfacing open challenges related to reasoning over
speech and dialogue dynamics.

</details>


### [559] [Beyond Physicians: Social and Familial Norms Driving Cesarean Section Decisions in Bangladesh](https://arxiv.org/abs/2508.12240)
*Jamal Uddin*

Main category: cs.SI

TL;DR: 孟加拉国剖腹产率过高，多数并非首选，家庭和社会期望比医生建议更能影响分娩方式决策。


<details>
  <summary>Details</summary>
Motivation: 为了解决孟加拉国剖腹产率急剧上升对妇女健康构成的风险。

Method: 本研究以健康信念模型（HBM）和计划行为理论（TPB）为指导，对503名调查参与者进行了分析，探讨了影响分娩方式决策的社会文化因素。

Result: 研究发现，91%的剖腹产案例并非产妇首选，表明健康信念与实际行为之间存在脱节。主观规范（尤其是家庭影响和社会期望）在决定剖腹产时比医生建议更重要。

Conclusion: 在孟加拉国，超过72%的住院分娩采用剖腹产，远超世卫组织15%的建议上限，对妇女健康构成威胁。

Abstract: Women's health in Bangladesh faces risks due to an alarming rise in cesarean
section (CS) rates, exceeding 72% in hospital-based deliveries, far surpassing
the WHO's recommended limit of 15%. This study, guided by the Health Belief
Model (HBM) and the Theory of Planned Behavior (TPB), explored socio-cultural
factors influencing childbirth mode decisions. Among 503 survey participants,
91% of CS cases occurred against initial preferences, revealing a disconnect
between health beliefs and behavior. Subjective norms, particularly family
influence and social expectations, emerged as more critical in shaping CS
decisions than physician recommendations.

</details>


### [560] [Insight Rumors: A Novel Textual Rumor Locating and Marking Model Leveraging Att_BiMamba2 Network](https://arxiv.org/abs/2508.12574)
*Bin Ma,Yifei Zhang,Yongjin Xian,Qi Li,Linna Zhou,Gongxun Miao*

Main category: cs.SI

TL;DR: 提出了一种名为"Insight Rumors"的新型模型，通过Att_BiMamba2和谣言定位与标记模块，能够精确定位和标记文本中的谣言内容。


<details>
  <summary>Details</summary>
Motivation: 现有谣言检测模型主要关注将上下文分类为谣言或非谣言，缺乏定位和标记特定谣言内容的能力。

Method: 提出了一种名为"Insight Rumors"的新型谣言检测模型，该模型包含一个“注意力双向Mamba2网络”（Att_BiMamba2）和一个“谣言定位与标记模块”。Att_BiMamba2通过构建双向Mamba2模型并应用点积注意力机制来加权和组合双向输出，以增强高维谣言特征表示。谣言定位与标记模块则利用跳接网络将高维谣言特征映射到低维标签特征，并结合条件随机场（CRF）对输出标签特征施加约束，以实现准确的谣言内容定位。此外，还构建了一个用于谣言定位与标记的标注数据集，并通过实验评估了所提出模型的有效性。

Result: 实验结果表明，所提出的模型在准确检测和精确定位与标记谣言方面均优于现有技术。

Conclusion: 该模型不仅能准确检测谣言，还能在上下文中精确定位和标记谣言，优于只能粗略区分谣言的现有方案。

Abstract: With the development of social media networks, rumor detection models have
attracted more and more attention. Whereas, these models primarily focus on
classifying contexts as rumors or not, lacking the capability to locate and
mark specific rumor content. To address this limitation, this paper proposes a
novel rumor detection model named Insight Rumors to locate and mark rumor
content within textual data. Specifically, we propose the Bidirectional Mamba2
Network with Dot-Product Attention (Att_BiMamba2), a network that constructs a
bidirectional Mamba2 model and applies dot-product attention to weight and
combine the outputs from both directions, thereby enhancing the representation
of high-dimensional rumor features. Simultaneously, a Rumor Locating and
Marking module is designed to locate and mark rumors. The module constructs a
skip-connection network to project high-dimensional rumor features onto
low-dimensional label features. Moreover, Conditional Random Fields (CRF) is
employed to impose strong constraints on the output label features, ensuring
accurate rumor content location. Additionally, a labeled dataset for rumor
locating and marking is constructed, with the effectiveness of the proposed
model is evaluated through comprehensive experiments. Extensive experiments
indicate that the proposed scheme not only detects rumors accurately but also
locates and marks them in context precisely, outperforming state-of-the-art
schemes that can only discriminate rumors roughly.

</details>


### [561] [Influence Prediction in Collaboration Networks: An Empirical Study on arXiv](https://arxiv.org/abs/2508.13029)
*Marina Lin,Laura P. Schaposnik,Raina Wu*

Main category: cs.SI

TL;DR: 本研究对社交领域模型进行了实证研究，以预测影响力。该模型结合了链接预测和中心性选择，并应用于arXiv合作网络。结果表明，该模型能有效识别潜在影响者，在初始图更密集时表现最佳，RA-2度量在预测误差方面表现优异，证明了其在预测现实世界影响力的可行性。


<details>
  <summary>Details</summary>
Motivation: 对先前提出的社交领域模型进行实证研究，以预测影响。

Method: 结合链接预测和基于中心性的Top-k选择，并将其应用于时间演化的arXiv广义相对论和量子宇宙学合作网络。

Result: 在链接预测和影响力最大化任务中，使用均方误差评估模型性能，并发现该模型能有效识别潜在影响者，在初始图更密集时表现最佳，RA-2度量在预测误差方面持续表现最优。

Conclusion: 该模型能够有效识别潜在的影响者，并在初始图更密集的情况下表现最佳，RA-2度量在预测误差方面表现优异，证明了该模型在预测不断演化的网络中的实际影响力的可行性。

Abstract: This paper provides an empirical study of the Social Sphere Model for
influence prediction, previously introduced by the authors, combining link
prediction with top-k centrality-based selection. We apply the model to the
temporal arXiv General Relativity and Quantum Cosmology collaboration network,
evaluating its performance under varying edge sampling rates and prediction
horizons to reflect different levels of initial data completeness and network
evolution. Accuracy is assessed using mean squared error in both link
prediction and influence maximization tasks. The results show that the model
effectively identifies latent influencers, i.e., nodes that are not initially
central but later influential, and performs best with denser initial graphs.
Among the similarity measures tested, the newly introduced RA-2 metric
consistently yields the lowest prediction errors. These findings support the
practical applicability of the model to predict real-world influence in
evolving networks.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [562] [HPD: Hybrid Projection Decomposition for Robust State Space Models on Analog CIM Hardware](https://arxiv.org/abs/2508.11935)
*Yuannuo Feng,Wenyong Zhou,Yuexi Lyu,Hanjie Liu,Zhengwu Liu,Ngai Wong,Wang Kang*

Main category: cs.AR

TL;DR: 本研究提出HPD策略，通过SVD分解和混合计算，显著提高了SSMs在CIM架构下的准确性和鲁棒性，尤其在处理噪声和推理任务时效果显著。


<details>
  <summary>Details</summary>
Motivation: CIM架构在处理SSMs时，设备非理想性会导致权重扰动，从而降低推理精度。本研究旨在分析SSMs在噪声条件下的鲁棒性，并提出一种改进方法。

Method: 通过SVD分解输出投影层的权重矩阵，将U矩阵映射到内存计算，V>矩阵映射到数字硬件，实现混合投影分解。

Result: HPD策略在Mamba模型上进行了测试，在各种噪声条件下，相比基线模型，困惑度最多降低了99.57%，在PIQA基准测试中，常识推理准确率最高提升了96.67%。

Conclusion: HPD策略通过混合投影分解策略，将SVD的U矩阵映射到内存计算，V>矩阵映射到数字硬件，从而提高了SSMs在CIM架构下的鲁棒性和准确性。

Abstract: State Space Models (SSMs) are efficient alternatives to traditional sequence
models, excelling at processing long sequences with lower computational
complexity. Their reliance on matrix multiplications makes them ideal for
compute-in-memory (CIM) architectures, which improve energy efficiency by
computing within memory arrays. However, device non-idealities in CIM introduce
weight perturbations that can degrade inference accuracy. In this paper, we
systematically analyze the robustness of SSMs under noisy conditions,
identifying that the final block and output projection layers are more
susceptible to perturbations compared to other components. Building on these
insights, we propose HPD, a Hybrid Projection Decomposition strategy for the
last output projection layer. We replace the original weight matrix with the
multiplication of U and {\Sigma} in its SVD to ensure compatibility with
existing hardware architectures, while offloading V> to digital hardware for
precise and robust correction. Comprehensive tests on Mamba models show that
our method reduces perplexity by up to 99.57% under various noise conditions
compared to baseline models, with accuracy gains of up to 96.67% on the PIQA
benchmark for commonsense reasoning.

</details>


### [563] [Special Session: Sustainable Deployment of Deep Neural Networks on Non-Volatile Compute-in-Memory Accelerators](https://arxiv.org/abs/2508.12195)
*Yifan Qin,Zheyu Yan,Wujie Wen,Xiaobo Sharon Hu,Yiyu Shi*

Main category: cs.AR

TL;DR: 提出了一种基于负反馈理论的OVF训练机制，以解决NVCIM加速器中因NVM器件变化导致的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: NVCIM加速器的性能会因为NVM器件的随机性和内在变化而下降，而传统的写-验证操作会消耗大量能量和时间。

Method: 提出了一种新颖的负优化训练机制，并通过开发定向变分前向（OVF）训练方法来实现该机制。

Result: OVF的实验结果显示，其性能优于现有的最先进技术，推理准确性最高提高了46.71%，同时降低了认知不确定性。

Conclusion: OVF通过减少对写-验证操作的依赖，提高了NVCIM加速器的推理准确性并降低了认知不确定性，为NVCIM加速器的可持续和实际部署做出了贡献，解决了性能下降问题，同时保持了NVCIM加速器在可持续计算方面的优势。

Abstract: Non-volatile memory (NVM) based compute-in-memory (CIM) accelerators have
emerged as a sustainable solution to significantly boost energy efficiency and
minimize latency for Deep Neural Networks (DNNs) inference due to their in-situ
data processing capabilities. However, the performance of NVCIM accelerators
degrades because of the stochastic nature and intrinsic variations of NVM
devices. Conventional write-verify operations, which enhance inference accuracy
through iterative writing and verification during deployment, are costly in
terms of energy and time. Inspired by negative feedback theory, we present a
novel negative optimization training mechanism to achieve robust DNN deployment
for NVCIM. We develop an Oriented Variational Forward (OVF) training method to
implement this mechanism. Experiments show that OVF outperforms existing
state-of-the-art techniques with up to a 46.71% improvement in inference
accuracy while reducing epistemic uncertainty. This mechanism reduces the
reliance on write-verify operations and thus contributes to the sustainable and
practical deployment of NVCIM accelerators, addressing performance degradation
while maintaining the benefits of sustainable computing with NVCIM
accelerators.

</details>


### [564] [HOMI: Ultra-Fast EdgeAI platform for Event Cameras](https://arxiv.org/abs/2508.12637)
*Shankaranarayanan H,Satyapreet Singh Yadav,Adithya Krishna,Ajay Vikram P,Mahesh Mehendale,Chetan Singh Thakur*

Main category: cs.AR

TL;DR: HOMI是一个超低延迟的端到端边缘AI平台，专为事件相机优化。它通过硬件加速和优化的预处理管道，在保持高精度的同时实现了高吞吐量，并且资源占用率低，为未来扩展留有余地。


<details>
  <summary>Details</summary>
Motivation: 事件相机由于其异步操作和稀疏、事件驱动的输出，在需要快速高效闭环控制的边缘机器人应用中具有优势，例如手势识别的人机交互。然而，现有的事件处理解决方案存在端到端实现不完整、高延迟和未能充分利用事件数据稀疏性等局限性。

Method: 提出了HOMI，一个包含Prophesee IMX636事件传感器芯片和Xilinx Zynq UltraScale+MPSoC FPGA芯片的超低延迟端到端边缘AI平台，并集成了一个自研AI加速器。开发了支持恒定时间和恒定事件模式的硬件优化预处理管道，用于直方图累积、线性和指数时间表面。

Result: HOMI在DVS Gesture数据集上实现了94%的准确率（高精度配置），并提供了1000 fps的吞吐量（低延迟配置）。

Conclusion: HOMI平台在DVS Gesture数据集上实现了94%的准确率，并在低延迟配置下提供了1000 fps的吞吐量。其硬件优化管道占用FPGA资源少（33% LUT），为进一步降低延迟、模型并行化、多任务部署或集成更复杂的架构留有充足空间。

Abstract: Event cameras offer significant advantages for edge robotics applications due
to their asynchronous operation and sparse, event-driven output, making them
well-suited for tasks requiring fast and efficient closed-loop control, such as
gesture-based human-robot interaction. Despite this potential, existing event
processing solutions remain limited, often lacking complete end-to-end
implementations, exhibiting high latency, and insufficiently exploiting event
data sparsity. In this paper, we present HOMI, an ultra-low latency, end-to-end
edge AI platform comprising a Prophesee IMX636 event sensor chip with an Xilinx
Zynq UltraScale+MPSoC FPGA chip, deploying an in-house developed AI
accelerator. We have developed hardware-optimized pre-processing pipelines
supporting both constant-time and constant-event modes for histogram
accumulation, linear and exponential time surfaces. Our general-purpose
implementation caters to both accuracy-driven and low-latency applications.
HOMI achieves 94% accuracy on the DVS Gesture dataset as a use case when
configured for high accuracy operation and provides a throughput of 1000 fps
for low-latency configuration. The hardware-optimised pipeline maintains a
compact memory footprint and utilises only 33% of the available LUT resources
on the FPGA, leaving ample headroom for further latency reduction, model
parallelisation, multi-task deployments, or integration of more complex
architectures.

</details>


### [565] [A Time- and Energy-Efficient CNN with Dense Connections on Memristor-Based Chips](https://arxiv.org/abs/2508.12251)
*Wenyong Zhou,Yuan Ren,Jiajun Zhou,Tianshu Hou,Ngai Wong*

Main category: cs.AR

TL;DR: To make lightweight CNNs work better with RRAM chips, this paper suggests a new way to combine feature maps in DenseNet to improve chip usage, making it faster and more energy-efficient than older methods while keeping accuracy high.


<details>
  <summary>Details</summary>
Motivation: The motivation is to design lightweight CNN models for edge AI that are compatible with Compute-in-Memory (CIM) architectures, specifically using RRAM devices. Classical lightweight designs like depthwise convolution under-utilize RRAM crossbars due to their dense weight-to-RRAM cell mapping. DenseNet, while accurate and parameter-efficient, suffers from low crossbar utilization and high latency/energy consumption due to linearly increasing channels.

Method: The paper proposes a scheme that concatenates feature maps of front layers to form the input of the last layer in each stage. This approach is evaluated on DenseNet and compared with conventional ResNet and DenseNet on CIFAR and ImageNet datasets.

Result: The proposed model consumes less time and energy than conventional ResNet and DenseNet, while producing competitive accuracy on CIFAR and ImageNet datasets.

Conclusion: This paper proposes a novel scheme for concatenating feature maps of front layers to form the input of the last layer in each stage to improve the utilization of RRAM crossbars in lightweight CNN models, resulting in reduced latency and energy consumption with competitive accuracy.

Abstract: Designing lightweight convolutional neural network (CNN) models is an active
research area in edge AI. Compute-in-memory (CIM) provides a new computing
paradigm to alleviate time and energy consumption caused by data transfer in
von Neumann architecture. Among competing alternatives, resistive random-access
memory (RRAM) is a promising CIM device owing to its reliability and multi-bit
programmability. However, classical lightweight designs such as depthwise
convolution incurs under-utilization of RRAM crossbars restricted by their
inherently dense weight-to-RRAM cell mapping. To build an RRAM-friendly yet
efficient CNN, we evaluate the hardware cost of DenseNet which maintains a high
accuracy vs other CNNs at a small parameter count. Observing the linearly
increasing channels in DenseNet leads to a low crossbar utilization and causes
large latency and energy consumption, we propose a scheme that concatenates
feature maps of front layers to form the input of the last layer in each stage.
Experiments show that our proposed model consumes less time and energy than
conventional ResNet and DenseNet, while producing competitive accuracy on CIFAR
and ImageNet datasets.

</details>


### [566] [AutoPower: Automated Few-Shot Architecture-Level Power Modeling by Power Group Decoupling](https://arxiv.org/abs/2508.12294)
*Qijun Zhang,Yao Lu,Mengming Li,Zhiyao Xie*

Main category: cs.AR

TL;DR: AutoPower 是一种用于 CPU 功耗建模的自动化工具，即使在数据有限的情况下也能实现高精度。


<details>
  <summary>Details</summary>
Motivation: 传统的分析式架构级功耗模型不准确，而最近提出的基于机器学习 (ML) 的模型需要大量数据进行训练，这在实际中是不可行的。

Method: AutoPower 通过解耦电源组并为每个组构建单独的电源模型，然后在每个电源组内将模型进一步解耦为多个子模型来实现。

Result: 与代表性的基于 ML 的功耗模型 McPAT-Calib 相比，AutoPower 的 MAPE 低 5%，$R^2$ 高 0.09。

Conclusion: AutoPower 可以在仅有两个已知配置的情况下，在训练中实现 4.36% 的低平均绝对百分比误差 (MAPE) 和 0.96 的高 $R^2$。

Abstract: Power efficiency is a critical design objective in modern CPU design.
Architects need a fast yet accurate architecture-level power evaluation tool to
perform early-stage power estimation. However, traditional analytical
architecture-level power models are inaccurate. The recently proposed machine
learning (ML)-based architecture-level power model requires sufficient data
from known configurations for training, making it unrealistic.
  In this work, we propose AutoPower targeting fully automated
architecture-level power modeling with limited known design configurations. We
have two key observations: (1) The clock and SRAM dominate the power
consumption of the processor, and (2) The clock and SRAM power correlate with
structural information available at the architecture level. Based on these two
observations, we propose the power group decoupling in AutoPower. First,
AutoPower decouples across power groups to build individual power models for
each group. Second, AutoPower designs power models by further decoupling the
model into multiple sub-models within each power group. In our experiments,
AutoPower can achieve a low mean absolute percentage error (MAPE) of 4.36\% and
a high $R^2$ of 0.96 even with only two known configurations for training. This
is 5\% lower in MAPE and 0.09 higher in $R^2$ compared with McPAT-Calib, the
representative ML-based power model.

</details>


### [567] [Soft Error Probability Estimation of Nano-scale Combinational Circuits](https://arxiv.org/abs/2508.12345)
*Ali Jockar,Mohsen Raji*

Main category: cs.AR

TL;DR: 随着技术缩减，纳米电路更容易受单粒子翻转（SEU）影响。本研究提出了一种整合工艺变化（PV）和老化效应的新框架，通过改进的电气屏蔽模型和统计方法，可以更准确、更高效地估计软错误概率（SEP），计算开销比传统方法降低约2.5%，有助于提高纳米电路的可靠性。


<details>
  <summary>Details</summary>
Motivation: 随着技术扩展到纳米级别，数字电路更容易受到单粒子翻转（SEUs）和瞬变（SETs）的影响。虽然逻辑、电气和时序屏蔽效应会影响软错误概率（SEP），但工艺变化（PV）和老化引起的退化进一步增加了SEP估计的复杂性。现有方法通常单独处理PV或老化效应，或者依赖计算量大的蒙特卡洛模拟，这限制了它们在大规模电路优化中的实用性。

Method: 本研究提出了一种新的框架，用于整合工艺变化（PV）和老化效应的单粒子翻转（SEP）分析。研究采用了增强的电气屏蔽模型和统计方法来量化软错误概率。

Result: 实验结果表明，所提出的方法实现了高精度，并将计算开销与基于蒙特卡洛的方法相比降低了约2.5%。

Conclusion: 该研究提出了一种创新的框架，用于全面集成工艺变化（PV）和老化效应的单粒子翻转（SEP）分析。通过引入增强的电气屏蔽模型和统计方法，该框架能够量化在工艺和老化变化下的软错误概率。实验结果表明，与基于蒙特卡洛的方法相比，该方法在保持高精度的同时，将计算开销降低了约2.5%。这项工作通过实现对制造变化和长期晶体管退化影响下的SEP的高效、准确估计，推动了纳米级电路可靠性设计的发展。

Abstract: As technology scales, nano-scale digital circuits face heightened
susceptibility to single event upsets (SEUs) and transients (SETs) due to
shrinking feature sizes and reduced operating voltages. While logical,
electrical, and timing masking effects influence soft error probability (SEP),
the combined impact of process variation (PV) and aging-induced degradation
further complicates SEP estimation. Existing approaches often address PV or
aging in isolation, or rely on computationally intensive methods like Monte
Carlo simulations, limiting their practicality for large-scale circuit
optimization. This paper introduces a novel framework for SEP analysis that
holistically integrates PV and aging effects. We propose an enhanced electrical
masking model and a statistical methodology to quantify soft error probability
under process and aging variations. Experimental results demonstrate that the
proposed approach achieves high accuracy while reducing computational overhead
by approximately 2.5% compared to Monte Carlo-based methods. This work advances
the design of reliable nano-scale circuits by enabling efficient, accurate SEP
estimation in the presence of manufacturing variability and long-term
transistor degradation.

</details>


### [568] [An ECC-based Fault Tolerance Approach for DNNs](https://arxiv.org/abs/2508.12347)
*Mohsen Raji,Mohammad Zaree,Kimia Soroush*

Main category: cs.AR

TL;DR: SPW是一种基于ECC的DNN容错方法，可提高其在比特翻转错误下的准确性。


<details>
  <summary>Details</summary>
Motivation: DNN已广泛应用于数据中心和安全关键系统，其在存储器中参数的比特翻转错误可能影响其在安全关键应用中的适用性。

Method: 提出了一种基于错误纠正码（ECC）的容错方法SPW，通过ECC检测错误，单比特错误时进行纠正，否则将权重置零（掩码）。

Result: 实验结果表明，在10^(-1)的比特错误率下，SPW方法的准确率比未采用ECC的方案提高了300%以上，但面积开销增加了47.5%。

Conclusion: SPW是一种基于ECC的容错方法，可以提高DNN在比特翻转错误下的功能正确性，在10^(-1)的比特错误率下，准确率比不使用ECC的方案提高了300%以上，但会增加47.5%的面积开销。

Abstract: Deep Neural Network (DNN) has achieve great success in solving a wide range
of machine learning problems. Recently, they have been deployed in datacenters
(potentially for business-critical or industrial applications) and
safety-critical systems such as self-driving cars. So, their correct
functionality in the presence of potential bit-flip errors on DNN parameters
stored in memories plays the key role in their applicability in safety-critical
applications. In this paper, a fault tolerance approach based on Error
Correcting Codes (ECC), called SPW, is proposed to ensure the correct
functionality of DNNs in the presence of bit-flip faults. In the proposed
approach, error occurrence is detected by the stored ECC and then, it is
correct in case of a single-bit error or the weight is completely set to zero
(i.e. masked) otherwise. A statistical fault injection campaign is proposed and
utilized to investigate the efficacy of the proposed approach. The experimental
results show that the accuracy of the DNN increases by more than 300% in the
presence with Bit Error Rate of 10^(-1) in comparison to the case where ECC
technique is applied, in expense of just 47.5% area overhead.

</details>


### [569] [ATLAS: A Self-Supervised and Cross-Stage Netlist Power Model for Fine-Grained Time-Based Layout Power Analysis](https://arxiv.org/abs/2508.12433)
*Wenkai Li,Yao Lu,Wenji Fang,Jing Wang,Qijun Zhang,Zhiyao Xie*

Main category: cs.AR

TL;DR: ATLAS predicts VLSI design power from gate-level netlist with high accuracy and speed, outperforming traditional methods.


<details>
  <summary>Details</summary>
Motivation: Traditional accurate power simulation requires time-consuming back-end processing and simulation steps, which impede design optimization. Accurate power prediction is crucial for effective power optimization in VLSI design.

Method: ATLAS uses a new pre-training and fine-tuning paradigm customized for circuit power to achieve general time-based power modeling without any layout information.

Result: ATLAS achieves a mean absolute percentage error (MAPE) of 0.58% for clock tree power, 0.45% for register power, and 5.12% for combinational power. The overall MAPE for total power is less than 1%.

Conclusion: ATLAS can predict the ultimate time-based layout power for any new design in the gate-level netlist with significantly faster inference speed than standard commercial tools.

Abstract: Accurate power prediction in VLSI design is crucial for effective power
optimization, especially as designs get transformed from gate-level netlist to
layout stages. However, traditional accurate power simulation requires
time-consuming back-end processing and simulation steps, which significantly
impede design optimization. To address this, we propose ATLAS, which can
predict the ultimate time-based layout power for any new design in the
gate-level netlist. To the best of our knowledge, ATLAS is the first work that
supports both time-based power simulation and general cross-design power
modeling. It achieves such general time-based power modeling by proposing a new
pre-training and fine-tuning paradigm customized for circuit power. Targeting
golden per-cycle layout power from commercial tools, our ATLAS achieves the
mean absolute percentage error (MAPE) of only 0.58%, 0.45%, and 5.12% for the
clock tree, register, and combinational power groups, respectively, without any
layout information. Overall, the MAPE for the total power of the entire design
is <1%, and the inference speed of a workload is significantly faster than the
standard flow of commercial tools.

</details>


### [570] [MemorySim: An RTL-level, timing accurate simulator model for the Chisel ecosystem](https://arxiv.org/abs/2508.12636)
*Ansh Chaurasia*

Main category: cs.AR

TL;DR: MemorySim是一个RTL级内存模拟器，解决了现有模拟器在正确性和RTL集成方面的不足，可用于AI硬件开发。


<details>
  <summary>Details</summary>
Motivation: AI应用快速增长导致对专用AI硬件的需求增加，内存子系统成为高性能计算（如LLM）的瓶颈，现有模拟器在正确性或RTL集成方面存在不足。

Method: 本文提出MemorySim，一个RTL级内存模拟器，旨在实现精确计时和功能正确性，并能与Chisel/Chipyard生态系统集成。

Result: MemorySim可以精确地估算性能和功耗，并支持FireSim等下游评估。

Conclusion: MemorySim是一个RTL级内存模拟器，可在Chisel和Verilog模拟中实现精确计时和功能正确性，并与Chipyard生态系统兼容，可用于性能和功耗估算。

Abstract: The rapid growth of AI applications has driven increased demand for
specialized AI hardware, highlighting critical opportunities within the memory
subsystem, which often serves as a performance bottleneck in high-demand
workloads such as large language models (LLMs). Existing high-level memory
simulators, such as DRAMSim2 and DRAMSim3, offer timing simulations but
frequently compromise on correctness or integration at the register-transfer
level (RTL). We present MemorySim, an RTL-level memory simulator designed to
deliver both accurate timing and functional correctness. MemorySim integrates
seamlessly with existing Chisel and Verilog simulations and is fully compatible
with the Chisel/Chipyard ecosystem. This enables users to obtain precise
performance and power estimates, supporting downstream evaluation through
simulation platforms such as FireSim.

</details>


### [571] [XR-NPE: High-Throughput Mixed-precision SIMD Neural Processing Engine for Extended Reality Perception Workloads](https://arxiv.org/abs/2508.13049)
*Tejas Chaudhari,Akarsh J.,Tanushree Dewangan,Mukul Lokhande,Santosh Kumar Vishvakarma*

Main category: cs.AR

TL;DR: XR-NPE 是一种用于 XR 设备的高效混合精度神经处理引擎，支持多种低精度格式，并通过 RMMEC 和量化感知训练优化性能和功耗，在面积、功耗和效率方面优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 为扩展现实 (XR) 感知工作负载（如视觉惯性里程计 (VIO)、物体分类和眼动追踪）设计一种高吞吐量的混合精度 SIMD 神经处理引擎，以应对资源受限的 XR 设备的需求。

Method: 提出了一种名为 XR-NPE 的高吞吐量混合精度 SIMD 神经处理引擎，该引擎支持 FP4、Posit (4,1)、Posit (8,0) 和 Posit (16,1) 格式，并采用层自适应混合算法实现，支持超低比特精度以减少内存带宽需求，并结合量化感知训练以最小化精度损失。其重构尾数乘法和指数处理电路 (RMMEC) 通过选择性功率门控减少了 SIMD MAC 计算引擎中的暗硅，实现了 2.85 倍的算术强度提升。

Result: XR-NPE 在 CMOS 28nm 工艺下实现了 1.72 GHz 的最高工作频率，面积 0.016 mm²，算术强度 14 pJ，相比现有的 MAC 方法，面积减少 42%，功耗降低 38%。基于 XR-NPE 的协处理器在 VCU129 上功耗效率提升 1.2 倍，LUT 数量减少 1.4 倍，FF 数量减少 1.77 倍。对于 VIO 工作负载，功耗效率提升 23%，计算密度提高 4%。

Conclusion: XR-NPE 作为一个可扩展、精度自适应的计算引擎，适用于未来资源受限的 XR 设备。

Abstract: This work proposes XR-NPE, a high-throughput Mixed-precision SIMD Neural
Processing Engine, designed for extended reality (XR) perception workloads like
visual inertial odometry (VIO), object classification, and eye gaze extraction.
XR-NPE is first to support FP4, Posit (4,1), Posit (8,0), and Posit (16,1)
formats, with layer adaptive hybrid-algorithmic implementation supporting
ultra-low bit precision to significantly reduce memory bandwidth requirements,
and accompanied by quantization-aware training for minimal accuracy loss. The
proposed Reconfigurable Mantissa Multiplication and Exponent processing
Circuitry (RMMEC) reduces dark silicon in the SIMD MAC compute engine, assisted
by selective power gating to reduce energy consumption, providing 2.85x
improved arithmetic intensity. XR-NPE achieves a maximum operating frequency of
1.72 GHz, area 0.016 mm2 , and arithmetic intensity 14 pJ at CMOS 28nm,
reducing 42% area, 38% power compared to the best of state-of-the-art MAC
approaches. The proposed XR-NPE based AXI-enabled Matrix-multiplication
co-processor consumes 1.4x fewer LUTs, 1.77x fewer FFs, and provides 1.2x
better energy efficiency compared to SoTA accelerators on VCU129. The proposed
co-processor provides 23% better energy efficiency and 4% better compute
density for VIO workloads. XR-NPE establishes itself as a scalable,
precision-adaptive compute engine for future resource-constrained XR devices.
The complete set for codes for results reproducibility are released publicly,
enabling designers and researchers to readily adopt and build upon them.
https://github.com/mukullokhande99/XR-NPE.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [572] [Andreev crystals in hybrid Josephson junction arrays](https://arxiv.org/abs/2508.11768)
*Anders Enevold Dahl,Andrea Maiani,Max Geier,Javad Shabani,Karsten Flensberg*

Main category: cond-mat.mes-hall

TL;DR: 安德烈夫晶体是一种新型滤波器，可实现定向信号传输。


<details>
  <summary>Details</summary>
Motivation: 当超导体的长度与超导相干长度相当时，安德烈夫的边界态在相反的边缘会通过准粒子隧穿发生杂化，形成一个低于超导能隙的能带。

Method: 推导了这些安德烈夫晶体的输运性质的理论框架。

Result: 在高的界面透明度和邻近超导体恒定相位偏压下，这些能带是定向的：一个能带仅由右移电子态组成，另一个能带仅由左移电子态组成。

Conclusion: 该装置可用作通量和偏置电压可调的滤波器，仅允许单向信号传输。

Abstract: Andreev bound states are superpositions of electrons and holes in a metal
that form by coherent reflection from a superconductor. When the length of the
superconductor is comparable to the superconducting coherence length, Andreev
bound states at opposite edges hybridize by quasiparticle tunneling. In a
periodic array, these hybridized bound states form a band at energies below the
superconducting gap. In this paper, we derive a theoretical framework for the
transport properties of these Andreev crystals. We demonstrate that at high
interface transparency and constant phase bias between neighboring
superconductors, these bands are {\it directional}: one band consists only of
right -- while the other only of left-moving electronic states. This property
enables the application of this device as a flux- and bias-voltage tunable
filter that permits signal transmission in only one direction.

</details>


### [573] [Voltage-tunable field-free Josephson diode](https://arxiv.org/abs/2508.12056)
*Sjoerd Telkamp,Junting Zhao,Saulius Vaitiekėnas*

Main category: cond-mat.mes-hall

TL;DR: 本研究成功制备了一种新型的约瑟夫森二极管，它可以通过电压进行调控，并且能在零磁场下工作。该器件基于特殊的纳米线结构，有望在未来的电子学领域得到应用。


<details>
  <summary>Details</summary>
Motivation: 研究的动机在于探索和实现一种新型的约瑟夫森二极管，该二极管具有电压控制的特性，并且能够在零磁场下工作，这对于未来的电子学应用具有重要意义。

Method: 本文通过实验合成了包含自旋-轨道的半导体核心以及外延铁磁绝缘体和超导体壳的混合纳米线结，并测量了其在不同栅电压和轴向磁场下的电学特性，以验证约瑟夫森二极管效应及其门控可调性。

Result: 实验结果表明，该混合纳米线结确实表现出门控可调的约瑟夫森二极管效应，并且在零磁场下也能够工作，证明了其在电子学应用中的潜力。

Conclusion: 该研究报告了一种由自旋-轨道耦合的半导体核心以及外延铁磁绝缘体和超导体壳组成的混合纳米线结，其中实现了门控可调的约瑟夫森二极管效应。该器件在轴向磁场下表现出滞后的超导窗口。在超导状态下，器件显示出非互易的超电流传输，二极管效率对背栅电压表现出强烈的依赖性。在经过控制的退磁程序后，该效应在剩余磁化状态下依然存在，实现了零场操作。这些发现展示了一种单结电压控制的约瑟夫森二极管，并为探索混合材料中内禀的破缺反演和时间反转对称性提供了途径。

Abstract: We report a gate-tunable Josephson diode effect in hybrid nanowire junctions
consisting of a spin-orbit-coupled semiconductor core coated with epitaxial
ferromagnetic insulator and superconductor shells. The wires display a
hysteretic superconducting window as a function of axial magnetic field. In the
superconducting regime, the devices exhibit nonreciprocal supercurrent
transport, with the diode efficiency showing a strong dependence on back-gate
voltage. The effect persists in a remanent magnetization state following a
controlled demagnetization procedure, establishing zero-field operation. These
findings demonstrate a voltage-controlled Josephson diode in a single junction
and suggest a route toward probing intrinsically broken inversion and
time-reversal symmetries in hybrid materials.

</details>


### [574] [High-root topological edge-state bands](https://arxiv.org/abs/2508.12066)
*R. G. Dias,L. Madail,A. M. Marques*

Main category: cond-mat.mes-hall

TL;DR: 本文研究了一维拓扑绝缘体的边缘态，发现 HRTI 的边缘态是均匀链杂质带的切片，并提出了一种无需对角化即可确定边缘态能级的方法。


<details>
  <summary>Details</summary>
Motivation: 探究 HRTI 的拓扑特性，特别是其边缘态的性质以及与杂质系统和边界条件的关系。

Method: 对一维（1D）方形和高阶根拓扑绝缘体（HRTI）进行了复杂的带分析，并将 HRTI 的边缘态带视为均匀紧束缚链的杂质带的切片。

Result: HRTI 的边缘态带是均匀紧束缚链的杂质带的切片。HRTI 的边缘态是无限系统倏逝态的子集，可以映射到具有有效能量相关边缘势的均匀链的杂质态。ítható确定边缘态能级。

Conclusion: 基于边缘态带的存在和边界条件施加的限制，对具有广义边界条件的 HRTI 进行了简化的拓扑表征。HRTI 中的边缘态可以映射到具有有效能量相关边缘势的均匀链的杂质态，从而无需对实空间或体哈密顿量进行对角化即可确定边缘态能级。

Abstract: This paper presents a complex band analysis of one-dimensional (1D) square
and high-root topological insulators (HRTIs). We show that edge-state bands of
HRTIs are sliced sections of impurity bands of a uniform tight-binding chain. A
simplified topological characterization of HRTIs with generalized boundary
conditions is carried out based on the existence of edge-state bands in the
infinite HRTI and the restrictions imposed by the boundary conditions. Edge
states in finite or semi-infinite 1D HRTIs are shown to be a subset of
evanescent states of the infinite system and mapped onto impurity states of the
uniform chain with effective energy-dependent edge potentials. The latter
result allows the determination of the edge state levels without needing the
diagonalization of real space or bulk Hamiltonians.

</details>


### [575] [Diode Effect for Skyrmions Interacting with Linear Protrusion Defects](https://arxiv.org/abs/2508.12090)
*J. C. Bellizotti Souza,C. J. O. Reichhardt,C. Reichhardt,N. P. Vizarim,P. A. Venegas*

Main category: cond-mat.mes-hall

TL;DR: 模拟发现斯格明子在周期性不对称通道中表现出强的二极管效应，且受马格努斯力影响。


<details>
  <summary>Details</summary>
Motivation: 研究斯格明子在不对称环境中的集体运动行为，特别是二极管效应和湮灭率的不对称性，以期控制和利用斯格明子。

Method: 通过模拟周期性不对称通道中的集体相互作用的斯格明子流，研究斯格明子在不对称环境中的运动和湮灭行为。

Result: 发现了强的二极管效应，斯格明子流沿难向湮灭率更高，并绘制了二极管效率与磁场和衬底不对称角度的函数关系图。

Conclusion: 1. 模拟了周期性不对称通道中的集体相互作用的斯格明子流，发现了强的二极管效应。
2. 发现斯格明子流沿衬底不对称的难易方向施加电流时，斯格明子湮灭率存在不对称性，难向湮灭率更高。
3. 绘制了二极管效率与磁场和衬底不对称角度的函数关系图。
4. 证明了马格努斯力通过迫使斯格明子进入突出几何形状的角落，影响二极管运动和湮灭率的不对称性。

Abstract: We simulate collectively interacting skyrmions in a channel with periodic
asymmetry, and find a strong diode effect for the skyrmion flow. There is also
an asymmetry in the skyrmion annihilation rate for currents applied along the
hard or easy substrate asymmetry direction, with a higher annihilation rate for
hard direction currents. We map out the diode efficiency as a function of
magnetic field and substrate asymmetry angle. We also show that the Magnus
force impacts the diode motion and annihilation rate asymmetry by forcing
skyrmions into corners of the protrusion geometry.

</details>


### [576] [Quantized nonlinear kink movement through topological boundary state instabilities](https://arxiv.org/abs/2508.12101)
*Markus Bestler,Oded Zilberberg*

Main category: cond-mat.mes-hall

TL;DR: Thouless 泵浦的非线性推广。我们提出了一个非线性二聚体链模型，当泵浦参数周期性调制时，会出现 the kink 的量子输运。该模型展示了拓扑保护的定向输运，但无法用传统的拓扑指标完全捕捉，更像是一种拓扑棘轮。此外，通过引入多个泵浦参数，可以实现对多个 the kink 轨迹和孤子运动的精细控制，这在信息传输方面具有潜在应用。本研究将线性拓扑和非线性动力学概念结合起来，为非线性介质中的量子输运建立了框架。


<details>
  <summary>Details</summary>
Motivation: 扩展了 Thouless 泵浦的理论框架，研究了非线性泵浦中线性拓扑的常规框架的必要性，并提出了一种新的非线性量子输运模型。

Method: 利用非线性动力学方法研究非线性二聚体链模型，分析边界模式的不稳定性如何驱动 the kink 运动，并证明了该模型无法完全用传统的拓扑指标捕捉。

Result: 开发了一个非线性二聚体链模型，该模型能够实现拓扑保护的定向输运，并且可以通过引入多个泵浦参数来精确控制多个 the kink 轨迹和孤子运动。

Conclusion: 本研究提出的非线性泵浦模型通过非线性动力学机制实现了拓扑量子输运，并展示了其在信息传输方面的应用潜力，为非线性介质中的量子输运提供了新的理论框架。

Abstract: Thouless pumping is a paradigmatic example of topologically protected,
directed transport in linear systems. Recent extensions to nonlinear pumps
often overlook the need to reassess the conventional framework of linear
topology. In this work, we study a nonlinear dimer-chain model that exhibits
quantized transport of kinks under a periodic modulation of a pumping
parameter. Crucially, linear excitations in the system map to a Rice-Mele model
and display topological boundary modes localized at these kinks. Using methods
from nonlinear dynamics, we show that instabilities in these boundary modes are
the driving mechanism behind the observed kink motion. While the transport
resembles that of a linear Thouless pump, it cannot be fully captured by
conventional topological indices. Instead, the behavior is more akin to a
topological ratchet: robust, directional, and reproducible, yet fundamentally
nonlinear. Furthermore, by introducing multiple pumping parameters, we
demonstrate fine control over multiple kink trajectories, as well as soliton
motion, suggesting applications in information transport. Our results unify
concepts from linear topology and nonlinear dynamics to establish a framework
for quantized transport in nonlinear media.

</details>


### [577] [Novel SuperLattice Plasmon Mode in a Grating of 2D Electron Strips](https://arxiv.org/abs/2508.12182)
*V. M. Muravev,K. R. Dzhikirba,A. A. Zabolotnykh,A. Shuvaev,M. S. Ryzhkov,D. A. Khudaiberdiev,A. S. Astrakhantseva,I. V. Kukushkin,A. Pimenov*

Main category: cond-mat.mes-hall

TL;DR: GaAs/AlGaAs异质结膜超表面的研究揭示了一种新的等离激元模式，并提供了分析方法。


<details>
  <summary>Details</summary>
Motivation: 研究GaAs/AlGaAs异质结膜的超表面，揭示其在透射率中的强等离子体共振现象，并探究其背后的物理机制。

Method: 开发了一种分析方法来精确描述新发现的超晶格等离激元模式。

Result: 发现了由超晶格的集体效应和条带间的横向屏蔽引起的新的等离激元模式。

Conclusion: 发现了一种新的超表面等离激元模式，并通过分析方法对其行为进行了精确描述，为等离激元超表面系统提供了新的物理见解。

Abstract: We investigate GaAs/AlGaAs heterostructure membranes with a metasurface made
up of a grating of two-dimensional electron system (2DES) strips. Experiments
have revealed a strong plasma resonance in the transmission of the metasurface.
We have found that a collective effect from the superlattice, along with
lateral screening between the strips, leads to the emergence of a new plasmon
mode in the metasurface under study. Furthermore, we develop an analytical
approach that accurately describes the behavior of the discovered superlattice
plasmon mode, providing new insights into the fundamental physics of plasmonic
metasurface systems.

</details>


### [578] [Atom-surface interaction induced by quenched monopolar charge disorder](https://arxiv.org/abs/2508.12280)
*Bing-Sui Lu*

Main category: cond-mat.mes-hall

TL;DR: 该研究探讨了电荷无序对原子能级的影响，发现它会导致能级向下移动，并可能抵消Casimir-Polder力。能级移动的强度与距离和电荷无序方差有关，并且在双 slab 结构中，它会受到 slab 表面电荷无序方差的影响。


<details>
  <summary>Details</summary>
Motivation: 研究原子能级位移对由相邻介电 slab 块体和表面的淬灭单极电荷无序的修改。

Method: 通过假设电荷无序遵循零均值的Гауссова统计，研究了原子能级位移对由相邻介电 slab 块体和表面的淬灭单极电荷无序的修改。

Result: 电荷无序通常导致能级向下移动，且能随原子表面距离的增大而衰减，并与电荷无序密度的方差成正比。研究了在双 slab 结构中，不同电荷无序方差的 slab 对净零无序力位置的影响。

Conclusion: 电荷无序通常会导致原子能级向下移动，并且对于足够大的原子表面距离，这种效应会抵消或超过非共振Casimir-Polder力。对于靠近单个半无限 slab 的原子，其能级移动随距离的衰减率为 $z_0^{-1}$ (对于块体电荷无序) 或 $z_0^{-2}$ (对于表面电荷无序)。能级移动与电荷无序密度的方差成正比。在双 slab 结构中，净零无序力出现的位置更靠近电荷无序方差较小的 slab 表面。

Abstract: We study the modification to the energy level shifts of an atom induced by
the quenched monopolar charge disorder inside the bulk of neighboring
dielectric slabs as well as their surfaces. By assuming that the charge
disorder follows Gaussian statistics with a zero mean, we find that the
disorder generally results in a downward shift of the energy levels, which
corresponds to an attractive force that can compete with and overcome the
nonresonant Casimir-Polder force for sufficiently large atom-surface
separations $z_0$. For an atom near a single semi-infinite slab with bulk
(surface) charge disorder, the shift decays as $z_0^{-1}$ ($z_0^{-2}$). For
both surface and bulk disorder, the shift is proportional to the variance of
the charge disorder density. In addition, we investigate the behavior of the
charge disorder-induced energy level shift for an atom confined to a vacuum gap
between two coplanar and semi-infinite slabs of the same dielectric material,
finding that the position of net zero disorder-induced force occurs closer to
the surface of the slab with the smaller charge disorder variance.

</details>


### [579] [Bulk photovoltaic effects in the Haldane model](https://arxiv.org/abs/2508.12414)
*Bo-Xin Lin,Hsiu-Chuan Hsu*

Main category: cond-mat.mes-hall

TL;DR: 二维材料的体光伏效应（BPVE）受MT对称性约束。Haldane模型中，线性偏振光可诱导移位和注入电流，圆偏振光下则消失。MT对称性导致响应分离。拓扑相变时，移位电流符号翻转。量子几何解释了BPVE的微观起源。


<details>
  <summary>Details</summary>
Motivation: 研究体光伏效应（BPVE）在二维材料中的性质，探索其与对称性及量子几何的关系，并为太阳能技术提供理论基础。

Method: 通过推导对称性约束和计算量子几何（包括贝里曲率、量子度量和厄米联络）来分析BPVE。

Result: 在Haldane模型中，证明了MT对称性对BPVE（包括移位电流和注入电流）的约束作用，并揭示了响应分离现象。观察到在拓扑相变过程中移位电流的符号翻转，并确认了布里渊区厄米联络矢量场的涡旋结构与拓扑相的关系。

Conclusion: BPVE在二维系统中的性质受镜像-时间对称性（MT对称性）的约束。对于Haldane模型，线性偏振光可以诱导移位电流和注入电流，而圆偏振光下的这些电流则会消失。MT对称性还导致了响应的分离：一个方向表现出时间反演对称性允许的响应，另一个方向则表现出宇称-时间对称性允许的响应。在拓扑相变过程中，注入电流符号不变，而移位电流符号翻转。此外，布里渊区中厄米联络的矢量场在拓扑相中具有涡旋，而在平凡相中则没有。计算相关的量子几何（贝里曲率、量子度量和厄米联络）证明了BPVE的微观量子起源。

Abstract: The bulk photovoltaic effect (BPVE) refers to the direct current generation
in a noncentrosymmetric material under illumination and can be applied to solar
energy technology. BPVE includes injection and shift currents, led by the
change of velocity and displacement of wave packet during optical transitions,
respectively. We derive the constraints on the conductivity tensors imposed by
mirror-time ($\mathcal{MT}$) symmetry for two-dimensional systems. For the
Haldane model, we show that linearly polarized light can induce shift and
injection currents, which vanish under circularly polarized light as
constrained by the three-fold rotation and $\mathcal{MT}$ symmetry.
Additionally, due to the presence of $\mathcal{MT}$ symmetry, a separation of
responses is observed in the Haldane model: one direction exhibits a
time-reversal symmetry-allowed response, whereas another manifests a
parity-time symmetry-allowed response. Across the topological phase transition,
the injection current does not change sign, whereas shift current shows a sign
flip. The vector field of the Hermitian connection in the Brillouin zone
possesses vortices in the topological phase, but not in the trivial phase.
Furthermore, we calculate the related quantum geometry, including Berry
curvature, quantum metric and Hermitian connection, and demonstrate the
microscopic quantum origin of the BPVE.

</details>


### [580] [Fabry-Perot interference in three dimensional second-order topological insulator constrictions](https://arxiv.org/abs/2508.12655)
*Junyu Luo,Kun Luo*

Main category: cond-mat.mes-hall

TL;DR: 三维第二类拓扑绝缘体（SOTI）的无缝手征铰链态在约束中表现出法布里-珀罗振荡，磁场会影响该振荡，结果对无序具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 研究三维第二类拓扑绝缘体（SOTI）的无缝手征铰链态，及其在厚纳米线上的量子化电导平台。

Method: 对SOTI（三维第二类拓扑绝缘体）约束的电导进行数值研究。

Result: 有限尺寸效应对窄区域的铰链态产生杂化，在约束两端引起反射，导致电导出现法布里-珀罗振荡。磁场通过使电子局域化在两个铰链上来影响法布里-珀罗干涉，表现出维度效应。

Conclusion: 研究结果对中等强度的无序具有鲁棒性，预期可在实验中观察到法布里-珀罗图案。

Abstract: The gapless chiral hinge states of three dimensional second-order topological
insulators (SOTIs) support a quantized conductance plateau on thick nanowire.
Here, we numerical study the conductance of SOTI constrictions. According to
finite size effects, the hinge states in narrow region could be hybridized,
which will induce reflection at the two ends of constrictions. The conductance
exists the Fabry-Perot oscillation pattern because of multiple reflections. We
also study the impact of the magnetic field on the Fabry-Perot interference. We
show the dimensional effect that the magnetic field leads to the electrons
being localized on two hinges. Our results are robust against moderate disorder
so that we expect these Fabry-Perot patterns could be observed in experiments.

</details>


### [581] [Waveguiding in two-dimensional Floquet non-Abelian topological insulators](https://arxiv.org/abs/2508.12678)
*Yujie Zhou,Changsen Li,Xiumei Wang,Xingping Zhou*

Main category: cond-mat.mes-hall

TL;DR: 在非阿贝尔电荷的背景下，研究了Floquet高阶拓扑相位，并构建了一个二维模型，在其中发现了角态和边态，并证明了非阿贝尔动力学。


<details>
  <summary>Details</summary>
Motivation: 尽管在单粒子水平上已经探索了Floquet（周期驱动）高阶拓扑相位，但相互作用在具有多个纠缠能隙的非阿贝尔拓扑绝缘体中的作用尚不完全清楚。

Method: 通过Floquet工程构建了一个二维非阿贝尔高阶拓扑相位模型，该模型是在方形格格上进行两步周期驱动。

Result: 在非阿贝尔电荷（四元数电荷）的背景下，研究了Floquet高阶拓扑相位。发现在所有能隙中会出现角态和边态，并且空间交换驱动会产生非阿贝尔动力学的特征——非对易性。非零的复合陈数证明了Floquet非阿贝尔系统的非平凡性。四元数电荷边态的构型完全由时间演化中的四重简并的相位-能带奇异点决定。

Conclusion: 该工作为研究高阶拓扑态和非平衡量子动力学提供了一个平台。

Abstract: Topological phases characterized by non-Abelian charges have garnered
increasing attention recently. Although Floquet (periodic-driving) higher-order
topological phases have been explored at the single-particle level, the role of
interactions in non-Abelian topological insulators with multiple entangled
energy gaps remains incompletely understood. In this work, we extend previous
research by investigating higher-order topological phases featuring non-Abelian
charges through Floquet engineering. Here we construct a model for
two-dimensional non-Abelian higher-order topological phases on a square lattice
subjected to two-step periodic driving. We find that the corner and edge states
emerge and appear in all energy gaps despite the quaternion charge being
trivial. Moreover, spatially exchanging the driving generates exotic interface
modes-a hallmark of non-Abelian dynamics, namely non-commutativity. Notably,
the non-zero composite Chern number demonstrates the non-triviality of the
Floquet non-Abelian system with. We further reveal that the configuration of
these quaternion-charge edge states is entirely determined by the quadruple
degenerate phase-band singularities in the time evolution. Our work provides a
platform for studying higher-order topological states and non-equilibrium
quantum dynamics.

</details>


### [582] [Fermi velocity and magic angle renormalization in twisted bilayer graphene](https://arxiv.org/abs/2508.12825)
*Miguel Sánchez Sánchez,José González,Tobias Stauber*

Main category: cond-mat.mes-hall

TL;DR: 研究了扭转双层石墨烯中的费米速度重整化，发现库仑交换相互作用会增加费米速度和能带宽度，并解释了临界温度随扭转角的变化。


<details>
  <summary>Details</summary>
Motivation: 研究扭转双层石墨烯中费米速度重整化现象及其对材料性质的影响。

Method: 采用了原子尺度紧束缚模型和Slater-Koster参数化方法，并考虑了平面外跳跃项的重整化。

Result: 发现费米速度随扭转角的变化以及库仑交换相互作用对平坦能带宽度的影响。此外，还确定了与最大Tc相关的最佳扭转角，并基于不同扭转角范围的相变机制（BCS和BKT）来解释临界温度。

Conclusion: 讨论了费米速度重整化，特别是其在扭转双层石墨烯中由于库仑交换相互作用而引起的变化。研究结果为临界温度（Tc）与扭转角的关系提供了微观解释，并指出了最大Tc出现在1.1°附近。

Abstract: We discuss the Fermi-velocity renormalization in twisted bilayer graphene due
to Coulomb exchange interaction within an atomistic tight-binding model.
Adopting the Slater-Koster parametrization for the hopping parameters obtained
from first principles, our results only depend on the effective dielectric
constant $\epsilon$ and the Hubbard-interaction $U$. The Fermi velocity of
graphene increases twist-angle independent by $~25\%$ for $\epsilon=10$ and
$U=4eV$, leading to an increase by more than $100\%$ of the flat bandwidth at
twist-angle $\theta=1.4^\circ$. Including also the renormalization of the
out-of-plane hopping terms, we further observe a shift of the magic angle from
$1.02^\circ$ to $0.96^\circ$. Our results offer a microscopic explanation of
the critical temperature, $T_c$, as function of the twist angle where the
largest $T_c$ is found at $\theta_{max}=1.1^\circ$. For $\theta>\theta_{max}$,
$T_c$ is obtained from the Bethe-Salpeter equation of the Cooper channel. For
$\theta<\theta_{max}$, the discussion is based on the critical line of the
Berezinskii-Kosterlitz-Thouless phase transition.

</details>


### [583] [Edge-state competition in a 2D topological insulator-semiconductor heterostructure](https://arxiv.org/abs/2508.12841)
*Wei Li,Pier Philipsen,Thomas Brumme,Thomas Heine*

Main category: cond-mat.mes-hall

TL;DR: 研究了 1T'/2H WSe2 异质结构中的量子自旋霍尔边缘传输。研究发现 1T' 条带中的边缘态对于 2H 衬底是鲁棒的，但终止的 2H 边缘会产生平凡的色散分支。通过控制扭转角和避免终止的 2H 边缘，可以实现量子电导。


<details>
  <summary>Details</summary>
Motivation: 研究二维过渡金属二卤化物中的量子自旋霍尔边缘传输，重点关注其一维边缘通道在实际衬底和器件边界下的保持情况。

Method: 在 Amsterdam Modeling Suite 中，在 DFTB 和 GFN-xTB 中实现了自旋-轨道耦合，并将其应用于 1T'/2H WSe2 异质结构。

Result: 1T' 条带中存在鲁棒的边缘态，并且这些状态对于仅通过长波起伏移动狄拉克点而不引入额外带隙态的横向无限 2H 衬底是鲁棒的。相比之下，终止的 2H 边缘会在相同的能量窗口中产生平凡的色散分支，而与拓扑边缘模式的杂化很弱。在体相中，费米能级态源于 1T'；在小扭转角下，晶格弛豫引起的应变会驱动子带重构，而在大扭转角下，层会解耦。

Conclusion: 在控制扭转角和避免终止的 2H 边缘的条件下，可以实现量子电导和明确的光谱学。

Abstract: Quantum spin Hall edge transport in two-dimensional transition-metal
dichalcogenides depends on whether their one-dimensional edge channels are
preserved under realistic substrates and device boundaries. Here we implement
spin-orbit coupling in DFTB and GFN-xTB within the Amsterdam Modeling Suite,
and apply it to 1T$'$/2H WSe$_2$ heterostructures. Edge-projected spectra
reveal robust edge states in 1T$'$ ribbons; and these states remain robust
against a laterally infinite 2H substrate, which only shifts the Dirac point
via long-wavelength corrugation without introducing additional in-gap states.
By contrast, terminated 2H edges generate trivial dispersion branches in the
same energy window that hybridize only weakly with the topological edge modes.
In the bulk, Fermi-level states are 1T$'$-derived; at the small twist angle,
lattice-relaxation-induced strain drives miniband reconstruction, whereas at
the large twist angle, the layers become electronically decoupled. These
findings suggest the conditions -- controlled twist angle and avoidance of
terminated 2H edges -- for achieving quantized conductance and unambiguous
spectroscopic

</details>


### [584] [Theoretical Investigation of Performance-Improved Ferroelectric Tunnel Junction Based on Trap-Assisted Tunneling](https://arxiv.org/abs/2508.12879)
*Shi-Xi Kong,Tuo-Hung Hou*

Main category: cond-mat.mes-hall

TL;DR: CMOS兼容的HfO2基铁电隧穿结（FTJ）是内存计算（IMC）的有希望的候选者，但传统FTJ存在电流密度不足和开关比受限的问题。本研究提出了一种基于陷阱辅助隧穿（TAT）的FTJ，通过整合FTJ模型并优化陷阱参数，实现了超高电流密度和开关比，满足IMC要求。


<details>
  <summary>Details</summary>
Motivation: 传统铁电隧穿结（FTJ）由于依赖直接隧穿（DT）和福勒-诺德海姆（FN）隧穿机制，存在电流密度（JON）不足和开关比有限的问题，阻碍了其在内存计算（IMC）中的实际应用。本研究旨在通过引入陷阱辅助隧穿（TAT）机制来克服这些限制。

Method: 开发了一个整合了铁电（FE）开关、直接隧穿（DT）、福勒-诺德海姆（FN）隧穿和陷阱辅助隧穿（TAT）机制的综合FTJ模型，用于详细分析陷阱条件及其对性能的影响。

Result: 所提出的TAT基FTJ实现了超高电流密度（JON）和显著的开/关电流比，满足了纳米级IMC的要求。

Conclusion: 基于陷阱辅助隧穿（TAT）的铁电隧穿结（FTJ）通过优化陷阱参数和器件结构，实现了超高电流密度和优异的开关比，满足纳米级内存计算（IMC）的要求，展现了其作为高性能IMC内存解决方案的潜力。

Abstract: CMOS-compatible HfO2-based ferroelectric tunnel junction (FTJ) has attracted
significant attention as a promising candidate for in-memory computing (IMC)
due to its extremely low power consumption. However, conventional FTJs face
inherent challenges and hinder their practical applications. Insufficient
current density (JON) and limited on-off current ratios in FTJs are primarily
constrained by their dependence on direct tunneling (DT) and Fowler-Nordheim
(FN) tunneling mechanisms. Building on previous experimental results, this
paper proposes a trap-assisted tunneling (TAT)-based FTJ that leverages the TAT
mechanism to overcome these limitations. A comprehensive FTJ model integrating
ferroelectric (FE) switching, DT, FN tunneling, and TAT mechanisms is
developed, enabling detailed analyses of the trap conditions and their impact
on performance. Through systematic optimization of trap parameters and device
structure, the TAT-based FTJ achieves ultra-high JON and a remarkable on-off
current ratio, meeting the nanoscale IMC requirements. The results highlight
the potential of TAT-based FTJs as high-performance memory solutions for IMC
applications.

</details>


### [585] [Frequency Domain Berry Curvature Effect on Time Refraction](https://arxiv.org/abs/2508.12893)
*Shiyue Deng,Yang Gao,Qian Niu*

Main category: cond-mat.mes-hall

TL;DR: 光子在色散光学系统中具有频域贝里曲率，会导致时间折射效应。


<details>
  <summary>Details</summary>
Motivation: 研究光子在色散光学系统中的贝里曲率特性，以及它对光子轨迹的影响。

Method: 我们研究了色散光学系统中光子波函数中的频域贝里曲率，并将其应用于磁等离激元-极化子的时间折射。

Result: 发现了频域贝里曲率，并证明了它在磁等离激元-极化子的时间折射中引起的偏转效应。

Conclusion: 我们证明了在色散光学系统中，光子的波函数中存在频域贝里曲率。这种性质源于其介电函数的频率色散，这使得麦克斯韦方程成为一个非标准的特征值方程，其中特征值（频率）本身出现在算子内部。我们以磁等离激元-极化子的时间折射为例，研究了这种新的贝里曲率效应。它可以引起光子轨迹的偏转，使光线摆动。

Abstract: We demonstrate that there exist frequency domain Berry curvature in the wave
function of photons in dispersive optical systems. This property arises from
the frequency dispersion of its dielectric function, which makes Maxwell
equations a non-standard eigenvalue equation, with the eigenvalue (frequency)
appearing inside the operator itself. We study this new Berry curvature effect
on time refraction of magnetoplasmon-polariton as an example. It can induce
deflection in the trajectory of a photon and make the ray swing.

</details>


### [586] [Observation of Altermagnetic Spin Splitting in an Intercalated Transition Metal Dichalcogenide](https://arxiv.org/abs/2508.12985)
*Milo Sprague,Mazharul Islam Mondal,Anup Pradhan Sakhya,Resham Babu Regmi,Surasree Sadhukhan,Arun K. Kumay,Himanshu Sheokand,Igor I. Mazin,Nirmal J. Ghimire,Madhab Neupane*

Main category: cond-mat.mes-hall

TL;DR: 本研究利用ARPES和DFT技术，确定Co1/4TaSe2是一种具有高Néel温度（178 K）的层状反常磁材料，并观察到其独特的自旋分裂和温度依赖的电子结构变化。


<details>
  <summary>Details</summary>
Motivation: 尽管理论界对反常磁材料的兴趣日益增长，但实验上已验证的高Néel温度层状化合物的报道有限。本研究旨在寻找并验证一种具有高Néel温度的层状反常磁材料。

Method: 通过角分辨光电子能谱（ARPES）和密度泛函理论（DFT）研究了Co1/4TaSe2的性质。同时结合了磁化率测量来确认其磁序和Néel温度。

Result: Co1/4TaSe2被确认为一种层状反常磁材料，其Néel温度为178 K。ARPES测量结果与DFT计算结果高度一致，并显示出费米面上的反常自旋分裂。温度相关的ARPES测量揭示了价带结构的重构，表现为导带移动和能量隙的闭合，这与反常磁有序在Néel温度之上的抑制现象一致。

Conclusion: Co1/4TaSe2被确定为一种有潜力的层状反常磁材料，其Néel温度为178 K。ARPES和DFT研究揭示了其费米面上的反常自旋分裂，并且在高于Néel温度时，其价带结构会发生重构，能量隙闭合，这与反常磁序的抑制一致。

Abstract: Altermagnetism is a novel magnetic phase combining characteristics of both
antiferromagnetism and ferromagnetic ordering. Despite growing theoretical
interest in altermagnetic materials, reports of experimentally verified high
Neel temperature layered compounds are limited or remain to be firmly
established. Here, we present an angle resolved photoemission spectroscopy
(ARPES) and density functional theory (DFT) study of Co1/4TaSe2, a compound we
identify as a layered altermagnetic material. Magnetic susceptibility
measurements confirm type A antiferromagnetic ordering with a Neel temperature
of 178 K. Our ARPES measurements reveal an electronic band structure in
excellent agreement with DFT calculations, demonstrating clear signatures of
altermagnetic spin splitting at the Fermi surface. Furthermore, temperature
dependent ARPES reveals a reconstructed valence band structure, with observable
band shifts and the closing of energy gaps upon heating above the Neel
temperature (TN), consistent with the suppression of altermagnetic order. These
findings establish Co1/4TaSe2 as a promising platform for exploring
altermagnetic phenomena.

</details>


### [587] [Skyrmion Lattice Domain Formation in a Non-Flat Energy Landscape](https://arxiv.org/abs/2508.12988)
*Raphael Gruber,Jan Rothörl,Simon M. Fröhlich,Maarten A. Brems,Tobias Sparmann,Fabian Kammerbauer,Maria-Andromachi Syskaki,Elizabeth M. Jefremovas,Sachin Krishnia,Asle Sudbø,Peter Virnau,Mathias Kläui*

Main category: cond-mat.mes-hall

TL;DR: 本研究利用磁场振荡来控制磁斯格明子晶格的顺序，克服了钉扎效应的限制，为开发新型数据存储和处理设备提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 磁斯格明子作为信息载体在数据存储和处理设备中展现出巨大潜力。然而，在实验中，薄膜中准长程有序的主要限制因素是能量场的不平整性（即钉扎效应）。因此，本研究旨在探索一种有效的方法来控制和研究这种斯格明子晶格的特性。

Method: 本研究结合了Kerr显微镜实验和布朗动力学模拟，通过量化晶格顺序和动力学来研究磁场振荡如何影响斯格明子晶格的能量场和畴壁的形成与演变。

Result: 本研究成功展示了通过磁场振荡来调整能量场，从而直接控制斯格明子晶格顺序的方法。研究量化了晶格顺序和动力学，揭示了钉扎效应对畴壁形成和演变的影响。

Conclusion: 通过有效地利用磁场振荡来调整能量场，从而实现了对斯格明子晶格顺序的直接控制。本研究通过量化晶格顺序和动力学，深入探讨了由于钉扎效应导致畴壁形成和演变的过程，为控制和研究新兴的斯格明子晶格特性以及二维相行为提供了新的途径。

Abstract: Magnetic skyrmions are chiral spin structures with non-trivial topology that
comprise two-dimensional quasi-particles and are promising information carriers
for data storage and processing devices. Skyrmion lattices in magnetic thin
films exhibit Kosterlitz-Thouless-Halperin-Nelson-Young (KTHNY) phase
transitions and have garnered significant interest for studying emergent 2D
phase behavior. In experimental skyrmion lattices, the main factor limiting the
quasi-long-range order in thin films has been the non-flat energy landscape -
often referred to as pinning effects. We demonstrate direct control of the
skyrmion lattice order by effectively tuning the energy landscape employing
magnetic field oscillations. By quantifying lattice order and dynamics, we
explore how domain boundaries form and evolve due to pinning effects in Kerr
microscopy experiments and in Brownian dynamics simulations, offering a pathway
to control and study emergent skyrmion lattice properties and 2D phase
behavior.

</details>


### [588] [Macroscopic coherence and vorticity in room-temperature polariton condensate confined in a self-assembled perovskite microcavity](https://arxiv.org/abs/2508.13042)
*Martin Montagnac,Yesenia A. García Jomaso,Emiliano Robledo Ibarra,Rodrigo Sánchez-Martínez,Moroni Santiago García,César L. Ordóñez-Romero,Hugo A. Lara-García,Arturo Camacho-Guardian,Giuseppe Pirruccio*

Main category: cond-mat.mes-hall

TL;DR: 在室温下，利用 CsPbBr$_3$ 微晶片实现了极化激子凝聚，该微晶片具有固有的无序性，可以调控光学约束，并允许研究凝聚态的波函数、相干性和涡旋现象。


<details>
  <summary>Details</summary>
Motivation: 在室温下实现激子-极化激子玻色-爱因斯坦凝聚，为在环境条件下运行的量子光子学技术提供了一条有前景的途径，并解决了强限制、非线性相互作用和结构无序共存的挑战。

Method: 通过使用自组装成具有良好调谐的腔模的CsPbBr3微晶片，实现了极化激子-激子复合凝聚。

Result: 在CsPbBr3微晶片中实现了极化激子凝聚，表现出典型的非平衡凝聚特征，如发射强度的非线性增加、光谱变窄和相互作用引起的蓝移。结果还显示了由无序势固定的量化涡旋的存在，并揭示了扩展的相位相干性。

Conclusion: 这项工作在室温下建立了用于研究驱动耗散光量子流的, 可扩展的平台，其中内在的无序平衡了光学约束，并提供了对凝聚态波函数、相干性和涡旋现象的窗口。

Abstract: Exciton-polariton Bose-Einstein condensation at room temperature offers a
promising pathway toward quantum photonic technologies that can operate under
ambient conditions. A key challenge in this field is to engineer a controlled
platform where strong confinement, nonlinear interactions, and structural
disorder coexist, unlocking access to rich collective behavior and
unconventional condensate dynamics. We demonstrate polariton condensation in
CsPbBr$_3$ microplatelets that self-assemble into whispering gallery mode
microresonators featuring tight lateral photon confinement finely balanced with
intrinsic disorder. The system exhibits hallmark signatures of
out-of-equilibrium condensation, including a non-linear increase in emission
intensity, spectral narrowing, and interaction-induced blueshift. Intrinsic
disorder subtly reshapes the cavity energy landscape, inducing condensate
fragmentation and enabling direct optical access to the condensate
wavefunction. Interferometric measurements reveal extended phase coherence,
whereas characteristic fork-shaped fringe dislocations confirm the presence of
quantized vortices pinned by the disordered potential. These topological
excitations underscore the rich physics driven by the interplay of gain, loss,
confinement, and disorder. Our work establishes a scalable platform for
investigating driven-dissipative quantum fluids of light at room temperature,
where the intrinsic disorder balances optical confinement and provides a window
into condensate wavefunction, coherence, and vortex phenomena. This study
system opens new opportunities for exploring many-body physics and potentially
advancing topological photonics in integrable microcavity architectures.

</details>


### [589] [Noise signatures of a charged Sachdev-Ye-Kitaev dot in mesoscopic transport](https://arxiv.org/abs/2508.13098)
*Andrei I. Pavlov,Mikhail N. Kiselev*

Main category: cond-mat.mes-hall

TL;DR: 在介观量子点中研究了量子噪声，发现了可用于识别SYK物理和非费米液体特征的噪声特征。


<details>
  <summary>Details</summary>
Motivation: 研究一个作为带电Sachdev-Ye-Kitaev（SYK）模型实现的介观量子点中的量子噪声，该模型通过隧穿接触弱耦合到一个电子铅。

Method: 开发了一种线性响应理论，将所有类型的噪声置于同一基础上进行处理，并将电荷和热流的输运系数的概念及其关系推广到平衡噪声功率。

Result: 在所有可能与SYK点实验实现相关的区域中，发现了噪声系数的特征温度依赖性，以及一组连接这些系数且其值是SYK物理所独有的通用常数，并表征了库仑阻塞的噪声表现。

Conclusion: 该研究发现了在电压和温度偏差下的噪声特征，这些特征可以作为SYK物理在相关设置的实验中的明确标记。在超过SYK系统的范围内，这些结果可以作为识别非费米液体特征和提供温和现象实验额外可观测量的通用框架。

Abstract: We investigate quantum noise in a mesoscopic quantum dot serving as a
realization of the charged Sachdev-Ye-Kitaev (SYK) model weakly coupled to a
fermionic lead via a tunnel contact. We find noise signatures under voltage and
temperature biases that can serve as clear markers of the SYK physics in
experiments with related setups. We develop a linear response theory that
treats all types of noise on the same footing and generalizes a concept of
transport coefficients for charge and heat currents, as well as relations
between them, to equilibrium noise power. Within this theory, we find
characteristic scaling of the noise coefficients with temperature in all
regimes that can be relevant for experimental realizations of the SYK dots,
find a set of universal constants, with their values being unique to the SYK
physics, that connect these coefficients, and characterize noise manifestations
of the Coulomb blockade. Beyond SYK systems, these results may serve as a
general framework for identification of non-Fermi-liquid signatures in
mesoscopic transport and provide additional observables for experiments on
thermoelectric phenomena.

</details>


### [590] [Topological invariant for finite systems in the presence of disorder](https://arxiv.org/abs/2508.13146)
*Robert Eissele,Binayyak B. Roy,Sumanta Tewari,Tudor D. Stanescu*

Main category: cond-mat.mes-hall

TL;DR: 为有限尺寸无序系统提出了一种新的、更可靠的拓扑指标。


<details>
  <summary>Details</summary>
Motivation: 现有的拓扑指标在有限尺寸无序系统（如半导体-超导体杂化纳米线）中存在偏差且定义不明确，限制了其在实验中的应用。

Method: 提出了一种新的拓扑指标，该指标是通过周期性重复原始有限无序系统构建一个无限系统来定义的。

Result: 新方法生成的拓扑指标能够准确捕捉系统在参数空间中的拓扑性质（拓扑或平庸），并且不受有限尺寸指标常见偏差的影响，为解释实验结果提供了可靠的工具。

Conclusion: 提出了一个通用的、清晰的方法，为有限尺寸的无序系统生成可靠的拓扑指标，解决了现有指标的偏差和定义不清的问题，并以一维半导体-超导体杂化纳米线为例进行了验证。

Abstract: Topological invariants, rigorously defined only in the thermodynamic limit,
have been generalized to topological indicators applicable to finite-size
disordered systems. However, in many experimentally relevant situations, such
as semiconductor-superconductor (SM-SC) hybrid nanowires hosting Majorana zero
modes, the interplay between strong disorder and finite-size effects renders
these indicators (e.g., the so-called topological visibility) biased and
ill-defined, significantly limiting their usefulness. In this paper, we propose
the topological invariant rigorously defined for an infinite system constructed
by periodically repeating the original finite disordered system, as a
topological indicator. Using the one-dimensional SM-SC hybrid nanowire as an
example, we show that this general and transparent approach yields faithful
topological indicators free from the biases affecting commonly used finite-size
indicators, capturing the nature (topological or trivial) of the phase at
generic points in parameter space, and providing a reliable tool for
interpreting experimental results.

</details>


### [591] [Strain-induced Ettingshausen effect in spin-orbit coupled noncentrosymmetric metals](https://arxiv.org/abs/2508.13147)
*Gautham Varma K,Azaz Ahmad,Gargee Sharma*

Main category: cond-mat.mes-hall

TL;DR: 该研究探讨了SOC-NCMs中应变、手征反常和电热磁输运的相互作用，发现了应变诱导轴向电场，以及应变和磁场耦合产生的温度梯度，并揭示了Berry曲率驱动的异常Ettingshausen效应。


<details>
  <summary>Details</summary>
Motivation: 填补应变、手征反常（CA）以及电荷和热磁输运在自旋-轨道耦合非中心对称金属（SOC-NCMs）中相互作用的研究空白。

Method: 使用SOC-NCMs的紧束缚模型，并结合考虑动量依赖的带内和带间散射过程的准经典玻尔兹曼输运形式。

Result: 1. 应变在SOC-NCMs中诱导自旋-轨道耦合的各向异性并产生轴向电场。2. 应变和外磁场可以通过Nernst-Ettingshausen效应产生温度梯度，该梯度的方向和行为取决于多种因素的相互作用。3. 时间反演对称性破缺在外磁场下会产生由Berry曲率驱动的异常Ettingshausen效应，这与传统的洛伦兹力驱动效应不同。

Conclusion: 该研究揭示了在自旋-轨道耦合非中心对称金属（SOC-NCMs）中，应变、手征反常（CA）和电荷/热磁输运之间的相互作用。研究表明，应变会引起SOC-NCMs中自旋-轨道耦合的各向异性并产生轴向电场。在准经典玻尔兹曼输运形式下，作者发现应变和外磁场能够通过Nernst-Ettingshausen效应产生温度梯度，其方向和行为取决于应变与磁场夹角、手征反常、洛伦兹力以及带间散射强度等多种因素的相互作用。此外，研究还揭示了时间反演对称性破缺在外磁场下会产生由Berry曲率驱动的异常Ettingshausen效应，这与传统的洛伦兹力驱动效应有显著区别。

Abstract: Elastic deformations couple with electronic degrees of freedom in materials
to generate gauge fields that lead to interesting transport properties.
Recently, it has been well studied that strain-induced chiral magnetic fields
in Weyl semimetals lead to interesting magnetotransport induced by the chiral
anomaly (CA). Recent studies have revealed that CA is not necessarily only a
Weyl-node property, but is rather a Fermi surface property, and is also present
in a more general class of materials, for example, in spin orbit-coupled
noncentrosymmetric metals (SOC-NCMs). The interplay of strain, CA, and charge
and thermomagnetic transport in SOC-NCMs, however, remains unexplored. Here we
resolve this gap. Using a tight-binding model for SOC-NCMs, we first
demonstrate that strain in SOC-NCMs induces anisotropy in the spin-orbit
coupling and generates an axial electric field. Then, using the quasi-classical
Boltzmann transport formalism with momentum-dependent intraband and interband
scattering processes, we show that strain in the presence of external magnetic
field can generate temperature gradients via the Nernst-Ettingshausen effect,
whose direction and behavior depends the on interplay of multiple factors: the
angle between the applied strain and magnetic field, the presence of the chiral
anomaly, the Lorentz force, and the strength of interband scattering. We
further reveal that time-reversal symmetry breaking in the presence of an
external magnetic field generates the Berry-curvature-driven anomalous
Ettingshausen effect, which is qualitatively distinct from the conventional
Lorentz-force-driven counterpart. In light of recent and forthcoming
theoretical and experimental advances in the field of SOC-NCMs, we find our
study to be particularly timely and relevant.

</details>


### [592] [Magnetic Interactions of Wigner Crystal in Magnetic Field and Berry Curvature: Multi-Particle Tunneling through Complex Trajectories](https://arxiv.org/abs/2508.13149)
*Kyung-Su Kim*

Main category: cond-mat.mes-hall

TL;DR: 该研究利用半经典方法，分析了磁场和Berry曲率对二维Wigner晶体磁相互作用的影响，发现了AB效应、Berry相位和有效质量修正等关键因素。


<details>
  <summary>Details</summary>
Motivation: 研究磁场和Berry曲率对二维Wigner晶体磁相互作用的影响。

Method: 利用半经典大-$r_s$展开研究弱垂直磁场$B$和Berry曲率$\(Omega\)如何修改二维Wigner晶体的磁相互作用。

Result: 单独存在磁场时，电子沿着复数轨迹隧穿产生各种环交换相互作用。每个环交换常数获得等于$B=0$问题真实隧穿轨迹所围磁通量的Aharonov-Bohm（AB）相位。存在Berry曲率时，需考虑多粒子隧穿，交换常数获得纯虚轨迹在动量空间所围的Berry相位。当$B$和$\(Omega\)同时存在时，交换常数的大小还会受到有效质量修正的影响。

Conclusion: B和Berry曲率共同作用下，会修正二维Wigner晶体的磁相互作用，通过AB效应和Berry相位以及有效质量修正共同影响交换常数，这可能与四层和五层菱形石墨烯中观察到的现象有关。

Abstract: We study how a weak perpendicular magnetic field $B$ and a Berry curvature
$\Omega$ modify the magnetic interactions of a two-dimensional Wigner crystal
(WC), using the semi-classical large-$r_s$ expansion. When only a magnetic
field is present, various ring-exchange interactions arise from electron
tunneling along {\it complex} trajectories, which constitute {\it complex
instanton} solutions of the coordinate-space path integral. To leading order in
$B$, each ring-exchange constant acquires an Aharonov-Bohm (AB) phase equal to
the magnetic flux enclosed by the real tunneling trajectory of the $B=0$
problem. This effect is directly relevant to two-dimensional electron systems
with a small $g$-factor ($g \ll 1$). In the presence of a Berry curvature,
multi-particle tunneling must be considered in a (complexified) phase space
$({\bf r}, {\bf k})$. To leading order in $\Omega$, the exchange constants
acquire the Berry phase enclosed by a {\it purely imaginary} trajectory in a
momentum space. Finally, when both $B$ and $\Omega$ are non-zero, in addition
to having the AB and Berry phase factors, the magnitude of the exchange
constant can also be renormalized by an effective-mass correction. These
effects may be relevant for the WC and its proximate phases recently observed
in tetra- and penta-layer rhombohedral graphene.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [593] [Vibe2Spike: Batteryless Wireless Tags for Vibration Sensing with Event Cameras and Spiking Networks](https://arxiv.org/abs/2508.11640)
*Danny Scott,William LaForest,Hritom Das,Ioannis Polykretis,Catherine D. Schuman,Charles Rizzo,James Plank,Sai Swaminathan*

Main category: eess.SP

TL;DR: Vibe2Spike是一种创新的无电池传感系统，使用可见光通信和尖峰神经网络，通过振动识别活动，实现了智能环境的节能和可扩展部署。


<details>
  <summary>Details</summary>
Motivation: 现有的智能环境传感解决方案在能源、可扩展性和可靠性方面存在瓶颈，这主要是由于电池维护、无线传输开销和数据处理复杂性造成的。因此，需要一种无需电池、节能且可扩展的传感方法。

Method: 使用由压电盘、齐纳二极管和LED组成的无电池标签，利用振动能量收集和可见光通信（VLC）发送稀疏的可见光脉冲。这些脉冲由事件相机捕获，并使用EONS框架进化的尖峰神经网络（SNN）模型进行分类。

Result: 在五个设备类别上进行了评估，平均分类准确率达到94.9%，并分析了不同时间分箱策略的延迟-准确率权衡。

Conclusion: Vibe2Spike是一个可扩展、节能且无需电池的智能环境传感框架，通过振动识别活动。

Abstract: The deployment of dense, low-cost sensors is critical for realizing
ubiquitous smart environments. However, existing sensing solutions struggle
with the energy, scalability, and reliability trade-offs imposed by battery
maintenance, wireless transmission overhead, and data processing complexity. In
this work, we present Vibe2Spike, a novel battery-free, wireless sensing
framework that enables vibration-based activity recognition using visible light
communication (VLC) and spiking neural networks (SNNs). Our system uses
ultra-low-cost tags composed only of a piezoelectric disc, a Zener diode, and
an LED, which harvest vibration energy and emit sparse visible light spikes
without requiring batteries or RF radios. These optical spikes are captured by
event cameras and classified using optimized SNN models evolved via the EONS
framework. We evaluate Vibe2Spike across five device classes, achieving 94.9\%
average classification fitness while analyzing the latency-accuracy trade-offs
of different temporal binning strategies. Vibe2Spike demonstrates a scalable,
and energy-efficient approach for enabling intelligent environments in a
batteryless manner.

</details>


### [594] [Data-driven RF Tomography via Cross-modal Sensing and Continual Learning](https://arxiv.org/abs/2508.11654)
*Yang Zhao,Tao Wang,Said Elhadi*

Main category: eess.SP

TL;DR: 提出 DRIFT 框架，结合跨模态学习和持续学习，提高动态环境中地下目标检测的准确性。


<details>
  <summary>Details</summary>
Motivation: 为了解决数据驱动射频断层扫描在动态环境中实现准确性和鲁棒性方面存在的挑战，以用于地下目标检测。

Method: 提出了一种包含射频和视觉传感器的跨模态传感系统，并采用跨模态学习方法训练射频断层扫描深度神经网络（DNN）模型。此外，还应用持续学习机制，在检测到动态环境变化时自动更新 DNN 模型。

Result: 实验结果表明，该方法实现了 2.29 厘米的平均等效直径误差，比现有最先进的方法提高了 23.2%。

Conclusion: 所提出的 DRIFT 框架通过结合跨模态学习和持续学习，在动态环境中实现了地下目标检测的准确性和鲁棒性，并将等效直径误差平均提高了 23.2%。

Abstract: Data-driven radio frequency (RF) tomography has demonstrated significant
potential for underground target detection, due to the penetrative nature of RF
signals through soil. However, it is still challenging to achieve accurate and
robust performance in dynamic environments. In this work, we propose a
data-driven radio frequency tomography (DRIFT) framework with the following key
components to reconstruct cross section images of underground root tubers, even
with significant changes in RF signals. First, we design a cross-modal sensing
system with RF and visual sensors, and propose to train an RF tomography deep
neural network (DNN) model following the cross-modal learning approach. Then we
propose to apply continual learning to automatically update the DNN model, once
environment changes are detected in a dynamic environment. Experimental results
show that our approach achieves an average equivalent diameter error of 2.29
cm, 23.2% improvement upon the state-of-the-art approach. Our DRIFT code and
dataset are publicly available on https://github.com/Data-driven-RTI/DRIFT.

</details>


### [595] [Inductive transfer learning from regression to classification in ECG analysis](https://arxiv.org/abs/2508.11656)
*Ridma Jayasundara,Ishan Fernando,Adeepa Fernando,Roshan Ragel,Vajira Thambawita,Isuru Nawinne*

Main category: eess.SP

TL;DR: Synthetic ECG data and transfer learning can improve CVD diagnosis by enhancing deep learning model performance in classifying ECG signals.


<details>
  <summary>Details</summary>
Motivation: Cardiovascular diseases (CVDs) are the leading cause of mortality worldwide, and timely diagnosis through ECG is crucial. However, privacy concerns regarding patient ECG data have led to interest in synthetic data. This study aims to explore the potential of synthetic ECG data for training deep learning models and assess the viability of transfer learning for improved classification performance.

Method: The study explores the potential of synthetic ECG data for training deep learning models for regression and classification tasks, and evaluates the feasibility of transfer learning to enhance classification performance on real ECG data. The researchers experimented with popular deep learning models to predict four key cardiac parameters (Heart Rate, PR interval, QT interval, and QRS complex) using separate regression models. Subsequently, these regression models were leveraged for transfer learning to perform 5-class ECG signal classification.

Result: Experiments demonstrate that transfer learning from regression to classification improves classification performance, indicating its potential for better utilization of diverse ECG datasets (both open-access and synthetic).

Conclusion: Transfer learning from regression to classification improves classification performance, highlighting its potential to maximize the utility of available data and advance deep learning applications in the domain of ECG analysis.

Abstract: Cardiovascular diseases (CVDs) are the leading cause of mortality worldwide,
accounting for over 30% of global deaths according to the World Health
Organization (WHO). Importantly, one-third of these deaths are preventable with
timely and accurate diagnosis. The electrocardiogram (ECG), a non-invasive
method for recording the electrical activity of the heart, is crucial for
diagnosing CVDs. However, privacy concerns surrounding the use of patient ECG
data in research have spurred interest in synthetic data, which preserves the
statistical properties of real data without compromising patient
confidentiality. This study explores the potential of synthetic ECG data for
training deep learning models from regression to classification tasks and
evaluates the feasibility of transfer learning to enhance classification
performance on real ECG data. We experimented with popular deep learning models
to predict four key cardiac parameters, namely, Heart Rate (HR), PR interval,
QT interval, and QRS complex-using separate regression models. Subsequently, we
leveraged these regression models for transfer learning to perform 5-class ECG
signal classification. Our experiments systematically investigate whether
transfer learning from regression to classification is viable, enabling better
utilization of diverse open-access and synthetic ECG datasets. Our findings
demonstrate that transfer learning from regression to classification improves
classification performance, highlighting its potential to maximize the utility
of available data and advance deep learning applications in this domain.

</details>


### [596] [Agent-Based Anti-Jamming Techniques for UAV Communications in Adversarial Environments: A Comprehensive Survey](https://arxiv.org/abs/2508.11687)
*Jingpu Yang,Mingxuan Cui,Hang Zhang,Fengxian Ji,Zhengzhao Lai,Yufeng Wang*

Main category: eess.SP

TL;DR: 该调查通过概念形式化、P-D-A框架以及博弈论和强化学习的应用，全面概述了无人机通信中的智能抗干扰Agent。


<details>
  <summary>Details</summary>
Motivation: 为了应对无人机通信在动态对抗环境中日益严峻的多源干扰挑战，以及提高其可靠性和韧性。

Method: 对无人机通信中的智能抗干扰Agent进行概念形式化，并建立了一个以“感知-决策-行动”（P-D-A）范式为中心的闭环决策框架。在此框架内，系统地回顾了每个阶段的关键技术，特别强调了使用博弈论对无人机-干扰器交互进行建模，以及整合基于强化学习的智能算法来推导自适应抗干扰策略。

Result: 对无人机通信中的智能抗干扰Agent进行了概念形式化，并建立了“感知-决策-行动”（P-D-A）闭环决策框架，回顾了各阶段的关键技术，并讨论了当前方法的潜在局限性、关键工程挑战以及未来的研究方向。

Conclusion: 为无人机开发更智能、更强大的抗干扰通信系统提供有价值的参考。

Abstract: Unmanned Aerial Vehicle communications are encountering increasingly severe
multi-source interference challenges in dynamic adversarial environments, which
impose higher demands on their reliability and resilience. To address these
challenges, agent-based autonomous anti-jamming techniques have emerged as a
crucial research direction. This paper presents a comprehensive survey that
first formalizes the concept of intelligent anti-jamming agents for UAV
communications and establishes a closed-loop decision-making framework centered
on the "Perception-Decision-Action" (P-D-A) paradigm. Within this framework, we
systematically review key technologies at each stage, with particular emphasis
on employing game theory to model UAV-jammer interactions and integrating
reinforcement learning-based intelligent algorithms to derive adaptive
anti-jamming strategies. Furthermore, we discuss potential limitations of
current approaches, identify critical engineering challenges, and outline
promising future research directions, aiming to provide valuable references for
developing more intelligent and robust anti-jamming communication systems for
UAVs.

</details>


### [597] [Robust Sparse Bayesian Learning Based on Minimum Error Entropy for Noisy High-Dimensional Brain Activity Decoding](https://arxiv.org/abs/2508.11657)
*Yuanhao Li,Badong Chen,Wenjun Bai,Yasuharu Koike,Okito Yamashita*

Main category: eess.SP

TL;DR: 本研究提出了一种基于最小误差熵（MEE）的稀疏贝叶斯学习框架，以解决带噪声的高维大脑信号解码问题。实验结果表明，该方法在解码性能和生理模式方面优于现有方法，为脑机接口等生物医学工程应用提供了有力工具。


<details>
  <summary>Details</summary>
Motivation: 传统的稀疏贝叶斯学习在处理大脑信号解码的高维问题时，其对高斯和二项式等数据分布的假设可能无法充分描述带噪声的大脑活动信号。因此，本研究旨在提出一个稳健的稀疏贝叶斯学习框架来解决带噪声的高维大脑活动解码问题。

Method: 提出了一种基于最小误差熵（MEE）标准的似然函数，以促进稀疏贝叶斯学习在分析带噪声大脑数据集时的准确推理。

Result: 所提出的方法在回归和分类背景下的两个高维脑解码任务中进行了评估。实验结果表明，与传统和最先进的方法相比，该方法能够实现更优越的解码指标和生理模式。

Conclusion: 利用所提出的基于MEE的似然模型，稀疏贝叶斯学习能够有效应对脑解码任务中的噪声和高维性挑战。

Abstract: Objective: Sparse Bayesian learning provides an effective scheme to solve the
high-dimensional problem in brain signal decoding. However, traditional
assumptions regarding data distributions such as Gaussian and binomial are
potentially inadequate to characterize the noisy signals of brain activity.
Hence, this study aims to propose a robust sparse Bayesian learning framework
to address noisy highdimensional brain activity decoding. Methods: Motivated by
the commendable robustness of the minimum error entropy (MEE) criterion for
handling complex data distributions, we proposed an MEE-based likelihood
function to facilitate the accurate inference of sparse Bayesian learning in
analyzing noisy brain datasets. Results: Our proposed approach was evaluated
using two high-dimensional brain decoding tasks in regression and
classification contexts, respectively. The experimental results showed that,
our approach can realize superior decoding metrics and physiological patterns
than the conventional and state-of-the-art methods. Conclusion: Utilizing the
proposed MEE-based likelihood model, sparse Bayesian learning is empowered to
simultaneously address the challenges of noise and high dimensionality in the
brain decoding task. Significance: This work provides a powerful tool to
realize robust brain decoding, advancing biomedical engineering applications
such as brain-computer interface.

</details>


### [598] [CECGSR: Circular ECG Super-Resolution](https://arxiv.org/abs/2508.11658)
*Honggui Li,Zhengyang Zhang,Dingtai Li,Sinan Chen,Nahid Md Lokman Hossain,Xinfeng Xu,Yuting Feng,Hantao Lu,Yinlu Qin,Ruobing Wang,Maria Trocan,Dimitri Galayko,Amara Amara,Mohamad Sawan*

Main category: eess.SP

TL;DR: 提出了一种新的闭环ECG超分辨率方法（CECGSR），通过负反馈机制和即插即用策略，提高了ECG信号的重构质量，优于现有开环方法。


<details>
  <summary>Details</summary>
Motivation: ECG信号由于使用方便的采集设备以及内部和外部的噪声和伪影而存在低分辨率（LR）问题。为了提高ECG信号的质量，提出了一种新的超分辨率方法。

Method: 提出了一种闭环方法，称为循环ECGSR（CECGSR），它对从SR ECG信号到LR信号的退化过程进行建模。闭环系统的负反馈机制基于LR ECG信号之间的差异。构建了一个数学环路方程来表征闭环基础设施。利用泰勒级数展开来证明所提出方法的近乎零的稳态误差。考虑采用即插即用策略来建立所提出架构的SR单元，利用任何现有的先进的开环ECGSR方法。

Result: 在PTB-XL数据集的无噪声和有噪声子集上的仿真实验表明，所提出的CECGSR在ECG信号的重构性能上优于最先进的开环ECGSR算法。

Conclusion: 所提出的CECGSR方法在重构性能上优于最先进的开环ECGSR算法。

Abstract: The electrocardiogram (ECG) plays a crucial role in the diagnosis and
treatment of various cardiac diseases. ECG signals suffer from low-resolution
(LR) due to the use of convenient acquisition devices, as well as internal and
external noises and artifacts. Classical ECG super-resolution (ECGSR) methods
adopt an open-loop architecture that converts LR ECG signals to
super-resolution (SR) ones. According to the theory of automatic control, a
closed-loop framework exhibits superior dynamic and static performance compared
with its open-loop counterpart. This paper proposes a closed-loop approach,
termed circular ECGSR (CECGSR), which models the degradation process from SR
ECG signals to LR ones. The negative feedback mechanism of the closed-loop
system is based on the differences between the LR ECG signals. A mathematical
loop equation is constructed to characterize the closed-loop infrastructure.
The Taylor series expansion is employed to demonstrate the near-zero
steady-state error of the proposed method. A Plug-and-Play strategy is
considered to establish the SR unit of the proposed architecture, leveraging
any existing advanced open-loop ECGSR methods. Simulation experiments on both
noiseless and noisy subsets of the PTB-XL datasets demonstrate that the
proposed CECGSR outperforms state-of-the-art open-loop ECGSR algorithms in the
reconstruction performance of ECG signals.

</details>


### [599] [Unsupervised Pairwise Learning Optimization Framework for Cross-Corpus EEG-Based Emotion Recognition Based on Prototype Representation](https://arxiv.org/abs/2508.11663)
*Guangli Li,Canbiao Wu,Zhen Liang*

Main category: eess.SP

TL;DR: 通过最大化分类差异和最小化特征分布，McdPL框架能有效解决跨语料情感识别的挑战，尤其是在决策边界附近的样本。


<details>
  <summary>Details</summary>
Motivation: 为了解决跨语料情感识别中由于被试生理差异、实验环境和设备变化导致的挑战，特别是在决策边界附近的样本。

Method: 提出了一种基于域对抗迁移学习的优化方法，命名为最大分类器差异与成对学习（McdPL）框架，以细粒度对齐情感特征。该框架设计了对偶对抗分类器（Ada分类器和RMS分类器），并采用三阶段对抗训练来最大化分类差异并最小化特征分布，以对齐决策边界附近的争议样本。此外，引入成对学习将样本的分类问题转化为样本间的相似性问题，以减轻标签噪声的影响。

Result: McdPL模型在跨语料情感识别任务上优于其他基线模型，平均准确率分别提高了4.76%和3.97%。

Conclusion: 本研究提出的McdPL框架在跨语料情感识别任务上优于其他基线模型，平均准确率分别提高了4.76%和3.97%，为情感识别的跨语料应用提供了一种有前景的解决方案。

Abstract: Affective computing is a rapidly developing interdisciplinary research
direction in the field of brain-computer interface. In recent years, the
introduction of deep learning technology has greatly promoted the development
of the field of emotion recognition. However, due to physiological differences
between subjects, as well as the variations in experimental environments and
equipment, cross-corpus emotion recognition faces serious challenges,
especially for samples near the decision boundary. To solve the above problems,
we propose an optimization method based on domain adversarial transfer learning
to fine-grained alignment of affective features, named Maximum classifier
discrepancy with Pairwise Learning (McdPL) framework. In McdPL, we design a
dual adversarial classifier (Ada classifier and RMS classifier), and apply a
three-stage adversarial training to maximize classification discrepancy and
minimize feature distribution to align controversy samples near the decision
boundary. In the process of domain adversarial training, the two classifiers
also maintain an adversarial relationship, ultimately enabling precise
cross-corpus feature alignment. In addition, the introduction of pairwise
learning transforms the classification problem of samples into a similarity
problem between samples, alleviating the influence of label noise. We conducted
systematic experimental evaluation of the model using publicly available SEED,
SEED-IV and SEED-V databases. The results show that the McdPL model is superior
to other baseline models in the cross-corpus emotion recognition task, and the
average accuracy improvements of 4.76\% and 3.97\%, respectively. Our work
provides a promising solution for emotion recognition cross-corpus. The source
code is available at https://github.com/WuCB-BCI/Mcd_PL.

</details>


### [600] [Energy-Efficient Real-Time 4-Stage Sleep Classification at 10-Second Resolution: A Comprehensive Study](https://arxiv.org/abs/2508.11664)
*Zahra Mohammadi,Parnian Fazel,Siamak Mohammadi*

Main category: eess.SP

TL;DR: 本研究提出了一种使用单导ECG监测睡眠阶段的节能方法，其效率和准确性均优于现有方法，为可穿戴设备提供了实用解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统的睡眠分期方法（如多导睡眠图）成本高昂且不适用于长期家庭使用。因此，需要一种更经济、更实用的方法来监测睡眠。

Method: 研究提出了一种能量高效的流程，仅使用单导ECG即可检测四种睡眠阶段（清醒、REM、浅睡和深睡）。采用了两种窗口策略：一种是用于具有手工特征的机器学习模型的5分钟窗口（30秒步长），另一种是用于深度学习模型的30秒窗口（10秒步长），可实现近乎实时的10秒分辨率。设计了一个名为SleepLiteCNN的自定义模型，并对其进行了8位量化和FPGA部署以确认其低资源使用情况。

Result: 与MobileNet-v1（准确率92%，F1分数91%）相比，SleepLiteCNN在降低能耗的同时，取得了89%的准确率和89%的F1分数，能耗降低至45nm工艺下的每次推理5.48微焦耳。8位量化保持了准确率并进一步降低了功耗。

Conclusion: 该系统为基于ECG的连续、可穿戴睡眠监测提供了一种实用的解决方案。

Abstract: Sleep stage classification is crucial for diagnosing and managing disorders
such as sleep apnea and insomnia. Conventional clinical methods like
polysomnography are costly and impractical for long-term home use. We present
an energy-efficient pipeline that detects four sleep stages (wake, REM, light,
and deep) from a single-lead ECG. Two windowing strategies are introduced: (1)
a 5-minute window with 30-second steps for machine-learning models that use
handcrafted features, and (2) a 30-second window with 10-second steps for
deep-learning models, enabling near-real-time 10-second resolution. Lightweight
networks such as MobileNet-v1 reach 92 percent accuracy and 91 percent F1-score
but still draw significant energy. We therefore design SleepLiteCNN, a custom
model that achieves 89 percent accuracy and 89 percent F1-score while lowering
energy use to 5.48 microjoules per inference at 45 nm. Applying eight-bit
quantization preserves accuracy and further reduces power, and FPGA deployment
confirms low resource usage. The proposed system offers a practical solution
for continuous, wearable ECG-based sleep monitoring.

</details>


### [601] [Explainable Deep Neural Network for Multimodal ECG Signals: Intermediate vs Late Fusion](https://arxiv.org/abs/2508.11666)
*Timothy Oladunni,Ehimen Aneni*

Main category: eess.SP

TL;DR: 本研究利用多模态深度神经网络（MDNN）融合ECG信号的时域、频域和时频域信息，发现中间融合策略优于晚期融合，准确率达97%，并具有良好的可解释性，可用于提高心血管疾病分类的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 为了解决单模态深度学习模型（尤其是过拟合和泛化能力有限）的局限性，并应对临床高风险场景（如ECG心血管疾病分类）中对鲁棒性和准确性的需求，本研究旨在探讨中间融合和晚期融合策略的有效性。

Method: 本研究通过在时域、频域和时频域三个域上使用ECG信号，研究了中间融合（特征级）和晚期融合（决策级）策略的比较有效性，并进行了一系列实验来识别性能最佳的融合架构。

Result: 结果表明，中间融合在准确性上始终优于晚期融合，峰值准确率达到97%，与单独模型相比Cohen

Conclusion: 本研究提出的基于ECG域的多模态模型在预测能力和可解释性方面均优于最先进的模型，这在医学人工智能应用中是至关重要的。

Abstract: The limitations of unimodal deep learning models, particularly their tendency
to overfit and limited generalizability, have renewed interest in multimodal
fusion strategies. Multimodal deep neural networks (MDNN) have the capability
of integrating diverse data domains and offer a promising solution for robust
and accurate predictions. However, the optimal fusion strategy, intermediate
fusion (feature-level) versus late fusion (decision-level) remains
insufficiently examined, especially in high-stakes clinical contexts such as
ECG-based cardiovascular disease (CVD) classification. This study investigates
the comparative effectiveness of intermediate and late fusion strategies using
ECG signals across three domains: time, frequency, and time-frequency. A series
of experiments were conducted to identify the highest-performing fusion
architecture. Results demonstrate that intermediate fusion consistently
outperformed late fusion, achieving a peak accuracy of 97 percent, with Cohen's
d > 0.8 relative to standalone models and d = 0.40 compared to late fusion.
Interpretability analyses using saliency maps reveal that both models align
with the discretized ECG signals. Statistical dependency between the
discretized ECG signals and corresponding saliency maps for each class was
confirmed using Mutual Information (MI). The proposed ECG domain-based
multimodal model offers superior predictive capability and enhanced
explainability, crucial attributes in medical AI applications, surpassing
state-of-the-art models.

</details>


### [602] [Neural Gaussian Radio Fields for Channel Estimation](https://arxiv.org/abs/2508.11668)
*Muhammad Umer,Muhammad Ahmed Mohsin,Ahsan Bilal,John M. Cioffi*

Main category: eess.SP

TL;DR: nGRF是一种新的无线信道状态信息估计框架，利用3D高斯基元，显著提高了精度和效率，降低了延迟和数据需求，克服了传统方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统的信道状态信息估计技术在现代无线网络中存在瓶颈，特别是在移动性和延迟方面，导致性能下降。

Method: nGRF框架，利用显式3D高斯基元进行信道状态信息估计。

Result: nGRF在室内场景下预测信噪比比现有技术高10.9倍，推理延迟从242毫秒降低到1.1毫秒（加速220倍）；在室外场景下，信噪比达到26.2分贝；数据采集量和训练时间均大幅减少。

Conclusion: nGRF通过使用显式3D高斯基元，实现了对复杂信道矩阵的精确高效合成，在无线通信领域具有显著优势。

Abstract: Accurate channel state information (CSI) remains the most critical bottleneck
in modern wireless networks, with pilot overhead consuming up to 11-21% of
transmission bandwidth, increasing latency by 20-40% in massive MIMO systems,
and reducing potential spectral efficiency by over 53%. Traditional estimation
techniques fundamentally fail under mobility, with feedback delays as small as
4 ms causing 50% throughput degradation at even modest speeds (30 km/h). We
present neural Gaussian radio fields (nGRF), a novel framework that leverages
explicit 3D Gaussian primitives to synthesize complex channel matrices
accurately and efficiently. Unlike NeRF-based approaches that rely on slow
implicit representations or existing Gaussian splatting methods that use
non-physical 2D projections, nGRF performs direct 3D electromagnetic field
aggregation, with each Gaussian acting as a localized radio modulator. nGRF
demonstrates superior performance across diverse environments: in indoor
scenarios, it achieves a 10.9$\times$ higher prediction SNR than state of the
art methods while reducing inference latency from 242 ms to just 1.1 ms (a
220$\times$ speedup). For large-scale outdoor environments, where existing
approaches fail to function, nGRF achieves an SNR of 26.2 dB. Moreover, nGRF
requires only 0.011 measurements per cubic foot compared to 0.2-178.1 for
existing methods, thereby reducing data collection burden by 18$\times$.
Training time is similarly reduced from hours to minutes (a 180$\times$
reduction), enabling rapid adaptation to dynamic environments. The code and
datasets are available at: https://github.com/anonym-auth/n-grf

</details>


### [603] [Direction of Arrival Estimation: A Tutorial Survey of Classical and Modern Methods](https://arxiv.org/abs/2508.11675)
*Amgad A. Salama*

Main category: eess.SP

TL;DR: 本综述为 DOA 估计的初学者提供了经典和现代方法的全面介绍，并附有 Python 实现和性能比较。


<details>
  <summary>Details</summary>
Motivation: DOA 估计是阵列信号处理中的一个基本问题，其应用涵盖雷达、声纳、无线通信和声学信号处理等领域。本教程调查为该领域的新学生和研究人员提供了对经典和现代 DOA 估计方法的全面介绍。

Method: 本综述涵盖了经典波束成形方法、基于子空间的技术（MUSIC、ESPRIT）、最大似然方法以及稀疏信号处理方法，并附有开源存储库中的 Python 实现。

Result: 通过跨各种场景的系统性能比较，我们为方法选择和参数调整提供了实用的指导。

Conclusion: 本综述旨在弥合理论基础与实际应用之间的差距，使 DOA 估计对初学者来说易于理解，并为该领域提供全面的参考。

Abstract: Direction of arrival (DOA) estimation is a fundamental problem in array
signal processing with applications spanning radar, sonar, wireless
communications, and acoustic signal processing. This tutorial survey provides a
comprehensive introduction to classical and modern DOA estimation methods,
specifically designed for students and researchers new to the field. We focus
on narrowband signal processing using uniform linear arrays, presenting
step-by-step mathematical derivations with geometric intuition. The survey
covers classical beamforming methods, subspace-based techniques (MUSIC,
ESPRIT), maximum likelihood approaches, and sparse signal processing methods.
Each method is accompanied by Python implementations available in an
open-source repository, enabling reproducible research and hands-on learning.
Through systematic performance comparisons across various scenarios, we provide
practical guidelines for method selection and parameter tuning. This work aims
to bridge the gap between theoretical foundations and practical implementation,
making DOA estimation accessible to beginners while serving as a comprehensive
reference for the field. See https://github.com/AmgadSalama/DOA for detail
implementation of the methods.

</details>


### [604] [Age-Normalized HRV Features for Non-Invasive Glucose Prediction: A Pilot Sleep-Aware Machine Learning Study](https://arxiv.org/abs/2508.11682)
*Md Basit Azam,Sarangthem Ibotombi Singh*

Main category: eess.SP

TL;DR: A new method normalizing heart rate variability (HRV) by age improves blood glucose prediction during sleep. This technique, using BayesianRidge regression, showed a 25.6% increase in accuracy compared to traditional methods and may be useful for non-invasive glucose monitoring, but needs further validation.


<details>
  <summary>Details</summary>
Motivation: Traditional HRV analyses are confounded by age-related autonomic changes, posing a challenge for glucose prediction using HRV during sleep. This study aims to address this by normalizing HRV features for age.

Method: BayesianRidge regression with 5-fold cross-validation was used for log-glucose prediction, employing a novel age-normalization technique for HRV features by dividing raw values by age-scaled factors.

Result: Age-normalized HRV features achieved R2 = 0.161 (MAE = 0.182) for log-glucose prediction, a 25.6% improvement over non-normalized features (R2 = 0.132). Key predictive features included age-normalized HRV means during REM and 'ds' sleep stages, and diastolic blood pressure. Ablation studies confirmed the critical role of age-normalization and the added value of sleep-stage specific features.

Conclusion: Age-normalized HRV features significantly enhance glucose prediction accuracy compared to traditional methods, showing preliminary feasibility for non-invasive glucose monitoring. However, validation in larger cohorts is needed.

Abstract: Non-invasive glucose monitoring remains a critical challenge in the
management of diabetes. HRV during sleep shows promise for glucose prediction
however, age-related autonomic changes significantly confound traditional HRV
analyses. We analyzed 43 subjects with multi-modal data including sleep-stage
specific ECG, HRV features, and clinical measurements. A novel
age-normalization technique was applied to the HRV features by, dividing the
raw values by age-scaled factors. BayesianRidge regression with 5-fold
cross-validation was employed for log-glucose prediction. Age-normalized HRV
features achieved R2 = 0.161 (MAE = 0.182) for log-glucose prediction,
representing a 25.6% improvement over non-normalized features (R2 = 0.132). The
top predictive features were hrv rem mean rr age normalized (r = 0.443, p =
0.004), hrv ds mean rr age normalized (r = 0.438, p = 0.005), and diastolic
blood pressure (r = 0.437, p = 0.005). Systematic ablation studies confirmed
age-normalization as the critical component, with sleep-stage specific features
providing additional predictive value. Age-normalized HRV features
significantly enhance glucose prediction accuracy compared with traditional
approaches. This sleep-aware methodology addresses fundamental limitations in
autonomic function assessment and suggests a preliminary feasibility for
non-invasive glucose monitoring applications. However, these results require
validation in larger cohorts before clinical consideration.

</details>


### [605] [A Graph Neural Network based on a Functional Topology Model: Unveiling the Dynamic Mechanisms of Non-Suicidal Self-Injury in Single-Channel EEG](https://arxiv.org/abs/2508.11684)
*BG Tong*

Main category: eess.SP

TL;DR: 研究提出了一种新的“功能-能量拓扑模型”，使用图神经网络分析单通道脑电图，以理解非自杀性自伤（NSSI）的神经机制。该模型在预测NSSI状态方面表现出高准确性，并发现NSSI状态下存在关键的反馈回路功能障碍和方向逆转。


<details>
  <summary>Details</summary>
Motivation: 提出并初步验证了一种新颖的“功能-能量拓扑模型”，以揭示非自杀性自伤（NSSI）的神经动力学机制。

Method: 采用图神经网络（GNNs）解码来自单通道脑电图的大脑网络模式，并使用GNNExplainer进行可解释性分析。

Result: 模型实现了高受试者内准确率（>85%）和显著高于机会水平的跨受试者表现（约73.7%）。可解释性分析揭示了一个关键发现：在NSSI状态下，调节躯体感觉的关键反馈回路表现出功能障碍和方向逆转。

Conclusion: 该工作证明了将理论指导的图神经网络应用于稀疏单通道脑电图以解码复杂心理状态的可行性。所识别出的“反馈回路逆转”为NSSI机制提供了一种新颖、动态且可计算的模型，为客观生物标志物和下一代数字疗法（DTx）铺平了道路。

Abstract: Objective: This study proposes and preliminarily validates a novel
"Functional-Energetic Topology Model" to uncover neurodynamic mechanisms of
Non-Suicidal Self-Injury (NSSI), using Graph Neural Networks (GNNs) to decode
brain network patterns from single-channel EEG in real-world settings.Methods:
EEG data were collected over ~1 month from three adolescents with NSSI using a
smartphone app and a portable Fp1 EEG headband during impulsive and
non-impulsive states. A theory-driven GNN with seven functional nodes was
built. Performance was evaluated via intra-subject (80/20 split) and
leave-one-subject-out cross-validation (LOSOCV). GNNExplainer was used for
interpretability.Results: The model achieved high intra-subject accuracy (>85%)
and significantly above-chance cross-subject performance (approximately73.7%).
Explainability analysis revealed a key finding: during NSSI states, a critical
feedback loop regulating somatic sensation exhibits dysfunction and directional
reversal. Specifically, the brain loses its ability to self-correct via
negative bodily feedback, and the regulatory mechanism enters an "ineffective
idling" state.Conclusion: This work demonstrates the feasibility of applying
theory-guided GNNs to sparse, single-channel EEG for decoding complex mental
states. The identified "feedback loop reversal" offers a novel, dynamic, and
computable model of NSSI mechanisms, paving the way for objective biomarkers
and next-generation Digital Therapeutics (DTx).

</details>


### [606] [Enhancing Corrosion Resistance of Aluminum Alloys Through AI and ML Modeling](https://arxiv.org/abs/2508.11685)
*Farnaz Kaboudvand,Maham Khalid,Nydia Assaf,Vardaan Sahgal,Jon P. Ruffley,Brian J. McDermott*

Main category: eess.SP

TL;DR: 本研究利用机器学习（ML）预测和优化铝合金在海洋环境中的耐腐蚀性。研究采用了随机森林、神经网络和高斯过程回归（GPR）等方法，并发现GPR（特别是混合核函数和对数转换后）表现出最佳性能。


<details>
  <summary>Details</summary>
Motivation: 腐蚀对铝合金的性能构成了重大挑战，尤其是在海洋环境中。本研究旨在利用机器学习（ML）算法来预测和优化耐腐蚀性。

Method: 本研究探索了两种不同的方法：一种直接方法，使用材料成分和环境条件作为输入来预测腐蚀速率；另一种逆向方法，以腐蚀速率作为输入来识别合适的材料成分。研究中采用了三种不同的机器学习方法进行前向预测：随机森林回归（通过网格搜索进行优化）、前馈神经网络（使用ReLU激活和Adam优化）以及高斯过程回归（GPR）（使用GPyTorch实现并采用各种核函数）。

Result: 随机森林和神经网络模型能够根据元素组成和环境条件进行预测。值得注意的是，高斯过程回归（GPR）表现出卓越的性能，尤其是在使用混合核函数时。对数转换的GPR进一步提高了预测精度。

Conclusion: 本研究强调了机器学习，特别是高斯过程回归（GPR）在预测腐蚀速率和材料特性方面的有效性。

Abstract: Corrosion poses a significant challenge to the performance of aluminum
alloys, particularly in marine environments. This study investigates the
application of machine learning (ML) algorithms to predict and optimize
corrosion resistance, utilizing a comprehensive open-source dataset compiled
from various sources. The dataset encompasses corrosion rate data and
environmental conditions, preprocessed to standardize units and formats. We
explored two different approaches, a direct approach, where the material's
composition and environmental conditions were used as inputs to predict
corrosion rates; and an inverse approach, where corrosion rate served as the
input to identify suitable material compositions as output. We employed and
compared three distinct ML methodologies for forward predictions: Random Forest
regression, optimized via grid search; a feed-forward neural network, utilizing
ReLU activation and Adam optimization; and Gaussian Process Regression (GPR),
implemented with GPyTorch and employing various kernel functions. The Random
Forest and neural network models provided predictive capabilities based on
elemental compositions and environmental conditions. Notably, Gaussian Process
Regression demonstrated superior performance, particularly with hybrid kernel
functions. Log-transformed GPR further refined predictions. This study
highlights the efficacy of ML, particularly GPR, in predicting corrosion rates
and material properties.

</details>


### [607] [The Lost-K and Shorter-J Phenomenon in Non-Standard Ballistocardiography Data](https://arxiv.org/abs/2508.11686)
*Shuai Jiao,Jian Fang,Tianshu Zhou,Jinsong Li,Yanhong Liu,Ye Liu,Ming Ju*

Main category: eess.SP

TL;DR: 本研究提出了两种非标准BCG信号中普遍存在的J峰不明显现象（缩短J现象和丢失K现象），并提出三种信号变换方法来改善这些现象。实验结果表明，这些方法能有效提升J峰的检测和BCG周期的提取，特别是非标准BCG信号。


<details>
  <summary>Details</summary>
Motivation: 非标准的 the ballistocardiogram(BCG) 数据通常缺乏明显的J峰。这篇论文介绍了两种普遍存在于非标准BCG信号中，导致J峰不明显的现象：缩短J现象和丢失K现象。

Method: 提出两种缩短J峰和丢失K的方法，并提出三种信号变换方法来改善这两种现象。

Result: 基于变换后的信号，仅通过检测局部最大值或最小值就能实现的简单J峰检测方法，在定位J峰和提取BCG周期方面表现更好，尤其是在处理非标准BCG数据时。

Conclusion: 提出三种信号变换方法，可以有效地改善J峰缺失和缩短现象，从而可以基于J峰的检测和BCG周期的提取，即使是对于非标准BCG信号。

Abstract: Non-standard ballistocardiogram(BCG) data generally do not have prominent J
peaks. This paper introduces two phenomena that reduce the prominence of
Jpeaks: the shorter-J phenomenon and the lost-K phenomenon, both of which are
commonly observed in non-standard BCG signals . This paper also proposes three
signal transformation methods that effectively improve the lost-K and shorter-J
phenomena. The methods were evaluated on a time-aligned ECG-BCG dataset with 40
subjects. The results show that based on the transformed signal, simple
J-peak-based methods using only the detection of local maxima or minima show
better performance in locating J-peaks and extracting BCG cycles, especially
for non-standard BCG data.

</details>


### [608] [Towards Generalizable Learning Models for EEG-Based Identification of Pain Perception](https://arxiv.org/abs/2508.11691)
*Mathis Rezzouk,Fabrice Gagnon,Alyson Champagne,Mathieu Roy,Philippe Albouy,Michel-Pierre Coll,Cem Subakan*

Main category: eess.SP

TL;DR: 本研究评估了机器学习模型在跨个体泛化EEG信号以识别疼痛感知方面的性能。结果表明，深度学习模型（特别是图神经网络）比传统模型更能适应不同个体，并提供了一个标准化的数据集供未来研究使用。


<details>
  <summary>Details</summary>
Motivation: 解决当前研究中机器学习模型在跨个体泛化方面的挑战，这种挑战源于EEG信号高跨被试变异性以及现有研究对直接疼痛感知识别的有限关注。

Method: 系统评估了包括传统分类器和深度神经网络分类器在内的多种模型在识别热痛和厌恶性听觉刺激的传感模式方面的跨被试泛化性能。

Result: 深度学习模型在跨被试评估设置中表现出比传统模型更好的性能，尽管性能变异性仍然很高。图神经网络模型表现尤为突出。

Conclusion: 深度学习模型在跨被试泛化方面比传统模型更具韧性，尤其图神经网络模型在捕捉不依赖于被试的EEG信号结构方面显示出巨大潜力。研究提供了预处理后的数据集，为评估未来算法提供了标准化基准。

Abstract: EEG-based analysis of pain perception, enhanced by machine learning, reveals
how the brain encodes pain by identifying neural patterns evoked by noxious
stimulation. However, a major challenge that remains is the generalization of
machine learning models across individuals, given the high cross-participant
variability inherent to EEG signals and the limited focus on direct pain
perception identification in current research. In this study, we systematically
evaluate the performance of cross-participant generalization of a wide range of
models, including traditional classifiers and deep neural classifiers for
identifying the sensory modality of thermal pain and aversive auditory
stimulation from EEG recordings. Using a novel dataset of EEG recordings from
108 participants, we benchmark model performance under both within- and
cross-participant evaluation settings. Our findings show that traditional
models suffered the largest drop from within- to cross-participant performance,
while deep learning models proved more resilient, underscoring their potential
for subject-invariant EEG decoding. Even though performance variability
remained high, the strong results of the graph-based model highlight its
potential to capture subject-invariant structure in EEG signals. On the other
hand, we also share the preprocessed dataset used in this study, providing a
standardized benchmark for evaluating future algorithms under the same
generalization constraints.

</details>


### [609] [Scalable, Technology-Agnostic Diagnosis and Predictive Maintenance for Point Machine using Deep Learning](https://arxiv.org/abs/2508.11692)
*Eduardo Di Santi,Ruixiang Ci,Clément Lefebvre,Nenad Mijatovic,Michele Pugnaloni,Jonathan Brown,Victor Martín,Kenza Saiah*

Main category: eess.SP

TL;DR: 与现有技术不同，我们的方法只需要一个输入。我们应用深度学习模型对电源信号模式进行分类，以确定点式机是正常的还是与任何故障类型相关，精度>99.99%，假阳性<0.01%，假阴性可忽略不计。我们的方法是通用的、与技术无关的，并且已被证明可扩展到部署在现实世界和测试台环境中的多种 electromechanical  التركيبات نقطة آلة。最后，通过使用共形预测，维护人员可以清楚地了解系统输出的确定性，为操作增加了置信度层，并使该方法符合ISO-17359标准。


<details>
  <summary>Details</summary>
Motivation: 为了避免不必要的服务中断，通过在故障发生前检测异常来对点式机进行预防性维护。

Method: 应用深度学习模型到电源信号模式，以对点式机进行分类（正常或与任何故障类型相关）。

Result: 精度>99.99%，假阳性<0.01%，假阴性可忽略不计。该方法是通用的、与技术无关的，并且可扩展到多种 electromechanical  التركيبات نقطة آلة。

Conclusion: 该方法具有通用性和技术无关性，已被证明可扩展至多种机 electromechanical  التركيبات نقطة آلة، في بيئات واقعية ومختبرية. باستخدام التنبؤ المتوافق، يحصل القائم بالصيانة على مؤشر واضح لليقين في مخرجات النظام، مما يضيف طبقة من الثقة للعمليات ويجعل الطريقة متوافقة مع معيار ISO-17359.

Abstract: The Point Machine (PM) is a critical piece of railway equipment that switches
train routes by diverting tracks through a switchblade. As with any critical
safety equipment, a failure will halt operations leading to service
disruptions; therefore, pre-emptive maintenance may avoid unnecessary
interruptions by detecting anomalies before they become failures. Previous work
relies on several inputs and crafting custom features by segmenting the signal.
This not only adds additional requirements for data collection and processing,
but it is also specific to the PM technology, the installed locations and
operational conditions limiting scalability. Based on the available maintenance
records, the main failure causes for PM are obstacles, friction, power source
issues and misalignment. Those failures affect the energy consumption pattern
of PMs, altering the usual (or healthy) shape of the power signal during the PM
movement. In contrast to the current state-of-the-art, our method requires only
one input. We apply a deep learning model to the power signal pattern to
classify if the PM is nominal or associated with any failure type, achieving
>99.99\% precision, <0.01\% false positives and negligible false negatives. Our
methodology is generic and technology-agnostic, proven to be scalable on
several electromechanical PM types deployed in both real-world and test bench
environments. Finally, by using conformal prediction the maintainer gets a
clear indication of the certainty of the system outputs, adding a confidence
layer to operations and making the method compliant with the ISO-17359
standard.

</details>


### [610] [Track Component Failure Detection Using Data Analytics over existing STDS Track Circuit data](https://arxiv.org/abs/2508.11693)
*Francisco López,Eduardo Di Santi,Clément Lefebvre,Nenad Mijatovic,Michele Pugnaloni,Victor Martín,Kenza Saiah*

Main category: eess.SP

TL;DR: 该研究提出了一种基于SVM分类器和STDS电流数据的方法，能够自动识别轨道电路中的15种故障，分类准确率高，可用于改进维护。


<details>
  <summary>Details</summary>
Motivation: 为了改进维护行动，旨在自动识别轨道电路中出现故障的具体组件。

Method: 使用支持向量机（SVM）分类器，将智能列车检测系统（STDS）的电流数据作为故障识别的依据。

Result: 该方法被训练用于对属于3个更广泛类别的15种不同故障进行分类。使用来自10个不同轨道电路的现场数据进行测试，并得到了STDS轨道电路专家和维护人员的验证，所有使用案例均被正确分类。

Conclusion: 该方法能够自动识别15种不同的故障，且所有使用案例均被正确分类，可用于改进维护操作。

Abstract: Track Circuits (TC) are the main signalling devices used to detect the
presence of a train on a rail track. It has been used since the 19th century
and nowadays there are many types depending on the technology. As a general
classification, Track Circuits can be divided into 2 main groups, DC (Direct
Current) and AC (Alternating Current) circuits. This work is focused on a
particular AC track circuit, called "Smart Train Detection System" (STDS),
designed with both high and low-frequency bands. This approach uses STDS
current data applied to an SVM (support vector machine) classifier as a type of
failure identifier. The main purpose of this work consists on determine
automatically which is the component of the track that is failing to improve
the maintenance action. Model was trained to classify 15 different failures
that belong to 3 more general categories. The method was tested with field data
from 10 different track circuits and validated by the STDS track circuit expert
and maintainers. All use cases were correctly classified by the method.

</details>


### [611] [Operational machine learning for park-scale irrigation to support urban cooling](https://arxiv.org/abs/2508.11700)
*Mesut Koçyiğit,Bahman Javadi,Russell Thomson,Sebastian Pfautsch,Oliver Obst*

Main category: eess.SP

TL;DR: SIMPaCT是一个城市公园灌溉系统，通过预测土壤湿度来优化夜间灌溉，以达到城市降温的目的。该系统使用kNN预测器，并通过异常检测和虚拟传感器来保证鲁棒性。实验结果表明，SIMPaCT的预测精度高，优于SARIMA模型。


<details>
  <summary>Details</summary>
Motivation: 城市公园可以缓解局部热量，但灌溉控制通常是为节水而不是降温而调整的。

Method: SIMPaCT收集200个土壤湿度传感器、50个温湿度（TRH）节点和13个气象站的数据，并对每个传感器训练kNN预测器。一个基于规则的异常检测流程用于筛选丢失和卡住的信号，并使用基于模型的检查（Isolation Forest和ARIMA）。当设备发生故障时，一个互信息邻域会选择信息量最大的邻居，并且一个小型多层感知器会提供一个“虚拟传感器”直到修复。

Result: 在所有传感器上，平均绝对误差为0.78%，与更复杂的基线相当；kNN的上四分位数误差（P75）低于SARIMA（分别为0.71%和0.93%）。

Conclusion: SIMPaCT是一个城市公园规模的部署，它将每个区域的土壤湿度预测与夜间灌溉设定点联系起来，以支持城市降温。SIMPaCT是一个运行日常的系统，并将建议的设定点写入现有的控制器以供操作员审查。

Abstract: Urban parks can mitigate local heat, yet irrigation control is usually tuned
for water savings rather than cooling. We report on SIMPaCT (Smart Irrigation
Management for Parks and Cool Towns), a park-scale deployment that links
per-zone soil-moisture forecasts to overnight irrigation set-points in support
of urban cooling. SIMPaCT ingests data from 202 soil-moisture sensors, 50
temperature-relative humidity (TRH) nodes, and 13 weather stations, and trains
a per-sensor k-nearest neighbours (kNN) predictor on short rolling windows
(200-900h). A rule-first anomaly pipeline screens missing and stuck-at signals,
with model-based checks (Isolation Forest and ARIMA). When a device fails, a
mutual-information neighbourhood selects the most informative neighbour and a
small multilayer perceptron supplies a "virtual sensor" until restoration.
Across sensors the mean absolute error was 0.78%, comparable to more complex
baselines; the upper-quartile error (P75) was lower for kNN than SARIMA (0.71%
vs 0.93%). SIMPaCT runs daily and writes proposed set-points to the existing
controller for operator review. This short communication reports an operational
recipe for robust, cooling-oriented irrigation at city-park scale.

</details>


### [612] [Scaling Wideband Massive MIMO Radar via Beamspace Dimension Reduction](https://arxiv.org/abs/2508.11790)
*Oveys Delafrooz Noroozi,Jiyoon Han,Wei Tang,Zhengya Zhang,Upamanyu Madhow*

Main category: eess.SP

TL;DR: 提出了一种可扩展的数字波束形成架构，通过波束空间变换将计算复杂度从O(N^3)降低到O(NlogN)，实现了与全维度方法相当的性能，同时显著降低了计算和训练开销。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统空间处理方法在处理大规模MIMO雷达时面临的计算复杂性问题，该研究旨在开发一种可扩展的数字波束形成架构。

Method: 提出了一种用于宽带大规模MIMO雷达数字波束形成的可扩展架构，该架构利用波束空间中的能量集中来实现计算复杂性的大幅降低，并将阵列扩展性与用于波束空间变换的空间FFT的O(NlogN)复杂度相关联。具体而言，提出了一种用于窗口化波束空间MVDR波束形成的架构，该架构可跨目标和子带进行并行处理。

Result: 通过使用DARPA SOAP项目提供的宽带雷达数据进行评估，证明了所提出的方法在波束形成和干扰抑制方面的有效性。

Conclusion: 所提出的模型在计算和训练开销方面显著降低了复杂性，同时实现了与全维度基准相当的检测性能。

Abstract: We present an architecture for scaling digital beamforming for wideband
massive MIMO radar. Conventional spatial processing becomes computationally
prohibitive as array size grows; for example, the computational complexity of
MVDR beamforming scales as O(N^3) for an N-element array. In this paper, we
show that energy concentration in beamspace provides the basis for drastic
complexity reduction, with array scaling governed by the O(NlogN) complexity of
the spatial FFT used for beamspace transformation. Specifically, we propose an
architecture for windowed beamspace MVDR beamforming, parallelized across
targets and subbands, and evaluate its efficacy for beamforming and
interference suppression for government-supplied wideband radar data from the
DARPA SOAP (Scalable On-Array Processing) program. We demonstrate that our
approach achieves detection performance comparable to full-dimensional
benchmarks while significantly reducing computational and training overhead,
and provide insight into tradeoffs between beamspace window size and FFT
resolution in balancing complexity, detection accuracy, and interference
suppression.

</details>


### [613] [Digital Post-Distortion Architectures for Nonlinear Power Amplifiers: Volterra and Kernel Methods](https://arxiv.org/abs/2508.11792)
*Daniel Schäufele,Jochen Fink,Renato L. G. Cavalcante,Sławomir Stańczak*

Main category: eess.SP

TL;DR: This paper explores digital post-distortion (DPoD) to address PA power consumption and nonlinear distortions in 5G UEs. It proposes DPoD in the time-domain with frequency-domain equalization and a novel kernel method for reduced complexity, showing significant performance improvements in simulations.


<details>
  <summary>Details</summary>
Motivation: The power amplifier (PA) in 5G UEs consumes significant power, especially at the cell edge. Reducing power backoff improves PA efficiency but introduces nonlinear distortions. Existing solutions like digital pre-distortion increase UE complexity and power consumption. DPoD is explored as an alternative that compensates for distortions at the base station.

Method: This study explores digital post-distortion (DPoD) techniques, analyzing challenges and advantages in time-domain, frequency-domain, and DFT-s-domain. It proposes posing the complex-valued nonlinearity compensation problem in a real Hilbert space and introduces an equivalent kernel method to reduce algorithmic complexity.

Result: Simulations validate the analysis, showing that the proposed algorithm significantly improves performance compared to state-of-the-art algorithms. The findings suggest that time-domain DPoD with frequency-domain channel equalization offers a good balance between low computational complexity and efficient nonlinearity compensation.

Conclusion: In this study, implementing DPoD in the time-domain, complemented by frequency-domain channel equalization, strikes a good balance between low computational complexity and efficient nonlinearity compensation. Memory must be taken into account regardless of the PA's memory. Posing the complex-valued problem in a real Hilbert space emphasizes potential performance enhancements. An equivalent kernel method can reduce algorithmic complexity compared to the traditional Volterra series.

Abstract: In modern 5G user equipments (UEs), the power amplifier (PA) contributes
significantly to power consumption during uplink transmissions, especially in
cell-edge scenarios. While reducing power backoff can enhance PA efficiency, it
introduces nonlinear distortions that degrade signal quality. Existing
solutions, such as digital pre-distortion, require complex feedback mechanisms
for optimal performance, leading to increased UE complexity and power
consumption. Instead, in this study we explore digital post-distortion (DPoD)
techniques, which compensate for these distortions at the base station,
leveraging its superior computational resources. In this study, we conduct an
comprehensive study concerning the challenges and advantages associated with
applying DPoD in time-domain, frequency-domain, and DFT-s-domain. Our findings
suggest that implementing DPoD in the time-domain, complemented by
frequency-domain channel equalization, strikes a good balance between low
computational complexity and efficient nonlinearity compensation. In addition,
we demonstrate that memory has to be taken into account regardless of the
memory of the PA. Subsequently, we show how to pose the complex-valued problem
of nonlinearity compensation in a real Hilbert space, emphasizing the potential
performance enhancements as a result. We then discuss the traditional Volterra
series and show an equivalent kernel method that can reduce algorithmic
complexity. Simulations validate the results of our analysis and show that our
proposed algorithm can significantly improve performance compared to
state-of-the-art algorithms.

</details>


### [614] [Autonomous Driving with RSMA-Enabled Finite Blocklength Transmissions: Ergodic Performance Analysis and Optimization](https://arxiv.org/abs/2508.12012)
*Yi Wang,Yingyang Chen,Li Wang,Donghong Cai,Xiaofan Li,Pingzhi Fan*

Main category: eess.SP

TL;DR: 该研究提出了一种用于高移动性自动驾驶场景的 RSMA 方案，通过联合优化功率分配和速率分裂来提高遍历性能、降低块长度和 BLER，并保证用户公平性。


<details>
  <summary>Details</summary>
Motivation: 为了应对高移动性自动驾驶中超可靠低延迟通信 (URLLC) 的严格要求，本研究实现了 RSMA 有限块长度 (FBL) 传输，并明确评估了遍历性能。

Method: 首先，推导了 RSMA 的遍历和速率的闭式下界，考虑了车辆速度、车辆位置、每路码流的功率分配、块长度和块错误率 (BLER)。然后，为了进一步提高遍历和速率，同时满足服务质量 (QoS) 速率约束，我们联合优化了全局功率系数、私有功率分配和速率分裂。梯度下降用于首先根据其和速率解调整全局功率系数，该系数控制公共码流的功率状态，以实现动态激活或去激活。如果激活，则优化私有功率分配和速率分裂以满足最小传输约束；如果停用，则使用顺序二次规划进行私有功率分配。

Result: RSMA 方案显著提高了遍历性能，降低了块长度和块错误率，超过了具有平均私有功率和 SDMA 的 RSMA 对手。我们的方法还保证了用户速率，提高了网络公平性。

Conclusion: 所提出的 RSMA 方案显著提高了遍历性能，降低了块长度和块错误率，超过了具有平均私有功率和空分多址 (SDMA) 的 RSMA 对手。此外，我们还证明了我们的方法可以保证信道条件最差的用户的速率，从而提高网络的公平性。

Abstract: Rate-splitting multiple access (RSMA) is a key technology for next-generation
multiple access systems due to its robustness against imperfect channel state
information (CSI). This makes RSMA particularly suitable for high-mobility
autonomous driving, where ultra-reliable and low-latency communication (URLLC)
is essential. To address the stringent requirements, this study enables RSMA
finite blocklength (FBL) transmissions and explicitly evaluates the ergodic
performance. We derive the closed-form lower bound for the ergodic sum-rate of
RSMA, considering vital factors such as the vehicle velocities, vehicle
positions, power allocation of each stream, blocklengths, and block error rates
(BLERs). To further enhance the ergodic sum-rate while complying with quality
of service (QoS) rate constraints, we jointly optimize the global power
coefficient, private power distribution, and common rate splitting. Guided by
gradient descent, we first adjust the global power coefficient based on its
sum-rate solution. This parameter regulates the power state of the common
stream, allowing for dynamic activation or deactivation: if active, we optimize
the private power distribution and adjust the common rate splitting to meet
minimum transmission constraints; if inactive, we use the sequential quadratic
programming for private power distribution optimization. Simulation results
confirm that our RSMA scheme significantly improves the ergodic performance,
reduces blocklength and BLER, surpassing the RSMA counterpart with average
private power and space division multiple access (SDMA). Furthermore, our
approach is validated to guarantee the rates for users with the poorest channel
conditions, thereby enhancing fairness across the network.

</details>


### [615] [A Generalized Multidimensional Chinese Remainder Theorem (MD-CRT) for Multiple Integer Vectors](https://arxiv.org/abs/2508.12099)
*Guangpu Guo,Xiang-Gen Xia*

Main category: eess.SP

TL;DR: 本文研究了多维中国剩余定理（MD-CRT），解决了多维向量的唯一可确定范围和最大动态范围的实现条件问题，并提出了相应的算法。研究结果在多维信号处理中具有潜在应用价值。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决多维中国剩余定理（MD-CRT）的两个基本问题：在无先验信息的情况下，多维向量的唯一可确定范围是多少？以及在什么条件下可以实现最大可能动态范围？

Method: 本文首先推导了在无先验信息的情况下多维向量的唯一可确定范围，并提出了一种实现该范围的算法。然后，针对仅涉及两个整数向量的特殊情况，研究了实现最大可能动态范围的条件，并得出了一个新的条件。

Result: 本文推导了多维向量的唯一可确定范围，并提出了一种实现该范围的算法。对于两个整数向量的特殊情况，找到了实现最大动态范围的新条件，该条件在降维到1时优于现有的一维标量整数的广义CRT条件。

Conclusion: 本文得出了关于多维中国剩余定理（MD-CRT）的两个基本问题的答案，并提出了相应的算法。研究结果为多维信号处理中的频率检测提供了新的可能。

Abstract: Chinese remainder theorem (CRT) is widely applied in cryptography, coding
theory, and signal processing. It has been extended to the multidimensional CRT
(MD-CRT), which reconstructs an integer vector from its vector remainders
modulo multiple integer matrices. This paper investigates a generalized MD-CRT
for multiple integer vectors, where the goal is to determine multiple integer
vectors from multiple vector residue sets modulo multiple integer
matrices.Comparing to the existing generalized CRT for multiple scalar
integers, the challenge is that the moduli in MD-CRT are matrices that do not
commute and the corresponding uniquely determinable range is multidimensional
and the inclusion relationship is much more complicated. In this paper,we
address two fundamental questions regarding the generalized MD-CRT. The first
question concerns the uniquely determinable range of multiple integer vectors
when no prior information about them is available. The second question is about
the conditions under which the maximal possible dynamic range can be
achieved.To answer these two questions, we first derive a uniquely determinable
range without prior information and accordingly propose an algorithm to achieve
it. A special case involving only two integer vectors is investigated for the
second question, leading to a new condition for achieving the maximal possible
dynamic range. Interestingly, this newly obtained condition, when the dimension
is reduced to $1$, is even better than the existing ones for the conventional
generalized CRT for scalar integers.These results may have applications for
frequency detection in multidimensional signal processing.

</details>


### [616] [RFSS: A Comprehensive Multi-Standard RF Signal Source Separation Dataset with Advanced Channel Modeling](https://arxiv.org/abs/2508.12106)
*Hao Chen,Rui Jin,Dayuan Tan*

Main category: eess.SP

TL;DR: RFSS是一个包含52,847个真实多标准射频信号的开源数据集，支持GSM、UMTS、LTE和5G NR。CNN-LSTM在源分离任务中的表现优于ICA和NMF，SINR提高了26.7 dB。


<details>
  <summary>Details</summary>
Motivation: 随着无线通信系统（2G/3G/4G/5G）的快速发展和复杂电磁环境的出现，需要先进的信号源分离技术。

Method: 提出了一种名为RFSS（RF信号源分离）的综合开源数据集，其中包含52,847个符合3GPP标准的真实多标准射频信号样本。该框架生成了符合GSM、UMTS、LTE和5G NR标准的真实基带信号，并包含先进的信道建模，如多径衰落、高达8x8天线的MIMO处理以及真实的干扰场景。

Result: 实验验证表明，CNN-LSTM架构在源分离任务中表现出优越的性能，SINR（信噪比）提高了26.7 dB，显著优于传统的ICA（15.2 dB）和NMF（18.3 dB）方法。

Conclusion: RFSS数据集促进了射频信号分离、认知无线电和机器学习领域的可复现研究，并保持完全开源可访问性。

Abstract: The rapid evolution of wireless communication systems has created complex
electromagnetic environments where multiple cellular standards (2G/3G/4G/5G)
coexist, necessitating advanced signal source separation techniques. We present
RFSS (RF Signal Source Separation), a comprehensive open-source dataset
containing 52,847 realistic multi-standard RF signal samples with complete 3GPP
standards compliance. Our framework generates authentic baseband signals for
GSM, UMTS, LTE, and 5G NR with advanced channel modeling including multipath
fading, MIMO processing up to 8 by 8 antennas, and realistic interference
scenarios. Experimental validation demonstrates superior performance of
CNN-LSTM architectures achieving 26.7 dB SINR improvement in source separation
tasks, significantly outperforming traditional ICA (15.2 dB) and NMF (18.3 dB)
approaches. The RFSS dataset enables reproducible research in RF source
separation, cognitive radio, and machine learning applications while
maintaining complete open-source accessibility

</details>


### [617] [Effect of Phase Shift Errors on the Security of UAV-assisted STAR-RIS IoT Networks](https://arxiv.org/abs/2508.12114)
*Mustafa Gusaibat,Mohammed Hnaish,Abdelhamid Salem,Khaled Rabie,Zubair Md Fadlullah,Wali Ullah Khan,Mohamad A. Alawad,Yazeed Alkhrijah*

Main category: eess.SP

TL;DR: 本文研究了UAV上STAR-RIS辅助的IoT系统中相位估计误差对保密性能的影响，并通过优化UAV位置最大化了加权和保密率（WSSR）。


<details>
  <summary>Details</summary>
Motivation: 为了研究UAV抖动和气流等实际不完美性对STAR-RIS相位移的影响，以及由此对网络安全造成的损害，本文研究了相位移误差对UAV上STAR-RIS辅助的IoT系统保密性能的影响。

Method: 本文推导了不完美相位调整下的遍历保密率的解析闭合形式表达式，并使用基于线性网格的算法解决了优化UAV放置以最大化加权和保密率（WSSR）的问题。

Result: 推导了不完美相位调整下的遍历保密率的解析闭合形式表达式，并通过优化UAV位置解决了最大化加权和保密率（WSSR）的问题，并通过蒙特卡洛模拟验证了分析推导的正确性。

Conclusion: UAV-mounted STAR-RIS-assisted NOMA系统在相位估计误差下的保密性能受到影响，但通过优化UAV位置可以最大化加权和保密率（WSSR），为STAR-RIS在安全UAV驱动的物联网网络中的实际应用提供了关键见解。

Abstract: Unmanned aerial vehicles (UAV)-mounted simultaneous transmitting and
reflecting reconfigurable intelligent surface (STAR-RIS) systems can provide
full-dimensional coverage and flexible deployment opportunities in future
6G-enabled IoT networks. However, practical imperfections such as jittering and
airflow of UAV could affect the phase shift of STAR-RIS, and consequently
degrade network security. In this respect, this paper investigates the impact
of phase shift errors on the secrecy performance of UAV-mounted
STAR-RIS-assisted IoT systems. More specifically, we consider a UAV-mounted
STAR-RIS-assisted non-orthogonal multiple access (NOMA) system where IoT
devices are grouped into two groups: one group on each side of the STAR-RIS.
The nodes in each group are considered as potential Malicious nodes for the
ones on the other side. By modeling phase estimation errors using a von Mises
distribution, analytical closed-form expressions for the ergodic secrecy rates
under imperfect phase adjustment are derived. An optimization problem to
maximize the weighted sum secrecy rate (WSSR) by optimizing the UAV placement
is formulated and is then solved using a linear grid-based algorithm. Monte
Carlo simulations are provided to validate the analytical derivations. The
impact of phase estimation errors on system's secrecy performance is analyzed,
providing critical insights for the practical realisation of STAR-RIS
deployments for secure UAV-enabled IoT networks.

</details>


### [618] [ATLAS: AI-Native Receiver Test-and-Measurement by Leveraging AI-Guided Search](https://arxiv.org/abs/2508.12204)
*Mauro Belgiovine,Suyash Pradhan,Johannes Lange,Michael Löhning,Kaushik Chowdhury*

Main category: eess.SP

TL;DR: ATLAS 是一种 AI 驱动的测试方法，可以为 AI 无线接收机模型生成测试用例，以解决其可解释性差的问题。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏可解释性以及在发生故障时对网络功能造成重大风险，行业在采用 AI 无线接收机方面进展缓慢。

Method: ATLAS 使用基于梯度的优化来生成测试用例，以在线方式探测可能导致故障的特定配置，从而避免了对所有环境和信道条件的穷举测试。

Result: ATLAS 确定了 AI 驱动的 DeepRx（包括完整训练和部分训练的变体）在特定移动性、信道延迟扩展和噪声组合下表现不佳，而经典接收器则表现更好。

Conclusion: ATLAS 通过减少每次发现故障所需的测试数量来提高效率，与网格搜索相比，在 3 个参数的输入优化问题上减少了 19%，并且随着变量数量的增加，其计算成本的增长速度比网格搜索慢得多，从而克服了 AI 模型可解释性差的缺点。

Abstract: Industry adoption of Artificial Intelligence (AI)-native wireless receivers,
or even modular, Machine Learning (ML)-aided wireless signal processing blocks,
has been slow. The main concern is the lack of explainability of these trained
ML models and the significant risks posed to network functionalities in case of
failures, especially since (i) testing on every exhaustive case is infeasible
and (ii) the data used for model training may not be available. This paper
proposes ATLAS, an AI-guided approach that generates a battery of tests for
pre-trained AI-native receiver models and benchmarks the performance against a
classical receiver architecture. Using gradient-based optimization, it avoids
spanning the exhaustive set of all environment and channel conditions; instead,
it generates the next test in an online manner to further probe specific
configurations that offer the highest risk of failure. We implement and
validate our approach by adopting the well-known DeepRx AI-native receiver
model as well as a classical receiver using differentiable tensors in NVIDIA's
Sionna environment. ATLAS uncovers specific combinations of mobility, channel
delay spread, and noise, where fully and partially trained variants of
AI-native DeepRx perform suboptimally compared to the classical receivers. Our
proposed method reduces the number of tests required per failure found by 19%
compared to grid search for a 3-parameters input optimization problem,
demonstrating greater efficiency. In contrast, the computational cost of the
grid-based approach scales exponentially with the number of variables, making
it increasingly impractical for high-dimensional problems.

</details>


### [619] [Weighted Covariance Intersection for Range-based Distributed Cooperative Localization of Multi-Agent Systems](https://arxiv.org/abs/2508.12207)
*Chenxin Tu,Xiaowei Cui,Gang Liu,Mingquan Lu*

Main category: eess.SP

TL;DR: 该研究提出了一种加权协方差交集（WCI）方法，用于改进3D分布式協同定位的精度，解决了经典方法的不足，并在仿真中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决了分布式協同定位（DCL）在3D场景下面临的经典协方差交集（CI）优化准则存在的尺度不平衡和相关性不匹配问题，以及在3D场景下状态分量尺度和可观测性差异导致的性能严重下降问题。

Method: 提出了一种加权协方差交集（WCI）机制，并将其应用于基于距离的3D分布式協同定位，设计了一种用于融合多个距离测量的并发融合策略，并基于惯性导航系统（INS）的误差传播规则设计了权重矩阵。

Result: 仿真结果表明，所提出的WCI显著提高了協同定位性能，并且分布式方法在鲁棒性、可扩展性方面优于集中式方法，更适用于大规模集群。

Conclusion: 提出了一种加权协方差交集（WCI）方法，用于解决分布式協同定位（DCL）中3D场景下的尺度不平衡和相关性不匹配问题，并通过仿真结果证明了WCI相比经典CI的优越性，同时分布式方法在鲁棒性、可扩展性方面优于集中式方法，更适用于大规模集群。

Abstract: Precise localization of multi-agent systems (MAS) in harsh environments is a
critical challenge for swarm applications, and cooperative localization is
considered a key solution to this issue. Among all solutions, distributed
cooperative localization (DCL) has garnered widespread attention due to its
robustness and scalability. The main challenge of DCL lies in how to fuse
relative measurements between agents under unknown correlations. To address
this, covariance intersection (CI) was introduced to DCL. However, the
classical CI optimization criteria suffer from issues such as scale imbalance
and correlation mismatch during the fusion process. These deficiencies are not
as pronounced in 2D scenarios, where the state space is relatively simple and
the observability of each state component is well. However, in 3D scenarios,
where the state space is more complex and there are significant disparities in
the scale and observability of state components, performance degradation
becomes severe. This necessitates the design of specialized mechanisms to
improve the data fusion process. In this paper, we identify three main
drawbacks of the classical CI optimization criteria in recursive filtering and
introduce a weighting mechanism, namely weighted covariance intersection (WCI),
to improve its performance. We then introduce WCI into range-based distributed
cooperative localization in 3D scenarios, developing a concurrent fusion
strategy for multiple distance measurements and designing a weighting matrix
based on the error propagation rule of the inertial navigation system (INS).
Simulation results demonstrate that the proposed WCI significantly enhances
cooperative localization performance compared to classical CI, while the
distributed approach outperforms the centralized approach in terms of
robustness, scalability, and is more suitable for large-scale swarms.

</details>


### [620] [Towards Generalizable Human Activity Recognition: A Survey](https://arxiv.org/abs/2508.12213)
*Yize Cai,Baoshen Guo,Flora Salim,Zhiqing Hong*

Main category: eess.SP

TL;DR: 本综述对IMU基础的泛化人类活动识别（HAR）进行了全面的回顾，重点关注解决用户、传感器位置或环境变化引起的泛化能力问题。文章回顾了229篇论文和25个数据集，对模型和数据驱动的方法进行了分类，并讨论了该领域的挑战和未来方向，包括大型语言模型和物理信息推理的应用。


<details>
  <summary>Details</summary>
Motivation: IMU基础的人类活动识别（HAR）是可穿戴AI的关键组成部分，近年来引起了学术界和工业界的广泛关注。然而，由于用户、传感器位置或环境变化引起的域偏移，其泛化能力仍然是实际应用中的关键障碍。因此，本综述旨在探索IMU基础泛化HAR领域，为该领域提供一个广泛而深刻的概述。

Method: 本综述回顾了229篇研究论文和25个公开数据集，首先介绍了IMU基础HAR任务的背景和整体框架，以及面向泛化的训练设置。然后，从两个角度对代表性方法进行了分类：(i)以模型为中心的方法，包括预训练方法、端到端方法和基于大型语言模型（LLM）的学习方法；(ii)以数据为中心的方法，包括多模态学习和数据增强技术。此外，还总结了该领域广泛使用的数据集以及相关的工具和基准。

Result: 本综述对IMU基础泛化HAR领域进行了全面的回顾，分类了模型驱动和数据驱动的方法，总结了常用的数据集、工具和基准。此外，还讨论了IMU基础HAR的广泛适用性，并指出了未来的研究方向。

Conclusion: 虽然在特定场景下，基于IMU的人类活动识别（HAR）性能有所提高，但其泛化能力仍然是广泛实际应用的关键障碍。本篇综述探讨了IMU基础的泛化HAR领域，对229篇研究论文和25个公开数据集进行了回顾，并讨论了该领域的普遍适用性，最后讨论了持续存在的挑战（如数据稀缺、高效训练和可靠评估）并概述了未来的方向，包括基础模型和大型语言模型的应用、物理信息和上下文感知推理、生成模型以及资源高效的训练和推理。

Abstract: As a critical component of Wearable AI, IMU-based Human Activity Recognition
(HAR) has attracted increasing attention from both academia and industry in
recent years. Although HAR performance has improved considerably in specific
scenarios, its generalization capability remains a key barrier to widespread
real-world adoption. For example, domain shifts caused by variations in users,
sensor positions, or environments can significantly decrease the performance in
practice. As a result, in this survey, we explore the rapidly evolving field of
IMU-based generalizable HAR, reviewing 229 research papers alongside 25
publicly available datasets to provide a broad and insightful overview. We
first present the background and overall framework of IMU-based HAR tasks, as
well as the generalization-oriented training settings. Then, we categorize
representative methodologies from two perspectives: (i) model-centric
approaches, including pre-training method, end-to-end method, and large
language model (LLM)-based learning method; and (ii) data-centric approaches,
including multi-modal learning and data augmentation techniques. In addition,
we summarize widely used datasets in this field, as well as relevant tools and
benchmarks. Building on these methodological advances, the broad applicability
of IMU-based HAR is also reviewed and discussed. Finally, we discuss persistent
challenges (e.g., data scarcity, efficient training, and reliable evaluation)
and also outline future directions for HAR, including the adoption of
foundation and large language models, physics-informed and context-aware
reasoning, generative modeling, and resource-efficient training and inference.
The complete list of this survey is available at
https://github.com/rh20624/Awesome-IMU-Sensing, which will be updated
continuously.

</details>


### [621] [A Novel Symbol Level Precoding based AFDM Transmission Framework: Offloading Equalization Burden to Transmitter Side](https://arxiv.org/abs/2508.12215)
*Shuntian Tang,Zesong Fei,Xinyi Wang,Dongkai Zhou,Zhiqiang Wei,Christos Masouros*

Main category: eess.SP

TL;DR: 本研究提出了一种新的AFDM传输框架，通过符号级预编码（SLP）将接收端的计算复杂度转移到基站，实现了无需信道估计或均衡的直接符号检测。该框架利用稀疏贝叶斯学习（SBL）进行上行信道估计，并通过SOCP优化下行波形设计，最终在降低复杂度的同时保证了性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决AFDM在高接收端计算复杂度方面的主要障碍，提出了一种新颖的基于符号级预编码（SLP）的AFDM传输框架。

Method: 提出了一种新颖的基于符号级预编码（SLP）的AFDM传输框架。在下行链路中，BS利用SLP技术，基于估计的上行链路信道状态信息（CSI）和信道互易性来设计传输波形。推导了贝叶斯Cramer-Rao界（BCRB）来表征理论性能极限。在下行链路中，BS采用SLP技术，根据估计的上行链路信道状态信息（CSI）和信道互易性来设计传输波形。该优化问题被表述为二阶锥规划（SOCP）问题，并通过拉格朗日函数和KKT条件对其对偶问题进行了研究。

Result: 所提出的SBL估计器在精度和抗离网效应能力方面优于传统的OMP，而基于SLP的波形设计方案实现了与传统AFDM接收器相当的性能，同时显著降低了接收器处的计算复杂度。

Conclusion: 仿真结果表明，所提出的SBL估计器在精度和抗离网效应能力方面优于传统的OMP，而基于SLP的波形设计方案实现了与传统AFDM接收器相当的性能，同时显著降低了接收器处的计算复杂度，验证了该方法的实用性。

Abstract: Affine Frequency Division Multiplexing (AFDM) has attracted considerable
attention for its robustness to Doppler effects. However, its high
receiver-side computational complexity remains a major barrier to practical
deployment. To address this, we propose a novel symbol-level precoding
(SLP)-based AFDM transmission framework, which shifts the signal processing
burden in downlink communications from user side to the base station (BS),
enabling direct symbol detection without requiring channel estimation or
equalization at the receiver. Specifically, in the uplink phase, we propose a
Sparse Bayesian Learning (SBL) based channel estimation algorithm by exploiting
the inherent sparsity of affine frequency (AF) domain channels. In particular,
the sparse prior is modeled via a hierarchical Laplace distribution, and
parameters are iteratively updated using the Expectation-Maximization (EM)
algorithm. We also derive the Bayesian Cramer-Rao Bound (BCRB) to characterize
the theoretical performance limit. In the downlink phase, the BS employs the
SLP technology to design the transmitted waveform based on the estimated uplink
channel state information (CSI) and channel reciprocity. The resulting
optimization problem is formulated as a second-order cone programming (SOCP)
problem, and its dual problem is investigated by Lagrangian function and
Karush-Kuhn-Tucker conditions. Simulation results demonstrate that the proposed
SBL estimator outperforms traditional orthogonal matching pursuit (OMP) in
accuracy and robustness to off-grid effects, while the SLP-based waveform
design scheme achieves performance comparable to conventional AFDM receivers
while significantly reducing the computational complexity at receiver,
validating the practicality of our approach.

</details>


### [622] [Polarization Reconfigurable Transmit-Receive Beam Alignment with Interpretable Transformer](https://arxiv.org/abs/2508.12298)
*Seungcheol Oh,Han Han,Joongheon Kim,Sean Kwon*

Main category: eess.SP

TL;DR: 该研究提出了一种新的深度学习框架，利用可解释 Transformer 来优化大规模 MIMO 系统中的极化和波束形成，以降低导频开销并提高性能。


<details>
  <summary>Details</summary>
Motivation: 旨在于大规模 MIMO 系统中，通过联合设计极化和波束形成向量，以实现同时的信道重构和波束对齐，从而显着提高波束形成增益。然而，在没有信道状态信息 (CSI) 的情况下联合优化极化和波束形成向量是一个挑战性任务，因为去极化增加了信道维度，而大规模 MIMO 系统通常具有有限的射频链导致的低维导频测量。

Method: 提出了一种基于可解释 Transformer 的深度学习框架，用于联合设计极化和波束形成向量，以在接收导频的序列基础上，主动设计导频和传输阶段的极化和波束形成向量。

Result: 数值实验证明，我们提出的框架在性能上优于现有的非自适应和自适应数据驱动方法。此外，我们利用所提出框架的可解释性来分析模型的学习能力。

Conclusion: 所提出的基于可解释 Transformer 的深度学习框架能够显着降低该类系统的导频开销，并提供优于现有非自适应和自适应数据驱动方法的性能。

Abstract: Recent advancement in next generation reconfigurable antenna and fluid
antenna technology has influenced the wireless system with polarization
reconfigurable (PR) channels to attract significant attention for promoting
beneficial channel condition. We exploit the benefit of PR antennas by
integrating such technology into massive multiple-input-multiple-output (MIMO)
system. In particular, we aim to jointly design the polarization and
beamforming vectors on both transceivers for simultaneous channel
reconfiguration and beam alignment, which remarkably enhance the beamforming
gain. However, joint optimization over polarization and beamforming vectors
without channel state information (CSI) is a challenging task, since
depolarization increases the channel dimension; whereas massive MIMO systems
typically have low-dimensional pilot measurement from limited radio frequency
(RF) chain. This leads to pilot overhead because the transceivers can only
observe low-dimensional measurement of the high-dimension channel. This paper
pursues the reduction of the pilot overhead in such systems by proposing to
employ \emph{interpretable transformer}-based deep learning framework on both
transceivers to actively design the polarization and beamforming vectors for
pilot stage and transmission stage based on the sequence of accumulated
received pilots. Numerical experiments demonstrate the significant performance
gain of our proposed framework over the existing non-adaptive and active
data-driven methods. Furthermore, we exploit the interpretability of our
proposed framework to analyze the learning capabilities of the model.

</details>


### [623] [Jamming Identification with Differential Transformer for Low-Altitude Wireless Networks](https://arxiv.org/abs/2508.12320)
*Pengyu Wang,Zhaocheng Wang,Tianqi Mao,Weijie Yuan,Haijun Zhang,George K. Karagiannidis*

Main category: eess.SP

TL;DR: 提出了一种改进的差分 Transformer 框架，用于无线干扰识别，显著提高了对恶意攻击的抵抗能力。


<details>
  <summary>Details</summary>
Motivation: 低空无线网络（如无人机终端）易受电磁干扰，传统的基于深度学习的干扰识别方案容易受到对抗性样本的攻击，导致鲁棒性下降。因此，需要一种能够提高鲁棒性的无线干扰识别方法。

Method: 提出了一种差分 Transformer 框架，包括差分 Transformer 网络用于区分干扰信号，通过在差分方式下执行自注意力操作来克服传统方法的注意噪声；提出了一种随机遮蔽训练策略，通过补丁分区机制创建并行的特征提取分支，每个分支操作于不同的随机遮蔽补丁子集，以约束对抗性扰动在网络中的传播；引入了一个新的一致性训练框架，通过双分支正则化来增强对抗性鲁棒性。

Result: 仿真结果表明，所提出的方法在提高对对抗性样本的鲁棒性方面优于现有方法。

Conclusion: 提出的差分 Transformer 框架通过差分方式执行自注意力操作，并结合随机遮蔽训练策略和一致性训练框架，在区分干扰信号和提高网络鲁棒性方面优于现有方法，能够有效抵抗对抗性样本的攻击。

Abstract: Wireless jamming identification, which detects and classifies electromagnetic
jamming from non-cooperative devices, is crucial for emerging low-altitude
wireless networks consisting of many drone terminals that are highly
susceptible to electromagnetic jamming. However, jamming identification schemes
adopting deep learning (DL) are vulnerable to attacks involving carefully
crafted adversarial samples, resulting in inevitable robustness degradation. To
address this issue, we propose a differential transformer framework for
wireless jamming identification. Firstly, we introduce a differential
transformer network in order to distinguish jamming signals, which overcomes
the attention noise when compared with its traditional counterpart by
performing self-attention operations in a differential manner. Secondly, we
propose a randomized masking training strategy to improve network robustness,
which leverages the patch partitioning mechanism inherent to transformer
architectures in order to create parallel feature extraction branches. Each
branch operates on a distinct, randomly masked subset of patches, which
fundamentally constrains the propagation of adversarial perturbations across
the network. Additionally, the ensemble effect generated by fusing predictions
from these diverse branches demonstrates superior resilience against
adversarial attacks. Finally, we introduce a novel consistent training
framework that significantly enhances adversarial robustness through dualbranch
regularization. Simulation results demonstrate that our proposed methodology is
superior to existing methods in boosting robustness to adversarial samples.

</details>


### [624] [Coherent Compensation-Based Sensing for Long-Range Targets in Integrated Sensing and Communication System](https://arxiv.org/abs/2508.12371)
*Lin Wang,Zhiqing Wei,Xu Chen,Zhiyong Feng*

Main category: eess.SP

TL;DR: 对于 6G 具有光谱和能源效率优势的集成传感和通信 (ISAC) 系统，可以解决 OFDM 信号的 ISI 和 ICI 问题，以及远距离目标检测中的近距离目标干扰问题，通过提出的基于 MUSIC 和 LS 的空间信号分离和基于相干补偿的感知信号处理方法，可以提高 RDM 的信噪比和检测概率。


<details>
  <summary>Details</summary>
Motivation: 为了解决正交频分复用 (OFDM) 信号在往返延迟超过循环前缀 (CP) 持续时间时存在的符号间干扰 (ISI) 和载波间干扰 (ICI) 问题，以及检测远距离目标时，由于近距离目标的反射回波功率远大于远距离目标，导致波束覆盖近距离目标的问题。

Method: 提出了一种基于多信号分类 (MUSIC) 和最小二乘 (LS) 的空间信号分离方法来分离从不同目标反射的回波信号。此外，还提出了一种基于相干补偿的接收端感知信号处理方法，以提高生成具有更高信噪比的距离-多普勒图 (RDM) 的 OFDM 块的信噪比。

Result: 仿真结果表明，与二维快速傅里叶变换 (2D-FFT) 方法相比，所提出的方法将 500 米处目标信噪比提高了 10 分贝。此外，与基准方法相比，检测概率也得到了显着提高。

Conclusion: 所提出的方法在 500 米处的目标的信噪比提高了 10 分贝，并且与基准方法相比，检测概率也得到了显着提高。

Abstract: Integrated sensing and communication (ISAC) is a promising candidate
technology for 6G due to its improvement in spectral efficiency and energy
efficiency. Orthogonal frequency division multiplexing (OFDM) signal is a
mainstream candidate ISAC waveform. However, there are inter-symbol
interference (ISI) and inter-carrier interference (ICI) when the round-trip
delay exceeds the cyclic prefix (CP) duration for OFDM signals, which limits
the maximum sensing range of ISAC system. When detecting a long-range target,
the wide beam inevitably covers the close-range target, of which the echo's
power is much larger than that of the long-range target. In order to tackle the
above problem, a multiple signal classification (MUSIC) and least squares
(LS)-based spatial signal separation method is proposed to separate the echo
signals reflected from different targets. Moreover, a coherent
compensation-based sensing signal processing method at the receiver is proposed
to enhance the signal to interference plus noise power ratio (SINR) of the OFDM
block for generating the range-Doppler map (RDM) with higher SINR. Simulation
results reveal that the proposed method greatly enhances the SINR of RDM by 10
dB for a target at 500 m compared with two-dimensional fast Fourier transform
(2D-FFT) method. Besides, the detection probability is also significantly
improved compared to the benchmarking method.

</details>


### [625] [On the Extension of Differential Beamforming Theory to Arbitrary Planar Arrays of First-Order Elements](https://arxiv.org/abs/2508.12403)
*Federico Miotello,Davide Albertini,Alberto Bernardini*

Main category: eess.SP

TL;DR: 提出了一种广义模态匹配框架，用于频率不变的差分波束成形，解决了真实换能器频率依赖性方向性问题，实现了跨频率、几何和噪声条件的稳健性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统差分波束成形方法假设阵元为全向性，而真实换能器表现出频率依赖性方向性这一限制，该研究提出了新的方法。

Method: 提出了一种广义模态匹配框架，用于频率不变的差分波束成形，适用于一阶定向元件的无约束平面阵列。该方法通过将期望的波束图表示为截断的圆谐展开并将其拟合到实际元件响应，从而适应任意的平面几何形状和元件方向。

Result: 仿真结果证实，在设计阶段就考虑传感器方向性，能够在不同频率、几何形状和噪声条件下实现精确且鲁棒的性能。

Conclusion: 该方法通过在设计阶段考虑传感器方向性，实现了跨越不同频率、几何形状和噪声条件的精确稳健的性能。

Abstract: Small-size acoustic arrays exploit spatial diversity to achieve capabilities
beyond those of single-element devices, with applications ranging from
teleconferencing to immersive multimedia. A key requirement for broadband array
processing is a frequency-invariant spatial response, which ensures consistent
directivity across wide bandwidths and prevents spectral coloration.
Differential beamforming offers an inherently frequency-invariant solution by
leveraging pressure differences between closely spaced elements of small-size
arrays. Traditional approaches, however, assume the array elements to be
omnidirectional, whereas real transducers exhibit frequency-dependent
directivity that can degrade performance if not properly modeled. To address
this limitation, we propose a generalized modal matching framework for
frequency-invariant differential beamforming, applicable to unconstrained
planar arrays of first-order directional elements. By representing the desired
beampattern as a truncated circular harmonic expansion and fitting it to the
actual element responses, our method accommodates arbitrary planar geometries
and element orientations. This approach enables the synthesis of beampatterns
of any order and steering direction without imposing rigid layout requirements.
Simulations confirm that accounting for sensor directivity at the design stage
yields accurate and robust performance across varying frequencies, geometries,
and noise conditions.

</details>


### [626] [Towards SISO Bistatic Sensing for ISAC](https://arxiv.org/abs/2508.12614)
*Zhongqin Wang,J. Andrew Zhang,Kai Wu,Min Xu,Y. Jay Guo*

Main category: eess.SP

TL;DR: WiDFS 3.0 是一个用于单天线收发器的ISAC框架，能精确估计延迟和多普勒，即使在有相位偏移的情况下也能工作，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决在低成本、单天线收发器部署的ISAC系统中，时钟异步引起的CSI随机相位偏移问题，以及现有方法无法处理双站SISO设置下的多普勒镜像模糊。

Method: 提出了一种名为WiDFS 3.0的轻量级双站SISO传感框架，结合自参考互相关（SRCC）方法处理受相位偏移影响的CSI，并采用延迟域波束形成来解决多普勒模糊。

Result: WiDFS 3.0 在单目标和多目标场景下均实现了准确的参数估计，特别是在延迟估计方面，性能优于或媲美多天线方法。其提取的消除了模糊的特征在MobileViT-XXS等紧凑型网络上展现了强大的传感精度和泛化能力。

Conclusion: WiDFS 3.0 在单发单收（SISO）设置下，通过自参考互相关（SRCC）方法移除相位偏移，并利用延迟域波束形成解决多普勒模糊，实现了准确的延迟-多普勒估计，性能可与多天线方法媲美，在紧凑型神经网络（如MobileViT-XXS）上表现优异。

Abstract: Integrated Sensing and Communication (ISAC) is a key enabler for
next-generation wireless systems. However, real-world deployment is often
limited to low-cost, single-antenna transceivers. In such bistatic Single-Input
Single-Output (SISO) setup, clock asynchrony introduces random phase offsets in
Channel State Information (CSI), which cannot be mitigated using conventional
multi-antenna methods. This work proposes WiDFS 3.0, a lightweight bistatic
SISO sensing framework that enables accurate delay and Doppler estimation from
distorted CSI by effectively suppressing Doppler mirroring ambiguity. It
operates with only a single antenna at both the transmitter and receiver,
making it suitable for low-complexity deployments. We propose a
self-referencing cross-correlation (SRCC) method for SISO random phase removal
and employ delay-domain beamforming to resolve Doppler ambiguity. The resulting
unambiguous delay-Doppler-time features enable robust sensing with compact
neural networks. Extensive experiments show that WiDFS 3.0 achieves accurate
parameter estimation, with performance comparable to or even surpassing that of
prior multi-antenna methods, especially in delay estimation. Validated under
single- and multi-target scenarios, the extracted ambiguity-resolved features
show strong sensing accuracy and generalization. For example, when deployed on
the embedded-friendly MobileViT-XXS with only 1.3M parameters, WiDFS 3.0
consistently outperforms conventional features such as CSI amplitude, mirrored
Doppler, and multi-receiver aggregated Doppler.

</details>


### [627] [Factorized Disentangled Representation Learning for Interpretable Radio Frequency Fingerprint](https://arxiv.org/abs/2508.12660)
*Yezhuo Zhang,Zinan Zhou,Guangyu Li,Xuanpeng Li*

Main category: eess.SP

TL;DR: 本研究提出了一种新颖的解耦表示学习（DRL）框架，用于解决射频指纹识别（RFFI）中的鲁棒性和可控性问题。该框架通过学习明确、独立的因子表示，并结合因子分类和信号重建模块，有效提升了RFFI的性能，并实现了对信号生成的可控性。


<details>
  <summary>Details</summary>
Motivation: 现有的射频指纹识别（RFFI）方法主要依赖于域自适应技术，但这些技术缺乏显式的因子表示，导致鲁棒性和可控性有限，难以应对因信号传输到接收过程中多种变化因素（除RFF本身外）导致的有效性降低问题。

Method: 本研究提出了一种新颖的解耦表示学习（DRL）框架，该框架包含专门的解耦模块、因子分类模块和信号重建模块。通过设计定制化的损失函数，鼓励有效的解耦并增强对下游任务的支持，从而提取出一组明确表示相应因子的可解释向量。

Result: 所提出的DRL框架在两个公开基准数据集和自收集数据集上进行了评估，在多个DRL指标上取得了显著的性能。此外，该方法在下游RFFI任务和条件信号生成任务中的有效性也得到了分析。所有模块的贡献均提高了分类准确性，并实现了对条件生成信号的精确控制。

Conclusion: 本研究提出的解耦表示学习（DRL）框架通过学习明确且独立的表示，包括射频指纹（RFF），有效解决了现有RFFI方法鲁棒性和可控性不足的问题。该框架通过包含因子分类和信号重建的专用模块，以及量身定制的损失函数，实现了有效的解耦，并为下游任务提供了更好的支持。实验结果表明，该框架在多个DRL指标上表现出色，并在RFFI和条件信号生成任务中展现了其有效性，突显了其在可解释和明确RFF方面的潜力。

Abstract: In response to the rapid growth of Internet of Things (IoT) devices and
rising security risks, Radio Frequency Fingerprint (RFF) has become key for
device identification and authentication. However, various changing factors -
beyond the RFF itself - can be entangled from signal transmission to reception,
reducing the effectiveness of RFF Identification (RFFI). Existing RFFI methods
mainly rely on domain adaptation techniques, which often lack explicit factor
representations, resulting in less robustness and limited controllability for
downstream tasks. To tackle this problem, we propose a novel Disentangled
Representation Learning (DRL) framework that learns explicit and independent
representations of multiple factors, including the RFF. Our framework
introduces modules for disentanglement, guided by the principles of
explicitness, modularity, and compactness. We design two dedicated modules for
factor classification and signal reconstruction, each with tailored loss
functions that encourage effective disentanglement and enhance support for
downstream tasks. Thus, the framework can extract a set of interpretable
vectors that explicitly represent corresponding factors. We evaluate our
approach on two public benchmark datasets and a self-collected dataset. Our
method achieves impressive performance on multiple DRL metrics. We also analyze
the effectiveness of our method on downstream RFFI task and conditional signal
generation task. All modules of the framework contribute to improved
classification accuracy, and enable precise control over conditional generated
signals. These results highlight the potential of our DRL framework for
interpretable and explicit RFFs.

</details>


### [628] [Multi-Domain Supervised Contrastive Learning for UAV Radio-Frequency Open-Set Recognition](https://arxiv.org/abs/2508.12689)
*Ning Gao,Tianrui Zeng,Bowen Chen,Donghong Cai,Shi Jin,Michail Matthaiou*

Main category: eess.SP

TL;DR: 该论文提出了一种名为Open-RFNet的无人机射频开放集识别框架，通过融合多种特征并结合监督对比学习和改进的OpenMax算法，有效解决了未经授权的无人机飞行对低空感知通信网络的安全威胁，并在实验中取得了高识别准确率。


<details>
  <summary>Details</summary>
Motivation: 为了解决低空感知通信（LA-ISAC）网络中，由于传统行业监管规范滞后导致未经授权的无人机飞行事件频发，对网络构成严重安全威胁的问题，需要对非合作无人机进行监测。

Method: 提出了一种多域监督对比学习（MD-SupContrast）框架，用于无人机射频（RF）开放集识别。具体方法包括：融合来自ResNet和TransformerEncoder的纹理特征和时频位置特征，然后应用监督对比学习优化闭集样本的特征表示。接着，提出了一种改进的生成OpenMax（IG-OpenMax）算法，并构建了一个开放集识别模型Open-RFNet。该模型在面对未知样本时，会冻结特征提取层，仅重新训练分类层，从而在闭集和开集识别方面都取得了优异的性能。

Result: 实验结果表明，所提出的Open-RFNet在闭集和开集识别方面均表现出色，在25种无人机类型下，闭集识别准确率为95.12%，开集识别准确率为96.08%，优于现有基准方法。

Conclusion: 所提出的Open-RFNet在识别准确率上优于现有基准方法，在25种无人机类型下，闭集识别准确率为95.12%，开集识别准确率为96.08%。

Abstract: 5G-Advanced (5G-A) has enabled the vibrant development of low altitude
integrated sensing and communication (LA-ISAC) networks. As a core component of
these networks, unmanned aerial vehicles (UAVs) have witnessed rapid growth in
recent years. However, due to the lag in traditional industry regulatory norms,
unauthorized flight incidents occur frequently, posing a severe security threat
to LA-ISAC networks. To surveil the non-cooperative UAVs, in this paper, we
propose a multi-domain supervised contrastive learning (MD-SupContrast)
framework for UAV radio frequency (RF) open-set recognition. Specifically,
first, the texture features and the time-frequency position features from the
ResNet and the TransformerEncoder are fused, and then the supervised
contrastive learning is applied to optimize the feature representation of the
closed-set samples. Next, to surveil the invasive UAVs that appear in real
life, we propose an improved generative OpenMax (IG-OpenMax) algorithm and
construct an open-set recognition model, namely Open-RFNet. According to the
unknown samples, we first freeze the feature extraction layers and then only
retrain the classification layer, which achieves excellent recognition
performance both in closed-set and open-set recognitions. We analyze the
computational complexity of the proposed model. Experiments are conducted with
a large-scale UAV open dataset. The results show that the proposed Open-RFNet
outperforms the existing benchmark methods in terms of recognition accuracy
between the known and the unknown UAVs, as it achieves 95.12% in closed-set and
96.08% in open-set under 25 UAV types, respectively.

</details>


### [629] [LLM-RIMSA: Large Language Models driven Reconfigurable Intelligent Metasurface Antenna Systems](https://arxiv.org/abs/2508.12728)
*Yunsong Huang,Hui-Ming Wang,Qingli Yan,Zhaowei Wang*

Main category: eess.SP

TL;DR: LLM-RIMSA框架通过结合大语言模型和新型可重构智能超表面天线（RIMSA），解决了现有RIS技术的局限性，并在6G网络中实现了先进的性能，降低了训练成本。


<details>
  <summary>Details</summary>
Motivation: 现有RIS技术在硬件效率、动态控制和可扩展性方面存在局限性，无法满足6G网络对超大连接和智能无线环境的需求。

Method: 提出了一种结合大语言模型（LLM）和新型可重构智能超表面天线（RIMSA）架构的LLM-RIMSA框架。RIMSA采用并行同轴馈电和二维超表面集成，使每个超材料单元能够独立调整幅度和相位。LLM-RIMSA利用LLM的跨模态推理和少样本学习能力来动态优化RIMSA配置。

Result: 模拟结果表明，LLM-RIMSA在和速率方面优于传统的基于深度学习的方法，并减少了训练开销。

Conclusion: LLM-RIMSA框架为6G网络中的智能无线环境提供了新的方向，利用LLM优化RIMSA配置。

Abstract: The evolution of 6G networks demands ultra-massive connectivity and
intelligent radio environments, yet existing reconfigurable intelligent surface
(RIS) technologies face critical limitations in hardware efficiency, dynamic
control, and scalability. This paper introduces LLM-RIMSA, a transformative
framework that integrates large language models (LLMs) with a novel
reconfigurable intelligent metasurface antenna (RIMSA) architecture to address
these challenges. Unlike conventional RIS designs, RIMSA employs parallel
coaxial feeding and 2D metasurface integration, enabling each individual
metamaterial element to independently adjust both its amplitude and phase.
While traditional optimization and deep learning (DL) methods struggle with
high-dimensional state spaces and prohibitive training costs for RIMSA control,
LLM-RIMSA leverages pre-trained LLMs cross-modal reasoning and few-shot
learning capabilities to dynamically optimize RIMSA configurations. Simulations
demonstrate that LLM-RIMSA achieves state-of-the-art performance, outperforming
conventional DL-based methods in sum rate while reducing training overhead. The
proposed framework pave the way for LLM-driven intelligent radio environments.

</details>


### [630] [Range-Angle Likelihood Maps for Indoor Positioning Using Deep Neural Networks](https://arxiv.org/abs/2508.12746)
*Muhammad Ammad,Paul Schwarzbach,Michael Schultz,Oliver Michler*

Main category: eess.SP

TL;DR: 通过使用残差神经网络（ResNet）和范围-角度测量，在飞机驾驶舱环境中实现了厘米级精度的室内定位。


<details>
  <summary>Details</summary>
Motivation: 为了在飞机驾驶舱环境中实现高精度和高可靠性的室内定位，类似于室外导航的可靠性。

Method: 提出一种利用残差神经网络（ResNet）模型，将范围和角度测量值映射为残差图，然后转换为似然网格图，并与真实位置一起作为输入来训练模型，以预测精确位置。

Result: 在模拟的飞机驾驶舱环境中实现了厘米级精度的定位。

Conclusion: 利用包含范围和角度的测量值，并结合改进的残差神经网络（ResNet）模型，在模拟的飞机驾驶舱环境中实现了厘米级精度定位。

Abstract: Accurate and high precision of the indoor positioning is as important as
ensuring reliable navigation in outdoor environments. Using the
state-of-the-art deep learning models provides better reliability and accuracy
to navigate and monitor the accurate positions in the aircraft cabin
environment. We utilize the simulated aircraft cabin environment measurements
and propose a residual neural network (ResNet) model to predict the accurate
positions inside the cabin. The measurements include the ranges and angles
between a tag and the anchors points which are then mapped onto a grid as range
and angle residuals. These residual maps are then transformed into the
likelihood grid maps where each cell of the grid shows the likelihood of being
a true location. These grid maps along with the true positions are then passed
as inputs to train the ResNet model. Since any deep learning model involve
numerous parameter settings, hyperparameter optimization is performed to get
the optimal parameters for training the model effectively with the highest
accuracy. Once we get the best hyperparameters settings of the model, it is
then trained to predict the positions which provides a centimeter-level
accuracy of the localization.

</details>


### [631] [A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted RAN](https://arxiv.org/abs/2508.12892)
*Mahdi Abdollahpour,Marco Bertuletti,Yichao Zhang,Yawei Li,Luca Benini,Alessandro Vanelli-Coralli*

Main category: eess.SP

TL;DR: 一种低复杂度、可扩展的 AI 接收器，可用于 5G RAN 边缘，性能优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有的 AI 基带处理方法计算和内存需求高，阻碍了其在 RAN 边缘的部署以及在 6G 系统中的可扩展性。

Method: 提出了一种低复杂度、模型驱动的神经网络接收器，适用于多用户 MIMO 系统，并兼容 5G NR，支持多种调制方案、带宽、用户数和基站天线数，且无需重新训练。

Result: 该方法在 PUSCH 处理方面，在 TBLER 方面优于现有方法，并将 FLOPs 和可学习参数分别减少了 66 倍和 396 倍。

Conclusion: 提出了一种低复杂度、模型驱动的神经网络接收器，适用于 RAN 边缘的 MU-MIMO 系统。

Abstract: Artificial intelligence approaches for base-band processing for radio
receivers have demonstrated significant performance gains. Most of the proposed
methods are characterized by high compute and memory requirements, hindering
their deployment at the edge of the Radio Access Networks (RAN) and limiting
their scalability to large bandwidths and many antenna 6G systems. In this
paper, we propose a low-complexity, model-driven neural network-based receiver,
designed for multi-user multiple-input multiple-output (MU-MIMO) systems and
suitable for implementation at the RAN edge. The proposed solution is compliant
with the 5G New Radio (5G NR), and supports different modulation schemes,
bandwidths, number of users, and number of base-station antennas with a single
trained model without the need for further training. Numerical simulations of
the Physical Uplink Shared Channel (PUSCH) processing show that the proposed
solution outperforms the state-of-the-art methods in terms of achievable
Transport Block Error Rate (TBLER), while reducing the Floating Point
Operations (FLOPs) by 66$\times$, and the learnable parameters by 396$\times$.

</details>


### [632] [Interference-Asymmetric UAV Remote Control Links: Measurements and Performance Evaluation](https://arxiv.org/abs/2508.12941)
*Donggu Lee,Sung Joon Maeng,Ozgur Ozdemir,Mani Bharathi Pandian,Ismail Guvenc*

Main category: eess.SP

TL;DR: Interference in the uplink connection between a drone and its remote control hurts the download speed because the drone can't get confirmation signals.


<details>
  <summary>Details</summary>
Motivation: Interference sources degrade UAV RC link quality; UAVs are more susceptible to interference than ground RC units due to line of sight with more sources.

Method: Conducted a measurement campaign using a helikite platform and evaluated the throughput impact using MATLAB LTE and 5G toolboxes.

Result: Numerical results confirm that uplink interference asymmetry substantially degrades throughput performance due to the loss of HARQ indicator feedback.

Conclusion: Uplink interference asymmetry significantly degrades downlink throughput by causing loss of HARQ indicator feedback.

Abstract: Reliable and secure connectivity is crucial for remote control (RC) and
uncrewed aerial vehicles (UAVs) links. A major problem for UAV RC links is that
interference sources within the coverage may degrade the link quality. Such
interference problems are a higher concern for the UAV than the RC unit on the
ground due to the UAV being in line of sight (LoS) with a larger number of
interference sources. As a result, lost hybrid automatic repeat request (HARQ)
indicators (ACK/NACK) feedback in the uplink (UL, RC to UAV) may degrade the
downlink (DL, UAV to RC) throughput. To get physical evidence for our
interference asymmetry argument, we first conducted a measurement campaign
using a helikite platform at the Main Campus area of NC State University during
the 2024 Packapalooza festival. Subsequently, we evaluated the throughput
impact of the loss of HARQ indicator feedback caused by UL asymmetry using
MATLAB long-term-evolution (LTE) and fifth-generation (5G) toolboxes. Our
numerical results confirm that UL interference asymmetry substantially degrades
the throughput performance due to the loss of HARQ indicator feedback.

</details>


### [633] [A Novel CNN Based Standalone Detector for Faster-than-Nyquist Signaling](https://arxiv.org/abs/2508.12964)
*Osman Tokluoglu,Enver Cavus,Ebrahim Bedeer,Halim Yanikomeroglu*

Main category: eess.SP

TL;DR: 该研究提出了一种基于CNN的FTN信号检测器，通过结构化固定卷积核和分层滤波器分配有效缓解ISI，在接近最优BER性能的同时显著降低了计算成本，并证明了其在不同调制方式和信道条件下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了更有效地检测FTN信号，缓解符号间干扰（ISI），并提高检测精度和计算效率。

Method: 提出了一种新颖的基于卷积神经网络（CNN）的FTN信号检测器，该检测器采用结构化固定卷积核层和领域感知掩码来缓解ISI。通过分层滤波器分配策略，根据ISI分量强度分配不同数量的滤波器给不同层。

Result: 在压缩因子 $\tau \geq 0.7$ 时，该检测器实现了接近最优的BER性能，与BCJR算法相当。与M-BCJR相比，BPSK和QPSK调制下的计算成本分别降低了46%和84%。该方法还适用于高阶调制（高达64-QAM），在准静态瑞利衰落多径信道中表现鲁棒，并在LDPC编码的FTN传输下有效。

Conclusion: 该研究提出了一种新颖的基于卷积神经网络（CNN）的更快奈奎斯特定词（FTN）信号检测器，并采用了带有领域感知掩码的结构化固定卷积核层来有效缓解符号间干扰（ISI）。该方法通过分层滤波器分配策略，为早期层分配更多滤波器以处理更强的ISI分量，为后期层分配较少滤波器以处理较弱分量，从而提升了特征表示能力、消除了冗余计算并提高了检测精度，同时保持了计算效率。仿真结果表明，该检测器在压缩因子 $	au \geq 0.7$ 时，其比特错误率（BER）性能接近最优，与BCJR算法相当，并且在BPSK和QPSK调制下，计算成本相比M-BCJR分别降低了高达46%和84%。此外，该方法还适用于高阶调制（高达64-QAM），在准静态瑞利衰落多径信道中具有鲁棒性，并且在LDPC编码的FTN传输下表现有效，证明了其稳健性和实用性。

Abstract: This paper presents a novel convolutional neural network (CNN)-based detector
for faster-than-Nyquist (FTN) signaling, introducing structured fixed kernel
layers with domain-informed masking to effectively mitigate intersymbol
interference (ISI). Unlike standard CNN architectures that rely on moving
kernels, the proposed approach employs fixed convolutional kernels at
predefined positions to explicitly learn ISI patterns at varying distances from
the central symbol. To enhance feature extraction, a hierarchical filter
allocation strategy is employed, assigning more filters to earlier layers for
stronger ISI components and fewer to later layers for weaker components. This
structured design improves feature representation, eliminates redundant
computations, and enhances detection accuracy while maintaining computational
efficiency. Simulation results demonstrate that the proposed detector achieves
near-optimal bit error rate (BER) performance, comparable to the BCJR algorithm
for the compression factor $\tau \geq 0.7$, while offering up to $46\%$ and
$84\%$ computational cost reduction over M-BCJR for BPSK and QPSK,
respectively. Additional evaluations confirm the method's adaptability to
high-order modulations (up to 64-QAM), resilience in quasi-static multipath
Rayleigh fading channels, and effectiveness under LDPC-coded FTN transmission,
highlighting its robustness and practicality.

</details>


### [634] [Wavefield Correlation Imaging in Arbitrary Media with Inherent Aberration Correction](https://arxiv.org/abs/2508.13017)
*Scott Schoen Jr,Brian Lause,Marko Jakovljevic,Rimon Tadross,Mike Washburn,Anthony E. Samir*

Main category: eess.SP

TL;DR: 提出HWCI技术，提高超声成像质量，尤其适用于肥胖人群。


<details>
  <summary>Details</summary>
Motivation: 为了解决超声成像在面对具有形态异质性的受试者（如超重或肥胖人群）时面临的挑战，并改进现有成像算法在波束形成过程中未考虑空间变化的问题。

Method: 提出并实现了一种异构波场相关成像（HWCI）技术，该技术在图像形成过程中直接整合了任意已知的声速分布，克服了传统方法的局限性。

Result: 在计算模拟、体外和体内实验中，HWCI技术实现了超过30%的分辨率提升和约10%的对比度提升，优于传统的波场相关成像（WCI）。

Conclusion: 本研究提出的异构波场相关成像（HWCI）技术通过直接在图像形成过程中考虑任意已知声速分布，显著提高了超声成像的分辨率（超过30%）和对比度（约10%），有望提升超声图像的客观质量和临床应用价值。

Abstract: Ultrasound (US) imaging is an indispensable tool for diagnostic imaging,
particularly given its cost, safety, and portability profiles compared to other
modalities. However, US is challenged in subjects with morphological
heterogeneity (e.g., those with overweight or obesity), largely because
conventional imaging algorithms do not account for such variation in the
beamforming process. Specific knowledge of the these spatial variations enables
supplemental corrections of these algorithms, but with added computational
complexity. Wavefield correlation imaging (WCI) enables efficient image
formation in the spatial frequency domain that, in its canonical formulation,
assumes a uniform medium. In this work, we present an extension of WCI to
arbitrary known speed-of-sound distributions directly in the image formation
process, and demonstrate its feasibility in silico, in vitro, and in vivo. We
report resolution improvements of over 30% and contrast improvements of order
10% over conventional WCI imaging. Together our results suggest heterogeneous
WCI (HWCI) may have high translational potential to improve the objective
quality, and thus clinical utility, of ultrasound images.

</details>


### [635] [Low-complexity Leakage Minimization Beamforming for Large-scale Multi-user Cell-Free Massive MIMO](https://arxiv.org/abs/2508.13067)
*Iván Alexander Morales Sandoval,Getuar Rexhepi,Kengo Ando,Giuseppe Thadeu Freitas de Abreu*

Main category: eess.SP

TL;DR: 该研究提出了一种用于CF-mMIMO系统的低复杂度波束成形设计，通过FP和CCP技术最小化信息泄露，实现了与SotA相当的保密速率，并降低了计算复杂性、提高了收敛速度。


<details>
  <summary>Details</summary>
Motivation: 提出一种用于多用户（MU）无小区大规模多输入多输出（CF-mMIMO）系统中信息泄露最小化的低复杂度波束成形（BF）设计。

Method: 本文利用分数规划（FP）将保密速率最大化问题重新表述为可处理的差分凸形式，并采用凹凸过程（CCP）来解决由此产生的非凸问题。

Result: 仿真结果表明，该方案在实现与现有技术（SotA）方法相当的保密速率方面表现优异，同时显著降低了计算复杂性，并加快了收敛速度。

Conclusion: 所提出的方案在实现可与最先进方法相媲美的保密速率的同时，显著降低了计算复杂性并提高了收敛速度。

Abstract: We propose a low-complexity beamforming (BF) design for information leakage
minimization in multi-user (MU) cell-free massive multiple-input
multiple-output (CF-mMIMO) systems. Our approach leverages fractional
programming (FP) to reformulate the secrecy rate maximization problem into a
tractable difference-of-convex form. To efficiently solve the resulting
non-convex problem, we employ the Concave-Convex Procedure (CCP), enabling fast
convergence to a local optimum. Simulation results demonstrate that the
proposed scheme achieves secrecy rates comparable to state-of-the-art (SotA)
methods, while significantly reducing computational complexity and improving
convergence speed.

</details>


### [636] [BeamSeek: Deep Learning-based DOA Estimation for Low-Complexity mmWave Phased Arrays](https://arxiv.org/abs/2508.13075)
*Arav Sharma,Lei Chi,Ari Gebhardt,Alon S. Levin,Timothy R. Hoerning,Sam Keene*

Main category: eess.SP

TL;DR: BeamSeek是一种结合敏捷波束切换和深度学习的新方法，用于提高毫米波系统的DOA估计速度和精度，实验证明其优于传统方法，特别适合复杂环境。


<details>
  <summary>Details</summary>
Motivation: 传统DOA方法在模拟或混合波束成形系统中不切实际，敏捷波束切换技术虽然速度快，但精度和鲁棒性有待提高。

Method: 提出了一种结合敏捷波束切换和多层感知机（MLP）的深度学习方法，并采用专门的数据增强技术来模拟真实传播条件。

Result: 在60 GHz的NSF PAWR COSMOS测试台上进行了实验验证，与基于相关的方法相比，BeamSeek在各种信噪比（SNR）水平下平均估计误差最多可减少8度，在噪声信道中表现尤为突出。

Conclusion: BeamSeek通过结合敏捷波束切换和深度学习，在低复杂度的硬件实现下，显著提高了毫米波相控阵系统的到达角（DOA）估计速度和精度，尤其在噪声和多径干扰的实际部署场景中优势明显。

Abstract: A novel approach combining agile beam switching with deep learning to enhance
the speed and accuracy of Direction of Arrival (DOA) estimation for
millimeter-wave (mmWave) phased array systems with low-complexity hardware
implementations is proposed and evaluated. Traditional DOA methods requiring
direct access to individual antenna elements are impractical for analog or
hybrid beamforming systems prevalent in modern mmWave implementations. Recent
agile beam switching techniques have demonstrated rapid DOA estimation, but
their accuracy and robustness can be further improved via deep learning.
BeamSeek addresses these limitations by employing a Multi-Layer Perceptron
(MLP) and specialized data augmentation that emulates real-world propagation
conditions. The proposed approach was experimentally validated at 60 GHz using
the NSF PAWR COSMOS testbed, demonstrating significant improvements over a
correlation-based method across various Signal-to-Noise Ratio (SNR) levels.
Results show that BeamSeek achieves up to an 8 degree reduction in average
estimation error compared to this baseline, with particular advantages in noisy
channels. This makes it especially suitable for practical mmWave deployments in
environments characterized by multipath interference and hardware constraints.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [637] [Electro-thermal Co-design of High-power Vertical \b{eta}-Ga2O3 Schottky Diodes with High-permittivity Dielectric Field-plate](https://arxiv.org/abs/2508.11775)
*Ahsanul Mohaimeen Audri,Chung-Ping Ho,Jingjing Shi,Esmat Farzana*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究提出了垂直 {eta}-Ga2O3 SBDs 的电热协同设计，使用 BTO/AlN 场板提高了散热和高场管理能力，并获得了约 11 MV/cm 的高击穿场强。


<details>
  <summary>Details</summary>
Motivation: 为了提高垂直 {eta}-Ga2O3 SBDs 在高功率应用中的散热和高场管理能力。

Method: 通过分析 BTO/AlN 场板和仅 BTO 场板配置的 {eta}-Ga2O3 SBDs 的热输运特性，并结合 Landauer 方法来评估热边界电导 (TBC)。

Result: BTO/AlN 场板配置能有效降低界面处的焦耳热，并提高高场下的击穿电压。而仅 BTO 场板配置则在肖特基接触边缘附近出现局部热点。深度蚀刻和侧壁场板 SBD 结构进一步降低了阳极边缘附近的累积热量和电场。

Conclusion: BTO/AlN 场板比仅使用 BTO 的场板配置具有更优越的散热能力，并且 AlN 可作为垂直 {eta}-Ga2O3 SBDs 中场板电介质的绝佳选择，可在高功率应用中同时提供增强的高场可持续性和改进的散热性能。

Abstract: This work presents electrothermal co-design of vertical \b{eta}-Ga2O3
Schottky barrier diodes (SBDs) to enhance both heat dissipation and high field
management in high-power applications. Here, we demonstrate device-level
thermal management tailored for two vertical \b{eta}-Ga2O3 SBD structures that
employed different edge termination techniques, such as field-plate and deep
etch with sidewall field-plate, where the field-plate was formed with
high-permittivity dielectric (BaTiO3). The localized thermal hot spots were
detected at the Schottky contact edges near BaTiO3 dielectric based
field-plate. However, a substantial reduction of the thermal hotspots was
observed by forming the field-plate with BaTiO3 and thermally-conductive AlN
insulator, where the AlN can effectively decrease Joule heating at interface
and the high permittivity of BaTiO3 contributes to high field reduction. The
deep etch and sidewall field-plate SBD structure further reduced accumulated
heat and electric field near the critical anode edge by removing lateral
depletion regions. We also analyzed thermal transport at
dielectric/\b{eta}-Ga2O3 interfaces using Landauer approach that revealed
significantly higher thermal boundary conductance (TBC) enabled by AlN compared
to BaTiO3, attesting to the superior heat dissipation ability by BaTiO3/AlN
field-plate than the BaTiO3-only configuration. Experimental investigation with
vertical metal/AlN/\b{eta}-Ga2O3 diodes also extracted a high breakdown field
(~11 MV/cm) of AlN, significantly exceeding the material breakdown field of
\b{eta}-Ga2O3. This indicates that AlN can be an excellent choice for
field-plate dielectric in vertical \b{eta}-Ga2O3 SBDs to provide both enhanced
high field sustainability and improved heat dissipation in high-power
applications.

</details>


### [638] [Comprehensive Structural Characterization of Charged Polymers Involved in Moisture-Driven Direct Air Capture](https://arxiv.org/abs/2508.11809)
*Gayathri Yogaganeshan,Rui Zhang,Raimund Fromme,Sharang Sharang,Jamie Ford,Douglas M Yates,Marlene Velazco Medel,Martin Uher,Justin Flory,Jennifer Wade,Petra Fromme*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究通过多种显微和散射技术，对用于直接空气捕获的两种AEM聚合物（Fumasep FAA-3和IRA 900）进行了结构分析，揭示了湿度对其结构和性能的影响，为开发更节能的DAC聚合物提供了基础。


<details>
  <summary>Details</summary>
Motivation: 随着大气中二氧化碳（CO2）水平的升高，人们迫切需要有效的碳捕获方法，其中直接空气捕获（DAC）被认为是一种有前途的解决方案。本研究旨在表征用于低能耗、湿气驱动的DAC应用的AEM聚合物的结构。

Method: 本研究采用X射线衍射、小角/广角X射线散射（SAXS/WAXS）、原子力显微镜（AFM）、聚焦离子束扫描电子显微镜（FIB-SEM）和透射电子显微镜（TEM）等多种技术，对商业化的碱性阴离子交换膜（AEM）聚合物（Fumasep FAA-3和IRA 900）进行了结构表征。

Result: X射线散射分析揭示了两种材料的分子序构和大规模结构组织，而湿度变化则凸显了湿气对结构特性的影响。AFM表面分析表明存在团聚、孔隙率和溶胀，这与FIB-SEM和TEM成像结果一致。

Conclusion: 这项研究为开发更节能的直接空气捕获（DAC）聚合物奠定了基础，为改进的二氧化碳捕获技术铺平了道路。

Abstract: The rise in atmospheric carbon dioxide (CO2) levels has led to urgent calls
for effective carbon capture methods, with direct air capture (DAC) emerging as
a promising solution. This study focuses on the structural characterization of
commercially available alkaline anion-exchange membrane (AEM) polymers, Fumasep
FAA-3 and IRA 900, for use in low-energy, moisture-driven DAC applications. A
combination of X-ray diffraction, small and wide-angle X-ray scattering
(SAXS/WAXS), atomic force microscopy (AFM), focused ion beam-scanning electron
microscopy (FIB-SEM), and transmission electron microscopy (TEM) were employed
to explore the structural features of these materials. X-ray scattering
analysis revealed molecular ordering and large-scale structural organization in
both materials, while humidity-induced changes highlighted the impact of
moisture on structural properties. AFM surface analysis further indicated the
presence of clustering, porosity, and swelling, which were corroborated by
FIB-SEM and TEM imaging. These structural insights offer a deeper understanding
of the behavior of AEM-DAC materials during CO2 capture and release,
emphasizing the role of moisture in these processes. This work lays the
foundation for the development of more energy-efficient DAC polymers, paving
the way for improved CO2 capture technologies.

</details>


### [639] [Control of magnetic transition, metal-semiconductor transition, and magnetic anisotropy in noncentrosymmetric monolayer Cr$_2$Ge$_2$Se$_3$Te$_3$](https://arxiv.org/abs/2508.11899)
*Rui-Qi Wang,Tengfei Cao,Tian-Min Lei,Xie Zhang,Yue-Wen Fang*

Main category: cond-mat.mtrl-sci

TL;DR: 这项工作首次在Janus铁磁材料Cr$_2$Ge$_2$Se$_3$Te$_3$中发现了反演对称性破缺，并展示了通过应变和电场调控其磁性的潜力。


<details>
  <summary>Details</summary>
Motivation: 二维非中心对称材料中的铁磁序仍是一个未被充分探索的领域。

Method: 通过第一性原理计算

Result: 我们发现了Cr$_2$Ge$_2$Se$_3$Te$_3$单层材料，它是一种具有反演对称性破缺的Janus铁磁材料，可在不同应变下经历铁磁-反铁磁转变和金属-半导体转变，并且磁晶各向异性能（MAE）可以通过电场或应变进行调制，特别是磁化易轴可以从面内变为面外。

Conclusion: 这项研究为研究应变或电场对磁性的控制提供了一个有前途的Janus铁磁材料平台。

Abstract: Recent advances in two-dimensional materials have greatly expanded the family
of ferromagnetic materials. The well-known 2D ferromagnets, such as CrI$_3$,
Cr$_2$Ge$_2$Te$_6$, and Fe$_3$GeTe$_2$ monolayers, are characterized by
centrosymmetric crystal structures. In contrast, ferromagnetic ordering in 2D
noncentrosymmetric materials remains an underexplored area. Here we report a
Janus ferromagnet, Cr$_2$Ge$_2$Se$_3$Te$_3$ with inversion symmetry breaking,
through first-principles calculations. This monolayer can undergo a
ferromagnetic-antiferromagnetic transformation and a metal-semiconductor
transition under different strains. Additionally, the strength of
magnetocrystalline anisotropy energy (MAE) can be modulated by electric field
or strain. In particular, the magnetization easy axis can be altered from
in-plane to out-of-plane under strain. We find that Te$_3$ atoms play a key
role in determining the MAE, where contributions are primarily from $p_z / p_y$
and $p_x / p_y$ orbitals. This study of Janus ferromagnetic materials has
provided a promising platform for the research on the control of magnetism by
strain or electric field.

</details>


### [640] [Stable crack propagation in dislocation-engineered oxide visualized by double cleavage drilled compression test](https://arxiv.org/abs/2508.11965)
*Oliver Preuß,Zhangtao Li,Enrico Bruder,Philippe Carrez,Yinan Cui,Jürgen Rödel,Xufei Fang*

Main category: cond-mat.mtrl-sci

TL;DR: 通过原位观察和模拟，研究了裂纹尖端与位错的相互作用，结果表明富含位错的区域能有效减缓裂纹扩展，为设计更抗裂纹的陶瓷提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 为了提高室温下具有塑性变形能力的半脆性材料（如陶瓷）的抗断裂能力，理解裂纹尖端-位错相互作用至关重要。

Method: 使用改进的双裂缝钻孔压缩（DCDC）样本几何形状，以实现裂纹尖端-位错相互作用的现场观察。MgO样本配备了富含位错的屏障。

Result: 裂纹扩展在富含位错的区域内明显减速，速度比原始晶体慢85%。离开这些区域后，裂纹会重新加速，直到到达下一个富含位错的屏障。结合相场和晶体塑性模型复制了实验观察结果。

Conclusion: 该技术能够为通过位错设计更抗裂纹的陶瓷提供信息。

Abstract: Understanding crack tip - dislocation interaction is critical for improving
the fracture resistance of semi-brittle materials like room-temperature
plastically deformable ceramics. Here, we use a modified double cleavage
drilled compression (DCDC) specimen geometry, which facilitates stable crack
propagation, to achieve in situ observation of crack tip - dislocation
interaction. MgO specimens, furnished with dislocation-rich barriers, were
employed to study how dislocations influence crack propagation. Crack
progression was clearly observed to decelerate within dislocation-rich regions,
slowing to 15% of its velocity as compared to the pristine crystal. Upon
exiting these regions, cracks reaccelerated until reaching the next
dislocation-rich barrier. Coupled phase field and crystal plasticity modeling
replicates the experimental observations and provides mechanistic insight into
crack tip - dislocation interactions. The aligned experiment and simulation
results underscore the robustness of the technique and its potential to inform
the design of more fracture-resistant ceramics via dislocations.

</details>


### [641] [Hubbard energy dependence of electronic structures in rare-earth monoxides](https://arxiv.org/abs/2508.12635)
*Mizuki Tago,Tsukasa Kurachi,Takayuki Makino*

Main category: cond-mat.mtrl-sci

TL;DR: Studied U energy's effect on LuO's optical properties, finding even small U changes are detectable spectrally.


<details>
  <summary>Details</summary>
Motivation: Understanding Hubbard parameters (U) is of central importance to realize the potential of optical materials like rare-earth monoxides, and recent studies suggest U parameters can change with subtle structural modifications.

Method: Theoretically evaluated U energy dependence of the differential transmission and reflectivity spectra for LuO to assess the impact of U energy on the optical properties.

Result: Observed the influence of the Drude tail owing to U-induced plasma energy modulation, in addition to the conventional derivative-like contribution.

Conclusion: A few meV modulations in U are sufficient for a detectable spectral response given the typical detection sensitivity of differential spectroscopy (approximately 1x10^-4).

Abstract: To realize the significant potential of optical materials such as strongly
electron-correlated open-shell rare-earth monoxides, understanding the
electron-localization Hubbard parameters ($U$) is of central importance. The
Hubbard energy is believed to be material specific and constant. However, it
has recently been pointed out that even subtle structural changes can induce
changes in $U$ parameters. For LuO, we theoretically evaluated $U$ energy
dependence of the differential transmission and reflectivity spectra to assess
the impact of $U$ energy on the optical properties. In addition to the
conventional derivative-like contribution, we observed the influence of the
Drude tail owing to $U$-induced plasma energy modulation. Given the typical
detection sensitivity of differential spectroscopy ($\sim 1 \times 10^{-4}$),
even a few meV modulations in $U$ are sufficient for a detectable spectral
response.

</details>


### [642] [Accelerating Amorphous Alloy Discovery: Data-Driven Property Prediction via General-Purpose Machine Learning Interatomic Potential](https://arxiv.org/abs/2508.11989)
*Xuhe Gong,Hengbo Zhao,Xiao Fu,Jingchen Lian,Qifan Yang,Ran Li,Ruijuan Xiao,Tao Zhang,Hong Li*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究开发了首个通用的非晶态合金机器学习内禀势，解决了传统方法的局限性，实现了高效的设计和性质预测。


<details>
  <summary>Details</summary>
Motivation: 传统的设计非晶态合金的方法成本高且效率低下，而仅基于成分的机器学习方法缺乏关键的原子结构信息。机器学习内禀势作为一种强大的替代方案，可以高效地逼近复杂的三维势能面，其精度接近于密度泛函理论（DFT）。

Method: 通过使用包含20400个配置的数据集，开发了一个通用的机器学习内禀势，该数据集涵盖了代表性的二元和三元非晶态合金系统。该模型在独立的测试集上表现出优异的预测性能，能量的平均绝对误差为5.06 meV/atom，力的平均绝对误差为128.51 meV/Å。

Result: 该模型在独立的测试集上表现出优异的预测性能，能量的平均绝对误差为5.06 meV/atom，力的平均绝对误差为128.51 meV/Å。模型能够可靠地捕捉宏观性质（如密度、杨氏模量和玻璃化转变温度）在原始训练系统及其衍生成分修饰系统中的变化趋势，可以直接应用于非晶态合金的成分-性质映射，并能获取非晶态合金的原子结构，从而实现微观分析和对实验结果的解释。

Conclusion: 该研究开发了首个用于非晶态合金系统的通用机器学习内禀势，打破了长期存在的计算瓶颈，为数据驱动设计和高通量成分筛选提供了基础。

Abstract: While traditional trial-and-error methods for designing amorphous alloys are
costly and inefficient, machine learning approaches based solely on composition
lack critical atomic structural information. Machine learning interatomic
potentials, trained on data from first-principles calculations, offer a
powerful alternative by efficiently approximating the complex three-dimensional
potential energy surface with near-DFT accuracy. In this work, we develop a
general-purpose machine learning interatomic potential for amorphous alloys by
using a dataset comprising 20400 configurations across representative binary
and ternary amorphous alloys systems. The model demonstrates excellent
predictive performance on an independent test set, with a mean absolute error
of 5.06 meV/atom for energy and 128.51 meV/\r{A} for forces. Through extensive
validation, the model is shown to reliably capture the trends in macroscopic
property variations such as density, Young's modulus and glass transition
temperature across both the original training systems and the compositionally
modified systems derived from them. It can be directly applied to
composition-property mapping of amorphous alloys. Furthermore, the developed
interatomic potential enables access to the atomic structures of amorphous
alloys, allowing for microscopic analysis and interpretation of experimental
results, particularly those deviating from empirical trends.This work breaks
the long-standing computational bottleneck in amorphous alloys research by
developing the first general-purpose machine learning interatomic potential for
amorphous alloy systems. The resulting framework provides a robust foundation
for data-driven design and high-throughput composition screening in a field
previously constrained by traditional simulation limitations.

</details>


### [643] [Structural, optical, and dielectric properties of Cr-doped ZnO films via DC magnetron sputtering](https://arxiv.org/abs/2508.12642)
*Men Guo,Gilad Orr,Paul Ben Ishai,Xia Zhao,Shlomo Glasser*

Main category: cond-mat.mtrl-sci

TL;DR: 通过磁控溅射和退火制备Cr掺杂ZnO薄膜，研究其光学、介电和微结构特性。结果显示，Cr掺杂可以提高ZnO薄膜的导电性和稳定性，但会略微降低透射率。该方法有望用于开发高性能透明电极。


<details>
  <summary>Details</summary>
Motivation: 开发一种制备Cr掺杂ZnO薄膜的新方法，并探索其在透明电极方面的应用潜力，以及提高透射率、导电性和稳定性。

Method: 采用直流磁控溅射沉积Cr-Zn层，然后在空气中进行退火制备Cr掺杂ZnO薄膜。

Result: 随着Cr含量的增加，平均晶粒尺寸减小（56.34-39.50 nm），带隙增大（从3.18 eV增加到3.23 eV），透射率（在600 nm处）降低（从91%降低到83%）。掺杂Cr后，两种导电活化能增加，表明温度稳定性增强。

Conclusion: Cr掺杂的ZnO薄膜在最佳Cr含量下表现出高透射率和导电性，有潜力用于透明电极的开发。该方法可扩展至其他掺杂ZnO薄膜（如Al掺杂ZnO透明电极），以实现透射率、导电性和稳定性在柔性及可穿戴应用中的同步提升。

Abstract: Cr-doped ZnO films were fabricated by a new but feasible method, that is,
annealing Cr-Zn layers deposited via DC magnetron sputtering in air.
Microstructures of the films were investigated using X-ray diffraction,
scanning electron microscopy, and atomic force microscopy, intrinsic point
defects were identified via photoluminescence spectroscopy, and optical and
dielectric properties were analyzed using a UV-vis spectrophotometer and
dielectric spectrometer, respectively. It was found that the average grain
sizes decrease (56.34 - 39.50 nm), the band gap increases (from 3.18 to 3.23
eV), and the transmittance (at 600 nm) decreases (from 91% to 83%) with
increasing Cr. Two activation energies of conduction increase after doping Cr,
indicating enhanced temperature stability. At optimal Cr levels, ZnO films
exhibit high transmittance and conductivity, exhibiting potential for
transparent electrode development. This method can be extended to other doped
ZnO films, such as Al-doped ZnO transparent electrodes, to achieve simultaneous
improvements in transmittance, conductivity, and stability for flexible and
wearable applications.

</details>


### [644] [Domain Wall-mediated Interfacial Ferroelectric Switching](https://arxiv.org/abs/2508.11997)
*Hao-Wen Xu,Wen-Cheng Fan,Jun-Ding Zheng,Cheng-Shi Yao,Ni Zhong,Wen-Yi Tong,Chun-Gang Duan*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究利用从头算、机器学习和实验，发现界面铁电体中的畴壁在电场下会迁移，从而实现极化转换，并提出了优化策略。


<details>
  <summary>Details</summary>
Motivation: 界面铁电性为了超快、低功耗的记忆器件提供了有前景的平台。尽管之前的研究将极化转换归因于整个层级的滑动，但对称性限制构成了基础性限制。

Method: 本研究通过结合从头算、机器学习方法和实验验证，展示了内禀极化畴壁的C3对称性破缺，使得在外禀电场下能够实现极化结构的转换。

Result: 研究表明，内禀极化畴壁的C3对称性破缺使得在外禀电场下能够实现极化结构的转换。局部极化向量会偏离以响应电场，并引起局部重构，最终驱动畴壁的迁移。与传统铁电体中的机制相似，不同的畴壁类型会导致不同的转换行为，这对于确定极化转换的可逆性至关重要。此外，研究提出了实现非挥发性铁电转换的策略，并通过实验成功实现。

Conclusion: 本研究阐明了六方界面铁电体中微观的结构转换机制，并为未来的纳米电子学应用奠定了基础。

Abstract: Interfacial ferroelectricity offers a promising platform for ultrafast,
low-power memory devices. While previous studies have attributed polarization
switching to full-layer sliding, the symmetry constraints pose fundamental
limitations. By integrating first-principles calculations, machine learning
methods, and experimental validations, we show that domain walls within
in-plane polarization break C3 symmetry, enabling polarization switching under
out-of-plane electric fields. Local polarization vectors deviate to response to
the field, leading to local reconstruction, and ultimately drives the migration
of domain walls. This mechanism bears clear resemblance to that in traditional
ferroelectrics. Notably, different domain wall types result in distinct
switching behaviors, which play a crucial role in determining the reversibility
of polarization switching. We then propose strategies beyond ideal conditions
to achieve non-volatile ferroelectric switching, successfully realized by our
experiments. These insights clarify the microscopic switching mechanism in
hexagonal interfacial ferroelectrics, providing a basis for future
nanoelectronics applications.

</details>


### [645] [Microscopic model of the operation of the Single-chalcogenide X-point Memory](https://arxiv.org/abs/2508.12118)
*P. Fantini,A. Ghetti,E. Varesi,A. Pirovano,F. Pellizzer,D. Baratella,C. Ribaldone,S. Caravati,D. Campi,M. Bernasconi,R. Bez*

Main category: cond-mat.mtrl-sci

TL;DR: OTS电压VT的极性依赖性对于SXM内存至关重要。通过结合电学测量、TCAD和DFT计算，我们提出了一个GBG模型，该模型能够解释OTS的极性依赖性，并为内存设计和合金选择提供指导。


<details>
  <summary>Details</summary>
Motivation: 利用Ovonic阈值开关（OTS）在相变内存和交叉点阵列选择器单元中的关键作用，并利用OTS电压VT依赖于外加电场极性的特性，实现了单沟道X点内存（SXM），其中单一沟道合金薄膜既可作为内存单元，也可作为选择器单元。

Method: 利用电学和物理测量、基于技术计算机辅助设计（TCAD）的数值模拟以及基于密度泛函理论（DFT）的电子结构计算，提供了对依赖于极性的阈值电压（VT）的微观理解。提出了一种分级带隙（GBG）模型，其中通过强电场在阴极的相反效应和阳极导带中高密度的电子，在带隙中建立了非均匀分布的局域电子态。

Result: 提出的GBG模型能够重现编程窗口的多种特性，包括其对温度、厚度和沟道合金成分的依赖性。

Conclusion: 这项工作为改进内存设计和为新兴内存技术选择更高性能的合金奠定了基础。

Abstract: Ovonic threshold switching is the key process for several applications of
chalcogenide alloys including phase change memories and selector elements in
cross-points arrays. Very recently, it has been shown that the threshold
switching voltage VT depends on the polarity of the applied field. This feature
has been already exploited in the realization of the Single Chalcogenide
X-point Memory (SXM) in which a single film of a chalcogenide alloy can serve
as both a memory and selector unit. In this work, we provide a microscopic
understanding of the polarity-dependent VT by leveraging electrical and
physical measurements, numerical simulations based on technology computer aided
design (TCAD) and electronic structure calculations based on density functional
theory (DFT). We developed a Graded Band Gap (GBG) model in which an
inhomogeneous distribution of localized electronic states in the gap is
established by the opposite effect of a strong electric field at the cathode
and a high density of electrons in the conduction band at the anode. The model
is suitable to reproduce several features of the programming window, including
its dependence on temperature, thickness and composition of the chalcogenide
alloy. The microscopic understanding that we gained on the SXM operation lays
the foundation for important improvements in the memory design and in the
selection of better performing alloys for applications in enabling memory
technologies.

</details>


### [646] [Effects of Defects on Thermal Transport across Solid/Solid Heterogeneous Interfaces](https://arxiv.org/abs/2508.12744)
*Ershuai Yin,Wenzhu Luo,Lei Wang,Qiang Li*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究通过结合第一性原理计算和蒙特卡洛模拟，研究了缺陷对四种半导体异质界面热传输的影响。研究发现，缺陷通常会削弱热传输，但在 GaN/SiC 界面中，SiC 中的缺陷会通过声子能量重新分布来增强热传输。


<details>
  <summary>Details</summary>
Motivation: 揭示缺陷在异质结构制造过程中对界面热传输的影响机制。

Method: 结合第一性原理计算和蒙特卡洛模拟，明确考虑了缺陷的影响，开发了微尺度热传输模型。

Result: 研究了缺陷浓度和位置对四种异质界面：Si/SiC、GaN/SiC、Si/Diamond 和 GaN/Diamond 热传输特性的影响。结果表明，在大多数情况下，缺陷会削弱热传输，但 GaN/SiC 界面出现例外，其中 SiC 中的缺陷会增强热传输，这归因于由缺陷引起的近界面声子能量重新分布。

Conclusion: 该研究丰富了对半导体异质界面热传输的基本理解，并指导了高 ITC 异质结构的设 计和制造。

Abstract: During the fabrication of heterogeneous structures inside chips, impurities
and defects are inevitably introduced. However, the mechanism by which defects
affect interfacial heat transport remains unclear. In this work, a microscale
thermal transport model is developed by combining first-principles calculations
with Monte Carlo simulations, explicitly accounting for the effects of defects.
The effects of defect concentration and location on thermal transport
characteristics are investigated for four heterointerfaces: Si/SiC, GaN/SiC,
Si/Diamond, and GaN/Diamond. Temperature distribution, spectral thermal
conductance, average phonon scattering numbers, and interfacial thermal
conductance (ITC) are compared under different conditions. The results show
that, for Si/SiC, Si/Diamond, and GaN/Diamond interfaces, introducing defects
weakens heat transport. Higher defect concentration leads to lower ITC.
Furthermore, when defects are in SiC or Diamond, which have broader phonon
spectral distributions, their impact on ITC is weaker. For the GaN/SiC
interface, defects in GaN reduce ITC, while defects in SiC enhance ITC. At a
defect concentration of 0.05, ITC decreases by 54.1% when defects are present
in GaN, but increases by 57.2% when defects are present in SiC. This behavior
arises from defect-induced phonon energy redistribution near the interface. The
redistribution increases the population of low-frequency phonons, which are
more capable of crossing the interface, thus enhancing heat transfer. This
study enriches the fundamental understanding of thermal transport across
semiconductor heterointerfaces and guides the design and fabrication of
high-ITC heterostructures.

</details>


### [647] [Comparative study of magnetic exchange parameters and magnon dispersions in NiO and MnO from first principles](https://arxiv.org/abs/2508.12153)
*Flaviano José dos Santos,Luca Binci,Guido Menichetti,Ruchika Mahajan,Nicola Marzari,Iurii Timrov*

Main category: cond-mat.mtrl-sci

TL;DR: 本文评估了三种第一性原理方法在计算磁性材料（NiO和MnO）的磁交换参数和磁畴色散方面的准确性，发现TDDFPT+U和基于ΔE参数的Heisenberg模型与实验数据吻合度更高。


<details>
  <summary>Details</summary>
Motivation: 密度泛函理论（DFT）中的（半）局部泛函存在自相互作用误差，影响了过渡金属化合物中局域和部分填充的d轨道的性质，这使得准确模拟这些化合物中的自旋波激发具有挑战性。

Method: 本文比较了三种先进的第一性原理方法来计算NiO和MnO中的磁交换参数和磁畴色散，所有方法都基于从密度泛函微扰理论获得的从头算Hubbard U值的DFT+U基态。两种方法直接提取交换参数：一种通过四态映射（ΔE）的总能量差，另一种通过磁力定理（MFT）和无穷小自旋旋转。然后，通过Heisenberg哈密顿量和线性自旋波理论（LSWT）获得磁畴色散。第三种方法，即含U的时变密度泛函微扰理论（TDDFPT+U），直接从动力学自旋磁化率获得磁畴色散，并通过LSWT进行事后拟合以进行比较。

Result: TDDFPT+U和基于ΔE交换参数的Heisenberg模型在磁畴色散方面与实验结果（中子散射数据）一致性较好，而MFT方法存在较大偏差。

Conclusion: TDDFPT+U方法和基于ΔE参数的Heisenberg模型与实验结果吻合较好，而基于MFT的方法存在较大差异，这可能归因于其固有的近似和实现上的局限性。本研究对用于自旋波模拟的先进第一性原理技术进行了基准测试，并有助于推进用于磁性材料研究和设计的可靠计算工具。

Abstract: Spin-wave excitations are fundamental to understanding the behavior of
magnetic materials and hold promise for future information and communication
technologies. Yet, modeling these accurately in transition-metal compounds
remains challenging, starting from the self-interaction errors affecting
localized and partially filled $d$-orbitals in density-functional theory (DFT)
with (semi-)local functionals. In this work, we compare three advanced
first-principles approaches for computing magnetic exchange parameters and
magnon dispersions in NiO and MnO, all based on a common DFT+$U$ ground state
with ab initio Hubbard $U$ values obtained from density-functional perturbation
theory. Two methods extract exchange parameters directly: one via total-energy
differences using the four-state mapping ($\Delta E$), and the other via the
magnetic force theorem (MFT) using infinitesimal spin rotations. Magnon
dispersions are then obtained from a Heisenberg Hamiltonian through linear
spin-wave theory (LSWT). The third approach, time-dependent density-functional
perturbation theory with $U$ (TDDFPT+$U$), yields magnon dispersions directly
from the dynamical spin susceptibility, with exchange parameters fitted a
posteriori, for comparison, via LSWT. Our results show that TDDFPT+$U$ and the
Heisenberg model based on $\Delta E$-derived parameters align well with
experimental neutron scattering data, whereas the MFT-based approach shows
larger discrepancies, possibly due to some inherent approximations and
limitations of the particular implementation used. This study benchmarks the
accuracy of state-of-the-art first-principles techniques for spin-wave modeling
and contributes to advancing reliable computational tools for the study and
design of magnetic materials.

</details>


### [648] [Neutralizing Optical Defects in GeSn](https://arxiv.org/abs/2508.13027)
*Nirosh M. Eldose,Dinesh Baral,Diandian Zhang,Fernando Maia de Oliveira,Hryhorii Stanchu,Mohammad Zamani-Alavijeh,Yuriy I. Mazur,Wei Du,Shui-Qing Yu,Gregory J. Salamo*

Main category: cond-mat.mtrl-sci

TL;DR: 通过掺杂Ge衬底抑制了GeSn的光致发光缺陷，在2300 nm处观察到预期发光。


<details>
  <summary>Details</summary>
Motivation: 为了克服分子束外延生长的GeSn光致发光有限的问题，并确定限制因素。

Method: 利用掺杂Ge(001)衬底进行生长，并通过光致发光谱收集和分析来研究GeSn薄膜的光物理特性。

Result: 在掺杂Ge(001)衬底上生长的GeSn薄膜在2300 nm处显示出光致发光，且消除了2400 nm处的缺陷信号。

Conclusion: 通过掺杂Ge(001)衬底成功抑制了GeSn层中与缺陷相关的光致发光，并在预期波长2300 nm处观察到了Sn含量为10.5%的GeSn薄膜的光致发光，同时消除了通常在2400 nm处观察到的缺陷信号。

Abstract: Reports of photoluminescence from GeSn grown on Ge substrates by molecular
beam epitaxy have been limited. We find that one limiting factor to observing
photoluminescence is due to localized defect states marked by photoluminescence
at 2400 nm and originating from the Ge substrate and buffer layer. In this
study, we report on an optical study utilizing doped Ge(001) substrates to
effectively suppress defect-related photoluminescence in GeSn layers by filling
localized defect trap states. For this experiment, a GeSn layer with Sn content
up to 10.5% was grown on a doped Ge(001) substrate. Analysis of the physics of
the photoluminescence spectrum collected from the GeSn thin film shows an
emission at the expected wavelength of 2300 nm for 10.5% Sn content and the
absence of the typically observed defect related signal at 2400 nm. This
understanding is further confirmed using short pulse optical excitation of the
GeSn grown on undoped Ge substrates.

</details>


### [649] [Critical Importance of Grain Boundaries to the Conductivity of Polycrystalline Molecular Crystals](https://arxiv.org/abs/2508.12172)
*Shujit Chandra Paul,William A. Goddard III,Michael J. Zdilla,Prabhat Prakash,Stephanie L. Wunder*

Main category: cond-mat.mtrl-sci

TL;DR: 软固态分子晶体中，晶界（GB）的离子传导性远高于晶粒，晶粒是离子的来源，而晶界是主要的传导通道。


<details>
  <summary>Details</summary>
Motivation: 为了阐明软固态分子晶体中离子在晶粒和晶界（GB）中的传导贡献。

Method: 通过改变晶体尺寸和 adiponitrile/LiPF6 摩尔比来改变 GB 体积分数，并结合分子动力学（MD）模拟来分析离子运动。

Result: 分子动力学（MD）模拟表明，离子在晶粒中呈亚扩散运动，在晶界（GB）中呈良好扩散运动。晶界（GB）表现为无序的纳米限制区域，载流子浓度（1M）高于饱和LiPF6-Adpn溶液（0.04M），离子主要被-CN基团溶剂化，接触离子对很少。晶界（GB）的扩散系数比晶粒高至少一个数量级。

Conclusion: 软固态分子晶体通过晶粒间的离子迁移和晶界（GB）来增强锂离子传输，其中GB在离子传输中起关键作用，具有比饱和LiPF6-Adpn溶液高得多的载流子浓度（1M vs 0.04M），并且离子主要被-CN基团溶剂化。离子在GB中的扩散系数比在晶粒中的高至少一个数量级，晶粒充当了离子库，向快速传导的GBs迁移。

Abstract: Soft-solid molecular crystals consist of crystalline grains and fluid grain
boundaries (GB) that enhance the grain binding and transport of Li+ ions
between the grains. The total ionic conductivity consists of ion migration in
both the grains and GBs. To unravel these contributions in adiponitrile
(Adpn)-LiPF6 molecular crystals, the GB volume fraction was varied by changing
the size of the crystals and the adiponitrile/LiPF6 molar ratio. Molecular
dynamic (MD) simulations indicate that ion motion was sub-diffusive in the
grains and well-diffusive in the GBs, with GBs characterized as disordered
nano-confined regions of higher charge carrier concentration (1M) than in
saturated LiPF6-Adpn solutions (0.04M), and ions predominantly solvated by -CN
groups with few contact ion pairs. The diffusivity in the GBs is at least an
order of magnitude higher than in the crystalline grains. The emergent picture
is the grains as a reservoir of ions that migrate to the fast-conducting GBs.

</details>


### [650] [Ultrafast Nonequilibrium Enhancement of Electron-Phonon Interaction in 2H-MoTe$_2$](https://arxiv.org/abs/2508.12239)
*Nina Girotto Erhardt,Sotirios Fragkos,Dominique Descamps,Stéphane Petit,Michael Schüler,Dino Novko,Samuel Beaulieu*

Main category: cond-mat.mtrl-sci

TL;DR: 通过时间分辨光电子能谱和量子化学计算，研究表明增加光激发载流子密度可以增强2H-MoTe2的电子-声子相互作用，导致带隙重整化和寿命缩短，这得益于电子-声子耦合矩阵元素的非平衡修正。


<details>
  <summary>Details</summary>
Motivation: 理解非平衡电子-声子相互作用在微观层面和超快时间尺度是凝聚态物理学的核心目标。

Method: 结合使用时间分辨和角度分辨的极端紫外光电子能谱学以及约束密度泛函微扰理论。

Result: 研究结果表明，光激发载流子密度可以作为调控手段，在非平衡条件下增强电子-声子相互作用。具体而言，非平衡能带结构映射和半导体过渡金属二硫属化物2H-MoTe2中谷分辨的超快布居动力学揭示了随着光激发载流子密度的增加，带隙会发生重整化，布居寿命会缩短。

Conclusion: 该研究通过理论分析光诱导电子和声子能量及线宽重整化，将这些瞬态特征归因于光激发载流子密度增加引起的电子-声子耦合矩阵元素的非平衡修正。

Abstract: Understanding nonequilibrium electron-phonon interactions at the microscopic
level and on ultrafast timescales is a central goal of modern condensed matter
physics. Combining time- and angle-resolved extreme ultraviolet photoemission
spectroscopy with constrained density functional perturbation theory, we
demonstrate that photoexcited carrier density can serve as a tuning knob to
enhance electron-phonon interactions in nonequilibrium conditions.
Specifically, nonequilibrium band structure mapping and valley-resolved
ultrafast population dynamics in semiconducting transition-metal dichalcogenide
2H-MoTe$_2$ reveal band-gap renormalizations and reduced population lifetimes
as photoexcited carrier densities increase. Through theoretical analysis of
photoinduced electron and phonon energy and linewidth renormalizations, we
attribute these transient features to nonequilibrium modifications of
electron-phonon coupling matrix elements. The present study advances our
understanding of microscopic coupling mechanisms enabling control over
relaxation pathways in driven solids.

</details>


### [651] [Photocatalytic CO2 Reduction Enhanced by Synergetic Interactions among Photon Phonon and Molecule](https://arxiv.org/abs/2508.12262)
*Chen Sun,Yimin Xuan*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究通过氮掺杂Cu2O和微柱石英薄膜的协同作用，利用光-振动-物质耦合机制，显著提高了光催化CO2制燃料的效率和太阳光谱利用率。


<details>
  <summary>Details</summary>
Motivation: 光催化CO2还原受限于CO2活化效率低和太阳光谱利用率差。本研究旨在通过发现光子、声子和分子之间的振动耦合机制，显著提高CO2催化转化为燃料的效率。

Method: 设计并合成了负载在石英光学基底上的氮掺杂Cu2O催化剂。利用微柱石英薄膜诱导CO2的不对称伸缩振动模式与表面声子极化子共振之间的振动强耦合（VSC）。通过同步辐射源（SRS）的傅里叶变换红外光谱验证了分子振动与光子-声子模式之间的相互作用。

Result: 氮掺杂Cu2O催化剂将吸附的CO2分子转化为线性几何，有效降低了活化势垒并促进了CO2解离。与微柱石英薄膜结合后，系统诱导了振动强耦合（VSC），实现了167.7 umol h-1 g-1的CO产率，比非VSC体系提高了46%，是目前Cu2O基光催化剂的最高产率。

Conclusion: 本研究揭示了一种新颖的光热机理，并通过光-振动-物质耦合为光催化CO2转化中的键活化提供了新策略。

Abstract: Photocatalytic CO2 reduction is limited by inefficient CO2 activation and
poor solar spectrum utilization. Here, we discovered and revealed the vibration
coupling mechanism among photons, phonons, and molecules, which remarkably
enhances photocatalytic catalysis of CO2 into fuels. We designed the
nitrogen-doped Cu2O-based catalyst loaded onto the quartz optical substrate.
The N-doping Cu2O converts linearly geometry of adsorbed CO2 molecules, which
efficiently lowers the activation barrier and facilitates CO2 dissociation.
Once the Cu-based catalyst is combined with a micro-pillar quartz film, the
system induces vibrational strong coupling (VSC) between the asymmetric CO2
stretching mode and surface phonon polariton resonances. These resonances arise
from the photothermal conversion of incident solar photons on the
micro-pillars. The resonant coupling phenomena were further verified by
Fourier-transform infrared spectroscopy using Synchrotron Radiation Source
(SRS), which directly confirmed the interactions between molecular vibrations
and photonic-phononic modes. The synergetic functions originated from this
hybrid architecture achieve a CO yield of 167.7 umol h-1 g-1 under pure water
conditions, which is the highest reported yield for Cu2O-based photocatalysts
with 46% enhancement over non-VSC systems. This work uncovers a novel
photo-thermal mechanism. It further provides a new strategy to control bond
activation in photocatalytic CO2 conversion through light-vibration-matter
coupling.

</details>


### [652] [Phase transitions driven by solute concentration, temperature, and pressure in uranium-6wt % niobium alloy](https://arxiv.org/abs/2508.12310)
*Yanwen Liao,Yongfeng Huang,Kun Wang,Wenjun Zhu,Wu-Xing Zhou,Yi Liao,Songlin Yao*

Main category: cond-mat.mtrl-sci

TL;DR: 开发了U-Nb势，用于模拟相变和高压行为，揭示了高压下的孪晶耦合相变机制。


<details>
  <summary>Details</summary>
Motivation: 为了准确预测U-Nb系统的相变（由溶质浓度驱动的α到γ相变；在U-6Nb合金中由温度驱动的α-prime到γ相变）、弹性性质、缺陷能量和混合焓，需要开发一种新的势。

Method: 通过拟合柔性交叉相互作用函数和合金参数到实验和第一性原理数据，在现有的U的ADP势和新的Nb的EAM势基础上，开发了U-Nb系统的角相关势。

Result: 开发了U-Nb系统的角相关势，能够可靠地重现U-Nb固溶体的熔点，并捕捉到γ-U-6Nb的晶格参数膨胀。该势能准确预测了高达约90 GPa的Hugoniot关系和状态方程，并解决了静态高压下的α-prime到γ的转变。研究揭示了U-6Nb在高压下经历孪晶耦合的α-prime到γ的转变，预测静态相变压力为54.5 GPa。此外，研究表明U-6Nb单晶在塑性屈服前会经历非线性弹性弛豫。

Conclusion: 该研究成功开发了一种适用于U-Nb系统的角相关势，能够准确预测相变、弹性性质、缺陷能量和混合焓，并解决了高压冲击加载下剪应力弛豫机制的长期存在的差异。

Abstract: An angular-dependent potential for the U-Nb system is developed based on an
existing ADP for U and a new EAM potential for Nb through fitting flexible
cross-interaction functions and alloy parameters to experimental and
first-principles data, enabling accurate prediction of phase transitions (alpha
to gamma driven by solute concentration; alpha-prime to gamma under temperature
in U-6Nb alloy), elastic properties, defect energetics, and mixed enthalpy. The
potential reliably reproduces melting points of U-Nb solid solutions and
captures lattice parameter expansion of gamma U-6Nb. Notably, it correctly
predicts Hugoniot relations and equations of state up to about 90 GPa and
resolves the alpha-prime to gamma transition under static high pressure.
Combined with atomic simulations, we reveal a twinning-coupled alpha-prime to
gamma transition of U-6Nb under high pressures: {112}gamma twins form via
nanosecond-scale twinning precursors generated during the transient adiabatic
compressions. The static phase transition pressure is predicted to be 54.5 GPa,
comparable to 67.2 GPa by first-principles calculations. Besides, our result
suggests that U-6Nb single-crystal would experience a nonlinear elastic
relaxation before yielding plastically at 3.1 GPa (shear stress: 0.9 GPa). The
results in this work help resolve long-standing discrepancies in understanding
the abnormal shear stress relaxation mechanisms under high-pressure shock
loading.

</details>


### [653] [Enhancement of the energy storage and electrocaloric effect performances in 0.4 BCZT 0.6 BSTSn medium entropy ceramic prepared by sol gel method](https://arxiv.org/abs/2508.12357)
*S. Khardazi,Z. Gargar,A. Lyubchyk,O. Zakir,D. Mezzane,M. Amjoud,A. Alimoussa,Z. Kutnjak*

Main category: cond-mat.mtrl-sci

TL;DR: 通过溶胶凝胶法合成了一种新型铁电材料0.4BCZT 0.6BSTSn，该材料在低电场下表现出优异的储能和电热效应性能，且具有良好的温度稳定性。


<details>
  <summary>Details</summary>
Motivation: 设计并合成具有良好储能和电热效应的0.4 Ba0.85Ca0.15Zr0.10Ti0.90O3 0.6 Ba0.9Sr0.1Ti0.9Sn0.1O3中熵材料。

Method: 采用溶胶凝胶法设计并合成了基于传统多晶铁电体Ba0.85Ca0.15Zr0.10Ti0.90O3的0.4 Ba0.85Ca0.15Zr0.10Ti0.90O3 0.6 Ba0.9Sr0.1Ti0.9Sn0.1O3中熵材料，并研究了其结构、介电、储能和电热效应性能。

Result: 研究发现该材料在低电场下表现出优异的储能和电热效应性能，并且具有良好的温度稳定性。

Conclusion: 所制备的0.4 Ba0.85Ca0.15Zr0.10Ti0.90O3 0.6 Ba0.9Sr0.1Ti0.9Sn0.1O3陶瓷在30 kV/cm的低电场下，同时具有255.4 mJ/cm3的显著可恢复储能密度、67.9%的效率、1.36 K的大ECE温度变化以及0.453 K.mm/kV的高ECE响应度。此外，在所研究的0.4BCZT 0.6BSTSn样品中，Wrec（小于10%）表现出优异的温度稳定性。

Abstract: Based on the traditional polycrystalline ferroelectric
Ba0.85Ca0.15Zr0.10Ti0.90O3, the 0.4 Ba0.85Ca0.15Zr0.10Ti0.90O3 0.6
Ba0.9Sr0.1Ti0.9Sn0.1O3 medium entropy material with good energy storage and
electrocaloric effect performances is designed and synthesized by the solgel
method. The structural, dielectric, energy storage and electrocaloric effect
properties of the prepared sample were studied. The findings demonstrate that
the 0.4 Ba0.85Ca0.15Zr0.10Ti0.90O3 0.6 Ba0.9Sr0.1Ti0.9Sn0.1O3 ceramic
simultaneously has a significant recoverable energy storage density of 255.4
mJ/cm3, an efficiency of 67.9%, a large ECE temperature change of 1.36 K, and a
high ECE responsivity of 0.453 K.mm/kV under a low electric field of 30 kV/cm.
Moreover, excellent temperature stability of Wrec (less than 10%) was achieved
in the investigated sample 0.4BCZT 0.6BSTSn.

</details>


### [654] [Chiral quantum magnets with optically and catalytically active spin ladders](https://arxiv.org/abs/2508.12362)
*Bum Chul Park,Sung-Chul Kim,Dae Beom Lee,Young Kwang Kim,Bomin Kim,Sonny H. Rhim,Eunsoo Lee,Yongju Hong,Kwangyeol Lee,Sang Hyun Lee,Jessica Ma,Michal Sawczyk,Jun Lu,Jason Manassa,Nishkarsh Agarwal,Robert Hovden,Sung Ok Won,Min Jun Ko,Minkyu Park,Jiung Cho,Xiaoming Mao,Kai Sun,Young Keun Kim,Nicholas A. Kotov*

Main category: cond-mat.mtrl-sci

TL;DR: LIOX 是一种新型手性量子磁体，具有室温下的螺旋自旋排列，易于合成且具有光学和催化应用潜力。


<details>
  <summary>Details</summary>
Motivation: 寻找具有大能量隙的手性量子磁体，并克服现有材料在室温自旋失配、Dzyaloshinskii-Moriya 相互作用弱和晶格畸变高能量需求方面的物理化学障碍。

Method: 通过嵌入手性氨基酸，在 LIOX 的二聚 FeO6 八面体的自旋态中诱导手性，形成具有螺旋耦合磁矩的锯齿形链或螺旋自旋梯。

Result: LIOX 中的自旋态是化学和光学可及的，显示出与螺旋匹配光子的强光学共振，并实现自旋选择性电荷传输。LIOX 中的静态而非动态极化使其特别适用于催化。

Conclusion: LIOX 及其插层材料因其室温下的自旋配对、场可调性、环境鲁棒性和合成简单性，成为一类独特的实用量子磁体。

Abstract: Chiral quantum magnets with spin-states separated by a large energy gap are
technologically attractive but difficult to realize. Geometrically frustrated
topological states with nanoscale chirality may offer a chemical pathway to
such materials. However, room temperature spin misalignment, weakness of
Dzyaloshinskii-Moriya interactions, and high energy requirements for lattice
distortions set high physicochemical barriers for their realization. Here, we
show that layered iron oxyhydroxides (LIOX) address these challenges due to
chirality transfer from surface ligands into spin-states of dimerized FeO6
octahedra with zig-zag stacking. The intercalation of chiral amino acids
induces angular displacements in the antiferromagnetic spin pairs with a
helical coupling of magnetic moments along the screw axis of the zig-zag
chains, or helical spin-ladders. Unlike other chiral magnets, the spin states
in LIOX are chemically and optically accessible, they display strong optical
resonances with helicity-matching photons and enable spin-selective charge
transport. The static rather than dynamic polarization of spin ladders in LIOX
makes them particularly suitable for catalysis. Room-temperature spin pairing,
field-tunability, environmental robustness, and synthetic simplicity make LIOX
and its intercalates a uniquely practical family of quantum magnets.

</details>


### [655] [Structural contribution to light-induced gap suppression in Ta$_2$NiSe$_5$](https://arxiv.org/abs/2508.12363)
*Chen Zijing,Xu Chenhang,Xie Chendi,Tang Weichen,Liu Qiaomei,Wu Dong,Xu Qing,Jiang Tao,Zhu Pengfei,Zou Xiao,Li Jun,Wang Zhiwei,Wang Nanlin,Qian Dong,Zong Alfred,Xiang Dao*

Main category: cond-mat.mtrl-sci

TL;DR: Ta2NiSe5的能量间隙变化主要是由光诱导的结构变化引起的，而非激子效应。


<details>
  <summary>Details</summary>
Motivation: Ta2NiSe5作为一种潜在的激子绝缘体材料，其能隙的成因一直存在争议，特别是结构相变与能隙开​​口并存的情况。本研究旨在通过精确的动力学测量来解决这一争议。

Method: 采用MeV超快电子衍射技术，结合第一性原理计算，对Ta2NiSe5在光激发后的原子位移进行了定量分析。

Result: 研究发现，Ta2NiSe5的光诱导能量间隙减小主要由结构变化引起，而无需考虑激子效应。定量分析了原子位移对能量间隙的影响。

Conclusion: 该研究表明，在Ta2NiSe5中，光诱导的结构变化是导致能量间隙减小的主要原因，而之前的研究可能忽视了这一点。

Abstract: An excitonic insulator is a material that hosts an exotic ground state, where
an energy gap opens due to spontaneous condensation of bound electron-hole
pairs. Ta$_2$NiSe$_5$ is a promising candidate for this type of material, but
the coexistence of a structural phase transition with the gap opening has led
to a long-standing debate regarding the origin of the insulating gap. Here we
employ MeV ultrafast electron diffraction to obtain quantitative insights into
the atomic displacements in Ta$_2$NiSe$_5$ following photoexcitation, which has
been overlooked in previous time-resolved spectroscopy studies. In conjunction
with first-principles calculations using the measured atomic displacements, we
find that the structural change can largely account for the photoinduced
reduction in the energy gap without considering excitonic effects. Our work
illustrates the importance of a quantitative reconstruction of individual
atomic pathways during nonequilibrium phase transitions, paving the way for a
mechanistic understanding of a diverse array of phase transitions in correlated
materials where lattice dynamics can play a pivotal role.

</details>


### [656] [CoRuTiGe: A Possible Spin Gapless Semiconductor](https://arxiv.org/abs/2508.12376)
*Ravinder Kumar,Tufan Roy,Baisali Ghadai,Rakesh Kumar,Sucheta Mondal,Anil Kumar,Archana Lakhani,Devendra Kumar,Masafumi Shirai,Sachin Gupta*

Main category: cond-mat.mtrl-sci

TL;DR: CoRuTiGe合金具有铁磁性，表现出自旋 the gapless 半导体特性，在低温下具有负磁阻，在自旋电子学领域具有应用潜力。


<details>
  <summary>Details</summary>
Motivation: 研究CoRuTiGe合金的磁性和自旋特性，以探索其在自旋电子学应用中的潜力。

Method: 通过电弧熔炼技术合成CoRuTiGe四元Heusler合金，并对其进行晶体结构、磁化和电阻率的实验与理论研究。

Result: CoRuTiGe合金在室温下呈四方晶体结构，具有铁磁性，饱和磁化强度为0.681 µB/f.u.（5 K）。电阻率随温度近似线性变化，表现出自旋 the gapless 半导体特性。霍尔效应分析表明，异常霍尔效应源于内在和外在机制。

Conclusion: CoRuTiGe合金在低温下表现出良好的负磁阻，并且具有自旋 the gapless 半导体特性，这使得该材料在自旋电子学应用方面具有巨大的潜力。

Abstract: We report experimental and theoretical investigations on the quaternary
Heusler alloy CoRuTiGe, synthesized using the arc melting technique. Crystal
structure analysis reveals a tetragonal structure at room temperature.
Magnetization measurements as a function of temperature and magnetic field
indicate ferromagnetic nature with a saturation magnetization of 0.681 mB/f.u.
at 5 K. The temperature dependence of electrical resistivity shows a nearly
linear decrease in the high-temperature range, indicating the spin gapless
semiconductor like behavior of the material. This SGS nature is further
supported by the temperature-independent carrier concentration and mobility.
Hall effect analysis reveals that the anomalous Hall effect in CoRuTiGe arises
from both intrinsic and extrinsic mechanisms. Additionally, a well-defined
symmetric negative magnetoresistance is observed at low temperatures. These
findings suggest that CoRuTiGe holds significant promise for spintronic
applications.

</details>


### [657] [Machine Learning Prediction of Magnetic Proximity Effect in van der Waals Heterostructures: From Atoms to Moiré](https://arxiv.org/abs/2508.12406)
*Lukas Cvitkovich,Klaus Zollner,Jaroslav Fabian*

Main category: cond-mat.mtrl-sci

TL;DR: 机器学习模型能高效预测范德华异质结中的磁性，克服了DFT的计算成本。对石墨烯/Cr2Ge2Te6的研究发现其磁性行为存在二分性，磁矩分布在碳原子上，无法用传统方法解析。所提出的随机森林模型能实现对磁性的精准预测，并揭示了其丰富的磁性纹理。


<details>
  <summary>Details</summary>
Motivation: 克服密度泛函理论（DFT）计算成本高昂的问题，以有效预测范德华异质结构中由近邻效应引起的大规模磁性。

Method: 利用随机森林模型，并采用平滑原子位置重叠（Smooth Overlap of Atomic Positions）描述符，将局域（~2 nm²）原子尺度几何映射到碳磁矩，以克服石墨烯/Cr2Ge2Te6中的磁性二分性。

Result: 该机器学习框架能够有效预测范德华异质结中的大规模磁性，并揭示了石墨烯/Cr2Ge2Te6中未被识别的磁性二分性。模型显示近邻诱导磁矩分布在碳原子上，并且能够揭示丰富的磁性莫尔纹理。

Conclusion: 该机器学习框架能够有效地预测范德华异质结中由近邻效应引起的大规模磁性，克服了密度泛函理论（DFT）的高计算成本。该模型揭示了石墨烯/Cr2Ge2Te6中的磁性二分性，近邻诱导磁矩分布在碳原子上，并且该方法可以广泛应用于对局域原子环境敏感且超出解析描述范围的轨道和自旋近邻效应。

Abstract: We introduce a machine learning framework that efficiently predicts
large-scale proximity-induced magnetism in van der Waals heterostructures,
overcoming the high computational cost of density functional theory (DFT). We
apply it to graphene/Cr$_2$Ge$_2$Te$_6$, which exhibits a previously
unrecognized dichotomy. Unlike the spin polarization at the Fermi level, which
follows the pseudospin, the proximity-induced magnetic moments vary across
carbon atoms, defying analytical modeling. To address this, we develop a Random
Forest model trained on DFT data and employ Smooth Overlap of Atomic Positions
descriptors to map the local ($\sim 2\,$nm$^2$) atomic-scale geometry to the
carbon magnetic moments. Besides demonstrating locality, the model reveals rich
magnetic moir\'e textures. Crucially, this method can be broadly applied to
orbital and spin proximity effects that are highly sensitive to local atomic
environments and are beyond analytical description.

</details>


### [658] [Nonadiabaticity under compression in metastable carbon monoxide-nitroxide mixtures](https://arxiv.org/abs/2508.12488)
*Reetam Paul,Jonathan C. Crowhurst,Stanimir Bonev*

Main category: cond-mat.mtrl-sci

TL;DR: High-pressure simulations reveal that CO-N2O mixtures transform into complex solids, with N2O dissociation triggering CO polymerization and nonadiabatic effects becoming significant at high temperatures.


<details>
  <summary>Details</summary>
Motivation: To understand the structural and chemical transformations in CO-N2O mixtures under high pressure and temperature, and how these two species interact and couple through various pathways, which has received comparatively little attention.

Method: Ab initio adiabatic/nonadiabatic molecular dynamics simulations using a diabatic trajectory stitching approach were employed to study CO-N2O mixtures under pressures ranging from 0-160 GPa and temperatures from 300-1500 K.

Result: The simulations mapped the evolution of CO-N2O mixtures from van-der-Waals fluids to extended amorphous network solids. Key findings include the sequence of phase transitions, the influence of N2O dissociation on CO polymerization, and the emergence of nonadiabatic dynamics at high temperatures.

Conclusion: CO-N2O mixtures exhibit a sequence of transitions from gas to molecular crystal to polymerized amorphous solid under high pressure and temperature, influenced by thermal effects and compression. N2O unimolecular dissociation plays a key role in initiating CO polymerization. Nonadiabatic pathways, driven by N2O dissociation and spin transitions in oxygen atoms, become dominant at temperatures above 900 K, causing deviations from Born-Oppenheimer dynamics.

Abstract: Carbon monoxide (CO) and nitrous oxide (N2O) both undergo profound structural
and chemical transformations when compressed. While their individual high-P/T
phase diagrams have been mapped in considerable detail, comparatively little
attention has been paid to the mixtures in which the two species can couple
through oxygen transfer, charge redistribution, and nonadiabatic dissociation
pathways. Here we use comprehensive ab initio adiabatic/nonadiabatic molecular
dynamics simulations, essentially a diabatic trajectory stitching approach,
that chart the evolution of CO-N2O mixtures from van-der-Waals fluids to
extended amorphous network solids over the range 0-160 GPa and 300-1500 K. We
emphasize on (i) the sequence of gas to molecular crystal to polymerized
amorphous solid reactive transitions that arise from an interplay between
thermal and compression effects in metastable C-N-O mixtures, (ii) the role of
N2O unimolecular dissociation in lowering the onset pressure for CO
polymerization, and (iii) the emergence of nonadiabatic pathways, via thermal
unimolecular dissociation of N2O, accompanied by spin-transition in oxygen
atoms that can make C-N-O systems deviate from Born-Oppenheimer dynamics. This
dominates the chemistry once the mixture enters the regime of bond-breaking
temperatures (T>900 K).

</details>


### [659] [Operando Electron Microscopy of Nanoscale Electronic Devices on Non-Conductive Substrates](https://arxiv.org/abs/2508.12503)
*Menglin Zhu,Michael Xu,Zishen Tian,Colin Gilgenbach,Daniel Drury,Bridget R. Denzer,Ching-Che Lin,Deokyoung Kang,Lane W. Martin,James M. LeBeau*

Main category: cond-mat.mtrl-sci

TL;DR: 为了解决在非导电衬底上对薄膜电容器进行原位电子显微镜操作的挑战，我们开发了一种新的样品制备和操作流程。该流程通过引入绝缘阻挡层，避免了对原始薄膜结构的改变，并能准确地研究器件的电学性质。


<details>
  <summary>Details</summary>
Motivation: 在非导电衬底上对薄膜电容器进行原位电子显微镜操作时，实现与本体电子器件相当的工作条件仍然是一个挑战。现有的样品制备方法，如聚焦离子束铣削，精度有限，并且通常需要使用导电衬底或人为加厚的层，这会改变器件的本征应变、静电边界条件和器件响应。

Method: 提出了一种通用的、多功能的原位偏压工作流程，包括样品制备和器件操作。通过在靠近本体表征的电容器处引入图案化的绝缘阻挡层，使得样品制备过程无需改变原始薄膜结构。

Result: 成功地将该方法应用于压电薄膜电容器，并在施加电场时，在原子尺度上保持了对边界条件敏感的畴切换。

Conclusion: 该方法通过引入图案化的绝缘阻挡层，实现了在非导电衬底上薄膜电容器的原位偏压操作，从而避免了对原始薄膜结构的改变，并成功应用于压电薄膜电容器的畴切换研究。

Abstract: Achieving operating conditions comparable to ``bulk'' electronic devices,
such as thin film capacitors, during \textit{operando} electron microscopy
remains challenging, particularly when devices are grown on non-conductive
substrates. Limited precision of focused ion beam milling for sample
preparation often necessitates the use of conductive substrates or artificially
thick layers that differ from actual device architectures. These modifications
can alter native strain, electrostatic boundary conditions, and ultimately
device response. Here, we present a generic and versatile workflow for
\textit{operando} biasing of thin-film capacitors in the (scanning)
transmission electron microscope, including sample fabrication and device
operation. By introducing a patterned insulating barrier adjacent to the
bulk-characterized capacitors, our approach enables sample preparation without
altering the original film structure. As a case study, we apply the method to a
piezoelectric thin-film capacitor grown on an insulating substrate, and
demonstrate that it preserves the boundary-condition-sensitive domain switching
at the atomic scale under applied electric fields. Overall, the process can
help to establish a foundation for systematic \textit{operando} studies of
complex thin-film systems under representative bulk testing geometries.

</details>


### [660] [Robust Topological Conduction in Bi2 Bi2Se3 Superlattices at Ambient Conditions](https://arxiv.org/abs/2508.12544)
*Lakshan Don Manuwelge Don,Md. Sakauat Hasan Sakib,Gracie Pillow,Sara McGinnis,Seth Shields,Joseph P. Corbett*

Main category: cond-mat.mtrl-sci

TL;DR: Bi2Bi2Se3 薄膜的拓扑表面态和边缘态对环境条件具有鲁棒性，可通过机械力调控。


<details>
  <summary>Details</summary>
Motivation: 研究 Bi2Bi2Se3 的电子结构和边缘态，以了解其拓扑特性及其在光电器件中的潜在应用。

Method: 通过进行性原子力显微镜 (C-AFM) 和点 I-V 光谱分析，研究了 Bi2Bi2Se3 [001] 取向薄膜在环境条件下的电子结构和边缘态。

Result: 研究结果表明，在铋烯和 Bi2Se3 两种终止层上都观察到了边缘态，并且这些边缘态的电导率高于平台。此外，随着机械力的增加，边缘态的宽度会增加，直至覆盖整个平台。该研究还发现，施加的机械力会导致平台高度发生畸变，这表明欧姆接触机制的出现是应变和尖端诱导效应共同作用的结果。

Conclusion: 该研究表明，拓扑保护的表面态和边缘态对环境条件具有鲁棒性，并且可以通过施加机械力来调控。

Abstract: Topologically protected surface states have garnered significant attention
due to their robustness against perturbations and potential applications in
optoelectronics. Bi2 Bi2Se3 is a topological semimetal composed of a 2D
bismuthene sheet and a Bi2Se3 quintuple layer, forming an intrinsic
superlattice. This study investigates the electronic structure and edge states
of Bi2 Bi2Se3 [001] oriented films under ambient conditions through conducting
atomic force microscopy (C-AFM). Point I-V spectroscopy and current imaging are
used to characterize the surface and local transport properties of bismuthene
and Bi2Se3 terminated layers. Our measurements reveal force dependent shifts in
conduction mechanisms in both bismuthene and Bi2Se3, transitioning from direct
tunneling (DT) at low forces and low biases, to Fowler Nordheim tunneling (FNT)
at low forces and high biases, and eventually to a more ohmic like behavior at
the highest forces. Under DT conditions on the bismuthene termination, we
observed the Dirac cone in the dI/dV spectroscopy. Edge states are observed
along the perimeter of the (001) terraces for both terminations, and are
observed to have higher conductivity than the local terrace. Force-dependent
imaging revealed an increase in the width of the edge state as force increased,
until the conductive edge state appeared to cover the entire terrace.
Furthermore, terrace heights display a force dependent distortion from the high
tip forces, which indicates that the transition to the ohmic-like contact
regime on either termination results from a complex interplay between strain
and tip induced effects. All measurements were performed under ambient
conditions, which demonstrates the robustness of the topological and edge
states to ambient conditions.

</details>


### [661] [Understanding high photocatalytic activity of the TiO2 high-pressure columbite phase by experiments and first-principles calculations](https://arxiv.org/abs/2508.12559)
*Jacqueline Hidalgo-Jimenez,Taner Akbay,Tatsumi Ishihara,Kaveh Edalati*

Main category: cond-mat.mtrl-sci

TL;DR: 通过高压扭转法制备的缺氧高压TiO2（铌矿石相）光催化剂比锐钛矿相活性更高，这归因于其优化的光吸收和水裂解的表面催化活性。


<details>
  <summary>Details</summary>
Motivation: 为了提高TiO2在光催化产氢中的活性，本研究探索了一种新的TiO2相——铌矿石相。

Method: 通过高压扭转法稳定了TiO2的一种缺氧高压相——铌矿石相，并将其作为产氢光催化剂，利用密度泛函理论（DFT）研究了其高活性的机理。

Result: 铌矿石相的活性似乎高于锐钛矿相。DFT计算表明，铌矿石相的氧空位比锐钛矿相更显著地改善了其光学带隙和光吸收，并且其(101)原子平面上水吸附能更高，水裂解表面活化能更低。

Conclusion: 虽然columbite不是低带隙半导体，但其较大的光吸收率和较高的表面催化活性使其成为光催化反应的有希望的候选者。

Abstract: The clean production of hydrogen as a zero-emission fuel can be done using
photocatalysis, with TiO2 being one of the most promising photocatalysts.
However, the activity of TiO2 anatase and rutile phases is still limited. In
this study, an oxygen-deficient high-pressure phase of TiO2, columbite, is
stabilized by a high-pressure torsion method. The phase is utilized as an
active photocatalyst for hydrogen production, and the mechanism of its high
activity is examined using density functional theory (DFT). The activity of
columbite appears to be experimentally higher than that of the anatase phase.
DFT calculations revealed that columbite does not have a narrow electronic
bandgap, but its optical bandgap and light absorbance are improved by oxygen
vacancies more significantly compared to anatase. Moreover, the water
adsorption energy is higher and the surface activation energy for water
splitting on the (101) atomic plane of columbite is lower than that for the
active planes of anatase. In conclusion, although columbite is not a
low-bandgap semiconductor, its large light absorbance and high surface
catalytic activity make it a promising candidate for photocatalytic reactions.

</details>


### [662] [Chiral Altermagnetic Second-Order Topological Phases and Sign-Reversible Transport](https://arxiv.org/abs/2508.12770)
*Chengwu Xie,Zhenzhou Guo,Wenhong Wang,Weizhen Meng,Xiaotian Wang,Zhenxiang Cheng,Xiaodong Zhou*

Main category: cond-mat.mtrl-sci

TL;DR: 研究发现K[Co(HCOO)3]是一种具有手性磁序的第二类拓扑绝缘体，具有独特的电子和光学特性，有望用于拓扑自旋电子学。


<details>
  <summary>Details</summary>
Motivation: 探索手性磁序在altermagnets材料中的应用，特别是手性磁序在提供新颖拓扑性质和输运响应方面的潜力。

Method: 通过实验表征了K[Co(HCOO)3]的磁性、拓扑态和输运性质，揭示了其g波形能带、可控的第二类拓扑态以及与手性相关的反常输运特性。

Result: 发现K[Co(HCOO)3]是首个具有altermagnetic顺序的第二类拓扑绝缘体，具有g波形自旋分裂能带、可控的第二类拓扑态以及与手性锁定的反常输运特性，包括反常霍尔效应和磁光效应。

Conclusion: 该研究发现了首个具有新颖的altermagnetic顺序的第二类拓扑绝缘体材料K[Co(HCOO)3]，并展示了其独特的电子和光学特性。

Abstract: Chiral materials are rare in nature, yet they play a fundamental role in
modern physics due to their unconventional topological properties and transport
responses. While chiral charge and structural orders have been extensively
studied, chiral magnetic order -- particularly in altermagnets (AMs) -- remains
largely unexplored. Here, we demonstrate that the experimentally
well-characterized three-dimensional metal-organic framework K[Co(HCOO)$_3$]
represents the first realization of a chiral second-order topological insulator
with altermagnetic order. This system hosts $\emph{g}$-wave spin-split bands,
controllable second-order topological states, and chirality-locked anomalous
transport properties. Its second-order topological phase manifests as
alternating spin-up and spin-down hinge modes along the boundaries of hexagonal
nanotubes. Remarkably, these spin-polarized hinge states can be switched
through lattice chiral inversion. Simultaneously, the anomalous Hall effect and
magneto-optical effects exhibit reversed signs in left/right-handed
enantiomers, substantiating a universal chirality-controlled response across
both electronic and optical channels. Our results establish chiral AMs as a
promising platform for non-volatile topological spintronics, opening new
avenues for manipulating quantum transport via lattice chirality.

</details>


### [663] [Entropy-driven phase transition in a non-collinear antiferromagnet due to higher-order exchange interactions](https://arxiv.org/abs/2508.12829)
*Leo Kollwitz,Moritz A. Goerzen,Bjarne Beyer,Hendrik Schrautzer,Stefan Heinze*

Main category: cond-mat.mtrl-sci

TL;DR: 研究表明，在Mn/Re(0001)体系中，三Q态和行反铁磁态之间存在一个由熵驱动的低温柔性相变，该相变具有普遍性，也存在于其他多Q态体系中。


<details>
  <summary>Details</summary>
Motivation: 阐述了三Q态作为一种有趣的非共面自旋态，其热力学性质知之甚少，因此需要研究其相变行为。

Method: 通过基于密度泛函理论参数化的原子自旋模型的蒙特卡洛模拟，揭示了三Q态和行反铁磁态之间的低温柔性相变，并推导了自由能和配分函数的解析表达式，以证明该相变由熵驱动。

Result: 成功揭示了三Q态和行反铁磁态之间的低温柔性相变，并证明该相变由熵驱动。

Conclusion: 该研究揭示了三Q态和行反铁磁态之间的低温柔性相变，该相变由熵驱动，并且不仅限于Mn/Re(0001)体系，在多种磁相互作用参数下都会出现，并有望在其他多Q态体系中发生。

Abstract: The triple-Q state arises due to the superposition of three symmetry
equivalent spin spirals stabilized by higher-order exchange interactions. It
has been predicted more than 20 years ago but was only recently discovered in a
Mn monolayer on the Re(0001) surface. To date little is known about the
thermodynamic properties of this intriguing non-coplanar spin state. Here, we
reveal a low-temperature phase transition between the triple-Q and the row-wise
antiferromagnetic state in this system via Monte Carlo simulations based on an
atomistic spin model parametrized by density functional theory. By modeling the
free energy landscape in terms of thermal excitations we derive an analytical
expression of the partition function, which allows us to prove that the phase
transition is driven by entropy. The predicted phase transition is not unique
to Mn/Re(0001) but appears for a wide range of magnetic interaction parameters
and is expected to occur also for other multi-Q states.

</details>


### [664] [Magnetic Order in Pulsed Laser Deposited (Fe,Ni)5GeTe2 Films](https://arxiv.org/abs/2508.13085)
*Tamal Kumar Dalui,John Derek Demaree,Thomas Parker,Ramesh C. Budhani*

Main category: cond-mat.mtrl-sci

TL;DR: Two-dimensional (Fe,Ni)5GeTe2 films were grown on sapphire, showing ferromagnetism up to 495 K and an anomalous Hall effect.


<details>
  <summary>Details</summary>
Motivation: To explore the synthesis and properties of two-dimensional ferromagnetic materials for potential spintronic applications.

Method: Pulsed laser deposition was used to grow highly textured thin films of (Fe,Ni)5GeTe2 on c-plane sapphire.

Result: The synthesized films showed preferential (000l) orientation, robust ferromagnetism with a Curie temperature of 495 K, a clear anomalous Hall effect (anomalous Hall conductivity = 20 ohm-1cm-1, Hall angle = 0.90), and thickness-dependent magnetoresistance.

Conclusion: “The study successfully synthesized highly textured thin films of (Fe,Ni)5GeTe2, a two-dimensional ferromagnet, on c-plane sapphire via pulsed laser deposition. The films exhibit preferential orientation along the (000l) direction, indicating high crystallographic texture.

Abstract: We report the successful growth of highly textured thin films of
(Fe,Ni)5GeTe2 two-dimensional ferromagnet on c-plane sapphire using pulsed
laser deposition. Structural characterization via X-ray diffraction confirms
preferential orientation along the (000l) direction, indicative of a high
crystallographic texture. These films of van der Waals (vdW) type interplanar
bonding exhibit robust ferromagnetism with a Curie temperature reaching = 495
K. Electrical transport measurements reveal a clear anomalous Hall effect, with
an anomalous Hall conductivity and Hall angle (%) of = 20 ohm-1cm-1 and = 0.90,
respectively. Furthermore, the magnetoresistance displays a pronounced
dependence on film thickness, highlighting the tunability of spin-dependent
transport in these vdW ferromagnetic thin films.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [665] [Toward Practical Equilibrium Propagation: Brain-inspired Recurrent Neural Network with Feedback Regulation and Residual Connections](https://arxiv.org/abs/2508.11659)
*Zhuo Liu,Tao Chen*

Main category: cs.NE

TL;DR: 提出了一种名为 FRE-RNN 的新型神经网络，可以更高效、更快速地进行学习，性能与现有方法相当，并解决了深度学习中的一些关键问题。


<details>
  <summary>Details</summary>
Motivation: 现有的 EP 实现存在不稳定和计算成本高昂的问题，需要更有效、更具生物学可行性的学习方法。

Method: 提出了一种受大脑结构和动力学启发的生物学上可行的反馈调节残差递归神经网络（FRE-RNN）框架，用于 EP 学习。

Result: FRE-RNN 通过减少频谱半径实现了快速收敛，将 EP 的计算成本和训练时间降低了几个数量级，并在基准任务上取得了与反向传播（BP）相当的性能。此外，具有大脑启发拓扑的残差连接有助于缓解深度 RNN 中由于反馈通路较弱而出现的梯度消失问题。

Conclusion: 该方法显著提高了 EP 在大规模网络中的适用性和实用性，为在物理神经网络中实现就地学习提供了指导。

Abstract: Brain-like intelligent systems need brain-like learning methods. Equilibrium
Propagation (EP) is a biologically plausible learning framework with strong
potential for brain-inspired computing hardware. However, existing
im-plementations of EP suffer from instability and prohibi-tively high
computational costs. Inspired by the structure and dynamics of the brain, we
propose a biologically plau-sible Feedback-regulated REsidual recurrent neural
network (FRE-RNN) and study its learning performance in EP framework. Feedback
regulation enables rapid convergence by reducing the spectral radius. The
improvement in con-vergence property reduces the computational cost and
train-ing time of EP by orders of magnitude, delivering perfor-mance on par
with backpropagation (BP) in benchmark tasks. Meanwhile, residual connections
with brain-inspired topologies help alleviate the vanishing gradient problem
that arises when feedback pathways are weak in deep RNNs. Our approach
substantially enhances the applicabil-ity and practicality of EP in large-scale
networks that un-derpin artificial intelligence. The techniques developed here
also offer guidance to implementing in-situ learning in physical neural
networks.

</details>


### [666] [Learning Internal Biological Neuron Parameters and Complexity-Based Encoding for Improved Spiking Neural Networks Performance](https://arxiv.org/abs/2508.11674)
*Zofia Rudnicka,Janusz Szczepanski,Agnieszka Pregowska*

Main category: cs.NE

TL;DR: 本文提出了一种新的概率元神经元模型和基于SNN与LZC的分类框架，用于处理时空神经数据，可提升分类精度和效率。


<details>
  <summary>Details</summary>
Motivation: 传统感知器神经元模型在处理复杂数据时存在局限性，本研究旨在通过引入受生物启发的概率元神经元来改进SNN的分类精度，并提出一种新的分类框架以提高时空神经数据的效率和可解释性。

Method: 本文提出了一种新的感知器神经元模型，使用受生物启发的概率元神经元，并联合学习内部神经元参数。此外，还提出了一个结合SNN和Lempel-Ziv复杂度的分类框架，用于分析时空神经数据。研究中使用了反向传播、STDP和Tempotron学习规则，并通过泊松过程模拟神经元发放活动。

Result: 结果表明，受生物启发的概率元神经元模型在SNN中能够提升分类精度。结合SNN和LZC的分类框架能够高效且可解释地分类时空神经数据。在不同的训练方法下，分类器的效率最高可提升11.00%，证明了学习额外神经元参数的重要性。

Conclusion: 本研究提出的概率元神经元模型和结合SNN与Lempel-Ziv复杂度的分类框架，在处理时空神经数据方面表现出优越的效率和可解释性，并且在某些情况下能提升分类精度高达11.00%，证明了学习除加权输入之外的神经元参数的优势。

Abstract: This study introduces a novel approach by replacing the traditional
perceptron neuron model with a biologically inspired probabilistic meta neuron,
where the internal neuron parameters are jointly learned, leading to improved
classification accuracy of spiking neural networks (SNNs). To validate this
innovation, we implement and compare two SNN architectures: one based on
standard leaky integrate-and-fire (LIF) neurons and another utilizing the
proposed probabilistic meta neuron model. As a second key contribution, we
present a new biologically inspired classification framework that uniquely
integrates SNNs with Lempel-Ziv complexity (LZC) a measure closely related to
entropy rate. By combining the temporal precision and biological plausibility
of SNNs with the capacity of LZC to capture structural regularity, the proposed
approach enables efficient and interpretable classification of spatiotemporal
neural data, an aspect not addressed in existing works. We consider learning
algorithms such as backpropagation, spike-timing-dependent plasticity (STDP),
and the Tempotron learning rule. To explore neural dynamics, we use Poisson
processes to model neuronal spike trains, a well-established method for
simulating the stochastic firing behavior of biological neurons. Our results
reveal that depending on the training method, the classifier's efficiency can
improve by up to 11.00%, highlighting the advantage of learning additional
neuron parameters beyond the traditional focus on weighted inputs alone.

</details>


### [667] [Adaptive Spiking with Plasticity for Energy Aware Neuromorphic Systems](https://arxiv.org/abs/2508.11689)
*Eduardo Calle-Ortiz,Hui Guan,Deepak Ganesan,Phuc Nguyen*

Main category: cs.NE

TL;DR: ASPEN是一种新颖的节能技术，用于神经形态系统，通过在训练期间扰动神经元阈值来减少峰值活动和能耗，从而实现智能、始终开启、超低功耗和低负担的可穿戴设备。


<details>
  <summary>Details</summary>
Motivation: 探索神经形态计算在可穿戴设备上的可行性，识别开放的研究方向，并为资源受限设备在始终开启的应用中实现节能计算提供一种自适应脉冲技术。

Method: ASPEN通过在训练期间对神经元阈值进行随机扰动，实现能量感知计算，该方法能够增强网络的鲁棒性、泛化能力，并减少峰值活动，从而在无需复杂重新训练或剪枝的情况下实现能量控制。

Result: ASPEN能够显著降低峰值计数和能耗，同时保持与最先进方法相媲美的准确性。

Conclusion: ASPEN能够在不影响精度的前提下，显著降低神经形态系统的峰值计数和能耗，适用于资源受限的始终开启的应用。

Abstract: This paper presents ASPEN, a novel energy-aware technique for neuromorphic
systems that could unleash the future of intelligent, always-on,
ultra-low-power, and low-burden wearables. Our main research objectives are to
explore the feasibility of neuromorphic computing for wearables, identify open
research directions, and demonstrate the feasibility of developing an adaptive
spiking technique for energy-aware computation, which can be game-changing for
resource-constrained devices in always-on applications. As neuromorphic
computing systems operate based on spike events, their energy consumption is
closely related to spiking activity, i.e., each spike incurs computational and
power costs; consequently, minimizing the number of spikes is a critical
strategy for operating under constrained energy budgets. To support this goal,
ASPEN utilizes stochastic perturbations to the neuronal threshold during
training to not only enhance the network's robustness across varying
thresholds, which can be controlled at inference time, but also act as a
regularizer that improves generalization, reduces spiking activity, and enables
energy control without the need for complex retraining or pruning. More
specifically, ASPEN adaptively adjusts intrinsic neuronal parameters as a
lightweight and scalable technique for dynamic energy control without
reconfiguring the entire model. Our evaluation on neuromorphic emulator and
hardware shows that ASPEN significantly reduces spike counts and energy
consumption while maintaining accuracy comparable to state-of-the-art methods.

</details>


### [668] [Data-Driven Discovery of Interpretable Kalman Filter Variants through Large Language Models and Genetic Programming](https://arxiv.org/abs/2508.11703)
*Vasileios Saketos,Sebastian Kaltenbach,Sergey Litvinov,Petros Koumoutsakos*

Main category: cs.NE

TL;DR: 通过结合使用进化算法（CGP）和大型语言模型（LLM），研究人员发现了一种自动化方法来发现科学计算中的算法。该方法在卡尔曼滤波器最优性假设成立时能找到接近最优的解，在假设不成立时能找到优于卡尔曼滤波器的可解释替代方案。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索是否可以通过自动化、数据驱动的进化过程（利用CGP和LLM）来发现科学计算中的著名算法——卡尔曼滤波器。

Method: 本研究采用笛卡尔遗传编程（CGP）和大型语言模型（LLM）的自动化、数据驱动的进化过程来发现卡尔曼滤波器。

Result: 研究结果表明，在卡尔曼最优性假设成立的情况下，CGP和LLM辅助的进化框架能够收敛到近乎最优的解。当这些假设被违反时，该框架能够进化出可解释的替代方案，其性能优于卡尔曼滤波器。

Conclusion: 该研究表明，结合进化算法和生成模型，可以为科学计算中的可解释、数据驱动的简单计算模块的合成提供一种有效的方法，从而实现算法发现。

Abstract: Algorithmic discovery has traditionally relied on human ingenuity and
extensive experimentation. Here we investigate whether a prominent scientific
computing algorithm, the Kalman Filter, can be discovered through an automated,
data-driven, evolutionary process that relies on Cartesian Genetic Programming
(CGP) and Large Language Models (LLM). We evaluate the contributions of both
modalities (CGP and LLM) in discovering the Kalman filter under varying
conditions. Our results demonstrate that our framework of CGP and LLM-assisted
evolution converges to near-optimal solutions when Kalman optimality
assumptions hold. When these assumptions are violated, our framework evolves
interpretable alternatives that outperform the Kalman filter. These results
demonstrate that combining evolutionary algorithms and generative models for
interpretable, data-driven synthesis of simple computational modules is a
potent approach for algorithmic discovery in scientific computing.

</details>


### [669] [LLM4CMO: Large Language Model-aided Algorithm Design for Constrained Multiobjective Optimization](https://arxiv.org/abs/2508.11871)
*Zhen-Song Chen,Hong-Wei Ding,Xian-Jia Wang,Witold Pedrycz*

Main category: cs.NE

TL;DR: A new algorithm called LLM4CMO uses AI (LLMs) to help design better optimization algorithms for complex problems with multiple conflicting goals and constraints. It performed better than existing methods in tests and shows that AI can be a useful partner in creating these algorithms.


<details>
  <summary>Details</summary>
Motivation: Existing dual-population two-stage algorithms show promise for constrained multi-objective optimization problems (CMOPs), but designing high-performing algorithms is challenging. LLMs offer potential for assisting algorithm design, but their integration is underexplored.

Method: LLM4CMO utilizes a dual-population, two-stage framework. Stage 1 identifies the constrained and unconstrained Pareto fronts. Stage 2 employs hybrid operators, an epsilon-based constraint-handling method, a classification-based UPF-CPF relationship strategy, and dynamic resource allocation. Core modules were designed using prompt template engineering and LLM-human interaction.

Result: LLM4CMO demonstrated superior performance compared to eleven state-of-the-art algorithms on six benchmark test suites and ten real-world CMOPs. Ablation studies confirmed the effectiveness of the LLM-aided modular design.

Conclusion: LLM4CMO, a novel CMOEA based on a dual-population, two-stage framework, outperforms eleven state-of-the-art baseline algorithms in experiments. The study suggests LLMs can be efficient co-designers for complex evolutionary optimization algorithms.

Abstract: Constrained multi-objective optimization problems (CMOPs) frequently arise in
real-world applications where multiple conflicting objectives must be optimized
under complex constraints. Existing dual-population two-stage algorithms have
shown promise by leveraging infeasible solutions to improve solution quality.
However, designing high-performing constrained multi-objective evolutionary
algorithms (CMOEAs) remains a challenging task due to the intricacy of
algorithmic components. Meanwhile, large language models (LLMs) offer new
opportunities for assisting with algorithm design; however, their effective
integration into such tasks remains underexplored. To address this gap, we
propose LLM4CMO, a novel CMOEA based on a dual-population, two-stage framework.
In Stage 1, the algorithm identifies both the constrained Pareto front (CPF)
and the unconstrained Pareto front (UPF). In Stage 2, it performs targeted
optimization using a combination of hybrid operators (HOps), an epsilon-based
constraint-handling method, and a classification-based UPF-CPF relationship
strategy, along with a dynamic resource allocation (DRA) mechanism. To reduce
design complexity, the core modules, including HOps, epsilon decay function,
and DRA, are decoupled and designed through prompt template engineering and
LLM-human interaction. Experimental results on six benchmark test suites and
ten real-world CMOPs demonstrate that LLM4CMO outperforms eleven
state-of-the-art baseline algorithms. Ablation studies further validate the
effectiveness of the LLM-aided modular design. These findings offer preliminary
evidence that LLMs can serve as efficient co-designers in the development of
complex evolutionary optimization algorithms. The code associated with this
article is available at https://anonymous.4open.science/r/LLM4CMO971.

</details>


### [670] [Improving MSA Estimation through Adaptive Weight Vectors in MOEA/D](https://arxiv.org/abs/2508.12133)
*Saem Hasan,Muhammad Ali Nayeem,M. Sohel Rahman*

Main category: cs.NE

TL;DR: PMAO++通过结合自适应权重向量调整（MOEA/D-ADF）和PMAO，提高了多序列比对的准确性和系统发育推断的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 准确的系统发育推断依赖于高质量的多序列比对，但最优比对计算复杂且对评分敏感。因此，需要更优的比对方法。

Method: 提出了一种名为MOEA/D-ADF的新型MOEA/D变体，该变体基于适应度方差自适应地调整子问题权重向量，以改善探索-利用权衡。将MOEA/D-ADF与PMAO结合形成PMAO++，PMAO生成的解用于初始化MOEA/D-ADF的种群，并使用30个权重向量进行演化，最终产生多样的比对-树对。

Result: PMAO++在大多数基准测试案例中优于原始PMAO，在17个BAliBASE派生数据集中有12个实现了更低的假阴性（FN）率，并产生了更优的最佳树，包括几个FN率为零的实例。

Conclusion: PMAO++在序列比对和系统发育分析方面表现出明显的优势，特别是在FN率和最佳树方面优于PMAO，并且能够提供多样的比对-树对，有利于下游分析。

Abstract: Accurate phylogenetic inference from biological sequences depends critically
on the quality of multiple sequence alignments, yet optimal alignment for many
sequences is computationally intractable and sensitive to scoring choices. In
this work we introduce MOEA/D-ADF, a novel variant of MOEA/D that adaptively
adjusts subproblem weight vectors based on fitness variance to improve the
exploration-exploitation trade-off. We combine MOEA/D-ADF with PMAO (PASTA with
many application-aware optimization criteria) to form PMAO++, where
PMAO-generated solutions are used to seed MOEA/D-ADF, which then evolves a
population using 30 weight vectors to produce a diverse ensemble of
alignment-tree pairs. PMAO++ outperforms the original PMAO on a majority of
benchmark cases, achieving better false-negative (FN) rates on 12 of 17
BAliBASE-derived datasets and producing superior best-case trees, including
several instances with zero FN rate. Beyond improving single best alignments,
the rich set of alignment-tree pairs produced by PMAO++ is especially valuable
for downstream summary methods (for example, consensus and summary-tree
approaches), allowing more robust phylogenetic inference by integrating signal
across multiple plausible alignments and trees. Certain dataset features, such
as large terminal N/C extensions found in the RV40 group, remain challenging,
but overall PMAO++ demonstrates clear advantages for sequence-based
phylogenetic analysis. Future work will explore parameter tuning, larger
benchmark suites, and tighter integration with summary-tree pipelines to
further enhance applicability for biological sequence studies.

</details>


### [671] [A Self-Ensemble Inspired Approach for Effective Training of Binary-Weight Spiking Neural Networks](https://arxiv.org/abs/2508.12609)
*Qingyan Meng,Mingqing Xiao,Zhengyu Ma,Huihui Zhou,Yonghong Tian,Zhouchen Lin*

Main category: cs.NE

TL;DR: 本文提出了一种新方法来训练二值权重SNN（SEI-BWSNN），解决了SNN和BNN训练中的梯度不可微问题。该方法将SNN训练视为一种特殊的二值神经网络训练，并结合了多重短连接和知识蒸馏技术。实验结果显示，该方法在ImageNet上达到了82.52%的准确率，且延迟低。


<details>
  <summary>Details</summary>
Motivation: 尽管SNN和BNN在各自领域都面临梯度不可微的挑战，但二者之间的深层联系以及相互借鉴训练技术以提升性能的研究尚不系统。特别是，训练二值权重的SNN面临更大的困难。本文旨在探索SNN和BNN之间的关系，并提出一种能有效训练二值权重SNN的新方法。

Method: 本文提出了一种新颖的视角来理解SNN的动态及其与BNN的紧密联系，通过分析反向传播过程，将前馈SNN的训练视为一个带有噪声注入的二值激活神经网络的自合奏训练。基于此理解，开发了自合奏激励二值权重SNN（SEI-BWSNN）训练方法，并结合了多重短连接结构和基于知识蒸馏的训练技术来优化训练过程。

Result: 所提出的SEI-BWSNN方法在仅使用1比特权重的情况下，实现了高性能和低延迟。具体来说，通过二值化Transformer模型的前馈网络层，在ImageNet数据集上取得了82.52%的准确率，且仅使用了2个时间步，验证了该方法在SNN训练，尤其是二值权重SNN训练方面的有效性。

Conclusion: 所提出的自重构激励二值权重SNN（SEI-BWSNN）训练方法，通过利用多重短连接和知识蒸馏技术，能够有效地训练二值权重SNN，即使在仅使用1比特权重的情况下也能实现高性能和低延迟。研究表明，通过二值化Transformer架构中的前馈网络层，可以在ImageNet上达到82.52%的准确率，且仅需2个时间步，证明了该方法在SNN训练领域的潜力和有效性。

Abstract: Spiking Neural Networks (SNNs) are a promising approach to low-power
applications on neuromorphic hardware due to their energy efficiency. However,
training SNNs is challenging because of the non-differentiable spike generation
function. To address this issue, the commonly used approach is to adopt the
backpropagation through time framework, while assigning the gradient of the
non-differentiable function with some surrogates. Similarly, Binary Neural
Networks (BNNs) also face the non-differentiability problem and rely on
approximating gradients. However, the deep relationship between these two
fields and how their training techniques can benefit each other has not been
systematically researched. Furthermore, training binary-weight SNNs is even
more difficult. In this work, we present a novel perspective on the dynamics of
SNNs and their close connection to BNNs through an analysis of the
backpropagation process. We demonstrate that training a feedforward SNN can be
viewed as training a self-ensemble of a binary-activation neural network with
noise injection. Drawing from this new understanding of SNN dynamics, we
introduce the Self-Ensemble Inspired training method for (Binary-Weight) SNNs
(SEI-BWSNN), which achieves high-performance results with low latency even for
the case of the 1-bit weights. Specifically, we leverage a structure of
multiple shortcuts and a knowledge distillation-based training technique to
improve the training of (binary-weight) SNNs. Notably, by binarizing FFN layers
in a Transformer architecture, our approach achieves 82.52% accuracy on
ImageNet with only 2 time steps, indicating the effectiveness of our
methodology and the potential of binary-weight SNNs.

</details>


### [672] [IzhiRISC-V -- a RISC-V-based Processor with Custom ISA Extension for Spiking Neuron Networks Processing with Izhikevich Neurons](https://arxiv.org/abs/2508.12846)
*Wiktor J. Szczerek,Artur Podobas*

Main category: cs.NE

TL;DR: 为了提高Spiking Neural Network在RISC-V上的能效，我们提出了一种包含神经形态指令集扩展的处理器IzhiRISC-V。


<details>
  <summary>Details</summary>
Motivation: Spiking Neural Network在通用硬件上存在代码效率低的问题，导致能耗高。需要一种新的方法来提高其能效。

Method: 介绍了一种在RISC-V处理器上实现神经形态指令集扩展的方法，并通过定制ISA扩展和硬件加速来优化Spiking Neural Network的处理。

Result: 实现了支持神经形态指令集扩展的RISC-V处理器IzhiRISC-V，这是构建大规模Spiking Neural Network系统的第一步。

Conclusion: 该论文提出了一个基于RISC-V的处理器IzhiRISC-V，它支持神经形态指令集扩展，以提高Spiking Neural Network在通用硬件上的能效。

Abstract: Spiking Neural Network processing promises to provide high energy efficiency
due to the sparsity of the spiking events. However, when realized on
general-purpose hardware -- such as a RISC-V processor -- this promise can be
undermined and overshadowed by the inefficient code, stemming from repeated
usage of basic instructions for updating all the neurons in the network. One of
the possible solutions to this issue is the introduction of a custom ISA
extension with neuromorphic instructions for spiking neuron updating, and
realizing those instructions in bespoke hardware expansion to the existing ALU.
In this paper, we present the first step towards realizing a large-scale system
based on the RISC-V-compliant processor called IzhiRISC-V, supporting the
custom neuromorphic ISA extension.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [673] [Categorical Construction of Logically Verifiable Neural Architectures](https://arxiv.org/abs/2508.11647)
*Logan Nye*

Main category: cs.LO

TL;DR: 通过将逻辑理论作为代数结构（Lawvere理论）并使用范畴代数将其转换为神经网络，可以构建具有可证明逻辑保证的神经网络体系结构，从而解决神经网络在逻辑推理中的局限性。


<details>
  <summary>Details</summary>
Motivation: 解决神经网络在可靠的逻辑推理方面的局限性，这些推理通常会在推理过程中违反基本的逻辑原则。

Method: 该方法将逻辑理论视为称为Lawvere理论的代数结构，并使用2范畴参数图的范畴代数将其转换为神经网络。

Result: 该框架通过为命题逻辑构建可微分神经网络结构来证明这一点，该结构在保持可梯度下降训练的同时保留布尔推理。该框架在有限逻辑理论和神经网络之间建立了双射对应关系，证明每个逻辑约束网络都唯一地来自该构造。

Conclusion: 该框架为可信赖的AI系统提供了数学基础，可应用于定理证明、形式验证和需要可验证逻辑行为的安全关键推理任务。

Abstract: Neural networks excel at pattern recognition but struggle with reliable
logical reasoning, often violating basic logical principles during inference.
We address this limitation by developing a categorical framework that
systematically constructs neural architectures with provable logical
guarantees. Our approach treats logical theories as algebraic structures called
Lawvere theories, which we transform into neural networks using categorical
algebra in the 2-category of parametric maps. Unlike existing methods that
impose logical constraints during training, our categorical construction embeds
logical principles directly into the network's architectural structure, making
logical violations mathematically impossible. We demonstrate this framework by
constructing differentiable neural architectures for propositional logic that
preserve boolean reasoning while remaining trainable via gradient descent. Our
main theoretical result establishes a bijective correspondence between finitary
logical theories and neural architectures, proving that every logically
constrained network arises uniquely from our construction. This extends
Categorical Deep Learning beyond geometric symmetries to semantic constraints,
enabling automatic derivation of verified architectures from logical
specifications. The framework provides mathematical foundations for trustworthy
AI systems, with applications to theorem proving, formal verification, and
safety-critical reasoning tasks requiring verifiable logical behavior.

</details>


### [674] [Queen Domination by SAT Solving](https://arxiv.org/abs/2508.11945)
*Taha Rostami,Curtis Bright*

Main category: cs.LO

TL;DR: 本研究提出了一种结合效率与可验证性的方法来解决皇后支配问题，通过SAT编码和现代SAT求解器，解决了n=19的难题，并修正了n=16的数据。


<details>
  <summary>Details</summary>
Motivation: 在解决皇后支配问题（minimum number of queens needed to attack all squares on an n x n chessboard）的已知最优数的同时，为先前未经验证的特定实例（如n=16和n=19）提供可验证的证明。

Method: 将皇后支配问题归约（reduce）为命题可满足性问题（SAT），并利用能够生成证明证书的现代SAT求解器来解决。

Result: 发现了n=16的先前结果存在差异，并解决了先前未解决的n=19的皇后支配问题。

Conclusion: 该论文通过改进SAT编码、采用静态对称性打破和Cube-and-Conquer范式，实现了高效且可验证的皇后支配问题解决方案。

Abstract: The queen domination problem asks for the minimum number of queens needed to
attack all squares on an $n\times n$ chessboard. Once this optimal number is
known, determining the number of distinct solutions up to isomorphism has also
attracted considerable attention. Previous work has introduced specialized and
highly optimized search procedures to address open instances of the problem.
While efficient in terms of runtime, these approaches have not provided proofs
that can be independently verified by third-party checkers. In contrast, this
paper aims to combine efficiency with verifiability. We reduce the problem to a
propositional satisfiability problem (SAT) using a straightforward encoding,
and solve the resulting formulas with modern SAT solvers capable of generating
proof certificates. By improving the SAT encoding with a novel literal ordering
strategy, and leveraging established techniques such as static symmetry
breaking and the Cube-and-Conquer paradigm, this paper achieves both
performance and trustworthiness. Our approach discovers and corrects a
discrepancy in previous results for $n=16$ and resolves the previously open
case $n=19$.

</details>


### [675] [Finite Axiomatizability by Disjunctive Existential Rules](https://arxiv.org/abs/2508.11946)
*Marco Calautti,Marco Console,Andreas Pieris*

Main category: cs.LO

TL;DR: 该工作研究了析取存在规则的表现力，并用模型论性质来精确描述它们。


<details>
  <summary>Details</summary>
Motivation: 该工作旨在精确描述析取存在规则的表现力，并建立其与模型论性质的关系。

Method: 通过使用临界性、闭产品的闭包的精炼版本以及图兼容性来精确描述析取存在规则的表现力。

Result: 该工作精确描述了析取存在规则的表现力，并建立了其与模型论性质的关系。

Conclusion: 该工作通过模型论性质（临界性、闭产品的闭包的精炼版本以及依赖于图的方法的新颖性质图兼容性）来精确描述析取存在规则的表现力。

Abstract: Rule-based languages lie at the core of several areas of central importance
to databases and artificial intelligence such as deductive databases and
knowledge representation and reasoning. Disjunctive existential rules (a.k.a.
disjunctive tuple-generating dependencies in the database literature) form such
a prominent rule-based language. The goal of this work is to pinpoint the
expressive power of disjunctive existential rules in terms of insightful
model-theoretic properties. More precisely, given a collection $\mathcal{C}$ of
relational structures, we show that $\mathcal{C}$ is axiomatizable via a finite
set $\Sigma$ of disjunctive existential rules (i.e., $\mathcal{C}$ is precisely
the set of models of $\Sigma$) iff $\mathcal{C}$ enjoys certain model-theoretic
properties. This is achieved by using the well-known property of criticality, a
refined version of closure under direct products, and a novel property called
diagrammatic compatibility that relies on the method of diagrams. We further
establish analogous characterizations for the well-behaved classes of linear
and guarded disjunctive existential rules by adopting refined versions of
diagrammatic compatibility that consider the syntactic restrictions imposed by
linearity and guardedness; this illustrates the robustness of diagrammatic
compatibility. We finally exploit diagrammatic compatibility to rewrite a set
of guarded disjunctive existential rules into an equivalent set that falls in
the weaker class of linear disjunctive existential rules, if one exists.

</details>


### [676] [Reachability is Decidable for ATM-Typable Finitary PCF with Effect Handlers](https://arxiv.org/abs/2508.12572)
*Ryunosuke Endo,Tachio Terauchi*

Main category: cs.LO

TL;DR: 该论文证明了带代数效应和处理器的finitary PCF语言在加入答案类型修改（ATM）后，可达性问题仍然是可判定的。研究还展示了ATM对程序可型化性的影响，并利用CPS变换证明了相关程序的终止性。


<details>
  <summary>Details</summary>
Motivation: 为了探究在finitary PCF语言中加入代数效应和处理器后，可达性问题是否仍然可判定，并与现有研究进行对比。

Method: 通过一种新颖的连续传递风格（CPS）变换，将带效应处理器的ATM类型finitary PCF程序转化为不带效应处理器的finitary PCF程序。

Result: 证明了在扩展了ATM的类型系统中，带代数效应和处理器的finitary PCF语言的可达性问题是可判定的。通过CPS变换，还证明了不含递归函数的ATM类型finitary PCF语言的程序会终止。

Conclusion: 该研究证明了在扩展了答案类型修改（ATM）的类型系统中，带代数效应和处理器的finitary PCF语言的可达性问题是可判定的。研究还展示了ATM的引入会影响可型化性，使得一些程序可以被型化但也有一些程序变得无法被型化。此外，该研究还证明了不含递归函数的ATM类型finitary PCF语言的程序会终止，并反驳了一项先前研究的结论。

Abstract: It is well known that the reachability problem for simply-typed lambda
calculus with recursive definitions and finite base-type values (finitary PCF)
is decidable. A recent paper by Dal Lago and Ghyselen has shown that the same
problem becomes undecidable when the language is extended with algebraic effect
and handlers (effect handlers). We show that, perhaps surprisingly, the problem
becomes decidable even with effect handlers when the type system is extended
with answer type modification (ATM). A natural intuition may find the result
contradictory, because one would expect allowing ATM makes more programs
typable. Indeed, this intuition is correct in that there are programs that are
typable with ATM but not without it, as we shall show in the paper. However, a
corollary of our decidability result is that the converse is true as well:
there are programs that are typable without ATM but becomes untypable with ATM,
and we will show concrete examples of such programs in the paper. Our
decidability result is proven by a novel continuation passing style (CPS)
transformation that transforms an ATM-typable finitary PCF program with effect
handlers to a finitary PCF program without effect handlers. Additionally, as
another application of our CPS transformation, we show that every
recursive-function-free ATM-typable finitary PCF program with effect handlers
terminates, while there are (necessarily ATM-untypable) recursive-function-free
finitary PCF programs with effect handlers that may diverge. Finally, we
disprove a claim made in a recent work that proved a similar but strictly
weaker decidability result. We foresee our decidability result to lay a
foundation for developing verification methods for programs with effect
handlers, just as the decidability result for reachability of finitary PCF has
done such for programs without effect handlers.

</details>


### [677] [From Interpolating Formulas to Separating Languages and Back Again](https://arxiv.org/abs/2508.12805)
*Agi Kurucz,Frank Wolter,Michael Zakharyaschev*

Main category: cs.LO

TL;DR: 本研究将Craig插值问题从具有CIP的逻辑推广到不具有CIP的逻辑，并将其与语言分离问题联系起来，最终证明了LTL的Craig插值存在性是可判定的。


<details>
  <summary>Details</summary>
Motivation: 传统研究主要关注具有CIP的逻辑及其插值提取算法，而忽略了不具有CIP的逻辑。本研究旨在拓展Craig插值的研究范围，包括不具有CIP的逻辑、弱语言插值以及逻辑语言与形式语言中的插值问题。

Method: 本研究通过考察不具有CIP的逻辑、在弱语言中寻找插值、将插值问题转化为语言分离问题，并连接分离问题和Craig插值存在性问题来研究Craig插值。

Result: 研究表明，可以通过分析不具有CIP的逻辑、在弱语言中寻找插值以及研究语言分离问题来解决 Craig插值问题，并且可以利用正则语言分离问题的可判定性来证明LTL的Craig插值存在性是可判定的。

Conclusion: 该研究将Craig插值问题推广到不具有Craig插值性质（CIP）的逻辑，并探讨了在较弱语言中寻找Craig插值的问题，以及在形式语言中插值与分离的关系。最后，将分离问题在正则语言上的可判定性与线性时序逻辑（LTL）的Craig插值存在性问题联系起来。

Abstract: Traditionally, research on Craig interpolation is concerned with (a)
establishing the Craig interpolation property (CIP) of a logic saying that
every valid implication in the logic has a Craig interpolant and (b) designing
algorithms that extract Craig interpolants from proofs. Logics that lack the
CIP are regarded as `pathological' and excluded from consideration. In this
chapter, we survey variations and generalisations of traditional Craig
interpolation. First, we consider Craig interpolants for implications in logics
without the CIP, focusing on the decidability and complexity of deciding their
existence. We then generalise interpolation by looking for Craig interpolants
in languages L' that can be weaker than the language L of the given
implication. Thus, do not only we restrict the non-logical symbols of Craig
interpolants but also the logical ones. The resulting L/L'-interpolation
problem generalises L/L'-definability, the question whether an L-formula is
equivalent to some L'-formula. After that, we move from logical languages to
formal languages where interpolation disguises itself as separation: given two
disjoint languages in a class C, does there exist a separating language in a
smaller class C'? This question is particularly well-studied in the case when
the input languages are regular and the separating language is first-order
definable. Finally, we connect the different research strands by showing how
the decidability of the separation problem for regular languages can be used to
prove the decidability of Craig interpolant existence for linear temporal logic
LTL.

</details>


### [678] [Compositional Verification of Almost-Sure Büchi Objectives in MDPs](https://arxiv.org/abs/2508.13087)
*Marck van der Vegt,Kazuki Watanabe,Ichiro Hasuo,Sebastian Junges*

Main category: cs.LO

TL;DR: 本研究提出了在具有组合结构的 MDP 中验证几乎确定性 Buchi 目标的方法，并给出了两种算法：一种递归算法和一种迭代算法。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决在具有已知、组合结构的 MDP 中验证几乎确定性 Buchi 目标的问题，特别是确定是否存在一种策略可以确保 Buchi 目标几乎确定性地得到满足。

Method: 我们定义了两种算法：一种是自下而上的算法，以递归方式计算统计数据，以获得整个字符串图的验证结果；另一种是多项式时间的迭代算法，通过执行迭代策略精炼来避免计算所有适当的退出集。

Result: 我们证明了适当的退出集与 Buchi 状态的可达性是组合验证几乎确定性 Buchi 目标的一个充分必要统计量。

Conclusion: 本研究表明，具有正确退出集和 Buchi 状态可达性的组合是用于组合验证几乎确定性 Buchi 目标，并且是充分必要条件。我们还提出了两种算法：一种自下而上的递归算法，用于计算整个字符串图的统计数据；另一种是迭代策略精炼算法，其运行时间为多项式时间。

Abstract: This paper studies the verification of almost-sure B\"uchi objectives in MDPs
with a known, compositional structure based on string diagrams. In particular,
we ask whether there is a strategy that ensures that a B\"uchi objective is
almost-surely satisfied. We first show that proper exit sets -- the sets of
exits that can be reached within a component without losing locally -- together
with the reachability of a B\"uchi state are a sufficient and necessary
statistic for the compositional verification of almost-sure B\"uchi objectives.
The number of proper exit sets may grow exponentially in the number of exits.
We define two algorithms: (1) A straightforward bottom-up algorithm that
computes this statistic in a recursive manner to obtain the verification result
of the entire string diagram and (2) a polynomial-time iterative algorithm
which avoids computing all proper exit sets by performing iterative strategy
refinement.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [679] [Centralized Permutation Equivariant Policy for Cooperative Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2508.11706)
*Zhuofan Xu,Benedikt Bollig,Matthias Függer,Thomas Nowak,Vincent Le Dréau*

Main category: cs.MA

TL;DR: CPE 学习使用 GLPE 网络解决了 MARL 中的部分可观察性和可扩展性问题，提高了合作任务的性能。


<details>
  <summary>Details</summary>
Motivation: 为了克服多智能体强化学习 (MARL) 中分布式策略的部分可观察性和中心化策略的可扩展性挑战。

Method: 提出了一种新的置换等价架构，称为全局-局部置换等价 (GLPE) 网络，用于中心化训练和执行。

Result: CPE 无缝集成值分解和 actor-critic 方法，在合作基准测试 MPE、SMAC 和 RWARE 中显著提高了标准 CTDE 算法的性能。

Conclusion: CPE 学习是一种中心化训练和执行框架，它利用新的全局-局部置换等价 (GLPE) 网络，克服了现有方法的局限性。

Abstract: The Centralized Training with Decentralized Execution (CTDE) paradigm has
gained significant attention in multi-agent reinforcement learning (MARL) and
is the foundation of many recent algorithms. However, decentralized policies
operate under partial observability and often yield suboptimal performance
compared to centralized policies, while fully centralized approaches typically
face scalability challenges as the number of agents increases.
  We propose Centralized Permutation Equivariant (CPE) learning, a centralized
training and execution framework that employs a fully centralized policy to
overcome these limitations. Our approach leverages a novel permutation
equivariant architecture, Global-Local Permutation Equivariant (GLPE) networks,
that is lightweight, scalable, and easy to implement. Experiments show that CPE
integrates seamlessly with both value decomposition and actor-critic methods,
substantially improving the performance of standard CTDE algorithms across
cooperative benchmarks including MPE, SMAC, and RWARE, and matching the
performance of state-of-the-art RWARE implementations.

</details>


### [680] [SafeSieve: From Heuristics to Experience in Progressive Pruning for LLM-based Multi-Agent Communication](https://arxiv.org/abs/2508.11733)
*Ruijia Zhang,Xinyan Zhao,Ruixiang Wang,Sigen Chen,Guibin Zhang,An Zhang,Kun Wang,Qingsong Wen*

Main category: cs.MA

TL;DR: SafeSieve是一种创新的多智能体通信优化算法，通过渐进式剪枝减少了token开销和冗余通信，同时保持了高准确率和鲁棒性，适用于实际多智能体系统。


<details>
  <summary>Details</summary>
Motivation: LLM驱动的多智能体系统虽然协作能力强，但常伴有通信冗余和过多的token开销。现有方法虽能通过预训练GNN或贪婪算法提高效率，但常将任务前后优化割裂，缺乏统一策略。

Method: SafeSieve是一种渐进式、自适应的多智能体剪枝算法，通过新颖的双重机制动态地优化智能体间的通信。SafeSieve整合了基于LLM的初始语义评估和累积的性能反馈，实现了从启发式初始化到经验驱动的细化的平滑过渡。与现有的贪婪式Top-k剪枝方法不同，SafeSieve采用0扩展聚类来保留结构上连贯的智能体组，同时消除无效连接。

Result: 实验结果表明，SafeSieve在SVAMP、HumanEval等基准测试中达到了94.01%的平均准确率，同时将token使用量减少了12.4%-27.8%。在对抗提示注入攻击时，准确率平均仅下降1.23%，表现出良好的鲁棒性。在异构环境中，SafeSieve将部署成本降低了13.3%，同时保持了性能。

Conclusion: SafeSieve是一个稳健、高效且可扩展的框架，适用于实际的多智能体系统。

Abstract: LLM-based multi-agent systems exhibit strong collaborative capabilities but
often suffer from redundant communication and excessive token overhead.
Existing methods typically enhance efficiency through pretrained GNNs or greedy
algorithms, but often isolate pre- and post-task optimization, lacking a
unified strategy. To this end, we present SafeSieve, a progressive and adaptive
multi-agent pruning algorithm that dynamically refines the inter-agent
communication through a novel dual-mechanism. SafeSieve integrates initial
LLM-based semantic evaluation with accumulated performance feedback, enabling a
smooth transition from heuristic initialization to experience-driven
refinement. Unlike existing greedy Top-k pruning methods, SafeSieve employs
0-extension clustering to preserve structurally coherent agent groups while
eliminating ineffective links. Experiments across benchmarks (SVAMP, HumanEval,
etc.) showcase that SafeSieve achieves 94.01% average accuracy while reducing
token usage by 12.4%-27.8%. Results further demonstrate robustness under prompt
injection attacks (1.23% average accuracy drop). In heterogeneous settings,
SafeSieve reduces deployment costs by 13.3% while maintaining performance.
These results establish SafeSieve as a robust, efficient, and scalable
framework for practical multi-agent systems. Our code can be found in
https://anonymous.4open.science/r/SafeSieve-D8F2FFUN.

</details>


### [681] [A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond](https://arxiv.org/abs/2508.11957)
*Xiaodong Qu,Andrews Damoah,Joshua Sherwood,Peiyan Liu,Christian Shun Jin,Lulu Chen,Minjie Shen,Nawwaf Aleisa,Zeyuan Hou,Chenyu Zhang,Lifu Gao,Yanshu Li,Qikai Yang,Qun Wang,Cristabelle De Souza*

Main category: cs.MA

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Artificial Intelligence (AI) agents have rapidly evolved from specialized,
rule-based programs to versatile, learning-driven autonomous systems capable of
perception, reasoning, and action in complex environments. The explosion of
data, advances in deep learning, reinforcement learning, and multi-agent
coordination have accelerated this transformation. Yet, designing and deploying
unified AI agents that seamlessly integrate cognition, planning, and
interaction remains a grand challenge. In this review, we systematically
examine the architectural principles, foundational components, and emergent
paradigms that define the landscape of contemporary AI agents. We synthesize
insights from cognitive science-inspired models, hierarchical reinforcement
learning frameworks, and large language model-based reasoning. Moreover, we
discuss the pressing ethical, safety, and interpretability concerns associated
with deploying these agents in real-world scenarios. By highlighting major
breakthroughs, persistent challenges, and promising research directions, this
review aims to guide the next generation of AI agent systems toward more
robust, adaptable, and trustworthy autonomous intelligence.

</details>


### [682] [Synchronization Dynamics of Heterogeneous, Collaborative Multi-Agent AI Systems](https://arxiv.org/abs/2508.12314)
*Chiranjit Mitra*

Main category: cs.MA

TL;DR: 该研究提出了一种受物理学启发的框架，将同步理论与多智能体AI相结合，使用Kuramoto模型来描述和优化AI代理的集体行为，并发现增加耦合强度可以改善同步和协作。


<details>
  <summary>Details</summary>
Motivation: 旨在弥合同步理论与多智能体AI系统之间的差距，以理解和优化AI系统的集体行为。

Method: 将Kuramoto模型改编为描述异构AI智能体在复杂任务执行中的集体动力学，将AI智能体表示为具有相位和幅度动力学的耦合振荡器。引入序参数量化协调和同步程度。将思维链提示与同步现象形式化对应。

Result: 通过模拟证明，增加耦合强度可以促进强大的同步，即使在异构智能体和不同网络拓扑的情况下也能如此。

Conclusion: 该研究提出了一种新的跨学科框架，将同步理论与多智能体AI系统相结合，通过调整Kuramoto模型来描述异构AI智能体在复杂任务执行中的集体动力学。该模型通过将AI智能体表示为具有相位和幅度动力学的耦合振荡器，捕捉了网络系统中智能体专业化、影响和通信的关键方面。研究引入了一个序参数来量化协调和同步的程度，揭示了耦合强度、智能体多样性和网络拓扑如何影响新兴的集体行为。此外，该研究将AI推理中的思维链提示与同步现象进行了形式化的详细对应，将类似人类的迭代问题解决方法与新兴的群体智能统一起来。通过在全连接和确定性无标度网络上进行的大量模拟，研究证明了尽管智能体能力各异，但增加耦合能够促进强大的同步，这反映了现实中协作式AI的场景。该研究的这一受物理学启发的 दिसून表明，为设计、分析和优化可扩展、自适应和可解释的多智能体AI系统奠定了严格的数学基础。这项工作为原则性地协调agentic AI开辟了道路，并为未来纳入学习动力学和自适应网络架构以进一步提高系统弹性和效率奠定了基础。

Abstract: We present a novel interdisciplinary framework that bridges synchronization
theory and multi-agent AI systems by adapting the Kuramoto model to describe
the collective dynamics of heterogeneous AI agents engaged in complex task
execution. By representing AI agents as coupled oscillators with both phase and
amplitude dynamics, our model captures essential aspects of agent
specialization, influence, and communication within networked systems. We
introduce an order parameter to quantify the degree of coordination and
synchronization, providing insights into how coupling strength, agent
diversity, and network topology impact emergent collective behavior.
Furthermore, we formalize a detailed correspondence between Chain-of-Thought
prompting in AI reasoning and synchronization phenomena, unifying human-like
iterative problem solving with emergent group intelligence. Through extensive
simulations on all-to-all and deterministic scale-free networks, we demonstrate
that increased coupling promotes robust synchronization despite heterogeneous
agent capabilities, reflecting realistic collaborative AI scenarios. Our
physics-informed approach establishes a rigorous mathematical foundation for
designing, analyzing, and optimizing scalable, adaptive, and interpretable
multi-agent AI systems. This work opens pathways for principled orchestration
of agentic AI and lays the groundwork for future incorporation of learning
dynamics and adaptive network architectures to further enhance system
resilience and efficiency.

</details>


### [683] [A Taxonomy of Hierarchical Multi-Agent Systems: Design Patterns, Coordination Mechanisms, and Industrial Applications](https://arxiv.org/abs/2508.12683)
*David J. Moore*

Main category: cs.MA

TL;DR: 该论文提出了一个用于分层多智能体系统（HMAS）的五维分类法，结合了协调机制和工业应用，以分析和比较不同设计。该分类法统一了结构、时间、通信维度，并探讨了可解释性、可扩展性和LLM集成等挑战。


<details>
  <summary>Details</summary>
Motivation: 为了应对分层多智能体系统（HMAS）的复杂性，并提供一个比较不同设计方法的框架。当前的HMAS设计虽然能简化协调，但也可能带来不易察觉的权衡。因此，需要一个统一的框架来分析其结构、时间、通信和协调机制。

Method: 提出了一种基于五个维度（控制层级、信息流、角色和任务委派、时间层、通信结构）的多维度分类法，并将其与具体的协调机制（如合同网协议、分层强化学习）以及工业应用实例（电网、油田运营）相结合，用于分析和比较不同的分层多智能体系统。

Result: 该论文提出的分类法是第一个将分层多智能体系统的结构、时间、通信维度统一到一个单一设计框架中的方法，它连接了经典的协调机制与现代的强化学习和大型语言模型代理。工业案例表明，分层结构可以在保持局部自主性的同时实现全局效率，但这种平衡是微妙的。

Conclusion: 该论文提出了一个多维度的部分可解释性多智能体系统（HMAS）分类法，涵盖了控制层级、信息流、角色和任务委派、时间层以及通信结构。该分类法将经典的协调机制与现代强化学习和大型语言模型代理相结合，旨在为比较不同方法提供一个视角，而不是规定单一的最佳设计。在工业领域（如电网和油田运营）的应用表明，分层结构可以在实现全局效率的同时保持局部自主性，但这种平衡需要仔细权衡。

Abstract: Hierarchical multi-agent systems (HMAS) organize collections of agents into
layered structures that help manage complexity and scale. These hierarchies can
simplify coordination, but they also can introduce trade-offs that are not
always obvious. This paper proposes a multi-dimensional taxonomy for HMAS along
five axes: control hierarchy, information flow, role and task delegation,
temporal layering, and communication structure. The intent is not to prescribe
a single "best" design but to provide a lens for comparing different
approaches.
  Rather than treating these dimensions in isolation, the taxonomy is connected
to concrete coordination mechanisms - from the long-standing contract-net
protocol for task allocation to more recent work in hierarchical reinforcement
learning. Industrial contexts illustrate the framework, including power grids
and oilfield operations, where agents at production, maintenance, and supply
levels coordinate to diagnose well issues or balance energy demand. These cases
suggest that hierarchical structures may achieve global efficiency while
preserving local autonomy, though the balance is delicate.
  The paper closes by identifying open challenges: making hierarchical
decisions explainable to human operators, scaling to very large agent
populations, and assessing whether learning-based agents such as large language
models can be safely integrated into layered frameworks. This paper presents
what appears to be the first taxonomy that unifies structural, temporal, and
communication dimensions of hierarchical MAS into a single design framework,
bridging classical coordination mechanisms with modern reinforcement learning
and large language model agents.

</details>
