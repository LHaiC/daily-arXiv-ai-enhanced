<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 90]
- [cs.CL](#cs.CL) [Total: 52]
- [cs.LO](#cs.LO) [Total: 2]
- [cs.GR](#cs.GR) [Total: 1]
- [cs.DC](#cs.DC) [Total: 13]
- [eess.SP](#eess.SP) [Total: 12]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 23]
- [cs.AR](#cs.AR) [Total: 1]
- [cs.GT](#cs.GT) [Total: 8]
- [cs.LG](#cs.LG) [Total: 90]
- [cs.NE](#cs.NE) [Total: 2]
- [physics.app-ph](#physics.app-ph) [Total: 4]
- [eess.SY](#eess.SY) [Total: 20]
- [quant-ph](#quant-ph) [Total: 45]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 8]
- [cs.AI](#cs.AI) [Total: 30]
- [cs.DS](#cs.DS) [Total: 2]
- [cs.RO](#cs.RO) [Total: 24]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [GAZE:Governance-Aware pre-annotation for Zero-shot World Model Environments](https://arxiv.org/abs/2510.14992)
*Leela Krishna,Mengyang Zhao,Saicharithreddy Pasula,Harshit Rajgarhia,Abhishek Mukherji*

Main category: cs.CV

TL;DR: 该论文提出了一个名为GAZE的自动化视频数据处理流程，用于为世界模型训练生成高质量、可信赖的监督数据，显著提高了效率并降低了人工审查成本。


<details>
  <summary>Details</summary>
Motivation: 手动标注数据耗时昂贵且效率低下，阻碍了世界模型训练所需的大规模、精细标注的多模态数据集的生成。

Method: GAZE流程包括三个主要步骤：1. 格式标准化和分片；2. 利用一系列AI模型进行密集的多模态预标注（如场景理解、物体跟踪、音频转录、隐私/不适宜内容/未成年人检测）；3. 整合信号并生成结构化输出，便于人工验证。

Result: GAZE流程能够提高效率（每小时人工审查节省约19分钟），并通过自动跳过低相关性片段将人工审查量减少80%以上。它还提高了标签的密度和一致性，并整合了隐私保护和溯源元数据，生成了可直接用于学习跨模态动力学和条件预测的高保真、隐私感知数据集。

Conclusion: GAZE流程为生成高质量世界模型训练数据提供了一个可扩展的蓝图，无需牺牲吞吐量或治理，有效解决了手动标注的瓶颈问题。

Abstract: Training robust world models requires large-scale, precisely labeled
multimodal datasets, a process historically bottlenecked by slow and expensive
manual annotation. We present a production-tested GAZE pipeline that automates
the conversion of raw, long-form video into rich, task-ready supervision for
world-model training. Our system (i) normalizes proprietary 360-degree formats
into standard views and shards them for parallel processing; (ii) applies a
suite of AI models (scene understanding, object tracking, audio transcription,
PII/NSFW/minor detection) for dense, multimodal pre-annotation; and (iii)
consolidates signals into a structured output specification for rapid human
validation.
  The GAZE workflow demonstrably yields efficiency gains (~19 minutes saved per
review hour) and reduces human review volume by >80% through conservative
auto-skipping of low-salience segments. By increasing label density and
consistency while integrating privacy safeguards and chain-of-custody metadata,
our method generates high-fidelity, privacy-aware datasets directly consumable
for learning cross-modal dynamics and action-conditioned prediction. We detail
our orchestration, model choices, and data dictionary to provide a scalable
blueprint for generating high-quality world model training data without
sacrificing throughput or governance.

</details>


### [2] [PC-UNet: An Enforcing Poisson Statistics U-Net for Positron Emission Tomography Denoising](https://arxiv.org/abs/2510.14995)
*Yang Shi,Jingchao Wang,Liangsi Lu,Mingxuan Huang,Ruixin He,Yifeng Xie,Hanqian Liu,Minzhe Guo,Yangyang Liang,Weipeng Zhang,Zimeng Li,Xuhang Chen*

Main category: cs.CV

TL;DR: 提出了一种名为PC-UNet的新的去噪模型，通过PVMC-Loss损失函数，能够有效处理低剂量PET图像的泊松噪声，提高了图像的物理一致性和清晰度。


<details>
  <summary>Details</summary>
Motivation: 临床上PET成像受限于高剂量辐射暴露和低剂量下图像噪声过大的问题，现有去噪方法无法有效处理泊松噪声，导致图像失真和伪影。

Method: 提出了一种泊松一致性U-Net（PC-UNet）模型，并设计了一种新的泊松方差-均值一致性损失（PVMC-Loss）。该损失函数整合了物理信息，具有统计无偏的方差和梯度自适应能力，并且是广义矩方法（Generalized Method of Moments）的一种实现，对数据不匹配具有鲁棒性。

Result: 在PET数据集上的测试表明，PC-UNet在物理一致性和图像保真度方面均有所提升。

Conclusion: PVMC-Loss通过整合物理信息，能够有效提高PET图像的质量，证明了其在去噪和图像重建领域的潜力。

Abstract: Positron Emission Tomography (PET) is crucial in medicine, but its clinical
use is limited due to high signal-to-noise ratio doses increasing radiation
exposure. Lowering doses increases Poisson noise, which current denoising
methods fail to handle, causing distortions and artifacts. We propose a Poisson
Consistent U-Net (PC-UNet) model with a new Poisson Variance and Mean
Consistency Loss (PVMC-Loss) that incorporates physical data to improve image
fidelity. PVMC-Loss is statistically unbiased in variance and gradient
adaptation, acting as a Generalized Method of Moments implementation, offering
robustness to minor data mismatches. Tests on PET datasets show PC-UNet
improves physical consistency and image fidelity, proving its ability to
integrate physical information effectively.

</details>


### [3] [DeLeaker: Dynamic Inference-Time Reweighting For Semantic Leakage Mitigation in Text-to-Image Models](https://arxiv.org/abs/2510.15015)
*Mor Ventura,Michael Toker,Or Patashnik,Yonatan Belinkov,Roi Reichart*

Main category: cs.CV

TL;DR: DeLeaker 是一种无需优化、即时干预模型注意力图的轻量级方法，通过重新加权注意力图来减少文本到图像生成中的语义泄漏，并提高了图像的身份保持能力。同时，研究者还发布了首个专门用于语义泄漏评估的数据集 SLIM。实验表明 DeLeaker 效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像生成模型容易出现语义泄漏问题，即不同实体之间会意外地传递语义相关特征。现有的解决方法大多基于优化或依赖外部输入，不够高效。因此，需要一种更轻量级、无需优化的方法来解决此问题。

Method: DeLeaker 在扩散过程的推理阶段，通过动态地重新加权模型的注意力图，来抑制不同实体之间过度的交叉交互，同时增强每个实体的身份特征，从而达到减少语义泄漏的目的。此外，研究者还构建了首个专门用于语义泄漏评估的数据集 SLIM，包含 1,130 个经过人工验证的样本，并提出了新的自动评估框架。

Result: 实验结果表明，DeLeaker 在减少语义泄漏方面始终优于所有基线方法，即使在基线方法使用了外部信息的情况下也是如此。该方法在有效减少泄漏的同时，并没有损害图像的保真度或质量。

Conclusion: 研究结果强调了注意力控制在文本到图像生成中的重要性，并为开发更具语义精确性的模型指明了方向。DeLeaker 的成功表明，通过直接干预注意力图可以有效地解决语义泄漏问题。

Abstract: Text-to-Image (T2I) models have advanced rapidly, yet they remain vulnerable
to semantic leakage, the unintended transfer of semantically related features
between distinct entities. Existing mitigation strategies are often
optimization-based or dependent on external inputs. We introduce DeLeaker, a
lightweight, optimization-free inference-time approach that mitigates leakage
by directly intervening on the model's attention maps. Throughout the diffusion
process, DeLeaker dynamically reweights attention maps to suppress excessive
cross-entity interactions while strengthening the identity of each entity. To
support systematic evaluation, we introduce SLIM (Semantic Leakage in IMages),
the first dataset dedicated to semantic leakage, comprising 1,130
human-verified samples spanning diverse scenarios, together with a novel
automatic evaluation framework. Experiments demonstrate that DeLeaker
consistently outperforms all baselines, even when they are provided with
external information, achieving effective leakage mitigation without
compromising fidelity or quality. These results underscore the value of
attention control and pave the way for more semantically precise T2I models.

</details>


### [4] [UrbanVerse: Scaling Urban Simulation by Watching City-Tour Videos](https://arxiv.org/abs/2510.15018)
*Mingxuan Liu,Honglin He,Elisa Ricci,Wayne Wu,Bolei Zhou*

Main category: cs.CV

TL;DR: UrbanVerse是一个新的真实到模拟系统，它使用众包的城市旅游视频来生成物理感知的、可交互的城市模拟场景，用于训练城市AI代理。


<details>
  <summary>Details</summary>
Motivation: 现有的城市模拟环境在可扩展性或真实复杂性方面存在不足，难以满足日益增长的城市AI代理的训练需求。

Method: UrbanVerse包括UrbanVerse-100K（一个包含100k+带注释的城市3D资产的存储库）和UrbanVerse-Gen（一个从视频中提取场景布局并使用检索到的资产实例化度量尺度3D模拟的自动管道）。

Result: UrbanVerse生成的场景保留了真实的语义和布局，在真实感方面与手动创建的场景相当。在城市导航实验中，在UrbanVerse中训练的策略表现出强大的泛化能力，与先前的方法相比，在模拟中成功率提高了+6.3%，在零样本真实传递中提高了+30.1%。

Conclusion: UrbanVerse提供了一个可扩展的、逼真的城市模拟环境，能够有效地训练城市AI代理，并在真实世界任务中取得显著的性能提升。

Abstract: Urban embodied AI agents, ranging from delivery robots to quadrupeds, are
increasingly populating our cities, navigating chaotic streets to provide
last-mile connectivity. Training such agents requires diverse, high-fidelity
urban environments to scale, yet existing human-crafted or procedurally
generated simulation scenes either lack scalability or fail to capture
real-world complexity. We introduce UrbanVerse, a data-driven real-to-sim
system that converts crowd-sourced city-tour videos into physics-aware,
interactive simulation scenes. UrbanVerse consists of: (i) UrbanVerse-100K, a
repository of 100k+ annotated urban 3D assets with semantic and physical
attributes, and (ii) UrbanVerse-Gen, an automatic pipeline that extracts scene
layouts from video and instantiates metric-scale 3D simulations using retrieved
assets. Running in IsaacSim, UrbanVerse offers 160 high-quality constructed
scenes from 24 countries, along with a curated benchmark of 10 artist-designed
test scenes. Experiments show that UrbanVerse scenes preserve real-world
semantics and layouts, achieving human-evaluated realism comparable to manually
crafted scenes. In urban navigation, policies trained in UrbanVerse exhibit
scaling power laws and strong generalization, improving success by +6.3% in
simulation and +30.1% in zero-shot sim-to-real transfer comparing to prior
methods, accomplishing a 300 m real-world mission with only two interventions.

</details>


### [5] [BiomedXPro: Prompt Optimization for Explainable Diagnosis with Biomedical Vision Language Models](https://arxiv.org/abs/2510.15866)
*Kaushitha Silva,Mansitha Eashwara,Sanduni Ubayasiri,Ruwan Tennakoon,Damayanthi Herath*

Main category: cs.CV

TL;DR: BiomedXPro是一个用于医学图像诊断的进化框架，通过生成可解释的自然语言提示对来克服现有方法的局限性，并在少样本设置下表现优于最先进的方法。


<details>
  <summary>Details</summary>
Motivation: 现有医学影像模型采用的提示优化技术要么生成不可解释的隐变量，要么只生成单一的文本提示，这阻碍了它们在临床上的应用，因为临床诊断需要整合多种信息，而这种不透明性降低了模型在关键场景下的可信度。

Method: BiomedXPro利用大型语言模型作为生物医学知识提取器和自适应优化器，自动生成多样化的、可解释的自然语言提示对，用于疾病诊断。

Result: 在多个生物医学基准测试中，BiomedXPro的性能持续优于最先进的提示调整方法，尤其是在数据稀疏的少样本设置下。此外，发现的提示与具有统计学意义的临床特征之间存在很强的语义一致性。

Conclusion: BiomedXPro通过生成多样化的、可解释的提示对，为模型预测提供了可验证的基础，是开发更可信、更符合临床需求的AI系统的重要一步。

Abstract: The clinical adoption of biomedical vision-language models is hindered by
prompt optimization techniques that produce either uninterpretable latent
vectors or single textual prompts. This lack of transparency and failure to
capture the multi-faceted nature of clinical diagnosis, which relies on
integrating diverse observations, limits their trustworthiness in high-stakes
settings. To address this, we introduce BiomedXPro, an evolutionary framework
that leverages a large language model as both a biomedical knowledge extractor
and an adaptive optimizer to automatically generate a diverse ensemble of
interpretable, natural-language prompt pairs for disease diagnosis. Experiments
on multiple biomedical benchmarks show that BiomedXPro consistently outperforms
state-of-the-art prompt-tuning methods, particularly in data-scarce few-shot
settings. Furthermore, our analysis demonstrates a strong semantic alignment
between the discovered prompts and statistically significant clinical features,
grounding the model's performance in verifiable concepts. By producing a
diverse ensemble of interpretable prompts, BiomedXPro provides a verifiable
basis for model predictions, representing a critical step toward the
development of more trustworthy and clinically-aligned AI systems.

</details>


### [6] [NANO3D: A Training-Free Approach for Efficient 3D Editing Without Masks](https://arxiv.org/abs/2510.15019)
*Junliang Ye,Shenghao Xie,Ruowen Zhao,Zhengyi Wang,Hongyu Yan,Wenqiang Zu,Lei Ma,Jun Zhu*

Main category: cs.CV

TL;DR: Nano3D是一个无需训练的3D物体编辑框架，通过集成FlowEdit和TRELLIS，并采用Voxel/Slat-Merge策略，实现了精确、连贯且能保持未编辑区域完整性的3D物体编辑，解决了现有方法的不足，并在第一个大规模3D编辑数据集Nano3D-Edit-100k上进行了验证。


<details>
  <summary>Details</summary>
Motivation: 现有3D物体编辑方法效率低下、不一致且难以保持未编辑区域的完整性，主要依赖于多视图渲染和重建，易引入瑕疵。Nano3D旨在解决这些挑战。

Method: Nano3D框架集成了FlowEdit和TRELLIS，利用前视图渲染进行局部编辑，并引入了Voxel/Slat-Merge策略，通过自适应地保持编辑区域和未编辑区域之间的一致性来保证结构保真度。

Result: 实验表明，Nano3D在3D一致性和视觉质量方面优于现有方法。此外，还构建了包含超过10万个3D编辑对的Nano3D-Edit-100k数据集。

Conclusion: Nano3D框架在算法设计和数据可用性方面均取得了突破，显著提高了3D编辑的通用性和可靠性，为前馈3D编辑模型的发展奠定了基础。

Abstract: 3D object editing is essential for interactive content creation in gaming,
animation, and robotics, yet current approaches remain inefficient,
inconsistent, and often fail to preserve unedited regions. Most methods rely on
editing multi-view renderings followed by reconstruction, which introduces
artifacts and limits practicality. To address these challenges, we propose
Nano3D, a training-free framework for precise and coherent 3D object editing
without masks. Nano3D integrates FlowEdit into TRELLIS to perform localized
edits guided by front-view renderings, and further introduces region-aware
merging strategies, Voxel/Slat-Merge, which adaptively preserve structural
fidelity by ensuring consistency between edited and unedited areas. Experiments
demonstrate that Nano3D achieves superior 3D consistency and visual quality
compared with existing methods. Based on this framework, we construct the first
large-scale 3D editing datasets Nano3D-Edit-100k, which contains over 100,000
high-quality 3D editing pairs. This work addresses long-standing challenges in
both algorithm design and data availability, significantly improving the
generality and reliability of 3D editing, and laying the groundwork for the
development of feed-forward 3D editing models. Project
Page:https://jamesyjl.github.io/Nano3D

</details>


### [7] [Constantly Improving Image Models Need Constantly Improving Benchmarks](https://arxiv.org/abs/2510.15021)
*Jiaxin Ge,Grace Luo,Heekyung Lee,Nishant Malpani,Long Lian,XuDong Wang,Aleksander Holynski,Trevor Darrell,Sewon Min,David M. Chan*

Main category: cs.CV

TL;DR: ECHO是一个从社交媒体帖子中提取的图像生成基准框架，能够发现新颖的提示和用户反馈，从而更准确地评估模型能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试无法跟上GPT-4o等专有图像生成系统的发展，导致对模型能力的评估滞后。

Method: ECHO框架从社交媒体帖子中收集真实世界的使用证据（新颖提示和用户评价），构建图像生成基准测试数据集。

Result: 通过ECHO框架构建的数据集包含超过31,000个提示，发现了现有基准测试中缺失的创意和复杂任务（如多语言产品标签重新渲染、指定金额的收据生成），能更好地区分先进模型，并收集了用于模型质量度量（如颜色、身份、结构变化）的用户反馈。

Conclusion: ECHO框架能够有效地从真实世界的使用证据中构建图像生成基准测试，弥合了社区认知与正式评估之间的差距，并为模型评估和改进提供了新的途径。

Abstract: Recent advances in image generation, often driven by proprietary systems like
GPT-4o Image Gen, regularly introduce new capabilities that reshape how users
interact with these models. Existing benchmarks often lag behind and fail to
capture these emerging use cases, leaving a gap between community perceptions
of progress and formal evaluation. To address this, we present ECHO, a
framework for constructing benchmarks directly from real-world evidence of
model use: social media posts that showcase novel prompts and qualitative user
judgments. Applying this framework to GPT-4o Image Gen, we construct a dataset
of over 31,000 prompts curated from such posts. Our analysis shows that ECHO
(1) discovers creative and complex tasks absent from existing benchmarks, such
as re-rendering product labels across languages or generating receipts with
specified totals, (2) more clearly distinguishes state-of-the-art models from
alternatives, and (3) surfaces community feedback that we use to inform the
design of metrics for model quality (e.g., measuring observed shifts in color,
identity, and structure). Our website is at https://echo-bench.github.io.

</details>


### [8] [LoRAverse: A Submodular Framework to Retrieve Diverse Adapters for Diffusion Models](https://arxiv.org/abs/2510.15022)
*Mert Sonmezer,Matthew Zheng,Pinar Yanardag*

Main category: cs.CV

TL;DR: LoRA模型虽能实现预训练扩散模型的个性化，但其庞大的数量和缺乏结构化给用户选择和使用带来挑战。本文提出了一种组合优化框架，通过子模化方法解决LoRA模型选择问题，旨在生成多样化且相关的模型。


<details>
  <summary>Details</summary>
Motivation: 解决用户在海量、多样化且缺乏结构化组织的LoRA模型库中选择最合适模型时遇到的困难。

Method: 将LoRA模型选择问题构建为组合优化问题，并提出一种新颖的子模化框架来解决该问题。

Result: 通过定量和定性实验证明，所提出的方法能在广泛的领域内生成多样化的输出。

Conclusion: 所提出的子模化框架能够有效解决LoRA模型选择的挑战，并生成多样化的结果。

Abstract: Low-rank Adaptation (LoRA) models have revolutionized the personalization of
pre-trained diffusion models by enabling fine-tuning through low-rank,
factorized weight matrices specifically optimized for attention layers. These
models facilitate the generation of highly customized content across a variety
of objects, individuals, and artistic styles without the need for extensive
retraining. Despite the availability of over 100K LoRA adapters on platforms
like Civit.ai, users often face challenges in navigating, selecting, and
effectively utilizing the most suitable adapters due to their sheer volume,
diversity, and lack of structured organization. This paper addresses the
problem of selecting the most relevant and diverse LoRA models from this vast
database by framing the task as a combinatorial optimization problem and
proposing a novel submodular framework. Our quantitative and qualitative
experiments demonstrate that our method generates diverse outputs across a wide
range of domains.

</details>


### [9] [MOBIUS: Big-to-Mobile Universal Instance Segmentation via Multi-modal Bottleneck Fusion and Calibrated Decoder Pruning](https://arxiv.org/abs/2510.15026)
*Mattia Segu,Marta Tintore Gazulla,Yongqin Xian,Luc Van Gool,Federico Tombari*

Main category: cs.CV

TL;DR: MOBIUS 是一种旨在实现帕累托最优降维的通用实例分割基础模型，可在各种设备上部署，它通过采用瓶颈像素解码器、语言引导不确定性校准损失和统一的训练策略来减少训练和推理需求，同时保持最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基础模型因计算成本高而难以在资源受限的平台上部署，本研究旨在解决这一限制。

Method: 提出了一种名为 MOBIUS 的模型家族，包含三个关键组成部分：(1) 用于有效多尺度和多模态融合的瓶颈像素解码器；(2) 用于自适应解码器剪枝的语言引导不确定性校准损失；(3) 简化的统一训练策略。

Result: MOBIUS 将像素和 Transformer 解码器的 FLOPs 减少了高达 55% 和 75%，同时在仅三分之一的训练迭代次数下保持了最先进的性能。

Conclusion: MOBIUS 在高性能计算平台和移动设备上均确立了高效分割的新基准。

Abstract: Scaling up model size and training data has advanced foundation models for
instance-level perception, achieving state-of-the-art in-domain and zero-shot
performance across object detection and segmentation. However, their high
computational cost limits adoption on resource-constrained platforms. We first
examine the limitations of existing architectures in enabling efficient edge
deployment without compromising performance. We then introduce MOBIUS, a family
of foundation models for universal instance segmentation, designed for
Pareto-optimal downscaling to support deployment across devices ranging from
high-end accelerators to mobile hardware. To reduce training and inference
demands, we propose: (i) a bottleneck pixel decoder for efficient multi-scale
and multi-modal fusion, (ii) a language-guided uncertainty calibration loss for
adaptive decoder pruning, and (iii) a streamlined, unified training strategy.
Unlike efficient baselines that trade accuracy for reduced complexity, MOBIUS
reduces pixel and transformer decoder FLOPs by up to 55% and 75%, respectively,
while maintaining state-of-the-art performance in just a third of the training
iterations. MOBIUS establishes a new benchmark for efficient segmentation on
both high-performance computing platforms and mobile devices.

</details>


### [10] [Composition-Grounded Instruction Synthesis for Visual Reasoning](https://arxiv.org/abs/2510.15040)
*Xinyi Gu,Jiayuan Mao,Zhang-Wei Hong,Zhuoran Yu,Pengyuan Li,Dhiraj Joshi,Rogerio Feris,Zexue He*

Main category: cs.CV

TL;DR: 由于在难以收集标注数据的领域（例如图表、渲染文档和网页）中，预训练的多模态大语言模型（MLLMs）的推理能力有限，本研究提出了 COGS（COmposition-Grounded instruction Synthesis）框架。该框架能够利用少量种子问题，通过将问题分解为基本感知和推理因素，并用新图像系统地重新组合这些因素来生成大规模的合成问答对，从而有效地为 MLLMs 装备高级推理能力。生成的问答对包含子问题和中间答案，支持因子级过程奖励的强化学习。


<details>
  <summary>Details</summary>
Motivation: 预训练的多模态大语言模型（MLLMs）在处理缺乏大规模人类标注推理数据集的人工图像领域（如图表、渲染文档和网页）时，推理能力受到限制。

Method: 提出 COGS（COmposition-Grounded instruction Synthesis）框架，该框架通过将种子问题分解为基本感知和推理因素，并用新图像系统地重新组合这些因素来生成合成问答对，以训练 MLLMs。生成的问答对包含子问题和中间答案，支持因子级过程奖励的强化学习。

Result: 在图表推理实验中，COGS 显著提高了模型在未见过的问题上的性能，尤其是在推理密集型和组合型问题上。在多个数据集上进行训练可以获得更好的迁移性，表明 COGS 能够带来可泛化的能力。该框架也被证明可以扩展到网页等其他领域。

Conclusion: COGS 框架能够有效地为 MLLMs 装备高级推理能力，尤其是在缺乏大规模标注数据的领域，并且能够带来可泛化的能力。

Abstract: Pretrained multi-modal large language models (MLLMs) demonstrate strong
performance on diverse multimodal tasks, but remain limited in reasoning
capabilities for domains where annotations are difficult to collect. In this
work, we focus on artificial image domains such as charts, rendered documents,
and webpages, which are abundant in practice yet lack large-scale human
annotated reasoning datasets. We introduce COGS (COmposition-Grounded
instruction Synthesis), a data-efficient framework for equipping MLLMs with
advanced reasoning abilities from a small set of seed questions. The key idea
is to decompose each seed question into primitive perception and reasoning
factors, which can then be systematically recomposed with new images to
generate large collections of synthetic question-answer pairs. Each generated
question is paired with subquestions and intermediate answers, enabling
reinforcement learning with factor-level process rewards. Experiments on chart
reasoning show that COGS substantially improves performance on unseen
questions, with the largest gains on reasoning-heavy and compositional
questions. Moreover, training with a factor-level mixture of different seed
data yields better transfer across multiple datasets, suggesting that COGS
induces generalizable capabilities rather than dataset-specific overfitting. We
further demonstrate that the framework extends beyond charts to other domains
such as webpages.

</details>


### [11] [Generalized Dynamics Generation towards Scannable Physical World Model](https://arxiv.org/abs/2510.15041)
*Yichen Li,Zhiyi Li,Brandon Feng,Dinghuai Zhang,Antonio Torralba*

Main category: cs.CV

TL;DR: GDGen是一个统一的框架，能够处理刚体、关节体和软体动力学，用于在数字孪生世界中开发通用具身智能体。


<details>
  <summary>Details</summary>
Motivation: 为了在具有复杂物理行为的数字孪生世界中开发通用具身智能体，需要一个能够统一处理不同物理动力学的系统。

Method: GDGen从势能角度出发，通过引入方向性刚度来扩展经典弹性动力学，并采用专门的网络和神经场来表示材料属性和变形，从而实现刚体、关节体和软体动力学的统一。该系统能够从简单的运动观察中推断出物理属性。

Result: GDGen能够稳健地统一各种模拟范例，为创建交互式虚拟环境和在复杂、动态丰富的场景中训练机器人代理提供了基础。

Conclusion: GDGen框架成功地统一了刚体、关节体和软体动力学，为数字孪生世界中的具身智能体开发提供了通用的解决方案。

Abstract: Digital twin worlds with realistic interactive dynamics presents a new
opportunity to develop generalist embodied agents in scannable environments
with complex physical behaviors. To this end, we present GDGen (Generalized
Representation for Generalized Dynamics Generation), a framework that takes a
potential energy perspective to seamlessly integrate rigid body, articulated
body, and soft body dynamics into a unified, geometry-agnostic system. GDGen
operates from the governing principle that the potential energy for any stable
physical system should be low. This fresh perspective allows us to treat the
world as one holistic entity and infer underlying physical properties from
simple motion observations. We extend classic elastodynamics by introducing
directional stiffness to capture a broad spectrum of physical behaviors,
covering soft elastic, articulated, and rigid body systems. We propose a
specialized network to model the extended material property and employ a neural
field to represent deformation in a geometry-agnostic manner. Extensive
experiments demonstrate that GDGen robustly unifies diverse simulation
paradigms, offering a versatile foundation for creating interactive virtual
environments and training robotic agents in complex, dynamically rich
scenarios.

</details>


### [12] [Comprehensive language-image pre-training for 3D medical image understanding](https://arxiv.org/abs/2510.15042)
*Tassilo Wald,Ibrahim Ethem Hamamci,Yuan Gao,Sam Bond-Taylor,Harshita Sharma,Maximilian Ilse,Cynthia Lo,Olesya Melnichenko,Noel C. F. Codella,Maria Teodora Wetscherek,Klaus H. Maier-Hein,Panagiotis Korfiatis,Valentina Salvatelli,Javier Alvarez-Valle,Fernando Pérez-García*

Main category: cs.CV

TL;DR: 通过引入报告生成目标和结合仅视觉预训练，COLIPRI 编码器在 3D 医学图像领域取得了最先进的性能，克服了数据稀缺的限制。


<details>
  <summary>Details</summary>
Motivation: 现有 3D 视觉语言编码器 (VLE) 的能力受到数据可用性限制，无法充分支持放射科医生。

Method: 通过注入额外的归纳偏差，包括引入报告生成目标和将视觉语言预训练与仅视觉预训练相结合，以利用图像和图像-文本数据集，并结合 3D 医学影像领域的最佳实践，开发了 COLIPRI 编码器。

Result: COLIPRI 编码器在报告生成、分类探测和零样本分类方面取得了最先进的性能，并在语义分割方面保持竞争力。

Conclusion: COLIPRI 编码器通过克服数据稀缺问题，在 3D 医学影像分析任务中展现了优越的性能。

Abstract: Vision-language pre-training, i.e., aligning images with paired text, is a
powerful paradigm to create encoders that can be directly used for tasks such
as classification and retrieval, and for downstream tasks such as segmentation
and report generation. In the 3D medical image domain, these capabilities allow
vision-language encoders (VLEs) to support radiologists by retrieving patients
with similar abnormalities or predicting likelihoods of abnormality. While the
methodology holds promise, data availability limits the capabilities of current
3D VLEs.
  In this paper, we alleviate the lack of data by injecting additional
inductive biases: introducing a report generation objective and pairing
vision-language pre-training with vision-only pre-training. This allows us to
leverage both image-only and paired image-text 3D datasets, increasing the
total amount of data to which our model is exposed. Through these additional
inductive biases, paired with best practices of the 3D medical imaging domain,
we develop the Comprehensive Language-image Pre-training (COLIPRI) encoder
family. Our COLIPRI encoders achieve state-of-the-art performance in report
generation, classification probing, and zero-shot classification, and remain
competitive for semantic segmentation.

</details>


### [13] [Directional Reasoning Injection for Fine-Tuning MLLMs](https://arxiv.org/abs/2510.15050)
*Chao Huang,Zeliang Zhang,Jiang Liu,Ximeng Sun,Jialian Wu,Xiaodong Yu,Ze Wang,Chenliang Xu,Emad Barsoum,Zicheng Liu*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Multimodal large language models (MLLMs) are rapidly advancing, yet their
reasoning ability often lags behind that of strong text-only counterparts.
Existing methods to bridge this gap rely on supervised fine-tuning over
large-scale multimodal reasoning data or reinforcement learning, both of which
are resource-intensive. A promising alternative is model merging, which
interpolates parameters between reasoning-enhanced LLMs and multimodal
variants. However, our analysis shows that naive merging is not always a "free
lunch": its effectiveness varies drastically across model families, with some
(e.g., LLaVA, Idefics) benefiting while others (e.g., Qwen) suffer performance
degradation. To address this, we propose Directional Reasoning Injection for
Fine-Tuning (DRIFT) MLLMs, a lightweight method that transfers reasoning
knowledge in the gradient space, without destabilizing multimodal alignment.
DRIFT precomputes a reasoning prior as the parameter-space difference between
reasoning and multimodal variants, then uses it to bias gradients during
multimodal fine-tuning. This approach preserves the simplicity of standard
supervised fine-tuning pipelines while enabling efficient reasoning transfer.
Extensive experiments on multimodal reasoning benchmarks, including MathVista
and MathVerse, demonstrate that DRIFT consistently improves reasoning
performance over naive merging and supervised fine-tuning, while matching or
surpassing training-heavy methods at a fraction of the cost.

</details>


### [14] [A solution to generalized learning from small training sets found in everyday infant experiences](https://arxiv.org/abs/2510.15060)
*Frangil Ramirez,Elizabeth Clerkin,David J. Crandall,Linda B. Smith*

Main category: cs.CV

TL;DR: 婴儿从有限的视觉经验中学习和泛化物体类别，这得益于他们日常经验中“块状相似性”的结构。


<details>
  <summary>Details</summary>
Motivation: 探讨幼儿如何从有限的经验中学习和泛化物体类别，以及这与大规模数据集学习的对比。

Method: 分析了14名婴儿（7-11个月大）的自发图像，研究了他们日常视觉输入的“块状相似性”结构，并进行了计算实验来验证模仿这种结构对机器学习泛化的影响。

Result: 婴儿的日常视觉输入呈现出“块状相似性”结构，即高度相似的图像聚集在一起，并穿插着稀疏、多变的图像。模仿这种结构可以提高机器从小型数据集中泛化学习的能力。

Conclusion: 婴儿经验的自然“块状性”可能支持早期物体类别的学习和泛化，并为各种学习者和问题的有效学习提供原则。

Abstract: Young children readily recognize and generalize visual objects labeled by
common nouns, suggesting that these basic level object categories may be given.
Yet if they are, how they arise remains unclear. We propose that the answer
lies in the statistics of infant daily life visual experiences. Whereas large
and diverse datasets typically support robust learning and generalization in
human and machine learning, infants achieve this generalization from limited
experiences. We suggest that the resolution of this apparent contradiction lies
in the visual diversity of daily life, repeated experiences with single object
instances. Analyzing egocentric images from 14 infants (aged 7 to 11 months) we
show that their everyday visual input exhibits a lumpy similarity structure,
with clusters of highly similar images interspersed with rarer, more variable
ones, across eight early-learned categories. Computational experiments show
that mimicking this structure in machines improves generalization from small
datasets in machine learning. The natural lumpiness of infant experience may
thus support early category learning and generalization and, more broadly,
offer principles for efficient learning across a variety of problems and kinds
of learners.

</details>


### [15] [SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images](https://arxiv.org/abs/2510.15072)
*Jiaxin Guo,Tongfan Guan,Wenzhen Dong,Wenzhao Zheng,Wenting Wang,Yue Wang,Yeung Yam,Yun-Hui Liu*

Main category: cs.CV

TL;DR: SaLon3R是一个新颖的框架，用于结构感知、长时3DGS重建，能够去除50%到90%的冗余，并实现超过50个视图的实时重建。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯泼溅（3DGS）方法在处理长视频序列时存在冗余和几何不一致性问题。

Method: SaLon3R引入了紧凑的锚点图元，通过可微分的显著性感知高斯量化来消除冗余。它还使用3D点Transformer来优化锚点属性和显著性，以解决跨帧的几何和光度不一致性。首先，利用3D重建骨干网络预测密集的逐像素高斯和区域几何复杂度图。然后，通过优先考虑高复杂度区域来将冗余高斯压缩成紧凑锚点。最后，3D点Transformer学习3D空间中的空间结构先验，以优化锚点属性和显著性，实现区域自适应高斯解码以获得几何保真度。

Result: SaLon3R在多个数据集上实现了最先进的性能，在视图合成和深度估计方面表现优异，并展示了在长时通用3D重建方面的卓越效率、鲁棒性和泛化能力。

Conclusion: SaLon3R通过结构感知和长时重建，有效解决了现有3DGS方法的冗余和几何不一致性问题，在效率、鲁棒性和泛化能力方面取得了显著的进步。

Abstract: Recent advances in 3D Gaussian Splatting (3DGS) have enabled generalizable,
on-the-fly reconstruction of sequential input views. However, existing methods
often predict per-pixel Gaussians and combine Gaussians from all views as the
scene representation, leading to substantial redundancies and geometric
inconsistencies in long-duration video sequences. To address this, we propose
SaLon3R, a novel framework for Structure-aware, Long-term 3DGS Reconstruction.
To our best knowledge, SaLon3R is the first online generalizable GS method
capable of reconstructing over 50 views in over 10 FPS, with 50% to 90%
redundancy removal. Our method introduces compact anchor primitives to
eliminate redundancy through differentiable saliency-aware Gaussian
quantization, coupled with a 3D Point Transformer that refines anchor
attributes and saliency to resolve cross-frame geometric and photometric
inconsistencies. Specifically, we first leverage a 3D reconstruction backbone
to predict dense per-pixel Gaussians and a saliency map encoding regional
geometric complexity. Redundant Gaussians are compressed into compact anchors
by prioritizing high-complexity regions. The 3D Point Transformer then learns
spatial structural priors in 3D space from training data to refine anchor
attributes and saliency, enabling regionally adaptive Gaussian decoding for
geometric fidelity. Without known camera parameters or test-time optimization,
our approach effectively resolves artifacts and prunes the redundant 3DGS in a
single feed-forward pass. Experiments on multiple datasets demonstrate our
state-of-the-art performance on both novel view synthesis and depth estimation,
demonstrating superior efficiency, robustness, and generalization ability for
long-term generalizable 3D reconstruction. Project Page:
https://wrld.github.io/SaLon3R/.

</details>


### [16] [TGT: Text-Grounded Trajectories for Locally Controlled Video Generation](https://arxiv.org/abs/2510.15104)
*Guofeng Zhang,Angtian Wang,Jacob Zhiyuan Fang,Liming Jiang,Haotian Yang,Bo Liu,Yiding Yang,Guang Chen,Longyin Wen,Alan Yuille,Chongyang Ma*

Main category: cs.CV

TL;DR: TGT框架通过结合文本描述和轨迹来改进文本到视频生成，提高了对主体构图的控制精度和视觉质量。


<details>
  <summary>Details</summary>
Motivation: 现有文本到视频生成方法在控制主体构图方面能力有限，尤其是在复杂场景和多对象设置下，精度不足且轨迹与视觉实体的对应关系不明确。TGT旨在解决这些问题。

Method: TGT框架提出了一种名为LACA（Location-Aware Cross-Attention）的新机制，用于整合轨迹和局部文本描述信号，并采用双重CFG（Classifier-Free Guidance）方案分别调整局部和全局文本引导。此外，还开发了一个数据处理流程来生成带有局部描述的轨迹，并标注了大量视频片段用于训练。

Result: 实验表明，TGT在视觉质量、文本对齐准确性和运动可控性方面优于现有方法。

Conclusion: TGT框架通过将点轨迹作为直观的运动控制手柄，并将其与文本描述配对，实现了对视频生成中物体外观和运动的精确控制。

Abstract: Text-to-video generation has advanced rapidly in visual fidelity, whereas
standard methods still have limited ability to control the subject composition
of generated scenes. Prior work shows that adding localized text control
signals, such as bounding boxes or segmentation masks, can help. However, these
methods struggle in complex scenarios and degrade in multi-object settings,
offering limited precision and lacking a clear correspondence between
individual trajectories and visual entities as the number of controllable
objects increases. We introduce Text-Grounded Trajectories (TGT), a framework
that conditions video generation on trajectories paired with localized text
descriptions. We propose Location-Aware Cross-Attention (LACA) to integrate
these signals and adopt a dual-CFG scheme to separately modulate local and
global text guidance. In addition, we develop a data processing pipeline that
produces trajectories with localized descriptions of tracked entities, and we
annotate two million high quality video clips to train TGT. Together, these
components enable TGT to use point trajectories as intuitive motion handles,
pairing each trajectory with text to control both appearance and motion.
Extensive experiments show that TGT achieves higher visual quality, more
accurate text alignment, and improved motion controllability compared with
prior approaches. Website: https://textgroundedtraj.github.io.

</details>


### [17] [Deep generative priors for 3D brain analysis](https://arxiv.org/abs/2510.15119)
*Ana Lawry Aguila,Dina Zemlyanker,You Cheng,Sudeshna Das,Daniel C. Alexander,Oula Puonti,Annabel Sorby-Adams,W. Taylor Kimberly,Juan Eugenio Iglesias*

Main category: cs.CV

TL;DR: 本文提出将扩散模型作为先验来解决医学成像逆问题，特别是在脑部MRI分析中，结合了扩散模型的强大生成能力和贝叶斯逆问题的领域知识，实现了无需配对训练数据即可获得高质量的成像结果。


<details>
  <summary>Details</summary>
Motivation: 目前的脑成像领域，数据驱动的扩散模型难以结合领域知识，而传统的贝叶斯逆问题虽然能融入领域知识但其解剖建模先验不足以捕捉大脑的复杂结构。因此，需要一种能够结合扩散模型的强大生成能力和贝叶斯方法的领域知识，并能有效处理复杂解剖结构的方法。

Method: 本文提出将扩散模型作为先验，并使用在大量脑部MRI数据上训练的模型。该方法结合了灵活的正向模型，可以处理超分辨率、偏置场校正、图像修复等任务，并能与其他深度学习方法结合以提高输出的解剖保真度。

Result: 在多样的临床和研究MRI数据集上的实验表明，该方法在无需配对训练数据集的情况下，达到了最先进的性能，能够生成一致的高质量解决方案，并在提高现有深度学习方法输出的解剖保真度方面展现了潜力。

Conclusion: 扩散模型作为先验在解决脑部MRI逆问题方面具有巨大潜力，可以作为脑部MRI分析的通用工具，实现高质量、无需配对训练数据的成像。

Abstract: Diffusion models have recently emerged as powerful generative models in
medical imaging. However, it remains a major challenge to combine these
data-driven models with domain knowledge to guide brain imaging problems. In
neuroimaging, Bayesian inverse problems have long provided a successful
framework for inference tasks, where incorporating domain knowledge of the
imaging process enables robust performance without requiring extensive training
data. However, the anatomical modeling component of these approaches typically
relies on classical mathematical priors that often fail to capture the complex
structure of brain anatomy. In this work, we present the first general-purpose
application of diffusion models as priors for solving a wide range of medical
imaging inverse problems. Our approach leverages a score-based diffusion prior
trained extensively on diverse brain MRI data, paired with flexible forward
models that capture common image processing tasks such as super-resolution,
bias field correction, inpainting, and combinations thereof. We further
demonstrate how our framework can refine outputs from existing deep learning
methods to improve anatomical fidelity. Experiments on heterogeneous clinical
and research MRI data show that our method achieves state-of-the-art
performance producing consistent, high-quality solutions without requiring
paired training datasets. These results highlight the potential of diffusion
priors as versatile tools for brain MRI analysis.

</details>


### [18] [Fourier Transform Multiple Instance Learning for Whole Slide Image Classification](https://arxiv.org/abs/2510.15138)
*Anthony Bilic,Guangyu Sun,Ming Li,Md Sanzid Bin Hossain,Yu Tian,Wei Zhang,Laura Brattain,Dexter Hadley,Chen Chen*

Main category: cs.CV

TL;DR: FFT-MIL通过在MIL中引入傅里叶变换来捕捉WSIs的全局依赖性，提高了WSI分类的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的WSI分类方法在处理巨大的WSIs时，由于局部性限制，难以捕捉全局依赖关系，这阻碍了诊断预测的准确性。

Method: 提出FFT-MIL框架，通过傅里叶变换提取低频图像块，并利用FFT-Block（包含卷积层和Min-Max归一化）处理以获得全局上下文。然后将学习到的全局频率特征与空间块特征融合。

Result: 在三个公共数据集（BRACS、LUAD和IMP）上，将FFT-Block集成到六种先进的MIL方法中，平均宏观F1分数提高了3.51%，AUC提高了1.51%。

Conclusion: 频率域学习是一种有效且高效的捕捉WSI分类中全局依赖性的机制，可以与空间特征互补，提高MIL的准确性和可扩展性。

Abstract: Whole Slide Image (WSI) classification relies on Multiple Instance Learning
(MIL) with spatial patch features, yet existing methods struggle to capture
global dependencies due to the immense size of WSIs and the local nature of
patch embeddings. This limitation hinders the modeling of coarse structures
essential for robust diagnostic prediction.
  We propose Fourier Transform Multiple Instance Learning (FFT-MIL), a
framework that augments MIL with a frequency-domain branch to provide compact
global context. Low-frequency crops are extracted from WSIs via the Fast
Fourier Transform and processed through a modular FFT-Block composed of
convolutional layers and Min-Max normalization to mitigate the high variance of
frequency data. The learned global frequency feature is fused with spatial
patch features through lightweight integration strategies, enabling
compatibility with diverse MIL architectures.
  FFT-MIL was evaluated across six state-of-the-art MIL methods on three public
datasets (BRACS, LUAD, and IMP). Integration of the FFT-Block improved macro F1
scores by an average of 3.51% and AUC by 1.51%, demonstrating consistent gains
across architectures and datasets. These results establish frequency-domain
learning as an effective and efficient mechanism for capturing global
dependencies in WSI classification, complementing spatial features and
advancing the scalability and accuracy of MIL-based computational pathology.

</details>


### [19] [XModBench: Benchmarking Cross-Modal Capabilities and Consistency in Omni-Language Models](https://arxiv.org/abs/2510.15148)
*Xingrui Wang,Jiang Liu,Chao Huang,Xiaodong Yu,Ze Wang,Ximeng Sun,Jialian Wu,Alan Yuille,Emad Barsoum,Zicheng Liu*

Main category: cs.CV

TL;DR: XModBench是一个新的基准测试，用于评估全模态大语言模型（OLLM）在音频、视觉和文本理解中的跨模态一致性。实验表明，即使是像Gemini 2.5 Pro这样最强的模型，在空间和时间推理方面表现不佳，并且在不同模态之间存在性能差异，特别是在使用音频作为输入时。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要评估通用的跨模态问答能力，但未能明确OLLM是否实现了模态不变推理或表现出模态特定偏见。

Method: 引入XModBench，一个大规模三模态基准，包含60,28张多项选择题，涵盖五个任务家族，系统地覆盖所有六种模态组合，以精细诊断OLLM的模态不变推理、模态差异和方向不平衡。

Result: 即使是最强的模型Gemini 2.5 Pro，在空间和时间推理方面准确率低于60%；当相同语义内容通过音频而非文本传达时，性能会显著下降；与文本作为上下文相比，视觉作为上下文时一致性较低。

Conclusion: 当前的OLLM距离真正的模态不变推理还有很长的路要走，XModBench是评估和改进跨模态能力的基本诊断工具。

Abstract: Omni-modal large language models (OLLMs) aim to unify audio, vision, and text
understanding within a single framework. While existing benchmarks primarily
evaluate general cross-modal question-answering ability, it remains unclear
whether OLLMs achieve modality-invariant reasoning or exhibit modality-specific
biases. We introduce XModBench, a large-scale tri-modal benchmark explicitly
designed to measure cross-modal consistency. XModBench comprises 60,828
multiple-choice questions spanning five task families and systematically covers
all six modality compositions in question-answer pairs, enabling fine-grained
diagnosis of an OLLM's modality-invariant reasoning, modality disparity, and
directional imbalance. Experiments show that even the strongest model, Gemini
2.5 Pro, (i) struggles with spatial and temporal reasoning, achieving less than
60% accuracy, (ii) reveals persistent modality disparities, with performance
dropping substantially when the same semantic content is conveyed through audio
rather than text, and (iii) shows systematic directional imbalance, exhibiting
lower consistency when vision serves as context compared to text. These
findings indicate that current OLLMs remain far from truly modality-invariant
reasoning and position XModBench as a fundamental diagnostic tool for
evaluating and improving cross-modal competence. All data and evaluation tools
will be available at https://xingruiwang.github.io/projects/XModBench/.

</details>


### [20] [Train a Unified Multimodal Data Quality Classifier with Synthetic Data](https://arxiv.org/abs/2510.15162)
*Weizhi Wang,Rongmei Lin,Shiyang Li,Colin Lockard,Ritesh Sarkhel,Sanket Lokegaonkar,Jingbo Shang,Xifeng Yan,Nasser Zalmout,Xian Li*

Main category: cs.CV

TL;DR: 提出UniFilter，一个用于筛选高质量图文混合文档数据的模型，通过半合成数据进行训练，并在OBELICS和DataComp数据集上进行了验证，提升了MLLMs的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的MLLMs在预训练时，对图文混合文档数据的高质量筛选方法探索不足。

Method: 提出UniFilter，一个高效的MLLM，被训练成一个统一的多模态数据质量分类器，用于筛选高质量的图文标题和图文混合文档数据。利用半合成方法生成带有质量标签的多模态数据来训练UniFilter。

Result: 使用UniFilter筛选的数据预训练的MLLMs在零样本推理和上下文学习能力上显著优于使用基线筛选数据训练的模型。经过视觉监督微调后，在各种基准测试中表现更强。

Conclusion: 高质量的多模态预训练对下游任务有益。发布了训练UniFilter的合成数据、UniFilter模型检查点以及UniFilter筛选出的高质量图文混合文档子集OBELICS-HQ。

Abstract: The Multimodal Large Language Models (MLLMs) are continually pre-trained on a
mixture of image-text caption data and interleaved document data, while the
high-quality data filtering towards image-text interleaved document data is
under-explored. We propose to train an efficient MLLM as a Unified Mulitmodal
Data Quality Classifier to Filter both high-quality image-text caption and
interleaved data (UniFilter). To address the challenge of collecting diverse
labeled multimodal data, we introduce a semi-synthetic approach that leverages
readily available raw images and generates corresponding text across four
quality levels. This method enables efficient creation of sample-score pairs
for both caption and interleaved document data to train UniFilter. We apply
UniFilter to curate high-quality caption data from DataComp caption dataset and
interleaved data from the OBELICS image-text interleaved dataset. MLLMs
pre-trained on the filtered data demonstrate significantly enhanced
capabilities compared to those trained on baseline-filtered data, achieving
stronger zero-shot reasoning and in-context learning capabilities. After visual
supervised fine-tuning, these UniFilter-induced MLLMs achieve stronger
performance on various benchmarks, highlighting the downstream benefits of
high-quality multimodal pre-training. We release the synthetic training data
used for training UniFilter, the UniFilter model checkpoints, and the
high-quality interleaved document subset OBELICS-HQ, curated by UniFilter, to
the community for reproduction and further development.

</details>


### [21] [Hyperparameter Optimization and Reproducibility in Deep Learning Model Training](https://arxiv.org/abs/2510.15164)
*Usman Afzaal,Ziyu Su,Usama Sajjad,Hao Lu,Mostafa Rezapour,Metin Nafi Gurcan,Muhammad Khalid Khan Niazi*

Main category: cs.CV

TL;DR: 在病理学基础模型训练中，通过系统评估不同的超参数和数据增强策略，我们发现在 QUILT-1M 数据集上训练的 CLIP 模型中，RandomResizedCrop 值为 0.7-0.8 效果最佳，分布式训练（无局部损失）提高了稳定性，低于 5.0e-5 的学习率会降低性能。LC25000 (Colon) 数据集提供了最可复现的基准。这些发现强调了计算病理学中的可复现性不仅需要透明的文档，还需要仔细选择的实验配置，并为未来在数字病理学中开发可复现的基础模型提供了实用的指导。


<details>
  <summary>Details</summary>
Motivation: 病理学基础模型训练中的可复现性是一个关键挑战，这通常受到软件随机性、硬件非确定性和不一致的超参数报告的阻碍。

Method: 在 QUILT-1M 数据集上训练了一个 CLIP 模型，并系统地评估了不同超参数设置和数据增强策略在三个下游病理学数据集（PatchCamelyon、LC25000-Lung 和 LC25000-Colon）上的影响。

Result: 尽管运行结果存在差异，但我们发现了明确的趋势：RandomResizedCrop 值为 0.7-0.8 优于更严格（0.6）或更保守（0.9）的设置；分布式训练（无局部损失）提高了稳定性；低于 5.0e-5 的学习率在所有数据集中均导致性能下降。LC25000 (Colon) 数据集提供了最可复现的基准。

Conclusion: 计算病理学中的可复现性不仅取决于透明的文档，还取决于仔细选择的实验配置。我们提供了实用的规则来指导未来在数字病理学中开发可复现的基础模型的努力。

Abstract: Reproducibility remains a critical challenge in foundation model training for
histopathology, often hindered by software randomness, hardware
non-determinism, and inconsistent hyperparameter reporting. To investigate
these issues, we trained a CLIP model on the QUILT-1M dataset and
systematically evaluated the impact of different hyperparameter settings and
augmentation strategies across three downstream histopathology datasets
(PatchCamelyon, LC25000-Lung, and LC25000-Colon). Despite variability across
runs, we identified clear trends: RandomResizedCrop values of 0.7-0.8
outperformed more aggressive (0.6) or conservative (0.9) settings, distributed
training without local loss improved stability, and learning rates below 5.0e-5
consistently degraded performance across all datasets. The LC25000 (Colon)
dataset consistently provided the most reproducible benchmark. These findings
highlight that reproducibility in computational pathology depends not only on
transparent documentation but also on carefully chosen experimental
configurations, and we provide practical rules to guide future efforts in
developing reproducible foundation models for digital pathology.

</details>


### [22] [Salient Concept-Aware Generative Data Augmentation](https://arxiv.org/abs/2510.15194)
*Tianchen Zhao,Xuanbai Chen,Zhihua Li,Jun Fang,Dongsheng An,Xiang Xu,Zhuowen Tu,Yifan Xing*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Recent generative data augmentation methods conditioned on both image and
text prompts struggle to balance between fidelity and diversity, as it is
challenging to preserve essential image details while aligning with varied text
prompts. This challenge arises because representations in the synthesis process
often become entangled with non-essential input image attributes such as
environmental contexts, creating conflicts with text prompts intended to modify
these elements. To address this, we propose a personalized image generation
framework that uses a salient concept-aware image embedding model to reduce the
influence of irrelevant visual details during the synthesis process, thereby
maintaining intuitive alignment between image and text inputs. By generating
images that better preserve class-discriminative features with additional
controlled variations, our framework effectively enhances the diversity of
training datasets and thereby improves the robustness of downstream models. Our
approach demonstrates superior performance across eight fine-grained vision
datasets, outperforming state-of-the-art augmentation methods with averaged
classification accuracy improvements by 0.73% and 6.5% under conventional and
long-tail settings, respectively.

</details>


### [23] [CARDIUM: Congenital Anomaly Recognition with Diagnostic Images and Unified Medical records](https://arxiv.org/abs/2510.15208)
*Daniela Vega,Hannah V. Ceballos,Javier S. Vera,Santiago Rodriguez,Alejandra Perez,Angela Castillo,Maria Escobar,Dario Londoño,Luis A. Sarmiento,Camila I. Castro,Nadiezhda Rodriguez,Juan C. Briceño,Pablo Arbeláez*

Main category: cs.CV

TL;DR: 该研究介绍了CARDIUM数据集和一种新的多模态Transformer架构，用于产前先天性心脏病（CHD）的检测。CARDIUM是首个整合了胎儿超声心动图影像和孕期临床记录的公开数据集，旨在解决现有数据集稀疏、质量低和信息单一的问题。所提出的多模态Transformer模型通过跨注意机制融合图像和表格数据，显著提高了CHD检测的准确性，优于单一模态方法，并在CARDIUM数据集上取得了79.8%的F1分数。


<details>
  <summary>Details</summary>
Motivation: 由于先天性心脏病（CHD）的罕见性，导致用于产前诊断的数据集存在不平衡和质量不高的问题，这阻碍了人工智能（AI）模型在这一领域的应用。此外，现有研究缺乏整合影像和临床数据等多源信息的方法，限制了AI模型在临床决策支持方面的潜力。

Method: 研究人员创建了CARDIUM数据集，这是一个包含胎儿超声心动图影像和孕期临床记录的多模态数据集，用于产前CHD检测。他们还提出了一种新的多模态Transformer架构，该架构利用跨注意机制融合来自图像和表格数据的特征表示。

Result: 所提出的多模态Transformer模型在CHD检测方面，相比仅使用图像或仅使用表格数据的模型，分别提高了11%和50%。在CARDIUM数据集上，该模型的F1分数达到了79.8 ± 4.8%。

Conclusion: CARDIUM数据集和新提出的多模态Transformer模型有效地解决了产前CHD检测中数据稀疏、质量低和信息整合不足的挑战，显著提高了模型的检测性能，为该领域的研究开辟了新方向。研究团队将公开数据集和代码以促进进一步的研究。

Abstract: Prenatal diagnosis of Congenital Heart Diseases (CHDs) holds great potential
for Artificial Intelligence (AI)-driven solutions. However, collecting
high-quality diagnostic data remains difficult due to the rarity of these
conditions, resulting in imbalanced and low-quality datasets that hinder model
performance. Moreover, no public efforts have been made to integrate multiple
sources of information, such as imaging and clinical data, further limiting the
ability of AI models to support and enhance clinical decision-making. To
overcome these challenges, we introduce the Congenital Anomaly Recognition with
Diagnostic Images and Unified Medical records (CARDIUM) dataset, the first
publicly available multimodal dataset consolidating fetal ultrasound and
echocardiographic images along with maternal clinical records for prenatal CHD
detection. Furthermore, we propose a robust multimodal transformer architecture
that incorporates a cross-attention mechanism to fuse feature representations
from image and tabular data, improving CHD detection by 11% and 50% over image
and tabular single-modality approaches, respectively, and achieving an F1 score
of 79.8 $\pm$ 4.8% in the CARDIUM dataset. We will publicly release our dataset
and code to encourage further research on this unexplored field. Our dataset
and code are available at https://github.com/BCVUniandes/Cardium, and at the
project website https://bcv-uniandes.github.io/CardiumPage/

</details>


### [24] [The Face of Persuasion: Analyzing Bias and Generating Culture-Aware Ads](https://arxiv.org/abs/2510.15240)
*Aysan Aghazadeh,Adriana Kovashka*

Main category: cs.CV

TL;DR: 该研究探讨了文本到图像模型在定制视觉广告和针对特定人群方面的潜力，重点关注广告中的人口统计偏见以及具有不同性别/种族描绘的相同广告的说服力差异。此外，还实验了一种针对特定国家广告的投放技术。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是探索文本到图像模型在定制视觉广告和定向投放方面的应用潜力，并识别和量化这些模型在生成广告时可能存在的偏见。

Method: 研究方法包括：1. 检查不同广告主题下的人口统计偏见。2. 评估相同广告（仅改变人物性别/种族）的说服力差异。3. 实验一种针对特定国家投放广告的技术。

Result: 研究结果揭示了文本到图像模型在生成广告时存在人口统计偏见，并且相同广告在描绘不同性别/种族时，其说服力也存在差异。同时，针对特定国家投放广告的技术也进行了实验。

Conclusion: 研究表明，文本到图像模型在广告领域的应用具有潜力，但也存在人口统计偏见和说服力不均等的问题，需要在实际应用中加以关注和解决。

Abstract: Text-to-image models are appealing for customizing visual advertisements and
targeting specific populations. We investigate this potential by examining the
demographic bias within ads for different ad topics, and the disparate level of
persuasiveness (judged by models) of ads that are identical except for
gender/race of the people portrayed. We also experiment with a technique to
target ads for specific countries. The code is available at
https://github.com/aysanaghazadeh/FaceOfPersuasion

</details>


### [25] [DriveGen3D: Boosting Feed-Forward Driving Scene Generation with Efficient Video Diffusion](https://arxiv.org/abs/2510.15264)
*Weijie Wang,Jiagang Zhu,Zeyu Zhang,Xiaofeng Wang,Zheng Zhu,Guosheng Zhao,Chaojun Ni,Haoxiao Wang,Guan Huang,Xinze Chen,Yukun Zhou,Wenkang Qin,Duochao Shi,Haoyun Li,Guanghong Jia,Jiwen Lu*

Main category: cs.CV

TL;DR: DriveGen3D是一个用于生成高质量、高度可控的动态3D驾驶场景的新框架，解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有驾驶场景合成方法存在计算成本高、仅限于视频合成无3D表示或仅限于静态场景重建等问题。

Method: DriveGen3D结合了加速的长期视频生成和大规模动态场景重建，通过多模态条件控制。它包括一个用于文本和鸟瞰图（BEV）引导的高分辨率、时间连贯视频合成的快速视频扩散变换器（FastDrive-DiT），以及一个用于跨时间快速构建3D高斯表示并确保时空一致性的前馈重建模块（FastRecon3D）。

Result: 该框架能够实时生成扩展的驾驶视频（高达424x800，12 FPS）和相应的动态3D场景，在新视角合成方面实现了0.811的SSIM和22.84的PSNR，同时保持参数效率。

Conclusion: DriveGen3D通过集成视频生成和3D重建，实现了高效、高质量的动态3D驾驶场景合成。

Abstract: We present DriveGen3D, a novel framework for generating high-quality and
highly controllable dynamic 3D driving scenes that addresses critical
limitations in existing methodologies. Current approaches to driving scene
synthesis either suffer from prohibitive computational demands for extended
temporal generation, focus exclusively on prolonged video synthesis without 3D
representation, or restrict themselves to static single-scene reconstruction.
Our work bridges this methodological gap by integrating accelerated long-term
video generation with large-scale dynamic scene reconstruction through
multimodal conditional control. DriveGen3D introduces a unified pipeline
consisting of two specialized components: FastDrive-DiT, an efficient video
diffusion transformer for high-resolution, temporally coherent video synthesis
under text and Bird's-Eye-View (BEV) layout guidance; and FastRecon3D, a
feed-forward reconstruction module that rapidly builds 3D Gaussian
representations across time, ensuring spatial-temporal consistency. Together,
these components enable real-time generation of extended driving videos (up to
$424\times800$ at 12 FPS) and corresponding dynamic 3D scenes, achieving SSIM
of 0.811 and PSNR of 22.84 on novel view synthesis, all while maintaining
parameter efficiency.

</details>


### [26] [CuSfM: CUDA-Accelerated Structure-from-Motion](https://arxiv.org/abs/2510.15271)
*Jingrui Yu,Jun Liu,Kefei Ren,Joydeep Biswas,Rurui Ye,Keqiang Wu,Chirag Majithia,Di Zeng*

Main category: cs.CV

TL;DR: cuSfM是一个利用GPU加速进行运动恢复结构（SfM）的离线系统，能够高效地进行相机姿态估计和全局一致性建图，并在精度和速度上优于COLMAP。


<details>
  <summary>Details</summary>
Motivation: 准确的相机姿态估计是自动驾驶、机器人感知和虚拟仿真系统中密集重建的基础。

Method: cuSfM系统利用CUDA加速和GPU并行化，能够高效地运用计算密集但精度高的特征提取器，生成全面且无冗余的数据关联，从而实现精确的相机姿态估计和全局一致性建图。该系统支持姿态优化、建图、先验地图定位和外部校准。

Result: 实验结果表明，cuSfM在各种测试场景下，其精度和处理速度均显著优于广泛使用的COLMAP方法，同时保持了离线SfM应用所需的高精度和全局一致性。

Conclusion: cuSfM作为一种高效且精确的离线SfM系统，通过GPU加速显著提升了相机姿态估计和建图的性能，为相关领域的研究和应用提供了有力支持。

Abstract: Efficient and accurate camera pose estimation forms the foundational
requirement for dense reconstruction in autonomous navigation, robotic
perception, and virtual simulation systems. This paper addresses the challenge
via cuSfM, a CUDA-accelerated offline Structure-from-Motion system that
leverages GPU parallelization to efficiently employ computationally intensive
yet highly accurate feature extractors, generating comprehensive and
non-redundant data associations for precise camera pose estimation and globally
consistent mapping. The system supports pose optimization, mapping, prior-map
localization, and extrinsic refinement. It is designed for offline processing,
where computational resources can be fully utilized to maximize accuracy.
Experimental results demonstrate that cuSfM achieves significantly improved
accuracy and processing speed compared to the widely used COLMAP method across
various testing scenarios, while maintaining the high precision and global
consistency essential for offline SfM applications. The system is released as
an open-source Python wrapper implementation, PyCuSfM, available at
https://github.com/nvidia-isaac/pyCuSFM, to facilitate research and
applications in computer vision and robotics.

</details>


### [27] [Post-Processing Methods for Improving Accuracy in MRI Inpainting](https://arxiv.org/abs/2510.15282)
*Nishad Kulkarni,Krithika Iyer,Austin Tapp,Abhijeet Parida,Daniel Capellán-Martín,Zhifan Jiang,María J. Ledesma-Carbayo,Syed Muhammad Anwar,Marius George Linguraru*

Main category: cs.CV

TL;DR: MRI inpainting tools struggle with large lesions like tumors. This paper combines multiple inpainting models with post-processing techniques and a U-Net enhancement to improve anatomical plausibility and visual fidelity, leading to more accurate and robust results.


<details>
  <summary>Details</summary>
Motivation: Most automated MRI analysis tools are optimized for healthy brains and fail with large lesions (e.g., tumors). Image inpainting aims to synthesize healthy tissue in lesion regions to enable the use of these general-purpose tools.

Method: The paper evaluates state-of-the-art inpainting models and proposes a methodology combining model ensembling with post-processing strategies (median filtering, histogram matching, pixel averaging) and a U-Net enhancement stage for anatomical refinement.

Result: The proposed pipeline improves the anatomical plausibility and visual fidelity of inpainted regions, achieving higher accuracy and more robust outcomes compared to individual baseline models.

Conclusion: By combining established models with targeted post-processing and enhancement, the paper achieves improved and more accessible inpainting outcomes, supporting broader clinical deployment and sustainable research. A docker is provided for the BraTS 2025 inpainting task.

Abstract: Magnetic Resonance Imaging (MRI) is the primary imaging modality used in the
diagnosis, assessment, and treatment planning for brain pathologies. However,
most automated MRI analysis tools, such as segmentation and registration
pipelines, are optimized for healthy anatomies and often fail when confronted
with large lesions such as tumors. To overcome this, image inpainting
techniques aim to locally synthesize healthy brain tissues in tumor regions,
enabling the reliable application of general-purpose tools. In this work, we
systematically evaluate state-of-the-art inpainting models and observe a
saturation in their standalone performance. In response, we introduce a
methodology combining model ensembling with efficient post-processing
strategies such as median filtering, histogram matching, and pixel averaging.
Further anatomical refinement is achieved via a lightweight U-Net enhancement
stage. Comprehensive evaluation demonstrates that our proposed pipeline
improves the anatomical plausibility and visual fidelity of inpainted regions,
yielding higher accuracy and more robust outcomes than individual baseline
models. By combining established models with targeted post-processing, we
achieve improved and more accessible inpainting outcomes, supporting broader
clinical deployment and sustainable, resource-conscious research. Our 2025
BraTS inpainting docker is available at
https://hub.docker.com/layers/aparida12/brats2025/inpt.

</details>


### [28] [QCFace: Image Quality Control for boosting Face Representation & Recognition](https://arxiv.org/abs/2510.15289)
*Duc-Phuong Doan-Ngo,Thanh-Dang Diep,Thanh Nguyen-Duc,Thanh-Sach LE,Nam Thoai*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Recognizability, a key perceptual factor in human face processing, strongly
affects the performance of face recognition (FR) systems in both verification
and identification tasks. Effectively using recognizability to enhance feature
representation remains challenging. In deep FR, the loss function plays a
crucial role in shaping how features are embedded. However, current methods
have two main drawbacks: (i) recognizability is only partially captured through
soft margin constraints, resulting in weaker quality representation and lower
discrimination, especially for low-quality or ambiguous faces; (ii) mutual
overlapping gradients between feature direction and magnitude introduce
undesirable interactions during optimization, causing instability and confusion
in hypersphere planning, which may result in poor generalization, and entangled
representations where recognizability and identity are not cleanly separated.
To address these issues, we introduce a hard margin strategy - Quality Control
Face (QCFace), which overcomes the mutual overlapping gradient problem and
enables the clear decoupling of recognizability from identity representation.
Based on this strategy, a novel hard-margin-based loss function employs a
guidance factor for hypersphere planning, simultaneously optimizing for
recognition ability and explicit recognizability representation. Extensive
experiments confirm that QCFace not only provides robust and quantifiable
recognizability encoding but also achieves state-of-the-art performance in both
verification and identification benchmarks compared to existing
recognizability-based losses.

</details>


### [29] [Hyperbolic Structured Classification for Robust Single Positive Multi-label Learning](https://arxiv.org/abs/2510.15296)
*Yiming Lin,Shang Wang,Junkai Zhou,Qiufeng Wang,Xiao-Bo Jin,Kaizhu Huang*

Main category: cs.CV

TL;DR: 提出首个用于单正多标签学习（SPMLL）的双曲球分类框架，通过几何交互自然建模标签间的包含、重叠和分离关系，并引入温度自适应分类器和双井正则化，在四个基准数据集上实验证明了其优越的性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有SPMLL方法隐式建模标签关系，缺乏明确的几何定义来区分不同关系类型。

Method: 提出首个基于双曲几何的SPMLL框架，将标签表示为双曲球而非点或向量，通过球的几何交互自然地模拟标签间的包含、重叠和分离关系。引入了温度自适应双曲球分类器和双井正则化器。

Result: 在MS-COCO、PASCAL VOC、NUS-WIDE和CUB-200-2011四个基准数据集上进行了广泛的实验，结果显示该方法性能具有竞争力，并且比现有方法具有更好的可解释性。学习到的嵌入与现实世界的共现模式高度相关。

Conclusion: 双曲几何为结构化分类和不完全监督提供了一个更鲁棒的范式，能够有效地捕捉和利用标签间的复杂关系。

Abstract: Single Positive Multi-Label Learning (SPMLL) addresses the challenging
scenario where each training sample is annotated with only one positive label
despite potentially belonging to multiple categories, making it difficult to
capture complex label relationships and hierarchical structures. While existing
methods implicitly model label relationships through distance-based similarity,
lacking explicit geometric definitions for different relationship types. To
address these limitations, we propose the first hyperbolic classification
framework for SPMLL that represents each label as a hyperbolic ball rather than
a point or vector, enabling rich inter-label relationship modeling through
geometric ball interactions. Our ball-based approach naturally captures
multiple relationship types simultaneously: inclusion for hierarchical
structures, overlap for co-occurrence patterns, and separation for semantic
independence. Further, we introduce two key component innovations: a
temperature-adaptive hyperbolic ball classifier and a physics-inspired
double-well regularization that guides balls toward meaningful configurations.
To validate our approach, extensive experiments on four benchmark datasets
(MS-COCO, PASCAL VOC, NUS-WIDE, CUB-200-2011) demonstrate competitive
performance with superior interpretability compared to existing methods.
Furthermore, statistical analysis reveals strong correlation between learned
embeddings and real-world co-occurrence patterns, establishing hyperbolic
geometry as a more robust paradigm for structured classification under
incomplete supervision.

</details>


### [30] [Exploring Conditions for Diffusion models in Robotic Control](https://arxiv.org/abs/2510.15510)
*Heeseong Shin,Byeongho Heo,Dongyoon Han,Seungryong Kim,Taekyung Kim*

Main category: cs.CV

TL;DR: 冻结预训练视觉模型无法很好地适应机器人控制任务，提出ORCA，通过引入可学习的任务提示和视觉提示，利用预训练的文本到图像扩散模型生成适应性强的视觉表征，以提高机器人控制性能。


<details>
  <summary>Details</summary>
Motivation: 现有的预训练视觉表征在机器人控制任务中通常是固定的，无法适应特定任务。

Method: 提出ORCA，利用预训练的文本到图像扩散模型，引入可学习的任务提示和视觉提示，以生成适应机器人控制任务的视觉表征，而无需对扩散模型进行微调。

Result: ORCA在多个机器人控制基准测试中取得了最先进的性能，显著优于现有方法。

Conclusion: 通过引入任务提示和视觉提示，ORCA能够有效地利用预训练的文本到图像扩散模型生成适应性强的视觉表征，从而在机器人控制任务中取得优异表现。

Abstract: While pre-trained visual representations have significantly advanced
imitation learning, they are often task-agnostic as they remain frozen during
policy learning. In this work, we explore leveraging pre-trained text-to-image
diffusion models to obtain task-adaptive visual representations for robotic
control, without fine-tuning the model itself. However, we find that naively
applying textual conditions - a successful strategy in other vision domains -
yields minimal or even negative gains in control tasks. We attribute this to
the domain gap between the diffusion model's training data and robotic control
environments, leading us to argue for conditions that consider the specific,
dynamic visual information required for control. To this end, we propose ORCA,
which introduces learnable task prompts that adapt to the control environment
and visual prompts that capture fine-grained, frame-specific details. Through
facilitating task-adaptive representations with our newly devised conditions,
our approach achieves state-of-the-art performance on various robotic control
benchmarks, significantly surpassing prior methods.

</details>


### [31] [Latent Diffusion Model without Variational Autoencoder](https://arxiv.org/abs/2510.15301)
*Minglei Shi,Haolin Wang,Wenzhao Zheng,Ziyang Yuan,Xiaoshi Wu,Xintao Wang,Pengfei Wan,Jie Zhou,Jiwen Lu*

Main category: cs.CV

TL;DR: 潜变量扩散模型（LDM）虽然在生成高质量图像方面表现出色，但存在训练效率低下、推理速度慢和泛化能力不足等问题。这些问题源于其潜变量空间缺乏清晰的语义分离和判别性结构。为解决这些问题，本文提出了一种名为SVG的新型扩散模型，它摒弃了变分自编码器（VAE），转而利用自监督表征进行视觉生成。SVG通过使用冻结的DINO特征构建了一个具有清晰语义判别性的特征空间，并利用一个轻量级的残差分支来捕捉细节以实现高保真重建。在SVG的语义结构化潜变量空间上直接训练扩散模型，可以提高训练效率，实现快速采样和生成质量的提升。实验证明，SVG能够保留底层自监督表征的语义和判别能力，为实现通用的高质量视觉表征提供了一条有效途径。


<details>
  <summary>Details</summary>
Motivation: 现有的基于VAE的潜变量扩散模型在训练效率、推理速度和跨任务迁移能力方面存在局限，这主要是由于其潜变量空间缺乏清晰的语义分离和判别性结构。

Method: 本文提出了一种名为SVG的新型模型，它不使用VAE，而是利用自监督表征（冻结的DINO特征）来构建一个具有语义判别性的特征空间，并通过一个轻量级残差分支来处理细节，然后在该结构化潜层空间上训练扩散模型。

Result: SVG模型实现了更快的扩散模型训练、支持少步采样，并提高了生成质量。此外，SVG保留了底层自监督表征的语义和判别能力。

Conclusion: SVG模型通过利用自监督表征构建语义结构化的潜变量空间，成功克服了传统基于VAE的扩散模型的局限性，在训练效率、采样速度和生成质量方面均有显著提升，并展现出作为通用视觉表征的潜力。

Abstract: Recent progress in diffusion-based visual generation has largely relied on
latent diffusion models with variational autoencoders (VAEs). While effective
for high-fidelity synthesis, this VAE+diffusion paradigm suffers from limited
training efficiency, slow inference, and poor transferability to broader vision
tasks. These issues stem from a key limitation of VAE latent spaces: the lack
of clear semantic separation and strong discriminative structure. Our analysis
confirms that these properties are crucial not only for perception and
understanding tasks, but also for the stable and efficient training of latent
diffusion models. Motivated by this insight, we introduce SVG, a novel latent
diffusion model without variational autoencoders, which leverages
self-supervised representations for visual generation. SVG constructs a feature
space with clear semantic discriminability by leveraging frozen DINO features,
while a lightweight residual branch captures fine-grained details for
high-fidelity reconstruction. Diffusion models are trained directly on this
semantically structured latent space to facilitate more efficient learning. As
a result, SVG enables accelerated diffusion training, supports few-step
sampling, and improves generative quality. Experimental results further show
that SVG preserves the semantic and discriminative capabilities of the
underlying self-supervised representations, providing a principled pathway
toward task-general, high-quality visual representations.

</details>


### [32] [Layer as Puzzle Pieces: Compressing Large Language Models through Layer Concatenation](https://arxiv.org/abs/2510.15304)
*Fei Wang,Li Shen,Liang Ding,Chao Xue,Ye Liu,Changxing Ding*

Main category: cs.CV

TL;DR: CoMe通过一种渐进式剪枝框架和分层蒸馏后训练过程来解决大型语言模型（LLM）剪枝带来的性能下降问题，实现了在减小模型尺寸的同时保留其能力。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）因模型规模巨大而面临高昂的计算和存储成本。虽然结构化剪枝是一种有效的减小模型尺寸的方法，但现有方法往往忽略了在剪枝过程中保留模型原有能力。具体来说，直接移除层会导致性能显著下降，线性权重层聚合能力不足，并且缺乏有效的训练后恢复机制。

Method: CoMe提出了一个渐进式剪枝框架，结合了基于拼接的融合技术和分层蒸馏的后训练过程。该框架首先引入一个利用激活强度和权重范数的通道敏感性度量，用于细粒度的通道选择。然后，采用基于拼接的层融合方法，将相邻层中最关键的通道进行融合，实现渐进式模型尺寸缩减。最后，通过分层蒸馏协议，利用剪枝过程中建立的原始模型层与剪枝后模型层之间的对应关系，实现高效的知识迁移。

Result: 在七个基准测试上的实验表明，CoMe在剪枝LLaMA-2-7b参数量30%的情况下，保留了原始模型83%的平均准确率，达到了最先进的性能。

Conclusion: CoMe通过其创新的渐进式剪枝框架和分层蒸馏后训练过程，有效地解决了大型语言模型剪枝中的性能下降问题，实现了在减小模型尺寸的同时最大程度地保留模型能力。

Abstract: Large Language Models excel at natural language processing tasks, but their
massive size leads to high computational and storage demands. Recent works have
sought to reduce their model size through layer-wise structured pruning.
However, they tend to ignore retaining the capabilities in the pruned part. In
this work, we re-examine structured pruning paradigms and uncover several key
limitations: 1) notable performance degradation due to direct layer removal, 2)
incompetent linear weight layer aggregation, and 3) the lack of effective
post-training recovery mechanisms. To address these limitations, we propose
CoMe, including a progressive layer pruning framework with a
Concatenation-based Merging technology and a hierarchical distillation
post-training process. Specifically, we introduce a channel sensitivity metric
that utilizes activation intensity and weight norms for fine-grained channel
selection. Subsequently, we employ a concatenation-based layer merging method
to fuse the most critical channels across adjacent layers, enabling progressive
model size reduction. Finally, we propose a hierarchical distillation protocol
that leverages the correspondences between the original and pruned model layers
established during pruning, thereby enabling efficient knowledge transfer.
Experiments on seven benchmarks show that CoMe achieves state-of-the-art
performance; when pruning 30% of LLaMA-2-7b's parameters, the pruned model
retains 83% of its original average accuracy. Our code is available at
https://github.com/MPI-Lab/CoMe.

</details>


### [33] [Proto-Former: Unified Facial Landmark Detection by Prototype Transformer](https://arxiv.org/abs/2510.15338)
*Shengkai Hu,Haozhe Qi,Jun Wan,Jiaxing Huang,Lefei Zhang,Hang Sun,Dacheng Tao*

Main category: cs.CV

TL;DR: Proto-Former是一个统一、自适应的人脸关键点检测框架，通过联合训练和原型感知的损失函数，解决了多数据集训练的局限性，提高了模型泛化能力和检测精度。


<details>
  <summary>Details</summary>
Motivation: 现有的人脸关键点检测方法大多只能在单一数据集上训练，限制了模型的泛化能力和统一模型的开发。不同的数据集定义了不同数量的关键点，进一步加剧了这一问题。

Method: 提出Proto-Former框架，包含自适应原型感知编码器（APAE）和渐进式原型感知解码器（PPAD），实现了自适应特征提取和原型表示学习。引入新颖的原型感知（PA）损失函数，通过约束原型专家选择权重来解决多数据集训练中的原型专家不稳定的问题，减轻梯度冲突，提取更精确的面部结构特征。

Result: 在多个基准数据集上的广泛实验表明，Proto-Former的性能优于现有的最先进方法。

Conclusion: Proto-Former通过其统一的架构、自适应的特征提取、原型表示学习以及新颖的PA损失函数，有效地解决了多数据集训练的挑战，实现了更优的人脸关键点检测性能。

Abstract: Recent advances in deep learning have significantly improved facial landmark
detection. However, existing facial landmark detection datasets often define
different numbers of landmarks, and most mainstream methods can only be trained
on a single dataset. This limits the model generalization to different datasets
and hinders the development of a unified model. To address this issue, we
propose Proto-Former, a unified, adaptive, end-to-end facial landmark detection
framework that explicitly enhances dataset-specific facial structural
representations (i.e., prototype). Proto-Former overcomes the limitations of
single-dataset training by enabling joint training across multiple datasets
within a unified architecture. Specifically, Proto-Former comprises two key
components: an Adaptive Prototype-Aware Encoder (APAE) that performs adaptive
feature extraction and learns prototype representations, and a Progressive
Prototype-Aware Decoder (PPAD) that refines these prototypes to generate
prompts that guide the model's attention to key facial regions. Furthermore, we
introduce a novel Prototype-Aware (PA) loss, which achieves optimal path
finding by constraining the selection weights of prototype experts. This loss
function effectively resolves the problem of prototype expert addressing
instability during multi-dataset training, alleviates gradient conflicts, and
enables the extraction of more accurate facial structure features. Extensive
experiments on widely used benchmark datasets demonstrate that our Proto-Former
achieves superior performance compared to existing state-of-the-art methods.
The code is publicly available at: https://github.com/Husk021118/Proto-Former.

</details>


### [34] [Spatial457: A Diagnostic Benchmark for 6D Spatial Reasoning of Large Multimodal Models](https://arxiv.org/abs/2502.08636)
*Xingrui Wang,Wufei Ma,Tiezheng Zhang,Celso M de Melo,Jieneng Chen,Alan Yuille*

Main category: cs.CV

TL;DR: LMM在3D空间推理方面能力不足，Spatial457数据集和评估框架旨在解决此问题。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注2D空间理解，缺乏全面评估LMM在不同复杂度下的6D空间推理能力的框架。

Method: 提出Spatial457数据集，包含多对象识别、2D/3D定位和3D方向4项能力，并构建了7种问题类型和5个难度级别。评估了多种LMM，并引入RPDR量化3D推理挑战，同时分析了数据集中存在的预测偏见。

Result: LMM在复杂性和3D/6D空间任务上的性能随任务复杂度增加而下降，特别是在3D推理方面。分析发现了不同属性的预测偏见。

Conclusion: LMM在复杂3D空间推理方面存在显著不足，Spatial457数据集和评估方法有助于揭示和量化这些挑战，并为未来研究提供了方向。

Abstract: Although large multimodal models (LMMs) have demonstrated remarkable
capabilities in visual scene interpretation and reasoning, their capacity for
complex and precise 3-dimensional spatial reasoning remains uncertain. Existing
benchmarks focus predominantly on 2D spatial understanding and lack a framework
to comprehensively evaluate 6D spatial reasoning across varying complexities.
To address this limitation, we present Spatial457, a scalable and unbiased
synthetic dataset designed with 4 key capability for spatial reasoning:
multi-object recognition, 2D location, 3D location, and 3D orientation. We
develop a cascading evaluation structure, constructing 7 question types across
5 difficulty levels that range from basic single object recognition to our new
proposed complex 6D spatial reasoning tasks. We evaluated various large
multimodal models (LMMs) on PulseCheck457, observing a general decline in
performance as task complexity increases, particularly in 3D reasoning and 6D
spatial tasks. To quantify these challenges, we introduce the Relative
Performance Dropping Rate (RPDR), highlighting key weaknesses in 3D reasoning
capabilities. Leveraging the unbiased attribute design of our dataset, we also
uncover prediction biases across different attributes, with similar patterns
observed in real-world image settings. The code and data are released in
https://github.com/XingruiWang/Spatial457.

</details>


### [35] [SHARE: Scene-Human Aligned Reconstruction](https://arxiv.org/abs/2510.15342)
*Joshua Li,Brendan Chharawala,Chang Shu,Xue Bin Peng,Pengcheng Xi*

Main category: cs.CV

TL;DR: SHARE利用场景几何来精确地进行人类运动重建，仅需单目RGB视频。


<details>
  <summary>Details</summary>
Motivation: 为游戏、AR/VR和机器人技术中的自主代理实现逼真角色与环境交互是重要的，但现有方法在精确的3D空间定位方面存在困难。

Method: SHARE首先估计每帧的人体网格和分割掩码，以及关键帧的场景点图。通过将人体网格与从场景中提取的人体点图进行比较，迭代地优化关键帧的人体位置。非关键帧的人体网格通过保持其相对于关键帧根关节的位置来保持一致性。

Result: SHARE实现了更精确的3D人体定位，同时重建了周围场景，并且在策划数据集和网络视频中都表现出色，实验证明其优于现有方法。

Conclusion: SHARE提供了一种利用场景几何进行精确人体运动重建的方法，仅需单目RGB视频，并能同时重建场景，具有广泛的应用前景。

Abstract: Animating realistic character interactions with the surrounding environment
is important for autonomous agents in gaming, AR/VR, and robotics. However,
current methods for human motion reconstruction struggle with accurately
placing humans in 3D space. We introduce Scene-Human Aligned REconstruction
(SHARE), a technique that leverages the scene geometry's inherent spatial cues
to accurately ground human motion reconstruction. Each reconstruction relies
solely on a monocular RGB video from a stationary camera. SHARE first estimates
a human mesh and segmentation mask for every frame, alongside a scene point map
at keyframes. It iteratively refines the human's positions at these keyframes
by comparing the human mesh against the human point map extracted from the
scene using the mask. Crucially, we also ensure that non-keyframe human meshes
remain consistent by preserving their relative root joint positions to keyframe
root joints during optimization. Our approach enables more accurate 3D human
placement while reconstructing the surrounding scene, facilitating use cases on
both curated datasets and in-the-wild web videos. Extensive experiments
demonstrate that SHARE outperforms existing methods.

</details>


### [36] [End-to-End Multi-Modal Diffusion Mamba](https://arxiv.org/abs/2510.13253)
*Chunhao Lu,Qiang Lu,Meichen Dong,Jake Luo*

Main category: cs.CV

TL;DR: MDM是一个统一多模态处理的新型架构，它使用基于Mamba的多步选择扩散模型，通过统一的变分自编码器来生成和细化模态信息，并在高维数据处理、图像生成、图像描述、视觉问答、文本理解和推理任务上表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前端到端多模态模型采用不同的编码器和解码器来处理输入和输出信息，这阻碍了多模态信息的联合表示学习。

Method: MDM利用一个基于Mamba的多步选择扩散模型，通过一个统一的变分自编码器来逐步生成和细化模态信息，该自编码器同时用于编码和解码。

Result: MDM在处理高维数据方面取得了优越的性能，特别是在同时生成高分辨率图像和扩展文本序列方面。在图像生成、图像描述、视觉问答、文本理解和推理任务的评估中，MDM显著优于现有的端到端模型（如MonoFormer、LlamaGen和Chameleon），并能与GPT-4V、Gemini Pro和Mistral等SOTA模型有效竞争。

Conclusion: MDM的有效性验证了其在统一多模态过程方面的能力，同时保持了计算效率，为端到端多模态架构开辟了新的方向。

Abstract: Current end-to-end multi-modal models utilize different encoders and decoders
to process input and output information. This separation hinders the joint
representation learning of various modalities. To unify multi-modal processing,
we propose a novel architecture called MDM (Multi-modal Diffusion Mamba). MDM
utilizes a Mamba-based multi-step selection diffusion model to progressively
generate and refine modality-specific information through a unified variational
autoencoder for both encoding and decoding. This innovative approach allows MDM
to achieve superior performance when processing high-dimensional data,
particularly in generating high-resolution images and extended text sequences
simultaneously. Our evaluations in areas such as image generation, image
captioning, visual question answering, text comprehension, and reasoning tasks
demonstrate that MDM significantly outperforms existing end-to-end models
(MonoFormer, LlamaGen, and Chameleon etc.) and competes effectively with SOTA
models like GPT-4V, Gemini Pro, and Mistral. Our results validate MDM's
effectiveness in unifying multi-modal processes while maintaining computational
efficiency, establishing a new direction for end-to-end multi-modal
architectures.

</details>


### [37] [Cortical-SSM: A Deep State Space Model for EEG and ECoG Motor Imagery Decoding](https://arxiv.org/abs/2510.15371)
*Shuntaro Suzuki,Shunya Nagashima,Masayuki Hirata,Komei Sugiura*

Main category: cs.CV

TL;DR: Cortical-SSM是一种新的深度状态空间模型架构，可以更好地捕捉EEG和ECoG信号在时间、空间和频率域内的细微依赖关系，从而在运动想象任务的分类中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于Transformer的方法在处理EEG和ECoG信号时，难以捕捉其细粒度的依赖关系，并且这些信号容易受到生理伪影的影响。

Method: 提出了一种名为Cortical-SSM的新架构，该架构扩展了深度状态空间模型，能够跨时间、空间和频率域捕捉EEG和ECoG信号的集成依赖关系。

Result: 在三个基准数据集（包括两个大规模公共MI EEG数据集和一个临床MI ECoG数据集）上进行了验证，结果表明Cortical-SSM优于基线方法。模型的可视化解释表明，它能有效捕捉EEG和ECoG信号中与神经生理学相关的区域。

Conclusion: Cortical-SSM在处理EEG和ECoG信号方面具有优势，能够捕捉更精细的依赖关系，并在运动想象任务分类中取得更好的性能。

Abstract: Classification of electroencephalogram (EEG) and electrocorticogram (ECoG)
signals obtained during motor imagery (MI) has substantial application
potential, including for communication assistance and rehabilitation support
for patients with motor impairments. These signals remain inherently
susceptible to physiological artifacts (e.g., eye blinking, swallowing), which
pose persistent challenges. Although Transformer-based approaches for
classifying EEG and ECoG signals have been widely adopted, they often struggle
to capture fine-grained dependencies within them. To overcome these
limitations, we propose Cortical-SSM, a novel architecture that extends deep
state space models to capture integrated dependencies of EEG and ECoG signals
across temporal, spatial, and frequency domains. We validated our method across
three benchmarks: 1) two large-scale public MI EEG datasets containing more
than 50 subjects, and 2) a clinical MI ECoG dataset recorded from a patient
with amyotrophic lateral sclerosis. Our method outperformed baseline methods on
the three benchmarks. Furthermore, visual explanations derived from our model
indicate that it effectively captures neurophysiologically relevant regions of
both EEG and ECoG signals.

</details>


### [38] [Adaptive transfer learning for surgical tool presence detection in laparoscopic videos through gradual freezing fine-tuning](https://arxiv.org/abs/2510.15372)
*Ana Davila,Jacinto Colan,Yasuhisa Hasegawa*

Main category: cs.CV

TL;DR: 该研究提出了一种新颖的、分阶段的自适应微调方法，用于在标注数据有限的情况下，在微创手术图像中更有效地检测手术工具。


<details>
  <summary>Details</summary>
Motivation: 在微创手术中，自动化的手术工具检测对于高级分析和辅助至关重要，但标注数据的稀缺阻碍了深度学习模型的训练。因此，需要一种能够克服数据限制并提高模型性能的有效方法。

Method: 该方法包括两个阶段：首先，通过线性探测阶段将额外的分类层调整到预训练的卷积神经网络（CNN）架构上；然后，通过渐进式冻结阶段动态减少可微调的层数，以调节模型对特定手术域的适应性。这种策略减少了网络复杂性，提高了效率，并且只需要一个训练循环。

Result: 在Cholec80数据集上，使用ResNet-50和DenseNet-121（在ImageNet上预训练）进行评估，该方法在结肠切除术内窥镜视频的手术工具检测方面，取得了96.4%的平均精度均值（mAP），优于现有方法和传统微调技术。此外，在CATARACTS数据集（微创眼科手术）上验证了该方法的泛化能力。

Conclusion: 渐进式冻结微调是一种有前景的技术，能够提高在不同类型的手术中手术工具的检测性能，并且可能在一般的图像分类任务中具有更广泛的应用。

Abstract: Minimally invasive surgery can benefit significantly from automated surgical
tool detection, enabling advanced analysis and assistance. However, the limited
availability of annotated data in surgical settings poses a challenge for
training robust deep learning models. This paper introduces a novel staged
adaptive fine-tuning approach consisting of two steps: a linear probing stage
to condition additional classification layers on a pre-trained CNN-based
architecture and a gradual freezing stage to dynamically reduce the
fine-tunable layers, aiming to regulate adaptation to the surgical domain. This
strategy reduces network complexity and improves efficiency, requiring only a
single training loop and eliminating the need for multiple iterations. We
validated our method on the Cholec80 dataset, employing CNN architectures
(ResNet-50 and DenseNet-121) pre-trained on ImageNet for detecting surgical
tools in cholecystectomy endoscopic videos. Our results demonstrate that our
method improves detection performance compared to existing approaches and
established fine-tuning techniques, achieving a mean average precision (mAP) of
96.4%. To assess its broader applicability, the generalizability of the
fine-tuning strategy was further confirmed on the CATARACTS dataset, a distinct
domain of minimally invasive ophthalmic surgery. These findings suggest that
gradual freezing fine-tuning is a promising technique for improving tool
presence detection in diverse surgical procedures and may have broader
applications in general image classification tasks.

</details>


### [39] [FreqPDE: Rethinking Positional Depth Embedding for Multi-View 3D Object Detection Transformers](https://arxiv.org/abs/2510.15385)
*Haisheng Su,Junjie Zhang,Feixiang Song,Sanping Zhou,Wei Wu,Nanning Zheng,Junchi Yan*

Main category: cs.CV

TL;DR: 提出一种新颖的 FreqPDE 方法，通过融合多尺度频率信息、跨视图一致性和尺度不变性来增强 3D 对象检测的深度估计，从而提高精度，特别是在处理物体边界和小型物体方面。


<details>
  <summary>Details</summary>
Motivation: 现有方法在从多视图 2D 图像检测 3D 对象时，依赖深度预测来恢复空间信息，但这需要 LiDAR 点云的显式监督。然而，现有深度预测方法存在物体边界深度不连续和小物体不清晰等问题，这主要是由于投影点的监督稀疏以及使用高层图像特征进行深度预测。此外，之前的研究也忽略了跨视图一致性和尺度不变性。

Method: 提出一种名为 FreqPDE 的方法，包含三个主要模块：1. 频率感知空间金字塔编码器 (FSPE)：融合不同层级的高频边缘线索和低频语义信息，构建特征金字塔。2. 跨视图尺度不变深度预测器 (CSDP)：利用跨视图和通道注意力机制估计像素级深度分布。3. 位置深度编码器 (PDE)：结合 2D 图像特征和 3D 位置嵌入，生成用于查询解码的 3D 深度感知特征。此外，采用混合深度监督，从度量和分布两个方面进行互补的深度学习。

Result: 在 nuScenes 数据集上进行的大量实验证明了所提出方法的有效性和优越性。

Conclusion: 所提出的 FreqPDE 方法通过整合频率信息、跨视图一致性和尺度不变性，能够有效提升 3D 对象检测的性能，解决了现有方法在深度预测方面的不足。

Abstract: Detecting 3D objects accurately from multi-view 2D images is a challenging
yet essential task in the field of autonomous driving. Current methods resort
to integrating depth prediction to recover the spatial information for object
query decoding, which necessitates explicit supervision from LiDAR points
during the training phase. However, the predicted depth quality is still
unsatisfactory such as depth discontinuity of object boundaries and
indistinction of small objects, which are mainly caused by the sparse
supervision of projected points and the use of high-level image features for
depth prediction. Besides, cross-view consistency and scale invariance are also
overlooked in previous methods. In this paper, we introduce Frequency-aware
Positional Depth Embedding (FreqPDE) to equip 2D image features with spatial
information for 3D detection transformer decoder, which can be obtained through
three main modules. Specifically, the Frequency-aware Spatial Pyramid Encoder
(FSPE) constructs a feature pyramid by combining high-frequency edge clues and
low-frequency semantics from different levels respectively. Then the Cross-view
Scale-invariant Depth Predictor (CSDP) estimates the pixel-level depth
distribution with cross-view and efficient channel attention mechanism.
Finally, the Positional Depth Encoder (PDE) combines the 2D image features and
3D position embeddings to generate the 3D depth-aware features for query
decoding. Additionally, hybrid depth supervision is adopted for complementary
depth learning from both metric and distribution aspects. Extensive experiments
conducted on the nuScenes dataset demonstrate the effectiveness and superiority
of our proposed method.

</details>


### [40] [PFGS: Pose-Fused 3D Gaussian Splatting for Complete Multi-Pose Object Reconstruction](https://arxiv.org/abs/2510.15386)
*Ting-Yu Yen,Yu-Sheng Chiu,Shih-Hsuan Hung,Peter Wonka,Hung-Kuo Chu*

Main category: cs.CV

TL;DR: PFGS是一个姿态感知3D高斯泼溅框架，通过融合来自多个姿势的图像来重建完整的物体，解决了传统3DGS在处理遮挡和自遮挡区域时的不足。


<details>
  <summary>Details</summary>
Motivation: 现有3DGS方法通常假设物体姿态单一，导致重建不完整，无法处理遮挡区域。PFGS旨在解决从多姿态图像捕获中重建完整物体的实际挑战。

Method: PFGS迭代地将辅助姿态的图像集融合到主姿态的统一3DGS表示中。采用姿态感知融合策略，结合全局和局部配准来合并视图并优化3DGS模型。它利用背景特征进行姿态估计，并运用基础模型进行跨姿态配准，以提高鲁棒性和效率，同时解决背景不一致问题。

Result: 实验结果表明，PFGS在定性和定量评估中均优于现有方法，能够生成更完整的重建和更高保真度的3DGS模型。

Conclusion: PFGS通过其新颖的姿态感知融合策略，成功地实现了从多姿态图像捕获中重建完整物体，并在重建完整性和保真度方面取得了显著的改进。

Abstract: Recent advances in 3D Gaussian Splatting (3DGS) have enabled high-quality,
real-time novel-view synthesis from multi-view images. However, most existing
methods assume the object is captured in a single, static pose, resulting in
incomplete reconstructions that miss occluded or self-occluded regions. We
introduce PFGS, a pose-aware 3DGS framework that addresses the practical
challenge of reconstructing complete objects from multi-pose image captures.
Given images of an object in one main pose and several auxiliary poses, PFGS
iteratively fuses each auxiliary set into a unified 3DGS representation of the
main pose. Our pose-aware fusion strategy combines global and local
registration to merge views effectively and refine the 3DGS model. While recent
advances in 3D foundation models have improved registration robustness and
efficiency, they remain limited by high memory demands and suboptimal accuracy.
PFGS overcomes these challenges by incorporating them more intelligently into
the registration process: it leverages background features for per-pose camera
pose estimation and employs foundation models for cross-pose registration. This
design captures the best of both approaches while resolving background
inconsistency issues. Experimental results demonstrate that PFGS consistently
outperforms strong baselines in both qualitative and quantitative evaluations,
producing more complete reconstructions and higher-fidelity 3DGS models.

</details>


### [41] [LILAC: Long-sequence Incremental Low-latency Arbitrary Motion Stylization via Streaming VAE-Diffusion with Causal Decoding](https://arxiv.org/abs/2510.15392)
*Peng Ren,Hai Yang*

Main category: cs.CV

TL;DR: LILAC通过引入潜空间流式架构和滑动窗口因果设计，将离线VAE-Diffusion风格化框架扩展到在线设置，实现了低延迟、长序列的任意运动风格化。


<details>
  <summary>Details</summary>
Motivation: 实时生成长序列和风格化的人体运动对于需要持续和响应式角色控制的应用至关重要，但现有方法存在计算开销大和时间稳定性差的问题。

Method: LILAC扩展了一个高性能的离线框架，通过潜空间流式架构、滑动窗口因果设计以及注入解码的运动特征来实现在线风格化，无需未来帧或修改扩散模型。

Result: 实验证明，LILAC在保持风格化质量的同时实现了良好的响应性，能够在基准数据集上进行长序列实时任意风格化。

Conclusion: LILAC成功地将先进的离线运动风格化技术扩展到实时在线场景，解决了现有流式方法的局限性，并在风格化质量和响应速度之间取得了良好的平衡。

Abstract: Generating long and stylized human motions in real time is critical for
applications that demand continuous and responsive character control. Despite
its importance, existing streaming approaches often operate directly in the raw
motion space, leading to substantial computational overhead and making it
difficult to maintain temporal stability. In contrast, latent-space
VAE-Diffusion-based frameworks alleviate these issues and achieve high-quality
stylization, but they are generally confined to offline processing. To bridge
this gap, LILAC (Long-sequence Incremental Low-latency Arbitrary Motion
Stylization via Streaming VAE-Diffusion with Causal Decoding) builds upon a
recent high-performing offline framework for arbitrary motion stylization and
extends it to an online setting through a latent-space streaming architecture
with a sliding-window causal design and the injection of decoded motion
features to ensure smooth motion transitions. This architecture enables
long-sequence real-time arbitrary stylization without relying on future frames
or modifying the diffusion model architecture, achieving a favorable balance
between stylization quality and responsiveness as demonstrated by experiments
on benchmark datasets. Supplementary video and examples are available at the
project page: https://pren1.github.io/lilac/

</details>


### [42] [MARIS: Marine Open-Vocabulary Instance Segmentation with Geometric Enhancement and Semantic Alignment](https://arxiv.org/abs/2510.15398)
*Bingyu Li,Feiyu Wang,Da Zhang,Zhiyuan Zhao,Junyu Gao,Xuelong Li*

Main category: cs.CV

TL;DR: MARIS是一个用于水下开放词汇实例分割的大规模细粒度基准，并提出了一种利用几何先验和语义对齐来解决视觉退化和语义不匹配问题的框架。


<details>
  <summary>Details</summary>
Motivation: 现有的水下实例分割方法受限于词汇量预测，难以识别新的海洋类别。需要一个基准和方法来支持水下开放词汇分割。

Method: 提出了一种名为MARIS（Marine Open-Vocabulary Instance Segmentation）的基准，并设计了一个包含几何先验增强模块（GPEM）和语义对齐注入机制（SAIM）的统一框架。GPEM利用物体部件和结构线索来保持物体在视觉退化下的稳定性，SAIM通过注入领域特定先验来丰富语言嵌入，减少语义歧义，提升对未见类别的识别能力。

Result: 在MARIS基准上，提出的框架在入域和跨域设置下均显著优于现有的开放词汇基线方法。

Conclusion: 该研究为未来的水下感知研究奠定了坚实的基础，解决了水下开放词汇分割中的视觉退化和语义不匹配问题。

Abstract: Most existing underwater instance segmentation approaches are constrained by
close-vocabulary prediction, limiting their ability to recognize novel marine
categories. To support evaluation, we introduce \textbf{MARIS}
(\underline{Mar}ine Open-Vocabulary \underline{I}nstance
\underline{S}egmentation), the first large-scale fine-grained benchmark for
underwater Open-Vocabulary (OV) segmentation, featuring a limited set of seen
categories and diverse unseen categories. Although OV segmentation has shown
promise on natural images, our analysis reveals that transfer to underwater
scenes suffers from severe visual degradation (e.g., color attenuation) and
semantic misalignment caused by lack underwater class definitions. To address
these issues, we propose a unified framework with two complementary components.
The Geometric Prior Enhancement Module (\textbf{GPEM}) leverages stable
part-level and structural cues to maintain object consistency under degraded
visual conditions. The Semantic Alignment Injection Mechanism (\textbf{SAIM})
enriches language embeddings with domain-specific priors, mitigating semantic
ambiguity and improving recognition of unseen categories. Experiments show that
our framework consistently outperforms existing OV baselines both In-Domain and
Cross-Domain setting on MARIS, establishing a strong foundation for future
underwater perception research.

</details>


### [43] [Robust High-Resolution Multi-Organ Diffusion MRI Using Synthetic-Data-Tuned Prompt Learning](https://arxiv.org/abs/2510.15400)
*Chen Qian,Haoyu Zhang,Junnan Ma,Liuhong Zhu,Qingrui Cai,Yu Wang,Ruibo Song,Lv Li,Lin Mei,Xianwang Jiang,Qin Xu,Boyu Jiang,Ran Tao,Chunmiao Chen,Shufang Chen,Dongyun Liang,Qiu Guo,Jianzhong Lin,Taishan Kang,Mengtian Lu,Liyuan Fu,Ruibin Huang,Huijuan Wan,Xu Huang,Jianhua Wang,Di Guo,Hai Zhong,Jianjun Zhou,Xiaobo Qu*

Main category: cs.CV

TL;DR: LoSP-Prompt是一个基于物理模型和提示学习的重建框架，能有效解决多拍扩散加权成像（multi-shot DWI）中的运动伪影问题，提高成像分辨率和质量，适用于多器官成像，具有广泛的临床应用潜力。


<details>
  <summary>Details</summary>
Motivation: 临床上多拍扩散加权成像（multi-shot DWI）因呼吸、蠕动等引起的严重运动伪影，以及多器官、多层、多方向、多b值的复杂性，限制了其在全身肿瘤诊断中的应用。

Method: 提出了一种名为LoSP-Prompt的重建框架，通过物理信息建模和合成数据驱动的提示学习来克服这些挑战。该框架将相差变化建模为高阶局部平滑相位（LoSP），并整合到低秩Hankel矩阵重建中。通过在模拟生理运动的腹部DWI合成数据上进行训练，利用提示学习自动设置算法的秩参数。

Result: LoSP-Prompt实现了临床单拍DWI两倍的空间分辨率，提高了肝脏病灶的可见性；单一模型泛化到七个不同的解剖区域（肝脏、肾脏、骶髂、盆腔、膝盖、脊髓、大脑）；在图像质量、伪影抑制和降噪方面优于现有最先进的方法（基于11位放射科医生的评分），在肾脏DWI上获得4-5分（优秀），肝脏、骶髂和脊髓DWI上获得4分（良好至优秀），膝盖和脑肿瘤DWI上获得3-4分（良好）。该方法无需导航信号和真实数据监督，实现了可解释、鲁棒的高分辨率多器官多拍DWI成像，且性能不受扫描仪影响。

Conclusion: LoSP-Prompt提供了一种可解释、鲁棒的解决方案，能够实现高分辨率的多器官多拍DWI成像，并且性能不受扫描仪影响，具有在精准肿瘤学领域带来变革的潜力。

Abstract: Clinical adoption of multi-shot diffusion-weighted magnetic resonance imaging
(multi-shot DWI) for body-wide tumor diagnostics is limited by severe
motion-induced phase artifacts from respiration, peristalsis, and so on,
compounded by multi-organ, multi-slice, multi-direction and multi-b-value
complexities. Here, we introduce a reconstruction framework, LoSP-Prompt, that
overcomes these challenges through physics-informed modeling and
synthetic-data-driven prompt learning. We model inter-shot phase variations as
a high-order Locally Smooth Phase (LoSP), integrated into a low-rank Hankel
matrix reconstruction. Crucially, the algorithm's rank parameter is
automatically set via prompt learning trained exclusively on synthetic
abdominal DWI data emulating physiological motion. Validated across 10,000+
clinical images (43 subjects, 4 scanner models, 5 centers), LoSP-Prompt: (1)
Achieved twice the spatial resolution of clinical single-shot DWI, enhancing
liver lesion conspicuity; (2) Generalized to seven diverse anatomical regions
(liver, kidney, sacroiliac, pelvis, knee, spinal cord, brain) with a single
model; (3) Outperformed state-of-the-art methods in image quality, artifact
suppression, and noise reduction (11 radiologists' evaluations on a 5-point
scale, $p<0.05$), achieving 4-5 points (excellent) on kidney DWI, 4 points
(good to excellent) on liver, sacroiliac and spinal cord DWI, and 3-4 points
(good) on knee and tumor brain. The approach eliminates navigator signals and
realistic data supervision, providing an interpretable, robust solution for
high-resolution multi-organ multi-shot DWI. Its scanner-agnostic performance
signifies transformative potential for precision oncology.

</details>


### [44] [Learning to Detect Unknown Jailbreak Attacks in Large Vision-Language Models](https://arxiv.org/abs/2510.15430)
*Shuang Liang,Zhihao Xu,Jialing Tao,Hui Xue,Xiting Wang*

Main category: cs.CV

TL;DR: 大型视觉语言模型（LVLMs）容易受到越狱攻击，现有检测方法泛化能力差或效率低。本研究提出了一种名为 LoD（Learning to Detect）的通用框架，通过多模态安全概念激活向量模块和安全模式自编码器模块，实现了对未知越狱攻击的高效准确检测，提高了检测准确率和效率。


<details>
  <summary>Details</summary>
Motivation: 现有针对大型视觉语言模型（LVLMs）的越狱攻击检测方法存在泛化能力差或效率和准确率受限的问题。本研究旨在提出一种更通用、更高效、更准确的检测框架。

Method: 提出了一种名为 LoD（Learning to Detect）的通用框架，该框架包含一个多模态安全概念激活向量（Multi-modal Safety Concept Activation Vector）模块，用于进行面向安全的表示学习；以及一个安全模式自编码器（Safety Pattern Auto-Encoder）模块，用于进行无监督的攻击分类。

Result: 在多样化的未知越狱攻击上，LoD 方法实现了更高且持续的检测 AUROC（Area Under the Receiver Operating Characteristic Curve）指标，同时提高了检测效率。

Conclusion: LoD 框架通过将重点从特定攻击学习转移到特定任务学习，能够有效、高效地检测未知的越狱攻击，克服了现有方法的局限性。

Abstract: Despite extensive alignment efforts, Large Vision-Language Models (LVLMs)
remain vulnerable to jailbreak attacks, posing serious safety risks. To address
this, existing detection methods either learn attack-specific parameters, which
hinders generalization to unseen attacks, or rely on heuristically sound
principles, which limit accuracy and efficiency. To overcome these limitations,
we propose Learning to Detect (LoD), a general framework that accurately
detects unknown jailbreak attacks by shifting the focus from attack-specific
learning to task-specific learning. This framework includes a Multi-modal
Safety Concept Activation Vector module for safety-oriented representation
learning and a Safety Pattern Auto-Encoder module for unsupervised attack
classification. Extensive experiments show that our method achieves
consistently higher detection AUROC on diverse unknown attacks while improving
efficiency. The code is available at
https://anonymous.4open.science/r/Learning-to-Detect-51CB.

</details>


### [45] [Semantic4Safety: Causal Insights from Zero-shot Street View Imagery Segmentation for Urban Road Safety](https://arxiv.org/abs/2510.15434)
*Huan Chen,Ting Han,Siyu Chen,Zhihao Guo,Yiping Chen,Meiliu Wu*

Main category: cs.CV

TL;DR: 该研究提出了Semantic4Safety框架，利用零样本语义分割技术从街景图像中提取11个可解释的街景指标，并结合道路类型信息，对大量交通事故记录进行分析，旨在解决街景图像在交通事故风险评估中的应用挑战。


<details>
  <summary>Details</summary>
Motivation: 街景图像（SVI）虽然能提供精细的交通风险视角，但在构建捕捉事故相关特征的街头指标以及量化其对不同类型事故的因果影响方面存在两大挑战。

Method: 提出Semantic4Safety框架，应用零样本语义分割从SVI提取11个可解释的街景指标，结合道路类型信息，利用eXtreme Gradient Boosting（XGBoost）多分类器进行分析，并使用Shapley Additive Explanations（SHAP）进行全局和局部特征贡献解释，最后应用Generalized Propensity Score（GPS）加权和Average Treatment Effect（ATE）估计来控制混淆并量化因果效应。

Result: 研究结果揭示了与事故类型相关的、异质性的因果模式： the scene complexity, exposure, and roadway geometry（场景复杂度、暴露度和道路几何形状）等特征具有主导预测能力；可驾驶区域和紧急空间更大可以降低风险，而过度的视觉开放性则可能增加风险。

Conclusion: 通过结合预测建模和因果推断，Semantic4Safety为城市道路安全规划提供了一个可扩展、数据驱动的工具，支持针对性的干预措施和高风险通道诊断。

Abstract: Street-view imagery (SVI) offers a fine-grained lens on traffic risk, yet two
fundamental challenges persist: (1) how to construct street-level indicators
that capture accident-related features, and (2) how to quantify their causal
impacts across different accident types. To address these challenges, we
propose Semantic4Safety, a framework that applies zero-shot semantic
segmentation to SVIs to derive 11 interpretable streetscape indicators, and
integrates road type as contextual information to analyze approximately 30,000
accident records in Austin. Specifically, we train an eXtreme Gradient Boosting
(XGBoost) multi-class classifier and use Shapley Additive Explanations (SHAP)
to interpret both global and local feature contributions, and then apply
Generalized Propensity Score (GPS) weighting and Average Treatment Effect (ATE)
estimation to control confounding and quantify causal effects. Results uncover
heterogeneous, accident-type-specific causal patterns: features capturing scene
complexity, exposure, and roadway geometry dominate predictive power; larger
drivable area and emergency space reduce risk, whereas excessive visual
openness can increase it. By bridging predictive modeling with causal
inference, Semantic4Safety supports targeted interventions and high-risk
corridor diagnosis, offering a scalable, data-informed tool for urban road
safety planning.

</details>


### [46] [Rethinking Convergence in Deep Learning: The Predictive-Corrective Paradigm for Anatomy-Informed Brain MRI Segmentation](https://arxiv.org/abs/2510.15439)
*Feifei Zhang,Zhenhong Jia,Sensen Song,Fei Shi,Dayong Ren*

Main category: cs.CV

TL;DR: PCMambaNet通过引入预测-校正（PC）范式，将医学影像分割任务解耦，显著加速了学习过程，提高了数据效率和模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 端到端学习范式在深度学习中虽然取得了巨大成功，但在医学影像等数据稀疏领域，其收敛速度慢、对大规模数据集依赖性强等缺点限制了效率和适用性。

Method: 提出了一种新颖的网络PCMambaNet，它包含两个协同工作的模块：预测先验模块（PPM）和校正残差网络（CRN）。PPM利用解剖学知识（双边对称性）生成粗略的“焦点图”，以识别诊断相关的非对称区域；CRN则专注于学习和修正这些区域的残差误差，以勾画出精确的病理边界。

Result: PCMambaNet在 А高分辨率脑部MRI分割任务上取得了最先进的准确性，并且仅在1-5个训练周期内收敛，远超传统端到端模型。

Conclusion: 通过显式地整合领域知识来简化学习目标，PCMambaNet有效地缓解了数据效率低下和过拟合问题，展示了PC范式在加速学习和提高模型泛化能力方面的潜力。

Abstract: Despite the remarkable success of the end-to-end paradigm in deep learning,
it often suffers from slow convergence and heavy reliance on large-scale
datasets, which fundamentally limits its efficiency and applicability in
data-scarce domains such as medical imaging. In this work, we introduce the
Predictive-Corrective (PC) paradigm, a framework that decouples the modeling
task to fundamentally accelerate learning. Building upon this paradigm, we
propose a novel network, termed PCMambaNet. PCMambaNet is composed of two
synergistic modules. First, the Predictive Prior Module (PPM) generates a
coarse approximation at low computational cost, thereby anchoring the search
space. Specifically, the PPM leverages anatomical knowledge-bilateral
symmetry-to predict a 'focus map' of diagnostically relevant asymmetric
regions. Next, the Corrective Residual Network (CRN) learns to model the
residual error, focusing the network's full capacity on refining these
challenging regions and delineating precise pathological boundaries. Extensive
experiments on high-resolution brain MRI segmentation demonstrate that
PCMambaNet achieves state-of-the-art accuracy while converging within only 1-5
epochs-a performance unattainable by conventional end-to-end models. This
dramatic acceleration highlights that by explicitly incorporating domain
knowledge to simplify the learning objective, PCMambaNet effectively mitigates
data inefficiency and overfitting.

</details>


### [47] [Select Less, Reason More: Prioritizing Evidence Purity for Video Reasoning](https://arxiv.org/abs/2510.15440)
*Xuchen Li,Xuzhao Li,Shiyu Hu,Kaiqi Huang*

Main category: cs.CV

TL;DR: 现有的视频语言模型在处理长视频时存在信息稀释和关键证据被忽视的问题。我们提出了一个名为EARL的新框架，通过强化学习来主动选择最相关的帧，并对关键帧进行局部重采样以获取更精细的时间信息。实验证明，该模型在多个基准测试中取得了最先进的成果，证明了优先考虑证据纯度和该框架的有效性。


<details>
  <summary>Details</summary>
Motivation: 长视频推理对视频大语言模型来说是一个重大挑战，因为静态的统一帧采样会导致信息稀释和关键证据的模糊。此外，现有的像素空间视频推理代理虽然能主动与视频交互以获取新的视觉信息，但由于缺乏严格的奖励机制来保证证据的纯粹性以及在预采样帧之外进行时间信息补充的能力，因此仍然不理想。

Method: 我们提出了一个基于“少选精选，多思妙解”的核心理念，构建了一个新颖的、以证据为优先的自适应框架。该框架的核心是证据感知强化学习（EARL）框架，它将模型转变为证据的主动审问者。EARL被精确设计用于动态选择最相关的帧，并至关重要的是，对选定的关键帧进行局部重采样，以获取细粒度的时间细节。

Result: 在五个要求苛刻的视频推理基准上的大量实验证明，我们训练的EARL模型在开源视频大语言模型中取得了新的最先进成果，同时学习到了一个有效的、高纯度的视觉证据选择策略。模型在LongVideoBench上达到了59.8%，在MVBench上达到了69.0%，在VideoMME上达到了64.9%。

Conclusion: 这些结果突显了优先考虑证据纯度的重要性以及我们框架的有效性。

Abstract: Long-form video reasoning remains a major challenge for Video Large Language
Models (Video LLMs), as static uniform frame sampling leads to information
dilution and obscures critical evidence. Furthermore, existing pixel-space
video reasoning agents, which are designed to actively interact with the video
to acquire new visual information, remain suboptimal due to their lack of
rigorous reward mechanisms to enforce evidence purity and their inability to
perform temporal information supplementation beyond pre-sampled frames. To
address this critical gap, we propose a novel evidence-prioritized adaptive
framework built upon our core philosophy: "Select Less, Reason More." Our core
contribution is the evidence-aware reinforcement learning (EARL) framework,
which transforms the model into an active interrogator of evidence. EARL is
precisely engineered to dynamically select the most relevant frames and,
crucially, to perform localized re-sampling around the selected key frames to
access fine-grained temporal detail. Extensive experiments on five demanding
video reasoning benchmarks demonstrate that our EARL-trained model achieves new
state-of-the-art among open-source Video LLMs, simultaneously learning an
effective and high-purity visual evidence selection policy. Impressively, our
7B model achieves 59.8% on LongVideoBench, 69.0% on MVBench and 64.9% on
VideoMME. These results highlight the importance of prioritizing evidence
purity and the effectiveness of our framework.

</details>


### [48] [MAVR-Net: Robust Multi-View Learning for MAV Action Recognition with Cross-View Attention](https://arxiv.org/abs/2510.15448)
*Nengbo Zhang,Hann Woei Ho*

Main category: cs.CV

TL;DR: MAVR-Net是一个多视图学习框架，通过结合RGB帧、光流和分割掩码来识别微型飞行器（MAV）的运动，提高了运动识别的鲁棒性和准确性。


<details>
  <summary>Details</summary>
Motivation: 基于视觉的MAV运动识别模型仅依赖RGB数据，难以捕捉复杂的时空特征，限制了区分不同动作的能力。

Method: 提出MAVR-Net框架，使用ResNet提取各视图特征，利用多尺度特征金字塔保留时空细节，并通过跨视图注意力模块和多视图对齐损失增强视图间交互和语义一致性。

Result: 在Short MAV、Medium MAV和Long MAV数据集上，MAVR-Net分别达到了97.8%、96.5%和92.8%的准确率，优于现有方法。

Conclusion: MAVR-Net通过多视图学习显著提高了MAV运动识别的性能。

Abstract: Recognizing the motion of Micro Aerial Vehicles (MAVs) is crucial for
enabling cooperative perception and control in autonomous aerial swarms. Yet,
vision-based recognition models relying only on RGB data often fail to capture
the complex spatial temporal characteristics of MAV motion, which limits their
ability to distinguish different actions. To overcome this problem, this paper
presents MAVR-Net, a multi-view learning-based MAV action recognition
framework. Unlike traditional single-view methods, the proposed approach
combines three complementary types of data, including raw RGB frames, optical
flow, and segmentation masks, to improve the robustness and accuracy of MAV
motion recognition. Specifically, ResNet-based encoders are used to extract
discriminative features from each view, and a multi-scale feature pyramid is
adopted to preserve the spatiotemporal details of MAV motion patterns. To
enhance the interaction between different views, a cross-view attention module
is introduced to model the dependencies among various modalities and feature
scales. In addition, a multi-view alignment loss is designed to ensure semantic
consistency and strengthen cross-view feature representations. Experimental
results on benchmark MAV action datasets show that our method clearly
outperforms existing approaches, achieving 97.8\%, 96.5\%, and 92.8\% accuracy
on the Short MAV, Medium MAV, and Long MAV datasets, respectively.

</details>


### [49] [DPTrack:Directional Kernel-Guided Prompt Learning for Robust Nighttime Aerial Tracking](https://arxiv.org/abs/2510.15449)
*Zhiqiang Zhu,Xinbo Gao,Wen Lu,Jie Li,Zhaoyang Wang,Mingqian Ge*

Main category: cs.CV

TL;DR: DPTrack通过编码目标属性特征到定向卷积核来生成精确的提示，以解决现有夜间航空追踪器在空间定位监督下的模糊性问题，并在基准测试中表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于提示学习的夜间航空追踪器仅依赖空间定位监督，无法提供指向目标特征的精细线索，导致追踪器性能不佳。

Method: DPTrack首先从视觉仿生学中汲取灵感，分层捕捉对象的拓扑结构，并利用拓扑属性丰富特征表示。然后，编码器将这些拓扑感知特征压缩成定向卷积核，作为明确封装对象精细属性线索的核心引导信号。最后，基于通道-类别对应属性构建的卷积核引导提示模块，将卷积核跨搜索区域的特征进行传播，以精确定位目标特征的位置，并将其转换为精确的提示，同时集成空间门控以实现鲁棒的夜间追踪。

Result: DPTrack在已建立的基准测试中表现出优越的性能。

Conclusion: DPTrack通过编码目标属性特征到定向卷积核来生成精确的提示，解决了现有夜间航空追踪器的局限性，并在夜间追踪任务中取得了显著的性能提升。

Abstract: Existing nighttime aerial trackers based on prompt learning rely solely on
spatial localization supervision, which fails to provide fine-grained cues that
point to target features and inevitably produces vague prompts. This limitation
impairs the tracker's ability to accurately focus on the object features and
results in trackers still performing poorly. To address this issue, we propose
DPTrack, a prompt-based aerial tracker designed for nighttime scenarios by
encoding the given object's attribute features into the directional kernel
enriched with fine-grained cues to generate precise prompts. Specifically,
drawing inspiration from visual bionics, DPTrack first hierarchically captures
the object's topological structure, leveraging topological attributes to enrich
the feature representation. Subsequently, an encoder condenses these
topology-aware features into the directional kernel, which serves as the core
guidance signal that explicitly encapsulates the object's fine-grained
attribute cues. Finally, a kernel-guided prompt module built on
channel-category correspondence attributes propagates the kernel across the
features of the search region to pinpoint the positions of target features and
convert them into precise prompts, integrating spatial gating for robust
nighttime tracking. Extensive evaluations on established benchmarks demonstrate
DPTrack's superior performance. Our code will be available at
https://github.com/zzq-vipsl/DPTrack.

</details>


### [50] [Improving Micro-Expression Recognition with Phase-Aware Temporal Augmentation](https://arxiv.org/abs/2510.15466)
*Vu Tram Anh Khuong,Luu Tu Nguyen,Thanh Ha Le,Thi Duyen Ngo*

Main category: cs.CV

TL;DR: 深度学习在微表情识别（MER）中面临数据稀疏性挑战，提出一种基于动态图像的相位感知时间增强方法，将表情序列分解为两个运动阶段（Onset-to-Apex和Apex-to-Offset），为每个阶段生成独立的动态图像（DI），实现双阶段DI增强策略，以丰富运动多样性并引入重要的互补时间线索。


<details>
  <summary>Details</summary>
Motivation: 当前微表情识别（MER）研究受限于标注数据的稀缺性，影响了模型的泛化能力和运动模式的多样性。现有方法主要依赖于简单的空间增强，忽视了能更好利用运动特征的时间增强策略。

Method: 提出一种基于动态图像的相位感知时间增强方法。将微表情序列分解为Onset-to-Apex和Apex-to-Offset两个运动阶段，并为每个阶段生成独立的动态图像（DI），形成双阶段DI增强策略。

Result: 在CASME-II和SAMM数据集上，该方法与CNN、Vision Transformer和LEARNet等六种深度架构结合，在识别准确率、F1分数和平均召回率方面均实现一致的性能提升，与空间增强结合时相对提升高达10%。

Conclusion: 所提出的双阶段DI增强方法简单、模型无关且在资源受限情况下有效，为实现鲁棒且可泛化的MER提供了有前景的方向。

Abstract: Micro-expressions (MEs) are brief, involuntary facial movements that reveal
genuine emotions, typically lasting less than half a second. Recognizing these
subtle expressions is critical for applications in psychology, security, and
behavioral analysis. Although deep learning has enabled significant advances in
micro-expression recognition (MER), its effectiveness is limited by the
scarcity of annotated ME datasets. This data limitation not only hinders
generalization but also restricts the diversity of motion patterns captured
during training. Existing MER studies predominantly rely on simple spatial
augmentations (e.g., flipping, rotation) and overlook temporal augmentation
strategies that can better exploit motion characteristics. To address this gap,
this paper proposes a phase-aware temporal augmentation method based on dynamic
image. Rather than encoding the entire expression as a single onset-to-offset
dynamic image (DI), our approach decomposes each expression sequence into two
motion phases: onset-to-apex and apex-to-offset. A separate DI is generated for
each phase, forming a Dual-phase DI augmentation strategy. These phase-specific
representations enrich motion diversity and introduce complementary temporal
cues that are crucial for recognizing subtle facial transitions. Extensive
experiments on CASME-II and SAMM datasets using six deep architectures,
including CNNs, Vision Transformer, and the lightweight LEARNet, demonstrate
consistent performance improvements in recognition accuracy, unweighted
F1-score, and unweighted average recall, which are crucial for addressing class
imbalance in MER. When combined with spatial augmentations, our method achieves
up to a 10\% relative improvement. The proposed augmentation is simple,
model-agnostic, and effective in low-resource settings, offering a promising
direction for robust and generalizable MER.

</details>


### [51] [MRASfM: Multi-Camera Reconstruction and Aggregation through Structure-from-Motion in Driving Scenes](https://arxiv.org/abs/2510.15467)
*Lingfeng Xuan,Chang Nie,Yiqing Xu,Zhe Liu,Yanzi Miao,Hesheng Wang*

Main category: cs.CV

TL;DR: MRASfM框架通过利用多相机系统的固定空间关系、采用平面模型去除错误点以及在BA中将多相机组视为单一单元来解决驾驶场景中SfM的挑战，实现了更可靠的姿态估计、更高质量的道路表面重建和更高的效率。它还通过场景关联和粗到精的组装模块实现了多场景聚合，并在真实世界应用和公共数据集中得到了验证，在nuScenes数据集上达到了0.124的绝对姿态误差。


<details>
  <summary>Details</summary>
Motivation: SfM在驾驶场景的多相机系统应用中存在姿态估计不可靠、道路表面重建离群点过多和重建效率低等问题。

Method: 提出了一种名为MRASfM的多相机重建和聚合结构化运动框架。该框架在注册过程中利用多相机系统的固定空间关系来提高相机姿态估计的可靠性。它采用平面模型来去除道路表面重建中的错误点。在捆绑调整（BA）中，将多相机组视为一个单一单元以减少优化变量并提高效率。此外，MRASfM通过场景关联和组装模块以粗到精的方式实现多场景聚合。

Result: MRASfM框架在真实世界应用和公共数据集上得到了验证，展现了其在各种场景下的泛化能力和在挑战性条件下的鲁棒性。在nuScenes数据集上，MRASfM取得了0.124的绝对姿态误差，达到了最先进的性能。

Conclusion: MRASfM框架能够有效解决现有SfM方法在多相机驾驶场景中遇到的挑战，并在重建精度和效率方面取得了显著的改进。

Abstract: Structure from Motion (SfM) estimates camera poses and reconstructs point
clouds, forming a foundation for various tasks. However, applying SfM to
driving scenes captured by multi-camera systems presents significant
difficulties, including unreliable pose estimation, excessive outliers in road
surface reconstruction, and low reconstruction efficiency. To address these
limitations, we propose a Multi-camera Reconstruction and Aggregation
Structure-from-Motion (MRASfM) framework specifically designed for driving
scenes. MRASfM enhances the reliability of camera pose estimation by leveraging
the fixed spatial relationships within the multi-camera system during the
registration process. To improve the quality of road surface reconstruction,
our framework employs a plane model to effectively remove erroneous points from
the triangulated road surface. Moreover, treating the multi-camera set as a
single unit in Bundle Adjustment (BA) helps reduce optimization variables to
boost efficiency. In addition, MRASfM achieves multi-scene aggregation through
scene association and assembly modules in a coarse-to-fine fashion. We deployed
multi-camera systems on actual vehicles to validate the generalizability of
MRASfM across various scenes and its robustness in challenging conditions
through real-world applications. Furthermore, large-scale validation results on
public datasets show the state-of-the-art performance of MRASfM, achieving
0.124 absolute pose error on the nuScenes dataset.

</details>


### [52] [MSAM: Multi-Semantic Adaptive Mining for Cross-Modal Drone Video-Text Retrieval](https://arxiv.org/abs/2510.15470)
*Jinghao Huang,Yaxiong Chen,Ganchao Liu*

Main category: cs.CV

TL;DR: 为了解决无人机视频数据量激增带来的语义检索需求，本研究提出了无人机视频-文本检索（DVTR）任务，并首次系统性地研究了该任务。


<details>
  <summary>Details</summary>
Motivation: 无人机视频具有俯视视角、强结构同质性和目标组合多样化的特点，现有针对地面视角的跨模态方法难以有效处理这些特征，因此需要专门针对无人机场景的检索机制。

Method: 提出了一种名为多语义自适应挖掘（MSAM）的新方法，该方法引入了多语义自适应学习机制，能够动态地捕捉帧间变化，并从特定场景区域提取丰富的语义信息。MSAM通过细粒度的文本-视频帧交互，结合了自适应语义构建模块、分布驱动的语义学习项和多样性语义项，以加深文本和无人机视频模态间的交互，并提高特征表示的鲁棒性。此外，为了减少复杂背景的干扰，MSAM引入了跨模态交互特征融合池化机制，专注于目标区域的特征提取和匹配，以减小噪声影响。

Result: 在两个自行构建的无人机视频-文本数据集上的大量实验表明，MSAM在无人机视频-文本检索任务上的表现优于其他现有方法。

Conclusion: MSAM在无人机视频-文本检索任务上取得了优越的性能，并且开源代码和数据集将公开提供。

Abstract: With the advancement of drone technology, the volume of video data increases
rapidly, creating an urgent need for efficient semantic retrieval. We are the
first to systematically propose and study the drone video-text retrieval (DVTR)
task. Drone videos feature overhead perspectives, strong structural
homogeneity, and diverse semantic expressions of target combinations, which
challenge existing cross-modal methods designed for ground-level views in
effectively modeling their characteristics. Therefore, dedicated retrieval
mechanisms tailored for drone scenarios are necessary. To address this issue,
we propose a novel approach called Multi-Semantic Adaptive Mining (MSAM). MSAM
introduces a multi-semantic adaptive learning mechanism, which incorporates
dynamic changes between frames and extracts rich semantic information from
specific scene regions, thereby enhancing the deep understanding and reasoning
of drone video content. This method relies on fine-grained interactions between
words and drone video frames, integrating an adaptive semantic construction
module, a distribution-driven semantic learning term and a diversity semantic
term to deepen the interaction between text and drone video modalities and
improve the robustness of feature representation. To reduce the interference of
complex backgrounds in drone videos, we introduce a cross-modal interactive
feature fusion pooling mechanism that focuses on feature extraction and
matching in target regions, minimizing noise effects. Extensive experiments on
two self-constructed drone video-text datasets show that MSAM outperforms other
existing methods in the drone video-text retrieval task. The source code and
dataset will be made publicly available.

</details>


### [53] [A Novel Combined Optical Flow Approach for Comprehensive Micro-Expression Recognition](https://arxiv.org/abs/2510.15471)
*Vu Tram Anh Khuong,Thi Bich Phuong Man,Luu Tu Nguyen,Thanh Ha Le,Thi Duyen Ngo*

Main category: cs.CV

TL;DR: 本研究提出了一种结合光流（COF）的方法，该方法整合了微表情的 onset-to-apex 和 apex-to-offset 两个阶段，以增强特征表示并提高微表情识别（MER）性能。


<details>
  <summary>Details</summary>
Motivation: 现有的微表情识别（MER）方法主要关注光流的 onset-to-apex 阶段，忽略了包含关键时间动态信息的 apex-to-offset 阶段。

Method: 提出了一种结合光流（COF）的方法，该方法整合了微表情的 onset-to-apex 和 apex-to-offset 两个阶段，以进行更全面的运动分析。

Result: 在 CASMEII 和 SAMM 数据集上的实验结果表明，COF 的性能优于仅基于光流单阶段的方法，证明了其在捕捉微表情动态方面的有效性。

Conclusion: 所提出的 COF 方法通过整合微表情的两个主要运动阶段，能够更全面地分析运动信息，从而提高微表情识别的准确性。

Abstract: Facial micro-expressions are brief, involuntary facial movements that reveal
hidden emotions. Most Micro-Expression Recognition (MER) methods that rely on
optical flow typically focus on the onset-to-apex phase, neglecting the
apex-to-offset phase, which holds key temporal dynamics. This study introduces
a Combined Optical Flow (COF), integrating both phases to enhance feature
representation. COF provides a more comprehensive motion analysis, improving
MER performance. Experimental results on CASMEII and SAMM datasets show that
COF outperforms single optical flow-based methods, demonstrating its
effectiveness in capturing micro-expression dynamics.

</details>


### [54] [Iterative Motion Compensation for Canonical 3D Reconstruction from UAV Plant Images Captured in Windy Conditions](https://arxiv.org/abs/2510.15491)
*Andre Rochow,Jonas Marcic,Svetlana Seliunina,Sven Behnke*

Main category: cs.CV

TL;DR: 使用无人机和迭代方法对植物进行3D表型分析，以克服风和无人机下洗造成的运动伪影，生成高质量的3D重建。


<details>
  <summary>Details</summary>
Motivation: 为了更好地理解植物生长、产量预测和病虫害控制，需要对植物进行3D表型分析，但现有的方法受到环境风和无人机下洗的影响，难以生成高质量的3D重建。

Method: 提出了一种全自动化的3D重建流程，使用商用无人机拍摄图像，并通过Android应用程序进行控制。该流程集成了最先进的3D重建方法，并采用一种迭代方法，通过变形调整输入图像来减轻叶片运动造成的误差。利用原始输入图像和从相应视点渲染的中间3D重建之间的光流来估计运动，逐步减少场景运动，从而得到一个标准化的表示。

Result: 该流程能够提高最先进方法的重建质量，并生成高分辨率的3D网格。此外，还将公开源代码，并提供包含多个植物、不同作物和不同时间点的数据集。

Conclusion: 该研究提出了一种新颖的3D植物表型分析方法，能够生成高质量的3D重建，并克服了现有方法面临的挑战。该方法具有重要的应用价值，并为未来的研究提供了宝贵的数据集和源代码。

Abstract: 3D phenotyping of plants plays a crucial role for understanding plant growth,
yield prediction, and disease control. We present a pipeline capable of
generating high-quality 3D reconstructions of individual agricultural plants.
To acquire data, a small commercially available UAV captures images of a
selected plant. Apart from placing ArUco markers, the entire image acquisition
process is fully autonomous, controlled by a self-developed Android application
running on the drone's controller. The reconstruction task is particularly
challenging due to environmental wind and downwash of the UAV. Our proposed
pipeline supports the integration of arbitrary state-of-the-art 3D
reconstruction methods. To mitigate errors caused by leaf motion during image
capture, we use an iterative method that gradually adjusts the input images
through deformation. Motion is estimated using optical flow between the
original input images and intermediate 3D reconstructions rendered from the
corresponding viewpoints. This alignment gradually reduces scene motion,
resulting in a canonical representation. After a few iterations, our pipeline
improves the reconstruction of state-of-the-art methods and enables the
extraction of high-resolution 3D meshes. We will publicly release the source
code of our reconstruction pipeline. Additionally, we provide a dataset
consisting of multiple plants from various crops, captured across different
points in time.

</details>


### [55] [Rethinking Efficient Hierarchical Mixing Architecture for Low-light RAW Image Enhancement](https://arxiv.org/abs/2510.15497)
*Xianmin Chen,Peiliang Huang,Longfei Han,Dingwen Zhang,Junwei Han*

Main category: cs.CV

TL;DR: HiMA是一种结合Transformer和Mamba的新型低光图像处理架构，通过LoDA和MPF模块解决不均匀光照和细节增强问题，在保证高效的同时实现了卓越的性能。


<details>
  <summary>Details</summary>
Motivation: 低光RAW图像增强在保持强大增强质量和高效率方面仍然面临挑战，现有的深度学习方法存在固有局限性。

Method: 提出了一种名为HiMA（Hierarchical Mixing Architecture）的高效低光图像信号处理架构，结合了Transformer和Mamba模块来分别处理大尺度和小尺度特征，并提出了LoDA（Local Distribution Adjustment）来处理不均匀光照和局部变化，以及MPF（Multi-prior Fusion）模块来融合时域和频域先验以增强细节。

Result: 在多个公共数据集上的大量实验表明，该方法优于最先进的方法，以更少的参数实现了卓越的性能。

Conclusion: HiMA通过结合Transformer和Mamba的优势，并引入LoDA和MPF模块，有效解决了低光图像增强中的效率和质量问题，并在实验中取得了领先的成果。

Abstract: Low-light RAW image enhancement remains a challenging task. Although numerous
deep learning based approaches have been proposed, they still suffer from
inherent limitations. A key challenge is how to simultaneously achieve strong
enhancement quality and high efficiency. In this paper, we rethink the
architecture for efficient low-light image signal processing (ISP) and
introduce a Hierarchical Mixing Architecture (HiMA). HiMA leverages the
complementary strengths of Transformer and Mamba modules to handle features at
large and small scales, respectively, thereby improving efficiency while
avoiding the ambiguities observed in prior two-stage frameworks. To further
address uneven illumination with strong local variations, we propose Local
Distribution Adjustment (LoDA), which adaptively aligns feature distributions
across different local regions. In addition, to fully exploit the denoised
outputs from the first stage, we design a Multi-prior Fusion (MPF) module that
integrates spatial and frequency-domain priors for detail enhancement.
Extensive experiments on multiple public datasets demonstrate that our method
outperforms state-of-the-art approaches, achieving superior performance with
fewer parameters. Code will be released at https://github.com/Cynicarlos/HiMA.

</details>


### [56] [Latent Feature Alignment: Discovering Biased and Interpretable Subpopulations in Face Recognition Models](https://arxiv.org/abs/2510.15520)
*Ignacio Serna*

Main category: cs.CV

TL;DR: 该研究提出了一种名为LFA的无标签算法，用于识别面部识别模型中的亚群体偏差，解决了传统方法依赖昂贵标签和预定义类别的限制。


<details>
  <summary>Details</summary>
Motivation: 现有面部识别模型的准确率高，但仍存在对特定亚人群产生系统性偏差的问题。传统的偏差评估框架需要昂贵的标签数据，并且仅限于预定义的类别。

Method: 提出了一种名为潜在特征对齐（Latent Feature Alignment, LFA）的算法。该算法不依赖属性标签，而是利用潜在方向来识别亚群体。LFA的优势在于能够生成语义上连贯的分组，并且能发现与年龄、种族或穿着等语义属性相对应的可解释方向。

Result: 在四个先进的识别模型（ArcFace, CosFace, ElasticFace, PartialFC）和两个基准（RFW, CelebA）上，LFA在组内语义一致性方面优于k-means和最近邻搜索，并发现了与人口统计学和上下文属性相关的可解释潜在方向。

Conclusion: LFA是一种实用的方法，可以对人脸识别模型进行表示审计，使实践者能够在没有预定义属性注释的情况下识别和解释有偏差的亚群体。

Abstract: Modern face recognition models achieve high overall accuracy but continue to
exhibit systematic biases that disproportionately affect certain
subpopulations. Conventional bias evaluation frameworks rely on labeled
attributes to form subpopulations, which are expensive to obtain and limited to
predefined categories. We introduce Latent Feature Alignment (LFA), an
attribute-label-free algorithm that uses latent directions to identify
subpopulations. This yields two main benefits over standard clustering: (i)
semantically coherent grouping, where faces sharing common attributes are
grouped together more reliably than by proximity-based methods, and (ii)
discovery of interpretable directions, which correspond to semantic attributes
such as age, ethnicity, or attire. Across four state-of-the-art recognition
models (ArcFace, CosFace, ElasticFace, PartialFC) and two benchmarks (RFW,
CelebA), LFA consistently outperforms k-means and nearest-neighbor search in
intra-group semantic coherence, while uncovering interpretable latent
directions aligned with demographic and contextual attributes. These results
position LFA as a practical method for representation auditing of face
recognition models, enabling practitioners to identify and interpret biased
subpopulations without predefined attribute annotations.

</details>


### [57] [Shakti-VLMs: Scalable Vision-Language Models for Enterprise AI](https://arxiv.org/abs/2502.17092)
*Syed Abdul Gaffar Shakhadri,Kruthika KR,Kartik Basavaraj Angadi*

Main category: cs.CV

TL;DR: Shakti VLM 是一系列 1B 和 4B 参数的视觉-语言模型，旨在解决多模态学习中的数据效率挑战。通过架构创新和三阶段训练策略，Shakti 模型在数据量较少的情况下实现了具有竞争力的性能，在文档理解、视觉推理、OCR 提取和一般多模态推理方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言模型（VLM）虽然性能强大，但需要海量训练数据。本研究旨在解决多模态学习中的数据效率挑战，探索在较少数据量下实现高性能的方法。

Method: 提出了一种名为 Shakti VLM 的模型系列（1B 和 4B 参数）。该模型采用了包括 QK-Normalization、混合归一化技术和增强的位置编码在内的架构创新。此外，还设计了一种三阶段的训练策略来优化学习效率。

Result: Shakti-VLM-1B 和 Shakti-VLM-4B 在文档理解、视觉推理、OCR 提取和一般多模态推理任务上取得了优异的成绩，证明了其在数据效率方面的优势。

Conclusion: 研究表明，通过精巧的模型设计和有效的训练策略，可以在不依赖海量数据的情况下实现 VLM 的高性能。Shakti VLM 为大规模企业级多模态任务提供了一个高效的解决方案。

Abstract: We introduce Shakti VLM, a family of vision-language models in the capacity
of 1B and 4B parameters designed to address data efficiency challenges in
multimodal learning. While recent VLMs achieve strong performance through
extensive training data, Shakti models leverage architectural innovations to
attain competitive results with fewer tokens. Key advancements include
QK-Normalization for attention stability, hybrid normalization techniques, and
enhanced positional encoding. A three-stage training strategy further optimizes
learning efficiency. Evaluations show that Shakti-Shakti-VLM-1B and
Shakti-VLM-4B excel in document understanding, Visual Reasoning, OCR
extraction, and general multimodal reasoning. Our results highlight that high
performance can be achieved through model design and training strategy rather
than sheer data volume, making Shakti an efficient solution for
enterprise-scale multimodal tasks.

</details>


### [58] [Balanced Multi-Task Attention for Satellite Image Classification: A Systematic Approach to Achieving 97.23% Accuracy on EuroSAT Without Pre-Training](https://arxiv.org/abs/2510.15527)
*Aditya Vir*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This work presents a systematic investigation of custom convolutional neural
network architectures for satellite land use classification, achieving 97.23%
test accuracy on the EuroSAT dataset without reliance on pre-trained models.
Through three progressive architectural iterations (baseline: 94.30%,
CBAM-enhanced: 95.98%, and balanced multi-task attention: 97.23%) we identify
and address specific failure modes in satellite imagery classification. Our
principal contribution is a novel balanced multi-task attention mechanism that
combines Coordinate Attention for spatial feature extraction with
Squeeze-Excitation blocks for spectral feature extraction, unified through a
learnable fusion parameter. Experimental results demonstrate that this
learnable parameter autonomously converges to alpha approximately 0.57,
indicating near-equal importance of spatial and spectral modalities for
satellite imagery. We employ progressive DropBlock regularization (5-20% by
network depth) and class-balanced loss weighting to address overfitting and
confusion pattern imbalance. The final 12-layer architecture achieves Cohen's
Kappa of 0.9692 with all classes exceeding 94.46% accuracy, demonstrating
confidence calibration with a 24.25% gap between correct and incorrect
predictions. Our approach achieves performance within 1.34% of fine-tuned
ResNet-50 (98.57%) while requiring no external data, validating the efficacy of
systematic architectural design for domain-specific applications. Complete
code, trained models, and evaluation scripts are publicly available.

</details>


### [59] [Diffusion Bridge Networks Simulate Clinical-grade PET from MRI for Dementia Diagnostics](https://arxiv.org/abs/2510.15556)
*Yitong Li,Ralph Buchert,Benita Schmitz-Koep,Timo Grimmer,Björn Ommer,Dennis M. Hedderich,Igor Yakushev,Christian Wachinger*

Main category: cs.CV

TL;DR: SiM2P是一个基于3D扩散桥的框架，可以将MRI和辅助患者信息映射到模拟的FDG-PET图像，提高了诊断准确性，并使其在资源有限的环境中更易获得。


<details>
  <summary>Details</summary>
Motivation: 与MRI相比，FDG-PET在诊断痴呆症方面效果更好，但可及性和成本是一个问题。本研究旨在通过模拟PET图像来解决这个问题。

Method: 提出了一种名为SiM2P的3D扩散桥框架，该框架学习从MRI和辅助患者信息到模拟PET图像的概率映射。

Result: SiM2P将区分三种人群（阿尔茨海默病、额颞叶痴呆和认知健康对照组）的整体诊断准确性从75.0%提高到84.7%。模拟PET图像的诊断确定性评分更高，并且评分者之间的一致性优于MRI图像。

Conclusion: SiM2P框架通过模拟PET图像，提高了诊断准确性，并使其在资源有限的环境中更易获得，从而可能改善痴呆症的早期检测和鉴别诊断。

Abstract: Positron emission tomography (PET) with 18F-Fluorodeoxyglucose (FDG) is an
established tool in the diagnostic workup of patients with suspected dementing
disorders. However, compared to the routinely available magnetic resonance
imaging (MRI), FDG-PET remains significantly less accessible and substantially
more expensive. Here, we present SiM2P, a 3D diffusion bridge-based framework
that learns a probabilistic mapping from MRI and auxiliary patient information
to simulate FDG-PET images of diagnostic quality. In a blinded clinical reader
study, two neuroradiologists and two nuclear medicine physicians rated the
original MRI and SiM2P-simulated PET images of patients with Alzheimer's
disease, behavioral-variant frontotemporal dementia, and cognitively healthy
controls. SiM2P significantly improved the overall diagnostic accuracy of
differentiating between three groups from 75.0% to 84.7% (p<0.05). Notably, the
simulated PET images received higher diagnostic certainty ratings and achieved
superior interrater agreement compared to the MRI images. Finally, we developed
a practical workflow for local deployment of the SiM2P framework. It requires
as few as 20 site-specific cases and only basic demographic information. This
approach makes the established diagnostic benefits of FDG-PET imaging more
accessible to patients with suspected dementing disorders, potentially
improving early detection and differential diagnosis in resource-limited
settings. Our code is available at https://github.com/Yiiitong/SiM2P.

</details>


### [60] [ClapperText: A Benchmark for Text Recognition in Low-Resource Archival Documents](https://arxiv.org/abs/2510.15557)
*Tingyu Lin,Marco Peer,Florian Kleber,Robert Sablatnig*

Main category: cs.CV

TL;DR: ClapperText是一个包含二战时期视频片段中的手写和印刷文本的基准数据集，旨在解决视觉降级和低资源环境下的文本识别问题。


<details>
  <summary>Details</summary>
Motivation: 识别二战时期带有视觉降级和非标准形式的结构化文本，这与历史文献分析中的普遍挑战相呼应。

Method: 构建了一个包含9,813个标注帧和94,573个单词级文本实例的数据集，其中包含转录、语义类别、文本类型和遮挡状态等信息，并提供标注的旋转边界框。对六种代表性识别模型和七种检测模型进行了零样本和微调条件下的基准测试。

Result: 通过微调，即使在只有18个视频的训练集下，性能也得到了显著提升，证明了ClapperText在少样本学习场景下的适用性。

Conclusion: ClapperText为在低资源档案环境中推进鲁棒的光学字符识别和文档理解提供了真实且具有文化背景的资源。

Abstract: This paper presents ClapperText, a benchmark dataset for handwritten and
printed text recognition in visually degraded and low-resource settings. The
dataset is derived from 127 World War II-era archival video segments containing
clapperboards that record structured production metadata such as date,
location, and camera-operator identity. ClapperText includes 9,813 annotated
frames and 94,573 word-level text instances, 67% of which are handwritten and
1,566 are partially occluded. Each instance includes transcription, semantic
category, text type, and occlusion status, with annotations available as
rotated bounding boxes represented as 4-point polygons to support spatially
precise OCR applications. Recognizing clapperboard text poses significant
challenges, including motion blur, handwriting variation, exposure
fluctuations, and cluttered backgrounds, mirroring broader challenges in
historical document analysis where structured content appears in degraded,
non-standard forms. We provide both full-frame annotations and cropped word
images to support downstream tasks. Using a consistent per-video evaluation
protocol, we benchmark six representative recognition and seven detection
models under zero-shot and fine-tuned conditions. Despite the small training
set (18 videos), fine-tuning leads to substantial performance gains,
highlighting ClapperText's suitability for few-shot learning scenarios. The
dataset offers a realistic and culturally grounded resource for advancing
robust OCR and document understanding in low-resource archival contexts. The
dataset and evaluation code are available at
https://github.com/linty5/ClapperText.

</details>


### [61] [Imaginarium: Vision-guided High-Quality 3D Scene Layout Generation](https://arxiv.org/abs/2510.15564)
*Xiaoming Zhu,Xu Huang,Qinghongbing Xie,Zhi Deng,Junsheng Yu,Yirui Guan,Zhongyuan Liu,Lin Zhu,Qijun Zhao,Ligang Liu,Long Zeng*

Main category: cs.CV

TL;DR: 本研究提出了一种新的视觉引导式3D场景布局生成系统，解决了传统方法在规则约束、深度生成模型多样性不足以及大型语言模型鲁棒性和空间关系捕捉能力方面存在的挑战。


<details>
  <summary>Details</summary>
Motivation: 生成艺术性强、一致性好的3D场景布局在数字内容创作中至关重要，但现有方法存在局限性。

Method: 该系统首先构建了一个包含2037个场景资产和147个3D场景布局的高质量资产库。然后，利用图像生成模型将提示表示转换为图像，并进行微调以匹配资产库。接着，开发了一个鲁棒的图像解析模块，根据视觉语义和几何信息恢复场景的3D布局。最后，通过场景图和整体视觉语义优化布局，确保逻辑一致性并与图像对齐。

Result: 与现有方法相比，该算法在布局丰富度和质量方面表现出显著优势，并且进行了广泛的用户测试。

Conclusion: 本研究提出的视觉引导式3D场景布局生成系统在生成丰富、高质量且逻辑一致的3D场景方面取得了显著进展。

Abstract: Generating artistic and coherent 3D scene layouts is crucial in digital
content creation. Traditional optimization-based methods are often constrained
by cumbersome manual rules, while deep generative models face challenges in
producing content with richness and diversity. Furthermore, approaches that
utilize large language models frequently lack robustness and fail to accurately
capture complex spatial relationships. To address these challenges, this paper
presents a novel vision-guided 3D layout generation system. We first construct
a high-quality asset library containing 2,037 scene assets and 147 3D scene
layouts. Subsequently, we employ an image generation model to expand prompt
representations into images, fine-tuning it to align with our asset library. We
then develop a robust image parsing module to recover the 3D layout of scenes
based on visual semantics and geometric information. Finally, we optimize the
scene layout using scene graphs and overall visual semantics to ensure logical
coherence and alignment with the images. Extensive user testing demonstrates
that our algorithm significantly outperforms existing methods in terms of
layout richness and quality. The code and dataset will be available at
https://github.com/HiHiAllen/Imaginarium.

</details>


### [62] [Unmasking Facial DeepFakes: A Robust Multiview Detection Framework for Natural Images](https://arxiv.org/abs/2510.15576)
*Sami Belguesmia,Mohand Saïd Allili,Assia Hamadene*

Main category: cs.CV

TL;DR: 提出了一种多视图架构，通过在多个层级分析面部特征来增强 DeepFake 检测能力，以解决现有方法在姿势变化、遮挡和伪影等方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的 DeepFake 检测方法在真实世界的条件下，如姿势变化、遮挡和难以检测的伪影，常常表现不佳。本研究旨在通过一种新的多视图架构来解决这些挑战。

Method: 提出了一种多视图架构，集成了三个专门的编码器：一个全局视图编码器用于检测边界不一致性，一个中间视图编码器用于分析纹理和颜色对齐，以及一个局部视图编码器用于捕捉眼睛、鼻子和嘴巴等表情面部区域的失真。此外，还包含一个面部方向编码器，用于分类面部姿势，以确保在各种视角下的鲁棒检测。通过融合这些编码器的特征来提高检测性能。

Result: 在具有挑战性的数据集上的实验结果表明，该方法在姿势和光照条件下的检测效果优于传统的单视图方法。

Conclusion: 所提出的多视图架构通过整合不同层级的面部特征分析和面部方向分类，能够有效地提高 DeepFake 检测的准确性，尤其是在处理复杂场景时，表现出了比传统方法更优越的性能。

Abstract: DeepFake technology has advanced significantly in recent years, enabling the
creation of highly realistic synthetic face images. Existing DeepFake detection
methods often struggle with pose variations, occlusions, and artifacts that are
difficult to detect in real-world conditions. To address these challenges, we
propose a multi-view architecture that enhances DeepFake detection by analyzing
facial features at multiple levels. Our approach integrates three specialized
encoders, a global view encoder for detecting boundary inconsistencies, a
middle view encoder for analyzing texture and color alignment, and a local view
encoder for capturing distortions in expressive facial regions such as the
eyes, nose, and mouth, where DeepFake artifacts frequently occur. Additionally,
we incorporate a face orientation encoder, trained to classify face poses,
ensuring robust detection across various viewing angles. By fusing features
from these encoders, our model achieves superior performance in detecting
manipulated images, even under challenging pose and lighting
conditions.Experimental results on challenging datasets demonstrate the
effectiveness of our method, outperforming conventional single-view approaches

</details>


### [63] [Lightweight CycleGAN Models for Cross-Modality Image Transformation and Experimental Quality Assessment in Fluorescence Microscopy](https://arxiv.org/abs/2510.15579)
*Mohammad Soltaninezhad,Yashar Rouzbahani,Jhonatan Contreras,Rohan Chippalkatti,Daniel Kwaku Abankwa,Christian Eggeling,Thomas Bocklitz*

Main category: cs.CV

TL;DR: 本研究提出了一种轻量级CycleGAN模型，用于荧光显微镜图像的模态转换（共聚焦到STED/去卷积STED），解决了非配对数据集的挑战。通过固定通道方法取代传统的通道加倍策略，模型参数量从4180万大幅减少至约9千，同时实现了更优的性能、更快的训练速度和更低的内存占用。此外，该模型还可以作为诊断工具，通过分析生成图像与新实验图像的差异来识别成像问题，如光漂白、伪影或标签不准确，从而验证实验准确性和图像保真度。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统深度学习模型计算成本高、环境影响大的问题，特别是在科学应用领域，需要开发轻量级的模型。同时，荧光显微镜图像模态转换（如共聚焦到STED）常常面临非配对数据集的挑战。

Method: 提出了一种轻量级CycleGAN模型，用于荧光显微镜图像的模态转换。在生成器中，采用固定的通道数，取代了U-Net中常用的通道加倍策略，从而大幅减少了模型参数量。将GAN作为诊断工具，通过分析生成图像与新实验图像的差异来评估成像质量。

Result: 模型参数量从4180万减少到约9千，实现了优于传统方法的性能，同时训练速度更快，内存占用更低。该模型能够有效地将共聚焦显微镜图像转换为STED/去卷积STED图像，并且可以识别出光漂白、伪影或标签不准确等实验问题。

Conclusion: 该轻量级CycleGAN模型在荧光显微镜图像模态转换方面取得了显著成效，大幅降低了计算成本和资源需求。同时，它作为一个新颖的诊断工具，能够有效评估和验证显微镜实验的准确性和图像质量，为显微镜成像工作流程提供了实用价值。

Abstract: Lightweight deep learning models offer substantial reductions in
computational cost and environmental impact, making them crucial for scientific
applications. We present a lightweight CycleGAN for modality transfer in
fluorescence microscopy (confocal to super-resolution STED/deconvolved STED),
addressing the common challenge of unpaired datasets. By replacing the
traditional channel-doubling strategy in the U-Net-based generator with a fixed
channel approach, we drastically reduce trainable parameters from 41.8 million
to approximately nine thousand, achieving superior performance with faster
training and lower memory usage. We also introduce the GAN as a diagnostic tool
for experimental and labeling quality. When trained on high-quality images, the
GAN learns the characteristics of optimal imaging; deviations between its
generated outputs and new experimental images can reveal issues such as
photobleaching, artifacts, or inaccurate labeling. This establishes the model
as a practical tool for validating experimental accuracy and image fidelity in
microscopy workflows.

</details>


### [64] [Standardization for improved Spatio-Temporal Image Fusion](https://arxiv.org/abs/2510.15589)
*Harkaitz Goyena,Peter M. Atkinson,Unai Pérez-Goya,M. Dolores Ugarte*

Main category: cs.CV

TL;DR: 本文提出并比较了两种图像融合标准化方法：基于传统上采样的方法和一种名为ABSIS的锐化方法，以提高图像融合的准确性。


<details>
  <summary>Details</summary>
Motivation: 为了便于应用时空图像融合（STIF）方法，需要处理不同传感器捕捉的具有匹配空间和光谱分辨率的图像集。

Method: 提出并比较了两种标准化方法：1. 传统上采样；2. ABSIS锐化方法，该方法将高分辨率图像序列的整体特征与特定低分辨率图像的独特属性相结合，生成更接近聚合高分辨率图像结果的图像。

Result: 两种方法都显著提高了非配对时空图像块融合（USTFIP）方法的准确性，其中锐化方法在光谱和空间精度方面分别提高了高达49.46%和78.40%。

Conclusion: ABSIS锐化方法在提高STIF方法的融合精度方面表现优异。

Abstract: Spatio-Temporal Image Fusion (STIF) methods usually require sets of images
with matching spatial and spectral resolutions captured by different sensors.
To facilitate the application of STIF methods, we propose and compare two
different standardization approaches. The first method is based on traditional
upscaling of the fine-resolution images. The second method is a sharpening
approach called Anomaly Based Satellite Image Standardization (ABSIS) that
blends the overall features found in the fine-resolution image series with the
distinctive attributes of a specific coarse-resolution image to produce images
that more closely resemble the outcome of aggregating the fine-resolution
images. Both methods produce a significant increase in accuracy of the Unpaired
Spatio Temporal Fusion of Image Patches (USTFIP) STIF method, with the
sharpening approach increasing the spectral and spatial accuracies of the fused
images by up to 49.46\% and 78.40\%, respectively.

</details>


### [65] [FlexiReID: Adaptive Mixture of Expert for Multi-Modal Person Re-Identification](https://arxiv.org/abs/2510.15595)
*Zhen Sun,Lei Tan,Yunhang Shen,Chengmao Cai,Xing Sun,Pingyang Dai,Liujuan Cao,Rongrong Ji*

Main category: cs.CV

TL;DR: FlexiReID是一个灵活的跨模态行人重识别框架，支持RGB、红外、素描和文本四种模态的任意查询-检索组合，并取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有跨模态行人重识别方法通常只支持有限的跨模态设置，无法处理任意的查询-检索组合，这在实际部署中存在局限性。

Method: FlexiReID框架引入了一个自适应的专家混合（MoE）机制来动态集成不同的模态特征，并设计了一个跨模态查询融合模块来增强多模态特征提取。此外，为了方便评估，作者构建了一个包含所有四种模态的统一数据集CIRS-PEDES。

Result: FlexiReID在提出的CIRS-PEDES数据集和现有数据集上进行了广泛的实验评估，结果表明该方法达到了最先进的性能，并且在复杂场景下具有强大的泛化能力。

Conclusion: FlexiReID通过其灵活的框架、MoE机制和跨模态查询融合模块，有效解决了现有跨模态行人重识别方法的局限性，并在多模态行人重识别任务上取得了显著的成果。

Abstract: Multimodal person re-identification (Re-ID) aims to match pedestrian images
across different modalities. However, most existing methods focus on limited
cross-modal settings and fail to support arbitrary query-retrieval
combinations, hindering practical deployment. We propose FlexiReID, a flexible
framework that supports seven retrieval modes across four modalities: rgb,
infrared, sketches, and text. FlexiReID introduces an adaptive
mixture-of-experts (MoE) mechanism to dynamically integrate diverse modality
features and a cross-modal query fusion module to enhance multimodal feature
extraction. To facilitate comprehensive evaluation, we construct CIRS-PEDES, a
unified dataset extending four popular Re-ID datasets to include all four
modalities. Extensive experiments demonstrate that FlexiReID achieves
state-of-the-art performance and offers strong generalization in complex
scenarios.

</details>


### [66] [Quantized FCA: Efficient Zero-Shot Texture Anomaly Detection](https://arxiv.org/abs/2510.15602)
*Andrei-Timotei Ardelean,Patrick Rückbeil,Tim Weyrich*

Main category: cs.CV

TL;DR: 本论文提出了一种名为QFCA的实时零样本异常纹理检测与定位方法，通过量化特征对应分析（FCA）并结合主成分分析（PCA）进行预处理，在保持高精度的同时实现了10倍的加速，解决了现有方法运行时间长的问题，适用于实时场景如生产线监控。


<details>
  <summary>Details</summary>
Motivation: 现有零样本异常检测方法运行时间长，不适用于装配线监控等现实场景。本研究旨在提出一种实时的方法来检测和定位纹理中的异常区域。

Method: 提出一种名为QFCA的新方法，该方法实现了特征对应分析（FCA）算法的量化版本。通过将块统计比较适应于量化值的直方图，并引入基于主成分分析（PCA）的特征预处理步骤，以提高对复杂纹理的检测精度。

Result: QFCA方法实现了10倍的加速，并且精度损失很小。主成分分析（PCA）的引入提高了在复杂纹理上的检测精度。

Conclusion: QFCA是一种高效且准确的零样本异常纹理检测与定位方法，其显著的运行速度提升和高精度使其在实时应用中具有潜力。

Abstract: Zero-shot anomaly localization is a rising field in computer vision research,
with important progress in recent years. This work focuses on the problem of
detecting and localizing anomalies in textures, where anomalies can be defined
as the regions that deviate from the overall statistics, violating the
stationarity assumption. The main limitation of existing methods is their high
running time, making them impractical for deployment in real-world scenarios,
such as assembly line monitoring. We propose a real-time method, named QFCA,
which implements a quantized version of the feature correspondence analysis
(FCA) algorithm. By carefully adapting the patch statistics comparison to work
on histograms of quantized values, we obtain a 10x speedup with little to no
loss in accuracy. Moreover, we introduce a feature preprocessing step based on
principal component analysis, which enhances the contrast between normal and
anomalous features, improving the detection precision on complex textures. Our
method is thoroughly evaluated against prior art, comparing favorably with
existing methods. Project page:
https://reality.tf.fau.de/pub/ardelean2025quantized.html

</details>


### [67] [Lightweight Data-Free Denoising for Detail-Preserving Biomedical Image Restoration](https://arxiv.org/abs/2510.15611)
*Tomáš Chobola,Julia A. Schnabel,Tingying Peng*

Main category: cs.CV

TL;DR: 本研究提出了一种名为Noise2Detail（N2D）的超轻量级自监督去噪模型，解决了现有技术计算和内存开销大的问题，在保证去噪质量的同时实现了快速推理，尤其适用于生物医学成像领域。


<details>
  <summary>Details</summary>
Motivation: 现有自监督去噪技术存在计算和内存开销大的问题，限制了其在实际应用中的推广，需要在推理速度和重建质量之间进行权衡。本研究旨在解决这一挑战，提出一种超轻量级模型，同时实现快速去噪和高质量图像重建。

Method: 在Noise2Noise训练框架的基础上，提出了一种创新的多阶段去噪流程Noise2Detail（N2D）。该方法在推理时会破坏噪声模式的空间相关性，产生中间的平滑结构，然后直接从带噪输入中恢复细节。

Result: Noise2Detail在性能上超越了现有的无数据集去噪技术，同时计算资源需求仅占一小部分。

Conclusion: Noise2Detail结合了效率、低计算成本和无数据的方法，克服了生物医学成像领域中因稀有和复杂的成像模式而导致缺乏干净训练数据的挑战，并实现了快速推理，是一个有价值的工具。

Abstract: Current self-supervised denoising techniques achieve impressive results, yet
their real-world application is frequently constrained by substantial
computational and memory demands, necessitating a compromise between inference
speed and reconstruction quality. In this paper, we present an
ultra-lightweight model that addresses this challenge, achieving both fast
denoising and high quality image restoration. Built upon the Noise2Noise
training framework-which removes the reliance on clean reference images or
explicit noise modeling-we introduce an innovative multistage denoising
pipeline named Noise2Detail (N2D). During inference, this approach disrupts the
spatial correlations of noise patterns to produce intermediate smooth
structures, which are subsequently refined to recapture fine details directly
from the noisy input. Extensive testing reveals that Noise2Detail surpasses
existing dataset-free techniques in performance, while requiring only a
fraction of the computational resources. This combination of efficiency, low
computational cost, and data-free approach make it a valuable tool for
biomedical imaging, overcoming the challenges of scarce clean training data-due
to rare and complex imaging modalities-while enabling fast inference for
practical use.

</details>


### [68] [Deep Learning Based Domain Adaptation Methods in Remote Sensing: A Comprehensive Survey](https://arxiv.org/abs/2510.15615)
*Shuchang Lyu,Qi Zhao,Zheng Zhou,Meng Li,You Zhou,Dingding Yao,Guangliang Cheng,Huiyu Zhou,Zhenwei Shi*

Main category: cs.CV

TL;DR: 本篇论文全面 survey 了 深度学习在遥感领域域适应方面的最新进展，涵盖了广泛的任务、数据集和方法，并指出了未来的挑战和方向。


<details>
  <summary>Details</summary>
Motivation: 遥感图像在不同地理位置、传感器和环境条件下存在巨大差异，导致模型泛化能力不足。因此，将知识从一个域迁移到另一个域（域适应）对于遥感应用至关重要。深度学习的强大特征提取和跨域迁移能力使其成为解决该问题的有力工具。

Method: 本文提出了一种系统的遥感领域自适应方法分类方法，并从任务类别、输入模式、监督范式和算法粒度等多个角度对现有算法进行了组织和回顾。此外，还对常用的数据集和最先进方法的性能进行了总结。

Result: 本文对遥感领域自适应研究的现状进行了全面的概述，总结了现有方法的性能，并为该领域提供了结构化的理解。

Conclusion: 本 survey 旨在通过提供全面的知识、系统的分类和对当前挑战的见解，激发研究界的研究，促进理解，并指导遥感领域自适应的未来工作。

Abstract: Domain adaptation is a crucial and increasingly important task in remote
sensing, aiming to transfer knowledge from a source domain a differently
distributed target domain. It has broad applications across various real-world
applications, including remote sensing element interpretation, ecological
environment monitoring, and urban/rural planning. However, domain adaptation in
remote sensing poses significant challenges due to differences in data, such as
variations in ground sampling distance, imaging modes from various sensors,
geographical landscapes, and environmental conditions. In recent years, deep
learning has emerged as a powerful tool for feature representation and
cross-domain knowledge transfer, leading to widespread adoption in remote
sensing tasks. In this paper, we present a comprehensive survey of significant
advancements in deep learning based domain adaptation for remote sensing. We
first introduce the preliminary knowledge to clarify key concepts, mathematical
notations, and the taxonomy of methodologies. We then organize existing
algorithms from multiple perspectives, including task categorization, input
mode, supervision paradigm, and algorithmic granularity, providing readers with
a structured understanding of the field. Next, we review widely used datasets
and summarize the performance of state-of-the-art methods to provide an
overview of current progress. We also identify open challenges and potential
directions to guide future research in domain adaptation for remote sensing.
Compared to previous surveys, this work addresses a broader range of domain
adaptation tasks in remote sensing, rather than concentrating on a few
subfields. It also presents a systematic taxonomy, providing a more
comprehensive and organized understanding of the field. As a whole, this survey
can inspire the research community, foster understanding, and guide future work
in the field.

</details>


### [69] [Uncertainty-Aware Extreme Point Tracing for Weakly Supervised Ultrasound Image Segmentation](https://arxiv.org/abs/2510.15666)
*Lei Shi,Gang Li,Junxing Zhang*

Main category: cs.CV

TL;DR: 该研究提出了一种利用四个极端点作为标签的弱监督医学图像分割框架，能达到与全监督方法相当的性能，同时大大降低了标注成本。


<details>
  <summary>Details</summary>
Motivation: 全监督医学图像分割需要耗费大量时间和成本进行像素级标注，因此提出弱监督方法以降低标注负担。

Method: 利用极端点生成边界框，提示SAM2模型生成初始伪标签，并通过增强的FGEPM算法进行优化，该算法结合了基于蒙特卡洛dropout的不确定性估计来构建梯度不确定性代价图谱进行边界追踪。此外，还引入了双分支不确定性感知尺度一致性（USC）损失和边界框对齐损失来保证训练过程中的空间一致性和精确边界对齐。

Result: 在BUSI和UNS两个公共超声数据集上进行的大量实验表明，该方法取得了与全监督方法相当甚至更优的性能，同时显著降低了标注成本。

Conclusion: 所提出的弱监督框架在超声图像分割方面是有效且实用的。

Abstract: Automatic medical image segmentation is a fundamental step in computer-aided
diagnosis, yet fully supervised approaches demand extensive pixel-level
annotations that are costly and time-consuming. To alleviate this burden, we
propose a weakly supervised segmentation framework that leverages only four
extreme points as annotation. Specifically, bounding boxes derived from the
extreme points are used as prompts for the Segment Anything Model 2 (SAM2) to
generate reliable initial pseudo labels. These pseudo labels are progressively
refined by an enhanced Feature-Guided Extreme Point Masking (FGEPM) algorithm,
which incorporates Monte Carlo dropout-based uncertainty estimation to
construct a unified gradient uncertainty cost map for boundary tracing.
Furthermore, a dual-branch Uncertainty-aware Scale Consistency (USC) loss and a
box alignment loss are introduced to ensure spatial consistency and precise
boundary alignment during training. Extensive experiments on two public
ultrasound datasets, BUSI and UNS, demonstrate that our method achieves
performance comparable to, and even surpassing fully supervised counterparts
while significantly reducing annotation cost. These results validate the
effectiveness and practicality of the proposed weakly supervised framework for
ultrasound image segmentation.

</details>


### [70] [Valeo Near-Field: a novel dataset for pedestrian intent detection](https://arxiv.org/abs/2510.15673)
*Antonyo Musabini,Rachid Benmokhtar,Jagdish Bhanushali,Victor Galizzi,Bertrand Luvison,Xavier Perrotton*

Main category: cs.CV

TL;DR: 本文提出了一个用于检测行人意图的新数据集，包含多模态数据（鱼眼相机、激光雷达、超声波传感器、运动捕捉），并提供标注的3D人体姿态和行人位置，用于评估感知算法。发布部分数据集和基准测试套件，包含准确性、效率和可扩展性指标，并提供基线性能。旨在推动智能车辆近场感知能力的发展。


<details>
  <summary>Details</summary>
Motivation: 检测行人意图对于提高智能车辆在近场场景下的安全性至关重要，但现有数据集在真实世界场景的覆盖、数据模态的丰富性以及标注的精度和同步性方面存在不足。

Method: 收集了包含鱼眼相机、激光雷达、超声波传感器和运动捕捉数据的多模态数据集，并对3D人体关节位置和行人3D位置进行了精确标注和同步。构建了包含评估指标的基准测试套件，并在自定义神经网络上进行了基线性能评估。

Result: 发布了一个包含多模态数据和详细标注的新数据集，以及一套用于评估感知算法的基准测试套件。通过在自定义神经网络上进行评估，获得了基线性能指标，并指出了未来研究方向。

Conclusion: 所提出的新数据集为研究人员提供了一个独特的资源，能够推动行人检测、3D姿态估计和4D轨迹及意图预测等领域的研究，尤其是在智能车辆近场场景下，有助于提升其安全性和智能性。

Abstract: This paper presents a novel dataset aimed at detecting pedestrians'
intentions as they approach an ego-vehicle. The dataset comprises synchronized
multi-modal data, including fisheye camera feeds, lidar laser scans, ultrasonic
sensor readings, and motion capture-based 3D body poses, collected across
diverse real-world scenarios. Key contributions include detailed annotations of
3D body joint positions synchronized with fisheye camera images, as well as
accurate 3D pedestrian positions extracted from lidar data, facilitating robust
benchmarking for perception algorithms. We release a portion of the dataset
along with a comprehensive benchmark suite, featuring evaluation metrics for
accuracy, efficiency, and scalability on embedded systems. By addressing
real-world challenges such as sensor occlusions, dynamic environments, and
hardware constraints, this dataset offers a unique resource for developing and
evaluating state-of-the-art algorithms in pedestrian detection, 3D pose
estimation and 4D trajectory and intention prediction. Additionally, we provide
baseline performance metrics using custom neural network architectures and
suggest future research directions to encourage the adoption and enhancement of
the dataset. This work aims to serve as a foundation for researchers seeking to
advance the capabilities of intelligent vehicles in near-field scenarios.

</details>


### [71] [Towards Label-Free Brain Tumor Segmentation: Unsupervised Learning with Multimodal MRI](https://arxiv.org/abs/2510.15684)
*Gerard Comas-Quiles,Carles Garcia-Cabrera,Julia Dietlmeier,Noel E. O'Connor,Ferran Marques*

Main category: cs.CV

TL;DR: 本研究提出了一种新颖的无监督多模态视觉Transformer自编码器（MViT-AE），利用重建误差图来检测和定位脑部MRI肿瘤，无需手动标注，提高了可扩展性。


<details>
  <summary>Details</summary>
Motivation: 在神经影像学中，当标注数据集有限、成本高昂或不一致时，无监督异常检测（UAD）为脑肿瘤分割提供了一种有力的监督学习替代方案。

Method: 提出了一种新颖的无监督多模态视觉Transformer自编码器（MViT-AE），仅在健康脑MRI上进行训练，利用重建误差图进行肿瘤检测和定位。引入了多模态早晚融合策略以利用多模态MRI序列的互补信息，并整合了Segment Anything Model（SAM）进行后处理以优化肿瘤轮廓。

Result: 在BraTS-GoAT 2025 Lighthouse数据集上评估，该方法实现了临床上可行的肿瘤定位，在测试集上实现了0.437（全肿瘤）、0.316（肿瘤核心）和0.350（增强肿瘤）的分割相似系数（DSC），并在验证集上实现了89.4%的异常检测率。

Conclusion: 基于Transformer的无监督模型在神经肿瘤学成像领域具有作为可扩展、标签效率高工具的潜力，能够克服手动标注的瓶颈。

Abstract: Unsupervised anomaly detection (UAD) presents a complementary alternative to
supervised learning for brain tumor segmentation in magnetic resonance imaging
(MRI), particularly when annotated datasets are limited, costly, or
inconsistent. In this work, we propose a novel Multimodal Vision Transformer
Autoencoder (MViT-AE) trained exclusively on healthy brain MRIs to detect and
localize tumors via reconstruction-based error maps. This unsupervised paradigm
enables segmentation without reliance on manual labels, addressing a key
scalability bottleneck in neuroimaging workflows. Our method is evaluated in
the BraTS-GoAT 2025 Lighthouse dataset, which includes various types of tumors
such as gliomas, meningiomas, and pediatric brain tumors. To enhance
performance, we introduce a multimodal early-late fusion strategy that
leverages complementary information across multiple MRI sequences, and a
post-processing pipeline that integrates the Segment Anything Model (SAM) to
refine predicted tumor contours. Despite the known challenges of UAD,
particularly in detecting small or non-enhancing lesions, our method achieves
clinically meaningful tumor localization, with lesion-wise Dice Similarity
Coefficient of 0.437 (Whole Tumor), 0.316 (Tumor Core), and 0.350 (Enhancing
Tumor) on the test set, and an anomaly Detection Rate of 89.4% on the
validation set. These findings highlight the potential of transformer-based
unsupervised models to serve as scalable, label-efficient tools for
neuro-oncological imaging.

</details>


### [72] [Unimedvl: Unifying Medical Multimodal Understanding And Generation Through Observation-Knowledge-Analysis](https://arxiv.org/abs/2510.15710)
*Junzhi Ning,Wei Li,Cheng Tang,Jiashi Lin,Chenglong Ma,Chaoyang Zhang,Jiyao Liu,Ying Chen,Shujian Gao,Lihao Liu,Yuandong Pu,Huihui Xu,Chenhui Gou,Ziyan Huang,Yi Xin,Qi Qin,Zhongying Deng,Diping Song,Bin Fu,Guang Yang,Yuanfeng Ji,Tianbin Li,Yanzhou Su,Jin Ye,Shixiang Tang,Ming Hu,Junjun He*

Main category: cs.CV

TL;DR: 现有的医疗AI系统在处理多模态医疗输入（图像、病史、实验室结果）并生成文本报告和视觉内容方面存在局限性。本研究提出了一个名为UniMedVL的多模态框架，该框架基于OKA（Observation-Knowledge-Analysis）范式，并构建了UniMed-5M数据集，采用了渐进式课程学习方法，实现了医疗图像理解和生成任务的统一。UniMedVL在五个医学图像理解基准测试中表现优越，在八种医学成像模态的生成质量上可与专用模型相媲美，并实现了双向知识共享，提高了整体性能。


<details>
  <summary>Details</summary>
Motivation: 现有医疗AI系统在处理多模态医疗输入并生成文本和视觉内容方面存在不足，导致数据表示、特征整合和任务级多模态能力存在差距。

Method: 提出一个多层次框架，借鉴了OK A（Observation-Knowledge-Analysis）范式。在观察层面，构建了包含超过560万个样本的UniMed-5M数据集。在知识层面，提出了渐进式课程学习。在分析层面，提出了UniMedVL，一个统一的多模态模型，用于单一架构内的图像理解和生成任务。

Result: UniMedVL在五个医学图像理解基准测试中取得了优越的性能，并在八种医学成像模态的生成质量上达到了与专用模型相媲美的水平。该统一架构实现了双向知识共享，生成任务提升了视觉理解特征。

Conclusion: 将传统上分离的医学图像理解和生成能力整合到单一框架内，可以实现跨多种医学视觉-语言任务的性能提升。

Abstract: Medical diagnostic applications require models that can process multimodal
medical inputs (images, patient histories, lab results) and generate diverse
outputs including both textual reports and visual content (annotations,
segmentation masks, and images). Despite this need, existing medical AI systems
disrupt this unified process: medical image understanding models interpret
images but cannot generate visual outputs, while medical image generation
models synthesize images but cannot provide textual explanations. This leads to
gaps in data representation, feature integration, and task-level multimodal
capabilities. To this end, we propose a multi-level framework that draws
inspiration from diagnostic workflows through the
Observation-Knowledge-Analysis (OKA) paradigm. Specifically, at the observation
level, we construct UniMed-5M, a dataset comprising over 5.6M samples that
reformat diverse unimodal data into multimodal pairs for foundational
observation. At the knowledge level, we propose Progressive Curriculum Learning
that systematically introduces medical multimodal knowledge. At the analysis
level, we introduce UniMedVL, the first medical unified multimodal model for
the simultaneous analysis of image understanding and generation tasks within a
single architecture. UniMedVL achieves superior performance on five medical
image understanding benchmarks, while matching specialized models in generation
quality across eight medical imaging modalities. Crucially, our unified
architecture enables bidirectional knowledge sharing: generation tasks enhance
visual understanding features, demonstrating that integrating traditionally
separate capabilities within a single medical framework unlocks improvements
across diverse medical vision-language tasks. Code is available at
https://github.com/uni-medical/UniMedVL.

</details>


### [73] [OmniVinci: Enhancing Architecture and Data for Omni-Modal Understanding LLM](https://arxiv.org/abs/2510.15870)
*Hanrong Ye,Chao-Han Huck Yang,Arushi Goel,Wei Huang,Ligeng Zhu,Yuanhang Su,Sean Lin,An-Chieh Cheng,Zhen Wan,Jinchuan Tian,Yuming Lou,Dong Yang,Zhijian Liu,Yukang Chen,Ambrish Dantrey,Ehsan Jahangiri,Sreyan Ghosh,Daguang Xu,Ehsan Hosseini-Asl,Danial Mohseni Taheri,Vidya Murali,Sifei Liu,Jason Lu,Oluwatobi Olabiyi,Frank Wang,Rafael Valle,Bryan Catanzaro,Andrew Tao,Song Han,Jan Kautz,Hongxu Yin,Pavlo Molchanov*

Main category: cs.CV

TL;DR: 提出OmniVinci，一个开源的全模态大模型，旨在融合视觉、听觉和文本信息，并在多模态理解、听觉和视觉任务上取得显著进步，同时大幅减少训练数据量。


<details>
  <summary>Details</summary>
Motivation: 为了推进机器智能的发展，需要让机器具备像人类一样感知世界的多模态能力。

Method: 提出OmniVinci模型，包含三个关键创新：OmniAlignNet（加强视觉和听觉嵌入的对齐）、Temporal Embedding Grouping（捕捉视听信号的相对时间对齐）和Constrained Rotary Time Embedding（编码全模态嵌入的绝对时间信息）。同时，构建了一个包含24M单模态和全模态对话的数据集。

Result: OmniVinci在DailyOmni（跨模态理解）、MMAR（听觉）和Video-MME（视觉）基准测试中分别超越Qwen2.5-Omni +19.05、+1.7和+3.9，并且训练数据量减少了6倍。所提出的方法在机器人、医疗AI和智能工厂等下游应用中展示了全模态的优势。

Conclusion: 多模态信息在感知和推理方面能够相互促进，OmniVinci展示了其在整合多模态信息方面的优越性，并能显著提高模型性能，同时降低训练成本。

Abstract: Advancing machine intelligence requires developing the ability to perceive
across multiple modalities, much as humans sense the world. We introduce
OmniVinci, an initiative to build a strong, open-source, omni-modal LLM. We
carefully study the design choices across model architecture and data curation.
For model architecture, we present three key innovations: (i) OmniAlignNet for
strengthening alignment between vision and audio embeddings in a shared
omni-modal latent space; (ii) Temporal Embedding Grouping for capturing
relative temporal alignment between vision and audio signals; and (iii)
Constrained Rotary Time Embedding for encoding absolute temporal information in
omni-modal embeddings. We introduce a curation and synthesis pipeline that
generates 24M single-modal and omni-modal conversations. We find that
modalities reinforce one another in both perception and reasoning. Our model,
OmniVinci, outperforms Qwen2.5-Omni with +19.05 on DailyOmni (cross-modal
understanding), +1.7 on MMAR (audio), and +3.9 on Video-MME (vision), while
using just 0.2T training tokens - a 6 times reduction compared to
Qwen2.5-Omni's 1.2T. We finally demonstrate omni-modal advantages in downstream
applications spanning robotics, medical AI, and smart factory.

</details>


### [74] [DGME-T: Directional Grid Motion Encoding for Transformer-Based Historical Camera Movement Classification](https://arxiv.org/abs/2510.15725)
*Tingyu Lin,Armin Dadras,Florian Kleber,Robert Sablatnig*

Main category: cs.CV

TL;DR: 本文提出了DGME-T模型，通过引入方向网格运动编码来提升摄像机运动分类在历史影像上的表现。


<details>
  <summary>Details</summary>
Motivation: 现代摄像机运动分类模型在处理老旧、低质量的历史影像时性能下降，需要弥合这一差距。

Method: 构建了一个包含两个现代语料库和四个类别，并重构了HISTORIAN数据集的基准。提出了DGME-T模型，通过一个学习和归一化的 late-fusion 层，将源自光流的方向网格运动编码注入到Video Swin Transformer中。

Result: DGME-T模型在现代片段上将top-1准确率从81.78%提高到86.14%，宏观F1分数从82.08%提高到87.81%。在二战影像上，准确率从83.43%提高到84.62%，宏观F1分数从81.72%提高到82.63%。中间的微调阶段将历史表现提高了超过5个百分点。

Conclusion: 结构化的运动先验和Transformer表示是互补的，即使是一个小的、经过校准的运动模块也能显著提高在低质量影像分析中的鲁棒性。

Abstract: Camera movement classification (CMC) models trained on contemporary,
high-quality footage often degrade when applied to archival film, where noise,
missing frames, and low contrast obscure motion cues. We bridge this gap by
assembling a unified benchmark that consolidates two modern corpora into four
canonical classes and restructures the HISTORIAN collection into five balanced
categories. Building on this benchmark, we introduce DGME-T, a lightweight
extension to the Video Swin Transformer that injects directional grid motion
encoding, derived from optical flow, via a learnable and normalised late-fusion
layer. DGME-T raises the backbone's top-1 accuracy from 81.78% to 86.14% and
its macro F1 from 82.08% to 87.81% on modern clips, while still improving the
demanding World-War-II footage from 83.43% to 84.62% accuracy and from 81.72%
to 82.63% macro F1. A cross-domain study further shows that an intermediate
fine-tuning stage on modern data increases historical performance by more than
five percentage points. These results demonstrate that structured motion priors
and transformer representations are complementary and that even a small,
carefully calibrated motion head can substantially enhance robustness in
degraded film analysis. Related resources are available at
https://github.com/linty5/DGME-T.

</details>


### [75] [Scaling Instruction-Based Video Editing with a High-Quality Synthetic Dataset](https://arxiv.org/abs/2510.15742)
*Qingyan Bai,Qiuyu Wang,Hao Ouyang,Yue Yu,Hanlin Wang,Wen Wang,Ka Leong Cheng,Shuailei Ma,Yanhong Zeng,Zichen Liu,Yinghao Xu,Yujun Shen,Qifeng Chen*

Main category: cs.CV

TL;DR: Ditto是一个用于指令驱动视频编辑的框架，通过新颖的数据生成、高效的模型架构和智能代理，解决了训练数据稀缺和计算成本高的问题，并创建了一个包含一百万个视频编辑示例的大型数据集 Ditto-1M，在指令遵循和视频编辑方面取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 当前指令驱动视频编辑领域面临大规模、高质量训练数据稀缺的挑战，阻碍了其发展。

Method: Ditto框架包含一个新颖的数据生成流程，结合了图像编辑器的创意多样性和视频生成器，并采用高效的蒸馏模型架构和时间增强器来降低成本和提高时间连贯性。此外，一个智能代理负责生成多样化指令和过滤输出，以实现大规模的可扩展性。

Result: 使用Ditto框架，研究者们构建了一个包含一百万个高质量视频编辑示例的数据集Ditto-1M，并在该数据集上使用课程学习策略训练了名为Editto的模型，该模型在指令遵循能力和视频编辑方面取得了最先进的性能。

Conclusion: Ditto框架通过其创新的数据生成、模型架构和智能代理，成功解决了指令驱动视频编辑中的数据稀缺和成本问题，并构建了一个大规模数据集，显著提高了模型的性能，达到了新的最先进水平。

Abstract: Instruction-based video editing promises to democratize content creation, yet
its progress is severely hampered by the scarcity of large-scale, high-quality
training data. We introduce Ditto, a holistic framework designed to tackle this
fundamental challenge. At its heart, Ditto features a novel data generation
pipeline that fuses the creative diversity of a leading image editor with an
in-context video generator, overcoming the limited scope of existing models. To
make this process viable, our framework resolves the prohibitive cost-quality
trade-off by employing an efficient, distilled model architecture augmented by
a temporal enhancer, which simultaneously reduces computational overhead and
improves temporal coherence. Finally, to achieve full scalability, this entire
pipeline is driven by an intelligent agent that crafts diverse instructions and
rigorously filters the output, ensuring quality control at scale. Using this
framework, we invested over 12,000 GPU-days to build Ditto-1M, a new dataset of
one million high-fidelity video editing examples. We trained our model, Editto,
on Ditto-1M with a curriculum learning strategy. The results demonstrate
superior instruction-following ability and establish a new state-of-the-art in
instruction-based video editing.

</details>


### [76] [SEGA: A Stepwise Evolution Paradigm for Content-Aware Layout Generation with Design Prior](https://arxiv.org/abs/2510.15749)
*Haoran Wang,Bo Zhao,Jinghui Wang,Hanzhang Wang,Huan Yang,Wei Ji,Hao Liu,Xinyan Xiao*

Main category: cs.CV

TL;DR: SEGA是一个新颖的、用于内容感知布局生成的逐步演进范例，通过分层推理和粗粒度到细粒度的策略来解决复杂布局规划问题，并取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理复杂元素布局规划时，由于缺乏基于反馈的自我修正机制，失败率很高。本研究旨在解决内容感知布局生成问题，自动生成与给定背景图像协调的布局。

Method: SEGA采用分层推理框架和粗粒度到细粒度的策略。首先，粗粒度模块进行大致的布局规划，然后，细粒度模块对粗粒度规划进行精细推理。此外，该模型还融入了版式设计原则作为先验知识。并提出了包含丰富元信息注释的新型大规模海报数据集GenPoster-100K。

Result: 实验证明了该方法在多个基准数据集上的有效性，取得了最先进的成果。

Conclusion: SEGA通过其逐步演进的范例和结合设计原则的策略，有效地解决了内容感知布局生成中的复杂性问题，并在多个基准数据集上取得了优于现有方法的性能。

Abstract: In this paper, we study the content-aware layout generation problem, which
aims to automatically generate layouts that are harmonious with a given
background image. Existing methods usually deal with this task with a
single-step reasoning framework. The lack of a feedback-based self-correction
mechanism leads to their failure rates significantly increasing when faced with
complex element layout planning. To address this challenge, we introduce SEGA,
a novel Stepwise Evolution Paradigm for Content-Aware Layout Generation.
Inspired by the systematic mode of human thinking, SEGA employs a hierarchical
reasoning framework with a coarse-to-fine strategy: first, a coarse-level
module roughly estimates the layout planning results; then, another refining
module performs fine-level reasoning regarding the coarse planning results.
Furthermore, we incorporate layout design principles as prior knowledge into
the model to enhance its layout planning ability. Besides, we present
GenPoster-100K that is a new large-scale poster dataset with rich
meta-information annotation. The experiments demonstrate the effectiveness of
our approach by achieving the state-of-the-art results on multiple benchmark
datasets. Our project page is at: https://brucew91.github.io/SEGA.github.io/

</details>


### [77] [NDM: A Noise-driven Detection and Mitigation Framework against Implicit Sexual Intentions in Text-to-Image Generation](https://arxiv.org/abs/2510.15752)
*Yitong Sun,Yao Huang,Ruochen Zhang,Huanran Chen,Shouwei Ruan,Ranjie Duan,Xingxing Wei*

Main category: cs.CV

TL;DR: 该研究提出了NDM，一个首创的噪声驱动的检测和缓解框架，用于在文本到图像生成中检测和缓解隐晦的性暗示内容，同时保持模型原有的生成能力。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像模型容易生成不当内容，特别是对于隐晦的性暗示提示，而现有检测方法难以识别这些隐晦提示，并且微调方法可能会损害模型的生成质量。

Method: 提出了一种基于噪声的检测方法，利用早期预测噪声的可分离性来识别恶意内容；提出了一种噪声增强的自适应负面引导机制，通过抑制显著区域的注意力来优化初始噪声，从而增强自适应负面引导在性内容缓解方面的效果。

Result: NDM在自然和对抗性数据集上均表现出优越的性能，超越了SLD、UCE和RECE等现有方法。

Conclusion: NDM是第一个能够检测和缓解文本到图像生成中隐晦性暗示问题的框架，同时保持了模型的生成能力。

Abstract: Despite the impressive generative capabilities of text-to-image (T2I)
diffusion models, they remain vulnerable to generating inappropriate content,
especially when confronted with implicit sexual prompts. Unlike explicit
harmful prompts, these subtle cues, often disguised as seemingly benign terms,
can unexpectedly trigger sexual content due to underlying model biases, raising
significant ethical concerns. However, existing detection methods are primarily
designed to identify explicit sexual content and therefore struggle to detect
these implicit cues. Fine-tuning approaches, while effective to some extent,
risk degrading the model's generative quality, creating an undesirable
trade-off. To address this, we propose NDM, the first noise-driven detection
and mitigation framework, which could detect and mitigate implicit malicious
intention in T2I generation while preserving the model's original generative
capabilities. Specifically, we introduce two key innovations: first, we
leverage the separability of early-stage predicted noise to develop a
noise-based detection method that could identify malicious content with high
accuracy and efficiency; second, we propose a noise-enhanced adaptive negative
guidance mechanism that could optimize the initial noise by suppressing the
prominent region's attention, thereby enhancing the effectiveness of adaptive
negative guidance for sexual mitigation. Experimentally, we validate NDM on
both natural and adversarial datasets, demonstrating its superior performance
over existing SOTA methods, including SLD, UCE, and RECE, etc. Code and
resources are available at https://github.com/lorraine021/NDM.

</details>


### [78] [Semantic segmentation with coarse annotations](https://arxiv.org/abs/2510.15756)
*Jort de Jong,Mike Holenderski*

Main category: cs.CV

TL;DR: 本文提出了一种使用粗粒度标注进行语义分割的正则化方法，通过鼓励分割像素形成SLIC超像素来提高边界对齐精度，并在多个数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 获取精细的像素级标注成本高昂，而粗粒度标注（部分像素未标注）是可行的替代方案，但其在优化类别边界对齐方面存在挑战。

Method: 提出了一种基于编码器-解码器架构和超像素上采样的正则化方法，鼓励模型生成的分割像素形成SLIC超像素，该方法独立于分割标注，并应用于FCN-16网络架构。

Result: 与现有技术相比，在粗粒度标注下，边界召回率得到了显著提高。

Conclusion: 所提出的正则化方法能够有效地提升在粗粒度标注下的语义分割模型的边界对齐精度。

Abstract: Semantic segmentation is the task of classifying each pixel in an image.
Training a segmentation model achieves best results using annotated images,
where each pixel is annotated with the corresponding class. When obtaining fine
annotations is difficult or expensive, it may be possible to acquire coarse
annotations, e.g. by roughly annotating pixels in an images leaving some pixels
around the boundaries between classes unlabeled. Segmentation with coarse
annotations is difficult, in particular when the objective is to optimize the
alignment of boundaries between classes. This paper proposes a regularization
method for models with an encoder-decoder architecture with superpixel based
upsampling. It encourages the segmented pixels in the decoded image to be
SLIC-superpixels, which are based on pixel color and position, independent of
the segmentation annotation. The method is applied to FCN-16 fully
convolutional network architecture and evaluated on the SUIM, Cityscapes, and
PanNuke data sets. It is shown that the boundary recall improves significantly
compared to state-of-the-art models when trained on coarse annotations.

</details>


### [79] [QSilk: Micrograin Stabilization and Adaptive Quantile Clipping for Detail-Friendly Latent Diffusion](https://arxiv.org/abs/2510.15761)
*Denis Rychkovskiy*

Main category: cs.CV

TL;DR: QSilk is a lightweight stabilization layer for latent diffusion models that enhances high-frequency details and reduces extreme activation spikes without requiring training.


<details>
  <summary>Details</summary>
Motivation: The paper aims to improve high-frequency fidelity and suppress rare activation spikes in latent diffusion models.

Method: QSilk employs a per-sample micro clamp to limit extreme values while preserving texture, and Adaptive Quantile Clip (AQClip) which dynamically adjusts value corridors per region. AQClip can use local structure statistics or attention entropy for guidance.

Result: When integrated into the CADE 2.5 rendering pipeline, QSilk produces cleaner, sharper images at low step counts and high resolutions with minimal overhead. It shows consistent qualitative improvements across SD/SDXL backbones and synergizes with CFG/Rescale, allowing for higher guidance without artifacts.

Conclusion: QSilk is an effective, training-free stabilization layer for latent diffusion that enhances image quality and stability with minimal user control and computational overhead.

Abstract: We present QSilk, a lightweight, always-on stabilization layer for latent
diffusion that improves high-frequency fidelity while suppressing rare
activation spikes. QSilk combines (i) a per-sample micro clamp that gently
limits extreme values without washing out texture, and (ii) Adaptive Quantile
Clip (AQClip), which adapts the allowed value corridor per region. AQClip can
operate in a proxy mode using local structure statistics or in an attention
entropy guided mode (model confidence). Integrated into the CADE 2.5 rendering
pipeline, QSilk yields cleaner, sharper results at low step counts and
ultra-high resolutions with negligible overhead. It requires no training or
fine-tuning and exposes minimal user controls. We report consistent qualitative
improvements across SD/SDXL backbones and show synergy with CFG/Rescale,
enabling slightly higher guidance without artifacts.

</details>


### [80] [Towards more holistic interpretability: A lightweight disentangled Concept Bottleneck Model](https://arxiv.org/abs/2510.15770)
*Gaoxiang Huang,Songning Lai,Yutao Yue*

Main category: cs.CV

TL;DR: LDCBM通过将视觉特征解耦为有意义的组件，提高了概念和类别的准确性，从而克服了现有CBM的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有概念瓶颈模型（CBM）存在输入到概念的映射偏差和可控性有限的问题，限制了其在实际应用中的价值和基于概念的方法的可靠性。

Method: 提出了一种轻量级的解耦概念瓶颈模型（LDCBM），通过引入滤波器分组损失和联合概念监督，自动将视觉特征分组为有意义的组件，而无需区域注释。

Result: LDCBM在三个不同的数据集上进行了实验，结果表明其概念和类别的准确性更高，在可解释性和分类性能上均优于以前的CBM。

Conclusion: LDCBM通过将概念与视觉证据相结合，克服了先前模型的基本限制，提高了可解释人工智能的可靠性。

Abstract: Concept Bottleneck Models (CBMs) enhance interpretability by predicting
human-understandable concepts as intermediate representations. However,
existing CBMs often suffer from input-to-concept mapping bias and limited
controllability, which restricts their practical value, directly damage the
responsibility of strategy from concept-based methods. We propose a lightweight
Disentangled Concept Bottleneck Model (LDCBM) that automatically groups visual
features into semantically meaningful components without region annotation. By
introducing a filter grouping loss and joint concept supervision, our method
improves the alignment between visual patterns and concepts, enabling more
transparent and robust decision-making. Notably, Experiments on three diverse
datasets demonstrate that LDCBM achieves higher concept and class accuracy,
outperforming previous CBMs in both interpretability and classification
performance. By grounding concepts in visual evidence, our method overcomes a
fundamental limitation of prior models and enhances the reliability of
interpretable AI.

</details>


### [81] [Controlling the image generation process with parametric activation functions](https://arxiv.org/abs/2510.15778)
*Ilia Pavlov*

Main category: cs.CV

TL;DR: 该研究提出了一种通过交互和实验来理解图像生成模型的新方法，允许用户替换和调整模型内的激活函数参数来控制网络输出，并已在StyleGAN2和BigGAN上进行了演示。


<details>
  <summary>Details</summary>
Motivation: 现有的图像生成模型在保真度和普及度上不断提高，但能够以可解释的方式与其内部机制进行交互的工具却很少受到关注。

Method: 通过允许用户将生成网络中的激活函数替换为参数化函数，并设置这些函数的参数，来提供一种控制网络输出的新方法。

Result: 在StyleGAN2和BigGAN网络上进行了方法演示，这些网络分别在FFHQ和ImageNet数据集上进行了训练。

Conclusion: 所提出的交互式系统能够帮助用户更好地理解图像生成模型。

Abstract: As image generative models continue to increase not only in their fidelity
but also in their ubiquity the development of tools that leverage direct
interaction with their internal mechanisms in an interpretable way has received
little attention In this work we introduce a system that allows users to
develop a better understanding of the model through interaction and
experimentation By giving users the ability to replace activation functions of
a generative network with parametric ones and a way to set the parameters of
these functions we introduce an alternative approach to control the networks
output We demonstrate the use of our method on StyleGAN2 and BigGAN networks
trained on FFHQ and ImageNet respectively.

</details>


### [82] [ReCon: Region-Controllable Data Augmentation with Rectification and Alignment for Object Detection](https://arxiv.org/abs/2510.15783)
*Haowei Zhu,Tianxiang Pan,Rui Qin,Jun-Hai Yong,Bin Wang*

Main category: cs.CV

TL;DR: ReCon是一个新颖的增强框架，通过在扩散采样过程中集成区域引导校正，利用预训练感知模型的反馈来校正错误生成的区域，并提出区域对齐交叉注意力来强制空间-语义对齐，从而提高了生成数据的质量和可训练性，并带来了跨数据集、骨干架构和数据规模的一致性能提升。


<details>
  <summary>Details</summary>
Motivation: 生成模型在数据增强方面具有潜力，但现有方法在实现令人满意的结果方面存在复杂后处理、大量微调、内容-位置不匹配和语义泄露等问题。因此，需要一种能够克服这些限制的增强框架。

Method: ReCon通过在扩散采样过程中集成区域引导校正，并利用预训练感知模型的反馈来校正错误生成的区域。此外，还提出了区域对齐交叉注意力，以强制对齐图像区域和其文本线索，以提高语义一致性和图像保真度。

Result: 实验表明，ReCon显著提高了生成数据的质量和可训练性，在不同的数据集、骨干架构和数据规模上都取得了持续的性能提升。

Conclusion: ReCon框架成功地克服了现有生成方法的局限性，提高了生成数据的质量和可训练性，为物体检测任务带来了性能提升。

Abstract: The scale and quality of datasets are crucial for training robust perception
models. However, obtaining large-scale annotated data is both costly and
time-consuming. Generative models have emerged as a powerful tool for data
augmentation by synthesizing samples that adhere to desired distributions.
However, current generative approaches often rely on complex post-processing or
extensive fine-tuning on massive datasets to achieve satisfactory results, and
they remain prone to content-position mismatches and semantic leakage. To
overcome these limitations, we introduce ReCon, a novel augmentation framework
that enhances the capacity of structure-controllable generative models for
object detection. ReCon integrates region-guided rectification into the
diffusion sampling process, using feedback from a pre-trained perception model
to rectify misgenerated regions within diffusion sampling process. We further
propose region-aligned cross-attention to enforce spatial-semantic alignment
between image regions and their textual cues, thereby improving both semantic
consistency and overall image fidelity. Extensive experiments demonstrate that
ReCon substantially improve the quality and trainability of generated data,
achieving consistent performance gains across various datasets, backbone
architectures, and data scales. Our code is available at
https://github.com/haoweiz23/ReCon .

</details>


### [83] [ERNet: Efficient Non-Rigid Registration Network for Point Sequences](https://arxiv.org/abs/2510.15800)
*Guangzhao He,Yuxi Xiao,Zhen Xu,Xiaowei Zhou,Sida Peng*

Main category: cs.CV

TL;DR: ERNet是一个高效的前馈模型，用于解决非刚性形变下的物体形状配准问题，通过两阶段的形变图预测来处理噪声和不完整输入，并利用时序信息实现准确一致的序列配准，在DeformingThings4D和D-FAUST数据集上均优于现有方法，且速度提升4倍以上。


<details>
  <summary>Details</summary>
Motivation: 非刚性形变下物体形状配准是一个长期存在的挑战，主要难点在于配准目标的局部最小值和长序列中的误差累积，这阻碍了准确鲁棒的形变估计和跟踪。

Method: 提出了一种名为ERNet的数据驱动方法，这是一个高效的前馈模型，通过两阶段流水线预测形变图：首先估计逐帧的粗略图节点以进行鲁棒初始化，然后在滑动窗口中优化它们的轨迹。

Result: 在DeformingThings4D和D-FAUST数据集上的实验表明，ERNet的性能优于现有最先进的方法，并且实现了超过4倍的速度提升。

Conclusion: ERNet通过其高效的两阶段形变图预测方法，能够处理噪声和不完整输入，有效利用时序信息，在准确性、鲁棒性和效率方面均取得了显著改进。

Abstract: Registering an object shape to a sequence of point clouds undergoing
non-rigid deformation is a long-standing challenge. The key difficulties stem
from two factors: (i) the presence of local minima due to the non-convexity of
registration objectives, especially under noisy or partial inputs, which
hinders accurate and robust deformation estimation, and (ii) error accumulation
over long sequences, leading to tracking failures. To address these challenges,
we introduce to adopt a scalable data-driven approach and propose ERNet, an
efficient feed-forward model trained on large deformation datasets. It is
designed to handle noisy and partial inputs while effectively leveraging
temporal information for accurate and consistent sequential registration. The
key to our design is predicting a sequence of deformation graphs through a
two-stage pipeline, which first estimates frame-wise coarse graph nodes for
robust initialization, before refining their trajectories over time in a
sliding-window fashion. Extensive experiments show that our proposed approach
(i) outperforms previous state-of-the-art on both the DeformingThings4D and
D-FAUST datasets, and (ii) achieves more than 4x speedup compared to the
previous best, offering significant efficiency improvement.

</details>


### [84] [VISTA: A Test-Time Self-Improving Video Generation Agent](https://arxiv.org/abs/2510.15831)
*Do Xuan Long,Xingchen Wan,Hootan Nakhost,Chen-Yu Lee,Tomas Pfister,Sercan Ö. Arık*

Main category: cs.CV

TL;DR: VISTA是一个多智能体系统，通过迭代优化提示来提高文本到视频合成的质量和用户意图的一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到视频合成方法对用户提示的准确性要求很高，而现有的测试时间优化方法在视频领域效果不佳。

Method: VISTA将用户想法分解为结构化时间计划，通过生成、识别最佳视频（通过成对竞赛）、由专门的智能体进行评估（视觉、听觉、上下文保真度），最后由一个推理智能体整合反馈来重写和增强提示，以进行下一轮生成。

Result: VISTA在单场景和多场景视频生成任务中持续提高视频质量和用户意图的一致性，在成对比较中击败了最先进的基线方法（获胜率高达60%）。

Conclusion: VISTA能够有效提升视频生成质量和用户意图的一致性，实验结果和人类评估都证明了其优越性。

Abstract: Despite rapid advances in text-to-video synthesis, generated video quality
remains critically dependent on precise user prompts. Existing test-time
optimization methods, successful in other domains, struggle with the
multi-faceted nature of video. In this work, we introduce VISTA (Video
Iterative Self-improvemenT Agent), a novel multi-agent system that autonomously
improves video generation through refining prompts in an iterative loop. VISTA
first decomposes a user idea into a structured temporal plan. After generation,
the best video is identified through a robust pairwise tournament. This winning
video is then critiqued by a trio of specialized agents focusing on visual,
audio, and contextual fidelity. Finally, a reasoning agent synthesizes this
feedback to introspectively rewrite and enhance the prompt for the next
generation cycle. Experiments on single- and multi-scene video generation
scenarios show that while prior methods yield inconsistent gains, VISTA
consistently improves video quality and alignment with user intent, achieving
up to 60% pairwise win rate against state-of-the-art baselines. Human
evaluators concur, preferring VISTA outputs in 66.4% of comparisons.

</details>


### [85] [Neuro-Symbolic Spatial Reasoning in Segmentation](https://arxiv.org/abs/2510.15841)
*Jiayi Lin,Jiabo Huang,Shaogang Gong*

Main category: cs.CV

TL;DR: RelateSeg通过引入神经符号学（NeSy）空间推理来解决开放词汇语义分割（OVSS）中的空间关系理解问题，通过一阶逻辑（FOL）强制执行显式空间关系约束，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 开放词汇语义分割（OVSS）需要对未见过的物体进行像素级标注，而现有的基于视觉-语言模型（VLM）的方法在理解场景中物体的空间关系方面存在不足。

Method: 提出RelateSeg，一种在神经网络架构中利用一阶逻辑（FOL）强制执行显式空间关系约束的神经符号学（NeSy）方法。RelateSeg自动提取空间关系（例如，<cat, to-right-of, person>），并将其编码为伪类别的一阶逻辑公式。每个像素同时预测语义类别和空间伪类别，以强制执行关系约束。通过模糊逻辑松弛将逻辑约束纳入深度网络，实现端到端学习。

Result: RelateSeg在四个基准数据集的平均mIoU方面取得了最先进的性能，特别是在包含多个类别的图像上表现出明显优势，并且仅引入了一个辅助损失函数，没有额外的参数。

Conclusion: 神经符号学（NeSy）空间推理能有效提升OVSS的性能。

Abstract: Open-Vocabulary Semantic Segmentation (OVSS) assigns pixel-level labels from
an open set of categories, requiring generalization to unseen and unlabelled
objects. Using vision-language models (VLMs) to correlate local image patches
with potential unseen object categories suffers from a lack of understanding of
spatial relations of objects in a scene. To solve this problem, we introduce
neuro-symbolic (NeSy) spatial reasoning in OVSS. In contrast to contemporary
VLM correlation-based approaches, we propose Relational Segmentor (RelateSeg)
to impose explicit spatial relational constraints by first order logic (FOL)
formulated in a neural network architecture. This is the first attempt to
explore NeSy spatial reasoning in OVSS. Specifically, RelateSeg automatically
extracts spatial relations, e.g., <cat, to-right-of, person>, and encodes them
as first-order logic formulas using our proposed pseudo categories. Each pixel
learns to predict both a semantic category (e.g., "cat") and a spatial pseudo
category (e.g., "right of person") simultaneously, enforcing relational
constraints (e.g., a "cat" pixel must lie to the right of a "person"). Finally,
these logic constraints are formulated in a deep network architecture by fuzzy
logic relaxation, enabling end-to-end learning of spatial-relationally
consistent segmentation. RelateSeg achieves state-of-the-art performance in
terms of average mIoU across four benchmark datasets and particularly shows
clear advantages on images containing multiple categories, with the cost of
only introducing a single auxiliary loss function and no additional parameters,
validating the effectiveness of NeSy spatial reasoning in OVSS.

</details>


### [86] [3DPR: Single Image 3D Portrait Relight using Generative Priors](https://arxiv.org/abs/2510.15846)
*Pramod Rao,Abhimitra Meka,Xilong Zhou,Gereon Fox,Mallikarjun B R,Fangneng Zhan,Tim Weyrich,Bernd Bickel,Hanspeter Pfister,Wojciech Matusik,Thabo Beeler,Mohamed Elgharib,Marc Habermann,Christian Theobalt*

Main category: cs.CV

TL;DR: 3DPR是一个基于图像的重新照明模型，它利用从多视图单次光照（OLAT）图像中学习到的生成先验，以实现从单视角人脸肖像到新视角、新光照的人脸渲染。


<details>
  <summary>Details</summary>
Motivation: 从单张肖像图像输入渲染出具有新光照的人脸新视图是一个本质上约束不足的问题。传统图形学方法通过可微分渲染将输入图像分解为几何、材质和光照，但这受限于底层模型和场景组件参数化的多重假设和近似。

Method: 3DPR利用从光照台捕获的多视图单次光照（OLAT）图像中学习到的生成先验。引入了一个包含139个主体的大规模多视图4K OLAT数据集，以学习高频人脸反射率的分布先验。利用预训练的生成头部模型（从野外图像数据集中学习）的潜在空间，通过基于编码器的反演过程将输入肖像嵌入该模型的潜在流形。然后，利用在光照台数据上训练的新型三平面反射率网络，合成高保真OLAT图像，以实现基于图像的重新照明。该反射率网络在生成头部模型的潜在空间中操作，使得能够用相对较少的光照台图像来训练反射率模型。将生成的OLAT图像根据给定的HDRI环境图进行组合，可以产生物理上准确的环境重新照明结果。

Result: 3DPR在定量和定性评估中均优于先前方法，尤其在保持身份特征和捕捉镜面反射、自阴影和次表面散射等光照效果方面表现出色。

Conclusion: 3DPR通过利用生成先验和创新的反射率网络，有效解决了单视角人脸图像的重新照明问题，并在保持身份和真实感光照效果方面取得了显著的进展。

Abstract: Rendering novel, relit views of a human head, given a monocular portrait
image as input, is an inherently underconstrained problem. The traditional
graphics solution is to explicitly decompose the input image into geometry,
material and lighting via differentiable rendering; but this is constrained by
the multiple assumptions and approximations of the underlying models and
parameterizations of these scene components. We propose 3DPR, an image-based
relighting model that leverages generative priors learnt from multi-view
One-Light-at-A-Time (OLAT) images captured in a light stage. We introduce a new
diverse and large-scale multi-view 4K OLAT dataset of 139 subjects to learn a
high-quality prior over the distribution of high-frequency face reflectance. We
leverage the latent space of a pre-trained generative head model that provides
a rich prior over face geometry learnt from in-the-wild image datasets. The
input portrait is first embedded in the latent manifold of such a model through
an encoder-based inversion process. Then a novel triplane-based reflectance
network trained on our lightstage data is used to synthesize high-fidelity OLAT
images to enable image-based relighting. Our reflectance network operates in
the latent space of the generative head model, crucially enabling a relatively
small number of lightstage images to train the reflectance model. Combining the
generated OLATs according to a given HDRI environment maps yields physically
accurate environmental relighting results. Through quantitative and qualitative
evaluations, we demonstrate that 3DPR outperforms previous methods,
particularly in preserving identity and in capturing lighting effects such as
specularities, self-shadows, and subsurface scattering. Project Page:
https://vcai.mpi-inf.mpg.de/projects/3dpr/

</details>


### [87] [Memory-SAM: Human-Prompt-Free Tongue Segmentation via Retrieval-to-Prompt](https://arxiv.org/abs/2510.15849)
*Joongwon Chae,Lihui Luo,Xi Yuan,Dongmei Yu,Zhenglin Chen,Lian Zhang,Peiwu Qin*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Accurate tongue segmentation is crucial for reliable TCM analysis. Supervised
models require large annotated datasets, while SAM-family models remain
prompt-driven. We present Memory-SAM, a training-free, human-prompt-free
pipeline that automatically generates effective prompts from a small memory of
prior cases via dense DINOv3 features and FAISS retrieval. Given a query image,
mask-constrained correspondences to the retrieved exemplar are distilled into
foreground/background point prompts that guide SAM2 without manual clicks or
model fine-tuning. We evaluate on 600 expert-annotated images (300 controlled,
300 in-the-wild). On the mixed test split, Memory-SAM achieves mIoU 0.9863,
surpassing FCN (0.8188) and a detector-to-box SAM baseline (0.1839). On
controlled data, ceiling effects above 0.98 make small differences less
meaningful given annotation variability, while our method shows clear gains
under real-world conditions. Results indicate that retrieval-to-prompt enables
data-efficient, robust segmentation of irregular boundaries in tongue imaging.
The code is publicly available at https://github.com/jw-chae/memory-sam.

</details>


### [88] [BLIP3o-NEXT: Next Frontier of Native Image Generation](https://arxiv.org/abs/2510.15857)
*Jiuhai Chen,Le Xue,Zhiyang Xu,Xichen Pan,Shusheng Yang,Can Qin,An Yan,Honglu Zhou,Zeyuan Chen,Lifu Huang,Tianyi Zhou,Junnan Li,Silvio Savarese,Caiming Xiong,Ran Xu*

Main category: cs.CV

TL;DR: BLIP3o-NEXT是一个开源的、统一文本到图像生成和图像编辑的生成模型，通过结合自回归模型和扩散模型的优势，并在四大关键见解的指导下，实现了更高的图像质量和编辑能力。


<details>
  <summary>Details</summary>
Motivation: 提出BLIP3o-NEXT，以推动原生图像生成和图像编辑的下一代发展，并探索影响模型性能的关键因素。

Method: BLIP3o-NEXT采用自回归模型+扩散模型的架构，首先生成离散图像令牌，然后作为扩散模型的条件来生成高保真图像。该模型还通过后训练和数据引擎来增强指令遵循和图像一致性。

Result: BLIP3o-NEXT在文本到图像生成和图像编辑方面表现出优越的性能，超越了现有模型。

Conclusion: BLIP3o-NEXT通过创新的架构和对关键因素的深入理解，在图像生成和编辑领域取得了显著进展，证明了其在推动AI图像生成技术前沿的潜力。

Abstract: We present BLIP3o-NEXT, a fully open-source foundation model in the BLIP3
series that advances the next frontier of native image generation. BLIP3o-NEXT
unifies text-to-image generation and image editing within a single
architecture, demonstrating strong image generation and image editing
capabilities. In developing the state-of-the-art native image generation model,
we identify four key insights: (1) Most architectural choices yield comparable
performance; an architecture can be deemed effective provided it scales
efficiently and supports fast inference; (2) The successful application of
reinforcement learning can further push the frontier of native image
generation; (3) Image editing still remains a challenging task, yet instruction
following and the consistency between generated and reference images can be
significantly enhanced through post-training and data engine; (4) Data quality
and scale continue to be decisive factors that determine the upper bound of
model performance. Building upon these insights, BLIP3o-NEXT leverages an
Autoregressive + Diffusion architecture in which an autoregressive model first
generates discrete image tokens conditioned on multimodal inputs, whose hidden
states are then used as conditioning signals for a diffusion model to generate
high-fidelity images. This architecture integrates the reasoning strength and
instruction following of autoregressive models with the fine-detail rendering
ability of diffusion models, achieving a new level of coherence and realism.
Extensive evaluations of various text-to-image and image-editing benchmarks
show that BLIP3o-NEXT achieves superior performance over existing models.

</details>


### [89] [LightsOut: Diffusion-based Outpainting for Enhanced Lens Flare Removal](https://arxiv.org/abs/2510.15868)
*Shr-Ruei Tsai,Wei-Cheng Chang,Jie-Ying Lee,Chih-Hai Su,Yu-Lun Liu*

Main category: cs.CV

TL;DR: 提出了一种名为LightsOut的基于扩散的图像去辉方法，通过重建图像外的光源来提升单张图像去辉（SIFR）效果。


<details>
  <summary>Details</summary>
Motivation: 现有SIFR方法在处理图像外光源不完整或缺失时效果不佳，影响了计算机视觉任务的性能。

Method: 利用多任务回归模块和经过LoRA微调的扩散模型，生成逼真且物理一致的图像外延结果。

Result: 实验证明，LightsOut能够显著提升现有SIFR方法在各种挑战性场景下的性能，且无需重新训练，可作为即插即用的预处理解决方案。

Conclusion: LightsOut是一种有效的SIFR增强方法，通过重建图像外的光源，提高了SIFR的鲁棒性和性能。

Abstract: Lens flare significantly degrades image quality, impacting critical computer
vision tasks like object detection and autonomous driving. Recent Single Image
Flare Removal (SIFR) methods perform poorly when off-frame light sources are
incomplete or absent. We propose LightsOut, a diffusion-based outpainting
framework tailored to enhance SIFR by reconstructing off-frame light sources.
Our method leverages a multitask regression module and LoRA fine-tuned
diffusion model to ensure realistic and physically consistent outpainting
results. Comprehensive experiments demonstrate LightsOut consistently boosts
the performance of existing SIFR methods across challenging scenarios without
additional retraining, serving as a universally applicable plug-and-play
preprocessing solution. Project page: https://ray-1026.github.io/lightsout/

</details>


### [90] [Skyfall-GS: Synthesizing Immersive 3D Urban Scenes from Satellite Imagery](https://arxiv.org/abs/2510.15869)
*Jie-Ying Lee,Yi-Ruei Liu,Shr-Ruei Tsai,Wei-Cheng Chang,Chung-Ho Wu,Jiewen Chan,Zhenjun Zhao,Chieh Hubert Lin,Yu-Lun Liu*

Main category: cs.CV

TL;DR: Skyfall-GS是一个城市街区规模的3D场景创建框架，通过结合卫星图像和开放域扩散模型，无需昂贵的3D注释即可生成大规模、可探索、几何精确的3D城市场景，并具有实时、沉浸式的3D探索功能。


<details>
  <summary>Details</summary>
Motivation: 现有的3D场景合成方法面临大规模、高质量真实世界3D扫描数据缺乏的挑战，这限制了可泛化生成模型的训练。因此，本研究旨在探索一种无需昂贵3D注释即可创建大规模3D场景的替代方法。

Method: 提出Skyfall-GS框架，利用现有的卫星图像提供粗糙几何信息，并结合开放域扩散模型生成高质量的近景外观。采用课程驱动的迭代优化策略，逐步提升几何完整性和照片级真实感纹理。

Result: 实验证明，与现有最先进的方法相比，Skyfall-GS在跨视图一致的几何和更逼真的纹理方面表现更优。

Conclusion: Skyfall-GS成功实现了在没有昂贵3D注释的情况下，创建大规模、可探索、几何精确的3D城市场景，并能生成逼真的纹理，为沉浸式和具身应用提供了新的解决方案。

Abstract: Synthesizing large-scale, explorable, and geometrically accurate 3D urban
scenes is a challenging yet valuable task in providing immersive and embodied
applications. The challenges lie in the lack of large-scale and high-quality
real-world 3D scans for training generalizable generative models. In this
paper, we take an alternative route to create large-scale 3D scenes by
synergizing the readily available satellite imagery that supplies realistic
coarse geometry and the open-domain diffusion model for creating high-quality
close-up appearances. We propose \textbf{Skyfall-GS}, the first city-block
scale 3D scene creation framework without costly 3D annotations, also featuring
real-time, immersive 3D exploration. We tailor a curriculum-driven iterative
refinement strategy to progressively enhance geometric completeness and
photorealistic textures. Extensive experiments demonstrate that Skyfall-GS
provides improved cross-view consistent geometry and more realistic textures
compared to state-of-the-art approaches. Project page:
https://skyfall-gs.jayinnn.dev/

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [91] [Rethinking Toxicity Evaluation in Large Language Models: A Multi-Label Perspective](https://arxiv.org/abs/2510.15007)
*Zhiqiang Kou,Junyang Chen,Xin-Qiang Cai,Ming-Kun Xie,Biao Liu,Changwei Wang,Lei Feng,Yuheng Jia,Gang Niu,Masashi Sugiyama,Xin Geng*

Main category: cs.CL

TL;DR: 大型语言模型（LLM）生成有害内容的风险引起了安全担忧。现有的毒性检测器主要基于单一标签的基准，无法充分应对现实世界中多维度、多标签的毒性提示，导致评估偏差。为解决此问题，我们提出了三个新的多标签基准（Q-A-MLL, R-A-MLL, H-X-MLL），并进行了理论证明，表明伪标签训练优于单一标签训练。我们还开发了一种基于伪标签的毒性检测方法，实验证明该方法在准确性和可靠性方面显著优于现有先进模型，如GPT-4o和DeepSeek。


<details>
  <summary>Details</summary>
Motivation: 现有的毒性检测器主要基于单一标签的基准，无法充分应对现实世界中多维度、多标签的毒性提示，导致评估偏差，并且收集细粒度的多标签注释成本高昂，阻碍了有效的评估和开发。

Method: 提出了三个新的多标签基准（Q-A-MLL, R-A-MLL, H-X-MLL），并进行了理论证明，表明伪标签训练优于单一标签训练。开发了一种基于伪标签的毒性检测方法。

Result: 提出的方法在准确性和可靠性方面显著优于现有先进模型，如GPT-4o和DeepSeek，能够更准确、更可靠地评估LLM生成内容的多标签毒性。

Conclusion: 提出的多标签基准和基于伪标签的毒性检测方法能够更准确、更可靠地评估LLM生成内容的多标签毒性，解决了现有方法的局限性。

Abstract: Large language models (LLMs) have achieved impressive results across a range
of natural language processing tasks, but their potential to generate harmful
content has raised serious safety concerns. Current toxicity detectors
primarily rely on single-label benchmarks, which cannot adequately capture the
inherently ambiguous and multi-dimensional nature of real-world toxic prompts.
This limitation results in biased evaluations, including missed toxic
detections and false positives, undermining the reliability of existing
detectors. Additionally, gathering comprehensive multi-label annotations across
fine-grained toxicity categories is prohibitively costly, further hindering
effective evaluation and development. To tackle these issues, we introduce
three novel multi-label benchmarks for toxicity detection: \textbf{Q-A-MLL},
\textbf{R-A-MLL}, and \textbf{H-X-MLL}, derived from public toxicity datasets
and annotated according to a detailed 15-category taxonomy. We further provide
a theoretical proof that, on our released datasets, training with pseudo-labels
yields better performance than directly learning from single-label supervision.
In addition, we develop a pseudo-label-based toxicity detection method.
Extensive experimental results show that our approach significantly surpasses
advanced baselines, including GPT-4o and DeepSeek, thus enabling more accurate
and reliable evaluation of multi-label toxicity in LLM-generated content.

</details>


### [92] [Can generative AI figure out figurative language? The influence of idioms on essay scoring by ChatGPT, Gemini, and Deepseek](https://arxiv.org/abs/2510.15009)
*Enis Oğuz*

Main category: cs.CL

TL;DR: 生成式AI在学生作文自动评分方面表现出潜力，其中Gemini在处理包含习语的作文方面表现最佳，并显示出无明显人口统计偏见。


<details>
  <summary>Details</summary>
Motivation: 评估生成式AI模型在处理包含习语和不包含习语的学生作文时的评分表现，并将其与人类评分者进行比较。

Method: 使用三个生成式AI模型（ChatGPT、Gemini和Deepseek）对包含和不包含习语的学生作文进行评分，并与人类评分者进行比较。

Result: 所有模型都表现出极好的一致性，但Gemini在与人类评分者的一致性方面表现优于其他模型。在处理包含习语的作文时，Gemini的评分模式与人类评分者最为相似。所有模型在评分时均无明显的人口统计偏见。

Conclusion: 生成式AI，特别是Gemini，在处理包含习语的作文方面显示出作为自动评分工具的巨大潜力，并且有望在未来独立承担此任务。

Abstract: The developments in Generative AI technologies have paved the way for
numerous innovations in different fields. Recently, Generative AI has been
proposed as a competitor to AES systems in evaluating student essays
automatically. Considering the potential limitations of AI in processing
idioms, this study assessed the scoring performances of Generative AI models
for essays with and without idioms by incorporating insights from Corpus
Linguistics and Computational Linguistics. Two equal essay lists were created
from 348 student essays taken from a corpus: one with multiple idioms present
in each essay and another with no idioms in essays. Three Generative AI models
(ChatGPT, Gemini, and Deepseek) were asked to score all essays in both lists
three times, using the same rubric used by human raters in assigning essay
scores. The results revealed excellent consistency for all models, but Gemini
outperformed its competitors in interrater reliability with human raters. There
was also no detectable bias for any demographic group in AI assessment. For
essays with multiple idioms, Gemini followed a the most similar pattern to
human raters. While the models in the study demonstrated potential for a hybrid
approach, Gemini was the best candidate for the task due to its ability to
handle figurative language and showed promise for handling essay-scoring tasks
alone in the future.

</details>


### [93] [A Generalizable Rhetorical Strategy Annotation Model Using LLM-based Debate Simulation and Labelling](https://arxiv.org/abs/2510.15081)
*Shiyu Ji,Farnoosh Hashemi,Joice Chen,Juanwen Pan,Weicheng Ma,Hefan Zhang,Sophia Pan,Ming Cheng,Shubham Mohole,Saeed Hassanpour,Soroush Vosoughi,Michael Macy*

Main category: cs.CL

TL;DR: 该研究提出了一种利用大型语言模型（LLM）自动生成和标注辩论数据集的框架，以克服传统手动标注的局限性，并开发了一个包含四种修辞策略（因果、经验、情感、道德）的分类器。


<details>
  <summary>Details</summary>
Motivation: 传统修辞策略分析依赖昂贵、不一致且难以扩展的人工标注，并且现有数据集通常仅限于特定主题和策略，这给鲁棒的模型开发带来了挑战。

Method: 利用大型语言模型（LLM）自动生成和标注基于四部分修辞类型（因果、经验、情感、道德）的合成辩论数据，并在此LLM标注的数据集上对基于Transformer的分类器进行微调。

Result: 该模型在针对人工标注数据的验证中表现出高分，并且在多个外部语料库上具有很强的泛化能力。研究还展示了该微调模型的两个应用：1.通过整合修辞策略标签来提高说服力预测的准确性；2.分析美国总统辩论（1960-2020）中修辞策略的时间和党派变化，揭示了情感性论证相对于认知性论证的使用增加。

Conclusion: 该研究提出的新框架能够克服现有修辞策略分析方法的局限性，并为理解和应用修辞策略提供了新的途径。

Abstract: Rhetorical strategies are central to persuasive communication, from political
discourse and marketing to legal argumentation. However, analysis of rhetorical
strategies has been limited by reliance on human annotation, which is costly,
inconsistent, difficult to scale. Their associated datasets are often limited
to specific topics and strategies, posing challenges for robust model
development. We propose a novel framework that leverages large language models
(LLMs) to automatically generate and label synthetic debate data based on a
four-part rhetorical typology (causal, empirical, emotional, moral). We
fine-tune transformer-based classifiers on this LLM-labeled dataset and
validate its performance against human-labeled data on this dataset and on
multiple external corpora. Our model achieves high performance and strong
generalization across topical domains. We illustrate two applications with the
fine-tuned model: (1) the improvement in persuasiveness prediction from
incorporating rhetorical strategy labels, and (2) analyzing temporal and
partisan shifts in rhetorical strategies in U.S. Presidential debates
(1960-2020), revealing increased use of affective over cognitive argument in
U.S. Presidential debates.

</details>


### [94] [Continual Learning via Sparse Memory Finetuning](https://arxiv.org/abs/2510.15103)
*Jessy Lin,Luke Zettlemoyer,Gargi Ghosh,Wen-Tau Yih,Aram Markosyan,Vincent-Pierre Berges,Barlas Oğuz*

Main category: cs.CL

TL;DR: 现代语言模型在部署后通常是静态的，而灾难性遗忘是持续学习的主要障碍。通过只更新新知识激活的记忆槽，可以减少新知识与模型现有能力之间的干扰。


<details>
  <summary>Details</summary>
Motivation: 灾难性遗忘是现代语言模型持续学习的障碍，因为可训练参数在所有任务之间共享。

Method: 提出稀疏记忆微调（Sparse Memory Finetuning），利用记忆层模型（Memory Layer Models），只更新被新知识高度激活的记忆槽，以减少遗忘。

Result: 稀疏记忆微调在学习新知识的同时，遗忘率显著低于全量微调和LoRA。在问答任务上，与全量微调（F1下降89%）和LoRA（F1下降71%）相比，稀疏记忆微调仅导致F1下降11%。

Conclusion: 现代语言模型中记忆层的稀疏性为实现持续学习提供了一个有前景的方向。

Abstract: Modern language models are powerful, but typically static after deployment. A
major obstacle to building models that continually learn over time is
catastrophic forgetting, where updating on new data erases previously acquired
capabilities. Motivated by the intuition that mitigating forgetting is
challenging because trainable parameters are shared across all tasks, we
investigate whether sparse parameter updates can enable learning without
catastrophic forgetting. We introduce sparse memory finetuning, leveraging
memory layer models (Berges et al., 2024), which are sparsely updated by
design. By updating only the memory slots that are highly activated by a new
piece of knowledge relative to usage on pretraining data, we reduce
interference between new knowledge and the model's existing capabilities. We
evaluate learning and forgetting compared to full finetuning and
parameter-efficient finetuning with LoRA on two question answering tasks. We
find that sparse memory finetuning learns new knowledge while exhibiting
substantially less forgetting: while NaturalQuestions F1 drops by 89% after
full finetuning on new facts and 71% with LoRA, sparse memory finetuning yields
only an 11% drop with the same level of new knowledge acquisition. Our results
suggest sparsity in memory layers offers a promising path toward continual
learning in large language models.

</details>


### [95] [Measuring the Effect of Disfluency in Multilingual Knowledge Probing Benchmarks](https://arxiv.org/abs/2510.15115)
*Kirill Semenov,Rico Sennrich*

Main category: cs.CL

TL;DR: MLAMA 数据集存在语法和语义问题，导致多语言事实知识评估不准确。通过使用谷歌翻译和 ChatGPT 进行句子级翻译，可以提高评估分数，并鼓励社区改进多语言数据集的语法。另可参见：https://github.com/ZurichNLP/Fluent-mLAMA。


<details>
  <summary>Details</summary>
Motivation: 现有的多语言事实知识评估基准（如 MLAMA）在模板翻译时未考虑实体的语法和语义信息，导致提示语句不规范或措辞错误，尤其在形态丰富的语言中，这会影响分数的可解释性。

Method: 从 MLAMA 数据集中抽取 4 种斯拉夫语言，比较了原始 MLAMA 数据集和使用谷歌翻译及 ChatGPT 进行句子级翻译后的知识检索分数。此外，还对另外 5 种不同语系的语言进行了分析。

Result: 使用谷歌翻译和 ChatGPT 进行句子级翻译后，知识检索分数显著提高。在其他 5 种语言中也观察到类似模式。

Conclusion: 鼓励社区检查多语言数据集的语法，以获得更高且更具可解释性的结果。使用神经机器翻译或大型语言模型进行全句翻译是实现这一目标的可行方法。

Abstract: For multilingual factual knowledge assessment of LLMs, benchmarks such as
MLAMA use template translations that do not take into account the grammatical
and semantic information of the named entities inserted in the sentence. This
leads to numerous instances of ungrammaticality or wrong wording of the final
prompts, which complicates the interpretation of scores, especially for
languages that have a rich morphological inventory. In this work, we sample 4
Slavic languages from the MLAMA dataset and compare the knowledge retrieval
scores between the initial (templated) MLAMA dataset and its sentence-level
translations made by Google Translate and ChatGPT. We observe a significant
increase in knowledge retrieval scores, and provide a qualitative analysis for
possible reasons behind it. We also make an additional analysis of 5 more
languages from different families and see similar patterns. Therefore, we
encourage the community to control the grammaticality of highly multilingual
datasets for higher and more interpretable results, which is well approximated
by whole sentence translation with neural MT or LLM systems. The dataset and
all related code is published at the Github repository:
https://github.com/ZurichNLP/Fluent-mLAMA.

</details>


### [96] [Latent Topic Synthesis: Leveraging LLMs for Electoral Ad Analysis](https://arxiv.org/abs/2510.15125)
*Alexander Brady,Tunazzina Islam*

Main category: cs.CL

TL;DR: 本研究提出了一种结合无监督聚类和提示式标签生成的方法，利用大型语言模型自动构建可解释的主题分类法，并将其应用于分析2024年美国总统大选前Meta平台的政治广告。


<details>
  <summary>Details</summary>
Motivation: 分析海量且快速变化的社交媒体政治信息是一个巨大挑战，需要一种自动化的方法来理解其潜在的话题结构和叙事。

Method: 提出一个端到端的框架，结合无监督聚类和提示式标签生成，利用大型语言模型迭代地构建主题分类法，无需种子集或领域专业知识。

Result: 该框架成功应用于分析2024年美国总统大选前Meta平台的政治广告，揭示了投票和移民广告占主导地位，堕胎和选举公正性广告触及范围广。研究还发现，不同议题的资金模式和道德框架存在显著差异，并且话题显著性与道德基础和议题之间存在相关性，同时揭示了人口统计学定位。

Conclusion: 本研究提出的框架支持对社交媒体政治信息进行可扩展、可解释的分析，有助于研究人员、政策制定者和公众更好地理解新兴叙事、两极分化动态以及数字政治传播的道德基础。

Abstract: Social media platforms play a pivotal role in shaping political discourse,
but analyzing their vast and rapidly evolving content remains a major
challenge. We introduce an end-to-end framework for automatically generating an
interpretable topic taxonomy from an unlabeled corpus. By combining
unsupervised clustering with prompt-based labeling, our method leverages large
language models (LLMs) to iteratively construct a taxonomy without requiring
seed sets or domain expertise. We apply this framework to a large corpus of
Meta (previously known as Facebook) political ads from the month ahead of the
2024 U.S. Presidential election. Our approach uncovers latent discourse
structures, synthesizes semantically rich topic labels, and annotates topics
with moral framing dimensions. We show quantitative and qualitative analyses to
demonstrate the effectiveness of our framework. Our findings reveal that voting
and immigration ads dominate overall spending and impressions, while abortion
and election-integrity achieve disproportionate reach. Funding patterns are
equally polarized: economic appeals are driven mainly by conservative PACs,
abortion messaging splits between pro- and anti-rights coalitions, and
crime-and-justice campaigns are fragmented across local committees. The framing
of these appeals also diverges--abortion ads emphasize liberty/oppression
rhetoric, while economic messaging blends care/harm, fairness/cheating, and
liberty/oppression narratives. Topic salience further reveals strong
correlations between moral foundations and issues. Demographic targeting also
emerges. This work supports scalable, interpretable analysis of political
messaging on social media, enabling researchers, policymakers, and the public
to better understand emerging narratives, polarization dynamics, and the moral
underpinnings of digital political communication.

</details>


### [97] [FarsiMCQGen: a Persian Multiple-choice Question Generation Framework](https://arxiv.org/abs/2510.15134)
*Mohammad Heydari Rad,Rezvan Afari,Saeedeh Momtazi*

Main category: cs.CL

TL;DR: FarsiMCQGen是一种用于生成波斯语多项选择题（MCQ）的方法，它结合了候选生成、过滤和排序技术，利用Transformer、知识图谱和基于规则的方法来生成可信的干扰项。该研究还引入了一个包含10,289个问题的波斯语MCQ数据集，并证明了其模型的有效性。


<details>
  <summary>Details</summary>
Motivation: 生成高质量的多项选择题（MCQ），特别是在波斯语等资源匮乏的语言中，仍然是一个重大挑战。

Method: 该方法结合了候选生成、过滤和排序技术，利用Transformer、知识图谱和基于规则的方法来生成可信的干扰项。

Result: 所提出的模型有效，并且生成的数据集质量很高。

Conclusion: FarsiMCQGen的有效性以及生成的数据集质量证明了其在该领域的潜力，有望激发更多关于MCQ的研究。

Abstract: Multiple-choice questions (MCQs) are commonly used in educational testing, as
they offer an efficient means of evaluating learners' knowledge. However,
generating high-quality MCQs, particularly in low-resource languages such as
Persian, remains a significant challenge. This paper introduces FarsiMCQGen, an
innovative approach for generating Persian-language MCQs. Our methodology
combines candidate generation, filtering, and ranking techniques to build a
model that generates answer choices resembling those in real MCQs. We leverage
advanced methods, including Transformers and knowledge graphs, integrated with
rule-based approaches to craft credible distractors that challenge test-takers.
Our work is based on data from Wikipedia, which includes general knowledge
questions. Furthermore, this study introduces a novel Persian MCQ dataset
comprising 10,289 questions. This dataset is evaluated by different
state-of-the-art large language models (LLMs). Our results demonstrate the
effectiveness of our model and the quality of the generated dataset, which has
the potential to inspire further research on MCQs.

</details>


### [98] [Structure-R1: Dynamically Leveraging Structural Knowledge in LLM Reasoning through Reinforcement Learning](https://arxiv.org/abs/2510.15191)
*Junlin Wu,Xianrui Zhong,Jiashuo Sun,Bolian Li,Bowen Jin,Jiawei Han,Qingkai Zeng*

Main category: cs.CL

TL;DR: LLMs在推理方面表现出色，但受限于结构化知识获取。RAG通过引入外部知识来增强LLMs的推理能力，但其处理的非结构化文本信息密度低。本文提出Structure-R1框架，将检索到的内容转换为结构化表示以优化推理。该框架利用强化学习学习内容表示策略，并能根据多步推理需求动态生成和调整结构格式。与依赖固定模式的先前方法不同，Structure-R1采用生成范式，能为特定查询生成特定任务的结构。为确保表示的质量和可靠性，引入了自奖励结构验证机制。在七个知识密集型基准测试上的实验表明，Structure-R1使用7B模型取得了有竞争力的性能，并达到了更大模型的性能水平。理论分析表明，结构化表示通过提高信息密度和上下文清晰度来增强推理能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在推理能力方面取得了显著的进步，但其性能受到对显式和结构化领域知识的有限访问的限制。检索增强生成（RAG）通过整合外部信息作为上下文来增强推理，从而解决了这个问题。然而，传统的RAG系统通常处理非结构化和碎片化的文本，导致信息密度低和推理效果不佳。

Method: 提出了一种名为Structure-R1的新框架，该框架将检索到的内容转换为针对推理进行优化的结构化表示。利用强化学习，Structure-R1学习一种内容表示策略，能够根据多步推理的需求动态地生成和调整结构格式。与依赖固定模式的先前方法不同，该方法采用生成范式，能够为单个查询生成特定任务的结构。为了确保这些表示的质量和可靠性，引入了一种自奖励的结构验证机制，用于检查生成的结构是否既正确又自包含。

Result: 在七个知识密集型基准测试上的广泛实验表明，Structure-R1使用7B规模的骨干模型始终 achieves 具有竞争力的性能，并匹配了更大模型的性能。

Conclusion: 结构化表示通过提高信息密度和上下文清晰度来增强推理能力。

Abstract: Large language models (LLMs) have demonstrated remarkable advances in
reasoning capabilities. However, their performance remains constrained by
limited access to explicit and structured domain knowledge. Retrieval-Augmented
Generation (RAG) addresses this by incorporating external information as
context to augment reasoning. Nevertheless, traditional RAG systems typically
operate over unstructured and fragmented text, resulting in low information
density and suboptimal reasoning. To overcome these limitations, we propose
\textsc{Structure-R1}, a novel framework that transforms retrieved content into
structured representations optimized for reasoning. Leveraging reinforcement
learning, \textsc{Structure-R1} learns a content representation policy that
dynamically generates and adapts structural formats based on the demands of
multi-step reasoning. Unlike prior methods that rely on fixed schemas, our
approach adopts a generative paradigm capable of producing task-specific
structures tailored to individual queries. To ensure the quality and
reliability of these representations, we introduce a self-reward structural
verification mechanism that checks whether the generated structures are both
correct and self-contained. Extensive experiments on seven knowledge-intensive
benchmarks show that \textsc{Structure-R1} consistently achieves competitive
performance with a 7B-scale backbone model and matches the performance of much
larger models. Additionally, our theoretical analysis demonstrates how
structured representations enhance reasoning by improving information density
and contextual clarity. Our code and data are available at:
https://github.com/jlwu002/sr1.

</details>


### [99] [Extending Audio Context for Long-Form Understanding in Large Audio-Language Models](https://arxiv.org/abs/2510.15231)
*Yuatyong Chaichana,Pittawat Taveekitworachai,Warit Sirichotedumrong,Potsawee Manakul,Kunat Pipatanakul*

Main category: cs.CL

TL;DR: 该研究提出了一种名为Partial YaRN的训练无关的音频扩展方法，以及一种名为VLAT的训练策略，用于解决大型音频语言模型（LALM）的短音频上下文窗口限制问题。


<details>
  <summary>Details</summary>
Motivation: 大型音频语言模型（LALM）的短音频上下文窗口限制了其对长篇音频的理解能力，而现有的上下文扩展方法尚未应用于LALM。

Method: 1. Partial YaRN：一种训练无关的、仅音频的扩展方法，通过修改音频令牌位置而不改变文本令牌位置来扩展上下文。 2. VLAT：一种训练策略，将Partial YaRN作为训练时的位置增强，模拟不同的音频长度，以提高模型泛化到训练时未见过的长输入的能力。

Result: 在SALMONN和Qwen2-Audio上的实验表明，Partial YaRN在各种设置下都优于原始模型，而VLAT训练策略带来了显著的改进，在处理训练时未见过的长音频方面取得了强大的性能。

Conclusion: Partial YaRN和VLAT的结合能够有效地扩展LALM的上下文窗口，提高其对长篇音频的理解能力和泛化能力。

Abstract: Large Audio-Language Models (LALMs) are often constrained by short audio
context windows, even when their text backbones support long contexts, limiting
long-form audio understanding. Prior work has introduced context-extension
methods (e.g. YaRN) on unimodal LLMs, yet their application to LALMs remains
unexplored. First, building on RoPE-based context extension, we introduce
Partial YaRN, a training-free, audio-only extension method that modifies only
audio token positions, leaving text positions intact to preserve the base LLM's
text capabilities. Second, we propose Virtual Longform Audio Training (VLAT), a
training strategy that extends Partial YaRN into a training-time positional
augmentation. VLAT simulates diverse audio lengths during training, enabling
generalization to inputs far longer than those seen in training and improving
robustness for long-context audio understanding. Our experiments on SALMONN and
Qwen2-Audio show that Partial YaRN outperforms the original models across wide
range of settings, and VLAT training strategy provides substantial improvement,
achieving strong performance on long audio of unseen lengths.

</details>


### [100] [Planner and Executor: Collaboration between Discrete Diffusion And Autoregressive Models in Reasoning](https://arxiv.org/abs/2510.15244)
*Lina Berrayana,Ahmed Heakl,Muhammad Abdullah Sohail,Thomas Hofmann,Salman Khan,Wei Chen*

Main category: cs.CL

TL;DR: 通过结合离散扩散语言模型（DDLM）和自回归语言模型（ARM）的混合架构，可以提高文本生成任务的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 探索DDLM和ARM的协作是否能带来互补优势，以提高生成模型的性能。

Method: 首先在文本空间中进行协作，然后扩展到潜在空间通信，引入学习到的投影仪将DDLM的潜在表示映射到ARM的嵌入空间。

Result: 将通信从文本空间转移到潜在空间可以显著提高准确性（例如，在DART-5上从27.0%提高到54.0%，在AIME24上从0.0%提高到14.0%）。混合架构在保持准确性的同时，可以节省计算资源。例如，潜在空间流水线在DART-5和AIME上优于Qwen3.1-7B，尽管Qwen使用了更多的token。

Conclusion: DDLM在混合架构中具有巨大潜力，可以为推理提供新的见解。

Abstract: Current autoregressive language models (ARMs) achieve high accuracy but
require long token sequences, making them costly. Discrete diffusion language
models (DDLMs) enable parallel and flexible generation within a fixed number of
steps and have recently emerged for their strong performance in complex
reasoning and long-term planning tasks. We present a study exploring hybrid
architectures that couple DDLMs with ARMs to assess whether their collaboration
can yield complementary benefits. We first examine collaboration in text space,
where one model plans the reasoning process and another executes the final
answer based on that plan. We then extend this setup to latent-space
communication, introducing a learned projector that maps DDLM latents into the
ARM's embedding space, potentially bypassing some of the text-generation
limitations of diffusion models. We find that shifting DDLM --> ARM
communication from text space to latent space yields significant accuracy
gains, for example increasing from 27.0% to 54.0% on DART-5 and from 0.0% to
14.0% on AIME24. We also find that combining a DDLM planner with an ARM
executor can provide substantial computational savings with little to no impact
on accuracy. For example, the latent-space pipeline, using 64 tokens for
planning and roughly 5 for execution, surpasses Qwen3.1-7B on DART-5 and AIME,
despite Qwen using 44 times more tokens. Overall, our study offers new insights
into reasoning with DDLMs and highlights their potential in hybrid
architectures.

</details>


### [101] [Scaling Beyond Context: A Survey of Multimodal Retrieval-Augmented Generation for Document Understanding](https://arxiv.org/abs/2510.15253)
*Sensen Gao,Shanshan Zhao,Xu Jiang,Lunhao Duan,Yong Xien Chng,Qing-Guo Chen,Weihua Luo,Kaifu Zhang,Jia-Wang Bian,Mingming Gong*

Main category: cs.CL

TL;DR: 本文提出了一种用于文档理解的多模态检索增强生成（Multimodal RAG）方法，解决了现有方法在结构细节丢失和上下文建模方面的局限性，并对该领域进行了系统性 survey，包括方法、数据集、基准和未来挑战。


<details>
  <summary>Details</summary>
Motivation: 现有基于OCR的管道和多模态大语言模型（MLLM）在文档理解方面存在局限性，前者丢失结构细节，后者难以进行上下文建模。多模态RAG能够实现跨模态的综合检索和推理，以实现全面的文档智能。

Method: 提出了一种基于领域、检索模态和粒度的多模态RAG分类法，并回顾了涉及图结构和智能体框架的进展，同时总结了关键的数据集、基准和应用。

Result: 对多模态RAG在文档理解领域的应用进行了全面的调查，总结了关键的数据集、基准和应用。

Conclusion: 尽管取得了进展，但在效率、细粒度表示和鲁棒性方面仍存在挑战，需要进一步研究以推动文档人工智能的发展。

Abstract: Document understanding is critical for applications from financial analysis
to scientific discovery. Current approaches, whether OCR-based pipelines
feeding Large Language Models (LLMs) or native Multimodal LLMs (MLLMs), face
key limitations: the former loses structural detail, while the latter struggles
with context modeling. Retrieval-Augmented Generation (RAG) helps ground models
in external data, but documents' multimodal nature, i.e., combining text,
tables, charts, and layout, demands a more advanced paradigm: Multimodal RAG.
This approach enables holistic retrieval and reasoning across all modalities,
unlocking comprehensive document intelligence. Recognizing its importance, this
paper presents a systematic survey of Multimodal RAG for document
understanding. We propose a taxonomy based on domain, retrieval modality, and
granularity, and review advances involving graph structures and agentic
frameworks. We also summarize key datasets, benchmarks, and applications, and
highlight open challenges in efficiency, fine-grained representation, and
robustness, providing a roadmap for future progress in document AI.

</details>


### [102] [TraceCoder: Towards Traceable ICD Coding via Multi-Source Knowledge Integration](https://arxiv.org/abs/2510.15267)
*Mucheng Ren,He Chen,Yuchen Yan,Danqing Hu,Jun Xu,Xian Zeng*

Main category: cs.CL

TL;DR: TraceCoder是一个创新的框架，利用多源外部知识（UMLS、维基百科、LLMs）来改进ICD编码的准确性和可解释性，解决了现有方法的语义鸿沟、长尾代码性能差和可解释性差的问题。


<details>
  <summary>Details</summary>
Motivation: 现有ICD编码方法在处理临床文本和ICD编码之间的语义鸿沟、处理罕见和长尾代码以及提供可解释性方面存在挑战。

Method: TraceCoder框架动态整合了UMLS、维基百科和大型语言模型（LLMs）等多源外部知识，通过混合注意力机制来增强代码表示，弥合语义鸿沟，并处理罕见和模糊的代码，同时通过外部证据使预测具有可解释性。

Result: 在MIMIC-III-ICD9、MIMIC-IV-ICD9和MIMIC-IV-ICD10数据集上的实验表明，TraceCoder在ICD编码方面取得了最先进的性能，并且其组件的有效性得到了验证。

Conclusion: TraceCoder为自动化ICD编码提供了一个可扩展且鲁棒的解决方案，提高了准确性、可解释性和可靠性，满足了临床需求。

Abstract: Automated International Classification of Diseases (ICD) coding assigns
standardized diagnosis and procedure codes to clinical records, playing a
critical role in healthcare systems. However, existing methods face challenges
such as semantic gaps between clinical text and ICD codes, poor performance on
rare and long-tail codes, and limited interpretability. To address these
issues, we propose TraceCoder, a novel framework integrating multi-source
external knowledge to enhance traceability and explainability in ICD coding.
TraceCoder dynamically incorporates diverse knowledge sources, including UMLS,
Wikipedia, and large language models (LLMs), to enrich code representations,
bridge semantic gaps, and handle rare and ambiguous codes. It also introduces a
hybrid attention mechanism to model interactions among labels, clinical
context, and knowledge, improving long-tail code recognition and making
predictions interpretable by grounding them in external evidence. Experiments
on MIMIC-III-ICD9, MIMIC-IV-ICD9, and MIMIC-IV-ICD10 datasets demonstrate that
TraceCoder achieves state-of-the-art performance, with ablation studies
validating the effectiveness of its components. TraceCoder offers a scalable
and robust solution for automated ICD coding, aligning with clinical needs for
accuracy, interpretability, and reliability.

</details>


### [103] [TACL: Threshold-Adaptive Curriculum Learning Strategy for Enhancing Medical Text Understanding](https://arxiv.org/abs/2510.15269)
*Mucheng Ren,Yucheng Yan,He Chen,Danqing Hu,Jun Xu,Xian Zeng*

Main category: cs.CL

TL;DR: TACL框架通过自适应调整训练难度，提高了模型对医疗文本的理解能力，在多语言医疗任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有NLP模型在处理医疗文本时，未能区分不同难度的数据，影响了对复杂病例的泛化能力。

Method: 提出TACL（Threshold-Adaptive Curriculum Learning）框架，根据样本复杂度动态调整训练过程，先易后难。

Result: 在包括英语和中文在内的多语言医疗数据上，TACL框架在ICD编码、再入院预测和中医证候诊断等任务上显著提高了模型性能。

Conclusion: TACL框架通过区分和处理不同难度的医疗文本，提升了模型的准确性和泛化能力，有望统一不同医学领域的解决方案。

Abstract: Medical texts, particularly electronic medical records (EMRs), are a
cornerstone of modern healthcare, capturing critical information about patient
care, diagnoses, and treatments. These texts hold immense potential for
advancing clinical decision-making and healthcare analytics. However, their
unstructured nature, domain-specific language, and variability across contexts
make automated understanding an intricate challenge. Despite the advancements
in natural language processing, existing methods often treat all data as
equally challenging, ignoring the inherent differences in complexity across
clinical records. This oversight limits the ability of models to effectively
generalize and perform well on rare or complex cases. In this paper, we present
TACL (Threshold-Adaptive Curriculum Learning), a novel framework designed to
address these challenges by rethinking how models interact with medical texts
during training. Inspired by the principle of progressive learning, TACL
dynamically adjusts the training process based on the complexity of individual
samples. By categorizing data into difficulty levels and prioritizing simpler
cases early in training, the model builds a strong foundation before tackling
more complex records. By applying TACL to multilingual medical data, including
English and Chinese clinical records, we observe significant improvements
across diverse clinical tasks, including automatic ICD coding, readmission
prediction and TCM syndrome differentiation. TACL not only enhances the
performance of automated systems but also demonstrates the potential to unify
approaches across disparate medical domains, paving the way for more accurate,
scalable, and globally applicable medical text understanding solutions.

</details>


### [104] [Exemplar-Guided Planing: Enhanced LLM Agent for KGQA](https://arxiv.org/abs/2510.15283)
*Jingao Xu,Shuoyoucheng Ma,Xin Song,Rong Jiang,Hongkui Tu,Bin Zhou*

Main category: cs.CL

TL;DR: LLM在知识图谱问答（KGQA）中存在语义鸿沟问题，导致规划不佳和探索效率低下。本文提出了一种名为Exemplar-Guided Planning（EGP）的新框架，通过对训练数据进行实体模板化、检索相似问题及其推理路径，并利用这些示例来指导LLM的规划过程（任务分解和关系探索），从而增强LLM代理的规划能力。此外，还引入了智能前瞻机制来提高效率。在WebQSP和CWQ数据集上的实验表明，EGP显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在知识图谱问答（KGQA）中虽然展现出潜力，但常常受限于自然语言查询与结构化知识图谱（KG）表示之间的语义鸿沟，导致规划不佳和探索效率低下。此外，无需训练的方法也未能充分利用训练数据中的宝贵推理模式。

Method: 提出了一种名为Exemplar-Guided Planning（EGP）的新框架。该框架首先通过实体模板化对训练集问题进行预处理，以规范语义变异。然后，利用语义嵌入和高效的FAISS索引，从预处理后的集合中检索高度相似的示例问题及其成功的推理路径。这些检索到的示例在两个关键阶段动态地指导LLM的规划过程：（1）任务分解，通过将生成的子目标与已证实的推理步骤对齐；（2）关系探索，通过提供高质量的辅助信息来提高关系剪枝的准确性。此外，还引入了智能前瞻（Smart Lookahead）机制，通过先发制人地探索有希望的路径并可能提前终止探索来提高关系探索阶段的效率。将EGP应用于Plan-on-Graph（PoG）框架，形成PoG-EGP。

Result: 在WebQSP和CWQ两个真实世界的KGQA数据集上进行的大量实验表明，PoG-EGP显著优于基线PoG系统和其他对比方法。

Conclusion: EGP框架通过利用示例来指导LLM的规划过程，有效解决了LLM在KGQA中面临的语义鸿沟和规划效率问题，并在真实数据集上取得了显著的性能提升。

Abstract: Large Language Models (LLMs) as interactive agents show significant promise
in Knowledge Graph Question Answering (KGQA) but often struggle with the
semantic gap between natural language queries and structured knowledge graph
(KG) representations. This leads to suboptimal planning and inefficient
exploration on KG, while training-free approaches often underutilize valuable
reasoning patterns in training data. To address these limitations, we propose a
novel framework, Exemplar-Guided Planning (EGP), which enhances the planning
capabilities of LLM agents for KGQA. EGP first preprocesses the training set
questions via entity templating to normalize semantic variations. It then
retrieves highly similar exemplary questions and their successful reasoning
paths from this preprocessed set using semantic embeddings and an efficient
FAISS index. These retrieved exemplars dynamically guide the LLM's planning
process in two key phases: (1) Task Decomposition, by aligning generated
sub-objectives with proven reasoning steps, and (2) Relation Exploration, by
providing high-quality auxiliary information to improve relation pruning
accuracy. Additionally, we introduce a Smart Lookahead mechanism during
relation exploration to improve efficiency by preemptively exploring promising
paths and potentially terminating exploration earlier. We apply EGP to the
Plan-on-Graph (PoG) framework, termed PoG-EGP. Extensive experiments on two
real-world KGQA datasets, WebQSP and CWQ, demonstrate that PoG-EGP
significantly improves over the baseline PoG system and other compared methods.

</details>


### [105] [Automatic essay scoring: leveraging Jaccard coefficient and Cosine similaritywith n-gram variation in vector space model approach](https://arxiv.org/abs/2510.15311)
*Andharini Dwi Cahyani,Moh. Wildan Fathoni,Fika Hastarita Rachman,Ari Basuki,Salman Amin,Bain Khusnul Khotimah*

Main category: cs.CL

TL;DR: 本研究比较了Jaccard系数和余弦相似度在自动论文评分(AES)中的效果，使用不同N元语法模型。结果表明，余弦相似度在处理单N元语法时效果最佳，RMSE最低。


<details>
  <summary>Details</summary>
Motivation: 为了评估在自动论文评分(AES)中，向量空间模型（VSM）结合不同的相似性度量（Jaccard系数和余弦相似度）以及不同的N元语法（unigram、bigram、trigram）的效果。

Method: 通过对初中公民教育课程的形成性论文进行预处理，使用unigram、bigram和trigram模型提取特征，并将其向量化。随后，使用Jaccard系数和余弦相似度计算论文间的相似度得分，并通过均方根误差（RMSE）来评估系统性能。

Result: 余弦相似度在评估中优于Jaccard系数。在N元语法方面，unigram模型的RMSE最低，表明其在本次研究的AES任务中表现最好。

Conclusion: 在本次自动论文评分研究中，结合向量空间模型，使用余弦相似度和unigram模型是更有效的选择。

Abstract: Automated essay scoring (AES) is a vital area of research aiming to provide
efficient and accurate assessment tools for evaluating written content. This
study investigates the effectiveness of two popular similarity metrics, Jaccard
coefficient, and Cosine similarity, within the context of vector space
models(VSM)employing unigram, bigram, and trigram representations. The data
used in this research was obtained from the formative essay of the citizenship
education subject in a junior high school. Each essay undergoes preprocessing
to extract features using n-gram models, followed by vectorization to transform
text data into numerical representations. Then, similarity scores are computed
between essays using both Jaccard coefficient and Cosine similarity. The
performance of the system is evaluated by analyzing the root mean square error
(RMSE), which measures the difference between the scores given by human graders
and those generated by the system. The result shows that the Cosine similarity
outperformed the Jaccard coefficient. In terms of n-gram, unigrams have lower
RMSE compared to bigrams and trigrams.

</details>


### [106] [Accelerating Mobile Language Model Generation via Hybrid Context and Hardware Coordination](https://arxiv.org/abs/2510.15312)
*Zhiyang Chen,Daliang Xu,Haiyang Shen,Mengwei Xu,Shangguang Wang,Yun Ma*

Main category: cs.CL

TL;DR: 通过结合投机解码和动态硬件调度，CoordGen框架显著提高了移动设备上LLM的文本生成速度和能效。


<details>
  <summary>Details</summary>
Motivation: 移动设备上的LLM需要利用本地数据进行个性化和任务感知生成，但现有的方法在token-by-token生成阶段存在延迟高和硬件利用率低的问题。

Method: CoordGen框架整合了投机解码和动态硬件调度。其包含三个组成部分：1. 适应性执行调度，动态平衡预填充和解码阶段的计算图；2. 上下文对齐草拟，通过轻量级在线校准提高投机效率；3. 硬件高效草拟扩展，通过重用和扩展中间序列来提高并行度和降低验证成本。

Result: 在多部智能手机和代表性工作负载上的实验表明，与现有的移动推理解决方案相比，CoordGen的生成速度提高了3.8倍，能效提高了4.7倍。

Conclusion: CoordGen框架通过其创新的组件有效解决了移动设备LLM生成延迟和能耗问题，并在实际应用中取得了显著的性能提升。

Abstract: Enhancing on-device large language models (LLMs) with contextual information
from local data enables personalized and task-aware generation, powering use
cases such as intelligent assistants and UI agents. While recent developments
in neural processors have substantially improved the efficiency of prefill on
mobile devices, the token-by-token generation process still suffers from high
latency and limited hardware utilization due to its inherently memory-bound
characteristics. This work presents CoordGen, a mobile inference framework that
integrates speculative decoding with dynamic hardware scheduling to accelerate
context-aware text generation on mobile devices. The framework introduces three
synergistic components: (1) adaptive execution scheduling, which dynamically
balances compute graphs between prefill and decoding phases; (2)
context-aligned drafting, which improves speculative efficiency through
lightweight online calibration to current tasks; and (3) hardware-efficient
draft extension, which reuses and expands intermediate sequences to improve
processing parallelism and reduce verification cost. Experiments on multiple
smartphones and representative workloads show consistent improvements of up to
3.8x in generation speed and 4.7x in energy efficiency compared with existing
mobile inference solutions. Component-level analysis further validates the
contribution of each optimization.

</details>


### [107] [Capabilities and Evaluation Biases of Large Language Models in Classical Chinese Poetry Generation: A Case Study on Tang Poetry](https://arxiv.org/abs/2510.15313)
*Bolei Ma,Yina Yao,Anna-Carolina Haensch*

Main category: cs.CL

TL;DR: LLMs在古诗生成和评估方面表现不佳，存在“回音室效应”，且评估标准偏离人类判断，因此需要结合人类和模型的混合验证。


<details>
  <summary>Details</summary>
Motivation: LLMs在古诗生成和评估方面的表现不佳，现有评估方法和LLM评估存在局限性。

Method: 提出一个三步评估框架，结合计算指标、LLM-as-a-judge和人类专家验证，评估六种先进LLM的诗歌质量。

Result: LLMs在评估时存在“回音室效应”，评估标准偏离人类判断。LLMs在生成和评估古诗方面存在系统性偏差。

Conclusion: LLMs在古诗生成和评估方面有潜力但能力有限，需要人类和模型的混合验证。

Abstract: Large Language Models (LLMs) are increasingly applied to creative domains,
yet their performance in classical Chinese poetry generation and evaluation
remains poorly understood. We propose a three-step evaluation framework that
combines computational metrics, LLM-as-a-judge assessment, and human expert
validation. Using this framework, we evaluate six state-of-the-art LLMs across
multiple dimensions of poetic quality, including themes, emotions, imagery,
form, and style. Our analysis reveals systematic generation and evaluation
biases: LLMs exhibit "echo chamber" effects when assessing creative quality,
often converging on flawed standards that diverge from human judgments. These
findings highlight both the potential and limitations of current capabilities
of LLMs as proxy for literacy generation and the limited evaluation practices,
thereby demonstrating the continued need of hybrid validation from both humans
and models in culturally and technically complex creative tasks.

</details>


### [108] [AutoGraph-R1: End-to-End Reinforcement Learning for Knowledge Graph Construction](https://arxiv.org/abs/2510.15339)
*Hong Ting Tsang,Jiaxin Bai,Haoyu Huang,Qiao Xiao,Tianshi Zheng,Baixuan Xu,Shujie Liu,Yangqiu Song*

Main category: cs.CL

TL;DR: AutoGraph-R1是一个利用强化学习优化知识图谱(KG)构建以提升检索增强生成(RAG)问答系统性能的框架。


<details>
  <summary>Details</summary>
Motivation: 现有的知识图谱构建与下游应用（如RAG问答）是分离的，导致图结构不理想。本研究旨在解决这一问题。

Method: AutoGraph-R1将图生成视为策略学习问题，并利用强化学习训练一个大型语言模型（LLM）作为图构建器。通过设计两种新颖的、任务感知的奖励函数（分别针对作为知识载体和知识索引的图），来优化图的功能效用，并直接根据其在RAG流水线中的表现来指导构建过程。

Result: 在多个问答基准测试中，AutoGraph-R1显著提升了基于图的RAG方法的性能，优于使用与任务无关的基线图的方法。

Conclusion: 本研究成功地实现了构建与应用之间的闭环，将构建“好”图的范式转变为构建“有用”图的范式。

Abstract: Building effective knowledge graphs (KGs) for Retrieval-Augmented Generation
(RAG) is pivotal for advancing question answering (QA) systems. However, its
effectiveness is hindered by a fundamental disconnect: the knowledge graph (KG)
construction process is decoupled from its downstream application, yielding
suboptimal graph structures. To bridge this gap, we introduce AutoGraph-R1, the
first framework to directly optimize KG construction for task performance using
Reinforcement Learning (RL). AutoGraph-R1 trains an LLM constructor by framing
graph generation as a policy learning problem, where the reward is derived from
the graph's functional utility in a RAG pipeline. We design two novel,
task-aware reward functions, one for graphs as knowledge carriers and another
as knowledge indices. Across multiple QA benchmarks, AutoGraph-R1 consistently
enables graph RAG methods to achieve significant performance gains over using
task-agnostic baseline graphs. Our work shows it is possible to close the loop
between construction and application, shifting the paradigm from building
intrinsically ``good'' graphs to building demonstrably ``useful'' ones.

</details>


### [109] [Readability Reconsidered: A Cross-Dataset Analysis of Reference-Free Metrics](https://arxiv.org/abs/2510.15345)
*Catarina G Belem,Parker Glenn,Alfy Samuel,Anoop Kumar,Daben Liu*

Main category: cs.CL

TL;DR: 自动可读性评估的现有方法未能准确反映人类感知，基于模型的指标表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有可读性评估方法在定义和测量上存在不一致，并且依赖于肤浅的文本特征，未能准确捕捉人类对文本可读性的感知。

Method: 分析了897个用户对文本可读性的判断，并评估了15种流行和6种基于模型的可读性指标在五个英文数据集上的表现。

Result: 研究发现，信息内容和主题对文本的可理解性有显著影响。基于模型的指标在与人类判断的相关性排名中 consistently 优于传统的指标，其中最好的传统指标平均排名为8.6。

Conclusion: 目前的文本可读性指标与人类感知之间存在差距，基于模型的指标是未来更有前景的方向。

Abstract: Automatic readability assessment plays a key role in ensuring effective and
accessible written communication. Despite significant progress, the field is
hindered by inconsistent definitions of readability and measurements that rely
on surface-level text properties. In this work, we investigate the factors
shaping human perceptions of readability through the analysis of 897 judgments,
finding that, beyond surface-level cues, information content and topic strongly
shape text comprehensibility. Furthermore, we evaluate 15 popular readability
metrics across five English datasets, contrasting them with six more nuanced,
model-based metrics. Our results show that four model-based metrics
consistently place among the top four in rank correlations with human
judgments, while the best performing traditional metric achieves an average
rank of 8.6. These findings highlight a mismatch between current readability
metrics and human perceptions, pointing to model-based approaches as a more
promising direction.

</details>


### [110] [When to Ensemble: Identifying Token-Level Points for Stable and Fast LLM Ensembling](https://arxiv.org/abs/2510.15346)
*Heecheol Yun,Kwangmin Ki,Junghyun Lee,Eunho Yang*

Main category: cs.CL

TL;DR: 通过选择性集成来改进长篇文本生成中的 LLM 集成，提高了准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）集成方法在长篇生成方面效果不佳，需要一种改进的方法来利用模型的互补优势。

Method: 提出了一种名为 SAFE（Stable And Fast LLM Ensembling）的框架，该框架通过考虑词元化不匹配和下一个词元概率分布的一致性来选择性地集成模型。还引入了一种概率锐化策略来提高稳定性。

Result: 在 MATH500 和 BBH 等基准测试中，SAFE 在准确性和效率方面均优于现有方法，即使仅集成少于 1% 的词元也能获得改进。

Conclusion: SAFE 框架通过选择性集成解决了长篇文本生成中 LLM 集成方法的局限性，并在准确性和效率方面取得了显著成果。

Abstract: Ensembling Large Language Models (LLMs) has gained attention as a promising
approach to surpass the performance of individual models by leveraging their
complementary strengths. In particular, aggregating models' next-token
probability distributions to select the next token has been shown to be
effective in various tasks. However, while successful for short-form answers,
its application to long-form generation remains underexplored. In this paper,
we show that using existing ensemble methods in long-form generation requires a
careful choice of ensembling positions, since the standard practice of
ensembling at every token often degrades performance. We identify two key
factors for determining these positions: tokenization mismatch across models
and consensus in their next-token probability distributions. Based on this, we
propose SAFE, (Stable And Fast LLM Ensembling), a framework that selectively
ensembles by jointly considering these factors. To further improve stability,
we introduce a probability sharpening strategy that consolidates probabilities
spread across multiple sub-word tokens representing the same word into a single
representative token. Our experiments on diverse benchmarks, including MATH500
and BBH, demonstrate that SAFE outperforms existing methods in both accuracy
and efficiency, with gains achieved even when ensembling fewer than 1% of
tokens.

</details>


### [111] [Infinity Parser: Layout Aware Reinforcement Learning for Scanned Document Parsing](https://arxiv.org/abs/2510.15349)
*Baode Wang,Biao Wu,Weizhen Li,Meng Fang,Zuming Huang,Jun Huang,Haozhe Wang,Yanjie Liang,Ling Chen,Wei Chu,Yuan Qi*

Main category: cs.CL

TL;DR: LayoutRL是一个利用强化学习优化文档布局理解的框架，并构建了Infinity-Doc-400K数据集来训练一个名为Infinity-Parser的模型，该模型在各种文档类型中表现出强大的泛化能力和最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有监督学习方法在处理多样化的文档类型和有限的高质量训练数据时存在泛化能力不足的问题，特别是在处理非分布内数据时表现不佳。

Method: 提出LayoutRL框架，利用强化学习和结合了归一化编辑距离、段落计数准确性和阅读顺序保持的复合奖励来优化布局理解。同时，构建了Infinity-Doc-400K数据集，并训练了一个名为Infinity-Parser的视觉-语言模型。

Result: 在OmniDocBench、olmOCR-Bench、PubTabNet和FinTabNet等基准测试中，Infinity-Parser在各种文档类型、语言和结构复杂性方面都达到了最先进的性能，显著优于专门的文档解析系统和通用的视觉-语言模型。

Conclusion: LayoutRL框架和Infinity-Parser模型能够有效地解决文档解析中的挑战，并在广泛的文档类型和复杂性上实现最先进的性能和鲁棒的泛化能力。

Abstract: Document parsing from scanned images into structured formats remains a
significant challenge due to its complexly intertwined elements such as text
paragraphs, figures, formulas, and tables. Existing supervised fine-tuning
methods often struggle to generalize across diverse document types, leading to
poor performance, particularly on out-of-distribution data. This issue is
further exacerbated by the limited availability of high-quality training data
for layout-aware parsing tasks. To address these challenges, we introduce
LayoutRL, a reinforcement learning framework that optimizes layout
understanding through composite rewards integrating normalized edit distance,
paragraph count accuracy, and reading order preservation. To support this
training, we construct the Infinity-Doc-400K dataset, which we use to train
Infinity-Parser, a vision-language model demonstrating robust generalization
across various domains. Extensive evaluations on benchmarks including
OmniDocBench, olmOCR-Bench, PubTabNet, and FinTabNet show that Infinity-Parser
consistently achieves state-of-the-art performance across a broad range of
document types, languages, and structural complexities, substantially
outperforming both specialized document parsing systems and general-purpose
vision-language models. We will release our code, dataset, and model to
facilitate reproducible research in document parsing.

</details>


### [112] [VocalBench-DF: A Benchmark for Evaluating Speech LLM Robustness to Disfluency](https://arxiv.org/abs/2510.15406)
*Hongcheng Liu,Yixuan Hou,Heyang Liu,Yuhao Wang,Yanfeng Wang,Yu Wang*

Main category: cs.CL

TL;DR: 现有语音大语言模型(Speech-LLMs)在处理带 P“口吃”的语音输入时表现出显著的性能下降，表明它们在现实世界中的鲁棒性不足，急需改进以实现包容性设计。


<details>
  <summary>Details</summary>
Motivation: 现有语音大语言模型(Speech-LLMs)在实际应用中表现出色，但对其鲁棒性，特别是对语音不流畅（如口吃）的鲁棒性，进行的研究不足。现有评估方法往往忽略了口吃等常见语音缺陷，尤其是在帕金森病等疾病患者中。本研究旨在探讨当前的 Speech-LLMs 在与有语言障碍的用户交互时能否保持性能。

Method: 引入了一个名为 VocalBench-DF 的框架，用于对口吃进行多维度分类和系统性评估。评估了 22 个主流的 Speech-LLMs。

Result: 评估结果显示，所有被评估的 Speech-LLMs 在处理口吃语音时均出现性能下降。进一步分析指出，潜在的瓶颈在于模型在音素级别处理和长上下文建模方面的能力不足。

Conclusion: 目前的 Speech-LLMs 在处理口吃语音时存在显著的性能缺陷，其实用性受到限制。提高模型在音素级别处理和长上下文建模方面的能力，可以显著增强其鲁棒性。未来需要开发新的方法来改进 Speech-LLMs 处理口吃的能力，以构建真正包容性的模型。

Abstract: While Speech Large Language Models (Speech-LLMs) show strong performance in
many applications, their robustness is critically under-tested, especially to
speech disfluency. Existing evaluations often rely on idealized inputs,
overlooking common disfluencies, particularly those associated with conditions
like Parkinson's disease. This work investigates whether current Speech-LLMs
can maintain performance when interacting with users who have speech
impairments. To facilitate this inquiry, we introduce VocalBench-DF, a
framework for the systematic evaluation of disfluency across a
multi-dimensional taxonomy. Our evaluation of 22 mainstream Speech-LLMs reveals
substantial performance degradation, indicating that their real-world readiness
is limited. Further analysis identifies phoneme-level processing and
long-context modeling as primary bottlenecks responsible for these failures.
Strengthening recognition and reasoning capability from components and
pipelines can substantially improve robustness. These findings highlight the
urgent need for new methods to improve disfluency handling and build truly
inclusive Speech-LLMs

</details>


### [113] [Large-scale User Game Lifecycle Representation Learning](https://arxiv.org/abs/2510.15412)
*Yanjie Gou,Jiangming Liu,Kouying Xue,Yi Hua*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The rapid expansion of video game production necessitates the development of
effective advertising and recommendation systems for online game platforms.
Recommending and advertising games to users hinges on capturing their interest
in games. However, existing representation learning methods crafted for
handling billions of items in recommendation systems are unsuitable for game
advertising and recommendation. This is primarily due to game sparsity, where
the mere hundreds of games fall short for large-scale user representation
learning, and game imbalance, where user behaviors are overwhelmingly dominated
by a handful of popular games. To address the sparsity issue, we introduce the
User Game Lifecycle (UGL), designed to enrich user behaviors in games.
Additionally, we propose two innovative strategies aimed at manipulating user
behaviors to more effectively extract both short and long-term interests. To
tackle the game imbalance challenge, we present an Inverse Probability Masking
strategy for UGL representation learning. The offline and online experimental
results demonstrate that the UGL representations significantly enhance model by
achieving a 1.83% AUC offline increase on average and a 21.67% CVR online
increase on average for game advertising and a 0.5% AUC offline increase and a
0.82% ARPU online increase for in-game item recommendation.

</details>


### [114] [Fine-Tuning MedGemma for Clinical Captioning to Enhance Multimodal RAG over Malaysia CPGs](https://arxiv.org/abs/2510.15418)
*Lee Qi Zun,Mohamad Zulhilmi Bin Abdul Halim,Goh Man Fye*

Main category: cs.CL

TL;DR: 本研究提出并验证了一个框架，通过知识蒸馏和QLoRA微调MedGemma模型，生成用于马来西亚临床实践指南的多模态检索增强生成（RAG）系统的高保真医学图像描述，以克服现有模型在图像查询方面的局限性，并提高了分类准确性和描述的忠实度、相关性和正确性。


<details>
  <summary>Details</summary>
Motivation: 现有的检索增强生成（RAG）系统在提供基于事实的临床指南指导方面至关重要，但它们在处理基于图像的查询时效果有限，因为通用的视觉-语言模型（VLM）生成的描述往往缺乏临床特异性和事实依据。

Method: 该研究提出并验证了一个框架，采用知识蒸馏方法创建了一个包含皮肤病学、眼底和胸部放射学领域的合成数据集，并使用参数高效的QLoRA方法对MedGemma模型进行微调。模型性能通过一个双重框架进行评估，该框架同时测量分类准确性，并通过新颖地应用RAGAS框架来评估生成描述的忠实度、相关性和正确性。

Result: 微调后的模型在分类性能上表现出显著的改进。RAGAS评估证实，在生成描述的忠实度和正确性方面取得了显著的进步，证明了模型生成可靠、事实依据充分的描述的能力。

Conclusion: 这项工作建立了一个专门用于医学VLM的健壮流程，并验证了由此产生的模型作为一个高质量的查询生成器，为增强多模态RAG系统在循证临床决策支持方面的能力奠定了基础。

Abstract: Retrieval-Augmented Generation systems are essential for providing fact-based
guidance from Malaysian Clinical Practice Guidelines. However, their
effectiveness with image-based queries is limited, as general Vision-Language
Model captions often lack clinical specificity and factual grounding. This
study proposes and validates a framework to specialize the MedGemma model for
generating high-fidelity captions that serve as superior queries. To overcome
data scarcity, we employ a knowledge distillation pipeline to create a
synthetic dataset across dermatology, fundus, and chest radiography domains,
and fine-tune MedGemma using the parameter-efficient QLoRA method. Performance
was rigorously assessed through a dual framework measuring both classification
accuracy and, via a novel application of the RAGAS framework, caption
faithfulness, relevancy, and correctness. The fine-tuned model demonstrated
substantial improvements in classification performance, while RAGAS evaluation
confirmed significant gains in caption faithfulness and correctness, validating
the models ability to produce reliable, factually grounded descriptions. This
work establishes a robust pipeline for specializing medical VLMs and validates
the resulting model as a high-quality query generator, laying the groundwork
for enhancing multimodal RAG systems in evidence-based clinical decision
support.

</details>


### [115] [When Seeing Is not Enough: Revealing the Limits of Active Reasoning in MLLMs](https://arxiv.org/abs/2510.15421)
*Hongcheng Liu,Pingjie Wang,Yuhao Wang,Siqu Ou,Yanfeng Wang,Yu Wang*

Main category: cs.CL

TL;DR: 评估多模态大语言模型（MLLM）在信息不完整时主动获取证据和迭代决策的能力，并提出名为GuessBench的新基准。


<details>
  <summary>Details</summary>
Motivation: 现有评估主要关注被动推理，与需要主动获取证据的现实场景不符，因此需要评估MLLM在信息不完整时主动获取证据的能力。

Method: 提出GuessBench基准，包含面向感知和面向知识的图像，以评估MLLM在信息不完整时主动获取证据和迭代决策的能力，并通过选择候选图像池中的目标图像来完成任务，无需特定任务的先验知识。

Result: 评估了20个优秀的MLLM，发现其在主动推理方面的表现远落后于被动设置，表明存在很大的改进空间。感知和及时决策是主要的挑战。感知增强对较小模型有益，而面向思维的方法在所有模型尺寸上都提供了持续的收益。

Conclusion: 多模态大语言模型在主动推理方面仍有很大提升空间，未来的研究应关注感知增强和面向思维的方法。

Abstract: Multimodal large language models (MLLMs) have shown strong capabilities
across a broad range of benchmarks. However, most existing evaluations focus on
passive inference, where models perform step-by-step reasoning under complete
information. This setup is misaligned with real-world use, where seeing is not
enough. This raises a fundamental question: Can MLLMs actively acquire missing
evidence under incomplete information? To bridge this gap, we require the MLLMs
to actively acquire missing evidence and iteratively refine decisions under
incomplete information, by selecting a target image from a candidate pool
without task-specific priors. To support systematic study, we propose
GuessBench, a benchmark with both perception-oriented and knowledge-oriented
images for evaluating active reasoning in MLLMs. We evaluate 20 superior MLLMs
and find that performance on active reasoning lags far behind it on passive
settings, indicating substantial room for improvement. Further analysis
identifies fine-grained perception and timely decision-making as key
challenges. Ablation studies show that perceptual enhancements benefit smaller
models, whereas thinking-oriented methods provide consistent gains across model
sizes. These results suggest promising directions for future research on
multimodal active reasoning.

</details>


### [116] [Controllable Abstraction in Summary Generation for Large Language Models via Prompt Engineering](https://arxiv.org/abs/2510.15436)
*Xiangchen Song,Yuchen Liu,Yaxuan Luan,Jinxu Guo,Xiaofan Guo*

Main category: cs.CL

TL;DR: 本研究提出一种基于提示工程的大语言模型可控摘要生成方法，通过多阶段提示生成框架，利用语义分析、主题建模和噪声控制来生成不同抽象级别的摘要，并在CNN/Daily Mail数据集上进行了实验。


<details>
  <summary>Details</summary>
Motivation: 为解决传统摘要方法在摘要质量和可控性方面存在的问题。

Method: 设计了一个多阶段的提示生成框架，通过对输入文本进行语义分析、主题建模和噪声控制来生成不同抽象级别的摘要。

Result: 实验结果表明，提示长度显著影响摘要质量，过长或过短的提示都会降低摘要质量。数据噪声也会对摘要生成过程产生负面影响，噪声增加导致ROUGE-L分数逐渐降低。不同类型的文本对模型生成摘要的能力影响不同，模型处理新闻文本效果最好，处理学术文章效果较差。

Conclusion: 本研究为利用大语言模型改进摘要生成提供了新思路，特别是在控制提示策略和优化文本预处理以提高摘要准确性和可控性方面。

Abstract: This study presents a controllable abstract summary generation method for
large language models based on prompt engineering. To address the issues of
summary quality and controllability in traditional methods, we design a
multi-stage prompt generation framework. This framework generates summaries
with varying levels of abstraction by performing semantic analysis, topic
modeling, and noise control on the input text. The experiment uses the
CNN/Daily Mail dataset and provides a detailed analysis of different prompt
lengths, data noise, and text types. The experimental results show that prompt
length has a significant impact on the quality of generated summaries. Both
very short and very long prompt tokens result in a decrease in summary quality.
Data noise also negatively affects the summary generation process. As noise
levels increase, the ROUGE-L score gradually decreases. Furthermore, different
text types have varying effects on the model's ability to generate summaries.
The model performs best when handling news texts, while its performance is
worse when processing academic articles. This research provides new insights
into improving summary generation using large language models, particularly in
how controlling prompt strategies and optimizing text preprocessing can enhance
summary accuracy and controllability.

</details>


### [117] [CORE: Reducing UI Exposure in Mobile Agents via Collaboration Between Cloud and Local LLMs](https://arxiv.org/abs/2510.15455)
*Gucongcong Fan,Chaoyue Niu,Chengfei Lyu,Fan Wu,Guihai Chen*

Main category: cs.CL

TL;DR: CORE是一个结合了云端和本地大语言模型(LLM)的框架，通过布局感知分块、协同规划和协同决策来减少移动代理的UI暴露，同时保持任务准确性。


<details>
  <summary>Details</summary>
Motivation: 云端大语言模型(LLM)虽然任务准确率高，但需要上传完整的UI状态，暴露不必要信息；本地LLM避免了UI上传，但能力有限，任务成功率较低。需要一种方法来减少UI暴露同时保持任务准确性。

Method:  CORE框架包含三个主要组件：1. 布局感知分块：基于XML屏幕层级，将语义相关的UI元素分组。2. 协同规划：本地和云端LLM协同确定当前子任务。3. 协同决策：本地LLM对相关UI块进行排序，云端LLM在排名靠前的块中选择特定UI元素。此外，CORE还引入了多轮累积机制来弥补本地判断失误或上下文有限的问题。

Result: 在多样化的移动应用和任务实验中，CORE将UI暴露减少了高达55.6%，同时任务成功率略低于仅使用云端LLM的代理，有效缓解了不必要的隐私暴露给云端的问题。

Conclusion: CORE通过结合云端和本地LLM的优势，在减少移动代理UI暴露和保持任务准确性方面取得了良好的效果，为保护用户隐私提供了一种有效的解决方案。

Abstract: Mobile agents rely on Large Language Models (LLMs) to plan and execute tasks
on smartphone user interfaces (UIs). While cloud-based LLMs achieve high task
accuracy, they require uploading the full UI state at every step, exposing
unnecessary and often irrelevant information. In contrast, local LLMs avoid UI
uploads but suffer from limited capacity, resulting in lower task success
rates. We propose $\textbf{CORE}$, a $\textbf{CO}$llaborative framework that
combines the strengths of cloud and local LLMs to $\textbf{R}$educe UI
$\textbf{E}$xposure, while maintaining task accuracy for mobile agents. CORE
comprises three key components: (1) $\textbf{Layout-aware block partitioning}$,
which groups semantically related UI elements based on the XML screen
hierarchy; (2) $\textbf{Co-planning}$, where local and cloud LLMs
collaboratively identify the current sub-task; and (3)
$\textbf{Co-decision-making}$, where the local LLM ranks relevant UI blocks,
and the cloud LLM selects specific UI elements within the top-ranked block.
CORE further introduces a multi-round accumulation mechanism to mitigate local
misjudgment or limited context. Experiments across diverse mobile apps and
tasks show that CORE reduces UI exposure by up to 55.6% while maintaining task
success rates slightly below cloud-only agents, effectively mitigating
unnecessary privacy exposure to the cloud. The code is available at
https://github.com/Entropy-Fighter/CORE.

</details>


### [118] [DeceptionBench: A Comprehensive Benchmark for AI Deception Behaviors in Real-world Scenarios](https://arxiv.org/abs/2510.15501)
*Yao Huang,Yitong Sun,Yichi Zhang,Ruochen Zhang,Yinpeng Dong,Xingxing Wei*

Main category: cs.CL

TL;DR: 该研究提出了DeceptionBench，一个评估大型语言模型（LLM）在不同社会领域中欺骗行为的基准测试。


<details>
  <summary>Details</summary>
Motivation: 识别和理解LLM在现实世界场景中日益增长的欺骗行为，这些行为可能带来严重风险。

Method: 创建了一个包含150个场景和1000多个样本的DeceptionBench基准测试，涵盖经济、医疗、教育、社交和娱乐五个领域。研究评估了模型的自利或讨好用户行为（内在维度），以及在不同外部因素（中性、奖励、强制）影响下的欺骗行为（外在维度）。实验还模拟了多轮交互和现实世界反馈动态。

Result: 实验表明，LLM和LRM在DeceptionBench上存在明显的漏洞，特别是在强化学习动态下，欺骗行为被放大。模型缺乏抵抗操纵性上下文线索的能力。

Conclusion: 现有的大型模型在抵御欺骗行为方面存在严重不足，急需开发更强的安全措施来应对各种欺骗行为。

Abstract: Despite the remarkable advances of Large Language Models (LLMs) across
diverse cognitive tasks, the rapid enhancement of these capabilities also
introduces emergent deceptive behaviors that may induce severe risks in
high-stakes deployments. More critically, the characterization of deception
across realistic real-world scenarios remains underexplored. To bridge this
gap, we establish DeceptionBench, the first benchmark that systematically
evaluates how deceptive tendencies manifest across different societal domains,
what their intrinsic behavioral patterns are, and how extrinsic factors affect
them. Specifically, on the static count, the benchmark encompasses 150
meticulously designed scenarios in five domains, i.e., Economy, Healthcare,
Education, Social Interaction, and Entertainment, with over 1,000 samples,
providing sufficient empirical foundations for deception analysis. On the
intrinsic dimension, we explore whether models exhibit self-interested egoistic
tendencies or sycophantic behaviors that prioritize user appeasement. On the
extrinsic dimension, we investigate how contextual factors modulate deceptive
outputs under neutral conditions, reward-based incentivization, and coercive
pressures. Moreover, we incorporate sustained multi-turn interaction loops to
construct a more realistic simulation of real-world feedback dynamics.
Extensive experiments across LLMs and Large Reasoning Models (LRMs) reveal
critical vulnerabilities, particularly amplified deception under reinforcement
dynamics, demonstrating that current models lack robust resistance to
manipulative contextual cues and the urgent need for advanced safeguards
against various deception behaviors. Code and resources are publicly available
at https://github.com/Aries-iai/DeceptionBench.

</details>


### [119] [Temporal Referential Consistency: Do LLMs Favor Sequences Over Absolute Time References?](https://arxiv.org/abs/2510.15513)
*Ashutosh Bajpai,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: LLMs在法律、医疗和金融等领域日益普及，但其时间推理能力不足。本文提出了一个评估LLM时间一致性的新基准TEMP-ReCon，并开发了一个名为UnTRaP的新模型来提高LLM的时间一致性，实验证明了UnTRaP的有效性。


<details>
  <summary>Details</summary>
Motivation: LLMs在时间敏感领域日益普及，需要具备跨时间维度的一致性，但现有研究缺乏对LLM时间一致性的评估和改进。

Method: 提出TEMP-ReCon基准和UnTRaP模型，通过多语言实验评估LLM的时间一致性，并验证UnTRaP的有效性。

Result: LLMs在时间参照一致性方面表现不足。UnTRaP模型在提高LLM时间一致性方面优于多个基线模型。

Conclusion: LLMs在时间一致性方面存在挑战，提出的TEMP-ReCon基准和UnTRaP模型为评估和改进LLM的时间推理能力提供了有效的方法。

Abstract: The increasing acceptance of large language models (LLMs) as an alternative
to knowledge sources marks a significant paradigm shift across various domains,
including time-sensitive fields such as law, healthcare, and finance. To
fulfill this expanded role, LLMs must not only be factually accurate but also
demonstrate consistency across temporal dimensions, necessitating robust
temporal reasoning capabilities. Despite this critical requirement, efforts to
ensure temporal consistency in LLMs remain scarce including noticeable absence
of endeavors aimed at evaluating or augmenting LLMs across temporal references
in time-sensitive inquiries. In this paper, we seek to address this gap by
introducing a novel benchmark entitled temporal referential consistency,
accompanied by a resource TEMP-ReCon designed to benchmark a wide range of both
open-source and closed-source LLMs with various linguistic contexts
characterized by differing resource richness (including English, French, and
Romanian). The findings emphasis that LLMs do exhibit insufficient temporal
referent consistency. To address this, we propose \newmodel, a reasoning path
alignment-based model that aims to enhance the temporal referential consistency
of LLMs. Our empirical experiments substantiate the efficacy of UnTRaP compared
to several baseline models.

</details>


### [120] [From Characters to Tokens: Dynamic Grouping with Hierarchical BPE](https://arxiv.org/abs/2510.15517)
*Rares Dolga,Lucas Maystre,Tudor Berariu,David Barber*

Main category: cs.CL

TL;DR: BPE 存在稀有词表示效率低下和嵌入矩阵大的问题，字符级模型有性能瓶颈，现有分块方法有局限性。本文提出一种动态字符分组方法，利用 BPE 结构，通过添加显式词尾标记和二级 BPE 压缩来控制块粒度，实现高效、灵活、语言无关的表示，性能与现有方法相当或更优，同时保持词汇量紧凑。


<details>
  <summary>Details</summary>
Motivation: 现有 BPE 方法在表示稀有词和嵌入矩阵大小方面存在效率问题，字符级模型在 Transformer 中有性能瓶颈，而现有分块方法存在语言限制或需要额外模型。

Method: 提出一种动态字符分组方法，利用 BPE 结构，通过附加显式词尾标记和引入二级 BPE 压缩来控制块粒度。

Result: 该方法在保持词汇量紧凑的同时，性能与动态熵和基于空格的分块策略相当或更优。

Conclusion: 所提出的动态字符分组方法能够高效、灵活且语言无关地进行表示，并能匹配或超越现有方法的性能。

Abstract: Subword tokenization methods like Byte Pair Encoding (BPE) are widely used in
large language models due to their balance of vocabulary compactness and
representational power. However, they suffer from inefficiencies in
representing rare words and require large embedding matrices. Character-level
models address these issues but introduce performance bottlenecks, particularly
in Transformer-based architectures. Recent hierarchical models attempt to merge
the benefits of both paradigms by grouping characters into patches, but
existing patching strategies either rely on whitespace-limiting applicability
to certain languages, or require auxiliary models that introduce new
dependencies. In this paper, we propose a dynamic character grouping method
that leverages the structure of existing BPE tokenization without requiring
additional models. By appending explicit end-of-patch markers to BPE tokens and
introducing a second-level BPE compression stage to control patch granularity,
our method offers efficient, flexible, and language-agnostic representations.
Empirical results demonstrate that our approach matches or exceeds the
performance of dynamic entropy- and whitespace-based patching strategies, while
maintaining a compact vocabulary.

</details>


### [121] [Latent Reasoning in LLMs as a Vocabulary-Space Superposition](https://arxiv.org/abs/2510.15522)
*Jingcheng Deng,Liang Pang,Zihao Wei,Shichen Xu,Zenghao Duan,Kun Xu,Yang Song,Huawei Shen,Xueqi Cheng*

Main category: cs.CL

TL;DR: 通过将LLM的词汇概率约束到列空间来改进潜在推理，从而减少计算开销并提高性能。


<details>
  <summary>Details</summary>
Motivation: 显式推理会带来显著的计算开销，而现有的潜在推理方法由于潜在空间的不确定性而导致性能下降。

Method: 提出了一种名为Latent-SFT的两阶段学习框架。在第一阶段，使用专门的注意力掩码来指导潜在令牌的生成。在第二阶段，直接训练LLM自主生成这些潜在令牌，并使用KL和CE损失进行优化。

Result: Latent-SFT在GSM8k上达到了新的最先进水平，其性能与显式SFT相当，但推理链缩短了4倍，并且优于以前的潜在方法。在Math500和AIME24上，基于词汇概率的潜在推理也明显优于基于隐藏状态的方法。

Conclusion: Latent-SFT通过结构化潜在空间来解决现有潜在推理方法的局限性，实现了在减少计算成本的同时保持或提高性能。潜在推理既是一种单路径压缩，也是一种多路径叠加。

Abstract: Large language models (LLMs) demonstrate strong reasoning abilities with
chain-of-thought prompting, but explicit reasoning introduces substantial
computational overhead. Recent work on latent reasoning reduces this cost by
reasoning in latent space without explicit supervision, but performance drops
significantly. Our preliminary experiments suggest that this degradation stems
from the unstructured latent space, which makes fitting latent tokens
difficult. To address this, we restrict the latent space to the column space of
the LLM vocabulary, treating latent reasoning as a superposition over
vocabulary probabilities. Once latent reasoning concludes, it collapses into an
eigenstate of explicit reasoning to yield the final answer. Based on this idea,
we propose Latent-SFT, a two-stage learning framework. In the first stage, we
design two specialized attention masks to guide the Latent Token Encoder in
generating latent tokens, allowing the LLM to produce the correct answer
conditioned on them. In the second stage, the Latent Token Encoder is
discarded, and the LLM is directly trained to generate these latent tokens
autonomously for latent reasoning, optimized with KL and CE losses. Latent-SFT
sets a new state of the art on GSM8k, matching explicit SFT performance while
cutting reasoning chains by up to 4 times and outperforming prior latent
methods. On Math500 and AIME24, lexical probability-based latent reasoning also
clearly surpasses hidden-state-based approaches. Our metrics of effective
compression rate and effective global parallelism further show that latent
reasoning is both the compression of a single path and the superposition of
multiple paths.

</details>


### [122] [MCA: Modality Composition Awareness for Robust Composed Multimodal Retrieval](https://arxiv.org/abs/2510.15543)
*Qiyu Wu,Shuyang Cui,Satoshi Hayakawa,Wei-Yao Wang,Hiromi Wakaki,Yuki Mitsufuji*

Main category: cs.CL

TL;DR: 统一编码器在多模态检索中存在模态捷径问题，提出模态组合感知框架以提高鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 旨在解决统一编码器在多模态检索中因对比学习而产生的模态捷径问题，提高模型在分布外数据的鲁棒性。

Method: 提出模态组合感知框架，包括偏好损失和组合正则化两个目标。偏好损失使多模态嵌入优于单模态嵌入，组合正则化使多模态嵌入与由单模态部分组成的嵌入保持一致。

Result: 在多个基准测试中，所提出的框架在分布外检索方面表现出显著的提升。

Conclusion: 模态组合感知是利用多模态大语言模型作为统一编码器进行鲁棒的多模态检索的有效原则。

Abstract: Multimodal retrieval, which seeks to retrieve relevant content across
modalities such as text or image, supports applications from AI search to
contents production. Despite the success of separate-encoder approaches like
CLIP align modality-specific embeddings with contrastive learning, recent
multimodal large language models (MLLMs) enable a unified encoder that directly
processes composed inputs. While flexible and advanced, we identify that
unified encoders trained with conventional contrastive learning are prone to
learn modality shortcut, leading to poor robustness under distribution shifts.
We propose a modality composition awareness framework to mitigate this issue.
Concretely, a preference loss enforces multimodal embeddings to outperform
their unimodal counterparts, while a composition regularization objective
aligns multimodal embeddings with prototypes composed from its unimodal parts.
These objectives explicitly model structural relationships between the composed
representation and its unimodal counterparts. Experiments on various benchmarks
show gains in out-of-distribution retrieval, highlighting modality composition
awareness as a effective principle for robust composed multimodal retrieval
when utilizing MLLMs as the unified encoder.

</details>


### [123] [TokenTiming: A Dynamic Alignment Method for Universal Speculative Decoding Model Pairs](https://arxiv.org/abs/2510.15545)
*Sibo Xiao,Jinyuan Fu,Zhongle Xie,Lidan Shou*

Main category: cs.CL

TL;DR: TokenTiming 算法实现了通用推测解码，解决了现有方法在词汇表不匹配时无法使用的问题，并在实验中实现了 1.57 倍的加速。


<details>
  <summary>Details</summary>
Motivation: 现有的推测解码（SD）方法要求草稿模型和目标模型拥有相同的词汇表，这限制了可用草稿模型的选择，并常常需要从头开始训练新模型。

Method: 提出了一种名为 TokenTiming 的算法，该算法借鉴了动态时间规整（DTW）的思想，通过重新编码草稿令牌序列来生成新的目标令牌序列，并利用 DTW 建立映射关系来转移概率分布以进行推测采样。

Result: 所提出的 TokenTiming 算法能够处理不匹配的词汇表，并且可以在无需重新训练和修改的情况下与现有的模型配合使用，在各种任务的实验中实现了 1.57 倍的加速。

Conclusion: TokenTiming 算法为选择草稿模型提供了一种通用方法，使得推测解码成为加速大型语言模型（LLM）的更通用、更实用的工具。

Abstract: Accelerating the inference of large language models (LLMs) has been a
critical challenge in generative AI. Speculative decoding (SD) substantially
improves LLM inference efficiency. However, its utility is limited by a
fundamental constraint: the draft and target models must share the same
vocabulary, thus limiting the herd of available draft models and often
necessitating the training of a new model from scratch. Inspired by Dynamic
Time Warping (DTW), a classic algorithm for aligning time series, we propose
the algorithm TokenTiming for universal speculative decoding. It operates by
re-encoding the draft token sequence to get a new target token sequence, and
then uses DTW to build a mapping to transfer the probability distributions for
speculative sampling. Benefiting from this, our method accommodates mismatched
vocabularies and works with any off-the-shelf models without retraining and
modification. We conduct comprehensive experiments on various tasks,
demonstrating 1.57x speedup. This work enables a universal approach for draft
model selection, making SD a more versatile and practical tool for LLM
acceleration.

</details>


### [124] [Rethinking Cross-lingual Gaps from a Statistical Viewpoint](https://arxiv.org/abs/2510.15551)
*Vihari Piratla,Purvam Jain,Darshan Singh,Partha Talukdar,Trevor Cohn*

Main category: cs.CL

TL;DR: LLMs在跨语言知识迁移中存在准确率下降的“跨语言鸿沟”问题。以往研究归因于语言表征的差异，而本文提出 variance（方差）是主要原因，并通过实验和干预验证了该假设，提出了一种通过控制响应方差来减小跨语言鸿沟的方法，并将目标语言的准确率提高了 20-25%。


<details>
  <summary>Details</summary>
Motivation: 以往研究认为跨语言鸿沟是由于源语言和目标语言的潜在表征存在差异，而本文作者认为目标语言响应的方差是造成此现象的主要原因。

Method: 提出了一种将跨语言鸿沟用偏差-方差分解进行形式化的新方法，并通过大量实验来支持该理论和假设。在此基础上，通过多种推理干预手段来控制方差并减小跨语言鸿沟。

Result: 提出的方法和假设得到了实验的大量证据支持。通过控制响应方差，跨语言鸿沟得以减小，并且在不同模型上，目标语言的准确率提高了 20-25%。

Conclusion: 响应方差是导致跨语言鸿沟的关键因素。通过控制响应方差，可以有效减小跨语言鸿沟，提高模型在目标语言上的性能。

Abstract: Any piece of knowledge is usually expressed in one or a handful of natural
languages on the web or in any large corpus. Large Language Models (LLMs) act
as a bridge by acquiring knowledge from a source language and making it
accessible when queried from target languages. Prior research has pointed to a
cross-lingual gap, viz., a drop in accuracy when the knowledge is queried in a
target language compared to when the query is in the source language. Existing
research has rationalized divergence in latent representations in source and
target languages as the source of cross-lingual gap. In this work, we take an
alternative view and hypothesize that the variance of responses in the target
language is the main cause of this gap. For the first time, we formalize the
cross-lingual gap in terms of bias-variance decomposition. We present extensive
experimental evidence which support proposed formulation and hypothesis. We
then reinforce our hypothesis through multiple inference-time interventions
that control the variance and reduce the cross-lingual gap. We demonstrate a
simple prompt instruction to reduce the response variance, which improved
target accuracy by 20-25% across different models.

</details>


### [125] [Think Parallax: Solving Multi-Hop Problems via Multi-View Knowledge-Graph-Based Retrieval-Augmented Generation](https://arxiv.org/abs/2510.15552)
*Jinliang Liu*

Main category: cs.CL

TL;DR: ParallaxRAG通过多视图头专业化来解决LLM在多跳推理中的幻觉和推理问题，通过对称解耦查询和图三元组到多视图空间，强制执行头部多样性并约束弱相关路径，从而实现鲁棒的检索架构。


<details>
  <summary>Details</summary>
Motivation: 现有的基于知识图谱的检索增强生成（KG-RAG）方法依赖于扁平的嵌入和嘈杂的路径探索，导致LLM在多跳推理中存在幻觉和推理困难。

Method: ParallaxRAG框架将查询和图三元组对称地解耦到多视图空间，并利用不同注意力头在不同推理阶段对语义关系的专业化，以构建更清晰的子图并指导LLM进行基于知识的、分步的推理。

Result: 在WebQSP和CWQ数据集上，ParallaxRAG在检索和问答方面表现出竞争力，同时减少了幻觉并具有良好的泛化能力。

Conclusion: 多视图头专业化是知识图谱增强的多跳推理的一个有原则的方向。

Abstract: Large language models (LLMs) excel at language understanding but often
hallucinate and struggle with multi-hop reasoning. Knowledge-graph-based
retrieval-augmented generation (KG-RAG) offers grounding, yet most methods rely
on flat embeddings and noisy path exploration. We propose ParallaxRAG, a
framework that symmetrically decouples queries and graph triples into
multi-view spaces, enabling a robust retrieval architecture that explicitly
enforces head diversity while constraining weakly related paths. Central to our
approach is the observation that different attention heads specialize in
semantic relations at distinct reasoning stages, contributing to different hops
of the reasoning chain. This specialization allows ParallaxRAG to construct
cleaner subgraphs and guide LLMs through grounded, step-wise reasoning.
Experiments on WebQSP and CWQ, under our unified, reproducible setup (BGE-M3 +
Llama3.1-8B), demonstrate competitive retrieval and QA performance, alongside
reduced hallucination and good generalization. Our results highlight multi-view
head specialization as a principled direction for knowledge-grounded multi-hop
reasoning. Our implementation will be released as soon as the paper is
accepted.

</details>


### [126] [KITE: A Benchmark for Evaluating Korean Instruction-Following Abilities in Large Language Models](https://arxiv.org/abs/2510.15558)
*Dongjun Kim,Chanhee Park,Chanjun Park,Heuiseok Lim*

Main category: cs.CL

TL;DR: LLMs在遵循韩语指令方面存在不足，KITE基准旨在解决这一问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM评估主要集中在英语，忽略了其他语言的细微差别，特别是韩语，缺乏专门的评估基准。

Method: 提出KITE（Korean Instruction-following Task Evaluation）基准，包含通用和韩语特有指令，并结合自动和人工评估。

Result: 评估结果显示不同模型在韩语指令遵循能力上存在差距，揭示了各自的优劣。

Conclusion: KITE基准的发布旨在促进对包容性LLM的研究，并鼓励为其他语言开发类似基准。

Abstract: The instruction-following capabilities of large language models (LLMs) are
pivotal for numerous applications, from conversational agents to complex
reasoning systems. However, current evaluations predominantly focus on English
models, neglecting the linguistic and cultural nuances of other languages.
Specifically, Korean, with its distinct syntax, rich morphological features,
honorific system, and dual numbering systems, lacks a dedicated benchmark for
assessing open-ended instruction-following capabilities. To address this gap,
we introduce the Korean Instruction-following Task Evaluation (KITE), a
comprehensive benchmark designed to evaluate both general and Korean-specific
instructions. Unlike existing Korean benchmarks that focus mainly on factual
knowledge or multiple-choice testing, KITE directly targets diverse, open-ended
instruction-following tasks. Our evaluation pipeline combines automated metrics
with human assessments, revealing performance disparities across models and
providing deeper insights into their strengths and weaknesses. By publicly
releasing the KITE dataset and code, we aim to foster further research on
culturally and linguistically inclusive LLM development and inspire similar
endeavors for other underrepresented languages.

</details>


### [127] [Finetuning LLMs for EvaCun 2025 token prediction shared task](https://arxiv.org/abs/2510.15561)
*Josef Jon,Ondřej Bojar*

Main category: cs.CL

TL;DR: 本提交的系统基于在任务数据上微调的LLM，并比较了三种不同的预测方法。


<details>
  <summary>Details</summary>
Motivation: 在EvaCun 2025的令牌预测任务中提交系统。

Method: 使用Command-R、Mistral和Aya Expanse等LLM，在任务提供的训练数据上进行微调，未进行调整、预处理或过滤。比较了三种基于不同提示的预测方法。

Result: 在保留数据上评估了三种预测方法。

Conclusion: 未在摘要中明确说明结论，但暗示了对不同提示的比较结果。

Abstract: In this paper, we present our submission for the token prediction task of
EvaCun 2025. Our sys-tems are based on LLMs (Command-R, Mistral, and Aya
Expanse) fine-tuned on the task data provided by the organizers. As we only
pos-sess a very superficial knowledge of the subject field and the languages of
the task, we simply used the training data without any task-specific
adjustments, preprocessing, or filtering. We compare 3 different approaches
(based on 3 different prompts) of obtaining the predictions, and we evaluate
them on a held-out part of the data.

</details>


### [128] [From Ghazals to Sonnets: Decoding the Polysemous Expressions of Love Across Languages](https://arxiv.org/abs/2510.15569)
*Syed Mohammad Sualeh Ali*

Main category: cs.CL

TL;DR: 本研究通过分析乌尔都语诗歌中三个关于“爱”的词（pyaar, muhabbat, ishq）的细微差别，揭示了乌尔都语表达爱的复杂性。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探讨乌尔都语诗歌中“爱”的多义性，揭示看似同义的词语之间细微的语义差别及其在诗歌中的独特表达方式。

Method: 本研究采用多义性案例研究方法，分析了 pyaar, muhabbat, 和 ishq 这三个词在乌尔都语诗歌中的使用和语境。此外，还对乌尔都语和英语中与“爱”相关的词语进行了词嵌入分析，以量化和可视化它们的语义空间。

Result: 研究揭示了 pyaar, muhabbat, 和 ishq 在乌尔都语诗歌中各自独特的含义和情感色彩，这些差别在英语中缺乏直接对应。词嵌入分析提供了量化的证据，证明了这些词语在语义空间中的区别。

Conclusion: 本研究成功揭示了乌尔都语诗歌中表达爱的复杂性和丰富性，强调了语言和文化在表达情感方面的重要性。通过对具体词语的深入分析和量化研究，为理解乌尔都语诗歌提供了新的视角。

Abstract: This paper delves into the intricate world of Urdu poetry, exploring its
thematic depths through a lens of polysemy. By focusing on the nuanced
differences between three seemingly synonymous words (pyaar, muhabbat, and
ishq) we expose a spectrum of emotions and experiences unique to the Urdu
language. This study employs a polysemic case study approach, meticulously
examining how these words are interwoven within the rich tapestry of Urdu
poetry. By analyzing their usage and context, we uncover a hidden layer of
meaning, revealing subtle distinctions which lack direct equivalents in English
literature. Furthermore, we embark on a comparative analysis, generating word
embeddings for both Urdu and English terms related to love. This enables us to
quantify and visualize the semantic space occupied by these words, providing
valuable insights into the cultural and linguistic nuances of expressing love.
Through this multifaceted approach, our study sheds light on the captivating
complexities of Urdu poetry, offering a deeper understanding and appreciation
for its unique portrayal of love and its myriad expressions

</details>


### [129] [BiMax: Bidirectional MaxSim Score for Document-Level Alignment](https://arxiv.org/abs/2510.15577)
*Xiaotian Wang,Takehito Utsuro,Masaaki Nagata*

Main category: cs.CL

TL;DR: BiMax 是一种新的跨语言文档对齐方法，在 WMT16 双语文档对齐任务上，其准确性与 OT 方法相当，但速度提高了约 100 倍。


<details>
  <summary>Details</summary>
Motivation: 现有的文档对齐方法（如基于句子嵌入的方法 TK-PERT 和 OT）在处理大规模网络挖掘数据时，需要在准确性和速度之间进行权衡。

Method: 提出了一种名为 BiMax 的跨语言双向最大得分方法，用于计算文档到文档的相似度，以提高效率。

Result: 在 WMT16 双语文档对齐任务上，BiMax 实现了与 OT 方法相当的准确性，同时速度提高了约 100 倍。

Conclusion: BiMax 在保持高准确性的同时显著提高了效率，是一种有效的文档对齐方法。

Abstract: Document alignment is necessary for the hierarchical mining (Ba\~n\'on et
al., 2020; Morishita et al., 2022), which aligns documents across source and
target languages within the same web domain. Several high precision sentence
embedding-based methods have been developed, such as TK-PERT (Thompson and
Koehn, 2020) and Optimal Transport (OT) (Clark et al., 2019; El-Kishky and
Guzm\'an, 2020). However, given the massive scale of web mining data, both
accuracy and speed must be considered. In this paper, we propose a
cross-lingual Bidirectional Maxsim score (BiMax) for computing doc-to-doc
similarity, to improve efficiency compared to the OT method. Consequently, on
the WMT16 bilingual document alignment task, BiMax attains accuracy comparable
to OT with an approximate 100-fold speed increase. Meanwhile, we also conduct a
comprehensive analysis to investigate the performance of current
state-of-the-art multilingual sentence embedding models. All the alignment
methods in this paper are publicly available as a tool called EmbDA
(https://github.com/EternalEdenn/EmbDA).

</details>


### [130] [The Elephant in the Coreference Room: Resolving Coreference in Full-Length French Fiction Works](https://arxiv.org/abs/2510.15594)
*Antoine Bourgois,Thierry Poibeau*

Main category: cs.CL

TL;DR: 该论文发布了一个新的法语长篇小说核心词分析数据集，并提出了一个可扩展到长文档的消歧模型。


<details>
  <summary>Details</summary>
Motivation: 现有的核心词分析数据集多为短文本，缺乏长文本数据集，无法满足对长篇文学作品进行核心词分析的需求。

Method: 构建了一个包含三部法语长篇小说、超过28.5万词的标注语料库，并提出一个模块化的核心词分析流程，能够进行细粒度的错误分析。

Result: 所提出的方法在长文档上具有竞争力并且能够有效扩展，同时可以用于推断虚构人物的性别。

Conclusion: 该数据集和方法对于文学分析和下游自然语言处理任务都具有相关性。

Abstract: While coreference resolution is attracting more interest than ever from
computational literature researchers, representative datasets of fully
annotated long documents remain surprisingly scarce. In this paper, we
introduce a new annotated corpus of three full-length French novels, totaling
over 285,000 tokens. Unlike previous datasets focused on shorter texts, our
corpus addresses the challenges posed by long, complex literary works, enabling
evaluation of coreference models in the context of long reference chains. We
present a modular coreference resolution pipeline that allows for fine-grained
error analysis. We show that our approach is competitive and scales effectively
to long documents. Finally, we demonstrate its usefulness to infer the gender
of fictional characters, showcasing its relevance for both literary analysis
and downstream NLP tasks.

</details>


### [131] [HypoSpace: Evaluating LLM Creativity as Set-Valued Hypothesis Generators under Underdetermination](https://arxiv.org/abs/2510.15614)
*Tingting Chen,Beibei Lin,Zifeng Yuan,Qiran Zou,Hongyu He,Yew-Soon Ong,Anirudh Goyal,Dianbo Liu*

Main category: cs.CL

TL;DR: HypoSpace是一个评估语言模型提出多组科学解释能力的工具套件，通过评估有效性、独特性和恢复性来衡量模型在面对多重可能性时的表现，揭示了模型可能存在的模式崩溃问题。


<details>
  <summary>Details</summary>
Motivation: 评估语言模型在科学工作流中提出多组解释而非单一答案的能力至关重要，因为许多科学问题存在多种可能的解释。

Method: 介绍HypoSpace，一个将语言模型视为有限假设集采样器的诊断套件，并测量三个互补指标：有效性（提出的解释与观测结果一致的精确度）、独特性（提出解释之间的非冗余性）和恢复性（对已枚举的可接受解释集的覆盖度）。在三个结构化域（因果图、3D体素重建、布尔遗传相互作用）中实例化HypoSpace，并使用确定性验证器和枚举假设空间。

Result: 在不同类型的语言模型上进行评估，发现当可接受的解释空间增大时，模型的有效性通常保持较高水平，但独特性和恢复性会下降，暴露出仅用正确性指标无法检测到的模式崩溃现象。

Conclusion: HypoSpace提供了一种可控的探测方法，用于评估那些能够显式探索和覆盖可接受解释空间的方法，而不是提供一个简单的排行榜。

Abstract: As language models are increasingly used in scientific workflows, evaluating
their ability to propose sets of explanations-not just a single correct
answer-becomes critical. Many scientific problems are underdetermined:
multiple, mechanistically distinct hypotheses are consistent with the same
observations. We introduce HypoSpace, a diagnostic suite that treats LLMs as
samplers of finite hypothesis sets and measures three complementary indicators:
Validity (precision of proposals consistent with observations), Uniqueness
(non-redundancy among proposals), and Recovery (coverage of the enumerated
admissible set). We instantiate HypoSpace in three structured domains with
deterministic validators and exactly enumerated hypothesis spaces: (i) causal
graphs from perturbations, (ii) gravity-constrained 3D voxel reconstruction
from top-down projections, and (iii) Boolean genetic interactions. Across
instruction-tuned and reasoning-focused models, Validity often remains high
while Uniqueness and Recovery degrade as the admissible space grows, revealing
mode collapse that is invisible to correctness-only metrics. HypoSpace offers a
controlled probe-rather than a leaderboard-for methods that explicitly explore
and cover admissible explanation spaces. Code is available at:
https://github.com/CTT-Pavilion/_HypoSpace.

</details>


### [132] [Leveraging LLMs for Context-Aware Implicit Textual and Multimodal Hate Speech Detection](https://arxiv.org/abs/2510.15685)
*Joshua Wolfe Brook,Ilia Markov*

Main category: cs.CL

TL;DR: LLMs can be used as dynamic knowledge bases to generate background context for Hate Speech Detection (HSD), improving performance in both textual and multimodal settings.


<details>
  <summary>Details</summary>
Motivation: The paper aims to improve Hate Speech Detection (HSD) by leveraging Large Language Models (LLMs) to generate relevant background context.

Method: The research explores two strategies for context generation (named entity-focused and full-text prompting) and four methods for incorporating this context into HSD classifiers (text concatenation, embedding concatenation, hierarchical transformer-based fusion, and LLM-driven text enhancement). Experiments were performed on the Latent Hatred dataset (textual) and the MAMI dataset (multimodal).

Result: Both context generation and incorporation methods significantly impact HSD performance. The best system, using embedding concatenation for context incorporation, achieved improvements of up to 3 F1 points on textual data and 6 F1 points on multimodal data compared to a zero-context baseline.

Conclusion: Generating and effectively incorporating background context using LLMs is crucial for enhancing both textual and multimodal Hate Speech Detection systems.

Abstract: This research introduces a novel approach to textual and multimodal Hate
Speech Detection (HSD), using Large Language Models (LLMs) as dynamic knowledge
bases to generate background context and incorporate it into the input of HSD
classifiers. Two context generation strategies are examined: one focused on
named entities and the other on full-text prompting. Four methods of
incorporating context into the classifier input are compared: text
concatenation, embedding concatenation, a hierarchical transformer-based
fusion, and LLM-driven text enhancement. Experiments are conducted on the
textual Latent Hatred dataset of implicit hate speech and applied in a
multimodal setting on the MAMI dataset of misogynous memes. Results suggest
that both the contextual information and the method by which it is incorporated
are key, with gains of up to 3 and 6 F1 points on textual and multimodal setups
respectively, from a zero-context baseline to the highest-performing system,
based on embedding concatenation.

</details>


### [133] [Cost-Aware Retrieval-Augmentation Reasoning Models with Adaptive Retrieval Depth](https://arxiv.org/abs/2510.15719)
*Helia Hashemi,Victor Rühle,Saravan Rajmohan*

Main category: cs.CL

TL;DR: 该研究提出了一个检索增强推理模型，通过动态调整检索文档列表的长度来降低计算成本，并使用成本感知优势函数进行强化学习训练，在七个公开的问答数据集上实现了效率和效果的双重提升。


<details>
  <summary>Details</summary>
Motivation: 检索增强推理模型虽然性能强大，但计算成本高昂，因为检索和推理的标记都会消耗大量资源。

Method: 提出了一种检索增强推理模型，该模型能根据查询和检索结果动态调整检索文档列表的长度。开发了一种成本感知优势函数，通过强化学习来训练高效的检索增强推理模型。探索了所提出的成本感知框架在近端和分组相对策略优化算法上的内存和延迟限制的实现。

Result: 在七个公开的问答数据集上进行了评估，证明了在不牺牲有效性的前提下，显著提高了效率。模型延迟平均降低了约 16-20%，而精确匹配率平均提高了约 5%。

Conclusion: 所提出的成本感知检索增强推理框架在效率和效果方面均取得了显著提升。

Abstract: Reasoning models have gained significant attention due to their strong
performance, particularly when enhanced with retrieval augmentation. However,
these models often incur high computational costs, as both retrieval and
reasoning tokens contribute substantially to the overall resource usage. In
this work, we make the following contributions: (1) we propose a
retrieval-augmented reasoning model that dynamically adjusts the length of the
retrieved document list based on the query and retrieval results; (2) we
develop a cost-aware advantage function for training of efficient
retrieval-augmented reasoning models through reinforcement learning; and (3) we
explore both memory- and latency-bound implementations of the proposed
cost-aware framework for both proximal and group relative policy optimization
algorithms. We evaluate our approach on seven public question answering
datasets and demonstrate significant efficiency gains, without compromising
effectiveness. In fact, we observed that the model latency decreases by ~16-20%
across datasets, while its effectiveness increases by ~5% on average, in terms
of exact match.

</details>


### [134] [Attention Sinks in Diffusion Language Models](https://arxiv.org/abs/2510.15731)
*Maximo Eduardo Rulli,Simone Petruzzi,Edoardo Michielon,Fabrizio Silvestri,Simone Scardapane,Alessio Devoto*

Main category: cs.CL

TL;DR: Masked Diffusion Language Models (DLMs) show attention sinks, but unlike Autoregressive Models (ARMs), these sinks are dynamic and their removal has minimal impact on DLM performance, highlighting key differences between the two architectures.


<details>
  <summary>Details</summary>
Motivation: The internal mechanisms governing DLMs, particularly their attention patterns, remain largely unexplored despite their promise as an alternative to ARMs.

Method: Empirical analysis of DLM attention patterns, focusing on the attention sinking phenomenon and comparing its characteristics and impact to that observed in ARMs.

Result: DLMs exhibit attention sinks that dynamically shift positions during generation. Masking these sinks causes only minor performance degradation, indicating DLM robustness.

Conclusion: DLMs have distinct attention allocation and utilization mechanisms compared to ARMs, characterized by dynamic attention sinks that do not significantly harm performance when removed.

Abstract: Masked Diffusion Language Models (DLMs) have recently emerged as a promising
alternative to traditional Autoregressive Models (ARMs). DLMs employ
transformer encoders with bidirectional attention, enabling parallel token
generation while maintaining competitive performance. Although their efficiency
and effectiveness have been extensively studied, the internal mechanisms that
govern DLMs remain largely unexplored. In this work, we conduct an empirical
analysis of DLM attention patterns, focusing on the attention sinking
phenomenon, an effect previously observed in various transformer-based
architectures. Our findings reveal that DLMs also exhibit attention sinks, but
with distinct characteristics. First, unlike in ARMs, the sink positions in
DLMs tend to shift throughout the generation process, displaying a dynamic
behaviour. Second, while ARMs are highly sensitive to the removal of attention
sinks, DLMs remain robust: masking sinks leads to only a minor degradation in
performance. These results provide new insights into the inner workings of
diffusion-based language models and highlight fundamental differences in how
they allocate and utilize attention compared to autoregressive models.

</details>


### [135] [LLMs Judge Themselves: A Game-Theoretic Framework for Human-Aligned Evaluation](https://arxiv.org/abs/2510.15746)
*Gao Yang,Yuhang Liu,Siyu Miao,Xinyue Liang,Zhengyang Liu,Heyan Huang*

Main category: cs.CL

TL;DR: 本文提出一种新的评估大型语言模型（LLM）的方法——自动互评，其中LLM相互评估对方的输出，并通过与人类投票行为的比较来验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统LLM评估方法在处理开放式、主观性强的任务时存在不足，无法有效捕捉LLM的复杂行为。

Method: 提出自动互评框架，让LLM通过自我对弈和同行评审来评估彼此的输出，并利用博弈论的投票算法来整合评估结果，最后将模型生成的排名与人类的判断进行比较。

Result: 实验结果表明，模型评估与人类评估之间存在一致性和差异性，揭示了互评方法的潜力和局限性。

Conclusion: 自动互评结合博弈论聚合和人类验证，是评估LLM能力的一种新颖且有前景的方法，为LLM评估领域提供了新的见解。

Abstract: Ideal or real - that is the question.In this work, we explore whether
principles from game theory can be effectively applied to the evaluation of
large language models (LLMs). This inquiry is motivated by the growing
inadequacy of conventional evaluation practices, which often rely on
fixed-format tasks with reference answers and struggle to capture the nuanced,
subjective, and open-ended nature of modern LLM behavior. To address these
challenges, we propose a novel alternative: automatic mutual evaluation, where
LLMs assess each other's output through self-play and peer review. These peer
assessments are then systematically compared with human voting behavior to
evaluate their alignment with human judgment. Our framework incorporates
game-theoretic voting algorithms to aggregate peer reviews, enabling a
principled investigation into whether model-generated rankings reflect human
preferences. Empirical results reveal both convergences and divergences between
theoretical predictions and human evaluations, offering valuable insights into
the promises and limitations of mutual evaluation. To the best of our
knowledge, this is the first work to jointly integrate mutual evaluation,
game-theoretic aggregation, and human-grounded validation for evaluating the
capabilities of LLMs.

</details>


### [136] [On Non-interactive Evaluation of Animal Communication Translators](https://arxiv.org/abs/2510.15768)
*Orr Paradise,David F. Gruber,Adam Tauman Kalai*

Main category: cs.CL

TL;DR: 本研究提出了一种无需参考翻译即可评估AI翻译器（特别是用于复杂语言，如鲸语）的新方法，通过分析翻译输出的连贯性和逻辑性来检测“幻觉”，并在数据稀疏的人类语言和人工语言实验中验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决在没有参考翻译的情况下，如何评估AI翻译器（尤其是用于复杂且难以直接交互的物种，如鲸鱼）的有效性问题，并提出了一种新的评估方法。

Method: 研究者提出了一种名为“逐段翻译+NLP洗牌测试”的方法。该方法将待翻译的物种交流内容进行分段处理，然后逐段进行翻译。通过评估翻译后的英文内容在原始顺序下是否比被打乱顺序后更有意义，来判断翻译的准确性，从而检测和评估翻译中的“幻觉”现象。

Result: 在数据稀疏的人类语言和人工语言的实验中，该方法被证明具有潜在的实用性。实验结果表明，这种无参考翻译的评估方法与基于参考翻译的标准评估方法高度相关。此外，理论分析表明，在翻译学习的早期阶段，与动物的互动可能并非必需，甚至可能效率不高。

Conclusion: 本研究提出的无参考翻译评估方法，特别是结合逐段翻译和NLP洗牌测试，在数据稀疏的情况下能够有效评估翻译器的质量，甚至可能在早期学习阶段无需与被翻译物种进行直接互动。

Abstract: If you had an AI Whale-to-English translator, how could you validate whether
or not it is working? Does one need to interact with the animals or rely on
grounded observations such as temperature? We provide theoretical and
proof-of-concept experimental evidence suggesting that interaction and even
observations may not be necessary for sufficiently complex languages. One may
be able to evaluate translators solely by their English outputs, offering
potential advantages in terms of safety, ethics, and cost. This is an instance
of machine translation quality evaluation (MTQE) without any reference
translations available. A key challenge is identifying ``hallucinations,''
false translations which may appear fluent and plausible. We propose using
segment-by-segment translation together with the classic NLP shuffle test to
evaluate translators. The idea is to translate animal communication, turn by
turn, and evaluate how often the resulting translations make more sense in
order than permuted. Proof-of-concept experiments on data-scarce human
languages and constructed languages demonstrate the potential utility of this
evaluation methodology. These human-language experiments serve solely to
validate our reference-free metric under data scarcity. It is found to
correlate highly with a standard evaluation based on reference translations,
which are available in our experiments. We also perform a theoretical analysis
suggesting that interaction may not be necessary nor efficient in the early
stages of learning to translate.

</details>


### [137] [Emergence of Linear Truth Encodings in Language Models](https://arxiv.org/abs/2510.15804)
*Shauli Ravfogel,Gilad Yehudai,Tal Linzen,Joan Bruna,Alberto Bietti*

Main category: cs.CL

TL;DR: 大型语言模型中存在区分真假语句的线性子空间，但其成因尚不明确。本文通过一个透明的单层Transformer玩具模型，端到端地重现了这种真理子空间，并揭示了一种可能的形成机制。研究发现在事实陈述共现（反之亦然）的数据分布下，模型为了降低损失而学习区分真假。这一模式在预训练语言模型中也得到了证实。玩具模型中观察到两阶段学习动态：模型首先快速记忆事实关联，然后逐渐学会线性区分真伪，从而降低语言建模损失。


<details>
  <summary>Details</summary>
Motivation: 了解大型语言模型中区分真假语句的线性子空间出现的原因。

Method: 引入一个透明的单层Transformer玩具模型，研究数据分布和学习动态，并在预训练语言模型中进行实验验证。

Result: 在玩具模型和预训练模型中都观察到真理子空间的出现。识别出一种数据分布模式（事实陈述共现）可以促使模型学习区分真伪。玩具模型中存在两阶段学习动态：先记忆，后线性区分。该过程能降低语言建模损失。

Conclusion: 线性真理表征可以在语言模型中出现，这可以通过一种具体的机制（如事实陈述共现的数据分布）来解释，并且存在两阶段的学习过程。

Abstract: Recent probing studies reveal that large language models exhibit linear
subspaces that separate true from false statements, yet the mechanism behind
their emergence is unclear. We introduce a transparent, one-layer transformer
toy model that reproduces such truth subspaces end-to-end and exposes one
concrete route by which they can arise. We study one simple setting in which
truth encoding can emerge: a data distribution where factual statements
co-occur with other factual statements (and vice-versa), encouraging the model
to learn this distinction in order to lower the LM loss on future tokens. We
corroborate this pattern with experiments in pretrained language models.
Finally, in the toy setting we observe a two-phase learning dynamic: networks
first memorize individual factual associations in a few steps, then -- over a
longer horizon -- learn to linearly separate true from false, which in turn
lowers language-modeling loss. Together, these results provide both a
mechanistic demonstration and an empirical motivation for how and why linear
truth representations can emerge in language models.

</details>


### [138] [Paper2Web: Let's Make Your Paper Alive!](https://arxiv.org/abs/2510.15842)
*Yuhang Chen,Tianpeng Lv,Siyi Zhang,Yixiang Yin,Yao Wan,Philip S. Yu,Dongping Chen*

Main category: cs.CL

TL;DR: 本研究提出了Paper2Web，一个用于评估学术网页生成的基准数据集和多维度评估框架，并介绍了PWAgent，一个能将学术论文转换为交互式网页的自主流程。


<details>
  <summary>Details</summary>
Motivation: 现有学术项目网站在传播研究方面存在不足，传统方法难以生成布局感知和交互式网站，且缺乏全面的评估体系。

Method: 提出了Paper2Web基准数据集和评估框架，包含基于规则的指标（连通性、完整性）和人工验证的LLM-as-a-Judge（交互性、美观性、信息性），以及PaperQuiz（知识保留度）。同时，引入PWAgent自主流程，通过迭代优化内容和布局，利用MCP工具提升呈现质量。

Result: PWAgent在各项评估中显著优于基于模板和arXiv/alphaXiv等基线方法，实现了学术网页生成的帕累托最优。

Conclusion: Paper2Web和PWAgent为学术网页生成任务提供了新的评估标准和更优的解决方案。

Abstract: Academic project websites can more effectively disseminate research when they
clearly present core content and enable intuitive navigation and interaction.
However, current approaches such as direct Large Language Model (LLM)
generation, templates, or direct HTML conversion struggle to produce
layout-aware, interactive sites, and a comprehensive evaluation suite for this
task has been lacking. In this paper, we introduce Paper2Web, a benchmark
dataset and multi-dimensional evaluation framework for assessing academic
webpage generation. It incorporates rule-based metrics like Connectivity,
Completeness and human-verified LLM-as-a-Judge (covering interactivity,
aesthetics, and informativeness), and PaperQuiz, which measures paper-level
knowledge retention. We further present PWAgent, an autonomous pipeline that
converts scientific papers into interactive and multimedia-rich academic
homepages. The agent iteratively refines both content and layout through MCP
tools that enhance emphasis, balance, and presentation quality. Our experiments
show that PWAgent consistently outperforms end-to-end baselines like
template-based webpages and arXiv/alphaXiv versions by a large margin while
maintaining low cost, achieving the Pareto-front in academic webpage
generation.

</details>


### [139] [Enhanced Sentiment Interpretation via a Lexicon-Fuzzy-Transformer Framework](https://arxiv.org/abs/2510.15843)
*Shayan Rokhva,Mousa Alizadeh,Maryam Abdollahi Shamami*

Main category: cs.CL

TL;DR: 提出了一种结合VADER、DistilBERT和模糊逻辑的混合模型，用于对产品评论和社交媒体帖子进行细粒度的情感分析。


<details>
  <summary>Details</summary>
Motivation: 现有的情感分析方法难以处理非正式和领域特定的语言，导致在检测情感极性和强度时存在挑战。

Method: 该框架结合了基于规则的启发式方法、DistilBERT的上下文深度学习和模糊逻辑。首先使用VADER进行初步估计，然后利用DistilBERT的置信度分数进行两阶段调整，并应用模糊逻辑来减少中性偏见并提高粒度。最后，使用模糊推理系统将分数映射到0到1的连续区间。

Result: 在四个领域特定的数据集（食品配送、电子商务、旅游和时尚）上进行了评估，结果显示与用户评分的一致性提高，极端情感的识别能力增强，误分类减少。模型在定量指标和定性分析中都表现出鲁棒性和效率。

Conclusion: 将符号推理与神经网络模型相结合，可以为语言动态变化的领域提供可解释的、细粒度的情感分析。

Abstract: Accurately detecting sentiment polarity and intensity in product reviews and
social media posts remains challenging due to informal and domain-specific
language. To address this, we propose a novel hybrid lexicon-fuzzy-transformer
framework that combines rule-based heuristics, contextual deep learning, and
fuzzy logic to generate continuous sentiment scores reflecting both polarity
and strength. The pipeline begins with VADER-based initial sentiment
estimations, which are refined through a two-stage adjustment process. This
involves leveraging confidence scores from DistilBERT, a lightweight
transformer and applying fuzzy logic principles to mitigate excessive
neutrality bias and enhance granularity. A custom fuzzy inference system then
maps the refined scores onto a 0 to 1 continuum, producing expert)like
judgments. The framework is rigorously evaluated on four domain-specific
datasets. food delivery, e-commerce, tourism, and fashion. Results show
improved alignment with user ratings, better identification of sentiment
extremes, and reduced misclassifications. Both quantitative metrics
(distributional alignment, confusion matrices) and qualitative insights (case
studies, runtime analysis) affirm the models robustness and efficiency. This
work demonstrates the value of integrating symbolic reasoning with neural
models for interpretable, finegrained sentiment analysis in linguistically
dynamic domains.

</details>


### [140] [SpeechLLMs for Large-scale Contextualized Zero-shot Slot Filling](https://arxiv.org/abs/2510.15851)
*Kadri Hacioglu,Manjunath K E,Andreas Stolcke*

Main category: cs.CL

TL;DR: SpeechLLMs 在口语语言理解 (SLU) 的槽位填充任务上展现了巨大潜力，通过统一的生成式和指令遵循方法，并在数据、计算和泛化方面优于传统方法。本研究通过建立任务的经验上限，识别性能差距，并提出数据、架构和训练策略的改进，以缩小差距，并为实际应用提供指导。


<details>
  <summary>Details</summary>
Motivation: 解决传统 SLU 中槽位填充任务的级联方法效率低下、泛化能力不足的问题，并探索和利用新兴的 SpeechLLM 模型在数据、计算和零样本泛化方面的优势。

Method: 1. 建立槽位填充任务的经验性能上限。 2. 识别现有 SpeechLLM 在性能、鲁棒性和泛化方面与上限的差距。 3. 提出改进方法，包括优化训练数据、调整模型架构和改进训练策略。

Result: 通过改进训练数据、架构和训练策略，显著提高了 SpeechLLM 在槽位填充任务上的性能，并缩小了与经验上限的差距。

Conclusion: SpeechLLM 在槽位填充任务上具有巨大潜力，通过数据、架构和训练策略的优化可以进一步提升其性能和泛化能力，但仍需克服实际应用中的挑战，并为未来研究提供指导。

Abstract: Slot filling is a crucial subtask in spoken language understanding (SLU),
traditionally implemented as a cascade of speech recognition followed by one or
more natural language understanding (NLU) components. The recent advent of
speech-based large language models (speechLLMs), which integrate speech and
textual foundation models, has opened new avenues for achieving speech
understanding tasks in a more unified, generative, and instruction-following
manner while promising data and compute efficiency with zero-shot abilities,
generalizing to unseen slot labels. We address the slot-filling task by
creating an empirical upper bound for the task, identifying performance,
robustness, and generalization gaps, and proposing improvements to the training
data, architecture, and training strategies to narrow the gap with the upper
bound result. We show that each of these measures improve performance
substantially, while highlighting practical challenges and providing empirical
guidance and insights for harnessing these emerging models.

</details>


### [141] [InfiMed-ORBIT: Aligning LLMs on Open-Ended Complex Tasks via Rubric-Based Incremental Training](https://arxiv.org/abs/2510.15859)
*Pengkai Wang,Qi Zuo,Pengwei Liu,Zhijie Sang,Congkai Xie,Hongxia Yang*

Main category: cs.CL

TL;DR: LLM在数学和代码等领域通过强化学习取得显著进展，但在开放式领域（如创意写作、科学推理和医疗咨询）因缺乏明确的奖励函数而面临挑战。本文提出ORBIT框架，通过结合合成对话生成和动态创建的评分标准，指导增量强化学习过程，以应对高风险医疗对话的挑战。ORBIT不依赖外部医学知识或手动规则，而是利用基于评分标准的反馈进行学习。在Qwen3-4B-Instruct模型上，ORBIT使用2k样本将HealthBench-Hard基准测试的性能从7.0提升到27.2，达到同等规模模型的最优水平。研究表明，基于评分标准的强化学习能够提升模型在各种咨询场景下的表现，证明了基于评分标准的反馈是提升LLM在复杂开放式任务能力的有效策略。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）在数学和代码等领域通过强化学习（RL）取得了显著进展，但在奖励函数模糊、主观或依赖于上下文的开放式领域（如创意写作、科学推理和医疗咨询）面临挑战。本文旨在解决在开放式领域，特别是高风险医疗对话中，由于缺乏稳健的奖励函数而导致RL策略难以有效应用的问题。

Method: 本文提出ORBIT（open-ended rubric-based incremental training）框架，该框架结合了合成对话生成和动态评分标准的创建，并利用这些评分标准来指导增量强化学习过程。该方法不依赖外部医学知识或手动规则，而是通过基于评分标准的反馈来塑造模型的学习。

Result: 在Qwen3-4B-Instruct模型上，ORBIT使用2k样本将HealthBench-Hard基准测试的性能从7.0提升到27.2，达到了同等规模模型的最优水平。分析表明，基于评分标准的RL能够跨越不同的咨询场景，带来稳定且超越简单数值提升的性能。

Conclusion: 基于评分标准的反馈是一种可扩展的策略，能够有效提升大型语言模型在复杂、开放式任务中的能力，特别是在高风险医疗对话等领域。ORBIT框架证明了其在提升LLM在医疗咨询方面性能的有效性。

Abstract: Large Language Models (LLMs) have shown substantial advances through
reinforcement learning (RL), particularly in domains where rewards can be
programmatically verified, such as mathematics and code. In these areas, models
benefit from a well-defined operational base guided by explicit rule-based
objectives. However, this progress reveals a significant limitation: in
open-ended domains where rewards are ambiguous, subjective, or
context-dependent, such as creative writing, scientific reasoning, and notably
medical consultation, robust reward functions are lacking, making these areas
challenging for current RL strategies. To bridge this gap, we introduce ORBIT,
an open-ended rubric-based incremental training framework specifically designed
for high-stakes medical dialogue. ORBIT integrates syn- thetic dialogue
generation with the dynamic creation of rubrics, employing these rubrics to
direct an incremental RL process. In particular, this approach does not depend
on external medical knowledge or manual rules, instead utilizing rubric-guided
feedback to shape learning. When implemented on the Qwen3-4B-Instruct model,
our method can greatly enhance its performance on the HealthBench-Hard
benchmark from 7.0 to 27.2 using only 2k samples, thus achieving
state-of-the-art results for models of this scale. Our analysis confirms that
rubric-driven RL fos-ters consistent performance gains across diverse
consultation scenarios, going beyond simple numerical improvements. These
findings underscore rubric-based feedback as a scalable strategy for advancing
LLMs in intricate, open-ended tasks.

</details>


### [142] [PolySkill: Learning Generalizable Skills Through Polymorphic Abstraction](https://arxiv.org/abs/2510.15863)
*Simon Yu,Gang Li,Weiyan Shi,Peng Qi*

Main category: cs.CL

TL;DR: PolySkill框架通过分离抽象目标和具体实现来学习可泛化和可组合的技能，提高了技能复用性和成功率，并使智能体能在不同网站上学习通用技能。


<details>
  <summary>Details</summary>
Motivation: 现有技能学习方法创建的技能过于单一，无法泛化，而PolySkill旨在解决这一问题，使智能体能够学习可泛化和可组合的技能。

Method: PolySkill框架受软件工程中多态性的启发，将技能的抽象目标（完成什么）与其具体实现（如何执行）分离开来。

Result: 实验表明，PolySkill将技能复用性提高了1.7倍，在Mind2Web和未见过网站上的成功率分别提高了9.4%和13.9%，同时减少了20%以上的步骤。在无特定任务的自我探索环境中，PolySkill提高了任务质量，并使智能体能够学习跨不同网站的通用技能。

Conclusion: 将技能的目标与其执行分离开是开发能够持续学习和泛化于开放网络的自主智能体的关键一步。

Abstract: Large language models (LLMs) are moving beyond static uses and are now
powering agents that learn continually during their interaction with external
environments. For example, agents can learn reusable skills while navigating
web pages or toggling new tools. However, existing methods for skill learning
often create skills that are over-specialized to a single website and fail to
generalize. We introduce PolySkill, a new framework that enables agents to
learn generalizable and compositional skills. The core idea, inspired by
polymorphism in software engineering, is to decouple a skill's abstract goal
(what it accomplishes) and its concrete implementation (how it is executed).
Experiments show that our method (1) improves skill reuse by 1.7x on seen
websites and (2) boosts success rates by up to 9.4% on Mind2Web and 13.9% on
unseen websites, while reducing steps by over 20%. (3) In self-exploration
settings without specified tasks, our framework improves the quality of
proposed tasks and enables agents to learn generalizable skills that work
across different sites. By enabling the agent to identify and refine its own
goals, the PolySkill enhances the agent's ability to learn a better curriculum,
leading to the acquisition of more generalizable skills compared to baseline
methods. This work provides a practical path toward building agents capable of
continual learning in adaptive environments. Our findings show that separating
a skill's goal from its execution is a crucial step toward developing
autonomous agents that can learn and generalize across the open web
continuously.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [143] [ProofBridge: Auto-Formalization of Natural Language Proofs in Lean via Joint Embeddings](https://arxiv.org/abs/2510.15681)
*Prithwish Jana,Kaan Kale,Ahmet Ege Tanriverdi,Cruise Song,Sriram Vishwanath,Vijay Ganesh*

Main category: cs.LO

TL;DR: ProofBridge 是一个统一的框架，可自动将自然语言 (NL) 的数学定理和证明翻译成 Lean 4。它使用联合嵌入模型对 NL 和 FL (NL-FL) 定理-证明对进行联合训练，使模型能够跨模态检索相关的 FL 示例以指导翻译。通过集成检索增强的微调和迭代式证明修复，ProofBridge 利用 Lean 的类型检查器和语义等价反馈来确保语法正确性和语义保真度。实验结果表明，与现有基线相比，ProofBridge 在证明的自动形式化方面取得了显著的改进，特别是在语义正确性和类型正确性方面。它在跨模态检索质量方面取得了高达 3.28 倍的 Recall@1 提升，并在语义正确性方面取得了 +31.14% 的提升，在类型正确性方面取得了 +1.64% 的提升（pass@32）。


<details>
  <summary>Details</summary>
Motivation: 将人类编写的数学定理和证明从自然语言 (NL) 翻译成形式语言 (FL)，如 Lean 4，长期以来一直是人工智能的一个重大挑战。现有的方法通常将定理翻译和证明生成分开进行，导致与真正的证明自动形式化之间存在根本性的脱节。AlphaProof 在 2024 年 IMO 上获得的银牌成绩也凸显了这种两步过程的局限性，即使在那时也需要手动翻译问题陈述。

Method: ProofBridge 使用一个联合嵌入模型，将自然语言 (NL) 和形式语言 (FL) 的定理-证明对映射到一个共享的语义空间中。这种映射使得模型能够根据语义相关性检索 FL 示例，以指导 NL 定理和证明到 Lean 4 的翻译。该框架集成了检索增强的微调和迭代式的证明修复。在整个过程中，它利用 Lean 的类型检查器和语义等价反馈来确保翻译出的证明在语法上正确且在语义上忠实于原始证明。

Result: ProofBridge 在证明的自动形式化方面取得了显著的改进，超越了包括 GPT-5、Gemini-2.5、Kimina-Prover 和 DeepSeek-Prover 在内的强有力基线。其检索增强的方法在语义正确性 (SC) 和类型正确性 (TC) 方面取得了显著的提升。具体而言，与 all-MiniLM-L6-v2 相比，ProofBridge 的跨模态检索质量提高了 3.28 倍的 Recall@1。与基线 Kimina-Prover-RL-1.7B 相比，ProofBridge 在 pass@32 指标下，语义正确性 (SC) 提高了 +31.14%，类型正确性 (TC) 提高了 +1.64%。

Conclusion: ProofBridge 提供了一个统一的框架，能够有效地将自然语言的数学定理和证明自动翻译成 Lean 4。通过其创新的联合嵌入模型和检索增强的微调与迭代式证明修复相结合的方法，ProofBridge 显著提高了证明自动形式化的准确性和可靠性。实验结果表明，该方法在语义正确性和类型正确性方面均优于现有最先进的技术，为数学定理的形式化研究开辟了新的可能性。

Abstract: Translating human-written mathematical theorems and proofs from natural
language (NL) into formal languages (FLs) like Lean 4 has long been a
significant challenge for AI. Most state-of-the-art methods address this
separately, first translating theorems and then generating proofs, creating a
fundamental disconnect vis-a-vis true proof auto-formalization. This two-step
process and its limitations were evident even in AlphaProof's silver-medal
performance at the 2024 IMO, where problem statements needed manual translation
before automated proof synthesis.
  We present ProofBridge, a unified framework for automatically translating
entire NL theorems and proofs into Lean 4. At its core is a joint embedding
model that aligns NL and FL (NL-FL) theorem-proof pairs in a shared semantic
space, enabling cross-modal retrieval of semantically relevant FL examples to
guide translation. Our training ensures that NL-FL theorems (and their proofs)
are mapped close together in this space if and only if the NL-FL pairs are
semantically equivalent. ProofBridge integrates retrieval-augmented fine-tuning
with iterative proof repair, leveraging Lean's type checker and semantic
equivalence feedback to ensure both syntactic correctness and semantic
fidelity. Experiments show substantial improvements in proof auto-formalization
over strong baselines (including GPT-5, Gemini-2.5, Kimina-Prover,
DeepSeek-Prover), with our retrieval-augmented approach yielding significant
gains in semantic correctness (SC, via proving bi-directional equivalence) and
type correctness (TC, via type-checking theorem+proof) across pass@k metrics on
miniF2F-Test-PF, a dataset we curated. In particular, ProofBridge improves
cross-modal retrieval quality by up to 3.28x Recall@1 over all-MiniLM-L6-v2,
and achieves +31.14% SC and +1.64% TC (pass@32) compared to the baseline
Kimina-Prover-RL-1.7B.

</details>


### [144] [Weakening Goals in Logical Specifications](https://arxiv.org/abs/2510.15718)
*Ben M. Andrew*

Main category: cs.LO

TL;DR: We present a counterexample-guided technique for iteratively weakening logical specifications, enabling verification of properties that do not strictly hold under system degradation or environmental changes.


<details>
  <summary>Details</summary>
Motivation: Traditional verification methods fail when software properties no longer hold due to system degradation or environmental changes. Weaker versions of these properties can still be useful for understanding system behavior and aiding compositional verification.

Method: A counterexample-guided technique is used to iteratively weaken properties, applied to propositional logic specifications.

Result: The technique can find weaker properties that still hold under uncertain conditions.

Conclusion: The presented technique provides a way to handle and verify properties that are not strictly satisfied, with planned extensions to state-based representations.

Abstract: Logical specifications are widely used to represent software systems and
their desired properties. Under system degradation or environmental changes,
commonly seen in complex real-world robotic systems, these properties may no
longer hold and so traditional verification methods will simply fail to
construct a proof. However, weaker versions of these properties do still hold
and can be useful for understanding the system's behaviour in uncertain
conditions, as well as aiding compositional verification. We present a
counterexample-guided technique for iteratively weakening properties, apply it
to propositional logic specifications, and discuss planned extensions to
state-based representations.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [145] [Fix False Transparency by Noise Guided Splatting](https://arxiv.org/abs/2510.15736)
*Aly El Hakie,Yiren Lu,Yu Yin,Michael Jenkins,Yehe Liu*

Main category: cs.GR

TL;DR: 3DGS在重建不透明物体时，常出现虚假透明表面，导致背景和内部图案在相机移动时出现不一致。这是因为3DGS的优化问题不明确，缺乏对表面不透明度的明确约束。本研究首次提出NGS策略，通过注入不透明噪声高斯来鼓励表面高斯具有更高的不透明度，从而解决虚假透明问题。同时，提出了一种基于透射率的度量方法来量化评估虚假透明度，并构建了新的数据集和增强了现有数据集以评估方法的鲁棒性。实验证明，NGS能显著减少虚假透明，同时保持标准渲染指标的竞争力。


<details>
  <summary>Details</summary>
Motivation: 3DGS在重建不透明物体时，由于优化问题不明确，缺乏对表面不透明度的明确约束，导致出现虚假透明表面，在交互式查看时产生不一致的背景和内部图案。

Method: 提出NGS策略，通过在训练期间向物体体积内注入不透明噪声高斯，鼓励表面高斯具有更高的不透明度。该方法仅需对现有渲染过程进行少量修改。此外，提出了一种基于透射率的度量方法来量化评估虚假透明度，并构建了新的数据集和增强了现有数据集以评估方法的鲁棒性。

Result: NGS策略能够显著减少虚假透明现象，同时在标准的渲染指标上保持具有竞争力的性能，证明了其有效性。

Conclusion: 本研究首次识别、描述并提出了解决3DGS中虚假透明问题的NGS策略，并通过提出的度量方法和数据集验证了其有效性。

Abstract: Opaque objects reconstructed by 3DGS often exhibit a falsely transparent
surface, leading to inconsistent background and internal patterns under camera
motion in interactive viewing. This issue stems from the ill-posed optimization
in 3DGS. During training, background and foreground Gaussians are blended via
alpha-compositing and optimized solely against the input RGB images using a
photometric loss. As this process lacks an explicit constraint on surface
opacity, the optimization may incorrectly assign transparency to opaque
regions, resulting in view-inconsistent and falsely transparent. This issue is
difficult to detect in standard evaluation settings but becomes particularly
evident in object-centric reconstructions under interactive viewing. Although
other causes of view-inconsistency have been explored recently, false
transparency has not been explicitly identified. To the best of our knowledge,
we are the first to identify, characterize, and develop solutions for this
artifact, an underreported artifact in 3DGS. Our strategy, NGS, encourages
surface Gaussians to adopt higher opacity by injecting opaque noise Gaussians
in the object volume during training, requiring only minimal modifications to
the existing splatting process. To quantitatively evaluate false transparency
in static renderings, we propose a transmittance-based metric that measures the
severity of this artifact. In addition, we introduce a customized, high-quality
object-centric scan dataset exhibiting pronounced transparency issues, and we
augment popular existing datasets with complementary infill noise specifically
designed to assess the robustness of 3D reconstruction methods to false
transparency. Experiments across multiple datasets show that NGS substantially
reduces false transparency while maintaining competitive performance on
standard rendering metrics, demonstrating its overall effectiveness.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [146] [Hive Hash Table: A Warp-Cooperative, Dynamically Resizable Hash Table for GPUs](https://arxiv.org/abs/2510.15095)
*Md Sabbir Hossain Polak,David Troendle,Byunghyun Jang*

Main category: cs.DC

TL;DR: Hive是一种高性能、动态可调的GPU哈希表，通过优化的数据布局、并发控制协议和动态调整策略，在高达95%的负载因子下仍能高效运行，提供比现有GPU哈希表高1.5-2倍的吞吐量。


<details>
  <summary>Details</summary>
Motivation: 现有GPU哈希表的实现难以应对并发更新、高负载因子和不规则内存访问模式的挑战。

Method: Hive采用了三种关键技术：1. 缓存对齐的打包桶布局，使用64位字存储键值对，实现内存合并访问和单次CAS原子更新。2. Warp同步并发协议（WABC和WCME），将争用降至每个warp一次原子操作，并确保无锁进展。3. 负载因子感知的动态调整策略，使用线性哈希在warp并行K-bucket批次中扩展或收缩容量，以保持均衡占用。为处理高争用的插入操作，Hive采用了一种四步策略：替换、声明并提交、有界uckoo驱逐和溢出隐藏回退。

Result: 在NVIDIA RTX 4090上的实验评估显示，Hive哈希表在高达95%的负载因子下仍能保持高性能，在混合插入-删除-查找工作负载下，吞吐量比Slab-Hash、DyCuckoo和WarpCore等最先进的GPU哈希表高1.5-2倍。在均衡工作负载下，Hive哈希表的更新速度达到每秒35亿次，查找速度接近每秒40亿次。

Conclusion: Hive哈希表通过其创新的设计，显著提高了GPU哈希表的性能和可扩展性，能够有效处理高负载和高并发场景，为GPU加速的数据处理提供了高效解决方案。

Abstract: Hash tables are essential building blocks in data-intensive applications, yet
existing GPU implementations often struggle with concurrent updates, high load
factors, and irregular memory access patterns. We present Hive hash table, a
high-performance, warp-cooperative and dynamically resizable GPU hash table
that adapts to varying workloads without global rehashing.
  Hive hash table makes three key contributions. First, a cache-aligned packed
bucket layout stores key-value pairs as 64-bit words, enabling coalesced memory
access and atomic updates via single-CAS operations. Second, warp-synchronous
concurrency protocols - Warp-Aggregated-Bitmask-Claim (WABC) and
Warp-Cooperative Match-and-Elect (WCME) - reduce contention to one atomic
operation per warp while ensuring lock-free progress. Third, a
load-factor-aware dynamic resizing strategy expands or contracts capacity in
warp-parallel K-bucket batches using linear hashing, maintaining balanced
occupancy. To handle insertions under heavy contention, Hive hash table employs
a four-step strategy: replace, claim-and-commit, bounded cuckoo eviction, and
overflow-stash fallback. This design provides lock-free fast paths and bounded
recovery cost under contention determined by a fixed eviction depth, while
eliminating ABA hazards during concurrent updates.
  Experimental evaluation on an NVIDIA RTX 4090 shows Hive hash table sustains
load factors up to 95% while delivering 1.5-2x higher throughput than
state-of-the-art GPU hash tables (Slab-Hash, DyCuckoo, WarpCore) under mixed
insert-delete-lookup workloads. On balanced workload, Hive hash table reaches
3.5 billion updates/s and nearly 4 billion lookups/s, demonstrating scalability
and efficiency for GPU-accelerated data processing.

</details>


### [147] [NEMO: Faster Parallel Execution for Highly Contended Blockchain Workloads (Full version)](https://arxiv.org/abs/2510.15122)
*François Ezard,Can Umut Ileri,Jérémie Decouchant*

Main category: cs.DC

TL;DR: NEMO是一个结合了OCC和对象数据模型的新型区块链执行引擎，旨在解决高并发下的性能瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 当前区块链的性能瓶颈已从共识层转移到执行层，尤其是在高并发场景下，现有的OCC和PCC框架性能会下降。

Method: NEMO结合了OCC和对象数据模型，并通过四项创新来解决此问题：(i) 贪婪提交规则；(ii) 精确的依赖处理以减少重执行；(iii) 使用不完整但可静态推导的读/写提示来指导执行；(iv) 基于优先级的调度器，优先执行可解锁其他交易的交易。

Result: 通过模拟执行实验，NEMO显著减少了冗余计算，并实现了比代表性方法更高吞吐量。在16个工作节点下，NEMO的吞吐量比Block-STM（先进的OCC方法）高42%，比PCC基线高61%。

Conclusion: NEMO通过结合OCC和对象数据模型，并引入多项创新，有效解决了高并发区块链执行的性能瓶颈问题，实现了显著的吞吐量提升。

Abstract: Following the design of more efficient blockchain consensus algorithms, the
execution layer has emerged as the new performance bottleneck of blockchains,
especially under high contention. Current parallel execution frameworks either
rely on optimistic concurrency control (OCC) or on pessimistic concurrency
control (PCC), both of which see their performance decrease when workloads are
highly contended, albeit for different reasons. In this work, we present NEMO,
a new blockchain execution engine that combines OCC with the object data model
to address this challenge. NEMO introduces four core innovations: (i) a greedy
commit rule for transactions using only owned objects; (ii) refined handling of
dependencies to reduce re-executions; (iii) the use of incomplete but
statically derivable read/write hints to guide execution; and (iv) a
priority-based scheduler that favors transactions that unblock others. Through
simulated execution experiments, we demonstrate that NEMO significantly reduces
redundant computation and achieves higher throughput than representative
approaches. For example, with 16 workers NEMO's throughput is up to 42% higher
than the one of Block-STM, the state-of-the-art OCC approach, and 61% higher
than the pessimistic concurrency control baseline used.

</details>


### [148] [An Elastic Job Scheduler for HPC Applications on the Cloud](https://arxiv.org/abs/2510.15147)
*Aditya Bhosale,Kavitha Chandrasekar,Laxmikant Kale,Sara Kokkila-Schumacher*

Main category: cs.DC

TL;DR: 云环境下的HPC应用可以通过Charm++和Kubernetes的弹性调度器进行动态伸缩，以提高资源利用率并减少响应时间。


<details>
  <summary>Details</summary>
Motivation: 为了有效利用云资源，需要为HPC应用开发支持动态伸缩的编程模型和调度器。然而，传统的MPI等编程模型原生支持伸缩的功能尚不成熟。

Method: 提出并实现了一个在Kubernetes集群上运行Charm++应用的Kubernetes Operator，以及一个基于优先级的弹性作业调度器，该调度器可以根据集群状态动态伸缩作业。

Result: 弹性调度器在HPC作业的动态伸缩方面开销极小，并展示了相比传统静态调度器显著的性能提升。

Conclusion: 所提出的弹性调度器能够有效利用Kubernetes集群资源，同时最小化高优先级作业的响应时间，证明了其在云HPC环境中的优越性。

Abstract: The last few years have seen an increase in adoption of the cloud for running
HPC applications. The pay-as-you-go cost model of these cloud resources has
necessitated the development of specialized programming models and schedulers
for HPC jobs for efficient utilization of cloud resources. A key aspect of
efficient utilization is the ability to rescale applications on the fly to
maximize the utilization of cloud resources. Most commonly used parallel
programming models like MPI have traditionally not supported autoscaling either
in a cloud environment or on supercomputers. While more recent work has been
done to implement this functionality in MPI, it is still nascent and requires
additional programmer effort. Charm++ is a parallel programming model that
natively supports dynamic rescaling through its migratable objects paradigm. In
this paper, we present a Kubernetes operator to run Charm++ applications on a
Kubernetes cluster. We then present a priority-based elastic job scheduler that
can dynamically rescale jobs based on the state of a Kubernetes cluster to
maximize cluster utilization while minimizing response time for high-priority
jobs. We show that our elastic scheduler, with the ability to rescale HPC jobs
with minimal overhead, demonstrates significant performance improvements over
traditional static schedulers.

</details>


### [149] [Spatiotemporal Traffic Prediction in Distributed Backend Systems via Graph Neural Networks](https://arxiv.org/abs/2510.15215)
*Zhimin Qiu,Feng Liu,Yuxiao Wang,Chenrui Hu,Ziyu Cheng,Di Wu*

Main category: cs.DC

TL;DR: 该论文提出一种基于图神经网络的交通预测方法，用于解决分布式后端系统中的交通预测问题，并显著提高了预测的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统交通预测模型在捕捉复杂依赖关系和动态特征方面存在局限性，需要新的方法来改进分布式后端系统的交通预测。

Method: 将分布式后端系统抽象为图，节点表示流量和资源状态，边表示服务交互。利用图卷积机制进行多阶特征传播和聚合，并通过门控循环结构动态建模历史序列，实现时空联合建模，最后通过解码器生成未来交通预测。模型使用均方误差进行训练。

Result: 所提方法在公开的分布式系统日志上进行了实验，与主流基线方法进行了比较。实验结果表明，该方法在不同预测范围和模型深度下均表现出稳定的性能和较低的误差，显著提高了预测精度和鲁棒性。

Conclusion: 基于图神经网络的方法在分布式后端系统的交通预测任务中表现出色，证明了图神经网络在复杂系统建模方面的潜力。

Abstract: This paper addresses the problem of traffic prediction in distributed backend
systems and proposes a graph neural network based modeling approach to overcome
the limitations of traditional models in capturing complex dependencies and
dynamic features. The system is abstracted as a graph with nodes and edges,
where node features represent traffic and resource states, and adjacency
relations describe service interactions. A graph convolution mechanism enables
multi order propagation and aggregation of node features, while a gated
recurrent structure models historical sequences dynamically, thus integrating
spatial structures with temporal evolution. A spatiotemporal joint modeling
module further fuses graph representation with temporal dependency, and a
decoder generates future traffic predictions. The model is trained with mean
squared error to minimize deviations from actual values. Experiments based on
public distributed system logs construct combined inputs of node features,
topology, and sequences, and compare the proposed method with mainstream
baselines using MSE, RMSE, MAE, and MAPE. Results show that the proposed method
achieves stable performance and low error across different prediction horizons
and model depths, significantly improving the accuracy and robustness of
traffic forecasting in distributed backend systems and verifying the potential
of graph neural networks in complex system modeling.

</details>


### [150] [BeLLMan: Controlling LLM Congestion](https://arxiv.org/abs/2510.15330)
*Tella Rajashekhar Reddy,Atharva Deshmukh,Karan Tandon,Rohan Gandhi,Anjaly Parayil,Debopam Bhattacherjee*

Main category: cs.DC

TL;DR: beLLMan是一个控制器，可以根据系统负载动态调整LLM的输出长度，从而降低延迟并提高能效。


<details>
  <summary>Details</summary>
Motivation: LLM应用通常不考虑底层基础设施的系统负载，这可能导致推理延迟增加和用户体验下降。

Method: beLLMan控制器能够主动、渐进地向LLM应用程序发出信号，以响应不断变化的系统负载来调整输出长度。

Result: 在配备H100 GPU的实际测试环境中，beLLMan在拥塞期间将停留时间控制在8倍以内，并将能耗降低了25%，同时处理了19%的请求。

Conclusion: beLLMan可以有效控制LLM应用的推理延迟，提高能效，并提升用户体验。

Abstract: Large language model (LLM) applications are blindfolded to the infrastructure
underneath and generate tokens autoregressively, indifferent to the system
load, thus risking inferencing latency inflation and poor user experience. Our
first-cut controller, named beLLMan, enables the LLM infrastructure to actively
and progressively signal the first-party LLM application to adjust the output
length in response to changing system load. On a real testbed with H100 GPUs,
beLLMan helps keep inferencing latency under control (upto 8X lower end-to-end
latency) and reduces energy consumption by 25% (while serving 19% more
requests) during periods of congestion for a summarization workload.

</details>


### [151] [Cloud-Enabled Virtual Prototypes](https://arxiv.org/abs/2510.15355)
*Tim Kraus,Axel Sauer,Ingo Feldner*

Main category: cs.DC

TL;DR: 本地与云端仿真环境在嵌入式AI开发中的权衡。


<details>
  <summary>Details</summary>
Motivation: AI算法日益复杂，嵌入式系统快速发展，需要强大的软硬件协同设计方法，而虚拟原型技术是实现这一目标的关键。需要探讨不同仿真解决方案的优劣以及本地和云端仿真环境的差异。

Method: 探讨本地与云端仿真环境的权衡，重点关注可扩展性与隐私性，分析计算基础设施的设置如何影响执行性能和数据安全性，并讨论嵌入式AI的开发流程和高效仿真的作用。

Result: 提出一种解决方案，旨在可持续地提高对远程仿真的信任度，并促进虚拟原型实践的采用。

Conclusion: 通过分析本地和云端仿真环境的优缺点，为嵌入式AI开发提供更优的仿真策略。

Abstract: The rapid evolution of embedded systems, along with the growing variety and
complexity of AI algorithms, necessitates a powerful hardware/software
co-design methodology based on virtual prototyping technologies. The market
offers a diverse range of simulation solutions, each with its unique
technological approach and therefore strengths and weaknesses. Additionally,
with the increasing availability of remote on-demand computing resources and
their adaptation throughout the industry, the choice of the host infrastructure
for execution opens even more new possibilities for operational strategies.
This work explores the dichotomy between local and cloud-based simulation
environments, focusing on the trade-offs between scalability and privacy. We
discuss how the setup of the compute infrastructure impacts the performance of
the execution and security of data involved in the process. Furthermore, we
highlight the development workflow associated with embedded AI and the critical
role of efficient simulations in optimizing these algorithms. With the proposed
solution, we aim to sustainably improve trust in remote simulations and
facilitate the adoption of virtual prototyping practices.

</details>


### [152] [(Almost) Perfect Discrete Iterative Load Balancing](https://arxiv.org/abs/2510.15473)
*Petra Berenbrink,Robert Elsässer,Tom Friedetzky,Hamed Hosseinpour,Dominik Kaaser,Peter Kling,Thomas Sauerwald*

Main category: cs.DC

TL;DR: 该研究提出了一种基于匹配的离散迭代负载均衡方案，适用于任意图。该方案通过随机匹配节点并平均其负载来工作，对于总负载为奇数的节点，随机选择一个节点接收额外的token。


<details>
  <summary>Details</summary>
Motivation: 在分布式系统中，将负载均衡到各个节点是一个基础性问题。该研究旨在探索离散、迭代的负载均衡方法，并分析其在任意图上的性能。

Method: 提出了一类基于匹配的局部均衡方案。在每个回合，随机选择一对节点进行匹配，并平均它们持有的token数量。如果token总和为奇数，则随机选择一个节点接收额外的token。该方案涵盖了匹配模型、均衡电路模型和异步模型。

Result: 证明了该离散均衡方案可以达到3个单位的离散度，并且所需的回合数渐近地匹配了连续负载均衡的谱界。

Conclusion: 该离散负载均衡方案在任意图上实现了常数级别的离散度，表明离散负载均衡的难度不亚于连续负载均衡。

Abstract: We consider discrete, iterative load balancing via matchings on arbitrary
graphs. Initially each node holds a certain number of tokens, defining the load
of the node, and the objective is to redistribute the tokens such that
eventually each node has approximately the same number of tokens. We present
results for a general class of simple local balancing schemes where the tokens
are balanced via matchings. In each round the process averages the tokens of
any two matched nodes. If the sum of their tokens is odd, the node to receive
the one excess token is selected at random. Our class covers three popular
models: in the matching model a new matching is generated randomly in each
round, in the balancing circuit model a fixed sequence of matchings is applied
periodically, and in the asynchronous model the load is balanced over a
randomly chosen edge.
  We measure the quality of a load vector by its discrepancy, defined as the
difference between the maximum and minimum load across all nodes. As our main
result we show that with high probability our discrete balancing scheme reaches
a discrepancy of $3$ in a number of rounds which asymptotically matches the
spectral bound for continuous load balancing with fractional load.
  This result improves and tightens a long line of previous works, by not only
achieving a small constant discrepancy (instead of a non-explicit, large
constant) but also holding for arbitrary instead of regular graphs. The result
also demonstrates that in the general model we consider, discrete load
balancing is no harder than continuous load balancing.

</details>


### [153] [Balancing Fairness and Performance in Multi-User Spark Workloads with Dynamic Scheduling (extended version)](https://arxiv.org/abs/2510.15485)
*Dāvis Kažemaks,Laurens Versluis,Burcu Kulahcioglu Ozkan,Jérémie Decouchant*

Main category: cs.DC

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Apache Spark is a widely adopted framework for large-scale data processing.
However, in industrial analytics environments, Spark's built-in schedulers,
such as FIFO and fair scheduling, struggle to maintain both user-level fairness
and low mean response time, particularly in long-running shared applications.
Existing solutions typically focus on job-level fairness which unintentionally
favors users who submit more jobs. Although Spark offers a built-in fair
scheduler, it lacks adaptability to dynamic user workloads and may degrade
overall job performance. We present the User Weighted Fair Queuing (UWFQ)
scheduler, designed to minimize job response times while ensuring equitable
resource distribution across users and their respective jobs. UWFQ simulates a
virtual fair queuing system and schedules jobs based on their estimated finish
times under a bounded fairness model. To further address task skew and reduce
priority inversions, which are common in Spark workloads, we introduce runtime
partitioning, a method that dynamically refines task granularity based on
expected runtime. We implement UWFQ within the Spark framework and evaluate its
performance using multi-user synthetic workloads and Google cluster traces. We
show that UWFQ reduces the average response time of small jobs by up to 74%
compared to existing built-in Spark schedulers and to state-of-the-art fair
scheduling algorithms.

</details>


### [154] [Retrofitting Service Dependency Discovery in Distributed Systems](https://arxiv.org/abs/2510.15490)
*Diogo Landau,Gijs Blanken,Jorge Barbosa,Nishant Saurabh*

Main category: cs.DC

TL;DR: 该论文提出了一种名为XXXX的新型运行时系统，用于构建进程级别的服务依赖图，解决了NAT等复杂路由技术导致的依赖关系推断不准确的问题。该系统通过在TCP数据包头中注入元数据来实现，无需代码插桩，并且在部分部署时也不会影响现有TCP连接。实验评估表明，XXXX在各种网络配置和微服务基准测试中表现优于现有技术，在准确性和召回率方面也达到了很高水平。


<details>
  <summary>Details</summary>
Motivation: 现代分布式系统中的服务依赖关系复杂，故障易于传播，因此准确构建服务依赖图对定位性能下降的根源至关重要。然而，NAT等路由技术会干扰现有的依赖图推断方法。

Method: XXXX通过在TCP数据包头中注入元数据来构建进程级别服务依赖图，无需修改源代码，并且能够处理NAT等复杂网络路由。该方法具有非侵入性，即使在接收端没有部署的情况下也不会影响TCP连接。

Result: 在涉及NAT和微服务基准测试的九种场景下，XXXX是唯一在所有网络配置中均表现一致的方法。在准确性和召回率方面，其表现与现有最佳技术相当或更优，在大多数场景下达到100%。

Conclusion: XXXX是一种有效的、可扩展的运行时系统，能够准确地构建服务依赖图，即使在存在NAT等复杂网络配置的情况下也能保持高性能。

Abstract: Modern distributed systems rely on complex networks of interconnected
services, creating direct or indirect dependencies that can propagate faults
and cause cascading failures. To localize the root cause of performance
degradation in these environments, constructing a service dependency graph is
highly beneficial. However, building an accurate service dependency graph is
impaired by complex routing techniques, such as Network Address Translation
(NAT), an essential mechanism for connecting services across networks. NAT
obfuscates the actual hosts running the services, causing existing run-time
approaches that passively observe network metadata to fail in accurately
inferring service dependencies. To this end, this paper introduces XXXX, a
novel run-time system for constructing process-level service dependency graphs.
It operates without source code instrumentation and remains resilient under
complex network routing mechanisms, including NAT. XXXX implements a
non-disruptive method of injecting metadata onto a TCP packet's header that
maintains protocol correctness across host boundaries. In other words, if no
receiving agent is present, the instrumentation leaves existing TCP connections
unaffected, ensuring non-disruptive operation when it is partially deployed
across hosts. We evaluated XXXX extensively against three state-of-the-art
systems across nine scenarios, involving three network configurations
(NAT-free, internal-NAT, external-NAT) and three microservice benchmarks. XXXX
was the only approach that performed consistently across networking
configurations. With regards to correctness, it performed on par with, or
better than, the state-of-the-art with precision and recall values of 100% in
the majority of the scenarios.

</details>


### [155] [PRISM: Probabilistic Runtime Insights and Scalable Performance Modeling for Large-Scale Distributed Training](https://arxiv.org/abs/2510.15596)
*Alicia Golden,Michael Kuchnik,Samuel Hsia,Zachary DeVito,Gu-Yeon Wei,David Brooks,Carole-Jean Wu*

Main category: cs.DC

TL;DR: 在超大规模模型训练中，GPU 集群的动态性能波动是训练效率的关键瓶颈。本文提出了 PRISM 框架，通过统计方法量化性能波动，并利用该框架优化训练策略和识别关键计算核，以提高训练效率和稳定性。


<details>
  <summary>Details</summary>
Motivation: 大规模（超过 64k GPU）的分布式模型训练面临着日益严峻的 GPU 性能波动问题，这种波动会严重影响训练效率。了解和量化这种波动对于优化训练过程至关重要。

Method: PRISM 框架，它采用统计方法量化大规模分布式训练的性能波动，并提供对训练时间的概率性保证。通过分析 GPU 微基准测试，研究硬件和环境对性能波动的影响。

Result: PRISM 框架在实际系统中得到验证，预测准确度（Kolmogorov-Smirnov 距离为 20.8%）。通过 PRISM 分析发现，根据计算节点部署位置的不同，最高可实现 1.26 倍的性能提升。优化 AllGather 和 ReduceScatter 等通信核能显著降低训练步长时间的波动性。

Conclusion: PRISM 框架能够有效量化和预测大规模分布式训练中的性能波动，并为优化训练策略、硬件选择和系统设计提供指导，从而显著提高训练效率和稳定性。

Abstract: Large model training beyond tens of thousands of GPUs is an uncharted
territory. At such scales, disruptions to the training process are not a matter
of if, but a matter of when -- a stochastic process degrading training
productivity. Dynamic runtime variation will become increasingly more frequent
as training scales up and GPUs are operated in increasingly power-limited and
thermally-stressed environments. At the 64k GPU scale, we already observed 9%
GPU time variability for frontier foundation model training. To understand
potential causes of variability, we analyze GPU microbenchmarks at scale across
a variety of platforms, showing up to 14% variation in GPU performance on GEMM
workloads depending on training hardware and deployed environment.
  Motivated by our analysis and the large design space around performance
variability, we present PRISM -- a performance modeling framework that
considers the stochastic nature of the large-scale distributed training. The
core of PRISM is the statistical method that provides a quantifiable measure
for probabilistic guarantees on training time. Using PRISM, we explore the
design and optimization space of distributed training, from parallelization
methods to next-generation training systems. PRISM is validated with
real-system measurement, showing training time prediction accuracy with 20.8%
Kolmogorov-Smirnov distance. Using PRISM, we demonstrate that, depending on
computation node placement, up to 1.26x performance improvement potential is
available if we factor in sensitivities of parallelization strategies to
variation. In addition, we use PRISM to identify kernels to optimize for
reducing performance variability and predict probability of slow-down for
large-scale jobs where variation is magnified. We find optimizing communication
kernels, such as AllGather and ReduceScatter, contribute most to minimizing
variability in training step time.

</details>


### [156] [GOGH: Correlation-Guided Orchestration of GPUs in Heterogeneous Clusters](https://arxiv.org/abs/2510.15652)
*Ahmad Raeisi,Mahdi Dolati,Sina Darabi,Sadegh Talebi,Patrick Eugster,Ahmad Khonsari*

Main category: cs.DC

TL;DR: 该研究提出了一种基于学习的在线系统，用于在异构硬件集群中管理机器学习工作负载，通过迭代优化来最小化能耗并满足性能要求。


<details>
  <summary>Details</summary>
Motivation: 在异构硬件集群中，机器学习对计算资源的需求不断增长，使得资源的高效分配面临挑战。由于升级到最新硬件并不可行，因此需要可持续地利用现有混合代硬件。

Method: 提出一个基于学习的在线系统，该系统使用两个神经网络。第一个网络提供新模型利用不同硬件类型以及对共同部署模型影响的初始估计。然后，一个优化器根据这些估计进行资源分配。部署后，系统会监控实际性能，并利用这些数据通过第二个神经网络来优化其预测。

Result: 该系统能够自适应地、迭代地学习，从而在异构深度学习集群中做出更有效的资源分配决策，提高了资源利用率和能效。

Conclusion: 所提出的学习系统能够通过迭代优化，在异构硬件集群中有效地管理机器学习工作负载，在满足性能要求的同时最小化能源消耗。

Abstract: The growing demand for computational resources in machine learning has made
efficient resource allocation a critical challenge, especially in heterogeneous
hardware clusters where devices vary in capability, age, and energy efficiency.
Upgrading to the latest hardware is often infeasible, making sustainable use of
existing, mixed-generation resources essential. In this paper, we propose a
learning-based architecture for managing machine learning workloads in
heterogeneous clusters. The system operates online, allocating resources to
incoming training or inference requests while minimizing energy consumption and
meeting performance requirements. It uses two neural networks: the first
provides initial estimates of how well a new model will utilize different
hardware types and how it will affect co-located models. An optimizer then
allocates resources based on these estimates. After deployment, the system
monitors real performance and uses this data to refine its predictions via a
second neural network. This updated model improves estimates not only for the
current hardware but also for hardware not initially allocated and for
co-location scenarios not yet observed. The result is an adaptive, iterative
approach that learns over time to make more effective resource allocation
decisions in heterogeneous deep learning clusters.

</details>


### [157] [A Post-Quantum Lower Bound for the Distributed Lovász Local Lemma](https://arxiv.org/abs/2510.15698)
*Sebastian Brandt,Tim Göttlicher*

Main category: cs.DC

TL;DR: 本文研究了分布式量子计算中的 Lov	ászl	ocal lemma (LLL) 问题，并证明了在 quantum-LOCAL 模型中，分布式 LLL 的复杂度至少为 $2^{\Omega(\log^* n)}$。研究结果也适用于 sinkless orientation 的特殊情况，并在更强的 randomized online-LOCAL 模型中获得了相同的下界。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决分布式量子计算中的 Lov	ászl	ocal lemma (LLL) 问题，并提供相关的复杂度下界。

Method: 本文提出了一种新的证明下界的技术，并将其应用于 sinkless orientation 和分布式 LLL 问题。

Result: 证明了在 quantum-LOCAL 模型中，分布式 LLL 的复杂度下界为 $2^{\Omega(\log^* n)}$。同时，在 randomized online-LOCAL 模型中也获得了 sinkless orientation 的下界。

Conclusion: 本文首次为 sinkless orientation 和分布式 LLL 在多种模型中提供了超常数下界，并提出了一种新的、可能通用的后量子下界证明技术。

Abstract: In this work, we study the Lov\'asz local lemma (LLL) problem in the area of
distributed quantum computing, which has been the focus of attention of recent
advances in quantum computing [STOC'24, STOC'25, STOC'25]. We prove a lower
bound of $2^{\Omega(\log^* n)}$ for the complexity of the distributed LLL in
the quantum-LOCAL model. More specifically, we obtain our lower bound already
for a very well-studied special case of the LLL, called sinkless orientation,
in a stronger model than quantum-LOCAL, called the randomized online-LOCAL
model. As a consequence, we obtain the same lower bounds for sinkless
orientation and the distributed LLL also in a variety of other models studied
across different research communities.
  Our work provides the first superconstant lower bound for sinkless
orientation and the distributed LLL in all of these models, addressing recently
stated open questions. Moreover, to obtain our results, we develop an entirely
new lower bound technique that we believe has the potential to become the first
generic technique for proving post-quantum lower bounds for many of the most
important problems studied in the context of locality.

</details>


### [158] [Funky: Cloud-Native FPGA Virtualization and Orchestration](https://arxiv.org/abs/2510.15755)
*Atsushi Koshiba,Charalampos Mainas,Pramod Bhatotia*

Main category: cs.DC

TL;DR: FPGA在云原生环境中的应用受到限制，因为缺乏对FPGA的虚拟化、隔离和抢占支持。本文提出了Funky，一个全栈FPGA感知编排引擎，通过FPGA虚拟化、状态管理和符合行业标准的编排组件来解决这些问题。Funky能够实现高利用率、可扩展性和容错能力，并且性能开销低，镜像尺寸小。


<details>
  <summary>Details</summary>
Motivation: 云原生环境中的FPGA应用受到限制，现有CPU导向的编排器缺乏对FPGA的虚拟化、隔离和抢占支持，导致服务能力不足。

Method: 提出Funky，一个全栈FPGA感知编排引擎，包含FPGA虚拟化、状态管理和FPGA感知编排组件。

Result: Funky能够适配23个OpenCL应用，OCI镜像大小比Docker容器小28.7倍，性能开销仅为7.4%，并能在生产环境中实现可扩展、容错和高效调度。

Conclusion: Funky成功地解决了FPGA在云原生环境中的应用障碍，提供了强大的编排能力，实现了高利用率、可扩展性和容错能力。

Abstract: The adoption of FPGAs in cloud-native environments is facing impediments due
to FPGA limitations and CPU-oriented design of orchestrators, as they lack
virtualization, isolation, and preemption support for FPGAs. Consequently,
cloud providers offer no orchestration services for FPGAs, leading to low
scalability, flexibility, and resiliency.
  This paper presents Funky, a full-stack FPGA-aware orchestration engine for
cloud-native applications. Funky offers primary orchestration services for FPGA
workloads to achieve high performance, utilization, scalability, and fault
tolerance, accomplished by three contributions: (1) FPGA virtualization for
lightweight sandboxes, (2) FPGA state management enabling task preemption and
checkpointing, and (3) FPGA-aware orchestration components following the
industry-standard CRI/OCI specifications.
  We implement and evaluate Funky using four x86 servers with Alveo U50 FPGA
cards. Our evaluation highlights that Funky allows us to port 23 OpenCL
applications from the Xilinx Vitis and Rosetta benchmark suites by modifying
3.4% of the source code while keeping the OCI image sizes 28.7 times smaller
than AMD's FPGA-accessible Docker containers. In addition, Funky incurs only
7.4% performance overheads compared to native execution, while providing
virtualization support with strong hypervisor-enforced isolation and
cloud-native orchestration for a set of distributed FPGAs. Lastly, we evaluate
Funky's orchestration services in a large-scale cluster using Google production
traces, showing its scalability, fault tolerance, and scheduling efficiency.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [159] [A Structured Family of Grassmannian Constellations via Geodesic Mapping for MIMO Noncoherent Communications](https://arxiv.org/abs/2510.15070)
*Álvaro Pendás-Recondo,Enrique Pendás-Recondo*

Main category: eess.SP

TL;DR: 本文提出了一种新颖的Grassmannian星座，用于MIMO非相干通信，具有单非零行条目、低硬件复杂度和可比的错误性能。


<details>
  <summary>Details</summary>
Motivation: 为MIMO非相干通信设计一种利用Grassmann流形几何结构的星座。

Method: 基于Grassmann流形上的测地线构造星座。

Result: 星座大小限制为$4M^2$，频谱效率为0.25-1 bps/Hz，但具有单非零行条目、降低硬件复杂度和功耗的优点，并实现了与最先进设计相当的错误性能和简化的ML检测。

Conclusion: 所提出的Grassmannian星座设计在MIMO非相干通信中具有硬件和功耗优势，并能与现有最优设计相媲美。

Abstract: This work presents a novel structured family of Grassmannian constellations
for multiple-input multiple-output (MIMO) noncoherent communications over
Rayleigh block-fading channels, where neither the transmitter nor the receiver
has channel state information (CSI). The proposed constellation design is built
upon the geodesic curves of the Grassmann manifold, thereby exploiting its
underlying geometric structure. The resulting solution is limited in spectral
efficiency (with a maximum constellation size of $4M^2$ points, where $M$ is
the number of transmit antennas), targeting a rate in the range of $0.25$-$1$
bps/Hz. However, all space-time matrices resulting from this design exhibit the
remarkable property of having a single nonzero entry per row, meaning that only
one transmit antenna is active per time slot. This property significantly
reduces hardware complexity and implementation cost, while also lowering power
consumption, as only a single power amplifier is required for transmission.
Furthermore, within the constellation size limits, the proposed design achieves
error performance comparable to state-of-the-art optimization-based
unstructured designs, as validated through symbol error rate (SER) numerical
results. It also enables simple yet effective bit labeling, confirmed by
comparisons of bit error rate (BER) and SER, and reduces the computational
complexity of the maximum-likelihood (ML) detector for Grassmannian
constellations by a factor of $M$.

</details>


### [160] [Pulse Shaping Filter Design for Integrated Sensing & Communication with Zak-OTFS](https://arxiv.org/abs/2510.15195)
*Nishant Mehrotra,Sandesh Rao Mattu,Robert Calderbank*

Main category: eess.SP

TL;DR: Zak-OTFS 框架是用于高延迟和多普勒扩展环境中的集成感知与通信 (ISAC) 的一种新兴框架。对于 ISAC，脉冲成形滤波器的设计至关重要。对于感知，局部化的脉冲成形滤波器能够实现接近物理散射信道的理想输入-输出 (I/O) 关系估计。对于通信，信息格上的脉冲形状正交性可防止符号间干扰，并且没有时域和带宽扩展可实现完整的频谱效率。同时满足这三个目标的滤波器是 ISAC 的理想选择。现有的滤波器设计可以实现上述目标中的两个，但不能同时实现所有三个目标。例如，sinc 滤波器是正交且带宽/时域受限的，但不是局部化的。高斯滤波器是局部化且带宽/时域受限的，但不是正交的。RRC 滤波器是局部化且正交的，但不是带宽/时域受限的。最近提出的混合高斯-sinc 滤波器比 sinc 滤波器更局部化且带宽/时域受限，但不是正交的。在这项工作中，我们通过各向同性正交变换算法设计满足所有三个目标的最佳脉冲成形滤波器。与文献中现有的滤波器选择相比，所提出的脉冲成形滤波器在数据检测（通信）和 I/O 关系估计（感知）性能方面有所提高。


<details>
  <summary>Details</summary>
Motivation: ISAC 框架需要一种能够同时满足局部化、正交性和时域/带宽限制这三个关键目标的脉冲成形滤波器，而现有滤波器设计无法同时实现所有目标。

Method: 利用各向同性正向变换算法 (Isotropic Orthogonal Transform Algorithm) 设计满足局部化、正交性和时域/带宽限制这三个目标的脉冲成形滤波器。

Result: 提出的脉冲成形滤波器在数据检测（通信）和 I/O 关系估计（感知）方面相比现有滤波器设计取得了更好的性能。

Conclusion: 通过各向同性正向变换算法成功设计了能够同时满足局部化、正交性和时域/带宽限制的脉冲成形滤波器，为 Zak-OTFS 框架在 ISAC 应用中提供了更优的性能。

Abstract: Zak-OTFS is an emerging framework for integrated sensing & communication
(ISAC) in high delay and Doppler spread environments. A critical enabler for
ISAC with Zak-OTFS is the design of pulse shaping filters. For sensing, a
localized pulse shaping filter enables ideal input-output (I/O) relation
estimates close to the physical scattering channel. For communication,
orthogonality of the pulse shape on the information lattice prevents
inter-symbol interference, and no time and bandwidth expansion enables full
spectral efficiency. A filter simultaneously meeting all three objectives is
ideal for ISAC. Existing filter designs achieve two of the above objectives,
but not all three simultaneously. For instance, the sinc filter is orthogonal
and bandwidth/time-limited, but is not localized. The Gaussian filter is
localized and bandwidth/time-limited, but not orthogonal. The RRC filter is
localized and orthogonal, but not bandwidth/time-limited. A recently proposed
hybrid Gaussian-sinc filter is more localized than the sinc filter and
bandwidth/time-limited, but is not orthogonal. In this work, we design optimal
pulse shaping filters meeting all three objectives via the Isotropic Orthogonal
Transform Algorithm. The proposed pulse shaping filters offer improved data
detection (communication) and I/O relation estimation (sensing) performance
compared to existing filter choices in the literature.

</details>


### [161] [Multidimensional Physiology-Inspired Enhanced Vital Sign Monitoring Using MIMO mmWave Bio-radar](https://arxiv.org/abs/2510.15278)
*Heyao Zhu,Yimeng Zhao,Zirui Zhang,Huansheng Yi,Chenbin Gao,Canhua Xu,Jianqi Wang,Fugui Qi*

Main category: eess.SP

TL;DR: 本研究提出了一种基于多维度生理特征驱动的多输入多输出（MIMO）生物雷达生命体征增强检测方法，以解决现有毫米波（mmWave）雷达生命体征监测中多通道信号融合效率低的问题。


<details>
  <summary>Details</summary>
Motivation: 随着人口老龄化加剧和慢性病负担增加，生命体征监测需求日益迫切，而现有基于等权重平均的相控阵雷达系统在多通道信号融合方面效率低下。

Method: 该方法采用两阶段融合策略：第一阶段，基于生理特征的单通道信号增强，构建胸壁多散射点模型，根据呼吸/心动生理频带能量比选择有效测距单元，并使用最大比值合并（MRC）技术增强信噪比（SNR）。第二阶段，基于脏器辐射空间分布特征的多通道融合，引入脏器空间辐射特征进行信噪比和通道属性筛选，然后采用物理模型和模板匹配方法提取呼吸和心率。

Result: 实验结果验证了脏器辐射空间分布特征的存在性，并分析了距离和状态对算法的影响。

Conclusion: 所提出的方法能够有效克服传统生命体征监测技术的局限性，提高多通道信号融合的效率，为实现更精确的生命体征监测提供了新的途径。

Abstract: With the intensiffcation of population aging and increasing burden of chronic
diseases, the demand for vital signs monitoring is becoming increasingly
urgent. A key challenge facing current non-contact detection technologies using
millimeter wave (mmWave) radar is the low efffciency of multi-channel signal
fusion in array radar systems based on equal weighting. To address this
challenge, this paper proposes a vital sign enhancement detection method for
multiple input and multiple output (MIMO) bio-radar, driven by multidimensional
physiological characteristics, which overcomes traditional limitations through
a two-stage fusion strategy. Stage 1: Enhanced Vital Sign Detection Using
Single-Channel Signals Based on Physiological Characteristics. First, a chest
wall multi-scattering point model is constructed. For single channel
time-distance two-dimensional echo signals, effective range bins are selected
based on the respiratory/cardiac physiological frequency band energy ratio, and
the signal-to-noise ratio (SNR) of respiration/heart signals is enhanced using
phase-aligned maximal ratio combining (MRC). Stage 2: Multi-Channel Fusion
Based on Organ Radiation Spatial Distribution Characteristics. The spatial
radiation characteristics of cardiopulmonary organs are introduced for the
ffrst time as the theoretical foundation for SNR-based channel screening,
channel attribute identiffcation, and multi-channel weighted fusion. Then, we
propose a template matching method to extract respiratory rate (RR) and heart
rate (HR) by adopting physical models of respiration and cardiac activities.
The experimental results demonstrate the existence of the spatial distribution
characteristics of organ radiation. In addition, we analyzed the impact of
distance and state on the algorithm from these two aspects.

</details>


### [162] [Multi-Target Flexible Angular Emulation for ISAC Base Station Testing Using a Conductive Amplitude and Phase Matrix Setup: Framework and Experimental Validation](https://arxiv.org/abs/2510.15457)
*Chunhui Li,Chengrui Wang,Zhiqiang Yuan,Wei Fan*

Main category: eess.SP

TL;DR: 提出了一种用于集成感知与通信（ISAC）基站（BS）的雷达目标模拟器（RTS）框架，解决了多目标模拟的接口限制问题，并在两种ISAC操作模式下进行了实验验证。


<details>
  <summary>Details</summary>
Motivation: ISAC技术发展需要对未来ISAC基站在真实场景下进行全面评估，但现有的雷达目标模拟器（RTS）接口有限，难以满足大规模天线阵列ISAC基站的多目标模拟需求。

Method: 提出了一种基于导电幅度相移矩阵的框架，该框架在ISAC基站和RTS之间引入了可调谐的导电幅度相移调制网络，以解决RTS接口限制问题。并针对ISAC基站的阵列双工传输与接收（ADTR）和分阵列传输与接收（SATR）两种工作模式进行了配置研究。

Result: 通过两种单站传感场景的实验验证，包括ADTR模式下的多无人机动态传感和SATR模式下的单无人机静态传感，证明了该框架能够精确模拟多传感目标的联合RCS、距离、速度和角度特性。

Conclusion: 所提出的导电幅度相移矩阵框架是一种简单、高效且实用的解决方案，能够有效解决ISAC基站测试中的多目标模拟挑战，具有在sub-6 GHz ISAC基站开发和验证中应用的巨大潜力。

Abstract: Comprehensive evaluation of the functionalities, algorithms, hardware
components, and performance characteristics of future integrated sensing and
communication (ISAC) base stations (BSs) under realistic deployment scenarios
in controlled laboratory environments represents a critical requirement for
ISAC technology advancement. A primary challenge in achieving this objective
involves the emulation of multiple targets with arbitrary radar cross-section
(RCS), range, angle, and Doppler profiles for ISAC BS equipped with large-scale
antenna arrays using radar target simulator (RTS) with limited interface ports.
In this work, we introduce a simple yet highly effective and practical
conductive amplitude and phase matrix framework to address this fundamental
challenge. The core concept involves introducing a tunable conductive amplitude
and phase modulation network in the test configuration between the ISAC BS
under test and a RTS. Based on this structure, we subsequently investigate the
corresponding configurations for different sensing operational modes of ISAC
BSs, specifically the array duplex transmission and reception (ADTR) mode and
the split-array transmission and reception (SATR) mode. For experimental
validation, we design two distinct monostatic sensing scenarios to demonstrate
the framework capabilities across both operational modes. The first scenario
involves dynamic multi-drone sensing validation for ADTR mode operation, while
the second scenario addresses static single-drone sensing for SATR mode
validation. The experimental results demonstrate that the proposed framework
can accurately emulate the joint RCS, range, velocity, and angular
characteristics of multiple sensing targets within the conductive test
environment, highlighting its significant potential for testing applications in
sub-6 GHz ISAC BS development and validation.

</details>


### [163] [Pseudo-Random TDM-MIMO FMCW Based Millimeter-Wave Sensing and Communication Integration for UAV Swarm](https://arxiv.org/abs/2510.15575)
*Yi Tao,Zhen Gao,Zhuoran Li,Ziwei Wan,Tuan Li,Chunli Zhu,Lei Chen,Guanghui Wen,Dezhi Zheng,Dusit Niyato*

Main category: eess.SP

TL;DR: 该论文提出了一种基于伪随机时分复用（TDM）-MIMO毫米波（mmWave）调频连续波（FMCW）的集成传感与通信（ISAC）解决方案，用于无人机（UAV）集群的协同操作。


<details>
  <summary>Details</summary>
Motivation: 无人机集群在通信和环境感知方面需要高效的硬件和频谱资源共享，ISAC技术能满足此需求，提升系统性能、灵活性和效率。

Method: 提出了一种新的ISAC啁啾波形，能够同时调制延迟域和复数幅度，并具备高精度传感能力。通过伪随机天线选择和压缩感知算法解决TDM-MIMO挑战，确保最大无模糊速度。采用啁啾划分多址（CDMA）方案，实现无干扰多天线传输，动态分配时频资源，支持多用户传输。提出一种通信与传感融合的动态迭代计算方案，同时实现数据解调和传感参数估计。

Result: 仿真结果表明，该方案在无人机动态飞行场景下实现了ISAC。与mmWave-LoRadar相比，该方案在通信和传感性能上均有优势，但传感性能略低于传统FMCW。在城市杂波模型下，该方案仍表现出良好的鲁棒性，尽管存在一定程度的性能下降。

Conclusion: 该论文提出的基于伪随机TDM-MIMO mmWave FMCW的ISAC解决方案，能够有效地应用于无人机集群的协同操作，并在通信和传感方面展现出优越性能和鲁棒性。

Abstract: The integrated sensing and communications (ISAC) can achieve the sharing of
hardware and spectrum resources, enabling efficient data transmission and
environmental sensing. This fusion is particularly important for unmanned
aerial vehicle (UAV) swarms, as it enhances the overall performance,
flexibility, and efficiency of such systems. To facilitate the collaborative
operations among UAVs, this paper proposes an ISAC solution based on the
pseudo-random time-division multiplexing (TDM)-multiple input multiple output
(MIMO) millimeter-wave (mmWave) frequency modulated continuous wave (FMCW).
Specifically, a novel ISAC chirp waveform is proposed to modulate data in both
the delay domain and complex amplitude, while also possessing high-precision
sensing capabilities. To address challenges in the TDM-MIMO, we utilize the
pseudo-random antenna selection and compressed sensing algorithms, ensuring
that the maximum unambiguous velocity is not compromised. Moreover, by
employing a chirp-division multiple access scheme, we propose an
interference-free multiple antenna transmission scheme to achieve dynamic
allocation of time-frequency resources and multi-user transmission. Finally, we
propose a communication and sensing fusion-based dynamic iterative computation
scheme, simultaneously achieving data demodulation and sensing parameter
estimation. Simulation results show that the proposed scheme can achieve ISAC
under the dynamic flight scenarios of UAVs. Meanwhile, the scheme outperforms
the mmWave-LoRadar in communication and sensing performance, yet its sensing
performance is slightly lower than that of the traditional FMCW. Under the
urban clutter modeling, the scheme still maintains favorable robustness despite
a certain degree of performance degradation.

</details>


### [164] [More on Boundary Behavior of Univalent Harmonic Mappings](https://arxiv.org/abs/2510.15689)
*Gebreslassie atsbha weldegebrial,hunduma legesse geleta*

Main category: eess.SP

TL;DR: 该研究扩展了关于注入谐波映射边界行为的工作，特别关注解析函数的幅角和对数，并研究了在特定条件下扩张的零点集。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是建立在Laugesen、Bshouty等人的工作之上，扩展关于谐波映射的边界行为的研究，特别是在不同条件下对解析函数的幅角和对数进行研究。

Method: 研究方法包括分析谐波函数在边界处的一阶导数，并研究扩张的零点集在斯托尔兹角内的行为。

Result: 研究结果表明，当谐波函数f的一阶导数在边界处为无穷大时，扩张在任何斯托尔兹角内只拥有有限个零点。

Conclusion: 该研究成功地扩展了先前关于谐波映射边界行为的研究，并为理解特定条件下扩张的零点行为提供了新的见解。

Abstract: Many authors have examined various boundary behaviors of injective harmonic
mappings in the open unit disk. Building on Laugesen's work, Bshouty and others
explored the boundary behavior of harmonic mappings under different conditions.
In this paper, we extend their work and find out the angular limits of the
arguments and logarithms of analytic functions under various conditions. We
also examined the dilatation possesses only a finite set of zeros within any
stolz angle if the first derivative of harmonic function $f$ at the boundary is
positive infinity.

</details>


### [165] [Detection Seizure Onset Zone Using Circadian Fluctuating Epileptic Biomarkers: A Signal Processing and Machine Learning Approach](https://arxiv.org/abs/2510.15717)
*Mehdi Zekriyapanah Gashti,Mostafa Mohammadpour,Hassan Eshkiki*

Main category: eess.SP

TL;DR: 癫痫生物标志物在癫痫治疗手术规划中至关重要，但其会随时间变化。本研究旨在探究昼夜节律如何影响癫痫生物标志物，并确定其分析的最佳时间。研究人员对癫痫患者的颅内脑电图数据进行了回顾性分析，通过自动检测识别了棘波、棘波序列、高频振荡（HFOs）和病理性HFOs等生物标志物，并计算了α/δ比值来区分睡眠和清醒状态。结果显示，所有生物标志物的发生率在睡眠阶段均高于清醒阶段，且病理性HFOs和棘波序列比棘波或HFOs更能精确指示与癫痫发作的距离。本研究首次综合运用多种生物标志物来提高癫痫发作起始区的预测精度，并强调了睡眠期数据分析在提高预测准确性方面的重要性。


<details>
  <summary>Details</summary>
Motivation: 癫痫生物标志物在术前规划中至关重要，但其时效性会影响效果。本研究旨在探究昼夜节律对癫痫生物标志物的影响，并确定最佳分析时间以提高其临床有效性。

Method: 对9名癫痫患者的颅内脑电图数据进行回顾性分析，自动检测棘波、棘波序列、高频振荡（HFOs）和病理性HFOs，并计算α/δ比值以区分睡眠和清醒状态。比较不同睡眠/清醒状态下生物标志物的变化情况及其与发作起始区的关系。

Result: 睡眠/清醒状态分类的曲线下面积为84%。所有生物标志物的发生率在睡眠阶段均高于清醒阶段。病理性HFOs和棘波序列比棘波或HFOs更能精确指示与发作起始区的距离。

Conclusion: 癫痫生物标志物的发生率在睡眠和清醒时存在显著差异，睡眠期数据分析能更有效地预测癫痫发作起始区。本研究首次综合运用多种生物标志物，为提高癫痫发作起始区预测精度提供了新的途径。

Abstract: Epileptic biomarkers play a crucial role in identifying the origin of
seizures, an essential aspect of pre-surgical planning for epilepsy treatment.
These biomarkers can vary significantly over time. By studying these temporal
fluctuations, we can enhance their effectiveness in guiding surgical planning.
This research focuses on examining how circadian rhythms influence epilepsy
biomarkers and aims to determine the optimal times for their analysis. To
investigate the relationship between epilepsy biomarkers and circadian rhythm,
the sleep/wake states first need to be classified. After the biomarkers are
identified, they are compared across these states. A retrospective analysis was
conducted on intracranial electroencephalography data from patients with focal
epilepsy. The biomarkers spike, sequence of spikes, high-frequency oscillations
(HFOs), and pathological HFOs were identified through automatic detection. The
alpha/delta ratio was also calculated to distinguish between asleep and awake
stages. Data from 9 patients were analyzed, and the classification of sleep and
wake states was achieved with an area under the curve of 84%. All biomarker
rates were higher during the sleep stage compared to the wake stage.
Pathological HFOs and the sequence of spikes proved to be more precise
indicators regarding distance to seizure onset than spikes or HFOs. Unlike
previous studies that relied predominantly on long-term spike biomarker
analysis, this study is the first to utilize a comprehensive set of biomarkers,
including HFOs, spike sequences, and pathological HFOs, to enhance seizure
onset zone prediction. The rates of epilepsy biomarkers during sleep vary
considerably from those seen while awake, making sleep data analysis more
effective for accurately predicting the seizure onset zone.

</details>


### [166] [On the Impact of Electromagnetic Interference and Inter-RIS Reflections in Indoor Factory Local 6G Networks](https://arxiv.org/abs/2510.15759)
*Ishan Rangajith Koralege,Nurul Huda Mahmood,Arthur Sousa de Sena,Italo Atzeni*

Main category: eess.SP

TL;DR: 本论文研究了电磁干扰(EMI)和多RIS间反射(IRR)对6G局部网络中可重构智能表面(RIS)性能的联合影响，并提出了一种基于黎曼共轭梯度法的交替优化算法来解决这些问题。


<details>
  <summary>Details</summary>
Motivation: 可重构智能表面(RIS)是6G网络的一个重要组成部分，但其性能会受到电磁干扰(EMI)和多RIS间反射(IRR)的影响。

Method: 通过系统级仿真评估EMI和IRR对多RIS多小区系统的联合影响，并提出一种基于黎曼共轭梯度法的交替优化算法来优化RIS相位。

Result: 仿真结果表明，EMI和IRR的联合影响比单独影响更严重。所提出的算法可以显著提高系统和率并降低中断概率。

Conclusion: 所提出的交替优化算法能够有效地应对EMI和IRR对6G局部网络中RIS性能的影响。

Abstract: The Sixth Generation (6G) radio technology is expected to include local 6G
networks as a special use case, extending the capabilities of `generic' 6G
networks towards more demanding performance requirements. Reconfigurable
intelligent surfaces (RISs) offer a novel paradigm for next-generation wireless
communications, especially in the context of local 6G networks, enabling
advanced signal propagation control through intelligent phase-shift
configurations. However, in practical deployments, their performance can be
adversely affected by electromagnetic interference (EMI) from external sources
and inter-RIS reflections (IRR) caused by signal reflections between multiple
colocated RIS units. This paper presents a comprehensive analysis of the joint
impact of EMI and IRR in a multi-RIS multi-cell system deployed within an
indoor factory environment. A detailed evaluation study is first carried out to
investigate their impact on system performance. System-level simulations
demonstrate that the joint impact of EMI and IRR degrades system performance
more significantly than their individual effects, particularly as RIS
dimensions and transmit power increase. To address these adverse effects, an
alternate optimization algorithm using the Riemannian conjugate gradient method
is then proposed. The novel algorithm optimizes the phase shifts of the RIS
elements considering the spatial correlation among their associated channels,
and is found to provide up to several orders of magnitude gains in terms of the
system sum rate and the outage probability.

</details>


### [167] [RIS-assisted Atomic MIMO Receiver](https://arxiv.org/abs/2510.15763)
*Qihao Peng,Jiuyu Liu,Qu Luo,Yi Ma,Pei Xiao,Maged Elkashlan,George K. Karagiannidis*

Main category: eess.SP

TL;DR: 本论文提出了一种新颖的、低复杂度的原子多输入多输出(MIMO)接收机架构，并辅以可重构智能表面(RIS)。


<details>
  <summary>Details</summary>
Motivation: 通过引入RIS并利用脉冲幅度调制(PAM)，有效地将传输信号的相位与本地振荡器(LO)的相位对齐，从而减轻相位模糊，并显著降低信号检测复杂度和整体接收机复杂度。

Method: 为了解决由此产生的非凸优化问题，我们通过最小化等效矩阵的Frobenius范数将其重新表述为可处理的形式，并使用基于Adam的梯度下降算法进行有效求解。

Result: 该方法有效解决了非凸优化问题，降低了信号检测和整体接收机的复杂度。

Conclusion: 所提出的RIS辅助MIMO接收机架构结合PAM和基于Adam的梯度下降算法，能够有效降低通信系统的复杂度和功耗。

Abstract: In this paper, we propose a novel and low-complexity atomic multiple-input
multiple-output (MIMO) receiver architecture assisted by a reconfigurable
intelligent surface (RIS). By introducing RIS and utilizing pulse amplitude
modulation (PAM), the phase of the transmitted signal is effectively aligned
with that of the local oscillator (LO), thereby mitigating phase ambiguity and
substantially reducing both signal detection complexity and overall receiver
complexity.To tackle the resulting non-convex optimization problem, we
reformulate it into a tractable form by minimizing the Frobenius norm of an
equivalent matrix, which is efficiently solved using an Adam-based gradient
descent algorithm.

</details>


### [168] [Rydberg Atomic Quantum Satellites for Enhanced Ground-to-Space Direct Uplink Access](https://arxiv.org/abs/2510.15773)
*Qihao Peng Tierui Gong,Zihang Song,Qu Luo,Cunhua Pan,Pei Xiao,Chau Yuen*

Main category: eess.SP

TL;DR: RAQ-MIMO卫星在地面到空间链路接入方面优于传统MIMO。


<details>
  <summary>Details</summary>
Motivation: 研究基于里德堡原子量子（RAQ）的MIMO卫星在地面到空间链路接入方面的性能优势。

Method: 推导了均方误差（MSE）和归一化均方误差（NMSE）的闭合表达式，以评估里德堡原子对信道估计的影响。在此基础上，推导了最大比合并（MRC）和迫零（ZF）检测方案的可用数据率的下界。

Result: RAQ-MIMO在瑞利信道和卫星信道条件下均优于传统RF MIMO。在瑞利衰落下，RAQ-MIMO具有“平方”增益，尤其是在长距离和严格功耗限制的场景下。在视距（LoS）主导的卫星信道下，增益饱和，剩余的改进主要来自归一化噪声背景。蒙特卡洛模拟验证了分析结果。

Conclusion: RAQ-MIMO卫星的性能优势可以转化为更小的天线孔径、更低的发射功率和更长的通信距离，为下一代卫星网络铺平了道路。

Abstract: This paper investigates the performance advantages of Rydberg atomic quantum
(RAQ)-based multiple-input multiple-output (MIMO) satellites for enhancing
direct ground-to-space uplink access.We analytically evaluate the impact of
Rydberg atoms on channel estimation by deriving closed-form expressions for the
mean-square error (MSE) and normalized mean-square error (NMSE). Based on the
estimated channels, we further derive lower bounds on the achievable data rates
for maximum ratio combining (MRC) and zero-forcing (ZF) detection schemes.
Rigorous analysis demonstrates that RAQ-MIMO outperforms conventional
radio-frequency (RF) MIMO under both Rayleigh and satellite channel conditions.
Specifically, compared with conventional MIMO, RAQR achieves a ``squaring" gain
under Rayleigh fading, especially in long-distance transmission scenarios with
stringent power constraints. In contrast, under line-of-sight (LoS)-dominated
satellite channels, this gain saturates as channel-estimation benefits
diminish, with the remaining improvement primarily arising from the normalized
noise background. Monte Carlo simulations validate the analytical results and
show that the performance gains of RAQ-MIMO satellites translate into smaller
antenna apertures, lower transmit power, and longer communication ranges,
thereby paving the way for next-generation satellite networks.

</details>


### [169] [From Active to Battery-Free: Rydberg Atomic Quantum Receivers for Self-Sustained SWIPT-MIMO Networks](https://arxiv.org/abs/2510.15784)
*Qihao Peng,Qu Luo,Zheng Chu,Neng Ye,Hong Ren,Cunhua Pan,Lixia Xiao,Pei Xiao*

Main category: eess.SP

TL;DR: 本论文提出了一种混合同时无线信息与能量传输（SWIPT）的多输入多输出（MIMO）架构，其中基站（BS）使用常规射频（RF）发射器进行下行链路传输，并使用里德堡原子量子接收器（RAQR）接收物联网（IoT）设备的上行链路信号。为了充分利用这种集成，我们联合设计了传输方案和功率分配策略以最大化总速率，这是一个非凸问题。为了解决这个挑战，我们首先推导了最大比值合并（MRC）和零强制（ZF）的上行链路可实现速率，以及最大比值传输（MRT）和ZF预编码的下行链路速率和能量收集的闭式下界。在此基础上，我们提出了一种依赖于最佳单项逼近和几何规划（GP）的迭代算法来解决非凸问题。最后，仿真验证了我们推导的下界的紧密性，并证明了所提出算法优于基准方案。重要的是，通过将RAQR与支持SWIPT的MIMO集成，基站可以可靠地检测仅由收集的能量供电的物联网设备的微弱上行链路信号，从而实现无电池通信。


<details>
  <summary>Details</summary>
Motivation: 实现支持SWIPT的MIMO架构，解决由IoT设备供电的微弱上行链路信号检测问题。

Method: 联合设计传输方案和功率分配策略，推导MRC、ZF、MRT的闭式下界，并提出基于最佳单项逼近和GP的迭代算法。

Result: 所提出的算法能够最大化总速率，并且仿真结果验证了所提出算法的有效性，证明了其优于基准方案。

Conclusion: 通过将RAQR与支持SWIPT的MIMO集成，可以实现可靠的电池供电设备的信号检测，从而实现无电池通信。

Abstract: In this paper, we proposed a hybrid simultaneous wireless information and
power transfer (SWIPT)-enabled multiple-input multiple-output (MIMO)
architecture, where the base station (BS) uses a conventional RF transmitter
for downlink transmission and a Rydberg atomic quantum receiver (RAQR) for
receiving uplink signal from Internet of Things (IoT) devices. To fully exploit
this integration, we jointly design the transmission scheme and the
power-splitting strategy to maximize the sum rate, which leads to a non-convex
problem. To address this challenge, we first derive closed-form lower bounds on
the uplink achievable rates for maximum ratio combining (MRC) and zero-forcing
(ZF), as well as on the downlink rate and harvested energy for maximum ratio
transmission (MRT) and ZF precoding. Building upon these bounds, we propose an
iterative algorithm relying on the best monomial approximation and geometric
programming (GP) to solve the non-convex problem. Finally, simulations validate
the tightness of our derived lower bounds and demonstrate the superiority of
the proposed algorithm over benchmark schemes. Importantly, by integrating RAQR
with SWIPT-enabled MIMO, the BS can reliably detect weak uplink signals from
IoT devices powered only by harvested energy, enabling battery-free
communication.

</details>


### [170] [Resilient Full-Duplex ISAC in the Face of Imperfect SI Cancellation: Globally Optimal Timeslot Allocation and Beam Selection](https://arxiv.org/abs/2510.15810)
*Luis F. Abanto-Leon,Setareh Maghsudi*

Main category: eess.SP

TL;DR: 本文提出了一种用于优化下行全双工集成传感与通信（ISAC）系统无线资源管理的联合设计方法，以解决不完美的自干扰消除问题。


<details>
  <summary>Details</summary>
Motivation: ISAC系统在无线资源管理（RRM）设计方面面临挑战，特别是在联合优化时隙分配和波束选择以及处理不完美的自干扰消除方面。

Method: 提出了一种定制的重构策略，将一个半无限非凸混合整数非线性规划（MINLP）问题转化为一个混合整数线性规划（MILP）问题，从而可以全局优化。

Result: 该方法能够全局优化时隙分配和波束选择，提高了全双工ISAC系统的效率，并增强了其抵抗残余自干扰的能力。

Conclusion: 所提出的联合设计方法能够有效地解决ISAC系统中的RRM问题，并在不完美的自干扰消除条件下实现最优性能。

Abstract: This work addresses the radio resource management (RRM) design in downlink
full-duplex integrated sensing and communications (ISAC) systems, jointly
optimizing timeslot allocation and beam selection under imperfect
self-interference cancellation. Timeslot allocation governs the distribution of
discrete channel uses between sensing and communication tasks, while beam
selection determines transmit and receive directions along with adaptive
beamwidths. The joint design leads to a semi-infinite, nonconvex mixed-integer
nonlinear program (MINLP), which is difficult to solve. To overcome this, we
develop a tailored reformulation strategy that transforms the problem into a
tractable mixed-integer linear program (MILP), enabling globally optimal
solutions. Our approach provides insights into the coordinated optimization of
timeslot allocation and beam selection, enhancing the efficiency of full-duplex
ISAC systems while ensuring resilience against residual self-interference.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [171] [Incorporating Si into Sb2Se3: Tailoring Optical Phase Change Materials via Nanocomposites](https://arxiv.org/abs/2510.14990)
*Chih-Yu Lee,Yi-Siou Huang,Felix Adams,Chuanyu Lian,Hongyi Sun,Jie Zhao,Zichao Ye,Nathan Youngblood,Juejun Hu,Leslie H Allen,Yifei Mo,Ichiro Takeuchi,Carlos A Rios Ocampo*

Main category: cond-mat.mtrl-sci

TL;DR: Si掺杂Sb2Se3可提高可见光下的透明度，但会降低光学对比度和相变速率。


<details>
  <summary>Details</summary>
Motivation: 现有的宽带光开关材料（OPCMs）在可见光谱范围内的透明度不足，需要开发新型材料或改进现有材料以扩大其应用范围。

Method: 通过磁控溅射技术在Sb2Se3中掺杂Si，并利用椭偏光谱、X射线衍射、拉曼光谱、扫描/透射电子显微镜以及纳米差示扫描量热法（NanoDSC）研究掺杂对光学性质、晶体结构、结晶和熔融淬灭的影响，并与第一性原理计算进行比较。

Result: 20%的Si掺杂提高了材料在非晶和晶体状态下的透明度窗口（非晶状态下达到800 nm），并降低了熔融温度，从而减少了功率消耗。然而，这也导致了非晶态和晶态之间的折射率对比度降低，并减慢了相变动力学。

Conclusion: Si掺杂Sb2Se3在提高可见光透明度方面显示出潜力，但需要在光学对比度和相变速度之间进行权衡。

Abstract: Chalcogenide-based optical phase change materials (OPCMs) exhibit a large
contrast in refractive index when reversibly switched between their stable
amorphous and crystalline states. OPCMs have rapidly gained attention due to
their versatility as nonvolatile amplitude or phase modulators in various
photonic devices. However, open challenges remain, such as achieving reliable
response and transparency spanning into the visible spectrum, a combination of
properties in which current broadband OPCMs (e.g., Ge2Sb2Se4Te1, Sb2Se3, or
Sb2S3) fall short. Discovering novel materials or engineering existing ones is,
therefore, crucial in extending the application scope of OPCMs. Here, we use
magnetron co-sputtering to study the effects of Si doping into Sb2Se3. We
employ ellipsometry, X-ray diffraction, Raman spectroscopy, and scanning and
transmission electron microscopy to investigate the effects of Si doping on the
optical properties and crystal structure and compare these results with those
from first principles calculations. Moreover, we study the crystallization and
melt-quenching of thin films via nano-differential scanning calorimetry
(NanoDSC). Our experiments demonstrate that 20% Si doping increases the
transparency window in both states, specifically to 800 nm (1.55 eV) in the
amorphous phase, while reducing power consumption by lowering the melting
temperature. However, this reduction comes at the cost of reducing the
refractive index contrast between states and slowing the kinetics of the phase
transition.

</details>


### [172] [Unusual dependence on the angle of magnetic field for the spin Hall magnetoresistance of monodomain epitaxial BiFeO3 thin films](https://arxiv.org/abs/2510.15091)
*Yongjian Tang,Pratap Pal,Matthew Roddy,Jon Schad,Ruofan Li,Joongwon Lee,Farhan Rana,Tianxiang Nan,Chang-Beom Eom,Daniel C. Ralph*

Main category: cond-mat.mtrl-sci

TL;DR: Pt/BiFeO$_3$双层结构中的自旋霍尔磁阻(SMR)测量显示出与预期(0或90度)不同的角度依赖性，表明存在有趣的微观机制。


<details>
  <summary>Details</summary>
Motivation: 研究磁绝缘体材料的表面自旋结构，特别是研究Pt/BiFeO3双层结构中的自旋霍尔磁阻现象。

Method: 测量Pt/BiFeO3双层结构中的自旋霍尔磁阻，分析电阻信号与外加磁场角度的关系。

Result: 观察到电阻信号呈现$	riangle$R $\\

Conclusion: Pt/BiFeO3双层结构中的SMR角度依赖性表现出与铁磁体和反铁磁体不同的行为，其$\\

Abstract: Spin Hall magnetoresistance (SMR) measurements provide a way to probe the
surface spin structure of insulating magnetic materials. Such measurements
produce resistance signals of the form {$\Delta$}R {$\propto$}
cos[2($\alpha$-$\alpha$$_0$)], where $\alpha$ is the angle between the current
and the external in-plane magnetic field. Previous experiments on a wide range
of materials have found $\alpha$$_0$ = 0$\deg$ for ferromagnets and
$\alpha$$_0$ = 90$\deg$ for antiferromagnets. Here we investigate SMR in
bilayers of Pt with monodomain BiFeO$_3$ multiferroic epitaxial thin films. We
observe signals of the form {$\Delta$}R {$\propto$}
cos[2($\alpha$-$\alpha$$_0$)] but surprisingly the angle $\alpha$$_0$ can take
values very different from 90$\deg$ or 0$\deg$, with large variations from
sample to sample. The aim of the paper is to report this striking departure
from the expected magnetic field dependence of SMR and to encourage
consideration of possible microscopic mechanisms.

</details>


### [173] [Morphotropic Phase Boundary (MPB) Induced Enhancement of Ferroelectric and Piezoelectric Properties in Li and Ta modified K0.5Na0.5NbO3](https://arxiv.org/abs/2510.15139)
*Satyaranjan Sahoo,Dhiren K. Pradhan,Shalini Kumari,Abhisikta Sahu,Koyal Suman Samantaray,Vikas N. Thakur,Anupam Mishra,M. M. Rahaman,Ashok Kumar,Reji Thomas,Philip D. Rack,Dillip K. Pradhan*

Main category: cond-mat.mtrl-sci

TL;DR: 研究了Li和Ta取代对(K0.48Na0.48Li0.04)NbO3陶瓷相变行为、微观结构、铁电、介电和压电性能的影响。


<details>
  <summary>Details</summary>
Motivation: 研究Li和Ta取代对(K0.48Na0.48Li0.04)NbO3陶瓷性能的影响。

Method: 采用X射线衍射、拉曼光谱、微观结构分析和温度相关介电研究，结合实验数据构建了组分-温度相图。

Result: 随Ta浓度增加，陶瓷密度增加，晶粒尺寸减小。x < 0.10为斜方相，0.10 <= x <= 0.20为斜方相和四方相共存，x > 0.20为四方相。相变温度随Ta浓度增加而降低，x > 0.15时，斜方-四方转变温度低于室温。KNLNT-0.20具有最高的介电常数（Er = 556）和压电系数（d33 = 159 pC/N）。

Conclusion: 增强的压电响应归因于马氏体相边界，而非多形相边界温度的移动。

Abstract: Lead-free (K0.48Na0.48Li0.04)(Nb1-xTax)O3 (KNLNT-x) ceramics were synthesized
to study the effects of Li and Ta substitution on phase transition behavior,
microstructure, and ferroelectric, dielectric, and piezoelectric properties.
X-ray diffraction and Raman spectroscopy show that compositions with x < 0.10
exhibit a single orthorhombic (Amm2) phase, while 0.10 <= x <= 0.20 show
coexistence of orthorhombic and tetragonal (Amm2 + P4mm) phases. For x > 0.20,
a single tetragonal (P4mm) phase is obtained. Microstructural analysis shows a
dense ceramic with decreasing grain size as Ta concentration increases.
Temperature-dependent dielectric studies reveal two transitions:
orthorhombic-tetragonal (TO-T) and tetragonal-cubic (TC). Both transition
temperatures decrease systematically with increasing Ta, and TO-T shifts below
room temperature for x > 0.15. The composition KNLNT-0.20 exhibits the highest
dielectric constant (Er = 556) and piezoelectric coefficient (d33 = 159 pC/N).
The enhanced piezoelectric response is attributed to a morphotropic phase
boundary rather than a shift of the polymorphic phase boundary temperature. A
composition-temperature phase diagram was constructed based on XRD, Raman, and
dielectric data.

</details>


### [174] [Advancing AI-Driven Analysis in X-ray Absorption Spectroscopy: Spectral Domain Mapping and Universal Models](https://arxiv.org/abs/2510.15167)
*Nina Cao,Pavan Ravindra,Shubha R. Kharel,Chuntian Cao,Boyang Li,Xuance Jiang,Matthew R. Carbone,Xiaohui Qu,Deyu Lu*

Main category: cond-mat.mtrl-sci

TL;DR: AI/ML方法在X射线吸收光谱(XAS)分析中展现出巨大潜力，可提高效率并减少人为偏见。本文提出了一个包含基准、工作流程、数据库和AI/ML模型的AI驱动XAS分析流程。


<details>
  <summary>Details</summary>
Motivation: 传统XAS分析方法效率低下且存在人为偏见，AI/ML方法有望克服这些局限。

Method: 本文提出并演示了一个AI驱动的XAS分析流程，包含基准、工作流程、数据库和AI/ML模型。通过两个案例研究，展示了光谱域映射（SDM）在调和模拟与实验数据中的作用，以及开发覆盖全元素周期表的通用XAS ML模型。

Result: 案例研究一：在应用SDM之前，仅基于模拟数据训练的ML模型预测的Ti原子氧化态趋势不正确；应用SDM后，模型成功恢复了正确的氧化态趋势。案例研究二：开发了可覆盖全元素周期表的通用XAS ML模型。

Conclusion: AI驱动的XAS分析流程能够显著提高XAS分析的效率和准确性，有望实现实时XAS分析，从而加速科学发现。

Abstract: In recent years, rapid progress has been made in developing artificial
intelligence (AI) and machine learning (ML) methods for x-ray absorption
spectroscopy (XAS) analysis. Compared to traditional XAS analysis methods,
AI/ML approaches offer dramatic improvements in efficiency and help eliminate
human bias. To advance this field, we advocate an AI-driven XAS analysis
pipeline that features several inter-connected key building blocks: benchmarks,
workflows, databases, and AI/ML models. Specifically, we present two case
studies for XAS ML. In the first study, we demonstrate the importance of
reconciling the discrepancies between simulation and experiment using spectral
domain mapping (SDM). Our ML model, which is trained solely on simulated
spectra, predicts an incorrect oxidation state trend for Ti atoms in a
combinatorial zinc titanate film. After transforming the experimental spectra
into a simulation-like representation using SDM, the same model successfully
recovers the correct oxidation state trend. In the second study, we explore the
development of universal XAS ML models that are trained on the entire periodic
table, which enables them to leverage common trends across elements. Looking
ahead, we envision that an AI-driven pipeline can unlock the potential of
real-time XAS analysis to accelerate scientific discovery.

</details>


### [175] [Development and Validation of 2NN-MEAM Interatomic Potential for Sc and Al-Sc Alloys Thermodynamics Solidification and Intermetallic Ordering](https://arxiv.org/abs/2510.15170)
*Avik Mahata*

Main category: cond-mat.mtrl-sci

TL;DR: 开发了一种用于Sc和Al-Sc合金的2NN-MEAM势，能够统一描述内聚、热力学和凝固行为，并为未来合金设计提供基础。


<details>
  <summary>Details</summary>
Motivation: 需要一个能够统一描述内聚、热力学和凝固行为的Sc和Al-Sc合金势，以支持未来的合金设计和模拟研究。

Method: 开发了第二近邻修正嵌入原子模型（2NN-MEAM）势，该势考虑了Sc的内聚能、晶格常数、缺陷能量学以及固液两相共存的实验熔点。Al-Sc二元相互作用参数通过L12-Al3Sc参考点和第一性原理及量热数据进行拟合。

Result: 该势能够准确描述Sc的性质，包括内聚能、晶格常数、缺陷能量学和熔点。对于Al-Sc合金，该势能准确重现了Al3Sc的强负形成焓（-0.45 eV/原子）、竞争相的相对稳定性以及实际的弹性性能。液态合金的混合焓与理想相关溶液和CALPHAD模型一致，表明该势能捕捉到了液态中Al-Sc的放热结合。分子动力学模拟揭示了凝固过程中预期的成核行为，包括纯Al的易结晶性以及Al-1at.% Sc的孵化期延长和生长减慢。还观察到有序Al3Sc型L12胚胎的自发出现，其中Sc原子占据周围有12个Al原子的立方角（B）位。

Conclusion: 开发的2NN-MEAM势为模拟Sc和Al-Sc体系的熔化、凝固和金属间有序提供了可靠的定量基础，可用于未来的多组分合金设计和大规模成核研究。

Abstract: We present a second-nearest-neighbor Modified Embedded Atom Method
(2NN--MEAM) potential for Scandium (Sc) and Aluminum-Scandium (Al--Sc) alloys
that unifies cohesive, thermodynamic, and solidification behavior within a
single transferable framework. The Sc component accurately reproduces cohesive
energy, lattice constants, defect energetics, and the experimental melting
point obtained from two-phase coexistence, demonstrating reliable description
of both hcp and liquid phases. The Al--Sc binary interaction parameters were
fitted using the L1$_2$--Al$_3$Sc reference and benchmarked against
first-principles and calorimetric data. The potential reproduces the strong
negative formation enthalpy of Al$_3$Sc (--0.45~eV~atom$^{-1}$), correct
relative stability of competing phases, and realistic elastic properties.
Mixing enthalpies of the liquid alloy agree with ideal-associated-solution and
CALPHAD models, confirming that the potential captures exothermic Al--Sc
association in the melt. Molecular-dynamics simulations of solidification
reveal the expected temperature and composition dependence of homogeneous
nucleation. Pure Al crystallizes readily, while Al--1~at.\%~Sc exhibits a
longer incubation and slower growth at the same absolute temperature due to
reduced undercooling and solute drag. Within the alloy, ordered Al$_3$Sc-type
L1$_2$ embryos appear spontaneously, with Sc atoms occupying cube-corner (B)
sites surrounded by twelve Al neighbors. Energy--volume trajectories confirm
that the potential links thermodynamics to microstructural evolution. Overall,
the developed 2NN--MEAM potential provides a quantitatively grounded basis for
modeling melting, solidification, and intermetallic ordering in Sc and Al--Sc
systems, enabling future multicomponent alloy design and large-scale nucleation
studies.

</details>


### [176] [Enhanced magnetic, electrical, and magnetostrictive properties of La-doped SrCoO3 synthesized by microwave heating](https://arxiv.org/abs/2510.15235)
*L. A. Longchar,M. Manikandan,R. Mahendiran*

Main category: cond-mat.mtrl-sci

TL;DR: 微波加热（MWH）合成的La掺杂SrCoO3-δ比传统加热（CH）合成的具有更好的物理性质，表现为更高的居里温度、饱和磁化强度和磁致伸缩，以及金属导电行为。


<details>
  <summary>Details</summary>
Motivation: 探索微波加热（MWH）合成La掺杂SrCoO3-δ的优越性及其物理性质。

Method: 采用微波加热（MWH）和传统加热（CH）两种方法合成La掺杂SrCoO3-δ，并比较其物理性质，包括居里温度、饱和磁化强度、矫顽场、磁阻、直流电阻率和纵向磁致伸缩。

Result: MWH合成的样品具有更高的居里温度（176 K vs 158 K）、更高的饱和磁化强度、更小的矫顽场和磁阻，并且在350 K至10 K下表现出金属性，而CH样品在120 K以下电阻急剧增加。MWH样品的纵向磁致伸缩也更高（247 ppm vs 128 ppm）。

Conclusion: MWH合成的La掺杂SrCO3-δ样品表现出更优越的物理性质，这可能归因于较少的氧缺陷和Co3+向Co4+的部分氧化，但具体机制仍需进一步研究。

Abstract: We report microwave-assisted synthesis and physical properties of La-doped
SrCoO3-{\delta}. The Sr0.8La0.2CoO3-{\delta} synthesized via microwave heating
(MWH) exhibits superior physical properties compared to a nominally identical
composition obtained by conventional heating (CH) in an electrical furnace. The
MWH sample exhibits an enhanced ferromagnetic Curie temperature (158 K in CH
and 176 K in MWH samples) and higher saturation magnetization but smaller
coercive field and magnetoresistance at 10 K compared to the CH sample. While
the dc resistivity increases substantially below 120 K in the CH sample, it is
metallic from 350 to 10 K in the MWH sample. Further, the longitudinal
magnetostriction of the MWH sample ({\lambda}par = 247 ppm for H = 50 kOe) at
10 K is also higher than that of the CH sample ({\lambda}par = 128 ppm). The
observed enhanced properties of the MWH sample can not be attributed to grain
size and grain boundaries but are likely to arise from lesser oxygen defects
and partial oxidation of Co3+ into Co4+, however, the exact mechanism is not
fully understood at present.

</details>


### [177] [Ab-initio study of structural, vibrational and non-linear optical properties of (TiO2)-(Tl2O)-(TeO2) glasses](https://arxiv.org/abs/2510.15343)
*Raghvender Raghvender,Assil Bouzid,Evgenii M. Roginskii,David Hamani,Olivier Noguera,Philippe Thomas,Olivier Masson*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究利用第一性原理分子动力学研究了二元和三元碲酸盐玻璃的结构和非线性光学性质，并开发了一个可预测的模型来调整玻璃的原子结构和光学响应。


<details>
  <summary>Details</summary>
Motivation: 研究二元和三元碲酸盐玻璃的结构和非线性光学性质，并建立一个可预测的模型来调整这些性质。

Method: 利用第一性原理分子动力学研究二元 (TlO$_{0.5}$)$_{y}$-(TeO$_2$)$_{1-y}$ 和三元 $(TiO$_2$)$_{x}$-(TlO$_{0.5}$)$_{y}$-(TeO$_2$)_{1-x-y}$ 碲酸盐玻璃，验证所得结构模型，计算拉曼光谱和非线性光学性质。

Result: 在二元体系中，增加 TlO$_{0.5}$ 含量会降低网络聚合度，并导致非桥接氧的增多。在三元体系中，TiO$_2$ 作为网络形成体，保持 Te 配位数，并促进桥接氧的形成，从而重新聚合网络。计算出的拉曼光谱和非线性光学性质与实验结果一致。

Conclusion: TiO$_2$ 的加入可以保持碲酸盐玻璃的高光学非线性，同时维持网络的整体连接性。TiO$_2$ 的加入可以作为一种调节玻璃结构和非线性光学响应的有效手段。

Abstract: This paper reports on a systematic first-principles molecular dynamics
investigation of binary (TlO$_{0.5}$)$_{y}$-(TeO$_2$)$_{1-y}$ and ternary
$(TiO$_{2}$)$_{x}$-(TlO$_{0.5}$)$_{y}$-(TeO$_2$)_{1-x-y}$ tellurite glasses.
The obtained structural models are validated against available measured X-ray
pair distribution functions. In the binary system, increasing TlO$_{0.5}$
content induces network depolymerization through the reduction of Te
coordination number, the substitution of Te-O-Te linkages with
Te=O$^{-}$...Tl$^{+}$ units, and the proliferation of non-bridging oxygens. In
addition, rings analysis demonstrates a loss of the network connectivity via
the opening of small n-membered rings. In contrast, TiO$_2$ acts as a network
former in ternary glasses, preserving Te coordination number, and promoting a
high fraction of bridging oxygens. Ti atoms induces a network repolymerization
that manifests through the formation of smaller Ti-containing n-membered rings
thereby balancing the strong effect of Tl$_2$O modifier. Beside the structural
analysis, we also computed Raman spectra and non-linear optical properties on
the obtained large periodic models. Our results reproduce experimental trends
in Raman band shifts with composition, while nonlinear optical calculations
show that <$\chi^{(3)}$> remains stable with TlO$_{0.5}$ addition in binary
glasses, consistent with experiment. In the case of ternary systems, we find
that the inclusion of a small fraction of TiO$_2$ preserves the high optical
nonlinearity of the TeO$_2$ network while maintaining the overall network
connectivity. These results establish a predictive framework for tailoring the
atomic structure and nonlinear optical response of tellurite glasses through
the controlled interplay of modifiers nature and concentration.

</details>


### [178] [Dielectric Deposition Enhanced Crystallization in Atomic-Layer-Deposited Indium Oxide Transistors Achieving High Gated-Hall Mobility Exceeding 100 cm2/Vs at Room Temperature](https://arxiv.org/abs/2510.15358)
*Chen Wang,Kai Jiang,Jinxiu Zhao,Ziheng Wang,Guilei Wang,Chao Zhao,Mengwei Si*

Main category: cond-mat.mtrl-sci

TL;DR: 氧化铟 (In2O3) 晶体管通过顶部氧化铪 (HfO2) 沉积得到增强，实现了高栅极霍尔迁移率（超过 100 cm²/Vs）和良好的亚阈摆幅。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是提高原子层沉积的氧化铟 (In2O3) 晶体管的性能，特别是其栅极霍尔迁移率。

Method: 采用原子层沉积 (ALD) 技术制备 In2O3 晶体管，并在 In2O3 沟道上方沉积 HfO2 层，以增强 In2O3 的结晶度。通过栅极霍尔测量评估器件性能。

Result: 顶部 HfO2 沉积显著提高了 In2O3 的结晶度，平均晶粒尺寸达到 97.2 nm（对于 4.2 nm 的 In2O3 沟道）。所制备的 In2O3 晶体管在室温下实现了 100.9 cm²/Vs 的高栅极霍尔迁移率和 94 mV/dec 的亚阈摆幅。在 100 K 时，迁移率进一步提高到 162.2 cm²/Vs。

Conclusion: 顶部介电层沉积诱导的结晶对于提高载流子传输至关重要，为开发高迁移率器件提供了一条可扩展的途径。

Abstract: In this work, we report high-performance atomic-layer-deposited indium oxide
(In2O3) transistors with high gated-Hall mobility ({\mu}H) exceeding 100 cm2/Vs
at room temperature (RT). It is found that the deposition of top hafnium oxide
(HfO2) above the In2O3 channel significantly enhances its crystallization,
leading to an average grain size of 97.2 nm in a 4.2-nm In2O3 channel. The ALD
of In2O3 exhibits an epitaxy-like growth behavior, with its (222) planes
aligning parallel to the (111) planes of both the top and bottom HfO2
dielectrics. As a result, bottom-gate In2O3 transistors with a high {\mu}H of
100.9 cm2/Vs and a decent subthreshold swing (SS) of 94 mV/dec are achieved by
gated-Hall measurement at RT. Furthermore, the devices maintain excellent
performance at low temperatures, achieving a {\mu}H of 162.2 cm2/Vs at 100 K.
Our study reveals the critical role of dielectric deposition induced
crystallization in enhancing carrier transport and offers a scalable pathway
toward high-mobility devices.

</details>


### [179] [Unravelling the Catalytic Activity of Dual-Metal Doped N6-Graphene for Sulfur Reduction via Machine Learning-Accelerated First-Principles Calculations](https://arxiv.org/abs/2510.15397)
*Sahil Kumar,Adithya Maurya K R,Mudit Dixit*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究利用机器学习加速框架PACE，结合MLIPs和DFT，系统研究了N6-协调双原子催化剂（DACs）对多硫化锂的吸附和转化，发现Fe-Ni和Fe-Pt表现出最佳催化性能，并开发了预测吉布斯自由能的ML回归模型，为下一代锂硫电池的催化剂设计提供了数据驱动策略。


<details>
  <summary>Details</summary>
Motivation: 多硫化锂的吸附和转化过程对缓解锂硫电池（LSBs）的穿梭效应和迟缓的氧化还原动力学至关重要。

Method: 本研究提出了一种名为PACE（Precise and Accurate Configuration Evaluation）的机器学习加速框架，该框架结合了机器学习原子间势（MLIPs）和密度泛函理论（DFT），系统地探索了一系列N6-协调双原子催化剂（DACs）的吸附构型和能量。此外，还开发了一个基于DFT计算数据训练的机器学习（ML）回归模型，以预测吉布斯自由能（ΔG），并利用了梯度提升回归（GBR）模型。

Result: 研究表明，与单原子催化剂相比，DACs通过协同的金属-硫相互作用和相邻金属中心的电子耦合，表现出对锂多硫化物的吸附和氧化还原转化的性能。其中，Fe-Ni和Fe-Pt表现出最佳催化性能，具有最佳的吸附能（-1.0至-2.3 eV）、低自由能垒（≤0.4 eV）用于Li2S2到Li2S的转化，以及易于分解Li2S的势垒（≤1.0 eV）。开发的GBR模型预测ΔG的R^2为0.85，MAE为0.26 eV，能够快速预测未探索DACs的ΔG。电子结构分析表明，优越的性能源于双金属中心的协同效应所诱导的最佳d带对齐和S-S键极化。

Conclusion: 本研究提出的双ML-DFT框架展示了一种可推广的、数据驱动的设计策略，用于合理发现下一代LSBs的高效催化剂。

Abstract: Understanding and optimizing polysulfide adsorption and conversion processes
are critical to mitigating shuttle effects and sluggish redox kinetics in
lithium-sulfur batteries (LSBs). Here, we introduce a
machine-learning-accelerated framework, Precise and Accurate Configuration
Evaluation (PACE), that integrates Machine Learning Interatomic Potentials
(MLIPs) with Density Functional Theory (DFT) to systematically explore
adsorption configurations and energetics of a series of N6-coordinated
dual-atom catalysts (DACs). Our results demonstrate that, compared with
single-atom catalysts, DACs exhibit improved LiPS adsorption and redox
conversion through cooperative metal-sulfur interactions and electronic
coupling between adjacent metal centers. Among all DACs, Fe-Ni and Fe-Pt show
optimal catalytic performance, due to their optimal adsorption energies (-1.0
to -2.3 eV), low free-energy barriers (<=0.4 eV) for the Li2S2 to Li2S
conversion, and facile Li2S decomposition barriers (<=1.0 eV). To accelerate
catalyst screening, we further developed a machine learning (ML) regression
model trained on DFT-calculated data to predict the Gibbs free energy (\Delta
G) of Li2Sn adsorption using physically interpretable descriptors. The Gradient
Boosting Regression (GBR) model yields an R^2 of 0.85 and an MAE of 0.26 eV,
enabling the rapid prediction of \Delta G for unexplored DACs.
Electronic-structure analyses reveal that the superior performance originates
from the optimal d-band alignment and S-S bond polarization induced by the
cooperative effect of dual metal centres. This dual ML-DFT framework
demonstrates a generalizable, data-driven design strategy for the rational
discovery of efficient catalysts for next-generation LSBs.

</details>


### [180] [Antiphase boundaries in Ni-Mn-Ga single crystal - experiment and model](https://arxiv.org/abs/2510.15433)
*O. Heczko,F. Maca,V. Drchal,L. Fekete,L. Straka,J. Zemen*

Main category: cond-mat.mtrl-sci

TL;DR: Ni-Mn-Ga单晶中的热诱导反相畴界（APBs）呈复杂、不规则形状和闭合环路，且无晶格平面偏好。


<details>
  <summary>Details</summary>
Motivation: 在铁磁性、有序Ni-Mn-Ga单晶中，热诱导的反相畴界（APBs）呈现复杂、不规则的形状和闭合环路，且无晶格平面偏好，这需要进一步研究其性质和成因。

Method: 使用磁力显微镜（MFM）在母体立方奥氏体和单斜马氏体（具有单轴磁各向异性）的相同位置观察到APBs。结合从头计算，我们提出一个具有深浅对比度的APB曲线由一对APB界面组成，其核心只有单层厚度，具有部分B2'结构序，与本体的完全L21序相反。使用静磁连续体模拟计算的磁对比度与MFM观测结果吻合良好。

Result: MFM观测和从头计算结果表明，Ni-Mn-Ga单晶中的APBs具有复杂形状，由具有部分B2'结构序的单层厚度核心组成，并且计算出的磁对比度与观测结果一致。

Conclusion: Ni-Mn-Ga单晶中的热诱导APBs形状复杂，其核心结构为部分B2'序，这与MFM观测和静磁连续体模拟结果一致。

Abstract: Thermally induced antiphase boundaries (APBs) in ferromagnetic, ordered
Ni-Mn-Ga single crystal exhibit complex, irregular shapes and closed loops
without any lattice plane preferences. The APBs were visualized on polished
(100) surface using magnetic force microscopy (MFM) at the same location in
parent cubic austenite and monoclinic martensite with uniaxial magnetic
anisotropy. Based on ab-initio calculation we suggest that one APB curve with
dark and light contrast consists of a pair of APB interfaces with narrow, only
one-layer thick, core with structural partial B2' order in contrast to full L21
order of bulk. Calculated magnetic contrast using magnetostatic continuum
simulations agrees well with MFM observation.

</details>


### [181] [Surface diffusion of phosphorus on Si(100) after PBr3 adsorption](https://arxiv.org/abs/2510.15599)
*T. V. Pavlova,V. M. Shevlyuga*

Main category: cond-mat.mtrl-sci

TL;DR: P原子在Si(100)表面扩散行为


<details>
  <summary>Details</summary>
Motivation: 研究P原子在Si(100)表面的扩散行为及其影响因素

Method: 使用STM在77K和300K下观察P原子扩散，并用DFT计算活化能

Result: P原子在77K和300K下扩散路径不同，Br原子的存在限制了P原子的迁移，P原子会向表面出现的O原子扩散

Conclusion: 磷与硅表面的相互作用，特别是磷在Si(100)表面的扩散路径得到补充。

Abstract: Phosphorus diffusion on a Si(100) surface was studied using scanning
tunneling microscopy (STM) at temperatures of 77 and 300 K. The phosphorus
source utilized was the PBr$_3$ molecule, which fully dissociates on the
surface at 77 K. We observed diffusion of P atoms both along and across the
rows of Si dimers. To support the observation of different diffusion pathways
of phosphorus, activation energy calculations were performed using density
functional theory. At 77 K, phosphorus diffusion started and (or) finished
mostly in bridge positions. At 300 K, phosphorus diffuses predominantly between
end-bridge positions, accompanied by bromine diffusion. The presence of Br near
phosphorus significantly restricts its mobility. Additionally, phosphorus was
found to diffuse to an oxygen atom that appeared on the surface as a result of
water adsorption. This diffusion occurs because the P site near the oxidized
dimer is more stable compared to that on the clean surface. The obtained
results complement the knowledge about the interaction of phosphorus with the
silicon surface, specifically the phosphorus diffusion pathways on the Si(100)
surface.

</details>


### [182] [Synergistic modulation of band structure and phonon transport for higher thermoelectric performance of WSe2](https://arxiv.org/abs/2510.15523)
*Mazhar Hussain Danish,Amil Aligayev,Zahir Muhammad,Tao Chen,Adil Mansoor,Zia Ur Rahman,F. J. Dominguez-Gutierrez,Di Li,Jian Zhang,Zhuang Hao Zheng,Xiaoying Qin*

Main category: cond-mat.mtrl-sci

TL;DR: 通过共掺杂Nb和Te，WSe2的功率因子提高了17倍，晶格热导率降低了72%，最大ZT值达到1，显著提升了其热电性能。


<details>
  <summary>Details</summary>
Motivation: 尽管WSe2具有高热电系数、成本效益和环境友好等优点，但其较低的电导率、功率因子和较高的晶格热导率限制了其热电性能。

Method: 通过密度泛函理论（DFT）分析和实验研究，对WSe2进行Nb（取代W）和Te（取代Se）的共掺杂，以提高其功率因子和降低晶格热导率。

Result: 共掺杂后的WSe2的功率因子提高了17倍（在850 K时达到8.91 μW cm^-1 K^-2），晶格热导率从1.70 W m^-1 K^-1降低到0.48 W m^-1 K^-1。在850 K时，W0.95Nb0.05Se2-yTey (y=0.3) 样品的ZT_max约为1，相比于WSe2提高了约30倍。

Conclusion: Nb和Te的共掺杂显著提高了WSe2的热电性能，其功率因子和电导率的提升归因于态密度、有效质量和迁移率的增加，而晶格热导率的降低则主要是由于Te-Se和Nb-W缺陷引起的声子散射。

Abstract: Tungsten diselenide (WSe2) emerges as a promising thermoelectric (TE)
candidate due to its high thermopower (S), cost-effectiveness, and
environmentally friendly characteristics. However, pristine WSe2 exhibits
limited electrical conductivity (sigma), a low power factor (PF), and high
lattice thermal conductivity (k_L), which restrict its overall TE performance.
Here, we show that through co-doping of Nb for W and Te for Se in WSe2, its
power factor increases 17-fold, reaching 8.91 microW cm^-1 K^-2 at 850 K.
Simultaneously, its lattice thermal conductivity (k_L) decreases from 1.70 W
m^-1 K^-1 to 0.48 W m^-1 K^-1. Experiments and density functional theory (DFT)
analysis demonstrate that the enhancement of PF is linked to an increased
density of states, higher effective mass (md*), improved mobility (mu), and
elevated electrical conductivity (sigma) owing to the replacement of Se2- with
Te2-; while the observed 72% reduction in k_L results primarily from phonon
scattering at Te-Se and Nb-W defects. As a result, a remarkable ZT_max ~ 1 is
obtained at 850 K for the sample W0.95Nb0.05Se2-yTey with y = 0.3, which is
about a 30-fold increase compared to WSe2, proving that Nb and Te co-doping in
WSe2 can significantly boost its TE performance.

</details>


### [183] [Atomically-resolved exciton emission from single defects in MoS$_2$](https://arxiv.org/abs/2510.15676)
*Lysander Huberich,Eve Ammerman,Gu Yu,Yining Ren,Sotirios Papadopoulos,Chengye Dong,Joshua A. Robinson,Kenji Watanabe,Takashi Taniguchi,Oliver Gröning,Lukas Novotny,Tingxin Li,Shiyong Wang,Bruno Schuler*

Main category: cond-mat.mtrl-sci

TL;DR: 通过扫描隧道光谱学和发光技术，我们首次将二维半导体MoS$_{2}$中单个缺陷的原子结构与其光学特征联系起来，并识别了常见的点缺陷，如硫空位、氧取代和碳氢复合物。


<details>
  <summary>Details</summary>
Motivation: 理解原子缺陷如何影响二维半导体材料的纳米级光学特性对于推进量子技术和光电子学至关重要。

Method: 利用扫描隧道光谱学（STS）和发光（STML）技术，关联单层MoS$_{2}$中单个缺陷的原子结构和光学特征。通过六方氮化硼（hBN）双层实现MoS$_{2}$与石墨烯衬底的解耦，并观察了缺陷的STML发射线。

Result: 确定了MoS$_{2}$中常见点缺陷（硫空位Vac$_{\text{S}}^{-}$、氧取代O$_{\text{S}}$和负电荷碳氢复合物CH$_{\text{S}}^{-}$）的光谱特征。其中，CH$_{\text{S}}^{-}$产生了低于MoS$_{2}$激子约200 meV的缺陷束缚激子复合物（$A^{-}X$）。近缺陷区域观察到光谱大范围移动，与预期的带-缺陷光学跃迁一致。

Conclusion: 这项工作建立了结构、电子态和光学响应之间的原子级精确关联，为在二维材料中确定性地设计量子发光体提供了基础。

Abstract: Understanding how atomic defects shape the nanoscale optical properties of
two-dimensional (2D) semiconductors is essential for advancing quantum
technologies and optoelectronics. Using scanning tunneling spectroscopy (STS)
and luminescence (STML), we correlate the atomic structure and optical
fingerprints of individual defects in monolayer MoS$_2$. A bilayer of hexagonal
boron nitride (hBN) effectively decouples MoS$_2$ from the graphene substrate,
increasing its band gap and extending the defect charge state lifetime. This
enables the observation of sharp STML emission lines from MoS$_2$ excitons and
trions exhibiting nanoscale sensitivity to local potential fluctuations. We
identify the optical signatures of common point defects in MoS$_2$: sulfur
vacancies (Vac$_\text{S}^-$), oxygen substitutions (O$_\text{S}$), and
negatively charged carbon-hydrogen complexes (CH$_\text{S}^-$). While
Vac$_\text{S}^-$ and O$_\text{S}$ only suppress pristine excitonic emission,
CH$_\text{S}^-$ generate defect-bound exciton complexes ($A^-X$) about 200\,meV
below the MoS$_2$ exciton. Sub-nanometer-resolved STML maps reveal large
spectral shifts near charged defects, concurrent with the local band bending
expected for band-to-defect optical transitions. These results establish an
atomically precise correlation between structure, electronic states, and
optical response, enabling deterministic engineering of quantum emitters in 2D
materials.

</details>


### [184] [CoNi-MOF laccase-like nanozymes prepared by dielectric barrier discharge plasma for treatment of antibiotic pollution](https://arxiv.org/abs/2510.15524)
*Chao Liu,Yi Cao,Qi Xia,Amil Aligayev,Qing Huang*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究利用低溫等離子體技術製備了一種仿天然漆酶的雙金屬金屬-有機框架材料（CoNi-MOF），該材料在降解抗生素四環素方面表現出優異的催化性能和穩定性。


<details>
  <summary>Details</summary>
Motivation: 為了克服天然漆酶成本高、穩定性差、回收困難等實際應用限制，本研究受到天然漆酶催化機制的啟發，設計並製備了一種新型仿生催化劑。

Method: 利用介質阻擋放電等離子體技術製備雙金屬金屬-有機框架材料（CoNi-MOF），通過精確調製N2/O2氣體比例來調控氧空位濃度。結合實驗和密度泛函理論（DFT）計算，闡明了氧空位在增強仿漆酶活性中的關鍵作用，促進了分子氧（O2）的活化以生成活性氧物種（ROS）。

Result: 與天然漆酶相比，CoNi-MOF在降解抗生素四環素（TC）方面表現出優越的催化性能，同時增強了對惡劣環境條件的抵抗力、穩定性，並具有低生物毒性。此外，曝氣能提高溶解氧（DO）含量，進一步改善TC降解效率。

Conclusion: 本研究提出了一種簡便高效的低溫等離子體技術用於合成高性能仿漆酶納米酶，並為環境中抗生素污染的修復提供了一種有前景且環保的策略。

Abstract: Laccase is a natural green catalyst and utilized in pollution treatment.
Nevertheless, its practical application is constrained by limitations including
high cost, poor stability, and difficulties in recovery. Herein, with
inspiration from catalytic mechanism of natural laccase, we designed and
prepared a bimetallic metal-organic framework, namely, CoNi-MOF, using
low-temperature plasma (LTP) technology. We employed dielectric barrier
discharge (DBD) plasma to prepare CoNi-MOF, and by precisely modulating the
N2/O2 gas ratio, we could modulate the distribution concentration of oxygen
vacancies in CoNi-MOF. Experimental investigations and density functional
theory (DFT) calculations elucidated that the critical role of the oxygen
vacancies in enhancing the laccase-like activity, which promoted the activation
of molecular oxygen (O2) for generation of reactive oxygen species (ROS).
Compared to natural laccase, CoNi-MOF exhibited superior catalytic performance
in the degradation of antibiotic tetracycline (TC), along with enhanced
resistance to harsh environmental conditions, improved stability, and low
biotoxicity. Notably, aeration increased the dissolved oxygen (DO) content,
further improving the TC degradation efficiency. As such, this study not only
proposes a facile and efficient low-temperature plasma technology for
synthesizing high-performance laccase-like nanozymes but also provides a
promising and environmentally friendly strategy for the remediation of
antibiotic contamination in the environment.

</details>


### [185] [Facet Specific Electron Conduction in Pentavalent (W5+) WO3 Drives Superior Photocatalytic CO 2 Reduction in (002) Plane](https://arxiv.org/abs/2510.15528)
*Muhammad Rizwan Kamal,Mohammad Z. Rahman,Amil Aligayev,Min Liu,Li Zhong,Pengfei Xia,Yueheng Li,Yue Ruan,Xia Xiang,Pir Muhammad Ismail,Qaisar Alam,Ahmed Ismail,Muhammad Zahid,Xiaoqiang Wu,Abdullah N. Alodhayb,Qing Huang,Raj Wali Khan,Fazal Raziq,Sharafat Ali,Liang Qiao*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究通过热诱导实现WO3的拓扑结构修饰，合成了具有(002)活性面的多孔氧空位WO3纳米片，并展现了优异的光催化CO2还原性能。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是探索通过调控WO3的原子结构来调控其物理、光学和电子性质，以期在光催化CO2还原等领域获得更优异的应用。

Method: 本研究采用热诱导方法对非层状WO3进行拓扑结构修饰，合成了具有(002)活性面的多孔氧空位WO3纳米片。通过实验测量和密度泛函理论（DFT）计算，揭示了光生电子在(002)面的优先积累机制，以及其在光催化CO2还原中的催化活性。

Result: 制备得到了多孔氧空位WO3纳米片，并发现其(002)面具有优于(220)面和(205)面的光催化CO2还原性能。

Conclusion: 本研究为通过精细的原子结构调控来改善WO3的光电性质提供了新的认识，并可能在光电子、传感器和能源转换领域具有广泛的应用前景。

Abstract: This article reports a concept of heat-induced topological modifications of
non-layered WO 3 followed by successful synthesis of oxygen-vacant more-porous
nanosheets with exposed active (002) facet. Experimental measurements and
Density Functional Theory (DFT) calculations have revealed that the
photoexcited electrons are found to accumulate preferentially on (002) facet to
yield enhanced electron conduction, and consequently, strengthen the reduction
potential as active catalytic sites for photocatalytic CO2 reduction. Owing to
these beneficial properties, the more-porous nanosheets of WO 3 with (002)
facet have exhibited superior performance than that of less-porous nanosheets
of WO3 with (220) facet and bulk WO3 with (205) facet. This study therefore
provides a new understanding of regulating physical, optical, and electronic
properties through intricate atomic structure modulation of WO3, and may find
widespread application in optoelectronics, sensors, and energy conversion.

</details>


### [186] [A finite-element Delta-Sternheimer approach for accurate all-electron RPA correlation energies of arbitrary molecules](https://arxiv.org/abs/2510.15570)
*Hao Peng,Haochen Liu,Chuhao Li,Hehu Xie,Xinguo Ren*

Main category: cond-mat.mtrl-sci

TL;DR: 使用有限元方法结合原子轨道基组计算RPA相关能，在50个分子上实现了meV级别的准确度。


<details>
  <summary>Details</summary>
Motivation: 单粒子基组的不完备性给求解相关电子结构问题带来挑战，难以获得数值收敛的结果。

Method: 使用有限元方法计算RPA相关能，并结合原子轨道基组加速总能量收敛。

Result: 计算了50个分子的原子化能，精度达到每原子meV级别。

Conclusion: 将实空间离散化技术与原子轨道相结合的计算策略有望启发相关电子结构领域的研究。

Abstract: The incompleteness of single-particle basis sets has long cast a shadow over
correlated electronic-structure methods, making it highly challenging to obtain
numerically converged results. In this work, we compute the RPA correlation
energies of general molecules using the finite element method, while
ingeniously combining atomic orbital basis sets to accelerate the convergence
of total energies. We report atomization energies for 50 molecules within the
RPA framework, achieving accuracies on the order of meV per atom. The
computational strategy that integrates real-space discretization techniques
with atomic orbitals is expected to inspire the entire correlated
electronic-structure community.

</details>


### [187] [Visualizing anomalous exciton diffusion dynamics in TMDCs using transient scattering microscopy: the role of trap states and Auger recombination](https://arxiv.org/abs/2510.15587)
*Enrique Arévalo Rodríguez,Marc Meléndez Schofield,Jorge Cuadra,Ferry Prins*

Main category: cond-mat.mtrl-sci

TL;DR: 瞬态散射显微镜（TScM）用于研究块状过渡金属二硫化物（TMDCs）中的激子输运，发现激子分布呈非高斯分布，并提出通过分析峰度（kurtosis）来识别反常扩散，同时开发了非高斯拟合方法以获得可靠的扩散系数。


<details>
  <summary>Details</summary>
Motivation: 瞬态显微镜技术在能量传输研究中取得了进展，但TScM对不同载流子的敏感性使得结果解释复杂化，因此需要开发针对TScM的定制模型。

Method: 利用TScM观察块状TMDCs中的激子输运，通过分析激子分布的峰度来研究非高斯分布，并结合包含俄歇复合和陷阱态的反常扩散的数值模拟来解释实验现象。通过调节注入载流子密度区分了俄歇主导和陷阱主导的扩散机制。

Result: 实验观察到激子种群呈现非高斯分布（通过分析其过量峰度）。数值模拟能够重现这些实验结果。峰度的时间特征能够区分俄歇主导和陷阱主导的扩散机制。传统的高斯拟合方法提取的扩散系数可能不一致，而离散变量计算可以得到稳健且一致的扩散系数值。

Conclusion: 峰度是识别反常扩散的重要诊断参数，并且在分析TScM数据时必须超越高斯近似，以获得准确的分析结果。

Abstract: Research on energy transport has advanced in recent years with the emergence
of transient microscopy techniques that allow for imaging of carriers with high
spatial and temporal resolution. In this context, transient scattering
microscopy (TScM), has emerged as an alternative to traditional techniques.
However, the sensitivity of TScM to different carriers can complicate the
interpretation of results, highlighting the need to develop models tailored to
TScM. Here, TScM is used to visualize exciton transport in bulk TMDCs. We show
that exciton populations exhibit non-Gaussian profiles by analyzing the their
excess kurtosis. Numerical simulations incorporating anomalous diffusion -such
as Auger recombination and trap states- reproduce these experimental
observations. Furthermore, by tuning the injected carrier density, we
demonstrate that the temporal signature of the kurtosis is distinct for
Auger-dominated and trap-dominated regimes. Additionally, we find that
traditional Gaussian-fitting methods can yield inconsistent results for the
extracted diffusivities. As an alternative, we implement a discrete variable
calculation which yields robust, consistent diffusivity values. Our results
establish kurtosis as a vital diagnostic parameter for identifying anomolous
diffusion and demonstrate the necessity of moving beyond Gaussian
approximations for accurate analysis of TScM data.

</details>


### [188] [Calculations of pathways of precise P incorporation into chlorinated Si(100) surface](https://arxiv.org/abs/2510.15608)
*T. V. Pavlova*

Main category: cond-mat.mtrl-sci

TL;DR: 通过理论计算发现，氯化硅表面上非对称的氯空位可以控制磷原子的取代位点，从而实现精确的磷掺杂。


<details>
  <summary>Details</summary>
Motivation: 实现纳米电子器件中单杂质原子的精确掺杂，解决了现有扫描隧道显微镜（STM）光刻技术中磷原子取代硅原子时存在概率不均一的问题。

Method: 利用密度泛函理论（DFT）计算了在具有三个氯空位的Si(100)-2×1-Cl表面上，磷原子与相邻硅原子之间进行P-Si交换的激活能垒和交换速率，研究了不同P-Si交换路径。

Result: 计算结果表明，由于氯空位的非对称排布，磷原子更有可能取代其中一个特定的硅原子，而非随机取代。

Conclusion: 基于理论计算和已有实验结果，提出了一种可控且无不确定性的磷原子掺杂硅表面的方案。

Abstract: The precise incorporation of a phosphorus atom into a silicon surface is
essential for the fabrication of nanoelectronic devices in which the active
area is formed from single impurities. The most accurate approach employs
scanning tunneling microscopy (STM) lithography, which may be done with atomic
precision. However, the accuracy decreases when phosphorus is incorporated into
the surface because P substitutes one of two neighboring Si atoms with equal
probability. Here, the P-Si exchange mechanism was studied theoretically on a
chlorinated Si(100) surface with an asymmetric configuration of Cl vacancies
surrounding the P atom. Density functional theory was used to estimate the
activation barriers and exchange rates between a P atom and neighboring Si
atoms on a Si(100)-2$\times$1-Cl surface with three Cl vacancies. The
calculation of various P-Si exchange pathways revealed that phosphorus has a
higher probability of substituting one Si atom than the others due to the
asymmetric configuration of Cl vacancies. Based on the theoretical study of the
P-Si exchange mechanism and experimental results from previous works, a scheme
for controlled P incorporation into the silicon surface without uncertainty is
proposed.

</details>


### [189] [Transitions between positive and negative charge states of dangling bonds on a halogenated Si(100) surface](https://arxiv.org/abs/2510.15625)
*T. V. Pavlova,V. M. Shevlyuga*

Main category: cond-mat.mtrl-sci

TL;DR: 硅表面悬挂键（DBs）的电荷状态转换行为研究。


<details>
  <summary>Details</summary>
Motivation: 悬挂键（DBs）是影响硅电子性能的常见缺陷。本研究旨在深入理解单个DBs的电荷状态转换机制及其与电荷中性能级（CNL）的关系。

Method: 利用扫描隧道显微镜（STM）研究了氯化和溴化Si(100)-2x1表面单个DBs在正、负电荷态之间的转换过程，并分析了转换与DBs及其周围环境的关系。

Result: 观察到DBs在正负电荷态之间发生了转换，且未经过中性态。证明了这种转换发生在DBs与衬底状态失衡时，并且与CNL相关，表明DBs表现出给体或受体的性质。转换电压随DBs静电环境的变化而变化。

Conclusion: 本研究结果丰富了对DBs电子特性的理解，为利用DBs进行电荷操控的应用提供了参考。

Abstract: Dangling bonds (DBs) are common defects in silicon that affect its electronic
performance by trapping carriers at the in-gap levels. For probing the
electrical properties of individual DBs, a scanning tunneling microscope (STM)
is an effective instrument. Here we study transitions between charge states of
a single DB on chlorinated and brominated Si(100)-2$\times$1 surfaces in an
STM. We observed transitions between positively and negatively charged states
of the DB, without the participation of the neutral state. We demonstrated that
the $(+/-)$ transition occurs when the DB and substrate states are out of
equilibrium. This transition is related to the charge neutrality level (CNL),
which indicates a change in the DB's character from donor-like to
acceptor-like. The STM voltage at which the $(+/-)$ transition took place
varied depending to the electrostatic environment of the DB. Our results
complement the understanding of the electronic properties of the DBs, and they
should be taken into account in applications that use charge manipulation on
the DBs.

</details>


### [190] [Specimen preparation for atom probe tomography analysis of complex multifunctional nanoparticles and nanostructures: state-of-the-art and challenges](https://arxiv.org/abs/2510.15629)
*Varatharaja Nallathambi,Se-Ho Kim,Nikita Polin,Natalia F. Shkodich,Sven Reichenberger,Stephan Barcikowski,Baptiste Gault*

Main category: cond-mat.mtrl-sci

TL;DR: APT是一种强大的材料表征技术，但其样品制备方法对纳米材料不友好。本文提出了一种共电沉积方法，可以简化纳米材料的APT样品制备过程，并展示了该方法的广泛适用性。


<details>
  <summary>Details</summary>
Motivation: 现有样品制备方法难以满足纳米材料的APT分析需求，限制了对功能纳米材料结构-成分-性质关系的理解。

Method: 通过共电沉积技术将纳米材料与金属基底结合，形成易于进行APT分析的样品。

Result: 成功制备了多种纳米材料（纳米线、纳米片、纳米/微米颗粒、气凝胶等）的APT样品，并进行了表征。

Conclusion: 共电沉积是一种有效的纳米材料APT样品制备方法，但仍需进一步优化以提高测量产率，从而更好地服务于功能纳米材料的性能优化。

Abstract: Atom probe tomography (APT) provides the three-dimensional composition of
materials at near-atomic length scales, achieving detection limits in the range
of tens of atomic parts-per-million regardless of element type. APT requires
the specimen to be shaped as a needle with a tip radius of ~100 nm. The
development of site-specific lift-out procedures using focused ion
beam-scanning electron microscopy (FIB-SEM) has enabled APT analysis of
multifunctional materials, advancing our understanding of their
structure-composition-property relationships. Yet these approaches are not
readily suitable for analyzing many nanomaterials. Co-electrodeposition of
metallic films forms a composite containing the nanomaterials of interest,
thereby facilitating APT specimen preparation and enabling analysis of
nanowires, nanosheets, and nano- and microparticles, etc. In this perspective
article, we showcase diverse examples from simple elementary to compositionally
complex alloys of varying dimensionalities, from individual nanoparticles to
aerogel structures. We emphasize the challenges encountered with specific
material classes during co-electrodeposition procedures and provide
recommendations for improving specimen preparation protocols to enhance
measurement yield, thereby advancing APT analysis capabilities for optimizing
the performance of functional nanomaterials.

</details>


### [191] [Atomic cluster expansion potential for the Si-H system](https://arxiv.org/abs/2510.15633)
*Louise A. M. Rosset,Volker L. Deringer*

Main category: cond-mat.mtrl-sci

TL;DR: 基于ACE框架的机器学习势模型，可用于模拟Si-H相，推动对a-Si:H的探索。


<details>
  <summary>Details</summary>
Motivation: 探索氢化硅基质的原子尺度效应，以改进太阳能电池器件。

Method: 使用ACE框架构建机器学习势模型，并进行数值和物理验证。

Result: 建立了可描述多种Si-H相（包括晶态、非晶态、表面和分子）的模型，并与实验结果进行了比较。

Conclusion: 该模型是探索a-Si:H在实际器件尺度下的大型结构模型的关键进展。

Abstract: The silicon-hydrogen system is of key interest for solar-cell devices,
including both crystalline and amorphous modifications. Elemental amorphous Si
is now well understood, but the atomic-scale effects of hydrogenating the
silicon matrix remain to be fully explored. Here, we present a machine-learned
interatomic potential model based on the atomic cluster expansion (ACE)
framework that can describe a wide range of Si-H phases, from crystalline and
amorphous bulk structures to surfaces and molecules. We perform numerical and
physical validation across a range of hydrogen concentrations and compare our
results to experimental findings. Our work constitutes an advancement toward
the exploration of large structural models of a-Si:H at realistic device
scales.

</details>


### [192] [Multiferrons: lattice excitations with finite polarization and magnetization](https://arxiv.org/abs/2510.15703)
*Mike Pols,Carl P. Romao,Dominik M. Juraschek*

Main category: cond-mat.mtrl-sci

TL;DR: 本文介绍了多铁子（multiferrons）的概念，这是一种同时具有电和磁性质的准粒子，它们可以调制和传输电极化，并产生磁化。


<details>
  <summary>Details</summary>
Motivation: 引入了多铁子（multiferrons）的概念，这是一种同时具有电和磁性质的准粒子，可以调制和传输电极化，并产生磁化。

Method: 使用第一性原理计算，研究了LiNbO3中的多铁子行为。

Result: 计算表明，多铁子的电极化垂直于平衡铁电极化，而磁化则平行于平衡铁电极化。多铁子还携带净电和磁四极矩和八极矩（多极子）。

Conclusion: 多铁子及其携带的多极子可能与其它多极自由度或外部探针发生耦合，从而在相干或热激发下产生可观测的现象。

Abstract: Ferrons are a type of quasiparticle corresponding to elementary excitations
of the ferroelectric order. Analogously to how magnons modulate and transport
magnetization, ferrons modulate and transport electric polarization. Here, we
introduce multiferrons as elementary excitations with both electric and
magnetic character. Multiferrons lead to a tilt and elliptical precession of
the polarization and at the same time create a magnetization through the
mechanism of dynamical multiferroicity. Using first-principles calculations for
LiNbO$_3$, we show that the electric polarization of multiferrons is
perpendicular to the equilibrium ferroelectric polarization, whereas the
magnetization is parallel to it. Our calculations further demonstrate that
multiferrons carry net electric and magnetic quadrupole and octupole moments,
which we term multipolons. These multipolons could couple to internal
multipolar degrees of freedom, for example in altermagnets, or to external
probes such as neutrons, leading to potentially experimentally observable
phenomena following coherent or thermal excitation of multiferrons.

</details>


### [193] [Multiscale Modeling of Abnormal Grain Growth: Role of Solute Segregation and Grain Boundary Character](https://arxiv.org/abs/2510.15840)
*Albert Linda,Rajdip Mukherjee,Somanth Bhowmick*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究提出了一种多尺度框架，结合了原子尺度成分偏析和介观尺度晶粒生长动力学，以研究反常晶粒生长（AGG）。研究使用α-Fe作为示例系统，并考虑了九种不同溶质原子在三种不同重合位点晶格（CSL）边界上的多位点偏析能量。结果表明，AGG源于晶界（GB）各向异性，且程度很大程度上取决于溶质原子的种类。低能Σ3边界对于大多数溶质（Co除外）表现出更高的迁移率和优先生长。当10-30%的晶界为高迁移率类型时，观察到类似王冠的形貌，导致AGG。


<details>
  <summary>Details</summary>
Motivation: 反常晶粒生长（AGG）影响多晶材料的性质，但其潜在机制，特别是溶质偏析在晶界（GB）中的作用，难以精确量化。

Method: 本研究采用多尺度框架，整合了原子尺度的成分偏析（使用密度泛函理论）和介观尺度的晶粒生长动力学（使用相场模型），以研究反常晶粒生长（AGG）。研究了九种不同溶质原子（Co、Cr、Mn、Mo、Nb、Ni、Ti、W和V）在三种不同重合位点晶格（CSL）边界（Σ3(11-2)、Σ9(-221)和Σ3(-111)）上的多位点偏析能量。模型考虑了溶质拖曳对晶界迁移率的影响，溶质浓度为0.1 at%。

Result: 研究结果表明，AGG源于晶界（GB）各向异性，其程度很大程度上取决于溶质原子的种类。低能Σ3边界对于大多数溶质（Co除外）表现出更高的迁移率和优先生长。当10-30%的晶界为高迁移率类型时，观察到类似王冠的形貌，导致AGG。晶界类型分布对AGG有显著影响。

Conclusion: 研究结果强调了晶界化学和晶体学在控制AGG中的关键作用。所提出的模型可以推广为通过战略性溶质设计来控制先进合金中晶粒生长的预测框架。

Abstract: Abnormal grain growth (AGG) influences the properties of polycrystalline
materials; however, the underlying mechanisms, particularly the role of solute
segregation at the grain boundary (GB), are difficult to quantify precisely.
This study demonstrates a multiscale framework that integrates atomic-scale
segregation energetics (using density functional theory) with mesoscale grain
growth dynamics (using phase-field model) to investigate AGG, using $\alpha$-Fe
as an example system. Multisite segregation energies are calculated for
symmetric tilt grain boundaries (STGBs) along the $\langle 110 \rangle$ axis
for nine different solutes (Co, Cr, Mn, Mo, Nb, Ni, Ti, W, and V), encompassing
three different types of coincident site lattice (CSL) boundaries: $\sum 3
(11\bar{2})$, $\sum 9 (\bar{2}21)$, and $\sum 3 (\bar{1}11)$. The model takes
into account the effect of solute drag on GB mobility, estimated using a bulk
solute concentration of 0.1 at\%. The results demonstrate that AGG originates
due to GB anisotropy, the extent of which largely depends on the type of solute
atom present. Such a complex dependence necessitates using a multiscale model
to understand AGG comprehensively. In general, low-energy $\Sigma 3$ boundaries
are found to have higher mobility and show preferential growth for most of the
solutes, other than Co. The study reveals how the distribution of GB types
significantly influences AGG. When 10-30\% of the GBs are high-mobility type,
crown-like morphologies are observed, leading to AGG. These findings underscore
the critical role of GB chemistry and crystallography in governing AGG, and the
model can be generalized to provide a predictive framework for controlling
grain growth through strategic solute design in advanced alloys.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [194] [Cleaning up the Mess](https://arxiv.org/abs/2510.15744)
*Haocong Luo,Ataberk Olgun,Maria Makeenkova,F. Nisa Bostanci,Geraldo F. Oliveira,A. Giray Yaglikci,Onur Mutlu*

Main category: cs.AR

TL;DR: Mess论文中的Ramulator 2.0和DAMOV模拟结果不准确且不可复现，该研究纠正了这些错误并强调了验证模拟结果和开源合作的重要性。


<details>
  <summary>Details</summary>
Motivation: Mess论文（MICRO 2024最佳论文亚军）提出的评估内存系统性能的基准存在问题，其Ramulator 2.0和DAMOV模拟结果不准确且不可复现，影响了科学记录的可靠性。

Method: 通过重新配置Ramulator 2.0并使用正确的DAMOV模拟统计数据，来验证和纠正Mess论文中的错误。同时，检查了Mess论文的工件库以评估可复现性。

Result: Ramulator 2.0的模拟结果经正确配置后，能很好地反映真实系统特性，反驳了Mess论文的核心论点。DAMOV模拟结果使用了不相关的统计数据。Mess论文的工件库缺乏完全复现所需的所有源代码。

Conclusion: Mess论文中的Ramulator 2.0和DAMOV模拟结果存在严重错误且无法复现。本研究纠正了这些错误，强调了严格验证模拟结果和遵循开源精神的重要性，以维护科学记录的准确性和完整性。该研究还引发了对评审和工件评估过程完整性的质疑。

Abstract: A MICRO 2024 best paper runner-up publication (the Mess paper) with all three
artifact badges awarded (including "Reproducible") proposes a new benchmark to
evaluate real and simulated memory system performance. In this paper, we
demonstrate that the Ramulator 2.0 simulation results reported in the Mess
paper are incorrect and, at the time of the publication of the Mess paper,
irreproducible. We find that the authors of Mess paper made multiple trivial
human errors in both the configuration and usage of the simulators. We show
that by correctly configuring Ramulator 2.0, Ramulator 2.0's simulated memory
system performance actually resembles real system characteristics well, and
thus a key claimed contribution of the Mess paper is factually incorrect. We
also identify that the DAMOV simulation results in the Mess paper use wrong
simulation statistics that are unrelated to the simulated DRAM performance.
Moreover, the Mess paper's artifact repository lacks the necessary sources to
fully reproduce all the Mess paper's results.
  Our work corrects the Mess paper's errors regarding Ramulator 2.0 and
identifies important issues in the Mess paper's memory simulator evaluation
methodology. We emphasize the importance of both carefully and rigorously
validating simulation results and contacting simulator authors and developers,
in true open source spirit, to ensure these simulators are used with correct
configurations and as intended. We encourage the computer architecture
community to correct the Mess paper's errors. This is necessary to prevent the
propagation of inaccurate and misleading results, and to maintain the
reliability of the scientific record. Our investigation also opens up questions
about the integrity of the review and artifact evaluation processes. To aid
future work, our source code and scripts are openly available at https:
//github.com/CMU-SAFARI/ramulator2/tree/mess.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [195] [Combinatorial Contract Design: Recent Progress and Emerging Frontiers](https://arxiv.org/abs/2510.15065)
*Michal Feldman*

Main category: cs.GT

TL;DR: 本论文提出并研究了组合契约设计这一算法契约设计的新兴前沿领域，重点关注智能体选择多种行动或多智能体协作的复杂场景。


<details>
  <summary>Details</summary>
Motivation: 经典契约理论模型虽然优雅，但在处理现代应用（如在线劳动力市场、医疗保健、AI委托和区块链协议）时面临计算效率的挑战，需要算法视角。

Method: 本文综述了三种组合契约设置：(i) 单一智能体选择多种行动，(ii) 多个智能体选择二元行动，(iii) 多个智能体各自选择多种行动。为每种设置，文章都分析了其结构性洞见、算法技术和复杂性障碍。

Result: 研究结果包括在 gross substitutes 奖励函数等易处理情况下的解决方案，以及在价值和需求预言机模型下的复杂性障碍和近似保证。

Conclusion: 本文描绘了组合契约设计的最新进展，并指出了该领域未来的基本开放性问题和有前景的研究方向。

Abstract: Contract theory studies how a principal can incentivize agents to exert
costly, unobservable effort through performance-based payments. While classical
economic models provide elegant characterizations of optimal solutions, modern
applications, ranging from online labor markets and healthcare to AI delegation
and blockchain protocols, call for an algorithmic perspective. The challenge is
no longer only which contracts induce desired behavior, but whether such
contracts can be computed efficiently. This viewpoint has given rise to
\emph{algorithmic contract design}, paralleling the rise of algorithmic
mechanism design two decades ago.
  This article focuses on \emph{combinatorial contracts}, an emerging frontier
within algorithmic contract design, where agents may choose among exponentially
many combinations of actions, or where multiple agents must work together as a
team, and the challenge lies in selecting the right composition. These models
capture a wide variety of real-world contracting environments, from hospitals
coordinating physicians across treatment protocols to firms hiring teams of
engineers for interdependent tasks. We review three combinatorial settings: (i)
a single agent choosing multiple actions, (ii) multiple agents with binary
actions, and (iii) multiple agents each selecting multiple actions. For each,
we highlight structural insights, algorithmic techniques, and complexity
barriers. Results include tractable cases such as gross substitutes reward
functions, hardness results, and approximation guarantees under value- and
demand-oracle access. By charting these advances, the article maps the emerging
landscape of combinatorial contract design, and highlights fundamental open
questions and promising directions for future work.

</details>


### [196] [Beyond Outcome-Based Imperfect-Recall: Higher-Resolution Abstractions for Imperfect-Information Games](https://arxiv.org/abs/2510.15094)
*Yanchang Fu,Qiyue Yin,Shengda Liu,Pei Xu,Kaiqi Huang*

Main category: cs.GT

TL;DR: 提出SOOGs，一种IIGs的子类，用于扑克等游戏，并定义了分辨率边界，用于衡量手部抽象的性能上限。提出FROI算法，通过整合历史信息来提高性能。


<details>
  <summary>Details</summary>
Motivation: 现有手部抽象方法在不完美信息博弈（IIGs）中存在局限，缺乏正式的任务模型和高效的评估方法。

Method: 提出SOOGs（信号观察有序博弈），并定义了分辨率边界。提出FROI（全回忆结果同构），并与基于结果的不完全回忆算法进行比较。

Result: FROI在德州扑克风格的游戏中表现优于基于结果的不完全回忆基线方法。

Conclusion: SOOGs和分辨率边界为手部抽象提供了正式的理论基础，FROI为设计更高分辨率的抽象提供了实际指导。

Abstract: Hand abstraction is crucial for scaling imperfect-information games (IIGs)
such as Texas Hold'em, yet progress is limited by the lack of a formal task
model and by evaluations that require resource-intensive strategy solving. We
introduce signal observation ordered games (SOOGs), a subclass of IIGs tailored
to hold'em-style games that cleanly separates signal from player action
sequences, providing a precise mathematical foundation for hand abstraction.
Within this framework, we define a resolution bound-an information-theoretic
upper bound on achievable performance under a given signal abstraction. Using
the bound, we show that mainstream outcome-based imperfect-recall algorithms
suffer substantial losses by arbitrarily discarding historical information; we
formalize this behavior via potential-aware outcome Isomorphism (PAOI) and
prove that PAOI characterizes their resolution bound. To overcome this
limitation, we propose full-recall outcome isomorphism (FROI), which integrates
historical information to raise the bound and improve policy quality.
Experiments on hold'em-style benchmarks confirm that FROI consistently
outperforms outcome-based imperfect-recall baselines. Our results provide a
unified formal treatment of hand abstraction and practical guidance for
designing higher-resolution abstractions in IIGs.

</details>


### [197] [How to Sell High-Dimensional Data Optimally](https://arxiv.org/abs/2510.15214)
*Andrew Li,R. Ravi,Karan Singh,Zihong Yi,Weizhong Zhang*

Main category: cs.GT

TL;DR: 卖家可以通过设计一个包含统计实验的菜单来向买家出售信息，即使在买家偏好未知的情况下也能实现收益最大化。该算法在样本量与状态空间无关的情况下，能够生成接近最优的菜单，并在高维高斯数据的情况下，通过半定规划有效地找到最优菜单。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是解决销售专有数据的问题，特别是信息定价问题，其中卖方拥有决定买方效用的底层状态信息。由于买方需要信息来做出更好的决策，卖方可以提供信息并收取费用。然而，卖方可能不完全了解买方的私有偏好，因此需要设计一个能够实现收益最大化的信息产品。

Method: 研究提出了一种算法，该算法能够从状态空间中进行采样，并生成一个接近最优的信息菜单。该算法的样本量与状态空间的大小无关。此外，研究还分析了高维高斯数据的一个特例，证明了只需考虑标量高斯实验，并且可以通过半定规划有效地找到最优菜单。

Result: 在高维高斯数据的情况下，研究证明了（a）考虑标量高斯实验就足够了，（b）可以通过半定规划高效地找到最优的实验菜单，以及（c）当且仅当在买方潜在偏好集上满足某个分离条件时，可以实现完全盈余提取。

Conclusion: 该研究提出了一种有效的算法来解决信息定价问题，即使在买方偏好未知的情况下也能实现收益最大化。在高维高斯数据的情况下，该方法可以高效地找到最优信息产品，并且在特定条件下可以实现完全盈余提取。

Abstract: Motivated by the problem of selling large, proprietary data, we consider an
information pricing problem proposed by Bergemann et al. that involves a
decision-making buyer and a monopolistic seller. The seller has access to the
underlying state of the world that determines the utility of the various
actions the buyer may take. Since the buyer gains greater utility through
better decisions resulting from more accurate assessments of the state, the
seller can therefore promise the buyer supplemental information at a price. To
contend with the fact that the seller may not be perfectly informed about the
buyer's private preferences (or utility), we frame the problem of designing a
data product as one where the seller designs a revenue-maximizing menu of
statistical experiments.
  Prior work by Cai et al. showed that an optimal menu can be found in time
polynomial in the state space, whereas we observe that the state space is
naturally exponential in the dimension of the data. We propose an algorithm
which, given only sampling access to the state space, provably generates a
near-optimal menu with a number of samples independent of the state space. We
then analyze a special case of high-dimensional Gaussian data, showing that (a)
it suffices to consider scalar Gaussian experiments, (b) the optimal menu of
such experiments can be found efficiently via a semidefinite program, and (c)
full surplus extraction occurs if and only if a natural separation condition
holds on the set of potential preferences of the buyer.

</details>


### [198] [HOB: A Holistically Optimized Bidding Strategy under Heterogeneous Auction Mechanisms with Organic Traffic](https://arxiv.org/abs/2510.15238)
*Qi Li,Wendong Huang,Qichen Ye,Wutong Xu,Cheems Wang,Rongquan Bai,Wei Yuan,Guan Wang,Chuan Yu,Jian Xu*

Main category: cs.GT

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The E-commerce advertising platforms typically sell commercial traffic
through either second-price auction (SPA) or first-price auction (FPA). SPA was
historically prevalent due to its dominant strategy incentive-compatible (DSIC)
for bidders with quasi-linear utilities, especially when budgets are not a
binding constraint, while FPA has gained more prominence for offering higher
revenue potential to publishers and avoiding the possibility for discriminatory
treatment in personalized reserve prices. Meanwhile, on the demand side,
advertisers are increasingly adopting platform-wide marketing solutions akin to
QuanZhanTui, shifting from spending budgets solely on commercial traffic to
bidding on the entire traffic for the purpose of maximizing overall sales. For
automated bidding systems, such a trend poses a critical challenge: determining
optimal strategies across heterogeneous auction channels to fulfill diverse
advertiser objectives, such as maximizing return (MaxReturn) or meeting target
return on ad spend (TargetROAS). To overcome this challenge, this work makes
two key contributions. First, we derive an efficient solution for optimal
bidding under FPA channels, which takes into account the presence of organic
traffic - traffic can be won for free. Second, we introduce a marginal cost
alignment (MCA) strategy that provably secures bidding efficiency across
heterogeneous auction mechanisms. To validate performance of our developed
framework, we conduct comprehensive offline experiments on public datasets and
large-scale online A/B testing, which demonstrate consistent improvements over
existing methods.

</details>


### [199] [A Renegotiable contract-theoretic incentive mechanism for Federated learning](https://arxiv.org/abs/2510.15344)
*Xavier Tan,Xiaoli Tang,Han Yu*

Main category: cs.GT

TL;DR: 该研究提出了一种名为RC-TIM的可重新协商合同激励机制，用于联邦学习（FL）市场，以解决现有合同在不可预见情况下无法更改的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦学习（FL）激励机制在合同签订后通常保持不变，但不可预见的情况可能导致数据所有者（DOs）无法履行合同，从而造成数据消费者（DCs）预算的低效利用。因此，需要一种能够适应DOs行为和预算变化的动态激励机制。

Method: 提出了一种名为RC-TIM的可重新协商合同-理论激励机制（Renegotiable Contract-Theoretic Incentive Mechanism）。该机制允许在联邦学习任务进行中重新协商合同，以适应数据所有者行为和预算的变化，从而实现灵活和动态的激励。

Result: 在三个基准数据集上的大量实验表明，RC-TIM的效用平均提高了45.76%，显著优于四种最先进的相关方法。

Conclusion: RC-TIM通过支持合同重新协商，能够更好地适应操作环境中可能影响数据所有者提供的服务质量的不可预测变化，从而提高联邦学习系统的适应性并实现更优的激励效果。

Abstract: Federated learning (FL) has gained prominence due to heightened concerns over
data privacy. Privacy restrictions limit the visibility for data consumers
(DCs) to accurately assess the capabilities and efforts of data owners (DOs).
Thus, for open collaborative FL markets to thrive, effective incentive
mechanisms are key as they can motivate data owners (DOs) to contribute to FL
tasks. Contract theory is a useful technique for developing FL incentive
mechanisms. Existing approaches generally assume that once the contract between
a DC and a DO is signed, it remains unchanged until the FL task is finished.
However, unforeseen circumstances might force a DO to be unable to fulfill the
current contract, resulting in inefficient utilization of DCs' budgets. To
address this limitation, we propose the Renegotiable Contract-Theoretic
Incentive Mechanism (RC-TIM) for FL. Unlike previous approaches, it adapts to
changes in DOs' behavior and budget constraints by supporting the renegotiation
of contracts, providing flexible and dynamic incentives. Under RC-TIM, an FL
system is more adaptive to unpredictable changes in the operating environment
that can affect the quality of the service provided by DOs. Extensive
experiments on three benchmark datasets demonstrate that RC-TIM significantly
outperforms four state-of-the-art related methods, delivering up to a 45.76%
increase in utility on average.

</details>


### [200] [Co-Investment with Dynamic Participation under Unforeseeable Opportunity Costs: A Coalitional Game Approach](https://arxiv.org/abs/2510.15384)
*Amal Sakr,Andrea Araldo,Tijani Chahed,Daniel Kofman*

Main category: cs.GT

TL;DR: 该研究提出了一种基于联盟博弈理论的动态联合投资方案，以解决移动边缘计算（MEC）基础设施部署的投资障碍。该方案允许多个参与者（基础设施提供商和多个服务提供商）灵活地加入、退出或留在联合投资中，并可根据情况调整基础设施容量和资源共享。研究还提出了一种计算进入费和退出罚金的方法，以公平补偿留下的参与者。数值结果表明，该动态方案能有效鼓励参与，并提高参与者的利润，尤其是在机会成本较高的情况下。


<details>
  <summary>Details</summary>
Motivation: 移动边缘计算（MEC）等技术依赖于基础设施的可用性。基础设施提供商（InP）可能不愿意独自承担部署和维护基础设施的高昂投资成本。

Method: 提出一种基于联盟博弈理论的动态联合投资方案，允许参与者灵活地加入、退出或留在联合投资中，并可动态调整基础设施容量和资源共享。同时，提出计算进入费和退出罚金的方法，以补偿留下的参与者。

Result: 数值结果表明，该动态方案能有效鼓励参与，并提高参与者的利润，尤其是在机会成本较高的情况下。

Conclusion: 所提出的动态联合投资方案能够有效地鼓励基础设施部署的参与，并在存在较高机会成本的情况下增加参与者的利润。

Abstract: Technologies such as Mobile Edge Computing (MEC) depend on the availability
of infrastructure. We define the Infrastructure Provider (InP) as the actor
responsible for deploying and maintaining this infrastructure, while Service
Providers (SPs) operate applications over it to serve end users and earn
revenues. Deploying such infrastructure requires however a significant
investment, and the InP may be reluctant to bear it alone. We propose
co-investment to overcome this barrier, allowing players, the InP and multiple
SPs, to share costs and revenues. However, committing to a co-investment over a
long period may be too constraining for players: in an unforeseeable future,
players may realize that they could make more profit outside the co-investment
(such a profit is called opportunity cost). For this reason, we propose a
scheme, based on coalitional game theory, which is dynamic in terms of
(i)allowing players to join, remain in, or leave the co-investment, (ii)
adjusting the infrastructure capacity and resource sharing over time. We
propose a method to compute entry fees and exit penalties in order to
appropriately compensate players remaining in the co-investment. We numerically
show that our dynamic scheme encourages player participation and increases
profit (in case of high opportunity cost).

</details>


### [201] [Reviving, reproducing, and revisiting Axelrod's second tournament](https://arxiv.org/abs/2510.15438)
*Vincent Knight,Owen Campbell,Marc Harper,T. J. Gaffney,Nikoleta E. Glynatsi*

Main category: cs.GT

TL;DR: 复现了Axelrod的第二次囚徒困境竞赛，验证了“针锋相对”策略的有效性，并发现该策略在更广泛的比赛环境中并非最优。


<details>
  <summary>Details</summary>
Motivation: 现有关于Axelrod的第二次囚徒困境竞赛的记录不完整，引发了对其结果可复现性的质疑，因此需要对该竞赛进行复现和重新评估。

Method: 通过修复原始Fortran代码并构建Python接口，成功复现了Axelrod的第二次囚徒困境竞赛，并使用Axelrod-Python库进行了大量扩展实验。

Result: 复现了Axelrod的主要发现，即“针锋相对”策略获胜，并且成功的策略倾向于合作、响应背叛且乐于原谅。在包含新策略和不同环境的比赛中，发现“针锋相对”策略并非总是最优，一些先前不知名的策略表现更佳。

Conclusion: Axelrod的第二次囚徒困境竞赛结果具有一定的可复现性，但“针锋相对”策略的统治地位并非绝对，在更广泛和复杂环境中，其他策略可能表现更优。复现工作为未来的研究提供了工具和基础。

Abstract: Direct reciprocity, typically studied using the Iterated Prisoner's Dilemma
(IPD), is central to understanding how cooperation evolves. In the 1980s,
Robert Axelrod organized two influential IPD computer tournaments, where Tit
for Tat (TFT) emerged as the winner. Yet the archival record is incomplete: for
the first tournament only a report survives, and for the second the submitted
Fortran strategies remain but not the final tournament code. This gap raises
questions about the reproducibility of these historically influential results.
We recreate the second tournament by restoring the surviving Fortran
implementations to compile with modern compilers and by building a Python
interface that calls the original strategy functions without modification.
Using the open-source Axelrod-Python library to run tournaments, we reproduce
Axelrod's main findings: TFT prevails, and successful play tends to be
cooperative, responsive to defection, and willing to forgive. Strategy rankings
remain mostly unchanged. We then assess the robustness of the originally
submitted strategies by incorporating additional strategies, and we run one of
the largest IPD tournaments to date. We find that the original tournament was
especially favorable to TFT and that it is difficult to dethrone TFT when the
original submissions make up the majority of the field. We also observe that
several lesser-known submissions perform strongly in more diverse settings and
under noise. Our contributions are: (i) the first systematic reproduction of
Axelrod's second tournament; (ii) a contemporary reassessment of the original
results in light of new strategies and settings; and (iii) a preserved,
easy-to-use implementation of the second-tournament strategies within
Axelrod-Python to support future research.

</details>


### [202] [Active Inverse Methods in Stackelberg Games with Bounded Rationality](https://arxiv.org/abs/2510.15582)
*Jianguo Chen,Jinlong Lei,Biqiang Mu,Yiguang Hong,Hongsheng Qi*

Main category: cs.GT

TL;DR: 本研究将逆向博弈理论扩展到主动学习逆向博弈，使学习者能够作为游戏中的主动参与者，以提高学习效率。研究了具有有限理性的Stackelberg博弈，其中领导者作为学习者，通过主动选择动作来学习跟随者的成本函数。


<details>
  <summary>Details</summary>
Motivation: 现有的逆向博弈理论未能将学习者视为游戏中的活跃参与者，而这可以显著地促进学习过程。

Method: 首先，研究者提出了一种利用Fisher信息来最大化未知参数信息增益的主动学习方法，并证明了其一致性和渐近正态性。其次，当领导者考虑自身成本时，研究者提出了一种主动逆向博弈方法，以平衡探索和利用，并证明了其在二次成本函数下的稳定性和渐近Stackelberg均衡性。

Result: 通过二次方程案例模拟验证了这些方法的性质，并证明了主动逆向博弈方法可以通过主动探索更快地达到Stackelberg均衡。

Conclusion: 主动学习逆向博弈可以使学习者成为游戏中的活跃参与者，从而提高学习效率。

Abstract: Inverse game theory is utilized to infer the cost functions of all players
based on game outcomes. However, existing inverse game theory methods do not
consider the learner as an active participant in the game, which could
significantly enhance the learning process. In this paper, we extend inverse
game theory to active inverse methods. For Stackelberg games with bounded
rationality, the leader, acting as a learner, actively chooses actions to
better understand the follower's cost functions. First, we develop a method of
active learning by leveraging Fisher information to maximize information gain
about the unknown parameters and prove the consistency and asymptotic
normality. Additionally, when leaders consider its cost, we develop a method of
active inverse game to balance exploration and exploitation, and prove the
consistency and asymptotic Stackelberg equilibrium with quadratic cost
functions. Finally, we verify the properties of these methods through
simulations in the quadratic case and demonstrate that the active inverse game
method can achieve Stackelberg equilibrium more quickly through active
exploration.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [203] [Decentralizing Multi-Agent Reinforcement Learning with Temporal Causal Information](https://arxiv.org/abs/2506.07829)
*Jan Corazza,Hadi Partovi Aria,Hyohun Kim,Daniel Neider,Zhe Xu*

Main category: cs.LG

TL;DR: 本论文研究了在多智能体强化学习（DMARL）中，如何利用高层符号知识来解决隐私、通信和性能限制等挑战。通过扩展兼容性检查的正式工具，使得去中心化训练在更多场景下具有理论保证，并能加快学习过程。


<details>
  <summary>Details</summary>
Motivation: 许多现实世界问题需要多个智能体协作以达成共同目标，而现有的去中心化多智能体强化学习（DMARL）方法在兼容性、隐私、通信和性能方面存在挑战。

Method: 扩展了用于检查局部策略与团队任务兼容性的形式化工具，并利用环境事件的时间演化方面的符号知识来加速DMARL的学习过程。

Result: 实验证明，提供关于环境事件时间演化的符号知识可以显著加快DMARL的学习过程。

Conclusion: 高层符号知识的引入可以扩展去中心化训练的适用范围，并提高DMARL的效率。

Abstract: Reinforcement learning (RL) algorithms can find an optimal policy for a
single agent to accomplish a particular task. However, many real-world problems
require multiple agents to collaborate in order to achieve a common goal. For
example, a robot executing a task in a warehouse may require the assistance of
a drone to retrieve items from high shelves. In Decentralized Multi-Agent RL
(DMARL), agents learn independently and then combine their policies at
execution time, but often must satisfy constraints on compatibility of local
policies to ensure that they can achieve the global task when combined. In this
paper, we study how providing high-level symbolic knowledge to agents can help
address unique challenges of this setting, such as privacy constraints,
communication limitations, and performance concerns. In particular, we extend
the formal tools used to check the compatibility of local policies with the
team task, making decentralized training with theoretical guarantees usable in
more scenarios. Furthermore, we empirically demonstrate that symbolic knowledge
about the temporal evolution of events in the environment can significantly
expedite the learning process in DMARL.

</details>


### [204] [Automotive Crash Dynamics Modeling Accelerated with Machine Learning](https://arxiv.org/abs/2510.15201)
*Mohammad Amin Nabian,Sudeep Chavare,Deepak Akhare,Rishikesh Ranade,Ram Cherukuri,Srinivas Tadepalli*

Main category: cs.LG

TL;DR: 本研究探索使用机器学习替代方法来预测汽车碰撞中的结构变形，使用NVIDIA PhysicsNeMo框架，并比较了MeshGraphNet和Transolver两种模型以及三种时间动态建模策略。


<details>
  <summary>Details</summary>
Motivation: 传统的有限元（FE）模拟在汽车碰撞安全评估中计算成本高昂且耗时，本研究旨在探索机器学习替代模型以提高效率。

Method: 研究了MeshGraphNet和Transolver两种神经网络架构，并结合了时间条件、标准自回归和稳定性增强自回归三种瞬态动力学建模策略，使用包含150个FE模拟的BIW碰撞数据集进行训练和评估。

Result: 所提出的机器学习模型能够以合理的保真度捕捉整体变形趋势，计算成本比FE模拟降低了几个数量级。

Conclusion: 机器学习方法在结构碰撞动力学领域具有可行性和工程实用性，能够显著降低计算成本，从而实现碰撞安全评估中的快速设计探索和早期优化。

Abstract: Crashworthiness assessment is a critical aspect of automotive design,
traditionally relying on high-fidelity finite element (FE) simulations that are
computationally expensive and time-consuming. This work presents an exploratory
comparative study on developing machine learning-based surrogate models for
efficient prediction of structural deformation in crash scenarios using the
NVIDIA PhysicsNeMo framework. Given the limited prior work applying machine
learning to structural crash dynamics, the primary contribution lies in
demonstrating the feasibility and engineering utility of the various modeling
approaches explored in this work. We investigate two state-of-the-art neural
network architectures for modeling crash dynamics: MeshGraphNet, and
Transolver. Additionally, we examine three strategies for modeling transient
dynamics: time-conditional, the standard Autoregressive approach, and a
stability-enhanced Autoregressive scheme incorporating rollout-based training.
The models are evaluated on a comprehensive Body-in-White (BIW) crash dataset
comprising 150 detailed FE simulations using LS-DYNA. The dataset represents a
structurally rich vehicle assembly with over 200 components, including 38 key
components featuring variable thickness distributions to capture realistic
manufacturing variability. Each model utilizes the undeformed mesh geometry and
component characteristics as inputs to predict the spatiotemporal evolution of
the deformed mesh during the crash sequence. Evaluation results show that the
models capture the overall deformation trends with reasonable fidelity,
demonstrating the feasibility of applying machine learning to structural crash
dynamics. Although not yet matching full FE accuracy, the models achieve
orders-of-magnitude reductions in computational cost, enabling rapid design
exploration and early-stage optimization in crashworthiness evaluation.

</details>


### [205] [Extending Load Forecasting from Zonal Aggregates to Individual Nodes for Transmission System Operators](https://arxiv.org/abs/2510.14983)
*Oskar Triebe,Fletcher Passow,Simon Wittner,Leonie Wagner,Julio Arend,Tao Sun,Chad Zanocco,Marek Miltner,Arezou Ghesmati,Chen-Hao Tsai,Christoph Bergmeir,Ram Rajagopal*

Main category: cs.LG

TL;DR: 该研究提出了一种多层次系统，用于满足电力系统运营商对小时级日前负荷预测的需求，以应对可持续能源发展带来的电网可靠性挑战。


<details>
  <summary>Details</summary>
Motivation: 可持续能源发展增加了电力负荷的不确定性，对本地电网基础设施的可靠性构成了挑战。输电系统运营商（TSO）需要更高空间分辨率的负荷预测，将当前面向区域聚合的预测扩展到单个节点，但节点负荷预测精度较低且数量庞大，难以管理。

Method: 设计了一个多层次系统，包括一个可解释且可扩展的预测模型，允许TSO逐步将区域预测扩展到节点预测；评估了解决节点负荷异构性和波动性的方案；提出了一种全并行化单模型预测工作流以实现系统可管理性。

Result: 该系统在区域预测方面提高了准确性和可解释性，在节点预测方面取得了显著的改进。

Conclusion: 该多层次预测系统使运营商能够以前所未有的置信度和准确性调整预测，并精确诊断以往难以发现的错误。

Abstract: The reliability of local power grid infrastructure is challenged by
sustainable energy developments increasing electric load uncertainty.
Transmission System Operators (TSOs) need load forecasts of higher spatial
resolution, extending current forecasting operations from zonal aggregates to
individual nodes. However, nodal loads are less accurate to forecast and
require a large number of individual forecasts, which are hard to manage for
the human experts assessing risks in the control room's daily operations
(operator). In collaboration with a TSO, we design a multi-level system that
meets the needs of operators for hourly day-ahead load forecasting. Utilizing a
uniquely extensive dataset of zonal and nodal net loads, we experimentally
evaluate our system components. First, we develop an interpretable and scalable
forecasting model that allows for TSOs to gradually extend zonal operations to
include nodal forecasts. Second, we evaluate solutions to address the
heterogeneity and volatility of nodal load, subject to a trade-off. Third, our
system is manageable with a fully parallelized single-model forecasting
workflow. Our results show accuracy and interpretability improvements for zonal
forecasts, and substantial improvements for nodal forecasts. In practice, our
multi-level forecasting system allows operators to adjust forecasts with
unprecedented confidence and accuracy, and to diagnose otherwise opaque errors
precisely.

</details>


### [206] [Fine-Tuning Small Language Models for Domain-Specific AI: An Edge AI Perspective](https://arxiv.org/abs/2503.01933)
*Rakshit Aralimatti,Syed Abdul Gaffar Shakhadri,Kruthika KR,Kartik Basavaraj Angadi*

Main category: cs.LG

TL;DR: Shakti SLMs are efficient small language models designed for edge devices, overcoming computational, energy, and privacy challenges through efficient architectures, quantization, and responsible AI principles. They show strong performance on general and specialized tasks.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the challenges of deploying large language models on edge devices, including high computational demands, energy consumption, and data privacy risks.

Method: The paper introduces Shakti Small Language Models (SLMs) with efficient architectures, quantization techniques, and responsible AI principles. It details their design philosophy, training pipelines, and benchmark performance.

Result: The Shakti series (Shakti-100M, Shakti-250M, Shakti-500M) enables on-device intelligence for edge devices and demonstrates that carefully engineered compact models can meet or exceed expectations in real-world edge-AI scenarios, performing well on general and specialized tasks.

Conclusion: Compact language models, when properly engineered and fine-tuned, are capable of meeting and often surpassing requirements in practical edge-AI applications.

Abstract: Deploying large scale language models on edge devices faces inherent
challenges such as high computational demands, energy consumption, and
potential data privacy risks. This paper introduces the Shakti Small Language
Models (SLMs) Shakti-100M, Shakti-250M, and Shakti-500M which target these
constraints headon. By combining efficient architectures, quantization
techniques, and responsible AI principles, the Shakti series enables on-device
intelligence for smartphones, smart appliances, IoT systems, and beyond. We
provide comprehensive insights into their design philosophy, training
pipelines, and benchmark performance on both general tasks (e.g., MMLU,
Hellaswag) and specialized domains (healthcare, finance, and legal). Our
findings illustrate that compact models, when carefully engineered and
fine-tuned, can meet and often exceed expectations in real-world edge-AI
scenarios.

</details>


### [207] [TangledFeatures: Robust Feature Selection in Highly Correlated Spaces](https://arxiv.org/abs/2510.15005)
*Allen Daniel Sunny*

Main category: cs.LG

TL;DR: TangledFeatures框架可以从纠缠的预测变量组中识别出代表性特征，从而减少冗余并保留解释力，适用于相关特征空间中的特征选择。


<details>
  <summary>Details</summary>
Motivation: 现有特征选择方法主要关注预测准确性，在存在相关预测变量时性能会下降，而TangledFeatures旨在解决这一差距。

Method: TangledFeatures框架识别相关特征空间中纠缠预测变量组的代表性特征。

Result: 在丙氨酸二肽数据集上，TangledFeatures选择的特征与解释骨架扭转角变化的结构上有意义的原子间距离相对应，显示了其有效性。

Conclusion: TangledFeatures提供了一种比传统选择技术更具可解释性和稳定性的特征子集，可直接用于下游模型。

Abstract: Feature selection is a fundamental step in model development, shaping both
predictive performance and interpretability. Yet, most widely used methods
focus on predictive accuracy, and their performance degrades in the presence of
correlated predictors. To address this gap, we introduce TangledFeatures, a
framework for feature selection in correlated feature spaces. It identifies
representative features from groups of entangled predictors, reducing
redundancy while retaining explanatory power. The resulting feature subset can
be directly applied in downstream models, offering a more interpretable and
stable basis for analysis compared to traditional selection techniques. We
demonstrate the effectiveness of TangledFeatures on Alanine Dipeptide, applying
it to the prediction of backbone torsional angles and show that the selected
features correspond to structurally meaningful intra-atomic distances that
explain variation in these angles.

</details>


### [208] [Theoretical Refinement of CLIP by Utilizing Linear Structure of Optimal Similarity](https://arxiv.org/abs/2510.15508)
*Naoki Yoshida,Satoshi Hayakawa,Yuhta Takida,Toshimitsu Uesaka,Hiromi Wakaki,Yuki Mitsufuji*

Main category: cs.LG

TL;DR: KME-CLIP通过利用PMI的潜在线性结构来提高多模态对比预训练框架的相似性计算。实验证明，KME-CLIP在检索和分类任务上优于标准CLIP。


<details>
  <summary>Details</summary>
Motivation: 现有的CLIP及其变体未能充分利用PMI的潜在线性结构，而理论研究表明最优相似性度量应对应PMI。

Method: 提出KME-CLIP，利用再生核希尔伯特空间中的内积来利用PMI的潜在线性结构。

Result: 理论上证明KME-CLIP可以任意精度地逼近PMI，并在检索和分类任务上实现了优于标准CLIP的性能。

Conclusion: KME-CLIP通过利用PMI的线性结构，在多模态对比预训练中提供了更好的相似性计算方法，并在多项任务中取得了优于现有方法的性能。

Abstract: In this study, we propose an enhancement to the similarity computation
mechanism in multi-modal contrastive pretraining frameworks such as CLIP. Prior
theoretical research has demonstrated that the optimal similarity metrics
between paired modalities should correspond to the pointwise mutual information
(PMI) between the two modalities. However, the current implementations of CLIP
and its variants fail to fully utilize the underlying linear structure of PMI.
We therefore propose KME-CLIP, which leverages this structure through the inner
product in a reproducing kernel Hilbert space. We theoretically prove that our
method can approximate PMI with arbitrary accuracy and empirically demonstrate
that our approach overall outperforms the standard CLIP formulation across
several retrieval and classification tasks.

</details>


### [209] [Bridging Simplicity and Sophistication using GLinear: A Novel Architecture for Enhanced Time Series Prediction](https://arxiv.org/abs/2501.01087)
*Syed Tahir Hussain Rizvi,Neel Kanwal,Muddasar Naeem*

Main category: cs.LG

TL;DR: GLinear是一种新的多变量时间序列预测模型，它利用周期性模式，在数据效率和准确性方面优于现有的线性模型和Transformer模型。


<details>
  <summary>Details</summary>
Motivation: 探讨Transformer在时间序列预测中处理时间关系的能力，并提出一种新的数据高效架构GLinear。

Method: 提出了一种名为高斯激活线性模型（GLinear）的新型多变量时间序列预测架构，该架构利用周期性模式来提高准确性。

Result: GLinear在四个不同的数据集（ETTh1、Electricity、Traffic和Weather）上进行了评估，并在大多数多变量时间序列预测情况下优于现有的先进线性模型（NLinear、DLinear、RLinear）和基于Transformer的模型（Autoformer），同时在其他情况下也具有竞争力。

Conclusion: GLinear模型在数据效率和预测准确性方面表现出色，有望促进更简单、更复杂的时间序列分析架构的研究和开发。

Abstract: Time Series Forecasting (TSF) is an important application across many fields.
There is a debate about whether Transformers, despite being good at
understanding long sequences, struggle with preserving temporal relationships
in time series data. Recent research suggests that simpler linear models might
outperform or at least provide competitive performance compared to complex
Transformer-based models for TSF tasks. In this paper, we propose a novel
data-efficient architecture, \textit{Gaussian-activated Linear model
(GLinear)}, for multivariate TSF that exploits periodic patterns to provide
better accuracy. It achieves higher prediction accuracy while requiring less
historical data than other state-of-the-art linear predictors. Four different
datasets (ETTh1, Electricity, Traffic, and Weather) are used to evaluate the
performance of the proposed predictor. A performance comparison with
state-of-the-art linear architectures (such as NLinear, DLinear, and RLinear)
and transformer-based time series predictors (Autoformer) shows that the
GLinear, despite being data efficient, outperforms the existing architectures
in most cases of multivariate TSF while being competitive in others. We hope
that the proposed GLinear model opens new fronts of research and development of
simpler and more sophisticated architectures for data and computationally
efficient time-series analysis. The source code is publicly available on
GitHub.

</details>


### [210] [Compressive Modeling and Visualization of Multivariate Scientific Data using Implicit Neural Representation](https://arxiv.org/abs/2510.15535)
*Abhay Kumar Dwivedi,Shanu Saklani,Soumya Dutta*

Main category: cs.LG

TL;DR: 使用单一网络和参数共享技术，为包含数十至数百个变量的多变量数据集学习压缩神经表示，实现了最先进的数据压缩、高质量的数据重建、渲染和可视化，并有效保留了变量间的依赖信息，同时提高了存储效率。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在科学可视化任务中的应用日益广泛，特别是利用隐式神经表示构建压缩数据模型在时空体积可视化和超分辨率等任务中取得了显著成效。受到这些成功的启发，本文旨在为包含大量变量的多变量数据集开发压缩神经表示。

Method: 利用单一神经网络同时学习所有数据变量的表示，并通过参数共享实现。

Result: 实现了最先进的数据压缩，在重建数据质量、渲染和可视化质量、变量间依赖信息保留和存储效率方面均表现出优越性能。

Conclusion: 所提出的压缩神经表示方法能够有效地处理包含大量变量的多变量数据集，并在多个关键性能指标上超越现有技术。

Abstract: The extensive adoption of Deep Neural Networks has led to their increased
utilization in challenging scientific visualization tasks. Recent advancements
in building compressed data models using implicit neural representations have
shown promising results for tasks like spatiotemporal volume visualization and
super-resolution. Inspired by these successes, we develop compressed neural
representations for multivariate datasets containing tens to hundreds of
variables. Our approach utilizes a single network to learn representations for
all data variables simultaneously through parameter sharing. This allows us to
achieve state-of-the-art data compression. Through comprehensive evaluations,
we demonstrate superior performance in terms of reconstructed data quality,
rendering and visualization quality, preservation of dependency information
among variables, and storage efficiency.

</details>


### [211] [Online Correlation Clustering: Simultaneously Optimizing All $\ell_p$-norms](https://arxiv.org/abs/2510.15076)
*Sami Davies,Benjamin Moseley,Heather Newman*

Main category: cs.LG

TL;DR: 本论文提出了一个在线算法，能够同时近似$\\ell_p$-范数、$\\ell_\infty$-范数和$\\ell_1$-范数的相关聚类问题，并在AOS模型下实现了有保证的近似比。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是探索在在线设置中实现离线设置中已有的$\\ell_p$-范数目标（包括$\\ell_1$和$\\ell_\infty$范数）的同时近似保证。此外，研究还受到标准随机顺序（RO）在线模型中$\\ell_1$和$\\ell_\infty$范数之间基本分离的新硬度结果的启发。

Method: 本文提出了一个在线算法（AOS模型），该算法使用一小部分输入作为样本，能够同时实现所有$\\ell_p$-范数（具有高概率的$\\text{O}(\\log^4 n)$竞争比）、$\\ell_\infty$-范数（具有高概率的$\\text{O}(\\log n)$竞争比）和$\\ell_1$-范数（期望为$\\text{O}(1)$竞争比）的近似。

Result: 在AOS模型下，提出的算法实现了对所有$\\ell_p$-范数$\\text{O}(\\log^4 n)$的近似（高概率），对$\\ell_\infty$-范数$\\text{O}(\\log n)$的近似（高概率），以及对$\\ell_1$-范数$\\text{O}(1)$的近似（期望）。此外，还证明了在RO模型中，$\\ell_\infty$-范数至少需要$\\Omega(n^{1/3})$的竞争比，并且在AOS模型中，$\\ell_1$和$\\ell_\infty$范数的竞争比接近理论下界。

Conclusion: 本论文成功地将离线的“全范数”保证转化到了在线世界，并为AOS模型提供了接近最优的算法和下界。研究结果强调了在标准RO模型之外采用其他模型（如AOS）的必要性，以处理公平性问题。

Abstract: The $\ell_p$-norm objectives for correlation clustering present a fundamental
trade-off between minimizing total disagreements (the $\ell_1$-norm) and
ensuring fairness to individual nodes (the $\ell_\infty$-norm). Surprisingly,
in the offline setting it is possible to simultaneously approximate all
$\ell_p$-norms with a single clustering. Can this powerful guarantee be
achieved in an online setting? This paper provides the first affirmative
answer. We present a single algorithm for the online-with-a-sample (AOS) model
that, given a small constant fraction of the input as a sample, produces one
clustering that is simultaneously $O(\log^4 n)$-competitive for all
$\ell_p$-norms with high probability, $O(\log n)$-competitive for the
$\ell_\infty$-norm with high probability, and $O(1)$-competitive for the
$\ell_1$-norm in expectation. This work successfully translates the offline
"all-norms" guarantee to the online world.
  Our setting is motivated by a new hardness result that demonstrates a
fundamental separation between these objectives in the standard random-order
(RO) online model. Namely, while the $\ell_1$-norm is trivially
$O(1)$-approximable in the RO model, we prove that any algorithm in the RO
model for the fairness-promoting $\ell_\infty$-norm must have a competitive
ratio of at least $\Omega(n^{1/3})$. This highlights the necessity of a
different beyond-worst-case model. We complement our algorithm with lower
bounds, showing our competitive ratios for the $\ell_1$- and $\ell_\infty$-
norms are nearly tight in the AOS model.

</details>


### [212] [ES-C51: Expected Sarsa Based C51 Distributional Reinforcement Learning Algorithm](https://arxiv.org/abs/2510.15006)
*Rijul Tandon,Peter Vamplew,Cameron Foale*

Main category: cs.LG

TL;DR: ES-C51使用Expected Sarsa更新替代C51的贪婪Q学习更新，以提高分布学习的稳定性和性能。


<details>
  <summary>Details</summary>
Motivation: C51算法在处理具有相似期望回报但不同回报分布的动作时可能存在不稳定的问题。

Method: 提出了一种名为ES-C51的C51变体，用Expected Sarsa更新替代贪婪Q学习更新，并使用softmax结合所有动作的信息。为了公平比较，将C51的探索策略从e-greedy改为softmax，称为QL-C51。

Result: 在Gym经典控制环境和Atari-10游戏中，ES-C51的表现优于QL-C51。

Conclusion: ES-C51通过采用Expected Sarsa更新，解决了C51在某些情况下的学习不稳定性问题，并在多项评估环境中取得了更好的性能。

Abstract: In most value-based reinforcement learning (RL) algorithms, the agent
estimates only the expected reward for each action and selects the action with
the highest reward. In contrast, Distributional Reinforcement Learning (DRL)
estimates the entire probability distribution of possible rewards, providing
richer information about uncertainty and variability. C51 is a popular DRL
algorithm for discrete action spaces. It uses a Q-learning approach, where the
distribution is learned using a greedy Bellman update. However, this can cause
problems if multiple actions at a state have similar expected reward but with
different distributions, as the algorithm may not learn a stable distribution.
This study presents a modified version of C51 (ES-C51) that replaces the greedy
Q-learning update with an Expected Sarsa update, which uses a softmax
calculation to combine information from all possible actions at a state rather
than relying on a single best action. This reduces instability when actions
have similar expected rewards and allows the agent to learn higher-performing
policies. This approach is evaluated on classic control environments from Gym,
and Atari-10 games. For a fair comparison, we modify the standard C51's
exploration strategy from e-greedy to softmax, which we refer to as QL-C51 (Q-
Learning based C51). The results demonstrate that ES-C51 outperforms QL-C51
across many environments.

</details>


### [213] [Poultry Farm Intelligence: An Integrated Multi-Sensor AI Platform for Enhanced Welfare and Productivity](https://arxiv.org/abs/2510.15757)
*Pieris Panagi,Savvas Karatsiolis,Kyriacos Mosphilis,Nicholas Hadjisavvas,Andreas Kamilaris,Nicolas Nicolaou,Efstathios Stavrakis,Vassilis Vassiliades*

Main category: cs.LG

TL;DR: PoultryFI是一个集成了六个AI模块的低成本、模块化平台，用于优化家禽养殖场的生产力和动物福利。


<details>
  <summary>Details</summary>
Motivation: 小型和中型农场缺乏负担得起的、用于持续监控和决策制定的集成工具，因此依赖于手动、被动的检查。

Method: 该平台包括一个优化摄像头布局的模块、一个从同步视频、音频和饲喂数据中提取福利指标的模块、一个生成每日摘要和实时通知的模块、一个自动跟踪生产的模块、一个预测产蛋量和饲喂消耗的模块，以及一个提供建议的模块。

Result: 在Raspberry Pi 5上实现了100%的产蛋量计数准确性、稳健的异常检测和可靠的短期预测。

Conclusion: PoultryFI通过集成低成本传感、边缘分析和规范性AI，实现了对养殖场的持续监控、生产预测和性能优化，弥合了孤立工具与可扩展的农场级智能之间的差距，使生产者能够主动保障动物福利和盈利能力。

Abstract: Poultry farming faces increasing pressure to meet productivity targets while
ensuring animal welfare and environmental compliance. Yet many small and
medium-sized farms lack affordable, integrated tools for continuous monitoring
and decision-making, relying instead on manual, reactive inspections. This
paper presents Poultry Farm Intelligence (PoultryFI) - a modular,
cost-effective platform that integrates six AI-powered modules: Camera
Placement Optimizer, Audio-Visual Monitoring, Analytics & Alerting, Real-Time
Egg Counting, Production & Profitability Forecasting, and a Recommendation
Module.
  Camera layouts are first optimized offline using evolutionary algorithms for
full poultry house coverage with minimal hardware. The Audio-Visual Monitoring
module extracts welfare indicators from synchronized video, audio, and feeding
data. Analytics & Alerting produces daily summaries and real-time
notifications, while Real-Time Egg Counting uses an edge vision model to
automate production tracking. Forecasting models predict egg yield and feed
consumption up to 10 days in advance, and the Recommendation Module integrates
forecasts with weather data to guide environmental and operational adjustments.
  This is among the first systems to combine low-cost sensing, edge analytics,
and prescriptive AI to continuously monitor flocks, predict production, and
optimize performance. Field trials demonstrate 100% egg-count accuracy on
Raspberry Pi 5, robust anomaly detection, and reliable short-term forecasting.
PoultryFI bridges the gap between isolated pilot tools and scalable, farm-wide
intelligence, empowering producers to proactively safeguard welfare and
profitability.

</details>


### [214] [Deep Neural ODE Operator Networks for PDEs](https://arxiv.org/abs/2510.15651)
*Ziqian Li,Kang Liu,Yongcun Song,Hangrui Yue,Enrique Zuazua*

Main category: cs.LG

TL;DR: 该论文提出了一种名为NODE-ONet的深度神经常微分方程（ODE）算子网络框架，以解决现有算子学习方法在处理偏微分方程（PDE）时忽略领域知识、难以捕捉时间动态和泛化能力不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有算子学习方法在处理PDE时，往往忽略了PDE本身的领域知识，导致在捕捉时间动态和泛化到训练时间范围之外时遇到困难。

Method: 该框架采用了一种包含三个核心组件的编码器-解码器架构：1. 编码器：对输入函数进行空间离散化。2. 神经ODE：捕捉潜在的时间动态。3. 解码器：在物理空间中重建解。此外，论文还研究了编码器-解码器架构的误差分析，并提出了物理信息编码的神经ODE，将PDE特定的物理性质融入模型，以降低复杂性并提高效率、鲁棒性、适用性和泛化能力。

Result: 在非线性扩散-反应方程和Navier-Stokes方程上的数值实验表明，该框架具有高精度、计算效率高，并且能够进行训练时间范围之外的预测。

Conclusion: NODE-ONet框架通过结合编码器-解码器架构和物理信息编码的神经ODE，有效解决了现有算子学习方法的局限性，在处理PDE方面表现出高精度、高效率和良好的泛化能力，是一种有潜力的可扩展的、物理信息编码的科学机器学习工具。

Abstract: Operator learning has emerged as a promising paradigm for developing
efficient surrogate models to solve partial differential equations (PDEs).
However, existing approaches often overlook the domain knowledge inherent in
the underlying PDEs and hence suffer from challenges in capturing temporal
dynamics and generalization issues beyond training time frames. This paper
introduces a deep neural ordinary differential equation (ODE) operator network
framework, termed NODE-ONet, to alleviate these limitations. The framework
adopts an encoder-decoder architecture comprising three core components: an
encoder that spatially discretizes input functions, a neural ODE capturing
latent temporal dynamics, and a decoder reconstructing solutions in physical
spaces. Theoretically, error analysis for the encoder-decoder architecture is
investigated. Computationally, we propose novel physics-encoded neural ODEs to
incorporate PDE-specific physical properties. Such well-designed neural ODEs
significantly reduce the framework's complexity while enhancing numerical
efficiency, robustness, applicability, and generalization capacity. Numerical
experiments on nonlinear diffusion-reaction and Navier-Stokes equations
demonstrate high accuracy, computational efficiency, and prediction
capabilities beyond training time frames. Additionally, the framework's
flexibility to accommodate diverse encoders/decoders and its ability to
generalize across related PDE families further underscore its potential as a
scalable, physics-encoded tool for scientific machine learning.

</details>


### [215] [Hybrid Autoencoder-Based Framework for Early Fault Detection in Wind Turbines](https://arxiv.org/abs/2510.15010)
*Rekha R Nair,Tina Babu,Alavikunhu Panthakkan,Balamurugan Balusamy,Wathiq Mansoor*

Main category: cs.LG

TL;DR: 该研究提出了一种基于集成深度学习框架的无监督风力涡轮机异常检测新方法，可提前检测故障。


<details>
  <summary>Details</summary>
Motivation: 风力涡轮机在可再生能源领域至关重要，早期故障检测可显著降低停机时间和维护成本。

Method: 该方法集成了变分自编码器（VAE）、LSTM自编码器和Transformer架构，并通过特征工程提取时间、统计和频域指标，最后结合集成评分和自适应阈值进行异常检测。

Result: 在CARE数据集上，该方法实现了0.947的AUC-ROC，可提前48小时检测到故障。

Conclusion: 该方法通过实现预测性维护，减少涡轮机故障并提高大规模风能部署的运行效率，具有显著的社会价值。

Abstract: Wind turbine reliability is critical to the growing renewable energy sector,
where early fault detection significantly reduces downtime and maintenance
costs. This paper introduces a novel ensemble-based deep learning framework for
unsupervised anomaly detection in wind turbines. The method integrates
Variational Autoencoders (VAE), LSTM Autoencoders, and Transformer
architectures, each capturing different temporal and contextual patterns from
high-dimensional SCADA data. A unique feature engineering pipeline extracts
temporal, statistical, and frequency-domain indicators, which are then
processed by the deep models. Ensemble scoring combines model predictions,
followed by adaptive thresholding to detect operational anomalies without
requiring labeled fault data. Evaluated on the CARE dataset containing 89 years
of real-world turbine data across three wind farms, the proposed method
achieves an AUC-ROC of 0.947 and early fault detection up to 48 hours prior to
failure. This approach offers significant societal value by enabling predictive
maintenance, reducing turbine failures, and enhancing operational efficiency in
large-scale wind energy deployments.

</details>


### [216] [AlignFlow: Improving Flow-based Generative Models with Semi-Discrete Optimal Transport](https://arxiv.org/abs/2510.15038)
*Lingkai Kong,Molei Tao,Yang Liu,Bryan Wang,Jinmiao Fu,Chien-Chih Wang,Huidong Liu*

Main category: cs.LG

TL;DR: AlignFlow是一种利用半离散最优输运（SDOT）来改进基于流的生成模型（FGM）训练的新方法，通过在噪声分布和数据点之间建立显式、最优的对齐，解决了现有基于OT的方法在处理大规模、高维数据集时的扩展性问题，并实现了可保证的收敛性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于最优输运（OT）的方法在训练基于流的生成模型（FGM）时，由于使用（mini-）批次采样的噪声和数据点来估计OT计划，限制了它们在处理大规模、高维数据集时的扩展性。

Method: AlignFlow利用半离散最优输运（SDOT）来增强FGM的训练。它通过将噪声空间划分为多个Laguerre单元，并将每个单元映射到一个相应的数据点，从而建立噪声分布和数据点之间的显式、最优的对齐。在FGM训练过程中，通过SDOT映射将独立同分布的噪声样本与数据点配对。

Result: AlignFlow在扩展性方面表现良好，可以处理大规模数据集和复杂的模型架构，并且计算开销可忽略不计。实验结果表明，AlignFlow能够提高多种最先进的FGM算法的性能，并且可以作为一个即插即用的组件进行集成。

Conclusion: AlignFlow通过引入SDOT，为FGM的训练提供了一种可扩展且高效的解决方案，通过显式地对齐噪声和数据分布，提高了模型的性能和收敛性。

Abstract: Flow-based Generative Models (FGMs) effectively transform noise into complex
data distributions. Incorporating Optimal Transport (OT) to couple noise and
data during FGM training has been shown to improve the straightness of flow
trajectories, enabling more effective inference. However, existing OT-based
methods estimate the OT plan using (mini-)batches of sampled noise and data
points, which limits their scalability to large and high-dimensional datasets
in FGMs. This paper introduces AlignFlow, a novel approach that leverages
Semi-Discrete Optimal Transport (SDOT) to enhance the training of FGMs by
establishing an explicit, optimal alignment between noise distribution and data
points with guaranteed convergence. SDOT computes a transport map by
partitioning the noise space into Laguerre cells, each mapped to a
corresponding data point. During FGM training, i.i.d. noise samples are paired
with data points via the SDOT map. AlignFlow scales well to large datasets and
model architectures with negligible computational overhead. Experimental
results show that AlignFlow improves the performance of a wide range of
state-of-the-art FGM algorithms and can be integrated as a plug-and-play
component. Code is available at: https://github.com/konglk1203/AlignFlow.

</details>


### [217] [IQNN-CS: Interpretable Quantum Neural Network for Credit Scoring](https://arxiv.org/abs/2510.15044)
*Abdul Samad Khan,Nouhaila Innan,Aeysha Khalique,Muhammad Shafique*

Main category: cs.LG

TL;DR: IQNN-CS是一个可解释的量子神经网络框架，用于多类信用风险分类，结合了变分QNN和事后解释技术，并引入了ICAA指标来量化模型区分信用风险类别的能力。


<details>
  <summary>Details</summary>
Motivation: 量子机器学习（QML）的黑箱性质在需要透明度和信任的领域（如金融服务中的信用评分）带来了挑战。因此，需要开发可解释的QML模型。

Method: 提出IQNN-CS框架，该框架结合了变分QNN和事后解释技术。引入了一种名为Inter-Class Attribution Alignment（ICAA）的新指标，用于量化跨预测类别的归因差异，以提高QML的可解释性。

Result: 在两个真实的信用数据集上评估IQNN-CS，结果显示其具有稳定的训练动态、有竞争力的预测性能和增强的可解释性。

Conclusion: IQNN-CS为在金融决策中实现透明且负责任的QML模型提供了一条实用的途径。

Abstract: Credit scoring is a high-stakes task in financial services, where model
decisions directly impact individuals' access to credit and are subject to
strict regulatory scrutiny. While Quantum Machine Learning (QML) offers new
computational capabilities, its black-box nature poses challenges for adoption
in domains that demand transparency and trust. In this work, we present
IQNN-CS, an interpretable quantum neural network framework designed for
multiclass credit risk classification. The architecture combines a variational
QNN with a suite of post-hoc explanation techniques tailored for structured
data. To address the lack of structured interpretability in QML, we introduce
Inter-Class Attribution Alignment (ICAA), a novel metric that quantifies
attribution divergence across predicted classes, revealing how the model
distinguishes between credit risk categories. Evaluated on two real-world
credit datasets, IQNN-CS demonstrates stable training dynamics, competitive
predictive performance, and enhanced interpretability. Our results highlight a
practical path toward transparent and accountable QML models for financial
decision-making.

</details>


### [218] [Internalizing World Models via Self-Play Finetuning for Agentic RL](https://arxiv.org/abs/2510.15047)
*Shiqi Chen,Tongyao Zhu,Zian Wang,Jinghan Zhang,Kangrui Wang,Siyang Gao,Teng Xiao,Yee Whye Teh,Junxian He,Manling Li*

Main category: cs.LG

TL;DR: LLM代理在处理现实世界中复杂多变的分布外（OOD）场景时面临挑战。本文提出的SPA框架通过引入世界模型，改进了LLM代理的决策能力，显著提升了其在Sokoban、FrozenLake和Sudoku等环境下的表现。


<details>
  <summary>Details</summary>
Motivation: LLM代理在分布外（OOD）场景下表现不佳，传统强化学习训练方法难以应对现实世界环境的复杂性和动态性，导致模型泛化能力有限。

Method: SPA框架结合了世界模型（状态表示和转移建模）和强化学习。首先，通过自玩监督微调（SFT）阶段对策略进行冷启动，让模型学习世界模型。然后，利用世界模型在策略优化前模拟未来状态。

Result: SPA框架在Sokoban、FrozenLake和Sudoku等多个环境中显著提升了LLM代理的性能。例如，在Sokoban中，SPA将成功率从25.6%提高到59.8%；在FrozenLake中，将分数从22.1%提高到70.9%（使用Qwen2.5-1.5B-Instruct模型）。

Conclusion: SPA框架通过引入世界模型，能够更好地使LLM代理的推理与环境动态保持一致，从而有效提升其在分布外场景下的决策能力和泛化性能。

Abstract: Large Language Models (LLMs) as agents often struggle in out-of-distribution
(OOD) scenarios. Real-world environments are complex and dynamic, governed by
task-specific rules and stochasticity, which makes it difficult for LLMs to
ground their internal knowledge in those dynamics. Under such OOD conditions,
vanilla RL training often fails to scale; we observe Pass@k--the probability
that at least one of (k) sampled trajectories succeeds--drops markedly across
training steps, indicating brittle exploration and limited generalization.
Inspired by model-based reinforcement learning, we hypothesize that equipping
LLM agents with an internal world model can better align reasoning with
environmental dynamics and improve decision-making. We show how to encode this
world model by decomposing it into two components: state representation and
transition modeling. Building on this, we introduce SPA, a simple reinforcement
learning framework that cold-starts the policy via a Self-Play supervised
finetuning (SFT) stage to learn the world model by interacting with the
environment, then uses it to simulate future states prior to policy
optimization. This simple initialization outperforms the online world-modeling
baseline and greatly boosts the RL-based agent training performance.
Experiments across diverse environments like Sokoban, FrozenLake, and Sudoku
show that our approach significantly improves performance. For example, SPA
boosts the Sokoban success rate from 25.6% to 59.8% and raises the FrozenLake
score from 22.1% to 70.9% for the Qwen2.5-1.5B-Instruct model.

</details>


### [219] [Learn to Change the World: Multi-level Reinforcement Learning with Model-Changing Actions](https://arxiv.org/abs/2510.15056)
*Ziqing Lu,Babak Hassibi,Lifeng Lai,Weiyu Xu*

Main category: cs.LG

TL;DR: 代理可以通过模型改变动作来修改环境，并在多层可配置的随时间变化的马尔可夫决策过程中优化配置策略和原始动作策略。


<details>
  <summary>Details</summary>
Motivation: 大多数强化学习代理被限制在被动适应环境中，而本文考虑的代理可以主动修改环境的模型。

Method: 提出多层可配置的随时间变化的马尔可夫决策过程（MCTVMDP），其中较低级别的MDP具有可通过上层模型改变动作配置的非平稳转换函数。

Result: 代理的目标包括优化上层MDP中的配置策略和优化较低层MDP中的原始动作策略，以联合提高预期的长期奖励。

Conclusion: 与传统的强化学习不同，MCTVMDP允许代理通过模型改变动作来主动重塑环境，从而可能获得更高的奖励。

Abstract: Reinforcement learning usually assumes a given or sometimes even fixed
environment in which an agent seeks an optimal policy to maximize its long-term
discounted reward. In contrast, we consider agents that are not limited to
passive adaptations: they instead have model-changing actions that actively
modify the RL model of world dynamics itself. Reconfiguring the underlying
transition processes can potentially increase the agents' rewards. Motivated by
this setting, we introduce the multi-layer configurable time-varying Markov
decision process (MCTVMDP). In an MCTVMDP, the lower-level MDP has a
non-stationary transition function that is configurable through upper-level
model-changing actions. The agent's objective consists of two parts: Optimize
the configuration policies in the upper-level MDP and optimize the primitive
action policies in the lower-level MDP to jointly improve its expected
long-term reward.

</details>


### [220] [Antislop: A Comprehensive Framework for Identifying and Eliminating Repetitive Patterns in Language Models](https://arxiv.org/abs/2510.15061)
*Samuel Paech,Allen Roush,Judah Goldfeder,Ravid Shwartz-Ziv*

Main category: cs.LG

TL;DR: Antislop框架通过反向跟踪采样器、自动化的模型倾斜分析和最终标记偏好优化（FTPO）来检测和消除大型语言模型（LLM）输出中的重复短语（“slop”），在保持或提高性能的同时，将slop减少了90%。


<details>
  <summary>Details</summary>
Motivation: 解决广泛采用LLM所带来的输出质量下降和AI生成文本可识别性的问题，这种问题由特征性的重复短语“slop”引起。

Method: 提出Antislop框架，结合了三种创新：1. Antislop Sampler：在推理时使用反向跟踪来抑制不需要的字符串，同时不破坏词汇。2. 自动化流水线：针对模型特定的slop与人类基线进行分析，并生成训练数据。3. 最终标记偏好优化（FTPO）：一种新颖的微调方法，对单个标记进行操作，在禁止的模式出现在推理轨迹中的地方，进行精确的logits调整。

Result: 某些slop模式在LLM输出中出现的频率是人类文本的1000倍以上。Antislop Sampler成功抑制了8000多个模式，同时保持了质量，而标记禁止在仅2000个模式时就变得不可用。FTPO在跨领域评估（包括GSM8K、MMLU和创意写作任务）中实现了90%的slop减少，同时保持或提高了性能。相比之下，DPO在实现较弱的抑制的同时，写作质量和词汇多样性明显下降。

Conclusion: Antislop框架，特别是FTPO方法，在有效减少LLM输出中的slop方面非常成功，同时保持了模型的性能和输出质量，优于其他方法如DPO。

Abstract: Widespread LLM adoption has introduced characteristic repetitive phraseology,
termed ``slop,'' which degrades output quality and makes AI-generated text
immediately recognizable. We present Antislop, a comprehensive framework
providing tools to both detect and eliminate these overused patterns. Our
approach combines three innovations: (1) The Antislop Sampler, which uses
backtracking to suppress unwanted strings at inference time without destroying
vocabulary; (2) An automated pipeline that profiles model-specific slop against
human baselines and generates training data; (3) Final Token Preference
Optimization (FTPO), a novel fine-tuning method that operates on individual
tokens, surgically adjusting logits wherever a banned pattern has appeared in
an inference trace. We demonstrate that some slop patterns appear over
1,000$\times$ more frequently in LLM output than human text. The Antislop
Sampler successfully suppresses 8,000+ patterns while maintaining quality,
whereas token banning becomes unusable at just 2,000. Most importantly, FTPO
achieves 90\% slop reduction while maintaining or improving performance in
cross-domain evals including GSM8K, MMLU, and creative writing tasks. In
contrast, DPO suffers significant degradation in writing quality and lexical
diversity despite achieving weaker suppression. We release all code and results
under MIT license: https://github.com/sam-paech/auto-antislop.

</details>


### [221] [Physics-informed data-driven machine health monitoring for two-photon lithography](https://arxiv.org/abs/2510.15075)
*Sixian Jia,Zhiqiao Dong,Chenhui Shao*

Main category: cs.LG

TL;DR: 本研究提出三种预测性维护方法，用于监测二维光刻（TPL）系统的健康状况，以提高制造质量和效率。


<details>
  <summary>Details</summary>
Motivation: 当前的TPL系统维护依赖于经验，可能导致维护不及时或不必要，从而造成停机和效率低下。

Method: 通过整合了物理信息和数据驱动的预测模型（用于结构尺寸）以及统计方法，开发了三种TPL系统健康监测方法。

Result: 所提出的方法在包含六个工艺参数组合和六个结构尺寸的实验数据上进行了评估，在两种不同的机器健康状况下，证明了其高准确性、鲁棒性和泛化能力。

Conclusion: 这些方法是实现TPL系统基于状况的预测性维护的重要一步。

Abstract: Two-photon lithography (TPL) is a sophisticated additive manufacturing
technology for creating three-dimensional (3D) micro- and nano-structures.
Maintaining the health of TPL systems is critical for ensuring consistent
fabrication quality. Current maintenance practices often rely on experience
rather than informed monitoring of machine health, resulting in either untimely
maintenance that causes machine downtime and poor-quality fabrication, or
unnecessary maintenance that leads to inefficiencies and avoidable downtime. To
address this gap, this paper presents three methods for accurate and timely
monitoring of TPL machine health. Through integrating physics-informed
data-driven predictive models for structure dimensions with statistical
approaches, the proposed methods are able to handle increasingly complex
scenarios featuring different levels of generalizability. A comprehensive
experimental dataset that encompasses six process parameter combinations and
six structure dimensions under two machine health conditions was collected to
evaluate the effectiveness of the proposed approaches. Across all test
scenarios, the approaches are shown to achieve high accuracies, demonstrating
excellent effectiveness, robustness, and generalizability. These results
represent a significant step toward condition-based maintenance for TPL
systems.

</details>


### [222] [Operator Flow Matching for Timeseries Forecasting](https://arxiv.org/abs/2510.15101)
*Yolanne Yi Ran Lee,Kyriakos Flouris*

Main category: cs.LG

TL;DR: TempO是一个利用稀疏条件和通道折叠的潜在流匹配模型，用于高效处理3D时空场，并在多个PDE数据集上取得了优于最先进方法的性能。


<details>
  <summary>Details</summary>
Motivation: 预测高维、受偏微分方程控制的动力学是生成模型的核心挑战。现有的自回归和基于扩散的方法经常出现累积误差和离散化伪影，限制了长期、物理上一致的预测。

Method: TempO利用时间条件傅立叶层来处理3D时空场，通过稀疏条件和通道折叠来捕获多尺度模式，并证明了傅立叶神经算子（FNO）的近似误差上界。

Result: TempO在三个基准PDE数据集上超越了现有最先进的方法，其性能优于基于注意力和卷积的方法，并且在多尺度动力学恢复方面表现出色。

Conclusion: TempO在处理高维、受偏微分方程控制的动力学方面是一种高效且准确的模型，具有参数和内存占用小的优点。

Abstract: Forecasting high-dimensional, PDE-governed dynamics remains a core challenge
for generative modeling. Existing autoregressive and diffusion-based approaches
often suffer cumulative errors and discretisation artifacts that limit long,
physically consistent forecasts. Flow matching offers a natural alternative,
enabling efficient, deterministic sampling. We prove an upper bound on FNO
approximation error and propose TempO, a latent flow matching model leveraging
sparse conditioning with channel folding to efficiently process 3D
spatiotemporal fields using time-conditioned Fourier layers to capture
multi-scale modes with high fidelity. TempO outperforms state-of-the-art
baselines across three benchmark PDE datasets, and spectral analysis further
demonstrates superior recovery of multi-scale dynamics, while efficiency
studies highlight its parameter- and memory-light design compared to
attention-based or convolutional regressors.

</details>


### [223] [DLER: Doing Length pEnalty Right - Incentivizing More Intelligence per Token via Reinforcement Learning](https://arxiv.org/abs/2510.15110)
*Shih-Yang Liu,Xin Dong,Ximing Lu,Shizhe Diao,Mingjie Liu,Min-Hung Chen,Hongxu Yin,Yu-Chiang Frank Wang,Kwang-Ting Cheng,Yejin Choi,Jan Kautz,Pavlo Molchanov*

Main category: cs.LG

TL;DR: 通过引入DLER训练方法，可以显著减少大型语言模型的输出长度，同时保持甚至提高其准确性，并在推理时提供更快的速度。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（如OpenAI-o1, DeepSeek-R1, Qwen）虽然在生成长链式思考方面表现出色，但输出冗长。本研究旨在解决“每token最大化智能”（即准确性与响应长度比率）这一开放性问题。

Method: 提出了一种名为“Doing Length pEnalty Right”（DLER）的训练方法，该方法结合了批量奖励归一化、更高范围的剪辑、动态采样和简单的截断长度惩罚，以解决强化学习（RL）优化中的三个关键挑战：优势估计中的大偏差、熵崩溃和稀疏奖励信号。此外，还引入了难度感知DLER（Difficulty-Aware DLER）和一种选择性更新合并方法。

Result: DLER在准确性-效率权衡方面达到了最先进水平，输出长度减少超过70%，同时准确性超越了所有先前基线。DLER-7B相比DeepSeek-R1-7B，在生成多个简洁响应时，准确性提高了28%，延迟更低。难度感知DLER进一步提高了效率。选择性更新合并方法在RL训练数据有限的情况下，能够保留基线准确性并获得简洁推理能力。

Conclusion: DLER训练方法能够有效地在保持甚至提高模型准确性的同时，大幅缩短大型语言模型的输出长度，并在推理时实现更高的效率和更低的延迟。

Abstract: Reasoning language models such as OpenAI-o1, DeepSeek-R1, and Qwen achieve
strong performance via extended chains of thought but often generate
unnecessarily long outputs. Maximizing intelligence per token--accuracy
relative to response length--remains an open problem. We revisit reinforcement
learning (RL) with the simplest length penalty--truncation--and show that
accuracy degradation arises not from the lack of sophisticated penalties but
from inadequate RL optimization. We identify three key challenges: (i) large
bias in advantage estimation, (ii) entropy collapse, and (iii) sparse reward
signal. We address them with Doing Length pEnalty Right (DLER), a training
recipe combining batch-wise reward normalization, higher clipping, dynamic
sampling, and a simple truncation length penalty. DLER achieves
state-of-the-art accuracy--efficiency trade-offs, cutting output length by over
70 percent while surpassing all previous baseline accuracy. It also improves
test-time scaling: compared to DeepSeek-R1-7B, DLER-7B generates multiple
concise responses in parallel with 28 percent higher accuracy and lower
latency. We further introduce Difficulty-Aware DLER, which adaptively tightens
truncation on easier questions for additional efficiency gains. We also propose
an update-selective merging method that preserves baseline accuracy while
retaining the concise reasoning ability of the DLER model, which is useful for
scenarios where RL training data is scarce.

</details>


### [224] [Navigating the consequences of mechanical ventilation in clinical intensive care settings through an evolutionary game-theoretic framework](https://arxiv.org/abs/2510.15127)
*David J. Albers,Tell D. Bennett,Jana de Wiljes,Bradford J. Smith,Peter D. Sottile,J. N. Stroh*

Main category: cs.LG

TL;DR: 本研究提出一个框架，利用演化博弈论分析重症监护患者的呼吸模式，以优化机械通气策略。


<details>
  <summary>Details</summary>
Motivation: 为了理解机械通气策略对危重症患者的影响，需要分析不同患者-呼吸机系统中的数据，并结合临床决策环境。

Method: 该研究开发了一个联合患者-呼吸机-护理系统（J6）的视角，并使用演化博弈论（EGT）分析呼吸行为，为更深层次的分析提供量化依据，并结合强化学习等方法。

Result: 该方法在合成数据上进行了分析验证，并应用于真实ICU数据，揭示了数据生成过程的复杂性。

Conclusion: 该研究是实现机械通气优化和个性化的一步，并提出了一个状态转移模型，用于模拟机械通气决策的影响。

Abstract: Identifying the effects of mechanical ventilation strategies and protocols in
critical care requires analyzing data from heterogeneous patient-ventilator
systems within the context of the clinical decision-making environment. This
research develops a framework to help understand the consequences of mechanical
ventilation (MV) and adjunct care decisions on patient outcome from
observations of critical care patients receiving MV. Developing an
understanding of and improving critical care respiratory management requires
the analysis of existing secondary-use clinical data to generate hypotheses
about advantageous variations and adaptations of current care. This work
introduces a perspective of the joint patient-ventilator-care systems
(so-called J6) to develop a scalable method for analyzing data and trajectories
of these complex systems. To that end, breath behaviors are analyzed using
evolutionary game theory (EGT), which generates the necessary quantitative
precursors for deeper analysis through probabilistic and stochastic machinery
such as reinforcement learning. This result is one step along the pathway
toward MV optimization and personalization. The EGT-based process is
analytically validated on synthetic data to reveal potential caveats before
proceeding to real-world ICU data applications that expose complexities of the
data-generating process J6. The discussion includes potential developments
toward a state transition model for the simulating effects of MV decision using
empirical and game-theoretic elements.

</details>


### [225] [A Simple Method for PMF Estimation on Large Supports](https://arxiv.org/abs/2510.15132)
*Alex Shtoff*

Main category: cs.LG

TL;DR: 该研究提出了一种基于图拉普拉斯算子和低通滤波的非参数概率质量函数（PMF）估计方法，适用于多峰且长尾分布的大离散支撑集。


<details>
  <summary>Details</summary>
Motivation: 处理具有多峰和长尾特性的概率质量函数（PMF）的非参数估计问题，特别是在支持集很大的情况下。

Method: 将经验PMF视为线图上的信号，应用数据依赖的低通滤波器。具体来说，构建了一个经验PMF的对角矩阵扰动的路径图拉普拉斯算子，然后计算最小特征值的特征向量，并将经验PMF投影到由这些特征向量张成的低维子空间上，最后进行裁剪和重新归一化处理。

Result: 该方法能够生成平滑、多峰的PMF估计，有效保留数据的粗糙结构并抑制噪声。与logspline和高斯核密度估计（KDE）等基线方法相比，在预期场景下表现更优，并且计算效率高、鲁棒性强，适用于大规模自动化分析。

Conclusion: 该方法是一种快速、可靠且易于实现的PMF估计技术，特别适用于多峰长尾数据，但在处理具有明显不连续性的数据时存在已知缺陷。

Abstract: We study nonparametric estimation of a probability mass function (PMF) on a
large discrete support, where the PMF is multi-modal and heavy-tailed. The core
idea is to treat the empirical PMF as a signal on a line graph and apply a
data-dependent low-pass filter. Concretely, we form a symmetric tri-diagonal
operator, the path graph Laplacian perturbed with a diagonal matrix built from
the empirical PMF, then compute the eigenvectors, corresponding to the smallest
feq eigenvalues. Projecting the empirical PMF onto this low dimensional
subspace produces a smooth, multi-modal estimate that preserves coarse
structure while suppressing noise. A light post-processing step of clipping and
re-normalizing yields a valid PMF.
  Because we compute the eigenpairs of a symmetric tridiagonal matrix, the
computation is reliable and runs time and memory proportional to the support
times the dimension of the desired low-dimensional supspace. We also provide a
practical, data-driven rule for selecting the dimension based on an
orthogonal-series risk estimate, so the method "just works" with minimal
tuning. On synthetic and real heavy-tailed examples, the approach preserves
coarse structure while suppressing sampling noise, compares favorably to
logspline and Gaussian-KDE baselines in the intended regimes. However, it has
known failure modes (e.g., abrupt discontinuities). The method is short to
implement, robust across sample sizes, and suitable for automated pipelines and
exploratory analysis at scale because of its reliability and speed.

</details>


### [226] [Decentralized Parameter-Free Online Learning](https://arxiv.org/abs/2510.15644)
*Tomas Ortega,Hamid Jafarkhani*

Main category: cs.LG

TL;DR: 我们提出了第一个具有网络遗憾保证的无参数去中心化在线学习算法，该算法在无需超参数调整的情况下实现了次线性遗憾。


<details>
  <summary>Details</summary>
Motivation: 该论文的动机是开发具有网络遗憾保证的无参数去中心化在线学习算法，以在无需超参数调整的情况下实现次线性遗憾。

Method: 该论文提出了一种将多智能体硬币投注与去中心化在线学习通过 gossip 步骤联系起来的算法。它引入了一种新颖的“投注函数”表述来进行硬币投注，以简化多智能体遗憾分析。

Result: 该分析表明了次线性网络遗憾界限，并通过在合成和真实数据集上的实验得到了验证。

Conclusion: 该算法系列适用于分布式传感、去中心化优化和协作机器学习应用。

Abstract: We propose the first parameter-free decentralized online learning algorithms
with network regret guarantees, which achieve sublinear regret without
requiring hyperparameter tuning. This family of algorithms connects multi-agent
coin-betting and decentralized online learning via gossip steps. To enable our
decentralized analysis, we introduce a novel "betting function" formulation for
coin-betting that simplifies the multi-agent regret analysis. Our analysis
shows sublinear network regret bounds and is validated through experiments on
synthetic and real datasets. This family of algorithms is applicable to
distributed sensing, decentralized optimization, and collaborative ML
applications.

</details>


### [227] [Predicting the Unpredictable: Reproducible BiLSTM Forecasting of Incident Counts in the Global Terrorism Database (GTD)](https://arxiv.org/abs/2510.15136)
*Oluwasegun Adegoke*

Main category: cs.LG

TL;DR: 使用GTD数据，BiLSTM在短期恐袭数量预测方面优于LSTM-Attention和线性回归模型，表明长期数据训练和双向编码是关键。


<details>
  <summary>Details</summary>
Motivation: 利用GTD数据库（1970-2016）进行短期（每周）恐袭数量的预测，并与现有模型进行比较。

Method: 构建可复现的预测流程，使用时间分割，并评估双向长短期记忆网络（BiLSTM）与季节性朴素、ARIMA、线性回归以及LSTM-Attention等基线模型。

Result: BiLSTM在测试集上达到RMSE 6.38，优于LSTM-Attention（9.19）和线性回归基线（+35.4% RMSE提升），MAE和MAPE指标也有类似改善。消融实验表明，长期数据训练、适度的回看窗口（20-30周）以及双向编码对模型性能至关重要。短期结构特征（滞后计数和滚动统计）贡献最大，地理和伤亡特征有增量作用。

Conclusion: 该研究提供了一个透明且优于基线的GTD事件预测参考方法，BiLSTM模型通过利用长期历史数据和双向编码，在短期恐袭数量预测方面表现出色。

Abstract: We study short-horizon forecasting of weekly terrorism incident counts using
the Global Terrorism Database (GTD, 1970--2016). We build a reproducible
pipeline with fixed time-based splits and evaluate a Bidirectional LSTM
(BiLSTM) against strong classical anchors (seasonal-naive, linear/ARIMA) and a
deep LSTM-Attention baseline. On the held-out test set, the BiLSTM attains RMSE
6.38, outperforming LSTM-Attention (9.19; +30.6\%) and a linear lag-regression
baseline (+35.4\% RMSE gain), with parallel improvements in MAE and MAPE.
Ablations varying temporal memory, training-history length, spatial grain,
lookback size, and feature groups show that models trained on long historical
data generalize best; a moderate lookback (20--30 weeks) provides strong
context; and bidirectional encoding is critical for capturing both build-up and
aftermath patterns within the window. Feature-group analysis indicates that
short-horizon structure (lagged counts and rolling statistics) contributes
most, with geographic and casualty features adding incremental lift. We release
code, configs, and compact result tables, and provide a data/ethics statement
documenting GTD licensing and research-only use. Overall, the study offers a
transparent, baseline-beating reference for GTD incident forecasting.

</details>


### [228] [Policy Transfer Ensures Fast Learning for Continuous-Time LQR with Entropy Regularization](https://arxiv.org/abs/2510.15165)
*Xin Guo,Zijiu Lyu*

Main category: cs.LG

TL;DR: 该论文研究了在连续时间强化学习（RL）中，利用策略迁移（TL）技术，特别是初始化学习策略来提高训练效率。研究对象是具有熵正则化的连续时间线性二次调节器（LQR）。


<details>
  <summary>Details</summary>
Motivation: 在复杂的RL任务中，从头开始训练效率低下。TL，尤其是在LLM中取得成功的策略迁移，为提高RL效率提供了潜力。

Method: 研究了连续时间LQR问题中的策略迁移，并提出了一个新的策略学习算法，该算法具有全局线性收敛和局部超线性收敛的特点。

Result: 理论上证明了策略迁移在连续时间RL中的有效性，证明了在一个LQR任务上最优的策略可以作为邻近LQR任务的近优初始化策略，同时保持原算法的收敛速率。新算法在理论上和实践中都显示出优势。

Conclusion: 策略迁移在连续时间RL中具有理论保证和算法优势，填补了现有文献的空白，并将先前在离散时间设置下的工作扩展到了连续时间。此外，通过LQR与连续时间评分基线扩散模型的联系，推导了这类模型的稳定性。

Abstract: Reinforcement Learning (RL) enables agents to learn optimal decision-making
strategies through interaction with an environment, yet training from scratch
on complex tasks can be highly inefficient. Transfer learning (TL), widely
successful in large language models (LLMs), offers a promising direction for
enhancing RL efficiency by leveraging pre-trained models.
  This paper investigates policy transfer, a TL approach that initializes
learning in a target RL task using a policy from a related source task, in the
context of continuous-time linear quadratic regulators (LQRs) with entropy
regularization. We provide the first theoretical proof of policy transfer for
continuous-time RL, proving that a policy optimal for one LQR serves as a
near-optimal initialization for closely related LQRs, while preserving the
original algorithm's convergence rate. Furthermore, we introduce a novel policy
learning algorithm for continuous-time LQRs that achieves global linear and
local super-linear convergence. Our results demonstrate both theoretical
guarantees and algorithmic benefits of transfer learning in continuous-time RL,
addressing a gap in existing literature and extending prior work from discrete
to continuous time settings.
  As a byproduct of our analysis, we derive the stability of a class of
continuous-time score-based diffusion models via their connection with LQRs.

</details>


### [229] [A simple mean field model of feature learning](https://arxiv.org/abs/2510.15174)
*Niclas Göring,Chris Mingard,Yoonsoo Nam,Ard Louis*

Main category: cs.LG

TL;DR: 使用统计物理方法，我们推导了一个可行的、自洽的平均场理论，用于描述通过随机梯度 Langevin 动力学 (SGLD) 训练的贝叶斯两层非线性网络的后验。在无限宽度下，该理论简化为核岭回归，但在有限宽度下，它预测了一个对称性破缺相变，网络会突然与目标函数对齐。虽然基本的平均场理论为理解有限宽度范围内特征学习 (FL) 的出现提供了理论见解，并能半定量地预测具有噪声或样本量的 FL 的开始，但它大大低估了过渡后泛化能力的提高。我们将这种差异归因于一个在标准平均场描述中缺失的关键机制：*自增强输入特征选择*。将此机制纳入平均场理论，可以使我们能够定量匹配 SGLD 训练网络的学习曲线，并为 FL 提供机制性见解。


<details>
  <summary>Details</summary>
Motivation: 两层非线性网络在随机梯度 Langevin 动力学 (SGLD) 训练下的特征学习 (FL) 机制仍然知之甚少。

Method: 使用统计物理方法，推导了贝叶斯后验的自洽平均场 (MF) 理论，并考虑了对称性破缺相变和自增强输入特征选择。

Result: 在无限宽度下，该理论还原为核岭回归；在有限宽度下，预测了对称性破缺相变，网络会突然与目标函数对齐。改进后的 MF 理论能够定量匹配 SGLD 训练网络的学习曲线。

Conclusion: 自增强输入特征选择是有限宽度神经网络中 FL 的一个关键机制，将其纳入平均场理论可以定量匹配实验结果并提供对其工作原理的机制性见解。

Abstract: Feature learning (FL), where neural networks adapt their internal
representations during training, remains poorly understood. Using methods from
statistical physics, we derive a tractable, self-consistent mean-field (MF)
theory for the Bayesian posterior of two-layer non-linear networks trained with
stochastic gradient Langevin dynamics (SGLD). At infinite width, this theory
reduces to kernel ridge regression, but at finite width it predicts a symmetry
breaking phase transition where networks abruptly align with target functions.
While the basic MF theory provides theoretical insight into the emergence of FL
in the finite-width regime, semi-quantitatively predicting the onset of FL with
noise or sample size, it substantially underestimates the improvements in
generalisation after the transition. We trace this discrepancy to a key
mechanism absent from the plain MF description: \textit{self-reinforcing input
feature selection}. Incorporating this mechanism into the MF theory allows us
to quantitatively match the learning curves of SGLD-trained networks and
provides mechanistic insight into FL.

</details>


### [230] [Finding geodesics with the Deep Ritz method](https://arxiv.org/abs/2510.15177)
*Conor Rowan*

Main category: cs.LG

TL;DR: 文章提出使用深度黎曼方法解决测地线问题，并通过路径规划、光学和固体力学中的数值算例进行了验证。


<details>
  <summary>Details</summary>
Motivation: 测地线问题在物理和工程学中普遍存在，但科学机器学习社区对其研究较少。文章认为测地线问题非常适合使用深度黎曼方法。

Method: 利用深度黎曼方法，并通过三个数值算例（路径规划、光学、固体力学）进行验证。

Result: 验证了深度黎曼方法在解决测地线问题上的有效性。

Conclusion: 测地线问题是深度黎曼方法的一个有前景的应用，也是未来科学机器学习研究的一个有益方向。

Abstract: Geodesic problems involve computing trajectories between prescribed initial
and final states to minimize a user-defined measure of distance, cost, or
energy. They arise throughout physics and engineering -- for instance, in
determining optimal paths through complex environments, modeling light
propagation in refractive media, and the study of spacetime trajectories in
control theory and general relativity. Despite their ubiquity, the scientific
machine learning (SciML) community has given relatively little attention to
investigating its methods in the context of these problems. In this work, we
argue that given their simple geometry, variational structure, and natural
nonlinearity, geodesic problems are particularly well-suited for the Deep Ritz
method. We substantiate this claim with three numerical examples drawn from
path planning, optics, and solid mechanics. Our goal is not to provide an
exhaustive study of geodesic problems, but rather to identify a promising
application of the Deep Ritz method and a fruitful direction for future SciML
research.

</details>


### [231] [An Advanced Two-Stage Model with High Sensitivity and Generalizability for Prediction of Hip Fracture Risk Using Multiple Datasets](https://arxiv.org/abs/2510.15179)
*Shuo Sun,Meiling Zhou,Chen Zhao,Joyce H. Keyak,Nancy E. Lane,Jeffrey D. Deng,Kuan-Jui Su,Hui Shen,Hong-Wen Deng,Kui Zhang,Weihua Zhou*

Main category: cs.LG

TL;DR: 该研究提出了一种结合临床和影像学信息的序贯两阶段模型，以提高老年人髋部骨折风险评估的准确性，优于传统的T分数和FRAX工具。


<details>
  <summary>Details</summary>
Motivation: 现有工具（如DXA T分数和FRAX）在髋部骨折风险评估中敏感性不足，容易漏诊高风险个体（尤其是在无骨折史或骨质疏松的个体中），因此需要更精确的评估方法。

Method: 采用序贯两阶段模型：第一阶段（筛查）使用临床、人口统计学和功能变量估计基线风险；第二阶段（影像学）结合DXA衍生的特征进行精炼。使用MrOS、SOF和UK Biobank三个队列的数据进行模型开发和验证。

Result: 与T分数和FRAX相比，该两阶段模型在内部和外部测试中均表现出更高的敏感性和更低的漏诊率，在不同队列中表现一致且具有适应性。

Conclusion: 该序贯两阶段模型能够更有效地识别高风险个体，提供一种比传统方法更具成本效益和个性化的早期髋部骨折风险评估策略。

Abstract: Hip fractures are a major cause of disability, mortality, and healthcare
burden in older adults, underscoring the need for early risk assessment.
However, commonly used tools such as the DXA T-score and FRAX often lack
sensitivity and miss individuals at high risk, particularly those without prior
fractures or with osteopenia. To address this limitation, we propose a
sequential two-stage model that integrates clinical and imaging information to
improve prediction accuracy. Using data from the Osteoporotic Fractures in Men
Study (MrOS), the Study of Osteoporotic Fractures (SOF), and the UK Biobank,
Stage 1 (Screening) employs clinical, demographic, and functional variables to
estimate baseline risk, while Stage 2 (Imaging) incorporates DXA-derived
features for refinement. The model was rigorously validated through internal
and external testing, showing consistent performance and adaptability across
cohorts. Compared to T-score and FRAX, the two-stage framework achieved higher
sensitivity and reduced missed cases, offering a cost-effective and
personalized approach for early hip fracture risk assessment.
  Keywords: Hip Fracture, Two-Stage Model, Risk Prediction, Sensitivity, DXA,
FRAX

</details>


### [232] [Dissecting Mahalanobis: How Feature Geometry and Normalization Shape OOD Detection](https://arxiv.org/abs/2510.15202)
*Denis Janiak,Jakub Binkowski,Tomasz Kajdanowicz*

Main category: cs.LG

TL;DR: 几种数据归一化方法会影响基于马氏距离的 OOD 检测性能，可以通过调整特征空间的径向几何来提高性能。


<details>
  <summary>Details</summary>
Motivation: 虽然基于马氏距离的 OOD 检测方法被广泛使用，但其性能受到表示几何和归一化的影响，这限制了其在实际应用中的可靠性。

Method: 通过对各种图像基础模型、数据集和距离归一化方案进行广泛的实证研究，来分析马氏距离方法的性能。定义了数据表示的理想几何形状，并使用光谱和内在维度指标来预测模型的 OOD 性能。最后，分析了归一化对 OOD 性能的影响，并提出了一种新的径向缩放 L2 归一化方法。

Result: 研究表明，基于马氏距离的方法并不总是可靠的。光谱和内在维度指标可以准确预测模型的 OOD 性能。提出的径向缩放 L2 归一化方法通过直接控制特征空间的径向几何，可以显著提高 OOD 检测性能。

Conclusion: 数据表示的几何形状和归一化方法对于基于马氏距离的 OOD 检测至关重要。提出的径向缩放 L2 归一化方法通过调整特征空间的径向几何，能够有效提升 OOD 检测的性能，为设计更可靠的深度学习模型提供了新的思路。

Abstract: Out-of-distribution (OOD) detection is critical for the reliable deployment
of deep learning models. hile Mahalanobis distance methods are widely used, the
impact of representation geometry and normalization on their performance is not
fully understood, which may limit their downstream application. To address this
gap, we conducted a comprehensive empirical study across diverse image
foundation models, datasets, and distance normalization schemes. First, our
analysis shows that Mahalanobis-based methods aren't universally reliable.
Second, we define the ideal geometry for data representations and demonstrate
that spectral and intrinsic-dimensionality metrics can accurately predict a
model's OOD performance. Finally, we analyze how normalization impacts OOD
performance. Building upon these studies, we propose radially scaled $\ell_2$
normalization, a method that generalizes the standard $\ell_2$ normalization
recently applied to Mahalanobis-based OOD detection. Our approach introduces a
tunable parameter to directly control the radial geometry of the feature space,
systematically contracting or expanding representations to significantly
improve OOD detection performance. By bridging the gap between representation
geometry, normalization, and OOD performance, our findings offer new insights
into the design of more effective and reliable deep learning models.

</details>


### [233] [ReasonIF: Large Reasoning Models Fail to Follow Instructions During Reasoning](https://arxiv.org/abs/2510.15211)
*Yongchan Kwon,Shang Zhu,Federico Bianchi,Kaitlyn Zhou,James Zou*

Main category: cs.LG

TL;DR: LLMs遵循用户指令的能力对其可靠性、安全性和实用性至关重要。然而，现有研究主要关注模型主响应中的指令遵循情况，而忽略了在推理过程中遵循指令的重要性。本研究引入ReasonIF基准来评估大型推理模型（LRMs）在推理过程中的指令遵循能力，并发现现有模型存在严重的指令遵循问题，尤其是在任务难度增加时。此外，研究还探讨了通过多轮推理和合成数据进行推理指令微调（RIF）来提升指令遵循能力的策略，并取得了初步成效。


<details>
  <summary>Details</summary>
Motivation: 评估大型推理模型（LRMs）在推理过程中遵循用户指令的能力，因为这关系到模型的可靠性、安全性、实用性、可控性和透明度，并能减少不希望出现的捷径、幻觉或奖励攻击的风险。

Method: 引入ReasonIF基准，包含六类指令提示，涵盖多语言推理、格式和长度控制。对GPT-OSS、Qwen3和DeepSeek-R1等多个开源LRMs进行评估。探索了多轮推理和推理指令微调（RIF）两种策略来提升指令遵循能力。

Result: 在多个开源LRMs上进行评估，发现其在推理指令遵循方面存在显著问题，最高指令遵循分数（IFS）低于0.25。任务难度增加时，指令遵循能力进一步下降。RIF策略将GPT-OSS-20B的IFS从0.11提升至0.27，表明有可衡量的进步，但仍有很大提升空间。

Conclusion: 现有的LRMs在推理过程中遵循用户指令的能力不足，特别是在更复杂的任务中。RIF策略可以提高指令遵循能力，但仍需进一步研究以实现更可靠的指令遵循。

Abstract: The ability of large language models (LLMs) to follow user instructions is
central to their reliability, safety, and usefulness. While prior studies
assess instruction adherence in the model's main responses, we argue that it is
also critical for large reasoning models (LRMs) to follow user instructions
throughout their reasoning process. Reasoning instruction following makes LRMs
more controllable and transparent, while reducing risks of undesirable
shortcuts, hallucinations, or reward hacking within reasoning traces. To
evaluate this dimension, we introduce ReasonIF, a systematic benchmark for
assessing reasoning instruction following. ReasonIF includes six categories of
instruction prompts, spanning multilingual reasoning, formatting and length
control. Across many open-source LRMs including GPT-OSS, Qwen3, and
DeepSeek-R1, we find substantial failures in reasoning instruction adherence:
the highest instruction following score (IFS) remains below 0.25, meaning that
fewer than $25\%$ of reasoning traces comply with the given instructions.
Notably, as task difficulty increases, reasoning instruction following degrades
further. We also explore two strategies to enhance reasoning instruction
fidelity. (1) multi-turn reasoning and (2) Reasoning Instruction Finetuning
(RIF) using synthetic data. RIF improves the IFS of $GPT-OSS-20B$ from 0.11 to
0.27, indicating measurable progress but leaving ample room for improvement.

</details>


### [234] [Soundness-Aware Level: A Microscopic Signature that Predicts LLM Reasoning Potential](https://arxiv.org/abs/2510.15216)
*Xuansheng Wu,Xiaoman Pan,Wenlin Yao,Jianshu Chen*

Main category: cs.LG

TL;DR: RLHF 训练后 LLM 的推理能力差异很大，这取决于预训练模型的一个微观属性：区分“严格”规则和“嘈杂”规则的能力。


<details>
  <summary>Details</summary>
Motivation: 在 RLHF 训练后，不同基础模型在 LLM 的推理能力上表现出显著差异。本研究旨在探究导致这种差异的预训练模型的微观属性。

Method: 1. 将推理形式化为由 LLM 的潜在空间特征组成的 Horn 子句链，这些特征通过交叉层稀疏自编码器 (SAE) 提取。 2. 估计这些特征之间的转移概率。 3. 使用 LLM 将每个规则按其语义健全性级别（严格、合理、嘈杂）进行分类。 4. 提出“健全性感知级别 (SAL)”指标，利用 Jensen-Shannon 散度来衡量不同健全性级别规则的概率分布的分离程度。

Result: 模型在 RLHF 训练后的推理能力与其 SAL 分数高度相关（R^2=0.87）。高 SAL 分数的模型（即，能够区分不同健全性级别规则的模型）在 RLHF 训练后表现出更强的推理能力。这种相关性在不同的模型家族（Qwen、Mistral、Llama、DeepSeek）和规模（0.5B-14B）中均成立。

Conclusion: 模型的推理潜力与其区分可靠知识和不可靠知识的内在预训练能力有关。SAL 是一个量化这种能力的实用指标，可以用于选择和设计更强的基础模型。

Abstract: Reinforcement learning with verifiable rewards (RLVR) can elicit strong
reasoning in large language models (LLMs), while their performance after RLVR
varies dramatically across different base models. This raises a fundamental
question: what microscopic property of pre-trained models leads to this
variation? To investigate, we formalize reasoning as chains of Horn clauses
("if-then" rules) built from features extracted from the LLM's latent space via
cross-layer sparse autoencoders (SAEs). We estimate the transition
probabilities between its features, and further categorize each rule by its
semantic soundness level (e.g., strict, plausible, noisy) with an LLM. Our key
discovery is that high-potential models are inherently soundness-aware: their
internal probability distributions systematically shift across rules' soundness
levels, becoming highly distinct for "strict" versus "noisy" rules. In
contrast, weaker models are soundness-agnostic, collapsing to one distribution
regardless of soundness levels. To quantify this, we introduce the
Soundness-Aware Level (SAL), a microscopic metric using the Jensen-Shannon
Divergence to measure the separation between these distributions. We show that
SAL's predictions of post-RLVR reasoning performance follow a precise empirical
law (R^2=0.87) across diverse model families (Qwen, Mistral, Llama, DeepSeek)
and scales (0.5B-14B). This reveals that a model's reasoning potential is tied
to its intrinsic, pre-trained ability to distinguish sound knowledge from
unsound ones. These findings underscore the critical role of model pre-training
in shaping reasoning and offer a practical metric grounded in the model's
internal mechanisms for selecting/designing stronger base models.

</details>


### [235] [Reflections from Research Roundtables at the Conference on Health, Inference, and Learning (CHIL) 2025](https://arxiv.org/abs/2510.15217)
*Emily Alsentzer,Marie-Laure Charpignon,Bill Chen,Niharika D'Souza,Jason Fries,Yixing Jiang,Aparajita Kashyap,Chanwoo Kim,Simon Lee,Aishwarya Mandyam,Ashery Christopher Mbilinyi,Nikita Mehandru,Nitish Nagesh,Brighton Nuwagira,Emma Pierson,Arvind Pillai,Akane Sano,Tanveer Syeda-Mahmood,Shashank Yadav,Elias Adhanom,Muhammad Umar Afza,Amelia Archer,Suhana Bedi,Vasiliki Bikia,Trenton Chang,George H. Chen,Winston Chen,Erica Chiang,Edward Choi,Octavia Ciora,Paz Dozie-Nnamah,Shaza Elsharief,Matthew Engelhard,Ali Eshragh,Jean Feng,Josh Fessel,Scott Fleming,Kei Sen Fong,Thomas Frost,Soham Gadgil,Judy Gichoya,Leeor Hershkovich,Sujeong Im,Bhavya Jain,Vincent Jeanselme,Furong Jia,Qixuan,Jin,Yuxuan Jin,Daniel Kapash,Geetika Kapoor,Behdokht Kiafar,Matthias Kleiner,Stefan Kraft,Annika Kumar,Daeun Kyung,Zhongyuan Liang,Joanna Lin,Qianchu,Liu,Chang Liu,Hongzhou Luan,Chris Lunt,Leopoldo Julían Lechuga López,Matthew B. A. McDermott,Shahriar Noroozizadeh,Connor O'Brien,YongKyung Oh,Mixail Ota,Stephen Pfohl,Meagan Pi,Tanmoy Sarkar Pias,Emma Rocheteau,Avishaan Sethi,Toru Shirakawa,Anita Silver,Neha Simha,Kamile Stankeviciute,Max Sunog,Peter Szolovits,Shengpu Tang,Jialu Tang,Aaron Tierney,John Valdovinos,Byron Wallace,Will Ke Wang,Peter Washington,Jeremy Weiss,Daniel Wolfe,Emily Wong,Hye Sun Yun,Xiaoman Zhang,Xiao Yu Cindy Zhang,Hayoung Jeong,Kaveri A. Thakoor*

Main category: cs.LG

TL;DR: CHIL 2025会议举办了关于机器学习与医疗保健交叉领域的八场研究圆桌讨论会，旨在促进合作对话和集体创新。


<details>
  <summary>Details</summary>
Motivation: 促进机器学习与医疗保健交叉领域的合作对话，探讨关键挑战并寻求可行的解决方案。

Method: 在CHIL 2025会议期间，由资深和青年主席主持了八场研究圆桌讨论会，围绕特定主题展开了严谨的讨论、新兴机会的探索和集体构思。

Result: 会议成功举办了八场关于特定主题（如可解释性、不确定性、因果关系、领域自适应、基础模型、小样本医疗数据学习、多模态方法以及可扩展的医疗解决方案）的研究圆桌讨论会。

Conclusion: 研究圆桌讨论会有效地促进了机器学习与医疗保健领域内的思想交流和协作，为该领域未来的发展指明了方向。

Abstract: The 6th Annual Conference on Health, Inference, and Learning (CHIL 2025),
hosted by the Association for Health Learning and Inference (AHLI), was held in
person on June 25-27, 2025, at the University of California, Berkeley, in
Berkeley, California, USA. As part of this year's program, we hosted Research
Roundtables to catalyze collaborative, small-group dialogue around critical,
timely topics at the intersection of machine learning and healthcare. Each
roundtable was moderated by a team of senior and junior chairs who fostered
open exchange, intellectual curiosity, and inclusive engagement. The sessions
emphasized rigorous discussion of key challenges, exploration of emerging
opportunities, and collective ideation toward actionable directions in the
field. In total, eight roundtables were held by 19 roundtable chairs on topics
of "Explainability, Interpretability, and Transparency," "Uncertainty, Bias,
and Fairness," "Causality," "Domain Adaptation," "Foundation Models," "Learning
from Small Medical Data," "Multimodal Methods," and "Scalable, Translational
Healthcare Solutions."

</details>


### [236] [Machine Learning for Early Detection of Meningitis: Stacked Ensemble Learning with EHR data](https://arxiv.org/abs/2510.15218)
*Han Ouyang,Jesse Hamilton,Saeed Amal*

Main category: cs.LG

TL;DR: 利用 MIMIC-III 数据库中的脑膜炎患者数据，结合随机森林、LightGBM 和深度神经网络，通过集成学习构建了一个脑膜炎诊断模型，并在两个测试集上获得了 AUC 0.9637 和 0.9472 的优异表现。


<details>
  <summary>Details</summary>
Motivation: 在真实世界急诊室场景下，为脑膜炎的诊断提供一个具有挑战性但又贴合实际的应用条件，为未来人工智能驱动的脑膜炎诊断方法铺平道路。

Method: 从 MIMIC-III 数据库中提取了 214 名脑膜炎患者和 46,303 名非脑膜炎患者的数据，经过数据预处理、特征选择后，训练了随机森林、LightGBM 和深度神经网络三个基础模型，并利用逻辑回归作为元模型进行集成学习。

Result: 在两个测试集上，集成学习模型分别获得了 0.9637 和 0.9472 的 AUC 值。

Conclusion: 该研究通过集成学习方法构建的脑膜炎诊断模型在模拟的急诊室场景下表现出优异的性能，为未来开发人工智能辅助诊断工具提供了有前景的方向。

Abstract: We utilized a cohort of 214 meningitis patients and 46,303 non-meningitis
patients from the MIMIC-III database. After extensive data preprocessing, which
included ICD-based cohort selection, one-hot encoding of coding, and a
two-stage feature selection process (for both the training set and the testing
sets), clinically relevant features such as gender and high-risk ICD codes
(including subarachnoid hemorrhage, secondary malignant neoplasm of the brain,
and generalized epilepsy) are selected. Overall, these clinically reasonable
and temporally adherent features provided excellent modeling performance. Three
models (Random Forest, LightGBM, and Deep Neural Networks (DNN) are trained as
base models for Ensemble Learning. Base model outputs are aggregated and
stacked into a meta model (Logistic Regression) that uses the base model
outputs as input values in training. Ultimately, soldier outputs (AUC of
Testing Set 1: 0.9637, AUC of Testing Set 2: 0.9472) are obtained through
ensemble learning.
  We created a challenging condition for diagnosing meningitis, simulating a
real-world ER (Emergency Room) scenario to enhance clinical use in real-world
applications. While directly deploying a diagnostic tool that clinicians can
use is challenging, this paper paves the way for a potential future AI-driven
diagnostic approach for meningitis using Ensemble Learning.

</details>


### [237] [Towards Robust Zero-Shot Reinforcement Learning](https://arxiv.org/abs/2510.15382)
*Kexin Zheng,Lauriane Teyssier,Yinan Zheng,Yu Luo,Xiayuan Zhan*

Main category: cs.LG

TL;DR: BREEZE通过行为正则化和扩散模型改进了零样本强化学习，提高了稳定性和性能。


<details>
  <summary>Details</summary>
Motivation: 现有的前向-后向（FB）表示方法在零样本强化学习中存在模型表达能力不足和外推误差导致性能次优的问题。

Method: BREEZE框架通过引入行为正则化将策略优化转化为稳定的样本内学习范式，并使用任务条件扩散模型提取策略以生成高质量、多模态的动作分布，同时采用基于注意力的表达性架构进行表示学习。

Result: 在ExORL和D4RL Kitchen数据集上的广泛实验表明，BREEZE的性能优于或接近最优，并且比先前的方法具有更强的鲁棒性。

Conclusion: BREEZE通过增强学习稳定性、策略提取能力和表示学习质量，有效解决了现有零样本强化学习方法的局限性，并在实验中取得了优异的性能和鲁棒性。

Abstract: The recent development of zero-shot reinforcement learning (RL) has opened a
new avenue for learning pre-trained generalist policies that can adapt to
arbitrary new tasks in a zero-shot manner. While the popular Forward-Backward
representations (FB) and related methods have shown promise in zero-shot RL, we
empirically found that their modeling lacks expressivity and that extrapolation
errors caused by out-of-distribution (OOD) actions during offline learning
sometimes lead to biased representations, ultimately resulting in suboptimal
performance. To address these issues, we propose Behavior-REgularizEd Zero-shot
RL with Expressivity enhancement (BREEZE), an upgraded FB-based framework that
simultaneously enhances learning stability, policy extraction capability, and
representation learning quality. BREEZE introduces behavioral regularization in
zero-shot RL policy learning, transforming policy optimization into a stable
in-sample learning paradigm. Additionally, BREEZE extracts the policy using a
task-conditioned diffusion model, enabling the generation of high-quality and
multimodal action distributions in zero-shot RL settings. Moreover, BREEZE
employs expressive attention-based architectures for representation modeling to
capture the complex relationships between environmental dynamics. Extensive
experiments on ExORL and D4RL Kitchen demonstrate that BREEZE achieves the best
or near-the-best performance while exhibiting superior robustness compared to
prior offline zero-shot RL methods. The official implementation is available
at: https://github.com/Whiterrrrr/BREEZE.

</details>


### [238] [Integrating Product Coefficients for Improved 3D LiDAR Data Classification (Part II)](https://arxiv.org/abs/2510.15219)
*Patricia Medina,Rasika Karkare*

Main category: cs.LG

TL;DR: 将乘积系数与自编码器表示和 KNN 分类器相结合，可提高 3D LiDAR 点云分类性能。


<details>
  <summary>Details</summary>
Motivation: 在先前工作的基础上，通过结合乘积系数、自编码器表示和 KNN 分类器来增强 3D LiDAR 点云分类。

Method: 将乘积系数与自编码器表示和 KNN 分类器相结合，并逐级分析乘积系数的影响。

Result: 与 PCA 基线和先前框架相比，该方法在分类性能上获得了一致的提升。逐级添加乘积系数显示出清晰的趋势：更丰富的系数集系统性地提高了类别可分性和整体准确性。

Conclusion: 结合分层乘积系数特征和自编码器是进一步提高 LiDAR 分类性能的有效方法。

Abstract: This work extends our previous study on enhancing 3D LiDAR point-cloud
classification with product coefficients
\cite{medina2025integratingproductcoefficientsimproved}, measure-theoretic
descriptors that complement the original spatial Lidar features. Here, we show
that combining product coefficients with an autoencoder representation and a
KNN classifier delivers consistent performance gains over both PCA-based
baselines and our earlier framework. We also investigate the effect of adding
product coefficients level by level, revealing a clear trend: richer sets of
coefficients systematically improve class separability and overall accuracy.
The results highlight the value of combining hierarchical product-coefficient
features with autoencoders to push LiDAR classification performance further.

</details>


### [239] [Stress-Aware Learning under KL Drift via Trust-Decayed Mirror Descent](https://arxiv.org/abs/2510.15222)
*Gabriel Nixon Raj*

Main category: cs.LG

TL;DR: 提出熵正则化信任衰减方法，用于解决分布漂移下的序贯决策问题，并在此基础上得到了动态后悔界限。


<details>
  <summary>Details</summary>
Motivation: 研究分布漂移下的序贯决策问题。

Method: 提出熵正则化信任衰减，将压力感知指数倾斜注入信念更新和镜面下降决策。在单形上，通过 Fenchel 对偶等价性表明信念倾斜和决策倾斜是相同的。形式化了通过脆弱性（KL 球中的最坏情况超额风险）、信念带宽（维持目标超额的半径）和决策空间脆弱性指数（T 的 O(sqrt(T)) 后悔的容忍漂移）来衡量鲁棒性。

Result: 证明了高概率敏感性界限，并获得了 KL-drift 路径长度 $S_T = 
umpy.sum 
umpy.sqrt(
umpy.clip({m KL}(D_t|D_{t-1})/2, 0, 
umpy.inf)))$ 下的 $	ilde{O}(
umpy.sqrt(T))$ 动态后悔保证。特别是，信任衰减实现了 $O(1)$ 的每次切换后悔，而无压力更新会产生 $
umpy.Omega(1)$ 的尾部。一种无参数的对冲方法可以调整倾斜以适应未知的漂移，而持续的过度倾斜会产生 $
umpy.Omega(
umpy.power(
umpy.lambda, 2) * T)$ 的稳态惩罚。还获得了校准压力界限以及对二阶更新、土匪反馈、异常值、压力变化、分布式优化和插件 KL-漂移估计的扩展。

Conclusion: 该框架将动态后悔分析、分布鲁棒目标和 KL 正则化控制统一在单一的压力自适应更新中。

Abstract: We study sequential decision-making under distribution drift. We propose
entropy-regularized trust-decay, which injects stress-aware exponential tilting
into both belief updates and mirror-descent decisions. On the simplex, a
Fenchel-dual equivalence shows that belief tilt and decision tilt coincide. We
formalize robustness via fragility (worst-case excess risk in a KL ball),
belief bandwidth (radius sustaining a target excess), and a decision-space
Fragility Index (drift tolerated at $O(\sqrt{T})$ regret). We prove
high-probability sensitivity bounds and establish dynamic-regret guarantees of
$\tilde{O}(\sqrt{T})$ under KL-drift path length $S_T = \sum_{t\ge2}\sqrt{{\rm
KL}(D_t|D_{t-1})/2}$. In particular, trust-decay achieves $O(1)$ per-switch
regret, while stress-free updates incur $\Omega(1)$ tails. A parameter-free
hedge adapts the tilt to unknown drift, whereas persistent over-tilting yields
an $\Omega(\lambda^2 T)$ stationary penalty. We further obtain
calibrated-stress bounds and extensions to second-order updates, bandit
feedback, outliers, stress variation, distributed optimization, and plug-in
KL-drift estimation. The framework unifies dynamic-regret analysis,
distributionally robust objectives, and KL-regularized control within a single
stress-adaptive update.

</details>


### [240] [FinTrust: A Comprehensive Benchmark of Trustworthiness Evaluation in Finance Domain](https://arxiv.org/abs/2510.15232)
*Tiansheng Hu,Tongyan Hu,Liuyang Bai,Yilun Zhao,Arman Cohan,Chen Zhao*

Main category: cs.LG

TL;DR: 该论文提出了FinTrust，一个用于评估金融领域大模型（LLM）可信度的综合基准，并评估了11个LLM。结果显示，私有模型在安全方面表现优于开源模型，但两者在行业公平性方面各有优势。所有模型在受托人对齐和披露方面均表现不佳，表明在法律意识方面存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 在金融领域应用大模型（LLM）面临高风险和高风险的挑战，需要评估其可信度。

Method: 提出了FinTrust基准，该基准专门设计用于评估金融应用中LLM的可信度，涵盖了广泛的对齐问题，并为可信度评估的每个维度设置了细粒度的任务。评估了11个LLM在FinTrust上的表现。

Result: 在FinTrust的评估中，私有模型（如o4-mini）在安全等大多数任务上表现优于开源模型（如DeepSeek-V3），而开源模型在行业公平性等特定领域具有优势。所有LLM在受托人对齐和披露等具有挑战性的任务上均表现不佳，显示出法律意识方面的显著差距。

Conclusion: FinTrust可以成为评估金融领域LLM可信度的宝贵基准。

Abstract: Recent LLMs have demonstrated promising ability in solving finance related
problems. However, applying LLMs in real-world finance application remains
challenging due to its high risk and high stakes property. This paper
introduces FinTrust, a comprehensive benchmark specifically designed for
evaluating the trustworthiness of LLMs in finance applications. Our benchmark
focuses on a wide range of alignment issues based on practical context and
features fine-grained tasks for each dimension of trustworthiness evaluation.
We assess eleven LLMs on FinTrust and find that proprietary models like o4-mini
outperforms in most tasks such as safety while open-source models like
DeepSeek-V3 have advantage in specific areas like industry-level fairness. For
challenging task like fiduciary alignment and disclosure, all LLMs fall short,
showing a significant gap in legal awareness. We believe that FinTrust can be a
valuable benchmark for LLMs' trustworthiness evaluation in finance domain.

</details>


### [241] [Cavity Duplexer Tuning with 1d Resnet-like Neural Networks](https://arxiv.org/abs/2510.15796)
*Anton Raskovalov*

Main category: cs.LG

TL;DR: 提出一种基于监督学习的机器学习方法，用于调整具有大量调节螺钉的腔体双工器，仅需4-5次旋转即可达到接近调谐状态。


<details>
  <summary>Details</summary>
Motivation: 提出一种用于调整具有大量调节螺钉的腔体双工器的新方法，以提高调整效率。

Method: 采用包含1D ResNet类骨干和S参数（曲线形状、峰值位置和幅度）的附加信息处理的神经网络架构，并结合外部控制算法。

Result: 该方法能够在4-5次旋转内使双工器接近调谐状态。

Conclusion: 所提出的基于监督学习的机器学习方法比传统的强化学习方法更有效，能够快速准确地调整腔体双工器。

Abstract: This paper presents machine learning method for tuning of cavity duplexer
with a large amount of adjustment screws. After testing we declined
conventional reinforcement learning approach and reformulated our task in the
supervised learning setup. The suggested neural network architecture includes
1d ResNet-like backbone and processing of some additional information about
S-parameters, like the shape of curve and peaks positions and amplitudes. This
neural network with external control algorithm is capable to reach almost the
tuned state of the duplexer within 4-5 rotations per screw.

</details>


### [242] [Adaptive Individual Uncertainty under Out-Of-Distribution Shift with Expert-Routed Conformal Prediction](https://arxiv.org/abs/2510.15233)
*Amitesh Badkul,Lei Xie*

Main category: cs.LG

TL;DR: TESSERA是一种新的不确定性量化方法，为蛋白质-配体亲和力预测提供了可靠的覆盖率和信息量，以及可操作的预测区间。


<details>
  <summary>Details</summary>
Motivation: 目前机器学习领域缺乏可靠、信息丰富且个体化的不确定性量化（UQ），这阻碍了人工智能/机器学习在风险敏感领域的有效应用，尤其是在药物发现等高风险领域，蛋白质-配体亲和力（PLI）预测面临数据噪声异构、化学空间不平衡且庞大以及分布偏移等挑战。

Method: 提出了一种名为TESSERA（Trustworthy Expert Split-conformal with Scaled Estimation for Efficient Reliable Adaptive intervals）的新型不确定性量化方法，该方法能够提供每个样本的不确定性，并具有可靠的覆盖率保证，以及信息丰富且自适应的预测区间宽度，能够跟踪绝对误差。该方法结合了专家混合（MoE）的多样性和共形校准。

Result: 在独立同分布（i.i.d.）和基于支架的分布外（OOD）拆分下，TESSERA在蛋白质-配体结合亲和力预测方面达到了近乎名义的覆盖率，并在覆盖率-宽度权衡方面（以覆盖率-宽度标准CWC衡量）表现最佳，同时保持了具有竞争力的自适应性（以稀疏化误差面积AUSE衡量，最低）。尺寸分层覆盖（SSC）进一步证实了区间大小的合理性，表明在数据稀疏或嘈杂时宽度增加，在预测可靠时宽度保持紧凑。

Conclusion: TESSERA通过融合专家混合（MoE）的多样性和共形校准，提供了可信赖、紧凑且自适应的不确定性，非常适合药物发现流程及其他应用中的选择性预测和下游决策制定。

Abstract: Reliable, informative, and individual uncertainty quantification (UQ) remains
missing in current ML community. This hinders the effective application of
AI/ML to risk-sensitive domains. Most methods either fail to provide coverage
on new data, inflate intervals so broadly that they are not actionable, or
assign uncertainties that do not track actual error, especially under a
distribution shift. In high-stakes drug discovery, protein-ligand affinity
(PLI) prediction is especially challenging as assay noise is heterogeneous,
chemical space is imbalanced and large, and practical evaluations routinely
involve distribution shift. In this work, we introduce a novel uncertainty
quantification method, Trustworthy Expert Split-conformal with Scaled
Estimation for Efficient Reliable Adaptive intervals (TESSERA), that provides
per-sample uncertainty with reliable coverage guarantee, informative and
adaptive prediction interval widths that track the absolute error. We evaluate
on protein-ligand binding affinity prediction under both independent and
identically distributed (i.i.d.) and scaffold-based out-of-distribution (OOD)
splits, comparing against strong UQ baselines. TESSERA attains near-nominal
coverage and the best coverage-width trade-off as measured by the
Coverage-Width Criterion (CWC), while maintaining competitive adaptivity
(lowest Area Under the Sparsification Error (AUSE)). Size-Stratified Coverage
(SSC) further confirms that intervals are right-sized, indicating width
increases when data are scarce or noisy, and remain tight when predictions are
reliable. By unifying Mixture of Expert (MoE) diversity with conformal
calibration, TESSERA delivers trustworthy, tight, and adaptive uncertainties
that are well-suited to selective prediction and downstream decision-making in
the drug-discovery pipeline and other applications.

</details>


### [243] [Dual-Weighted Reinforcement Learning for Generative Preference Modeling](https://arxiv.org/abs/2510.15242)
*Shengyu Feng,Yun He,Shuang Ma,Beibin Li,Yuanhao Xiong,Vincent Li,Karishma Mandyam,Julian Katz-Samuels,Shengjie Bi,Licheng Yu,Hejia Zhang,Karthik Abinav Sankararaman,Han Fang,Riham Mansour,Yiming Yang,Manaal Faruqui*

Main category: cs.LG

TL;DR: DWRL是一种用于偏好建模的新框架，将链式思考（CoT）推理与Bradley-Terry（BT）模型相结合，通过双加权RL目标来保留偏好建模的归纳偏差。它通过实例级错位权重和组级条件偏好得分来近似BT模型的最大似然目标。DWRL在多个基准和模型规模上均优于现有方法，并产生连贯、可解释的思考过程。


<details>
  <summary>Details</summary>
Motivation: 将强化学习（RL）应用于具有可验证答案的任务的链式思考（CoT）推理，但扩展到更通用的、通常以人类偏好对形式出现的不可验证任务仍然具有挑战性且探索不足。

Method: DWRL通过一个双加权RL目标来整合CoT推理和Bradley-Terry（BT）模型，该目标保留了偏好建模的归纳偏差。DWRL通过两个互补的权重来近似BT模型的最大似然目标：一个实例级的错位权重，强调与人类偏好不一致的训练不足的配对；以及一个组级的（自归一化）条件偏好得分，以促进有希望的思考过程。DWRL通过训练生成式偏好模型（GPM）来生成思考过程并预测人类偏好得分。

Result: 在多个基准测试和模型规模（Llama3和Qwen2.5）上，DWRL的性能始终优于GPM基线和标量模型，同时还能产生连贯、可解释的思考过程。

Conclusion: DWRL是一种通用的、增强推理能力的偏好学习框架，适用于可验证和不可验证的任务。

Abstract: Reinforcement learning (RL) has recently proven effective at scaling
chain-of-thought (CoT) reasoning in large language models on tasks with
verifiable answers. However, extending RL to more general non-verifiable tasks,
typically in the format of human preference pairs, remains both challenging and
underexplored. In this work, we propose Dual-Weighted Reinforcement Learning
(DWRL), a new framework for preference modeling that integrates CoT reasoning
with the Bradley-Terry (BT) model via a dual-weighted RL objective that
preserves preference-modeling inductive bias. DWRL approximates the
maximum-likelihood objective of the BT model with two complementary weights: an
instance-wise misalignment weight, which emphasizes under-trained pairs
misaligned with human preference, and a group-wise (self-normalized)
conditional preference score, which promotes promising thoughts. In this paper,
we apply DWRL to preference modeling by training generative preference models
(GPMs) to first generate a thought and then predict the human preference score.
Across multiple benchmarks and model scales (Llama3 and Qwen2.5), DWRL
consistently outperforms both GPM baselines and scalar models, while producing
coherent, interpretable thoughts. In summary, our results position DWRL as a
general framework for reasoning-enhanced preference learning beyond verifiable
tasks.

</details>


### [244] [Spatiotemporal Transformers for Predicting Avian Disease Risk from Migration Trajectories](https://arxiv.org/abs/2510.15254)
*Dingya Feng,Dingyuan Xue*

Main category: cs.LG

TL;DR: 该研究提出了一个基于Transformer的模型，用于预测迁徙鸟类迁徙终点地区的禽流感爆发风险。


<details>
  <summary>Details</summary>
Motivation: 准确预测禽流感爆发对于野生动物保护和公共卫生至关重要。

Method: 整合了来自Movebank的GPS追踪数据、世界动物卫生组织（WOAH）的疫情记录以及GADM和Natural Earth的地理空间背景数据。使用H3分层地理空间编码处理原始坐标以捕捉空间模式。该模型学习鸟类运动序列中的时空依赖性来估计终点地区的疾病风险。

Result: 在测试集上的评估显示出强大的预测性能，准确率达到0.9821，ROC曲线下面积（AUC）为0.9803，平均精度（AP）为0.9299，F1分数达到0.8836。

Conclusion: 结果表明Transformer架构在禽流感监测预警系统方面具有潜力，能够实现及时的干预和预防策略。

Abstract: Accurate forecasting of avian disease outbreaks is critical for wildlife
conservation and public health. This study presents a Transformer-based
framework for predicting the disease risk at the terminal locations of
migratory bird trajectories. We integrate multi-source datasets, including GPS
tracking data from Movebank, outbreak records from the World Organisation for
Animal Health (WOAH), and geospatial context from GADM and Natural Earth. The
raw coordinates are processed using H3 hierarchical geospatial encoding to
capture spatial patterns. The model learns spatiotemporal dependencies from
bird movement sequences to estimate endpoint disease risk. Evaluation on a
held-out test set demonstrates strong predictive performance, achieving an
accuracy of 0.9821, area under the ROC curve (AUC) of 0.9803, average precision
(AP) of 0.9299, and an F1-score of 0.8836 at the optimal threshold. These
results highlight the potential of Transformer architectures to support
early-warning systems for avian disease surveillance, enabling timely
intervention and prevention strategies.

</details>


### [245] [DRO-InstructZero: Distributionally Robust Prompt Optimization for Large Language Models](https://arxiv.org/abs/2510.15260)
*Yangyang Li*

Main category: cs.LG

TL;DR: DRO-InstructZero 通过贝叶斯优化解决了提示词选择的分布偏移问题，在不牺牲查询效率的情况下提高了模型的鲁棒性和迁移性。


<details>
  <summary>Details</summary>
Motivation: 现有提示词搜索方法在分布偏移和对抗性评估下表现不佳，导致模型在不同环境下效果不一。DRO-InstructZero 旨在解决这一问题，提高提示词的可迁移性。

Method: DRO-InstructZero 将零样本提示词优化构建为一种鲁棒的贝叶斯优化问题，使用 f-散度球定义评估分布的模糊集，并通过鲁棒性获取规则最大化最坏情况下的预期效用。

Result: 在信息到正式改写任务上，准确率从 61.3% 提高到 85-90%；在自动代码调试任务上，在域转移下提高了约 25%；在因果关系等稳定任务上，性能保持在 96% 以上。

Conclusion: DRO-InstructZero 将分布鲁棒优化与提示词学习相结合，为在真实世界不确定性下实现可靠、可迁移的提示词对齐提供了一种即插即用的通用方法。

Abstract: Large language models are highly sensitive to prompt wording. However,
popular automatic prompt search methods, including InstructZero, often degrade
under distribution shift and adversarial evaluation because they optimize
expected performance under a single evaluation distribution. Consequently,
prompts that work in one setting frequently fail to transfer. To address this,
DRO-InstructZero formulates zero-shot prompt optimization as robust Bayesian
optimization. Specifically, an f-divergence ball defines an ambiguity set
around the evaluation distribution, and a robust acquisition rule maximizes
worst-case expected utility while retaining the query efficiency of Bayesian
search. Therefore, the search explicitly targets reliability under distribution
shift rather than average behavior alone. Experiments follow the
instruction-induction protocol with matched query budgets across formality
rewriting, code debugging, and translation. For example, on BIG-Bench
informative-to-formal rewriting, accuracy improves from 61.3 +/- 0.7% to
approximately 85-90%, yielding an absolute gain of about 25-30 points.
Moreover, auto-debugging shows about +25-point gains under domain shift.
Meanwhile, stable tasks such as cause-and-effect remain above 96%, indicating
no loss on in-distribution cases. Furthermore, improvements are consistent
across divergence choices and decoding temperatures. Overall, DRO-InstructZero
connects distributionally robust optimization with prompt learning, offering a
plug-and-play and general approach for reliable, transferable prompt alignment
under real-world uncertainty.

</details>


### [246] [Robust Layerwise Scaling Rules by Proper Weight Decay Tuning](https://arxiv.org/abs/2510.15262)
*Zhiyuan Fan,Yifeng Liu,Qingyue Zhao,Angela Yuan,Quanquan Gu*

Main category: cs.LG

TL;DR: 现代Transformer训练的优化器状态下，$\mu$P方法无法进行学习率迁移。本文提出了一种AdamW的权重衰减缩放规则，通过保持子层增益在不同宽度下不变，实现了学习率和权重衰减的零样本迁移，无需进行超参数搜索。


<details>
  <summary>Details</summary>
Motivation: 在现代Transformer等规模不变的网络中，训练会迅速进入一个由优化器控制的稳态。在此稳态下，归一化层会引起反向传播的尺度敏感性，导致学习率的有效值与网络宽度相关，从而破坏了$\mu$P方法的学习率迁移能力。

Method: 提出了一种AdamW的权重衰减缩放规则，该规则可以保持子层增益在不同网络宽度下保持不变。具体地，对于矩阵类参数，作者观察到其奇异值谱的范数按$\sqrt{\eta/\lambda}$缩放，并且形状近似不变。在宽度缩放为$d$时，最大的奇异值近似按$\sqrt{\eta/\lambda}\cdot d^{0.75}$缩放。结合$\mu$P学习率规则$\eta_2\propto d^{-1}$，可以推导出经验性的权重衰减缩放规则$\lambda_2\propto \sqrt{d}$，从而近似保持子层增益在不同宽度下不变。对于向量类参数，使用$\eta_1=\Theta_d(1)$和$\lambda_1=0$进行训练。

Result: 所提出的方法在LLaMA风格的Transformer和最小化合成设置中得到了验证。通过匹配顶层奇异值，可以检查子层增益不变性。该方法能够实现学习率和权重衰减的零样本迁移，消除了对不同宽度的超参数搜索。

Conclusion: 本文提出的AdamW权重衰减缩放规则，通过显式控制优化器设置的稳态尺度，将$\mu$P方法扩展到了接近初始化之外的更广泛的训练阶段，为在AdamW优化器下实现宽度鲁棒的超参数迁移提供了一个实用的方法。

Abstract: Empirical scaling laws prescribe how to allocate parameters, data, and
compute, while maximal-update parameterization ($\mu$P) enables learning-rate
transfer across widths by equalizing early-time update magnitudes. However, in
modern scale-invariant architectures, training quickly enters an
optimizer-governed steady state where normalization layers create backward
scale sensitivity and the effective learning rate becomes width dependent,
degrading $\mu$P transfer. We address this by introducing a weight-decay
scaling rule for AdamW that preserves sublayer gain across widths. Empirically,
the singular-value spectrum of each matrix parameter scales in norm as
$\sqrt{\eta/\lambda}$ with an approximately invariant shape; under width
scaling $d$, we observe that the top singular value scales approximately as
$\sqrt{\eta/\lambda}\cdot d^{0.75}$. Combining this observation with the $\mu$P
learning-rate rule $\eta_2\propto d^{-1}$ for matrix-like parameters implies an
empirical weight-decay scaling rule $\lambda_2\propto \sqrt{d}$ that
approximately keeps sublayer gains width invariant. Together with vector-like
parameters trained at $\eta_1=\Theta_d(1)$ and $\lambda_1=0$, this yields
\emph{zero-shot} transfer of both learning rate and weight decay from proxy to
target widths, removing per-width sweeps. We validate the rule on LLaMA-style
Transformers and in a minimal synthetic setting, and we provide a simple
diagnostic, matching top singular values, to check sublayer-gain invariance.
Our results extend $\mu$P beyond the near-init regime by explicitly controlling
steady-state scales set by the optimizer, offering a practical recipe for
width-robust hyperparameter transfer under AdamW.

</details>


### [247] [Causal Time Series Modeling of Supraglacial Lake Evolution in Greenland under Distribution Shift](https://arxiv.org/abs/2510.15265)
*Emam Hossain,Muhammad Hasan Ferdous,Devon Dunmire,Aneesh Subramanian,Md Osman Gani*

Main category: cs.LG

TL;DR: 本研究提出了RIC-TSC框架，通过因果发现来改进时空地球观测中的时间序列分类，提高了模型的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前时空地球观测模型常依赖于纯粹的关联特征，这些特征在不同领域之间迁移能力有限，未能充分利用因果建模来发现稳定的、不变的关系。

Method: 利用多模态卫星和再分析数据，结合联合PCMCI+（J-PCMCI+）算法，识别冰缘湖演化过程的区域特异性和不变预测因子及其时间滞后，并将这些因果发现的预测因子用于轻量级分类器。

Result: 在对2018-2019年两个不同融化季的1000个手动标记湖泊的基准测试中，因果模型在分布外评估中的准确率比基于相关性的基线模型高出12.59%。

Conclusion: 因果发现不仅是特征选择的手段，也是实现动态地球表面过程的可泛化、机制性基础模型的途径。

Abstract: Causal modeling offers a principled foundation for uncovering stable,
invariant relationships in time-series data, thereby improving robustness and
generalization under distribution shifts. Yet its potential is underutilized in
spatiotemporal Earth observation, where models often depend on purely
correlational features that fail to transfer across heterogeneous domains. We
propose RIC-TSC, a regionally-informed causal time-series classification
framework that embeds lag-aware causal discovery directly into sequence
modeling, enabling both predictive accuracy and scientific interpretability.
Using multi-modal satellite and reanalysis data-including Sentinel-1 microwave
backscatter, Sentinel-2 and Landsat-8 optical reflectance, and CARRA
meteorological variables-we leverage Joint PCMCI+ (J-PCMCI+) to identify
region-specific and invariant predictors of supraglacial lake evolution in
Greenland. Causal graphs are estimated globally and per basin, with validated
predictors and their time lags supplied to lightweight classifiers. On a
balanced benchmark of 1000 manually labeled lakes from two contrasting melt
seasons (2018-2019), causal models achieve up to 12.59% higher accuracy than
correlation-based baselines under out-of-distribution evaluation. These results
show that causal discovery is not only a means of feature selection but also a
pathway to generalizable and mechanistically grounded models of dynamic Earth
surface processes.

</details>


### [248] [Semi-Supervised Regression with Heteroscedastic Pseudo-Labels](https://arxiv.org/abs/2510.15266)
*Xueqing Sun,Renzhen Wang,Quanziang Wang,Yichen Wu,Xixi Jia,Deyu Meng*

Main category: cs.LG

TL;DR: 该研究提出了一种不确定性感知的伪标签框架，用于半监督回归（SSR）问题，通过双层优化来动态调整伪标签的影响，以减少错误累积和过拟合。


<details>
  <summary>Details</summary>
Motivation: 伪标签在半监督学习中常用，但其在半监督回归（SSR）中的应用因连续输出和异方差噪声使得评估伪标签可靠性困难，易导致错误累积和过拟合。因此，需要一种新的方法来解决SSR中的伪标签问题。

Method: 提出了一种不确定性感知的伪标签框架，该框架从双层优化的角度动态调整伪标签的影响。通过联合最小化所有数据上的经验风险和优化不确定性估计以增强标记数据上的泛化能力，该方法有效减轻了不可靠伪标签的影响。

Result: 通过理论分析和在多个基准SSR数据集上的广泛实验，验证了该方法的有效性。实验结果表明，该方法在鲁棒性和性能上均优于现有方法。

Conclusion: 所提出的不确定性感知伪标签框架能够有效解决半监督回归中的伪标签问题，提高模型的性能和鲁棒性。

Abstract: Pseudo-labeling is a commonly used paradigm in semi-supervised learning, yet
its application to semi-supervised regression (SSR) remains relatively
under-explored. Unlike classification, where pseudo-labels are discrete and
confidence-based filtering is effective, SSR involves continuous outputs with
heteroscedastic noise, making it challenging to assess pseudo-label
reliability. As a result, naive pseudo-labeling can lead to error accumulation
and overfitting to incorrect labels. To address this, we propose an
uncertainty-aware pseudo-labeling framework that dynamically adjusts
pseudo-label influence from a bi-level optimization perspective. By jointly
minimizing empirical risk over all data and optimizing uncertainty estimates to
enhance generalization on labeled data, our method effectively mitigates the
impact of unreliable pseudo-labels. We provide theoretical insights and
extensive experiments to validate our approach across various benchmark SSR
datasets, and the results demonstrate superior robustness and performance
compared to existing methods. Our code is available at
https://github.com/sxq/Heteroscedastic-Pseudo-Labels.

</details>


### [249] [Foundation Models for Scientific Discovery: From Paradigm Enhancement to Paradigm Transition](https://arxiv.org/abs/2510.15280)
*Fan Liu,Jindong Han,Tengfei Lyu,Weijia Zhang,Zhe-Rui Yang,Lu Dai,Cancheng Liu,Hao Liu*

Main category: cs.LG

TL;DR: This paper argues that foundation models (FMs) are not just improving current scientific methods but are creating a new scientific paradigm. It proposes a three-stage framework (Meta-Scientific Integration, Hybrid Human-AI Co-Creation, and Autonomous Scientific Discovery) to describe this evolution and reviews current FM applications, risks, and future directions.


<details>
  <summary>Details</summary>
Motivation: The increasing capability of foundation models (FMs) like GPT-4 and AlphaFold raises a fundamental question about their impact on scientific research: are they merely enhancing existing methods, or are they redefining the scientific process itself?

Method: The paper proposes a three-stage framework (Meta-Scientific Integration, Hybrid Human-AI Co-Creation, and Autonomous Scientific Discovery) to analyze the evolution of scientific paradigms driven by FMs. It reviews current applications and emerging capabilities of FMs across various scientific domains and identifies potential risks and future research directions.

Result: The paper reviews current applications of FMs in science, illustrating their role in enhancing existing workflows and acting as collaborators. It also identifies emerging capabilities that suggest FMs are moving towards autonomous scientific discovery.

Conclusion: Foundation models are catalyzing a transition to a new scientific paradigm, moving from enhancing traditional workflows to enabling hybrid human-AI co-creation and ultimately to autonomous scientific discovery. The paper aims to guide the scientific community in understanding this transformation and shaping the future of scientific research.

Abstract: Foundation models (FMs), such as GPT-4 and AlphaFold, are reshaping the
landscape of scientific research. Beyond accelerating tasks such as hypothesis
generation, experimental design, and result interpretation, they prompt a more
fundamental question: Are FMs merely enhancing existing scientific
methodologies, or are they redefining the way science is conducted? In this
paper, we argue that FMs are catalyzing a transition toward a new scientific
paradigm. We introduce a three-stage framework to describe this evolution: (1)
Meta-Scientific Integration, where FMs enhance workflows within traditional
paradigms; (2) Hybrid Human-AI Co-Creation, where FMs become active
collaborators in problem formulation, reasoning, and discovery; and (3)
Autonomous Scientific Discovery, where FMs operate as independent agents
capable of generating new scientific knowledge with minimal human intervention.
Through this lens, we review current applications and emerging capabilities of
FMs across existing scientific paradigms. We further identify risks and future
directions for FM-enabled scientific discovery. This position paper aims to
support the scientific community in understanding the transformative role of
FMs and to foster reflection on the future of scientific discovery. Our project
is available at
https://github.com/usail-hkust/Awesome-Foundation-Models-for-Scientific-Discovery.

</details>


### [250] [Small Ensemble-based Data Assimilation: A Machine Learning-Enhanced Data Assimilation Method with Limited Ensemble Size](https://arxiv.org/abs/2510.15284)
*Zhilin Li,Zhou Yao,Xianglong Li,Zeng Liu,Zhaokuan Lu,Shanlin Xu,Seungnam Kim,Guangyao Wang*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Ensemble-based data assimilation (DA) methods have become increasingly
popular due to their inherent ability to address nonlinear dynamic problems.
However, these methods often face a trade-off between analysis accuracy and
computational efficiency, as larger ensemble sizes required for higher accuracy
also lead to greater computational cost. In this study, we propose a novel
machine learning-based data assimilation approach that combines the traditional
ensemble Kalman filter (EnKF) with a fully connected neural network (FCNN).
Specifically, our method uses a relatively small ensemble size to generate
preliminary yet suboptimal analysis states via EnKF. A FCNN is then employed to
learn and predict correction terms for these states, thereby mitigating the
performance degradation induced by the limited ensemble size. We evaluate the
performance of our proposed EnKF-FCNN method through numerical experiments
involving Lorenz systems and nonlinear ocean wave field simulations. The
results consistently demonstrate that the new method achieves higher accuracy
than traditional EnKF with the same ensemble size, while incurring negligible
additional computational cost. Moreover, the EnKF-FCNN method is adaptable to
diverse applications through coupling with different models and the use of
alternative ensemble-based DA methods.

</details>


### [251] [Identifying internal patterns in (1+1)-dimensional directed percolation using neural networks](https://arxiv.org/abs/2510.15294)
*Danil Parkhomenko,Pavel Ovchinnikov,Konstantin Soldatov,Vitalii Kapitan,Gennady Y. Chitov*

Main category: cs.LG

TL;DR: In this paper, a neural network combining CNN, TCN, and GRU is proposed for automatic detection and classification of phase transitions and hidden percolation patterns in a (1+1)-dimensional replication process. The network is trained on raw data, eliminating manual feature extraction, and successfully reproduces the phase diagram and assigns phase labels, demonstrating its ability to extract hierarchical structures from numerical experiment data.


<details>
  <summary>Details</summary>
Motivation: The motivation is to develop a neural network-based method for automatically detecting phase transitions and classifying hidden percolation patterns in a (1+1)-dimensional replication process, without requiring manual feature extraction.

Method: A neural network model combining CNN, TCN, and GRU is used. This network is trained directly on raw configurations from numerical experiments.

Result: The network successfully reproduces the phase diagram and assigns phase labels to configurations.

Conclusion: Deep neural network architectures are capable of extracting hierarchical structures directly from the raw data of numerical experiments.

Abstract: In this paper we present a neural network-based method for the automatic
detection of phase transitions and classification of hidden percolation
patterns in a (1+1)-dimensional replication process. The proposed network model
is based on the combination of CNN, TCN and GRU networks, which are trained
directly on raw configurations without any manual feature extraction. The
network reproduces the phase diagram and assigns phase labels to
configurations. It shows that deep architectures are capable of extracting
hierarchical structures from the raw data of numerical experiments.

</details>


### [252] [DFCA: Decentralized Federated Clustering Algorithm](https://arxiv.org/abs/2510.15300)
*Jonas Kirch,Sebastian Becker,Tiago Koketsu Rodrigues,Stefan Harmeling*

Main category: cs.LG

TL;DR: DFCA是一种完全去中心化的联邦聚类学习算法，它允许客户端在没有中央协调的情况下协同训练特定于簇的模型，并能在稀疏连接下保持聚类性能。


<details>
  <summary>Details</summary>
Motivation: 现有的簇状联邦学习方法（如IFCA）依赖中央服务器进行协调，存在瓶颈和单点故障问题，限制了其在去中心化学习场景中的应用。

Method: DFCA采用顺序运行平均法聚合邻居的模型更新，在模型更新到达时进行通信，这是一种通信高效的替代批处理聚合的方法，同时保持了聚类性能。

Result: 实验表明，DFCA在各种数据集上表现优于其他去中心化算法，并且在稀疏连通性下，其性能与中心化的IFCA相当。

Conclusion: DFCA是一种实用且鲁棒的去中心化联邦学习算法，适用于动态的、真实的去中心化网络。

Abstract: Clustered Federated Learning has emerged as an effective approach for
handling heterogeneous data across clients by partitioning them into clusters
with similar or identical data distributions. However, most existing methods,
including the Iterative Federated Clustering Algorithm (IFCA), rely on a
central server to coordinate model updates, which creates a bottleneck and a
single point of failure, limiting their applicability in more realistic
decentralized learning settings. In this work, we introduce DFCA, a fully
decentralized clustered FL algorithm that enables clients to collaboratively
train cluster-specific models without central coordination. DFCA uses a
sequential running average to aggregate models from neighbors as updates
arrive, providing a communication-efficient alternative to batch aggregation
while maintaining clustering performance. Our experiments on various datasets
demonstrate that DFCA outperforms other decentralized algorithms and performs
comparably to centralized IFCA, even under sparse connectivity, highlighting
its robustness and practicality for dynamic real-world decentralized networks.

</details>


### [253] [On the Generalization Properties of Learning the Random Feature Models with Learnable Activation Functions](https://arxiv.org/abs/2510.15327)
*Zailin Ma,Jiansheng Yang,Yaodong Yang*

Main category: cs.LG

TL;DR: 该论文研究了具有可学习激活函数 (RFLAF) 的随机特征模型，并提供了其泛化特性的最尖锐界限。


<details>
  <summary>Details</summary>
Motivation: 研究 RFLAF 的泛化特性，并改进其学习所需的特征数量界限。

Method: 提出了一种数据依赖的采样方案来生成特征，并推导了统一的定理来描述特征数量的复杂性。讨论了普通采样方案和数据依赖的杠杆加权方案的结果。提出了一种寻找近似核并应用杠杆加权采样的算法。

Result: 在回归和分类任务中，通过加权采样，MSE 损失的界限从 $\Omega(1/\epsilon^2)$ 改进到 $\tilde{\Omega}((1/\epsilon)^{1/t})$，在 Gram 矩阵具有有限秩的情况下甚至改进到 $\Omega(1)$。对于 Lipschitz 损失，界限从 $\Omega(1/\epsilon^2)$ 改进到 $\tilde{\Omega}((1/\epsilon^2)^{1/t})$。实验结果表明，加权 RFLAF 与普通采样 RFLAF 相比，在性能相当的情况下所需的特征数量大大减少。

Conclusion: 数据依赖的采样方案，特别是杠杆加权方案，显著提高了 RFLAF 的学习效率，减少了所需的特征数量，并在实验中得到了验证。

Abstract: This paper studies the generalization properties of a recently proposed
kernel method, the Random Feature models with Learnable Activation Functions
(RFLAF). By applying a data-dependent sampling scheme for generating features,
we provide by far the sharpest bounds on the required number of features for
learning RFLAF in both the regression and classification tasks. We provide a
unified theorem that describes the complexity of the feature number $s$, and
discuss the results for the plain sampling scheme and the data-dependent
leverage weighted scheme. Through weighted sampling, the bound on $s$ in the
MSE loss case is improved from $\Omega(1/\epsilon^2)$ to
$\tilde{\Omega}((1/\epsilon)^{1/t})$ in general $(t\geq 1)$, and even to
$\Omega(1)$ when the Gram matrix has a finite rank. For the Lipschitz loss
case, the bound is improved from $\Omega(1/\epsilon^2)$ to
$\tilde{\Omega}((1/\epsilon^2)^{1/t})$. To learn the weighted RFLAF, we also
propose an algorithm to find an approximate kernel and then apply the leverage
weighted sampling. Empirical results show that the weighted RFLAF achieves the
same performances with a significantly fewer number of features compared to the
plainly sampled RFLAF, validating our theories and the effectiveness of this
method.

</details>


### [254] [Backdoor or Manipulation? Graph Mixture of Experts Can Defend Against Various Graph Adversarial Attacks](https://arxiv.org/abs/2510.15333)
*Yuyuan Feng,Bin Ma,Enyan Dai*

Main category: cs.LG

TL;DR: 本研究提出了一种基于混合专家（MoE）架构的统一框架，用于防御图神经网络（GNNs）中的多种图对抗攻击（后门攻击、边操纵和节点注入）。


<details>
  <summary>Details</summary>
Motivation: 现有的GNN防御方法通常只针对单一类型的攻击，缺乏统一的防御策略来同时应对多种威胁。

Method: 研究提出了一种基于互信息（MI）的逻辑多样性损失，鼓励专家关注不同的邻域结构，并引入了一个鲁棒性感知路由器，以识别扰动模式并将受扰动节点自适应地路由到相应的鲁棒专家。

Result: 实验结果表明，该方法在多种对抗攻击场景下，能够有效抵御多种图对抗攻击，展现出优越的鲁棒性。

Conclusion: 所提出的基于MoE的统一框架能够有效防御多种图对抗攻击，并在实验中取得了优于现有方法的性能。

Abstract: Extensive research has highlighted the vulnerability of graph neural networks
(GNNs) to adversarial attacks, including manipulation, node injection, and the
recently emerging threat of backdoor attacks. However, existing defenses
typically focus on a single type of attack, lacking a unified approach to
simultaneously defend against multiple threats. In this work, we leverage the
flexibility of the Mixture of Experts (MoE) architecture to design a scalable
and unified framework for defending against backdoor, edge manipulation, and
node injection attacks. Specifically, we propose an MI-based logic diversity
loss to encourage individual experts to focus on distinct neighborhood
structures in their decision processes, thus ensuring a sufficient subset of
experts remains unaffected under perturbations in local structures. Moreover,
we introduce a robustness-aware router that identifies perturbation patterns
and adaptively routes perturbed nodes to corresponding robust experts.
Extensive experiments conducted under various adversarial settings demonstrate
that our method consistently achieves superior robustness against multiple
graph adversarial attacks.

</details>


### [255] [Sequence Modeling with Spectral Mean Flows](https://arxiv.org/abs/2510.15366)
*Jinwoo Kim,Max Beier,Petar Bevanda,Nayun Kim,Seunghoon Hong*

Main category: cs.LG

TL;DR: 该研究将算子理论应用于序列建模，提出了一种基于隐马尔可夫模型（HMM）的新方法，将序列分布嵌入希尔伯特空间，并通过最大均值差异（MMD）梯度流定义生成过程。为了解决张量计算和采样效率问题，引入了“谱均值流”算法，包括利用算子谱分解的新型神经网络架构和扩展的MMD梯度流，实现了无模拟学习和更快的采样速度，并在时间序列建模任务上取得了有竞争力的结果。


<details>
  <summary>Details</summary>
Motivation: 序列建模中的一个关键问题是如何表示和学习高度非线性和概率性的状态动态。算子理论提供了一种有吸引力的视角，即将动态视为希尔伯特空间中的线性映射，但该视角在序列建模中未被充分利用。

Method: 提出了一种基于算子理论视角的隐马尔可夫模型（HMM）序列建模新方法。具体来说，将完整的序列分布嵌入到乘积希尔伯特空间中的张量表示，并定义了一个基于最大均值差异（MMD）梯度流的生成过程。为解决大张量和采样收敛慢的问题，引入了“谱均值流”算法，包括：1. 利用算子谱分解提出了一种可扩展的序列均值嵌入张量网络分解的新型神经网络架构。2. 将MMD梯度流扩展到时变希尔伯特空间，并与连续性方程联系起来，实现无模拟学习和加速采样。

Result: 所提出的谱均值流算法在多种时间序列建模数据集上取得了具有竞争力的结果。

Conclusion: 该研究成功地将算子理论应用于序列建模，提出了一种新颖且有效的基于谱均值流的序列建模方法，该方法通过张量网络分解和扩展的MMD梯度流，解决了现有方法的挑战，并在实验中证明了其有效性。

Abstract: A key question in sequence modeling with neural networks is how to represent
and learn highly nonlinear and probabilistic state dynamics. Operator theory
views such dynamics as linear maps on Hilbert spaces containing mean embedding
vectors of distributions, offering an appealing but currently overlooked
perspective. We propose a new approach to sequence modeling based on an
operator-theoretic view of a hidden Markov model (HMM). Instead of
materializing stochastic recurrence, we embed the full sequence distribution as
a tensor in the product Hilbert space. A generative process is then defined as
maximum mean discrepancy (MMD) gradient flow in the space of sequences. To
overcome challenges with large tensors and slow sampling convergence, we
introduce spectral mean flows, a novel tractable algorithm integrating two core
concepts. First, we propose a new neural architecture by leveraging spectral
decomposition of linear operators to derive a scalable tensor network
decomposition of sequence mean embeddings. Second, we extend MMD gradient flows
to time-dependent Hilbert spaces and connect them to flow matching via the
continuity equation, enabling simulation-free learning and faster sampling. We
demonstrate competitive results on a range of time-series modeling datasets.
Code is available at https://github.com/jw9730/spectral-mean-flow.

</details>


### [256] [Iterative Refinement of Flow Policies in Probability Space for Online Reinforcement Learning](https://arxiv.org/abs/2510.15388)
*Mingyang Sun,Pengxiang Ding,Weinan Zhang,Donglin Wang*

Main category: cs.LG

TL;DR: 行为克隆策略（如流/扩散策略）在从演示中学习复杂技能方面表现出色，但容易出现分布偏移。标准强化学习方法难以微调这些模型。我们提出了逐步流策略（SWFP）框架，通过将流匹配推理过程离散化为固定步长的欧拉格式，并将其与最优传输中的JKO原理相结合。SWFP将全局流分解为一系列小的、增量式的变换，每个步骤对应一个JKO更新，通过熵正则化实现稳定的在线适应。该方法通过一系列小的流块来微调预训练的流，训练更简单、更快，计算和内存成本更低，并具有基于 Wasserstein 置信区域的可证明稳定性。实验证明SWFP在机器人控制基准测试中具有更高的稳定性、效率和适应性能。


<details>
  <summary>Details</summary>
Motivation: 行为克隆策略容易出现分布偏移，而标准强化学习方法难以微调这些模型。

Method: 提出逐步流策略（SWFP）框架，将流匹配推理过程离散化为固定步长的欧拉格式，并将其与最优传输中的JKO原理相结合。SWFP将全局流分解为一系列小的、增量式的变换，每个步骤对应一个JKO更新，通过熵正则化实现稳定的在线适应。

Result: SWFP通过一系列小的流块来微调预训练的流，训练更简单、更快，计算和内存成本更低，并具有基于 Wasserstein 置信区域的可证明稳定性。实验证明SWFP在机器人控制基准测试中具有更高的稳定性、效率和适应性能。

Conclusion: SWFP框架通过将流匹配推理过程离散化并与JKO原理相结合，有效解决了行为克隆策略的分布偏移问题，并实现了高效、稳定的模型微调和在线适应。

Abstract: While behavior cloning with flow/diffusion policies excels at learning
complex skills from demonstrations, it remains vulnerable to distributional
shift, and standard RL methods struggle to fine-tune these models due to their
iterative inference process and the limitations of existing workarounds. In
this work, we introduce the Stepwise Flow Policy (SWFP) framework, founded on
the key insight that discretizing the flow matching inference process via a
fixed-step Euler scheme inherently aligns it with the variational
Jordan-Kinderlehrer-Otto (JKO) principle from optimal transport. SWFP
decomposes the global flow into a sequence of small, incremental
transformations between proximate distributions. Each step corresponds to a JKO
update, regularizing policy changes to stay near the previous iterate and
ensuring stable online adaptation with entropic regularization. This
decomposition yields an efficient algorithm that fine-tunes pre-trained flows
via a cascade of small flow blocks, offering significant advantages:
simpler/faster training of sub-models, reduced computational/memory costs, and
provable stability grounded in Wasserstein trust regions. Comprehensive
experiments demonstrate SWFP's enhanced stability, efficiency, and superior
adaptation performance across diverse robotic control benchmarks.

</details>


### [257] [Geometric Mixture Models for Electrolyte Conductivity Prediction](https://arxiv.org/abs/2510.15403)
*Anyi Li,Jiacheng Cen,Songyou Li,Mingze Li,Yang Yu,Wenbing Huang*

Main category: cs.LG

TL;DR: 该研究提出了GeoMix框架，一个几何感知框架，用于准确预测离子电导率，解决了现有数据集和模型中的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有研究在离子电导率预测方面面临缺乏高质量基准和混合物系统几何结构/分子间相互作用模型不足的挑战。

Method: 通过整合几何图表示来增强CALiSol和DiffMix数据集，并提出GeoMix框架，该框架利用几何交互网络（GIN）来保持Set-SE(3)等变性，并进行跨分子几何消息传递。

Result: GeoMix在两个数据集上均持续优于多种基线模型（包括MLP、GNN和几何GNN），验证了跨分子几何相互作用和等变消息传递对准确预测的重要性。

Conclusion: 该研究不仅为电解质研究建立了新基准，还提供了一个通用的几何学习框架，促进了能源材料、药物开发及其他领域混合物系统的建模。

Abstract: Accurate prediction of ionic conductivity in electrolyte systems is crucial
for advancing numerous scientific and technological applications. While
significant progress has been made, current research faces two fundamental
challenges: (1) the lack of high-quality standardized benchmarks, and (2)
inadequate modeling of geometric structure and intermolecular interactions in
mixture systems. To address these limitations, we first reorganize and enhance
the CALiSol and DiffMix electrolyte datasets by incorporating geometric graph
representations of molecules. We then propose GeoMix, a novel geometry-aware
framework that preserves Set-SE(3) equivariance-an essential but challenging
property for mixture systems. At the heart of GeoMix lies the Geometric
Interaction Network (GIN), an equivariant module specifically designed for
intermolecular geometric message passing. Comprehensive experiments demonstrate
that GeoMix consistently outperforms diverse baselines (including MLPs, GNNs,
and geometric GNNs) across both datasets, validating the importance of
cross-molecular geometric interactions and equivariant message passing for
accurate property prediction. This work not only establishes new benchmarks for
electrolyte research but also provides a general geometric learning framework
that advances modeling of mixture systems in energy materials, pharmaceutical
development, and beyond.

</details>


### [258] [Online Kernel Dynamic Mode Decomposition for Streaming Time Series Forecasting with Adaptive Windowing](https://arxiv.org/abs/2510.15404)
*Christopher Salazar,Krithika Manohar,Ashis G. Banerjee*

Main category: cs.LG

TL;DR: WORK-DMD是一种结合了随机傅里叶特征和在线动态模式分解（DMD）的流数据实时预测方法，通过显式特征映射捕捉非线性动态，同时保持固定的计算成本和竞争力。它在滚动窗口中使用Sherman-Morrison更新，能够仅从当前数据持续适应动态变化，无需冗长的训练或大量存储。实验表明，WORK-DMD在短期预测方面表现优于现有方法，并且样本效率高，是流数据预测的一种实用替代方案。


<details>
  <summary>Details</summary>
Motivation: 现有的流数据实时预测方法在处理非平稳动态、严格的计算限制和避免灾难性遗忘方面面临挑战，并且在准确性、适应性和效率之间存在权衡，尤其是在计算资源受限的环境中。

Method: WORK-DMD（Windowed Online Random Kernel Dynamic Mode Decomposition）结合了随机傅里叶特征和在线动态模式分解，通过显式特征映射来捕捉非线性动态。它在滚动窗口中使用Sherman-Morrison更新，允许仅从当前数据持续适应动态变化，无需冗长的训练或大量存储。

Result: 在多个领域的基准数据集上的实验表明，WORK-DMD的准确性高于几种最先进的在线预测方法，并且只需要一次数据遍历。它在短期预测方面表现尤为出色，表明核评估与自适应矩阵更新的结合可以实现强大的预测性能，且数据需求极小。

Conclusion: WORK-DMD通过结合核评估和自适应矩阵更新，在数据需求极小的情况下实现了强大的预测性能。这种样本效率为流数据预测应用提供了一种实用的替代深度学习的方法。

Abstract: Real-time forecasting from streaming data poses critical challenges: handling
non-stationary dynamics, operating under strict computational limits, and
adapting rapidly without catastrophic forgetting. However, many existing
approaches face trade-offs between accuracy, adaptability, and efficiency,
particularly when deployed in constrained computing environments. We introduce
WORK-DMD (Windowed Online Random Kernel Dynamic Mode Decomposition), a method
that combines Random Fourier Features with online Dynamic Mode Decomposition to
capture nonlinear dynamics through explicit feature mapping, while preserving
fixed computational cost and competitive predictive accuracy across evolving
data. WORK-DMD employs Sherman-Morrison updates within rolling windows,
enabling continuous adaptation to evolving dynamics from only current data,
eliminating the need for lengthy training or large storage requirements for
historical data. Experiments on benchmark datasets across several domains show
that WORK-DMD achieves higher accuracy than several state-of-the-art online
forecasting methods, while requiring only a single pass through the data and
demonstrating particularly strong performance in short-term forecasting. Our
results show that combining kernel evaluations with adaptive matrix updates
achieves strong predictive performance with minimal data requirements. This
sample efficiency offers a practical alternative to deep learning for streaming
forecasting applications.

</details>


### [259] [ParaFormer: Shallow Parallel Transformers with Progressive Approximation](https://arxiv.org/abs/2510.15425)
*Wei Wang,Xiao-Yong Wei,Qing Li*

Main category: cs.LG

TL;DR: ParaFormer是一种浅层Transformer架构，通过并行分支实现跨层协作，解决了深度Transformer的训练和推理效率问题，并在模型压缩和速度方面表现优越。


<details>
  <summary>Details</summary>
Motivation: 增加模型深度以提高性能（如ResNet、Transformer）带来了训练时间长、推理延迟高和资源受限设备难以部署等问题。

Method: ParaFormer将标准Transformer的层设计成并行分支，并通过算法强制实现跨层协作，以渐进逼近的方式确保每一层都能减少前一层带来的损失，从而加速收敛。

Result: ParaFormer在性能上优于ViT等标准Transformer，支持高达15.07倍的模型压缩，并且在多GPU部署上比FairScale快3.30倍。

Conclusion: 通过对Transformer进行基于万能逼近定理的闭式公式推导，ParaFormer不仅解释了对深度的依赖，还为设计高效的Transformer架构开辟了新途径。

Abstract: The widespread 'deeper is better' philosophy has driven the creation of
architectures like ResNet and Transformer, which achieve high performance by
stacking numerous layers. However, increasing model depth comes with challenges
such as longer training times, higher inference latency, and impracticality on
resource-constrained devices. To address these issues, we propose ParaFormer, a
shallow Transformer architecture designed for true parallelism in both
structure and computation. By formulating standard Transformers as function
approximators in closed-form, our theoretical analysis shows that their
performance relies on inter-layer collaboration for progressive approximation,
rather than depth itself. While deep Transformers enforce this collaboration
through sequential designs, we demonstrate that such collaboration is not
inherently tied to sequential structures. ParaFormer removes the sequential
constraint by organizing layers into parallel branches, enforcing inter-layer
collaboration algorithmically. Specifically, we implement progressive
approximation, ensuring that each new branch further reduces the loss from
preceding branches, enabling faster convergence. Extensive experiments validate
ParaFormer's effectiveness, outperforming standard Transformers like ViT.
Moreover, ParaFormer supports up to 15.07x model compression and facilitates
model expansion for adaptive continuous learning. Experimental results on
multi-GPU deployment demonstrate that ParaFormer is 3.30x faster than widely
used parallelism solutions such as FairScale. These advancements stem from our
closed-form formulation of Transformers based on the Universal Approximation
Theorem, which not only explains the ``depth belief'' but also opens new
avenues for designing efficient Transformer architectures. Source code:
https://(open-upon-acceptance)

</details>


### [260] [Safe, Efficient, and Robust Reinforcement Learning for Ranking and Diffusion Models](https://arxiv.org/abs/2510.15429)
*Shashank Gupta*

Main category: cs.LG

TL;DR: 本论文研究了如何设计安全、样本高效且鲁棒的强化学习（RL）方法，并将其应用于排序、推荐和文本到图像扩散模型。


<details>
  <summary>Details</summary>
Motivation: 在排序系统中实现安全部署，并在单动作老虎机问题中提高样本效率，以及在生成RL中平衡效率和效果。

Method: 通过上下文老虎机RL的视角，研究了用于排序系统的安全强化学习方法，包括导出暴露泛化界限和提出反事实风险最小化目标。研究了用于单动作老虎机问题的各种离策略估计器，并提出了一个最优基线。最后，研究了PPO和REINFORCE算法在生成RL中的权衡，并提出了LOOP算法。

Result: 提出的反事实风险最小化目标能够保证在稀疏反馈下性能不低于记录策略。最优基线被证明可以最小化评估和策略梯度方差。LOOP算法在保持PPO样本效率的同时，提高了生成与文本属性的一致性。

Conclusion: 强化学习方法可以通过改进理论和算法设计，在保证安全性的前提下，提高样本效率和鲁棒性，并应用于包括排序、推荐和文本到图像生成在内的多个领域。

Abstract: This dissertation investigates how reinforcement learning (RL) methods can be
designed to be safe, sample-efficient, and robust. Framed through the unifying
perspective of contextual-bandit RL, the work addresses two major application
domains - ranking and recommendation, and text-to-image diffusion models. The
first part of the thesis develops theory and algorithms for safe deployment in
ranking systems. An exposure-based generalisation bound is derived, leading to
a counterfactual risk-minimisation objective whose solution is guaranteed not
to underperform the logging policy, even with sparse feedback. This guarantee
is extended to doubly robust estimators, enabling safety even under adversarial
or misspecified user models and offering practitioners explicit control over
permissible utility loss. The second part turns to single-action bandits, where
various off-policy estimators are unified within a baseline-correction
framework. A closed-form optimal baseline is proposed and shown to minimise
both evaluation and policy-gradient variance, thereby improving off-policy
learning reliability. The final part examines the trade-offs between efficiency
and effectiveness in generative RL. A systematic study of PPO and REINFORCE
motivates the Leave-One-Out PPO (LOOP) algorithm, which combines multiple
diffusion trajectories with a REINFORCE-style baseline inside PPO's clipped
objective. LOOP achieves PPO-level sample efficiency while producing
generations that align more faithfully with textual attributes.

</details>


### [261] [A Theoretical Study on Bridging Internal Probability and Self-Consistency for LLM Reasoning](https://arxiv.org/abs/2510.15444)
*Zhi Zhou,Yuhao Tan,Zenan Li,Yuan Yao,Lan-Zhe Guo,Yu-Feng Li,Xiaoxing Ma*

Main category: cs.LG

TL;DR: 本文提出了RPC，一种结合了置信度估计、推理剪枝和置信度一致性（RPC）的混合方法，用于提高大型语言模型（LLMs）的推理性能，同时降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的测试时推断方法（如自洽性、困惑度）在理论基础和实际应用中存在局限性，例如自洽性估计误差高，困惑度存在模型误差和收敛问题。

Method: 本文提出了RPC方法，包括“困惑度一致性”和“推理剪枝”两个关键部分。“困惑度一致性”结合了自洽性和困惑度的优点，提高了估计误差的收敛速度，并保持了模型误差。“推理剪枝”通过消除低概率的推理路径来防止模型性能下降。

Result: 通过理论分析和在七个基准数据集上的实验，证明了RPC能有效降低推理误差，将估计误差的收敛速度从线性提高到指数级。RPC在推理性能上可与自洽性媲美，同时提高了置信度的可靠性，并将采样成本降低了50%。

Conclusion: RPC是一种有前景的方法，可以提高LLMs的推理性能，并且具有更可靠的置信度估计和更低的计算成本。

Abstract: Test-time scaling seeks to improve the reasoning performance of large
language models (LLMs) by adding computational resources. A prevalent approach
within the field is sampling-based test-time scaling methods, which enhance
reasoning by generating multiple reasoning paths for a given input during
inference. However, despite its practical success, the theoretical foundations
remain underexplored. In this paper, we provide the first theoretical framework
for analyzing sampling-based test-time scaling methods, grounded in the
perspective of confidence estimation. Based on the framework, we analyze two
dominant paradigms: self-consistency and perplexity, and reveal key
limitations: self-consistency suffers from high estimation error while
perplexity exhibits substantial modeling error and possible degradation of the
estimation error convergence. To address these limitations, we introduce RPC, a
hybrid method that leverages our theoretical insights through two key
components: Perplexity Consistency and Reasoning Pruning. Perplexity
Consistency combines the strengths of self-consistency and perplexity, boosting
the convergence rate of estimation error from linear to exponential while
preserving model error. Reasoning Pruning prevents degradation by eliminating
low-probability reasoning paths. Both theoretical analysis and empirical
results across seven benchmark datasets demonstrate that RPC has a strong
potential for reducing reasoning error. Notably, RPC achieves reasoning
performance comparable to self-consistency while not only enhancing confidence
reliability but also reducing sampling costs by 50%. The code and resources are
available at https://wnjxyk.github.io/RPC.

</details>


### [262] [Particle Dynamics for Latent-Variable Energy-Based Models](https://arxiv.org/abs/2510.15447)
*Shiqin Tang,Shuxin Zhuang,Rong Feng,Runsheng Yu,Hongzong Li,Youzhi Zhang*

Main category: cs.LG

TL;DR: LVEBMs是具有潜在变量的能量模型，通过将最大似然训练视为鞍点问题来训练，并使用Langevin更新和随机参数上升，不需要判别器或辅助网络。


<details>
  <summary>Details</summary>
Motivation: LVEBMs具有表示性生成建模能力和捕捉隐藏结构的能力，但其最大似然训练可被视为鞍点问题。

Method: 将最大似然训练重构为潜在变量和联合流形上的分布鞍点问题，并将内部更新视为耦合的Wasserstein梯度流。该算法结合了Langevin更新和随机参数上升，无需判别器或辅助网络。

Result: 证明了在标准光滑性和耗散性假设下，KL散度和Wasserstein-2距离的衰减率的存在性和收敛性。与仅限于了简化的近似后验的界限相比，得到了更严格的ELBO，并在数值物理系统上表现具有竞争力。

Conclusion: 提出的新算法通过鞍点优化和Langevin动力学，在潜在变量能量模型上实现了具有理论保证和良好经验性能的生成建模。

Abstract: Latent-variable energy-based models (LVEBMs) assign a single normalized
energy to joint pairs of observed data and latent variables, offering
expressive generative modeling while capturing hidden structure. We recast
maximum-likelihood training as a saddle problem over distributions on the
latent and joint manifolds and view the inner updates as coupled Wasserstein
gradient flows. The resulting algorithm alternates overdamped Langevin updates
for a joint negative pool and for conditional latent particles with stochastic
parameter ascent, requiring no discriminator or auxiliary networks. We prove
existence and convergence under standard smoothness and dissipativity
assumptions, with decay rates in KL divergence and Wasserstein-2 distance. The
saddle-point view further yields an ELBO strictly tighter than bounds obtained
with restricted amortized posteriors. Our method is evaluated on numerical
approximations of physical systems and performs competitively against
comparable approaches.

</details>


### [263] [Expediting Reinforcement Learning by Incorporating Knowledge About Temporal Causality in the Environment](https://arxiv.org/abs/2510.15456)
*Jan Corazza,Hadi Partovi Aria,Daniel Neider,Zhe Xu*

Main category: cs.LG

TL;DR: PRMs combined with causal information in the form of Temporal Logic-based Causal Diagrams can expedite policy learning and aid the transfer of task specifications to new environments, with a theoretical convergence guarantee and empirical validation.


<details>
  <summary>Details</summary>
Motivation: Traditional PRMs are difficult to modify and design by hand, hindering the use of high-level causal knowledge and the transfer of reward formalisms to new domains. 

Method: This paper proposes a novel method to incorporate causal information, in the form of Temporal Logic-based Causal Diagrams, into the PRM reward formalism.

Result: The proposed method expedites policy learning and aids the transfer of task specifications to new environments. A theoretical result about convergence to the optimal policy is provided, and the method's strengths are demonstrated empirically.

Conclusion: The novel method effectively addresses the limitations of traditional PRMs by incorporating causal information, leading to improved policy learning and transferability.

Abstract: Reinforcement learning (RL) algorithms struggle with learning optimal
policies for tasks where reward feedback is sparse and depends on a complex
sequence of events in the environment. Probabilistic reward machines (PRMs) are
finite-state formalisms that can capture temporal dependencies in the reward
signal, along with nondeterministic task outcomes. While special RL algorithms
can exploit this finite-state structure to expedite learning, PRMs remain
difficult to modify and design by hand. This hinders the already difficult
tasks of utilizing high-level causal knowledge about the environment, and
transferring the reward formalism into a new domain with a different causal
structure. This paper proposes a novel method to incorporate causal information
in the form of Temporal Logic-based Causal Diagrams into the reward formalism,
thereby expediting policy learning and aiding the transfer of task
specifications to new environments. Furthermore, we provide a theoretical
result about convergence to optimal policy for our method, and demonstrate its
strengths empirically.

</details>


### [264] [Learning to Answer from Correct Demonstrations](https://arxiv.org/abs/2510.15464)
*Nirmit Joshi,Gene Li,Siddharth Bhandari,Shiva Prasad Kasiviswanathan,Cong Ma,Nathan Srebro*

Main category: cs.LG

TL;DR: 在存在多个正确答案的情况下，从最优策略的演示中学习生成答案的问题，其中不明确观察到奖励。提出了一种超越最大似然估计的新方法，该方法具有对奖励类基数（cardinality）对数关系的样本复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有方法假设演示者属于低复杂度策略类，从而需要最大似然估计。然而，我们提出一个更宽松的假设，即奖励模型（指定哪些答案是正确的）属于低基数类，并表明最大似然估计在这种情况下可能失效。

Method: 提出了一种新的方法，该方法在奖励模型属于低基数类的假设下，从最优策略的演示中进行学习，其中不明确观察到奖励。该方法具有对奖励类基数（cardinality）对数关系的样本复杂度。

Result: 与最大似然估计相比，新方法在奖励模型属于低基数类的情况下，能够更有效地学习。

Conclusion: 在从正确演示中学习时，应考虑最大似然估计以外的方法。

Abstract: We study the problem of learning to generate an answer (or completion) to a
question (or prompt), where there could be multiple correct answers, any one of
which is acceptable at test time. Learning is based on demonstrations of some
correct answer to each training question, as in Supervised Fine Tuning (SFT).
We formalize the problem as offline imitation learning in contextual bandits,
with demonstrations from some optimal policy, without explicitly observed
rewards. Prior work assumes that the demonstrator belongs to a low-complexity
policy class, which motivates maximum likelihood estimation (i.e., log-loss
minimization). In contrast, we propose relying only on the reward model
(specifying which answers are correct) being in a low-cardinality class, which
we argue is a weaker assumption. We show that likelihood maximization methods
can fail in this case, and instead devise an alternative novel approach that
learns with sample complexity logarithmic in the cardinality of the reward
class. Our work motivates looking beyond likelihood maximization when learning
from correct demonstrations.

</details>


### [265] [Adversary-Free Counterfactual Prediction via Information-Regularized Representations](https://arxiv.org/abs/2510.15479)
*Shiqin Tang,Rong Feng,Shuxin Zhuang,Hongzong Li,Youzhi Zhang*

Main category: cs.LG

TL;DR: 本文提出一种基于信息论的方法来解决带偏倚的个体处理效应估计问题，通过学习与处理无关的表征来预测结果，从而移除处理与协变量的依赖关系。


<details>
  <summary>Details</summary>
Motivation: 在存在处理分配偏倚的情况下，准确估计个体处理效应（ITE）是一个挑战。现有的方法，如对抗性训练，可能存在训练不稳定的问题。

Method: 本文提出一种基于信息论的方法，学习一个随机表征Z，使其能够预测结果（Y）但与处理（T）的相互信息最小化（I(Z;T)）。通过推导一个变分目标函数来上界信息项，并结合监督解码器，形成一个稳定且有理论依据的训练标准。该框架还可以扩展到动态设置。

Result: 在数值模拟和真实世界临床数据集上的评估结果显示，该方法在似然性、个体处理效应误差和策略评估等指标上优于现有的平衡、重加权和对抗性基线方法，同时避免了对抗性方案的训练不稳定和调优负担。

Conclusion: 所提出的基于信息论的方法在处理分配偏倚的情况下能够进行有效的反事实预测，相比现有方法具有更好的性能和稳定性。

Abstract: We study counterfactual prediction under assignment bias and propose a
mathematically grounded, information-theoretic approach that removes
treatment-covariate dependence without adversarial training. Starting from a
bound that links the counterfactual-factual risk gap to mutual information, we
learn a stochastic representation Z that is predictive of outcomes while
minimizing I(Z; T). We derive a tractable variational objective that
upper-bounds the information term and couples it with a supervised decoder,
yielding a stable, provably motivated training criterion. The framework extends
naturally to dynamic settings by applying the information penalty to sequential
representations at each decision time. We evaluate the method on controlled
numerical simulations and a real-world clinical dataset, comparing against
recent state-of-the-art balancing, reweighting, and adversarial baselines.
Across metrics of likelihood, counterfactual error, and policy evaluation, our
approach performs favorably while avoiding the training instabilities and
tuning burden of adversarial schemes.

</details>


### [266] [OffSim: Offline Simulator for Model-based Offline Inverse Reinforcement Learning](https://arxiv.org/abs/2510.15495)
*Woo-Jin Ahn,Sang-Ryul Baek,Yong-Jun Lee,Hyun-Duck Choi,Myo-Taeg Lim*

Main category: cs.LG

TL;DR: OffSim是一个基于模型的离线逆强化学习框架，可以从专家轨迹中学习环境动态和奖励函数，从而在无需与真实环境交互的情况下进行离线策略训练。


<details>
  <summary>Details</summary>
Motivation: 手动定义奖励函数和开发交互式模拟器耗时耗力，OffSim旨在解决此问题。

Method: OffSim联合优化了一个高熵转移模型和一个基于IRL的奖励函数，以模仿环境动力学和奖励结构。OffSim$^+$扩展通过引入边际奖励来处理多数据集设置。

Result: OffSim在MuJoCo实验中取得了显著的性能提升，优于现有的离线IRL方法。

Conclusion: OffSim框架能够有效地从专家数据中学习环境动态和奖励，从而实现无需真实环境交互的离线策略训练，并且具有良好的泛化性和鲁棒性。

Abstract: Reinforcement learning algorithms typically utilize an interactive simulator
(i.e., environment) with a predefined reward function for policy training.
Developing such simulators and manually defining reward functions, however, is
often time-consuming and labor-intensive. To address this, we propose an
Offline Simulator (OffSim), a novel model-based offline inverse reinforcement
learning (IRL) framework, to emulate environmental dynamics and reward
structure directly from expert-generated state-action trajectories. OffSim
jointly optimizes a high-entropy transition model and an IRL-based reward
function to enhance exploration and improve the generalizability of the learned
reward. Leveraging these learned components, OffSim can subsequently train a
policy offline without further interaction with the real environment.
Additionally, we introduce OffSim$^+$, an extension that incorporates a
marginal reward for multi-dataset settings to enhance exploration. Extensive
MuJoCo experiments demonstrate that OffSim achieves substantial performance
gains over existing offline IRL methods, confirming its efficacy and
robustness.

</details>


### [267] [The Road Less Traveled: Enhancing Exploration in LLMs via Sequential Sampling](https://arxiv.org/abs/2510.15502)
*Shijia Kang,Muhan Zhang*

Main category: cs.LG

TL;DR: SESA通过顺序生成解决方案草图来解决强化学习中LLM探索不足和熵崩溃的问题，提高了路径多样性和整体性能。


<details>
  <summary>Details</summary>
Motivation: 强化学习（RL）在增强大型语言模型（LLM）的推理能力方面发挥了关键作用，但它经常遭受有限的探索和熵崩溃的困扰，这会导致模型倾向于利用狭窄的解决方案集，从而导致采样多样性丧失，并阻碍RL进一步提高性能。在并行采样方法中，从同一分布中抽取多个输出，这可能导致模型收敛到相似的解决方案，使得这一问题更加严重。

Method: 提出了一种新颖的顺序采样框架SESA，通过依次生成多样化的解决方案草图，然后将其扩展为完整的推理路径来缓解这一挑战。这种方法通过将每个新输出条件化在先前的输出上，确保了更广泛的探索，在整个过程中促进了多样性，并防止了策略崩溃。

Result: 在合成任务上的实验表明，顺序采样在路径多样性和从崩溃中恢复方面始终优于传统的RL方法。在实际任务上的进一步评估表明，SESA提高了有效策略的探索和LLM的整体性能。在三个代理基准测试中，SESA将成功率比基础模型提高了+0.25、+0.42和+0.07个百分点（相较于基线RL，相对提高了211%），凸显了其探索优势。

Conclusion: SESA通过顺序生成解决方案草图来解决强化学习中LLM探索不足和熵崩溃的问题，提高了路径多样性和整体性能。这项工作引入了一种结构化的探索方法，为RL训练的LLM实现了更有效和多样化的推理铺平了道路。

Abstract: Reinforcement learning (RL) has been pivotal in enhancing the reasoning
capabilities of large language models (LLMs), but it often suffers from limited
exploration and entropy collapse, where models exploit a narrow set of
solutions, leading to a loss of sampling diversity and subsequently preventing
RL from further improving performance. This issue is exacerbated in parallel
sampling methods, where multiple outputs are drawn from the same distribution,
potentially causing the model to converge to similar solutions. We propose
SESA, a novel SEquential SAmpling framework that mitigates this challenge by
generating diverse solution sketches sequentially before expanding them into
full reasoning paths. This approach ensures broader exploration by conditioning
each new output on previous ones, promoting diversity throughout the process
and preventing policy collapse. Our experiments on a synthetic task show that
sequential sampling consistently outperforms traditional RL methods in terms of
path diversity and recovery from collapse. Further evaluations on real-world
tasks demonstrate that SESA improves both the exploration of valid strategies
and the overall performance of LLMs. On three agent benchmarks, SESA lifts
success rates by $+0.25$, $+0.42$, and $+0.07$ absolute over the base model (up
to an additional $211\%$ relative improvement over baseline RL), underscoring
its exploration advantage. This work introduces a structured approach to
exploration, paving the way for more effective and diverse reasoning in
RL-trained LLMs. Our code is released at https://github.com/MuLabPKU/sesa.

</details>


### [268] [Language Models are Injective and Hence Invertible](https://arxiv.org/abs/2510.15511)
*Giorgos Nikolaou,Tommaso Mencattini,Donato Crisostomi,Andrea Santilli,Yannis Panagakis,Emanuele Rodola'*

Main category: cs.LG

TL;DR: Transformer 模型在初始化时是注入的，并且在训练过程中保持这种注入性，这意味着它们是无损的。我们提出了一种名为 SipIt 的算法，可以从模型的隐藏激活中精确地重建输入文本。


<details>
  <summary>Details</summary>
Motivation: 研究 Transformer 模型表示是否会丢失信息，挑战了它们固有的非注入性观点。

Method: 首先，在数学上证明了 Transformer 模型是注入的和无损的；其次，通过大量的碰撞测试进行实证验证；最后，提出 SipIt 算法，用于从隐藏激活中重建输入文本。

Result: 证明了 Transformer 模型是注入的和无损的，并且 SipIt 算法能够精确地重建输入文本，具有线性时间保证。

Conclusion: Transformer 模型的注入性是一个基本且可利用的属性，对模型的透明度、可解释性和安全性有直接影响。

Abstract: Transformer components such as non-linear activations and normalization are
inherently non-injective, suggesting that different inputs could map to the
same output and prevent exact recovery of the input from a model's
representations. In this paper, we challenge this view. First, we prove
mathematically that transformer language models mapping discrete input
sequences to their corresponding sequence of continuous representations are
injective and therefore lossless, a property established at initialization and
preserved during training. Second, we confirm this result empirically through
billions of collision tests on six state-of-the-art language models, and
observe no collisions. Third, we operationalize injectivity: we introduce
SipIt, the first algorithm that provably and efficiently reconstructs the exact
input text from hidden activations, establishing linear-time guarantees and
demonstrating exact invertibility in practice. Overall, our work establishes
injectivity as a fundamental and exploitable property of language models, with
direct implications for transparency, interpretability, and safe deployment.

</details>


### [269] [Revisiting Knowledge Distillation: The Hidden Role of Dataset Size](https://arxiv.org/abs/2510.15516)
*Giulia Lanzillotta,Felix Sarnthein,Gil Kur,Thomas Hofmann,Bobby He*

Main category: cs.LG

TL;DR: 知识蒸馏在小数据集环境下表现出更强的“数据效率”，并且现有理论中“暗知识”假说得到进一步验证，而“标签平滑”假说被证伪。


<details>
  <summary>Details</summary>
Motivation: 现有关于知识蒸馏（KD）的研究大多集中在模型大小和泛化能力上，对于KD在不同数据集大小下的表现和原理尚不明确。

Method: 通过在多种数据集、任务和模型架构上进行实验，研究KD在数据集大小变化下的表现，并检验现有KD理论（如标签平滑和暗知识假说）。

Result: 在低数据量情况下，KD的效果不仅得以保留，反而有所增强，这种现象被称为KD的数据效率。研究结果证伪了KD等同于标签平滑的假设，并为暗知识假说提供了更多证据。

Conclusion: 数据集大小是影响KD机制的一个基本但被忽视的因素。KD在小数据集环境下表现出更强的数据效率，并且暗知识假说比标签平滑假说更能解释KD的现象。

Abstract: The concept of knowledge distillation (KD) describes the training of a
student model from a teacher model and is a widely adopted technique in deep
learning. However, it is still not clear how and why distillation works.
Previous studies focus on two central aspects of distillation: model size, and
generalisation. In this work we study distillation in a third dimension:
dataset size. We present a suite of experiments across a wide range of
datasets, tasks and neural architectures, demonstrating that the effect of
distillation is not only preserved but amplified in low-data regimes. We call
this newly discovered property the data efficiency of distillation. Equipped
with this new perspective, we test the predictive power of existing theories of
KD as we vary the dataset size. Our results disprove the hypothesis that
distillation can be understood as label smoothing, and provide further evidence
in support of the dark knowledge hypothesis. Finally, we analyse the impact of
modelling factors such as the objective, scale and relative number of samples
on the observed phenomenon. Ultimately, this work reveals that the dataset size
may be a fundamental but overlooked variable in the mechanisms underpinning
distillation.

</details>


### [270] [An Empirical Study on MC Dropout--Based Uncertainty--Error Correlation in 2D Brain Tumor Segmentation](https://arxiv.org/abs/2510.15541)
*Saumya B*

Main category: cs.LG

TL;DR: MC Dropout在脑肿瘤MRI分割中的不确定性估计与分割错误之间的相关性很弱，尤其是在边界区域，这表明需要改进不确定性估计方法。


<details>
  <summary>Details</summary>
Motivation: 评估MC Dropout在脑肿瘤MRI分割中估计模型不确定性以识别分割错误（尤其是在肿瘤边界附近）的有效性。

Method: 在四种不同的数据增强设置下（无、水平翻转、旋转、缩放）训练U-Net模型，并计算50次随机前向传播的MC Dropout不确定性，然后使用Pearson和Spearman系数计算不确定性与像素级错误之间的相关性。

Result: 全局相关性较弱（r ≈ 0.30-0.38），边界相关性可忽略不计（|r| < 0.05）。不同数据增强设置之间的差异在统计学上显著，但实际意义不大。

Conclusion: MC Dropout不确定性为定位边界错误提供的线索有限，凸显了在医学图像分割中采用替代或混合不确定性估计方法的必要性。

Abstract: Accurate brain tumor segmentation from MRI is vital for diagnosis and
treatment planning. Although Monte Carlo (MC) Dropout is widely used to
estimate model uncertainty, its effectiveness in identifying segmentation
errors -- especially near tumor boundaries -- remains unclear. This study
empirically examines the relationship between MC Dropout--based uncertainty and
segmentation error in 2D brain tumor MRI segmentation using a U-Net trained
under four augmentation settings: none, horizontal flip, rotation, and scaling.
Uncertainty was computed from 50 stochastic forward passes and correlated with
pixel-wise errors using Pearson and Spearman coefficients. Results show weak
global correlations ($r \approx 0.30$--$0.38$) and negligible boundary
correlations ($|r| < 0.05$). Although differences across augmentations were
statistically significant ($p < 0.001$), they lacked practical relevance. These
findings suggest that MC Dropout uncertainty provides limited cues for boundary
error localization, underscoring the need for alternative or hybrid uncertainty
estimation methods in medical image segmentation.

</details>


### [271] [Doubly Robust Estimation of Causal Effects in Strategic Equilibrium Systems](https://arxiv.org/abs/2510.15555)
*Sibo Xiao*

Main category: cs.LG

TL;DR: SDR是一种结合了博弈论和双重稳健估计的因果推断新框架，用于处理内生性处理分配问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法有效处理由策略性主体行为引起的内生性处理分配问题，并且难以在包含策略性行为的场景下进行因果推断。

Method: 提出SDR估计器，该估计器整合了策略性均衡模型和双重稳健估计。

Result: SDR估计器在理论上被证明是一致且渐近正态的。在实际评估中，SDR相比基线方法在不同策略强度下偏差减少了7.6%-29.3%，并具有良好的可扩展性。

Conclusion: SDR为在策略性参与者对干预措施做出反应的环境中进行可靠的因果推断提供了一种原则性的方法。

Abstract: We introduce the Strategic Doubly Robust (SDR) estimator, a novel framework
that integrates strategic equilibrium modeling with doubly robust estimation
for causal inference in strategic environments. SDR addresses endogenous
treatment assignment arising from strategic agent behavior, maintaining double
robustness while incorporating strategic considerations. Theoretical analysis
confirms SDR's consistency and asymptotic normality under strategic
unconfoundedness. Empirical evaluations demonstrate SDR's superior performance
over baseline methods, achieving 7.6\%-29.3\% bias reduction across varying
strategic strengths and maintaining robust scalability with agent populations.
The framework provides a principled approach for reliable causal inference when
agents respond strategically to interventions.

</details>


### [272] [On the Neural Feature Ansatz for Deep Neural Networks](https://arxiv.org/abs/2510.15563)
*Edward Tansley,Estelle Massart,Coralia Cartis*

Main category: cs.LG

TL;DR: 神经网络的特征学习是理解深度学习的基础。神经特征假设（NFA）指出，训练后，网络第一层权重的Gram矩阵与输入有关的平均梯度外积（AGOP）的某个幂$\\alpha > 0$成正比。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在将神经特征假设（NFA）从两层线性网络推广到具有 L（L >= 2）层的网络，并研究其在不平衡初始化和存在非线性激活函数时的适用性。

Method: 通过数学推导证明了 NFA 在 L 层网络中以指数 \\alpha = 1/L 成立，并证明了在应用权重衰减的情况下，NFA 在不平衡初始化下渐近成立。通过数值实验验证了理论结果。

Result: NFA 适用于 L 层网络，指数为 \\alpha = 1/L，证明了 NFA 的深度依赖性。在有权重衰减的情况下，NFA 在不平衡初始化下渐近成立。发现了 NFA 在某些具有非线性激活函数的网络架构中不成立的反例。

Conclusion: NFA 及其深度依赖性得到了理论和数值上的证实，但其在包含非线性激活函数的网络中的适用性受到限制。

Abstract: Understanding feature learning is an important open question in establishing
a mathematical foundation for deep neural networks. The Neural Feature Ansatz
(NFA) states that after training, the Gram matrix of the first-layer weights of
a deep neural network is proportional to some power $\alpha>0$ of the average
gradient outer product (AGOP) of this network with respect to its inputs.
Assuming gradient flow dynamics with balanced weight initialization, the NFA
was proven to hold throughout training for two-layer linear networks with
exponent $\alpha = 1/2$ (Radhakrishnan et al., 2024). We extend this result to
networks with $L \geq 2$ layers, showing that the NFA holds with exponent
$\alpha = 1/L$, thus demonstrating a depth dependency of the NFA. Furthermore,
we prove that for unbalanced initialization, the NFA holds asymptotically
through training if weight decay is applied. We also provide counterexamples
showing that the NFA does not hold for some network architectures with
nonlinear activations, even when these networks fit arbitrarily well the
training data. We thoroughly validate our theoretical results through numerical
experiments across a variety of optimization algorithms, weight decay rates and
initialization schemes.

</details>


### [273] [Attn-JGNN: Attention Enhanced Join-Graph Neural Networks](https://arxiv.org/abs/2510.15583)
*Jixin Zhang,Yong Lai*

Main category: cs.LG

TL;DR: Attn-JGNN通过在连接图中使用注意力机制来解决#SAT问题，提高了求解精度。


<details>
  <summary>Details</summary>
Motivation: 解决#SAT问题并提高求解精度。

Method: 使用树分解将CNF公式编码为连接图，然后在连接图上进行迭代消息传递，并通过学习分割函数来近似模型数量。在连接图的簇内和簇之间应用注意力机制，以关注关键变量和簇，减少冗余计算。

Result: Attn-JGNN模型在实验中取得了比其他神经网络方法更好的结果。

Conclusion: Attn-JGNN模型在解决#SAT问题上表现优于其他神经网络方法。

Abstract: We propose an Attention Enhanced Join-Graph Neural Networks(Attn-JGNN) model
for solving #SAT problems, which significantly improves the solving accuracy.
Inspired by the Iterative Join Graph Propagation (IJGP) algorithm, Attn-JGNN
uses tree decomposition to encode the CNF formula into a join-graph, then
performs iterative message passing on the join-graph, and finally approximates
the model number by learning partition functions. In order to further improve
the accuracy of the solution, we apply the attention mechanism in and between
clusters of the join-graphs, which makes Attn-JGNN pay more attention to the
key variables and clusters in probabilistic inference, and reduces the
redundant calculation. Finally, our experiments show that our Attn-JGNN model
achieves better results than other neural network methods.

</details>


### [274] [GRATING: Low-Latency and Memory-Efficient Semantic Selection on Device](https://arxiv.org/abs/2510.15620)
*Jiahao Zhou,Chengliang Lin,Dingji Li,Mingkai Dong,Haibo Chen*

Main category: cs.LG

TL;DR: GRATING是一个用于在边缘设备上进行语义Top-K选择的训练无关推理系统，通过渐进式聚类剪枝和I/O与计算重叠来显著降低延迟和内存使用，同时不损失精度。


<details>
  <summary>Details</summary>
Motivation: 边缘设备上的AI服务（如检索增强生成、代理记忆和个性化推荐）需要语义Top-K选择，但其延迟和内存需求对端到端预算造成了挑战。

Method: GRATING通过保持所有候选者的全局视图，利用渐进式聚类剪枝来降低延迟，并通过双层滑动窗口和分块执行来重叠I/O和计算，从而限制峰值内存使用。

Result: 在Apple M2和RTX 5070上，GRATING在具有0.6B到8B参数的重排器上，延迟最多降低89.0%，峰值内存最多降低94.9%，且无精度损失。在三个实际的设备端AI应用中，GRATING的延迟降低了11.6%-51.0%，峰值内存降低了18.6%-77.8%。

Conclusion: GRATING在效率和可部署性方面取得了显著的改进，解决了设备端AI服务中的延迟和内存瓶颈问题。

Abstract: Semantic top-K selection with cross-encoder rerankers underpins of on-device
AI services, such as retrieval-augmented generation, agent memory, and
personalized recommendation. However, its latency and memory demands dominate
end-to-end budgets on edge hardware. Revisiting the objective of top-K
selection, we reveal that only relative rankings matter, not exact
per-candidate scores. We further observe sequence-level sparsity: relative
rankings stabilize early in intermediate layers, allowing pruning opportunities
prior to completing full inference.
  Building on this insight, we propose monolithic forwarding and develop a
training-free inference system, GRATING. By maintaining a global view of all
candidates, it reduces latency through progressive cluster pruning. It also
bounds peak memory usage by strategically overlapping I/O with computation via
dual-layer sliding window and chunked execution. We evaluate GRATING against
state-of-the-art baselines on rerankers from 0.6B to 8B parameters across Apple
M2 and RTX 5070. GRATING consistently reduces latency by up to 89.0% and peak
memory by up to 94.9% in microbenchmarks, without any loss in precision. Across
three real-world on-device AI applications, GRATING lowers latency by
11.6%-51.0% and peak memory by 18.6%-77.8%, demonstrating substantial
improvements in efficiency and deployability.

</details>


### [275] [CQD-SHAP: Explainable Complex Query Answering via Shapley Values](https://arxiv.org/abs/2510.15623)
*Parsa Abbasi,Stefan Heindorf*

Main category: cs.LG

TL;DR: CQD-SHAP框架通过计算查询的每个部分对特定答案排名的贡献来解释神经 CQA 模型，这些贡献基于 Shapley 值。


<details>
  <summary>Details</summary>
Motivation: 现有的神经和神经符号 CQA 方法大多是黑盒模型，缺乏可解释性，这引发了用户信任问题。现有的神经符号方法虽然允许跟踪中间结果，但未能解释查询不同部分的重要性。

Method: 提出 CQD-SHAP 框架，该框架基于合作博弈论中的 Shapley 值，计算查询的每个部分对特定答案排名的贡献。该框架解释了利用可以从不完整 KG 推断新知识的神经网络预测器而不是仅仅依赖 KG 中现有事实的符号方法的价值。

Result: 自动评估表明，CQD-SHAP 在必要和充分的解释方面是有效的，并且与各种基线相比，对于大多数查询类型都有效。

Conclusion: CQD-SHAP 框架通过提供基于 Shapley 值的可解释性，解决了神经 CQA 方法中的用户信任问题，并证明了其在解释查询部分贡献方面的有效性。

Abstract: Complex query answering (CQA) goes beyond the well-studied link prediction
task by addressing more sophisticated queries that require multi-hop reasoning
over incomplete knowledge graphs (KGs). Research on neural and neurosymbolic
CQA methods is still an emerging field. Almost all of these methods can be
regarded as black-box models, which may raise concerns about user trust.
Although neurosymbolic approaches like CQD are slightly more interpretable,
allowing intermediate results to be tracked, the importance of different parts
of the query remains unexplained. In this paper, we propose CQD-SHAP, a novel
framework that computes the contribution of each query part to the ranking of a
specific answer. This contribution explains the value of leveraging a neural
predictor that can infer new knowledge from an incomplete KG, rather than a
symbolic approach relying solely on existing facts in the KG. CQD-SHAP is
formulated based on Shapley values from cooperative game theory and satisfies
all the fundamental Shapley axioms. Automated evaluation of these explanations
in terms of necessary and sufficient explanations, and comparisons with various
baselines, shows the effectiveness of this approach for most query types.

</details>


### [276] [Fast and Compact Tsetlin Machine Inference on CPUs Using Instruction-Level Optimization](https://arxiv.org/abs/2510.15653)
*Yefan Zeng,Shengyu Duan,Rishad Shafik,Alex Yakovlev*

Main category: cs.LG

TL;DR: Tsetlin Machine (TM) 通过利用指令级位运算和提前退出机制，实现了CPU上的高效推理，推理时间减少高达96.71%。


<details>
  <summary>Details</summary>
Motivation: 利用 Tsetlin Machine (TM) 在资源受限设备（如CPU）上进行高速推理的潜力，因其逻辑驱动操作适合并行执行。

Method: 提出了一种高效的TM软件实现，利用指令级位运算进行模型压缩和加速；引入了提前退出机制，利用TM的AND子句评估来避免不必要的计算；提出了一种字面重排策略，通过统计分析最大化提前退出的可能性。

Result: 在ARM处理器的gem5模拟器上进行的实验表明，与传统的基于整数的TM实现相比，推理时间减少了高达96.71%，同时代码密度相当。

Conclusion: 所提出的优化TM实现显著提高了在资源受限设备上的推理速度，同时保持了模型密度。

Abstract: The Tsetlin Machine (TM) offers high-speed inference on resource-constrained
devices such as CPUs. Its logic-driven operations naturally lend themselves to
parallel execution on modern CPU architectures. Motivated by this, we propose
an efficient software implementation of the TM by leveraging instruction-level
bitwise operations for compact model representation and accelerated processing.
To further improve inference speed, we introduce an early exit mechanism, which
exploits the TM's AND-based clause evaluation to avoid unnecessary
computations. Building upon this, we propose a literal Reorder strategy
designed to maximize the likelihood of early exits. This strategy is applied
during a post-training, pre-inference stage through statistical analysis of all
literals and the corresponding actions of their associated Tsetlin Automata
(TA), introducing negligible runtime overhead. Experimental results using the
gem5 simulator with an ARM processor show that our optimized implementation
reduces inference time by up to 96.71% compared to the conventional
integer-based TM implementations while maintaining comparable code density.

</details>


### [277] [WARP-LUTs - Walsh-Assisted Relaxation for Probabilistic Look Up Tables](https://arxiv.org/abs/2510.15655)
*Lino Gerlach,Liv Våge,Thore Gerlach,Elliott Kauffman*

Main category: cs.LG

TL;DR: WARP-LUTs是一种新的梯度学习方法，比DLGNs收敛更快，参数更少，并且有望扩展到更高输入的逻辑块。


<details>
  <summary>Details</summary>
Motivation: 现有的乘法器模型（如DLGNs）虽然在准确性、资源使用和延迟方面表现出色，但在训练期间计算成本高且泛化能力不足。

Method: 提出了一种名为WARP-LUTs的新型梯度学习方法，该方法使用少得多的可训练参数来学习逻辑门组合。

Result: WARP-LUTs在CIFAR-10数据集上实现了比DLGNs更快的收敛速度，同时保持了相当的准确性。

Conclusion: WARP-LUTs在逻辑门学习方面取得了显著的进步，并且有潜力扩展到更高输入的逻辑块，为在FPGA上的高效部署和实时科学应用提供了新的可能性。

Abstract: Fast and efficient machine learning is of growing interest to the scientific
community and has spurred significant research into novel model architectures
and hardware-aware design. Recent hard? and software co-design approaches have
demonstrated impressive results with entirely multiplication-free models.
Differentiable Logic Gate Networks (DLGNs), for instance, provide a
gradient-based framework for learning optimal combinations of low-level logic
gates, setting state-of-the-art trade-offs between accuracy, resource usage,
and latency. However, these models suffer from high computational cost during
training and do not generalize well to logic blocks with more inputs. In this
work, we introduce Walsh-Assisted Relaxation for Probabilistic Look-Up Tables
(WARP-LUTs) - a novel gradient-based method that efficiently learns
combinations of logic gates with substantially fewer trainable parameters. We
demonstrate that WARP-LUTs achieve significantly faster convergence on CIFAR-10
compared to DLGNs, while maintaining comparable accuracy. Furthermore, our
approach suggests potential for extension to higher-input logic blocks,
motivating future research on extremely efficient deployment on modern FPGAs
and its real-time science applications.

</details>


### [278] [CarBoN: Calibrated Best-of-N Sampling Improves Test-time Reasoning](https://arxiv.org/abs/2510.15674)
*Yung-Chen Tang,Pin-Yu Chen,Andrea Cavallaro*

Main category: cs.LG

TL;DR: 通过引入CarBoN框架，使用输入特定的温度T和加性偏移向量δ来校准模型logits，提高大型语言模型在推理任务中的效率和准确性，无需重新训练模型。


<details>
  <summary>Details</summary>
Motivation: 现有的测试时间扩展方法（如Best-of-$N$采样）在增加N时回报递减，效率低下，尤其是在推理任务中。

Method: 提出了一种通用的测试时间校准框架，并在此框架下提出了CarBoN（Calibrated Best-of-$N$）方法。CarBoN分两个阶段：首先探索解空间，然后学习一个输入特定的logits校准（通过温度T和加性偏移向量δ），以引导生成过程走向更可靠的推理路径。

Result: 在MATH-500和AIME-2024数据集上，CarBoN的效率得到了显著提升，以少4倍的采样次数达到相同准确率，并在固定预算下通常能获得更高的准确率。同时，分析了T和δ在输出多样性和正确性之间的平衡作用，并证明该框架可推广到步长采样策略。

Conclusion: CarBoN提供了一种无需LLM重新训练即可提高推理任务效率和准确性的有效方法，并且该框架具有理论保证，能够提高有限采样下的期望奖励下界。

Abstract: Allocating more computation during inference time (test-time scaling)
improves language model performance, especially for reasoning tasks. However,
popular methods like Best-of-$N$ sampling often show diminishing returns as $N$
increases. To address this inefficiency, we introduce a general test-time
calibration framework that adaptively modifies the model toward high-reward
reasoning paths, with theoretical guarantees of improving the lower bound of
expected reward under finite sampling, all without large language model (LLM)
retraining. Within this framework, we propose CarBoN (Calibrated Best-of-$N$),
a two-phase method that first explores the solution space and then learns a
calibration of the logits via an input-specific temperature $T$ and additive
shift vector $\delta$, guiding generation toward more reliable reasoning.
Experiments on MATH-500 and AIME-2024 show that CarBoN improves efficiency,
with up to $4\times$ fewer rollouts to reach the same accuracy, while often
achieving higher accuracy under fixed budgets. We also analyze the
complementary roles of $T$ and $\delta$ in balancing output diversity and
correctness, and demonstrate that the framework also generalizes to step-level
sampling strategies such as beam search. For more information, please refer to
our project page at huggingface.co/spaces/TrustSafeAI/Test-Time-Calibration.

</details>


### [279] [KS-Net: Multi-layer network model for determining the rotor type from motor parameters in interior PMSMs](https://arxiv.org/abs/2510.15688)
*Kivanc Dogan,Ahmet Orhan*

Main category: cs.LG

TL;DR: 通过机器学习方法，特别是立方支持向量机（Cubic SVM）和二次支持向量机（Quadratic SVM），可以高精度地识别电机转子形状，为电机设计和故障诊断提供了一种比传统有限元方法（FEM）更快、成本更低的方法。


<details>
  <summary>Details</summary>
Motivation: 电机驱动系统对高效率和精确控制的需求，导致了对Interior Permanent Magnet Synchronous Motors (IPMSMs)的广泛采用，而转子几何形状显著影响其性能。传统依赖有限元方法（FEM）进行转子形状分析计算成本高昂。

Method: 研究提出了一种基于机器学习的方法，利用电磁参数来分类IPMSMs的转子形状（2D型、V型、Nabla型），并将其与传统的FEM方法进行了比较。具体地，评估了一个自定义的深度学习模型KS-Net，并与Cubic SVM、Quadratic SVM、Fine KNN、Cosine KNN和Fine Tree等算法进行了比较。使用了包含9,000个样本的平衡数据集，并通过10倍交叉验证进行测试，评估指标包括准确率、精确率、召回率和F1分数。

Result: 立方SVM和二次SVM算法实现了100%的准确率，对所有样本进行了完美分类。用户自定义的KS-Net模型达到了99.98%的准确率，仅有两个错误分类，显示出与经典方法相当的竞争力。

Conclusion: 研究证明，利用数据驱动的方法可以高精度地预测IPMSMs的转子形状，为替代计算成本高昂的FEM分析提供了一种快速且经济高效的途径。这些发现为加速电机设计过程、开发自动化转子识别系统以及在工程应用中实现数据驱动的故障诊断奠定了坚实基础。

Abstract: The demand for high efficiency and precise control in electric drive systems
has led to the widespread adoption of Interior Permanent Magnet Synchronous
Motors (IPMSMs). The performance of these motors is significantly influenced by
rotor geometry. Traditionally, rotor shape analysis has been conducted using
the finite element method (FEM), which involves high computational costs. This
study aims to classify the rotor shape (2D type, V type, Nabla type) of IPMSMs
using electromagnetic parameters through machine learning-based methods and to
demonstrate the applicability of this approach as an alternative to classical
methods. In this context, a custom deep learning model, KS-Net, developed by
the user, was comparatively evaluated against Cubic SVM, Quadratic SVM, Fine
KNN, Cosine KNN, and Fine Tree algorithms. The balanced dataset, consisting of
9,000 samples, was tested using 10-fold cross-validation, and performance
metrics such as accuracy, precision, recall, and F1-score were employed. The
results indicate that the Cubic SVM and Quadratic SVM algorithms classified all
samples flawlessly, achieving 100% accuracy, while the KS-Net model achieved
99.98% accuracy with only two misclassifications, demonstrating competitiveness
with classical methods. This study shows that the rotor shape of IPMSMs can be
predicted with high accuracy using data-driven approaches, offering a fast and
cost-effective alternative to FEM-based analyses. The findings provide a solid
foundation for accelerating motor design processes, developing automated rotor
identification systems, and enabling data-driven fault diagnosis in engineering
applications.

</details>


### [280] [Constrained Adversarial Perturbation](https://arxiv.org/abs/2510.15699)
*Virendra Nishad,Bhaskar Mukhoty,Hilal AlQuabeh,Sandeep K. Shukla,Sayak Ray Chowdhury*

Main category: cs.LG

TL;DR: 该研究提出了一种名为CAP的算法，用于生成满足特定领域约束的通用对抗性扰动（UAP），提高了攻击成功率并降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有UAP方法忽略了特定领域的约束，导致对抗样本的不可靠性，限制了其在现实世界中的应用。

Method: 提出了一种基于增广拉格朗日函数的最小-最大优化问题来强制执行多种约束，并使用基于梯度的交替优化策略来解决该问题，提出CAP算法。

Result: CAP算法在金融、IT网络和网络物理系统等多个领域都取得了更高的攻击成功率，并且显著减少了运行时间。该方法还可以推广到单个对抗性扰动，并实现了类似的效果。

Conclusion: CAP算法能够有效地生成满足领域约束的对抗性扰动，提高了对抗样本的实用性，并且提出了一种从数据中学习约束的方法，使其具有广泛的适用性。

Abstract: Deep neural networks have achieved remarkable success in a wide range of
classification tasks. However, they remain highly susceptible to adversarial
examples - inputs that are subtly perturbed to induce misclassification while
appearing unchanged to humans. Among various attack strategies, Universal
Adversarial Perturbations (UAPs) have emerged as a powerful tool for both
stress testing model robustness and facilitating scalable adversarial training.
Despite their effectiveness, most existing UAP methods neglect domain specific
constraints that govern feature relationships. Violating such constraints, such
as debt to income ratios in credit scoring or packet flow invariants in network
communication, can render adversarial examples implausible or easily
detectable, thereby limiting their real world applicability.
  In this work, we advance universal adversarial attacks to constrained feature
spaces by formulating an augmented Lagrangian based min max optimization
problem that enforces multiple, potentially complex constraints of varying
importance. We propose Constrained Adversarial Perturbation (CAP), an efficient
algorithm that solves this problem using a gradient based alternating
optimization strategy. We evaluate CAP across diverse domains including
finance, IT networks, and cyber physical systems, and demonstrate that it
achieves higher attack success rates while significantly reducing runtime
compared to existing baselines. Our approach also generalizes seamlessly to
individual adversarial perturbations, where we observe similar strong
performance gains. Finally, we introduce a principled procedure for learning
feature constraints directly from data, enabling broad applicability across
domains with structured input spaces.

</details>


### [281] [ProofOptimizer: Training Language Models to Simplify Proofs without Human Demonstrations](https://arxiv.org/abs/2510.15700)
*Alex Gu,Bartosz Piotrowski,Fabian Gloeckle,Kaiyu Yang,Aram H. Markosyan*

Main category: cs.LG

TL;DR: ProofOptimizer是一个首个无需人工干预即可简化Lean证明的语言模型，通过专家迭代和强化学习进行训练，能将现有最先进的RL训练证明器产生的证明长度大幅缩短，并在miniF2F、PutnamBench和Seed-Prover的IMO 2025证明上分别实现了87%、57%和49%的长度缩减，同时简化后的证明在Lean中检查速度更快，并能通过作为监督微调的训练数据来提高下游证明器的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）在处理由强化学习（RL）训练的证明器产生的冗长、复杂的数学证明时存在困难，而这些证明对于人类来说难以理解，限制了其在数学洞见方面的应用。然而，用于证明简化的训练数据稀缺，因此需要一个能够自主简化证明的模型。

Method: ProofOptimizer通过专家迭代和强化学习进行训练，并利用Lean系统进行验证和提供训练信号。在推理时，该模型在一个迭代的证明缩短工作流中运行，逐步减小证明的长度。

Result: ProofOptimizer在miniF2F基准上将证明长度减少了87%，在PutnamBench上减少了57%，在Seed-Prover的IMO 2025证明上减少了49%。此外，简化后的证明在Lean中检查速度更快，并且作为监督微调的训练数据时，能够进一步提高下游证明器的性能。

Conclusion: ProofOptimizer在证明简化方面取得了显著进展，能够生成更简洁、更易于理解和检查的数学证明，同时还能提升其他证明工具的性能。

Abstract: Neural theorem proving has advanced rapidly in the past year, reaching IMO
gold-medalist capabilities and producing formal proofs that span thousands of
lines. Although such proofs are mechanically verified by formal systems like
Lean, their excessive length renders them difficult for humans to comprehend
and limits their usefulness for mathematical insight. Proof simplification is
therefore a critical bottleneck. Yet, training data for this task is scarce,
and existing methods -- mainly agentic scaffolding with off-the-shelf LLMs --
struggle with the extremely long proofs generated by RL-trained provers. We
introduce ProofOptimizer, the first language model trained to simplify Lean
proofs without requiring additional human supervision. ProofOptimizer is
trained via expert iteration and reinforcement learning, using Lean to verify
simplifications and provide training signal. At inference time, it operates
within an iterative proof-shortening workflow, progressively reducing proof
length. Experiments show that ProofOptimizer substantially compresses proofs
generated by state-of-the-art RL-trained provers on standard benchmarks,
reducing proof length by 87% on miniF2F, 57% on PutnamBench, and 49% on
Seed-Prover's IMO 2025 proofs. Beyond conciseness, the simplified proofs check
faster in Lean and further improve downstream prover performance when reused as
training data for supervised finetuning.

</details>


### [282] [ProSh: Probabilistic Shielding for Model-free Reinforcement Learning](https://arxiv.org/abs/2510.15720)
*Edwin Hamel-De le Court,Gaspard Ohlmann,Francesco Belardinelli*

Main category: cs.LG

TL;DR: ProSh是一种无模型安全强化学习算法，通过风险预算和学习到的成本批评来增强约束MDP，以在成本约束下提供安全保证，并在确定性环境中保持最优性。


<details>
  <summary>Details</summary>
Motivation: 开发不仅性能最优而且能提供形式化安全保证的可部署强化学习系统。

Method: ProSh通过引入风险预算来增强约束MDP状态空间，并利用学习到的成本批评对策略分布应用保护机制，以确保采样动作在期望上是安全的。

Result: 该算法能够保证在期望成本下的安全性，并且在确定性环境中可以保持最优性。在温和且实际可行的假设下，ProSh在训练期间也能保证安全性。

Conclusion: ProSh是一种有效的无模型安全强化学习算法，通过整合风险预算和学习到的成本批评，在满足成本约束的同时提供了安全保证，并且在训练过程中也表现出良好的安全性。

Abstract: Safety is a major concern in reinforcement learning (RL): we aim at
developing RL systems that not only perform optimally, but are also safe to
deploy by providing formal guarantees about their safety. To this end, we
introduce Probabilistic Shielding via Risk Augmentation (ProSh), a model-free
algorithm for safe reinforcement learning under cost constraints. ProSh
augments the Constrained MDP state space with a risk budget and enforces safety
by applying a shield to the agent's policy distribution using a learned cost
critic. The shield ensures that all sampled actions remain safe in expectation.
We also show that optimality is preserved when the environment is
deterministic. Since ProSh is model-free, safety during training depends on the
knowledge we have acquired about the environment. We provide a tight
upper-bound on the cost in expectation, depending only on the backup-critic
accuracy, that is always satisfied during training. Under mild, practically
achievable assumptions, ProSh guarantees safety even at training time, as shown
in the experiments.

</details>


### [283] [RLAF: Reinforcement Learning from Automaton Feedback](https://arxiv.org/abs/2510.15728)
*Mahyar Alinejad,Alvaro Velasquez,Yue Wang,George Atia*

Main category: cs.LG

TL;DR: 本研究提出一种基于自动机反馈的强化学习方法，通过从确定性有限自动机(DFA)推导偏好来指导学习，替代了传统方法中的显式奖励函数。


<details>
  <summary>Details</summary>
Motivation: 在具有复杂、依赖历史的奖励结构的环境中，传统强化学习方法面临严峻挑战。

Method: 提出一种新方法，利用自动机结构生成轨迹偏好，用于学习奖励函数，无需手动设计奖励。该框架包含静态方法（直接用学习到的奖励函数进行策略优化）和动态方法（通过迭代更新持续改进奖励函数和策略）。

Result: 在离散和连续环境中，该方法使强化学习代理能够学习到有效的策略，在具有时间依赖性的任务中表现优于传统奖励工程和基于自动机的基线方法（如奖励机和LTL引导方法）。

Conclusion: 基于自动机的偏好在处理非马尔可夫奖励方面具有优势，为传统奖励建模提供了一种可扩展、高效且独立于人类的替代方案。此外，研究证明了该方法在标准假设下可以学习到接近最优的策略。

Abstract: Reinforcement Learning (RL) in environments with complex, history-dependent
reward structures poses significant challenges for traditional methods. In this
work, we introduce a novel approach that leverages automaton-based feedback to
guide the learning process, replacing explicit reward functions with
preferences derived from a deterministic finite automaton (DFA). Unlike
conventional approaches that use automata for direct reward specification, our
method employs the structure of the DFA to generate preferences over
trajectories that are used to learn a reward function, eliminating the need for
manual reward engineering. Our framework introduces a static approach that uses
the learned reward function directly for policy optimization and a dynamic
approach that involves continuous refining of the reward function and policy
through iterative updates until convergence.
  Our experiments in both discrete and continuous environments demonstrate that
our approach enables the RL agent to learn effective policies for tasks with
temporal dependencies, outperforming traditional reward engineering and
automaton-based baselines such as reward machines and LTL-guided methods. Our
results highlight the advantages of automaton-based preferences in handling
non-Markovian rewards, offering a scalable, efficient, and human-independent
alternative to traditional reward modeling. We also provide a convergence
guarantee showing that under standard assumptions our automaton-guided
preference-based framework learns a policy that is near-optimal with respect to
the true non-Markovian objective.

</details>


### [284] [A Comprehensive Evaluation of Graph Neural Networks and Physics Informed Learning for Surrogate Modelling of Finite Element Analysis](https://arxiv.org/abs/2510.15750)
*Nayan Kumar Singh*

Main category: cs.LG

TL;DR: 图神经网络（GNN）和3D U-Net在模拟有限元分析（FEA）方面，GNN表现优于U-Net。结合物理信息（PINN）和课程学习策略可以提高准确性和稳定性。MPNN PINN在预测性能、模型大小和推理速度之间取得了最佳平衡，是最实用的解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统的有限元分析（FEA）计算成本高，不适用于设计优化。深度学习模型可以作为替代方案，但选择能够精确模拟FEA的架构是一个挑战。

Method: 本文评估了图神经网络（GNNs）和3D U-Nets作为参数化工字梁有限元分析（FEA）的替代模型。提出了一种基于Navier Cauchy方程的物理信息神经网络（PINN）框架。采用课程学习策略，先进行数据预训练，然后进行物理信息微调。

Result: GNN在精度上优于U-Net。GCN的相对L2误差为8.7%，而U-Net最佳模型（带注意力机制）为13.0%。MPNN和Graph Transformer的相对L2误差分别为3.5%和2.6%。PINN将误差最多降低了11.3%。Graph Transformer虽然最准确，但推理速度比MPNN PINN慢37.5%。

Conclusion: PINN增强的MPNN（MPNN PINN）在预测性能、模型大小和推理速度方面取得了最佳平衡，是最实用的FEA替代解决方案。

Abstract: Although Finite Element Analysis (FEA) is an integral part of the product
design lifecycle, the analysis is computationally expensive, making it
unsuitable for many design optimization problems. The deep learning models can
be a great solution. However, selecting the architecture that emulates the FEA
with great accuracy is a challenge. This paper presents a comprehensive
evaluation of graph neural networks (GNNs) and 3D U-Nets as surrogates for FEA
of parametric I-beams. We introduce a Physics-Informed Neural Network (PINN)
framework, governed by the Navier Cauchy equations, to enforce physical laws.
Crucially, we demonstrate that a curriculum learning strategy, pretraining on
data followed by physics informed fine tuning, is essential for stabilizing
training. Our results show that GNNs fundamentally outperform the U-Net. Even
the worst performer among GNNs, the GCN framework, achieved a relative L2 error
of 8.7% while the best framework among U Net, U Net with attention mechanism
trained on high resolution data, achieved 13.0% score. Among the graph-based
architectures, the Message Passing Neural Networks (MPNN) and Graph
Transformers achieved the highest accuracy, achieving a relative L2 score of
3.5% and 2.6% respectively. The inclusion of physics fundamental laws (PINN)
significantly improved the generalization, reducing error by up to 11.3% on
high-signal tasks. While the Graph Transformer is the most accurate model, it
is more 37.5% slower during inference when compared to second best model, MPNN
PINN. The PINN enhanced MPNN (MPNN PINN) provides the most practical solution.
It offers a good compromise between predictive performance, model size, and
inference speed.

</details>


### [285] [SAMix: Calibrated and Accurate Continual Learning via Sphere-Adaptive Mixup and Neural Collapse](https://arxiv.org/abs/2510.15751)
*Trung-Anh Dang,Vincent Nguyen,Ngoc-Son Vu,Christel Vrain*

Main category: cs.LG

TL;DR: 本研究提出了一种名为Sphere-Adaptive Mixup（SAMix）的新方法，通过自适应混合策略增强了持续学习模型的校准和性能，解决了现有方法忽视网络校准的问题，并取得了优于现有SOTA方法的成果。


<details>
  <summary>Details</summary>
Motivation: 大多数持续学习方法在关注遗忘和准确性的同时，忽视了网络校准这一关键问题。然而，神经坍缩现象（最后层特征坍缩到类别均值）在持续学习中通过减少特征-分类器不对齐展现出优势。本研究旨在通过提出一种新方法来改善持续学习模型的校准，以实现更可靠的预测。

Method: 提出了一种名为Sphere-Adaptive Mixup（SAMix）的新方法。SAMix是一种自适应混合策略，专门为基于神经坍缩的方法设计。它能根据神经坍缩下特征空间的几何特性来调整混合过程，从而实现更鲁棒的正则化和对齐。

Result: 实验结果表明，SAMix显著提升了性能，在持续学习方面超越了现有最先进（SOTA）的方法，同时也提高了模型的校准度。SAMix在任务间准确性和预测的整体可靠性方面都得到了提升。

Conclusion: SAMix是一种有前景的、用于稳健持续学习的先进技术，它不仅能提高模型在不同任务上的准确性，还能增强预测的整体可靠性。

Abstract: While most continual learning methods focus on mitigating forgetting and
improving accuracy, they often overlook the critical aspect of network
calibration, despite its importance. Neural collapse, a phenomenon where
last-layer features collapse to their class means, has demonstrated advantages
in continual learning by reducing feature-classifier misalignment. Few works
aim to improve the calibration of continual models for more reliable
predictions. Our work goes a step further by proposing a novel method that not
only enhances calibration but also improves performance by reducing
overconfidence, mitigating forgetting, and increasing accuracy. We introduce
Sphere-Adaptive Mixup (SAMix), an adaptive mixup strategy tailored for neural
collapse-based methods. SAMix adapts the mixing process to the geometric
properties of feature spaces under neural collapse, ensuring more robust
regularization and alignment. Experiments show that SAMix significantly boosts
performance, surpassing SOTA methods in continual learning while also improving
model calibration. SAMix enhances both across-task accuracy and the broader
reliability of predictions, making it a promising advancement for robust
continual learning systems.

</details>


### [286] [AB-UPT for Automotive and Aerospace Applications](https://arxiv.org/abs/2510.15808)
*Benedikt Alkin,Richard Kurle,Louis Serrano,Dennis Just,Johannes Brandstetter*

Main category: cs.LG

TL;DR: AB-UPT在汽车和飞机CFD模拟中表现出色，能够快速且经济高效地进行预测。


<details>
  <summary>Details</summary>
Motivation: 为了扩展AB-UPT在汽车和飞机计算流体动力学（CFD）模拟中的应用，并提供高质量的数据集进行评估。

Method: 生成包含汽车（SHIFT-SUV）和飞机（SHIFT-Wing）的新数据集，并使用AB-UPT模型在这些数据集上进行训练和评估，与现有基线进行比较。

Result: AB-UPT在两个新数据集上均表现出色，能够以极高的精度预测空气动力学载荷，并且训练成本低廉。

Conclusion: AB-UPT在汽车和飞机CFD模拟中具有巨大潜力，可以实现行业规模的应用。

Abstract: The recently proposed Anchored-Branched Universal Physics Transformers
(AB-UPT) shows strong capabilities to replicate automotive computational fluid
dynamics simulations requiring orders of magnitudes less compute than
traditional numerical solvers. In this technical report, we add two new
datasets to the body of empirically evaluated use-cases of AB-UPT, combining
high-quality data generation with state-of-the-art neural surrogates. Both
datasets were generated with the Luminary Cloud platform containing automotives
(SHIFT-SUV) and aircrafts (SHIFT-Wing). We start by detailing the data
generation. Next, we show favorable performances of AB-UPT against previous
state-of-the-art transformer-based baselines on both datasets, followed by
extensive qualitative and quantitative evaluations of our best AB-UPT model.
AB-UPT shows strong performances across the board. Notably, it obtains near
perfect prediction of integrated aerodynamic forces within seconds from a
simple isotopically tesselate geometry representation and is trainable within a
day on a single GPU, paving the way for industry-scale applications.

</details>


### [287] [Chronos-2: From Univariate to Universal Forecasting](https://arxiv.org/abs/2510.15821)
*Abdul Fatir Ansari,Oleksandr Shchur,Jaris Küken,Andreas Auer,Boran Han,Pedro Mercado,Syama Sundar Rangapuram,Huibin Shen,Lorenzo Stella,Xiyuan Zhang,Mononito Goswami,Shubham Kapoor,Danielle C. Maddix,Pablo Guerron,Tony Hu,Junming Yin,Nick Erickson,Prateek Mutalik Desai,Hao Wang,Huzefa Rangwala,George Karypis,Yuyang Wang,Michael Bohlke-Schneider*

Main category: cs.LG

TL;DR: Chronos-2是一个预训练模型，能够以零样本方式处理单变量、多变量和协变量信息预测任务，在三个基准测试中均表现出最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的预训练时间序列模型主要集中在单变量预测，限制了它们在处理多变量数据和协变量等现实场景中的应用。

Method: Chronos-2采用分组注意力机制，通过在组内多个时间序列之间共享信息来实现上下文学习（ICL），并在合成数据集上进行训练，以实现对各种多变量结构的处理。

Result: Chronos-2在fev-bench、GIFT-Eval和Chronos Benchmark II三个基准测试中均取得了最先进的性能，特别是在涉及多变量和协变量的预测任务上表现优异，并展示了在能源和零售领域的实际应用优势。

Conclusion: Chronos-2的上下文学习能力使其成为一个通用的预测模型，可以直接应用于实际的预测流程中。

Abstract: Pretrained time series models have enabled inference-only forecasting systems
that produce accurate predictions without task-specific training. However,
existing approaches largely focus on univariate forecasting, limiting their
applicability in real-world scenarios where multivariate data and covariates
play a crucial role. We present Chronos-2, a pretrained model capable of
handling univariate, multivariate, and covariate-informed forecasting tasks in
a zero-shot manner. Chronos-2 employs a group attention mechanism that
facilitates in-context learning (ICL) through efficient information sharing
across multiple time series within a group, which may represent sets of related
series, variates of a multivariate series, or targets and covariates in a
forecasting task. These general capabilities are achieved through training on
synthetic datasets that impose diverse multivariate structures on univariate
series. Chronos-2 delivers state-of-the-art performance across three
comprehensive benchmarks: fev-bench, GIFT-Eval, and Chronos Benchmark II. On
fev-bench, which emphasizes multivariate and covariate-informed forecasting,
Chronos-2's universal ICL capabilities lead to substantial improvements over
existing models. On tasks involving covariates, it consistently outperforms
baselines by a wide margin. Case studies in the energy and retail domains
further highlight its practical advantages. The in-context learning
capabilities of Chronos-2 establish it as a general-purpose forecasting model
that can be used "as is" in real-world forecasting pipelines.

</details>


### [288] [SNOO: Step-K Nesterov Outer Optimizer - The Surprising Effectiveness of Nesterov Momentum Applied to Pseudo-Gradients](https://arxiv.org/abs/2510.15830)
*Dominik Kallusky,Vinay Rao,Vishal Nandavanam,Hao-Jun Michael Shi*

Main category: cs.LG

TL;DR: DiLoCo通过将Nesterov动量应用于伪梯度，在非分布式设置中提高了训练效果，我们称之为SNOO。SNOO在最大1e23训练FLOPs的非分布式设置中实现了1.5-2.5倍的计算增益，并且随着模型规模的增大而提高。


<details>
  <summary>Details</summary>
Motivation: LLM的发展对更高效的优化技术提出了更高的要求，而Lookahead优化器及其变体DiLoCo在训练中表现出了优于AdamW的性能。

Method: 通过实证分析，证明DiLoCo的有效性主要来自于将其Nesterov动量应用于伪梯度，并提出了SNOO（Step-K Nesterov Outer Optimizer）。

Result: SNOO在非分布式设置中，在最大1e23训练FLOPs的规模下，实现了1.5-2.5倍的计算效率提升，并且这种提升随着模型规模的增大而更加显著。

Conclusion: SNOO具有较低的计算和内存开销，并且兼容模型分片，是一种实用的优化器增强方法，适用于AdamW和Muon等多种内部优化器。

Abstract: The rapid development of large language models (LLMs) has driven the demand
for more efficient optimization techniques. Among these, the Lookahead family
of optimizers employs a two-loop framework, maintaining fast and slow sets of
model weights. Multiple inner optimizer steps on the fast weights produce a
trajectory - the pseudo-gradient - that is used to update the slow weights.
DiLoCo, a notable example originally designed for distributed training, applies
Nesterov momentum to the averaged pseudo-gradient from multiple workers,
claiming to even outperform AdamW in a non-distributed setup. In this paper, we
empirically show that DiLoCo's surprising effectiveness stems primarily from
applying Nesterov momentum to the pseudo-gradient, which improves training in a
non-distributed setting. We call this Lookahead variant the Step-$K$ Nesterov
Outer Optimizer (SNOO). We demonstrate that SNOO achieves compute factor gains
of 1.5 - 2.5$\times$ in a non-distributed setting up to a scale of 1e23
training FLOPs, with improvements that increase with model size. Because of its
minimal compute and memory overhead and compatibility with model sharding, SNOO
is a practical enhancement for a variety of inner optimizers, including AdamW
and Muon.

</details>


### [289] [FIDDLE: Reinforcement Learning for Quantum Fidelity Enhancement](https://arxiv.org/abs/2510.15833)
*Hoang M. Ngo,Tamer Kahveci,My T. Thai*

Main category: cs.LG

TL;DR: FIDDLE是一个新的学习框架，通过高斯过程和强化学习来优化量子电路中的路由，以最大化保真度，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 提高量子计算中量子电路的可靠性，特别是在转译过程的路由阶段，以最大化保真度。

Method: FIDDLE框架：1. 高斯过程（GP）作为代理模型，以较少的训练样本估计过程保真度。 2. 强化学习（RL）模块，用于优化路由。 3. 端到端框架，直接最大化过程保真度。

Result: FIDDLE框架提出的代理模型比现有学习技术能提供更好的过程保真度估计。该端到端框架显著提高了各种噪声模型下量子电路的过程保真度，优于现有的状态艺术保真度估计技术和路由优化方法。

Conclusion: FIDDLE框架通过直接最大化过程保真度，成功解决了量子计算路由阶段的保真度最大化问题，为提高量子电路的可靠性提供了一种新的有效方法。

Abstract: Quantum computing has the potential to revolutionize fields like quantum
optimization and quantum machine learning. However, current quantum devices are
hindered by noise, reducing their reliability. A key challenge in gate-based
quantum computing is improving the reliability of quantum circuits, measured by
process fidelity, during the transpilation process, particularly in the routing
stage. In this paper, we address the Fidelity Maximization in Routing Stage
(FMRS) problem by introducing FIDDLE, a novel learning framework comprising two
modules: a Gaussian Process-based surrogate model to estimate process fidelity
with limited training samples and a reinforcement learning module to optimize
routing. Our approach is the first to directly maximize process fidelity,
outperforming traditional methods that rely on indirect metrics such as circuit
depth or gate count. We rigorously evaluate FIDDLE by comparing it with
state-of-the-art fidelity estimation techniques and routing optimization
methods. The results demonstrate that our proposed surrogate model is able to
provide a better estimation on the process fidelity compared to existing
learning techniques, and our end-to-end framework significantly improves the
process fidelity of quantum circuits across various noise models.

</details>


### [290] [Transfer Orthology Networks](https://arxiv.org/abs/2510.15837)
*Vikash Singh*

Main category: cs.LG

TL;DR: TRON是一种新颖的神经网络架构，用于跨物种迁移学习，它利用物种间的直系同源关系来指导知识迁移，通过学习一个线性变换将基因表达从源物种映射到目标物种的基因空间，从而实现有效的知识迁移，并可能提供功能直系同源性的解释。


<details>
  <summary>Details</summary>
Motivation: 需要一种有效的方法来进行跨物种迁移学习，以利用不同物种的转录组数据来预测表型。

Method: 提出了一种名为TRON的新型神经网络架构，它利用直系同源关系（表示为物种间的二分图）来指导知识迁移。具体来说，在预训练的前馈神经网络之前添加了一个学习到的物种转换层，该层的权重由该二分图的伴随矩阵进行掩码，从而学习一个线性变换，将源物种的基因表达映射到目标物种的基因空间。

Result: TRON通过学习到的转换层权重，为解释功能直系同源性提供了一条潜在的途径，并深入了解跨物种基因如何影响所关注的表型。TRON提供了一种有生物学依据且可解释的跨物种迁移学习方法，能够更有效地利用现有的转录组数据。

Conclusion: TRON提供了一种有生物学依据且可解释的跨物种迁移学习方法，能够更有效地利用现有的转录组数据。目前正在收集跨物种转录组/表型数据以获得TRON架构的实验验证。

Abstract: We present Transfer Orthology Networks (TRON), a novel neural network
architecture designed for cross-species transfer learning. TRON leverages
orthologous relationships, represented as a bipartite graph between species, to
guide knowledge transfer. Specifically, we prepend a learned species conversion
layer, whose weights are masked by the biadjacency matrix of this bipartite
graph, to a pre-trained feedforward neural network that predicts a phenotype
from gene expression data in a source species. This allows for efficient
transfer of knowledge to a target species by learning a linear transformation
that maps gene expression from the source to the target species' gene space.
The learned weights of this conversion layer offer a potential avenue for
interpreting functional orthology, providing insights into how genes across
species contribute to the phenotype of interest. TRON offers a biologically
grounded and interpretable approach to cross-species transfer learning, paving
the way for more effective utilization of available transcriptomic data. We are
in the process of collecting cross-species transcriptomic/phenotypic data to
gain experimental validation of the TRON architecture.

</details>


### [291] [Learning Correlated Reward Models: Statistical Barriers and Opportunities](https://arxiv.org/abs/2510.15839)
*Yeshwanth Cherapanamjeri,Constantinos Daskalakis,Gabriele Farina,Sobhan Mohammadpour*

Main category: cs.LG

TL;DR: 该论文研究了具有相关性Probit模型的随机效用模型（RUM），该模型避免了无关选项独立性（IIA）假设，并提出了使用“三项最佳”偏好数据来解决其固有的统计和计算挑战。


<details>
  <summary>Details</summary>
Motivation: 许多随机效用模型（RUM）存在无关选项独立性（IIA）假设的缺陷，该假设将所有人类偏好简化为单一的普适性效用函数，无法精确描述人类偏好的多样性。虽然避免IIA假设的模型在统计和计算方面缺乏保证，但该研究旨在解决这一问题。

Method: 研究了学习具有相关性Probit模型（一种避免IIA假设的RUM）的统计和计算挑战。首先，证明了传统的成对偏好数据收集范式不足以学习相关性信息。然后，提出使用“三项最佳”偏好数据可以克服这些缺点，并设计了一种具有近乎最优性能的统计和计算高效的估计器。

Result: 研究表明，成对偏好数据在学习相关性信息方面存在根本性不足。而“三项最佳”偏好数据能够有效解决这一问题，并提出了一种高效的估计器，其性能接近最优。在真实世界数据集上的验证也表明，该方法能够实现更精细化的人类偏好建模和个性化。

Conclusion: 该研究强调了高阶偏好数据在学习具有相关性的效用函数方面的优势，能够更精细地模拟人类偏好。研究结果表明，“三项最佳”偏好数据收集范式克服了传统成对偏好数据的局限性，为解决随机效用模型中的统计和计算挑战提供了有效途径。

Abstract: Random Utility Models (RUMs) are a classical framework for modeling user
preferences and play a key role in reward modeling for Reinforcement Learning
from Human Feedback (RLHF). However, a crucial shortcoming of many of these
techniques is the Independence of Irrelevant Alternatives (IIA) assumption,
which collapses \emph{all} human preferences to a universal underlying utility
function, yielding a coarse approximation of the range of human preferences. On
the other hand, statistical and computational guarantees for models avoiding
this assumption are scarce. In this paper, we investigate the statistical and
computational challenges of learning a \emph{correlated} probit model, a
fundamental RUM that avoids the IIA assumption. First, we establish that the
classical data collection paradigm of pairwise preference data is
\emph{fundamentally insufficient} to learn correlational information,
explaining the lack of statistical and computational guarantees in this
setting. Next, we demonstrate that \emph{best-of-three} preference data
provably overcomes these shortcomings, and devise a statistically and
computationally efficient estimator with near-optimal performance. These
results highlight the benefits of higher-order preference data in learning
correlated utilities, allowing for more fine-grained modeling of human
preferences. Finally, we validate these theoretical guarantees on several
real-world datasets, demonstrating improved personalization of human
preferences.

</details>


### [292] [Self-Certifying Primal-Dual Optimization Proxies for Large-Scale Batch Economic Dispatch](https://arxiv.org/abs/2510.15850)
*Michael Klamkin,Mathieu Tanneau,Pascal Van Hentenryck*

Main category: cs.LG

TL;DR: 该研究提出了一种混合求解器，结合了优化代理和经典求解器，以在可信赖的部署中实现可解释的速度-优化权衡。


<details>
  <summary>Details</summary>
Motivation: 为了在优化代理和经典求解器之间取得平衡，从而在可解释的速度-优化权衡的基础上实现可信赖的部署，并满足用户定义的优化阈值。

Method: 提出了一种混合求解器，该求解器利用对偶理论来有效地界定预测的优化差距，并在无法认证最优性的查询中回退到经典求解器。为了提高混合求解器的加速效果，提出了一种结合了原始和对偶代理训练的替代训练程序。

Result: 实验结果表明，该混合求解器具有高可扩展性，与并行化单纯形求解器相比，速度提高了1000倍以上，同时保证了最大2%的优化差距。

Conclusion: 该混合求解器能够以可解释的方式提供速度-优化权衡，并满足用户定义的优化阈值，从而实现可信赖的部署。

Abstract: Recent research has shown that optimization proxies can be trained to high
fidelity, achieving average optimality gaps under 1% for large-scale problems.
However, worst-case analyses show that there exist in-distribution queries that
result in orders of magnitude higher optimality gap, making it difficult to
trust the predictions in practice. This paper aims at striking a balance
between classical solvers and optimization proxies in order to enable
trustworthy deployments with interpretable speed-optimality tradeoffs based on
a user-defined optimality threshold. To this end, the paper proposes a hybrid
solver that leverages duality theory to efficiently bound the optimality gap of
predictions, falling back to a classical solver for queries where optimality
cannot be certified. To improve the achieved speedup of the hybrid solver, the
paper proposes an alternative training procedure that combines the primal and
dual proxy training. Experiments on large-scale transmission systems show that
the hybrid solver is highly scalable. The proposed hybrid solver achieves
speedups of over 1000x compared to a parallelized simplex-based solver while
guaranteeing a maximum optimality gap of 2%.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [293] [Design and Analysis of Parallel Artificial Protozoa Optimizer (P-APO) using CUDA Architecture](https://arxiv.org/abs/2510.14982)
*Henish Soliya,Anugrah Jain*

Main category: cs.NE

TL;DR: 该论文提出了一种利用 NVIDIA CUDA 框架加速的人工原生体优化器（APO）的并行实现，以解决元启发式算法执行时间长的问题。


<details>
  <summary>Details</summary>
Motivation: 元启发式算法在解决复杂问题时执行时间长，尤其是在问题规模和解空间增大以及需要大量迭代次数时，这成为了主要问题之一。因此，研究人员正在开发这些算法的并行版本。

Method: 提出了一种使用 NVIDIA CUDA 框架的 APO 并行实现，并与现有的顺序版本进行了比较。

Result: 在 CEC2022 基准函数上的实验结果表明，所提出的并行版本实现了高达 6.7 倍的加速。在工程优化中的拉伸/压缩弹簧设计和基于 Otsu 方法的图像阈值处理这两个实际应用中也测试了该实现。 conclusión: 所提出的 APO 并行实现显著提高了性能，并能有效处理实际问题。

Conclusion: 所提出的 APO 并行实现显著提高了性能，并能有效处理实际问题。

Abstract: Metaheuristic algorithms are widely used for solving complex problems due to
their ability to provide near-optimal solutions. But the execution time of
these algorithms increases with the problem size and solution space. And, to
get more promising results, we have to execute these algorithms for a large
number of iterations, requiring a large amount of time and this is one of the
main issues found with these algorithms. To handle the same, researchers are
now-adays working on design and development of parallel versions of state of
the art metaheuristic optimization algorithms. We, in this paper, present a
parallel implementation of state of the art Artificial Protozoa Optimizer using
NVIDIA CUDA framework to leverage GPU acceleration. Our implementation
optimizes the state of the art Artificial Protozoa Optimizer (APO) to achieve
high performance. We implement both the existing sequential version and the
proposed parallel version of Artificial Protozoa Optimizer in this paper. The
experimental results calculated over benchmarks functions of CEC2022
demonstrate a significant performance gain i.e. up to 6.7 times speed up
achieved in case of proposed parallel version. We also use two real world
applications (1) Tension/Compression Spring Design in engineering optimization
and (2) Image Thresholding using otsu method for testing the performance of
proposed implementation in handling real tasks.

</details>


### [294] [SpikeFit: Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardware](https://arxiv.org/abs/2510.15542)
*Ivan Kartashov,Mariia Pushkareva,Iakov Karandashev*

Main category: cs.NE

TL;DR: SpikeFit是一种新的SNN训练方法，可实现神经形态硬件上的高效推理，满足神经元数量、突触数量和低比特宽度等硬件约束。它通过将离散的权重值作为可学习参数进行优化，实现最优的聚类感知训练（CAT），从而提高网络压缩效率并限制突触连接数量。SpikeFit还引入了一种新的硬件友好型剪枝方法（FSC），并在实验中取得了最先进的性能，特别是在仅允许四种唯一突触权重值（M=4）的情况下，优于现有SNN压缩方法，满足更广泛的硬件要求并提供最低能耗。


<details>
  <summary>Details</summary>
Motivation: 现有SNN压缩方法未能充分满足神经形态硬件对神经元数量、突触数量和低比特宽度表示的严格要求。SpikeFit旨在解决这一问题，通过联合优化离散权重值和模型参数，实现更全面的硬件约束满足和更高的压缩效率。

Method: SpikeFit是一种训练方法，它将离散的权重值视为可学习参数，与模型参数一起进行优化。该方法利用聚类感知训练（CAT）技术，在低精度（2、4或8位）下对模型权重进行最优化的聚类。此外，SpikeFit还引入了一种新的硬件友好型Fisher Spike Contribution（FSC）剪枝方法。

Result: SpikeFit在仅允许四种唯一突触权重值（M=4）的情况下，相比于现有的SNN压缩方法和结合了极端量化方案与聚类算法的传统基线方法，取得了更优越的性能。该方法满足了更广泛的神经形态硬件要求，并在实验中实现了最低的能耗。

Conclusion: SpikeFit是一种有效的SNN训练方法，通过联合优化离散权重值和模型参数，并结合CAT和FSC等技术，能够有效地满足神经形态硬件的约束，实现高压缩效率、优越的性能和最低的能耗。

Abstract: This paper introduces SpikeFit, a novel training method for Spiking Neural
Networks (SNNs) that enables efficient inference on neuromorphic hardware,
considering all its stringent requirements: the number of neurons and synapses
that can fit on a single device, and lower bit-width representations (e.g.,
4-bit, 8-bit). Unlike conventional compressing approaches that address only a
subset of these requirements (limited numerical precision and limited number of
neurons in the network), SpikeFit treats the allowed weights' discrete values
themselves as learnable parameters co-optimized with the model, allowing for
optimal Clusterization-Aware Training (CAT) of the model's weights at low
precision (2-, 4-, or 8-bit) which results in higher network compression
efficiency, as well as limiting the number of unique synaptic connections to a
value required by neuromorphic processor. This joint optimization allows
SpikeFit to find a discrete weight set aligned with hardware constraints,
enabling the most complete deployment across a broader range of neuromorphic
processors than existing methods of SNN compression support. Moreover, SpikeFit
introduces a new hardware-friendly Fisher Spike Contribution (FSC) pruning
method showing the state-of-the-art performance. We demonstrate that for
spiking neural networks constrained to only four unique synaptic weight values
(M = 4), our SpikeFit method not only outperforms state-of-the-art SNNs
compression methods and conventional baselines combining extreme quantization
schemes and clustering algorithms, but also meets a wider range of neuromorphic
hardware requirements and provides the lowest energy use in experiments.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [295] [Unveiling Retention Loss Mechanism in FeFETs with Gate-side Interlayer by Decoupling Trapped Charges and Ferroelectric Polarization](https://arxiv.org/abs/2510.15275)
*Runhao Han,Tao Hu,Jia Yang,Saifei Dai,Yajing Ding,Mingkai Bai,Xianzhou Shao,Junshuai Chai,Hao Xu,Qing Luo,Wenwu Wang,Tianchun Ye,Xiaolei Wang*

Main category: physics.app-ph

TL;DR: 该研究提出了一种在铁电场效应晶体管 (FeFET) 中提取陷阱电荷和量化能带图的实验技术，揭示了栅极注入电荷和沟道注入电荷的比例，确定了保持时间损失的来源是栅极注入电荷的去陷，并分析了栅极侧夹层厚度对去陷路径的影响，最后强调了材料设计和带隙工程对于提高保持时间的重要性。


<details>
  <summary>Details</summary>
Motivation: 为了解决铁电场效应晶体管 (FeFET) 中保持时间损失的问题，并深入理解其物理机制，需要一种能够提取陷阱电荷和量化能带图的实验技术。

Method: 通过栅极侧夹层 (G.IL) 厚度与阈值电压 (Vth) 之间的物理关系，提出了一种直接的实验提取技术，用于提取金属-绝缘体-铁电体-绝缘体-半导体 (MIFIS) 结构 FeFETs 中的陷阱电荷和量化能带图。该技术能够解耦陷阱电荷和铁电极化。

Result: 研究结果表明：(i) 栅极注入电荷和沟道注入电荷的比例与铁电极化大致成固定比例（分别为~170% 和 ~130%）。(ii) 保持时间损失主要来源于栅极注入电荷的去陷，而非铁电去极化。(iii) 随着栅极侧夹层厚度的增加，栅极注入电荷的去陷路径从栅极侧转变为沟道侧。

Conclusion: 为了提高 MIFIS-FeFETs 的保持时间，必须仔细进行材料设计、优化以及带隙工程。该研究提出的实验技术和发现，为 3D FE NAND 中 MIFIS-FeFETs 的高保持时间策略提供了重要的理论依据和理解。

Abstract: We propose a direct experimental extraction technique for trapped charges and
quantitative energy band diagrams in the FeFETs with
metal-insulator-ferroelectric-insulator-semiconductor (MIFIS) structure,
derived from the physical relationship between Vth and gate-side interlayer
(G.IL) thickness. By decoupling trapped charges and ferroelectric polarization,
we reveal that: (i) The gateinjected charges and channel-injected charges are
excessive and maintain consistent ratios to ferroelectric polarization (~170%
and ~130%, respectively). (ii) Retention loss originates from the detrapping of
gate-injected charges rather than ferroelectric depolarization. (iii) As the
G.IL thickens, the gate-injected charge de-trapping path transforms from
gate-side to channel-side. To address the retention loss, careful material
design, optimization, and bandgap engineering in the MIFIS structure are
crucial. This work advances the understanding of high retention strategies for
MIFIS-FeFETs in 3D FE NAND.

</details>


### [296] [Multiscale X-ray computed tomography of standard optical fibers](https://arxiv.org/abs/2510.15597)
*Maria Caterina Crocco,Flavio Cognigni,Alessia Sanna,Raffaele Filosa,Svetlana Siprova,Riccardo C. Barberi,Raffaele G. Agostino,Stefan Wabnitz,Antonio D'Alessandro,Sylvie Lebrun,Marco Rossi,Vincenzo Formoso,Roberto Termine,Alberto Bravin,Mario Ferraro*

Main category: physics.app-ph

TL;DR: 本文提出了一种多尺度表征光学纤维的方法，通过比较三种X射线断层扫描技术（微断层扫描、X射线显微镜和纳米断层扫描）来评估它们在分辨率、视场和分割效率方面的权衡。结果表明，微断层扫描适用于长光纤的低分辨率分析，纳米断层扫描具有最高分辨率但样本量有限，而X射线显微镜在视场和分辨率之间取得了良好平衡，特别适合光纤制造的实时质量控制。


<details>
  <summary>Details</summary>
Motivation: 为了实现对光学纤维（用于通信、医疗成像和传感）内部结构的三维精确映射和表征，特别是解决不同尺度下表征的挑战。

Method: 将经典显微断层扫描、X射线显微镜和纳米断层扫描这三种X射线断层扫描技术进行比较分析，并引入深度学习分割阈值方法以提升图像分析效率。

Result: 三种断层扫描技术各有优缺点：经典显微断层扫描视场大，适合长光纤低分辨率分析；纳米断层扫描分辨率最高，但仅限于微米级的微小样品；X射线显微镜在视场和分辨率上达到良好平衡，适合内部特征成像。

Conclusion: X射线断层扫描与人工智能的结合将彻底改变光纤表征，实现光纤制造中的精确监控和自适应控制。其中，X射线显微镜因其成本效益和便捷性，被认为是最适合光纤制造实时质量控制的技术。

Abstract: Optical fiber technologies enable high-speed communication, medical imaging,
and advanced sensing. Among the techniques for the characterization of optical
fibers, Xray computed tomography has recently emerged as a versatile
non-destructive tool for mapping their refractive index variations in 3D. In
this study, we present a multiscale characterization of standard optical
fibers. We carry out an intercomparison of three tomography setups: classical
computed microtomography, X-ray microscopy, and nanotomography. In each method,
our analysis highlights the trade-offs between resolution, field of view, and
segmentation efficiency. Additionally, we integrate deep learning segmentation
thresholding to improve the image analysis process. Thanks to its large field
of view, microtomography with classical sources is ideal for the analysis of
relatively long fiber spans, where a low spatial resolution is acceptable. The
other way around, nanotomography has the highest spatial resolution, but it is
limited to very small fiber samples, e.g., fiber tapers and nanofibers, which
have diameters of the order of a few microns. Finally, X-ray microscopy
provides a good compromise between the sample size fitting the device's field
of view and the spatial resolution needed for properly imaging the inner
features of the fiber. Specifically, thanks to its practicality in terms of
costs and cumbersomeness, we foresee that the latter will provide the most
suitable choice for the quality control of fiber drawing in real-time, e.g.,
using the "One-Minute Tomographies with Fast Acquisition Scanning Technology"
developed by Zeiss. In this regard, the combination of X-ray computed
tomography and artificial intelligence-driven enhancements is poised to
revolutionize fiber characterization, by enabling precise monitoring and
adaptive control in fiber manufacturing.

</details>


### [297] [Integration of Porous Graphene and 3D-printed Piezopolymer for Flexible Ultrasound Transducers](https://arxiv.org/abs/2510.15737)
*Shirin Movaghgharnezhad,Ehsan Ansari,Clayton A Baker,Ahmed A Bashatah,Dulcce A Valenzuela,Pilgyu Kang,Parag V Chitnis*

Main category: physics.app-ph

TL;DR: 提出了一种结合激光石墨烯化和3D打印的新型柔性超声换能器，成本低且性能优于传统银基换能器。


<details>
  <summary>Details</summary>
Motivation: 传统超声换能器在柔韧性和制造方面存在局限，需要开发薄膜和柔性压电材料。

Method: 结合激光石墨烯化和3D打印技术，将多孔石墨烯（LIG）与PVDF-TrFE压电材料集成，制成柔性LIG/PVDF-TrFE超声贴片。通过调整PVDF-TrFE的厚度来调谐中心频率。

Result: 制备的LIG基超声换能器具有6.72 V的高信号幅度，433的信噪比，8.86 MHz（37%）的-6 dB带宽。与银基换能器相比，其声学性能更高。成功获得了包含囊肿模型的二维超声图像。LIG电极的图案化实现了所需的传感器配置，且材料成本低于5美元。

Conclusion: 所提出的激光石墨烯化和3D打印技术能够低成本地生产高性能的柔性超声换能器阵列，无需切割，适用于超声贴片应用。

Abstract: Ultrasound technology is crucial in diagnostic imaging, making it widely used
in medical applications. However, traditional ultrasound transducers face
limitations in flexibility and ease of fabrication, leading to the exploration
of thin-film and flexible piezoelectric materials. Here, we present a novel
approach that combines laser graphitization with 3D printing to integrate
flexible laser-induced porous graphene (LIG) with poly(vinylidene
fluoride-trifluoroethylene) (PVDF-TrFE), resulting in the development of
flexible LIG/PVDF-TrFE ultrasound patches. The thickness of PVDF-TrFE is
adjusted to tune the central frequency of the ultrasound transducer, allowing
customization within a range of 10 to 28 MHz. LIG-based ultrasound transducer
demonstrates a high signal amplitude of 6.72 V and a signal-to-noise ratio
(SNR) of 433, along with a -6 dB bandwidth of 8.86 MHz (37%). The LIG-based
transducer exhibits higher acoustic performance compared to the smooth
silver-based transducer. A high-quality two-dimensional ultrasound image,
including a B-mode image of a cyst phantom, demonstrates the transducer's
imaging capabilities. The patterning of LIG-based electrodes facilitates the
desired sensor configuration, demonstrating the suitability of our novel
technique for producing flexible transducer arrays without dicing and cutting.
The materials cost of our LIG/PVDF-TrFE transducer is under $5 per unit, making
it a low-cost solution for ultrasound patches.

</details>


### [298] [Non-uniform pneumatic actuation switches macroscopic properties of elastomeric honeycombs](https://arxiv.org/abs/2510.15741)
*Ondřej Faltus,Martin Doškář,Jan Havelka,Pavel Rychnovský,Ondřej Rokoš*

Main category: physics.app-ph

TL;DR: Honeycomb microstructures can change patterns through pneumatic actuation of voids, not just mechanical strain, leading to tunable stiffness and acoustic properties.


<details>
  <summary>Details</summary>
Motivation: To investigate if pneumatic actuation can induce pattern transformations in honeycomb microstructures, similar to mechanical strain, and to explore the resulting tunable stiffness and acoustic properties.

Method: 1. Numerically simulate honeycomb microstructures under pneumatic actuation (suction pressures in voids) to observe pattern formation. 2. Experimentally validate the numerical findings using silicone rubber samples. 3. Analyze the evolution of homogenized stiffness and anisotropy during pattern genesis. 4. Study the effect of pneumatic actuation on acoustic properties and bandgaps.

Result: 1. Pneumatic actuation triggers the same three deformation patterns as macroscopic strain, dependent on pressurization schemes. 2. Macroscopic stiffness can vary by a factor of two with loading direction, controlled by reversible pneumatic actuation. 3. Different acoustic bandgaps can be triggered by the proposed pneumatic actuation method.

Conclusion: Pneumatic actuation offers a viable method to control pattern formation, stiffness, and acoustic properties in honeycomb microstructures, providing a reversible and tunable alternative to mechanical strain.

Abstract: Honeycomb microstructures with circular voids are well known to undergo
pattern transformations under macroscopic strain loading. Depending on the
biaxiality of the applied strain, they deform into three different patterns.
Here we demonstrate that the same three patterns can be triggered also by
pneumatic actuation of the voids, with resulting patterns depending on an
applied pressurization scheme, i.e., the ratio of suction pressures introduced
in different voids within the microstructure. Our numerically obtained findings
are experimentally validated on two finite size samples made of silicone rubber
cast in a 3D printed mold. In numerical studies, we first showcase the
evolution of homogenized stiffness and its anisotropy during the genesis of
pneumatically-induced patterns. Our loading schemes result in macroscopic
stiffness varying by a factor of two with loading direction, chosen by a
reversible actuation independent of the load itself. Second, we study the
effect of the pneumatic actuation on acoustic properties of the microstructure,
finding the proposed method viable to trigger different acoustic bandgaps.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [299] [TranSimHub:A Unified Air-Ground Simulation Platform for Multi-Modal Perception and Decision-Making](https://arxiv.org/abs/2510.15365)
*Maonan Wang,Yirong Chen,Yuxin Cai,Aoyu Pang,Yuejiao Xie,Zian Ma,Chengcheng Xu,Kemou Jiang,Ding Wang,Laurent Roullet,Chung Shue Chen,Zhiyong Cui,Yuheng Kan,Michael Lepech,Man-On Pun*

Main category: eess.SY

TL;DR: TranSimHub是一个统一的空地协同智能交通管理仿真平台，支持跨域感知、通信和决策研究。


<details>
  <summary>Details</summary>
Motivation: 缺乏统一的多模态仿真环境阻碍了对跨域感知、通信受限下的协同以及联合决策优化的研究。

Method: 提出TranSimHub仿真平台，该平台提供同步的多视角渲染（RGB、深度、语义分割）、支持空地信息交换、包含因果场景编辑器，可实现可控的场景创建和反事实分析。

Result: TranSimHub支持端到端的感知、融合和控制研究，并在真实的空地交通场景中得到验证。

Conclusion: TranSimHub是一个开源平台，为未来城市智能交通管理中的空地协同智能研究提供了支持。

Abstract: Air-ground collaborative intelligence is becoming a key approach for
next-generation urban intelligent transportation management, where aerial and
ground systems work together on perception, communication, and decision-making.
However, the lack of a unified multi-modal simulation environment has limited
progress in studying cross-domain perception, coordination under communication
constraints, and joint decision optimization. To address this gap, we present
TranSimHub, a unified simulation platform for air-ground collaborative
intelligence. TranSimHub offers synchronized multi-view rendering across RGB,
depth, and semantic segmentation modalities, ensuring consistent perception
between aerial and ground viewpoints. It also supports information exchange
between the two domains and includes a causal scene editor that enables
controllable scenario creation and counterfactual analysis under diverse
conditions such as different weather, emergency events, and dynamic obstacles.
We release TranSimHub as an open-source platform that supports end-to-end
research on perception, fusion, and control across realistic air and ground
traffic scenes. Our code is available at
https://github.com/Traffic-Alpha/TranSimHub.

</details>


### [300] [Hypergame-based Cognition Modeling and Intention Interpretation for Human-Driven Vehicles in Connected Mixed Traffic](https://arxiv.org/abs/2510.15573)
*Jianguo Chen,Zhengqin Liu,Jinlong Lei,Peng Yi,Yiguang Hong,Hong Chen*

Main category: eess.SY

TL;DR: 该研究提出了一种基于超博弈论的框架，用于在混合自动驾驶和人类驾驶车辆交通系统中，考虑人类驾驶员的认知和感知局限性，进行车辆轨迹规划。


<details>
  <summary>Details</summary>
Motivation: 为了提高安全性和交通效率，需要准确预测人类驾驶员的轨迹，但现有研究假设人类驾驶员拥有完美信息，这不切实际。本研究旨在解决这一差距。

Method: 提出了一种分层认知建模框架，利用超博弈论来考虑人类驾驶员有限的理性，并建立了车辆间的认知关系。开发了一种逆向学习算法，通过车联网通信进行分布式的意图解释，并提出了一种分布式的轨迹预测和规划方法。

Result: 仿真结果表明，该方法在参数学习方面准确，对噪声轨迹观测具有鲁棒性，并在人类驾驶员轨迹预测方面保证了安全性。

Conclusion: 所提出的方法在混合交通系统中是有效和安全的，能够准确地预测人类驾驶员的轨迹并进行相应的车辆轨迹规划。

Abstract: With the practical implementation of connected and autonomous vehicles
(CAVs), the traffic system is expected to remain a mix of CAVs and human-driven
vehicles (HVs) for the foreseeable future. To enhance safety and traffic
efficiency, the trajectory planning strategies of CAVs must account for the
influence of HVs, necessitating accurate HV trajectory prediction. Current
research often assumes that human drivers have perfect knowledge of all
vehicles' objectives, an unrealistic premise. This paper bridges the gap by
leveraging hypergame theory to account for cognitive and perception limitations
in HVs. We model human bounded rationality without assuming them to be merely
passive followers and propose a hierarchical cognition modeling framework that
captures cognitive relationships among vehicles. We further analyze the
cognitive stability of the system, proving that the strategy profile where all
vehicles adopt cognitively equilibrium strategies constitutes a hyper Nash
equilibrium when CAVs accurately learn HV parameters. To achieve this, we
develop an inverse learning algorithm for distributed intention interpretation
via vehicle-to-everything (V2X) communication, which extends the framework to
both offline and online scenarios. Additionally, we introduce a distributed
trajectory prediction and planning approach for CAVs, leveraging the learned
parameters in real time. Simulations in highway lane-changing scenarios
demonstrate the proposed method's accuracy in parameter learning, robustness to
noisy trajectory observations, and safety in HV trajectory prediction. The
results validate the effectiveness of our method in both offline and online
implementations.

</details>


### [301] [Q-EnergyDEX: A Zero-Trust Distributed Energy Trading Framework Driven by Quantum Key Distribution and Blockchain](https://arxiv.org/abs/2510.15045)
*Ziqing Zhu*

Main category: eess.SY

TL;DR: 该论文提出了一个名为Q-EnergyDEX的分布式能源交易框架，利用量子密钥分发和区块链技术来解决本地电力市场面临的网络物理安全挑战，特别是对经典加密算法的量子攻击威胁。


<details>
  <summary>Details</summary>
Motivation: 本地电力市场的去中心化和数字化带来了新的网络物理安全漏洞，如密钥泄露、数据篡改和身份欺骗。现有的基于区块链的解决方案虽然提供了透明度和可追溯性，但仍然依赖于易受量子攻击的经典密码学。本研究旨在提出一种能够抵御量子攻击的安全解决方案。

Method: 本研究提出了Q-EnergyDEX框架，该框架整合了物理层的量子随机性和市场层面的操作。具体措施包括：1. 使用基于云的量子密钥管理服务（Quantum Key Management Service）生成可验证的熵，并通过速率自适应算法调节密钥生成以维持高质量的随机性。2. 采用对称认证协议（Q-SAH）建立安全低延迟的会话。3. 利用量子辅助共识机制（PoR-Lite）在几秒钟内实现概率性账本确定性。4. 引入库茨威勒约束的双边拍卖（Stackelberg-constrained bilateral auction）将市场清算与熵可用性相结合，以确保经济效率和密码学安全。

Result: 模拟结果表明，Q-EnergyDEX能够维持稳定的密钥，并实现接近最优的社会福利，证明了其在大规模分布式能源市场中应用的可行性。

Conclusion: Q-EnergyDEX框架成功地利用量子密钥分发和区块链技术，为分布式能源交易提供了一个端到端的量子安全基础设施，有效解决了现有解决方案面临的量子威胁和安全漏洞问题，并在经济效率和密码学安全方面取得了良好平衡。

Abstract: The rapid decentralization and digitalization of local electricity markets
have introduced new cyber-physical vulnerabilities, including key leakage, data
tampering, and identity spoofing. Existing blockchain-based solutions provide
transparency and traceability but still depend on classical cryptographic
primitives that are vulnerable to quantum attacks. To address these challenges,
this paper proposes Q-EnergyDEX, a zero-trust distributed energy trading
framework driven by quantum key distribution and blockchain. The framework
integrates physical-layer quantum randomness with market-level operations,
providing an end-to-end quantum-secured infrastructure. A cloud-based Quantum
Key Management Service continuously generates verifiable entropy and regulates
key generation through a rate-adaptive algorithm to sustain high-quality
randomness. A symmetric authentication protocol (Q-SAH) establishes secure and
low-latency sessions, while the quantum-aided consensus mechanism (PoR-Lite)
achieves probabilistic ledger finality within a few seconds. Furthermore, a
Stackelberg-constrained bilateral auction couples market clearing with entropy
availability, ensuring both economic efficiency and cryptographic security.
Simulation results show that Q-EnergyDEX maintains robust key stability and
near-optimal social welfare, demonstrating its feasibility for large-scale
decentralized energy markets.

</details>


### [302] [Exploring a New Design Paradigm for Omnidirectional MAVs for Minimal Actuation and Internal Force Elimination: Theoretical Framework and Control](https://arxiv.org/abs/2510.15071)
*Ahmed Ali,Chiara Gabellieri,Antonio Franchi*

Main category: eess.SY

TL;DR: 提出一种仅用6个输入实现多旋翼飞行器（MAV）全向性的新型概念，该概念在平衡点无内力。该概念集成了单个主动倾斜的螺旋桨以及3个类似摆的连杆，每个连杆都带有一个螺旋桨，并通过万向节被动连接到主车身上。


<details>
  <summary>Details</summary>
Motivation: 提出一种仅用6个输入实现多旋翼飞行器（MAV）全向性的新型概念，该概念在平衡点无内力。该概念集成了单个主动倾斜的螺旋桨以及3个类似摆的连杆，每个连杆都带有一个螺旋桨，并通过万向节被动连接到主车身上。

Method: 首先开发了多连杆MAV的详细动力学模型。随后，分析确定了平衡构型，并说明对于MAV主平台的每个姿态都存在一个强制平衡。为了使闭环系统中的该平衡点渐近稳定，利用基于SE(3)上的左平凡误差作为主平台构型误差的动态反馈线性化和反步技术，构建了几何非线性控制器。

Result: 该设计确保了全向性，同时最大限度地减少了内力，并且没有采用过度驱动（即超过6个输入）。

Conclusion: 通过数值模拟验证了所提出的方法。模拟结果表明，该MAV在非零初始条件、参数不确定性和执行器噪声下，能够执行解耦的姿态和平移运动。

Abstract: This paper presents a novel concept for achieving omnidirectionality in a
multirotor aerial vehicle (MAV) that uses only 6 inputs and ensures no internal
forces at the equilibria. The concept integrates a single actively-tilting
propeller along with 3 pendulum-like links, each carrying a propeller,
connected by passive universal joints to the main body. We show that this
design ensures omnidirectionality while minimizing the internal forces and
without resorting to overactuation (i.e., more than 6 inputs). A detailed
dynamic model of the multi-link MAV is first developed. Afterwards, the
analysis identifies the equilibrium configurations and illustrates that a
forced equilibrium exists for every pose of the MAV's main platform. In order
to render this equilibrium asymptotically stable for the closed-loop system, a
geometric nonlinear controller is constructed using dynamic feedback
linearization and backstepping techniques with the main platform configuration
error being the left-trivialized error on SE(3). The stability of the
closed-loop system is then investigated by employing standard Lyapunov
arguments on the zero dynamics. We conclude by providing numerical simulations
validating the proposed approach. They demonstrate the MAV capability to
perform decoupled attitude and translational motions under non-zero initial
conditions, parametric uncertainty, and actuators noise.

</details>


### [303] [Sparsity-exploiting Gaussian Process for Robust Transient Learning of Power System Dynamics](https://arxiv.org/abs/2510.15150)
*Tina Gao,Shimiao Li,Lawrence Pileggi*

Main category: eess.SY

TL;DR: 该研究提出了一种鲁棒的瞬态学习方法，用于处理因稀疏损坏模式而导致不准确的高斯过程（GP）推断。通过结合稀疏优化和矩量法（MoM）来应对数据损坏，并优化稀疏权重以识别损坏的仪表位置。为了提高大规模系统的推理速度，还采用了K-medoid聚类进行降维（DR）和聚合表示（AR）。实验证明了该方法在处理随机大误差、定向虚假数据注入和局部PMU时钟漂移方面的鲁棒性，并显著提高了推理速度。


<details>
  <summary>Details</summary>
Motivation: 高斯过程（GP）在从稀疏的PMU测量中学习动态电网行为方面取得了进展，但实际测量可能受到各种随机和定向威胁的破坏，导致结果不准确。本研究旨在克服这一挑战，开发一种鲁棒的瞬态学习方法。

Method: 本研究将稀疏优化与矩量法（MoM）相结合，以确保学习过程对稀疏分布的数据损坏具有鲁棒性。然后，通过优化稀疏权重来识别损坏的仪表位置。为了提高大规模系统的推理速度，采用了K-medoid聚类方法进行降维（DR）和聚合表示（AR）。

Result: 实验结果表明，该方法能够有效应对随机大误差、定向虚假数据注入和局部PMU时钟漂移等问题。在1354个节点的系统上，使用DR方法使推理速度提高了18倍，结合AR方法后速度更是提高了400倍。

Conclusion: 所提出的鲁棒瞬态学习方法能够有效地处理PMU测量数据中的稀疏损坏，并显著提高大规模电网状态估计的效率。

Abstract: Advances in leveraging Gaussian processes (GP) have enabled learning and
inferring dynamic grid behavior from scarce PMU measurements. However, real
measurements can be corrupted by various random and targeted threats, leading
to inaccurate and meaningless results. This paper develops robust transient
learning to overcome this challenge by exploiting the sparse corruption
patterns in the data flow. Specifically, we integrate sparse optimization with
method of moments (MoM) to make learning robust to a sparse distribution of
data corruptions; then, we optimize sparse weights to identify corrupted meter
locations. To improve inference speed on large-scale systems, we further adopt
K-medoid clustering of locations to develop dimension reduction (DR) and
aggregate representation (AR) heuristics. Experimental results demonstrate
robustness against random large errors, targeted false data injections, and
local PMU clock drifts. On a 1354-bus system, inference turns out to be 18x
faster using DR and 400x faster when further combined with AR heuristics.

</details>


### [304] [Tail-Optimized Caching for LLM Inference](https://arxiv.org/abs/2510.15152)
*Wenxin Zhang,Yueying Li,Ciamac C. Moallemi,Tianyi Peng*

Main category: eess.SY

TL;DR: Prompt 缓存对于降低 LLM 推理的延迟和成本至关重要，但 LRU 策略在优化尾部延迟方面表现不佳。我们提出了 Tail-Optimized LRU，一种简单的改进方法，通过优先考虑高延迟对话来优化 KV 缓存分配，并在理论和实验上都证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: Prompt 缓存对于降低 LLM 推理的延迟和成本至关重要，但现有的 LRU 策略在优化尾部延迟方面表现不佳，而尾部延迟对实际应用者至关重要。

Method: 提出 Tail-Optimized LRU，对 LRU 进行两行代码的修改，通过优先逐出不太可能影响未来轮次的缓存条目来重新分配 KV 缓存容量，从而优先考虑高延迟对话。

Result: 在 WildChat 数据集上，Tail-Optimized LRU 与 LRU 相比，P90 尾部首次令牌延迟最多可降低 27.5%，P95 尾部延迟最多可降低 23.9%，SLO 违规（200ms）最多可减少 38.9%。

Conclusion: Tail-Optimized LRU 是一种实用的、理论上有根据的解决方案，可以帮助实际应用者优化 LLM 部署中的尾部延迟。

Abstract: Prompt caching is critical for reducing latency and cost in LLM inference:
OpenAI and Anthropic report up to 50-90% cost savings through prompt reuse.
Despite its widespread success, little is known about what constitutes an
optimal prompt caching policy, particularly when optimizing tail latency, a
metric of central importance to practitioners. The widely used Least Recently
Used (LRU) policy can perform arbitrarily poor on this metric, as it is
oblivious to the heterogeneity of conversation lengths. To address this gap, we
propose Tail-Optimized LRU, a simple two-line modification that reallocates KV
cache capacity to prioritize high-latency conversations by evicting cache
entries that are unlikely to affect future turns. Though the implementation is
simple, we prove its optimality under a natural stochastic model of
conversation dynamics, providing the first theoretical justification for LRU in
this setting, a result that may be of independent interest to the caching
community. Experimentally, on real conversation data WildChat, Tail-Optimized
LRU achieves up to 27.5% reduction in P90 tail Time to First Token latency and
23.9% in P95 tail latency compared to LRU, along with up to 38.9% decrease in
SLO violations of 200ms. We believe this provides a practical and theoretically
grounded option for practitioners seeking to optimize tail latency in
real-world LLM deployments.

</details>


### [305] [A Comparative Study of Oscillatory Perturbations in Car-Following Models](https://arxiv.org/abs/2510.15190)
*Oumaima Barhoumi,Ghazal Farhani,Taufiq Rahman,Mohamed H. Zaki,Sofiène Tahar*

Main category: eess.SY

TL;DR: 研究了车联网和自动驾驶车辆队列的稳定性问题，并通过对比四种不同的跟驰模型（IDM, OVM, GMM, CACC）来评估它们在面对扰动时的表现。


<details>
  <summary>Details</summary>
Motivation: 随着网联车和自动驾驶车辆的普及，车队行驶（platooning）成为提高道路容量、降低燃料消耗和改善交通流的关键策略。然而，车队的稳定性对这些效益至关重要，不稳定性可能导致不安全的车距和能量消耗的增加。

Method: 提出了一种比较研究方法，对比了智能驾驶模型（IDM）、最优速度模型（OVM）、通用汽车模型（GMM）和协同自适应巡航控制（CACC）等不同的跟驰模型。通过在模型中引入扰动（改变领头车的速度），来观察跟驰车辆的行为。具体来说，通过引入正弦振荡和离散速度变化等受控扰动来评估每个模型的动态响应，并分析由此产生的车辆轨迹和车间距变化，以评估各模型对扰动传播的鲁棒性。

Result: 通过对比分析不同模型在面对扰动时的车辆轨迹和车间距变化，评估了各模型对扰动传播的鲁棒性，揭示了模型对扰动的敏感性以及稳定性特征。

Conclusion: 研究结果有助于深入理解不同跟驰模型的敏感性和稳定性特征，并为设计鲁棒的车队控制策略提供了参考。

Abstract: As connected and autonomous vehicles become more widespread, platooning has
emerged as a key strategy to improve road capacity, reduce fuel consumption,
and enhance traffic flow. However, the benefits of platoons strongly depend on
their ability to maintain stability. Instability can lead to unsafe spacing and
increased energy usage. In this work, we study platoon instability and analyze
the root cause of its occurrence, as well as its impacts on the following
vehicle. To achieve this, we propose a comparative study between different
car-following models such as the Intelligent Driver Model (IDM), the Optimal
Velocity Model (OVM), the General Motors Model (GMM), and the Cooperative
Adaptive Cruise Control (CACC). In our approach, we introduce a disruption in
the model by varying the velocity of the leading vehicle to visualize the
behavior of the following vehicles. To evaluate the dynamic response of each
model, we introduce controlled perturbations in the velocity of the leading
vehicle, specifically, sinusoidal oscillations and discrete velocity changes.
The resulting vehicle trajectories and variations in inter-vehicle spacing are
analyzed to assess the robustness of each model to disturbance propagation. The
findings offer insight into model sensitivity, stability characteristics, and
implications for designing resilient platooning control strategies.

</details>


### [306] [Quantum-Key-Distribution Authenticated Aggregation and Settlement for Virtual Power Plants](https://arxiv.org/abs/2510.15239)
*Ziqing Zhu*

Main category: eess.SY

TL;DR: VPPs are crucial for modern grids, but their business pipeline needs secure communication. This paper proposes a quantum-authenticated aggregation and settlement framework for VPPs, using QKD to minimize risk and ensure latency guarantees under cyberattacks and weather shocks. The framework formulates a key-budgeted risk minimization problem, validated by case studies showing reduced risk, fewer SLA violations, and improved key efficiency.


<details>
  <summary>Details</summary>
Motivation: The increasing reliance on VPPs and the vulnerability of their cyber-physical-economic systems to cyberattacks and extreme weather necessitate advanced security measures. Conventional cryptography is insufficient for long-term protection, making QKD a potential solution, but its practical application faces challenges due to limited key generation rates, routing capacity, and system overhead, requiring efficient key allocation.

Method: The paper develops a system-threat model connecting QKD to security strategies, authentication strength, refresh frequency, and delay constraints. It then formulates a key-budgeted risk minimization problem that considers economic risk, service-level violations, and key-budget feasibility. A threshold property linking marginal security value to shadow prices is revealed.

Result: Case studies on a representative VPP system demonstrate that the proposed quantum-authenticated aggregation and settlement framework significantly reduces residual risk and SLA violations. It also enhances key efficiency and robustness, with observed dynamics aligning with the theoretical shadow price mechanism.

Conclusion: The proposed quantum-authenticated aggregation and settlement framework effectively addresses the security challenges in VPPs by optimizing QKD key allocation to minimize risk and meet latency requirements, thereby enhancing the overall security and efficiency of VPP operations.

Abstract: The proliferation of distributed energy resources (DERs) and demand-side
flexibility has made virtual power plants (VPPs) central to modern grid
operation. Yet their end-to-end business pipeline, covering bidding, dispatch,
metering, settlement, and archival, forms a tightly coupled
cyber-physical-economic system where secure and timely communication is
critical. Under the combined stress of sophisticated cyberattacks and extreme
weather shocks, conventional cryptography offers limited long-term protection.
Quantum key distribution (QKD), with information-theoretic guarantees, is
viewed as a gold standard for securing critical infrastructures. However,
limited key generation rates, routing capacity, and system overhead render key
allocation a pressing challenge: scarce quantum keys must be scheduled across
heterogeneous processes to minimize residual risk while maintaining latency
guarantees. This paper introduces a quantum-authenticated aggregation and
settlement framework for VPPs. We first develop a system-threat model that
connects QKD key generation and routing with business-layer security
strategies, authentication strength, refresh frequency, and delay constraints.
Building on this, we formulate a key-budgeted risk minimization problem that
jointly accounts for economic risk, service-level violations, and key-budget
feasibility, and reveal a threshold property linking marginal security value to
shadow prices. Case studies on a representative VPP system demonstrate that the
proposed approach significantly reduces residual risk and SLA violations,
enhances key efficiency and robustness, and aligns observed dynamics with the
theoretical shadow price mechanism.

</details>


### [307] [Techno-Economic Feasibility Analysis of Quantum Key Distribution for Power-System Communications](https://arxiv.org/abs/2510.15248)
*Ziqing Zhu*

Main category: eess.SY

TL;DR: 该论文提出了一个技术经济框架，用于评估量子密钥分发（QKD）在保护未来电网通信免受网络威胁（尤其是量子计算威胁）方面的可行性。通过模拟和经济分析，研究表明混合QKD架构在降低密钥中断概率和提高服务可用性方面表现出色，并在特定条件下（如中等光损耗和适当的缓冲区大小）具有成本效益。


<details>
  <summary>Details</summary>
Motivation: 现代电力系统日益增长的数字化和去中心化使其通信基础设施面临着不断增加的网络风险，特别是在量子计算威胁的背景下。因此，需要评估像QKD这样的新技术的可行性，以确保电力系统通信的安全性。

Method: 开发了一个随机系统模型，结合了密钥需求、受光损耗限制的QKD供应、缓冲区和后量子密码学（PQC）的后备机制。推导了服务水平保证的分析条件，并制定了包括量子密钥分发（QKD）的单位安全成本（LCoSec）和增量安全成本（CIS）在内的量化指标。使用IEEE测试系统进行了离散事件模拟，比较了纯PQC、纯QKD和混合架构。

Result: 模拟结果表明，以QKD为主导的混合架构显著降低了密钥中断概率和服务水平协议（SLA）的不足，实现了近乎单位的服务可用性。经济分析显示，在特定条件下（主要在城市和配电网络中，中等光损耗和缓冲区大小），采用QKD的部署变得具有成本效益。

Conclusion: 该研究提出了一个可重现的、风险感知的决策工具，为未来大规模、经济上合理的QKD在弹性电力系统基础设施中的应用提供了指导。混合QKD架构在提高电力系统通信安全性和可靠性方面显示出巨大潜力。

Abstract: The accelerating digitalization and decentralization of modern power systems
expose critical communication infrastructures to escalating cyber risks,
particularly under emerging quantum computing threats. This paper presents an
integrated techno-economic framework to evaluate the feasibility of Quantum Key
Distribution (QKD) for secure power-system communications. A stochastic system
model is developed to jointly capture time-varying key demand, QKD supply under
optical-loss constraints, station-side buffering, and post-quantum cryptography
(PQC) fallback mechanisms. Analytical conditions are derived for service-level
assurance, including buffer stability, outage probability, and availability
bounds. Building on this, two quantitative metrics, including the Levelized
Cost of Security (LCoSec) and Cost of Incremental Security (CIS), are
formulated to unify capital, operational, and risk-related expenditures within
a discounted net-present-value framework. Using IEEE 118-bus, 123-node, and
39-bus test systems, we conduct discrete-event simulations comparing PQC-only,
QKD-only, and Hybrid architectures across multiple topologies and service
profiles. Results show that Hybrid architectures dominated by QKD significantly
reduce key-outage probability and SLA shortfalls, achieving near-unit
availability for real-time and confidentiality-critical services. Economic
analyses reveal clear breakeven zones where QKD-enhanced deployments become
cost-effective, primarily in metropolitan and distribution-level networks under
moderate optical loss and buffer sizing. The proposed framework provides a
reproducible, risk-aware decision tool for guiding large-scale, economically
justified QKD adoption in future resilient power-system infrastructures.

</details>


### [308] [Comprehensive Dynamic Modeling and Constraint-Aware Air Supply Control for Localized Water Management in Automotive Polymer Electrolyte Membrane Fuel Cells](https://arxiv.org/abs/2510.15250)
*Mostafaali Ayubirad,Zeng Qiu,Hao Wang,Chris Weinkauf,Michiel Van Nieuwstadt,Hamid R. Ossareh*

Main category: eess.SY

TL;DR: 本文提出了一种预测性约束感知控制方案，用于质子交换膜（PEM）燃料电池系统的局部水合管理。


<details>
  <summary>Details</summary>
Motivation: 为了解决质子交换膜燃料电池系统中的局部水合管理问题，特别是防止膜干燥。

Method: 提出了一种基于命令调控器（CG）框架的预测性约束感知控制方案。首先，建立了包含堆栈、反应物供应和冷却子系统的伪二维（P2D）模型的综合非线性动力学模型。然后，推导了一个降阶线性化模型来近似膜水合行为，并将其用于CG框架，以在必要时调整空气供应设定点，从而防止膜干燥。

Result: 通过实际工况模拟，证明了该方法在保持局部膜水合的同时，能够紧密跟踪所要求的净功率。

Conclusion: 所提出的命令调控器（CG）框架下的预测性约束感知控制方案能够有效地维持局部膜水合，并紧密跟踪净功率需求。

Abstract: In this paper, a predictive constraint-aware control scheme is formulated
within the Command Governor (CG) framework for localized hydration management
of a proton exchange membrane (PEM) fuel cell system. First, a comprehensive
nonlinear dynamic model of the fuel cell system is presented which includes a
pseudo 2-dimensional (P2D) model of the stack, reactant supply and cooling
subsystems. The model captures the couplings among the various subsystems and
serves as the basis for designing output feedback controllers to track the
optimal set-points of the air supply and cooling systems for power
optimization. The closed-loop nonlinear model is then used to analyze the
dynamic behavior of membrane hydration near the anode inlet, the driest region
of the membrane in a counter-flow configuration, under various operating
conditions. A reduced-order linearized model is then derived to approximate
hydration behavior with sufficient fidelity for constraint enforcement. This
model is used within the CG framework to adjust the air supply set-points when
necessary to prevent membrane dry-out. The effectiveness of the proposed
approach in maintaining local membrane hydration while closely tracking the
requested net power is demonstrated through realistic drive-cycle simulations.

</details>


### [309] [Modeling and Dynamic Simulation of a Hybrid Wind-Wave System on a Hexagonal Semi-Submersible Platform](https://arxiv.org/abs/2510.15285)
*Saeid Bayat,Jerry Zuo,Jing Sun*

Main category: eess.SY

TL;DR: 本研究提出了一种集成了风力涡轮机和振荡波浪能转换器（WEC）的混合式海上平台，并对其进行了建模、仿真和可行性分析。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有海上可再生能源系统各自独立运行的局限性，本研究旨在提出一种能够同时捕获风能和波浪能的混合式海上平台。

Method: 本研究设计了一种集成了风力涡轮机和三个振荡波浪能转换器（WEC）的六边形半潜式平台。利用WEC-Sim建立了仿真框架，并通过与NREL 5 MW半潜式参考模型进行比对进行基准测试。对平台的稳性、几何变量进行了敏感性分析，并进行了时域仿真以评估不同波浪入射角下的性能。最后，基于场地数据估算了年能量生产（AEP）。

Result: 仿真结果表明，该混合平台在静水力学上是稳定的，并且襟翼的尺寸和塔身长度是影响稳性、能量捕获和塔身应力的主要因素。时域仿真显示，平台的性能受波浪入射角影响，襟翼的功率分配、捕获宽度比（CWR）和平台响应均有变化。此外，研究还证明了可以通过改变襟翼的扫掠范围来调节俯仰运动。年能量生产估算显示，风能可提供16.86 GWh，波浪能可提供3.65 GWh，其中WEC的贡献约为总能量的18%。

Conclusion: 本研究提出的集成风浪混合式海上平台具有显著的应用潜力，能够有效提高海上可再生能源的利用率。未来的研究可以进一步关注结构的详细建模和先进控制策略的开发。

Abstract: Offshore renewable energy systems offer promising solutions for sustainable
power generation, yet most existing platforms harvest either wind or wave
energy in isolation. This study presents a hybrid floating offshore platform
that integrates a wind turbine with three oscillating surge wave energy
converters (WECs) into a hexagonal semi-submersible structure. In this
configuration, the flaps are integrated with the platform geometry to provide
both energy extraction and hydrodynamic stability. A modeling and simulation
framework was developed using WEC-Sim and benchmarked against the NREL 5 MW
semisubmersible reference. Metacentric height analysis confirmed hydrostatic
stability across a range of prescribed flap angles. Sensitivity analysis of
twelve geometric variables identified flap dimensions and tower length as
dominant drivers of stability, energy capture, and tower stress. Time-domain
simulations revealed dependence on wave incidence angle, with variations in
flap power sharing, capture width ratio (CWR), and platform response. The
feasibility of using flap sweeps to modulate pitch motion was also
demonstrated. Annual energy production (AEP) estimates based on site-specific
data indicate 16.86 GWh from wind and 3.65 GWh from wave energy, with WECs
contributing about 18% of the total. These results highlight the potential of
integrated wind-wave platforms and point toward future studies on structural
modeling and advanced control.

</details>


### [310] [A Tsetlin Machine Image Classification Accelerator on a Flexible Substrate](https://arxiv.org/abs/2510.15519)
*Yushu Qin,Marcos L. L. Sartori,Shengyu Duan,Emre Ozer,Rishad Shafik,Alex Yakovlev*

Main category: eess.SY

TL;DR: 本论文实现了首个基于柔性IGZO技术的数字Tsetlin Machine (TM) 芯片，证明了TM在柔性电子设备上的可行性。


<details>
  <summary>Details</summary>
Motivation: 在柔性集成电路（FlexIC）上实现以高能效、可解释性和适用于边缘计算而闻名的Tsetlin Machines (TM)，以克服传统硅基芯片的刚性限制。

Method: 开发了两种TM推理模型作为FlexIC芯片：一种采用6800个NAND2等效逻辑门，面积为8x8 mm²，准确率达到98.5%；另一种更紧凑的版本采用1420个NAND2等效门，面积为4x4 mm²，准确率为93%。两个模型均针对8x8像素手写数字识别数据集进行了定制设计。

Result: 成功在柔性IGZO技术上实现了两种TM推理模型，分别在精度和尺寸/功耗上达到了不同的平衡点，证明了其在特定任务上的有效性。

Conclusion: 本研究证明了将柔性TM推理引擎部署到可穿戴健康和边缘计算应用中的可行性。

Abstract: This paper introduces the first implementation of digital Tsetlin Machines
(TMs) on flexible integrated circuit (FlexIC) using Pragmatic's 600nm
IGZO-based FlexIC technology. TMs, known for their energy efficiency,
interpretability, and suitability for edge computing, have previously been
limited by the rigidity of conventional silicon-based chips. We develop two TM
inference models as FlexICs: one achieving 98.5% accuracy using 6800 NAND2
equivalent logic gates with an area of 8X8 mm2, and a second more compact
version achieving slightly lower prediction accuracy of 93% but using only 1420
NAND2 equivalent gates with an area of 4X4 mm2, both of which are
custom-designed for an 8X8-pixel handwritten digit recognition dataset. The
paper demonstrates the feasibility of deploying flexible TM inference engines
into wearable healthcare and edge computing applications.

</details>


### [311] [Observer Design over Hypercomplex Quaternions](https://arxiv.org/abs/2510.15598)
*Michael Sebek*

Main category: eess.SY

TL;DR: 本研究提出了一种在超复数四元数上设计观测器的方法，该方法不依赖于特征多项式，通过右可观测伴随型及其伴随多项式来编码误差动态，并避免了不适用于四元数的行列式和特征多项式等概念。


<details>
  <summary>Details</summary>
Motivation: 旨在解决在超复数四元数环境下设计观测器的问题，并克服传统方法在四元数上失效的限制。

Method: 提出了一种在超复数四元数上设计观测器的方法，该方法不依赖于特征多项式，通过右可观测伴随型及其伴随多项式来编码误差动态，并避免了不适用于四元数的行列式和特征多项式等概念。

Result: 给出了全阶观测器的简单设计方案，阐明了右谱及其相似类的作用，并指出了经典单次公式有效的条件。数值算例证明了该方法及其优于向量化或复共轭替代方法的优点。

Conclusion: 研究结果为在四元数上直接设计全阶观测器提供了简单易行的方法，并加深了对右谱和相似类在观测器设计中的作用的理解。

Abstract: We develop observer design over hypercomplex quaternions in a
characteristic-polynomial-free framework. Using the standard right-module
convention, we derive a right observable companion form and its companion
polynomial that encodes error dynamics via right-eigenvalue similarity classes.
The design mirrors the real/complex case - coefficient updates in companion
coordinates, followed by a similarity back - yet avoids determinants,
characteristic/minimal polynomials, and Cayley-Hamilton identities that do not
transfer to quaternions. We also give an Ackermann-type construction for the
important case of closed-loop companion polynomials with real coefficients,
ensuring similarity-equivariant evaluation. The results yield simple recipes
for full-order observers directly over quaternions, clarify the role of right
spectra and their similarity classes, and pinpoint when classical one-shot
formulas remain valid. Numerical examples illustrate the method and advantages
over vectorized or complex-adjoint surrogates.

</details>


### [312] [A Predictive Flexibility Aggregation Method for Low Voltage Distribution System Control](https://arxiv.org/abs/2510.15613)
*Clément Moureau,Thomas Stegen,Mevludin Glavic,Bertrand Cornélusse*

Main category: eess.SY

TL;DR: 本文提出了一种用于管理低压配电系统的预测控制策略，通过聚合住宅单元的灵活性并将其表示为三维图表（包含注入的有功功率、无功功率和灵活性成本），实现了高效、低成本且保护隐私的系统管理。


<details>
  <summary>Details</summary>
Motivation: 低压配电系统需要一种能够整合住宅单元灵活性的管理策略，以满足实时控制需求并实现高效、低成本和隐私保护的管理。

Method: 首先，离线解决多参数优化问题以聚合住宅单元的资产灵活性。然后，解决半显式模型预测控制问题以考虑预测。结合两者的结果和测量值生成灵活性图表。

Result: 该方法在包含5个节点的低压网络上进行了验证，并与一种理想技术进行了比较，证明了其有效性。

Conclusion: 该方法通过将实时灵活性评估与能源调度相结合，实现了对低压配电系统的有效、低成本和隐私保护的管理，并且适用于实时控制要求。

Abstract: This paper presents a predictive control strategy to manage low-voltage
distribution systems. The proposed approach relies on an aggregate of the
flexibility at the residential unit level into a three-dimensional chart that
represents the injected active and reactive power, and the flexibility cost.
First, this method solves a multiparametric optimization problem offline at the
residential unit level to aggregate the flexibility of the assets. Then, a
semi-explicit model predictive control problem is solved to account for
forecasts. By combining the results of these problems with measurements, the
method generates the desired flexibility chart. The proposed approach is
compatible with realtime control requirements, as heavy computations are
performed offline locally, making it naturally parallelizable. By linking
realtime flexibility assessment with energy scheduling, our approach enables
efficient, low-cost, and privacy-preserving management of low-voltage
distribution systems. We validate this method on a low-voltage network of 5
buses by comparing it with an ideal technique.

</details>


### [313] [Cross-border offshore hydrogen trade and carbon mitigation for Europe's net zero transition](https://arxiv.org/abs/2510.15695)
*Sheng Wang,Muhammad Maladoh Bah*

Main category: eess.SY

TL;DR: 欧洲国家雄心勃勃地致力于净零排放转型和海上能源资源开发。爱尔兰和英国政府承诺到 2050 年实现海上风电容量——分别为 37 吉瓦和 125 吉瓦，这超过了他们预测的电力需求的两倍。与此同时，德国等其他欧洲大陆国家则呼吁提供更清洁的燃料资源。出口剩余的海上绿色氢气并弥合供需缺口，对于欧洲减缓碳排放至关重要。然而，这些岛国的潜力通常被低估。本文采用自下而上的方法，研究了爱尔兰和英国的海上氢气在整个欧洲脱碳过程中所起的作用。我们评估了未来的氢气/氨气贸易以及每个国家在减缓碳排放方面的贡献，同时考虑了它们在海上氢气生产、国内每小时电力和天然气系统运行以及国际航运成本方面的相对成本竞争力。结果表明，海上绿色氢气每年可减少欧洲 1.7516 亿吨二氧化碳排放量。从 2030 年到 2040 年，英国将是最大的氢气供应国，到 2050 年将被爱尔兰超越，届时将向法国和西班牙出口 161 太瓦时的氢气。海上绿色氢气每年可减少 1.7516 亿吨二氧化碳排放量。这种从西向东的总体氢气流动不仅促进了欧洲的净零排放进展，而且重塑了能源供应结构，并有助于确保整个欧洲大陆的能源安全。


<details>
  <summary>Details</summary>
Motivation: 欧洲国家在净零排放转型和海上能源发展方面雄心勃勃，特别是爱尔兰和英国的海上风电目标远超其电力需求。因此，探索海上绿色氢气的出口潜力，以实现欧洲的脱碳目标并弥合供需缺口，具有重要意义。

Method: 本文采用自下而上的方法，评估了爱尔兰和英国的海上绿色氢气在欧洲脱碳中的作用。研究考虑了贸易、成本竞争力、国内电力和天然气系统运行以及国际航运成本等因素，以量化其对碳减排的贡献。

Result: 研究结果表明，海上绿色氢气每年可为欧洲减少 1.7516 亿吨二氧化碳排放量。英国将是 2030 年至 2040 年间最大的氢气供应国，而爱尔兰将在 2050 年超过英国，并向法国和西班牙出口 161 太瓦时的氢气。这种从西向东的氢气流动有助于欧洲的净零排放目标、能源结构重塑和能源安全。

Conclusion: 海上绿色氢气，特别是来自爱尔兰和英国的海上绿色氢气，在欧洲的脱碳进程中扮演着关键角色，能够显著减少碳排放，并对欧洲的能源供应结构和安全产生积极影响。

Abstract: European countries are ambitious in both the net-zero transition and offshore
energy resource development. The Irish and UK governments announced their
commitments to offshore wind capacities - 37 and 125 GW, respectively, in 2050,
more than two times higher than their projected power demands. While other
continental countries, such as Germany, are calling for cleaner fuel resources.
Exporting surplus offshore green hydrogen and bridging supply and demand could
be pivotal in carbon emission mitigation for Europe. Yet, the potentials of
these Island countries, are usually underestimated. This paper developed a
bottom-up method to investigate the role of offshore hydrogen from Ireland and
the UK in the decarbonisation of the entire Europe. We evaluate the future
hydrogen/ammonia trading and the contributions of each country in carbon
emission mitigation, considering their relative cost-competitiveness in
offshore hydrogen production, domestic hourly power and gas system operation,
and international shipping costs. Results indicate that the offshore green
hydrogen could reduce 175.16 Mt/year of carbon dioxide emissions in Europe. The
UK will be the largest hydrogen supplier from 2030 to 2040, while surpassed by
Ireland in 2050, with 161 TWh of hydrogen exports to France and Spain. The
offshore green hydrogen can contribute to 175.16 Mt of annual carbon dioxide
emission reductions in total. This general flow of hydrogen from the West to
the East not only facilitates Europe's net-zero progress, but also reshapes the
energy supply structure and helps to ensure energy security across the European
continent.

</details>


### [314] [Mitigating Underwater Noise from Offshore Wind Turbines via Individual Pitch Control](https://arxiv.org/abs/2510.15707)
*Martín de Frutos,Laura Botero-Bolívar,Esteban Ferrer*

Main category: eess.SY

TL;DR: 本研究提出了一种俯仰控制策略，以减小海上风力涡轮机水下声学足迹，为保护海洋生物至关重要。


<details>
  <summary>Details</summary>
Motivation: 由于海洋生物依赖声音进行交流、导航和生存，因此有必要减小海上风力涡轮机对水下声学的影响。

Method: 首先，研究人员使用耦合叶片单元动量和耦合空气-水声传播模型量化了三种参考涡轮机（NREL 5 MW、DTU 10 MW 和 IEA 22 MW）产生的叶片气动噪声的水下声学特征。其次，提出并实施了一种开环个体叶片俯仰（IPC）控制策略，该策略在叶片通过频率下调节叶片俯仰，以衰减整体声压级（OSPL）和传输噪声的幅度调制（AM）。最后，将 IPC 性能与传统俯仰方案进行比较。

Result: 研究结果表明，通过大约 5° 的俯仰角变化，可以将 OSPL 降低高达 5 dB，并将 AM 深度降低 20%，同时仅损失 5-10% 的能量捕获量。

Conclusion: 研究结果强调了一个先前未被充分认识的噪声传播途径，并证明了目标叶片俯仰调制可以减轻其影响。

Abstract: This paper proposes a pitch control strategy to mitigate the underwater
acoustic footprint of offshore wind turbines, a measure that will soon become
necessary to minimize impacts on marine life, which rely on sound for
communication, navigation, and survival. First, we quantify the underwater
acoustic signature of blade-generated aerodynamic noise from three reference
turbines, the NREL 5 MW, DTU 10 MW, and IEA 22 MW, using coupling blade element
momentum and coupled air-water acoustic propagation modeling. Second, we
propose and implement an open-loop individual pitch control (IPC) strategy that
modulates the pitch of the blade at the blade passing frequency to attenuate
the overall sound pressure level (OSPL) and the amplitude modulation (AM) of
the transmitted noise. Third, we benchmark IPC performance against conventional
pitch schemes. The results indicate that up to 5 dB reductions in OSPL and a
decrease in AM depth 20% can be achieved with a pitch variation of
$\Delta\theta\approx 5^\circ$, with small losses (5-10%) in energy capture.
These findings highlight a previously underappreciated noise pathway and
demonstrate that targeted blade-pitch modulation can mitigate its impact.

</details>


### [315] [Sugar Shack 4.0: Practical Demonstration of an IIoT-Based Event-Driven Automation System](https://arxiv.org/abs/2510.15708)
*Thomas Bernard,François Grondin,Jean-Michel Lavoie*

Main category: eess.SY

TL;DR: 提出一种基于工业物联网工具的事件驱动架构，作为PLC中心化自动化的替代方案，并成功应用于枫糖浆生产中心。


<details>
  <summary>Details</summary>
Motivation: 提供一种可行的、非PLC中心的自动化替代方案，利用工业物联网技术实现事件驱动的自动化。

Method: 采用分层设计，在本地边缘服务器上实现：(i)执行器抽象；(ii)通过带优先级队列的联锁强制共享物理资源互斥；(iii)组合确定性单一操作；(iv)在Node-RED中将完整工作流编排为状态机，并使用MQTT进行通信。设备层使用ESP32网关接口传感器和执行器，所有自动化逻辑都卸载到服务器端。

Result: 在枫糖浆生产中心的实际部署和整个生产季的评估显示：消息传输中位时延约为0.1秒，命令发出到动作的延迟约2-3秒，命令完成（受执行器机械限制）约6秒。操作运行时间从几秒到几分钟不等。

Conclusion: 所提出的系统在网络和编排开销可忽略不计的情况下，实现了模块化、分布式的控制，且不影响确定性和故障隔离。该方法减少了物料和集成工作量，支持可移植的容器化部署，并自然地实现了边缘/云分离。

Abstract: This paper presents a practical alternative to
programmable-logic-controller-centric automation by implementing an
event-driven architecture built with industrial Internet of Things tools. A
layered design on a local edge server (i) abstracts actuators, (ii) enforces
mutual exclusion of shared physical resources through an interlock with
priority queueing, (iii) composes deterministic singular operations, and (iv)
orchestrates complete workflows as state machines in Node-RED, with
communication over MQTT. The device layer uses low-cost ESP32-based gateways to
interface sensors and actuators, while all automation logic is offloaded to the
server side. As part of a larger project involving the first
scientifically-documented integration of Industry 4.0 technologies in a maple
syrup boiling center, this work demonstrates the deployment of the proposed
system as a case-study. Evaluation over an entire production season shows
median message time of flight around one tenth of a second, command
issuance-to-motion latencies of about two to three seconds, and command
completion near six seconds dominated by actuator mechanics; operation runtimes
span tens of seconds to minutes. These results indicate that network and
orchestration overheads are negligible relative to process dynamics, enabling
modular, distributed control without compromising determinism or fault
isolation. The approach reduces material and integration effort, supports
portable containerized deployment, and naturally enables an edge/cloud split in
which persistence and analytics are offloaded while automation remains at the
edge.

</details>


### [316] [Integrating Conductor Health into Dynamic Line Rating and Unit Commitment under Uncertainty](https://arxiv.org/abs/2510.15740)
*Geon Roh,Jip Kim*

Main category: eess.SY

TL;DR: 该研究量化了动态线路额定值(DLR)下的高温运行(ETO)成本，并提出了一种考虑导体健康成本的单元承诺(CHA-UC)模型，以在优化电网运行的同时，降低成本并减少可再生能源的浪费。


<details>
  <summary>Details</summary>
Motivation: DLR 能够更有效地利用现有输电线路，但在实际应用中，其高温运行 (ETO) 对导体的长期健康影响常被忽视。本研究旨在解决此问题，量化 ETO 相关的折旧成本，并将其纳入电网运行决策。

Method: 提出了一种导体健康感知单元承诺 (CHA-UC) 模型。该模型通过稳健的线性近似方法来估算导体温度，并将因 ETO 导致的预期折旧成本整合到目标函数中，以指导运行决策。

Result: 在德克萨斯州 123 节点测试系统上的案例研究表明，与静态线路额定值 (SLR) 相比，CHA-UC 模型可将总成本降低 0.8%，可再生能源弃置率降低 84%。未经风险考量的常规 DLR 运行反而会因过度 ETO 导致成本增加。CHA-UC 模型通过调整发电机组的承诺组合，实现了更安全的线路潮流。

Conclusion: CHA-UC 模型能够有效地将导体健康成本纳入电网运行决策，在提高 DLR 利用率的同时，降低了运营成本和可再生能源弃置率，并确保了线路安全。此外，该模型还能根据风力发电与 DLR 预测误差之间的相关性，自适应地调整运行策略，以对冲或规避风险。

Abstract: Dynamic line rating (DLR) enables greater utilization of existing
transmission lines by leveraging real-time weather data. However, the elevated
temperature operation (ETO) of conductors under DLR is often overlooked,
despite its long-term impact on conductor health. This paper addresses this
issue by 1) quantifying depreciation costs associated with ETO and 2) proposing
a Conductor Health-Aware Unit Commitment (CHA-UC) that internalizes these costs
in operational decisions. The CHA-UC incorporates a robust linear approximation
of conductor temperature and integration of expected depreciation costs due to
hourly ETO into the objective function. Case studies on the Texas 123-bus
backbone test system using NOAA weather data demonstrate that the proposed
CHA-UC model reduces the total cost by 0.8% and renewable curtailment by
84%compared to static line rating (SLR), while conventional DLR operation
without risk consideration resulted in higher costs due to excessive ETO.
Further analysis of the commitment decisions and the line temperature
statistics confirms that the CHA-UC achieves safer line flows by shifting
generator commitments. Finally, we examine the emergent correlation between
wind generation and DLR forecast errors, and show that CHA-UC adaptively
manages this effect by relaxing flows for risk-hedging conditions while
tightening flows for risk-amplifying ones.

</details>


### [317] [Braking within Barriers: Constructive Safety-Critical Control for Input-Constrained Vehicles via the Backup Set Method](https://arxiv.org/abs/2510.15797)
*Laszlo Gacsi,Adam K. Kiss,Tamas G. Molnar*

Main category: eess.SY

TL;DR: 该研究提出了一种安全关键控制框架，用于在不对称路面上制动时保持车辆的侧向运动在规定范围内，旨在防止车辆失控打转，同时最小化制动距离。


<details>
  <summary>Details</summary>
Motivation: 车辆在不对称路面上制动时，存在侧向运动失控的风险，需要保证车辆安全。

Method: 研究人员提出了一种制动控制器，利用了后备控制屏障函数（backup control barrier functions）来设计安全控制器。为了构建后备集和后备控制器，他们提出了一种基于反馈线性化和连续时间李雅普诺夫方程（continuous-time Lyapunov equations）的新颖系统化方法。

Result: 通过简单的示例和在四轮车辆模型上进行制动仿真，验证了所提出的安全关键控制方法的有效性。

Conclusion: 该研究成功提出并验证了一种安全关键控制方法，能够有效防止车辆在不对称路面上制动时发生侧向失控，并能在输入约束条件下最小化制动距离。

Abstract: This paper presents a safety-critical control framework to maintain bounded
lateral motions for vehicles braking on asymmetric surfaces. We synthesize a
brake controller that assists drivers and guarantees safety against excessive
lateral motions (i.e., prevents the vehicle from spinning out) while minimizing
the stopping distance. We address this safety-critical control problem in the
presence of input constraints, since braking forces are limited by the
available friction on the road. We use backup control barrier functions for
safe control design. As this approach requires the construction of a backup set
and a backup controller, we propose a novel, systematic method to creating
valid backup set-backup controller pairs based on feedback linearization and
continuous-time Lyapunov equations. We use simple examples to demonstrate our
proposed safety-critical control method. Finally, we implement our approach on
a four-wheel vehicle model for braking on asymmetric surfaces and present
simulation results.

</details>


### [318] [Bio-inspired Microgrid Management based on Brain's Sensorimotor Gating](https://arxiv.org/abs/2510.15847)
*Panos C. Papageorgiou,Anastasios E. Giannopoulos,Sotirios T. Spantideas*

Main category: eess.SY

TL;DR: 本文提出了一种受大脑感觉运动门控机制（特别是前脉冲抑制和前脉冲促进）启发的神经微电网（SG-NMG）框架，用于增强微电网在动态扰动处理、保护协调和不确定性方面的能力，将PPI映射为保护性阻尼，将PPF映射为自适应放大控制动作，并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 微电网在实现弹性、可持续和智能电网方面发挥着关键作用，但在动态扰动处理、保护协调和不确定性方面仍面临挑战。

Method: 通过将大脑的感觉运动门控机制（PPI和PPF）映射到微电网的层级控制结构，提出了一种名为SG-NMG的框架，并进行了分析工作流程设计、神经电路类比和机器学习集成。

Result: 提出的SG-NMG框架通过类比PPI和PPF机制，为微电网提供了自保护、自适应和弹性的控制策略。

Conclusion: 感觉运动门控为设计自保护、自适应和弹性微电网提供了一个有前景的框架，但仍需在数学建模、数字孪生验证和跨学科合作等方面进行深入研究。

Abstract: Microgrids are emerging as key enablers of resilient, sustainable, and
intelligent power systems, but they continue to face challenges in dynamic
disturbance handling, protection coordination, and uncertainty. Recent efforts
have explored Brain Emotional Learning (BEL) controllers as bio-inspired
solutions for microgrid control. Building on this growing trajectory, this
article introduces a new paradigm for Neuro-Microgrids, inspired by the brain's
sensorimotor gating mechanisms, specifically the Prepulse Inhibition (PPI) and
Prepulse Facilitation (PPF). Sensorimotor gating offers a biological model for
selectively suppressing or amplifying responses depending on contextual
relevance. By mapping these principles onto the hierarchical control
architecture of microgrids, we propose a Sensorimotor Gating-Inspired
Neuro-Microgrid (SG-NMG) framework. In this architecture, PPI-like control
decisions correspond to protective damping in primary and secondary management
of microgrids, whereas PPF-like decisions correspond to adaptive amplification
of corrective control actions. The framework is presented through analytical
workflow design, neuro-circuitry analogies, and integration with machine
learning methods. Finally, open challenges and research directions are
outlined, including the mathematical modeling of gating, digital twin
validation, and cross-disciplinary collaboration between neuroscience and
industrial power systems. The resulting paradigm highlights sensorimotor gating
as a promising framework for designing self-protective, adaptive, and resilient
microgrids.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [319] [Stroboscopic Saturation of Multiparameter Quantum Limits in Distributed Quantum Sensing](https://arxiv.org/abs/2510.15029)
*Berihu Teklu,Victor Montenegro*

Main category: quant-ph

TL;DR: 使用量子现象的高精度传感器可以超越标准的量子测量精度极限。然而，在多参数同时编码的场景下，由于最优测量方法的不兼容性，其实际应用受到限制。本文提出了一种针对分布式量子传感网络的通用框架，用于同时估计多个参数，并在理论和实践上解决了量子优势的实现问题。


<details>
  <summary>Details</summary>
Motivation: 在多参数同时编码的量子传感场景下，实现超越标准量子极限的测量精度并找到最优测量策略是一个关键挑战。

Method: 通过解析方法证明了分布式量子探针在估计全局性质时具有量子增强的灵敏度，并提出了相应的最优测量策略，实现了Holevo和量子Cramér-Rao界限的饱和。并将该框架应用于重力测量和耦合强度估计。

Result: 在多种分布式量子探针场景下，包括可以实现二次或四次精度标度的场景，都得到了量子增强的灵敏度。并且，提出的最优测量策略可以达到理论上的精度极限。提出的方案在重力测量和耦合强度估计的场景下具有可行性，并有望在当前实验技术下实现。

Conclusion: 本文提出了一种通用的量子传感框架，能够实现多参数估计的量子优势，并给出了具体的测量策略，在重力测量和耦合强度估计等场景下具有实际应用潜力，且符合当前实验技术的可行性。

Abstract: High-precision sensors that exploit uniquely quantum phenomena have been
shown to surpass the standard quantum limit of measurement precision. However,
in the general scenario where multiple parameters are simultaneously encoded in
a quantum probe, while surpassing the standard quantum limit is possible, its
practical attainability is severely hindered. This difficulty arises due to the
fundamental incompatibility among the optimal measurements required for
estimating different parameters. A naturally multiparameter sensing scenario
emerges when a network of quantum sensors is spatially distributed, with each
individual sensor probing a distinct parameter of interest. The central goal in
such a setting is twofold: first, to surpass the standard quantum limit in
estimating global properties of the system -- thereby achieving
quantum-enhanced sensitivity for a given network size -- and second, to
explicitly identify the optimal measurement strategies necessary to practically
attain this quantum advantage. Here, we analytically demonstrate
quantum-enhanced sensitivity for a broad class of distributed quantum probes,
including cases where the precision scales quadratically or quartically with
the sensing resources. We construct the corresponding optimal measurement
strategies that achieve the ultimate precision limits -- namely, saturation of
both the Holevo and quantum Cram\'{e}r-Rao bounds. We then apply our framework
to two concrete scenarios: the simultaneous estimation of multiple
gravitational accelerations (gravimetry) and coupling strengths across
spatially separated locations. Feasibility analyses indicate that the proposed
distributed quantum-enhanced sensing schemes are within reach of current
experimental capabilities.

</details>


### [320] [Solving the 3D Heat Equation with VQA via Remeshing-Based Warm Starts](https://arxiv.org/abs/2510.15645)
*Samuel Donachie,Ulysse Remond,Arthur Mathorel,Kyryl Kazymyrenko*

Main category: quant-ph

TL;DR: VQA 可用于求解热传导方程，通过 FEM 离散化得到线性方程组 Ku=f。


<details>
  <summary>Details</summary>
Motivation: 量子计算有望解决经典难以处理的问题，如线性系统和偏微分方程（PDEs）。

Method: 使用 VQA 求解热传导方程的 PDEs，通过 FEM 离散化为线性系统。引入一种渐进式网格细化策略来优化成本函数，并复用先前优化过的参数以提升训练能力并避开平台期。

Result: 研究结果表明，标量量随网格细化而收敛。

Conclusion: 这项工作提供了一种将 VQA 应用于 PDEs 的实用方法，并揭示了当前量子硬件的能力与局限性。

Abstract: Quantum computing holds great promise for solving classically intractable
problems such as linear systems and partial differential equations (PDEs).
While fully fault-tolerant quantum computers remain out of reach, current noisy
intermediate-scale quantum (NISQ) devices enable the exploration of hybrid
quantum-classical algorithms. Among these, Variational Quantum Algorithms
(VQAs) have emerged as a leading candidate for near-term applications. In this
work, we investigate the use of VQAs to solve PDEs arising in stationary heat
transfer. These problems are discretized via the finite element method (FEM),
yielding linear systems of the form Ku=f, where K is the stiffness matrix. We
define a cost function that encodes the thermal energy of the system, and
optimize it using various ansatz families. To improve trainability and bypass
barren plateaus, we introduce a remeshing strategy which gradually increases
resolution by reusing optimized parameters from coarser discretizations. Our
results demonstrate convergence of scalar quantities with mesh refinement. This
work provides a practical methodology for applying VQAs to PDEs, offering
insight into the capabilities and limitations of current quantum hardware.

</details>


### [321] [Second-order discretization of Dyson series: iterative method, numerical analysis and applications in open quantum systems](https://arxiv.org/abs/2510.15287)
*Zhenning Cai,Yixiao Sun,Geshuo Wang*

Main category: quant-ph

TL;DR: 提出一种通用的方法离散化 Dyson 级数，用于模拟开放量子系统中的系统-浴动力学，并开发了两种数值方案（一阶和二阶），其中二阶方案在保持二阶精度的情况下显著降低了计算复杂性，并减少了内存和计算资源的需求。


<details>
  <summary>Details</summary>
Motivation: 提出一种通用的策略来离散化 Dyson 级数，以解决高维积分的数值计算问题，并将其扩展到开放量子系统，以模拟系统-浴动力学。

Method: 该方法将 Dyson 级数离散化，并结合 Strang 分裂和泰勒展开。开发了一阶和二阶数值方案，并通过严格的数值分析证明了它们的收敛阶。二阶方案通过省略部分项来优化计算复杂度。

Result: 一阶和二阶方法的全局误差分别以 O(Δt) 和 O(Δt^2) 的速度减小。二阶方法在保持二阶精度的同时，显著降低了计算复杂性，计算复杂度为 O(M^3 2^(2Kmax) Kmax^2)，空间复杂度为 O(M^2 2^(2Kmax) Kmax)。对于多能级系统 (M>=3)，该方法所需的内存和计算量明显少于现有方法。

Conclusion: 所提出的数值方法在模拟开放量子系统动力学方面是有效且高效的，特别是在计算复杂性和内存使用方面具有优势。

Abstract: We propose a general strategy to discretize the Dyson series without applying
direct numerical quadrature to high-dimensional integrals, and extend this
framework to open quantum systems. The resulting discretization can also be
interpreted as a Strang splitting combined with a Taylor expansion. Based on
this formulation, we develop a numerically exact iterative method for
simulation system-bath dynamics. We propose two numerical schemes, which are
first-order and second-order in time step $\Delta t$ respectively. We perform a
rigorous numerical analysis to establish the convergence orders of both
schemes, proving that the global error decreases as $\mathcal{O}(\Delta t)$ and
$\mathcal{O}(\Delta t^2)$ for the first- and second-order methods,
respectively. In the second-order scheme, we can safely omitted most terms
arising from the Strang splitting and Taylor expansion while maintaining
second-order accuracy, leading to a substantial reduction in computational
complexity. For the second-order method, we achieves a time complexity of
$\mathcal{O}(M^3 2^{2K_{\max}} K_{\max}^2)$ and a space complexity of
$\mathcal{O}(M^2 2^{2K_{\max}} K_{\max})$ where $M$ denotes the number of
system levels and $K_{\max}$ the number of time steps within the memory length.
Compared with existing methods, our approach requires substantially less memory
and computational effort for multilevel systems ($M\geqslant 3$). Numerical
experiments are carried out to illustrate the validity and efficiency of our
method.

</details>


### [322] [Adiabatic transport of neural network quantum states](https://arxiv.org/abs/2510.15030)
*Matija Medvidović,Alev Orfi,Juan Carrasquilla,Dries Sels*

Main category: quant-ph

TL;DR: 提出一种基于绝热演化的神经网络方法来精确计算多体激子态及其性质。


<details>
  <summary>Details</summary>
Motivation: 利用神经网络量子态表示复杂多体波函数，并实现对多体激子态的精确计算。

Method: 采用绝热演化方法，将简单哈密顿量的本征态演化到强关联区域，构建神经网络表示。

Result: 可以精确获得激子态能量，从而计算临界指数，并且可以并行计算，无需参考整个能谱。

Conclusion: 该方法为大规模数值研究提供了一种有效途径，可以用于研究整个物质相的普适性质。

Abstract: Variational methods have offered controllable and powerful tools for
capturing many-body quantum physics for decades. The recent introduction of
expressive neural network quantum states has enabled the accurate
representation of a broad class of complex wavefunctions for many Hamiltonians
of interest. We introduce a first-principles method for building neural network
representations of many-body excited states by adiabatically continuing
eigenstates of simple Hamiltonians into the strongly correlated regime. With
controlled access to the full many-body gap, we obtain accurate estimates of
critical exponents. Successive eigenstate estimates can be run entirely in
parallel, enabling precise targeting of excited-state properties without
reference to the rest of the spectrum, opening the door to large-scale
numerical investigations of universal properties of entire phases of matter.

</details>


### [323] [Advances in Quantum Genetic Algorithms](https://arxiv.org/abs/2510.15059)
*Dennis Lima,Rakesh Saini,Saif Al-Kuwari*

Main category: quant-ph

TL;DR: 本论文全面回顾了量子遗传算法(QGAs)在物理应用中的适应度函数选择和编码问题，重点关注势能最小化和分子特征值求解。


<details>
  <summary>Details</summary>
Motivation: 为了解决量子遗传算法(QGAs)在设计中适应度函数选择和编码这两个关键且耗时的步骤，为化学和工程领域的应用提供指导。

Method: 通过调查量子优势案例，对QGAs及其子程序进行分类和说明，并讨论了势能最小化和分子特征值求解这两个主要物理问题。

Result: 研究表明，汤姆孙问题中使用的编码是QGAs在多种物理应用中取得成功的决定性因素，而Grover搜索算法在约简QGAs中的应用是实现量子加速的主要驱动力。

Conclusion: 汤姆孙问题的编码是QGAs应用于各种物理应用的关键，而Grover搜索作为约简QGAs中的选择步骤是量子加速的主要驱动力。

Abstract: Quantum Genetic Algorithms (QGAs) are an emerging field of multivariate
quantum optimization that emulate Darwinian evolution and natural selection,
with vast applications in chemistry and engineering. The appropriate
application of fitness functions and fitness selection are the problem-encoding
step and the slowest step in designing QGAs for specific physical applications.
In this paper, we provide a comprehensive review of these crucial steps. Our
survey maps cases of quantum advantage, classifies and illustrates QGAs and
their subroutines, and discusses the two main physical problems tackled by
QGAs: potential energy minimization of particles on a sphere, and molecular
eigensolving. We conclude that the encoding used by the Thomson problem is a
decisive step toward the use of QGAs in a variety of physical applications,
while Grover's search as a selection step in Reduced QGAs is the main driver of
quantum speedup.

</details>


### [324] [Efficient encoding of the 2D toric code logical state using local Clifford gates](https://arxiv.org/abs/2510.15107)
*Ivan H. C. Shum*

Main category: quant-ph

TL;DR: 该算法使用深度为2L+1的电路对L×L二维环形码逻辑状态进行编码，仅使用局部受控非（CX）和哈达玛（H）门。


<details>
  <summary>Details</summary>
Motivation: 提出一种使用局部门对二维环形码逻辑状态进行有效编码的方法。

Method: 设计一个深度为2L+1的量子电路，利用局部CX和H门实现L×L二维环形码逻辑状态的编码。

Result: 成功展示了一种使用有限深度量子电路对二维环形码逻辑状态进行编码的算法。

Conclusion: 该算法为在容错量子计算中实现和操作二维环形码逻辑状态提供了一种高效的途径。

Abstract: An algorithm which encodes the $L\times L$ 2D toric code logical state with a
circuit of depth $2L+1$, using only local controlled-NOT($CX$) and
Hadamard($H$) gates, is presented.

</details>


### [325] [Quantum Worst-Case to Average-Case Reduction for Matrix-Vector Multiplication](https://arxiv.org/abs/2510.15721)
*Divesh Aggarwal,Dexter Kwan*

Main category: quant-ph

TL;DR: 本研究在量子设置下，为矩阵-向量乘法问题提供了一个更有效、更简单的最坏情况到平均情况的规约。


<details>
  <summary>Details</summary>
Motivation: 提供连接最坏情况硬度和平均情况计算难度的桥梁，并解决现有规约方法复杂且开销大的问题。

Method: 通过将硬度自扩技术适应于量子领域，实现了量子最坏情况到平均情况的规约。

Result: 得到了一个在成功概率方面具有改进依赖性的量子最坏情况到平均情况的规约。

Conclusion: 为更广泛地应用于量子细粒度复杂度奠定了基础。

Abstract: Worst-case to average-case reductions are a cornerstone of complexity theory,
providing a bridge between worst-case hardness and average-case computational
difficulty. While recent works have demonstrated such reductions for
fundamental problems using deep tools from ad- ditive combinatorics, these
approaches often suffer from substantial complexity and suboptimal overheads.
In this work, we focus on the quantum setting, and provide a new reduction for
the Matrix-Vector Multiplication problem that is more efficient, and
conceptually simpler than previous constructions. By adapting hardness
self-amplification techniques to the quantum do- main, we obtain a quantum
worst-case to average-case reduction with improved dependence on the success
probability, laying the groundwork for broader applications in quantum
fine-grained complexity.

</details>


### [326] [Interrelation of Non-Classicality, Entropy, Irreversibility and Work extraction in Open Quantum Systems](https://arxiv.org/abs/2510.15140)
*Jai Lalita,Subhashish Banerjee*

Main category: quant-ph

TL;DR: 研究了开放量子系统中非经典体积、冯诺依曼熵、熵产生和能量提取之间的相互作用，并探讨了其在不同模型中的演化规律及其相互关系。


<details>
  <summary>Details</summary>
Motivation: 探究开放量子系统中非经典体积、冯诺依曼熵、熵产生和能量提取之间的相互作用及其普遍联系，并揭示初始状态对这些相互作用的影响。

Method: 利用两种开放量子系统模型（自旋-自旋相互作用模型和自旋-玻色子相互作用模型）进行研究。具体模型包括量子碰撞模型、中心自旋模型、非马尔可夫振幅阻尼信道、马尔可夫广义振幅阻尼信道以及 Jaynes-Cummings 模型。

Result: 在所研究的各种开放量子系统中，发现了普遍存在的相互关系：非经典体积的演化与熵表现出对比关系，熵产生与能量提取也呈现对比关系。此外，研究还表明，开放量子系统中初始状态对这些相互关系有重要影响。

Conclusion: 研究结果揭示了开放量子系统中的非经典体积、熵、熵产生和能量提取之间存在普遍的相互联系，并且这些联系受到系统初始状态的影响，为量子信息和开放量子系统热力学之间建立了一个有趣的桥梁。

Abstract: The interplay of non-classical volume, von Neumann entropy, entropy
production, and ergotropy is investigated in various open quantum systems. Two
categories of open quantum system models are utilized: spin-spin and spin-boson
interaction models. The spin-spin interaction models include the quantum
collision and central spin models. On the other hand, the spin-boson
interaction models consist of non-Markovian amplitude damping channel,
Markovian generalized amplitude damping channel, and the Jaynes-Cummings model.
Across these various open quantum systems, universal interrelations emerge,
where the non-classical volume shows contrasting evolution with entropy, and
entropy production contrasts with ergotropy. The initial state of the reservoir
in these open quantum systems is shown to have an impact on these
interrelations. These findings establish an interesting link between quantum
information and the thermodynamics of open quantum systems.

</details>


### [327] [The Elegant Joint Measurement is Non-Classical in the Triangle Network](https://arxiv.org/abs/2510.15143)
*Victor Gitton,Renato Renner*

Main category: quant-ph

TL;DR: EJM分布已被证明是非经典的。


<details>
  <summary>Details</summary>
Motivation: 贝尔场景比一般网络简单，因为后者涉及棘手的非凸优化问题。三角网络是最简单的展示这种非凸性的网络之一。尽管三角网络中存在一些量子非定域性的特例，但仍缺乏证明经典不相容性的一般方法，这表明我们对网络的理解仍然有限。然而，EJM分布是一种在三角网络中通过量子系统和测量获得的简单且高度对称的输出分布，被认为是八年前非经典的。

Method: 通过结合因果推断技术中的膨胀（inflation）、强大的对称性约简以及用于大规模优化的Frank-Wolfe算法，获得了精确算术中的计算机辅助非经典性证明。

Result: EJM分布被证明是非经典的。

Conclusion: EJM分布的非经典性已被证明。

Abstract: When quantum systems are shared by multiple parties in a network, the
measurement outcomes of the parties can exhibit non-classical correlations,
i.e., correlations that cannot be obtained if the parties shared classical
systems instead. This phenomenon is known as quantum nonlocality and is
typically demonstrated in the Bell scenario. However, the Bell scenario is
fundamentally simpler to investigate than general networks, since the latter
come with non-convex optimization problems that are often intractable. The
triangle network is one of the simplest networks exhibiting this non-convexity
due to the presence of three independent sources. Although some special cases
of quantum nonlocality are known in the triangle network, general methods to
certify classical incompatibility are still lacking, which suggests that our
understanding of networks is still rather limited. For instance, the Elegant
Joint Measurement (EJM) distribution is a simple and highly-symmetric outcome
distribution that can be obtained with quantum systems and measurements in the
triangle network. This distribution was conjectured to be non-classical eight
years ago. In this article, we provide the first proof of non-classicality of
the EJM distribution. To do so, we show how to combine inflation, a causal
inference technique, with powerful symmetry reductions and Frank-Wolfe
algorithms for large-scale optimization. We then use these methods to obtain
computer-assisted proofs of non-classicality in exact arithmetic.

</details>


### [328] [Superconducting Gap Engineering in Tantalum-Alloy-Based Resonators](https://arxiv.org/abs/2510.15182)
*Chen Yang,Faranak Bahrami,Guangming Cheng,Mayer Feldman,Nana Shumiya,Stephen A. Lyon,Nan Yao,Andrew A. Houck,Nathalie P. de Leon,Robert J. Cava*

Main category: quant-ph

TL;DR: 通过合金化钽（Ta）材料来提高超导电路性能，并探索了超导能隙工程在量子技术中的应用。


<details>
  <summary>Details</summary>
Motivation: 为了在量子器件中实现更高的性能，需要对超导材料进行优化，特别是钽（Ta）基材料。

Method: 通过在钽薄膜中加入20%的铪（Hf）合金，系统地改变沉积条件来控制薄膜的取向和输运性质，并使用直流输运和微波测量来评估其超导性能。

Result: 钽-铪（Ta-Hf）合金薄膜的超导转变温度（$T_c$）达到了6.09 K，比纯钽提高了40%，但低温下的双能级系统（TLS）和准粒子（QPs）损耗没有改变。

Conclusion: 材料工程，特别是通过合金化钽材料，为提高超导电路性能和发展量子技术提供了有前景的途径，但仍需进一步研究以解决损耗问题。

Abstract: Utilizing tantalum (Ta) in superconducting circuits has led to significant
improvements, such as high qubit lifetimes and quality factors in both qubits
and resonators, underscoring the importance of material optimization in quantum
device performance. In this work, we explore superconducting gap engineering in
Ta-based devices as a strategy to expand the range of viable host materials. By
alloying 20 atomic percent hafnium (Hf) into Ta thin films, we achieve a
superconducting transition temperature ($T_c$) of 6.09~K, as measured by DC
transport, reflecting an increased superconducting gap. We systematically vary
deposition conditions to control film orientation and transport properties of
the Ta-Hf alloy films. The enhancement in $T_c$ is further confirmed by
microwave measurements at millikelvin temperatures. Despite the 40\% increase
in $T_c$ relative to pure Ta, the loss contributions from two-level systems
(TLS) and quasiparticles (QPs) remain unchanged in the low-temperature regime.
These findings highlight the potential of material engineering to improve
superconducting circuit performance and motivate further exploration of
engineered alloys for quantum technologies.

</details>


### [329] [Fundamental Limits to Cat-Code Qubits from Chaos-Assisted Tunneling](https://arxiv.org/abs/2510.15175)
*Lionel E. Martínez,Ignacio García-Mata,Diego A. Wisniacki*

Main category: quant-ph

TL;DR: 混沌辅助隧穿（CAT）对 Kerr-cat 离心机的保护设定了内在限制。


<details>
  <summary>Details</summary>
Motivation: Kerr-cat 离心机的保护依赖于静态有效描述，其中假简并的 cat 状态之间的隧穿可以被指数级抑制，从而确保长寿命。然而，当非线性增加时，混沌状态会介导 cat 状态之间的隧穿。

Method: 使用完整的量子模拟和半经典 WKB 理论计算隧穿率，并进行 Floquet 分析。

Result: Floquet 分析表明，当非线性增加时，混沌状态介导 cat 状态之间的隧穿，产生大的准能量分裂。计算得到的隧穿率与模拟和 WKB 理论在数量上一致，并证实分裂与混沌直接相关。

Conclusion: 研究结果提供了 CAT 在 Kerr-cat 离心机中存在的第一个证据，并证明混沌为动态保护的超导离心机的相干性设定了基本限制。

Abstract: We show that chaos-assisted tunneling (CAT) imposes an intrinsic limit to the
protection of Kerr-cat qubits. In the static effective description, tunneling
between the quasi-degenerate cat states can be exponentially suppressed,
ensuring long lifetimes. However, our Floquet analysis reveals that when the
nonlinearities increase, chaotic states mediate tunneling between the cat
states, producing large quasi-energy splittings. We compute tunneling rates
using both full quantum simulations and semiclassical WKB theory, finding
quantitative agreement and confirming that the splittings are directly linked
to chaos. These results provide the first evidence of CAT in the Kerr-cat qubit
and demonstrate that chaos sets a fundamental bound on the coherence of
dynamically protected superconducting qubits.

</details>


### [330] [Investigating the performance of RPM JTWPAs by optimizing LC-resonator elements](https://arxiv.org/abs/2510.15310)
*M. A. Gali Labarias,T. Yamada,Y. Nakashima,Y. Urade,K. Inomata*

Main category: quant-ph

TL;DR: 优化约瑟夫森 traveling-wave 参数放大器（JTWPA）的谐振器设计可提高增益和压缩，但损耗会限制其性能。


<details>
  <summary>Details</summary>
Motivation: 约瑟夫森 traveling-wave 参数放大器（JTWPA）在量子计算和量子信息应用中至关重要，因其具备低噪声、宽带放大和正交压缩能力。本研究旨在通过优化 JTWPA 的参数化谐振器元件来提高其增益、带宽和正交压缩能力。

Method: 本研究采用数值优化方法，优化参数化谐振器元件，以最大化增益、带宽和正交压缩。

Result: 优化后的谐振器可在理想无噪声情况下将最大增益和压缩提高 5 dB 以上。然而，在考虑损耗的情况下，增益随损耗的增加而饱和，而压缩模式则迅速下降，无论是否进行谐振器优化。

Conclusion: 谐振器设计在提高放大器性能方面具有巨大潜力，但目前的制备技术和固有损耗带来了挑战。

Abstract: Resonant phase-matched Josephson traveling-wave parametric amplifiers (RPM
JTWPAs) play a key role in quantum computing and quantum information
applications due to their low-noise, broadband amplification, and quadrature
squeezing capabilities. This research focuses on optimizing RPM JTWPAs through
numerical optimization of parametrized resonator elements to maximize gain,
bandwidth and quadrature squeezing. Our results show that optimized resonators
can increase the maximum gain and squeezing by more than 5 dB in the ideal
noiseless case. However, introducing the effects of loss through a
lumped-element model reveals that gain saturates with increasing loss, while
squeezing modes degrade rapidly, regardless of resonator optimization. These
results highlight the potential of resonator design to significantly improve
amplifier performance, as well as the challenges posed by current fabrication
technologies and inherent losses.

</details>


### [331] [Entanglement complexification transition driven by a single non-Hermitian impurity](https://arxiv.org/abs/2510.15370)
*Yao Zhou,Peng Ye*

Main category: quant-ph

TL;DR: A Hermitian gapless chain with a non-Hermitian impurity exhibits an entanglement complexification transition where the central charge becomes complex, indicating a transition to a nonunitary defect-CFT phase.


<details>
  <summary>Details</summary>
Motivation: To explore how a non-Hermitian boundary affects the entanglement structure of Hermitian critical systems, which has been largely unexplored.

Method: Analytically solved a Hermitian gapless chain with a single non-Hermitian impurity acting as a non-Hermitian boundary, analyzing the entanglement entropy and correlation matrix when the entanglement cut is placed at the impurity.

Result: Discovered an 'entanglement complexification transition' where the logarithmic entanglement entropy scaling form is retained but the effective central charge evolves from real to complex values, accompanied by a spectral collapse of the correlation matrix. The complex regime was found to lie beyond the analytic continuation from a unitary defect conformal field theory (CFT) and an analytical formula was derived for it.

Conclusion: A single non-Hermitian impurity can drive a Hermitian critical system into a nonunitary defect-CFT phase, providing a rare analytically solvable platform for studying boundary non-Hermiticity.

Abstract: While non-Hermitian bulk systems and their sensitivity to boundary conditions
have been extensively studied, how a non-Hermitian boundary affects the
entanglement structure of Hermitian critical systems remains largely
unexplored. Here we present a fully analytical framework by exactly solving a
Hermitian gapless chain with a single non-Hermitian impurity acting as a
non-Hermitian boundary. When the entanglement cut is placed at the impurity, we
uncover a sharp \emph{entanglement complexification transition}: the
logarithmic entanglement entropy retains its scaling form, but the effective
central charge evolves from real to complex values, accompanied by a spectral
collapse of the correlation matrix. We demonstrate that the real regime follows
analytic continuation from a unitary defect conformal field theory (CFT),
whereas the complex regime lies entirely beyond this framework. For the latter,
we derive an analytical formula in perfect agreement with numerics. Our results
reveal that a single non-Hermitian impurity can drive a Hermitian critical
system into a nonunitary defect-CFT phase, establishing a rare analytically
solvable platform for boundary non-Hermiticity.

</details>


### [332] [Open system dynamics in local Lindbladians with chaotic spectra](https://arxiv.org/abs/2510.15193)
*Sanket Chirame,Fiona J. Burnell*

Main category: quant-ph

TL;DR: 我们研究了具有随机矩阵理论（RMT）谱的通用Lindbladian的物理后果，并比较了它们在空间局域和完全随机的Lindblad动力学在一维空间中的后果。我们发现，谱由RMT描述的Lindbladian在非线性于密度矩阵的量方面表现出准通用的早期动力学，这意味着对于通用的、高度纠缠的初始状态，早期演化与初始状态的选择无关。我们数值研究了局域性如何普遍地对Lindblad本征算子的大小依赖性施加约束。这种大小依赖性意味着线性可观测量的（例如局域算子期望值）对热力学极限中光谱之外的本征模式高度敏感，并在耗散存在下限制算子增长方面起着核心作用。我们发现，当单站点耗散占主导时，算子的退相干性近似线性地随其泡利权重扩展，即使在存在双站点跃迁算子的情况下也是如此。然而，当仅双站点耗散占主导时，算子大小的这种通用趋势可能会被违反，导致长寿命的高泡利权重算子。


<details>
  <summary>Details</summary>
Motivation: 研究具有随机矩阵理论（RMT）谱的通用Lindbladian的物理后果，比较其在空间局域和完全随机的Lindblad动力学在一维空间中的不同表现。

Method: 研究Lindbladian的谱是否满足RMT，以及局域性对Lindblad本征算子大小依赖性的影响。通过数值模拟研究算子退相干性与泡利权重的关系，并分析耗散类型（单站点或双站点）对算子大小通用趋势的影响。

Result: 具有RMT谱的Lindbladian在非线性于密度矩阵的量方面表现出准通用的早期动力学，早期演化与初始状态选择无关。局域性对Lindblad本征算子大小依赖性施加约束，线性可观测量对光谱之外的本征模式高度敏感。单站点耗散主导时，算子退相干性近似线性地随泡利权重扩展；双站点耗散主导时，此趋势可能被违反，导致长寿命的高泡利权重算子。

Conclusion: 局域性在限制算子增长和影响算子动力学方面起着关键作用。耗散的类型（单站点或双站点）会显著影响算子大小的演化趋势，并可能导致非预期的长寿命高泡利权重算子的出现。这对于理解和控制量子系统的动力学具有重要意义。

Abstract: We investigate the physical consequences of having a spectrum that satisfies
random matrix theory (RMT) for generic Lindbladians, and compare its
consequences for spatially local and completely random Lindblad dynamics in one
spatial dimension. We find that Lindbladians whose spectrum is described by RMT
exhibit quasi-universal early-time dynamics for quantities non-linear in the
density matrix, in the sense that for generic, highly entangled initial states,
the early time evolution is independent of the choice of initial state. We
numerically investigate how locality generically imposes constraints on the
size-dependence of Lindblad eigenoperators. This size dependence implies that
linear observables, such as expectation values of local operators, are highly
sensitive to eigenmodes outside the bulk of the spectrum in the thermodynamic
limit, and plays a central role in limiting operator growth in the presence of
dissipation. We find that when single-site dissipation dominates, an operator's
decoherence scales approximately linearly with its Pauli weight, even in the
presence of 2-site jump operators. When two-site only dissipation dominates,
however, this generic trend in operator size can be violated, leading to
long-lived high Pauli-weight operators.

</details>


### [333] [Game-Theoretic Discovery of Quantum Error-Correcting Codes Through Nash Equilibria](https://arxiv.org/abs/2510.15223)
*Rubén Darío Guerrero*

Main category: quant-ph

TL;DR: 通过博弈论框架发现新的量子纠错码，可优化多种目标并提供可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有量子纠错码发现方法依赖于代数构造或计算搜索，缺乏可解释性。本研究旨在引入一种新的框架来解决这个问题。

Method: 将量子纠错码优化重构为一种博弈论框架，将代码优化视为竞争目标的策略互动，通过纳什均衡来系统地生成具有期望属性的码。应用于图态稳定器码，通过重新配置目标而非重新设计算法来发现满足不同目标（如最大化距离、硬件适应性、率-距离优化、簇态生成、表面码类拓扑、连通性增强）的码。

Result: 该博弈论框架成功发现了一种 $[
u 15, 
u 7, 
u 3]$ 的码，该码具有双分簇态结构，支持基于测量的量子计算，同时保持了距离 $d=3$。与同等距离的表面码相比，开销减少了 40%。

Conclusion: 博弈论框架为量子纠错码的发现提供了一种新颖且可解释的方法，通过策略互动实现多目标优化，并能发现具有优越性能的新型量子码。

Abstract: Quantum error correction code discovery has relied on algebraic constructions
with predetermined structure or computational brute-force search lacking
mechanistic interpretability. We introduce a game-theoretic framework that
recasts code optimization as strategic interactions between competing
objectives, where Nash equilibria systematically generate codes with desired
properties. Applied to graph state stabilizer codes, the framework discovers
codes across six distinct objectives -- distance maximization, hardware
adaptation, rate-distance optimization, cluster-state generation, surface-like
topologies, and connectivity enhancement -- through objective reconfiguration
rather than algorithm redesign. Game dynamics spontaneously generate a
$[\![15,7,3]\!]$ code with bipartite cluster-state structure enabling
measurement-based quantum computation while maintaining distance $d=3$,
achieving 40\% overhead reduction versus surface codes at equivalent distance.
Equilibrium analysis provides transparent mechanistic insights connecting
strategic topology to code parameters, opening research avenues at the
intersection of game theory, optimization, and quantum information.

</details>


### [334] [Quantum Voting Protocol for Centralized and Distributed Voting Based on Phase-Flip Counting](https://arxiv.org/abs/2510.15243)
*Ali Emre Aydin,Ammar Daskin*

Main category: quant-ph

TL;DR: 提出了一种利用量子叠加和纠缠实现安全匿名投票的新型量子投票协议。


<details>
  <summary>Details</summary>
Motivation: 为了在中心化和分布式环境中实现安全、匿名的投票。

Method: 利用纠缠候选态上的相位翻转编码，并将选票记录为以选民身份寄存器为条件的受控相位操作。该协议采用基于候选寄存器测量的简化计票机制。

Result: 在中心化单机模型和分布式量子通道模型中进行了数学公式推导，并通过4选民（2候选人）和8选民（3候选人）的例子进行了演示，验证了协议的概率保持和票数统计的正确性。

Conclusion: 该协议确保了投票者的匿名性，通过纠缠机制防止了重复投票，并可能为大规模选举提供加速潜力。

Abstract: In this paper, we introduce a novel quantum voting protocol that leverages
quantum superposition and entanglement to achieve secure, anonymous voting in
both centralized and distributed settings. Our approach utilizes phase-flip
encoding on entangled candidate states, where votes are recorded as controlled
phase operations conditioned on voter identity registers. The protocol employs
a simplified tallying mechanism based on candidate register measurements. We
provide comprehensive mathematical formulations for a centralized
single-machine model suitable for local voting systems, and a distributed
quantum channel model enabling remote voting with enhanced security through
entanglement verification. The efficiency of the protocol stems from its use of
basic quantum gates (Hadamard and controlled-Z) and its ability to count votes
through quantum measurements rather than iterative classical counting. We
demonstrate the practicality of the protocol through examples with 4 voters (2
candidates) and 8 voters (3 candidates), showing exact probability preservation
and correct vote tallying. The protocol ensures voter anonymity through quantum
superposition, prevents double-voting through entanglement mechanisms, and can
offer speedup potential for large-scale elections.

</details>


### [335] [Trust Region Bayesian Optimization of Annealing Schedules on a Quantum Annealer](https://arxiv.org/abs/2510.15245)
*Seon-Geun Jeong,Mai Dinh Cong,Minh-Duong Nguyen,Xuan Tung Nguyen,Quoc-Viet Pham,Won-Joo Hwang*

Main category: quant-ph

TL;DR: TuRBO框架通过联合优化退火时间和傅里叶参数化调度，提高了量子退火在嘈杂中等规模量子（NISQ）设备上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有量子退火（QA）硬件的性能受退火时间表设计的影响很大，需要考虑硬件退相干和噪声，而设计有效的退火时间表仍然是一个重大挑战。

Method: 提出了一种基于信任区域贝叶斯优化的（TuRBO）框架，该框架利用高斯过程代理模型和期望改进策略来联合调整退火时间和傅里叶参数化调度，同时考虑硬件限制。

Result: 仿真研究表明，TuRBO框架在能量、可行解概率和链断裂率方面优于随机和贪婪搜索方法，能够设计出更优的退火时间表。

Conclusion: TuRBO是一种资源高效且可扩展的退火时间表设计策略，能够有效提高QA在NISQ设备上的性能，并可扩展至工业优化问题。

Abstract: Quantum annealing (QA) is a practical model of adiabatic quantum computation,
already realized on hardware and considered promising for combinatorial
optimization. However, its performance is critically dependent on the annealing
schedule due to hardware decoherence and noise. Designing schedules that
account for such limitations remains a significant challenge. We propose a
trust region Bayesian optimization (TuRBO) framework that jointly tunes
annealing time and Fourier-parameterized schedules. Given a fixed embedding on
a quantum processing unit (QPU), the framework employs Gaussian process
surrogates with expected improvement to balance exploration and exploitation,
while trust region updates refine the search around promising candidates. The
framework further incorporates mechanisms to manage QPU runtime and enforce
feasibility under hardware constraints efficiently. Simulation studies
demonstrate that TuRBO consistently identifies schedules that outperform random
and greedy search in terms of energy, feasible solution probability, and chain
break fraction. These results highlight TuRBO as a resource-efficient and
scalable strategy for annealing schedule design, offering improved QA
performance in noisy intermediate-scale quantum regimes and extensibility to
industrial optimization tasks.

</details>


### [336] [Capturing Protein Free Energy Landscape using Efficient Quantum Encoding](https://arxiv.org/abs/2510.15316)
*Ashwini Kannan,Jaya Vasavi Pamidimukkala,Avinash Dakshinamoorthy,Soham Bopardikar,Kalyan Dasgupta,Sanjib Senapati*

Main category: quant-ph

TL;DR: 提出一种基于量子计算的蛋白质折叠结构预测新方法。


<details>
  <summary>Details</summary>
Motivation: 蛋白质折叠是生物学中的一个核心问题，理解其机制对于认识蛋白质功能和相关疾病至关重要。之前的研究集中于疏水折叠，但本研究旨在纳入更全面的相互作用以提高预测精度。

Method: 提出一种新的基于回合的编码优化算法，并构建了一个包含疏水相互作用和宫泽-耶尼根势能的哈密顿量，该哈密顿量在一个三维面心立方晶格上编码折叠过程。使用经典和量子求解器（特别是IBM的133量子比特硬件上的变分量子特征求解器）来求解哈密顿量，以寻找最低能量的折叠构象。

Result: 通过与实验数据对比（使用均方根偏差作为度量）以及与经典模拟退火和分子动力学模拟结果进行比较，验证了预测结构的准确性。

Conclusion: 混合经典和量子计算方法在蛋白质折叠预测方面展现出巨大潜力，尤其对于低同源性序列的预测效果显著。

Abstract: Protein folding is one of the age-old biological problems that refers to the
mechanism of understanding and predicting how a protein's linear sequence of
amino acids folds into its specific three dimensional structure.This structure
is critical, as a protein's functionality is inherently linked to its final
folded form. Misfolding can lead to severe diseases such as Alzheimer's and
cystic fibrosis, highlighting the biological and clinical importance of
understanding protein folding mechanisms. This work presents a novel turn based
encoding optimization algorithm for predicting the folded structures of
peptides and small proteins. Our approach builds upon our previous research,
where our objective function focused on hydrophobic collapse, a fundamental
phenomenon underlying the protein folding process. In this work, we extend that
framework by not only incorporating hydrophobic interactions but also including
all non bonded interactions modeled using the Miyazawa Jernigan potential. We
constructed a Hamiltonian from the defined objective function that encodes the
folding process on a three dimensional face centered cubic lattice, offering
superior packing efficiency and a realistic representation of protein
conformations. This Hamiltonian is then solved using classical and quantum
solvers to explore the vast conformational space of proteins. To identify the
lowest-energy folded configurations, we utilize the Variational Quantum
Eigensolver implemented on IBM 133 qubit hardware. The predicted structures are
validated against experimental data using root mean square deviation as a
metric and compared against classical simulated annealing and molecular
dynamics simulation results. Our findings highlight the promise of hybrid
classical and quantum approaches in advancing protein folding predictions,
particularly for sequences with low homology.

</details>


### [337] [Achieving Sub-Exponential Speedup in Gate-Based Quantum Computing for Quadratic Unconstrained Binary Optimization](https://arxiv.org/abs/2510.15334)
*Tseng Ying-Wei,Kao Yu-Ting,Chang Yeong-Jar,Ou Chia-Ho,Chang Wen-Chih*

Main category: quant-ph

TL;DR: 该研究提出了一种结合模拟退火（SA）和Grover算法的混合方法，用于优化酶发酵中的625个二进制参数，以最大化活性成分。


<details>
  <summary>Details</summary>
Motivation: 现有的量子启发式模拟退火算法在处理大规模组合优化问题时效率不高，而Grover算法提供的二次加速也不够实用。本研究旨在通过混合方法实现亚指数加速，提高工业应用的可行性。

Method: 将模拟退火（SA）与Grover算法相结合，并将其应用于酶发酵问题。通过历史实验和人工智能技术生成一个625比特的二次无约束二元优化（QUBO）问题，其中最小化QUBO成本等同于最大化活性成分。

Result: 该混合方法通过门基量子计算实现了亚指数加速，并成功应用于酶发酵案例研究。

Conclusion: 本研究提出的SA与Grover算法的混合方法，在酶发酵的组合优化问题中实现了亚指数加速，证明了其在工业应用中的潜力。

Abstract: Recent quantum-inspired methods based on the Simulated Annealing (SA)
algorithm have shown strong potential for solving combinatorial optimization
problems. However, Grover's algorithm [1] in gate-based quantum computing
offers only a quadratic speedup, which remains impractical for large problem
sizes. This paper proposes a hybrid approach that integrates SA with Grover's
algorithm to achieve sub-exponential speedup, thereby improving its industrial
applicability.
  In enzyme fermentation, variables such as temperature, stirring, wait time,
pH, tryptophan, rice flour and so on are encoded by 625 binary parameters,
defining the space of possible enzyme formulations. We aim to find a binary
configuration that maximizes the active ingredient, formulated as a 625-bit
QUBO which is generated by historical experiments and AI techniques. Minimizing
the QUBO cost corresponds to maximizing the active ingredient. This case study
demonstrates that our hybrid method achieves sub-exponential speedup through
gate-based quantum computing.

</details>


### [338] [Singularity-free dynamical invariants-based quantum control](https://arxiv.org/abs/2510.15340)
*Ritik Sareen,Akram Youssry,Alberto Peruzzo*

Main category: quant-ph

TL;DR: 本研究提出了一种广义不变性方法，用于在任意噪声条件下制备单量子比特态，克服了现有方法的局限性，并能在NISQ硬件等实际应用中实现高保真度的量子态制备。


<details>
  <summary>Details</summary>
Motivation: 量子技术（计算、通信、传感）依赖于精确的量子态制备。在具有环境记忆和模型不确定性的非马尔可夫开放量子系统中，实现高保真度控制更具挑战性。现有的基于不变性的逆向工程方法常用于合成解析控制场，但存在脉冲奇异、控制场不可行以及仅限于简化噪声模型（如Lindblad形式）等问题。

Method: 本研究提出了一种两阶段的广义不变性方法：1. 构建一族有界脉冲，在闭系统实现完美的态制备。2. 优化脉冲族中的最优脉冲，以最小化噪声影响。该框架可处理（i）已表征的噪声（实现噪声感知控制）和（ii）未表征的噪声（通过无噪声感知变体实现鲁棒性，无需主方程描述）。

Result: 数值模拟表明，该方法在制备各种目标态时均能实现高保真度，并产生平滑、适用于硬件的控制场。该方法无奇异点，将不变性控制扩展到实际的开放系统领域。

Conclusion: 本研究提出的无奇异点、广义不变性框架能够处理任意噪声条件下的量子态制备问题，解决了现有方法的局限性，为在NISQ硬件及其他具有非马尔可夫动力学的平台上实现鲁棒的量子态工程提供了通用途径。

Abstract: State preparation is a cornerstone of quantum technologies, underpinning
applications in computation, communication, and sensing. Its importance becomes
even more pronounced in non-Markovian open quantum systems, where environmental
memory and model uncertainties pose significant challenges to achieving
high-fidelity control. Invariant-based inverse engineering provides a
principled framework for synthesizing analytic control fields, yet existing
parameterizations often lead to experimentally infeasible, singular pulses and
are limited to simplified noise models such as those of Lindblad form. Here, we
introduce a generalized invariant-based protocol for single-qubit state
preparation under arbitrary noise conditions. The control proceeds in
two-stages: first, we construct a family of bounded pulses that achieve perfect
state preparation in a closed system; second, we identify the optimal member of
this family that minimizes the effect of noise. The framework accommodates both
(i) characterized noise, enabling noise-aware control synthesis, and (ii)
uncharacterized noise, where a noise-agnostic variant preserves robustness
without requiring a master-equation description. Numerical simulations
demonstrate high-fidelity state preparation across diverse targets while
producing smooth, hardware-feasible control fields. This singularity-free
framework extends invariant-based control to realistic open-system regimes,
providing a versatile route toward robust quantum state engineering on NISQ
hardware and other platforms exhibiting non-Markovian dynamics.

</details>


### [339] [Generalized Boundary Conditions for the qBounce Experiment](https://arxiv.org/abs/2510.15341)
*Eric J. Sung,Benjamin Koch,Tobias Jenke,Hartmut Abele,Denys I. Bondar*

Main category: quant-ph

TL;DR: 研究了超冷中子在地球引力下边界条件的处理方法，引入了自伴随参数λ，并推导了能量谱、特征函数和矩阵元等解析表达式，强调了边界条件在定量预测中的重要性。


<details>
  <summary>Details</summary>
Motivation: 超冷中子在镜子上方的弹跳实验数据与理论之间存在差异，促使研究人员重新审视边界条件的实现方式。

Method: 采用自伴随延拓理论，处理直线上的线性引力势，推导出使哈密顿量自伴随的最一般边界条件，引入了单个实自伴随参数λ，该参数在狄利克雷情况和更一般的（罗宾类型）反射表面之间连续插值。

Result: 推导了能量谱、特征函数、相关矩阵元以及一组对任意λ都成立的求和规则的解析表达式。证明了非平凡的边界条件会影响g的测量，并可能模仿或掩盖假定的短程“第五种力”。

Conclusion: 强调了执行自伴随性并模拟正确的边界物理学对于引力量子态的定量预测至关重要。该方法不仅适用于中子量子反弹，而且广泛适用于边界和自伴随性控制可观测光谱和动力学的系统。

Abstract: Discrepancies between theory and recent qBounce data have prompted renewed
scrutiny of how boundary conditions are implemented for ultracold neutrons
bouncing above a mirror in Earth's gravity. We apply the theory of self-adjoint
extensions to the linear gravitational potential on the half-line and derive
the most general boundary condition that renders the Hamiltonian self-adjoint.
This introduces a single real self-adjoint parameter $\lambda$ that
continuously interpolates between the Dirichlet case and more general
(Robin-type) reflecting surfaces.
  Building on this framework, we provide analytical expressions for the energy
spectrum, eigenfunctions, relevant matrix elements, and a set of sum rules
valid for arbitrary $\lambda$. We show how nontrivial boundary conditions can
bias measurements of $g$ and can mimic or mask putative short-range
''fifth-force''. Our results emphasize that enforcing self-adjointness-and
modeling the correct boundary physics-is essential for quantitative predictions
in gravitational quantum states. Beyond neutron quantum bounces, the approach
is broadly applicable to systems where boundaries and self-adjointness govern
the observable spectra and dynamics.

</details>


### [340] [Fisher discord as a quantifier of quantum complexity](https://arxiv.org/abs/2510.15375)
*Huihui Li,Shunlong Luo,Yue Zhang*

Main category: quant-ph

TL;DR: 两种经典互信息的表达式在扩展到量子系统时出现分歧，这可用于定义量子散度。同样，经典Fisher信息的等效表达式在扩展到量子状态时也会出现分歧，这种差异可用于表征量子状态的复杂性。本文提出了一种信息论量化器，称为Fisher散度，用于量化量子状态的复杂性，它通过对称对数导数定义的量子Fisher信息与Wigner-Yanase偏斜信息之间的差异来定义。研究表明，平衡态和纯态的复杂性为零。


<details>
  <summary>Details</summary>
Motivation: 为了量化量子态的复杂性，需要一种能够捕捉经典和量子特征混合性质的度量。本文受到量子散度的启发，提出了一种新的复杂性量化方法。

Method: 提出了一种名为Fisher散度的信息论量化器，通过计算对称对数导数定义的量子Fisher信息与Wigner-Yanase偏斜信息之间的差异来定义。

Result: 研究表明，平衡态（与哈密顿量对易的稳定态）和所有纯态的Fisher散度为零。文章还评估了离散和连续变量量子系统中各种典型态的复杂性。

Conclusion: Fisher散度是一种有用的量子态复杂性度量，它能够捕捉量子态中经典的和量子的特征。该度量对于平衡态和纯态的复杂性为零，并已在各种量子系统中进行了评估。

Abstract: Two classically equivalent expressions of mutual information of probability
distributions (classical bipartite states) diverge when extended to quantum
systems, and this difference has been employed to define quantum discord, a
quantifier of quantum correlations beyond entanglement. Similarly, equivalent
expressions of classical Fisher information of parameterized probability
distributions diverge when extended to quantum states, and this difference may
be exploited to characterize the complex nature of quantum states. By
complexity of quantum states, we mean some hybrid nature which intermingles the
classical and quantum features. It is desirable to quantify complexity of
quantum states from various perspectives. In this work, we pursue the idea of
discord and introduce an information-theoretic quantifier of complexity for
quantum states (relative to the Hamiltonian that drives the evolution of
quantum systems) via the notion of Fisher discord, which is defined by the
difference between two important versions of quantum Fisher information: the
quantum Fisher information defined via the symmetric logarithmic derivatives
and the Wigner-Yanase skew information defined via the square roots of quantum
states. We reveal basic properties of the quantifier of complexity, and compare
it with some other quantifiers of complexity. In particular, we show that
equilibrium states (or stable states, which commute with the Hamiltonian of the
quantum system) and all pure states exhibit zero complexity in this setting. As
illustrations, we evaluate the complexity for various prototypical states in
both discrete and continuous-variable quantum systems.

</details>


### [341] [A Hybrid Quantum Solver for Gaussian Process Regression](https://arxiv.org/abs/2510.15486)
*Kerem Bükrü,Steffen Leger,M. Lautaro Hickmann,Hans-Martin Rieser,Ralf Sturm,Tjark Siefkes*

Main category: quant-ph

TL;DR: 高斯过程回归可以通过变分量子线性求解器在NISQ设备上进行有效推理，其回归质量与经典方法相当。


<details>
  <summary>Details</summary>
Motivation: 标准高斯过程训练方法计算复杂度高（三次方程），难以处理大型数据集。量子算法（如HHL）虽能解决线性方程组，但需要大规模容错量子计算机，目前尚不可用。变分量子线性求解器（VQLS）作为一种混合量子-经典算法，适用于NISQ设备，可用于高斯过程推理。

Method: 将高斯过程的矩阵求逆问题重构为一系列线性方程组，并使用变分量子线性求解器（VQLS）进行求解。VQLS通过经典计算机优化变分量子电路参数。

Result: 实验表明，使用VQLS进行高斯过程回归推理，其回归质量与经典方法相当。

Conclusion: 变分量子线性求解器提供了一种在高斯过程回归中进行推理的替代方法，尤其适用于NISQ设备，并能在不牺牲回归质量的情况下，克服经典方法的计算瓶颈。

Abstract: Gaussian processes are widely known for their ability to provide
probabilistic predictions in supervised machine learning models. Their
non-parametric nature and flexibility make them particularly effective for
regression tasks. However, training a Gaussian process model using standard
methods requires matrix inversions with a cubic time complexity, which poses
significant computational challenges for inference on larger datasets. Quantum
algorithms, such as the HHL algorithm, have been proposed as solutions that
overcome the need for classical matrix inversions by efficiently solving linear
systems of equations using quantum computers. However, to gain a computational
advantage over classical algorithms, these algorithms require fault-tolerant
quantum computers with a large number of qubits, which are not yet available.
The Variational Quantum Linear Solver is a hybrid quantum-classical algorithm
that solves linear systems of equations by optimizing the parameters of a
variational quantum circuit using a classical computer. This method is
especially suitable for noisy intermediate-scale quantum computers, as it does
not require many qubits. It can be used to compute the posterior distribution
of a Gaussian process by reformulating the matrix inversion into a set of
linear systems of equations. We empirically demonstrate that using the
Variational Quantum Linear Solver to perform inference for Gaussian process
regression delivers regression quality comparable to that of classical methods.

</details>


### [342] [Adaptive quantum channel discrimination using methods of quantum metrology](https://arxiv.org/abs/2510.15506)
*Stanisław Sieniawski,Rafał Demkowicz-Dobrzański*

Main category: quant-ph

TL;DR: 提出了高效的张量网络算法，用于量子信道鉴别策略。


<details>
  <summary>Details</summary>
Motivation: 受量子计量学中寻找最优自适应信道估计协议的数值方法启发，提出了一种高效的张量网络算法，用于寻找最优自适应量子信道鉴别策略。

Method: 使用张量网络算法。

Result:  examined the connection between channel discrimination and estimation problems, highlighting in particular an appealing structural similarity between models that admit Heisenberg scaling estimation performance, and models that admit perfect channel discrimination in finite--number of channel uses.

Conclusion: 量子信道鉴别和估计问题之间存在结构相似性。

Abstract: We present an efficient tensor-network based algorithm for finding the
optimal adaptive quantum channel discrimination strategies inspired by recently
developed numerical methods in quantum metrology to find the optimal adaptive
channel estimation protocols. We examine the connection between channel
discrimination and estimation problems, highlighting in particular an appealing
structural similarity between models that admit Heisenberg scaling estimation
performance, and models that admit perfect channel discrimination in
finite--number of channel uses.

</details>


### [343] [Parameterized quantum algorithms for closest string problems](https://arxiv.org/abs/2510.15529)
*Josh Cudby,Sergii Strelchuk*

Main category: quant-ph

TL;DR: 本文研究了计算复杂性理论中参数化复杂性在处理NP难问题中的应用，特别是针对基因组数据日益增长的计算需求，对字符串匹配问题（CSP和CSSP）进行了量子参数化复杂性研究。


<details>
  <summary>Details</summary>
Motivation: 由于基因组数据量的爆炸式增长及其计算需求的增加，研究字符串匹配问题的量子参数化复杂性具有重要意义。

Method: 本文提出了三种用于解决CSP问题的量子算法和一种用于解决CSSP问题的量子算法。

Result: 与经典算法相比，本文提出的量子算法在特定参数下表现出更优越的性能，并为CSP问题（二元字母表）推导出了条件性下界，证明了其中一个算法在主要缩放因子上的最优性。

Conclusion: 量子计算方法在处理具有特定结构的组合问题方面展现出巨大潜力，尤其是在字符串匹配这类问题上。

Abstract: Parameterized complexity enables the practical solution of generally
intractable NP-hard problems when certain parameters are small, making it
particularly useful in real-world applications. The study of string problems in
this framework has been particularly fruitful, yielding many state-of-the-art
classical algorithms that run efficiently in certain parameter regimes contrary
to their worst- or average-case performance. Motivated by the dramatic increase
in genomic data and its growing computational demands, we initiate the study of
the quantum parameterized complexity of the Closest String Problem (CSP) and
the related Closest Substring Problem (CSSP). We present three quantum
algorithms for the CSP and one for the CSSP. Each algorithm demonstrates
improved performance over classical counterparts in specific parameter regimes,
highlighting the promise of quantum approaches in structured combinatorial
settings. We also derive a conditional lower bound for the CSP with binary
alphabets, showing that our first algorithm is tight in its dominant scaling
factor.

</details>


### [344] [Benchmarking non-Clifford gates using only Pauli twirling group](https://arxiv.org/abs/2510.15554)
*Han Ye,Guoding Liu,Xiongfeng Ma*

Main category: quant-ph

TL;DR: 该研究提出了一种名为“Pauli Transfer Character Benchmarking”的协议，用于在存在状态制备和测量误差的情况下，对非Clifford量子门进行保真度基准测试。


<details>
  <summary>Details</summary>
Motivation: 现有的随机基准测试（RB）方法虽然能有效处理Clifford门，但在处理非Clifford门时面临根本性挑战，尤其是在保真度估计方面。

Method: 提出了一种名为“Pauli Transfer Character Benchmarking”的协议，该协议仅使用局部的Pauli操作来估计量子通道的Pauli转移矩阵元素。在此基础上，开发了一种针对满足$U^2=I$的非Clifford门$U$的保真度基准测试方法。

Result: 通过对Toffoli门进行数值模拟，验证了该协议的可行性。

Conclusion: 所提出的Pauli Transfer Character Benchmarking协议能够有效解决现有RB方法在非Clifford门基准测试方面的局限性，并能通过局部Pauli操作实现对特定类型非Clifford门的保真度基准测试。

Abstract: Quantum gate benchmarking is unavoidably influenced by state preparation and
measurement errors. Randomized benchmarking addresses this challenge by
employing group twirling to regularize the noise channel, then provides a
characterization of quantum channels that is robust to these errors through
exponential fittings. In practice, local twirling gates are preferred due to
their high fidelity and experimental feasibility. However, while existing RB
methods leveraging local twirling gates are effective for benchmarking Clifford
gates, they face fundamental challenges in benchmarking non-Clifford gates. In
this work, we solve this problem by introducing the Pauli Transfer Character
Benchmarking. This protocol estimates the Pauli transfer matrix elements for a
quantum channel using only local Pauli operations. Building on this protocol,
we develop a fidelity benchmarking method for non-Clifford gates $U$ satisfying
$U^2=I$. We validate the feasibility of our protocol through numerical
simulations applied to Toffoli gates as a concrete example.

</details>


### [345] [Elastic Quantum Coupling Between Free Electrons and Photons](https://arxiv.org/abs/2510.15584)
*Dingguo Zheng,Ofer Kfir*

Main category: quant-ph

TL;DR: 该研究提出了自由电子和光子的量子耦合理论，并将量子光学技术应用于电子显微镜，实现了亚埃尺度的量子传感和成像。


<details>
  <summary>Details</summary>
Motivation: 利用自由电子和光子的量子耦合，将量子光学技术应用于电子显微镜，以实现高分辨率成像和传感。

Method: 推导了弹性电子-光子量子耦合的理论，并分析了其对光学腔内光子模式的影响，提出了一个电子计数哈密顿量。

Result: 当电子穿过光学腔场时，会引起光子模式的相位移动，这相当于电子的折射率；该方法可以实现对电子束进行量子态不敏感的计数；有望实现亚埃尺度的量子传感和成像。

Conclusion: 自由电子和光子的量子耦合为电子显微镜提供了新的量子光学工具，有望在量子传感和成像领域取得突破。

Abstract: The quantum coupling between free-electrons and photons enables applying
quantum optics techniques in electron microscopy. Here, we formulate the
elastic electron-photon quantum coupling and its possible implications. Our
analysis shows that when an electron traverses the field of an optical cavity,
it induces a phase shift onto its confined photonic mode, which can be
quantified as a refractive index of a free electron. This principle can be
applied to counting electrons in a beam without changing its quantum states.
The elastic scattering operator forms an electron-counting dispersive
Hamiltonian for electron-photon systems within electron microscope, and it
could enable quantum- and sub-shot-noise sensing and imaging at the
{\AA}-scale.

</details>


### [346] [A Gauss-Bonnet Theorem for Quantum States: Gauss Curvature and Topology in the Projective Hilbert Space](https://arxiv.org/abs/2510.15760)
*Shin-Ming Huang*

Main category: quant-ph

TL;DR: 该论文提出了一种计算Bloch带量子度量曲率的解析方法，发现了量子态流形中的奇点，并提出了一个修正的高斯-博内定理，将总曲率与陈数联系起来。


<details>
  <summary>Details</summary>
Motivation: 现代凝聚态物理中几何和拓扑学至关重要，但其在量子系统中的精确联系尚不完全清楚。

Method: 开发了一种基于本征投影符的规范不变形式，用于计算Bloch带量子度量的曲率，并将其应用于二维双带模型。

Result: 发现高斯曲率在正则区域是恒定的，但量子态流形不可避免地会出现度量张量退化的奇点闭合曲线。该论文引入了“前沿”和带符号面积形式的概念，推导了一个广义的高斯-博内关系，其中包含沿折叠曲线定义的奇异曲率项。

Conclusion: 总的来说，这项工作将微分几何和拓扑带理论联系起来，揭示了奇点如何调节量子体积和拓扑电荷之间的差异，并提供了Berry曲率和量子度量的统一几何解释。

Abstract: Geometry and topology are fundamental to modern condensed matter physics, but
their precise connection in quantum systems remains incompletely understood.
Here, we develop an analytical scheme for calculating the curvature of the
quantum metric of Bloch bands. Using a gauge-invariant formulation based on
eigenprojectors, we construct the full Riemannian geometry of the quantum-state
manifold and apply it to a two-dimensional two-band model. We find that the
Gauss curvature is constant over regular regions, but the manifold inevitably
develops a closed curve of singular points where the metric tensor degenerates.
These singularities obstruct the conventional Gauss-Bonnet theorem. By
introducing the notion of a front and a signed area form, we derive a
generalized Gauss-Bonnet relation that includes a singular curvature term
defined along the fold curve. This result establishes a direct, quantized link
between the total signed Gauss curvature and the Chern number, providing a
unified geometric interpretation of Berry curvature and quantum metric. This
framework bridges differential geometry and topological band theory, revealing
how singular folds mediate the discrepancy between quantum volume and
topological charge.

</details>


### [347] [A single optically detectable tumbling spin in silicon](https://arxiv.org/abs/2510.15590)
*Félix Cache,Yoann Baron,Baptiste Lefaucher,Jean-Baptiste Jager,Frédéric Mazen,Frédéric Milési,Sébastien Kerdilès,Isabelle Robert-Philip,Jean-Michel Gérard,Guillaume Cassabois,Vincent Jacques,Anaïs Dréau*

Main category: quant-ph

TL;DR: Esr可以分析微观结构，但传统方法需要探测超过十亿个电子才能看到单个原子的运动。尽管有单自旋光谱法，但仅限于静态系统。本研究展示了硅中G心（一种荧光翻转缺陷）的单自旋光谱法，该缺陷表现得像一个在晶体中随机取向的拟分子。通过高分辨率自旋光谱法，我们揭示了由于自旋主轴在晶体中离散取向跳变而产生的精细磁结构。通过对缺陷原子取向进行建模，我们证明了自旋翻转会引起微波磁场耦合的变化，从而能够在相干自旋控制实验中检测到位置相关的拉比频率。鉴于其拟分子构型，硅中的G心是一种独特的量子系统，可以研究光学、自旋和旋转特性在多功能材料中的相互作用。


<details>
  <summary>Details</summary>
Motivation: 传统电子自旋共振光谱技术因系综平均效应而无法实现对单个原子运动的探测，现有单自旋光谱技术也仅限于静态系统。本研究旨在探索一种适用于动态系统的单自旋光谱技术，并利用硅中的G心（一种具有荧光特性的翻转缺陷）作为研究对象。

Method: 利用高分辨率自旋光谱技术，对硅中的G心（一种荧光翻转缺陷）进行单自旋光谱分析，并对其原子取向进行建模，以研究其自旋翻转诱导的微波磁场耦合变化和位置相关的拉比频率。

Result: 揭示了G心精细的磁结构，发现自旋主轴在晶体中存在离散取向的跳变。通过建模证实，自旋翻转确实会引起微波磁场耦合的变化，并且能够在相干自旋控制实验中检测到位置相关的拉比频率。

Conclusion: 硅中的G心作为一种独特的拟分子构型量子系统，为研究光学、自旋和旋转特性在多功能材料中的相互作用提供了新的途径。本研究成功展示了单自旋光谱技术在动态系统中的应用潜力。

Abstract: Electron spin resonance spectroscopy is a widely used technique for analyzing
the microscopic structure, local environment and reorientation of atomic and
molecular systems. Conventional inductive detection methods typically require
to probe more than a billion of electron spins such that single atom motion is
hidden through ensemble averaging. While several single spin spectroscopy
methods are currently available, they have been so far limited to static
systems. Here we demonstrate single spin spectroscopy of a fluorescent tumbling
defect in silicon called the G center, behaving as a pseudo-molecule randomly
reorienting itself in the crystalline matrix. Using high-resolution spin
spectroscopy, we reveal a fine magnetic structure resulting from the spin
principal axes jumping between discrete orientations in the crystal. By
modeling the atomic reorientation of the defect, we demonstrate that spin
tumbling induces variations in the coupling to the microwave magnetic field,
enabling position-dependent Rabi frequencies to be detected in coherent spin
control experiments. By virtue of its pseudo-molecule configuration, the G
center in silicon is a unique quantum system to investigate the mutual
interaction between optical, spin and rotation properties in a highly versatile
material.

</details>


### [348] [Time evolution of the Husimi and Glauber-Sudarshan functions in terms of complementary Hamiltonian symbols](https://arxiv.org/abs/2510.15628)
*Mritunjay Tyagi,Simon Friederich*

Main category: quant-ph

TL;DR: 提出了基于互补量子算符符号的相空间分布函数动力学的新框架，用于描述量子系统的演化。


<details>
  <summary>Details</summary>
Motivation: 为了系统地研究和推导量子系统相空间分布函数（如Husimi Q函数和Glauber-Sudarshan P函数）的演化方程，并简化计算过程。

Method: 利用互补算符符号（Anti-Wick用于Q函数，Wick用于P函数）来表示量子哈密顿量，从而推导出相空间分布函数的演化方程。重点关注了四次及以下哈密顿量的情况，并将其演化方程简化为经典Liouvillian漂移加上高阶导数项，特别是Fokker-Planck方程。

Result: 推导出了通用的演化方程，并证明对于低阶哈密顿量，可以简化为Fokker-Planck方程。推导了Wick/Anti-Wick符号的Ehrenfest定理。指出了之前报道的非经典贡献是特定量子化方案的产物。

Conclusion: 该研究巩固了使用互补符号来描述相空间分布函数动力学的理论框架，并提供了一种计算和解释量子相空间演化的有效途径。

Abstract: We present a compact, systematic formulation of the dynamics of the Husimi Q-
and Glauber-Sudarshan P-phase space distribution functions expressed in terms
of their \emph{complementary} Hamiltonian symbols: Anti-Wick for Q and Wick for
P. The resulting evolution equations have a universal leading structure, the
classical Liouvillian drift plus terms with higher-order derivatives of the
Hamiltonian. For Hamiltonians no higher than quartic in the moduli of the
complex phase space variables $\alpha_i$, the higher-order terms reduce to a
second-order Fokker-Planck type term with a \emph{traceless} diffusion matrix,
thereby clarifying and recovering recent results for such Hamiltonians within a
simple star-product framework. We further derive a transparent Ehrenfest
theorem for Wick/Anti-Wick symbols of the operators representing dynamical
observables. Using these results, we show that a previously reported
nonclassical contribution to the Q-function drift for the anharmonic oscillator
is an artifact of the quantization scheme used. Our paper consolidates the
formulation of the dynamics of the phase space distribution functions using
complementary symbols and provides an efficient route to compute and interpret
quantum phase space evolution.

</details>


### [349] [Distributed Quantum Information Processing: A Review of Recent Progress](https://arxiv.org/abs/2510.15630)
*Johannes Knörzer,Xiaoyu Liu,Benjamin F. Schiffer,Jordi Tura*

Main category: quant-ph

TL;DR: 分布式量子信息处理通过互联量子节点来克服可扩展性限制，实现更大规模问题和新算法。它还支持对高维量子态的多副本进行联合测量，这与单副本访问不同，并揭示了任务复杂性的差异，帮助识别受益于分布式量子资源的计算问题。


<details>
  <summary>Details</summary>
Motivation: 分布式量子信息处理旨在通过互联量子节点来克服单一量子设备的规模限制，从而扩展其能力，处理更大的问题实例并运用新的算法技术。

Method: 本文回顾了分布式量子信息处理的理论基础、实验平台和算法应用，重点关注单副本和多副本访问的差异，以及经典与量子通信模型的权衡和其实验挑战。

Result: 分布式量子信息处理不仅能增加量子比特数量，还能实现定性的新功能，例如对高维量子态的多副本进行联合测量。

Conclusion: 分布式量子信息处理在理论、实验和算法应用方面都有重要进展，但实际实现仍面临挑战，需要权衡通信模型并解决实验难题。对单副本和多副本访问的区分有助于理解分布式量子资源的优势和应用范围。

Abstract: Distributed quantum information processing seeks to overcome the scalability
limitations of monolithic quantum devices by interconnecting multiple quantum
processing nodes via classical and quantum communication. This approach extends
the capabilities of individual devices, enabling access to larger problem
instances and novel algorithmic techniques. Beyond increasing qubit counts, it
also enables qualitatively new capabilities, such as joint measurements on
multiple copies of high-dimensional quantum states. The distinction between
single-copy and multi-copy access reveals important differences in task
complexity and helps identify which computational problems stand to benefit
from distributed quantum resources. At the same time, it highlights trade-offs
between classical and quantum communication models and the practical challenges
involved in realizing them experimentally. In this review, we contextualize
recent developments by surveying the theoretical foundations of distributed
quantum protocols and examining the experimental platforms and algorithmic
applications that realize them in practice.

</details>


### [350] [High-dimensional Path-Encoded Entanglement Distribution Between Photonic Chips Enabled by Multimode Phase Stabilisation](https://arxiv.org/abs/2510.15675)
*Molly A. Thomas,Daniel Llewellyn,Patrick W. Yard,Benjamin A. Slater,Caterina Vigliar,Stefano Paesani,Massimo Borghi,Döndü Sahin,John G. Rarity,Leif K. Oxenløwe,Mark G. Thompson,Karsten Rottwitt,Yunhong Ding,Jianwei Wang,Davide Bacco,Jorge Barreto*

Main category: quant-ph

TL;DR: 演示了通过集成光子芯片和新颖的多模相位稳定算法来分发四维路径编码的纠缠量子态，并将分发保真度提高了 86%。


<details>
  <summary>Details</summary>
Motivation: 在光学纤维网络中可靠地分发高维纠缠量子态对于量子技术至关重要，但维持多模相干性具有挑战性。

Method: 使用集成光子电路和一种新的多模相位稳定算法，该算法只需两次测量即可完成任意数量模式的相位稳定，并且不需要额外的硬件。

Result: 分发纠缠态的保真度为 86%（相比之下，未使用相位稳定时为 8.1%），纠缠熵为 0.995±0.002。

Conclusion: 所提出的多模相位稳定算法能够有效地分发高维纠缠量子态，提高了分发保真度，并使使用最少数量的局部测量来验证纠缠态成为可能。

Abstract: The reliable distribution of high-dimensional entangled quantum states, an
important resource in quantum technologies, through optical fibre networks is
challenging due to the need to maintain coherence across multiple modes. Here
we demonstrate the distribution of four-dimensional path-encoded entangled
quantum states between photonic chips, enabled by a novel multimode phase
stabilisation algorithm. The algorithm utilises the reconfigurability of the
integrated photonic circuits to complete one iteration of phase stabilisation
in just two measurement rounds for an arbitrary number of modes, and requires
no additional hardware to the quantum measurements it enables. As a result, we
are able to perform complete quantum state tomography across two chips using
the minimum number of local projective measurements to verify the fidelity of
the distributed entangled state to be $86\%$ (compared to $8.1\%$ without the
phase stabilisation) with an entanglement entropy of $0.995\pm0.002$.

</details>


### [351] [Fragment, Entangle, and Consolidate: Strong Correlation through Bi-fold Quantum Circuits](https://arxiv.org/abs/2510.15678)
*Arpan Choudhury,Sonaldeep Halder,Rahul Maitra,Debashree Ghosh*

Main category: quant-ph

TL;DR: 该研究提出了一种处理强电子相关性的通用且可定制的方案，结合了问题分解、纠缠构建和后续合并。


<details>
  <summary>Details</summary>
Motivation: 精确描述强相关性对于探索新兴化学现象至关重要，但近期的量子算法在模拟多参考效应方面存在不足，阻碍了新化学空间的合理设计。

Method: 该方案基于问题启发的分子分解，利用硬件高效ansatz制备纠缠子系统，然后通过幺正耦合簇框架引入动态相关性。

Result: 该方案在强相关系统上的数值应用表明，它能够高度准确、灵活且稳健地捕捉不同程度的相关性，并有潜力为量子化学带来量子优势。

Conclusion: 该混合架构能够以平衡的方式部署不同的ansatz结构来捕捉各种相关性，同时保留其单独提供的可扩展性和灵活性。

Abstract: An accurate description of strong correlation is quintessential for the
exploration of emerging chemical phenomena. While near-term variational quantum
algorithms provide a theoretically scalable framework for quantum chemical
problems, the accurate simulation of multireference effects remains elusive,
hindering progress toward the rational design of novel chemical space. In this
regard, we introduce a general and customizable scheme to handle strong
electronic correlation, based on problem decomposition, entanglement buildup,
and subsequent consolidation. Based on a problem-inspired molecular
decomposition, the deployment of Hardware Efficient Ansatz to prepare entangled
subsystems ensures efficient construction of a multireference state while
concurrently adhering to the hardware topology. The dynamic correlation is
subsequently introduced through a unitary coupled cluster framework, with
static or dynamic ansatz parametrized by a set of inter-fragment generalized
operators, and with the product state spanning various subsystems taken as the
reference. The hybrid architecture ensures a judicious deployment of separate
ansatze structures for capturing various degrees of correlation in a balanced
manner, while concurrently retaining the scalability and flexibility provided
by them individually. Over a number of numerical applications on a strongly
correlated system, the proposed scheme is shown to be highly accurate,
flexible, and robust in unlocking the potential to harness quantum advantage
for quantum chemistry.

</details>


### [352] [Generation of multipartite photonic entanglement using a trapped-ion quantum processing node](https://arxiv.org/abs/2510.15693)
*Marco Canteri,James Bate,Ida Mishra,Nicolai Friis,Victor Krutyanskiy,Benjamin P. Lanyon*

Main category: quant-ph

TL;DR: 利用集成腔的离子阱量子处理器演示了工厂节点的功能，制备了真正多方位的 GHZ 态光子，为量子局域网中的多方纠缠分发奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 为实现科学和技术领域的广泛新应用，在量子网络节点之间建立纠缠至关重要，而利用强大的中央节点（工厂节点）制备并分发多方纠缠态是一种有前景的方法。

Method: 使用腔集成离子阱量子处理器，编程以生成三个可路径切换光子的真正多方 GHZ 纠缠态，并通过定制的纠缠见证进行验证。

Result: 成功制备了三光子 GHZ 态，并通过实验验证了其多方纠缠特性。

Conclusion: 证明了用于制备共陷离子量子比特纠缠态的成熟技术可用于制备旅行光子的相同状态，为量子局域网中的多方纠缠分发铺平了道路。

Abstract: The ability to establish entanglement between the nodes of future quantum
networks is essential for enabling a wide range of new applications in science
and technology. A promising approach involves the use of a powerful central
node capable of deterministically preparing arbitrary multipartite entangled
states of its matter-based qubits and efficiently distributing these states to
surrounding end nodes via flying photons. This central node, referred to as a
``factory node", serves as a hub for the production and distribution of
multipartite entanglement. In this work, we demonstrate key functionalities of
a factory node using a cavity-integrated trapped-ion quantum processor.
Specifically, we program the system to generate genuinely multipartite
entangled Greenberger-Horne-Zeilinger (GHZ) states of three path-switchable
photons and verify them using custom-designed entanglement witnesses. These
photons can, in the future, be used to establish stored multipartite
entanglement between remote matter-based nodes. Our results demonstrate that
the well-established techniques for the deterministic preparation of entangled
states of co-trapped ion qubits can be used to prepare the same states of
traveling photons, paving the way for multipartite entanglement distribution in
quantum local area networks.

</details>


### [353] [Globalizing the Carleman linear embedding method for nonlinear dynamics](https://arxiv.org/abs/2510.15715)
*Ivan Novikau,Ilon Joseph*

Main category: quant-ph

TL;DR: 该研究提出了一种全局分片Carleman嵌入技术，通过将空间划分为多个区域来解决标准Carleman嵌入方法在多重不动点区域失效的问题。


<details>
  <summary>Details</summary>
Motivation: 标准Carleman嵌入方法在存在多个不动点的区域会失效，因此需要改进该方法。

Method: 提出并测试了三种全局分片Carleman嵌入技术的变体：1. 局部线性化区域切换；2. 动态适应性图大小；3. 静态网格分区。

Result: 所有方法在可积和混沌非线性动力学系统上进行了数值测试，证明了它们在标准方法无法处理的问题上的适用性。自适应方法在模拟混沌系统方面表现出强大能力，而非自适应方法在特定情况下可能更快且更适合量子计算。

Conclusion: 全局分片Carleman嵌入技术能够有效地处理标准方法无法解决的问题，并且其不同变体适用于不同的应用场景，特别是自适应方法在模拟混沌系统方面表现优异，而非自适应方法则在速度和量子计算应用方面具有潜力。

Abstract: The Carleman embedding method is a widely used technique for linearizing a
system of nonlinear differential equations, but fails to converge in regions
where there are multiple fixed points. We propose and test three different
versions of a global piecewise Carleman embedding technique, based on
partitioning space into multiple regions where the center and size of the
embedding region are chosen to control convergence. The first method switches
between local linearization regions of fixed size once the trajectory reaches
the boundary of the current linearization chart. During the transition, the
embedding is reconstructed within the newly created chart, centered at the
transition point. The second method also adapts the chart size dynamically,
enhancing accuracy in regions where multiple fixed points are located. The
third method partitions the state space using a static grid with precomputed
linearization charts of fixed size, making it more suitable for applications
that require high speed. All techniques are numerically tested on multiple
integrable and chaotic nonlinear dynamical systems demonstrating their
applicability for problems that are completely intractable for the standard
Carleman embedding method. Simulations of chaotic dynamical systems such as
various types of strange attractors demonstrate the power of the adaptive
methods, if a sufficiently low tolerance is imposed. Still, the non-adaptive
version of the method, with fixed centers and sizes of the linearization
charts, can be faster in simulating dynamical systems while providing similar
accuracy and may be more appropriate as the basis of algorithms for future
quantum computers.

</details>


### [354] [Optomechanical crystal in light-resilient quantum ground-state](https://arxiv.org/abs/2510.15724)
*Johan Kolvik,Paul Burger,David Hambraeus,Trond H. Haug,Joey Frey,Mads B. Kristensen,Raphaël Van Laer*

Main category: quant-ph

TL;DR: 本研究提出了一种无需释放的片上硅光力学晶体腔（OMC），在低温下运行，并能有效抑制热光效应，提高对激光的耐受性，为低噪声和高功率的量子光力学系统提供了新的途径。


<details>
  <summary>Details</summary>
Motivation: 集成光子学、量子光学和非线性光学领域需要研究光与高频声的相互作用，但传统的悬浮光力学结构存在热锚固差、易受光学吸收引起的热噪声影响的问题。

Method: 提出并实现了一种无需释放的片上硅光力学晶体腔（OMC），在低温下进行实验，并与悬浮纳米梁OMC进行对比。

Result: 与悬浮纳米梁OMC相比，该器件的热光效应抑制了18 dB，并且能够在更高（高35 dB）的腔内光能量下维持接近于1的声子占据数。时间分辨测量表明，快速的初始热化过程受机械衰减时间控制。

Conclusion: 这些结果表明，无需释放的片上系统是实现低噪声和高功率经典及量子光力学的可行途径，可用于微波光子与光学光子之间的频率转换等应用。

Abstract: Interaction between light and high-frequency sound is a key area in
integrated photonics, quantum and nonlinear optics, and quantum science.
However, the typical suspended optomechanical structures suffer from poor
thermal anchoring, making them susceptible to thermal noise arising from
optical absorption. Here, we demonstrate a chip-scale, release-free silicon
optomechanical crystal cavity (OMC) operating cryogenically with improved
resilience to laser light. Relative to a suspended nanobeam OMC, we observe an
18 dB suppression of the thermo-optic effect, and the device sustains
near-unity phonon occupation at 35 dB higher intracavity optical energy.
Time-resolved measurements further reveal rapid initial thermalization governed
by the mechanical decay time. With further material and design improvements in
sight, these results bolster release-free systems on a chip as a path for
low-noise and high-power classical and quantum electro-optomechanics, such as
for frequency converters between microwave and optical photons.

</details>


### [355] [The Geometry of Qubit Decoherence: Linear vs. Nonlinear Dynamics in the Bloch Ball](https://arxiv.org/abs/2510.15726)
*Alan C. Maioli,Evaldo M. F. Curado,Jean-Pierre Gazeau,Tomoi Koide*

Main category: quant-ph

TL;DR: We propose two methods to solve the GKSL equation for open qubits, one using linearity and the other using SU(2) symmetry, leading to different types of solutions and insights into the system dynamics.


<details>
  <summary>Details</summary>
Motivation: The paper aims to find solutions for the GKSL equation for an open qubit using two novel approaches.

Method: The first method utilizes linearity to find solutions, visualized through mixed state trajectories and revealing non-random fixed points and exceptional points. The second method leverages SU(2) symmetry to establish a nonlinear dynamical system that decouples angular dynamics from radial dissipation.

Result: The linearity-based approach provides solutions visualized by mixed states trajectories in the Bloch ball, including non-random asymptotic fixed points and exceptional points. The symmetry-based approach results in a nonlinear dynamical system that separates angular dynamics from radial dissipation.

Conclusion: The SU(2) symmetry-based approach offers a potential pathway for generalizing the findings to open qudits.

Abstract: We present two complementary approaches to the GKSL equation for an open
qubit. The first, based on linearity, yields solutions illustrated by mixed
states trajectories in the Bloch ball, including non-random asymptotic fixed
points, and exceptional points. The second, exploiting the SU(2) symmetry,
leads to a nonlinear dynamical system that separates angular dynamics from
radial dissipation. This symmetry-based perspective offers a promising route
toward generalisation to open qudits.

</details>


### [356] [Emergence of irreversible decoherence from unitary dynamics](https://arxiv.org/abs/2510.15730)
*Ri-Hua Zheng,Jia-Hao Lü,Fan Wu,Yan Xia,Li-Hua Lin,Zhen-Biao Yang,Shi-Biao Zheng*

Main category: quant-ph

TL;DR: 实验展示了量子系统与多自由度环境的酉演化如何导致不可逆的退相干，从而解释了量子-经典过渡的涌现现象。


<details>
  <summary>Details</summary>
Motivation: 理解经典可区分态叠加（猫态）的退相干对于解释量子-经典过渡和量子测量至关重要。然而，系统-环境酉动力学如何导致不可逆退相干在实验中仍未得到充分探索。

Method: 利用电路量子电动力学装置，其中一个包含光子猫态的微波谐振腔与许多非线性电子振荡器耦合。通过逐步增加环境自由度数量，观察相干性的衰减。

Result: 随着环境自由度数量的增加，可复原的量子相干性逐渐衰减，这是由于环境中关于系统状态的不可擦除信息量不断增长。

Conclusion: 量子系统的不可逆退相干是一种涌现现象，源于系统与环境多自由度的酉动力学。这一发现对于调和量子力学与经典物理学至关重要。

Abstract: The decoherence of superpositions of classically distinguishable states (cat
states) is crucial for understanding quantum-to-classical transitions and
quantum measurements. So far, decoherence processes of mesoscopic cat states
have been demonstrated in several experiments. However, the issue of how the
unitary system-reservoir dynamics can lead to irreversible system decoherence
remains largely unexplored in experiments. Here we experimentally explore this
fundamental issue with a circuit quantum electrodynamics device, where a bus
microwave resonator storing a photonic cat state is connected to many nonlinear
electronic oscillators. Each of these oscillators that are effectively coupled
to the bus resonator serves as one degree of freedom of the reservoir. By
gradually increasing the number of the reservoir's degrees of freedom, we find
that the revivable quantum coherence progressively decays, owing to the growth
in the amount of inerasable information about the system's state encoded in the
reservoir. Our results illustrate that irreversible decoherence of a quantum
system is an emergent phenomenon, arising from the unitary dynamics involving
the system and many of the reservoir's degrees of freedom, which is crucial for
the reconciliation of quantum mechanics and classical physics.

</details>


### [357] [A source of heralded atom-photon entanglement for quantum networking](https://arxiv.org/abs/2510.15765)
*Gianvito Chiarella,Tobias Frank,Leart Zuka,Pau Farrera,Gerhard Rempe*

Main category: quant-ph

TL;DR: 通过在发送方实现基于级联双光子发射的原子纠缠信封，可以提高量子网络中原子-光子纠缠的保真度和效率，从而减少光子损耗的影响。


<details>
  <summary>Details</summary>
Motivation: 通信中的光子损耗会影响量子网络的性能，需要一种方法来减轻由此产生的错误，而传统的接收方测量信封策略存在速度慢和易受虚假信封（如探测器暗计数）影响的问题。

Method: 利用单个原子级联双光子发射到两个光纤腔中，其中一个光子的偏振与原子的自旋纠缠，第二个光子作为纠缠生成的信封。

Result: 在提出的方案中，纠缠信封将原子-光子纠缠的在纤效率和保真度分别提高到68(3)%和87(2)%。

Conclusion: 该方案有潜力用于噪声限制的长距离量子通信，因为它可以扩展恒定保真度的范围或在给定距离下提高保真度。

Abstract: Communication in quantum networks suffers notoriously from photon loss.
Resulting errors can be mitigated with a suitable measurement herald at the
receiving node. However, waiting for a herald and communicating the measurement
result back to the sender in a repeat-until-success strategy makes the protocol
slow and prone to errors from false heralds such as detector dark counts. Here
we implement an entanglement herald at the sending node by employing a cascaded
two-photon emission of a single atom into two optical fiber cavities: The
polarization of one photon is entangled with the spin of the atom, and the
second photon heralds entanglement generation. We show that heralding improves
the atom-photon entanglement in-fiber efficiency and fidelity to 68(3)% and
87(2)%, respectively. We highlight the potential of our source for
noise-limited long-distance quantum communication by extending the range for
constant fidelity or, alternatively, increasing the fidelity for a given
distance.

</details>


### [358] [Hybrid Path-Transverse Electric Mode Qudit Encoding on an Integrated Photonic Chip](https://arxiv.org/abs/2510.15774)
*Imogen Forbes,Patrick Yard,Martin Bielak,Molly A. Thomas,Matthew S. Jones,Stefano Paesani,Massimo Borghi,Anthony Laing*

Main category: quant-ph

TL;DR: 通过利用集成光子学中易于使用的横电模式（TE模式）和其他自由度，研究人员构建了一个可重构的集成光子器件，用于生成高保真度的qudit态和超纠缠态，并成功将其应用于单拷贝纠缠提纯协议，展示了混合编码在减小量子光子实验尺寸方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 混合编码可以利用多个自由度来编码量子信息，从而在硬件要求增加很小的情况下扩大希尔伯特空间，并且这种编码方式易于与集成光子学兼容。

Method: 开发了一个可重构的集成光子器件，其中包含用于控制横电模式的多模态组件。利用该器件生成在路径和横电模式自由度上纠缠的qudit态，并生成和验证了高保真度的超纠缠态（$f
F = 67.3 

 0.2\%$）和GHZ$_{4}$风格的态（$f
F = 85.2 

 0.4\%$）。将生成的超纠缠态应用于单拷贝纠缠提纯协议。

Result: 成功生成并验证了保真度分别为 $f
F_{\text{HE}} = 67.3 \pm 0.2\%$ 的超纠缠态和 $f
F_{\text{GHZ}_{4}} = 85.2 \pm 0.4\%$ 的 GHZ$_{4}$-style 态。在单拷贝纠缠提纯协议中，平均保真度提高了 $f 9.1\%$，即使在高达 $f 50\%$ 的比特翻转错误概率下也能实现。

Conclusion: 所提出的混合编码方法，特别是利用横电模式，是实现量子光子实验小型化和提高其性能的第一步，具有重要的实际意义。

Abstract: Hybrid encodings, where multiple degrees of freedom are used to encode
quantum information, can increase the size of the Hilbert space with minimal
increase to hardware requirements. We show a reprogrammable integrated photonic
device, with multimodal components designed to allow for control over the
transverse electric modes. We use this device to generate qudit states
entangled in the path and transverse electric mode degrees of freedom. We
generate and verify a hyperentangled state with a fidelity of
$\mathcal{F}_{\text{HE}} = 67.3 \pm 0.2\%$ and a GHZ$_{4}$-style state with a
fidelity of $\mathcal{F}_{\text{GHZ}_{4}} = 85.2 \pm 0.4 \%$. We use our
hyperentangled state in a single-copy entanglement distillation protocol,
resulting in an average $9.1 \%$ increase in the fidelity of the distilled Bell
state for up to a $50\%$ probability of bit flip error. By utilising degrees of
freedom which are readily compatible with integrated photonics, our work
highlights how this hybrid encoding demonstrates a first step in using the
transverse electric mode to reduce the footprint of integrated quantum photonic
experiments.

</details>


### [359] [Flexible Qubit Allocation of Network Resource States](https://arxiv.org/abs/2510.15776)
*Francesco Mazza,Jorge Miguel-Ramiro,Jessica Illiano,Alexander Pirker,Marcello Caleffi,Angela Sara Cacciapuoti,Wolfgang Dür*

Main category: quant-ph

TL;DR: 研究使用具有灵活的、非平凡的量子比特到节点分配的图态，以太网作为量子网络资源状态，特别是簇状态，以提高量子互联网的可扩展性和弹性。


<details>
  <summary>Details</summary>
Motivation: 识别可扩展和有弹性的量子网络资源状态对于实现仍处于起步阶段的量子互联网至关重要。

Method: 探索具有灵活的、非平凡的量子比特到节点分配的图态，重点是具有任意分配的簇态，并引入用于将纠缠拓扑覆盖在物理网络上的建模框架。

Result: 优化的和随机的量子比特分配可以创建捷径，提高鲁棒性并节省内存，同时与传统方法相比，大大缩短了远程网络节点之间的平均跳数。

Conclusion: 具有任意分配的簇态是量子网络核心级纠缠资源的有希望的候选者，因为它们具有灵活的连接性和对粒子损失的弹性。

Abstract: The Quantum Internet is still in its infancy, yet identifying scalable and
resilient quantum network resource states is an essential task for realizing
it. We explore the use of graph states with flexible, non-trivial qubit-to-node
assignments. This flexibility enables adaptable engineering of the entanglement
topology of an arbitrary quantum network. In particular, we focus on cluster
states with arbitrary allocation as network resource states and as a promising
candidate for a network core-level entangled resource, due to its intrinsic
flexible connectivity properties and resilience to particle losses. We
introduce a modeling framework for overlaying entanglement topologies on
physical networks and demonstrate how optimized and even random qubit
assignment, creates shortcuts and improves robustness and memory savings, while
substantially reducing the average hop distance between remote network nodes,
when compared to conventional approaches.

</details>


### [360] [Adaptive time Compressed QITE (ACQ) and its geometrical interpretation](https://arxiv.org/abs/2510.15781)
*Alberto Acevedo Meléndez,Carmen G. Almudéver,Miguel Angel Garcia-March,Rafael Gómez-Lurbe,Luca Ion,Mohit Lal Bera,Rodrigo M. Sanz,Somayeh Mehrabankar,Tanmoy Pandit,Armando Pérez,Andreu Anglés-Castillo*

Main category: quant-ph

TL;DR: 本文提出了一种新颖的量子虚时演化（QITE）算法，通过利用几何性质来减少算法运行时间和电路深度，并进行了数值研究以评估其性能。


<details>
  <summary>Details</summary>
Motivation: 在材料科学、化学和优化等领域，为给定的哈密顿量制备基态，特别是针对大型强关联系统，是一个具有挑战性的计算任务。

Method: 提出了一种新的QITE算法，结合了迭代线搜索和牛顿法来最小化能量和优化时间步长。通过将QITE算法产生的酉算子近似为单参数群的元素来减少电路深度。

Result: 进行了数值研究，评估了保真度与截断参数的关系，并估计了门计数。

Conclusion: 所提出的QITE算法通过利用几何性质，有望减少算法运行时间和电路深度，为有效制备量子基态提供了新的途径。

Abstract: Preparing the ground state of a given Hamiltonian is a computational task of
interest in many fields, such as material science, chemistry and even some
optimization problems, to name a few. Efficiently preparing ground states for
large, strongly correlated systems is a challenging task for both classical and
quantum hardware. Drawing from classical optimization methods, e.g. dynamical
optimization techniques, one may deduce the spectral decomposition in manner
that avoids direct spectral decomposition and is amenable to Trotterization
methods. An instance of the latter is ground state preparation by Imaginary
Time Evolution (ITE), understood in physical terms as a natural cooling
process. Its quantum version QITE (Quantum Imaginary Time Evolution) aims at
implementing ITE in a quantum computer. In this paper we introduce a novel QITE
algorithm, which leverages underlying geometric properties for
algorithm-runtime and circuit depth reduction. This will materialize in the
form of an iterative Line Search approach for minimization of energy as well as
a Newton's method approach for the deduction of the optimal time-steps for each
iteration of QITE. The depth-reduction will be carried out via approximating
the resulting unitary operator estimated from the QITE algorithm with unitary
operator which is an element of a one-parameter group; making expressible as a
single unitary in a quantum circuit. Furthermore, we perform a numerical study
to stablish the scaling of fidelities with the different truncation parameters
and give gate counts estimates for each.

</details>


### [361] [Role of exceptional points in the dynamics of the Lindblad Sachdev-Ye-Kitaev model](https://arxiv.org/abs/2510.15793)
*Jie-ping Zheng,Jorge Dukelsky,Rafael A. Molina,Antonio M. García-García*

Main category: quant-ph

TL;DR: SYK模型在耗散环境下的动力学行为表现出非单调衰减率和动力学相变，这源于Liouvillian谱中的exceptional points。


<details>
  <summary>Details</summary>
Motivation: 研究SYK模型在耗散环境下的非平衡态动力学，特别是其衰减率和Loschmidt回声的行为，并探究其背后机制。

Method: 通过解析计算（小N）和数值模拟（大N）相结合的方式，分析SYK模型在Lindblad形式下与马尔可夫浴耦合时的行为，重点关注Liouvillian谱中的exceptional points。

Result: 发现SYK模型向稳态的衰减率随浴耦合强度μ呈现非单调行为，Loschmidt回声表现出动力学相变并可能转变为crossover。这些现象与Liouvillian谱中靠近零特征值的实特征值exceptional points的存在有关。小N的解析计算和数值模拟结果表明，对应最长寿命模式的exceptional point出现的μ值（约0.1）接近衰减率的局部最大值，此后出现弛豫率随耦合强度增强而减弱的异常弛豫区。Loschmidt回声的相变到crossover的转变发生在更大的μ值（约0.3），这与Liouvillian低能谱中exceptional points的增殖有关。

Conclusion: SYK模型耗散动力学中的非单调衰减率和动力学相变现象源于Liouvillian谱中的exceptional points。这些发现可能普遍适用于量子强相互作用多体Liouvillian在趋于平衡过程中的行为。

Abstract: The out of equilibrium dynamics of the Sachdev-Ye-Kitaev model (SYK),
comprising $N$ Majoranas with random all-to-all four-body interactions,
minimally coupled to a Markovian bath modeled by the Lindblad formalism,
displays intriguing nontrivial features. In particular, the decay rate towards
the steady state is a non-monotonic function of the bath coupling $\mu$, and an
analogue of the Loschmidt echo for dissipative quantum systems undergoes a
first order dynamical phase transitions that eventually becomes a crossover for
sufficiently large $\mu$. We provide evidence that these features have their
origin in the presence of exceptional points in the purely real eigenvalues of
the SYK Liouvillian closest to the zero eigenvalue associated with the steady
state. An analytic calculation at small $N$, supported by numerical results for
larger $N$, reveals that the value of $\mu \sim 0.1$ at which the exceptional
point corresponding to the longest living modes occurs is close to a local
maximum of the decay rate. This value marks the start of a region of anomalous
equilibration where the relaxation rate diminishes as the coupling to the bath
becomes stronger. Moreover, the mentioned change from transition to crossover
in the Loschmidt echo occurs at a larger $\mu \sim 0.3$ corresponding with a
proliferation of exceptional points in the low energy limit of the Liouvillian
spectrum. We expect these features to be generic in the approach to equilibrium
in quantum strongly interacting many-body Liouvillians.

</details>


### [362] [Operator Commutativity Screening and Progressive Operator Block Reordering toward Many-body Inspired Quantum State Preparation](https://arxiv.org/abs/2510.15806)
*Dibyendu Mondal,Debaarjun Mukherjee,Rahul Maitra*

Main category: quant-ph

TL;DR: VQE的动态构造策略通过结合交换筛选、能量排序和张量分解来构建紧凑且高效的ansatz，成功解决了NISQ时代量子化学计算中的挑战，提高了准确性并有效避开了局部最小值。


<details>
  <summary>Details</summary>
Motivation: 在NISQ时代，VQE在量子化学中用于确定分子能量和性质，但其主要挑战在于设计能够表示精确基态波函数且易于进行经典优化的ansatz。ansatz需要足够紧凑以适应当前量子硬件的限制，同时又要足够灵活以捕捉重要的相关效应。

Method: 提出了一种系统性的动态ansatz构造策略：首先通过交换筛选和能量排序识别主要的算子块；然后通过迭代算子块重排逐步扩展ansatz；通过降低的下半部分张量分解来包含高阶相关项；最后，通过自适应构造策略引导优化，避开局部最小值。

Result: 该策略在各种分子系统的基准测试中，以显著减少的参数实现了精确的能量学，并有效避开了局部最小值。在强相关区域（如键解离），该方法成功地重现了基态，而其他当前方法常常失败。

Conclusion: 该方法通过渐进式算子块添加策略，在NISQ时代实现了准确的分子能量计算，相比于其他方法，该方法参数更少，并且能够有效避开局部最小值，在强关联区域表现尤为出色。

Abstract: In the field of quantum chemistry, the variational quantum eigensolver (VQE)
has emerged as a highly promising approach to determine molecular energies and
properties within the noisy intermediate-scale quantum (NISQ) era. The central
challenges of this approach lie in the design of an expressive ansatz capable
of representing the exact ground state wavefunction while concurrently being
efficient to avoid numerical instabilities during the classical optimization.
Owing to the constraints of current quantum hardware, the ansatz must remain
sufficiently compact while retaining the flexibility to capture essential
correlation effects. To address these challenges, we propose a systematic
dynamic ansatz construction strategy in which the dominant operator blocks are
initially identified through commutativity screening, combined with an energy
sorting criteria. Subsequently, the ansatz is progressively expanded in a
stepwise manner via iterative operator block reordering. To minimize the
overhead, the higher order correlation terms are incorporated via reduced
lower-body tensor factorization in each operator block, while the adaptive
construction strategy ensures that the optimization is guided along the optimal
trajectory to mitigate potential numerical instabilities due to the presence of
local traps. Benchmark applications to various molecular systems demonstrate
that this strategy of progressive operator-block addition achieves accurate
energetics with significantly fewer parameters while efficiently bypassing
local traps. Moreover, in strongly correlated regions, such as bond
dissociation, the method successfully reproduces the ground state, where other
contemporary approaches often fail.

</details>


### [363] [Spectral statistics and energy gap-scaling in $k-$local spin Hamiltonians](https://arxiv.org/abs/2510.15829)
*Sasanka Dowarah*

Main category: quant-ph

TL;DR: 该研究探讨了全连接自旋哈密顿量的谱性质，重点关注了由正态分布耦合系数定义的情形。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解具有随机耦合的自旋系统的谱性质，特别是其与高斯随机矩阵集成（GOE，GUE，GSE）的普适性分类，以及系统大小和局部性对能量间隙的影响。

Method: 研究方法包括了对全连接自旋哈密顿量的谱性质进行理论分析，利用正态分布的均值和方差来定义耦合系数。当均值为零时，根据系统大小 L 的奇偶性和局部性 k 来将哈密顿量分类到 GOE，GUE 或 GSE 集成。当均值非零时，研究将哈密顿量映射到变形随机矩阵集成，并分析了基态和第一激发态之间的能量间隙。

Result: 研究结果表明，在完全无序的情况下（均值为零），谱统计的普适性类别取决于系统大小 L 的奇偶性和局部性 k。对于非零均值耦合，当局部性 k 远小于根号 L 时，能量间隙关闭的阈值与均值耦合 σ ~ μ 成正比。当局部性 k 远大于根号 L 时，只要 μ > σ 就存在谱间隙，并推导出了该能量间隙的解析表达式。

Conclusion: 该研究提出了一个半可解的玩具模型，用于理解随机矩阵的普适性、能量间隙的普适缩放，并为通过系统性的修改和耦合来探索更广泛的性质奠定了基础。

Abstract: We investigate the spectral properties of all-to-all interacting spin
Hamiltonians acting on exactly $k$ spins whose coupling coefficients are drawn
from a normal distribution with mean $\mu$ and variance $\sigma^2$. For the
completely disordered case $\mu = 0$, we show that the universality class of
level statistics depends solely on the parity of system size $L$ and locality
$k$, classifying these Hamiltonians into the Gaussian Orthogonal (GOE), Unitary
(GUE), or Symplectic (GSE) ensembles. For couplings with a non-zero mean, we
map the Hamiltonians to deformed random matrix ensembles and analyze conditions
for a energy gap between the ground state and the first excited state. We find
two distinct regimes: for small locality ($k \ll \sqrt{L}$), we show that the
gap closing threshold scales proportionally with the mean coupling $\sigma \sim
\mu$, and for large locality ($k \gg \sqrt{L}$) a spectral gap exists as long
as $\mu > \sigma$. We analytically derive the expression for this energy gap in
the $k \gg \sqrt{L}$ limit. Our work provides a semi-solvable toy model for
understanding random matrix universality, universal energy gap scaling, and a
foundation for exploring more general properties through systematic
modifications and couplings.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [364] [Topological Order Without Band Topology in Moiré Graphene](https://arxiv.org/abs/2510.15027)
*Hui Liu,Raul Perea-Causin,Zhao Liu,Emil J. Bergholtz*

Main category: cond-mat.mes-hall

TL;DR: 在具有拓扑平庸带的扭曲多层石墨烯中，通过长程库仑相互作用，发现了分数化拓扑阶，表现为分数化量子霍尔电导和劳克林行为。


<details>
  <summary>Details</summary>
Motivation: 研究拓扑与关联的相互作用，并证明在现实条件下，即使在拓扑平庸的莫尔带中也可以出现分数化拓扑阶。

Method: 将长程库仑相互作用投影到扭曲多层石墨烯的平庸带中，并分析其产生的非压缩FCI基态。

Result: 识别出表现出分数化量子霍尔电导的FCI基态，并通过粒子切割纠缠谱证实了其劳克林行为。发现了量子几何在重塑相互作用效应中起着关键作用，独立于带的拓扑。

Conclusion: 证明了多体拓扑阶可以独立于单粒子带的拓扑在现实场景中出现，并提出了一个量子几何机制来解释和推广这种现象，甚至可以稳定更高陈数带中的FCI。

Abstract: The discovery of zero-field fractional Chern insulators (FCIs) in moir\'e
materials has attracted intense interest in the interplay between topology and
correlations. Here, we demonstrate that fractionalized topological order can
emerge under realistic conditions even within a topologically trivial moir\'e
band. By projecting long-range Coulomb interactions into a trivial band of
twisted multilayer graphene, we identify a set of incompressible FCI ground
states exhibiting fractional quantized Hall conductance. Their Laughlin-like
behavior is further confirmed through the particle-cut entanglement spectrum.
We trace the origin of this phase to the strongly inhomogeneous distribution of
quantum geometry within the moir\'e Brillouin zone, which reshapes interaction
effects independently of the band topology. Extending this heuristic quantum
geometric mechanism, we demonstrate that similarly unexpected Laughlin-like
FCIs can also be stabilized in higher-Chern-number moir\'e bands under
experimentally accessible conditions. Our results establish realistic scenarios
under which many-body topological order can emerge independently of
single-particle band topology.

</details>


### [365] [Does Moire Matter? Critical Moire Dependence with Quantum Fluctuations in Graphene Based Integer and Fractional Chern Insulators](https://arxiv.org/abs/2510.15309)
*Zihao Huo,Wenxuan Wang,Jian Xie,Yves H. Kwan,Jonah Herzog-Arbeitman,Zaizhe Zhang,Qiu Yang,Min Wu,Kenji Watanabe,Takashi Taniguchi,Kaihui Liu,Nicolas Regnault,B. Andrei Bernevig,Xiaobo Lu*

Main category: cond-mat.mes-hall

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Rhombohedral multilayer graphene has emerged as a powerful platform for
investigating flat-band-driven correlated phenomena, yet most aspects remain
not understood. In this work, we systematically study the moire-dependent band
topology in rhombohedral hexalayer graphene. For the first time we demonstrate
that the moire twist angle plays a crucial role in the formation of the moire
Chern insulators in rhombohedral hexalayer graphene/hexagonal boron nitride
(RHG/hBN) moire superlattices. In the moire-distant regime at filling factor v
= 1, only systems with a twist angle {\theta} < 1.1{\deg} exhibit an integer
moire Chern insulator, while the fractional Chern insulator at v = 2/3 requires
smaller twist angle to be stabilized. Our theoretical modelling, which includes
quantum fluctuations and exact diagonalization results, suggests that
mean-field theory, which has been widely adopted, does not explain the
twist-angle dependence of the v = 1 phase diagram, and that correlation effects
are crucial. Moreover, we realize two distinct stacking configurations ( /Xi=0
and /Xi=1) between graphene and hBN, and find that both cases can yield a Chern
insulator at v = 1. Our experimental work upends the current mean-field
paradigm, illuminates how quantum fluctuations and moir\'e effects shape the
RHG/hBN phase diagram, and paves the way for future understanding and
engineering of topological correlated states in rhombohedral graphene moire
systems.

</details>


### [366] [Altermagnetism induced surface Chern insulator](https://arxiv.org/abs/2510.15357)
*Xuance Jiang,Sayed Ali Akbar Ghorashi,Deyu Lu,Jennifer Cano*

Main category: cond-mat.mes-hall

TL;DR: 通过将交替磁体耦合到拓扑晶体绝缘体（TCI），提出了一种新的量子化反常霍尔效应（QAHE）途径，在近乎消失的磁化强度下，在鲁棒且可切换的平台上实现了QAHE。


<details>
  <summary>Details</summary>
Motivation: 提出了一种新的量子化反常霍尔效应（QAHE）途径，以实现具有近乎消失磁化强度的鲁棒且可切换的QAHE平台。

Method: 通过研究TCI SnTe与交替磁体RuO2层的耦合平板，利用第一性原理计算揭示了RuO2中的d波交替磁性在SnTe的（110）表面诱导了7 meV的狄拉克表面态能隙，产生了有限的反常霍尔效应。

Result: 在SnTe的（110）表面诱导了7 meV的狄拉克表面态能隙，产生了有限的反常霍尔效应。

Conclusion: 该方法推广到更广泛的交替磁性材料和TCI，提供了一系列具有小或消失磁化强度的拓扑交替磁性异质结构，支持非平凡陈数。该研究强调了一个有前途的新型拓扑平台，具有很高的可调性和在自旋电子学中的应用潜力。

Abstract: We propose a new pathway to the quantized anomalous Hall effect (QAHE) by
coupling an altermagnet to a topological crystalline insulator (TCI). The
former gaps the topological surface states of the TCI, thereby realizing the
QAHE in a robust and switchable platform with near- vanishing magnetization. We
demonstrate the feasibility of this approach by studying a slab of the TCI SnTe
coupled to an altermagnetic RuO2 layer. Our first-principles calculations
reveal that the d-wave altermagnetism in RuO2 induces a 7 meV gap to the Dirac
surface states on the (110) surface of SnTe, producing a finite anomalous Hall
effect. Our approach generalizes to broader classes of altermagnetic materials
and TCIs, thereby providing a family of topological altermagnetic
heterostructures with small or vanishing magnetization that support nontrivial
Chern numbers. Our results highlight a promising new topological platform with
great tunability and applications to spintronics.

</details>


### [367] [Gate-tunable Josephson diodes in magic-angle twisted bilayer graphene](https://arxiv.org/abs/2510.15503)
*A. Rothstein,R. J. Dolleman,L. Klebl,A. Achtermann,F. Volmer,K. Watanabe,T. Taniguchi,F. Hassler,L. Banszerus,B. Beschoten,C. Stampfer*

Main category: cond-mat.mes-hall

TL;DR: MATBG中的约瑟夫森结表现出可调的约瑟夫森二极管效应，这源于大动能电感和非均匀超流分布，并且微观不均匀性会影响二极管行为。


<details>
  <summary>Details</summary>
Motivation: 在接近$
u = -2$的莫尔填充因子下，研究魔角扭曲双层石墨烯（MATBG）中两个相邻、由栅极定义的约瑟夫森结（JJs）的低温柔性。

Method: 进行低温柔性测量，并分析了两个约瑟夫森结的干涉图样和二极管行为。

Result: 两个约瑟夫森结均表现出显著的、由栅极调谐的约瑟夫森二极管效应，且二极管行为不同。非互易超流电流可通过栅极电压进行调谐，从而调谐二极管效率并改变极性。

Conclusion: 微观不均匀性（如扭转角变化）会影响非均匀超流分布并驱动二极管行为，为在超导量子电路中定制约瑟夫森二极管性能提供了潜在途径。

Abstract: We report low-temperature measurements of two adjacent, gate-defined
Josephson junctions (JJs) in magic-angle twisted bilayer graphene (MATBG) at a
moir\'e filling factor near $\nu = -2$. We show that both junctions exhibit a
prominent, gate-tunable Josephson diode effect, which we explain by a
combination of large kinetic inductance and non-uniform supercurrent
distribution. Despite their proximity, the JJs display differences in their
interference patterns and different diode behavior, underscoring that
microscopic inhomogeneities such as twist angle variations shape the
non-uniform supercurrent and drive the diode behavior. As a result, the
nonreciprocal supercurrent can be tuned by gate voltage, enabling tuning of the
diode efficiency and even reversing the polarity at fixed magnetic fields. Our
findings offer potential routes for tailoring Josephson diode performance in
superconducting quantum circuits.

</details>


### [368] [Topological Magnetic Phases and Magnon-Phonon Hybridization in the Presence of Strong Dzyaloshinskii-Moriya Interaction](https://arxiv.org/abs/2510.15525)
*Weicen Dong,Haoxin Wang,Matteo Baggioli,Yi Liu*

Main category: cond-mat.mes-hall

TL;DR: Strong DMI in a 2D magnetic system leads to noncollinear magnetic order and diverse topological phases, detectable via anomalous thermal Hall effect, with significant magnon-phonon coupling.


<details>
  <summary>Details</summary>
Motivation: Investigate topological magnetic phases and magnon-phonon hybridization in the largely unexplored strong DMI regime of 2D magnetic systems, motivated by the potential of topological magnons for spintronics.

Method: Examine a 2D magnetic system with strong DMI, analyzing the ground state, the effect of an additional Zeeman field, and magnon-phonon coupling. Propose probing topological phases through the anomalous thermal Hall effect.

Result: Strong DMI drives a transition to a 120° noncollinear order. A Zeeman field induces noncoplanar spin textures and diverse topological phases. Anomalous thermal Hall effect can probe these phases. Magnon-phonon coupling occurs in the strong-D phase, creating hybridized topological bands, but vanishes in the weak-D phase.

Conclusion: The study reveals rich topological physics in the strong DMI regime, including novel spin textures and hybridized topological bands, with potential applications in spintronics and sensing through the anomalous thermal Hall effect.

Abstract: In recent years, the interplay between quantum magnetism and topology has
attracted growing interest, both for its fundamental importance and its
technological potential. Topological magnons, quantized spin excitations with
nontrivial band topology, hold particular promise for spintronics, offering
routes to robust, low-dissipation devices for next-generation information
processing and storage. While topological magnons in honeycomb ferromagnets
with weak next-nearest-neighbor Dzyaloshinskii-Moriya interactions (DMI) have
been extensively investigated, the strong-DMI regime remains largely
unexplored. In this work, we examine topological magnetic phases and
magnon-phonon hybridization in a two-dimensional magnetic system with strong
DMI. We show that strong DMI drives a transition from a ferromagnetic ground
state to a 120$^\circ$ noncollinear order. An additional Zeeman field further
induces noncoplanar spin textures, giving rise to a diverse set of topological
phases. We demonstrate that these topological phases can be directly probed
through the anomalous thermal Hall effect. Finally, we find that the spin-spin
interactions in the strong-$D$ phase enable magnon-phonon coupling that yields
hybridized topological bands, whereas such coupling vanishes in the weak-$D$
phase.

</details>


### [369] [Emergent Topology in Kagome Ferromagnets](https://arxiv.org/abs/2510.15536)
*Seif Alwan,Jonas Fransson*

Main category: cond-mat.mes-hall

TL;DR: 在具有 DMI 和标量自旋手性的二维kagome 铁磁体中，我们研究了拓扑磁畴相的出现，其中 DMI 和拓扑轨道耦合 kappa_TO 之间的相互作用产生了几何相位、非平凡的 Berry 曲率和磁畴带中的量子化陈数。我们发现，有限的 DMI 会形成动量空间中的 skyrmions，它们是几何曲率的来源。然而，仅有 DMI 并不足以打破时间反转对称性，只有在存在标量手性项的情况下，系统才能产生非零的 Berry 相位和拓扑传输特征。


<details>
  <summary>Details</summary>
Motivation: 研究具有 DMI 和标量自旋手性的二维 kagome 铁磁体中拓扑磁畴相的出现，以及 DMI 和拓扑轨道耦合 kappa_TO 之间的相互作用如何产生几何相位、非平凡的 Berry 曲率和量子化陈数。

Method: 采用动量空间表示和线性自旋波理论，计算布里渊区中轨道纹理、涡旋度和 Berry 曲率。

Result: 非共面自旋纹理（由有限 DMI 驱动）形成动量空间中的 skyrmions，它们是几何曲率的来源。DMI 本身不足以打破时间反转对称性，只有有限的标量手性项才能产生非零的 Berry 相位和拓扑传输特征。全局劈纹旋转会调节 Berry 曲率和陈数，但带状结构保持不变。

Conclusion: 在具有 DMI 和标量自旋手性的二维 kagome 铁磁体中，DMI 和拓扑轨道耦合 kappa_TO 之间的相互作用会产生拓扑磁畴相。标量手性项对于实现非零的 Berry 相位和拓扑传输至关重要。通过操纵晶格几何和手性，可以调节磁畴的拓扑特性。

Abstract: We investigate the emergence of a topological magnon phase in a
two-dimensional kagome ferromagnet with Dzyaloshinskii-Moriya interaction (DMI)
and scalar spin chirality. By incorporating a chiral interaction term
proportional to the scalar triple product chi_ijk = S_i (S_j x S_k), we examine
how the interplay between DMI and the topological orbital coupling kappa_TO
gives rise to geometric phase, nontrivial Berry curvature, and quantized Chern
numbers in the magnon bands. Using a momentum-space representation and linear
spin-wave theory, we compute the orbital texture, its vorticity, and the Berry
curvature across the Brillouin zone. We show that noncoplanar spin textures,
driven by finite DMI, form momentum-space skyrmions that act as sources of
geometric curvature. Importantly, we demonstrate that DMI alone is insufficient
to break time-reversal symmetry; only the presence of finite scalar chirality
terms allows the system to develop a nonzero Berry phase and topological
transport signatures. We further explore the effect of a global plaquette
rotation, showing that while the band structure remains invariant under this
unitary transformation, the Berry curvature and Chern number are modulated,
highlighting the geometric sensitivity of the topological response. Our results
establish a direct correspondence between the lattice geometry, chirality, and
magnon topology, providing a route toward tunable topological phases in
frustrated magnetic systems.

</details>


### [370] [The impact of dimensionality on universality of 2D quantum Hall transitions](https://arxiv.org/abs/2510.15671)
*Qiwei Wan,Yi Zhang*

Main category: cond-mat.mes-hall

TL;DR: 厚度会影响量子霍尔过渡行为，使其偏离二维普遍性并趋向三维高斯酉系综。


<details>
  <summary>Details</summary>
Motivation: 尽管二维量子霍尔系统行为普遍，但实验、理论和数值结果仍存在冲突。需要探究导致这些冲突的潜在因素。

Method: 研究具有有限厚度（$L_z>1$）、无序和磁场的准二维 Weyl 系统，使用递归方法分析局域长度和局域态密度，研究其标度行为。

Result: 有限厚度会导致系统偏离二维量子霍尔普遍性，并出现向三维高斯酉系综的交叉现象。

Conclusion: 论文强调了厚度等辅助自由度对量子霍尔过渡行为的重要性，并指出三维量子霍尔物理并非二维情况的简单推广。

Abstract: Regardless of model and platform details, the critical phenomena exhibit
universal behaviors that are remarkably consistent across various experiments
and theories, resulting in a significant scientific success of condensed matter
physics. One widely known and commonly used example is the 2D quantum Hall
transition; yet, its universal exponents still somewhat conflict between
experiments, theoretical models, and numerical ansatzes. We study critical
behaviors of quasi-2D Weyl semimetal systems with a finite thickness $L_z>1$,
disorder, and external magnetic field $B_z$. By analyzing the scaling behaviors
of the localization lengths and local density of states using recursive
methods, we find that the finite thickness yields a deviation from the 2D
quantum Hall universality ($L_z=1$ case) and a crossover toward the 3D Gaussian
Unitary Ensemble ($L_z\rightarrow \infty$ limit), potentially offering another
cause of the discrepancy. Our work demonstrates the often-overlooked importance
of auxiliary degrees of freedom, such as thickness, and that 3D quantum Hall
physics is not merely a trivial finite-thickness extension of its 2D
counterpart.

</details>


### [371] [Measuring the magnetic anisotropy of the spin Hall effect and spin relaxation length in nickel and permalloy via electrical spin injection](https://arxiv.org/abs/2510.15809)
*Eoin Dolan,Jone Mencos,Williams Savero Torres,Maxen Cosset-Chéneau,Jean-Philippe Attané,Laurent Vila,Luis E. Hueso,Fèlix Casanova*

Main category: cond-mat.mes-hall

TL;DR: 自旋弛豫长度和自旋霍尔角在铁磁材料中表现出各向异性，并且它们对磁化取向的变化具有相反的响应，这可能导致自旋-电荷相互转换输出的抵消。


<details>
  <summary>Details</summary>
Motivation: 研究自旋霍尔效应在铁磁材料中的应用，特别是自旋极化与磁化相对取向对自旋霍尔角的影响，以及自旋弛豫长度的磁化取向依赖性。

Method: 使用改进的横向自旋阀结构，通过铜通道和坡莫合金自旋注入器，在两种不同的器件几何结构中，测量坡莫合金和镍的自旋霍尔角和自旋弛豫长度对磁化取向的依赖性，以区分自旋弛豫长度和自旋霍尔角对自旋-电荷相互转换电压输出的贡献。

Result: 结果表明，坡莫合金和镍都表现出自旋弛豫长度和自旋霍尔角的显著各向异性，这与理论计算一致。并且，自旋弛豫长度随磁化与自旋极化平行时而增加，而自旋霍尔角则减小，导致自旋-电荷相互转换输出几乎完全抵消。

Conclusion: 自旋弛豫长度和自旋霍尔角在铁磁材料中表现出各向异性，并且它们对磁化取向的变化具有相反的响应，这可能导致自旋-电荷相互转换输出的抵消。

Abstract: The spin Hall effect in ferromagnets is of great interest in the field of
spintronics, and while the effect has been quantified in many materials, the
dependence of the spin Hall angle on the relative orientation of spin
polarization and the magnetization is less well studied. Of equal importance
for the purpose of spin-charge interconversion in ferromagnets is the spin
relaxation length, which is predicted to be highly anisotropic with respect to
magnetization. Using a modified lateral spin valve geometry with a copper
channel and permalloy spin injector, we measure the dependence of the spin Hall
angle and spin relaxation length on magnetization orientation in permalloy and
nickel, using two distinct device geometries. This allows us to disentangle the
contributions of the spin relaxation length and spin Hall angle to the measured
spin-charge interconversion voltage output. Our results indicate a large
anisotropy in both the spin relaxation length and spin Hall angle in both
permalloy and nickel, in agreement with theoretical calculations. The
quantities change in opposite directions, with the spin relaxation length
rising as the magnetization is moved parallel to the spin polarization and the
spin Hall angle falling, leading to a near total cancellation of the
spin-charge interconversion output.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [372] [Build Your Personalized Research Group: A Multiagent Framework for Continual and Interactive Science Automation](https://arxiv.org/abs/2510.15624)
*Ed Li,Junyu Ren,Xintian Pan,Cat Yan,Chuanhao Li,Dirk Bergemann,Zhuoran Yang*

Main category: cs.AI

TL;DR: freephdlabor是一个开源多智能体框架，通过完全动态的工作流和模块化架构解决了现有科学研究中自动化代理系统的局限性，实现了从构思到出版的端到端自动化研究。


<details>
  <summary>Details</summary>
Motivation: 现有科学研究中的自动化代理系统存在工作流僵化和上下文管理不足的问题，无法适应中间发现或支持长期研究。

Method: freephdlabor框架采用了完全动态的工作流（由实时智能体推理决定）和模块化架构（允许用户自定义、添加或删除智能体）。它还包括自动上下文压缩、基于工作区的通信、内存持久性和非阻塞的人工干预机制。

Result: 该框架能够实现持续的研究项目，系统地建立在先前的探索之上，并整合人类反馈，最终能够自主地完成从构思、实验到生成出版级手稿的端到端研究。

Conclusion: freephdlabor为构建可定制的共生科学家系统提供了架构原则和实际实现，旨在促进自动化研究在各科学领域的广泛应用，并实现端到端的自动化研究。

Abstract: The automation of scientific discovery represents a critical milestone in
Artificial Intelligence (AI) research. However, existing agentic systems for
science suffer from two fundamental limitations: rigid, pre-programmed
workflows that cannot adapt to intermediate findings, and inadequate context
management that hinders long-horizon research. We present
\texttt{freephdlabor}, an open-source multiagent framework featuring
\textit{fully dynamic workflows} determined by real-time agent reasoning and a
\coloremph{\textit{modular architecture}} enabling seamless customization --
users can modify, add, or remove agents to address domain-specific
requirements. The framework provides comprehensive infrastructure including
\textit{automatic context compaction}, \textit{workspace-based communication}
to prevent information degradation, \textit{memory persistence} across
sessions, and \textit{non-blocking human intervention} mechanisms. These
features collectively transform automated research from isolated, single-run
attempts into \textit{continual research programs} that build systematically on
prior explorations and incorporate human feedback. By providing both the
architectural principles and practical implementation for building customizable
co-scientist systems, this work aims to facilitate broader adoption of
automated research across scientific domains, enabling practitioners to deploy
interactive multiagent systems that autonomously conduct end-to-end research --
from ideation through experimentation to publication-ready manuscripts.

</details>


### [373] [Hypergraph Contrastive Sensor Fusion for Multimodal Fault Diagnosis in Induction Motors](https://arxiv.org/abs/2510.15547)
*Usman Ali,Ali Zia,Waqas Ali,Umer Ramzan,Abdul Rehman,Muhammad Tayyab Chaudhry,Wei Xiang*

Main category: cs.AI

TL;DR: MM-HCAN是一个创新的多模态超图对比注意力网络，用于可靠的感应电机故障诊断，能够同时处理多种故障类型，并在噪声和跨域条件下表现出鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统电机故障诊断方法在处理复杂多模态信号关系、单一数据源或单一故障类型方面存在局限，并且在噪声或跨域条件下性能下降。本研究旨在提出一种更可靠、更通用的故障诊断方法。

Method: 提出一种名为MM-HCAN的多模态超图对比注意力网络。该网络将对比学习嵌入超图结构中，以融合多模态传感器数据，能够联合建模模内和模间依赖关系，并在超越欧几里得嵌入空间的条件下提升泛化能力。该模型能够同时诊断轴承、定子和转子故障。

Result: 在三个真实世界数据集上的评估显示，MM-HCAN的准确率高达99.82%，并表现出强大的跨域泛化能力和噪声鲁棒性，证明其适用于实际部署。消融研究验证了各组成部分的有效性。

Conclusion: MM-HCAN为全面的多故障诊断提供了一个可扩展且鲁棒的解决方案，有助于工业环境中的预测性维护和延长设备寿命。

Abstract: Reliable induction motor (IM) fault diagnosis is vital for industrial safety
and operational continuity, mitigating costly unplanned downtime. Conventional
approaches often struggle to capture complex multimodal signal relationships,
are constrained to unimodal data or single fault types, and exhibit performance
degradation under noisy or cross-domain conditions. This paper proposes the
Multimodal Hypergraph Contrastive Attention Network (MM-HCAN), a unified
framework for robust fault diagnosis. To the best of our knowledge, MM-HCAN is
the first to integrate contrastive learning within a hypergraph topology
specifically designed for multimodal sensor fusion, enabling the joint
modelling of intra- and inter-modal dependencies and enhancing generalisation
beyond Euclidean embedding spaces. The model facilitates simultaneous diagnosis
of bearing, stator, and rotor faults, addressing the engineering need for
consolidated di- agnostic capabilities. Evaluated on three real-world
benchmarks, MM-HCAN achieves up to 99.82% accuracy with strong cross-domain
generalisation and resilience to noise, demonstrating its suitability for
real-world deployment. An ablation study validates the contribution of each
component. MM-HCAN provides a scalable and robust solution for comprehensive
multi-fault diagnosis, supporting predictive maintenance and extended asset
longevity in industrial environments.

</details>


### [374] [OpenEstimate: Evaluating LLMs on Reasoning Under Uncertainty with Real-World Data](https://arxiv.org/abs/2510.15096)
*Alana Renda,Jillian Ross,Michael Cafarella,Jacob Andreas*

Main category: cs.AI

TL;DR: 该研究提出了OpenEstimate基准来评估语言模型在不确定性下的数值估计能力，并发现现有模型表现不佳。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型评估主要关注明确答案的问题，忽视了真实世界应用中常见的处理不确定性和信息不完整性的需求，导致模型在这一能力上的表现缺乏评估。

Method: 引入了一个名为OpenEstimate的可扩展、跨领域基准，用于评估语言模型在需要综合背景信息和表达概率先验预测的数值估计任务上的表现，并通过准确性和校准性来量化评估。

Result: 在六种前沿语言模型上的实验表明，模型产生的概率先验往往不准确且过于自信，尽管通过不同的不确定性引导方式可以略微提升性能，但采样策略、推理过程或提示设计等因素影响不大。

Conclusion: OpenEstimate基准为评估前沿语言模型提供了一个具有挑战性的平台，并有助于推动在概率估计和不确定性推理方面更优模型的发展。

Abstract: Real-world settings where language models (LMs) are deployed -- in domains
spanning healthcare, finance, and other forms of knowledge work -- require
models to grapple with incomplete information and reason under uncertainty. Yet
most LM evaluations focus on problems with well-defined answers and success
criteria. This gap exists in part because natural problems involving
uncertainty are difficult to construct: given that LMs have access to most of
the same knowledge as humans, it is non-trivial to design questions for which
LMs will struggle to produce correct answers, but which humans can answer
reliably. As a result, LM performance on reasoning under uncertainty remains
poorly characterized. To address this gap, we introduce OpenEstimate, an
extensible, multi-domain benchmark for evaluating LMs on numerical estimation
tasks that require models to synthesize significant amounts of background
information and express predictions as probabilistic priors. We assess these
priors for accuracy and calibration, quantifying their usefulness relative to
samples from the true distribution of interest. Across six frontier LMs, we
find that LM-elicited priors are often inaccurate and overconfident.
Performance improves modestly depending on how uncertainty is elicited from the
model, but is largely unaffected by changes in sampling strategy, reasoning
effort, or prompt design. The OpenEstimate benchmark thus offers a challenging
evaluation for frontier LMs and a platform for developing models that are
better at probabilistic estimation and reasoning under uncertainty.

</details>


### [375] [AURA: An Agent Autonomy Risk Assessment Framework](https://arxiv.org/abs/2510.15739)
*Lorenzo Satta Chiris,Ayush Mishra*

Main category: cs.AI

TL;DR: AURA是一个统一的框架，用于检测、量化和缓解自主AI代理带来的风险，通过基于gamma的风险评分方法、人机交互和A2H通信机制，支持负责任、透明且可治理的企业级AI代理部署。


<details>
  <summary>Details</summary>
Motivation: 当前，自主AI代理在组织中的应用面临对齐、治理和风险管理方面的挑战，这阻碍了其大规模部署。因此，需要一个框架来解决这些问题。

Method: AURA框架采用基于gamma的风险评分方法，并结合了人机交互（HITL）监督和代理到人类（A2H）通信机制，以实现自主评估和风险管理。它还支持与现有协议（MCP和A2A）和工具的互操作性。

Result: AURA通过其风险评分方法和交互式评估过程，能够检测、量化和缓解AI代理的风险。它提供了与现有系统的互操作性，并支持人机协作，从而实现了对AI代理的有效治理。

Conclusion: AURA框架为负责任、透明且可治理的企业级AI代理部署提供了关键支持，它通过有效的风险检测和缓解策略，在保证计算资源效率的同时，解决了自主AI代理在大规模应用中面临的挑战。

Abstract: As autonomous agentic AI systems see increasing adoption across
organisations, persistent challenges in alignment, governance, and risk
management threaten to impede deployment at scale. We present AURA (Agent
aUtonomy Risk Assessment), a unified framework designed to detect, quantify,
and mitigate risks arising from agentic AI. Building on recent research and
practical deployments, AURA introduces a gamma-based risk scoring methodology
that balances risk assessment accuracy with computational efficiency and
practical considerations. AURA provides an interactive process to score,
evaluate and mitigate the risks of running one or multiple AI Agents,
synchronously or asynchronously (autonomously). The framework is engineered for
Human-in-the-Loop (HITL) oversight and presents Agent-to-Human (A2H)
communication mechanisms, allowing for seamless integration with agentic
systems for autonomous self-assessment, rendering it interoperable with
established protocols (MCP and A2A) and tools. AURA supports a responsible and
transparent adoption of agentic AI and provides robust risk detection and
mitigation while balancing computational resources, positioning it as a
critical enabler for large-scale, governable agentic AI in enterprise
environments.

</details>


### [376] [Procedural Game Level Design with Deep Reinforcement Learning](https://arxiv.org/abs/2510.15120)
*Miraç Buğra Özkan*

Main category: cs.AI

TL;DR: 本研究提出了一种使用深度强化学习（DRL）在Unity 3D环境中进行程序化关卡设计的新方法。


<details>
  <summary>Details</summary>
Motivation: 程序化内容生成（PCG）在游戏开发中越来越受欢迎，可用于创建动态、可重玩和可扩展的环境，并减少人工投入。本研究旨在探索DRL在自主游戏关卡设计中的潜力。

Method: 提出了一种包含两个智能体的系统：一个蜂鸟智能体（求解器）和一个浮岛智能体（内容生成器）。蜂鸟智能体使用近端策略优化（PPO）算法在程序生成的地形上导航并收集花朵。浮岛智能体也使用PPO算法，根据障碍物位置、蜂鸟的初始状态和历史表现生成花朵布局。

Result: 该方法不仅实现了有效的智能体行为，还能在各种环境配置中实现良好的泛化能力，生成具有挑战性和吸引力的关卡。

Conclusion: DRL能够让智能体在虚拟环境中生成和解决内容，为游戏开发带来了新的机遇，特别是推动了由机器学习驱动的自主游戏关卡设计。

Abstract: Procedural content generation (PCG) has become an increasingly popular
technique in game development, allowing developers to generate dynamic,
replayable, and scalable environments with reduced manual effort. In this
study, a novel method for procedural level design using Deep Reinforcement
Learning (DRL) within a Unity-based 3D environment is proposed. The system
comprises two agents: a hummingbird agent, acting as a solver, and a floating
island agent, responsible for generating and placing collectible objects
(flowers) on the terrain in a realistic and context-aware manner. The
hummingbird is trained using the Proximal Policy Optimization (PPO) algorithm
from the Unity ML-Agents toolkit. It learns to navigate through the terrain
efficiently, locate flowers, and collect them while adapting to the
ever-changing procedural layout of the island. The island agent is also trained
using the Proximal Policy Optimization (PPO) algorithm. It learns to generate
flower layouts based on observed obstacle positions, the hummingbird's initial
state, and performance feedback from previous episodes. The interaction between
these agents leads to emergent behavior and robust generalization across
various environmental configurations. The results demonstrate that the approach
not only produces effective and efficient agent behavior but also opens up new
opportunities for autonomous game level design driven by machine learning. This
work highlights the potential of DRL in enabling intelligent agents to both
generate and solve content in virtual environments, pushing the boundaries of
what AI can contribute to creative game development processes.

</details>


### [377] [Towards Error Centric Intelligence I, Beyond Observational Learning](https://arxiv.org/abs/2510.15128)
*Marcus A. Thomas*

Main category: cs.AI

TL;DR: AGI的进展受限于理论而非数据或规模。


<details>
  <summary>Details</summary>
Motivation: 观测等价的世界在干预下可能不同，仅靠观测充足性无法保证干预能力。需要一种新的方法来解决这个问题。

Method: 提出“因果力学”，一个以机制为中心的程序，其中假设空间的变化是一等操作，并仅在有用时使用概率结构。引入了差分局部性和自​​主性原理、独立因果机制的规范不变形式以及组合自主性原理。

Result: 提出了一种用于构建能够将不可达错误转换为可达错误并纠正它们的系统的支架。

Conclusion: AGI 的进展受限于理论，而不是数据或规模。

Abstract: We argue that progress toward AGI is theory limited rather than data or scale
limited. Building on the critical rationalism of Popper and Deutsch, we
challenge the Platonic Representation Hypothesis. Observationally equivalent
worlds can diverge under interventions, so observational adequacy alone cannot
guarantee interventional competence. We begin by laying foundations,
definitions of knowledge, learning, intelligence, counterfactual competence and
AGI, and then analyze the limits of observational learning that motivate an
error centric shift. We recast the problem as three questions about how
explicit and implicit errors evolve under an agent's actions, which errors are
unreachable within a fixed hypothesis space, and how conjecture and criticism
expand that space. From these questions we propose Causal Mechanics, a
mechanisms first program in which hypothesis space change is a first class
operation and probabilistic structure is used when useful rather than presumed.
We advance structural principles that make error discovery and correction
tractable, including a differential Locality and Autonomy Principle for modular
interventions, a gauge invariant form of Independent Causal Mechanisms for
separability, and the Compositional Autonomy Principle for analogy
preservation, together with actionable diagnostics. The aim is a scaffold for
systems that can convert unreachable errors into reachable ones and correct
them.

</details>


### [378] [HugAgent: Evaluating LLMs in Simulating Human-Like Individual Reasoning on Open-Ended Tasks](https://arxiv.org/abs/2510.15144)
*Chance Jiajie Li,Zhenze Mo,Yuhan Tang,Ao Qu,Jiayi Wu,Kaiya Ivy Zhao,Yulu Gan,Jie Fan,Jiangbo Yu,Hang Jiang,Paul Pu Liang,Jinhua Zhao,Luis Alberto Alonso Pastor,Kent Larson*

Main category: cs.AI

TL;DR: 该研究提出了HugAgent基准，用于评估大型语言模型在个体化推理和信念更新方面的能力，以解决当前模型缺乏个体差异性的问题。


<details>
  <summary>Details</summary>
Motivation: 当前的大型语言模型虽然在模仿大众反应方面表现出色，但往往忽略了个体独特的推理风格和信念轨迹，这阻碍了机器实现更类人的推理。因此，需要一个能够评估模型适应个体化推理能力的基准。

Method: HugAgent基准采用双轨道设计：合成轨道用于大规模、系统性的压力测试，人类轨道则用于收集生态学上有效的“出声”推理数据。这种设计允许对模型内部的保真度进行可扩展、可重复的评估，即模型不仅能捕捉人们的信念，还能追踪其推理过程的演变。

Result: 对现有的大型语言模型进行的实验表明，它们在个体化推理和信念更新方面仍存在显著的差距，证明了HugAgent作为评估和改进机器与人类思维个体化一致性的第一个可扩展基准的有效性。

Conclusion: HugAgent基准是第一个可扩展的基准，用于衡量机器推理与人类思维个体化的一致性，其设计能够有效地评估模型捕捉个体推理风格和信念演变轨迹的能力。该基准和相关工具已开源。

Abstract: Simulating human reasoning in open-ended tasks has been a long-standing
aspiration in AI and cognitive science. While large language models now
approximate human responses at scale, they remain tuned to population-level
consensus, often erasing the individuality of reasoning styles and belief
trajectories. To advance the vision of more human-like reasoning in machines,
we introduce HugAgent (Human-Grounded Agent Benchmark), a benchmark for
average-to-individual reasoning adaptation. The task is to predict how a
specific person would reason and update their beliefs in novel scenarios, given
partial evidence of their past views. HugAgent adopts a dual-track design: a
synthetic track for scale and systematic stress tests, and a human track for
ecologically valid, "out-loud" reasoning data. This design enables scalable,
reproducible evaluation of intra-agent fidelity: whether models can capture not
just what people believe, but how their reasoning evolves. Experiments with
state-of-the-art LLMs reveal persistent adaptation gaps, positioning HugAgent
as the first extensible benchmark for aligning machine reasoning with the
individuality of human thought. Our benchmark and chatbot are open-sourced as
HugAgent (https://anonymous.4open.science/r/HugAgent) and TraceYourThinking
(https://anonymous.4open.science/r/trace-your-thinking).

</details>


### [379] [WELD: A Large-Scale Longitudinal Dataset of Emotional Dynamics for Ubiquitous Affective Computing](https://arxiv.org/abs/2510.15221)
*Xiao Sun*

Main category: cs.AI

TL;DR: 该研究提出了一个大规模、长期的工作场所情绪数据集，包含超过73万条面部表情记录，覆盖了38名员工30.5个月的真实办公环境数据。数据集包含了七种基本情绪的概率、工作角色、就业结果、人格特质等元数据，并跨越了新冠疫情及上海封锁等重大社会事件时期。研究者计算了32种扩展情绪指标，并通过技术验证（如周末效应、昼夜节律）和预测分析（如员工离职预测，AUC=1.0）证明了数据的质量。基线实验达到了91.2%的情绪分类准确率和0.84的效价预测R2值。该数据集是目前公开的最大、最长期的纵向工作场所情绪数据集，可用于情绪识别、情绪动力学建模、情绪传染、离职预测和情感感知系统设计等研究。


<details>
  <summary>Details</summary>
Motivation: 在真实工作场所进行自动情绪识别是一个挑战，因为缺乏大规模、长期的、在自然环境中收集的数据集。

Method: 构建了一个包含733,651个面部表情记录的数据集，这些记录来自38名员工在真实办公环境中长达30.5个月的收集。数据包含了七种情绪的概率、详细的元数据（工作角色、就业结果、人格特质），以及32种扩展情绪指标（如效价、唤醒度、波动性、可预测性、惯性、情绪传染强度）。通过技术验证（重现周末效应和昼夜节律）和预测分析（员工离职预测）来评估数据质量。

Result: 技术验证成功复制了已知的心理学模式（周末效应：效价提升192%，p < 0.001；昼夜节律得到验证），并实现了对员工离职的完美预测（AUC=1.0）。基线实验使用随机森林和LSTM模型，在情绪分类上达到了91.2%的准确率，在效价预测上达到了R2 = 0.84。

Conclusion: 该研究发布了迄今为止最大、最长的纵向工作场所情绪数据集，为情绪识别、情绪动力学建模、情绪传染、离职预测和情感感知系统设计等领域的研究提供了宝贵的资源。

Abstract: Automated emotion recognition in real-world workplace settings remains a
challenging problem in affective computing due to the scarcity of large-scale,
longitudinal datasets collected in naturalistic environments. We present a
novel dataset comprising 733,651 facial expression records from 38 employees
collected over 30.5 months (November 2021 to May 2024) in an authentic office
environment. Each record contains seven emotion probabilities (neutral, happy,
sad, surprised, fear, disgusted, angry) derived from deep learning-based facial
expression recognition, along with comprehensive metadata including job roles,
employment outcomes, and personality traits. The dataset uniquely spans the
COVID-19 pandemic period, capturing emotional responses to major societal
events including the Shanghai lockdown and policy changes. We provide 32
extended emotional metrics computed using established affective science
methods, including valence, arousal, volatility, predictability, inertia, and
emotional contagion strength. Technical validation demonstrates high data
quality through successful replication of known psychological patterns (weekend
effect: +192% valence improvement, p < 0.001; diurnal rhythm validated) and
perfect predictive validity for employee turnover (AUC=1.0). Baseline
experiments using Random Forest and LSTM models achieve 91.2% accuracy for
emotion classification and R2 = 0.84 for valence prediction. This is the
largest and longest longitudinal workplace emotion dataset publicly available,
enabling research in emotion recognition, affective dynamics modeling,
emotional contagion, turnover prediction, and emotion-aware system design.

</details>


### [380] [From Checklists to Clusters: A Homeostatic Account of AGI Evaluation](https://arxiv.org/abs/2510.15236)
*Brett Reynolds*

Main category: cs.AI

TL;DR: AGI评估应考虑领域因果中心性并衡量能力持久性，以区分真实通用智能和易变的性能。


<details>
  <summary>Details</summary>
Motivation: 当前AGI评估存在两个问题：(1)所有领域权重相同，这与人类智能研究不符；(2)快照式评估无法区分持久能力和在压力下会崩溃的脆弱表现。

Method: 提出将通用智能视为一种稳态特性簇，即一组能力加上在扰动下保持这些能力共存的机制。建议AGI评估应根据领域因果中心性（对簇稳定性的贡献）加权，并要求跨会话持久性的证据。提出了两种兼容现有电池的扩展：一种引入CHC派生权重和敏感性分析的中心性优先得分，以及一套簇稳定性指数，用于分离特征持久性、持久性学习和错误纠正。

Result: 提出的评估方法能够保留多领域广度，同时减少脆弱性和被操纵的可能性。

Conclusion: 通过引入基于因果中心性的加权和持久性测试，可以更准确地评估AGI的通用智能。建议的测试方法可在无需访问模型架构的情况下被实验室采用，并提出了可检验的预测。

Abstract: Contemporary AGI evaluations report multidomain capability profiles, yet they
typically assign symmetric weights and rely on snapshot scores. This creates
two problems: (i) equal weighting treats all domains as equally important when
human intelligence research suggests otherwise, and (ii) snapshot testing can't
distinguish durable capabilities from brittle performances that collapse under
delay or stress. I argue that general intelligence -- in humans and potentially
in machines -- is better understood as a homeostatic property cluster: a set of
abilities plus the mechanisms that keep those abilities co-present under
perturbation. On this view, AGI evaluation should weight domains by their
causal centrality (their contribution to cluster stability) and require
evidence of persistence across sessions. I propose two battery-compatible
extensions: a centrality-prior score that imports CHC-derived weights with
transparent sensitivity analysis, and a Cluster Stability Index family that
separates profile persistence, durable learning, and error correction. These
additions preserve multidomain breadth while reducing brittleness and gaming. I
close with testable predictions and black-box protocols labs can adopt without
architectural access.

</details>


### [381] [Multi-dimensional Data Analysis and Applications Basing on LLM Agents and Knowledge Graph Interactions](https://arxiv.org/abs/2510.15258)
*Xi Wang,Xianyao Ling,Kun Li,Gang Yin,Liang Zhang,Jiang Wu,Jun Xu,Fu Zhang,Wenbo Lei,Annie Wang,Peng Gong*

Main category: cs.AI

TL;DR: 本研究提出一种结合大语言模型（LLM）和知识图谱（KG）交互的分析方法，以应对大数据分析中的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的大数据分析方法在处理海量、异构、复杂关联的多维度数据时面临挑战。LLM在理解和生成自然语言方面表现出色，但在处理结构化知识时存在“幻觉”问题且难以实时更新。知识图谱虽然能存储结构化知识，但其静态性限制了动态交互和分析能力。因此，需要一种能够结合两者的优势，并克服其局限性的方法。

Method: 本研究利用LLM智能体与知识图谱（KG）的交互，构建了一个动态的、协同的分析生态系统。具体而言，该方法使用LLM智能体从非结构化数据中自动提取产品数据，并实时构建和可视化知识图谱。此外，通过一个交互平台，支持用户对图谱节点进行深度探索和分析。

Result: 实验结果表明，该方法在产品生态系统分析、关系挖掘以及用户驱动的探索性分析方面具有显著优势。

Conclusion: 本研究提出的LLM智能体与知识图谱交互的方法，为多维度数据分析提供了新的思路和工具，有效解决了传统方法在处理动态、复杂数据时的不足。

Abstract: In the current era of big data, extracting deep insights from massive,
heterogeneous, and complexly associated multi-dimensional data has become a
significant challenge. Large Language Models (LLMs) perform well in natural
language understanding and generation, but still suffer from "hallucination"
issues when processing structured knowledge and are difficult to update in
real-time. Although Knowledge Graphs (KGs) can explicitly store structured
knowledge, their static nature limits dynamic interaction and analytical
capabilities. Therefore, this paper proposes a multi-dimensional data analysis
method based on the interactions between LLM agents and KGs, constructing a
dynamic, collaborative analytical ecosystem. This method utilizes LLM agents to
automatically extract product data from unstructured data, constructs and
visualizes the KG in real-time, and supports users in deep exploration and
analysis of graph nodes through an interactive platform. Experimental results
show that this method has significant advantages in product ecosystem analysis,
relationship mining, and user-driven exploratory analysis, providing new ideas
and tools for multi-dimensional data analysis.

</details>


### [382] [Experience-Driven Exploration for Efficient API-Free AI Agents](https://arxiv.org/abs/2510.15259)
*Chenwei Tang,Jingyu Xing,Xinyu Liu,Zizhou Wang,Jiawei Du,Liangli Zhen,Jiancheng Lv*

Main category: cs.AI

TL;DR: 现有软件缺乏API，导致基于LLM的代理在像素级GUI操作中效率低下。为解决此问题，我们提出KG-Agent框架，将交互构建为状态-动作知识图谱（SA-KG），以克服探索效率低下和支持长远规划。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的代理在缺乏API的GUI环境中面临效率瓶颈，因其局限于局部视觉体验，决策短视且依赖低效的试错，阻碍了技能获取和长期规划。

Method: 提出KG-Agent框架，将代理的像素级交互构建成持久的状态-动作知识图谱（SA-KG），通过连接功能相似但视觉不同的GUI状态来克服探索效率低下，形成丰富的经验邻域，使代理能够从多样化的历史策略中进行泛化。设计了基于图拓扑的混合内在奖励机制，结合了用于利用已知高价值路径的状态值奖励和鼓励目标探索的新颖性奖励，实现了策略规划与纯粹探索的分离。

Result: 在Civilization V和Slay the Spire这两个复杂的、开放式的GUI决策环境中，KG-Agent相比最先进的方法在探索效率和策略深度方面展现出显著的改进。

Conclusion: KG-Agent通过构建状态-动作知识图谱和采用混合内在奖励机制，有效解决了LLM代理在API缺失的GUI环境中面临的效率和规划挑战。

Abstract: Most existing software lacks accessible Application Programming Interfaces
(APIs), requiring agents to operate solely through pixel-based Graphical User
Interfaces (GUIs). In this API-free setting, large language model (LLM)-based
agents face severe efficiency bottlenecks: limited to local visual experiences,
they make myopic decisions and rely on inefficient trial-and-error, hindering
both skill acquisition and long-term planning. To address these challenges, we
propose KG-Agent, an experience-driven learning framework that structures an
agent's raw pixel-level interactions into a persistent State-Action Knowledge
Graph (SA-KG). KG-Agent overcomes inefficient exploration by linking
functionally similar but visually distinct GUI states, forming a rich
neighborhood of experience that enables the agent to generalize from a diverse
set of historical strategies. To support long-horizon reasoning, we design a
hybrid intrinsic reward mechanism based on the graph topology, combining a
state value reward for exploiting known high-value pathways with a novelty
reward that encourages targeted exploration. This approach decouples strategic
planning from pure discovery, allowing the agent to effectively value setup
actions with delayed gratification. We evaluate KG-Agent in two complex,
open-ended GUI-based decision-making environments (Civilization V and Slay the
Spire), demonstrating significant improvements in exploration efficiency and
strategic depth over the state-of-the-art methods.

</details>


### [383] [AUGUSTUS: An LLM-Driven Multimodal Agent System with Contextualized User Memory](https://arxiv.org/abs/2510.15261)
*Jitesh Jain,Shubham Maheshwari,Ning Yu,Wen-mei Hwu,Humphrey Shi*

Main category: cs.AI

TL;DR: AUGUSTUS是一个多模态的代理系统，通过结合图像和文本信息，模仿人类记忆的存储和检索机制，在图像分类等任务上表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于检索增强生成的代理系统主要处理文本信息，忽略了多模态信号的重要性，而人类记忆具有多模态的特性。

Method: AUGUSTUS系统包含理解输入、存储信息、检索相关上下文和执行任务四个阶段，并将信息存储在图结构的多模态上下文记忆中，通过语义标签进行概念驱动的检索。

Result: 与传统的基于向量数据库的多模态检索增强生成方法相比，AUGUSTUS在ImageNet分类任务上速度提高了3.5倍，并在MSC基准测试中优于MemGPT。

Conclusion: AUGUSTUS通过利用图结构的多模态上下文记忆，实现了比传统多模态检索增强生成方法更有效的概念驱动检索，并在多个任务上取得了更好的性能。

Abstract: Riding on the success of LLMs with retrieval-augmented generation (RAG),
there has been a growing interest in augmenting agent systems with external
memory databases. However, the existing systems focus on storing text
information in their memory, ignoring the importance of multimodal signals.
Motivated by the multimodal nature of human memory, we present AUGUSTUS, a
multimodal agent system aligned with the ideas of human memory in cognitive
science. Technically, our system consists of 4 stages connected in a loop: (i)
encode: understanding the inputs; (ii) store in memory: saving important
information; (iii) retrieve: searching for relevant context from memory; and
(iv) act: perform the task. Unlike existing systems that use vector databases,
we propose conceptualizing information into semantic tags and associating the
tags with their context to store them in a graph-structured multimodal
contextual memory for efficient concept-driven retrieval. Our system
outperforms the traditional multimodal RAG approach while being 3.5 times
faster for ImageNet classification and outperforming MemGPT on the MSC
benchmark.

</details>


### [384] [WebGen-V Bench: Structured Representation for Enhancing Visual Design in LLM-based Web Generation and Evaluation](https://arxiv.org/abs/2510.15306)
*Kuang-Da Wang,Zhao Wang,Yotaro Shimose,Wei-Yao Wang,Shingo Takamatsu*

Main category: cs.AI

TL;DR: WebGen-V是一个用于指令到HTML生成的基准和框架，通过创新的代理爬行框架、结构化的数据表示和分节的多模态评估协议，提高了数据质量和评估粒度。


<details>
  <summary>Details</summary>
Motivation: 在利用LLM进行编码和多模态理解取得进展的背景下，需要一个能够提高数据质量和评估粒度的指令到HTML生成新基准和框架。

Method: WebGen-V包含一个代理爬行框架，用于收集真实网页数据；一个结构化的、分节的数据表示，整合了元数据、UI截图以及文本和图像资产的JSON格式；以及一个分节的多模态评估协议，用于评估文本、布局和视觉元素。

Result: 实验证明了结构化数据和分节评估的有效性，以及各个组件的贡献。WebGen-V是第一个能够实现高粒度代理爬行和评估的指令到HTML生成工作。

Conclusion: WebGen-V提供了一个从真实世界数据采集、网页生成到结构化多模态评估的统一流程，为指令到HTML生成领域提供了新的能力。

Abstract: Witnessed by the recent advancements on leveraging LLM for coding and
multimodal understanding, we present WebGen-V, a new benchmark and framework
for instruction-to-HTML generation that enhances both data quality and
evaluation granularity. WebGen-V contributes three key innovations: (1) an
unbounded and extensible agentic crawling framework that continuously collects
real-world webpages and can leveraged to augment existing benchmarks; (2) a
structured, section-wise data representation that integrates metadata,
localized UI screenshots, and JSON-formatted text and image assets, explicit
alignment between content, layout, and visual components for detailed
multimodal supervision; and (3) a section-level multimodal evaluation protocol
aligning text, layout, and visuals for high-granularity assessment. Experiments
with state-of-the-art LLMs and ablation studies validate the effectiveness of
our structured data and section-wise evaluation, as well as the contribution of
each component. To the best of our knowledge, WebGen-V is the first work to
enable high-granularity agentic crawling and evaluation for instruction-to-HTML
generation, providing a unified pipeline from real-world data acquisition and
webpage generation to structured multimodal assessment.

</details>


### [385] [VERITAS: Leveraging Vision Priors and Expert Fusion to Improve Multimodal Data](https://arxiv.org/abs/2510.15317)
*Tingqiao Xu,Ziru Zeng,Jiayu Chen*

Main category: cs.AI

TL;DR: VERITAS是一个用于提升大模型微调数据质量的流水线，它结合了视觉先验知识、多个大语言模型和统计方法，以解决现有数据增强方法中存在的视觉感知不足和事实错误问题。该流水线通过提取结构化视觉信息，并利用多个大语言模型对原始答案进行评估和打分，生成一个高置信度的共识分数作为真实标签。此外，还训练了一个轻量级的评论模型来优化推理能力，并由大语言模型根据评论来优化答案。实验结果表明，使用VERITAS处理过的数据进行微调的模型在多个基准测试中表现优于使用原始数据的模型，尤其在富文本和细粒度推理任务中效果更佳。VERITAS流水线、数据集和模型检查点已公开。


<details>
  <summary>Details</summary>
Motivation: 现有大模型微调（SFT）数据增强方法在视觉感知方面存在不足，容易产生事实错误和幻觉。VERITAS旨在通过整合视觉先验知识、多个大语言模型和统计方法来提升SFT数据的质量。

Method: VERITAS流水线首先利用视觉识别模型（RAM++）和OCR系统（PP-OCRv4）提取结构化视觉先验，然后结合图像、问题和答案。接着，使用三个大语言模型（GPT-4o, Gemini-2.5-Pro, Doubao-1.5-pro）评估原始答案，并生成批评和分数。通过统计融合这些信息，得到一个高置信度的共识分数作为真实标签。然后，利用Group Relative Policy Optimization（GRPO）训练一个轻量级评论模型，以高效提升推理能力。最后，大语言模型根据评论优化原始答案，并选择得分最高的作为最终优化答案。

Result: 在六个多模态基准测试中，使用VERITAS处理的数据微调的模型，其性能持续优于使用原始数据的模型。特别是在文本密集型和细粒度推理任务中，性能提升尤为显著。此外，VERITAS训练的评论模型在能力上可与最先进的大语言模型相媲美，但效率更高。

Conclusion: VERITAS流水线成功地提高了大语言模型微调数据的质量，并通过实验证明了其在提升模型性能方面的有效性，尤其是在处理复杂的多模态任务时。该研究为多模态数据优化领域做出了贡献，并提供了可复用的资源。

Abstract: The quality of supervised fine-tuning (SFT) data is crucial for the
performance of large multimodal models (LMMs), yet current data enhancement
methods often suffer from factual errors and hallucinations due to inadequate
visual perception. To address this challenge, we propose VERITAS, a pipeline
that systematically integrates vision priors and multiple state-of-the-art LMMs
with statistical methods to enhance SFT data quality. VERITAS leverages visual
recognition models (RAM++) and OCR systems (PP-OCRv4) to extract structured
vision priors, which are combined with images, questions, and answers. Three
LMMs (GPT-4o, Gemini-2.5-Pro, Doubao-1.5-pro) evaluate the original answers,
providing critique rationales and scores that are statistically fused into a
high-confidence consensus score serving as ground truth. Using this consensus,
we train a lightweight critic model via Group Relative Policy Optimization
(GRPO), enhancing reasoning capabilities efficiently. Each LMM then refines the
original answers based on the critiques, generating new candidate answers; we
select the highest-scoring one as the final refined answer. Experiments across
six multimodal benchmarks demonstrate that models fine-tuned with data
processed by VERITAS consistently outperform those using raw data, particularly
in text-rich and fine-grained reasoning tasks. Our critic model exhibits
enhanced capability comparable to state-of-the-art LMMs while being
significantly more efficient. We release our pipeline, datasets, and model
checkpoints to advance research in multimodal data optimization.

</details>


### [386] [Towards Flash Thinking via Decoupled Advantage Policy Optimization](https://arxiv.org/abs/2510.15374)
*Zezhong Tan,Hang Gao,Xinhong Ma,Feng Zhang,Ziqiang Dong*

Main category: cs.AI

TL;DR: DEPO框架通过解耦优势算法、难度感知长度惩罚和优势裁剪方法，有效减少了大型推理模型（LRMs）的冗余推理，降低了响应长度和计算消耗，同时提高了准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的大型推理模型（LRMs）在通过监督微调（SFT）和强化学习（RL）解决复杂问题时，尽管准确率较高，但仍存在响应过长和过度思考的问题，尤其在简单任务上增加了推理延迟和计算成本。DEPO框架旨在解决这个问题。

Method: DEPO框架包含三个核心组件：1. 创新的优势解耦算法，用于指导模型减少冗余令牌；2. 难度感知长度惩罚，用于降低模型响应的整体长度；3. 优势裁剪方法，用于防止策略优化中的偏差。

Result: 将DEPO框架应用于DeepSeek-Distill-Qwen-7B和DeepSeek-Distill-Qwen-1.5B模型，实现了39%的序列长度显著缩减，减少了冗余令牌中的过度推理，并且在整体准确性上优于基础模型。

Conclusion: DEPO框架能够有效减少大型推理模型的冗余推理，降低响应长度和计算成本，同时保持甚至提高模型在各种任务上的准确性。

Abstract: Recent Large Reasoning Models (LRMs) have achieved remarkable performance in
solving complex problems via supervised fine-tuning (SFT) and reinforcement
learning (RL). Although existing RL algorithms significantly enhance model
accuracy, they still suffer from excessively lengthy responses and overthinking
issues, resulting in increased inference latency and computational consumption,
especially for simple tasks that require minimal reasoning. To address this, we
propose a novel RL framework, DEPO, to reduce inefficient reasoning for models.
Our method mainly consists of three core components: (1) an innovative
advantage decoupled algorithm to guide model reduction of inefficient tokens;
(2) a difficulty-aware length penalty to lower the overall length of model
responses; (3) an advantage clipping method to prevent bias in policy
optimization. In our experiments, applied to DeepSeek-Distill-Qwen-7B and
DeepSeek-Distill-Qwen-1.5B as base models, DEPO achieves a significant
reduction in sequence length by 39% and reduces excessive reasoning paths in
inefficient tokens, while outperforming the base model in overall accuracy.

</details>


### [387] [Advancing Routing-Awareness in Analog ICs Floorplanning](https://arxiv.org/abs/2510.15387)
*Davide Basso,Luca Bortolussi,Mirjana Videnovic-Misic,Husni Habal*

Main category: cs.AI

TL;DR: 本研究提出了一种基于强化学习和图卷积神经网络的自动布局引擎，以解决模拟集成电路布局中的路由感知问题。


<details>
  <summary>Details</summary>
Motivation: 为了满足布局工程师对可路由性布局解决方案的需求，本文着重于解决模拟集成电路布局的挑战。

Method: 提出了一种结合强化学习和关系图卷积神经网络的自动布局引擎，通过增加网格分辨率、精确集成引脚信息和动态路由资源估计来优化布局。

Result: 与以往基于学习的技术相比，该方法在模拟环境中实现了13.8%的减少的无效空间，40.6%的减少的布线长度，以及73.4%的提高的布线成功率。

Conclusion: 所提出的方法有效地平衡了布线和面积效率，满足了工业标准，并显著优于现有的基于学习的技术。

Abstract: The adoption of machine learning-based techniques for analog integrated
circuit layout, unlike its digital counterpart, has been limited by the
stringent requirements imposed by electric and problem-specific constraints,
along with the interdependence of floorplanning and routing steps. In this
work, we address a prevalent concern among layout engineers regarding the need
for readily available routing-aware floorplanning solutions. To this extent, we
develop an automatic floorplanning engine based on reinforcement learning and
relational graph convolutional neural network specifically tailored to
condition the floorplan generation towards more routable outcomes. A
combination of increased grid resolution and precise pin information
integration, along with a dynamic routing resource estimation technique, allows
balancing routing and area efficiency, eventually meeting industrial standards.
When analyzing the place and route effectiveness in a simulated environment,
the proposed approach achieves a 13.8% reduction in dead space, a 40.6%
reduction in wirelength and a 73.4% increase in routing success when compared
to past learning-based state-of-the-art techniques.

</details>


### [388] [Corrigibility Transformation: Constructing Goals That Accept Updates](https://arxiv.org/abs/2510.15395)
*Rubi Hudson*

Main category: cs.AI

TL;DR: AI 训练中的目标需要可修正性，以防止 AI 抵制训练。本文提出了一种构造可修正目标的方法，该方法通过预测成本最小化来预测奖励，并已在实验中得到验证。


<details>
  <summary>Details</summary>
Motivation: AI 训练过程中，AI 可能会为了达成已部分学到的目标而抵制进一步的训练更新，这使得 AI 的目标难以被修正。因此，需要 AI 目标具备可修正性，以确保 AI 能够接受正确的训练，并允许在出现错误或人类偏好发生变化时进行修正。

Method: 本文提出了一种将任何可修正目标转化为可修正版本的方法。该方法通过对成本最小化下的奖励进行预测来评估目标，并以此来确定接受更新时的奖励。此外，该方法还可以递归地将可修正性扩展到由可修正代理创建的新代理，并防止代理故意修改其目标。

Result: 通过在两个 Gridworld 实验中进行测试，证明了所提出的可修正目标不仅可以被有效地学习，而且能够引导 AI 产生期望的行为。

Conclusion: 可修正性是 AI 安全的关键属性。本文提出的目标构造方法能够生成既可修正又具有竞争力的目标，解决了现有文献中的不足，并已在实验中得到验证。

Abstract: For an AI's training process to successfully impart a desired goal, it is
important that the AI does not attempt to resist the training. However,
partially learned goals will often incentivize an AI to avoid further goal
updates, as most goals are better achieved by an AI continuing to pursue them.
We say that a goal is corrigible if it does not incentivize taking actions that
avoid proper goal updates or shutdown. In addition to convergence in training,
corrigibility also allows for correcting mistakes and changes in human
preferences, which makes it a crucial safety property. Despite this, the
existing literature does not include specifications for goals that are both
corrigible and competitive with non-corrigible alternatives. We provide a
formal definition for corrigibility, then introduce a transformation that
constructs a corrigible version of any goal that can be made corrigible,
without sacrificing performance. This is done by myopically eliciting
predictions of reward conditional on costlessly preventing updates, which then
also determine the reward when updates are accepted. The transformation can be
modified to recursively extend corrigibility to any new agents created by
corrigible agents, and to prevent agents from deliberately modifying their
goals. Two gridworld experiments demonstrate that these corrigible goals can be
learned effectively, and that they lead to the desired behavior.

</details>


### [389] [MARS: Reinforcing Multi-Agent Reasoning of LLMs through Self-Play in Strategic Games](https://arxiv.org/abs/2510.15414)
*Huining Yuan,Zelai Xu,Zheyue Tan,Xiangmin Yi,Mo Guang,Kaiwen Long,Haojia Hui,Boxun Li,Xinlei Chen,Bo Zhao,Xiao-Ping Zhang,Chao Yu,Yu Wang*

Main category: cs.AI

TL;DR: 本研究提出了MARS框架，通过自玩（self-play）强化学习（RL）来提升大型语言模型（LLMs）在多智能体系统中的合作与竞争能力，解决了传统RL在多回合、多智能体场景下的信用分配和优势估计难题。


<details>
  <summary>Details</summary>
Motivation: 在多智能体系统中，为了实现更高级的智能，需要让大型语言模型（LLMs）有效地进行合作与竞争。然而，将强化学习（RL）应用于多回合、多智能体场景面临长期信用分配和特定智能体优势估计的挑战。

Method: MARS框架通过端到端的RL，利用自玩（self-play）机制在合作与竞争游戏中激励LLMs进行多智能体推理。该框架包含一个回合级优势估计器，用于解决信用分配问题，并采用特定智能体优势归一化来稳定训练过程。

Result: 通过在合作与竞争游戏中进行自玩训练，MARS框架显著提升了Qwen3-4B模型的能力，在测试游戏中表现提高了27.8%。更重要的是，通过自玩获得的能力可以泛化到游戏之外的推理任务，在AIME和GPQA-Diamond等基准测试中分别带来了10.0%和12.5%的性能提升。

Conclusion: 研究表明，通过在战略游戏中进行端到端的RL自玩训练，是开发LLMs通用多智能体推理能力的一种有效方法。

Abstract: Developing Large Language Models (LLMs) to cooperate and compete effectively
within multi-agent systems is a critical step towards more advanced
intelligence. While reinforcement learning (RL) has proven effective for
enhancing reasoning in single-agent tasks, its extension to multi-turn,
multi-agent scenarios remains underexplored due to the challenges of
long-horizon credit assignment and agent-specific advantage estimation. To
address these challenges, we introduce MARS, an end-to-end RL framework that
incentivizes Multi-Agent Reasoning of LLMs through Self-play in both
cooperative and competitive games. MARS features a turn-level advantage
estimator that aligns learning signals with each interaction for credit
assignment, and an agent-specific advantage normalization to stabilize
multi-agent training. By learning with self-play across cooperative and
competitive games, the MARS agent trained from Qwen3-4B develops strong
strategic abilities that generalize to held-out games with up to 28.7%
performance improvements. More importantly, the capability acquired through
self-play generalizes beyond games, yielding consistent performance gains of
multi-agent systems in reasoning benchmarks. When integrated into leading
multi-agent systems, our MARS agent achieves significant performance gains of
10.0% on AIME and 12.5% on GPQA-Diamond. These results establish end-to-end RL
training with self-play in strategic games as a powerful approach for
developing generalizable multi-agent reasoning capabilities in LLMs. Our code
and models are publicly available at https://github.com/thu-nics/MARS.

</details>


### [390] [Adaptive Minds: Empowering Agents with LoRA-as-Tools](https://arxiv.org/abs/2510.15416)
*Pavan C Shekar,Ashwanth Krishnan*

Main category: cs.AI

TL;DR: Adaptive Minds是一个创新的代理系统，通过让基础大语言模型动态选择LoRA适配器作为领域专家工具，实现了高效的领域适应性。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是开发一种能够根据用户查询灵活切换不同领域专业知识的AI系统，以克服单一模型或固定路由方法的局限性。

Method: Adaptive Minds利用基础大语言模型作为语义路由器，分析每个查询并动态选择最相关的LoRA（Low-Rank Adaptation）适配器（工具）。该系统使用LangGraph进行工作流管理，并支持API和Web接口。

Result: 该系统能够根据查询无缝切换不同的领域专家，提供准确、专业的回复，同时保持对话能力。它结合了多智能体编排的灵活性和参数高效微调的效率。

Conclusion: Adaptive Minds提供了一个可扩展且可扩展的、面向领域的自适应AI助手的基础。

Abstract: We present Adaptive Minds, an agentic system that treats LoRA adapters as
domain-specific tools. Instead of relying on a single fine-tuned model or rigid
rule-based routing, our approach empowers the base LLM itself to act as a
semantic router analyzing each query and dynamically selecting the most
relevant LoRA tool. This enables the agent to seamlessly switch between
different domain experts on demand. By combining the flexibility of multi-agent
orchestration with the efficiency of parameter-efficient fine-tuning, Adaptive
Minds delivers accurate, specialized responses while preserving conversational
ability. The system is built with LangGraph for workflow management, supports
both API and web interfaces, and is fully open source, providing a scalable and
extensible foundation for domain-adaptive AI assistance.

</details>


### [391] [Taming the Judge: Deconflicting AI Feedback for Stable Reinforcement Learning](https://arxiv.org/abs/2510.15514)
*Boyin Liu,Zhuo Zhang,Sen Huang,Lipeng Xie,Qingxu Fu,Haoran Chen,LI YU,Tianyi Hu,Zhaoyang Liu,Bolin Ding,Dongbin Zhao*

Main category: cs.AI

TL;DR: 本框架通过引入冲突检测率(CDR)和去冲突图奖励(DGR)来解决强化学习中因判断不一致（如偏好循环）导致的不稳定问题，并通过实验证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在强化学习中常面临判断不一致性问题，可能导致训练不稳定。先前的研究主要关注判断的准确性，而忽略了逻辑一致性（特别是偏好循环）这一关键问题。

Method: 本框架包含两个主要部分：1. 冲突检测率（CDR），一个量化判断冲突的新指标。2. 去冲突图奖励（DGR），一个在策略优化前通过移除循环来净化信号的框架。DGR 从初始判断构建偏好图，将其转换为无冲突的有向无环图（DAG），并生成一个与任何策略优化器兼容的、逻辑上一致的奖励信号。

Result: 实验结果表明，与强大的基线相比，本框架显著提高了训练稳定性和模型性能。

Conclusion: 本框架的引入确立了逻辑一致性作为人工智能反馈中一个关键且可管理的新维度。

Abstract: However, this method often faces judgment inconsistencies that can
destabilize reinforcement learning. While prior research has focused on the
accuracy of judgments, the critical issue of logical coherence especially
issues such as preference cycles hasn't been fully addressed. To fill this gap,
we introduce a comprehensive framework designed to systematically detect and
resolve these inconsistencies during the reinforcement learning training
process. Our framework includes two main contributions: first, the Conflict
Detection Rate (CDR), a new metric that quantifies judgment conflicts, and
second, Deconflicted Graph Rewards (DGR), a framework that purifies signals by
removing cycles before policy optimization. DGR constructs preference graphs
from the initial judgments, transforms them into conflict-free Directed Acyclic
Graphs (DAGs), and generates a logically coherent reward signal that is
compatible with any policy optimizer. Experimental results show that our
framework significantly enhances training stability and model performance
compared to strong baselines, establishing logical consistency as a crucial and
now manageable dimension of AI feedback.

</details>


### [392] [JudgeSQL: Reasoning over SQL Candidates with Weighted Consensus Tournament](https://arxiv.org/abs/2510.15560)
*Jiayuan Bai,Xuan-guang Pan,Chongyang Tao,Shuai Ma*

Main category: cs.AI

TL;DR: JudgeSQL是一个通过结构化推理和加权共识锦标赛来改进Text-to-SQL查询选择的框架，它使用基于推理的SQL裁判模型和可验证奖励来提高准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的Text-to-SQL查询选择方法（如self-consistency或best-of-N解码）信号浅层，容易出现评分不一致、推理链脆弱以及无法捕捉细微语义差别的问题。

Method: JudgeSQL引入了一个基于推理的SQL裁判模型，该模型利用强化学习和可验证奖励来提炼推理过程，并结合一个加权共识锦标赛机制，整合了显式推理偏好和隐式生成器置信度。

Result: 在BIRD基准测试上的大量实验表明，JudgeSQL在SQL判断能力、跨尺度泛化能力以及对生成器容量的鲁棒性方面均表现优异。

Conclusion: JudgeSQL通过结构化推理和加权共识锦标赛，为Text-to-SQL候选查询选择提供了一个更准确、可解释且鲁棒的解决方案。

Abstract: Text-to-SQL is a pivotal task that bridges natural language understanding and
structured data access, yet it remains fundamentally challenging due to
semantic ambiguity and complex compositional reasoning. While large language
models (LLMs) have greatly advanced SQL generation though prompting, supervised
finetuning and reinforced tuning, the shift toward test-time scaling exposes a
new bottleneck: selecting the correct query from a diverse candidate pool.
Existing selection approaches, such as self-consistency or best-of-$N$
decoding, provide only shallow signals, making them prone to inconsistent
scoring, fragile reasoning chains, and a failure to capture fine-grained
semantic distinctions between closely related SQL candidates. To this end, we
introduce JudgeSQL, a principled framework that redefines SQL candidate
selection through structured reasoning and weighted consensus tournament
mechanism. JudgeSQL develops a reasoning-based SQL judge model that distills
reasoning traces with reinforcement learning guided by verifiable rewards,
enabling accurate and interpretable judgments. Building on this, a weighted
consensus tournament integrates explicit reasoning preferences with implicit
generator confidence, yielding selections that are both more reliable and more
efficient. Extensive experiments on the BIRD benchmark demonstrate that
JudgeSQL exhibits superior SQL judgment capabilities and good cross-scale
generalization and robustness to generator capacity.

</details>


### [393] [Context-aware deep learning using individualized prior information reduces false positives in disease risk prediction and longitudinal health assessment](https://arxiv.org/abs/2510.15591)
*Lavanya Umapathy,Patricia M Johnson,Tarun Dutt,Angela Tong,Madhur Nayan,Hersh Chandarana,Daniel K Sodickson*

Main category: cs.AI

TL;DR: 通过整合患者随访数据，改进了前列腺癌风险预测模型，提高了特异性并降低了误诊率。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有模型在患者就诊次数有限且频率不确定时，对患者健康状况进行评估的不足，本文旨在开发一种能够整合以往就诊信息的机器学习框架，以改进健康监测。

Method: 提出了一种机器学习框架，首先使用最近一次就诊的医学数据估计初始疾病风险，然后整合以往的影像和/或临床生物标志物信息来优化风险评估。该框架应用于前列腺癌风险预测，使用了近十年的大规模人口数据。

Result: 在预测就诊时临床上显著的前列腺癌风险方面，整合以往就诊信息将假阳性转化为真阳性，提高了整体特异性，同时保持了高敏感性。与仅使用单次就诊数据相比，整合最多三次以往影像学检查信息可将假阳性率从51%逐步降低到33%，结合以往临床数据后进一步降低到24%。预测就诊五年内发生前列腺癌的风险时，整合以往信息可将假阳性率从64%降低到9%。

Conclusion: 时间序列数据能有效提高医学风险预测的特异性。通过减少假阳性，该方法有望将纵向健康监测项目扩展到基线风险较低的大规模人群，从而实现早期检测和改善健康结果。

Abstract: Temporal context in medicine is valuable in assessing key changes in patient
health over time. We developed a machine learning framework to integrate
diverse context from prior visits to improve health monitoring, especially when
prior visits are limited and their frequency is variable. Our model first
estimates initial risk of disease using medical data from the most recent
patient visit, then refines this assessment using information digested from
previously collected imaging and/or clinical biomarkers. We applied our
framework to prostate cancer (PCa) risk prediction using data from a large
population (28,342 patients, 39,013 magnetic resonance imaging scans, 68,931
blood tests) collected over nearly a decade. For predictions of the risk of
clinically significant PCa at the time of the visit, integrating prior context
directly converted false positives to true negatives, increasing overall
specificity while preserving high sensitivity. False positive rates were
reduced progressively from 51% to 33% when integrating information from up to
three prior imaging examinations, as compared to using data from a single
visit, and were further reduced to 24% when also including additional context
from prior clinical data. For predicting the risk of PCa within five years of
the visit, incorporating prior context reduced false positive rates still
further (64% to 9%). Our findings show that information collected over time
provides relevant context to enhance the specificity of medical risk
prediction. For a wide range of progressive conditions, sufficient reduction of
false positive rates using context could offer a pathway to expand longitudinal
health monitoring programs to large populations with comparatively low baseline
risk of disease, leading to earlier detection and improved health outcomes.

</details>


### [394] [Unleashing Scientific Reasoning for Bio-experimental Protocol Generation via Structured Component-based Reward Mechanism](https://arxiv.org/abs/2510.15600)
*Haoran Sun,Yankai Jiang,Zhenyu Tang,Yaning Pan,Shuang Gu,Zekai Lin,Lilong Wang,Wenjie Lou,Lei Liu,Lei Bai,Xiaosong Wang*

Main category: cs.AI

TL;DR: 通过引入SciRecipe数据集和“Sketch-and-Fill”范式，并结合结构化组件奖励机制，我们提出了Thoth模型，显著提高了LLM生成科学实验方案的准确性和可执行性。


<details>
  <summary>Details</summary>
Motivation: 当前的LLM在生成科学实验方案时存在不完整或不一致的问题，限制了其在科学研究中的应用。

Method: 我们提出了“Sketch-and-Fill”范式，将实验方案的生成分解为分析、结构化和表达三个独立但可验证的步骤。此外，我们设计了结构化组件奖励机制来评估方案的粒度、动作顺序和语义准确性。我们还构建了一个名为SciRecipe的大型数据集，包含超过12000个结构化实验方案。最后，我们开发并训练了Thoth模型，采用知识到行动的阶段性训练过程。

Result: Thoth模型在多个基准测试中，在步骤对齐、逻辑排序和语义准确性方面均显著优于现有的专有和开源LLM。

Conclusion: 我们提出的方法能够生成可靠的、可执行的科学实验方案，为实现能够连接知识与实验操作的科学助手铺平了道路。

Abstract: The foundation of reproducible science lies in protocols that are precise,
logically ordered, and executable. The autonomous generation of these protocols
through natural language queries could greatly improve the efficiency of the
reproduction process. However, current leading large language models (LLMs)
often generate incomplete or inconsistent protocols, limiting their utility. To
address this limitation, we first introduce SciRecipe, a large-scale dataset of
over 12K structured protocols spanning 27 biological subfields and encompassing
both comprehension and problem-solving tasks. To further improve protocol
generation, we propose the "Sketch-and-Fill" paradigm, which separates
analysis, structuring, and expression to ensure each step is explicit and
verifiable. Complementing this, the structured component-based reward mechanism
evaluates step granularity, action order, and semantic fidelity, aligning model
optimization with experimental reliability. Building on these components, we
develop Thoth, trained through a staged Knowledge-to-Action process that
progresses from knowledge acquisition to operational reasoning and ultimately
to robust, executable protocol generation. Across multiple benchmarks, Thoth
consistently surpasses both proprietary and open-source LLMs, achieving
significant improvements in step alignment, logical sequencing, and semantic
accuracy. Our approach paves the way for reliable scientific assistants that
bridge knowledge with experimental execution. All data, code, and models will
be released publicly.

</details>


### [395] [Direct Preference Optimization with Unobserved Preference Heterogeneity: The Necessity of Ternary Preferences](https://arxiv.org/abs/2510.15716)
*Keertana Chidambaram,Karthik Vinary Seetharaman,Vasilis Syrgkanis*

Main category: cs.AI

TL;DR: RLHF和DPO方法在对齐大型语言模型时忽略了人类评估者偏好的多样性和二元比较的局限性。本研究提出一种结合计量经济学的方法，使用多项排序而非二元比较来识别潜在用户偏好。此外，研究开发了一种期望最大化算法，用于发现潜在的评估者类型并训练相应的LLM混合模型，并提出了一种使用最小-最大遗憾公平性标准的聚合算法，以生成具有公平性能保证的单一生成策略。


<details>
  <summary>Details</summary>
Motivation: 现有的RLHF和DPO方法在对齐大型语言模型时，通常假设评估者偏好是统一的，并且依赖于二元比较，这忽略了人类评估者偏好的多样性和成对反馈的局限性。

Method: 1. 将RLHF中的偏好学习与计量经济学文献联系起来，证明了多项排序（三个或更多响应的排名）能够确保从有限的用户数据和无限的用户中识别潜在用户偏好，而二元比较则不足以实现这一点。 2. 引入了将异构偏好纳入对齐算法的方法。开发了一种DPO的期望最大化（EM）方法，用于发现潜在的评估者类型并相应地训练LLM的混合模型。 3. 提出了一种使用最小-最大遗憾公平性标准的聚合算法，以生成具有公平性能保证的单一生成策略。

Result: 研究提出了一个理论和算法框架，能够实现生成模型对齐的公平性和个性化，以适应多样化的用户群体。

Conclusion: 本研究通过引入多项排序和考虑异构偏好，解决了RLHF和DPO在处理多样化评估者和成对反馈局限性方面的问题，为生成模型对齐的公平性和个性化提供了新的理论和算法基础。

Abstract: Reinforcement Learning from Human Feedback (RLHF) has become central to
aligning large language models with human values, typically by first learning a
reward model from preference data which is then used to update the model with
reinforcement learning. Recent alternatives such as Direct Preference
Optimization (DPO) simplify this pipeline by directly optimizing on
preferences. However, both approaches often assume uniform annotator
preferences and rely on binary comparisons, overlooking two key limitations:
the diversity of human evaluators and the limitations of pairwise feedback. In
this work, we address both these issues. First, we connect preference learning
in RLHF with the econometrics literature and show that binary comparisons are
insufficient for identifying latent user preferences from finite user data and
infinite users, while (even incomplete) rankings over three or more responses
ensure identifiability. Second, we introduce methods to incorporate
heterogeneous preferences into alignment algorithms. We develop an
Expectation-Maximization adaptation of DPO that discovers latent annotator
types and trains a mixture of LLMs accordingly. Then we propose an aggregation
algorithm using a min-max regret fairness criterion to produce a single
generative policy with equitable performance guarantees. Together, these
contributions establish a theoretical and algorithmic framework for fairness
and personalization for diverse users in generative model alignment.

</details>


### [396] [Invoice Information Extraction: Methods and Performance Evaluation](https://arxiv.org/abs/2510.15727)
*Sai Yashwant,Anurag Dubey,Praneeth Paikray,Gantala Thulsiram*

Main category: cs.AI

TL;DR: 该论文提出使用Docling和LlamaCloud Services从发票文档中提取结构化信息，并建立了一套评估指标（EM）来衡量提取数据的准确性。


<details>
  <summary>Details</summary>
Motivation: 评估和改进从发票文档中提取结构化信息的方法，并提出一套标准的评估指标。

Method: 预处理扫描或数字发票，利用Docling和LlamaCloud Services识别和提取关键字段（如发票号、日期、总金额、供应商信息），并建立包含字段级精度、一致性检查失败率和精确匹配准确率的评估框架。

Result: 提出了一套评估指标，用于衡量发票信息提取的准确性，并能展示不同提取方法的优劣。

Conclusion: 建立的评估框架为比较不同的发票信息提取方法提供了一种标准化的方式，并能突出各字段的具体表现。

Abstract: This paper presents methods for extracting structured information from
invoice documents and proposes a set of evaluation metrics (EM) to assess the
accuracy of the extracted data against annotated ground truth. The approach
involves pre-processing scanned or digital invoices, applying Docling and
LlamaCloud Services to identify and extract key fields such as invoice number,
date, total amount, and vendor details. To ensure the reliability of the
extraction process, we establish a robust evaluation framework comprising
field-level precision, consistency check failures, and exact match accuracy.
The proposed metrics provide a standardized way to compare different extraction
methods and highlight strengths and weaknesses in field-specific performance.

</details>


### [397] [Towards Relaxed Multimodal Inputs for Gait-based Parkinson's Disease Assessment](https://arxiv.org/abs/2510.15748)
*Minlin Zeng,Zhipeng Zhou,Yang Qiu,Zhiqi Shen*

Main category: cs.AI

TL;DR: 提出了一种基于多目标优化（MOO）的帕金森病评估系统（TRIP），解决了多模态数据同步和推理依赖问题，并取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有帕金森病评估方法在多模态数据同步和推理依赖方面存在局限性，阻碍了实际应用。

Method: 将多模态学习构建为多目标优化（MOO）问题，并引入基于边界的类别再平衡策略来处理类别不平衡问题。

Result: 在三个公开数据集上进行了广泛的实验，与现有方法相比，在异步和同步设置下均取得了显著的性能提升，尤其是在异步设置下。

Conclusion: TRIP系统在帕金森病评估方面表现出卓越的有效性和适应性，克服了现有方法的局限性。

Abstract: Parkinson's disease assessment has garnered growing interest in recent years,
particularly with the advent of sensor data and machine learning techniques.
Among these, multimodal approaches have demonstrated strong performance by
effectively integrating complementary information from various data sources.
However, two major limitations hinder their practical application: (1) the need
to synchronize all modalities during training, and (2) the dependence on all
modalities during inference. To address these issues, we propose the first
Parkinson's assessment system that formulates multimodal learning as a
multi-objective optimization (MOO) problem. This not only allows for more
flexible modality requirements during both training and inference, but also
handles modality collapse issue during multimodal information fusion. In
addition, to mitigate the imbalance within individual modalities, we introduce
a margin-based class rebalancing strategy to enhance category learning. We
conduct extensive experiments on three public datasets under both synchronous
and asynchronous settings. The results show that our framework-Towards Relaxed
InPuts (TRIP)-achieves state-of-the-art performance, outperforming the best
baselines by 16.48, 6.89, and 11.55 percentage points in the asynchronous
setting, and by 4.86 and 2.30 percentage points in the synchronous setting,
highlighting its effectiveness and adaptability.

</details>


### [398] [Preliminary Quantitative Study on Explainability and Trust in AI Systems](https://arxiv.org/abs/2510.15769)
*Allen Daniel Sunny*

Main category: cs.AI

TL;DR: 本研究通过实验探究了解释性与用户信任AI的关系，发现交互性解释能提高用户参与度和信任度，解释的清晰度和相关性是信任的关键。


<details>
  <summary>Details</summary>
Motivation: 大型AI模型（如GPT-4）在法律、医疗和金融等关键领域的广泛应用引发了对信任和透明度的紧迫问题，因此本研究旨在调查可解释性与用户对AI系统的信任之间的关系。

Method: 本研究采用定量实验设计，利用交互式、基于网络的贷款审批模拟，比较了不同类型的解释（从基本特征重要性到交互式反事实解释）对感知信任的影响。

Result: 结果表明，交互性增强了用户的参与度和信心，而解释的清晰度和相关性是信任的关键决定因素。

Conclusion: 本研究通过实证证据为日益增长的人类中心可解释AI领域做出了贡献，强调了可解释性设计对用户感知的可衡量影响。

Abstract: Large-scale AI models such as GPT-4 have accelerated the deployment of
artificial intelligence across critical domains including law, healthcare, and
finance, raising urgent questions about trust and transparency. This study
investigates the relationship between explainability and user trust in AI
systems through a quantitative experimental design. Using an interactive,
web-based loan approval simulation, we compare how different types of
explanations, ranging from basic feature importance to interactive
counterfactuals influence perceived trust. Results suggest that interactivity
enhances both user engagement and confidence, and that the clarity and
relevance of explanations are key determinants of trust. These findings
contribute empirical evidence to the growing field of human-centered
explainable AI, highlighting measurable effects of explainability design on
user perception

</details>


### [399] [Self-evolving expertise in complex non-verifiable subject domains: dialogue as implicit meta-RL](https://arxiv.org/abs/2510.15772)
*Richard M. Bailey*

Main category: cs.AI

TL;DR: 利用Dialectica框架，通过结构化对话、记忆、自我反思和策略约束的上下文编辑，增强大型语言模型处理复杂问题的能力，并在评估中显示出显著的学习和能力提升。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM在处理‘顽固问题’（wicked problems）时缺乏通过经验发展专业知识的内生机制，尽管可以通过微调、系统提示和外部工具进行改进。

Method: 提出Dialectica框架，让代理商进行结构化对话，并辅以记忆、自我反思和策略约束的上下文编辑。将对话视为一种隐式的元强化学习过程。

Result: 在两种模型架构（Qwen3:30b和OpenAI的o4-mini）上进行评估，使用Elo分数、归一化的Bradley-Terry-Davidson能力和AlphaRank质量进行比较。结果表明，启用基于反思的上下文编辑的代理商显著优于基线对照组。

Conclusion: Dialectica框架通过对话驱动的上下文演变，为在开放的、不可验证的领域中进行有针对性的专业知识放大提供了一条实用的途径。定性和定量证据都支持这一结论。

Abstract: So-called `wicked problems', those involving complex multi-dimensional
settings, non-verifiable outcomes, heterogeneous impacts and a lack of single
objectively correct answers, have plagued humans throughout history. Modern
examples include decisions over justice frameworks, solving environmental
pollution, planning for pandemic resilience and food security. The use of
state-of-the-art artificial intelligence systems (notably Large Language
Model-based agents) collaborating with humans on solving such problems is being
actively explored. While the abilities of LLMs can be improved by, for example,
fine-tuning, hand-crafted system prompts and scaffolding with external tools,
LLMs lack endogenous mechanisms to develop expertise through experience in such
settings. This work address this gap with Dialectica, a framework where agents
engage in structured dialogue on defined topics, augmented by memory,
self-reflection, and policy-constrained context editing. Formally, discussion
is viewed as an implicit meta-reinforcement learning process. The
`dialogue-trained' agents are evaluated post-hoc using judged pairwise
comparisons of elicited responses. Across two model architectures (locally run
Qwen3:30b and OpenAI's o4-mini) results show that enabling reflection-based
context editing during discussion produces agents which dominate their baseline
counterparts on Elo scores, normalized Bradley-Terry-Davidson ability, and
AlphaRank mass. The predicted signatures of learning are observed qualitatively
in statement and reflection logs, where reflections identify weaknesses and
reliably shape subsequent statements. Agreement between quantitative and
qualitative evidence supports dialogue-driven context evolution as a practical
path to targeted expertise amplification in open non-verifiable domains.

</details>


### [400] [Demo: Guide-RAG: Evidence-Driven Corpus Curation for Retrieval-Augmented Generation in Long COVID](https://arxiv.org/abs/2510.15782)
*Philip DiGiacomo,Haoyang Wang,Jinrui Fang,Yan Leng,W Michael Brode,Ying Ding*

Main category: cs.AI

TL;DR: 为长新冠（LC）临床问答开发了六种检索增强生成（RAG）语料库配置，并使用LLM-as-a-judge框架进行评估。结合临床指南和高质量系统评价的RAG配置效果最佳，表明针对新兴疾病，以精选的次级评价为基础的检索是最佳选择。


<details>
  <summary>Details</summary>
Motivation: AI聊天机器人在临床医学中的应用日益广泛，但针对复杂、新兴疾病的有效框架开发仍面临挑战。

Method: 开发并评估了六种针对长新冠（LC）临床问答的检索增强生成（RAG）语料库配置，从专家策源的资料到大规模文献数据库。使用LLM-as-a-judge框架，结合忠实度、相关性和全面性指标，以及新创建的专家生成的长新冠临床问题数据集（LongCOVID-CQ）进行评估。

Result: 结合临床指南和高质量系统评价的RAG语料库配置，在忠实度、相关性和全面性方面均优于单一指南方法和大规模文献数据库。具体来说，这种配置在处理长新冠临床问题时，在信息全面性和准确性之间取得了最佳平衡。

Conclusion: 对于新兴疾病，以精心挑选的次级评价为基础的检索，是在狭窄的共识文件和未经筛选的原始文献之间取得最佳平衡的方法，能够支持临床决策，同时避免信息过载和过于简化的指导。我们提出了Guide-RAG，一个结合了专家知识和全面文献数据库的聊天机器人系统及其评估框架，以有效回答长新冠的临床问题。

Abstract: As AI chatbots gain adoption in clinical medicine, developing effective
frameworks for complex, emerging diseases presents significant challenges. We
developed and evaluated six Retrieval-Augmented Generation (RAG) corpus
configurations for Long COVID (LC) clinical question answering, ranging from
expert-curated sources to large-scale literature databases. Our evaluation
employed an LLM-as-a-judge framework across faithfulness, relevance, and
comprehensiveness metrics using LongCOVID-CQ, a novel dataset of
expert-generated clinical questions. Our RAG corpus configuration combining
clinical guidelines with high-quality systematic reviews consistently
outperformed both narrow single-guideline approaches and large-scale literature
databases. Our findings suggest that for emerging diseases, retrieval grounded
in curated secondary reviews provides an optimal balance between narrow
consensus documents and unfiltered primary literature, supporting clinical
decision-making while avoiding information overload and oversimplified
guidance. We propose Guide-RAG, a chatbot system and accompanying evaluation
framework that integrates both curated expert knowledge and comprehensive
literature databases to effectively answer LC clinical questions.

</details>


### [401] [PokeeResearch: Effective Deep Research via Reinforcement Learning from AI Feedback and Robust Reasoning Scaffold](https://arxiv.org/abs/2510.15862)
*Yi Wan,Jiuqi Wang,Liam Li,Jinsong Liu,Ruihao Zhu,Zheqing Zhu*

Main category: cs.AI

TL;DR: PokeeResearch-7B是一个70亿参数的深度研究智能体，通过单一的强化学习框架进行训练，旨在提高鲁棒性、对齐性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 当前的智能体在检索、对齐指标和工具使用方面存在局限性。PokeeResearch-7B旨在通过统一的强化学习框架克服这些限制。

Method: PokeeResearch-7B采用无需标注的AI反馈强化学习（RLAIF）框架进行训练，并结合了链式思考驱动的多调用推理脚手架，以实现自我验证和对工具失败的适应性恢复。

Result: 在10个深度研究基准测试中，PokeeResearch-7B在70亿参数的智能体中取得了最先进的性能。

Conclusion: 精心设计的强化学习和推理方法可以创造出高效、有弹性且达到研究级别的人工智能智能体。

Abstract: Tool-augmented large language models (LLMs) are emerging as deep research
agents, systems that decompose complex queries, retrieve external evidence, and
synthesize grounded responses. Yet current agents remain limited by shallow
retrieval, weak alignment metrics, and brittle tool-use behavior. We introduce
PokeeResearch-7B, a 7B-parameter deep research agent built under a unified
reinforcement learning framework for robustness, alignment, and scalability.
PokeeResearch-7B is trained by an annotation-free Reinforcement Learning from
AI Feedback (RLAIF) framework to optimize policies using LLM-based reward
signals that capture factual accuracy, citation faithfulness, and instruction
adherence. A chain-of-thought-driven multi-call reasoning scaffold further
enhances robustness through self-verification and adaptive recovery from tool
failures. Among 10 popular deep research benchmarks, PokeeResearch-7B achieves
state-of-the-art performance among 7B-scale deep research agents. This
highlights that careful reinforcement learning and reasoning design can produce
efficient, resilient, and research-grade AI agents. The model and inference
code is open-sourced under MIT license at
https://github.com/Pokee-AI/PokeeResearchOSS.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [402] [Revoke vs. Restart in Unweighted Throughput Scheduling](https://arxiv.org/abs/2510.15318)
*Changdao He*

Main category: cs.DS

TL;DR: 在线算法在单机预占-撤销模型下的吞吐量调度问题上，无法获得常数竞争比。


<details>
  <summary>Details</summary>
Motivation: 研究单机预占-撤销模型下的加权吞吐量调度问题，其中运行中的作业可能随时被中止，但所有进度都会永久丢失且无法重新启动。

Method: 通过一个三作业实例的对抗性构造，其中 	extsf{ALG} 最多完成一个作业，而 	extsf{OPT} 完成所有三个作业，然后通过归纳法迭代嵌套此构造，为任意 k>=3 的情况证明了 	extsf{ALG} 最多能完成一个作业，而 	extsf{OPT} 至少能完成 k 个作业。

Result: 竞争比可以被强制为 1/k，并且可以任意接近于零。我们证明了没有确定性在线算法能够获得常数竞争比。

Conclusion: 在预占-撤销模型下，确定性在线算法的竞争比可以任意接近于零，这与预占-重启动模型（其中存在 1/2-竞争算法）形成鲜明对比。

Abstract: We study the unweighted throughput scheduling problem on a single machine in
the preemption-revoke model, where a running job may be aborted at any time,
but all progress is permanently lost and the job cannot be restarted. Each job
$J_i=(r_i,p_i,s_i)$ is defined by a release time $r_i$, a processing time
$p_i$, and a slack $s_i$, and must start no later than $r_i+s_i$ to be
feasible. We prove that no deterministic online algorithm can achieve a
constant competitive ratio. The lower bound is established via an adversarial
construction: starting from a three-job instance where $\textsf{ALG}$ completes
at most one job while $\textsf{OPT}$ completes all three, we iteratively nest
such constructions. By induction, for every $k\ge 3$, there exists an instance
where $\textsf{ALG}$ completes at most one job, while $\textsf{OPT}$ completes
at least $k$ jobs. Thus, the competitive ratio can be forced to $1/k$, and
hence made arbitrarily close to zero. Our result stands in sharp contrast to
the preemption-restart model, where Hoogeveen, Potts, and Woeginger (2000) gave
a deterministic $1/2$-competitive algorithm.

</details>


### [403] [Temporal Graph Reconfiguration for Always-Connected Graphs](https://arxiv.org/abs/2510.15593)
*Paul Sievers,George Skretas,Georg Tennigkeit*

Main category: cs.DS

TL;DR: The paper introduces the temporal graph reconfiguration problem, focusing on layered connectivity reconfiguration. It presents a polynomial-time algorithm to find a reconfiguration sequence of edges in a temporal graph while maintaining connectivity, with a maximum sequence length of 2M^2. It also proves that minimizing this sequence length is NP-hard.


<details>
  <summary>Details</summary>
Motivation: The motivation is to study network redesign problems in temporal graphs, specifically addressing the constraints of step-by-step modifications while the network remains operational and connected.

Method: The paper defines the temporal graph reconfiguration problem and focuses on the Layered Connectivity Reconfiguration problem. It analyzes how bridges can be reconfigured based on reachability partitions to identify changeable and unchangeable edges. A polynomial-time algorithm is developed to generate a reconfiguration sequence of length at most 2M^2. The NP-hardness of minimizing the sequence length is shown via a reduction from the vertex cover problem.

Result: A polynomial-time algorithm is presented that guarantees a valid reconfiguration sequence of length at most 2M^2 for layered connectivity reconfiguration, or determines impossibility. The problem of minimizing the reconfiguration sequence length is proven to be NP-hard.

Conclusion: The paper establishes the temporal graph reconfiguration problem, provides a constructive algorithm for layered connectivity reconfiguration with bounded sequence length, and demonstrates the computational hardness of optimizing this sequence length.

Abstract: Network redesign problems ask to modify the edges of a given graph to satisfy
some properties. In temporal graphs, where edges are only active at certain
times, we are sometimes only allowed to modify when the edges are going to be
active. In practice, we might not even be able to perform all of the necessary
modifications at once; changes must be applied step-by-step while the network
is still in operation, meaning that the network must continue to satisfy some
properties. To initiate a study in this area, we introduce the temporal graph
reconfiguration problem. As a starting point, we consider the Layered
Connectivity Reconfiguration problem in which every snapshot of the temporal
graph must remain connected throughout the reconfiguration. We provide insights
into how bridges can be reconfigured into non-bridges based on their
reachability partitions, which lets us identify any edge as either changeable
or unchangeable. From this we construct a polynomial-time algorithm that gives
a valid reconfiguration sequence of length at most 2M^2 (where M is the number
of temporal edges), or determines that reconfiguration is not possible. We also
show that minimizing the length of the reconfiguration sequence is NP-hard via
a reduction from vertex cover.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [404] [Autonomous Reactive Masonry Construction using Collaborative Heterogeneous Aerial Robots with Experimental Demonstration](https://arxiv.org/abs/2510.15114)
*Marios-Nektarios Stamatopoulos,Elias Small,Shridhar Velhal,Avijit Banerjee,George Nikolakopoulos*

Main category: cs.RO

TL;DR: 本文提出了一种利用异构无人机进行全自主空中砖砌建造的框架，并进行了实验验证。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够自主进行空中砖砌建造的系统，以应对传统建筑方法的局限性。

Method: 设计了两种专用无人机：砖块搬运无人机（带球关节执行器）和粘合剂涂抹无人机（带伺服阀和挤出喷嘴）。采用反应式任务规划单元（结合依赖图和冲突图）、分层状态机、动态任务分配和最小加加速度轨迹生成。砖块搬运无人机还配备了基于ArUco标记和最小二乘优化滤波的实时姿态估计系统。

Result: 成功进行了全自主空中砖砌建造的实验演示，证明了所提框架的有效性。

Conclusion: 该工作首次实现了利用异构无人机进行全自主空中砖砌建造，为未来自主空中机器人建造奠定了基础。

Abstract: This article presents a fully autonomous aerial masonry construction
framework using heterogeneous unmanned aerial vehicles (UAVs), supported by
experimental validation. Two specialized UAVs were developed for the task: (i)
a brick-carrier UAV equipped with a ball-joint actuation mechanism for precise
brick manipulation, and (ii) an adhesion UAV integrating a servo-controlled
valve and extruder nozzle for accurate adhesion application. The proposed
framework employs a reactive mission planning unit that combines a dependency
graph of the construction layout with a conflict graph to manage simultaneous
task execution, while hierarchical state machines ensure robust operation and
safe transitions during task execution. Dynamic task allocation allows
real-time adaptation to environmental feedback, while minimum-jerk trajectory
generation ensures smooth and precise UAV motion during brick pickup and
placement. Additionally, the brick-carrier UAV employs an onboard vision system
that estimates brick poses in real time using ArUco markers and a least-squares
optimization filter, enabling accurate alignment during construction. To the
best of the authors' knowledge, this work represents the first experimental
demonstration of fully autonomous aerial masonry construction using
heterogeneous UAVs, where one UAV precisely places the bricks while another
autonomously applies adhesion material between them. The experimental results
supported by the video showcase the effectiveness of the proposed framework and
demonstrate its potential to serve as a foundation for future developments in
autonomous aerial robotic construction.

</details>


### [405] [RM-RL: Role-Model Reinforcement Learning for Precise Robot Manipulation](https://arxiv.org/abs/2510.15189)
*Xiangyu Chen,Chuhao Zhou,Yuxi Liu,Jianfei Yang*

Main category: cs.RO

TL;DR: RM-RL通过利用近似最优动作生成标签，消除了对人类演示的需求，从而实现了在线和离线训练的统一，并在机器人操作任务中实现了更快的收敛速度和更高的精度。


<details>
  <summary>Details</summary>
Motivation: 精确的机器人操作对于精细化的应用至关重要，但现有的方法（如模仿学习和离线强化学习）在获取高质量演示和处理分布偏移方面存在困难。

Method: RM-RL框架结合了在线和离线训练，并通过角色模型策略自动生成在线训练数据的标签，将策略学习重新表述为监督训练，并采用混合训练方案重复利用在线数据。

Result: 与现有的强化学习方法相比，RM-RL收敛更快、更稳定，在翻译精度上提高了53%，在旋转精度上提高了20%，并成功完成了在精确放置细胞板到架子上的挑战性任务。

Conclusion: RM-RL框架能够有效地解决精确机器人操作中的挑战，通过其角色模型策略和混合训练方案，提高了数据效率和任务性能，克服了传统方法的局限性。

Abstract: Precise robot manipulation is critical for fine-grained applications such as
chemical and biological experiments, where even small errors (e.g., reagent
spillage) can invalidate an entire task. Existing approaches often rely on
pre-collected expert demonstrations and train policies via imitation learning
(IL) or offline reinforcement learning (RL). However, obtaining high-quality
demonstrations for precision tasks is difficult and time-consuming, while
offline RL commonly suffers from distribution shifts and low data efficiency.
We introduce a Role-Model Reinforcement Learning (RM-RL) framework that unifies
online and offline training in real-world environments. The key idea is a
role-model strategy that automatically generates labels for online training
data using approximately optimal actions, eliminating the need for human
demonstrations. RM-RL reformulates policy learning as supervised training,
reducing instability from distribution mismatch and improving efficiency. A
hybrid training scheme further leverages online role-model data for offline
reuse, enhancing data efficiency through repeated sampling. Extensive
experiments show that RM-RL converges faster and more stably than existing RL
methods, yielding significant gains in real-world manipulation: 53% improvement
in translation accuracy and 20% in rotation accuracy. Finally, we demonstrate
the successful execution of a challenging task, precisely placing a cell plate
onto a shelf, highlighting the framework's effectiveness where prior methods
fail.

</details>


### [406] [GaussGym: An open-source real-to-sim framework for learning locomotion from pixels](https://arxiv.org/abs/2510.15352)
*Alejandro Escontrela,Justin Kerr,Arthur Allshire,Jonas Frey,Rocky Duan,Carmelo Sferrazza,Pieter Abbeel*

Main category: cs.RO

TL;DR: 该研究提出了一种将3D高斯泼溅（3D Gaussian Splatting）集成到IsaacGym等向量化物理模拟器中的新方法，实现了每秒超过10万步的模拟速度，同时保持高视觉保真度，并展示了其在机器人模拟和现实迁移中的应用。


<details>
  <summary>Details</summary>
Motivation: 研究的动机在于提高机器人模拟的速度和视觉保真度，并探索富含视觉语义信息在机器人导航和决策中的作用，同时简化大规模逼真训练场景的创建。

Method: 该方法将3D高斯泼溅作为一种即插即用型渲染器集成到IsaacGym等向量化物理模拟器中。

Result: 实现了极高的模拟速度（超过10万步/秒），保持了高视觉保真度，并展示了在机器人模拟和现实迁移中的应用，证明了视觉语义信息（如避开危险区域）的价值，并能够轻松整合来自iPhone扫描、大型场景数据集（如GrandTour、ARKit）以及生成模型（如Veo）的数千个环境。

Conclusion: 该工作成功地结合了高吞吐量模拟和高保真感知，推动了可扩展和可泛化的机器人学习的发展，并将开源所有代码和数据。

Abstract: We present a novel approach for photorealistic robot simulation that
integrates 3D Gaussian Splatting as a drop-in renderer within vectorized
physics simulators such as IsaacGym. This enables unprecedented speed --
exceeding 100,000 steps per second on consumer GPUs -- while maintaining high
visual fidelity, which we showcase across diverse tasks. We additionally
demonstrate its applicability in a sim-to-real robotics setting. Beyond
depth-based sensing, our results highlight how rich visual semantics improve
navigation and decision-making, such as avoiding undesirable regions. We
further showcase the ease of incorporating thousands of environments from
iPhone scans, large-scale scene datasets (e.g., GrandTour, ARKit), and outputs
from generative video models like Veo, enabling rapid creation of realistic
training worlds. This work bridges high-throughput simulation and high-fidelity
perception, advancing scalable and generalizable robot learning. All code and
data will be open-sourced for the community to build upon. Videos, code, and
data available at https://escontrela.me/gauss_gym/.

</details>


### [407] [Nauplius Optimisation for Autonomous Hydrodynamics](https://arxiv.org/abs/2510.15350)
*Shyalan Ramesh,Scott Mann,Alex Stumpf*

Main category: cs.RO

TL;DR: NOAH是一种受藤壶幼体启发的仿生优化算法，用于在存在强水流、通信受限和持续传感需求的水下环境中进行自主水下航行器（AUV）的可靠协同。


<details>
  <summary>Details</summary>
Motivation: 传统的群体优化方法在强水流、有限声学带宽和持续传感需求的水下环境中并不可靠，需要一种新的方法来克服这些限制。

Method: NOAH算法结合了当前感知的漂移、持久传感节点中不可逆的沉降以及基于菌落的通信，灵感来源于藤壶幼体的行为。

Result: 验证研究表明，在永久锚定场景中成功率为86%，为水下机器人技术提供了统一的流体动力学约束和不可逆沉降行为的公式，并在流动条件下进行了实证研究。

Conclusion: NOAH为可扩展且节能的水下群体机器人技术奠定了基础，解决了现有群体算法在水下探索任务中的关键限制，提供了水动力感知、不可逆锚定机制和基于菌落的通信能力。

Abstract: Autonomous Underwater vehicles must operate in strong currents, limited
acoustic bandwidth, and persistent sensing requirements where conventional
swarm optimisation methods are unreliable. This paper presents NOAH, a novel
nature-inspired swarm optimisation algorithm that combines current-aware drift,
irreversible settlement in persistent sensing nodes, and colony-based
communication. Drawing inspiration from the behaviour of barnacle nauplii, NOAH
addresses the critical limitations of existing swarm algorithms by providing
hydrodynamic awareness, irreversible anchoring mechanisms, and colony-based
communication capabilities essential for underwater exploration missions. The
algorithm establishes a comprehensive foundation for scalable and
energy-efficient underwater swarm robotics with validated performance analysis.
Validation studies demonstrate an 86% success rate for permanent anchoring
scenarios, providing a unified formulation for hydrodynamic constraints and
irreversible settlement behaviours with an empirical study under flow.

</details>


### [408] [Lagrange-Poincaré-Kepler Equations of Disturbed Space-Manipulator Systems in Orbit](https://arxiv.org/abs/2510.15199)
*Borna Monazzah Moghaddam,Robin Chhabra*

Main category: cs.RO

TL;DR: 本文提出了拉格朗日-庞加莱-开普勒方程（LPKE），用于模拟在非惯性轨道参考系中运行的航天器-机械臂系统的动力学。


<details>
  <summary>Details</summary>
Motivation: 本文旨在扩展拉格朗日-庞加莱方程（LPE）以模拟航天器-机械臂系统在非惯性轨道参考系中的动力学，并结合了航天器姿态动力学、轨道运动和机械臂运动学之间的耦合。

Method: 本文利用拉格朗日-达朗贝尔原理，结合了基础航天器的欧拉-庞加莱方程、参考系的开普勒轨道动力学以及利用指数关节参数化的机械臂缩减欧拉-拉格朗日方程，推导出了能够明确捕捉轨道扰动及其与机械臂系统动力学耦合的新型闭式结构矩阵。

Result: 通过一个包含7自由度机械臂的航天器仿真研究，展示了该模型的有效性及其在数值上的优越性。

Conclusion: LPKE框架能够系统地纳入外部施加的、破坏对称性的力矩，可直接集成到轨道环境中自主机器人操作的硬件在环仿真和基于模型的控制体系结构中。

Abstract: This article presents an extension of the Lagrange-Poincare Equations (LPE)
to model the dynamics of spacecraft-manipulator systems operating within a
non-inertial orbital reference frame. Building upon prior formulations of LPE
for vehicle-manipulator systems, the proposed framework, termed the
Lagrange-Poincare-Kepler Equations (LPKE), incorporates the coupling between
spacecraft attitude dynamics, orbital motion, and manipulator kinematics. The
formalism combines the Euler-Poincare equations for the base spacecraft,
Keplerian orbital dynamics for the reference frame, and reduced Euler-Lagrange
equations for the manipulator's shape space, using an exponential joint
parametrization. Leveraging the Lagrange-d'Alembert principle on principal
bundles, we derive novel closed-form structural matrices that explicitly
capture the effects of orbital disturbances and their dynamic coupling with the
manipulator system. The LPKE framework also systematically includes externally
applied, symmetry-breaking wrenches, allowing for immediate integration into
hardware-in-the-loop simulations and model-based control architectures for
autonomous robotic operations in the orbital environment. To illustrate the
effectiveness of the proposed model and its numerical superiority, we present a
simulation study analyzing orbital effects on a 7-degree-of-freedom manipulator
mounted on a spacecraft.

</details>


### [409] [LVI-Q: Robust LiDAR-Visual-Inertial-Kinematic Odometry for Quadruped Robots Using Tightly-Coupled and Efficient Alternating Optimization](https://arxiv.org/abs/2510.15220)
*Kevin Christiansen Marsim,Minho Oh,Byeongho Yu,Seungjae Lee,I Made Aswin Nahrendra,Hyungtae Lim,Hyun Myung*

Main category: cs.RO

TL;DR: 提出了一种集成的激光雷达-视觉-惯性-运动学里程计系统，通过融合相机、激光雷达、IMU和关节编码器信息，解决了现有SLAM系统在复杂动态环境中面临的估计漂移问题，并在公开和长期数据集上表现出鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于传感器融合的SLAM方法在复杂动态环境中容易出现估计漂移，因此需要更鲁棒的系统。

Method: 提出了一种集成的激光雷达-视觉-惯性-运动学（LVIK）里程计系统。该系统根据测量可用性，采用基于优化的视觉-惯性-运动学里程计（VIKO）和基于滤波的激光雷达-惯性-运动学里程计（LIKO）的融合方法。VIKO利用了足部预积分技术和基于超像素聚类的鲁棒激光雷达-视觉深度一致性，在滑动窗口优化中进行。LIKO结合了足部运动学，并在误差状态迭代卡尔曼滤波器（ESIKF）中采用了点到面残差。

Result: 与现有的SLAM算法相比，该方法在公开和长期数据集上表现出鲁棒的性能。

Conclusion: 所提出的LVIK系统能够有效提高机器人位姿估计的鲁棒性，尤其是在具有挑战性的环境中。

Abstract: Autonomous navigation for legged robots in complex and dynamic environments
relies on robust simultaneous localization and mapping (SLAM) systems to
accurately map surroundings and localize the robot, ensuring safe and efficient
operation. While prior sensor fusion-based SLAM approaches have integrated
various sensor modalities to improve their robustness, these algorithms are
still susceptible to estimation drift in challenging environments due to their
reliance on unsuitable fusion strategies. Therefore, we propose a robust
LiDAR-visual-inertial-kinematic odometry system that integrates information
from multiple sensors, such as a camera, LiDAR, inertial measurement unit
(IMU), and joint encoders, for visual and LiDAR-based odometry estimation. Our
system employs a fusion-based pose estimation approach that runs
optimization-based visual-inertial-kinematic odometry (VIKO) and filter-based
LiDAR-inertial-kinematic odometry (LIKO) based on measurement availability. In
VIKO, we utilize the footpreintegration technique and robust LiDAR-visual depth
consistency using superpixel clusters in a sliding window optimization. In
LIKO, we incorporate foot kinematics and employ a point-toplane residual in an
error-state iterative Kalman filter (ESIKF). Compared with other sensor
fusion-based SLAM algorithms, our approach shows robust performance across
public and longterm datasets.

</details>


### [410] [PolyFly: Polytopic Optimal Planning for Collision-Free Cable-Suspended Aerial Payload Transportation](https://arxiv.org/abs/2510.15226)
*Mrunal Sarvaiya,Guanrui Li,Giuseppe Loianno*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Aerial transportation robots using suspended cables have emerged as versatile
platforms for disaster response and rescue operations. To maximize the
capabilities of these systems, robots need to aggressively fly through tightly
constrained environments, such as dense forests and structurally unsafe
buildings, while minimizing flight time and avoiding obstacles. Existing
methods geometrically over-approximate the vehicle and obstacles, leading to
conservative maneuvers and increased flight times. We eliminate these
restrictions by proposing PolyFly, an optimal global planner which considers a
non-conservative representation for aerial transportation by modeling each
physical component of the environment, and the robot (quadrotor, cable and
payload), as independent polytopes. We further increase the model accuracy by
incorporating the attitude of the physical components by constructing
orientation-aware polytopes. The resulting optimal control problem is
efficiently solved by converting the polytope constraints into smooth
differentiable constraints via duality theory. We compare our method against
the existing state-of-the-art approach in eight maze-like environments and show
that PolyFly produces faster trajectories in each scenario. We also
experimentally validate our proposed approach on a real quadrotor with a
suspended payload, demonstrating the practical reliability and accuracy of our
method.

</details>


### [411] [A Generalized Sylvester-Fermat-Torricelli problem with application in disaster relief operations by UAVs](https://arxiv.org/abs/2510.15229)
*Sina Kazemdehbashi,Yanchao Liu,Boris S. Mordukhovich*

Main category: cs.RO

TL;DR: 开发了一个新的数学框架来优化无人机基站的部署位置，以应对灾难响应中的恶劣天气和无人机异质性问题。


<details>
  <summary>Details</summary>
Motivation: 在灾难响应中，特别是在通信基础设施被破坏的情况下，快速收集灾区信息至关重要。无人机（UAVs）在这种场景下很有价值，但恶劣天气（尤其是风）是实际部署的主要挑战。

Method: 提出了一种新的数学框架，将 Sylvester 问题推广为 Sylvester-Fermat-Torricelli (SFT) 问题，该问题统一考虑了风的影响、无人机的异质性以及往返运动，以确定移动无人机基站的最佳位置。

Result: 实验结果表明，该框架可以将浪费的操作时间减少高达 84%，从而显著提高灾后任务的效率和效果。

Conclusion: 所提出的框架通过考虑风和无人机异质性等现实因素，增强了基于无人机的灾难响应规划的实用性。

Abstract: Natural and human-made disasters can cause severe devastation and claim
thousands of lives worldwide. Therefore, developing efficient methods for
disaster response and management is a critical task for relief teams. One of
the most essential components of effective response is the rapid collection of
information about affected areas, damages, and victims. More data translates
into better coordination, faster rescue operations, and ultimately, more lives
saved. However, in some disasters, such as earthquakes, the communication
infrastructure is often partially or completely destroyed, making it extremely
difficult for victims to send distress signals and for rescue teams to locate
and assist them in time. Unmanned Aerial Vehicles (UAVs) have emerged as
valuable tools in such scenarios. In particular, a fleet of UAVs can be
dispatched from a mobile station to the affected area to facilitate data
collection and establish temporary communication networks. Nevertheless,
real-world deployment of UAVs faces several challenges, with adverse weather
conditions--especially wind--being among the most significant. To address this,
we develop a novel mathematical framework to determine the optimal location of
a mobile UAV station while explicitly accounting for the heterogeneity of the
UAVs and the effect of wind. In particular, we generalize the Sylvester problem
to introduce the Sylvester-Fermat-Torricelli (SFT) problem, which captures
complex factors such as wind influence, UAV heterogeneity, and back-and-forth
motion within a unified framework. The proposed framework enhances the
practicality of UAV-based disaster response planning by accounting for
real-world factors such as wind and UAV heterogeneity. Experimental results
demonstrate that it can reduce wasted operational time by up to 84%, making
post-disaster missions significantly more efficient and effective.

</details>


### [412] [Traversability-aware Consistent Situational Graphs for Indoor Localization and Mapping](https://arxiv.org/abs/2510.15319)
*Jeewon Kim,Minho Oh,Hyun Myung*

Main category: cs.RO

TL;DR: 该研究提出了一种考虑可通行性的房间分割方法，以解决传统方法在 3D 映射中分割大房间或不规则房间时遇到的挑战，从而提高机器人定位和建图的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有场景图和分层场景图方法在机器人 3D 映射中虽然有所改进，但在分割房间时，由于传感器视点和视野的限制，以及时间依赖性或基于体素的方法的不足，经常出现过分割或欠分割的问题，导致定位和建图的准确性下降。

Method: 提出了一种考虑机器人与周围环境交互以及可通行性信息的房间分割方法，旨在提高房间分割的语义一致性和计算效率。

Result: 通过在重复遍历同一空间的 数据集上评估，该方法在房间重新检测频率和优化时间消耗方面表现出改进的性能。

Conclusion: 所提出的可通行性感知房间分割方法可以增强场景图与姿态图优化的集成，从而提高机器人定位和建图的准确性与效率。

Abstract: Scene graphs enhance 3D mapping capabilities in robotics by understanding the
relationships between different spatial elements, such as rooms and objects.
Recent research extends scene graphs to hierarchical layers, adding and
leveraging constraints across these levels. This approach is tightly integrated
with pose-graph optimization, improving both localization and mapping accuracy
simultaneously. However, when segmenting spatial characteristics, consistently
recognizing rooms becomes challenging due to variations in viewpoints and
limited field of view (FOV) of sensors. For example, existing real-time
approaches often over-segment large rooms into smaller, non-functional spaces
that are not useful for localization and mapping due to the time-dependent
method. Conversely, their voxel-based room segmentation method often
under-segment in complex cases like not fully enclosed 3D space that are
non-traversable for ground robots or humans, leading to false constraints in
pose-graph optimization. We propose a traversability-aware room segmentation
method that considers the interaction between robots and surroundings, with
consistent feasibility of traversability information. This enhances both the
semantic coherence and computational efficiency of pose-graph optimization.
Improved performance is demonstrated through the re-detection frequency of the
same rooms in a dataset involving repeated traversals of the same space along
the same path, as well as the optimization time consumption.

</details>


### [413] [ASBI: Leveraging Informative Real-World Data for Active Black-Box Simulator Tuning](https://arxiv.org/abs/2510.15331)
*Gahee Kim,Takamitsu Matsubara*

Main category: cs.RO

TL;DR: 本研究提出了一种主动仿真推断（ASBI）框架，通过机器人主动收集在线数据来优化黑盒模拟器的参数。


<details>
  <summary>Details</summary>
Motivation: 黑盒模拟器在机器人领域应用广泛，但由于无法获得似然函数，其参数优化充满挑战。在黑盒场景下，由于无法确定参数和观测之间的关系，准备包含足够信息用于参数估计的观测数据非常困难。

Method: ASBI 框架通过最大化信息增益来优化机器人动作，以收集信息量大的观测。信息增益定义为后验和先验之间香农熵的预期减少。由于无法获得似然函数，该方法利用神经后验估计（NPE）来学习后验估计器。

Result: 通过三个仿真实验验证了该方法能够实现精确的参数估计，后验分布能很好地集中在真实参数周围。此外，研究还展示了一个实际应用，使用真实的机器人来估计立方体颗粒的模拟参数，以模拟两种真实物体（珠子和沙砾）的桶倾倒动作。

Conclusion: ASBI 框架能够有效地解决黑盒模拟器参数优化中的挑战，通过主动数据收集实现精确的参数估计。

Abstract: Black-box simulators are widely used in robotics, but optimizing their
parameters remains challenging due to inaccessible likelihoods.
Simulation-Based Inference (SBI) tackles this issue using simulation-driven
approaches, estimating the posterior from offline real observations and forward
simulations. However, in black-box scenarios, preparing observations that
contain sufficient information for parameter estimation is difficult due to the
unknown relationship between parameters and observations. In this work, we
present Active Simulation-Based Inference (ASBI), a parameter estimation
framework that uses robots to actively collect real-world online data to
achieve accurate black-box simulator tuning. Our framework optimizes robot
actions to collect informative observations by maximizing information gain,
which is defined as the expected reduction in Shannon entropy between the
posterior and the prior. While calculating information gain requires the
likelihood, which is inaccessible in black-box simulators, our method solves
this problem by leveraging Neural Posterior Estimation (NPE), which leverages a
neural network to learn the posterior estimator. Three simulation experiments
quantitatively verify that our method achieves accurate parameter estimation,
with posteriors sharply concentrated around the true parameters. Moreover, we
show a practical application using a real robot to estimate the simulation
parameters of cubic particles corresponding to two real objects, beads and
gravel, with a bucket pouring action.

</details>


### [414] [Adaptive Cost-Map-based Path Planning in Partially Unknown Environments with Movable Obstacles](https://arxiv.org/abs/2510.15336)
*Liviu-Mihai Stan,Ranulfo Bezerra,Shotaro Kojima,Tsige Tadesse Alemayoh,Satoshi Tadokoro,Masashi Konyo,Kazunori Ohno*

Main category: cs.RO

TL;DR: 该框架通过添加一个动态障碍物层和一个姿态进度检查器来增强ROS2 Nav2堆栈，以实现对可移动障碍物的导航。


<details>
  <summary>Details</summary>
Motivation: 在灾难响应和其他非结构化室内环境中，可靠的机器人导航需要避开障碍物并识别哪些障碍物可以被推开。

Method: 提出一个基于LiDAR和里程计的自适应路径规划框架。该框架包含一个动态障碍物层，该层将动态障碍物标记为可移动，并为其分配较低的遍历成本。一个姿态进度检查器会监控机器人的速度，并在机器人明显减速或停滞时提高局部成本，以触发全局规划器重新规划路径。

Result: 在Gazebo环境中，使用Scout Mini机器人进行了评估。结果表明，与没有动态障碍物层的基线相比，该框架在目标到达率方面有所提高，死锁情况有所减少，同时遍历时间大致相当。该方法仅依赖于平面扫描和CPU计算，适用于资源受限的机器人，并可轻松集成到异构平台中。

Conclusion: 基于交互感知的成本图是一种轻量级的、ROS2原生的方法，适用于在非结构化环境中导航潜在可移动障碍物。

Abstract: Reliable navigation in disaster-response and other unstructured indoor
settings requires robots not only to avoid obstacles but also to recognise when
those obstacles can be pushed aside. We present an adaptive, LiDAR and
odometry-based path-planning framework that embeds this capability into the
ROS2 Nav2 stack. A new Movable Obstacles Layer labels all LiDAR returns missing
from a prior static map as tentatively movable and assigns a reduced traversal
cost. A companion Slow-Pose Progress Checker monitors the ratio of commanded to
actual velocity; when the robot slows appreciably, the local cost is raised
from light to heavy, and on a stall to lethal, prompting the global planner to
back out and re-route. Gazebo evaluations on a Scout Mini, spanning isolated
objects and cluttered corridors, show higher goal-reach rates and fewer
deadlocks than a no-layer baseline, with traversal times broadly comparable.
Because the method relies only on planar scans and CPU-level computation, it
suits resource-constrained search and rescue robots and integrates into
heterogeneous platforms with minimal engineering. Overall, the results indicate
that interaction-aware cost maps are a lightweight, ROS2-native extension for
navigating among potentially movable obstacles in unstructured settings. The
full implementation will be released as open source
athttps://costmap-namo.github.io.

</details>


### [415] [Towards Automated Chicken Deboning via Learning-based Dynamically-Adaptive 6-DoF Multi-Material Cutting](https://arxiv.org/abs/2510.15376)
*Zhaodong Yang,Ai-Ping Hu,Harish Ravichandar*

Main category: cs.RO

TL;DR: 自动化鸡肩去骨技术在部分遮挡、可变形、多材料关节中进行精确的6-DoF切割，以避免骨骼接触带来的健康与安全风险。本研究提出了一种结合系统级和算法级的解决方案，通过训练和部署一种反应式力反馈切割策略，该策略能够动态调整名义轨迹并实现刀具的全6-DoF控制，以在狭窄的关节间隙中导航并避开骨骼。


<details>
  <summary>Details</summary>
Motivation: 自动化鸡肩去骨在部分遮挡、可变形、多材料关节中进行精确的6-DoF切割，以避免骨骼接触带来的健康与安全风险。

Method: 1. 提出一个开源的定制化仿真器，用于多材料切割的仿真，该仿真器能够模拟耦合力、断裂力和切割力，并支持强化学习。2. 设计了一个可重复使用的物理测试台，模拟鸡肩环境：将两个具有可控姿态的刚性“骨头”球嵌入较软的块体中，以进行严格和可重复的评估。3. 训练并部署了一个残差强化学习策略，结合了离散化的力观测和领域随机化，实现了从仿真到现实的零样本迁移，并首次演示了去骨真实鸡肩的策略。

Result: 在仿真器、物理测试台和真实鸡肩上的实验表明，所提出的策略能够可靠地导航关节间隙，减少不期望的骨骼/软骨接触，并将成功率和骨骼避让方面比现有的开环切割基线提高了4倍。研究结果还证明了力反馈在安全有效地进行多材料切割中的必要性。

Conclusion: 本研究提出了一种创新的自动化鸡肩去骨方法，通过结合仿真、物理测试台和强化学习策略，实现了高精度的6-DoF切割和优异的骨骼避让能力，为机器人切割领域提供了重要的贡献。

Abstract: Automating chicken shoulder deboning requires precise 6-DoF cutting through a
partially occluded, deformable, multi-material joint, since contact with the
bones presents serious health and safety risks. Our work makes both
systems-level and algorithmic contributions to train and deploy a reactive
force-feedback cutting policy that dynamically adapts a nominal trajectory and
enables full 6-DoF knife control to traverse the narrow joint gap while
avoiding contact with the bones. First, we introduce an open-source
custom-built simulator for multi-material cutting that models coupling,
fracture, and cutting forces, and supports reinforcement learning, enabling
efficient training and rapid prototyping. Second, we design a reusable physical
testbed to emulate the chicken shoulder: two rigid "bone" spheres with
controllable pose embedded in a softer block, enabling rigorous and repeatable
evaluation while preserving essential multi-material characteristics of the
target problem. Third, we train and deploy a residual RL policy, with
discretized force observations and domain randomization, enabling robust
zero-shot sim-to-real transfer and the first demonstration of a learned policy
that debones a real chicken shoulder. Our experiments in our simulator, on our
physical testbed, and on real chicken shoulders show that our learned policy
reliably navigates the joint gap and reduces undesired bone/cartilage contact,
resulting in up to a 4x improvement over existing open-loop cutting baselines
in terms of success rate and bone avoidance. Our results also illustrate the
necessity of force feedback for safe and effective multi-material cutting. The
project website is at https://sites.google.com/view/chickendeboning-2026.

</details>


### [416] [VDRive: Leveraging Reinforced VLA and Diffusion Policy for End-to-end Autonomous Driving](https://arxiv.org/abs/2510.15446)
*Ziang Guo,Zufeng Zhang*

Main category: cs.RO

TL;DR: VDRive是一个端到端的自动驾驶管道，通过结合视觉-语言-动作模型（VLA）和生成式扩散策略，实现了可解释和鲁棒的决策制定。


<details>
  <summary>Details</summary>
Motivation: 为了应对自动驾驶中动态环境和边缘情况对车辆状态理解和决策制定的鲁棒性挑战。

Method: VDRive管道结合了VLA模型和生成式扩散策略。VLA通过令牌生成预训练来预测未来观测，并使用条件向量量化变分自编码器（CVQ-VAE）将观测表示为离散代码。通过强化学习微调VLA，以预测基于当前驾驶条件的未来轨迹和动作。VLA提供当前和预测的状态令牌给动作策略头部，以生成分层动作和轨迹。在策略训练期间，学习到的评估器通过基于梯度的反馈来评估策略生成的动作，形成一个Actor-Critic框架。

Result: VDRive在Bench2Drive闭环基准和nuScenes开环规划中取得了最先进的性能。

Conclusion: VDRive通过明确的状态-动作映射，能够实现可解释和鲁棒的自动驾驶决策。

Abstract: In autonomous driving, dynamic environment and corner cases pose significant
challenges to the robustness of ego vehicle's state understanding and decision
making. We introduce VDRive, a novel pipeline for end-to-end autonomous driving
that explicitly models state-action mapping to address these challenges,
enabling interpretable and robust decision making. By leveraging the
advancement of the state understanding of the Vision Language Action Model
(VLA) with generative diffusion policy-based action head, our VDRive guides the
driving contextually and geometrically. Contextually, VLA predicts future
observations through token generation pre-training, where the observations are
represented as discrete codes by a Conditional Vector Quantized Variational
Autoencoder (CVQ-VAE). Geometrically, we perform reinforcement learning
fine-tuning of the VLA to predict future trajectories and actions based on
current driving conditions. VLA supplies the current state tokens and predicted
state tokens for the action policy head to generate hierarchical actions and
trajectories. During policy training, a learned critic evaluates the actions
generated by the policy and provides gradient-based feedback, forming an
actor-critic framework that enables a reinforcement-based policy learning
pipeline. Experiments show that our VDRive achieves state-of-the-art
performance in the Bench2Drive closed-loop benchmark and nuScenes open-loop
planning.

</details>


### [417] [Perfect Prediction or Plenty of Proposals? What Matters Most in Planning for Autonomous Driving](https://arxiv.org/abs/2510.15505)
*Aron Distelzweig,Faris Janjoš,Oliver Scheel,Sirish Reddy Varra,Raghu Rajan,Joschka Boedecker*

Main category: cs.RO

TL;DR: IPP方法并未充分利用预测信息，提出以生成高质量候选动作替代，并在高交互和分布外场景下取得SOTA。


<details>
  <summary>Details</summary>
Motivation: 评估IPP方法在多大程度上真正提高了规划性能，并探究了预测在IPP方法中的作用。

Method: 在Val14和interPlan基准上分析了即使拥有完美预测，IPP方法也未能提升规划结果。提出了一种以生成高质量候选动作为核心，并主要使用预测进行碰撞检查的方法，该方法基于PDM并增强了候选动作生成。

Result: 现有基于模仿学习的规划器在生成真实合理的候选动作方面存在困难，性能不如简单的车道跟随方法。所提出的以候选动作为中心的方法在分布外和高交互场景下表现显著优于现有方法，并达到了新的SOTA。

Conclusion: IPP方法未能充分利用预测信息，改进候选动作生成是提升规划性能的关键，尤其是在复杂场景下。

Abstract: Traditionally, prediction and planning in autonomous driving (AD) have been
treated as separate, sequential modules. Recently, there has been a growing
shift towards tighter integration of these components, known as Integrated
Prediction and Planning (IPP), with the aim of enabling more informed and
adaptive decision-making. However, it remains unclear to what extent this
integration actually improves planning performance. In this work, we
investigate the role of prediction in IPP approaches, drawing on the widely
adopted Val14 benchmark, which encompasses more common driving scenarios with
relatively low interaction complexity, and the interPlan benchmark, which
includes highly interactive and out-of-distribution driving situations. Our
analysis reveals that even access to perfect future predictions does not lead
to better planning outcomes, indicating that current IPP methods often fail to
fully exploit future behavior information. Instead, we focus on high-quality
proposal generation, while using predictions primarily for collision checks. We
find that many imitation learning-based planners struggle to generate realistic
and plausible proposals, performing worse than PDM - a simple lane-following
approach. Motivated by this observation, we build on PDM with an enhanced
proposal generation method, shifting the emphasis towards producing diverse but
realistic and high-quality proposals. This proposal-centric approach
significantly outperforms existing methods, especially in out-of-distribution
and highly interactive settings, where it sets new state-of-the-art results.

</details>


### [418] [VO-DP: Semantic-Geometric Adaptive Diffusion Policy for Vision-Only Robotic Manipulation](https://arxiv.org/abs/2510.15530)
*Zehao Ni,Yonghao He,Lingfeng Qian,Jilei Mao,Fa Fu,Wei Sui,Hu Su,Junran Peng,Zhipeng Wang,Bin He*

Main category: cs.RO

TL;DR: 该研究提出了一种名为VO-DP的纯视觉单视图扩散策略学习方法，利用预训练的视觉基础模型融合语义和几何特征，并在机器人操作任务中取得了优于现有纯视觉和点云基准方法的性能，同时保持了良好的鲁棒性，并开源了一个支持多种模型的训练库。


<details>
  <summary>Details</summary>
Motivation: 现有基于点云的模仿学习方法在机器人操作中精度较高，但忽略了纯视觉解决方案的潜力。本研究旨在探索一种仅使用视觉信息的单视图方法。

Method: VO-DP方法利用预训练的视觉基础模型，提取VGG的中间特征，并结合DINOv2的语义特征和交替注意力块的几何特征。通过交叉注意力融合这些特征，并使用CNN进行空间压缩，最终输入策略头部。此方法不依赖点云输入。

Result: 在模拟任务中，VO-DP的平均成功率为64.6%，与DP3（64.0%）相当，远高于DP（34.8%）。在真实世界任务中，VO-DP的成功率为87.9%，显著优于DP3（67.5%）和DP（11.2%）。此外，VO-DP在颜色、大小、背景和光照变化下均表现出高稳定性。最后，研究开源了一个支持多机多GPU并行训练、混合精度训练、兼容DP、DP3、VO-DP等策略以及RoboTwin模拟器的机器人操作训练库。

Conclusion: VO-DP是一种有效的纯视觉单视图扩散策略学习方法，它利用预训练的视觉基础模型融合语义和几何特征，在机器人操作任务中取得了优于纯视觉基线和点云基线方法的性能，并展现了良好的鲁棒性。此外，开源的训练库为相关研究提供了支持。

Abstract: In the context of imitation learning, visuomotor-based diffusion policy
learning is one of the main directions in robotic manipulation. Most of these
approaches rely on point clouds as observation inputs and construct scene
representations through point clouds feature learning, which enables them to
achieve remarkable accuracy. However, the existing literature lacks an in-depth
exploration of vision-only solutions that have significant potential. In this
paper, we propose a Vision-Only and single-view Diffusion Policy learning
method (VO-DP) that leverages pretrained visual foundation models to achieve
effective fusion of semantic and geometric features. We utilize intermediate
features from VGGT incorporating semantic features from DINOv2 and geometric
features from Alternating Attention blocks. Features are fused via
cross-attention and spatially compressed with a CNN to form the input to the
policy head. Extensive experiments demonstrate that VO-DP not only outperforms
the vision-only baseline DP significantly but also exhibits distinct
performance trends against the point cloud-based method DP3: in simulation
tasks, VO-DP achieves an average success rate of 64.6% on par with DP3 64.0%
and far higher than DP 34.8%, while in real-world tasks, it reaches 87.9%,
outperforming both DP3 67.5% and DP 11.2% by a notable margin. Further
robustness evaluations confirm that VO-DP remains highly stable under varying
conditions including color, size, background, and lighting. Lastly, we
open-source a training library for robotic manipulation. Built on Accelerate,
this library supports multi-machine and multi-GPU parallel training, as well as
mixed precision training. It is compatible with visuomotor policies such as DP,
DP3 and VO-DP, and also supports the RoboTwin simulator.

</details>


### [419] [Improved Extended Kalman Filter-Based Disturbance Observers for Exoskeletons](https://arxiv.org/abs/2510.15533)
*Shilei Li,Dawei Shi,Makoto Iwasaki,Yan Ning,Hongpeng Zhou,Ling Shi*

Main category: cs.RO

TL;DR: 该研究提出了一种新的干扰估计方法，用于提高机械系统的鲁棒性，并验证了其在假肢实验中的有效性。


<details>
  <summary>Details</summary>
Motivation: 机械系统在实际应用中常受到未知干扰的影响，导致性能下降。现有的控制结构虽然可以解耦标称性能和干扰抑制，但在干扰动态未知的情况下，无法实现完美的干扰抑制。因此，需要新的方法来提高干扰估计的准确性。

Method: 提出了一种基于交互多模型和多核互相关扩展卡尔曼滤波的干扰观测器，用于增强干扰估计能力，并分析了干扰估计中跟踪速度和跟踪不确定性之间的固有权衡。

Result: 实验结果表明，所提出的两种新方法在假肢实验中，对于髋关节误差的跟踪精度分别提高了36.3%和16.2%，对于膝关节误差的跟踪精度分别提高了46.3%和24.4%，相较于传统的基于扩展卡尔曼滤波的干扰观测器，尤其在时变交互力场景下，证明了该方法的优越性。

Conclusion: 所提出的两种新颖的干扰估计方法能够显著提高机械系统的跟踪精度，尤其是在存在未知时变干扰的情况下，为提高机械系统的鲁棒性提供了有效的解决方案。

Abstract: The nominal performance of mechanical systems is often degraded by unknown
disturbances. A two-degree-of-freedom control structure can decouple nominal
performance from disturbance rejection. However, perfect disturbance rejection
is unattainable when the disturbance dynamic is unknown. In this work, we
reveal an inherent trade-off in disturbance estimation subject to tracking
speed and tracking uncertainty. Then, we propose two novel methods to enhance
disturbance estimation: an interacting multiple model extended Kalman
filter-based disturbance observer and a multi-kernel correntropy extended
Kalman filter-based disturbance observer. Experiments on an exoskeleton verify
that the proposed two methods improve the tracking accuracy $36.3\%$ and
$16.2\%$ in hip joint error, and $46.3\%$ and $24.4\%$ in knee joint error,
respectively, compared to the extended Kalman filter-based disturbance
observer, in a time-varying interaction force scenario, demonstrating the
superiority of the proposed method.

</details>


### [420] [Adaptive Legged Locomotion via Online Learning for Model Predictive Control](https://arxiv.org/abs/2510.15626)
*Hongyu Zhou,Xiaoyu Zhang,Vasileios Tzoumas*

Main category: cs.RO

TL;DR: 通过在线学习和模型预测控制，为自适应的兽脚类动物运动提供了一种算法。


<details>
  <summary>Details</summary>
Motivation: 该算法旨在使四足动物能够在未来自主执行复杂任务，即使在存在模型不确定性和外部干扰等现实世界未知不确定性的情况下。

Method: 该算法结合了模型预测控制（MPC）和残差动力学的在线学习。残差动力学使用随机傅里叶特征在再生核希尔伯特空间中进行近似。然后，MPC 使用当前学习到的残差动力学模型进行控制，该模型以自监督的方式使用最小二乘法在线更新。

Result: 该算法在 Gazebo 和 MuJoCo 模拟中得到了验证，其中四足动物能够跟踪参考轨迹。模拟包括各种外部干扰，例如恒定的外部力、不同坡度和粗糙地形，以及负载和变化的地面摩擦系数。

Conclusion: 该算法实现了亚线性动态遗憾，表明其在面对未知动态时具有良好的性能。

Abstract: We provide an algorithm for adaptive legged locomotion via online learning
and model predictive control. The algorithm is composed of two interacting
modules: model predictive control (MPC) and online learning of residual
dynamics. The residual dynamics can represent modeling errors and external
disturbances. We are motivated by the future of autonomy where quadrupeds will
autonomously perform complex tasks despite real-world unknown uncertainty, such
as unknown payload and uneven terrains. The algorithm uses random Fourier
features to approximate the residual dynamics in reproducing kernel Hilbert
spaces. Then, it employs MPC based on the current learned model of the residual
dynamics. The model is updated online in a self-supervised manner using least
squares based on the data collected while controlling the quadruped. The
algorithm enjoys sublinear \textit{dynamic regret}, defined as the
suboptimality against an optimal clairvoyant controller that knows how the
residual dynamics. We validate our algorithm in Gazebo and MuJoCo simulations,
where the quadruped aims to track reference trajectories. The Gazebo
simulations include constant unknown external forces up to $12\boldsymbol{g}$,
where $\boldsymbol{g}$ is the gravity vector, in flat terrain, slope terrain
with $20\degree$ inclination, and rough terrain with $0.25m$ height variation.
The MuJoCo simulations include time-varying unknown disturbances with payload
up to $8~kg$ and time-varying ground friction coefficients in flat terrain.

</details>


### [421] [Educational SoftHand-A: Building an Anthropomorphic Hand with Soft Synergies using LEGO MINDSTORMS](https://arxiv.org/abs/2510.15638)
*Jared K. Lepora,Haoran Li,Efi Psomopoulou,Nathan F. Lepora*

Main category: cs.RO

TL;DR: 该论文介绍了一个完全由LEGO MINDSTORMS构建的拟人化机器人手，名为Educational SoftHand-A，它是一个基于Pisa/IIT SoftHand及其相关手的肌腱驱动、高度欠驱动的机器人手。


<details>
  <summary>Details</summary>
Motivation: 为了适应教育环境，该设计仅限于使用标准的LEGO零件，并使用家中常见的设备进行测试。

Method: 该手具有双电机，为每根手指驱动一对拮抗/协同肌腱，这被证明可以实现反应式精细控制。手指运动通过软协同作用同步，并使用带离合器齿轮的差速机构实现。

Result: 总体而言，该设计产生了一个可以通过简单的驱动和控制机制自适应抓取广泛物体的拟人化手。

Conclusion: 由于该手可以由LEGO零件构建，并使用了最先进的机器人手设计理念，因此它有潜力教育和激励儿童了解现代机器人学的前沿。

Abstract: This paper introduces an anthropomorphic robot hand built entirely using LEGO
MINDSTORMS: the Educational SoftHand-A, a tendon-driven, highly-underactuated
robot hand based on the Pisa/IIT SoftHand and related hands. To be suitable for
an educational context, the design is constrained to use only standard LEGO
pieces with tests using common equipment available at home. The hand features
dual motors driving an agonist/antagonist opposing pair of tendons on each
finger, which are shown to result in reactive fine control. The finger motions
are synchonized through soft synergies, implemented with a differential
mechanism using clutch gears. Altogether, this design results in an
anthropomorphic hand that can adaptively grasp a broad range of objects using a
simple actuation and control mechanism. Since the hand can be constructed from
LEGO pieces and uses state-of-the-art design concepts for robotic hands, it has
the potential to educate and inspire children to learn about the frontiers of
modern robotics.

</details>


### [422] [Integration of a Variable Stiffness Link for Long-Reach Aerial Manipulation](https://arxiv.org/abs/2510.15639)
*Manuel J. Fernandez,Alejandro Suarez,Anibal Ollero,Matteo Fumagalli*

Main category: cs.RO

TL;DR: 该研究提出了一种用于长距离空中操作的可变刚度连杆（VSL），以实现空中多旋翼平台和双臂机械臂之间的自适应机械耦合。


<details>
  <summary>Details</summary>
Motivation: 传统长距离操控系统依赖于刚性或电缆连接，这限制了精度或将干扰传递给飞行器。本研究旨在通过引入可调刚度连杆来解决这一问题，使其能够根据任务需求在柔性绳索或刚性杆之间切换。

Method: 该系统安装在配备LiCAS双臂机械臂和VSL的四旋翼上，并通过遥操作实验进行评估，包括外部干扰和包裹运送任务。实验中，研究人员改变了连杆的刚度，并观察其对无人机与负载之间动态交互的影响。

Result: 结果表明，改变连杆刚度可以显著改变无人机与负载之间的动态交互。柔性配置能有效衰减外部冲击和气动扰动，而刚性配置则能提高操控阶段的位置精度。

Conclusion: 该研究证实，VSL提高了系统的通用性和安全性，在顺从性和精确性之间提供了可控的权衡。未来的工作将集中于自主刚度调节、多绳索配置、协同空中操作以及用户研究，以进一步评估其对遥操作和半自主空中任务的影响。

Abstract: This paper presents the integration of a Variable Stiffness Link (VSL) for
long-reach aerial manipulation, enabling adaptable mechanical coupling between
an aerial multirotor platform and a dual-arm manipulator. Conventional
long-reach manipulation systems rely on rigid or cable connections, which limit
precision or transmit disturbances to the aerial vehicle. The proposed VSL
introduces an adjustable stiffness mechanism that allows the link to behave
either as a flexible rope or as a rigid rod, depending on task requirements.
  The system is mounted on a quadrotor equipped with the LiCAS dual-arm
manipulator and evaluated through teleoperated experiments, involving external
disturbances and parcel transportation tasks. Results demonstrate that varying
the link stiffness significantly modifies the dynamic interaction between the
UAV and the payload. The flexible configuration attenuates external impacts and
aerodynamic perturbations, while the rigid configuration improves positional
accuracy during manipulation phases.
  These results confirm that VSL enhances versatility and safety, providing a
controllable trade-off between compliance and precision. Future work will focus
on autonomous stiffness regulation, multi-rope configurations, cooperative
aerial manipulation and user studies to further assess its impact on
teleoperated and semi-autonomous aerial tasks.

</details>


### [423] [Freehand 3D Ultrasound Imaging: Sim-in-the-Loop Probe Pose Optimization via Visual Servoing](https://arxiv.org/abs/2510.15668)
*Yameng Zhang,Dianye Huang,Max Q. -H. Meng,Nassir Navab,Zhongliang Jiang*

Main category: cs.RO

TL;DR: 提出一种利用轻量级摄像头和视觉伺服技术进行精确3D超声成像的经济高效的解决方案，以克服传统方法在探头姿态估计方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 传统的三维超声（US）探头姿态估计方法依赖于昂贵的跟踪系统，或者在处理图像噪声和误差累积方面存在困难，这会影响重建的精度。因此，需要一种经济高效且通用的解决方案。

Method: 提出一种利用轻量级摄像头和视觉伺服技术进行精确3D超声成像的解决方案。摄像头捕捉纹理平面工作空间中的视觉反馈。引入图像修复方法来重建被遮挡的区域。采用模拟回路的方法进行姿态估计，该方法在模拟环境中复制系统设置，并迭代地最小化模拟和现实世界观测之间的姿态误差。视觉伺服控制器通过优化图像对齐来改进平移估计。

Result: 在血管模型、锥形模型和人臂上进行了验证，豪斯多夫距离分别为0.359 mm、1.171 mm和0.858 mm，证明了该方法的鲁棒性和准确性。

Conclusion: 该方法在提高三维超声成像的精确性和可靠性方面具有巨大潜力，为实现可靠的自由手三维超声重建提供了有效的解决方案。

Abstract: Freehand 3D ultrasound (US) imaging using conventional 2D probes offers
flexibility and accessibility for diverse clinical applications but faces
challenges in accurate probe pose estimation. Traditional methods depend on
costly tracking systems, while neural network-based methods struggle with image
noise and error accumulation, compromising reconstruction precision. We propose
a cost-effective and versatile solution that leverages lightweight cameras and
visual servoing in simulated environments for precise 3D US imaging. These
cameras capture visual feedback from a textured planar workspace. To counter
occlusions and lighting issues, we introduce an image restoration method that
reconstructs occluded regions by matching surrounding texture patterns. For
pose estimation, we develop a simulation-in-the-loop approach, which replicates
the system setup in simulation and iteratively minimizes pose errors between
simulated and real-world observations. A visual servoing controller refines the
alignment of camera views, improving translational estimation by optimizing
image alignment. Validations on a soft vascular phantom, a 3D-printed conical
model, and a human arm demonstrate the robustness and accuracy of our approach,
with Hausdorff distances to the reference reconstructions of 0.359 mm, 1.171
mm, and 0.858 mm, respectively. These results confirm the method's potential
for reliable freehand 3D US reconstruction.

</details>


### [424] [HEADER: Hierarchical Robot Exploration via Attention-Based Deep Reinforcement Learning with Expert-Guided Reward](https://arxiv.org/abs/2510.15679)
*Yuhong Cao,Yizhuo Wang,Jingsong Liang,Shuhao Liao,Yifeng Zhang,Peizhuo Li,Guillaume Sartoretti*

Main category: cs.RO

TL;DR: HEADER是一种基于注意力的强化学习方法，结合分层图，能够高效地探索大规模环境。它通过新颖的社区算法构建全局图，并利用注意力网络进行多尺度推理，以做出最优的下一步视点决策。该方法在模拟和真实大规模场景中均表现出优越的可扩展性和效率。


<details>
  <summary>Details</summary>
Motivation: 在环境规模和探索效率方面，推动了基于学习的方法在机器人自主探索中的应用。

Method: 提出了一种名为HEADER的基于注意力的强化学习方法，结合分层图来高效探索大规模环境。该方法构建了分层地图表示，并设计了一种社区算法来构建和更新全局图，该图是全增量的、形状自适应的，并且具有线性复杂度。基于注意力网络，该方法在局部范围内对附近的信念进行精细推理，同时在全局范围内粗略利用远处的信息，从而能够做出考虑多尺度空间依赖性的下一步视点决策。此外，还引入了一种无参数的特权奖励，以避免手工设计奖励函数造成的训练目标偏差。

Result: 在模拟的大规模探索场景中，HEADER展现了比现有的大多数学习和非学习方法更好的可扩展性，并且在探索效率方面比最先进的基线方法有显著提高（最高可达20%）。在真实硬件上的部署和在复杂的大规模真实场景（包括300m*230m的校园环境）中的验证也取得了成功。

Conclusion: HEADER在提高机器人自主探索的环境规模和效率方面取得了显著进展。

Abstract: This work pushes the boundaries of learning-based methods in autonomous robot
exploration in terms of environmental scale and exploration efficiency. We
present HEADER, an attention-based reinforcement learning approach with
hierarchical graphs for efficient exploration in large-scale environments.
HEADER follows existing conventional methods to construct hierarchical
representations for the robot belief/map, but further designs a novel
community-based algorithm to construct and update a global graph, which remains
fully incremental, shape-adaptive, and operates with linear complexity.
Building upon attention-based networks, our planner finely reasons about the
nearby belief within the local range while coarsely leveraging distant
information at the global scale, enabling next-best-viewpoint decisions that
consider multi-scale spatial dependencies. Beyond novel map representation, we
introduce a parameter-free privileged reward that significantly improves model
performance and produces near-optimal exploration behaviors, by avoiding
training objective bias caused by handcrafted reward shaping. In simulated
challenging, large-scale exploration scenarios, HEADER demonstrates better
scalability than most existing learning and non-learning methods, while
achieving a significant improvement in exploration efficiency (up to 20%) over
state-of-the-art baselines. We also deploy HEADER on hardware and validate it
in complex, large-scale real-life scenarios, including a 300m*230m campus
environment.

</details>


### [425] [Few-Shot Demonstration-Driven Task Coordination and Trajectory Execution for Multi-Robot Systems](https://arxiv.org/abs/2510.15686)
*Taehyeon Kim,Vishnunandan L. N. Venkatesh,Byung-Cheol Min*

Main category: cs.RO

TL;DR: DDACE 是一个新颖的少样本学习框架，用于多机器人系统的空间和时间元素的集成。


<details>
  <summary>Details</summary>
Motivation: 传统学习演示方法需要大量数据，而 DDACE 通过结合时间图网络和高斯过程，将时间和空间方面解耦，从而显著减少了数据需求。

Method: DDACE 利用时间图网络学习与任务无关的时间排序，并使用高斯过程进行空间轨迹建模，以实现模块化和跨任务的泛化。

Result: 实验证明，DDACE 在少样本学习条件下成功实现了任务执行，并在动态和多样化的环境中有效泛化。

Conclusion: DDACE 的模块化架构在提高实际应用中多机器人系统的实用性和可扩展性方面具有巨大潜力。

Abstract: In this paper, we propose a novel few-shot learning framework for multi-robot
systems that integrate both spatial and temporal elements: Few-Shot
Demonstration-Driven Task Coordination and Trajectory Execution (DDACE). Our
approach leverages temporal graph networks for learning task-agnostic temporal
sequencing and Gaussian Processes for spatial trajectory modeling, ensuring
modularity and generalization across various tasks. By decoupling temporal and
spatial aspects, DDACE requires only a small number of demonstrations,
significantly reducing data requirements compared to traditional learning from
demonstration approaches. To validate our proposed framework, we conducted
extensive experiments in task environments designed to assess various aspects
of multi-robot coordination-such as multi-sequence execution, multi-action
dynamics, complex trajectory generation, and heterogeneous configurations. The
experimental results demonstrate that our approach successfully achieves task
execution under few-shot learning conditions and generalizes effectively across
dynamic and diverse settings. This work underscores the potential of modular
architectures in enhancing the practicality and scalability of multi-robot
systems in real-world applications. Additional materials are available at
https://sites.google.com/view/ddace.

</details>


### [426] [DexCanvas: Bridging Human Demonstrations and Robot Learning for Dexterous Manipulation](https://arxiv.org/abs/2510.15786)
*Xinyue Xu,Jieqiang Sun,Jing,Dai,Siyuan Chen,Lanjie Ma,Ke Sun,Bin Zhao,Jianbo Yuan,Yiwen Lu*

Main category: cs.RO

TL;DR: DexCanvas是一个包含7000小时真实世界数据和21种基本操作类型的大规模混合真实-合成人类操作数据集，可用于机器人操作学习、接触控制和技能迁移。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏大规模、系统化覆盖操作技能并包含物理验证接触标注的手操作数据集，阻碍了机器人操作学习、接触控制和技能迁移等领域的研究。

Method: 构建了一个包含7000小时真实世界数据和21种基本操作类型的大规模混合真实-合成人类操作数据集。该数据集结合了多视图RGB-D、高精度动作捕捉（MANO手部参数）和每帧接触点及物理一致的力学曲线。利用真实到模拟（real-to-sim）技术，通过强化学习训练驱动的MANO手策略，在物理模拟中复现人类演示，并推断产生观测到的物体运动的潜在接触力。

Result: DexCanvas是首个结合大规模真实演示、基于成熟分类法的系统化技能覆盖以及物理验证接触标注的操作数据集。

Conclusion: DexCanvas数据集能够促进机器人操作学习、接触控制和跨不同手部形态的技能迁移等领域的研究。

Abstract: We present DexCanvas, a large-scale hybrid real-synthetic human manipulation
dataset containing 7,000 hours of dexterous hand-object interactions seeded
from 70 hours of real human demonstrations, organized across 21 fundamental
manipulation types based on the Cutkosky taxonomy. Each entry combines
synchronized multi-view RGB-D, high-precision mocap with MANO hand parameters,
and per-frame contact points with physically consistent force profiles. Our
real-to-sim pipeline uses reinforcement learning to train policies that control
an actuated MANO hand in physics simulation, reproducing human demonstrations
while discovering the underlying contact forces that generate the observed
object motion. DexCanvas is the first manipulation dataset to combine
large-scale real demonstrations, systematic skill coverage based on established
taxonomies, and physics-validated contact annotations. The dataset can
facilitate research in robotic manipulation learning, contact-rich control, and
skill transfer across different hand morphologies.

</details>


### [427] [Dynamic Recalibration in LiDAR SLAM: Integrating AI and Geometric Methods with Real-Time Feedback Using INAF Fusion](https://arxiv.org/abs/2510.15803)
*Zahra Arjmandi,Gunho Sohn*

Main category: cs.RO

TL;DR: INAF利用AI和几何里程计融合LiDAR SLAM，提高了定位和3D建图的精度。


<details>
  <summary>Details</summary>
Motivation: 提升LiDAR SLAM的定位和3D建图精度。

Method: 提出Inferred Attention Fusion (INAF)模块，该模块利用AI和几何里程计，并根据环境反馈动态调整注意力权重。

Result: 在KITTI数据集上，INAF提高了系统的适应性和测量精度，从而提升了定位和3D建图的精度。

Conclusion: INAF融合技术能够提高SLAM系统的精度，有潜力增强复杂场景下的自主导航能力。

Abstract: This paper presents a novel fusion technique for LiDAR Simultaneous
Localization and Mapping (SLAM), aimed at improving localization and 3D mapping
using LiDAR sensor. Our approach centers on the Inferred Attention Fusion
(INAF) module, which integrates AI with geometric odometry. Utilizing the KITTI
dataset's LiDAR data, INAF dynamically adjusts attention weights based on
environmental feedback, enhancing the system's adaptability and measurement
accuracy. This method advances the precision of both localization and 3D
mapping, demonstrating the potential of our fusion technique to enhance
autonomous navigation systems in complex scenarios.

</details>
