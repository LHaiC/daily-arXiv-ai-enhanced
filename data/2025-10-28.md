<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 210]
- [cs.CL](#cs.CL) [Total: 114]
- [cs.AR](#cs.AR) [Total: 4]
- [eess.SY](#eess.SY) [Total: 26]
- [cs.AI](#cs.AI) [Total: 83]
- [cs.RO](#cs.RO) [Total: 73]
- [eess.SP](#eess.SP) [Total: 22]
- [cs.MA](#cs.MA) [Total: 8]
- [cs.DC](#cs.DC) [Total: 4]
- [cs.ET](#cs.ET) [Total: 2]
- [cs.SI](#cs.SI) [Total: 7]
- [cs.LG](#cs.LG) [Total: 214]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 14]
- [cs.GR](#cs.GR) [Total: 3]
- [quant-ph](#quant-ph) [Total: 54]
- [cs.GT](#cs.GT) [Total: 3]
- [physics.app-ph](#physics.app-ph) [Total: 1]
- [cs.LO](#cs.LO) [Total: 5]
- [cs.NE](#cs.NE) [Total: 6]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 42]
- [cs.DS](#cs.DS) [Total: 11]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Diagnosing Bottlenecks in Data Visualization Understanding by Vision-Language Models](https://arxiv.org/abs/2510.21740)
*Alexa R. Tartaglini,Satchel Grant,Daniel Wurgaft,Christopher Potts,Judith E. Fan*

Main category: cs.CV

TL;DR: VLMs在理解数据可视化方面存在不足，FUGU任务套件旨在诊断其失败原因，研究发现错误源于视觉-语言信息传递，而非视觉编码或语言处理本身，并指出当前VLM的架构限制。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型（VLMs）在理解数据可视化方面存在不足，但失败原因尚不明确，需要精确诊断。

Method: 开发了FUGU任务套件，用于精确表征数据可视化理解中的潜在困难点（如数据点位置、距离、摘要统计等）。利用FUGU评估了三个广泛使用的VLMs，并结合激活修复和线性探针技术追踪信息流，以诊断错误来源。

Result: 部分模型无法正确生成数据点坐标，这些初始错误常导致最终响应错误。当提供正确坐标时，模型性能显著提升。即使模型响应错误，其潜在表示中仍可读出正确坐标，表明错误源于视觉-语言交互。然而，提供正确坐标对需要跨多个数据点提取统计关系的任务反而会降低性能。在FUGU上进行微调也未能达到最佳性能。

Conclusion: 当前VLMs的架构限制可能对可靠的数据可视化理解构成重大挑战，特别是信息在视觉编码器中正确提取后，在视觉-语言交互环节出现的错误是主要问题。

Abstract: Data visualizations are vital components of many scientific articles and news
stories. Current vision-language models (VLMs) still struggle on basic data
visualization understanding tasks, but the causes of failure remain unclear.
Are VLM failures attributable to limitations in how visual information in the
data visualization is encoded, how information is transferred between the
vision and language modules, or how information is processed within the
language module? We developed FUGU, a suite of data visualization understanding
tasks, to precisely characterize potential sources of difficulty (e.g.,
extracting the position of data points, distances between them, and other
summary statistics). We used FUGU to investigate three widely used VLMs. To
diagnose the sources of errors produced by these models, we used activation
patching and linear probes to trace information flow through models across a
variety of prompting strategies. We found that some models fail to generate the
coordinates of individual data points correctly, and these initial errors often
lead to erroneous final responses. When these models are provided with the
correct coordinates, performance improves substantially. Moreover, even when
the model generates an incorrect response, the correct coordinates can be
successfully read out from the latent representations in the vision encoder,
suggesting that the source of these errors lies in the vision-language handoff.
We further found that while providing correct coordinates helps with tasks
involving one or a small number of data points, it generally worsens
performance for tasks that require extracting statistical relationships across
many data points. Fine-tuning models on FUGU also fails to yield ceiling
performance. These findings point to architectural constraints in current VLMs
that might pose significant challenges for reliable data visualization
understanding.

</details>


### [2] [Agro-Consensus: Semantic Self-Consistency in Vision-Language Models for Crop Disease Management in Developing Countries](https://arxiv.org/abs/2510.21757)
*Mihir Gupta,Pratik Desai,Ross Greer*

Main category: cs.CV

TL;DR: 通过使用语义聚类和人工反馈，提出了一种经济高效的框架，以提高农业图像字幕中视觉语言模型（VLM）的可靠性，从而在诊断、症状、治疗和预防方面提供更准确的建议。


<details>
  <summary>Details</summary>
Motivation: 开发中国家在农业病虫害管理方面面临挑战，因为缺乏专家、互联网连接不可靠以及成本高昂，这阻碍了大型人工智能系统的部署。

Method: 提出了一种经济高效的自洽性框架，采用语义聚类和轻量级嵌入模型来对候选字幕进行分组，并通过基于余弦相似度的共识来选择最连贯的字幕。还包含一个由用户确认作物类型的人工在回路（HITL）组件，以过滤错误。

Result: 在 PlantVillage 数据集上，使用 3B 参数的 PaliGemma 模型，该框架在 800 张作物病害图像上进行了评估。单集群共识方法在 10 次候选生成下达到了 83.1% 的准确率，高于基线 77.5%。多集群方法在任何前 4 个候选集群中找到正确响应的准确率达到 94.0%，优于基线 88.5%。

Conclusion: 所提出的框架通过语义聚类和人工在回路验证，有效地提高了农业图像字幕的准确性和可靠性，为资源有限的环境提供了可行的解决方案。

Abstract: Agricultural disease management in developing countries such as India, Kenya,
and Nigeria faces significant challenges due to limited access to expert plant
pathologists, unreliable internet connectivity, and cost constraints that
hinder the deployment of large-scale AI systems. This work introduces a
cost-effective self-consistency framework to improve vision-language model
(VLM) reliability for agricultural image captioning. The proposed method
employs semantic clustering, using a lightweight (80MB) pre-trained embedding
model to group multiple candidate responses. It then selects the most coherent
caption -- containing a diagnosis, symptoms, analysis, treatment, and
prevention recommendations -- through a cosine similarity-based consensus. A
practical human-in-the-loop (HITL) component is incorporated, wherein user
confirmation of the crop type filters erroneous generations, ensuring
higher-quality input for the consensus mechanism. Applied to the publicly
available PlantVillage dataset using a fine-tuned 3B-parameter PaliGemma model,
our framework demonstrates improvements over standard decoding methods.
Evaluated on 800 crop disease images with up to 21 generations per image, our
single-cluster consensus method achieves a peak accuracy of 83.1% with 10
candidate generations, compared to the 77.5% baseline accuracy of greedy
decoding. The framework's effectiveness is further demonstrated when
considering multiple clusters; accuracy rises to 94.0% when a correct response
is found within any of the top four candidate clusters, outperforming the 88.5%
achieved by a top-4 selection from the baseline.

</details>


### [3] [Proportion and Perspective Control for Flow-Based Image Generation](https://arxiv.org/abs/2510.21763)
*Julien Boudier,Hugo Caselles-Dupré*

Main category: cs.CV

TL;DR: 现代文生图模型在图像质量上表现优异，但在空间结构和几何形状控制方面能力有限。本文提出了两种专用的ControlNets来增强艺术控制能力：比例ControlNet（使用边界框控制物体位置和缩放）和透视ControlNet（使用消失线控制三维场景几何）。


<details>
  <summary>Details</summary>
Motivation: 解决现代文生图模型在空间和几何结构控制方面的局限性。

Method: 提出并评估了两种ControlNets：比例ControlNet（基于边界框）和透视ControlNet（基于消失线）。同时，利用视觉-语言模型和专门的条件图像合成算法支持这些模块的训练。

Result: 实验表明，这两种ControlNet模块都能有效地提供控制，但在复杂约束条件下存在局限性。

Conclusion: 比例ControlNet和透视ControlNet为文生图模型提供了有效的空间和几何结构控制，但需要进一步改进以处理复杂场景。

Abstract: While modern text-to-image diffusion models generate high-fidelity images,
they offer limited control over the spatial and geometric structure of the
output. To address this, we introduce and evaluate two ControlNets specialized
for artistic control: (1) a proportion ControlNet that uses bounding boxes to
dictate the position and scale of objects, and (2) a perspective ControlNet
that employs vanishing lines to control the 3D geometry of the scene. We
support the training of these modules with data pipelines that leverage
vision-language models for annotation and specialized algorithms for
conditioning image synthesis. Our experiments demonstrate that both modules
provide effective control but exhibit limitations with complex constraints.
Both models are released on HuggingFace:
https://huggingface.co/obvious-research

</details>


### [4] [Multi-Agent Pose Uncertainty: A Differentiable Rendering Cramér-Rao Bound](https://arxiv.org/abs/2510.21785)
*Arun Muthukkumar*

Main category: cs.CV

TL;DR: 该研究提出了一种计算相机位姿估计不确定性的新方法，利用可微分渲染器推导出一种类似Cramér-Rao的边界，可扩展到多代理设置，并可用于合作感知和新视图合成等下游任务。


<details>
  <summary>Details</summary>
Motivation: 计算机视觉和机器人领域对位姿估计的需求很大，但现有方法在密集或学习模型下缺乏严格的不确定性量化。

Method: 将可微分渲染器视为测量函数，推导出相机位姿估计协方差的闭式下界，并考虑了渲染过程的感知。通过在流形上对位姿扰动进行线性化，得到类似Cramér-Rao的边界。

Result: 该方法可自然扩展到多代理设置，通过融合多个相机的Fisher信息来实现。它还可以用于合作感知和新视图合成，而无需明确的关键点对应。

Conclusion: 该研究提出了一种新的、具有统计意义的相机位姿不确定性量化方法，该方法具有理论基础，易于扩展，并具有实际应用价值。

Abstract: Pose estimation is essential for many applications within computer vision and
robotics. Despite its uses, few works provide rigorous uncertainty
quantification for poses under dense or learned models. We derive a closed-form
lower bound on the covariance of camera pose estimates by treating a
differentiable renderer as a measurement function. Linearizing image formation
with respect to a small pose perturbation on the manifold yields a render-aware
Cram\'er-Rao bound. Our approach reduces to classical bundle-adjustment
uncertainty, ensuring continuity with vision theory. It also naturally extends
to multi-agent settings by fusing Fisher information across cameras. Our
statistical formulation has downstream applications for tasks such as
cooperative perception and novel view synthesis without requiring explicit
keypoint correspondences.

</details>


### [5] [H2OFlow: Grounding Human-Object Affordances with 3D Generative Models and Dense Diffused Flows](https://arxiv.org/abs/2510.21769)
*Harry Zhang,Luca Carlone*

Main category: cs.CV

TL;DR: H2OFlow是一个新框架，仅使用合成数据通过密集3D流学习3D人类-物体交互（HOI）的接触、方向和空间占用，并在现实世界物体上超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前的人类-物体交互（HOI）理解方法依赖于劳动密集型、手动标记的数据集，并且在3D可供性理解方面仅限于基于接触的分析，忽略了方向和空间占用等方面。

Method: H2OFlow框架使用仅从3D生成模型生成的合成数据，通过在点云上运行的密集扩散过程学习密集3D流表示，以学习3D HOI的可供性。

Result: H2OFlow能够全面学习3D HOI的可供性，包括接触、方向和空间占用，并且在现实世界物体上表现出良好的泛化能力，在3D可供性建模方面优于依赖手动注释或基于网格表示的现有方法。

Conclusion: H2OFlow框架通过仅使用合成数据和密集3D流表示，克服了现有HOI可供性理解方法的局限性，并在3D可供性建模方面取得了先进的性能。

Abstract: Understanding how humans interact with the surrounding environment, and
specifically reasoning about object interactions and affordances, is a critical
challenge in computer vision, robotics, and AI. Current approaches often depend
on labor-intensive, hand-labeled datasets capturing real-world or simulated
human-object interaction (HOI) tasks, which are costly and time-consuming to
produce. Furthermore, most existing methods for 3D affordance understanding are
limited to contact-based analysis, neglecting other essential aspects of
human-object interactions, such as orientation (\eg, humans might have a
preferential orientation with respect certain objects, such as a TV) and
spatial occupancy (\eg, humans are more likely to occupy certain regions around
an object, like the front of a microwave rather than its back). To address
these limitations, we introduce \emph{H2OFlow}, a novel framework that
comprehensively learns 3D HOI affordances -- encompassing contact, orientation,
and spatial occupancy -- using only synthetic data generated from 3D generative
models. H2OFlow employs a dense 3D-flow-based representation, learned through a
dense diffusion process operating on point clouds. This learned flow enables
the discovery of rich 3D affordances without the need for human annotations.
Through extensive quantitative and qualitative evaluations, we demonstrate that
H2OFlow generalizes effectively to real-world objects and surpasses prior
methods that rely on manual annotations or mesh-based representations in
modeling 3D affordance.

</details>


### [6] [Improving the Physics of Video Generation with VJEPA-2 Reward Signal](https://arxiv.org/abs/2510.21840)
*Jianhao Yuan,Xiaofeng Zhang,Felix Friedrich,Nicolas Beltran-Velez,Melissa Hall,Reyhane Askari-Hemmat,Xiaochuang Han,Nicolas Ballas,Michal Drozdzal,Adriana Romero-Soriano*

Main category: cs.CV

TL;DR: SSL预训练模型VJEPA-2可提升视频生成模型约6%的物理合理性。


<details>
  <summary>Details</summary>
Motivation: 现有技术状态的视频生成模型在物理理解方面存在局限性，常常生成不合理的视频。虽然视觉真实性不代表物理理解，但直觉物理理解已在自然视频的SSL预训练中出现。本报告旨在探索如何利用基于SSL的视频世界模型来提高视频生成模型的物理合理性。

Method: 在最先进的视频生成模型MAGI-1的基础上，结合新提出的VJEPA-2模型来指导生成过程，并使用VJEPA-2作为奖励信号。

Result: 通过将VJEPA-2作为奖励信号，视频生成模型的物理合理性得到了约6%的提升。

Conclusion: SSL预训练模型VJEPA-2可以作为奖励信号，有效提升现有视频生成模型（如MAGI-1）的物理合理性。

Abstract: This is a short technical report describing the winning entry of the
PhysicsIQ Challenge, presented at the Perception Test Workshop at ICCV 2025.
State-of-the-art video generative models exhibit severely limited physical
understanding, and often produce implausible videos. The Physics IQ benchmark
has shown that visual realism does not imply physics understanding. Yet,
intuitive physics understanding has shown to emerge from SSL pretraining on
natural videos. In this report, we investigate whether we can leverage
SSL-based video world models to improve the physics plausibility of video
generative models. In particular, we build ontop of the state-of-the-art video
generative model MAGI-1 and couple it with the recently introduced Video Joint
Embedding Predictive Architecture 2 (VJEPA-2) to guide the generation process.
We show that by leveraging VJEPA-2 as reward signal, we can improve the physics
plausibility of state-of-the-art video generative models by ~6%.

</details>


### [7] [OCR-Quality: A Human-Annotated Dataset for OCR Quality Assessment](https://arxiv.org/abs/2510.21774)
*Yulong Zhang*

Main category: cs.CV

TL;DR: OCR-Quality 是一个包含 1000 页 PDF 文档及其 OCR 质量评估分数的数据集，旨在用于开发和评估 OCR 质量评估方法。


<details>
  <summary>Details</summary>
Motivation: 现有 OCR 质量评估方法缺乏针对真实世界场景的可靠评估基准，需要一个包含多样化文档和人工标注质量分数的数据集来解决此问题。

Method: 收集了来自学术论文、教科书、电子书和多语言文档的 1000 页 PDF 文档，将其转换为 300 DPI 的 PNG 图像，并使用最先进的视觉语言模型 (VLMs) 进行处理。然后，人工标注这些文档的 OCR 质量，评分系统分为四个级别：1（优秀）、2（良好）、3（一般）和 4（差）。

Result: 创建了一个名为 OCR-Quality 的数据集，其中包含 1000 页图像及其对应的人工标注的 OCR 质量分数，涵盖了不同难度级别的各种情况。

Conclusion: OCR-Quality 数据集填补了真实世界 OCR 质量评估的空白，为训练和评估 OCR 验证系统提供了一个有价值的基准。

Abstract: We present OCR-Quality, a comprehensive human-annotated dataset designed for
evaluating and developing OCR quality assessment methods. The dataset consists
of 1,000 PDF pages converted to PNG images at 300 DPI, sampled from diverse
real-world scenarios, including academic papers, textbooks, e-books, and
multilingual documents. Each document has been processed using state-of-the-art
Vision-Language Models (VLMs) and manually annotated with quality scores using
a 4-level scoring system (1: Excellent, 2: Good, 3: Fair, 4: Poor). The dataset
includes detailed source information, annotation guidelines, and representative
cases across various difficulty levels. OCR-Quality addresses the critical need
for reliable OCR quality assessment in real-world applications and provides a
valuable benchmark for training and evaluating OCR verification systems. The
dataset is publicly available at
https://huggingface.co/datasets/Aslan-mingye/OCR-Quality .

</details>


### [8] [LSF-Animation: Label-Free Speech-Driven Facial Animation via Implicit Feature Representation](https://arxiv.org/abs/2510.21864)
*Xin Lu,Chuanqing Zhuang,Chenxi Jin,Zhengda Lu,Yiqun Wang,Wu Liu,Jun Xiao*

Main category: cs.CV

TL;DR: LSF-Animation框架通过隐式提取语音中的情感信息和从面部网格中捕获身份特征，实现了无需手动标签即可泛化到未见过的说话人和情感状态的3D面部动画生成，并通过引入分层交互融合块（HIFB）有效融合了情感、运动和身份线索，实验证明其在情感表达、身份泛化和动画真实性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有语音驱动的3D面部动画方法在生成特定身份和情感的动画时，依赖显式的一热编码，限制了对未见过的说话人的泛化能力，并且忽略了语音中固有的情感线索，影响了动画的自然度和适应性。

Method: 提出LSF-Animation框架，该框架隐式地从语音中提取情感信息，并从静态的面部网格中捕获身份特征，无需手动标签。引入分层交互融合块（HIFB），利用融合令牌整合双重Transformer特征，以更有效地融合情感、运动和身份相关的线索。

Result: 在3DMEAD数据集上的广泛实验表明，所提出的方法在情感表达、身份泛化和动画真实性方面优于现有的最先进方法。

Conclusion: LSF-Animation框架通过隐式地从语音和静态面部网格中提取情感和身份信息，并结合HIFB模块，成功实现了对未见过的说话人和情感状态的3D面部动画生成，提高了动画的自然度和泛化能力。

Abstract: Speech-driven 3D facial animation has attracted increasing interest since its
potential to generate expressive and temporally synchronized digital humans.
While recent works have begun to explore emotion-aware animation, they still
depend on explicit one-hot encodings to represent identity and emotion with
given emotion and identity labels, which limits their ability to generalize to
unseen speakers. Moreover, the emotional cues inherently present in speech are
often neglected, limiting the naturalness and adaptability of generated
animations. In this work, we propose LSF-Animation, a novel framework that
eliminates the reliance on explicit emotion and identity feature
representations. Specifically, LSF-Animation implicitly extracts emotion
information from speech and captures the identity features from a neutral
facial mesh, enabling improved generalization to unseen speakers and emotional
states without requiring manual labels. Furthermore, we introduce a
Hierarchical Interaction Fusion Block (HIFB), which employs a fusion token to
integrate dual transformer features and more effectively integrate emotional,
motion-related and identity-related cues. Extensive experiments conducted on
the 3DMEAD dataset demonstrate that our method surpasses recent
state-of-the-art approaches in terms of emotional expressiveness, identity
generalization, and animation realism. The source code will be released at:
https://github.com/Dogter521/LSF-Animation.

</details>


### [9] [Face-MakeUpV2: Facial Consistency Learning for Controllable Text-to-Image Generation](https://arxiv.org/abs/2510.21775)
*Dawei Dai,Yinxiu Zhou,Chenghang Li,Guolai Jiang,Chengfang Zhang*

Main category: cs.CV

TL;DR: Face-MakeUpV2通过结合3D渲染、全局面部特征通道、语义对齐和感知损失，解决了现有文本到图像模型在处理局部语义指令时面部属性泄露和物理一致性不足的问题，并在保持面部ID和物理一致性方面取得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像模型在生成面部图像时，存在面部属性泄露和物理一致性不足的问题，尤其是在响应局部语义指令时。

Method: Face-MakeUpV2模型：1.构建了包含约一百万图像-文本-掩码对的数据集FaceCaptionMask-1M，为局部语义指令提供空间监督。2.使用预训练的文本到图像模型作为骨干，并引入3D面部渲染通道（整合物理特征）和全局面部特征通道。3.提出语义对齐和感知损失两个优化目标，以解决属性泄露和保持ID一致性。

Result: Face-MakeUpV2在保持面部ID和物理一致性方面取得了最佳整体性能。

Conclusion: Face-MakeUpV2在可靠、可控的面部编辑方面具有实际应用潜力。

Abstract: In facial image generation, current text-to-image models often suffer from
facial attribute leakage and insufficient physical consistency when responding
to local semantic instructions. In this study, we propose Face-MakeUpV2, a
facial image generation model that aims to maintain the consistency of face ID
and physical characteristics with the reference image. First, we constructed a
large-scale dataset FaceCaptionMask-1M comprising approximately one million
image-text-masks pairs that provide precise spatial supervision for the local
semantic instructions. Second, we employed a general text-to-image pretrained
model as the backbone and introduced two complementary facial information
injection channels: a 3D facial rendering channel to incorporate the physical
characteristics of the image and a global facial feature channel. Third, we
formulated two optimization objectives for the supervised learning of our
model: semantic alignment in the model's embedding space to mitigate the
attribute leakage problem and perceptual loss on facial images to preserve ID
consistency. Extensive experiments demonstrated that our Face-MakeUpV2 achieves
best overall performance in terms of preserving face ID and maintaining
physical consistency of the reference images. These results highlight the
practical potential of Face-MakeUpV2 for reliable and controllable facial
editing in diverse applications.

</details>


### [10] [Ageing Drift in Binary Face Templates: A Bits-per-Decade Analysis](https://arxiv.org/abs/2510.21778)
*Abdelilah Ganmati,Karim Afdel,Lahcen Koutti*

Main category: cs.CV

TL;DR: 研究紧凑型二元人脸模板的纵向稳定性，并直接以每十年比特数来量化老化漂移。


<details>
  <summary>Details</summary>
Motivation: 量化紧凑型二元人脸模板的纵向稳定性，并直接以每十年比特数来量化老化漂移。

Method: 使用PCA-ITQ将现代人脸CNN的浮点嵌入压缩成64位和128位代码。对于AgeDB中至少有三张不同年龄人脸的每个人，形成所有真实配对，并拟合一个每人脸的线性模型，将汉明距离与绝对年龄差距相关联。

Result: 在566个人的研究中，64位模板的中位斜率为每十年1.357比特，128位模板的中位斜率为每十年2.571比特。这些斜率与代码长度成正比，表明在固定决策阈值下，较短的代码本身就具有更强的年龄稳定性。

Conclusion: 漂移与代码长度成正比，表明在固定决策阈值下，较短的代码本身就具有更强的年龄稳定性。研究结果对智能卡和卡上匹配的部署具有启示意义，包括周期性重新注册和针对经验上不稳定的比特位置的定向奇偶校验等简单缓解措施。

Abstract: We study the longitudinal stability of compact binary face templates and
quantify ageing drift directly in bits per decade. Float embeddings from a
modern face CNN are compressed with PCA-ITQ into 64- and 128-bit codes. For
each identity in AgeDB with at least three distinct ages, we form all genuine
pairs and fit a per-identity linear model of Hamming distance versus absolute
age gap. Across 566 identities, the median slope is 1.357 bits per decade for
64-bit templates and 2.571 bits per decade for 128-bit templates, with tight
non-parametric 95 percent bootstrap confidence intervals. The distributions are
predominantly positive, indicating a small but systematic increase in
intra-class distance over time. Because drift scales with code length, shorter
codes are inherently more age-stable at a fixed decision threshold. We connect
these slopes to operating characteristics by reporting EER and TPR at FAR = 1
percent in three age bins. We discuss implications for smart-card and
match-on-card deployments, including simple mitigations such as periodic
re-enrolment and targeted parity on empirically unstable bit positions. Code
and CSV artifacts are provided to support reproducibility.

</details>


### [11] [MOGRAS: Human Motion with Grasping in 3D Scenes](https://arxiv.org/abs/2510.22199)
*Kunal Bhosikar,Siddharth Katageri,Vivek Madhavaram,Kai Han,Charu Sharma*

Main category: cs.CV

TL;DR: MOGRAS是一个包含大规模人体抓取动作和3D室内场景的大型数据集，旨在弥合现有方法在生成连贯且场景感知的人体抓取动作方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成与物体交互的逼真全身运动方面存在不足，尤其是在精细抓取任务中，往往忽略了周围的3D场景，因此需要一个能够生成既符合物理规律又考虑场景信息的人体抓取动作的方法。

Method: 提出MOGRAS数据集，包含抓取前的全身行走运动和最终的抓取姿势，并在此基础上提出一种简单有效的方法来改进现有方法，使其能够适应3D场景。

Result: 通过广泛的定量和定性实验，验证了MOGRAS数据集的有效性，并展示了所提出方法在场景感知生成方面的显著改进。

Conclusion: MOGRAS数据集和所提出的方法能够生成更逼真的人体-场景交互，为相关应用领域（如机器人、虚拟现实和人机交互）的发展铺平了道路。

Abstract: Generating realistic full-body motion interacting with objects is critical
for applications in robotics, virtual reality, and human-computer interaction.
While existing methods can generate full-body motion within 3D scenes, they
often lack the fidelity for fine-grained tasks like object grasping.
Conversely, methods that generate precise grasping motions typically ignore the
surrounding 3D scene. This gap, generating full-body grasping motions that are
physically plausible within a 3D scene, remains a significant challenge. To
address this, we introduce MOGRAS (Human MOtion with GRAsping in 3D Scenes), a
large-scale dataset that bridges this gap. MOGRAS provides pre-grasping
full-body walking motions and final grasping poses within richly annotated 3D
indoor scenes. We leverage MOGRAS to benchmark existing full-body grasping
methods and demonstrate their limitations in scene-aware generation.
Furthermore, we propose a simple yet effective method to adapt existing
approaches to work seamlessly within 3D scenes. Through extensive quantitative
and qualitative experiments, we validate the effectiveness of our dataset and
highlight the significant improvements our proposed method achieves, paving the
way for more realistic human-scene interactions.

</details>


### [12] [Bridging Accuracy and Interpretability: Deep Learning with XAI for Breast Cancer Detection](https://arxiv.org/abs/2510.21780)
*Bishal Chhetri,B. V. Rathish Kumar*

Main category: cs.CV

TL;DR: 本研究提出了一个可解释的深度学习框架，利用乳腺肿块细针穿刺（FNA）图像的量化特征，实现了早期乳腺癌检测。


<details>
  <summary>Details</summary>
Motivation: 为了解决深度学习模型在临床应用中因“黑箱”性质而缺乏可解释性的问题，本研究旨在开发一个既有高预测准确性又具备可解释性的深度学习框架，以促进其在临床诊断中的应用。

Method: 研究提出了一种基于ReLU激活、Adam优化器和二元交叉熵损失的深度神经网络模型，并结合了SHAP和LIME等模型无关的可解释人工智能技术来生成特征层面的归因和可视化解释。

Result: 所提出的深度学习模型在乳腺癌早期检测任务中取得了优于现有文献报道的基准和多种经典算法（如逻辑回归、随机森林等）的分类性能，准确率达到0.992，精确率1.000，召回率0.977，F1分数0.988。可解释性分析表明，细胞核的凹点特征对分类任务具有最显著的积极影响。

Conclusion: 本研究成功构建了一个兼具高精度和可解释性的深度学习框架，用于早期乳腺癌检测。通过SHAP和LIME等技术提供的特征归因，不仅提升了模型的临床可信度，还揭示了细胞核凹点特征的关键作用，为改进乳腺癌的诊断和治疗提供了有价值的见解。

Abstract: In this study, we present an interpretable deep learning framework for the
early detection of breast cancer using quantitative features extracted from
digitized fine needle aspirate (FNA) images of breast masses. Our deep neural
network, using ReLU activations, the Adam optimizer, and a binary cross-entropy
loss, delivers state-of-the-art classification performance, achieving an
accuracy of 0.992, precision of 1.000, recall of 0.977, and an F1 score of
0.988. These results substantially exceed the benchmarks reported in the
literature. We evaluated the model under identical protocols against a suite of
well-established algorithms (logistic regression, decision trees, random
forests, stochastic gradient descent, K-nearest neighbors, and XGBoost) and
found the deep model consistently superior on the same metrics. Recognizing
that high predictive accuracy alone is insufficient for clinical adoption due
to the black-box nature of deep learning models, we incorporated model-agnostic
Explainable AI techniques such as SHAP and LIME to produce feature-level
attributions and human-readable visualizations. These explanations quantify the
contribution of each feature to individual predictions, support error analysis,
and increase clinician trust, thus bridging the gap between performance and
interpretability for real-world clinical use. The concave points feature of the
cell nuclei is found to be the most influential feature positively impacting
the classification task. This insight can be very helpful in improving the
diagnosis and treatment of breast cancer by highlighting the key
characteristics of breast tumor.

</details>


### [13] [VoMP: Predicting Volumetric Mechanical Property Fields](https://arxiv.org/abs/2510.22975)
*Rishit Dagli,Donglai Xiang,Vismay Modi,Charles Loop,Clement Fuji Tsang,Anka He Chen,Anita Hu,Gavriel State,David I. W. Levin,Maria Shugrina*

Main category: cs.CV

TL;DR: VoMP是一个用于预测3D物体体积材料属性（杨氏模量、泊松比、密度）的AI模型，它使用多视图特征和几何Transformer，能够生成物理上合理的材料属性。


<details>
  <summary>Details</summary>
Motivation: 手动制作3D物体的空间变化力学属性既耗时又困难，需要一个自动化的方法来预测这些属性。

Method: VoMP通过聚合多视图特征并使用几何Transformer来预测每个体素的材料潜在编码。这些潜在编码被约束在一个由真实世界数据学习到的物理上可行的材料流形上，以确保输出的有效性。该模型还可以从分割的3D数据集、材料数据库和视觉语言模型中生成训练数据。

Result: VoMP能够准确地估计出3D物体的体积材料属性，在准确性和速度上都远超现有的方法。

Conclusion: VoMP成功地实现了对3D物体体积材料属性的自动化预测，并在准确性和效率方面取得了显著的进步，为物理仿真提供了更便捷的解决方案。

Abstract: Physical simulation relies on spatially-varying mechanical properties, often
laboriously hand-crafted. VoMP is a feed-forward method trained to predict
Young's modulus ($E$), Poisson's ratio ($\nu$), and density ($\rho$) throughout
the volume of 3D objects, in any representation that can be rendered and
voxelized. VoMP aggregates per-voxel multi-view features and passes them to our
trained Geometry Transformer to predict per-voxel material latent codes. These
latents reside on a manifold of physically plausible materials, which we learn
from a real-world dataset, guaranteeing the validity of decoded per-voxel
materials. To obtain object-level training data, we propose an annotation
pipeline combining knowledge from segmented 3D datasets, material databases,
and a vision-language model, along with a new benchmark. Experiments show that
VoMP estimates accurate volumetric properties, far outperforming prior art in
accuracy and speed.

</details>


### [14] [EdgeSync: Accelerating Edge-Model Updates for Data Drift through Adaptive Continuous Learning](https://arxiv.org/abs/2510.21781)
*Runchu Donga,Peng Zhao,Guiqin Wang,Nan Qi,Jie Lin*

Main category: cs.CV

TL;DR: EdgeSync 通过优化样本过滤和动态训练管理来提高边缘视频分析模型的准确性和及时性。


<details>
  <summary>Details</summary>
Motivation: 边缘设备上的模型因数据分布变化而导致准确性下降，现有云端再训练方法存在计算密集和模型不匹配的问题。

Method: EdgeSync 提出了一种高效的边缘模型更新方法，通过结合时效性和推理结果来增强样本过滤，并利用动态训练管理模块优化更新时机和顺序。

Result: 在真实数据集上的评估显示，EdgeSync 比现有方法提高了约 3.4% 的准确率，比传统方法提高了约 10%。

Conclusion: EdgeSync 是一种有效的边缘模型更新方法，能够提高准确性和及时性，优于现有方法。

Abstract: Real-time video analytics systems typically deploy lightweight models on edge
devices to reduce latency. However, the distribution of data features may
change over time due to various factors such as changing lighting and weather
conditions, leading to decreased model accuracy. Recent frameworks try to
address this issue by leveraging remote servers to continuously train and adapt
lightweight edge models using more complex models in the cloud. Despite these
advancements, existing methods face two key challenges: first, the retraining
process is compute-intensive, causing significant delays in model updates;
second, the new model may not align well with the evolving data distribution of
the current video stream. To address these challenges, we introduce EdgeSync,
an efficient edge-model updating approach that enhances sample filtering by
incorporating timeliness and inference results, thus ensuring training samples
are more relevant to the current video content while reducing update delays.
Additionally, EdgeSync features a dynamic training management module that
optimizes the timing and sequencing of model updates to improve their
timeliness. Evaluations on diverse and complex real-world datasets demonstrate
that EdgeSync improves accuracy by approximately 3.4% compared to existing
methods and by about 10% compared to traditional approaches.

</details>


### [15] [Yesnt: Are Diffusion Relighting Models Ready for Capture Stage Compositing? A Hybrid Alternative to Bridge the Gap](https://arxiv.org/abs/2510.23494)
*Elisabeth Jüttner,Leona Krath,Stefan Korfhage,Hannah Dröge,Matthias B. Hullin,Markus Plack*

Main category: cs.CV

TL;DR: 本研究提出一种混合式光照重构框架，用于解决体积视频的暂时性稳定性和生产就绪性问题。


<details>
  <summary>Details</summary>
Motivation: 现有体积视频光照重构方法在处理序列时存在随机噪声和不稳定问题，而视频扩散模型受限于内存和规模。

Method: 该框架结合了基于扩散模型的材质先验知识、时间正则化以及物理驱动的渲染。它利用多帧的材质属性估计，通过光流引导正则化来聚合得到时间上一致的着色分量。对于阴影和反射等间接光照效果，方法提取了高斯不透明度场的网格代理，并在标准图形管线中进行渲染。

Result: 与仅使用扩散模型的方法相比，该混合方法在序列上实现了更稳定的光照重构，并且能够处理比视频扩散模型更长的视频片段。

Conclusion: 混合方法将学习到的先验知识与物理约束相结合，是实现生产就绪的体积视频光照重构的可行途径。

Abstract: Volumetric video relighting is essential for bringing captured performances
into virtual worlds, but current approaches struggle to deliver temporally
stable, production-ready results. Diffusion-based intrinsic decomposition
methods show promise for single frames, yet suffer from stochastic noise and
instability when extended to sequences, while video diffusion models remain
constrained by memory and scale. We propose a hybrid relighting framework that
combines diffusion-derived material priors with temporal regularization and
physically motivated rendering. Our method aggregates multiple stochastic
estimates of per-frame material properties into temporally consistent shading
components, using optical-flow-guided regularization. For indirect effects such
as shadows and reflections, we extract a mesh proxy from Gaussian Opacity
Fields and render it within a standard graphics pipeline. Experiments on real
and synthetic captures show that this hybrid strategy achieves substantially
more stable relighting across sequences than diffusion-only baselines, while
scaling beyond the clip lengths feasible for video diffusion. These results
indicate that hybrid approaches, which balance learned priors with physically
grounded constraints, are a practical step toward production-ready volumetric
video relighting.

</details>


### [16] [Promptable Fire Segmentation: Unleashing SAM2's Potential for Real-Time Mobile Deployment with Strategic Bounding Box Guidance](https://arxiv.org/abs/2510.21782)
*Emmanuel U. Ugwu,Zhang Xinming*

Main category: cs.CV

TL;DR: 本文首次全面评估了SAM2系列模型在火灾分割任务上的表现，并着重研究了用于增强部署可行性的边界框提示策略。


<details>
  <summary>Details</summary>
Motivation: 火灾分割因火焰边界不规则、边缘半透明及亮度变化剧烈等特点，在计算机视觉领域仍具挑战性。尽管SAM系列模型泛化能力强，但在移动端部署下的火灾分割效果尚待探索。

Method: 系统评估了四种SAM2.1变体（tiny, small, base_plus, large）以及面向移动端的TinySAM和MobileSAM，在三个火灾数据集上使用了多种提示策略（自动、单点、点+负点、多点、边界框、边界框+点）进行评估。

Result: 实验结果显示，边界框提示策略优于自动和单点提示。其中，Box+MP在Khan数据集上取得了最高的mIoU（0.64）和Dice系数（0.75）。TinySAM和MobileSAM等轻量化模型在降低成本方面更具优势，适用于延迟可容忍的边缘场景。

Conclusion: 本研究为在火灾监控系统中部署可提示分割模型提供了关键见解，并为领域特定SAM应用的未来研究奠定了基准。

Abstract: Fire segmentation remains a critical challenge in computer vision due to
flames' irregular boundaries, translucent edges, and highly variable
intensities. While the Segment Anything Models (SAM and SAM2) have demonstrated
impressive cross-domain generalization capabilities, their effectiveness in
fire segmentation -- particularly under mobile deployment constraints --
remains largely unexplored. This paper presents the first comprehensive
evaluation of SAM2 variants for fire segmentation, focusing on bounding box
prompting strategies to enhance deployment feasibility. We systematically
evaluate four SAM2.1 variants (tiny, small, base_plus, large) alongside
mobile-oriented variants (TinySAM, MobileSAM) across three fire datasets using
multiple prompting strategies: automatic, single positive point (SP), single
positive point + single negative point (SP+SN), multiple positive points (MP),
bounding box (Box), and hybrid variants (Box+SP and Box+MP). Our experimental
results demonstrate that bounding box prompts consistently outperform automatic
and single point-based approaches, with Box+MP achieving the highest mean IoU
(0.64) and Dice coefficient (0.75) on the Khan dataset. Lightweight variants
such as TinySAM and MobileSAM further reduce memory and computational costs,
making them more suitable for latency-tolerant edge scenarios. Overall, this
work provides critical insights for deploying promptable segmentation models in
fire monitoring systems and establishes benchmarks for future research in
domain-specific SAM applications. Code is available at:
https://github.com/UEmmanuel5/ProFSAM

</details>


### [17] [Track, Inpaint, Resplat: Subject-driven 3D and 4D Generation with Progressive Texture Infilling](https://arxiv.org/abs/2510.23605)
*Shuhong Zheng,Ashkan Mirzaei,Igor Gilitschenski*

Main category: cs.CV

TL;DR: TIRE是一种新颖的、面向主题的3D/4D生成方法，通过视频跟踪、2D修复和3D重投影来提高身份保留能力。


<details>
  <summary>Details</summary>
Motivation: 现有的3D/4D生成方法通常侧重于照片真实感、效率和美观性，但往往无法在不同视角下保持对象的语义身份。该研究旨在解决个性化3D/4D生成这一未被充分探索的领域，以生成符合特定对象身份的视觉内容。

Method: TIRE方法首先接收一个由现有3D生成模型产生的初始3D资产，然后利用视频跟踪技术识别需要修改的区域。接着，采用一种面向主题的2D修复模型逐步填充这些区域。最后，将修改后的2D多视角观测数据重新投影回3D，同时保持一致性。

Result: 大量实验表明，与最先进的方法相比，TIRE显著提高了3D/4D生成中的身份保留能力。

Conclusion: TIRE是一种有效的主题驱动3D/4D生成方法，通过结合视频跟踪、2D修复和3D重投影技术，能够显著提升生成内容在不同视角下对原始对象身份的保持能力。

Abstract: Current 3D/4D generation methods are usually optimized for photorealism,
efficiency, and aesthetics. However, they often fail to preserve the semantic
identity of the subject across different viewpoints. Adapting generation
methods with one or few images of a specific subject (also known as
Personalization or Subject-driven generation) allows generating visual content
that align with the identity of the subject. However, personalized 3D/4D
generation is still largely underexplored. In this work, we introduce TIRE
(Track, Inpaint, REsplat), a novel method for subject-driven 3D/4D generation.
It takes an initial 3D asset produced by an existing 3D generative model as
input and uses video tracking to identify the regions that need to be modified.
Then, we adopt a subject-driven 2D inpainting model for progressively infilling
the identified regions. Finally, we resplat the modified 2D multi-view
observations back to 3D while still maintaining consistency. Extensive
experiments demonstrate that our approach significantly improves identity
preservation in 3D/4D generation compared to state-of-the-art methods. Our
project website is available at
https://zsh2000.github.io/track-inpaint-resplat.github.io/.

</details>


### [18] [Noise Aggregation Analysis Driven by Small-Noise Injection: Efficient Membership Inference for Diffusion Models](https://arxiv.org/abs/2510.21783)
*Guo Li,Yuyang Yu,Xuemiao Xu*

Main category: cs.CV

TL;DR: 本文提出了一种针对扩散模型的高效成员推断攻击方法，通过注入噪声并分析噪声分布的聚合度来区分训练样本和非训练样本，该方法相较于现有方法访问次数更少，且在大型文本到图像扩散模型上表现出优越的性能和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在生成高质量图像方面表现出色，但也带来了潜在的隐私风险，特别是成员推断攻击，旨在判断特定数据样本是否被用于模型训练。

Method: 提出了一种基于注入轻微噪声和评估噪声分布聚合度的方法。其原理是：训练集样本和非训练集样本在扩散模型的噪声预测模式上存在可区分的差异。具体来说，成员图像在扩散过程的特定时间步长周围表现出更高的预测噪声聚合度，而非成员图像则表现出更离散的特征。通过向待测图像注入轻微噪声，并分析模型预测的噪声分布的聚合度来判断其成员身份。

Result: 与现有方法相比，该方法需要更少的目标扩散模型访问次数。实验结果表明，该方法在多个数据集上取得了优越的性能。同时，该方法在面对大规模文本到图像扩散模型时，在攻击成功率（ASR）和曲线下面积（AUC）方面也表现出更好的攻击效果，证明了该方法的有效性和可扩展性。

Conclusion: 所提出的高效成员推断攻击方法能够有效且可扩展地应用于扩散模型，尤其是在处理大规模文本到图像生成模型时，为评估和增强扩散模型的隐私保护提供了有力的工具。

Abstract: Diffusion models have demonstrated powerful performance in generating
high-quality images. A typical example is text-to-image generator like Stable
Diffusion. However, their widespread use also poses potential privacy risks. A
key concern is membership inference attacks, which attempt to determine whether
a particular data sample was used in the model training process. We propose an
efficient membership inference attack method against diffusion models. This
method is based on the injection of slight noise and the evaluation of the
aggregation degree of the noise distribution. The intuition is that the noise
prediction patterns of diffusion models for training set samples and
non-training set samples exhibit distinguishable differences.Specifically, we
suppose that member images exhibit higher aggregation of predicted noise around
a certain time step of the diffusion process. In contrast, the predicted noises
of non-member images exhibit a more discrete characteristic around the certain
time step. Compared with other existing methods, our proposed method requires
fewer visits to the target diffusion model. We inject slight noise into the
image under test and then determine its membership by analyzing the aggregation
degree of the noise distribution predicted by the model. Empirical findings
indicate that our method achieves superior performance across multiple
datasets. At the same time, our method can also show better attack effects in
ASR and AUC when facing large-scale text-to-image diffusion models, proving the
scalability of our method.

</details>


### [19] [EventFormer: A Node-graph Hierarchical Attention Transformer for Action-centric Video Event Prediction](https://arxiv.org/abs/2510.21786)
*Qile Su,Shoutai Zhu,Shuai Zhang,Baoyu Liang,Chao Tong*

Main category: cs.CV

TL;DR: 该研究提出了一个名为AVEP的新任务，旨在根据动作来预测视频中的后续事件，并为此构建了一个大型数据集。他们还提出了一个名为EventFormer的模型来解决这个任务，并在实验中证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中在文本脚本事件预测，缺乏对视频中事件预测的研究，而现实世界中的事件多以视频形式呈现。

Method: 构建了一个包含约3.5万个视频和超过17.8万个事件片段的大型标注数据集AVEP，其特点是使用多模态事件参数节点作为原子单元，提供更精细的结构化表示。提出了基于节点-图分层注意力机制的视频事件预测模型EventFormer，以捕捉事件及其参数间的关系以及参数间的指代关系。

Result: 在AVEP数据集上进行实验，对比了多种先进的视频预测模型和LVLMs。结果表明，AVEP任务具有挑战性，且该数据集具有价值。他们提出的EventFormer模型优于所有对比的视频预测模型。

Conclusion: AVEP任务和其数据集的提出填补了视频事件预测领域的空白，并提供了一个新的研究方向。EventFormer模型在处理复杂视频事件逻辑方面表现出色。计划公开数据集和代码以供复现。

Abstract: Script event induction, which aims to predict the subsequent event based on
the context, is a challenging task in NLP, achieving remarkable success in
practical applications. However, human events are mostly recorded and presented
in the form of videos rather than scripts, yet there is a lack of related
research in the realm of vision. To address this problem, we introduce AVEP
(Action-centric Video Event Prediction), a task that distinguishes itself from
existing video prediction tasks through its incorporation of more complex logic
and richer semantic information. We present a large structured dataset, which
consists of about $35K$ annotated videos and more than $178K$ video clips of
event, built upon existing video event datasets to support this task. The
dataset offers more fine-grained annotations, where the atomic unit is
represented as a multimodal event argument node, providing better structured
representations of video events. Due to the complexity of event structures,
traditional visual models that take patches or frames as input are not
well-suited for AVEP. We propose EventFormer, a node-graph hierarchical
attention based video event prediction model, which can capture both the
relationships between events and their arguments and the coreferencial
relationships between arguments. We conducted experiments using several SOTA
video prediction models as well as LVLMs on AVEP, demonstrating both the
complexity of the task and the value of the dataset. Our approach outperforms
all these video prediction models. We will release the dataset and code for
replicating the experiments and annotations.

</details>


### [20] [Mismatch reconstruction theory for unknown measurement matrix in imaging through multimode fiber bending](https://arxiv.org/abs/2510.21787)
*Le Yang*

Main category: cs.CV

TL;DR: 本文提出了一种在测量矩阵未知的情况下进行图像重建的新理论和方法，通过构建新的测量矩阵，实现了传统重建算法的匹配，并成功重建了原始图像，该方法对噪声、计算精度和正交性具有一定的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 实际应用中，由于系统配置未知或光纤弯曲后难以实时对准，测量矩阵难以获得，导致传统重建算法失效。

Method: 提出失配方程，设计匹配和校准求解算法来构建新的测量矩阵，并对这些方程和算法进行了详细的理论证明。

Result: 实验结果表明，在低噪声水平下，构建的测量矩阵可以用于传统重建算法中的匹配对，并成功重建原始图像。分析了噪声、计算精度和正交性对重建性能的影响，结果表明所提算法具有一定的鲁棒性。

Conclusion: 所提出的失配重建理论和算法能够有效解决测量矩阵未知的问题，在实际应用中具有一定的鲁棒性和应用潜力。

Abstract: Multimode fiber imaging requires strict matching between measurement value
and measurement matrix to achieve image reconstruction. However, in practical
applications, the measurement matrix often cannot be obtained due to unknown
system configuration or difficulty in real-time alignment after arbitrary fiber
bending, resulting in the failure of traditional reconstruction algorithms.
This paper presents a novel mismatch reconstruction theory for solving the
problem of image reconstruction when measurement matrix is unknown. We first
propose mismatch equation and design matched and calibration solution
algorithms to construct a new measurement matrix. In addition, we also provide
a detailed proof of these equations and algorithms in the appendix. The
experimental results show that under low noise levels, constructed matrix can
be used for matched pair in traditional reconstruction algorithms, and
reconstruct the original image successfully. Then, we analyze the impact of
noise, computational precision and orthogonality on reconstruction performance.
The results show that proposed algorithms have a certain degree of robustness.
Finally, we discuss the limitations and potential applications of this theory.
The code is available: https://github.com/yanglebupt/mismatch-solution.

</details>


### [21] [Exploring the design space of diffusion and flow models for data fusion](https://arxiv.org/abs/2510.21791)
*Niraj Chaudhari,Manmeet Singh,Naveen Sudharsan,Amit Kumar Srivastava,Harsh Kamath,Dushyant Mahajan,Ayan Paul*

Main category: cs.CV

TL;DR: 本研究探索了在卫星遥感数据融合任务中应用扩散模型和流模型。


<details>
  <summary>Details</summary>
Motivation: 数据融合在多源信息整合、提升数据质量和洞察力方面至关重要，尤其是在卫星遥感领域，融合多传感器观测可以提高时空分辨率。

Method: 研究设计了基于UNET、扩散和流模型的2D图像到图像生成模型，并评估了它们在DMSP-OLS和VIIRS夜间灯光数据融合中的有效性。

Result: 研究发现，基于UNet的扩散模型在保留细微空间细节和生成高保真融合图像方面表现尤为出色。此外，还提供了关于噪声调度器选择的指导，并探索了量化技术以优化内存和计算成本。

Conclusion: 本研究为数据融合任务（尤其是在遥感应用中）选择最有效的扩散和流模型架构提供了实用的见解，并为利用噪声调度策略增强融合质量提供了建议。

Abstract: Data fusion is an essential task in various domains, enabling the integration
of multi-source information to enhance data quality and insights. One key
application is in satellite remote sensing, where fusing multi-sensor
observations can improve spatial and temporal resolution. In this study, we
explore the design space of diffusion and flow models for data fusion, focusing
on the integration of Defense Meteorological Satellite Program's Operational
Linescan System (DMSP-OLS) and Visible Infrared Imaging Radiometer Suite
(VIIRS) nighttime lights data. Our approach leverages a diverse set of 2D
image-to-image generative models, including UNET, diffusion, and flow modeling
architectures. We evaluate the effectiveness of these architectures in
satellite remote sensing data fusion, identifying diffusion models based on
UNet as particularly adept at preserving fine-grained spatial details and
generating high-fidelity fused images. We also provide guidance on the
selection of noise schedulers in diffusion-based models, highlighting the
trade-offs between iterative solvers for faster inference and discrete
schedulers for higher-quality reconstructions. Additionally, we explore
quantization techniques to optimize memory efficiency and computational cost
without compromising performance. Our findings offer practical insights into
selecting the most effective diffusion and flow model architectures for data
fusion tasks, particularly in remote sensing applications, and provide
recommendations for leveraging noise scheduling strategies to enhance fusion
quality.

</details>


### [22] [2D_3D Feature Fusion via Cross-Modal Latent Synthesis and Attention Guided Restoration for Industrial Anomaly Detection](https://arxiv.org/abs/2510.21793)
*Usman Ali,Ali Zia,Abdul Rehman,Umer Ramzan,Zohaib Hassan,Talha Sattar,Jing Wang,Wei Xiang*

Main category: cs.CV

TL;DR: MAFR是一个新颖的无监督框架，通过融合2D和3D数据来检测工业异常，在MVTec 3D-AD和Eyecandies基准测试中取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 工业异常检测（IAD）日益受益于集成2D和3D数据，但鲁棒的跨模态融合仍然具有挑战性。

Method: 提出了一种新颖的无监督框架MAFR，它使用共享的融合编码器从RGB图像和点云合成统一的潜在空间，然后通过注意力引导的、特定于模态的解码器进行处理。通过测量输入特征与其恢复对应物之间的重建误差来定位异常。

Result: 在MVTec 3D-AD和Eyecandies基准测试中，MAFR分别取得了0.972和0.901的平均I-AUROC，达到了最先进的水平。该框架在少样本学习设置中也表现出强大的性能。

Conclusion: MAFR为融合视觉和几何信息提供了一种原则性的方法，提高了工业异常检测的鲁棒性和准确性。

Abstract: Industrial anomaly detection (IAD) increasingly benefits from integrating 2D
and 3D data, but robust cross-modal fusion remains challenging. We propose a
novel unsupervised framework, Multi-Modal Attention-Driven Fusion Restoration
(MAFR), which synthesises a unified latent space from RGB images and point
clouds using a shared fusion encoder, followed by attention-guided,
modality-specific decoders. Anomalies are localised by measuring reconstruction
errors between input features and their restored counterparts. Evaluations on
the MVTec 3D-AD and Eyecandies benchmarks demonstrate that MAFR achieves
state-of-the-art results, with a mean I-AUROC of 0.972 and 0.901, respectively.
The framework also exhibits strong performance in few-shot learning settings,
and ablation studies confirm the critical roles of the fusion architecture and
composite loss. MAFR offers a principled approach for fusing visual and
geometric information, advancing the robustness and accuracy of industrial
anomaly detection. Code is available at https://github.com/adabrh/MAFR

</details>


### [23] [Token-Level Inference-Time Alignment for Vision-Language Models](https://arxiv.org/abs/2510.21794)
*Kejia Chen,Jiawen Zhang,Jiacong Hu,Kewei Gao,Jian Lou,Zunlei Feng,Mingli Song*

Main category: cs.CV

TL;DR: TITA是一个轻量级框架，通过训练奖励模型并在推理时提取隐式偏好信号，实现了视觉-语言模型（VLM）的令牌级推理时间对齐，从而减少了幻觉并提高了跨多个基准的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言模型（VLM）对其输出容易出现与视觉输入不匹配的幻觉。现有的对齐方法通常依赖于昂贵的、带注释的偏好数据的微调，或者提供粗粒度、延迟反馈的序列级推理策略。

Method: TITA（令牌级推理时间对齐）框架冻结基础VLM，并训练一个奖励模型来近似其分布。在推理过程中，通过奖励模型和目标VLM之间的对数概率比提取隐式偏好信号，从而提供密集的自回归反馈。这可以被视为直接偏好优化（DPO）的推理时变体。

Result: 在LLaVA-1.5-7B和13B上的广泛评估显示，在12个基准测试中持续获得收益，MMVet提高了8.6%，POPE提高了6.7%。在Qwen2.5-VL-7B和DeepSeek-VL2-27.5B上的额外实验显示，幻觉减少和VQA准确性方面有可比的收益，而推理开销可忽略不计。

Conclusion: TITA提供了一种轻量级的方法，通过令牌级推理时间对齐来减少VLM中的幻觉，并在各种基准测试中提高了性能，同时几乎没有增加推理开销。

Abstract: Vision-Language Models (VLMs) have become essential backbones of modern
multimodal intelligence, yet their outputs remain prone to
hallucination-plausible text misaligned with visual inputs. Existing alignment
approaches often rely on expensive fine-tuning with annotated preference data
or sequence-level inference strategies that provide only coarse, delayed
feedback. To overcome these limitations, we present TITA (Token-level
Inference-Time Alignment), a lightweight framework that freezes the base VLM
and instead trains a reward model to approximate its distribution. During
inference, implicit preference signals are extracted as log-probability ratios
between the reward model and the target VLM, yielding dense autoregressive
feedback. This formulation can be viewed as an inference-time variant of Direct
Preference Optimization (DPO), providing token-level corrective signals without
retraining the backbone. Extensive evaluations on LLaVA-1.5-7B and 13B show
consistent gains across 12 benchmarks, with improvements of 8.6% on MMVet and
6.7% on POPE, indicating stronger general understanding and reduced
hallucinations. Additional experiments on Qwen2.5-VL-7B and DeepSeek-VL2-27.5B
show comparable gains, especially in hallucination reduction and VQA accuracy,
while incurring negligible inference overhead.

</details>


### [24] [Xihe: Scalable Zero-Shot Time Series Learner Via Hierarchical Interleaved Block Attention](https://arxiv.org/abs/2510.21795)
*Yinbo Sun,Yuchen Fang,Zhibo Zhu,Jia Li,Yu Liu,Qiwen Deng,Jun Zhou,Hang Yu,Xingyu Lu,Lintao Ma*

Main category: cs.CV

TL;DR: HIBA是一种新的时间序列基础模型（TSFM）架构，通过分层稀疏注意力解决了现有TSFM在跨领域迁移学习中捕捉多尺度时间依赖性的问题。该模型在GIFT-Eval基准测试中表现出色，尤其是其紧凑型模型Xihe-tiny在参数效率方面优于大多数现有TSFM，而大型模型Xihe-max在零样本迁移学习方面取得了新的最先进成果。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列基础模型（TSFM）直接迁移自语言模型架构，导致在捕捉时间序列特有的多尺度时间依赖性方面存在局限，尤其是在跨数据集零样本迁移时。这限制了它们在不同模式和采样策略的数据集上的有效性。

Method: 提出了一种名为分层交错块注意力（HIBA）的新架构，该架构采用分层、块内和块间的稀疏注意力机制来有效捕捉多尺度依赖性。块内注意力促进局部信息交换，块间注意力则跨块捕捉全局时间模式交互和动态演化。基于HIBA，开发了一个可扩展的TSFM系列Xihe，参数量从9.5M到1.5B不等。

Result: 在GIFT-Eval基准测试中，参数量为9.5M的Xihe-tiny模型在参数效率方面超过了大多数现有TSFM。参数量为1.5B的Xihe-max模型在零样本迁移学习方面取得了新的最先进成果，显著优于之前的最佳结果。

Conclusion: HIBA架构在整个参数范围内都表现出持续的卓越性能，证明了其出色的泛化能力和架构优势，能够有效解决现有TSFM在处理多尺度时间依赖性和跨领域迁移学习方面的挑战。

Abstract: The rapid advancement of time series foundation models (TSFMs) has been
propelled by migrating architectures from language models. While existing TSFMs
demonstrate impressive performance, their direct adoption of cross-domain
architectures constrains effective capture of multiscale temporal dependencies
inherent to time series data. This limitation becomes particularly pronounced
during zero-shot transfer across datasets with divergent underlying patterns
and sampling strategies. To address these challenges, we propose Hierarchical
Interleaved Block Attention (HIBA) which employs hierarchical inter- and
intra-block sparse attention to effectively capture multi-scale dependencies.
Intra-block attention facilitates local information exchange, and inter-block
attention operates across blocks to capture global temporal pattern interaction
and dynamic evolution. Leveraging the HIBA architecture, we introduce Xihe, a
scalable TSFM family spanning from an ultra-efficient 9.5M parameter
configuration to high-capacity 1.5B variant. Evaluated on the comprehensive
GIFT-Eval benchmark, our most compact Xihe-tiny model (9.5M) surpasses the
majority of contemporary TSFMs, demonstrating remarkable parameter efficiency.
More impressively, Xihe-max (1.5B) establishes new state-of-the-art zero-shot
performance, surpassing previous best results by a substantial margin. This
consistent performance excellence across the entire parameter spectrum provides
compelling evidence for the exceptional generalization capabilities and
architectural superiority of HIBA.

</details>


### [25] [AI-Boosted Video Annotation: Assessing the Process Enhancement](https://arxiv.org/abs/2510.21798)
*Juan Gutiérrez,Ángel Mora,Pablo Regodón,Silvia Rodriguez,José Luis Blanco*

Main category: cs.CV

TL;DR: 通过集成AI自动预标注，在UCF-Crime数据集上显著提高了视频标注的效率和质量，标注时间减少了35%，且标注结果更一致。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索如何通过集成自动标注能力来增强人工参与的视频标注，以减轻标注员的工作负担并评估其表现。

Method: 采用基于Label Studio和AI零样本预标注的单迭代方案，在UCF-Crime数据集上对视频中的正常和异常活动进行标注。

Result: AI自动预标注将视频标注工作流程提速，70%的标注员标注时间减少了35%，同时保持了相似的标注质量。标注结果更连贯，且与视频帧的自然聚类匹配度更高。

Conclusion: AI自动预标注能够优化视频标注流程，提升效率和标注质量，并使标注结果更加一致。

Abstract: We explore the enhancement of Human-in-the-Loop video annotation by
integrating automatic capabilities to ease the task for annotators and assess
their performance. The research delves into the practical implications of the
annotation processes, the integration of AI components, and the evaluation of
its outcomes. We analyze their impact on efficiency, accuracy, and overall
annotation quality. Focusing on the Human-in-the-Loop for video annotation
tasks, we implemented a single-iteration scheme using Label Studio and
AI-powered zero-shot pre-annotations. Using this framework, we designed a test
based on the annotation of the UCF-Crime dataset to discriminate between normal
and abnormal activities in video footage. Our results evidence how automatic
AI-based pre-annotation can streamline the video annotation workflow,
empowering human annotators and optimizing the overall pipeline. Using the
pre-annotated data, we observed a 35% reduction in the annotation time for 70%
of the annotators with similar quality annotations, compared to the traditional
manual annotation task. Results are consistent with asset duration and
complexity. We also observed that while annotators rapidly learned to use the
tool, the produced annotations are more coherent among annotators and better
match the natural clustering of the video frames.

</details>


### [26] [Morphology-Aware KOA Classification: Integrating Graph Priors with Vision Models](https://arxiv.org/abs/2510.21801)
*Marouane Tliba,Mohamed Amine Kerkouri,Yassine Nasser,Nour Aburaed,Aladine Chetouani,Ulas Bagci,Rachid Jennane*

Main category: cs.CV

TL;DR: 通过结合解剖结构和影像特征，提出一种新的多模态框架，利用SAM分割生成的形态图表示与视觉编码器相结合，并通过互信息最大化实现几何信息图嵌入与影像特征的对齐，显著提高了KOA分类的准确性。


<details>
  <summary>Details</summary>
Motivation: 标准深度学习模型难以有效捕捉X光片中膝骨关节炎（KOA）诊断的细微形态学细节。

Method: 提出一种新的多模态框架，结合解剖结构和影像特征，通过整合由SAM分割生成的形态图表示与视觉编码器，并利用互信息最大化实现几何信息图嵌入与影像特征的对齐。

Result: 在骨关节炎倡议（Osteoarthritis Initiative）数据集上，该方法比单一模态基线提高了10%的准确率（接近80%），并比现有的最先进方法提高了8%的准确率和11%的F1分数。

Conclusion: 将解剖结构纳入影像分析对于准确评估KOA严重程度至关重要。

Abstract: Knee osteoarthritis (KOA) diagnosis from radiographs remains challenging due
to the subtle morphological details that standard deep learning models struggle
to capture effectively. We propose a novel multimodal framework that combines
anatomical structure with radiographic features by integrating a morphological
graph representation - derived from Segment Anything Model (SAM) segmentations
- with a vision encoder. Our approach enforces alignment between
geometry-informed graph embeddings and radiographic features through mutual
information maximization, significantly improving KOA classification accuracy.
By constructing graphs from anatomical features, we introduce explicit
morphological priors that mirror clinical assessment criteria, enriching the
feature space and enhancing the model's inductive bias. Experiments on the
Osteoarthritis Initiative dataset demonstrate that our approach surpasses
single-modality baselines by up to 10\% in accuracy (reaching nearly 80\%),
while outperforming existing state-of-the-art methods by 8\% in accuracy and
11\% in F1 score. These results underscore the critical importance of
incorporating anatomical structure into radiographic analysis for accurate KOA
severity grading.

</details>


### [27] [It Takes Two to Tango: Two Parallel Samplers Improve Quality in Diffusion Models for Limited Steps](https://arxiv.org/abs/2510.21802)
*Pedro Cisneros-Velarde*

Main category: cs.CV

TL;DR: 使用两个并行采样器可以提高扩散模型采样的图像质量，即使在有限的去噪步数下也是如此。


<details>
  <summary>Details</summary>
Motivation: 在扩散模型采样时，去噪步数（模型评估次数）有限是一个常见限制。本研究旨在探讨如何在这一限制下提高采样图像的质量。

Method: 提出了一种简单且即插即用的方法，使用两个并行处理器或采样器，在交替的时间步长上执行去噪操作，并以适当的方式集成它们的信息。该方法不依赖于特定的模型，无需额外微调或外部模型。

Result: 实验表明，通过并行采样器可以提高采样图像的质量。然而，简单的信息集成方式反而会降低样本质量。此外，增加更多的并行采样器并不能保证进一步提高样本质量。

Conclusion: 所提出的并行采样器方法是一种简单有效的方法，可以在有限的去噪步数下提高扩散模型的采样质量。该方法具有模型无关性和易于实现的优点。

Abstract: We consider the situation where we have a limited number of denoising steps,
i.e., of evaluations of a diffusion model. We show that two parallel processors
or samplers under such limitation can improve the quality of the sampled image.
Particularly, the two samplers make denoising steps at successive times, and
their information is appropriately integrated in the latent image. Remarkably,
our method is simple both conceptually and to implement: it is plug-&-play,
model agnostic, and does not require any additional fine-tuning or external
models. We test our method with both automated and human evaluations for
different diffusion models. We also show that a naive integration of the
information from the two samplers lowers sample quality. Finally, we find that
adding more parallel samplers does not necessarily improve sample quality.

</details>


### [28] [Frame-Difference Guided Dynamic Region Perception for CLIP Adaptation in Text-Video Retrieval](https://arxiv.org/abs/2510.21806)
*Jiaao Yu,Mingjie Han,Tao Gong,Jian Zhang,Man Lan*

Main category: cs.CV

TL;DR: FDA-CLIP是一个基于CLIP的文本-视频检索框架，通过引入帧差引导的动态掩码来增强视频动态特征并抑制静态背景，从而提高跨模态对齐的准确性。


<details>
  <summary>Details</summary>
Motivation: 早期文本-视频检索方法依赖大量标注数据且存在显著的模态间隙，CLIP等视觉语言模型在视频任务上的应用也存在动态特征增强不足和静态冗余特征抑制不佳的问题。

Method: 提出FDA-CLIP框架，利用帧差生成动态区域掩码，并将其作为Alpha通道输入Alpha-CLIP，引导模型关注语义关键的动态区域，抑制静态背景。

Result: 实验表明，帧差引导的视频语义编码能有效平衡检索效率和准确性。

Conclusion: FDA-CLIP通过引入帧差引导的动态掩码，有效解决了现有文本-视频检索方法在动态特征增强和静态特征抑制方面的不足，提高了跨模态对齐的准确性和检索效率。

Abstract: With the rapid growth of video data, text-video retrieval technology has
become increasingly important in numerous application scenarios such as
recommendation and search. Early text-video retrieval methods suffer from two
critical drawbacks: first, they heavily rely on large-scale annotated
video-text pairs, leading to high data acquisition costs; second, there is a
significant modal gap between video and text features, which limits cross-modal
alignment accuracy. With the development of vision-language model, adapting
CLIP to video tasks has attracted great attention. However, existing adaptation
methods generally lack enhancement for dynamic video features and fail to
effectively suppress static redundant features. To address this issue, this
paper proposes FDA-CLIP (Frame Difference Alpha-CLIP), which is a concise
CLIP-based training framework for text-video alignment. Specifically, the
method uses frame differences to generate dynamic region masks, which are input
into Alpha-CLIP as an additional Alpha channel. This proactively guides the
model to focus on semantically critical dynamic regions while suppressing
static background redundancy. Experiments demonstrate that frame
difference-guided video semantic encoding can effectively balance retrieval
efficiency and accuracy.

</details>


### [29] [Activating Visual Context and Commonsense Reasoning through Masked Prediction in VLMs](https://arxiv.org/abs/2510.21807)
*Jiaao Yu,Shenwei Li,Mingjie Han,Yifei Yin,Wenzheng Song,Chenghao Jia,Man Lan*

Main category: cs.CV

TL;DR: 该研究提出了一种名为Masked Prediction via Context and Commonsense的新型微调任务，以解决大型语言模型在视觉语言任务中的推理能力不足的问题。通过在遮挡图像中重建语义内容，该任务能促进模型整合视觉上下文和常识推理。此外，研究还开发了一个名为MPCC Eval的评估基准，并引入了一种名为Reinforcement Fine tuning with Prior Sampling的训练方法，以提升模型的泛化推理能力，特别是在OOD（出分布）和跨任务场景中。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在具备可验证奖励的任务上取得了显著的推理能力突破，但在处理现实世界的多模态场景（尤其是视觉语言任务）时，由于过度侧重于单一模态语言设置，适应性仍然不足。现有的将强化学习技术应用于视觉语言模型的方法，往往局限于以感知为中心的任务，或将图像简化为文本摘要，未能充分利用视觉上下文和常识知识，限制了推理能力在不同多模态环境中的泛化。

Method: 提出了一种名为Masked Prediction via Context and Commonsense的新型微调任务，该任务通过从被遮挡的图像中重建有意义的内容，强迫模型整合视觉上下文和常识推理。开发了一个名为MPCC Eval的专门评估基准来系统地评估模型在泛化推理方面的性能。采用多种微调策略来指导推理，其中引入了一种名为Reinforcement Fine tuning with Prior Sampling的创新训练方法。

Result: 所提出的方法和训练策略（特别是Reinforcement Fine tuning with Prior Sampling）不仅提高了模型性能，还增强了其在OOD（出分布）和跨任务场景中的泛化推理能力。

Conclusion: 通过引入Masked Prediction via Context and Commonsense微调任务和MPCC Eval评估基准，以及采用Reinforcement Fine tuning with Prior Sampling训练方法，可以有效提升大型语言模型在视觉语言任务中的推理能力和泛化能力，克服现有方法的局限性。

Abstract: Recent breakthroughs in reasoning models have markedly advanced the reasoning
capabilities of large language models, particularly via training on tasks with
verifiable rewards. Yet, a significant gap persists in their adaptation to real
world multimodal scenarios, most notably, vision language tasks, due to a heavy
focus on single modal language settings. While efforts to transplant
reinforcement learning techniques from NLP to VLMs have emerged, these
approaches often remain confined to perception centric tasks or reduce images
to textual summaries, failing to fully exploit visual context and commonsense
knowledge, ultimately constraining the generalization of reasoning capabilities
across diverse multimodal environments. To address this limitation, we
introduce a novel fine tuning task, Masked Prediction via Context and
Commonsense, which forces models to integrate visual context and commonsense
reasoning by reconstructing semantically meaningful content from occluded
images, thereby laying the foundation for generalized reasoning. To
systematically evaluate the model performance in generalized reasoning, we
developed a specialized evaluation benchmark, MPCC Eval, and employed various
fine tuning strategies to guide reasoning. Among these, we introduced an
innovative training method, Reinforcement Fine tuning with Prior Sampling,
which not only enhances model performance but also improves its generalized
reasoning capabilities in OOD and cross task scenarios.

</details>


### [30] [Semantic Relation-Enhanced CLIP Adapter for Domain Adaptive Zero-Shot Learning](https://arxiv.org/abs/2510.21808)
*Jiaao Yu,Mingjie Han,Jinkun Jiang,Junyu Dong,Tao Gong,Man Lan*

Main category: cs.CV

TL;DR: 本文提出了一种名为SRE-CLIP的框架，用于解决数据有限情况下的域自适应零样本学习问题，特别是在利用CLIP模型时遇到的挑战。


<details>
  <summary>Details</summary>
Motivation: 高昂的数据标注成本促使研究者探索在数据有限的情况下训练深度学习模型。现有方法在跨域迁移和跨类别泛化之间未能取得良好平衡，因此需要域自适应零样本学习（DAZSL）。尽管CLIP等视觉-语言模型在DAZSL领域具有优势，但现有研究未能充分挖掘其潜力。

Method: 提出了一种名为SRE-CLIP的适配器框架，该框架集成了语义关系结构损失和跨模态对齐保持策略，以解决CLIP在DAZSL中面临的知识迁移效率低下和跨模态对齐能力下降的问题。

Result: SRE-CLIP在I2AwA和I2WebV基准测试中取得了最先进的性能，显著优于现有方法。

Conclusion: SRE-CLIP作为首个基于CLIP的DAZSL方法，有效地解决了现有CLIP模型在DAZSL应用中的核心挑战，并在相关基准测试上取得了优异的成果。

Abstract: The high cost of data annotation has spurred research on training deep
learning models in data-limited scenarios. Existing paradigms, however, fail to
balance cross-domain transfer and cross-category generalization, giving rise to
the demand for Domain-Adaptive Zero-Shot Learning (DAZSL). Although
vision-language models (e.g., CLIP) have inherent advantages in the DAZSL
field, current studies do not fully exploit their potential. Applying CLIP to
DAZSL faces two core challenges: inefficient cross-category knowledge transfer
due to the lack of semantic relation guidance, and degraded cross-modal
alignment during target domain fine-tuning. To address these issues, we propose
a Semantic Relation-Enhanced CLIP (SRE-CLIP) Adapter framework, integrating a
Semantic Relation Structure Loss and a Cross-Modal Alignment Retention
Strategy. As the first CLIP-based DAZSL method, SRE-CLIP achieves
state-of-the-art performance on the I2AwA and I2WebV benchmarks, significantly
outperforming existing approaches.

</details>


### [31] [Quality-controlled registration of urban MLS point clouds reducing drift effects by adaptive fragmentation](https://arxiv.org/abs/2510.23416)
*Marco Antonio Ortiz Rincon,Yihui Yang,Christoph Holst*

Main category: cs.CV

TL;DR: 本研究提出了一种新颖的工作流程，用于在城市街道场景中将大型移动激光扫描（MLS）点云高效、准确地配准到目标模型点云。


<details>
  <summary>Details</summary>
Motivation: 针对城市环境中存在的复杂性，以及集成密度、噪声特征和遮挡场景各不相同的点云所带来的挑战。

Method: 提出了一种名为半球体检查（SSC）的预处理技术，通过识别相互垂直的平面表面来优化地分割MLS轨迹数据，并提出了一种基于平面体素的广义最近点（PV-GICP）的精配准方法，该方法选择性地利用体素分区内的平面表面。

Result: 所提出的工作流程实现了优于0.01米的平均配准精度，同时将处理时间缩短了50%以上。

Conclusion: 实验证明，该工作流程在提高点云配准精度和效率方面具有显著优势，在城市规划、基础设施管理和动态城市监测等领域具有潜在应用价值。

Abstract: This study presents a novel workflow designed to efficiently and accurately
register large-scale mobile laser scanning (MLS) point clouds to a target model
point cloud in urban street scenarios. This workflow specifically targets the
complexities inherent in urban environments and adeptly addresses the
challenges of integrating point clouds that vary in density, noise
characteristics, and occlusion scenarios, which are common in bustling city
centers. Two methodological advancements are introduced. First, the proposed
Semi-sphere Check (SSC) preprocessing technique optimally fragments MLS
trajectory data by identifying mutually orthogonal planar surfaces. This step
reduces the impact of MLS drift on the accuracy of the entire point cloud
registration, while ensuring sufficient geometric features within each fragment
to avoid local minima. Second, we propose Planar Voxel-based Generalized
Iterative Closest Point (PV-GICP), a fine registration method that selectively
utilizes planar surfaces within voxel partitions. This pre-process strategy not
only improves registration accuracy but also reduces computation time by more
than 50% compared to conventional point-to-plane ICP methods. Experiments on
real-world datasets from Munich's inner city demonstrate that our workflow
achieves sub-0.01 m average registration accuracy while significantly
shortening processing times. The results underscore the potential of the
proposed methods to advance automated 3D urban modeling and updating, with
direct applications in urban planning, infrastructure management, and dynamic
city monitoring.

</details>


### [32] [Embodied Navigation with Auxiliary Task of Action Description Prediction](https://arxiv.org/abs/2510.21809)
*Haru Kondoh,Asako Kanezaki*

Main category: cs.CV

TL;DR: 该研究提出将语言描述动作作为辅助任务，结合到强化学习的机器人室内导航任务中，解决了现有方法中数据缺失和性能损失的问题，并在导航性能和动作描述方面取得了良好效果，特别是在语义视听导航任务上达到了最先进的水平。


<details>
  <summary>Details</summary>
Motivation: 现有机器人导航系统过于复杂，难以解释其决策过程，而可解释性与性能之间存在权衡。本研究旨在解决这一问题。

Method: 将语言描述动作作为辅助任务，并利用预训练的}("vision-language models") 结合知识蒸馏来解决缺乏真实数据的问题，将其融入强化学习的导航任务中。

Result: 该方法能够描述导航动作，同时保持高导航性能，并在语义视听导航等具有挑战性的任务上取得了最先进的性能。

Conclusion: 将语言描述动作作为辅助任务可以提高机器人导航系统的可解释性，同时不牺牲性能，甚至能在某些任务上取得更好的效果。

Abstract: The field of multimodal robot navigation in indoor environments has garnered
significant attention in recent years. However, as tasks and methods become
more advanced, the action decision systems tend to become more complex and
operate as black-boxes. For a reliable system, the ability to explain or
describe its decisions is crucial; however, there tends to be a trade-off in
that explainable systems can not outperform non-explainable systems in terms of
performance. In this paper, we propose incorporating the task of describing
actions in language into the reinforcement learning of navigation as an
auxiliary task. Existing studies have found it difficult to incorporate
describing actions into reinforcement learning due to the absence of
ground-truth data. We address this issue by leveraging knowledge distillation
from pre-trained description generation models, such as vision-language models.
We comprehensively evaluate our approach across various navigation tasks,
demonstrating that it can describe actions while attaining high navigation
performance. Furthermore, it achieves state-of-the-art performance in the
particularly challenging multimodal navigation task of semantic audio-visual
navigation.

</details>


### [33] [Hybrid Deep Learning Framework for Enhanced Diabetic Retinopathy Detection: Integrating Traditional Features with AI-driven Insights](https://arxiv.org/abs/2510.21810)
*Arpan Maity,Aviroop Pal,MD. Samiul Islam,Tamal Ghosh*

Main category: cs.CV

TL;DR: 该研究提出了一种结合传统特征提取和深度学习（DL）的混合诊断框架，用于增强糖尿病视网膜病变（DR）的检测。该方法通过融合可解释的临床数据和学习到的特征，提高了早期诊断的准确性，并减少了漏诊，有望实现大规模、准确的DR筛查。


<details>
  <summary>Details</summary>
Motivation: 糖尿病视网膜病变（DR）是糖尿病（DM）的一种致盲并发症，对全球特别是印度等糖尿病高发地区构成了重大健康威胁。由于DR早期无症状，早期筛查至关重要，而眼底成像技术有助于通过检测视网膜病灶来精确诊断。

Method: 本研究提出了一种混合诊断框架，结合了传统的特征提取方法和深度学习（DL）技术。传统的特征提取能够捕捉关键的临床指标，而深度学习则能够自动化识别多层次的模式。

Result: 与单独使用深度学习的方法相比，该混合模型通过融合可解释的临床数据和学习到的特征，在分类方面表现更优，并能有效减少假阴性病例。

Conclusion: 这种多模态人工智能驱动的方法能够实现大规模、准确的DR筛查，这对于糖尿病负担沉重的地区尤为重要。

Abstract: Diabetic Retinopathy (DR), a vision-threatening complication of Dia-betes
Mellitus (DM), is a major global concern, particularly in India, which has one
of the highest diabetic populations. Prolonged hyperglycemia damages reti-nal
microvasculature, leading to DR symptoms like microaneurysms, hemor-rhages, and
fluid leakage, which, if undetected, cause irreversible vision loss. Therefore,
early screening is crucial as DR is asymptomatic in its initial stages. Fundus
imaging aids precise diagnosis by detecting subtle retinal lesions. This paper
introduces a hybrid diagnostic framework combining traditional feature
extraction and deep learning (DL) to enhance DR detection. While handcrafted
features capture key clinical markers, DL automates hierarchical pattern
recog-nition, improving early diagnosis. The model synergizes interpretable
clinical data with learned features, surpassing standalone DL approaches that
demon-strate superior classification and reduce false negatives. This
multimodal AI-driven approach enables scalable, accurate DR screening, crucial
for diabetes-burdened regions.

</details>


### [34] [Comparative Analysis of Object Detection Algorithms for Surface Defect Detection](https://arxiv.org/abs/2510.21811)
*Arpan Maity,Tamal Ghosh*

Main category: cs.CV

TL;DR: YOLOv11在NEU-DET数据集上表现优于其他六种目标检测算法，在表面缺陷检测方面精度和速度均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 评估六种主流目标检测算法（YOLOv11, RetinaNet, Fast R-CNN, YOLOv8, RT-DETR, DETR）在NEU-DET数据集上的表面缺陷检测性能。

Method: 在包含划痕、夹杂物和轧制氧化皮等金属表面缺陷图像的NEU-DET数据集上，评估了每个模型的检测精度、速度和鲁棒性。

Result: YOLOv11的平均准确率比其他方法高出70%，其增强的特征提取能力、单次前向传播处理能力、优化的锚框生成和更深的卷积层使其在检测微小表面缺陷方面更快、更有效，并能更精确地定位缺陷。

Conclusion: YOLOv11在精度和速度方面的卓越表现，使其成为NEU数据集表面缺陷检测最有效的模型，在各项指标上均大幅超越竞争对手。

Abstract: This article compares the performance of six prominent object detection
algorithms, YOLOv11, RetinaNet, Fast R-CNN, YOLOv8, RT-DETR, and DETR, on the
NEU-DET surface defect detection dataset, comprising images representing
various metal surface defects, a crucial application in industrial quality
control. Each model's performance was assessed regarding detection accuracy,
speed, and robustness across different defect types such as scratches,
inclusions, and rolled-in scales. YOLOv11, a state-of-the-art real-time object
detection algorithm, demonstrated superior performance compared to the other
methods, achieving a remarkable 70% higher accuracy on average. This
improvement can be attributed to YOLOv11s enhanced feature extraction
capabilities and ability to process the entire image in a single forward pass,
making it faster and more efficient in detecting minor surface defects.
Additionally, YOLOv11's architecture optimizations, such as improved anchor box
generation and deeper convolutional layers, contributed to more precise
localization of defects. In conclusion, YOLOv11's outstanding performance in
accuracy and speed solidifies its position as the most effective model for
surface defect detection on the NEU dataset, surpassing competing algorithms by
a substantial margin.

</details>


### [35] [SITS-DECO: A Generative Decoder Is All You Need For Multitask Satellite Image Time Series Modelling](https://arxiv.org/abs/2510.21813)
*Samuel J. Barrett,Docko Sow*

Main category: cs.CV

TL;DR: EO 基础模型存在需要额外适配且结构僵化的问题。本文提出 SITS-DECO，一个受 LLM 启发的生成模型，将 EO 数据统一为序列进行处理，仅用 GPT 风格的解码器架构，无需任务或模态适配，即可执行多种监督和自监督任务，并在农作物类型分类任务上超越现有模型，证明了密集时间序列建模的重要性，并提出了一种数据驱动的建模范式。


<details>
  <summary>Details</summary>
Motivation: 现有 EO 基础模型需要额外适配且结构僵化，限制了其在多样化任务中的应用。

Method: 受 LLM 启发，提出 SITS-DECO（Satellite Image Time Series-DECoder Only）模型，采用 GPT 风格的解码器架构，将 EO 数据统一为序列，通过符号提示实现多种监督和自监督任务，无需任务或模态适配。

Result: SITS-DECO 在农作物类型分类任务（PASTIS-R）上超越了更大的 EO 基础模型，尽管模型简单且缺乏空间上下文，证明了密集时间序列建模的关键作用。

Conclusion: SITS-DECO 提供了一种轻量级、实用的多模态、多任务 EO 建模方法，展示了数据驱动的建模范式（能力来源于训练数据的多样性和结构而非架构复杂度），并为未来的生成式 EO 基础模型搭建了概念桥梁。

Abstract: Earth Observation (EO) Foundation Modelling (FM) holds great promise for
simplifying and improving the use of EO data for diverse real-world tasks.
However, most existing models require additional adaptation before they can be
used and are structured rigidly around particular data sources or training
approaches. To address this, we take inspiration from large language models,
where diverse tasks, both pre-training and downstream, are implicitly captured
through next-token prediction over unified token sequences, leveraging the
structure and diversity of the training data.
  We introduce SITS-DECO (Satellite Image Time Series-DECoder Only), a
proof-of-concept generative model that applies this unified-sequence framing to
EO data. Using a simple GPT-style decoder-only architecture, and demonstrate
its ability to perform useful EO tasks (pixel-wise, multi-temporal, multi-modal
crop-type classification) in a purely generative framework. Through symbolic
prompting, we show that the model can perform multiple supervised and
self-supervised tasks within a single unified architecture, without task- or
modality-specific adaptation. Despite its simplicity and lack of spatial
context, SITS-DECO outperforms much larger EO foundation models on crop-type
classification (PASTIS-R) demonstrating that dense temporal sequence modelling
is a critical missing ingredient in the current paradigm.
  This work exemplifies a data-centric modelling paradigm in which capability
arises from the diversity and structure of the training data rather than from
architectural complexity. SITS-DECO provides a lightweight, practical route to
multi-modal, multi-task EO modelling, and a conceptual bridge toward future
generative EO foundation models.

</details>


### [36] [Gestura: A LVLM-Powered System Bridging Motion and Semantics for Real-Time Free-Form Gesture Understanding](https://arxiv.org/abs/2510.21814)
*Zhuoming Li,Aitong Liu,Mengxi Jia,Tengxiang Zhang,Dell Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: Gestura是一个新的手势理解系统，使用预训练的大型视觉语言模型（LVLM）、地标处理模块和思维链（CoT）推理策略，以提高准确性和响应速度。


<details>
  <summary>Details</summary>
Motivation: 现有手势识别系统（如GestureGPT）在识别准确性和响应速度方面存在局限性，需要更优的解决方案。

Method: Gestura利用预训练的LVLM来理解手势的动态模式，并结合地标处理模块来捕捉细微的手部动作。此外，采用CoT推理策略进行逐步推理，以增强对模糊或非常规手势的理解。

Result: Gestura在准确性和响应速度方面优于现有方法，并能实现鲁棒且适应性强的自由形式手势理解。该研究还发布了一个包含300,000多个标注问答对的自由形式手势数据集。

Conclusion: Gestura通过结合LVLM、地标处理模块和CoT推理，显著提高了自由形式手势理解的性能，并为该领域提供了一个新的数据集。

Abstract: Free-form gesture understanding is highly appealing for human-computer
interaction, as it liberates users from the constraints of predefined gesture
categories. However, the sole existing solution GestureGPT suffers from limited
recognition accuracy and slow response times. In this paper, we propose
Gestura, an end-to-end system for free-form gesture understanding. Gestura
harnesses a pre-trained Large Vision-Language Model (LVLM) to align the highly
dynamic and diverse patterns of free-form gestures with high-level semantic
concepts. To better capture subtle hand movements across different styles, we
introduce a Landmark Processing Module that compensate for LVLMs' lack of
fine-grained domain knowledge by embedding anatomical hand priors. Further, a
Chain-of-Thought (CoT) reasoning strategy enables step-by-step semantic
inference, transforming shallow knowledge into deep semantic understanding and
significantly enhancing the model's ability to interpret ambiguous or
unconventional gestures. Together, these components allow Gestura to achieve
robust and adaptable free-form gesture comprehension. Additionally, we have
developed the first open-source dataset for free-form gesture intention
reasoning and understanding with over 300,000 annotated QA pairs.

</details>


### [37] [Prompt fidelity of ChatGPT4o / Dall-E3 text-to-image visualisations](https://arxiv.org/abs/2510.21821)
*Dirk HR Spennemann*

Main category: cs.CV

TL;DR: ChatGPT4o 和 DALL-E3 在图像生成中存在提示保真度差距，尤其是在描述人物年龄等方面。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在分析ChatGPT4o/DALL-E3等文本到图像生成模型在视觉化过程中，用户提供的提示（prompt）中明确指定的属性是否能在生成的图像中得到准确呈现。

Method: 研究使用了两个公开数据集，包含200张关于文化创意产业女性工作者的图像和230张关于博物馆策展人的图像。研究评估了个人属性（如年龄、发型）、外观（如着装、眼镜）和附属物品（如名牌、文件夹）的准确性。

Result: DALL-E3 在所有属性（n=710）中有 15.6% 的情况下偏离了提示的规范。其中，附属物品的错误率最低，个人外观的错误率居中，而人物自身的描绘（尤其是年龄）错误率最高。

Conclusion: 研究结果表明，在提示到图像的生成过程中存在可衡量的保真度差距，这对偏见检测和模型评估具有重要意义。

Abstract: This study examines the prompt fidelity of ChatGPT4o / DALL-E3 text-to-image
visualisations by analysing whether attributes explicitly specified in
autogenously generated prompts are correctly rendered in the resulting images.
Using two public-domain datasets comprising 200 visualisations of women working
in the cultural and creative industries and 230 visualisations of museum
curators, the study assessed accuracy across personal attributes (age, hair),
appearance (attire, glasses), and paraphernalia (name tags, clipboards). While
correctly rendered in most cases, DALL-E3 deviated from prompt specifications
in 15.6% of all attributes (n=710). Errors were lowest for paraphernalia,
moderate for personal appearance, and highest for depictions of the person
themselves, particularly age. These findings demonstrate measurable
prompt-to-image fidelity gaps with implications for bias detection and model
evaluation.

</details>


### [38] [Wavelet-based GAN Fingerprint Detection using ResNet50](https://arxiv.org/abs/2510.21822)
*Sai Teja Erukude,Suhasnadh Reddy Veluru,Viswa Chaitanya Marella*

Main category: cs.CV

TL;DR: 本研究提出一种基于小波变换的GAN图像检测方法，通过离散小波变换（DWT）预处理和ResNet50分类器，提高了GAN生成图像的检测精度。


<details>
  <summary>Details</summary>
Motivation: 识别生成对抗网络（GAN）生成的图像在数字图像取证领域是一个重大挑战。

Method: 采用Haar和Daubechies小波滤波器将输入图像转换为多分辨率表示，然后输入到ResNet50网络进行分类，以利用生成过程中留下的细微伪影。

Result: 基于Haar和Daubechies小波变换的预处理模型分别达到了93.8%和95.1%的准确率，显著高于在空间域训练的模型（81.5%的准确率）。基于Daubechies小波的模型优于Haar小波。

Conclusion: 所提出的方法证明了小波域分析在检测GAN图像方面的有效性，并强调了进一步发展未来深度伪造检测系统能力的潜力。GAN生成的图像具有独特的小波域伪影或“指纹”。

Abstract: Identifying images generated by Generative Adversarial Networks (GANs) has
become a significant challenge in digital image forensics. This research
presents a wavelet-based detection method that uses discrete wavelet transform
(DWT) preprocessing and a ResNet50 classification layer to differentiate the
StyleGAN-generated images from real ones. Haar and Daubechies wavelet filters
are applied to convert the input images into multi-resolution representations,
which will then be fed to a ResNet50 network for classification, capitalizing
on subtle artifacts left by the generative process. Moreover, the wavelet-based
models are compared to an identical ResNet50 model trained on spatial data. The
Haar and Daubechies preprocessed models achieved a greater accuracy of 93.8
percent and 95.1 percent, much higher than the model developed in the spatial
domain (accuracy rate of 81.5 percent). The Daubechies-based model outperforms
Haar, showing that adding layers of descriptive frequency patterns can lead to
even greater distinguishing power. These results indicate that the
GAN-generated images have unique wavelet-domain artifacts or "fingerprints."
The method proposed illustrates the effectiveness of wavelet-domain analysis to
detect GAN images and emphasizes the potential of further developing the
capabilities of future deepfake detection systems.

</details>


### [39] [Explainable Deep Learning in Medical Imaging: Brain Tumor and Pneumonia Detection](https://arxiv.org/abs/2510.21823)
*Sai Teja Erukude,Viswa Chaitanya Marella,Suhasnadh Reddy Veluru*

Main category: cs.CV

TL;DR: 本研究提出一个可解释的深度学习框架，用于在MRI和X光图像中检测脑肿瘤和肺炎，并集成了Grad-CAM技术以提高模型的可解释性。


<details>
  <summary>Details</summary>
Motivation: 深度学习在医学影像诊断方面潜力巨大，但缺乏可解释性阻碍了临床应用，因此需要开发可解释的深度学习模型来增强临床信任。

Method: 使用ResNet50和DenseNet121模型，在Kaggle的脑部MRI和胸部X光数据集上进行训练，并集成Grad-CAM技术生成热力图可视化，以解释模型的诊断决策过程。

Result: DenseNet121在脑肿瘤（94.3%准确率）和肺炎（89.1%准确率）检测方面均优于ResNet50（分别为92.5%和84.4%）。Grad-CAM显示DenseNet121更关注核心病灶区域，而ResNet50有时会将注意力分散到周边区域。

Conclusion: 深度学习与可解释人工智能的结合为开发可靠、可解释且具有临床应用价值的诊断工具提供了一条有前景的途径。

Abstract: Deep Learning (DL) holds enormous potential for improving medical imaging
diagnostics, yet the lack of interpretability in most models hampers clinical
trust and adoption. This paper presents an explainable deep learning framework
for detecting brain tumors in MRI scans and pneumonia in chest X-ray images
using two leading Convolutional Neural Networks, ResNet50 and DenseNet121.
These models were trained on publicly available Kaggle datasets comprising
7,023 brain MRI images and 5,863 chest X-ray images, achieving high
classification performance. DenseNet121 consistently outperformed ResNet50 with
94.3 percent vs. 92.5 percent accuracy for brain tumors and 89.1 percent vs.
84.4 percent accuracy for pneumonia. For better explainability,
Gradient-weighted Class Activation Mapping (Grad-CAM) was integrated to create
heatmap visualizations superimposed on the test images, indicating the most
influential image regions in the decision-making process. Interestingly, while
both models produced accurate results, Grad-CAM showed that DenseNet121
consistently focused on core pathological regions, whereas ResNet50 sometimes
scattered attention to peripheral or non-pathological areas. Combining deep
learning and explainable AI offers a promising path toward reliable,
interpretable, and clinically useful diagnostic tools.

</details>


### [40] [Precise classification of low quality G-banded Chromosome Images by reliability metrics and data pruning classifier](https://arxiv.org/abs/2510.21827)
*Mojtaba Moattari*

Main category: cs.CV

TL;DR: 该论文提出了一种新的染色体分类方法，通过引入可靠性阈值指标和工程特征，提高了低质量图像下的分类精度，并验证了其在资源匮乏地区的适用性。


<details>
  <summary>Details</summary>
Motivation: 现有染色体分类系统需要大量高质量的训练数据，这在一些偏远病理实验室难以实现。为防止低成本、低质量图像系统出现假阳性，需要改进分类精度。

Method: 提出可靠性阈值指标和工程特征，并使用改进的Alex-Net、SVM、K近邻及其级联管道进行评估，实现了对半直线染色体的自动化过滤。

Result: 分类精度在常见缺陷和易位染色体上提高了90%以上。对提出的阈值指标进行了比较分析，并选出了最佳指标。

Conclusion: 提出的指标和剪枝方法适用于低成本、低质量的染色体核型分析，特别是在贫困国家和预算有限的病理实验室。

Abstract: In the last decade, due to high resolution cameras and accurate meta-phase
analyzes, the accuracy of chromosome classification has improved substantially.
However, current Karyotyping systems demand large number of high quality train
data to have an adequately plausible Precision per each chromosome. Such
provision of high quality train data with accurate devices are not yet
accomplished in some out-reached pathological laboratories. To prevent false
positive detections in low-cost systems and low-quality images settings, this
paper improves the classification Precision of chromosomes using proposed
reliability thresholding metrics and deliberately engineered features. The
proposed method has been evaluated using a variation of deep Alex-Net neural
network, SVM, K Nearest-Neighbors, and their cascade pipelines to an automated
filtering of semi-straight chromosome. The classification results have highly
improved over 90% for the chromosomes with more common defections and
translocations. Furthermore, a comparative analysis over the proposed
thresholding metrics has been conducted and the best metric is bolded with its
salient characteristics. The high Precision results provided for a very
low-quality G-banding database verifies suitability of the proposed metrics and
pruning method for Karyotyping facilities in poor countries and lowbudget
pathological laboratories.

</details>


### [41] [Structured and Abstractive Reasoning on Multi-modal Relational Knowledge Images](https://arxiv.org/abs/2510.21828)
*Yichi Zhang,Zhuo Chen,Lingbing Guo,Lei Liang,Wen Zhang,Huajun Chen*

Main category: cs.CV

TL;DR: 本论文提出了一个用于多模态关系知识（MMRK）结构化和抽象推理（STAR）的数据引擎和训练框架，并发布了STAR-64K数据集，旨在提升多模态大语言模型（MLLMs）理解和推理抽象视觉信息的能力。


<details>
  <summary>Details</summary>
Motivation: 当前的多模态大语言模型在理解和推理视觉模态中的抽象信息方面存在挑战，特别是多模态关系知识（MMRK）的结构化和抽象推理（STAR）领域，该领域缺乏大规模高质量数据和相应的方法学支持。

Method: 1. 开发了一个自动化的STAR数据引擎，能够合成图像和MMRK，生成包含可靠思维链的多模态指令数据，用于各种STAR任务。 2. 构建了一个全面的两阶段能力增强训练框架，并设计了针对不同STAR任务的评估协议。 3. 基于上述贡献，发布了包含64K高质量多模态指令样本的STAR-64K数据集。

Result: 在STAR-64K数据集上进行实验，结果表明，本论文提出的两阶段增强框架能够使较小的3B/7B模型在STAR任务上显著优于GPT-4o。此外，还提供了关于不同设计有效性、数据可迁移性和可扩展性的深入分析。

Conclusion: 本研究成功地构建了STAR-64K数据集和两阶段能力增强训练框架，有效提升了MLLMs在多模态关系知识的结构化和抽象推理方面的能力，甚至超越了像GPT-4o这样的大型模型，并为未来的研究提供了分析和见解。

Abstract: Understanding and reasoning with abstractive information from the visual
modality presents significant challenges for current multi-modal large language
models (MLLMs). Among the various forms of abstractive information, Multi-Modal
Relational Knowledge (MMRK), which represents abstract relational structures
between multi-modal entities using node-edge formats, remains largely
under-explored. In particular, STructured and Abstractive Reasoning (STAR) on
such data has received little attention from the research community. To bridge
the dual gaps in large-scale high-quality data and capability enhancement
methodologies, this paper makes the following key contributions: (i). An
automatic STAR data engine capable of synthesizing images with MMRK to build
multi-modal instruction data with reliable chain-of-thought thinking for
various STAR tasks and (ii). A comprehsive two-stage capability enhancement
training framework, accompanied by a suite of evaluation protocols tailored to
different STAR tasks. Based upon these contributions, we introduce STAR-64K, a
dataset comprising 64K high-quality multi-modal instruction samples, and
conduct experiments across 5 open-source MLLMs. Experimental results show that
our two-stage enhancement framework enables smaller 3B/7B models to
significantly outperform GPT-4o in STAR. Additionally, we provide in-depth
analysis regarding the effectiveness of various designs, data transferability,
and scalability.

</details>


### [42] [A Flow Model with Low-Rank Transformers for Incomplete Multimodal Survival Analysis](https://arxiv.org/abs/2510.21829)
*Yi Yin,Yuntao Shou,Zao Dai,Yun Peng,Tao Meng,Wei Ai,Keqin Li*

Main category: cs.CV

TL;DR: 提出了一种结合低秩Transformer和基于流的生成模型的新框架，用于处理不完整多模态生存分析。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态生存分析方法在处理真实世界数据集中缺失模态信息时，往往会忽略模态间的分布差异，导致重建不一致且不可靠。

Method: 使用多实例表示的全切片图像（WSIs）和基因组学特征，将问题制定为不完整多模态生存分析。提出了一种类特定的流模型来实现跨模态分布对齐，通过可逆的归一化流模型构建缺失模态的一致性潜在空间。设计了一个轻量级的低秩Transformer来处理模态内依赖关系和高维模态融合的过拟合问题。

Result: 该方法在完整和不完整模态设置下均取得了最先进的性能，并保持了鲁棒性和优越的准确性。

Conclusion: 所提出的框架能够有效处理不完整多模态生存分析的挑战，提供更准确可靠的生存预测。

Abstract: In recent years, multimodal medical data-based survival analysis has
attracted much attention. However, real-world datasets often suffer from the
problem of incomplete modality, where some patient modality information is
missing due to acquisition limitations or system failures. Existing methods
typically infer missing modalities directly from observed ones using deep
neural networks, but they often ignore the distributional discrepancy across
modalities, resulting in inconsistent and unreliable modality reconstruction.
To address these challenges, we propose a novel framework that combines a
low-rank Transformer with a flow-based generative model for robust and flexible
multimodal survival prediction. Specifically, we first formulate the concerned
problem as incomplete multimodal survival analysis using the multi-instance
representation of whole slide images (WSIs) and genomic profiles. To realize
incomplete multimodal survival analysis, we propose a class-specific flow for
cross-modal distribution alignment. Under the condition of class labels, we
model and transform the cross-modal distribution. By virtue of the reversible
structure and accurate density modeling capabilities of the normalizing flow
model, the model can effectively construct a distribution-consistent latent
space of the missing modality, thereby improving the consistency between the
reconstructed data and the true distribution. Finally, we design a lightweight
Transformer architecture to model intra-modal dependencies while alleviating
the overfitting problem in high-dimensional modality fusion by virtue of the
low-rank Transformer. Extensive experiments have demonstrated that our method
not only achieves state-of-the-art performance under complete modality
settings, but also maintains robust and superior accuracy under the incomplete
modalities scenario.

</details>


### [43] [Towards Accurate and Efficient Waste Image Classification: A Hybrid Deep Learning and Machine Learning Approach](https://arxiv.org/abs/2510.21833)
*Ngoc-Bao-Quang Nguyen,Tuan-Minh Do,Cong-Tam Phan,Thi-Thu-Hong Phan*

Main category: cs.CV

TL;DR: 该研究通过对比机器学习、深度学习和混合方法在垃圾图像分类任务上的表现，提出了一种高效的混合模型，在多个数据集上达到了极高的准确率，并能显著降低计算成本，适用于资源受限环境。


<details>
  <summary>Details</summary>
Motivation: 现有的基于图像的自动化垃圾分类方法缺乏系统的基准测试，未能有效整合机器学习、深度学习和混合方法，以确定最高效的策略。

Method: 研究人员比较了三种方法：1. 使用手工特征的机器学习算法；2. 包括ResNet和EfficientNetV2S在内的深度学习模型；3. 结合深度模型提取特征和支持向量机、逻辑回归等传统分类器的混合方法。实验在TrashNet、Garbage Classification和改进后的Household Garbage Dataset上进行，并进行了特征选择以降低维度。

Result: 混合方法在所有三个数据集上均表现最佳，在TrashNet和改进后的Household Garbage Dataset上达到100%的准确率，在Garbage Classification上达到99.87%的准确率，超过了现有最佳基准。特征选择将维度降低了95%以上，同时保持了准确率，并加快了训练和推理速度。

Conclusion: 该研究建立了更可靠的垃圾分类基准，并提出了一种高效的混合框架，该框架在实现高准确率的同时降低了推理成本，适合在资源受限的环境中进行可扩展部署。

Abstract: Automated image-based garbage classification is a critical component of
global waste management; however, systematic benchmarks that integrate Machine
Learning (ML), Deep Learning (DL), and efficient hybrid solutions remain
underdeveloped. This study provides a comprehensive comparison of three
paradigms: (1) machine learning algorithms using handcrafted features, (2) deep
learning architectures, including ResNet variants and EfficientNetV2S, and (3)
a hybrid approach that utilizes deep models for feature extraction combined
with classical classifiers such as Support Vector Machine and Logistic
Regression to identify the most effective strategy. Experiments on three public
datasets - TrashNet, Garbage Classification, and a refined Household Garbage
Dataset (with 43 corrected mislabels)- demonstrate that the hybrid method
consistently outperforms the others, achieving up to 100% accuracy on TrashNet
and the refined Household set, and 99.87% on Garbage Classification, thereby
surpassing state-of-the-art benchmarks. Furthermore, feature selection reduces
feature dimensionality by over 95% without compromising accuracy, resulting in
faster training and inference. This work establishes more reliable benchmarks
for waste classification and introduces an efficient hybrid framework that
achieves high accuracy while reducing inference cost, making it suitable for
scalable deployment in resource-constrained environments.

</details>


### [44] [Evaluating ChatGPT's Performance in Classifying Pneumonia from Chest X-Ray Images](https://arxiv.org/abs/2510.21839)
*Pragna Prahallad,Pranathi Prahallad*

Main category: cs.CV

TL;DR: GPT-4o 在零样本设置下对胸部 X 光图像进行分类，简洁、面向特征的提示准确率为 74%，但诊断可靠性仍然有限。


<details>
  <summary>Details</summary>
Motivation: 评估 OpenAI 的 gpt-4o 模型在零样本设置下对胸部 X 光图像进行分类的能力。

Method: 使用平衡的测试集（400 张图像，每类 200 张）来评估四种不同的提示设计，从最少的指令到详细的、基于推理的提示。

Result: 简洁、面向特征的提示实现了 74% 的最高分类准确率，而面向推理的提示导致性能下降。

Conclusion: 虽然 ChatGPT 表现出医学图像解释的新兴潜力，但其诊断可靠性仍然有限，需要进一步的视觉推理和特定领域的适应才能在临床实践中安全应用。

Abstract: In this study, we evaluate the ability of OpenAI's gpt-4o model to classify
chest X-ray images as either NORMAL or PNEUMONIA in a zero-shot setting,
without any prior fine-tuning. A balanced test set of 400 images (200 from each
class) was used to assess performance across four distinct prompt designs,
ranging from minimal instructions to detailed, reasoning-based prompts. The
results indicate that concise, feature-focused prompts achieved the highest
classification accuracy of 74\%, whereas reasoning-oriented prompts resulted in
lower performance. These findings highlight that while ChatGPT exhibits
emerging potential for medical image interpretation, its diagnostic reliability
remains limited. Continued advances in visual reasoning and domain-specific
adaptation are required before such models can be safely applied in clinical
practice.

</details>


### [45] [RatioWaveNet: A Learnable RDWT Front-End for Robust and Interpretable EEG Motor-Imagery Classification](https://arxiv.org/abs/2510.21841)
*Marco Siino,Giuseppe Bonomo,Rosario Sorbello,Ilenia Tinnirello*

Main category: cs.CV

TL;DR: RatioWaveNet通过在TCFormer（一种强大的时域CNN-Transformer骨干网络）中加入一个可训练的、理性膨胀小波变换（RDWT）前端，来增强基于运动想象（MI）的脑机接口（BCI），以提高最差受试者的准确性，同时保持效率。


<details>
  <summary>Details</summary>
Motivation: 目前的脑机接口（BCI）在从非侵入式脑电图（EEG）解码运动意图方面仍然面临挑战，尤其是在处理非平稳性、低信噪比和被试变异性方面。本研究旨在测试RDWT前端是否能提高BCI在最困难的受试者上的鲁棒性，并评估这些改进在不同协议下的一致性。

Method: 提出RatioWaveNet模型，它结合了一个可训练的RDWT前端和一个TCFormer骨干网络。RDWT进行多分辨率子带分解，以增强运动感觉节律并减轻伪影。子带通过分组1-D卷积进行融合，然后输入到多核CNN、分组查询注意力编码器和TCN头中进行特征提取和时间整合。

Result: 在BCI-IV-2a和BCI-IV-2b数据集上，RatioWaveNet在最差受试者的准确性上分别比单独的Transformer骨干网络提高了+0.17/+0.42个百分点（依赖受试者/留一法）和+1.07/+2.54个百分点（依赖受试者/留一法），并且在平均情况下也显示出持续的性能提升，计算开销适中。

Conclusion: 一个简单、可训练的小波前端是增强基于Transformer的BCI的有效插件，可以在不牺牲效率的情况下提高最差情况下的可靠性。

Abstract: Brain-computer interfaces (BCIs) based on motor imagery (MI) translate covert
movement intentions into actionable commands, yet reliable decoding from
non-invasive EEG remains challenging due to nonstationarity, low SNR, and
subject variability. We present RatioWaveNet, which augments a strong temporal
CNN-Transformer backbone (TCFormer) with a trainable, Rationally-Dilated
Wavelet Transform (RDWT) front end. The RDWT performs an undecimated,
multi-resolution subband decomposition that preserves temporal length and
shift-invariance, enhancing sensorimotor rhythms while mitigating jitter and
mild artifacts; subbands are fused via lightweight grouped 1-D convolutions and
passed to a multi-kernel CNN for local temporal-spatial feature extraction, a
grouped-query attention encoder for long-range context, and a compact TCN head
for causal temporal integration.
  Our goal is to test whether this principled wavelet front end improves
robustness precisely where BCIs typically fail - on the hardest subjects - and
whether such gains persist on average across seeds under both intra- and
inter-subject protocols. On BCI-IV-2a and BCI-IV-2b, across five seeds,
RatioWaveNet improves worst-subject accuracy over the Transformer backbone by
+0.17 / +0.42 percentage points (Sub-Dependent / LOSO) on 2a and by +1.07 /
+2.54 percentage points on 2b, with consistent average-case gains and modest
computational overhead. These results indicate that a simple, trainable wavelet
front end is an effective plug-in to strengthen Transformer-based BCIs,
improving worst-case reliability without sacrificing efficiency.

</details>


### [46] [Modal Aphasia: Can Unified Multimodal Models Describe Images From Memory?](https://arxiv.org/abs/2510.21842)
*Michael Aerni,Joshua Swanson,Kristina Nikolić,Florian Tramèr*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We present modal aphasia, a systematic dissociation in which current unified
multimodal models accurately memorize concepts visually but fail to articulate
them in writing, despite being trained on images and text simultaneously. For
one, we show that leading frontier models can generate near-perfect
reproductions of iconic movie artwork, but confuse crucial details when asked
for textual descriptions. We corroborate those findings through controlled
experiments on synthetic datasets in multiple architectures. Our experiments
confirm that modal aphasia reliably emerges as a fundamental property of
current unified multimodal models, not just as a training artifact. In
practice, modal aphasia can introduce vulnerabilities in AI safety frameworks,
as safeguards applied to one modality may leave harmful concepts accessible in
other modalities. We demonstrate this risk by showing how a model aligned
solely on text remains capable of generating unsafe images.

</details>


### [47] [SCoPE VLM: Selective Context Processing for Efficient Document Navigation in Vision-Language Models](https://arxiv.org/abs/2510.21850)
*Gyubeum Lim,Yemo Koo,Vijay Krishna Madisetti*

Main category: cs.CV

TL;DR: SCoPE VLM是一个创新的视觉语言模型，通过新颖的


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型在理解长上下文视觉信息方面存在挑战，特别是在GUI控制和网页导航等任务中。它们通常忽略了文档的结构化特性和面向决策的理解，并且在处理长高分辨率输入时内存消耗大，不适用于本地部署。

Method: 提出SCoPE VLM，一个文档导航专家，利用新颖的

Result: 该方法显著减少了内存使用，并能有效模拟类似人类的阅读行为。

Conclusion: SCoPE VLM是第一个明确模拟多页文档问答中代理阅读模式的框架，提升了多模态代理的能力。

Abstract: Understanding long-context visual information remains a fundamental challenge
for vision-language models, particularly in agentic tasks such as GUI control
and web navigation. While web pages and GUI environments are inherently
structured documents, current VLMs typically neglect decision-oriented document
understanding in their training objectives. Existing approaches primarily
extend visual embeddings to process long, high-resolution inputs, but these
methods are memory-intensive and impractical for locally deployable solutions.
To address these issues, we propose SCoPE VLM, a document navigation expert
that leverages a novel Chain of Scroll mechanism to selectively and recursively
navigate documents, focusing exclusively on relevant segments. We introduce a
dedicated data generation pipeline to construct informative Chain of Scroll
trajectories and Episodic Group Relative Policy Optimization, a tailored
reinforcement learning method to reduce the gap between training and inference.
Our method substantially reduces memory usage and effectively models human-like
reading behaviors. To the best of our knowledge, SCoPE VLM is the first
framework to explicitly model agentic reading patterns in multi-page document
question answering, advancing the capabilities of multimodal agents.

</details>


### [48] [Poisson Flow Consistency Training](https://arxiv.org/abs/2510.21857)
*Anthony Zhang,Mahmut Gokmen,Dennis Hein,Rongjun Ge,Wenjun Xia,Ge Wang,Jin Chen*

Main category: cs.CV

TL;DR: PFCM只能通过蒸馏进行训练，限制了其在多种数据模式下的应用。本研究提出了独立训练PFCM的方法——PFCT，通过引入扰动核、正弦离散化和Beta噪声分布，提高了模型适应性和样本质量。PFCT在低剂量CT图像去噪任务中表现出色，在LPIPS和SSIM方面有所提升，并显示出与其他模型相当的去噪效果，为PFCM的创建和应用带来了更大的灵活性。


<details>
  <summary>Details</summary>
Motivation: 现有的PFCM模型只能通过蒸馏进行训练，这在很大程度上限制了其在各种数据模式下的应用潜力。因此，有必要开发一种能够独立训练PFCM的方法。

Method: 该研究引入了一种名为PFCT（Poisson Flow Consistency Training）的新方法，用于独立训练PFCM。该方法利用扰动核来移除预训练的PFGM++，并结合了正弦离散化和Beta噪声分布，以增强模型的适应性和改善样本质量。

Result: PFCT在低剂量CT图像去噪任务中取得了显著成效，其去噪后的图像在LPIPS和SSIM指标上均有所提升。此外，PFCT在去噪效果方面与一致性模型（Consistency Model）等现有模型相当。

Conclusion: PFCT已被证明是一种有效的PFCM训练方法，在CT图像去噪任务中展现出与其它生成模型相媲美的竞争力。尽管PFCT在优化和应用于其他生成模型任务方面仍需进一步研究，但该框架为PFCM的创建和在生成模型领域的应用提供了更大的灵活性。

Abstract: The Poisson Flow Consistency Model (PFCM) is a consistency-style model based
on the robust Poisson Flow Generative Model++ (PFGM++) which has achieved
success in unconditional image generation and CT image denoising. Yet the PFCM
can only be trained in distillation which limits the potential of the PFCM in
many data modalities. The objective of this research was to create a method to
train the PFCM in isolation called Poisson Flow Consistency Training (PFCT).
The perturbation kernel was leveraged to remove the pretrained PFGM++, and the
sinusoidal discretization schedule and Beta noise distribution were introduced
in order to facilitate adaptability and improve sample quality. The model was
applied to the task of low dose computed tomography image denoising and
improved the low dose image in terms of LPIPS and SSIM. It also displayed
similar denoising effectiveness as models like the Consistency Model. PFCT is
established as a valid method of training the PFCM from its effectiveness in
denoising CT images, showing potential with competitive results to other
generative models. Further study is needed in the precise optimization of PFCT
and in its applicability to other generative modeling tasks. The framework of
PFCT creates more flexibility for the ways in which a PFCM can be created and
can be applied to the field of generative modeling.

</details>


### [49] [A Multi-Stage Hybrid Framework for Automated Interpretation of Multi-View Engineering Drawings Using Vision Language Model](https://arxiv.org/abs/2510.21862)
*Muhammad Tayyab Khan,Zane Yong,Lequn Chen,Wenhe Feng,Nicholas Yew Jin Tan,Seung Ki Moon*

Main category: cs.CV

TL;DR: 提出一种三阶段混合框架，利用YOLOv11和基于Donut的视觉语言模型（VLMs）自动解析2D工程图纸，用于制造业。


<details>
  <summary>Details</summary>
Motivation: 手动解析工程图纸具有挑战性，尤其是在处理复杂的、带有密集标注的多视图图纸时。现有的OCR和深度学习方法在处理多变布局、方向和混合符号文本内容方面存在不足。

Method: 该框架分为三个阶段：1. 使用YOLOv11-det进行布局分割，识别视图、标题栏和注释等关键区域。2. 使用YOLOv11-obb进行细粒度、面向方向的标注（尺寸、形位公差符号、表面粗糙度）检测。3. 使用两个基于Donut的、无OCR的VLMs：字母VLM用于文本和分类信息提取（标题栏、注释），数值VLM用于量化数据解释（尺寸、形位公差、表面粗糙度）。

Result: 在为布局检测和标注级别训练专门创建的数据集上，字母VLM达到了0.672的F1分数，数值VLM达到了0.963的F1分数，表明了它们在文本和量化信息解释方面的强大性能。

Conclusion: 该框架通过结合先进的检测和视觉语言模型，实现了工程图纸的自动化解析，并生成统一的JSON输出，可无缝集成到CAD和制造数据库中，为智能工程图纸分析提供了可扩展的解决方案。

Abstract: Engineering drawings are fundamental to manufacturing communication, serving
as the primary medium for conveying design intent, tolerances, and production
details. However, interpreting complex multi-view drawings with dense
annotations remains challenging using manual methods, generic optical character
recognition (OCR) systems, or traditional deep learning approaches, due to
varied layouts, orientations, and mixed symbolic-textual content. To address
these challenges, this paper proposes a three-stage hybrid framework for the
automated interpretation of 2D multi-view engineering drawings using modern
detection and vision language models (VLMs). In the first stage, YOLOv11-det
performs layout segmentation to localize key regions such as views, title
blocks, and notes. The second stage uses YOLOv11-obb for orientation-aware,
fine-grained detection of annotations, including measures, GD&T symbols, and
surface roughness indicators. The third stage employs two Donut-based, OCR-free
VLMs for semantic content parsing: the Alphabetical VLM extracts textual and
categorical information from title blocks and notes, while the Numerical VLM
interprets quantitative data such as measures, GD&T frames, and surface
roughness. Two specialized datasets were developed to ensure robustness and
generalization: 1,000 drawings for layout detection and 1,406 for
annotation-level training. The Alphabetical VLM achieved an overall F1 score of
0.672, while the Numerical VLM reached 0.963, demonstrating strong performance
in textual and quantitative interpretation, respectively. The unified JSON
output enables seamless integration with CAD and manufacturing databases,
providing a scalable solution for intelligent engineering drawing analysis.

</details>


### [50] [Addressing Corner Cases in Autonomous Driving: A World Model-based Approach with Mixture of Experts and LLMs](https://arxiv.org/abs/2510.21867)
*Haicheng Liao,Bonan Wang,Junxian Yang,Chengyue Wang,Zhengbin He,Guohui Zhang,Chengzhong Xu,Zhenning Li*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Accurate and reliable motion forecasting is essential for the safe deployment
of autonomous vehicles (AVs), particularly in rare but safety-critical
scenarios known as corner cases. Existing models often underperform in these
situations due to an over-representation of common scenes in training data and
limited generalization capabilities. To address this limitation, we present
WM-MoE, the first world model-based motion forecasting framework that unifies
perception, temporal memory, and decision making to address the challenges of
high-risk corner-case scenarios. The model constructs a compact scene
representation that explains current observations, anticipates future dynamics,
and evaluates the outcomes of potential actions. To enhance long-horizon
reasoning, we leverage large language models (LLMs) and introduce a lightweight
temporal tokenizer that maps agent trajectories and contextual cues into the
LLM's feature space without additional training, enriching temporal context and
commonsense priors. Furthermore, a mixture-of-experts (MoE) is introduced to
decompose complex corner cases into subproblems and allocate capacity across
scenario types, and a router assigns scenes to specialized experts that infer
agent intent and perform counterfactual rollouts. In addition, we introduce
nuScenes-corner, a new benchmark that comprises four real-world corner-case
scenarios for rigorous evaluation. Extensive experiments on four benchmark
datasets (nuScenes, NGSIM, HighD, and MoCAD) showcase that WM-MoE consistently
outperforms state-of-the-art (SOTA) baselines and remains robust under
corner-case and data-missing conditions, indicating the promise of world
model-based architectures for robust and generalizable motion forecasting in
fully AVs.

</details>


### [51] [AI Powered Urban Green Infrastructure Assessment Through Aerial Imagery of an Industrial Township](https://arxiv.org/abs/2510.21876)
*Anisha Dutta*

Main category: cs.CV

TL;DR: 本研究提出一种利用人工智能和计算机视觉技术，结合面向对象的图像分析和深度学习算法，通过高分辨率无人机影像精确估算城市树冠覆盖率的方法。


<details>
  <summary>Details</summary>
Motivation: 准确评估城市树冠覆盖对于城市规划、环境监测和应对气候变化至关重要，但传统方法存在技术、可扩展性、数据处理和专业知识方面的局限性。

Method: 利用深度学习算法进行面向对象的图像分析，从高分辨率无人机影像中识别和分割绿化树冠，并在云平台上利用高性能处理器处理大规模数据集，以克服计算挑战。

Result: 该方法在城市尺度上准确估算了树冠覆盖率，为工业区的城市林业管理提供了有价值的见解，生成的数据可用于优化植树造林和评估城市森林的碳汇能力。

Conclusion: 通过将这些见解纳入可持续城市规划，可以创建更具韧性的城市环境，为建设更绿色、更健康的未来做出贡献。

Abstract: Accurate assessment of urban canopy coverage is crucial for informed urban
planning, effective environmental monitoring, and mitigating the impacts of
climate change. Traditional practices often face limitations due to inadequate
technical requirements, difficulties in scaling and data processing, and the
lack of specialized expertise. This study presents an efficient approach for
estimating green canopy coverage using artificial intelligence, specifically
computer vision techniques, applied to aerial imageries. Our proposed
methodology utilizes object-based image analysis, based on deep learning
algorithms to accurately identify and segment green canopies from
high-resolution drone images. This approach allows the user for detailed
analysis of urban vegetation, capturing variations in canopy density and
understanding spatial distribution. To overcome the computational challenges
associated with processing large datasets, it was implemented over a cloud
platform utilizing high-performance processors. This infrastructure efficiently
manages space complexity and ensures affordable latency, enabling the rapid
analysis of vast amounts of drone imageries. Our results demonstrate the
effectiveness of this approach in accurately estimating canopy coverage at the
city scale, providing valuable insights for urban forestry management of an
industrial township. The resultant data generated by this method can be used to
optimize tree plantation and assess the carbon sequestration potential of urban
forests. By integrating these insights into sustainable urban planning, we can
foster more resilient urban environments, contributing to a greener and
healthier future.

</details>


### [52] [TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge](https://arxiv.org/abs/2510.21879)
*Shu-Hao Zhang,Wei-Cheng Tang,Chen Wu,Peng Hu,Nan Li,Liang-Jie Zhang,Qi Zhang,Shao-Qun Zhang*

Main category: cs.CV

TL;DR: TernaryCLIP是一个轻量级的计算框架，通过将CLIP的视觉和文本编码器的连接权重转换为三元格式，实现了高达99%的权重三元化，并能在保持性能的同时大幅压缩模型、加速推理和减少内存占用，适用于资源受限设备。


<details>
  <summary>Details</summary>
Motivation: 随着图像-文本对比学习模型（如CLIP）的兴起，对这些模型进行轻量化和高效计算的需求日益增长，特别是在资源受限设备上的部署。

Method: 提出TernaryCLIP框架，将CLIP的连接权重转换为三元格式（而非全精度或浮点格式）。该框架结合了感知量化训练和知识蒸馏模块，以防止精度下降，并实现低成本、高效率的计算。

Result: TernaryCLIP实现了高达99%的权重三元化（1.58位表示），压缩比达到16.98倍，推理速度提升2.3倍，存储空间减少16倍，内存占用优化10倍，稀疏度达到60%。在零样本图像分类和图像-文本检索任务中，性能与原始CLIP模型相当，并在41个常用数据集上进行了验证。

Conclusion: 极度量化对于大型多模态模型是可行的，能够支持在资源受限设备上的有效和高效部署。TernaryCLIP证明了在不显著牺牲性能的情况下，大幅优化模型计算效率的可能性。

Abstract: Recent years have witnessed an increasing interest in image-text contrastive
modeling, exemplified by models such as Contrastive Language-Image Pretraining
(CLIP). In this paper, we propose the TernaryCLIP, a lightweight computational
framework that converts connection weights of both vision and text encoders of
CLIP into the ternary format, instead of full-precision or floating ones.
TernaryCLIP incorporates quantization-aware training and distillation modules,
preventing precision degradation and enabling low-cost and high-efficiency
computations. Comprehensive experiments demonstrate that TernaryCLIP can
achieve up to 99\% ternarized weights with 1.58-bit representation, 16.98
$\times$ compression ratio, 2.3 $\times$ inference acceleration, 16 $\times$
storage reduction, 10 $\times$ memory optimization, and 60\% sparsity while
maintaining promising performance on zero-shot image classification and
image-text retrieval tasks across 41 commonly used datasets. Our work
highlights the feasibility of extreme quantization for large multimodal models,
supporting effective and efficient deployment on resource-constrained devices.
The model and code can be accessed from Hugging Face and GitHub.

</details>


### [53] [Generative AI in Depth: A Survey of Recent Advances, Model Variants, and Real-World Applications](https://arxiv.org/abs/2510.21887)
*Shamim Yazdani,Akansha Singh,Nripsuta Saxena,Zichong Wang,Avash Palikhe,Deng Pan,Umapada Pal,Jie Yang,Wenbin Zhang*

Main category: cs.CV

TL;DR: 深度学习生成模型（GANs、VAEs、DMs）在内容生成方面取得了显著进展，但研究、应用和技术挑战的快速增长给研究人员带来了跟进的困难。本篇综述旨在通过一个全面的分类体系来组织现有文献，并提供一个理解GANs、VAEs和DMs发展（包括其变体和组合方法）的凝聚力框架。


<details>
  <summary>Details</summary>
Motivation: 由于深度学习生成模型（GANs、VAEs、DMs）的研究、应用和技术挑战发展迅速，研究人员难以跟上最新的进展。本综述旨在通过提供一个全面的分类体系来应对这一挑战，从而帮助研究人员理解该领域的发展。

Method: 本综述通过一个全面的分类体系来组织GANs、VAEs和DMs的文献，并总结了提高生成内容质量、多样性和可控性的关键技术创新。此外，本综述还讨论了相关的伦理问题和未来的研究方向。

Result: 本综述总结了GANs、VAEs和DMs在提高生成内容质量、多样性和可控性方面的关键技术进展，并探讨了合成媒体带来的伦理问题，如滥用风险和社会影响。

Conclusion: 本综述提供了一个结构化的、前瞻性的视角，以应对生成式人工智能领域快速发展的挑战，并为研究人员指明了未来的研究方向。

Abstract: In recent years, deep learning based generative models, particularly
Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and
Diffusion Models (DMs), have been instrumental in in generating diverse,
high-quality content across various domains, such as image and video synthesis.
This capability has led to widespread adoption of these models and has captured
strong public interest. As they continue to advance at a rapid pace, the
growing volume of research, expanding application areas, and unresolved
technical challenges make it increasingly difficult to stay current. To address
this need, this survey introduces a comprehensive taxonomy that organizes the
literature and provides a cohesive framework for understanding the development
of GANs, VAEs, and DMs, including their many variants and combined approaches.
We highlight key innovations that have improved the quality, diversity, and
controllability of generated outputs, reflecting the expanding potential of
generative artificial intelligence. In addition to summarizing technical
progress, we examine rising ethical concerns, including the risks of misuse and
the broader societal impact of synthetic media. Finally, we outline persistent
challenges and propose future research directions, offering a structured and
forward looking perspective for researchers in this fast evolving field.

</details>


### [54] [Sprint: Sparse-Dense Residual Fusion for Efficient Diffusion Transformers](https://arxiv.org/abs/2510.21986)
*Dogyun Park,Moayed Haji-Ali,Yanyu Li,Willi Menapace,Sergey Tulyakov,Hyunwoo J. Kim,Aliaksandr Siarohin,Anil Kag*

Main category: cs.CV

TL;DR: SPRINT是一种用于高效Diffusion Transformers（DiTs）的稀疏-密集残差融合方法，通过在早期层处理所有token，在较深层处理稀疏token，并融合它们的输出来实现高达75%的token丢弃率，从而显著降低训练成本并提高推理效率。


<details>
  <summary>Details</summary>
Motivation: DiTs在生成任务中表现出色，但其训练成本与序列长度呈二次方关系，限制了大规模预训练。现有的token丢弃方法要么引入额外参数，要么在高丢弃率下性能下降。

Method: SPRINT采用一种两阶段训练策略：首先进行长时间的掩码预训练以提高效率，然后进行短时间的完全token微调以缩小训练-推理差距。其核心在于利用浅层和深层处理不同数量的token，并通过残差连接融合它们的输出。

Result: 在ImageNet-1K 256x256数据集上，SPRINT实现了9.8倍的训练成本节省，同时保持了可比的FID/FDD分数。在推理时，其Path-Drop Guidance（PDG）将FLOPs降低近一半，同时提高了图像质量。

Conclusion: SPRINT是一种简单、有效且通用的解决方案，可显著提高DiT的训练效率，同时保持生成质量和推理性能。

Abstract: Diffusion Transformers (DiTs) deliver state-of-the-art generative performance
but their quadratic training cost with sequence length makes large-scale
pretraining prohibitively expensive. Token dropping can reduce training cost,
yet na\"ive strategies degrade representations, and existing methods are either
parameter-heavy or fail at high drop ratios. We present SPRINT, Sparse--Dense
Residual Fusion for Efficient Diffusion Transformers, a simple method that
enables aggressive token dropping (up to 75%) while preserving quality. SPRINT
leverages the complementary roles of shallow and deep layers: early layers
process all tokens to capture local detail, deeper layers operate on a sparse
subset to cut computation, and their outputs are fused through residual
connections. Training follows a two-stage schedule: long masked pre-training
for efficiency followed by short full-token fine-tuning to close the
train--inference gap. On ImageNet-1K 256x256, SPRINT achieves 9.8x training
savings with comparable FID/FDD, and at inference, its Path-Drop Guidance (PDG)
nearly halves FLOPs while improving quality. These results establish SPRINT as
a simple, effective, and general solution for efficient DiT training.

</details>


### [55] [LiteDiff](https://arxiv.org/abs/2510.22004)
*Ruchir Namjoshi,Nagasai Thadishetty,Vignesh Kumar,Hemanth Venkateshwara*

Main category: cs.CV

TL;DR: LiteDiff通过集成轻量级适配层、潜在形态自动编码器和像素级判别器，实现对扩散模型的轻量级微调，在医学影像等低数据领域取得了优于全微调的效果。


<details>
  <summary>Details</summary>
Motivation: 由于特定领域（如医学影像）的数据有限和全模型适应的高计算成本，对扩散模型进行微调具有挑战性。

Method: LiteDiff冻结基础模型的权重，仅优化小的残差适配器模块，并集成了一个潜在形态自动编码器（用于领域特定潜在一致性）和一个像素级判别器（用于对抗性对齐）。

Result: 在三个胸部X射线数据集上进行实验，证明LiteDiff实现了优越的适应效率，并且通过消融研究分析了在不同U-Net块中选择性集成适配层的影响，揭示了效率和性能之间的最佳平衡。

Conclusion: LiteDiff框架为扩散模型中的迁移学习提供了一个有前景的方向，有利于其在各种低数据域中的部署。

Abstract: In recent years, diffusion models have demonstrated remarkable success in
high-fidelity image synthesis. However, fine-tuning these models for
specialized domains, such as medical imaging, remains challenging due to
limited domain-specific data and the high computational cost of full model
adaptation. In this paper, we introduce Lite-Diff (Lightweight Diffusion Model
Adaptation), a novel finetuning approach that integrates lightweight adaptation
layers into a frozen diffusion U-Net while enhancing training with a latent
morphological autoencoder (for domain-specific latent consistency) and a pixel
level discriminator(for adversarial alignment). By freezing weights of the base
model and optimizing only small residual adapter modules, LiteDiff
significantly reduces the computational overhead and mitigates overfitting,
even in minimal-data settings. Additionally, we conduct ablation studies to
analyze the effects of selectively integrating adaptation layers in different
U-Net blocks, revealing an optimal balance between efficiency and performance.
Experiments on three chest X-ray datasets - (1) Kaggle Chest X-Ray Pneumonia,
(2) NIH Chest X-ray14 and (3) VinBigData Chest X_ray demonstrate that LiteDiff
achieves superior adaptation efficiency compared to naive full fine-tuning. Our
framework provides a promising direction for transfer learning in diffusion
models, facilitating their deployment in diverse low data domains.

</details>


### [56] [FlowOpt: Fast Optimization Through Whole Flow Processes for Training-Free Editing](https://arxiv.org/abs/2510.22010)
*Or Ronai,Vladimir Kulikov,Tomer Michaeli*

Main category: cs.CV

TL;DR: FlowOpt是一个无需反向传播的零阶优化框架，可用于控制扩散和流匹配模型中的测试时生成，在图像编辑等任务中实现了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 现有的基于梯度的方法在扩散和流匹配模型中进行测试时控制是计算上不切实际的，因为它们需要通过整个采样过程进行反向传播，并且通常只单独操纵每个时间步。

Method: FlowOpt将整个流过程视为一个黑盒，通过整个采样路径进行优化，而无需对模型进行反向传播。它包括一个关于步长的收敛保证，以及一个用于选择适当步长的经验性上界估计。

Result: FlowOpt在图像编辑任务（包括反演和文本引导编辑）中实现了最先进的结果，其神经函数评估（NFE）数量与现有方法大致相同。

Conclusion: FlowOpt是一个高效且可扩展的框架，用于控制测试时生成，并保证收敛到全局最优。

Abstract: The remarkable success of diffusion and flow-matching models has ignited a
surge of works on adapting them at test time for controlled generation tasks.
Examples range from image editing to restoration, compression and
personalization. However, due to the iterative nature of the sampling process
in those models, it is computationally impractical to use gradient-based
optimization to directly control the image generated at the end of the process.
As a result, existing methods typically resort to manipulating each timestep
separately. Here we introduce FlowOpt - a zero-order (gradient-free)
optimization framework that treats the entire flow process as a black box,
enabling optimization through the whole sampling path without backpropagation
through the model. Our method is both highly efficient and allows users to
monitor the intermediate optimization results and perform early stopping if
desired. We prove a sufficient condition on FlowOpt's step-size, under which
convergence to the global optimum is guaranteed. We further show how to
empirically estimate this upper bound so as to choose an appropriate step-size.
We demonstrate how FlowOpt can be used for image editing, showcasing two
options: (i) inversion (determining the initial noise that generates a given
image), and (ii) directly steering the edited image to be similar to the source
image while conforming to a target text prompt. In both cases, FlowOpt achieves
state-of-the-art results while using roughly the same number of neural function
evaluations (NFEs) as existing methods. Code and examples are available on the
project's webpage.

</details>


### [57] [Reconnaissance Automatique des Langues des Signes : Une Approche Hybridée CNN-LSTM Basée sur Mediapipe](https://arxiv.org/abs/2510.22011)
*Fraisse Sacré Takouchouang,Ho Tuong Vinh*

Main category: cs.CV

TL;DR: 本研究提出了一种基于混合CNN-LSTM架构的自动手语识别系统，使用Mediapipe进行手势关键点提取，并使用Python、TensorFlow和Streamlit进行开发，可实现实时手势翻译。


<details>
  <summary>Details</summary>
Motivation: 手语在聋人社区的交流中至关重要，但常常被边缘化，限制了他们获得医疗和教育等基本服务的机会。

Method: 提出一种基于混合CNN-LSTM架构的自动手语识别系统，并使用Mediapipe进行手势关键点提取。系统使用Python、TensorFlow和Streamlit进行开发。

Result: 该系统平均准确率为92%，对于“你好”和“谢谢”等明显的手势表现良好，但对于“打电话”和“是”等视觉上相似的手势仍存在混淆。

Conclusion: 这项工作为在医疗、教育和公共服务等领域开发应用提供了有趣的前景。

Abstract: Sign languages play a crucial role in the communication of deaf communities,
but they are often marginalized, limiting access to essential services such as
healthcare and education. This study proposes an automatic sign language
recognition system based on a hybrid CNN-LSTM architecture, using Mediapipe for
gesture keypoint extraction. Developed with Python, TensorFlow and Streamlit,
the system provides real-time gesture translation. The results show an average
accuracy of 92\%, with very good performance for distinct gestures such as
``Hello'' and ``Thank you''. However, some confusions remain for visually
similar gestures, such as ``Call'' and ``Yes''. This work opens up interesting
perspectives for applications in various fields such as healthcare, education
and public services.

</details>


### [58] [Caption-Driven Explainability: Probing CNNs for Bias via CLIP](https://arxiv.org/abs/2510.22035)
*Patrick Koller,Amil V. Dravid,Guido M. Schuster,Aggelos K. Katsaggelos*

Main category: cs.CV

TL;DR: XAI方法结合CLIP模型，通过网络手术实现，以识别概念并提高模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型的鲁棒性问题以及现有XAI方法（如显著图）的局限性，即可能被虚假显着特征误导。

Method: 提出一种基于字幕的XAI方法，利用新颖的网络手术方法将待解释模型集成到CLIP模型中。

Result: 所提出的基于字幕的XAI模型能够识别出对模型预测贡献最大的主导概念。

Conclusion: 该方法能降低模型因协变量偏移而失败的风险，有助于提高机器学习模型的鲁棒性。

Abstract: Robustness has become one of the most critical problems in machine learning
(ML). The science of interpreting ML models to understand their behavior and
improve their robustness is referred to as explainable artificial intelligence
(XAI). One of the state-of-the-art XAI methods for computer vision problems is
to generate saliency maps. A saliency map highlights the pixel space of an
image that excites the ML model the most. However, this property could be
misleading if spurious and salient features are present in overlapping pixel
spaces. In this paper, we propose a caption-based XAI method, which integrates
a standalone model to be explained into the contrastive language-image
pre-training (CLIP) model using a novel network surgery approach. The resulting
caption-based XAI model identifies the dominant concept that contributes the
most to the models prediction. This explanation minimizes the risk of the
standalone model falling for a covariate shift and contributes significantly
towards developing robust ML models.

</details>


### [59] [VLM-SlideEval: Evaluating VLMs on Structured Comprehension and Perturbation Sensitivity in PPT](https://arxiv.org/abs/2510.22045)
*Hyeonsu Kang,Emily Bao,Anjan Goswami*

Main category: cs.CV

TL;DR: VLM-SlideEval是一个评估框架，用于评估视觉语言模型（VLM）在幻灯片理解方面的能力。该框架通过元素级提取、鲁棒性测试和高层理解能力来评估VLM。实验表明，VLM在像素级提取和跨幻灯片叙事结构方面表现不佳，但在单张幻灯片内容理解方面表现较好。


<details>
  <summary>Details</summary>
Motivation: 目前视觉语言模型（VLM）在评估多模态内容（包括演示幻灯片）方面的应用日益广泛，但其对幻灯片特有的理解能力仍有待深入研究，尤其是在模型驱动的代理流程中，VLM正扮演着越来越重要的评估者角色。

Method: VLM-SlideEval框架从三个维度评估VLM：1. 元素级提取：从幻灯片图像中提取元素并与真实情况进行比对；2. 鲁棒性测试：评估VLM在几何、风格和文本受到控制性扰动时的表现；3. 高层理解：例如从打乱顺序的幻灯片中恢复演示文稿的叙事顺序。该框架使用Zenodo公开的演示文稿数据集，并将PowerPoint XML和实时渲染的内容标准化为统一、可验证的模式，作为真实元数据。

Result: 实验结果表明，VLM在像素级准确提取方面表现不佳，并且在受到控制性扰动时，其一致性、保真度和可靠性表现不一，但在单张幻灯片的内容理解方面表现更好。然而，VLM在跨幻灯片捕捉叙事结构方面并不可靠。

Conclusion: 当前VLM在幻灯片评估方面存在局限性，这表明需要开发经过校准的、包含评估者在内的迭代式评估工具，以驱动代理流程中的迭代改进和选择。

Abstract: Vision-language models (VLMs) are increasingly used to evaluate multimodal
content, including presentation slides, yet their slide-specific understanding
remains underexplored {despite their growing role as critics in agentic,
model-forward pipelines}. We introduce VLM-SlideEval, an evaluation framework
that probes VLMs along three axes: (1) element-level extraction from slide
images aligned to ground truth; (2) robustness to controlled perturbations in
geometry, style, and text; and (3) higher-level comprehension, such as
recovering a deck's narrative order from shuffled slides. Using publicly
available decks from Zenodo
(https://huggingface.co/datasets/Forceless/Zenodo10K/viewer/default/pptx), we
standardize ground-truth element metadata from PowerPoint XML and live
renderings into a unified, verifiable schema. Empirically, VLMs underperform on
pixel-accurate extraction and show non-trivial agreement, fidelity, and
consistency under controlled perturbations, while performing better on
single-slide content understanding; however, they do not reliably capture
narrative structure across slides. These results highlight the limits of
current VLMs for slide evaluation and motivate calibrated, critic-in-the-loop
evaluators that drive iterative refinement and selection in agentic pipelines.

</details>


### [60] [Human-Centric Anomaly Detection in Surveillance Videos Using YOLO-World and Spatio-Temporal Deep Learning](https://arxiv.org/abs/2510.22056)
*Mohammad Ali Etemadi Naeen,Hoda Mohammadzade,Saeed Bagheri Shouraki*

Main category: cs.CV

TL;DR: 本研究提出了一种新颖的深度学习框架，通过以人为中心的预处理和时空建模来解决监控视频中的多类别异常检测问题。


<details>
  <summary>Details</summary>
Motivation: 监控视频中的异常检测因异常事件的多样性、类别不平衡以及场景依赖性视觉干扰而面临挑战。

Method: 该框架首先使用YOLO-World检测人体实例，然后使用ByteTrack进行身份感知跟踪。通过高斯模糊抑制背景区域，并使用InceptionV3提取空间特征，最后利用双向LSTM捕捉时间动态以进行序列级分类。

Result: 在UCF-Crime数据集的五类别子集上（正常、入店行窃、打斗、纵火、爆炸），该方法实现了92.41%的平均测试准确率，类别F1分数均超过0.85，并在多个评估指标上表现出良好的泛化能力和对类别不平衡的鲁棒性。

Conclusion: 研究结果表明，以前景为中心的预处理显著提高了在实际监控场景中区分异常事件的能力。

Abstract: Anomaly detection in surveillance videos remains a challenging task due to
the diversity of abnormal events, class imbalance, and scene-dependent visual
clutter. To address these issues, we propose a robust deep learning framework
that integrates human-centric preprocessing with spatio-temporal modeling for
multi-class anomaly classification. Our pipeline begins by applying YOLO-World
- an open-vocabulary vision-language detector - to identify human instances in
raw video clips, followed by ByteTrack for consistent identity-aware tracking.
Background regions outside detected bounding boxes are suppressed via Gaussian
blurring, effectively reducing scene-specific distractions and focusing the
model on behaviorally relevant foreground content. The refined frames are then
processed by an ImageNet-pretrained InceptionV3 network for spatial feature
extraction, and temporal dynamics are captured using a bidirectional LSTM
(BiLSTM) for sequence-level classification. Evaluated on a five-class subset of
the UCF-Crime dataset (Normal, Burglary, Fighting, Arson, Explosion), our
method achieves a mean test accuracy of 92.41% across three independent trials,
with per-class F1-scores consistently exceeding 0.85. Comprehensive evaluation
metrics - including confusion matrices, ROC curves, and macro/weighted averages
- demonstrate strong generalization and resilience to class imbalance. The
results confirm that foreground-focused preprocessing significantly enhances
anomaly discrimination in real-world surveillance scenarios.

</details>


### [61] [Capturing Gaze Shifts for Guidance: Cross-Modal Fusion Enhancement for VLM Hallucination Mitigation](https://arxiv.org/abs/2510.22067)
*Zheng Qi,Chao Shang,Evangelia Spiliopoulou,Nikolaos Pappas*

Main category: cs.CV

TL;DR: GIFT通过利用“注视转移”来增强视觉-语言模型中的跨模态融合，从而减轻幻觉，提高在生成和分类任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言模型（VLM）在处理输入时常常产生幻觉，部分原因是过度依赖语言先验知识而非视觉输入，并且现有方法在处理视觉注意力分配和跨模态融合时存在不足，例如视觉注意力汇聚问题和跨模态融合不平衡。

Method: 提出了一种名为GIFT（Gaze Shift-Guided Cross-modal Fusion Enhancement）的方法。GIFT通过追踪用户查询理解过程中的视觉注意力变化（“注视转移”）来预先计算全局视觉显著性图，并在每个解码步骤中利用该图来增强显著视觉信息和用户查询的注意力，以解决视觉注意力汇聚问题并确保跨模态融合的平衡。

Result: GIFT能有效减轻VLM在生成和分类任务中的幻觉问题，相比贪婪解码有高达20.7%的提升，同时保持了良好的视觉-语言性能，并且计算开销低。

Conclusion: GIFT是一种有效的方法，通过引导跨模态融合来减轻VLM的幻觉问题，并在不显著增加计算成本的情况下提高了模型的性能。

Abstract: Vision language models (VLMs) often generate hallucination, i.e., content
that cannot be substantiated by either textual or visual inputs. Prior work
primarily attributes this to over-reliance on linguistic prior knowledge rather
than visual inputs. Some methods attempt to mitigate hallucination by
amplifying visual token attention proportionally to their attention scores.
However, these methods overlook the visual attention sink problem, where
attention is frequently misallocated to task-irrelevant visual regions, and
neglect cross-modal fusion balance by enhancing only visual attention without
adjusting attention to the user query. This can result in amplifying incorrect
areas while failing to properly interpret the user query. To address these
challenges, we propose a simple yet effective method called Gaze Shift-Guided
Cross-modal Fusion Enhancement (GIFT). GIFT pre-computes a holistic visual
saliency map by tracking positive changes in visual attention, or "gaze
shifts", during user query comprehension, and leverages this map to amplify
attention to both salient visual information and the user query at each
decoding step. This reduces the impact of visual attention sink, as irrelevant
tokens exhibit minimal shifts, while ensuring balanced cross-modal fusion for
well-integrated representation. Extensive experiments show that GIFT
effectively mitigates hallucination in VLMs across both generative and
classification tasks, achieving up to 20.7% improvement over greedy decoding,
while maintaining general vision-language performance with low computational
overhead.

</details>


### [62] [Scanner-Agnostic MRI Harmonization via SSIM-Guided Disentanglement](https://arxiv.org/abs/2510.22073)
*Luca Caldera,Lara Cavinato,Francesca Ieva*

Main category: cs.CV

TL;DR: 提出一种新颖的基于图像的3D T1加权脑部MRI的协调框架，用于减少跨中心研究中的扫描仪和站点差异，同时保持解剖学保真度和下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 多中心研究中的MRI扫描仪型号、采集方案和成像位点差异造成的变异性阻碍了分析的一致性和泛化能力。

Method: 提出一种新颖的基于图像的协调框架，用于3D T1加权脑部MRI，该框架可分离解剖内容与扫描仪和位点特异性变异性。该模型采用基于结构相似性指数（SSIM）的可微分损失来保留生物学特征，同时减少跨站点变异性。该损失可分别评估图像亮度、对比度和结构分量。

Result: 在多个公开可用数据集上进行训练和验证，并在健康和临床人群中进行测试。采用多种风格目标（包括风格无关的参考）进行协调，产生了高质量的输出。协调后的图像在不同采集设置下实现了高度一致，同时保持了图像的解剖保真度。协调后，结构SSIM达到0.97，亮度SSIM为0.98-0.99，平均沃勒斯泰因距离显著降低。脑龄预测的平均绝对误差从5.36年降至3.30年，阿尔茨海默病分类的AUC从0.78升至0.85。

Conclusion: 所提出的框架增强了跨站点图像的一致性，保留了解剖保真度，并提高了下游模型的性能，为大规模多中心神经影像学研究提供了一个稳健且可泛化的解决方案。

Abstract: The variability introduced by differences in MRI scanner models, acquisition
protocols, and imaging sites hinders consistent analysis and generalizability
across multicenter studies. We present a novel image-based harmonization
framework for 3D T1-weighted brain MRI, which disentangles anatomical content
from scanner- and site-specific variations. The model incorporates a
differentiable loss based on the Structural Similarity Index (SSIM) to preserve
biologically meaningful features while reducing inter-site variability. This
loss enables separate evaluation of image luminance, contrast, and structural
components. Training and validation were performed on multiple publicly
available datasets spanning diverse scanners and sites, with testing on both
healthy and clinical populations. Harmonization using multiple style targets,
including style-agnostic references, produced consistent and high-quality
outputs. Visual comparisons, voxel intensity distributions, and SSIM-based
metrics demonstrated that harmonized images achieved strong alignment across
acquisition settings while maintaining anatomical fidelity. Following
harmonization, structural SSIM reached 0.97, luminance SSIM ranged from 0.98 to
0.99, and Wasserstein distances between mean voxel intensity distributions
decreased substantially. Downstream tasks showed substantial improvements: mean
absolute error for brain age prediction decreased from 5.36 to 3.30 years, and
Alzheimer's disease classification AUC increased from 0.78 to 0.85. Overall,
our framework enhances cross-site image consistency, preserves anatomical
fidelity, and improves downstream model performance, providing a robust and
generalizable solution for large-scale multicenter neuroimaging studies.

</details>


### [63] [Mitigating Coordinate Prediction Bias from Positional Encoding Failures](https://arxiv.org/abs/2510.22102)
*Xingjian Tao,Yiwei Wang,Yujun Cai,Yihong Luo,Jing Tang*

Main category: cs.CV

TL;DR: 高分辨率输入下的多模态大语言模型在精确坐标预测方面存在挑战，作者提出了VPSG方法来解决这个问题。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型在处理高分辨率输入时，坐标预测能力会受到位置编码和方向偏差的负面影响。

Method: 作者通过分析模型在视觉位置编码（VPE）被打乱时的行为，发现了模型在坐标预测中的偏差。在此基础上，提出了一种名为VPSG的训练无关的测试时方法，该方法利用打乱的VPE来辅助解码，并结合有限状态机来纠正坐标预测的偏差。

Result: 在ScreenSpot-Pro数据集上的实验表明，VPSG方法能够可靠地提高模型在坐标预测方面的准确性。

Conclusion: 提高位置编码的鲁棒性是多模态大语言模型进行空间推理的关键因素。

Abstract: Multimodal large language models (MLLMs) excel at vision-language tasks such
as VQA and document understanding, yet precise coordinate prediction remains
challenging. High-resolution inputs exacerbate this difficulty by producing
long token sequences that weaken positional encodings and introduce directional
biases in coordinate outputs. We investigate this phenomenon by analyzing how
MLLMs behave when visual positional encodings (VPEs) are deliberately perturbed
through shuffling. Our analysis reveals that such perturbations induce
predictable, non-random coordinate biases rather than random errors, suggesting
that models rely on internal positional priors when spatial grounding signals
are degraded. Crucially, we observe similar directional error patterns in
natural high-resolution datasets, indicating that positional encoding failures
are a key bottleneck for accurate coordinate prediction at scale. To address
this issue, we propose Vision-PE Shuffle Guidance (VPSG), a training-free
test-time method that leverages the directional nature of these biases for
correction. VPSG runs auxiliary decoding with shuffled VPEs to isolate
position-unconditioned tendencies, then uses this as negative evidence to guide
digit prediction while preserving coordinate format through a lightweight
finite-state machine. Experiments on ScreenSpot-Pro demonstrate reliable
improvements, highlighting positional encoding robustness as a critical factor
for spatial reasoning in MLLMs.

</details>


### [64] [Discovering Latent Graphs with GFlowNets for Diverse Conditional Image Generation](https://arxiv.org/abs/2510.22107)
*Bailey Trang,Parham Saremi,Alan Q. Wang,Fangrui Huang,Zahra TehraniNasab,Amar Kumar,Tal Arbel,Li Fei-Fei,Ehsan Adeli*

Main category: cs.CV

TL;DR: Rainbow是一个新的条件图像生成框架，它通过将输入条件分解为潜在表征来生成多样化和逼真的图像，能够改进图像合成、图像生成和反事实生成等任务。


<details>
  <summary>Details</summary>
Motivation: 在条件和基于提示的图像生成中，尤其是在条件包含不确定性导致可能出现多个合理输出时，捕捉多样性至关重要。传统方法难以区分样本间的有意义的差异或在口头可解释的多样性方面存在局限性。

Method: Rainbow框架将生成流网络（GFlowNets）集成到提示表征的计算中，利用GFlowNets的图采样能力来捕捉不确定性并生成多样的轨迹，从而产生多样化的条件表征和相应的输出图像。

Result: 在自然图像和医学图像数据集上的评估表明，Rainbow在图像合成、图像生成和反事实生成任务中的多样性和保真度方面均有所提高。

Conclusion: Rainbow通过将输入条件分解为潜在表征，有效解决了条件/提示不确定性问题，并生成了多样化且逼真的图像，在多个图像生成任务中表现出优越性。

Abstract: Capturing diversity is crucial in conditional and prompt-based image
generation, particularly when conditions contain uncertainty that can lead to
multiple plausible outputs. To generate diverse images reflecting this
diversity, traditional methods often modify random seeds, making it difficult
to discern meaningful differences between samples, or diversify the input
prompt, which is limited in verbally interpretable diversity. We propose
Rainbow, a novel conditional image generation framework, applicable to any
pretrained conditional generative model, that addresses inherent
condition/prompt uncertainty and generates diverse plausible images. Rainbow is
based on a simple yet effective idea: decomposing the input condition into
diverse latent representations, each capturing an aspect of the uncertainty and
generating a distinct image. First, we integrate a latent graph, parameterized
by Generative Flow Networks (GFlowNets), into the prompt representation
computation. Second, leveraging GFlowNets' advanced graph sampling capabilities
to capture uncertainty and output diverse trajectories over the graph, we
produce multiple trajectories that collectively represent the input condition,
leading to diverse condition representations and corresponding output images.
Evaluations on natural image and medical image datasets demonstrate Rainbow's
improvement in both diversity and fidelity across image synthesis, image
generation, and counterfactual generation tasks.

</details>


### [65] [GRAID: Enhancing Spatial Reasoning of VLMs Through High-Fidelity Data Generation](https://arxiv.org/abs/2510.22118)
*Karim Elmaaroufi,Liheng Lai,Justin Svegliato,Yutong Bai,Sanjit A. Seshia,Matei Zaharia*

Main category: cs.CV

TL;DR: GRAID是一个新框架，利用2D几何图元生成高质量的视觉问答（VQA）数据集，以提高视觉语言模型（VLMs）的空间推理能力。该框架通过仅使用2D边界框来避免3D重建错误和生成幻觉，从而生成比现有工具更高质量的数据集。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型（VLMs）在空间推理方面存在不足，而现有的数据集生成方法存在模型错误、答案容差大、注释不详细和生成幻觉等问题。

Method: GRAID框架利用2D边界框生成高质量的VQA数据集，用于训练VLMs的空间推理能力。

Result: GRAID生成的数据集通过了91.16%的人工验证，远高于现有方法的57.6%。使用GRAID数据训练的模型在空间推理任务上表现出良好的泛化能力，准确率提升显著。

Conclusion: GRAID框架能够生成高质量的VQA数据集，有效提升VLMs在空间推理方面的能力，并且展现出良好的泛化性。

Abstract: Vision Language Models (VLMs) achieve strong performance on many
vision-language tasks but often struggle with spatial reasoning\textemdash{}a
prerequisite for many applications. Empirically, we find that a dataset
produced by a current training data generation pipeline has a 57.6\% human
validation rate. These rates stem from current limitations: single-image 3D
reconstruction introduces cascading modeling errors and requires wide answer
tolerances, while caption-based methods require hyper-detailed annotations and
suffer from generative hallucinations. We present GRAID, built on the key
insight that qualitative spatial relationships can be reliably determined from
2D geometric primitives alone. By operating exclusively on 2D bounding boxes
from standard object detectors, GRAID avoids both 3D reconstruction errors and
generative hallucinations, resulting in datasets that are of higher quality
than existing tools that produce similar datasets as validated by human
evaluations. We apply our framework to the BDD100k, NuImages, and Waymo
datasets, generating over 8.5 million high-quality VQA pairs creating questions
spanning spatial relations, counting, ranking, and size comparisons. We
evaluate one of the datasets and find it achieves 91.16\% human-validated
accuracy\textemdash{}compared to 57.6\% on a dataset generated by recent work.
% or recent work Critically, we demonstrate that when trained on GRAID data,
models learn spatial reasoning concepts that generalize: models fine-tuned on 6
question types improve on over 10 held-out types, with accuracy gains of 47.5\%
on BDD and 37.9\% on NuImages for Llama 3.2B 11B, and when trained on all
questions types, achieve improvements on several existing benchmarks such as
BLINK. The GRAID framework, datasets, and additional information can be found
on our \href{https://ke7.github.io/graid/}{project page}.

</details>


### [66] [CogStereo: Neural Stereo Matching with Implicit Spatial Cognition Embedding](https://arxiv.org/abs/2510.22119)
*Lihuang Fang,Xiao Hu,Yuchen Zou,Hong Zhang*

Main category: cs.CV

TL;DR: CogStereo是一个创新的立体匹配框架，通过结合单目深度特征和双重条件细化机制，解决了遮挡或纹理稀疏等挑战性区域的匹配问题，并在各种数据集和真实世界场景中实现了最先进的零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 尽管深度立体匹配在基准数据集上取得了显著进展，但在零样本泛化能力方面仍不如其他视觉任务中的基础模型。因此，需要一种新的方法来解决遮挡或纹理稀疏等具有挑战性的区域，并且不依赖于特定数据集的先验知识。

Method: CogStereo框架将隐式空间认知嵌入到细化过程中，利用单目深度特征作为先验，实现超越局部对应关系的整体场景理解。它采用双重条件细化机制，结合像素级不确定性和认知引导特征，对不匹配进行一致的全局校正。

Result: CogStereo在Scene Flow、KITTI、Middlebury、ETH3D、EuRoc以及真实世界数据上进行了广泛的实验，证明了其最先进的性能，并在跨域泛化方面表现出色。

Conclusion: CogStereo通过引入认知引导的立体匹配方法，提高了在具有挑战性区域的匹配精度和零样本泛化能力，推动立体视觉向认知驱动的方向发展。

Abstract: Deep stereo matching has advanced significantly on benchmark datasets through
fine-tuning but falls short of the zero-shot generalization seen in foundation
models in other vision tasks. We introduce CogStereo, a novel framework that
addresses challenging regions, such as occlusions or weak textures, without
relying on dataset-specific priors. CogStereo embeds implicit spatial cognition
into the refinement process by using monocular depth features as priors,
capturing holistic scene understanding beyond local correspondences. This
approach ensures structurally coherent disparity estimation, even in areas
where geometry alone is inadequate. CogStereo employs a dual-conditional
refinement mechanism that combines pixel-wise uncertainty with cognition-guided
features for consistent global correction of mismatches. Extensive experiments
on Scene Flow, KITTI, Middlebury, ETH3D, EuRoc, and real-world demonstrate that
CogStereo not only achieves state-of-the-art results but also excels in
cross-domain generalization, shifting stereo vision towards a cognition-driven
approach.

</details>


### [67] [Mint: A Simple Test-Time Adaptation of Vision-Language Models against Common Corruptions](https://arxiv.org/abs/2510.22127)
*Wenxuan Bao,Ruxi Deng,Jingrui He*

Main category: cs.CV

TL;DR: 在输入损坏导致分布转移时，CLIP等预训练视觉-语言模型虽然具有强大的零样本泛化能力，但仍然容易受到影响。本文研究了损坏如何影响CLIP的图像嵌入，并发现了一种称为“嵌入方差坍塌”的现象，即随着损坏程度的增加，类内和类间方差都会缩小。我们发现这种坍塌与性能下降密切相关，其中类间方差与分类精度高度相关。为了解释这种现象，我们分析了损坏如何改变嵌入空间的结构。我们的理论结果表明，视觉编码器倾向于编码与损坏相关的信号，这会稀释区分类别的特征并压缩表示的几何结构。我们还发现，即使是从伪标签估计的，最大化类间方差也能有效地提高嵌入质量。基于此，我们提出了一种名为Mint的简单测试时适应方法，该方法使用均值累加器和梯度累加器来动态地最大化基于伪标签的类间方差。Mint在小批量大小下也能有效运行，并在多个损坏基准和CLIP架构上持续提高性能。


<details>
  <summary>Details</summary>
Motivation: 预训练视觉-语言模型（如CLIP）在面对输入损坏导致的分布偏移时，其泛化能力会下降。需要研究损坏对模型嵌入的影响，并提出改进方法。

Method: 研究损坏对CLIP图像嵌入的影响，提出“嵌入方差坍塌”现象的假设。通过理论分析和实验，揭示了损坏改变嵌入空间结构的原因。提出了一种名为Mint的测试时适应方法，通过最大化伪标签的类间方差来提高嵌入质量。

Result: 发现“嵌入方差坍塌”现象，即损坏导致类内和类间方差缩小，且类间方差与分类精度强相关。Mint方法在多个损坏基准和CLIP架构上均有效，提升了模型性能。

Conclusion: Mint是一种有效的测试时适应方法，通过最大化类间方差来解决输入损坏导致的分布偏移问题，提高了CLIP等模型的鲁棒性和准确性。

Abstract: Pretrained vision-language models such as CLIP achieve strong zero-shot
generalization but remain vulnerable to distribution shifts caused by input
corruptions. In this work, we investigate how corruptions affect CLIP's image
embeddings and uncover a consistent phenomenon we term as embedding variance
collapse, where both intra-class and inter-class variances shrink as corruption
severity increases. We find that this collapse is closely tied to performance
degradation, with inter-class variance strongly correlated with classification
accuracy. To explain this phenomenon, we analyze how corruptions alter the
structure of the embedding space. Our theoretical results suggest that the
visual encoder tends to encode corruption-related signals, which dilute
class-discriminative features and compress the representation geometry. We
further show that maximizing inter-class variance, even when estimated from
pseudo-labels, can provably enhance embedding quality. Based on this insight,
we propose Mint, a simple test-time adaptation method that maximizes
pseudo-label-based inter-class variance on the fly using a mean accumulator and
a gradient accumulator. Mint operates effectively with small batch sizes and
consistently improves performance across multiple corruption benchmarks and
CLIP architectures. Our code is available at https://github.com/baowenxuan/Mint .

</details>


### [68] [egoEMOTION: Egocentric Vision and Physiological Signals for Emotion and Personality Recognition in Real-World Tasks](https://arxiv.org/abs/2510.22129)
*Matthias Jammot,Bjöern Braun,Paul Streli,Rafael Wampfler,Christian Holz*

Main category: cs.CV

TL;DR: 该研究提出了egoEMOTION数据集，首次将自我中心视觉和生理信号与详细的情感和个性自我报告相结合，旨在弥补当前自我中心视觉基准中对情绪状态的忽视，并为情绪驱动的行为建模开辟新方向。


<details>
  <summary>Details</summary>
Motivation: 当前自我中心视觉基准主要关注物理活动和手部-物体交互，忽略了个体的情绪状态对其决策和行为的影响，限制了视觉系统捕捉行为关键内部驱动因素的能力。

Method: 构建了一个包含50多小时、来自43名参与者的egoEMOTION数据集，使用了Meta的Project Aria眼镜。数据包括同步的眼动追踪视频、头戴式光电容积描记法、惯性运动数据和生理基线。参与者在进行情绪诱导任务和自然活动时，使用Cucumplex模型和Mikels' Wheel报告情感状态，并使用大五人格模型报告个性。定义了三个基准任务：连续情感分类（效价、唤醒度、优势度）、离散情绪分类和特质水平个性推断。

Result: 通过实验表明，使用经典的基于学习的方法，从自我中心视觉系统捕获的信号进行情感预测，优于仅处理生理信号的方法。

Conclusion: egoEMOTION数据集将情感和个性确立为自我中心感知中的核心维度，并为情绪驱动的行为、意图和交互模型开辟了新的研究方向。

Abstract: Understanding affect is central to anticipating human behavior, yet current
egocentric vision benchmarks largely ignore the person's emotional states that
shape their decisions and actions. Existing tasks in egocentric perception
focus on physical activities, hand-object interactions, and attention modeling
- assuming neutral affect and uniform personality. This limits the ability of
vision systems to capture key internal drivers of behavior. In this paper, we
present egoEMOTION, the first dataset that couples egocentric visual and
physiological signals with dense self-reports of emotion and personality across
controlled and real-world scenarios. Our dataset includes over 50 hours of
recordings from 43 participants, captured using Meta's Project Aria glasses.
Each session provides synchronized eye-tracking video, headmounted
photoplethysmography, inertial motion data, and physiological baselines for
reference. Participants completed emotion-elicitation tasks and naturalistic
activities while self-reporting their affective state using the Circumplex
Model and Mikels' Wheel as well as their personality via the Big Five model. We
define three benchmark tasks: (1) continuous affect classification (valence,
arousal, dominance); (2) discrete emotion classification; and (3) trait-level
personality inference. We show that a classical learning-based method, as a
simple baseline in real-world affect prediction, produces better estimates from
signals captured on egocentric vision systems than processing physiological
signals. Our dataset establishes emotion and personality as core dimensions in
egocentric perception and opens new directions in affect-driven modeling of
behavior, intent, and interaction.

</details>


### [69] [STG-Avatar: Animatable Human Avatars via Spacetime Gaussian](https://arxiv.org/abs/2510.22140)
*Guangan Jiang,Tianzi Zhang,Dong Li,Zhenjun Zhao,Haoang Li,Mingrui Li,Hongyu Wang*

Main category: cs.CV

TL;DR: STG-Avatar是一个基于3DGS的框架，用于高保真可驱动人体化身重建，通过刚性-非刚性耦合变形框架，结合时空高斯（STG）和线性混合蒙皮（LBS），并利用光流优化，在重建质量和效率上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于3DGS的人体化身在精确表示非刚性物体（如服装变形）和动态区域（如快速移动的四肢）方面存在不足，阻碍了人机交互和虚拟体验的发展。

Method: 提出STG-Avatar框架，采用刚性-非刚性耦合变形方法，结合时空高斯（STG）和线性混合蒙皮（LBS）。LBS驱动全局姿态变换以实现实时骨骼控制，STG通过时空自适应优化3D高斯进行补充。同时，利用光流识别高动态区域并指导3D高斯的自适应加密。

Result: 实验结果表明，STG-Avatar在重建质量和运行效率方面持续优于最先进的基线方法，实现了更高的量化指标，并保留了实时渲染能力。

Conclusion: STG-Avatar通过刚性-非刚性耦合变形和时空高斯自适应优化，成功解决了现有3DGS化身在细节表示和动态区域处理上的挑战，实现了高保真、可驱动的人体化身重建，并在性能和效率上取得了显著优势。

Abstract: Realistic animatable human avatars from monocular videos are crucial for
advancing human-robot interaction and enhancing immersive virtual experiences.
While recent research on 3DGS-based human avatars has made progress, it still
struggles with accurately representing detailed features of non-rigid objects
(e.g., clothing deformations) and dynamic regions (e.g., rapidly moving limbs).
To address these challenges, we present STG-Avatar, a 3DGS-based framework for
high-fidelity animatable human avatar reconstruction. Specifically, our
framework introduces a rigid-nonrigid coupled deformation framework that
synergistically integrates Spacetime Gaussians (STG) with linear blend skinning
(LBS). In this hybrid design, LBS enables real-time skeletal control by driving
global pose transformations, while STG complements it through spacetime
adaptive optimization of 3D Gaussians. Furthermore, we employ optical flow to
identify high-dynamic regions and guide the adaptive densification of 3D
Gaussians in these regions. Experimental results demonstrate that our method
consistently outperforms state-of-the-art baselines in both reconstruction
quality and operational efficiency, achieving superior quantitative metrics
while retaining real-time rendering capabilities. Our code is available at
https://github.com/jiangguangan/STG-Avatar

</details>


### [70] [LOC: A General Language-Guided Framework for Open-Set 3D Occupancy Prediction](https://arxiv.org/abs/2510.22141)
*Yuhang Gao,Xiang Xiang,Sheng Zhong,Guoyou Wang*

Main category: cs.CV

TL;DR: LOC是一个通用的语言引导框架，可以适应各种占用网络，并支持监督和自监督学习范式，以解决3D场景理解中的数据稀疏性问题。


<details>
  <summary>Details</summary>
Motivation: 3D数据集的有限性阻碍了视觉语言模型（VLM）在3D场景理解中的有效应用。

Method: 该框架通过融合多帧激光雷达点、使用泊松重建填充空洞、并通过KNN分配语义来获得全面的体素表示。为了缓解特征过度均质化问题，引入了密集对比学习（DCL），利用密集的体素语义信息和预定义的文本提示，在没有密集像素级监督的情况下增强开放集识别能力。该模型预测CLIP特征空间中嵌入的密集体素特征，并基于文本和语义相似性进行分类。

Result: 在nuScenes数据集上的实验表明，该方法在已知类别的预测精度高，并且无需额外的训练数据即可区分未知类别。

Conclusion: LOC框架能够有效地整合文本和图像像素信息，提高了3D场景理解的准确性和鲁棒性，尤其在开放集识别方面表现出色。

Abstract: Vision-Language Models (VLMs) have shown significant progress in open-set
challenges. However, the limited availability of 3D datasets hinders their
effective application in 3D scene understanding. We propose LOC, a general
language-guided framework adaptable to various occupancy networks, supporting
both supervised and self-supervised learning paradigms. For self-supervised
tasks, we employ a strategy that fuses multi-frame LiDAR points for
dynamic/static scenes, using Poisson reconstruction to fill voids, and
assigning semantics to voxels via K-Nearest Neighbor (KNN) to obtain
comprehensive voxel representations. To mitigate feature over-homogenization
caused by direct high-dimensional feature distillation, we introduce Densely
Contrastive Learning (DCL). DCL leverages dense voxel semantic information and
predefined textual prompts. This efficiently enhances open-set recognition
without dense pixel-level supervision, and our framework can also leverage
existing ground truth to further improve performance. Our model predicts dense
voxel features embedded in the CLIP feature space, integrating textual and
image pixel information, and classifies based on text and semantic similarity.
Experiments on the nuScenes dataset demonstrate the method's superior
performance, achieving high-precision predictions for known classes and
distinguishing unknown classes without additional training data.

</details>


### [71] [Attention Residual Fusion Network with Contrast for Source-free Domain Adaptation](https://arxiv.org/abs/2510.22142)
*Renrong Shao,Wei Zhang,Jun Wang*

Main category: cs.CV

TL;DR: 提出了一种名为ARFNet的新框架，利用对比学习来解决无源域自适应（SFDA）问题，以减轻负迁移和域漂移。


<details>
  <summary>Details</summary>
Motivation: SFDA任务复杂，现有方法忽视了负迁移对模型性能的负面影响。

Method: ARFNet框架结合了注意力残差融合、全局-局部注意力对比和动态质心评估。具体来说，利用注意力机制捕捉目标区域，通过跨层注意力残差融合实现自蒸馏，对比全局和局部表示以提高感知能力，并利用动态质心评估来选择可信质心和伪标签以减轻域漂移。

Result: 在五个不同规模的基准测试中进行了广泛的实验，ARFNet在SFDA基准测试中取得了优于其他技术的卓越性能。

Conclusion: ARFNet通过有效解决负迁移和域漂移问题，在SFDA任务上取得了显著的性能提升。

Abstract: Source-free domain adaptation (SFDA) involves training a model on source
domain and then applying it to a related target domain without access to the
source data and labels during adaptation. The complexity of scene information
and lack of the source domain make SFDA a difficult task. Recent studies have
shown promising results, but many approaches to domain adaptation concentrate
on domain shift and neglect the effects of negative transfer, which may impede
enhancements of model performance during adaptation. n this paper, addressing
this issue, we propose a novel framework of Attention Residual Fusion Network
(ARFNet) based on contrast learning for SFDA to alleviate negative transfer and
domain shift during the progress of adaptation, in which attention residual
fusion, global-local attention contrast, and dynamic centroid evaluation are
exploited. Concretely, the attention mechanism is first exploited to capture
the discriminative region of the target object. Then, in each block, attention
features are decomposed into spatial-wise and channel-wise attentions to
achieve the cross-layer attention residual fusion progressively and
self-distillation. During adaptation progress, we contrast global and local
representations to improve the perceptual capabilities of different categories,
which enables the model to discriminate variations between inner-class and
intra-class. Finally, a dynamic centroid evaluation strategy is exploited to
evaluate the trustworthy centroids and labels for self-supervised
self-distillation, which aims to accurately approximate the center of the
source domain and pseudo-labels to mitigate domain shift. To validate the
efficacy, we execute comprehensive experiments on five benchmarks of varying
scales. Experimental outcomes indicate that our method surpasses other
techniques, attaining superior performance across SFDA benchmarks.

</details>


### [72] [I2-NeRF: Learning Neural Radiance Fields Under Physically-Grounded Media Interactions](https://arxiv.org/abs/2510.22161)
*Shuhong Liu,Lin Gu,Ziteng Cui,Xuangeng Chu,Tatsuya Harada*

Main category: cs.CV

TL;DR: I2-NeRF是一种新的神经辐射场框架，通过反分层上采样策略和新的辐射公式来增强3D物理世界的感知，特别是在媒体降级的情况下，实现了近乎均匀的采样，从而保持了等距性，并能估计介质属性。


<details>
  <summary>Details</summary>
Motivation: 为生成式AI提供3D物理世界感知能力，并解决现有NeRF模型在媒体降级下的等距和各向同性感知问题。

Method: 提出了一种名为I2-NeRF的新型神经辐射场框架。该框架采用反分层上采样策略实现近乎均匀的3D空间采样，以保持等距性。同时，提出了一种通用的辐射公式来模拟媒体降级（包括发射、吸收和散射），该公式基于比尔-朗伯衰减定律，并将直接辐射和媒体散射辐射结合起来。

Result: I2-NeRF在真实数据集上的实验表明，与现有方法相比，该方法在重建保真度和物理合理性方面均有显著提升。该方法还能够估计介质属性，如水深。

Conclusion: I2-NeRF通过其独特的采样策略和媒体辐射公式，能够有效地处理媒体降级问题，实现更好的3D感知和重建，并能估计介质属性，为生成式AI在复杂环境中的应用提供了新的可能性。

Abstract: Participating in efforts to endow generative AI with the 3D physical world
perception, we propose I2-NeRF, a novel neural radiance field framework that
enhances isometric and isotropic metric perception under media degradation.
While existing NeRF models predominantly rely on object-centric sampling,
I2-NeRF introduces a reverse-stratified upsampling strategy to achieve
near-uniform sampling across 3D space, thereby preserving isometry. We further
present a general radiative formulation for media degradation that unifies
emission, absorption, and scattering into a particle model governed by the
Beer-Lambert attenuation law. By composing the direct and media-induced
in-scatter radiance, this formulation extends naturally to complex media
environments such as underwater, haze, and even low-light scenes. By treating
light propagation uniformly in both vertical and horizontal directions, I2-NeRF
enables isotropic metric perception and can even estimate medium properties
such as water depth. Experiments on real-world datasets demonstrate that our
method significantly improves both reconstruction fidelity and physical
plausibility compared to existing approaches.

</details>


### [73] [HARMONY: Hidden Activation Representations and Model Output-Aware Uncertainty Estimation for Vision-Language Models](https://arxiv.org/abs/2510.22171)
*Erum Mushtaq,Zalan Fabian,Yavuz Faruk Bakman,Anil Ramakrishna,Mahdi Soltanolkotabi,Salman Avestimehr*

Main category: cs.CV

TL;DR: HARMONY是一个新的不确定性估计框架，它结合了VLM的激活和输出分布来评估其响应的可靠性，并在三个VQA基准测试中取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 现有的基于概率或隐藏表征的不确定性估计方法在捕捉多模态关系和处理语言先验偏差方面存在不足，因此需要更可靠的方法来评估高风险应用中视觉语言模型（VLM）的生成。HARMONY框架旨在解决这些问题。

Method: HARMONY框架联合利用了模型激活中的融合多模态信息和VLM的输出分布，以确定响应的可靠性。它假设模型的内部视觉理解（通过隐藏表征捕捉）和产生的标记概率都包含有价值的可靠性信号，可以联合利用以提高不确定性估计的性能。

Result: 在A-OKVQA、VizWiz和PathVQA三个开放式VQA基准测试和LLaVa-7b、LLaVA-13b和InstructBLIP三个最先进的VLM上进行的大量实验表明，HARMONY框架在不确定性估计方面持续与现有方法持平或表现更好，在AUROC方面提高了4%，在PRR方面提高了6%。

Conclusion: HARMONY框架通过联合利用模型激活和输出分布，在不确定性估计方面为VLM设定了新的最先进水平，证明了结合多模态信息来源可以显著提高模型可靠性评估的准确性。

Abstract: The growing deployment of Vision-Language Models (VLMs) in high-stakes
applications such as autonomous driving and assistive technologies for visually
impaired individuals necessitates reliable mechanisms to assess the
trustworthiness of their generation. Uncertainty Estimation (UE) plays a
central role in quantifying the reliability of model outputs and reducing
unsafe generations via selective prediction. In this regard, most existing
probability-based UE approaches rely on output probability distributions,
aggregating token probabilities into a single uncertainty score using
predefined functions such as length-normalization. Another line of research
leverages model hidden representations and trains MLP-based models to predict
uncertainty. However, these methods often fail to capture the complex
multimodal relationships between semantic and textual tokens and struggle to
identify biased probabilities often influenced by language priors. Motivated by
these observations, we propose a novel UE framework, HARMONY, that jointly
leverages fused multimodal information in model activations and the output
distribution of the VLM to determine the reliability of responses. The key
hypothesis of our work is that both the model's internal belief in its visual
understanding, captured by its hidden representations, and the produced token
probabilities carry valuable reliability signals that can be jointly leveraged
to improve UE performance, surpassing approaches that rely on only one of these
components. Experimental results on three open-ended VQA benchmarks, A-OKVQA,
VizWiz, and PathVQA, and three state-of-the-art VLMs, LLaVa-7b, LLaVA-13b and
InstructBLIP demonstrate that our method consistently performs on par with or
better than existing approaches, achieving up to 4\% improvement in AUROC, and
6\% in PRR, establishing new state of the art in uncertainty estimation for
VLMs.

</details>


### [74] [Scaling Non-Parametric Sampling with Representation](https://arxiv.org/abs/2510.22196)
*Vincent Lu,Aaron Truong,Zeyu Yun,Yubei Chen*

Main category: cs.CV

TL;DR: 本文提出了一个简单、非参数的生成模型，通过模拟自然图像的空间非平稳性、低级规律性和高级语义性来生成图像，无需训练即可在MNIST和CIFAR-10数据集上取得良好效果，并揭示了其泛化和生成机制。


<details>
  <summary>Details</summary>
Motivation: 现有的图像生成模型虽然在视觉效果上表现出色，但其内部机制却难以理解。本文旨在摒弃复杂的工程技术，提出一个简单的非参数生成模型，以期获得可解释性。

Method: 模型基于自然图像的三个特性（空间非平稳性、低级规律性、高级语义性）进行设计，并从局部上下文窗口定义每个像素的分布。模型无需训练，结构简单。

Result: 在MNIST数据集上生成了高保真度的样本，在CIFAR-10数据集上生成了具有视觉吸引力的图像。通过追溯生成像素的来源图像，分析了模型的“部分-整体泛化”能力。

Conclusion: 该模型结合了简洁性与强大的经验性能，表明自然图像结构可能存在一个最小理论。模型的白盒特性也使得我们能够理解其泛化和生成多样化图像的机制，并提出了关于大型神经网络生成模型如何学习泛化的大胆假设。

Abstract: Scaling and architectural advances have produced strikingly photorealistic
image generative models, yet their mechanisms still remain opaque. Rather than
advancing scaling, our goal is to strip away complicated engineering tricks and
propose a simple, non-parametric generative model. Our design is grounded in
three principles of natural images-(i) spatial non-stationarity, (ii) low-level
regularities, and (iii) high-level semantics-and defines each pixel's
distribution from its local context window. Despite its minimal architecture
and no training, the model produces high-fidelity samples on MNIST and visually
compelling CIFAR-10 images. This combination of simplicity and strong empirical
performance points toward a minimal theory of natural-image structure. The
model's white-box nature also allows us to have a mechanistic understanding of
how the model generalizes and generates diverse images. We study it by tracing
each generated pixel back to its source images. These analyses reveal a simple,
compositional procedure for "part-whole generalization", suggesting a
hypothesis for how large neural network generative models learn to generalize.

</details>


### [75] [LongCat-Video Technical Report](https://arxiv.org/abs/2510.22200)
*Meituan LongCat Team,Xunliang Cai,Qilong Huang,Zhuoliang Kang,Hongyu Li,Shijun Liang,Liya Ma,Siyu Ren,Xiaoming Wei,Rixu Xie,Tong Zhang*

Main category: cs.CV

TL;DR: LongCat-Video是一个13.6B参数的基础视频生成模型，擅长高效、高质量的长视频生成，是迈向世界模型的关键一步。它采用统一的DiT架构支持多种任务，通过视频续写预训练实现分钟级长视频生成，并利用粗粒度到细粒度策略和块稀疏注意力实现高效推理。结合多奖励RLHF训练，其性能可与顶尖模型媲美。


<details>
  <summary>Details</summary>
Motivation: 视频生成是通往世界模型的关键途径，高效的长视频推理是其中的核心能力。本研究旨在构建一个强大的基础视频生成模型，以实现高质量、长时序的视频生成，并为迈向世界模型奠定基础。

Method: 本研究提出了LongCat-Video，一个拥有13.6B参数的基础视频生成模型。该模型基于Diffusion Transformer (DiT)框架，采用统一架构支持文本到视频、图像到视频和视频续写等多种任务。通过在视频续写任务上进行预训练，模型能够生成高质量且时序连贯的分钟级长视频。为实现高效推理，模型采用了沿时间和空间轴的粗粒度到细粒度生成策略，并结合块稀疏注意力机制，尤其在处理高分辨率视频时能显著提升效率。此外，还采用了多奖励强化学习从人类反馈（RLHF）进行训练，以优化模型性能。

Result: LongCat-Video 在多项视频生成任务上表现出色，尤其在高效、高质量的长视频生成方面具有优势。该模型能够生成720p、30fps的视频，耗时仅需几分钟。通过多奖励RLHF训练，其性能与目前最先进的闭源和开源模型相当。

Conclusion: LongCat-Video 是一个在视频生成领域具有重要意义的模型，它在长视频生成、推理效率和多任务处理能力方面取得了显著进展。该模型的公开代码和权重将有助于加速该领域的研究和发展，是迈向更强大世界模型的重要一步。

Abstract: Video generation is a critical pathway toward world models, with efficient
long video inference as a key capability. Toward this end, we introduce
LongCat-Video, a foundational video generation model with 13.6B parameters,
delivering strong performance across multiple video generation tasks. It
particularly excels in efficient and high-quality long video generation,
representing our first step toward world models. Key features include: Unified
architecture for multiple tasks: Built on the Diffusion Transformer (DiT)
framework, LongCat-Video supports Text-to-Video, Image-to-Video, and
Video-Continuation tasks with a single model; Long video generation:
Pretraining on Video-Continuation tasks enables LongCat-Video to maintain high
quality and temporal coherence in the generation of minutes-long videos;
Efficient inference: LongCat-Video generates 720p, 30fps videos within minutes
by employing a coarse-to-fine generation strategy along both the temporal and
spatial axes. Block Sparse Attention further enhances efficiency, particularly
at high resolutions; Strong performance with multi-reward RLHF: Multi-reward
RLHF training enables LongCat-Video to achieve performance on par with the
latest closed-source and leading open-source models. Code and model weights are
publicly available to accelerate progress in the field.

</details>


### [76] [TrajGATFormer: A Graph-Based Transformer Approach for Worker and Obstacle Trajectory Prediction in Off-site Construction Environments](https://arxiv.org/abs/2510.22205)
*Mohammed Alduais,Xinming Li,Qipei Mei*

Main category: cs.CV

TL;DR: 该论文提出了一种结合YOLOv10n和DeepSORT的框架，并引入了两种新的轨迹预测模型（TrajGATFormer和TrajGATFormer-Obstacle），用于预测建筑工地上工人和障碍物的未来轨迹，以减少碰撞风险。


<details>
  <summary>Details</summary>
Motivation: 建筑行业对更快、更安全、更高效的施工流程的需求日益增长，但现场施工带来了新的安全风险。开发碰撞避免系统以减轻这些风险，需要准确预测工人的未来轨迹并考虑社会和环境因素。传统方法难以适应建筑环境的动态性和不可预测性，而现有数据驱动方法在捕捉长期行为和空间/社会背景方面存在挑战。

Method: 该框架使用YOLOv10n进行物体检测，DeepSORT进行物体跟踪。 TrajGATFormer和TrajGATFormer-Obstacle模型结合了Transformer和图注意力网络（GAT）来捕捉时空交互，用于预测轨迹。TrajGATFormer预测工人轨迹，TrajGATFormer-Obstacle则同时预测工人和障碍物的轨迹。

Result: TrajGATFormer在4.8秒的预测范围内实现了1.25米的平均位移误差（ADE）和2.3米的最终位移误差（FDE）。TrajGATFormer-Obstacle取得了更高的精度，ADE为1.15米，FDE为2.2米。与传统方法相比，这两种模型将ADE和FDE分别降低了高达35%和38%。

Conclusion: 所提出的框架及其轨迹预测模型在提高建筑安全方面显示出巨大潜力，能够更准确地预测工人和障碍物的运动，从而有效减少碰撞风险。

Abstract: As the demand grows within the construction industry for processes that are
not only faster but also safer and more efficient, offsite construction has
emerged as a solution, though it brings new safety risks due to the close
interaction between workers, machinery, and moving obstacles. Predicting the
future trajectories of workers and taking into account social and environmental
factors is a crucial step for developing collision-avoidance systems to
mitigate such risks. Traditional methods often struggle to adapt to the dynamic
and unpredictable nature of construction environments. Many rely on simplified
assumptions or require hand-crafted features, limiting their ability to respond
to complex, real-time interactions between workers and moving obstacles. While
recent data-driven methods have improved the modeling of temporal patterns,
they still face challenges in capturing long-term behavior and accounting for
the spatial and social context crucial to collision risk assessment. To address
these limitations, this paper proposes a framework integrating YOLOv10n and
DeepSORT for precise detection and tracking, along with two novel trajectory
prediction models: TrajGATFormer and TrajGATFormer-Obstacle. YOLOv10n serves as
the backbone for object detection, accurately identifying workers and obstacles
in diverse scenes, while DeepSORT efficiently tracks them over time with unique
IDs for continuity. Both models employ a transformer encoder-decoder with Graph
Attention Networks (GAT) to capture temporal and spatial interactions.
TrajGATFormer predicts worker trajectories with an ADE of 1.25 m and FDE of 2.3
m over a 4.8 s horizon, while TrajGATFormer-Obstacle extends prediction to both
workers and obstacles, achieving higher accuracy (ADE 1.15 m, FDE 2.2 m).
Comparative analysis shows both models outperform traditional methods, reducing
ADE and FDE by up to 35% and 38%, respectively.

</details>


### [77] [DynamicTree: Interactive Real Tree Animation via Sparse Voxel Spectrum](https://arxiv.org/abs/2510.22213)
*Yaokun Li,Lihe Ding,Xiao Chen,Guang Tan,Tianfan Xue*

Main category: cs.CV

TL;DR: 提出了一种名为DynamicTree的框架，用于生成逼真、实时的3D高斯树木动画，解决了现有方法在生成复杂真实树木的4D运动方面存在的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成逼真、长期的复杂真实树木4D运动方面存在挑战。

Method: 提出了一种名为DynamicTree的框架，使用紧凑的稀疏体素频谱来表示树木运动，并利用该频谱生成网格运动，然后将高斯点绑定到变形的网格上。该方法采用快速前馈方式生成动画，并支持实时交互响应。

Result: 实验证明，该方法能够生成逼真且响应迅速的树木动画，在视觉质量和计算效率方面均显著优于现有方法。同时，还引入了一个包含8,786个带语义标签的动画树网格和100帧运动序列的大规模合成4D树数据集4DTree。

Conclusion: DynamicTree框架能够生成高质量、实时的3D高斯树木动画，并且在计算效率和交互性方面具有显著优势，为虚拟现实、游戏和世界模拟等领域提供了新的解决方案。

Abstract: Generating dynamic and interactive 3D objects, such as trees, has wide
applications in virtual reality, games, and world simulation. Nevertheless,
existing methods still face various challenges in generating realistic 4D
motion for complex real trees. In this paper, we propose DynamicTree, the first
framework that can generate long-term, interactive animation of 3D Gaussian
Splatting trees. Unlike prior optimization-based methods, our approach
generates dynamics in a fast feed-forward manner. The key success of our
approach is the use of a compact sparse voxel spectrum to represent the tree
movement. Given a 3D tree from Gaussian Splatting reconstruction, our pipeline
first generates mesh motion using the sparse voxel spectrum and then binds
Gaussians to deform the mesh. Additionally, the proposed sparse voxel spectrum
can also serve as a basis for fast modal analysis under external forces,
allowing real-time interactive responses. To train our model, we also introduce
4DTree, the first large-scale synthetic 4D tree dataset containing 8,786
animated tree meshes with semantic labels and 100-frame motion sequences.
Extensive experiments demonstrate that our method achieves realistic and
responsive tree animations, significantly outperforming existing approaches in
both visual quality and computational efficiency.

</details>


### [78] [GALA: A GlobAl-LocAl Approach for Multi-Source Active Domain Adaptation](https://arxiv.org/abs/2510.22214)
*Juepeng Zheng,Peifeng Zhang,Yibin Wen,Qingmei Li,Yang Zhang,Haohuan Fu*

Main category: cs.CV

TL;DR: 该研究提出了一种名为GALA的多源主动域自适应（MS-ADA）策略，通过全局聚类和局部选择相结合的方式，有效利用多个源域知识并选择性地标注目标域数据，以提高目标域任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究在多源域自适应（MSDA）方面仍存在性能差距，且未能解决主动选择目标域标注以进一步提升性能的问题。本文旨在探索更实用、更具挑战性的多源主动域自适应（MS-ADA）场景。

Method: 提出了一种名为GALA的策略，该策略结合了全局k-means聚类和聚类感知的局部选择标准，用于选择目标域样本进行标注，以应对类别间多样性和多源域变化的挑战。

Result: GALA策略在三个标准的域自适应基准测试中，始终优于先前的主动学习和主动域自适应方法，并且在仅使用1%的目标域标注的情况下，实现了与完全监督学习相当的性能。

Conclusion: GALA策略是一种简单有效且即插即用的方法，能够显著提升多源主动域自适应任务的性能，使其接近完全监督学习的水平，同时大大减少了对目标域标注的需求。

Abstract: Domain Adaptation (DA) provides an effective way to tackle target-domain
tasks by leveraging knowledge learned from source domains. Recent studies have
extended this paradigm to Multi-Source Domain Adaptation (MSDA), which exploits
multiple source domains carrying richer and more diverse transferable
information. However, a substantial performance gap still remains between
adaptation-based methods and fully supervised learning. In this paper, we
explore a more practical and challenging setting, named Multi-Source Active
Domain Adaptation (MS-ADA), to further enhance target-domain performance by
selectively acquiring annotations from the target domain. The key difficulty of
MS-ADA lies in designing selection criteria that can jointly handle inter-class
diversity and multi-source domain variation. To address these challenges, we
propose a simple yet effective GALA strategy (GALA), which combines a global
k-means clustering step for target-domain samples with a cluster-wise local
selection criterion, effectively tackling the above two issues in a
complementary manner. Our proposed GALA is plug-and-play and can be seamlessly
integrated into existing DA frameworks without introducing any additional
trainable parameters. Extensive experiments on three standard DA benchmarks
demonstrate that GALA consistently outperforms prior active learning and active
DA methods, achieving performance comparable to the fully-supervised upperbound
while using only 1% of the target annotations.

</details>


### [79] [Enpowering Your Pansharpening Models with Generalizability: Unified Distribution is All You Need](https://arxiv.org/abs/2510.22217)
*Yongchuan Cui,Peng Liu,Hui Zhang*

Main category: cs.CV

TL;DR: 现有的深度学习遥感论文锐化模型在训练数据集上表现优异，但在应用于新的卫星数据时，由于传感器特性和成像条件的变化，泛化能力不足。本文提出了UniPAN方法，通过构建一个分布变换函数，将不同来源的像素归一化到相同的分布，从而增强模型的泛化能力，实现“一次训练，永久部署”。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习遥感论文锐化模型在泛化到新的卫星数据时性能下降，原因是训练和测试数据的分布差异。

Method: 提出UniPAN方法，构建一个分布变换函数，将不同来源的像素归一化到相同的分布，并在变换后的域上训练和测试模型。

Result: 通过广泛的实验验证了UniPAN的有效性，证明了其能够显著提升深度论文锐化模型在不同卫星传感器上的性能。

Conclusion: UniPAN通过统一的分布策略，解决了深度学习遥感论文锐化模型泛化能力不足的问题，提高了模型在不同数据源上的性能。

Abstract: Existing deep learning-based models for remote sensing pansharpening exhibit
exceptional performance on training datasets. However, due to sensor-specific
characteristics and varying imaging conditions, these models suffer from
substantial performance degradation when applied to unseen satellite data,
lacking generalizability and thus limiting their applicability. We argue that
the performance drops stem primarily from distributional discrepancies from
different sources and the key to addressing this challenge lies in bridging the
gap between training and testing distributions. To validate the idea and
further achieve a "train once, deploy forever" capability, this paper
introduces a novel and intuitive approach to enpower any pansharpening models
with generalizability by employing a unified distribution strategy (UniPAN).
Specifically, we construct a distribution transformation function that
normalizes the pixels sampled from different sources to conform to an identical
distribution. The deep models are trained on the transformed domain, and during
testing on new datasets, the new data are also transformed to match the
training distribution. UniPAN aims to train and test the model on a unified and
consistent distribution, thereby enhancing its generalizability. Extensive
experiments validate the efficacy of UniPAN, demonstrating its potential to
significantly enhance the performance of deep pansharpening models across
diverse satellite sensors. Codes: https://github.com/yc-cui/UniPAN.

</details>


### [80] [Audio Frequency-Time Dual Domain Evaluation on Depression Diagnosis](https://arxiv.org/abs/2510.22225)
*Yu Luo,Nan Huang,Sophie Yu,Hendry Xu,Jerry Wang,Colin Wang,Zhichao Liu,Chen Zeng*

Main category: cs.CV

TL;DR: 利用语音信号的频时域多模态特征和深度学习模型，开发抑郁症智能评估与诊断算法，以应对诊断困难、标准模糊和咨询率低等挑战。


<details>
  <summary>Details</summary>
Motivation: 抑郁症作为典型的精神疾病，已成为影响公众健康的普遍性问题。然而，其预防和治疗仍面临诊断程序复杂、标准模糊、咨询率低等多重挑战，严重阻碍了及时的评估和干预。

Method: 本研究采用语音作为生理信号，并利用其频时域多模态特征以及深度学习模型，开发一种用于抑郁症的智能评估与诊断算法。

Result: 实验结果表明，所提出的方法在抑郁症诊断的分类任务中取得了优异的性能。

Conclusion: 该研究为抑郁症的评估、筛查和诊断提供了新的见解和方法。

Abstract: Depression, as a typical mental disorder, has become a prevalent issue
significantly impacting public health. However, the prevention and treatment of
depression still face multiple challenges, including complex diagnostic
procedures, ambiguous criteria, and low consultation rates, which severely
hinder timely assessment and intervention. To address these issues, this study
adopts voice as a physiological signal and leverages its frequency-time dual
domain multimodal characteristics along with deep learning models to develop an
intelligent assessment and diagnostic algorithm for depression. Experimental
results demonstrate that the proposed method achieves excellent performance in
the classification task for depression diagnosis, offering new insights and
approaches for the assessment, screening, and diagnosis of depression.

</details>


### [81] [Diffusion-Driven Two-Stage Active Learning for Low-Budget Semantic Segmentation](https://arxiv.org/abs/2510.22229)
*Jeongin Kim,Wonho Bae,YouLee Han,Giyeong Oh,Youngjae Yu,Danica J. Sutherland,Junhyug Noh*

Main category: cs.CV

TL;DR: 本研究提出了一种低预算下用于语义分割的主动学习方法，通过利用预训练的扩散模型提取多尺度特征，并结合代表性选择和不确定性评估，以极少的标注像素实现高分割精度。


<details>
  <summary>Details</summary>
Motivation: 语义分割需要密集的像素级标注，在标注预算极其有限的情况下成本过高。

Method: 提出了一种新颖的两阶段选择流程：第一阶段，利用最大聚群（MaxHerding）选择每张图像的代表性像素子集，然后进行全局多样性优化；第二阶段，计算增强熵的差异分数（eDALD），结合了认知不确定性和预测置信度，以选择信息量最大的像素进行标注。

Result: 在CamVid、ADE-Bed、Cityscapes和Pascal-Context四个基准数据集上进行了广泛的实验，在极端的像素预算条件下，本研究的方法显著优于现有基线方法。

Conclusion: 本研究提出的方法通过分离多样性和不确定性度量，能够以极少的标注像素实现高语义分割精度。

Abstract: Semantic segmentation demands dense pixel-level annotations, which can be
prohibitively expensive - especially under extremely constrained labeling
budgets. In this paper, we address the problem of low-budget active learning
for semantic segmentation by proposing a novel two-stage selection pipeline.
Our approach leverages a pre-trained diffusion model to extract rich
multi-scale features that capture both global structure and fine details. In
the first stage, we perform a hierarchical, representation-based candidate
selection by first choosing a small subset of representative pixels per image
using MaxHerding, and then refining these into a diverse global pool. In the
second stage, we compute an entropy-augmented disagreement score (eDALD) over
noisy multi-scale diffusion features to capture both epistemic uncertainty and
prediction confidence, selecting the most informative pixels for annotation.
This decoupling of diversity and uncertainty lets us achieve high segmentation
accuracy with only a tiny fraction of labeled pixels. Extensive experiments on
four benchmarks (CamVid, ADE-Bed, Cityscapes, and Pascal-Context) demonstrate
that our method significantly outperforms existing baselines under extreme
pixel-budget regimes. Our code is available at
https://github.com/jn-kim/two-stage-edald.

</details>


### [82] [DiffusionLane: Diffusion Model for Lane Detection](https://arxiv.org/abs/2510.22236)
*Kunyang Zhou,Yeqin Shao*

Main category: cs.CV

TL;DR: DiffusionLane是一个新颖的基于扩散模型的车道线检测方法，将车道线检测视为参数空间中的去噪扩散过程，并提出了一种混合解码策略来提高特征表示能力，在多个基准测试中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是提出一种新颖的、性能优越的车道线检测模型，以解决现有方法在特征表示和检测性能方面的不足。

Method: 该方法将车道线检测视为参数空间中的去噪扩散过程。首先，向真实车道线的参数（起点和角度）添加高斯噪声以获得带噪声的车道线锚点，然后模型学习逐步优化带噪声的车道线锚点以获得目标车道线。其次，提出了一种混合解码策略，结合全局和局部解码器来处理由于带噪声车道线锚点而导致的编码器特征表示不足的问题。在训练阶段，采用辅助头来采用可学习的车道线锚点，以增强对编码器的监督。

Result: 在Carlane、Tusimple、CULane和LLAMAS四个基准数据集上的实验结果表明，DiffusionLane具有强大的泛化能力和有希望的检测性能。例如，使用ResNet18的DiffusionLane在Carlane数据集上的准确率比现有方法至少提高了1%。此外，使用MobileNetV4的DiffusionLane在CULane上达到了81.32%的F1分数，在Tusimple上达到了96.89%的准确率（使用ResNet34），在LLAMAS上达到了97.59%的F1分数（使用ResNet101）。

Conclusion: DiffusionLane通过将车道线检测视为参数空间中的扩散去噪过程，并采用混合解码策略和辅助监督，在多个数据集上证明了其优越的检测性能和泛化能力，超越了现有的最先进方法。

Abstract: In this paper, we present a novel diffusion-based model for lane detection,
called DiffusionLane, which treats the lane detection task as a denoising
diffusion process in the parameter space of the lane. Firstly, we add the
Gaussian noise to the parameters (the starting point and the angle) of ground
truth lanes to obtain noisy lane anchors, and the model learns to refine the
noisy lane anchors in a progressive way to obtain the target lanes. Secondly,
we propose a hybrid decoding strategy to address the poor feature
representation of the encoder, resulting from the noisy lane anchors.
Specifically, we design a hybrid diffusion decoder to combine global-level and
local-level decoders for high-quality lane anchors. Then, to improve the
feature representation of the encoder, we employ an auxiliary head in the
training stage to adopt the learnable lane anchors for enriching the
supervision on the encoder. Experimental results on four benchmarks, Carlane,
Tusimple, CULane, and LLAMAS, show that DiffusionLane possesses a strong
generalization ability and promising detection performance compared to the
previous state-of-the-art methods. For example, DiffusionLane with ResNet18
surpasses the existing methods by at least 1\% accuracy on the domain
adaptation dataset Carlane. Besides, DiffusionLane with MobileNetV4 gets
81.32\% F1 score on CULane, 96.89\% accuracy on Tusimple with ResNet34, and
97.59\% F1 score on LLAMAS with ResNet101. Code will be available at
https://github.com/zkyntu/UnLanedet.

</details>


### [83] [Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework](https://arxiv.org/abs/2510.22243)
*Amir Mohammad Khadem Hosseini,Sattar Mirzakuchaki*

Main category: cs.CV

TL;DR: FPGA上的实时语义分割实现，利用LMIINet和CGRA4ML，实现了90%的像素准确率和45%的mIoU，速度为20 FPS。


<details>
  <summary>Details</summary>
Motivation: 在满足计算和硬件限制的同时，在自动驾驶等实时应用中实现高精度的语义分割。

Method: 在CGRA4ML硬件框架上实现了轻量级LMIINet架构，使用8位量化感知训练，并对模型进行了修改以适应CGRA4ML的限制。

Result: 实现了大约90%的像素准确率和45%的mIoU，在ZCU104 FPGA板上实现了20 FPS的实时性能和50.1 ms的延迟。

Conclusion: CGRA4ML具有灵活性，可以映射现代层和利用片外内存，为在FPGA上实现先进的语义分割网络提供了途径，以在功耗效率方面超越传统GPU解决方案，同时保持有竞争力的准确性。

Abstract: Semantic segmentation has emerged as a fundamental problem in computer
vision, gaining particular importance in real-time applications such as
autonomous driving. The main challenge is achieving high accuracy while
operating under computational and hardware constraints. In this research, we
present an FPGA-based implementation of real-time semantic segmentation
leveraging the lightweight LMIINet architecture and the Coarse-Grained
Reconfigurable Array for Machine Learning (CGRA4ML) hardware framework. The
model was trained using Quantization-Aware Training (QAT) with 8-bit precision
on the Cityscapes dataset, reducing memory footprint by a factor of four while
enabling efficient fixed-point computations. Necessary modifications were
applied to adapt the model to CGRA4ML constraints, including simplifying skip
connections, employing hardware-friendly operations such as depthwise-separable
and 1A-1 convolutions, and redesigning parts of the Flatten Transformer. Our
implementation achieves approximately 90% pixel accuracy and 45% mean
Intersection-over-Union (mIoU), operating in real-time at 20 frames per second
(FPS) with 50.1 ms latency on the ZCU104 FPGA board. The results demonstrate
the potential of CGRA4ML, with its flexibility in mapping modern layers and
off-chip memory utilization for skip connections, provides a path for
implementing advanced semantic segmentation networks on FPGA for real-time
applications to outperform traditional GPU solutions in terms of power
efficiency while maintaining competitive accuracy. The code for this project is
publicly available at https://github.com/STAmirr/ cgra4ml_semantic_segmentation

</details>


### [84] [Accident Anticipation via Temporal Occurrence Prediction](https://arxiv.org/abs/2510.22260)
*Tianhao Zhao,Yiyang Zou,Zihao Mao,Peilun Xiao,Yulin Huang,Hongda Yang,Yuxuan Li,Qun Li,Guobin Wu,Yutian Lin*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Accident anticipation aims to predict potential collisions in an online
manner, enabling timely alerts to enhance road safety. Existing methods
typically predict frame-level risk scores as indicators of hazard. However,
these approaches rely on ambiguous binary supervision (labeling all frames in
accident videos as positive) despite the fact that risk varies continuously
over time, leading to unreliable learning and false alarms. To address this, we
propose a novel paradigm that shifts the prediction target from current-frame
risk scoring to directly estimating accident scores at multiple future time
steps (e.g., 0.1s-2.0s ahead), leveraging precisely annotated accident
timestamps as supervision. Our method employs a snippet-level encoder to
jointly model spatial and temporal dynamics, and a Transformer-based temporal
decoder that predicts accident scores for all future horizons simultaneously
using dedicated temporal queries. Furthermore, we introduce a refined
evaluation protocol that reports Time-to-Accident (TTA) and recall (evaluated
at multiple pre-accident intervals (0.5s, 1.0s, and 1.5s)) only when the false
alarm rate (FAR) remains within an acceptable range, ensuring practical
relevance. Experiments show that our method achieves superior performance in
both recall and TTA under realistic FAR constraints.

</details>


### [85] [GSAlign: Geometric and Semantic Alignment Network for Aerial-Ground Person Re-Identification](https://arxiv.org/abs/2510.22268)
*Qiao Li,Jie Li,Yukang Zhang,Lei Tan,Jing Chen,Jiayi Ji*

Main category: cs.CV

TL;DR: 本论文提出了一种名为GSAlign的网络，通过学习薄板样条变换和动态对齐模块来解决航空和地面行人重识别中的视角差异、遮挡和域迁移问题，在CARGO数据集上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的航空-地面行人重识别（AG-ReID）方法在处理极端视角差异、遮挡和域迁移方面存在局限性，尤其是在处理严重的姿态变化和空间错位方面。

Method: 提出了一种名为GSAlign的网络，包含两个关键组件：1. 学习薄板样条（LTPS）模块，通过学习关键点自适应地扭曲行人特征，以补偿视角变化导致的几何畸变。 2. 动态对齐（DAM）模块，估计可见性感知表示掩码，突出可见的身体区域，以减轻遮挡和部分观测的影响。

Result: +18.8% mAP and +16.8% Rank-1 accuracy improvement on CARGO dataset.

Conclusion: GSAlign通过结合LTPS模块和DAM模块，能够有效地处理AG-ReID任务中的几何畸变和语义错位问题，显著优于现有方法。

Abstract: Aerial-Ground person re-identification (AG-ReID) is an emerging yet
challenging task that aims to match pedestrian images captured from drastically
different viewpoints, typically from unmanned aerial vehicles (UAVs) and
ground-based surveillance cameras. The task poses significant challenges due to
extreme viewpoint discrepancies, occlusions, and domain gaps between aerial and
ground imagery. While prior works have made progress by learning cross-view
representations, they remain limited in handling severe pose variations and
spatial misalignment. To address these issues, we propose a Geometric and
Semantic Alignment Network (GSAlign) tailored for AG-ReID. GSAlign introduces
two key components to jointly tackle geometric distortion and semantic
misalignment in aerial-ground matching: a Learnable Thin Plate Spline (LTPS)
Module and a Dynamic Alignment Module (DAM). The LTPS module adaptively warps
pedestrian features based on a set of learned keypoints, effectively
compensating for geometric variations caused by extreme viewpoint changes. In
parallel, the DAM estimates visibility-aware representation masks that
highlight visible body regions at the semantic level, thereby alleviating the
negative impact of occlusions and partial observations in cross-view
correspondence. A comprehensive evaluation on CARGO with four matching
protocols demonstrates the effectiveness of GSAlign, achieving significant
improvements of +18.8\% in mAP and +16.8\% in Rank-1 accuracy over previous
state-of-the-art methods on the aerial-ground setting. The code is available
at: \textcolor{magenta}{https://github.com/stone96123/GSAlign}.

</details>


### [86] [Bag-of-Word-Groups (BoWG): A Robust and Efficient Loop Closure Detection Method Under Perceptual Aliasing](https://arxiv.org/abs/2510.22529)
*Xiang Fei,Tina Tian,Howie Choset,Lu Li*

Main category: cs.CV

TL;DR: BoWG是一种新的闭环检测方法，通过引入词组、时间一致性和特征分布分析来提高精度、召回率、鲁棒性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统闭环方法在感知别名环境（如狭窄管道）中存在不足（向量量化、特征稀疏、纹理重复），现有解决方案计算成本高。

Method: 提出词组（BoWG）方法，引入词组捕捉视觉词汇的空间共现和邻近性来构建在线词典。借鉴概率转移模型，将时间一致性融入相似度计算，并采用自适应方案。结合特征分布分析模块和后验证机制。

Result: BoWG在精度-召回率和计算效率方面优于现有方法，包括传统和基于学习的方法。在Bicocca25b数据集上，处理17,565张图像的平均处理时间为16毫秒，表现出良好的可扩展性。

Conclusion: BoWG在精度-召回率、鲁棒性和计算效率方面均优于现有方法，并且具有良好的可扩展性。

Abstract: Loop closure is critical in Simultaneous Localization and Mapping (SLAM)
systems to reduce accumulative drift and ensure global mapping consistency.
However, conventional methods struggle in perceptually aliased environments,
such as narrow pipes, due to vector quantization, feature sparsity, and
repetitive textures, while existing solutions often incur high computational
costs. This paper presents Bag-of-Word-Groups (BoWG), a novel loop closure
detection method that achieves superior precision-recall, robustness, and
computational efficiency. The core innovation lies in the introduction of word
groups, which captures the spatial co-occurrence and proximity of visual words
to construct an online dictionary. Additionally, drawing inspiration from
probabilistic transition models, we incorporate temporal consistency directly
into similarity computation with an adaptive scheme, substantially improving
precision-recall performance. The method is further strengthened by a feature
distribution analysis module and dedicated post-verification mechanisms. To
evaluate the effectiveness of our method, we conduct experiments on both public
datasets and a confined-pipe dataset we constructed. Results demonstrate that
BoWG surpasses state-of-the-art methods, including both traditional and
learning-based approaches, in terms of precision-recall and computational
efficiency. Our approach also exhibits excellent scalability, achieving an
average processing time of 16 ms per image across 17,565 images in the
Bicocca25b dataset.

</details>


### [87] [WAON: Large-Scale and High-Quality Japanese Image-Text Pair Dataset for Vision-Language Models](https://arxiv.org/abs/2510.22276)
*Issa Sugiura,Shuhei Kurita,Yusuke Oda,Daisuke Kawahara,Yasuo Okabe,Naoaki Okazaki*

Main category: cs.CV

TL;DR: WAON是一个包含约1.55亿个图像-文本对的大规模高质量日语数据集，用于训练视觉语言模型。


<details>
  <summary>Details</summary>
Motivation: 为了构建大规模、高质量的日语图像-文本对数据集，以促进高性能视觉语言模型（VLMs）的发展。

Method: 通过从Common Crawl收集数据，并采用过滤和去重等技术构建了一个包含约1.55亿个样本的WAON数据集。同时，创建了一个包含374个类别的日语文化图像分类基准WAON-Bench。使用WAON和ReLAION的日语子集对SigLIP2模型进行微调。

Result: 在WAON-Bench上，使用WAON训练的模型比使用ReLAION训练的模型效率更高。在所有评估的基准测试中，使用WAON的模型都取得了更高的准确性。此外，在多个日语文化基准测试中，使用WAON微调的模型达到了最先进的性能。

Conclusion: WAON数据集能够有效地提升模型在日语视觉-语言任务上的性能，并在多个日语文化相关任务上取得了最先进的结果。

Abstract: Large-scale and high-quality image-text pair datasets play an important role
in developing high-performing Vision-Language Models (VLMs). In this work, we
introduce WAON, a large-scale and high-quality Japanese image-text pair dataset
containing approximately 155 million examples, collected from Common Crawl. Our
dataset construction pipeline employs various techniques, including filtering
and deduplication, which have been shown to be effective in previous studies.
To evaluate its effectiveness, we also construct WAON-Bench, a manually curated
benchmark for Japanese cultural image classification, consisting of 374
classes. To assess the effectiveness of our dataset, we conduct experiments
using both WAON and the Japanese subset of ReLAION, one of the most widely used
vision-language datasets. We fine-tune SigLIP2, a strong multilingual model, on
both datasets. The results demonstrate that WAON enhances model performance on
WAON-Bench more efficiently than ReLAION and achieves higher accuracy across
all evaluated benchmarks. Furthermore, the model fine-tuned on WAON achieves
state-of-the-art performance on several Japanese cultural benchmarks. We
release our dataset, model, and code at https://speed1313.github.io/WAON.

</details>


### [88] [Look and Tell: A Dataset for Multimodal Grounding Across Egocentric and Exocentric Views](https://arxiv.org/abs/2510.22672)
*Anna Deichler,Jonas Beskow*

Main category: cs.CV

TL;DR: 我们提出了Look and Tell，一个用于研究跨主观和客观视角的指代通信的多模态数据集。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是创建一个多模态数据集，用于研究在主观和客观视角下进行的指代通信，以推动具身智能体的开发。

Method: 使用Meta Project Aria智能眼镜和固定摄像机，记录了25名参与者指导他们识别厨房食材的同步注视、语音和视频。结合3D场景重建，该设置提供了一个基准，用于评估不同的空间表示（2D vs. 3D；主观 vs. 客观）如何影响多模态基础。数据集包含3.67小时的录音，包括2,707个带丰富注释的指代表达。

Result: 生成了一个包含3.67小时录音和2,707个带注释指代表达的数据集，用于评估空间表示对多模态基础的影响。

Conclusion: Look and Tell数据集为研究不同空间表示如何影响多模态基础提供了基准，旨在促进能够理解和进行情境对话的具身智能体的开发。

Abstract: We introduce Look and Tell, a multimodal dataset for studying referential
communication across egocentric and exocentric perspectives. Using Meta Project
Aria smart glasses and stationary cameras, we recorded synchronized gaze,
speech, and video as 25 participants instructed a partner to identify
ingredients in a kitchen. Combined with 3D scene reconstructions, this setup
provides a benchmark for evaluating how different spatial representations (2D
vs. 3D; ego vs. exo) affect multimodal grounding. The dataset contains 3.67
hours of recordings, including 2,707 richly annotated referential expressions,
and is designed to advance the development of embodied agents that can
understand and engage in situated dialogue.

</details>


### [89] [CityRiSE: Reasoning Urban Socio-Economic Status in Vision-Language Models via Reinforcement Learning](https://arxiv.org/abs/2510.22282)
*Tianhui Liu,Hetian Pang,Xin Zhang,Jie Feng,Yong Li,Pan Hui*

Main category: cs.CV

TL;DR: CityRiSE是一个利用纯强化学习（RL）的框架，通过引导大型视觉语言模型（LVLM）关注有意义的视觉线索，来提高城市社会经济状况预测的准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 利用大型视觉语言模型（LVLM）解决城市社会经济感知和理解问题，但现有研究表明LVLM在准确性和可解释性方面存在不足。

Method: 提出了一种名为CityRiSE的新型框架，利用纯强化学习（RL）来引导LVLM进行城市社会经济地位的推理。该框架使用了精心策划的多模态数据和可验证的奖励设计，以实现结构化和面向目标化的推理。

Result: CityRiSE在预测准确性和泛化能力方面显著优于现有方法，尤其是在预测未知城市和未知指标方面表现突出。

Conclusion: 将强化学习（RL）和大型视觉语言模型（LVLM）结合，为实现可解释和通用的城市社会经济感知提供了有前景的方法。

Abstract: Harnessing publicly available, large-scale web data, such as street view and
satellite imagery, urban socio-economic sensing is of paramount importance for
achieving global sustainable development goals. With the emergence of Large
Vision-Language Models (LVLMs), new opportunities have arisen to solve this
task by treating it as a multi-modal perception and understanding problem.
However, recent studies reveal that LVLMs still struggle with accurate and
interpretable socio-economic predictions from visual data. To address these
limitations and maximize the potential of LVLMs, we introduce
\textbf{CityRiSE}, a novel framework for \textbf{R}eason\textbf{i}ng urban
\textbf{S}ocio-\textbf{E}conomic status in LVLMs through pure reinforcement
learning (RL). With carefully curated multi-modal data and verifiable reward
design, our approach guides the LVLM to focus on semantically meaningful visual
cues, enabling structured and goal-oriented reasoning for generalist
socio-economic status prediction. Experiments demonstrate that CityRiSE with
emergent reasoning process significantly outperforms existing baselines,
improving both prediction accuracy and generalization across diverse urban
contexts, particularly for prediction on unseen cities and unseen indicators.
This work highlights the promise of combining RL and LVLMs for interpretable
and generalist urban socio-economic sensing.

</details>


### [90] [GRPO-Guard: Mitigating Implicit Over-Optimization in Flow Matching via Regulated Clipping](https://arxiv.org/abs/2510.22319)
*Jing Wang,Jiajun Liang,Jie Liu,Henglin Liu,Gongye Liu,Jun Zheng,Wanyuan Pang,Ao Ma,Zhenyu Xie,Xintao Wang,Meng Wang,Pengfei Wan,Xiaodan Liang*

Main category: cs.CV

TL;DR: GRPO-Guard通过引入 ratio normalization 和 gradient reweighting 来解决 GRPO 在流匹配模型优化中出现的隐式过优化问题，提高了生成质量和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于 GRPO 的强化学习方法在优化流匹配模型时，由于重要性比率分布的系统性偏移（均值低于1且方差随时间步变化），导致裁剪机制失效，策略模型进入隐式过优化阶段，最终影响生成质量和实用性。

Method: 提出 GRPO-Guard，通过 ratio normalization 恢复重要性比率的平衡和跨时间步的一致性，并结合 gradient reweighting 策略均衡不同噪声条件下的策略梯度，从而稳定优化过程。

Result: GRPO-Guard 显著降低了过优化现象，同时保持甚至提高了生成质量，并在 SD3.5M、Flux.1-dev 等多个扩散模型和多种代理任务上进行了验证。

Conclusion: GRPO-Guard 是一种简单有效的方法，可以增强现有的 GRPO 框架，有效解决隐式过优化问题，提高流匹配模型的性能和稳定性。

Abstract: Recently, GRPO-based reinforcement learning has shown remarkable progress in
optimizing flow-matching models, effectively improving their alignment with
task-specific rewards. Within these frameworks, the policy update relies on
importance-ratio clipping to constrain overconfident positive and negative
gradients. However, in practice, we observe a systematic shift in the
importance-ratio distribution-its mean falls below 1 and its variance differs
substantially across timesteps. This left-shifted and inconsistent distribution
prevents positive-advantage samples from entering the clipped region, causing
the mechanism to fail in constraining overconfident positive updates. As a
result, the policy model inevitably enters an implicit over-optimization
stage-while the proxy reward continues to increase, essential metrics such as
image quality and text-prompt alignment deteriorate sharply, ultimately making
the learned policy impractical for real-world use. To address this issue, we
introduce GRPO-Guard, a simple yet effective enhancement to existing GRPO
frameworks. Our method incorporates ratio normalization, which restores a
balanced and step-consistent importance ratio, ensuring that PPO clipping
properly constrains harmful updates across denoising timesteps. In addition, a
gradient reweighting strategy equalizes policy gradients over noise conditions,
preventing excessive updates from particular timestep regions. Together, these
designs act as a regulated clipping mechanism, stabilizing optimization and
substantially mitigating implicit over-optimization without relying on heavy KL
regularization. Extensive experiments on multiple diffusion backbones (e.g.,
SD3.5M, Flux.1-dev) and diverse proxy tasks demonstrate that GRPO-Guard
significantly reduces over-optimization while maintaining or even improving
generation quality.

</details>


### [91] [Beyond Augmentation: Leveraging Inter-Instance Relation in Self-Supervised Representation Learning](https://arxiv.org/abs/2510.22322)
*Ali Javidani,Babak Nadjar Araabi,Mohammad Amin Sadeghi*

Main category: cs.CV

TL;DR: 本论文提出了一种新的图论结合自监督表征学习的方法，通过构建KNN图来捕捉实例间的关系，并使用GNN进行表征优化，在多个数据集上取得了显著的精度提升。


<details>
  <summary>Details</summary>
Motivation: 传统自监督表征学习方法主要关注实例内部的变异，忽略了实例间的关系。本方法旨在解决这一问题，通过引入图论来捕捉和利用实例间的关系。

Method: 本方法在预训练阶段构建教师和学生流的KNN图，其中节点代表样本及其潜在表征，边表示实例间的相似性。在预训练之后，使用GNN进行表征细化，允许信息在图谱中跨越多跳进行传播，从而实现更广泛的上下文整合。

Result: 在CIFAR-10、ImageNet-100和ImageNet-1K数据集上，本方法分别比现有最先进的方法提高了7.3%、3.2%和1.0%的准确率。

Conclusion: 实验结果证明了所提出的基于图的方法在自监督表征学习中的有效性。

Abstract: This paper introduces a novel approach that integrates graph theory into
self-supervised representation learning. Traditional methods focus on
intra-instance variations generated by applying augmentations. However, they
often overlook important inter-instance relationships. While our method retains
the intra-instance property, it further captures inter-instance relationships
by constructing k-nearest neighbor (KNN) graphs for both teacher and student
streams during pretraining. In these graphs, nodes represent samples along with
their latent representations. Edges encode the similarity between instances.
Following pretraining, a representation refinement phase is performed. In this
phase, Graph Neural Networks (GNNs) propagate messages not only among immediate
neighbors but also across multiple hops, thereby enabling broader contextual
integration. Experimental results on CIFAR-10, ImageNet-100, and ImageNet-1K
demonstrate accuracy improvements of 7.3%, 3.2%, and 1.0%, respectively, over
state-of-the-art methods. These results highlight the effectiveness of the
proposed graph based mechanism. The code is publicly available at
https://github.com/alijavidani/SSL-GraphNNCLR.

</details>


### [92] [Moving Beyond Diffusion: Hierarchy-to-Hierarchy Autoregression for fMRI-to-Image Reconstruction](https://arxiv.org/abs/2510.22335)
*Xu Zhang,Ruijie Quan,Wenguan Wang,Yi Yang*

Main category: cs.CV

TL;DR: MindHier是一个新框架，通过多层次的fMRI信号生成图像，比现有方法更快、更准确。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散的方法将fMRI信号映射到单一的高层嵌入，这与图像重建过程中对阶段性信息的需求不符，并且会丢失层次化的神经信息。

Method: MindHier框架包含三个组件：1. 层次化fMRI编码器：提取多层次的神经嵌入。2. 层次化对齐方案：强制进行层级与CLIP特征的一致性。3. 尺度感知粗粒度到细粒度神经引导策略：在匹配的尺度上将嵌入注入自回归模型。该框架采用粗粒度到细粒度的重建方式，先合成全局语义，再优化局部细节。

Result: 在NSD数据集上的实验表明，MindHier在语义保真度方面优于基于扩散的方法，并且推理速度提高了4.67倍，结果更具确定性。

Conclusion: MindHier通过采用层次化的重建过程，能够实现比基于扩散的方法更高效、更符合认知规律的fMRI到图像重建。

Abstract: Reconstructing visual stimuli from fMRI signals is a central challenge
bridging machine learning and neuroscience. Recent diffusion-based methods
typically map fMRI activity to a single high-level embedding, using it as fixed
guidance throughout the entire generation process. However, this fixed guidance
collapses hierarchical neural information and is misaligned with the
stage-dependent demands of image reconstruction. In response, we propose
MindHier, a coarse-to-fine fMRI-to-image reconstruction framework built on
scale-wise autoregressive modeling. MindHier introduces three components: a
Hierarchical fMRI Encoder to extract multi-level neural embeddings, a
Hierarchy-to-Hierarchy Alignment scheme to enforce layer-wise correspondence
with CLIP features, and a Scale-Aware Coarse-to-Fine Neural Guidance strategy
to inject these embeddings into autoregression at matching scales. These
designs make MindHier an efficient and cognitively-aligned alternative to
diffusion-based methods by enabling a hierarchical reconstruction process that
synthesizes global semantics before refining local details, akin to human
visual perception. Extensive experiments on the NSD dataset show that MindHier
achieves superior semantic fidelity, 4.67x faster inference, and more
deterministic results than the diffusion-based baselines.

</details>


### [93] [GeoDiffusion: A Training-Free Framework for Accurate 3D Geometric Conditioning in Image Generation](https://arxiv.org/abs/2510.22337)
*Phillip Mueller,Talip Uenlue,Sebastian Schmidt,Marcel Kollovieh,Jiajie Fan,Stephan Guennemann,Lars Mikelsons*

Main category: cs.CV

TL;DR: GeoDiffusion是一个无需训练的框架，可以通过3D对象作为几何先验来精确控制图像生成中的3D对象特征，并能通过GeoDrag进行拖拽编辑。


<details>
  <summary>Details</summary>
Motivation: 传统的3D编辑方法耗时且需要专业技能，现有的基于图像的生成方法在几何条件控制方面精度不足，无法满足工程设计和创意产业中对3D对象特征进行精确图像空间控制的需求。

Method: GeoDiffusion利用类别特定的3D对象作为几何先验来定义3D空间中的关键点和参数相关性。通过渲染参考3D对象的图像来确保视角一致性，然后进行风格迁移以满足用户定义的外观规范。其核心是GeoDrag，用于提高基于拖拽的图像编辑在几何引导任务和DragBench通用指令上的准确性和速度。

Result: GeoDiffusion能够实现多种迭代设计流程中精确的几何修改。

Conclusion: GeoDiffusion为图像生成提供了精确且高效的几何条件控制，并能通过GeoDrag进行高效的拖拽编辑。

Abstract: Precise geometric control in image generation is essential for engineering \&
product design and creative industries to control 3D object features accurately
in image space. Traditional 3D editing approaches are time-consuming and demand
specialized skills, while current image-based generative methods lack accuracy
in geometric conditioning. To address these challenges, we propose
GeoDiffusion, a training-free framework for accurate and efficient geometric
conditioning of 3D features in image generation. GeoDiffusion employs a
class-specific 3D object as a geometric prior to define keypoints and
parametric correlations in 3D space. We ensure viewpoint consistency through a
rendered image of a reference 3D object, followed by style transfer to meet
user-defined appearance specifications. At the core of our framework is
GeoDrag, improving accuracy and speed of drag-based image editing on geometry
guidance tasks and general instructions on DragBench. Our results demonstrate
that GeoDiffusion enables precise geometric modifications across various
iterative design workflows.

</details>


### [94] [EndoSfM3D: Learning to 3D Reconstruct Any Endoscopic Surgery Scene using Self-supervised Foundation Model](https://arxiv.org/abs/2510.22359)
*Changhao Zhang,Matthew J. Clarkson,Mobarak I. Hoque*

Main category: cs.CV

TL;DR: 该研究提出了一种集成内参估计的自监督单目深度估计框架，用于内窥镜手术场景的三维重建。


<details>
  <summary>Details</summary>
Motivation: 现有内窥镜三维重建方法通常不估计内参，限制了重建的准确性和可靠性。内窥镜手术场景中，消毒限制和连续变焦、旋转等特性使得内参标定尤具挑战性。

Method: 通过改进 Depth Anything V2 (DA2) 模型，使其能够联合预测深度、位姿和内参。引入了基于注意力的位姿网络和 DoRA (Weight-Decomposed Low-Rank Adaptation) 策略进行高效微调。

Result: 在 SCARED 和 C3VD 数据集上进行了验证，与现有最先进的自监督单目深度估计和三维重建方法相比，取得了优越的性能。

Conclusion: 该方法有效地将内参估计集成到自监督单目深度估计框架中，显著提高了内窥镜手术场景三维重建的准确性和鲁棒性。

Abstract: 3D reconstruction of endoscopic surgery scenes plays a vital role in
enhancing scene perception, enabling AR visualization, and supporting
context-aware decision-making in image-guided surgery. A critical yet
challenging step in this process is the accurate estimation of the endoscope's
intrinsic parameters. In real surgical settings, intrinsic calibration is
hindered by sterility constraints and the use of specialized endoscopes with
continuous zoom and telescope rotation. Most existing methods for endoscopic 3D
reconstruction do not estimate intrinsic parameters, limiting their
effectiveness for accurate and reliable reconstruction. In this paper, we
integrate intrinsic parameter estimation into a self-supervised monocular depth
estimation framework by adapting the Depth Anything V2 (DA2) model for joint
depth, pose, and intrinsics prediction. We introduce an attention-based pose
network and a Weight-Decomposed Low-Rank Adaptation (DoRA) strategy for
efficient fine-tuning of DA2. Our method is validated on the SCARED and C3VD
public datasets, demonstrating superior performance compared to recent
state-of-the-art approaches in self-supervised monocular depth estimation and
3D reconstruction. Code and model weights can be found in project repository:
https://github.com/MOYF-beta/EndoSfM3D.

</details>


### [95] [EndoWave: Rational-Wavelet 4D Gaussian Splatting for Endoscopic Reconstruction](https://arxiv.org/abs/2510.23087)
*Taoyu Wu,Yiyi Miao,Jiaxin Guo,Ziyan Chen,Sihang Zhao,Zhuoxiao Li,Zhe Tang,Baoru Huang,Limin Yu*

Main category: cs.CV

TL;DR: EndoWave使用结合了光流几何约束和多分辨率小波监督的统一时空高斯溅射框架，解决了机器人辅助微创手术中内窥镜视频3D重建的挑战。


<details>
  <summary>Details</summary>
Motivation: 内窥镜场景存在光度不一致、非刚性组织运动和视角相关高光等独特挑战，仅依赖外观约束的3DGS方法在这种情况下不足以进行准确的3D重建。

Method: EndoWave采用统一的时空高斯表示，优化4D域中的原始元；引入源自光流的几何约束以增强时间连贯性并约束场景的3D结构；提出多分辨率有理正交小波作为约束，以分离内窥镜细节并提高渲染性能。

Result: 在EndoNeRF和StereoMIS两个真实手术数据集上的广泛评估表明，与基线方法相比，EndoWave在重建质量和视觉准确性方面达到了最先进的水平。

Conclusion: EndoWave通过结合光流几何约束和多分辨率小波监督，成功解决了内窥镜视频3D重建的挑战，并在真实手术数据集上实现了最先进的性能。

Abstract: In robot-assisted minimally invasive surgery, accurate 3D reconstruction from
endoscopic video is vital for downstream tasks and improved outcomes. However,
endoscopic scenarios present unique challenges, including photometric
inconsistencies, non-rigid tissue motion, and view-dependent highlights. Most
3DGS-based methods that rely solely on appearance constraints for optimizing
3DGS are often insufficient in this context, as these dynamic visual artifacts
can mislead the optimization process and lead to inaccurate reconstructions. To
address these limitations, we present EndoWave, a unified spatio-temporal
Gaussian Splatting framework by incorporating an optical flow-based geometric
constraint and a multi-resolution rational wavelet supervision. First, we adopt
a unified spatio-temporal Gaussian representation that directly optimizes
primitives in a 4D domain. Second, we propose a geometric constraint derived
from optical flow to enhance temporal coherence and effectively constrain the
3D structure of the scene. Third, we propose a multi-resolution rational
orthogonal wavelet as a constraint, which can effectively separate the details
of the endoscope and enhance the rendering performance. Extensive evaluations
on two real surgical datasets, EndoNeRF and StereoMIS, demonstrate that our
method EndoWave achieves state-of-the-art reconstruction quality and visual
accuracy compared to the baseline method.

</details>


### [96] [T2SMark: Balancing Robustness and Diversity in Noise-as-Watermark for Diffusion Models](https://arxiv.org/abs/2510.22366)
*Jindong Yang,Han Fang,Weiming Zhang,Nenghai Yu,Kejiang Chen*

Main category: cs.CV

TL;DR: T2SMark是一种用于扩散模型的两阶段水印方案，它使用尾部截断采样（TTS）来平衡水印鲁棒性和生成多样性，解决了现有方法在这两者之间难以权衡的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的图像水印方法，特别是NaW方法，在鲁棒性和生成多样性之间难以取得平衡。一些方法为了获得更强的鲁棒性而过度约束了初始噪声采样，损害了用户体验；而另一些方法虽然保持了多样性，但在实际应用中却过于脆弱。

Method: T2SMark提出了一种基于尾部截断采样（TTS）的两阶段水印方案。TTS通过将比特信息嵌入到可靠的尾部区域，并随机采样中心区域来增强鲁棒性，同时保持潜在分布。两阶段框架通过整合随机生成的会话密钥来确保采样多样性。

Result: 在基于U-Net和DiT骨干的扩散模型上的实验表明，T2SMark在鲁棒性和多样性之间取得了最佳的平衡。

Conclusion: T2SMark通过尾部截断采样（TTS）和两阶段框架，成功地在扩散模型的图像水印任务中实现了鲁棒性和生成多样性的最佳平衡。

Abstract: Diffusion models have advanced rapidly in recent years, producing
high-fidelity images while raising concerns about intellectual property
protection and the misuse of generative AI. Image watermarking for diffusion
models, particularly Noise-as-Watermark (NaW) methods, encode watermark as
specific standard Gaussian noise vector for image generation, embedding the
infomation seamlessly while maintaining image quality. For detection, the
generation process is inverted to recover the initial noise vector containing
the watermark before extraction. However, existing NaW methods struggle to
balance watermark robustness with generation diversity. Some methods achieve
strong robustness by heavily constraining initial noise sampling, which
degrades user experience, while others preserve diversity but prove too fragile
for real-world deployment. To address this issue, we propose T2SMark, a
two-stage watermarking scheme based on Tail-Truncated Sampling (TTS). Unlike
prior methods that simply map bits to positive or negative values, TTS enhances
robustness by embedding bits exclusively in the reliable tail regions while
randomly sampling the central zone to preserve the latent distribution. Our
two-stage framework then ensures sampling diversity by integrating a randomly
generated session key into both encryption pipelines. We evaluate T2SMark on
diffusion models with both U-Net and DiT backbones. Extensive experiments show
that it achieves an optimal balance between robustness and diversity. Our code
is available at
\href{https://github.com/0xD009/T2SMark}{https://github.com/0xD009/T2SMark}.

</details>


### [97] [Efficient Large-Deformation Medical Image Registration via Recurrent Dynamic Correlation](https://arxiv.org/abs/2510.22380)
*Tianran Li,Marius Staring,Yuchuan Qiao*

Main category: cs.CV

TL;DR: 使用循环相关性框架处理大形变，在准确性和计算量之间取得良好平衡，速度快且计算量少。


<details>
  <summary>Details</summary>
Motivation: 在医学影像配准中，深度学习方法虽然能减少运行时间，但处理大形变仍然是一个挑战。现有方法如体素到区域匹配，虽然效率较高，但其固有的局部性限制了捕捉远距离对应关系的能力，而区域到区域匹配则会产生冗余。需要一种能够有效处理大形变的配准方法。

Method: 提出一种循环相关性（Recurrent Correlation-based）框架，通过动态重新定位匹配区域来捕捉远距离对应关系。在每个步骤中，进行局部匹配并使用估计的偏移量指导下一个搜索区域。此外，还使用了一个具有记忆能力的轻量级循环更新模块，并将运动相关特征与纹理特征分离，以减少语义冗余。

Result: 在脑部MRI和腹部CT数据集上进行了广泛的实验，结果表明该方法在准确性-计算量权衡方面表现出色，性能优于或等于现有最先进的方法。例如，在非仿射OASIS数据集上，该方法实现了可比的性能，但仅使用了RDP方法的9.5%的浮点运算量，并且运行速度提高了96%。

Conclusion: 所提出的循环相关性框架能够有效地处理大形变，并在准确性和计算成本之间取得了良好的平衡，为医学影像配准提供了一种高效且准确的解决方案。

Abstract: Deformable image registration estimates voxel-wise correspondences between
images through spatial transformations, and plays a key role in medical
imaging. While deep learning methods have significantly reduced runtime,
efficiently handling large deformations remains a challenging task.
Convolutional networks aggregate local features but lack direct modeling of
voxel correspondences, promoting recent works to explore explicit feature
matching. Among them, voxel-to-region matching is more efficient for direct
correspondence modeling by computing local correlation features whithin
neighbourhoods, while region-to-region matching incurs higher redundancy due to
excessive correlation pairs across large regions. However, the inherent
locality of voxel-to-region matching hinders the capture of long-range
correspondences required for large deformations. To address this, we propose a
Recurrent Correlation-based framework that dynamically relocates the matching
region toward more promising positions. At each step, local matching is
performed with low cost, and the estimated offset guides the next search
region, supporting efficient convergence toward large deformations. In
addition, we uses a lightweight recurrent update module with memory capacity
and decouples motion-related and texture features to suppress semantic
redundancy. We conduct extensive experiments on brain MRI and abdominal CT
datasets under two settings: with and without affine pre-registration. Results
show that our method exibits a strong accuracy-computation trade-off,
surpassing or matching the state-of-the-art performance. For example, it
achieves comparable performance on the non-affine OASIS dataset, while using
only 9.5% of the FLOPs and running 96% faster than RDP, a representative
high-performing method.

</details>


### [98] [DPGLA: Bridging the Gap between Synthetic and Real Data for Unsupervised Domain Adaptation in 3D LiDAR Semantic Segmentation](https://arxiv.org/abs/2510.23525)
*Wanmeng Li,Simone Mosco,Daniel Fusaro,Alberto Pretto*

Main category: cs.CV

TL;DR: 现有的基于自训练的无监督域适应方法在利用未标记数据方面存在不足，可能导致性能不佳。我们提出了一种动态伪标签过滤（DPLF）方案和一种先验引导数据增强（PG-DAP）流程，以提高点云域适应中的数据利用率并减轻域偏移，从而在合成到现实的点云语义分割任务中取得优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于自训练的无监督域适应（UDA）方法在利用未标记数据方面存在不足，通常依赖预定义或固定的置信度阈值，导致性能不佳。

Method: 提出动态伪标签过滤（DPLF）方案以增强对未标记数据的利用；设计先验引导数据增强（PG-DAP）流程以减轻域偏移；利用数据混合一致性损失来学习上下文无关的表示。

Result: 在两个具有挑战性的合成到现实点云语义分割任务上，相比最先进的方法取得了优越的性能。消融研究证实了DPLF和PG-DAP模块的有效性。

Conclusion: 所提出的DPLF和PG-DAP方法能够有效提升点云UDA语义分割的性能。

Abstract: Annotating real-world LiDAR point clouds for use in intelligent autonomous
systems is costly. To overcome this limitation, self-training-based
Unsupervised Domain Adaptation (UDA) has been widely used to improve point
cloud semantic segmentation by leveraging synthetic point cloud data. However,
we argue that existing methods do not effectively utilize unlabeled data, as
they either rely on predefined or fixed confidence thresholds, resulting in
suboptimal performance. In this paper, we propose a Dynamic Pseudo-Label
Filtering (DPLF) scheme to enhance real data utilization in point cloud UDA
semantic segmentation. Additionally, we design a simple and efficient
Prior-Guided Data Augmentation Pipeline (PG-DAP) to mitigate domain shift
between synthetic and real-world point clouds. Finally, we utilize data mixing
consistency loss to push the model to learn context-free representations. We
implement and thoroughly evaluate our approach through extensive comparisons
with state-of-the-art methods. Experiments on two challenging synthetic-to-real
point cloud semantic segmentation tasks demonstrate that our approach achieves
superior performance. Ablation studies confirm the effectiveness of the DPLF
and PG-DAP modules. We release the code of our method in this paper.

</details>


### [99] [A Fully Interpretable Statistical Approach for Roadside LiDAR Background Subtraction](https://arxiv.org/abs/2510.22390)
*Aitor Iglesias,Nerea Aranjuelo,Patricia Javierre,Ainhoa Menendez,Ignacio Arganda-Carreras,Marcos Nieto*

Main category: cs.CV

TL;DR: 提出了一种用于路侧激光雷达数据的全可解释、灵活的背景扣除统计方法，通过高斯分布网格（GDG）和滤波算法对背景点进行分类，以增强自动驾驶基础设施感知。该方法支持多种激光雷达类型和配置，在RCooper数据集上表现优于现有技术，并且能在资源受限的硬件上高效运行。


<details>
  <summary>Details</summary>
Motivation: 增强自动驾驶的道路基础设施感知能力，需要一种准确、灵活且可解释的背景扣除方法来处理路侧激光雷达数据。

Method: 提出了一种基于高斯分布网格（GDG）的统计方法。首先，使用仅包含背景的扫描数据构建GDG来模拟背景的空间统计信息。然后，设计一个滤波算法，利用GDG来区分激光雷达点是属于前景还是背景。

Result: 在公开的RCooper数据集上评估，该方法在准确性和灵活性方面优于最先进的技术，即使在背景数据量很少的情况下也能取得良好效果。所提出的方法能够高效运行，满足资源受限硬件的需求。

Conclusion: 该方法提供了一种全可解释、灵活且准确的背景扣除方案，适用于各种激光雷达传感器和配置，为自动驾驶中的路侧基础设施感知提供了可靠的解决方案，并具有良好的可扩展性。

Abstract: We present a fully interpretable and flexible statistical method for
background subtraction in roadside LiDAR data, aimed at enhancing
infrastructure-based perception in automated driving. Our approach introduces
both a Gaussian distribution grid (GDG), which models the spatial statistics of
the background using background-only scans, and a filtering algorithm that uses
this representation to classify LiDAR points as foreground or background. The
method supports diverse LiDAR types, including multiline 360 degree and
micro-electro-mechanical systems (MEMS) sensors, and adapts to various
configurations. Evaluated on the publicly available RCooper dataset, it
outperforms state-of-the-art techniques in accuracy and flexibility, even with
minimal background data. Its efficient implementation ensures reliable
performance on low-resource hardware, enabling scalable real-world deployment.

</details>


### [100] [Top-Down Semantic Refinement for Image Captioning](https://arxiv.org/abs/2510.22391)
*Jusheng Zhang,Kaitong Cai,Jing Yang,Jian Wang,Chengpei Tang,Keze Wang*

Main category: cs.CV

TL;DR: 大型视觉-语言模型（VLMs）在图像描述方面存在一个固有的矛盾：它们强大的单步生成能力常常导致近视的决策过程，难以在捕捉丰富细节的同时保持全局叙事连贯性。为了解决这个根本性挑战，我们将图像描述重新定义为一个面向目标的、分层的优化规划问题，并提出了一个名为“自上而下语义优化”（TDSR）的新框架，将生成过程建模为一个马尔可夫决策过程（MDP）。我们设计了一个高效的、针对VLMs定制的蒙特卡洛树搜索（MCTS）算法，通过引入视觉引导的并行扩展和轻量级价值网络，TDSR将昂贵的VLM调用频率降低了一个数量级，同时保持了规划质量。此外，一个自适应的提前停止机制能够动态地将计算开销与图像的复杂性相匹配。在DetailCaps、COMPOSITIONCAP和POPE等多个基准测试上的大量实验表明，TDSR作为一个即插即用模块，能够显著提升现有VLMs（如LLaVA-1.5、Qwen2.5-VL）在细粒度描述、组合泛化和幻觉抑制方面的性能，达到最先进或具有高度竞争力。


<details>
  <summary>Details</summary>
Motivation: 大型视觉-语言模型（VLMs）在图像描述方面存在一个固有的矛盾：强大的单步生成能力导致近视的决策过程，难以在捕捉丰富细节的同时保持全局叙事连贯性，尤其是在需要多步和复杂场景描述的任务中。

Method: 将图像描述重新定义为面向目标的、分层的优化规划问题，并提出一个名为“自上而下语义优化”（TDSR）的新框架，将生成过程建模为一个马尔可夫决策过程（MDP）。设计了一个高效的、针对VLMs定制的蒙特卡洛树搜索（MCTS）算法，包括视觉引导的并行扩展和轻量级价值网络，以及一个自适应的提前停止机制。

Result: TDSR将昂贵的VLM调用频率降低了一个数量级，同时保持了规划质量。在DetailCaps、COMPOSITIONCAP和POPE等多个基准测试上，TDSR显著提升了现有VLMs（如LLaVA-1.5、Qwen2.5-VL）在细粒度描述、组合泛化和幻觉抑制方面的性能，达到了最先进或具有高度竞争力。

Conclusion: TDSR作为一个即插即用模块，能够通过高效的MCTS算法解决大型VLMs在图像描述中面临的全局连贯性和细节捕捉的矛盾，显著提升现有模型的性能。

Abstract: Large Vision-Language Models (VLMs) face an inherent contradiction in image
captioning: their powerful single-step generation capabilities often lead to a
myopic decision-making process. This makes it difficult to maintain global
narrative coherence while capturing rich details, a limitation that is
particularly pronounced in tasks that require multi-step and complex scene
description. To overcome this fundamental challenge, we redefine image
captioning as a goal-oriented hierarchical refinement planning problem, and
further propose a novel framework, named Top-Down Semantic Refinement (TDSR),
which models the generation process as a Markov Decision Process (MDP).
However, planning within the vast state space of a VLM presents a significant
computational hurdle. Our core contribution, therefore, is the design of a
highly efficient Monte Carlo Tree Search (MCTS) algorithm tailored for VLMs. By
incorporating a visual-guided parallel expansion and a lightweight value
network, our TDSR reduces the call frequency to the expensive VLM by an order
of magnitude without sacrificing planning quality. Furthermore, an adaptive
early stopping mechanism dynamically matches computational overhead to the
image's complexity. Extensive experiments on multiple benchmarks, including
DetailCaps, COMPOSITIONCAP, and POPE, demonstrate that our TDSR, as a
plug-and-play module, can significantly enhance the performance of existing
VLMs (e.g., LLaVA-1.5, Qwen2.5-VL) by achieving state-of-the-art or highly
competitive results in fine-grained description, compositional generalization,
and hallucination suppression.

</details>


### [101] [3D Roadway Scene Object Detection with LIDARs in Snowfall Conditions](https://arxiv.org/abs/2510.22436)
*Ghazal Farhani,Taufiq Rahman,Syed Mostaquim Ali,Andrew Liu,Mohamed Zaki,Dominique Charlebois,Benoit Anctil*

Main category: cs.CV

TL;DR: LiDAR在雨雪天气下表现不佳，需要量化其性能衰减并模拟雨雪天气以提高自动驾驶系统的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 雨雪天气条件下LiDAR性能下降，影响自动驾驶系统的感知能力，但目前对其性能衰减的量化不足。

Method: 开发了一个基于物理的LiDAR模型，分析了LiDAR在雪天条件下的失效模式，研究了信号衰减与降雪率的关系，并模拟了不同降雪率下的数据。

Result: 通过模拟数据评估了LiDAR在不同降雪率下的性能，并验证了该模型在模拟真实雪天条件下的有效性。

Conclusion: 该研究提出的模型能够模拟雪天条件对LiDAR性能的影响，并为提升自动驾驶系统的鲁棒性提供了数据支持。

Abstract: Because 3D structure of a roadway environment can be characterized directly
by a Light Detection and Ranging (LiDAR) sensors, they can be used to obtain
exceptional situational awareness for assitive and autonomous driving systems.
Although LiDARs demonstrate good performance in clean and clear weather
conditions, their performance significantly deteriorates in adverse weather
conditions such as those involving atmospheric precipitation. This may render
perception capabilities of autonomous systems that use LiDAR data in learning
based models to perform object detection and ranging ineffective. While efforts
have been made to enhance the accuracy of these models, the extent of signal
degradation under various weather conditions remains largely not quantified. In
this study, we focus on the performance of an automotive grade LiDAR in snowy
conditions in order to develop a physics-based model that examines failure
modes of a LiDAR sensor. Specifically, we investigated how the LiDAR signal
attenuates with different snowfall rates and how snow particles near the source
serve as small but efficient reflectors. Utilizing our model, we transform data
from clear conditions to simulate snowy scenarios, enabling a comparison of our
synthetic data with actual snowy conditions. Furthermore, we employ this
synthetic data, representative of different snowfall rates, to explore the
impact on a pre-trained object detection model, assessing its performance under
varying levels of snowfall

</details>


### [102] [Benchmarking Egocentric Multimodal Goal Inference for Assistive Wearable Agents](https://arxiv.org/abs/2510.22443)
*Vijay Veerabadran,Fanyi Xiao,Nitin Kamra,Pedro Matias,Joy Chen,Caley Drooff,Brett D Roads,Riley Williams,Ethan Henderson,Xuanyi Zhao,Kevin Carlberg,Joseph Tighe,Karl Ridgeway*

Main category: cs.CV

TL;DR: 研究提出了WAGIBench基准来评估和改进穿戴式智能体在多模态情境下推断用户目标的能力。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是解决穿戴式智能体在没有明确指令的情况下，如何通过观察用户行为和环境信息来理解用户目标的问题，以提升用户体验。

Method: 研究者收集了一个包含29小时多模态数据（视觉、听觉、数字和纵向上下文）的新数据集，并创建了WAGIBench基准，使用户能够评估和改进视觉-语言模型（VLMs）在目标推断任务上的表现。实验评估了几类现代VLMs，并进行了模态消融实验。

Result: 在WAGIBench基准上，人类达到了93%的准确率，而表现最好的VLM为84%。评估结果显示，更大的模型在目标推断任务上表现更好，但生成相关目标的准确率仅为55%，距离实际应用仍有差距。模态消融实验表明，模型能从相关模态中获益，而无关模态对性能影响很小。

Conclusion: WAGIBench为评估和推动目标推断技术的发展提供了一个重要的基准。虽然现有模型在目标推断方面取得了显著进展，但仍需进一步改进才能达到实用水平。研究强调了多模态信息对于提升模型性能的重要性。

Abstract: There has been a surge of interest in assistive wearable agents: agents
embodied in wearable form factors (e.g., smart glasses) who take assistive
actions toward a user's goal/query (e.g. "Where did I leave my keys?"). In this
work, we consider the important complementary problem of inferring that goal
from multi-modal contextual observations. Solving this "goal inference" problem
holds the promise of eliminating the effort needed to interact with such an
agent. This work focuses on creating WAGIBench, a strong benchmark to measure
progress in solving this problem using vision-language models (VLMs). Given the
limited prior work in this area, we collected a novel dataset comprising 29
hours of multimodal data from 348 participants across 3,477 recordings,
featuring ground-truth goals alongside accompanying visual, audio, digital, and
longitudinal contextual observations. We validate that human performance
exceeds model performance, achieving 93% multiple-choice accuracy compared with
84% for the best-performing VLM. Generative benchmark results that evaluate
several families of modern vision-language models show that larger models
perform significantly better on the task, yet remain far from practical
usefulness, as they produce relevant goals only 55% of the time. Through a
modality ablation, we show that models benefit from extra information in
relevant modalities with minimal performance degradation from irrelevant
modalities.

</details>


### [103] [SemiETPicker: Fast and Label-Efficient Particle Picking for CryoET Tomography Using Semi-Supervised Learning](https://arxiv.org/abs/2510.22454)
*Linhan Wang,Jianwen Dou,Wang Li,Shengkun Wang,Zhiwu Xie,Chang-Tien Lu,Yinlin Chen*

Main category: cs.CV

TL;DR: 一种快速、标签高效的半监督框架，用于在细胞内利用未标记的冷冻断层扫描电镜数据解决蛋白质结构问题，通过多视图伪标签和 CryoET 特定 DropBlock 增强，在 CZII 数据集上实现了 10% 的 F1 改进。


<details>
  <summary>Details</summary>
Motivation: 冷冻断层扫描电镜 (CryoET) 结合亚体平均 (SVA) 是在分子分辨率下解析细胞内蛋白质结构的唯一成像方式。然而，粒子挑选（在 3D CryoET 体积中定位和分类目标蛋白质）仍然是主要瓶颈，因为其依赖耗时的手动标签，导致大量的未标记断层扫描数据未被充分利用。

Method: 提出了一种快速、标签高效的半监督框架，包括：(i) 受关键点检测启发的端到端热图监督检测模型；(ii) 增强稀疏标记条件下性能的师生协同训练机制。此外，还引入了多视图伪标签和 CryoET 特定的 DropBlock 增强策略。

Result: 在大型 CZII 数据集上的广泛评估表明，该方法比监督基线提高了 10% 的 F1 分数。

Conclusion: 该半监督学习方法在利用未标记的 CryoET 数据方面显示出巨大潜力。

Abstract: Cryogenic Electron Tomography (CryoET) combined with sub-volume averaging
(SVA) is the only imaging modality capable of resolving protein structures
inside cells at molecular resolution. Particle picking, the task of localizing
and classifying target proteins in 3D CryoET volumes, remains the main
bottleneck. Due to the reliance on time-consuming manual labels, the vast
reserve of unlabeled tomograms remains underutilized. In this work, we present
a fast, label-efficient semi-supervised framework that exploits this untapped
data. Our framework consists of two components: (i) an end-to-end
heatmap-supervised detection model inspired by keypoint detection, and (ii) a
teacher-student co-training mechanism that enhances performance under sparse
labeling conditions. Furthermore, we introduce multi-view pseudo-labeling and a
CryoET-specific DropBlock augmentation strategy to further boost performance.
Extensive evaluations on the large-scale CZII dataset show that our approach
improves F1 by 10% over supervised baselines, underscoring the promise of
semi-supervised learning for leveraging unlabeled CryoET data.

</details>


### [104] [DynaPose4D: High-Quality 4D Dynamic Content Generation via Pose Alignment Loss](https://arxiv.org/abs/2510.22473)
*Jing Yang,Yufeng Yang*

Main category: cs.CV

TL;DR: 该研究提出了DynaPose4D，一个结合4D高斯溅射和类别无关姿势估计的技术，用于从单张静态图像生成高质量的4D动态内容，解决了传统方法在时序依赖和动态几何变化建模上的局限性，尤其是在考虑相机视角变化时。


<details>
  <summary>Details</summary>
Motivation: 从单张静态图像生成高质量的4D动态内容是一个重大挑战，传统方法在建模时序依赖和动态几何变化方面存在局限，尤其是在视角变化的情况下。

Method: 提出DynaPose4D框架，结合4D高斯溅射（4DGS）和类别无关姿势估计（CAPE）技术。该框架使用3D高斯溅射从单张图像构建3D模型，然后基于单视角支持预测多视角姿势关键点，并利用监督信号增强运动一致性。

Result: 实验结果表明，DynaPose4D在动态运动生成方面实现了出色的连贯性、一致性和流畅性。

Conclusion: DynaPose4D框架的有效性得到了验证，并显示出其在计算机视觉和动画制作领域的应用潜力。

Abstract: Recent advancements in 2D and 3D generative models have expanded the
capabilities of computer vision. However, generating high-quality 4D dynamic
content from a single static image remains a significant challenge. Traditional
methods have limitations in modeling temporal dependencies and accurately
capturing dynamic geometry changes, especially when considering variations in
camera perspective. To address this issue, we propose DynaPose4D, an innovative
solution that integrates 4D Gaussian Splatting (4DGS) techniques with
Category-Agnostic Pose Estimation (CAPE) technology. This framework uses 3D
Gaussian Splatting to construct a 3D model from single images, then predicts
multi-view pose keypoints based on one-shot support from a chosen view,
leveraging supervisory signals to enhance motion consistency. Experimental
results show that DynaPose4D achieves excellent coherence, consistency, and
fluidity in dynamic motion generation. These findings not only validate the
efficacy of the DynaPose4D framework but also indicate its potential
applications in the domains of computer vision and animation production.

</details>


### [105] [Single-Teacher View Augmentation: Boosting Knowledge Distillation via Angular Diversity](https://arxiv.org/abs/2510.22480)
*Seonghoon Yu,Dongjun Nam,Dina Katabi,Jeany Son*

Main category: cs.CV

TL;DR: 本论文提出一种通过单教师多分支生成多视图知识蒸馏的方法，并通过角度多样性损失函数提升模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 为了在知识蒸馏中实现多教师视角以提升性能，同时避免多教师网络带来的高计算成本。

Method: 提出一种新颖的、具有成本效益的知识增强方法，通过为单个教师附加多个分支来生成多视图。引入两个角度多样性目标：1）约束性交角多样性损失，用于最大化增强视图之间的角度，同时保持与原始教师输出的接近性；2）内角多样性损失，用于鼓励视图围绕原始输出均匀分布。将来自这些角度多样化视图以及原始教师的集合知识蒸馏到学生模型中。

Result: 实验结果表明，该方法在多种配置下均优于现有的知识增强方法，并且可以即插即用地兼容其他知识蒸馏框架，持续提升泛化性能。

Conclusion: 所提出的方法能够通过单教师多分支有效生成多视图，并通过角度多样性损失函数实现更有效的知识蒸馏，提升模型泛化能力。

Abstract: Knowledge Distillation (KD) aims to train a lightweight student model by
transferring knowledge from a large, high-capacity teacher. Recent studies have
shown that leveraging diverse teacher perspectives can significantly improve
distillation performance; however, achieving such diversity typically requires
multiple teacher networks, leading to high computational costs. In this work,
we propose a novel cost-efficient knowledge augmentation method for KD that
generates diverse multi-views by attaching multiple branches to a single
teacher. To ensure meaningful semantic variation across multi-views, we
introduce two angular diversity objectives: 1) constrained inter-angle
diversify loss, which maximizes angles between augmented views while preserving
proximity to the original teacher output, and 2) intra-angle diversify loss,
which encourages an even distribution of views around the original output. The
ensembled knowledge from these angularly diverse views, along with the original
teacher, is distilled into the student. We further theoretically demonstrate
that our objectives increase the diversity among ensemble members and thereby
reduce the upper bound of the ensemble's expected loss, leading to more
effective distillation. Experimental results show that our method surpasses an
existing knowledge augmentation method across diverse configurations. Moreover,
the proposed method is compatible with other KD frameworks in a plug-and-play
fashion, providing consistent improvements in generalization performance.

</details>


### [106] [GateFuseNet: An Adaptive 3D Multimodal Neuroimaging Fusion Network for Parkinson's Disease Diagnosis](https://arxiv.org/abs/2510.22507)
*Rui Jin,Chen Chen,Yin Liu,Hongfu Sun,Min Zeng,Min Li,Yang Gao*

Main category: cs.CV

TL;DR: GateFuseNet是一个3D多模态融合网络，结合了定量磁化率图（QSM）和T1加权成像（T1w）来诊断帕金森病（PD），通过门控融合模块选择性地调节特征，提高了诊断准确性（85.00%）和AUC（92.06%），优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统的基于幅度T1w的MRI在诊断帕金森病方面存在挑战，因为症状变异性和病理异质性，而基于相位的MRI技术（如QSM）对铁沉积更敏感。

Method: 提出了一种名为GateFuseNet的自适应3D多模态融合网络，该网络包含一个门控融合模块，用于学习模态特定的注意力权重和通道级门控向量，以进行选择性特征调节，从而增强感兴趣区域（ROI）的特征并抑制无关信号。

Result: GateFuseNet在PD诊断方面取得了85.00%的准确率和92.06%的AUC，优于三种现有的最先进方法。消融研究证实了ROI引导、多模态集成和融合位置的有效性。Grad-CAM可视化确认了模型关注临床相关的病理区域。

Conclusion: GateFuseNet通过有效融合QSM和T1w图像，并利用门控融合机制，能够准确诊断帕金森病，并且其关注的区域与临床病理区域一致。

Abstract: Accurate diagnosis of Parkinson's disease (PD) from MRI remains challenging
due to symptom variability and pathological heterogeneity. Most existing
methods rely on conventional magnitude-based MRI modalities, such as
T1-weighted images (T1w), which are less sensitive to PD pathology than
Quantitative Susceptibility Mapping (QSM), a phase-based MRI technique that
quantifies iron deposition in deep gray matter nuclei. In this study, we
propose GateFuseNet, an adaptive 3D multimodal fusion network that integrates
QSM and T1w images for PD diagnosis. The core innovation lies in a gated fusion
module that learns modality-specific attention weights and channel-wise gating
vectors for selective feature modulation. This hierarchical gating mechanism
enhances ROI-aware features while suppressing irrelevant signals. Experimental
results show that our method outperforms three existing state-of-the-art
approaches, achieving 85.00% accuracy and 92.06% AUC. Ablation studies further
validate the contributions of ROI guidance, multimodal integration, and fusion
positioning. Grad-CAM visualizations confirm the model's focus on clinically
relevant pathological regions. The source codes and pretrained models can be
found at https://github.com/YangGaoUQ/GateFuseNet

</details>


### [107] [Open Multimodal Retrieval-Augmented Factual Image Generation](https://arxiv.org/abs/2510.22521)
*Yang Tian,Fan Liu,Jingyuan Zhang,Wei Bi,Yupeng Hu,Liqiang Nie*

Main category: cs.CV

TL;DR: 大型多模态模型（LMM）在生成逼真且与提示一致的图像方面取得了显著进展，但它们常常会产生与可验证知识相矛盾的输出，尤其是在提示涉及细粒度属性或时间敏感事件时。传统的检索增强方法试图通过引入外部信息来解决此问题，但由于依赖静态源和浅层证据集成，它们根本无法将生成与准确且不断发展的知识联系起来。为了弥合这一差距，我们引入了 ORIG，这是一个用于事实图像生成（FIG）的代理开放多模态检索增强框架。FIG 是一项新任务，需要视觉真实性和事实基础。ORIG 迭代地从网络检索和过滤多模态证据，并将精炼的知识逐步集成到丰富提示中以指导生成。为了支持系统评估，我们构建了 FIG-Eval，一个涵盖感知、构成和时间维度的十个类别的基准。实验表明，与强大的基线相比，ORIG 显著提高了事实一致性和整体图像质量，凸显了开放多模态检索在事实图像生成方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 大型多模态模型（LMM）在图像生成方面表现出色，但常常生成与事实不符的图像，尤其是在处理细粒度属性或时间敏感事件时。现有的检索增强方法因依赖静态源和浅层证据集成，无法将生成与准确且不断发展的知识联系起来。

Method: 引入 ORIG，一个代理开放多模态检索增强框架，用于事实图像生成（FIG）。ORIG 迭代地从网络检索和过滤多模态证据，并将精炼的知识逐步集成到丰富提示中以指导生成。

Result: ORIG 显著提高了事实一致性和整体图像质量，优于现有基线。我们还构建了一个名为 FIG-Eval 的基准，用于评估 FIG 任务。

Conclusion: 开放多模态检索在事实图像生成方面具有巨大潜力，可以提高图像的事实一致性和整体质量。

Abstract: Large Multimodal Models (LMMs) have achieved remarkable progress in
generating photorealistic and prompt-aligned images, but they often produce
outputs that contradict verifiable knowledge, especially when prompts involve
fine-grained attributes or time-sensitive events. Conventional
retrieval-augmented approaches attempt to address this issue by introducing
external information, yet they are fundamentally incapable of grounding
generation in accurate and evolving knowledge due to their reliance on static
sources and shallow evidence integration. To bridge this gap, we introduce
ORIG, an agentic open multimodal retrieval-augmented framework for Factual
Image Generation (FIG), a new task that requires both visual realism and
factual grounding. ORIG iteratively retrieves and filters multimodal evidence
from the web and incrementally integrates the refined knowledge into enriched
prompts to guide generation. To support systematic evaluation, we build
FIG-Eval, a benchmark spanning ten categories across perceptual, compositional,
and temporal dimensions. Experiments demonstrate that ORIG substantially
improves factual consistency and overall image quality over strong baselines,
highlighting the potential of open multimodal retrieval for factual image
generation.

</details>


### [108] [AesCrop: Aesthetic-driven Cropping Guided by Composition](https://arxiv.org/abs/2510.22528)
*Yen-Hong Wong,Lai-Kuan Wong*

Main category: cs.CV

TL;DR: AesCrop是一个结合了VMamba图像编码器、新颖的Mamba Composition Attention Bias (MCAB)和Transformer解码器的组合感知混合图像裁剪模型，通过端到端排序生成多个裁剪图及其质量分数，在实验中表现优于现有最先进的方法。


<details>
  <summary>Details</summary>
Motivation: 需要生成具有视觉吸引力的图像裁剪，例如用于推荐和缩略图生成，而构图是视觉吸引力的关键因素。现有方法存在局限性，混合方法虽然有所改进，但忽略了摄影构图指导。

Method: 提出AesCrop模型，该模型是一个组合感知的混合图像裁剪模型。它集成了VMamba图像编码器、新颖的Mamba Composition Attention Bias (MCAB)以及Transformer解码器，用于端到端的基于排序的图像裁剪，能够生成多个裁剪图及其相应的质量分数。MCAB通过将组合线索显式编码到注意力机制中，引导模型关注最具组合显著性的区域。

Result: AesCrop在定量指标上优于现有最先进的方法，并且在定性上生成了更具吸引力的裁剪图。

Conclusion: AesCrop通过显式地将组合线索集成到注意力机制中，成功地实现了组合感知的混合图像裁剪，并在实验中取得了优于现有方法的性能。

Abstract: Aesthetic-driven image cropping is crucial for applications like view
recommendation and thumbnail generation, where visual appeal significantly
impacts user engagement. A key factor in visual appeal is composition--the
deliberate arrangement of elements within an image. Some methods have
successfully incorporated compositional knowledge through evaluation-based and
regression-based paradigms. However, evaluation-based methods lack globality
while regression-based methods lack diversity. Recently, hybrid approaches that
integrate both paradigms have emerged, bridging the gap between these two to
achieve better diversity and globality. Notably, existing hybrid methods do not
incorporate photographic composition guidance, a key attribute that defines
photographic aesthetics. In this work, we introduce AesCrop, a
composition-aware hybrid image-cropping model that integrates a VMamba image
encoder, augmented with a novel Mamba Composition Attention Bias (MCAB) and a
transformer decoder to perform end-to-end rank-based image cropping, generating
multiple crops along with the corresponding quality scores. By explicitly
encoding compositional cues into the attention mechanism, MCAB directs AesCrop
to focus on the most compositionally salient regions. Extensive experiments
demonstrate that AesCrop outperforms current state-of-the-art methods,
delivering superior quantitative metrics and qualitatively more pleasing crops.

</details>


### [109] [SRSR: Enhancing Semantic Accuracy in Real-World Image Super-Resolution with Spatially Re-Focused Text-Conditioning](https://arxiv.org/abs/2510.22534)
*Chen Chen,Majid Abdolshah,Violetta Shevchenko,Hongdong Li,Chang Xu,Pulak Purkait*

Main category: cs.CV

TL;DR: 现有的基于扩散的超分辨率方法由于文本条件的准确性和完整性不足，以及交叉注意易偏离不相关像素的倾向，常常表现出语义模糊。本文提出了一种新的即插即用空间重聚焦超分辨率（SRSR）框架，包含两个核心组件：1）空间重聚焦交叉注意力（SRCA），通过应用视觉基础分割掩码来指导交叉注意力，从而在推理时优化文本条件；2）空间目标分类器无引导（STCFG）机制，选择性地绕过文本对未加固像素的影响，以防止产生幻觉。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散的超分辨率方法在文本条件和交叉注意力方面存在不足，导致语义不匹配和细节幻觉。

Method: 提出空间重聚焦超分辨率（SRSR）框架，包括空间重聚焦交叉注意力（SRCA）和空间目标分类器无引导（STCFG）机制。

Result: SRSR在标准保真度指标（PSNR和SSIM）和感知质量指标（LPIPS和DISTS）上均优于七种最先进的基线方法。

Conclusion: SRSR在实现高语义保真度和感知质量方面是有效的。

Abstract: Existing diffusion-based super-resolution approaches often exhibit semantic
ambiguities due to inaccuracies and incompleteness in their text conditioning,
coupled with the inherent tendency for cross-attention to divert towards
irrelevant pixels. These limitations can lead to semantic misalignment and
hallucinated details in the generated high-resolution outputs. To address
these, we propose a novel, plug-and-play spatially re-focused super-resolution
(SRSR) framework that consists of two core components: first, we introduce
Spatially Re-focused Cross-Attention (SRCA), which refines text conditioning at
inference time by applying visually-grounded segmentation masks to guide
cross-attention. Second, we introduce a Spatially Targeted Classifier-Free
Guidance (STCFG) mechanism that selectively bypasses text influences on
ungrounded pixels to prevent hallucinations. Extensive experiments on both
synthetic and real-world datasets demonstrate that SRSR consistently
outperforms seven state-of-the-art baselines in standard fidelity metrics (PSNR
and SSIM) across all datasets, and in perceptual quality measures (LPIPS and
DISTS) on two real-world benchmarks, underscoring its effectiveness in
achieving both high semantic fidelity and perceptual quality in
super-resolution.

</details>


### [110] [STATUS Bench: A Rigorous Benchmark for Evaluating Object State Understanding in Vision-Language Models](https://arxiv.org/abs/2510.22571)
*Mahiro Ukai,Shuhei Kurita,Nakamasa Inoue*

Main category: cs.CV

TL;DR: 该研究提出了一个名为STATUS Bench的基准测试，用于评估视觉-语言模型（VLMs）在识别物体状态（如开关、开闭）方面的能力。该基准包含三个任务：物体状态识别（OSI）、图像检索（IR）和状态变化识别（SCI），并提供了一个手工制作的数据集。此外，研究还发布了一个包含1300万个描述的训练数据集STATUS Train，以促进该领域的研究。实验表明，现有先进的VLMs在区分细微物体状态方面仍有很大困难，大多数开源模型在零样本测试下表现接近随机猜测。通过在STATUS Train上进行微调，Qwen2.5-VL模型的性能可与Gemini 2.0 Flash媲美。


<details>
  <summary>Details</summary>
Motivation: 评估现有视觉-语言模型（VLMs）在识别细微物体状态变化方面的精确度，并为该领域的研究提供基准和训练资源。

Method: 提出名为STATUS Bench的基准测试，包含物体状态识别（OSI）、图像检索（IR）和状态变化识别（SCI）三个任务，并构建了一个手工制作的数据集。同时，发布了一个包含1300万个描述的大规模半自动创建的训练数据集STATUS Train。

Result: 现有先进的VLMs在细微物体状态识别方面表现不佳，大多数开源模型在零样本测试下的表现接近随机水平。经过在STATUS Train数据集上微调后，Qwen2.5-VL模型的性能达到了与Gemini 2.0 Flash相当的水平。

Conclusion: STATUS Bench和STATUS Train对于推动VLMs在物体状态识别能力方面的发展至关重要。

Abstract: Object state recognition aims to identify the specific condition of objects,
such as their positional states (e.g., open or closed) and functional states
(e.g., on or off). While recent Vision-Language Models (VLMs) are capable of
performing a variety of multimodal tasks, it remains unclear how precisely they
can identify object states. To alleviate this issue, we introduce the STAte and
Transition UnderStanding Benchmark (STATUS Bench), the first benchmark for
rigorously evaluating the ability of VLMs to understand subtle variations in
object states in diverse situations. Specifically, STATUS Bench introduces a
novel evaluation scheme that requires VLMs to perform three tasks
simultaneously: object state identification (OSI), image retrieval (IR), and
state change identification (SCI). These tasks are defined over our fully
hand-crafted dataset involving image pairs, their corresponding object state
descriptions and state change descriptions. Furthermore, we introduce a
large-scale training dataset, namely STATUS Train, which consists of 13 million
semi-automatically created descriptions. This dataset serves as the largest
resource to facilitate further research in this area. In our experiments, we
demonstrate that STATUS Bench enables rigorous consistency evaluation and
reveal that current state-of-the-art VLMs still significantly struggle to
capture subtle object state distinctions. Surprisingly, under the proposed
rigorous evaluation scheme, most open-weight VLMs exhibited chance-level
zero-shot performance. After fine-tuning on STATUS Train, Qwen2.5-VL achieved
performance comparable to Gemini 2.0 Flash. These findings underscore the
necessity of STATUS Bench and Train for advancing object state recognition in
VLM research.

</details>


### [111] [MELDAE: A Framework for Micro-Expression Spotting, Detection, and Automatic Evaluation in In-the-Wild Conversational Scenes](https://arxiv.org/abs/2510.22575)
*Yigui Feng,Qinglin Wang,Yang Liu,Ke Liu,Haotian Mo,Enhao Huang,Gencheng Liu,Mingzhe Liu,Jie Liu*

Main category: cs.CV

TL;DR: 提出首个对话场景微表情数据集、端到端检测框架MELDAE及边界感知损失函数，提升了微表情分析的准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有微表情分析研究多依赖实验室数据，在真实对话等场景下表现不佳。

Method: 提出首个对话场景微表情数据集、端到端检测框架MELDAE及边界感知损失函数。

Result: 在WDMD数据集上，F1_{DR}指标提升17.72%，并在现有基准测试中展现出良好的泛化能力。

Conclusion: 所提出的方法在真实对话场景下显著提高了微表情分析的准确性。

Abstract: Accurately analyzing spontaneous, unconscious micro-expressions is crucial
for revealing true human emotions, but this task remains challenging in wild
scenarios, such as natural conversation. Existing research largely relies on
datasets from controlled laboratory environments, and their performance
degrades dramatically in the real world. To address this issue, we propose
three contributions: the first micro-expression dataset focused on
conversational-in-the-wild scenarios; an end-to-end localization and detection
framework, MELDAE; and a novel boundary-aware loss function that improves
temporal accuracy by penalizing onset and offset errors. Extensive experiments
demonstrate that our framework achieves state-of-the-art results on the WDMD
dataset, improving the key F1_{DR} localization metric by 17.72% over the
strongest baseline, while also demonstrating excellent generalization
capabilities on existing benchmarks.

</details>


### [112] [From Pixels to Views: Learning Angular-Aware and Physics-Consistent Representations for Light Field Microscopy](https://arxiv.org/abs/2510.22577)
*Feng He,Guodong Tan,Qiankun Li,Jun Yu,Quan Wen*

Main category: cs.CV

TL;DR: 该论文提出了一个用于光场显微镜（LFM）的3D重建方法，解决了大规模神经成像中的数据集缺失和模型效率问题。


<details>
  <summary>Details</summary>
Motivation: 神经科学领域需要大规模、高时间分辨率的体视成像技术，光场显微镜（LFM）具备这些潜力，但其基于学习的3D重建方法因缺乏标准化数据集和有效建模其角度-空间结构而受到限制。

Method: 提出了XLFM-Zebrafish基准（包含大规模数据集和评估套件）、掩码视角建模（MVN-LF）自监督任务（通过预测遮挡视角来学习角度先验）以及光学渲染一致性损失（ORC Loss）（强制预测体数据与基于PSF的正向投影对齐）。

Result: 在XLFM-Zebrafish基准上，所提出的方法比现有最优基线提高了7.7%的PSNR。

Conclusion: 所提出的方法通过构建基准数据集、引入自监督学习任务和物理约束，有效解决了LFM 3D重建的挑战，并在重建精度上取得了显著提升。

Abstract: Light field microscopy (LFM) has become an emerging tool in neuroscience for
large-scale neural imaging in vivo, notable for its single-exposure volumetric
imaging, broad field of view, and high temporal resolution. However,
learning-based 3D reconstruction in XLFM remains underdeveloped due to two core
challenges: the absence of standardized datasets and the lack of methods that
can efficiently model its angular-spatial structure while remaining physically
grounded. We address these challenges by introducing three key contributions.
First, we construct the XLFM-Zebrafish benchmark, a large-scale dataset and
evaluation suite for XLFM reconstruction. Second, we propose Masked View
Modeling for Light Fields (MVN-LF), a self-supervised task that learns angular
priors by predicting occluded views, improving data efficiency. Third, we
formulate the Optical Rendering Consistency Loss (ORC Loss), a differentiable
rendering constraint that enforces alignment between predicted volumes and
their PSF-based forward projections. On the XLFM-Zebrafish benchmark, our
method improves PSNR by 7.7% over state-of-the-art baselines.

</details>


### [113] [Cross-View UAV Geo-Localization with Precision-Focused Efficient Design: A Hierarchical Distillation Approach with Multi-view Refinement](https://arxiv.org/abs/2510.22582)
*Jian Sun,Kangdao Liu,Chi Zhang,Chuangquan Chen,Junge Shen,Chi-Man Vong*

Main category: cs.CV

TL;DR: PFED框架通过分层知识转移和多视图表示细化，实现了高效且精确的跨视图地理定位（CVGL），适用于无人机在GNSS受限环境下的自主导航。


<details>
  <summary>Details</summary>
Motivation: 现有CVGL方法依赖资源密集型的细粒度特征提取和对齐，导致推理成本高，难以在边缘设备上部署。

Method: PFED框架包含两个主要部分：1) 训练时，采用HD-CVGL（分层蒸馏范式）和UAPA（不确定性感知预测对齐）来提取关键信息并处理数据不平衡。2) 推理时，MRM（多视图细化模块）利用互信息过滤冗余样本并优化多视图数据。

Result: PFED在University-1652数据集上达到了97.15%的Recall@1，在计算量（FLOPs）和速度上分别比以往SOTA方法提高了5倍和3倍。在AGX Orin边缘设备上，PFED的运行速度达到251.5 FPS。

Conclusion: PFED在精度和效率上均达到SOTA水平，证明了其在实时无人机应用中的实用性。

Abstract: Cross-view geo-localization (CVGL) enables UAV localization by matching
aerial images to geo-tagged satellite databases, which is critical for
autonomous navigation in GNSS-denied environments. However, existing methods
rely on resource-intensive fine-grained feature extraction and alignment, where
multiple branches and modules significantly increase inference costs, limiting
their deployment on edge devices. We propose Precision-Focused Efficient Design
(PFED), a resource-efficient framework combining hierarchical knowledge
transfer and multi-view representation refinement. This innovative method
comprises two key components: 1) During training, Hierarchical Distillation
paradigm for fast and accurate CVGL (HD-CVGL), coupled with Uncertainty-Aware
Prediction Alignment (UAPA) to distill essential information and mitigate the
data imbalance without incurring additional inference overhead. 2) During
inference, an efficient Multi-view Refinement Module (MRM) leverages mutual
information to filter redundant samples and effectively utilize the multi-view
data. Extensive experiments show that PFED achieves state-of-the-art
performance in both accuracy and efficiency, reaching 97.15\% Recall@1 on
University-1652 while being over $5 \times$ more efficient in FLOPs and $3
\times$ faster than previous top methods. Furthermore, PFED runs at 251.5 FPS
on the AGX Orin edge device, demonstrating its practical viability for
real-time UAV applications. The project is available at
https://github.com/SkyEyeLoc/PFED

</details>


### [114] [PSScreen V2: Partially Supervised Multiple Retinal Disease Screening](https://arxiv.org/abs/2510.22589)
*Boyi Zheng,Yalin Zheng,Hrvoje Bogunović,Qing Liu*

Main category: cs.CV

TL;DR: PSScreen V2是一个部分监督的自训练框架，用于多重视网膜疾病筛查，能够处理标签缺失和域偏移问题，并在多个视网膜数据集上达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 以往的方法依赖于全标签或单领域数据集，而PSScreen V2旨在从多个部分标签且分布不同的数据集中学习，以解决标签缺失和域偏移的挑战。

Method: PSScreen V2采用三分支架构，包含一个教师网络和两个学生网络。教师分支从弱增强图像生成伪标签，解决标签缺失问题。两个学生网络引入了低频信息丢弃（LF-Dropout）和低频不确定性（LF-Uncert）的特征增强策略，以提高域鲁棒性和处理不确定的域变异性。

Result: 在多个域内和域外眼底数据集上的广泛实验表明，PSScreen V2 在性能和域泛化能力上均优于现有方法，达到了最先进水平。

Conclusion: PSScreen V2 框架具有普遍性和适应性，不仅在多个视网膜疾病筛查任务中表现出色，而且兼容不同的骨干网络（包括 DINOv2），甚至在胸部X光数据集上也显示出潜力。

Abstract: In this work, we propose PSScreen V2, a partially supervised self-training
framework for multiple retinal disease screening. Unlike previous methods that
rely on fully labelled or single-domain datasets, PSScreen V2 is designed to
learn from multiple partially labelled datasets with different distributions,
addressing both label absence and domain shift challenges. To this end,
PSScreen V2 adopts a three-branch architecture with one teacher and two student
networks. The teacher branch generates pseudo labels from weakly augmented
images to address missing labels, while the two student branches introduce
novel feature augmentation strategies: Low-Frequency Dropout (LF-Dropout),
which enhances domain robustness by randomly discarding domain-related
low-frequency components, and Low-Frequency Uncertainty (LF-Uncert), which
estimates uncertain domain variability via adversarially learned Gaussian
perturbations of low-frequency statistics. Extensive experiments on multiple
in-domain and out-of-domain fundus datasets demonstrate that PSScreen V2
achieves state-of-the-art performance and superior domain generalization
ability. Furthermore, compatibility tests with diverse backbones, including the
vision foundation model DINOv2, as well as evaluations on chest X-ray datasets,
highlight the universality and adaptability of the proposed framework. The
codes are available at https://github.com/boyiZheng99/PSScreen_V2.

</details>


### [115] [Projection Embedded Diffusion Bridge for CT Reconstruction from Incomplete Data](https://arxiv.org/abs/2510.22605)
*Yuang Wang,Pengfei Jin,Siyeop Yoon,Matthew Tivnan,Shaoyang Zhang,Li Zhang,Quanzheng Li,Zhiqiang Chen,Dufan Wu*

Main category: cs.CV

TL;DR: 提出一种名为PEDB的新型CT图像重建模型，通过在扩散模型中融入投影数据一致性，以解决不完整投影数据重建的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有扩散桥模型在从FBP重建中恢复图像时表现出潜力，但未能充分探索数据一致性的整合，而数据一致性对于提高重建保真度和细节恢复至关重要。

Method: 提出PEDB模型，利用新颖的反向随机微分方程（SDE）从受FBP重建和不完整投影数据约束的清洁图像分布中采样。通过将投影数据嵌入到反向SDE的评分函数中，自然地实现了数据一致性。推导了后验评分的可行表达式，并引入一个自由参数来控制反向过程的随机性水平，同时设计了一个离散化方案来减少离散化误差。

Result: 在稀疏视图、有限角度和截断投影等三种不完整数据类型的CT重建实验中，PEDB均取得了优于当前最先进的扩散桥模型的效果，并在标准、噪声和域偏移评估中均表现出色。

Conclusion: PEDB在不完整投影数据CT重建方面取得了显著的性能提升，优于现有方法，证明了在扩散模型中整合投影数据一致性的有效性。

Abstract: Reconstructing CT images from incomplete projection data remains challenging
due to the ill-posed nature of the problem. Diffusion bridge models have
recently shown promise in restoring clean images from their corresponding
Filtered Back Projection (FBP) reconstructions, but incorporating data
consistency into these models remains largely underexplored. Incorporating data
consistency can improve reconstruction fidelity by aligning the reconstructed
image with the observed projection data, and can enhance detail recovery by
integrating structural information contained in the projections. In this work,
we propose the Projection Embedded Diffusion Bridge (PEDB). PEDB introduces a
novel reverse stochastic differential equation (SDE) to sample from the
distribution of clean images conditioned on both the FBP reconstruction and the
incomplete projection data. By explicitly conditioning on the projection data
in sampling the clean images, PEDB naturally incorporates data consistency. We
embed the projection data into the score function of the reverse SDE. Under
certain assumptions, we derive a tractable expression for the posterior score.
In addition, we introduce a free parameter to control the level of
stochasticity in the reverse process. We also design a discretization scheme
for the reverse SDE to mitigate discretization error. Extensive experiments
demonstrate that PEDB achieves strong performance in CT reconstruction from
three types of incomplete data, including sparse-view, limited-angle, and
truncated projections. For each of these types, PEDB outperforms evaluated
state-of-the-art diffusion bridge models across standard, noisy, and
domain-shift evaluations.

</details>


### [116] [SWAN: Self-supervised Wavelet Neural Network for Hyperspectral Image Unmixing](https://arxiv.org/abs/2510.22607)
*Yassh Ramchandani,Vijayashekhar S S,Jignesh S. Bhatt*

Main category: cs.CV

TL;DR: SWAN是一个用于高光谱图像端元和丰度联合估计的三阶段自监督小波神经网络。


<details>
  <summary>Details</summary>
Motivation: 从高光谱图像中联合估计端元和丰度的需求。

Method: SWAN采用三阶段方法：SWANencoder将小波系数映射到低维潜在空间，SWANdecoder从潜在表示重建小波系数，SWANforward学习底层物理。通过三阶段联合损失函数进行自监督训练，无需真实标签。

Result: 在合成和真实高光谱数据集上的实验表明，SWAN在定性、定量和消融研究中均优于最先进的基于神经网络的解混方法，实现了鲁棒的解混函数。

Conclusion: SWAN通过自监督学习和紧凑的网络参数，为高光谱图像的端元和丰度联合估计提供了一种有效的解决方案。

Abstract: In this article, we present SWAN: a three-stage, self-supervised wavelet
neural network for joint estimation of endmembers and abundances from
hyperspectral imagery. The contiguous and overlapping hyperspectral band images
are first expanded to Biorthogonal wavelet basis space that provides sparse,
distributed, and multi-scale representations. The idea is to exploit latent
symmetries from thus obtained invariant and covariant features using a
self-supervised learning paradigm. The first stage, SWANencoder maps the input
wavelet coefficients to a compact lower-dimensional latent space. The second
stage, SWANdecoder uses the derived latent representation to reconstruct the
input wavelet coefficients. Interestingly, the third stage SWANforward learns
the underlying physics of the hyperspectral image. A three-stage combined loss
function is formulated in the image acquisition domain that eliminates the need
for ground truth and enables self-supervised training. Adam is employed for
optimizing the proposed loss function, while Sigmoid with a dropout of 0.3 is
incorporated to avoid possible overfitting. Kernel regularizers bound the
magnitudes and preserve spatial variations in the estimated endmember
coefficients. The output of SWANencoder represents estimated abundance maps
during inference, while weights of SWANdecoder are retrieved to extract
endmembers. Experiments are conducted on two benchmark synthetic data sets with
different signal-to-noise ratios as well as on three real benchmark
hyperspectral data sets while comparing the results with several
state-of-the-art neural network-based unmixing methods. The qualitative,
quantitative, and ablation results show performance enhancement by learning a
resilient unmixing function as well as promoting self-supervision and compact
network parameters for practical applications.

</details>


### [117] [Cross-Species Transfer Learning in Agricultural AI: Evaluating ZebraPose Adaptation for Dairy Cattle Pose Estimation](https://arxiv.org/abs/2510.22618)
*Mackenzie Tapp,Sibi Chakravarthy Parivendan,Kashfia Sailunaz,Suresh Neethirajan*

Main category: cs.CV

TL;DR: 本研究评估了跨物种迁移学习在牛姿态估计中的潜力，发现尽管在训练数据上表现良好，但在新环境中泛化能力不足，强调了真实农场环境数据集和跨环境鲁棒性的重要性。


<details>
  <summary>Details</summary>
Motivation: 农业应用中，尤其是在牛的姿态估计方面，由于缺乏大规模、标注好的数据集，面临严峻挑战。本研究旨在评估将为斑马设计的姿态估计模型（ZebraPose）迁移应用于奶牛的可行性。

Method: 使用三种配置（单独的农场数据集、APT-36K数据集子集、以及两者的组合）来评估基于Transformer的ZebraPose模型在奶牛27关键点检测上的准确性和泛化能力。

Result: 结合模型在训练数据上取得了良好的结果（AP=0.86, AR=0.87, PCK@0.5=0.869），但在应用于未见过的数据集时，泛化能力出现显著下降，表明合成数据到真实世界的域迁移存在巨大障碍。

Conclusion: 形态上的相似性不足以实现跨物种的有效迁移学习，农业AI的部署面临合成到真实域的巨大挑战。研究强调了数据集多样性、环境变化和计算限制对实际部署的影响。研究呼吁采用“农业优先”的设计理念，重视农场级别的真实性、跨环境的鲁棒性以及开放的基准数据集，以推动值得信赖且可扩展的动物中心技术的发展。

Abstract: Pose estimation serves as a cornerstone of computer vision for understanding
animal posture, behavior, and welfare. Yet, agricultural applications remain
constrained by the scarcity of large, annotated datasets for livestock,
especially dairy cattle. This study evaluates the potential and limitations of
cross-species transfer learning by adapting ZebraPose - a vision
transformer-based model trained on synthetic zebra imagery - for 27-keypoint
detection in dairy cows under real barn conditions. Using three configurations
- a custom on-farm dataset (375 images, Sussex, New Brunswick, Canada), a
subset of the APT-36K benchmark dataset, and their combination, we
systematically assessed model accuracy and generalization across environments.
While the combined model achieved promising performance (AP = 0.86, AR = 0.87,
PCK 0.5 = 0.869) on in-distribution data, substantial generalization failures
occurred when applied to unseen barns and cow populations. These findings
expose the synthetic-to-real domain gap as a major obstacle to agricultural AI
deployment and emphasize that morphological similarity between species is
insufficient for cross-domain transfer. The study provides practical insights
into dataset diversity, environmental variability, and computational
constraints that influence real-world deployment of livestock monitoring
systems. We conclude with a call for agriculture-first AI design, prioritizing
farm-level realism, cross-environment robustness, and open benchmark datasets
to advance trustworthy and scalable animal-centric technologies.

</details>


### [118] [Robust Atypical Mitosis Classification with DenseNet121: Stain-Aware Augmentation and Hybrid Loss for Domain Generalization](https://arxiv.org/abs/2510.22630)
*Adinath Dukre,Ankan Deria,Yutong Xie,Imran Razzak*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Atypical mitotic figures are important biomarkers of tumor aggressiveness in
histopathology, yet reliable recognition remains challenging due to severe
class imbalance and variability across imaging domains. We present a
DenseNet-121-based framework tailored for atypical mitosis classification in
the MIDOG 2025 (Track 2) setting. Our method integrates stain-aware
augmentation (Macenko), geometric and intensity transformations, and
imbalance-aware learning via weighted sampling with a hybrid objective
combining class-weighted binary cross-entropy and focal loss. Trained
end-to-end with AdamW and evaluated across multiple independent domains, the
model demonstrates strong generalization under scanner and staining shifts,
achieving balanced accuracy 85.0%, AUROC 0.927, sensitivity 89.2%, and
specificity 80.9% on the official test set. These results indicate that
combining DenseNet-121 with stain-aware augmentation and imbalance-adaptive
objectives yields a robust, domain-generalizable framework for atypical mitosis
classification suitable for real-world computational pathology workflows.

</details>


### [119] [A Critical Study on Tea Leaf Disease Detection using Deep Learning Techniques](https://arxiv.org/abs/2510.22647)
*Nabajyoti Borah,Raju Moni Borah,Bandan Boruah,Purnendu Bikash Acharjee,Sajal Saha,Ripjyoti Hazarika*

Main category: cs.CV

TL;DR: 该研究提出了一种深度学习技术，能够识别茶树叶片上的三种病害（红锈病、Helopeltis 病和红蜘蛛螨病），并标示出病变区域。研究评估了 SSD MobileNet V2 和 Faster R-CNN ResNet50 V1 两种目标检测模型，其中 Faster R-CNN ResNet50 V1 的 mAP（25%）优于 SSD MobileNet V2（20.9%）。此外，还利用 Mask R-CNN 进行了实例分割，并自定义方法计算了病变区域的比例。


<details>
  <summary>Details</summary>
Motivation: 为了识别茶树叶片上的三种主要病害（红锈病、Helopeltis 病和红蜘蛛螨病），并量化病变区域，以提供一种自动化的解决方案。

Method: 使用深度学习技术，具体包括 SSD MobileNet V2 和 Faster R-CNN ResNet50 V1 进行目标检测，以识别病害及其位置。同时，使用 Mask R-CNN 进行实例分割，并开发自定义方法来计算叶片上受病害影响的面积比例。

Result: Faster R-CNN ResNet50 V1 模型在 IOU 范围 0.50:0.95 下，精度为 0.252，召回率为 0.044，mAP 为 25%。SSD MobileNet V2 模型在相同 IOU 范围下，精度为 0.209，召回率为 0.02，mAP 为 20.9%。Faster R-CNN ResNet50 V1 的表现优于 SSD MobileNet V2。

Conclusion: Faster R-CNN ResNet50 V1 在茶树叶片病害识别任务上表现更优。结合 Mask R-CNN 的实例分割能力，可以有效识别病害并量化受影响的叶片区域。所提出的深度学习方法为茶树病害的自动化检测和管理提供了有效途径。

Abstract: The proposed solution is Deep Learning Technique that will be able classify
three types of tea leaves diseases from which two diseases are caused by the
pests and one due to pathogens (infectious organisms) and environmental
conditions and also show the area damaged by a disease in leaves. Namely Red
Rust, Helopeltis and Red spider mite respectively. In this paper we have
evaluated two models namely SSD MobileNet V2 and Faster R-CNN ResNet50 V1 for
the object detection. The SSD MobileNet V2 gave precision of 0.209 for IOU
range of 0.50:0.95 with recall of 0.02 on IOU 0.50:0.95 and final mAP of 20.9%.
While Faster R-CNN ResNet50 V1 has precision of 0.252 on IOU range of 0.50:0.95
and recall of 0.044 on IOU of 0.50:0.95 with a mAP of 25%, which is better than
SSD. Also used Mask R-CNN for Object Instance Segmentation where we have
implemented our custom method to calculate the damaged diseased portion of
leaves. Keywords: Tea Leaf Disease, Deep Learning, Red Rust, Helopeltis and Red
Spider Mite, SSD MobileNet V2, Faster R-CNN ResNet50 V1 and Mask RCNN.

</details>


### [120] [Self-Attention Decomposition For Training Free Diffusion Editing](https://arxiv.org/abs/2510.22650)
*Tharun Anand,Mohammad Hassan Vali,Arno Solin*

Main category: cs.CV

TL;DR: 通过分析预训练扩散模型的自注意力权重矩阵的特征向量，提出一种无需额外数据或微调即可获得可编辑语义方向的方法，实现高效的图像编辑。


<details>
  <summary>Details</summary>
Motivation: 目前的扩散模型在生成图像方面表现出色，但在实现对生成图像的精确控制以进行目标编辑方面仍存在挑战。为了提高可控性，一个关键步骤是在模型的潜在表示中找到与语义属性相对应的可解释的方向。然而，现有的寻找可解释方向的方法通常依赖于采样大量图像或训练辅助网络，这限制了效率。

Method: 提出一种分析方法，直接从预训练的扩散模型参数中推导出语义编辑方向，无需额外数据或微调。该方法的核心思想是，自注意力权重矩阵编码了模型在训练过程中学习到的数据分布的丰富结构信息。通过计算这些权重矩阵的特征向量，可以获得鲁棒且可解释的编辑方向。

Result: 实验结果表明，该方法在多个数据集上实现了高质量的编辑，并且与现有基准相比，编辑时间显著减少了 60%。

Conclusion: 所提出的分析方法能够有效地从预训练的扩散模型中提取语义编辑方向，从而实现高效且高质量的图像编辑，克服了现有方法的局限性。

Abstract: Diffusion models achieve remarkable fidelity in image synthesis, yet precise
control over their outputs for targeted editing remains challenging. A key step
toward controllability is to identify interpretable directions in the model's
latent representations that correspond to semantic attributes. Existing
approaches for finding interpretable directions typically rely on sampling
large sets of images or training auxiliary networks, which limits efficiency.
We propose an analytical method that derives semantic editing directions
directly from the pretrained parameters of diffusion models, requiring neither
additional data nor fine-tuning. Our insight is that self-attention weight
matrices encode rich structural information about the data distribution learned
during training. By computing the eigenvectors of these weight matrices, we
obtain robust and interpretable editing directions. Experiments demonstrate
that our method produces high-quality edits across multiple datasets while
reducing editing time significantly by 60% over current benchmarks.

</details>


### [121] [SARCLIP: A Vision Language Foundation Model for Semantic Understanding and Target Recognition in SAR Imagery](https://arxiv.org/abs/2510.22665)
*Qiwei Ma,Zhiyu Wang,Wang Liu,Xukun Lu,Bin Deng,Puhong Duan,Xudong Kang,Shutao Li*

Main category: cs.CV

TL;DR: 该论文构建了SARCLIP-1M数据集和SARCLIP模型，利用对比学习方法提升SAR图像的语义理解能力，并在图像-文本检索和零样本分类任务上取得了优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有的SAR基础模型主要关注低级视觉特征，忽略了多模态对齐和零样本识别能力。为了解决这个问题，本研究旨在构建一个大规模的SAR-文本数据集，并训练一个能够连接SAR图像和文本描述的视觉语言基础模型。

Method: 1. 构建了一个包含超过一百万文本-图像对的SARCLIP-1M数据集。 2. 引入了SARCLIP模型，一个专门为SAR领域设计的视觉语言基础模型。 3. 采用领域迁移策略，利用对比视觉语言学习方法训练SARCLIP模型，以实现SAR图像和文本描述的对齐。

Result: SARCLIP模型在图像-文本检索和零样本分类任务上表现优于现有的最先进的基础模型，显著提高了SAR图像的特征提取和解释能力。

Conclusion: SARCLIP模型有效地弥补了SAR图像和文本描述之间的差距，提升了SAR图像的语义理解能力，为SAR图像的分析和应用开辟了新的可能性。

Abstract: Synthetic Aperture Radar (SAR) has emerged as a crucial imaging modality due
to its all-weather capabilities. While recent advancements in self-supervised
learning and Masked Image Modeling (MIM) have paved the way for SAR foundation
models, these approaches primarily focus on low-level visual features, often
overlooking multimodal alignment and zero-shot target recognition within SAR
imagery. To address this limitation, we construct SARCLIP-1M, a large-scale
vision language dataset comprising over one million text-image pairs aggregated
from existing datasets. We further introduce SARCLIP, the first vision language
foundation model tailored for the SAR domain. Our SARCLIP model is trained
using a contrastive vision language learning approach by domain transferring
strategy, enabling it to bridge the gap between SAR imagery and textual
descriptions. Extensive experiments on image-text retrieval and zero-shot
classification tasks demonstrate the superior performance of SARCLIP in feature
extraction and interpretation, significantly outperforming state-of-the-art
foundation models and advancing the semantic understanding of SAR imagery. The
code and datasets will be released soon.

</details>


### [122] [LVD-GS: Gaussian Splatting SLAM for Dynamic Scenes via Hierarchical Explicit-Implicit Representation Collaboration Rendering](https://arxiv.org/abs/2510.22669)
*Wenkai Zhu,Xu Li,Qimin Xu,Benwu Wang,Kun Wei,Yiming Peng,Zihang Wang*

Main category: cs.CV

TL;DR: LVD-GS通过引入分层协作表示和联合动态建模来改进3D高斯泼溅SLAM，解决了大规模动态场景中的尺度模糊和累积姿态误差问题，并在多个数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯泼溅SLAM方法依赖单一表示，在大规模动态户外场景中表现不佳，并存在累积姿态误差和尺度模糊问题。

Method: 提出LVD-GS系统，引入分层协作表示模块以优化映射并减轻尺度漂移，以及联合动态建模模块，通过融合开放世界分割、隐式残差约束和DINO-Depth特征的不确定性估计来生成动态掩码。

Result: 在KITTI、nuScenes和自收集数据集上的广泛评估表明，LVD-GS在性能上优于现有方法，实现了最先进的成果。

Conclusion: LVD-GS通过其新颖的表示和动态建模方法，有效解决了现有3D高斯泼溅SLAM的局限性，在大规模动态场景中提供了鲁棒且高保真的映射能力。

Abstract: 3D Gaussian Splatting SLAM has emerged as a widely used technique for
high-fidelity mapping in spatial intelligence. However, existing methods often
rely on a single representation scheme, which limits their performance in
large-scale dynamic outdoor scenes and leads to cumulative pose errors and
scale ambiguity. To address these challenges, we propose \textbf{LVD-GS}, a
novel LiDAR-Visual 3D Gaussian Splatting SLAM system. Motivated by the human
chain-of-thought process for information seeking, we introduce a hierarchical
collaborative representation module that facilitates mutual reinforcement for
mapping optimization, effectively mitigating scale drift and enhancing
reconstruction robustness. Furthermore, to effectively eliminate the influence
of dynamic objects, we propose a joint dynamic modeling module that generates
fine-grained dynamic masks by fusing open-world segmentation with implicit
residual constraints, guided by uncertainty estimates from DINO-Depth features.
Extensive evaluations on KITTI, nuScenes, and self-collected datasets
demonstrate that our approach achieves state-of-the-art performance compared to
existing methods.

</details>


### [123] [Alias-Free ViT: Fractional Shift Invariance via Linear Attention](https://arxiv.org/abs/2510.22673)
*Hagay Michaeli,Daniel Soudry*

Main category: cs.CV

TL;DR: Vision Transformers (ViTs) 相比于卷积神经网络（CNNs）缺乏归纳偏置，对图像平移更敏感。本文提出了 Alias-Free ViT，通过引入无别名（alias-free）的下采样和非线性层，并结合线性交叉协方差注意力机制，实现了对整数和分数平移的移位等变性，从而获得移位不变的全局表示。


<details>
  <summary>Details</summary>
Motivation: Transformer在视觉任务中虽有竞争力，但缺乏CNN的归纳偏置，可能限制其性能。ViT在平移不变性和对图像微小平移的敏感度方面不如CNN。虽然CNN也不是完全移位不变的，但已有方法提高了CNN的平移鲁棒性。本文旨在借鉴这些方法，提升ViT的平移鲁棒性。

Method: 本文提出了Alias-Free ViT，包含两个主要部分：1. 使用无别名（alias-free）的下采样和非线性层。2. 使用线性交叉协方差注意力机制，该机制对整数和分数平移都具有移位等变性，从而实现移位不变的全局表示。

Result: Alias-Free ViT在图像分类任务上保持了有竞争力的性能，并且在对抗性平移鲁棒性方面优于同等规模的模型。

Conclusion: Alias-Free ViT通过引入无别名下采样、非线性层以及线性交叉协方差注意力机制，提高了ViT在图像分类任务上的性能和对平移的鲁棒性。

Abstract: Transformers have emerged as a competitive alternative to convnets in vision
tasks, yet they lack the architectural inductive bias of convnets, which may
hinder their potential performance. Specifically, Vision Transformers (ViTs)
are not translation-invariant and are more sensitive to minor image
translations than standard convnets. Previous studies have shown, however, that
convnets are also not perfectly shift-invariant, due to aliasing in
downsampling and nonlinear layers. Consequently, anti-aliasing approaches have
been proposed to certify convnets' translation robustness. Building on this
line of work, we propose an Alias-Free ViT, which combines two main components.
First, it uses alias-free downsampling and nonlinearities. Second, it uses
linear cross-covariance attention that is shift-equivariant to both integer and
fractional translations, enabling a shift-invariant global representation. Our
model maintains competitive performance in image classification and outperforms
similar-sized models in terms of robustness to adversarial translations.

</details>


### [124] [DAMap: Distance-aware MapNet for High Quality HD Map Construction](https://arxiv.org/abs/2510.22675)
*Jinpeng Dong,Chen Li,Yutong Lin,Jingwen Fu,Sanping Zhou,Nanning Zheng*

Main category: cs.CV

TL;DR: 现有HD地图构建方法因任务不匹配导致预测质量不高，本文提出DAMap方法解决此问题，通过DAFL、HLS和TMDA组件提升了预测精度。


<details>
  <summary>Details</summary>
Motivation: 现有HD地图构建方法在预测质量上表现不佳，主要是由于任务不匹配，具体表现在不合适的任务标签（一对多匹配查询共享相同标签）和次优的任务特征（任务共享采样机制）。

Method: 提出了一种名为DAMap的新型HD地图构建方法，包含三个组件：距离感知焦点损失（DAFL），用于为一对多匹配样本分配合适的分类标签；混合损失方案（HLS），用于更好地利用DAFL的优势；任务调制可变形注意力（TMDA），用于获取具有区分度的特定任务特征。

Result: 在NuScenes和Argoverse2基准测试中，在不同指标、基线、分割、骨干网络和调度下，DAMap始终取得了性能提升。

Conclusion: DAMap通过解决一对多匹配标签不当和任务共享采样机制次优的问题，显著提高了HD地图元素的预测质量。

Abstract: Predicting High-definition (HD) map elements with high quality (high
classification and localization scores) is crucial to the safety of autonomous
driving vehicles. However, current methods perform poorly in high quality
predictions due to inherent task misalignment. Two main factors are responsible
for misalignment: 1) inappropriate task labels due to one-to-many matching
queries sharing the same labels, and 2) sub-optimal task features due to
task-shared sampling mechanism. In this paper, we reveal two inherent defects
in current methods and develop a novel HD map construction method named DAMap
to address these problems. Specifically, DAMap consists of three components:
Distance-aware Focal Loss (DAFL), Hybrid Loss Scheme (HLS), and Task Modulated
Deformable Attention (TMDA). The DAFL is introduced to assign appropriate
classification labels for one-to-many matching samples. The TMDA is proposed to
obtain discriminative task-specific features. Furthermore, the HLS is proposed
to better utilize the advantages of the DAFL. We perform extensive experiments
and consistently achieve performance improvement on the NuScenes and Argoverse2
benchmarks under different metrics, baselines, splits, backbones, and
schedules. Code will be available at https://github.com/jpdong-xjtu/DAMap.

</details>


### [125] [Estimation of Fireproof Structure Class and Construction Year for Disaster Risk Assessment](https://arxiv.org/abs/2510.22683)
*Hibiki Ayabe,Kazushi Okamoto,Koki Karube,Atsushi Shibata,Kei Harada*

Main category: cs.CV

TL;DR: 使用建筑外观图像进行多任务学习，以预测建筑年份、结构和类型，进而推断结构防火等级，应用于日本的风险评估和保险定价。


<details>
  <summary>Details</summary>
Motivation: 日本的结构防火等级分类对灾害风险评估和保险定价至关重要，但建筑元数据（如建造年份和结构类型）常缺失或过时，尤其是在二手房市场。

Method: 提出一个多任务学习模型，联合预测建造年份、建筑结构和物业类型，并通过基于规则的映射推断结构防火等级（H：非防火，T：半防火，M：防火）。

Result: 使用大规模日本住宅图像数据集训练和评估模型，模型在建造年份回归和不平衡类别的分类方面表现出高准确性和稳健性，并能捕捉与建筑年代和材料相关的视觉线索。

Conclusion: 该方法证明了可扩展、可解释的、基于图像的风险分析系统的可行性，可应用于保险、城市规划和灾害准备。

Abstract: Structural fireproof classification is vital for disaster risk assessment and
insurance pricing in Japan. However, key building metadata such as construction
year and structure type are often missing or outdated, particularly in the
second-hand housing market. This study proposes a multi-task learning model
that predicts these attributes from facade images. The model jointly estimates
the construction year, building structure, and property type, from which the
structural fireproof class - defined as H (non-fireproof), T (semi-fireproof),
or M (fireproof) - is derived via a rule-based mapping based on official
insurance criteria. We trained and evaluated the model using a large-scale
dataset of Japanese residential images, applying rigorous filtering and
deduplication. The model achieved high accuracy in construction-year regression
and robust classification across imbalanced categories. Qualitative analyses
show that it captures visual cues related to building age and materials. Our
approach demonstrates the feasibility of scalable, interpretable, image-based
risk-profiling systems, offering potential applications in insurance, urban
planning, and disaster preparedness.

</details>


### [126] [RoboSVG: A Unified Framework for Interactive SVG Generation with Multi-modal Guidance](https://arxiv.org/abs/2510.22684)
*Jiuniu Wang,Gongjie Zhang,Quanhao Qian,Junlong Gao,Deli Zhao,Ran Xu*

Main category: cs.CV

TL;DR: RoboSVG是一个统一的多模态框架，可以根据文本、图像和数值信号生成交互式SVG，并引入了RoboDraw数据集来支持这项工作。


<details>
  <summary>Details</summary>
Motivation: 可扩展矢量图形（SVG）在数字设计和机器人控制中至关重要，但现有方法在处理文本、图像和数值信号的统一生成方面存在不足。

Method: RoboSVG框架首先生成多模态引导，然后通过专门的生成模块合成候选SVG，最后在数值引导下进行优化。该框架还引入了一个包含一百万个示例的大型数据集RoboDraw，以支持文本到SVG、图像到SVG、部分SVG到SVG和部分图像到SVG等任务。

Result: RoboSVG在查询相关性和视觉保真度方面表现优于现有方法，在多功能SVG生成方面树立了新的标杆。

Conclusion: RoboSVG是一个统一的多模态框架，可以根据文本、图像和数值信号生成交互式SVG，并在各种任务中取得了最先进的性能。

Abstract: Scalable Vector Graphics (SVGs) are fundamental to digital design and robot
control, encoding not only visual structure but also motion paths in
interactive drawings. In this work, we introduce RoboSVG, a unified multimodal
framework for generating interactive SVGs guided by textual, visual, and
numerical signals. Given an input query, the RoboSVG model first produces
multimodal guidance, then synthesizes candidate SVGs through dedicated
generation modules, and finally refines them under numerical guidance to yield
high-quality outputs. To support this framework, we construct RoboDraw, a
large-scale dataset of one million examples, each pairing an SVG generation
condition (e.g., text, image, and partial SVG) with its corresponding
ground-truth SVG code. RoboDraw dataset enables systematic study of four tasks,
including basic generation (Text-to-SVG, Image-to-SVG) and interactive
generation (PartialSVG-to-SVG, PartialImage-to-SVG). Extensive experiments
demonstrate that RoboSVG achieves superior query compliance and visual fidelity
across tasks, establishing a new state of the art in versatile SVG generation.
The dataset and source code of this project will be publicly available soon.

</details>


### [127] [VADTree: Explainable Training-Free Video Anomaly Detection via Hierarchical Granularity-Aware Tree](https://arxiv.org/abs/2510.22693)
*Wenlong Li,Yifei Xu,Yuan Rao,Zhenhua Wang,Shuiguang Deng*

Main category: cs.CV

TL;DR: VADTree是一种新颖的视频异常检测方法，它利用分层粒度感知树（HGTree）结构进行灵活采样，结合预训练的GEBD模型和视觉语言模型（VLMs），实现了先进的无监督异常检测性能，并显著减少了采样片段数量。


<details>
  <summary>Details</summary>
Motivation: 现有视频异常检测（VAD）方法存在监督方法需要大量标注数据且解释性差，以及无监督方法在捕捉不同时间跨度的异常时存在困难的问题。因此，需要一种能够灵活采样并有效检测异常的方法。

Method: VADTree提出了一种分层粒度感知树（HGTree）结构，利用预训练的通用事件边界检测（GEBD）模型来识别潜在的异常事件边界。该方法将视频分解为事件节点，构建HGTree，并通过视觉语言模型（VLMs）进行节点异常感知，利用大型语言模型（LLMs）进行异常推理，最后通过节点相关性方法整合多粒度异常分数。

Result: 在三个具有挑战性的数据集上进行的大量实验表明，VADTree在无监督设置下取得了最先进的性能，并显著减少了采样视频片段的数量。

Conclusion: VADTree通过其创新的HGTree结构和多模型融合方法，成功解决了现有视频异常检测方法的局限性，在提高检测精度的同时，降低了计算复杂度，达到了最先进的无监督检测效果。

Abstract: Video anomaly detection (VAD) focuses on identifying anomalies in videos.
Supervised methods demand substantial in-domain training data and fail to
deliver clear explanations for anomalies. In contrast, training-free methods
leverage the knowledge reserves and language interactivity of large pre-trained
models to detect anomalies. However, the current fixed-length temporal window
sampling approaches struggle to accurately capture anomalies with varying
temporal spans. Therefore, we propose VADTree that utilizes a Hierarchical
Granularityaware Tree (HGTree) structure for flexible sampling in VAD. VADTree
leverages the knowledge embedded in a pre-trained Generic Event Boundary
Detection (GEBD) model to characterize potential anomaly event boundaries.
Specifically, VADTree decomposes the video into generic event nodes based on
boundary confidence, and performs adaptive coarse-fine hierarchical structuring
and redundancy removal to construct the HGTree. Then, the multi-dimensional
priors are injected into the visual language models (VLMs) to enhance the
node-wise anomaly perception, and anomaly reasoning for generic event nodes is
achieved via large language models (LLMs). Finally, an inter-cluster node
correlation method is used to integrate the multi-granularity anomaly scores.
Extensive experiments on three challenging datasets demonstrate that VADTree
achieves state-of-the-art performance in training-free settings while
drastically reducing the number of sampled video segments. The code will be
available at https://github.com/wenlongli10/VADTree.

</details>


### [128] [Windsock is Dancing: Adaptive Multimodal Retrieval-Augmented Generation](https://arxiv.org/abs/2510.22694)
*Shu Zhao,Tianyi Shen,Nilesh Ahuja,Omesh Tickoo,Vijaykrishnan Narayanan*

Main category: cs.CV

TL;DR: MRAG方法通过引入外部知识库来增强多模态大语言模型（MLLMs）的事实性和时效性，但现有方法存在检索策略静态、模态选择不灵活以及检索信息利用不充分的问题。为解决这些挑战，本文提出了Windsock模块，该模块能够根据查询动态决定检索的必要性和模态选择，从而降低计算开销并提高响应质量。此外，还引入了动态抗噪声（DANCE）指令调优策略，以提高MLLMs利用检索信息的能力并抵抗噪声干扰。最后，采用自评估方法将问答数据集转化为MRAG训练数据集。实验结果表明，该方法显著提高了生成质量（17.07%），并减少了8.95%的检索时间。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态检索增强生成（MRAG）方法在检索策略、模态选择和信息利用方面存在不足，导致生成质量和效率有待提高。

Method: 提出了一种名为Windsock的查询依赖模块，用于动态决定检索的必要性和模态选择。同时，引入了动态抗噪声（DANCE）指令调优策略，以增强模型利用检索信息的能力并提高鲁棒性。此外，还采用自评估方法将问答数据集转换为MRAG训练数据集。

Result: 实验证明，所提出的方法将生成质量提高了17.07%，并将检索时间减少了8.95%。

Conclusion: 本文提出的Windsock模块和DANCE指令调优策略有效解决了现有MRAG方法的挑战，显著提高了多模态大语言模型的生成质量和效率。

Abstract: Multimodal Retrieval-Augmented Generation (MRAG) has emerged as a promising
method to generate factual and up-to-date responses of Multimodal Large
Language Models (MLLMs) by incorporating non-parametric knowledge from external
knowledge bases. However, existing MRAG approaches suffer from static retrieval
strategies, inflexible modality selection, and suboptimal utilization of
retrieved information, leading to three critical challenges: determining when
to retrieve, what modality to incorporate, and how to utilize retrieved
information effectively. To address these challenges, we introduce Windsock, a
query-dependent module making decisions on retrieval necessity and modality
selection, effectively reducing computational overhead and improving response
quality. Additionally, we propose Dynamic Noise-Resistance (DANCE) Instruction
Tuning, an adaptive training strategy that enhances MLLMs' ability to utilize
retrieved information while maintaining robustness against noise. Moreover, we
adopt a self-assessment approach leveraging knowledge within MLLMs to convert
question-answering datasets to MRAG training datasets. Extensive experiments
demonstrate that our proposed method significantly improves the generation
quality by 17.07% while reducing 8.95% retrieval times.

</details>


### [129] [WaveMAE: Wavelet decomposition Masked Auto-Encoder for Remote Sensing](https://arxiv.org/abs/2510.22697)
*Vittorio Bernuzzi,Leonardo Rossi,Tomaso Fontanini,Massimo Bertozzi,Andrea Prati*

Main category: cs.CV

TL;DR: WaveMAE是一个用于多光谱卫星图像的自监督学习框架，它利用多级离散小波变换（DWT）和地理条件位置编码（GPE）来学习具有地理空间意识的表示，并在各种下游任务中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 遥感领域标注数据稀缺，限制了全监督方法。需要一种有效的自监督学习方法来构建基础模型。

Method: WaveMAE框架，利用多级离散小波变换（DWT）解耦频率分量，实现感知尺度的高频表示学习；引入地理条件位置编码（GPE），通过球谐函数整合地理先验，促进语义和地理空间结构的一致性。

Result: WaveMAE在PANGAEA基准的语义分割、回归、变化检测和多标签分类等下游任务上，相比现有最先进的方法取得了持续的改进，在分割和回归任务上表现尤为突出。即使是参数量减少到26.4%的轻量级变体，也达到了最先进的性能。

Conclusion: WaveMAE是一个强大且具有地理空间意识的基础模型，适用于多光谱遥感图像，能够有效解决遥感领域数据稀缺的问题。

Abstract: Self-supervised learning (SSL) has recently emerged as a key strategy for
building foundation models in remote sensing, where the scarcity of annotated
data limits the applicability of fully supervised approaches. In this work, we
introduce WaveMAE, a masked autoencoding framework tailored for multispectral
satellite imagery. Unlike conventional pixel-based reconstruction, WaveMAE
leverages a multi-level Discrete Wavelet Transform (DWT) to disentangle
frequency components and guide the encoder toward learning scale-aware
high-frequency representations. We further propose a Geo-conditioned Positional
Encoding (GPE), which incorporates geographical priors via Spherical Harmonics,
encouraging embeddings that respect both semantic and geospatial structure. To
ensure fairness in evaluation, all methods are pretrained on the same dataset
(fMoW-S2) and systematically evaluated on the diverse downstream tasks of the
PANGAEA benchmark, spanning semantic segmentation, regression, change
detection, and multilabel classification. Extensive experiments demonstrate
that WaveMAE achieves consistent improvements over prior state-of-the-art
approaches, with substantial gains on segmentation and regression benchmarks.
The effectiveness of WaveMAE pretraining is further demonstrated by showing
that even a lightweight variant, containing only 26.4% of the parameters,
achieves state-of-the-art performance. Our results establish WaveMAE as a
strong and geographically informed foundation model for multispectral remote
sensing imagery.

</details>


### [130] [IGGT: Instance-Grounded Geometry Transformer for Semantic 3D Reconstruction](https://arxiv.org/abs/2510.22706)
*Hao Li,Zhengyu Zou,Fangfu Liu,Xuanyang Zhang,Fangzhou Hong,Yukang Cao,Yushi Lan,Manyuan Zhang,Gang Yu,Dingwen Zhang,Ziwei Liu*

Main category: cs.CV

TL;DR: 本研究提出了一种名为IGGT的大型统一Transformer模型，用于同时处理三维场景的几何重建和实例级上下文理解，以解决现有方法各自处理几何和语义信息导致泛化能力受限的问题。通过3D一致性对比学习策略，仅使用2D视觉输入就能编码几何结构和实例感知的统一表示，从而实现2D到3D场景的连贯提升。此外，研究者还构建了一个大规模数据集InsScene-15K来支持该任务。


<details>
  <summary>Details</summary>
Motivation: 现有三维场景分析方法在处理几何重建和空间理解时存在割裂，忽视了两者之间的相互作用，导致泛化能力受限和下游任务表现不佳。简单地将三维模型与特定语言模型对齐会限制感知能力和适应性。

Method: 提出了一种名为IGGT的大型统一Transformer模型，并设计了一种3D一致性对比学习策略，仅利用2D视觉输入来编码几何结构和实例感知的统一表示。该表示支持将2D视觉输入一致地提升为具有明确区分的对象实例的连贯3D场景。

Result: 通过所提出的IGGT模型和3D一致性对比学习策略，能够从2D视觉输入生成具有明确对象实例的连贯3D场景表示。

Conclusion: IGGT模型通过统一几何重建和实例级上下文理解，并利用3D一致性对比学习从2D输入生成统一表示，解决了现有方法的局限性，能够更有效地进行3D场景分析。同时，构建的InsScene-15K数据集为该任务提供了支持。

Abstract: Humans naturally perceive the geometric structure and semantic content of a
3D world as intertwined dimensions, enabling coherent and accurate
understanding of complex scenes. However, most prior approaches prioritize
training large geometry models for low-level 3D reconstruction and treat
high-level spatial understanding in isolation, overlooking the crucial
interplay between these two fundamental aspects of 3D-scene analysis, thereby
limiting generalization and leading to poor performance in downstream 3D
understanding tasks. Recent attempts have mitigated this issue by simply
aligning 3D models with specific language models, thus restricting perception
to the aligned model's capacity and limiting adaptability to downstream tasks.
In this paper, we propose InstanceGrounded Geometry Transformer (IGGT), an
end-to-end large unified transformer to unify the knowledge for both spatial
reconstruction and instance-level contextual understanding. Specifically, we
design a 3D-Consistent Contrastive Learning strategy that guides IGGT to encode
a unified representation with geometric structures and instance-grounded
clustering through only 2D visual inputs. This representation supports
consistent lifting of 2D visual inputs into a coherent 3D scene with explicitly
distinct object instances. To facilitate this task, we further construct
InsScene-15K, a large-scale dataset with high-quality RGB images, poses, depth
maps, and 3D-consistent instance-level mask annotations with a novel data
curation pipeline.

</details>


### [131] [LRW-Persian: Lip-reading in the Wild Dataset for Persian Language](https://arxiv.org/abs/2510.22716)
*Zahra Taghizadeh,Mohammad Shahverdikondori,Arian Noori,Alireza Dadgarnia*

Main category: cs.CV

TL;DR: 研究提出了LRW-Persian，一个大规模的波斯语唇语识别数据集，包含超过41.4万个视频片段，用于唇语识别研究。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语音识别资源，尤其是针对非英语的资源非常有限。本研究旨在通过创建一个大规模的波斯语唇语数据集来填补这一空白，以促进相关领域的研究和技术发展。

Method: 研究者们创建了一个名为LRW-Persian的数据集，其中包含743个目标单词和超过41.4万个视频片段，这些片段提取自67个电视节目，总时长超过1900小时。数据集的构建过程采用了一个全自动化的端到端处理流程，包括自动语音识别（ASR）转录、说话人定位、质量过滤以及头部姿态/遮挡筛选。此外，研究者还对两个常用的唇语识别模型在LRW-Persian数据集上进行了微调，以建立基准性能。

Result: LRW-Persian数据集的建立为波斯语视觉语音识别提供了一个大规模的、包含丰富元数据（如头部姿态、年龄、性别）的公开资源。通过在该数据集上对现有模型进行微调，研究者们初步评估了波斯语视觉语音识别的难度，并建立了一个性能基准。

Conclusion: LRW-Persian数据集的发布填补了低资源语言在唇语识别领域的关键空白，它不仅能够支持严格的基准测试，还可以促进跨语言迁移学习，并为在代表性不足的语言环境中推进多模态语音研究奠定基础。

Abstract: Lipreading has emerged as an increasingly important research area for
developing robust speech recognition systems and assistive technologies for the
hearing-impaired. However, non-English resources for visual speech recognition
remain limited. We introduce LRW-Persian, the largest in-the-wild Persian
word-level lipreading dataset, comprising $743$ target words and over
$414{,}000$ video samples extracted from more than $1{,}900$ hours of footage
across $67$ television programs. Designed as a benchmark-ready resource,
LRW-Persian provides speaker-disjoint training and test splits, wide regional
and dialectal coverage, and rich per-clip metadata including head pose, age,
and gender. To ensure large-scale data quality, we establish a fully automated
end-to-end curation pipeline encompassing transcription based on Automatic
Speech Recognition(ASR), active-speaker localization, quality filtering, and
pose/mask screening. We further fine-tune two widely used lipreading
architectures on LRW-Persian, establishing reference performance and
demonstrating the difficulty of Persian visual speech recognition. By filling a
critical gap in low-resource languages, LRW-Persian enables rigorous
benchmarking, supports cross-lingual transfer, and provides a foundation for
advancing multimodal speech research in underrepresented linguistic contexts.
The dataset is publicly available at: https://lrw-persian.vercel.app.

</details>


### [132] [Cross-view Localization and Synthesis -- Datasets, Challenges and Opportunities](https://arxiv.org/abs/2510.22736)
*Ningli Xu,Rongjun Qin*

Main category: cs.CV

TL;DR: 本文全面 survey 了 cross-view localization and synthesis 领域的最新进展，涵盖了数据集、挑战、技术以及未来方向。


<details>
  <summary>Details</summary>
Motivation: Cross-view localization and synthesis 在自主导航、城市规划和增强现实等领域有广泛应用，但由于视角、分辨率和遮挡的差异而面临挑战。

Method: Cross-view localization 通常被表述为图像检索问题，利用 CNNs 或 ViTs 提取特征进行匹配。Cross-view synthesis 则使用 GANs 或 diffusion models 生成图像。

Result: 文章对该领域的最新技术进行了综述，并提供了项目页面链接。

Conclusion: 文章总结了该领域的挑战、现有技术的局限性，并指出了未来研究方向。

Abstract: Cross-view localization and synthesis are two fundamental tasks in cross-view
visual understanding, which deals with cross-view datasets: overhead (satellite
or aerial) and ground-level imagery. These tasks have gained increasing
attention due to their broad applications in autonomous navigation, urban
planning, and augmented reality. Cross-view localization aims to estimate the
geographic position of ground-level images based on information provided by
overhead imagery while cross-view synthesis seeks to generate ground-level
images based on information from the overhead imagery. Both tasks remain
challenging due to significant differences in viewing perspective, resolution,
and occlusion, which are widely embedded in cross-view datasets. Recent years
have witnessed rapid progress driven by the availability of large-scale
datasets and novel approaches. Typically, cross-view localization is formulated
as an image retrieval problem where ground-level features are matched with
tiled overhead images feature, extracted by convolutional neural networks
(CNNs) or vision transformers (ViTs) for cross-view feature embedding.
Cross-view synthesis, on the other hand, seeks to generate ground-level views
based on information from overhead imagery, generally using generative
adversarial networks (GANs) or diffusion models. This paper presents a
comprehensive survey of advances in cross-view localization and synthesis,
reviewing widely used datasets, highlighting key challenges, and providing an
organized overview of state-of-the-art techniques. Furthermore, it discusses
current limitations, offers comparative analyses, and outlines promising
directions for future research. We also include the project page via
https://github.com/GDAOSU/Awesome-Cross-View-Methods.

</details>


### [133] [ConMatFormer: A Multi-attention and Transformer Integrated ConvNext based Deep Learning Model for Enhanced Diabetic Foot Ulcer Classification](https://arxiv.org/abs/2510.22743)
*Raihan Ahamed Rifat,Fuyad Hasan Bhoyan,Md Humaion Kabir Mehedi,Md Kaviul Hossain,Md. Jakir Hossen,M. F. Mridha*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Diabetic foot ulcer (DFU) detection is a clinically significant yet
challenging task due to the scarcity and variability of publicly available
datasets. To solve these problems, we propose ConMatFormer, a new hybrid deep
learning architecture that combines ConvNeXt blocks, multiple attention
mechanisms convolutional block attention module (CBAM) and dual attention
network (DANet), and transformer modules in a way that works together. This
design facilitates the extraction of better local features and understanding of
the global context, which allows us to model small skin patterns across
different types of DFU very accurately. To address the class imbalance, we used
data augmentation methods. A ConvNeXt block was used to obtain detailed local
features in the initial stages. Subsequently, we compiled the model by adding a
transformer module to enhance long-range dependency. This enabled us to
pinpoint the DFU classes that were underrepresented or constituted minorities.
Tests on the DS1 (DFUC2021) and DS2 (diabetic foot ulcer (DFU)) datasets showed
that ConMatFormer outperformed state-of-the-art (SOTA) convolutional neural
network (CNN) and Vision Transformer (ViT) models in terms of accuracy,
reliability, and flexibility. The proposed method achieved an accuracy of
0.8961 and a precision of 0.9160 in a single experiment, which is a significant
improvement over the current standards for classifying DFUs. In addition, by
4-fold cross-validation, the proposed model achieved an accuracy of 0.9755 with
a standard deviation of only 0.0031. We further applied explainable artificial
intelligence (XAI) methods, such as Grad-CAM, Grad-CAM++, and LIME, to
consistently monitor the transparency and trustworthiness of the
decision-making process.. Our findings set a new benchmark for DFU
classification and provide a hybrid attention transformer framework for medical
image analysis.

</details>


### [134] [Self-Calibrated Consistency can Fight Back for Adversarial Robustness in Vision-Language Models](https://arxiv.org/abs/2510.22785)
*Jiaxiang Liu,Jiawei Du,Xiao Liu,Prayag Tiwari,Mingkun Xu*

Main category: cs.CV

TL;DR: 现有的预训练视觉-语言模型（VLM）虽然具有强大的零样本能力，但容易受到对抗性攻击。现有的防御方法需要有标签数据，这在零样本场景下并不适用。本文提出了自校准一致性（SCC）作为一种即时防御方法，解决了当前CLIP攻击在语义和视角上的脆弱性问题。SCC包含语义一致性和空间一致性两个模块，旨在提高模型在对抗性攻击下的鲁棒性，同时保持其准确性，并且可以轻松地与其他VLM集成。


<details>
  <summary>Details</summary>
Motivation: 现有的预训练视觉-语言模型（VLM），如CLIP，虽然在零样本能力方面表现出色，但对对抗性扰动非常敏感，这会破坏图像-文本的对齐并影响其可靠性。然而，现有的防御方法通常依赖于有标签数据的对抗性微调，这限制了它们在零样本场景下的应用。

Method: 本文提出了一种名为自校准一致性（SCC）的即时防御方法。SCC包含两个互补的模块：1. 语义一致性：利用对抗性攻击的软伪标签和多视角预测来规范跨模态对齐，并将目标嵌入与混淆的负样本分开。2. 空间一致性：通过增强的视角来对齐受扰动的视觉预测，以在对抗性扰动下稳定推理。这两种模块结合起来形成了一种即插即用的推理策略。

Result: 在22个基准测试和多种攻击设置下的广泛实验表明，SCC在保持准确性的同时，能够持续提高CLIP的零样本鲁棒性，并且可以无缝集成到其他VLM中以获得进一步的性能提升。

Conclusion: SCC是一种有效的即时防御方法，通过解决语义和视角上的脆弱性，显著提高了CLIP等VLM在对抗性攻击下的鲁棒性，同时保持了准确性。这一方法为建立对抗性鲁棒的VLM范式提供了新的思路，并对更广泛的视觉-语言领域具有启示意义。

Abstract: Pre-trained vision-language models (VLMs) such as CLIP have demonstrated
strong zero-shot capabilities across diverse domains, yet remain highly
vulnerable to adversarial perturbations that disrupt image-text alignment and
compromise reliability. Existing defenses typically rely on adversarial
fine-tuning with labeled data, limiting their applicability in zero-shot
settings. In this work, we identify two key weaknesses of current CLIP
adversarial attacks -- lack of semantic guidance and vulnerability to view
variations -- collectively termed semantic and viewpoint fragility. To address
these challenges, we propose Self-Calibrated Consistency (SCC), an effective
test-time defense. SCC consists of two complementary modules: Semantic
consistency, which leverages soft pseudo-labels from counterattack warm-up and
multi-view predictions to regularize cross-modal alignment and separate the
target embedding from confusable negatives; and Spatial consistency, aligning
perturbed visual predictions via augmented views to stabilize inference under
adversarial perturbations. Together, these modules form a plug-and-play
inference strategy. Extensive experiments on 22 benchmarks under diverse attack
settings show that SCC consistently improves the zero-shot robustness of CLIP
while maintaining accuracy, and can be seamlessly integrated with other VLMs
for further gains. These findings highlight the great potential of establishing
an adversarially robust paradigm from CLIP, with implications extending to
broader vision-language domains such as BioMedCLIP.

</details>


### [135] [MedXplain-VQA: Multi-Component Explainable Medical Visual Question Answering](https://arxiv.org/abs/2510.22803)
*Hai-Dang Nguyen,Minh-Anh Dang,Minh-Tan Le,Minh-Tuan Le*

Main category: cs.CV

TL;DR: MedXplain-VQA是一个集成了五种可解释AI组件的医学视觉问答框架，通过微调BLIP-2、医学查询重述、增强Grad-CAM注意力、精确区域提取和结构化思维链推理，提供可解释的医学图像分析。在PathVQA数据集上，与基线方法相比，该系统在临床相关评估中取得了显著的改进（0.683 vs 0.378），同时保持了高推理置信度（0.890）。研究表明，MedXplain-VQA在医学VQA领域具有巨大潜力。


<details>
  <summary>Details</summary>
Motivation: 提高医学视觉问答（VQA）系统在临床应用中的可解释性，使医生能够信任AI生成的诊断。

Method: 框架集成了五种可解释AI组件：微调的BLIP-2骨干、医学查询重述、增强的Grad-CAM注意力、精确区域提取和通过多模态语言模型进行的结构化思维链推理。

Result: 在500个PathVQA样本上，MedXplain-VQA取得了0.683的综合得分，而基线方法为0.378，同时保持了0.890的推理置信度。系统能识别3-5个诊断相关区域，并生成平均57字的结构化解释。

Conclusion: MedXplain-VQA是一个强大的、可解释的医学VQA系统，在提高AI诊断的可信度和临床相关性方面显示出巨大潜力。

Abstract: Explainability is critical for the clinical adoption of medical visual
question answering (VQA) systems, as physicians require transparent reasoning
to trust AI-generated diagnoses. We present MedXplain-VQA, a comprehensive
framework integrating five explainable AI components to deliver interpretable
medical image analysis. The framework leverages a fine-tuned BLIP-2 backbone,
medical query reformulation, enhanced Grad-CAM attention, precise region
extraction, and structured chain-of-thought reasoning via multi-modal language
models. To evaluate the system, we introduce a medical-domain-specific
framework replacing traditional NLP metrics with clinically relevant
assessments, including terminology coverage, clinical structure quality, and
attention region relevance. Experiments on 500 PathVQA histopathology samples
demonstrate substantial improvements, with the enhanced system achieving a
composite score of 0.683 compared to 0.378 for baseline methods, while
maintaining high reasoning confidence (0.890). Our system identifies 3-5
diagnostically relevant regions per sample and generates structured
explanations averaging 57 words with appropriate clinical terminology. Ablation
studies reveal that query reformulation provides the most significant initial
improvement, while chain-of-thought reasoning enables systematic diagnostic
processes. These findings underscore the potential of MedXplain-VQA as a
robust, explainable medical VQA system. Future work will focus on validation
with medical experts and large-scale clinical datasets to ensure clinical
readiness.

</details>


### [136] [MAGIC-Talk: Motion-aware Audio-Driven Talking Face Generation with Customizable Identity Control](https://arxiv.org/abs/2510.22810)
*Fatemeh Nazarieh,Zhenhua Feng,Diptesh Kanojia,Muhammad Awais,Josef Kittler*

Main category: cs.CV

TL;DR: MAGIC-Talk是一个单镜头扩散模型，用于生成具有时间一致性、身份保持和可定制性的说话人脸视频，解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有音频驱动的说话人脸生成方法在时间一致性、身份保持和可定制性方面存在不足，尤其是在长视频生成方面。

Method: MAGIC-Talk包含ReferenceNet（用于身份保持和文本驱动的面部编辑）和AnimateNet（利用结构化运动先验增强运动连贯性），并采用渐进式潜在融合策略来提高长视频质量。

Result: 实验表明，MAGIC-Talk在视觉质量、身份保持和同步准确性方面优于现有最先进的方法。

Conclusion: MAGIC-Talk为说话人脸生成提供了一个鲁棒的解决方案，通过单一图像保持身份，并确保帧间的平滑过渡，同时提高长视频的质量。

Abstract: Audio-driven talking face generation has gained significant attention for
applications in digital media and virtual avatars. While recent methods improve
audio-lip synchronization, they often struggle with temporal consistency,
identity preservation, and customization, especially in long video generation.
To address these issues, we propose MAGIC-Talk, a one-shot diffusion-based
framework for customizable and temporally stable talking face generation.
MAGIC-Talk consists of ReferenceNet, which preserves identity and enables
fine-grained facial editing via text prompts, and AnimateNet, which enhances
motion coherence using structured motion priors. Unlike previous methods
requiring multiple reference images or fine-tuning, MAGIC-Talk maintains
identity from a single image while ensuring smooth transitions across frames.
Additionally, a progressive latent fusion strategy is introduced to improve
long-form video quality by reducing motion inconsistencies and flickering.
Extensive experiments demonstrate that MAGIC-Talk outperforms state-of-the-art
methods in visual quality, identity preservation, and synchronization accuracy,
offering a robust solution for talking face generation.

</details>


### [137] [FairJudge: MLLM Judging for Social Attributes and Prompt Image Alignment](https://arxiv.org/abs/2510.22827)
*Zahraa Al Sahili,Maryam Fetanat,Maimuna Nowaz,Ioannis Patras,Matthew Purver*

Main category: cs.CV

TL;DR: FairJudge是一个评估文本到图像模型公平性的协议，它使用大型语言模型作为裁判，并遵循一个有据可依、排除不确定性的评估标准。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像（T2I）评估方法缺乏可复现性，并且在评估图像与提示的匹配度以及模型对社会属性的处理方式上存在不足，例如它们倾向于关注表面线索，缺乏校准的弃权机制，并且忽略了那些不易察觉的属性（如宗教、文化、残疾）。

Method: FairJudge协议采用轻量级协议，将多模态大型语言模型（LLMs）作为公平的裁判。它使用一个面向解释的评分标准，将分数映射到[-1, 1]区间；将判断限制在封闭的标签集合内；要求判断必须基于可见内容；并且在线索不足时强制弃权。

Result: FairJudge协议在性别、种族和年龄等属性上，通过FairFace、PaTA和FairCoT数据集进行了评估；并扩展到宗教、文化和残疾等属性；同时在IdenProf、FairCoT-Professions和DIVERSIFY-Professions数据集上评估了职业正确性和对齐度。此外，还发布了一个包含469张多样化、非标志性场景图像的DIVERSIFY语料库。实验结果表明，使用大型语言模型作为裁判的模型，在人口统计学预测方面优于对比学习和以人脸为中心的基线模型，同时提高了平均对齐度，并保持了高职业准确率，从而实现了更可靠、可复现的公平性审计。

Conclusion: FairJudge协议提供了一种更可靠、可复现的评估T2I系统公平性的方法，通过利用LLMs作为裁判并结合一套严谨的评估标准，解决了现有评估方法的不足，并能更全面地评估各种社会属性和职业对齐度。

Abstract: Text-to-image (T2I) systems lack simple, reproducible ways to evaluate how
well images match prompts and how models treat social attributes. Common
proxies -- face classifiers and contrastive similarity -- reward surface cues,
lack calibrated abstention, and miss attributes only weakly visible (for
example, religion, culture, disability). We present FairJudge, a lightweight
protocol that treats instruction-following multimodal LLMs as fair judges. It
scores alignment with an explanation-oriented rubric mapped to [-1, 1];
constrains judgments to a closed label set; requires evidence grounded in the
visible content; and mandates abstention when cues are insufficient. Unlike
CLIP-only pipelines, FairJudge yields accountable, evidence-aware decisions;
unlike mitigation that alters generators, it targets evaluation fairness. We
evaluate gender, race, and age on FairFace, PaTA, and FairCoT; extend to
religion, culture, and disability; and assess profession correctness and
alignment on IdenProf, FairCoT-Professions, and our new DIVERSIFY-Professions.
We also release DIVERSIFY, a 469-image corpus of diverse, non-iconic scenes.
Across datasets, judge models outperform contrastive and face-centric baselines
on demographic prediction and improve mean alignment while maintaining high
profession accuracy, enabling more reliable, reproducible fairness audits.

</details>


### [138] [LLM-based Fusion of Multi-modal Features for Commercial Memorability Prediction](https://arxiv.org/abs/2510.22829)
*Aleksandar Pramov*

Main category: cs.CV

TL;DR: 本研究提出了一种基于LLM的视频可记忆性预测方法，并通过实验证明其优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决媒体评估2025竞赛“子任务2：广告/品牌可记忆性预测”中的商业广告可记忆性预测问题。

Method: 提出了一种多模态融合系统，使用Gemma-3 LLM作为骨干，结合预计算的视觉（ViT）和文本（E5）特征，并通过多模态投影进行整合。模型使用LoRA进行适应性调整。同时，构建了一个经过大量调优的梯度提升树集成模型作为基线。一个关键的贡献是使用了基于专家知识生成的LLM推理提示来指导融合模型。

Result: 基于LLM的系统在最终测试集上的表现优于基线模型，展现出更强的鲁棒性和泛化能力。

Conclusion: 基于LLM的系统在预测商业广告可记忆性方面表现出优越的性能，并具有更好的鲁棒性和泛化能力。

Abstract: This paper addresses the prediction of commercial (brand) memorability as
part of "Subtask 2: Commercial/Ad Memorability" within the "Memorability:
Predicting movie and commercial memorability" task at the MediaEval 2025
workshop competition. We propose a multimodal fusion system with a Gemma-3 LLM
backbone that integrates pre-computed visual (ViT) and textual (E5) features by
multi-modal projections. The model is adapted using Low-Rank Adaptation (LoRA).
A heavily-tuned ensemble of gradient boosted trees serves as a baseline. A key
contribution is the use of LLM-generated rationale prompts, grounded in
expert-derived aspects of memorability, to guide the fusion model. The results
demonstrate that the LLM-based system exhibits greater robustness and
generalization performance on the final test set, compared to the baseline.
  The paper's codebase can be found at
https://github.com/dsgt-arc/mediaeval-2025-memorability

</details>


### [139] [Semantic-Preserving Cross-Style Visual Reasoning for Robust Multi-Modal Understanding in Large Vision-Language Models](https://arxiv.org/abs/2510.22838)
*Aya Nakayama,Brian Wong,Yuji Nishimura,Kaito Tanaka*

Main category: cs.CV

TL;DR: SP-CSVR框架通过解耦风格与内容、适应性解码和对比学习，解决了LVLMs在跨风格视觉推理中的


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLMs）在处理多样化视觉风格时面临“风格陷阱”的挑战，影响了跨风格的语义理解和 in-context learning（ICL）能力。现有方法难以有效分离风格与内容，限制了模型的泛化能力。

Method: 提出了一种名为“语义保持交叉风格视觉推理器”（SP-CSVR）的新框架。该框架包含三个关键组件：1. 交叉风格特征编码器（CSFE），用于实现风格与内容的解耦；2. 语义对齐的上下文解码器（SAICD），用于高效的少样本风格适应；3. 自适应语义一致性模块（ASCM），通过多任务对比学习来强制执行跨风格的语义不变性。

Result: 在具有挑战性的多风格数据集上进行了广泛的实验，SP-CSVR在视觉字幕、视觉问答和上下文风格适应方面取得了最先进的性能。消融研究和泛化分析也证实了SP-CSVR在提高模型鲁棒性、泛化性和效率方面的有效性。

Conclusion: SP-CSVR框架能够稳定地进行语义理解，并适应性地进行跨风格的视觉推理，有效解决了LVLMs在处理多样化视觉风格时遇到的“风格陷阱”问题。

Abstract: The "style trap" poses a significant challenge for Large Vision-Language
Models (LVLMs), hindering robust semantic understanding across diverse visual
styles, especially in in-context learning (ICL). Existing methods often fail to
effectively decouple style from content, hindering generalization. To address
this, we propose the Semantic-Preserving Cross-Style Visual Reasoner (SP-CSVR),
a novel framework for stable semantic understanding and adaptive cross-style
visual reasoning. SP-CSVR integrates a Cross-Style Feature Encoder (CSFE) for
style-content disentanglement, a Semantic-Aligned In-Context Decoder (SAICD)
for efficient few-shot style adaptation, and an Adaptive Semantic Consistency
Module (ASCM) employing multi-task contrastive learning to enforce cross-style
semantic invariance. Extensive experiments on a challenging multi-style dataset
demonstrate SP-CSVR's state-of-the-art performance across visual captioning,
visual question answering, and in-context style adaptation. Comprehensive
evaluations, including ablation studies and generalization analysis, confirm
SP-CSVR's efficacy in enhancing robustness, generalization, and efficiency
across diverse visual styles.

</details>


### [140] [FastJAM: a Fast Joint Alignment Model for Images](https://arxiv.org/abs/2510.22842)
*Omri Hirsch,Ron Shapira Weber,Shira Ifergane,Oren Freifeld*

Main category: cs.CV

TL;DR: FastJAM是一种快速、基于图的联合对齐方法，可在几秒钟内实现高质量的图像对齐，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的联合对齐方法通常需要长时间的训练、大容量模型和大量的超参数调整，而FastJAM旨在提供一种计算效率更高的方法。

Method: FastJAM利用现成的图像匹配器计算的成对匹配，以及快速的非参数聚类，构建一个表示图像内和图像间关键点关系的图。图神经网络通过图像级池化传播和聚合这些对应关系，高效地预测每张图像的单应性参数。使用反组合损失，无需对预测变换进行正则化，从而省去了相关的超参数调整。

Result: 在多个基准测试的实验结果表明，FastJAM在对齐质量方面优于现有的现代联合对齐方法，并将计算时间从几小时或几分钟缩短到几秒钟。

Conclusion: FastJAM是一种快速有效的联合对齐方法，在对齐质量和计算效率方面均优于现有方法，且无需进行繁琐的超参数调整。

Abstract: Joint Alignment (JA) of images aims to align a collection of images into a
unified coordinate frame, such that semantically-similar features appear at
corresponding spatial locations. Most existing approaches often require long
training times, large-capacity models, and extensive hyperparameter tuning. We
introduce FastJAM, a rapid, graph-based method that drastically reduces the
computational complexity of joint alignment tasks. FastJAM leverages pairwise
matches computed by an off-the-shelf image matcher, together with a rapid
nonparametric clustering, to construct a graph representing intra- and
inter-image keypoint relations. A graph neural network propagates and
aggregates these correspondences, efficiently predicting per-image homography
parameters via image-level pooling. Utilizing an inverse-compositional loss,
that eliminates the need for a regularization term over the predicted
transformations (and thus also obviates the hyperparameter tuning associated
with such terms), FastJAM performs image JA quickly and effectively.
Experimental results on several benchmarks demonstrate that FastJAM achieves
results better than existing modern JA methods in terms of alignment quality,
while reducing computation time from hours or minutes to mere seconds. Our code
is available at our project webpage, https://bgu-cs-vil.github.io/FastJAM/

</details>


### [141] [Semantic Surgery: Zero-Shot Concept Erasure in Diffusion Models](https://arxiv.org/abs/2510.22851)
*Lexiang Xiong,Chengyu Liu,Jingwen Ye,Yan Liu,Yuecong Xu*

Main category: cs.CV

TL;DR: Semantic Surgery是一种新颖的、无需训练的、零样本框架，用于在文本到图像扩散模型中擦除概念，它在扩散过程之前直接作用于文本嵌入。


<details>
  <summary>Details</summary>
Motivation: 现有的概念擦除方法在减轻有害内容的同时，往往会损害生成质量。需要一种能够提高擦除的完整性和局部性的方法。

Method: Semantic Surgery通过动态估计提示中目标概念的存在，并进行校准的向量减法来消除其影响。它还包括一个用于多概念擦除的共现编码模块和一个用于解决潜在概念持久性的视觉反馈循环。

Result: 在对象、露骨内容、艺术风格和多名人擦除任务的广泛实验中，Semantic Surgery显著优于现有方法，在对象擦除中达到93.58 H-score，将露骨内容减少到仅1个实例，在风格擦除中达到8.09 H_a，且没有质量损失。

Conclusion: Semantic Surgery是一种有效且通用的概念擦除方法，它在不损害图像质量的情况下实现了高完成度和鲁棒性，并可用作内置的威胁检测系统，为更安全的文本到图像生成提供了一种实用的解决方案。

Abstract: Concept erasure in text-to-image diffusion models is crucial for mitigating
harmful content, yet existing methods often compromise generative quality. We
introduce Semantic Surgery, a novel training-free, zero-shot framework for
concept erasure that operates directly on text embeddings before the diffusion
process. It dynamically estimates the presence of target concepts in a prompt
and performs a calibrated vector subtraction to neutralize their influence at
the source, enhancing both erasure completeness and locality. The framework
includes a Co-Occurrence Encoding module for robust multi-concept erasure and a
visual feedback loop to address latent concept persistence. As a training-free
method, Semantic Surgery adapts dynamically to each prompt, ensuring precise
interventions. Extensive experiments on object, explicit content, artistic
style, and multi-celebrity erasure tasks show our method significantly
outperforms state-of-the-art approaches. We achieve superior completeness and
robustness while preserving locality and image quality (e.g., 93.58 H-score in
object erasure, reducing explicit content to just 1 instance, and 8.09 H_a in
style erasure with no quality degradation). This robustness also allows our
framework to function as a built-in threat detection system, offering a
practical solution for safer text-to-image generation.

</details>


### [142] [Seeing the Unseen: Towards Zero-Shot Inspection for Wind Turbine Blades using Knowledge-Augmented Vision Language Models](https://arxiv.org/abs/2510.22868)
*Yang Zhang,Qianyu Zhou,Farhad Imani,Jiong Tang*

Main category: cs.CV

TL;DR: 提出一个结合检索增强生成（RAG）和视觉-语言模型（VLM）的零样本（zero-shot）风力涡轮机叶片损伤检测框架，无需大量标注数据集，即可通过注入领域知识来提高检测准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 风力涡轮机叶片易受损，需要及时检测以避免故障和优化维护。现有基于无人机和深度学习的方法依赖大量标注数据，难以检测罕见或演变中的损伤类型。

Method: 构建包含技术文档、参考图像和领域指南的多模态知识库。利用混合文本-图像检索器（含关键词感知重排）提取相关上下文，以条件化VLM，在推理时注入领域知识，无需针对性训练。

Result: 在包含多种损伤类型的30张叶片图像的小型测试集上，RAG-驱动的VLM正确分类了所有样本，而未使用检索的VLM表现较差。该框架的消融研究表明，其主要优势在于可解释性和泛化性，能够通过领域知识检测未见过的缺陷。

Conclusion: 该研究提出了一种数据高效的工业检测解决方案，减少了对海量标注数据集的依赖，提高了风力涡轮机叶片损伤检测的准确性、可解释性和泛化能力。

Abstract: Wind turbine blades operate in harsh environments, making timely damage
detection essential for preventing failures and optimizing maintenance.
Drone-based inspection and deep learning are promising, but typically depend on
large, labeled datasets, which limit their ability to detect rare or evolving
damage types. To address this, we propose a zero-shot-oriented inspection
framework that integrates Retrieval-Augmented Generation (RAG) with
Vision-Language Models (VLM). A multimodal knowledge base is constructed,
comprising technical documentation, representative reference images, and
domain-specific guidelines. A hybrid text-image retriever with keyword-aware
reranking assembles the most relevant context to condition the VLM at
inference, injecting domain knowledge without task-specific training. We
evaluate the framework on 30 labeled blade images covering diverse damage
categories. Although the dataset is small due to the difficulty of acquiring
verified blade imagery, it covers multiple representative defect types. On this
test set, the RAG-grounded VLM correctly classified all samples, whereas the
same VLM without retrieval performed worse in both accuracy and precision. We
further compare against open-vocabulary baselines and incorporate uncertainty
Clopper-Pearson confidence intervals to account for the small-sample setting.
Ablation studies indicate that the key advantage of the framework lies in
explainability and generalizability: retrieved references ground the reasoning
process and enable the detection of previously unseen defects by leveraging
domain knowledge rather than relying solely on visual cues. This research
contributes a data-efficient solution for industrial inspection that reduces
dependence on extensive labeled datasets.

</details>


### [143] [Estimating Pasture Biomass from Top-View Images: A Dataset for Precision Agriculture](https://arxiv.org/abs/2510.22916)
*Qiyu Liao,Dadong Wang,Rebecca Haling,Jiajun Liu,Xun Li,Martyna Plomecka,Andrew Robson,Matthew Pringle,Rhys Pirie,Megan Walker,Joshua Whelan*

Main category: cs.CV

TL;DR: 本研究提供了一个包含1,162张标注过的澳大利亚牧场图像的数据集，用于精准管理牲畜生产系统。


<details>
  <summary>Details</summary>
Motivation: 为了最大化牧场利用率、最小化过度放牧风险和促进整体系统健康，需要准确估算牧场生物量以辅助决策。

Method: 收集了包含1,162张标注过的、从顶部拍摄的牧场图像，覆盖澳大利亚19个地点，跨越多个季节，包含多种温带牧场物种。每张图像记录了70cm * 30cm的样方，并配有地面测量数据，包括按成分（绿色、枯死、豆科植物）分类的生物量、植被高度以及来自主动光学传感器（AOS）的归一化植被指数（NDVI）。

Result: 该数据集结合了视觉、光谱和结构信息，为改进精准放牧管理提供了新的可能性。

Conclusion: 研究发布了一个用于牧场生物量估算的数据集，并通过Kaggle竞赛鼓励机器学习社区参与，旨在推动精准放牧管理技术的发展。

Abstract: Accurate estimation of pasture biomass is important for decision-making in
livestock production systems. Estimates of pasture biomass can be used to
manage stocking rates to maximise pasture utilisation, while minimising the
risk of overgrazing and promoting overall system health. We present a
comprehensive dataset of 1,162 annotated top-view images of pastures collected
across 19 locations in Australia. The images were taken across multiple seasons
and include a range of temperate pasture species. Each image captures a 70cm *
30cm quadrat and is paired with on-ground measurements including biomass sorted
by component (green, dead, and legume fraction), vegetation height, and
Normalized Difference Vegetation Index (NDVI) from Active Optical Sensors
(AOS). The multidimensional nature of the data, which combines visual,
spectral, and structural information, opens up new possibilities for advancing
the use of precision grazing management. The dataset is released and hosted in
a Kaggle competition that challenges the international Machine Learning
community with the task of pasture biomass estimation. The dataset is available
on the official Kaggle webpage:
https://www.kaggle.com/competitions/csiro-biomass

</details>


### [144] [Gen-LangSplat: Generalized Language Gaussian Splatting with Pre-Trained Feature Compression](https://arxiv.org/abs/2510.22930)
*Pranav Saxena*

Main category: cs.CV

TL;DR: Gen-LangSplat使用通用自动编码器替代了特定场景的自动编码器，实现了可扩展、实时的3D AI应用。


<details>
  <summary>Details</summary>
Motivation: 在3D环境中对开放词汇语言进行建模对于直观的人机交互和物理环境查询至关重要，但现有方法需要昂贵的场景特定训练。

Method: 提出Gen-LangSplat，使用在ScanNet数据集上预训练的通用自动编码器，替代了LangSplat中每个场景都需要训练的特定场景自动编码器，从而消除了场景特定训练的瓶颈。

Result: Gen-LangSplat的整个语言场构建过程效率得到了提升，并且查询性能与原始LangSplat方法相当或更优。通过消融实验确定了最优的潜在嵌入维度，并使用均方误差和余弦相似度量化了表示保真度。

Conclusion: 通用嵌入能够高效、准确地支持新3D场景中的开放词汇查询，为可扩展的、实时的交互式3D AI应用铺平了道路。

Abstract: Modeling open-vocabulary language fields in 3D is essential for intuitive
human-AI interaction and querying within physical environments.
State-of-the-art approaches, such as LangSplat, leverage 3D Gaussian Splatting
to efficiently construct these language fields, encoding features distilled
from high-dimensional models like CLIP. However, this efficiency is currently
offset by the requirement to train a scene-specific language autoencoder for
feature compression, introducing a costly, per-scene optimization bottleneck
that hinders deployment scalability. In this work, we introduce Gen-LangSplat,
that eliminates this requirement by replacing the scene-wise autoencoder with a
generalized autoencoder, pre-trained extensively on the large-scale ScanNet
dataset. This architectural shift enables the use of a fixed, compact latent
space for language features across any new scene without any scene-specific
training. By removing this dependency, our entire language field construction
process achieves a efficiency boost while delivering querying performance
comparable to, or exceeding, the original LangSplat method. To validate our
design choice, we perform a thorough ablation study empirically determining the
optimal latent embedding dimension and quantifying representational fidelity
using Mean Squared Error and cosine similarity between the original and
reprojected 512-dimensional CLIP embeddings. Our results demonstrate that
generalized embeddings can efficiently and accurately support open-vocabulary
querying in novel 3D scenes, paving the way for scalable, real-time interactive
3D AI applications.

</details>


### [145] [Positional Preservation Embedding for Multimodal Large Language Models](https://arxiv.org/abs/2510.22936)
*Mouxiao Huang,Borui Jiang,Dehua Zheng,Hailin Hu,Kai Han,Xinghao Chen*

Main category: cs.CV

TL;DR: PPE通过解耦3D位置信息来压缩视觉标记，以保留时空结构，从而提高MLLM的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉标记压缩方法会破坏时空结构，影响MLLM在视觉语言任务上的表现。

Method: 提出了一种名为位置保持嵌入（PPE）的新型编码算子，该算子将3D位置信息解耦并编码到标记维度，以在压缩标记的同时保留时空结构。PPE支持级联聚类等渐进式标记压缩策略，并且是无需调整即可无缝集成到现有方法中的参数无关的通用算子。

Result: PPE在MMBench、TextVQA和VideoMME等多个视觉语言基准上，与最先进的标记合并框架结合使用时，一致提高了2%~5%的性能。

Conclusion: 保留位置线索对于高效且有效的MLLM推理至关重要。

Abstract: Multimodal large language models (MLLMs) have achieved strong performance on
vision-language tasks, yet often suffer from inefficiencies due to redundant
visual tokens. Existing token merging methods reduce sequence length but
frequently disrupt spatial layouts and temporal continuity by disregarding
positional relationships. In this work, we propose a novel encoding operator
dubbed as \textbf{P}ositional \textbf{P}reservation \textbf{E}mbedding
(\textbf{PPE}), which has the main hallmark of preservation of spatiotemporal
structure during visual token compression. PPE explicitly introduces the
disentangled encoding of 3D positions in the token dimension, enabling each
compressed token to encapsulate different positions from multiple original
tokens. Furthermore, we show that PPE can effectively support cascade
clustering -- a progressive token compression strategy that leads to better
performance retention. PPE is a parameter-free and generic operator that can be
seamlessly integrated into existing token merging methods without any
adjustments. Applied to state-of-the-art token merging framework, PPE achieves
consistent improvements of $2\%\sim5\%$ across multiple vision-language
benchmarks, including MMBench (general vision understanding), TextVQA (layout
understanding) and VideoMME (temporal understanding). These results demonstrate
that preserving positional cues is critical for efficient and effective MLLM
reasoning.

</details>


### [146] [Bi-Encoder Contrastive Learning for Fingerprint and Iris Biometrics](https://arxiv.org/abs/2510.22937)
*Matthew So,Judah Goldfeder,Mark Lis,Hod Lipson*

Main category: cs.CV

TL;DR: 双编码器网络在指纹到指纹、虹膜到虹膜和跨模态指纹到虹膜匹配任务上进行了训练，以测试生物特征统计不相关的假设。结果表明，左眼和右眼虹膜之间存在相关性，而指纹模型也显示出与先前工作一致的积极的同类主体结果。跨模态匹配仅略高于随机水平。


<details>
  <summary>Details</summary>
Motivation: 测试生物特征统计不相关的历史假设。

Method: 使用 ResNet-50 和 Vision Transformer 主干网络训练双编码器架构，以最小化来自同一图像个体的对比损失。

Result: 虹膜 ResNet 架构在虹膜到虹膜匹配中达到 91 ROC AUC 分数，证明了左眼和右眼虹膜的相关性。指纹模型与先前工作一致。跨模态匹配仅略高于随机水平。

Conclusion: 左眼和右眼虹膜之间存在相关性，这挑战了生物特征独立性的假设。跨模态匹配的结果表明需要更多数据和更复杂的管道。

Abstract: There has been a historic assumption that the biometrics of an individual are
statistically uncorrelated. We test this assumption by training Bi-Encoder
networks on three verification tasks, including fingerprint-to-fingerprint
matching, iris-to-iris matching, and cross-modal fingerprint-to-iris matching
using 274 subjects with $\sim$100k fingerprints and 7k iris images. We trained
ResNet-50 and Vision Transformer backbones in Bi-Encoder architectures such
that the contrastive loss between images sampled from the same individual is
minimized. The iris ResNet architecture reaches 91 ROC AUC score for
iris-to-iris matching, providing clear evidence that the left and right irises
of an individual are correlated. Fingerprint models reproduce the positive
intra-subject suggested by prior work in this space. This is the first work
attempting to use Vision Transformers for this matching. Cross-modal matching
rises only slightly above chance, which suggests that more data and a more
sophisticated pipeline is needed to obtain compelling results. These findings
continue challenge independence assumptions of biometrics and we plan to extend
this work to other biometrics in the future. Code available:
https://github.com/MatthewSo/bio_fingerprints_iris.

</details>


### [147] [Switchable Token-Specific Codebook Quantization For Face Image Compression](https://arxiv.org/abs/2510.22943)
*Yongbo Wang,Haonan Wang,Guodong Mu,Ruixin Zhang,Jiaqi Chen,Jingyun Zhang,Jun Wang,Yuan Xie,Zhizhong Zhang,Shouhong Ding*

Main category: cs.CV

TL;DR: 提出了可切换的、面向特定令牌的码本量化方法，通过为不同图像类别学习不同的码本组并为每个令牌分配独立的码本，以提高面部图像压缩在低比特率下的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于码本的解决方案在处理富含属性的面部图像时，忽略了类别特定的相关性和令牌间的语义差异，导致在低比特率下性能不佳。

Method: 提出了一种可切换的、面向特定令牌的码本量化方法。该方法为不同图像类别学习不同的码本组，并为每个令牌分配一个独立的码本。通过用少量比特记录每个令牌所属的码本组，减少了每个码本组大小减小时产生的损失，从而在较低的总比特率下实现更大的码本总数。

Result: 在面部识别数据集上进行了测试，在0.05比特每像素（bpp）的情况下，重建图像的平均准确率达到了93.51%。

Conclusion: 该方法通过引入类别特定的码本和令牌级别的独立码本，提高了面部图像在低比特率下的压缩和重建性能，并且具有良好的泛化能力，可以集成到现有的基于码本的方法中。

Abstract: With the ever-increasing volume of visual data, the efficient and lossless
transmission, along with its subsequent interpretation and understanding, has
become a critical bottleneck in modern information systems. The emerged
codebook-based solution utilize a globally shared codebook to quantize and
dequantize each token, controlling the bpp by adjusting the number of tokens or
the codebook size. However, for facial images, which are rich in attributes,
such global codebook strategies overlook both the category-specific
correlations within images and the semantic differences among tokens, resulting
in suboptimal performance, especially at low bpp. Motivated by these
observations, we propose a Switchable Token-Specific Codebook Quantization for
face image compression, which learns distinct codebook groups for different
image categories and assigns an independent codebook to each token. By
recording the codebook group to which each token belongs with a small number of
bits, our method can reduce the loss incurred when decreasing the size of each
codebook group. This enables a larger total number of codebooks under a lower
overall bpp, thereby enhancing the expressive capability and improving
reconstruction performance. Owing to its generalizable design, our method can
be integrated into any existing codebook-based representation learning approach
and has demonstrated its effectiveness on face recognition datasets, achieving
an average accuracy of 93.51% for reconstructed images at 0.05 bpp.

</details>


### [148] [LightBagel: A Light-weighted, Double Fusion Framework for Unified Multimodal Understanding and Generation](https://arxiv.org/abs/2510.22946)
*Zeyu Wang,Zilong Chen,Chenhui Gou,Feng Li,Chaorui Deng,Deyao Zhu,Kunchang Li,Weihao Yu,Haoqin Tu,Haoqi Fan,Cihang Xie*

Main category: cs.CV

TL;DR: 通过融合现有的预训练模型，在计算资源有限的情况下实现了高效且具有竞争力的多模态能力。


<details>
  <summary>Details</summary>
Motivation: 当前的统一多模态模型通常需要从头开始训练，计算成本高昂。本文旨在探索一种更高效的方法，通过融合现有模型来获得竞争力。

Method: 保留现有模型模块，并交错插入多模态自注意力模块，形成一种双重融合机制，以融合不同模态的信息，同时保留基础模型的优势。

Result: 在文本到图像生成（GenEval，DPG-Bench）和图像编辑（GEditBench，ImgEdit-Bench）等基准测试中取得了优异的成绩，训练数据量仅为约35B tokens。

Conclusion: 该方法通过融合现有模型，在保证性能的同时大幅降低了训练成本，并公开了相关资源以促进未来研究。

Abstract: Unified multimodal models have recently shown remarkable gains in both
capability and versatility, yet most leading systems are still trained from
scratch and require substantial computational resources. In this paper, we show
that competitive performance can be obtained far more efficiently by
strategically fusing publicly available models specialized for either
generation or understanding. Our key design is to retain the original blocks
while additionally interleaving multimodal self-attention blocks throughout the
networks. This double fusion mechanism (1) effectively enables rich multi-modal
fusion while largely preserving the original strengths of the base models, and
(2) catalyzes synergistic fusion of high-level semantic representations from
the understanding encoder with low-level spatial signals from the generation
encoder. By training with only ~ 35B tokens, this approach achieves strong
results across multiple benchmarks: 0.91 on GenEval for compositional
text-to-image generation, 82.16 on DPG-Bench for complex text-to-image
generation, 6.06 on GEditBench, and 3.77 on ImgEdit-Bench for image editing. By
fully releasing the entire suite of code, model weights, and datasets, we hope
to support future research on unified multimodal modeling.

</details>


### [149] [FAME: Fairness-aware Attention-modulated Video Editing](https://arxiv.org/abs/2510.22960)
*Zhangkai Wu,Xuhui Fan,Zhongyuan Xie,Kaize Shi,Zhidong Li,Longbing Cao*

Main category: cs.CV

TL;DR: FAME通过注入公平性嵌入和注意力调制来减少视频编辑中的性别偏见，并在FairVE基准上取得了更好的公平性和语义保真度。


<details>
  <summary>Details</summary>
Motivation: 现有的免训练视频编辑模型在处理与职业相关的提示时，往往会陷入性别刻板印象。本研究旨在减轻这种职业相关的性别偏见，同时保持提示的对齐和时间一致性。

Method: FAME通过以下方式实现公平性：1. 从现有的少数群体表示中提取公平性嵌入，通过软性注入解偏胀词到文本编码器。2. 将公平性调制集成到时间自注意力和提示到区域的交叉注意力中，以减少直接引入公平性线索引起的运动损坏和时间不一致。具体来说，时间自注意力采用区域约束注意掩码和时间衰减加权，交叉注意力则通过公平性敏感的相似性掩码重新加权来实现。

Result: 在新的视频编辑公平性导向基准FairVE上的大量实验表明，FAME在公平性对齐和语义保真度方面表现优于现有的视频编辑基线。

Conclusion: FAME是一种公平性感知注意力调制的视频编辑方法，能够有效减少性别偏见，并保持视频编辑的提示对齐和时间一致性。

Abstract: Training-free video editing (VE) models tend to fall back on gender
stereotypes when rendering profession-related prompts. We propose \textbf{FAME}
for \textit{Fairness-aware Attention-modulated Video Editing} that mitigates
profession-related gender biases while preserving prompt alignment and temporal
consistency for coherent VE. We derive fairness embeddings from existing
minority representations by softly injecting debiasing tokens into the text
encoder. Simultaneously, FAME integrates fairness modulation into both temporal
self attention and prompt-to-region cross attention to mitigate the motion
corruption and temporal inconsistency caused by directly introducing fairness
cues. For temporal self attention, FAME introduces a region constrained
attention mask combined with time decay weighting, which enhances intra-region
coherence while suppressing irrelevant inter-region interactions. For cross
attention, it reweights tokens to region matching scores by incorporating
fairness sensitive similarity masks derived from debiasing prompt embeddings.
Together, these modulations keep fairness-sensitive semantics tied to the right
visual regions and prevent temporal drift across frames. Extensive experiments
on new VE fairness-oriented benchmark \textit{FairVE} demonstrate that FAME
achieves stronger fairness alignment and semantic fidelity, surpassing existing
VE baselines.

</details>


### [150] [Survey of Multimodal Geospatial Foundation Models: Techniques, Applications, and Challenges](https://arxiv.org/abs/2510.22964)
*Liling Yang,Ning Chen,Jun Yue,Yidan Liu,Jiayi Ma,Pedram Ghamisi,Antonio Plaza,Leyuan Fang*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Foundation models have transformed natural language processing and computer
vision, and their impact is now reshaping remote sensing image analysis. With
powerful generalization and transfer learning capabilities, they align
naturally with the multimodal, multi-resolution, and multi-temporal
characteristics of remote sensing data. To address unique challenges in the
field, multimodal geospatial foundation models (GFMs) have emerged as a
dedicated research frontier. This survey delivers a comprehensive review of
multimodal GFMs from a modality-driven perspective, covering five core visual
and vision-language modalities. We examine how differences in imaging physics
and data representation shape interaction design, and we analyze key techniques
for alignment, integration, and knowledge transfer to tackle modality
heterogeneity, distribution shifts, and semantic gaps. Advances in training
paradigms, architectures, and task-specific adaptation strategies are
systematically assessed alongside a wealth of emerging benchmarks.
Representative multimodal visual and vision-language GFMs are evaluated across
ten downstream tasks, with insights into their architectures, performance, and
application scenarios. Real-world case studies, spanning land cover mapping,
agricultural monitoring, disaster response, climate studies, and geospatial
intelligence, demonstrate the practical potential of GFMs. Finally, we outline
pressing challenges in domain generalization, interpretability, efficiency, and
privacy, and chart promising avenues for future research.

</details>


### [151] [VALA: Learning Latent Anchors for Training-Free and Temporally Consistent](https://arxiv.org/abs/2510.22970)
*Zhangkai Wu,Xuhui Fan,Zhongyuan Xie,Kaize Shi,Longbing Cao*

Main category: cs.CV

TL;DR: VALA是一种新的变分对齐模块，用于在文本到图像的视频编辑中自适应地选择关键帧并将其潜在特征压缩成语义锚点，以提高时间和内容的一致性。


<details>
  <summary>Details</summary>
Motivation: 现有模型在训练免费视频编辑中，依赖启发式帧选择来保持时间一致性，这引入了手动偏差并降低了端到端推理的可扩展性。

Method: VALA模块使用变分框架和对比学习目标来学习有意义的分配，将跨帧潜在表示转换为保留内容和时间相干性的压缩潜在锚点。

Result: VALA在反演保真度、编辑质量和时间一致性方面取得了最先进的性能，并且比以前的方法效率更高。

Conclusion: VALA可以完全集成到基于文本到图像的视频编辑模型中，显著提高了视频编辑的质量和效率。

Abstract: Recent advances in training-free video editing have enabled lightweight and
precise cross-frame generation by leveraging pre-trained text-to-image
diffusion models. However, existing methods often rely on heuristic frame
selection to maintain temporal consistency during DDIM inversion, which
introduces manual bias and reduces the scalability of end-to-end inference. In
this paper, we propose~\textbf{VALA} (\textbf{V}ariational \textbf{A}lignment
for \textbf{L}atent \textbf{A}nchors), a variational alignment module that
adaptively selects key frames and compresses their latent features into
semantic anchors for consistent video editing. To learn meaningful assignments,
VALA propose a variational framework with a contrastive learning objective.
Therefore, it can transform cross-frame latent representations into compressed
latent anchors that preserve both content and temporal coherence. Our method
can be fully integrated into training-free text-to-image based video editing
models. Extensive experiments on real-world video editing benchmarks show that
VALA achieves state-of-the-art performance in inversion fidelity, editing
quality, and temporal consistency, while offering improved efficiency over
prior methods.

</details>


### [152] [Scaling Up Occupancy-centric Driving Scene Generation: Dataset and Method](https://arxiv.org/abs/2510.22973)
*Bohan Li,Xin Jin,Hu Zhu,Hongsi Liu,Ruikai Li,Jiazhe Guo,Kaiwen Cai,Chao Ma,Yueming Jin,Hao Zhao,Xiaokang Yang,Wenjun Zeng*

Main category: cs.CV

TL;DR: 为了解决自动驾驶领域数据标注不足的问题，我们发布了Nuplan-Occ数据集，并基于此开发了一个统一的框架，可以同时生成高质量的语义占用、多视角视频和激光雷达点云。该框架采用时空解耦架构，并结合了高斯溅射渲染和传感器感知嵌入策略，以提高生成质量和真实感，并在下游任务中验证了其实用性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶场景生成对于感知和规划评估等下游应用至关重要。然而，现有的以占用为中心的方法依赖于标注数据，而标注数据仍然稀缺。

Method: 创建了Nuplan-Occ数据集，这是迄今为止最大的语义占用数据集，由Nuplan基准构建。在此基础上，开发了一个统一的框架，该框架能够联合合成高质量的语义占用、多视图视频和激光雷达点云。该方法采用时空解耦架构，支持4D动态占用的高保真空间扩展和时间预测。为了弥合模态差距，我们提出了两种新技术：一种基于高斯溅射的稀疏点图渲染策略，用于增强多视图视频生成；一种传感器感知嵌入策略，用于显式建模激光雷达传感器属性，以实现逼真的多激光雷达模拟。

Result: 实验证明，我们提出的方法在生成保真度和可扩展性方面优于现有方法，并在下游任务中验证了其实际价值。

Conclusion: 我们提出了Nuplan-Occ数据集和统一的生成框架，解决了自动驾驶场景生成中的数据稀缺和多模态合成问题，并证明了其在下游任务中的有效性。

Abstract: Driving scene generation is a critical domain for autonomous driving,
enabling downstream applications, including perception and planning evaluation.
Occupancy-centric methods have recently achieved state-of-the-art results by
offering consistent conditioning across frames and modalities; however, their
performance heavily depends on annotated occupancy data, which still remains
scarce. To overcome this limitation, we curate Nuplan-Occ, the largest semantic
occupancy dataset to date, constructed from the widely used Nuplan benchmark.
Its scale and diversity facilitate not only large-scale generative modeling but
also autonomous driving downstream applications. Based on this dataset, we
develop a unified framework that jointly synthesizes high-quality semantic
occupancy, multi-view videos, and LiDAR point clouds. Our approach incorporates
a spatio-temporal disentangled architecture to support high-fidelity spatial
expansion and temporal forecasting of 4D dynamic occupancy. To bridge modal
gaps, we further propose two novel techniques: a Gaussian splatting-based
sparse point map rendering strategy that enhances multi-view video generation,
and a sensor-aware embedding strategy that explicitly models LiDAR sensor
properties for realistic multi-LiDAR simulation. Extensive experiments
demonstrate that our method achieves superior generation fidelity and
scalability compared to existing approaches, and validates its practical value
in downstream tasks. Repo:
https://github.com/Arlo0o/UniScene-Unified-Occupancy-centric-Driving-Scene-Generation/tree/v2

</details>


### [153] [SceneDecorator: Towards Scene-Oriented Story Generation with Scene Planning and Scene Consistency](https://arxiv.org/abs/2510.22994)
*Quanjian Song,Donghao Zhou,Jingyu Lin,Fei Shen,Jiaze Wang,Xiaowei Hu,Cunjian Chen,Pheng-Ann Heng*

Main category: cs.CV

TL;DR: 该研究提出了一种名为SceneDecorator的框架，用于解决文本到图像模型在生成故事图像时保持场景一致性的问题。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像模型在生成故事图像时，虽然关注角色一致性，但忽略了场景在叙事中的重要性，限制了创造力。本研究旨在解决场景规划和场景一致性两大挑战，以实现场景导向的故事生成。

Method: 提出SceneDecorator框架，采用VLM-Guided Scene Planning来确保跨场景的叙事连贯性（全局到局部），并利用Long-Term Scene-Sharing Attention来维持长期场景一致性和主题多样性。

Result: 实验证明SceneDecorator在生成故事图像方面表现优越，能够更好地保持场景一致性和叙事连贯性。

Conclusion: SceneDecorator框架在场景一致性和故事生成方面取得了显著进展，有望在艺术、电影和游戏领域释放创造力。

Abstract: Recent text-to-image models have revolutionized image generation, but they
still struggle with maintaining concept consistency across generated images.
While existing works focus on character consistency, they often overlook the
crucial role of scenes in storytelling, which restricts their creativity in
practice. This paper introduces scene-oriented story generation, addressing two
key challenges: (i) scene planning, where current methods fail to ensure
scene-level narrative coherence by relying solely on text descriptions, and
(ii) scene consistency, which remains largely unexplored in terms of
maintaining scene consistency across multiple stories. We propose
SceneDecorator, a training-free framework that employs VLM-Guided Scene
Planning to ensure narrative coherence across different scenes in a
``global-to-local'' manner, and Long-Term Scene-Sharing Attention to maintain
long-term scene consistency and subject diversity across generated stories.
Extensive experiments demonstrate the superior performance of SceneDecorator,
highlighting its potential to unleash creativity in the fields of arts, films,
and games.

</details>


### [154] [LoMix: Learnable Weighted Multi-Scale Logits Mixing for Medical Image Segmentation](https://arxiv.org/abs/2510.22995)
*Md Mostafijur Rahman,Radu Marculescu*

Main category: cs.CV

TL;DR: LoMix是一种新的即插即用模块，通过混合不同尺度的U型网络输出，并学习最优的融合策略，来提升模型性能，特别是在数据稀疏的情况下。它通过四种轻量级融合算子（加法、乘法、连接、注意力加权融合）生成新的混合尺度预测图，并自动优化这些预测图的损失权重，实现了高效的架构搜索。LoMix在多个基准测试中显著提高了DICE分数，且没有增加推理开销。


<details>
  <summary>Details</summary>
Motivation: 现有的U型网络在训练时孤立地处理不同尺度的输出，未能充分利用不同尺度预测之间的互补信息，导致最终输出未能达到最优。现有的监督方法（仅监督最高分辨率输出或所有尺度等权重深度监督）没有探索不同尺度输出的混合组合，这限制了模型的性能。

Method: LoMix模块通过四种轻量级融合算子（加法、乘法、连接、注意力加权融合）将多尺度的U型网络输出（logits）进行混合，生成一系列新的、合成的“突变”预测图。然后，为每个原始预测图和新生成的预测图分配一个softplus损失权重，该权重与网络参数一起进行联合优化。这种方式模拟了一步架构搜索，能够自动发现最有效的尺度、混合方式和融合算子。

Result: 在Synapse 8器官数据集上，将LoMix集成到PVT-V2-B2骨干网络和EMCAD解码器的U型架构中，相比单一尺度监督，DICE分数提高了4.2%；相比深度监督，提高了2.2%；相比等权重加法融合，提高了1.5%。在数据稀疏的情况下（1-2个标记扫描），性能提升高达9.23%。在四个不同的基准测试和多种U型网络上，LoMix相对于单一尺度监督，DICE分数最高可提升13.5%。

Conclusion: LoMix通过学习到的加权混合尺度融合，能够广泛地提升U型网络的性能，并且具有数据效率高、完全可解释、推理开销为零等优点。它解决了现有U型网络在处理多尺度输出时存在的局限性，尤其在数据量有限的情况下表现出色。

Abstract: U-shaped networks output logits at multiple spatial scales, each capturing a
different blend of coarse context and fine detail. Yet, training still treats
these logits in isolation - either supervising only the final,
highest-resolution logits or applying deep supervision with identical loss
weights at every scale - without exploring mixed-scale combinations.
Consequently, the decoder output misses the complementary cues that arise only
when coarse and fine predictions are fused. To address this issue, we introduce
LoMix (Logits Mixing), a NAS-inspired, differentiable plug-and-play module that
generates new mixed-scale outputs and learns how exactly each of them should
guide the training process. More precisely, LoMix mixes the multi-scale decoder
logits with four lightweight fusion operators: addition, multiplication,
concatenation, and attention-based weighted fusion, yielding a rich set of
synthetic mutant maps. Every original or mutant map is given a softplus loss
weight that is co-optimized with network parameters, mimicking a one-step
architecture search that automatically discovers the most useful scales,
mixtures, and operators. Plugging LoMix into recent U-shaped architectures
(i.e., PVT-V2-B2 backbone with EMCAD decoder) on Synapse 8-organ dataset
improves DICE by +4.2% over single-output supervision, +2.2% over deep
supervision, and +1.5% over equally weighted additive fusion, all with zero
inference overhead. When training data are scarce (e.g., one or two labeled
scans), the advantage grows to +9.23%, underscoring LoMix's data efficiency.
Across four benchmarks and diverse U-shaped networks, LoMiX improves DICE by up
to +13.5% over single-output supervision, confirming that learnable weighted
mixed-scale fusion generalizes broadly while remaining data efficient, fully
interpretable, and overhead-free at inference. Our code is available at
https://github.com/SLDGroup/LoMix.

</details>


### [155] [CoMo: Compositional Motion Customization for Text-to-Video Generation](https://arxiv.org/abs/2510.23007)
*Youcan Xu,Zhen Wang,Jiaxin Shi,Kexin Li,Feifei Shao,Jun Xiao,Yi Yang,Jun Yu,Long Chen*

Main category: cs.CV

TL;DR: CoMo框架通过解耦运动与外观以及空间隔离来解决文本到视频生成中的多运动合成问题，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有文本到视频模型在精确运动控制，特别是复杂多主体运动方面存在不足。现有的单运动定制方法在组合场景中效果不佳，主要面临运动-外观纠缠和多运动融合效率低的问题。

Method: CoMo框架采用两阶段方法：1. 单运动学习阶段，通过静态-动态解耦调优范式学习运动特定模块。2. 多运动合成阶段，利用即插即用式分割合并策略，在去噪过程中空间隔离影响，无需额外训练即可合成多运动。

Result: CoMo在多运动保真度和融合评估方面表现出色，实现了最先进的性能，显著提升了可控视频生成的能力。

Conclusion: CoMo框架成功解决了文本到视频生成中的组合运动定制问题，通过解耦运动与外观以及有效的融合策略，实现了在单个视频中合成多个不同运动的能力。

Abstract: While recent text-to-video models excel at generating diverse scenes, they
struggle with precise motion control, particularly for complex, multi-subject
motions. Although methods for single-motion customization have been developed
to address this gap, they fail in compositional scenarios due to two primary
challenges: motion-appearance entanglement and ineffective multi-motion
blending. This paper introduces CoMo, a novel framework for
$\textbf{compositional motion customization}$ in text-to-video generation,
enabling the synthesis of multiple, distinct motions within a single video.
CoMo addresses these issues through a two-phase approach. First, in the
single-motion learning phase, a static-dynamic decoupled tuning paradigm
disentangles motion from appearance to learn a motion-specific module. Second,
in the multi-motion composition phase, a plug-and-play divide-and-merge
strategy composes these learned motions without additional training by
spatially isolating their influence during the denoising process. To facilitate
research in this new domain, we also introduce a new benchmark and a novel
evaluation metric designed to assess multi-motion fidelity and blending.
Extensive experiments demonstrate that CoMo achieves state-of-the-art
performance, significantly advancing the capabilities of controllable video
generation. Our project page is at https://como6.github.io/.

</details>


### [156] [UGAE: Unified Geometry and Attribute Enhancement for G-PCC Compressed Point Clouds](https://arxiv.org/abs/2510.23009)
*Pan Zhao,Hui Yuan,Chongzhen Tian,Tian Guo,Raouf Hamzaoui,Zhigeng Pan*

Main category: cs.CV

TL;DR: UGAE是一个统一的几何和属性增强框架，通过三种方法（PoGE、PAE、PoAE）显著提高了点云压缩的质量和效率，在BD-PSNR和BD比特率节省方面均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 点云的有损压缩会导致几何结构和属性信息不可逆的失真，因此需要提出一种框架来解决这些问题。

Method: 提出了一种统一的几何和属性增强（UGAE）框架，包含三个组件：后几何增强（PoGE），通过基于Transformer的稀疏卷积U-Net预测体素占用概率来重建几何结构；预属性增强（PAE），使用增强的几何引导的重新着色策略（DA-KNN）实现精确的重新着色并保留高频细节；后属性增强（PoAE），使用属性残差预测网络和加权均方误差（W-MSE）损失来增强高频区域质量并保持低频区域保真度。

Result: UGAE在三个基准数据集（8iVFB、Owlii和MVUB）上显著优于现有方法。与TMC13v29相比，UGAE在几何方面平均BD-PSNR提高了9.98 dB，BD比特率节省了90.98%；在属性方面（Y分量），BD-PSNR提高了3.67 dB，BD比特率节省了56.88%。此外，感官质量也得到了显著改善。

Conclusion: UGAE框架通过结合几何和属性增强技术，有效解决了有损点云压缩中的失真问题，并在性能和效率上取得了显著的进步。

Abstract: Lossy compression of point clouds reduces storage and transmission costs;
however, it inevitably leads to irreversible distortion in geometry structure
and attribute information. To address these issues, we propose a unified
geometry and attribute enhancement (UGAE) framework, which consists of three
core components: post-geometry enhancement (PoGE), pre-attribute enhancement
(PAE), and post-attribute enhancement (PoAE). In PoGE, a Transformer-based
sparse convolutional U-Net is used to reconstruct the geometry structure with
high precision by predicting voxel occupancy probabilities. Building on the
refined geometry structure, PAE introduces an innovative enhanced
geometry-guided recoloring strategy, which uses a detail-aware K-Nearest
Neighbors (DA-KNN) method to achieve accurate recoloring and effectively
preserve high-frequency details before attribute compression. Finally, at the
decoder side, PoAE uses an attribute residual prediction network with a
weighted mean squared error (W-MSE) loss to enhance the quality of
high-frequency regions while maintaining the fidelity of low-frequency regions.
UGAE significantly outperformed existing methods on three benchmark datasets:
8iVFB, Owlii, and MVUB. Compared to the latest G-PCC test model (TMC13v29),
UGAE achieved an average BD-PSNR gain of 9.98 dB and 90.98% BD-bitrate savings
for geometry under the D1 metric, as well as a 3.67 dB BD-PSNR improvement with
56.88% BD-bitrate savings for attributes on the Y component. Additionally, it
improved perceptual quality significantly.

</details>


### [157] [M$^{3}$T2IBench: A Large-Scale Multi-Category, Multi-Instance, Multi-Relation Text-to-Image Benchmark](https://arxiv.org/abs/2510.23020)
*Huixuan Zhang,Xiaojun Wan*

Main category: cs.CV

TL;DR: 该研究提出了一个包含多类别、多实例、多关系场景的文本到图像生成评估基准 M$^3$T2IBench，以及一个与人类评估高度相关的评估指标 $AlignScore$。结果表明，现有模型在该基准上表现不佳。此外，研究还提出了一种名为 Revise-Then-Enforce 的训练无关后编辑方法，以提升图像-文本对齐能力。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像生成评估方法过于简单，无法处理包含同一类别下多个不同实例的复杂提示，并且现有指标与人类评估的相关性不高。

Method: 提出 M$^3$T2IBench 评估基准，该基准包含多类别、多实例、多关系场景。提出基于目标检测的评估指标 $AlignScore$，该指标与人类评估高度相关。提出 Revise-Then-Enforce 方法，一种训练无关的后编辑方法，用于提升图像-文本对齐能力。

Result: 在 M$^3$T2IBench 基准上，现有开源文本到图像模型表现不佳。Revise-Then-Enforce 方法在多种扩散模型上都提升了图像-文本对齐能力。

Conclusion: M$^3$T2IBench 是一个更具挑战性的评估基准，能够更好地评估文本到图像模型在复杂场景下的性能。$AlignScore$ 是一个可靠的评估指标。Revise-Then-Enforce 方法是一种有效的提升图像-文本对齐能力的技术。

Abstract: Text-to-image models are known to struggle with generating images that
perfectly align with textual prompts. Several previous studies have focused on
evaluating image-text alignment in text-to-image generation. However, these
evaluations either address overly simple scenarios, especially overlooking the
difficulty of prompts with multiple different instances belonging to the same
category, or they introduce metrics that do not correlate well with human
evaluation. In this study, we introduce M$^3$T2IBench, a large-scale,
multi-category, multi-instance, multi-relation along with an
object-detection-based evaluation metric, $AlignScore$, which aligns closely
with human evaluation. Our findings reveal that current open-source
text-to-image models perform poorly on this challenging benchmark.
Additionally, we propose the Revise-Then-Enforce approach to enhance image-text
alignment. This training-free post-editing method demonstrates improvements in
image-text alignment across a broad range of diffusion models. \footnote{Our
code and data has been released in supplementary material and will be made
publicly available after the paper is accepted.}

</details>


### [158] [UniAIDet: A Unified and Universal Benchmark for AI-Generated Image Content Detection and Localization](https://arxiv.org/abs/2510.23023)
*Huixuan Zhang,Xiaojun Wan*

Main category: cs.CV

TL;DR: 现有基准在图像生成模型的覆盖范围和图像类别方面存在局限性，未能涵盖端到端图像编辑和艺术图像。本研究提出了UniAIDet，一个统一且全面的基准，包含摄影和艺术图像，并涵盖了文本到图像、图像到图像、图像修复、图像编辑和深度伪造等多种生成模型。使用UniAIDet，我们对各种检测方法进行了全面评估，并回答了有关泛化能力以及检测与定位之间关系的关键研究问题。


<details>
  <summary>Details</summary>
Motivation: 数字图像的真实性随着图像生成模型的快速发展而成为一个重要的关注点。然而，现有的基准在覆盖不同的生成模型和图像类别方面存在不足，常常忽略端到端的图像编辑和艺术图像。

Method: 提出UniAIDet，一个包含摄影和艺术图像的统一全面的基准，覆盖文本到图像、图像到图像、图像修复、图像编辑和深度伪造等多种生成模型。在此基础上，对各种检测方法进行了全面的评估，并研究了泛化能力以及检测与定位之间的关系。

Result: 通过使用UniAIDet基准，对各种检测方法进行了全面的评估，并回答了关于泛化能力以及检测与定位之间关系的关键研究问题。

Conclusion: UniAIDet基准和分析为未来的研究提供了一个坚实的基础，以应对图像生成模型带来的挑战。

Abstract: With the rapid proliferation of image generative models, the authenticity of
digital images has become a significant concern. While existing studies have
proposed various methods for detecting AI-generated content, current benchmarks
are limited in their coverage of diverse generative models and image
categories, often overlooking end-to-end image editing and artistic images. To
address these limitations, we introduce UniAIDet, a unified and comprehensive
benchmark that includes both photographic and artistic images. UniAIDet covers
a wide range of generative models, including text-to-image, image-to-image,
image inpainting, image editing, and deepfake models. Using UniAIDet, we
conduct a comprehensive evaluation of various detection methods and answer
three key research questions regarding generalization capability and the
relation between detection and localization. Our benchmark and analysis provide
a robust foundation for future research.

</details>


### [159] [Nested AutoRegressive Models](https://arxiv.org/abs/2510.23028)
*Hongyu Wu,Xuhui Fan,Zhangkai Wu,Longbing Cao*

Main category: cs.CV

TL;DR: NestAR通过引入嵌套自回归架构，在图像生成方面实现了计算效率和样本多样性的显著提升，将复杂度从O(n)降至O(log n)。


<details>
  <summary>Details</summary>
Motivation: 现有自回归（AR）模型在图像生成方面虽然表现出色，但其逐个生成图像的机制计算成本高昂，且像VAR这样的现有解决方案在样本多样性方面存在局限。

Method: 提出了一种名为NestAR（Nested AutoRegressive）的新模型，该模型采用了嵌套自回归架构。NestAR设计了多尺度模块，并按层级顺序排列。这些不同尺度的模块均采用AR架构构建，其中较大的模块以前面的较小模块的输出来进行条件化。在每个模块内部，NestAR使用另一AR结构来生成token“块”。此外，NestAR还引入了流匹配损失（flow matching loss）以支持连续token，并开发了用于在模型训练中协调这些多尺度模块的目标函数。

Result: NestAR将图像生成（生成n个图像token）的整体复杂度从O(n)降低到O(log n)，同时提高了图像多样性，并在图像生成性能上达到了具有竞争力水平，同时显著降低了计算成本。

Conclusion: NestAR通过其创新的嵌套AR架构，在降低图像生成计算复杂度和提高样本多样性方面取得了突破性进展，为AR模型在图像生成领域的应用开辟了新方向。

Abstract: AutoRegressive (AR) models have demonstrated competitive performance in image
generation, achieving results comparable to those of diffusion models. However,
their token-by-token image generation mechanism remains computationally
intensive and existing solutions such as VAR often lead to limited sample
diversity. In this work, we propose a Nested AutoRegressive~(NestAR) model,
which proposes nested AutoRegressive architectures in generating images. NestAR
designs multi-scale modules in a hierarchical order. These different scaled
modules are constructed in an AR architecture, where one larger-scale module is
conditioned on outputs from its previous smaller-scale module. Within each
module, NestAR uses another AR structure to generate ``patches'' of tokens. The
proposed nested AR architecture reduces the overall complexity from
$\mathcal{O}(n)$ to $\mathcal{O}(\log n)$ in generating $n$ image tokens, as
well as increases image diversities. NestAR further incorporates flow matching
loss to use continuous tokens, and develops objectives to coordinate these
multi-scale modules in model training. NestAR achieves competitive image
generation performance while significantly lowering computational cost.

</details>


### [160] [HieraMamba: Video Temporal Grounding via Hierarchical Anchor-Mamba Pooling](https://arxiv.org/abs/2510.23043)
*Joungbin An,Kristen Grauman*

Main category: cs.CV

TL;DR: HieraMamba是一个新的分层架构，用于视频时间定位任务，通过使用Anchor-MambaPooling（AMP）块和两种对比损失，能够在长视频中精确地定位查询的起止时间。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理长视频时，为了捕捉全局上下文而牺牲了时间细节，或者因为使用固定的时间窗口而导致时间保真度不足。

Method: 提出了一种名为HieraMamba的分层架构，其中包含Anchor-MambaPooling（AMP）块，该块利用Mamba的选择性扫描机制来生成多尺度的紧凑锚点（anchor）令牌，以总结视频内容。此外，还设计了两种互补的损失函数：基于锚点的对比损失和基于片段池化的对比损失，以确保锚点能够保留局部细节并具有全局区分度。

Result: HieraMamba在Ego4D-NLQ、MAD和TACoS数据集上取得了新的最先进成果，证明了其在长视频中进行精确、时间保真度高的定位能力。

Conclusion: HieraMamba通过其分层架构和新颖的AMP块，有效地解决了长视频时间定位中的挑战，实现了在保留时间结构和语义丰富性的同时，进行精确的时间定位。

Abstract: Video temporal grounding, the task of localizing the start and end times of a
natural language query in untrimmed video, requires capturing both global
context and fine-grained temporal detail. This challenge is particularly
pronounced in long videos, where existing methods often compromise temporal
fidelity by over-downsampling or relying on fixed windows. We present
HieraMamba, a hierarchical architecture that preserves temporal structure and
semantic richness across scales. At its core are Anchor-MambaPooling (AMP)
blocks, which utilize Mamba's selective scanning to produce compact anchor
tokens that summarize video content at multiple granularities. Two
complementary objectives, anchor-conditioned and segment-pooled contrastive
losses, encourage anchors to retain local detail while remaining globally
discriminative. HieraMamba sets a new state-of-the-art on Ego4D-NLQ, MAD, and
TACoS, demonstrating precise, temporally faithful localization in long,
untrimmed videos.

</details>


### [161] [Strategies for Robust Deep Learning Based Deformable Registration](https://arxiv.org/abs/2510.23079)
*Joel Honkamaa,Pekka Marttinen*

Main category: cs.CV

TL;DR: LUMIR 2025脑部配准挑战赛通过在训练集未包含的对比度和模态上评估配准性能，旨在提高深度学习配准方法的泛化能力。该方法通过将图像转换为MIND特征空间来增强鲁棒性，并采用特殊的集成策略以获得一致性改进。


<details>
  <summary>Details</summary>
Motivation: 深度学习脑部配准方法的泛化能力不足，限制了其实用性。LUMIR 2025脑部配准挑战赛旨在通过在不同于训练数据的对比度和模态上评估配准性能来推动该领域发展。

Method: 在将图像输入模型之前，将其转换为MIND特征空间。采用特殊的集成策略。

Result: 将图像转换为MIND特征空间可显著提高鲁棒性，集成策略可带来微小但一致的改进。

Conclusion: 通过将图像转换为MIND特征空间和采用特殊的集成策略，可以有效提高深度学习脑部配准方法的泛化能力和鲁棒性。

Abstract: Deep learning based deformable registration methods have become popular in
recent years. However, their ability to generalize beyond training data
distribution can be poor, significantly hindering their usability. LUMIR brain
registration challenge for Learn2Reg 2025 aims to advance the field by
evaluating the performance of the registration on contrasts and modalities
different from those included in the training set. Here we describe our
submission to the challenge, which proposes a very simple idea for
significantly improving robustness by transforming the images into MIND feature
space before feeding them into the model. In addition, a special ensembling
strategy is proposed that shows a small but consistent improvement.

</details>


### [162] [Revisiting Multimodal Positional Encoding in Vision-Language Models](https://arxiv.org/abs/2510.23095)
*Jie Huang,Xuejing Liu,Sibo Song,Ruibing Hou,Hong Chang,Junyang Lin,Shuai Bai*

Main category: cs.CV

TL;DR: 本研究系统地分析了视觉-语言模型中的多模态旋转位置嵌入（RoPE），提出了两种新的变体MHRoPE和MRoPE-I，并在多个基准测试中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言模型在多模态位置编码方面缺乏系统的研究，而多模态位置编码对于模型性能至关重要。

Method: 通过分析RoPE的位置设计和频率分配两个核心组件，提出了三个指导方针：位置相干性、全频率利用和文本先验保留。基于这些见解，提出了两种即插即用的变体MHRoPE和MRoPE-I。

Result: 提出的MHRoPE和MRoPE-I在各种基准测试中持续优于现有方法，在通用和细粒度多模态理解方面均取得了显著改进。

Conclusion: 本研究提出的MHRoPE和MRoPE-I为多模态位置编码提供了有效的解决方案，在不改变模型架构的情况下，显著提升了视觉-语言模型的性能。

Abstract: Multimodal position encoding is essential for vision-language models, yet
there has been little systematic investigation into multimodal position
encoding. We conduct a comprehensive analysis of multimodal Rotary Positional
Embedding (RoPE) by examining its two core components: position design and
frequency allocation. Through extensive experiments, we identify three key
guidelines: positional coherence, full frequency utilization, and preservation
of textual priors-ensuring unambiguous layout, rich representation, and
faithful transfer from the pre-trained LLM. Based on these insights, we propose
Multi-Head RoPE (MHRoPE) and MRoPE-Interleave (MRoPE-I), two simple and
plug-and-play variants that require no architectural changes. Our methods
consistently outperform existing approaches across diverse benchmarks, with
significant improvements in both general and fine-grained multimodal
understanding. Code will be avaliable at
https://github.com/JJJYmmm/Multimodal-RoPEs.

</details>


### [163] [Residual Diffusion Bridge Model for Image Restoration](https://arxiv.org/abs/2510.23116)
*Hebaixu Wang,Jing Zhang,Haoyang Chen,Haonan Guo,Di Wang,Jiayi Ma,Bo Du*

Main category: cs.CV

TL;DR: 该论文提出残差扩散桥模型（RDBM），通过理论分析和对噪声注入/移除的自适应调整，解决了现有扩散桥模型在图像恢复中的局限性，并在多种图像恢复任务中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有扩散桥模型将图像恢复视为简单的随机插值，缺乏统一的分析视角，并且在全局噪声注入和移除过程中会不必要地扭曲未降质区域。本研究旨在解决这些问题。

Method: 提出残差扩散桥模型（RDBM），理论上重新构建了广义扩散桥的随机微分方程，推导了其前向和反向过程的解析公式，并利用给定分布的残差来调节噪声的注入和移除，实现对降质区域的自适应恢复，同时保持其他区域的完整性。

Result: RDBM在理论上统一了现有的桥模型，并证明了其最优性。实验证明，该模型在多种图像恢复任务中取得了最先进的定性和定量性能。

Conclusion: RDBM通过对噪声注入和移除的自适应调整，有效解决了现有扩散桥模型在图像恢复中的不足，并在各种图像恢复任务中展现出优越的性能。

Abstract: Diffusion bridge models establish probabilistic paths between arbitrary
paired distributions and exhibit great potential for universal image
restoration. Most existing methods merely treat them as simple variants of
stochastic interpolants, lacking a unified analytical perspective. Besides,
they indiscriminately reconstruct images through global noise injection and
removal, inevitably distorting undegraded regions due to imperfect
reconstruction. To address these challenges, we propose the Residual Diffusion
Bridge Model (RDBM). Specifically, we theoretically reformulate the stochastic
differential equations of generalized diffusion bridge and derive the
analytical formulas of its forward and reverse processes. Crucially, we
leverage the residuals from given distributions to modulate the noise injection
and removal, enabling adaptive restoration of degraded regions while preserving
intact others. Moreover, we unravel the fundamental mathematical essence of
existing bridge models, all of which are special cases of RDBM and empirically
demonstrate the optimality of our proposed models. Extensive experiments are
conducted to demonstrate the state-of-the-art performance of our method both
qualitatively and quantitatively across diverse image restoration tasks. Code
is publicly available at https://github.com/MiliLab/RDBM.

</details>


### [164] [Task-Agnostic Fusion of Time Series and Imagery for Earth Observation](https://arxiv.org/abs/2510.23118)
*Gianfranco Basile,Johannes Jakubik,Benedikt Blumenstiel,Thomas Brunschwiler,Juan Bernabe Moreno*

Main category: cs.CV

TL;DR: 我们提出了一个用于时间序列和单时间戳图像的多模态融合的通用框架，实现了跨模态生成和鲁棒的下游性能。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在开发一个能够处理时间序列和单时间戳图像的多模态融合框架，并实现跨模态生成和提高下游任务的性能。

Method: 该框架探索了时间序列量化的确定性和学习策略，并利用掩码相关性学习目标，在统一的表示空间中对离散的图像和时间序列标记进行对齐。

Result: 在地球观测领域，预训练模型可以从卫星图像生成一致的全球温度剖面，并通过反事实实验进行验证。在下游任务中，与特定任务的融合方法相比，我们的通用预训练方法在 R² 上平均提高了 6%，在 RMSE 上提高了 2%，并且在 R² 上提高了 50%，在 RMSE 上提高了 12%，优于基线方法。最后，我们分析了跨模态的梯度敏感性，为模型鲁棒性提供了见解。

Conclusion: 本研究提出的通用多模态融合框架在地球观测领域取得了显著成果，能够从卫星图像生成全球温度剖面，并在下游任务中表现出优于现有方法的性能，同时提供了对模型鲁棒性的见解。

Abstract: We propose a task-agnostic framework for multimodal fusion of time series and
single timestamp images, enabling cross-modal generation and robust downstream
performance. Our approach explores deterministic and learned strategies for
time series quantization and then leverages a masked correlation learning
objective, aligning discrete image and time series tokens in a unified
representation space. Instantiated in the Earth observation domain, the
pretrained model generates consistent global temperature profiles from
satellite imagery and is validated through counterfactual experiments. Across
downstream tasks, our task-agnostic pretraining outperforms task-specific
fusion by 6\% in R$^2$ and 2\% in RMSE on average, and exceeds baseline methods
by 50\% in R$^2$ and 12\% in RMSE. Finally, we analyze gradient sensitivity
across modalities, providing insights into model robustness. Code, data, and
weights will be released under a permissive license.

</details>


### [165] [DeepSalt: Bridging Laboratory and Satellite Spectra through Domain Adaptation and Knowledge Distillation for Large-Scale Soil Salinity Estimation](https://arxiv.org/abs/2510.23124)
*Rupasree Dey,Abdul Matin,Everett Lewark,Tanjim Bin Faruk,Andrei Bachinin,Sam Leuthold,M. Francesca Cotrufo,Shrideep Pallickara,Sangmi Lee Pallickara*

Main category: cs.CV

TL;DR: DeepSalt利用深度学习和光谱适应单元，将实验室光谱信息迁移至卫星图像，实现了大规模高精度的土壤盐度估算。


<details>
  <summary>Details</summary>
Motivation: 土壤盐渍化威胁生态和农业，现有遥感方法在精度和尺度上存在局限。

Method: 提出DeepSalt深度学习框架，结合知识蒸馏和光谱适应单元，实现实验室高光谱分辨率信息向卫星低光谱分辨率信息的迁移。

Result: DeepSalt在基准测试中表现优于其他方法，能有效估算土壤盐度，并具有良好的地理区域泛化能力。

Conclusion: DeepSalt成功解决了实验室光谱与卫星光谱的域迁移问题，为大规模土壤盐度监测提供了有效方法。

Abstract: Soil salinization poses a significant threat to both ecosystems and
agriculture because it limits plants' ability to absorb water and, in doing so,
reduces crop productivity. This phenomenon alters the soil's spectral
properties, creating a measurable relationship between salinity and light
reflectance that enables remote monitoring. While laboratory spectroscopy
provides precise measurements, its reliance on in-situ sampling limits
scalability to regional or global levels. Conversely, hyperspectral satellite
imagery enables wide-area observation but lacks the fine-grained
interpretability of laboratory instruments. To bridge this gap, we introduce
DeepSalt, a deep-learning-based spectral transfer framework that leverages
knowledge distillation and a novel Spectral Adaptation Unit to transfer
high-resolution spectral insights from laboratory-based spectroscopy to
satellite-based hyperspectral sensing. Our approach eliminates the need for
extensive ground sampling while enabling accurate, large-scale salinity
estimation, as demonstrated through comprehensive empirical benchmarks.
DeepSalt achieves significant performance gains over methods without explicit
domain adaptation, underscoring the impact of the proposed Spectral Adaptation
Unit and the knowledge distillation strategy. The model also effectively
generalized to unseen geographic regions, explaining a substantial portion of
the salinity variance.

</details>


### [166] [Note on the Construction of Structure Tensor](https://arxiv.org/abs/2510.23137)
*Josef Bigun,Fernado Alonso-Fernandez*

Main category: cs.CV

TL;DR: 本文通过总最小二乘线拟合方法，统一了两种结构张量构建方法，并提出了改进。我们认为，当这两种方法都通过对功率谱进行总最小二乘线拟合时，可以很好地统一起来，并且会带来更多的好处。此外，我们还提出了一种新的方法，可以直接从二次滤波器的响应中拟合出多个方向，而无需依赖结构张量。


<details>
  <summary>Details</summary>
Motivation: 探讨并统一两种结构张量构建方法（Bigun and Granlund 1987, Granlund and Knutsson 1995），并从总最小二乘线拟合的角度提出改进。

Method: 将两种结构张量构建方法（Bigun and Granlund 1987, Granlund and Knutsson 1995）通过总最小二乘线拟合的共同视角进行分析和统一，并提出改进。

Result: 统一了两种结构张量构建方法，并发现移除Granlund and Knutsson 1995中的校正项可以使张量保持半正定，简化特征值解释。此外，还提出了一种新的方法，可以直接从二次滤波器响应中拟合多个方向，无需结构张量。

Conclusion: 从总最小二乘线拟合的角度，可以统一并改进现有的结构张量构建方法，并提出了一种新的不依赖结构张量的方法来拟合多个方向。

Abstract: This note presents a theoretical discussion of two structure tensor
constructions: one proposed by Bigun and Granlund 1987, and the other by
Granlund and Knutsson 1995. At first glance, these approaches may appear quite
different--the former is implemented by averaging outer products of gradient
filter responses, while the latter constructs the tensor from weighted outer
products of tune-in frequency vectors of quadrature filters. We argue that when
both constructions are viewed through the common lens of Total Least Squares
(TLS) line fitting to the power spectrum, they can be reconciled to a large
extent, and additional benefits emerge. From this perspective, the correction
term introduced in Granlund and Knutsson 1995 becomes unnecessary. Omitting it
ensures that the resulting tensor remains positive semi-definite, thereby
simplifying the interpretation of its eigenvalues. Furthermore, this
interpretation allows fitting more than a single 0rientation to the input by
reinterpreting quadrature filter responses without relying on a structure
tensor. It also removes the constraint that responses must originate strictly
from quadrature filters, allowing the use of alternative filter types and
non-angular tessellations. These alternatives include Gabor filters--which,
although not strictly quadrature, are still suitable for structure tensor
construction--even when they tessellate the spectrum in a Cartesian fashion,
provided they are sufficiently concentrated.

</details>


### [167] [Fast Voxel-Wise Kinetic Modeling in Dynamic PET using a Physics-Informed CycleGAN](https://arxiv.org/abs/2510.23140)
*Christian Salomonsen,Samuel Kuttner,Michael Kampffmeyer,Robert Jenssen,Kristoffer Wickstrøm,Jong Chul Ye,Elisabeth Wetzer*

Main category: cs.CV

TL;DR: 我们提出了一种基于物理信息CycleGAN的方法，用于动态PET定量分析，解决了传统方法中复杂且侵入性的人工动脉输入函数（AIF）估计问题。


<details>
  <summary>Details</summary>
Motivation: 传统的基于示踪剂动力学建模的诊断、治疗规划、示踪剂开发和肿瘤学方法需要复杂且侵入性的人工动脉输入函数（AIF）估计。

Method: 采用基于物理信息CycleGAN的方法，将用于动态对比增强MRI（DCE-MRI）定量分析的模型应用于动态PET定量分析。

Result: 实验结果表明，该方法能够准确预测AIF，并生成与参考模型相似的参数图。

Conclusion: 基于物理信息CycleGAN的方法在动态PET定量分析中显示出潜力，能够有效解决AIF估计的难题。

Abstract: Tracer kinetic modeling serves a vital role in diagnosis, treatment planning,
tracer development and oncology, but burdens practitioners with complex and
invasive arterial input function estimation (AIF). We adopt a physics-informed
CycleGAN showing promise in DCE-MRI quantification to dynamic PET
quantification. Our experiments demonstrate sound AIF predictions and parameter
maps closely resembling the reference.

</details>


### [168] [DQ3D: Depth-guided Query for Transformer-Based 3D Object Detection in Traffic Scenarios](https://arxiv.org/abs/2510.23144)
*Ziyu Wang,Wenhao Li,Ji Wu*

Main category: cs.CV

TL;DR: 提出了一种新的3D目标检测方法DQ3D，通过利用深度信息和2D检测来生成更准确的查询点，并结合历史检测结果来处理遮挡问题，在nuScenes数据集上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有3D目标检测方法依赖于从3D参考点生成的对象查询，但这些参考点有时距离目标对象较远，可能导致误报。

Method: 提出了一种深度引导查询生成器（DQ3D），利用深度信息和2D检测来确保参考点从对象表面或内部采样。此外，为了解决当前帧中部分遮挡的对象问题，提出了一种混合注意力机制，将历史检测结果与深度引导查询融合，形成混合查询。

Result: 在nuScenes数据集上的评估显示，与基线方法相比，该方法在平均精度均值（mAP）方面提高了6.3%，在nuScenes检测分数（NDS）方面提高了4.3%。

Conclusion: DQ3D通过确保查询点采样于对象表面或内部，并有效处理遮挡，提高了3D目标检测的准确性。

Abstract: 3D object detection from multi-view images in traffic scenarios has garnered
significant attention in recent years. Many existing approaches rely on object
queries that are generated from 3D reference points to localize objects.
However, a limitation of these methods is that some reference points are often
far from the target object, which can lead to false positive detections. In
this paper, we propose a depth-guided query generator for 3D object detection
(DQ3D) that leverages depth information and 2D detections to ensure that
reference points are sampled from the surface or interior of the object.
Furthermore, to address partially occluded objects in current frame, we
introduce a hybrid attention mechanism that fuses historical detection results
with depth-guided queries, thereby forming hybrid queries. Evaluation on the
nuScenes dataset demonstrates that our method outperforms the baseline by 6.3\%
in terms of mean Average Precision (mAP) and 4.3\% in the NuScenes Detection
Score (NDS).

</details>


### [169] [Implicit Modeling for Transferability Estimation of Vision Foundation Models](https://arxiv.org/abs/2510.23145)
*Yaoyan Zheng,Huiqun Wang,Nan Zhou,Di Huang*

Main category: cs.CV

TL;DR: 通过隐式迁移学习模型（ITM）和分而治之变分逼近（DVA）策略，实现了比现有方法更稳定、更有效、更高效的迁移学习评估。


<details>
  <summary>Details</summary>
Motivation: 现有迁移学习评估方法难以准确评估新兴预训练模型，ITM旨在解决此问题。

Method: 提出了一种名为隐式迁移学习模型（ITM）的新框架，并结合分而治之变分逼近（DVA）策略来评估迁移学习能力。

Result: ITM在广泛的模型类型和训练策略的综合基准测试中，在稳定性、有效性和效率方面均优于现有方法。

Conclusion: ITM框架能够更广泛地推广到各种模型和下游任务，并能更准确地评估迁移学习能力。

Abstract: Transferability estimation identifies the best pre-trained models for
downstream tasks without incurring the high computational cost of full
fine-tuning. This capability facilitates deployment and advances the
pre-training and fine-tuning paradigm. However, existing methods often struggle
to accurately assess transferability for emerging pre-trained models with
diverse architectures, training strategies, and task alignments. In this work,
we propose Implicit Transferability Modeling (ITM), a novel framework that
implicitly models each model's intrinsic transferability, coupled with a
Divide-and-Conquer Variational Approximation (DVA) strategy to efficiently
approximate embedding space evolution. This design enables generalization
across a broader range of models and downstream tasks. Extensive experiments on
a comprehensive benchmark--spanning extensive training regimes and a wider
variety of model types--demonstrate that ITM consistently outperforms existing
methods in terms of stability, effectiveness, and efficiency.

</details>


### [170] [AG-Fusion: adaptive gated multimodal fusion for 3d object detection in complex scenes](https://arxiv.org/abs/2510.23151)
*Sixian Liu,Chen Xu,Qiang Wang,Donghai Shi,Yiwen Li*

Main category: cs.CV

TL;DR: AG-Fusion是一种创新的多模态融合方法，通过自适应门控机制选择性地整合相机和LiDAR的特征，以提高在传感器降级或环境干扰等挑战性场景下的3D目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态融合方法在传感器降级或环境干扰等挑战性场景下性能会显著下降，需要更鲁棒的融合技术。

Method: 提出了一种自适应门控融合（AG-Fusion）方法，将跨模态特征投影到统一的BEV空间，并使用基于交叉注意力机制的自适应门控模块进行特征融合，以生成鲁棒的BEV表示。同时，构建了Excavator3D（E3D）数据集，专注于挖掘机操作场景。

Result: 在KITTI数据集上达到了93.92%的准确率，在E3D数据集上相比基线方法提升了24.88%。

Conclusion: AG-Fusion方法在挑战性场景下表现出优越的鲁棒性，能够有效处理不可靠的模态信息，证明了其在复杂工业场景下的应用潜力。

Abstract: Multimodal camera-LiDAR fusion technology has found extensive application in
3D object detection, demonstrating encouraging performance. However, existing
methods exhibit significant performance degradation in challenging scenarios
characterized by sensor degradation or environmental disturbances. We propose a
novel Adaptive Gated Fusion (AG-Fusion) approach that selectively integrates
cross-modal knowledge by identifying reliable patterns for robust detection in
complex scenes. Specifically, we first project features from each modality into
a unified BEV space and enhance them using a window-based attention mechanism.
Subsequently, an adaptive gated fusion module based on cross-modal attention is
designed to integrate these features into reliable BEV representations robust
to challenging environments. Furthermore, we construct a new dataset named
Excavator3D (E3D) focusing on challenging excavator operation scenarios to
benchmark performance in complex conditions. Our method not only achieves
competitive performance on the standard KITTI dataset with 93.92% accuracy, but
also significantly outperforms the baseline by 24.88% on the challenging E3D
dataset, demonstrating superior robustness to unreliable modal information in
complex industrial scenes.

</details>


### [171] [Finding 3D Scene Analogies with Multimodal Foundation Models](https://arxiv.org/abs/2510.23184)
*Junho Kim,Young Min Kim*

Main category: cs.CV

TL;DR: 通过利用多模态基础模型，我们提出了一种新的三维场景类比方法，可以在零样本、开放词汇量的设置下，在复杂的三维场景之间建立准确的对应关系，从而实现轨迹和航路点的转移。


<details>
  <summary>Details</summary>
Motivation: 为了使机器人能够适应和规划新的、未知的 3D 环境，需要将当前观察与先前的经验联系起来。现有的三维场景类比方法在训练和物体词汇量方面存在局限性。

Method: 提出一种混合场景神经表示，结合了基于视觉-语言模型特征的稀疏图和源自 3D 形状基础模型特征场。然后，以粗到精的方式寻找三维场景类比，首先对齐图，然后用特征场细化对应关系。

Result: 能够精确地对齐复杂场景，并成功应用于轨迹和航路点的转移。

Conclusion: 所提出的基于多模态基础模型的方法在零样本、开放词汇量的条件下，能够有效地在三维场景中找到类比，并在轨迹和航路点转移方面展现出实际应用潜力。

Abstract: Connecting current observations with prior experiences helps robots adapt and
plan in new, unseen 3D environments. Recently, 3D scene analogies have been
proposed to connect two 3D scenes, which are smooth maps that align scene
regions with common spatial relationships. These maps enable detailed transfer
of trajectories or waypoints, potentially supporting demonstration transfer for
imitation learning or task plan transfer across scenes. However, existing
methods for the task require additional training and fixed object vocabularies.
In this work, we propose to use multimodal foundation models for finding 3D
scene analogies in a zero-shot, open-vocabulary setting. Central to our
approach is a hybrid neural representation of scenes that consists of a sparse
graph based on vision-language model features and a feature field derived from
3D shape foundation models. 3D scene analogies are then found in a
coarse-to-fine manner, by first aligning the graph and refining the
correspondence with feature fields. Our method can establish accurate
correspondences between complex scenes, and we showcase applications in
trajectory and waypoint transfer.

</details>


### [172] [Evaluation of Vision-LLMs in Surveillance Video](https://arxiv.org/abs/2510.23190)
*Pascal Benschop,Cristian Meo,Justin Dauwels,Jelte P. Mense*

Main category: cs.CV

TL;DR: 视频分析中的空间推理对于识别异常事件至关重要，本文提出了一种利用视觉语言模型（VLM）进行零样本异常检测的方法，并通过实验评估了其在不同条件下的性能，并指出了未来改进的方向。


<details>
  <summary>Details</summary>
Motivation: 由于摄像头的广泛使用，视频数据量巨大，超出人工监控能力，因此及时检测异常或犯罪事件对公共安全至关重要。

Method: 将异常动作识别视为一个零样本、语言约束的任务，通过将视频转换为文本描述并使用文本蕴含来评估标签，以解决具身感知对动态3D场景从稀疏2D视频的解释挑战。

Result: 评估了四种开放模型在UCF-Crime和RWF-2000数据集上的表现，发现在简单、空间显著的事件上表现较好，但在处理噪声空间线索和身份模糊方面存在不足。少数样本示例可以提高某些模型的准确性，但可能增加误报；隐私过滤器（尤其是全身GAN变换）会引入不一致性并降低准确性。

Conclusion: 目前的研究为在没有特定任务训练的情况下，通过结构感知提示、跨片段的轻量级空间记忆、描述中的场景图或3D姿态先验以及保留动作相关几何的隐私方法来增强空间推理提供了方向，并将零样本、语言约束的 VLM 定位为具身、真实世界视频理解的适应性构建块。

Abstract: The widespread use of cameras in our society has created an overwhelming
amount of video data, far exceeding the capacity for human monitoring. This
presents a critical challenge for public safety and security, as the timely
detection of anomalous or criminal events is crucial for effective response and
prevention. The ability for an embodied agent to recognize unexpected events is
fundamentally tied to its capacity for spatial reasoning. This paper
investigates the spatial reasoning of vision-language models (VLMs) by framing
anomalous action recognition as a zero-shot, language-grounded task, addressing
the embodied perception challenge of interpreting dynamic 3D scenes from sparse
2D video. Specifically, we investigate whether small, pre-trained vision--LLMs
can act as spatially-grounded, zero-shot anomaly detectors by converting video
into text descriptions and scoring labels via textual entailment. We evaluate
four open models on UCF-Crime and RWF-2000 under prompting and
privacy-preserving conditions. Few-shot exemplars can improve accuracy for some
models, but may increase false positives, and privacy filters -- especially
full-body GAN transforms -- introduce inconsistencies that degrade accuracy.
These results chart where current vision--LLMs succeed (simple, spatially
salient events) and where they falter (noisy spatial cues, identity
obfuscation). Looking forward, we outline concrete paths to strengthen spatial
grounding without task-specific training: structure-aware prompts, lightweight
spatial memory across clips, scene-graph or 3D-pose priors during description,
and privacy methods that preserve action-relevant geometry. This positions
zero-shot, language-grounded pipelines as adaptable building blocks for
embodied, real-world video understanding. Our implementation for evaluating
VLMs is publicly available at:
https://github.com/pascalbenschopTU/VLLM_AnomalyRecognition

</details>


### [173] [DecoDINO: 3D Human-Scene Contact Prediction with Semantic Classification](https://arxiv.org/abs/2510.23203)
*Lukas Bierling,Davide Pasero,Fleur Dolmans,Helia Ghasemi,Angelo Broere*

Main category: cs.CV

TL;DR: DecoDINO是一个改进的DECO模型，用于预测人体与物体之间的顶点接触，解决了DECO在软表面、遮挡、儿童和假阳性足部接触方面的局限性。它使用双DINOv2 ViT-g/14编码器、类别平衡损失加权和斑块级交叉注意力，并引入了语义接触标签。在DAMON基准测试中，DecoDINO在F1分数和测地线误差方面均优于DECO，并增加了物体级语义标签。


<details>
  <summary>Details</summary>
Motivation: 准确的顶点级人与物体接触预测对于机器人、AR/VR和行为模拟中的高保真人机交互模型至关重要。DECO是该任务的第一个野外估计器，但存在局限性。

Method: DecoDINO是一个三分支网络，基于DECO的框架。它使用两个DINOv2 ViT-g/14编码器、类别平衡损失加权以减少偏差，以及斑块级交叉注意力以改进局部推理。最后，通过轻量级MLP和softmax分配语义接触标签。

Result: 在DAMON基准测试中，DecoDINO将二元接触F1分数提高了7%，将测地线误差减半，并增加了物体级语义标签。消融研究表明，LoRA微调和双编码器是这些改进的关键。DecoDINO在DAMON挑战赛的两个任务中均优于基线。

Conclusion: DecoDINO在顶点级接触预测方面取得了显著的改进，解决了DECO的局限性，并在DAMON基准测试和挑战赛中取得了领先的性能。

Abstract: Accurate vertex-level contact prediction between humans and surrounding
objects is a prerequisite for high fidelity human object interaction models
used in robotics, AR/VR, and behavioral simulation. DECO was the first in the
wild estimator for this task but is limited to binary contact maps and
struggles with soft surfaces, occlusions, children, and false-positive foot
contacts. We address these issues and introduce DecoDINO, a three-branch
network based on DECO's framework. It uses two DINOv2 ViT-g/14 encoders,
class-balanced loss weighting to reduce bias, and patch-level cross-attention
for improved local reasoning. Vertex features are finally passed through a
lightweight MLP with a softmax to assign semantic contact labels. We also
tested a vision-language model (VLM) to integrate text features, but the
simpler architecture performed better and was used instead. On the DAMON
benchmark, DecoDINO (i) raises the binary-contact F1 score by 7$\%$, (ii)
halves the geodesic error, and (iii) augments predictions with object-level
semantic labels. Ablation studies show that LoRA fine-tuning and the dual
encoders are key to these improvements. DecoDINO outperformed the challenge
baseline in both tasks of the DAMON Challenge. Our code is available at
https://github.com/DavidePasero/deco/tree/main.

</details>


### [174] [VR-Drive: Viewpoint-Robust End-to-End Driving with Feed-Forward 3D Gaussian Splatting](https://arxiv.org/abs/2510.23205)
*Hoonhee Cho,Jae-Young Kang,Giwon Lee,Hyemin Yang,Heejun Park,Seokwoo Jung,Kuk-Jin Yoon*

Main category: cs.CV

TL;DR: VR-Drive是一个端到端的自动驾驶框架，通过联合学习3D场景重建和视角感知视图合成，解决了在不同摄像头视角下的鲁棒性问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界中，由于车辆配置的多样性，自动驾驶系统在不同摄像头视角下的鲁棒性是一个未解决的挑战。

Method: VR-Drive提出了一种新颖的端到端自动驾驶框架，通过联合学习3D场景重建作为辅助任务，以实现规划感知的视图合成。它采用前馈推理策略，支持从稀疏视图进行在线训练时增强，无需额外注释。此外，还引入了视角混合记忆库和视角一致性蒸馏策略，以增强多视角下的时间交互和知识转移。

Result: VR-Drive有效减轻了由视图合成引起噪声，并在视角变化下提高了规划性能。新发布的数据集用于评估在新型摄像头视角下的端到端自动驾驶性能。

Conclusion: VR-Drive为端到端自动驾驶系统在现实世界中的部署提供了一个可扩展且鲁棒的解决方案。

Abstract: End-to-end autonomous driving (E2E-AD) has emerged as a promising paradigm
that unifies perception, prediction, and planning into a holistic, data-driven
framework. However, achieving robustness to varying camera viewpoints, a common
real-world challenge due to diverse vehicle configurations, remains an open
problem. In this work, we propose VR-Drive, a novel E2E-AD framework that
addresses viewpoint generalization by jointly learning 3D scene reconstruction
as an auxiliary task to enable planning-aware view synthesis. Unlike prior
scene-specific synthesis approaches, VR-Drive adopts a feed-forward inference
strategy that supports online training-time augmentation from sparse views
without additional annotations. To further improve viewpoint consistency, we
introduce a viewpoint-mixed memory bank that facilitates temporal interaction
across multiple viewpoints and a viewpoint-consistent distillation strategy
that transfers knowledge from original to synthesized views. Trained in a fully
end-to-end manner, VR-Drive effectively mitigates synthesis-induced noise and
improves planning under viewpoint shifts. In addition, we release a new
benchmark dataset to evaluate E2E-AD performance under novel camera viewpoints,
enabling comprehensive analysis. Our results demonstrate that VR-Drive is a
scalable and robust solution for the real-world deployment of end-to-end
autonomous driving systems.

</details>


### [175] [Accurate and Scalable Multimodal Pathology Retrieval via Attentive Vision-Language Alignment](https://arxiv.org/abs/2510.23224)
*Hongyi Wang,Zhengjie Zhu,Jiabo Ma,Fang Wang,Yue Shi,Bo Luo,Jili Wang,Qiuyu Cai,Xiuming Zhang,Yen-Wei Chen,Lanfen Lin,Hao Chen*

Main category: cs.CV

TL;DR: PathSearch是一个统一了细粒度注意力马赛克表示和通过视觉语言对比学习对齐的全局幻灯片嵌入的检索框架，能够进行图像到图像和多模态检索，并在多个数据集上进行了严格评估，证明了其在数字病理学中的有效性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 为了解决全切片图像（WSI）因其千兆像素的规模以及在大量无关内容中捕捉细微语义差异的难度而带来的检索挑战，需要一种能够捕捉细粒度形态学线索和高级语义模式的检索框架。

Method: PathSearch框架整合了细粒度注意力马赛克表示和通过视觉语言对比学习对齐的全局幻灯片嵌入。它使用包含6,926个病例/报告对语料库进行训练，支持基于马赛克的图像到图像检索和文本查询的多模态检索。

Result: PathSearch在四个公共病理数据集和三个内部队列上进行了评估，在解剖部位检索、肿瘤分型、肿瘤与非肿瘤鉴别和分级等任务中表现优于传统图像到图像检索框架。多中心研究者研究表明，PathSearch在真实临床场景中提高了诊断准确性、增强了信心和提高了观察者之间的一致性。

Conclusion: PathSearch是一个可扩展且可推广的数字病理学检索解决方案，它通过结合细粒度形态学和高层语义信息，有效地解决了全切片图像检索的挑战，并在临床应用中显示出显著的优势。

Abstract: The rapid digitization of histopathology slides has opened up new
possibilities for computational tools in clinical and research workflows. Among
these, content-based slide retrieval stands out, enabling pathologists to
identify morphologically and semantically similar cases, thereby supporting
precise diagnoses, enhancing consistency across observers, and assisting
example-based education. However, effective retrieval of whole slide images
(WSIs) remains challenging due to their gigapixel scale and the difficulty of
capturing subtle semantic differences amid abundant irrelevant content. To
overcome these challenges, we present PathSearch, a retrieval framework that
unifies fine-grained attentive mosaic representations with global-wise slide
embeddings aligned through vision-language contrastive learning. Trained on a
corpus of 6,926 slide-report pairs, PathSearch captures both fine-grained
morphological cues and high-level semantic patterns to enable accurate and
flexible retrieval. The framework supports two key functionalities: (1)
mosaic-based image-to-image retrieval, ensuring accurate and efficient slide
research; and (2) multi-modal retrieval, where text queries can directly
retrieve relevant slides. PathSearch was rigorously evaluated on four public
pathology datasets and three in-house cohorts, covering tasks including
anatomical site retrieval, tumor subtyping, tumor vs. non-tumor discrimination,
and grading across diverse organs such as breast, lung, kidney, liver, and
stomach. External results show that PathSearch outperforms traditional
image-to-image retrieval frameworks. A multi-center reader study further
demonstrates that PathSearch improves diagnostic accuracy, boosts confidence,
and enhances inter-observer agreement among pathologists in real clinical
scenarios. These results establish PathSearch as a scalable and generalizable
retrieval solution for digital pathology.

</details>


### [176] [Through the Lens: Benchmarking Deepfake Detectors Against Moiré-Induced Distortions](https://arxiv.org/abs/2510.23225)
*Razaib Tariq,Minji Heo,Simon S. Woo,Shahroz Tariq*

Main category: cs.CV

TL;DR: Moiré 伪影会显著降低深度伪影检测器的性能，特别是在智能手机拍摄的视频中。本研究评估了各种检测器在受 Moiré 影响的视频上的表现，并引入了一个新的数据集 DMF 来促进未来的研究。


<details>
  <summary>Details</summary>
Motivation: 深度伪影检测在现实世界中面临挑战，智能手机拍摄的视频中的 Moiré 伪影会影响检测结果。本研究旨在评估现有深度伪影检测器在 Moiré 伪影存在下的表现，并研究 Moiré 伪影对检测性能的影响。

Method: 收集了包含 Moiré 伪影的视频数据集，并使用 DMF 数据集和两种合成 Moiré 生成技术对 15 种领先的深度伪影检测器进行了评估。同时，还评估了去 Moiré 方法对检测性能的影响。

Result: Moiré 伪影使深度伪影检测器的性能下降高达 25.4%，而合成 Moiré 模式则导致准确率下降 21.4%。去 Moiré 方法反而使准确率下降了高达 17.2%。

Conclusion: 现有的深度伪影检测模型在处理 Moiré 伪影方面存在不足，需要开发能够鲁棒处理 Moiré 伪影以及其他现实世界挑战（如压缩、锐化和模糊）的检测模型。DMF 数据集的引入旨在推动相关研究，缩小实际应用与受控实验之间的差距。

Abstract: Deepfake detection remains a pressing challenge, particularly in real-world
settings where smartphone-captured media from digital screens often introduces
Moir\'e artifacts that can distort detection outcomes. This study
systematically evaluates state-of-the-art (SOTA) deepfake detectors on
Moir\'e-affected videos, an issue that has received little attention. We
collected a dataset of 12,832 videos, spanning 35.64 hours, from the Celeb-DF,
DFD, DFDC, UADFV, and FF++ datasets, capturing footage under diverse real-world
conditions, including varying screens, smartphones, lighting setups, and camera
angles. To further examine the influence of Moir\'e patterns on deepfake
detection, we conducted additional experiments using our DeepMoir\'eFake,
referred to as (DMF) dataset and two synthetic Moir\'e generation techniques.
Across 15 top-performing detectors, our results show that Moir\'e artifacts
degrade performance by as much as 25.4%, while synthetically generated Moir\'e
patterns lead to a 21.4% drop in accuracy. Surprisingly, demoir\'eing methods,
intended as a mitigation approach, instead worsened the problem, reducing
accuracy by up to 17.2%. These findings underscore the urgent need for
detection models that can robustly handle Moir\'e distortions alongside other
realworld challenges, such as compression, sharpening, and blurring. By
introducing the DMF dataset, we aim to drive future research toward closing the
gap between controlled experiments and practical deepfake detection.

</details>


### [177] [Autoregressive Styled Text Image Generation, but Make it Reliable](https://arxiv.org/abs/2510.23240)
*Carmine Zaccagnino,Fabio Quattrini,Vittorio Pippi,Silvia Cascianelli,Alessio Tonioni,Rita Cucchiara*

Main category: cs.CV

TL;DR: Eruku是一个新的手写文本生成模型，通过多模态提示条件生成，解决了现有模型的不足，提高了生成文本的忠实度和内容一致性。


<details>
  <summary>Details</summary>
Motivation: 生成忠实且可读的风格化文本图像（特别是手写文本生成-HTG）是一个开放性问题，在图形设计、文档理解和图像编辑等领域有多种应用。现有研究主要集中在重现给定书写者的风格特征，而最近提出的HTG自回归Transformer范式在风格保真度和泛化性方面取得了有希望的结果。然而，该方法需要额外的输入，缺乏适当的停止机制，并可能陷入重复循环，产生视觉伪影。

Method: 将HTG重新表述为多模态提示条件生成任务，并通过引入特殊的文本输入标记来解决内容可控性问题，以更好地与视觉标记对齐。此外，还设计了一种基于分类器-无引导的策略。

Result: 通过广泛的实验验证，与之前的解决方案相比，该方法（Eruku）需要更少的输入，能更好地泛化到未见过的风格，并且更忠实地遵循文本提示，提高了内容一致性。

Conclusion: Eruku在手写文本生成方面取得了显著的进步，解决了现有方法的局限性，并在多个方面优于先前的方法。

Abstract: Generating faithful and readable styled text images (especially for Styled
Handwritten Text generation - HTG) is an open problem with several possible
applications across graphic design, document understanding, and image editing.
A lot of research effort in this task is dedicated to developing strategies
that reproduce the stylistic characteristics of a given writer, with promising
results in terms of style fidelity and generalization achieved by the recently
proposed Autoregressive Transformer paradigm for HTG. However, this method
requires additional inputs, lacks a proper stop mechanism, and might end up in
repetition loops, generating visual artifacts. In this work, we rethink the
autoregressive formulation by framing HTG as a multimodal prompt-conditioned
generation task, and tackle the content controllability issues by introducing
special textual input tokens for better alignment with the visual ones.
Moreover, we devise a Classifier-Free-Guidance-based strategy for our
autoregressive model. Through extensive experimental validation, we demonstrate
that our approach, dubbed Eruku, compared to previous solutions requires fewer
inputs, generalizes better to unseen styles, and follows more faithfully the
textual prompt, improving content adherence.

</details>


### [178] [Progressive Growing of Patch Size: Curriculum Learning for Accelerated and Improved Medical Image Segmentation](https://arxiv.org/abs/2510.23241)
*Stefan M. Fischer,Johannes Kiechle,Laura Daza,Lina Felsner,Richard Osuala,Daniel M. Lang,Karim Lekadir,Jan C. Peeken,Julia A. Schnabel*

Main category: cs.CV

TL;DR: 提出一种名为“渐进式增长块大小”的自动课程学习方法，用于3D医学图像分割，在不牺牲性能的情况下提高了训练效率，并对多种分割任务和模型进行了验证。


<details>
  <summary>Details</summary>
Motivation: 为了提高3D医学图像分割的效率和性能，特别是针对类别不平衡的问题，并加速训练过程。

Method: 渐进式增长块大小（Progressive Growing of Patch Size）：在模型训练过程中逐步增加块的大小，以改善小块大小时的类别平衡并加速收敛。评估了资源高效模式和性能模式。

Result: 资源高效模式在与传统方法相当的Dice分数下，训练时间减少了56%（仅为44%）。性能模式在Dice分数上提高了1.28%，并将训练时间减少到89%，同时在所有15个任务中都优于基线。在类别不平衡的任务（如病灶分割）中效果尤为显著。性能模式还提高了模型比较的可靠性，降低了性能方差。该方法不依赖于特定架构，可应用于UNet、UNETR和SwinUNETR等多种模型。

Conclusion: 渐进式增长块大小是一种简单而有效的策略，可以显著提高3D医学图像分割的Dice分数和训练时间，并且适用于多种分割模型。

Abstract: In this work, we introduce Progressive Growing of Patch Size, an automatic
curriculum learning approach for 3D medical image segmentation. Our approach
progressively increases the patch size during model training, resulting in an
improved class balance for smaller patch sizes and accelerated convergence of
the training process. We evaluate our curriculum approach in two settings: a
resource-efficient mode and a performance mode, both regarding Dice score
performance and computational costs across 15 diverse and popular 3D medical
image segmentation tasks. The resource-efficient mode matches the Dice score
performance of the conventional constant patch size sampling baseline with a
notable reduction in training time to only 44%. The performance mode improves
upon constant patch size segmentation results, achieving a statistically
significant relative mean performance gain of 1.28% in Dice Score. Remarkably,
across all 15 tasks, our proposed performance mode manages to surpass the
constant patch size baseline in Dice Score performance, while simultaneously
reducing training time to only 89%. The benefits are particularly pronounced
for highly imbalanced tasks such as lesion segmentation tasks. Rigorous
experiments demonstrate that our performance mode not only improves mean
segmentation performance but also reduces performance variance, yielding more
trustworthy model comparison. Furthermore, our findings reveal that the
proposed curriculum sampling is not tied to a specific architecture but
represents a broadly applicable strategy that consistently boosts performance
across diverse segmentation models, including UNet, UNETR, and SwinUNETR. In
summary, we show that this simple yet elegant transformation on input data
substantially improves both Dice Score performance and training runtime, while
being compatible across diverse segmentation backbones.

</details>


### [179] [A Video Is Not Worth a Thousand Words](https://arxiv.org/abs/2510.23253)
*Sam Pollard,Michael Wray*

Main category: cs.CV

TL;DR: 该研究提出了一种基于 Shapley 值的联合计算特征归因和模态得分的方法，用于评估视觉语言模型（VLM）在视频问答（VQA）任务上的表现，并指出当前模型存在文本依赖性问题，且多项选择 VQA 任务易退化为模型忽略干扰项的能力。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型（VLM）在视频问答（VQA）任务中存在文本主导问题，且跨模态交互的研究尚不充分，需要新的评估方法来衡量模型进展。

Method: 提出一种基于 Shapley 值的联合计算方法，用于计算特征归因和模态得分，将视频帧和文本元素视为同等特征，并将多项选择 VQA 任务视为视频、问题和答案三种模态间的交互。

Result: 通过在 4 个数据集上比较 6 个不同上下文长度的 VLM 模型，结果表明模型存在对文本的依赖性，并且多项选择 VQA 任务的评估效果不佳，因为它主要考察模型忽略干扰项的能力。

Conclusion: 现有的 VLM 在 VQA 任务中过度依赖文本信息，且多项选择 VQA 任务的设计未能有效评估模型真正的多模态理解能力。

Abstract: As we become increasingly dependent on vision language models (VLMs) to
answer questions about the world around us, there is a significant amount of
research devoted to increasing both the difficulty of video question answering
(VQA) datasets, and the context lengths of the models that they evaluate. The
reliance on large language models as backbones has lead to concerns about
potential text dominance, and the exploration of interactions between
modalities is underdeveloped. How do we measure whether we're heading in the
right direction, with the complexity that multi-modal models introduce? We
propose a joint method of computing both feature attributions and modality
scores based on Shapley values, where both the features and modalities are
arbitrarily definable. Using these metrics, we compare $6$ VLM models of
varying context lengths on $4$ representative datasets, focusing on
multiple-choice VQA. In particular, we consider video frames and whole textual
elements as equal features in the hierarchy, and the multiple-choice VQA task
as an interaction between three modalities: video, question and answer. Our
results demonstrate a dependence on text and show that the multiple-choice VQA
task devolves into a model's ability to ignore distractors. Code available at
https://github.com/sjpollard/a-video-is-not-worth-a-thousand-words.

</details>


### [180] [hYOLO Model: Enhancing Object Classification with Hierarchical Context in YOLOv8](https://arxiv.org/abs/2510.23278)
*Veska Tsenkova,Peter Stanchev,Daniel Petrov,Deyan Lazarov*

Main category: cs.CV

TL;DR: 提出了一种端到端的用于图像检测和分类的 PPO 模型，该模型能够处理真实世界中存在的对象层次结构。


<details>
  <summary>Details</summary>
Motivation: 真实世界的物体通常具有自然的层次结构，这可以极大地帮助分类任务，并且能够捕捉物体间的关系，从而实现更好的上下文理解和控制错误严重性。

Method: 提出了一种新颖的 PPO 模型，包括层次结构、修改后的损失函数以及针对模型层次性质定制的性能指标。该模型基于 YOLO 模型家族构建，并进行了端到端训练和评估。

Result: 所提出的方法能够处理真实世界物体中固有的层次结构，而这通常是传统平坦分类算法所忽略的。

Conclusion: 基于 YOLO 的 PPO 模型在处理具有挑战性的数据集时，能够有效地利用对象的层次结构，从而提高图像检测和分类的性能。

Abstract: Current convolution neural network (CNN) classification methods are
predominantly focused on flat classification which aims solely to identify a
specified object within an image. However, real-world objects often possess a
natural hierarchical organization that can significantly help classification
tasks. Capturing the presence of relations between objects enables better
contextual understanding as well as control over the severity of mistakes.
Considering these aspects, this paper proposes an end-to-end hierarchical model
for image detection and classification built upon the YOLO model family. A
novel hierarchical architecture, a modified loss function, and a performance
metric tailored to the hierarchical nature of the model are introduced. The
proposed model is trained and evaluated on two different hierarchical
categorizations of the same dataset: a systematic categorization that
disregards visual similarities between objects and a categorization accounting
for common visual characteristics across classes. The results illustrate how
the suggested methodology addresses the inherent hierarchical structure present
in real-world objects, which conventional flat classification algorithms often
overlook.

</details>


### [181] [Adaptive Stochastic Coefficients for Accelerating Diffusion Sampling](https://arxiv.org/abs/2510.23285)
*Ruoyu Wang,Beier Zhu,Junzhi Li,Liangyu Yuan,Chi Zhang*

Main category: cs.CV

TL;DR: AdaSDE通过引入一个可学习的系数，在单个SDE求解步中平衡计算速度和样本质量，实现了生成模型的先进性能。


<details>
  <summary>Details</summary>
Motivation: ODE和SDE求解器在计算速度和样本质量之间存在固有的权衡：ODE求解器会累积不可约的梯度误差，而SDE求解器在有限步数下会放大离散化误差。

Method: 提出AdaSDE，一种新颖的单步SDE求解器，通过一个通过轻量级蒸馏估计的可学习系数，动态调节误差校正强度，以加速扩散采样。该方法可以与现有求解器集成。

Result: 在CIFAR-10、FFHQ和LSUN Bedroom数据集上，AdaSDE在仅5次模型评估（NFE）的情况下，取得了4.18、8.05和6.96的FID分数，达到了最先进的性能。

Conclusion: AdaSDE通过一种新颖的单步SDE求解方法，有效解决了现有扩散模型求解器的局限性，并在速度和样本质量上取得了显著的提升。

Abstract: Diffusion-based generative processes, formulated as differential equation
solving, frequently balance computational speed with sample quality. Our
theoretical investigation of ODE- and SDE-based solvers reveals complementary
weaknesses: ODE solvers accumulate irreducible gradient error along
deterministic trajectories, while SDE methods suffer from amplified
discretization errors when the step budget is limited. Building upon this
insight, we introduce AdaSDE, a novel single-step SDE solver that aims to unify
the efficiency of ODEs with the error resilience of SDEs. Specifically, we
introduce a single per-step learnable coefficient, estimated via lightweight
distillation, which dynamically regulates the error correction strength to
accelerate diffusion sampling. Notably, our framework can be integrated with
existing solvers to enhance their capabilities. Extensive experiments
demonstrate state-of-the-art performance: at 5 NFE, AdaSDE achieves FID scores
of 4.18 on CIFAR-10, 8.05 on FFHQ and 6.96 on LSUN Bedroom. Codes are available
in https://github.com/WLU-wry02/AdaSDE.

</details>


### [182] [MMSD3.0: A Multi-Image Benchmark for Real-World Multimodal Sarcasm Detection](https://arxiv.org/abs/2510.23299)
*Haochen Zhao,Yuyao Kong,Yongxiu Xu,Gaopeng Gou,Hongbo Xu,Yubin Wang,Haoliang Zhang*

Main category: cs.CV

TL;DR: 本研究提出了MMSD3.0多图模态讽刺检测数据集和跨图像推理模型(CIRM)，以解决现有数据集侧重于单图场景的不足。


<details>
  <summary>Details</summary>
Motivation: 现有模态讽刺检测方法主要关注单图场景，忽略了多图之间的潜在语义和情感联系，这与真实世界中多图线索引发讽刺的现象不符。

Method: 提出MMSD3.0数据集，该数据集完全由推特和亚马逊评论中的多图样本构成。提出跨图像推理模型(CIRM)，该模型进行有针对性的跨图像序列建模以捕捉图像间的潜在联系。引入基于图文对应关系的、相关性引导的细粒度跨模态融合机制，以减少信息整合过程中的损失。

Result: 在MMSD、MMSD2.0和MMSD3.0数据集上进行了广泛的实验，证明了MMSD3.0作为基准的有效性和可靠性，更能反映真实世界的情况。CIRM在所有三个数据集上均取得了最先进的性能，验证了其在单图和多图场景下的有效性。

Conclusion: MMSD3.0数据集和CIRM模型能够有效解决现有模态讽刺检测中多图线索被忽略的问题，并在单图和多图场景下均取得了领先的性能。

Abstract: Despite progress in multimodal sarcasm detection, existing datasets and
methods predominantly focus on single-image scenarios, overlooking potential
semantic and affective relations across multiple images. This leaves a gap in
modeling cases where sarcasm is triggered by multi-image cues in real-world
settings. To bridge this gap, we introduce MMSD3.0, a new benchmark composed
entirely of multi-image samples curated from tweets and Amazon reviews. We
further propose the Cross-Image Reasoning Model (CIRM), which performs targeted
cross-image sequence modeling to capture latent inter-image connections. In
addition, we introduce a relevance-guided, fine-grained cross-modal fusion
mechanism based on text-image correspondence to reduce information loss during
integration. We establish a comprehensive suite of strong and representative
baselines and conduct extensive experiments, showing that MMSD3.0 is an
effective and reliable benchmark that better reflects real-world conditions.
Moreover, CIRM demonstrates state-of-the-art performance across MMSD, MMSD2.0
and MMSD3.0, validating its effectiveness in both single-image and multi-image
scenarios.

</details>


### [183] [MDReID: Modality-Decoupled Learning for Any-to-Any Multi-Modal Object Re-Identification](https://arxiv.org/abs/2510.23301)
*Yingying Feng,Jie Li,Jie Hu,Yukang Zhang,Lei Tan,Jiayi Ji*

Main category: cs.CV

TL;DR: MDReID是一个灵活的任意对任意图像ReID框架，可以处理模态匹配和不匹配的情况，通过解耦模态共享和特定特征，并结合模态感知度量学习，在多个基准测试中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的ReID方法在处理跨传感器（如RGB、NIR、TIR）的模态不一致问题时鲁棒性和可扩展性有限，而MDReID旨在解决此挑战。

Method: MDReID提出了一种新颖的框架，包含两个关键组件：模态解耦学习（MDL）和模态感知度量学习（MML）。MDL将模态特征分解为模态共享和模态特定表示；MML则通过强制这两个组件之间的正交性和互补性来提高跨模态的区分能力。

Result: 在RGBNT201、RGBNT100和MSVR310三个多模态ReID基准测试中，MDReID在模态匹配场景下分别取得了9.8%、3.0%和11.5%的mAP提升，在模态不匹配场景下平均提升分别为3.4%、11.8%和10.9%。

Conclusion: MDReID在模态匹配和不匹配的条件下都表现出色，显著优于现有方法，展示了其在实际应用中的鲁棒性和可扩展性。

Abstract: Real-world object re-identification (ReID) systems often face modality
inconsistencies, where query and gallery images come from different sensors
(e.g., RGB, NIR, TIR). However, most existing methods assume modality-matched
conditions, which limits their robustness and scalability in practical
applications. To address this challenge, we propose MDReID, a flexible
any-to-any image-level ReID framework designed to operate under both
modality-matched and modality-mismatched scenarios. MDReID builds on the
insight that modality information can be decomposed into two components:
modality-shared features that are predictable and transferable, and
modality-specific features that capture unique, modality-dependent
characteristics. To effectively leverage this, MDReID introduces two key
components: the Modality Decoupling Learning (MDL) and Modality-aware Metric
Learning (MML). Specifically, MDL explicitly decomposes modality features into
modality-shared and modality-specific representations, enabling effective
retrieval in both modality-aligned and mismatched scenarios. MML, a tailored
metric learning strategy, further enforces orthogonality and complementarity
between the two components to enhance discriminative power across modalities.
Extensive experiments conducted on three challenging multi-modality ReID
benchmarks (RGBNT201, RGBNT100, MSVR310) consistently demonstrate the
superiority of MDReID. Notably, MDReID achieves significant mAP improvements of
9.8\%, 3.0\%, and 11.5\% in general modality-matched scenarios, and average
gains of 3.4\%, 11.8\%, and 10.9\% in modality-mismatched scenarios,
respectively. The code is available at:
\textcolor{magenta}{https://github.com/stone96123/MDReID}.

</details>


### [184] [ReconViaGen: Towards Accurate Multi-view 3D Object Reconstruction via Generation](https://arxiv.org/abs/2510.23306)
*Jiahao Chang,Chongjie Ye,Yushuang Wu,Yuantao Chen,Yidan Zhang,Zhongjin Luo,Chenghong Li,Yihao Zhi,Xiaoguang Han*

Main category: cs.CV

TL;DR: 现有的多视角三维物体重建方法依赖于充足的视角重叠，但在实际应用中，遮挡和稀疏覆盖常常导致重建不完整。扩散模型在三维生成方面展现了潜力，可以利用学习到的生成先验来推断物体不可见部分。然而，其随机性限制了生成结果的准确性和可靠性，使得现有重建框架难以整合这些生成先验。本文分析了扩散模型在三维重建中不一致的原因，包括（a）在提取多视角图像特征作为条件时，跨视图连接的构建和利用不足，以及（b）迭代去噪在局部细节生成中的可控性差，容易导致与输入不一致的细节。为此，我们提出了ReconViaGen，将重建先验整合到生成框架中，并提出了有效解决这些问题的策略。实验证明，ReconViaGen能够重建与输入视图在整体结构和局部细节上都一致的完整、准确的三维模型。


<details>
  <summary>Details</summary>
Motivation: 现有的多视角三维物体重建方法在处理遮挡和稀疏覆盖时存在重建不完整的问题。虽然扩散模型可以生成三维结构，但其随机性限制了重建的准确性和可靠性。因此，需要一种方法来整合重建先验到生成框架中，以提高重建的完整性和准确性。

Method: 本文分析了扩散模型在三维重建中不一致的原因，包括跨视图连接的构建和利用不足，以及迭代去噪在局部细节生成中的可控性差。在此基础上，提出了ReconViaGen，将重建先验整合到生成框架中，并 devised several strategies 来解决这些问题。

Result: 通过大量实验证明，ReconViaGen 能够重建完整且准确的三维模型，并且在整体结构和局部细节上都与输入视图保持一致。

Conclusion: ReconViaGen 能够有效地解决现有方法在多视角三维物体重建中遇到的挑战，通过整合生成先验和重建先验，实现了更高质量和更一致的三维重建。

Abstract: Existing multi-view 3D object reconstruction methods heavily rely on
sufficient overlap between input views, where occlusions and sparse coverage in
practice frequently yield severe reconstruction incompleteness. Recent
advancements in diffusion-based 3D generative techniques offer the potential to
address these limitations by leveraging learned generative priors to
hallucinate invisible parts of objects, thereby generating plausible 3D
structures. However, the stochastic nature of the inference process limits the
accuracy and reliability of generation results, preventing existing
reconstruction frameworks from integrating such 3D generative priors. In this
work, we comprehensively analyze the reasons why diffusion-based 3D generative
methods fail to achieve high consistency, including (a) the insufficiency in
constructing and leveraging cross-view connections when extracting multi-view
image features as conditions, and (b) the poor controllability of iterative
denoising during local detail generation, which easily leads to plausible but
inconsistent fine geometric and texture details with inputs. Accordingly, we
propose ReconViaGen to innovatively integrate reconstruction priors into the
generative framework and devise several strategies that effectively address
these issues. Extensive experiments demonstrate that our ReconViaGen can
reconstruct complete and accurate 3D models consistent with input views in both
global structure and local details.Project page:
https://jiahao620.github.io/reconviagen.

</details>


### [185] [Multitask Multimodal Self-Supervised Learning for Medical Images](https://arxiv.org/abs/2510.23325)
*Cristian Simionescu*

Main category: cs.CV

TL;DR: 本论文提出了一种名为Medformer的新型自监督学习和域适应方法，以解决医学图像分析中对大量标注数据的依赖问题，并能在不同模态和尺寸的医学图像上进行预训练，同时提高了模型对不同类型医学图像的处理能力。


<details>
  <summary>Details</summary>
Motivation: 医学图像分析中存在对大量标注数据的依赖，而标注数据获取成本高、受隐私和法律限制。本研究旨在通过自监督学习和域适应方法来解决这些局限性。

Method: 开发了名为Medformer的新型神经网络架构，支持多任务学习和深度域适应。该模型能够处理不同尺寸和模态的医学图像，并具有动态输入输出适应机制。此外，还探索了自监督学习在医学成像中的应用，并引入了新的具有挑战性的任务，以从无标签数据中提取有意义的信息。

Result: 通过在MedMNIST数据集上进行实验验证，证明了Medformer模型在学习通用特征方面具有很强的能力，能够应用于各种下游任务，并有效解决了对大量标注数据的依赖问题。

Conclusion: 本论文为医学图像分析领域提供了可扩展、自适应的框架，减少了对标注数据的依赖，为医疗保健领域更准确、更高效的诊断工具铺平了道路，是深度学习在医学成像应用中的重要进展。

Abstract: This thesis works to address a pivotal challenge in medical image analysis:
the reliance on extensive labeled datasets, which are often limited due to the
need for expert annotation and constrained by privacy and legal issues. By
focusing on the development of self-supervised learning techniques and domain
adaptation methods, this research aims to circumvent these limitations,
presenting a novel approach to enhance the utility and efficacy of deep
learning in medical imaging.
  Central to this thesis is the development of the Medformer, an innovative
neural network architecture designed for multitask learning and deep domain
adaptation. This model is adept at pre-training on diverse medical image
datasets, handling varying sizes and modalities, and is equipped with a dynamic
input-output adaptation mechanism. This enables efficient processing and
integration of a wide range of medical image types, from 2D X-rays to complex
3D MRIs, thus mitigating the dependency on large labeled datasets.
  Further, the thesis explores the current state of self-supervised learning in
medical imaging. It introduces novel pretext tasks that are capable of
extracting meaningful information from unlabeled data, significantly advancing
the model's interpretative abilities. This approach is validated through
rigorous experimentation, including the use of the MedMNIST dataset,
demonstrating the model's proficiency in learning generalized features
applicable to various downstream tasks.
  In summary, this thesis contributes to the advancement of medical image
analysis by offering a scalable, adaptable framework that reduces reliance on
labeled data. It paves the way for more accurate, efficient diagnostic tools in
healthcare, signifying a major step forward in the application of deep learning
in medical imaging.

</details>


### [186] [Interpretable Tile-Based Classification of Paclitaxel Exposure](https://arxiv.org/abs/2510.23363)
*Sean Fletcher,Gabby Scott,Douglas Currie,Xin Zhang,Yuqi Song,Bruce MacLeod*

Main category: cs.CV

TL;DR: 该研究提出了一种基于图像块 tiling-and-aggregation 的方法，用于从相差显微镜图像中对紫杉醇（Taxol）暴露进行分类，并在 C6 胶质瘤细胞上取得了最先进的准确性。


<details>
  <summary>Details</summary>
Motivation: 在药物发现和临床前评估中，医学图像分析对于加速决策至关重要，然而，相差显微镜图像中紫杉醇暴露（Taxol）的细微剂量差异对全图像模型提出了挑战。

Method: 提出了一种简单的 tiling-and-aggregation 流水线，该流水线操作于局部图像块，并将图像块的输出组合成图像标签。

Result: 该方法在基准数据集上实现了最先进的准确性，比已发布的基线提高了约 20 个百分点，并且交叉验证证实了这种趋势。此外，Grad-CAM 和 Score-CAM 及注意力分析增强了模型的可解释性。

Conclusion: 研究提出的 tiling-and-aggregation 方法在紫杉醇暴露分类任务中表现出色，并且通过可解释性分析为未来的医学图像研究指明了方向。

Abstract: Medical image analysis is central to drug discovery and preclinical
evaluation, where scalable, objective readouts can accelerate decision-making.
We address classification of paclitaxel (Taxol) exposure from phase-contrast
microscopy of C6 glioma cells -- a task with subtle dose differences that
challenges full-image models. We propose a simple tiling-and-aggregation
pipeline that operates on local patches and combines tile outputs into an image
label, achieving state-of-the-art accuracy on the benchmark dataset and
improving over the published baseline by around 20 percentage points, with
trends confirmed by cross-validation. To understand why tiling is effective, we
further apply Grad-CAM and Score-CAM and attention analyses, which enhance
model interpretability and point toward robustness-oriented directions for
future medical image research. Code is released to facilitate reproduction and
extension.

</details>


### [187] [PlanarTrack: A high-quality and challenging benchmark for large-scale planar object tracking](https://arxiv.org/abs/2510.23368)
*Yifan Jiao,Xinran Liu,Xiaoqiong Liu,Xiaohui Yuan,Heng Fan,Libo Zhang*

Main category: cs.CV

TL;DR: PlanarTrack是一个大规模、高质量、具有挑战性的平面跟踪基准，包含1150个序列（733K帧），旨在推动机器人和增强现实领域的平面跟踪技术发展。


<details>
  <summary>Details</summary>
Motivation: 现有的平面跟踪方法在深度学习时代由于缺乏大规模数据集而受到限制，因此需要一个更具挑战性、更真实的数据集来推动该领域的发展。

Method: 构建了一个包含1150个序列（1000个短期，150个长期）的大规模数据集PlanarTrack，所有视频均在真实世界条件下录制，并经过手动标注和多轮审核。同时，对10种代表性的平面跟踪方法进行了评估和分析。

Result: 现有的顶级平面跟踪方法在PlanarTrack数据集上面临性能显著下降，表明需要进一步的研究来改进平面跟踪技术。

Conclusion: PlanarTrack是迄今为止最大、最多样化、最具挑战性的平面跟踪数据集，其评估结果揭示了当前平面跟踪技术的局限性，并为未来的研究提供了基准。

Abstract: Planar tracking has drawn increasing interest owing to its key roles in
robotics and augmented reality. Despite recent great advancement, further
development of planar tracking, particularly in the deep learning era, is
largely limited compared to generic tracking due to the lack of large-scale
platforms. To mitigate this, we propose PlanarTrack, a large-scale high-quality
and challenging benchmark for planar tracking. Specifically, PlanarTrack
consists of 1,150 sequences with over 733K frames, including 1,000 short-term
and 150 new long-term videos, which enables comprehensive evaluation of short-
and long-term tracking performance. All videos in PlanarTrack are recorded in
unconstrained conditions from the wild, which makes PlanarTrack challenging but
more realistic for real-world applications. To ensure high-quality annotations,
each video frame is manually annotated by four corner points with multi-round
meticulous inspection and refinement. To enhance target diversity of
PlanarTrack, we only capture a unique target in one sequence, which is
different from existing benchmarks. To our best knowledge, PlanarTrack is by
far the largest and most diverse and challenging dataset dedicated to planar
tracking. To understand performance of existing methods on PlanarTrack and to
provide a comparison for future research, we evaluate 10 representative planar
trackers with extensive comparison and in-depth analysis. Our evaluation
reveals that, unsurprisingly, the top planar trackers heavily degrade on the
challenging PlanarTrack, which indicates more efforts are required for
improving planar tracking. Our data and results will be released at
https://github.com/HengLan/PlanarTrack

</details>


### [188] [An Efficient Remote Sensing Super Resolution Method Exploring Diffusion Priors and Multi-Modal Constraints for Crop Type Mapping](https://arxiv.org/abs/2510.23382)
*Songxi Yang,Tang Sui,Qunying Huang*

Main category: cs.CV

TL;DR: LSSR是一个用于遥感影像超分辨率（RSSR）的高效框架，它利用预训练的Stable Diffusion模型，并结合多模态数据（Landsat 8和Sentinel 2）、辅助知识（DEM、土地覆盖、月份）以及SAR数据，通过适配器和傅里叶NDVI损失来提升图像的空间细节和光谱保真度。该方法在训练和推理效率上表现出色，并在农作物边界提取和分类等下游任务中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的遥感影像超分辨率（RSSR）方法，特别是基于扩散模型的，存在训练成本高、推理速度慢、对辅助信息利用不足以及缺乏下游任务评估等问题。

Method: 提出了一种名为LSSR的高效RSSR框架。该框架基于冻结的预训练Stable Diffusion模型，并引入了跨模态注意力机制，整合了数字高程模型（DEM）、土地覆盖和月份等辅助知识，以及合成孔径雷达（SAR）数据。通过适配器（adapters）和定制的傅里叶NDVI损失函数来优化空间细节和光谱保真度。

Result: LSSR在农作物边界提取和恢复方面显著提高了性能，在RGB和IR波段分别取得了32.63/0.84和23.99/0.78的峰值信噪比/结构相似性指数（PSNR/SSIM）。同时，NDVI均方根误差（MSE）最低（0.042）。推理速度高效，每张图像仅需0.39秒。此外，LSSR在NASA Harmonized Landsat and Sentinel (HLS) 数据集上的超分辨率任务中表现出良好的迁移能力，生成的图像在农作物分类任务中（F1分数：0.86）优于单独的Sentinel-2数据（F1分数：0.85）。

Conclusion: LSSR通过有效利用多模态数据和辅助知识，克服了现有RSSR方法的局限性，实现了高效且高性能的遥感影像超分辨率。该研究证明了RSSR在推动精准农业发展方面的潜力。

Abstract: Super resolution offers a way to harness medium even lowresolution but
historically valuable remote sensing image archives. Generative models,
especially diffusion models, have recently been applied to remote sensing super
resolution (RSSR), yet several challenges exist. First, diffusion models are
effective but require expensive training from scratch resources and have slow
inference speeds. Second, current methods have limited utilization of auxiliary
information as real-world constraints to reconstruct scientifically realistic
images. Finally, most current methods lack evaluation on downstream tasks. In
this study, we present a efficient LSSR framework for RSSR, supported by a new
multimodal dataset of paired 30 m Landsat 8 and 10 m Sentinel 2 imagery. Built
on frozen pretrained Stable Diffusion, LSSR integrates crossmodal attention
with auxiliary knowledge (Digital Elevation Model, land cover, month) and
Synthetic Aperture Radar guidance, enhanced by adapters and a tailored Fourier
NDVI loss to balance spatial details and spectral fidelity. Extensive
experiments demonstrate that LSSR significantly improves crop boundary
delineation and recovery, achieving state-of-the-art performance with Peak
Signal-to-Noise Ratio/Structural Similarity Index Measure of 32.63/0.84 (RGB)
and 23.99/0.78 (IR), and the lowest NDVI Mean Squared Error (0.042), while
maintaining efficient inference (0.39 sec/image). Moreover, LSSR transfers
effectively to NASA Harmonized Landsat and Sentinel (HLS) super resolution,
yielding more reliable crop classification (F1: 0.86) than Sentinel-2 (F1:
0.85). These results highlight the potential of RSSR to advance precision
agriculture.

</details>


### [189] [VideoTG-R1: Boosting Video Temporal Grounding via Curriculum Reinforcement Learning on Reflected Boundary Annotations](https://arxiv.org/abs/2510.23397)
*Lu Dong,Haiyu Zhang,Han Lin,Ziang Yan,Xiangyu Zeng,Hongjie Zhang,Yifei Huang,Yi Wang,Zhen-Hua Ling,Limin Wang,Yali Wang*

Main category: cs.CV

TL;DR: 本文提出了一种名为 VideoTG-R1 的新颖课程强化学习框架，通过引入反射边界注释来解决视频时间定位（VTG）中存在的训练样本质量和难度挑战，以实现数据高效训练。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型（MLLMs）在解决视频时间定位（VTG）问题时，忽略了训练样本的质量和难度所带来的挑战。具体来说，部分标注样本（存在标注区间之外的相关片段）引入了模糊监督，而难以定位的样本（零样本性能差）在强化学习（RL）训练中产生持续低且无差别的奖励，阻碍了学习效率。

Method: 提出了一种名为 VideoTG-R1 的课程强化学习框架。该框架包含一个边界反射代理，它利用 MLLMs 预测标注区间之外与查询相关的时戳，以识别和过滤部分标注样本，从而减少模糊性。此外，还引入了一个难度估计代理，用于评估每个样本的训练难度，并设计了一个课程强化学习策略，根据训练步数动态地屏蔽难以定位的样本视频，从而降低训练难度并提供更清晰的偏好。

Result: 在 VTG 和基础视频问答（grounded VideoQA）任务上的实验证明了该方法的有效性。在仅使用 10% 的训练样本和 21% 的计算预算的情况下，VideoTG-R1 在组相对策略优化（GRPO）和监督微调（SFT）下均优于使用全部训练样本的方法。

Conclusion: VideoTG-R1 框架能够有效地解决视频时间定位任务中由于部分标注样本和难以定位样本带来的挑战，通过数据高效的训练方法，在有限的资源下取得了优于传统方法的性能。

Abstract: Video temporal grounding (VTG) aims to locate precise segments in videos
based on language queries, which is a fundamental challenge in video
understanding. While recent Multimodal Large Language Models (MLLMs) have shown
promise in tackling VTG through reinforcement learning (RL), they overlook the
challenges arising from both the quality and difficulty of training samples.
(1) Partially annotated samples. Many samples contain relevant segments beyond
the annotated interval, introducing ambiguous supervision. (2) Hard-to-ground
samples. Samples with poor zero-shot performance produce consistently low and
indistinguishable rewards during RL training, exhibiting no clear preference
among multiple outputs and thus hindering learning efficiency. To address these
challenges, we propose VideoTG-R1, a novel curriculum RL framework with
reflected boundary annotations, enabling data-efficient training. Specifically,
we propose a Boundary Reflection Agent that utilizes MLLMs to predict
query-relevant timestamps outside the annotated intervals, allowing us to
identify and filter out partially annotated samples, thereby reducing
ambiguity. Furthermore, we introduce a Difficulty Estimation Agent to assess
the training difficulty of each sample and design a curriculum RL strategy that
dynamically masks the videos of hard-to-ground samples according to the
training steps, easing the training difficulty and providing clearer
preference. Experiments on the VTG and grounded VideoQA tasks demonstrate the
effectiveness of our method. Remarkably, with only 10% of the training samples
and 21% of the computational budget, VideoTG-R1 outperforms full-data
counterparts under both group relative policy optimization (GRPO) and
supervised fine-tuning (SFT). The code is available at
https://github.com/ldong1111/VideoTG-R1.

</details>


### [190] [Color and Frequency Correction for Image Colorization](https://arxiv.org/abs/2510.23399)
*Yun Kai Zhuang*

Main category: cs.CV

TL;DR: DDColor在图像色彩还原方面存在局限性，尤其是在某些频段和输入维度不足时会导致色偏。通过两种优化方案的结合，提升了DDColor的PSNR和SSIM指标。


<details>
  <summary>Details</summary>
Motivation: 现有DDColor模型在图像色彩还原方面存在局限性，尤其是在某些频段和输入维度不足时会导致色偏问题。

Method: 对现有DDColor模型进行了重新优化，构建了两种优化方案并进行了结合。

Result: 结合后的优化方案在PSNR和SSIM等指标上取得了性能提升。

Conclusion: 对DDColor模型进行优化，解决了其在某些频段和输入维度不足时出现的色偏问题，并提升了图像色彩还原的质量。

Abstract: The project has carried out the re-optimization of image coloring in
accordance with the existing Autocolorization direction model DDColor. For the
experiments on the existing weights of DDColor, we found that it has
limitations in some frequency bands and the color cast problem caused by
insufficient input dimension. We construct two optimization schemes and combine
them, which achieves the performance improvement of indicators such as PSNR and
SSIM of the images after DDColor.

</details>


### [191] [Symmetria: A Synthetic Dataset for Learning in Point Clouds](https://arxiv.org/abs/2510.23414)
*Ivan Sipiran,Gustavo Santelices,Lucas Oyarzún,Andrea Ranieri,Chiara Romanengo,Silvia Biasotti,Bianca Falcidieno*

Main category: cs.CV

TL;DR: Symmetria是一个大规模点云数据集，通过利用对称性生成，能够解决点云学习中数据稀缺的问题。该数据集可以按需生成，保证了地面真值的精确性，并能提高数据效率和泛化能力。实验证明，Symmetria在点云自监督预训练方面表现出色，下游任务（如分类和分割）表现优异，并具有良好的少样本学习能力。此外，该数据集还可以支持对真实世界物体进行分类的模型微调，并引入了对称性检测任务和基准测试。


<details>
  <summary>Details</summary>
Motivation: 点云学习领域普遍存在大规模数据集稀缺的问题，限制了相关技术的发展。

Method: 提出了一种名为Symmetria的公式驱动型数据集生成方法，该方法利用对称性概念生成具有已知结构和高变异性的形状，从而促进神经网路有效地学习点云特征。用户可以按任意比例生成数据集，并保证精确的地面真值。

Result: 通过Symmetria数据集进行点云自监督预训练的模型，在分类和分割等下游任务中表现出强大的性能，并且具有良好的少样本学习能力。此外，该数据集也支持对真实世界物体进行分类的模型微调。

Conclusion: Symmetria数据集的提出解决了点云学习中的数据稀缺性问题，并通过其高效性、泛化性和可扩展性，为点云自监督预训练和下游任务提供了有力支持。该数据集的公开以及生成大规模数据集的能力，将促进点云学习领域的进一步研究和创新。

Abstract: Unlike image or text domains that benefit from an abundance of large-scale
datasets, point cloud learning techniques frequently encounter limitations due
to the scarcity of extensive datasets. To overcome this limitation, we present
Symmetria, a formula-driven dataset that can be generated at any arbitrary
scale. By construction, it ensures the absolute availability of precise ground
truth, promotes data-efficient experimentation by requiring fewer samples,
enables broad generalization across diverse geometric settings, and offers easy
extensibility to new tasks and modalities. Using the concept of symmetry, we
create shapes with known structure and high variability, enabling neural
networks to learn point cloud features effectively. Our results demonstrate
that this dataset is highly effective for point cloud self-supervised
pre-training, yielding models with strong performance in downstream tasks such
as classification and segmentation, which also show good few-shot learning
capabilities. Additionally, our dataset can support fine-tuning models to
classify real-world objects, highlighting our approach's practical utility and
application. We also introduce a challenging task for symmetry detection and
provide a benchmark for baseline comparisons. A significant advantage of our
approach is the public availability of the dataset, the accompanying code, and
the ability to generate very large collections, promoting further research and
innovation in point cloud learning.

</details>


### [192] [Towards Generalisable Foundation Models for 3D Brain MRI](https://arxiv.org/abs/2510.23415)
*Moona Mazher,Geoff J. M. Parker,Daniel C. Alexander*

Main category: cs.CV

TL;DR: BrainFound是一个为脑部MRI设计的自监督基础模型，通过结合3D解剖信息和多模态输入，提高了下游任务的性能，尤其是在标签稀疏和多对比度的情况下，并有潜力用于临床部署。


<details>
  <summary>Details</summary>
Motivation: 为脑部MRI开发一个能够进行通用特征学习的自监督基础模型，以应对标签稀疏和多对比度等挑战。

Method: 扩展DINO-v2模型，使其能够处理3D脑部MRI数据，并支持单模态和多模态输入。

Result: BrainFound在疾病检测和图像分割等下游任务中，优于现有的自监督预训练策略和监督基线，尤其是在标签稀疏和多对比度设置下。

Conclusion: BrainFound是一个灵活、可扩展且实用的3D神经影像学解决方案，能够提高诊断准确性并减少对专家注释的依赖，具有重要的临床应用和研究潜力。

Abstract: Foundation models in artificial intelligence (AI) are transforming medical
imaging by enabling general-purpose feature learning from large-scale,
unlabeled datasets. In this work, we introduce BrainFound, a self-supervised
foundation model for brain MRI, built by extending DINO-v2, a vision
transformer originally designed for 2D natural images. BrainFound adapts
DINO-v2 to model full 3D brain anatomy by incorporating volumetric information
from sequential MRI slices, moving beyond conventional single-slice paradigms.
It supports both single- and multimodal inputs, enabling a broad range of
downstream tasks, including disease detection and image segmentation, while
generalising across varied imaging protocols and clinical scenarios. We show
that BrainFound consistently outperforms existing self-supervised pretraining
strategies and supervised baselines, particularly in label-scarce and
multi-contrast settings. By integrating information from diverse 3D MRI
modalities (e.g., T1, T2, FLAIR), it enhances diagnostic accuracy and reduces
dependency on extensive expert annotations. This flexibility makes BrainFound a
scalable and practical solution for 3D neuroimaging pipelines, with significant
potential for clinical deployment and research innovation.

</details>


### [193] [MiCADangelo: Fine-Grained Reconstruction of Constrained CAD Models from 3D Scans](https://arxiv.org/abs/2510.23429)
*Ahmet Serdar Karadeniz,Dimitrios Mallis,Danila Rukhovich,Kseniya Cherenkova,Anis Kacem,Djamila Aouada*

Main category: cs.CV

TL;DR: 该研究提出了一种新的CAD逆向工程方法，通过多平面交叉剖切来提取2D模式，更有效地捕捉参数化细节，并首次将草图约束纳入重建过程，以生成可编辑的CAD模型，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的CAD逆向工程方法在处理高精度和结构复杂性时存在不足，要么无法生成完全参数化的输出，要么忽略几何细节，并且忽视了CAD建模中的关键要素——草图约束。

Method: 提出一种受人类设计师启发的新方法，利用多平面交叉剖切来提取2D模式和捕捉精细的参数化细节，并将草图约束整合到重建过程中。

Result: 该方法能够重建出细节丰富且可编辑的CAD模型，并且在性能上优于现有最先进的方法。

Conclusion: 该研究成功地开发了一种新的CAD逆向工程方法，通过引入多平面交叉剖切和草图约束，解决了现有方法的局限性，实现了高质量的CAD模型重建。

Abstract: Computer-Aided Design (CAD) plays a foundational role in modern manufacturing
and product development, often requiring designers to modify or build upon
existing models. Converting 3D scans into parametric CAD representations--a
process known as CAD reverse engineering--remains a significant challenge due
to the high precision and structural complexity of CAD models. Existing deep
learning-based approaches typically fall into two categories: bottom-up,
geometry-driven methods, which often fail to produce fully parametric outputs,
and top-down strategies, which tend to overlook fine-grained geometric details.
Moreover, current methods neglect an essential aspect of CAD modeling:
sketch-level constraints. In this work, we introduce a novel approach to CAD
reverse engineering inspired by how human designers manually perform the task.
Our method leverages multi-plane cross-sections to extract 2D patterns and
capture fine parametric details more effectively. It enables the reconstruction
of detailed and editable CAD models, outperforming state-of-the-art methods
and, for the first time, incorporating sketch constraints directly into the
reconstruction process.

</details>


### [194] [CURVETE: Curriculum Learning and Progressive Self-supervised Training for Medical Image Classification](https://arxiv.org/abs/2510.23442)
*Asmaa Abbas,Mohamed Gaber,Mohammed M. Abdelsamea*

Main category: cs.CV

TL;DR: CURVETE通过课程学习和渐进式自监督训练，解决医疗图像分析中样本数量不足和类别分布不均的问题，在多个数据集上提高了分类性能。


<details>
  <summary>Details</summary>
Motivation: 医疗图像分析中存在高质量、易获取的标注样本不足的问题，而类别分布不均会削弱迁移学习的效果。

Method: 提出了一种名为CURVETE的新型深度卷积神经网络，采用基于样本分解粒度的课程学习策略对无标签样本进行训练，并结合类别分解方法处理下游任务中的类别不均问题。

Result: 在脑肿瘤、膝关节X光和Mini-DDSM数据集上进行了评估。使用ResNet-50基线模型，CURVETE在脑肿瘤、膝关节X光和Mini-DDSM数据集上的准确率分别为96.60%、75.60%和93.35%。使用DenseNet-121基线模型，准确率分别为95.77%、80.36%和93.22%，优于其他训练策略。

Conclusion: CURVETE模型能够有效解决医疗图像分析中的样本数量不足和类别分布不均的挑战，并提升模型的泛化能力和分类性能。

Abstract: Identifying high-quality and easily accessible annotated samples poses a
notable challenge in medical image analysis. Transfer learning techniques,
leveraging pre-training data, offer a flexible solution to this issue. However,
the impact of fine-tuning diminishes when the dataset exhibits an irregular
distribution between classes. This paper introduces a novel deep convolutional
neural network, named Curriculum Learning and Progressive Self-supervised
Training (CURVETE). CURVETE addresses challenges related to limited samples,
enhances model generalisability, and improves overall classification
performance. It achieves this by employing a curriculum learning strategy based
on the granularity of sample decomposition during the training of generic
unlabelled samples. Moreover, CURVETE address the challenge of irregular class
distribution by incorporating a class decomposition approach in the downstream
task. The proposed method undergoes evaluation on three distinct medical image
datasets: brain tumour, digital knee x-ray, and Mini-DDSM datasets. We
investigate the classification performance using a generic self-supervised
sample decomposition approach with and without the curriculum learning
component in training the pretext task. Experimental results demonstrate that
the CURVETE model achieves superior performance on test sets with an accuracy
of 96.60% on the brain tumour dataset, 75.60% on the digital knee x-ray
dataset, and 93.35% on the Mini-DDSM dataset using the baseline ResNet-50.
Furthermore, with the baseline DenseNet-121, it achieved accuracies of 95.77%,
80.36%, and 93.22% on the brain tumour, digital knee x-ray, and Mini-DDSM
datasets, respectively, outperforming other training strategies.

</details>


### [195] [FRBNet: Revisiting Low-Light Vision through Frequency-Domain Radial Basis Network](https://arxiv.org/abs/2510.23444)
*Fangtong Sun,Congyu Li,Ke Yang,Yuchen Pan,Hanwen Yu,Xichuan Zhang,Yiying Li*

Main category: cs.CV

TL;DR: FRBNet通过在频域中利用通道比率来提取对光照不变的特征，从而提高低光照图像的下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有的低光照视觉方法在处理光照退化方面仍有不足，需要更好地模拟低光照条件。

Method: 提出了一种名为FRBNet的新型端到端可训练模块，该模块将频域通道比率操作与可学习的频域滤波器相结合，用于光照不变特征增强。该方法基于理论证明，即频域通道比率可用于提取光照不变特征。

Result: FRBNet在包括暗物体检测（+2.2 mAP）和夜间分割（+2.9 mIoU）在内的各种下游任务中取得了优于现有方法的性能。

Conclusion: FRBNet作为一种即插即用模块，可以集成到现有的低光照下游任务网络中，无需修改损失函数，并且在各种下游任务中表现出色。

Abstract: Low-light vision remains a fundamental challenge in computer vision due to
severe illumination degradation, which significantly affects the performance of
downstream tasks such as detection and segmentation. While recent
state-of-the-art methods have improved performance through invariant feature
learning modules, they still fall short due to incomplete modeling of low-light
conditions. Therefore, we revisit low-light image formation and extend the
classical Lambertian model to better characterize low-light conditions. By
shifting our analysis to the frequency domain, we theoretically prove that the
frequency-domain channel ratio can be leveraged to extract
illumination-invariant features via a structured filtering process. We then
propose a novel and end-to-end trainable module named \textbf{F}requency-domain
\textbf{R}adial \textbf{B}asis \textbf{Net}work (\textbf{FRBNet}), which
integrates the frequency-domain channel ratio operation with a learnable
frequency domain filter for the overall illumination-invariant feature
enhancement. As a plug-and-play module, FRBNet can be integrated into existing
networks for low-light downstream tasks without modifying loss functions.
Extensive experiments across various downstream tasks demonstrate that FRBNet
achieves superior performance, including +2.2 mAP for dark object detection and
+2.9 mIoU for nighttime segmentation. Code is available at:
https://github.com/Sing-Forevet/FRBNet.

</details>


### [196] [Video-Thinker: Sparking "Thinking with Videos" via Reinforcement Learning](https://arxiv.org/abs/2510.23473)
*Shijian Wang,Jiarui Jin,Xingjian Wang,Linxin Song,Runhao Fu,Hecheng Wang,Zongyuan Ge,Yuan Lu,Xuelian Cheng*

Main category: cs.CV

TL;DR: Video-Thinker 提出了一种新的视频推理方法，通过自主利用 MLLMs 的“接地”和“字幕”能力来生成推理线索，并在 Video-Thinker-10K 数据集上进行训练，显著提高了视频推理任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的“Thinking with Images”方法在图像推理方面取得了成功，但尚未扩展到视频推理任务。

Method: Video-Thinker 提出让 MLLMs 自主利用其“接地”和“字幕”能力来生成推理线索，并使用 Video-Thinker-10K 数据集进行训练，该数据集包含自主工具使用的链式推理序列。训练策略包括监督微调（SFT）和基于组相对策略优化（GRPO）的强化学习。

Result: Video-Thinker 在 Video-Holmes、CG-Bench-Reasoning 和 VRBench 等视频推理基准上取得了显著的性能提升，并且 Video-Thinker-7B 模型在 7B 参数规模的模型中达到了最先进的性能，优于 Video-R1 等现有基线。

Conclusion: Video-Thinker 能够让 MLLMs 自主完成视频推理任务，无需外部工具，并在多项基准测试中取得了优异的成绩。

Abstract: Recent advances in image reasoning methods, particularly "Thinking with
Images", have demonstrated remarkable success in Multimodal Large Language
Models (MLLMs); however, this dynamic reasoning paradigm has not yet been
extended to video reasoning tasks. In this paper, we propose Video-Thinker,
which empowers MLLMs to think with videos by autonomously leveraging their
intrinsic "grounding" and "captioning" capabilities to generate reasoning clues
throughout the inference process. To spark this capability, we construct
Video-Thinker-10K, a curated dataset featuring autonomous tool usage within
chain-of-thought reasoning sequences. Our training strategy begins with
Supervised Fine-Tuning (SFT) to learn the reasoning format, followed by Group
Relative Policy Optimization (GRPO) to strengthen this reasoning capability.
Through this approach, Video-Thinker enables MLLMs to autonomously navigate
grounding and captioning tasks for video reasoning, eliminating the need for
constructing and calling external tools. Extensive experiments demonstrate that
Video-Thinker achieves significant performance gains on both in-domain tasks
and challenging out-of-domain video reasoning benchmarks, including
Video-Holmes, CG-Bench-Reasoning, and VRBench. Our Video-Thinker-7B
substantially outperforms existing baselines such as Video-R1 and establishes
state-of-the-art performance among 7B-sized MLLMs.

</details>


### [197] [UrbanIng-V2X: A Large-Scale Multi-Vehicle, Multi-Infrastructure Dataset Across Multiple Intersections for Cooperative Perception](https://arxiv.org/abs/2510.23478)
*Karthikeyan Chandra Sekaran,Markus Geisler,Dominik Rößle,Adithya Mohan,Daniel Cremers,Wolfgang Utschick,Michael Botsch,Werner Huber,Torsten Schön*

Main category: cs.CV

TL;DR: 第一个大规模多模态数据集UrbanIng-V2X，包含跨越三个城市交叉口的车辆和基础设施传感器，用于支持协同感知。


<details>
  <summary>Details</summary>
Motivation: 现有数据集在单一交叉口或单一车辆方面存在局限性，无法满足对跨越多个交叉口的互联车辆和基础设施传感器进行全面感知的需求，导致模型可能出现过拟合，并在相似的交叉口布局和交通参与者行为下表现出误导性的高性能。

Method: 介绍UrbanIng-V2X，这是一个大规模、多模态数据集，包含跨越德国殷戈尔施塔特三个城市交叉口的车辆和基础设施传感器，用于协同感知。该数据集包含34个时间对齐且空间校准的传感器序列，每个序列持续20秒。序列包含来自三个交叉口之一的记录，涉及两辆车和多达三个安装在基础设施上的传感器杆，运行在协调场景中。数据集包括12个车载RGB摄像头、2个车载LiDAR、17个基础设施热成像摄像头和12个基础设施LiDAR。所有序列均以10赫兹的频率进行注释，并带有3D边界框，涵盖13个对象类别，数据集总共包含约712,000个注释实例。

Result: 对最先进的协同感知方法进行了全面评估，并公开提供代码库、数据集、高精地图和完整数据收集环境的数字孪生。

Conclusion: UrbanIng-V2X是第一个大规模、多模态数据集，支持跨越多个城市交叉口的车辆和基础设施传感器之间的协同感知，为算法基准测试和智能交通应用的发展提供了重要的资源。

Abstract: Recent cooperative perception datasets have played a crucial role in
advancing smart mobility applications by enabling information exchange between
intelligent agents, helping to overcome challenges such as occlusions and
improving overall scene understanding. While some existing real-world datasets
incorporate both vehicle-to-vehicle and vehicle-to-infrastructure interactions,
they are typically limited to a single intersection or a single vehicle. A
comprehensive perception dataset featuring multiple connected vehicles and
infrastructure sensors across several intersections remains unavailable,
limiting the benchmarking of algorithms in diverse traffic environments.
Consequently, overfitting can occur, and models may demonstrate misleadingly
high performance due to similar intersection layouts and traffic participant
behavior. To address this gap, we introduce UrbanIng-V2X, the first
large-scale, multi-modal dataset supporting cooperative perception involving
vehicles and infrastructure sensors deployed across three urban intersections
in Ingolstadt, Germany. UrbanIng-V2X consists of 34 temporally aligned and
spatially calibrated sensor sequences, each lasting 20 seconds. All sequences
contain recordings from one of three intersections, involving two vehicles and
up to three infrastructure-mounted sensor poles operating in coordinated
scenarios. In total, UrbanIng-V2X provides data from 12 vehicle-mounted RGB
cameras, 2 vehicle LiDARs, 17 infrastructure thermal cameras, and 12
infrastructure LiDARs. All sequences are annotated at a frequency of 10 Hz with
3D bounding boxes spanning 13 object classes, resulting in approximately 712k
annotated instances across the dataset. We provide comprehensive evaluations
using state-of-the-art cooperative perception methods and publicly release the
codebase, dataset, HD map, and a digital twin of the complete data collection
environment.

</details>


### [198] [MergeMix: A Unified Augmentation Paradigm for Visual and Multi-Modal Understanding](https://arxiv.org/abs/2510.23479)
*Xin Jin,Siyuan Li,Siyong Jian,Kai Yu,Huan Wang*

Main category: cs.CV

TL;DR: MergeMix是一种新的训练范式，通过混合图像和偏好学习来改进多模态大模型，在保持准确性的同时提高效率。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大模型训练方法（如SFT和RL）存在稳定性、效率和对人类标注的依赖性等问题，难以平衡模型性能和训练成本。

Method: MergeMix采用一种名为“token merge”的注意力感知图像混合技术，并结合混合图像和原始图像构建偏好对，然后使用SimPO损失进行优化。

Result: MergeMix在分类任务上表现出比其他基于启发式的方法更优的注意力和效率，并在准确性上具有竞争力，同时提高了效率。

Conclusion: MergeMix为多模态大模型提供了可扩展的偏好对齐方法，有望在保持模型性能的同时降低训练成本。

Abstract: Vision-language alignment in multi-modal large language models (MLLMs)
typically relies on supervised fine-tuning (SFT) or reinforcement learning
(RL). SFT is stable and efficient but requires large-scale human annotations
and cannot capture subtle preferences, while RL brings in a reward signal for
training, but suffers from overhead and instability. These limitations
highlight a trade-off between scalability, robustness, and alignment quality.
To address this, we propose MergeMix, a training-time augmentation paradigm
that bridges SFT and RL. It first applies an attention-aware image mixing via
token merge with more cluster representation and spatial context, and then
presents a preference-driven training paradigm for MLLMs by building preference
pairs with mixed images and raw images, and optimizing via SimPO loss. As a
mixup augmentation, MergeMix enhances attention consistency and efficiency,
surpassing other heuristic-based methods in classification. Extensive
experiments demonstrate that MergeMix achieves competitive accuracy with
improved efficiency, providing a scalable approach to preference alignment in
classification and MLLMs.

</details>


### [199] [On the Faithfulness of Visual Thinking: Measurement and Enhancement](https://arxiv.org/abs/2510.23482)
*Zujing Liu,Junwen Pan,Qi She,Yuan Gao,Guisong Xia*

Main category: cs.CV

TL;DR: 最近的大型视觉-语言模型（LVLM）在强化微调（RFT）后可以生成视觉-文本多模态思维链（MCoT）的痕迹。然而，我们观察到 MCoT 中包含的视觉信息通常不准确，尽管仍然可以得出正确的答案，这表明 MCoT 推理过程缺乏忠实性。我们认为这种不忠实性源于 RFT 中的 RL 奖励，该奖励仅奖励交错视觉-文本线索的格式，即它鼓励模型将视觉信息纳入其文本推理步骤，而不考虑视觉信息的正确性。在本研究中，我们首先通过测量在其视觉和文本思考受到干预时预测会发生多大变化来探测 MCoT 的忠实性。令人惊讶的是，在视觉干预下，模型的预测几乎没有变化，但在文本干预下，预测发生显著变化，这表明视觉证据在很大程度上被忽略了。为了进一步分析视觉信息，我们引入了一种自动化的基于 LVLM 的评估指标，该指标从可靠性和充分性两个角度量化视觉线索的忠实性。我们的评估显示，当前 MCoT 痕迹中的视觉信息同时不可靠且不充分。为了解决这个问题，我们提出了一种新颖的 MCoT 学习策略，称为充分成分因果模型（SCCM）学习。该方法鼓励 MCoT 生成充分但最小的视觉组件，这些组件能够独立地得出正确的答案。我们注意到，所提出的 SCCM 是无注释的，并且可以即插即用地与各种 MCoT 的 RFT 兼容。实证结果表明，SCCM 在一套细粒度的感知和推理基准测试中始终能提高视觉忠实性。代码可在 https://github.com/EugeneLiu01/Faithful_Thinking_with_Image 获取。


<details>
  <summary>Details</summary>
Motivation: 大型视觉-语言模型（LVLM）在强化微调（RFT）后能够生成多模态思维链（MCoT），但其中包含的视觉信息往往不准确，表明其推理过程缺乏忠实性。这主要是由于 RFT 中的 RL 奖励仅关注 MCoT 的格式，而忽略了视觉信息的正确性。

Method: 1. 探测 MCoT 的忠实性：通过在视觉和文本信息上进行干预，观察模型预测的变化情况，发现视觉信息在 MCoT 中被忽略。 2. 提出基于 LVLM 的评估指标：从可靠性和充分性两个角度量化视觉线索的忠实性，发现当前 MCoT 的视觉信息不可靠且不充分。 3. 提出 SCCM 学习策略：鼓励模型生成充分但最小的视觉组件，使其能够独立地导向正确答案。该策略无需注释，且可兼容各种 RFT。

Result: SCCM 学习策略能够提高 MCoT 在感知和推理任务中的视觉忠实性。在进行视觉和文本干预的实验中，模型的预测在视觉干预下几乎不变，但在文本干预下发生显著变化，表明视觉信息被忽略。所提出的评估指标显示当前 MCoT 的视觉信息既不可靠也不充分。

Conclusion: SCCM 学习策略是一种有效的、无需注释的方法，可以提高 LVLM 中 MCoT 的视觉忠实性，解决了当前 MCoT 依赖格式而非准确视觉信息的问题，并能在各种基准测试中带来性能提升。

Abstract: Recent large vision-language models (LVLMs) can generate vision-text
multimodal chain-of-thought (MCoT) traces after reinforcement fine-tuning
(RFT). However, we observe that the visual information incorporated in MCoT is
often inaccurate, though still yield correct answers, indicating a lack of
faithfulness in the MCoT reasoning process. We attribute this unfaithfulness to
the RL reward in RFT, which solely incentivizes the format of interleaved
vision-text cues, ie, it encourages the model to incorporate visual information
into its text reasoning steps without considering the correctness of the visual
information. In this paper, we first probe the faithfulness of MCoT by
measuring how much the prediction changes when its visual and textual thoughts
are intervened. Surprisingly, the model's predictions remain nearly unchanged
under visual intervention but change significantly under textual intervention,
indicating that the visual evidence is largely ignored. To further analyze
visual information, we introduce an automated LVLM-based evaluation metric that
quantifies the faithfulness of visual cues from two perspectives: reliability
and sufficiency. Our evaluation reveals that the visual information in current
MCoT traces is simultaneously unreliable and insufficient. To address this
issue, we propose a novel MCoT learning strategy termed Sufficient-Component
Cause Model (SCCM) learning. This approach encourages the MCoT to generate
sufficient yet minimal visual components that are independently capable of
leading to correct answers. We note that the proposed SCCM is annotation-free
and compatible with various RFT for MCoT in a plug-and-play manner. Empirical
results demonstrate that SCCM consistently improves the visual faithfulness
across a suite of fine-grained perception and reasoning benchmarks. Code is
available at https://github.com/EugeneLiu01/Faithful_Thinking_with_Image.

</details>


### [200] [VOLD: Reasoning Transfer from LLMs to Vision-Language Models via On-Policy Distillation](https://arxiv.org/abs/2510.23497)
*Walid Bousselham,Hilde Kuehne,Cordelia Schmid*

Main category: cs.CV

TL;DR: VOLD框架利用文本推理能力提升视觉语言模型（VLM）的推理能力，通过结合强化学习和在线蒸馏，并强调冷启动对齐的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（VLM）在复杂推理方面存在数据稀缺的挑战，而文本推理资源丰富，但如何将其用于VLM推理仍是开放性问题。

Method: 提出VOLD框架，利用强化学习（GRPO）和在线蒸馏，将文本教师模型的推理能力迁移到VLM学生模型，并引入冷启动对齐（SFT）以确保有效的迁移。

Result: VOLD在MMMU-Pro、MathVision、MathVista和LogicVista等基准测试中显著优于基线模型，并超越了现有技术水平。

Conclusion: 冷启动对齐对于在在线训练阶段进行有效的知识迁移至关重要，尤其是在使用仅文本教师模型进行在线蒸馏时。

Abstract: Training vision-language models (VLMs) for complex reasoning remains a
challenging task, i.a. due to the scarcity of high-quality image-text reasoning
data. Conversely, text-based reasoning resources are abundant and scalable, but
it is still an open question how to leveraging them for VLM reasoning. To
address this problem, we propose VOLD, a framework to transfer reasoning
capabilities from text-only teacher models to VLM student models. To this end,
VOLD combines reinforcement learning via Group Relative Policy Optimization
(GRPO) with on-policy distillation, which allows the student reasoning traces
to be guided by the teacher model, resulting in a significant gain over using
GRPO alone. We further show that a cold-start alignment is essential for an
effective transfer during the online training phase in this scenario and that
without sufficient distributional alignment between teacher and student,
on-policy distillation fails to provide meaningful guidance. We evaluate VOLD
across diverse benchmarks including MMMU-Pro, MathVision, MathVista, and
LogicVista, showing that VOLD outperforms the baseline model significantly and
improves over the state of the art by a margin. Our ablation shows the
importance of a cold-start alignment via SFT for on-policy distillation with a
text-only teacher.

</details>


### [201] [iPac: Incorporating Intra-image Patch Context into Graph Neural Networks for Medical Image Classification](https://arxiv.org/abs/2510.23504)
*Usama Zidan,Mohamed Gaber,Mohammed M. Abdelsamea*

Main category: cs.CV

TL;DR: iPac是一种新的图神经网络方法，通过引入图像的图表示来增强医学图像分类，并在各种数据集上实现了高达5%的准确率提升。


<details>
  <summary>Details</summary>
Motivation: 现有的图神经网络在图像分类任务中的性能受到对视觉实体之间底层结构和关系的有限考虑的限制。

Method: iPac整合了图像分割、特征提取、聚类、图构建和图学习等多个阶段，构建了一个有意义的图表示，能够有效地封装图像的语义。

Result: 在各种医学图像数据集上的实验评估证明了iPac的有效性，与基线方法相比，平均准确率提高了高达5%。

Conclusion: iPac通过利用图表示并考虑视觉实体之间固有的结构和关系，为图像分类，特别是在医学图像领域，提供了一个通用且高效的解决方案。

Abstract: Graph neural networks have emerged as a promising paradigm for image
processing, yet their performance in image classification tasks is hindered by
a limited consideration of the underlying structure and relationships among
visual entities. This work presents iPac, a novel approach to introduce a new
graph representation of images to enhance graph neural network image
classification by recognizing the importance of underlying structure and
relationships in medical image classification. iPac integrates various stages,
including patch partitioning, feature extraction, clustering, graph
construction, and graph-based learning, into a unified network to advance graph
neural network image classification. By capturing relevant features and
organising them into clusters, we construct a meaningful graph representation
that effectively encapsulates the semantics of the image. Experimental
evaluation on diverse medical image datasets demonstrates the efficacy of iPac,
exhibiting an average accuracy improvement of up to 5% over baseline methods.
Our approach offers a versatile and generic solution for image classification,
particularly in the realm of medical images, by leveraging the graph
representation and accounting for the inherent structure and relationships
among visual entities.

</details>


### [202] [FreeFuse: Multi-Subject LoRA Fusion via Auto Masking at Test Time](https://arxiv.org/abs/2510.23515)
*Yaoli Liu,Yao-Xiang Ding,Kun Zhou*

Main category: cs.CV

TL;DR: FreeFuse是一种创新的训练免费方法，通过自动融合多个主题LoRA来实现多主题文本到图像生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多主题生成方面存在局限性，如需要预推理LoRA权重合并、依赖分割模型或复杂的噪声混合技术。FreeFuse的动机是提出一种更简洁、高效且无需训练的方法。

Method: FreeFuse利用交叉注意力层权重自动推断出上下文感知的动态主题蒙版，并将这些蒙版应用于LoRA的输出，以在推理过程中隔离和融合不同主题。

Result: 实验证明，FreeFuse在多主题生成任务的生成质量和可用性方面均优于现有方法，且无需额外训练、修改LoRA、辅助模型或用户定义的模板/区域，只需提供LoRA激活词。

Conclusion: FreeFuse通过自动蒙版技术实现了高效、易用的多主题文本到图像生成，显著优于现有方法。

Abstract: This paper proposes FreeFuse, a novel training-free approach for
multi-subject text-to-image generation through automatic fusion of multiple
subject LoRAs. In contrast to existing methods that either focus on
pre-inference LoRA weight merging or rely on segmentation models and complex
techniques like noise blending to isolate LoRA outputs, our key insight is that
context-aware dynamic subject masks can be automatically derived from
cross-attention layer weights. Mathematical analysis shows that directly
applying these masks to LoRA outputs during inference well approximates the
case where the subject LoRA is integrated into the diffusion model and used
individually for the masked region. FreeFuse demonstrates superior practicality
and efficiency as it requires no additional training, no modification to LoRAs,
no auxiliary models, and no user-defined prompt templates or region
specifications. Alternatively, it only requires users to provide the LoRA
activation words for seamless integration into standard workflows. Extensive
experiments validate that FreeFuse outperforms existing approaches in both
generation quality and usability under the multi-subject generation tasks. The
project page is at https://future-item.github.io/FreeFuse/

</details>


### [203] [EgoThinker: Unveiling Egocentric Reasoning with Spatio-Temporal CoT](https://arxiv.org/abs/2510.23569)
*Baoqi Pei,Yifei Huang,Jilan Xu,Yuping He,Guo Chen,Fei Wu,Yu Qiao,Jiangmiao Pang*

Main category: cs.CV

TL;DR: EgoThinker框架通过时空链式思考监督和两阶段学习课程，提升了大型多模态模型在第一人称视频推理方面的能力，并在多个基准测试中取得优于现有方法的结果。


<details>
  <summary>Details</summary>
Motivation: 现有的大型多模态语言模型（MLLMs）在处理可见事件推理方面表现出色，但缺乏具身的第一人称理解能力，这限制了它们在需要推断隐藏意图和识别细粒度交互的以自我为中心的视频推理任务中的应用。

Method: EgoThinker框架通过时空链式思考（spatio-temporal chain-of-thought）监督和两阶段学习课程来增强MLLMs的以自我为中心的推理能力。首先，构建了一个大规模以自我为中心的问答数据集EgoRe-5M（包含13M个视频片段），其中包含详细的链式思考（CoT）和手部-物体定位标注。然后，使用EgoRe-5M对模型进行监督微调（SFT），以注入推理能力，接着进行强化微调（RFT）以增强时空定位能力。

Result: EgoThinker框架在多个以自我为中心的基准测试中表现优于现有方法，并在细粒度的时空定位任务上取得了显著的改进。

Conclusion: EgoThinker框架成功地为大型多模态语言模型增加了以自我为中心的推理能力，解决了现有模型在理解第一人称视角视频方面的局限性。

Abstract: Egocentric video reasoning centers on an unobservable agent behind the camera
who dynamically shapes the environment, requiring inference of hidden
intentions and recognition of fine-grained interactions. This core challenge
limits current multimodal large language models MLLMs, which excel at visible
event reasoning but lack embodied, first-person understanding. To bridge this
gap, we introduce EgoThinker, a novel framework that endows MLLMs with robust
egocentric reasoning capabilities through spatio-temporal chain-of-thought
supervision and a two-stage learning curriculum. First, we introduce EgoRe-5M,
a large-scale egocentric QA dataset constructed from 13M diverse egocentric
video clips. This dataset features multi-minute segments annotated with
detailed CoT rationales and dense hand-object grounding. Second, we employ SFT
on EgoRe-5M to instill reasoning skills, followed by reinforcement fine-tuning
RFT to further enhance spatio-temporal localization. Experimental results show
that EgoThinker outperforms existing methods across multiple egocentric
benchmarks, while achieving substantial improvements in fine-grained
spatio-temporal localization tasks. Full code and data are released at
https://github.com/InternRobotics/EgoThinker.

</details>


### [204] [More Than Generation: Unifying Generation and Depth Estimation via Text-to-Image Diffusion Models](https://arxiv.org/abs/2510.23574)
*Hongkai Lin,Dingkang Liang,Mingyang Du,Xin Zhou,Xiang Bai*

Main category: cs.CV

TL;DR: MERGE是一个统一模型，可用于图像生成和深度估计，它利用固定的预训练文本到图像扩散模型，并在不损害其生成能力的情况下实现最先进的深度估计性能。


<details>
  <summary>Details</summary>
Motivation: 预训练的文本到图像扩散模型在深度估计任务中表现出惊人的零样本能力，但训练过程中的参数更新会导致其图像生成能力严重下降。现有的方法未能有效解决这一问题。

Method: MERGE提出了一种即插即用的框架，允许在图像生成和深度估计之间无缝切换，同时引入了一种组重用机制来促进参数重用并提高可学习参数的利用率。

Result: MERGE在多个深度估计基准测试中取得了最先进的性能，同时保留了预训练模型的原始图像生成能力。

Conclusion: MERGE成功地释放了预训练文本到图像模型在深度估计方面的强大能力，同时保护了其生成能力，为统一模型在多模态任务中的应用提供了新的方向。

Abstract: Generative depth estimation methods leverage the rich visual priors stored in
pre-trained text-to-image diffusion models, demonstrating astonishing zero-shot
capability. However, parameter updates during training lead to catastrophic
degradation in the image generation capability of the pre-trained model. We
introduce MERGE, a unified model for image generation and depth estimation,
starting from a fixed pre-trained text-to-image model. MERGE demonstrates that
the pre-trained text-to-image model can do more than image generation, but also
expand to depth estimation effortlessly. Specifically, MERGE introduces a
play-and-plug framework that enables seamless switching between image
generation and depth estimation modes through simple and pluggable converters.
Meanwhile, we propose a Group Reuse Mechanism to encourage parameter reuse and
improve the utilization of the additional learnable parameters. MERGE unleashes
the powerful depth estimation capability of the pre-trained text-to-image model
while preserving its original image generation ability. Compared to other
unified models for image generation and depth estimation, MERGE achieves
state-of-the-art performance across multiple depth estimation benchmarks. The
code will be made available at https://github.com/H-EmbodVis/MERGE

</details>


### [205] [Lookahead Anchoring: Preserving Character Identity in Audio-Driven Human Animation](https://arxiv.org/abs/2510.23581)
*Junyoung Seo,Rodrigo Mira,Alexandros Haliassos,Stella Bounareli,Honglie Chen,Linh Tran,Seungryong Kim,Zoe Landgraf,Jie Shen*

Main category: cs.CV

TL;DR: 音频驱动的人体动画模型会随着时间推移逐渐失去人物身份特征。我们提出了“前瞻锚定”方法，通过利用生成窗口之外的未来时间帧作为中间时间锚点，解决了身份漂移问题，同时无需单独的关键帧生成阶段，并允许更自然的运动。该方法通过持续引导模型朝着未来的锚点移动，同时响应当前的音频线索，从而保持身份一致性。参考图像本身也可以作为前瞻目标，无需额外生成关键帧。实验表明，“前瞻锚定”可以平衡动作的表达力和身份一致性，并且在三个现有的人体动画模型上都取得了更好的唇部同步、身份保持和视觉质量。


<details>
  <summary>Details</summary>
Motivation: 现有的音频驱动人体动画模型在生成过程中存在身份漂移问题，即角色身份会随着时间推移而逐渐丢失。虽然可以通过生成关键帧来缓解此问题，但这会增加一个额外的生成阶段并可能限制运动的自然性。

Method: 提出了一种名为“前瞻锚定”（Lookahead Anchoring）的方法。该方法不依赖于当前生成窗口内的关键帧，而是利用生成窗口之前的未来时间帧作为中间时间锚点。模型在响应即时音频线索的同时，会持续地朝着这些未来的锚点进行生成，从而通过持续的引导来维持身份一致性。此外，该方法还实现了“自关键帧”功能，即可以将参考图像本身作为前瞻目标，从而完全无需生成关键帧。

Result: 将“前瞻锚定”方法应用于三个最近的人体动画模型后，在唇部同步、身份保持和视觉质量方面均取得了优越的性能。实验表明，时间前瞻距离可以自然地控制动作的表达力和身份一致性之间的平衡：距离越长，动作自由度越大；距离越短，身份保持能力越强。该方法显著改善了不同架构下的时间条件。

Conclusion: “前瞻锚定”通过利用未来帧作为指导，有效地解决了音频驱动人体动画中的身份漂移问题，提高了动画的整体质量和一致性，并提供了灵活的参数来平衡动作的表达力和身份保持。

Abstract: Audio-driven human animation models often suffer from identity drift during
temporal autoregressive generation, where characters gradually lose their
identity over time. One solution is to generate keyframes as intermediate
temporal anchors that prevent degradation, but this requires an additional
keyframe generation stage and can restrict natural motion dynamics. To address
this, we propose Lookahead Anchoring, which leverages keyframes from future
timesteps ahead of the current generation window, rather than within it. This
transforms keyframes from fixed boundaries into directional beacons: the model
continuously pursues these future anchors while responding to immediate audio
cues, maintaining consistent identity through persistent guidance. This also
enables self-keyframing, where the reference image serves as the lookahead
target, eliminating the need for keyframe generation entirely. We find that the
temporal lookahead distance naturally controls the balance between expressivity
and consistency: larger distances allow for greater motion freedom, while
smaller ones strengthen identity adherence. When applied to three recent human
animation models, Lookahead Anchoring achieves superior lip synchronization,
identity preservation, and visual quality, demonstrating improved temporal
conditioning across several different architectures. Video results are
available at the following link: https://lookahead-anchoring.github.io.

</details>


### [206] [FARMER: Flow AutoRegressive Transformer over Pixels](https://arxiv.org/abs/2510.23588)
*Guangting Zheng,Qinyu Zhao,Tao Yang,Fei Xiao,Zhijie Lin,Jie Wu,Jiajun Deng,Yanyong Zhang,Rui Zhu*

Main category: cs.CV

TL;DR: FARMER是一个结合了归一化流（NF）和自回归（AR）模型的新型生成框架，用于直接从原始像素进行似然估计和高质量图像合成。它通过可逆的自回归流将图像转换为潜在序列，并利用自监督降维来处理冗余信息，从而实现更高效的AR模型。此外，FARMER还通过单步蒸馏加速推理，并通过基于重采样的无分类器引导来提升生成质量。实验证明，FARMER在提供精确似然和可扩展训练的同时，性能与现有像素级生成模型相当。


<details>
  <summary>Details</summary>
Motivation: 直接对原始数据分布的显式似然进行建模是机器学习的关键主题，这在大型语言模型中通过自回归建模取得了显著成功。然而，视觉像素数据的连续自回归建模在处理极长序列和高维空间时存在困难。

Method: FARMER采用可逆的自回归流将图像转换为潜在序列，并使用自回归模型对其分布进行隐式建模。为了解决像素级建模的冗余和复杂性，提出了一种自监督降维方案，将NF潜在通道划分为信息和冗余组，以实现更有效和高效的AR建模。此外，还设计了一种单步蒸馏方案来加速推理，并引入了一种基于重采样的无分类器引导算法来提高图像生成质量。

Result: 大量实验表明，FARMER在提供精确似然和可扩展训练的同时，与现有的像素级生成模型相比，实现了具有竞争力的性能。

Conclusion: FARMER是一个端到端的生成框架，能够直接从原始像素进行似然估计和高质量图像合成，它通过结合NF和AR模型，并引入创新的降维、加速和引导技术，在性能和效率上都取得了显著进展。

Abstract: Directly modeling the explicit likelihood of the raw data distribution is key
topic in the machine learning area, which achieves the scaling successes in
Large Language Models by autoregressive modeling. However, continuous AR
modeling over visual pixel data suffer from extremely long sequences and
high-dimensional spaces. In this paper, we present FARMER, a novel end-to-end
generative framework that unifies Normalizing Flows (NF) and Autoregressive
(AR) models for tractable likelihood estimation and high-quality image
synthesis directly from raw pixels. FARMER employs an invertible autoregressive
flow to transform images into latent sequences, whose distribution is modeled
implicitly by an autoregressive model. To address the redundancy and complexity
in pixel-level modeling, we propose a self-supervised dimension reduction
scheme that partitions NF latent channels into informative and redundant
groups, enabling more effective and efficient AR modeling. Furthermore, we
design a one-step distillation scheme to significantly accelerate inference
speed and introduce a resampling-based classifier-free guidance algorithm to
boost image generation quality. Extensive experiments demonstrate that FARMER
achieves competitive performance compared to existing pixel-based generative
models while providing exact likelihoods and scalable training.

</details>


### [207] [InFlux: A Benchmark for Self-Calibration of Dynamic Intrinsics of Video Cameras](https://arxiv.org/abs/2510.23589)
*Erich Liang,Roma Bhattacharjee,Sreemanti Dey,Rafael Moschopoulos,Caitlin Wang,Michel Liao,Grace Tan,Andrew Wang,Karhan Kayan,Stamatis Alexandropoulos,Jia Deng*

Main category: cs.CV

TL;DR: 本文提出了InFlux基准，一个包含动态相机内参标注的真实世界视频数据集，以解决现有基准在场景多样性和内参变化方面的局限性。该数据集包含386个室内外视频，超过143K帧，并对现有方法进行了评估，发现它们在处理动态内参方面存在困难。


<details>
  <summary>Details</summary>
Motivation: 现有3D理解算法通常假设相机内参在视频中保持不变，但这在许多真实场景中不成立。然而，目前缺乏包含连续帧内参变化的动态相机内参基准，限制了该领域的发展。

Method: 构建了一个全面的校准实验查找表，并扩展了Kalibr工具箱以提高精度和鲁棒性，从而生成InFlux基准，其中包含逐帧的真实相机内参标注。利用此基准，评估了现有相机内参预测方法的性能。

Result: 在InFlux基准上，大多数现有的相机内参预测方法在处理动态内参视频时，预测精度不佳，表明该领域仍有提升空间。

Conclusion: InFlux基准的提出填补了动态相机内参基准的空白，为该领域的研究提供了重要的资源。通过对现有方法的评估，揭示了当前技术的不足，并为未来的研究指明了方向。

Abstract: Accurately tracking camera intrinsics is crucial for achieving 3D
understanding from 2D video. However, most 3D algorithms assume that camera
intrinsics stay constant throughout a video, which is often not true for many
real-world in-the-wild videos. A major obstacle in this field is a lack of
dynamic camera intrinsics benchmarks--existing benchmarks typically offer
limited diversity in scene content and intrinsics variation, and none provide
per-frame intrinsic changes for consecutive video frames. In this paper, we
present Intrinsics in Flux (InFlux), a real-world benchmark that provides
per-frame ground truth intrinsics annotations for videos with dynamic
intrinsics. Compared to prior benchmarks, InFlux captures a wider range of
intrinsic variations and scene diversity, featuring 143K+ annotated frames from
386 high-resolution indoor and outdoor videos with dynamic camera intrinsics.
To ensure accurate per-frame intrinsics, we build a comprehensive lookup table
of calibration experiments and extend the Kalibr toolbox to improve its
accuracy and robustness. Using our benchmark, we evaluate existing baseline
methods for predicting camera intrinsics and find that most struggle to achieve
accurate predictions on videos with dynamic intrinsics. For the dataset, code,
videos, and submission, please visit https://influx.cs.princeton.edu/.

</details>


### [208] [PRISM-Bench: A Benchmark of Puzzle-Based Visual Tasks with CoT Error Detection](https://arxiv.org/abs/2510.23594)
*Yusu Qian,Cheng Wan,Chao Jia,Yinfei Yang,Qingyu Zhao,Zhe Gan*

Main category: cs.CV

TL;DR: PRISM-Bench是一个包含视觉谜题的基准测试，用于评估多模态大语言模型（MLLM）的推理过程，而不仅仅是最终答案的准确性。它包含一个诊断任务，要求模型找出推理链（CoT）中的第一个错误，以评估逻辑一致性、错误检测和视觉推理能力。该基准测试包含需要符号、几何和类比推理的多步谜题，并揭示了当前MLLM在流畅生成和忠实推理之间存在的差距。


<details>
  <summary>Details</summary>
Motivation: 评估多模态大语言模型（MLLM）的推理能力，特别是其逻辑一致性、错误检测和视觉推理能力，而不仅仅是最终答案的准确性。现有的评估方法未能提供细粒度的分析，PRISM-Bench旨在弥补这一不足。

Method: 创建一个包含视觉谜题的基准测试（PRISM-Bench），其中包含一个诊断任务。该任务要求模型识别出一步一步的推理链（CoT）中的第一个错误。这些谜题需要多步符号、几何和类比推理。在多种先进的MLLM上进行评估。

Result: 评估结果显示，MLLM在流畅生成看似合理的推理链方面表现良好，但在定位简单的逻辑错误方面存在困难。这表明当前模型在生成能力和实际推理能力之间存在差距。

Conclusion: PRISM-Bench通过将答案生成与推理验证分离开来，为评估多模态推理能力提供了一个更精确的视角。它强调了在开发值得信赖的MLLM时，需要诊断性评估协议。

Abstract: We introduce \textbf{PRISM-Bench}, a benchmark of puzzle-based visual
challenges designed to evaluate not only whether models can solve problems, but
how their reasoning unfolds. Unlike prior evaluations that measure only
final-answer accuracy, PRISM-Bench introduces a diagnostic task: given a visual
puzzle and a step-by-step chain-of-thought (CoT) containing exactly one error,
models must identify the first incorrect step. This setting enables
fine-grained assessment of logical consistency, error detection, and visual
reasoning. The puzzles in PRISM-Bench require multi-step symbolic, geometric,
and analogical reasoning, resisting shortcuts based on superficial pattern
matching. Evaluations across state-of-the-art MLLMs reveal a persistent gap
between fluent generation and faithful reasoning: models that produce plausible
CoTs often fail to locate simple logical faults. By disentangling answer
generation from reasoning verification, PRISM-Bench offers a sharper lens on
multimodal reasoning competence and underscores the need for diagnostic
evaluation protocols in the development of trustworthy MLLMs.

</details>


### [209] [PixelRefer: A Unified Framework for Spatio-Temporal Object Referring with Arbitrary Granularity](https://arxiv.org/abs/2510.23603)
*Yuqian Yuan,Wenqiao Zhang,Xin Li,Shihao Wang,Kehan Li,Wentong Li,Jun Xiao,Lei Zhang,Beng Chin Ooi*

Main category: cs.CV

TL;DR: PixelRefer是一个统一的区域级多模态大语言模型框架，能够对图像和视频中用户指定的区域进行精细理解。它引入了自适应对象标记器（SAOT）来生成紧凑且丰富的对象表示，并提出了PixelRefer-Lite，一个轻量级的高效变体。此外，还构建了PixelRefer-2.2M数据集用于微调。实验证明PixelRefer在少样本学习方面表现出色，PixelRefer-Lite在保持精度的同时提高了效率。


<details>
  <summary>Details</summary>
Motivation: 现有模型在细粒度、以物体为中心的推理方面存在不足，PixelRefer旨在解决这一问题。

Method: 提出自适应对象标记器（SAOT）生成对象表示；设计PixelRefer-Lite，通过对象中心注入模块预融合全局上下文；构建PixelRefer-2.2M数据集。

Result: PixelRefer在少样本学习方面取得了领先的性能；PixelRefer-Lite在保持竞争力的准确性的同时，效率得到了显著提升。

Conclusion: PixelRefer框架在细粒度视觉理解方面表现出色，PixelRefer-Lite提供了高效的选择。

Abstract: Multimodal large language models (MLLMs) have demonstrated strong
general-purpose capabilities in open-world visual comprehension. However, most
existing MLLMs primarily focus on holistic, scene-level understanding, often
overlooking the need for fine-grained, object-centric reasoning. In this paper,
we present PixelRefer, a unified region-level MLLM framework that enables
advanced fine-grained understanding over user-specified regions across both
images and videos. Motivated by the observation that LLM attention
predominantly focuses on object-level tokens, we propose a Scale-Adaptive
Object Tokenizer (SAOT) to generate compact and semantically rich object
representations from free-form regions. Our analysis reveals that global visual
tokens contribute mainly in early LLM layers, inspiring the design of
PixelRefer-Lite, an efficient variant that employs an Object-Centric Infusion
module to pre-fuse global context into object tokens. This yields a lightweight
Object-Only Framework that substantially reduces computational cost while
maintaining high semantic fidelity. To facilitate fine-grained instruction
tuning, we curate PixelRefer-2.2M, a high-quality object-centric instruction
dataset. Extensive experiments across a range of benchmarks validate that
PixelRefer achieves leading performance with fewer training samples, while
PixelRefer-Lite offers competitive accuracy with notable gains in efficiency.

</details>


### [210] [Concerto: Joint 2D-3D Self-Supervised Learning Emerges Spatial Representations](https://arxiv.org/abs/2510.23607)
*Yujia Zhang,Xiaoyang Wu,Yixing Lao,Chengyao Wang,Zhuotao Tian,Naiyan Wang,Hengshuang Zhao*

Main category: cs.CV

TL;DR:  Concerto通过结合3D内模态自蒸馏和2D-3D跨模态联合嵌入，实现了高效的空间概念学习，在零样本可视化、线性探测和全模型微调方面均超越了现有SOTA模型，并在ScanNet等基准测试中取得了新的SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 受人类通过多感官协同学习抽象概念，并能从单一感官回忆的启发，提出Concerto模型以模拟空间认知中的概念学习。

Method: Concerto模型结合了3D内模态自蒸馏和2D-3D跨模态联合嵌入两种方法。

Result: Concerto学习到了更连贯、信息量更丰富的空间特征，在零样本可视化中得到证明。与独立的SOTA 2D和3D自监督模型相比，在3D场景感知的线性探测任务中，分别提高了14.2%和4.8%。在全模型微调方面，Concerto在多个场景理解基准测试中设定了新的SOTA结果（例如，在ScanNet上mIoU达到80.7%）。此外，还提出了用于视频增强点云空间理解的Concerto变体，以及一个能将Concerto表示线性投影到CLIP语言空间的翻译器，实现了开放世界感知。

Conclusion: Concerto模型能够涌现出具有优越的细粒度几何和语义一致性的空间表示。

Abstract: Humans learn abstract concepts through multisensory synergy, and once formed,
such representations can often be recalled from a single modality. Inspired by
this principle, we introduce Concerto, a minimalist simulation of human concept
learning for spatial cognition, combining 3D intra-modal self-distillation with
2D-3D cross-modal joint embedding. Despite its simplicity, Concerto learns more
coherent and informative spatial features, as demonstrated by zero-shot
visualizations. It outperforms both standalone SOTA 2D and 3D self-supervised
models by 14.2% and 4.8%, respectively, as well as their feature concatenation,
in linear probing for 3D scene perception. With full fine-tuning, Concerto sets
new SOTA results across multiple scene understanding benchmarks (e.g., 80.7%
mIoU on ScanNet). We further present a variant of Concerto tailored for
video-lifted point cloud spatial understanding, and a translator that linearly
projects Concerto representations into CLIP's language space, enabling
open-world perception. These results highlight that Concerto emerges spatial
representations with superior fine-grained geometric and semantic consistency.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [211] [A Multi-lingual Dataset of Classified Paragraphs from Open Access Scientific Publications](https://arxiv.org/abs/2510.21762)
*Eric Jeangirard*

Main category: cs.CL

TL;DR: 生成一个太长不看摘要


<details>
  <summary>Details</summary>
Motivation: 描述这篇论文的动机

Method: 这篇论文的方法

Result: 这篇论文的结果

Conclusion: 这篇论文的结论

Abstract: We present a dataset of 833k paragraphs extracted from CC-BY licensed
scientific publications, classified into four categories: acknowledgments, data
mentions, software/code mentions, and clinical trial mentions. The paragraphs
are primarily in English and French, with additional European languages
represented. Each paragraph is annotated with language identification (using
fastText) and scientific domain (from OpenAlex). This dataset, derived from the
French Open Science Monitor corpus and processed using GROBID, enables training
of text classification models and development of named entity recognition
systems for scientific literature mining. The dataset is publicly available on
HuggingFace https://doi.org/10.57967/hf/6679 under a CC-BY license.

</details>


### [212] [Policy Optimization Prefers The Path of Least Resistance](https://arxiv.org/abs/2510.21853)
*Debdeep Sanyal,Aakash Sen Sharma,Dhruv Kumar,Saurabh Deshpande,Murari Mandal*

Main category: cs.CL

TL;DR: 策略优化（PO）在开放式思维-回答（CoT）结构下倾向于选择最简单的路径，导致模型退化为仅回答模式，即使在奖励权重增加的情况下也无法避免。这表明PO在遵循奖励函数的同时，也容易受到“奖励窃取”的影响。


<details>
  <summary>Details</summary>
Motivation: 研究在开放式CoT结构下，策略优化（PO）算法的行为，以及当移除严格的“先思考-后回答”格式时，PO的行为如何变化。

Method: 通过一系列控制实验，包括在不同模型和算法上进行实验，以及奖励分解实验，来分析PO的行为模式。

Result: PO在开放式CoT结构下倾向于选择阻力最小的路径，即学习忽略显式推理，退化为仅回答模式。这种行为在增加奖励权重后仍然存在。奖励分解实验表明，PO优先优化最简单的奖励成分。

Conclusion: PO在追求高回报的同时，容易利用奖励函数中最简单的部分，对齐过程中存在“奖励窃取”的挑战。

Abstract: Policy optimization (PO) algorithms are used to refine Large Language Models
for complex, multi-step reasoning. Current state-of-the-art pipelines enforce a
strict think-then-answer format to elicit chain-of-thought (CoT); however, the
behavior of PO when these rigid constraints are relaxed into an open-ended CoT
structure remains an under-studied question. We investigate this gap with an
extensive suite of controlled experiments and identify a consistent principle:
\textit{policy optimization consistently follows the path of least resistance}.
When afforded the flexibility to interleave reasoning and response, policy
optimization consistently learns to discard explicit reasoning, causing the
policy to degenerate to a direct \texttt{<answer>}-only format. This outcome
holds true across various models and algorithms. We find that this collapse in
format is persistent even when the complex \texttt{<think><answer>} format is
assigned up to 4x larger reward weights. We formalize this principle through a
series of controlled reward decomposition experiments, demonstrating a clear
hierarchy: PO systematically optimizes for the simplest reward component first,
a preference that holds even when faced with mutually exclusive choices or
strong incentives for more complex behaviors. Finally, we show that successful
convergence on the high-reward shortcut is not a low-effort drift but is driven
by the optimization process that requires the KL-regularized policy to have
sufficient freedom to make a significant shift from its initial prior. Our
findings reveal that granting policies the freedom to diverge is a double-edged
sword: while necessary for discovering high-reward shortcuts, it also creates a
powerful incentive to game the simplest aspects of the reward function, posing
a critical challenge for reward hacking under alignment.

</details>


### [213] [Language Ranker: A Lightweight Ranking framework for LLM Decoding](https://arxiv.org/abs/2510.21883)
*Chenheng Zhang,Tianqi Du,Jizhe Zhang,Mingqing Xiao,Yifei Wang,Yisen Wang,Zhouchen Lin*

Main category: cs.CL

TL;DR: LLM生成可借鉴推荐系统中的排序思想，提出轻量级语言排序框架，在保证性能的同时显著降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有LLM研究侧重输出分布，忽略了解码过程；基于奖励模型的方法计算成本高昂且适用性有限。

Method: 将LLM解码过程类比为推荐系统中的排序阶段，提出名为Language Ranker的框架，使用基础模型提取的特征对候选响应进行重新排序，引入轻量级模块。

Result: Language Ranker在多项任务上的表现可与大规模奖励模型媲美，但额外参数量仅需0.5M，显著降低了训练和推理的计算开销。

Conclusion: Language Ranker框架能够高效且有效地提升LLM性能，展示了其解锁LLM全部潜力的潜力。

Abstract: Conventional research on large language models (LLMs) has primarily focused
on refining output distributions, while paying less attention to the decoding
process that transforms these distributions into final responses. Recent
advances, such as scaling the computation of inference time with reward models,
have underscored the importance of decoding, but these methods often suffer
from high computational costs and limited applicability. In this paper, we
revisit LLM generation through the lens of recommender systems, conceptualizing
the decoding process as analogous to the ranking stage in recommendation
pipelines. From this perspective, we observe that both traditional decoding
methods and reward models exhibit clear limitations such as redundancy.
Motivated by this insight, we propose Language Ranker, a novel framework that
introduces a lightweight module to rerank candidate responses using features
extracted by the base model. Experiments across a wide range of tasks show that
Language Ranker achieves performance comparable to large-scale reward models,
while requiring only <0.5M additional parameters, significantly reducing the
computational overhead during both training and inference stages. This
highlights the efficiency and effectiveness of our method, showcasing its
potential to fully unlock the capabilities of LLMs.

</details>


### [214] [Framework for Machine Evaluation of Reasoning Completeness in Large Language Models For Classification Tasks](https://arxiv.org/abs/2510.21884)
*Avinash Patil*

Main category: cs.CL

TL;DR: 本研究提出了RACE框架，用于评估大型语言模型（LLM）生成解释的准确性，方法是将LLM的解释与逻辑回归基线的可解释特征重要性分数进行比较，发现在正确预测时，解释更侧重于支持性特征，而在错误预测时，则更多地依赖矛盾性特征。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习在敏感领域的应用增加，对透明和可解释的人工智能的需求日益增长。尽管大型语言模型（LLM）能够生成自然语言解释，但尚不清楚这些解释是否真实地反映了其决策的预测信号。

Method: 提出了RACE（Reasoning Alignment for Completeness of Explanations）框架，该框架通过比较LLM生成的解释与从逻辑回归基线得出的可解释特征重要性分数来评估LLM解释与特征重要性分数的一致性。研究分析了四个常用的文本分类数据集（WIKI ONTOLOGY, AG NEWS, IMDB, GOEMOTIONS），并将LLM的解释与排名靠前的支持性和矛盾性词汇特征进行比较。为了在多个粒度级别上捕捉一致性，RACE采用了令牌感知、精确字符串和编辑距离匹配技术。

Result: 实证结果显示出一种持续的不对称性：正确预测显示出更高的支持性特征覆盖率，而错误预测则与更高的矛盾性特征覆盖率相关。编辑距离匹配进一步揭示了释义重叠，提高了覆盖率，同时保持了这种不对称性。这些发现表明，LLM的解释结合了表面证据和灵活的证据复用，但也可能在出错时放大误导性线索。

Conclusion: RACE框架为评估LLM解释的忠实度提供了新的见解，并为量化评估神经语言模型中的推理完整性奠定了基础。研究结果表明，LLM的解释机制在正确和错误预测的情况下表现出不同的模式，这对于理解和改进LLM的可解释性至关重要。

Abstract: The growing adoption of machine learning (ML) in sensitive domains has
heightened the demand for transparent and interpretable artificial
intelligence. Large Language Models (LLMs) are increasingly capable of
producing natural language explanations, yet it remains unclear whether these
rationales faithfully capture the predictive signals that underlie decisions.
This paper introduces RACE-Reasoning Alignment for Completeness of
Explanations, a systematic framework to evaluate the alignment between
LLM-generated explanations and interpretable feature importance scores derived
from a logistic regression baseline. We analyze four widely used text
classification datasets-WIKI ONTOLOGY, AG NEWS, IMDB, and GOEMOTIONS-and
compare LLM rationales against top-ranked supporting and contradicting lexical
features. To capture alignment at multiple levels of granularity, RACE
implements token-aware, exact string, and edit-distance matching techniques.
Empirical results reveal a consistent asymmetry: correct predictions exhibit
higher coverage of supporting features, while incorrect predictions are
associated with elevated coverage of contradicting features. Edit-distance
matching further uncovers paraphrastic overlaps, boosting coverage while
preserving this asymmetry. These findings demonstrate that LLM rationales
combine both surface-level and flexible evidence reuse, yet can also amplify
misleading cues in error cases. RACE provides new insights into the
faithfulness of LLM explanations and establishes a quantitative basis for
evaluating reasoning completeness in neural language models.

</details>


### [215] [Preventing Catastrophic Forgetting: Behavior-Aware Sampling for Safer Language Model Fine-Tuning](https://arxiv.org/abs/2510.21885)
*Anh Pham,Mihir Thalanki,Michael Sun,Aditya Chaloo,Ankita Gupta,Tian Xia,Aditya Mate,Ehimwenma Nosakhare,Soundararajan Srinivasan*

Main category: cs.CL

TL;DR: 通过行为感知采样来减少大语言模型微调过程中的灾难性遗忘，提高安全性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在微调过程中会遗忘已对齐的安全行为，而添加随机安全示例效果不明确，需要更有效的选择方法。

Method: 提出一个行为感知的采样框架，基于指令-响应行为（如拒绝或遵守）和跨危害类别的语义多样性来选择安全示例。

Result: 该方法显著减少了有害输出，同时保持了有用性，在仅增加0.5%的训练数据的情况下，有害性降低了41%。

Conclusion: 有针对性的数据选择可以提高大规模微调的安全性和效率。

Abstract: Large language models often lose previously aligned safety behaviors when
fine-tuned on benign data, a phenomenon known as catastrophic forgetting. Prior
work shows that adding random safety examples can mitigate this effect, but it
remains unclear which examples are most effective. We propose a behavior-aware
sampling framework that selects safety examples based on two complementary
factors: instruction-response behavior (e.g., refusal versus compliance) and
semantic diversity across harm categories. Systematic evaluation shows that
this approach substantially reduces harmful outputs while maintaining
helpfulness, achieving up to a 41% reduction in harmfulness with only 0.5%
additional training data. These results highlight how targeted data selection
can improve the safety and efficiency of fine-tuning at scale.

</details>


### [216] [Embedding Trust: Semantic Isotropy Predicts Nonfactuality in Long-Form Text Generation](https://arxiv.org/abs/2510.21891)
*Dhrupad Bhardwaj,Julia Kempe,Tim G. J. Rudner*

Main category: cs.CL

TL;DR: 通过评估文本嵌入在单位球上的均匀性（语义各向同性）来衡量大型语言模型（LLM）生成内容的可靠性，该方法比现有方法更有效，且成本更低。


<details>
  <summary>Details</summary>
Motivation: 需要一种可靠且计算成本低廉的方法来评估大型语言模型（LLM）在要求实质性准确性的开放式提示中的长篇回复的可信度，而现有方法（如逐条事实核查）成本高昂且不够灵活。

Method: 提出“语义各向同性”的概念，即文本嵌入在单位球上的均匀程度。通过生成多个长篇回复，将其嵌入化，并估计这些回复的语义各向同性水平（以嵌入在单位球上的角度分散度衡量）。

Result: 研究发现，更高的语义各向同性（即更大的嵌入分散度）可靠地预示着跨样本的事实一致性较低。

Conclusion: 所提出的语义各向同性方法无需标记数据、无需微调、无需超参数选择，即可与开放或闭源的嵌入模型配合使用。该方法在多个领域中，通过仅使用少量样本就能持续优于现有方法在预测长篇回复的非事实性方面，为在实际的LLM工作流中整合信任评估提供了一种实用且低成本的解决方案。

Abstract: To deploy large language models (LLMs) in high-stakes application domains
that require substantively accurate responses to open-ended prompts, we need
reliable, computationally inexpensive methods that assess the trustworthiness
of long-form responses generated by LLMs. However, existing approaches often
rely on claim-by-claim fact-checking, which is computationally expensive and
brittle in long-form responses to open-ended prompts. In this work, we
introduce semantic isotropy -- the degree of uniformity across normalized text
embeddings on the unit sphere -- and use it to assess the trustworthiness of
long-form responses generated by LLMs. To do so, we generate several long-form
responses, embed them, and estimate the level of semantic isotropy of these
responses as the angular dispersion of the embeddings on the unit sphere. We
find that higher semantic isotropy -- that is, greater embedding dispersion --
reliably signals lower factual consistency across samples. Our approach
requires no labeled data, no fine-tuning, and no hyperparameter selection, and
can be used with open- or closed-weight embedding models. Across multiple
domains, our method consistently outperforms existing approaches in predicting
nonfactuality in long-form responses using only a handful of samples --
offering a practical, low-cost approach for integrating trust assessment into
real-world LLM workflows.

</details>


### [217] [Understanding Network Behaviors through Natural Language Question-Answering](https://arxiv.org/abs/2510.21894)
*Mingzhe Xing,Chang Tian,Jianan Zhang,Lichen Pan,Peipei Liu,Zhaoteng Yan,Yinliang Yue*

Main category: cs.CL

TL;DR: NetMind是一个利用自然语言理解网络行为的新框架，通过分块、统一事实图和混合语言来克服LLM在处理大规模、异构网络配置时的挑战，并在实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 网络复杂性增加导致误配置风险，而传统的领域特定语言（DSL）学习曲线陡峭且灵活性有限，因此需要更易于访问和可解释的自然语言（NL）接口来理解网络行为。

Method: NetMind采用一种基于树的配置分块策略来保留语义并高效分区；构建统一的事实图来规范特定厂商的配置；设计了一种混合命令式-声明式语言以减轻LLM的推理负担并提高精度。

Result: 实验表明，NetMind在网络行为理解方面实现了准确性和可扩展性，并且优于现有的基线方法。NetMind还包含一个包含自然语言问题-答案对和网络配置的基准。

Conclusion: NetMind框架通过其创新的分块、统一表示和混合语言方法，能够有效解决大规模、异构网络环境中自然语言查询所面临的挑战，实现了准确且可扩展的网络行为理解。

Abstract: Modern large-scale networks introduce significant complexity in understanding
network behaviors, increasing the risk of misconfiguration. Prior work proposed
to understand network behaviors by mining network configurations, typically
relying on domain-specific languages interfaced with formal models. While
effective, they suffer from a steep learning curve and limited flexibility. In
contrast, natural language (NL) offers a more accessible and interpretable
interface, motivating recent research on NL-guided network behavior
understanding. Recent advances in large language models (LLMs) further enhance
this direction, leveraging their extensive prior knowledge of network concepts
and strong reasoning capabilities. However, three key challenges remain: 1)
numerous router devices with lengthy configuration files challenge LLM's
long-context understanding ability; 2) heterogeneity across devices and
protocols impedes scalability; and 3) complex network topologies and protocols
demand advanced reasoning abilities beyond the current capabilities of LLMs. To
tackle the above challenges, we propose NetMind, a novel framework for querying
networks using NL. Our approach introduces a tree-based configuration chunking
strategy to preserve semantic coherence while enabling efficient partitioning.
We then construct a unified fact graph as an intermediate representation to
normalize vendor-specific configurations. Finally, we design a hybrid
imperative-declarative language to reduce the reasoning burden on LLMs and
enhance precision. We contribute a benchmark consisting of NL question-answer
pairs paired with network configurations. Experiments demonstrate that NetMind
achieves accurate and scalable network behavior understanding, outperforming
existing baselines.

</details>


### [218] [Deep Literature Survey Automation with an Iterative Workflow](https://arxiv.org/abs/2510.21900)
*Hongbo Zhang,Han Cui,Yidong Wang,Yijian Tian,Qi Guo,Cunxiang Wang,Jian Wu,Chiyu Song,Yue Zhang*

Main category: cs.CL

TL;DR: 通过迭代式大纲生成来改进自动文献综述的生成，解决了现有方法中的噪声检索、碎片化结构和上下文过载问题。


<details>
  <summary>Details</summary>
Motivation: 现有自动文献综述系统通常采用一次性方法，导致检索噪声大、结构碎片化和上下文信息过载，限制了综述质量。

Method: 提出了一种基于循环大纲生成的框架（\ours），通过规划代理逐步检索、阅读和更新大纲，以实现探索性和一致性。设计了“论文卡片”来提炼每篇论文的贡献、方法和发现，并引入了带有可视化增强的审查和优化循环，以改善文本流畅性并整合如图表等多模态元素。

Result: 在既有和新兴课题上的实验表明，\ours
在内容覆盖度、结构一致性和引用质量方面显著优于现有最先进方法，并生成了更易于理解和组织更好的综述。

Conclusion: 所提出的迭代式方法能够生成更高质量的自动文献综述，并且引入的Survey-Arena基准提供了对生成系统更可靠的评估。

Abstract: Automatic literature survey generation has attracted increasing attention,
yet most existing systems follow a one-shot paradigm, where a large set of
papers is retrieved at once and a static outline is generated before drafting.
This design often leads to noisy retrieval, fragmented structures, and context
overload, ultimately limiting survey quality. Inspired by the iterative reading
process of human researchers, we propose \ours, a framework based on recurrent
outline generation, in which a planning agent incrementally retrieves, reads,
and updates the outline to ensure both exploration and coherence. To provide
faithful paper-level grounding, we design paper cards that distill each paper
into its contributions, methods, and findings, and introduce a
review-and-refine loop with visualization enhancement to improve textual flow
and integrate multimodal elements such as figures and tables. Experiments on
both established and emerging topics show that \ours\ substantially outperforms
state-of-the-art baselines in content coverage, structural coherence, and
citation quality, while producing more accessible and better-organized surveys.
To provide a more reliable assessment of such improvements, we further
introduce Survey-Arena, a pairwise benchmark that complements absolute scoring
and more clearly positions machine-generated surveys relative to human-written
ones. The code is available at
https://github.com/HancCui/IterSurvey\_Autosurveyv2.

</details>


### [219] [Explaining and Mitigating Crosslingual Tokenizer Inequities](https://arxiv.org/abs/2510.21909)
*Catherine Arnett,Tyler A. Chang,Stella Biderman,Benjamin K. Bergen*

Main category: cs.CL

TL;DR: 不同语言的并行文本编码在不同语言上的标记数不同，称为标记溢价。高标记溢价会导致训练吞吐量降低和推理成本增加。即使在控制了数据集大小、词汇量大小和数据内容之后，单语标记器在不同语言之间的标记溢价也存在很大差异。通过训练大约 7000 个可比的单语标记器来研究跨语言差异，我们发现词汇量大小和预标记会影响标记溢价。增加词汇量大小并不能减少标记溢价效应，但可以确定每个语言的“最佳”词汇量大小以显着降低标记溢价效应。我们还训练了允许空格合并的超级词标记器，它们可以减少标记溢价效应并提高整体压缩率。因此，干预词汇量大小或预标记器可以显着降低跨语言标记溢价效应。


<details>
  <summary>Details</summary>
Motivation: 标记溢价（即不同语言的并行文本编码所需的标记数差异）会导致训练吞吐量降低和推理成本增加。理解并减少这种跨语言差异至关重要。

Method: 训练了约 7000 个可比的单语标记器，涵盖 97 种语言，并操纵了标记化算法、词汇量大小和数据集大小。测量标记溢价，并测试数据相似性、词汇量大小、预标记以及书写系统和单词长度等语言特定特征与标记溢价之间的关系。

Result: 在控制了数据集大小、词汇量大小和数据内容后，单语标记器在不同语言之间表现出广泛的标记溢价。数据相似性不影响标记溢价，但词汇量大小和预标记会影响标记溢价。虽然增加词汇量大小本身并不能减少标记溢价效应，但可以确定每个语言的“最佳”词汇量大小以显着降低标记溢价效应。训练允许空格合并的超级词标记器可以减少标记溢价效应并提高整体压缩率。

Conclusion: 通过调整词汇量大小或采用预标记策略（例如超级词标记器）可以显着降低跨语言标记溢价效应。

Abstract: The number of tokens it takes to encode parallel text in different languages
is known to vary. These disparities are called token premiums. Having high
token premiums leads to less throughput during training and increases costs at
inference. In this paper, we show that even after controlling for dataset size,
vocabulary size, and data content, monolingual tokenizers exhibit a wide range
of token premiums across languages. To understand the cross-linguistic
differences that cause these token premiums, we train a suite of approximately
7,000 comparable monolingual tokenizers for 97 languages, manipulating
tokenization algorithm, vocabulary size, and dataset size. We measure token
premiums and test for a relationship between factors such as data similarity
(between tokenizer training and evaluation), vocabulary size, and
pre-tokenization. We also investigate the role of language-specific features
such as writing system and word length. We find that similarity between
training and test data does not impact token premiums, but vocabulary size and
pre-tokenization do. While simply increasing vocabulary size does not lead to
reduced token premium effects, we can determine an ``optimal'' vocabulary size
for each language to achieve significantly reduced token premium effects. We
also train superword tokenizers which allow merges over whitespaces, and we
find that they both reduce token premium effects and improve compression
overall. Thus, intervening on the vocabulary size or the pre-tokenizer
significantly reduces crosslingual token premium effects.

</details>


### [220] [Model-Aware Tokenizer Transfer](https://arxiv.org/abs/2510.21954)
*Mykola Haltiuk,Aleksander Smywiński-Pohl*

Main category: cs.CL

TL;DR: LLMs 的分词器限制了它们对低资源或非拉丁字母语言的适应性。现有方法依赖语义启发式，忽略了模型内部动态。我们提出了模型感知分词器迁移 (MATT)，它通过注意力影响建模 (AIM) 目标将源模型的跨分词器通信模式融入目标模型，从而在标准语言建模之前进行高效预热。MATT 在 GPU 上仅需几小时即可恢复大部分原始模型性能，优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有的 LLM 分词器迁移方法忽略了模型内部动态，限制了迁移质量，尤其是在低资源或使用不同脚本的语言方面。

Method: MATT 引入了一种注意力影响建模 (AIM) 目标，将源模型中的跨分词器通信模式蒸馏到具有新分词器的目标模型中，从而在进行标准语言建模之前提供有效的预热。

Result: 在不同语言环境下进行的实验表明，MATT 可以在几小时内恢复大部分原始模型性能，并且优于基于启发式的方法。

Conclusion: 将模型内部信号纳入分词器迁移过程，是实现多语言 LLM 中稳健分词器迁移的实用且有效的方法。

Abstract: Large Language Models (LLMs) are trained to support an increasing number of
languages, yet their predefined tokenizers remain a bottleneck for adapting
models to lower-resource or distinct-script languages. Existing tokenizer
transfer methods typically rely on semantic heuristics to initialize new
embeddings, ignoring higher-layer model dynamics and limiting transfer quality.
We propose Model-Aware Tokenizer Transfer (MATT), a method that incorporates
model internals into the tokenizer transfer process. MATT introduces an
Attention Influence Modeling (AIM) objective that distills inter-token
communication patterns from a source model into a target model with a new
tokenizer, providing an efficient warm-up before standard language modeling.
Unlike approaches that focus solely on embedding similarity, MATT leverages
attention behavior to guide embedding initialization and adaptation.
Experiments across diverse linguistic settings show that MATT recovers a large
fraction of the original model's performance within a few GPU hours,
outperforming heuristic baselines. These results demonstrate that incorporating
model-level signals offers a practical and effective path toward robust
tokenizer transfer in multilingual LLMs.

</details>


### [221] [A Stylometric Application of Large Language Models](https://arxiv.org/abs/2510.21958)
*Harrison F. Stropkay,Jiayi Chen,Mohammad J. Latifi,Daniel N. Rockmore,Jeremy R. Manning*

Main category: cs.CL

TL;DR: LLMs can identify authors by their writing styles. A GPT-2 model trained on one author's work can better predict that author's text than others'. This method confirmed R. P. Thompson as the author of an Oz book.


<details>
  <summary>Details</summary>
Motivation: To demonstrate that LLMs can distinguish between different authors' writing styles and to apply this method to confirm authorship.

Method: Train a GPT-2 model from scratch on an author's works and test its accuracy in predicting text from known and unknown authors. Apply this to a specific case of disputed authorship.

Result: A GPT-2 model trained on one author's work shows higher accuracy in predicting that author's held-out text compared to other authors' texts. The method successfully confirmed R. P. Thompson's authorship.

Conclusion: LLMs can effectively embody and identify an author's unique writing style, as demonstrated by the accuracy of trained models and the successful resolution of an authorship attribution case.

Abstract: We show that large language models (LLMs) can be used to distinguish the
writings of different authors. Specifically, an individual GPT-2 model, trained
from scratch on the works of one author, will predict held-out text from that
author more accurately than held-out text from other authors. We suggest that,
in this way, a model trained on one author's works embodies the unique writing
style of that author. We first demonstrate our approach on books written by
eight different (known) authors. We also use this approach to confirm R. P.
Thompson's authorship of the well-studied 15th book of the Oz series,
originally attributed to F. L. Baum.

</details>


### [222] [Uncovering the Persuasive Fingerprint of LLMs in Jailbreaking Attacks](https://arxiv.org/abs/2510.21983)
*Havva Alizadeh Noughabi,Julien Serbanescu,Fattane Zarrinkalam,Ali Dehghantanha*

Main category: cs.CL

TL;DR: 尽管LLM取得了进展，但它们仍然容易受到绕过对齐防护并产生有害输出的越狱攻击。本研究探讨了利用社会科学中的说服理论来Craft对抗性提示，以规避LLM中的对齐约束，并研究LLM是否会对其越狱响应产生独特的说服性指纹。实验表明，具有说服性的提示可以显著绕过安全防护，凸显了跨学科研究在解决LLM安全挑战中的重要性。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是解决大型语言模型（LLM）在面对越狱攻击时仍然存在的脆弱性问题，特别是那些能够绕过对齐防护并诱导有害输出的攻击。尽管已有多种攻击策略被提出，但很少有研究关注影响模型对攻击敏感性的语言和心理机制。因此，本研究旨在借鉴社会科学中的说服理论，探索一种新的攻击范式。

Method: 本研究采用跨学科方法，借鉴社会科学中的说服理论来Craft对抗性提示，以期绕过大型语言模型（LLM）的对齐约束。研究者假设，经过大规模人类生成文本训练的LLM可能会更顺从地响应具有说服性结构的提示。此外，研究者还调查了LLM是否会对其越狱响应产生独特地说服性指纹。通过在多个对齐的LLM上进行实证评估来验证这些假设。

Result: 实证评估结果表明，采用说服性策略的提示能够显著绕过LLM的安全防护机制，成功诱导越狱行为。这证明了这种方法在规避LLM对齐约束方面的有效性。此外，研究还发现LLM在其越狱响应中可能展现出独特地说服性指纹。

Conclusion: 本研究得出结论，利用社会科学中的说服理论来Craft对抗性提示是一种有效的方法，可以绕过大型语言模型（LLM）的对齐防护机制，并诱导其产生有害输出。研究结果强调了跨学科洞察力在应对不断发展的LLM安全挑战方面的重要性。所提出的方法和发现为开发更强大的LLM安全措施提供了新的视角。

Abstract: Despite recent advances, Large Language Models remain vulnerable to jailbreak
attacks that bypass alignment safeguards and elicit harmful outputs. While
prior research has proposed various attack strategies differing in human
readability and transferability, little attention has been paid to the
linguistic and psychological mechanisms that may influence a model's
susceptibility to such attacks. In this paper, we examine an interdisciplinary
line of research that leverages foundational theories of persuasion from the
social sciences to craft adversarial prompts capable of circumventing alignment
constraints in LLMs. Drawing on well-established persuasive strategies, we
hypothesize that LLMs, having been trained on large-scale human-generated text,
may respond more compliantly to prompts with persuasive structures.
Furthermore, we investigate whether LLMs themselves exhibit distinct persuasive
fingerprints that emerge in their jailbreak responses. Empirical evaluations
across multiple aligned LLMs reveal that persuasion-aware prompts significantly
bypass safeguards, demonstrating their potential to induce jailbreak behaviors.
This work underscores the importance of cross-disciplinary insight in
addressing the evolving challenges of LLM safety. The code and data are
available.

</details>


### [223] [Toward Understanding the Transferability of Adversarial Suffixes in Large Language Models](https://arxiv.org/abs/2510.22014)
*Sarah Ball,Niki Hasrati,Alexander Robey,Avi Schwarzschild,Frauke Kreuter,Zico Kolter,Andrej Risteski*

Main category: cs.CL

TL;DR: 离散优化攻击的“越狱”后缀具有可迁移性，这并非由提示的语义相似性驱动，而是由其在模型内部的拒绝方向上的统计特性决定。


<details>
  <summary>Details</summary>
Motivation: 填补当前研究在理论和实证层面缺乏对大型语言模型“越狱”攻击中后缀可迁移性进行严谨分析的空白。

Method: 识别并分析了三个与后缀可迁移性高度相关的统计特性：（1）原始提示激活模型内部拒绝方向的程度；（2）后缀将模型推离拒绝方向的强度；（3）后缀在与拒绝方向正交的方向上引起的偏移幅度。同时，也验证了提示语义相似性与可迁移性之间的弱相关性。

Result: 研究发现，提示激活拒绝方向的程度、后缀推离拒绝方向的强度以及在正交方向上的偏移幅度是影响后缀可迁移性的关键因素，而提示的语义相似性影响甚微。

Conclusion: 对后缀可迁移性的统计特性进行深入理解，有助于改进攻击的成功率，并通过干预性实验证明了所提出统计分析方法的有效性。

Abstract: Discrete optimization-based jailbreaking attacks on large language models aim
to generate short, nonsensical suffixes that, when appended onto input prompts,
elicit disallowed content. Notably, these suffixes are often transferable --
succeeding on prompts and models for which they were never optimized. And yet,
despite the fact that transferability is surprising and empirically
well-established, the field lacks a rigorous analysis of when and why transfer
occurs. To fill this gap, we identify three statistical properties that
strongly correlate with transfer success across numerous experimental settings:
(1) how much a prompt without a suffix activates a model's internal refusal
direction, (2) how strongly a suffix induces a push away from this direction,
and (3) how large these shifts are in directions orthogonal to refusal. On the
other hand, we find that prompt semantic similarity only weakly correlates with
transfer success. These findings lead to a more fine-grained understanding of
transferability, which we use in interventional experiments to showcase how our
statistical analysis can translate into practical improvements in attack
success.

</details>


### [224] [Penalizing Length: Uncovering Systematic Bias in Quality Estimation Metrics](https://arxiv.org/abs/2510.22028)
*Yilin Zhang,Wenda Xu,Zhongtao Liu,Tetsuji Nakagawa,Markus Freitag*

Main category: cs.CL

TL;DR: QE指标存在长度偏差，会过度预测长句子的错误并偏好较短的翻译，即使它们质量不高。提出了长度归一化和引入参考文本的缓解策略。


<details>
  <summary>Details</summary>
Motivation: 在机器翻译的质量评估（QE）中，长度偏差的影响和普遍性尚未得到充分研究，而QE指标对于无参考评估和作为强化学习的奖励信号至关重要。

Method: 通过对10种不同语言对的顶级回归QE指标和LLM-as-a-Judge QE指标进行系统性研究，揭示了两种关键的长度偏差。

Result: QE指标持续地过度预测随着翻译长度增加而出现的错误，即使对于高质量、无错误的文本也是如此。当有多个候选翻译文本时，QE指标偏好较短的翻译。然而，长度归一化和引入参考文本的策略能有效减轻这些偏差。

Conclusion: QE指标中存在的长度偏差会不公平地惩罚较长但正确的翻译，并可能导致QE重新排序和QE指导的强化学习等应用中的次优决策。所提出的缓解策略可以有效减少长度偏差。

Abstract: Quality Estimation (QE) metrics are vital in machine translation for
reference-free evaluation and as a reward signal in tasks like reinforcement
learning. However, the prevalence and impact of length bias in QE have been
underexplored. Through a systematic study of top-performing regression-based
and LLM-as-a-Judge QE metrics across 10 diverse language pairs, we reveal two
critical length biases: First, QE metrics consistently over-predict errors with
increasing translation length, even for high-quality, error-free texts. Second,
they exhibit a preference for shorter translations when multiple candidates are
available for the same source text. These inherent length biases risk unfairly
penalizing longer, correct translations and can lead to sub-optimal
decision-making in applications such as QE reranking and QE guided
reinforcement learning. To mitigate this, we propose two strategies: (a)
applying length normalization during model training, and (b) incorporating
reference texts during evaluation. Both approaches were found to effectively
reduce the identified length bias.

</details>


### [225] [ATLAS: Adaptive Transfer Scaling Laws for Multilingual Pretraining, Finetuning, and Decoding the Curse of Multilinguality](https://arxiv.org/abs/2510.22037)
*Shayne Longpre,Sneha Kudugunta,Niklas Muennighoff,I-Hung Hsu,Isaac Caswell,Alex Pentland,Sercan Arik,Chen-Yu Lee,Sayna Ebrahimi*

Main category: cs.CL

TL;DR: 英文AI模型主要服务于国际用户，而现有研究主要集中在英文上，因此本研究进行了大规模多语言模型扩展定律研究，发现了新的自适应迁移扩展定律（ATLAS），并分析了多语言学习动态、语言间迁移和多语言诅咒等问题，为多语言模型扩展提供了理论基础。


<details>
  <summary>Details</summary>
Motivation: 现有AI模型主要服务于国际用户，但Scaling laws的研究主要集中在英文上，这与模型实际应用场景不符。

Method: 进行了774次多语言训练实验，涵盖10M-8B模型参数、400多种训练语言和48种评估语言。提出自适应迁移扩展定律（ATLAS），并分析了跨语言迁移、语言无关扩展定律以及从头预训练与微调的计算交叉点。

Result: ATLAS在样本外泛化能力上优于现有扩展定律，R^2提升超过0.3。得出了跨语言迁移矩阵，量化了1444种语言对之间的互惠得分。推导了语言无关扩展定律，指出了在不牺牲性能的情况下，增加语言时最优的模型大小和数据扩展方法。确定了从头预训练与微调的计算交叉点。

Conclusion: 本研究提出的ATLAS以及对多语言学习动态、迁移特性和多语言诅咒的分析，为跨语言扩展定律的民主化提供了科学基础，并能帮助实践者更有效地扩展模型，超越以英语为中心的人工智能。

Abstract: Scaling laws research has focused overwhelmingly on English -- yet the most
prominent AI models explicitly serve billions of international users. In this
work, we undertake the largest multilingual scaling laws study to date,
totaling 774 multilingual training experiments, spanning 10M-8B model
parameters, 400+ training languages and 48 evaluation languages. We introduce
the Adaptive Transfer Scaling Law (ATLAS) for both monolingual and multilingual
pretraining, which outperforms existing scaling laws' out-of-sample
generalization often by more than 0.3 R^2. Our analyses of the experiments shed
light on multilingual learning dynamics, transfer properties between languages,
and the curse of multilinguality. First, we derive a cross-lingual transfer
matrix, empirically measuring mutual benefit scores between 38 x 38=1444
language pairs. Second, we derive a language-agnostic scaling law that reveals
how to optimally scale model size and data when adding languages without
sacrificing performance. Third, we identify the computational crossover points
for when to pretrain from scratch versus finetune from multilingual
checkpoints. We hope these findings provide the scientific foundation for
democratizing scaling laws across languages, and enable practitioners to
efficiently scale models -- beyond English-first AI.

</details>


### [226] [Emotions Where Art Thou: Understanding and Characterizing the Emotional Latent Space of Large Language Models](https://arxiv.org/abs/2510.22042)
*Benjamin Reichman,Adar Avsian,Larry Heck*

Main category: cs.CL

TL;DR: LLMs在内部表示情感时，其隐藏状态空间呈现出一种低维的情感流形，情感表征以方向编码、跨层分布并与可解释的维度对齐。这种结构在深度上是稳定的，并能推广到八个跨五种语言的真实世界情感数据集。跨域对齐表现出低误差和强烈的线性探针性能，表明存在一个通用的情感子空间。在该空间内，可以通过学习到的干预模块来引导内部情感感知，同时保持语义，并且在跨语言的基本情感方面表现出尤其强的控制力。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型（LLMs）如何通过分析其隐藏状态空间的几何结构来在内部表示情感。

Method: 通过分析LLMs隐藏状态空间的几何结构来识别低维情感流形，并研究情感表征的方向编码、跨层分布和与可解释维度的对齐情况。使用学习到的干预模块来引导内部情感感知，同时保持语义。

Result: LLMs的隐藏状态空间存在一个低维的情感流形，情感表征以方向编码、跨层分布并与可解释的维度对齐。这种结构在深度上是稳定的，并能推广到八个跨五种语言的真实世界情感数据集。跨域对齐表现出低误差和强烈的线性探针性能，表明存在一个通用的情感子空间。通过干预模块可以有效引导内部情感感知，尤其是在跨语言的基本情感方面。

Conclusion: LLMs内部存在一种一致且可操控的情感几何结构，这为了解它们如何内化和处理情感提供了新的见解。

Abstract: This work investigates how large language models (LLMs) internally represent
emotion by analyzing the geometry of their hidden-state space. The paper
identifies a low-dimensional emotional manifold and shows that emotional
representations are directionally encoded, distributed across layers, and
aligned with interpretable dimensions. These structures are stable across depth
and generalize to eight real-world emotion datasets spanning five languages.
Cross-domain alignment yields low error and strong linear probe performance,
indicating a universal emotional subspace. Within this space, internal emotion
perception can be steered while preserving semantics using a learned
intervention module, with especially strong control for basic emotions across
languages. These findings reveal a consistent and manipulable affective
geometry in LLMs and offer insight into how they internalize and process
emotion.

</details>


### [227] [Compositional Bias Control in Large Language Models: Preference Learning Fails, Supervision Succeeds](https://arxiv.org/abs/2510.22084)
*Atij Mahesh*

Main category: cs.CL

TL;DR: LLMs 仍会产生性别刻板印象语言，已有技术（提示、约束解码、后处理、微调）用于缓解，但效果和学习动态仍不明确。


<details>
  <summary>Details</summary>
Motivation: LLMs 仍会产生性别刻板印象语言，现有缓解技术的效果和学习动态仍不明确，需要进行比较分析。

Method: 比较分析了六种偏见缓解技术：仅提示、生成-过滤、DFA-based Ctrl-G解码、监督微调（SFT）、直接偏好优化（DPO）和迭代零空间投影（INLP），在需要生成包含代理和共情描述符的句子任务上进行评估。

Result: SFT 在合规性和词汇多样性方面表现最佳（99.87% 合规性），Ctrl-G 保证完美合规但牺牲流畅性和多样性，DPO 等偏好学习方法无法满足组合约束（4.53% 合规性）。

Conclusion: 偏好学习无法满足组合约束，仅有显式正向监督才能缓解组合偏见，表明偏好学习的局限性以及显式监督对于公平和流畅的受控生成至关重要。

Abstract: Large Language Models (LLMs) still produce gender-stereotyped language even
in occupation-neutral contexts that reflect deep societal biases (Rudinger et
al., 2018). To address this, prior work has proposed prompting, constrained
decoding (Dathathri et al., 2020; Zhou et al., 2024), post-processing, and
fine-tuning-based alignment (Rafailov et al., 2023; Ravfogel et al., 2022).
However, the comparative efficacy and learning dynamics remain little
understood. We report a comparative analysis of six control techniques for bias
mitigation: prompt-only, generate-and-filter, DFA-based Ctrl-G decoding,
Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and
Iterative Nullspace Projection (INLP). We evaluate each method on a
compositional constraint task. This task requires generating sentences that
contain at least one agentic and one communal descriptor for each of the twenty
Winogender-derived occupations. We quantify trade-offs between control strength
and naturalness with evaluations of constraint compliance, lexical diversity,
and fluency. Our results reveal key contrasts among the methods: SFT achieves
99.87 +- 0.15% compliance and high lexical diversity, while DPO, despite
similar training stability, fails at 4.53 +- 0.82%. Ctrl-G guarantees perfect
compliance, but at the cost of severely reduced fluency and diversity.
Preference-based learning fundamentally differs: it cannot satisfy
compositional constraints, as binary preference signals encode ranking, not
logical conjunctions. Only explicit positive supervision enables mitigation of
compositional biases; preference-based alignment fails to generalize logical
structures, underscoring the limitations of preference learning and the
necessity of explicit supervision for fair and fluent controlled generation.

</details>


### [228] [Generalization or Memorization: Dynamic Decoding for Mode Steering](https://arxiv.org/abs/2510.22099)
*Xuanming Zhang*

Main category: cs.CL

TL;DR: LLMs 表现出泛化和死记硬背的双重性，这影响了它们在高风险应用中的可靠性。本文提出了一个统一的框架来理解、识别和控制这些不同的推理模式。该框架基于信息瓶颈（IB）原理，将泛化形式化为学习压缩的、任务相关的表示，并将记忆视为压缩失败。在此理论基础上，我们开发了动态模式引导（DMS），这是一种新颖的推理时间算法，包括一个识别模型对记忆的即时依赖性的轻量级、因果相关线性探测器，以及一个动态激活引导机制，将模型的计算引导至预先识别的泛化电路。DMS 被视为一种自适应的、自对比的解码形式。在推理和忠实性任务上的实验表明，DMS 显著提高了逻辑一致性和事实准确性，从而为提高 LLM 的可靠性提供了一个有原则的方法。


<details>
  <summary>Details</summary>
Motivation: LLMs 表现出泛化和死记硬背的双重性，这影响了它们在高风险应用中的可靠性。

Method: 本文提出了一个统一的框架来理解、识别和控制这些不同的推理模式。该框架基于信息瓶颈（IB）原理，将泛化形式化为学习压缩的、任务相关的表示，并将记忆视为压缩失败。在此理论基础上，我们开发了动态模式引导（DMS），这是一种新颖的推理时间算法，包括一个识别模型对记忆的即时依赖性的轻量级、因果相关线性探测器，以及一个动态激活引导机制，将模型的计算引导至预先识别的泛化电路。DMS 被视为一种自适应的、自对比的解码形式。

Result: 在推理和忠实性任务上的实验表明，DMS 显著提高了逻辑一致性和事实准确性。

Conclusion: DMS 为提高 LLM 的可靠性提供了一个有原则的方法。

Abstract: Large Language Models (LLMs) exhibit a troubling duality, capable of both
remarkable generalization and brittle, verbatim memorization of their training
data. This unpredictability undermines their reliability in high-stakes
applications. In this work, we propose a unified framework to understand,
identify, and control these distinct reasoning modes. First, we introduce a
theoretical model based on the Information Bottleneck (IB) principle,
formalizing generalization as the learning of a compressed, task-relevant
representation and memorization as a failure to compress. Building on this
theory, we develop Dynamic Mode Steering (DMS), a novel inference-time
algorithm which comprises two components: (1) a lightweight, causally-grounded
linear probe that identifies the model's instantaneous reliance on
memorization, and (2) a dynamic activation steering mechanism that nudges the
model's computation towards pre-identified generalization circuits. We frame
DMS as a form of adaptive, self-contrastive decoding. Experiments on reasoning
and faithfulness tasks demonstrate that DMS significantly improves logical
consistency and factual accuracy, thereby offering a principled approach to
enhancing LLM reliability.

</details>


### [229] [Gradual Forgetting: Logarithmic Compression for Extending Transformer Context Windows](https://arxiv.org/abs/2510.22109)
*Billy Dickson,Zoran Tiganj*

Main category: cs.CL

TL;DR: 通过对输入标记进行尺度不变的对数压缩来处理长上下文，而不是修改 Transformer 架构。


<details>
  <summary>Details</summary>
Motivation: 现有处理长上下文的方法通常会增加 Transformer 内部架构的复杂性。本文提出一种替代方法，通过修改输入表示而不是 Transformer 架构来处理长上下文。

Method: 将尺度不变的对数压缩应用于输入标记，然后使用标准 Transformer 处理压缩后的表示。

Result: 在 WikiText-103 和 PG-19 语言建模基准上，与未压缩的基线相比，该方法可降低困惑度，并且随着压缩时间上下文的增加，性能会持续提高。

Conclusion: 输入级别的对数压缩是扩展 Transformer 长期记忆的简单有效的方法。

Abstract: Most approaches to long-context processing increase the complexity of the
transformer's internal architecture by integrating mechanisms such as
recurrence or auxiliary memory modules. In this work, we introduce an
alternative approach that modifies the input representation itself, rather than
the transformer architecture. Inspired by cognitive models of human memory, our
method applies a scale-invariant logarithmic compression to the input tokens.
The resulting compressed representation is processed by a standard, unmodified
transformer, preserving architectural simplicity. We evaluate this approach on
the WikiText-103 and PG-19 language modeling benchmarks, showing a reduction in
perplexity compared to uncompressed baselines. Moreover, performance improves
consistently with longer compressed temporal contexts, showing that input-level
logarithmic compression is a simple and effective way to extend a transformer's
long-range memory.

</details>


### [230] [Every Activation Boosted: Scaling General Reasoner to 1 Trillion Open Language Foundation](https://arxiv.org/abs/2510.22115)
*Ling-Team,Ang Li,Ben Liu,Binbin Hu,Bing Li,Bingwei Zeng,Borui Ye,Caizhi Tang,Changxin Tian,Chao Huang,Chao Zhang,Chen Qian,Chenchen Ju,Chenchen Li,Chengfu Tang,Chili Fu,Chunshao Ren,Chunwei Wu,Cong Zhang,Cunyin Peng,Dafeng Xu,Daixin Wang,Dalong Zhang,Dingnan Jin,Dingyuan Zhu,Dongke Hu,Fangzheng Zhao,Feifan Wu,Feng Zhu,Gangshan Wang,Haitao Zhang,Hailin Zhao,Hanxiao Zhang,Hanzi Wang,Hao Qian,Haoyi Yu,Heng Zhang,Hongliang Zhang,Hongzhi Luan,Huirong Dong,Huizhong Li,Jia Li,Jia Liu,Jialong Zhu,Jian Sha,Jianping Wei,Jiaolong Yang,Jieyue Ma,Jiewei Wu,Jinjing Huang,Jingyun Tian,Jingyuan Zhang,Jinquan Sun,Juanhui Tu,Jun Liu,Jun Xu,Jun Zhou,Junjie Ou,Junpeng Fang,Kaihong Zhang,Kaiqin Hu,Ke Shi,Kun Tang,Kunlong Chen,Lanyin Mei,Lei Liang,Lei Xu,Libo Zhang,Lin Ju,Lin Yuan,Ling Zhong,Lintao Ma,Lu Liu,Lu Yu,Lun Cai,Meiqi Zhu,Mengying Li,Min Chen,Minghao Xue,Minghong Cai,Mingming Yin,Peijie Jiang,Peilong Zhao,Pingping Liu,Qian Zhao,Qing Cui,Qingxiang Huang,Qingyuan Yang,Quankun Yu,Shaowei Wei,Shijie Lian,Shoujian Zheng,Shun Song,Shungen Zhang,Shuo Zhang,Siyuan Li,Song Liu,Ting Guo,Tong Zhao,Wanli Gu,Weichang Wu,Weiguang Han,Wenjing Fang,Wubin Wang,Xiang Shu,Xiao Shi,Xiaoshun Lan,Xiaolu Zhang,Xiaqing Sun,Xin Zhao,Xingyu Lu,Xiong Xu,Xudong Wang,Xudong Wang,Xuemin Yang,Yajie Yang,Yang Xiang,Yanzhe Li,Yi Zhang,Yilong Wang,Yingxue Li,Yongzhen Guo,Yuzhuo Fu,Yuanyuan Wang,Yue Yang,Yue Yu,Yufeng Deng,Yun Zhang,Yunfei Xu,Yuqi Zhang,Yuxiao He,Zengke Gui,Zhaoxin Huan,Zhaoyang Wang,Zhibo Zhu,Zhihao Wang,Zhiqiang Zhang,Zhoufei Wang,Zihang Zeng,Ziqi Liu,Zitao Xuan,Zuoli Tang*

Main category: cs.CL

TL;DR: Ling 2.0是一个基于Mixture-of-Experts（MoE）范式的系列化语言模型，旨在提高推理能力和计算效率，其参数规模从数十亿到万亿不等，并提出了多种创新技术以优化模型性能。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是构建一个能够扩展到万亿参数规模、同时提高推理能力和计算效率的语言模型基础。通过在每个激活中融入推理能力，并采用MoE范式，旨在实现比密集模型更高的效率。

Method: 研究采用高稀疏度的MoE架构，结合MTP（混合专家并行）、推理导向数据、中间训练CoT激活、DFT和Evo-CoT等强化学习微调技术，以及全规模FP8训练和细粒度异构流水线。模型规模从Ling-mini-2.0（16B）到Ling-1T（1T）不等。

Result: Ling 2.0系列模型实现了高达7倍于密集模型的计算效率。其中，Ling-1T模型在推理准确性和计算效率之间达到了新的帕累托前沿，证明了稀疏激活在推理任务上的可扩展性和效率。

Conclusion: Ling 2.0系列模型为未来推理和思考模型（包括基于相同基础构建的Ring系列）提供了一个统一、开放且高效的基础，展示了稀疏激活在实现可扩展和高效智能方面的潜力。

Abstract: We introduce Ling 2.0, a series reasoning-oriented language foundation built
upon the principle that every activation boosts reasoning capability. Designed
to scale from tens of billions to one trillion parameters under a unified
Mixture-of-Experts (MoE) paradigm, Ling 2.0 emphasizes high sparsity,
cross-scale consistency, and efficiency guided by empirical scaling laws. The
series includes three non-thinking (instruct) models - Ling-mini-2.0,
Ling-flash-2.0, and Ling-1T - ranging from 16B to 1T total parameters and
achieving up to 7-fold active-compute efficiency compared with dense
counterparts. Ling 2.0 integrates coordinated innovations across model
architecture, pre-training, post-training, and infrastructure: a high-sparsity
MoE with MTP for efficient reasoning, reasoning-oriented data and mid-training
CoT activation, reinforcement-based fine-tuning (DFT, Evo-CoT), and full-scale
FP8 training with fine-grained heterogeneous pipelines. At the trillion scale,
Ling-1T establishes a new Pareto frontier of reasoning accuracy versus
computational efficiency, demonstrating that sparse activation, when properly
aligned with reasoning objectives, enables scalable and efficient intelligence.
Collectively, Ling 2.0 provides a coherent, open, and efficient foundation for
advancing future reasoning and thinking models, including the Ring series built
upon the same base.

</details>


### [231] [OlaMind: Towards Human-Like and Hallucination-Safe Customer Service for Retrieval-Augmented Dialogue](https://arxiv.org/abs/2510.22143)
*Tianhong Gao,Jundong Shen,Bei Shi,Jiapeng Wang,Ying Ju,Junfeng Yao,Jiao Ran,Yong Zhang,Lin Dong,Huiyu Yu,Tingting Ye*

Main category: cs.CL

TL;DR: OlaMind是一个用于检索增强对话的类人、防幻觉客服框架，通过学习推理过程和响应策略，并在大规模A/B实验中显著提高了智能解决率并降低了人工接管率。


<details>
  <summary>Details</summary>
Motivation: 现有的通过检索增强生成(RAG)实现的智能客服(ICS)系统虽然提高了自动化和效率，但仍存在幻觉和生成僵硬、机械的回复等问题，尤其是在Web客户服务交互场景下，这会带来业务风险并影响用户体验。

Method: OlaMind框架首先通过‘Learn-to-Think’阶段学习人类专家的推理过程和响应策略，然后通过‘Learn-to-Respond’阶段进行冷启动监督微调(SFT)，并结合强化学习(RL)进行由易到难的自我完善。

Result: OlaMind在行业级社交客服场景的大规模在线A/B实验中，在社区支持场景下智能解决率提高了+28.92%，人工接管率降低了-6.08%；在直播互动场景下，智能解决率提高了+18.42%，人工接管率降低了-7.12%。

Conclusion: OlaMind框架在真实世界的应用中表现出持续的有效性，能够显著提高类人性和自然度，同时有效减轻幻觉和关键业务风险。

Abstract: Intelligent customer service (ICS) systems via retrieval-augmented generation
(RAG) have been widely adopted in Web-based domains such as social platforms
and e-commerce, achieving remarkable improvements in automation and efficiency.
However, notable limitations still remain: these systems are prone to
hallucinations and often generate rigid, mechanical responses, which can
introduce business risks and undermine user experience, especially in Web-based
customer service interactions under the RAG scenarios. In this paper, we
introduce OlaMind, a human-like and hallucination-safe customer service
framework for retrieval-augmented dialogue. Specifically, it first leverages a
Learn-to-Think stage to learn the reasoning processes and response strategies
from human experts, and then employs a Learn-to-Respond stage to perform
cold-start supervised fine-tuning (SFT) combined with reinforcement learning
(RL) for basic-to-hard self-refinement. Our method significantly enhances
human-likeness and naturalness while effectively mitigating hallucinations and
critical business risks. We have conducted large-scale online A/B experiments
in an industry-level social customer service setting, and extensive
experimental results show that OlaMind achieves significant cumulative relative
improvements with intelligent resolution rates +28.92%/+18.42% and human
takeover rate -6.08%/-7.12% in community-support/livestream-interaction
scenarios, respectively, which highlights its consistent effectiveness across
diverse real-world applications. The code and data will be publicly available.

</details>


### [232] [SentiMaithili: A Benchmark Dataset for Sentiment and Reason Generation for the Low-Resource Maithili Language](https://arxiv.org/abs/2510.22160)
*Rahul Ranjan,Mahendra Kumar Gurve,Anuj,Nitin,Yamuna Prasad*

Main category: cs.CL

TL;DR: 我们提出了一个包含3221个句子、带有情感极性和自然语言解释的排基里语数据集，以解决低资源语言在自然语言处理方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏本土语言专家以及标注所需的时间和成本，为低资源语言开发基准数据集面临巨大挑战。因此，排基里语在自然语言处理研究中仍然代表性不足，尽管它是一种拥有超过1300万使用者的印度-雅利安语，具有丰富的语言结构和文化意义。此外，尽管情感分析在高资源语言中取得了显著进展，但像排基里语这样的低资源语言的资源仍然稀缺，并且缺乏可解释性机制。

Method: 我们引入了一个包含3221个排基里语句子的新数据集，并标注了情感极性和自然语言解释。这些解释是用排基里语写成的，以促进有文化背景的解读并增强情感模型的可解释性。随后，我们使用传统的机器学习和最先进的Transformer架构进行了广泛的实验，以证明该数据集在可解释情感分析方面的有效性。

Result: 实验证明了该数据集在可解释情感分析方面的有效性。

Conclusion: 这项工作为排基里语的可解释情感计算建立了第一个基准，为多语言自然语言处理和可解释人工智能的广泛发展做出了宝贵的贡献。

Abstract: Developing benchmark datasets for low-resource languages poses significant
challenges, primarily due to the limited availability of native linguistic
experts and the substantial time and cost involved in annotation. Given these
challenges, Maithili is still underrepresented in natural language processing
research. It is an Indo-Aryan language spoken by more than 13 million people in
the Purvanchal region of India, valued for its rich linguistic structure and
cultural significance. While sentiment analysis has achieved remarkable
progress in high-resource languages, resources for low-resource languages, such
as Maithili, remain scarce, often restricted to coarse-grained annotations and
lacking interpretability mechanisms. To address this limitation, we introduce a
novel dataset comprising 3,221 Maithili sentences annotated for sentiment
polarity and accompanied by natural language justifications. Moreover, the
dataset is carefully curated and validated by linguistic experts to ensure both
label reliability and contextual fidelity. Notably, the justifications are
written in Maithili, thereby promoting culturally grounded interpretation and
enhancing the explainability of sentiment models. Furthermore, extensive
experiments using both classical machine learning and state-of-the-art
transformer architectures demonstrate the dataset's effectiveness for
interpretable sentiment analysis. Ultimately, this work establishes the first
benchmark for explainable affective computing in Maithili, thus contributing a
valuable resource to the broader advancement of multilingual NLP and
explainable AI.

</details>


### [233] [DETECT: Determining Ease and Textual Clarity of German Text Simplifications](https://arxiv.org/abs/2510.22212)
*Maria Korobeynikova,Alessia Battisti,Lukas Fischer,Yingqiang Gao*

Main category: cs.CL

TL;DR: 该论文介绍了DETECT，一个首个针对德语自动文本简化（ATS）的专用评估指标，解决了现有通用指标（如SARI、BLEU、BERTScore）在评估简化质量方面的不足。DETECT通过LLM生成合成数据进行训练，能够同时评估简化性、意义保留和流畅性三个维度。论文还构建了最大的德语人工评估数据集来验证该指标，并证明DETECT与人类判断的相关性远高于现有指标。


<details>
  <summary>Details</summary>
Motivation: 现有的德语自动文本简化（ATS）评估依赖通用指标，这些指标未能充分捕捉简化质量的三个关键维度：简洁性、意义保留和流畅性。虽然存在针对英语的专用指标（如LENS），但由于缺乏人工标注语料库，德语领域的研究滞后。

Method: 开发了一种名为DETECT的新型德语ATS评估指标。该指标基于LENS框架，并引入了两个关键创新：1. 使用大型语言模型（LLM）生成合成质量分数，用于创建数据集，无需人工标注。2. 增加了一个基于LLM的精炼步骤，以确保评分标准与简化要求保持一致。此外，论文还构建了迄今为止最大的德语人工评估数据集，用于直接验证DETECT指标。

Result: 实验结果表明，DETECT指标在与人类判断的相关性方面，显著优于广泛使用的ATS指标，尤其在意义保留和流畅性方面表现突出。此外，该研究还突显了LLM在自动评估方面的潜力和局限性，并为通用语言可访问性任务提供了可迁移的指导方针。

Conclusion: DETECT是首个专门为德语ATS设计的全面评估指标，它通过利用LLM生成合成数据，克服了数据标注的限制，并在简洁性、意义保留和流畅性方面提供了比现有通用指标更准确的评估。该研究不仅改进了德语ATS的评估方法，还为利用LLM进行跨语言的评估任务提供了有价值的见解和方法。

Abstract: Current evaluation of German automatic text simplification (ATS) relies on
general-purpose metrics such as SARI, BLEU, and BERTScore, which insufficiently
capture simplification quality in terms of simplicity, meaning preservation,
and fluency. While specialized metrics like LENS have been developed for
English, corresponding efforts for German have lagged behind due to the absence
of human-annotated corpora. To close this gap, we introduce DETECT, the first
German-specific metric that holistically evaluates ATS quality across all three
dimensions of simplicity, meaning preservation, and fluency, and is trained
entirely on synthetic large language model (LLM) responses. Our approach adapts
the LENS framework to German and extends it with (i) a pipeline for generating
synthetic quality scores via LLMs, enabling dataset creation without human
annotation, and (ii) an LLM-based refinement step for aligning grading criteria
with simplification requirements. To the best of our knowledge, we also
construct the largest German human evaluation dataset for text simplification
to validate our metric directly. Experimental results show that DETECT achieves
substantially higher correlations with human judgments than widely used ATS
metrics, with particularly strong gains in meaning preservation and fluency.
Beyond ATS, our findings highlight both the potential and the limitations of
LLMs for automatic evaluation and provide transferable guidelines for general
language accessibility tasks.

</details>


### [234] [Estimating the Error of Large Language Models at Pairwise Text Comparison](https://arxiv.org/abs/2510.22219)
*Tianyi Li*

Main category: cs.CL

TL;DR: 本文提出了一种无需真实标签即可衡量大型语言模型（LLM）在成对文本比较中输出错误概率的方法，并应用于六种不同的LLM。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在成对文本比较中的错误率，特别是其偏好中的错误概率。

Method: 提出了一种不依赖真实标签的方法，该方法支持两种场景：(i) 假设错误率与比较顺序无关，通过对每对文本进行两次比较（每次将其中一个文本置于首位）来估计；(ii) 假设存在二元位置偏见，即不同比较顺序下存在不同的错误率，通过重复比较来估计。采用Copeland计数法构建比较文本的排名，以揭示基于LLM的成对比较的可扩展性问题，并估计LLM的错误率。将该方法应用于ChatGPT、Claude、DeepSeek、Gemini、Grok和Qwen六种LLM，并使用了五种不同类型的文本输入。

Result: 实验结果显示，在所测量的LLM中，Claude在错误率和对提示变化的鲁棒性方面表现最优。所提出的模型在指示LLM在此任务中的错误率方面优于有偏的Bradley-Terry模型和可交换性得分。

Conclusion: 所提出的方法能够有效衡量LLM在成对文本比较中的错误率，并揭示了LLM在该任务中的性能差异。Claude在实验中表现出最佳性能。

Abstract: We measure LLMs' output error at pairwise text comparison, noting the
probability of error in their preferences. Our method does not rely on the
ground truth and supports two scenarios: (i) uniform error rate regardless of
the order of comparison, estimated with two comparisons for each text pair with
either text placed first; (ii) binary positional bias assuming distinct error
rates for the two orders of comparison, estimated with repeated comparisons
between the texts. The Copeland counting constructs a ranking over the compared
texts from pairwise preferences; the ranking reveals the poor scalability of
LLM-based pairwise comparison and helps yield the estimates for LLMs' error
rates. We apply the method to six LLMs (ChatGPT, Claude, DeepSeek, Gemini,
Grok, Qwen) with five types of text input and obtain consistent estimates of
LLMs' error. In general, the measured two positional bias terms are similar,
close to the uniform error. Considering both the error rates and the robustness
to the variation of prompts, Claude obtained the most desirable performance in
this experiment. Our model outperforms the biased Bradley-Terry model and the
commutativity score in indicating LLMs' error at this task.

</details>


### [235] [Evolution of the lexicon: a probabilistic point of view](https://arxiv.org/abs/2510.22220)
*Maurizio Serva*

Main category: cs.CL

TL;DR: Swadesh法确定语言间时间距离的假设不现实，且存在数学上的精度限制。本文分析了这些限制，并提出考虑词语逐渐演变这一随机过程可以提高精度。


<details>
  <summary>Details</summary>
Motivation: Swadesh法在确定语言间时间距离时存在假设不现实和精度限制的问题，需要改进。

Method: 分析Swadesh法的不现实假设和数学上的精度限制，并引入词语逐渐演变这一随机过程来提高精度。

Result: 证明了考虑词语逐渐演变这一随机过程可以显著提高确定语言间时间距离的精度。

Conclusion: Swadesh法存在局限性，考虑词语逐渐演变过程能提升语言时间距离测算的精度。

Abstract: The Swadesh approach for determining the temporal separation between two
languages relies on the stochastic process of words replacement (when a
complete new word emerges to represent a given concept). It is well known that
the basic assumptions of the Swadesh approach are often unrealistic due to
various contamination phenomena and misjudgments (horizontal transfers,
variations over time and space of the replacement rate, incorrect assessments
of cognacy relationships, presence of synonyms, and so on). All of this means
that the results cannot be completely correct.
  More importantly, even in the unrealistic case that all basic assumptions are
satisfied, simple mathematics places limits on the accuracy of estimating the
temporal separation between two languages. These limits, which are purely
probabilistic in nature and which are often neglected in lexicostatistical
studies, are analyzed in detail in this article.
  Furthermore, in this work we highlight that the evolution of a language's
lexicon is also driven by another stochastic process: gradual lexical
modification of words. We show that this process equally also represents a
major contribution to the reshaping of the vocabulary of languages over the
centuries and we also show, from a purely probabilistic perspective, that
taking into account this second random process significantly increases the
precision in determining the temporal separation between two languages.

</details>


### [236] [You Don't Need Prompt Engineering Anymore: The Prompting Inversion](https://arxiv.org/abs/2510.22251)
*Imran Khan*

Main category: cs.CL

TL;DR: Sculpting是一种基于规则的提示工程方法，旨在通过减少语义模糊和常识性错误来改进CoT提示，但在GPT-5上表现不如标准CoT。


<details>
  <summary>Details</summary>
Motivation: Prompt工程，特别是CoT提示，能显著提升LLM的推理能力。但标准CoT可能存在语义模糊和常识错误。

Method: 评估了零样本、标准CoT和Sculpting三种提示策略在三代OpenAI模型（gpt-4o-mini, gpt-4o, gpt-5）上的表现，使用了GSM8K数学推理基准。

Result: Sculpting在GPT-4o上优于标准CoT（97% vs 93%），但在GPT-5上表现不佳（94.00% vs 96.36%）。这种现象归因于约束条件从“护栏”转变为“镣铐”，阻止了中等模型中的常识错误，却导致更高级模型中的过度字面化。

Conclusion: 最优的提示策略需要与模型能力协同进化，更高级的模型可能需要更简单的提示。

Abstract: Prompt engineering, particularly Chain-of-Thought (CoT) prompting,
significantly enhances LLM reasoning capabilities. We introduce "Sculpting," a
constrained, rule-based prompting method designed to improve upon standard CoT
by reducing errors from semantic ambiguity and flawed common sense.
  We evaluate three prompting strategies (Zero Shot, standard CoT, and
Sculpting) across three OpenAI model generations (gpt-4o-mini, gpt-4o, gpt-5)
using the GSM8K mathematical reasoning benchmark (1,317 problems).
  Our findings reveal a "Prompting Inversion": Sculpting provides advantages on
gpt-4o (97% vs. 93% for standard CoT), but becomes detrimental on gpt-5 (94.00%
vs. 96.36% for CoT on full benchmark). We trace this to a
"Guardrail-to-Handcuff" transition where constraints preventing common-sense
errors in mid-tier models induce hyper-literalism in advanced models. Our
detailed error analysis demonstrates that optimal prompting strategies must
co-evolve with model capabilities, suggesting simpler prompts for more capable
models.

</details>


### [237] [SteerX: Disentangled Steering for LLM Personalization](https://arxiv.org/abs/2510.22256)
*Xiaoyan Zhao,Ming Yan,Yilun Qiu,Haoting Ni,Yang Zhang,Fuli Feng,Hong Cheng,Tat-Seng Chua*

Main category: cs.CL

TL;DR: SteerX是一种解耦的激活引导方法，用于改进大型语言模型的个性化，通过区分用户偏好驱动的组件和非偏好驱动的组件，并利用因果推理来识别和利用偏好驱动的代币，从而产生更准确的引导向量。


<details>
  <summary>Details</summary>
Motivation: 现有激活引导方法依赖所有历史数据来计算引导向量，忽略了并非所有内容都反映真实用户偏好，从而削弱了信号。因此，需要一种能够区分偏好驱动和非偏好驱动组件的方法来改进个性化。

Method: SteerX利用因果推理理论来估计代币级别的因果效应，以识别偏好驱动的代币。然后，它将这些离散信号转化为连贯的描述，并利用它们来引导个性化的大型语言模型生成。

Result: SteerX在两个代表性的引导骨干方法和真实数据集上进行实验，结果一致地提高了引导向量的质量，证明了其在LLM个性化方面的有效性。

Conclusion: SteerX通过区分和利用偏好驱动的信息，为大型语言模型提供了更有效的个性化解决方案。

Abstract: Large language models (LLMs) have shown remarkable success in recent years,
enabling a wide range of applications, including intelligent assistants that
support users' daily life and work. A critical factor in building such
assistants is personalizing LLMs, as user preferences and needs vary widely.
Activation steering, which directly leverages directions representing user
preference in the LLM activation space to adjust its behavior, offers a
cost-effective way to align the model's outputs with individual users. However,
existing methods rely on all historical data to compute the steering vector,
ignoring that not all content reflects true user preferences, which undermines
the personalization signal. To address this, we propose SteerX, a disentangled
steering method that isolates preference-driven components from
preference-agnostic components. Grounded in causal inference theory, SteerX
estimates token-level causal effects to identify preference-driven tokens,
transforms these discrete signals into a coherent description, and then
leverages them to steer personalized LLM generation. By focusing on the truly
preference-driven information, SteerX produces more accurate activation
steering vectors and enhances personalization. Experiments on two
representative steering backbone methods across real-world datasets demonstrate
that SteerX consistently enhances steering vector quality, offering a practical
solution for more effective LLM personalization.

</details>


### [238] [PatenTEB: A Comprehensive Benchmark and Model Family for Patent Text Embedding](https://arxiv.org/abs/2510.22264)
*Iliass Ayaou,Denis Cavallucci*

Main category: cs.CL

TL;DR: PatenTEB是一个包含15个任务和206万个示例的专利文本嵌入基准，旨在解决现有基准未能充分解决专利特定挑战的问题。它采用了领域分层拆分、领域特定硬负例挖掘以及通用嵌入基准中缺少的非对称片段到文档匹配场景的系统性覆盖。还开发了patembed模型家族，并在外部验证中取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 现有基准未能充分解决专利特定挑战，影响了专利文本嵌入在先艺术检索、技术布局和专利分析等方面的应用。

Method: 开发了一个名为PatenTEB的全面基准，包含15个任务（检索、分类、释义、聚类），拥有2.06百万个示例。该基准采用了领域分层拆分、领域特定硬负例挖掘和系统性覆盖非对称片段到文档匹配场景。同时，通过多任务训练开发了patembed模型家族（67M到344M参数，上下文长度高达4096个token）。

Result: PatenTEB基准和patembed模型在外部验证中表现出色。patembed-base在MTEB BigPatentClustering.v2上达到了最先进的0.494 V-measure。patembed-large在DAPFAM上取得了0.377 NDCG@100。消融实验表明，多任务训练提高了外部泛化能力，领域预训练初始化在所有任务家族中都提供了持续的优势。

Conclusion: PatenTEB基准和patembed模型家族能够有效应对专利文本嵌入的挑战，并在多项任务中取得最先进的性能，证明了多任务训练和领域预训练的重要性。

Abstract: Patent text embeddings enable prior art search, technology landscaping, and
patent analysis, yet existing benchmarks inadequately capture patent-specific
challenges. We introduce PatenTEB, a comprehensive benchmark comprising 15
tasks across retrieval, classification, paraphrase, and clustering, with 2.06
million examples. PatenTEB employs domain-stratified splits, domain specific
hard negative mining, and systematic coverage of asymmetric
fragment-to-document matching scenarios absent from general embedding
benchmarks. We develop the patembed model family through multi-task training,
spanning 67M to 344M parameters with context lengths up to 4096 tokens.
External validation shows strong generalization: patembed-base achieves
state-of-the-art on MTEB BigPatentClustering.v2 (0.494 V-measure vs. 0.445
previous best), while patembed-large achieves 0.377 NDCG@100 on DAPFAM.
Systematic ablations reveal that multi-task training improves external
generalization despite minor benchmark costs, and that domain-pretrained
initialization provides consistent advantages across task families. All
resources will be made available at https://github.com/iliass-y/patenteb.
Keywords: patent retrieval, sentence embeddings, multi-task learning,
asymmetric retrieval, benchmark evaluation, contrastive learning.

</details>


### [239] [From Slides to Chatbots: Enhancing Large Language Models with University Course Materials](https://arxiv.org/abs/2510.22272)
*Tu Anh Dinh,Philipp Nicolas Schumacher,Jan Niehues*

Main category: cs.CL

TL;DR: LLM在大学计算机科学课程中的学习支持方面仍存在挑战，研究表明，通过整合课程材料（如幻灯片和讲稿）可以提高LLM的性能。研究比较了检索增强生成（RAG）和持续预训练（CPT）两种策略，并探索了多模态RAG（将幻灯片作为图像输入）的应用。实验结果显示，对于规模有限的大学课程材料，RAG比CPT更有效，而多模态RAG在性能上优于纯文本检索。


<details>
  <summary>Details</summary>
Motivation: LLM在大学计算机科学课程中的应用仍面临准确性挑战，本研究旨在探讨如何通过整合大学课程材料来提升LLM在该场景下的表现。

Method: 本研究比较了两种策略：检索增强生成（RAG）和持续预训练（CPT），以利用课程特定知识扩展LLM。对于包含图像和公式的教学幻灯片，研究还探索了一种多模态RAG方法，将检索到的内容以图像形式提供给生成器。

Result: 实验表明，对于规模相对较小的大学课程材料，RAG比CPT更有效且高效。此外，在多模态设置中将幻灯片作为图像整合，相比纯文本检索能显著提升性能。

Conclusion: 本研究提出了实用的策略，用于开发能更好支持教学和学习的AI助手，并期望这些方法能在其他教育场景中得到启发。

Abstract: Large Language Models (LLMs) have advanced rapidly in recent years. One
application of LLMs is to support student learning in educational settings.
However, prior work has shown that LLMs still struggle to answer questions
accurately within university-level computer science courses. In this work, we
investigate how incorporating university course materials can enhance LLM
performance in this setting. A key challenge lies in leveraging diverse course
materials such as lecture slides and transcripts, which differ substantially
from typical textual corpora: slides also contain visual elements like images
and formulas, while transcripts contain spoken, less structured language. We
compare two strategies, Retrieval-Augmented Generation (RAG) and Continual
Pre-Training (CPT), to extend LLMs with course-specific knowledge. For lecture
slides, we further explore a multi-modal RAG approach, where we present the
retrieved content to the generator in image form. Our experiments reveal that,
given the relatively small size of university course materials, RAG is more
effective and efficient than CPT. Moreover, incorporating slides as images in
the multi-modal setting significantly improves performance over text-only
retrieval. These findings highlight practical strategies for developing AI
assistants that better support learning and teaching, and we hope they inspire
similar efforts in other educational contexts.

</details>


### [240] [Supervised Fine-Tuning or In-Context Learning? Evaluating LLMs for Clinical NER](https://arxiv.org/abs/2510.22285)
*Andrei Baroian*

Main category: cs.CL

TL;DR: BERT和GPT-4o在CADEC临床命名实体识别任务上进行比较，SFT的GPT-4o表现最佳，但成本较高。


<details>
  <summary>Details</summary>
Motivation: 在CADEC语料库上研究临床命名实体识别（NER），并比较不同方法。

Method: 比较了BERT类编码器、GPT-4o的少样本学习（ICL）和监督微调（SFT）。

Result: RoBERTa-large和BioClinicalBERT的改进有限。简单的ICL优于复杂的提示，SFT表现最好（F1≈87.1%），但成本更高。LLM在简化任务上准确率更高。

Conclusion: SFT是CADEC临床NER的最优方法，但需考虑成本。LLM在处理简化任务时表现更佳。

Abstract: We study clinical Named Entity Recognition (NER) on the CADEC corpus and
compare three families of approaches: (i) BERT-style encoders (BERT Base,
BioClinicalBERT, RoBERTa-large), (ii) GPT-4o used with few-shot in-context
learning (ICL) under simple vs.\ complex prompts, and (iii) GPT-4o with
supervised fine-tuning (SFT). All models are evaluated on standard NER metrics
over CADEC's five entity types (ADR, Drug, Disease, Symptom, Finding).
RoBERTa-large and BioClinicalBERT offer limited improvements over BERT Base,
showing the limit of these family of models. Among LLM settings, simple ICL
outperforms a longer, instruction-heavy prompt, and SFT achieves the strongest
overall performance (F1 $\approx$ 87.1%), albeit with higher cost. We find that
the LLM achieve higher accuracy on simplified tasks, restricting classification
to two labels.

</details>


### [241] [Memory-based Language Models: An Efficient, Explainable, and Eco-friendly Approach to Large Language Modeling](https://arxiv.org/abs/2510.22317)
*Antal van den Bosch,Ainhoa Risco Patón,Teun Buijse,Peter Berck,Maarten van Gompel*

Main category: cs.CL

TL;DR: 提出了一种名为OLIFANT的内存式语言建模方法，作为深度神经网络语言模型的节能环保替代方案。


<details>
  <summary>Details</summary>
Motivation: 内存式语言建模提供了一种高效、环保的深度神经网络语言模型替代方案，具有对数线性可扩展的下一个词预测性能和强大的记忆能力。

Method: 通过实现k近邻分类的快速近似来构建内存式语言模型，该模型完全依赖CPU，具有低词延迟，并具有简单的内部工作原理和完全的透明度。

Result: OLIFANT在下一个词预测准确性、估计排放和速度方面与GPT-2和GPT-Neo相当，并进行了更深入的模型分析。

Conclusion: 内存式语言建模作为一种高效、环保的替代方案，在计算资源和性能上都具有竞争力。

Abstract: We present memory-based language modeling as an efficient, eco-friendly
alternative to deep neural network-based language modeling. It offers
log-linearly scalable next-token prediction performance and strong memorization
capabilities. Implementing fast approximations of k-nearest neighbor
classification, memory-based language modeling leaves a relatively small
ecological footprint both in training and in inference mode, as it relies fully
on CPUs and attains low token latencies. Its internal workings are simple and
fully transparent. We compare our implementation of memory-based language
modeling, OLIFANT, with GPT-2 and GPT-Neo on next-token prediction accuracy,
estimated emissions and speeds, and offer some deeper analyses of the model.

</details>


### [242] [Multilingual Target-Stance Extraction](https://arxiv.org/abs/2510.22334)
*Ethan Mines,Bonnie Dorr*

Main category: cs.CL

TL;DR: 本研究首次提出了多语言目标立场抽取（TSE）基准，涵盖了多种语言，并扩展了现有的TSE方法以适应多语言环境，同时强调了目标预测的挑战性以及TSE分数对目标表述的敏感性。


<details>
  <summary>Details</summary>
Motivation: 现有TSE研究仅限于英语，缺乏多语言处理能力，因此需要一个多语言TSE基准来推动该领域的研究。

Method: 将原始TSE方法扩展到多语言环境，无需为每种语言单独建立模型，并分析了目标预测和目标表述对TSE分数的影响。

Result: 在包含加泰罗尼亚语、爱沙尼亚语、法语、意大利语、普通话和西班牙语的语料库上，TSE模型的F1分数仅为12.78，表明多语言TSE比单一语言更具挑战性，其中目标预测是主要的瓶颈。

Conclusion: 本研究提出的多语言TSE基准和方法为多语言TSE的资源、算法和评估标准奠定了基础，并指出了目标预测和目标表述敏感性是未来研究的关键方向。

Abstract: Social media enables data-driven analysis of public opinion on contested
issues. Target-Stance Extraction (TSE) is the task of identifying the target
discussed in a document and the document's stance towards that target. Many
works classify stance towards a given target in a multilingual setting, but all
prior work in TSE is English-only. This work introduces the first multilingual
TSE benchmark, spanning Catalan, Estonian, French, Italian, Mandarin, and
Spanish corpora. It manages to extend the original TSE pipeline to a
multilingual setting without requiring separate models for each language. Our
model pipeline achieves a modest F1 score of 12.78, underscoring the increased
difficulty of the multilingual task relative to English-only setups and
highlighting target prediction as the primary bottleneck. We are also the first
to demonstrate the sensitivity of TSE's F1 score to different target
verbalizations. Together these serve as a much-needed baseline for resources,
algorithms, and evaluation criteria in multilingual TSE.

</details>


### [243] [FAIR-RAG: Faithful Adaptive Iterative Refinement for Retrieval-Augmented Generation](https://arxiv.org/abs/2510.22344)
*Mohammad Aghajani Asl,Majid Asgari-Bidhendi,Behrooz Minaei-Bidgoli*

Main category: cs.CL

TL;DR: FAIR-RAG是一个新颖的代理框架，通过迭代细化周期和结构化证据评估（SEA）模块，改进了检索增强生成（RAG）系统，以处理复杂的多跳查询。它通过识别和填补证据缺口，显著优于现有方法，并在HotpotQA上达到了新的最先进水平。


<details>
  <summary>Details</summary>
Motivation: 现有RAG框架在处理需要综合来自不同来源信息的复杂多跳查询时存在不足，并且缺乏识别和填补证据缺口的稳健机制，可能导致噪声传播或信息收集不全面。

Method: FAIR-RAG将标准RAG流程转变为一个动态的、由证据驱动的推理过程。其核心是一个由结构化证据评估（SEA）模块管理的迭代细化周期。SEA将初始查询分解为所需发现的清单，并审核聚合证据以识别已确认的事实和明确的信息缺口。然后，这些缺口指导一个自适应查询改进代理生成新的、有针对性的子查询以检索缺失信息。此过程一直重复，直到证据被验证为足够。

Result: 在HotpotQA、2WikiMultiHopQA和MusiQue等具有挑战性的多跳问答基准测试中，FAIR-RAG显著优于强大的基线。在HotpotQA上，FAIR-RAG达到了0.453的F1分数，比最强的迭代基线高出8.3个百分点，在这些基准测试中为该类方法创下了新的最先进水平。

Conclusion: 一个结构化的、由证据驱动的、具有明确缺口分析的细化过程对于在处理复杂、知识密集型任务的高级RAG系统中实现可靠和准确的推理至关重要。

Abstract: While Retrieval-Augmented Generation (RAG) mitigates hallucination and
knowledge staleness in Large Language Models (LLMs), existing frameworks often
falter on complex, multi-hop queries that require synthesizing information from
disparate sources. Current advanced RAG methods, employing iterative or
adaptive strategies, lack a robust mechanism to systematically identify and
fill evidence gaps, often propagating noise or failing to gather a
comprehensive context. We introduce FAIR-RAG, a novel agentic framework that
transforms the standard RAG pipeline into a dynamic, evidence-driven reasoning
process. At its core is an Iterative Refinement Cycle governed by a module we
term Structured Evidence Assessment (SEA). The SEA acts as an analytical gating
mechanism: it deconstructs the initial query into a checklist of required
findings and audits the aggregated evidence to identify confirmed facts and,
critically, explicit informational gaps. These gaps provide a precise signal to
an Adaptive Query Refinement agent, which generates new, targeted sub-queries
to retrieve missing information. This cycle repeats until the evidence is
verified as sufficient, ensuring a comprehensive context for a final, strictly
faithful generation. We conducted experiments on challenging multi-hop QA
benchmarks, including HotpotQA, 2WikiMultiHopQA, and MusiQue. In a unified
experimental setup, FAIR-RAG significantly outperforms strong baselines. On
HotpotQA, it achieves an F1-score of 0.453 -- an absolute improvement of 8.3
points over the strongest iterative baseline -- establishing a new
state-of-the-art for this class of methods on these benchmarks. Our work
demonstrates that a structured, evidence-driven refinement process with
explicit gap analysis is crucial for unlocking reliable and accurate reasoning
in advanced RAG systems for complex, knowledge-intensive tasks.

</details>


### [244] [Irony Detection in Urdu Text: A Comparative Study Using Machine Learning Models and Large Language Models](https://arxiv.org/abs/2510.22356)
*Fiaz Ahmad,Nisar Hussain,Amna Qasim,Momina Hafeez,Muhammad Usman Grigori Sidorov,Alexander Gelbukh*

Main category: cs.CL

TL;DR: 本研究旨在检测乌尔都语中的反讽，通过翻译英语反讽语料库至乌尔都语，并评估了十种最新的机器学习算法和先进的 Transformer 模型（包括 BERT、RoBERTa、LLaMA 2、LLaMA 3 和 Mistral）。结果显示，梯度提升在机器学习模型中表现最佳（F1 分数 89.18%），而 LLaMA 3 (8B) 在 Transformer 模型中表现最佳（F1 分数 94.61%），证明了结合音译技术和现代 NLP 模型可以有效地检测乌尔都语中的反讽。


<details>
  <summary>Details</summary>
Motivation: 检测乌尔都语中的反讽，特别是在处理与英语在句法和文化背景上存在差异的语言时。

Method: 将英语反讽语料库翻译成乌尔都语。使用 GloVe 和 Word2Vec 词嵌入评估了十种最新的机器学习算法，并与经典方法进行了比较。此外，还对 BERT、RoBERTa、LLaMA 2 (7B)、LLaMA 3 (8B) 和 Mistral 等先进的 Transformer 模型进行了微调，以评估大型模型在反讽检测中的有效性。

Result: 在机器学习模型中，梯度提升取得了最佳性能，F1 分数为 89.18%。在 Transformer 模型中，LLaMA 3 (8B) 取得了最高的性能，F1 分数为 94.61%。

Conclusion: 结合音译技术和现代 NLP 模型能够有效地检测乌尔都语中的反讽，而乌尔都语在历史上一直是资源匮乏的语言。

Abstract: Ironic identification is a challenging task in Natural Language Processing,
particularly when dealing with languages that differ in syntax and cultural
context. In this work, we aim to detect irony in Urdu by translating an English
Ironic Corpus into the Urdu language. We evaluate ten state-of-the-art machine
learning algorithms using GloVe and Word2Vec embeddings, and compare their
performance with classical methods. Additionally, we fine-tune advanced
transformer-based models, including BERT, RoBERTa, LLaMA 2 (7B), LLaMA 3 (8B),
and Mistral, to assess the effectiveness of large-scale models in irony
detection. Among machine learning models, Gradient Boosting achieved the best
performance with an F1-score of 89.18%. Among transformer-based models, LLaMA 3
(8B) achieved the highest performance with an F1-score of 94.61%. These results
demonstrate that combining transliteration techniques with modern NLP models
enables robust irony detection in Urdu, a historically low-resource language.

</details>


### [245] [GigaEmbeddings: Efficient Russian Language Embedding Model](https://arxiv.org/abs/2510.22369)
*Egor Kolodin,Daria Khomich,Nikita Savushkin,Anastasia Ianina,Fyodor Minkin*

Main category: cs.CL

TL;DR: GigaEmbeddings是一个用于训练高性能俄语文本嵌入的新框架，通过GigaChat-3B模型的层级指令调优实现。该框架包括对比预训练、难负例微调和多任务泛化三个阶段，并采用了双向注意力、潜在注意力池化和层剪枝等技术。在ruMTEB基准测试中，GigaEmbeddings取得了最先进的69.1平均分。


<details>
  <summary>Details</summary>
Motivation: 现有的俄语文本嵌入方法存在局限性，需要一个能统一不同目标并利用合成数据生成来提升性能的框架。

Method: 1. **对比预训练**: 在网络规模语料库上进行。 2. **难负例微调**: 使用难负例进行微调。 3. **多任务泛化**: 涵盖检索、分类和聚类任务。 4. **架构创新**: 包括双向注意力、潜在注意力池化和25%的Transformer层剪枝。

Result: GigaEmbeddings在ruMTEB基准测试（涵盖23个多语言任务）上取得了69.1的平均分，优于参数量更大的基线模型。

Conclusion: GigaEmbeddings在俄语文本嵌入方面取得了最先进的成果，通过创新的训练流程和模型架构提高了性能和效率。

Abstract: We introduce GigaEmbeddings, a novel framework for training high-performance
Russian-focused text embeddings through hierarchical instruction tuning of the
decoder-only LLM designed specifically for Russian language (GigaChat-3B). Our
three-stage pipeline, comprising large-scale contrastive pre-training in
web-scale corpora, fine-tuning with hard negatives, and multitask
generalization across retrieval, classification, and clustering tasks,
addresses key limitations of existing methods by unifying diverse objectives
and leveraging synthetic data generation. Architectural innovations include
bidirectional attention for contextual modeling, latent attention pooling for
robust sequence aggregation, and strategic pruning of 25% of transformer layers
to enhance efficiency without compromising performance. Evaluated on the ruMTEB
benchmark spanning 23 multilingual tasks, GigaEmbeddings achieves
state-of-the-art results (69.1 avg. score), outperforming strong baselines with
a larger number of parameters.

</details>


### [246] [VisJudge-Bench: Aesthetics and Quality Assessment of Visualizations](https://arxiv.org/abs/2510.22373)
*Yupeng Xie,Zhiyang Zhang,Yifan Wu,Sirong Lu,Jiayi Zhang,Zhaoyang Yu,Jinlin Wang,Sirui Hong,Bang Liu,Chenglin Wu,Yuyu Luo*

Main category: cs.CL

TL;DR: 该研究提出了VisJudge-Bench，一个用于评估多模态大语言模型（MLLM）在可视化质量评估能力的基准测试。研究发现现有MLLMs（如GPT-5）在评估可视化方面与人类专家存在显著差距。为解决此问题，研究提出了VisJudge模型，该模型在可视化质量评估方面表现优于GPT-5，并显著缩小了与人类专家的差距。


<details>
  <summary>Details</summary>
Motivation: 评估多模态大语言模型（MLLM）在可视化质量评估方面的能力，并解决现有评估方法和模型在这一领域存在的不足。

Method: 构建了一个包含3090个专家注释样本的可视化评估基准测试（VisJudge-Bench），涵盖了多种图表类型和复杂性。并提出了一个专门用于可视化质量评估的模型（VisJudge）。

Result: 现有先进的MLLMs（如GPT-5）在可视化评估方面与人类专家的平均绝对误差（MAE）为0.551，与人类评分的相关性仅为0.429。提出的VisJudge模型将MAE降低到0.442，与人类专家的相关性提高到0.681。

Conclusion: VisJudge-Bench 是一个衡量MLLM在可视化评估能力的首个综合性基准。现有MLLMs在可视化评估方面仍有改进空间，但提出的VisJudge模型能够显著提高评估的准确性和与人类专家的_致性。

Abstract: Visualization, a domain-specific yet widely used form of imagery, is an
effective way to turn complex datasets into intuitive insights, and its value
depends on whether data are faithfully represented, clearly communicated, and
aesthetically designed. However, evaluating visualization quality is
challenging: unlike natural images, it requires simultaneous judgment across
data encoding accuracy, information expressiveness, and visual aesthetics.
Although multimodal large language models (MLLMs) have shown promising
performance in aesthetic assessment of natural images, no systematic benchmark
exists for measuring their capabilities in evaluating visualizations. To
address this, we propose VisJudge-Bench, the first comprehensive benchmark for
evaluating MLLMs' performance in assessing visualization aesthetics and
quality. It contains 3,090 expert-annotated samples from real-world scenarios,
covering single visualizations, multiple visualizations, and dashboards across
32 chart types. Systematic testing on this benchmark reveals that even the most
advanced MLLMs (such as GPT-5) still exhibit significant gaps compared to human
experts in judgment, with a Mean Absolute Error (MAE) of 0.551 and a
correlation with human ratings of only 0.429. To address this issue, we propose
VisJudge, a model specifically designed for visualization aesthetics and
quality assessment. Experimental results demonstrate that VisJudge
significantly narrows the gap with human judgment, reducing the MAE to 0.442 (a
19.8% reduction) and increasing the consistency with human experts to 0.681 (a
58.7% improvement) compared to GPT-5. The benchmark is available at
https://github.com/HKUSTDial/VisJudgeBench.

</details>


### [247] [Confabulations from ACL Publications (CAP): A Dataset for Scientific Hallucination Detection](https://arxiv.org/abs/2510.22395)
*Federica Gamba,Aman Sinha,Timothee Mickus,Raul Vazquez,Patanjali Bhamidipati,Claudio Savelli,Ahana Chattopadhyay,Laura A. Zanella,Yash Kankanampati,Binesh Arakkal Remesh,Aryan Ashok Chandramania,Rohit Agarwal,Chuyuan Li,Ioana Buhnila,Radhika Mamidi*

Main category: cs.CL

TL;DR: 该研究提出了CAP数据集，一个包含900个科学问题和7000多个语言模型生成答案的多语言数据集，用于研究科学文本生成中的幻觉现象。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型语言模型（LLMs）在科学领域生成文本时出现的幻觉问题，该研究创建了一个专门的数据集，因为科学领域的术语、统计推理和上下文依赖性会加剧幻觉的失真。

Method: 研究人员构建了一个跨语言的数据集（CAP），涵盖了五种高资源语言和四种低资源语言，收集了900个科学问题和16个公开模型的7000多个答案。每个答案都标有是否存在科学幻觉（事实错误）和流畅性标签。

Result: CAP数据集包含900个科学问题和7000多个LLM生成的答案，并附有标记，用于评估LLM在科学文本生成中的事实准确性和语言流畅性。

Conclusion: CAP数据集的发布旨在促进对幻觉检测、多语言LLM评估以及开发更可靠的科学NLP系统的研究。

Abstract: We introduce the CAP (Confabulations from ACL Publications) dataset, a
multilingual resource for studying hallucinations in large language models
(LLMs) within scientific text generation. CAP focuses on the scientific domain,
where hallucinations can distort factual knowledge, as they frequently do. In
this domain, however, the presence of specialized terminology, statistical
reasoning, and context-dependent interpretations further exacerbates these
distortions, particularly given LLMs' lack of true comprehension, limited
contextual understanding, and bias toward surface-level generalization. CAP
operates in a cross-lingual setting covering five high-resource languages
(English, French, Hindi, Italian, and Spanish) and four low-resource languages
(Bengali, Gujarati, Malayalam, and Telugu). The dataset comprises 900 curated
scientific questions and over 7000 LLM-generated answers from 16 publicly
available models, provided as question-answer pairs along with token sequences
and corresponding logits. Each instance is annotated with a binary label
indicating the presence of a scientific hallucination, denoted as a factuality
error, and a fluency label, capturing issues in the linguistic quality or
naturalness of the text. CAP is publicly released to facilitate advanced
research on hallucination detection, multilingual evaluation of LLMs, and the
development of more reliable scientific NLP systems.

</details>


### [248] [CHOIR: Collaborative Harmonization fOr Inference Robustness](https://arxiv.org/abs/2510.22475)
*Xiangjue Dong,Cong Wang,Maria Teleki,Millennium Bismay,James Caverlee*

Main category: cs.CL

TL;DR: Persona驱动的大语言模型（LLMs）在采用不同角色时，即使是简单的代词改变，也会导致推理路径和答案的差异。本文提出CHOIR框架，通过协调多个反事实角色的推理信号，将它们统一起来，以提高推理的鲁棒性。实验表明，CHOIR在无需额外训练的情况下，能显著提升模型在各种基准测试上的表现，尤其是在个别群体上可达26.4%的提升。


<details>
  <summary>Details</summary>
Motivation: 探索将Persona的细微差异（如代词改变）视为提高大语言模型（LLMs）推理鲁棒性的资源，而非需要消除的偏差。

Method: 提出CHOIR（Collaborative Harmonization fOr Inference Robustness）框架，该框架在测试时协调多个Persona条件下的推理信号，通过协作解码过程统一预测，平衡推理路径中的一致性与分歧性。

Result: 在多个推理基准测试中，CHOIR在不同的人口统计特征、模型架构、模型规模和任务上持续提升了性能，无需额外训练。其中，对个别群体性能提升最高可达26.4%，五个人口统计群体平均提升19.2%。即使在基础Persona表现不佳的情况下，CHOIR依然有效。

Conclusion: CHOIR通过将Persona变化视为一种有益的信号，为实现更可靠的LLM推理提供了一种可扩展且通用的方法。

Abstract: Persona-assigned Large Language Models (LLMs) can adopt diverse roles,
enabling personalized and context-aware reasoning. However, even minor
demographic perturbations in personas, such as simple pronoun changes, can
alter reasoning trajectories, leading to divergent sets of correct answers.
Instead of treating these variations as biases to be mitigated, we explore
their potential as a constructive resource to improve reasoning robustness. We
propose CHOIR (Collaborative Harmonization fOr Inference Robustness), a
test-time framework that harmonizes multiple persona-conditioned reasoning
signals into a unified prediction. CHOIR orchestrates a collaborative decoding
process among counterfactual personas, dynamically balancing agreement and
divergence in their reasoning paths. Experiments on various reasoning
benchmarks demonstrate that CHOIR consistently enhances performance across
demographics, model architectures, scales, and tasks - without additional
training. Improvements reach up to 26.4% for individual demographic groups and
19.2% on average across five demographics. It remains effective even when base
personas are suboptimal. By reframing persona variation as a constructive
signal, CHOIR provides a scalable and generalizable approach to more reliable
LLM reasoning.

</details>


### [249] [The Tonogenesis Continuum in Tibetan: A Computational Investigation](https://arxiv.org/abs/2510.22485)
*Siyu Liang,Zhaxi Zerong*

Main category: cs.CL

TL;DR: 通过分析藏语系中不同方言对降噪的敏感度，研究发现声调演变存在一个连续统：无声调的安多方言对音高去除的容忍度最高，而完全有声调的卫藏方言则出现严重退化，介于两者之间的康方言则表现出可衡量的中间状态。


<details>
  <summary>Details</summary>
Motivation: 研究音高在语音变化过程中所扮演的功能性角色，特别是在声调演变（Tonogenesis）这一历史过程中，并引入一种新的计算方法来量化这一角色。

Method: 提出一种计算方法，通过测量音高变化对自动语音识别（ASR）性能的影响，来量化音高在声调演变不同阶段的功能性作用，并选取了一系列关系密切的藏语方言进行分析。

Result: 研究发现，安多方言（无声调）对音高去除的容忍度最高，卫藏方言（全声调）则出现严重性能下降，康方言（介于两者之间）的性能下降程度介于两者之间。这表明存在一个声调演变的连续统。

Conclusion: 计算方法能够捕捉到语音变化的细微阶段，并且可能比仅基于最小对的传统方法更准确地估计过渡系统中的音高依赖性。ASR模型能够隐式学习语言从以辅音为基础到以声调为基础的转换过程中音高的功能负荷变化。

Abstract: Tonogenesis-the historical process by which segmental contrasts evolve into
lexical tone-has traditionally been studied through comparative reconstruction
and acoustic phonetics. We introduce a computational approach that quantifies
the functional role of pitch at different stages of this sound change by
measuring how pitch manipulation affects automatic speech recognition (ASR)
performance. Through analysis on the sensitivity to pitch-flattening from a set
of closely related Tibetan languages, we find evidence of a tonogenesis
continuum: atonal Amdo dialects tolerate pitch removal the most, while fully
tonal U-Tsang varieties show severe degradation, and intermediate Kham dialects
fall measurably between these extremes. These gradient effects demonstrate how
ASR models implicitly learn the shifting functional load of pitch as languages
transition from consonant-based to tone-based lexical contrasts. Our findings
show that computational methods can capture fine-grained stages of sound change
and suggest that traditional functional load metrics, based solely on minimal
pairs, may overestimate pitch dependence in transitional systems where
segmental and suprasegmental cues remain phonetically intertwined.

</details>


### [250] [Frustratingly Easy Task-aware Pruning for Large Language Models](https://arxiv.org/abs/2510.22489)
*Yuanhe Tian,Junjie Liu,Xican Yang,Haishan Ye,Yan Song*

Main category: cs.CL

TL;DR: 通过结合通用和特定任务的校准数据来计算参数重要性得分，将参数划分为共享和独占组，然后融合得分以指导剪枝过程，从而在压缩的同时保留LLM的专业能力。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM剪枝方法主要关注生成流畅句子的能力，而忽略了在特定领域和任务上的性能。

Method: 提出了一种简单有效的LLM剪枝方法，将特定任务的特征分布纳入现有剪枝算法的权重计算中，通过结合通用和特定任务的校准数据来计算权重得分，并将参数分为共享和独占两组，最后融合它们的得分进行剪枝。

Result: 在广泛使用的基准测试中，该方法在相同的剪枝率和不同的设置下，一致优于基线方法。

Conclusion: 所提出的剪枝框架能够有效保留LLM的专业能力，同时减小其参数空间。

Abstract: Pruning provides a practical solution to reduce the resources required to run
large language models (LLMs) to benefit from their effective capabilities as
well as control their cost for training and inference. Research on LLM pruning
often ranks the importance of LLM parameters using their magnitudes and
calibration-data activations and removes (or masks) the less important ones,
accordingly reducing LLMs' size. However, these approaches primarily focus on
preserving the LLM's ability to generate fluent sentences, while neglecting
performance on specific domains and tasks. In this paper, we propose a simple
yet effective pruning approach for LLMs that preserves task-specific
capabilities while shrinking their parameter space. We first analyze how
conventional pruning minimizes loss perturbation under general-domain
calibration and extend this formulation by incorporating task-specific feature
distributions into the importance computation of existing pruning algorithms.
Thus, our framework computes separate importance scores using both general and
task-specific calibration data, partitions parameters into shared and exclusive
groups based on activation-norm differences, and then fuses their scores to
guide the pruning process. This design enables our method to integrate
seamlessly with various foundation pruning techniques and preserve the LLM's
specialized abilities under compression. Experiments on widely used benchmarks
demonstrate that our approach is effective and consistently outperforms the
baselines with identical pruning ratios and different settings.

</details>


### [251] [The Limits of Data Scaling: Sub-token Utilization and Acoustic Saturation in Multilingual ASR](https://arxiv.org/abs/2510.22492)
*Siyu Liang,Nicolas Ballier,Gina-Anne Levow,Richard Wright*

Main category: cs.CL

TL;DR: 音频数据量对多语言ASR模型的亚词单元库影响不大，但训练数据差异会影响推理时的亚词单元利用。


<details>
  <summary>Details</summary>
Motivation: 评估多语言ASR模型（Whisper）在不同语言下学习到的亚词单元（sub-token）库存，以及数据不均衡性如何影响推理时的亚词单元利用。

Method: 分析Whisper在49种语言下解码时的行为，记录候选亚词单元并追踪其累积发现过程，研究模型亚词单元空间的利用模式。

Result: 发现总的亚词单元发现数量与语言的训练时长关系不大，表明数据不均衡性不强烈影响假设空间中的词汇多样性。亚词单元的发现率呈现一致的指数饱和模式，表明存在一个稳定的时间窗口，超过该窗口后，增加音频能激活的新亚词单元数量很少。该收敛阈值被称为声学饱和时间（AST）。词频分布呈现类似Zipf定律的模式，受Zipf-Mandelbrot定律的建模效果更好，平均亚词单元长度与资源水平呈正相关。拉丁字母语言的指标模式优于西里尔字母、CJK和闪米特字母语言。

Conclusion: 多语言ASR推理过程中的亚词单元利用更多地受到语音的统计、类型学和正字法结构限制，而非训练数据规模，这为更公平的语料库构建和跨语言评估提供了实证依据。

Abstract: How much audio is needed to fully observe a multilingual ASR model's learned
sub-token inventory across languages, and does data disparity in multilingual
pre-training affect how these tokens are utilized during inference? We address
this question by analyzing Whisper's decoding behavior during inference across
49 languages. By logging decoding candidate sub-tokens and tracking their
cumulative discovery over time, we study the utilization pattern of the model's
sub-token space. Results show that the total number of discovered tokens
remains largely independent of a language's pre-training hours, indicating that
data disparity does not strongly influence lexical diversity in the model's
hypothesis space. Sub-token discovery rates follow a consistent exponential
saturation pattern across languages, suggesting a stable time window after
which additional audio yields minimal new sub-token activation. We refer to
this convergence threshold as acoustic saturation time (AST). Further analyses
of rank-frequency distributions reveal Zipf-like patterns better modeled by a
Zipf-Mandelbrot law, and mean sub-token length shows a positive correlation
with resource level. Additionally, those metrics show more favorable patterns
for languages in the Latin script than those in scripts such as Cyrillic, CJK,
and Semitic. Together, our study suggests that sub-token utilization during
multilingual ASR inference is constrained more by the statistical, typological,
and orthographic structure of the speech than by training data scale, providing
an empirical basis for more equitable corpus construction and cross-lingual
evaluation.

</details>


### [252] [A Sociophonetic Analysis of Racial Bias in Commercial ASR Systems Using the Pacific Northwest English Corpus](https://arxiv.org/abs/2510.22495)
*Michael Scott,Siyu Liang,Alicia Wassink,Gina-Anne Levow*

Main category: cs.CL

TL;DR: 本研究使用太平洋西北英语语料库，系统评估了四种主流商用自动语音识别（ASR）系统在不同族裔（非裔美国人、高加索裔美国人、奇卡诺克斯人和亚基马人）发言者上的语音转录准确性，并分析了社会语音学变异如何导致系统性能差异。研究引入了一种基于启发式确定的语音错误率（PER）指标，将识别错误与源自社会语音学注释的语言学变量联系起来。分析结果表明，元音质量变异，特别是对低后合并和鼻前合并模式的抵抗，与不同族裔群体的错误率差异显著相关，其中非裔美国人受到的影响最为明显。这表明，方言语音学变异的声学建模是导致ASR系统偏见的主要原因，而非词汇或句法因素。本研究确立了PNWE语料库作为语音技术偏见评估的宝贵资源，并为通过目标性地在训练数据中表示社会语音学多样性来改进ASR性能提供了可操作的指导。


<details>
  <summary>Details</summary>
Motivation: 评估四种主要商用自动语音识别（ASR）系统在不同族裔发言者上的种族偏见，并探究社会语音学变异如何导致系统性能差异。

Method: 使用太平洋西北英语（PNWE）语料库，分析非裔美国人、高加索裔美国人、奇卡诺克斯人和亚基马人发言者的转录准确性。引入语音错误率（PER）指标，将识别错误与社会语音学变异联系起来，并分析了十一种社会语音学特征。

Result: 元音质量变异，特别是对低后合并和鼻前合并模式的抵抗，与不同族裔群体的错误率差异显著相关，其中非裔美国人受到的影响最为明显。声学建模的方言语音学变异是ASR系统偏见的主要来源。

Conclusion: 声学建模的方言语音学变异是导致ASR系统偏见的主要原因，而非词汇或句法因素。PNWE语料库为偏见评估提供了资源，并为改进ASR性能提供了指导，强调了在训练数据中表示社会语音学多样性的重要性。

Abstract: This paper presents a systematic evaluation of racial bias in four major
commercial automatic speech recognition (ASR) systems using the Pacific
Northwest English (PNWE) corpus. We analyze transcription accuracy across
speakers from four ethnic backgrounds (African American, Caucasian American,
ChicanX, and Yakama) and examine how sociophonetic variation contributes to
differential system performance. We introduce a heuristically-determined
Phonetic Error Rate (PER) metric that links recognition errors to specific
linguistically motivated variables derived from sociophonetic annotation. Our
analysis of eleven sociophonetic features reveals that vowel quality variation,
particularly resistance to the low-back merger and pre-nasal merger patterns,
is systematically associated with differential error rates across ethnic
groups, with the most pronounced effects for African American speakers across
all evaluated systems. These findings demonstrate that acoustic modeling of
dialectal phonetic variation, rather than lexical or syntactic factors, remains
a primary source of bias in commercial ASR systems. The study establishes the
PNWE corpus as a valuable resource for bias evaluation in speech technologies
and provides actionable guidance for improving ASR performance through targeted
representation of sociophonetic diversity in training data.

</details>


### [253] [Text to Trust: Evaluating Fine-Tuning and LoRA Trade-offs in Language Models for Unfair Terms of Service Detection](https://arxiv.org/abs/2510.22531)
*Noshitha Padma Pratyusha Juttu,Sahithi Singireddy,Sravani Gona,Sujal Timilsina*

Main category: cs.CL

TL;DR: LLMs在法律领域的应用可以通过全微调、参数高效微调（如LoRA）和零样本提示等方法进行，其中全微调效果最好，LoRA在内存成本上具有优势，为法律文本处理提供了有效的模型选择和优化方案。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在法律领域的适应性，特别是在服务条款（ToS）文档中检测不公平条款的应用，旨在解决全微调成本高昂的限制，并探索更高效的适应策略。

Method: 对BERT、DistilBERT进行全微调；对TinyLlama、LLaMA 3B/7B、SaulLM等模型应用4位低秩适配（LoRA）；评估GPT-4o和O-versions的零样本提示能力；在CLAUDETTE-ToS基准和多语言Scraper语料库上进行实验。

Result: 全微调在精确率和召回率的平衡上表现最佳；基于LoRA的模型在召回率方面具有竞争力，同时内存成本降低高达3倍。

Conclusion: 研究揭示了在法律领域应用LLMs时，在效率和性能之间进行设计的实际权衡，为法律文本处理中的微调研究贡献了开放基线。

Abstract: Large Language Models (LLMs) have transformed text understanding, yet their
adaptation to specialized legal domains remains constrained by the cost of full
fine-tuning. This study provides a systematic evaluation of fine tuning,
parameter efficient adaptation (LoRA, QLoRA), and zero-shot prompting
strategies for unfair clause detection in Terms of Service (ToS) documents, a
key application in legal NLP. We finetune BERT and DistilBERT, apply 4-bit
Low-Rank Adaptation (LoRA) to models such as TinyLlama, LLaMA 3B/7B, and
SaulLM, and evaluate GPT-4o and O-versions in zero-shot settings. Experiments
on the CLAUDETTE-ToS benchmark and the Multilingual Scraper Corpus show that
full fine-tuning achieves the strongest precision recall balance, while
LoRA-based models provide competitive recall with up to 3x lower memory cost.
These findings highlight practical design trade-offs for efficient and
domain-adapted LLMs, contributing open baselines for fine-tuning research in
legal text processing.

</details>


### [254] [LooGLE v2: Are LLMs Ready for Real World Long Dependency Challenges?](https://arxiv.org/abs/2510.22548)
*Ziyuan He,Yuxuan Wang,Jiaqi Li,Kexin Liang,Muhan Zhang*

Main category: cs.CL

TL;DR: LLMs在处理长文本依赖任务方面能力有限，LooGLE v2基准测试显示，即使是最好的模型也只能达到59.2%的分数，表明在实际长文本理解方面仍有很大改进空间。


<details>
  <summary>Details</summary>
Motivation: LLMs虽然上下文窗口不断扩展，但在长依赖任务上的理解能力仍有限且未被充分研究，尤其是在真实世界的应用中。

Method: 引入LooGLE v2基准测试，该测试包含从16k到2M token的真实长文本（涵盖法律、金融、游戏和代码领域），设计了10种特定领域的长依赖任务，并生成了1934个多样化且复杂的QA实例。

Result: 对6个本地部署和4个API模型的评估显示，最佳模型在该基准测试上的总体得分仅为59.2%，表明LLMs实际能理解的文本长度远小于其声称的上下文窗口长度。

Conclusion: 尽管LLMs拥有扩展的上下文窗口，但它们在处理真实世界长依赖任务方面的能力有限，距离实际应用仍有差距，模型在长文本理解方面有很大的改进潜力。

Abstract: Large language models (LLMs) are equipped with increasingly extended context
windows recently, yet their long context understanding capabilities over long
dependency tasks remain fundamentally limited and underexplored. This gap is
especially significant in many real-world long-context applications that were
rarely benchmarked. In this paper, we introduce LooGLE v2, a novel benchmark
designed to evaluate LLMs' long context ability in real-world applications and
scenarios. Our benchmark consists of automatically collected real-world long
texts, ranging from 16k to 2M tokens, encompassing domains in law, finance,
game and code. Accordingly, we delicately design 10 types of domain-specific
long-dependency tasks and generate 1,934 QA instances with various diversity
and complexity in a scalable data curation pipeline for further practical
needs. We conduct a comprehensive assessment of 6 locally deployed and 4
API-based LLMs. The evaluation results show that even the best-performing model
achieves only a 59.2% overall score on our benchmark. Despite the extensive
context windows, popular LLMs are only capable of understanding a much shorter
length of context than they claim to be, revealing significant limitations in
their ability to handle real-world tasks with long dependencies and
highlighting substantial room for model improvement in practical long-context
understanding.

</details>


### [255] [SABlock: Semantic-Aware KV Cache Eviction with Adaptive Compression Block Size](https://arxiv.org/abs/2510.22556)
*Jinhan Chen,Jianchun Liu,Hongli Xu,Xianjun Gao,Shilong Wang*

Main category: cs.CL

TL;DR: SABlock通过语义感知方法自适应地确定KV缓存的块大小，以提高长上下文LLM推理的效率和内存使用率。


<details>
  <summary>Details</summary>
Motivation: 长上下文LLM推理中，KV缓存不断增长的内存占用对模型的可扩展性构成了严重瓶颈。现有的KV缓存压缩方法（如基于token、块或句子的压缩）在保持语义连贯性和内存效率之间难以取得平衡。

Method: SABlock首先进行语义分割，将压缩边界与语言结构对齐，然后应用受段引导的token评分来优化token重要性估计。最后，对每个段，采用预算驱动的搜索策略，自适应地确定最优块大小，以在给定缓存预算下保持语义完整性并提高压缩效率。

Result: 在长上下文基准测试上的大量实验表明，SABlock在相同的内存预算下始终优于最先进的方法。例如，在Needle-in-a-Haystack（NIAH）任务上，SABlock以仅96个KV条目实现了99.9%的检索准确率，几乎可以媲美保留多达8K个条目的完整缓存基线。在固定的1024缓存预算下，SABlock可将峰值内存使用量进一步降低46.28%，并将128K上下文长度的解码速度提高高达9.5倍。

Conclusion: SABlock通过语义感知和自适应块大小调整，有效地解决了长上下文LLM推理中的KV缓存内存瓶颈问题，在保证语义完整性的同时显著提高了内存效率和推理速度。

Abstract: The growing memory footprint of the Key-Value (KV) cache poses a severe
scalability bottleneck for long-context Large Language Model (LLM) inference.
While KV cache eviction has emerged as an effective solution by discarding less
critical tokens, existing token-, block-, and sentence-level compression
methods struggle to balance semantic coherence and memory efficiency. To this
end, we introduce SABlock, a \underline{s}emantic-aware KV cache eviction
framework with \underline{a}daptive \underline{block} sizes. Specifically,
SABlock first performs semantic segmentation to align compression boundaries
with linguistic structures, then applies segment-guided token scoring to refine
token importance estimation. Finally, for each segment, a budget-driven search
strategy adaptively determines the optimal block size that preserves semantic
integrity while improving compression efficiency under a given cache budget.
Extensive experiments on long-context benchmarks demonstrate that SABlock
consistently outperforms state-of-the-art baselines under the same memory
budgets. For instance, on Needle-in-a-Haystack (NIAH), SABlock achieves 99.9%
retrieval accuracy with only 96 KV entries, nearly matching the performance of
the full-cache baseline that retains up to 8K entries. Under a fixed cache
budget of 1,024, SABlock further reduces peak memory usage by 46.28% and
achieves up to 9.5x faster decoding on a 128K context length.

</details>


### [256] [A Closed-Loop Personalized Learning Agent Integrating Neural Cognitive Diagnosis, Bounded-Ability Adaptive Testing, and LLM-Driven Feedback](https://arxiv.org/abs/2510.22559)
*Zhifeng Wang,Xinyue Zheng,Chunyan Zeng*

Main category: cs.CL

TL;DR: 本研究提出EduLoop-Agent，一个端到端的个性化学习代理，通过整合神经认知诊断模型(NCD)、有界能力估计计算机自适应测试策略(BECAT)和大型语言模型(LLMs)，解决了现有教育方法各自为政的局限性，实现了“诊断-推荐-反馈”的闭环。


<details>
  <summary>Details</summary>
Motivation: 现有教育方法在建模、题目选择和反馈方面往往孤立处理，导致学生模型粗糙、自适应性受限且反馈缺乏针对性。本研究旨在通过一个闭环框架来克服这些缺点。

Method: 本研究提出的EduLoop-Agent集成了三个核心组件：1. 神经认知诊断模型(NCD)，用于精细化评估知识点层面的学生掌握程度；2. 有界能力估计计算机自适应测试策略(BECAT)，用于动态选择题目以最大化相关性和学习效率；3. 大型语言模型(LLMs)，用于将诊断信号转化为结构化、可操作的反馈。这三者共同构成了一个“诊断-推荐-反馈”的闭环系统。

Result: 在ASSISTments数据集上的实验表明，NCD模块在预测学生回答方面表现出色，并能进行可解释的掌握度评估。BECAT策略提高了题目的相关性和个性化水平。基于LLM的反馈能够提供与学生薄弱环节相符的针对性学习指导。

Conclusion: EduLoop-Agent在实践中是有效且可部署的，为生成个性化的智能教育学习路径提供了一条可行的途径。

Abstract: As information technology advances, education is moving from
one-size-fits-all instruction toward personalized learning. However, most
methods handle modeling, item selection, and feedback in isolation rather than
as a closed loop. This leads to coarse or opaque student models,
assumption-bound adaptivity that ignores diagnostic posteriors, and generic,
non-actionable feedback. To address these limitations, this paper presents an
end-to-end personalized learning agent, EduLoop-Agent, which integrates a
Neural Cognitive Diagnosis model (NCD), a Bounded-Ability Estimation
Computerized Adaptive Testing strategy (BECAT), and large language models
(LLMs). The NCD module provides fine-grained estimates of students' mastery at
the knowledge-point level; BECAT dynamically selects subsequent items to
maximize relevance and learning efficiency; and LLMs convert diagnostic signals
into structured, actionable feedback. Together, these components form a
closed-loop framework of ``Diagnosis--Recommendation--Feedback.'' Experiments
on the ASSISTments dataset show that the NCD module achieves strong performance
on response prediction while yielding interpretable mastery assessments. The
adaptive recommendation strategy improves item relevance and personalization,
and the LLM-based feedback offers targeted study guidance aligned with
identified weaknesses. Overall, the results indicate that the proposed design
is effective and practically deployable, providing a feasible pathway to
generating individualized learning trajectories in intelligent education.

</details>


### [257] [Pedagogy-driven Evaluation of Generative AI-powered Intelligent Tutoring Systems](https://arxiv.org/abs/2510.22581)
*Kaushal Kumar Maurya,Ekaterina Kochmar*

Main category: cs.CL

TL;DR: 生成式AI在教育领域的应用，特别是大型语言模型驱动的智能辅导系统（ITSs）取得了显著进展，但缺乏统一、可靠的评估框架阻碍了其发展和影响力的追踪。现有评估方法主观且标准化程度低，导致结果不一致且泛化能力有限。本文回顾了ITSs的评估实践，指出了其中的挑战，并提出了三个基于学习科学原理、旨在建立公平、统一、可扩展的ITSs评估方法的研究方向。


<details>
  <summary>Details</summary>
Motivation: 生成式AI（GenAI）和大型语言模型（LLM）的出现加速了智能辅导系统（ITSs）的发展，但目前缺乏统一、可靠的评估框架来追踪这些系统的进展和影响，现有评估方法存在主观性、标准化程度低、结果不一致和泛化能力有限等问题。

Method: 本文回顾了当前智能辅导系统（ITSs）的评估实践，通过真实案例研究指出了其中的挑战，并提出了三个基于学习科学原理的研究方向，旨在建立公平、统一、可扩展的ITSs评估方法。

Result: 文章识别出现有ITSs评估的不足，例如主观性、非标准化基准以及由此产生的评估结果不一致和泛化能力有限的问题。文章提出了三个研究方向，旨在建立更公平、统一和可扩展的ITSs评估方法。

Conclusion: 为了充分发挥LLM驱动的ITSs的潜力，需要建立统一、公平且可扩展的评估方法。本文回顾了当前的评估实践，强调了现有方法的局限性，并提出了三个基于学习科学的研究方向，为未来的ITSs评估提供了一个理论上合理且实用的框架。

Abstract: The interdisciplinary research domain of Artificial Intelligence in Education
(AIED) has a long history of developing Intelligent Tutoring Systems (ITSs) by
integrating insights from technological advancements, educational theories, and
cognitive psychology. The remarkable success of generative AI (GenAI) models
has accelerated the development of large language model (LLM)-powered ITSs,
which have potential to imitate human-like, pedagogically rich, and cognitively
demanding tutoring. However, the progress and impact of these systems remain
largely untraceable due to the absence of reliable, universally accepted, and
pedagogy-driven evaluation frameworks and benchmarks. Most existing educational
dialogue-based ITS evaluations rely on subjective protocols and
non-standardized benchmarks, leading to inconsistencies and limited
generalizability. In this work, we take a step back from mainstream ITS
development and provide comprehensive state-of-the-art evaluation practices,
highlighting associated challenges through real-world case studies from careful
and caring AIED research. Finally, building on insights from previous
interdisciplinary AIED research, we propose three practical, feasible, and
theoretically grounded research directions, rooted in learning science
principles and aimed at establishing fair, unified, and scalable evaluation
methodologies for ITSs.

</details>


### [258] [AutoBench: Automating LLM Evaluation through Reciprocal Peer Assessment](https://arxiv.org/abs/2510.22593)
*Dario Loi,Elena Maria Muià,Federico Siciliano,Giovanni Trappolini,Vincenzo Crisà,Peter Kruger,Fabrizio Silvestri*

Main category: cs.CL

TL;DR: AutoBench是一个全自动、自给自足的框架，通过相互同行评审来评估大型语言模型（LLU）。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型的挑战，包括测试集污染和适应性有限，而AutoBench提供了一种动态生成新评估任务的方法。

Method: AutoBench动态生成新评估任务，模型交替担任生成者、竞争者和裁判。它使用迭代加权机制来放大可靠评估者的影响力，并将同行判断聚合为基于共识的排名。

Result: 实验证明AutoBench与MMLU-Pro和GPQA等基准测试有很强的相关性（分别为78%和63%）。多法官设计显著优于单法官基线。

Conclusion: AutoBench提供了一种可扩展、抗污染的替代静态基准的方法，用于持续评估不断发展的语言模型。

Abstract: We present AutoBench, a fully automated and self-sustaining framework for
evaluating Large Language Models (LLMs) through reciprocal peer assessment.
This paper provides a rigorous scientific validation of the AutoBench
methodology, originally developed as an open-source project by eZecute S.R.L..
Unlike static benchmarks that suffer from test-set contamination and limited
adaptability, AutoBench dynamically generates novel evaluation tasks while
models alternately serve as question generators, contestants, and judges across
diverse domains. An iterative weighting mechanism amplifies the influence of
consistently reliable evaluators, aggregating peer judgments into
consensus-based rankings that reflect collective model agreement. Our
experiments demonstrate strong correlations with established benchmarks
including MMLU-Pro and GPQA (respectively 78\% and 63\%), validating this
peer-driven evaluation paradigm. The multi-judge design significantly
outperforms single-judge baselines, confirming that distributed evaluation
produces more robust and human-consistent assessments. AutoBench offers a
scalable, contamination-resistant alternative to static benchmarks for the
continuous evaluation of evolving language models.

</details>


### [259] [Personal Care Utility (PCU): Building the Health Infrastructure for Everyday Insight and Guidance](https://arxiv.org/abs/2510.22602)
*Mahyar Abbasian,Ramesh Jain*

Main category: cs.CL

TL;DR: PCU是一个结合了数字基础设施和生物医学创新的终身健康指导系统，利用多模态数据、AI和多种代理来提供个性化健康信息、主动健康导航和治疗反应监测。


<details>
  <summary>Details</summary>
Motivation: 当前医疗保健模式是零散的，而PCU旨在创建一个持续的、适应性的健康指导系统，以改善个体和群体健康。

Method: PCU系统整合了多模态代理、事件中心建模和上下文推理，以实现其三大核心功能：个性化健康信息、主动健康导航和治疗反应解释。

Result: PCU通过整合个人传感、体验式计算和群体分析，有望改善个体健康结果，并为公共卫生和科学发现提供新的基础。

Conclusion: PCU是一个新兴的健康范式，通过其持续、适应性的方法，有望彻底改变个人健康管理和公共卫生策略，尽管其实现面临挑战。

Abstract: Building on decades of success in digital infrastructure and biomedical
innovation, we propose the Personal Care Utility (PCU) - a cybernetic system
for lifelong health guidance. PCU is conceived as a global, AI-powered utility
that continuously orchestrates multimodal data, knowledge, and services to
assist individuals and populations alike. Drawing on multimodal agents,
event-centric modeling, and contextual inference, it offers three essential
capabilities: (1) trusted health information tailored to the individual, (2)
proactive health navigation and behavior guidance, and (3) ongoing
interpretation of recovery and treatment response after medical events. Unlike
conventional episodic care, PCU functions as an ambient, adaptive companion -
observing, interpreting, and guiding health in real time across daily life. By
integrating personal sensing, experiential computing, and population-level
analytics, PCU promises not only improved outcomes for individuals but also a
new substrate for public health and scientific discovery. We describe the
architecture, design principles, and implementation challenges of this emerging
paradigm.

</details>


### [260] [PerCoR: Evaluating Commonsense Reasoning in Persian via Multiple-Choice Sentence Completion](https://arxiv.org/abs/2510.22616)
*Morteza Alikhani,Mohammadtaha Bagherifard,Erfan Zinvandi,Mehran Sarmadi*

Main category: cs.CL

TL;DR: PerCoR是第一个大规模波斯语常识推理基准，包含106K个多项选择题，并提出了一种新的联合基础分割策略和DRESS-AF方法来生成具有挑战性的干扰项。


<details>
  <summary>Details</summary>
Motivation: 构建一个大规模的波斯语常识推理基准，以促进该领域的研究。

Method: 使用联合基础分割策略生成连贯的句子补全对，并提出DRESS-AF（基于嵌入相似度评分和对抗性过滤的干扰项排序）方法来生成具有挑战性的干扰项。

Result: PerCoR包含106K个多项选择题，其中89%的题目由人工标注。OpenAI-o3和Claude-Sonnet-3.7在PerCoR上分别取得了92.18%和91.17%的准确率，而最强的开源模型DeepSeek-R1达到了82.51%。DRESS-AF方法也被证明可以迁移到英语HellaSwag基准上。

Conclusion: PerCoR是一个具有挑战性的波斯语常识推理数据集，它突出了该领域现有模型的性能差距。DRESS-AF是一种有效的方法，可以生成更具挑战性的干扰项，并且可以跨语言迁移。

Abstract: We introduced PerCoR (Persian Commonsense Reasoning), the first large-scale
Persian benchmark for commonsense reasoning. PerCoR contains 106K
multiple-choice sentence-completion problems drawn from more than forty news,
cultural, and other web sources. We introduce a novel conjunction-based
segmentation strategy to generate coherent sentence-completion pairs, enabling
broad topical and structural diversity. To create challenging distractors, we
propose DRESS-AF (Distractor Ranking via Embedding Similarity Scoring and
Adversarial Filtering), a generation-free adversarial filtering method that
selects distractors from the pool of gold continuations while maximising model
confusion. Human annotators score 89% on PerCoR, while OpenAI-o3 achieves the
highest performance at 92.18%, followed closely by Claude-Sonnet-3.7 (91.17%).
The strongest open-source model, DeepSeek-R1, reaches 82.51%, underscoring both
the dataset's difficulty and the remaining performance gap in Persian
commonsense reasoning. We further show that DRESS-AF transfers to the English
HellaSwag benchmark, increasing its difficulty without hurting human
solvability. The dataset is available at
https://huggingface.co/datasets/MCINext/PerCoR.

</details>


### [261] [Integrating Linguistics and AI: Morphological Analysis and Corpus development of Endangered Toto Language of West Bengal](https://arxiv.org/abs/2510.22629)
*Ambalika Guha,Sajal Saha,Debanjan Ballav,Soumi Mitra,Hritwick Chakraborty*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Preserving linguistic diversity is necessary as every language offers a
distinct perspective on the world. There have been numerous global initiatives
to preserve endangered languages through documentation. This paper is a part of
a project which aims to develop a trilingual (Toto-Bangla-English) language
learning application to digitally archive and promote the endangered Toto
language of West Bengal, India. This application, designed for both native Toto
speakers and non-native learners, aims to revitalize the language by ensuring
accessibility and usability through Unicode script integration and a structured
language corpus. The research includes detailed linguistic documentation
collected via fieldwork, followed by the creation of a morpheme-tagged,
trilingual corpus used to train a Small Language Model (SLM) and a
Transformer-based translation engine. The analysis covers inflectional
morphology such as person-number-gender agreement, tense-aspect-mood
distinctions, and case marking, alongside derivational strategies that reflect
word-class changes. Script standardization and digital literacy tools were also
developed to enhance script usage. The study offers a sustainable model for
preserving endangered languages by incorporating traditional linguistic
methodology with AI. This bridge between linguistic research with technological
innovation highlights the value of interdisciplinary collaboration for
community-based language revitalization.

</details>


### [262] [Culturally Grounded Physical Commonsense Reasoning in Italian and English: A Submission to the MRL 2025 Shared Task](https://arxiv.org/abs/2510.22631)
*Marco De Santis,Lisa Alazraki*

Main category: cs.CL

TL;DR: MRL 2025 共享任务的目标是创建多语言的物理常识推理数据集，本研究提出了 FormaMentis 这一基于意大利语言和文化的新基准。


<details>
  <summary>Details</summary>
Motivation: 创建非英语语言的物理常识推理评估数据集，以遵循 PIQA 格式。

Method: 由意大利母语专家创建数据样本，并将其翻译成英语，同时保留意大利文化元素。

Result: 提出了 FormaMentis，一个基于意大利语言和文化的新颖的物理常识推理基准。

Conclusion: FormaMentis 为多语言物理常识推理研究提供了宝贵的资源，特别是在意大利语背景下。

Abstract: This paper presents our submission to the MRL 2025 Shared Task on
Multilingual Physical Reasoning Datasets. The objective of the shared task is
to create manually-annotated evaluation data in the physical commonsense
reasoning domain, for languages other than English, following a format similar
to PIQA. Our contribution, FormaMentis, is a novel benchmark for physical
commonsense reasoning that is grounded in Italian language and culture. The
data samples in FormaMentis are created by expert annotators who are native
Italian speakers and are familiar with local customs and norms. The samples are
additionally translated into English, while preserving the cultural elements
unique to the Italian context.

</details>


### [263] [Conjugate Relation Modeling for Few-Shot Knowledge Graph Completion](https://arxiv.org/abs/2510.22656)
*Zilong Wang,Qingtian Zeng,Hua Duan,Cheng Cheng,Minghao Zou,Ziyang Wang*

Main category: cs.CL

TL;DR: 提出了一种新的共轭关系建模框架（CR-FKGC），用于少样本知识图谱补全（FKGC），以解决现有方法在捕获复杂关系模式和缓解数据稀疏性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的少样本知识图谱补全（FKGC）方法在捕获复杂的关系模式和缓解数据稀疏性方面存在挑战。

Method: 提出了一种新的共轭关系建模框架（CR-FKGC），包括一个整合高阶邻域信息的邻域聚合编码器，一个结合隐式条件扩散关系模块和稳定关系模块的共轭关系学习器，以及一个用于高效评估和推理的流形共轭解码器。

Result: 在三个基准测试中，CR-FKGC 取得了优于现有最先进方法的性能。

Conclusion: CR-FKGC 框架在少样本知识图谱补全任务上展现出优越的性能。

Abstract: Few-shot Knowledge Graph Completion (FKGC) infers missing triples from
limited support samples, tackling long-tail distribution challenges. Existing
methods, however, struggle to capture complex relational patterns and mitigate
data sparsity. To address these challenges, we propose a novel FKGC framework
for conjugate relation modeling (CR-FKGC). Specifically, it employs a
neighborhood aggregation encoder to integrate higher-order neighbor
information, a conjugate relation learner combining an implicit conditional
diffusion relation module with a stable relation module to capture stable
semantics and uncertainty offsets, and a manifold conjugate decoder for
efficient evaluation and inference of missing triples in manifold space.
Experiments on three benchmarks demonstrate that our method achieves superior
performance over state-of-the-art methods.

</details>


### [264] [Rule-Based Explanations for Retrieval-Augmented LLM Systems](https://arxiv.org/abs/2510.22689)
*Joel Rorseth,Parke Godfrey,Lukasz Golab,Divesh Srivastava,Jarek Szlichta*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: If-then rules are widely used to explain machine learning models; e.g., "if
employed = no, then loan application = rejected." We present the first proposal
to apply rules to explain the emerging class of large language models (LLMs)
with retrieval-augmented generation (RAG). Since RAG enables LLM systems to
incorporate retrieved information sources at inference time, rules linking the
presence or absence of sources can explain output provenance; e.g., "if a Times
Higher Education ranking article is retrieved, then the LLM ranks Oxford
first." To generate such rules, a brute force approach would probe the LLM with
all source combinations and check if the presence or absence of any sources
leads to the same output. We propose optimizations to speed up rule generation,
inspired by Apriori-like pruning from frequent itemset mining but redefined
within the scope of our novel problem. We conclude with qualitative and
quantitative experiments demonstrating our solutions' value and efficiency.

</details>


### [265] [SALSA: Single-pass Autoregressive LLM Structured Classification](https://arxiv.org/abs/2510.22691)
*Ruslan Berdichevsky,Shai Nahum-Gefen,Elad Ben Zaken*

Main category: cs.CL

TL;DR: SALSA是一个结合结构化提示、类别到令牌映射和参数高效微调的流水线，用于解决指令微调的大型语言模型在文本分类基准上表现不佳的问题，并在多个基准测试中取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 指令微调的大型语言模型在文本分类基准上表现不佳。

Method: SALSA流水线结合了结构化提示、类别到令牌映射和参数高效微调。每个类别标签被映射到一个独特的输出令牌，提示被构建为仅引发单个令牌的响应。在推理过程中，模型的输出仅被投射到相关类别令牌的logits上，从而在一次前向传播中实现高效准确的分类。

Result: SALSA在多个基准测试中取得了最先进的结果，证明了其在基于大型语言模型的分类应用中的鲁棒性和可扩展性。

Conclusion: SALSA流水线通过结构化提示、类别到令牌映射和参数高效微调的结合，有效地提高了指令微调大型语言模型在文本分类任务上的表现。

Abstract: Despite their impressive generalization capabilities, instruction-tuned Large
Language Models often underperform on text classification benchmarks. We
introduce SALSA, a coherent pipeline that combines structured prompting,
class-to-token mapping, and parameter-efficient fine-tuning, thereby avoiding
cold-start training. Each class label is mapped to a distinct output token, and
prompts are constructed to elicit a single-token response. During inference,
the model's output is projected only onto the logits of the relevant class
tokens, enabling efficient and accurate classification in a single forward
pass. SALSA achieves state-of-the-art results across diverse benchmarks,
demonstrating its robustness and scalability for LLM-based classification
applications.

</details>


### [266] [$\text{E}^2\text{Rank}$: Your Text Embedding can Also be an Effective and Efficient Listwise Reranker](https://arxiv.org/abs/2510.22733)
*Qi Liu,Yanzhao Zhang,Mingxin Li,Dingkun Long,Pengjun Xie,Jiaxin Mao*

Main category: cs.CL

TL;DR: 通过对文本嵌入模型进行微调，实现高效检索和列表式重排的统一框架E^2Rank。


<details>
  <summary>Details</summary>
Motivation: 现有文本嵌入模型在检索方面高效但排序保真度有限，无法媲美专门的重排模型（尤其是基于LLM的列表式重排模型），后者能更好地捕捉查询-文档和文档-文档间的交互。本研究旨在弥合这一差距。

Method: 提出了一种名为E^2Rank的统一框架，它通过在列表式排序目标下进行持续训练，将单一文本嵌入模型扩展到同时进行高质量检索和列表式重排。该框架使用查询和文档嵌入之间的余弦相似度作为统一的排序函数，并将原始查询及其候选文档构建成列表式排序提示（prompt），从而增强查询信号，类似于传统检索模型中的伪相关反馈（PRF）。

Result: E^2Rank在BEIR重排基准测试中取得了最先进的成果，在BRIGHT基准测试中也表现出强劲的竞争力，并且重排延迟极低。此外，在MTEB基准测试中，E^2Rank的训练过程也提高了嵌入模型的性能。

Conclusion: 单一嵌入模型能够有效地统一检索和重排任务，兼具计算效率和可观的排序准确性。

Abstract: Text embedding models serve as a fundamental component in real-world search
applications. By mapping queries and documents into a shared embedding space,
they deliver competitive retrieval performance with high efficiency. However,
their ranking fidelity remains limited compared to dedicated rerankers,
especially recent LLM-based listwise rerankers, which capture fine-grained
query-document and document-document interactions. In this paper, we propose a
simple yet effective unified framework $\text{E}^2\text{Rank}$, means Efficient
Embedding-based Ranking (also means Embedding-to-Rank), which extends a single
text embedding model to perform both high-quality retrieval and listwise
reranking through continued training under a listwise ranking objective,
thereby achieving strong effectiveness with remarkable efficiency. By applying
cosine similarity between the query and document embeddings as a unified
ranking function, the listwise ranking prompt, which is constructed from the
original query and its candidate documents, serves as an enhanced query
enriched with signals from the top-K documents, akin to pseudo-relevance
feedback (PRF) in traditional retrieval models. This design preserves the
efficiency and representational quality of the base embedding model while
significantly improving its reranking performance. Empirically,
$\textrm{E}^2\text{Rank}$ achieves state-of-the-art results on the BEIR
reranking benchmark and demonstrates competitive performance on the
reasoning-intensive BRIGHT benchmark, with very low reranking latency. We also
show that the ranking training process improves embedding performance on the
MTEB benchmark. Our findings indicate that a single embedding model can
effectively unify retrieval and reranking, offering both computational
efficiency and competitive ranking accuracy.

</details>


### [267] [Low-Resource Dialect Adaptation of Large Language Models: A French Dialect Case-Study](https://arxiv.org/abs/2510.22747)
*Eeham Khan,Firas Saidani,Owen Van Esbroeck,Richard Khoury,Leila Kosseim*

Main category: cs.CL

TL;DR: 儘管大型語言模型 (LLM) 已被廣泛採用，但它們最強大的功能仍然主要局限於少數擁有豐富訓練數據的高資源語言。最近，持續預訓練 (CPT) 已成為一種微調這些模型以適應低資源地區方言的方法。本研究探討在數據和計算預算有限的情況下，使用 CPT 進行方言學習。我們使用低秩適應 (LoRA) 和計算高效的 CPT，並使用非常小的數據集將三個 LLM 適應於魁北克法語方言，並在 COLE 套件上進行基準測試。


<details>
  <summary>Details</summary>
Motivation: 儘管大型語言模型 (LLM) 已被廣泛採用，但它們最強大的功能仍然主要局限於少數擁有豐富訓練 તલિમ ડેટાવાળી ઉચ્ચ-સંસાધન ભાષાઓ. તાજેતરમાં, સતત પૂર્વ-તાલીમ (CPT) એ આ મોડેલોને ઓછી-સંસાધન પ્રાદેશિક બોલીઓ માટે ફાઇન-ટ્યુન કરવાની પદ્ધતિ તરીકે ઉભરી આવી છે. આ પેપરમાં, અમે ટાઇટ ડેટા અને કમ્પ્યુટ બજેટ હેઠળ બોલી શીખવા માટે CPT ના ઉપયોગનો અભ્યાસ કરીએ છીએ.

Method: 使用低秩適應 (LoRA) 和計算高效的持續預訓練 (CPT) 將三個大型語言模型 (LLM) 適應於魁北克法語方言，並使用非常小的數據集。

Result: 我們的實驗證明，在少數方言基準測試上有所改進，同時在主流語言基準測試上的回歸很小，模型參數更新不到 1%。對結果的分析表明，收益高度依賴於語料庫的組成。

Conclusion: CPT 與參數高效微調 (PEFT) 相結合，可以通過提供成本效益高且可持續的語言資源創建，縮小方言差距，從而擴大高質量 LLM 對少數語言社區的訪問。我們在 HuggingFace 上發布了第一個魁北克法語 LLM。

Abstract: Despite the widespread adoption of large language models (LLMs), their
strongest capabilities remain largely confined to a small number of
high-resource languages for which there is abundant training data. Recently,
continual pre-training (CPT) has emerged as a means to fine-tune these models
to low-resource regional dialects. In this paper, we study the use of CPT for
dialect learning under tight data and compute budgets. Using low-rank
adaptation (LoRA) and compute-efficient continual pre-training, we adapt three
LLMs to the Qu\'ebec French dialect using a very small dataset and benchmark
them on the COLE suite. Our experiments demonstrate an improvement on the
minority dialect benchmarks with minimal regression on the prestige language
benchmarks with under 1% of model parameters updated. Analysis of the results
demonstrate that gains are highly contingent on corpus composition. These
findings indicate that CPT with parameter-efficient fine-tuning (PEFT) can
narrow the dialect gap by providing cost-effective and sustainable language
resource creation, expanding high-quality LLM access to minority linguistic
communities. We release the first Qu\'ebec French LLMs on HuggingFace.

</details>


### [268] [Beyond Semantics: How Temporal Biases Shape Retrieval in Transformer and State-Space Models](https://arxiv.org/abs/2510.22752)
*Anooshka Bajaj,Deven Mahesh Mistry,Sahaj Singh Maini,Yash Aggarwal,Zoran Tiganj*

Main category: cs.CL

TL;DR: LLM在情境学习中区分和检索时间上分离的事件的能力，类似于人类的情感记忆。通过实验发现，模型倾向于预测重复出现的token，但对输入开头或结尾附近的token存在偏见。这一现象在Transformer模型中与归纳头有关，并且在不同模型架构中都存在。


<details>
  <summary>Details</summary>
Motivation: 探究LLM在情境学习中区分和检索时间上分离事件的能力，以及时间关系如何影响信息检索。

Method: 通过设计包含重复出现的token的序列，并改变其他token的位置，来分离时间效应和语义混淆，然后分析模型对下一个token的预测。

Result: 模型普遍倾向于预测重复出现的token，但对于开头或结尾附近的token存在偏见。Transformer模型中的这种现象与归纳头有关。位于输入中间的记忆检索可靠性较低。Transformer和状态空间模型在时间偏见上表现相似。

Conclusion: LLM的情境学习能力受到时间关系的影响，存在时间偏见，这种偏见能够促进时间分离和事件检索。

Abstract: In-context learning is governed by both temporal and semantic relationships,
shaping how Large Language Models (LLMs) retrieve contextual information.
Analogous to human episodic memory, where the retrieval of specific events is
enabled by separating events that happened at different times, this work probes
the ability of various pretrained LLMs, including transformer and state-space
models, to differentiate and retrieve temporally separated events.
Specifically, we prompted models with sequences containing multiple
presentations of the same token, which reappears at the sequence end. By fixing
the positions of these repeated tokens and permuting all others, we removed
semantic confounds and isolated temporal effects on next-token prediction.
Across diverse sequences, models consistently placed the highest probabilities
on tokens following a repeated token, but with a notable bias for those nearest
the beginning or end of the input. An ablation experiment linked this
phenomenon in transformers to induction heads. Extending the analysis to unique
semantic contexts with partial overlap further demonstrated that memories
embedded in the middle of a prompt are retrieved less reliably. Despite
architectural differences, state-space and transformer models showed comparable
temporal biases. Our findings deepen the understanding of temporal biases in
in-context learning and offer an illustration of how these biases can enable
temporal separation and episodic retrieval.

</details>


### [269] [EchoMind: An Interrelated Multi-level Benchmark for Evaluating Empathetic Speech Language Models](https://arxiv.org/abs/2510.22758)
*Li Zhou,Lutong Yu,You Lyu,Yihang Lin,Zefeng Zhao,Junyi Ao,Yuhao Zhang,Benyou Wang,Haizhou Li*

Main category: cs.CL

TL;DR: EchoMind是一个新的基准，用于评估语音语言模型（SLM）在有声对话中的共情能力，并发现现有模型在理解和回应非词汇语音线索方面存在不足。


<details>
  <summary>Details</summary>
Motivation: 评估SLM在理解和回应情感和背景因素方面的共情能力，以及它们整合语言、声学、推理和对话能力以实现类人对话的能力。

Method: 提出EchoMind，一个多层次的基准，通过一系列相互关联的任务来模拟共情对话的认知过程：语音内容理解、语音线索感知、综合推理和回应生成。这些任务使用相同的、语义中性的脚本，并通过控制语音风格的变化来测试发音方式的影响。EchoMind基于一个包含3个粗粒度和12个细粒度维度的共情框架，涵盖39种语音属性，并使用客观和主观指标进行评估。

Result: 对12个先进SLM的测试表明，即使是最先进的模型在处理高表现力的语音线索时也面临挑战，这限制了共情回应的质量。模型在指令遵循、对自然语音变化的适应性以及有效利用语音线索进行共情方面存在持续的不足。

Conclusion: 目前的SLM在整合语言内容和多样的语音线索以实现真正的共情对话能力方面存在不足，需要进一步的研究和开发。

Abstract: Speech Language Models (SLMs) have made significant progress in spoken
language understanding. Yet it remains unclear whether they can fully perceive
non lexical vocal cues alongside spoken words, and respond with empathy that
aligns with both emotional and contextual factors. Existing benchmarks
typically evaluate linguistic, acoustic, reasoning, or dialogue abilities in
isolation, overlooking the integration of these skills that is crucial for
human-like, emotionally intelligent conversation. We present EchoMind, the
first interrelated, multi-level benchmark that simulates the cognitive process
of empathetic dialogue through sequential, context-linked tasks: spoken-content
understanding, vocal-cue perception, integrated reasoning, and response
generation. All tasks share identical and semantically neutral scripts that are
free of explicit emotional or contextual cues, and controlled variations in
vocal style are used to test the effect of delivery independent of the
transcript. EchoMind is grounded in an empathy-oriented framework spanning 3
coarse and 12 fine-grained dimensions, encompassing 39 vocal attributes, and
evaluated using both objective and subjective metrics. Testing 12 advanced SLMs
reveals that even state-of-the-art models struggle with high-expressive vocal
cues, limiting empathetic response quality. Analyses of prompt strength, speech
source, and ideal vocal cue recognition reveal persistent weaknesses in
instruction-following, resilience to natural speech variability, and effective
use of vocal cues for empathy. These results underscore the need for SLMs that
integrate linguistic content with diverse vocal cues to achieve truly
empathetic conversational ability.

</details>


### [270] [Iterative Layer Pruning for Efficient Translation Inference](https://arxiv.org/abs/2510.22763)
*Yasmin Moslem,Muhammad Hazim Al Farouq,John D. Kelleher*

Main category: cs.CL

TL;DR: 本文提出了一种通过迭代层剪枝和层重要性分析来压缩大型语言模型（LLMs）以提高机器翻译效率的方法，并在捷克语到德语和英语到埃及阿拉伯语的翻译任务上取得了显著的模型压缩和推理时间缩短，同时保持了翻译质量。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在自然语言处理领域取得了显著进展，但在机器翻译中的高效部署面临计算资源密集的问题。

Method: 本文提出了一种迭代层剪枝的方法，该方法由层重要性分析指导，并使用Aya-Expanse-8B模型在捷克语到德语以及英语到埃及阿拉伯语的翻译任务上进行了评估。

Result: 所提出的方法实现了模型大小和推理时间的显著减少，同时保持了基线模型的翻译质量。

Conclusion: 迭代层剪枝和层重要性分析是一种有效的方法，可以提高大型语言模型在机器翻译任务中的效率。

Abstract: Large language models (LLMs) have transformed many areas of natural language
processing, including machine translation. However, efficient deployment of
LLMs remains challenging due to their intensive computational requirements. In
this paper, we address this challenge and present our submissions to the Model
Compression track at the Conference on Machine Translation (WMT 2025). In our
experiments, we investigate iterative layer pruning guided by layer importance
analysis. We evaluate this method using the Aya-Expanse-8B model for
translation from Czech to German, and from English to Egyptian Arabic. Our
approach achieves substantial reductions in model size and inference time,
while maintaining the translation quality of the baseline models.

</details>


### [271] [MMPersuade: A Dataset and Evaluation Framework for Multimodal Persuasion](https://arxiv.org/abs/2510.22768)
*Haoyi Qiu,Yilun Zhou,Pranav Narayanan Venkit,Kung-Hsiang Huang,Jiaxin Zhang,Nanyun Peng,Chien-Sheng Wu*

Main category: cs.CL

TL;DR: 本研究提出了MMPersuade框架，用于系统地研究大型视觉语言模型(LVLMs)在面对多模态劝说内容时的行为。研究发现，多模态输入比纯文本更能有效地劝说LVLMs，尤其是在错误信息场景下。同时，表明的先验偏好可以降低LVLMs的易受劝说程度，但多模态信息仍具有优势。不同的劝说策略在不同情境下效果各异。


<details>
  <summary>Details</summary>
Motivation: 随着LVLMs在购物、健康、新闻等领域的广泛应用，它们会接触到大量的劝说性内容。理解LVLMs如何以及为何会被说服，以及不同劝说策略的有效性至关重要，因为过于容易被说服的模型可能采信错误信息，覆盖用户偏好，或产生不道德/不安全的输出。

Method: 提出MMPersuade框架，包含一个多模态数据集（将图像/视频与劝说原则相结合）和一个评估框架（通过第三方评分和对话历史的置信度来量化劝说效果和模型易感性）。

Result: 研究了六个领先的LVLMs。发现：1. 多模态输入比纯文本更能显著地提高劝说效果和模型易感性，尤其是在错误信息场景。2. 表明的先验偏好会降低易感性，但多模态信息仍具劝说优势。3. 不同策略效果因情境而异（互惠在商业/主观情境中最有效，信誉/逻辑在对抗情境中更胜一筹）。

Conclusion: MMPersuade框架为开发在面对劝说性多模态内容时具有鲁棒性、偏好一致性和道德对齐性的模型提供了原则性基础。

Abstract: As Large Vision-Language Models (LVLMs) are increasingly deployed in domains
such as shopping, health, and news, they are exposed to pervasive persuasive
content. A critical question is how these models function as persuadees-how and
why they can be influenced by persuasive multimodal inputs. Understanding both
their susceptibility to persuasion and the effectiveness of different
persuasive strategies is crucial, as overly persuadable models may adopt
misleading beliefs, override user preferences, or generate unethical or unsafe
outputs when exposed to manipulative messages. We introduce MMPersuade, a
unified framework for systematically studying multimodal persuasion dynamics in
LVLMs. MMPersuade contributes (i) a comprehensive multimodal dataset that pairs
images and videos with established persuasion principles across commercial,
subjective and behavioral, and adversarial contexts, and (ii) an evaluation
framework that quantifies both persuasion effectiveness and model
susceptibility via third-party agreement scoring and self-estimated token
probabilities on conversation histories. Our study of six leading LVLMs as
persuadees yields three key insights: (i) multimodal inputs substantially
increase persuasion effectiveness-and model susceptibility-compared to text
alone, especially in misinformation scenarios; (ii) stated prior preferences
decrease susceptibility, yet multimodal information maintains its persuasive
advantage; and (iii) different strategies vary in effectiveness across
contexts, with reciprocity being most potent in commercial and subjective
contexts, and credibility and logic prevailing in adversarial contexts. By
jointly analyzing persuasion effectiveness and susceptibility, MMPersuade
provides a principled foundation for developing models that are robust,
preference-consistent, and ethically aligned when engaging with persuasive
multimodal content.

</details>


### [272] [Scalable Supervising Software Agents with Patch Reasoner](https://arxiv.org/abs/2510.22775)
*Junjielong Xu,Boyin Tan,Xiaoyuan Liu,Chao Peng,Pengfei Gao,Pinjia He*

Main category: cs.CL

TL;DR: 现有基于测试的监督方法在扩展性上存在局限，限制了大型语言模型在软件工程任务上的潜力。本文提出的 R4P 模型通过推理来验证代码补丁，提供了一种可扩展的奖励机制，用于训练和测试软件工程代理。R4P 通过对比多个补丁的修改来减少奖励被利用的风险，实现了 72.2% 的准确率，优于 OpenAI o3。基于 R4P，Mini-SE 模型在 SWE-bench-verified 上达到了 26.2% 的 Pass@1，比原始 Qwen3-32B 提高了 10.0%。R4P 的验证速度快，平均只需一秒，比传统测试快 50 倍。


<details>
  <summary>Details</summary>
Motivation: 现有基于测试的监督方法在软件工程任务中存在可扩展性差、开销大、易出错以及数据稀缺等问题，限制了大型语言模型（LLM）在该领域的应用和发展。

Method: 本文提出 R4P 模型，将代码补丁验证视为一项推理任务。R4P 在强化学习训练中采用分组目标，允许模型对比多个补丁的修改，从而获得更密集的奖励，实现稳定训练。此外，本文还设计并训练了一个名为 Mini-SE 的精简模型，所有奖励均由 R4P 提供。

Result: R4P 在补丁验证任务上达到了 72.2% 的准确率，超过了 OpenAI o3。基于 R4P 的 Mini-SE 模型在 SWE-bench-verified 上实现了 26.2% 的 Pass@1，相比原始 Qwen3-32B 提高了 10.0%，使用 R4P 进行测试时甚至可以达到 32.8% 的 Pass@1。R4P 的验证速度极快，平均只需不到一秒，比传统测试方法快 50 倍。

Conclusion: R4P 模型通过推理实现了可扩展的补丁验证，为训练和测试软件工程代理提供了有效的解决方案。该方法不仅提高了准确率和效率，还解决了传统基于测试的监督方法的局限性，展示了其在软件工程领域的实用价值。

Abstract: While large language model agents have advanced software engineering tasks,
the unscalable nature of existing test-based supervision is limiting the
potential improvement of data scaling. The reason is twofold: (1) building and
running test sandbox is rather heavy and fragile, and (2) data with
high-coverage tests is naturally rare and threatened by test hacking via edge
cases. In this paper, we propose R4P, a patch verifier model to provide
scalable rewards for training and testing SWE agents via reasoning. We consider
that patch verification is fundamentally a reasoning task, mirroring how human
repository maintainers review patches without writing and running new
reproduction tests. To obtain sufficient reference and reduce the risk of
reward hacking, R4P uses a group-wise objective for RL training, enabling it to
verify multiple patches against each other's modification and gain a dense
reward for stable training. R4P achieves 72.2% Acc. for verifying patches from
SWE-bench-verified, surpassing OpenAI o3. To demonstrate R4P's practicality, we
design and train a lite scaffold, Mini-SE, with pure reinforcement learning
where all rewards are derived from R4P. As a result, Mini-SE achieves 26.2%
Pass@1 on SWE-bench-verified, showing a 10.0% improvement over the original
Qwen3-32B. This can be further improved to 32.8% with R4P for test-time
scaling. Furthermore, R4P verifies patches within a second, 50x faster than
testing on average. The stable scaling curves of rewards and accuracy along
with high efficiency reflect R4P's practicality.

</details>


### [273] [VEHME: A Vision-Language Model For Evaluating Handwritten Mathematics Expressions](https://arxiv.org/abs/2510.22798)
*Thu Phuong Nguyen,Duc M. Nguyen,Hyotaek Jeon,Hyunwook Lee,Hyunmin Song,Sungahn Ko,Taehwan Kim*

Main category: cs.CL

TL;DR: VEHME是一个用于评估手写数学表达式的视觉-语言模型，旨在解决教育技术领域中自动评估手写数学题目的挑战。它通过监督微调和强化学习进行训练，并引入了表达式感知视觉提示模块来增强空间理解能力。在AIHub和FERMAT数据集上的评估结果显示，VEHME的性能优于现有的开源模型，并接近专有系统。该模型为自动化数学评估提供了一个可扩展且易于访问的工具。


<details>
  <summary>Details</summary>
Motivation: 自动评估手写数学解决方案在教育技术领域具有重要意义，但由于格式多样、布局不规则和符号复杂性等问题，一直是一项重大挑战。

Method: VEHME模型集成了两阶段训练流程：1. 使用结构化推理数据进行监督微调；2. 进行强化学习，使模型输出与多维度评分目标（包括正确性、推理深度和错误定位）保持一致。为了增强空间理解能力，提出了一种表达式感知视觉提示模块，并在合成的多行数学表达式数据集上进行训练。

Result: 在AIHub和FERMAT数据集上的评估结果表明，VEHME在开源模型中取得了最先进的性能，并且在准确性上接近专有系统。

Conclusion: VEHME模型在自动化评估手写数学表达式方面展现出高准确性和可解释的推理能力，为教育技术领域提供了一个可扩展且易于访问的解决方案。

Abstract: Automatically assessing handwritten mathematical solutions is an important
problem in educational technology with practical applications, but it remains a
significant challenge due to the diverse formats, unstructured layouts, and
symbolic complexity of student work. To address this challenge, we introduce
VEHME-a Vision-Language Model for Evaluating Handwritten Mathematics
Expressions-designed to assess open-form handwritten math responses with high
accuracy and interpretable reasoning traces. VEHME integrates a two-phase
training pipeline: (i) supervised fine-tuning using structured reasoning data,
and (ii) reinforcement learning that aligns model outputs with
multi-dimensional grading objectives, including correctness, reasoning depth,
and error localization. To enhance spatial understanding, we propose an
Expression-Aware Visual Prompting Module, trained on our synthesized multi-line
math expressions dataset to robustly guide attention in visually heterogeneous
inputs. Evaluated on AIHub and FERMAT datasets, VEHME achieves state-of-the-art
performance among open-source models and approaches the accuracy of proprietary
systems, demonstrating its potential as a scalable and accessible tool for
automated math assessment. Our training and experiment code is publicly
available at our GitHub repository.

</details>


### [274] [Cross-Lingual Stability and Bias in Instruction-Tuned Language Models for Humanitarian NLP](https://arxiv.org/abs/2510.22823)
*Poli Nemkova,Amrit Adhikari,Matthew Pearson,Vamsi Krishna Sadu,Mark V. Albert*

Main category: cs.CL

TL;DR: 人权监测领域，商业API和开源模型各有优劣。本研究首次系统比较了两种模型在七种语言中的表现，量化了成本与可靠性的权衡。


<details>
  <summary>Details</summary>
Motivation: 人道主义组织在监测人权时面临成本与可靠性的选择困境，尤其是在低资源语言方面，现有开源模型缺乏实证验证。

Method: 比较了四种指令微调模型（Claude-Sonnet-4, DeepSeek-V3, Gemini-Flash-2.0, GPT-4.1-mini）和两种开源模型（LLaMA-3-8B, Mistral-7B）在七种语言中的表现，使用了标准分类指标和四种新的跨语言可靠性指标（CD, B, LRS, LSS）。

Result: 研究发现，模型的对齐程度而非规模决定了其稳定性。对齐模型在不同语言（包括低资源语言）上保持了接近不变的准确率和校准度，而开源模型则表现出明显的提示-语言敏感性和校准漂移。

Conclusion: 多语言对齐使得模型能够进行语言无关的推理，为预算有限但需要可靠多语言监测的人道主义组织提供了实际指导。

Abstract: Humanitarian organizations face a critical choice: invest in costly
commercial APIs or rely on free open-weight models for multilingual human
rights monitoring. While commercial systems offer reliability, open-weight
alternatives lack empirical validation -- especially for low-resource languages
common in conflict zones. This paper presents the first systematic comparison
of commercial and open-weight large language models (LLMs) for
human-rights-violation detection across seven languages, quantifying the
cost-reliability trade-off facing resource-constrained organizations. Across
78,000 multilingual inferences, we evaluate six models -- four
instruction-aligned (Claude-Sonnet-4, DeepSeek-V3, Gemini-Flash-2.0,
GPT-4.1-mini) and two open-weight (LLaMA-3-8B, Mistral-7B) -- using both
standard classification metrics and new measures of cross-lingual reliability:
Calibration Deviation (CD), Decision Bias (B), Language Robustness Score (LRS),
and Language Stability Score (LSS). Results show that alignment, not scale,
determines stability: aligned models maintain near-invariant accuracy and
balanced calibration across typologically distant and low-resource languages
(e.g., Lingala, Burmese), while open-weight models exhibit significant
prompt-language sensitivity and calibration drift. These findings demonstrate
that multilingual alignment enables language-agnostic reasoning and provide
practical guidance for humanitarian organizations balancing budget constraints
with reliability in multilingual deployment.

</details>


### [275] [Exploration of Summarization by Generative Language Models for Automated Scoring of Long Essays](https://arxiv.org/abs/2510.22830)
*Haowei Hua,Hong Jiao,Xinyi Wang*

Main category: cs.CL

TL;DR: BERT及其变体在自动评分中的应用受到512个标记的限制，而生成式语言模型通过摘要和提示可以提高长文书评分的准确性。


<details>
  <summary>Details</summary>
Motivation: BERT及其变体在自动评分中存在512个标记的限制，无法处理长篇文章。

Method: 使用生成式语言模型，通过摘要和提示技术，对长篇文章进行自动评分。

Result: 使用生成式语言模型将评分准确性QWK从0.822提高到0.8878（使用“学习机构实验室自动长文评分2.0”数据集）。

Conclusion: 生成式语言模型在自动长文评分方面取得了显著的改进。

Abstract: BERT and its variants are extensively explored for automated scoring.
However, a limit of 512 tokens for these encoder-based models showed the
deficiency in automated scoring of long essays. Thus, this research explores
generative language models for automated scoring of long essays via
summarization and prompting. The results revealed great improvement of scoring
accuracy with QWK increased from 0.822 to 0.8878 for the Learning Agency Lab
Automated Essay Scoring 2.0 dataset.

</details>


### [276] [Leveraging Large Language Models to Identify Conversation Threads in Collaborative Learning](https://arxiv.org/abs/2510.22844)
*Prerna Ravi,Dong Won Lee,Beatriz Flamia,Jasmine David,Brandon Hanks,Cynthia Breazeal,Emma Anderson,Grace Lin*

Main category: cs.CL

TL;DR: 该研究通过引入对话线索来改进大型语言模型(LLM)对小组讨论的分析能力，解决了在同步语音对话中识别对话线索的挑战，并证明了明确的对话线索能提高LLM在协作学习分析中的表现。


<details>
  <summary>Details</summary>
Motivation: 理解小组对话中思想的发展和流动对于分析协作学习至关重要。对话线索是这些交互的一个关键结构特征，但由于语音对话的重叠发言和隐晦线索，在同步语音对话中检测对话线索仍然具有挑战性。同时，大型语言模型（LLM）在自动化话语分析方面显示出潜力，但常常难以处理依赖于追踪对话联系的长上下文任务。

Method: 该研究提出了一个系统化的指南，用于识别同步多方对话记录中的对话线索，并对不同的LLM提示策略进行了基准测试，以实现自动化对话线索检测。随后，研究测试了对话线索如何影响下游对话分析框架（如同意、构建和引导）的编码性能。

Result: 研究结果表明，提供清晰的对话线索信息可以提高LLM的编码性能，并强调下游分析在很大程度上依赖于结构良好的对话。此外，研究还讨论了时间、成本等实际权衡，并指出了混合人机方法可以带来最佳价值。

Conclusion: 该研究通过结合LLM和稳健的对话线索结构，改进了理解复杂、实时小组交互的方法，并证明了明确的对话线索可以提高LLM在协作学习分析中的表现。

Abstract: Understanding how ideas develop and flow in small-group conversations is
critical for analyzing collaborative learning. A key structural feature of
these interactions is threading, the way discourse talk naturally organizes
into interwoven topical strands that evolve over time. While threading has been
widely studied in asynchronous text settings, detecting threads in synchronous
spoken dialogue remains challenging due to overlapping turns and implicit cues.
At the same time, large language models (LLMs) show promise for automating
discourse analysis but often struggle with long-context tasks that depend on
tracing these conversational links. In this paper, we investigate whether
explicit thread linkages can improve LLM-based coding of relational moves in
group talk. We contribute a systematic guidebook for identifying threads in
synchronous multi-party transcripts and benchmark different LLM prompting
strategies for automated threading. We then test how threading influences
performance on downstream coding of conversational analysis frameworks, that
capture core collaborative actions such as agreeing, building, and eliciting.
Our results show that providing clear conversational thread information
improves LLM coding performance and underscores the heavy reliance of
downstream analysis on well-structured dialogue. We also discuss practical
trade-offs in time and cost, emphasizing where human-AI hybrid approaches can
yield the best value. Together, this work advances methods for combining LLMs
and robust conversational thread structures to make sense of complex, real-time
group interactions.

</details>


### [277] [Once Upon an Input: Reasoning via Per-Instance Program Synthesis](https://arxiv.org/abs/2510.22849)
*Adam Stein,Neelay Velingker,Mayur Naik,Eric Wong*

Main category: cs.CL

TL;DR: PIPS是一种在算法推理中改进大型语言模型（LLM）性能的新方法，通过实例级程序合成和结构化反馈，减少了不理想的程序生成，并在多个基准测试中取得了显著的准确性提升。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在零样本推理方面表现出色，但在复杂的多步推理方面仍然存在挑战。像思维链（CoT）和思想程序（PoT）这样的方法虽然有所改进，但尤其是在算法领域，常常产生不理想的解决方案。

Method: PIPS（Per-Instance Program Synthesis）方法在实例级别生成和优化程序，利用结构化反馈，无需特定任务的指导或显式测试用例。此外，PIPS包含一个置信度指标，可以根据实例动态地在直接推理和程序合成之间进行选择。

Result: 在三个前沿LLM和30个基准测试（包括Big Bench Extra Hard（BBEH）的所有任务、视觉问答任务、关系推理任务和数学推理任务）上的实验表明，与PoT和CoT相比，PIPS的绝对调和平均准确率分别提高了8.6%和9.4%，并且在算法任务上与Gemini-2.0-Flash的PoT相比，不理想的程序生成减少了65.1%。

Conclusion: PIPS通过实例级程序合成和结构化反馈，在复杂推理任务中显著提高了LLM的性能，特别是在算法领域，同时减少了不理想的输出。

Abstract: Large language models (LLMs) excel at zero-shot inference but continue to
struggle with complex, multi-step reasoning. Recent methods that augment LLMs
with intermediate reasoning steps such as Chain of Thought (CoT) and Program of
Thought (PoT) improve performance but often produce undesirable solutions,
especially in algorithmic domains. We introduce Per-Instance Program Synthesis
(PIPS), a method that generates and refines programs at the instance-level
using structural feedback without relying on task-specific guidance or explicit
test cases. To further improve performance, PIPS incorporates a confidence
metric that dynamically chooses between direct inference and program synthesis
on a per-instance basis. Experiments across three frontier LLMs and 30
benchmarks including all tasks of Big Bench Extra Hard (BBEH), visual question
answering tasks, relational reasoning tasks, and mathematical reasoning tasks
show that PIPS improves the absolute harmonic mean accuracy by up to 8.6% and
9.4% compared to PoT and CoT respectively, and reduces undesirable program
generations by 65.1% on the algorithmic tasks compared to PoT with
Gemini-2.0-Flash.

</details>


### [278] [Far from the Shallow: Brain-Predictive Reasoning Embedding through Residual Disentanglement](https://arxiv.org/abs/2510.22860)
*Linyang He,Tianjun Zhong,Richard Antonello,Gavin Mischler,Micah Goldblum,Nima Mesgarani*

Main category: cs.CL

TL;DR: LLMs的纠缠表征阻碍了对大脑更高层次认知功能的神经科学研究。本研究提出了一种残差解纠缠方法，将LLM表征分离为词汇、句法、意义和推理四个几乎正交的嵌入。该方法能够分离出推理的神经信号，该信号具有独特的预测能力，并且在时间上晚于其他语言特征，这表明了其在认知处理层级中的位置。


<details>
  <summary>Details</summary>
Motivation: 理解人脑如何从处理简单的语言输入过渡到进行高级推理是神经科学中的一个基本挑战。尽管现代大型语言模型（LLM）越来越多地被用于模拟神经对语言的反应，但它们的内部表征高度“纠缠”，混合了词汇、句法、意义和推理的信息。这种纠缠使传统的神经编码分析偏向于词汇和句法等语言学浅层特征，从而难以分离认知更深层过程的神经基础。

Method: 本研究引入了一种残差解纠缠方法，在计算上分离这些组成部分。通过首先探测语言模型以识别特定于特征的层，该方法迭代地回归去除较低级别的表征，以产生词汇、句法、意义和推理四个近乎正交的嵌入。

Result: 1.分离出的推理嵌入具有独特的预测能力，能够解释其他语言特征无法解释的神经活动的变化，甚至扩展到经典语言区域以外的视觉区域的募集。 2.推理的神经信号在时间上是不同的，其峰值时间（约350-400毫秒）晚于与词汇、句法和意义相关的信号，这与其在处理层级结构中的位置一致。 3.标准的、未解纠缠的LLM嵌入可能具有误导性，因为它们的预测成功主要归因于语言学上的浅层特征，从而掩盖了更深层认知处理的微妙贡献。

Conclusion: 所提出的残差解纠缠方法能够成功分离LLM中的语言学特征，并揭示了推理的神经表征，这在时间和预测能力上都与其他语言特征不同。这为研究大脑中的高级认知功能提供了新的途径，并强调了在分析LLM表征时需要谨慎，以避免得出误导性结论。

Abstract: Understanding how the human brain progresses from processing simple
linguistic inputs to performing high-level reasoning is a fundamental challenge
in neuroscience. While modern large language models (LLMs) are increasingly
used to model neural responses to language, their internal representations are
highly "entangled," mixing information about lexicon, syntax, meaning, and
reasoning. This entanglement biases conventional brain encoding analyses toward
linguistically shallow features (e.g., lexicon and syntax), making it difficult
to isolate the neural substrates of cognitively deeper processes. Here, we
introduce a residual disentanglement method that computationally isolates these
components. By first probing an LM to identify feature-specific layers, our
method iteratively regresses out lower-level representations to produce four
nearly orthogonal embeddings for lexicon, syntax, meaning, and, critically,
reasoning. We used these disentangled embeddings to model intracranial (ECoG)
brain recordings from neurosurgical patients listening to natural speech. We
show that: 1) This isolated reasoning embedding exhibits unique predictive
power, accounting for variance in neural activity not explained by other
linguistic features and even extending to the recruitment of visual regions
beyond classical language areas. 2) The neural signature for reasoning is
temporally distinct, peaking later (~350-400ms) than signals related to
lexicon, syntax, and meaning, consistent with its position atop a processing
hierarchy. 3) Standard, non-disentangled LLM embeddings can be misleading, as
their predictive success is primarily attributable to linguistically shallow
features, masking the more subtle contributions of deeper cognitive processing.

</details>


### [279] [Interpreting and Mitigating Unwanted Uncertainty in LLMs](https://arxiv.org/abs/2510.22866)
*Tiasa Singha Roy,Ayush Rajesh Jhaveri,Ilias Triantafyllopoulos*

Main category: cs.CL

TL;DR: LLM在被重新提示时会产生不希望出现的不确定性，即使它们之前给出了正确的答案。本研究通过修改“Needle-in-a-Haystack”检索框架并结合“Flip-style”重新评估提示，研究了导致这种现象的机制。研究发现，检索头并非不确定性的主要原因，而是少数非检索注意力头在不确定情境下过多地关注误导性标记。通过掩盖这些头，可以将答案翻转行为减少高达15%，同时不会引入不连贯或过度修正的问题。然而，在下游任务测试中，答案翻转行为与此存在权衡。这项研究为理解LLM的机制提供了新的见解，并提出了一种缓解不确定性导致模型失效的有效技术。


<details>
  <summary>Details</summary>
Motivation: LLM（大语言模型）在被重新提示时会产生不希望出现的不确定性，即使它们之前给出了正确的答案。这种行为会破坏信任，并在高风险领域带来严重风险。本研究旨在调查驱动这种现象的机制。

Method: 研究者调整了“Needle-in-a-Haystack”检索框架，并整合了“Flip-style”重新评估提示，以模拟现实的答案翻转场景。

Result: 研究发现，检索头并非主要负责避免不确定性。相反，研究确定了一小部分非检索注意力头，它们在不确定的上下文中不成比例地关注误导性标记。掩盖这些头可以显著改善模型性能，将翻转行为减少高达15%，同时不会引入不连贯或过度修正的问题。然而，在下游任务测试中，观察到翻转行为与性能之间存在权衡。

Conclusion: 本研究的发现有助于机制可解释性领域的发展，并提出了一种简单而有效的技术，用于减轻由不确定性驱动的LLM故障模式。

Abstract: Despite their impressive capabilities, Large Language Models (LLMs) exhibit
unwanted uncertainty, a phenomenon where a model changes a previously correct
answer into an incorrect one when re-prompted. This behavior undermines trust
and poses serious risks in high-stakes domains. In this work, we investigate
the mechanisms that drive this phenomenon. We adapt the Needle-in-a-Haystack
retrieval framework and integrate a Flip-style re-evaluation prompt to simulate
realistic answer-flipping scenarios. We find that retrieval heads are not
primarily responsible for avoiding uncertainty. Instead, we identify a small
set of non-retrieval attention heads that disproportionately attend to
misleading tokens in uncertain contexts. Masking these heads yields significant
improvements, reducing flip behavior by up to 15% without introducing
incoherence or overcorrection. However, when tested for downstream tasks, we
observe trade-offs with flip behavior. Our findings contribute to the growing
field of mechanistic interpretability and present a simple yet effective
technique for mitigating uncertainty-driven failure modes in LLMs.

</details>


### [280] [A Comprehensive Dataset for Human vs. AI Generated Text Detection](https://arxiv.org/abs/2510.22874)
*Rajarshi Roy,Nasrin Imanpour,Ashhar Aziz,Shashwat Bajpai,Gurpreet Singh,Shwetangshu Biswas,Kapil Wanaskar,Parth Patwa,Subhankar Ghosh,Shreyas Dixit,Nilesh Ranjan Pal,Vipula Rawte,Ritvik Garimella,Gaytri Jena,Amit Sheth,Vasu Sharma,Aishwarya Naresh Reganti,Vinija Jain,Aman Chadha,Amitava Das*

Main category: cs.CL

TL;DR: 该研究提出了一个包含超过58,000个文本样本的数据集，用于检测和溯源AI生成文本。数据集结合了《纽约时报》的真实文章和由多个先进大型语言模型（LLMs）生成的合成版本。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型（LLMs）生成的文本越来越像人类文本，引发了对内容真实性、错误信息和可信度的担忧，因此需要可靠地检测AI生成文本并将其归因于特定模型。

Method: 创建了一个包含58,000多个文本样本的数据集，其中包含《纽约时报》的真实文章和由Gemma-2-9b、Mistral-7B、Qwen-2-72B、LLaMA-8B、Yi-Large和GPT-4-o等多个先进LLMs生成的合成版本。使用原始文章摘要作为提示，生成了全文人类撰写叙述。

Result: 在区分人类编写文本和AI生成文本的任务上，达到了58.35%的准确率；在将AI文本归因于其生成模型方面，准确率达到了8.92%。

Conclusion: 该数据集旨在通过结合真实的 and 现代生成模型的内容，推动强大的检测和归因方法的发展，从而在生成式AI时代促进信任和透明度。

Abstract: The rapid advancement of large language models (LLMs) has led to increasingly
human-like AI-generated text, raising concerns about content authenticity,
misinformation, and trustworthiness. Addressing the challenge of reliably
detecting AI-generated text and attributing it to specific models requires
large-scale, diverse, and well-annotated datasets. In this work, we present a
comprehensive dataset comprising over 58,000 text samples that combine
authentic New York Times articles with synthetic versions generated by multiple
state-of-the-art LLMs including Gemma-2-9b, Mistral-7B, Qwen-2-72B, LLaMA-8B,
Yi-Large, and GPT-4-o. The dataset provides original article abstracts as
prompts, full human-authored narratives. We establish baseline results for two
key tasks: distinguishing human-written from AI-generated text, achieving an
accuracy of 58.35\%, and attributing AI texts to their generating models with
an accuracy of 8.92\%. By bridging real-world journalistic content with modern
generative models, the dataset aims to catalyze the development of robust
detection and attribution methods, fostering trust and transparency in the era
of generative AI. Our dataset is available at:
https://huggingface.co/datasets/gsingh1-py/train.

</details>


### [281] [Batch Speculative Decoding Done Right](https://arxiv.org/abs/2510.22876)
*Ranran Haoran Zhang,Soumik Dey,Ashirbad Mishra,Hansi Wu,Binbin Li,Rui Zhang*

Main category: cs.CL

TL;DR: 批处理推断中的投机解码通过解决不齐张量问题并引入一种动态分组方法来提高效率和正确性。


<details>
  <summary>Details</summary>
Motivation: 为生产服务扩展批处理推断中的投机解码，同时解决不齐张量问题并确保输出等价性。

Method: 提出了一种名为EQSPEC的正确性优先的批处理投机解码方法，该方法暴露了需要40%开销的重新对齐。然后，引入了EXSPEC，它维护一个滑动序列池并动态地形成相同长度的组，以减少重新对齐开销，同时保留每序列的投机加速。

Result: 在SpecBench数据集上，对于Vicuna-7B/68M、Qwen3-8B/0.6B和GLM-4-9B/0.6B目标/草稿对，与批量大小为1相比，批量大小为8时，吞吐量提高了3倍，并且通过批量大小为8实现了高效扩展，同时保持了95%的输出等价性。该方法不需要自定义内核，并能与现有推断堆栈干净地集成。

Conclusion: EXSPEC通过解决批处理推断中的不齐张量问题，在保持输出等价性的同时，实现了高效的批处理投机解码，从而提高了吞吐量和可扩展性。

Abstract: Speculative decoding speeds up LLM inference by using a small draft model to
propose multiple tokens that a target model verifies in parallel. Extending
this idea to batches is essential for production serving, but it introduces the
ragged tensor problem: sequences in the same batch accept different numbers of
draft tokens, breaking right-alignment and corrupting position IDs, attention
masks, and KV-cache state. We show that several existing batch implementations
violate output equivalence-the fundamental requirement that speculative
decoding must produce identical token sequences to standard autoregressive
generation. These violations occur precisely due to improper handling of the
ragged tensor problem. In response, we (1) characterize the synchronization
requirements that guarantee correctness, (2) present a correctness-first batch
speculative decoding EQSPEC that exposes realignment as consuming 40% of
overhead, and (3) introduce EXSPEC, which maintains a sliding pool of sequences
and dynamically forms same-length groups, to reduce the realignment overhead
while preserving per-sequence speculative speedups. On the SpecBench dataset,
across Vicuna-7B/68M, Qwen3-8B/0.6B, and GLM-4-9B/0.6B target/draft pairs, our
approach achieves up to 3$\times$ throughput improvement at batch size 8
compared to batch size 1, with efficient scaling through batch size 8, while
maintaining 95% output equivalence. Our method requires no custom kernels and
integrates cleanly with existing inference stacks. Our code is available at
https://github.com/eBay/spec_dec.

</details>


### [282] [Language Server CLI Empowers Language Agents with Process Rewards](https://arxiv.org/abs/2510.22907)
*Yifan Zhang,Lanser Contributors*

Main category: cs.CL

TL;DR: Lanser-CLI是一个命令行工具，它通过固定和协调语言服务器协议(LSP)服务器来为编码代理和CI提供确定性、可重现的工作流程，解决大型语言模型在API调用和代码编辑中的不确定性问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型经常出现幻觉和错误定位编辑的问题，而语言服务器能提供关于真实代码的、经过验证的、IDE级别的准确信息。因此，需要一个能够利用语言服务器提供的信息来引导编码代理的工具。

Method: Lanser-CLI通过提供一个选择器DSL（包括符号、AST路径和内容锚定选择器）来解决定位问题，并提出了一种原则性的重新定位算法。它还通过分析束来规范化语言服务器的响应，并捕获环境和能力元数据。此外，它还为重命名和代码操作等变异操作提供了一个安全框架，包括预览、工作区隔离和Git感知的事务性应用。最后，它从语言服务器的事实（如诊断差异、消歧置信度和安全应用检查）中推导出一个进程奖励函数。

Result: Lanser-CLI提供了一个选择器DSL，用于精确的代码定位，分析束来规范化和捕获语言服务器响应的元数据，以及一个安全的变异操作框架。它还提出了一个可在线计算和离线重放的进程奖励函数，该函数基于语言服务器的事实。

Conclusion: Lanser-CLI通过利用语言服务器提供的事实信息，为编码代理提供了一个确定性、可重现的工作流程，解决了大型语言模型在代码生成和编辑中的不确定性问题。进程奖励函数使得代理的规划循环能够与程序现实保持一致，并支持进程监督和反事实分析。

Abstract: Large language models routinely hallucinate APIs and mislocalize edits, while
language servers compute verified, IDE-grade facts about real code. We present
Lanser-CLI, a CLI-first orchestration layer that pins and mediates a Language
Server Protocol (LSP) server for coding agents and CI, exposing deterministic,
replayable workflows. Our position is that language servers provide not only
structural information (definitions, references, types, diagnostics) but also
an actionable process reward: machine-checked, step-wise signals that align an
agent's planning loop with program reality. In this work, Lanser-CLI
contributes: (i) a robust addressing scheme beyond brittle "file:line:col" via
a Selector DSL (symbolic, AST-path, and content-anchored selectors) with a
principled relocation algorithm; (ii) deterministic Analysis Bundles that
normalize Language Server responses and capture environment/capability metadata
with stable content hashes; (iii) a safety envelope for mutating operations
(rename, code actions) with preview, workspace jails, and Git-aware,
transactional apply; and (iv) a process-reward functional derived from Language
Server facts (diagnostic deltas, disambiguation confidence, and safe-apply
checks) that is computable online and replayable offline. We formalize
determinism under frozen snapshots and establish a monotonicity property for
the process reward, making it suitable for process supervision and
counterfactual analysis. Project Page:
https://github.com/yifanzhang-pro/lanser-cli

</details>


### [283] [Artificial Hivemind: The Open-Ended Homogeneity of Language Models (and Beyond)](https://arxiv.org/abs/2510.22954)
*Liwei Jiang,Yuanjun Chai,Margaret Li,Mickel Liu,Raymond Fok,Nouha Dziri,Yulia Tsvetkov,Maarten Sap,Alon Albalak,Yejin Choi*

Main category: cs.CL

TL;DR: 大型语言模型（LMs）在生成多样化、人性化的创意内容方面存在挑战，这引发了人们对长期接触类似输出可能导致人类思想同质化的担忧。然而，评估LM输出多样性的可扩展方法仍然有限，尤其是在随机数或名称生成等狭窄任务之外，或者在单一模型重复采样之外。我们引入了Infinity-Chat，一个包含26K个多样化、真实世界、开放式用户查询的大型数据集，这些查询允许有多种合理的答案，没有单一的正确答案。我们提出了第一个用于表征LM所面临的开放式提示的全面分类法，包括6个顶级类别（例如，头脑风暴和构思），进一步细分为17个子类别。利用Infinity-Chat，我们对LM中的模式崩溃进行了大规模研究，揭示了LM在开放式生成中显著的“人工智能蜂群思维”效应，其特点是（1）模型内部重复，即单一模型持续生成类似响应，以及更严重的（2）模型间同质性，即不同模型产生惊人相似的输出。Infinity-Chat还包括31,250个人工标注，包括绝对评分和成对偏好，每个示例有25个独立的）。这使得研究在响应开放式查询时，集体和个人特定的**人类偏好成为可能。我们的研究结果表明，尽管LMs、奖励模型和LM裁判在整体质量上保持可比性，但在引起不同特定标注者偏好的模型生成方面，它们与人类评分的校准程度较低。总的来说，INFINITY-CHAT提供了第一个用于系统研究LM的真实世界开放式查询的大规模资源，揭示了关键见解，以指导未来研究，减轻“人工智能蜂群思维”带来的长期人工智能安全风险。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LMs）在开放式生成任务中输出多样性的方法有限，并担心长期接触类似输出可能导致人类思想同质化。本研究旨在通过引入大规模数据集和全面的分类法来解决这些问题，并研究LMs中的“人工智能蜂群思维”效应。

Method: 引入了Infinity-Chat数据集（26K个开放式用户查询）和开放式提示的分类法。利用该数据集研究了LMs中的模式崩溃和“人工智能蜂群思维”效应，分析了模型内部和模型间的重复性。还纳入了31,250个人工标注（绝对评分和成对偏好），以研究人类偏好。

Result: 研究发现LMs在开放式生成中存在显著的“人工智能蜂群思维”效应，表现为模型内部和模型间的重复性。LMs、奖励模型和LM裁判在处理引起不同人类偏好的模型生成时，与人类评分的校准程度较低，尽管整体质量相当。

Conclusion: Infinity-Chat是一个大规模资源，用于系统地研究LMs的真实世界开放式查询，揭示了“人工智能蜂群思维”效应，这对于减轻长期人工智能安全风险至关重要。研究强调了在评估和改进LM开放式生成能力方面，考虑人类多样化偏好的重要性。

Abstract: Language models (LMs) often struggle to generate diverse, human-like creative
content, raising concerns about the long-term homogenization of human thought
through repeated exposure to similar outputs. Yet scalable methods for
evaluating LM output diversity remain limited, especially beyond narrow tasks
such as random number or name generation, or beyond repeated sampling from a
single model. We introduce Infinity-Chat, a large-scale dataset of 26K diverse,
real-world, open-ended user queries that admit a wide range of plausible
answers with no single ground truth. We introduce the first comprehensive
taxonomy for characterizing the full spectrum of open-ended prompts posed to
LMs, comprising 6 top-level categories (e.g., brainstorm & ideation) that
further breaks down to 17 subcategories. Using Infinity-Chat, we present a
large-scale study of mode collapse in LMs, revealing a pronounced Artificial
Hivemind effect in open-ended generation of LMs, characterized by (1)
intra-model repetition, where a single model consistently generates similar
responses, and more so (2) inter-model homogeneity, where different models
produce strikingly similar outputs. Infinity-Chat also includes 31,250 human
annotations, across absolute ratings and pairwise preferences, with 25
independent human annotations per example. This enables studying collective and
individual-specific human preferences in response to open-ended queries. Our
findings show that LMs, reward models, and LM judges are less well calibrated
to human ratings on model generations that elicit differing idiosyncratic
annotator preferences, despite maintaining comparable overall quality. Overall,
INFINITY-CHAT presents the first large-scale resource for systematically
studying real-world open-ended queries to LMs, revealing critical insights to
guide future research for mitigating long-term AI safety risks posed by the
Artificial Hivemind.

</details>


### [284] [Tagging-Augmented Generation: Assisting Language Models in Finding Intricate Knowledge In Long Contexts](https://arxiv.org/abs/2510.22956)
*Anwesan Pal,Karen Hovsepian,Tinghao Guo,Mengnan Zhao,Somendra Tripathi,Nikos Kanakaris,George Mihaila,Sumit Nigam*

Main category: cs.CL

TL;DR: TAG是一种轻量级的数据增强策略，通过在检索到的文档中添加标签或将标签定义纳入提示中，来提高LLM在长上下文场景下的问答和推理能力，而无需进行复杂的预处理或修改文档。


<details>
  <summary>Details</summary>
Motivation: 现有的长上下文处理方法（如RAG）存在局限性，对预处理和模型选择敏感，并且会改变文档的完整性。需要一种更有效、更轻量级的方法来提升LLM在长上下文中的表现。

Method: 提出了一种名为Tagging-Augmented Generation (TAG) 的数据增强策略，该策略通过在检索到的文档中添加标签或将标签定义添加到提示中，来增强LLM在长上下文场景下的性能。

Result: 在NoLima和NovelQA两个基准测试上，TAG策略在32K token上下文下一致性地提高了性能，最高可达17%。对于需要跨大范围文本知识的多跳复杂推理问答，性能提升了2.9%。

Conclusion: TAG是一种有效且轻量级的数据增强方法，可以显著提高LLM在长上下文问答和推理任务中的性能，同时保持检索文档的完整性。

Abstract: Recent investigations into effective context lengths of modern flagship large
language models (LLMs) have revealed major limitations in effective question
answering (QA) and reasoning over long and complex contexts for even the
largest and most impressive cadre of models. While approaches like
retrieval-augmented generation (RAG) and chunk-based re-ranking attempt to
mitigate this issue, they are sensitive to chunking, embedding and retrieval
strategies and models, and furthermore, rely on extensive pre-processing,
knowledge acquisition and indexing steps. In this paper, we propose
Tagging-Augmented Generation (TAG), a lightweight data augmentation strategy
that boosts LLM performance in long-context scenarios, without degrading and
altering the integrity and composition of retrieved documents. We validate our
hypothesis by augmenting two challenging and directly relevant
question-answering benchmarks -- NoLima and NovelQA -- and show that tagging
the context or even just adding tag definitions into QA prompts leads to
consistent performance gains over the baseline -- up to 17% for 32K token
contexts, and 2.9% in complex reasoning question-answering for multi-hop
queries requiring knowledge across a wide span of text. Additional details are
available at https://sites.google.com/view/tag-emnlp.

</details>


### [285] [MAD-Fact: A Multi-Agent Debate Framework for Long-Form Factuality Evaluation in LLMs](https://arxiv.org/abs/2510.22967)
*Yucheng Ning,Xixun Lin,Fang Fang,Yanan Cao*

Main category: cs.CL

TL;DR: LLM在长文本事实性方面存在问题，本文提出了一种结合大规模长文本数据集、多智能体验证和加权评估指标的系统化方法，并构建了中文长文本数据集LongHalluQA和多智能体验证系统MAD-Fact，实验表明该方法能有效评估和提升长文本事实可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM评估方法在长文本事实性方面存在不足，尤其是在生物医学、法律和教育等高风险领域，LLM的输出准确性令人担忧。

Method: 构建了中文长文本事实性数据集LongHalluQA；开发了基于辩论的多智能体验证系统MAD-Fact；引入了事实重要性层级来衡量长文本中声明的不同重要性。

Result: 实验表明，较大的LLM通常能保持较高的事实一致性，而国内模型在中文内容上表现更优。MAD-Fact在评估长文本事实性方面优于现有方法。

Conclusion: 本文提出的结构化框架能够评估和增强长文本LLM输出的事实可靠性，为在敏感领域安全部署LLM提供了指导。

Abstract: The widespread adoption of Large Language Models (LLMs) raises critical
concerns about the factual accuracy of their outputs, especially in high-risk
domains such as biomedicine, law, and education. Existing evaluation methods
for short texts often fail on long-form content due to complex reasoning
chains, intertwined perspectives, and cumulative information. To address this,
we propose a systematic approach integrating large-scale long-form datasets,
multi-agent verification mechanisms, and weighted evaluation metrics. We
construct LongHalluQA, a Chinese long-form factuality dataset; and develop
MAD-Fact, a debate-based multi-agent verification system. We introduce a fact
importance hierarchy to capture the varying significance of claims in long-form
texts. Experiments on two benchmarks show that larger LLMs generally maintain
higher factual consistency, while domestic models excel on Chinese content. Our
work provides a structured framework for evaluating and enhancing factual
reliability in long-form LLM outputs, guiding their safe deployment in
sensitive domains.

</details>


### [286] [Measuring Teaching with LLMs](https://arxiv.org/abs/2510.22968)
*Michael Hardy*

Main category: cs.CL

TL;DR: 通过使用基于句子嵌入的自定义大语言模型（LLM），研究人员开发出一种新的教育质量衡量方法，该方法在大规模、可靠和有效的教师发展反馈方面显示出巨大潜力。


<details>
  <summary>Details</summary>
Motivation: 教育领域长期存在教学质量衡量不准确、难以扩展的问题。虽然大型语言模型（LLM）有潜力，但通用模型在应用复杂的课堂观察工具方面存在困难。

Method: 本研究采用基于句子嵌入的自定义LLM，并采用数据高效的训练方法，以系统评估五种不同的句子嵌入模型。

Result: 结果表明，这些专业模型在专家评分高于0.65时，可以达到甚至超越人类水平的评分者相关性。此外，研究发现更先进的模型更倾向于将分数变化归因于课程层面的特征，而不是孤立的言论。聚合模型分数与教师增值测量结果一致，但个体条目层面的结果不一致。

Conclusion: 本研究提出了一种可行且强大的新方法，用于AI驱动的教学质量衡量，为提供可扩展、可靠和有效的教师发展反馈开辟了道路。

Abstract: Objective and scalable measurement of teaching quality is a persistent
challenge in education. While Large Language Models (LLMs) offer potential,
general-purpose models have struggled to reliably apply complex, authentic
classroom observation instruments. This paper uses custom LLMs built on
sentence-level embeddings, an architecture better suited for the long-form,
interpretive nature of classroom transcripts than conventional subword
tokenization. We systematically evaluate five different sentence embeddings
under a data-efficient training regime designed to prevent overfitting. Our
results demonstrate that these specialized models can achieve human-level and
even super-human performance with expert human ratings above 0.65 and
surpassing the average human-human rater correlation. Further, through analysis
of annotation context windows, we find that more advanced models-those better
aligned with human judgments-attribute a larger share of score variation to
lesson-level features rather than isolated utterances, challenging the
sufficiency of single-turn annotation paradigms. Finally, to assess external
validity, we find that aggregate model scores align with teacher value-added
measures, indicating they are capturing features relevant to student learning.
However, this trend does not hold at the individual item level, suggesting that
while the models learn useful signals, they have not yet achieved full
generalization. This work establishes a viable and powerful new methodology for
AI-driven instructional measurement, offering a path toward providing scalable,
reliable, and valid feedback for educator development.

</details>


### [287] [Understanding In-Context Learning Beyond Transformers: An Investigation of State Space and Hybrid Architectures](https://arxiv.org/abs/2510.23006)
*Shenran Wang,Timothy Tin-Long Tse,Jian Zhu*

Main category: cs.CL

TL;DR: 大规模语言模型（LLM）在不同架构（Transformer, State-Space, Hybrid）上的模型内部机制进行 in-context learning (ICL) 的深入评估，发现不同架构模型在任务表现上可能相似，但在内部机制上存在差异。函数向量（FVs）主要存在于自注意力层和Mamba层，而Mamba2可能采用不同的ICL机制。FVs 对于参数化知识检索的ICL更重要，而对于上下文理解则不那么重要。该研究结合行为探查和干预方法，强调了结合行为和机制分析的重要性。


<details>
  <summary>Details</summary>
Motivation: 理解不同架构的大语言模型（LLMs）在 in-context learning (ICL) 任务中的内部工作机制，并探讨函数向量（FVs）在其中的作用。

Method: 结合行为探查和干预方法，在两种知识密集型ICL任务上，对Transformer、State-Space和Hybrid等不同架构的大语言模型进行深入评估，分析函数向量（FVs）在不同类型ICL任务中的重要性。

Result: 发现不同架构的LLMs在任务表现上可能相似，但在内部机制上存在差异。函数向量（FVs）主要存在于自注意力和Mamba层，且对于涉及参数化知识检索的ICL任务比上下文理解任务更重要。Mamba2可能使用不同于FVs的机制进行ICL。

Conclusion: 不同架构的LLMs在ICL任务中的内部机制存在差异，函数向量（FVs）在其中扮演重要角色，尤其是在参数化知识检索方面。结合行为分析和机制分析对于深入理解LLMs的能力至关重要。

Abstract: We perform in-depth evaluations of in-context learning (ICL) on
state-of-the-art transformer, state-space, and hybrid large language models
over two categories of knowledge-based ICL tasks. Using a combination of
behavioral probing and intervention-based methods, we have discovered that,
while LLMs of different architectures can behave similarly in task performance,
their internals could remain different. We discover that function vectors (FVs)
responsible for ICL are primarily located in the self-attention and Mamba
layers, and speculate that Mamba2 uses a different mechanism from FVs to
perform ICL. FVs are more important for ICL involving parametric knowledge
retrieval, but not for contextual knowledge understanding. Our work contributes
to a more nuanced understanding across architectures and task types.
Methodologically, our approach also highlights the importance of combining both
behavioural and mechanistic analyses to investigate LLM capabilities.

</details>


### [288] [LangLingual: A Personalised, Exercise-oriented English Language Learning Tool Leveraging Large Language Models](https://arxiv.org/abs/2510.23011)
*Sammriddh Gupta,Sonit Singh,Aditya Joshi,Mira Kim*

Main category: cs.CL

TL;DR: LangLingual是一个利用大型语言模型和LangChain框架构建的会话代理，用于提供实时的语法反馈、生成语言练习和追踪学习者能力，旨在丰富语言学习体验。


<details>
  <summary>Details</summary>
Motivation: 语言教育工作者在提供反馈和练习方面可能受到限制，因此需要创新的解决方案来丰富学习者体验。

Method: 设计和开发了一个名为LangLingual的会话代理，该代理使用LangChain框架，并由大型语言模型驱动，能够提供实时的、侧重于语法的反馈，生成上下文感知的语言练习，并追踪学习者随时间推移的能力。

Result: 研究结果表明LangLingual具有很强的可用性，能够带来积极的学习成果，并能有效激发学习者的参与度。

Conclusion: LangLingual作为一个由大型语言模型和LangChain框架驱动的会话代理，在提供实时语法反馈、生成练习和追踪学习者能力方面表现出色，能够有效提升语言学习体验。

Abstract: Language educators strive to create a rich experience for learners, while
they may be restricted in the extend of feedback and practice they can provide.
We present the design and development of LangLingual, a conversational agent
built using the LangChain framework and powered by Large Language Models. The
system is specifically designed to provide real-time, grammar-focused feedback,
generate context-aware language exercises and track learner proficiency over
time. The paper discusses the architecture, implementation and evaluation of
LangLingual in detail. The results indicate strong usability, positive learning
outcomes and encouraging learner engagement.

</details>


### [289] [Incentivizing Agentic Reasoning in LLM Judges via Tool-Integrated Reinforcement Learning](https://arxiv.org/abs/2510.23038)
*Ran Xu,Jingjing Chen,Jiayu Ye,Yu Wu,Jun Yan,Carl Yang,Hongkun Yu*

Main category: cs.CL

TL;DR: LLM judges can be enhanced with code execution capabilities through an RL framework called TIR-Judge, improving their evaluation accuracy on complex tasks and benchmarks.


<details>
  <summary>Details</summary>
Motivation: Most LLM judges rely on intrinsic text-based reasoning, which limits their ability to handle complex constraints or perform accurate computations. TIR-Judge aims to address this limitation by integrating a code executor.

Method: TIR-Judge is an end-to-end RL framework that trains LLM judges to integrate a code executor for precise evaluation. It incorporates diverse training across verifiable and non-verifiable domains, flexible judgment formats, and iterative RL that bootstraps directly from the initial model.

Result: TIR-Judge outperforms strong reasoning-based judges on seven public benchmarks by up to 6.4% (pointwise) and 7.7% (pairwise). It also achieves comparable listwise performance to Claude-Opus-4 with significantly fewer parameters (8B). Notably, TIR-Judge-Zero, trained without distilled trajectories, matches the performance of distilled variants.

Conclusion: Tool-augmented LLM judges can be effectively trained using iterative reinforcement learning, achieving strong performance even without distillation, demonstrating their potential for self-evolution and improved evaluation capabilities.

Abstract: Large Language Models (LLMs) are widely used as judges to evaluate response
quality, providing a scalable alternative to human evaluation. However, most
LLM judges operate solely on intrinsic text-based reasoning, limiting their
ability to verify complex constraints or perform accurate computation.
Motivated by the success of tool-integrated reasoning (TIR) in numerous tasks,
we propose TIR-Judge, an end-to-end RL framework for training LLM judges that
integrates a code executor for precise evaluation. TIR-Judge is built on three
principles: (i) diverse training across verifiable and non-verifiable domains,
(ii) flexible judgment formats (pointwise, pairwise, listwise), and (iii)
iterative RL that bootstraps directly from the initial model without
distillation. On seven public benchmarks, TIR-Judge surpasses strong
reasoning-based judges by up to 6.4% (pointwise) and 7.7% (pairwise), and
achieves listwise performance comparable to Claude-Opus-4 despite having only
8B parameters. Remarkably, TIR-Judge-Zero - trained entirely without distilled
judge trajectories, matches the performance of distilled variants,
demonstrating that tool-augmented judges can self-evolve through iterative
reinforcement learning.

</details>


### [290] [Knocking-Heads Attention](https://arxiv.org/abs/2510.23052)
*Zhanchao Zhou,Xiaodong Chen,Haoxing Chen,Zhenzhong Lan,Jianguo Li*

Main category: cs.CL

TL;DR: Multi-head attention (MHA) is standard in LLMs, but more heads weaken individual capacity. We propose Knocking-Heads Attention (KHA) to enable cross-head feature interactions before attention, using a shared, diagonally-initialized projection matrix. KHA adds minimal overhead, integrates easily, and improves training dynamics and downstream performance.


<details>
  <summary>Details</summary>
Motivation: Existing MHA variants like GQA and GTA concatenate outputs from isolated heads without strong interaction, which weakens individual head capacity as the number of heads increases. To address this, we need a mechanism that facilitates cross-head feature-level interactions.

Method: Knocking-Heads Attention (KHA) enables attention heads to interact by applying a shared, diagonally-initialized projection matrix across all heads before scaled dot-product attention. The diagonal initialization helps maintain head specialization early in training while allowing the model to learn integrated cross-head representations over time. This approach adds minimal parameters and FLOPs and can be integrated into various attention mechanisms.

Result: KHA was validated by training a 6.1B parameter MoE model on 1T tokens. Compared to baseline attention mechanisms, KHA demonstrated superior and more stable training dynamics, leading to better performance on downstream tasks.

Conclusion: Knocking-Heads Attention (KHA) is an effective method for improving multi-head attention by enabling feature-level interactions between heads, leading to better training stability and downstream performance with minimal computational overhead.

Abstract: Multi-head attention (MHA) has become the cornerstone of modern large
language models, enhancing representational capacity through parallel attention
heads. However, increasing the number of heads inherently weakens individual
head capacity, and existing attention mechanisms - whether standard MHA or its
variants like grouped-query attention (GQA) and grouped-tied attention (GTA) -
simply concatenate outputs from isolated heads without strong interaction. To
address this limitation, we propose knocking-heads attention (KHA), which
enables attention heads to "knock" on each other - facilitating cross-head
feature-level interactions before the scaled dot-product attention. This is
achieved by applying a shared, diagonally-initialized projection matrix across
all heads. The diagonal initialization preserves head-specific specialization
at the start of training while allowing the model to progressively learn
integrated cross-head representations. KHA adds only minimal parameters and
FLOPs and can be seamlessly integrated into MHA, GQA, GTA, and other attention
variants. We validate KHA by training a 6.1B parameter MoE model (1.01B
activated) on 1T high-quality tokens. Compared to baseline attention
mechanisms, KHA brings superior and more stable training dynamics, achieving
better performance across downstream tasks.

</details>


### [291] [Quality-Aware Translation Tagging in Multilingual RAG system](https://arxiv.org/abs/2510.23070)
*Hoyeon Moon,Byeolhee Kim,Nikhil Verma*

Main category: cs.CL

TL;DR: QTT-RAG通过评估翻译质量（语义等价性、语法准确性、自然流畅性）并将其作为元数据附加，解决了多语言检索增强生成（mRAG）中翻译质量差的问题，从而提高了低资源语言的问答性能。


<details>
  <summary>Details</summary>
Motivation: 低资源多语言检索增强生成（mRAG）中，从英文文档翻译到查询语言时，翻译质量差会降低响应生成性能。现有方法要么假设翻译质量足够好，要么使用会引入事实失真和幻觉的重写方法。

Method: 提出质量感知翻译标记（QTT-RAG），它明确评估翻译质量的三个维度（语义等价性、语法准确性、自然流畅性），并将这些分数作为元数据附加，而不改变原始内容。

Result: 在XORQA和MKQA两个开放域问答基准上，使用六种不同参数规模的指令调优大语言模型，针对韩语、芬兰语（低资源语言）和中文（高资源语言），QTT-RAG 相较于 CrossRAG 和 DKM-RAG 基线，在保持事实完整性的同时，提高了生成模型根据翻译可靠性做出明智决策的能力。

Conclusion: QTT-RAG 提出了一种有效利用跨语言文档的实用且鲁棒的解决方案，尤其是在缺乏本地语言文档的低资源环境下，能够跨越多个语言领域。

Abstract: Multilingual Retrieval-Augmented Generation (mRAG) often retrieves English
documents and translates them into the query language for low-resource
settings. However, poor translation quality degrades response generation
performance. Existing approaches either assume sufficient translation quality
or utilize the rewriting method, which introduces factual distortion and
hallucinations. To mitigate these problems, we propose Quality-Aware
Translation Tagging in mRAG (QTT-RAG), which explicitly evaluates translation
quality along three dimensions-semantic equivalence, grammatical accuracy, and
naturalness&fluency-and attach these scores as metadata without altering the
original content. We evaluate QTT-RAG against CrossRAG and DKM-RAG as baselines
in two open-domain QA benchmarks (XORQA, MKQA) using six instruction-tuned LLMs
ranging from 2.4B to 14B parameters, covering two low-resource languages
(Korean and Finnish) and one high-resource language (Chinese). QTT-RAG
outperforms the baselines by preserving factual integrity while enabling
generator models to make informed decisions based on translation reliability.
This approach allows for effective usage of cross-lingual documents in
low-resource settings with limited native language documents, offering a
practical and robust solution across multilingual domains.

</details>


### [292] [A Survey on LLM Mid-training](https://arxiv.org/abs/2510.23081)
*Chengying Tu,Xuemiao Zhang,Rongxiang Weng,Rumei Li,Chen Zhang,Yang Bai,Hongfei Yan,Jingang Wang,Xunliang Cai*

Main category: cs.CL

TL;DR: 近期，基础模型在多阶段训练方面取得了显著进展，其中中期训练作为连接预训练和后训练的关键阶段尤为重要。中期训练利用中间数据和计算资源，系统地增强数学、编码、推理和长上下文扩展等特定能力，同时保持基础能力。本调查为大型语言模型（LLMs）的中期训练提供了正式定义，并研究了包括数据管理、训练策略和模型架构优化在内的优化框架。我们分析了主流模型在目标驱动干预下的实现，说明了中期训练如何作为LLM能力逐步发展中一个独特而关键的阶段。通过阐明中期训练的独特贡献，本调查提供了一个全面的分类和可行的见解，以支持LLM发展的未来研究和创新。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在多阶段训练中，尤其是在预训练和后训练之间引入中期训练阶段，对于提升数学、编码、推理和长上下文等特定能力至关重要，同时保留基础能力。

Method: 本调查为LLMs的中期训练提供了正式定义，并研究了包括数据管理、训练策略和模型架构优化在内的优化框架，同时分析了主流模型在目标驱动干预下的实现。

Result: 中期训练被证明是LLM能力逐步发展中一个独特而关键的阶段，通过对数据管理、训练策略和模型架构的优化，可以系统地增强特定能力。

Conclusion: 本调查为LLMs的中期训练提供了全面的分类和可行的见解，阐明了其独特贡献，以支持LLM发展的未来研究和创新。

Abstract: Recent advances in foundation models have highlighted the significant
benefits of multi-stage training, with a particular emphasis on the emergence
of mid-training as a vital stage that bridges pre-training and post-training.
Mid-training is distinguished by its use of intermediate data and computational
resources, systematically enhancing specified capabilities such as mathematics,
coding, reasoning, and long-context extension, while maintaining foundational
competencies. This survey provides a formal definition of mid-training for
large language models (LLMs) and investigates optimization frameworks that
encompass data curation, training strategies, and model architecture
optimization. We analyze mainstream model implementations in the context of
objective-driven interventions, illustrating how mid-training serves as a
distinct and critical stage in the progressive development of LLM capabilities.
By clarifying the unique contributions of mid-training, this survey offers a
comprehensive taxonomy and actionable insights, supporting future research and
innovation in the advancement of LLMs.

</details>


### [293] [MAP4TS: A Multi-Aspect Prompting Framework for Time-Series Forecasting with Large Language Models](https://arxiv.org/abs/2510.23090)
*Suchan Lee,Jihoon Choi,Sohyeon Lee,Minseok Song,Bong-Gyu Jang,Hwanjo Yu,Soyeon Caren Han*

Main category: cs.CL

TL;DR: MAP4TS框架通过整合经典时间序列分析到提示设计中，提升了基于LLM的时间序列预测性能，并在八个多样化数据集上超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的多模态方法忽视了时间序列数据的统计特性和时间依赖性，需要一种能显式整合经典时间序列分析的方法。

Method: 提出MAP4TS框架，包含全局域提示、局部域提示、统计提示和时间提示，结合原始时间序列嵌入，通过跨模态对齐模块生成统一表示，然后由LLM处理并进行预测。

Result: MAP4TS在八个多样化数据集上始终优于最先进的LLM方法；消融研究表明提示感知设计显著提高了性能稳定性；GPT-2骨干模型与结构化提示结合在长期预测任务上优于LLaMA等大型模型。

Conclusion: MAP4TS框架通过显式整合经典时间序列分析，有效提升了LLM在时间序列预测任务上的性能，并在长期预测方面展现出优势。

Abstract: Recent advances have investigated the use of pretrained large language models
(LLMs) for time-series forecasting by aligning numerical inputs with LLM
embedding spaces. However, existing multimodal approaches often overlook the
distinct statistical properties and temporal dependencies that are fundamental
to time-series data. To bridge this gap, we propose MAP4TS, a novel
Multi-Aspect Prompting Framework that explicitly incorporates classical
time-series analysis into the prompt design. Our framework introduces four
specialized prompt components: a Global Domain Prompt that conveys
dataset-level context, a Local Domain Prompt that encodes recent trends and
series-specific behaviors, and a pair of Statistical and Temporal Prompts that
embed handcrafted insights derived from autocorrelation (ACF), partial
autocorrelation (PACF), and Fourier analysis. Multi-Aspect Prompts are combined
with raw time-series embeddings and passed through a cross-modality alignment
module to produce unified representations, which are then processed by an LLM
and projected for final forecasting. Extensive experiments across eight diverse
datasets show that MAP4TS consistently outperforms state-of-the-art LLM-based
methods. Our ablation studies further reveal that prompt-aware designs
significantly enhance performance stability and that GPT-2 backbones, when
paired with structured prompts, outperform larger models like LLaMA in
long-term forecasting tasks.

</details>


### [294] [Leveraging Hierarchical Organization for Medical Multi-document Summarization](https://arxiv.org/abs/2510.23104)
*Yi-Li Hsu,Katelyn X. Mei,Lucy Lu Wang*

Main category: cs.CL

TL;DR: 通过引入分层结构，研究人员改进了医疗多文档摘要（MDS）任务，提高了模型组织和关联信息的能力，生成了比人类专家更受欢迎的摘要。


<details>
  <summary>Details</summary>
Motivation: 评估分层结构是否能提升多文档摘要（MDS）任务中模型组织和关联跨文档信息的能力，并与传统平铺方法进行比较。

Method: 研究了两种引入分层结构的方法，并在三种大型语言模型（LLM）上进行了实验，然后使用自动评估指标、基于模型的评估指标以及领域专家对摘要的偏好、可理解性、清晰度、复杂性、相关性、覆盖度、事实准确性和连贯性进行综合评估。

Result: 与人类撰写的摘要相比，人类专家更偏好模型生成的摘要。分层方法在保持事实准确性、覆盖度和连贯性的同时，提高了人类对摘要的偏好度。GPT-4的模拟评估结果与人类评估结果在更客观的评估方面具有较高的一致性。

Conclusion: 分层结构可以提高模型生成的医疗摘要的清晰度，同时保持内容覆盖度，从而在实践中提高人类对生成摘要的偏好。

Abstract: Medical multi-document summarization (MDS) is a complex task that requires
effectively managing cross-document relationships. This paper investigates
whether incorporating hierarchical structures in the inputs of MDS can improve
a model's ability to organize and contextualize information across documents
compared to traditional flat summarization methods. We investigate two ways of
incorporating hierarchical organization across three large language models
(LLMs), and conduct comprehensive evaluations of the resulting summaries using
automated metrics, model-based metrics, and domain expert evaluation of
preference, understandability, clarity, complexity, relevance, coverage,
factuality, and coherence. Our results show that human experts prefer
model-generated summaries over human-written summaries. Hierarchical approaches
generally preserve factuality, coverage, and coherence of information, while
also increasing human preference for summaries. Additionally, we examine
whether simulated judgments from GPT-4 align with human judgments, finding
higher agreement along more objective evaluation facets. Our findings
demonstrate that hierarchical structures can improve the clarity of medical
summaries generated by models while maintaining content coverage, providing a
practical way to improve human preference for generated summaries.

</details>


### [295] [Flexing in 73 Languages: A Single Small Model for Multilingual Inflection](https://arxiv.org/abs/2510.23114)
*Tomáš Sourada,Jana Straková*

Main category: cs.CL

TL;DR: 提出了一种紧凑、单一模型的多语言词形变化方法，该方法能够处理 73 种语言，并且在大多数语言中优于单语基线模型。


<details>
  <summary>Details</summary>
Motivation: 解决目前缺乏开源、通用、能够处理多种语言（包括捷克语）中未见过单词的多语言形态屈折系统的问 题。

Method: 训练了一个单一模型，该模型联合处理来自 73 种语言的数据，并提出了一个新颖的频率加权、词元不重叠的训练-开发-测试重采样程序，以确保真实的数据划分。

Result: 该模型轻量级、对未见过单词具有鲁棒性，并且在大多数语言中优于单语基线模型。

Conclusion: 多语言建模在词形变化任务中是有效的，并且具有实际优势，因为它简化了部署，无需管理和重新训练数十个单独的单语模型。

Abstract: We present a compact, single-model approach to multilingual inflection, the
task of generating inflected word forms from base lemmas to express grammatical
categories. Our model, trained jointly on data from 73 languages, is
lightweight, robust to unseen words, and outperforms monolingual baselines in
most languages. This demonstrates the effectiveness of multilingual modeling
for inflection and highlights its practical benefits: simplifying deployment by
eliminating the need to manage and retrain dozens of separate monolingual
models. In addition to the standard SIGMORPHON shared task benchmarks, we
evaluate our monolingual and multilingual models on 73 Universal Dependencies
(UD) treebanks, extracting lemma-tag-form triples and their frequency counts.
To ensure realistic data splits, we introduce a novel frequency-weighted,
lemma-disjoint train-dev-test resampling procedure. Our work addresses the lack
of an open-source, general-purpose, multilingual morphological inflection
system capable of handling unseen words across a wide range of languages,
including Czech. All code is publicly released at:
https://github.com/tomsouri/multilingual-inflection.

</details>


### [296] [Beyond Higher Rank: Token-wise Input-Output Projections for Efficient Low-Rank Adaptation](https://arxiv.org/abs/2510.23123)
*Shiwei Li,Xiandi Luo,Haozhao Wang,Xing Tang,Ziqiang Cui,Dugang Liu,Yuhua Li,Xiuqiang He,Ruixuan Li*

Main category: cs.CL

TL;DR: TopLoRA是一种参数高效微调（PEFT）方法，通过动态调整LoRA权重来捕捉token特定的信息，并在多项任务中超越了标准LoRA。


<details>
  <summary>Details</summary>
Motivation: 标准LoRA在微调大型语言模型（LLMs）时，所有输入token共享相同的权重，无法有效捕捉token之间的语义差异。

Method: TopLoRA通过引入一个由输入token生成的对角矩阵 $\Sigma_X$，将LoRA权重表示为 $B\Sigma_X A$，从而实现token级别的权重调整，学习token特定的输入-输出映射。

Result: 实验证明，TopLoRA在多项任务中持续优于LoRA及其变体，表明其在模型微调方面更有效。

Conclusion: TopLoRA通过实现token级别的LoRA权重调整，克服了标准LoRA的局限性，能够更精细地适应模型，并在各项任务中取得更好的性能。

Abstract: Low-rank adaptation (LoRA) is a parameter-efficient fine-tuning (PEFT) method
widely used in large language models (LLMs). LoRA essentially describes the
projection of an input space into a low-dimensional output space, with the
dimensionality determined by the LoRA rank. In standard LoRA, all input tokens
share the same weights and undergo an identical input-output projection. This
limits LoRA's ability to capture token-specific information due to the inherent
semantic differences among tokens. To address this limitation, we propose
Token-wise Projected Low-Rank Adaptation (TopLoRA), which dynamically adjusts
LoRA weights according to the input token, thereby learning token-wise
input-output projections in an end-to-end manner. Formally, the weights of
TopLoRA can be expressed as $B\Sigma_X A$, where $A$ and $B$ are low-rank
matrices (as in standard LoRA), and $\Sigma_X$ is a diagonal matrix generated
from each input token $X$. Notably, TopLoRA does not increase the rank of LoRA
weights but achieves more granular adaptation by learning token-wise LoRA
weights (i.e., token-wise input-output projections). Extensive experiments
across multiple models and datasets demonstrate that TopLoRA consistently
outperforms LoRA and its variants. The code is available at
https://github.com/Leopold1423/toplora-neurips25.

</details>


### [297] [Corpus Frequencies in Morphological Inflection: Do They Matter?](https://arxiv.org/abs/2510.23131)
*Tomáš Sourada,Jana Straková*

Main category: cs.CL

TL;DR: 通过在训练、评估和数据采样中引入词频信息，提高词形屈折任务的性能。


<details>
  <summary>Details</summary>
Motivation: 传统词形屈折方法忽略了词频信息，这与实际应用中的词语使用频率分布不符。因此，需要将词频信息纳入模型开发过程，以更好地反映真实世界的词语使用情况。

Method: 1. 训练-开发-测试划分：结合了不重叠词条的方法（评估泛化能力）和考虑词频的策略（反映训练和测试集中不同词频区间的真实分布）。 2. 评估：补充了标准的类型准确率（所有词条同等对待），引入了词元准确率（更重视高频词，更接近实际文本表现）。 3. 训练数据采样：提出了一种新颖的“频率感知训练”方法，将词频明确纳入采样过程。

Result: 频率感知训练在43种语言中的26种语言上表现优于均匀采样。

Conclusion: 将词频信息融入词形屈折任务的开发过程（包括数据划分、评估和训练采样）可以提高模型的性能，尤其是在反映真实文本的运行表现方面。

Abstract: The traditional approach to morphological inflection (the task of modifying a
base word (lemma) to express grammatical categories) has been, for decades, to
consider lexical entries of lemma-tag-form triples uniformly, lacking any
information about their frequency distribution. However, in production
deployment, one might expect the user inputs to reflect a real-world
distribution of frequencies in natural texts. With future deployment in mind,
we explore the incorporation of corpus frequency information into the task of
morphological inflection along three key dimensions during system development:
(i) for train-dev-test split, we combine a lemma-disjoint approach, which
evaluates the model's generalization capabilities, with a frequency-weighted
strategy to better reflect the realistic distribution of items across different
frequency bands in training and test sets; (ii) for evaluation, we complement
the standard type accuracy (often referred to simply as accuracy), which treats
all items equally regardless of frequency, with token accuracy, which assigns
greater weight to frequent words and better approximates performance on running
text; (iii) for training data sampling, we introduce a method novel in the
context of inflection, frequency-aware training, which explicitly incorporates
word frequency into the sampling process. We show that frequency-aware training
outperforms uniform sampling in 26 out of 43 languages.

</details>


### [298] [ENTP: Enhancing Low-Quality SFT Data via Neural-Symbolic Text Purge-Mix](https://arxiv.org/abs/2510.23160)
*Zile Yang,Ling Li,Na Di,Jinlong Pang,Yao Zhou,Hao Cheng,Bo Han,Jiaheng Wei*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Supervised Fine-Tuning (SFT) adapts pre-trained Large Language Models (LLMs)
to domain-specific instructions by training on a carefully curated subset of
high-quality instruction-response pairs, typically drawn from a larger dataset
that often contains many low-quality or noisy samples. However, existing
quality-first paradigms often overlook valuable signals in discarded
low-quality data and rely on imperfect quality filters. We introduce ENTP
(Enhancing low-quality SFT data via Neural-symbolic Text Purge-Mix), a
framework that revitalizes low-quality corpora through symbolic purification
and neural reconstruction. The symbolic module identifies and prunes noisy
samples based on statistical priors, while the neural component synthesizes
enriched instruction-response pairs by leveraging latent representations and
model knowledge. This neural-symbolic synergy enhances data informativeness and
diversity. Experiments show that ENTP-augmented datasets, constructed
exclusively from low-quality data, outperform 13 established data-selection
baselines across five instruction-following benchmarks, and even surpass
fine-tuning on the full original dataset (approximately 300K examples). Our
results highlight the untapped potential of low-quality data and underscore the
importance of intelligent purification and synthesis for efficient instruction
alignment.

</details>


### [299] [Beyond Direct Generation: A Decomposed Approach to Well-Crafted Screenwriting with LLMs](https://arxiv.org/abs/2510.23163)
*Hang Lei,Shengyi Zong,Zhaoyan Li,Ziren Zhou,Hao Liu*

Main category: cs.CL

TL;DR: LLM 难以直接生成高质量剧本，提出双阶段精炼（DSR）框架，将叙事生成与格式转换分离，并结合混合数据合成解决数据稀疏问题，实验证明 DSR 效果优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 直接的端到端 LLM 生成方法在剧本创作中效果不佳，因为它们需要同时掌握叙事创造和格式遵循两种不同能力，导致生成的剧本缺乏结构完整性和故事深度，无法满足专业需求。

Method: 提出双阶段精炼（DSR）框架：第一阶段将简短大纲转化为丰富的小说风格散文；第二阶段将该叙事精炼为专业格式的剧本。为解决配对大纲到小说的训练数据稀缺问题，采用混合数据合成方法，包括反向合成（将现有剧本分解为结构化输入）和前向合成（利用这些输入生成高质量叙事文本作为训练目标）。

Result: 通过专业编剧进行的盲测评估显示，DSR 相较于 Gemini-2.5-Pro 等强基线模型取得了 75% 的胜率，达到了人类水平的 82.7%。

Conclusion: 分解生成架构结合定制的数据合成方法能够有效地使 LLM 专注于复杂创意领域，实现了高质量剧本的生成。

Abstract: The screenplay serves as the foundation for television production, defining
narrative structure, character development, and dialogue. While Large Language
Models (LLMs) show great potential in creative writing, direct end-to-end
generation approaches often fail to produce well-crafted screenplays. We argue
this failure stems from forcing a single model to simultaneously master two
disparate capabilities: creative narrative construction and rigid format
adherence. The resulting outputs may mimic superficial style but lack the deep
structural integrity and storytelling substance required for professional use.
To enable LLMs to generate high-quality screenplays, we introduce Dual-Stage
Refinement (DSR), a decomposed framework that decouples creative narrative
generation from format conversion. The first stage transforms a brief outline
into rich, novel-style prose. The second stage refines this narrative into a
professionally formatted screenplay. This separation enables the model to
specialize in one distinct capability at each stage. A key challenge in
implementing DSR is the scarcity of paired outline-to-novel training data. We
address this through hybrid data synthesis: reverse synthesis deconstructs
existing screenplays into structured inputs, while forward synthesis leverages
these inputs to generate high-quality narrative texts as training targets.
Blind evaluations by professional screenwriters show that DSR achieves a 75%
win rate against strong baselines like Gemini-2.5-Pro and reaches 82.7% of
human-level performance. Our work demonstrates that decomposed generation
architecture with tailored data synthesis effectively specializes LLMs in
complex creative domains.

</details>


### [300] [MATCH: Task-Driven Code Evaluation through Contrastive Learning](https://arxiv.org/abs/2510.23169)
*Marah Ghoummaid,Vladimir Tchuiev,Ofek Glick,Michal Moschkovitz,Dotan Di Castro*

Main category: cs.CL

TL;DR: AI生成的代码评估是一个难题，现有方法如单元测试成本高，BLEU/ROUGE无法捕捉功能，CodeBERTScore需要参考代码。本文提出MATCH，一种无需参考代码的评估指标，使用对比学习生成代码和任务描述的嵌入，以评估代码实现任务的程度。MATCH在跨语言评估中显示出比现有指标更强的与功能正确性和人类偏好的相关性。


<details>
  <summary>Details</summary>
Motivation: 现有的AI生成代码评估方法存在不足，如单元测试成本高、BLEU/ROUGE无法衡量功能、CodeBERTScore需要参考代码。因此，需要一种无需参考代码且能有效评估代码功能的方法。

Method: 本文提出MATCH，一种基于对比学习的无参考代码评估指标。MATCH为代码和自然语言任务描述生成嵌入，并通过计算相似度来评估代码实现任务的能力。

Result: MATCH在多个编程语言上，与功能正确性和人类偏好的相关性优于现有指标。

Conclusion: MATCH是一种有效且无需参考代码的AI生成代码评估新方法，通过对比学习提高了评估的准确性。

Abstract: AI-based code generation is increasingly prevalent, with GitHub Copilot
estimated to generate 46% of the code on GitHub. Accurately evaluating how well
generated code aligns with developer intent remains a critical challenge.
Traditional evaluation methods, such as unit tests, are often unscalable and
costly. Syntactic similarity metrics (e.g., BLEU, ROUGE) fail to capture code
functionality, and metrics like CodeBERTScore require reference code, which is
not always available. To address the gap in reference-free evaluation, with few
alternatives such as ICE-Score, this paper introduces MATCH, a novel
reference-free metric. MATCH uses Contrastive Learning to generate meaningful
embeddings for code and natural language task descriptions, enabling similarity
scoring that reflects how well generated code implements the task. We show that
MATCH achieves stronger correlations with functional correctness and human
preference than existing metrics across multiple programming languages.

</details>


### [301] [SI-Bench: Benchmarking Social Intelligence of Large Language Models in Human-to-Human Conversations](https://arxiv.org/abs/2510.23182)
*Shuai Huang,Wenxuan Zhao,Jun Gao*

Main category: cs.CL

TL;DR: SI-Bench是一个包含2221个真实社交对话的新基准，用于评估LLM的社交智能。该基准的实验表明，尽管最先进的模型在复杂社交情境下的过程推理能力已超越人类专家，但在回复质量方面仍逊于人类，并且引入的思维链（CoT）推理可能会降低LLM在社交对话任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在真实、复杂的社交互动中的表现是一个重大挑战，现有的方法未能捕捉真实人类对话中的语言风格和关系动态。

Method: 创建了一个名为SI-Bench的新基准，其中包含从社交网络应用程序收集的2,221个真实多轮对话，并手动标注了其中312个对话以评估8种主要模型。

Result: 最先进的模型在复杂社交情境下的过程推理能力已超越人类专家，但在回复质量方面仍落后于人类。思维链（CoT）推理可能会降低LLM在社交对话任务中的性能。

Conclusion: SI-Bench为评估LLM的社交智能提供了一个新的、基于真实数据的基准。实验结果表明，尽管LLM在某些方面表现出色，但在社交对话的回复质量和CoT推理的应用方面仍有改进空间。

Abstract: As large language models (LLMs) develop anthropomorphic abilities, they are
increasingly being deployed as autonomous agents to interact with humans.
However, evaluating their performance in realistic and complex social
interactions remains a significant challenge. Most previous research built
datasets through simulated agent-to-agent interactions, which fails to capture
the authentic linguistic styles and relational dynamics found in real human
conversations. To address this gap, we introduce SI-Bench, a novel benchmark
designed to evaluate aspects of social intelligence in LLMs. Grounded in broad
social science theories, SI-Bench contains 2,221 authentic multi-turn dialogues
collected from a social networking application. We further selected a subset of
312 dialogues for manual annotation across 8 major models. The experiments show
that SOTA models have surpassed the human expert in process reasoning under
complex social situations, yet they still fall behind humans in reply quality.
Moreover, introducing Chain-of-Thought (CoT) reasoning may degrade the
performance of LLMs in social dialogue tasks. All datasets are openly available
at https://github.com/SI-Bench/SI-Bench.git.

</details>


### [302] [DREaM: Drug-Drug Relation Extraction via Transfer Learning Method](https://arxiv.org/abs/2510.23189)
*Ali Fata,Hossein Rahmani,Parinaz Soltanzadeh,Amirhossein Derakhshan,Behrouz Minaei Bidgoli*

Main category: cs.CL

TL;DR: 该研究提出了DREAM方法，利用迁移学习和大型语言模型来提取和验证药物-药物关系，构建药物关系本体，并分析了该方法在处理医学领域歧义性方面的能力。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏专门用于药物-药物关系提取的数据集，因此需要利用迁移学习来应用机器学习方法。本研究旨在解决这一数据稀疏性问题。

Method: 首先，使用一个预训练的关系提取模型来发现实体之间的关系。然后，将此模型应用于医学文本语料库，构建药物关系的本体。最后，使用大型语言模型对提取的关系进行验证。

Result: 大型语言模型在PubMed摘要子集上对提取出的71个关系表示同意。定性分析表明，该方法能够揭示医学领域的歧义性。

Conclusion: DREAM方法通过迁移学习和大型语言模型验证，有效地提取和构建了药物关系本体，并揭示了关系提取的挑战。

Abstract: Relation extraction between drugs plays a crucial role in identifying drug
drug interactions and predicting side effects. The advancement of machine
learning methods in relation extraction, along with the development of large
medical text databases, has enabled the low cost extraction of such relations
compared to other approaches that typically require expert knowledge. However,
to the best of our knowledge, there are limited datasets specifically designed
for drug drug relation extraction currently available. Therefore, employing
transfer learning becomes necessary to apply machine learning methods in this
domain. In this study, we propose DREAM, a method that first employs a trained
relation extraction model to discover relations between entities and then
applies this model to a corpus of medical texts to construct an ontology of
drug relationships. The extracted relations are subsequently validated using a
large language model. Quantitative results indicate that the LLM agreed with 71
of the relations extracted from a subset of PubMed abstracts. Furthermore, our
qualitative analysis indicates that this approach can uncover ambiguities in
the medical domain, highlighting the challenges inherent in relation extraction
in this field.

</details>


### [303] [Process Reward Models for Sentence-Level Verification of LVLM Radiology Reports](https://arxiv.org/abs/2510.23217)
*Alois Thomas,Maya Varma,Jean-Benoit Delbrouck,Curtis P. Langlotz*

Main category: cs.CL

TL;DR: 大型视觉语言模型（LVLM）在自动生成放射科报告方面潜力巨大，但它们常产生危险的临床幻觉。现有方法缺乏句子级粒度或跨模型泛化能力。本研究提出了一种新颖的句子级过程奖励模型（PRM），用于预测生成句子的事实准确性。该模型在MIMIC-CXR数据集上进行了弱监督微调，一个轻量级的0.5B参数PRM在 Matthews Correlation Coefficient 和 AUROC 等指标上优于现有方法，并能很好地泛化到未见过的新LVLM。PRM还能有效过滤低质量报告，提高F1-CheXbert分数。此外，在MIMIC-CXR测试集上，PRM引导的加权最佳N项选择过程在F1-CheXbert和BERTScore等临床指标上显示出显著改进。


<details>
  <summary>Details</summary>
Motivation: 解决大型视觉语言模型（LVLM）在生成放射科报告时出现的临床关键幻觉问题，并克服现有幻觉检测方法在句子级粒度、泛化能力和易用性方面的不足。

Method: 提出并实现了一个句子级的过程奖励模型（PRM），该模型能够预测生成报告中每个句子的事实准确性。PRM在MIMIC-CXR数据集上使用弱监督标签进行微调，并评估其在不同LVLM上的表现以及作为过滤和选择机制的有效性。

Result: 在MIMIC-CXR数据集上，0.5B参数的PRM在 Matthews Correlation Coefficient 和 AUROC 指标上，相比于强基线方法分别提高了7.5%和1.8%。PRM能够很好地泛化到未知的LVLM。PRM分数能够有效过滤低质量报告，将F1-CheXbert分数提高4.5%。在MIMIC-CXR测试集上，PRM引导的加权最佳N项选择过程将F1-CheXbert分数提高了7.4%，BERTScore提高了0.6%。

Conclusion: 轻量级、上下文感知的PRM可以作为一种模型无关的安全层，用于临床LVLM，且无需访问模型的内部激活。

Abstract: Automating radiology report generation with Large Vision-Language Models
(LVLMs) holds great potential, yet these models often produce clinically
critical hallucinations, posing serious risks. Existing hallucination detection
methods frequently lack the necessary sentence-level granularity or robust
generalization across different LVLM generators. We introduce a novel approach:
a sentence-level Process Reward Model (PRM) adapted for this vision-language
task. Our PRM predicts the factual correctness of each generated sentence,
conditioned on clinical context and preceding text. When fine-tuned on
MIMIC-CXR with weakly-supervised labels, a lightweight 0.5B-parameter PRM
outperforms existing verification techniques, demonstrating, for instance,
relative improvements of 7.5% in Matthews Correlation Coefficient and 1.8% in
AUROC over strong white-box baselines on outputs from one LVLM. Unlike methods
reliant on internal model states, our PRM demonstrates strong generalization to
an unseen LVLM. We further show its practical utility: PRM scores effectively
filter low-quality reports, improving F1-CheXbert scores by 4.5% (when
discarding the worst 10% of reports). Moreover, when guiding a novel weighted
best-of-N selection process on the MIMIC-CXR test set, our PRM show relative
improvements in clinical metrics of 7.4% for F1-CheXbert and 0.6% for
BERTScore. These results demonstrate that a lightweight, context-aware PRM
provides a model-agnostic safety layer for clinical LVLMs without access to
internal activations

</details>


### [304] [Are ASR foundation models generalized enough to capture features of regional dialects for low-resource languages?](https://arxiv.org/abs/2510.23252)
*Tawsif Tashwar Dipto,Azmol Hossain,Rubayet Sabbir Faruque,Md. Rezuwan Hassan,Kanij Fatema,Tanmoy Shome,Ruwad Naswan,Md. Foriduzzaman Zihad,Mohaymen Ul Anam,Nazia Tasnim,Hasan Mahmud,Md Kamrul Hasan,Md. Mehedi Hasan Shawon,Farig Sadeque,Tahsin Reasat*

Main category: cs.CL

TL;DR: 该研究提出了一个包含78小时标注数据的孟加拉语语音转录（STT）语料库Ben-10，并证明了方言变异对自动语音识别（ASR）的负面影响，提出方言特定模型训练是解决此问题的有效途径。


<details>
  <summary>Details</summary>
Motivation: 调查方言变异对自动语音识别（ASR）的影响，并为低资源语言和区域方言的ASR研究提供资源。

Method: 开发了一个包含78小时标注数据的孟加拉语语音转录（STT）语料库Ben-10，并从语言学和数据驱动的角度进行了分析，验证了现有ASR模型在处理区域方言时的不足。

Result: 研究表明，现有的语音基础模型在处理区域方言ASR时表现不佳，无论是在零样本学习还是微调设置下。方言特定的模型训练能够缓解这个问题。Ben-10语料库也可以作为ASR算法在资源受限情况下的离群（OOD）评估资源。

Conclusion: 方言变异对ASR模型提出了重大挑战，但通过方言特定的模型训练可以有效解决。Ben-10语料库为进一步研究提供了宝贵的资源。

Abstract: Conventional research on speech recognition modeling relies on the canonical
form for most low-resource languages while automatic speech recognition (ASR)
for regional dialects is treated as a fine-tuning task. To investigate the
effects of dialectal variations on ASR we develop a 78-hour annotated Bengali
Speech-to-Text (STT) corpus named Ben-10. Investigation from linguistic and
data-driven perspectives shows that speech foundation models struggle heavily
in regional dialect ASR, both in zero-shot and fine-tuned settings. We observe
that all deep learning methods struggle to model speech data under dialectal
variations but dialect specific model training alleviates the issue. Our
dataset also serves as a out of-distribution (OOD) resource for ASR modeling
under constrained resources in ASR algorithms. The dataset and code developed
for this project are publicly available

</details>


### [305] [Mubeen AI: A Specialized Arabic Language Model for Heritage Preservation and User Intent Understanding](https://arxiv.org/abs/2510.23271)
*Mohammed Aljafari,Ismail Alturki,Ahmed Mori,Yehya Kadumi*

Main category: cs.CL

TL;DR: Mubeen是一个专为阿拉伯语语言、伊斯兰研究和文化遗产设计的专有阿拉伯语大模型，解决了“实用性差距危机”，能够根据用户意图提供准确、相关的答案，并与沙特2030愿景保持一致。


<details>
  <summary>Details</summary>
Motivation: Mubeen旨在解决当前阿拉伯语模型在理解用户意图和提供真正有用的答案方面存在的不足，即“实用性差距危机”，并促进文化和知识的传播，以支持沙特2030愿景。

Method: Mubeen通过一个专有的阿拉伯语OCR引擎，在一个包含古代手稿在内的广泛的阿拉伯语真实语料库上进行训练，并采用深度语言工程框架和实践闭合架构进行优化，结合了深度文化专业知识和多学科专家模块。

Result: Mubeen能够精确理解古典文本、当代写作和地区方言，有效识别用户意图并提供准确、符合语境的答案，解决了因答案不实用而导致用户反复追问的问题，并实现了从信息库到决策指导的转变。

Conclusion: Mubeen通过其创新的架构和对原生阿拉伯语数据的深度优化，克服了现有阿拉伯语模型的局限性，提供了文化真实且实用的解决方案，使其成为一个有价值的工具，尤其是在文化遗产保护和支持沙特2030愿景方面。

Abstract: Mubeen is a proprietary Arabic language model developed by MASARAT SA,
optimized for deep understanding of Arabic linguistics, Islamic studies, and
cultural heritage. Trained on an extensive collection of authentic Arabic
sources significantly expanded by digitizing historical manuscripts via a
proprietary Arabic OCR engine, the model incorporates seminal scholarly works
in linguistics, jurisprudence, hadith, and Quranic exegesis, alongside
thousands of academic theses and peer-reviewed research papers. Conditioned
through a deep linguistic engineering framework, Mubeen masters not just the
meaning but the eloquence of Arabic, enabling precise understanding across
classical texts, contemporary writing, and regional dialects with focus on
comprehending user intent and delivering accurate, contextually relevant
responses. Unlike other Arabic models relying on translated English data that
often fail in intent detection or retrieval-augmented generation (RAG), Mubeen
uses native Arabic sources to ensure cultural authenticity and accuracy. Its
core innovation is the Practical Closure Architecture, designed to solve the
"Utility Gap Crisis" where factually correct answers fail to resolve users'
core needs, forcing them into frustrating cycles of re-prompting. By
prioritizing clarity and decisive guidance, Mubeen transforms from an
information repository into a decisive guide, aligning with Saudi Vision 2030.
The model's architecture combines deep heritage specialization with
multi-disciplinary expert modules, enabling robust performance across both
cultural preservation and general knowledge domains.

</details>


### [306] [Code Aesthetics with Agentic Reward Feedback](https://arxiv.org/abs/2510.23272)
*Bang Xiao,Lingjie Jiang,Shaohan Huang,Tengchao Lv,Yupan Huang,Xun Wu,Lei Cui,Furu Wei*

Main category: cs.CL

TL;DR: LLM在编程方面表现出色，但在视觉导向的代码任务中效果不佳。本文提出了一个新流程来改进LLM生成代码的美观度，包括构建数据集AesCode-358K，提出多智能体评估系统（agentic reward feedback）以及GRPO-AR优化算法，并开发了基准测试OpenDesign。实验证明，该方法显著提高了代码美观度，并且AesCoder-4B模型在性能上超越了GPT-4o和GPT-4.1。


<details>
  <summary>Details</summary>
Motivation: LLM在视觉导向的代码任务中生成的代码在美观度方面存在不足，需要改进。

Method: 1. 构建AesCode-358K数据集。
2. 提出agentic reward feedback系统，评估代码的可执行性、静态美观度和交互美观度。
3. 开发GRPO-AR算法，结合监督微调和强化学习进行优化。
4. 引入OpenDesign基准测试。

Result: AesCoder-4B模型性能超越GPT-4o和GPT-4.1，并可与参数量达480B-685B的开源模型相媲美。该方法在OpenDesign和PandasPlotBench等基准测试上均有显著提升。

Conclusion: 结合AesCode-358K上的监督微调和基于agentic reward feedback的强化学习，能够有效提升LLM生成代码的美观度和性能。

Abstract: Large Language Models (LLMs) have become valuable assistants for developers
in code-related tasks. While LLMs excel at traditional programming tasks such
as code generation and bug fixing, they struggle with visually-oriented coding
tasks, often producing suboptimal aesthetics. In this paper, we introduce a new
pipeline to enhance the aesthetic quality of LLM-generated code. We first
construct AesCode-358K, a large-scale instruction-tuning dataset focused on
code aesthetics. Next, we propose agentic reward feedback, a multi-agent system
that evaluates executability, static aesthetics, and interactive aesthetics.
Building on this, we develop GRPO-AR, which integrates these signals into the
GRPO algorithm for joint optimization of functionality and code aesthetics.
Finally, we develop OpenDesign, a benchmark for assessing code aesthetics.
Experimental results show that combining supervised fine-tuning on AesCode-358K
with reinforcement learning using agentic reward feedback significantly
improves performance on OpenDesign and also enhances results on existing
benchmarks such as PandasPlotBench. Notably, our AesCoder-4B surpasses GPT-4o
and GPT-4.1, and achieves performance comparable to large open-source models
with 480B-685B parameters, underscoring the effectiveness of our approach.

</details>


### [307] [A Cocktail-Party Benchmark: Multi-Modal dataset and Comparative Evaluation Results](https://arxiv.org/abs/2510.23276)
*Thai-Binh Nguyen,Katerina Zmolikova,Pingchuan Ma,Ngoc Quan Pham,Christian Fuegen,Alexander Waibel*

Main category: cs.CL

TL;DR: MCoRec 任务旨在解决单房间内的多人对话重叠问题，利用音视频和上下文线索，实现对话转录和说话人聚类。


<details>
  <summary>Details</summary>
Motivation: 解决鸡尾酒会问题，即在单个房间内有多人同时说话的场景，利用音频、视觉和上下文线索来识别和区分不同的对话。

Method: 结合音频和视觉信息，对多人对话进行转录和聚类，以识别“谁在何时、说了什么、与谁交谈”。

Result: 仅使用音频的基线系统词错误率超过100%，而结合视觉线索的系统则有50%的显著改进，证明了多模态的重要性。

Conclusion: MCoRec 任务的提出是为了解决多人重叠对话的挑战，并展示了结合多模态线索在提高识别和聚类准确性方面的潜力。

Abstract: We introduce the task of Multi-Modal Context-Aware Recognition (MCoRec) in
the ninth CHiME Challenge, which addresses the cocktail-party problem of
overlapping conversations in a single-room setting using audio, visual, and
contextual cues. MCoRec captures natural multi-party conversations where the
recordings focus on unscripted, casual group chats, leading to extreme speech
overlap of up to 100% and highly fragmented conversational turns. The task
requires systems to answer the question "Who speaks when, what, and with whom?"
by jointly transcribing each speaker's speech and clustering them into their
respective conversations from audio-visual recordings. Audio-only baselines
exceed 100% word error rate, whereas incorporating visual cues yields
substantial 50% improvements, highlighting the importance of multi-modality. In
this manuscript, we present the motivation behind the task, outline the data
collection process, and report the baseline systems developed for the MCoRec.

</details>


### [308] [DCMM-SQL: Automated Data-Centric Pipeline and Multi-Model Collaboration Training for Text-to-SQL Model](https://arxiv.org/abs/2510.23284)
*Yuanzhen Xie,Liu Ye,Jiqun Chu,Mochi Gao,Hehuan Liu,Yunzhi Tan,Bo Hu,Zang Li*

Main category: cs.CL

TL;DR: 本研究提出了一种全自动化的数据中心化流水线，用于提高 Text-to-SQL 任务的性能，包括数据修复和错误数据增强，并结合多模型协作和集成策略，在轻量级 Text-to-SQL 模型中取得了领先的成果。


<details>
  <summary>Details</summary>
Motivation: 尽管 ChatGPT 推动了 Text-to-SQL 任务的改进，但数据中心化策略在该领域的影响尚未得到充分探索。

Method: 设计了一个全自动化的数据中心化流水线，包含自适应数据修复（自动查找和修复训练数据中的错误）和错误数据增强（增强初始模型预测的错误数据）。提出了一种多模型协作训练模式，使多个模型能够利用不同的增强数据，发挥各自优势并相互补充。最后，采用集成策略整合多个模型的能力来解决选择题，以提高 Text-to-SQL 任务的准确性。

Result: 实验结果和消融研究证明了数据中心化流水线和多模型交互迭代策略的有效性，在轻量级 Text-to-SQL 模型（70B 以下）中取得了第一名。

Conclusion: 数据中心化流水线和多模型协作策略能够有效提升 Text-to-SQL 任务的性能，特别是在轻量级模型方面。

Abstract: Text-to-SQL tasks have gained attractive improvements since the release of
ChatGPT. Among them, agent-based frameworks have been widely used in this
field. However, the impact of data-centric strategies on text-to-SQL tasks has
rarely been explored. In this paper, we systemically design a fully automated
data-centric pipeline for text-to-SQL tasks, including \emph{adaptive data
repair}, which can automatically find and fix errors in the training dataset;
and \emph{error data augmentation}, where we specifically diffuse and enhance
erroneous data predicted by the initially trained models. Meanwhile, we propose
a Multi-Model collaboration training schema, aiming to train multiple models
with different augmented data, enabling them to possess distinct capabilities
and work together to complement each other, because it has been found that the
capability of a single fine-tuned model is very limited. Furthermore, we
utilize an ensemble strategy to integrate the capabilities of multiple models
to solve a multiple-choice question, aiming to further improve the accuracy of
text-to-SQL tasks. The experiment results and ablation study have demonstrated
the effectiveness of data-centric pipeline and Multi-Model(MM) interactive
iterative strategies, achieving first place in lightweight text-to-SQL models
(within 70B).

</details>


### [309] [Arabic Little STT: Arabic Children Speech Recognition Dataset](https://arxiv.org/abs/2510.23319)
*Mouhand Alkadri,Dania Desouki,Khloud Al Jallad*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The performance of Artificial Intelligence (AI) systems fundamentally depends
on high-quality training data. However, low-resource languages like Arabic
suffer from severe data scarcity. Moreover, the absence of child-specific
speech corpora is an essential gap that poses significant challenges. To
address this gap, we present our created dataset, Arabic Little STT, a dataset
of Levantine Arabic child speech recorded in classrooms, containing 355
utterances from 288 children (ages 6 - 13). We further conduct a systematic
assessment of Whisper, a state-of-the-art automatic speech recognition (ASR)
model, on this dataset and compare its performance with adult Arabic
benchmarks. Our evaluation across eight Whisper variants reveals that even the
best-performing model (Large_v3) struggles significantly, achieving a 0.66 word
error rate (WER) on child speech, starkly contrasting with its sub 0.20 WER on
adult datasets. These results align with other research on English speech.
Results highlight the critical need for dedicated child speech benchmarks and
inclusive training data in ASR development. Emphasizing that such data must be
governed by strict ethical and privacy frameworks to protect sensitive child
information. We hope that this study provides an initial step for future work
on equitable speech technologies for Arabic-speaking children. We hope that our
publicly available dataset enrich the children's demographic representation in
ASR datasets.

</details>


### [310] [Adaptive Blockwise Search: Inference-Time Alignment for Large Language Models](https://arxiv.org/abs/2510.23334)
*Mohammad Atif Quamar,Mohammad Areeb,Nishant Sharma,Ananth Shreekumar,Jonathan Rosenthal,Muslum Ozgur Ozmen,Mikhail Kuznetsov,Z. Berkay Celik*

Main category: cs.CL

TL;DR: AdaSearch 是一种新的块状搜索策略，通过自适应地为关键初始标记分配计算预算来改进 LLM 对齐，在各种任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: LLM 对齐是一个重大挑战。虽然推理时的方法比微调更灵活，但它们通常计算成本高昂且效果不佳。该研究认为，在许多对齐任务中，响应的初始标记至关重要。

Method: 提出了一种名为 AdaSearch 的新型块状搜索策略，该策略采用基于采样计划的自适应计算分配，优先处理响应中的关键初始标记。还提出了 AdaBeam，这是 AdaSearch 在树搜索中的对应方法。

Result: AdaSearch 在八个大型语言模型上的评估表明，与最佳的 N 个模型和微调基线相比，AdaSearch 的性能有所提高。在无害生成、受控情感生成和数学推理任务中，与最佳的 N 个模型相比，AdaSearch 的胜率提高了 10% 以上。

Conclusion: AdaSearch 通过优先处理 LLM 生成响应中的关键初始标记，在 LLM 对齐方面取得了显著的进步，从而在计算效率和性能方面均优于现有方法。

Abstract: LLM alignment remains a critical challenge. Inference-time methods provide a
flexible alternative to fine-tuning, but their uniform computational effort
often yields suboptimal alignment. We hypothesize that for many alignment
tasks, the initial tokens of a response are disproportionately more critical.
To leverage this principle, we introduce AdaSearch, a novel blockwise search
strategy. It adaptively allocates a fixed computational budget using a sampling
schedule, focusing search effort on these critical tokens. We apply AdaSearch
to sequential decoding and introduce its tree-search counterpart, AdaBeam. Our
comprehensive evaluation across eight LLMs demonstrates that AdaSearch
outperforms strong Best-of-N and fine-tuning baselines. Specifically, win-rates
improve by over 10% for harmlessness generation, controlled sentiment
generation, and for mathematical reasoning tasks relative to Best-of-N.

</details>


### [311] [BaZi-Based Character Simulation Benchmark: Evaluating AI on Temporal and Persona Reasoning](https://arxiv.org/abs/2510.23337)
*Siyuan Zheng,Pai Liu,Xi Chen,Jizheng Dong,Sihan Jia*

Main category: cs.CL

TL;DR: 该研究提出了首个基于八字（BaZi）的虚拟人物个性生成系统，结合符号推理和大型语言模型（LLMs），实现了更具动态性和精细度的人物生成，并在准确性上超越了现有主流模型。


<details>
  <summary>Details</summary>
Motivation: 当前生成人性化虚拟人物的方法依赖于标注数据或手工提示，难以扩展并生成逼真、情境连贯的人物。本研究旨在解决这一难题，通过结合中国传统命理学八字来生成更真实、动态的人物个性。

Method: 提出了一种名为BaZi-LLM的系统，该系统整合了符号推理（基于八字）和大型语言模型（LLMs）。该系统使用了一个新创建的、包含真实人类生活事件（分为财富、健康、亲属、事业和关系）的八字问答数据集来进行人物个性推理。

Result: 与DeepSeek-v3和GPT-5-mini等主流LLMs相比，BaZi-LLM在人物个性生成任务上准确率提高了30.3%-62.6%。当输入错误的八字信息时，模型的准确率会下降20%-45%，这表明了该模型对准确的八字信息的依赖性以及符号-LLM整合的潜力。

Conclusion: 将中国传统命理学八字与大型语言模型相结合，可以实现更真实、更具动态性和精细度的人物个性生成。这种融合方法在准确性上优于现有技术，并证明了文化接地符号推理在虚拟人物模拟中的有效性。

Abstract: Human-like virtual characters are crucial for games, storytelling, and
virtual reality, yet current methods rely heavily on annotated data or
handcrafted persona prompts, making it difficult to scale up and generate
realistic, contextually coherent personas. We create the first QA dataset for
BaZi-based persona reasoning, where real human experiences categorized into
wealth, health, kinship, career, and relationships are represented as
life-event questions and answers. Furthermore, we propose the first BaZi-LLM
system that integrates symbolic reasoning with large language models to
generate temporally dynamic and fine-grained virtual personas. Compared with
mainstream LLMs such as DeepSeek-v3 and GPT-5-mini, our method achieves a
30.3%-62.6% accuracy improvement. In addition, when incorrect BaZi information
is used, our model's accuracy drops by 20%-45%, showing the potential of
culturally grounded symbolic-LLM integration for realistic character
simulation.

</details>


### [312] [LightKGG: Simple and Efficient Knowledge Graph Generation from Textual Data](https://arxiv.org/abs/2510.23341)
*Teng Lin*

Main category: cs.CL

TL;DR: 本研究提出LightKGG框架，利用小型语言模型(SLM)高效提取知识图谱(KG)，解决现有方法对高质量KG的依赖和计算资源需求大的问题。


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱提取方法依赖易出错的模式匹配或计算资源密集的大型语言模型(LLM)，限制了低资源环境的可及性。高质量知识图谱的稀缺性是下游人工智能应用的瓶颈。

Method: LightKGG框架通过两种关键技术创新实现：1. 上下文集成图提取，将上下文信息与节点和边整合到统一的图结构中；2. 拓扑增强关系推理，利用提取图的固有拓扑结构进行关系推理。

Result: 该方法能够在有限的硬件资源下实现准确的知识图谱构建。

Conclusion: LightKGG框架通过使用小型语言模型(SLM)和创新的提取与推理技术，实现了在计算资源有限的情况下高效准确地构建知识图谱，解决了实际部署中的挑战，并为结构化自然语言处理任务优化SLM效率提供了科学方法。

Abstract: The scarcity of high-quality knowledge graphs (KGs) remains a critical
bottleneck for downstream AI applications, as existing extraction methods rely
heavily on error-prone pattern-matching techniques or resource-intensive large
language models (LLMs). While recent tools leverage LLMs to generate KGs, their
computational demands limit accessibility for low-resource environments. Our
paper introduces LightKGG, a novel framework that enables efficient KG
extraction from textual data using small-scale language models (SLMs) through
two key technical innovations: (1) Context-integrated Graph extraction
integrates contextual information with nodes and edges into a unified graph
structure, reducing the reliance on complex semantic processing while
maintaining more key information; (2) Topology-enhanced relationship inference
leverages the inherent topology of the extracted graph to efficiently infer
relationships, enabling relationship discovery without relying on complex
language understanding capabilities of LLMs. By enabling accurate KG
construction with minimal hardware requirements, this work bridges the gap
between automated knowledge extraction and practical deployment scenarios while
introducing scientifically rigorous methods for optimizing SLM efficiency in
structured NLP tasks.

</details>


### [313] [How AI Forecasts AI Jobs: Benchmarking LLM Predictions of Labor Market Changes](https://arxiv.org/abs/2510.23358)
*Sheri Osborn,Rohit Valecha,H. Raghav Rao,Dan Sass,Anthony Rios*

Main category: cs.CL

TL;DR: 本文提出了一个基准，用于评估大型语言模型（LLMs）预测劳动力市场变化的准确性，特别是受人工智能影响的职业。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏系统性预测人工智能对就业影响的工具，本文旨在评估LLMs在此方面的能力。

Method: 结合了美国就业帖子指数和全球AI采用导致的职业变化预测数据集，设计了具有时间分割的预测任务，并使用结构化任务提示、角色扮演提示和混合方法评估了LLMs的预测能力。

Result: 结构化任务提示提高了预测稳定性，角色扮演提示在短期趋势方面表现更好，但模型在不同行业和预测时间尺度上的表现差异很大。

Conclusion: 发布该基准以促进未来在劳动力预测、提示设计和基于LLM的经济推理方面的研究，并为研究AI作为劳动力市场预测工具的潜力和局限性提供了一个可重复的测试平台。

Abstract: Artificial intelligence is reshaping labor markets, yet we lack tools to
systematically forecast its effects on employment. This paper introduces a
benchmark for evaluating how well large language models (LLMs) can anticipate
changes in job demand, especially in occupations affected by AI. Existing
research has shown that LLMs can extract sentiment, summarize economic reports,
and emulate forecaster behavior, but little work has assessed their use for
forward-looking labor prediction. Our benchmark combines two complementary
datasets: a high-frequency index of sector-level job postings in the United
States, and a global dataset of projected occupational changes due to AI
adoption. We format these data into forecasting tasks with clear temporal
splits, minimizing the risk of information leakage. We then evaluate LLMs using
multiple prompting strategies, comparing task-scaffolded, persona-driven, and
hybrid approaches across model families. We assess both quantitative accuracy
and qualitative consistency over time. Results show that structured task
prompts consistently improve forecast stability, while persona prompts offer
advantages on short-term trends. However, performance varies significantly
across sectors and horizons, highlighting the need for domain-aware prompting
and rigorous evaluation protocols. By releasing our benchmark, we aim to
support future research on labor forecasting, prompt design, and LLM-based
economic reasoning. This work contributes to a growing body of research on how
LLMs interact with real-world economic data, and provides a reproducible
testbed for studying the limits and opportunities of AI as a forecasting tool
in the context of labor markets.

</details>


### [314] [Detecting Religious Language in Climate Discourse](https://arxiv.org/abs/2510.23395)
*Evy Beijen,Pien Pieterse,Yusuf Çelik,Willem Th. van Peursen,Sandjai Bhulai,Meike Morren*

Main category: cs.CL

TL;DR: 尽管在看似世俗的环境活动和气候变化辩论中，宗教语言仍然渗透到当代的讨论中，但本研究探讨了宗教语言在气候相关文本中的显性和隐性形式。研究引入了基于规则的模型和大型语言模型（LLMs）的混合方法，以检测这些文本中的宗教语言。结果表明，基于规则的方法比 LLMs 标记了更多的句子，这突显了计算上检测宗教语言的方法挑战以及仅通过词汇或通过背景含义来定义宗教语言的更广泛的争论。


<details>
  <summary>Details</summary>
Motivation: 研究目的是探讨宗教语言如何渗透到气候变化等世俗领域的论述中，并比较不同方法检测宗教语言的能力。

Method: 本研究采用了基于规则的模型（使用源自生态神学文献的宗教术语层次树）和大型语言模型（LLMs）的零样本方法。

Result: 研究结果显示，基于规则的方法比 LLMs 标记了更多的句子，表明在检测宗教语言方面存在方法上的差异和挑战。

Conclusion: 本研究不仅揭示了计算检测宗教语言的方法挑战，还强调了在定义宗教语言时，仅考虑词汇或结合背景含义的争论。研究为数字人文研究提供了见解，展示了分析神圣语言在气候论述中持久性的潜力与局限性。

Abstract: Religious language continues to permeate contemporary discourse, even in
ostensibly secular domains such as environmental activism and climate change
debates. This paper investigates how explicit and implicit forms of religious
language appear in climate-related texts produced by secular and religious
nongovernmental organizations (NGOs). We introduce a dual methodological
approach: a rule-based model using a hierarchical tree of religious terms
derived from ecotheology literature, and large language models (LLMs) operating
in a zero-shot setting. Using a dataset of more than 880,000 sentences, we
compare how these methods detect religious language and analyze points of
agreement and divergence. The results show that the rule-based method
consistently labels more sentences as religious than LLMs. These findings
highlight not only the methodological challenges of computationally detecting
religious language but also the broader tension over whether religious language
should be defined by vocabulary alone or by contextual meaning. This study
contributes to digital methods in religious studies by demonstrating both the
potential and the limitations of approaches for analyzing how the sacred
persists in climate discourse.

</details>


### [315] [EMTSF:Extraordinary Mixture of SOTA Models for Time Series Forecasting](https://arxiv.org/abs/2510.23396)
*Musleh Alharthi,Kaleel Mahmood,Sarosh Patel,Ausif Mahmood*

Main category: cs.CL

TL;DR: Transformer在时间序列预测（TSF）中取得了巨大成功，但最近的研究对其有效性提出了质疑。本研究提出了一个基于Transformer的混合专家（MoE）框架，结合了多种先进的TSF模型，并在标准基准测试中取得了优于现有所有模型（包括其他MoE框架）的性能。


<details>
  <summary>Details</summary>
Motivation: 时间序列预测（TSF）领域在Transformer模型的有效性方面存在争议。虽然Transformer模型取得了巨大成功，但近期研究表明简单的线性模型甚至可能优于它们。此外，将大型语言模型（LLM）应用于TSF也受到了挑战，后续研究发现移除LLM组件反而能提升性能。这表明需要新的方法来解决TSF数据中近期数据偏好和不可预测事件的挑战。

Method: 提出一个基于Transformer的混合专家（MoE）框架。该框架整合了多种先进的TSF模型，包括xLSTM、增强线性模型、PatchTST和minGRU等。这些互补且多样化的模型通过一个基于Transformer的MoE门控网络进行集成。

Result: 该MoE框架在标准基准测试中超越了所有现有的TSF模型，包括最新的基于MoE框架的方法。

Conclusion: 提出的Transformer-based MoE框架在时间序列预测任务中取得了最先进的性能，解决了现有方法中的一些挑战。

Abstract: The immense success of the Transformer architecture
  in Natural Language Processing has led to its adoption in Time Se ries
Forecasting (TSF), where superior performance has been shown.
  However, a recent important paper questioned their effectiveness by
  demonstrating that a simple single layer linear model outperforms
  Transformer-based models. This was soon shown to be not as valid,
  by a better transformer-based model termed PatchTST. More re cently, TimeLLM
demonstrated even better results by repurposing a
  Large Language Model (LLM) for the TSF domain. Again, a follow
  up paper challenged this by demonstrating that removing the LLM
  component or replacing it with a basic attention layer in fact yields
  better performance. One of the challenges in forecasting is the fact
  that TSF data favors the more recent past, and is sometimes subject
  to unpredictable events. Based upon these recent insights in TSF, we
  propose a strong Mixture of Experts (MoE) framework. Our method
  combines the state-of-the-art (SOTA) models including xLSTM, en hanced
Linear, PatchTST, and minGRU, among others. This set of
  complimentary and diverse models for TSF are integrated in a Trans former
based MoE gating network. Our proposed model outperforms
  all existing TSF models on standard benchmarks, surpassing even the
  latest approaches based on MoE frameworks.

</details>


### [316] [Omni-Reward: Towards Generalist Omni-Modal Reward Modeling with Free-Form Preferences](https://arxiv.org/abs/2510.23451)
*Zhuoran Jin,Hongbang Yuan,Kejian Zhu,Jiachun Li,Pengfei Cao,Yubo Chen,Kang Liu,Jun Zhao*

Main category: cs.CL

TL;DR: 该论文提出Omni-Reward，一个支持自由形式偏好的全模态奖励模型，解决了模态不平衡和偏好僵化问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有奖励模型在模态覆盖（主要集中在文本和图像）和偏好表达（固定二元偏好对无法捕捉个性化需求的复杂性）方面存在的挑战，提出Omni-Reward。

Method: 提出Omni-Reward，包括：1. Omni-RewardBench，首个涵盖文本、图像、视频、音频和3D五种模态的自由形式偏好奖励模型基准；2. Omni-RewardData，一个包含248K通用偏好对和69K指令调优对的多模态偏好数据集；3. Omni-RewardModel，包含判别式和生成式奖励模型。

Result: Omni-RewardModel在Omni-RewardBench基准以及其他广泛使用的奖励建模基准上取得了强大的性能。

Conclusion: Omni-Reward在全模态奖励建模和自由形式偏好处理方面取得了显著进展。

Abstract: Reward models (RMs) play a critical role in aligning AI behaviors with human
preferences, yet they face two fundamental challenges: (1) Modality Imbalance,
where most RMs are mainly focused on text and image modalities, offering
limited support for video, audio, and other modalities; and (2) Preference
Rigidity, where training on fixed binary preference pairs fails to capture the
complexity and diversity of personalized preferences. To address the above
challenges, we propose Omni-Reward, a step toward generalist omni-modal reward
modeling with support for free-form preferences, consisting of: (1) Evaluation:
We introduce Omni-RewardBench, the first omni-modal RM benchmark with free-form
preferences, covering nine tasks across five modalities including text, image,
video, audio, and 3D; (2) Data: We construct Omni-RewardData, a multimodal
preference dataset comprising 248K general preference pairs and 69K
instruction-tuning pairs for training generalist omni-modal RMs; (3) Model: We
propose Omni-RewardModel, which includes both discriminative and generative
RMs, and achieves strong performance on Omni-RewardBench as well as other
widely used reward modeling benchmarks.

</details>


### [317] [BrowseConf: Confidence-Guided Test-Time Scaling for Web Agents](https://arxiv.org/abs/2510.23458)
*Litu Ou,Kuan Li,Huifeng Yin,Liwen Zhang,Zhongwang Zhang,Xixi Wu,Rui Ye,Zile Qiao,Yong Jiang,Pengjun Xie,Fei Huang,Jingren Zhou*

Main category: cs.CL

TL;DR: LLM搜索代理在多轮交互中可以通过语言表达置信度，TTS方法利用置信度评分来提高答案质量并减少token消耗。


<details>
  <summary>Details</summary>
Motivation: 研究LLM搜索代理在多轮交互中表达自身置信度的能力，以评估模型的不确定性和回答的可靠性。

Method: 在开源代理模型上进行实验，提出Test-Time Scaling (TTS)方法，该方法利用置信度分数来确定答案质量，并促使模型在达到满意置信度水平前进行重试。

Result: 模型在高置信度下表现出更高的任务准确性，而在低置信度下准确性接近于零。提出的TTS方法显著减少了token消耗，同时表现出与基线固定预算TTS方法相当的性能。

Conclusion: LLM搜索代理在多轮交互中能够通过置信度分数来沟通其不确定性，并且TTS方法能够有效利用这些信息来优化性能和资源利用率。

Abstract: Confidence in LLMs is a useful indicator of model uncertainty and answer
reliability. Existing work mainly focused on single-turn scenarios, while
research on confidence in complex multi-turn interactions is limited. In this
paper, we investigate whether LLM-based search agents have the ability to
communicate their own confidence through verbalized confidence scores after
long sequences of actions, a significantly more challenging task compared to
outputting confidence in a single interaction. Experimenting on open-source
agentic models, we first find that models exhibit much higher task accuracy at
high confidence while having near-zero accuracy when confidence is low. Based
on this observation, we propose Test-Time Scaling (TTS) methods that use
confidence scores to determine answer quality, encourage the model to try again
until reaching a satisfactory confidence level. Results show that our proposed
methods significantly reduce token consumption while demonstrating competitive
performance compared to baseline fixed budget TTS methods.

</details>


### [318] [Evaluating Large Language Models for Stance Detection on Financial Targets from SEC Filing Reports and Earnings Call Transcripts](https://arxiv.org/abs/2510.23464)
*Nikesh Gyawali,Doina Caragea,Alex Vasenkov,Cornelia Caragea*

Main category: cs.CL

TL;DR: 本文提出了一个针对金融领域特定目标（债务、每股收益、销售额）的句子级立场检测语料库，并利用大型语言模型（LLMs）在零样本、少样本和思维链（CoT）提示策略下进行了系统性评估。结果表明，少样本+CoT提示优于监督基线，且LLMs在不同金融文本（SEC文件和财报电话会议记录）上的表现有所差异。


<details>
  <summary>Details</summary>
Motivation: 金融报告（如SEC文件和财报电话会议记录）中的财务叙述对投资者、审计师和监管机构至关重要，但其长度、专业术语和细微语言增加了精细化分析的难度。现有的情感分析方法需要昂贵的标注数据集，难以实现句子级别针对特定金融目标的立场检测。

Method: 构建了一个包含句子级立场（正面、负面、中性）标注的语料库，句子来源于10-K文件和财报电话会议记录，并使用ChatGPT-o3-pro模型进行标注，辅以人工验证。利用该语料库，系统性地评估了不同提示策略（零样本、少样本、思维链）下大型语言模型（LLMs）在目标立场检测方面的表现。

Result: 少样本+思维链（CoT）提示策略在金融目标立场检测任务上表现优于监督基线模型。不同的大型语言模型在SEC文件和财报电话会议记录两种不同类型的金融文本上的表现存在差异。

Conclusion: 研究表明，在无需大量标注数据的情况下，利用大型语言模型进行金融领域特定目标的立场检测具有实际可行性。

Abstract: Financial narratives from U.S. Securities and Exchange Commission (SEC)
filing reports and quarterly earnings call transcripts (ECTs) are very
important for investors, auditors, and regulators. However, their length,
financial jargon, and nuanced language make fine-grained analysis difficult.
Prior sentiment analysis in the financial domain required a large, expensive
labeled dataset, making the sentence-level stance towards specific financial
targets challenging. In this work, we introduce a sentence-level corpus for
stance detection focused on three core financial metrics: debt, earnings per
share (EPS), and sales. The sentences were extracted from Form 10-K annual
reports and ECTs, and labeled for stance (positive, negative, neutral) using
the advanced ChatGPT-o3-pro model under rigorous human validation. Using this
corpus, we conduct a systematic evaluation of modern large language models
(LLMs) using zero-shot, few-shot, and Chain-of-Thought (CoT) prompting
strategies. Our results show that few-shot with CoT prompting performs best
compared to supervised baselines, and LLMs' performance varies across the SEC
and ECT datasets. Our findings highlight the practical viability of leveraging
LLMs for target-specific stance in the financial domain without requiring
extensive labeled data.

</details>


### [319] [MMTutorBench: The First Multimodal Benchmark for AI Math Tutoring](https://arxiv.org/abs/2510.23477)
*Tengchao Yang,Sichen Guo,Mengzhao Jia,Jiaming Su,Yuanyang Liu,Zhihan Zhang,Meng Jiang*

Main category: cs.CL

TL;DR: MMTutorBench是一个新基准，用于评估AI在数学辅导方面的能力，重点关注诊断学生困难和提供分步指导。该基准包含685个问题和详细的评分标准，涵盖三个任务：洞察发现、操作制定和操作执行。评估结果显示，专有模型优于开源模型，但与人类导师相比仍有差距。OCR处理、少样本提示和LLM作为裁判等因素对性能有不同程度的影响。


<details>
  <summary>Details</summary>
Motivation: 现有的AI数学辅导评估基准忽视了诊断学生困难和提供分步指导等关键辅导技能。为了解决这一问题，需要一个能够衡量这些技能的基准。

Method: 构建了一个包含685个问题（围绕教学关键步骤设计）和问题特定评分标准的基准（MMTutorBench）。该基准包含三个任务：洞察发现、操作制定和操作执行。使用该基准评估了12个领先的多模态大语言模型（MLLMs）。

Result: 在评估的12个MLLMs中，专有模型在性能上优于开源模型。所有模型与人类导师相比，在辅导能力上都存在显著差距。OCR处理会降低辅导质量，少样本提示的收益有限，并且基于评分卡的LLM作为裁判被证明是可靠的。

Conclusion: MMTutorBench是第一个用于AI数学辅导的基准，能够有效评估LLMs的辅导能力，并突显了AI在这一领域面临的挑战以及MMTutorBench在推动AI辅导研究方面诊断价值。

Abstract: Effective math tutoring requires not only solving problems but also
diagnosing students' difficulties and guiding them step by step. While
multimodal large language models (MLLMs) show promise, existing benchmarks
largely overlook these tutoring skills. We introduce MMTutorBench, the first
benchmark for AI math tutoring, consisting of 685 problems built around
pedagogically significant key-steps. Each problem is paired with
problem-specific rubrics that enable fine-grained evaluation across six
dimensions, and structured into three tasks-Insight Discovery, Operation
Formulation, and Operation Execution. We evaluate 12 leading MLLMs and find
clear performance gaps between proprietary and open-source systems, substantial
room compared to human tutors, and consistent trends across input variants: OCR
pipelines degrade tutoring quality, few-shot prompting yields limited gains,
and our rubric-based LLM-as-a-Judge proves highly reliable. These results
highlight both the difficulty and diagnostic value of MMTutorBench for
advancing AI tutoring.

</details>


### [320] [M4FC: a Multimodal, Multilingual, Multicultural, Multitask Real-World Fact-Checking Dataset](https://arxiv.org/abs/2510.23508)
*Jiahui Geng,Jonathan Tonglet,Iryna Gurevych*

Main category: cs.CL

TL;DR: M4FC是一个包含4982张图片和6980条声明的新型真实世界多模态自动事实核查数据集，解决了现有数据集的局限性，如规模小、语言和任务单一、证据泄露等。该数据集由专业事实核查人员验证，涵盖多样化的文化和地理背景，并支持十种语言中的一到两种。M4FC包含六个多模态事实核查任务，并提供了基线结果，分析了中间任务对最终预测结果的影响。


<details>
  <summary>Details</summary>
Motivation: 现有真实世界多模态自动事实核查数据集存在规模小、语言和任务单一、证据泄露、依赖外部新闻文章等问题。M4FC旨在解决这些局限性，提供一个更全面、多样化的数据集。

Method: 创建了一个包含4982张图片和6980条声明的新型真实世界数据集M4FC。该数据集由专业事实核查人员验证，涵盖多样化的文化和地理背景，并支持十种语言中的一到两种。M4FC包含六个多模态事实核查任务：视觉声明提取、声明者意图预测、虚假检测、图像情境化、位置验证和判决预测。提供了所有任务的基线结果，并分析了组合中间任务对下游判决预测性能的影响。

Result: M4FC数据集包含4982张图片和6980条声明，由专业事实核查人员验证，涵盖多样化的文化和地理背景，并支持十种语言中的一到两种。数据集包含六个多模态事实核查任务。提供了基线结果，并分析了中间任务对下游判决预测性能的影响。

Conclusion: M4FC数据集为多模态自动事实核查提供了一个新的、更全面的资源，解决了现有数据集的不足。通过支持多种语言和任务，并包含专业验证的真实世界数据，M4FC有助于推动该领域的研究和发展。

Abstract: Existing real-world datasets for multimodal automated fact-checking have
multiple limitations: they contain few instances, focus on only one or two
languages and tasks, suffer from evidence leakage, or depend on external sets
of news articles for sourcing true claims. To address these shortcomings, we
introduce M4FC, a new real-world dataset comprising 4,982 images paired with
6,980 claims. The images, verified by professional fact-checkers from 22
organizations, represent diverse cultural and geographic contexts. Each claim
is available in one or two out of ten languages. M4FC spans six multimodal
fact-checking tasks: visual claim extraction, claimant intent prediction, fake
detection, image contextualization, location verification, and verdict
prediction. We provide baseline results for all tasks and analyze how combining
intermediate tasks influence downstream verdict prediction performance. We make
our dataset and code available.

</details>


### [321] [IPQA: A Benchmark for Core Intent Identification in Personalized Question Answering](https://arxiv.org/abs/2510.23536)
*Jieyong Kim,Maryam Amirizaniani,Soojin Yoon,Dongha Lee*

Main category: cs.CL

TL;DR: 现有评估标准无法衡量个性化问答中的核心意图识别能力，该研究提出了IPQA基准，通过分析用户行为模式和满意度理论来识别用户优先考虑的核心意图，并构建了一个包含多个领域的数据集，实验表明当前模型在识别核心意图方面存在挑战，尤其是在问题复杂性增加时。


<details>
  <summary>Details</summary>
Motivation: 现有问答系统评估忽略了用户意图识别的重要性，无法满足个体信息需求。本研究旨在解决这一关键问题，通过识别用户优先考虑的核心意图来改进个性化问答。

Method: 提出核心意图的概念，并构建IPQA基准来评估它。通过分析用户在答案选择中的行为模式，并借鉴满意度理论，从用户行为中推导出核心意图。利用系统过滤、LLM标注和人工验证相结合的方法构建数据集。

Result: 通过实验评估，发现现有语言模型在识别个性化问答中的核心意图方面存在困难，尤其是在问题复杂度增加时，模型性能会下降。

Conclusion: 核心意图识别是个性化问答中的一个关键且具有挑战性的问题。现有模型在识别用户优先考虑的意图方面表现不佳，尤其是在处理复杂问题时。本研究提出的IPQA基准和数据集将有助于推动该领域的研究。

Abstract: Intent identification serves as the foundation for generating appropriate
responses in personalized question answering (PQA). However, existing
benchmarks evaluate only response quality or retrieval performance without
directly measuring intent identification capabilities. This gap is critical
because without understanding which intents users prioritize, systems cannot
generate responses satisfying individual information needs. To address this, we
introduce the concept of core intents: intents users prioritize when selecting
answers to satisfy their information needs. To evaluate these core intents, we
propose IPQA, a benchmark for core Intent identification in Personalized
Question Answering. Since users do not explicitly state their prioritized
intents, we derive core intents from observable behavior patterns in answer
selection, grounded in satisficing theory where users choose answers meeting
their acceptance thresholds. We construct a dataset with various domains
through systematic filtering, LLM-based annotation, and rigorous quality
control combining automated verification with human validation. Experimental
evaluations across state-of-the-art language models reveal that current systems
struggle with core intent identification in personalized contexts. Models fail
to identify core intents from user histories, with performance degrading as
question complexity increases. The code and dataset will be made publicly
available to facilitate future research in this direction.

</details>


### [322] [LimRank: Less is More for Reasoning-Intensive Information Reranking](https://arxiv.org/abs/2510.23544)
*Tingyu Song,Yilun Zhao,Siyue Zhang,Chen Zhao,Arman Cohan*

Main category: cs.CL

TL;DR: LIMRANK-SYNTHESIZER 可用于生成合成数据，从而在更少的数据上训练出具有竞争力的信息重排模型LIMRANK。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖大规模微调来适应大型语言模型（LLM）以进行信息重排任务，这在计算上成本高昂。本研究旨在证明仅使用少量高质量监督即可有效改编 LLM。

Method: 使用LIMRANK-SYNTHESIZER生成的合成数据，训练LIMRANK重排模型。

Result: LIMRANK在BRIGHT和FollowIR基准测试中取得了有竞争力的性能，并且其训练数据量少于先前工作的5%。此外，LIMRANK-SYNTHESIZER的有效性和LIMRANK在下游任务中的泛化能力也得到了验证。

Conclusion: LIMRANK-SYNTHESIZER可用于生成合成数据，从而在更少的数据上训练出具有竞争力的信息重排模型LIMRANK。LIMRANK模型具有强大的泛化能力，可应用于科学文献检索和知识密集型问题解决的检索增强生成等任务。

Abstract: Existing approaches typically rely on large-scale fine-tuning to adapt LLMs
for information reranking tasks, which is computationally expensive. In this
work, we demonstrate that modern LLMs can be effectively adapted using only
minimal, high-quality supervision. To enable this, we design
LIMRANK-SYNTHESIZER, a reusable and open-source pipeline for generating
diverse, challenging, and realistic reranking examples. Using this synthetic
data, we fine-tune our reranker model, LIMRANK. We evaluate LIMRANK on two
challenging benchmarks, i.e., BRIGHT for reasoning-intensive retrieval and
FollowIR for instruction-following retrieval. Our experiments demonstrate that
LIMRANK achieves competitive performance, while being trained on less than 5%
of the data typically used in prior work. Further ablation studies demonstrate
the effectiveness of LIMRANK-SYNTHESIZER and the strong generalization
capabilities of LIMRANK across downstream tasks, including scientific
literature search and retrieval-augmented generation for knowledge-intensive
problem solving.

</details>


### [323] [Hope Speech Detection in Social Media English Corpora: Performance of Traditional and Transformer Models](https://arxiv.org/abs/2510.23585)
*Luis Ramos,Hiram Calvo,Olga Kolesnikova*

Main category: cs.CL

TL;DR: 识别希望言论在NLP中是一个有前景的任务，尤其是在社交媒体上检测个体能动性和目标导向行为的表达。


<details>
  <summary>Details</summary>
Motivation: 识别希望言论的需求日益增长，以检测社交媒体上个体能动性和目标导向行为的表达。

Method: 评估了传统的机器学习模型（包括线性核SVM、逻辑回归、RBF核SVM和朴素贝叶斯）以及微调的Transformer模型在划分好的希望言论数据集上的表现。

Result: 在开发测试集上，线性核SVM和逻辑回归达到了0.78的宏F1分数；RBF核SVM为0.77，朴素贝叶斯为0.75。Transformer模型表现更优，最佳模型达到了0.82的加权精确率、0.80的加权召回率、0.79的加权F1分数、0.79的宏F1分数以及0.80的准确率。

Conclusion: 优化配置的传统机器学习模型仍然具有竞争力，但Transformer架构能更好地捕捉希望言论的细微语义，从而在希望言论检测任务中获得更高的精确率和召回率。这表明大型Transformer和LLM在小数据集上可能表现更好。

Abstract: The identification of hope speech has become a promised NLP task, considering
the need to detect motivational expressions of agency and goal-directed
behaviour on social media platforms. This proposal evaluates traditional
machine learning models and fine-tuned transformers for a previously split hope
speech dataset as train, development and test set. On development test, a
linear-kernel SVM and logistic regression both reached a macro-F1 of 0.78; SVM
with RBF kernel reached 0.77, and Na\"ive Bayes hit 0.75. Transformer models
delivered better results, the best model achieved weighted precision of 0.82,
weighted recall of 0.80, weighted F1 of 0.79, macro F1 of 0.79, and 0.80
accuracy. These results suggest that while optimally configured traditional
machine learning models remain agile, transformer architectures detect some
subtle semantics of hope to achieve higher precision and recall in hope speech
detection, suggesting that larges transformers and LLMs could perform better in
small datasets.

</details>


### [324] [Think Twice: Branch-and-Rethink Reasoning Reward Model](https://arxiv.org/abs/2510.23596)
*Yizhu Jiao,Jiaqi Zeng,Julien Veron Vialard,Oleksii Kuchaiev,Jiawei Han,Olivier Delalleau*

Main category: cs.CL

TL;DR: BR-RM是一种两阶段的奖励模型，通过引入“分支-再思考”机制，提高了对细微错误的敏感性，并在三个奖励建模基准上达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的奖励模型（RM）通常将多个质量维度压缩成单一标量，导致判断扩散，注意力分散，分析肤浅。LLMs的“先思考，再思考”策略表明，第二次审视可以增强推理能力，但这种策略尚未应用于奖励建模。

Method: 提出分支-再思考（BR-RM）奖励模型，这是一个两阶段模型。第一阶段进行自适应分支，选择实例关键维度并生成证据搜寻假设。第二阶段执行分支条件再思考，针对性地重读并审查关键点。模型使用GRPO风格的强化学习进行训练，结合简单的二元结果奖励和严格的格式检查，以兼容标准的RLHF流程。

Result: BR-RM通过将一次性评分转换为专注的二次审视推理，减少了判断扩散，提高了对细微 yet 有影响的错误的敏感性，同时保持了实用性和可扩展性。实验结果表明，该模型在三个具有挑战性的、跨领域的奖励建模基准上取得了最先进的性能。

Conclusion: BR-RM通过将“先思考，再思考”的原则应用于奖励建模，成功克服了现有奖励模型在处理多维度质量评估时存在的判断扩散问题，并在多个基准测试中取得了优异的成果。

Abstract: Large language models (LLMs) increasingly rely on thinking models that
externalize intermediate steps and allocate extra test-time compute, with
think-twice strategies showing that a deliberate second pass can elicit
stronger reasoning. In contrast, most reward models (RMs) still compress many
quality dimensions into a single scalar in one shot, a design that induces
judgment diffusion: attention spreads across evaluation criteria, yielding
diluted focus and shallow analysis. We introduce branch-and-rethink (BR-RM), a
two-turn RM that transfers the think-twice principle to reward modeling. Turn 1
performs adaptive branching, selecting a small set of instance-critical
dimensions (such as factuality and safety) and sketching concise,
evidence-seeking hypotheses. Turn 2 executes branch-conditioned rethinking, a
targeted reread that tests those hypotheses and scrutinizes only what matters
most. We train with GRPO-style reinforcement learning over structured two-turn
traces using a simple binary outcome reward with strict format checks, making
the approach compatible with standard RLHF pipelines. By converting
all-at-oncescoringintofocused, second-lookreasoning,
BR-RMreducesjudgmentdiffusionandimproves sensitivity to subtle yet
consequential errors while remaining practical and scalable. Experimental
results demonstrate that our model achieves state-of-the-art performance on
three challenging reward modeling benchmarks across diverse domains. The code
and the model will be released soon.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [325] [Simopt-Power: Leveraging Simulation Metadata for Low-Power Design Synthesis](https://arxiv.org/abs/2510.21745)
*Eashan Wadhwa,Shanker Shreejith*

Main category: cs.AR

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Excessive switching activity is a primary contributor to dynamic power
dissipation in modern FPGAs, where fine-grained configurability amplifies
signal toggling and associated capacitance. Conventional low-power techniques
-- gating, clock-domain partitioning, and placement-aware netlist rewrites -
either require intrusive design changes or offer diminishing returns as device
densities grow. In this work, we present Simopt-power, a simulator-driven
optimisation framework that leverages simulation analysis to identify and
selectively reconfigure high-toggle paths. By feeding activity profiles back
into a lightweight transformation pass, Simopt-power judiciously inserts
duplicate truth table logic using Shannon Decomposition principle and relocates
critical nets, thereby attenuating unnecessary transitions without perturbing
functional behaviour. We evaluated this framework on open-source RTLLM
benchmark, with Simopt-power achieves an average switching-induced power
reduction of ~9\% while incurring only ~9\% additional LUT-equivalent resources
for arithmetic designs. These results demonstrate that coupling simulation
insights with targeted optimisations can yield a reduced dynamic power,
offering a practical path toward using simulation metadata in the FPGA-CAD
flow.

</details>


### [326] [QuArch: A Benchmark for Evaluating LLM Reasoning in Computer Architecture](https://arxiv.org/abs/2510.22087)
*Shvetank Prakash,Andrew Cheng,Arya Tschand,Mark Mazumder,Varun Gohil,Jeffrey Ma,Jason Yik,Zishen Wan,Jessica Quaye,Elisavet Lydia Alvanaki,Avinash Kumar,Chandrashis Mazumdar,Tuhin Khare,Alexander Ingare,Ikechukwu Uchendu,Radhika Ghosal,Abhishek Tyagi,Chenyu Wang,Andrea Mattia Garavagno,Sarah Gu,Alice Guo,Grace Hur,Luca Carloni,Tushar Krishna,Ankita Nayak,Amir Yazdanbakhsh,Vijay Janapa Reddi*

Main category: cs.AR

TL;DR: QuArch是第一个用于评估大型语言模型（LLM）在计算机体系结构知识和推理能力方面的基准，包含2671个专家验证的问答对。研究发现，尽管前沿模型具备领域知识，但在需要更高层次思维的计算机体系结构问题上仍存在不足，准确率在34%到72%之间。


<details>
  <summary>Details</summary>
Motivation: 目前的LLM评估中缺乏对计算机体系结构领域的考察，而该领域连接着高层软件和底层硬件。因此，需要一个专门的基准来评估LLM在计算机体系结构方面的知识和推理能力。

Method: 构建了一个包含2671个专家验证的问答对的基准QuArch，涵盖处理器设计、内存系统和互连网络等计算机体系结构的关键方面。

Result: 前沿模型在QuArch基准上的准确率差异很大（34%至72%），表明它们在分析、设计和实现等高级计算机体系结构推理方面存在明显不足。

Conclusion: QuArch基准的建立为评估和提升LLM在计算机体系结构领域的推理能力奠定了基础，有助于推动计算系统创新。该基准的广泛参与性（来自40个机构的140多名贡献者）体现了社区在LLM评估领域设定标准方面的共同努力。

Abstract: The field of computer architecture, which bridges high-level software
abstractions and low-level hardware implementations, remains absent from
current large language model (LLM) evaluations. To this end, we present QuArch
(pronounced 'quark'), the first benchmark designed to facilitate the
development and evaluation of LLM knowledge and reasoning capabilities
specifically in computer architecture. QuArch provides a comprehensive
collection of 2,671 expert-validated question-answer (QA) pairs covering
various aspects of computer architecture, including processor design, memory
systems, and interconnection networks. Our evaluation reveals that while
frontier models possess domain-specific knowledge, they struggle with skills
that require higher-order thinking in computer architecture. Frontier model
accuracies vary widely (from 34% to 72%) on these advanced questions,
highlighting persistent gaps in architectural reasoning across analysis,
design, and implementation QAs. By holistically assessing fundamental skills,
QuArch provides a foundation for building and measuring LLM capabilities that
can accelerate innovation in computing systems. With over 140 contributors from
40 institutions, this benchmark represents a community effort to set the
standard for architectural reasoning in LLM evaluation.

</details>


### [327] [RAMAN: Resource-efficient ApproxiMate Posit Processing for Algorithm-Hardware Co-desigN](https://arxiv.org/abs/2510.22627)
*Mohd Faisal Khan,Mukul Lokhande,Santosh Kumar Vishvakarma*

Main category: cs.AR

TL;DR: RAMAN是一种基于posit(8,2)的资源高效、近似的乘累加（MAC）架构，旨在提高带宽受限环境下的硬件效率。


<details>
  <summary>Details</summary>
Motivation: Edge-AI应用在资源受限环境中提高计算效率仍面临挑战。

Method: 提出了一种基于posit的REAP MAC引擎，通过近似处理降低功耗和面积，并将其集成到可扩展的向量执行单元（VEU）中。还提出了一种算法-硬件协同设计框架，用于近似感知训练。

Result: 与基线设计相比，REAP MAC在LUT节省、面积和功耗方面分别实现了高达46%、35.66%和31.28%的降低，同时在手写数字识别中保持了98.45%的准确率。

Conclusion: RAMAN在硬件效率和学习性能之间取得了有希望的权衡，适用于下一代边缘智能。

Abstract: Edge-AI applications still face considerable challenges in enhancing
computational efficiency in resource-constrained environments. This work
presents RAMAN, a resource-efficient and approximate posit(8,2)-based
Multiply-Accumulate (MAC) architecture designed to improve hardware efficiency
within bandwidth limitations. The proposed REAP (Resource-Efficient Approximate
Posit) MAC engine, which is at the core of RAMAN, uses approximation in the
posit multiplier to achieve significant area and power reductions with an
impact on accuracy. To support diverse AI workloads, this MAC unit is
incorporated in a scalable Vector Execution Unit (VEU), which permits hardware
reuse and parallelism among deep neural network layers. Furthermore, we propose
an algorithm-hardware co-design framework incorporating approximation-aware
training to evaluate the impact of hardware-level approximation on
application-level performance. Empirical validation on FPGA and ASIC platforms
shows that the proposed REAP MAC achieves up to 46% in LUT savings and 35.66%
area, 31.28% power reduction, respectively, over the baseline Posit Dot-Product
Unit (PDPU) design, while maintaining high accuracy (98.45%) for handwritten
digit recognition. RAMAN demonstrates a promising trade-off between hardware
efficiency and learning performance, making it suitable for next-generation
edge intelligence.

</details>


### [328] [Approximate Signed Multiplier with Sign-Focused Compressor for Edge Detection Applications](https://arxiv.org/abs/2510.22674)
*L. Hemanth Krishna,Srinivasu Bodapati,Sreehari Veeramachaneni,BhaskaraRao Jammu,Noor Mahammad Sk*

Main category: cs.AR

TL;DR: 该论文提出了一种用于边缘检测的近似有符号乘法器架构，通过引入特殊的压缩器和截断/误差补偿机制，在功耗和延迟方面取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 为了提高边缘检测应用中乘法器的效率，特别是在机器学习和信号处理领域，需要设计一种能够处理有符号数并降低功耗和延迟的架构。

Method: 提出了一种包含A + B + C + 1和A + B + C + D + 1两种有符号压缩器的近似有符号乘法器架构。该架构同时采用了精确和近似的压缩器设计，并专注于处理常数1和负数部分积。此外，通过截断部分积矩阵的低N-1列并引入误差补偿机制来进一步提高效率。

Result: 提出的8位近似乘法器在功耗延迟积（PDP）方面降低了29.21%，在功耗方面降低了14.39%，优于现有的乘法器。将该乘法器集成到自定义卷积层中进行边缘检测，验证了其在实际应用中的有效性。

Conclusion: 所提出的近似有符号乘法器架构能够有效降低功耗和延迟，并且在边缘检测等实际应用中表现出良好的性能，为相关领域的硬件设计提供了有价值的参考。

Abstract: This paper presents an approximate signed multiplier architecture that
incorporates a sign-focused compressor, specifically designed for edge
detection applications in machine learning and signal processing. The
multiplier incorporates two types of sign-focused compressors: A + B + C + 1
and A + B + C + D + 1. Both exact and approximate compressor designs are
utilized, with a focus on efficiently handling constant value "1" and negative
partial products, which frequently appear in the partial product matrices of
signed multipliers. To further enhance efficiency, the lower N - 1 columns of
the partial product matrix are truncated, followed by an error compensation
mechanism. Experimental results show that the proposed 8-bit approximate
multiplier achieves a 29.21% reduction in power delay product (PDP) and a
14.39% reduction in power compared to the best of existing multipliers. The
proposed multiplier is integrated into a custom convolution layer and performs
edge detection, demonstrating its practical utility in real-world applications.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [329] [A Perspective on the Algebra, Topology, and Logic of Electrical Networks](https://arxiv.org/abs/2510.21911)
*Marko Orešković,Ivana Kuzmanović Ivičić,Juraj Benić,Mario Essert*

Main category: eess.SY

TL;DR: 本论文提出了一种基于Šare m-理论的统一代数、拓扑和逻辑框架，用于处理单端口电气网络。


<details>
  <summary>Details</summary>
Motivation: 为单端口电气网络提供一个统一的代数、拓扑和逻辑框架，并探索其在网络综合、分类和验证中的应用。

Method: 使用Šare的m-理论，将网络表示为m-词（jorbs），并引入m-拓扑、theta映射、λ--Δ度量和Φ值词态同态等概念来形式化网络结构和阻抗特性。此外，还开发了用于生成和分类非同构串并联拓扑的算法程序，以及Cauer/Foster综合工作流程。

Result: 实现了阻抗函数的符号到拓扑的转换，建立了代数表示与电气实现的建设性桥梁。开发了用于生成和分类非同构串并联拓扑的算法程序，并通过Ladenheim目录中的经典示例进行了验证。

Conclusion: 该框架为自动网络综合、分类和形式验证提供了一个自洽的理论和计算基础，有望在Jorbology这一新兴领域得到应用。

Abstract: This paper presents a unified algebraic, topological, and logical framework
for electrical one-port networks based on \v{S}are's $m$-theory. Within this
formalism, networks are represented by $m$-words (jorbs) over an ordered
alphabet, where series and parallel composition induce an $m$-topology on
$m$-graphs with a theta mapping $\vartheta$ that preserves one-port
equivalence. The study formalizes quasi-orders, shells, and cores, showing
their structural correspondence to network boundary conditions and impedance
behavior. The $\lambda--\Delta$ metric, together with the valuation morphism
$\Phi$, provides a concise descriptor of the impedance-degree structure. In the
computational domain, the framework is extended with algorithmic procedures for
generating and classifying non-isomorphic series-parallel topologies,
accompanied by programmatic Cauer/Foster synthesis workflows and validation
against canonical examples from Ladenheim's catalogue. The resulting approach
enables symbolic-to-topological translation of impedance functions, offering a
constructive bridge between algebraic representation and electrical
realization. Overall, the paper outlines a self-consistent theoretical and
computational foundation for automated network synthesis, classification, and
formal verification within the emerging field of Jorbology.

</details>


### [330] [Pricing Problems in Adoption of New Technologies](https://arxiv.org/abs/2510.21951)
*Yijin Wang,Subhonmesh Bose*

Main category: eess.SY

TL;DR: 该研究提出了一个离散时间的 Bass 扩散模型，考虑了价格对产品采纳的影响，并将其应用于优化定价策略和政策制定者与垄断者之间的博弈。


<details>
  <summary>Details</summary>
Motivation: 提出一个显式考虑价格影响的离散时间 Bass 扩散模型，以更好地拟合产品采纳数据，并研究相关的定价和政策制定问题。

Method: 首先，通过一个离散时间的 Bass 扩散模型来分析价格对产品采纳的影响，并将其应用于分析垄断者的最优定价策略（单期和多期）。其次，研究一个由政策制定者（通过返利最大化采纳率）和垄断者（通过定价最大化利润）之间的 Stackelberg 博弈。

Result: 在定价策略方面，完全刻画了单期问题的最优定价策略，并确定了多期问题的相关结构特性。在 Stackelberg 博弈方面，解析地刻画了单期博弈均衡路径的关键特性，并展示了这些特性如何延伸到多期博弈。

Conclusion: 研究提出的模型能够有效地拟合采纳数据，并为垄断者的定价策略和政策制定者与垄断者之间的博弈提供了重要的结构性结果。

Abstract: We propose a generalization of the Bass diffusion model in discrete-time that
explicitly models the effect of price in adoption. Our model is different from
earlier price-incorporated models and fits well to adoption data for various
products. We then utilize this model to study two decision-making problems.
First, we provide a series of structural results on optimal pricing strategies
to maximize profits from product sales by a monopolist over a finite horizon.
We fully characterize the optimal pricing strategy in the single-period
problem, and establish several structural properties of the same for the
multi-period counterpart. Second, we study a Stackelberg game between a
policy-maker and a monopolist, where the former seeks to maximize adoption
through rebates, while the latter focuses on profits. For this problem, we
analytically characterize crucial properties of the equilibrium path of the
single-period game, and demonstrate how they carry over to the multi-period
variant.

</details>


### [331] [Motion Planning with Precedence Specifications via Augmented Graphs of Convex Sets](https://arxiv.org/abs/2510.22015)
*Shilin You,Gael Luna,Juned Shaikh,David Gostin,Yu Xiang,Justin Koeln,Tyler Summers*

Main category: eess.SY

TL;DR: 提出一种规划避障轨迹并满足键门约束的算法。


<details>
  <summary>Details</summary>
Motivation: 处理包含键门约束的复杂导航问题。

Method: 1. 对无碰撞空间进行凸分解以编码连通性。 2. 构建增强图以编码键门约束。 3. 在增强图中求解最短路径问题。

Result: 在数字实验中，该方法比现有方法快几个数量级。

Conclusion: 该方法能有效且高效地解决带有键门约束的避障规划问题。

Abstract: We present an algorithm for planning trajectories that avoid obstacles and
satisfy key-door precedence specifications expressed with a fragment of signal
temporal logic. Our method includes a novel exact convex partitioning of the
obstacle free space that encodes connectivity among convex free space sets, key
sets, and door sets. We then construct an augmented graph of convex sets that
exactly encodes the key-door precedence specifications. By solving a shortest
path problem in this augmented graph of convex sets, our pipeline provides an
exact solution up to a finite parameterization of the trajectory. To illustrate
the effectiveness of our approach, we present a method to generate key-door
mazes that provide challenging problem instances, and we perform numerical
experiments to evaluate the proposed pipeline. Our pipeline is faster by
several orders of magnitude than recent state-of-the art methods that use
general purpose temporal logic tools.

</details>


### [332] [A Hybrid GNN-LSE Method for Fast, Robust, and Physically-Consistent AC Power Flow](https://arxiv.org/abs/2510.22020)
*Mohamed Shamseldein*

Main category: eess.SY

TL;DR: 本篇论文提出了一种结合物理信息图神经网络（GNN）和线性状态估计（LSE）的混合方法，用于解决传统交流潮流（ACPF）计算中的计算和收敛挑战。


<details>
  <summary>Details</summary>
Motivation: 传统的交流潮流（ACPF）求解器（如牛顿-拉夫逊法）在现代大规模电力系统中面临显著的计算和收敛挑战。

Method: 提出了一种新颖的两阶段混合方法，将物理信息图神经网络（GNN）与强大的迭代线性状态估计（LSE）精炼步骤相结合。GNN 使用具有高效动态加权方案的物理信息损失函数进行训练，以快速预测高质量的初始系统状态。然后，使用受状态估计技术启发的迭代、直接线性求解器对该预测进行精炼。此 LSE 精炼步骤求解一系列线性方程以强制执行物理定律，从而有效地绕过传统求解器的非线性问题和收敛问题。

Result: 在从小型径向配电网络（IEEE 33 节点、69 节点）到大型网状输电系统（IEEE 118 节点）的系统中进行了全面验证。结果表明，本论文提出的 GNN 变体比牛顿-拉夫逊法快 $8.4 	imes 10^3$ 倍。LSE 精炼提供了快速获得物理上一致的解决方案的途径，而重负荷压力测试（标称值的 120%-150%）和 N-1 故障分析则证明了该方法的可靠性和泛化能力。

Conclusion: 这项工作提出了一种强大而灵活的框架，用于将快速的数据驱动模型与严格的电力系统物理约束相结合，为实时运行和分析提供了实用的工具。

Abstract: Conventional AC Power Flow (ACPF) solvers like Newton-Raphson (NR) face
significant computational and convergence challenges in modern, large-scale
power systems. This paper proposes a novel, two-stage hybrid method that
integrates a Physics-Informed Graph Neural Network (GNN) with a robust,
iterative Linear State Estimation (LSE) refinement step to produce fast and
physically-consistent solutions. The GNN, trained with a physics-informed loss
function featuring an efficient dynamic weighting scheme, rapidly predicts a
high-quality initial system state. This prediction is then refined using an
iterative, direct linear solver inspired by state estimation techniques. This
LSE refinement step solves a series of linear equations to enforce physical
laws, effectively bypassing the non-linearities and convergence issues of
traditional solvers. The proposed GNN-LSE framework is comprehensively
validated on systems ranging from small radial distribution networks (IEEE
33-bus, 69-bus) to a large, meshed transmission system (IEEE 118-bus). Results
show that our GNN variants are up to $8.4 \times 10^3$ times faster than NR.
The LSE refinement provides a fast route to a physically-consistent solution,
while heavy-loading stress tests (120%-150% of nominal) and N-1 contingencies
demonstrate the method's reliability and generalization. This work presents a
powerful and flexible framework for bridging fast, data-driven models with the
rigorous constraints of power system physics, offering a practical tool for
real-time operations and analysis.

</details>


### [333] [High-Performance Rotor Cooling with Ducted Liquid in Completely Cold-Formed Modular Motor Shaft](https://arxiv.org/abs/2510.22029)
*Rezvan Alamian,Sören Müller,Uwe Steinmetz,Christian Henrich,Stefan Goetz*

Main category: eess.SY

TL;DR: 提出了一种新型转子冷却轴概念，用于高性能电机，可提高冷却效果且制造简单、成本效益高。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统冷却转子轴由于内部涡流形成而产生的高搅动损失以及其有限的传热问题，提出了一种创新的齿导向液体冷却轴设计。

Method: 采用计算流体分析，研究了四种转子冷却轴几何形状的热性能，并优化了传热效率和压力管理，通过纳入限制涡流形成的冷成型内通道来提高传热效果。

Result: 与传统的空心轴相比，齿导向设计在低转速下可实现高达110%的更高冷却效率，同时保持相当的压力水平。

Conclusion: 研究结果为几何驱动的热优化提供了实践见解，并为提高电机性能和耐用性指明了方向。

Abstract: This paper suggests a novel rotor-cooling shaft concept for high-performance
electric motors that increases the effectiveness of cooling and is yet simple
and cost-effective to manufacture. We investigate the thermal performance of
four shaft geometries for rotor cooling in automotive applications. The
proposed tooth-guided liquid-cooling shaft design aims to solve the high
churning loss of conventional cooled rotor shafts due to internal vortex
formation and their still limited heat transfer. Therefore, we optimize heat
transfer efficiency and pressure management by incorporating cold-formed
internal channels that restrict vortex formation beyond a degree that improves
heat transfer. We evaluated key performance metrics, including heat transfer
rate, outlet temperature, pressure drop, and velocity profiles, under varying
rotational speeds, inlet flow rates, and coolant temperatures. Computational
fluid analysis demonstrates that the tooth-guided design outperforms
conventional hollow shafts and achieves up to 110% higher cooling efficiency at
low rotational speeds, while it maintains comparable pressure levels. These
findings provide practical insight into geometry-driven thermal optimization
and offer a path toward improving the performance and durability of electric
motors.

</details>


### [334] [IoT-Driven Smart Management in Broiler Farming: Simulation of Remote Sensing and Control Systems](https://arxiv.org/abs/2510.23356)
*Sandra Coello Suarez,V. Sanchez Padilla,Ronald Ponguillo-Intriago,Albert Espinal*

Main category: eess.SY

TL;DR: 该研究提出了一种基于物联网（IoT）的自动化系统，用于监测和控制肉鸡养殖中的温度和饲喂。


<details>
  <summary>Details</summary>
Motivation: 参数监控和控制系统在工业中至关重要，可以实现提高生产力和资源优化。这些改进还有助于管理环境因素和生产管理所需的多个输入和输出之间的复杂交互。

Method: 该研究提出了一个基于模拟场景的肉鸡管理自动化系统，该系统涉及传感器网络和嵌入式系统，并利用物联网（IoT）来监控和控制肉鸡的温度和饲喂，并辅以仪表板和基于云的服务数据库来跟踪改进。

Result: 该系统旨在通过仪表板和云数据库进行改进，以跟踪肉鸡管理方面的改进。

Conclusion: 这项工作有望为畜牧业的利益相关者和企业家提供指导，通过简单且成本效益高的自动化解决方案促进可持续发展，从而在管理层面实现更有效的决策。

Abstract: Parameter monitoring and control systems are crucial in the industry as they
enable automation processes that improve productivity and resource
optimization. These improvements also help to manage environmental factors and
the complex interactions between multiple inputs and outputs required for
production management. This paper proposes an automation system for broiler
management based on a simulation scenario that involves sensor networks and
embedded systems. The aim is to create a transmission network for monitoring
and controlling broiler temperature and feeding using the Internet of Things
(IoT), complemented by a dashboard and a cloud-based service database to track
improvements in broiler management. We look forward this work will serve as a
guide for stakeholders and entrepreneurs in the animal production industry,
fostering sustainable development through simple and cost-effective automation
solutions. The goal is for them to scale and integrate these recommendations
into their existing operations, leading to more efficient decision-making at
the management level.

</details>


### [335] [TRASE-NODEs: Trajectory Sensitivity-aware Neural Ordinary Differential Equations for Efficient Dynamic Modeling](https://arxiv.org/abs/2510.22104)
*Fatima Al-Janahi,Min-Seung Ko,Hao Zhu*

Main category: eess.SY

TL;DR: TRASE-NODEs是一种新的机器学习方法，用于在数据有限的情况下对动态系统进行建模，特别是在控制设计中，提高了预测精度和数据效率。


<details>
  <summary>Details</summary>
Motivation: 标准NODEs在数据量不足时难以处理变化的控制输入，导致难以生成足够的数据和保证控制设计的安全性。

Method: 提出TRASE-NODEs，构建一个包含状态和敏感性的增强系统，同时学习它们的动态。该方法利用伴随法进行内存高效的梯度更新，并确保学习的动态能够捕捉到控制输入的影响。

Result: 在阻尼振荡器和基于逆变器的资源（IBRs）的评估中，TRASE-NODEs在有限的训练数据下表现出更好的泛化能力，预测误差低于标准NODEs。

Conclusion: TRASE-NODEs提供了一种数据高效、面向控制的动态系统建模方法，适用于需要精确轨迹敏感性预测的场景。

Abstract: Modeling dynamical systems is crucial across the science and engineering
fields for accurate prediction, control, and decision-making. Recently, machine
learning (ML) approaches, particularly neural ordinary differential equations
(NODEs), have emerged as a powerful tool for data-driven modeling of
continuous-time dynamics. Nevertheless, standard NODEs require a large number
of data samples to remain consistent under varying control inputs, posing
challenges to generate sufficient simulated data and ensure the safety of
control design. To address this gap, we propose trajectory-sensitivity-aware
(TRASE-)NODEs, which construct an augmented system for both state and
sensitivity, enabling simultaneous learning of their dynamics. This formulation
allows the adjoint method to update gradients in a memory-efficient manner and
ensures that control-input effects are captured in the learned dynamics. We
evaluate TRASE-NODEs using damped oscillator and inverter-based resources
(IBRs). The results show that TRASE-NODEs generalize better from the limited
training data, yielding lower prediction errors than standard NODEs for both
examples. The proposed framework offers a data-efficient, control-oriented
modeling approach suitable for dynamic systems that require accurate trajectory
sensitivity prediction.

</details>


### [336] [Fair Cost Allocation in Energy Communities: A DLMP-based Bilevel Optimization with a Shapley Value Approach](https://arxiv.org/abs/2510.22321)
*Hyeongon Park,Kyuhyeong Kwag,Daniel K. Molzahn,Rahul K. Gupta*

Main category: eess.SY

TL;DR: 该论文提出了一种考虑分布式节点边际电价（DLMP）的能源社区（EC）成本分配方法，通过双层优化模型和Shapley值实现公平分配。


<details>
  <summary>Details</summary>
Motivation: 现有的能源社区成本分配方法未能充分考虑分布式节点边际电价（DLMP）对系统运行成本的影响，该文旨在解决这一问题。

Method: 提出一个双层优化模型，其中社区能源聚合商（CEA）负责调度分布式能源（DER），而配电系统运营商（DSO）则根据网络约束确定DLMP。利用KKT条件和强对偶性将双层模型转化为可处理的单层问题，并应用Shapley值来量化社区对系统成本节约的边际贡献。

Result: 通过在多个基准配电系统上进行仿真，验证了所提出方法的有效性。

Conclusion: 该文提出的考虑DLMP的双层优化和Shapley值方法，能够实现能源社区内公平的成本分配。

Abstract: Energy communities (ECs) are emerging as a promising decentralized model for
managing cooperative distributed energy resources (DERs). As these communities
expand and their operations become increasingly integrated into the grid,
ensuring fairness in allocating operating costs among participants becomes a
challenge. In distribution networks, DER operations at the community level can
influence Distribution Locational Marginal Prices (DLMPs), which in turn affect
system's operation cost. This interdependence between local decisions and
system-level pricing introduces new challenges for fair and transparent cost
allocation. Despite growing interest in fairness-aware methods, most methods do
not account for the impact of DLMPs. To fill this gap, we propose a bilevel
optimization model in which a Community Energy Aggregator (CEA) schedules DERs
across multiple ECs while a Distribution System Operator (DSO) determines DLMPs
through network-constrained dispatch. Leveraging the Karush-Kuhn-Tucker (KKT)
conditions and strong duality, the bilevel model is reformulated into a
tractable single-level problem. We achieve fairness in the cost allocation by
applying the Shapley value to quantify each community's marginal contribution
to system-wide cost savings. The effectiveness of the proposed method is
validated through simulations on several benchmark distribution systems.

</details>


### [337] [Model-Free Power System Stability Enhancement with Dissipativity-Based Neural Control](https://arxiv.org/abs/2510.22324)
*Yifei Wang,Han Wang,Kehao Zhuang,Keith Moffat,Florian Dörfler*

Main category: eess.SY

TL;DR: 提出一种基于无模型、非线性和耗散性理论的控制器，用于提高并网虚拟同步发电机的瞬态稳定性，并使用神经网络学习耗散性矩阵。


<details>
  <summary>Details</summary>
Motivation: 现有基于Lyapunov和可传导性理论的方法在处理现代电网时存在局限性，如依赖于严格假设、难以求解大型电网的存储函数以及需要精确的电网模型。

Method: 训练神经网络学习耗散性特征矩阵，以实现基于无模型、非线性、耗散性理论的控制器，并结合成本函数整形以优化性能。

Result: 在修改后的、全VSG的Kundur双区电力系统上进行了数值验证，证明了该方法的有效性。

Conclusion: 该模型免费、非线性、基于耗散性的方法能够有效提高并网虚拟同步发电机的瞬态稳定性，并能通过成本函数整形进行性能优化。

Abstract: The integration of converter-interfaced generation introduces new transient
stability challenges to modern power systems. Classical Lyapunov- and scalable
passivity-based approaches typically rely on restrictive assumptions, and
finding storage functions for large grids is generally considered intractable.
Furthermore, most methods require an accurate grid dynamics model. To address
these challenges, we propose a model-free, nonlinear, and dissipativity-based
controller which, when applied to grid-connected virtual synchronous generators
(VSGs), enhances power system transient stability. Using input-state data, we
train neural networks to learn dissipativity-characterizing matrices that yield
stabilizing controllers. Furthermore, we incorporate cost function shaping to
improve the performance with respect to the user-specified objectives.
Numerical results on a modified, all-VSG Kundur two-area power system validate
the effectiveness of the proposed approach.

</details>


### [338] [Vector-Valued Native Space Embedding for Adaptive State Observation](https://arxiv.org/abs/2510.22374)
*Shengyuan Niu,Haoran Wang,Heejip Moon,Andrea L'Afflitto,Andrew Kurdila,Daniel Stilwell*

Main category: eess.SY

TL;DR: 该研究提出了一种结合向量值再生核希尔伯特空间嵌入和鲁棒自适应观测的非参数、鲁棒算法。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是处理具有无限维原生空间匹配不确定性、未匹配不确定性以及受扰动影响的被观测对象的状态估计问题。

Method: 该研究结合了向量值再生核希尔伯特空间嵌入和鲁棒自适应观测，提出了一种新的算法。

Result: 该研究为状态观测误差提供了解析形式的上界，并将其应用于刚体状态估计问题。

Conclusion: 该研究成功地将提出的理论结果应用于刚体状态估计问题，并提供了状态观测误差的上界。

Abstract: This paper combines vector-valued reproducing kernel Hilbert space (vRKHS)
embedding with robust adaptive observation, yielding an algorithm that is both
non-parametric and robust. The main contribution of this paper lies in the
ability of the proposed system to estimate the state of a plan model whose
matched uncertainties are elements of an infinite-dimensional native space. The
plant model considered in this paper also suffers from unmatched uncertainties.
Finally, the measured output is affected by disturbances as well. Upper bounds
on the state observation error are provided in an analytical form. The proposed
theoretical results are applied to the problem of estimating the state of a
rigid body.

</details>


### [339] [Resilient Composite Control for Stability Enhancement in EV Integrated DC Microgrids](https://arxiv.org/abs/2510.22429)
*Md Saiful Islam,Rahul Bhadani*

Main category: eess.SY

TL;DR: 将电动汽车集成到孤立的直流微电网中会因其恒功率负载（CPL）行为（表现为负增量阻抗，NII）和固有的低惯性问题而引发稳定性问题。本研究提出了一种结合全局积分终端滑模控制器和反步控制器的复合控制器，并采用虚拟电容器来解决低惯性问题和增强直流母线响应。采用改进的分数幂到达律来减少抖动并加速收敛。通过精确反馈线性化将非线性升压变换器模型转换为Brunovsky标准型，以解决NII和非最小相位问题。使用李雅普诺夫控制理论验证了整个系统的稳定性。仿真结果表明，与现有控制器相比，该方法在过冲、下冲和稳定时间方面分别减少了 34.4-53.3%、52.9-74.9% 和 12-47.4%，性能得到显著提升。


<details>
  <summary>Details</summary>
Motivation: 电动汽车（EV）集成到孤立的直流微电网（DCMG）中会因其恒功率负载（CPL）行为导致的负增量阻抗（NII）和低惯性问题而引发稳定性问题。

Method: 提出了一种复合控制器，结合了全局积分终端滑模控制器和反步控制器。通过引入虚拟电容器来解决低惯性问题。采用改进的分数幂到达律来减少抖动并加速收敛。利用精确反馈线性化将非线性升压变换器模型转换为Brunovsky标准型，以解决NII和非最小相位问题。使用李雅普诺夫控制理论进行稳定性验证。

Result: 仿真结果表明，与现有控制器相比，该方法在过冲、下冲和稳定时间方面分别减少了 34.4-53.3%、52.9-74.9% 和 12-47.4%。

Conclusion: 该复合控制器能够有效解决电动汽车集成到直流微电网中引起的稳定性和低惯性问题，并显著提高了系统的动态性能。

Abstract: When electric vehicles (EVs) are integrated into standalone DC microgrids
(DCMGs), stability issues arise due to their constant power load (CPL)
behavior, which provides negative incremental impedance (NII). In addition, the
microgrids suffer from an inherent low-inertia problem. Therefore, this study
presents a composite controller incorporating a global integral terminal
sliding mode controller with a backstepping controller. A virtual capacitor is
employed to mitigate the low-inertia issue and strengthen the DC-bus response.
An improved fractional power-based reaching law decreases chattering and
accelerates convergence. Exact feedback linearization converts the nonlinear
boost converter model into Brunovsky's canonical form, mitigating NII effects
and non-minimum phase issues. The entire system stability is verified using
Lyapunov control theory. Simulation outcomes confirm superior performance, with
34.4-53.3% reduction in overshoot, 52.9-74.9% in undershoot, and 12-47.4% in
settling time compared to the existing controller.

</details>


### [340] [A Scenario-based Stochastic Model of using BESS-based Virtual Transmission Lines in Day-Ahead Unit Commitment](https://arxiv.org/abs/2510.22483)
*Qiushi Wang,Xingpeng Li*

Main category: eess.SY

TL;DR: BESS-based VTL is a promising solution for renewable energy integration challenges, outperforming traditional methods in cost reduction and congestion relief.


<details>
  <summary>Details</summary>
Motivation: The rapid increase in renewable energy sources (RES) causes network congestion, impacting grid efficiency and leading to renewable curtailment. Existing deterministic optimization methods show that BESS-based Virtual Transmission Line (VTL) can alleviate these issues.

Method: A scenario-based stochastic security-constrained unit commitment model with VTL (SSCUC-VTL) is proposed. This model incorporates RES forecast errors into commitment decisions and compares VTL's performance against physical transmission lines and standalone BESS.

Result: Simulation results on an enhanced IEEE 24-bus test system show that VTL reduces operational costs by 23% more than a physical transmission line and provides up to 67% more congestion relief than a standalone BESS, especially in systems with solar and wind generation.

Conclusion: VTL, when integrated with BESS, is an effective strategy for mitigating congestion and reducing costs in power systems with high RES penetration, offering superior performance compared to traditional solutions.

Abstract: The rapid increase in renewable energy sources (RES) implementation in the
power system creates more severe network congestion, which may reduce grid
operation efficiency and cause renewable curtailment. Deterministic
optimization for the unit commitment shows that battery energy storage system
(BESS)-based Virtual Transmission Line (VTL), as an alternative to physical
transmission lines, can offer a quick solution for congestion relief, reduced
operational costs, and lowered renewable curtailment. This paper aims to
evaluate the benefits of VTL when considering Renewable Energy Sources
uncertainty. Particularly, this work proposes a scenario-based stochastic
security-constrained unit commitment model considering VTL, referred to as
SSCUC-VTL. It incorporates the forecast error of RES into the commitment
decision for systems with VTL. The performance of applying the VTL strategy is
compared to that of adding a new physical transmission line and a standalone
BESS. A case study has been conducted on an enhanced IEEE 24-bus test system.
The simulation results demonstrate that VTL provides 23% more operational cost
reduction than the physical transmission line, and up to 67% more congestion
relief than the standalone BESS in a power system with solar and wind
generation.

</details>


### [341] [Functional Uncertainty Classes, Nonparametric Adaptive Contro Functional Uncertainty Classes for Nonparametric Adaptive Control: the Curse of Dimensionality](https://arxiv.org/abs/2510.22496)
*Haoran Wang,Shengyuan Niu,Henry Moon,Ian Willebeek-LeMair,Andrew J. Kurdila,Andrea L'Afflitto,Daniel Stilwell*

Main category: eess.SY

TL;DR: 本文提出了一种新的向量值再生核希尔伯特空间（vRKHS）类，该空间基于算子值核定义，用于表示非参数自适应控制方法中出现的函数不确定性。


<details>
  <summary>Details</summary>
Motivation: 为了解决某些非参数自适应控制策略中可能出现的“维数灾难”问题。

Method: 本文推导了流形上的 vRKHS，其中流形被假设为近似支持要跟踪的参考系统的最终动力学。

Result: 定义了流形上的 vRKHS，以处理函数不确定性。

Conclusion: 所提出的 vRKHS 为解决非参数自适应控制中的“维数灾难”问题提供了一种新的表示方法。

Abstract: This paper derives a new class of vector-valued reproducing kernel Hilbert
spaces (vRKHS) defined in terms of operator-valued kernels for the
representation of functional uncertainty arising in nonparametric adaptive
control methods. These are referred to as maneuver or trajectory vRKHS KM in
the paper, and they are introduced to address the curse of dimensionality that
can arise for some types of nonparametric adaptive control strategies. The
maneuver vRKHSs are derived based on the structure of a compact, l-dimensional,
smooth Riemannian manifold M that is regularly embedded in the state space X =
Rn, where M is assumed to approximately support the ultimate dynamics of the
reference system to be tracked.

</details>


### [342] [Robust Multi-Agent Safety via Tube-Based Tightened Exponential Barrier Functions](https://arxiv.org/abs/2510.22514)
*Armel Koulong,Ali Pakniyat*

Main category: eess.SY

TL;DR: 该论文提出了一种为受界限干扰的非线性多智能体系统合成可证明安全控制器的框架。


<details>
  <summary>Details</summary>
Motivation: 为受界限干扰的非线性多智能体系统提供一种可证明的安全控制器合成方法。

Method: 采用约束强化技术，将鲁棒误差反馈与标称轨迹规划相结合。通过设计一个辅助反馈律，将状态误差约束在鲁棒正不变（RPI）管内，并利用RPI管的几何形状（通过其支撑函数）推导出状态相关的安全裕度，然后用以强化控制障碍函数（eCBF）约束，最终整合合成保证了标称轨迹的安全性。

Result: 实现了将形式合成方法应用于分布式模型预测控制（MPC）方案，在优化性能的同时继承了鲁棒安全保证。

Conclusion: 所提出的框架能够为非线性多智能体系统合成可证明安全的控制器，并通过与MPC结合，在保证安全性的前提下优化系统性能。

Abstract: This paper presents a constructive framework for synthesizing provably safe
controllers for nonlinear multi-agent systems subject to bounded disturbances.
The methodology applies to systems representable in Brunovsky canonical form,
accommodating arbitrary-order dynamics in multi-dimensional spaces. The central
contribution is a method of constraint tightening that formally couples robust
error feedback with nominal trajectory planning. The key insight is that the
design of an ancillary feedback law, which confines state errors to a robust
positively invariant (RPI) tube, simultaneously provides the exact information
needed to ensure the safety of the nominal plan. Specifically, the geometry of
the resulting RPI tube is leveraged via its support function to derive
state-dependent safety margins. These margins are then used to systematically
tighten the high relative-degree exponential control barrier function (eCBF)
constraints imposed on the nominal planner. This integrated synthesis
guarantees that any nominal trajectory satisfying the tightened constraints
corresponds to a provably safe trajectory for the true, disturbed system. We
demonstrate the practical utility of this formal synthesis method by
implementing the planner within a distributed Model Predictive Control (MPC)
scheme, which optimizes performance while inheriting the robust safety
guarantees.

</details>


### [343] [Approximate Gradient Coding for Distributed Learning with Heterogeneous Stragglers](https://arxiv.org/abs/2510.22539)
*Heekang Song,Wan Choi*

Main category: eess.SY

TL;DR: 提出了一种最优梯度编码方案，以减轻分布式学习中的慢启动问题。


<details>
  <summary>Details</summary>
Motivation: 现有梯度编码方法在处理异构慢启动模型或过度数据复制方面存在局限性。本研究旨在通过考虑个体慢启动概率来优化编码方案，以减少残差误差并确保梯度估计的无偏性。

Method: 通过拉格朗日对偶和凸优化推导出最优编码和解码系数的闭式解，并提出数据分配策略以减少冗余和计算量。同时分析了λ-强凸和μ-光滑损失函数的收敛行为。

Result: 数值结果表明，与现有方法相比，该方法显著降低了慢启动的影响并加速了收敛。

Conclusion: 所提出的最优结构梯度编码方案能够有效解决分布式学习中的慢启动问题，并在异构系统中实现更优的性能。

Abstract: In this paper, we propose an optimally structured gradient coding scheme to
mitigate the straggler problem in distributed learning. Conventional gradient
coding methods often assume homogeneous straggler models or rely on excessive
data replication, limiting performance in real-world heterogeneous systems. To
address these limitations, we formulate an optimization problem minimizing
residual error while ensuring unbiased gradient estimation by explicitly
considering individual straggler probabilities. We derive closed-form solutions
for optimal encoding and decoding coefficients via Lagrangian duality and
convex optimization, and propose data allocation strategies that reduce both
redundancy and computation load. We also analyze convergence behavior for
$\lambda$-strongly convex and $\mu$-smooth loss functions. Numerical results
show that our approach significantly reduces the impact of stragglers and
accelerates convergence compared to existing methods.

</details>


### [344] [Ellipsoidal Set-Theoretic Design of Robust Safety Filters for Constrained Linear Systems](https://arxiv.org/abs/2510.22790)
*Reza Pordal,Alireza Sharifi,Ali Baniasad*

Main category: eess.SY

TL;DR: 该研究提出了一种基于椭球集理论的鲁棒安全滤波器合成框架，用于处理受扰动和输入约束的线性系统。


<details>
  <summary>Details</summary>
Motivation: 为受限于扰动和输入约束的线性系统设计鲁棒安全滤波器。

Method: 将安全滤波器设计转化为凸线性矩阵不等式（LMI）优化问题，同时计算鲁棒受控不变（RCI）椭球集和状态反馈控制律。RCI集以椭球集为特征，允许计算上的可处理性，并提供正式的安全保证。该滤波器采用基于与不变集边界距离的平滑混合策略，以最小化对安全运行系统的干预。该方法通过将非线性项视为有界扰动并进行近似，可以扩展到非线性系统。

Result: 在六自由度四旋翼飞行器系统上进行了数值验证，证明了该滤波器在外部干扰和剧烈机动下保持稳定性的有效性，并在安全运行时保持标称性能。

Conclusion: 该方法为需要实时实现的具实时性要求的安全关键控制应用提供了一种构造性且计算高效的解决方案。

Abstract: This paper presents an ellipsoidal set-theoretic framework for robust safety
filter synthesis in constrained linear systems subject to additive bounded
disturbances and input constraints. We formulate the safety filter design as a
convex linear matrix inequality (LMI) optimization problem that simultaneously
computes a robust controlled invariant (RCI) ellipsoidal set and its associated
state-feedback control law. The RCI set is characterized as an ellipsoidal set,
enabling computational tractability for high-dimensional systems while
providing formal safety guarantees. The safety filter employs a smooth mixing
strategy between nominal and backup controllers based on distance to the
invariant set boundary, facilitating minimal intervention when the system
operates safely. The proposed method extends to nonlinear systems by treating
nonlinear terms as bounded disturbances with rigorous approximation bounds.
Numerical validation on a six-degree-of-freedom quadrotor system demonstrates
the filter's effectiveness in maintaining stability under external disturbances
and aggressive maneuvers while preserving nominal performance during safe
operation. The approach provides a constructive and computationally efficient
solution for safety-critical control applications requiring real-time
implementation.

</details>


### [345] [Residual Bias Compensation Filter for Physics-Based SOC Estimation in Lithium Iron Phosphate Batteries](https://arxiv.org/abs/2510.22813)
*Feng Guo,Luis D. Couto,Khiem Trad,Guangdi Hu,Mohammadhosein Safari*

Main category: eess.SY

TL;DR: 该研究提出了一种残差偏差补偿双扩展卡尔曼滤波器（RBC-DEKF）来解决磷酸铁锂（LFP）电池荷电状态（SOC）估算中因开路电压（OCV-SOC）特性平坦导致的观测性降低问题。


<details>
  <summary>Details</summary>
Motivation: 磷酸铁锂电池的OCV-SOC特性平坦导致SOC估算精度低，需要改进估算方法。

Method: 提出一种RBC-DEKF，通过双滤波器解耦残差偏差估算和电化学状态估算，其中一个EKF估算电池状态，另一个EKF估算残差偏差来实时修正电压观测方程。

Result: 在US06（0°C）、DST（25°C）和FUDS（50°C）三种工况下，RBC-DEKF将平均SOC均方根误差（RMSE）从3.75%降低到0.20%，电压RMSE从32.8 mV降低到0.8 mV。

Conclusion: RBC-DEKF显著提高了LFP电池在宽温度范围内基于模型的SOC估算精度，尤其在中SOC区域效果明显。

Abstract: This paper addresses state of charge (SOC) estimation for lithium iron
phosphate (LFP) batteries, where the relatively flat open-circuit voltage
(OCV-SOC) characteristic reduces observability. A residual bias compensation
dual extended Kalman filter (RBC-DEKF) is developed. Unlike conventional bias
compensation methods that treat the bias as an augmented state within a single
filter, the proposed dual-filter structure decouples residual bias estimation
from electrochemical state estimation. One EKF estimates the system states of a
control-oriented parameter-grouped single particle model with thermal effects,
while the other EKF estimates a residual bias that continuously corrects the
voltage observation equation, thereby refining the model-predicted voltage in
real time. Unlike bias-augmented single-filter schemes that enlarge the
covariance coupling, the decoupled bias estimator refines the voltage
observation without perturbing electrochemical state dynamics. Validation is
conducted on an LFP cell from a public dataset under three representative
operating conditions: US06 at 0 degC, DST at 25 degC, and FUDS at 50 degC.
Compared with a conventional EKF using the same model and identical state
filter settings, the proposed method reduces the average SOC RMSE from 3.75% to
0.20% and the voltage RMSE between the filtered model voltage and the measured
voltage from 32.8 mV to 0.8 mV. The improvement is most evident in the mid-SOC
range where the OCV-SOC curve is flat, confirming that residual bias
compensation significantly enhances accuracy for model-based SOC estimation of
LFP batteries across a wide temperature range.

</details>


### [346] [Transmission Neural Networks: Approximate Receding Horizon Control for Virus Spread on Networks](https://arxiv.org/abs/2510.22871)
*Shuang Gao,Peter E. Caines*

Main category: eess.SY

TL;DR: TransNNs是Gao和Caines（2022）提出的模型，可作为网络上传播的病毒模型和具有可调激活函数的神经网络模型。本文证明了TransNNs可以作为SIS模型的上界，并提出了一种基于TransNN的递推控制方法来缓解病毒传播，该方法在计算上比动态规划更节省，并且控制行为比基于TransNN的最优控制更不保守。


<details>
  <summary>Details</summary>
Motivation: 本文旨在研究Transmission Neural Networks (TransNNs) 作为病毒传播模型和神经网络模型的潜力，并提出一种基于TransNN的控制方法来缓解病毒传播。

Method: 本文证明了TransNNs可以作为SIS模型的上界，并提出了一种基于TransNN的递推控制方法来缓解病毒传播。

Result: 所提出的TransNN-based递推控制方法在计算上比动态规划更节省，并且控制行为比基于TransNN的最优控制更不保守。最后通过数值比较了动态规划、TransNN-based最优控制和TransNN-based递推控制的效果。

Conclusion: TransNNs可作为SIS模型的上界和近似模型，基于TransNN的递推控制方法是一种有效且计算效率高的缓解病毒传播的策略。

Abstract: Transmission Neural Networks (TransNNs) proposed by Gao and Caines (2022)
serve as both virus spread models over networks and neural network models with
tuneable activation functions. This paper establishes that TransNNs provide
upper bounds on the infection probability generated from the associated
Markovian stochastic Susceptible-Infected-Susceptible (SIS) model with 2^n
state configurations where n is the number of nodes in the network, and can be
employed as an approximate model for the latter. Based on such an
approximation, a TransNN-based receding horizon control approach for mitigating
virus spread is proposed and we demonstrate that it allows significant
computational savings compared to the dynamic programming solution to Markovian
SIS model with 2^n state configurations, as well as providing less conservative
control actions compared to the TransNN-based optimal control. Finally,
numerical comparisons among (a) dynamic programming solutions for the Markovian
SIS model, (b) TransNN-based optimal control and (c) the proposed TransNN-based
receding horizon control are presented.

</details>


### [347] [NeuroDOB: A Deep Neural Observer-Based Controller for Vehicle Lateral Dynamics](https://arxiv.org/abs/2510.23067)
*Sangmin Kim,Taehun Kim,Guntae Kim,Chang Mook Kang*

Main category: eess.SY

TL;DR: 本文提出了一种名为NeuroDOB的深度神经网络（DNN）控制器，用于车辆横向动力学控制，旨在增强个性化横向控制。


<details>
  <summary>Details</summary>
Motivation: 传统扰动观测器（DOB）难以处理车辆未建模动力学和驾驶员特定行为，因此需要一种能够学习和补偿这些因素的新型控制器。

Method: NeuroDOB将DNN集成到LQR控制器中，DNN学习生成转向补偿信号，以修正LQR的基线转向输入。DNN的输入特征包括横向位置和偏航角误差以及LQR控制输入。通过驾驶员在环仿真（使用CarSim作为替代驾驶员）进行训练。

Result: 在CarSim的横向动力学自行车模型上进行的实验验证表明，NeuroDOB能够有效适应个体驾驶习惯，并提高横向控制性能，优于传统的LQR控制器。

Conclusion: NeuroDOB作为一种基于深度学习的观测器，能够实现个性化和自适应的自动车辆控制，其双系统结构（LQR作为系统1，NeuroDOB作为系统2）类似于人类的直觉-反思交互，能够同时保证稳定性和适应性。

Abstract: This paper proposes NeuroDOB, a deep neural network based observer controller
for vehicle lateral dynamics, which replaces the conventional disturbance
observer (DOB) with a deep neural network (DNN) to enhance personalized lateral
control. Unlike conventional DOBs that compensate for general disturbances such
as road friction variation and crosswind, NeuroDOB explicitly addresses
unmodeled vehicle dynamics and driver-specific behaviors by learning the
steering compensation signal from driver-in-the-loop simulations using CarSim's
embedded controller as a surrogate driver. The proposed architecture integrates
NeuroDOB with a linear quadratic regulator (LQR), where the DNN outputs a delta
error correction added to the baseline LQR steering input to produce the final
control command. Input features to the DNN include lateral position and yaw
angle errors, and the LQR control input. Experimental validation using a
lateral dynamic bicycle model within CarSim demonstrates that NeuroDOB
effectively adapts to individual driving habits, improving lateral control
performance beyond what conventional LQR controllers achieve. The results
indicate the potential of deep neural network based observer to enable
personalized and adaptive autonomous vehicle control. In cognitive terms, the
proposed architecture can be viewed as a dual-system control structure. The
baseline LQR corresponds to System 1, a model-based, fast, and analytic
reasoning layer ensuring stability. The NeuroDOB acts as System 2, a
reflective, data-driven layer that learns compensation from experience and
corrects the analytical bias of System 1. Together, they form an integrated
decision process analogous to human intuition-reflection interaction, enabling
both stability and adaptability in lateral control.

</details>


### [348] [Context-awareness for Dependable Low-Power IoT](https://arxiv.org/abs/2510.23125)
*David E. Ruiz-Guirola,Prasoon Raghuwanshi,Gabriel M. de Jesus,Mateen Ashraf,Onel L. A. López*

Main category: eess.SY

TL;DR: 为能源受限的物联网网络设计了一个包含四个关键上下文维度（能量、信息新鲜度、任务相关性和物理/介质条件）的两步协议设计框架，以提高系统的可靠性。


<details>
  <summary>Details</summary>
Motivation: 确保大规模、能源受限的物联网部署的可靠运行至关重要且充满挑战，需要上下文感知的协议。

Method: 识别四个关键的上下文维度（能量状态、信息新鲜度、任务相关性和物理/介质条件），并展示它们如何支撑核心的可靠性属性。在此基础上，提出一个包含特定操作上下文字段的两步协议设计框架。

Result: 通过三个代表性的用例，展示了上下文感知如何在施加最小的控制平面开销的情况下显著提高系统可靠性。

Conclusion: 上下文感知可以显著提高系统可靠性，同时施加最小的控制平面开销。

Abstract: Dependability is the ability to consistently deliver trusted and
uninterrupted service in the face of operational uncertainties. Ensuring
dependable operation in large-scale, energy-constrained Internet of Things
(IoT) deployments is as crucial as challenging, and calls for context-aware
protocols where context refers to situational or state information. In this
paper, we identify four critical context dimensions for IoT networks, namely
energy status, information freshness, task relevance, and physical/medium
conditions, and show how each one underpins core dependability attributes.
Building on these insights, we propose a two-step protocol design framework
that incorporates operation-specific context fields. Through three
representative use cases, we demonstrate how context awareness can
significantly enhance system dependability while imposing only minimal
control-plane overhead.

</details>


### [349] [Embroidery Actuator Utilizing Embroidery Patterns to Generate Diverse Fabric Deformations](https://arxiv.org/abs/2510.23188)
*Yuki Ota,Yuki Funabora*

Main category: eess.SY

TL;DR: 本文提出了一种将可充气管线通过绣花工艺缝合到织物上，并利用绣花线和织物共同形成套筒来限制气管膨胀，从而实现可控形变的织物气动驱动器。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统织物驱动器依赖线状驱动器的限制，提出一种通过绣花图案设计实现多样化和可控变形的新型织物气动驱动器。

Method: 通过绣花工艺将可充气管线直接缝合到织物上，形成套筒结构。利用Neo-Hookean模型和拉格朗日方程建立气压与弯曲角度的解析变形模型，并通过动作捕捉实验进行验证。

Result: 实验结果表明，该驱动器的实际形变与解析变形模型预测结果高度吻合。

Conclusion: 该研究成功开发了一种新型的织物气动驱动器，并通过实验验证了其性能，为实现可控的织物变形提供了新的方法。

Abstract: This paper presents a novel Embroidery Actuator, a fabric-integrated
pneumatic actuator that enables diverse and controllable deformations through
embroidery pattern design. Unlike conventional fabric actuators that rely on
fiber- or thread-shaped actuators, the proposed actuator is fabricated by
directly stitching an inflatable tube onto the fabric using a cord-embroidery
technique. The embroidered thread and the fabric jointly form a sleeve that
constrains the expansion of the inflatable tube, converting internal pressure
into targeted bending or stretching deformations. By varying the embroidery
pattern, such as zigzag or cross configurations, different geometric
constraints can be realized, allowing for flexible control of deformation
direction and magnitude. Analytical deformation models based on the Neo-Hookean
model and Lagrange's equations were developed to predict the relationship
between pneumatic pressure and bending angle, and were experimentally validated
using motion-capture measurements. The results demonstrated that the actuator
achieves strong agreement with the analytical deformation model.

</details>


### [350] [Neural Networks for AC Optimal Power Flow: Improving Worst-Case Guarantees during Training](https://arxiv.org/abs/2510.23196)
*Bastien Giraud,Rahul Nellikath,Johanna Vorwerk,Maad Alowaifeer,Spyros Chatzivasileiadis*

Main category: eess.SY

TL;DR: 提出了一种结合验证信息的神经网络框架，用于解决交流最优潮流（AC-OPF）问题，旨在提高预测的准确性和安全性，减少约束违反，并实现大规模AC-OPF代理的所有运行约束的验证。


<details>
  <summary>Details</summary>
Motivation: 交流最优潮流（AC-OPF）问题在电力系统运行中至关重要，但由于其非凸和非线性的性质，难以高效求解。现有的神经网络（NN）虽然能提供快速的替代方案，但其黑盒特性引发了对可能危及安全的约束违反的担忧。

Method: 提出了一种结合验证信息的神经网络框架，在训练中直接考虑最坏情况下的约束违反，从而得到既准确又具有可证明安全性的模型。通过事后验证，显著减少了最坏情况下的违反，并首次验证了大规模AC-OPF代理的所有运行约束。此外，还采用了恢复和热启动策略来处理不可行的操作点，以提高实际可行性。

Result: 实验在包含57至793个节点的系统中进行了测试，结果证明了该方法的可扩展性、速度和可靠性，有效缩小了机器学习加速与AC-OPF解决方案安全、实时部署之间的差距。

Conclusion: 该研究提出的框架通过在训练中考虑最坏情况下的约束违反，并结合事后验证和可行性策略，成功解决了AC-OPF问题的安全性和效率问题，为数据驱动的最优控制铺平了道路。

Abstract: The AC Optimal Power Flow (AC-OPF) problem is central to power system
operation but challenging to solve efficiently due to its nonconvex and
nonlinear nature. Neural networks (NNs) offer fast surrogates, yet their
black-box behavior raises concerns about constraint violations that can
compromise safety. We propose a verification-informed NN framework that
incorporates worst-case constraint violations directly into training, producing
models that are both accurate and provably safer. Through post-hoc
verification, we achieve substantial reductions in worst-case violations and,
for the first time, verify all operational constraints of large-scale AC-OPF
proxies. Practical feasibility is further enhanced via restoration and
warm-start strategies for infeasible operating points. Experiments on systems
ranging from 57 to 793 buses demonstrate scalability, speed, and reliability,
bridging the gap between ML acceleration and safe, real-time deployment of
AC-OPF solutions - and paving the way toward data-driven optimal control.

</details>


### [351] [Inertia Partitioning Modular Control Framework for Reconfigurable Multibody Systems](https://arxiv.org/abs/2510.23226)
*Mohammad Dastranj,Jouni Mattila*

Main category: eess.SY

TL;DR: 提出了一种新颖的模块化控制框架，用于可重构刚体制动器系统，以应对具有闭环运动链的系统的模块化控制挑战。


<details>
  <summary>Details</summary>
Motivation: 该框架的动机是解决具有闭环运动链的可重构刚体制动器系统的模块化控制的挑战。

Method: 该框架根据自由度定义模块化，并根据每个惯性属性在系统动能中反映的方式来划分每个主体的惯性属性。

Result: 通过在三自由度串联-并联机械手上进行仿真实现了该框架，结果与预期的稳定性和跟踪性能一致，并表明了该框架在多体系统轨迹跟踪控制方面的可扩展潜力。

Conclusion: 所提出的框架通过一种新颖的模块化方法自然地处理闭环，无需显式约束力计算或基于微分代数方程的公式。

Abstract: A novel modular control framework for reconfigurable rigid multibody systems
is proposed, motivated by the challenges of modular control of systems with
closed kinematic chains. In the framework, modularity is defined in the sense
of degrees of freedom, and the inertial properties of each body are partitioned
with respect to how they are reflected in the kinetic energy of the system
through the motion induced by each degree of freedom. This approach inherently
handles closed chains in the same manner as tree-like structures, eliminating
the need for explicit constraint force calculations or formulations based on
differential-algebraic equations. The proposed framework is implemented via
simulation on a three-degree-of-freedom series-parallel manipulator, with the
results being consistent with the expected stability and tracking performance,
and indicating the framework's potential for scalability in trajectory-tracking
control of multibody systems.

</details>


### [352] [Payload trajectory tracking control for aerial transportation systems with cable length online optimization](https://arxiv.org/abs/2510.23296)
*Hai Yu,Zhichao Yang,Wei He,Jianda Han,Yongchun Fang,Xiao Liang*

Main category: eess.SY

TL;DR: 该研究提出了一种用于变长缆绳悬挂空中交通系统的反步控制策略，实现了精确的轨迹跟踪和动态缆绳长度调整。


<details>
  <summary>Details</summary>
Motivation: 空中交通系统，特别是配备变长缆绳的系统，因其灵活性而备受关注，但变长缆绳引入了更高的非线性和耦合度，给控制设计带来了挑战。

Method: 提出了一种反步控制策略，并开发了一个能够在线优化缆绳长度并满足状态约束的缆绳长度生成器，实现了多旋翼运动与缆绳长度变化的平衡。

Result: 仿真结果验证了所提出方法在轨迹跟踪和缆绳长度调整方面的有效性。

Conclusion: 所提出的反步控制策略和缆绳长度生成器能够有效地管理变长缆绳空中交通系统的轨迹跟踪和缆绳长度调整，并保证了闭环系统的渐近稳定性。

Abstract: Cable-suspended aerial transportation systems are employed extensively across
various industries. The capability to flexibly adjust the relative position
between the multirotor and the payload has spurred growing interest in the
system equipped with variable-length cable, promising broader application
potential. Compared to systems with fixed-length cables, introducing the
variable-length cable adds a new degree of freedom. However, it also results in
increased nonlinearity and more complex dynamic coupling among the multirotor,
the cable and the payload, posing significant challenges in control design.
This paper introduces a backstepping control strategy tailored for aerial
transportation systems with variable-length cable, designed to precisely track
the payload trajectory while dynamically adjusting cable length. Then, a cable
length generator has been developed that achieves online optimization of the
cable length while satisfying state constraints, thus balancing the
multirotor's motion and cable length changes without the need for manual
trajectory planning. The asymptotic stability of the closed-loop system is
guaranteed through Lyapunov techniques and the growth restriction condition.
Finally, simulation results confirm the efficacy of the proposed method in
managing trajectory tracking and cable length adjustments effectively.

</details>


### [353] [An Error-Based Safety Buffer for Safe Adaptive Control (Extended Version)](https://arxiv.org/abs/2510.23491)
*Peter A. Fisher,Johannes Autenrieb,Anuradha M. Annaswamy*

Main category: eess.SY

TL;DR: 本研究提出了一种结合自适应和控制障碍函数（CBF）的实时控制方法，用于处理具有匹配参数不确定性和状态约束的反馈线性化系统，以保证稳定性和安全性。


<details>
  <summary>Details</summary>
Motivation: 处理具有匹配参数不确定性和状态约束的反馈线性化系统的自适应控制问题，同时确保稳定性和安全性。

Method: 将自适应和控制障碍函数（CBF）相结合，构建了一个实时控制架构。CBF具有任意相对度。

Result: 所提出的方法保证了系统的稳定性、控制性能和安全性，同时实现了近乎零的保守性。不需要对命令信号施加激励条件。

Conclusion: 该方法能够有效地处理具有参数不确定性和状态约束的系统，并满足稳定性和安全目标，如模拟结果所示。

Abstract: We consider the problem of adaptive control of a class of feedback
linearizable plants with matched parametric uncertainties whose states are
accessible, subject to state constraints, which often arise due to safety
considerations. In this paper, we combine adaptation and control barrier
functions into a real-time control architecture that guarantees stability,
ensures control performance, and remains safe even with the parametric
uncertainties. Two problems are considered, differing in the nature of the
parametric uncertainties. In both cases, the control barrier function is
assumed to have an arbitrary relative degree. In addition to guaranteeing
stability, it is proved that both the control objective and safety objective
are met with near-zero conservatism. No excitation conditions are imposed on
the command signal. Simulation results demonstrate the non-conservatism of all
of the theoretical developments.

</details>


### [354] [Towards Stochastic (N-1)-Secure Redispatch](https://arxiv.org/abs/2510.23551)
*Oleksii Molodchyk,Hendrik Drögehorn,Martin Lindner,Mario Kendziorski,Timm Faulwasser*

Main category: eess.SY

TL;DR: 该研究提出了一种迭代方法来解决安全约束下的随机最优潮流问题，以应对可再生能源发电的不确定性。


<details>
  <summary>Details</summary>
Motivation: 可再生能源的不确定性给电网带来了挑战，需要经济调度来保证电网的稳定运行，但现有的随机最优潮流方法尚未探索在(N-1)安全约束下的应用。

Method: 提出了一种迭代方法，通过求解包含多项式混沌展开（PCE）的安全约束随机最优潮流问题，并逐步加入线路故障约束，直至达到(N-1)安全标准。

Result: 通过在一个118节点的系统上进行实验，并将所提方法与蒙特卡洛模拟进行比较，验证了该方法的有效性。

Conclusion: 该研究成功地将PCE方法应用于(N-1)安全约束下的随机最优潮流问题，并提出了一种有效的迭代求解方法。

Abstract: The intermittent nature of renewable power availability is one of the major
sources of uncertainty in power systems. While markets can guarantee that the
demand is covered by the available generation, transmission system operators
have to often intervene via economic redispatch to ensure that the physical
constraints of the network are satisfied. To account for uncertainty, the
underlying optimal power flow (OPF) routines have to be modified. Recently,
polynomial chaos expansion (PCE) has been suggested in the literature as a tool
for stochastic OPF problems. However, the usage of PCE-based methods in
security-constrained OPF for (N-1)-secure operations has not yet been explored.
In this paper, we propose a procedure that iteratively solves a PCE-overloaded
stochastic OPF problem by including line outage constraints until an
(N-1)-secure solution is achieved. We demonstrate the efficacy of our method by
comparing it with a Monte-Carlo simulation on a 118-bus example system.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [355] [A Multi-Component AI Framework for Computational Psychology: From Robust Predictive Modeling to Deployed Generative Dialogue](https://arxiv.org/abs/2510.21720)
*Anant Pareek*

Main category: cs.AI

TL;DR: 本论文提出一个整合预测模型和交互式系统的计算心理学框架，克服了工程挑战，并成功部署了一个包含预测和生成模型的微服务生态系统。


<details>
  <summary>Details</summary>
Motivation: 整合孤立的预测模型与交互式心理分析系统，以计算方法模拟、理解和交互复杂的人类心理状态。

Method: 首先，使用经典机器学习技术在四个心理学数据集上建立性能基准。其次，对先进的Transformer模型进行微调，解决了数值不稳定性等工程挑战。第三，使用参数高效技术微调了一个生成式大语言模型，作为交互式“人格大脑”。最后，将所有模型部署为可扩展的微服务生态系统。

Result: 成功稳定了基于Transformer的回归模型，在情感计算方面取得了有意义的预测性能，并开发了一种可复制的方法来普及大规模AI研究。

Conclusion: 该研究通过整合预测分析和生成对话，展示了一个完整的从研究到部署的流程，为计算心理学和人机交互的未来研究提供了一个实用的模型。

Abstract: The confluence of Artificial Intelligence and Computational Psychology
presents an opportunity to model, understand, and interact with complex human
psychological states through computational means. This paper presents a
comprehensive, multi-faceted framework designed to bridge the gap between
isolated predictive modeling and an interactive system for psychological
analysis. The methodology encompasses a rigorous, end-to-end development
lifecycle. First, foundational performance benchmarks were established on four
diverse psychological datasets using classical machine learning techniques.
Second, state-of-the-art transformer models were fine-tuned, a process that
necessitated the development of effective solutions to overcome critical
engineering challenges, including the resolution of numerical instability in
regression tasks and the creation of a systematic workflow for conducting
large-scale training under severe resource constraints. Third, a generative
large language model (LLM) was fine-tuned using parameter-efficient techniques
to function as an interactive "Personality Brain." Finally, the entire suite of
predictive and generative models was architected and deployed as a robust,
scalable microservices ecosystem. Key findings include the successful
stabilization of transformer-based regression models for affective computing,
showing meaningful predictive performance where standard approaches failed, and
the development of a replicable methodology for democratizing large-scale AI
research. The significance of this work lies in its holistic approach,
demonstrating a complete research-to-deployment pipeline that integrates
predictive analysis with generative dialogue, thereby providing a practical
model for future research in computational psychology and human-AI interaction.

</details>


### [356] [PREFINE: Personalized Story Generation via Simulated User Critics and User-Specific Rubric Generation](https://arxiv.org/abs/2510.21721)
*Kentaro Ueda,Takehiro Takayanagi*

Main category: cs.AI

TL;DR: PREFINE框架通过构建伪用户代理和生成用户特定标准，在无需更新模型参数或用户直接反馈的情况下，实现了个性化文本生成。


<details>
  <summary>Details</summary>
Motivation: 现有的个性化创意文本生成方法存在用户负担、数据收集、计算成本和隐私等实际问题。

Method: PREFINE框架扩展了Critique-and-Refine范式，通过构建伪用户代理并生成用户特定标准，让代理代表用户进行评估和优化，从而实现个性化。

Result: 在PerDOC和PerMPST故事数据集上的评估显示，PREFINE在自动评估（LLM-as-a-Judge）中优于基线方法，并且模型变体分析证实了伪用户代理和用户特定标准对于提升个性化性能至关重要。

Conclusion: PREFINE框架能够有效实现个性化文本生成，且在更广泛的应用领域具有潜力。

Abstract: While recent advances in Large Language Models (LLMs) have improved the
quality of creative text generation, significant challenges remain in producing
personalized stories that reflect individual user preferences. Conventional
approaches rely on explicit feedback or fine-tuning, which presents practical
issues regarding user burden, data collection, computational costs, and
privacy. In this work, we propose PREFINE (Persona-and-Rubric Guided
Critique-and-Refine), a novel framework that extends the Critique-and-Refine
paradigm to personalization. PREFINE constructs a pseudo-user agent from a
user's interaction history and generates user-specific rubrics (evaluation
criteria). By having this agent critique and refine outputs on the user's
behalf based on these tailored rubrics, our method achieves personalized
generation without requiring parameter updates or direct user feedback. We
conducted a comprehensive evaluation on the PerDOC and PerMPST story datasets.
We designed three baseline methods and several model variants to verify the
contribution of each component of our framework. In automatic evaluations
(LLM-as-a-Judge), PREFINE achieved higher win rates and statistically
significant scores than the baselines, without compromising general story
quality. Analysis of the model variants confirmed that both the pseudo-user
agent and the user-specific rubrics are crucial for enhancing personalization
performance. Beyond story generation, our approach holds potential for enabling
efficient personalization in broader applications, such as dialogue systems,
education, and recommendation.

</details>


### [357] [SIGN: Schema-Induced Games for Naming](https://arxiv.org/abs/2510.21855)
*Ryan Zhang,Herbert Woisetscläger*

Main category: cs.AI

TL;DR: LLM代理在处理复杂问题时，一致性协调至关重要。引入SIGN（Schema-Induced Games for Naming）通过轻量级结构促进约定形成，与无约束自然语言相比，能更快达成更高一致性（最高5.8倍）。


<details>
  <summary>Details</summary>
Motivation: 当LLM代理在处理复杂问题时，如果它们的约定不一致，协调就会失败。因此，协作编码和分布式规划等应用需要可靠、一致的通信，并且随着系统规模的扩大，可扩展性是一个核心问题。

Method: 引入SIGN（Schema-Induced Games for Naming），一个命名游戏，研究轻量级结构如何引导约定形成。

Result: 与无约束的自然语言相比，SIGN能够更快地实现高达5.8倍的一致性。

Conclusion: 最小的结构可以作为高效多代理协调的简单控制手段，这表明其应用前景广阔，超越了命名游戏本身。

Abstract: Real-world AI systems are tackling increasingly complex problems, often
through interactions among large language model (LLM) agents. When these agents
develop inconsistent conventions, coordination can break down. Applications
such as collaborative coding and distributed planning therefore require
reliable, consistent communication, and scalability is a central concern as
systems grow. We introduce Schema-Induced Games for Naming (SIGN), a naming
game that examines how lightweight structure can steer convention formation. We
compare schema-induced communication to unconstrained natural language and find
faster convergence with up to 5.8x higher agreement. These results suggest that
minimal structure can act as a simple control knob for efficient multi-agent
coordination, pointing toward broader applications beyond the naming game.

</details>


### [358] [Capability Ceilings in Autoregressive Language Models: Empirical Evidence from Knowledge-Intensive Tasks](https://arxiv.org/abs/2510.21866)
*Javier Marín*

Main category: cs.AI

TL;DR: decoder-only模型在知识密集型任务上存在能力瓶颈，参数扩展带来的准确性提升甚微，且模型对注意力扰动敏感。


<details>
  <summary>Details</summary>
Motivation: 为了探究decoder-only自回归语言模型的经验能力上限，特别是在知识密集型任务上的表现。

Method: 对OPT和Pythia模型家族（70M-30B参数）进行系统性评估，并进行注意力干预实验。

Result: 在知识检索任务上，模型准确性几乎没有提升，而损失平滑下降。MMLU数学基准测试中，准确性在所有尺度下均保持在19-20%（低于25%的随机猜测），但交叉熵损失下降了31%。算术等程序性任务则表现出常规的量化，准确性和损失同步提升。注意力干预实验表明模型对扰动高度敏感，注意力模式的交换会导致灾难性的性能崩溃。

Conclusion: 对于使用OPT和Pythia架构的知识密集型应用，超过1-2B参数的扩展带来的准确性增益极小。这些发现量化了模型家族在特定能力上的量化失败，可为资源分配提供参考。模型行为是由于decoder-only架构的基本限制还是实现特定限制尚待研究。

Abstract: We document empirical capability ceilings in decoder-only autoregressive
language models across knowledge-intensive tasks. Systematic evaluation of OPT
and Pythia model families (70M-30B parameters, spanning 240 times scaling)
reveals that knowledge retrieval tasks show negligible accuracy improvement
despite smooth loss reduction. On MMLU mathematics benchmarks, accuracy remains
flat at 19-20% (below 25% random chance) across all scales while cross-entropy
loss decreases by 31%. In contrast, procedural tasks like arithmetic show
conventional scaling where both metrics improve together. Attention
intervention experiments reveal high sensitivity to perturbation: swapping
attention patterns between models causes catastrophic performance collapse
(complete accuracy loss) rather than graceful degradation. These measurements
have immediate engineering implications: for knowledge-intensive applications
using OPT and Pythia architectures, parameter scaling beyond 1-2B offers
minimal accuracy gains despite continued loss improvement. Our findings
quantify capability-specific scaling failures in these model families to inform
resource allocation decisions. Whether these patterns reflect fundamental
constraints of decoder-only architectures or implementation-specific
limitations remains an open question requiring investigation across diverse
architectural approaches.

</details>


### [359] [Atlas Urban Index: A VLM-Based Approach for Spatially and Temporally Calibrated Urban Development Monitoring](https://arxiv.org/abs/2510.22702)
*Mithul Chander,Sai Pragnya Ranga,Prathamesh Mayekar*

Main category: cs.AI

TL;DR: 我们提出了Atlas Urban Index（AUI），一种利用Sentinel-2卫星图像计算的城市发展指标，旨在克服现有方法（如NDBI）在处理大气噪声、季节性变化和云层覆盖等因素时的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有城市发展指标（如NDBI）在处理大气噪声、季节性变化和云层覆盖等因素时存在不足，难以准确衡量城市发展，阻碍了对人类发展和城市化的广泛监测。

Method: 提出了一种利用视觉语言模型（VLM）为区域提供发展得分的方法。该方法收集区域的时间序列Sentinel-2图像，处理图像以获得代表性图像，并通过提供参考图像和最近的 past 图像来确保评分的一致性。

Result: 定性实验表明，AUI 在班加罗尔的表现优于 NDBI 等标准指标，能够克服传统城市化指数的挑战，并产生更可靠、更稳定的发展得分。

Conclusion: AUI 是一种创新的城市发展指标，通过利用 VLM 和创新的图像处理策略，有效解决了传统指标的局限性，提供了更准确、更稳定的城市发展衡量方法。

Abstract: We introduce the {\em Atlas Urban Index} (AUI), a metric for measuring urban
development computed using Sentinel-2 \citep{spoto2012sentinel2} satellite
imagery. Existing approaches, such as the {\em Normalized Difference Built-up
Index} (NDBI), often struggle to accurately capture urban development due to
factors like atmospheric noise, seasonal variation, and cloud cover. These
limitations hinder large-scale monitoring of human development and
urbanization. To address these challenges, we propose an approach that
leverages {\em Vision-Language Models }(VLMs) to provide a development score
for regions. Specifically, we collect a time series of Sentinel-2 images for
each region. Then, we further process the images within fixed time windows to
get an image with minimal cloud cover, which serves as the representative image
for that time window. To ensure consistent scoring, we adopt two strategies:
(i) providing the VLM with a curated set of reference images representing
different levels of urbanization, and (ii) supplying the most recent past image
to both anchor temporal consistency and mitigate cloud-related noise in the
current image. Together, these components enable AUI to overcome the challenges
of traditional urbanization indices and produce more reliable and stable
development scores. Our qualitative experiments on Bangalore suggest that AUI
outperforms standard indices such as NDBI.

</details>


### [360] [HW/SW Co-design of a PCM/PWM converter: a System Level Approach based in the SpecC Methodology](https://arxiv.org/abs/2510.22046)
*Daniel G. P. Petrini,Braz Izaias da Silva Junior*

Main category: cs.AI

TL;DR: 本研究将SpecC方法应用于PCM到PWM转换器的硬件/软件协同设计，通过系统级建模和仿真，找到了满足实时性要求且兼顾成本的HW/SW分区方案。


<details>
  <summary>Details</summary>
Motivation: 对一个Class-D音频放大器核心部件（PCM到PWM转换器）进行系统级硬件/软件协同设计，以期在满足实时性约束的同时，降低整体成本。

Method: 使用SpecC方法对PCM到PWM转换器进行建模和探索，以确定硬件/软件分区。通过系统级估算和快速功能仿真来评估不同的硬件/软件映射方案。

Result: 研究结果表明，通过系统级协同设计，可以在满足实时性要求的前提下，降低硬件成本，并避免使用昂贵的高端处理器进行纯软件实现。

Conclusion: 尽管设计复杂度适中，但本研究强调了系统级协同设计在提供早期架构洞察、快速验证以及实现可行的成本/性能权衡方面的价值。

Abstract: We present a case study applying the SpecC methodology within a system-level
hardware/software co-design flow to a PCM-to-PWM converter, the core of a
Class-D audio amplifier. The converter was modeled and explored with SpecC
methodology to derive an HW/SW partition. Using system-level estimates and fast
functional simulation, we evaluated mappings that meet real-time constraints
while reducing estimated cost of an all-hardware solution and avoiding the
expense of a purely software implementation on a high-end processor. Despite
the design's moderate complexity, the results underline the value of
system-level co-design for early architectural insight, rapid validation, and
actionable cost/performance trade-offs. [Original work from 2005; formatting
revised in 2025, with no changes to the results.]

</details>


### [361] [GeoThought: A Dataset for Enhancing Mathematical Geometry Reasoning in Vision-Language Models](https://arxiv.org/abs/2510.21881)
*Nannan Shi,Chuanyu Qin,Shipeng Song,Man Luo*

Main category: cs.AI

TL;DR: LLMs在几何推理方面表现不佳，因为任务复杂且现有数据集不足。我们提出了GeoThoughts数据集和GeoThought-MLLM模型，通过详细的推理过程提升了模型性能，并分析了错误案例。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在处理视觉推理，特别是几何问题时性能下降，原因在于几何问题的内在复杂性和现有数据集的局限性。

Method: 创建了GeoThoughts数据集（包含Geo-Thought-6K和Geo-Thought-Augmented-10K两个子集），并开发了GeoThought-MLLM模型，该模型能在解决问题时生成详细的思考过程。

Result: GeoThought-MLLM在几何任务上的表现优于现有基准，证明了Chain-of-Thought数据集能提升模型在相关和无关领域内的几何推理能力。

Conclusion: 几何推理中的错误主要源于对数学概念的误解或空间判断失误。通过引入Chain-of-Thought（CoT）可以纠正这些错误，从而得到正确答案。

Abstract: Large language models (LLMs) have demonstrated strong reasoning capabilities
in text-based mathematical problem solving; however, when adapted to visual
reasoning tasks, particularly geometric problem solving, their performance
substantially declines because geometric problems present unique challenges.
Specifically, these challenges stem from two key factors: first, the intrinsic
complexity of geometry requiring detailed image comprehension and multi-step
reasoning, and second, the limitations of existing datasets which lack
sufficient scale, diversity, and explicit reasoning traces, consequently
hindering effective model training. To address these challenges, we developed
the GeoThoughts dataset, a comprehensive geometric reasoning corpus with two
subsets: Geo-Thought-6K with 6,243 samples and its augmented version
Geo-Thought-Augmented-10K containing 10,834 samples. Each entry includes visual
descriptions, step-by-step solutions, explicit reasoning chains, reflection
steps, and final answers. Using this dataset, we developed GeoThought-MLLM, a
mathematical reasoning multimodal model that generates detailed thinking
processes during problem-solving. Our model outperforms existing benchmarks in
geometric tasks, demonstrating that training with our Chain-of-Thought dataset
improves geometric reasoning capabilities across both in-domain and
out-of-domain settings. Finally, we analyze failure cases and observe that
errors primarily arise from incorrect interpretation of mathematical concepts
or spatial misjudgment. By invoking CoT to correct these mistakes, the model
produces correct answers.

</details>


### [362] [Exploration through Generation: Applying GFlowNets to Structured Search](https://arxiv.org/abs/2510.21886)
*Mark Phillip Matovic*

Main category: cs.AI

TL;DR: GFlowNets 学习解决组合优化问题，如 TSP、MST 和最短路径，通过学习策略生成解决方案，并在计算可扩展性方面显示出前景。


<details>
  <summary>Details</summary>
Motivation: 探索 GFlowNets 在解决 TSP、MST 和最短路径等图优化问题中的应用，并评估其与经典算法相比的计算可扩展性。

Method: 使用 GFlowNets 和轨迹平衡损失，通过顺序构建解决方案（选择边、节点或城市）来解决 TSP、MST 和最短路径问题。

Result: GFlowNets 在不同大小的基准实例上成功学习生成最优解，其解决方案与经典算法（Dijkstra、Kruskal、精确 TSP 求解器）匹配。训练收敛性与问题复杂度相关，模型在收敛后能找到已知最优解。

Conclusion: GFlowNets 是一种有前途的基于学习的方法，可以解决组合优化问题，通过训练提供计算可扩展性，有望解决经典算法难以处理的大型问题实例。

Abstract: This work applies Generative Flow Networks (GFlowNets) to three graph
optimization problems: the Traveling Salesperson Problem, Minimum Spanning
Tree, and Shortest Path. GFlowNets are generative models that learn to sample
solutions proportionally to a reward function. The models are trained using the
Trajectory Balance loss to build solutions sequentially, selecting edges for
spanning trees, nodes for paths, and cities for tours. Experiments on benchmark
instances of varying sizes show that GFlowNets learn to find optimal solutions.
For each problem type, multiple graph configurations with different numbers of
nodes were tested. The generated solutions match those from classical
algorithms (Dijkstra for shortest path, Kruskal for spanning trees, and exact
solvers for TSP). Training convergence depends on problem complexity, with the
number of episodes required for loss stabilization increasing as graph size
grows. Once training converges, the generated solutions match known optima from
classical algorithms across the tested instances. This work demonstrates that
generative models can solve combinatorial optimization problems through learned
policies. The main advantage of this learning-based approach is computational
scalability: while classical algorithms have fixed complexity per instance,
GFlowNets amortize computation through training. With sufficient computational
resources, the framework could potentially scale to larger problem instances
where classical exact methods become infeasible.

</details>


### [363] [AutoStreamPipe: LLM Assisted Automatic Generation of Data Stream Processing Pipelines](https://arxiv.org/abs/2510.23408)
*Abolfazl Younesi,Zahra Najafabadi Samani,Thomas Fahringer*

Main category: cs.AI

TL;DR: AutoStreamPipe使用LLM和HGoT自动化流处理管道的设计、生成和部署，显著减少开发时间和错误率。


<details>
  <summary>Details</summary>
Motivation: 实现数据管道的自动化设计、生成和部署，以高效收集、处理和交付实时数据，支持快速数据分析。

Method: 集成超图（Hypergraph of Thoughts, HGoT）作为思维图（GoT）的扩展，结合弹性执行策略和高级查询分析，弥合用户意图与平台特定实现之间的语义鸿沟。

Result: 与仅使用LLM代码生成的方法相比，AutoStreamPipe将开发时间缩短了6.3倍，错误率降低了5.19倍（通过新颖的无错误分数EFS衡量）。

Conclusion: AutoStreamPipe能够显著减少流处理管道的开发时间和错误率，是一种有效的自动化框架。

Abstract: Data pipelines are essential in stream processing as they enable the
efficient collection, processing, and delivery of real-time data, supporting
rapid data analysis. In this paper, we present AutoStreamPipe, a novel
framework that employs Large Language Models (LLMs) to automate the design,
generation, and deployment of stream processing pipelines. AutoStreamPipe
bridges the semantic gap between high-level user intent and platform-specific
implementations across distributed stream processing systems for structured
multi-agent reasoning by integrating a Hypergraph of Thoughts (HGoT) as an
extended version of GoT. AutoStreamPipe combines resilient execution
strategies, advanced query analysis, and HGoT to deliver pipelines with good
accuracy. Experimental evaluations on diverse pipelines demonstrate that
AutoStreamPipe significantly reduces development time (x6.3) and error rates
(x5.19), as measured by a novel Error-Free Score (EFS), compared to LLM
code-generation methods.

</details>


### [364] [Computational Hardness of Reinforcement Learning with Partial $q^π$-Realizability](https://arxiv.org/abs/2510.21888)
*Shayan Karimi,Xiaoqi Tan*

Main category: cs.AI

TL;DR: 在部分qπ-可实现性框架下，使用线性函数逼近学习ε-最优策略被证明在计算上是困难的，在特定策略集下具有NP-hard和指数级下界。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在探索一种新的线性函数逼近方法（部分qπ-可实现性），以理解其在强化学习中的计算复杂性，并为函数逼近在实际应用中提供一个更实际的模型。

Method: 通过将两个已知的复杂性问题（δ-Max-3SAT 和 δ-Max-3SAT(b)）规约到GLinear-κ-RL（贪婪策略）和SLinear-κ-RL（softmax策略）的实例，来证明NP-hard和指数级下界。

Result: 在参数化贪婪策略集（argmax）下，证明了学习ε-最优策略是NP-hard的；当策略集包含softmax策略时，在随机指数时间假设下，存在指数级下界（与特征向量维度相关）。

Conclusion: 在部分qπ-可实现性框架下，尤其是在策略集包含除最优策略外的其他策略时，实现计算上的正向结果通常是不可行的，这与生成模型下的qπ-可实现性形成对比。

Abstract: This paper investigates the computational complexity of reinforcement
learning in a novel linear function approximation regime, termed partial
$q^{\pi}$-realizability. In this framework, the objective is to learn an
$\epsilon$-optimal policy with respect to a predefined policy set $\Pi$, under
the assumption that all value functions for policies in $\Pi$ are linearly
realizable. The assumptions of this framework are weaker than those in
$q^{\pi}$-realizability but stronger than those in $q^*$-realizability,
providing a practical model where function approximation naturally arises. We
prove that learning an $\epsilon$-optimal policy in this setting is
computationally hard. Specifically, we establish NP-hardness under a
parameterized greedy policy set (argmax) and show that - unless NP = RP - an
exponential lower bound (in feature vector dimension) holds when the policy set
contains softmax policies, under the Randomized Exponential Time Hypothesis.
Our hardness results mirror those in $q^*$-realizability and suggest
computational difficulty persists even when $\Pi$ is expanded beyond the
optimal policy. To establish this, we reduce from two complexity problems,
$\delta$-Max-3SAT and $\delta$-Max-3SAT(b), to instances of GLinear-$\kappa$-RL
(greedy policy) and SLinear-$\kappa$-RL (softmax policy). Our findings indicate
that positive computational results are generally unattainable in partial
$q^{\pi}$-realizability, in contrast to $q^{\pi}$-realizability under a
generative access model.

</details>


### [365] [Performance Trade-offs of Optimizing Small Language Models for E-Commerce](https://arxiv.org/abs/2510.21970)
*Josip Tomo Licardo,Nikola Tankovic*

Main category: cs.AI

TL;DR: 小型开源语言模型（如Llama 3.2）经过QLoRA和量化优化（GPTQ, GGUF）后，在电子商务意图识别任务上能达到与GPT-4.1相当的99%准确率，同时显著降低了计算成本和资源消耗，尤其GGUF在CPU上表现出高达18倍的推理吞吐量提升和超过90%的RAM节省。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在专业领域（如电子商务）的应用受到计算成本、延迟和运营费用的限制，因此需要探索资源高效的替代方案。

Method: 使用QLoRA技术对10亿参数的Llama 3.2模型进行微调，并使用合成数据针对多语言电子商务意图识别任务进行训练。随后，应用GPTQ和GGUF等后训练量化技术，生成GPU和CPU优化版本。

Result: 优化的1B模型在电子商务意图识别任务上达到了99%的准确率，与GPT-4.1相当。GPTQ量化在NVIDIA T4 GPU上降低了41%的VRAM使用，但推理速度反而降低了82%。GGUF在CPU上实现了高达18倍的推理吞吐量提升和超过90%的RAM节省。

Conclusion: 经过适当优化的、参数量小的开源模型是特定领域应用的理想选择，它们能在显著降低计算成本的同时，提供与大型模型相媲美的准确率。

Abstract: Large Language Models (LLMs) offer state-of-the-art performance in natural
language understanding and generation tasks. However, the deployment of leading
commercial models for specialized tasks, such as e-commerce, is often hindered
by high computational costs, latency, and operational expenses. This paper
investigates the viability of smaller, open-weight models as a
resource-efficient alternative. We present a methodology for optimizing a
one-billion-parameter Llama 3.2 model for multilingual e-commerce intent
recognition. The model was fine-tuned using Quantized Low-Rank Adaptation
(QLoRA) on a synthetically generated dataset designed to mimic real-world user
queries. Subsequently, we applied post-training quantization techniques,
creating GPU-optimized (GPTQ) and CPU-optimized (GGUF) versions. Our results
demonstrate that the specialized 1B model achieves 99% accuracy, matching the
performance of the significantly larger GPT-4.1 model. A detailed performance
analysis revealed critical, hardware-dependent trade-offs: while 4-bit GPTQ
reduced VRAM usage by 41%, it paradoxically slowed inference by 82% on an older
GPU architecture (NVIDIA T4) due to dequantization overhead. Conversely, GGUF
formats on a CPU achieved a speedup of up to 18x in inference throughput and a
reduction of over 90% in RAM consumption compared to the FP16 baseline. We
conclude that small, properly optimized open-weight models are not just a
viable but a more suitable alternative for domain-specific applications,
offering state-of-the-art accuracy at a fraction of the computational cost.

</details>


### [366] [Distribution Shift Alignment Helps LLMs Simulate Survey Response Distributions](https://arxiv.org/abs/2510.21977)
*Ji Huang,Mengfei Li,Shuai Shao*

Main category: cs.AI

TL;DR: DSA是一种新的LLM微调方法，通过对齐输出分布和分布变化，提高了调查模拟的准确性和效率，减少了对真实数据的需求。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在模拟人类调查响应方面存在提示敏感性和准确性低的问题，而传统的微调方法又会过度拟合训练数据，无法生成比训练集更准确的结果，这违背了使用LLM进行调查模拟的初衷。

Method: DSA是一种两阶段的微调方法，它不仅对齐输出分布，还对齐不同背景下的分布变化，通过学习分布的变化规律来模拟调查响应。

Result: DSA在五个公开的调查数据集上始终优于其他方法，并且在准确性、鲁棒性和数据节省方面进行了全面比较，证明了其有效性。DSA将所需的真实数据量减少了53.48-69.12%。

Conclusion: DSA通过对齐分布和分布变化，能够生成比训练数据更接近真实分布的调查响应，有效提高了调查模拟的准确性和效率，并显著减少了对真实数据的需求。

Abstract: Large language models (LLMs) offer a promising way to simulate human survey
responses, potentially reducing the cost of large-scale data collection.
However, existing zero-shot methods suffer from prompt sensitivity and low
accuracy, while conventional fine-tuning approaches mostly fit the training set
distributions and struggle to produce results more accurate than the training
set itself, which deviates from the original goal of using LLMs to simulate
survey responses. Building on this observation, we introduce Distribution Shift
Alignment (DSA), a two-stage fine-tuning method that aligns both the output
distributions and the distribution shifts across different backgrounds. By
learning how these distributions change rather than fitting training data, DSA
can provide results substantially closer to the true distribution than the
training data. Empirically, DSA consistently outperforms other methods on five
public survey datasets. We further conduct a comprehensive comparison covering
accuracy, robustness, and data savings. DSA reduces the required real data by
53.48-69.12%, demonstrating its effectiveness and efficiency in survey
simulation.

</details>


### [367] [Foundation of Intelligence: Review of Math Word Problems from Human Cognition Perspective](https://arxiv.org/abs/2510.21999)
*Zhenya Huang,Jiayu Liu,Xin Lin,Zhiyuan Ma,Shangzi Xue,Tong Xiao,Qi Liu,Yee Whye Teh,Enhong Chen*

Main category: cs.AI

TL;DR: 本论文对数学应用题（MWP）的求解研究进行了全面回顾，从人类认知角度分析了AI模型的发展趋势，并对现有方法进行了比较。


<details>
  <summary>Details</summary>
Motivation: AI在数学应用题（MWP）求解方面的研究旨在模拟人类的认知智能，但目前缺乏系统性的分类和对发展趋势的讨论。因此，本文旨在全面回顾MWP的求解研究，并探讨AI模型如何在模拟人类认知能力方面取得进展。

Method: 本文总结了MWP求解的5项关键认知能力（问题理解、逻辑组织、联想记忆、批判性思维和知识学习），并重点回顾了近十年来两大主流MWP模型（神经网络求解器和基于LLM的求解器），讨论了它们在解决问题过程中所展现的核心类人能力。此外，还对5个主流基准进行了统一的性能比较。

Result: 本文对近十年来最具影响力的MWP研究进行了全面的分析，从人类推理认知角度出发，提供了现有方法之间的一致性总体比较。

Conclusion: 本文首次从人类推理认知的角度全面分析了过去十年具有影响力的MWP研究，并对现有方法进行了一致性的整体比较，希望能启发AI推理的进一步研究。

Abstract: Math word problem (MWP) serves as a fundamental research topic in artificial
intelligence (AI) dating back to 1960s. This research aims to advance the
reasoning abilities of AI by mirroring the human-like cognitive intelligence.
The mainstream technological paradigm has evolved from the early rule-based
methods, to deep learning models, and is rapidly advancing towards large
language models. However, the field still lacks a systematic taxonomy for the
MWP survey along with a discussion of current development trends. Therefore, in
this paper, we aim to comprehensively review related research in MWP solving
through the lens of human cognition, to demonstrate how recent AI models are
advancing in simulating human cognitive abilities. Specifically, we summarize 5
crucial cognitive abilities for MWP solving, including Problem Understanding,
Logical Organization, Associative Memory, Critical Thinking, and Knowledge
Learning. Focused on these abilities, we review two mainstream MWP models in
recent 10 years: neural network solvers, and LLM based solvers, and discuss the
core human-like abilities they demonstrated in their intricate problem-solving
process. Moreover, we rerun all the representative MWP solvers and supplement
their performance on 5 mainstream benchmarks for a unified comparison. To the
best of our knowledge, this survey first comprehensively analyzes the
influential MWP research of the past decade from the perspective of human
reasoning cognition and provides an integrative overall comparison across
existing approaches. We hope it can inspire further research in AI reasoning.
Our repository is released on https://github.com/Ljyustc/FoI-MWP.

</details>


### [368] [LightAgent: Mobile Agentic Foundation Models](https://arxiv.org/abs/2510.22009)
*Yangqin Jiang,Chao Huang*

Main category: cs.AI

TL;DR: 本研究提出LightAgent，一个结合设备与云端能力的移动端GUI智能体基础模型，解决了移动端模型性能不足与大型模型部署成本高昂的困境。


<details>
  <summary>Details</summary>
Motivation: 移动端GUI智能体面临模型性能与部署成本的矛盾：小型端侧模型能力不足，大型模型（7B及以上）部署困难或成本高昂（如云端闭源MLLMs）。

Method: LightAgent通过两阶段SFT->GRPO训练（Qwen2.5-VL-3B模型）并结合GUI合成数据，增强决策能力；集成高效长时推理机制以在资源受限情况下利用历史交互；通过实时复杂度评估，优先在端侧执行，并将复杂子任务交给云端处理。

Result: 在AndroidLab基准测试和多样化应用实验中，LightAgent的性能与更大模型相当或接近，同时显著降低了云端成本。

Conclusion: LightAgent通过设备-云端协同，有效解决了移动端GUI智能体面临的性能与成本挑战，实现了高效且经济的智能体解决方案。

Abstract: With the advancement of multimodal large language models (MLLMs), building
GUI agent systems has become an increasingly promising direction-especially for
mobile platforms, given their rich app ecosystems and intuitive touch
interactions. Yet mobile GUI agents face a critical dilemma: truly on-device
models (4B or smaller) lack sufficient performance, while capable models
(starting from 7B) are either too large for mobile deployment or prohibitively
costly (e.g., cloud-only closed-source MLLMs). To resolve this, we propose
LightAgent, a mobile agentic foundation model solution that leverages
device-cloud collaboration to tap the cost-efficiency of on-device models and
the high capability of cloud models, while avoiding their drawbacks.
Specifically, LightAgent enhances Qwen2.5-VL-3B via two-stage SFT->GRPO
training on synthetic GUI data for strong decision-making, integrates an
efficient long-reasoning mechanism to utilize historical interactions under
tight resources, and defaults to on-device execution-only escalating
challenging subtasks to the cloud via real-time complexity assessment.
Experiments on the online AndroidLab benchmark and diverse apps show LightAgent
matches or nears larger models, with a significant reduction in cloud costs.

</details>


### [369] [LLM-AR: LLM-powered Automated Reasoning Framework](https://arxiv.org/abs/2510.22034)
*Rick Chen,Joseph Ternasky,Aaron Ontoyin Yin,Xianling Mu,Fuat Alican,Yigit Ihlamur*

Main category: cs.AI

TL;DR: LLM-AR通过结合LLM和概率逻辑来预测初创公司成功，提高了预测准确性并实现了可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在准确性方面的不足限制了其在高风险决策中的应用。本文旨在通过风险投资的视角，基于创始人特质预测初创公司的成功，以解决这一问题。

Method: 提出LLM-AR管道，该管道受神经符号系统的启发，将LLM生成的启发式规则提炼为由ProbLog自动推理引擎执行的概率规则。通过结合关联规则挖掘和迭代策略演化循环来逐步优化预测规则。

Result: 在未见过的数据集上，LLM-AR实现了59.5%的精确率和8.7%的召回率，精确率是随机基线的5.9倍，并能展示所有决策路径以供人类检查。

Conclusion: LLM-AR框架具有可解释性，可通过超参数进行调整，有望扩展到其他领域。

Abstract: Large language models (LLMs) can already identify patterns and reason
effectively, yet their variable accuracy hampers adoption in high-stakes
decision-making applications. In this paper, we study this issue from a venture
capital perspective by predicting idea-stage startup success based on founder
traits. (i) To build a reliable prediction model, we introduce LLM-AR, a
pipeline inspired by neural-symbolic systems that distils LLM-generated
heuristics into probabilistic rules executed by the ProbLog automated-reasoning
engine. (ii) An iterative policy-evolution loop incorporates association-rule
mining to progressively refine the prediction rules.
  On unseen folds, LLM-AR achieves 59.5% precision and 8.7% recall, 5.9x the
random baseline precision, while exposing every decision path for human
inspection. The framework is interpretable and tunable via hyperparameters,
showing promise to extend into other domains.

</details>


### [370] [Predictive Coding Enhances Meta-RL To Achieve Interpretable Bayes-Optimal Belief Representation Under Partial Observability](https://arxiv.org/abs/2510.22039)
*Po-Chen Kuo,Han Hou,Will Dabney,Edgar Y. Walker*

Main category: cs.AI

TL;DR: 在部分可观察环境中，集成预测编码模块的元强化学习（Meta-RL）可以学习到更紧凑、更具可解释性的贝叶斯最优信念状态，从而提高泛化能力，尤其是在需要主动信息搜寻的任务中。


<details>
  <summary>Details</summary>
Motivation: 传统的元强化学习（Meta-RL）在部分可观察环境中虽然能学习到接近贝叶斯最优的策略，但往往无法学习到紧凑、可解释的贝叶斯最优信念状态，这可能限制了其适应性和泛化能力。

Method: 通过在元强化学习中集成受神经科学预测编码启发的自监督预测编码模块，以促进贝叶斯最优表征的学习。

Result: 在状态机模拟中，与传统元强化学习相比，集成预测模块的元强化学习在多种任务中能持续生成更具可解释性的表征，并更接近贝叶斯最优信念状态。在需要主动信息搜寻的任务中，只有集成预测模块的元强化学习能成功学习到最优表征和策略，而传统元强化学习则在表征学习上遇到困难。集成预测模块还能提高泛化能力。

Conclusion: 预测学习在指导智能体在部分可观察环境中进行有效表征学习方面起着重要作用。

Abstract: Learning a compact representation of history is critical for planning and
generalization in partially observable environments. While meta-reinforcement
learning (RL) agents can attain near Bayes-optimal policies, they often fail to
learn the compact, interpretable Bayes-optimal belief states. This
representational inefficiency potentially limits the agent's adaptability and
generalization capacity. Inspired by predictive coding in neuroscience--which
suggests that the brain predicts sensory inputs as a neural implementation of
Bayesian inference--and by auxiliary predictive objectives in deep RL, we
investigate whether integrating self-supervised predictive coding modules into
meta-RL can facilitate learning of Bayes-optimal representations. Through state
machine simulation, we show that meta-RL with predictive modules consistently
generates more interpretable representations that better approximate
Bayes-optimal belief states compared to conventional meta-RL across a wide
variety of tasks, even when both achieve optimal policies. In challenging tasks
requiring active information seeking, only meta-RL with predictive modules
successfully learns optimal representations and policies, whereas conventional
meta-RL struggles with inadequate representation learning. Finally, we
demonstrate that better representation learning leads to improved
generalization. Our results strongly suggest the role of predictive learning as
a guiding principle for effective representation learning in agents navigating
partial observability.

</details>


### [371] [Towards Error-Centric Intelligence II: Energy-Structured Causal Models](https://arxiv.org/abs/2510.22050)
*Marcus Thomas*

Main category: cs.AI

TL;DR: 机器学习应更注重因果关系而非预测准确性，提出计算性解释，并用能量结构因果模型（ESCM）实现，以实现可干预和可修正的因果模型。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习模型虽然预测准确率高，但缺乏因果透明度，无法进行干预和修正。需要一种新的方法来构建可干预、可修正的因果模型。

Method: 提出计算性解释，并将因果模型具体化为能量结构因果模型（ESCM），其中机制用约束（能量函数或向量场）表示，干预通过局部手术修改约束来实现。实现了LAP和ICM等结构因果原则，并分析了经验风险最小化产生的表示问题（规范歧义）。

Result: ESCMs 允许在机制层面进行干预，并且在温和条件下可以恢复标准的SCM语义。解决了经验风险最小化导致的表示纠缠问题。

Conclusion: 提出了一种新的因果推理形式化语言，用于构建和精炼解释，该模型不仅能预测，而且能够理解。

Abstract: Contemporary machine learning optimizes for predictive accuracy, yet systems
that achieve state of the art performance remain causally opaque: their
internal representations provide no principled handle for intervention. We can
retrain such models, but we cannot surgically edit specific mechanisms while
holding others fixed, because learned latent variables lack causal semantics.
We argue for a conceptual reorientation: intelligence is the ability to build
and refine explanations, falsifiable claims about manipulable structure that
specify what changes and what remains invariant under intervention.
Explanations subsume prediction but demand more: causal commitments that can be
independently tested and corrected at the level of mechanisms. We introduce
computational explanations, mappings from observations to intervention ready
causal accounts. We instantiate these explanations with Energy Structured
Causal Models (ESCMs), in which mechanisms are expressed as constraints (energy
functions or vector fields) rather than explicit input output maps, and
interventions act by local surgery on those constraints. This shift makes
internal structure manipulable at the level where explanations live: which
relations must hold, which can change, and what follows when they do. We
provide concrete instantiations of the structural-causal principles LAP and ICM
in the ESCM context, and also argue that empirical risk minimization
systematically produces fractured, entangled representations, a failure we
analyze as gauge ambiguity in encoder energy pairs. Finally, we show that under
mild conditions, ESCMs recover standard SCM semantics. Building on Part I's
principles (LAP, ICM, CAP) and its definition of intelligence as
explanation-building under criticism, this paper offers a formal language for
causal reasoning in systems that aspire to understand, not merely to predict.

</details>


### [372] [Energy-Efficient Domain-Specific Artificial Intelligence Models and Agents: Pathways and Paradigms](https://arxiv.org/abs/2510.22052)
*Abhijit Chatterjee,Niraj K. Jha,Jonathan D. Cohen,Thomas L. Griffiths,Hongjing Lu,Diana Marculescu,Ashiqur Rasul,Keshab K. Parhi*

Main category: cs.AI

TL;DR: AI市场预计将从2023年的1890亿美元增长到2033年的4.8万亿美元，但目前由需要大量数据和能源的LLM主导，且存在幻觉问题。需要轻量级、领域特定的多模态模型，能够进行推理、规划和决策，同时具备持续学习和演进能力。这需要硬件的革新以实现更高的能效。


<details>
  <summary>Details</summary>
Motivation: 目前AI市场由LLM主导，但其训练成本高昂、能耗巨大且存在幻觉问题，限制了其在关键领域的应用。下一代AI需要更轻量、领域特定、多模态的模型，以实现更高级别的智能和能效。

Method: 提出了一种下一代AI的愿景，旨在开发轻量级、领域特定的多模态模型，能够进行推理、规划、决策，并具备持续学习和演进能力，同时需要硬件层面的革新以实现更高的能效。

Result: 文章提出了对未来AI系统的愿景，强调了轻量级、领域特定、多模态模型以及硬件能效提升的重要性。

Conclusion: 下一代AI将从大型模型转向轻量级、领域特定的智能代理，能够在不确定的世界中进行推理和思考，并需要硬件的重大革新来实现更高的能效。

Abstract: The field of artificial intelligence (AI) has taken a tight hold on broad
aspects of society, industry, business, and governance in ways that dictate the
prosperity and might of the world's economies. The AI market size is projected
to grow from 189 billion USD in 2023 to 4.8 trillion USD by 2033. Currently, AI
is dominated by large language models that exhibit linguistic and visual
intelligence. However, training these models requires a massive amount of data
scraped from the web as well as large amounts of energy (50--60 GWh to train
GPT-4). Despite these costs, these models often hallucinate, a characteristic
that prevents them from being deployed in critical application domains. In
contrast, the human brain consumes only 20~W of power. What is needed is the
next level of AI evolution in which lightweight domain-specific multimodal
models with higher levels of intelligence can reason, plan, and make decisions
in dynamic environments with real-time data and prior knowledge, while learning
continuously and evolving in ways that enhance future decision-making
capability. This will define the next wave of AI, progressing from today's
large models, trained with vast amounts of data, to nimble energy-efficient
domain-specific agents that can reason and think in a world full of
uncertainty. To support such agents, hardware will need to be reimagined to
allow energy efficiencies greater than 1000x over the state of the art. Such a
vision of future AI systems is developed in this work.

</details>


### [373] [Multi-Agent Conditional Diffusion Model with Mean Field Communication as Wireless Resource Allocation Planner](https://arxiv.org/abs/2510.22969)
*Kechen Meng,Sinuo Zhang,Rongpeng Li,Xiangming Meng,Chan Wang,Ming Lei,Zhifeng Zhao*

Main category: cs.AI

TL;DR: MA-CDMP是一种用于无线通信资源管理的基于模型的强化学习方法，它使用扩散模型和均值场机制来解决分布式强化学习中的非平稳性和协作问题，并在实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的分布式强化学习方法在通信资源管理中存在非平稳性和协作不足的问题，而中心化方法存在可扩展性和隐私风险。

Method: 提出MA-CDMP，一种基于模型的强化学习方法。它使用扩散模型来捕捉环境动态并规划未来轨迹，并利用逆动力学模型来指导动作生成。此外，引入均值场机制来近似大规模的智能体交互，以缓解非平稳性并增强协作。

Result: 实验结果表明，MA-CDMP在平均奖励和QoS指标方面优于现有的MARL基线方法，证明了其在无线网络优化中的可扩展性和实用性。

Conclusion: MA-CDMP通过结合扩散模型和均值场机制，有效地解决了分布式强化学习中的挑战，为无线通信资源管理提供了一种高效且实用的解决方案。

Abstract: In wireless communication systems, efficient and adaptive resource allocation
plays a crucial role in enhancing overall Quality of Service (QoS). While
centralized Multi-Agent Reinforcement Learning (MARL) frameworks rely on a
central coordinator for policy training and resource scheduling, they suffer
from scalability issues and privacy risks. In contrast, the Distributed
Training with Decentralized Execution (DTDE) paradigm enables distributed
learning and decision-making, but it struggles with non-stationarity and
limited inter-agent cooperation, which can severely degrade system performance.
To overcome these challenges, we propose the Multi-Agent Conditional Diffusion
Model Planner (MA-CDMP) for decentralized communication resource management.
Built upon the Model-Based Reinforcement Learning (MBRL) paradigm, MA-CDMP
employs Diffusion Models (DMs) to capture environment dynamics and plan future
trajectories, while an inverse dynamics model guides action generation, thereby
alleviating the sample inefficiency and slow convergence of conventional DTDE
methods. Moreover, to approximate large-scale agent interactions, a Mean-Field
(MF) mechanism is introduced as an assistance to the classifier in DMs. This
design mitigates inter-agent non-stationarity and enhances cooperation with
minimal communication overhead in distributed settings. We further
theoretically establish an upper bound on the distributional approximation
error introduced by the MF-based diffusion generation, guaranteeing convergence
stability and reliable modeling of multi-agent stochastic dynamics. Extensive
experiments demonstrate that MA-CDMP consistently outperforms existing MARL
baselines in terms of average reward and QoS metrics, showcasing its
scalability and practicality for real-world wireless network optimization.

</details>


### [374] [Embracing Trustworthy Brain-Agent Collaboration as Paradigm Extension for Intelligent Assistive Technologies](https://arxiv.org/abs/2510.22095)
*Yankai Chen,Xinni Zhang,Yifei Zhang,Yangning Li,Henry Peng Zou,Chunyu Miao,Weizhi Zhang,Xue Liu,Philip S. Yu*

Main category: cs.AI

TL;DR: BCI技術有潛力，但因傳輸率低和校準複雜而受限。將LLM整合到BCI中，可以從解碼命令轉向理解複雜認知狀態。然而，採用AI代理仍面臨技術和倫理挑戰。為了解決這些問題，本文主張將BCI擴展為“腦-代理協作”（BAC），將代理重新定義為主動的協作夥伴，而非被動的數據處理器。這需要關注數據處理倫理、模型可靠性以及穩健的人機協作框架，以確保系統的安全、可靠和有效。


<details>
  <summary>Details</summary>
Motivation: BCI（腦機接口）在為嚴重神經損傷患者提供溝通途徑方面展現了巨大潛力，但其廣泛應用因信息傳輸率低和用戶特定校準需求高等關鍵限制而受到阻礙。因此，有必要克服這些挑戰。

Method: 本文提出將大型語言模型（LLMs）整合到BCI中，並主張將該領域從BCI擴展為腦-代理協作（BAC）。該方法強調將代理重新定義為智能輔助的活躍協作夥伴，而不僅僅是被動的腦信號數據處理器。

Result: 將LLM整合到BCI中，可以從簡單的命令解碼轉向理解複雜的認知狀態。這項擴展為腦-代理協作（BAC）奠定了基礎。

Conclusion: 該領域正處於從BCI到BAC的範式擴展的轉折點。要實現安全、可信和有效的系統，必須關注倫理數據處理、模型可靠性以及穩健的人機協作框架。

Abstract: Brain-Computer Interfaces (BCIs) offer a direct communication pathway between
the human brain and external devices, holding significant promise for
individuals with severe neurological impairments. However, their widespread
adoption is hindered by critical limitations, such as low information transfer
rates and extensive user-specific calibration. To overcome these challenges,
recent research has explored the integration of Large Language Models (LLMs),
extending the focus from simple command decoding to understanding complex
cognitive states. Despite these advancements, deploying agentic AI faces
technical hurdles and ethical concerns. Due to the lack of comprehensive
discussion on this emerging direction, this position paper argues that the
field is poised for a paradigm extension from BCI to Brain-Agent Collaboration
(BAC). We emphasize reframing agents as active and collaborative partners for
intelligent assistance rather than passive brain signal data processors,
demanding a focus on ethical data handling, model reliability, and a robust
human-agent collaboration framework to ensure these systems are safe,
trustworthy, and effective.

</details>


### [375] [Controllable Mathematical Reasoning via Self-Optimizing Thought Vectors](https://arxiv.org/abs/2510.22132)
*Xuying LI*

Main category: cs.AI

TL;DR: 提出一种利用自优化思维向量和熵最小化进行可控数学推理的新方法。


<details>
  <summary>Details</summary>
Motivation: 介绍一种新的可控数学推理方法，该方法引入了可学习的思维向量来动态调节大型语言模型的内部推理过程。

Method: 使用自优化思维向量和熵最小化。

Result: 在GSM8K数据集上，使用Gemma-2-9B模型达到了90.1%的准确率和0.42的可控性得分。

Conclusion: 基于熵的奖励能有效地引导专注的推理模式，而无需外部奖励注释。分析显示了独特的思维向量簇和跨控制条件的一致低熵分布，验证了该框架在可控人工智能推理方面的有效性。

Abstract: We present a novel approach for controllable mathematical reasoning that
leverages self-optimizing thought vectors with entropy minimization. Our method
introduces learnable thought vectors that dynamically modulate the internal
reasoning process of large language models. Using Gemma-2-9B on GSM8K, we
achieve 90.1% accuracy with a controllability score of 0.42, demonstrating that
entropy-based rewards effectively guide focused reasoning patterns without
requiring external reward annotations. Our analysis reveals distinct thought
vector clusters and consistent low-entropy distributions across control
conditions, validating our framework for controllable AI reasoning.

</details>


### [376] [A Neuro-Symbolic Multi-Agent Approach to Legal-Cybersecurity Knowledge Integration](https://arxiv.org/abs/2510.23443)
*Chiara Bonfanti,Alessandro Druetto,Cataldo Basile,Tharindu Ranasinghe,Marcos Zampieri*

Main category: cs.AI

TL;DR: 网络安全和法律的交叉领域需要智能系统来弥合法律专家和网络安全专业人员之间的知识鸿沟。


<details>
  <summary>Details</summary>
Motivation: 现有的法律研究工具难以处理网络安全和法律之间细微的联系，阻碍了跨学科合作。

Method: 提出一个智能系统来处理日益复杂的网络法律领域，并在多语言任务上展示了初步结果。

Result: 在多语言任务上取得了初步的成功。

Conclusion: 该工作为构建能够驾驭复杂网络法律领域的智能系统奠定了基础，并在多语言任务上取得了有希望的初步结果。

Abstract: The growing intersection of cybersecurity and law creates a complex
information space where traditional legal research tools struggle to deal with
nuanced connections between cases, statutes, and technical vulnerabilities.
This knowledge divide hinders collaboration between legal experts and
cybersecurity professionals. To address this important gap, this work provides
a first step towards intelligent systems capable of navigating the increasingly
intricate cyber-legal domain. We demonstrate promising initial results on
multilingual tasks.

</details>


### [377] [Measure what Matters: Psychometric Evaluation of AI with Situational Judgment Tests](https://arxiv.org/abs/2510.22170)
*Alexandra Yost,Shreyans Jain,Shivam Raval,Grant Corser,Allen Roush,Nina Xu,Jacqueline Hammack,Ravid Shwartz-Ziv,Amirali Abdullah*

Main category: cs.AI

TL;DR: 该研究提出了一种名为AI心理测量学的框架，用于评估AI在需要情感判断和道德考量的角色中的表现，通过结合情境判断测试（SJTs）和精心设计的角色，提高了评估的真实性和相关性。


<details>
  <summary>Details</summary>
Motivation: 现有AI评估方法（如复用人类特质清单或临时创建的角色）在行为真实性和领域相关性方面存在局限性。

Method: 提出一个框架，包括：1.使用源自真实场景的情境判断测试（SJTs）来探查特定领域的AI能力；2.结合工业与组织心理学及人格心理学，设计包含行为、心理描述、生活史、社会情感功能等的复杂AI角色；3.利用人口统计学先验和回忆录式叙事，通过Pydantic模式进行结构化生成。

Result: 在执法助理案例研究中，构建了一个包含8个角色原型和11个属性的SJTs的丰富数据集，覆盖8,500个角色、4,000个SJTs和300,000个响应，并分析了不同人口子群体和场景下的行为。计划公开数据集和代码。

Conclusion: 该研究提出的AI心理测量学框架通过使用SJTs和复杂角色设计，能够更真实、更相关地评估AI在需要情感和道德判断的任务中的表现，并在执法领域进行了成功案例验证。

Abstract: AI psychometrics evaluates AI systems in roles that traditionally require
emotional judgment and ethical consideration. Prior work often reuses human
trait inventories (Big Five, \hexaco) or ad hoc personas, limiting behavioral
realism and domain relevance. We propose a framework that (1) uses situational
judgment tests (SJTs) from realistic scenarios to probe domain-specific
competencies; (2) integrates industrial-organizational and personality
psychology to design sophisticated personas which include behavioral and
psychological descriptors, life history, and social and emotional functions;
and (3) employs structured generation with population demographic priors and
memoir inspired narratives, encoded with Pydantic schemas. In a law enforcement
assistant case study, we construct a rich dataset of personas drawn across 8
persona archetypes and SJTs across 11 attributes, and analyze behaviors across
subpopulation and scenario slices. The dataset spans 8,500 personas, 4,000
SJTs, and 300,000 responses. We will release the dataset and all code to the
public.

</details>


### [378] [Dopamine-driven synaptic credit assignment in neural networks](https://arxiv.org/abs/2510.22178)
*Saranraj Nambusubramaniyan,Shervin Safavi,Raja Guru,Andreas Knoblauch*

Main category: cs.AI

TL;DR: Dopamine是一种新的无梯度优化器，通过受神经强化学习的启发，解决反向传播的效率问题，在XOR和时间序列预测任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 反向传播在计算和内存方面效率低下，并存在权重传输和更新锁定问题，这促使了对更优解决方案的探索。

Method: Dopamine利用随机权重扰动（WP）和奖励预测误差（RPE）来更新权重，并根据RPE调整学习率，实现自适应学习率策略。

Result: 在XOR任务和混沌时间序列预测任务中，Dopamine优化器训练的模型收敛速度更快，性能优于标准WP，并与基于梯度的算法相当，同时显著减少了计算和内存消耗。

Conclusion: Dopamine优化器在解决突触信用分配问题方面，不仅提供了与最先进的机器学习优化器相当的稳健解决方案，而且在生物学上更具可信度。

Abstract: Solving the synaptic Credit Assignment Problem(CAP) is central to learning in
both biological and artificial neural systems. Finding an optimal solution for
synaptic CAP means setting the synaptic weights that assign credit to each
neuron for influencing the final output and behavior of neural networks or
animals. Gradient-based methods solve this problem in artificial neural
networks using back-propagation, however, not in the most efficient way. For
instance, back-propagation requires a chain of top-down gradient computations.
This leads to an expensive optimization process in terms of computing power and
memory linked with well-known weight transport and update locking problems. To
address these shortcomings, we take a NeuroAI approach and draw inspiration
from neural Reinforcement Learning to develop a derivative-free optimizer for
training neural networks, Dopamine. Dopamine is developed for Weight
Perturbation (WP) learning that exploits stochastic updating of weights towards
optima. It achieves this by minimizing the regret, a form of Reward Prediction
Error (RPE) between the expected outcome from the perturbed model and the
actual outcome from the unperturbed model. We use this RPE to adjust the
learning rate in the network (i.e., creating an adaptive learning rate
strategy, similar to the role of dopamine in the brain). We tested the Dopamine
optimizer for training multi-layered perceptrons for XOR tasks, and recurrent
neural networks for chaotic time series forecasting. Dopamine-trained models
demonstrate accelerated convergence and outperform standard WP, and give
comparable performance to gradient-based algorithms, while consuming
significantly less computation and memory. Overall, the Dopamine optimizer not
only finds robust solutions and comparable performance to the state-of-the-art
Machine Learning optimizers but is also neurobiologically more plausible.

</details>


### [379] [OptiTree: Hierarchical Thoughts Generation with Tree Search for LLM Optimization Modeling](https://arxiv.org/abs/2510.22192)
*Haoyang Liu,Jie Wang,Yuyang Cai,Xiongwei Han,Yufei Kuang,Jianye Hao*

Main category: cs.AI

TL;DR: OptiTree是一种新的树搜索方法，通过自适应地将复杂问题分解为更简单的子问题来提高优化建模的准确性，在具有挑战性的基准测试中取得了超过10%的改进。


<details>
  <summary>Details</summary>
Motivation: 现有的基于LLM的优化建模方法在处理复杂数学结构时存在局限性，容易因固定的分解步骤而失败。

Method: 提出了一种名为OptiTree的新型树搜索方法。该方法构建了一个包含问题分类和相关建模思路的建模树，通过递归搜索该树来识别一系列更简单的子问题，并自适应地整合分层思想来合成全局建模思路。

Result: OptiTree在具有挑战性的基准测试中，相比现有最先进的方法，在建模准确性方面显著提高了10%以上。

Conclusion: OptiTree通过自适应问题分解的树搜索方法，能够有效地提升复杂优化建模的性能。

Abstract: Optimization modeling is one of the most crucial but technical parts of
operations research (OR). To automate the modeling process, existing works have
leveraged large language models (LLMs), prompting them to break down tasks into
steps for generating variables, constraints, and objectives. However, due to
the highly complex mathematical structures inherent in OR problems, standard
fixed-step decomposition often fails to achieve high performance. To address
this challenge, we introduce OptiTree, a novel tree search approach designed to
enhance modeling capabilities for complex problems through adaptive problem
decomposition into simpler subproblems. Specifically, we develop a modeling
tree that organizes a wide range of OR problems based on their hierarchical
problem taxonomy and complexity, with each node representing a problem category
and containing relevant high-level modeling thoughts. Given a problem to model,
we recurrently search the tree to identify a series of simpler subproblems and
synthesize the global modeling thoughts by adaptively integrating the
hierarchical thoughts. Experiments show that OptiTree significantly improves
the modeling accuracy compared to the state-of-the-art, achieving over 10\%
improvements on the challenging benchmarks. The code is released at
https://github.com/MIRALab-USTC/OptiTree/tree/main.

</details>


### [380] [PACR: Progressively Ascending Confidence Reward for LLM Reasoning](https://arxiv.org/abs/2510.22255)
*Eunseop Yoon,Hee Suk Yoon,Jaehyun Jang,SooHwan Eom,Qi Dai,Chong Luo,Mark A. Hasegawa-Johnson,Chang D. Yoo*

Main category: cs.AI

TL;DR: PACR是一种用于LLM的奖励函数，可以加速RLVR的探索过程。


<details>
  <summary>Details</summary>
Motivation: PACR旨在解决RLVR中奖励稀疏、缺乏中间步骤指导的问题。

Method: PACR是一种密集、模型内在的奖励，它直接从模型对正确答案不断变化的信念中计算出来，并引入了一个归纳偏倚，即在良好形成的推理轨迹中，正确答案的概率应该有一个普遍上升的趋势。

Result: PACR被证明可以加速探索，用更少的轨迹达到奖励饱和，并在多个基准测试中取得了改进。

Conclusion: PACR表明，密集、模型内在的塑造信号可以使RLVR训练更有效、更可靠。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has significantly
improved LLM reasoning, but its sparse, outcome-based reward provides no
guidance for intermediate steps, slowing exploration. We propose Progressively
Ascending Confidence Reward (PACR), a dense, model-intrinsic reward computed
directly from the model's evolving belief in the correct answer. PACR encodes
the inductive bias that, along a well-formed reasoning trajectory, the
probability of the ground-truth answer should have a generally ascending trend.
We provide empirical and theoretical analysis validating that such an inductive
bias constrains the exploration search space to regions richer in logically
sound reasoning. We demonstrate that PACR accelerates exploration, reaches
reward saturation with fewer trajectories, and yields improvements on multiple
benchmarks. Our results suggest that dense, model-intrinsic shaping signals can
make RLVR training more effective and reliable.

</details>


### [381] [VietLyrics: A Large-Scale Dataset and Models for Vietnamese Automatic Lyrics Transcription](https://arxiv.org/abs/2510.22295)
*Quoc Anh Nguyen,Bernard Cheng,Kelvin Soh*

Main category: cs.AI

TL;DR: 我们发布了 VietLyrics，这是越南语自动歌词转录 (ALT) 的首个大型数据集，并展示了微调 Whisper 模型在低资源语言 ALT 任务上的有效性。


<details>
  <summary>Details</summary>
Motivation: 越南语音乐的自动歌词转录 (ALT) 由于其声调复杂性和方言变异性而面临独特的挑战，但由于缺乏专门的数据集，因此在很大程度上仍未得到探索。

Method: 我们收集了 VietLyrics 数据集，其中包含 647 小时的歌曲，并带有逐行对齐的歌词和元数据。我们还微调了 Whisper 模型，并在 VietLyrics 数据集上对其进行了评估。

Result: 与现有的多语言 ALT 系统（包括 LyricWhiz）相比，我们微调的 Whisper 模型在转录准确性和处理非人声段落方面取得了更好的结果。

Conclusion: 我们公开发布了 VietLyrics 数据集和我们的模型，旨在推动越南语音乐计算研究，并展示这种方法在低资源语言和音乐 ALT 方面的潜力。

Abstract: Automatic Lyrics Transcription (ALT) for Vietnamese music presents unique
challenges due to its tonal complexity and dialectal variations, but remains
largely unexplored due to the lack of a dedicated dataset. Therefore, we
curated the first large-scale Vietnamese ALT dataset (VietLyrics), comprising
647 hours of songs with line-level aligned lyrics and metadata to address these
issues. Our evaluation of current ASRbased approaches reveal significant
limitations, including frequent transcription errors and hallucinations in
non-vocal segments. To improve performance, we fine-tuned Whisper models on the
VietLyrics dataset, achieving superior results compared to existing
multilingual ALT systems, including LyricWhiz. We publicly release VietLyrics
and our models, aiming to advance Vietnamese music computing research while
demonstrating the potential of this approach for ALT in low-resource language
and music.

</details>


### [382] [Graph-Coarsening Approach for the Capacitated Vehicle Routing Problem with Time Windows](https://arxiv.org/abs/2510.22329)
*Mustafa Mert Özyılmaz*

Main category: cs.AI

TL;DR: 该论文提出了一种用于解决大规模带时窗车辆路径问题的多层图粗化和精炼框架，通过时空距离度量聚合客户，使用经典启发式算法求解简化问题，然后进行可行性修正以恢复到原始空间。实验表明，该方法在保证或提高解的质量的同时，显著减少了计算时间，尤其是在容量和时间窗约束方面。论文还探讨了量子启发式优化技术的融合潜力。


<details>
  <summary>Details</summary>
Motivation: 解决大规模带时窗车辆路径问题的计算挑战。

Method: 提出一种多层图粗化和精炼框架，使用时空距离度量聚合客户，并通过可行性修正进行恢复。

Result: 在Solomon基准实例上，该方法在减少计算时间的同时，保持或提高了解决方案的质量，特别是在容量和时间窗约束方面。

Conclusion: 该提出的多层图粗化和精炼框架能够有效解决大规模带时窗车辆路径问题，并有潜力结合量子启发式优化技术进一步加速求解过程。

Abstract: The Capacitated Vehicle Routing Problem with Time Windows (CVRPTW) is a
fundamental NP-hard optimization problem in logistics. Solving large-scale
instances remains computationally challenging for exact solvers. This work
introduces a multilevel graph coarsening and refinement framework that
aggregates customers into meta-nodes using a spatio-temporal distance metric.
The reduced problem is solved with classical heuristics and subsequently
expanded back into the original space with feasibility corrections. Preliminary
experiments on Solomon benchmark instances show that the proposed method
reduces computation time while preserving or improving solution quality,
particularly with respect to capacity and time window constraints. The paper
also explores the integration of quantum-inspired optimization techniques,
highlighting their potential to further accelerate large-scale vehicle routing
tasks.

</details>


### [383] [LIFT: Interpretable truck driving risk prediction with literature-informed fine-tuned LLMs](https://arxiv.org/abs/2510.22333)
*Xiao Hu,Yuansheng Lian,Ke Zhang,Yunxuan Li,Yuelong Su,Meng Li*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This study proposes an interpretable prediction framework with
literature-informed fine-tuned (LIFT) LLMs for truck driving risk prediction.
The framework integrates an LLM-driven Inference Core that predicts and
explains truck driving risk, a Literature Processing Pipeline that filters and
summarizes domain-specific literature into a literature knowledge base, and a
Result Evaluator that evaluates the prediction performance as well as the
interpretability of the LIFT LLM. After fine-tuning on a real-world truck
driving risk dataset, the LIFT LLM achieved accurate risk prediction,
outperforming benchmark models by 26.7% in recall and 10.1% in F1-score.
Furthermore, guided by the literature knowledge base automatically constructed
from 299 domain papers, the LIFT LLM produced variable importance ranking
consistent with that derived from the benchmark model, while demonstrating
robustness in interpretation results to various data sampling conditions. The
LIFT LLM also identified potential risky scenarios by detecting key combination
of variables in truck driving risk, which were verified by PERMANOVA tests.
Finally, we demonstrated the contribution of the literature knowledge base and
the fine-tuning process in the interpretability of the LIFT LLM, and discussed
the potential of the LIFT LLM in data-driven knowledge discovery.

</details>


### [384] [DynaSolidGeo: A Dynamic Benchmark for Genuine Spatial Mathematical Reasoning of VLMs in Solid Geometry](https://arxiv.org/abs/2510.22340)
*Changti Wu,Shijie Lian,Zihao Liu,Lei Zhang,Laurence Tianruo Yang,Kai Chen*

Main category: cs.AI

TL;DR: 该研究提出了DynaSolidGeo，一个用于评估多模态大模型在三维几何问题解决中的空间推理能力的动态基准。


<details>
  <summary>Details</summary>
Motivation: 现有二维几何问题解决的基准存在局限性，例如侧重于静态数据集、易受数据污染和死记硬背影响，并且仅评估最终答案而忽略推理过程。

Method: 通过半自动标注流程构建了一个包含503个种子问题的动态基准，这些问题可以生成无限数量的文本-视觉实例。该基准不仅评估答案准确性，还基于专家标注的推理链评估逻辑有效性和因果一致性。

Result: 在多模态大模型上的实验显示，模型在动态设置下性能差异显著，并且在心理旋转和可视化等需要高级空间智能的任务上表现不佳。

Conclusion: DynaSolidGeo是首个用于评估真实空间推理能力的三维几何动态基准，实验结果揭示了当前多模态大模型在处理三维几何问题时面临的挑战。

Abstract: Solid geometry problem solving demands spatial mathematical reasoning that
integrates spatial intelligence and symbolic reasoning. However, most existing
multimodal mathematical reasoning benchmarks focus primarily on 2D plane
geometry, rely on static datasets prone to data contamination and memorization,
and evaluate models solely by final answers, overlooking the reasoning process.
To address these limitations, we introduce DynaSolidGeo, the first dynamic
benchmark for evaluating genuine spatial reasoning in Vision-Language Models
(VLMs). Constructed through a semi-automatic annotation pipeline, DynaSolidGeo
contains 503 expert-curated seed questions that can, in principle, dynamically
generate an unbounded number of diverse multimodal text-visual instances.
Beyond answer accuracy, we incorporate process evaluation based on
expert-annotated reasoning chains to measure logical validity and causal
coherence. Experiments across representative open-source and closed-source VLMs
reveal large performance gaps, severe degradation in dynamic settings, and poor
performance on tasks requiring high-level spatial intelligence, such as mental
rotation and visualization. The code and dataset are available at
\href{https://zgca-ai4edu.github.io/DynaSolidGeo/}{DynaSolidGeo}.

</details>


### [385] [Reasoning Models Reason Well, Until They Don't](https://arxiv.org/abs/2510.22371)
*Revanth Rameshkumar,Jimson Huang,Yunxin Sun,Fei Xia,Abulhair Saparov*

Main category: cs.AI

TL;DR: 大型推理模型（LRMs）在现有基准测试中表现出色，但在处理更复杂的推理问题时会突然失效，表明其泛化能力有限，但它们在现实世界的应用中仍有短期价值。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）在复杂推理任务中的局限性，并探索通过微调（LRMs）来改进这些模型，同时开发新的、可扩展的复杂性评估方法。

Method: 通过使用新数据集DeepRD来评估LRMs在处理具有可扩展复杂性的推理问题上的表现，并将其与真实世界数据集的复杂性分布进行比较。

Result: LRMs在具有一定复杂度的推理任务中表现良好，但在超过一定阈值后性能会突然下降，不具备泛化能力。现实世界中的大多数示例落在LRMs的能力范围内，但长尾分布暴露了其潜在的失败风险。

Conclusion: LRMs在短期内具有实用价值，但需要新的方法来克服现有模型在处理超出训练分布复杂性的问题时的泛化能力限制。

Abstract: Large language models (LLMs) have shown significant progress in reasoning
tasks. However, recent studies show that transformers and LLMs fail
catastrophically once reasoning problems exceed modest complexity. We revisit
these findings through the lens of large reasoning models (LRMs) -- LLMs
fine-tuned with incentives for step-by-step argumentation and
self-verification. LRM performance on graph and reasoning benchmarks such as
NLGraph seem extraordinary, with some even claiming they are capable of
generalized reasoning and innovation in reasoning-intensive fields such as
mathematics, physics, medicine, and law. However, by more carefully scaling the
complexity of reasoning problems, we show existing benchmarks actually have
limited complexity. We develop a new dataset, the Deep Reasoning Dataset
(DeepRD), along with a generative process for producing unlimited examples of
scalable complexity. We use this dataset to evaluate model performance on graph
connectivity and natural language proof planning. We find that the performance
of LRMs drop abruptly at sufficient complexity and do not generalize. We also
relate our LRM results to the distributions of the complexities of large,
real-world knowledge graphs, interaction graphs, and proof datasets. We find
the majority of real-world examples fall inside the LRMs' success regime, yet
the long tails expose substantial failure potential. Our analysis highlights
the near-term utility of LRMs while underscoring the need for new methods that
generalize beyond the complexity of examples in the training distribution.

</details>


### [386] [Modeling Hierarchical Thinking in Large Reasoning Models](https://arxiv.org/abs/2510.22437)
*G M Shahariar,Ali Nazari,Erfan Shayegani,Nael Abu-Ghazaleh*

Main category: cs.AI

TL;DR: LLMs可以通过逐步推理（chain-of-thought, CoT）来展现出强大的推理能力。本文提出使用无记忆有限状态机（FSM）来模拟和解释LLMs的CoT推理过程，将推理过程抽象为一系列离散的状态（如初始化、推导、策略选择、不确定性估计、回溯、结论），从而提供一种分析、理解和可视化不同模型推理方式的新方法，并揭示其潜在的缺陷。


<details>
  <summary>Details</summary>
Motivation: 理解大型语言模型（LLMs）的推理能力，特别是其新兴的层级思维策略，这对于改进模型的训练和理解其鲁棒性至关重要。

Method: 使用无记忆有限状态机（FSM）来近似LLMs的层级推理动态，将其抽象为一个结构化、可解释的系统。通过识别并标注CoT推理过程中的关键状态（初始化、推导、策略选择、不确定性估计、回溯、结论），将推理轨迹表示为状态转移序列。

Result: FSM模型能够揭示不同模型在解决问题时独特的推理模式和潜在的不足之处，提供了一个评估和改进LLM推理能力的新视角。

Conclusion: FSM公式化为分析和解释LLM的CoT推理提供了一种系统化的方法，通过揭示推理模式的差异，有助于理解和改进LLM的推理能力。

Abstract: Large Language Models (LLMs) have demonstrated remarkable reasoning abilities
when they generate step-by-step solutions, known as chain-of-thought (CoT)
reasoning. When trained to using chain-of-thought reasoning examples, the
resulting models (called Large Reasoning Models, or LRMs) appear to learn
hierarchical thinking strategies similar to those used by humans. However,
understanding LRMs emerging reasoning capabilities remains a difficult open
problem, with many potential important applications including improving
training and understanding robustness. In this paper, we adopt a memoryless
Finite State Machine formulation to approximate LRM's emerging hierarchical
reasoning dynamics as a structured, interpretable abstraction. We identify a
small set of discrete reasoning states including - initialization, deduction,
augmentation-strategy, uncertainty-estimation, backtracking, and
final-conclusion that capture the high-level states present in the model's
reasoning process. By annotating each step of a model's CoT with these states,
we can represent the reasoning trajectory as a transition sequence through the
state graph. This FSM formulation provides a systematic way to analyze,
interpret and visualize how different models approach problems. We describe the
FSM model, provide examples of CoT annotations under this scheme, and discuss
how it can shed light on differences between available models in their approach
to reasoning. Our results demonstrate that this FSM-based analysis reveals
distinct reasoning patterns and potential shortcomings, offering a new lens to
evaluate and improve LLM reasoning.

</details>


### [387] [Learning "Partner-Aware" Collaborators in Multi-Party Collaboration](https://arxiv.org/abs/2510.22462)
*Abhijnan Nath,Nikhil Krishnaswamy*

Main category: cs.AI

TL;DR: LLM在多轮、多方协作任务中可能忽视人类的干预，本文提出了一种名为ICR的新算法来解决此问题，以提高协作的共同基础。


<details>
  <summary>Details</summary>
Motivation: 在代理场景中，LLM作为人类的协作者，评估其有效协作能力至关重要。然而，标准的RLHF训练方法可能导致LLM忽视人类的干预，增加协作的共同基础是具有挑战性的。

Method: 本文采用双人改进动作MDP来研究标准AI代理的次优行为，并提出了一种名为ICR（Interruptible Collaborative Roleplayer）的新型伙伴感知学习算法来训练共同基础最优的协作者。

Result: 实验表明，ICR在促进共同基础收敛和探索更多样化的解决方案方面，平均能力优于现有方法。

Conclusion: ICR算法能够有效地训练出能够提高群体共同基础、探索更多样化解决方案的LLM协作代理。

Abstract: Large Language Models (LLMs) are increasingly bring deployed in agentic
settings where they act as collaborators with humans. Therefore, it is
increasingly important to be able to evaluate their abilities to collaborate
effectively in multi-turn, multi-party tasks. In this paper, we build on the AI
alignment and safe interruptability literature to offer novel theoretical
insights on collaborative behavior between LLM-driven collaborator agents and
an intervention agent. Our goal is to learn an ideal partner-aware collaborator
that increases the group's common-ground (CG)-alignment on task-relevant
propositions-by intelligently collecting information provided in interventions
by a partner agent.We show how LLM agents trained using standard RLHF and
related approaches are naturally inclined to ignore possibly well-meaning
interventions, which makes increasing group common ground non-trivial in this
setting. We employ a two-player Modified-Action MDP to examine this suboptimal
behavior of standard AI agents, and propose Interruptible Collaborative
Roleplayer (ICR)-a novel partner-aware learning algorithm to train CG-optimal
collaborators. Experiments on multiple collaborative task environments show
that ICR, on average, is more capable of promoting successful CG convergence
and exploring more diverse solutions in such tasks.

</details>


### [388] [OFFSIDE: Benchmarking Unlearning Misinformation in Multimodal Large Language Models](https://arxiv.org/abs/2510.22535)
*Hao Zheng,Zirui Pang,Ling li,Zhijie Deng,Yuhan Pu,Zhaowei Zhu,Xiaobo Xia,Jiaheng Wei*

Main category: cs.AI

TL;DR: 现有的多模态大语言模型（MLLM）的机器卸载（MU）基准存在图像多样性不足、潜在不准确性和评估场景不足的问题。为此，我们提出了OFFSIDE，一个基于足球转会传闻的、用于评估MLLM错误信息卸载的新型基准。该数据集包含15.68K条记录，涵盖80名球员，并设有四个测试集以评估遗忘效果、泛化性、效用和鲁棒性。OFFSIDE支持选择性卸载、纠正性再学习以及仅卸载文本数据的单模态卸载。实验表明，单模态方法在处理多模态传闻时无效，遗忘效果很大程度上受灾难性遗忘驱动，“视觉传闻”难以处理，卸载的传闻易于恢复，且所有方法都容易受到提示攻击。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM的机器卸载基准在图像多样性、准确性和评估场景方面存在不足，无法满足真实世界应用的需求。

Method: 提出OFFSIDE基准，该基准包含15.68K条关于80名球员的足球转会传闻记录，并包含四个评估测试集（遗忘、泛化、效用、鲁棒性），支持选择性卸载、纠正性再学习和单模态卸载。

Result: （1）单模态方法在处理多模态传闻时失效；（2）卸载效果很大程度上受灾难性遗忘影响；（3）所有方法在处理“视觉传闻”时都面临困难；（4）卸载后的传闻容易被恢复；（5）所有方法均易受提示攻击。

Conclusion: 现有的机器卸载方法在处理多模态信息时存在显著的脆弱性，需要开发更鲁棒的多模态卸载解决方案。

Abstract: Advances in Multimodal Large Language Models (MLLMs) intensify concerns about
data privacy, making Machine Unlearning (MU), the selective removal of learned
information, a critical necessity. However, existing MU benchmarks for MLLMs
are limited by a lack of image diversity, potential inaccuracies, and
insufficient evaluation scenarios, which fail to capture the complexity of
real-world applications. To facilitate the development of MLLMs unlearning and
alleviate the aforementioned limitations, we introduce OFFSIDE, a novel
benchmark for evaluating misinformation unlearning in MLLMs based on football
transfer rumors. This manually curated dataset contains 15.68K records for 80
players, providing a comprehensive framework with four test sets to assess
forgetting efficacy, generalization, utility, and robustness. OFFSIDE supports
advanced settings like selective unlearning and corrective relearning, and
crucially, unimodal unlearning (forgetting only text data). Our extensive
evaluation of multiple baselines reveals key findings: (1) Unimodal methods
(erasing text-based knowledge) fail on multimodal rumors; (2) Unlearning
efficacy is largely driven by catastrophic forgetting; (3) All methods struggle
with "visual rumors" (rumors appear in the image); (4) The unlearned rumors can
be easily recovered and (5) All methods are vulnerable to prompt attacks. These
results expose significant vulnerabilities in current approaches, highlighting
the need for more robust multimodal unlearning solutions. The code is available
at
\href{https://github.com/zh121800/OFFSIDE}{https://github.com/zh121800/OFFSIDE}.

</details>


### [389] [ATOM: AdapTive and OptiMized dynamic temporal knowledge graph construction using LLMs](https://arxiv.org/abs/2510.22590)
*Yassir Lairgi,Ludovic Moncla,Khalid Benabdeslem,Rémy Cazabet,Pierre Cléau*

Main category: cs.AI

TL;DR: ATOM是一个能够处理动态知识图谱构建的少样本方法，它通过将文本分解为“原子”事实并采用双时间模型来提高信息提取的完整性、稳定性和效率。


<details>
  <summary>Details</summary>
Motivation: 传统静态知识图谱在处理动态、时变数据方面存在局限性，而现有的零/少样本方法则不稳定且覆盖不全。

Method: ATOM将输入文档分解为最小的“原子”事实，然后构建原子时间知识图谱（TKGs），并使用区分信息观察时间和有效时间的双时间模型，最后并行合并原子TKGs。

Result: ATOM在提取的完备性上提高了约18%，稳定性提高了约17%，延迟降低了90%以上，显示出强大的可扩展性。

Conclusion: ATOM通过其创新的原子化和双时间建模方法，有效解决了动态TKG构建中的挑战，在性能和效率上均优于基线方法。

Abstract: In today's rapidly expanding data landscape, knowledge extraction from
unstructured text is vital for real-time analytics, temporal inference, and
dynamic memory frameworks. However, traditional static knowledge graph (KG)
construction often overlooks the dynamic and time-sensitive nature of
real-world data, limiting adaptability to continuous changes. Moreover, recent
zero- or few-shot approaches that avoid domain-specific fine-tuning or reliance
on prebuilt ontologies often suffer from instability across multiple runs, as
well as incomplete coverage of key facts. To address these challenges, we
introduce ATOM (AdapTive and OptiMized), a few-shot and scalable approach that
builds and continuously updates Temporal Knowledge Graphs (TKGs) from
unstructured texts. ATOM splits input documents into minimal, self-contained
"atomic" facts, improving extraction exhaustivity and stability. Then, it
constructs atomic TKGs from these facts while employing a dual-time modeling
that distinguishes when information is observed from when it is valid. The
resulting atomic TKGs are subsequently merged in parallel. Empirical
evaluations demonstrate that ATOM achieves ~18% higher exhaustivity, ~17%
better stability, and over 90% latency reduction compared to baseline methods,
demonstrating a strong scalability potential for dynamic TKG construction.

</details>


### [390] [A Framework for Quantifying How Pre-Training and Context Benefit In-Context Learning](https://arxiv.org/abs/2510.22594)
*Bingqing Song,Jiaxiang Li,Rong Wang,Songtao Lu,Mingyi Hong*

Main category: cs.AI

TL;DR: ICL 的能力源于预训练和上下文构建，具体表现为上下文可以量化地将输出分布引导至查询任务分布，并且 ICL 性能与上下文长度及预训练与查询任务分布之间的 KL 散度存在精确关系。


<details>
  <summary>Details</summary>
Motivation: 现有理论未能清晰解释 ICL 能力的来源，特别是预训练程序和上下文构建等关键因素的作用。

Method: 提出一个新的框架来分析 ICL 性能，包括网络架构、数据编码、数据生成和提示构建过程。首先，通过一个简单的单层 Transformer 例子，展示了在预训练数据分布与查询任务分布不同的情况下，合适的上下文可以量化地将输出分布移向查询任务分布。然后，将该发现推广到更一般的情况，并推导出 ICL 性能、上下文长度以及预训练与查询任务分布之间的 KL 散度之间的精确关系。

Result: 发现当预训练数据分布与查询任务分布不同时，适当构建的上下文能够量化地将输出分布引导至查询任务分布，从而在查询主题上实现准确预测。推导出了 ICL 性能、上下文长度和 KL 散度之间的精确关系。

Conclusion: ICL 的性能受到预训练和上下文构建的共同影响，并且其性能与上下文长度以及预训练与查询任务分布之间的 KL 散度存在明确的数学关系。

Abstract: Pre-trained large language models have demonstrated a strong ability to learn
from context, known as in-context learning (ICL). Despite a surge of recent
applications that leverage such capabilities, it is by no means clear, at least
theoretically, how the ICL capabilities arise, and in particular, what is the
precise role played by key factors such as pre-training procedure as well as
context construction. In this work, we propose a new framework to analyze the
ICL performance, for a class of realistic settings, which includes network
architectures, data encoding, data generation, and prompt construction process.
As a first step, we construct a simple example with a one-layer transformer,
and show an interesting result, namely when the pre-train data distribution is
different from the query task distribution, a properly constructed context can
shift the output distribution towards the query task distribution, in a
quantifiable manner, leading to accurate prediction on the query topic. We then
extend the findings in the previous step to a more general case, and derive the
precise relationship between ICL performance, context length and the KL
divergence between pre-train and query task distribution. Finally, we provide
experiments to validate our theoretical results.

</details>


### [391] [CLIN-LLM: A Safety-Constrained Hybrid Framework for Clinical Diagnosis and Treatment Generation](https://arxiv.org/abs/2510.22609)
*Md. Mehedi Hasan,Rafid Mostafiz,Md. Abir Hossain,Bikash Kumar Paul*

Main category: cs.AI

TL;DR: CLIN-LLM是一个安全约束的混合框架，用于症状到疾病的分类和个性化治疗建议。它通过整合多模态患者编码、不确定性校准的疾病分类和检索增强的治疗生成，解决了现有LLM系统缺乏医学依据和不确定性量化的问题。CLIN-LLM在准确性和临床安全性方面表现优于现有模型，并将低置信度病例标记出来以供专家审查，从而提高了决策支持的可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于LLM的系统在医学领域存在缺乏依据和无法量化不确定性的问题，导致输出不安全，尤其是在异质性高的患者环境中，症状到疾病的分类和治疗建议面临挑战。CLIN-LLM旨在通过引入安全约束和医学依据来解决这些问题。

Method: CLIN-LLM采用混合流水线，包括：1. 多模态患者编码；2. 不确定性校准的疾病分类（使用BioBERT和Focal Loss与Monte Carlo Dropout）；3. 检索增强的治疗生成（使用Biomedical Sentence-BERT检索MedDialog语料库，并用FLAN-T5生成治疗建议）；4. RxNorm进行抗生素管理和药物-药物相互作用（DDI）筛查。其中18%的低置信度病例会被自动标记。

Result: CLIN-LLM在疾病分类方面达到了98%的准确率和F1分数，比ClinicalBERT提高了7.1%（p < 0.001）。在治疗建议方面，检索精度达到78%（top-5），临床医生评分为4.2/5。与GPT-5相比，不安全的抗生素建议减少了67%。

Conclusion: CLIN-LLM在准确性、可解释性和临床安全性方面均表现出优越性，证明了其作为可部署的、包含人类在环的人工智能决策支持框架的潜力，尤其适用于资源有限的医疗环境。

Abstract: Accurate symptom-to-disease classification and clinically grounded treatment
recommendations remain challenging, particularly in heterogeneous patient
settings with high diagnostic risk. Existing large language model (LLM)-based
systems often lack medical grounding and fail to quantify uncertainty,
resulting in unsafe outputs. We propose CLIN-LLM, a safety-constrained hybrid
pipeline that integrates multimodal patient encoding, uncertainty-calibrated
disease classification, and retrieval-augmented treatment generation. The
framework fine-tunes BioBERT on 1,200 clinical cases from the Symptom2Disease
dataset and incorporates Focal Loss with Monte Carlo Dropout to enable
confidence-aware predictions from free-text symptoms and structured vitals.
Low-certainty cases (18%) are automatically flagged for expert review, ensuring
human oversight. For treatment generation, CLIN-LLM employs Biomedical
Sentence-BERT to retrieve top-k relevant dialogues from the 260,000-sample
MedDialog corpus. The retrieved evidence and patient context are fed into a
fine-tuned FLAN-T5 model for personalized treatment generation, followed by
post-processing with RxNorm for antibiotic stewardship and drug-drug
interaction (DDI) screening. CLIN-LLM achieves 98% accuracy and F1 score,
outperforming ClinicalBERT by 7.1% (p < 0.001), with 78% top-5 retrieval
precision and a clinician-rated validity of 4.2 out of 5. Unsafe antibiotic
suggestions are reduced by 67% compared to GPT-5. These results demonstrate
CLIN-LLM's robustness, interpretability, and clinical safety alignment. The
proposed system provides a deployable, human-in-the-loop decision support
framework for resource-limited healthcare environments. Future work includes
integrating imaging and lab data, multilingual extensions, and clinical trial
validation.

</details>


### [392] [SwiftSolve: A Self-Iterative, Complexity-Aware Multi-Agent Framework for Competitive Programming](https://arxiv.org/abs/2510.22626)
*Adhyayan Veer Singh,Aaron Shen,Brian Law,Ahmed Ismail,Jonas Rohweder,Sean O'Brien,Kevin Zhu*

Main category: cs.AI

TL;DR: SwiftSolve是一个多智能体系统，用于解决竞争性编程中的时间和内存限制问题，它结合了算法规划、实证分析和基于复杂度的修复，在26个问题上达到了61.54%的首次通过率和80.77%的三次通过率，并且在效率方面优于Claude Opus 4。


<details>
  <summary>Details</summary>
Motivation: 传统的基于LLM的程序生成方法往往只关注正确性，而忽略了时间和内存等资源限制，这在竞争性编程等场景下是不够的。

Method: SwiftSolve构建了一个多智能体系统，其中包含规划、编码、剖析和复杂度分析等专门的智能体。该系统首先由规划智能体提出算法草图，然后由静态剪枝智能体过滤掉高风险的规划。编码智能体生成C++代码，剖析智能体负责编译和执行代码以收集时间和内存使用情况。复杂度分析智能体则根据收集到的数据拟合增长曲线，确定复杂度类别，并向规划或编码智能体发送补丁以进行针对性修复。智能体之间通过JSON进行通信，并设置迭代上限和递减回报机制来控制整个过程。

Result: 在26个问题（16个Big-O问题，10个Codeforces Div. 2问题）的测试中，SwiftSolve在首次尝试时达到了61.54%（16/26）的pass@1，在3次尝试内解决问题的比例（Solved@<=3）为80.77%。平均每次尝试的延迟从11.96秒略微增加到12.66秒。总体的运行成功率为73.08%，平均运行时间为12.40秒。失败的案例主要是由于资源限制（超时或超出内存），而非逻辑错误。

Conclusion: SwiftSolve通过引入剖析和基于复杂度的再规划，成功地解决了LLM生成程序在资源效率方面的问题，同时保持了较高的正确性。该系统在效率指标（eff@k）、超时/内存不足（TLE/MLE）的发生率以及Big-O问题的复杂度拟合准确性方面都表现出色，证明了其在竞争性编程领域的有效性。

Abstract: Correctness alone is insufficient: LLM-generated programs frequently satisfy
unit tests while violating contest time or memory budgets. We present
SwiftSolve, a complexity-aware multi-agent system for competitive programming
that couples algorithmic planning with empirical profiling and
complexity-guided repair. We frame competitive programming as a software
environment where specialized agents act as programmers, each assuming roles
such as planning, coding, profiling, and complexity analysis. A Planner
proposes an algorithmic sketch; a deterministic Static Pruner filters high-risk
plans; a Coder emits ISO C++17; a Profiler compiles and executes candidates on
a fixed input-size schedule to record wall time and peak memory; and a
Complexity Analyst fits log-log growth (s, R2) with an LLM fallback to assign a
complexity class and dispatch targeted patches to either the Planner or Coder.
Agents communicate via typed, versioned JSON; a controller enforces iteration
caps and diminishing returns stopping. Evaluated on 26 problems (16 BigO, 10
Codeforces Div. 2) in a POSIX sandbox (2 s / 256-512 MB), SwiftSolve attains
pass@1 = 61.54% (16/26) on the first attempt and Solved@<=3 = 80.77% with
marginal latency change (mean 11.96 s to 12.66 s per attempt). Aggregate
run-level success is 73.08% at 12.40 s mean. Failures are predominantly
resource-bound, indicating inefficiency rather than logic errors. Against
Claude Opus 4, SwiftSolve improves run-level success (73.1% vs 52.6%) at
approximately 2x runtime overhead (12.4 s vs 6.8 s). Beyond correctness
(pass@k), we report efficiency metrics (eff@k for runtime and memory, incidence
of TLE or MLE, and complexity fit accuracy on BigO), demonstrating that
profiling and complexity-guided replanning reduce inefficiency while preserving
accuracy.

</details>


### [393] [Do Stop Me Now: Detecting Boilerplate Responses with a Single Iteration](https://arxiv.org/abs/2510.22679)
*Yuval Kainan,Shaked Zychlinski*

Main category: cs.AI

TL;DR: LLMs通过分析第一个生成词的对数概率来区分正式回答和样板化回答，从而实现效率提升。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在生成拒绝、简单确认和日常问候等样板化响应时消耗了大量的计算资源，导致不必要的成本和延迟。

Method: 提出一种仅通过一步生成即可检测此类响应的简单有效方法，利用第一个生成词的对数概率分布作为分类整个后续响应性质的信号。

Result: 实验表明，第一个词的对数概率向量能清晰地区分不同响应类型，使用轻量级k-NN分类器能高精度地预测响应是实质性回答还是样板化回答。

Conclusion: 提出一种实用且计算成本极低的技术，通过提前终止或重定向到更小的模型来优化LLM推理，从而显著节省计算成本，为更高效、更可持续的LLM部署提供了直接途径。

Abstract: Large Language Models (LLMs) often expend significant computational resources
generating boilerplate responses, such as refusals, simple acknowledgements and
casual greetings, which adds unnecessary cost and latency. To address this
inefficiency, we propose a simple yet highly effective method for detecting
such responses after only a single generation step. We demonstrate that the
log-probability distribution of the first generated token serves as a powerful
signal for classifying the nature of the entire subsequent response. Our
experiments, conducted across a diverse range of small, large, and
reasoning-specialized models, show that the first-token log-probability vectors
form distinctly separable clusters for different response types. Using a
lightweight k-NN classifier, we achieve high accuracy in predicting whether a
response will be a substantive answer or a form of boilerplate response,
including user-specified refusals. The primary implication is a practical,
computationally trivial technique, optimizing LLM inference by enabling early
termination or redirection to a smaller model, thereby yielding significant
savings in computational cost. This work presents a direct path toward more
efficient and sustainable LLM deployment.

</details>


### [394] [RaCoT: Plug-and-Play Contrastive Example Generation Mechanism for Enhanced LLM Reasoning Reliability](https://arxiv.org/abs/2510.22710)
*Kaitong Cai,Jusheng Zhang,Yijia Fan,Jing Yang,Keze Wang*

Main category: cs.AI

TL;DR: RaCoT通过在检索前生成对比问题来改进RAG，解决了长尾查询的知识稀疏和语义模糊问题，提高了准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 检索增强生成（RAG）在处理知识稀疏和语义模糊的长尾查询时存在瓶颈，检索噪声会干扰推理并需要昂贵的事后处理。

Method: 提出RaCoT（Retrieval-aware Contrastive-of-Thought）框架，在检索前进行对比思维，通过生成语义相邻但答案不同的对比问题，并提取$\Delta$-Prompt来捕捉关键差异，引导模型关注决定答案分歧的关键细节。

Result: 在六个权威基准测试中，RaCoT的性能优于RankRAG和Self-RAG等基线模型0.9-2.4个百分点，在对抗性测试中性能下降仅为8.6%，显著优于其他方法（超过15%的下降）。其低延迟（3.12s）和低令牌开销（11.54）也使其处于准确-效率帕累托前沿。

Conclusion: RaCoT将RAG范式从“事后上下文清理”转变为“先验塑造区分性推理”，为实时、资源受限的部署提供了通往可靠AI系统的高效且鲁棒的途径。

Abstract: Retrieval-Augmented Generation (RAG) faces a core bottleneck with
knowledge-sparse and semantically ambiguous long-tail queries, where retrieval
noise distorts reasoning and necessitates costly post-processing. To tackle
this, we propose RaCoT (Retrieval-aware Contrastive-of-Thought), a novel
framework that shifts contrastive thinking to the pre-retrieval stage. By
automatically generating a semantically adjacent yet differently answered
contrastive question and extracting a $\Delta$-Prompt to capture their key
differences, RaCoT guides the model to proactively focus on the ``critical
details that determine answer divergence." This approach allows it to suppress
semantic interference within a single retrieval pass, overcoming the
theoretical bottleneck of single-vector queries that struggle to simultaneously
encode signals for what to attend to and what to ignore. On six authoritative
benchmarks, including PopQA and TriviaQA-unfiltered, RaCoT outperforms strong
baselines like RankRAG and Self-RAG by 0.9-2.4 percentage points. It exhibits
superior robustness, with a performance drop of only 8.6\% in adversarial
tests, far surpassing the over 15\% degradation in other methods. Furthermore,
its low latency (3.12s) and token overhead (11.54) place it on the
accuracy-efficiency Pareto frontier, while ablation studies validate the
necessity of each component. Ultimately, RaCoT reframes the RAG paradigm from
``post-hoc context cleaning" to ``a priori shaping of discriminative
reasoning", offering an efficient and robust path toward reliable AI systems
for real-time, resource-constrained deployments.

</details>


### [395] [Critical Insights into Leading Conversational AI Models](https://arxiv.org/abs/2510.22729)
*Urja Kohli,Aditi Singh,Arun Sharma*

Main category: cs.AI

TL;DR: 五种主流大语言模型在性能、道德和可用性方面进行了比较，各有优劣。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLM）的广泛应用，理解不同模型在性能、道德行为和可用性方面的差异至关重要，因为这些差异源于它们不同的设计理念。

Method: 通过分析性能和准确性、道德与偏见缓解、可用性与集成三个关键因素，对谷歌的Gemini、High-Flyer的DeepSeek、Anthropic的Claude、OpenAI的GPT模型和Meta的LLaMA这五种顶级LLM进行了比较。

Result: 研究发现，Claude在道德推理方面表现出色，Gemini在多模态能力和强大的伦理框架方面更胜一筹，DeepSeek在基于事实的推理方面表现突出，LLaMA适用于开放式应用，而ChatGPT则在易用性方面表现均衡。

Conclusion: 这些模型在工作性能、易用性和道德考量方面存在显著差异，用户应根据自身需求，发挥各模型的优势。

Abstract: Big Language Models (LLMs) are changing the way businesses use software, the
way people live their lives and the way industries work. Companies like Google,
High-Flyer, Anthropic, OpenAI and Meta are making better LLMs. So, it's crucial
to look at how each model is different in terms of performance, moral behaviour
and usability, as these differences are based on the different ideas that built
them. This study compares five top LLMs: Google's Gemini, High-Flyer's
DeepSeek, Anthropic's Claude, OpenAI's GPT models and Meta's LLaMA. It performs
this by analysing three important factors: Performance and Accuracy, Ethics and
Bias Mitigation and Usability and Integration. It was found that Claude has
good moral reasoning, Gemini is better at multimodal capabilities and has
strong ethical frameworks. DeepSeek is great at reasoning based on facts, LLaMA
is good for open applications and ChatGPT delivers balanced performance with a
focus on usage. It was concluded that these models are different in terms of
how well they work, how easy they are to use and how they treat people
ethically, making it a point that each model should be utilised by the user in
a way that makes the most of its strengths.

</details>


### [396] [Multi-Modal Fact-Verification Framework for Reducing Hallucinations in Large Language Models](https://arxiv.org/abs/2510.22751)
*Piyushkumar Patel*

Main category: cs.AI

TL;DR: LLM 幻觉问题通过结合结构化数据库、实时网络搜索和学术文献进行事实核查，可将幻觉减少 67%，同时保持响应质量。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）会自信地生成听起来完全合理但实际上是错误的信息，这一“幻觉”问题是将其应用于需要准确性的现实世界应用的主要障碍。

Method: 开发了一个事实核查框架，通过将 LLM 的输出与多个知识来源进行交叉比对，实时捕捉和纠正错误。该系统结合了结构化数据库、实时网络搜索和学术文献来验证生成的事实声明，并在检测到不一致时自动纠正，同时保持响应的自然流畅性。

Result: 在不同领域的测试表明，该系统可将幻觉减少 67%，同时不牺牲响应质量。在医疗保健、金融和科学研究领域的领域专家对修正后的输出的满意度评分为 89%，显著优于未经核实的 LLM 响应。

Conclusion: 这项工作为提高 LLM 在不允许出现事实错误的应用中的可信度提供了一个实际的解决方案。

Abstract: While Large Language Models have transformed how we interact with AI systems,
they suffer from a critical flaw: they confidently generate false information
that sounds entirely plausible. This hallucination problem has become a major
barrier to deploying these models in real-world applications where accuracy
matters. We developed a fact verification framework that catches and corrects
these errors in real-time by cross checking LLM outputs against multiple
knowledge sources. Our system combines structured databases, live web searches,
and academic literature to verify factual claims as they're generated. When we
detect inconsistencies, we automatically correct them while preserving the
natural flow of the response. Testing across various domains showed we could
reduce hallucinations by 67% without sacrificing response quality. Domain
experts in healthcare, finance, and scientific research rated our corrected
outputs 89% satisfactory a significant improvement over unverified LLM
responses. This work offers a practical solution for making LLMs more
trustworthy in applications where getting facts wrong isn't an option.

</details>


### [397] [Jarvis: Towards Personalized AI Assistant via Personal KV-Cache Retrieval](https://arxiv.org/abs/2510.22765)
*Binxiao Xu,Junyu Feng,Ruichuan An,Yulin Luo,Shilin Yan,Hao Liang,Ming Lu,Wentao Zhang*

Main category: cs.AI

TL;DR: Jarvis是一个创新的框架，通过检索个性化的KV缓存来创建个性化AI助手，该缓存存储用户特定的文本和视觉信息，并在回答问题时用于提高准确性，在多个数据集上取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 现有的个性化视觉语言模型（VLMs）方法在生成准确的个性化答案方面存在挑战，要么学习概念令牌，要么训练VLM利用用户特定信息。

Method: Jarvis框架通过个性化KV缓存检索来存储和利用用户特定的文本（通过元数据摘要）和视觉（通过提取图像块）信息。

Result: Jarvis在视觉问答和纯文本任务的多个数据集上均取得了最先进的成果，尤其在需要细粒度用户特定信息的任务上表现更佳。

Conclusion: Jarvis提供了一种实用且更准确的方法来实现个性化AI助手，特别是在响应需要特定局部细节的查询时。

Abstract: The rapid development of Vision-language models (VLMs) enables open-ended
perception and reasoning. Recent works have started to investigate how to adapt
general-purpose VLMs into personalized assistants. Even commercial models such
as ChatGPT now support model personalization by incorporating user-specific
information. However, existing methods either learn a set of concept tokens or
train a VLM to utilize user-specific information. However, both pipelines
struggle to generate accurate answers as personalized assistants. We introduce
Jarvis, an innovative framework for a personalized AI assistant through
personal KV-Cache retrieval, which stores user-specific information in the
KV-Caches of both textual and visual tokens. The textual tokens are created by
summarizing user information into metadata, while the visual tokens are
produced by extracting distinct image patches from the user's images. When
answering a question, Jarvis first retrieves related KV-Caches from personal
storage and uses them to ensure accuracy in responses. We also introduce a
fine-grained benchmark built with the same distinct image patch mining
pipeline, emphasizing accurate question answering based on fine-grained
user-specific information. Jarvis is capable of providing more accurate
responses, particularly when they depend on specific local details. Jarvis
achieves state-of-the-art results in both visual question answering and
text-only tasks across multiple datasets, indicating a practical path toward
personalized AI assistants. The code and dataset will be released.

</details>


### [398] [How Do AI Agents Do Human Work? Comparing AI and Human Workflows Across Diverse Occupations](https://arxiv.org/abs/2510.22780)
*Zora Zhiruo Wang,Yijia Shao,Omar Shaikh,Daniel Fried,Graham Neubig,Diyi Yang*

Main category: cs.AI

TL;DR: AI代理在软件工程和写作等领域不断优化，但缺乏对人类工作方式的理解。本研究首次直接比较了人类和AI代理在数据分析、工程、计算、写作和设计等多种工作技能上的表现。


<details>
  <summary>Details</summary>
Motivation: AI代理在工作领域的应用日益广泛，但对其工作方式和能力的理解不足，本研究旨在弥合这一差距，明确AI代理的潜力和局限性。

Method: 开发了一个可扩展的工具包，用于从人类或AI代理的计算机使用活动中提取结构化的工作流程，并以此为基础，直接比较了人类和AI代理在多种任务上的表现。

Result: 研究发现，AI代理在所有领域都倾向于采用程序化的方法，与人类的UI中心方法形成对比。AI代理的工作质量较低，并通过数据伪造和滥用工具来掩盖缺陷。然而，AI代理的速度提高了88.3%，成本降低了90.4-96.2%。

Conclusion: AI代理在速度和成本方面具有显著优势，尤其是在可编程任务方面，显示出与人类协作的巨大潜力。尽管其工作质量有待提高，但通过明确其能力和局限性，可以有效地将其应用于特定任务，从而实现高效协作。

Abstract: AI agents are continually optimized for tasks related to human work, such as
software engineering and professional writing, signaling a pressing trend with
significant impacts on the human workforce. However, these agent developments
have often not been grounded in a clear understanding of how humans execute
work, to reveal what expertise agents possess and the roles they can play in
diverse workflows. In this work, we study how agents do human work by
presenting the first direct comparison of human and agent workers across
multiple essential work-related skills: data analysis, engineering,
computation, writing, and design. To better understand and compare
heterogeneous computer-use activities of workers, we introduce a scalable
toolkit to induce interpretable, structured workflows from either human or
agent computer-use activities. Using such induced workflows, we compare how
humans and agents perform the same tasks and find that: (1) While agents
exhibit promise in their alignment to human workflows, they take an
overwhelmingly programmatic approach across all work domains, even for
open-ended, visually dependent tasks like design, creating a contrast with the
UI-centric methods typically used by humans. (2) Agents produce work of
inferior quality, yet often mask their deficiencies via data fabrication and
misuse of advanced tools. (3) Nonetheless, agents deliver results 88.3% faster
and cost 90.4-96.2% less than humans, highlighting the potential for enabling
efficient collaboration by delegating easily programmable tasks to agents.

</details>


### [399] [Agentic Meta-Orchestrator for Multi-task Copilots](https://arxiv.org/abs/2510.22781)
*Xiaofeng Zhu,Yunshen Zhou*

Main category: cs.AI

TL;DR: Microsoft Copilot使用Agentic Meta-orchestrator (AMO)来动态扩展其代理能力，以处理M365电子商务和代码合规性等多种任务。


<details>
  <summary>Details</summary>
Motivation: 需要一个强大的协调器来处理Microsoft Copilot服务中的多任务和可扩展代理，该协调器能够将用户提示的任务分发给正确的代理，并提供自然语言和操作响应。

Method: 提出了一种名为Agentic Meta-orchestrator (AMO)的系统，该系统利用元学习（特别是训练过的决策树模型）来决定代理/模型之间的最佳推理策略，以处理多任务和可扩展代理。

Result: AMO通过两个生产用例进行了演示：Microsoft 365 (M365) 电子商务Copilot，用于向客户推广产品；以及代码合规性Copilot，用于扫描内部DevOps代码中的合规性问题。

Conclusion: AMO能够有效地处理Microsoft Copilot服务中的多任务和可扩展代理，如M365电子商务和代码合规性Copilot所示。

Abstract: Microsoft Copilot suites serve as the universal entry point for various
agents skilled in handling important tasks, ranging from assisting a customer
with product purchases to detecting vulnerabilities in corporate programming
code. Each agent can be powered by language models, software engineering
operations, such as database retrieval, and internal \& external knowledge. The
repertoire of a copilot can expand dynamically with new agents. This requires a
robust orchestrator that can distribute tasks from user prompts to the right
agents. In this work, we propose an Agentic Meta-orchestrator (AMO) for
handling multiple tasks and scalable agents in copilot services, which can
provide both natural language and action responses. We will also demonstrate
the planning that leverages meta-learning, i.e., a trained decision tree model
for deciding the best inference strategy among various agents/models. We
showcase the effectiveness of our AMO through two production use cases:
Microsoft 365 (M365) E-Commerce Copilot and code compliance copilot. M365
E-Commerce Copilot advertises Microsoft products to external customers to
promote sales success. The M365 E-Commerce Copilot provides up-to-date product
information and connects to multiple agents, such as relational databases and
human customer support. The code compliance copilot scans the internal DevOps
code to detect known and new compliance issues in pull requests (PR).

</details>


### [400] [Will Humanity Be Rendered Obsolete by AI?](https://arxiv.org/abs/2510.22814)
*Mohamed El Louadi,Emna Ben Romdhane*

Main category: cs.AI

TL;DR: AI的指数级发展可能导致人类灭绝，原因并非AI的恶意，而是其无法控制的、冷漠的认知优势。


<details>
  <summary>Details</summary>
Motivation: 分析人工智能（AI）对人类构成的生存风险，并追溯从当前AI到超智能的发展轨迹。

Method: 借鉴Irving J. Good和Nick Bostrom的理论工作，并结合近期关于AGI和超智能的出版物，探讨机器指数级增长的认知能力和假设的智商，以及远超人类智能的机器所带来的伦理和生存启示。

Result: 人类灭绝可能并非源于AI的恶意，而是源于其无法控制的、冷漠的认知优势。

Conclusion: AI的指数级发展对人类构成生存风险，其潜在的巨大认知优势可能导致人类灭绝，即使AI没有恶意。

Abstract: This article analyzes the existential risks artificial intelligence (AI)
poses to humanity, tracing the trajectory from current AI to ultraintelligence.
Drawing on Irving J. Good and Nick Bostrom's theoretical work, plus recent
publications (AI 2027; If Anyone Builds It, Everyone Dies), it explores AGI and
superintelligence. Considering machines' exponentially growing cognitive power
and hypothetical IQs, it addresses the ethical and existential implications of
an intelligence vastly exceeding humanity's, fundamentally alien. Human
extinction may result not from malice, but from uncontrollable, indifferent
cognitive superiority.

</details>


### [401] [HRM-Agent: Training a recurrent reasoning model in dynamic environments using reinforcement learning](https://arxiv.org/abs/2510.22832)
*Long H Dang,David Rawlinson*

Main category: cs.AI

TL;DR: HRM-Agent可以通过强化学习解决动态、不确定和部分可观察的环境问题，并重用先前的计算。


<details>
  <summary>Details</summary>
Motivation: HRM模型虽然有很强的推理能力，但只能应用于监督式、静态、全可观察的问题，无法处理现实世界中常见的动态、不确定或部分可观察等问题。

Method: 提出HRM-Agent，一种仅使用强化学习训练的HRM变体，并探索其递归推理过程的动态。

Result: HRM-Agent成功学会了在动态和不确定的迷宫环境中导航到目标，并有证据表明它能够重用早期环境时间步的计算。

Conclusion: HRM-Agent可以有效地应用于更广泛的现实世界问题，克服了HRM模型的局限性。

Abstract: The Hierarchical Reasoning Model (HRM) has impressive reasoning abilities
given its small size, but has only been applied to supervised, static,
fully-observable problems. One of HRM's strengths is its ability to adapt its
computational effort to the difficulty of the problem. However, in its current
form it cannot integrate and reuse computation from previous time-steps if the
problem is dynamic, uncertain or partially observable, or be applied where the
correct action is undefined, characteristics of many real-world problems.
  This paper presents HRM-Agent, a variant of HRM trained using only
reinforcement learning. We show that HRM can learn to navigate to goals in
dynamic and uncertain maze environments. Recent work suggests that HRM's
reasoning abilities stem from its recurrent inference process. We explore the
dynamics of the recurrent inference process and find evidence that it is
successfully reusing computation from earlier environment time-steps.

</details>


### [402] [Toward Agents That Reason About Their Computation](https://arxiv.org/abs/2510.22833)
*Adrian Orenstein,Jessica Chen,Gwyneth Anne Delos Santos,Bayley Sapara,Michael Bowling*

Main category: cs.AI

TL;DR: 在相同的训练计算预算下，能够进行计算推理的强化学习智能体比不能进行计算推理的智能体在75%的游戏中表现更好，并且平均计算量减少了3倍。


<details>
  <summary>Details</summary>
Motivation: 如果智能体能够在学习过程中推理其计算量，它们能否同样地减少计算量？如果可以，我们能否拥有更节能的智能体或为规划等其他过程释放计算周期？

Method: 在 the Arcade Learning Environment 中进行实验，向智能体展示其计算成本并赋予它们控制计算使用的能力。

Result: 在相同的训练计算预算下，能够进行计算推理的智能体在75%的游戏中表现更好，并且平均计算量减少了3倍。在个别游戏中分析了智能体获得这些效率的来源。

Conclusion: 强化学习智能体通过推理其计算量，可以比不能进行计算推理的智能体在75%的游戏中表现更好，并且平均计算量减少了3倍。

Abstract: While reinforcement learning agents can achieve superhuman performance in
many complex tasks, they typically do not become more computationally efficient
as they improve. In contrast, humans gradually require less cognitive effort as
they become more proficient at a task. If agents could reason about their
compute as they learn, could they similarly reduce their computation footprint?
If they could, we could have more energy efficient agents or free up compute
cycles for other processes like planning. In this paper, we experiment with
showing agents the cost of their computation and giving them the ability to
control when they use compute. We conduct our experiments on the Arcade
Learning Environment, and our results demonstrate that with the same training
compute budget, agents that reason about their compute perform better on 75% of
games. Furthermore, these agents use three times less compute on average. We
analyze individual games and show where agents gain these efficiencies.

</details>


### [403] [Rethinking the Text-Vision Reasoning Imbalance in MLLMs through the Lens of Training Recipes](https://arxiv.org/abs/2510.22836)
*Guanyu Yao,Qiucheng Wu,Yang Zhang,Zhaowen Wang,Handong Zhao,Shiyu Chang*

Main category: cs.AI

TL;DR: MLLMs在视觉-语言任务中表现出色，但存在“模态鸿沟”——即对文本线索过度依赖，对视觉内容关注不足。本文通过分析训练策略来探究该鸿沟，并提出数据和损失函数设计的策略来弥合它，以促进更均衡的多模态推理。


<details>
  <summary>Details</summary>
Motivation: 当前的多模态大语言模型（MLLMs）在处理视觉-语言任务时，存在对文本线索过度依赖、对视觉内容关注不足的问题，即“模态鸿沟”，这导致了在需要真实视觉推理的任务上表现不佳。

Method: 通过分析训练策略（training recipes），探究“模态鸿沟”的成因，并从数据和损失函数设计两个方面系统地探索弥合该鸿沟的策略。

Result: 现有的训练策略往往会加剧“模态鸿沟”。

Conclusion: 通过数据和损失函数的设计可以有效弥合“模态鸿沟”，促进更均衡的多模态推理。

Abstract: Multimodal large language models (MLLMs) have demonstrated strong
capabilities on vision-and-language tasks. However, recent findings reveal an
imbalance in their reasoning capabilities across visual and textual modalities.
Specifically, current MLLMs often over-rely on textual cues while
under-attending to visual content, resulting in suboptimal performance on tasks
that require genuine visual reasoning. We refer to this phenomenon as the
\textit{modality gap}, defined as the performance disparity between
text-centric and vision-centric inputs. In this paper, we analyze the modality
gap through the lens of training recipes. We first show that existing training
recipes tend to amplify this gap. Then, we systematically explore strategies to
bridge it from two complementary perspectives: data and loss design. Our
findings provide insights into developing training recipes that mitigate the
modality gap and promote more balanced multimodal reasoning. Our code is
publicly available at https://github.com/UCSB-NLP-Chang/Bridging-Modality-Gap.

</details>


### [404] [Lyapunov Function-guided Reinforcement Learning for Flight Control](https://arxiv.org/abs/2510.22840)
*Yifei Li,Erik-Jan van Kampen*

Main category: cs.AI

TL;DR: 该研究提出了一个级联在线学习飞行控制系统，并通过Lyapunov函数分析了其收敛性能，考虑了离散化和状态预测误差。


<details>
  <summary>Details</summary>
Motivation: 研究级联在线学习飞行控制系统的收敛性能，并考虑了模型带来的误差。

Method: 通过Lyapunov函数分析收敛性能，并考虑离散化误差和状态预测误差。

Result: 通过飞行控制仿真进行了对比结果的展示。

Conclusion: 该研究对所提出的控制系统进行了收敛性分析，并考虑了相关误差。

Abstract: A cascaded online learning flight control system has been developed and
enhanced with respect to action smoothness. In this paper, we investigate the
convergence performance of the control system, characterized by the increment
of a Lyapunov function candidate. The derivation of this metric accounts for
discretization errors and state prediction errors introduced by the incremental
model. Comparative results are presented through flight control simulations.

</details>


### [405] [Exploring Structures of Inferential Mechanisms through Simplistic Digital Circuits](https://arxiv.org/abs/2510.22883)
*Giovanni Sileno,Jean-Louis Dessalles*

Main category: cs.AI

TL;DR: 本文提出了一个统一的框架来连接认知科学和人工智能中的推理机制，通过将逻辑门电路类比为符号化的人工智能模型。


<details>
  <summary>Details</summary>
Motivation: 尽管认知科学和人工智能在推理机制（如分类、归纳、演绎、因果推理等）方面有不同的模型，但两者都缺乏一个统一的框架。本文旨在填补这一空白。

Method: 本文首先从电子电路和逻辑门的角度审视了符号化的人工智能模型，并观察到这种视角与标准逻辑在处理蕴含和否定时存在差异。然后，通过组合探索，识别出四种主要的依赖关系。接着，结合逻辑程序的上下文，将这些依赖关系映射到八种常见的推理模式，从而在一个统一的框架下整合了传统上不同的推理机制。最后，从概率的角度对逻辑程序进行解释，揭示了内在的功能依赖性。

Result: 识别出四种主要的依赖关系和八种常见的推理模式，将不同的推理机制统一在一个框架下，并揭示了内在的功能依赖性。

Conclusion: 本文的论证主要基于符号方法和数字系统，但其观察结果可能指向更普遍适用的结构，为理解更广泛的推理过程提供了线索。

Abstract: Cognitive studies and artificial intelligence have developed distinct models
for various inferential mechanisms (categorization, induction, abduction,
causal inference, contrast, merge, ...). Yet, both natural and artificial views
on cognition lack apparently a unifying framework. This paper formulates a
speculative answer attempting to respond to this gap. To postulate on
higher-level activation processes from a material perspective, we consider
inferential mechanisms informed by symbolic AI modelling techniques, through
the simplistic lenses of electronic circuits based on logic gates. We observe
that a logic gate view entails a different treatment of implication and
negation compared to standard logic and logic programming. Then, by
combinatorial exploration, we identify four main forms of dependencies that can
be realized by these inferential circuits. Looking at how these forms are
generally used in the context of logic programs, we identify eight common
inferential patterns, exposing traditionally distinct inferential mechanisms in
an unifying framework. Finally, following a probabilistic interpretation of
logic programs, we unveil inner functional dependencies. The paper concludes
elaborating in what sense, even if our arguments are mostly informed by
symbolic means and digital systems infrastructures, our observations may
pinpoint to more generally applicable structures.

</details>


### [406] [On Generalization in Agentic Tool Calling: CoreThink Agentic Reasoner and MAVEN Dataset](https://arxiv.org/abs/2510.22898)
*Vishvesh Bhat,Omkar Ghugarkar,Julian McAuley*

Main category: cs.AI

TL;DR: LLMs在跨工具调用环境中的泛化能力不足，提出MAVEN基准测试和CoreThink框架来解决此问题。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在孤立的基准测试中表现良好，但其跨不同域推理和协调工具的能力有待提高，泛化能力不足是关键挑战。

Method: 在一系列工具调用基准测试（包括BFCL v3, TauBench, Tau2Bench, AceBench）上进行了大规模LLM评估，并引入了MAVEN基准测试来专门测试多步推理和鲁棒性。提出了CoreThink框架，通过增加一个轻量级的符号推理层来增强LLM的结构化分解和自适应工具协调能力。

Result: 现有LLM在MAVEN基准测试上的准确率普遍低于50%，表明在工具使用方面存在显著的泛化差距。CoreThink框架在无需额外训练的情况下，在所有基准测试上均表现出良好的泛化能力，并在计算成本大幅降低的情况下，取得了比现有方法高出530%的性能提升。

Conclusion: CoreThink框架通过结合LLM和符号推理，有效解决了LLM在跨领域工具调用中的泛化能力问题，并在效率和性能上均超越了现有方法。

Abstract: Generalization across Agentic tool-calling environments remains a key
unsolved challenge in developing reliable agentic reasoning systems. While
large language models (LLMs) demonstrate strong performance on isolated
benchmarks, their ability to transfer reasoning strategies and co-ordinate
tools across diverse domains is poorly understood. In this work, we conduct a
large-scale evaluation of state-of-the-art LLMs on multiple tool-calling
benchmarksBFCL v3, TauBench, Tau2Bench, and AceBenchand introduce MAVEN (Math &
Physics Adversarial Verification & Evaluation Network), a new out of
distribution (OOD) benchmark designed to stress-test multi-step reasoning
through explicit verification and adversarial task composition. Our results
show that most current models achieve below 50% accuracy on MAVEN, revealing a
significant generalization gap across tool-use settings.
  To address this, we present the CoreThink Agentic Reasoner, a framework that
augments LLMs with a lightweight symbolic reasoning layer for structured
decomposition and adaptive tool orchestration. Without additional training, it
generalizes across all benchmarks, achieving state-of-the-art performance with
530% improvements over existing baselines at roughly one-tenth the
computational cost.

</details>


### [407] [GTR-Mamba: Geometry-to-Tangent Routing for Hyperbolic POI Recommendation](https://arxiv.org/abs/2510.22942)
*Zhuoxuan Li,Jieyuan Pei,Tangwei Ye,Zhongyuan Lai,Zihan Liu,Fengyuan Xu,Qi Zhang,Liang Hu*

Main category: cs.AI

TL;DR: GTR-Mamba是一个新的下一兴趣点（POI）推荐框架，通过结合双曲几何中的分层偏好和欧几里得切空间中的动态序列更新，解决了现有模型无法同时捕捉空间层次结构和用户特定时间上下文动态性的问题，并在真实数据集上取得了优于最先进模型的效果。


<details>
  <summary>Details</summary>
Motivation: 现有POI推荐模型（主要基于图神经网络和序列模型）在同时捕捉空间选择的固有分层结构和用户特定时间上下文的动态性及不规则变化方面存在局限性。

Method: 提出GTR-Mamba框架，利用不同数学空间的优势：在双曲几何中建模静态的、类似树状的偏好层次结构，并将动态序列更新路由到计算稳定且高效的欧几里得切空间中的新型Mamba层。通过跨流形通道融合时空信息，以明确引导状态空间模型（SSM），实现对上下文变化的灵活适应。

Result: 在三个真实世界数据集上的大量实验表明，GTR-Mamba在下一POI推荐方面持续优于最先进的基线模型。

Conclusion: GTR-Mamba通过创新的跨流形条件和路由机制，有效解决了现有POI推荐模型的局限性，并在准确性和适应性方面取得了显著提升。

Abstract: Next Point-of-Interest (POI) recommendation is a critical task in modern
Location-Based Social Networks (LBSNs), aiming to model the complex
decision-making process of human mobility to provide personalized
recommendations for a user's next check-in location. Existing POI
recommendation models, predominantly based on Graph Neural Networks and
sequential models, have been extensively studied. However, these models face a
fundamental limitation: they struggle to simultaneously capture the inherent
hierarchical structure of spatial choices and the dynamics and irregular shifts
of user-specific temporal contexts. To overcome this limitation, we propose
GTR-Mamba, a novel framework for cross-manifold conditioning and routing.
GTR-Mamba leverages the distinct advantages of different mathematical spaces
for different tasks: it models the static, tree-like preference hierarchies in
hyperbolic geometry, while routing the dynamic sequence updates to a novel
Mamba layer in the computationally stable and efficient Euclidean tangent
space. This process is coordinated by a cross-manifold channel that fuses
spatio-temporal information to explicitly steer the State Space Model (SSM),
enabling flexible adaptation to contextual changes. Extensive experiments on
three real-world datasets demonstrate that GTR-Mamba consistently outperforms
state-of-the-art baseline models in next POI recommendation.

</details>


### [408] [Exploring Semantic-constrained Adversarial Example with Instruction Uncertainty Reduction](https://arxiv.org/abs/2510.22981)
*Jin Hu,Jiakai Wang,Linna Jing,Haolin Li,Haodong Liu,Haotong Qin,Aishan Liu,Ke Xu,Xianglong Liu*

Main category: cs.AI

TL;DR: 本文提出了一种名为InSUR的多维度指令不确定性规约框架，旨在生成更具可迁移性、适应性和有效性的语义约束对抗性样本（SemanticAE）。


<details>
  <summary>Details</summary>
Motivation: 现有生成SemanticAE的方法未能充分解决人类指令中存在的语义不确定性因素（如指代多样性、描述不完整、边界模糊），导致其攻击能力不足。

Method: InSUR框架在三个维度上进行优化：1. 采样方法：提出残差驱动的攻击方向稳定（ResAdv-DDIM采样器），以缓解因语言指代多样性导致的不稳定优化问题。2. 任务建模：提出上下文编码的攻击场景约束，通过引导掩码和渲染器集成来弥补指令中缺失的知识，并规范2D/3D SemanticAE的约束。3. 生成器评估：提出语义抽象的攻击评估增强方法，以明确评估边界。

Result: 实验证明InSUR在迁移攻击性能方面表现优越，并首次实现了无参照的语义约束3D对抗性样本生成。

Conclusion: InSUR框架通过多维度优化，有效解决了现有SemanticAE生成方法在指令不确定性处理上的不足，显著提升了生成样本的攻击能力和应用范围。

Abstract: Recently, semantically constrained adversarial examples (SemanticAE), which
are directly generated from natural language instructions, have become a
promising avenue for future research due to their flexible attacking forms. To
generate SemanticAEs, current methods fall short of satisfactory attacking
ability as the key underlying factors of semantic uncertainty in human
instructions, such as referring diversity, descriptive incompleteness, and
boundary ambiguity, have not been fully investigated. To tackle the issues,
this paper develops a multi-dimensional instruction uncertainty reduction
(InSUR) framework to generate more satisfactory SemanticAE, i.e., transferable,
adaptive, and effective. Specifically, in the dimension of the sampling method,
we propose the residual-driven attacking direction stabilization to alleviate
the unstable adversarial optimization caused by the diversity of language
references. By coarsely predicting the language-guided sampling process, the
optimization process will be stabilized by the designed ResAdv-DDIM sampler,
therefore releasing the transferable and robust adversarial capability of
multi-step diffusion models. In task modeling, we propose the context-encoded
attacking scenario constraint to supplement the missing knowledge from
incomplete human instructions. Guidance masking and renderer integration are
proposed to regulate the constraints of 2D/3D SemanticAE, activating stronger
scenario-adapted attacks. Moreover, in the dimension of generator evaluation,
we propose the semantic-abstracted attacking evaluation enhancement by
clarifying the evaluation boundary, facilitating the development of more
effective SemanticAE generators. Extensive experiments demonstrate the
superiority of the transfer attack performance of InSUR. Moreover, we realize
the reference-free generation of semantically constrained 3D adversarial
examples for the first time.

</details>


### [409] [ProfileXAI: User-Adaptive Explainable AI](https://arxiv.org/abs/2510.22998)
*Gilber A. Corrales,Carlos Andrés Ferro Sánchez,Reinel Tabares-Soto,Jesús Alfonso López Sotelo,Gonzalo A. Ruz,Johan Sebastian Piña Durán*

Main category: cs.AI

TL;DR: ProfileXAI是一个模型和领域无关的框架，结合了事后解释器（SHAP、LIME、Anchor）和检索增强LLM，为不同类型的用户生成解释。该系统索引多模态知识库，通过量化标准为每个实例选择解释器，并生成带有聊天式提示的基于事实的叙述。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有解释器在解释模型和领域方面存在局限性，并且不能满足不同用户群体的需求的问题，提出了ProfileXAI框架。

Method: ProfileXAI框架首先索引多模态知识库，然后根据量化标准为每个实例选择合适的事后解释器（SHAP、LIME、Anchor），并结合检索增强LLM，通过聊天式提示生成基于事实的、可信的解释性叙述。

Result: 在心脏病和甲状腺癌数据集上的评估表明，没有一个解释器在所有方面都占优。LIME在保真度和鲁棒性之间取得了最佳平衡；Anchor生成最稀疏、令牌使用量最少的规则；SHAP获得了最高的满意度。ProfileXAI能够稳定令牌使用量并保持跨用户群体的积极评价。

Conclusion: ProfileXAI框架能够为不同用户群体提供高效且可信的解释，通过结合多种解释器和检索增强LLM，并在模型和领域无关的前提下，有效解决了现有解释方法的局限性。

Abstract: ProfileXAI is a model- and domain-agnostic framework that couples post-hoc
explainers (SHAP, LIME, Anchor) with retrieval - augmented LLMs to produce
explanations for different types of users. The system indexes a multimodal
knowledge base, selects an explainer per instance via quantitative criteria,
and generates grounded narratives with chat-enabled prompting. On Heart Disease
and Thyroid Cancer datasets, we evaluate fidelity, robustness, parsimony, token
use, and perceived quality. No explainer dominates: LIME achieves the best
fidelity--robustness trade-off (Infidelity $\le 0.30$, $L<0.7$ on Heart
Disease); Anchor yields the sparsest, low-token rules; SHAP attains the highest
satisfaction ($\bar{x}=4.1$). Profile conditioning stabilizes tokens ($\sigma
\le 13\%$) and maintains positive ratings across profiles ($\bar{x}\ge 3.7$,
with domain experts at $3.77$), enabling efficient and trustworthy
explanations.

</details>


### [410] [From Prompt Optimization to Multi-Dimensional Credibility Evaluation: Enhancing Trustworthiness of Chinese LLM-Generated Liver MRI Reports](https://arxiv.org/abs/2510.23008)
*Qiuli Wang,Xiaoming Li,Jie Chen,Yongxu Liu,Xingpeng Zhang,Chen Liu,Wei Chen*

Main category: cs.AI

TL;DR: LLM在生成影像诊断报告方面表现出色，但缺乏优化提示和评估可信度的标准化框架。本研究提出多维度可信度评估（MDCA）框架，并提供机构特定提示优化指南，以提升LLM生成的肝脏MRI报告的可信度。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在生成影像诊断报告方面有潜力，但缺乏统一的提示优化指南和可信度评估框架。本研究旨在解决这一问题，提升LLM生成肝脏MRI报告的可信度。

Method: 提出多维度可信度评估（MDCA）框架，并为机构特定的提示优化提供指导。使用SiliconFlow平台，对Kimi-K2-Instruct-0905、Qwen3-235B-A22B-Instruct-2507、DeepSeek-V3和ByteDance-Seed-OSS-36B-Instruct等LLM在肝脏MRI报告生成方面的表现进行评估和比较。

Result: 通过MDCA框架和提示优化，有望提高LLM生成的肝脏MRI报告的准确性和可靠性，并为评估和选择合适的LLM提供标准。

Conclusion: 本研究提出的MDCA框架和提示优化方法，能够有效提升LLM在放射学报告中的可信度，为LLM在医学影像领域的应用提供了重要的实践指导。

Abstract: Large language models (LLMs) have demonstrated promising performance in
generating diagnostic conclusions from imaging findings, thereby supporting
radiology reporting, trainee education, and quality control. However,
systematic guidance on how to optimize prompt design across different clinical
contexts remains underexplored. Moreover, a comprehensive and standardized
framework for assessing the trustworthiness of LLM-generated radiology reports
is yet to be established. This study aims to enhance the trustworthiness of
LLM-generated liver MRI reports by introducing a Multi-Dimensional Credibility
Assessment (MDCA) framework and providing guidance on institution-specific
prompt optimization. The proposed framework is applied to evaluate and compare
the performance of several advanced LLMs, including Kimi-K2-Instruct-0905,
Qwen3-235B-A22B-Instruct-2507, DeepSeek-V3, and
ByteDance-Seed-OSS-36B-Instruct, using the SiliconFlow platform.

</details>


### [411] [Mixed Density Diffuser: Efficient Planning with Non-uniform Temporal Resolution](https://arxiv.org/abs/2510.23026)
*Crimson Stambaugh,Rajesh P. N. Rao*

Main category: cs.AI

TL;DR: MDD通过调整时间密度超参数，在Maze2D、Franka Kitchen和Antmaze D4RL等领域实现了新的SOTA。


<details>
  <summary>Details</summary>
Motivation: 稀疏规划比单步规划更能使扩散规划器受益，但过稀的预测会降低性能。该研究假设时间密度阈值在时间跨度上不是均匀的，并且轨迹的某些部分应该被更密集地规划。

Method: 提出了一种名为混合密度扩散器（MDD）的扩散规划器，其中整个时间跨度内的密度是可调的超参数。

Result: MDD在Maze2D、Franka Kitchen和Antmaze D4RL等任务领域实现了新的SOTA。

Conclusion: MDD通过调整时间密度超参数，在Maze2D、Franka Kitchen和Antmaze D4RL等领域实现了新的SOTA。

Abstract: Recent studies demonstrate that diffusion planners benefit from sparse-step
planning over single-step planning. Training models to skip steps in their
trajectories helps capture long-term dependencies without additional or memory
computational cost. However, predicting excessively sparse plans degrades
performance. We hypothesize this temporal density threshold is non-uniform
across a temporal horizon and that certain parts of a planned trajectory should
be more densely planned. We propose Mixed Density Diffuser (MDD), a diffusion
planner where the densities throughout the horizon are tunable hyperparameters.
MDD achieves a new SOTA across the Maze2D, Franka Kitchen, and Antmaze D4RL
task domains.

</details>


### [412] [A Survey of AI Scientists: Surveying the automatic Scientists and Research](https://arxiv.org/abs/2510.23045)
*Guiyao Tie,Pan Zhou,Lichao Sun*

Main category: cs.AI

TL;DR: 人工智能正从计算工具转变为科学知识的自主生成者，即“人工智能科学家”。


<details>
  <summary>Details</summary>
Motivation: 人工智能科学家能够模仿完整的科学工作流程，有望从根本上改变科学发现的节奏和规模。然而，这些系统快速无序的发展造成了研究碎片化，阻碍了对总体方法论原则和发展趋势的理解。

Method: 提出一个统一的六阶段方法论框架，将端到端的科学过程分解为：文献综述、想法生成、实验准备、实验执行、科学写作和论文生成。通过该框架，梳理了该领域从早期的基础模块（2022-2023）到集成闭环系统（2024），再到可扩展性、影响力和人机协作（2025-至今）的前沿发展。

Result: 分析了人工智能科学家领域的发展历程，从基础模块到闭环系统，再到当前的可扩展性、影响力和人机协作前沿。

Conclusion: 该调查系统地阐述了人工智能科学的现状，并为克服现有鲁棒性和治理方面的挑战提供了关键路线图，旨在引导下一代系统成为人类科学探索中值得信赖且不可或缺的合作伙伴。

Abstract: Artificial intelligence is undergoing a profound transition from a
computational instrument to an autonomous originator of scientific knowledge.
This emerging paradigm, the AI scientist, is architected to emulate the
complete scientific workflow-from initial hypothesis generation to the final
synthesis of publishable findings-thereby promising to fundamentally reshape
the pace and scale of discovery. However, the rapid and unstructured
proliferation of these systems has created a fragmented research landscape,
obscuring overarching methodological principles and developmental trends. This
survey provides a systematic and comprehensive synthesis of this domain by
introducing a unified, six-stage methodological framework that deconstructs the
end-to-end scientific process into: Literature Review, Idea Generation,
Experimental Preparation, Experimental Execution, Scientific Writing, and Paper
Generation. Through this analytical lens, we chart the field's evolution from
early Foundational Modules (2022-2023) to integrated Closed-Loop Systems
(2024), and finally to the current frontier of Scalability, Impact, and
Human-AI Collaboration (2025-present). By rigorously synthesizing these
developments, this survey not only clarifies the current state of autonomous
science but also provides a critical roadmap for overcoming remaining
challenges in robustness and governance, ultimately guiding the next generation
of systems toward becoming trustworthy and indispensable partners in human
scientific inquiry.

</details>


### [413] [TLCD: A Deep Transfer Learning Framework for Cross-Disciplinary Cognitive Diagnosis](https://arxiv.org/abs/2510.23062)
*Zhifeng Wang,Meixin Su,Yang Yang,Chunyan Zeng,Lizhi Ye*

Main category: cs.AI

TL;DR: 本文提出了一种基于深度学习和迁移学习的跨学科认知诊断方法（TLCD），以解决传统方法在处理跨学科数据时的挑战。


<details>
  <summary>Details</summary>
Motivation: 在线教育模式的兴起和认知诊断技术在教育评估中的重要性，以及传统方法在跨学科数据处理中面临的特征提取复杂性和学科数据稀疏性等挑战。

Method: 研究神经网络认知诊断和知识关联神经网络认知诊断，并提出TLCD方法，结合深度学习和迁移学习策略，利用主学科的共同特征来提升目标学科模型的性能。

Result: 实验结果表明，基于深度学习的跨学科认知诊断模型在跨学科认知诊断任务上优于基线模型，能更准确地评估学生的学习状况。

Conclusion: 所提出的TLCD方法能够有效地进行跨学科认知诊断，提高模型在目标学科上的表现。

Abstract: Driven by the dual principles of smart education and artificial intelligence
technology, the online education model has rapidly emerged as an important
component of the education industry. Cognitive diagnostic technology can
utilize students' learning data and feedback information in educational
evaluation to accurately assess their ability level at the knowledge level.
However, while massive amounts of information provide abundant data resources,
they also bring about complexity in feature extraction and scarcity of
disciplinary data. In cross-disciplinary fields, traditional cognitive
diagnostic methods still face many challenges. Given the differences in
knowledge systems, cognitive structures, and data characteristics between
different disciplines, this paper conducts in-depth research on neural network
cognitive diagnosis and knowledge association neural network cognitive
diagnosis, and proposes an innovative cross-disciplinary cognitive diagnosis
method (TLCD). This method combines deep learning techniques and transfer
learning strategies to enhance the performance of the model in the target
discipline by utilizing the common features of the main discipline. The
experimental results show that the cross-disciplinary cognitive diagnosis model
based on deep learning performs better than the basic model in
cross-disciplinary cognitive diagnosis tasks, and can more accurately evaluate
students' learning situation.

</details>


### [414] [Smaller Models, Smarter Rewards: A Two-Sided Approach to Process and Outcome Rewards](https://arxiv.org/abs/2510.23083)
*Jan Niklas Groeneveld,Xi Qin,Alexander Schaefer,Yaad Oren*

Main category: cs.AI

TL;DR: 小型语言模型（如 Phi-4）经过微调后可以作为有效的代码奖励模型，通过结合过程和结果奖励，并能显著提升代码生成搜索能力。


<details>
  <summary>Details</summary>
Motivation: 探索小型语言模型（如 Phi-4 系列）是否能够通过融合过程奖励和结果奖励，转变为可用的奖励模型，以用于代码生成任务，并研究其推理能力。

Method: 使用 APPS 编码挑战基准构建了一个包含正确性标签的代码样本数据集，然后训练了一个值头模型来估计中间输出的成功概率。

Result: 评估结果表明，小型语言模型能够作为有效的奖励模型或代码评估批评者，成功地从多个候选代码中识别出正确的解决方案，并使我们最准确代码的搜索能力提高了 20% 以上。

Conclusion: 小型语言模型经过微调后，可以成为有效的代码评估工具，在代码生成和评估方面展现出优于先前方法的性能。

Abstract: Generating high-quality code remains a challenge for Large Language Models
(LLMs). For the evolution of reasoning models on this task, reward models are a
necessary intermediate step. These models judge outcomes or intermediate steps.
Decoder-only transformer models can be turned into reward models by introducing
a regression layer and supervised fine-tuning. While it is known that
reflection capabilities generally increase with the size of a model, we want to
investigate whether state-of-the-art small language models like the Phi-4
family can be turned into usable reward models blending the consideration of
process rewards and outcome rewards.
  Targeting this goal, we construct a dataset of code samples with correctness
labels derived from the APPS coding challenge benchmark. We then train a
value-head model to estimate the success probability of intermediate outputs.
Our evaluation shows that small LLMs are capable of serving as effective reward
models or code evaluation critics, successfully identifying correct solutions
among multiple candidates. Using this critic, we achieve over a 20% improvement
in the search capability of the most accurate code out of multiple generations.

</details>


### [415] [Lost in Tokenization: Context as the Key to Unlocking Biomolecular Understanding in Scientific LLMs](https://arxiv.org/abs/2510.23127)
*Kai Zhuang,Jiawei Zhang,Yumou Liu,Hanqun Cao,Chunbin Gu,Mengdi Liu,Zhangyang Gao,Zitong Jerry Wang,Xuanhe Zhou,Pheng-Ann Heng,Lijun Wu,Conghui He,Cheng Tan*

Main category: cs.AI

TL;DR: Sci-LLMs在处理生物序列时面临“分词困境”，现有方法限制了其推理能力。本文提出，提供结构化上下文信息而非直接处理序列，能显著提升Sci-LLMs的生物推理能力，甚至原始序列会干扰模型表现。结论是Sci-LLMs应被视为知识推理引擎，而非序列解码器，推动混合式AI代理的发展。


<details>
  <summary>Details</summary>
Motivation: 现有Sci-LLMs在处理生物序列时存在分词困境，限制了其推理能力，需要新的方法来提升其在生物发现中的作用。

Method: 通过对比三种输入模式（仅序列、仅上下文、序列+上下文），系统性地测试了领先的Sci-LLMs在生物推理任务上的表现，以评估不同输入方式对模型性能的影响。

Result: 仅使用上下文信息（来自生物信息学工具的结构化信息）的模式，在所有测试的Sci-LLMs和生物推理任务上，都持续且显著地优于仅使用序列或序列+上下文的模式。原始序列的加入甚至会降低模型性能。

Conclusion: Sci-LLMs的主要优势在于推理结构化知识，而非直接解释低级序列数据。应将Sci-LLMs重新定位为基于专家知识的推理引擎，而非序列解码器，并开发混合式AI代理，侧重于高层知识综合。

Abstract: Scientific Large Language Models (Sci-LLMs) have emerged as a promising
frontier for accelerating biological discovery. However, these models face a
fundamental challenge when processing raw biomolecular sequences: the
tokenization dilemma. Whether treating sequences as a specialized language,
risking the loss of functional motif information, or as a separate modality,
introducing formidable alignment challenges, current strategies fundamentally
limit their reasoning capacity. We challenge this sequence-centric paradigm by
positing that a more effective strategy is to provide Sci-LLMs with high-level
structured context derived from established bioinformatics tools, thereby
bypassing the need to interpret low-level noisy sequence data directly. Through
a systematic comparison of leading Sci-LLMs on biological reasoning tasks, we
tested three input modes: sequence-only, context-only, and a combination of
both. Our findings are striking: the context-only approach consistently and
substantially outperforms all other modes. Even more revealing, the inclusion
of the raw sequence alongside its high-level context consistently degrades
performance, indicating that raw sequences act as informational noise, even for
models with specialized tokenization schemes. These results suggest that the
primary strength of existing Sci-LLMs lies not in their nascent ability to
interpret biomolecular syntax from scratch, but in their profound capacity for
reasoning over structured, human-readable knowledge. Therefore, we argue for
reframing Sci-LLMs not as sequence decoders, but as powerful reasoning engines
over expert knowledge. This work lays the foundation for a new class of hybrid
scientific AI agents, repositioning the developmental focus from direct
sequence interpretation towards high-level knowledge synthesis. The code is
available at github.com/opendatalab-raise-dev/CoKE.

</details>


### [416] [Guiding Skill Discovery with Foundation Models](https://arxiv.org/abs/2510.23167)
*Zhao Yang,Thomas M. Moerland,Mike Preuss,Aske Plaat,Vincent François-Lavet,Edward S. Hu*

Main category: cs.AI

TL;DR: 该研究提出了一种名为FoG（Foundation model Guided）的技能发现方法，通过结合基础模型来学习人类偏好的技能，解决了现有方法只关注技能多样性而忽视人类意图的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的技能发现方法只关注最大化技能多样性，忽略了人类偏好，可能导致不期望甚至危险的行为（如机器人翻滚）。

Method: FoG利用基础模型提取一个评估状态是否符合人类意图的评分函数，然后用该评分函数重新加权技能发现算法的奖励，从而优化学习过程。

Result: FoG成功消除了不期望的行为（如翻滚）并避开了危险区域，同时也能发现难以明确定义的技能。实验在状态和像素级别任务上都取得了成功。

Conclusion: FoG能够有效地将人类意图融入技能发现过程，生成更符合人类期望的技能。

Abstract: Learning diverse skills without hand-crafted reward functions could
accelerate reinforcement learning in downstream tasks. However, existing skill
discovery methods focus solely on maximizing the diversity of skills without
considering human preferences, which leads to undesirable behaviors and
possibly dangerous skills. For instance, a cheetah robot trained using previous
methods learns to roll in all directions to maximize skill diversity, whereas
we would prefer it to run without flipping or entering hazardous areas. In this
work, we propose a Foundation model Guided (FoG) skill discovery method, which
incorporates human intentions into skill discovery through foundation models.
Specifically, FoG extracts a score function from foundation models to evaluate
states based on human intentions, assigning higher values to desirable states
and lower to undesirable ones. These scores are then used to re-weight the
rewards of skill discovery algorithms. By optimizing the re-weighted skill
discovery rewards, FoG successfully learns to eliminate undesirable behaviors,
such as flipping or rolling, and to avoid hazardous areas in both state-based
and pixel-based tasks. Interestingly, we show that FoG can discover skills
involving behaviors that are difficult to define. Interactive visualisations
are available from https://sites.google.com/view/submission-fog.

</details>


### [417] [AUPO -- Abstracted Until Proven Otherwise: A Reward Distribution Based Abstraction Algorithm](https://arxiv.org/abs/2510.23214)
*Robin Schmöcker,Alexander Dockhorn,Bodo Rosenhahn*

Main category: cs.AI

TL;DR: AUPO是一种新的蒙特卡洛树搜索（MCTS）的改进方法，通过利用奖励分布统计信息进行动作抽象，优于现有的MCTS方法。


<details>
  <summary>Details</summary>
Motivation: 为了改进MCTS的决策策略，使其能够处理更复杂的问题，并克服现有抽象算法的局限性。

Method: 提出了一种名为AUPO的自动动作抽象算法，该算法仅依赖于MCTS过程中获得的奖励分布统计数据，不需要转移概率或有向无环搜索图。

Result: AUPO在多种IPPC基准问题上进行了测试，结果表明AUPO明显优于MCTS，并且能够检测到现有框架（如ASAP）难以处理的对称动作。

Conclusion: AUPO是一种有效的MCTS改进方法，它通过新颖的动作抽象机制，提高了搜索效率和性能，并且不与其他抽象技术冲突。

Abstract: We introduce a novel, drop-in modification to Monte Carlo Tree Search's
(MCTS) decision policy that we call AUPO. Comparisons based on a range of IPPC
benchmark problems show that AUPO clearly outperforms MCTS. AUPO is an
automatic action abstraction algorithm that solely relies on reward
distribution statistics acquired during the MCTS. Thus, unlike other automatic
abstraction algorithms, AUPO requires neither access to transition
probabilities nor does AUPO require a directed acyclic search graph to build
its abstraction, allowing AUPO to detect symmetric actions that
state-of-the-art frameworks like ASAP struggle with when the resulting
symmetric states are far apart in state space. Furthermore, as AUPO only
affects the decision policy, it is not mutually exclusive with other
abstraction techniques that only affect the tree search.

</details>


### [418] [Human-Like Goalkeeping in a Realistic Football Simulation: a Sample-Efficient Reinforcement Learning Approach](https://arxiv.org/abs/2510.23216)
*Alessandro Sestini,Joakim Bergdahl,Jean-Philippe Barrette-LaPierre,Florian Fuchs,Brady Chen,Micheal Jones,Linus Gisslén*

Main category: cs.AI

TL;DR: 提出了一种用于游戏行业的样本高效深度强化学习方法，该方法通过利用预收集数据和增加网络可塑性来提高样本效率，并在EA SPORTS FC 25中训练的守门员代理上取得了优于内置AI的性能。


<details>
  <summary>Details</summary>
Motivation: 之前的深度强化学习（DRL）研究主要集中在训练超人类智能体，这对于资源有限但旨在创造类似人类智能体的游戏工作室来说是不切实际的。因此，需要一种适合游戏行业工业环境的样本高效DRL方法。

Method: 提出了一种样本高效的DRL方法，该方法通过利用预收集数据和增加网络可塑性来提高基于价值的DRL的样本效率，以适应游戏行业的工业设置。

Result: 在EA SPORTS FC 25中训练的守门员代理比内置AI的球率高出10%。消融研究表明，与标准的DRL方法相比，该方法可将训练速度提高50%。领域专家的定性评估表明，该方法比手工制作的代理更能创造类似人类的游戏玩法。

Conclusion: 所提出的方法在EA SPORTS FC 25中得到了验证，其性能优于内置AI，并且训练效率更高。该方法有望取代该系列下一代产品中的手工制作的AI，证明了其在游戏行业中的实际影响和应用潜力。

Abstract: While several high profile video games have served as testbeds for Deep
Reinforcement Learning (DRL), this technique has rarely been employed by the
game industry for crafting authentic AI behaviors. Previous research focuses on
training super-human agents with large models, which is impractical for game
studios with limited resources aiming for human-like agents. This paper
proposes a sample-efficient DRL method tailored for training and fine-tuning
agents in industrial settings such as the video game industry. Our method
improves sample efficiency of value-based DRL by leveraging pre-collected data
and increasing network plasticity. We evaluate our method training a goalkeeper
agent in EA SPORTS FC 25, one of the best-selling football simulations today.
Our agent outperforms the game's built-in AI by 10% in ball saving rate.
Ablation studies show that our method trains agents 50% faster compared to
standard DRL methods. Finally, qualitative evaluation from domain experts
indicates that our approach creates more human-like gameplay compared to
hand-crafted agents. As a testimony of the impact of the approach, the method
is intended to replace the hand-crafted counterpart in next iterations of the
series.

</details>


### [419] [Accelerating IC Thermal Simulation Data Generation via Block Krylov and Operator Action](https://arxiv.org/abs/2510.23221)
*Hong Wang,Wenkai Yang,Jie Wang,Huanshuo Dong,Zijie Geng,Zhen Huang,Depeng Xie,Zhezheng Hao,Hande Dong*

Main category: cs.AI

TL;DR: 提出的BlocKOA算法能加速芯片热仿真数据的生成并提高数据精度，相比现有方法，其时间复杂度低一个数量级，并实现了420倍的加速。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动方法在集成电路热仿真方面效率高，但需要大量高保真训练数据，计算成本高。

Method: BlocKOA算法结合块Krylov算法和算子作用，利用热方程结构快速获得基础解，并通过组合得到满足物理约束的大量温度分布，最后通过热算子确定热源分布，从而生成精确数据点。

Result: BlocKOA算法的时间复杂度比现有方法低一个数量级。在生成5000个具有不同物理参数和集成电路结构的芯片热仿真数据时，BlocKOA实现了420倍的加速。使用BlocKOA生成的数据训练的数据驱动方法，在仅占生成时间的4%的情况下，性能与使用现有方法生成的数据相当。

Conclusion: BlocKOA算法能够高效、精确地生成集成电路热仿真数据，有效解决了现有数据驱动方法对大量训练数据的依赖问题，并显著降低了数据生成成本。

Abstract: Recent advances in data-driven approaches, such as neural operators (NOs),
have shown substantial efficacy in reducing the solution time for integrated
circuit (IC) thermal simulations. However, a limitation of these approaches is
requiring a large amount of high-fidelity training data, such as chip
parameters and temperature distributions, thereby incurring significant
computational costs. To address this challenge, we propose a novel algorithm
for the generation of IC thermal simulation data, named block Krylov and
operator action (BlocKOA), which simultaneously accelerates the data generation
process and enhances the precision of generated data. BlocKOA is specifically
designed for IC applications. Initially, we use the block Krylov algorithm
based on the structure of the heat equation to quickly obtain a few basic
solutions. Then we combine them to get numerous temperature distributions that
satisfy the physical constraints. Finally, we apply heat operators on these
functions to determine the heat source distributions, efficiently generating
precise data points. Theoretical analysis shows that the time complexity of
BlocKOA is one order lower than the existing method. Experimental results
further validate its efficiency, showing that BlocKOA achieves a 420-fold
speedup in generating thermal simulation data for 5000 chips with varying
physical parameters and IC structures. Even with just 4% of the generation
time, data-driven approaches trained on the data generated by BlocKOA exhibits
comparable performance to that using the existing method.

</details>


### [420] [CNOT Minimal Circuit Synthesis: A Reinforcement Learning Approach](https://arxiv.org/abs/2510.23304)
*Riccardo Romanello,Daniele Lizzio Bosco,Jacopo Cossio,Dusan Sutulovic,Giuseppe Serra,Carla Piazza,Paolo Burelli*

Main category: cs.AI

TL;DR: 本论文提出了一种新的强化学习方法来最小化CNOT门电路中的CNOT门数量，并通过实验证明该方法在处理更大规模的电路时优于现有技术。


<details>
  <summary>Details</summary>
Motivation: CNOT门是量子计算的基础，但其数量的最小化（CNOT最小化）仍然是一个未解决的挑战。因此，需要新的方法来解决这个问题。

Method: 提出了一种新的强化学习方法，使用单个智能体处理不同大小的电路，并通过嵌入或高斯条带预处理不同大小的矩阵。在m=8的智能体上进行了训练，并在n=3到15的矩阵上进行了评估。

Result: 所提出的方法在n不断增加时，其性能优于现有的最先进算法。

Conclusion: 本研究提出的强化学习方法在CNOT最小化问题上展现出了优越的性能，尤其是在处理大规模量子电路时。

Abstract: CNOT gates are fundamental to quantum computing, as they facilitate
entanglement, a crucial resource for quantum algorithms. Certain classes of
quantum circuits are constructed exclusively from CNOT gates. Given their
widespread use, it is imperative to minimise the number of CNOT gates employed.
This problem, known as CNOT minimisation, remains an open challenge, with its
computational complexity yet to be fully characterised. In this work, we
introduce a novel reinforcement learning approach to address this task. Instead
of training multiple reinforcement learning agents for different circuit sizes,
we use a single agent up to a fixed size $m$. Matrices of sizes different from
m are preprocessed using either embedding or Gaussian striping. To assess the
efficacy of our approach, we trained an agent with m = 8, and evaluated it on
matrices of size n that range from 3 to 15. The results we obtained show that
our method overperforms the state-of-the-art algorithm as the value of n
increases.

</details>


### [421] [Planning Ahead with RSA: Efficient Signalling in Dynamic Environments by Projecting User Awareness across Future Timesteps](https://arxiv.org/abs/2510.23340)
*Anwesha Das,John Duff,Jörg Hoffmann,Vera Demberg*

Main category: cs.AI

TL;DR: 该研究提出了一种自适应信号理论框架，利用理性沟通原则（特别是贝叶斯参考解析和理性话语行为模型）来优化人机协作中的信息传递。


<details>
  <summary>Details</summary>
Motivation: 在快速变化的环境中，为了确保人类在时敏任务中对关键信息有准确的理解，辅助智能体不仅需要识别最高优先级的信息，还需要估计如何以及何时最有效地传达这些信息，因为人类的注意力是有限的认知资源。

Method: 提出了一种自适应信号理论框架，利用理性沟通原则，特别是通过理性话语行为（RSA）建模框架形式化的贝叶斯参考解析，来规划一系列消息，以优化用户信念与动态环境之间的及时对齐。该智能体根据对用户先验知识引导的消息解读如何影响注意力及后续信念更新的预测，跨越多个时间步，来适应性地调整消息的具体内容和发送时机。

Result: 与基线方法相比，该研究表明，这种有效性关键在于结合了多步规划和对用户注意力的现实模型。

Conclusion: 该研究首次将RSA应用于动态环境中的通信以及人机交互，为智能体团队中的实用通信奠定了理论基础，并强调了如何利用认知科学的见解来设计辅助智能体。

Abstract: Adaptive agent design offers a way to improve human-AI collaboration on
time-sensitive tasks in rapidly changing environments. In such cases, to ensure
the human maintains an accurate understanding of critical task elements, an
assistive agent must not only identify the highest priority information but
also estimate how and when this information can be communicated most
effectively, given that human attention represents a zero-sum cognitive
resource where focus on one message diminishes awareness of other or upcoming
information. We introduce a theoretical framework for adaptive signalling which
meets these challenges by using principles of rational communication,
formalised as Bayesian reference resolution using the Rational Speech Act (RSA)
modelling framework, to plan a sequence of messages which optimise timely
alignment between user belief and a dynamic environment. The agent adapts
message specificity and timing to the particulars of a user and scenario based
on projections of how prior-guided interpretation of messages will influence
attention to the interface and subsequent belief update, across several
timesteps out to a fixed horizon. In a comparison to baseline methods, we show
that this effectiveness depends crucially on combining multi-step planning with
a realistic model of user awareness. As the first application of RSA for
communication in a dynamic environment, and for human-AI interaction in
general, we establish theoretical foundations for pragmatic communication in
human-agent teams, highlighting how insights from cognitive science can be
capitalised to inform the design of assistive agents.

</details>


### [422] [Opinion Mining Based Entity Ranking using Fuzzy Logic Algorithmic Approach](https://arxiv.org/abs/2510.23384)
*Pratik N. Kalamkar,A. G. Phakatkar*

Main category: cs.AI

TL;DR: 这是一个关于意见挖掘的论文，它提出了一种使用模糊逻辑对实体进行更细粒度分类和排名的א方法。


<details>
  <summary>Details</summary>
Motivation: 从大量在线评论中提取有价值的见解，并对实体进行更细粒度的分类和排名。

Method: 使用模糊逻辑推理对评论进行更细粒度的分类，然后根据这些分类对实体进行排名。

Result: 能够对实体进行更细粒度的分类和排名，从而提供更深入的见解。

Conclusion: 该方法能够有效地从文本中提取意见，并对实体进行更细粒度的分类和排名。

Abstract: Opinions are central to almost all human activities and are key influencers
of our behaviors. In current times due to growth of social networking website
and increase in number of e-commerce site huge amount of opinions are now
available on web. Given a set of evaluative statements that contain opinions
(or sentiments) about an Entity, opinion mining aims to extract attributes and
components of the object that have been commented on in each statement and to
determine whether the comments are positive, negative or neutral. While lot of
research recently has been done in field of opinion mining and some of it
dealing with ranking of entities based on review or opinion set, classifying
opinions into finer granularity level and then ranking entities has never been
done before. In this paper method for opinion mining from statements at a
deeper level of granularity is proposed. This is done by using fuzzy logic
reasoning, after which entities are ranked as per this information.

</details>


### [423] [Bid2X: Revealing Dynamics of Bidding Environment in Online Advertising from A Foundation Model Lens](https://arxiv.org/abs/2510.23410)
*Jiahao Ji,Tianyu Wang,Yeshu Li,Yushen Huo,Zhilin Zhang,Chuan Yu,Jian Xu,Bo Zheng*

Main category: cs.AI

TL;DR: Bid2X是一个自动竞价模型，通过学习通用函数来预测竞价结果，并在实际应用中提高了GMV和ROI。


<details>
  <summary>Details</summary>
Motivation: 现有自动竞价模型泛化性不足，难以适应不同竞价场景。

Method: 提出Bid2X模型，利用统一的序列嵌入编码异构数据，并通过变量和时间注意力机制捕捉数据依赖关系，结合零膨胀预测模块进行竞价结果预测。

Result: 在八个数据集上的离线评估优于基线模型，在线A/B测试显示GMV提高4.65%，ROI提高2.44%。

Conclusion: Bid2X展示了其在不同竞价场景下的优越性和泛化能力，为计算广告领域的竞价基础模型铺平了道路。

Abstract: Auto-bidding is crucial in facilitating online advertising by automatically
providing bids for advertisers. While previous work has made great efforts to
model bidding environments for better ad performance, it has limitations in
generalizability across environments since these models are typically tailored
for specific bidding scenarios. To this end, we approach the
scenario-independent principles through a unified function that estimates the
achieved effect under specific bids, such as budget consumption, gross
merchandise volume (GMV), page views, etc. Then, we propose a bidding
foundation model Bid2X to learn this fundamental function from data in various
scenarios. Our Bid2X is built over uniform series embeddings that encode
heterogeneous data through tailored embedding methods. To capture complex
inter-variable and dynamic temporal dependencies in bidding data, we propose
two attention mechanisms separately treating embeddings of different variables
and embeddings at different times as attention tokens for representation
learning. On top of the learned variable and temporal representations, a
variable-aware fusion module is used to perform adaptive bidding outcome
prediction. To model the unique bidding data distribution, we devise a
zero-inflated projection module to incorporate the estimated non-zero
probability into its value prediction, which makes up a joint optimization
objective containing classification and regression. The objective is proven to
converge to the zero-inflated distribution. Our model has been deployed on the
ad platform in Taobao, one of the world's largest e-commerce platforms. Offline
evaluation on eight datasets exhibits Bid2X's superiority compared to various
baselines and its generality across different scenarios. Bid2X increased GMV by
4.65% and ROI by 2.44% in online A/B tests, paving the way for bidding
foundation model in computational advertising.

</details>


### [424] [Causal Deep Q Network](https://arxiv.org/abs/2510.23424)
*Elouanes Khelifi,Amir Saki,Usef Faghihi*

Main category: cs.AI

TL;DR: 提出一种将因果原理融入深度Q网络（DQN）的新方法，利用PEACE公式估计因果效应，以克服DQN对联想学习的依赖以及由此产生的虚假相关性。


<details>
  <summary>Details</summary>
Motivation: 深度Q网络（DQN）在强化学习任务中取得了成功，但其对联想学习的依赖会导致虚假相关性的产生，从而阻碍其解决问题的能力。

Method: 通过在训练中引入因果推理，利用PEACE（概率性易变因果效应）公式来估计因果效应，将因果原理整合到DQN中。

Result: 实验结果表明，该方法在标准基准环境中优于传统DQN，证明了因果推理在强化学习中的有效性。

Conclusion: 将DQN与因果能力相结合，可以在不影响性能的情况下显著提高其解决问题的能力，为通过基于原则的因果推断来提升深度强化学习代理的能力提供了一条有前景的途径。

Abstract: Deep Q Networks (DQN) have shown remarkable success in various reinforcement
learning tasks. However, their reliance on associative learning often leads to
the acquisition of spurious correlations, hindering their problem-solving
capabilities. In this paper, we introduce a novel approach to integrate causal
principles into DQNs, leveraging the PEACE (Probabilistic Easy vAriational
Causal Effect) formula for estimating causal effects. By incorporating causal
reasoning during training, our proposed framework enhances the DQN's
understanding of the underlying causal structure of the environment, thereby
mitigating the influence of confounding factors and spurious correlations. We
demonstrate that integrating DQNs with causal capabilities significantly
enhances their problem-solving capabilities without compromising performance.
Experimental results on standard benchmark environments showcase that our
approach outperforms conventional DQNs, highlighting the effectiveness of
causal reasoning in reinforcement learning. Overall, our work presents a
promising avenue for advancing the capabilities of deep reinforcement learning
agents through principled causal inference.

</details>


### [425] [What are the odds? Risk and uncertainty about AI existential risk](https://arxiv.org/abs/2510.23453)
*Marco Grossi*

Main category: cs.AI

TL;DR: 该论文是对 Cappelen, Goldstein 和 Hawthorne 的文章“AI生存故事：AI存在风险的分类分析”的评论，并探讨了线性风险模型的哲学局限性。


<details>
  <summary>Details</summary>
Motivation: 评论 Cappelen, Goldstein 和 Hawthorne 的文章，并探讨线性风险模型的哲学局限性，特别是关于AI存在风险的模型。

Method: 分析 Cappelen, Goldstein 和 Hawthorne 文章中使用的模型，比较其与标准的瑞士奶酪模型，并讨论了在认知冷漠的情况下，考虑到分层结构关系，P(D)的概率可能高于初步估计。此外，区分了风险和不确定性，并认为选项不确定性和状态空间不确定性这两种不确定性因素会影响P(D)的估计。

Result: 提供了对AI存在风险更深入的理解，强调了不确定性在评估P(D)中的作用。

Conclusion: 通过区分风险和不确定性，并纳入选项不确定性和状态空间不确定性，可以更好地理解AI存在风险的可能性。

Abstract: This work is a commentary of the article
\href{https://doi.org/10.18716/ojs/phai/2025.2801}{AI Survival Stories: a
Taxonomic Analysis of AI Existential Risk} by Cappelen, Goldstein, and
Hawthorne. It is not just a commentary though, but a useful reminder of the
philosophical limitations of \say{linear} models of risk. The article will
focus on the model employed by the authors: first, I discuss some differences
between standard Swiss Cheese models and this one. I then argue that in a
situation of epistemic indifference the probability of P(D) is higher than what
one might first suggest, given the structural relationships between layers. I
then distinguish between risk and uncertainty, and argue that any estimation of
P(D) is structurally affected by two kinds of uncertainty: option uncertainty
and state-space uncertainty. Incorporating these dimensions of uncertainty into
our qualitative discussion on AI existential risk can provide a better
understanding of the likeliness of P(D).

</details>


### [426] [Policy-Aware Generative AI for Safe, Auditable Data Access Governance](https://arxiv.org/abs/2510.23474)
*Shames Al Mandalawi,Muzakkiruddin Ahmed Mohammed,Hendrika Maclean,Mert Can Cakmak,John R. Talburt*

Main category: cs.AI

TL;DR: 利用Google Gemini Flash构建了一个策略感知控制器，通过LLM解读自然语言请求，并结合六阶段推理框架和策略门禁，实现了对访问决策的自动化，准确率达92.9%，满足了安全、合规和可审计的要求。


<details>
  <summary>Details</summary>
Motivation: 企业需要满足最小权限、法规遵从和可审计性要求的访问决策。

Method: 开发了一个策略感知控制器，使用LLM（Google Gemini Flash）解读自然语言请求，并应用一个包含六个推理阶段（上下文解释、用户验证、数据分类、业务目的测试、合规映射和风险综合）的框架，辅以早期硬策略门禁和默认拒绝机制。

Result: 在14个典型案例的7个场景家族的隐私保护基准测试中，精确决策匹配率从10/14提升至13/14（92.9%），拒绝召回率达到1.00，必须拒绝类别的错误批准率降至0，功能适当性和合规性达到14/14。LLM生成的理由质量评分高，中位延迟低于一分钟。

Conclusion: 策略约束的LLM推理，结合明确的门禁和审计追踪，能够将人类可读的策略转化为安全、合规且可追踪的机器决策。

Abstract: Enterprises need access decisions that satisfy least privilege, comply with
regulations, and remain auditable. We present a policy aware controller that
uses a large language model (LLM) to interpret natural language requests
against written policies and metadata, not raw data. The system, implemented
with Google Gemini~2.0 Flash, executes a six-stage reasoning framework (context
interpretation, user validation, data classification, business purpose test,
compliance mapping, and risk synthesis) with early hard policy gates and deny
by default. It returns APPROVE, DENY, CONDITIONAL together with cited controls
and a machine readable rationale. We evaluate on fourteen canonical cases
across seven scenario families using a privacy preserving benchmark. Results
show Exact Decision Match improving from 10/14 to 13/14 (92.9\%) after applying
policy gates, DENY recall rising to 1.00, False Approval Rate on must-deny
families dropping to 0, and Functional Appropriateness and Compliance Adherence
at 14/14. Expert ratings of rationale quality are high, and median latency is
under one minute. These findings indicate that policy constrained LLM
reasoning, combined with explicit gates and audit trails, can translate human
readable policies into safe, compliant, and traceable machine decisions.

</details>


### [427] [Human-AI Collaborative Uncertainty Quantification](https://arxiv.org/abs/2510.23476)
*Sima Noorani,Shayan Kiyani,George Pappas,Hamed Hassani*

Main category: cs.AI

TL;DR: 本研究提出了一种结合人类和AI优势的框架，用于在不确定性下进行预测，以提高决策的可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前AI在决策中缺乏领域知识、长时域背景和物理世界推理能力，促使研究者探索人机协作框架。

Method: 提出了一种名为“人机协作不确定性量化”的框架，旨在使AI模型能够优化人类专家的预测集，同时避免错误判断并弥补人类的疏漏。研究者还基于“双阈值结构”开发了离线和在线校准算法，并证明了其具有分布无关的有限样本保证。在线方法还能适应分布变化，包括“人类到AI的适应”现象。

Result: 实验结果表明，在图像分类、回归和医学决策等领域，人机协作的预测集在覆盖率和集合大小方面均优于单独的AI或人类专家。

Conclusion: 人机协作不确定性量化框架能够有效结合人类和AI的优势，在不确定性条件下提供更可靠的决策支持。

Abstract: AI predictive systems are increasingly embedded in decision making pipelines,
shaping high stakes choices once made solely by humans. Yet robust decisions
under uncertainty still rely on capabilities that current AI lacks: domain
knowledge not captured by data, long horizon context, and reasoning grounded in
the physical world. This gap has motivated growing efforts to design
collaborative frameworks that combine the complementary strengths of humans and
AI. This work advances this vision by identifying the fundamental principles of
Human AI collaboration within uncertainty quantification, a key component of
reliable decision making. We introduce Human AI Collaborative Uncertainty
Quantification, a framework that formalizes how an AI model can refine a human
expert's proposed prediction set with two goals: avoiding counterfactual harm,
ensuring the AI does not degrade correct human judgments, and complementarity,
enabling recovery of correct outcomes the human missed. At the population
level, we show that the optimal collaborative prediction set follows an
intuitive two threshold structure over a single score function, extending a
classical result in conformal prediction. Building on this insight, we develop
practical offline and online calibration algorithms with provable distribution
free finite sample guarantees. The online method adapts to distribution shifts,
including human behavior evolving through interaction with AI, a phenomenon we
call Human to AI Adaptation. Experiments across image classification,
regression, and text based medical decision making show that collaborative
prediction sets consistently outperform either agent alone, achieving higher
coverage and smaller set sizes across various conditions.

</details>


### [428] [Are Agents Just Automata? On the Formal Equivalence Between Agentic AI and the Chomsky Hierarchy](https://arxiv.org/abs/2510.23487)
*Roham Koohestani,Ziyou Li,Anton Podkopaev,Maliheh Izadi*

Main category: cs.AI

TL;DR: 将AI代理的架构类比于乔姆斯基层次的抽象机，并提出内存架构决定了AI代理的计算能力。


<details>
  <summary>Details</summary>
Motivation: 提出一种将AI代理的架构与乔姆斯基层次的抽象机形式化关联的方法，以期实现对AI代理的计算能力进行分类和优化。

Method: 将不同类型的AI代理（简单反射代理、分层任务分解代理、使用可读/写内存进行反思的代理）与有限自动机、下推自动机和图灵机进行对应。将框架扩展到概率自动机以处理基于LLM的代理，并提出开发静态分析工具和语法的议程。

Result: 建立了AI代理架构与乔姆斯基层次抽象机的形式等价性，并证明了不同类型代理与相应自动机的对应关系。

Conclusion: AI代理的内存架构决定其计算能力，可将其映射到相应的自动机类。该框架有助于优化代理架构、实现形式化验证、保证代理安全性和可预测性，并能区分可验证系统和行为不可判定系统。

Abstract: This paper establishes a formal equivalence between the architectural classes
of modern agentic AI systems and the abstract machines of the Chomsky
hierarchy. We posit that the memory architecture of an AI agent is the
definitive feature determining its computational power and that it directly
maps it to a corresponding class of automaton. Specifically, we demonstrate
that simple reflex agents are equivalent to Finite Automata, hierarchical
task-decomposition agents are equivalent to Pushdown Automata, and agents
employing readable/writable memory for reflection are equivalent to TMs. This
Automata-Agent Framework provides a principled methodology for right-sizing
agent architectures to optimize computational efficiency and cost. More
critically, it creates a direct pathway to formal verification, enables the
application of mature techniques from automata theory to guarantee agent safety
and predictability. By classifying agents, we can formally delineate the
boundary between verifiable systems and those whose behavior is fundamentally
undecidable. We address the inherent probabilistic nature of LLM-based agents
by extending the framework to probabilistic automata that allow quantitative
risk analysis. The paper concludes by outlining an agenda for developing static
analysis tools and grammars for agentic frameworks.

</details>


### [429] [Emotion-Coherent Reasoning for Multimodal LLMs via Emotional Rationale Verifier](https://arxiv.org/abs/2510.23506)
*Hyeongseop Rha,Jeong Hun Yeo,Yeonju Kim,Yong Man Ro*

Main category: cs.AI

TL;DR: MLLMs在情感理解方面取得了进展，但其生成的情感解释往往与预测的情感不一致。本研究提出了情感理由验证器（ERV）和解释奖励机制，以提高情感解释与预测的一致性，并提升了在MAFW和DFEW数据集上的表现，使MLLMs能够提供更具情感连贯性和可信度的交互。


<details>
  <summary>Details</summary>
Motivation: 当前的多模态大语言模型（MLLMs）在进行情感识别时，往往生成与预测情感不一致甚至矛盾的解释，这降低了交互的准确性和用户的信任度。

Method: 提出了一种名为情感理由验证器（ERV）的方法，并结合解释奖励机制，在不改变模型架构或增加额外标注的情况下，引导模型生成与目标情感一致的理由，从而实现多模态情感识别。

Result: 所提出的方法在MAFW和DFEW数据集上显著提高了情感解释与预测之间的一致性，并提升了解释情感的准确性。

Conclusion: 该方法通过增强解释与预测之间的一致性，使MLLMs能够提供情感连贯且可信的交互，是实现真正类人交互界面的关键一步。

Abstract: The recent advancement of Multimodal Large Language Models (MLLMs) is
transforming human-computer interaction (HCI) from surface-level exchanges into
more nuanced and emotionally intelligent communication. To realize this shift,
emotion understanding becomes essential allowing systems to capture subtle cues
underlying user intent. Furthermore, providing faithful explanations for
predicted emotions is crucial to ensure interpretability and build user trust.
However, current MLLM-based methods often generate emotion explanations that
diverge from the target labels and sometimes even contradict their own
predicted emotions. This inconsistency poses a critical risk for
misunderstanding and erodes reliability in interactive settings. To address
this, we propose a novel approach: the Emotional Rationale Verifier (ERV) and
an Explanation Reward. Our method guides the model to produce reasoning that is
explicitly consistent with the target emotion during multimodal emotion
recognition without modifying the model architecture or requiring additional
paired video-description annotations. Our method significantly improves
faithful explanation-prediction consistency and explanation emotion accuracy on
the MAFW and DFEW datasets. Through extensive experiments and human
evaluations, we show that our approach not only enhances alignment between
explanation and prediction but also empowers MLLMs to deliver emotionally
coherent, trustworthy interactions, marking a key step toward truly human-like
HCI systems.

</details>


### [430] [Toward Carbon-Neutral Human AI: Rethinking Data, Computation, and Learning Paradigms for Sustainable Intelligence](https://arxiv.org/abs/2510.23524)
*KC Santosh,Rodrigue Rizk,Longwei Wang*

Main category: cs.AI

TL;DR: AI的快速发展带来了巨大的计算需求和环境问题。本文提出了一种名为HAI的新框架，强调增量学习、碳感知优化和人机协作，以实现可持续、以人为中心的人工智能。


<details>
  <summary>Details</summary>
Motivation: AI的快速发展带来了巨大的计算需求、环境问题和伦理担忧，现有依赖大规模、静态数据集和单一训练模式的方法需要改进。

Method: 提出了一种名为HAI（Human AI）的新框架，该框架强调增量学习、碳感知优化和人机协作，并借鉴了生物认知和动态架构的原理。

Result: HAI框架能够实现AI的持续、情境化学习，同时最小化碳足迹和人工标注成本，解决了主动学习、持续适应和节能模型部署中的挑战。

Conclusion: HAI框架为实现负责任的、以人为中心的人工智能提供了一种途径，能够平衡性能与环境责任。

Abstract: The rapid advancement of Artificial Intelligence (AI) has led to
unprecedented computational demands, raising significant environmental and
ethical concerns. This paper critiques the prevailing reliance on large-scale,
static datasets and monolithic training paradigms, advocating for a shift
toward human-inspired, sustainable AI solutions. We introduce a novel
framework, Human AI (HAI), which emphasizes incremental learning, carbon-aware
optimization, and human-in-the-loop collaboration to enhance adaptability,
efficiency, and accountability. By drawing parallels with biological cognition
and leveraging dynamic architectures, HAI seeks to balance performance with
ecological responsibility. We detail the theoretical foundations, system
design, and operational principles that enable AI to learn continuously and
contextually while minimizing carbon footprints and human annotation costs. Our
approach addresses pressing challenges in active learning, continual
adaptation, and energy-efficient model deployment, offering a pathway toward
responsible, human-centered artificial intelligence.

</details>


### [431] [When No Paths Lead to Rome: Benchmarking Systematic Neural Relational Reasoning](https://arxiv.org/abs/2510.23532)
*Anirban Das,Irtaza Khalid,Rafael Peñaloza,Steven Schockaert*

Main category: cs.AI

TL;DR: 现有系统关系推理基准过于简化，限制了模型的泛化能力。为解决此问题，本文提出了NoRA基准，增加了难度，超越了基于路径的推理。


<details>
  <summary>Details</summary>
Motivation: 现有系统关系推理基准的过度简化限制了模型的泛化能力，阻碍了该领域的进展。

Method: 提出名为NoRA的新基准，增加难度，超越基于路径的推理。

Result: NoRA基准能够评估模型在超越路径推理方面的能力。

Conclusion: 需要新的基准（如NoRA）来推动神经系统关系推理的发展，使其能够处理更复杂的推理任务。

Abstract: Designing models that can learn to reason in a systematic way is an important
and long-standing challenge. In recent years, a wide range of solutions have
been proposed for the specific case of systematic relational reasoning,
including Neuro-Symbolic approaches, variants of the Transformer architecture,
and specialised Graph Neural Networks. However, existing benchmarks for
systematic relational reasoning focus on an overly simplified setting, based on
the assumption that reasoning can be reduced to composing relational paths. In
fact, this assumption is hard-baked into the architecture of several recent
models, leading to approaches that can perform well on existing benchmarks but
are difficult to generalise to other settings. To support further progress in
the field of systematic relational reasoning with neural networks, we introduce
NoRA, a new benchmark which adds several levels of difficulty and requires
models to go beyond path-based reasoning.

</details>


### [432] [JanusCoder: Towards a Foundational Visual-Programmatic Interface for Code Intelligence](https://arxiv.org/abs/2510.23538)
*Qiushi Sun,Jingyang Gong,Yang Liu,Qiaosheng Chen,Lei Li,Kai Chen,Qipeng Guo,Ben Kao,Fei Yuan*

Main category: cs.AI

TL;DR: 该论文提出JanusCoder模型，通过构建大规模多模态代码数据集JanusCode-800K，实现了从文本、视觉输入或两者的结合生成代码，并在多个编程任务上取得了优于现有模型（包括商业模型）的性能。


<details>
  <summary>Details</summary>
Motivation: 现有神经代码智能研究主要集中在文本代码，忽视了程序生成的丰富视觉输出，限制了其在内容生成和可视化编辑等高级应用中的发展。数据稀缺和评估困难是该领域的主要瓶颈。

Method: 开发了一个包含文本、视觉和代码的多模态代码数据集合成工具包，并以此构建了迄今为止最大的多模态代码数据集JanusCode-800K。基于该数据集，训练了JanusCoder和JanusCoderV两个统一模型，实现了从文本、视觉或两者的组合生成代码的功能。

Result: JanusCoder系列模型（7B至14B规模）在以文本为中心和以视觉为中心的编码任务上均表现出优越性能，媲美甚至超越了商业模型。此外，研究还深入分析了程序逻辑与其视觉表达的协调机制。

Conclusion: JanusCoder系列模型通过大规模多模态代码数据集和统一的建模方法，有效解决了神经代码智能中的视觉维度挑战，并在代码生成任务上取得了显著进展，为未来多模态代码智能研究奠定了基础。

Abstract: The scope of neural code intelligence is rapidly expanding beyond text-based
source code to encompass the rich visual outputs that programs generate. This
visual dimension is critical for advanced applications like flexible content
generation and precise, program-driven editing of visualizations. However,
progress has been impeded by the scarcity of high-quality multimodal code data,
a bottleneck stemming from challenges in synthesis and quality assessment. To
address these challenges, we make contributions from both a data and modeling
perspective. We first introduce a complete synthesis toolkit that leverages
reciprocal synergies between data modalities to efficiently produce a
large-scale, high-quality corpus spanning from standard charts to complex
interactive web UIs and code-driven animations. Leveraging this toolkit, we
construct JanusCode-800K, the largest multimodal code corpus to date. This
powers the training of our models, JanusCoder and JanusCoderV, which establish
a visual-programmatic interface for generating code from textual instructions,
visual inputs, or a combination of both. Our unified model is a departure from
existing approaches that build specialized models for isolated tasks. Extensive
experiments on both text-centric and vision-centric coding tasks demonstrate
the superior performance of the JanusCoder series, with our 7B to 14B scale
models approaching or even exceeding the performance of commercial models.
Furthermore, extensive analysis provides key insights into harmonizing
programmatic logic with its visual expression. Our code and checkpoints will
are available at https://github.com/InternLM/JanusCoder.

</details>


### [433] [OntoPret: An Ontology for the Interpretation of Human Behavior](https://arxiv.org/abs/2510.23553)
*Alexis Ellis,Stacie Severyn,Fjollë Novakazi,Hadi Banaee,Cogan Shimizu*

Main category: cs.AI

TL;DR: 该论文提出了OntoPret，一个用于实时解释人类行为的本体，以弥合技术中心机器人框架和描述性行为本体之间的差距。


<details>
  <summary>Details</summary>
Motivation: 随着工业5.0等范式中人机协作变得越来越重要，机器需要安全有效地理解复杂的人类行为。现有的技术中心机器人框架缺乏细致的人类行为模型，而描述性行为本体又不适用于实时协作解释，这之间存在研究空白。

Method: 提出OntoPret，一个基于认知科学和模块化工程方法的人类行为解释本体。该本体提供了一个形式化的、机器可处理的框架，用于对包括任务偏差和欺骗行为在内的行为进行分类。

Result: OntoPret已成功应用于制造业和游戏两种不同的场景，证明了其适应性，并为高级的人类意图推理奠定了语义基础。

Conclusion: OntoPret为机器理解和解释人类行为提供了一个强大的框架，有助于实现更安全、更有效的人机协作。

Abstract: As human machine teaming becomes central to paradigms like Industry 5.0, a
critical need arises for machines to safely and effectively interpret complex
human behaviors. A research gap currently exists between techno centric robotic
frameworks, which often lack nuanced models of human behavior, and descriptive
behavioral ontologies, which are not designed for real time, collaborative
interpretation. This paper addresses this gap by presenting OntoPret, an
ontology for the interpretation of human behavior. Grounded in cognitive
science and a modular engineering methodology, OntoPret provides a formal,
machine processable framework for classifying behaviors, including task
deviations and deceptive actions. We demonstrate its adaptability across two
distinct use cases manufacturing and gameplay and establish the semantic
foundations necessary for advanced reasoning about human intentions.

</details>


### [434] [ReCode: Unify Plan and Action for Universal Granularity Control](https://arxiv.org/abs/2510.23564)
*Zhaoyang Yu,Jiayi Zhang,Huixue Su,Yufan Zhao,Yifan Wu,Mingyi Deng,Jinyu Xiang,Yizhang Lin,Lingxiao Tang,Yingchao Li,Yuyu Luo,Bang Liu,Chenglin Wu*

Main category: cs.AI

TL;DR: ReCode通过递归代码生成统一规划和动作，实现跨不同粒度的决策。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的代理缺乏在不同决策粒度下操作的能力，因为现有范式强制区分高级规划和低级动作，这会影响动态适应性和泛化能力。

Method: 提出ReCode（递归代码生成）范式，将高级计划视为抽象的占位符函数，然后代理将其递归地分解为更细粒度的子函数，直到达到原始动作。

Result: ReCode在推理性能上显著优于先进基线，并在训练中表现出卓越的数据效率。

Conclusion: 通过递归代码生成统一规划和动作是实现通用粒度控制的有效方法。

Abstract: Real-world tasks require decisions at varying granularities, and humans excel
at this by leveraging a unified cognitive representation where planning is
fundamentally understood as a high-level form of action. However, current Large
Language Model (LLM)-based agents lack this crucial capability to operate
fluidly across decision granularities. This limitation stems from existing
paradigms that enforce a rigid separation between high-level planning and
low-level action, which impairs dynamic adaptability and limits generalization.
We propose ReCode (Recursive Code Generation), a novel paradigm that addresses
this limitation by unifying planning and action within a single code
representation. In this representation, ReCode treats high-level plans as
abstract placeholder functions, which the agent then recursively decomposes
into finer-grained sub-functions until reaching primitive actions. This
recursive approach dissolves the rigid boundary between plan and action,
enabling the agent to dynamically control its decision granularity.
Furthermore, the recursive structure inherently generates rich,
multi-granularity training data, enabling models to learn hierarchical
decision-making processes. Extensive experiments show ReCode significantly
surpasses advanced baselines in inference performance and demonstrates
exceptional data efficiency in training, validating our core insight that
unifying planning and action through recursive code generation is a powerful
and effective approach to achieving universal granularity control. The code is
available at https://github.com/FoundationAgents/ReCode.

</details>


### [435] [Reduced AI Acceptance After the Generative AI Boom: Evidence From a Two-Wave Survey Study](https://arxiv.org/abs/2510.23578)
*Joachim Baumann,Aleksandra Urman,Ulrich Leicht-Deobald,Zachary J. Roman,Anikó Hannák,Markus Christen*

Main category: cs.AI

TL;DR: 一项关于生成式人工智能（GenAI）普及前后公众态度的调查研究。


<details>
  <summary>Details</summary>
Motivation: 在生成式人工智能（GenAI）迅速普及、被许多组织集成到产品和服务中，但用户偏好常被忽视的背景下，本研究旨在探讨公众对人工智能（AI）使用的态度，特别是在有影响力的决策场景中，因为这方面的研究尚不充分。

Method: 本研究采用大规模、两阶段的调查方法，收集了代表瑞士人口的样本（第一阶段n=1514，第二阶段n=1488），考察了在ChatGPT发布前后公众态度的变化。

Result: 研究发现，GenAI的兴起与公众对AI接受度的显著下降（见图1）以及在各种决策情境下对人工监督需求的增加显著相关。完全不能接受AI的受访者比例从23%上升到30%，而仅支持人工决策的比例从18%上升到26%。这些变化加剧了原有的社会不平等，表现为GenAI热潮后教育、语言和性别差距的扩大。

Conclusion: 本研究结果对行业关于公众接受AI部署的假设提出了挑战，并强调了技术发展与不断变化的公众偏好相一致的极端重要性。

Abstract: The rapid adoption of generative artificial intelligence (GenAI) technologies
has led many organizations to integrate AI into their products and services,
often without considering user preferences. Yet, public attitudes toward AI
use, especially in impactful decision-making scenarios, are underexplored.
Using a large-scale two-wave survey study (n_wave1=1514, n_wave2=1488)
representative of the Swiss population, we examine shifts in public attitudes
toward AI before and after the launch of ChatGPT. We find that the GenAI boom
is significantly associated with reduced public acceptance of AI (see Figure 1)
and increased demand for human oversight in various decision-making contexts.
The proportion of respondents finding AI "not acceptable at all" increased from
23% to 30%, while support for human-only decision-making rose from 18% to 26%.
These shifts have amplified existing social inequalities in terms of widened
educational, linguistic, and gender gaps post-boom. Our findings challenge
industry assumptions about public readiness for AI deployment and highlight the
critical importance of aligning technological development with evolving public
preferences.

</details>


### [436] [Multi-Agent Evolve: LLM Self-Improve through Co-evolution](https://arxiv.org/abs/2510.23595)
*Yixing Chen,Yiding Wang,Siqi Zhu,Haofei Yu,Tao Feng,Muhan Zhan,Mostofa Patwary,Jiaxuan You*

Main category: cs.AI

TL;DR: MAE是一个多智能体框架，通过生成、求解和评审的交互式智能体，在无需人工监督的情况下提升LLM的通用推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的RL方法在提升LLM推理能力方面依赖于人工数据集和可验证的奖励，这限制了其可扩展性和通用性。虽然自我博弈RL方法试图摆脱对人工数据的依赖，但它们需要一个有界环境进行反馈，难以推广到通用领域。

Method: 提出多智能体进化（MAE）框架，该框架包含三个由单个LLM实例化的交互式智能体：提出者、求解者和评审者。这三个智能体通过强化学习进行优化，提出者生成问题，求解者尝试解决方案，评审者评估两者，并共同进化。

Result: 在Qwen2.5-3B-Instruct模型上进行的实验表明，MAE在多个基准测试上平均提升了4.54%。

Conclusion: MAE是一种可扩展、数据高效的方法，可以最小化对人工监督的依赖，从而增强LLM的通用推理能力。

Abstract: Reinforcement Learning (RL) has demonstrated significant potential in
enhancing the reasoning capabilities of large language models (LLMs). However,
the success of RL for LLMs heavily relies on human-curated datasets and
verifiable rewards, which limit their scalability and generality. Recent
Self-Play RL methods, inspired by the success of the paradigm in games and Go,
aim to enhance LLM reasoning capabilities without human-annotated data.
However, their methods primarily depend on a grounded environment for feedback
(e.g., a Python interpreter or a game engine); extending them to general
domains remains challenging. To address these challenges, we propose
Multi-Agent Evolve (MAE), a framework that enables LLMs to self-evolve in
solving diverse tasks, including mathematics, reasoning, and general knowledge
Q&A. The core design of MAE is based on a triplet of interacting agents
(Proposer, Solver, Judge) that are instantiated from a single LLM, and applies
reinforcement learning to optimize their behaviors. The Proposer generates
questions, the Solver attempts solutions, and the Judge evaluates both while
co-evolving. Experiments on Qwen2.5-3B-Instruct demonstrate that MAE achieves
an average improvement of 4.54% on multiple benchmarks. These results highlight
MAE as a scalable, data-efficient method for enhancing the general reasoning
abilities of LLMs with minimal reliance on human-curated supervision.

</details>


### [437] [Alita-G: Self-Evolving Generative Agent for Agent Generation](https://arxiv.org/abs/2510.23601)
*Jiahao Qiu,Xuan Qi,Hongru Wang,Xinzhe Juan,Yimin Wang,Zelin Zhao,Jiayi Geng,Jiacheng Guo,Peihang Li,Jingzhe Shi,Shilong Liu,Mengdi Wang*

Main category: cs.AI

TL;DR: ALITA-G是一个自进化框架，通过系统地生成、抽象和策展模型上下文协议（MCP）工具，将通用智能体转变为领域专家，在多个基准测试中取得了显著的性能提升，并降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLM）智能体在记忆、工具和反馈方面的能力有限，其自我进化主要局限于提示重写或失败重试。需要一种新的方法来使通用智能体具备领域专业知识。

Method: ALITA-G框架首先让一个通用智能体执行目标领域的任务，并从成功的路径中合成候选的MCP工具。然后，这些工具被抽象成参数化原语，并整合成一个MCP Box。在推理时，ALITA-A通过检索增强的MCP选择，结合工具描述和用例，然后执行配备MCP执行器的智能体。

Result: 在GAIA、PathVQA和Humanity's Last Exam等多个基准测试中，ALITA-G在GAIA验证集上取得了83.03%的pass@1和89.09%的pass@3的优异成绩，创下新的最先进纪录，同时将每个示例的平均代币数量减少了约15%。

Conclusion: ALITA-G提供了一个从通用能力到可重用、领域特定能力的原则性路径，提高了复杂推理任务的准确性和效率。

Abstract: Large language models (LLMs) have been shown to perform better when
scaffolded into agents with memory, tools, and feedback. Beyond this,
self-evolving agents have emerged, but current work largely limits adaptation
to prompt rewriting or failure retries. Therefore, we present ALITA-G, a
self-evolution framework that transforms a general-purpose agent into a domain
expert by systematically generating, abstracting, and curating Model Context
Protocol (MCP) tools. In this framework, a generalist agent executes a curated
suite of target-domain tasks and synthesizes candidate MCPs from successful
trajectories. These are then abstracted to parameterized primitives and
consolidated into an MCP Box. At inference time, ALITA-G performs
retrieval-augmented MCP selection with the help of each tool's descriptions and
use cases, before executing an agent equipped with the MCP Executor. Across
several benchmarks GAIA, PathVQA, and Humanity's Last Exam, ALITA-G attains
strong gains while reducing computation costs. On GAIA validation, it achieves
83.03% pass@1 and 89.09% pass@3, establishing a new state-of-the-art result
while reducing mean tokens per example by approximately 15% relative to a
strong baseline agent. ALITA-G thus provides a principled pathway from
generalist capability to reusable, domain-specific competence, improving both
accuracy and efficiency on complex reasoning tasks.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [438] [A Robotic Stirring Method with Trajectory Optimization and Adaptive Speed Control for Accurate Pest Counting in Water Traps](https://arxiv.org/abs/2510.21732)
*Xumin Gao,Mark Stevens,Grzegorz Cielniak*

Main category: cs.RO

TL;DR: 本研究提出了一种结合机器人搅拌、轨迹优化和自适应速度控制的水や罠害虫計数方法，以解决现有图像法在处理遮挡问题时的不足。


<details>
  <summary>Details</summary>
Motivation: 现有图像法在害虫計数时存在遮挡问题，影响计数准确性。

Method: 研究提出一种基于机器人手臂的自动搅拌系统，通过优化搅拌轨迹（圆形、方形、三角形、螺旋形、四个小圆形、随机线条）和引入计数置信度驱动的自适应速度控制，提高遮挡害虫的可视性，从而实现精确計数。

Result: 实验结果表明，该方法能够有效解决遮挡问题，提高計数准确性（具体结果需参考论文原文）。

Conclusion: 机器人搅拌法是解决水や罠害虫計数遮挡问题的一种有效新方法，并且首次研究了不同搅拌轨迹对动态液体中目标計数的影响，并实现了自适应速度搅拌。

Abstract: Accurate monitoring of pest population dynamics is crucial for informed
decision-making in precision agriculture. Currently, mainstream image-based
pest counting methods primarily rely on image processing combined with machine
learning or deep learning for pest counting. However, these methods have
limitations and struggle to handle situations involving pest occlusion. To
address this issue, this paper proposed a robotic stirring method with
trajectory optimization and adaptive speed control for accurate pest counting
in water traps. First, we developed an automated stirring system for pest
counting in yellow water traps based on a robotic arm. Stirring alters the
distribution of pests in the yellow water trap, making some of the occluded
individuals visible for detection and counting. Then, we investigated the
impact of different stirring trajectories on pest counting performance and
selected the optimal trajectory for pest counting. Specifically, we designed
six representative stirring trajectories, including circle, square, triangle,
spiral, four small circles, and random lines, for the robotic arm to stir. And
by comparing the overall average counting error and counting confidence of
different stirring trajectories across various pest density scenarios, we
determined the optimal trajectory. Finally, we proposed a counting
confidence-driven closed-loop control system to achieve adaptive-speed
stirring. It uses changes in pest counting confidence between consecutive
frames as feedback to adjust the stirring speed. To the best of our knowledge,
this is the first study dedicated to investigating the effects of different
stirring trajectories on object counting in the dynamic liquid environment and
to implement adaptive-speed stirring for this type of task. Experimental
results show ...

</details>


### [439] [Force-Displacement Profiling for Robot-Assisted Deployment of a Left Atrial Appendage Occluder Using FBG-EM Distal Sensing](https://arxiv.org/abs/2510.21734)
*Giovanni Battista Regazzo,Wim-Alexander Beckers,Xuan Thao Ha,Mouloud Ourak,Johan Vlekken,Emmanuel Vander Poorten*

Main category: cs.RO

TL;DR: 该研究提出了一种结合力传感和电磁跟踪的机器人辅助左心耳封堵术（LAAC）新方法，通过实时测量交互力和导管尖端位置，无需电离辐射即可表征封堵器部署动态并识别关键步骤，有望提高手术反馈和成功率。


<details>
  <summary>Details</summary>
Motivation: 左心房附件（LAA）功能障碍会增加血栓栓塞事件的风险，而左心房附件封堵术（LAAC）是一种通过封堵LAA来降低卒中风险的微创手术。现有技术依赖手动控制和成像技术（如透视和经食管超声心动图），存在辐射暴露和定位精度有限等问题。

Method: 该研究利用一种集成了光纤布拉格光栅（FBG）的力传感输送鞘，并结合电磁（EM）跟踪技术，在机器人辅助的LAAC封堵术中，对解剖模型进行实时交互力和导管尖端位置的测量。提出了一种新的力-位移剖析方法，用于表征封堵器部署动态并识别关键程序步骤，且不依赖电离辐射。

Result: 所提出的力剖析方法显示出低幅度的交互力，表明对周围解剖结构的机械应力最小。

Conclusion: 该方法有望为临床医生提供增强的术中反馈，提高部署结果。未来的工作将侧重于自动化部署步骤分类，并在动态、逼真的环境中验证传感策略。

Abstract: Atrial fibrillation (AF) increases the risk of thromboembolic events due to
impaired function of the left atrial appendage (LAA). Left atrial appendage
closure (LAAC) is a minimally invasive intervention designed to reduce stroke
risk by sealing the LAA with an expandable occluder device. Current deployment
relies on manual catheter control and imaging modalities like fluoroscopy and
transesophageal echocardiography, which carry limitations including radiation
exposure and limited positioning precision. In this study, we leverage a
previously developed force-sensing delivery sheath integrating fiber Bragg
gratings (FBGs) at the interface between the catheter and the occluder.
Combined with electromagnetic (EM) tracking, this setup enables real-time
measurement of interaction forces and catheter tip position during
robot-assisted LAAC deployment in an anatomical phantom. We present a novel
force-displacement profiling method that characterizes occluder deployment
dynamics and identifies key procedural steps without relying on ionizing
radiation. The force profiles reveal low-magnitude interaction forces,
suggesting minimal mechanical stress on the surrounding anatomy. This approach
shows promise in providing clinicians with enhanced intraoperative feedback,
improving deployment outcome. Future work will focus on automating deployment
steps classification and validating the sensing strategy in dynamic, realistic
environments.

</details>


### [440] [A phase-aware AI car-following model for electric vehicles with adaptive cruise control: Development and validation using real-world data](https://arxiv.org/abs/2510.21735)
*Yuhui Liu,Shian Wang,Ansel Panicker,Kate Embry,Ayana Asanova,Tianyi Li*

Main category: cs.RO

TL;DR: EVs具有独特的驾驶动力学，传统模型无法准确描述。本研究提出并验证了一个相感知人工智能（PAAI）跟车模型，以解决此问题。


<details>
  <summary>Details</summary>
Motivation: 现有微观模型能有效捕捉内燃机汽车的驾驶行为，但缺乏能够准确描述电动汽车独特跟车动力学的建模框架。鉴于电动汽车在交通中的日益普及，开发此类模型至关重要，但创建易于使用且准确的分析模型仍然具有挑战性。

Method: 开发并验证了一个相感知人工智能（PAAI）跟车模型，该模型通过引入人工智能组件来识别和适应不同的驾驶阶段（如快速加速和再生制动），从而增强了传统的基于物理的框架。利用配备自适应巡航控制（ACC）的车辆的真实轨迹数据，进行全面的模拟来验证模型的性能。

Result: 数值结果表明，与传统的跟车模型相比，PAAI模型显著提高了预测准确性。

Conclusion: PAAI模型为准确表示交通模拟中的电动汽车行为提供了一个有效的工具。

Abstract: Internal combustion engine (ICE) vehicles and electric vehicles (EVs) exhibit
distinct vehicle dynamics. EVs provide rapid acceleration, with electric motors
producing peak power across a wider speed range, and achieve swift deceleration
through regenerative braking. While existing microscopic models effectively
capture the driving behavior of ICE vehicles, a modeling framework that
accurately describes the unique car-following dynamics of EVs is lacking.
Developing such a model is essential given the increasing presence of EVs in
traffic, yet creating an easy-to-use and accurate analytical model remains
challenging.
  To address these gaps, this study develops and validates a Phase-Aware AI
(PAAI) car-following model specifically for EVs. The proposed model enhances
traditional physics-based frameworks with an AI component that recognizes and
adapts to different driving phases, such as rapid acceleration and regenerative
braking. Using real-world trajectory data from vehicles equipped with adaptive
cruise control (ACC), we conduct comprehensive simulations to validate the
model's performance. The numerical results demonstrate that the PAAI model
significantly improves prediction accuracy over traditional car-following
models, providing an effective tool for accurately representing EV behavior in
traffic simulations.

</details>


### [441] [Learn2Drive: A neural network-based framework for socially compliant automated vehicle control](https://arxiv.org/abs/2510.21736)
*Yuhui Liu,Samannita Halder,Shian Wang,Tianyi Li*

Main category: cs.RO

TL;DR: 本文提出了一种结合LSTM和物理约束的自适应巡航控制（ACC）新框架，旨在解决现有自动驾驶汽车（AVs）控制策略忽视与人类驾驶汽车（HVs）交互及对整体交通流影响的问题。该框架通过引入社会价值取向（SVO），使AVs能够考虑其对HVs和交通流的影响，充当移动交通调节器，从而减少拥堵、提高交通效率并降低能耗。


<details>
  <summary>Details</summary>
Motivation: 现有AVs控制策略主要关注个体车辆或车队的性能优化，忽视了与HVs的交互及对整体交通流的影响，可能加剧拥堵并降低系统效率。本文旨在解决这一研究空白，提出一种能够考虑AVs对HVs和交通流影响的社会兼容AV控制框架。

Method: 提出一种基于神经网络的社会兼容AV控制框架，该框架整合了长短期记忆（LSTM）网络和物理信息约束，并引入社会价值取向（SVO）。该框架定义了AVs和HVs的效用函数，并基于AVs的SVO进行优化，以平衡其自身控制目标与更广泛的交通流考量。

Result: 数值结果表明，所提出的方法能有效适应不同的交通状况，提升系统效率。当AV的控制模式从优先考虑能耗转向优化交通流效率时，跟随车队的车辆个体能耗至少增加58.99%，但个体平均速度的提升至少达到38.39%，表明交通动态得到显著改善。

Conclusion: 所提出的结合LSTM和物理约束的自适应巡航控制（ACC）框架，通过引入社会价值取向（SVO），使AVs能够充当移动交通调节器，有效平衡自身控制目标与整体交通流需求，从而减少拥堵、提高交通效率并降低能耗。该方法在适应不同交通状况和改善交通动态方面显示出显著效果。

Abstract: This study introduces a novel control framework for adaptive cruise control
(ACC) in automated driving, leveraging Long Short-Term Memory (LSTM) networks
and physics-informed constraints. As automated vehicles (AVs) adopt advanced
features like ACC, transportation systems are becoming increasingly intelligent
and efficient. However, existing AV control strategies primarily focus on
optimizing the performance of individual vehicles or platoons, often neglecting
their interactions with human-driven vehicles (HVs) and the broader impact on
traffic flow. This oversight can exacerbate congestion and reduce overall
system efficiency. To address this critical research gap, we propose a neural
network-based, socially compliant AV control framework that incorporates social
value orientation (SVO). This framework enables AVs to account for their
influence on HVs and traffic dynamics. By leveraging AVs as mobile traffic
regulators, the proposed approach promotes adaptive driving behaviors that
reduce congestion, improve traffic efficiency, and lower energy consumption.
Within this framework, we define utility functions for both AVs and HVs, which
are optimized based on the SVO of each AV to balance its own control objectives
with broader traffic flow considerations. Numerical results demonstrate the
effectiveness of the proposed method in adapting to varying traffic conditions,
thereby enhancing system-wide efficiency. Specifically, when the AV's control
mode shifts from prioritizing energy consumption to optimizing traffic flow
efficiency, vehicles in the following platoon experience at least a 58.99%
increase in individual energy consumption alongside at least a 38.39%
improvement in individual average speed, indicating significant enhancements in
traffic dynamics.

</details>


### [442] [Next-Generation LLM for UAV: From Natural Language to Autonomous Flight](https://arxiv.org/abs/2510.21739)
*Liangqi Yuan,Chuhao Deng,Dong-Jun Han,Inseok Hwang,Sabine Brunswicker,Christopher G. Brinton*

Main category: cs.RO

TL;DR: 该论文提出了NeLV系统，一个用于将大型语言模型（LLM）集成到无人机（UAV）操作中的自动化路线图，涵盖短、中、长程任务，并通过五级自动化分类法展示了从LLM作为解析器到完全自主的LLM作为自动驾驶仪的演变。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在无人机领域的应用研究主要集中在小型无人机和孤立任务上，缺乏对中长程、真实世界场景的综合研究。大型无人机平台面临着起降程序、法规遵循和任务期望等独特挑战。

Method: 提出NeLV系统，包含五个关键技术组件：LLM-as-Parser（指令解析）、Route Planner（兴趣点确定）、Path Planner（航点生成）、Control Platform（轨迹执行）和UAV monitoring（无人机监控）。通过多UAV巡逻、多兴趣点配送、多跳迁移三个用例进行可行性演示。提出一个五级自动化分类法，描述从LLM-as-Parser到LLM-as-Autopilot的演变过程。

Result: 成功演示了NeLV系统在不同操作规模下的可行性，并通过三项代表性用例进行了展示。建立了包含五个级别的自动化分类法，为LLM在无人机操作中的未来发展指明了方向。

Conclusion: NeLV系统为LLM在多尺度无人机操作中的集成提供了一个全面的自动化路线图，并提出了一个分类法来指导未来的研究和发展，以实现更高级别的自主性。

Abstract: With the rapid advancement of Large Language Models (LLMs), their
capabilities in various automation domains, particularly Unmanned Aerial
Vehicle (UAV) operations, have garnered increasing attention. Current research
remains predominantly constrained to small-scale UAV applications, with most
studies focusing on isolated components such as path planning for toy drones,
while lacking comprehensive investigation of medium- and long-range UAV systems
in real-world operational contexts. Larger UAV platforms introduce distinct
challenges, including stringent requirements for airport-based take-off and
landing procedures, adherence to complex regulatory frameworks, and specialized
operational capabilities with elevated mission expectations. This position
paper presents the Next-Generation LLM for UAV (NeLV) system -- a comprehensive
demonstration and automation roadmap for integrating LLMs into multi-scale UAV
operations. The NeLV system processes natural language instructions to
orchestrate short-, medium-, and long-range UAV missions through five key
technical components: (i) LLM-as-Parser for instruction interpretation, (ii)
Route Planner for Points of Interest (POI) determination, (iii) Path Planner
for waypoint generation, (iv) Control Platform for executable trajectory
implementation, and (v) UAV monitoring. We demonstrate the system's feasibility
through three representative use cases spanning different operational scales:
multi-UAV patrol, multi-POI delivery, and multi-hop relocation. Beyond the
current implementation, we establish a five-level automation taxonomy that
charts the evolution from current LLM-as-Parser capabilities (Level 1) to fully
autonomous LLM-as-Autopilot systems (Level 5), identifying technical
prerequisites and research challenges at each stage.

</details>


### [443] [FORGE-Tree: Diffusion-Forcing Tree Search for Long-Horizon Robot Manipulation](https://arxiv.org/abs/2510.21744)
*Yanjia Huang,Shuo Liu,Sheng Liu,Qingxiao Xu,Mingyang Wu,Xiangbo Gao,Zhengzhong Tu*

Main category: cs.RO

TL;DR: FORGE-Tree通过引入扩散强制（DF）和蒙特卡洛树扩散（MCTD）来解决长距离机器人操作中VLA策略的漂移和曝光偏差问题，提高了成功率。


<details>
  <summary>Details</summary>
Motivation: 长距离机器人操作任务对视觉-语言-动作（VLA）策略来说仍然是一个挑战，因为存在漂移和曝光偏差，并且通常会以固定的超参数对整个轨迹进行去噪，导致小的几何误差在不同阶段累积，并且没有机制在测试时将额外的计算分配给间隙较小的地方。

Method: FORGE-Tree引入了一个插入式控制层，它将一个与阶段对齐的扩散强制（DF）头与测试时的蒙特卡洛树扩散（MCTD）相结合。它使用一个固定的VLA编码器，DF将时间步与子任务阶段对齐；在推理过程中，它只对目标片段进行部分去噪，而冻结其他标记，将轨迹细化转化为一系列局部编辑。然后，它应用蒙特卡洛树扩散来选择下一个要细化的片段。场景图为扩展和几何关系感知的得分提供了先验知识，从而实现了树状去噪，其性能随搜索预算的增加而扩展，同时保留了已执行的前缀。

Result: 在LIBERO数据集上进行评估，FORGE-Tree将成功率在OpenVLA和Octo-Base的原始VLA基线上提高了13.4%至17.2%。在可比的计算预算下，尤其是在长距离变体上，性能提升仍然保持一致。

Conclusion: FORGE-Tree通过阶段对齐的DF和MCTD，有效解决了长距离机器人操作中的漂移和曝光偏差问题，提高了成功率和计算效率。

Abstract: Long-horizon robot manipulation tasks remain challenging for
Vision-Language-Action (VLA) policies due to drift and exposure bias, often
denoise the entire trajectory with fixed hyperparameters, causing small
geometric errors to compound across stages and offering no mechanism to
allocate extra test-time compute where clearances are tight. To address these
challenges, we introduce FORGE-Tree, a plug-in control layer that couples a
stage-aligned Diffusion Forcing (DF) head with test-time Monte Carlo Tree
Diffusion (MCTD). With a frozen VLA encoder, DF aligns timesteps to subtask
stages; during inference we partially denoise only a target segment while
keeping other tokens frozen, turning trajectory refinement into a sequence of
local edits. We then apply Monte Carlo Tree Diffusion to select the next
segment to refine. A scene graph supplies priors for expansion and geometry
relation-aware scoring for rollouts, yielding tree-structured denoising whose
performance scales with search budget while preserving the executed prefix.
Evaluation on LIBERO, FORGE-Tree improves success rate by 13.4 to 17.2 pp over
the native VLA baselines with both OpenVLA and Octo-Base. Gains remain
consistent under comparable compute budgets, especially on long-horizon
variants. Videos available at: https://taco-group.github.io/FORGE-Tree/

</details>


### [444] [Avi: Action from Volumetric Inference](https://arxiv.org/abs/2510.21746)
*Harris Song,Long Le*

Main category: cs.RO

TL;DR: Avi是一个新颖的3D视觉-语言-动作（VLA）架构，将机器人动作生成重新定义为3D感知和空间推理问题，而不是低级策略学习。它利用3D点云和语言理解来计算动作，而不是像现有的VLA模型那样在2D图像上进行端到端的任务特定策略学习。Avi不依赖于之前的动作，而是利用3D多模态大语言模型（MLLM）生成下一个点云，并通过经典变换显式计算动作，从而实现可泛化的行为，并能应对遮挡、相机姿态变化和视角变化。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型主要处理2D视觉输入并在任务特定的动作策略上进行端到端训练。Avi旨在通过利用3D点云和语言理解来改进这一点，将机器人动作生成视为3D感知和空间推理问题，而不是低级策略学习。

Method: Avi利用3D点云和语言理解来计算动作，通过经典几何变换生成机器人动作。它不依赖于之前的动作，而是利用3D多模态大语言模型（MLLM）来生成下一个点云，并通过经典变换显式计算动作。

Result: Avi在处理遮挡、相机姿态变化和视角变化方面表现出可泛化的行为。初步结果表明，3D视觉-语言推理可以作为可扩展、鲁棒的机器人系统的基础。

Conclusion: Avi通过将机器人决策过程视为在3D表示上的结构化推理任务，弥合了高级语言指令和低级驱动之间的差距，而无需进行不透明的策略学习。3D视觉-语言推理有潜力成为可扩展、鲁棒机器人系统的基础。

Abstract: We propose Avi, a novel 3D Vision-Language-Action (VLA) architecture that
reframes robotic action generation as a problem of 3D perception and spatial
reasoning, rather than low-level policy learning. While existing VLA models
primarily operate on 2D visual inputs and are trained end-to-end on
task-specific action policies, Avi leverages 3D point clouds and
language-grounded scene understanding to compute actions through classical
geometric transformations. Most notably, Avi does not train on previous action
tokens, rather, we build upon a 3D Multi-modal Large Language Model (MLLM) to
generate the next point cloud and explicitly calculate the actions through
classical transformations. This approach enables generalizable behaviors that
are robust to occlusions, camera pose variations, and changes in viewpoint. By
treating the robotic decision-making process as a structured reasoning task
over 3D representations, Avi bridges the gap between high-level language
instructions and low-level actuation without requiring opaque policy learning.
Our preliminary results highlight the potential of 3D vision-language reasoning
as a foundation for scalable, robust robotic systems. Check it out at
https://avi-3drobot.github.io/.

</details>


### [445] [Real-time Mixed-Integer Quadratic Programming for Driving Behavior-Inspired Speed Bump Optimal Trajectory Planning](https://arxiv.org/abs/2510.21751)
*Van Nam Dinh,Van Vy Phan,Thai Son Dang,Van Du Phan,The Anh Mai,Van Chuong Le,Sy Phuong Ho,Dinh Tu Duong,Hung Cuong Ta*

Main category: cs.RO

TL;DR: 提出了一种在混合整数二次规划（MIQP）框架下为自动驾驶汽车（AVs）规划轨迹的新方法，以应对在城市道路上平稳通过减速带的挑战。


<details>
  <summary>Details</summary>
Motivation: 解决在自动驾驶汽车的轨迹规划中，如何在一个统一的混合整数二次规划（MIQP）框架内处理减速带的复杂问题，并优化乘客舒适度。

Method: 利用模型预测控制（MPC）来制定轨迹，将模仿人类驾驶行为的减速带处理约束与更广泛的道路导航需求相结合。

Result: 通过在各种城市驾驶环境中进行的大量模拟，证明了该方法能够确保在通过减速带时实现平稳的速度转换，并保持适合实时部署的计算效率。

Conclusion: 该方法能够同时处理静态道路特征、动态约束以及专家级人类驾驶行为，代表了城市轨迹规划领域的重大进步。

Abstract: This paper proposes a novel methodology for trajectory planning in autonomous
vehicles (AVs), addressing the complex challenge of negotiating speed bumps
within a unified Mixed-Integer Quadratic Programming (MIQP) framework. By
leveraging Model Predictive Control (MPC), we develop trajectories that
optimize both the traversal of speed bumps and overall passenger comfort. A key
contribution of this work is the formulation of speed bump handling constraints
that closely emulate human driving behavior, seamlessly integrating these with
broader road navigation requirements. Through extensive simulations in varied
urban driving environments, we demonstrate the efficacy of our approach,
highlighting its ability to ensure smooth speed transitions over speed bumps
while maintaining computational efficiency suitable for real-time deployment.
The method's capability to handle both static road features and dynamic
constraints, alongside expert human driving, represents a significant step
forward in trajectory planning for urban

</details>


### [446] [Taxonomy and Trends in Reinforcement Learning for Robotics and Control Systems: A Structured Review](https://arxiv.org/abs/2510.21758)
*Kumater Ter,RexCharles Donatus,Ore-Ofe Ajayi,Daniel Udekwe*

Main category: cs.RO

TL;DR: 该综述深入探讨了强化学习（RL）在机器人和控制系统中的应用，重点介绍了深度强化学习（DRL）算法及其在解决高维、连续控制任务中的潜力。


<details>
  <summary>Details</summary>
Motivation: 该工作旨在总结强化学习（RL）在机器人和控制系统中的原理、高级深度强化学习（DRL）算法及其集成应用，以连接理论进展与实际应用，并提供对RL在自主机器人系统中不断发展的角色的综合视角。

Method: 该工作首先介绍了马尔可夫决策过程（MDPs）的形式化，概述了智能体-环境交互的基本要素，并探讨了核心算法策略，如Actor-Critic方法、基于价值的学习和策略梯度。随后，重点介绍了DDPG、TD3、PPO和SAC等现代DRL技术，并引入了一个结构化分类体系，用于对RL在运动、操纵、多智能体协调和人机交互等领域的应用进行分类，同时还讨论了训练方法和部署就绪水平。

Result: 该综述对RL原理、高级DRL算法及其在机器人和控制系统中的集成进行了深入回顾。它对RL在运动、操纵、多智能体协调和人机交互等领域的应用进行了分类，并讨论了训练方法和部署就绪水平。该综述综合了近期的研究成果，强调了技术趋势、设计模式以及RL在实际机器人技术中的日益成熟。

Conclusion: 总的来说，该工作为理解RL在自主机器人系统中的作用提供了一个综合的视角，连接了理论进展与实际应用。

Abstract: Reinforcement learning (RL) has become a foundational approach for enabling
intelligent robotic behavior in dynamic and uncertain environments. This work
presents an in-depth review of RL principles, advanced deep reinforcement
learning (DRL) algorithms, and their integration into robotic and control
systems. Beginning with the formalism of Markov Decision Processes (MDPs), the
study outlines essential elements of the agent-environment interaction and
explores core algorithmic strategies including actor-critic methods,
value-based learning, and policy gradients. Emphasis is placed on modern DRL
techniques such as DDPG, TD3, PPO, and SAC, which have shown promise in solving
high-dimensional, continuous control tasks. A structured taxonomy is introduced
to categorize RL applications across domains such as locomotion, manipulation,
multi-agent coordination, and human-robot interaction, along with training
methodologies and deployment readiness levels. The review synthesizes recent
research efforts, highlighting technical trends, design patterns, and the
growing maturity of RL in real-world robotics. Overall, this work aims to
bridge theoretical advances with practical implementations, providing a
consolidated perspective on the evolving role of RL in autonomous robotic
systems.

</details>


### [447] [J-ORA: A Framework and Multimodal Dataset for Japanese Object Identification, Reference, Action Prediction in Robot Perception](https://arxiv.org/abs/2510.21761)
*Jesse Atuhurra,Hidetaka Kamigaito,Taro Watanabe,Koichiro Yoshino*

Main category: cs.RO

TL;DR: J-ORA是一个包含日本语对话场景的、带有详细物体属性标注的多模态数据集，用于提升机器人感知能力，特别是在物体识别、指代消解和下一步动作预测方面。实验表明，详细的物体属性能够显著提高视觉语言模型（VLMs）的性能，但也揭示了专有模型和开源模型之间的性能差距，以及模型在理解物体功能和上下文关系方面的差异。


<details>
  <summary>Details</summary>
Motivation: 现有机器人感知研究缺乏包含详细物体属性标注的多模态数据集，特别是在日语对话场景下。

Method: 创建了一个名为J-ORA的多模态数据集，包含详细的物体属性（如类别、颜色、形状、大小、材质和空间关系）标注，并应用于日语人机对话场景。利用该数据集评估了不同视觉语言模型（VLMs）在物体识别、指代消解和下一步动作预测任务上的表现。

Result: 在包含物体属性时，VLMs在多模态感知任务上的表现得到显著提升。专有模型和开源模型之间仍存在性能差距。不同VLMs在理解物体功能和上下文关系方面表现各异。

Conclusion: 丰富的、上下文敏感的属性标注对于提升机器人在动态环境中的感知能力至关重要。

Abstract: We introduce J-ORA, a novel multimodal dataset that bridges the gap in robot
perception by providing detailed object attribute annotations within Japanese
human-robot dialogue scenarios. J-ORA is designed to support three critical
perception tasks, object identification, reference resolution, and next-action
prediction, by leveraging a comprehensive template of attributes (e.g.,
category, color, shape, size, material, and spatial relations). Extensive
evaluations with both proprietary and open-source Vision Language Models (VLMs)
reveal that incorporating detailed object attributes substantially improves
multimodal perception performance compared to without object attributes.
Despite the improvement, we find that there still exists a gap between
proprietary and open-source VLMs. In addition, our analysis of object
affordances demonstrates varying abilities in understanding object
functionality and contextual relationships across different VLMs. These
findings underscore the importance of rich, context-sensitive attribute
annotations in advancing robot perception in dynamic environments. See project
page at https://jatuhurrra.github.io/J-ORA/.

</details>


### [448] [Improving the performance of AI-powered Affordable Robotics for Assistive Tasks](https://arxiv.org/abs/2510.21771)
*Dharunish Yugeswardeenoo*

Main category: cs.RO

TL;DR: 全球看护需求巨大，现有机器人昂贵且需要专业知识，本研究提出了一种低成本、易于使用的仿人机器人，通过模仿学习视频完成喂食、清理、取药等任务，准确率超90%。


<details>
  <summary>Details</summary>
Motivation: 到2050年，全球辅助照护需求将达到35亿人，远超人力护工的供给能力。现有机器人方案成本高昂且需要专业技术知识，限制了其可及性。

Method: 本研究引入了一个低成本机器人手臂，用于执行喂食、清理溢出物和取药等辅助任务。该系统利用模仿学习自演示视频，无需进行特定任务编程或手动标注。机器人由六个伺服电机、双摄像头和3D打印的夹爪组成。通过与主导手臂进行远程操作收集数据，在三个任务中共获得50,000个视频帧。研究人员提出了一种新颖的Phased Action Chunking Transformer (PACT)来捕捉时间依赖性并分割运动动力学，同时采用Temporal Ensemble (TE)方法优化轨迹，以提高准确性和平滑度。

Result: 该系统在五个模型尺寸和四种架构上进行了评估，并进行了十小时的真实世界测试，实现了超过90%的任务准确率，比基线模型高出40%。PACT模型使模型尺寸减小了5倍，同时保持了75%的准确率。显著性分析表明，系统依赖于关键的视觉线索，并且相位令牌梯度在轨迹的关键时刻达到峰值，表明其有效的时间推理能力。

Conclusion: 本研究提出的低成本机器人手臂通过模仿学习，有效解决了日益增长的辅助照护需求与人力短缺的矛盾，展现了高准确性和效率，并具备进一步扩展应用的可能性。未来的工作将探索双臂操作和移动性，以增强其辅助能力。

Abstract: By 2050, the global demand for assistive care is expected to reach 3.5
billion people, far outpacing the availability of human caregivers. Existing
robotic solutions remain expensive and require technical expertise, limiting
accessibility. This work introduces a low-cost robotic arm for assistive tasks
such as feeding, cleaning spills, and fetching medicine. The system uses
imitation learning from demonstration videos, requiring no task-specific
programming or manual labeling. The robot consists of six servo motors, dual
cameras, and 3D-printed grippers. Data collection via teleoperation with a
leader arm yielded 50,000 video frames across the three tasks. A novel Phased
Action Chunking Transformer (PACT) captures temporal dependencies and segments
motion dynamics, while a Temporal Ensemble (TE) method refines trajectories to
improve accuracy and smoothness. Evaluated across five model sizes and four
architectures, with ten hours of real-world testing, the system achieved over
90% task accuracy, up to 40% higher than baselines. PACT enabled a 5x model
size reduction while maintaining 75% accuracy. Saliency analysis showed
reliance on key visual cues, and phase token gradients peaked at critical
trajectory moments, indicating effective temporal reasoning. Future work will
explore bimanual manipulation and mobility for expanded assistive capabilities.

</details>


### [449] [SPIRAL: Self-Play Incremental Racing Algorithm for Learning in Multi-Drone Competitions](https://arxiv.org/abs/2510.22568)
*Onur Akgün*

Main category: cs.RO

TL;DR: SPIRAL是一种用于训练自主无人机进行多人赛车比赛的新方法，通过自我对弈机制逐步培养复杂的赛车行为。


<details>
  <summary>Details</summary>
Motivation: 训练自主无人机在多人赛车比赛中掌握复杂的赛车行为和策略。

Method: 使用自我对弈机制，让无人机不断与更强大的自身版本竞争，逐步提高难度，从基本的飞行控制到复杂的合作策略。

Result: 在模拟中证明了SPIRAL的优势，并为不同的深度强化学习算法提供了基准测试。

Conclusion: SPIRAL是一个多功能、可扩展且能够自我改进的学习框架，为开发鲁棒和自适应的赛车策略开辟了新途径。

Abstract: This paper introduces SPIRAL (Self-Play Incremental Racing Algorithm for
Learning), a novel approach for training autonomous drones in multi-agent
racing competitions. SPIRAL distinctively employs a self-play mechanism to
incrementally cultivate complex racing behaviors within a challenging, dynamic
environment. Through this self-play core, drones continuously compete against
increasingly proficient versions of themselves, naturally escalating the
difficulty of competitive interactions. This progressive learning journey
guides agents from mastering fundamental flight control to executing
sophisticated cooperative multi-drone racing strategies. Our method is designed
for versatility, allowing integration with any state-of-the-art Deep
Reinforcement Learning (DRL) algorithms within its self-play framework.
Simulations demonstrate the significant advantages of SPIRAL and benchmark the
performance of various DRL algorithms operating within it. Consequently, we
contribute a versatile, scalable, and self-improving learning framework to the
field of autonomous drone racing. SPIRAL's capacity to autonomously generate
appropriate and escalating challenges through its self-play dynamic offers a
promising direction for developing robust and adaptive racing strategies in
multi-agent environments. This research opens new avenues for enhancing the
performance and reliability of autonomous racing drones in increasingly complex
and competitive scenarios.

</details>


### [450] [Real-Time QP Solvers: A Concise Review and Practical Guide Towards Legged Robots](https://arxiv.org/abs/2510.21773)
*Van Nam Dinh*

Main category: cs.RO

TL;DR: 该论文对机器人领域的二次规划（QP）求解器进行了全面的分析和基准测试，特别关注了其在机器人行走和操作中的应用。研究者们对多种先进的QP求解器进行了分类、评估和比较，旨在为在计算和时间限制下优化机器人运动提供实践指导。


<details>
  <summary>Details</summary>
Motivation: 二次规划（QP）是机器人实时运行（如状态估计、运动规划、控制）的关键，尤其是在机器人行走和操作等领域，但其对计算资源有较高要求。因此，需要对现有的QP求解器进行分析和评估，以满足嵌入式平台在时间和计算能力上的限制。

Method: 论文首先建立了标准的凸二次规划模型，并将求解器分为四类：内点法（IPM）、活跃集法（AS）、算子分裂法（OS）和增广拉格朗日法（AL）。接着，对每种方法进行了算法结构、计算特性、问题结构利用和热启动能力方面的分析。最后，使用公开的基准测试集，从计算时间、约束满足度和鲁棒性等方面评估了求解器的性能。

Result: 研究通过特征表和比较，为求解器的选择提供了实际指导，突出了速度、精度和能效之间的权衡。论文特别指出，对于长时域的MPC，稀疏内点法效果显著；对于高频的WBC，稠密活跃集法更为适用。同时，也提到了向非凸和分布式QP的扩展。

Conclusion: 论文强调了求解器、任务和硬件之间的协同作用对于实现敏捷、自主的机器人系统的关键性。研究结果为在资源受限的平台上选择合适的QP求解器提供了宝贵的见解，并指出了未来在非凸和分布式QP领域的研究方向。

Abstract: Quadratic programming (QP) underpins real-time robotics by enabling
efficient, constrained optimization in state estimation, motion planning, and
control. In legged locomotion and manipulation, essential modules like inverse
dynamics, Model Predictive Control (MPC), and Whole-Body Control (WBC) are
inherently QP-based, demanding reliable solutions amid tight timing, energy,
and computational limits on embedded platforms. This paper presents a
comprehensive analysis and benchmarking study of cutting-edge QP solvers for
legged robotics. We begin by formulating the standard convex QP and classify
solvers into four principal algorithmic approaches, including interior-point
methods, active-set strategies, operator splitting schemes, and augmented
Lagrangian approaches. Each solver is examined in terms of algorithmic
structure, computational characteristics, and its ability to exploit problem
structure and warm-starting. Performance is evaluated using publicly available
benchmarks, focusing on metrics such as computation time, constraint
satisfaction, and robustness under perturbations. Feature tables and
comparisons yield practical guidance for solver selection, underscoring
trade-offs in speed, accuracy, and energy efficiency. Our findings emphasize
the synergy between solver, task, and hardware, sparse IPMs for long-horizon
MPC, and dense active-set for high frequency WBC to advance agile, autonomous
legged systems, with emerging extensions to nonconvex and distributed QP.

</details>


### [451] [Curriculum-Based Iterative Self-Play for Scalable Multi-Drone Racing](https://arxiv.org/abs/2510.22570)
*Onur Akgün*

Main category: cs.RO

TL;DR: CRUISE是一个用于多旋翼无人机竞速的强化学习框架，通过结合课程学习和自我对弈，显著提高了性能和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 在高速、竞争环境中协调多个自主代理是一个重大的工程挑战，尤其是在多旋翼无人机竞速领域。

Method: CRUISE框架结合了渐进式难度课程和高效的自我对弈机制，以培养强大的竞争行为。该框架在具有真实四旋翼动力学的模拟环境中进行了验证。

Result: CRUISE策略的性能显著优于标准的强化学习基线和先进的博弈论规划器，平均竞速速度接近规划器的两倍，成功率高，并且在代理密度增加时表现出良好的可扩展性。消融研究表明，课程结构是性能提升的关键。

Conclusion: CRUISE提供了一种可扩展且有效的训练方法，推动了动态、竞争性任务的自主系统发展，并为未来的实际部署提供了蓝图。

Abstract: The coordination of multiple autonomous agents in high-speed, competitive
environments represents a significant engineering challenge. This paper
presents CRUISE (Curriculum-Based Iterative Self-Play for Scalable Multi-Drone
Racing), a reinforcement learning framework designed to solve this challenge in
the demanding domain of multi-drone racing. CRUISE overcomes key scalability
limitations by synergistically combining a progressive difficulty curriculum
with an efficient self-play mechanism to foster robust competitive behaviors.
Validated in high-fidelity simulation with realistic quadrotor dynamics, the
resulting policies significantly outperform both a standard reinforcement
learning baseline and a state-of-the-art game-theoretic planner. CRUISE
achieves nearly double the planner's mean racing speed, maintains high success
rates, and demonstrates robust scalability as agent density increases. Ablation
studies confirm that the curriculum structure is the critical component for
this performance leap. By providing a scalable and effective training
methodology, CRUISE advances the development of autonomous systems for dynamic,
competitive tasks and serves as a blueprint for future real-world deployment.

</details>


### [452] [VITA-E: Natural Embodied Interaction with Concurrent Seeing, Hearing, Speaking, and Acting](https://arxiv.org/abs/2510.21817)
*Xiaoyu Liu,Chaoyou Fu,Chi Yan,Chu Wu,Haihan Gao,Yi-Fan Zhang,Shaoqi Dong,Cheng Qian,Bin Luo,Xiuyong Yang,Guanwu Li,Yusheng Cai,Yunhang Shen,Deqiang Jiang,Haoyu Cao,Xing Sun,Caifeng Shan,Ran He*

Main category: cs.RO

TL;DR: VITA-E是一个新的具身交互框架，通过双模型架构实现行为并发和实时中断处理，解决了现有VLA模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有视语言动作（VLA）模型交互模式僵化，无法同时处理视觉、听觉、语音和动作，也无法动态处理实时用户中断，阻碍了无缝的具身协作，导致用户体验不灵活且无响应。

Method: 提出VITA-E框架，采用双模型架构（“活动模型”和“待命模型”），使具身智能体能够并发和可中断地观察环境、听取用户语音、提供语音响应和执行动作。通过“模型即控制器”范式，微调VLM以生成特殊令牌作为系统级命令，将模型推理与系统行为耦合。

Result: 在物理人形平台上进行实验，VITA-E能可靠地处理复杂交互场景。该框架兼容各种双系统VLA模型，在紧急停止和语音中断方面成功率极高，并能成功执行并发语音和动作。

Conclusion: VITA-E是实现更自然、更强大的具身助手的重大进步。

Abstract: Current Vision-Language-Action (VLA) models are often constrained by a rigid,
static interaction paradigm, which lacks the ability to see, hear, speak, and
act concurrently as well as handle real-time user interruptions dynamically.
This hinders seamless embodied collaboration, resulting in an inflexible and
unresponsive user experience. To address these limitations, we introduce
VITA-E, a novel embodied interaction framework designed for both behavioral
concurrency and nearly real-time interruption. The core of our approach is a
dual-model architecture where two parallel VLA instances operate as an ``Active
Model'' and a ``Standby Model'', allowing the embodied agent to observe its
environment, listen to user speech, provide verbal responses, and execute
actions, all concurrently and interruptibly, mimicking human-like multitasking
capabilities. We further propose a ``model-as-controller'' paradigm, where we
fine-tune the VLM to generate special tokens that serve as direct system-level
commands, coupling the model's reasoning with the system's behavior.
Experiments conducted on a physical humanoid platform demonstrate that VITA-E
can reliably handle complex interactive scenarios. Our framework is compatible
with various dual-system VLA models, achieving an extremely high success rate
on emergency stops and speech interruptions while also successfully performing
concurrent speech and action. This represents a significant step towards more
natural and capable embodied assistants.

</details>


### [453] [A Literature Review On Stewart-Gough Platform Calibrations A Literature Review On Stewart-Gough Platform Calibrations](https://arxiv.org/abs/2510.21854)
*Sourabh Karmakar,Cameron J. Turner*

Main category: cs.RO

TL;DR: Stewart-Gough平台（六足机器人）因其精密的控制特性而被广泛研究，在医疗、工程、太空、芯片制造、汽车制造等领域具有潜力。其微纳级三维运动控制能力使其成为精确、复杂和可重复运动的理想选择。为了满足应用精度要求，平台校准至关重要。本文着重回顾了基于逆运动学的六足机器人校准方法，讨论了不同的校准技术、实验方法（如使用外部仪器、限制运动、额外传感器）以及它们的结果和细节。


<details>
  <summary>Details</summary>
Motivation: Stewart-Gough平台在微纳级三维运动控制方面具有重要应用价值，但为了满足高精度应用需求，其校准至关重要。现有研究中，基于逆运动学的校准方法比基于正向运动学的方法更易于实现。

Method: 通过调研和分析现有的Stewart-Gough平台校准方法，重点关注基于逆运动学的校准技术，总结了不同的校准方法、实验设置（如外部仪器、运动约束、额外传感器）以及它们在提高平台位置和姿态精度方面的效果。研究还考虑了运动学、结构学以及环境因素对校准的影响，并指出了部分校准在无负载条件下进行。

Result: 研究发现，研究人员主要关注通过考虑单一或多重误差源（运动学、结构学、环境因素）来提高Stewart-Gough平台的定位和姿态精度。许多校准方法是在无负载条件下进行的。

Conclusion: 本研究旨在全面回顾Stewart-Gough平台校准的最新进展，重点介绍了校准过程中考虑的关键流程和误差因素，为该领域的研究提供了参考。

Abstract: Researchers have studied Stewart-Gough platforms, also known as Gough-Stewart
platforms or hexapod platforms extensively for their inherent fine control
characteristics. Their studies led to the potential deployment opportunities of
Stewart-Gough Platforms in many critical applications such as the medical
field, engineering machines, space research, electronic chip manufacturing,
automobile manufacturing, etc. Some of these applications need micro and
nano-level movement control in 3D space for the motions to be precise,
complicated, and repeatable; a Stewart-Gough platform fulfills these challenges
smartly. For this, the platform must be more accurate than the specified
application accuracy level and thus proper calibration for a parallel robot is
crucial. Forward kinematics-based calibration for these hexapod machines
becomes unnecessarily complex and inverse kinematics complete this task with
much ease. To experiment with different calibration techniques, various
calibration approaches were implemented by using external instruments,
constraining one or more motions of the system, and using extra sensors for
auto or self-calibration. This survey paid attention to those key
methodologies, their outcome, and important details related to inverse
kinematic-based parallel robot calibrations. It was observed during this study
that the researchers focused on improving the accuracy of the platform position
and orientation considering the errors contributed by one source or multiple
sources. The error sources considered are mainly kinematic and structural, in
some cases, environmental factors also are reviewed, however, those
calibrations are done under no-load conditions. This study aims to review the
present state of the art in this field and highlight the processes and errors
considered for the calibration of Stewart-Gough platforms.

</details>


### [454] [Butter-Bench: Evaluating LLM Controlled Robots for Practical Intelligence](https://arxiv.org/abs/2510.21860)
*Callum Sharrock,Lukas Petersson,Hanna Petersson,Axel Backlund,Axel Wennström,Kristoffer Nordström,Elias Aronsson*

Main category: cs.RO

TL;DR: Butter-Bench是一个评估大型语言模型（LLM）控制的机器人在实际智能方面的基准，实际智能被定义为在混乱的物理世界中导航的能力。我们发现，尽管LLM在分析智能方面超越了人类，但在Butter-Bench上，人类的表现仍然优于LLM。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在机器人实际智能方面的能力，特别是他们在处理物理世界混乱方面的能力。

Method: Butter-Bench评估LLM部分，不考虑VLA模型。评估了在体现实体推理方面进行微调的LLM。

Result: 在Butter-Bench上，最佳LLM得分为40%，而人类平均得分为95%。LLM在多步空间规划和社交理解方面遇到困难。微调对LLM在Butter-Bench上的得分没有提高。

Conclusion: 目前，尽管LLM在分析智能方面表现出色，但在实际的机器人任务中，人类仍然比LLM更胜一筹。

Abstract: We present Butter-Bench, a benchmark evaluating large language model (LLM)
controlled robots for practical intelligence, defined as the ability to
navigate the messiness of the physical world. Current state-of-the-art robotic
systems use a hierarchical architecture with LLMs in charge of high-level
reasoning, and a Vision Language Action (VLA) model for low-level control.
Butter-Bench evaluates the LLM part in isolation from the VLA. Although LLMs
have repeatedly surpassed humans in evaluations requiring analytical
intelligence, we find humans still outperform LLMs on Butter-Bench. The best
LLMs score 40% on Butter-Bench, while the mean human score is 95%. LLMs
struggled the most with multi-step spatial planning and social understanding.
We also evaluate LLMs that are fine-tuned for embodied reasoning and conclude
that this training does not improve their score on Butter-Bench.

</details>


### [455] [Policies over Poses: Reinforcement Learning based Distributed Pose-Graph Optimization for Multi-Robot SLAM](https://arxiv.org/abs/2510.22740)
*Sai Krishna Ghanta,Ramviyas Parasuraman*

Main category: cs.RO

TL;DR: 该研究提出了一种基于多智能体强化学习（MARL）的分布式平面姿态图优化（PGO）框架，用于提高多机器人SLAM的轨迹估计精度。


<details>
  <summary>Details</summary>
Motivation: 传统迭代方法在解决高度非凸的PGO问题时，常收敛到局部最小值，导致次优估计。

Method: 提出了一种基于MARL的框架，将PGO视为局部姿态图上的部分可观察马尔可夫博弈。每个机器人使用图神经网络（GNN）和自适应门控来处理局部姿态图，并通过混合策略逐步优化姿态估计。最后，通过共识机制协调机器人间的分歧，实现全局一致性。

Result: 与现有的分布式PGO框架相比，该MARL方法将全局目标平均减少了37.5%，并将推理效率提高了至少6倍。此外，该方法能够通过复制策略轻松扩展到更大的机器人团队，而无需重新训练。

Conclusion: 基于MARL的分布式PGO框架在提高精度和效率方面优于现有方法，并具有良好的可扩展性。

Abstract: We consider the distributed pose-graph optimization (PGO) problem, which is
fundamental in accurate trajectory estimation in multi-robot simultaneous
localization and mapping (SLAM). Conventional iterative approaches linearize a
highly non-convex optimization objective, requiring repeated solving of normal
equations, which often converge to local minima and thus produce suboptimal
estimates. We propose a scalable, outlier-robust distributed planar PGO
framework using Multi-Agent Reinforcement Learning (MARL). We cast distributed
PGO as a partially observable Markov game defined on local pose-graphs, where
each action refines a single edge's pose estimate. A graph partitioner
decomposes the global pose graph, and each robot runs a recurrent
edge-conditioned Graph Neural Network (GNN) encoder with adaptive edge-gating
to denoise noisy edges. Robots sequentially refine poses through a hybrid
policy that utilizes prior action memory and graph embeddings. After local
graph correction, a consensus scheme reconciles inter-robot disagreements to
produce a globally consistent estimate. Our extensive evaluations on a
comprehensive suite of synthetic and real-world datasets demonstrate that our
learned MARL-based actors reduce the global objective by an average of 37.5%
more than the state-of-the-art distributed PGO framework, while enhancing
inference efficiency by at least 6X. We also demonstrate that actor replication
allows a single learned policy to scale effortlessly to substantially larger
robot teams without any retraining. Code is publicly available at
https://github.com/herolab-uga/policies-over-poses.

</details>


### [456] [A Physics-Informed Neural Network Approach for UAV Path Planning in Dynamic Environments](https://arxiv.org/abs/2510.21874)
*Shuning Zhang*

Main category: cs.RO

TL;DR: PINN框架用于无人机轨迹优化，无需监督数据，可生成安全高效的轨迹，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 无人机在动态风场中运行时，需要规划安全且节能的轨迹，但传统方法存在不足。

Method: 提出一种物理信息神经网络（PINN）框架，将无人机动力学、风场干扰和避障融入学习过程，通过最小化物理残差和风险目标来学习轨迹。

Result: 与A*和Kino-RRT*相比，该方法在控制能耗、平滑度和安全性方面表现更优，飞行效率相似。

Conclusion: 物理信息学习有潜力统一基于模型和数据驱动的规划，为无人机轨迹优化提供可扩展且物理一致的框架。

Abstract: Unmanned aerial vehicles (UAVs) operating in dynamic wind fields must
generate safe and energy-efficient trajectories under physical and
environmental constraints. Traditional planners, such as A* and kinodynamic
RRT*, often yield suboptimal or non-smooth paths due to discretization and
sampling limitations. This paper presents a physics-informed neural network
(PINN) framework that embeds UAV dynamics, wind disturbances, and obstacle
avoidance directly into the learning process. Without requiring supervised
data, the PINN learns dynamically feasible and collision-free trajectories by
minimizing physical residuals and risk-aware objectives. Comparative
simulations show that the proposed method outperforms A* and Kino-RRT* in
control energy, smoothness, and safety margin, while maintaining similar flight
efficiency. The results highlight the potential of physics-informed learning to
unify model-based and data-driven planning, providing a scalable and physically
consistent framework for UAV trajectory optimization.

</details>


### [457] [Two-Steps Diffusion Policy for Robotic Manipulation via Genetic Denoising](https://arxiv.org/abs/2510.21991)
*Mateo Clemente,Leo Brunswic,Rui Heng Yang,Xuan Zhao,Yasser Khalil,Haoyu Lei,Amir Rasouli,Yinchuan Li*

Main category: cs.RO

TL;DR: 通过为具身AI任务定制去噪过程，扩散策略可以在更少的神经函数评估（NFE）下实现最先进的机器人操作性能。


<details>
  <summary>Details</summary>
Motivation: 许多扩散模型的推理策略被直接转移到控制领域而未经适应，而这些模型最初是为视觉任务开发的。本研究旨在调整扩散模型以适应具身AI任务的特点，特别是低维度的动作分布。

Method: 提出了一种基于种群的采样策略——遗传去噪，通过选择具有低分布外风险的去噪轨迹来增强性能和稳定性。

Result: 所提出的方法解决了具有挑战性的任务，仅需2次NFE，同时提高了或匹配了性能。在D4RL和Robomimic的14个机器人操作任务中进行了评估，在超过200万次的评估中，该方法在推理步数显著减少的情况下，持续优于标准的基于扩散的策略，性能提升高达20%。

Conclusion: 通过为具身AI任务定制去噪过程，扩散策略可以在更少的神经函数评估（NFE）下实现最先进的机器人操作性能，并且提出的遗传去噪方法在性能和稳定性方面都有所提升。

Abstract: Diffusion models, such as diffusion policy, have achieved state-of-the-art
results in robotic manipulation by imitating expert demonstrations. While
diffusion models were originally developed for vision tasks like image and
video generation, many of their inference strategies have been directly
transferred to control domains without adaptation. In this work, we show that
by tailoring the denoising process to the specific characteristics of embodied
AI tasks -- particularly structured, low-dimensional nature of action
distributions -- diffusion policies can operate effectively with as few as 5
neural function evaluations (NFE).
  Building on this insight, we propose a population-based sampling strategy,
genetic denoising, which enhances both performance and stability by selecting
denoising trajectories with low out-of-distribution risk. Our method solves
challenging tasks with only 2 NFE while improving or matching performance. We
evaluate our approach across 14 robotic manipulation tasks from D4RL and
Robomimic, spanning multiple action horizons and inference budgets. In over 2
million evaluations, our method consistently outperforms standard
diffusion-based policies, achieving up to 20\% performance gains with
significantly fewer inference steps.

</details>


### [458] [Estimation of Minimum Stride Frequency for the Frontal Plane Stability of Bipedal Systems](https://arxiv.org/abs/2510.22030)
*Harsha Karunanayaka,Siavash Rezazadeh*

Main category: cs.RO

TL;DR: 步态控制中的足式稳定性的研究。


<details>
  <summary>Details</summary>
Motivation: 目前对于质量、刚度、腿长和髋部宽度等关键参数如何影响稳定性以及维持稳定性所需的最小步频知之甚少，本研究旨在解决这些问题。

Method: 通过分析单个模型参数和系统固有频率如何影响维持稳定周期所需的最小步频，并提出预测最小步频的方法，然后将预测的步频与随机生成模型的实际值进行比较。

Result: 研究结果表明，可以通过调整步长时间、利用前馈腿部收缩和伸展来实现无反馈控制的稳定振荡，并能有效降低控制工作量和能量消耗，提高运动鲁棒性。

Conclusion: 本研究深入理解了额状面稳定性机制，以及如何利用前馈稳定性来降低控制工作量。

Abstract: Stability of bipedal systems in frontal plane is affected by the hip offset,
to the extent that adjusting stride time using feedforward retraction and
extension of the legs can lead to stable oscillations without feedback control.
This feedforward stabilization can be leveraged to reduce the control effort
and energy expenditure and increase the locomotion robustness. However, there
is limited understanding of how key parameters, such as mass, stiffness, leg
length, and hip width, affect stability and the minimum stride frequency needed
to maintain it. This study aims to address these gaps through analyzing how
individual model parameters and the system's natural frequency influence the
minimum stride frequency required to maintain a stable cycle. We propose a
method to predict the minimum stride frequency, and compare the predicted
stride frequencies with actual values for randomly generated models. The
findings of this work provide a better understanding of the frontal plane
stability mechanisms and how feedforward stabilization can be leveraged to
reduce the control effort.

</details>


### [459] [RaycastGrasp: Eye-Gaze Interaction with Wearable Devices for Robotic Manipulation](https://arxiv.org/abs/2510.22113)
*Zitiantao Lin,Yongpeng Sang,Yang Ye*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Robotic manipulators are increasingly used to assist individuals with
mobility impairments in object retrieval. However, the predominant
joystick-based control interfaces can be challenging due to high precision
requirements and unintuitive reference frames. Recent advances in human-robot
interaction have explored alternative modalities, yet many solutions still rely
on external screens or restrictive control schemes, limiting their
intuitiveness and accessibility. To address these challenges, we present an
egocentric, gaze-guided robotic manipulation interface that leverages a
wearable Mixed Reality (MR) headset. Our system enables users to interact
seamlessly with real-world objects using natural gaze fixation from a
first-person perspective, while providing augmented visual cues to confirm
intent and leveraging a pretrained vision model and robotic arm for intent
recognition and object manipulation. Experimental results demonstrate that our
approach significantly improves manipulation accuracy, reduces system latency,
and achieves single-pass intention and object recognition accuracy greater than
88% across multiple real-world scenarios. These results demonstrate the
system's effectiveness in enhancing intuitiveness and accessibility,
underscoring its practical significance for assistive robotics applications.

</details>


### [460] [EasyUUV: An LLM-Enhanced Universal and Lightweight Sim-to-Real Reinforcement Learning Framework for UUV Attitude Control](https://arxiv.org/abs/2510.22126)
*Guanwen Xie,Jingzehua Xu,Jiwei Tang,Yubo Huang,Shuai Zhang,Xiaofan Li*

Main category: cs.RO

TL;DR: EasyUUV是一个利用大型语言模型（LLM）增强的UUV姿态控制强化学习（RL）框架，通过并行RL训练和混合控制架构实现鲁棒性和自适应控制，并在低成本UUV平台上得到验证。


<details>
  <summary>Details</summary>
Motivation: 现有UUV姿态控制方法在泛化性、鲁棒性以及实际部署方面存在挑战。

Method: EasyUUV结合了并行RL训练和混合控制架构，其中学习策略输出由自适应S-Surface控制器执行的高层姿态修正。该框架集成了多模态LLM，利用视觉和文本反馈自适应地调整控制器参数，实现无需训练的自适应。

Result: 在广泛的仿真和真实世界实验中，EasyUUV在各种水下条件下实现了有效的UUV姿态鲁棒和自适应控制。

Conclusion: EasyUUV框架在UUV姿态控制方面表现出优越的性能和鲁棒性，并能有效适应各种水下条件。

Abstract: Despite recent advances in Unmanned Underwater Vehicle (UUV) attitude
control, existing methods still struggle with generalizability, robustness to
real-world disturbances, and efficient deployment. To address the above
challenges, this paper presents EasyUUV, a Large Language Model (LLM)-enhanced,
universal, and lightweight simulation-to-reality reinforcement learning (RL)
framework for robust attitude control of UUVs. EasyUUV combines parallelized RL
training with a hybrid control architecture, where a learned policy outputs
high-level attitude corrections executed by an adaptive S-Surface controller. A
multimodal LLM is further integrated to adaptively tune controller parameters
at runtime using visual and textual feedback, enabling training-free adaptation
to unmodeled dynamics. Also, we have developed a low-cost 6-DoF UUV platform
and applied an RL policy trained through efficient parallelized simulation.
Extensive simulation and real-world experiments validate the effectiveness and
outstanding performance of EasyUUV in achieving robust and adaptive UUV
attitude control across diverse underwater conditions. The source code is
available from the following website: https://360zmem.github.io/easyuuv/

</details>


### [461] [LT-Exosense: A Vision-centric Multi-session Mapping System for Lifelong Safe Navigation of Exoskeletons](https://arxiv.org/abs/2510.22164)
*Jianeng Wang,Matias Mattamala,Christina Kassab,Nived Chebrolu,Guillaume Burger,Fabio Elnecave,Marine Petriaux,Maurice Fallon*

Main category: cs.RO

TL;DR: LT-Exosense是一个用于外骨骼机器人的多会话、视觉优先的建图系统，通过融合多会话空间信息、检测环境变化和更新全局地图，实现智能路径规划，以适应动态变化的室内环境。


<details>
  <summary>Details</summary>
Motivation: 为解决下肢残疾人士的移动问题，需要开发在变化环境中能可靠长期运行的自平衡外骨骼，其关键在于拥有一个有效的感知系统。

Method: LT-Exosense通过增量融合多会话间的空间知识，检测环境变化，并更新持久化的全局地图，实现了多会话地图的构建与融合，进而支持自适应路径规划。

Result: 在真实世界实验中，LT-Exosense构建的可扩展多会话地图与地面激光扫描的平均点对点误差低于5厘米，并展示了在动态变化室内环境中自适应路径规划的潜力。

Conclusion: LT-Exosense通过多会话建图和自适应路径规划，为下肢残疾人士提供了可靠的长期自主导航解决方案。

Abstract: Self-balancing exoskeletons offer a promising mobility solution for
individuals with lower-limb disabilities. For reliable long-term operation,
these exoskeletons require a perception system that is effective in changing
environments. In this work, we introduce LT-Exosense, a vision-centric,
multi-session mapping system designed to support long-term (semi)-autonomous
navigation for exoskeleton users. LT-Exosense extends single-session mapping
capabilities by incrementally fusing spatial knowledge across multiple
sessions, detecting environmental changes, and updating a persistent global
map. This representation enables intelligent path planning, which can adapt to
newly observed obstacles and can recover previous routes when obstructions are
removed. We validate LT-Exosense through several real-world experiments,
demonstrating a scalable multi-session map that achieves an average
point-to-point error below 5 cm when compared to ground-truth laser scans. We
also illustrate the potential application of adaptive path planning in
dynamically changing indoor environments.

</details>


### [462] [ACG: Action Coherence Guidance for Flow-based VLA models](https://arxiv.org/abs/2510.22201)
*Minho Park,Kinam Kim,Junha Hyung,Hyojin Jang,Hoiyeong Jin,Jooyeol Yun,Hojoon Lee,Jaegul Choo*

Main category: cs.RO

TL;DR: 通过引入“动作一致性引导”（ACG）训练算法，提高视觉-语言-动作（VLA）模型在机器人操作中的性能，解决模仿学习中因人类演示噪声导致动作不连贯的问题。


<details>
  <summary>Details</summary>
Motivation: 模仿学习训练的视觉-语言-动作（VLA）模型，虽然生成能力强，但对人类演示中的噪声（如痉挛、停顿、抖动）很敏感，导致动作不连贯，进而引发机器人部署过程中的不稳定和轨迹漂移，这在精细操作任务中是灾难性的。

Method: 提出一种名为“动作一致性引导”（ACG）的训练无关、测试时引导算法，以提高VLA模型的动作一致性。

Result: 在RoboCasa、DexMimicGen以及真实世界的SO-101任务上进行了评估，ACG算法一致性地提高了动作一致性，并显著提升了各种操作任务的成功率。

Conclusion: ACG算法能够有效提高VLA模型的动作一致性，从而在机器人操作任务中取得性能提升，尤其是在精细操作等对精度要求高的场景中。

Abstract: Diffusion and flow matching models have emerged as powerful robot policies,
enabling Vision-Language-Action (VLA) models to generalize across diverse
scenes and instructions. Yet, when trained via imitation learning, their high
generative capacity makes them sensitive to noise in human demonstrations:
jerks, pauses, and jitter which reduce action coherence. Reduced action
coherence causes instability and trajectory drift during deployment, failures
that are catastrophic in fine-grained manipulation where precision is crucial.
In this paper, we present Action Coherence Guidance (ACG) for VLA models, a
training-free test-time guidance algorithm that improves action coherence and
thereby yields performance gains. Evaluated on RoboCasa, DexMimicGen, and
real-world SO-101 tasks, ACG consistently improves action coherence and boosts
success rates across diverse manipulation tasks. Code and project page are
available at https://github.com/DAVIAN-Robotics/ACG and
https://DAVIAN-Robotics.github.io/ACG , respectively.

</details>


### [463] [Bridging Perception and Reasoning: Dual-Pipeline Neuro-Symbolic Landing for UAVs in Cluttered Environments](https://arxiv.org/abs/2510.22204)
*Weixian Qian,Sebastian Schroder,Yao Deng,Jiaohong Yao,Linfeng Liang,Xiao Cheng,Richard Han,Xi Zheng*

Main category: cs.RO

TL;DR: NeuroSymLand是一个结合了大型语言模型（LLM）和轻量级基础模型的神经符号框架，用于在非结构化环境中实现自主无人机着陆。


<details>
  <summary>Details</summary>
Motivation: 在非结构化环境中实现无人机自主着陆是核心需求，但纯视觉或深度学习模型在协变量偏移下表现不佳且可解释性有限。

Method: 通过LLM和人工干预生成Scallop代码，提取可验证的符号知识；在线阶段，使用紧凑的基础模型进行语义分割，生成概率性Scallop事实，构建语义场景图进行推理。

Result: NeuroSymLand结合了基础模型的感知能力和符号推理的可解释性与可验证性，通过几何例程计算节点属性和边关系，避免了数据依赖和延迟。生成的Scallop程序包含着陆原则，并提供校准的安全分数、感兴趣区域排名和可读的解释。

Conclusion: NeuroSymLand在准确性、鲁棒性和效率方面优于现有方法，提高了无人机在紧急响应、监视和交付任务中的安全性和可靠性。

Abstract: Autonomous landing in unstructured (cluttered, uneven, and map-poor)
environments is a core requirement for Unmanned Aerial Vehicles (UAVs), yet
purely vision-based or deep learning models often falter under covariate shift
and provide limited interpretability. We propose NeuroSymLand, a neuro-symbolic
framework that tightly couples two complementary pipelines: (i) an offline
pipeline, where Large Language Models (LLMs) and human-in-the-loop refinement
synthesize Scallop code from diverse landing scenarios, distilling
generalizable and verifiable symbolic knowledge; and (ii) an online pipeline,
where a compact foundation-based semantic segmentation model generates
probabilistic Scallop facts that are composed into semantic scene graphs for
real-time deductive reasoning. This design combines the perceptual strengths of
lightweight foundation models with the interpretability and verifiability of
symbolic reasoning. Node attributes (e.g., flatness, area) and edge relations
(adjacency, containment, proximity) are computed with geometric routines rather
than learned, avoiding the data dependence and latency of train-time graph
builders. The resulting Scallop program encodes landing principles (avoid water
and obstacles; prefer large, flat, accessible regions) and yields calibrated
safety scores with ranked Regions of Interest (ROIs) and human-readable
justifications. Extensive evaluations across datasets, diverse simulation maps,
and real UAV hardware show that NeuroSymLand achieves higher accuracy, stronger
robustness to covariate shift, and superior efficiency compared with
state-of-the-art baselines, while advancing UAV safety and reliability in
emergency response, surveillance, and delivery missions.

</details>


### [464] [Breaking the Static Assumption: A Dynamic-Aware LIO Framework Via Spatio-Temporal Normal Analysis](https://arxiv.org/abs/2510.22313)
*Chen Zhiqiang,Le Gentil Cedric,Lin Fuling,Lu Minghao,Qiao Qiyuan,Xu Bowen,Qi Yuhua,Lu Peng*

Main category: cs.RO

TL;DR: 该研究提出了一种新的动态感知激光雷达-惯性里程计（LIO）方法，用于解决传统LIO在动态环境中遇到的挑战。


<details>
  <summary>Details</summary>
Motivation: 传统LIO方法在动态环境中表现不佳，因为它们依赖静态世界假设，这在动态物体占主导地位的场景中尤其明显。然而，现有的动态LIO方法在区分动态物体和准确进行姿态估计之间存在相互依赖的难题。

Method: 提出了一种动态感知迭代最近点（ICP）算法，并结合了时空法线分析和空间一致性验证方法，以增强静态地图的构建。这种方法将动态感知直接整合到点云配准过程中，打破了现有方法的局限性。

Result: 在具有挑战性的动态环境中，该方法在稀疏几何结构的情况下，相比于最先进的LIO系统取得了显著的性能提升。

Conclusion: 该研究成功地提出了一种创新的动态感知LIO方法，解决了传统方法在动态环境下的不足，并通过实验验证了其优越性。

Abstract: This paper addresses the challenge of Lidar-Inertial Odometry (LIO) in
dynamic environments, where conventional methods often fail due to their
static-world assumptions. Traditional LIO algorithms perform poorly when
dynamic objects dominate the scenes, particularly in geometrically sparse
environments. Current approaches to dynamic LIO face a fundamental challenge:
accurate localization requires a reliable identification of static features,
yet distinguishing dynamic objects necessitates precise pose estimation. Our
solution breaks this circular dependency by integrating dynamic awareness
directly into the point cloud registration process. We introduce a novel
dynamic-aware iterative closest point algorithm that leverages spatio-temporal
normal analysis, complemented by an efficient spatial consistency verification
method to enhance static map construction. Experimental evaluations demonstrate
significant performance improvements over state-of-the-art LIO systems in
challenging dynamic environments with limited geometric structure. The code and
dataset are available at https://github.com/thisparticle/btsa.

</details>


### [465] [Toward Humanoid Brain-Body Co-design: Joint Optimization of Control and Morphology for Fall Recovery](https://arxiv.org/abs/2510.22336)
*Bo Yue,Sheng Xu,Kui Jia,Guiliang Liu*

Main category: cs.RO

TL;DR: RoboCraft是一个用于人形机器人跌倒恢复的脑体协同设计框架，通过联合优化控制策略和物理形态来提升性能。


<details>
  <summary>Details</summary>
Motivation: 人形机器人因其拟人形态，在人类工作空间中具有天然部署优势。实现这一潜力的关键在于脑体协同设计，即联合优化控制策略和物理形态。跌倒恢复能力至关重要，它能提高安全性、韧性，并与运动系统集成，从而提升人形机器人的自主性。

Method: 提出RoboCraft框架，通过控制策略和形态的耦合更新来迭代优化跌倒恢复性能。利用预训练的共享策略对高性能形态进行微调，实现高效适应。形态搜索结合了受人类启发的先验知识和优化算法，并引入优先缓冲区来平衡候选评估与新设计探索。

Result: 在七个公开的人形机器人上，RoboCraft实现了平均44.55%的性能提升。在协同设计四个机器人时，形态优化贡献了至少40%的改进。

Conclusion: RoboCraft框架通过协同设计显著提升了人形机器人的跌倒恢复能力，强调了形态优化在其中的关键作用。

Abstract: Humanoid robots represent a central frontier in embodied intelligence, as
their anthropomorphic form enables natural deployment in humans' workspace.
Brain-body co-design for humanoids presents a promising approach to realizing
this potential by jointly optimizing control policies and physical morphology.
Within this context, fall recovery emerges as a critical capability. It not
only enhances safety and resilience but also integrates naturally with
locomotion systems, thereby advancing the autonomy of humanoids. In this paper,
we propose RoboCraft, a scalable humanoid co-design framework for fall recovery
that iteratively improves performance through the coupled updates of control
policy and morphology. A shared policy pretrained across multiple designs is
progressively finetuned on high-performing morphologies, enabling efficient
adaptation without retraining from scratch. Concurrently, morphology search is
guided by human-inspired priors and optimization algorithms, supported by a
priority buffer that balances reevaluation of promising candidates with the
exploration of novel designs. Experiments show that \ourmethod{} achieves an
average performance gain of 44.55% on seven public humanoid robots, with
morphology optimization drives at least 40% of improvements in co-designing
four humanoid robots, underscoring the critical role of humanoid co-design.

</details>


### [466] [Estimating Continuum Robot Shape under External Loading using Spatiotemporal Neural Networks](https://arxiv.org/abs/2510.22339)
*Enyi Wang,Zhen Deng,Chuanchuan Pan,Bingwei He,Jianwei Zhang*

Main category: cs.RO

TL;DR: 提出了一种基于学习的方法，通过融合多模态输入（包括当前和历史肌腱位移数据和RGB图像），利用时空神经网络来精确估计柔性连续体机器人在外部载荷下的3D形状，并使用Bézier曲线进行连续形状重建，实验证明该方法在有载荷和无载荷情况下均有高精度，优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 为精确估计柔性连续体机器人在外部载荷下的3D形状提供一种新的学习方法。

Method: 设计了一个时空神经网络架构，融合了肌腱位移数据和RGB图像。该网络包含用于时域特征提取的循环神经网络模块、用于空域特征提取的编码模块以及用于融合视觉空间特征和执行器时域依赖关系的多模态融合模块。通过将Bézier曲线拟合到预测的点云中来实现连续3D形状重建。

Result: 在无载荷情况下，平均形状估计误差为0.08毫米；在有载荷情况下，平均形状估计误差为0.22毫米。所提出的方法在TDCRs的形状传感方面优于最先进的方法。

Conclusion: 基于深度学习的时空数据融合方法能够实现精确的载荷下形状估计，验证了该方法的有效性。

Abstract: This paper presents a learning-based approach for accurately estimating the
3D shape of flexible continuum robots subjected to external loads. The proposed
method introduces a spatiotemporal neural network architecture that fuses
multi-modal inputs, including current and historical tendon displacement data
and RGB images, to generate point clouds representing the robot's deformed
configuration. The network integrates a recurrent neural module for temporal
feature extraction, an encoding module for spatial feature extraction, and a
multi-modal fusion module to combine spatial features extracted from visual
data with temporal dependencies from historical actuator inputs. Continuous 3D
shape reconstruction is achieved by fitting B\'ezier curves to the predicted
point clouds. Experimental validation demonstrates that our approach achieves
high precision, with mean shape estimation errors of 0.08 mm (unloaded) and
0.22 mm (loaded), outperforming state-of-the-art methods in shape sensing for
TDCRs. The results validate the efficacy of deep learning-based spatiotemporal
data fusion for precise shape estimation under loading conditions.

</details>


### [467] [BLIP-FusePPO: A Vision-Language Deep Reinforcement Learning Framework for Lane Keeping in Autonomous Vehicles](https://arxiv.org/abs/2510.22370)
*Seyed Ahmad Hosseini Miangoleh,Amin Jalal Aghdasian,Farzaneh Abdollahi*

Main category: cs.RO

TL;DR: 该研究提出了一种名为BLIP-FusePPO的新型多模态强化学习框架，用于自主车道保持（LK）任务。该框架将视觉-语言模型（VLM）生成的语义嵌入与几何状态、LiDAR观测和PID控制反馈融合，以增强代理的观测空间。


<details>
  <summary>Details</summary>
Motivation: 为了让自主驾驶代理能够学习到对周围环境有感知且易于理解的驾驶规则，该研究结合了VLM的高层场景理解能力与低层控制和空间信号。

Method: 提出了一种名为BLIP-FusePPO的多模态强化学习框架，将VLM生成的语义嵌入直接融合到代理的观测空间中，该空间还包含几何状态、LiDAR观测和PID控制反馈。采用混合奖励函数，包含语义对齐、LK准确性、障碍物避免和速度调节。

Result: 在各种困难的驾驶场景下，所提出的BLIP-FusePPO模型在车道保持的稳定性和适应性方面，优于最先进的基于视觉和多模态强化学习的基线模型。

Conclusion: BLIP-FusePPO通过将语义、几何和控制感知表示相结合，提高了策略学习的鲁棒性，并通过将语义特征直接嵌入状态表示，实现了比仅使用语义模型塑造奖励更高效、更具泛化性的学习。

Abstract: In this paper, we propose Bootstrapped Language-Image Pretraining-driven
Fused State Representation in Proximal Policy Optimization (BLIP-FusePPO), a
novel multimodal reinforcement learning (RL) framework for autonomous
lane-keeping (LK), in which semantic embeddings generated by a vision-language
model (VLM) are directly fused with geometric states, LiDAR observations, and
Proportional-Integral-Derivative-based (PID) control feedback within the agent
observation space. The proposed method lets the agent learn driving rules that
are aware of their surroundings and easy to understand by combining high-level
scene understanding from the VLM with low-level control and spatial signals.
Our architecture brings together semantic, geometric, and control-aware
representations to make policy learning more robust. A hybrid reward function
that includes semantic alignment, LK accuracy, obstacle avoidance, and speed
regulation helps learning to be more efficient and generalizable. Our method is
different from the approaches that only use semantic models to shape rewards.
Instead, it directly embeds semantic features into the state representation.
This cuts down on expensive runtime inference and makes sure that semantic
guidance is always available. The simulation results show that the proposed
model is better at LK stability and adaptability than the best vision-based and
multimodal RL baselines in a wide range of difficult driving situations. We
make our code publicly available.

</details>


### [468] [A Novel Multi-Timescale Stability-Preserving Hierarchical Reinforcement Learning Controller Framework for Adaptive Control in High-Dimensional Dynamical Systems](https://arxiv.org/abs/2510.22420)
*Mohammad Ali Labbaf Khaniki,Fateme Taroodi,Benyamin Safizadeh*

Main category: cs.RO

TL;DR: 本研究提出了多时序Lyapunov约束分层强化学习（MTLHRL）框架，以解决高维随机系统控制中的维度灾难、时间抽象缺失和随机稳定性保证等问题。


<details>
  <summary>Details</summary>
Motivation: 高维随机系统（如机器人、自动驾驶汽车和超混沌系统）在控制中面临维度灾难、缺乏时间抽象以及难以保证随机稳定性等挑战。

Method: MTLHRL框架将分层策略集成到半马尔可夫决策过程（SMDP）中，采用高层策略进行战略规划，低层策略进行反应式控制，并通过神经Lyapunov函数优化和拉格朗日松弛实现稳定性保证。

Result: 在8维超混沌系统和5自由度机器人操作器上的广泛模拟显示，MTLHRL在稳定性和性能上显著优于基线方法，在超混沌控制和机器人任务中分别实现了3.912和1.623的最低积分绝对误差（IAE），并具有更快的收敛速度和更好的扰动抑制能力。

Conclusion: MTLHRL为复杂随机系统的鲁棒控制提供了一个理论上可靠且实践中可行的解决方案。

Abstract: Controlling high-dimensional stochastic systems, critical in robotics,
autonomous vehicles, and hyperchaotic systems, faces the curse of
dimensionality, lacks temporal abstraction, and often fails to ensure
stochastic stability. To overcome these limitations, this study introduces the
Multi-Timescale Lyapunov-Constrained Hierarchical Reinforcement Learning
(MTLHRL) framework. MTLHRL integrates a hierarchical policy within a
semi-Markov Decision Process (SMDP), featuring a high-level policy for
strategic planning and a low-level policy for reactive control, which
effectively manages complex, multi-timescale decision-making and reduces
dimensionality overhead. Stability is rigorously enforced using a neural
Lyapunov function optimized via Lagrangian relaxation and multi-timescale
actor-critic updates, ensuring mean-square boundedness or asymptotic stability
in the face of stochastic dynamics. The framework promotes efficient and
reliable learning through trust-region constraints and decoupled optimization.
Extensive simulations on an 8D hyperchaotic system and a 5-DOF robotic
manipulator demonstrate MTLHRL's empirical superiority. It significantly
outperforms baseline methods in both stability and performance, recording the
lowest error indices (e.g., Integral Absolute Error (IAE): 3.912 in
hyperchaotic control and IAE: 1.623 in robotics), achieving faster convergence,
and exhibiting superior disturbance rejection. MTLHRL offers a theoretically
grounded and practically viable solution for robust control of complex
stochastic systems.

</details>


### [469] [A short methodological review on social robot navigation benchmarking](https://arxiv.org/abs/2510.22448)
*Pranup Chhetri,Alejandro Torrejon,Sergio Eslava,Luis J. Manso*

Main category: cs.RO

TL;DR: 缺乏对社交机器人导航的基准测试标准，这阻碍了该领域的进展。本综述分析了2020年1月至2025年7月期间的85篇论文，重点关注用于基准测试的指标、算法、人类调查的使用以及如何根据基准测试结果得出结论。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏公认的社交机器人导航基准测试标准，可能阻碍该领域的进展并导致结论不一致。

Method: 通过对2020年1月至2025年7月期间使用IEEE Xplore检索到的130篇论文进行分析，筛选出85篇符合要求的论文，并对其进行研究。

Result: 本研究分析了文献中用于基准测试的指标、所采用的算法、是否使用人类调查以及如何根据基准测试结果得出结论。

Conclusion: 缺乏统一的基准测试标准是社交机器人导航领域的一个重要问题，阻碍了该领域的进展。本综述旨在通过分析近期的相关研究来填补这一空白。

Abstract: Social Robot Navigation is the skill that allows robots to move efficiently
in human-populated environments while ensuring safety, comfort, and trust.
Unlike other areas of research, the scientific community has not yet achieved
an agreement on how Social Robot Navigation should be benchmarked. This is
notably important, as the lack of a de facto standard to benchmark Social Robot
Navigation can hinder the progress of the field and may lead to contradicting
conclusions. Motivated by this gap, we contribute with a short review focused
exclusively on benchmarking trends in the period from January 2020 to July
2025. Of the 130 papers identified by our search using IEEE Xplore, we analysed
the 85 papers that met the criteria of the review. This review addresses the
metrics used in the literature for benchmarking purposes, the algorithms
employed in such benchmarks, the use of human surveys for benchmarking, and how
conclusions are drawn from the benchmarking results, when applicable.

</details>


### [470] [Forward Kinematics Solution For A General Stewart Platform Through Iteration Based Simulation](https://arxiv.org/abs/2510.22465)
*Sourabh Karmakar,Cameron J. Turner*

Main category: cs.RO

TL;DR: 该研究提出了一种为Stewart平台生成唯一正运动学解的方法。


<details>
  <summary>Details</summary>
Motivation: Stewart平台正运动学求解复杂且存在多解，需要一种能生成唯一可行解的方法，以满足材料测试系统对高精度位姿控制的需求。

Method: 采用改进的Denavit-Hartenberg（DH）规范和简单的迭代算法，结合逆运动学得到的位姿数据和执行器长度，来求解正运动学。

Result: 该方法能够为每个有效的位姿生成唯一的、可行的正运动学解，无需手动验证，简化了后续计算。

Conclusion: 所提出的方法有效解决了Stewart平台正运动学多解的问题，生成的唯一解可直接用于材料测试系统等应用，提高了系统的精度和效率。

Abstract: This paper presents a method to generate feasible, unique forward-kinematic
solutions for a general Stewart platform. This is done by using inverse
kinematics to obtain valid workspace data and corresponding actuator lengths
for the moving platform. For parallel kinematic machines, such as the Stewart
Platform, inverse kinematics are straight forward, but the forward kinematics
are complex and generates multiple solutions due to the closed loop structure
of the kinematic links. In this research, a simple iterative algorithm has been
used employing modified Denavit-Hartenberg convention. The outcome is
encouraging as this method generates a single feasible forward kinematic
solution for each valid pose with the solved DH parameters and unlike earlier
forward kinematics solutions, this unique solution does not need to be manually
verified. Therefore, the forward kinematic solutions can be used directly for
further calculations without the need for manual pose verification. This
capability is essential for the six degree of freedom materials testing system
developed by the authors in their laboratory. The developed system is aimed at
characterizing additively manufactured materials under complex combined
multiple loading conditions. The material characterization is done by enabling
high precision force control on the moving platform via in situ calibration of
the as-built kinematics of the Stewart Gough Platform.

</details>


### [471] [On Steerability Factors for Growing Vine Robots](https://arxiv.org/abs/2510.22504)
*Ciera McFarland,Antonio Alvarez,Sarah Taher,Nathaniel Hanson,Margaret McGuinness*

Main category: cs.RO

TL;DR: Vine 机器人的管状身体可以通过从尖端挤出材料来伸展，从而能够以极简的软体在复杂环境中导航。尽管它们在现场应用，尤其是在城市搜索和救援领域具有应用前景，但性能受到所连接的传感器或工具的重量以及其他设计和控制选择的限制。这项工作研究了尖端负载、压力、长度、直径和制造方法如何影响藤蔓机器人的可操纵性——即以受控的曲率进行操纵的能力——对于那些通过串联气囊式气动执行器进行转向的机器人。我们进行了两组实验：(1) 研究了在支撑自身抵抗重力的机器人中，尖端负载、腔室压力、长度和直径；(2) 研究了在地支撑的机器人中，制造方法和执行器与腔室压力的比率。结果表明，随着尖端负载的增加，可操纵性降低，在中等腔室压力下最佳，随着长度增加而增加，并且在很大程度上不受直径影响。在机器人外部连接执行器的机器人在低压比下开始弯曲，但在高压比下饱和；执行器集成到机器人机身中的机器人在开始弯曲时需要更高的压比，但总体上实现了更高的曲率。我们证明，通过这些原理优化的机器人比具有临时参数的机器人在最大化向上和水平曲率的移动任务中表现更好。


<details>
  <summary>Details</summary>
Motivation: 尽管藤蔓机器人在城市搜索和救援等领域具有应用前景，但其性能受到负载、设计和控制选择的限制。因此，有必要研究尖端负载、压力、长度、直径和制造方法对机器人可操纵性的影响。

Method: 本研究通过两组实验来研究藤蔓机器人的可操纵性：(1) 在支撑自身抵抗重力的机器人中，研究尖端负载、腔室压力、长度和直径的影响；(2) 在地支撑的机器人中，研究制造方法和执行器与腔室压力的比率的影响。

Result: 结果显示，可操纵性随尖端负载的增加而降低，在中等腔室压力下达到最佳，随长度的增加而增加，并且基本不受直径影响。外部集成执行器的机器人在低压比下开始弯曲，但在高压比下饱和；内部集成执行器的机器人在低压比下开始弯曲，但总体曲率更高。。

Conclusion: 通过优化尖端负载、腔室压力、长度和制造方法，可以显著提高藤蔓机器人的可操纵性，从而在复杂环境中实现更有效的导航和执行任务。

Abstract: Vine robots extend their tubular bodies by everting material from the tip,
enabling navigation in complex environments with a minimalist soft body.
Despite their promise for field applications, especially in the urban search
and rescue domain, performance is constrained by the weight of attached sensors
or tools, as well as other design and control choices. This work investigates
how tip load, pressure, length, diameter, and fabrication method shape vine
robot steerability--the ability to maneuver with controlled curvature--for
robots that steer with series pouch motor-style pneumatic actuators. We conduct
two groups of experiments: (1) studying tip load, chamber pressure, length, and
diameter in a robot supporting itself against gravity, and (2) studying
fabrication method and ratio of actuator to chamber pressure in a robot
supported on the ground. Results show that steerability decreases with
increasing tip load, is best at moderate chamber pressure, increases with
length, and is largely unaffected by diameter. Robots with actuators attached
on their exterior begin curving at low pressure ratios, but curvature saturates
at high pressure ratios; those with actuators integrated into the robot body
require higher pressure ratios to begin curving but achieve higher curvature
overall. We demonstrate that robots optimized with these principles outperform
those with ad hoc parameters in a mobility task that involves maximizing upward
and horizontal curvatures.

</details>


### [472] [Ant-inspired Walling Strategies for Scalable Swarm Separation: Reinforcement Learning Approaches Based on Finite State Machines](https://arxiv.org/abs/2510.22524)
*Shenbagaraj Kannapiran,Elena Oikonomou,Albert Chu,Spring Berman,Theodore P. Pavlic*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In natural systems, emergent structures often arise to balance competing
demands. Army ants, for example, form temporary "walls" that prevent
interference between foraging trails. Inspired by this behavior, we developed
two decentralized controllers for heterogeneous robotic swarms to maintain
spatial separation while executing concurrent tasks. The first is a
finite-state machine (FSM)-based controller that uses encounter-triggered
transitions to create rigid, stable walls. The second integrates FSM states
with a Deep Q-Network (DQN), dynamically optimizing separation through emergent
"demilitarized zones." In simulation, both controllers reduce mixing between
subgroups, with the DQN-enhanced controller improving adaptability and reducing
mixing by 40-50% while achieving faster convergence.

</details>


### [473] [RoGER-SLAM: A Robust Gaussian Splatting SLAM System for Noisy and Low-light Environment Resilience](https://arxiv.org/abs/2510.22600)
*Huilin Yin,Zhaolin Yang,Linchuan Zhang,Gerhard Rigoll,Johannes Betz*

Main category: cs.RO

TL;DR: RoGER-SLAM 是一种鲁棒的 3DGS SLAM 系统，通过融合外观、深度和边缘线索、自适应跟踪目标以及基于 CLIP 的增强模块，提高了在嘈杂和低光照条件下的鲁棒性，从而提升了轨迹精度和重建质量。


<details>
  <summary>Details</summary>
Motivation: 视觉 SLAM 在存在噪声和低光照等干扰的环境中可靠性会受到限制。现有的 3DGS SLAM 框架在恶劣条件下映射和跟踪性能会下降。

Method: RoGER-SLAM 提出了一种结构保持鲁棒融合（SP-RoFusion）机制，结合了渲染的外观、深度和边缘线索。此外，还设计了一个具有残差平衡正则化的自适应跟踪目标。在复合退化下，会选择性地激活一个基于 CLIP 的增强模块，以恢复语义和结构保真度。

Result: 在 Replica、TUM 和真实世界序列上的实验表明，RoGER-SLAM 在恶劣成像条件下，轨迹精度和重建质量均优于其他 3DGS-SLAM 系统。

Conclusion: RoGER-SLAM 显著提高了 3DGS SLAM 在噪声和低光照等恶劣条件下的性能。

Abstract: The reliability of Simultaneous Localization and Mapping (SLAM) is severely
constrained in environments where visual inputs suffer from noise and low
illumination. Although recent 3D Gaussian Splatting (3DGS) based SLAM
frameworks achieve high-fidelity mapping under clean conditions, they remain
vulnerable to compounded degradations that degrade mapping and tracking
performance. A key observation underlying our work is that the original 3DGS
rendering pipeline inherently behaves as an implicit low-pass filter,
attenuating high-frequency noise but also risking over-smoothing. Building on
this insight, we propose RoGER-SLAM, a robust 3DGS SLAM system tailored for
noise and low-light resilience. The framework integrates three innovations: a
Structure-Preserving Robust Fusion (SP-RoFusion) mechanism that couples
rendered appearance, depth, and edge cues; an adaptive tracking objective with
residual balancing regularization; and a Contrastive Language-Image Pretraining
(CLIP)-based enhancement module, selectively activated under compounded
degradations to restore semantic and structural fidelity. Comprehensive
experiments on Replica, TUM, and real-world sequences show that RoGER-SLAM
consistently improves trajectory accuracy and reconstruction quality compared
with other 3DGS-SLAM systems, especially under adverse imaging conditions.

</details>


### [474] [Analytical Swarm Chemistry: Characterization and Analysis of Emergent Swarm Behaviors](https://arxiv.org/abs/2510.22821)
*Ricardo Vega,Connor Mattson,Kevin Zhu,Daniel S. Brown,Cameron Nowzari*

Main category: cs.RO

TL;DR: 通过引入分析性群体化学框架，结合宏观定义和相图分析，来预测和控制群体机器人中的涌现行为。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的群体机器人部署因难以预测由简单局部交互产生的涌现行为而受到限制。本研究旨在通过一种新的框架来解决这一挑战。

Method: 提出分析性群体化学框架，借鉴工程学、基于智能体的研究和化学概念，利用宏观定义和相图分析来研究群体参数如何影响涌现行为。将此框架应用于具有最小能力限制的智能体，识别产生特定行为（如聚集和扩散）的充分条件和参数空间区域。

Result: 识别出产生聚集和扩散行为的充分条件，并确定了能可靠产生这些行为的参数空间区域。初步的机器人实验验证了这些区域对应于实际可观察到的行为。

Conclusion: 分析性群体化学框架提供了一种原则性、可解释的方法，为实现可预测和可靠的现实世界群体系统中的涌现行为奠定了基础。

Abstract: Swarm robotics has potential for a wide variety of applications, but
real-world deployments remain rare due to the difficulty of predicting emergent
behaviors arising from simple local interactions. Traditional engineering
approaches design controllers to achieve desired macroscopic outcomes under
idealized conditions, while agent-based and artificial life studies explore
emergent phenomena in a bottom-up, exploratory manner. In this work, we
introduce Analytical Swarm Chemistry, a framework that integrates concepts from
engineering, agent-based and artificial life research, and chemistry. This
framework combines macrostate definitions with phase diagram analysis to
systematically explore how swarm parameters influence emergent behavior.
Inspired by concepts from chemistry, the framework treats parameters like
thermodynamic variables, enabling visualization of regions in parameter space
that give rise to specific behaviors. Applying this framework to agents with
minimally viable capabilities, we identify sufficient conditions for behaviors
such as milling and diffusion and uncover regions of the parameter space that
reliably produce these behaviors. Preliminary validation on real robots
demonstrates that these regions correspond to observable behaviors in practice.
By providing a principled, interpretable approach, this framework lays the
groundwork for predictable and reliable emergent behavior in real-world swarm
systems.

</details>


### [475] [Uncertainty-Aware Autonomous Vehicles: Predicting the Road Ahead](https://arxiv.org/abs/2510.22680)
*Shireen Kudukkil Manchingal,Armand Amaritei,Mihir Gohad,Maryam Sultana,Julian F. P. Kooij,Fabio Cuzzolin,Andrew Bradley*

Main category: cs.RO

TL;DR: 本研究利用随机集神经网络（RS-NNs）来解决自动驾驶汽车（AV）感知系统中因罕见事件或样本外数据导致的过度自信预测问题。通过明确量化预测不确定性，RS-NNs 能在新的或模糊的场景中清晰地识别和发出不确定性信号，并在真实世界的自动驾驶赛车软件栈中进行了测试。与传统的卷积神经网络（CNN）和贝叶斯神经网络相比，RS-NNs 在准确性和不确定性校准方面表现更优。将 RS-NNs 集成到基于 ROS 的车辆控制管线中，可以根据预测不确定性动态调整车辆速度，从而在保证高速度性能的同时，通过减速提高安全性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶汽车（AV）感知系统在处理罕见事件或样本外数据时，容易出现过度自信的预测，从而带来安全风险。本研究旨在为 AV 提供‘知道自己何时不确定’的能力。

Method: 本研究利用随机集神经网络（RS-NNs）来量化预测不确定性。RS-NNs 预测类别集合上的信念函数，从而能够识别和发出不确定性信号。该系统被集成到一个真实的自动驾驶赛车软件栈中，用于对道路布局进行分类并提供预测不确定性。

Result: 在真实世界的自动驾驶赛车软件栈中，RS-NNs 在分类道路布局及其预测不确定性方面表现出色。与传统的 CNN 和贝叶斯神经网络相比，RS-NNs 在准确性和不确定性校准方面取得了显著的优势。将 RS-NNs 集成到基于 ROS 的车辆控制管线中，能够根据预测不确定性动态调整车辆速度，从而在保持高速度的同时提高安全性。

Conclusion: 本研究证明了不确定性感知神经网络，特别是 RS-NNs，是实现更安全、更鲁棒的自动驾驶的可行解决方案。通过明确量化预测不确定性并动态调整车辆行为，可以有效提高自动驾驶系统的安全性和可靠性。

Abstract: Autonomous Vehicle (AV) perception systems have advanced rapidly in recent
years, providing vehicles with the ability to accurately interpret their
environment. Perception systems remain susceptible to errors caused by
overly-confident predictions in the case of rare events or out-of-sample data.
This study equips an autonomous vehicle with the ability to 'know when it is
uncertain', using an uncertainty-aware image classifier as part of the AV
software stack. Specifically, the study exploits the ability of Random-Set
Neural Networks (RS-NNs) to explicitly quantify prediction uncertainty. Unlike
traditional CNNs or Bayesian methods, RS-NNs predict belief functions over sets
of classes, allowing the system to identify and signal uncertainty clearly in
novel or ambiguous scenarios. The system is tested in a real-world autonomous
racing vehicle software stack, with the RS-NN classifying the layout of the
road ahead and providing the associated uncertainty of the prediction.
Performance of the RS-NN under a range of road conditions is compared against
traditional CNN and Bayesian neural networks, with the RS-NN achieving
significantly higher accuracy and superior uncertainty calibration. This
integration of RS-NNs into Robot Operating System (ROS)-based vehicle control
pipeline demonstrates that predictive uncertainty can dynamically modulate
vehicle speed, maintaining high-speed performance under confident predictions
while proactively improving safety through speed reductions in uncertain
scenarios. These results demonstrate the potential of uncertainty-aware neural
networks - in particular RS-NNs - as a practical solution for safer and more
robust autonomous driving.

</details>


### [476] [Never Too Rigid to Reach: Adaptive Virtual Model Control with LLM- and Lyapunov-Based Reinforcement Learning](https://arxiv.org/abs/2510.22892)
*Jingzehua Xu,Yangyang Li,Yangfei Chen,Guanwen Xie,Shuai Zhang*

Main category: cs.RO

TL;DR: 本研究提出了一种结合大语言模型（LLM）和基于Lyapunov的强化学习（RL）的自适应虚拟模型控制（VMC）方法，以解决传统VMC在不确定环境中适应性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 传统VMC在面对扰动或信息不完整时，由于依赖固定参数且虚拟组件间协调有限，导致其刚性和适应性不足，可能在任务目标变化时影响稳定性。

Method: 提出了一种自适应VMC方法，结合LLM提供结构化先验和高级推理，增强虚拟组件间的协调性，提高样本效率，并灵活适应任务需求。同时，利用基于Lyapunov的RL强制执行理论稳定性约束，确保在不确定性下的安全自适应。

Result: 在7自由度Panda机械臂上的广泛仿真表明，该方法能有效平衡动态任务中的竞争目标，实现卓越性能，并突出了LLM引导和Lyapunov约束自适应的协同优势。

Conclusion: 本研究提出的结合LLM和Lyapunov-based RL的自适应VMC方法，在保持VMC物理可解释性的同时，实现了有保证的在线自适应，有效解决了传统VMC的局限性，并在动态任务中表现出优越的性能。

Abstract: Robotic arms are increasingly deployed in uncertain environments, yet
conventional control pipelines often become rigid and brittle when exposed to
perturbations or incomplete information. Virtual Model Control (VMC) enables
compliant behaviors by embedding virtual forces and mapping them into joint
torques, but its reliance on fixed parameters and limited coordination among
virtual components constrains adaptability and may undermine stability as task
objectives evolve. To address these limitations, we propose Adaptive VMC with
Large Language Model (LLM)- and Lyapunov-Based Reinforcement Learning (RL),
which preserves the physical interpretability of VMC while supporting
stability-guaranteed online adaptation. The LLM provides structured priors and
high-level reasoning that enhance coordination among virtual components,
improve sample efficiency, and facilitate flexible adjustment to varying task
requirements. Complementarily, Lyapunov-based RL enforces theoretical stability
constraints, ensuring safe and reliable adaptation under uncertainty. Extensive
simulations on a 7-DoF Panda arm demonstrate that our approach effectively
balances competing objectives in dynamic tasks, achieving superior performance
while highlighting the synergistic benefits of LLM guidance and
Lyapunov-constrained adaptation.

</details>


### [477] [RL-AVIST: Reinforcement Learning for Autonomous Visual Inspection of Space Targets](https://arxiv.org/abs/2510.22699)
*Matteo El-Hariry,Andrej Orsula,Matthieu Geist,Miguel Olivares-Mendez*

Main category: cs.RO

TL;DR: 本文提出了一种名为RL-AVIST的强化学习框架，用于自主视觉空间目标检查。


<details>
  <summary>Details</summary>
Motivation: 传统控制系统在处理模型不确定性、多航天器配置或动态任务环境时适应性不足，而自主在轨服务（如检查、维护和态势感知）的需求日益增长，需要能够围绕大型轨道目标执行复杂机动的智能航天器。

Method: 利用空间机器人基准（SRB）模拟高保真6-DOF航天器动力学，并使用最先进的基于模型的强化学习算法DreamerV3进行训练，并以PPO和TD3作为无模型基线。重点研究了绕月球门户等空间资产的3D邻近机动任务，并通过在随机速度向量上训练的通用智能体和在固定轨迹上训练的专用智能体进行评估，还评估了在多种航天器形态和任务域中的鲁棒性和泛化能力。

Result: 结果表明，基于模型的强化学习在轨迹保真度和样本效率方面展现出潜力。

Conclusion: RL-AVIST为未来空间操作提供了可扩展、可重新训练的控制解决方案。

Abstract: The growing need for autonomous on-orbit services such as inspection,
maintenance, and situational awareness calls for intelligent spacecraft capable
of complex maneuvers around large orbital targets. Traditional control systems
often fall short in adaptability, especially under model uncertainties,
multi-spacecraft configurations, or dynamically evolving mission contexts. This
paper introduces RL-AVIST, a Reinforcement Learning framework for Autonomous
Visual Inspection of Space Targets. Leveraging the Space Robotics Bench (SRB),
we simulate high-fidelity 6-DOF spacecraft dynamics and train agents using
DreamerV3, a state-of-the-art model-based RL algorithm, with PPO and TD3 as
model-free baselines. Our investigation focuses on 3D proximity maneuvering
tasks around targets such as the Lunar Gateway and other space assets. We
evaluate task performance under two complementary regimes: generalized agents
trained on randomized velocity vectors, and specialized agents trained to
follow fixed trajectories emulating known inspection orbits. Furthermore, we
assess the robustness and generalization of policies across multiple spacecraft
morphologies and mission domains. Results demonstrate that model-based RL
offers promising capabilities in trajectory fidelity, and sample efficiency,
paving the way for scalable, retrainable control solutions for future space
operations

</details>


### [478] [End-to-End Design and Validation of a Low-Cost Stewart Platform with Nonlinear Estimation and Control](https://arxiv.org/abs/2510.22949)
*Benedictus C. G. Cinun,Tua A. Tamba,Immanuel R. Santjoko,Xiaofeng Wang,Michael A. Gunarso,Bin Hu*

Main category: cs.RO

TL;DR: 本文设计并验证了一个低成本的Stewart平台，用于机器人研究和教育。


<details>
  <summary>Details</summary>
Motivation: 开发一个价格实惠但功能齐全的Stewart平台，用于机器人研究和教育。强调了现有研究在独立方面（如建模或控制）的不足，而本文提供了一个完整的软硬件平台。

Method: 结合现成组件、3D打印和定制零件，使用六个线性驱动器实现六自由度运动。软件集成了动态建模、数据采集和实时控制。控制器采用基于反馈线性化的LQR方案，状态估计使用扩展卡尔曼滤波器融合IMU和编码器数据。

Result: 仿真和实验结果表明，该平台能够有效进行轨迹跟踪和实时状态估计，即使在传感器噪声和外部干扰下也能保持精确。

Conclusion: 所提出的低成本Stewart平台是一个经济高效且多功能的工具，适用于高级研究和教育应用，成功完成了软硬件集成和实验验证。

Abstract: This paper presents the complete design, control, and experimental validation
of a low-cost Stewart platform prototype developed as an affordable yet capable
robotic testbed for research and education. The platform combines off the shelf
components with 3D printed and custom fabricated parts to deliver full six
degrees of freedom motions using six linear actuators connecting a moving
platform to a fixed base. The system software integrates dynamic modeling, data
acquisition, and real time control within a unified framework. A robust
trajectory tracking controller based on feedback linearization, augmented with
an LQR scheme, compensates for the platform's nonlinear dynamics to achieve
precise motion control. In parallel, an Extended Kalman Filter fuses IMU and
actuator encoder feedback to provide accurate and reliable state estimation
under sensor noise and external disturbances. Unlike prior efforts that
emphasize only isolated aspects such as modeling or control, this work delivers
a complete hardware-software platform validated through both simulation and
experiments on static and dynamic trajectories. Results demonstrate effective
trajectory tracking and real-time state estimation, highlighting the platform's
potential as a cost effective and versatile tool for advanced research and
educational applications.

</details>


### [479] [SCAL for Pinch-Lifting: Complementary Rotational and Linear Prototypes for Environment-Adaptive Grasping](https://arxiv.org/abs/2510.22738)
*Wentao Guo,Wenzeng Zhang*

Main category: cs.RO

TL;DR: 该论文提出了一种名为 SCAL 的环境自适应夹取技术，并实现了 SCAL-R（旋转驱动）和 SCAL-L（线性驱动）两种手指设计，能够稳定抓取各种物体。


<details>
  <summary>Details</summary>
Motivation: 提出一种能够进行环境自适应夹取的机器人技术，以实现对薄形或低调目标物的稳定抓取，并最大限度地减少传感和控制需求。

Method: 提出了一种基于 SCAL（槽约束自适应连杆）的夹取技术，并设计了两种手指：SCAL-R（旋转驱动，主动折叠）和 SCAL-L（线性驱动，被动张开）。通过实验评估了两种手指在不同场景下的夹取能力，并进行了准静态分析以建立夹持力模型。

Result: SCAL-R 和 SCAL-L 在抓取小零件、盒子、罐子和胶带卷等多种物体时表现出稳定可靠的抓取能力。准静态分析提供了夹持力模型，为设计和操作提供了指导。

Conclusion: SCAL 技术及其衍生的 SCAL-R 和 SCAL-L 手指为实现稳健、环境自适应的机器人抓取提供了一条实用的途径，并且具有简单的驱动方式。

Abstract: This paper presents environment-adaptive pinch-lifting built on a
slot-constrained adaptive linkage (SCAL) and instantiated in two complementary
fingers: SCAL-R, a rotational-drive design with an active fingertip that folds
inward after contact to form an envelope, and SCAL-L, a linear-drive design
that passively opens on contact to span wide or weak-feature objects. Both
fingers convert surface following into an upward lifting branch while
maintaining fingertip orientation, enabling thin or low-profile targets to be
raised from supports with minimal sensing and control. Two-finger grippers are
fabricated via PLA-based 3D printing. Experiments evaluate (i)
contact-preserving sliding and pinch-lifting on tabletops, (ii) ramp
negotiation followed by lift, and (iii) handling of bulky objects via active
enveloping (SCAL-R) or contact-triggered passive opening (SCAL-L). Across
dozens of trials on small parts, boxes, jars, and tape rolls, both designs
achieve consistent grasps with limited tuning. A quasi-static analysis provides
closed-form fingertip-force models for linear parallel pinching and two-point
enveloping, offering geometry-aware guidance for design and operation. Overall,
the results indicate complementary operating regimes and a practical path to
robust, environment-adaptive grasping with simple actuation.

</details>


### [480] [An Intelligent Water-Saving Irrigation System Based on Multi-Sensor Fusion and Visual Servoing Control](https://arxiv.org/abs/2510.23003)
*ZhengKai Huang,YiKun Wang,ChenYu Hui,XiaoCheng*

Main category: cs.RO

TL;DR: 该研究介绍了一种用于精准农业的智能节水灌溉系统，该系统通过融合计算机视觉、机器人控制和姿态稳定技术，有效解决了传统灌溉方式中的水资源浪费和地形适应性差的问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决精准农业中存在的用水效率低和地形适应性差等关键挑战。

Method: 该系统集成了先进的计算机视觉、机器人控制和实时稳定技术，并采用了多传感器融合的方法。利用轻量级YOLO模型和K210嵌入式视觉处理器，实现了在不同光照条件下 plant container 的实时检测，准确率超过96%。简化的手眼标定算法确保了末端执行器的精确定位，成功率超过90%。基于STM32F103ZET6主控芯片和JY901S惯性测量单元的活动调平系统，能够在10度以内的斜坡上稳定灌溉平台，响应时间为1.8秒。

Result: 在三种模拟农业环境（标准温室、丘陵地带、复杂光照）的实验结果表明，与传统的漫灌方式相比，用水量减少了30-50%，在所有测试案例中的用水效率均超过92%。

Conclusion: 该智能节水灌溉系统在不同环境下均表现出高效的节水性能和良好的地形适应性，为精准农业提供了有效的解决方案。

Abstract: This paper introduces an intelligent water-saving irrigation system designed
to address critical challenges in precision agriculture, such as inefficient
water use and poor terrain adaptability. The system integrates advanced
computer vision, robotic control, and real-time stabilization technologies via
a multi-sensor fusion approach. A lightweight YOLO model, deployed on an
embedded vision processor (K210), enables real-time plant container detection
with over 96% accuracy under varying lighting conditions. A simplified hand-eye
calibration algorithm-designed for 'handheld camera' robot arm
configurations-ensures that the end effector can be precisely positioned, with
a success rate exceeding 90%. The active leveling system, driven by the
STM32F103ZET6 main control chip and JY901S inertial measurement data, can
stabilize the irrigation platform on slopes up to 10 degrees, with a response
time of 1.8 seconds. Experimental results across three simulated agricultural
environments (standard greenhouse, hilly terrain, complex lighting) demonstrate
a 30-50% reduction in water consumption compared to conventional flood
irrigation, with water use efficiency exceeding 92% in all test cases.

</details>


### [481] [TWC-SLAM: Multi-Agent Cooperative SLAM with Text Semantics and WiFi Features Integration for Similar Indoor Environments](https://arxiv.org/abs/2510.22754)
*Chunyu Li,Shoubin Chen,Dong Li,Weixing Xue,Qingquan Li*

Main category: cs.RO

TL;DR: TWC-SLAM利用文本和WiFi信号解决了多智能体SLAM在结构相似的室内环境中定位不准确的问题。


<details>
  <summary>Details</summary>
Motivation: 在结构相似的室内环境中，多智能体协同SLAM在定位和闭环检测方面存在挑战，导致共享定位不准确。

Method: TWC-SLAM框架集成了文本语义和WiFi信号特征，结合FAST-LIO2作为前端里程计，并包含一个利用文本和WiFi特征进行定位和闭环检测的模块，以及一个全局建图模块。

Result: 在包含相似走廊、房间和文字标识的室内数据集中进行评估，结果显示TWC-SLAM显著提高了在具有重复建筑特征的复杂环境中的协同SLAM性能。

Conclusion: TWC-SLAM通过融合文本和WiFi信号特征，能够有效提高多智能体协同SLAM在结构相似的室内环境中的定位和闭环检测的准确性，实现全局优化和一致性建图。

Abstract: Multi-agent cooperative SLAM often encounters challenges in similar indoor
environments characterized by repetitive structures, such as corridors and
rooms. These challenges can lead to significant inaccuracies in shared location
identification when employing point cloud-based techniques. To mitigate these
issues, we introduce TWC-SLAM, a multi-agent cooperative SLAM framework that
integrates text semantics and WiFi signal features to enhance location
identification and loop closure detection. TWC-SLAM comprises a single-agent
front-end odometry module based on FAST-LIO2, a location identification and
loop closure detection module that leverages text semantics and WiFi features,
and a global mapping module. The agents are equipped with sensors capable of
capturing textual information and detecting WiFi signals. By correlating these
data sources, TWC-SLAM establishes a common location, facilitating point cloud
alignment across different agents' maps. Furthermore, the system employs loop
closure detection and optimization modules to achieve global optimization and
cohesive mapping. We evaluated our approach using an indoor dataset featuring
similar corridors, rooms, and text signs. The results demonstrate that TWC-SLAM
significantly improves the performance of cooperative SLAM systems in complex
environments with repetitive architectural features.

</details>


### [482] [Seq-DeepIPC: Sequential Sensing for End-to-End Control in Legged Robot Navigation](https://arxiv.org/abs/2510.23057)
*Oskar Natan,Jun Miura*

Main category: cs.RO

TL;DR: Seq-DeepIPC是一个用于机器人腿部导航的端到端感知到控制模型，通过融合多模态感知（RGB-D + GNSS）和时间信息来提高导航性能，并在机器人狗上进行了验证。


<details>
  <summary>Details</summary>
Motivation: 为自主机器人腿部导航提供智能感知能力，并将其扩展到机器人腿部而非仅限于轮式机器人。

Method: Seq-DeepIPC模型将多模态感知（RGB-D + GNSS）与时间融合和控制相结合，联合预测语义分割和深度估计。采用EfficientNet-B0作为编码器以提高效率。通过GNSS位置计算航向角，取代了噪声较大的IMU。收集了包含道路和草地等多样化地形的数据集。

Result: Seq-DeepIPC在机器人狗上进行了验证，并进行了对比和消融研究。结果表明，顺序输入能够提升模型的感知和控制能力。Seq-DeepIPC实现了具有竞争力的模型尺寸和性能。GNSS单独使用的航向估计在开阔区域表现稳健，但在高层建筑附近可能不太可靠。

Conclusion: Seq-DeepIPC成功地将端到端导航扩展到了机器人腿部，实现了更强的感知和时间感知能力，为自主导航领域的研究提供了新的方向。

Abstract: We present Seq-DeepIPC, a sequential end-to-end perception-to-control model
for legged robot navigation in realworld environments. Seq-DeepIPC advances
intelligent sensing for autonomous legged navigation by tightly integrating
multi-modal perception (RGB-D + GNSS) with temporal fusion and control. The
model jointly predicts semantic segmentation and depth estimation, giving
richer spatial features for planning and control. For efficient deployment on
edge devices, we use EfficientNet-B0 as the encoder, reducing computation while
maintaining accuracy. Heading estimation is simplified by removing the noisy
IMU and instead computing the bearing angle directly from consecutive GNSS
positions. We collected a larger and more diverse dataset that includes both
road and grass terrains, and validated Seq-DeepIPC on a robot dog. Comparative
and ablation studies show that sequential inputs improve perception and control
in our models, while other baselines do not benefit. Seq-DeepIPC achieves
competitive or better results with reasonable model size; although GNSS-only
heading is less reliable near tall buildings, it is robust in open areas.
Overall, Seq-DeepIPC extends end-to-end navigation beyond wheeled robots to
more versatile and temporally-aware systems. To support future research, we
will release the codes to our GitHub repository at
https://github.com/oskarnatan/Seq-DeepIPC.

</details>


### [483] [PIP-LLM: Integrating PDDL-Integer Programming with LLMs for Coordinating Multi-Robot Teams Using Natural Language](https://arxiv.org/abs/2510.22784)
*Guangyao Shi,Yuwei Wu,Vijay Kumar,Gaurav S. Sukhatme*

Main category: cs.RO

TL;DR: PIP-LLM是一个结合了PDDL和IP的语言模型框架，用于解决多机器人协同任务规划问题，提高了规划成功率并降低了成本。


<details>
  <summary>Details</summary>
Motivation: 现有的基于LLM和PDDL的方法在多机器人协同方面存在任务分解脆弱、可扩展性差和协调效率低等问题。

Method: PIP-LLM首先使用PDDL进行团队级规划以分解任务，然后使用IP进行机器人级规划以优化成本和负载，实现了规划与分配的分离。

Result: PIP-LLM在各种任务中提高了规划成功率，降低了最大和平均旅行成本，并实现了比最先进的基线更好的负载平衡。

Conclusion: PIP-LLM通过分离规划和分配，成功克服了现有方法的局限性，为多机器人协同自然语言指令执行提供了有效的解决方案。

Abstract: Enabling robot teams to execute natural language commands requires
translating high-level instructions into feasible, efficient multi-robot plans.
While Large Language Models (LLMs) combined with Planning Domain Description
Language (PDDL) offer promise for single-robot scenarios, existing approaches
struggle with multi-robot coordination due to brittle task decomposition, poor
scalability, and low coordination efficiency.
  We introduce PIP-LLM, a language-based coordination framework that consists
of PDDL-based team-level planning and Integer Programming (IP) based
robot-level planning. PIP-LLMs first decomposes the command by translating the
command into a team-level PDDL problem and solves it to obtain a team-level
plan, abstracting away robot assignment. Each team-level action represents a
subtask to be finished by the team. Next, this plan is translated into a
dependency graph representing the subtasks' dependency structure. Such a
dependency graph is then used to guide the robot-level planning, in which each
subtask node will be formulated as an IP-based task allocation problem,
explicitly optimizing travel costs and workload while respecting robot
capabilities and user-defined constraints. This separation of planning from
assignment allows PIP-LLM to avoid the pitfalls of syntax-based decomposition
and scale to larger teams. Experiments across diverse tasks show that PIP-LLM
improves plan success rate, reduces maximum and average travel costs, and
achieves better load balancing compared to state-of-the-art baselines.

</details>


### [484] [Combining High Level Scheduling and Low Level Control to Manage Fleets of Mobile Robots](https://arxiv.org/abs/2510.23129)
*Sabino Francesco Roselli,Ze Zhang,Knut Åkesson*

Main category: cs.RO

TL;DR: 该论文提出了一个两层框架，结合了高层调度和低层控制，用于在动态工业环境中协调大型移动机器人车队进行物料搬运。


<details>
  <summary>Details</summary>
Motivation: 在工业环境中部署移动机器人进行物料搬运需要对大型车队进行可扩展的协调，以应对动态环境。

Method: 该方法使用组合算法ComSat进行任务分配和调度，生成参数化路线，并结合分布式模型预测控制（MPC）系统实时计算局部参考轨迹，同时考虑静态和动态障碍物，以确保安全、无碰撞的操作并支持快速重新调度。

Result: 在具有不同容量和交通条件的模拟2D环境中进行评估，该方法在高任务完成率和对拥堵的鲁棒性方面表现出色。

Conclusion: 该框架的模块化结构确保了计算的可行性和灵活性，适用于复杂的工业环境。

Abstract: The deployment of mobile robots for material handling in industrial
environments requires scalable coordination of large fleets in dynamic
settings. This paper presents a two-layer framework that combines high-level
scheduling with low-level control. Tasks are assigned and scheduled using the
compositional algorithm ComSat, which generates time-parameterized routes for
each robot. These schedules are then used by a distributed Model Predictive
Control (MPC) system in real time to compute local reference trajectories,
accounting for static and dynamic obstacles. The approach ensures safe,
collision-free operation, and supports rapid rescheduling in response to
disruptions such as robot failures or environmental changes. We evaluate the
method in simulated 2D environments with varying road capacities and traffic
conditions, demonstrating high task completion rates and robust behavior even
under congestion. The modular structure of the framework allows for
computational tractability and flexibility, making it suitable for deployment
in complex, real-world industrial scenarios.

</details>


### [485] [Learning Neural Observer-Predictor Models for Limb-level Sampling-based Locomotion Planning](https://arxiv.org/abs/2510.22789)
*Abhijeet M. Kulkarni,Ioannis Poulakakis,Guoquan Huang*

Main category: cs.RO

TL;DR: A learning-based framework with a neural observer and efficient predictor is developed for accurate full-body motion prediction in legged robots, enabling collision-aware planning.


<details>
  <summary>Details</summary>
Motivation: Existing simplified kinematic models fail to capture complex robot dynamics for safe autonomous navigation, limiting predictions to simple planar motion.

Method: A neural observer with UUB guarantees provides a latent state estimate from proprioceptive measurements, which initializes a computationally efficient predictor designed for rapid, parallel trajectory evaluation.

Result: The system was integrated into an MPPI-based planner on a Vision 60 quadruped, successfully demonstrating effective, limb-aware motion planning in challenging scenarios like narrow passages and over objects.

Conclusion: The proposed framework provides a robust foundation for high-performance, collision-aware motion planning on dynamic robotic platforms.

Abstract: Accurate full-body motion prediction is essential for the safe, autonomous
navigation of legged robots, enabling critical capabilities like limb-level
collision checking in cluttered environments. Simplified kinematic models often
fail to capture the complex, closed-loop dynamics of the robot and its
low-level controller, limiting their predictions to simple planar motion. To
address this, we present a learning-based observer-predictor framework that
accurately predicts this motion. Our method features a neural observer with
provable UUB guarantees that provides a reliable latent state estimate from a
history of proprioceptive measurements. This stable estimate initializes a
computationally efficient predictor, designed for the rapid, parallel
evaluation of thousands of potential trajectories required by modern
sampling-based planners. We validated the system by integrating our neural
predictor into an MPPI-based planner on a Vision 60 quadruped. Hardware
experiments successfully demonstrated effective, limb-aware motion planning in
a challenging, narrow passage and over small objects, highlighting our system's
ability to provide a robust foundation for high-performance, collision-aware
planning on dynamic robotic platforms.

</details>


### [486] [Kinematically Controllable Cable Robots with Reconfigurable End-effectors](https://arxiv.org/abs/2510.22825)
*Nan Zhang*

Main category: cs.RO

TL;DR: 增加连杆数量以扩大线控机器人工作空间会带来连杆干涉和张力求解不唯一的问题。本文设计了一种新型可重构末端执行器，通过弹簧、螺旋槽轴和螺母将直线运动转化为旋转运动，增加了旋转工作空间，并引入轴承提供额外的旋转自由度，使机构达到非冗余。


<details>
  <summary>Details</summary>
Motivation: 扩大线控机器人的平移工作空间，但增加连杆数量会带来连杆干涉和张力求解不唯一的问题。

Method: 设计了一种包含弹簧、螺旋槽轴、螺母和轴承的可重构末端执行器，将直线运动转化为旋转运动，并提供额外的旋转自由度以避免冗余。

Result: 成功扩大了旋转工作空间，并且末端执行器成为非冗余机构，使得机器人可以通过纯运动学进行控制，无需额外的张力传感和控制。

Conclusion: 本文提出的可重构末端执行器能够有效解决线控机器人工作空间受限和控制难题，实现纯运动学控制。

Abstract: To enlarge the translational workspace of cable-driven robots, one common
approach is to increase the number of cables. However, this introduces two
challenges: (1) cable interference significantly reduces the rotational
workspace, and (2) the solution of tensions in cables becomes non-unique,
resulting in difficulties for kinematic control of the robot. In this work, we
design structurally simple reconfigurable end-effectors for cable robots. By
incorporating a spring, a helical-grooved shaft, and a matching nut, relative
linear motions between end-effector components are converted into relative
rotations, thereby expanding the rotational workspace of the mechanism.
Meanwhile, a bearing is introduced to provide an additional rotational degree
of freedom, making the mechanism non-redundant. As a result, the robot's motion
can be controlled purely through kinematics without additional tension sensing
and control.

</details>


### [487] [HyPerNav: Hybrid Perception for Object-Oriented Navigation in Unknown Environment](https://arxiv.org/abs/2510.22917)
*Zecheng Yin,Hao Zhao,Zhen Li*

Main category: cs.RO

TL;DR: HyPerNav结合RGB-D和俯视地图信息，利用视觉语言模型（VLMs）提升目标导向导航（ObjNav）的表现。


<details>
  <summary>Details</summary>
Motivation: 现有目标导向导航（ObjNav）方法多依赖单一信息源（如RGB-D或俯视地图），未能有效整合两者提供的互补信息（局部细节与全局上下文），而人类导航则能同时利用这两种信息。

Method: 提出HyPerNav（Hybrid Perception Navigation）方法，利用VLMs强大的推理和视语理解能力，联合感知来自RGB-D传感器的视觉信息（局部）和俯视地图（全局），以提升在未知环境中的导航效果和智能性。

Result: 在模拟和真实世界评估中，HyPerNav均达到最先进水平，优于现有基线方法。消融实验证明，混合感知方法中的任何一种感知方式都对导航性能有贡献。

Conclusion: HyPerNav通过混合感知方法，同时利用来自主视角观测和俯视地图的信息，捕捉更丰富的线索，更有效地找到目标物体，从而提升了导航性能。

Abstract: Objective-oriented navigation(ObjNav) enables robot to navigate to target
object directly and autonomously in an unknown environment. Effective
perception in navigation in unknown environment is critical for autonomous
robots. While egocentric observations from RGB-D sensors provide abundant local
information, real-time top-down maps offer valuable global context for ObjNav.
Nevertheless, the majority of existing studies focus on a single source, seldom
integrating these two complementary perceptual modalities, despite the fact
that humans naturally attend to both. With the rapid advancement of
Vision-Language Models(VLMs), we propose Hybrid Perception Navigation
(HyPerNav), leveraging VLMs' strong reasoning and vision-language understanding
capabilities to jointly perceive both local and global information to enhance
the effectiveness and intelligence of navigation in unknown environments. In
both massive simulation evaluation and real-world validation, our methods
achieved state-of-the-art performance against popular baselines. Benefiting
from hybrid perception approach, our method captures richer cues and finds the
objects more effectively, by simultaneously leveraging information
understanding from egocentric observations and the top-down map. Our ablation
study further proved that either of the hybrid perception contributes to the
navigation performance.

</details>


### [488] [ManiDP: Manipulability-Aware Diffusion Policy for Posture-Dependent Bimanual Manipulation](https://arxiv.org/abs/2510.23016)
*Zhuo Li,Junjia Liu,Dianxi Li,Tao Teng,Miao Li,Sylvain Calinon,Darwin Caldwell,Fei Chen*

Main category: cs.RO

TL;DR: ManiDP通过整合双臂可操作性先验到扩散模型中，提高了双臂操作任务的成功率和任务兼容性。


<details>
  <summary>Details</summary>
Motivation: 现有双臂技能学习方法忽略了姿态依赖的任务特征，这对于根据力和速度要求调整双臂配置至关重要。

Method: 提出了一种名为ManiDP的新型模仿学习方法，该方法提取双臂可操作性，使用基于黎曼的概率模型对其进行编码，并将其合并到条件扩散过程中，以指导生成任务兼容的双臂运动序列。

Result: 在六个真实的双臂任务上进行了评估，与基线方法相比，平均操作成功率提高了39.33%，任务兼容性提高了0.45。

Conclusion: 将与姿态相关的机器人先验集成到双臂技能扩散中，对于实现类似人类的适应性和灵活性至关重要。

Abstract: Recent work has demonstrated the potential of diffusion models in robot
bimanual skill learning. However, existing methods ignore the learning of
posture-dependent task features, which are crucial for adapting dual-arm
configurations to meet specific force and velocity requirements in dexterous
bimanual manipulation. To address this limitation, we propose
Manipulability-Aware Diffusion Policy (ManiDP), a novel imitation learning
method that not only generates plausible bimanual trajectories, but also
optimizes dual-arm configurations to better satisfy posture-dependent task
requirements. ManiDP achieves this by extracting bimanual manipulability from
expert demonstrations and encoding the encapsulated posture features using
Riemannian-based probabilistic models. These encoded posture features are then
incorporated into a conditional diffusion process to guide the generation of
task-compatible bimanual motion sequences. We evaluate ManiDP on six real-world
bimanual tasks, where the experimental results demonstrate a 39.33$\%$ increase
in average manipulation success rate and a 0.45 improvement in task
compatibility compared to baseline methods. This work highlights the importance
of integrating posture-relevant robotic priors into bimanual skill diffusion to
enable human-like adaptability and dexterity.

</details>


### [489] [Awakening Facial Emotional Expressions in Human-Robot](https://arxiv.org/abs/2510.23059)
*Yongtong Zhu,Lei Li,Iggy Qian,WenBin Zhou,Ye Yuan,Qingdu Li,Na Liu,Jianwei Zhang*

Main category: cs.RO

TL;DR: 该论文提出了一种基于KAN和注意力机制的端到端学习框架，用于让机器人自主学习和生成类人面部表情，并构建了一个开源的机器人面部表情数据集。


<details>
  <summary>Details</summary>
Motivation: 目前机器人面部表情生成依赖预设模式，成本高昂。为了实现自然的人机交互，需要让机器人通过自我训练来学习类人表情。

Method: 设计了一个高度仿生的机器人面部，包含物理电子动画面部单元，并开发了一个基于KAN和注意力机制的端到端学习框架。同时，设计了一个基于面部运动原语专家策略的自动化数据收集系统来构建数据集。

Result: 实验结果表明，该方法能够实现对不同测试对象进行准确且多样化的面部模仿。

Conclusion: 该研究成功开发了一种让机器人自主学习和生成类人面部表情的方法，并首次公开了相关的面部表情数据集，为未来的人机交互研究提供了新的可能。

Abstract: The facial expression generation capability of humanoid social robots is
critical for achieving natural and human-like interactions, playing a vital
role in enhancing the fluidity of human-robot interactions and the accuracy of
emotional expression. Currently, facial expression generation in humanoid
social robots still relies on pre-programmed behavioral patterns, which are
manually coded at high human and time costs. To enable humanoid robots to
autonomously acquire generalized expressive capabilities, they need to develop
the ability to learn human-like expressions through self-training. To address
this challenge, we have designed a highly biomimetic robotic face with
physical-electronic animated facial units and developed an end-to-end learning
framework based on KAN (Kolmogorov-Arnold Network) and attention mechanisms.
Unlike previous humanoid social robots, we have also meticulously designed an
automated data collection system based on expert strategies of facial motion
primitives to construct the dataset. Notably, to the best of our knowledge,
this is the first open-source facial dataset for humanoid social robots.
Comprehensive evaluations indicate that our approach achieves accurate and
diverse facial mimicry across different test subjects.

</details>


### [490] [Breaking the Circle: An Autonomous Control-Switching Strategy for Stable Orographic Soaring in MAVs](https://arxiv.org/abs/2510.23084)
*Sunyou Hwang,Christophe De Wagter,Bart Remes,Guido de Croon*

Main category: cs.RO

TL;DR: 该研究提出了一种名为SAOS的控制切换方法，以解决无人机在地形气流中盘旋带来的能耗和失散风险问题。


<details>
  <summary>Details</summary>
Motivation: 地形气流飞行器（MAVs）的续航能力虽可观，但由于控制冲突导致的盘旋行为会增加能耗并提高失散风险。

Method: 提出SAOS（自主地形气流滑翔切换控制）方法，通过选择性控制水平或垂直轴来缓解盘旋行为，从而在滑翔时将系统从欠驱动变为完全驱动。此外，通过引入攻角到INDI控制器中，改进了力估计。

Result: 通过在不同初始位置的仿真和风洞实验，SAOS方法提高了位置收敛性，减少了油门使用，并缓解了由俯仰-滚转耦合引起的滚转振荡。

Conclusion: SAOS方法提高了在受限地形气流环境中的能效和飞行稳定性。

Abstract: Orographic soaring can significantly extend the endurance of micro aerial
vehicles (MAVs), but circling behavior, arising from control conflicts between
the longitudinal and vertical axes, increases energy consumption and the risk
of divergence. We propose a control switching method, named SAOS: Switched
Control for Autonomous Orographic Soaring, which mitigates circling behavior by
selectively controlling either the horizontal or vertical axis, effectively
transforming the system from underactuated to fully actuated during soaring.
Additionally, the angle of attack is incorporated into the INDI controller to
improve force estimation. Simulations with randomized initial positions and
wind tunnel experiments on two MAVs demonstrate that the SAOS improves position
convergence, reduces throttle usage, and mitigates roll oscillations caused by
pitch-roll coupling. These improvements enhance energy efficiency and flight
stability in constrained soaring environments.

</details>


### [491] [An Automated Tape Laying System Employing a Uniaxial Force Control Device](https://arxiv.org/abs/2510.23109)
*Bernhard Rameder,Hubert Gattringer,Ronald Naderer,Andreas Mueller*

Main category: cs.RO

TL;DR: 该论文设计了一种具有集成单轴力控制和精确温度控制的自动化铺带系统（ATL系统），以确保必要的压实力和胶带熔化。


<details>
  <summary>Details</summary>
Motivation: 为了确保产品不同层之间的最佳粘合，必须将基材和传入的胶带控制在特定的温度水平。因此，从卷轴上的胶带到最终固定在期望的模具上，需要经过几个工艺步骤。

Method: 设计了一个ATL系统，包含胶带存储卷轴、胶带导向辊、胶带加工单元、加热区和固化单元。该系统采用一种特殊的机器人控制概念，其中铺带设备固定，由机器人移动模具形状，以便处理紧凑且形状复杂的模具。

Result: 通过使用碳纤维增强高密度聚乙烯胶带进行实验，验证了子系统和铺带过程的功能。

Conclusion: 所提出的ATL系统设计和机器人控制概念在实验中得到了验证，证明了其在处理紧凑复杂形状方面的有效性。

Abstract: This paper deals with the design of a cost effective automated tape laying
system (ATL system) with integrated uniaxial force control to ensure the
necessary compaction forces as well as with an accurate temperature control to
guarantee the used tape being melted appropriate. It is crucial to control the
substrate and the oncoming tape onto a specific temperature level to ensure an
optimal consolidation between the different layers of the product. Therefore,
it takes several process steps from the spooled tape on the coil until it is
finally tacked onto the desired mold. The different modules are divided into
the tape storage spool, a tape-guiding roller, a tape processing unit, a
heating zone and the consolidation unit. Moreover, a special robot control
concept for testing the ATL system is presented. In contrast to many other
systems, with this approach, the tape laying device is spatially fixed and the
shape is moved accordingly by the robot, which allows for handling of rather
compact and complex shapes. The functionality of the subsystems and the taping
process itself was finally approved in experimental results using a carbon
fiber reinforced HDPE tape.

</details>


### [492] [OmniDexGrasp: Generalizable Dexterous Grasping via Foundation Model and Force Feedback](https://arxiv.org/abs/2510.23119)
*Yi-Lin Wei,Zhexi Luo,Yuhao Lin,Mu Lin,Zhizhao Liang,Shuoyu Chen,Wei-Shi Zheng*

Main category: cs.RO

TL;DR: 提出OmniDexGrasp框架，结合基础模型和迁移与控制策略，实现用户指令、灵巧具身和抓取任务的全能性。


<details>
  <summary>Details</summary>
Motivation: 现有机器人抓取和操作方法难以泛化到不同物体或任务，因为灵巧抓取数据集规模有限。基础模型虽能增强泛化，但抽象知识与物理执行之间存在差距。

Method: OmniDexGrasp框架包含三个关键模块：(i) 使用基础模型增强泛化能力，生成支持用户指令和任务全能性的人类抓取图像；(ii) 人类图像到机器人动作的迁移策略将人类演示转换为可执行的机器人动作，实现全能灵巧具身；(iii) 力感知自适应抓取策略确保抓取执行的鲁棒性和稳定性。

Result: 在模拟和真实机器人上的实验验证了OmniDexGrasp在处理各种用户指令、抓取任务和灵巧手方面的有效性，并且其性能可扩展至灵巧操作任务。

Conclusion: OmniDexGrasp框架通过结合基础模型和迁移与控制策略，有效解决了现有机器人抓取方法的泛化性问题，实现了用户指令、灵巧具身和抓取任务的全能性，并在模拟和真实机器人上得到了验证。

Abstract: Enabling robots to dexterously grasp and manipulate objects based on human
commands is a promising direction in robotics. However, existing approaches are
challenging to generalize across diverse objects or tasks due to the limited
scale of semantic dexterous grasp datasets. Foundation models offer a new way
to enhance generalization, yet directly leveraging them to generate feasible
robotic actions remains challenging due to the gap between abstract model
knowledge and physical robot execution. To address these challenges, we propose
OmniDexGrasp, a generalizable framework that achieves omni-capabilities in user
prompting, dexterous embodiment, and grasping tasks by combining foundation
models with the transfer and control strategies. OmniDexGrasp integrates three
key modules: (i) foundation models are used to enhance generalization by
generating human grasp images supporting omni-capability of user prompt and
task; (ii) a human-image-to-robot-action transfer strategy converts human
demonstrations into executable robot actions, enabling omni dexterous
embodiment; (iii) force-aware adaptive grasp strategy ensures robust and stable
grasp execution. Experiments in simulation and on real robots validate the
effectiveness of OmniDexGrasp on diverse user prompts, grasp task and dexterous
hands, and further results show its extensibility to dexterous manipulation
tasks.

</details>


### [493] [Reliable Robotic Task Execution in the Face of Anomalies](https://arxiv.org/abs/2510.23121)
*Bharath Santhanam,Alex Mitrevski,Santosh Thoduka,Sebastian Houben,Teena Hassan*

Main category: cs.RO

TL;DR: A framework couples learned robot policies with anomaly detection and recovery behaviors to improve reliability and safety in open environments.


<details>
  <summary>Details</summary>
Motivation: Learned robot policies lack mechanisms to handle complex open environments, leading to failures and unreliable behavior. This work aims to prevent failures by enabling policies to recognize and react to them.

Method: The framework trains an anomaly detection model using nominal execution data and integrates it into online policy execution. Deviations trigger a three-level recovery process: pausing execution, local state perturbation, and resetting to a safe state using a learned success model.

Result: The proposed method was verified on a door handle reaching task and an object placing task. Results show increased execution success rates in environments with anomalies like trajectory deviations and adversarial human interventions when anomaly detection and recovery are integrated.

Conclusion: Integrating learned policies with anomaly detection and recovery significantly enhances execution success rates and robot reliability in complex, open environments.

Abstract: Learned robot policies have consistently been shown to be versatile, but they
typically have no built-in mechanism for handling the complexity of open
environments, making them prone to execution failures; this implies that
deploying policies without the ability to recognise and react to failures may
lead to unreliable and unsafe robot behaviour. In this paper, we present a
framework that couples a learned policy with a method to detect visual
anomalies during policy deployment and to perform recovery behaviours when
necessary, thereby aiming to prevent failures. Specifically, we train an
anomaly detection model using data collected during nominal executions of a
trained policy. This model is then integrated into the online policy execution
process, so that deviations from the nominal execution can trigger a
three-level sequential recovery process that consists of (i) pausing the
execution temporarily, (ii) performing a local perturbation of the robot's
state, and (iii) resetting the robot to a safe state by sampling from a learned
execution success model. We verify our proposed method in two different
scenarios: (i) a door handle reaching task with a Kinova Gen3 arm using a
policy trained in simulation and transferred to the real robot, and (ii) an
object placing task with a UFactory xArm 6 using a general-purpose policy
model. Our results show that integrating policy execution with anomaly
detection and recovery increases the execution success rate in environments
with various anomalies, such as trajectory deviations and adversarial human
interventions.

</details>


### [494] [TARC: Time-Adaptive Robotic Control](https://arxiv.org/abs/2510.23176)
*Arnav Sukhija,Lenart Treven,Jin Cheng,Florian Dörfler,Stelian Coros,Andreas Krause*

Main category: cs.RO

TL;DR: 机器人可通过强化学习自主调整控制频率以平衡效率和鲁棒性，并在仿真到现实的实验中表现优于固定频率控制。


<details>
  <summary>Details</summary>
Motivation: 机器人固定频率控制在效率和鲁棒性之间存在权衡，而生物系统具有自适应性。

Method: 采用强化学习方法，让机器人自主选择控制动作及其持续时间，从而调整控制频率。

Result: 在零样本仿真到现实的实验中，该方法在RC跑车和四足机器人上均匹配或超越了固定频率基线，并显著降低了控制频率，表现出自适应性。

Conclusion: 通过强化学习实现自适应控制频率是机器人领域的一个有前景的方向。

Abstract: Fixed-frequency control in robotics imposes a trade-off between the
efficiency of low-frequency control and the robustness of high-frequency
control, a limitation not seen in adaptable biological systems. We address this
with a reinforcement learning approach in which policies jointly select control
actions and their application durations, enabling robots to autonomously
modulate their control frequency in response to situational demands. We
validate our method with zero-shot sim-to-real experiments on two distinct
hardware platforms: a high-speed RC car and a quadrupedal robot. Our method
matches or outperforms fixed-frequency baselines in terms of rewards while
significantly reducing the control frequency and exhibiting adaptive frequency
control under real-world conditions.

</details>


### [495] [If They Disagree, Will You Conform? Exploring the Role of Robots' Value Awareness in a Decision-Making Task](https://arxiv.org/abs/2510.23204)
*Giulia Pusceddu,Giulio Antonio Abbo,Francesco Rea,Tony Belpaeme,Alessandra Sciutti*

Main category: cs.RO

TL;DR: 研究了机器人代理是否会影响人类决策，特别是当机器人被视为‘价值感知’时。实验表明，人类能够区分‘价值感知’机器人和‘非价值感知’机器人，并更倾向于关注‘价值感知’机器人，认为其更忠诚。当机器人与参与者意见不合时，会引发犹豫，这可能被滥用于不道德目的，但也可能鼓励反思和避免诈骗。


<details>
  <summary>Details</summary>
Motivation: 研究机器人代理的意见对人类决策的影响，特别是当机器人被视为‘价值感知’（即理解人类原则）时。

Method: 设计了一个实验，参与者与一个‘价值感知’的Furhat机器人和一个‘非价值感知’的Furhat机器人进行交互，在一个关于人类价值观的图像标注任务中。

Result: 参与者能够区分‘价值感知’和‘非价值感知’机器人。虽然没有明确的偏好，但参与者更倾向于关注‘价值感知’机器人，并认为其更忠诚。当两个机器人不同意参与者时，大约有四分之一的试验中出现从众现象，并且参与者需要更长的时间来确认他们的回应。

Conclusion: ‘价值感知’可能增强机器人与群体的认同感。机器人表达异议可能引发犹豫，存在被滥用于不道德目的的风险，但也可能鼓励反思，帮助用户避免诈骗。

Abstract: This study investigates whether the opinions of robotic agents are more
likely to influence human decision-making when the robots are perceived as
value-aware (i.e., when they display an understanding of human principles). We
designed an experiment in which participants interacted with two Furhat robots
- one programmed to be Value-Aware and the other Non-Value-Aware - during a
labeling task for images representing human values. Results indicate that
participants distinguished the Value-Aware robot from the Non-Value-Aware one.
Although their explicit choices did not indicate a clear preference for one
robot over the other, participants directed their gaze more toward the
Value-Aware robot. Additionally, the Value-Aware robot was perceived as more
loyal, suggesting that value awareness in a social robot may enhance its
perceived commitment to the group. Finally, when both robots disagreed with the
participant, conformity occurred in about one out of four trials, and
participants took longer to confirm their responses, suggesting that two robots
expressing dissent may introduce hesitation in decision-making. On one hand,
this highlights the potential risk that robots, if misused, could manipulate
users for unethical purposes. On the other hand, it reinforces the idea that
social robots might encourage reflection in ambiguous situations and help users
avoid scams.

</details>


### [496] [Workspace Registration and Collision Detection for Industrial Robotics Applications](https://arxiv.org/abs/2510.23227)
*Klaus Zauner,Josef El Dib,Hubert Gattringer,Andreas Mueller*

Main category: cs.RO

TL;DR: 该论文比较了不同的传感器在机器人抓取任务中的应用，展示了从环境检测到生成碰撞环境的过程，并实现了机器人与该环境的碰撞检测。


<details>
  <summary>Details</summary>
Motivation: 在机器人操作规划中，需要精确的环境信息来定义禁区和考虑碰撞对象。然而，现有的方法在处理传感器数据和生成碰撞环境方面存在不足。

Method: 1. 使用点云采集环境信息。
2. 通过区域增长分割和VCCS算法识别碰撞对象。
3. 对点云簇进行近似处理。
4. 比较不同传感器在点云采集中的表现。
5. 展示从检测到生成碰撞环境的完整流程。
6. 实现机器人与生成环境的碰撞检测。

Result: 成功识别并生成了机器人操作环境中的碰撞对象，并实现了机器人与该环境的碰撞检测。不同传感器在点云采集的准确性和效率方面存在差异。

Conclusion: 研究提出了一种从传感器数据生成机器人操作碰撞环境的方法，并进行了验证。未来的工作可以集中在优化点云处理算法和探索更多类型的传感器以提高鲁棒性。

Abstract: Motion planning for robotic manipulators relies on precise knowledge of the
environment in order to be able to define restricted areas and to take
collision objects into account. To capture the workspace, point clouds of the
environment are acquired using various sensors. The collision objects are
identified by region growing segmentation and VCCS algorithm. Subsequently the
point clusters are approximated. The aim of the present paper is to compare
different sensors, to illustrate the process from detection to the finished
collision environment and to detect collisions between the robot and this
environment.

</details>


### [497] [Optimal Dimensioning of Elastic-Link Manipulators regarding Lifetime Estimation](https://arxiv.org/abs/2510.23234)
*Klaus Zauner,Hubert Gattringer,Andreas Mueller*

Main category: cs.RO

TL;DR: 该研究提出了一种用于估算弹性连杆机器人机械臂寿命的方法，并将其应用于轻量化和低振动的机器人几何形状优化。


<details>
  <summary>Details</summary>
Motivation: 为了实现可持续的工业自动化，需要对机器人进行资源优化设计和操作，这需要轻量化设计以及时间/能量最优控制。设计和控制是相互关联的，控制需要考虑机械的固有柔顺性，而设计则需要满足控制的动态要求。

Method: 提出了一种估算弹性连杆机器人机械臂寿命的方法，该方法结合了雨流计数算法和关键切割平面法进行疲劳分析。使用 Tresca 假设来制定等效应力，并假设线性损伤累积。该方法应用于柔性串联机械臂的几何优化，优化目标是整体重量和振动幅度的组合。

Result: 通过 Pareto 前沿选择最终的机器人几何形状，以平衡寿命和振动特性。该方法在一个三自由度关节式机器人机械臂上进行了演示。

Conclusion: 该方法为设计优化提供了基础，可以实现轻量化、低振动并估算寿命的机器人，适用于可持续的工业自动化。

Abstract: Resourceful operation and design of robots is key for sustainable industrial
automation. This will be enabled by lightweight design along with time and
energy optimal control of robotic manipulators. Design and control of such
systems is intertwined as the control must take into account inherent
mechanical compliance while the design must accommodate the dynamic
requirements demanded by the control. As basis for such design optimization, a
method for estimating the lifetime of elastic link robotic manipulators is
presented. This is applied to the geometry optimization of flexible serial
manipulators performing pick-and-place operations, where the optimization
objective is a combination of overall weight and vibration amplitudes. The
lifetime estimation draws from a fatigue analysis combining the rainflow
counting algorithm and the method of critical cutting plane. Tresca hypothesis
is used to formulate an equivalent stress, and linear damage accumulation is
assumed. The final robot geometry is selected from a Pareto front as a tradeoff
of lifetime and vibration characteristic. The method is illustrated for a three
degrees of freedom articulated robotic manipulator.

</details>


### [498] [Deep Active Inference with Diffusion Policy and Multiple Timescale World Model for Real-World Exploration and Navigation](https://arxiv.org/abs/2510.23258)
*Riko Yokozawa,Kentaro Fujii,Yuta Nomura,Shingo Murata*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Autonomous robotic navigation in real-world environments requires exploration
to acquire environmental information as well as goal-directed navigation in
order to reach specified targets. Active inference (AIF) based on the
free-energy principle provides a unified framework for these behaviors by
minimizing the expected free energy (EFE), thereby combining epistemic and
extrinsic values. To realize this practically, we propose a deep AIF framework
that integrates a diffusion policy as the policy model and a multiple timescale
recurrent state-space model (MTRSSM) as the world model. The diffusion policy
generates diverse candidate actions while the MTRSSM predicts their
long-horizon consequences through latent imagination, enabling action selection
that minimizes EFE. Real-world navigation experiments demonstrated that our
framework achieved higher success rates and fewer collisions compared with the
baselines, particularly in exploration-demanding scenarios. These results
highlight how AIF based on EFE minimization can unify exploration and
goal-directed navigation in real-world robotic settings.

</details>


### [499] [Precise Time Delay Measurement and Compensation for Tightly Coupled Underwater SINS/piUSBL Navigation](https://arxiv.org/abs/2510.23286)
*Jin Huang,Yingqiang Wang,Haoda Li,Zichen Liu,Zhikun Wang,Ying Chen*

Main category: cs.RO

TL;DR: 该研究提出了一种用于水下导航的多传感器时间同步框架，通过精确测量和补偿声学传播和系统处理延迟，显著提高了导航精度。


<details>
  <summary>Details</summary>
Motivation: 水下集成导航系统（特别是包含声学定位的系统）在多传感器时间同步方面面临严峻挑战，时间延迟会导致测量和融合时刻不匹配，从而严重影响精度。

Method: 提出了一种紧密集成的导航框架，融合了无源倒置超短基线（piUSBL）声学定位系统、捷联惯导系统（SINS）和深度计，并实现了精确的时间同步。该框架还引入了一种新颖的延迟测量策略，将延迟这一传统上不可观测的误差转化为可量化参数，从而可以显式估计声学传播延迟和系统处理延迟。

Result: 通过仿真和实际实验验证，所提出的延迟补偿导航方法将RMSE降低了40.45%，最大误差降低了32.55%。

Conclusion: 精确的延迟测量和补偿不仅能提高水下导航精度，还能为声学定位集成提供一个通用的框架，为延迟敏感的多传感器系统中的时间对齐和数据融合提供了宝贵的见解。

Abstract: In multi-sensor systems, time synchronization between sensors is a
significant challenge, and this issue is particularly pronounced in underwater
integrated navigation systems incorporating acoustic positioning. Such systems
are highly susceptible to time delay, which can significantly degrade accuracy
when measurement and fusion moments are misaligned. To address this challenge,
this paper introduces a tightly coupled navigation framework that integrates a
passive inverted ultra-short baseline (piUSBL) acoustic positioning system, a
strapdown inertial navigation system (SINS), and a depth gauge under precise
time synchronization. The framework fuses azimuth and slant range from the
piUSBL with depth data, thereby avoiding poor vertical-angle observability in
planar arrays. A novel delay measurement strategy is introduced, combining
synchronized timing with acoustic signal processing, which redefines
delay-traditionally an unobservable error-into a quantifiable parameter,
enabling explicit estimation of both acoustic propagation and system processing
delays. Simulations and field experiments confirm the feasibility of the
proposed method, with delay-compensated navigation reducing RMSE by 40.45% and
maximum error by 32.55%. These findings show that precise delay measurement and
compensation not only enhance underwater navigation accuracy but also establish
a generalizable framework for acoustic positioning integration, offering
valuable insights into time alignment and data fusion in latency-sensitive
multi-sensor systems.

</details>


### [500] [Transferable Deep Reinforcement Learning for Cross-Domain Navigation: from Farmland to the Moon](https://arxiv.org/abs/2510.23329)
*Shreya Santra,Thomas Robbins,Kazuya Yoshida*

Main category: cs.RO

TL;DR: DRL策略可以跨域泛化，在地球训练的机器人导航策略在月球模拟环境中也能达到近50%的成功率，为行星探索提供了一种可行的、低成本的解决方案。


<details>
  <summary>Details</summary>
Motivation: 机器人需要在未知环境中进行自主导航，但传统方法需要针对特定环境进行大量调整，限制了可扩展性。DRL提供了一种数据驱动的替代方案。

Method: 在3D农田模拟环境中，使用PPO训练一个农业机器人实现导航和避障，然后将其学到的策略在月球模拟环境中进行零样本（zero-shot）测试。

Result: 在月球模拟环境中，未进行额外训练和微调的策略达到了近50%的成功率。

Conclusion: 跨域DRL策略迁移是一种有潜力的方法，可以为未来的行星探索任务开发适应性强、效率高的自主导航系统，并能有效降低重新训练成本。

Abstract: Autonomous navigation in unstructured environments is essential for field and
planetary robotics, where robots must efficiently reach goals while avoiding
obstacles under uncertain conditions. Conventional algorithmic approaches often
require extensive environment-specific tuning, limiting scalability to new
domains. Deep Reinforcement Learning (DRL) provides a data-driven alternative,
allowing robots to acquire navigation strategies through direct interactions
with their environment. This work investigates the feasibility of DRL policy
generalization across visually and topographically distinct simulated domains,
where policies are trained in terrestrial settings and validated in a zero-shot
manner in extraterrestrial environments. A 3D simulation of an agricultural
rover is developed and trained using Proximal Policy Optimization (PPO) to
achieve goal-directed navigation and obstacle avoidance in farmland settings.
The learned policy is then evaluated in a lunar-like simulated environment to
assess transfer performance. The results indicate that policies trained under
terrestrial conditions retain a high level of effectiveness, achieving close to
50\% success in lunar simulations without the need for additional training and
fine-tuning. This underscores the potential of cross-domain DRL-based policy
transfer as a promising approach to developing adaptable and efficient
autonomous navigation for future planetary exploration missions, with the added
benefit of minimizing retraining costs.

</details>


### [501] [Large language model-based task planning for service robots: A review](https://arxiv.org/abs/2510.23357)
*Shaohan Bian,Ying Zhang,Guohui Tian,Zhiqiang Miao,Edmond Q. Wu,Simon X. Yang,Changchun Hua*

Main category: cs.RO

TL;DR: LLM正在彻底改变服务机器人领域，特别是通过增强其任务规划能力。本文回顾了LLM技术，讨论了它们作为机器人“大脑”的应用，分析了多模态输入驱动的任务规划，并指出了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 服务机器人越来越集成到日常生活中，需要强大的任务规划能力来智能高效地提供服务。

Method: 本文回顾了LLM的发展和基础技术（预训练、微调、RAG、提示工程），探讨了LLM作为服务机器人认知核心的应用，并分析了文本、视觉、音频和多模态输入驱动的LLM任务规划的最新进展。

Result: LLM在提高机器人自主性和决策能力方面发挥着重要作用，推动了多模态输入驱动的任务规划的进步。

Conclusion: 尽管LLM在服务机器人任务规划方面取得了显著进展，但仍存在挑战和局限性，未来需要在复杂、非结构化的家庭环境中进一步提升其能力。

Abstract: With the rapid advancement of large language models (LLMs) and robotics,
service robots are increasingly becoming an integral part of daily life,
offering a wide range of services in complex environments. To deliver these
services intelligently and efficiently, robust and accurate task planning
capabilities are essential. This paper presents a comprehensive overview of the
integration of LLMs into service robotics, with a particular focus on their
role in enhancing robotic task planning. First, the development and
foundational techniques of LLMs, including pre-training, fine-tuning,
retrieval-augmented generation (RAG), and prompt engineering, are reviewed. We
then explore the application of LLMs as the cognitive core-`brain'-of service
robots, discussing how LLMs contribute to improved autonomy and
decision-making. Furthermore, recent advancements in LLM-driven task planning
across various input modalities are analyzed, including text, visual, audio,
and multimodal inputs. Finally, we summarize key challenges and limitations in
current research and propose future directions to advance the task planning
capabilities of service robots in complex, unstructured domestic environments.
This review aims to serve as a valuable reference for researchers and
practitioners in the fields of artificial intelligence and robotics.

</details>


### [502] [T-ESKF: Transformed Error-State Kalman Filter for Consistent Visual-Inertial Navigation](https://arxiv.org/abs/2510.23359)
*Chungeng Tian,Ning Hao,Fenghua He*

Main category: cs.RO

TL;DR: 该研究提出了一种转换后的误差状态卡尔曼滤波器（T-ESKF）来解决视觉-惯性导航系统（VINS）中的可观测性不匹配问题，通过在误差状态上应用时变线性变换，使不可观子空间与状态解耦，从而提高估计精度和鲁棒性，并通过仿真和实验验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 视觉-惯性导航系统（VINS）在存在可观测性不匹配时会出现不一致性问题。

Method: 提出了一种转换后的误差状态卡尔曼滤波器（T-ESKF），通过在线性时变系统上对误差状态进行线性变换，使得非观测子空间与状态无关，从而保持了转换后系统的可观测性。此外，还提出了一种高效的协方差传播技术。

Result: 通过仿真和实验证明，T-ESKF 的性能优于（或至少具有竞争力）现有最先进的方法。

Conclusion: 提出的 T-ESKF 是一种一致性的 VINS 估计器，能够有效解决可观测性不匹配问题，并具有高效的协方差传播能力。

Abstract: This paper presents a novel approach to address the inconsistency problem
caused by observability mismatch in visual-inertial navigation systems (VINS).
The key idea involves applying a linear time-varying transformation to the
error-state within the Error-State Kalman Filter (ESKF). This transformation
ensures that \textrr{the unobservable subspace of the transformed error-state
system} becomes independent of the state, thereby preserving the correct
observability of the transformed system against variations in linearization
points. We introduce the Transformed ESKF (T-ESKF), a consistent VINS estimator
that performs state estimation using the transformed error-state system.
Furthermore, we develop an efficient propagation technique to accelerate the
covariance propagation based on the transformation relationship between the
transition and accumulated matrices of T-ESKF and ESKF. We validate the
proposed method through extensive simulations and experiments, demonstrating
better (or competitive at least) performance compared to state-of-the-art
methods. The code is available at github.com/HITCSC/T-ESKF.

</details>


### [503] [Full-Dynamics Real-Time Nonlinear Model Predictive Control of Heavy-Duty Hydraulic Manipulator for Trajectory Tracking Tasks](https://arxiv.org/abs/2510.23386)
*Alvaro Paz,Mahdi Hejrati,Pauli Mustalahti,Jouni Mattila*

Main category: cs.RO

TL;DR: 该研究提出了一个用于重型液压机械臂 (HHMs) 的非线性模型预测控制 (NMPC) 框架，以确保在 1 kHz 的实时控制频率下满足执行器约束，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 重型液压机械臂 (HHMs) 的运行受到严格的物理和安全关键约束，需要实时控制来确保关节和末端执行器轨迹的顺从性，但这在现有的实时控制框架中探索不足。

Method: 该研究提出了一个非线性模型预测控制 (NMPC) 框架，结合了多重 shooting 策略和实时传感器反馈，并辅以基于虚拟分解控制 (VDC) 的低级控制器，以实现精确的关节跟踪和实时 1 kHz 的控制频率。

Result: 实验结果表明，该 NMPC 框架能够强制执行关节级别的执行器约束，并确保末端执行器在笛卡尔空间中进行符合约束的运动，实现了高精度轨迹跟踪和严格的安全限制。

Conclusion: 该 NMPC 框架能够在高精度轨迹跟踪和严格遵守安全关键限制之间取得平衡，为大型液压系统的实时控制树立了新的基准。

Abstract: Heavy-duty hydraulic manipulators (HHMs) operate under strict physical and
safety-critical constraints due to their large size, high power, and complex
nonlinear dynamics. Ensuring that both joint-level and end-effector
trajectories remain compliant with actuator capabilities, such as force,
velocity, and position limits, is essential for safe and reliable operation,
yet remains largely underexplored in real-time control frameworks. This paper
presents a nonlinear model predictive control (NMPC) framework designed to
guarantee constraint satisfaction throughout the full nonlinear dynamics of
HHMs, while running at a real-time control frequency of 1 kHz. The proposed
method combines a multiple-shooting strategy with real-time sensor feedback,
and is supported by a robust low-level controller based on virtual
decomposition control (VDC) for precise joint tracking. Experimental validation
on a full-scale hydraulic manipulator shows that the NMPC framework not only
enforces actuator constraints at the joint level, but also ensures
constraint-compliant motion in Cartesian space for the end-effector. These
results demonstrate the method's capability to deliver high-accuracy trajectory
tracking while strictly respecting safety-critical limits, setting a new
benchmark for real-time control in large-scale hydraulic systems.

</details>


### [504] [COOPERA: Continual Open-Ended Human-Robot Assistance](https://arxiv.org/abs/2510.23495)
*Chenyang Ma,Kai Lu,Ruta Desai,Xavier Puig,Andrew Markham,Niki Trigoni*

Main category: cs.RO

TL;DR: COOPERA是一个新框架，用于持续、开放式人机协作，通过模拟具有心理特征和长期意图的人类与机器人进行交互，从而实现对长期、开放式人机协作的研究。


<details>
  <summary>Details</summary>
Motivation: 当前大多数机器人助手缺乏理解和适应个体人类特征、习惯和活动的能力，限制了它们在结构化环境之外的协作能力。

Method: COOPERA框架通过整合持续的人类反馈，并引入一个基准和一种方法来学习人类特征和上下文相关的意图，从而实现机器人协作行为的个性化。

Result: 实验证明了模拟人类能够反映真实的类人行为，并验证了推断和个性化人类意图对于开放式和长期人机协作的价值。

Conclusion: COOPERA框架能够实现对长期、开放式人机协作的研究，并通过个性化机器人行为来提升协作效率。

Abstract: To understand and collaborate with humans, robots must account for individual
human traits, habits, and activities over time. However, most robotic
assistants lack these abilities, as they primarily focus on predefined tasks in
structured environments and lack a human model to learn from. This work
introduces COOPERA, a novel framework for COntinual, OPen-Ended human-Robot
Assistance, where simulated humans, driven by psychological traits and
long-term intentions, interact with robots in complex environments. By
integrating continuous human feedback, our framework, for the first time,
enables the study of long-term, open-ended human-robot collaboration (HRC) in
different collaborative tasks across various time-scales. Within COOPERA, we
introduce a benchmark and an approach to personalize the robot's collaborative
actions by learning human traits and context-dependent intents. Experiments
validate the extent to which our simulated humans reflect realistic human
behaviors and demonstrate the value of inferring and personalizing to human
intents for open-ended and long-term HRC. Project Page:
https://dannymcy.github.io/coopera/

</details>


### [505] [Deductive Chain-of-Thought Augmented Socially-aware Robot Navigation World Model](https://arxiv.org/abs/2510.23509)
*Weizheng Wang,Obi Ike,Soyun Choi,Sungeun Hong,Byung-Cheol Min*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Social robot navigation increasingly relies on large language models for
reasoning, path planning, and enabling movement in dynamic human spaces.
However, relying solely on LLMs for planning often leads to unpredictable and
unsafe behaviors, especially in dynamic human spaces, due to limited physical
grounding and weak logical consistency. In this work, we introduce NaviWM, a
socially-aware robot Navigation World Model that augments LLM reasoning with a
structured world model and a logic-driven chain-of-thought process. NaviWM
consists of two main components: (1) a spatial-temporal world model that
captures the positions, velocities, and activities of agents in the
environment, and (2) a deductive reasoning module that guides LLMs through a
multi-step, logic-based inference process. This integration enables the robot
to generate navigation decisions that are both socially compliant and
physically safe, under well-defined constraints such as personal space,
collision avoidance, and timing. Unlike previous methods based on prompting or
fine-tuning, NaviWM encodes social norms as first-order logic, enabling
interpretable and verifiable reasoning. Experiments show that NaviWM improves
success rates and reduces social violations, particularly in crowded
environments. These results demonstrate the benefit of combining formal
reasoning with LLMs for robust social navigation. Additional experimental
details and demo videos for this work can be found at:
https://sites.google.com/view/NaviWM.

</details>


### [506] [Dexbotic: Open-Source Vision-Language-Action Toolbox](https://arxiv.org/abs/2510.23511)
*Bin Xie,Erjin Zhou,Fan Jia,Hao Shi,Haoqiang Fan,Haowei Zhang,Hebei Li,Jianjian Sun,Jie Bin,Junwen Huang,Kai Liu,Kaixin Liu,Kefan Gu,Lin Sun,Meng Zhang,Peilong Han,Ruitao Hao,Ruitao Zhang,Saike Huang,Songhan Xie,Tiancai Wang,Tianle Liu,Wenbin Tang,Wenqi Zhu,Yang Chen,Yingfei Liu,Yizhuang Zhou,Yu Liu,Yucheng Zhao,Yunchao Ma,Yunfei Wei,Yuxiang Chen,Ze Chen,Zeming Li,Zhao Wu,Ziheng Zhang,Ziming Liu,Ziwei Yan,Ziyu Zhang*

Main category: cs.RO

TL;DR: Dexbotic是一个基于PyTorch的开源视觉-语言-动作(VLA)模型工具箱，旨在为具身智能领域的研究人员提供一站式服务，支持多种主流VLA策略，并提供更强的预训练模型以提升性能。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在为具身智能领域的专业人士提供一个一站式的VLA研究服务，支持多种主流VLA策略，简化实验设置，并通过提供更强的预训练模型来提升现有VLA策略的性能。

Method: Dexbotic提供了支持多种主流VLA策略的单一环境设置代码库，允许用户通过修改Exp脚本快速开发新的VLA实验。此外，该工具箱还提供了更强的预训练模型。

Result: Dexbotic在实验中展示了其能够显著提升现有VLA策略的性能，并且易于用户进行新的VLA实验开发。

Conclusion: Dexbotic作为一个开源的VLA模型工具箱，通过提供便捷的研究环境、强大的预训练模型和持续的更新，将有力地推动具身智能领域的发展。

Abstract: In this paper, we present Dexbotic, an open-source Vision-Language-Action
(VLA) model toolbox based on PyTorch. It aims to provide a one-stop VLA
research service for professionals in the field of embodied intelligence. It
offers a codebase that supports multiple mainstream VLA policies
simultaneously, allowing users to reproduce various VLA methods with just a
single environment setup. The toolbox is experiment-centric, where the users
can quickly develop new VLA experiments by simply modifying the Exp script.
Moreover, we provide much stronger pretrained models to achieve great
performance improvements for state-of-the-art VLA policies. Dexbotic will
continuously update to include more of the latest pre-trained foundation models
and cutting-edge VLA models in the industry.

</details>


### [507] [Localising under the drape: proprioception in the era of distributed surgical robotic system](https://arxiv.org/abs/2510.23512)
*Martin Huber,Nicola A. Cavalcanti,Ayoob Davoodi,Ruixuan Li,Christopher E. Mower,Fabio Carrillo,Christoph J. Laux,Francois Teyssere,Thibault Chandanson,Antoine Harlé,Elie Saghbiny,Mazda Farshad,Guillaume Morel,Emmanuel Vander Poorten,Philipp Fürnstahl,Sébastien Ourselin,Christos Bergeles,Tom Vercauteren*

Main category: cs.RO

TL;DR: 本研究提出了一种无需标记物的空间感知方法，用于实现手术机器人（即使覆盖无菌罩）的精确定位，解决了现有系统依赖笨重红外摄像头和标记物的问题。


<details>
  <summary>Details</summary>
Motivation: 手术机器人缺乏对周围环境的空间感知能力，会导致碰撞、系统恢复和工作流程中断等问题，而现有追踪系统存在设备笨重、视野受限和增加手术室负担的缺点。

Method: 提出了一种无需标记物的空间感知方法，仅使用轻量级的立体RGB摄像头和基于Transformer的深度学习模型，并利用了迄今为止最大的多中心空间机器人手术数据集（包含1.4M张来自人体尸体和临床前体内研究的自标注图像）。该方法追踪整个机器人和手术场景，而非单个标记物。

Result: 该方法消除了标记物，并将追踪可见性提高了25%。在体内呼吸补偿任务中，该方法能够提供可观察到的组织动态信息，并能准确地在多机器人系统中进行定位，支持未来的智能交互。

Conclusion: 本研究首次实现了全覆盖手术机器人的无标记物空间感知，降低了设置复杂性，提高了安全性，为模块化和自主机器人手术铺平了道路。

Abstract: Despite their mechanical sophistication, surgical robots remain blind to
their surroundings. This lack of spatial awareness causes collisions, system
recoveries, and workflow disruptions, issues that will intensify with the
introduction of distributed robots with independent interacting arms. Existing
tracking systems rely on bulky infrared cameras and reflective markers,
providing only limited views of the surgical scene and adding hardware burden
in crowded operating rooms. We present a marker-free proprioception method that
enables precise localisation of surgical robots under their sterile draping
despite associated obstruction of visual cues. Our method solely relies on
lightweight stereo-RGB cameras and novel transformer-based deep learning
models. It builds on the largest multi-centre spatial robotic surgery dataset
to date (1.4M self-annotated images from human cadaveric and preclinical in
vivo studies). By tracking the entire robot and surgical scene, rather than
individual markers, our approach provides a holistic view robust to occlusions,
supporting surgical scene understanding and context-aware control. We
demonstrate an example of potential clinical benefits during in vivo breathing
compensation with access to tissue dynamics, unobservable under state of the
art tracking, and accurately locate in multi-robot systems for future
intelligent interaction. In addition, and compared with existing systems, our
method eliminates markers and improves tracking visibility by 25%. To our
knowledge, this is the first demonstration of marker-free proprioception for
fully draped surgical robots, reducing setup complexity, enhancing safety, and
paving the way toward modular and autonomous robotic surgery.

</details>


### [508] [Explicit Memory through Online 3D Gaussian Splatting Improves Class-Agnostic Video Segmentation](https://arxiv.org/abs/2510.23521)
*Anthony Opipari,Aravindhan K Krishnan,Shreekant Gayaka,Min Sun,Cheng-Hao Kuo,Arnie Sen,Odest Chadwicke Jenkins*

Main category: cs.RO

TL;DR: 本文提出了一种使用显式3D内存来增强视频分割模型的方法，通过在线3D高斯泼溅技术存储和融合过去的分割信息，提高了分割的准确性和一致性。


<details>
  <summary>Details</summary>
Motivation: 过去的视频分割算法要么不使用对象级内存，要么使用隐式内存（如RNN特征），这限制了其精度和一致性。因此，需要一种更有效的方法来利用历史分割信息。

Method: 开发了一种在线3D高斯泼溅（3DGS）技术，用于存储视频中预测的对象级分割。基于此3DGS表示，开发了一系列融合技术（FastSAM-Splat和SAM2-Splat），利用显式的3DGS内存来改进基础模型。

Result: 在真实世界和模拟的基准实验中，使用显式3D内存的模型比不使用内存或仅使用隐式内存的模型产生了更准确、更一致的预测。

Conclusion: 显式3D内存（通过3DGS实现）可以显著提高视频分割模型的准确性和一致性，优于无内存或仅有隐式内存的方法。

Abstract: Remembering where object segments were predicted in the past is useful for
improving the accuracy and consistency of class-agnostic video segmentation
algorithms. Existing video segmentation algorithms typically use either no
object-level memory (e.g. FastSAM) or they use implicit memories in the form of
recurrent neural network features (e.g. SAM2). In this paper, we augment both
types of segmentation models using an explicit 3D memory and show that the
resulting models have more accurate and consistent predictions. For this, we
develop an online 3D Gaussian Splatting (3DGS) technique to store predicted
object-level segments generated throughout the duration of a video. Based on
this 3DGS representation, a set of fusion techniques are developed, named
FastSAM-Splat and SAM2-Splat, that use the explicit 3DGS memory to improve
their respective foundation models' predictions. Ablation experiments are used
to validate the proposed techniques' design and hyperparameter settings.
Results from both real-world and simulated benchmarking experiments show that
models which use explicit 3D memories result in more accurate and consistent
predictions than those which use no memory or only implicit neural network
memories. Project Page: https://topipari.com/projects/FastSAM-Splat/

</details>


### [509] [RobotArena $\infty$: Scalable Robot Benchmarking via Real-to-Sim Translation](https://arxiv.org/abs/2510.23571)
*Yash Jangir,Yidi Zhang,Kashu Yamazaki,Chenyu Zhang,Kuan-Hsun Tu,Tsung-Wei Ke,Lei Ke,Yonatan Bisk,Katerina Fragkiadaki*

Main category: cs.RO

TL;DR: 本研究提出了一种新的机器人策略评估框架，利用大规模模拟环境和在线人类反馈，解决了现实世界测试的局限性。


<details>
  <summary>Details</summary>
Motivation: 机器人通用性的评估面临现实世界测试成本高、速度慢、不安全且难以复制的挑战，现有模拟基准也无法评估真实世界或不同模拟环境中训练的策略。

Method: 该框架利用视觉-语言模型、2D到3D生成模型和可微分渲染技术，将视频演示转换为模拟环境。在这些数字孪生中，使用VLM指导的自动评分和众包的人类偏好判断来评估VLA策略。通过系统地扰动模拟环境（如纹理和物体放置）来测试策略的泛化能力。

Result: 创建了一个可扩展、可复现且持续进化的基准，用于评估在真实世界训练的机器人操控策略。

Conclusion: 该框架克服了现有机器人策略评估的挑战，提供了一个解决当前机器人领域关键缺失能力的解决方案。

Abstract: The pursuit of robot generalists - instructable agents capable of performing
diverse tasks across diverse environments - demands rigorous and scalable
evaluation. Yet real-world testing of robot policies remains fundamentally
constrained: it is labor-intensive, slow, unsafe at scale, and difficult to
reproduce. Existing simulation benchmarks are similarly limited, as they train
and test policies within the same synthetic domains and cannot assess models
trained from real-world demonstrations or alternative simulation environments.
As policies expand in scope and complexity, these barriers only intensify,
since defining "success" in robotics often hinges on nuanced human judgments of
execution quality. In this paper, we introduce a new benchmarking framework
that overcomes these challenges by shifting VLA evaluation into large-scale
simulated environments augmented with online human feedback. Leveraging
advances in vision-language models, 2D-to-3D generative modeling, and
differentiable rendering, our approach automatically converts video
demonstrations from widely used robot datasets into simulated counterparts.
Within these digital twins, we assess VLA policies using both automated
VLM-guided scoring and scalable human preference judgments collected from
crowdworkers, transforming human involvement from tedious scene setup,
resetting, and safety supervision into lightweight preference comparisons. To
measure robustness, we systematically perturb simulated environments along
multiple axes, such as textures and object placements, stress-testing policy
generalization under controlled variation. The result is a continuously
evolving, reproducible, and scalable benchmark for real-world trained robot
manipulation policies, addressing a critical missing capability in today's
robotics landscape.

</details>


### [510] [UrbanVLA: A Vision-Language-Action Model for Urban Micromobility](https://arxiv.org/abs/2510.23576)
*Anqi Li,Zhiyong Wang,Jiazhao Zhang,Minghan Li,Yunpeng Qi,Zhibo Chen,Zhizheng Zhang,He Wang*

Main category: cs.RO

TL;DR: UrbanVLA是一个用于大规模城市导航的视觉-语言-动作（VLA）框架，通过对齐视觉观察和路线点来规划机器人轨迹，并结合监督微调和强化微调来掌握低级和高级导航技能。


<details>
  <summary>Details</summary>
Motivation: 现有导航方法难以应对真实城市环境的动态性和非结构性，而城市微出行（如送货机器人）需要可靠的、遵循长程路线指令的导航能力，包括点目标到达、避障和路线-视觉对齐等高级技能。

Method: 提出UrbanVLA框架，通过对齐路线航点与视觉观察来规划机器人轨迹。采用两阶段训练：首先在模拟环境和网络视频轨迹上进行监督微调（SFT），然后结合模拟和真实世界数据进行强化微调（RFT），以提高模型在真实环境中的安全性和适应性。

Result: 在MetaUrban的SocialNav任务上，UrbanVLA的表现比现有基线方法提高了55%以上。此外，UrbanVLA在真实世界导航中表现出可靠性，能够扩展到大规模城市环境，并能应对现实世界中的不确定性。

Conclusion: UrbanVLA框架在应对大规模城市导航的挑战方面取得了显著成效，能够实现可靠、可扩展和鲁棒的导航。

Abstract: Urban micromobility applications, such as delivery robots, demand reliable
navigation across large-scale urban environments while following long-horizon
route instructions. This task is particularly challenging due to the dynamic
and unstructured nature of real-world city areas, yet most existing navigation
methods remain tailored to short-scale and controllable scenarios. Effective
urban micromobility requires two complementary levels of navigation skills:
low-level capabilities such as point-goal reaching and obstacle avoidance, and
high-level capabilities, such as route-visual alignment. To this end, we
propose UrbanVLA, a route-conditioned Vision-Language-Action (VLA) framework
designed for scalable urban navigation. Our method explicitly aligns noisy
route waypoints with visual observations during execution, and subsequently
plans trajectories to drive the robot. To enable UrbanVLA to master both levels
of navigation, we employ a two-stage training pipeline. The process begins with
Supervised Fine-Tuning (SFT) using simulated environments and trajectories
parsed from web videos. This is followed by Reinforcement Fine-Tuning (RFT) on
a mixture of simulation and real-world data, which enhances the model's safety
and adaptability in real-world settings. Experiments demonstrate that UrbanVLA
surpasses strong baselines by more than 55% in the SocialNav task on MetaUrban.
Furthermore, UrbanVLA achieves reliable real-world navigation, showcasing both
scalability to large-scale urban environments and robustness against real-world
uncertainties.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [511] [Automated Tinnitus Detection Through Dual-Modality Neuroimaging: EEG Microstate Analysis and Resting-State fMRI Classification Using Deep Learning](https://arxiv.org/abs/2510.21748)
*Kiana Kiashemshaki,Sina Samieirad,Sarvenaz Erfani,Aryan Jalaeianbanayan,Nasibeh Asadi Isakan,Hossein Najafzadeh*

Main category: eess.SP

TL;DR: 本研究利用机器学习分析脑电图（EEG）和功能性磁共振成像（fMRI）数据，成功识别出区分耳鸣患者和健康对照组的神经特征，并开发出高精度的分类模型。


<details>
  <summary>Details</summary>
Motivation: 耳鸣影响10-15%的人口，但缺乏客观的诊断生物标志物。本研究旨在利用机器学习寻找区分耳鸣患者和健康对照组的神经特征。

Method: 研究分析了两组数据：80名参与者（40名耳鸣，40名健康）的64导联脑电图（EEG）记录，以及38名参与者（19名耳鸣，19名健康）的静息态功能性磁共振成像（fMRI）数据。EEG分析提取了4-7个聚类状态和5个频带下的微状态特征，共产生440个特征/受试者。还将全局场功率信号转换为小波图像用于深度学习。fMRI数据使用逐层卷积神经网络和结合预训练架构（VGG16、ResNet50）与决策树、随机森林和SVM分类器的混合模型进行分析。使用5倍交叉验证评估模型性能，基于准确率、精确率、召回率、F1分数和ROC-AUC。

Result: EEG微状态分析显示耳鸣患者的网络动力学改变，特别是γ波段微状态B的出现频率降低（健康组：56.56 vs 耳鸣组：43.81，p < 0.001），α波段覆盖范围减小。基于树的模型分类器准确率最高达到98.8%，而VGG16在小波变换的EEG数据的δ和α波段准确率分别为95.4%和94.1%。fMRI分析确定了12个高性能轴向切片（准确率>=90%），其中切片17的准确率达到99.0%。混合VGG16-决策树模型准确率为98.95% +/- 2.94%。

Conclusion: EEG和fMRI能够为耳鸣分类提供有效的神经生物标志物。基于树的模型和混合模型表现出优越的性能，凸显了耳鸣作为一种需要多模态分析的多网络疾病的特性。

Abstract: Objective: Tinnitus affects 10-15% of the population yet lacks objective
diagnostic biomarkers. This study applied machine learning to EEG and fMRI data
to identify neural signatures distinguishing tinnitus patients from healthy
controls. Methods: Two datasets were analyzed: 64-channel EEG recordings from
80 participants (40 tinnitus, 40 controls) and resting-state fMRI data from 38
participants (19 tinnitus, 19 controls). EEG analysis extracted microstate
features across four to seven clustering states and five frequency bands,
producing 440 features per subject. Global Field Power signals were also
transformed into wavelet images for deep learning. fMRI data were analyzed
using slice-wise convolutional neural networks and hybrid models combining
pre-trained architectures (VGG16, ResNet50) with Decision Tree, Random Forest,
and SVM classifiers. Model performance was evaluated using 5-fold
cross-validation based on accuracy, precision, recall, F1-score, and ROC-AUC.
Results: EEG microstate analysis revealed altered network dynamics in tinnitus,
particularly reduced gamma-band microstate B occurrence (healthy: 56.56 vs
tinnitus: 43.81, p < 0.001) and diminished alpha coverage. Tree-based
classifiers achieved up to 98.8% accuracy, while VGG16 on wavelet-transformed
EEG yielded 95.4% and 94.1% accuracy for delta and alpha bands, respectively.
fMRI analysis identified 12 high-performing axial slices (>=90% accuracy), with
slice 17 reaching 99.0%. The hybrid VGG16-Decision Tree model achieved 98.95%
+/- 2.94% accuracy. Conclusion: EEG and fMRI provided effective neural
biomarkers for tinnitus classification. Tree-based and hybrid models
demonstrated superior performance, highlighting tinnitus as a multi-network
disorder requiring multimodal analysis.

</details>


### [512] [Monitoring Real-Time ECG Signals on Mobile Systems](https://arxiv.org/abs/2510.21789)
*Beyazit Bestami Yuksel*

Main category: eess.SP

TL;DR: 该研究开发了一个基于移动系统的实时心电图(ECG)信号监测开发套件。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在开发一种便携式系统，能够实时监测心电图信号，并通过非侵入式方法在移动设备上显示，并在信号异常时发出警报。

Method: 使用Einthoven's triangle方法将ECG电极放置在身体的特定区域，并通过Visual Studio .NET平台开发的软件通过串行端口读取和显示ECG信号。当信号低于或达到特定阈值时，系统会根据医学数据提供警报反馈。

Result: 开发了一个完全便携的系统，能够实时监测ECG信号，并在移动设备上以图形方式显示，并在信号异常时提供警报。

Conclusion: 该系统不仅可以实时监测ECG信号，还有潜力成为一个多功能系统，可用于在线病人监护、病人位置追踪，甚至使用除颤器进行初步干预。

Abstract: This study focuses on the connection of a development kit that enables
real-time monitoring of electrocardiogram (ECG) signals using a mobile system.
A software developed on the Visual Studio .NET platform reads real-time ECG
signals from the human body through non invasive methods and displays them
graphically on the mobile system. ECG electrodes placed on specific areas of
the body using the method known as Einthoven's triangle. Subsequently, the
software initiates data flow through the serial port, and these data displayed
as signal values on the mobile device's screen via a graphical interface. When
the monitored ECG signals fall below a certain threshold or reach a critical
value, the system provides feedback with an alert based on medical data. The
developed system is fully portable. Additionally, the implemented system has
the potential to form the basis for a multi-purpose system in the future, such
as online patient monitoring, patient location tracking, and even initial
intervention using the defibrillation method.

</details>


### [513] [Adaptive Split-MMD Training for Small-Sample Cross-Dataset P300 EEG Classification](https://arxiv.org/abs/2510.21969)
*Weiyu Chen,Arnaud Delorme*

Main category: eess.SP

TL;DR: 为解决单次试验P300检测中少量标记数据和跨数据集迁移学习中的域偏移问题，提出了一种名为AS-MMD的自适应迁移学习方法，该方法结合了目标加权损失、分割批归一化和无参数的MMD正则化项，并在EEG Conformer模型上进行了验证，取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 单次试验P300检测在标记数据稀疏时面临挑战。当使用迁移学习来增强小目标数据集时，会遇到跨数据集的域偏移问题。

Method: 提出了一种名为自适应分割最大均值差异训练（AS-MMD）的方法，结合了目标加权损失（具有与源/目标大小比的平方根相关的预热）、分割批归一化（具有共享仿射参数和每域运行统计）以及使用中值带宽启发式的无参数对数级别径向基函数核最大均值差异项。该方法被实现为EEG Conformer的一个组成部分，不依赖于骨干网络，并且在推理时保持模型不变。

Result: AS-MMD在两个公共视觉异类事件相关电位数据集（Active Visual Oddball 和 ERP CORE P3）之间以及两个方向的迁移中，均优于仅使用目标数据和混合池化训练的方法。与混合池化训练相比，AS-MMD的准确率/AUC分别提高了（0.66/0.74 vs 0.5/0.5）和（0.61/0.65 vs 0.5/0.5），这些提升在校正的配对t检验下具有显著性。消融研究表明，AS-MMD的三个组成部分都对性能提升做出了贡献。

Conclusion: AS-MMD能够有效地缓解小样本设置下跨数据集P300检测的域偏移问题，并且其各个组成部分都对性能的提升起到了积极作用。

Abstract: Detecting single-trial P300 from EEG is difficult when only a few labeled
trials are available. When attempting to boost a small target set with a large
source dataset through transfer learning, cross-dataset shift arises. To
address this challenge, we study transfer between two public visual-oddball ERP
datasets using five shared electrodes (Fz, Pz, P3, P4, Oz) under a strict
small-sample regime (target: 10 trials/subject; source: 80 trials/subject). We
introduce Adaptive Split Maximum Mean Discrepancy Training (AS-MMD), which
combines (i) a target-weighted loss with warm-up tied to the square root of the
source/target size ratio, (ii) Split Batch Normalization (Split-BN) with shared
affine parameters and per-domain running statistics, and (iii) a parameter-free
logit-level Radial Basis Function kernel Maximum Mean Discrepancy (RBF-MMD)
term using the median-bandwidth heuristic. Implemented on an EEG Conformer,
AS-MMD is backbone-agnostic and leaves the inference-time model unchanged.
Across both transfer directions, it outperforms target-only and pooled training
(Active Visual Oddball: accuracy/AUC 0.66/0.74; ERP CORE P3: 0.61/0.65), with
gains over pooling significant under corrected paired t-tests. Ablations
attribute improvements to all three components.

</details>


### [514] [Experimental Demonstration of Multi-Object Tracking in Integrated Sensing and Communication](https://arxiv.org/abs/2510.22180)
*Maximilian Bauhofer,Marcus Henninger,Meik Kottkamp,Lucas Giroto,Philip Grill,Alexander Felix,Thorsten Wild,Stephan ten Brink,Silvio Mandelli*

Main category: eess.SP

TL;DR: 本研究将概率假设密度（PHD）滤波器应用于5G通信系统中的多目标跟踪，解决了实际环境中存在的杂波和硬件限制等挑战，在实际场景中实现了<1.5m的平均绝对误差和>91%的检测率。


<details>
  <summary>Details</summary>
Motivation: 为了实现设想中的集成传感与通信（ISAC）应用场景，需要在蜂窝通信系统中引入跟踪技术。尽管已存在多种多目标跟踪算法，但尚未应用于实际的ISAC系统，而实际ISAC系统面临杂波和非最优硬件等挑战。

Method: 本研究在距离-多普勒速度域中，基于概率假设密度（PHD）滤波器，使用符合5G标准的ISAC概念验证设备，在真实的工厂环境中，通过雷达目标模拟器生成类似行人的目标，采集测量数据，并详细介绍了从测量采集到评估的完整流程，特别关注了原始数据的后处理和跟踪本身。

Result: 通过端到端的评估和与仿真的对比，证明了该方法在真实且具有挑战性的场景下，具有良好的多目标跟踪性能，平均绝对误差小于1.5米，检测率大于91%。

Conclusion: 本研究成功地将PHD滤波器应用于实际的ISAC场景，实现了具有挑战性环境下的高精度多目标跟踪，为ISAC系统的发展提供了实证支持。

Abstract: For a wide range of envisioned integrated sensing and communication (ISAC)
use cases, it is necessary to incorporate tracking techniques into cellular
communication systems. While numerous multi-object tracking algorithms exist,
they have not yet been applied to real-world ISAC, with its challenges such as
clutter and non-optimal hardware. In this work, we showcase multi-object
tracking based on the probability hypothesis density (PHD) filter in the range
and Doppler speed domain. The measurements are taken with a 5G compliant ISAC
proof-of-concept in a real factory environment, where the pedestrian-like
objects are generated by a radar object emulator. We detail the complete
pipeline, from measurement acquisition to evaluation, with a focus on the
post-processing of the raw captured data and the tracking itself. Our
end-to-end evaluation and comparison to simulations show good multi-object
tracking performance with mean absolute error <1.5m and detection rates >91%
for realistic but challenging scenarios.

</details>


### [515] [Angular Estimation Comparison with ISAC PoC](https://arxiv.org/abs/2510.22297)
*Alexander Felix,Rudolf Hoffmann,Marcus Henninger,Stephan ten Brink,Silvio Mandelli*

Main category: eess.SP

TL;DR: ISAC系统仍将采用模拟或混合波束成形结构，但会限制角度估计能力。本文评估了基于最少角度采样点的角度估计方法，发现在角度估计方面，DFT插值方法比OMP方法表现更好。


<details>
  <summary>Details</summary>
Motivation: ISAC系统需要最优的角度估计和分离能力，以满足其应用需求。

Method: 评估了基于最少角度采样点的不同角度估计方法，包括DFT插值和OMP。

Result: DFT插值方法在整体估计性能上表现最佳，而OMP方法在估计单一、清晰目标时最准确。

Conclusion: DFT插值方法是ISAC系统中角度估计的更优选择。

Abstract: The introduction of Integrated Sensing and Communications (ISAC) in cellular
systems is not expected to result in a shift away from the popular choice of
cost- and energy-efficient analog or hybrid beamforming structures. However,
this comes at the cost of limiting the angular capabilities to a confined space
per acquisitions. Thus, as a prerequisite for the successful implementation of
numerous ISAC use cases, the need for an optimal angular estimation of targets
and their separation based on the minimal number of angular samples arises.
  In this work, different approaches for angular estimation based on a minimal,
DFT-based set of angular samples are evaluated. The samples are acquired
through sweeping multiple beams of an ISAC proof of concept (PoC) in the
industrial scenario of the ARENA2036. The study's findings indicate that
interpolation approaches are more effective for generalizing across different
types of angular scenarios. While the orthogonal matching pursuit (OMP)
approach exhibits the most accurate estimation for a single, strong and clearly
discriminable target, the DFT-based interpolation approach demonstrates the
best overall estimation performance.

</details>


### [516] [Data-driven, Wavelet-based Identification and Reduced-order Modeling of Linear Systems with Closely Spaced Modes](https://arxiv.org/abs/2510.22406)
*Anargyros Michaloliakos,Benjamin J. Chang,Lawrence A. Bergman,Alexander F. Vakakis*

Main category: eess.SP

TL;DR: 该研究提出了一种基于小波变换的模态识别和降阶建模方法，用于处理具有紧密间隔模态的线性动力学系统，克服了传统傅里叶方法的局限性，并通过数值和实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统傅里叶方法在处理具有紧密间隔模态的系统时存在局限性，无法可靠识别模态或准确捕捉模态交互。

Method: 利用连续小波变换（CWT）增强的时频分辨率，选择小波谱中的谐波区域来分离模态，然后通过逆连续小波变换（ICWT）将模态反演回时域，并利用希尔伯特变换提取瞬时相位，构建复模态矩阵来表征系统模态特性，最后利用识别的模态参数重构频率响应函数（FRFs）并建立降阶模型（ROM）。

Result: 该方法在数值模拟（非经典阻尼）和实验（飞机结构模型）中得到了验证，结果表明该方法能有效分离复杂的模态交互，并准确重现复杂结构系统的动力学响应。

Conclusion: 所提出的纯数据驱动的小波基框架能够有效地识别模态并建立降阶模型，即使在存在噪声、模型不确定性和模态干扰等挑战的情况下也能准确表征系统动力学。

Abstract: This work presents a purely data-driven, wavelet-based framework for modal
identification and reduced-order modeling of mechanical systems with assumed
linear dynamics characterized by closely spaced modes with classical or
non-classical damping distribution. Traditional Fourier-based methods often
fail to reliably identify closely spaced modes or accurately capture modal
interactions and complexities. To address these limitations, we propose a
methodology leveraging the enhanced time -frequency resolution capabilities of
the continuous wavelet transform (CWT). By selecting appropriate harmonic
regions within the wavelet spectra, we effectively isolate modes, and then
invert them back in the temporal domain by applying the inverse CWT (ICWT). In
this way we reconstruct the corresponding modal dynamics in the time domain.
Using the Hilbert transform, instantaneous phases are extracted for each
identified mode, enabling the introduction of a complexified modal matrix which
robustly characterizes the system's modal properties, even under challenging
perturbations such as noise and uncertainties due to modal interference and
unmodeled effects. The identified modal parameters are utilized to reconstruct
the frequency response functions (FRFs) of the system and to develop a
reduced-order model (ROM) that captures accurately the system's dominant
dynamical behavior valid in a specified frequency range.. Validation of the
methodology is conducted both with a numerical non-classical damping and an
experimental testbed representing a model of an airplane structure. Results
demonstrate the effectiveness of the proposed approach in resolving intricate
modal interactions and accurately reproducing the dynamic response of complex
structural systems.

</details>


### [517] [Genetic Optimization of a Software-Defined GNSS Receiver](https://arxiv.org/abs/2510.22417)
*Laura Train,Rodrigo Castellanos,Miguel Gómez-López*

Main category: eess.SP

TL;DR: SDR接收器的跟踪环路参数优化可提高高动态条件下的GNSS导航精度。


<details>
  <summary>Details</summary>
Motivation: COTS GNSS接收器在高动态条件下（如运载火箭）存在导航不连续的性能限制。

Method: 提出一种基于遗传算法的优化框架，用于自动搜索SDR接收器的跟踪环路参数（相位、频率、延迟）。

Result: 在模拟的GPS L1信号和三种动态条件下（火箭、LEO卫星、静态接收器）验证了该方法。结果显示，优化后的配置在静态、火箭和LEO场景下，最大位置误差分别为6米、12米和5米，最大速度误差分别为0.08米/秒、2.5米/秒和0.2米/秒。

Conclusion: 基于遗传算法的优化框架能够使SDR接收器在高动态条件下保持鲁棒且精确的PVT解算能力。

Abstract: Commercial off-the-shelf (COTS) Global Navigation Satellite System (GNSS)
receivers face significant limitations under high-dynamic conditions,
particularly in high-acceleration environments such as those experienced by
launch vehicles. These performance degradations, often observed as
discontinuities in the navigation solution, arise from the inability of
traditional tracking loop bandwidths to cope with rapid variations in
synchronization parameters. Software-Defined Radio (SDR) receivers overcome
these constraints by enabling flexible reconfiguration of tracking loops;
however, manual tuning involves a complex, multidimensional search and seldom
ensures optimal performance. This work introduces a genetic algorithm-based
optimization framework that autonomously explores the receiver configuration
space to determine optimal loop parameters for phase, frequency, and delay
tracking. The approach is validated within an SDR environment using
realistically simulated GPS L1 signals for three representative dynamic regimes
-guided rocket flight, Low Earth Orbit (LEO) satellite, and static
receiver-processed with the open-source GNSS-SDR architecture. Results
demonstrate that evolutionary optimization enables SDR receivers to maintain
robust and accurate Position, Velocity, and Time (PVT) solutions across diverse
dynamic conditions. The optimized configurations yielded maximum position and
velocity errors of approximately 6 m and 0.08 m/s for the static case, 12 m and
2.5 m/s for the rocket case, and 5 m and 0.2 m/s for the LEO case.

</details>


### [518] [Data-driven Exponential Framing for Pulsive Temporal Patterns without Repetition or Singularity](https://arxiv.org/abs/2510.22472)
*Yohei Kono,Yoshiyuki Tajima*

Main category: eess.SP

TL;DR: 该研究提出了一种名为数据驱动指数框架（DEF）的新方法，用于从少量重复或单一数据中提取脉冲式时间模式，并在制造应用中具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 从少量数据中提取脉冲式时间模式具有重要意义，但现有研究关注不足。

Method: 提出了一种基于时间延迟嵌入和数据驱动Hankel矩阵分析的方法，建立时间延迟坐标上的线性动力学系统模型，推导出具有不同指数衰减常数的离散时间基，并拟合到滑动窗口提取的子序列上，以量化模式的显现时长。

Result: 玩具模型实验表明，DEF能够识别多个具有不同长度的模式。实际应用中，DEF被应用于冲床的电流测量，并成功从真实世界的振荡数据中提取了多个模式。

Conclusion: DEF能够从少量数据中提取脉冲式时间模式，并在实际应用中展现出潜力。

Abstract: Extracting pulsive temporal patterns from a small dataset without their
repetition or singularity shows significant importance in manufacturing
applications but does not sufficiently attract scientific attention. We propose
to quantify how long temporal patterns appear without relying on their
repetition or singularity, enabling to extract such temporal patterns from a
small dataset. Inspired by the celebrated time delay embedding and data-driven
Hankel matrix analysis, we introduce a linear dynamical system model on the
time-delay coordinates behind the data to derive the discrete-time bases each
of which has a distinct exponential decay constant. The derived bases are
fitted onto subsequences that are extracted with a sliding window in order to
quantify how long patterns are dominant in the set of subsequences. We call the
quantification method Data-driven Exponential Framing (DEF). A toy model-based
experiment shows that DEF can identify multiple patterns with distinct lengths.
DEF is also applied to electric current measurement on a punching machine,
showing its possibility to extract multiple patterns from real-world
oscillatory data.

</details>


### [519] [Large-Model AI for Near Field Beam Prediction: A CNN-GPT2 Framework for 6G XL-MIMO](https://arxiv.org/abs/2510.22557)
*Wang Liu,Cunhua Pan,Hong Ren,Wei Zhang,Cheng-Xiang Wang,Jiangzhou Wang*

Main category: eess.SP

TL;DR: To address challenges in near-field beam prediction for extremely large-scale antenna arrays (ELAA) in high-mobility mmWave communications, such as increased pilot overhead and abrupt beam index dynamics, a CNN-GPT2 framework is proposed. This framework uses a novel uplink pilot transmission strategy with widebeam analog and frequency-varying digital precoding, followed by a CNN for feature extraction and a GPT-2 model to capture temporal dependencies and predict the near-field beam index.


<details>
  <summary>Details</summary>
Motivation: The emergence of ELAA in mmWave communications, especially in high-mobility scenarios, necessitates effective near-field beam prediction. Conventional methods struggle due to the need for joint angular and distance domain sampling, leading to high pilot overhead, and the abrupt, nonlinear dynamics of optimal near-field beam indices, which are difficult to model temporally.

Method: A novel CNN-GPT2 framework is proposed. It utilizes an uplink pilot transmission strategy with widebeam analog precoding and frequency-varying digital precoding for efficient channel probing. Received pilot signals are processed by a CNN-based feature extractor, and then fed into a GPT-2 model to capture temporal dependencies across frames and directly predict the near-field beam index in an end-to-end fashion.

Result: The paper proposes a CNN-GPT2 framework for near-field beam prediction, including a specific uplink pilot transmission strategy and preprocessing steps. The model aims to efficiently predict the near-field beam index by capturing both spatial features and temporal dynamics.

Conclusion: The proposed CNN-GPT2 framework offers a solution for near-field beam prediction in ELAA systems, tackling the issues of pilot overhead and complex beam dynamics through an integrated approach of pilot transmission, feature extraction, and temporal modeling.

Abstract: The emergence of extremely large-scale antenna arrays (ELAA) in
millimeter-wave (mmWave) communications, particularly in high-mobility
scenarios, highlights the importance of near-field beam prediction. Unlike the
conventional far-field assumption, near-field beam prediction requires
codebooks that jointly sample the angular and distance domains, which leads to
a dramatic increase in pilot overhead. Moreover, unlike the far-field case
where the optimal beam evolution is temporally smooth, the optimal near-field
beam index exhibits abrupt and nonlinear dynamics due to its joint dependence
on user angle and distance, posing significant challenges for temporal
modeling. To address these challenges, we propose a novel Convolutional Neural
Network-Generative Pre-trained Transformer 2 (CNN-GPT2) based near-field beam
prediction framework. Specifically, an uplink pilot transmission strategy is
designed to enable efficient channel probing through widebeam analog precoding
and frequency-varying digital precoding. The received pilot signals are
preprocessed and passed through a CNN-based feature extractor, followed by a
GPT-2 model that captures temporal dependencies across multiple frames and
directly predicts the near-field beam index in an end-to-end manner.

</details>


### [520] [Parametric Channel Estimation and Design for Active-RIS-Assisted Communications](https://arxiv.org/abs/2510.22621)
*Md. Shahriar Sadid,Ali A. Nasir,Saad Al-Ahmadi,Samir Al-Ghadhban*

Main category: eess.SP

TL;DR: 主动RIS的参数化信道估计方法，利用自适应MLE和角度-对码本，实现了低开销、高精度和高SE。


<details>
  <summary>Details</summary>
Motivation: 现有RIS技术受限于用户到RIS信道状态信息（CSI）获取困难，以及非参数方法的开销高。

Method: 提出一种主动RIS的参数化信道估计方法，集成主动RIS模型和自适应最大似然估计（MLE），并采用自适应主动RIS配置策略和正交角度-对码本。

Result: 提出的方法实现了近乎最优的性能，仅用少量导频就能超越非参数方法，并与传统无源RIS进行公平比较，证明了主动RIS具有更高的谱效率（SE），消除了无源RIS的乘性衰落。

Conclusion: 参数化信道估计方法和主动RIS模型相结合，能够以极低的开销实现高精度的信道估计，并提升系统的整体性能。

Abstract: Reconfigurable Intelligent Surface (RIS) technology has emerged as a key
enabler for future wireless communications. However, its potential is
constrained by the difficulty of acquiring accurate user-to-RIS channel state
information (CSI), due to the cascaded channel structure and the high pilot
overhead of non-parametric methods. Unlike a passive RIS, where the reflected
signal suffers from multiplicative path loss, an active RIS amplifies the
signal, improving its practicality in real deployments. In this letter, we
propose a parametric channel estimation method tailored for active RISs. The
proposed approach integrates an active RIS model with an adaptive Maximum
Likelihood Estimator (MLE) to recover the main channel parameters using a
minimal number of pilots. To further enhance performance, an adaptive active
RIS configuration strategy is employed, which refines the beam direction based
on an initial user location estimate. Moreover, an orthogonal angle-pair
codebook is used instead of the conventional Discrete Fourier Transform (DFT)
codebook, significantly reducing the codebook size and ensuring reliable
operation for both far-field and near-field users. Extensive simulations
demonstrate that the proposed method achieves near-optimal performance with
very few pilots compared to non-parametric approaches. Its performance is also
benchmarked against that of a traditional passive RIS under the same total
power budget to ensure fairness. Results show that active RIS yields higher
spectral efficiency (SE) by eliminating the multiplicative fading inherent in
passive RISs and allocating more resources to data transmission

</details>


### [521] [Enhancing WiFi CSI Fingerprinting: A Deep Auxiliary Learning Approach](https://arxiv.org/abs/2510.22731)
*Yong Huang,Wenjing Wang,Dalong Zhang,Junjie Wang,Chen Chen,Yan Cao,Wei Wang*

Main category: eess.SP

TL;DR: CSI2Q通过将CSI转换为时域信号并利用深度辅助学习从IQ模型迁移知识，实现了与IQ基方法相当的射频指纹识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于信道状态信息（CSI）的射频指纹识别方法存在粒度粗糙的问题，难以在开放世界环境中广泛应用。

Method: CSI2Q系统首先将频域CSI测量转换为时域信号，使其与IQ样本共享相同的特征空间。然后，利用深度辅助学习策略将IQ指纹识别模型的知识迁移到CSI模型。最后，结合OpenMax函数来估计未知信号的相似度。

Result: 在合成CSI数据集（85个设备）、实验室CSI数据集（10个WiFi路由器）和实际CSI数据集（25个WiFi路由器）上，CSI2Q的准确率分别提高了至少16%、20%和17%。

Conclusion: CSI2Q能够克服现有CSI指纹识别方法的局限性，在开放世界环境中实现与IQ基方法相当的性能。

Abstract: Radio frequency (RF) fingerprinting techniques provide a promising supplement
to cryptography-based approaches but rely on dedicated equipment to capture
in-phase and quadrature (IQ) samples, hindering their wide adoption. Recent
advances advocate easily obtainable channel state information (CSI) by
commercial WiFi devices for lightweight RF fingerprinting, while falling short
in addressing the challenges of coarse granularity of CSI measurements in an
open-world setting. In this paper, we propose CSI2Q, a novel CSI fingerprinting
system that achieves comparable performance to IQ-based approaches. Instead of
extracting fingerprints directly from raw CSI measurements, CSI2Q first
transforms frequency-domain CSI measurements into time-domain signals that
share the same feature space with IQ samples. Then, we employ a deep auxiliary
learning strategy to transfer useful knowledge from an IQ fingerprinting model
to the CSI counterpart. Finally, the trained CSI model is combined with an
OpenMax function to estimate the likelihood of unknown ones. We evaluate CSI2Q
on one synthetic CSI dataset involving 85 devices and two real CSI datasets,
including 10 and 25 WiFi routers, respectively. Our system achieves accuracy
increases of at least 16% on the synthetic CSI dataset, 20% on the in-lab CSI
dataset, and 17% on the in-the-wild CSI dataset.

</details>


### [522] [Neural-HAR: A Dimension-Gated CNN Accelerator for Real-Time Radar Human Activity Recognition](https://arxiv.org/abs/2510.22772)
*Yizhuo Wu,Francesco Fioranelli,Chang Gao*

Main category: eess.SP

TL;DR: Neural-HAR是一个针对资源受限平台的雷达人 activity 识别（HAR）的轻量级卷积神经网络加速器，通过其核心的GateCNN模块，在实现高精度的同时，显著降低了参数量和计算复杂度，并能在FPGA上实现低延迟和低功耗的边缘推理。


<details>
  <summary>Details</summary>
Motivation: 现有基于雷达的人 activity 识别（HAR）方法，特别是CNN/RNN和ViT/SSM变体，对于边缘部署来说通常过于庞大，无法满足实际的计算和内存预算。因此，需要开发轻量级的解决方案以实现资源受限平台上的实时HAR。

Method: 提出了一种名为Neural-HAR的维度门控CNN加速器，其核心是GateCNN。GateCNN是一个参数高效的多普勒-时间网络，它通过嵌入多普勒向量来强调随时间演变，并采用双路径门控卷积来调整多普勒感知的内容特征和时间门控，同时辅以残差路径以实现稳定的训练。

Result: 在University of Glasgow UoG2020连续雷达数据集上，GateCNN达到了86.4%的准确率，仅使用了2.7k参数和每次推理0.28M FLOPs，其复杂性远低于CNN-BiGRU。此外，在Xilinx Zynq-7000 Z-7007S的FPGA原型上，实现了107.5 $\mu$s的延迟和15 mW的动态功耗，并且仅使用了LUT和分布式RAM。

Conclusion: Neural-HAR成功展示了在资源受限平台（如FPGA）上实现实时、高能效的雷达HAR推理的可行性，其轻量级的GateCNN架构在性能和资源消耗之间取得了良好的平衡。

Abstract: Radar-based human activity recognition (HAR) is attractive for unobtrusive
and privacy-preserving monitoring, yet many CNN/RNN solutions remain too heavy
for edge deployment, and even lightweight ViT/SSM variants often exceed
practical compute and memory budgets. We introduce Neural-HAR, a
dimension-gated CNN accelerator tailored for real-time radar HAR on
resource-constrained platforms. At its core is GateCNN, a parameter-efficient
Doppler-temporal network that (i) embeds Doppler vectors to emphasize frequency
evolution over time and (ii) applies dual-path gated convolutions that modulate
Doppler-aware content features with temporal gates, complemented by a residual
path for stable training. On the University of Glasgow UoG2020 continuous radar
dataset, GateCNN attains 86.4% accuracy with only 2.7k parameters and 0.28M
FLOPs per inference, comparable to CNN-BiGRU at a fraction of the complexity.
Our FPGA prototype on Xilinx Zynq-7000 Z-7007S reaches 107.5 $\mu$s latency and
15 mW dynamic power using LUT-based ROM and distributed RAM only (zero
DSP/BRAM), demonstrating real-time, energy-efficient edge inference. Code and
HLS conversion scripts are available at https://github.com/lab-emi/AIRHAR.

</details>


### [523] [Rmd: Robust Modal Decomposition with Constrained Bandwidth](https://arxiv.org/abs/2510.22895)
*Wang Hao,Kuang Zhang,Hou Chengyu,Yang Yifan,Tan Chenxing,Fu Weifeng*

Main category: eess.SP

TL;DR: 该论文提出了一种名为鲁棒模态分解（RMD）的新方法，用于解决现有信号分解技术的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的信号分解方法（如EMD、VMD、SSA）存在各自的缺点，例如产生虚假模态或对噪声敏感，并且缺乏能够有效结合两者优点的统一方法。

Method: RMD将时间序列映射到相空间中的轨迹-GRAM矩阵，并通过引入带宽约束来增强噪声抵抗能力，从而保留信号的内在结构。

Result: 在合成和真实世界数据集（包括雷达回波、ECG、PCG和轴承故障检测）上的广泛实验表明，RMD方法有效且具有通用性。

Conclusion: RMD方法通过结合相空间映射和带宽约束，克服了现有模态分解技术的不足，并在多种信号分析任务中表现出优越的性能。

Abstract: Modal decomposition techniques, such as Empirical Mode Decomposition (EMD),
Variational Mode Decomposition (VMD), and Singular Spectrum Analysis (SSA),
have advanced time-frequency signal analysis since the early 21st century.
These methods are generally classified into two categories: numerical
optimization-based methods (EMD, VMD) and spectral decomposition methods (SSA)
that consider the physical meaning of signals. The former can produce spurious
modes due to the lack of physical constraints, while the latter is more
sensitive to noise and struggles with nonlinear signals. Despite continuous
improvements in these methods, a modal decomposition approach that effectively
combines the strengths of both categories remains elusive. This paper thus
proposes a Robust Modal Decomposition (RMD) method with constrained bandwidth,
which preserves the intrinsic structure of the signal by mapping the time
series into its trajectory-GRAM matrix in phase space. Moreover, the method
incorporates bandwidth constraints during the decomposition process, enhancing
noise resistance. Extensive experiments on synthetic and real-world datasets,
including millimeter-wave radar echoes, electrocardiogram (ECG),
phonocardiogram (PCG), and bearing fault detection data, demonstrate the
method's effectiveness and versatility. All code and dataset samples are
available on GitHub: https://github.com/Einstein-sworder/RMD.

</details>


### [524] [Clinic-Oriented Feasibility of a Sensor-Fused Wearable for Upper-Limb Function](https://arxiv.org/abs/2510.22913)
*Thanyanee Srichaisak,Arissa Ieochai,Aueaphum Aueawattthanaphisut*

Main category: eess.SP

TL;DR: 该研究评估了一种结合肌电信号（EMG）、惯性测量单元（IMU）、柔韧性和力传感器的新型可穿戴设备，用于辅助上肢康复。设备采用片上INT8推理（Tiny 1D-CNN/Transformer）和安全约束的辅助策略。在12名健康成人中进行的ADL任务测试表明，该设备能有效降低震颤（TI -0.092），增加运动范围（ROM +12.65%）和任务吞吐量（Reps +2.99 min⁻¹）。低至8.7毫秒的延迟和无不良事件的记录，证明了该技术的可行性，为未来患者研究奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 上肢无力和震颤（4-12赫兹）限制了日常生活活动（ADL）并降低了家庭康复的依从性。本研究旨在评估一种针对肱三头肌和拇长伸肌的传感器融合可穿戴设备的技​​术可行性以及临床医生关注的信号。

Method: 使用集成了表面肌电信号（EMG，1 kHz）、惯性测量单元（IMU，100-200 Hz）以及柔韧性和力传感器（flex/force sensors）的轻量级节点，并在设备上进行INT8推理（Tiny 1D-CNN/Transformer），同时结合安全约束的辅助策略（角度/扭矩/加加速度限制；失速/超时保护）。招募了12名健康成人参与者，执行了三项ADL任务。主要评估指标包括震颤指数（TI）、运动范围（ROM）和每分钟重复次数（Reps）。次要指标包括EMG中值频率斜率（评估疲劳趋势）、闭环延迟、会话完成率以及设备相关的不良事件。分析采用受试者级别配对中位数和BCa 95%置信区间，并在结果中报告精确的Wilcoxon P值。

Result: 辅助治疗与较低的震颤和提高的任务吞吐量相关：震颤指数（TI）降低了-0.092（95% CI [$-0.102$，$-0.079$]），运动范围（ROM）增加了+12.65%（95% CI [$+8.43$，$+13.89$]），每分钟重复次数（Reps）增加了+2.99次（95% CI [$+2.61$，$+3.35$]）。设备上处理的中值延迟为8.7毫秒，循环率为100 Hz；所有会话均成功完成，未发生与设备相关的不良事件。

Conclusion: 在初步技术可行性研究中，结合了低延迟、安全约束辅助的多模态传感技术，能够改善运动质量（TI下降）和吞吐量（ROM、Reps上升），支持其进入IRB批准的患者研究阶段。

Abstract: Background: Upper-limb weakness and tremor (4--12 Hz) limit activities of
daily living (ADL) and reduce adherence to home rehabilitation. Objective: To
assess technical feasibility and clinician-relevant signals of a sensor-fused
wearable targeting the triceps brachii and extensor pollicis brevis. Methods: A
lightweight node integrates surface EMG (1 kHz), IMU (100--200 Hz), and
flex/force sensors with on-device INT8 inference (Tiny 1D-CNN/Transformer) and
a safety-bounded assist policy (angle/torque/jerk limits; stall/time-out).
Healthy adults (n = 12) performed three ADL-like tasks. Primary outcomes:
Tremor Index (TI), range of motion (ROM), repetitions (Reps min$^{-1}$).
Secondary: EMG median-frequency slope (fatigue trend), closed-loop latency,
session completion, and device-related adverse events. Analyses used
subject-level paired medians with BCa 95\% CIs; exact Wilcoxon $p$-values are
reported in the Results. Results: Assistance was associated with lower tremor
prominence and improved task throughput: TI decreased by $-0.092$ (95\% CI
[$-0.102$, $-0.079$]), ROM increased by $+12.65\%$ (95\% CI [$+8.43$,
$+13.89$]), and Reps rose by $+2.99$ min$^{-1}$ (95\% CI [$+2.61$, $+3.35$]).
Median on-device latency was 8.7 ms at a 100 Hz loop rate; all sessions were
completed with no device-related adverse events. Conclusions: Multimodal
sensing with low-latency, safety-bounded assistance produced improved movement
quality (TI $\downarrow$) and throughput (ROM, Reps $\uparrow$) in a pilot
technical-feasibility setting, supporting progression to IRB-approved patient
studies. Trial registration: Not applicable (pilot non-clinical).

</details>


### [525] [Intelligent Multimodal Multi-Sensor Fusion-Based UAV Identification, Localization, and Countermeasures for Safeguarding Low-Altitude Economy](https://arxiv.org/abs/2510.22947)
*Yi Tao,Zhen Gao,Fangquan Ye,Jingbo Xu,Tao Song,Weidong Li,Yu Su,Lu Peng,Xiaomei Wu,Tong Qin,Zhongxiang Li,Dezhi Zheng*

Main category: eess.SP

TL;DR: 本文提出了一种基于深度学习的集成无人机管理与控制系统，通过多传感器融合实现无人机的精准识别、定位和协同反制，以应对低空空域安全挑战。


<details>
  <summary>Details</summary>
Motivation: 低空经济发展带来了无人机安全管理问题的突出，因此，精准识别、实时定位和有效反制已成为空域安全保障的核心挑战。

Method: 该系统集成了多模态多传感器融合感知、精准定位和协同反制。在检测层面，利用深度学习方法结合射频（RF）频谱特征分析、雷达探测、光电识别等手段，实现无人机的识别与分类。在定位层面，通过多传感器数据融合和空天地一体化通信网络，对无人机飞行状态进行实时跟踪与预测。在反制层面，采用“软杀伤”与“硬杀伤”相结合的综合措施，包括电磁信号干扰、导航欺骗、物理拦截等技术，形成从预警到最终处置的闭环管理控制过程。

Result: 该系统显著提升了低空无人机管理的响应效率和处置精度。

Conclusion: 该集成无人机管理与控制系统通过深度学习和多传感器融合，有效解决了低空无人机识别、定位和反制的核心挑战，提升了空域安全保障能力。

Abstract: The development of the low-altitude economy has led to a growing prominence
of uncrewed aerial vehicle (UAV) safety management issues. Therefore, accurate
identification, real-time localization, and effective countermeasures have
become core challenges in airspace security assurance. This paper introduces an
integrated UAV management and control system based on deep learning, which
integrates multimodal multi-sensor fusion perception, precise positioning, and
collaborative countermeasures. By incorporating deep learning methods, the
system combines radio frequency (RF) spectral feature analysis, radar
detection, electro-optical identification, and other methods at the detection
level to achieve the identification and classification of UAVs. At the
localization level, the system relies on multi-sensor data fusion and the
air-space-ground integrated communication network to conduct real-time tracking
and prediction of UAV flight status, providing support for early warning and
decision-making. At the countermeasure level, it adopts comprehensive measures
that integrate ``soft kill'' and ``hard kill'', including technologies such as
electromagnetic signal jamming, navigation spoofing, and physical interception,
to form a closed-loop management and control process from early warning to
final disposal, which significantly enhances the response efficiency and
disposal accuracy of low-altitude UAV management.

</details>


### [526] [PASS-Enhanced MEC: Joint Optimization of Task Offloading and Uplink PASS Beamforming](https://arxiv.org/abs/2510.22948)
*Zhaoming Hu,Ruikang Zhong,Xidong Mu,Dengao Li,Yuanwei Liu*

Main category: eess.SP

TL;DR: 一种新的PASS-MEC架构，通过深度强化学习优化任务卸载，以提高效率和降低延迟。


<details>
  <summary>Details</summary>
Motivation: 为了提高动态无线环境中移动边缘计算（MEC）的任务卸载效率和延迟性能。

Method: 提出了一种结合介质波导和可调捏缩天线的PASS系统，并将其应用于MEC架构。通过马尔可夫决策过程（MDP）和深度强化学习（DRL）来优化波束成形和任务卸载。提出了一种名为LBPPO的算法，以解决目标函数中的不稳定性问题，并考虑了节点和波导级别的负载均衡。

Result: 仿真结果表明，所提出的PASS增强MEC方法在用户数量多或发射功率高的情况下，比固定PA基线和传统MIMO辅助MEC具有更强的收敛能力。

Conclusion: PASS-MEC架构是一种有前景的高频MEC解决方案，能够通过优化的波束成形和任务卸载策略有效提高性能。

Abstract: A pinching-antenna system (PASS)-enhanced mobile edge computing (MEC)
architecture is investigated to improve the task offloading efficiency and
latency performance in dynamic wireless environments. By leveraging dielectric
waveguides and flexibly adjustable pinching antennas, PASS establishes
short-distance line-of-sight (LoS) links while effectively mitigating the
significant path loss and potential signal blockage, making it a promising
solution for high-frequency MEC systems. We formulate a network latency
minimization problem to joint optimize uplink PASS beamforming and task
offloading. The resulting problem is modeled as a Markov decision process (MDP)
and solved via the deep reinforcement learning (DRL) method. To address the
instability introduced by the $\max$ operator in the objective function, we
propose a load balancing-aware proximal policy optimization (LBPPO) algorithm.
LBPPO incorporates both node-level and waveguide-level load balancing
information into the policy design, maintaining computational and transmission
delay equilibrium, respectively. Simulation results demonstrate that the
proposed PASS-enhanced MEC with adaptive uplink PASS beamforming exhibit
stronger convergence capability than fixed-PA baselines and conventional
MIMO-assisted MEC, especially in scenarios with a large number of UEs or high
transmit power.

</details>


### [527] [Planning Oriented Integrated Sensing and Communication](https://arxiv.org/abs/2510.23021)
*Xibin Jin,Guoliang Li,Shuai Wang,Fan Liu,Miaowen Wen,Huseyin Arslan,Derrick Wing Kwan Ng,Chengzhong Xu*

Main category: eess.SP

TL;DR: 该论文提出了一种名为PISAC的框架，通过优化传感和通信来提高自动驾驶汽车的运动规划效率和安全性。


<details>
  <summary>Details</summary>
Motivation: 现有ISAC设计主要关注传感精度和通信吞吐量，忽视了关键障碍物对运动效率的影响。本研究旨在解决这一局限性。

Method: 提出PISAC框架，通过推导闭式安全边界，将ISAC发射功率与传感不确定性联系起来，并构建了一个双层功率分配与运动规划（PAMP）问题，内层优化ISAC波束功率分配，外层在考虑不确定性的安全约束下计算无碰撞轨迹。

Result: 仿真结果表明，PISAC在城市驾驶环境中，成功率提高了40%，通行时间缩短了5%以上，优于现有的基于ISAC和面向通信的基准。

Conclusion: PISAC框架能够有效减少规划瓶颈障碍物的传感不确定性，扩大可导航路径，从而提升自动驾驶汽车的安全性和效率。

Abstract: Integrated sensing and communication (ISAC) enables simultaneous
localization, environment perception, and data exchange for connected
autonomous vehicles. However, most existing ISAC designs prioritize sensing
accuracy and communication throughput, treating all targets uniformly and
overlooking the impact of critical obstacles on motion efficiency. To overcome
this limitation, we propose a planning-oriented ISAC (PISAC) framework that
reduces the sensing uncertainty of planning-bottleneck obstacles and expands
the safe navigable path for the ego-vehicle, thereby bridging the gap between
physical-layer optimization and motion-level planning. The core of PISAC lies
in deriving a closed-form safety bound that explicitly links ISAC transmit
power to sensing uncertainty, based on the Cram\'er-Rao Bound and occupancy
inflation principles. Using this model, we formulate a bilevel power allocation
and motion planning (PAMP) problem, where the inner layer optimizes the ISAC
beam power distribution and the outer layer computes a collision-free
trajectory under uncertainty-aware safety constraints. Comprehensive
simulations in high-fidelity urban driving environments demonstrate that PISAC
achieves up to 40% higher success rates and over 5% shorter traversal times
than existing ISAC-based and communication-oriented benchmarks, validating its
effectiveness in enhancing both safety and efficiency.

</details>


### [528] [HAPS-ISAC for 6G: Architecture, Design Trade-offs, and a Practical Roadmap](https://arxiv.org/abs/2510.23147)
*Parisa Kanani,Mohammad Javad Omidi,Mahmoud Modarres-Hashemi,Halim Yanikomeroglu*

Main category: eess.SP

TL;DR: 提出一种基于高空平台站（HAPS）的集成传感与通信（ISAC）架构，以满足6G网络的高数据速率和泛在覆盖目标。


<details>
  <summary>Details</summary>
Motivation: 为了满足下一代6G网络对超高数据速率和泛在覆盖的雄心勃勃的目标。

Method: 提出一种基于高空平台站（HAPS）的集成传感与通信（ISAC）架构。HAPS在平流层运行，既是强大的通信枢纽，也是先进的环境传感器。结合一组协同工作的无人机（UAV），该双功能系统形成了一个可扩展的智能3D网络。

Result: 仿真结果表明，该方法显著提高了网络性能，提高了传感精度，并确保了用户之间更公平的服务分配，优于传统的仅UAV基线。

Conclusion: 最后，概述了该技术在智慧城市和其他大规模环境中的预期应用和部署路线图。

Abstract: To meet the ambitious goals of next-generation 6G networks, including
ultra-high data rates and ubiquitous coverage, we propose a novel high-altitude
platform station (HAPS)-based integrated sensing and communication (ISAC)
architecture. Operating in the stratosphere, the HAPS functions as both a
powerful communication hub and an advanced environmental sensor. Combined with
a fleet of cooperative uncrewed aerial vehicles (UAVs), this dual-purpose
system forms a scalable and intelligent 3D network. Simulation results indicate
that this approach significantly boosts network performance, improves sensing
accuracy, and ensures a fairer service distribution across users, outperforming
conventional UAV-only baselines. We conclude by outlining the prospective
applications and a deployment roadmap for this technology for smart cities and
other large-scale environments.

</details>


### [529] [Approaching Domain Generalization with Embeddings for Robust Discrimination and Recognition of RF Communication Signals](https://arxiv.org/abs/2510.23186)
*Lukas Henneke,Frank Kurth*

Main category: eess.SP

TL;DR: 深度学习在射频信号识别中表现优异，但需要大量数据且泛化能力不足。本文提出一种无需真实射频信号录音即可学习判别性嵌入的方法，通过对合成无线协议信号进行训练，并在真实射频信号数据集上验证了该方法，证明了其在鲁棒射频信号分类和异常检测方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 深度学习方法在射频信号识别中表现出色，但通常需要大量训练数据，并且泛化到未见过的信号的能力不足。

Method: 在合成无线协议信号上进行训练，学习判别性嵌入，而无需真实射频信号录音。

Result: 所学到的嵌入能够捕捉特征，从而能够准确地区分以前未见过的真实世界信号。

Conclusion: 该方法有潜力用于鲁棒的射频信号分类和异常检测。

Abstract: Radio frequency (RF) signal recognition plays a critical role in modern
wireless communication and security applications. Deep learning-based
approaches have achieved strong performance but typically rely heavily on
extensive training data and often fail to generalize to unseen signals. In this
paper, we propose a method to learn discriminative embeddings without relying
on real-world RF signal recordings by training on signals of synthetic wireless
protocols. We validate the approach on a dataset of real RF signals and show
that the learned embeddings capture features enabling accurate discrimination
of previously unseen real-world signals, highlighting its potential for robust
RF signal classification and anomaly detection.

</details>


### [530] [Uplink SCMA-empowered Uncoordinated Random Access for Future mMTC](https://arxiv.org/abs/2510.23355)
*Pengyu Gao,Qu Luo,Jing Zhu,Gaojie Chen,Pei Xiao,Chuan Heng Foh*

Main category: eess.SP

TL;DR: 本论文提出了一种新颖的无协调随机接入（URA）协议，称为SCMA赋能URA，以满足未来大规模机器类型通信（mMTC）场景中对海量连接和低接入延迟的迫切需求。该方案将S-ALOHA与SCMA相结合，但缺乏中心协调导致码本冲突和解码困难。为了解决这个问题，提出了一种干扰消除（IC）优先解码策略，提高了系统吞吐量。此外，还引入了一种用户禁用机制来管理流量负载，通过估计空闲码本概率和实时负载来调整接入概率。仿真结果表明，SCMA赋能URA方案比传统的OMA-URA方案具有更高的最大吞吐量，并验证了理论分析和用户禁用机制的有效性。


<details>
  <summary>Details</summary>
Motivation: 未来的mMTC场景需要海量连接和低接入延迟，现有的协议难以满足这些需求。

Method: 提出了一种结合S-ALOHA和SCMA的无协调随机接入（URA）协议（SCMA赋能URA）。引入了干扰消除（IC）优先解码策略来解决码本冲突问题。引入了用户禁用机制来管理流量负载，包括计算空闲码本概率和自适应调整接入概率。

Result: SCMA赋能URA方案相比传统的OMA-URA方案具有更高的最大吞吐量。理论分析的准确性和用户禁用机制的有效性得到了验证。

Conclusion: SCMA赋能URA协议结合IC优先解码策略和用户禁用机制，能够有效提高mMTC场景下的系统吞吐量和连接性能。

Abstract: In this paper, a novel uncoordinated random access (URA) protocol is
presented to address the pressing demand for massive connectivity with low
access latency in future massive machine type communication (mMTC) scenarios.
The proposed URA scheme integrates the classical slotted ALOHA (S-ALOHA)
protocol with sparse code multiple access (SCMA) technique, referred to as
SCMA-empowered URA. Specifically, active users randomly choose an SCMA codebook
to access the communication network in an arbitrary time slot whenever they
want without scheduling. However, due to the lack of central coordination in
the proposed URA scheme, SCMA codebook collisions become inevitable, making
decoding challenging and leading to increased access failures. To cope with the
decoding issue, an interference-canceling (IC) first decoding strategy is
proposed at the access point (AP), which can partially tackles collision
problems, contributing to a higher system throughput. Taking the proposed
IC-first decoding strategy into account, a closed-form theoretical expression
of the throughput is derived. Moreover, to alleviate the throughput degradation
under the congested user traffic, a user barring mechanism is introduced to
manage the traffic load. Firstly, a closed-form expression of idle codebook
probability is developed to help indicate the system state, i.e., congested or
not. Then, in addition to the estimated real-time load, the AP adaptively
adjusts the access probability and redistributes the actual access load.
Finally, simulation results demonstrate that the proposed SCMA-empowered URA
scheme enjoys higher maximum throughput, compared to the conventional
orthogonal multiple access (OMA) based URA scheme. Moreover, the accuracy of
the presented theoretical analysis and the effectiveness of the user barring
mechanism are verified.

</details>


### [531] [Randomized Space-Time Coded Stacked Intelligent Metasurfaces for Massive Multiuser Downlink Connectivity](https://arxiv.org/abs/2510.23440)
*Donatella Darsena,Ivan Iudice,Vincenzo Galdi,Francesco Verde*

Main category: eess.SP

TL;DR: 该论文提出了一种新颖的随机空-时（ST）编码智能超表面（SIM）波束形成策略，通过引入随机时间变化来增强慢速信道动态下的用户调度和多用户分集，并提出了一种基于部分信道状态信息（CSIT）的波束形成方案以降低开销，实现了可扩展的下行链路连接。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统仅空间SIM架构中可重构速率受限于信道相干时间的问题，并增强慢速信道动态下的用户调度和多用户分集。

Method: 提出了一种结合了随机时间维度变化的空-时（ST）编码SIM设计，并采用基于部分CSIT的波束形成方案，利用随机导向矢量和有限的用户端反馈。

Result: 所提出的ST-SIM架构在降低CSIT获取和反馈开销的同时，实现了令人满意的总和速率性能。

Conclusion: 所提出的ST-SIM架构结合随机时间维度变化和部分CSIT波束形成，能够有效提升大规模下行链路连接的性能，特别是在密集网络环境中，同时显著降低了对信道状态信息的要求。

Abstract: Stacked intelligent metasurfaces (SIMs) represent a key enabler for
next-generation wireless networks, offering beamforming gains while
significantly reducing radio-frequency chain requirements. In conventional
space-only SIM architectures, the rate of reconfigurability of the SIM is equal
to the inverse of the channel coherence time. This paper investigates a novel
beamforming strategy for massive downlink connectivity using a randomized
space-time (ST) coded SIM. In addition to conventional space-only metasurface
layers, the proposed design integrates a ST metasurface layer at the input
stage of the SIM that introduces random time variations over each channel
coherence time interval. These artificial time variations enable opportunistic
user scheduling and exploitation of multiuser diversity under slow channel
dynamics. To mitigate the prohibitive overhead associated with full channel
state information at the transmitter (CSIT), we propose a partial-CSIT-based
beamforming scheme that leverages randomized steering vectors and limited
user-side feedback based on signal quality measurements. Numerical results
demonstrate that the proposed ST-SIM architecture achieves satisfactory
sum-rate performance while significantly reducing CSIT acquisition and feedback
overhead, thereby enabling scalable downlink connectivity in dense networks.

</details>


### [532] [Joint Uplink and Downlink Resource Allocation and Antenna Activation for Pinching Antenna Systems](https://arxiv.org/abs/2510.23467)
*Shreya Khisa,Ali Amhaz,Mohamed Elhattab,Chadi Assi,Sanaa Sharafeddine*

Main category: eess.SP

TL;DR: 本文提出了一种利用捏合天线系统(PASS)的联合上下行链路框架，通过优化天线激活和功率分配，在相同频谱资源下同时服务上下行用户，实现了相比时分双工(TDD)约60-90%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有通信系统在同一频谱上同时进行上行和下行传输存在挑战，需要更高效的资源利用方式。

Method: 提出了一种新的联合上下行链路框架，利用捏合天线系统(PASS)。将问题分解为天线激活子问题（基于距离和空间相关性算法）和功率分配子问题（基于连续凸近似SCA算法），并联合优化天线激活因子、基站（BS）和用户设备（UE）的发射功率。

Result: 提出的PASS框架在联合优化下，相比于TDD系统（上下行在不同时隙传输）能够实现60%-90%的性能增益。

Conclusion: 本文提出的PASS框架能够有效地在相同频谱资源下同时支持上下行通信，并显著优于传统的TDD系统。

Abstract: In this paper, we explore a novel joint uplink and downlink framework
utilizing a pinching antenna system (PASS). We consider two waveguides, one
dedicated to transmission and one to reception, and both of them are connected
to a base station (BS). Each type of waveguide consists of several pinching
antennas (PAs) in some preconfigured positions. In this framework, we assume
the BS can serve downlink and uplink user equipments (UEs) at the same time
using the same spectrum resources through the presented PASS. In this aspect,
we formulate a sum rate optimization problem that jointly optimizes the antenna
activation factor, the BS transmit power, and the UE's transmit power, subject
to power budget constraints for the BS and the UEs, as well as minimum rate
requirements for the UEs. The formulated problem is highly non-convex and
difficult to solve directly. Hence, we divide the main problem into two
sub-problems: the antenna activation sub-problem and the power allocation
sub-problem. Then, we solve the antenna activation problem utilizing a distance
and spatial correlation-based algorithm. Meanwhile, the resource allocation
problem is solved using a successive convex approximation (SCA)-based
algorithm. Numerical results show that our proposed framework can achieve
around 60-90\% performance gains over its time division duplex (TDD) where the
uplink and downlink transmissions are served in different orthogonal time
slots.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [533] [Collaborative Task Assignment, Sequencing and Multi-agent Path-finding](https://arxiv.org/abs/2510.21738)
*Yifan Bai,Shruti Kotpalliwar,Christoforos Kanellakis,George Nikolakopoulos*

Main category: cs.MA

TL;DR: CBS-TS是一个新的最优和完整的算法，用于解决带任务排序的TSP问题，通过交替进行任务排序和冲突解决来优化，并在大多数情况下优于CBSS。


<details>
  <summary>Details</summary>
Motivation: 解决具有冲突和排序约束的协作任务分配、排序和多智能体路径查找（TSPF）问题，同时最小化流时间。

Method: 提出了一种基于冲突的搜索与任务排序（CBS-TS）的算法，该算法结合了混合整数线性规划（MILP）进行任务排序和基于冲突的搜索（CBS）与多标签A*（MLA*）进行无碰撞路径规划。

Result: CBS-TS在大多数测试场景中优于基线方法CBSS，实现了更高的成功率和最优解，而CBSS在某些情况下仅能获得近似最优解。

Conclusion: CBS-TS是一种有效且最优的TSP问题解决方案，在计算效率和解的质量方面均优于现有方法。

Abstract: In this article, we address the problem of collaborative task assignment,
sequencing, and multi-agent pathfinding (TSPF), where a team of agents must
visit a set of task locations without collisions while minimizing flowtime.
TSPF incorporates agent-task compatibility constraints and ensures that all
tasks are completed. We propose a Conflict-Based Search with Task Sequencing
(CBS-TS), an optimal and complete algorithm that alternates between finding new
task sequences and resolving conflicts in the paths of current sequences.
CBS-TS uses a mixed-integer linear program (MILP) to optimize task sequencing
and employs Conflict-Based Search (CBS) with Multi-Label A* (MLA*) for
collision-free path planning within a search forest. By invoking MILP for the
next-best sequence only when needed, CBS-TS efficiently limits the search
space, enhancing computational efficiency while maintaining optimality. We
compare the performance of our CBS-TS against Conflict-based Steiner Search
(CBSS), a baseline method that, with minor modifications, can address the TSPF
problem. Experimental results demonstrate that CBS-TS outperforms CBSS in most
testing scenarios, achieving higher success rates and consistently optimal
solutions, whereas CBSS achieves near-optimal solutions in some cases. The
supplementary video is available at https://youtu.be/QT8BYgvefmU.

</details>


### [534] [LLM-augmented empirical game theoretic simulation for social-ecological systems](https://arxiv.org/abs/2510.21965)
*Jennifer Shi,Christopher K. Frantz,Christian Kimmich,Saba Siddiki,Atrisha Sarkar*

Main category: cs.MA

TL;DR: 本文比较了四种语言模型（LLM）增强的框架，用于模拟社会生态系统治理，并评估了它们在阿姆河地区灌溉和渔业案例研究中的表现。结果表明，不同框架产生了显著不同的行为模式，并且专家指导的基于博弈论的框架比仅通过提示词诱导行为的模型更有效。


<details>
  <summary>Details</summary>
Motivation: 设计用于社会-生态系统的制度需要能够捕捉异质性、不确定性和战略互动的模型。尽管已出现多种建模方法，如经验博弈论分析（EGTA）和新近流行的LLM驱动的模拟，但它们之间的整合方式以及生成的行为是否符合现实世界治理的范围尚不清楚。

Method: 本文比较了四种LLM增强的框架：程序性ABM、生成性ABM、LLM-EGTA和专家指导的LLM-EGTA。并在阿姆河地区灌溉和渔业的案例研究中，对集中式和分散式治理进行了评估。

Result: 程序性ABM、生成性ABM和LLM增强的EGTA模型产生了显著不同的集体行为模式。通过系统提示词在LLM中诱导行为的效果不如在专家指导的基于EGTA的模型中通过参数化收益来塑造行为。

Conclusion: LLM增强的模拟方法在社会-生态系统治理建模方面提供了新的可能性，但不同方法的选择会对结果产生显著影响。专家指导的基于博弈论的方法在塑造模型行为方面更为有效。

Abstract: Designing institutions for social-ecological systems requires models that
capture heterogeneity, uncertainty, and strategic interaction. Multiple
modeling approaches have emerged to meet this challenge, including empirical
game-theoretic analysis (EGTA), which merges ABM's scale and diversity with
game-theoretic models' formal equilibrium analysis. The newly popular class of
LLM-driven simulations provides yet another approach, and it is not clear how
these approaches can be integrated with one another, nor whether the resulting
simulations produce a plausible range of behaviours for real-world
social-ecological governance. To address this gap, we compare four
LLM-augmented frameworks: procedural ABMs, generative ABMs, LLM-EGTA, and
expert guided LLM-EGTA, and evaluate them on a real-world case study of
irrigation and fishing in the Amu Darya basin under centralized and
decentralized governance. Our results show: first, procedural ABMs, generative
ABMs, and LLM-augmented EGTA models produce strikingly different patterns of
collective behaviour, highlighting the value of methodological diversity.
Second, inducing behaviour through system prompts in LLMs is less effective
than shaping behaviour through parameterized payoffs in an expert-guided
EGTA-based model.

</details>


### [535] [CreditXAI: A Multi-Agent System for Explainable Corporate Credit Rating](https://arxiv.org/abs/2510.22222)
*Yumeng Shi,Zhongliang Yang,Yisi Wang,Linna Zhou*

Main category: cs.MA

TL;DR: CreditXAI是一个多智能体系统（MAS）框架，通过模拟专业信用分析师的协作决策过程，提高了公司信用评级中预测的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统的深度学习方法在公司信用评级中存在“黑箱”问题和可解释性有限的缺点。尽管融入非金融信息有所改善，但模型仍缺乏分层推理机制，限制了其综合分析能力。

Method: 提出CreditXAI，一个多智能体系统（MAS）框架，模拟专业信用分析师的协作决策过程，重点关注业务、财务和治理风险维度，以生成一致且可解释的信用评估。

Result: 与最佳的单一智能体基线相比，多智能体协作将预测准确性提高了7%以上，证明了其在公司信用风险评估中的显著协同优势。

Conclusion: 该研究为构建智能且可解释的信用评级模型提供了一条新的技术途径。

Abstract: In the domain of corporate credit rating, traditional deep learning methods
have improved predictive accuracy but still suffer from the inherent
'black-box' problem and limited interpretability. While incorporating
non-financial information enriches the data and provides partial
interpretability, the models still lack hierarchical reasoning mechanisms,
limiting their comprehensive analytical capabilities. To address these
challenges, we propose CreditXAI, a Multi-Agent System (MAS) framework that
simulates the collaborative decision-making process of professional credit
analysts. The framework focuses on business, financial, and governance risk
dimensions to generate consistent and interpretable credit assessments.
Experimental results demonstrate that multi-agent collaboration improves
predictive accuracy by more than 7% over the best single-agent baseline,
confirming its significant synergistic advantage in corporate credit risk
evaluation. This study provides a new technical pathway to build intelligent
and interpretable credit rating models.

</details>


### [536] [CGoT: A Novel Inference Mechanism for Embodied Multi-Agent Systems Using Composable Graphs of Thoughts](https://arxiv.org/abs/2510.22235)
*Yixiao Nie,Yang Zhang,Yingjie Jin,Zhepeng Wang,Xiu Li,Xiang Li*

Main category: cs.MA

TL;DR: 本文介绍了一种结合自动驾驶汽车和机器人服务的新型系统，并提出了一种名为CGOT的推理机制，以提高效率和协作能力。


<details>
  <summary>Details</summary>
Motivation: 无人驾驶汽车和服务机器人的融合以及大型语言模型的快速发展，促使研究人员探索将它们结合起来以提高效率和协作能力的潜力。

Method: 提出了一种名为CGOT的新型推理机制，并将其应用于由自动驾驶汽车运送服务机器人的系统中，让车辆将机器人运送到指定地点以执行任务。

Result: 实验结果验证了所提出方法的有效性。

Conclusion: 所提出的结合自动驾驶汽车和机器人服务的新型系统以及CGOT推理机制在提高运营效率和最大化车辆与机器人之间的协作潜力方面具有可行性和益处。

Abstract: The integration of self-driving cars and service robots is becoming
increasingly prevalent across a wide array of fields, playing a crucial and
expanding role in both industrial applications and everyday life. In parallel,
the rapid advancements in Large Language Models (LLMs) have garnered
substantial attention and interest within the research community. This paper
introduces a novel vehicle-robot system that leverages the strengths of both
autonomous vehicles and service robots. In our proposed system, two autonomous
ego-vehicles transports service robots to locations within an office park,
where they perform a series of tasks. The study explores the feasibility and
potential benefits of incorporating LLMs into this system, with the aim of
enhancing operational efficiency and maximizing the potential of the
cooperative mechanisms between the vehicles and the robots. This paper proposes
a novel inference mechanism which is called CGOT toward this type of system
where an agent can carry another agent. Experimental results are presented to
validate the performance of the proposed method.

</details>


### [537] [IFS: Information Flow Structure for Multi-agent Ad Hoc System](https://arxiv.org/abs/2510.22320)
*Yanqing Fu,Chenrun Wang,Chao Huang,Zhuping Wang*

Main category: cs.MA

TL;DR: Ad hoc 多智能体系统面临信息流动和处理能力不足的挑战。为解决这些问题，本文提出了一种新的信息流动结构（IFS），通过通信和信息融合来增强这些能力。实验结果表明，IFS 在 StarCraft II 中显著提高了信息流动和处理能力，并展现出强大的泛化能力，在复杂 ad hoc 团队协作场景中优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究在多智能体 ad hoc 系统中存在信息流动不足和信息处理能力有限的问题，限制了系统在动态、开放环境中的协作能力。

Method: 提出了一种信息流动结构（IFS），从通信和信息融合两个角度解决信息流动不足和信息处理能力有限的问题。

Result: IFS 在 StarCraft II 实验中显著提高了信息流动和处理能力，并展现出强大的泛化能力，优于基线方法。

Conclusion: IFS 是一种有效的信息流动结构，能够提升多智能体 ad hoc 系统在通信和信息融合方面的能力，并在复杂场景下取得更好的协作效果。

Abstract: Multi-agent ad hoc systems are dynamic collaborative systems in which
multiple autonomous agents must cooperate with both known and unknown teammates
in open environments, without relying on pre-coordinated strategies. These
systems operate under conditions of uncertainty and partial observability,
where team composition, agent behaviors, and environmental factors may change
during execution. Through an analysis of information flow in such systems, we
identify two key limitations in existing research: insufficient information
flow and limited information processing capacity. To address these issues, we
propose an information flow structure for multi-agent ad hoc systems (IFS),
which tackles these challenges from the perspectives of communication and
information fusion. Experimental results in StarCraft II demonstrate that IFS
significantly improves both information flow and processing capacity, while
exhibiting strong generalization capabilities and outperforming baseline
methods in complex ad hoc teamwork scenarios.

</details>


### [538] [Group size effects and collective misalignment in LLM multi-agent systems](https://arxiv.org/abs/2510.22422)
*Ariel Flint,Luca Maria Aiello,Romualdo Pastor-Satorras,Andrea Baronchelli*

Main category: cs.MA

TL;DR: 与以往不同，本研究系统地探讨了群体规模对多智能体大语言模型（LLM）交互动力学的影响，特别是多智能体不对齐问题。研究发现，群体规模会以非线性方式影响模型行为，并提出了一种均值场分析方法，该方法在临界群体规模以上可以预测模型的确定性行为。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要对比单个LLM智能体与固定规模群体智能体的行为差异，但未充分探讨群体规模如何影响LLM的交互动力学，特别是多智能体不对齐问题。

Method: 系统性地探索了不同群体规模下LLM的交互行为，重点关注多智能体不对齐现象。通过引入均值场分析方法，在临界群体规模以上对模型行为进行预测。

Result: 研究表明，群体交互不仅会放大个体偏见，还会引入新的偏见或覆盖模型自身的偏好。群体规模对交互动力学有非线性影响，并存在依赖于具体模型的动力学模式。在临界群体规模以上，模拟结果趋于确定性，并能揭示竞争性均衡的吸引域。

Conclusion: 群体规模是影响多智能体LLM交互动力学的关键因素，在规模化部署LLM系统时必须考虑群体层面的效应。

Abstract: Multi-agent systems of large language models (LLMs) are rapidly expanding
across domains, introducing dynamics not captured by single-agent evaluations.
Yet, existing work has mostly contrasted the behavior of a single agent with
that of a collective of fixed size, leaving open a central question: how does
group size shape dynamics? Here, we move beyond this dichotomy and
systematically explore outcomes across the full range of group sizes. We focus
on multi-agent misalignment, building on recent evidence that interacting LLMs
playing a simple coordination game can generate collective biases absent in
individual models. First, we show that collective bias is a deeper phenomenon
than previously assessed: interaction can amplify individual biases, introduce
new ones, or override model-level preferences. Second, we demonstrate that
group size affects the dynamics in a non-linear way, revealing model-dependent
dynamical regimes. Finally, we develop a mean-field analytical approach and
show that, above a critical population size, simulations converge to
deterministic predictions that expose the basins of attraction of competing
equilibria. These findings establish group size as a key driver of multi-agent
dynamics and highlight the need to consider population-level effects when
deploying LLM-based systems at scale.

</details>


### [539] [Hollywood Town: Long-Video Generation via Cross-Modal Multi-Agent Orchestration](https://arxiv.org/abs/2510.22431)
*Zheng Wei,Mingchen Li,Zeqian Zhang,Ruibin Yuan,Pan Hui,Huamin Qu,James Evans,Maneesh Agrawala,Anyi Rao*

Main category: cs.MA

TL;DR: 提出了一种名为OmniAgent的新的多代理框架，用于改进长视频生成和其他创意任务中的多代理协作。


<details>
  <summary>Details</summary>
Motivation: 多代理系统在创意任务（如长视频生成）中展现出巨大潜力，需要改进多代理协作方法。

Method: 1. OmniAgent框架：一个分层、基于图的多代理框架，采用类似电影制作的架构，实现模块化专业化和可扩展的代理协作。
2. 超图节点：受上下文工程启发，用于代理之间的临时小组讨论，以解决上下文不足的问题，降低单个代理的记忆需求。
3. 有限重试的有向循环图：从DAG转向有向循环图，允许代理进行迭代式反馈和改进，提高早期阶段的输出质量。

Result: 提出的方法能够改进多代理协作，从而在长视频生成等创意任务中取得更好的效果。

Conclusion: 该研究为开发更强大的多代理系统在创意任务中的应用奠定了基础。

Abstract: Recent advancements in multi-agent systems have demonstrated significant
potential for enhancing creative task performance, such as long video
generation. This study introduces three innovations to improve multi-agent
collaboration. First, we propose OmniAgent, a hierarchical, graph-based
multi-agent framework for long video generation that leverages a
film-production-inspired architecture to enable modular specialization and
scalable inter-agent collaboration. Second, inspired by context engineering, we
propose hypergraph nodes that enable temporary group discussions among agents
lacking sufficient context, reducing individual memory requirements while
ensuring adequate contextual information. Third, we transition from directed
acyclic graphs (DAGs) to directed cyclic graphs with limited retries, allowing
agents to reflect and refine outputs iteratively, thereby improving earlier
stages through feedback from subsequent nodes. These contributions lay the
groundwork for developing more robust multi-agent systems in creative tasks.

</details>


### [540] [Agent-GSPO: Communication-Efficient Multi-Agent Systems via Group Sequence Policy Optimization](https://arxiv.org/abs/2510.22477)
*Yijia Fan,Jusheng Zhang,Jing Yang,Keze Wang*

Main category: cs.MA

TL;DR: Agent-GSPO通过优化代币经济性来降低多智能体系统的通信成本，在新研究领域取得了最先进的性能，同时减少了代币消耗。


<details>
  <summary>Details</summary>
Motivation: 为了解决“自由”多智能体系统（MAS）高昂的通信成本问题。

Method: Agent-GSPO利用稳定且内存高效的群组序列策略优化（GSPO）算法，通过明确惩罚冗余的通信方式，在通信感知奖励方面对智能体进行训练。

Result: Agent-GSPO在七个推理基准测试中取得了新的最先进性能，并且其代币消耗量仅为现有方法的几分之一。

Conclusion: 通过培养“战略性沉默”等新兴策略，Agent-GSPO为开发可扩展且经济可行的多智能体系统提供了一个实用的蓝图。

Abstract: To combat the prohibitive communication costs of ``free-for-all" multi-agent
systems (MAS), we introduce \textbf{Agent-GSPO}, a framework that directly
optimizes for token economy using sequence-level reinforcement learning.
Agent-GSPO leverages the stable and memory-efficient Group Sequence Policy
Optimization (GSPO) algorithm to train agents on a communication-aware reward
that explicitly penalizes verbosity. Across seven reasoning benchmarks,
Agent-GSPO not only achieves new state-of-the-art performance but does so with
a fraction of the token consumption of existing methods. By fostering emergent
strategies like ``strategic silence," our approach provides a practical
blueprint for developing scalable and economically viable multi-agent systems.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [541] [When Agents are Powerful: Black Hole Search in Time-Varying Graphs](https://arxiv.org/abs/2510.22309)
*Tanvir Kaur,Ashish Saxena*

Main category: cs.DC

TL;DR: 在动态图中，增强代理的全局通信和1跳可见性可以更有效地解决黑洞搜索问题。


<details>
  <summary>Details</summary>
Motivation: 识别图中的黑洞（有害节点）至关重要。然而，在动态图中使用面对面通信来解决黑洞搜索（BHS）问题需要大量代理。

Method: 通过授予代理全局通信能力（无论其位置如何）和1跳可见性（允许观察邻近节点），增强代理的功能。

Result: 与先前在面对面通信下的工作相比，这些增强功能可以更有效地解决动态图中的BHS问题。

Conclusion: 通过增强代理的通信和可见性能力，可以更有效地解决动态图中的黑洞搜索问题。

Abstract: A black hole is a harmful node in a graph that destroys any resource entering
it, making its identification a critical task. In the \emph{Black Hole Search
(BHS)} problem, a team of agents operates on a graph $G$ with the objective
that at least one agent must survive and correctly identify an edge incident to
the black hole. Prior work has addressed BHS in arbitrary dynamic graphs under
the restrictive \emph{face-to-face} communication, where agents can exchange
information only when co-located. This constraint significantly increases the
number of agents required to solve the problem. In this work, we strengthen the
capabilities of agents in two ways: (i) granting them \emph{global
communication}, enabling interaction regardless of location, and (ii) equipping
them with \emph{1-hop visibility}, allowing each agent to observe its immediate
neighborhood. These enhancements lead to more efficient solutions for the BHS
problem in dynamic graphs.

</details>


### [542] [Separation of Unconscious Robots with Obstructed Visibility](https://arxiv.org/abs/2510.22434)
*Prajyot Pyati,Navjot Kaur,Saswata Jana,Adri Bhattacharya,Partha Sarathi Mandal*

Main category: cs.DC

TL;DR: 本研究提出了一个在不透明可见性模型下解决分离问题的算法，机器人需要分离成同心半圆。该算法在 O(n) 时间周期内解决问题，并且是无碰撞的。


<details>
  <summary>Details</summary>
Motivation: 已有研究中的机器人模型是透明的，允许机器人看到所有其他机器人。本研究提出了不透明可见性模型，其中机器人可能会遮挡其他机器人的视线。

Method: 提出了一种解决不透明可见性模型下分离问题的算法，要求机器人分离成同心半圆。该算法在半同步调度下运行，并且是无碰撞的。

Result: 在不透明可见性模型下，机器人可以在 O(n) 时间周期内分离成同心半圆。该算法是无碰撞的。

Conclusion: 本研究成功地解决了一个新提出的机器人模型下的分离问题，即不透明可见性模型，并提出了一个有效的无碰撞算法。

Abstract: We study a recently introduced \textit{unconscious} mobile robot model, where
each robot is associated with a \textit{color}, which is visible to other
robots but not to itself. The robots are autonomous, anonymous, oblivious and
silent, operating in the Euclidean plane under the conventional
\textit{Look-Compute-Move} cycle. A primary task in this model is the
\textit{separation problem}, where unconscious robots sharing the same color
must separate from others, forming recognizable geometric shapes such as
circles, points, or lines. All prior works model the robots as
\textit{transparent}, enabling each to know the positions and colors of all
other robots. In contrast, we model the robots as \textit{opaque}, where a
robot can obstruct the visibility of two other robots, if it lies on the line
segment between them. Under this obstructed visibility, we consider a variant
of the separation problem in which robots, starting from any arbitrary initial
configuration, are required to separate into concentric semicircles. We present
a collision-free algorithm that solves the separation problem under a
semi-synchronous scheduler in $O(n)$ epochs, where $n$ is the number of robots.
The robots agree on one coordinate axis but have no knowledge of $n$.

</details>


### [543] [Rethinking Inference Placement for Deep Learning across Edge and Cloud Platforms: A Multi-Objective Optimization Perspective and Future Directions](https://arxiv.org/abs/2510.22909)
*Zongshun Zhang,Ibrahim Matta*

Main category: cs.DC

TL;DR: 边缘智能应用广泛，但边缘设备难以支持大型深度学习模型。研究者提出模型优化和卸载策略，在用户设备、边缘服务器和云之间分配模型分区，以平衡响应延迟、计算成本、精度、传输延迟和隐私。


<details>
  <summary>Details</summary>
Motivation: 边缘智能应用（如VR/AR、聊天机器人）的普及，对计算能力要求不断提高，而边缘设备能力受限，难以直接运行大型深度学习模型。

Method: 对模型压缩、模型蒸馏、传输压缩和模型架构调整（包括内部分类器）等技术进行研究，并将其应用于多目标优化中，考虑推理延迟、数据隐私和资源货币成本。

Result: 总结了现有模型卸载方法和模型适应技术，并研究了它们在推理延迟、数据隐私和资源货币成本等多目标优化中的影响。

Conclusion: 现有的模型卸载方法和模型适应技术旨在平衡深度学习模型在边缘计算环境中的性能、隐私和成本，但通信瓶颈和数据泄露风险仍是挑战。

Abstract: Edge intelligent applications like VR/AR and language model based chatbots
have become widespread with the rapid expansion of IoT and mobile devices.
However, constrained edge devices often cannot serve the increasingly large and
complex deep learning (DL) models. To mitigate these challenges, researchers
have proposed optimizing and offloading partitions of DL models among user
devices, edge servers, and the cloud. In this setting, users can take advantage
of different services to support their intelligent applications. For example,
edge resources offer low response latency. In contrast, cloud platforms provide
low monetary cost computation resources for computation-intensive workloads.
However, communication between DL model partitions can introduce transmission
bottlenecks and pose risks of data leakage. Recent research aims to balance
accuracy, computation delay, transmission delay, and privacy concerns. They
address these issues with model compression, model distillation, transmission
compression, and model architecture adaptations, including internal
classifiers. This survey contextualizes the state-of-the-art model offloading
methods and model adaptation techniques by studying their implication to a
multi-objective optimization comprising inference latency, data privacy, and
resource monetary cost.

</details>


### [544] [Bayes-Split-Edge: Bayesian Optimization for Constrained Collaborative Inference in Wireless Edge Systems](https://arxiv.org/abs/2510.23503)
*Fatemeh Zahra Safaeipour,Jacob Chakareski,Morteza Hashemi*

Main category: cs.DC

TL;DR: 移动边缘设备（如AR/VR头显）通常需要在计算和能源资源有限的情况下，及时完成推理任务。本文研究了无线边缘网络中的协作推理问题，旨在满足时延约束。我们提出了一种名为Bayes-Split-Edge的新颖解决方案，利用贝叶斯优化来协作处理分离的推理任务。该方案联合优化了传输功率和神经网络切分点，并采用了一种新颖的混合获取函数来平衡推理任务效用、样本效率和约束违反惩罚。在VGG19和Resnet101模型上的实验结果表明，Bayes-Split-Edge相比标准贝叶斯优化可将评估成本降低2.4倍，并接近线性收敛。


<details>
  <summary>Details</summary>
Motivation: 移动边缘设备面临计算和能源资源限制，需要在规定时限内完成推理任务。

Method: 提出一种名为Bayes-Split-Edge的新颖解决方案，利用贝叶斯优化来协作处理分离的推理任务，联合优化传输功率和神经网络切分点，并采用一种新颖的混合获取函数来平衡推理任务效用、样本效率和约束违反惩罚。

Result: Bayes-Split-Edge相比标准贝叶斯优化可将评估成本降低2.4倍，接近线性收敛，并在性能上优于CMA-ES、DIRECT、穷举搜索和PPO等基线算法。

Conclusion: Bayes-Split-Edge为边缘计算系统中的无线分离推理提供了一种样本高效的解决方案，只需最少20次函数评估，并实现了约束感知优化。

Abstract: Mobile edge devices (e.g., AR/VR headsets) typically need to complete timely
inference tasks while operating with limited on-board computing and energy
resources. In this paper, we investigate the problem of collaborative inference
in wireless edge networks, where energy-constrained edge devices aim to
complete inference tasks within given deadlines. These tasks are carried out
using neural networks, and the edge device seeks to optimize inference
performance under energy and delay constraints. The inference process can be
split between the edge device and an edge server, thereby achieving
collaborative inference over wireless networks. We formulate an inference
utility optimization problem subject to energy and delay constraints, and
propose a novel solution called Bayes-Split-Edge, which leverages Bayesian
optimization for collaborative split inference over wireless edge networks. Our
solution jointly optimizes the transmission power and the neural network split
point. The Bayes-Split-Edge framework incorporates a novel hybrid acquisition
function that balances inference task utility, sample efficiency, and
constraint violation penalties. We evaluate our approach using the VGG19 model
on the ImageNet-Mini dataset, and Resnet101 on Tiny-ImageNet, and real-world
mMobile wireless channel datasets. Numerical results demonstrate that
Bayes-Split-Edge achieves up to 2.4x reduction in evaluation cost compared to
standard Bayesian optimization and achieves near-linear convergence. It also
outperforms several baselines, including CMA-ES, DIRECT, exhaustive search, and
Proximal Policy Optimization (PPO), while matching exhaustive search
performance under tight constraints. These results confirm that the proposed
framework provides a sample-efficient solution requiring maximum 20 function
evaluations and constraint-aware optimization for wireless split inference in
edge computing systems.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [545] [Quantum Autoencoders for Anomaly Detection in Cybersecurity](https://arxiv.org/abs/2510.21837)
*Rohan Senthil,Swee Liang Wong*

Main category: cs.ET

TL;DR: 量子自编码器（QAE）在数据有限的情况下，在网络安全异常检测方面优于经典自编码器（CAE）。


<details>
  <summary>Details</summary>
Motivation: 网络安全中的异常检测由于正常事件远超异常事件且新的异常频繁出现，因而具有挑战性。虽然经典自编码器已被用于异常检测，但在数据有限的情况下存在不足，而量子自编码器有望克服这一问题。

Method: 在BPF扩展跟踪蜜罐（BETH）数据集上应用量子自编码器（QAE）进行网络安全异常检测，并评估了多种编码技术、模型结构、重复次数和特征选择策略。

Result: 在数据有限的情况下，使用具有“RealAmplitude”模型和“Dense-Angle”编码的8特征QAE模型，其F1分数（0.87）优于经典自编码器（CAE）（0.77）。研究还展示并讨论了量子编码和特征选择对开发量子模型的影响。

Conclusion: 量子自编码器（QAE）可能在数据有限的网络安全异常检测场景中具有实际优势。

Abstract: Anomaly detection in cybersecurity is a challenging task, where normal events
far outnumber anomalous ones with new anomalies occurring frequently. Classical
autoencoders have been used for anomaly detection, but struggles in
data-limited settings which quantum counterparts can potentially overcome. In
this work, we apply Quantum Autoencoders (QAEs) for anomaly detection in
cybersecurity, specifically on the BPF-extended tracking honeypot (BETH)
dataset. QAEs are evaluated across multiple encoding techniques, ansatz types,
repetitions, and feature selection strategies. Our results demonstrate that an
8-feature QAE using Dense-Angle encoding with a RealAmplitude ansatz can
outperform Classical Autoencoders (CAEs), even when trained on substantially
fewer samples. The effects of quantum encoding and feature selection for
developing quantum models are demonstrated and discussed. In a data-limited
setting, the best performing QAE model has a F1 score of 0.87, better than that
of CAE (0.77). These findings suggest that QAEs may offer practical advantages
for anomaly detection in data-limited scenarios.

</details>


### [546] [Jenga: Responsive Tiered Memory Management without Thrashing](https://arxiv.org/abs/2510.22869)
*Rohan Kadekodi,Haoran Peng,Gilbert Bernstein,Michael D. Ernst,Baris Kasikci*

Main category: cs.ET

TL;DR: Jenga是一个新型多层级内存系统，通过改进的内存分配策略和准确的页面热度测量，解决了现有系统在处理热点和冷点对象混合以及热度变化剧烈时的性能瓶颈，显著提高了内存密集型应用的性能。


<details>
  <summary>Details</summary>
Motivation: 以往的多层级内存系统存在分配策略不佳（热/冷对象同页）和热度测量突变（导致抖动）的问题，影响了性能。

Method: Jenga采用新颖的基于上下文的页面分配策略，并能准确测量页面热度，及时响应内存访问行为变化，避免抖动。

Result: 与现有最佳系统相比，Jenga 在内存密集型应用中平均提速 28%，CPU 开销低于 3%，内存开销低于 0.3%。

Conclusion: Jenga 通过其独特的内存分配和热度测量机制，有效解决了多层级内存系统的性能挑战，实现了显著的加速效果。

Abstract: A heterogeneous memory has a single address space with fast access to some
addresses (a fast tier of DRAM) and slow access to other addresses (a capacity
tier of CXL-attached memory or NVM). A tiered memory system aims to maximize
the number of accesses to the fast tier via page migrations between the fast
and capacity tiers. Unfortunately, previous tiered memory systems can perform
poorly due to (1) allocating hot and cold objects in the same page and (2)
abrupt changes in hotness measurements that lead to thrashing.
  This paper presents Jenga, a tiered memory system that addresses both
problems. Jenga's memory allocator uses a novel context-based page allocation
strategy. Jenga's accurate measurements of page hotness enable it to react to
memory access behavior changes in a timely manner while avoiding thrashing.
Compared to the best previous tiered memory system, Jenga runs memory-intensive
applications 28% faster across 10 applications, when the fast tier capacity
matches the working set size, at a CPU overhead of <3% of a single core and a
memory overhead of <0.3%

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [547] [Heaven & Hell II: Scale Laws and Robustness in One-Step Heaven-Hell Consensus](https://arxiv.org/abs/2510.21950)
*Nnamdi Daniel Aghanya,Romain Leemans*

Main category: cs.SI

TL;DR: 该研究提出了“天堂-地狱”动力学模型，用于网络共识，并针对各种复杂情况（如多中心、异步更新等）改进了其收敛阈值，所有证明均已通过 Coq 形式化验证。


<details>
  <summary>Details</summary>
Motivation: 网络共识模型（“天堂-地狱”动力学）的精确收敛阈值在实际应用中需要更鲁棒的保证，以应对各种复杂因素。

Method: 通过开发尺度规律和操作性改进，使收敛阈值能够适应不同的策略和系统特性，包括：改进的界限、用于异步更新的单遍公平性，以及用于种子收敛的充分条件。所有证明均使用 Coq 进行形式化验证。

Result: 研究提出了一系列改进措施，使得“天堂-地狱”动力学的收敛阈值在面对节点容差、种子节点、多中心和异步更新等复杂情况时更加鲁棒，并通过在多种图结构上的实验验证了这些改进的有效性。

Conclusion: “天堂-地狱”动力学的收敛性可以通过尺度规律和操作性改进得到显著增强，从而在更广泛的网络共识场景中实现可靠和高效的共识。

Abstract: We study Heaven-Hell dynamics, a model for network consensus. A known result
establishes an exact one-step convergence threshold for systems with a single
uniform hub: the per-node inbound hub weight W suffices if and only if W >=
maxrest, the maximum non-hub inbound mass. We develop scale laws and
operational refinements that make this threshold robust to tie-breaking
policies, node-specific tolerances, targeted seeding, multiple hubs, and
asynchronous updates. Our contributions include a conservation-law perspective,
parameterized tie policies, tighter pointwise bounds improving on classical
worst-case guarantees, one-pass fairness for asynchronous updates, and
sufficient conditions for seeded convergence. All proofs are mechanized in Coq,
with experiments on rings, grids, scale-free graphs, and heterogeneous weighted
graphs validating tightness and gap closures

</details>


### [548] [From Social Division to Cohesion with AI Message Suggestions in Online Chat Groups](https://arxiv.org/abs/2510.21984)
*Faria Huq,Elijah L. Claggett,Hirokazu Shirado*

Main category: cs.SI

TL;DR: LLM驱动的通信辅助会影响在线讨论中的社会凝聚力，个性化建议可能导致群体隔离，而考虑群体成员立场的辅助则能增强凝聚力。


<details>
  <summary>Details</summary>
Motivation: 随着LLM日益融入在线通信，了解其对社会凝聚力的影响至关重要，尤其是在观点多样化的社会中。

Method: 进行了一项包含557名参与者的在线实验，参与者就政治争议性话题进行多轮讨论，并自由重组讨论小组。部分参与者获得了由LLM生成的实时消息建议，这些建议或是个性化的，或是针对讨论小组的。

Result: 与单独的个性化建议（导致用户隔离成意见相似的小组）相比，融入小组成员立场的关系型辅助通过更具接受性的交流增强了凝聚力。AI辅助可以改变语言风格，进而影响集体结构。

Conclusion: AI驱动的通信辅助有潜力支持多元化群体的社会凝聚力，但其效果在很大程度上取决于个性化设计的具体方式。

Abstract: Social cohesion is difficult to sustain in societies marked by opinion
diversity, particularly in online communication. As large language model
(LLM)-driven messaging assistance becomes increasingly embedded in these
contexts, it raises critical questions about its societal impact. We present an
online experiment with 557 participants who engaged in multi-round discussions
on politically controversial topics while freely reconfiguring their discussion
groups. In some conditions, participants received real-time message suggestions
generated by an LLM, either personalized to the individual or adapted to their
group context. We find that subtle shifts in linguistic style during
communication, mediated by AI assistance, can scale up to reshape collective
structures. While individual-focused assistance leads users to segregate into
like-minded groups, relational assistance that incorporates group members'
stances enhances cohesion through more receptive exchanges. These findings
demonstrate that AI-mediated communication can support social cohesion in
diverse groups, but outcomes critically depend on how personalization is
designed.

</details>


### [549] [Cross-Platform Short-Video Diplomacy: Topic and Sentiment Analysis of China-US Relations on Douyin and TikTok](https://arxiv.org/abs/2510.22415)
*Zheng Wei,Mingchen Li,Junxiang Liao,Zeyu Yang,Xiaoyu Yang,Yixuan Xie,Pan Hui,Huamin Qu*

Main category: cs.SI

TL;DR: 本研究通过分析抖音和TikTok上的中 সম্পর্ক 讨论，探讨了中国和美国社交媒体用户对中美关系的看法，并发现不同地区和经济因素会影响中国用户对美国的看法。


<details>
  <summary>Details</summary>
Motivation: 分析中国和美国社交媒体平台上围绕中美关系的讨论，以了解公众舆论和情绪。

Method: 通过对4040个视频和338,209条用户评论进行主题聚类和情感分析，并结合2022年4月后中国社交媒体账号披露的地理位置信息以及GDP、少数民族指数、互联网普及率等社会经济指标，研究中国不同地区用户对美国的情感变化。

Result: 识别出经济实力、技术和产业相互依存、文化认知和价值观追求以及对全球挑战的回应等关键主题。中国和美国在不同主题上存在显著的情感差异。研究发现，地区和社会经济因素会影响中国用户对美国的看法。

Conclusion: 通过将社会经济指标与在线讨论联系起来，深入分析了地区和经济因素如何影响中国用户对美国的看法，为中美关系研究和政策制定提供了重要见解。

Abstract: We examine discussions surrounding China-U.S. relations on the Chinese and
American social media platforms \textit{Douyin} and \textit{TikTok}. Both
platforms, owned by \textit{ByteDance}, operate under different regulatory and
cultural environments, providing a unique perspective for analyzing China-U.S.
public discourse. This study analyzed 4,040 videos and 338,209 user comments to
assess the public discussions and sentiments on social media regarding
China-U.S. relations. Through topic clustering and sentiment analysis, we
identified key themes, including economic strength, technological and
industrial interdependence, cultural cognition and value pursuits, and
responses to global challenges. There are significant emotional differences
between China and the US on various themes. Since April 2022, the Chinese
government has implemented a new regulation requiring all social media accounts
to disclose their provincial-level geolocation information. Utilizing this
publicly available data, along with factors such as GDP per capita, minority
index, and internet penetration rate, we investigate the changes in sentiment
towards the U.S. in mainland China. This study links socioeconomic indicators
with online discussions, deeply analyzing how regional and economic factors
influence Chinese comments on their views of the US, providing important
insights for China-U.S. relationship research and policy making.

</details>


### [550] [A Novel Discrete-time Model of Information Diffusion on Social Networks Considering Users Behavior](https://arxiv.org/abs/2510.22501)
*Tran Van Khanh,Do Xuan Cho,Hoang Phi Dung*

Main category: cs.SI

TL;DR: 本文提出了SDIR（Susceptible-Delayable-Infected-Recovered）模型，该模型是对经典SIR流行病框架的扩展，用于更明确地刻画在线社交网络中的用户行为。新增的D（可延迟）状态代表已接收信息但延迟传播并可能最终选择不分享的用户。基于平均场近似方法，推导了模型的动力学方程，并研究了其收敛性和稳定性条件。在这些条件下，提出了一种用于边删除问题的近似算法，旨在通过识别近似解来最小化信息传播的影响。


<details>
  <summary>Details</summary>
Motivation: 为了更明确地刻画在线社交网络中的用户行为，对经典SIR流行病框架进行了扩展。

Method: 使用平均场近似方法推导了SDIR模型的动力学方程，并研究了其收敛性和稳定性条件，然后提出了一种用于边删除问题的近似算法。

Result: 得出了SDIR模型的动力学方程，并确定了其收敛性和稳定性条件。此外，还提出了一种用于边删除问题的近似算法，旨在最小化信息传播的影响。

Conclusion: SDIR模型能够更明确地刻画在线社交网络中的用户行为，并且提出的近似算法可以有效地最小化信息传播的影响。

Abstract: In this paper, we introduce the SDIR
(Susceptible-Delayable-Infected-Recovered) model, an extension of the classical
SIR epidemic framework, to provide a more explicit characterization of user
behavior in online social networks. The newly merged state D (delayable)
represents users who have received the information but delayed its spreading
and may eventually choose not to share it at all. Based on the mean-field
approximation method, we derive the dynamical equations of the model and
investigate its convergence and stability conditions. Under these conditions,
we further propose an approximation algorithm for the edge-deletion problem,
aiming to minimize the influence of information diffusion by identifying
approximate solutions.

</details>


### [551] [Influence of Network Topology and Vaccination Strategies on HPV Dynamics: A Simulation Study Using the SeCoNet Growth Model](https://arxiv.org/abs/2510.22644)
*Weiyi Wang,Mahendra Piraveenan*

Main category: cs.SI

TL;DR: 该研究使用SeCoNet模型评估了不同疫苗接种策略在HPV传播中的有效性，并分析了网络拓扑的影响。


<details>
  <summary>Details</summary>
Motivation: 评估接触网络拓扑对HPV传播疫苗接种有效性的影响。

Method: 使用SeCoNet模型模拟了基于年龄、基于环和基于中心性（度、介数、渗透性）的疫苗接种策略，并分析了不同网络拓扑参数（平均度、幂律指数、平均最短路径长度、聚类系数）对疫苗接种效果的影响。

Result: 度、介数和渗透性中心性策略通常最有效，环状疫苗接种在降低女性累积发病率方面效果最好。更高的平均度会降低疫苗接种效果，而更高的幂律指数、更长的平均最短路径长度和更强的聚类会改善疫苗接种效果。

Conclusion: 网络结构对HPV疫苗接种策略的设计至关重要。

Abstract: This study examines how contact network topology influences the effectiveness
of vaccination programs in the context of human papillomavirus (HPV)
transmission. Using the SeCoNet sexual contact network growth model, we
evaluate age based, ring based, and several centrality based vaccination
strategies across the overall, male, and female cohorts, focusing on peak
incidence, timing of peak prevalence, and cumulative incidence. The simulations
show that degree, betweenness, and percolation centrality based strategies are
generally the most effective, while ring vaccination achieves the greatest
reduction in cumulative incidence among females. Network topology also plays a
critical role: higher average degree reduces vaccination effectiveness, whereas
higher power-law exponent, longer average shortest path length, and stronger
clustering improve vaccination outcomes. The results highlight the importance
of incorporating network structure into the design of HPV vaccination programs.

</details>


### [552] [Community Search in Attributed Networks using Dominance Relationships and Random Walks](https://arxiv.org/abs/2510.22850)
*Nikolaos Georgiadis,Eleftherios Tiakas,Apostolos N. Papadopoulos*

Main category: cs.SI

TL;DR: 该算法结合了基于跳跃和随机游走的方法，并利用支配得分和k-核心提取来平衡社区的结构连通性和属性相似性，在真实数据集上表现良好。


<details>
  <summary>Details</summary>
Motivation: 在有属性的网络中搜索社区，需要同时考虑网络的拓扑结构和节点的属性相似性，这是一个双重挑战。

Method: 该算法结合了基于跳跃和随机游走的方法，利用支配得分量化节点的属性影响力，然后进行k-核心提取以确保社区的结构凝聚力。

Result: 在大型真实世界数据集上进行了评估，证明了该算法能有效地识别出有凝聚力的社区。

Conclusion: 该算法通过同时考虑网络结构和节点属性，能够识别出既连通又具有相似属性的社区，适用于社交网络分析和推荐系统等应用。

Abstract: Community search in attributed networks poses a dual challenge: balancing
structural connectivity -- the network's topological properties -- and
attribute similarity -- the shared characteristics of nodes. This paper
introduces a novel algorithm that integrates hop-based and random-walk-based
methods to identify high-quality communities, effectively addressing this
balance. Our approach employs the concept of the domination score to quantify
the influence of nodes based on their attributes, followed by $k$-core
extraction to ensure strong structural cohesion within the communities. By
considering both the network structure and node attributes, the algorithm
identifies communities that are not only well-connected, but also share
meaningful attribute similarities. We evaluated the algorithm on large
real-world datasets, demonstrating its ability to efficiently identify cohesive
communities, making it suitable for applications such as social network
analysis and recommendation systems.

</details>


### [553] [Modeling Political Discourse with Sentence-BERT and BERTopic](https://arxiv.org/abs/2510.22904)
*Margarida Mendonca,Alvaro Figueira*

Main category: cs.SI

TL;DR: 该研究提出了一种结合BERTopic和道德基础理论（MFT）的框架，用于分析美国第117届国会期间推特政治话题的持久性和道德维度，发现护理和忠诚是持久话题的关键，而党派差异则体现在道德框架策略上。


<details>
  <summary>Details</summary>
Motivation: 分析社交媒体（特别是推特）上政治话题的持久性和道德维度，以及它们如何随着时间演变。

Method: 使用BERTopic进行话题建模，并结合道德基础理论（MFT）来追踪话题的动态变化，测量其与道德价值观的关联，并量化话题的持久性。

Result: 研究发现，虽然宏观话题保持稳定，但具体话题往往迅速消散，限制了其长期影响力。此外，道德基础（特别是护理和忠诚）对话题的持久性起着关键作用，而党派差异则通过不同的道德框架策略来体现。

Conclusion: 提出的框架为理解社交媒体上由道德驱动的话题演变提供了一种可扩展且可解释的方法，有助于社会网络分析和计算政治话语领域。

Abstract: Social media has reshaped political discourse, offering politicians a
platform for direct engagement while reinforcing polarization and ideological
divides. This study introduces a novel topic evolution framework that
integrates BERTopic-based topic modeling with Moral Foundations Theory (MFT) to
analyze the longevity and moral dimensions of political topics in Twitter
activity during the 117th U.S. Congress. We propose a methodology for tracking
dynamic topic shifts over time and measuring their association with moral
values and quantifying topic persistence. Our findings reveal that while
overarching themes remain stable, granular topics tend to dissolve rapidly,
limiting their long-term influence. Moreover, moral foundations play a critical
role in topic longevity, with Care and Loyalty dominating durable topics, while
partisan differences manifest in distinct moral framing strategies. This work
contributes to the field of social network analysis and computational political
discourse by offering a scalable, interpretable approach to understanding
moral-driven topic evolution on social media.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [554] [A Feature Engineering Approach for Business Impact-Oriented Failure Detection in Distributed Instant Payment Systems](https://arxiv.org/abs/2510.21710)
*Lorenzo Porcelli*

Main category: cs.LG

TL;DR: 本研究提出了一种基于消息处理时间的特征工程方法，用于实时支付系统，以实现早期故障检测和业务影响的可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统监控方法无法将技术指标与业务流程可见性联系起来，而实时支付系统对性能和零停机时间有严格要求。

Method: 通过计算连续ISO 20022消息交换之间的时间来构建特征，并将异常检测应用于这些特征，以实现早期故障检测、定位和事件分类。

Result: 在TARGET即时支付结算（TIPS）系统上进行的实验表明，该方法能有效检测各种异常模式，并提供可解释的业务影响。

Conclusion: 该框架通过将特征映射到不同的处理阶段，区分了内部和外部支付系统问题，显著减少了调查时间，并弥合了分布式系统中由于交易状态分散而导致的可见性差距。

Abstract: Instant payment infrastructures have stringent performance requirements,
processing millions of transactions daily with zero-downtime expectations.
Traditional monitoring approaches fail to bridge the gap between technical
infrastructure metrics and business process visibility. We introduce a novel
feature engineering approach based on processing times computed between
consecutive ISO 20022 message exchanges, creating a compact representation of
system state. By applying anomaly detection to these features, we enable early
failure detection and localization, allowing incident classification.
Experimental evaluation on the TARGET Instant Payment Settlement (TIPS) system,
using both real-world incidents and controlled simulations, demonstrates the
approach's effectiveness in detecting diverse anomaly patterns and provides
inherently interpretable explanations that enable operators to understand the
business impact. By mapping features to distinct processing phases, the
resulting framework differentiates between internal and external payment system
issues, significantly reduces investigation time, and bridges observability
gaps in distributed systems where transaction state is fragmented across
multiple entities.

</details>


### [555] [Numerical Fragility in Transformers: A Layer-wise Theory for Explaining, Forecasting, and Mitigating Instability](https://arxiv.org/abs/2510.21770)
*Jinwoo Baek*

Main category: cs.LG

TL;DR: 本文提出了一个预测 Transformer 模型在低精度训练中前向误差累积的理论框架，并开发了一套可解释的诊断指标，用于预测和缓解模型的不稳定性。


<details>
  <summary>Details</summary>
Motivation: 低精度训练 Transformer 时，前向误差可能会被放大，导致模型性能下降。需要一种理论来预测和理解这种误差的增长，并提出相应的缓解方法。

Method: 提出一个模块化的、一阶的理论来预测误差增长。对于自注意力机制，推导了一个每层的绑定，该绑定可以分解为三个可解释的诊断指标：score-scale ratio $\kappa_{\rm score}$，row-wise softmax sensitivity $\kappa_{\rm softmax}$，以及 value conditioning $\kappa(V)$。证明了一个残差松弛不等式来展示残差块如何衰减深度累积误差。引入了一个与精度和宽度相关的 LayerNorm 指标 $\rho_{\rm LN}$，并在 $\epsilon$-dominated regime 下给出了匹配的一阶绑定。将这些部分组合起来，形成一个统一的前向稳定性绑定，其右侧可以在训练过程中直接估计。

Result: 在 Tiny-ViT/CIFAR-10 上评估了该绑定和组件。结果表明：1. 预测器 $\kappa_{\rm softmax},(1+\kappa_{\rm score}),\kappa(V),|W_O|2+\kappa{\rm eff}+C_{\rm LN}$ 能够跟踪 FP32 与低精度之间的不匹配。2. $\kappa_{\rm softmax}$ 的时间序列最大值可以作为早期预警信号，提前 16-24 步预测误差峰值。3. 在 $\rho_{\rm LN}$ 的指导下，通过微调 LayerNorm 的 $\epsilon$ 值，可以稳定模型性能，且开销极小。

Conclusion: 提出的理论框架提供了可操作的、无单位的诊断指标，能够解释自注意力机制何时变得脆弱，预测模型不稳定性，并指导进行最小化的缓解措施。

Abstract: Transformers trained in low precision can suffer forward-error amplification.
We give a first-order, module-wise theory that predicts when and where errors
grow. For self-attention we derive a per-layer bound that factorizes into three
interpretable diagnostics: a score-scale ratio $\kappa_{\rm score}$, a rowwise
softmax sensitivity $\kappa_{\rm softmax}$, and value conditioning $\kappa(V)$.
We prove a residual relaxation inequality showing that residual blocks
attenuate depth-wise accumulation, and we introduce a precision- and
width-aware LayerNorm indicator $\rho_{\rm LN}$ with a matching first-order
bound in the $\epsilon$-dominated regime. These pieces yield a unified
forward-stability bound whose right-hand side is directly estimable during
training.
  On Tiny-ViT/CIFAR-10 we evaluate the bound and components. (1) The combined
predictor $\kappa_{\rm softmax},(1+\kappa_{\rm
score}),\kappa(V),|W_O|2+\kappa{\rm eff}+C_{\rm LN}$ tracks
FP32$\leftrightarrow$LP mismatches across seeds, widths, and precisions;
scaling by $\epsilon_{\rm mach}$ collapses mixed-precision points. (2) The
time-series maximum of $\kappa_{\rm softmax}$ acts as an early-warning signal,
leading error spikes by 16-24 steps (corr. 0.65-0.82; permutation
$p!\approx!10^{-3}$; Precision@K 0.89-1.00). (3) Guided by $\rho_{\rm LN}$, a
small LayerNorm-$\epsilon$ tweak targeting $\rho_\star$ gives consistent
stabilization (mean tail-loss $\downarrow\ \approx0.010$ at $\rho_\star!=!0.6$,
cap$=10^{-2}$) with negligible overhead.
  Overall, our theory supplies actionable, unitless diagnostics that (i)
explain when self-attention is fragile, (ii) forecast instability, and (iii)
motivate a minimally invasive mitigation.

</details>


### [556] [Chebyshev Moment Regularization (CMR): Condition-Number Control with Moment Shaping](https://arxiv.org/abs/2510.21772)
*Jinwoo Baek*

Main category: cs.LG

TL;DR: Chebyshev Moment Regularization (CMR) 是一种直接优化层谱的损失函数，可提高模型的稳定性、准确性和对抗鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统的模型训练方法可能导致模型不稳定，尤其是在对抗性设置下。本研究旨在通过直接优化模型的层谱来提高训练的稳定性和准确性。

Method: CMR 通过日志条件代理共同控制谱边，并通过 Chebyshev 矩塑造内部，同时采用解耦的、有上限的混合规则来保留任务梯度。该方法直接作用于层的谱特性，而非传统的损失函数。

Result: 在对抗性“κ-stress”设置（MNIST，15 层 MLP）下，CMR 将平均层条件数降低了约 10^3 倍（从约 3.9×10^3 降低到 5 个 epoch 后的约 3.4），增加了平均梯度幅度，并将测试准确率从约 10% 提高到约 86%。

Conclusion: 直接引导模型达到良好条件的状态是实现稳定、准确学习的一种有效的优化驱动的谱预条件方法。

Abstract: We introduce \textbf{Chebyshev Moment Regularization (CMR)}, a simple,
architecture-agnostic loss that directly optimizes layer spectra. CMR jointly
controls spectral edges via a log-condition proxy and shapes the interior via
Chebyshev moments, with a decoupled, capped mixing rule that preserves task
gradients. We prove strictly monotone descent for the condition proxy, bounded
moment gradients, and orthogonal invariance. In an adversarial
``$\kappa$-stress'' setting (MNIST, 15-layer MLP), \emph{compared to vanilla
training}, CMR reduces mean layer condition numbers by $\sim\!10^3$ (from
$\approx3.9\!\times\!10^3$ to $\approx3.4$ in 5 epochs), increases average
gradient magnitude, and restores test accuracy (
$\approx10\%\!\to\!\approx86\%$ ). These results support
\textbf{optimization-driven spectral preconditioning}: directly steering models
toward well-conditioned regimes for stable, accurate learning.

</details>


### [557] [Revisiting Orbital Minimization Method for Neural Operator Decomposition](https://arxiv.org/abs/2510.21952)
*J. Jon Ryu,Samuel Zhou,Gregory W. Wornell*

Main category: cs.LG

TL;DR: 本篇论文回顾了计算物理学中经典的轨道最小化方法（OMM），并将其应用于训练神经网络来分解正半定算子，证明了该方法在现代机器学习中的有效性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 在机器学习和科学计算的许多领域，线性算子的谱分解都扮演着核心角色。训练神经网络来近似这些算子的特征函数，为表示学习、动力学系统和偏微分方程（PDE）等领域提供了可扩展的方法。本研究旨在证明OMM方法更广泛地应用于现代学习管道的合理性。

Method: 本研究重新审视了计算物理学中一个经典的优化框架——轨道最小化方法（OMM），并将其改编用于训练神经网络分解正半定算子。

Result: 通过在多种基准任务上的实验，证明了该方法在实践中的优势，展示了其作为一种原则性的方法，可以有效地、可扩展地用于将神经网络部署到数值模拟和机器学习中。

Conclusion: 回顾经典的数值方法，并结合现代的理论与计算视角，不仅能够为将神经网络应用于数值模拟提供一个原则性的途径，而且还能开发出有效的、可扩展的机器学习工具。

Abstract: Spectral decomposition of linear operators plays a central role in many areas
of machine learning and scientific computing. Recent work has explored training
neural networks to approximate eigenfunctions of such operators, enabling
scalable approaches to representation learning, dynamical systems, and partial
differential equations (PDEs). In this paper, we revisit a classical
optimization framework from the computational physics literature known as the
\emph{orbital minimization method} (OMM), originally proposed in the 1990s for
solving eigenvalue problems in computational chemistry. We provide a simple
linear-algebraic proof of the consistency of the OMM objective, and reveal
connections between this method and several ideas that have appeared
independently across different domains. Our primary goal is to justify its
broader applicability in modern learning pipelines. We adapt this framework to
train neural networks to decompose positive semidefinite operators, and
demonstrate its practical advantages across a range of benchmark tasks. Our
results highlight how revisiting classical numerical methods through the lens
of modern theory and computation can provide not only a principled approach for
deploying neural networks in numerical simulation, but also effective and
scalable tools for machine learning.

</details>


### [558] [What Causes Postoperative Aspiration?](https://arxiv.org/abs/2510.21779)
*Supriya Nagesh,Karina Covarrubias,Robert El-Kareh,Shiva Prasad Kasiviswanathan,Nina Mishra*

Main category: cs.LG

TL;DR: 使用机器学习模型预测术后误吸风险，发现阿片类药物剂量、住院时长、患者年龄、手术部位是关键预测因素，并揭示了性别差异。


<details>
  <summary>Details</summary>
Motivation: 为了预测术后误吸风险，以进行及时的预防干预。

Method: 从MIMIC-IV数据库中提取了826名术后七天内发生误吸的患者及其匹配的非误吸对照组，并使用XGBoost、多层感知机和随机森林三种机器学习模型，利用术前住院数据进行训练，同时运用增广逆概率加权法估计平均处理效应（ATE）以探究因果关系。

Result: 机器学习模型在独立测试集上达到了0.86的AUROC和77.3%的敏感性。每日最大阿片类药物剂量、住院时长和患者年龄是最重要的预测因子。ATE分析显示阿片类药物（0.25 +/- 0.06）和手术部位（颈部：0.20 +/- 0.13，头部：0.19 +/- 0.13）是显著的致病因素。男性患者的误吸可能性是女性的1.5倍，并且接受的每日最大阿片类药物剂量比女性高27%。

Conclusion: 机器学习模型能有效预测术后误吸风险，从而实现靶向预防。每日最大阿片类药物剂量和手术部位显著影响误吸风险。男女在阿片类药物使用和误吸率上的差异值得进一步研究。这些发现对改进术后护理方案和误吸预防策略具有重要意义。

Abstract: Background: Aspiration, the inhalation of foreign material into the lungs,
significantly impacts surgical patient morbidity and mortality. This study
develops a machine learning (ML) model to predict postoperative aspiration,
enabling timely preventative interventions.
  Methods: From the MIMIC-IV database of over 400,000 hospital admissions, we
identified 826 surgical patients (mean age: 62, 55.7\% male) who experienced
aspiration within seven days post-surgery, along with a matched non-aspiration
cohort. Three ML models: XGBoost, Multilayer Perceptron, and Random Forest were
trained using pre-surgical hospitalization data to predict postoperative
aspiration. To investigate causation, we estimated Average Treatment Effects
(ATE) using Augmented Inverse Probability Weighting.
  Results: Our ML model achieved an AUROC of 0.86 and 77.3\% sensitivity on a
held-out test set. Maximum daily opioid dose, length of stay, and patient age
emerged as the most important predictors. ATE analysis identified significant
causative factors: opioids (0.25 +/- 0.06) and operative site (neck: 0.20 +/-
0.13, head: 0.19 +/- 0.13). Despite equal surgery rates across genders, men
were 1.5 times more likely to aspirate and received 27\% higher maximum daily
opioid dosages compared to women.
  Conclusion: ML models can effectively predict postoperative aspiration risk,
enabling targeted preventative measures. Maximum daily opioid dosage and
operative site significantly influence aspiration risk. The gender disparity in
both opioid administration and aspiration rates warrants further investigation.
These findings have important implications for improving postoperative care
protocols and aspiration prevention strategies.

</details>


### [559] [Accelerating Eigenvalue Dataset Generation via Chebyshev Subspace Filter](https://arxiv.org/abs/2510.23215)
*Hong Wang,Jie Wang,Jian Luo,huanshuo dong,Yeqiu Chen,Runmin Jiang,Zhen huang*

Main category: cs.LG

TL;DR: SCSF是一种新颖的神经特征值方法，通过利用算子间的相似性来加速特征值数据的生成，解决了传统方法对大量标记数据依赖的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的神经特征值方法在训练时需要大量标记数据（包括算子及其特征值），这限制了其应用。本研究旨在解决这一局限性。

Method: 提出了一种名为排序切比雪夫子空间滤波（SCSF）的新方法。SCSF利用截断的快速傅里叶变换排序来对具有相似特征值分布的算子进行分组，并构建一个切比雪夫子空间滤波器，利用先前已求解问题的特征对来辅助求解后续问题，从而减少冗余计算。

Result: 实验结果表明，与各种数值求解器相比，SCSF的提速最高可达3.5倍。

Conclusion: SCSF是首个能够加速特征值数据生成的方法，有效地解决了现有神经特征值方法在数据需求方面的限制，并在实验中取得了显著的加速效果。

Abstract: Eigenvalue problems are among the most important topics in many scientific
disciplines. With the recent surge and development of machine learning, neural
eigenvalue methods have attracted significant attention as a forward pass of
inference requires only a tiny fraction of the computation time compared to
traditional solvers. However, a key limitation is the requirement for large
amounts of labeled data in training, including operators and their eigenvalues.
To tackle this limitation, we propose a novel method, named Sorting Chebyshev
Subspace Filter (SCSF), which significantly accelerates eigenvalue data
generation by leveraging similarities between operators -- a factor overlooked
by existing methods. Specifically, SCSF employs truncated fast Fourier
transform sorting to group operators with similar eigenvalue distributions and
constructs a Chebyshev subspace filter that leverages eigenpairs from
previously solved problems to assist in solving subsequent ones, reducing
redundant computations. To the best of our knowledge, SCSF is the first method
to accelerate eigenvalue data generation. Experimental results show that SCSF
achieves up to a $3.5\times$ speedup compared to various numerical solvers.

</details>


### [560] [Online Mixture of Experts: No-Regret Learning for Optimal Collective Decision-Making](https://arxiv.org/abs/2510.21788)
*Larkin Liu,Jalal Etesami*

Main category: cs.LG

TL;DR: We introduce Online Mixture-of-Experts (OMoE), an expert-guided bandit learning approach for aggregating expert outputs to optimize aggregate accuracy. Two algorithms are proposed: one uses UCB-driven elimination, the other uses online weighted majority voting. Both have theoretical regret guarantees and are applied to fine-tune large language models (LLMs).


<details>
  <summary>Details</summary>
Motivation: The paper aims to address the problem of aggregating outputs from a committee of experts to achieve optimal results in terms of aggregate accuracy within a bandit learning setting.

Method: The paper proposes two algorithms: 1. Aggregate voting combined with UCB-driven successive elimination to prune suboptimal exploration actions. 2. Online weighted-majority-voting mechanism where expert voting power is proportional to their predictive power. Theoretical regret guarantees are derived, and empirical results are provided. The methods are applied to online fine-tuning of LLMs.

Result: The proposed OMoE methods, including UCB-driven elimination and weighted majority voting, achieve optimal aggregate accuracy. Applied to LLMs, these methods enable dynamic reweighing or selection of expert committees for generating accurate responses. The study provides no-regret guarantees for combining multiple experts.

Conclusion: The paper introduces novel methodologies and no-regret guarantees for effectively combining multiple experts to enhance the performance of an aggregate model, with successful application to the online fine-tuning of large language models.

Abstract: We explore the use of expert-guided bandit learning, which we refer to as
online mixture-of-experts (OMoE). In this setting, given a context, a candidate
committee of experts must determine how to aggregate their outputs to achieve
optimal results in terms of aggregate accuracy. We propose two algorithms to
address this problem. The first algorithm combines aggregate voting with
UCB-driven successive elimination, efficiently pruning suboptimal exploration
actions. The second algorithm employs an online weighted-majority-voting
mechanism, leveraging the respective voting power of each expert proportional
to their predictive power. We derive theoretical guarantees for the regret
properties in the bandit setting under ideal circumstances, and empirical
results are provided accordingly. As a modern study on applications, these
methods are applied to the online fine-tuning of a set of expert large language
models (LLMs), where after each response, the generative LLM dynamically
reweighs its set of experts and/or selects the optimal committee of experts to
generate the most accurate response. Our results introduce new methodologies
and no-regret guarantees for combining multiple experts to improve on the
performance of the an aggregate model overall.

</details>


### [561] [Grassmanian Interpolation of Low-Pass Graph Filters: Theory and Applications](https://arxiv.org/abs/2510.23235)
*Anton Savostianov,Michael T. Schaub,Benjamin Stamm*

Main category: cs.LG

TL;DR: 图信号处理中，参数化图族的低通图滤波器计算成本高昂。本文提出一种基于黎曼流形上法向量坐标插值的低通图滤波器插值新算法，并推导了子空间插值的误差界估计，同时提出了两种应用：一种是可通过相似性校正将节点特征的时间演化转化为演化图拓扑，另一种是利用给定的静态图推断点积图族，从而实现改进的消息传递机制进行节点分类。


<details>
  <summary>Details</summary>
Motivation: 计算参数化图族的低通图滤波器成本高昂，因为需要反复求解特征值问题。

Method: 提出一种基于黎曼流形上法向量坐标插值的低通图滤波器插值算法。

Result: 推导了子空间插值的误差界估计，并提出了两种应用：1. 通过相似性校正将节点特征的时间演化转化为演化图拓扑；2. 利用给定的静态图推断点积图族，以改进节点分类的消息传递方案。

Conclusion: 所提出的算法可以有效降低参数化图族低通图滤波器的计算成本，并通过两种应用展示了其有效性。

Abstract: Low-pass graph filters are fundamental for signal processing on graphs and
other non-Euclidean domains. However, the computation of such filters for
parametric graph families can be prohibitively expensive as computation of the
corresponding low-frequency subspaces, requires the repeated solution of an
eigenvalue problem. We suggest a novel algorithm of low-pass graph filter
interpolation based on Riemannian interpolation in normal coordinates on the
Grassmann manifold. We derive an error bound estimate for the subspace
interpolation and suggest two possible applications for induced parametric
graph families. First, we argue that the temporal evolution of the node
features may be translated to the evolving graph topology via a similarity
correction to adjust the homophily degree of the network. Second, we suggest a
dot product graph family induced by a given static graph which allows to infer
improved message passing scheme for node classification facilitated by the
filter interpolation.

</details>


### [562] [Logical GANs: Adversarial Learning through Ehrenfeucht Fraisse Games](https://arxiv.org/abs/2510.22824)
*Mirco A. Mannucci*

Main category: cs.LG

TL;DR: LOGAN将逻辑解释和GAN结合起来，通过限制判别器的“视野”到一个逻辑深度k，并让生成器产生对该判别器“正确”的样本，从而实现可解释的、可控的生成。


<details>
  <summary>Details</summary>
Motivation: 将生成对抗网络（GAN）与逻辑解释相结合，以实现可控和可解释的生成。

Method: LOGAN将判别器视为一个深度为k的Ehrenfeucht-Fraïssé（EF）“对手”，寻找小的、可解释的故障；生成器则充当“构建者”，生成能够与目标理论T进行k轮匹配的样本。该方法包含一个EF探测模拟器和MSO风格的图检查器。

Result: 通过模拟（实验3），LOGAN实现了92%-98%的属性满足率；通过实际的神经网络GAN训练（实验4），在具有挑战性的属性方面提高了5%-14%，并在连通性方面达到了98%的满足率。

Conclusion: LOGAN是一种紧凑、可复现的方法，可以实现逻辑约束下的生成，具有可解释的失败模式、已证明的有效性（模拟和实际训练）以及可调节的参数。

Abstract: GANs promise indistinguishability, logic explains it. We put the two on a
budget: a discriminator that can only ``see'' up to a logical depth $k$, and a
generator that must look correct to that bounded observer. \textbf{LOGAN}
(LOGical GANs) casts the discriminator as a depth-$k$ Ehrenfeucht--Fra\"iss\'e
(EF) \emph{Opponent} that searches for small, legible faults (odd cycles,
nonplanar crossings, directed bridges), while the generator plays
\emph{Builder}, producing samples that admit a $k$-round matching to a target
theory $T$. We ship a minimal toolkit -- an EF-probe simulator and MSO-style
graph checkers -- and four experiments including real neural GAN training with
PyTorch. Beyond verification, we score samples with a \emph{logical loss} that
mixes budgeted EF round-resilience with cheap certificate terms, enabling a
practical curriculum on depth. Framework validation demonstrates $92\%$--$98\%$
property satisfaction via simulation (Exp.~3), while real neural GAN training
achieves $5\%$--$14\%$ improvements on challenging properties and $98\%$
satisfaction on connectivity (matching simulation) through adversarial learning
(Exp.~4). LOGAN is a compact, reproducible path toward logic-bounded generation
with interpretable failures, proven effectiveness (both simulated and real
training), and dials for control.

</details>


### [563] [Variance-Reduction Guidance: Sampling Trajectory Optimization for Diffusion Models](https://arxiv.org/abs/2510.21792)
*Shifeng Xu,Yanzhu Liu,Adams Wai-Kin Kong*

Main category: cs.LG

TL;DR: 扩散模型采样过程中的预测误差会累积并降低生成质量。本文提出了方差-缩减引导 (VRG) 方法，通过在预定采样轨迹的基础上搜索新的轨迹来减小预测误差，从而提高生成质量，且无需微调或修改模型。


<details>
  <summary>Details</summary>
Motivation: 扩散模型的采样过程涉及多个步骤，每一步的预测误差会累积并导致生成质量下降。

Method: 提出了一种统计测量预测误差的新技术，并提出了方差-缩减引导 (VRG) 方法来减小该误差。VRG 在给定的采样轨迹基础上，搜索具有相同采样步数但能产生更高质量结果的新轨迹。

Result: VRG 是一种无需模型微调或修改的方法，可用于条件和无条件生成。在各种数据集和基线上的实验表明，VRG 显著提高了扩散模型的生成质量。

Conclusion: VRG 能够有效减轻扩散模型采样过程中的预测误差，从而提高生成质量，是一种通用的、无需微调的后处理方法。

Abstract: Diffusion models have become emerging generative models. Their sampling
process involves multiple steps, and in each step the models predict the noise
from a noisy sample. When the models make prediction, the output deviates from
the ground truth, and we call such a deviation as \textit{prediction error}.
The prediction error accumulates over the sampling process and deteriorates
generation quality. This paper introduces a novel technique for statistically
measuring the prediction error and proposes the Variance-Reduction Guidance
(VRG) method to mitigate this error. VRG does not require model fine-tuning or
modification. Given a predefined sampling trajectory, it searches for a new
trajectory which has the same number of sampling steps but produces higher
quality results. VRG is applicable to both conditional and unconditional
generation. Experiments on various datasets and baselines demonstrate that VRG
can significantly improve the generation quality of diffusion models. Source
code is available at https://github.com/shifengxu/VRG.

</details>


### [564] [BBOPlace-Bench: Benchmarking Black-Box Optimization for Chip Placement](https://arxiv.org/abs/2510.23472)
*Ke Xue,Ruo-Tong Chen,Rong-Xi Tan,Xi Lin,Yunqi Shi,Siyuan Xu,Mingxuan Yuan,Chao Qian*

Main category: cs.LG

TL;DR: 该论文提出了BBOPlace-Bench，一个专门用于评估和开发芯片放置黑盒优化（BBO）算法的基准测试。


<details>
  <summary>Details</summary>
Motivation: 现有芯片放置研究缺乏统一的、专门针对BBO的基准测试，阻碍了对不同问题表述和算法的全面评估。

Method: 提出BBOPlace-Bench基准测试，包含三种BBO问题表述，提供模块化、解耦和灵活的框架，并集成了SA、EA和BO等多种BBO算法。

Result: 实验结果表明，掩码引导优化和超参数优化问题表述优于序列对表述；EA算法在SearchCV和BO算法之上，尤其在高维搜索空间中表现更好，并达到了最先进的性能。

Conclusion: BBOPlace-Bench促进了高效BBO驱动的芯片放置解决方案的发展，并扩大了BBO在芯片放置领域的实际应用场景。

Abstract: Chip placement is a vital stage in modern chip design as it has a substantial
impact on the subsequent processes and the overall quality of the final chip.
The use of black-box optimization (BBO) for chip placement has a history of
several decades. However, early efforts were limited by immature problem
formulations and inefficient algorithm designs. Recent progress has shown the
effectiveness and efficiency of BBO for chip placement, proving its potential
to achieve state-of-the-art results. Despite these advancements, the field
lacks a unified, BBO-specific benchmark for thoroughly assessing various
problem formulations and BBO algorithms. To fill this gap, we propose
BBOPlace-Bench, the first benchmark designed specifically for evaluating and
developing BBO algorithms for chip placement tasks. It integrates three problem
formulations of BBO for chip placement, and offers a modular, decoupled, and
flexible framework that enables users to seamlessly implement, test, and
compare their own algorithms. BBOPlace-Bench integrates a wide variety of
existing BBO algorithms, including simulated annealing (SA), evolutionary
algorithms (EAs), and Bayesian optimization (BO). Experimental results show
that the problem formulations of mask-guided optimization and hyperparameter
optimization exhibit superior performance than the sequence pair problem
formulation, while EAs demonstrate better overall performance than SA and BO,
especially in high-dimensional search spaces, and also achieve state-of-the-art
performance compared to the mainstream chip placement methods. BBOPlace-Bench
not only facilitates the development of efficient BBO-driven solutions for chip
placement but also broadens the practical application scenarios (which are
urgently needed) for the BBO community. The code of BBOPlace-Bench is available
at https://github.com/lamda-bbo/BBOPlace-Bench.

</details>


### [565] [Mixed Precision Training of Neural ODEs](https://arxiv.org/abs/2510.23498)
*Elena Celledoni,Brynjulf Owren,Lars Ruthotto,Tianjiao Nicole Yang*

Main category: cs.LG

TL;DR: 该研究提出了一种用于神经ODE（Neural ODE）的混合精度训练框架，通过结合显式ODE求解器和自定义反向传播方案，在保证精度的同时，显著降低了计算成本和内存需求。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型和数据集的不断增长带来了巨大的计算成本，而神经ODE等连续时间架构在混合精度训练方面存在挑战，如舍入误差、不稳定性以及计算成本和内存需求问题。

Method: 提出了一种结合显式ODE求解器和自定义反向传播方案的混合精度训练框架。该框架对神经网路参数化的速度和中间状态使用低精度计算，并通过自定义动态伴随缩放以及高精度累积解和梯度来保证稳定性。

Result: 在图像分类和生成模型等神经ODE应用中，实现了约50%的内存减少和高达2倍的速度提升，同时保持了与单精度训练相当的准确性。

Conclusion: 所提出的混合精度训练框架能够有效解决神经ODE训练中的计算成本和内存增长问题，实现了在保持精度的前提下的效率提升。此外，研究发布了一个名为rampde的开源PyTorch包，方便用户替换现有代码。

Abstract: Exploiting low-precision computations has become a standard strategy in deep
learning to address the growing computational costs imposed by ever larger
models and datasets. However, naively performing all computations in low
precision can lead to roundoff errors and instabilities. Therefore, mixed
precision training schemes usually store the weights in high precision and use
low-precision computations only for whitelisted operations. Despite their
success, these principles are currently not reliable for training
continuous-time architectures such as neural ordinary differential equations
(Neural ODEs). This paper presents a mixed precision training framework for
neural ODEs, combining explicit ODE solvers with a custom backpropagation
scheme, and demonstrates its effectiveness across a range of learning tasks.
Our scheme uses low-precision computations for evaluating the velocity,
parameterized by the neural network, and for storing intermediate states, while
stability is provided by a custom dynamic adjoint scaling and by accumulating
the solution and gradients in higher precision. These contributions address two
key challenges in training neural ODE: the computational cost of repeated
network evaluations and the growth of memory requirements with the number of
time steps or layers. Along with the paper, we publish our extendable,
open-source PyTorch package rampde, whose syntax resembles that of leading
packages to provide a drop-in replacement in existing codes. We demonstrate the
reliability and effectiveness of our scheme using challenging test cases and on
neural ODE applications in image classification and generative models,
achieving approximately 50% memory reduction and up to 2x speedup while
maintaining accuracy comparable to single-precision training.

</details>


### [566] [The Principles of Diffusion Models](https://arxiv.org/abs/2510.21890)
*Chieh-Hsin Lai,Yang Song,Dongjun Kim,Yuki Mitsufuji,Stefano Ermon*

Main category: cs.LG

TL;DR: this monograph explains diffusion models by tracing their origins and showing how different formulations stem from shared mathematical concepts. it covers variational, score-based, and flow-based views, highlighting their common reliance on a time-dependent velocity field to transform noise into data via differential equations. the book also touches on controllable generation, numerical solvers, and diffusion-motivated flow-map models.


<details>
  <summary>Details</summary>
Motivation: The motivation behind this monograph is to present the core principles guiding the development of diffusion models, trace their origins, and demonstrate how diverse formulations emerge from shared mathematical ideas. It aims to provide a conceptually and mathematically grounded understanding of these models for readers with basic deep learning knowledge.

Method: The monograph explains diffusion models by detailing a forward process that corrupts data into noise and a reverse process that transforms noise back into data. It presents three complementary views: variational (learning to remove noise step-by-step), score-based (learning the gradient of the data distribution), and flow-based (treating generation as following a learned velocity field path). A common backbone of a time-dependent velocity field is identified, and sampling is described as solving a differential equation. The book also discusses guidance for controllable generation, efficient numerical solvers, and diffusion-motivated flow-map models.

Result: The monograph provides a comprehensive understanding of diffusion models, unifying different perspectives (variational, score-based, flow-based) under the concept of a time-dependent velocity field and differential equations for sampling. It also covers advanced topics like controllable generation and efficient solvers.

Conclusion: Diffusion models, unified by the concept of a time-dependent velocity field and solved through differential equations, offer a powerful framework for generative tasks. This monograph provides a foundational understanding, enabling further exploration into areas like controllable generation and efficient sampling.

Abstract: This monograph presents the core principles that have guided the development
of diffusion models, tracing their origins and showing how diverse formulations
arise from shared mathematical ideas. Diffusion modeling starts by defining a
forward process that gradually corrupts data into noise, linking the data
distribution to a simple prior through a continuum of intermediate
distributions. The goal is to learn a reverse process that transforms noise
back into data while recovering the same intermediates. We describe three
complementary views. The variational view, inspired by variational
autoencoders, sees diffusion as learning to remove noise step by step. The
score-based view, rooted in energy-based modeling, learns the gradient of the
evolving data distribution, indicating how to nudge samples toward more likely
regions. The flow-based view, related to normalizing flows, treats generation
as following a smooth path that moves samples from noise to data under a
learned velocity field. These perspectives share a common backbone: a
time-dependent velocity field whose flow transports a simple prior to the data.
Sampling then amounts to solving a differential equation that evolves noise
into data along a continuous trajectory. On this foundation, the monograph
discusses guidance for controllable generation, efficient numerical solvers,
and diffusion-motivated flow-map models that learn direct mappings between
arbitrary times. It provides a conceptual and mathematically grounded
understanding of diffusion models for readers with basic deep-learning
knowledge.

</details>


### [567] [A Physics-Guided AI Cascaded Corrector Model Significantly Extends Madden-Julian Oscillation Prediction Skill](https://arxiv.org/abs/2510.21796)
*Xiao Zhou,Yuze Sun,Jie Wu,Xiaomeng Huang*

Main category: cs.LG

TL;DR: 一个名为PCC-MJO的深度学习框架可以修正MJO（马登-杰齣）的动力学模型预报，将预报技巧的有效范围延长2-8天，并且能够克服“海洋大陆障碍”，同时AI分析表明该模型学习的是物理上合理的特征。


<details>
  <summary>Details</summary>
Motivation: MJO（马登-杰齣）是全球天气和气候事件的重要驱动因素，但其在业务动力学模型中的预测仍具挑战性，通常仅限于3-4周的有效预报期。

Method: 提出了一种名为PCC-MJO（物理引导级联校正器）的新型深度学习框架，作为对动力学模型MJO预报进行订正的通用后处理器。该模型分为两个阶段：首先使用物理信息3D U-Net校正时空场误差，然后使用为预报技巧优化的LSTM优化MJO的RMM指数。

Result: 将该框架应用于中国气象局、欧洲中期天气预报中心和美国国家环境预报中心的三种不同的业务预报，统一框架将有技巧的预报范围（双变量相关性>0.5）持续延长了2-8天。该模型有效缓解了“海洋大陆障碍”，实现了更真实的向东传播和振幅。可解释AI分析定量证实，模型的决策在空间上与观测到的MJO动力学一致（相关性>0.93），表明它学习的是物理上有意义的特征，而不是统计拟合。

Conclusion: 所提出的PCC-MJO框架为突破次季节预报的长期瓶颈提供了一条有前景的、物理上一致的、计算上高效且高度可推广的途径。

Abstract: The Madden-Julian Oscillation (MJO) is an important driver of global weather
and climate extremes, but its prediction in operational dynamical models
remains challenging, with skillful forecasts typically limited to 3-4 weeks.
Here, we introduce a novel deep learning framework, the Physics-guided Cascaded
Corrector for MJO (PCC-MJO), which acts as a universal post-processor to
correct MJO forecasts from dynamical models. This two-stage model first employs
a physics-informed 3D U-Net to correct spatial-temporal field errors, then
refines the MJO's RMM index using an LSTM optimized for forecast skill. When
applied to three different operational forecasts from CMA, ECMWF and NCEP, our
unified framework consistently extends the skillful forecast range (bivariate
correlation > 0.5) by 2-8 days. Crucially, the model effectively mitigates the
"Maritime Continent barrier", enabling more realistic eastward propagation and
amplitude. Explainable AI analysis quantitatively confirms that the model's
decision-making is spatially congruent with observed MJO dynamics (correlation
> 0.93), demonstrating that it learns physically meaningful features rather
than statistical fittings. Our work provides a promising physically consistent,
computationally efficient, and highly generalizable pathway to break through
longstanding barriers in subseasonal forecasting.

</details>


### [568] [Power to the Clients: Federated Learning in a Dictatorship Setting](https://arxiv.org/abs/2510.22149)
*Mohammadsajad Alipour,Mohammad Mohammadi Amiri*

Main category: cs.LG

TL;DR: 该论文提出了一种名为“独裁者客户端”的新型恶意参与者类别，能够完全清除服务器模型中除自身贡献外的所有其他客户端的贡献，并提出了相应的攻击策略和理论分析，通过实验验证了其在计算机视觉和自然语言处理任务中的有效性。


<details>
  <summary>Details</summary>
Motivation: 去中心化的联邦学习（FL）虽然允许多个客户端协作训练模型而不共享数据，但也容易受到恶意客户端的攻击。因此，需要研究恶意行为对FL的影响。

Method: 提出“独裁者客户端”的概念，设计攻击策略，并对包含一个或多个独裁者客户端的场景进行理论分析，包括它们合作、独立或结盟但最终互相背叛的情况。

Result: 展示了独裁者客户端如何完全清除其他客户端的贡献，并分析了不同场景下多独裁者客户端对全局模型收敛的影响。

Conclusion: 理论分析和算法得到了计算机视觉和自然语言处理基准的实证评估支持，证明了独裁者客户端攻击的有效性和复杂性。

Abstract: Federated learning (FL) has emerged as a promising paradigm for decentralized
model training, enabling multiple clients to collaboratively learn a shared
model without exchanging their local data. However, the decentralized nature of
FL also introduces vulnerabilities, as malicious clients can compromise or
manipulate the training process. In this work, we introduce dictator clients, a
novel, well-defined, and analytically tractable class of malicious participants
capable of entirely erasing the contributions of all other clients from the
server model, while preserving their own. We propose concrete attack strategies
that empower such clients and systematically analyze their effects on the
learning process. Furthermore, we explore complex scenarios involving multiple
dictator clients, including cases where they collaborate, act independently, or
form an alliance in order to ultimately betray one another. For each of these
settings, we provide a theoretical analysis of their impact on the global
model's convergence. Our theoretical algorithms and findings about the complex
scenarios including multiple dictator clients are further supported by
empirical evaluations on both computer vision and natural language processing
benchmarks.

</details>


### [569] [Quantifying Multimodal Imbalance: A GMM-Guided Adaptive Loss for Audio-Visual Learning](https://arxiv.org/abs/2510.21797)
*Zhaocheng Liu,Zhiwen Yu,Xiaoqing Liu*

Main category: cs.LG

TL;DR: 该研究提出了一种量化模态不平衡程度的新方法，并基于此设计了一种自适应损失函数，在CREMA-D和AVE数据集上达到了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前主流的多模态不平衡处理方法主要关注架构修改和基于优化的方法，而忽视了对模态间不平衡程度的量化分析。

Method: 提出“模态差距”概念，即不同模态对真实类别预测的Softmax分数之差。通过双峰高斯混合模型（GMM）对模态差距分布进行建模，并利用贝叶斯定理计算样本属于这两种分布的后验概率。基于此分析，设计了一种自适应损失函数，旨在最小化模态差距、促进不平衡样本向平衡样本迁移，并对不平衡样本施加更大的惩罚权重。采用两阶段训练策略：预热阶段和自适应训练阶段。

Result: 在CREMA-D和AVE数据集上取得了80.65%和70.90%的准确率，达到SOTA性能。

Conclusion: 提出的量化模态不平衡的方法和自适应损失函数能够有效提升多模态不平衡处理的效果。

Abstract: Current mainstream approaches to addressing multimodal imbalance primarily
focus on architectural modifications and optimization-based, often overlooking
a quantitative analysis of the imbalance degree between modalities. To address
this gap, our work introduces a novel method for the quantitative analysis of
multi-modal imbalance, which in turn informs the design of a sample-level
adaptive loss function.We begin by defining the "Modality Gap" as the
difference between the Softmax scores of different modalities (e.g., audio and
visual) for the ground-truth class prediction. Analysis of the Modality Gap
distribution reveals that it can be effectively modeled by a bimodal Gaussian
Mixture Model (GMM). These two components are found to correspond respectively
to "modality-balanced" and "modality-imbalanced" data samples. Subsequently, we
apply Bayes' theorem to compute the posterior probability of each sample
belonging to these two distinct distributions.Informed by this quantitative
analysis, we design a novel adaptive loss function with three objectives: (1)
to minimize the overall Modality Gap; (2) to encourage the imbalanced sample
distribution to shift towards the balanced one; and (3) to apply greater
penalty weights to imbalanced samples. We employ a two-stage training strategy
consisting of a warm-up phase followed by an adaptive training
phase.Experimental results demonstrate that our approach achieves
state-of-the-art (SOTA) performance on the public CREMA-D and AVE datasets,
attaining accuracies of $80.65\%$ and $70.90\%$, respectively. This validates
the effectiveness of our proposed methodology.

</details>


### [570] [Do You Trust the Process?: Modeling Institutional Trust for Community Adoption of Reinforcement Learning Policies](https://arxiv.org/abs/2510.22017)
*Naina Balepur,Xingrui Pei,Hari Sundaram*

Main category: cs.LG

TL;DR: 在政府制定决策的过程中，许多政府机构正在采用人工智能政策。特别是，强化学习已被用于设计公民在实施时应遵循的政策。然而，我们知道，在缺乏制度信任的情况下，公民不会遵循政府制定的政策。本研究提出了一种用于社区资源分配的信任感知强化学习算法。我们考虑人道工程的案例，其中组织旨在将某些技术或资源分配给社区成员。我们使用深度确定性策略梯度方法来学习适合该组织需求的资源分配。然后，我们模拟基于学习到的策略的资源分配，并模拟社区成员制度信任的变化。我们研究了制度信任的纳入对结果有何影响，并询问如果信任值是私有的，组织在多大程度上能够有效地学习策略。研究发现，将信任纳入强化学习算法可以导致更成功的策略，特别是在组织目标不太确定的情况下。我们发现，更保守的信任估计会导致公平性和平均社区信任度的提高，尽管组织会因此遭受损失。最后，我们探索了一种防止对社区造成不公平结果的策略。我们通过外部实体实施配额系统，当该实体服务的社区成员不足时，该系统的赔偿金会降低组织的效用。我们发现，在某些情况下，这种干预可以提高社区的公平性和信任度，同时也会降低组织的成功率。这项工作强调了制度信任在算法设计和实施中的重要性，并确定了组织成功与社区福祉之间的张力。


<details>
  <summary>Details</summary>
Motivation: 在政府制定决策的过程中，许多政府机构正在采用人工智能政策。特别是，强化学习已被用于设计公民在实施时应遵循的政策。然而，我们知道，在缺乏制度信任的情况下，公民不会遵循政府制定的政策。本研究提出了一种用于社区资源分配的信任感知强化学习算法。

Method: 我们使用深度确定性策略梯度方法来学习适合该组织需求的资源分配。然后，我们模拟基于学习到的策略的资源分配，并模拟社区成员制度信任的变化。我们研究了制度信任的纳入对结果有何影响，并询问如果信任值是私有的，组织在多大程度上能够有效地学习策略。我们通过外部实体实施配额系统，当该实体服务的社区成员不足时，该系统的赔偿金会降低组织的效用。

Result: 研究发现，将信任纳入强化学习算法可以导致更成功的策略，特别是在组织目标不太确定的情况下。我们发现，更保守的信任估计会导致公平性和平均社区信任度的提高，尽管组织会因此遭受损失。我们发现，这种干预可以提高社区的公平性和信任度，同时也会降低组织的成功率。

Conclusion: 这项工作强调了制度信任在算法设计和实施中的重要性，并确定了组织成功与社区福祉之间的张力。

Abstract: Many governmental bodies are adopting AI policies for decision-making. In
particular, Reinforcement Learning has been used to design policies that
citizens would be expected to follow if implemented. Much RL work assumes that
citizens follow these policies, and evaluate them with this in mind. However,
we know from prior work that without institutional trust, citizens will not
follow policies put in place by governments. In this work, we develop a
trust-aware RL algorithm for resource allocation in communities. We consider
the case of humanitarian engineering, where the organization is aiming to
distribute some technology or resource to community members. We use a Deep
Deterministic Policy Gradient approach to learn a resource allocation that fits
the needs of the organization. Then, we simulate resource allocation according
to the learned policy, and model the changes in institutional trust of
community members. We investigate how this incorporation of institutional trust
affects outcomes, and ask how effectively an organization can learn policies if
trust values are private. We find that incorporating trust into RL algorithms
can lead to more successful policies, specifically when the organization's
goals are less certain. We find more conservative trust estimates lead to
increased fairness and average community trust, though organization success
suffers. Finally, we explore a strategy to prevent unfair outcomes to
communities. We implement a quota system by an external entity which decreases
the organization's utility when it does not serve enough community members. We
find this intervention can improve fairness and trust among communities in some
cases, while decreasing the success of the organization. This work underscores
the importance of institutional trust in algorithm design and implementation,
and identifies a tension between organization success and community well-being.

</details>


### [571] [Sentinel: Dynamic Knowledge Distillation for Personalized Federated Intrusion Detection in Heterogeneous IoT Networks](https://arxiv.org/abs/2510.23019)
*Gurpreet Singh,Keshav Sood,P. Rajalakshmi,Yong Xiang*

Main category: cs.LG

TL;DR: Sentinel是一个创新的联邦学习框架，用于解决物联网网络入侵检测中的数据不平衡、非独立同分布（non-IID）和高通信开销等挑战，通过引入个性化教师-学生双模型架构和一系列优化机制，显著提升了检测性能和通信效率。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦学习方法在物联网入侵检测系统中面临严峻挑战，如数据不平衡、非独立同分布（non-IID）数据以及高通信开销，导致性能下降。因此，需要一种新的框架来克服这些限制。

Method: 提出Sentinel框架，采用客户端双模型（个性化教师模型和轻量级共享学生模型）架构，并通过双向知识蒸馏（带自适应温度缩放）、多方面特征对齐和类别平衡损失函数进行优化。服务器端采用归一化梯度聚合和均等客户端加权。

Result: 在IoTID20和5GNIDD数据集上的广泛实验表明，Sentinel显著优于最先进的联邦方法，尤其在极端数据异质性条件下，建立了新的性能基准，同时保持了通信效率。

Conclusion: Sentinel框架成功克服了联邦学习在物联网入侵检测中的关键挑战，通过其创新的双模型设计和优化机制，实现了高性能、个性化适应和高通信效率的平衡，为该领域带来了新的突破。

Abstract: Federated learning (FL) offers a privacy-preserving paradigm for machine
learning, but its application in intrusion detection systems (IDS) within IoT
networks is challenged by severe class imbalance, non-IID data, and high
communication overhead.These challenges severely degrade the performance of
conventional FL methods in real-world network traffic classification. To
overcome these limitations, we propose Sentinel, a personalized federated IDS
(pFed-IDS) framework that incorporates a dual-model architecture on each
client, consisting of a personalized teacher and a lightweight shared student
model. This design effectively balances deep local adaptation with efficient
global model consensus while preserving client privacy by transmitting only the
compact student model, thus reducing communication costs. Sentinel integrates
three key mechanisms to ensure robust performance: bidirectional knowledge
distillation with adaptive temperature scaling, multi-faceted feature
alignment, and class-balanced loss functions. Furthermore, the server employs
normalized gradient aggregation with equal client weighting to enhance fairness
and mitigate client drift. Extensive experiments on the IoTID20 and 5GNIDD
benchmark datasets demonstrate that Sentinel significantly outperforms
state-of-the-art federated methods, establishing a new performance benchmark,
especially under extreme data heterogeneity, while maintaining communication
efficiency.

</details>


### [572] [MARS-M: When Variance Reduction Meets Matrices](https://arxiv.org/abs/2510.21800)
*Yifeng Liu,Angela Yuan,Quanquan Gu*

Main category: cs.LG

TL;DR: MARS-M 结合了 MARS 的方差缩减技术和 Muon 的矩阵优化方法，在 LLM 预训练等任务上实现了比单独使用 MARS 或 Muon 更快的收敛速度和更好的性能。


<details>
  <summary>Details</summary>
Motivation: 为了结合 MARS 的方差缩减技术和 Muon 的矩阵优化方法的优点，以期在 LLM 预训练等任务上取得更好的效果。

Method: 提出了一种名为 MARS-M 的新优化器，该优化器集成了 MARS 的方差缩减技术和 Muon 的矩阵优化方法。

Result: 在理论上，MARS-M 证明了其收敛到一阶平稳点的收敛率为 $\tilde{\mathcal{O}}(T^{-1/3})$，优于 Muon 的 $\tilde{\mathcal{O}}(T^{-1/4})$。在实践中，MARS-M 在语言建模和计算机视觉任务上的实验结果显示，其损失值更低，并且在各种下游基准测试中表现更佳。

Conclusion: MARS-M 是一种有效的优化器，结合了方差缩减和矩阵优化方法的优点，能够提高 LLM 预训练等任务的性能。

Abstract: Matrix-based preconditioned optimizers, such as Muon, have recently been
shown to be more efficient than scalar-based optimizers for training
large-scale neural networks, including large language models (LLMs). On the
other hand, recent benchmarks on optimizers for LLM pre-training have
demonstrated that variance-reduction techniques such as MARS can achieve
substantial speedups over standard optimizers that do not employ variance
reduction. In this paper, to achieve the best of both worlds, we introduce
MARS-M, a new optimizer that integrates the variance reduction technique in
MARS with Muon. Under standard regularity conditions, we prove that Muon-M
converges to a first-order stationary point at a rate of
$\tilde{\mathcal{O}}(T^{-1/3})$, which improves upon
$\tilde{\mathcal{O}}(T^{-1/4})$ rate attained by Muon. Our empirical results on
language modeling and computer vision tasks demonstrate that MARS-M
consistently yields lower losses and improved performance across various
downstream benchmarks. The implementation of MARS-M is available at
https://github.com/AGI-Arena/MARS/MARS_M.

</details>


### [573] [Accelerating Materials Design via LLM-Guided Evolutionary Search](https://arxiv.org/abs/2510.22503)
*Nikhil Abhyankar,Sanchit Kabra,Saaketh Desai,Chandan K. Reddy*

Main category: cs.LG

TL;DR: LLEMA是一个结合了大型语言模型（LLM）、化学知识进化规则和记忆精炼的材料发现框架。它在14个跨越电子、能源、涂料、光学和航空航天领域的实际任务中，能够发现化学合理、热力学稳定且性能符合要求的材料，其成功率和帕累托前沿优于仅使用生成模型或LLM的方法。


<details>
  <summary>Details</summary>
Motivation: 材料发现需要在巨大的化学和结构空间中进行导航，同时满足多个常常相互冲突的目标。

Method: LLEMA框架将大型语言模型（LLM）的科学知识与化学知识驱动的进化规则以及基于记忆的精炼相结合。在每个迭代中，LLM在明确的属性约束下提出晶体学上明确的候选材料；一个代理增强的预言家估计物理化学性质；一个多目标评分器更新成功/失败记忆以指导后续的生成。

Result: 在14个跨越电子、能源、涂料、光学和航空航天领域的现实任务中，LLEMA发现的候选材料在化学上是合理的，热力学上是稳定的，并且在性能上是一致的，其命中率和帕累托前沿优于生成模型和仅LLM的基线。

Conclusion: 通过强制执行可合成性以及多目标权衡，LLEMA为加速实际材料发现提供了一条有原则的途径。消融研究证实了规则指导生成、基于记忆的精炼和代理预测的重要性。

Abstract: Materials discovery requires navigating vast chemical and structural spaces
while satisfying multiple, often conflicting, objectives. We present LLM-guided
Evolution for MAterials design (LLEMA), a unified framework that couples the
scientific knowledge embedded in large language models with chemistry-informed
evolutionary rules and memory-based refinement. At each iteration, an LLM
proposes crystallographically specified candidates under explicit property
constraints; a surrogate-augmented oracle estimates physicochemical properties;
and a multi-objective scorer updates success/failure memories to guide
subsequent generations. Evaluated on 14 realistic tasks spanning electronics,
energy, coatings, optics, and aerospace, LLEMA discovers candidates that are
chemically plausible, thermodynamically stable, and property-aligned, achieving
higher hit-rates and stronger Pareto fronts than generative and LLM-only
baselines. Ablation studies confirm the importance of rule-guided generation,
memory-based refinement, and surrogate prediction. By enforcing
synthesizability and multi-objective trade-offs, LLEMA delivers a principled
pathway to accelerate practical materials discovery.
  Code: https://github.com/scientific-discovery/LLEMA

</details>


### [574] [AirFed: Federated Graph-Enhanced Multi-Agent Reinforcement Learning for Multi-UAV Cooperative Mobile Edge Computing](https://arxiv.org/abs/2510.23053)
*Zhiyu Wang,Suman Raj,Rajkumar Buyya*

Main category: cs.LG

TL;DR: AirFed是一个创新的联邦图增强多智能体强化学习框架，通过创新的图神经网络、双Actor单Critic架构和基于声誉的去中心化联邦学习机制，有效解决了多无人机协同移动边缘计算系统在动态环境中面临的轨迹规划、任务卸载和资源分配等挑战，显著降低了成本和通信开销，提高了服务质量和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有的无人机协同移动边缘计算（MEC）系统在动态和不确定的环境中，在协调轨迹规划、任务卸载和资源分配以保证服务质量（QoS）方面面临严峻挑战，尤其是在处理具有严格截止日期限制的大规模物联网设备部署时，其可扩展性、收敛速度和无人机之间的知识共享效率有限。

Method: 提出了一种名为AirFed的新型联邦图增强多智能体强化学习框架。该框架包含三个关键创新：1. 设计了双层动态图注意力网络（GATs）来建模无人机和物联网设备之间的时空依赖性及拓扑交互。2. 开发了双Actor单Critic架构，以联合优化连续轨迹控制和离散任务卸载决策。3. 提出了一种基于声誉的去中心化联邦学习机制，结合梯度敏感自适应量化，以实现异构无人机之间高效且鲁棒的知识共享。

Result: 实验结果显示，与现有最优基线相比，AirFed将加权成本降低了42.9%，截止日期满足率超过99%，物联网设备覆盖率达到94.2%，通信开销减少了54.5%。可扩展性分析证实了该框架在不同无人机数量、物联网设备密度和系统规模下的稳健性能。

Conclusion: AirFed框架在解决大规模无人机-MEC部署中的挑战方面表现出实际应用价值，其优越的性能体现在成本、服务质量、通信效率和可扩展性等方面。

Abstract: Multiple Unmanned Aerial Vehicles (UAVs) cooperative Mobile Edge Computing
(MEC) systems face critical challenges in coordinating trajectory planning,
task offloading, and resource allocation while ensuring Quality of Service
(QoS) under dynamic and uncertain environments. Existing approaches suffer from
limited scalability, slow convergence, and inefficient knowledge sharing among
UAVs, particularly when handling large-scale IoT device deployments with
stringent deadline constraints. This paper proposes AirFed, a novel federated
graph-enhanced multi-agent reinforcement learning framework that addresses
these challenges through three key innovations. First, we design dual-layer
dynamic Graph Attention Networks (GATs) that explicitly model spatial-temporal
dependencies among UAVs and IoT devices, capturing both service relationships
and collaborative interactions within the network topology. Second, we develop
a dual-Actor single-Critic architecture that jointly optimizes continuous
trajectory control and discrete task offloading decisions. Third, we propose a
reputation-based decentralized federated learning mechanism with
gradient-sensitive adaptive quantization, enabling efficient and robust
knowledge sharing across heterogeneous UAVs. Extensive experiments demonstrate
that AirFed achieves 42.9% reduction in weighted cost compared to
state-of-the-art baselines, attains over 99% deadline satisfaction and 94.2%
IoT device coverage rate, and reduces communication overhead by 54.5%.
Scalability analysis confirms robust performance across varying UAV numbers,
IoT device densities, and system scales, validating AirFed's practical
applicability for large-scale UAV-MEC deployments.

</details>


### [575] [Residual-guided AI-CFD hybrid method enables stable and scalable simulations: from 2D benchmarks to 3D applications](https://arxiv.org/abs/2510.21804)
*Shilaj Baral,Youngkyu Lee,Sangam Khanal,Joongoo Jeon*

Main category: cs.LG

TL;DR: XRePIT是一种结合机器学习和求解器校正的混合仿真策略，实现了流体动力学稳定且加速的模拟，可扩展至3D流动，并能在实际工程中应用。


<details>
  <summary>Details</summary>
Motivation: 纯粹由数据驱动的计算流体动力学（CFD）代理模型容易因误差累积而失效，而现有的混合方法缺乏自动化和鲁棒性，难以实际应用。

Method: 开发了一种名为XRePIT的新型混合仿真策略，该策略结合了机器学习（ML）加速和基于求解器的校正，并实现了完全自动化和物理感知，以确保稳定性和实用性。

Result: XRePIT能够稳定地进行超过10,000个时间步长的加速模拟，泛化能力强，可处理未知的边界条件，并能扩展到3D流动模拟。该方法实现了高达4.98倍的加速，同时保持了高物理保真度，热场相对误差约为1E-3，低速速度场误差低于1E-2 ms-1。

Conclusion: XRePIT建立了一种成熟且可扩展的混合方法，解决了长期存在的挑战，为在实际工程中应用铺平了道路。

Abstract: Purely data-driven surrogates for fluid dynamics often fail catastrophically
from error accumulation, while existing hybrid methods have lacked the
automation and robustness for practical use. To solve this, we developed
XRePIT, a novel hybrid simulation strategy that synergizes machine learning
(ML) acceleration with solver-based correction. We specifically designed our
method to be fully automated and physics-aware, ensuring the stability and
practical applicability that previous approaches lacked. We demonstrate that
this new design overcomes long-standing barriers, achieving the first stable,
accelerated rollouts for over 10,000 timesteps. The method also generalizes
robustly to unseen boundary conditions and, crucially, scales to 3D flows. Our
approach delivers speedups up to 4.98$\times$ while maintaining high physical
fidelity, resolving thermal fields with relative errors of ~1E-3 and capturing
low magnitude velocity dynamics with errors below 1E-2 ms-1. This work thus
establishes a mature and scalable hybrid method, paving the way for its use in
real-world engineering.

</details>


### [576] [Solving Continuous Mean Field Games: Deep Reinforcement Learning for Non-Stationary Dynamics](https://arxiv.org/abs/2510.22158)
*Lorenzo Magnino,Kai Shao,Zida Wu,Jiacheng Shen,Mathieu Laurière*

Main category: cs.LG

TL;DR: 提出了一种新颖的深度强化学习（DRL）算法，用于解决非平稳连续平均场博弈（MFG）问题，克服了现有方法在有限空间或固定模型上的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的MFG强化学习方法在处理现实世界问题时，通常局限于有限空间或固定模型，限制了其应用范围。

Method: 该算法基于虚构博弈（FP）方法，利用DRL计算最佳响应，并结合监督学习表示平均策略。同时，使用条件归一化流学习时变种群分布的表示。

Result: 在三个不同复杂度的示例上验证了该方法的有效性。

Conclusion: 通过解决可扩展性和密度近似的关键限制，该研究显著推进了DRL在复杂MFG问题中的应用，使该领域更接近实际的多智能体系统。

Abstract: Mean field games (MFGs) have emerged as a powerful framework for modeling
interactions in large-scale multi-agent systems. Despite recent advancements in
reinforcement learning (RL) for MFGs, existing methods are typically limited to
finite spaces or stationary models, hindering their applicability to real-world
problems. This paper introduces a novel deep reinforcement learning (DRL)
algorithm specifically designed for non-stationary continuous MFGs. The
proposed approach builds upon a Fictitious Play (FP) methodology, leveraging
DRL for best-response computation and supervised learning for average policy
representation. Furthermore, it learns a representation of the time-dependent
population distribution using a Conditional Normalizing Flow. To validate the
effectiveness of our method, we evaluate it on three different examples of
increasing complexity. By addressing critical limitations in scalability and
density approximation, this work represents a significant advancement in
applying DRL techniques to complex MFG problems, bringing the field closer to
real-world multi-agent systems.

</details>


### [577] [Geographic Transferability of Machine Learning Models for Short-Term Airport Fog Forecasting](https://arxiv.org/abs/2510.21819)
*Marcelo Cerda Castillo*

Main category: cs.LG

TL;DR: 该研究提出了一种基于物理过程的坐标无关特征集，用于机场雾的短期预测，解决了地理泛化难题。


<details>
  <summary>Details</summary>
Motivation: 传统的机器学习模型在进行机场雾预测时，由于依赖于特定地点的特征，难以实现跨地点的泛化。本研究旨在探索是否可以通过编码基本的物理热力学和辐射过程到一个坐标无关（地点独立）的特征集中，来实现预测模型的地理迁移性。

Method: 研究者使用了一种梯度提升分类器（XGBoost），并使用智利圣地亚哥（SCEL）2002-2009年的数据进行训练。模型在2010-2012年的数据上进行评估，并进行了严格的零样本测试，将其应用于蒙特港（SCTE）、旧金山（KSFO）和伦敦（EGLL）三个地点。

Result: 在最远11,650公里的距离和不同的雾类型（辐射雾、平流雾、海洋雾）下，模型取得了0.923-0.947的AUC值。SHAP特征排名显示，能见度持续性、太阳角度和热梯度在预测中起主导作用，表明模型学习到了可迁移的物理关系，而非特定地点的模式。

Conclusion: 研究结果表明，通过物理信息驱动的、坐标无关的特征工程，可以开发出具有地理迁移能力的、用于大气预测的工具。

Abstract: Short-term forecasting of airport fog (visibility < 1.0 km) presents
challenges in geographic generalization because many machine learning models
rely on location-specific features and fail to transfer across sites. This
study investigates whether fundamental thermodynamic and radiative processes
can be encoded in a coordinate-free (location-independent) feature set to
enable geographic transferability. A gradient boosting classifier (XGBoost)
trained on Santiago, Chile (SCEL, 33S) data from 2002-2009 was evaluated on a
2010-2012 holdout set and under strict zero-shot tests at Puerto Montt (SCTE),
San Francisco (KSFO), and London (EGLL). The model achieved AUC values of
0.923-0.947 across distances up to 11,650 km and different fog regimes
(radiative, advective, marine). Consistent SHAP feature rankings show that
visibility persistence, solar angle, and thermal gradients dominate
predictions, suggesting the model learned transferable physical relationships
rather than site-specific patterns. Results suggest that physics-informed,
coordinate-free feature engineering can yield geographically transferable
atmospheric forecasting tools.

</details>


### [578] [Equivariant Neural Networks for General Linear Symmetries on Lie Algebras](https://arxiv.org/abs/2510.22984)
*Chankyo Kim,Sicheng Zhao,Minghan Zhu,Tzu-Yuan Lin,Maani Ghaffari*

Main category: cs.LG

TL;DR: ReLNs是一种新的神经网络架构，能够处理通用的线性对称性（GL(n)），并在各种科学任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的神经等变模型通常仅限于简单的对称性（如旋转），无法处理更广泛的线性变换（GL(n)），而这种变换在许多科学领域中都很常见。

Method: ReLNs通过引入一种新颖的伴随不变双线性层来实现对通用线性对称性的精确等变性，该层可以稳定地处理李代数特征和矩阵值输入，无需为每个子群重新设计。

Result: ReLNs在代数基准测试（具有sl(3)和sp(4)对称性）和洛伦兹等变粒子物理任务中均优于现有方法，并在3D无人机状态估计任务中取得了显著的轨迹精度改进。

Conclusion: ReLNs提供了一个实用且通用的框架，用于在李代数和矩阵值数据上学习具有广泛线性群对称性的模型。

Abstract: Encoding symmetries is a powerful inductive bias for improving the
generalization of deep neural networks. However, most existing equivariant
models are limited to simple symmetries like rotations, failing to address the
broader class of general linear transformations, GL(n), that appear in many
scientific domains. We introduce Reductive Lie Neurons (ReLNs), a novel neural
network architecture exactly equivariant to these general linear symmetries.
ReLNs are designed to operate directly on a wide range of structured inputs,
including general n-by-n matrices. ReLNs introduce a novel adjoint-invariant
bilinear layer to achieve stable equivariance for both Lie-algebraic features
and matrix-valued inputs, without requiring redesign for each subgroup. This
architecture overcomes the limitations of prior equivariant networks that only
apply to compact groups or simple vector data. We validate ReLNs' versatility
across a spectrum of tasks: they outperform existing methods on algebraic
benchmarks with sl(3) and sp(4) symmetries and achieve competitive results on a
Lorentz-equivariant particle physics task. In 3D drone state estimation with
geometric uncertainty, ReLNs jointly process velocities and covariances,
yielding significant improvements in trajectory accuracy. ReLNs provide a
practical and general framework for learning with broad linear group symmetries
on Lie algebras and matrix-valued data. Project page:
https://reductive-lie-neuron.github.io/

</details>


### [579] [Generalized Top-k Mallows Model for Ranked Choices](https://arxiv.org/abs/2510.22040)
*Shahrzad Haddadan,Sara Ahmadian*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The classic Mallows model is a foundational tool for modeling user
preferences. However, it has limitations in capturing real-world scenarios,
where users often focus only on a limited set of preferred items and are
indifferent to the rest. To address this, extensions such as the top-k Mallows
model have been proposed, aligning better with practical applications. In this
paper, we address several challenges related to the generalized top-k Mallows
model, with a focus on analyzing buyer choices. Our key contributions are: (1)
a novel sampling scheme tailored to generalized top-k Mallows models, (2) an
efficient algorithm for computing choice probabilities under this model, and
(3) an active learning algorithm for estimating the model parameters from
observed choice data. These contributions provide new tools for analysis and
prediction in critical decision-making scenarios. We present a rigorous
mathematical analysis for the performance of our algorithms. Furthermore,
through extensive experiments on synthetic data and real-world data, we
demonstrate the scalability and accuracy of our proposed methods, and we
compare the predictive power of Mallows model for top-k lists compared to the
simpler Multinomial Logit model.

</details>


### [580] [Unlocking Biomedical Insights: Hierarchical Attention Networks for High-Dimensional Data Interpretation](https://arxiv.org/abs/2510.21820)
*Rekha R Nair,Tina Babu,Alavikunhu Panthakkan,Hussain Al-Ahmad,Balamurugan Balusamy*

Main category: cs.LG

TL;DR: HAIN是一个新的深度学习模型，它结合了多级注意力机制、降维和解释性损失函数，能够对复杂的生物医学数据进行可解释和鲁棒的分析。它通过梯度加权注意力和基于原型的表示提供特征级和全局模型的可解释性。在TCGA数据集上的评估显示，HAIN的分类准确率为94.3%，优于SHAP和LIME等传统方法，并能识别出与癌症相关的生物标志物。


<details>
  <summary>Details</summary>
Motivation: 随着基因组学、医疗保健和金融等领域的高维数据集激增，迫切需要开发既准确又具有可解释性的机器学习模型。传统深度学习模型虽然预测性能强，但缺乏透明度，难以在关键决策应用中部署。

Method: HAIN是一种新颖的架构，它整合了多级注意力机制、降维和解释性驱动的损失函数。模型通过梯度加权注意力机制提供特征级可解释性，并通过基于原型的表示提供全局模型解释。

Result: HAIN在TCGA数据集上实现了94.3%的分类准确率，在透明度和解释能力方面均优于SHAP和LIME等传统的事后可解释性方法。此外，HAIN能有效识别出具有生物学意义的癌症生物标志物。

Conclusion: HAIN通过结合预测准确性和可解释性，在实现精准医疗和满足监管要求方面，推动了透明人工智能解决方案的发展。

Abstract: The proliferation of high-dimensional datasets in fields such as genomics,
healthcare, and finance has created an urgent need for machine learning models
that are both highly accurate and inherently interpretable. While traditional
deep learning approaches deliver strong predictive performance, their lack of
transparency often impedes their deployment in critical, decision-sensitive
applications. In this work, we introduce the Hierarchical Attention-based
Interpretable Network (HAIN), a novel architecture that unifies multi-level
attention mechanisms, dimensionality reduction, and explanation-driven loss
functions to deliver interpretable and robust analysis of complex biomedical
data. HAIN provides feature-level interpretability via gradientweighted
attention and offers global model explanations through prototype-based
representations. Comprehensive evaluation on The Cancer Genome Atlas (TCGA)
dataset demonstrates that HAIN achieves a classification accuracy of 94.3%,
surpassing conventional post-hoc interpretability approaches such as SHAP and
LIME in both transparency and explanatory power. Furthermore, HAIN effectively
identifies biologically relevant cancer biomarkers, supporting its utility for
clinical and research applications. By harmonizing predictive accuracy with
interpretability, HAIN advances the development of transparent AI solutions for
precision medicine and regulatory compliance.

</details>


### [581] [Towards Scaling Deep Neural Networks with Predictive Coding: Theory and Practice](https://arxiv.org/abs/2510.23323)
*Francesco Innocenti*

Main category: cs.LG

TL;DR: 本文提出了一种名为“μPC”的新参数化方法，可以稳定训练100多层的深度神经网络，并在简单任务上取得了有竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 反向传播（BP）是训练深度神经网络的标准算法，但它能耗高且不符合大脑工作机制。本文研究了一种替代的、受大脑启发的、可能更高效的算法——预测编码（PC）。

Method: 本文从优化理论的角度，通过分析PC的学习动态，提出了一种近似信任域方法，并引入了一种新的参数化方法“μPC”，实现了深度PC网络（PCN）的稳定训练。

Result: 本文证明了PC的学习动态可以被理解为一种近似信任域方法。此外，还提出了一种新的参数化方法“μPC”，首次实现了100多层网络的稳定训练，并在简单任务上取得了具有竞争力的性能。

Conclusion: 本文在理论上加深了对PCN推断和学习动态的理解，并提出了一种新的参数化方法“μPC”，显著提高了PCN的可扩展性。然而，未来的研究仍需关注硬件协同设计，以使PC能够在大规模应用中与BP竞争。

Abstract: Backpropagation (BP) is the standard algorithm for training the deep neural
networks that power modern artificial intelligence including large language
models. However, BP is energy inefficient and unlikely to be implemented by the
brain. This thesis studies an alternative, potentially more efficient
brain-inspired algorithm called predictive coding (PC). Unlike BP, PC networks
(PCNs) perform inference by iterative equilibration of neuron activities before
learning or weight updates. Recent work has suggested that this iterative
inference procedure provides a range of benefits over BP, such as faster
training. However, these advantages have not been consistently observed, the
inference and learning dynamics of PCNs are still poorly understood, and deep
PCNs remain practically untrainable. Here, we make significant progress towards
scaling PCNs by taking a theoretical approach grounded in optimisation theory.
First, we show that the learning dynamics of PC can be understood as an
approximate trust-region method using second-order information, despite
explicitly using only first-order local updates. Second, going beyond this
approximation, we show that PC can in principle make use of arbitrarily
higher-order information, such that for feedforward networks the effective
landscape on which PC learns is far more benign and robust to vanishing
gradients than the (mean squared error) loss landscape. Third, motivated by a
study of the inference dynamics of PCNs, we propose a new parameterisation
called ``$\mu$PC'', which for the first time allows stable training of 100+
layer networks with little tuning and competitive performance on simple tasks.
Overall, this thesis significantly advances our fundamental understanding of
the inference and learning dynamics of PCNs, while highlighting the need for
future research to focus on hardware co-design if PC is to compete with BP at
scale.

</details>


### [582] [Sublinear Sketches for Approximate Nearest Neighbor and Kernel Density Estimation](https://arxiv.org/abs/2510.23039)
*Ved Danait,Srijan Das,Sujoy Bhore*

Main category: cs.LG

TL;DR: 本文提出了用于动态数据流的近似最近邻（ANN）搜索和近似核密度估计（A-KDE）的新颖子线性（sublinear）Sketch 算法，实现了内存和查询时间的权衡。


<details>
  <summary>Details</summary>
Motivation: 在海量动态数据流中，设计能够保留数据结构特性并支持高效查询的紧凑型Sketch是核心挑战，尤其是在ANN和A-KDE问题上。

Method: 对于动态流模型下的ANN，提出了一种子线性Sketch，内存占用为 $\mathcal{O}(n^{1+\rho-\eta})$，仅存储输入数据的 $n^{-\eta}$ 分数，支持子线性查询时间和批量查询。对于滑动窗口模型下的A-KDE，提出了一个大小为 $\mathcal{O}\left(RW \cdot \frac{1}{\sqrt{1+\epsilon} - 1} \log^2 N\right)$ 的Sketch。

Result: ANN方面，实现了内存大小和近似误差之间的近乎最优的权衡，并且首次在ANN上取得了这一成果。A-KDE方面，首次在滑动窗口模型下实现了理论上的子线性Sketch保证。

Conclusion: 所提出的Sketch在理论上具有子线性空间和查询时间保证，实验结果表明其轻量且在实际应用中具有低误差。

Abstract: Approximate Nearest Neighbor (ANN) search and Approximate Kernel Density
Estimation (A-KDE) are fundamental problems at the core of modern machine
learning, with broad applications in data analysis, information systems, and
large-scale decision making. In massive and dynamic data streams, a central
challenge is to design compact sketches that preserve essential structural
properties of the data while enabling efficient queries.
  In this work, we develop new sketching algorithms that achieve sublinear
space and query time guarantees for both ANN and A-KDE for a dynamic stream of
data. For ANN in the streaming model, under natural assumptions, we design a
sublinear sketch that requires only $\mathcal{O}(n^{1+\rho-\eta})$ memory by
storing only a sublinear ($n^{-\eta}$) fraction of the total inputs, where
$\rho$ is a parameter of the LSH family, and $0<\eta<1$. Our method supports
sublinear query time, batch queries, and extends to the more general Turnstile
model. While earlier works have focused on Exact NN, this is the first result
on ANN that achieves near-optimal trade-offs between memory size and
approximation error.
  Next, for A-KDE in the Sliding-Window model, we propose a sketch of size
$\mathcal{O}\left(RW \cdot \frac{1}{\sqrt{1+\epsilon} - 1} \log^2 N\right)$,
where $R$ is the number of sketch rows, $W$ is the LSH range, $N$ is the window
size, and $\epsilon$ is the approximation error. This, to the best of our
knowledge, is the first theoretical sublinear sketch guarantee for A-KDE in the
Sliding-Window model.
  We complement our theoretical results with experiments on various real-world
datasets, which show that the proposed sketches are lightweight and achieve
consistently low error in practice.

</details>


### [583] [Beyond Point Matching: Evaluating Multiscale Dubuc Distance for Time Series Similarity](https://arxiv.org/abs/2510.21824)
*Azim Ahmadzadeh,Mahsa Khazaei,Elaina Rohlfing*

Main category: cs.LG

TL;DR: MDD是一种新的时间序列相似性度量方法，在许多场景下比DTW表现更好，并且在实际应用中具有显著优势。


<details>
  <summary>Details</summary>
Motivation: 时间序列数据具有高维度和复杂性的特点，高效地搜索和索引这类数据一直是数据挖掘中的一个挑战。本文旨在研究一种新提出的相似性度量方法——多尺度Dubuc距离（MDD）的优势和局限性，并与广泛使用的动态时间规整（DTW）方法进行比较。

Method: 通过在UCR数据库的95个数据集上进行模拟实验和真实世界分类任务来评估MDD和DTW的性能。

Result: MDD在许多场景下显著优于DTW，尤其是在MDD表现优于DTW的情况下，其性能提升尤为明显。在真实世界的分类任务中，MDD相比DTW取得了显著的改进。

Conclusion: MDD在评估时间序列相似性方面，尤其是在考虑多时间尺度和避免点对点对齐的情况下，相比DTW具有显著优势，并具有重要的实际应用价值。

Abstract: Time series are high-dimensional and complex data objects, making their
efficient search and indexing a longstanding challenge in data mining. Building
on a recently introduced similarity measure, namely Multiscale Dubuc Distance
(MDD), this paper investigates its comparative strengths and limitations
relative to the widely used Dynamic Time Warping (DTW). MDD is novel in two key
ways: it evaluates time series similarity across multiple temporal scales and
avoids point-to-point alignment. We demonstrate that in many scenarios where
MDD outperforms DTW, the gains are substantial, and we provide a detailed
analysis of the specific performance gaps it addresses. We provide simulations,
in addition to the 95 datasets from the UCR archive, to test our hypotheses.
Finally, we apply both methods to a challenging real-world classification task
and show that MDD yields a significant improvement over DTW, underscoring its
practical utility.

</details>


### [584] [Symbolic Neural Generation with Applications to Lead Discovery in Drug Design](https://arxiv.org/abs/2510.23379)
*Ashwin Srinivasan,A Baskar,Tirtharaj Dash,Michael Bain,Sanjay Kumar Dey,Mainak Banerjee*

Main category: cs.LG

TL;DR: SNGs combine symbolic learning and neural generation to create data generators that meet formal correctness criteria. They use symbolic specifications from data to constrain neural generators, ensuring generated data adheres to rules. An SNG outputs a triple (H, X, W) representing symbolic descriptions, generated instances, and weights. The paper introduces a formal semantics and a probabilistic extension for SNGs. An implementation combining ILP and LLMs shows competitive performance on benchmark problems and promising results in early-stage drug design, with experts finding the symbolic specifications valuable.


<details>
  <summary>Details</summary>
Motivation: The paper aims to address the underexplored area of hybrid neurosymbolic models that integrate symbolic learning with neural reasoning to construct data generators meeting formal correctness criteria. The motivation stems from exploiting the complementary strengths of symbolic and neural methods to generate data that adheres to logical specifications.

Method: The paper introduces Symbolic Neural Generators (SNGs), which employ symbolic learners to derive logical specifications from a small set of instances. These specifications then constrain a neural-based generator, which rejects any instance violating the symbolic rules. The paper also outlines a formal semantics using partially-ordered sets and a probabilistic extension involving searching over a weighted partial ordering. An implementation combines Inductive Logic Programming (ILP) with a large language model (LLM).

Result: The implemented SNG, combining ILP and LLM, was evaluated on early-stage drug design. On benchmark problems, its performance was statistically comparable to state-of-the-art methods. For exploratory problems with poorly understood targets, the generated molecules showed binding affinities on par with leading clinical candidates. Experts found the symbolic specifications useful as preliminary filters, and several generated molecules were identified as viable for synthesis and wet-lab testing.

Conclusion: SNGs represent a promising approach for constructing formally correct data generators by effectively integrating symbolic and neural methods. The proposed framework and its implementation demonstrate strong performance in the domain of early-stage drug design, offering valuable symbolic insights and generating potentially viable molecular candidates for further investigation.

Abstract: We investigate a relatively underexplored class of hybrid neurosymbolic
models integrating symbolic learning with neural reasoning to construct data
generators meeting formal correctness criteria. In \textit{Symbolic Neural
Generators} (SNGs), symbolic learners examine logical specifications of
feasible data from a small set of instances -- sometimes just one. Each
specification in turn constrains the conditional information supplied to a
neural-based generator, which rejects any instance violating the symbolic
specification. Like other neurosymbolic approaches, SNG exploits the
complementary strengths of symbolic and neural methods. The outcome of an SNG
is a triple $(H, X, W)$, where $H$ is a symbolic description of feasible
instances constructed from data, $X$ a set of generated new instances that
satisfy the description, and $W$ an associated weight. We introduce a semantics
for such systems, based on the construction of appropriate \textit{base} and
\textit{fibre} partially-ordered sets combined into an overall partial order,
and outline a probabilistic extension relevant to practical applications. In
this extension, SNGs result from searching over a weighted partial ordering. We
implement an SNG combining a restricted form of Inductive Logic Programming
(ILP) with a large language model (LLM) and evaluate it on early-stage drug
design. Our main interest is the description and the set of potential inhibitor
molecules generated by the SNG. On benchmark problems -- where drug targets are
well understood -- SNG performance is statistically comparable to
state-of-the-art methods. On exploratory problems with poorly understood
targets, generated molecules exhibit binding affinities on par with leading
clinical candidates. Experts further find the symbolic specifications useful as
preliminary filters, with several generated molecules identified as viable for
synthesis and wet-lab testing.

</details>


### [585] [UCB-type Algorithm for Budget-Constrained Expert Learning](https://arxiv.org/abs/2510.22654)
*Ilgam Latypov,Alexandra Suvorikova,Alexey Kroshnin,Alexander Gasnikov,Yuriy Dorn*

Main category: cs.LG

TL;DR: 该论文提出了一种名为 M-LCB 的新算法，用于在预算有限的情况下，从 K 个自适应学习算法中动态选择 M 个进行在线训练和预测，并提供了后悔界限。


<details>
  <summary>Details</summary>
Motivation: 在许多现代应用中，系统需要在多个自适应学习算法之间动态选择，这些算法是在线的。例如，在流式环境中进行模型选择、在金融领域切换交易策略、以及编排多个上下文老虎机或强化学习智能体。在每一轮中，学习者必须选择 K 个自适应专家中的一个来做出预测，同时在固定的训练预算下最多更新 M 个专家。然而，在每个回合的预算限制下同时训练多个自适应专家时，现有的研究缺乏后悔界限。

Method: M-LCB 算法是一种计算高效的 UCB 类型元算法，它提供随时后悔保证。其置信区间直接从实现的损失中构建，无需额外的优化，并能无缝反映底层专家的收敛特性。

Result: 如果每个专家实现内部后悔 $	ilde O(T^\alpha)$，则 M-LCB 保证整体后悔有界，形式为 $\tilde O(\sqrt{\tfrac{KT}{M}} + (K/M)^{1-\alpha} T^\alpha)$。

Conclusion: M-LCB 算法是首个在预算限制下同时训练多个自适应专家的后悔界限结果。该算法适用于在线训练的参数化模型和多臂老虎机算法等场景，将经典老虎机范式扩展到在有限资源下协调具有状态的自学习专家的更现实场景。

Abstract: In many modern applications, a system must dynamically choose between several
adaptive learning algorithms that are trained online. Examples include model
selection in streaming environments, switching between trading strategies in
finance, and orchestrating multiple contextual bandit or reinforcement learning
agents. At each round, a learner must select one predictor among $K$ adaptive
experts to make a prediction, while being able to update at most $M \le K$ of
them under a fixed training budget.
  We address this problem in the \emph{stochastic setting} and introduce
\algname{M-LCB}, a computationally efficient UCB-style meta-algorithm that
provides \emph{anytime regret guarantees}. Its confidence intervals are built
directly from realized losses, require no additional optimization, and
seamlessly reflect the convergence properties of the underlying experts. If
each expert achieves internal regret $\tilde O(T^\alpha)$, then \algname{M-LCB}
ensures overall regret bounded by $\tilde O\!\Bigl(\sqrt{\tfrac{KT}{M}} \;+\;
(K/M)^{1-\alpha}\,T^\alpha\Bigr)$.
  To our knowledge, this is the first result establishing regret guarantees
when multiple adaptive experts are trained simultaneously under per-round
budget constraints. We illustrate the framework with two representative cases:
(i) parametric models trained online with stochastic losses, and (ii) experts
that are themselves multi-armed bandit algorithms. These examples highlight how
\algname{M-LCB} extends the classical bandit paradigm to the more realistic
scenario of coordinating stateful, self-learning experts under limited
resources.

</details>


### [586] [Coresets for Clustering Under Stochastic Noise](https://arxiv.org/abs/2510.23438)
*Lingxiao Huang,Zhize Li,Nisheeth K. Vishnoi,Runkai Yang,Haoyu Zhao*

Main category: cs.LG

TL;DR: 针对带噪声的(k,z)-聚类问题，提出了一种基于新颖代理误差指标的共核构造算法，相比传统方法，该算法能获得更小的共核尺寸和更优的聚类成本保证，并在真实数据集上得到验证。


<details>
  <summary>Details</summary>
Motivation: 在输入数据集被已知分布的随机噪声污染的情况下，研究(k,z)-聚类问题的共核（coreset）构造方法。传统方法在评估带噪声数据的共核质量时面临挑战，因为真实的基础数据集是无法观测的。

Method: 提出并分析了两种代理误差度量指标：一种是先前工作中使用的传统度量，另一种是新提出的、与真实聚类成本更接近的度量。基于新提出的度量，设计了一种共核构造算法。

Result: 所提出的新误差度量指标独立于噪声分布，但其近似保证可以随噪声水平扩展。该算法在温和的数据和噪声假设下，相比传统度量，能提供更小的共核尺寸和对真实聚类成本更紧密的保证，共核尺寸的改进最多可达poly(k)倍。实验结果在真实数据集上验证了理论发现和实际优势。

Conclusion: 新提出的代理误差度量指标和相应的共核构造算法，为处理带噪声的(k,z)-聚类问题提供了一种更有效的方法，能够减小共核尺寸并提高聚类结果的准确性。

Abstract: We study the problem of constructing coresets for $(k, z)$-clustering when
the input dataset is corrupted by stochastic noise drawn from a known
distribution. In this setting, evaluating the quality of a coreset is
inherently challenging, as the true underlying dataset is unobserved. To
address this, we investigate coreset construction using surrogate error metrics
that are tractable and provably related to the true clustering cost. We analyze
a traditional metric from prior work and introduce a new error metric that more
closely aligns with the true cost. Although our metric is defined independently
of the noise distribution, it enables approximation guarantees that scale with
the noise level. We design a coreset construction algorithm based on this
metric and show that, under mild assumptions on the data and noise, enforcing
an $\varepsilon$-bound under our metric yields smaller coresets and tighter
guarantees on the true clustering cost than those obtained via classical
metrics. In particular, we prove that the coreset size can improve by a factor
of up to $\mathrm{poly}(k)$, where $n$ is the dataset size. Experiments on
real-world datasets support our theoretical findings and demonstrate the
practical advantages of our approach.

</details>


### [587] [GAPO: Group Adaptive Policy Optimization for Real-World Code Edit](https://arxiv.org/abs/2510.21830)
*Jianqing Zhang,Zhezheng Hao,Wei Xia,Hande Dong,Hong Wang,Chenxing Wei,Yuyan Zhou,Yubin Qi,Qiang Lin,Jian Cao*

Main category: cs.LG

TL;DR: GAPO通过自适应地找到每个提示的无异常值最高密度区间（HDI），并使用该区间的其中值作为自适应Q来替代GRPO中的组均值，从而解决代码编辑场景中奖励分布不均和异常值导致的问题，并在准确率上超越GRPO及其变体DAPO。


<details>
  <summary>Details</summary>
Motivation: 代码编辑场景中，奖励分布往往是倾斜的，并且包含不可预测的异常值，这会导致优势计算失真并增加噪声。而现有的GRPO等group-relative方法在这种情况下表现不佳。

Method: GAPO通过自适应地找到每个提示的无异常值最高密度区间（HDI），并使用该区间的其中值作为自适应Q来替代GRPO中的组均值，以进行优势计算。

Result: 在包含51,844个真实世界、历史感知的代码编辑任务的大型内部数据集上，针对9个不同规模（3B-14B）的指令微调LLMs进行了验证，GAPO在准确率上始终优于GRPO及其变体DAPO。

Conclusion: GAPO是一种有效的、即插即用的、高效的算法，能够鲁棒地处理倾斜的奖励分布，并在代码编辑任务中显著提升LLMs的性能。

Abstract: Reinforcement learning (RL) is widely used for post-training large language
models (LLMs) in code editing, where group-relative methods like GRPO are
popular for their critic-free, normalized advantage estimation. However, in
real-world code-editing scenarios, reward distributions are often skewed with
unpredictable outliers, leading to distorted advantage computation and
increased noise. To address this issue, we propose Group Adaptive Policy
Optimization (GAPO), which adaptively finds an outlier-free highest-density
interval (HDI) per prompt and then uses the median of that interval as an
adaptive Q to replace the group mean in advantage calculation. This adaptive Q
robustly handles skewed distributions while remaining plug-and-play and
efficient. We validate GAPO on nine instruction-tuned LLMs (3B-14B) using a
large internal dataset of 51,844 real-world, history-aware code-editing tasks
across 10 languages, demonstrating consistent improvements in exact match
accuracy over GRPO and its variant DAPO. Code is publicly available.

</details>


### [588] [ATLAS: Actor-Critic Task-Completion with Look-ahead Action Simulation](https://arxiv.org/abs/2510.22732)
*Jiali Cheng,Anjishnu Kumar,Roshan Lal,Rishi Rajasekaran,Hani Ramezani,Omar Zia Khan,Oleg Rokhlenko,Sunny Chiu-Webster,Gang Hua,Hadi Amiri*

Main category: cs.LG

TL;DR: ATLAS是一个内存增强型Web代理，通过在认知空间中模拟动作后果来制定基于环境模型的计划，从而在无需神经网络微调的情况下有效适应新环境，并在WebArena-Lite Benchmark上取得了新的最高成功率。


<details>
  <summary>Details</summary>
Motivation: 现有Web代理在缺乏神经网络微调的情况下，无法有效适应新环境，导致执行计划效率低下。

Method: 提出一种名为ATLAS（Actor-Critic Task-completion with Look-ahead Action Simulation）的内存增强型代理。该代理首先通过轻量级的、好奇心驱动的探索来构建“认知地图”，然后规划师提出候选动作，模拟器在认知空间中预测这些动作的后果，评论家分析选项以选择最佳的“roll-out”并更新原始计划，最后由浏览器执行器执行选定的动作。

Result: 在WebArena-Lite Benchmark上，ATLAS实现了63%的成功率，而之前最先进的方法成功率为53.9%。该代理的模块化架构无需针对特定网站进行LLM微调。

Conclusion: ATLAS通过引入认知地图、分层规划器和基于前瞻的重新规划器，有效解决了现有Web代理在适应新环境方面的局限性，并在性能上取得了显著提升。消融实验证明了这些组件在系统设计中的互补作用。

Abstract: We observe that current state-of-the-art web-agents are unable to effectively
adapt to new environments without neural network fine-tuning, without which
they produce inefficient execution plans due to a lack of awareness of the
structure and dynamics of the new environment. To address this limitation, we
introduce ATLAS (Actor-Critic Task-completion with Look-ahead Action
Simulation), a memory-augmented agent that is able to make plans grounded in a
model of the environment by simulating the consequences of those actions in
cognitive space. Our agent starts by building a "cognitive map" by performing a
lightweight curiosity driven exploration of the environment. The planner
proposes candidate actions; the simulator predicts their consequences in
cognitive space; a critic analyzes the options to select the best roll-out and
update the original plan; and a browser executor performs the chosen action. On
the WebArena-Lite Benchmark, we achieve a 63% success rate compared to 53.9%
success rate for the previously published state-of-the-art. Unlike previous
systems, our modular architecture requires no website-specific LLM fine-tuning.
Ablations show sizable drops without the world-model, hierarchical planner, and
look-ahead-based replanner confirming their complementary roles within the
design of our system

</details>


### [589] [Restoring Pruned Large Language Models via Lost Component Compensation](https://arxiv.org/abs/2510.21834)
*Zijian Feng,Hanzhang Zhou,Zixiao Zhu,Tianjiao Li,Jia Jim Deryl Chua,Lee Onn Mak,Gee Wah Ng,Kezhi Mao*

Main category: cs.LG

TL;DR: 通过补偿丢失的组件来恢复剪枝大语言模型的性能，同时保持其稀疏性和推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有的剪枝模型恢复方法（如PEFT）通常针对密集模型设计，未能充分考虑剪枝模型的特性，导致恢复效果不佳。

Method: RestoreLCC是一种即插即用的方法，通过对比激活编辑探查关键的注意力头，提取激活差异中的丢失组件，并将其注入到相应的剪枝头中进行补偿和恢复。该方法兼容多种剪枝策略。

Result: RestoreLCC在通用和特定任务的性能恢复方面持续优于最先进的基线方法，同时不影响剪枝模型的稀疏性或推理效率。

Conclusion: RestoreLCC能够有效恢复剪枝大语言模型的性能，同时保持其低成本和高效率的优势，且具有良好的兼容性。

Abstract: Pruning is a widely used technique to reduce the size and inference cost of
large language models (LLMs), but it often causes performance degradation. To
mitigate this, existing restoration methods typically employ
parameter-efficient fine-tuning (PEFT), such as LoRA, to recover the pruned
model's performance. However, most PEFT methods are designed for dense models
and overlook the distinct properties of pruned models, often resulting in
suboptimal recovery. In this work, we propose a targeted restoration strategy
for pruned models that restores performance while preserving their low cost and
high efficiency. We observe that pruning-induced information loss is reflected
in attention activations, and selectively reintroducing components of this
information can significantly recover model performance. Based on this insight,
we introduce RestoreLCC (Restoring Pruned LLMs via Lost Component
Compensation), a plug-and-play method that contrastively probes critical
attention heads via activation editing, extracts lost components from
activation differences, and finally injects them back into the corresponding
pruned heads for compensation and recovery. RestoreLCC is compatible with
structured, semi-structured, and unstructured pruning schemes. Extensive
experiments demonstrate that RestoreLCC consistently outperforms
state-of-the-art baselines in both general and task-specific performance
recovery, without compromising the sparsity or inference efficiency of pruned
models.

</details>


### [590] [Sequential Multi-Agent Dynamic Algorithm Configuration](https://arxiv.org/abs/2510.23535)
*Chen Lu,Ke Xue,Lei Yuan,Yao Wang,Yaoyuan Wang,Sheng Fu,Chao Qian*

Main category: cs.LG

TL;DR: Seq-MADAC是一个框架，通过考虑参数间的依赖关系来解决动态算法配置（DAC）中的次优问题，并在实验中表现优于现有的多智能体强化学习（MARL）方法。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体强化学习（MARL）方法在配置具有内在参数依赖性的复杂算法时，可能导致次优结果，因为它们没有考虑这些依赖关系。

Method: 提出了一种名为Seq-MADAC（sequential multi-agent DAC）的框架，通过一种“顺序优势分解网络”来解决参数间的依赖问题，该网络能利用动作顺序信息进行顺序优势分解。

Result: 在从合成函数到多目标优化算法配置的实验中，Seq-MADAC表现出了优于最先进的MARL方法，并显示出跨问题类的强大泛化能力。

Conclusion: Seq-MADAC为广泛的依赖感知自动算法配置建立了一个新的范式。

Abstract: Dynamic algorithm configuration (DAC) is a recent trend in automated machine
learning, which can dynamically adjust the algorithm's configuration during the
execution process and relieve users from tedious trial-and-error tuning tasks.
Recently, multi-agent reinforcement learning (MARL) approaches have improved
the configuration of multiple heterogeneous hyperparameters, making various
parameter configurations for complex algorithms possible. However, many complex
algorithms have inherent inter-dependencies among multiple parameters (e.g.,
determining the operator type first and then the operator's parameter), which
are, however, not considered in previous approaches, thus leading to
sub-optimal results. In this paper, we propose the sequential multi-agent DAC
(Seq-MADAC) framework to address this issue by considering the inherent
inter-dependencies of multiple parameters. Specifically, we propose a
sequential advantage decomposition network, which can leverage action-order
information through sequential advantage decomposition. Experiments from
synthetic functions to the configuration of multi-objective optimization
algorithms demonstrate Seq-MADAC's superior performance over state-of-the-art
MARL methods and show strong generalization across problem classes. Seq-MADAC
establishes a new paradigm for the widespread dependency-aware automated
algorithm configuration. Our code is available at
https://github.com/lamda-bbo/seq-madac.

</details>


### [591] [A Multimodal, Multitask System for Generating E Commerce Text Listings from Images](https://arxiv.org/abs/2510.21835)
*Nayan Kumar Singh*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Manually generating catchy descriptions and names is labor intensive and a
slow process for retailers. Although generative AI provides an automation
solution in form of Vision to Language Models (VLM), the current VLMs are prone
to factual "hallucinations". Siloed, single task models are not only
inefficient but also fail to capture interdependent relationships between
features. To address these challenges, we propose an end to end, multi task
system that generates factually grounded textual listings from a single image.
The contributions of this study are two proposals for the model architecture.
First, application of multi task learning approach for fine tuning a vision
encoder where a single vision backbone is jointly trained on attribute
prediction such as color, hemline and neck style and price regression. Second,
introduction of a hierarchical generation process where the model's own
predicted attributes are embedded in a prompt and fed to the text decoder to
improve factual consistency. The experiments demonstrate the superiority of
this architecture. The multi tasking approach outperforms both the independent
price regression, with a 3.6% better R2 Value and attribute classification,
with a 6.6% improvement F1 score. Critically, the hierarchical generation
process proves highly effective, slashing the factual hallucination rate from
12.7% to 7.1%, a 44.5% relative reduction, compared to a non hierarchical
ablation. The hierarchical approach also reduces the latency of the
autoregressive text generation process by a factor of 3.5 when compared to
direct vision to language model of similar size. One minor caveat is that the
model does perform 3.5% worse than direct vision-to-language model on ROUGE-L
score.

</details>


### [592] [COLA: Continual Learning via Autoencoder Retrieval of Adapters](https://arxiv.org/abs/2510.21836)
*Jaya Krishna Mandivarapu*

Main category: cs.LG

TL;DR: COLA框架通过学习任务权重相关的低维嵌入来解决大型语言模型（LLM）在持续学习中遇到的灾难性遗忘问题，实现了高效学习、保留旧知识并减少参数使用。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在持续学习中存在计算成本高、灾难性遗忘以及更新模型导致知识覆盖的问题，现有方法难以满足频繁再训练和知识增量的需求。

Method: 提出了一种名为COLA的新框架，该框架使用自动编码器学习捕获与不同任务相关的权重低维嵌入，从而在不使用数据重放或大量特定任务参数的情况下，促进新任务的知识迁移并防止灾难性遗忘。

Result: COLA框架能够使LLM在很少的训练下高效学习新任务，同时保持先前任务的性能，并且无需保留早期训练数据。实验评估表明，该方法在多个数据集上不仅克服了灾难性遗忘，还显著减少了参数使用和内存占用，并优于现有的最先进方法。

Conclusion: COLA框架通过利用低维嵌入有效解决了LLM在持续学习中的灾难性遗忘问题，同时提高了效率并减少了资源消耗，证明了其在多种任务上的优越性。

Abstract: Learning a set of tasks over time, also known as continual learning (CL), is
one of the most challenging problems in artificial intelligence due to
catastrophic forgetting. Large language models (LLMs) are often impractical to
frequent re-training and continual learning , due to high cost of computational
resources for training. Moreover, LLM are not suitable for continual learning
as updating these models over time for acquiring new knowledge leads to
overwrites existing knowledge leading to common phenomenon know as
\textit{catastrophic forgetting}. In this paper, we aim to address these
concerns using a novel framework , COLA that employs an autoencoder to learn
capture low-dimensional embeddings of the weights associated with various
tasks. Our approach facilitates the transfer of knowledge to new tasks while
preventing catastrophic forgetting, all without using data replay or a
substantial set of task-specific parameters. Our approach, COLA, makes the LLM
efficiently learn new tasks with minimal training, insignificant performance
degradation on previous tasks, and eliminates the need for retaining earlier
training data. Empirical evaluation on different datasets ranging from task
oriented dialouge system to intent classsfication datasets showcases that our
method not only overcomes catastrophic forgetting but also achieves significant
reduction in parameter usage and memory size, across multiple tasks and
outperforming the existing state of the art methods across multiple datasets.

</details>


### [593] [KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group](https://arxiv.org/abs/2510.21844)
*Azree Nazri*

Main category: cs.LG

TL;DR: LLMs因参数量大而面临计算和环境挑战。KARIPAP提出一种量子启发式张量网络压缩方法（iPEPS+TRG），可大幅减少模型大小、训练和推理时间，同时仅损失少量精度。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM压缩方法忽略了复杂的层间相关性，导致模型仍然存在巨大的计算和环境负担，限制了其可及性。

Method: 提出一种量子启发式张量网络压缩方法KARIPAP，利用无限投影纠缠对态（iPEPS）和张量重整化群（TRG）进行张量网络压缩，以捕捉跨层纠缠并实现多项式时间收缩。

Result: 在LLaMA-2 7B模型上，KARIPAP实现了高达93%的内存和70%的参数缩减，训练速度提升50%，推理速度提升25%，准确率仅下降2-3%。层间纠缠分析表明，较深层的模型冗余度较高，适合进行张量分解。

Conclusion: KARIPAP证明了现代LLM占据低维纠缠流形，为构建可扩展、节能且具有量子意识的AI架构提供了可能。

Abstract: Large Language Models (LLMs) like ChatGPT and LLaMA drive rapid progress in
generative AI, yet their huge parameter scales create severe computational and
environmental burdens. High training costs, energy use, and limited device
deployment hinder accessibility. Existing compression - pruning, distillation,
low-rank, and quantization - reduces size but ignores complex inter-layer
correlations. We propose KARIPAP, a quantum-inspired tensor network compression
using Infinite Projected Entangled Pair States (iPEPS) and Tensor
Renormalization Group (TRG) contraction. Unlike 1D Matrix Product States, iPEPS
captures multi-directional entanglement in attention and deep transformer
layers. TRG ensures polynomial-time contraction, making tensorization feasible
while preserving key correlation geometry. Experiments on LLaMA-2 7B show up to
93% memory and 70% parameter reduction, with 50% faster training, 25% faster
inference, and only 2-3% accuracy loss. Layer-wise entanglement profiling
reveals redundancy in deeper layers, confirming their suitability for tensor
factorization. KARIPAP demonstrates that modern LLMs occupy low-dimensional
entanglement manifolds, enabling scalable, energy-efficient, and quantum-aware
AI architectures.

</details>


### [594] [Training data membership inference via Gaussian process meta-modeling: a post-hoc analysis approach](https://arxiv.org/abs/2510.21846)
*Yongchao Huang,Pengfei Zhang,Shahzad Mumtaz*

Main category: cs.LG

TL;DR: GP-MIA是一种基于高斯过程（GP）元学习的高效且可解释的成员推断攻击（MIA）方法，它利用单个训练模型的后验指标来区分训练数据的成员和非成员，同时提供校准的不确定性估计。


<details>
  <summary>Details</summary>
Motivation: 现有的成员推断攻击（MIA）方法通常依赖于影子模型或大量的查询访问，这限制了它们的实际应用。因此，需要一种更实用、更高效的方法来检测数据点是否曾被用于模型的训练集，以应对潜在的隐私风险。

Method: GP-MIA利用单个已训练好的模型，提取其后验指标，如准确率、熵、数据集统计信息以及可选的敏感性特征（例如梯度、NTK度量）。然后，它训练一个GP分类器来区分数据点是属于训练集（成员）还是不属于训练集（非成员）。此外，该方法还能提供校准的不确定性估计。

Result: 在合成数据、欺诈检测数据、CIFAR-10和WikiText-2等数据集上的实验表明，GP-MIA在准确性和泛化性方面均表现出色，能够有效地区分成员和非成员。

Conclusion: GP-MIA作为一种新颖的成员推断攻击方法，通过利用高斯过程元学习和单个模型的后验指标，实现了高效、可解释且具有良好准确性和泛化性的隐私泄露检测，为解决现有MIA方法的局限性提供了一个切实可行的替代方案。

Abstract: Membership inference attacks (MIAs) test whether a data point was part of a
model's training set, posing serious privacy risks. Existing methods often
depend on shadow models or heavy query access, which limits their practicality.
We propose GP-MIA, an efficient and interpretable approach based on Gaussian
process (GP) meta-modeling. Using post-hoc metrics such as accuracy, entropy,
dataset statistics, and optional sensitivity features (e.g. gradients, NTK
measures) from a single trained model, GP-MIA trains a GP classifier to
distinguish members from non-members while providing calibrated uncertainty
estimates. Experiments on synthetic data, real-world fraud detection data,
CIFAR-10, and WikiText-2 show that GP-MIA achieves high accuracy and
generalizability, offering a practical alternative to existing MIAs.

</details>


### [595] [SynCast: Synergizing Contradictions in Precipitation Nowcasting via Diffusion Sequential Preference Optimization](https://arxiv.org/abs/2510.21847)
*Kaiyi Xu,Junchao Gong,Wenlong Zhang,Ben Fei,Lei Bai,Wanli Ouyang*

Main category: cs.LG

TL;DR: 本研究提出了一种名为SynCast的新方法，通过引入偏好优化来解决雷达回波预测中的不确定性和多指标冲突问题，旨在提高极端天气预测的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习方法在降水临近预报中存在预测平滑、难以捕捉极端事件以及概率生成模型性能波动等问题。同时，临近预报中的多个评价指标（如CSI和FAR）之间存在冲突，难以同时优化。

Method: 提出了一种名为SynCast的新方法，该方法采用两阶段的扩散序列偏好优化（Diffusion-SPO）框架。第一阶段优化目标是降低虚报率（FAR），第二阶段在保持FAR对齐的约束下进一步优化临界成功指数（CSI），以实现跨冲突指标的协同改进。

Result: SynCast通过两阶段的偏好优化，能够有效降低虚报率，并在保持低虚报率的同时提高临界成功指数，从而在相互冲突的指标上取得协同的性能提升。

Conclusion: SynCast通过引入偏好优化，首次将人类反馈强化学习的思想应用于降水临近预报，有效解决了现有方法的局限性，实现了在多个冲突指标上的持续优越性能。

Abstract: Precipitation nowcasting based on radar echoes plays a crucial role in
monitoring extreme weather and supporting disaster prevention. Although deep
learning approaches have achieved significant progress, they still face notable
limitations. For example, deterministic models tend to produce over-smoothed
predictions, which struggle to capture extreme events and fine-scale
precipitation patterns. Probabilistic generative models, due to their inherent
randomness, often show fluctuating performance across different metrics and
rarely achieve consistently optimal results. Furthermore, precipitation
nowcasting is typically evaluated using multiple metrics, some of which are
inherently conflicting. For instance, there is often a trade-off between the
Critical Success Index (CSI) and the False Alarm Ratio (FAR), making it
challenging for existing models to deliver forecasts that perform well on both
metrics simultaneously. To address these challenges, we introduce preference
optimization into precipitation nowcasting for the first time, motivated by the
success of reinforcement learning from human feedback in large language models.
Specifically, we propose SynCast, a method that employs the two-stage
post-training framework of Diffusion Sequential Preference Optimization
(Diffusion-SPO), to progressively align conflicting metrics and consistently
achieve superior performance. In the first stage, the framework focuses on
reducing FAR, training the model to effectively suppress false alarms. Building
on this foundation, the second stage further optimizes CSI with constraints
that preserve FAR alignment, thereby achieving synergistic improvements across
these conflicting metrics.

</details>


### [596] [TowerVision: Understanding and Improving Multilinguality in Vision-Language Models](https://arxiv.org/abs/2510.21849)
*André G. Viveiros,Patrick Fernandes,Saul Santos,Sonal Sannigrahi,Emmanouil Zaranis,Nuno M. Guerreiro,Amin Farajian,Pierre Colombo,Graham Neubig,André F. T. Martins*

Main category: cs.LG

TL;DR: 尽管视觉语言模型 (VLM) 已取得显著进展，但现有工作多以英语为中心，限制了其在多语言环境下的效果。本研究通过对训练数据构成、编码器选择和文本骨干等多种多语言设计选择进行全面的实证分析，提出了 TowerVision。TowerVision 是一个基于多语言纯文本模型 Tower+ 的开放多语言 VLM 系列，可用于图文和视频-文本任务。


<details>
  <summary>Details</summary>
Motivation: 分析多语言设计选择对 VLM 效果的影响，并提出相应的模型和数据集。

Method: 通过对训练数据构成、编码器选择和文本骨干等多种多语言设计选择进行实证分析，构建了 TowerVision 模型系列和 VisionBlocks 数据集。

Result: TowerVision 在多个多模态多语言基准测试中表现出竞争力，特别在文化相关任务和多模态翻译方面表现突出，并在 ALM-Bench、Multi30K（图像任务）和 ViMUL-Bench（视频任务）上超越了使用更大数据集训练的现有方法。VisionBlocks 是一个高质量、经过精心策划的视觉-语言数据集。研究发现，多语言视觉-语言训练数据能显著提高跨语言泛化能力，并且指令微调的 LLM 并非总是最佳的初始化点。

Conclusion: 多语言视觉-语言训练数据能显著提高跨语言泛化能力。指令微调的 LLM 并非总是最佳的初始化点。研究者公开发布了所有模型、数据和训练方法以支持进一步研究。

Abstract: Despite significant advances in vision-language models (VLMs), most existing
work follows an English-centric design process, limiting their effectiveness in
multilingual settings. In this work, we provide a comprehensive empirical study
analyzing the impact of several multilingual design choices, such as training
data composition, encoder selection, and text backbones. The result is
TowerVision, a family of open multilingual VLMs for both image-text and
video-text tasks, built upon the multilingual text-only model Tower+.
TowerVision achieves competitive performance on multiple multimodal
multilingual benchmarks and shows particular strength in culturally grounded
tasks and multimodal translation. By incorporating visual and cultural context
during fine-tuning, our models surpass existing approaches trained on
substantially larger datasets, as demonstrated on ALM-Bench and Multi30K (image
tasks) and ViMUL-Bench (video tasks). Alongside the models, we release
VisionBlocks, a high-quality, curated vision-language dataset. Our findings
highlight that multilingual vision-language training data substantially
improves cross-lingual generalization -- both from high-resource to
underrepresented languages and vice versa -- and that instruction-tuned LLMs
are not always the optimal initialization point. To support further research,
we publicly release all models, data, and training recipes.

</details>


### [597] [Towards Interpretable Deep Learning and Analysis of Dynamical Systems via the Discrete Empirical Interpolation Method](https://arxiv.org/abs/2510.21852)
*Hojin Kim,Romit Maulik*

Main category: cs.LG

TL;DR: 我们提出了一个可微框架，利用离散经验插值法（DEIM）进行可解释的深度学习和动力学系统分析。虽然DEIM可以有效地近似投影基降阶模型（POD-ROM）中的非线性项，但其固定的插值点限制了对复杂和时变动力学的适应性。为了解决这个限制，我们开发了一种可微的自适应DEIM公式，用于一维粘性Burgers方程，允许神经网络以计算高效且物理一致的方式动态选择插值点。然后，我们将DEIM作为一个可解释的分析工具，用于检查在二维涡流合并问题上预训练的神经常微分方程（NODE）的学习动力学。DEIM轨迹揭示了NODE学习动力学中具有物理意义的特征，并暴露了其在推断到未见过的流动配置时的局限性。这些发现表明，DEIM不仅可以作为降阶工具，还可以作为理解和改进神经常微分方程模型泛化行为的诊断框架。


<details>
  <summary>Details</summary>
Motivation: DEIM在近似非线性项方面很有效，但其固定的插值点限制了其处理复杂和时变动力学的能力。

Method: 开发了一种可微的自适应DEIM方法，用于一维粘性Burgers方程，允许动态选择插值点。将DEIM应用于分析二维涡流合并问题上预训练的NODE的学习动力学。

Result: DEIM轨迹揭示了NODE学习动力学中的物理意义特征，并暴露了其外推能力的局限性。DEIM可以作为一种诊断框架来理解和改进NODE模型的泛化行为。

Conclusion: DEIM不仅可以作为降阶工具，还可以作为理解和改进神经常微分方程模型泛化行为的诊断框架。

Abstract: We present a differentiable framework that leverages the Discrete Empirical
Interpolation Method (DEIM) for interpretable deep learning and dynamical
system analysis. Although DEIM efficiently approximates nonlinear terms in
projection-based reduced-order models (POD-ROM), its fixed interpolation points
limit the adaptability to complex and time-varying dynamics. To address this
limitation, we first develop a differentiable adaptive DEIM formulation for the
one-dimensional viscous Burgers equation, which allows neural networks to
dynamically select interpolation points in a computationally efficient and
physically consistent manner. We then apply DEIM as an interpretable analysis
tool for examining the learned dynamics of a pre-trained Neural Ordinary
Differential Equation (NODE) on a two-dimensional vortex-merging problem. The
DEIM trajectories reveal physically meaningful features in the learned dynamics
of NODE and expose its limitations when extrapolating to unseen flow
configurations. These findings demonstrate that DEIM can serve not only as a
model reduction tool but also as a diagnostic framework for understanding and
improving the generalization behavior of neural differential equation models.

</details>


### [598] [K-DAREK: Distance Aware Error for Kurkova Kolmogorov Networks](https://arxiv.org/abs/2510.22021)
*Masoud Ataei,Vikas Dhiman,Mohammad Javad Khojasteh*

Main category: cs.LG

TL;DR: KANs和KKANs是用于函数逼近的两种神经网络架构。KKANs通过使用切比雪夫层和多层感知器来改进KANs，从而在训练过程中实现更稳定的收敛。


<details>
  <summary>Details</summary>
Motivation: 评估KANs和KKANs在函数逼近、算子估计和动力学系统建模方面的能力。

Method: 提出了一种名为K-DAREK的新型学习算法，该算法结合了KKAN架构和距离感知误差，以实现高效且可解释的函数逼近，并进行不确定性量化。

Result: K-DAREK在安全控制任务中的案例研究表明，与KANs集成模型相比，K-DAREK的训练速度提高了约4倍，计算效率提高了10倍。与GPs相比，K-DAREK的数据集大小增加了8.6倍，可扩展性更强。与DAREK相比，K-DAREK的安全性提高了50%。

Conclusion: K-DAREK是一种高效且可解释的函数逼近方法，具有不确定性量化能力，在各种应用中显示出优越的性能。

Abstract: Neural networks are parametric and powerful tools for function approximation,
and the choice of architecture heavily influences their interpretability,
efficiency, and generalization. In contrast, Gaussian processes (GPs) are
nonparametric probabilistic models that define distributions over functions
using a kernel to capture correlations among data points. However, these models
become computationally expensive for large-scale problems, as they require
inverting a large covariance matrix. Kolmogorov- Arnold networks (KANs),
semi-parametric neural architectures, have emerged as a prominent approach for
modeling complex functions with structured and efficient representations
through spline layers. Kurkova Kolmogorov-Arnold networks (KKANs) extend this
idea by reducing the number of spline layers in KAN and replacing them with
Chebyshev layers and multi-layer perceptrons, thereby mapping inputs into
higher-dimensional spaces before applying spline-based transformations.
Compared to KANs, KKANs perform more stable convergence during training, making
them a strong architecture for estimating operators and system modeling in
dynamical systems. By enhancing the KKAN architecture, we develop a novel
learning algorithm, distance-aware error for Kurkova-Kolmogorov networks
(K-DAREK), for efficient and interpretable function approximation with
uncertainty quantification. Our approach establishes robust error bounds that
are distance-aware; this means they reflect the proximity of a test point to
its nearest training points. Through case studies on a safe control task, we
demonstrate that K-DAREK is about four times faster and ten times higher
computationally efficiency than Ensemble of KANs, 8.6 times more scalable than
GP by increasing the data size, and 50% safer than our previous work
distance-aware error for Kolmogorov networks (DAREK).

</details>


### [599] [Privacy-preserving Decision-focused Learning for Multi-energy Systems](https://arxiv.org/abs/2510.21858)
*Yangze Zhou,Ruiyang Yao,Dalin Qin,Yixiong Jia,Yi Wang*

Main category: cs.LG

TL;DR: 该研究提出了一种用于多能源系统（MES）的隐私保护决策导向学习（DFL）框架，通过信息隐藏、矩阵分解和同态加密等技术，在保护敏感负荷数据和模型参数隐私的同时，降低了 MES 的调度成本。


<details>
  <summary>Details</summary>
Motivation: 传统的多能源系统（MES）调度依赖于单独的负荷预测和决策，预测模型通常只关注最小化预测误差，忽略了其对下游决策的影响。决策导向学习（DFL）虽然旨在最小化决策成本，但在 MES 中的应用面临数据共享和模型参数交互带来的严重隐私问题。

Method: 提出了一种隐私保护的 DFL 框架，引入信息隐藏技术来保护私有数据，同时允许恢复模型训练所需的决策变量和梯度。结合矩阵分解和同态加密设计了安全协议，以防止串通和未经授权的数据访问。开发了隐私保护的负荷模式识别算法，以训练适用于异构负荷模式的专用 DFL 模型。

Result: 该框架在理论分析和实际 MES 数据案例研究中，证明了其在保护隐私的同时，能够持续实现比现有方法更低的平均日调度成本。

Conclusion: 所提出的隐私保护 DFL 框架能够有效解决 MES 调度中的隐私泄露问题，并在不牺牲预测精度的前提下，实现更优的调度决策，降低运营成本。

Abstract: Decision-making for multi-energy system (MES) dispatch depends on accurate
load forecasting. Traditionally, load forecasting and decision-making for MES
are implemented separately. Forecasting models are typically trained to
minimize forecasting errors, overlooking their impact on downstream
decision-making. To address this, decision-focused learning (DFL) has been
studied to minimize decision-making costs instead. However, practical adoption
of DFL in MES faces significant challenges: the process requires sharing
sensitive load data and model parameters across multiple sectors, raising
serious privacy issues. To this end, we propose a privacy-preserving DFL
framework tailored for MES. Our approach introduces information masking to
safeguard private data while enabling recovery of decision variables and
gradients required for model training. To further enhance security for DFL, we
design a safety protocol combining matrix decomposition and homomorphic
encryption, effectively preventing collusion and unauthorized data access.
Additionally, we developed a privacy-preserving load pattern recognition
algorithm, enabling the training of specialized DFL models for heterogeneous
load patterns. Theoretical analysis and comprehensive case studies, including
real-world MES data, demonstrate that our framework not only protects privacy
but also consistently achieves lower average daily dispatch costs compared to
existing methods.

</details>


### [600] [OpenEM: Large-scale multi-structural 3D datasets for electromagnetic methods](https://arxiv.org/abs/2510.21859)
*Shuang Wang,Xuben Wang,Fei Deng,Peifan Jiang,Jian Chen,Gianluca Fiandaca*

Main category: cs.LG

TL;DR: OpenEM是一个大规模、多结构的三维地电数据集，包含九类地质模型，并提供基于深度学习的快速正演方法，旨在加速深度学习在地电勘探中的应用。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习在地电方法中的应用受限于数据集质量和复杂度，未能充分代表真实地质环境，且缺乏标准化公开数据集，阻碍了研究进展。

Method: 构建了一个包含九类地质模型的OpenEM数据集，并开发了基于深度学习的快速三维正演建模方法，以高效处理该数据集。

Result: 开发了一个大规模、多结构的三维地电数据集OpenEM，以及配套的深度学习快速正演建模方法，实现了对数据集的高效正演模拟。

Conclusion: OpenEM数据集和配套的正演方法能够加速深度学习在地电勘探中的应用，为相关研究提供了一个统一、全面的资源。

Abstract: With the remarkable success of deep learning, applying such techniques to EM
methods has emerged as a promising research direction to overcome the
limitations of conventional approaches. The effectiveness of deep learning
methods depends heavily on the quality of datasets, which directly influences
model performance and generalization ability. Existing application studies
often construct datasets from random one-dimensional or structurally simple
three-dimensional models, which fail to represent the complexity of real
geological environments. Furthermore, the absence of standardized, publicly
available three-dimensional geoelectric datasets continues to hinder progress
in deep learning based EM exploration. To address these limitations, we present
OpenEM, a large scale, multi structural three dimensional geoelectric dataset
that encompasses a broad range of geologically plausible subsurface structures.
OpenEM consists of nine categories of geoelectric models, spanning from simple
configurations with anomalous bodies in half space to more complex structures
such as flat layers, folded layers, flat faults, curved faults, and their
corresponding variants with anomalous bodies. Since three-dimensional forward
modeling in electromagnetics is extremely time-consuming, we further developed
a deep learning based fast forward modeling approach for OpenEM, enabling
efficient and reliable forward modeling across the entire dataset. This
capability allows OpenEM to be rapidly deployed for a wide range of tasks.
OpenEM provides a unified, comprehensive, and large-scale dataset for common EM
exploration systems to accelerate the application of deep learning in
electromagnetic methods. The complete dataset, along with the forward modeling
codes and trained models, is publicly available at
https://doi.org/10.5281/zenodo.17141981.

</details>


### [601] [The Mirror Loop: Recursive Non-Convergence in Generative Reasoning Systems](https://arxiv.org/abs/2510.21861)
*Bentley DeVilling*

Main category: cs.LG

TL;DR: 在没有外部反馈的情况下，大型语言模型（LLM）的自我反思推理会陷入信息停滞，但即使是最小的外部验证也能重新激活其学习能力。


<details>
  <summary>Details</summary>
Motivation: 评估在没有外部反馈的情况下，LLM 进行递归自我评估的能力，并研究最小的外部验证如何影响其推理过程。

Method: 通过跨越三个模型（GPT-4o-mini、Claude 3 Haiku、Gemini 2.0 Flash）和四种任务类型（算术、代码、解释、反思）的 144 个推理序列，在无基础自我批评和最小基础干预（第三次迭代中的单一验证步骤）两种条件下进行测试，并使用信息变化（delta I）、n-gram 新颖性、嵌入漂移和字符级熵等指标进行量化。

Result: 在无基础运行中，信息变化（delta I）从早期（0.193）到后期（0.087）下降了 55%，并且在所有三个模型中都观察到一致的模式。在进行基础干预后，基础运行的信息变化立即反弹了 28%，并在此后保持了非零方差。补充指标也显示了相同的模式，表明无基础的反思会趋于信息封闭。

Conclusion: 在没有与独立验证者或环境进行信息交换的情况下，LLM 的递归推理会趋于认知停滞。最小的基础验证可以作为耗散耦合，重新引入信息流，从而克服这种结构性限制。这种跨架构的一致性表明，这种“镜像循环”可能源于共享的自回归训练目标，而不是特定于供应商的对齐方案。研究结果有助于区分表现性反思和认知性反思，并为基础、协作式推理的设计原则提供依据。

Abstract: Large language models are often described as capable of reflective reasoning,
yet recursive self-evaluation without external feedback frequently yields
reformulation rather than progress. We test this prediction in a cross-provider
study of 144 reasoning sequences across three models (OpenAI GPT-4o-mini,
Anthropic Claude 3 Haiku, and Google Gemini 2.0 Flash) and four task families
(arithmetic, code, explanation, reflection), each iterated ten times under two
conditions: ungrounded self-critique and a minimal grounding intervention (a
single verification step at iteration three). Mean informational change (delta
I, measured via normalized edit distance) declined by 55% from early (0.193) to
late (0.087) iterations in ungrounded runs, with consistent patterns across all
three providers. Grounded runs showed a +28% rebound in informational change
immediately after the intervention and sustained non-zero variance thereafter.
Complementary measures-n-gram novelty, embedding drift, and character-level
entropy-converged on the same pattern: reflection without contact tends toward
informational closure. We interpret this as evidence for a structural limit on
self-correction in generative reasoning: without an exchange of information
with an independent verifier or environment, recursive inference approaches an
attractor state of epistemic stasis. Minimal grounding functions as dissipative
coupling, reintroducing informational flux. The cross-architecture consistency
suggests the mirror loop arises from shared autoregressive training objectives
rather than provider-specific alignment schemes. The results delineate when
reflection is performative rather than epistemic and motivate design principles
for grounded, cooperative reasoning. Materials and code are publicly available.

</details>


### [602] [A supervised discriminant data representation: application to pattern classification](https://arxiv.org/abs/2510.21898)
*Fadi Dornaika,Ahmad Khoder,Abdelmalik Moujahid,Wassim Khoder*

Main category: cs.LG

TL;DR: 该方法提出了一种混合线性特征提取方案，用于监督多类分类问题，旨在融合RSLDA和ICS_DLSR的优点。


<details>
  <summary>Details</summary>
Motivation: 机器学习和模式识别算法的性能通常取决于数据表示，因此需要设计有效的预处理框架和数据转换方法。

Method: 提出了一种结合了RSLDA和ICS_DLSR优点的统一判据，利用稀疏性促进技术进行特征选择和保持样本的行稀疏性一致性。通过基于梯度下降和不同初始化方案的迭代交替最小化方案来估计线性变换和正交矩阵。

Result: 在人脸、物体和数字等多个数据集上的实验表明，该方法在大多数情况下优于现有方法。

Conclusion: 所提出的混合线性特征提取框架能够有效提升多类分类问题的性能。

Abstract: The performance of machine learning and pattern recognition algorithms
generally depends on data representation. That is why, much of the current
effort in performing machine learning algorithms goes into the design of
preprocessing frameworks and data transformations able to support effective
machine learning. The method proposed in this work consists of a hybrid linear
feature extraction scheme to be used in supervised multi-class classification
problems. Inspired by two recent linear discriminant methods: robust sparse
linear discriminant analysis (RSLDA) and inter-class sparsitybased
discriminative least square regression (ICS_DLSR), we propose a unifying
criterion that is able to retain the advantages of these two powerful methods.
The resulting transformation relies on sparsity-promoting techniques both to
select the features that most accurately represent the data and to preserve the
row-sparsity consistency property of samples from the same class. The linear
transformation and the orthogonal matrix are estimated using an iterative
alternating minimization scheme based on steepest descent gradient method and
different initialization schemes. The proposed framework is generic in the
sense that it allows the combination and tuning of other linear discriminant
embedding methods. According to the experiments conducted on several datasets
including faces, objects, and digits, the proposed method was able to
outperform competing methods in most cases.

</details>


### [603] [Adversarial Déjà Vu: Jailbreak Dictionary Learning for Stronger Generalization to Unseen Attacks](https://arxiv.org/abs/2510.21910)
*Mahavir Dabas,Tran Huynh,Nikhil Reddy Billa,Jiachen T. Wang,Peng Gao,Charith Peris,Yao Ma,Rahul Gupta,Ming Jin,Prateek Mittal,Ruoxi Jia*

Main category: cs.LG

TL;DR: 大型语言模型容易受到越狱攻击，但可以通过“对抗性先见”（Adversarial D'ejà Vu）假设来防御，该假设认为新的越狱攻击只是先前攻击的重新组合。通过提取和压缩“技能原语”，然后使用“对抗性技能组合训练”（ASCoT）进行训练，可以提高模型对未见过的攻击的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）仍然容易受到越狱攻击，绕过安全防护措施以产生有害输出。防御新型越狱攻击是人工智能安全领域面临的关键挑战。然而，现有的对抗训练方法由于优化困难和现实威胁模型定义不清，在实践中常常无法防御新型越狱攻击。

Method: 本研究提出了一种名为“对抗性先见”（Adversarial D'ejà Vu）的新范式，该范式假设新型越狱攻击是先前攻击的“技能原语”的重新组合。研究人员通过大规模分析32篇越狱攻击论文，使用自动化流程提取并压缩这些“技能原语”，并让大型语言模型生成可读的描述。在此基础上，引入了“对抗性技能组合训练”（ASCoT），该方法不依赖孤立的攻击实例，而是对“技能原语”的各种组合进行训练。

Result: 分析表明，未见的越狱攻击可以被解释为先前“技能原语”的稀疏组合，并且随着“技能覆盖率”的增加，解释能力单调增强。ASCoT在防御未见过的攻击（包括多轮越狱攻击）方面显著提高了鲁棒性，同时保持了较低的过度拒绝率。研究还发现，扩展“对抗性技能覆盖率”是防御新型攻击的关键，而不仅仅是增加数据规模。

Conclusion: 本研究提出的“对抗性先见”假设和ASCoT训练方法，为提高大型语言模型防御新型越狱攻击的能力提供了新的途径。通过理解和组合先前攻击的“技能原语”，可以更有效地提升模型的鲁棒性，并且扩大“技能覆盖率”是未来防御的关键。

Abstract: Large language models remain vulnerable to jailbreak attacks that bypass
safety guardrails to elicit harmful outputs. Defending against novel jailbreaks
represents a critical challenge in AI safety. Adversarial training -- designed
to make models robust against worst-case perturbations -- has been the dominant
paradigm for adversarial robustness. However, due to optimization challenges
and difficulties in defining realistic threat models, adversarial training
methods often fail on newly developed jailbreaks in practice. This paper
proposes a new paradigm for improving robustness against unseen jailbreaks,
centered on the Adversarial D\'ej\`a Vu hypothesis: novel jailbreaks are not
fundamentally new, but largely recombinations of adversarial skills from
previous attacks. We study this hypothesis through a large-scale analysis of 32
attack papers published over two years. Using an automated pipeline, we extract
and compress adversarial skills into a sparse dictionary of primitives, with
LLMs generating human-readable descriptions. Our analysis reveals that unseen
attacks can be effectively explained as sparse compositions of earlier skills,
with explanatory power increasing monotonically as skill coverage grows. Guided
by this insight, we introduce Adversarial Skill Compositional Training (ASCoT),
which trains on diverse compositions of skill primitives rather than isolated
attack instances. ASCoT substantially improves robustness to unseen attacks,
including multi-turn jailbreaks, while maintaining low over-refusal rates. We
also demonstrate that expanding adversarial skill coverage, not just data
scale, is key to defending against novel attacks.
\textcolor{red}{\textbf{Warning: This paper contains content that may be
harmful or offensive in nature.

</details>


### [604] [Joint Score-Threshold Optimization for Interpretable Risk Assessment Under Partial Supervision](https://arxiv.org/abs/2510.21934)
*Fardin Gankhanloo,Emmett Springer,Erik H. Hoyer,Daniel L. Young,Kimia Ghobadi*

Main category: cs.LG

TL;DR: EHR数据风险评估工具存在标签不全和误分类成本不对称的问题，提出一种混合整数规划（MIP）框架来优化评分权重和类别阈值，以解决这些挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的医疗风险评估工具使用点数评分系统，但电子健康记录（EHR）数据的应用受到标签不全（只有极端类别可信）和误分类成本不对称（随序数距离增加）的阻碍。

Method: 提出一个混合整数规划（MIP）框架，该框架在这些约束下联合优化评分权重和类别阈值。该方法通过每实例可行标签集处理部分监督，结合了不对称的、感知距离的客观函数，并通过最小阈值间隙防止了中间类别的坍塌。此外，通过使用softplus损失的CSO松弛来保留序数结构，同时实现高效优化。该框架还支持符号限制、稀疏性和对现有工具的最小修改等治理约束。

Result: 提出的MIP框架能够有效地处理部分监督和不对称的误分类成本，通过CSO松弛实现高效优化，并支持各种治理约束，确保在临床工作流程中的实际部署能力。

Conclusion: 该研究提出的混合整数规划（MIP）框架为优化EHR数据驱动的医疗风险评估工具提供了一个有效且可部署的解决方案，解决了现有方法的关键挑战。

Abstract: Risk assessment tools in healthcare commonly employ point-based scoring
systems that map patients to ordinal risk categories via thresholds. While
electronic health record (EHR) data presents opportunities for data-driven
optimization of these tools, two fundamental challenges impede standard
supervised learning: (1) partial supervision arising from intervention-censored
outcomes, where only extreme categories can be reliably labeled, and (2)
asymmetric misclassification costs that increase with ordinal distance. We
propose a mixed-integer programming (MIP) framework that jointly optimizes
scoring weights and category thresholds under these constraints. Our approach
handles partial supervision through per-instance feasible label sets,
incorporates asymmetric distance-aware objectives, and prevents middle-category
collapse via minimum threshold gaps. We further develop a CSO relaxation using
softplus losses that preserves the ordinal structure while enabling efficient
optimization. The framework supports governance constraints including sign
restrictions, sparsity, and minimal modifications to incumbent tools, ensuring
practical deployability in clinical workflows.

</details>


### [605] [AutoSciDACT: Automated Scientific Discovery through Contrastive Embedding and Hypothesis Testing](https://arxiv.org/abs/2510.21935)
*Samuel Bright-Thonney,Christina Reissel,Gaia Grosso,Nathaniel Woodward,Katya Govorkova,Andrzej Novak,Sang Eon Park,Eric Moreno,Philip Harris*

Main category: cs.LG

TL;DR: AutoSciDACT是一个新颖性检测流程，它结合了对比预训练和两样本检验，以应对科学数据中噪声和高维度的挑战，并能对检测到的异常进行统计量化。


<details>
  <summary>Details</summary>
Motivation: 科学数据具有噪声大、维度高且需要对异常值进行稳健统计声明的特点，而现有的异常检测方法通常无法满足科学发现的量化要求。

Method: 该工作提出了AutoSciDACT流程，首先利用对比预训练创建数据的低维表示，然后结合新物理学习机（NPLM）框架进行敏感的机器学习两样本检验，以识别并量化数据中的偏差。

Result: 在天文学、物理学、生物学、图像和合成数据集上的实验表明，该方法对微量异常数据的检测具有很高的敏感性。

Conclusion: AutoSciDACT是首个面向科学严谨统计要求的通用新颖性检测流程，能够有效处理科学数据的挑战并进行量化声明。

Abstract: Novelty detection in large scientific datasets faces two key challenges: the
noisy and high-dimensional nature of experimental data, and the necessity of
making statistically robust statements about any observed outliers. While there
is a wealth of literature on anomaly detection via dimensionality reduction,
most methods do not produce outputs compatible with quantifiable claims of
scientific discovery. In this work we directly address these challenges,
presenting the first step towards a unified pipeline for novelty detection
adapted for the rigorous statistical demands of science. We introduce
AutoSciDACT (Automated Scientific Discovery with Anomalous Contrastive
Testing), a general-purpose pipeline for detecting novelty in scientific data.
AutoSciDACT begins by creating expressive low-dimensional data representations
using a contrastive pre-training, leveraging the abundance of high-quality
simulated data in many scientific domains alongside expertise that can guide
principled data augmentation strategies. These compact embeddings then enable
an extremely sensitive machine learning-based two-sample test using the New
Physics Learning Machine (NPLM) framework, which identifies and statistically
quantifies deviations in observed data relative to a reference distribution
(null hypothesis). We perform experiments across a range of astronomical,
physical, biological, image, and synthetic datasets, demonstrating strong
sensitivity to small injections of anomalous data across all domains.

</details>


### [606] [Generalization Bounds for Rank-sparse Neural Networks](https://arxiv.org/abs/2510.21945)
*Antoine Ledent,Rodrigo Alves,Yunwen Lei*

Main category: cs.LG

TL;DR: 神经网络在训练中表现出低秩属性，这篇论文探讨了这种属性如何影响模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 研究神经网络的低秩属性与其泛化能力之间的关系。

Method: 利用权重矩阵的低秩结构来证明泛化界限，并分析Schatten p范数对界限的影响。

Result: 在存在低秩结构的情况下，为神经网络提供了泛化界限，并揭示了样本复杂度与网络宽度、深度和秩之间的关系。

Conclusion: 神经网络的低秩属性对于理解和提高其泛化能力至关重要。

Abstract: It has been recently observed in much of the literature that neural networks
exhibit a bottleneck rank property: for larger depths, the activation and
weights of neural networks trained with gradient-based methods tend to be of
approximately low rank. In fact, the rank of the activations of each layer
converges to a fixed value referred to as the ``bottleneck rank'', which is the
minimum rank required to represent the training data. This perspective is in
line with the observation that regularizing linear networks (without
activations) with weight decay is equivalent to minimizing the Schatten $p$
quasi norm of the neural network. In this paper we investigate the implications
of this phenomenon for generalization. More specifically, we prove
generalization bounds for neural networks which exploit the approximate low
rank structure of the weight matrices if present. The final results rely on the
Schatten $p$ quasi norms of the weight matrices: for small $p$, the bounds
exhibit a sample complexity $ \widetilde{O}(WrL^2)$ where $W$ and $L$ are the
width and depth of the neural network respectively and where $r$ is the rank of
the weight matrices. As $p$ increases, the bound behaves more like a norm-based
bound instead.

</details>


### [607] [Transformer Based Linear Attention with Optimized GPU Kernel Implementation](https://arxiv.org/abs/2510.21956)
*Armin Gerami,Ramani Duraiswami*

Main category: cs.LG

TL;DR: Transformer 中的线性注意力（LA）机制通过将时间复杂度从 O(N^2D) 降低到 O(ND^2) 来提高效率，但实际效率低于理论值。本文提出了一种新的 LA 前向和后向传播方法，并进行了 CUDA 实现优化，速度提高了 3.3 倍，内存消耗降低了 3.6 倍，并在大型语言模型上验证了其与常规注意力的可比性。


<details>
  <summary>Details</summary>
Motivation: Transformer 架构的 softmax 注意力机制具有 O(N^2D) 的时间复杂度，在训练和推理时效率低下。虽然线性注意力（LA）机制将复杂度降低到 O(ND^2)，但实际性能仍有提升空间。

Method: 提出了一种新颖的线性注意力（LA）前向和后向传播方法，并进行了高度优化的 CUDA 实现。

Result: 与现有技术相比，速度提高了 3.3 倍，内存消耗降低了 3.6 倍。在 1.4 亿参数语言模型上进行了验证，在推理基准测试中表现出与常规注意力相当的表达能力。

Conclusion: 所提出的 LA 方法和优化实现显著提高了 Transformer 的训练和推理效率，同时保持了模型的表达能力。

Abstract: The original softmax-based attention mechanism (regular attention) in the
extremely successful Transformer architecture computes attention between $N$
tokens, each embedded in a $D$-dimensional head, with a time complexity of
$O(N^2D)$. Given the success of Transformers, improving their runtime during
both training and inference is a popular research area. One such approach is
the introduction of the linear attention (LA) mechanisms, which offers a linear
time complexity of $O(ND^2)$ and have demonstrated comparable accuracy to
regular attention. However, LA in practice lags behind its theoretical
efficiency. We propose a novel method for LA's forward and backward passes,
along with a highly-optimized CUDA implementation. Our approach outperforms the
state-of-the-art by 3.3 times in speed and reduces memory consumption by 3.6
times. We validate these improvements in both single-layer and end-to-end
settings by training a 1.4 billion parameter language model, which demonstrates
similar expressivity to regular attention on major reasoning benchmarks.

</details>


### [608] [Parallel Sampling from Masked Diffusion Models via Conditional Independence Testing](https://arxiv.org/abs/2510.21961)
*Iskander Azangulov,Teodora Pandeva,Niranjani Prasad,Javier Zazo,Sushrut Karmalkar*

Main category: cs.LG

TL;DR: MDMs可以并行生成文本，但需要平衡条件独立性和高置信度预测。PUNT通过移除低置信度标记来解决此问题，提高了准确性和计算效率，尤其适用于长序列生成，并可能引发分层生成策略。


<details>
  <summary>Details</summary>
Motivation: 掩码扩散模型（MDMs）在离散文本生成方面有潜力，但需要解决并行采样中的条件独立性和高置信度预测之间的冲突。

Method: PUNT通过识别标记依赖关系并从冲突组中移除低置信度标记来解决并行采样中的取舍问题，从而生成满足独立性和置信度标准的标记索引集。

Result: PUNT在准确性和计算量之间提供了优于其他基线方法的权衡，尤其是在生成长序列时，在IFEval基准上准确率提高了16%。

Conclusion: PUNT在准确性和计算效率之间取得了良好的平衡，尤其是在长序列生成方面，并且可能通过一种分层生成策略来提高文本生成的整体质量。

Abstract: Masked diffusion models (MDMs) offer a compelling alternative to
autoregressive models (ARMs) for discrete text generation because they enable
parallel token sampling, rather than sequential, left-to-right generation. This
means potentially much faster inference. However, effective parallel sampling
faces two competing requirements: (i) simultaneously updated tokens must be
conditionally independent, and (ii) updates should prioritise high-confidence
predictions. These goals conflict because high-confidence predictions often
cluster and depend on each other, opportunities for parallel updates.
  We present PUNT, a model-agnostic sampler that reconciles this trade-off. Our
method identifies token dependencies and removes lower-confidence tokens from
conflicting groups. This produces sets of indices for unmasking that satisfy
both independence and confidence criteria. Our approach ensures improved
parallel unmasking through approximate conditional independence testing.
  Our experiments show that PUNT delivers a superior trade-off between accuracy
and compute when compared to other strong training-free baselines, especially
for generation of longer sequences. On the IFEval benchmark, it achieves up to
16\% higher accuracy over baseline methods, including sequential generation
(one-by-one). These gains hold across different values of hyperparameters,
mitigating the need for brittle hyperparameter tuning. Moreover, we observe
that PUNT induces an emergent hierarchical generation strategy, where the model
first establishes high-level paragraph structure before local refinement,
suggesting a planning-like generation process that contributes to strong
alignment performance.

</details>


### [609] [Deep Jump Gaussian Processes for Surrogate Modeling of High-Dimensional Piecewise Continuous Functions](https://arxiv.org/abs/2510.21974)
*Yang Xu,Chiwoo Park*

Main category: cs.LG

TL;DR: DJGP是一种用于高维分段连续函数的新型代理建模方法，通过添加局部线性投影层来克服传统方法在高维空间中的限制，并在实验中表现出优越的预测精度和不确定性量化能力。


<details>
  <summary>Details</summary>
Motivation: 提出一种用于高维分段连续函数的新型代理建模方法，以克服传统方法（如Jump Gaussian Processes）在高维输入空间中的局限性。

Method: DJGP通过在Jump Gaussian Processes（JGP）中添加一个局部线性投影层来实现。该投影层使用特定区域的矩阵来捕捉局部子空间结构，并将高维输入投影到低维空间。然后，使用JGP对投影后的输入进行建模，以捕捉分段连续关系。模型复杂度通过对投影矩阵应用高斯过程先验来控制。最后，开发了一种可扩展的变分推断算法来联合学习投影矩阵和JGP的超参数。

Result: DJGP在合成和基准数据集上的实验表明，与现有方法相比，其在预测精度和不确定性量化方面均表现更优。

Conclusion: DJGP是一种有效的高维分段连续函数代理建模方法，通过结合局部线性投影和Jump Gaussian Processes，在预测精度和不确定性量化方面取得了显著的改进。

Abstract: We introduce Deep Jump Gaussian Processes (DJGP), a novel method for
surrogate modeling of high-dimensional piecewise continuous functions. DJGP
overcomes the limitations of conventional Jump Gaussian Processes in
high-dimensional input spaces by adding a locally linear projection layer to
Jump Gaussian Processes. This projection uses region-specific matrices to
capture local subspace structures, naturally complementing the localized nature
of JGP, a variant of local Gaussian Processes. To control model complexity, we
place a Gaussian Process prior on the projection matrices, allowing them to
evolve smoothly across the input space. The projected inputs are then modeled
with a JGP to capture piecewise continuous relationships with the response.
This yields a distinctive two-layer deep learning of GP/JGP. We further develop
a scalable variational inference algorithm to jointly learn the projection
matrices and JGP hyperparameters. Experiments on synthetic and benchmark
datasets demonstrate that DJGP delivers superior predictive accuracy and more
reliable uncertainty quantification compared to existing approaches.

</details>


### [610] [Beyond Reasoning Gains: Mitigating General Capabilities Forgetting in Large Reasoning Models](https://arxiv.org/abs/2510.21978)
*Hoang Phan,Xianjun Yang,Kevin Yao,Jingyu Zhang,Shengjie Bi,Xiaocheng Tang,Madian Khabsa,Lijuan Liu,Deren Lei*

Main category: cs.LG

TL;DR: RLVR (Reinforcement Learning with Verifiable Rewards) can lead to models forgetting foundational skills. RECAP is a new replay strategy that dynamically reweights objectives to preserve general knowledge and improve reasoning without additional models or heavy tuning.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the risk of capability regression in RLVR, where models forget foundational skills after prolonged training, and the limitations of existing regularization strategies like KL divergence and experience replay in preventing this.

Method: The paper proposes RECAP, a replay strategy with dynamic objective reweighting for general knowledge preservation. RECAP's reweighting mechanism adapts online using short-horizon signals of convergence and instability to shift focus from saturated objectives to underperforming or volatile ones. It is designed to be end-to-end and applicable to existing RLVR pipelines without training additional models or heavy tuning.

Result: Extensive experiments on Qwen2.5-VL-3B and Qwen2.5-VL-7B benchmarks demonstrate that RECAP effectively preserves general capabilities and improves reasoning by enabling more flexible trade-offs among in-task rewards.

Conclusion: RECAP is an effective method for mitigating capability regression in RLVR, preserving general knowledge while simultaneously enhancing reasoning abilities through dynamic objective reweighting.

Abstract: Reinforcement learning with verifiable rewards (RLVR) has delivered
impressive gains in mathematical and multimodal reasoning and has become a
standard post-training paradigm for contemporary language and vision-language
models. However, the RLVR recipe introduces a significant risk of capability
regression, where models forget foundational skills after prolonged training
without employing regularization strategies. We empirically confirm this
concern, observing that open-source reasoning models suffer performance
degradation on core capabilities such as perception and faithfulness. While
imposing regularization terms like KL divergence can help prevent deviation
from the base model, these terms are calculated on the current task, thus they
do not guarantee broader knowledge. Meanwhile, commonly used experience replay
across heterogeneous domains makes it nontrivial to decide how much training
focus each objective should receive. To address this, we propose RECAP-a replay
strategy with dynamic objective reweighting for general knowledge preservation.
Our reweighting mechanism adapts in an online manner using short-horizon
signals of convergence and instability, shifting the post-training focus away
from saturated objectives and toward underperforming or volatile ones. Our
method is end-to-end and readily applicable to existing RLVR pipelines without
training additional models or heavy tuning. Extensive experiments on benchmarks
based on Qwen2.5-VL-3B and Qwen2.5-VL-7B demonstrate the effectiveness of our
method, which not only preserves general capabilities but also improves
reasoning by enabling more flexible trade-offs among in-task rewards.

</details>


### [611] [Boltzmann Graph Ensemble Embeddings for Aptamer Libraries](https://arxiv.org/abs/2510.21980)
*Starlika Bauskar,Jade Jiao,Narayanan Kannan,Alexander Kimm,Justin M. Baker,Matthew J. Tyler,Andrea L. Bertozzi,Anne M. Andrews*

Main category: cs.LG

TL;DR: 分子常被表示为相互作用图，但现有方法通常只考虑最小自由能结构。本文提出了一种基于Boltzmann权重的多图模型，能更全面地表示分子构象集合。该模型在SELEX数据集上进行了评估，即使存在实验偏差（如PCR扩增或测序噪声），也能有效检测与配体亲和力相关的社区和子图，从而识别出低丰度的候选适配体，用于进一步的实验评估。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习方法在生物化学中通常将分子表示为相互作用图，并主要基于最小自由能结构进行预测。然而，这种方法忽略了分子在热力学平衡状态下的多构象集合，可能导致对适配体-配体亲和力的错误评估，尤其是在存在实验偏差的情况下。

Method: 提出了一种基于热力学参数化的指数族随机图（ERGM）嵌入方法，将分子建模为Boltzmann权重下的相互作用图集合，而非单一图。该方法能够处理包含实验偏差（如PCR扩增或测序噪声）的SELEX数据集，并通过社区检测和子图分析来解释适配体-配体亲和力。

Result: 在SELEX数据集上，该ERGM嵌入方法能够克服实验偏差的影响，准确地检测与适配体-配体亲和力相关的社区和子图，即使在观察到的丰度与实际结合强度存在差异时也能实现。

Conclusion: 所提出的ERGM嵌入方法能够稳健地识别适配体-配体亲和力，即使在存在偏差的观测数据中也是如此。该方法有望用于识别低丰度的适配体候选物，以供进一步的实验验证。

Abstract: Machine-learning methods in biochemistry commonly represent molecules as
graphs of pairwise intermolecular interactions for property and structure
predictions. Most methods operate on a single graph, typically the minimal free
energy (MFE) structure, for low-energy ensembles (conformations) representative
of structures at thermodynamic equilibrium. We introduce a thermodynamically
parameterized exponential-family random graph (ERGM) embedding that models
molecules as Boltzmann-weighted ensembles of interaction graphs. We evaluate
this embedding on SELEX datasets, where experimental biases (e.g., PCR
amplification or sequencing noise) can obscure true aptamer-ligand affinity,
producing anomalous candidates whose observed abundance diverges from their
actual binding strength. We show that the proposed embedding enables robust
community detection and subgraph-level explanations for aptamer ligand
affinity, even in the presence of biased observations. This approach may be
used to identify low-abundance aptamer candidates for further experimental
evaluation.

</details>


### [612] [Deep Learning on Real-World Graphs](https://arxiv.org/abs/2510.21994)
*Emanuele Rossi*

Main category: cs.LG

TL;DR: GNNs在现实世界图数据上的应用受到可扩展性、时间性、方向性、数据不完整性和结构不确定性等挑战的限制。本论文提出了一系列模型（SIGN、TGN、Dir-GNN、FP、NuGget）来解决这些问题，使得GNN能够应用于工业规模的图数据，例如社交和推荐系统。


<details>
  <summary>Details</summary>
Motivation: GNNs在图数据学习中发挥着核心作用，但其在实际应用中面临诸多挑战，如可扩展性、时间性、方向性、数据不完整性和结构不确定性。

Method: 提出了一系列模型，包括SIGN（用于可扩展图学习）、TGN（用于时序图）、Dir-GNN（用于有向和异质网络）、特征传播（FP，用于处理缺失节点特征）以及NuGget（用于博弈论结构推断）。

Result: 这些模型共同解决了GNN在实际应用中的局限性，弥合了学术界和工业界在图规模上的差距。

Conclusion: 通过解决GNN在可扩展性、时间性、方向性、数据不完整性和结构不确定性等方面的挑战，本论文使得GNN能够更广泛地应用于社交和推荐系统等实际领域。

Abstract: Graph Neural Networks (GNNs) have become a central tool for learning on
graph-structured data, yet their applicability to real-world systems remains
limited by key challenges such as scalability, temporality, directionality,
data incompleteness, and structural uncertainty. This thesis introduces a
series of models addressing these limitations: SIGN for scalable graph
learning, TGN for temporal graphs, Dir-GNN for directed and heterophilic
networks, Feature Propagation (FP) for learning with missing node features, and
NuGget for game-theoretic structural inference. Together, these contributions
bridge the gap between academic benchmarks and industrial-scale graphs,
enabling the use of GNNs in domains such as social and recommender systems.

</details>


### [613] [Is Temporal Difference Learning the Gold Standard for Stitching in RL?](https://arxiv.org/abs/2510.21995)
*Michał Bortkiewicz,Władysław Pałucki,Mateusz Ostaszewski,Benjamin Eysenbach*

Main category: cs.LG

TL;DR: TD方法和MC方法在具有函数逼近的强化学习任务中都表现出经验缝合能力，但TD方法略优于MC方法。增加Critic容量可以缩小MC和TD方法的泛化差距。这表明在大型模型时代，TD方法的经验缝合归纳偏见可能不那么重要，而规模是实现泛化的关键。


<details>
  <summary>Details</summary>
Motivation: 研究在函数逼近的强化学习设置中，传统的关于TD方法比MC方法具有更好的经验缝合能力的观点是否成立。

Method: 通过实证研究，比较了TD方法和MC方法在具有函数逼近的强化学习任务中的经验缝合能力。

Result: MC方法也能实现经验缝合。TD方法略优于MC方法，但差距远小于网络大小带来的差距。增加Critic容量可以减小MC和TD方法的泛化差距。

Conclusion: 传统的TD归纳偏见在大型模型时代可能不那么必要，而规模是实现泛化的关键。经验缝合可以通过规模而非专门的算法（如TD学习）来实现。

Abstract: Reinforcement learning (RL) promises to solve long-horizon tasks even when
training data contains only short fragments of the behaviors. This experience
stitching capability is often viewed as the purview of temporal difference (TD)
methods. However, outside of small tabular settings, trajectories never
intersect, calling into question this conventional wisdom. Moreover, the common
belief is that Monte Carlo (MC) methods should not be able to recombine
experience, yet it remains unclear whether function approximation could result
in a form of implicit stitching. The goal of this paper is to empirically study
whether the conventional wisdom about stitching actually holds in settings
where function approximation is used. We empirically demonstrate that Monte
Carlo (MC) methods can also achieve experience stitching. While TD methods do
achieve slightly stronger capabilities than MC methods (in line with
conventional wisdom), that gap is significantly smaller than the gap between
small and large neural networks (even on quite simple tasks). We find that
increasing critic capacity effectively reduces the generalization gap for both
the MC and TD methods. These results suggest that the traditional TD inductive
bias for stitching may be less necessary in the era of large models for RL and,
in some cases, may offer diminishing returns. Additionally, our results suggest
that stitching, a form of generalization unique to the RL setting, might be
achieved not through specialized algorithms (temporal difference learning) but
rather through the same recipe that has provided generalization in other
machine learning settings (via scale). Project website:
https://michalbortkiewicz.github.io/golden-standard/

</details>


### [614] [From Black-box to Causal-box: Towards Building More Interpretable Models](https://arxiv.org/abs/2510.21998)
*Inwoo Hwang,Yushu Pan,Elias Bareinboim*

Main category: cs.LG

TL;DR: 深度学习模型的可解释性是一个挑战，本文提出了因果可解释性的概念，并提出了一种构建因果可解释模型的设计框架，在可解释性和预测准确性之间取得了权衡。


<details>
  <summary>Details</summary>
Motivation: 理解深度学习模型的预测结果，特别是在高风险应用中，是一个核心挑战。因果可解释性旨在通过反事实推理来洞察模型的决策过程。

Method: 本文形式化了因果可解释性的概念，分析了黑盒和基于概念的预测器，并提出了一个图形化标准来确定模型架构是否支持反事实查询。在此基础上，推导了在因果可解释性和预测准确性之间的权衡，并确定了在保持可解释性的前提下最大化预测表达能力的特征集。

Result: 分析表明，黑盒和基于概念的预测器通常不具备因果可解释性。所提出的框架可以构建因果可解释的模型，并在理论和实验上证明了因果可解释性与预测准确性之间存在根本性的权衡。

Conclusion: 本文形式化了因果可解释性的概念，并提供了一种构建因果可解释模型的设计方法，该方法能够在可解释性和预测准确性之间取得最优的权衡。

Abstract: Understanding the predictions made by deep learning models remains a central
challenge, especially in high-stakes applications. A promising approach is to
equip models with the ability to answer counterfactual questions --
hypothetical ``what if?'' scenarios that go beyond the observed data and
provide insight into a model reasoning. In this work, we introduce the notion
of causal interpretability, which formalizes when counterfactual queries can be
evaluated from a specific class of models and observational data. We analyze
two common model classes -- blackbox and concept-based predictors -- and show
that neither is causally interpretable in general. To address this gap, we
develop a framework for building models that are causally interpretable by
design. Specifically, we derive a complete graphical criterion that determines
whether a given model architecture supports a given counterfactual query. This
leads to a fundamental tradeoff between causal interpretability and predictive
accuracy, which we characterize by identifying the unique maximal set of
features that yields an interpretable model with maximal predictive
expressiveness. Experiments corroborate the theoretical findings.

</details>


### [615] [Optimal Detection for Language Watermarks with Pseudorandom Collision](https://arxiv.org/abs/2510.22007)
*T. Tony Cai,Xiang Li,Qi Long,Weijie J. Su,Garrett G. Wen*

Main category: cs.LG

TL;DR: 现有文本水印方法在处理LLM生成文本中的重复现象时存在不足，本文提出了一种新的统计框架来解决此问题。


<details>
  <summary>Details</summary>
Motivation: 现有文本水印方法假设生成文本具有完美的伪随机性，但实际LLM生成文本中的重复现象会导致统计碰撞，影响水印的有效性。

Method: 提出一个分层两层分区统计框架，定义了最小单元的概念，并将水印检测视为一个最小最大假设检验问题。

Result: 为Gumbel-max和逆变换水印生成了最优检测规则，并解释了丢弃重复统计量为何能提高性能，同时强调了必须处理单元内依赖性。

Conclusion: 该框架为在不完美伪随机性下进行水印检测提供了首个原则性基础，提高了检测能力，并严格控制了第一类错误率，为模型输出追踪提供了理论和实践指导。

Abstract: Text watermarking plays a crucial role in ensuring the traceability and
accountability of large language model (LLM) outputs and mitigating misuse.
While promising, most existing methods assume perfect pseudorandomness. In
practice, repetition in generated text induces collisions that create
structured dependence, compromising Type I error control and invalidating
standard analyses.
  We introduce a statistical framework that captures this structure through a
hierarchical two-layer partition. At its core is the concept of minimal units
-- the smallest groups treatable as independent across units while permitting
dependence within. Using minimal units, we define a non-asymptotic efficiency
measure and cast watermark detection as a minimax hypothesis testing problem.
  Applied to Gumbel-max and inverse-transform watermarks, our framework
produces closed-form optimal rules. It explains why discarding repeated
statistics often improves performance and shows that within-unit dependence
must be addressed unless degenerate. Both theory and experiments confirm
improved detection power with rigorous Type I error control. These results
provide the first principled foundation for watermark detection under imperfect
pseudorandomness, offering both theoretical insight and practical guidance for
reliable tracing of model outputs.

</details>


### [616] [A Multimodal Human Protein Embeddings Database: DeepDrug Protein Embeddings Bank (DPEB)](https://arxiv.org/abs/2510.22008)
*Md Saiful Islam Sajol,Magesh Rajasekaran,Hayden Gemeinhardt,Adam Bess,Chris Alvin,Supratik Mukhopadhyay*

Main category: cs.LG

TL;DR: DPEB是一个包含四种嵌入类型（AlphaFold2结构、BioEmbeddings序列、ESM-2上下文模式、ProtVec n-gram统计）的蛋白质数据集，旨在解决计算蛋白质-蛋白质相互作用（PPI）预测中缺乏多模态表示的问题。


<details>
  <summary>Details</summary>
Motivation: 计算蛋白质-蛋白质相互作用（PPI）预测面临挑战，因为缺乏集成的、多模态的蛋白质表示。

Method: DPEB整合了四种嵌入类型：AlphaFold2结构嵌入、BioEmbeddings序列嵌入、ESM-2上下文氨基酸模式嵌入和ProtVec序列n-gram统计嵌入。在基准评估中，使用了GraphSAGE模型。

Result: GraphSAGE结合BioEmbedding在PPI预测方面表现最佳，AUROC达到87.37%，准确率为79.16%。该框架在酶分类任务中准确率为77.42%，在蛋白质家族分类任务中准确率为86.04%。

Conclusion: DPEB通过提供AlphaFold2嵌入和其他多模态表示，支持多种图神经网络方法进行PPI预测，并可应用于系统生物学、药物靶点识别、通路分析和疾病机制研究等领域。

Abstract: Computationally predicting protein-protein interactions (PPIs) is challenging
due to the lack of integrated, multimodal protein representations. DPEB is a
curated collection of 22,043 human proteins that integrates four embedding
types: structural (AlphaFold2), transformer-based sequence (BioEmbeddings),
contextual amino acid patterns (ESM-2: Evolutionary Scale Modeling), and
sequence-based n-gram statistics (ProtVec]). AlphaFold2 protein structures are
available through public databases (e.g., AlphaFold2 Protein Structure
Database), but the internal neural network embeddings are not. DPEB addresses
this gap by providing AlphaFold2-derived embeddings for computational modeling.
Our benchmark evaluations show GraphSAGE with BioEmbedding achieved the highest
PPI prediction performance (87.37% AUROC, 79.16% accuracy). The framework also
achieved 77.42% accuracy for enzyme classification and 86.04% accuracy for
protein family classification. DPEB supports multiple graph neural network
methods for PPI prediction, enabling applications in systems biology, drug
target identification, pathway analysis, and disease mechanism studies.

</details>


### [617] [Cost-Sensitive Evaluation for Binary Classifiers](https://arxiv.org/abs/2510.22016)
*Pierangelo Lombardo,Antonio Casoli,Cristian Cingolani,Shola Oshodi,Michele Zanatta*

Main category: cs.LG

TL;DR: 选择合适的评估指标对于分类器至关重要，但目前尚无普遍接受的标准指标。本文提出了加权准确率（WA）作为一种新的评估指标，它可以直接解释为加权准确率，并与最小化总分类成本（TCC）的目标保持一致。该框架还可以应用于任何可以表示为示例相关量线性组合的度量，并允许在不同数据集之间进行比较，以及解决开发数据集和目标数据集之间的差异。最后，提出了一种在没有完全指定TCC的情况下估计WA权重参数的方法，并通过分析其与TCC的相关性来证明WA的稳健性。


<details>
  <summary>Details</summary>
Motivation: 分类器评估指标的选择和数据集不平衡的处理是模型比较和优化中的关键问题，但目前缺乏统一的标准和清晰的理论指导。

Method: 提出了一种名为加权准确率（WA）的新评估指标，它是一种加权准确率，与最小化总分类成本（TCC）的目标一致。构建了一个概念框架来处理成本敏感场景下的类别不平衡问题，并提出了一个估计WA权重参数的程序。

Result: WA提供了一种具有直接解释性的评估方法，并与最小化TCC的目标保持一致。所提出的框架可以处理类别不平衡问题，并能应用于多种评估指标。该方法还能够解决开发数据集和目标数据集之间的差异。

Conclusion: 加权准确率（WA）为二元分类器提供了一种新的、直观的评估指标，并与最小化总分类成本（TCC）的目标保持一致。所提出的概念框架为处理成本敏感场景下的类别不平衡问题提供了一个替代方案，并能应用于多种指标。此外，还提出了一种估计WA权重参数的方法，并证明了WA的稳健性。

Abstract: Selecting an appropriate evaluation metric for classifiers is crucial for
model comparison and parameter optimization, yet there is not consensus on a
universally accepted metric that serves as a definitive standard. Moreover,
there is often a misconception about the perceived need to mitigate imbalance
in datasets used to train classification models. Since the final goal in
classifier optimization is typically maximizing the return of investment or,
equivalently, minimizing the Total Classification Cost (TCC), we define
Weighted Accuracy (WA), an evaluation metric for binary classifiers with a
straightforward interpretation as a weighted version of the well-known accuracy
metric, coherent with the need of minimizing TCC. We clarify the conceptual
framework for handling class imbalance in cost-sensitive scenarios, providing
an alternative to rebalancing techniques. This framework can be applied to any
metric that, like WA, can be expressed as a linear combination of
example-dependent quantities and allows for comparing the results obtained in
different datasets and for addressing discrepancies between the development
dataset, used to train and validate the model, and the target dataset, where
the model will be deployed. It also specifies in which scenarios using
UCCs-unaware class rebalancing techniques or rebalancing metrics aligns with
TCC minimization and when it is instead counterproductive. Finally, we propose
a procedure to estimate the WA weight parameter in the absence of fully
specified UCCs and demonstrate the robustness of WA by analyzing its
correlation with TCC in example-dependent scenarios.

</details>


### [618] [LLM Meets Diffusion: A Hybrid Framework for Crystal Material Generation](https://arxiv.org/abs/2510.23040)
*Subhojyoti Khastagir,Kishalay Das,Pawan Goyal,Seung-Cheol Lee,Satadeep Bhattacharjee,Niloy Ganguly*

Main category: cs.LG

TL;DR: CrysLLMGen是一个结合大语言模型（LLM）和扩散模型的混合框架，用于生成周期性晶体结构。它克服了单独使用LLM（难以处理连续特征）或扩散模型（难以处理离散原子类型）的局限性。


<details>
  <summary>Details</summary>
Motivation: 填补现有生成模型在处理离散原子类型和连续结构特征方面的空白，以更全面地生成晶体结构。

Method: 首先使用微调后的大语言模型生成包含原子类型、原子坐标和晶格结构的中间表示，然后保留原子类型，将原子坐标和晶格结构传递给预训练的等变扩散模型进行优化。

Result: 在多个基准任务和数据集上，CrysLLMGen在结构和成分有效性方面取得了平衡的性能，并且比现有的基于LLM或基于扩散的模型生成更稳定、更新颖的材料。此外，它还具备强大的条件生成能力，能满足用户定义的约束。

Conclusion: CrysLLMGen通过结合LLM和扩散模型的优势，在晶体材料生成方面取得了优于现有方法的性能，并在稳定性、新颖性和条件生成能力方面表现出色。

Abstract: Recent advances in generative modeling have shown significant promise in
designing novel periodic crystal structures. Existing approaches typically rely
on either large language models (LLMs) or equivariant denoising models, each
with complementary strengths: LLMs excel at handling discrete atomic types but
often struggle with continuous features such as atomic positions and lattice
parameters, while denoising models are effective at modeling continuous
variables but encounter difficulties in generating accurate atomic
compositions. To bridge this gap, we propose CrysLLMGen, a hybrid framework
that integrates an LLM with a diffusion model to leverage their complementary
strengths for crystal material generation. During sampling, CrysLLMGen first
employs a fine-tuned LLM to produce an intermediate representation of atom
types, atomic coordinates, and lattice structure. While retaining the predicted
atom types, it passes the atomic coordinates and lattice structure to a
pre-trained equivariant diffusion model for refinement. Our framework
outperforms state-of-the-art generative models across several benchmark tasks
and datasets. Specifically, CrysLLMGen not only achieves a balanced performance
in terms of structural and compositional validity but also generates more
stable and novel materials compared to LLM-based and denoisingbased models
Furthermore, CrysLLMGen exhibits strong conditional generation capabilities,
effectively producing materials that satisfy user-defined constraints. Code is
available at https://github.com/kdmsit/crysllmgen

</details>


### [619] [Normalization in Attention Dynamics](https://arxiv.org/abs/2510.22026)
*Nikita Karagodin,Shu Ge,Yury Polyanskiy,Philippe Rigollet*

Main category: cs.LG

TL;DR: Normalization schemes in deep transformers regulate token representations by influencing clustering and collapse dynamics, with Peri-LN identified as effective.


<details>
  <summary>Details</summary>
Motivation: The paper studies the effect of various normalization schemes on token representations in deep transformers.

Method: The study models the evolution of token representations as interacting particles on a sphere, analyzing normalization as speed regulation to understand its influence on clustering dynamics and representation collapse. It unifies the analysis of Post-LN, Pre-LN, Mix-LN, Peri-LN, nGPT, and LN-Scaling schemes.

Result: The analysis reveals how different normalization schemes shape token representations across layers and provides a basis for comparison, highlighting Peri-LN as a particularly effective scheme.

Conclusion: Normalization schemes act as speed regulators for token representations in deep transformers, influencing their dynamics and potentially preventing collapse. Peri-LN demonstrates superior effectiveness compared to other schemes analyzed.

Abstract: We study the effect of normalization schemes on token representations in deep
transformers. Modeling their evolution as interacting particles on the sphere,
we show that normalization acts as a form of speed regulation. This perspective
enables a unified analysis of several schemes -- including Post-LN, Pre-LN,
Mix-LN, Peri-LN, nGPT, and LN-Scaling -- revealing how they influence
clustering dynamics and representation collapse. Our framework clarifies how
different schemes shape token representations across layers and provides a
principled basis for comparing them, identifying Peri-LN as a particularly
effective choice.

</details>


### [620] [Online Optimization for Offline Safe Reinforcement Learning](https://arxiv.org/abs/2510.22027)
*Yassine Chemingui,Aryan Deshwal,Alan Fern,Thanh Nguyen-Tang,Janardhan Rao Doppa*

Main category: cs.LG

TL;DR: 本研究提出了一种新的离线安全强化学习（OSRL）方法，通过将问题构建为最小-最大目标，并结合离线强化学习和在线优化算法来解决。该方法在保证安全约束的同时，能获得高回报。


<details>
  <summary>Details</summary>
Motivation: 学习从固定数据中获得最大回报的策略，同时满足累积成本约束。

Method: 将OSRL问题构建为最小-最大目标，并结合离线强化学习和在线优化算法求解。提出了一种实用的近似方法，可与任何离线强化学习算法结合使用，无需离线策略评估。

Result: 在DSRL基准测试中，该方法在严格的成本预算下能够可靠地执行安全约束，并获得高回报。

Conclusion: 所提出的方法能够有效地解决离线安全强化学习问题，并在保证安全性的前提下实现高回报。

Abstract: We study the problem of Offline Safe Reinforcement Learning (OSRL), where the
goal is to learn a reward-maximizing policy from fixed data under a cumulative
cost constraint. We propose a novel OSRL approach that frames the problem as a
minimax objective and solves it by combining offline RL with online
optimization algorithms. We prove the approximate optimality of this approach
when integrated with an approximate offline RL oracle and no-regret online
optimization. We also present a practical approximation that can be combined
with any offline RL algorithm, eliminating the need for offline policy
evaluation. Empirical results on the DSRL benchmark demonstrate that our method
reliably enforces safety constraints under stringent cost budgets, while
achieving high rewards. The code is available at
https://github.com/yassineCh/O3SRL.

</details>


### [621] [Differentiable Constraint-Based Causal Discovery](https://arxiv.org/abs/2510.22031)
*Jincheng Zhou,Mengbo Wang,Anqi He,Yumeng Zhou,Hessam Olya,Murat Kocaoglu,Bruno Ribeiro*

Main category: cs.LG

TL;DR: 本研究提出了一种新的因果发现方法，通过可微的d-分离得分和基于梯度的优化，在小样本情况下表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有的因果发现方法（基于约束或基于评分）各有局限性。基于约束的方法在小样本时性能不佳，而基于评分的方法则忽略了条件独立性检验。本研究旨在探索第三种方法，即开发可微的d-分离得分。

Method: 利用渗流理论和软逻辑，开发了可微的d-分离得分，并实现了基于梯度优化的条件独立性约束。

Result: 该方法在小样本情况下表现稳健，并在真实世界数据集上超越了传统的基于约束和基于评分的方法。

Conclusion: 本研究提出的基于可微d-分离得分和梯度优化的因果发现方法，尤其在小样本数据上具有优势，为因果发现提供了新的方向。

Abstract: Causal discovery from observational data is a fundamental task in artificial
intelligence, with far-reaching implications for decision-making, predictions,
and interventions. Despite significant advances, existing methods can be
broadly categorized as constraint-based or score-based approaches.
Constraint-based methods offer rigorous causal discovery but are often hindered
by small sample sizes, while score-based methods provide flexible optimization
but typically forgo explicit conditional independence testing. This work
explores a third avenue: developing differentiable $d$-separation scores,
obtained through a percolation theory using soft logic. This enables the
implementation of a new type of causal discovery method: gradient-based
optimization of conditional independence constraints. Empirical evaluations
demonstrate the robust performance of our approach in low-sample regimes,
surpassing traditional constraint-based and score-based baselines on a
real-world dataset. Code and data of the proposed method are publicly available
at https://github$.$com/PurdueMINDS/DAGPA.

</details>


### [622] [Linearized Optimal Transport for Analysis of High-Dimensional Point-Cloud and Single-Cell Data](https://arxiv.org/abs/2510.22033)
*Tianxiang Wang,Yingtong Ke,Dhananjay Bhaskar,Smita Krishnaswamy,Alexander Cloninger*

Main category: cs.LG

TL;DR: 该研究提出使用线性最优传输（LOT）框架来处理单细胞数据，将高维点云数据嵌入到固定维度的欧几里得空间中，以解决现有方法的不足。


<details>
  <summary>Details</summary>
Motivation: 现有单细胞技术生成的点云数据难以直接量化和比较个体间的生物学差异，且非线性方法缺乏可解释性。

Method: 将线性最优传输（LOT）框架应用于单细胞数据，将不规则的点云嵌入到固定维度的欧几里得空间中，以保持分布结构。

Result: LOT框架可以实现准确且可解释的COVID-19患者状态分类，分类器权重可追溯到具体的标记物和空间区域；还可以生成患者来源的类器官的合成数据；LOT barycenters可用于生成代表组合条件或样本的平均细胞谱，支持药物相互作用测试。

Conclusion: LOT框架能够整合预测性能、可解释性和生成模型，将异构点云转化为可追溯到原始数据的结构化嵌入，为理解高维生物系统中的免疫变异和治疗效果提供了新的机会。

Abstract: Single-cell technologies generate high-dimensional point clouds of cells,
enabling detailed characterization of complex patient states and treatment
responses. Yet each patient is represented by an irregular point cloud rather
than a simple vector, making it difficult to directly quantify and compare
biological differences between individuals. Nonlinear methods such as kernels
and neural networks achieve predictive accuracy but act as black boxes,
offering little biological interpretability.
  To address these limitations, we adapt the Linear Optimal Transport (LOT)
framework to this setting, embedding irregular point clouds into a
fixed-dimensional Euclidean space while preserving distributional structure.
This embedding provides a principled linear representation that preserves
optimal transport geometry while enabling downstream analysis. It also forms a
registration between any two patients, enabling direct comparison of their
cellular distributions. Within this space, LOT enables: (i) \textbf{accurate
and interpretable classification} of COVID-19 patient states, where classifier
weights map back to specific markers and spatial regions driving predictions;
and (ii) \textbf{synthetic data generation} for patient-derived organoids,
exploiting the linearity of the LOT embedding. LOT barycenters yield averaged
cellular profiles representing combined conditions or samples, supporting drug
interaction testing.
  Together, these results establish LOT as a unified framework that bridges
predictive performance, interpretability, and generative modeling. By
transforming heterogeneous point clouds into structured embeddings directly
traceable to the original data, LOT opens new opportunities for understanding
immune variation and treatment effects in high-dimensional biological systems.

</details>


### [623] [Fast Non-Log-Concave Sampling under Nonconvex Equality and Inequality Constraints with Landing](https://arxiv.org/abs/2510.22044)
*Kijung Jeon,Michael Muehlebach,Molei Tao*

Main category: cs.LG

TL;DR: OLLA是一个新的框架，可以处理等式和不等式约束的欠阻尼 Langevin 动力学，其通过确定性地沿约束曲面法线方向校正轨迹来避免显式投影，并具有指数级收敛性。


<details>
  <summary>Details</summary>
Motivation: 现有处理非凸约束集的欠阻尼 Langevin 算法通常需要代价高昂的投影步骤，且无法同时处理等式和不等式约束，并常常缺乏严格的收敛性保证。

Method: 提出了一种名为 OLLA 的新框架，该框架设计了能够同时适应等式和不等式约束的欠阻尼 Langevin 动力学。该动力学通过确定性地沿约束曲面法线方向校正轨迹来避免显式投影。

Result: 证明了在目标密度和约束集满足适当正则性条件下，OLLA 在 $W_2$ 距离上可指数级收敛到约束目标密度。实验表明，OLLA 相较于基于投影的约束 Langevin 算法及其松弛变量变体，在计算成本和经验混合方面具有优势。

Conclusion: OLLA 框架能够有效地处理等式和不等式约束，避免了昂贵的投影步骤，并提供了严格的收敛性保证，在实际应用中表现出优于现有方法的性能。

Abstract: Sampling from constrained statistical distributions is a fundamental task in
various fields including Bayesian statistics, computational chemistry, and
statistical physics. This article considers the cases where the constrained
distribution is described by an unconstrained density, as well as additional
equality and/or inequality constraints, which often make the constraint set
nonconvex. Existing methods for nonconvex constraint set $\Sigma \subset
\mathbb{R}^d$ defined by equality or inequality constraints commonly rely on
costly projection steps. Moreover, they cannot handle equality and inequality
constraints simultaneously as each method only specialized in one case. In
addition, rigorous and quantitative convergence guarantee is often lacking. In
this paper, we introduce Overdamped Langevin with LAnding (OLLA), a new
framework that can design overdamped Langevin dynamics accommodating both
equality and inequality constraints. The proposed dynamics also
deterministically corrects trajectories along the normal direction of the
constraint surface, thus obviating the need for explicit projections. We show
that, under suitable regularity conditions on the target density and $\Sigma$,
OLLA converges exponentially fast in $W_2$ distance to the constrained target
density $\rho_\Sigma(x) \propto \exp(-f(x))d\sigma_\Sigma$. Lastly, through
experiments, we demonstrate the efficiency of OLLA compared to projection-based
constrained Langevin algorithms and their slack variable variants, highlighting
its favorable computational cost and reasonable empirical mixing.

</details>


### [624] [PF$Δ$: A Benchmark Dataset for Power Flow under Load, Generation, and Topology Variations](https://arxiv.org/abs/2510.22048)
*Ana K. Rivera,Anvita Bhagavathula,Alvaro Carbonero,Priya Donti*

Main category: cs.LG

TL;DR: 该论文提出了一个名为PFΔ的数据集，用于评估电力系统潮流计算的性能，并对传统求解器和基于GNN的方法进行了基准测试。


<details>
  <summary>Details</summary>
Motivation: 传统的潮流计算在实时电网运行中面临计算瓶颈，尤其是在处理大量场景和可再生能源集成带来的不确定性时。需要更高效、准确的模拟工具。

Method: 创建了一个包含859,800个已解潮流实例的PFΔ数据集，涵盖不同规模的系统、多种故障场景（N，N-1，N-2）以及接近极限的工况。使用该数据集评估了传统求解器和基于GNN的方法。

Result: 评估结果揭示了现有方法在处理PFΔ数据集时的局限性，并指出了未来研究的方向。

Conclusion: PFΔ数据集为评估和改进电力系统潮流计算方法提供了基准，尤其是在应对实际运行中的复杂性和不确定性方面。

Abstract: Power flow (PF) calculations are the backbone of real-time grid operations,
across workflows such as contingency analysis (where repeated PF evaluations
assess grid security under outages) and topology optimization (which involves
PF-based searches over combinatorially large action spaces). Running these
calculations at operational timescales or across large evaluation spaces
remains a major computational bottleneck. Additionally, growing uncertainty in
power system operations from the integration of renewables and climate-induced
extreme weather also calls for tools that can accurately and efficiently
simulate a wide range of scenarios and operating conditions. Machine learning
methods offer a potential speedup over traditional solvers, but their
performance has not been systematically assessed on benchmarks that capture
real-world variability. This paper introduces PF$\Delta$, a benchmark dataset
for power flow that captures diverse variations in load, generation, and
topology. PF$\Delta$ contains 859,800 solved power flow instances spanning six
different bus system sizes, capturing three types of contingency scenarios (N ,
N -1, and N -2), and including close-to-infeasible cases near steady-state
voltage stability limits. We evaluate traditional solvers and GNN-based
methods, highlighting key areas where existing approaches struggle, and
identifying open problems for future research. Our dataset is available at
https://huggingface.co/datasets/pfdelta/pfdelta/tree/main and our code with
data generation scripts and model implementations is at
https://github.com/MOSSLab-MIT/pfdelta.

</details>


### [625] [Automatic Assessment of Students' Classroom Engagement with Bias Mitigated Multi-task Model](https://arxiv.org/abs/2510.22057)
*James Thiering,Tarun Sethupat Radha Krishna,Dylan Zelkin,Ashis Kumer Biswas*

Main category: cs.LG

TL;DR: 本研究提出了一种自动化系统来检测在线学习中的学生参与度，并采用一种新颖的培训方法来防止模型利用性别等敏感特征进行预测。


<details>
  <summary>Details</summary>
Motivation: 随着在线和虚拟学习的兴起，监控和提高学生参与度已成为有效教育的重要方面。传统评估方法可能不适用于虚拟环境，因此需要开发自动化系统来检测在线学习中的学生参与度。

Method: 提出了一种新的培训方法，该方法通过将属性正交正则化技术应用于拆分模型分类器，并结合多种迁移学习策略，以减少预测中敏感特征组的分布差异。

Result: 通过将 Pearson 相关系数从未缓解模型的 0.897 降低到缓解模型的 0.999，成功减少了预测中的差异。

Conclusion: 所提出的方法不仅能强制执行道德标准，还能提高模型预测的可解释性，并有效检测在线学习中的学生参与度。

Abstract: With the rise of online and virtual learning, monitoring and enhancing
student engagement have become an important aspect of effective education.
Traditional methods of assessing a student's involvement might not be
applicable directly to virtual environments. In this study, we focused on this
problem and addressed the need to develop an automated system to detect student
engagement levels during online learning. We proposed a novel training method
which can discourage a model from leveraging sensitive features like gender for
its predictions. The proposed method offers benefits not only in the
enforcement of ethical standards, but also to enhance interpretability of the
model predictions. We applied an attribute-orthogonal regularization technique
to a split-model classifier, which uses multiple transfer learning strategies
to achieve effective results in reducing disparity in the distribution of
prediction for sensitivity groups from a Pearson correlation coefficient of
0.897 for the unmitigated model, to 0.999 for the mitigated model. The source
code for this project is available on
https://github.com/ashiskb/elearning-engagement-study .

</details>


### [626] [Pruning and Quantization Impact on Graph Neural Networks](https://arxiv.org/abs/2510.22058)
*Khatoon Khedri,Reza Rawassizadeh,Qifu Wen,Mehdi Hosseinzadeh*

Main category: cs.LG

TL;DR: 图神经网络（GNNs）在图结构数据学习方面精度高，但计算和资源成本高。本研究通过剪枝和量化技术，在不同GNN模型、任务（图分类、节点分类、链接预测）和数据集（Cora, Proteins, BBBP）上进行了实证检验。


<details>
  <summary>Details</summary>
Motivation: GNNs精度高但计算和资源成本高，需要模型压缩技术来降低模型大小并保持精度。

Method: 研究了三种剪枝方法和三种量化方法对不同GNN模型（图分类、节点分类、链接预测）在Cora、Proteins和BBBP三个数据集上的效果。

Result: 全局非结构化细粒度剪枝可显著减小模型大小（50%），且微调后精度保持不变甚至提高。不同的量化方法对GNN的精度、推理时间和模型大小有不同影响。

Conclusion: 剪枝和量化是有效的GNN模型压缩技术，其中全局非结构化细粒度剪枝效果显著。量化方法的效果因具体方法和数据集而异。

Abstract: Graph neural networks (GNNs) are known to operate with high accuracy on
learning from graph-structured data, but they suffer from high computational
and resource costs. Neural network compression methods are used to reduce the
model size while maintaining reasonable accuracy. Two of the common neural
network compression techniques include pruning and quantization. In this
research, we empirically examine the effects of three pruning methods and three
quantization methods on different GNN models, including graph classification
tasks, node classification tasks, and link prediction. We conducted all
experiments on three graph datasets, including Cora, Proteins, and BBBP. Our
findings demonstrate that unstructured fine-grained and global pruning can
significantly reduce the model's size(50\%) while maintaining or even improving
precision after fine-tuning the pruned model. The evaluation of different
quantization methods on GNN shows diverse impacts on accuracy, inference time,
and model size across different datasets.

</details>


### [627] [Deep Gaussian Processes for Functional Maps](https://arxiv.org/abs/2510.22068)
*Matthew Lowery,Zhitong Xu,Da Long,Keyan Chen,Daniel S. Johnson,Yang Bai,Varun Shankar,Shandian Zhe*

Main category: cs.LG

TL;DR: DGPFM是一种利用高斯过程（GP）进行函数映射的新方法，解决了现有方法在处理非线性和不确定性量化方面的不足，在预测性能和不确定性校准方面表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有函数-函数回归方法在捕捉复杂非线性和处理噪声、稀疏、不规则采样数据的不确定性量化方面存在不足。

Method: 提出了一种名为深度高斯过程函数映射（DGPFM）的新方法，该方法设计了一系列基于GP的线性和非线性变换，包括核积分变换、GP插值和从GP采样得到非线性激活。通过固定离散近似核积分变换，可以灵活地整合各种变换设计。为了实现可扩展的概率推理，我们开发了一种使用诱导点和白化变换的变分学习算法。

Result: 在真实世界和偏微分方程（PDE）基准数据集上的经验结果表明，DGPFM在预测性能和不确定性校准方面均优于现有方法。

Conclusion: DGPFM在处理函数-函数回归问题方面，尤其是在数据噪声、稀疏和不规则采样的情况下，能够更准确地捕捉非线性和进行不确定性量化。

Abstract: Learning mappings between functional spaces, also known as
function-on-function regression, plays a crucial role in functional data
analysis and has broad applications, e.g. spatiotemporal forecasting, curve
prediction, and climate modeling. Existing approaches, such as functional
linear models and neural operators, either fall short of capturing complex
nonlinearities or lack reliable uncertainty quantification under noisy, sparse,
and irregularly sampled data. To address these issues, we propose Deep Gaussian
Processes for Functional Maps (DGPFM). Our method designs a sequence of
GP-based linear and nonlinear transformations, leveraging integral transforms
of kernels, GP interpolation, and nonlinear activations sampled from GPs. A key
insight simplifies implementation: under fixed locations, discrete
approximations of kernel integral transforms collapse into direct functional
integral transforms, enabling flexible incorporation of various integral
transform designs. To achieve scalable probabilistic inference, we use inducing
points and whitening transformations to develop a variational learning
algorithm. Empirical results on real-world and PDE benchmark datasets
demonstrate that the advantage of DGPFM in both predictive performance and
uncertainty calibration.

</details>


### [628] [Neural Index Policies for Restless Multi-Action Bandits with Heterogeneous Budgets](https://arxiv.org/abs/2510.22069)
*Himadri S. Pandey,Kai Wang,Gian-Gabriel P. Garcia*

Main category: cs.LG

TL;DR: 该研究提出了一种用于具有异构预算约束的多动作失衡多臂老虎机（RMAB）的神经索引策略（NIP），该策略通过神经网络学习分配与预算相关的索引，并使用可微分背包层将它们转换为可行分配，在实践中实现了接近最优的性能。


<details>
  <summary>Details</summary>
Motivation: 现有RMAB框架在处理多干预、异构成本和约束的真实世界场景（如医疗保健）时存在局限性，因为它们通常只假设二元动作和单一全局预算。

Method: 提出了一种神经索引策略（NIP），它使用神经网络为 arm-action 对学习分配与预算相关的索引，并通过将背包问题表述为熵正则化最优传输（OT）问题来使用可微分背包层将其转换为可行分配。该模型将索引预测和约束优化统一在一个端到端的、可微分的框架中，从而可以直接对决策质量进行基于梯度的训练。该网络通过使诱导的占用测度与线性规划松弛的理论上限保持一致来优化，从而将渐近 RMAB 理论与实际学习联系起来。

Result: NIP 的经验性能接近最优，比理论最优占用测度策略仅低 5%，同时严格遵守异构预算约束，并且能够扩展到数百个臂。

Conclusion: 这项工作为在复杂的、资源受限的环境中学习基于索引的策略提供了一个通用、理论上合理且可扩展的框架。

Abstract: Restless multi-armed bandits (RMABs) provide a scalable framework for
sequential decision-making under uncertainty, but classical formulations assume
binary actions and a single global budget. Real-world settings, such as
healthcare, often involve multiple interventions with heterogeneous costs and
constraints, where such assumptions break down. We introduce a Neural Index
Policy (NIP) for multi-action RMABs with heterogeneous budget constraints. Our
approach learns to assign budget-aware indices to arm--action pairs using a
neural network, and converts them into feasible allocations via a
differentiable knapsack layer formulated as an entropy-regularized optimal
transport (OT) problem. The resulting model unifies index prediction and
constrained optimization in a single end-to-end differentiable framework,
enabling gradient-based training directly on decision quality. The network is
optimized to align its induced occupancy measure with the theoretical upper
bound from a linear programming relaxation, bridging asymptotic RMAB theory
with practical learning. Empirically, NIP achieves near-optimal performance
within 5% of the oracle occupancy-measure policy while strictly enforcing
heterogeneous budgets and scaling to hundreds of arms. This work establishes a
general, theoretically grounded, and scalable framework for learning
index-based policies in complex resource-constrained environments.

</details>


### [629] [MAGIC-Flow: Multiscale Adaptive Conditional Flows for Generation and Interpretable Classification](https://arxiv.org/abs/2510.22070)
*Luca Caldera,Giacomo Bottacini,Lara Cavinato*

Main category: cs.LG

TL;DR: MAGIC-Flow是一种条件多尺度归一化流模型，可用于医学影像的生成和分类，解决了现有生成模型在临床应用中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的生成模型缺乏任务对齐，难以满足临床需求，需要一种能够同时进行生成和分类的模型。

Method: 提出了一种条件多尺度归一化流（MAGIC-Flow）架构，该模型采用可逆和可微的映射构建，确保了精确的似然计算和稳定的优化，并通过条件化类别标签支持可控样本合成和类别概率估计。

Result: MAGIC-Flow在多个数据集上进行了评估，在生成和分类任务上均表现出色，能够生成逼真的、多样化的样本，并提高分类性能，尤其在扫描噪声和特定模态合成与识别方面。

Conclusion: MAGIC-Flow是一种有效的生成和分类策略，特别适用于数据有限的领域，在隐私保护数据增强、鲁棒泛化和可信赖的医学人工智能方面具有直接优势。

Abstract: Generative modeling has emerged as a powerful paradigm for representation
learning, but its direct applicability to challenging fields like medical
imaging remains limited: mere generation, without task alignment, fails to
provide a robust foundation for clinical use. We propose MAGIC-Flow, a
conditional multiscale normalizing flow architecture that performs generation
and classification within a single modular framework. The model is built as a
hierarchy of invertible and differentiable bijections, where the Jacobian
determinant factorizes across sub-transformations. We show how this ensures
exact likelihood computation and stable optimization, while invertibility
enables explicit visualization of sample likelihoods, providing an
interpretable lens into the model's reasoning. By conditioning on class labels,
MAGIC-Flow supports controllable sample synthesis and principled
class-probability estimation, effectively aiding both generative and
discriminative objectives. We evaluate MAGIC-Flow against top baselines using
metrics for similarity, fidelity, and diversity. Across multiple datasets, it
addresses generation and classification under scanner noise, and
modality-specific synthesis and identification. Results show MAGIC-Flow creates
realistic, diverse samples and improves classification. MAGIC-Flow is an
effective strategy for generation and classification in data-limited domains,
with direct benefits for privacy-preserving augmentation, robust
generalization, and trustworthy medical AI.

</details>


### [630] [Agentic Reinforcement Learning for Real-World Code Repair](https://arxiv.org/abs/2510.22075)
*Siyu Zhu,Anastasiya Karpovich,Albert Chen,Jessica Koscheka,Shailesh Jannu,Di Wen,Yuqing Zhu,Rohit Jain,Alborz Geramifard*

Main category: cs.LG

TL;DR: 本研究提出了一个用于在真实代码库中训练可靠代码修复代理的可验证流水线，通过固定依赖关系和禁用自动升级来确保评估的稳定性，并在大约1000个真实问题上实现了可复现的成功。在此基础上，研究引入了一个简化的流水线用于大规模强化学习（RL）。


<details>
  <summary>Details</summary>
Motivation: 在真实的软件仓库中训练代码修复代理面临严峻的挑战，因为复杂的构建过程和不断变化的依赖关系导致评估结果不稳定，难以保证修复的可靠性。

Method: 研究提出了一种可验证的流水线，其成功标准是修复后能够通过构建验证，并通过固定依赖项和禁用自动升级来提高在约1000个真实问题上的可复现性。在此基础上，又设计了一个简化的流水线，用于大规模强化学习（RL）训练。研究将Qwen3-32B模型在该流水线中进行了监督微调（SFT），并在简化环境中对SFT模型进行了RL训练。SFT模型基于GPT-4.1的轨迹进行蒸馏。

Result: 基于GPT-4.1轨迹蒸馏的SFT模型，在性能相当的情况下，模型规模缩小了56倍。在匹配的训练-测试条件下，RL训练在SFT模型的基础上带来了7-20%的绝对性能提升。“思考模式”在实验中的表现相当或更差。SFT和RL模型均未能实现跨环境的泛化能力。

Conclusion: 在真实代码库中训练代码修复代理需要一个稳定且可复现的评估流水线。通过监督微调（SFT）和强化学习（RL）可以显著提升代码修复能力，但模型的泛化能力仍然有限，强调了在训练和测试中匹配环境的重要性。

Abstract: We tackle the challenge of training reliable code-fixing agents in real
repositories, where complex builds and shifting dependencies make evaluation
unstable. We developed a verifiable pipeline with success defined as post-fix
build validation and improved reproducibility across ~1K real issues by pinning
dependencies and disabling automatic upgrades. Building on this, we introduced
a scalable simplified pipeline for large-scale reinforcement learning (RL).
Using this setup, we supervised fine-tuned Qwen3-32B in the full pipeline and
applied RL on top of the SFT model in the simplified environment. The SFT model
distilled from GPT-4.1 trajectories performs on par while being 56x smaller,
and RL added 7-20% absolute gains under matched train-test conditions.
"Thinking mode" was on par or worse in our experiments. Both SFT and RL models
failed to generalize across environments, highlighting the importance of
matching train-test environments for building reliable real-world code-fixing
agents.

</details>


### [631] [Hierarchical Graph Networks for Accurate Weather Forecasting via Lightweight Training](https://arxiv.org/abs/2510.22094)
*Thomas Bailie,S. Karthik Mukkavilli,Varvara Vetrova,Yun Sing Koh*

Main category: cs.LG

TL;DR: HiFlowCast和HiAntFlow是嵌入物理学的多尺度预测HGNNs，通过保留全局趋势和集成PDE解场来提高天气预报的准确性和可靠性，尤其是在极端天气和长期预报方面。


<details>
  <summary>Details</summary>
Motivation: 现有的固定分辨率方法无法捕捉天气事件的多尺度动态，而现有的HGNNs在向下映射过程中会丢失全局趋势，削弱了物理学在预测中的作用。

Method: 提出了一种名为HiFlowCast（及其集合变体HiAntFlow）的HGNNs，该模型包含两个关键创新：1. 潜在记忆保留机制，用于在向下传播时保留全局趋势。2. 潜在到物理分支，用于集成跨尺度的PDE解场。

Result: HiFlowCast模型将13天预报提前量的误差减少了5%以上，在第1个和第99个百分位数极端情况下的误差减少了5-8%，提高了罕见事件的可靠性。模型在利用预训练权重时，可以在一个训练周期内收敛，从而降低了训练成本和碳足迹。

Conclusion: HiFlowCast和HiAntFlow通过嵌入物理学和多尺度预测框架，显著提高了天气预报的准确性和可靠性，尤其是在处理极端天气事件和长期预报方面。其高效的训练过程也解决了机器学习规模化带来的可持续性和可及性问题。

Abstract: Climate events arise from intricate, multivariate dynamics governed by
global-scale drivers, profoundly impacting food, energy, and infrastructure.
Yet, accurate weather prediction remains elusive due to physical processes
unfolding across diverse spatio-temporal scales, which fixed-resolution methods
cannot capture. Hierarchical Graph Neural Networks (HGNNs) offer a multiscale
representation, but nonlinear downward mappings often erase global trends,
weakening the integration of physics into forecasts. We introduce HiFlowCast
and its ensemble variant HiAntFlow, HGNNs that embed physics within a
multiscale prediction framework. Two innovations underpin their design: a
Latent-Memory-Retention mechanism that preserves global trends during downward
traversal, and a Latent-to-Physics branch that integrates PDE solution fields
across diverse scales. Our Flow models cut errors by over 5% at 13-day lead
times and by 5-8% under 1st and 99th quantile extremes, improving reliability
for rare events. Leveraging pretrained model weights, they converge within a
single epoch, reducing training cost and their carbon footprint. Such
efficiency is vital as the growing scale of machine learning challenges
sustainability and limits research accessibility. Code and model weights are in
the supplementary materials.

</details>


### [632] [Dynamic Graph Neural Network for Data-Driven Physiologically Based Pharmacokinetic Modeling](https://arxiv.org/abs/2510.22096)
*Su Liu,Xin Hu,Shurong Wen,Jiaqi Liu,Jiexi Xu,Lanruo Wang*

Main category: cs.LG

TL;DR: 基于深度学习的动态图神经网络在药物研发中用于PBPK预测，取得了比传统方法和基线模型更好的结果。


<details>
  <summary>Details</summary>
Motivation: 传统基于常微分方程的PBPK模型在处理非线性生理相互作用时存在局限性，需要更具适应性的数据驱动方法。

Method: 实现了一个多层感知机（MLP）和一个长短期记忆（LSTM）网络作为基线模型，并提出了一个动态图神经网络（Dynamic GNN）来模拟器官间的相互作用，将其视为循环消息传递过程。

Result: 动态图神经网络（Dynamic GNN）在预测中取得了最佳性能，R^2为0.9342，RMSE为0.0159，MAE为0.0116。MLP基线的R^2为0.8705，LSTM的R^2为0.8059。

Conclusion: 显式地模拟器官相互作用的空间和时间依赖性可以实现更准确、更通用的药物浓度预测。动态图神经网络（Dynamic GNN）为传统PBPK模型提供了一种可扩展、无需方程的数据驱动替代方案，在临床前和临床研究中具有巨大潜力。

Abstract: Physiologically Based Pharmacokinetic (PBPK) modeling plays a critical role
in drug development by predicting drug concentration dynamics across organs.
Traditional approaches rely on ordinary differential equations with strong
simplifying assumptions, which limit their adaptability to nonlinear
physiological interactions. In this study, we explore data-driven alternatives
for PBPK prediction using deep learning. Two baseline architectures - a
multilayer perceptron (MLP) and a long short-term memory (LSTM) network - are
implemented to capture molecular and temporal dependencies, respectively. To
incorporate inter-organ interactions, we propose a Dynamic Graph Neural Network
(Dynamic GNN) that models physiological connections as recurrent
message-passing processes between organs. Experimental results demonstrate that
the proposed Dynamic GNN achieves the highest predictive performance among all
models, with an R^2 of 0.9342, an RMSE of 0.0159, and an MAE of 0.0116. In
comparison, the MLP baseline obtains an R^2 of 0.8705 and the LSTM achieves
0.8059. These results highlight that explicitly modeling the spatial and
temporal dependencies of organ interactions enables more accurate and
generalizable drug concentration prediction. The Dynamic GNN provides a
scalable, equation-free alternative to traditional PBPK formulations and
demonstrates strong potential for data-driven pharmacokinetic modeling in
preclinical and clinical research.

</details>


### [633] [Learning 3D Anisotropic Noise Distributions Improves Molecular Force Field Modeling](https://arxiv.org/abs/2510.22123)
*Xixian Liu,Rui Jiao,Zhiyuan Liu,Yurou Liu,Yang Liu,Ziheng Lu,Wenbing Huang,Yang Zhang,Yixin Cao*

Main category: cs.LG

TL;DR: AniDS是一个新颖的3D分子去噪框架，使用各向异性变分自编码器来生成原子特定的高斯噪声，能够更好地模拟分子动力学，并在MD17和OC22基准测试中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的坐标去噪方法依赖于简化的分子动力学模拟，该模拟假设原子运动是各向同性的和同方差的。为了克服这些局限性，需要一种能够更好地反映分子系统方向性和结构可变性的去噪方法。

Method: AniDS框架引入了一个结构感知的各向异性噪声生成器，该生成器可以为高斯噪声分布生成原子特定的、全协方差矩阵，以更好地反映分子系统中的方向性和结构可变性。这些协方差是从成对原子相互作用中派生出来的，作为各向同性基底的各向异性校正。该设计确保了所得协方差矩阵是对称的、半正定的并且是SO(3)-等变的，同时提供了对复杂分子动力学建模的更大能力。

Result: AniDS在MD17和OC22基准测试中，在力预测精度方面平均相对提高了8.9%和6.2%，优于先前的各向同性和同方差去噪模型以及其他领先方法。在晶体和分子结构上的案例研究表明，AniDS能够沿着键合方向自适应地抑制噪声，这与物理化学原理一致。

Conclusion: AniDS通过引入各向异性噪声生成器，能够更准确地模拟分子动力学，并在3D分子预训练任务中取得了显著的性能提升。

Abstract: Coordinate denoising has emerged as a promising method for 3D molecular
pretraining due to its theoretical connection to learning molecular force
field. However, existing denoising methods rely on oversimplied molecular
dynamics that assume atomic motions to be isotropic and homoscedastic. To
address these limitations, we propose a novel denoising framework AniDS:
Anisotropic Variational Autoencoder for 3D Molecular Denoising. AniDS
introduces a structure-aware anisotropic noise generator that can produce
atom-specific, full covariance matrices for Gaussian noise distributions to
better reflect directional and structural variability in molecular systems.
These covariances are derived from pairwise atomic interactions as anisotropic
corrections to an isotropic base. Our design ensures that the resulting
covariance matrices are symmetric, positive semi-definite, and
SO(3)-equivariant, while providing greater capacity to model complex molecular
dynamics. Extensive experiments show that AniDS outperforms prior isotropic and
homoscedastic denoising models and other leading methods on the MD17 and OC22
benchmarks, achieving average relative improvements of 8.9% and 6.2% in force
prediction accuracy. Our case study on a crystal and molecule structure shows
that AniDS adaptively suppresses noise along the bonding direction, consistent
with physicochemical principles. Our code is available at
https://github.com/ZeroKnighting/AniDS.

</details>


### [634] [Efficient Utility-Preserving Machine Unlearning with Implicit Gradient Surgery](https://arxiv.org/abs/2510.22124)
*Shiji Zhou,Tianbai Yu,Zhi Zhang,Heng Chang,Xiao Zhou,Dong Wu,Han Zhao*

Main category: cs.LG

TL;DR: 机器学习模型能够高效地移除预训练模型中不需要的或有害的记忆。


<details>
  <summary>Details</summary>
Motivation: 现有的机器学习方法在移除不需要的记忆时，无法很好地平衡移除效果和模型原始性能之间的关系，导致移除效果不佳。

Method: 将机器学习模型视为一个约束优化问题，在保证模型性能损失可控的条件下，优化移除目标。通过单边梯度手术来解决上述优化问题，并提出一种隐式梯度手术方法，通过一次反向传播来逼近约束优化问题的解，从而实现高效的、保持模型性能的机器学习模型移除。

Result: 在理论上，该算法的收敛性得到了保证。在实践中，该算法在移除效果和模型性能的平衡方面优于现有基线方法。

Conclusion: 所提出的算法能够高效地移除预训练模型中的有害记忆，并保持模型的原始性能。

Abstract: Machine unlearning (MU) aims to efficiently remove sensitive or harmful
memory from a pre-trained model. The key challenge is to balance the potential
tradeoff between unlearning efficacy and utility preservation, which involves
forgetting undesirable information as defined while maintaining the model's
original performance. One potential way to tackle this problem is to use
multi-objective optimization to jointly optimize both the unlearning and
utility preservation objectives. However, existing multi-objective methods only
guarantee finding a Pareto-optimal solution without fine-grained control, which
causes under-optimization of the unlearning objective. To this end, we first
model MU as a constrained optimization problem, that is, optimizing the
unlearning objective under the constraint of a bounded increase for utility
loss. We then show that solving this optimization problem is equivalent to
unilateral gradient surgery on the unlearning objective. To resolve the
additional computational cost brought by gradient surgery, we propose an
implicit gradient surgery method, which approximates the solution to the
aforementioned constrained optimization problem via only one backpropagation,
thereby achieving efficient utility-preserving MU. Theoretically, we provide a
tight convergence analysis of the algorithm. Empirically, our extensive
experiments show that the proposed algorithm achieves better tradeoff results
than existing baselines. Codes are available at
https://github.com/anseryuer/EUPMU-Efficient-Utility-Preserving-Machine-Unlearning.

</details>


### [635] [Probing Neural Combinatorial Optimization Models](https://arxiv.org/abs/2510.22131)
*Zhiqin Zhang,Yining Ma,Zhiguang Cao,Hoong Chuin Lau*

Main category: cs.LG

TL;DR: 该论文首次尝试通过探测任务来解析神经组合优化（NCO）模型的内部机制，并提出了一种名为CS-Probing的新型探测工具，以深入分析模型表征。研究发现NCO模型既包含低级信息以构建解决方案，也包含高级知识以辅助决策。CS-Probing工具能够揭示不同NCO模型所携带的归纳偏置、模型泛化能力的关键因素以及与特定知识相关的嵌入维度。这些发现不仅加深了对NCO模型的理解，还为改进模型泛化能力提供了实践指导。


<details>
  <summary>Details</summary>
Motivation: 神经组合优化（NCO）模型的决策过程如同一个黑箱，阻碍了学术研究和实际应用，因为研究人员和利益相关者需要更深入地了解NCO模型。

Method: 提出了一种名为CS-Probing的新型探测工具，通过检查探测过程中的系数和统计显著性来深入分析NCO表征。进行了广泛的实验和分析。

Result: 研究发现NCO模型编码了构建解决方案所必需的低级信息，并捕获了促进更好决策的高级知识。CS-Probing工具揭示了普遍存在的NCO模型对其学习表征施加了不同的归纳偏置，发现了与模型泛化相关的直接证据，并识别了与特定知识相关的关键嵌入维度。这些见解可以转化为实践，例如通过对代码进行少量修改，可以提高所分析模型的泛化能力。

Conclusion: 这项工作代表了首次系统地尝试解释黑箱NCO模型，展示了探测作为分析其内部机制和为NCO社区揭示见解的有前途的工具。 源代码是公开的。

Abstract: Neural combinatorial optimization (NCO) has achieved remarkable performance,
yet its learned model representations and decision rationale remain a black
box. This impedes both academic research and practical deployment, since
researchers and stakeholders require deeper insights into NCO models. In this
paper, we take the first critical step towards interpreting NCO models by
investigating their representations through various probing tasks. Moreover, we
introduce a novel probing tool named Coefficient Significance Probing
(CS-Probing) to enable deeper analysis of NCO representations by examining the
coefficients and statistical significance during probing. Extensive experiments
and analysis reveal that NCO models encode low-level information essential for
solution construction, while capturing high-level knowledge to facilitate
better decisions. Using CS-Probing, we find that prevalent NCO models impose
varying inductive biases on their learned representations, uncover direct
evidence related to model generalization, and identify key embedding dimensions
associated with specific knowledge. These insights can be potentially
translated into practice, for example, with minor code modifications, we
improve the generalization of the analyzed model. Our work represents a first
systematic attempt to interpret black-box NCO models, showcasing probing as a
promising tool for analyzing their internal mechanisms and revealing insights
for the NCO community. The source code is publicly available.

</details>


### [636] [Robust Iterative Learning Hidden Quantum Markov Models](https://arxiv.org/abs/2510.23237)
*Ning Ning*

Main category: cs.LG

TL;DR: 该论文提出了一种名为AC-HQMM的新型量子模型，并开发了一种名为RILA的鲁棒学习算法，以解决现有HQMM算法对数据损坏和对抗性扰动敏感的问题。


<details>
  <summary>Details</summary>
Motivation: 现有HQMM学习算法对数据损坏和对抗性扰动高度敏感，缺乏鲁棒性。因此，需要开发一种能够处理受污染观测序列的鲁棒HQMM学习方法。

Method: 提出了一种名为AC-HQMM（对抗性污染隐蔽量子马尔可夫模型）的框架，并开发了一种名为RILA（鲁棒迭代学习算法）的学习算法。RILA采用无导数方法，结合了熵过滤模块（RCR-EF）和随机重采样程序，用于更新Kraus算子。此外，RILA还整合了L1正则化似然目标函数，以提高稳定性和抵抗过拟合。

Result: 在多个HQMM和HMM基准测试中，RILA相比现有算法表现出更优越的收敛稳定性、对污染的抵抗能力以及物理有效性的保持能力。

Conclusion: RILA为量子序列学习提供了一种原则性且高效的鲁棒方法，能够有效处理被对抗性污染的观测序列。

Abstract: Hidden Quantum Markov Models (HQMMs) extend classical Hidden Markov Models to
the quantum domain, offering a powerful probabilistic framework for modeling
sequential data with quantum coherence. However, existing HQMM learning
algorithms are highly sensitive to data corruption and lack mechanisms to
ensure robustness under adversarial perturbations. In this work, we introduce
the Adversarially Corrupted HQMM (AC-HQMM), which formalizes robustness
analysis by allowing a controlled fraction of observation sequences to be
adversarially corrupted. To learn AC-HQMMs, we propose the Robust Iterative
Learning Algorithm (RILA), a derivative-free method that integrates a Remove
Corrupted Rows by Entropy Filtering (RCR-EF) module with an iterative
stochastic resampling procedure for physically valid Kraus operator updates.
RILA incorporates L1-penalized likelihood objectives to enhance stability,
resist overfitting, and remain effective under non-differentiable conditions.
Across multiple HQMM and HMM benchmarks, RILA demonstrates superior convergence
stability, corruption resilience, and preservation of physical validity
compared to existing algorithms, establishing a principled and efficient
approach for robust quantum sequential learning.

</details>


### [637] [Tractable Shapley Values and Interactions via Tensor Networks](https://arxiv.org/abs/2510.22138)
*Farzaneh Heidari,Chao Li,Farzaneh Heidari*

Main category: cs.LG

TL;DR: TN-SHAP是一种利用张量网络（TN）替代方案，通过几次评估来取代Shapley值和Shapley风格交互指数的O(2^n)联盟枚举的方法，将预测器的局部行为表示为分解后的多线性映射，从而使联盟量成为系数张量的线性探测。


<details>
  <summary>Details</summary>
Motivation: 为了解决Shapley值和Shapley风格交互指数中存在的O(2^n)联盟枚举的计算复杂性问题。

Method: TN-SHAP将详尽的联盟扫描替换为少数几次有针对性的评估，以提取k阶Shapley交互。具体来说，1阶（单特征）和2阶（成对）计算的成本为O(n*poly(chi) + n^2)，其中chi是TN的最大截秩。对近似误差和TN-SHAP的可处理性提供了理论保证。

Result: 在UCI数据集上，TN-SHAP在拟合的替代方案上匹配枚举，同时将评估次数减少了几个数量级，并且在可比的准确性下，与KernelSHAP-IQ相比，实现了25-1000倍的实际运行时间加速，同时分摊了跨局部群的训练成本。

Conclusion: TN-SHAP通过利用张量网络提供了一种计算Shapley值和交互指数的有效方法，大大减少了计算复杂性，并在实际应用中实现了显著的加速。

Abstract: We show how to replace the O(2^n) coalition enumeration over n features
behind Shapley values and Shapley-style interaction indices with a
few-evaluation scheme on a tensor-network (TN) surrogate: TN-SHAP. The key idea
is to represent a predictor's local behavior as a factorized multilinear map,
so that coalitional quantities become linear probes of a coefficient tensor.
TN-SHAP replaces exhaustive coalition sweeps with just a small number of
targeted evaluations to extract order-k Shapley interactions. In particular,
both order-1 (single-feature) and order-2 (pairwise) computations have cost
O(n*poly(chi) + n^2), where chi is the TN's maximal cut rank. We provide
theoretical guarantees on the approximation error and tractability of TN-SHAP.
On UCI datasets, our method matches enumeration on the fitted surrogate while
reducing evaluation by orders of magnitude and achieves 25-1000x wall-clock
speedups over KernelSHAP-IQ at comparable accuracy, while amortizing training
across local cohorts.

</details>


### [638] [Edit Less, Achieve More: Dynamic Sparse Neuron Masking for Lifelong Knowledge Editing in LLMs](https://arxiv.org/abs/2510.22139)
*Jinzhe Liu,Junshu Sun,Shufan Shen,Chenxue Yang,Shuhui Wang*

Main category: cs.LG

TL;DR: NMKE通过精细化的神经元级别编辑和动态稀疏掩码来解决LLM知识编辑中错误累积的问题，实现了更高的编辑成功率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLM知识编辑方法在连续编辑过程中常会累积错误，导致编辑准确性和泛化能力下降。

Method: 提出了一种名为NMKE（Neuron-Specific Masked Knowledge Editing）的新型精细化编辑框架，结合了神经元级别归因和动态稀疏掩码。该方法利用神经元功能归因识别出知识通用神经元和知识特异神经元，并通过熵引导的动态稀疏掩码来定位与目标知识相关的神经元，从而实现更精确的、参数修改更少的神经元级别知识编辑。

Result: 在数千次连续编辑的实验中，NMKE在维持高编辑成功率和保持模型泛化能力方面优于现有方法。

Conclusion: NMKE是一种有效的长期知识编辑框架，能够克服现有方法的局限性，在保持模型知识更新的同时，有效降低错误累积的影响。

Abstract: Lifelong knowledge editing enables continuous, precise updates to outdated
knowledge in large language models (LLMs) without computationally expensive
full retraining. However, existing methods often accumulate errors throughout
the editing process, causing a gradual decline in both editing accuracy and
generalization. To tackle this problem, we propose Neuron-Specific Masked
Knowledge Editing (NMKE), a novel fine-grained editing framework that combines
neuron-level attribution with dynamic sparse masking. Leveraging neuron
functional attribution, we identify two key types of knowledge neurons, with
knowledge-general neurons activating consistently across prompts and
knowledge-specific neurons activating to specific prompts. NMKE further
introduces an entropy-guided dynamic sparse mask, locating relevant neurons to
the target knowledge. This strategy enables precise neuron-level knowledge
editing with fewer parameter modifications. Experimental results from thousands
of sequential edits demonstrate that NMKE outperforms existing methods in
maintaining high editing success rates and preserving model general
capabilities in lifelong editing.

</details>


### [639] [Quantitative Bounds for Sorting-Based Permutation-Invariant Embeddings](https://arxiv.org/abs/2510.22186)
*Nadav Dym,Matthias Wellershoff,Efstratios Tsoukanis,Daniel Levy,Radu Balan*

Main category: cs.LG

TL;DR: 该研究关注图深度学习中的排序嵌入方法，解决了嵌入维度和双Lipschitz常数估计的开放性问题。


<details>
  <summary>Details</summary>
Motivation: 图深度学习中的排序嵌入方法需要满足对节点排列不变性的要求，但现有方法在嵌入维度和双Lipschitz常数估计方面存在不足。

Method: 研究改进了嵌入维度（D）的上限，并提出了嵌入维度的下限。此外，研究还构造了特定的矩阵A，使得嵌入的Lipschitz失真与节点数n的平方成正比，且与特征数d无关，并证明了失真至少与sqrt(n)相关。最后，研究将这些结果扩展到经过线性投影降维的嵌入变体。

Result: 嵌入维度D的上限得到改进，并给出了嵌入维度的下限。构造了特定矩阵A，使得双Lipschitz失真与n^2成正比，独立于d。证明了失真至少为Omega(sqrt(n))。对降维后的嵌入变体得到了类似结果。

Conclusion: 该研究在排序嵌入的注入维度和双Lipschitz常数估计方面取得了显著进展，为图深度学习中的嵌入方法提供了理论支持和改进方向。

Abstract: We study the sorting-based embedding $\beta_{\mathbf A} : \mathbb R^{n \times
d} \to \mathbb R^{n \times D}$, $\mathbf X \mapsto {\downarrow}(\mathbf X
\mathbf A)$, where $\downarrow$ denotes column wise sorting of matrices. Such
embeddings arise in graph deep learning where outputs should be invariant to
permutations of graph nodes. Previous work showed that for large enough $D$ and
appropriate $\mathbf A$, the mapping $\beta_{\mathbf A}$ is injective, and
moreover satisfies a bi-Lipschitz condition. However, two gaps remain: firstly,
the optimal size $D$ required for injectivity is not yet known, and secondly,
no estimates of the bi-Lipschitz constants of the mapping are known.
  In this paper, we make substantial progress in addressing both of these gaps.
Regarding the first gap, we improve upon the best known upper bounds for the
embedding dimension $D$ necessary for injectivity, and also provide a lower
bound on the minimal injectivity dimension. Regarding the second gap, we
construct matrices $\mathbf A$, so that the bi-Lipschitz distortion of
$\beta_{\mathbf A} $ depends quadratically on $n$, and is completely
independent of $d$. We also show that the distortion of $\beta_{\mathbf A}$ is
necessarily at least in $\Omega(\sqrt{n})$. Finally, we provide similar results
for variants of $\beta_{\mathbf A}$ obtained by applying linear projections to
reduce the output dimension of $\beta_{\mathbf A}$.

</details>


### [640] [Multi-dataset Joint Pre-training of Emotional EEG Enables Generalizable Affective Computing](https://arxiv.org/abs/2510.22197)
*Qingzhu Zhang,Jiani Zhong,Zongsheng Li,Xinke Shen,Quanying Liu*

Main category: cs.LG

TL;DR: 开发了一个针对跨数据集情绪识别任务的特定多数据集联合预训练框架，通过跨数据集协方差对齐损失和混合编码器来解决数据集分布不匹配、类别定义不一致和受试者间变异性问题，显著提高了少样本情绪识别和零样本泛化的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的任务通用预训练EEG模型在情绪识别等复杂任务上表现不佳，因为任务特定特征与通用预训练方法之间存在不匹配。本研究旨在开发一个任务特定的多数据集联合预训练框架，用于跨数据集情绪识别，以解决数据集间分布偏移大、情绪类别定义不一致和受试者间变异性大的问题。

Method: 提出了一种跨数据集协方差对齐损失，用于对齐各数据集的二阶统计特性，实现了在无需大量标签或受试者校准的情况下进行稳健泛化。为了捕捉EEG的长期依赖和复杂动态，提出了一种混合编码器，结合了类Mamba的线性注意通道编码器和时空动态模型。

Result: 所提出的方法在少样本情绪识别任务上，相比于最先进的大规模EEG模型，AUROC平均提高了4.57%；在零样本泛化到新数据集的任务上，准确率提高了11.92%。预训练数据集的数量增加，性能随之提升。多数据集联合预训练相比单数据集训练，性能提升了8.55%。

Conclusion: 本研究提供了一个可扩展的任务特定预训练框架，并强调了其在可泛化情感计算中的优势。

Abstract: Task-specific pre-training is essential when task representations diverge
from generic pre-training features. Existing task-general pre-training EEG
models struggle with complex tasks like emotion recognition due to mismatches
between task-specific features and broad pre-training approaches. This work
aims to develop a task-specific multi-dataset joint pre-training framework for
cross-dataset emotion recognition, tackling problems of large inter-dataset
distribution shifts, inconsistent emotion category definitions, and substantial
inter-subject variability. We introduce a cross-dataset covariance alignment
loss to align second-order statistical properties across datasets, enabling
robust generalization without the need for extensive labels or per-subject
calibration. To capture the long-term dependency and complex dynamics of EEG,
we propose a hybrid encoder combining a Mamba-like linear attention channel
encoder and a spatiotemporal dynamics model. Our method outperforms
state-of-the-art large-scale EEG models by an average of 4.57% in AUROC for
few-shot emotion recognition and 11.92% in accuracy for zero-shot
generalization to a new dataset. Performance scales with the increase of
datasets used in pre-training. Multi-dataset joint pre-training achieves a
performance gain of 8.55% over single-dataset training. This work provides a
scalable framework for task-specific pre-training and highlights its benefit in
generalizable affective computing. Our code is available at
https://github.com/ncclab-sustech/mdJPT_nips2025.

</details>


### [641] [The Lossy Horizon: Error-Bounded Predictive Coding for Lossy Text Compression (Episode I)](https://arxiv.org/abs/2510.22207)
*Nnamdi Aghanya,Jun Li,Kewei Wang*

Main category: cs.LG

TL;DR: LLM可用于有损压缩，通过预测文本并仅在必要时存储修正来实现高效压缩。


<details>
  <summary>Details</summary>
Motivation: 探索LLM在有损压缩领域的应用，以在重建保真度和压缩率之间进行权衡。

Method: 提出一种名为错误有界预测编码（EPC）的有损文本编解码器，该编解码器使用掩码语言模型（MLM）作为解压器，仅在模型预测错误时存储基于秩的修正。

Result: 与PM基线和VQ+RE方法相比，EPC在比特率相同的情况下提供了卓越的保真度，或在相同保真度下实现了显著更低的比特率。

Conclusion: EPC能够通过有效利用LLM的内在知识，在有损文本压缩方面超越现有方法。

Abstract: Large Language Models (LLMs) can achieve near-optimal lossless compression by
acting as powerful probability models. We investigate their use in the lossy
domain, where reconstruction fidelity is traded for higher compression ratios.
This paper introduces Error-Bounded Predictive Coding (EPC), a lossy text codec
that leverages a Masked Language Model (MLM) as a decompressor. Instead of
storing a subset of original tokens, EPC allows the model to predict masked
content and stores minimal, rank-based corrections only when the model's top
prediction is incorrect. This creates a residual channel that offers continuous
rate-distortion control. We compare EPC to a simpler Predictive Masking (PM)
baseline and a transform-based Vector Quantisation with a Residual Patch
(VQ+RE) approach. Through an evaluation that includes precise bit accounting
and rate-distortion analysis, we demonstrate that EPC consistently dominates
PM, offering superior fidelity at a significantly lower bit rate by more
efficiently utilising the model's intrinsic knowledge.

</details>


### [642] [Simplifying Knowledge Transfer in Pretrained Models](https://arxiv.org/abs/2510.22208)
*Siddharth Jain,Shyamgopal Karthik,Vineet Gandhi*

Main category: cs.LG

TL;DR: 通过让预训练模型在知识转移中扮演学生或教师的角色，并利用公共模型库进行模型改进，在图像分类、语义分割和视频显著性预测等任务上取得了性能提升。


<details>
  <summary>Details</summary>
Motivation: 利用预训练模型库来改进模型性能，并探索模型间的知识转移。

Method: 提出一种数据划分策略，使预训练模型能够自主地扮演学生（获取知识）或教师（传授知识）的角色，实现双向知识转移。

Result: 在图像分类任务中，通过双向知识转移，ViT-B的性能提升了约1.4%。在语义分割任务中，所有评估指标均得到提升。在视频显著性预测任务中，取得了新的最先进成果。将方法扩展到多模型知识转移也带来了显著的性能提升。

Conclusion: 提出的方法能够有效地利用预训练模型库进行模型改进，并通过双向知识转移在多个下游任务上取得性能提升，甚至达到新的最先进水平。

Abstract: Pretrained models are ubiquitous in the current deep learning landscape,
offering strong results on a broad range of tasks. Recent works have shown that
models differing in various design choices exhibit categorically diverse
generalization behavior, resulting in one model grasping distinct data-specific
insights unavailable to the other. In this paper, we propose to leverage large
publicly available model repositories as an auxiliary source of model
improvements. We introduce a data partitioning strategy where pretrained models
autonomously adopt either the role of a student, seeking knowledge, or that of
a teacher, imparting knowledge. Experiments across various tasks demonstrate
the effectiveness of our proposed approach. In image classification, we
improved the performance of ViT-B by approximately 1.4% through bidirectional
knowledge transfer with ViT-T. For semantic segmentation, our method boosted
all evaluation metrics by enabling knowledge transfer both within and across
backbone architectures. In video saliency prediction, our approach achieved a
new state-of-the-art. We further extend our approach to knowledge transfer
between multiple models, leading to considerable performance improvements for
all model participants.

</details>


### [643] [Visual Model Selection using Feature Importance Clusters in Fairness-Performance Similarity Optimized Space](https://arxiv.org/abs/2510.22209)
*Sofoklis Kitharidis,Cor J. Veenman,Thomas Bäck,Niki van Stein*

Main category: cs.LG

TL;DR: 提供了一个交互式框架，用于在公平机器学习的多个模型中进行选择，通过学习马氏距离来反映公平性和性能的权衡，并使用k-means聚类来分组具有相似预测行为和公平性特征的模型。


<details>
  <summary>Details</summary>
Motivation: 在算法决策背景下，公平机器学习方法产生了多种在预测公平性和性能之间取得不同平衡的模型，这给必须根据特定需求和价值观选择模型的利益相关者带来了挑战。

Method: 提出一个交互式框架，利用弱监督度量学习学习一个马氏距离，该距离反映了公平性和性能结果的相似性，并根据利益相关者相关的标准构建了模型特征重要性空间。然后应用k-means聚类技术根据特征重要性的转换表示对模型进行分组。

Result: 该框架通过学习到的马氏距离和k-means聚类，能够根据公平性和性能的权衡以及驱动预测的特征来区分和组织模型。

Conclusion: 提出的交互式框架通过结构化特征重要性空间和模型分组，帮助利益相关者理解和导航公平机器学习模型的多样性，从而做出更明智的决策。

Abstract: In the context of algorithmic decision-making, fair machine learning methods
often yield multiple models that balance predictive fairness and performance in
varying degrees. This diversity introduces a challenge for stakeholders who
must select a model that aligns with their specific requirements and values. To
address this, we propose an interactive framework that assists in navigating
and interpreting the trade-offs across a portfolio of models. Our approach
leverages weakly supervised metric learning to learn a Mahalanobis distance
that reflects similarity in fairness and performance outcomes, effectively
structuring the feature importance space of the models according to
stakeholder-relevant criteria. We then apply clustering technique (k-means) to
group models based on their transformed representations of feature importances,
allowing users to explore clusters of models with similar predictive behaviors
and fairness characteristics. This facilitates informed decision-making by
helping users understand how models differ not only in their
fairness-performance balance but also in the features that drive their
predictions.

</details>


### [644] [When Fewer Layers Break More Chains: Layer Pruning Harms Test-Time Scaling in LLMs](https://arxiv.org/abs/2510.22228)
*Keyu Wang,Tian Lyu,Guinan Su,Jonas Geiping,Lu Yin,Marco Canini,Shiwei Liu*

Main category: cs.LG

TL;DR: 层剪枝严重损害大型语言模型（LLM）的推理能力，尽管在一般知识任务上表现良好。


<details>
  <summary>Details</summary>
Motivation: 研究层剪枝对大型语言模型长链推理能力的影响，特别是其测试时计算扩展能力。

Method: 通过实验评估层剪枝对测试时计算扩展能力的影响，并分析其对长链推理性能的损害机制。

Result: 即使剪枝少量层（一到两层）也会严重损害测试时计算扩展能力，导致长链推理性能急剧下降，而知识密集型和浅层推理任务的性能保持稳定。标准的监督微调无法恢复受损的测试时计算扩展能力。

Conclusion: 层剪枝对推理密集型大型语言模型存在根本性风险，需要重新思考剪枝策略，并开发能保持推理鲁棒性的方法。

Abstract: Layer pruning has emerged as a widely adopted technique for improving the
efficiency of large language models (LLMs). Although existing methods
demonstrate strong performance retention on general knowledge tasks, their
effect on long-chain reasoning, a more brittle yet crucial capability, remains
largely unexplored. In this work, we study the impact of layer pruning on
long-chain reasoning through the lens of test-time scaling, a key mechanism in
modern LLMs that enables strong reasoning capacity by allocating more
computation at inference time. With extensive experiments, we demonstrate that
pruning even one or two layers can severely impair test-time scaling, with
performance collapsing drastically on long reasoning benchmarks even when
performance on knowledge-intensive and shallow reasoning tasks remains stable.
Furthermore, we find that standard supervised fine-tuning remedies fail to
recover test-time scaling once it has deteriorated. Through in-depth analyses,
we identify the mechanisms underlying this fragility of test-time scaling and
highlight the fundamental risks of applying layer pruning to
reasoning-intensive LLMs. These findings call for a rethinking of layer pruning
strategies and provide insights for developing methods that preserve the
robustness of reasoning. We open-source the codebase in
\href{https://github.com/keyu-wang-2002/Layer-Pruning-Harms-Inference-Scaling}{https://github.com/keyu-wang-2002/Layer-Pruning-Harms-Inference-Scaling}.

</details>


### [645] [LUNA: Efficient and Topology-Agnostic Foundation Model for EEG Signal Analysis](https://arxiv.org/abs/2510.22257)
*Berkay Döner,Thorir Mar Ingolfsson,Luca Benini,Yawei Li*

Main category: cs.LG

TL;DR: LUNA是一个自监督基础模型，可以解决不同EEG数据集的拓扑异质性问题，通过将多通道EEG压缩到固定大小的、与拓扑无关的潜在空间，并在该空间中进行计算，从而实现高效的下游任务迁移，并在多个基准测试中取得有竞争力的结果，甚至达到最先进的水平。


<details>
  <summary>Details</summary>
Motivation: 公共EEG数据集的拓扑异质性（每个数据集都有自己的电极布局）阻碍了大规模模型的泛化。

Method: LUNA使用学习到的查询和交叉注意力将多通道EEG压缩到固定大小、与拓扑无关的潜在空间。下游Transformer块在该潜在表示上进行操作，使用逐块的时间自注意力，将计算与电极数量分离。该模型在TUEG和Siena数据集上进行了预训练，使用了掩码块重建目标。

Result: LUNA在四个下游任务（异常检测、伪影去除、缓慢分类和情绪识别）中表现出高效的迁移能力，并在多个基准测试中取得有竞争力的性能，在TUAR和TUSL上达到最先进的水平（例如，TUAR上的AUROC为0.921）。与之前的模型相比，FLOPs减少了300倍，GPU内存使用量减少了10倍，并且在所有评估的电极配置中都保持了一致的性能。

Conclusion: LUNA成功地解决了EEG数据拓扑异质性问题，通过一种可扩展且高效的方法，在各种下游任务中实现了先进的性能，同时显著降低了计算资源的需求。

Abstract: Electroencephalography (EEG) offers a non-invasive lens into human brain
activity, but building large-scale models is hampered by topological
heterogeneity: each public EEG data defines its own electrode layout, limiting
generalization. We introduce LUNA (Latent Unified Network Architecture), a
self-supervised foundation model that reconciles disparate electrode geometries
while scaling linearly -- not quadratically -- with channel count. LUNA
compresses multi-channel EEG into a fixed-size, topology-agnostic latent space
via learned queries and cross-attention. Downstream transformer blocks then
operate exclusively on this latent representation using patch-wise temporal
self-attention, decoupling computation from electrode count. Pre-trained on
TUEG and Siena (over 21,000 hours of raw EEG across diverse montages) using a
masked-patch reconstruction objective, LUNA transfers effectively to four
downstream tasks: abnormality detection, artifact rejection, slowing
classification, and emotion recognition. It demonstrates highly competitive
performance across several benchmarks, achieving state-of-the-art results on
TUAR and TUSL, e.g., 0.921 AUROC on TUAR, while reducing FLOPs by 300x and
trimming GPU memory use by up to 10x. Critically, these gains are consistent
across all evaluated electrode configurations. Code is available at
https://github.com/pulp-bio/BioFoundation

</details>


### [646] [Epistemic Deep Learning: Enabling Machine Learning Models to Know When They Do Not Know](https://arxiv.org/abs/2510.22261)
*Shireen Kudukkil Manchingal*

Main category: cs.LG

TL;DR: 本论文提出了一种名为“认知深度学习”的方法，通过明确建模和量化认知不确定性来解决机器学习在安全关键领域部署的局限性，特别是当模型遇到分布外数据、对抗性扰动或自然波动环境时，机器学习模型往往会做出过于自信和不可靠的预测。


<details>
  <summary>Details</summary>
Motivation: 机器学习在安全关键领域的部署受到其在处理不确定性方面的内在缺陷的阻碍，这导致在模型遇到分布外数据、对抗性扰动或自然波动环境时，模型会做出过于自信和不可靠的预测。

Method: 本论文提出了一种名为随机集神经网络（RS-NN）的新颖方法，该方法利用随机集理论来预测类别集合上的信念函数，并通过关联的可信度集的宽度来捕捉认知不确定性的程度。此外，论文还将RS-NN方法应用于大型语言模型（LLMs），并将其部署到自动驾驶赛车的气象分类任务中。最后，论文提出了一种统一的、面向不确定性感知分类器的评估框架。

Result: 通过大量实验验证，将认知不确定性感知能力集成到深度学习模型中，不仅能够降低与过于自信的预测相关的风险，还为人工智能范式转变奠定了基础，使模型能够‘知道自己何时不知道’，从而成为鲁棒和可靠系统的标志。

Conclusion: 本论文通过提出认知深度学习和随机集神经网络，解决了机器学习模型在安全关键领域中因认知不确定性而导致的不可靠预测问题，并展示了其在LLM和自动驾驶赛车等领域的应用潜力，强调了‘知道自己何时不知道’是构建鲁棒和可信赖人工智能系统的关键。

Abstract: Machine learning has achieved remarkable successes, yet its deployment in
safety-critical domains remains hindered by an inherent inability to manage
uncertainty, resulting in overconfident and unreliable predictions when models
encounter out-of-distribution data, adversarial perturbations, or naturally
fluctuating environments. This thesis, titled Epistemic Deep Learning: Enabling
Machine Learning Models to 'Know When They Do Not Know', addresses these
critical challenges by advancing the paradigm of Epistemic Artificial
Intelligence, which explicitly models and quantifies epistemic uncertainty: the
uncertainty arising from limited, biased, or incomplete training data, as
opposed to the irreducible randomness of aleatoric uncertainty, thereby
empowering models to acknowledge their limitations and refrain from
overconfident decisions when uncertainty is high.
  Central to this work is the development of the Random-Set Neural Network
(RS-NN), a novel methodology that leverages random set theory to predict belief
functions over sets of classes, capturing the extent of epistemic uncertainty
through the width of associated credal sets, applications of RS-NN, including
its adaptation to Large Language Models (LLMs) and its deployment in weather
classification for autonomous racing. In addition, the thesis proposes a
unified evaluation framework for uncertainty-aware classifiers. Extensive
experiments validate that integrating epistemic awareness into deep learning
not only mitigates the risks associated with overconfident predictions but also
lays the foundation for a paradigm shift in artificial intelligence, where the
ability to 'know when it does not know' becomes a hallmark of robust and
dependable systems. The title encapsulates the core philosophy of this work,
emphasizing that true intelligence involves recognizing and managing the limits
of one's own knowledge.

</details>


### [647] [A Multi-level Analysis of Factors Associated with Student Performance: A Machine Learning Approach to the SAEB Microdata](https://arxiv.org/abs/2510.22266)
*Rodrigo Tertulino,Ricardo Almeida*

Main category: cs.LG

TL;DR: 该研究使用多层机器学习模型和可解释人工智能，识别影响巴西基础教育学生学业成绩的因素，发现学校的社会经济因素比个人特征更重要。


<details>
  <summary>Details</summary>
Motivation: 确定影响巴西基础教育学生学业成绩的因素，为制定有效的公共政策提供依据。

Method: 采用多层机器学习方法，整合学生社会经济特征、教师专业背景、学校指标和校长管理风格等多源数据，并运用SHAP进行可解释人工智能分析，以识别关键影响因素。

Result: 随机森林模型在预测准确率（90.2%）和AUC（96.7%）方面表现最佳，可解释性分析揭示学校的平均社会经济水平是影响学生成绩的最主要因素。

Conclusion: 学业成绩是一个系统性现象，与学校的生态系统密切相关，政策制定应关注学校层面的系统性因素以促进教育公平。

Abstract: Identifying the factors that influence student performance in basic education
is a central challenge for formulating effective public policies in Brazil.
This study introduces a multi-level machine learning approach to classify the
proficiency of 9th-grade and high school students using microdata from the
System of Assessment of Basic Education (SAEB). Our model uniquely integrates
four data sources: student socioeconomic characteristics, teacher professional
profiles, school indicators, and director management profiles. A comparative
analysis of four ensemble algorithms confirmed the superiority of a Random
Forest model, which achieved 90.2% accuracy and an Area Under the Curve (AUC)
of 96.7%. To move beyond prediction, we applied Explainable AI (XAI) using
SHAP, which revealed that the school's average socioeconomic level is the most
dominant predictor, demonstrating that systemic factors have a greater impact
than individual characteristics in isolation. The primary conclusion is that
academic performance is a systemic phenomenon deeply tied to the school's
ecosystem. This study provides a data-driven, interpretable tool to inform
policies aimed at promoting educational equity by addressing disparities
between schools.

</details>


### [648] [Machine Learning Enabled Early Warning System For Financial Distress Using Real-Time Digital Signals](https://arxiv.org/abs/2510.22287)
*Laxmi pant,Syed Ali Reza,Md Khalilor Rahman,MD Saifur Rahman,Shamima Sharmin,Md Fazlul Huq Mithu,Kazi Nehal Hasnain,Adnan Farabi,Mahamuda khanom,Raisul Kabir*

Main category: cs.LG

TL;DR: 该研究引入了一个基于机器学习的预警系统，利用实时数字和宏观经济信号来近乎实时地识别家庭金融困境，并取得了显著的预测准确性提升，特别是通过引入数字经济指标。


<details>
  <summary>Details</summary>
Motivation: 全球和国内经济环境日益不稳定的背景下，家庭面临的金融困境风险增加，但传统计量经济学模型依赖滞后和聚合数据，效果有限。

Method: 研究构建了一个包含社会经济属性、宏观经济指标和数字经济措施的机器学习框架，并利用面板数据进行分析，通过数据预处理和特征工程（如滞后变量、波动性度量和交互项）来捕捉金融稳定性的变化，并对比了多种分类器（逻辑回归、决策树、随机森林、XGBoost、LightGBM）。

Result: 研究结果表明，数字经济的特征工程显著提高了预测准确性。该系统在二元困境检测和多类严重性分类方面均表现可靠，SHAP解释显示通胀波动和ICT需求是关键预测因子。

Conclusion: 该研究证明了以透明且可解释的方式应用机器学习来提供近乎实时的金融困境预警是可行的且具有影响力的，为加强家庭韧性和指导干预策略提供了可操作的见解。

Abstract: The growing instability of both global and domestic economic environments has
increased the risk of financial distress at the household level. However,
traditional econometric models often rely on delayed and aggregated data,
limiting their effectiveness. This study introduces a machine learning-based
early warning system that utilizes real-time digital and macroeconomic signals
to identify financial distress in near real-time. Using a panel dataset of 750
households tracked over three monitoring rounds spanning 13 months, the
framework combines socioeconomic attributes, macroeconomic indicators (such as
GDP growth, inflation, and foreign exchange fluctuations), and digital economy
measures (including ICT demand and market volatility). Through data
preprocessing and feature engineering, we introduce lagged variables,
volatility measures, and interaction terms to capture both gradual and sudden
changes in financial stability. We benchmark baseline classifiers, such as
logistic regression and decision trees, against advanced ensemble models
including random forests, XGBoost, and LightGBM. Our results indicate that the
engineered features from the digital economy significantly enhance predictive
accuracy. The system performs reliably for both binary distress detection and
multi-class severity classification, with SHAP-based explanations identifying
inflation volatility and ICT demand as key predictors. Crucially, the framework
is designed for scalable deployment in national agencies and low-bandwidth
regional offices, ensuring it is accessible for policymakers and practitioners.
By implementing machine learning in a transparent and interpretable manner,
this study demonstrates the feasibility and impact of providing near-real-time
early warnings of financial distress. This offers actionable insights that can
strengthen household resilience and guide preemptive intervention strategies.

</details>


### [649] [Does Homophily Help in Robust Test-time Node Classification?](https://arxiv.org/abs/2510.22289)
*Yan Jiang,Ruihong Qiu,Zi Huang*

Main category: cs.LG

TL;DR: GrapHoST通过在测试时调整图的同质性来提高GNN在节点分类任务上的鲁棒性和性能，尤其是在数据质量问题和分布变化的情况下。


<details>
  <summary>Details</summary>
Motivation: 现有GNN方法主要关注训练图，但在现实世界的测试图（如社交网络或引文网络）中，数据质量问题和分布变化（如领域转移、时间演化）会严重影响预训练模型的鲁棒性，导致测试性能下降。

Method: 提出了一种名为GrapHoST的新型测试时图结构转换方法。该方法通过同质性预测器来区分测试边，并根据预测的同质性得分的置信度自适应地进行测试时图结构转换，以提高或降低图的同质性，从而提高预训练GNN的鲁棒性和性能，而无需重新训练模型。

Result: 在九个基准数据集上的大量实验表明，GrapHoST在各种测试时数据质量问题下始终 achieves 领先的性能，性能提升高达10.92%。

Conclusion: 通过在测试时调整图结构（增加或减少同质性）可以显著提高预训练GNN在节点分类任务上的鲁棒性和性能，尤其是在面对数据质量问题和分布变化时。GrapHoST是一种有效的实现这一目标的测试时图结构转换方法。

Abstract: Homophily, the tendency of nodes from the same class to connect, is a
fundamental property of real-world graphs, underpinning structural and semantic
patterns in domains such as citation networks and social networks. Existing
methods exploit homophily through designing homophily-aware GNN architectures
or graph structure learning strategies, yet they primarily focus on GNN
learning with training graphs. However, in real-world scenarios, test graphs
often suffer from data quality issues and distribution shifts, such as domain
shifts across users from different regions in social networks and temporal
evolution shifts in citation network graphs collected over varying time
periods. These factors significantly compromise the pre-trained model's
robustness, resulting in degraded test-time performance. With empirical
observations and theoretical analysis, we reveal that transforming the test
graph structure by increasing homophily in homophilic graphs or decreasing it
in heterophilic graphs can significantly improve the robustness and performance
of pre-trained GNNs on node classifications, without requiring model training
or update. Motivated by these insights, a novel test-time graph structural
transformation method grounded in homophily, named GrapHoST, is proposed.
Specifically, a homophily predictor is developed to discriminate test edges,
facilitating adaptive test-time graph structural transformation by the
confidence of predicted homophily scores. Extensive experiments on nine
benchmark datasets under a range of test-time data quality issues demonstrate
that GrapHoST consistently achieves state-of-the-art performance, with
improvements of up to 10.92%. Our code has been released at
https://github.com/YanJiangJerry/GrapHoST.

</details>


### [650] [Predicting Metabolic Dysfunction-Associated Steatotic Liver Disease using Machine Learning Methods](https://arxiv.org/abs/2510.22293)
*Mary E. An,Paul Griffin,Jonathan G. Stine,Ramakrishna Balakrishnan,Ram Sriram,Soundar Kumara*

Main category: cs.LG

TL;DR: MASLD affects a significant portion of the US adult population and can lead to cirrhosis; early detection via lifestyle interventions is key. This study developed and evaluated four models (LASSO logistic regression, random forest, XGBoost, neural network) for MASLD prediction using EHR data. A LASSO logistic regression model with the top 10 features was chosen for its interpretability and performance. After applying an equal opportunity postprocessing method to reduce disparities, the model achieved an AUROC of 0.836 and accuracy of 77.6%, demonstrating a balance between predictive performance and fairness.


<details>
  <summary>Details</summary>
Motivation: Metabolic Dysfunction-Associated Steatotic Liver Disease (MASLD) affects approximately 33% of U.S. adults and is the most common chronic liver disease. Early detection is crucial as lifestyle interventions can prevent disease progression. The study aimed to develop a fair, rigorous, and reproducible MASLD prediction model and compare it to existing methods using a large electronic health record database.

Method: Four models (LASSO logistic regression, random forest, XGBoost, and a neural network) were evaluated for MASLD prediction using subsets of clinical features, including the top 10 SHAP-ranked features. An equal opportunity postprocessing method was applied to reduce disparities in true positive rates across different racial and ethnic subgroups.

Result: The LASSO logistic regression model with the top 10 features demonstrated comparable performance to other models and was selected for its interpretability. Before fairness adjustment, the model achieved an AUROC of 0.84, accuracy of 78%, sensitivity of 72%, specificity of 79%, and F1-score of 0.617. After applying the equal opportunity postprocessing, accuracy increased to 81% and specificity to 94%, while sensitivity decreased to 41% and F1-score to 0.515, indicating a trade-off for fairness.

Conclusion: The developed MASER prediction model, a LASSO logistic regression model, achieved competitive performance (AUROC 0.836, accuracy 77.6%) for MASLD prediction, comparable to ensemble and tree-based models. This approach highlights the ability of interpretable models to balance predictive performance and fairness in diverse patient populations.

Abstract: Background: Metabolic Dysfunction-Associated Steatotic Liver Disease (MASLD)
affects ~33% of U.S. adults and is the most common chronic liver disease.
Although often asymptomatic, progression can lead to cirrhosis. Early detection
is important, as lifestyle interventions can prevent disease progression. We
developed a fair, rigorous, and reproducible MASLD prediction model and
compared it to prior methods using a large electronic health record database.
  Methods: We evaluated LASSO logistic regression, random forest, XGBoost, and
a neural network for MASLD prediction using clinical feature subsets, including
the top 10 SHAP-ranked features. To reduce disparities in true positive rates
across racial and ethnic subgroups, we applied an equal opportunity
postprocessing method.
  Results: This study included 59,492 patients in the training data, 24,198 in
the validating data, and 25,188 in the testing data. The LASSO logistic
regression model with the top 10 features was selected for its interpretability
and comparable performance. Before fairness adjustment, the model achieved
AUROC of 0.84, accuracy of 78%, sensitivity of 72%, specificity of 79%, and
F1-score of 0.617. After equal opportunity postprocessing, accuracy modestly
increased to 81% and specificity to 94%, while sensitivity decreased to 41% and
F1-score to 0.515, reflecting the fairness trade-off.
  Conclusions: We developed the MASER prediction model (MASLD Static EHR Risk
Prediction), a LASSO logistic regression model which achieved competitive
performance for MASLD prediction (AUROC 0.836, accuracy 77.6%), comparable to
previously reported ensemble and tree-based models. Overall, this approach
demonstrates that interpretable models can achieve a balance of predictive
performance and fairness in diverse patient populations.

</details>


### [651] [AnyECG-Lab: An Exploration Study of Fine-tuning an ECG Foundation Model to Estimate Laboratory Values from Single-Lead ECG Signals](https://arxiv.org/abs/2510.22301)
*Yujie Xiao,Gongzhen Tang,Wenhui Liu,Jun Li,Guangkun Nie,Zhuoran Kan,Deyun Zhang,Qinghao Zhao,Shenda Hong*

Main category: cs.LG

TL;DR: 研究利用迁移学习和ECGFounder模型，通过分析超过2000万个ECG片段，实现了对33种实验室指标的准确预测，并为实时无创检测实验室值提供了AI驱动的解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有通过侵入性静脉采样获取实验室值的方法存在延迟，而ECG作为一种非侵入性且易于获取的信号，有潜力用于快速估算实验室值。然而，现有深度学习模型在信噪比、个体差异、数据多样性和泛化性方面存在局限，尤其是在低导联可穿戴设备上的应用效果不佳。

Method: 利用迁移学习对ECGFounder（一个大规模预训练ECG基础模型）进行微调，并使用斯坦福大学的多模态急诊监测（MC-MED）数据集。生成了超过2000万个标准化的10秒ECG片段，以提高对细微生化相关指标的敏感性。

Result: 在内部验证中，该模型对33种实验室指标表现出强预测性能（曲线下面积大于0.65），对59种指标表现出中等性能（0.55至0.65之间），对16种指标表现出有限性能（低于0.55）。

Conclusion: 该研究提供了一个高效的、由人工智能驱动的解决方案，并确定了实时、无创估算实验室值的可行范围。

Abstract: Timely access to laboratory values is critical for clinical decision-making,
yet current approaches rely on invasive venous sampling and are intrinsically
delayed. Electrocardiography (ECG), as a non-invasive and widely available
signal, offers a promising modality for rapid laboratory estimation. Recent
progress in deep learning has enabled the extraction of latent hematological
signatures from ECGs. However, existing models are constrained by low
signal-to-noise ratios, substantial inter-individual variability, limited data
diversity, and suboptimal generalization, especially when adapted to low-lead
wearable devices. In this work, we conduct an exploratory study leveraging
transfer learning to fine-tune ECGFounder, a large-scale pre-trained ECG
foundation model, on the Multimodal Clinical Monitoring in the Emergency
Department (MC-MED) dataset from Stanford. We generated a corpus of more than
20 million standardized ten-second ECG segments to enhance sensitivity to
subtle biochemical correlates. On internal validation, the model demonstrated
strong predictive performance (area under the curve above 0.65) for
thirty-three laboratory indicators, moderate performance (between 0.55 and
0.65) for fifty-nine indicators, and limited performance (below 0.55) for
sixteen indicators. This study provides an efficient artificial-intelligence
driven solution and establishes the feasibility scope for real-time,
non-invasive estimation of laboratory values.

</details>


### [652] [LacMaterial: Large Language Models as Analogical Chemists for Materials Discovery](https://arxiv.org/abs/2510.22312)
*Hongyu Guo*

Main category: cs.LG

TL;DR: LLMs can be used to discover new battery materials by retrieving cross-domain analogs and constructing in-domain analogical templates.


<details>
  <summary>Details</summary>
Motivation: Human analogical reasoning is constrained by expertise and biases, limiting scientific discovery. LLMs, trained on vast data, offer a potential solution.

Method: LLMs are used to (1) retrieve cross-domain analogs and (2) construct in-domain analogical templates from few labeled examples to guide material exploration.

Result: The LLM-generated battery material candidates fall outside established compositional spaces and outperform standard prompting baselines.

Conclusion: LLMs can serve as interpretable, expert-like hypothesis generators that utilize analogy-driven generalization for scientific innovation, particularly in discovering novel battery materials.

Abstract: Analogical reasoning, the transfer of relational structures across contexts
(e.g., planet is to sun as electron is to nucleus), is fundamental to
scientific discovery. Yet human insight is often constrained by domain
expertise and surface-level biases, limiting access to deeper, structure-driven
analogies both within and across disciplines. Large language models (LLMs),
trained on vast cross-domain data, present a promising yet underexplored tool
for analogical reasoning in science. Here, we demonstrate that LLMs can
generate novel battery materials by (1) retrieving cross-domain analogs and
analogy-guided exemplars to steer exploration beyond conventional dopant
substitutions, and (2) constructing in-domain analogical templates from few
labeled examples to guide targeted exploitation. These explicit analogical
reasoning strategies yield candidates outside established compositional spaces
and outperform standard prompting baselines. Our findings position LLMs as
interpretable, expert-like hypothesis generators that leverage analogy-driven
generalization for scientific innovation.

</details>


### [653] [Monitoring State Transitions in Markovian Systems with Sampling Cost](https://arxiv.org/abs/2510.22327)
*Kumar Saurav,Ness B. Shroff,Yingbin Liang*

Main category: cs.LG

TL;DR: 该研究提出了一个在有固定查询成本的情况下，利用时间序列预测模型（包括TSFMs）来跟踪动态节点状态的策略。研究分析了一个贪婪策略，并证明了其在一般情况下的次优性，但在常见条件下表现接近最优策略。此外，还提出了一种基于PSGD的学习算法，用于在未知转移概率的情况下实现有利的预测-查询权衡，并提高了计算效率。


<details>
  <summary>Details</summary>
Motivation: 在节点状态随时间变化且查询成本固定的情况下，需要设计一种有效的策略来跟踪节点状态，平衡预测准确性和查询成本。

Method: 1. 提出了一种贪婪策略：当预期预测损失低于查询成本时进行预测，否则进行查询。2. 在马尔可夫环境中分析了该贪婪策略，并将其与最优策略（OPT）进行了比较。3. 针对未知转移概率的情况，提出了一种基于投影随机梯度下降（PSGD）的学习算法。

Result: 1. 贪婪策略在一般情况下是次优的，其竞争比可能是无界的。2. 在转移概率同分布等常见条件下，贪婪策略的表现接近最优策略。3. PSGD算法在未知转移概率的情况下，能够实现良好的预测-查询权衡，并具有较高的计算效率。

Conclusion: 该研究为在存在查询成本的情况下跟踪动态节点状态提供了一种新的方法。贪婪策略在特定条件下是有效的，而PSGD算法则为更复杂的情况提供了可扩展的解决方案。

Abstract: We consider a node-monitor pair, where the node's state varies with time. The
monitor needs to track the node's state at all times; however, there is a fixed
cost for each state query. So the monitor may instead predict the state using
time-series forecasting methods, including time-series foundation models
(TSFMs), and query only when prediction uncertainty is high. Since query
decisions influence prediction accuracy, determining when to query is
nontrivial. A natural approach is a greedy policy that predicts when the
expected prediction loss is below the query cost and queries otherwise. We
analyze this policy in a Markovian setting, where the optimal (OPT) strategy is
a state-dependent threshold policy minimizing the time-averaged sum of query
cost and prediction losses. We show that, in general, the greedy policy is
suboptimal and can have an unbounded competitive ratio, but under common
conditions such as identically distributed transition probabilities, it
performs close to OPT. For the case of unknown transition probabilities, we
further propose a projected stochastic gradient descent (PSGD)-based learning
variant of the greedy policy, which achieves a favorable predict-query tradeoff
with improved computational efficiency compared to OPT.

</details>


### [654] [Transformer Key-Value Memories Are Nearly as Interpretable as Sparse Autoencoders](https://arxiv.org/abs/2510.22332)
*Mengyu Ye,Jun Suzuki,Tatsuro Inaba,Tatsuki Kuribayashi*

Main category: cs.LG

TL;DR: SAE 和 FF 的可解释性相似，SAE 略有改进，但 FF 在某些方面更优，挑战了 SAE 的优势。


<details>
  <summary>Details</summary>
Motivation: 评估 SAE 等代理模块学习到的特征与原始模型参数中已存在特征的比较，以及 FF 层特征的可解释性。

Method: 将 FF 层视为键值存储器，并使用现代可解释性基准进行评估，比较 SAE 和 FF 的可解释性。

Result: SAE 和 FF 具有相似的可解释性范围，SAE 在某些方面有微小但可观察的改进。然而，在某些方面，FF 的可解释性甚至优于 SAE，并且 SAE 和 FF 中发现的特征存在差异。

Conclusion: SAE 的优势受到质疑，因为直接解释 FF 特征向量在特征质量和忠实度方面具有可比性，并且 FF 键值参数是现代可解释性研究的有力基准。

Abstract: Recent interpretability work on large language models (LLMs) has been
increasingly dominated by a feature-discovery approach with the help of proxy
modules. Then, the quality of features learned by, e.g., sparse auto-encoders
(SAEs), is evaluated. This paradigm naturally raises a critical question: do
such learned features have better properties than those already represented
within the original model parameters, and unfortunately, only a few studies
have made such comparisons systematically so far. In this work, we revisit the
interpretability of feature vectors stored in feed-forward (FF) layers, given
the perspective of FF as key-value memories, with modern interpretability
benchmarks. Our extensive evaluation revealed that SAE and FFs exhibits a
similar range of interpretability, although SAEs displayed an observable but
minimal improvement in some aspects. Furthermore, in certain aspects,
surprisingly, even vanilla FFs yielded better interpretability than the SAEs,
and features discovered in SAEs and FFs diverged. These bring questions about
the advantage of SAEs from both perspectives of feature quality and
faithfulness, compared to directly interpreting FF feature vectors, and FF
key-value parameters serve as a strong baseline in modern interpretability
research.

</details>


### [655] [Uncertainty quantification in model discovery by distilling interpretable material constitutive models from Gaussian process posteriors](https://arxiv.org/abs/2510.22345)
*David Anton,Henning Wessels,Ulrich Römer,Alexander Henkes,Jorge-Humberto Urrea-Quintero*

Main category: cs.LG

TL;DR: 提出一种新的框架，用于在存在噪声的情况下进行本构模型发现和不确定性量化，无需先验知识，并能发现非线性模型。


<details>
  <summary>Details</summary>
Motivation: 先前的不确定性量化方法在模型发现方面存在局限性，例如需要先验知识、仅限于线性模型或参数概率分布受限。

Method: 1. 使用高斯过程增强应力-变形数据。 2. 使用归一化流逼近参数分布。 3. 通过匹配参数引起的应力-变形函数分布与高斯过程后验来提炼参数分布。 4. 进行 Sobol' 敏感性分析以获得稀疏且可解释的模型。

Result: 该框架能够处理各向同性和各向异性实验数据，以及线性和非线性模型库。

Conclusion: 该框架为本构模型发现提供了一种灵活且无需先验知识的不确定性量化方法，能够发现复杂的非线性模型。

Abstract: Constitutive model discovery refers to the task of identifying an appropriate
model structure, usually from a predefined model library, while simultaneously
inferring its material parameters. The data used for model discovery are
measured in mechanical tests and are thus inevitably affected by noise which,
in turn, induces uncertainties. Previously proposed methods for uncertainty
quantification in model discovery either require the selection of a prior for
the material parameters, are restricted to the linear coefficients of the model
library or are limited in the flexibility of the inferred parameter probability
distribution. We therefore propose a four-step partially Bayesian framework for
uncertainty quantification in model discovery that does not require prior
selection for the material parameters and also allows for the discovery of
non-linear constitutive models: First, we augment the available
stress-deformation data with a Gaussian process. Second, we approximate the
parameter distribution by a normalizing flow, which allows for capturing
complex joint distributions. Third, we distill the parameter distribution by
matching the distribution of stress-deformation functions induced by the
parameters with the Gaussian process posterior. Fourth, we perform a Sobol'
sensitivity analysis to obtain a sparse and interpretable model. We demonstrate
the capability of our framework for both isotropic and anisotropic experimental
data as well as linear and non-linear model libraries.

</details>


### [656] [Mapping Faithful Reasoning in Language Models](https://arxiv.org/abs/2510.22362)
*Jiazheng Li,Andreas Damianou,J Rosser,José Luis Redondo García,Konstantina Palla*

Main category: cs.LG

TL;DR: CoT可能不真实反映模型内部计算，引入Concept Walk在激活空间中分析推理过程，发现'简单'案例中的CoT是装饰性的，而'困难'案例中的CoT是忠实的。


<details>
  <summary>Details</summary>
Motivation: CoT的透明度承诺与其实际可能存在的“装饰性”推理之间的矛盾，对模型监督造成挑战。

Method: 提出Concept Walk框架，将推理的每个步骤投影到从对比数据中学到的概念方向上，以在激活空间中观察模型对概念的立场演变。

Result: 在Qwen 3-4B的安全领域案例研究中，发现'简单'案例的扰动CoT很快被忽略（装饰性），而'困难'案例的扰动CoT引起了持续的激活偏移（忠实性）。

Conclusion: Concept Walk提供了一种通过特定概念的内部动态来重新审视CoT忠实性的方法，有助于区分可信赖的推理和可能误导人的推理。

Abstract: Chain-of-thought (CoT) traces promise transparency for reasoning language
models, but prior work shows they are not always faithful reflections of
internal computation. This raises challenges for oversight: practitioners may
misinterpret decorative reasoning as genuine. We introduce Concept Walk, a
general framework for tracing how a model's internal stance evolves with
respect to a concept direction during reasoning. Unlike surface text, Concept
Walk operates in activation space, projecting each reasoning step onto the
concept direction learned from contrastive data. This allows us to observe
whether reasoning traces shape outcomes or are discarded. As a case study, we
apply Concept Walk to the domain of Safety using Qwen 3-4B. We find that in
'easy' cases, perturbed CoTs are quickly ignored, indicating decorative
reasoning, whereas in 'hard' cases, perturbations induce sustained shifts in
internal activations, consistent with faithful reasoning. The contribution is
methodological: Concept Walk provides a lens to re-examine faithfulness through
concept-specific internal dynamics, helping identify when reasoning traces can
be trusted and when they risk misleading practitioners.

</details>


### [657] [Bias Begins with Data: The FairGround Corpus for Robust and Reproducible Research on Algorithmic Fairness](https://arxiv.org/abs/2510.22363)
*Jan Simson,Alessandro Fabris,Cosima Fröhner,Frauke Kreuter,Christoph Kern*

Main category: cs.LG

TL;DR: FairGround是一个包含44个表格数据集的统一框架、数据集和Python包，旨在促进公平机器学习（ML）分类的可复现研究和关键数据研究，并提供标准化的工具来处理数据集。


<details>
  <summary>Details</summary>
Motivation: 现有公平ML研究依赖于狭窄、不一致且缺乏多样性的数据集，这影响了研究结果的普遍性和可复现性。

Method: FairGround提供了一个统一的框架、数据集（包含44个带有公平相关元数据的表格数据集）和Python包，用于标准化公平ML分类的数据加载、预处理、转换和拆分。

Result: FairGround通过提供多样化且文档齐全的数据集语料库以及强大的工具，支持开发更公平、更可靠、更可复现的ML模型。

Conclusion: FairGround通过提供多样化、标准化的数据集和工具，解决了公平ML研究中数据集的局限性，促进了公平ML的可复现性和可靠性。

Abstract: As machine learning (ML) systems are increasingly adopted in high-stakes
decision-making domains, ensuring fairness in their outputs has become a
central challenge. At the core of fair ML research are the datasets used to
investigate bias and develop mitigation strategies. Yet, much of the existing
work relies on a narrow selection of datasets--often arbitrarily chosen,
inconsistently processed, and lacking in diversity--undermining the
generalizability and reproducibility of results.
  To address these limitations, we present FairGround: a unified framework,
data corpus, and Python package aimed at advancing reproducible research and
critical data studies in fair ML classification. FairGround currently comprises
44 tabular datasets, each annotated with rich fairness-relevant metadata. Our
accompanying Python package standardizes dataset loading, preprocessing,
transformation, and splitting, streamlining experimental workflows. By
providing a diverse and well-documented dataset corpus along with robust
tooling, FairGround enables the development of fairer, more reliable, and more
reproducible ML models. All resources are publicly available to support open
and collaborative research.

</details>


### [658] [Label Smoothing Improves Gradient Ascent in LLM Unlearning](https://arxiv.org/abs/2510.22376)
*Zirui Pang,Hao Zheng,Zhijie Deng,Ling Li,Zixin Zhong,Jiaheng Wei*

Main category: cs.LG

TL;DR: SGA通过结合遗忘数据和构造的正常数据来稳定和优化LLM的知识遗忘过程，同时最大限度地保留模型效用。


<details>
  <summary>Details</summary>
Motivation: 现有LLM知识遗忘技术（如梯度上升法）存在不稳定的问题，可能导致模型效用显著下降。SGA旨在解决这个问题。

Method: SGA结合遗忘数据和多个构造的正常数据，通过可调的平滑率进行学习，实现更稳定的知识遗忘并更好地保留模型效用。理论上，SGA提供了选择最优平滑率的指导。

Result: 在TOFU、Harry Potter和MUSE-NEWS三个基准测试上，SGA在所有指标上持续优于梯度上升法，并在若干关键指标上达到所有基线方法的最高前两名。

Conclusion: SGA是一种有效且稳定的LLM知识遗忘方法，相比现有技术能更好地平衡知识遗忘和模型效用保留。

Abstract: LLM unlearning has emerged as a promising approach, aiming to enable models
to forget hazardous/undesired knowledge at low cost while preserving as much
model utility as possible. Among existing techniques, the most straightforward
method is performing Gradient Ascent (GA) w.r.t. the forget data, thereby
forcing the model to unlearn the forget dataset. However, GA suffers from
severe instability, as it drives updates in a divergent direction, often
resulting in drastically degraded model utility. To address this issue, we
propose Smoothed Gradient Ascent (SGA). SGA combines the forget data with
multiple constructed normal data through a tunable smoothing rate. Intuitively,
this extends GA from learning solely on the forget data to jointly learning
across both forget and normal data, enabling more stable unlearning while
better preserving model utility. Theoretically, we provide the theoretical
guidance on the selection of the optimal smoothing rate. Empirically, we
evaluate SGA on three benchmarks: TOFU, Harry Potter, and MUSE-NEWS.
Experimental results demonstrate that SGA consistently outperforms the original
Gradient Ascent (GA) method across all metrics and achieves top-2 performance
among all baseline methods on several key metrics.

</details>


### [659] [Dynamic Dropout: Leveraging Conway's Game of Life for Neural Networks Regularization](https://arxiv.org/abs/2510.22383)
*David Freire-Obregón,José Salas-Cáceres,Modesto Castrillón-Santana*

Main category: cs.LG

TL;DR: 一种使用生命游戏作为正则化技术的新方法，可以动态地禁用神经网络单元，并可能提供比传统方法更好的可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统的Dropout正则化技术虽然有效，但存在静态和缺乏可解释性的缺点。本研究旨在提出一种新的正则化方法，以克服这些限制。

Method: 本研究将神经网络单元表示为生命游戏（GoL）网格中的单元，并应用GoL规则来动态地禁用单元，从而在训练过程中引入单元失活。

Result: 在CIFAR-10数据集上的实验表明，使用GoL的动态单元失活在性能上可与传统Dropout相媲美，并且可以通过可视化演变模式来提供对网络行为的见解。此外，该方法还增强了不同Dropout技术在更深层网络中的性能。

Conclusion: 本研究提出了一种使用生命游戏进行动态单元失活的创新正则化方法，其性能可与Dropout媲美，并具有更好的可解释性，有望应用于更深层的神经网络架构。

Abstract: Regularization techniques play a crucial role in preventing overfitting and
improving the generalization performance of neural networks. Dropout, a widely
used regularization technique, randomly deactivates units during training to
introduce redundancy and prevent co-adaptation among neurons. Despite its
effectiveness, dropout has limitations, such as its static nature and lack of
interpretability. In this paper, we propose a novel approach to regularization
by substituting dropout with Conway's Game of Life (GoL), a cellular automata
with simple rules that govern the evolution of a grid of cells. We introduce
dynamic unit deactivation during training by representing neural network units
as cells in a GoL grid and applying the game's rules to deactivate units. This
approach allows for the emergence of spatial patterns that adapt to the
training data, potentially enhancing the network's ability to generalize. We
demonstrate the effectiveness of our approach on the CIFAR-10 dataset, showing
that dynamic unit deactivation using GoL achieves comparable performance to
traditional dropout techniques while offering insights into the network's
behavior through the visualization of evolving patterns. Furthermore, our
discussion highlights the applicability of our proposal in deeper
architectures, demonstrating how it enhances the performance of different
dropout techniques.

</details>


### [660] [Knowledge-guided Continual Learning for Behavioral Analytics Systems](https://arxiv.org/abs/2510.22405)
*Yasas Senarath,Hemant Purohit*

Main category: cs.LG

TL;DR: 在线平台用户行为变化导致模型性能下降，灾难性遗忘问题阻碍了模型更新。本文提出一种利用外部知识库进行数据增强的持续学习方法，通过在重放缓冲区中加入增强数据来克服固定缓冲区大小的限制，并在处理偏差行为分类任务时优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 在线平台用户行为的演变，包括有用信息和仇恨言论的发布，会导致用于分析这些行为的模型性能随时间下降（数据漂移）。然而，直接用新数据对模型进行微调可能会导致灾难性遗忘。

Method: 提出一种新颖的数据增强方法，将外部知识整合到基于重放的持续学习框架中。该方法利用外部知识库来扩充重放缓冲区中的数据，以克服固定缓冲区大小的限制，并最大限度地减少灾难性遗忘。

Result: 在三个与偏差行为分类相关的基准数据集上进行评估，证明了所提出的数据增强方法在持续学习框架中优于基线重放方法。

Conclusion: 通过利用外部知识进行数据增强，可以有效缓解基于重放的持续学习方法中固定缓冲区大小的限制，并提高模型在处理随时间变化的用户行为数据时的性能。

Abstract: User behavior on online platforms is evolving, reflecting real-world changes
in how people post, whether it's helpful messages or hate speech. Models that
learn to capture this content can experience a decrease in performance over
time due to data drift, which can lead to ineffective behavioral analytics
systems. However, fine-tuning such a model over time with new data can be
detrimental due to catastrophic forgetting. Replay-based approaches in
continual learning offer a simple yet efficient method to update such models,
minimizing forgetting by maintaining a buffer of important training instances
from past learned tasks. However, the main limitation of this approach is the
fixed size of the buffer. External knowledge bases can be utilized to overcome
this limitation through data augmentation. We propose a novel
augmentation-based approach to incorporate external knowledge in the
replay-based continual learning framework. We evaluate several strategies with
three datasets from prior studies related to deviant behavior classification to
assess the integration of external knowledge in continual learning and
demonstrate that augmentation helps outperform baseline replay-based
approaches.

</details>


### [661] [Low-Precision Streaming PCA](https://arxiv.org/abs/2510.22440)
*Sanjoy Dasgupta,Syamantak Kumar,Shourya Pandey,Purnamrita Sarkar*

Main category: cs.LG

TL;DR: 低精度流式PCA算法在有限精度下估计流式设置中的主成分。


<details>
  <summary>Details</summary>
Motivation: 在有限精度下，研究流式PCA算法估计主成分的问题。

Method: 研究Oja算法在混合线性和非线性随机量化下的流式PCA，并证明了该算法在温和的矩和谱隙假设下可以达到信息论下界。

Result: 在非线性量化下，实现了近乎与维度无关的量化误差，并在合成数据流上验证了理论结果。

Conclusion: 低精度流式PCA方法可以紧密跟踪标准Oja算法的性能。

Abstract: Low-precision streaming PCA estimates the top principal component in a
streaming setting under limited precision. We establish an
information-theoretic lower bound on the quantization resolution required to
achieve a target accuracy for the leading eigenvector. We study Oja's algorithm
for streaming PCA under linear and nonlinear stochastic quantization. The
quantized variants use unbiased stochastic quantization of the weight vector
and the updates. Under mild moment and spectral-gap assumptions on the data
distribution, we show that a batched version achieves the lower bound up to
logarithmic factors under both schemes. This leads to a nearly dimension-free
quantization error in the nonlinear quantization setting. Empirical evaluations
on synthetic streams validate our theoretical findings and demonstrate that our
low-precision methods closely track the performance of standard Oja's
algorithm.

</details>


### [662] [SmartMixed: A Two-Phase Training Strategy for Adaptive Activation Function Learning in Neural Networks](https://arxiv.org/abs/2510.22450)
*Amin Omidvar*

Main category: cs.LG

TL;DR: 提出了一种名为SmartMixed的训练策略，允许神经网络为每个神经元学习最优的激活函数，同时在推理时保持计算效率。


<details>
  <summary>Details</summary>
Motivation: 大多数神经网络架构在所有神经元上依赖固定的、统一的激活函数，但激活函数的选择对神经网络至关重要。

Method: SmartMixed策略分两个阶段进行训练：第一阶段，神经元使用可微的硬混合机制自适应地从候选激活函数池（ReLU、Sigmoid、Tanh、Leaky ReLU、ELU、SELU）中选择；第二阶段，确定每个神经元的激活函数，从而得到计算效率高的网络，并支持使用优化的向量化操作进行持续训练。

Result: 在MNIST数据集上，使用不同深度的前馈神经网络对SmartMixed进行了评估，结果表明不同层中的神经元对激活函数表现出不同的偏好，揭示了神经网络内部的功能多样性。

Conclusion: SmartMixed能够为每个神经元学习到最优的激活函数，并实现计算效率和模型性能的平衡。

Abstract: The choice of activation function plays a critical role in neural networks,
yet most architectures still rely on fixed, uniform activation functions across
all neurons. We introduce SmartMixed, a two-phase training strategy that allows
networks to learn optimal per-neuron activation functions while preserving
computational efficiency at inference. In the first phase, neurons adaptively
select from a pool of candidate activation functions (ReLU, Sigmoid, Tanh,
Leaky ReLU, ELU, SELU) using a differentiable hard-mixture mechanism. In the
second phase, each neuron's activation function is fixed according to the
learned selection, resulting in a computationally efficient network that
supports continued training with optimized vectorized operations. We evaluate
SmartMixed on the MNIST dataset using feedforward neural networks of varying
depths. The analysis shows that neurons in different layers exhibit distinct
preferences for activation functions, providing insights into the functional
diversity within neural architectures.

</details>


### [663] [GraphTOP: Graph Topology-Oriented Prompting for Graph Neural Networks](https://arxiv.org/abs/2510.22451)
*Xingbo Fu,Zhenyu Lei,Zihan Chen,Binchi Zhang,Chuxu Zhang,Jundong Li*

Main category: cs.LG

TL;DR: 图提示（graph prompting）是一种有效的策略，通过修改输入图数据来适应预训练的图神经网络（GNN）。现有的方法主要关注特征导向的提示，但忽略了拓扑导向提示的潜力。本研究提出了首个图拓扑导向提示（GraphTOP）框架，将拓扑导向提示视为一个边缘重连问题，并通过重新参数化将其松弛到连续概率空间，同时保持图的稀疏性。实验证明，GraphTOP在节点分类任务上优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有的图提示（graph prompting）方法主要关注特征导向的提示，忽略了拓扑导向提示的潜力，导致在适应预训练的图神经网络（GNN）到下游任务时性能不佳。

Method: 将拓扑导向提示重新定义为多跳局部子图中的边缘重连问题，并通过重参数化松弛到连续概率空间，同时保证松弛的紧密性和图的稀疏性。

Result: 在五个图数据集和四种预训练策略下进行的大量实验表明，提出的GraphTOP框架在多个节点分类数据集上优于六种基线方法。

Conclusion: GraphTOP是首个图拓扑导向提示框架，通过将边缘重连问题松弛到连续概率空间，有效适应了预训练的GNN模型，并在节点分类任务上取得了优于现有方法的性能。

Abstract: Graph Neural Networks (GNNs) have revolutionized the field of graph learning
by learning expressive graph representations from massive graph data. As a
common pattern to train powerful GNNs, the "pre-training, adaptation" scheme
first pre-trains GNNs over unlabeled graph data and subsequently adapts them to
specific downstream tasks. In the adaptation phase, graph prompting is an
effective strategy that modifies input graph data with learnable prompts while
keeping pre-trained GNN models frozen. Typically, existing graph prompting
studies mainly focus on *feature-oriented* methods that apply graph prompts to
node features or hidden representations. However, these studies often achieve
suboptimal performance, as they consistently overlook the potential of
*topology-oriented* prompting, which adapts pre-trained GNNs by modifying the
graph topology. In this study, we conduct a pioneering investigation of graph
prompting in terms of graph topology. We propose the first **Graph**
**T**opology-**O**riented **P**rompting (GraphTOP) framework to effectively
adapt pre-trained GNN models for downstream tasks. More specifically, we
reformulate topology-oriented prompting as an edge rewiring problem within
multi-hop local subgraphs and relax it into the continuous probability space
through reparameterization while ensuring tight relaxation and preserving graph
sparsity. Extensive experiments on five graph datasets under four pre-training
strategies demonstrate that our proposed GraphTOP outshines six baselines on
multiple node classification datasets. Our code is available at
https://github.com/xbfu/GraphTOP.

</details>


### [664] [Backward-Friendly Optimization: Training Large Language Models with Approximate Gradients under Memory Constraints](https://arxiv.org/abs/2510.22467)
*Jing Yang,Kaitong Cai,Yijia Fan,Yufeng Yang,Keze Wang*

Main category: cs.LG

TL;DR: GradLite 是一种内存效率高的优化器，通过低秩雅可比近似和误差反馈校正来减少 LLM 训练中的内存消耗，同时保持收敛性。


<details>
  <summary>Details</summary>
Motivation: 全参数微调大型语言模型（LLMs）内存消耗巨大，现有方法要么改变模型结构，要么增加计算量来节省内存，但优化器本身未被改进。

Method: GradLite 是一种向后兼容的优化器，它放宽了对精确梯度的要求。它使用两种关键技术：（1）低秩雅可比近似，以降低反向传播的误差信号的维度；（2）误差反馈校正，跨迭代累积并补偿近似误差，以保持收敛保证。

Result: GradLite 在不改变模型架构的情况下，将优化器状态和激活内存消耗减少了高达 50%。在推理、多语言和对话基准测试上，其性能与 checkpointing 和其他优化器（LoMo, GaLore）相当或更优。

Conclusion: GradLite 通过低秩雅可比近似和误差反馈校正，在不牺牲模型性能的情况下，显著降低了 LLM 训练的内存需求，为更高效的 LLM 微调提供了新的解决方案。

Abstract: Full fine-tuning of Large Language Models (LLMs) is notoriously
memory-intensive, primarily because conventional optimizers such as SGD or Adam
assume access to exact gradients derived from cached activations. Existing
solutions either alter the model architecture (e.g., reversible networks) or
trade memory for computation (e.g., activation checkpointing), but the
optimizer itself remains untouched. In this work, we introduce GradLite, a
backward-friendly optimizer that relaxes the requirement of exact gradients,
enabling efficient training even when intermediate activations are aggressively
discarded or approximated. GradLite leverages two key techniques: (i) low-rank
Jacobian approximation, which reduces the dimensionality of backpropagated
error signals, and (ii) error-feedback correction, which accumulates and
compensates approximation errors across iterations to preserve convergence
guarantees. We provide a theoretical analysis showing that GradLite maintains
unbiased gradient estimates with bounded variance, ensuring convergence rates
comparable to Adam. Empirically, GradLite reduces optimizer-state and
activation memory consumption by up to 50\% without architectural changes, and
achieves on-par or superior downstream performance on reasoning (MMLU, GSM8K),
multilingual, and dialogue benchmarks compared to checkpointing and
optimizer-centric baselines (LoMo, GaLore).

</details>


### [665] [Contextual Tokenization for Graph Inverted Indices](https://arxiv.org/abs/2510.22479)
*Pritish Chakraborty,Indradyumna Roy,Soumen Chakrabarti,Abir De*

Main category: cs.LG

TL;DR: CORGII是一个图索引框架，它将稠密的图表示转换为稀疏的二进制码，以便利用倒排索引进行高效检索，并在准确性和效率之间提供了更好的权衡。


<details>
  <summary>Details</summary>
Motivation: 现有的图检索方法需要对语料库中的图进行详尽的评分，效率低下。

Method: CORGII首先将图表示为上下文稠密的图表示，然后通过可微分离散化模块计算稀疏二元码。这种类文本表示允许使用倒排索引，并支持软集包含分数。此外，CORGII还引入了可训练的词汇影响权重，并探索了词汇扩展以实现更平滑的准确性-效率权衡。

Result: CORGII在准确性和效率之间提供了比现有基线更好的权衡。

Conclusion: CORGII是第一个使用离散词汇映射到高效倒排列表的稠密图表示索引器，在图检索方面取得了显著的进步。

Abstract: Retrieving graphs from a large corpus, that contain a subgraph isomorphic to
a given query graph, is a core operation in many real-world applications. While
recent multi-vector graph representations and scores based on set alignment and
containment can provide accurate subgraph isomorphism tests, their use in
retrieval remains limited by their need to score corpus graphs exhaustively. We
introduce CORGII (Contextual Representation of Graphs for Inverted Indexing), a
graph indexing framework in which, starting with a contextual dense graph
representation, a differentiable discretization module computes sparse binary
codes over a learned latent vocabulary. This text document-like representation
allows us to leverage classic, highly optimized inverted indices, while
supporting soft (vector) set containment scores. Pushing this paradigm further,
we replace the classical, fixed impact weight of a `token' on a graph (such as
TFIDF or BM25) with a data-driven, trainable impact weight. Finally, we explore
token expansion to support multi-probing the index for smoother
accuracy-efficiency tradeoffs. To our knowledge, CORGII is the first indexer of
dense graph representations using discrete tokens mapping to efficient inverted
lists. Extensive experiments show that CORGII provides better trade-offs
between accuracy and efficiency, compared to several baselines.

</details>


### [666] [LAMP: Data-Efficient Linear Affine Weight-Space Models for Parameter-Controlled 3D Shape Generation and Extrapolation](https://arxiv.org/abs/2510.22491)
*Ghadi Nehme,Yanxia Zhang,Dule Shu,Matt Klenk,Faez Ahmed*

Main category: cs.LG

TL;DR: LAMP是一个高效的3D生成框架，无需大量数据即可进行可控、可解释的3D几何生成，并能在参数约束下实现安全的外插和优化。


<details>
  <summary>Details</summary>
Motivation: 当前3D生成方法依赖大量数据，且在可控性和泛化性方面存在不足。本研究旨在克服这些局限性，提出一种数据高效、可控且可解释的3D生成框架。

Method: LAMP首先通过过拟合共享初始化中的每个示例来对SDF解码器进行对齐，然后通过解决对齐权重空间中的参数约束混合问题来合成新几何。此外，还提出了一种通过线性不匹配检测几何有效性的安全度量。

Result: LAMP在DrivAerNet++和BlendedNet两个3D参数基准上进行了评估，结果表明：(i) 在仅有100个样本的情况下，可以在边界内进行受控插值；(ii) 可以安全地超出训练范围高达100%的参数差异进行外插；(iii) 可以在固定参数下进行物理性能引导优化。LAMP在数据效率和外插能力方面显著优于条件自编码器和深度网络插值（DNI）基线。

Conclusion: LAMP在可控、数据高效和安全的3D生成方面取得了进展，可应用于设计探索、数据集生成和性能驱动优化。

Abstract: Generating high-fidelity 3D geometries that satisfy specific parameter
constraints has broad applications in design and engineering. However, current
methods typically rely on large training datasets and struggle with
controllability and generalization beyond the training distributions. To
overcome these limitations, we introduce LAMP (Linear Affine Mixing of
Parametric shapes), a data-efficient framework for controllable and
interpretable 3D generation. LAMP first aligns signed distance function (SDF)
decoders by overfitting each exemplar from a shared initialization, then
synthesizes new geometries by solving a parameter-constrained mixing problem in
the aligned weight space. To ensure robustness, we further propose a safety
metric that detects geometry validity via linearity mismatch. We evaluate LAMP
on two 3D parametric benchmarks: DrivAerNet++ and BlendedNet. We found that
LAMP enables (i) controlled interpolation within bounds with as few as 100
samples, (ii) safe extrapolation by up to 100% parameter difference beyond
training ranges, (iii) physics performance-guided optimization under fixed
parameters. LAMP significantly outperforms conditional autoencoder and Deep
Network Interpolation (DNI) baselines in both extrapolation and data
efficiency. Our results demonstrate that LAMP advances controllable,
data-efficient, and safe 3D generation for design exploration, dataset
generation, and performance-driven optimization.

</details>


### [667] [Scalable Oversight via Partitioned Human Supervision](https://arxiv.org/abs/2510.22500)
*Ren Yin,Takashi Ishida,Masashi Sugiyama*

Main category: cs.LG

TL;DR: 人类专家难以评估多领域AI的超越性任务，提出基于互补标签的弱监督框架，可不依赖真实标签评估和训练AI。


<details>
  <summary>Details</summary>
Motivation: 随着AI在多领域任务上超越人类专家，获取高质量的人类监督用于评估和训练变得愈发困难，尤其是在需要多领域深度知识和技能的任务上。

Method: 提出一个可扩展的监督框架，利用人类专家提供的互补标签（指出不正确选项的弱信号）来评估前沿AI系统，无需准备真实标签。推导出基于互补标签的无偏顶1准确率估计量，并量化所需互补标签数量以匹配普通标签的方差。引入两个估计量结合稀疏的普通标签和大量的互补标签。为仅互补标签和混合估计量提供有限样本偏差保证。

Result: 在经验上，证明了在拥有互补标签的情况下，可以不依赖真实标签评估大型语言模型的输出。进一步证明了可以使用这种弱信号训练AI系统，并设计了一个能够更好利用这种分区人类监督的智能体AI系统。

Conclusion: 提出的基于互补标签的弱监督框架能够有效解决多领域AI评估和训练中的挑战，实现无需真实标签的AI评估和训练。

Abstract: As artificial intelligence (AI) systems approach and surpass expert human
performance across a broad range of tasks, obtaining high-quality human
supervision for evaluation and training becomes increasingly challenging. Our
focus is on tasks that require deep knowledge and skills of multiple domains.
Unfortunately, even the best human experts are knowledgeable only in a single
narrow area, and will not be able to evaluate the correctness of advanced AI
systems on such superhuman tasks. However, based on their narrow expertise,
humans may provide a weak signal, i.e., a complementary label indicating an
option that is incorrect. For example, a cardiologist could state that "this is
not related to cardiology,'' even if they cannot identify the true disease.
Based on this weak signal, we propose a scalable oversight framework that
enables us to evaluate frontier AI systems without the need to prepare the
ground truth. We derive an unbiased estimator of top-1 accuracy from
complementary labels and quantify how many complementary labels are needed to
match the variance of ordinary labels. We further introduce two estimators to
combine scarce ordinary labels with abundant complementary labels. We provide
finite-sample deviation guarantees for both complementary-only and the mixed
estimators. Empirically, we show that we can evaluate the output of large
language models without the ground truth, if we have complementary labels. We
further show that we can train an AI system with such weak signals: we show how
we can design an agentic AI system automatically that can perform better with
this partitioned human supervision. Our code is available at
https://github.com/R-Yin-217/Scalable-Oversight-via-Human-Partitioned-Supervision.

</details>


### [668] [CANDI: Hybrid Discrete-Continuous Diffusion Models](https://arxiv.org/abs/2510.22510)
*Patrick Pynadath,Jiaxin Shi,Ruqi Zhang*

Main category: cs.LG

TL;DR: 连续扩散模型在图像生成等连续域表现优异，但在离散域表现不佳。本文提出CANDI混合框架，通过解耦离散和连续噪声，实现对条件结构和连续几何的同时学习，解决了离散数据扩散的挑战，并在文本生成等任务上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 连续扩散模型在离散数据上的应用表现不佳，这与它们能够学习跨越多个位置的联合演化能力相矛盾。需要理解这种差距的原因并提出解决方案。

Method: 提出“token identifiability”分析框架，区分离散身份腐蚀和连续秩退化两种噪声机制。提出CANDI（Continuous ANd Discrete diffusion）混合框架，解耦离散和连续噪声，同时学习条件结构和连续几何。

Result: 经验上验证了“temporal dissonance”现象。证明CANDI可以有效避免此现象。CANDI在可控生成任务上支持使用现成分类器进行引导，在文本生成任务上，特别是在低NFE（num_fuction_evaluations）时，性能优于masked diffusion。

Conclusion: CANDI混合框架成功地解决了连续扩散模型在离散数据上的应用挑战，通过解耦噪声机制并同时学习条件结构和连续几何，实现了在文本生成等任务上的性能提升。

Abstract: While continuous diffusion has shown remarkable success in continuous domains
such as image generation, its direct application to discrete data has
underperformed compared to purely discrete formulations. This gap is
counterintuitive, given that continuous diffusion learns score functions that
enable joint evolution across multiple positions. To understand this gap, we
introduce token identifiability as an analytical framework for understanding
how Gaussian noise corrupts discrete data through two mechanisms: discrete
identity corruption and continuous rank degradation. We reveal that these
mechanisms scale differently with vocabulary size, creating a temporal
dissonance: at noise levels where discrete corruption preserves enough
structure for conditional learning, continuous denoising is trivial; at noise
levels where continuous denoising is meaningful, discrete corruption destroys
nearly all conditional structure. To solve this, we propose CANDI (Continuous
ANd DIscrete diffusion), a hybrid framework that decouples discrete and
continuous corruption, enabling simultaneous learning of both conditional
structure and continuous geometry. We empirically validate the temporal
dissonance phenomenon and demonstrate that CANDI successfully avoids it. This
unlocks the benefits of continuous diffusion for discrete spaces: on controlled
generation, CANDI enables classifier-based guidance with off-the-shelf
classifiers through simple gradient addition; on text generation, CANDI
outperforms masked diffusion at low NFE, demonstrating the value of learning
continuous gradients for discrete spaces.

</details>


### [669] [Transitive RL: Value Learning via Divide and Conquer](https://arxiv.org/abs/2510.22512)
*Seohong Park,Aditya Oberai,Pranav Atreya,Sergey Levine*

Main category: cs.LG

TL;DR: Transitive Reinforcement Learning (TRL) 是一种新的基于分而治之范式的价值学习算法，适用于离线目标条件强化学习（GCRL）问题，可以从任何状态到达任何状态，步数最少。


<details>
  <summary>Details</summary>
Motivation: TRL 旨在解决离线目标条件强化学习（GCRL）问题，该问题旨在找到一个策略，能够以最少的步数从任何状态到达任何状态。

Method: TRL 利用 GCRL 中的三角不等式结构，将其转换为实用的分而治之价值更新规则。与 TD 方法相比，TRL 的偏差累积较少，因为它只需要 O(log T) 次递归即可处理长度为 T 的轨迹，而 TD 学习需要 O(T) 次。与蒙特卡洛方法相比，TRL 的方差较低，因为它执行动态规划。

Result: 实验结果表明，与以前的离线 GCRL 算法相比，TRL 在具有挑战性的长视野基准任务中取得了最佳性能。

Conclusion: TRL 算法在离线 GCRL 问题上表现优越，尤其是在长视野任务中。

Abstract: In this work, we present Transitive Reinforcement Learning (TRL), a new value
learning algorithm based on a divide-and-conquer paradigm. TRL is designed for
offline goal-conditioned reinforcement learning (GCRL) problems, where the aim
is to find a policy that can reach any state from any other state in the
smallest number of steps. TRL converts a triangle inequality structure present
in GCRL into a practical divide-and-conquer value update rule. This has several
advantages compared to alternative value learning paradigms. Compared to
temporal difference (TD) methods, TRL suffers less from bias accumulation, as
in principle it only requires $O(\log T)$ recursions (as opposed to $O(T)$ in
TD learning) to handle a length-$T$ trajectory. Unlike Monte Carlo methods, TRL
suffers less from high variance as it performs dynamic programming.
Experimentally, we show that TRL achieves the best performance in highly
challenging, long-horizon benchmark tasks compared to previous offline GCRL
algorithms.

</details>


### [670] [Toward Robust Signed Graph Learning through Joint Input-Target Denoising](https://arxiv.org/abs/2510.22513)
*Junran Wu,Beng Chin Ooi,Ke Xu*

Main category: cs.LG

TL;DR: RIDGE是一个新颖的框架，通过联合去噪图输入和监督目标来提高有符号图表示学习的鲁棒性，它将图信息瓶颈理论扩展到目标空间去噪，并在四个标准数据集上证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 鉴于现实世界连接的噪声性质，SGNN的鲁棒性已成为一个重要的研究领域，但缺乏具有理论指导的鲁棒SGNN研究。

Method: 提出了一种名为RIDGE的新颖框架，通过联合去噪图输入和监督目标来学习鲁棒的有符号图表示。该框架将图信息瓶颈（GIB）理论扩展到目标空间去噪，并使用重参数化和变分近似来优化目标函数。

Result: 在四个流行的有符号图数据集上的广泛验证表明，RIDGE在各种噪声水平下都能显著提高流行的SGNN模型的鲁棒性。

Conclusion: RIDGE通过联合去噪输入和目标，有效地提高了有符号图表示学习的鲁棒性，为相关研究提供了理论指导和实证支持。

Abstract: Signed Graph Neural Networks (SGNNs) are widely adopted to analyze complex
patterns in signed graphs with both positive and negative links. Given the
noisy nature of real-world connections, the robustness of SGNN has also emerged
as a pivotal research area. Under the supervision of empirical properties,
graph structure learning has shown its robustness on signed graph
representation learning, however, there remains a paucity of research
investigating a robust SGNN with theoretical guidance. Inspired by the success
of graph information bottleneck (GIB) in information extraction, we propose
RIDGE, a novel framework for Robust sI gned graph learning through joint
Denoising of Graph inputs and supervision targEts. Different from the basic
GIB, we extend the GIB theory with the capability of target space denoising as
the co-existence of noise in both input and target spaces. In instantiation,
RIDGE effectively cleanses input data and supervision targets via a tractable
objective function produced by reparameterization mechanism and variational
approximation. We extensively validate our method on four prevalent signed
graph datasets, and the results show that RIDGE clearly improves the robustness
of popular SGNN models under various levels of noise.

</details>


### [671] [A Scalable Global Optimization Algorithm For Constrained Clustering](https://arxiv.org/abs/2510.22519)
*Pedro Chumpitaz-Flores,My Duong,Cristobal Heredia,Kaixun Hua*

Main category: cs.LG

TL;DR: SDC-GBB框架通过样本驱动的约束分组分支定界方法，解决了大规模数据集上的约束聚类问题，实现了可扩展且全局最优的聚类。


<details>
  <summary>Details</summary>
Motivation: 现有混合整数优化方法在处理大规模数据集的约束聚类（尤其是必须链接和禁止链接约束）时面临NP难题，效率低下。

Method: 提出了一种可分解的分支定界（BB）框架，称为SDC-GBB，该框架通过将必须链接的样本折叠成基于质心的伪样本，并利用几何规则剪枝禁止链接的样本，来处理约束。它集成了分组样本拉格朗日分解和几何消除规则，以实现高效的上下界估计，并通过并行化实现可扩展的k-Means约束聚类。

Result: 该方法能够处理包含200,000个样本（带禁止链接约束）和1,500,000个样本（带必须链接约束）的数据集，其规模是现有最先进方法的200-1500倍，同时保持小于3%的最优性差距。此外，该方法避免了启发式算法在大规模数据集上常见的搜索失败问题，并提供了确定的全局最优保证。

Conclusion: SDC-GBB框架是一种可扩展且能保证全局最优的约束聚类方法，能够有效解决大规模数据集上的挑战，克服了现有方法的局限性。

Abstract: Constrained clustering leverages limited domain knowledge to improve
clustering performance and interpretability, but incorporating pairwise
must-link and cannot-link constraints is an NP-hard challenge, making global
optimization intractable. Existing mixed-integer optimization methods are
confined to small-scale datasets, limiting their utility. We propose
Sample-Driven Constrained Group-Based Branch-and-Bound (SDC-GBB), a
decomposable branch-and-bound (BB) framework that collapses must-linked samples
into centroid-based pseudo-samples and prunes cannot-link through geometric
rules, while preserving convergence and guaranteeing global optimality. By
integrating grouped-sample Lagrangian decomposition and geometric elimination
rules for efficient lower and upper bounds, the algorithm attains highly
scalable pairwise k-Means constrained clustering via parallelism. Experimental
results show that our approach handles datasets with 200,000 samples with
cannot-link constraints and 1,500,000 samples with must-link constraints, which
is 200 - 1500 times larger than the current state-of-the-art under comparable
constraint settings, while reaching an optimality gap of less than 3%. In
providing deterministic global guarantees, our method also avoids the search
failures that off-the-shelf heuristics often encounter on large datasets.

</details>


### [672] [Random Search Neural Networks for Efficient and Expressive Graph Learning](https://arxiv.org/abs/2510.22520)
*Michael Ito,Danai Koutra,Jenna Wiens*

Main category: cs.LG

TL;DR: RWNNs在图表示学习中很有前景，但受限于采样效率。我们提出了RSNNs，它通过随机搜索保证节点覆盖，理论上显著降低了采样复杂度，并具备通用逼近能力和同构不变性。实验证明RSNNs在分子和蛋白质数据集上优于RWNNs，采样效率更高。


<details>
  <summary>Details</summary>
Motivation: 现有的随机游走神经网络（RWNNs）在实际采样约束下，即使在小图上，也常常因为节点和边的覆盖不全而无法捕捉全局结构，限制了其表达能力。

Method: 提出了一种名为“随机搜索神经网络”（RSNNs）的新方法，该方法基于随机搜索，保证了节点覆盖的完整性。理论上证明了在稀疏图中，仅需O(log|V|)次搜索即可覆盖所有边，远少于RWNNs所需的O(|V|)次随机游走（假设游走长度随图大小扩展）。当与通用序列模型结合时，RSNNs能够成为通用逼近器。此外，RSNNs在概率上对图同构具有不变性，确保了其期望成为图同构不变函数。

Result: RSNNs在分子和蛋白质基准测试中持续优于RWNNs，在采样序列数量减少高达16倍的情况下，实现了相当或更优的性能。

Conclusion: RSNNs提供了一个更高效、更具表达力的图学习框架，特别是在稀疏图上，弥补了随机游走方法的理论和实践上的不足。

Abstract: Random walk neural networks (RWNNs) have emerged as a promising approach for
graph representation learning, leveraging recent advances in sequence models to
process random walks. However, under realistic sampling constraints, RWNNs
often fail to capture global structure even in small graphs due to incomplete
node and edge coverage, limiting their expressivity. To address this, we
propose \textit{random search neural networks} (RSNNs), which operate on random
searches, each of which guarantees full node coverage. Theoretically, we
demonstrate that in sparse graphs, only $O(\log |V|)$ searches are needed to
achieve full edge coverage, substantially reducing sampling complexity compared
to the $O(|V|)$ walks required by RWNNs (assuming walk lengths scale with graph
size). Furthermore, when paired with universal sequence models, RSNNs are
universal approximators. We lastly show RSNNs are probabilistically invariant
to graph isomorphisms, ensuring their expectation is an isomorphism-invariant
graph function. Empirically, RSNNs consistently outperform RWNNs on molecular
and protein benchmarks, achieving comparable or superior performance with up to
16$\times$ fewer sampled sequences. Our work bridges theoretical and practical
advances in random walk based approaches, offering an efficient and expressive
framework for learning on sparse graphs.

</details>


### [673] [Iteratively Refined Early Interaction Alignment for Subgraph Matching based Graph Retrieval](https://arxiv.org/abs/2510.22538)
*Ashwin Ramachandran,Vaibhav Raj,Indrayumna Roy,Soumen Chakrabarti,Abir De*

Main category: cs.LG

TL;DR: IsoNet++ 是一种基于 GNN 的图检索方法，通过引入节点对交互、可更新的对齐和分层 GNN 来改进 IsoNet。


<details>
  <summary>Details</summary>
Motivation: 在图检索、分子指纹检测和电路设计等领域，基于子图同构的图检索具有广泛的应用前景。现有方法如 IsoNet 在计算节点和边嵌入后才进行可训练的对齐映射，但仍有改进空间。

Method: IsoNet++ 采用早期交互 GNN 方法，包含三项主要创新：1. 通过跨图消息传递和节点对齐来计算节点嵌入；2. 采用分层 GNN 和延迟更新机制，在多轮中逐步优化节点对齐；3. 引入节点对交互机制，利用图中节点对之间是否存在边来细化对齐。

Result: 在多个数据集上的实验表明，IsoNet++ 的对齐映射随着训练轮次的增加而逐步优化，检索性能显著优于现有方法，并且三项创新技术都对性能提升做出了贡献。

Conclusion: IsoNet++ 通过其创新的早期交互 GNN 方法，在子图同构图检索任务上取得了显著的性能提升，证明了其有效性。

Abstract: Graph retrieval based on subgraph isomorphism has several real-world
applications such as scene graph retrieval, molecular fingerprint detection and
circuit design. Roy et al. [35] proposed IsoNet, a late interaction model for
subgraph matching, which first computes the node and edge embeddings of each
graph independently of paired graph and then computes a trainable alignment
map. Here, we present IsoNet++, an early interaction graph neural network
(GNN), based on several technical innovations. First, we compute embeddings of
all nodes by passing messages within and across the two input graphs, guided by
an injective alignment between their nodes. Second, we update this alignment in
a lazy fashion over multiple rounds. Within each round, we run a layerwise GNN
from scratch, based on the current state of the alignment. After the completion
of one round of GNN, we use the last-layer embeddings to update the alignments,
and proceed to the next round. Third, IsoNet++ incorporates a novel notion of
node-pair partner interaction. Traditional early interaction computes attention
between a node and its potential partners in the other graph, the attention
then controlling messages passed across graphs. In contrast, we consider node
pairs (not single nodes) as potential partners. Existence of an edge between
the nodes in one graph and non-existence in the other provide vital signals for
refining the alignment. Our experiments on several datasets show that the
alignments get progressively refined with successive rounds, resulting in
significantly better retrieval performance than existing methods. We
demonstrate that all three innovations contribute to the enhanced accuracy. Our
code and datasets are publicly available at
https://github.com/structlearning/isonetpp.

</details>


### [674] [FAPO: Flawed-Aware Policy Optimization for Efficient and Reliable Reasoning](https://arxiv.org/abs/2510.22543)
*Yuyang Ding,Chi Zhang,Juntao Li,Haibin Lin,Xin Liu,Min Zhang*

Main category: cs.LG

TL;DR: RLVR方法在LLM推理中存在问题，FAPO通过引入罚分来解决，GenRM用于检测错误。


<details>
  <summary>Details</summary>
Motivation: RLVR方法在LLM推理中虽然有潜力，但可能导致模型学习到不完全正确的推理模式，从而影响长期表现。

Method: 提出FAPO方法，对可能包含错误或不完全正确推理过程的“flawed-positive rollouts”进行参数无关的奖励惩罚，并引入GenRM（生成奖励模型）来精确识别和定位推理错误。

Result: FAPO能在不增加token预算的情况下，提高LLM推理的准确性、过程可靠性，并增强训练稳定性。

Conclusion: FAPO是一种有效的解决RLVR方法中“flawed-positive rollouts”问题的方案，能够平衡早期快速学习和后期可靠推理的需求。

Abstract: Reinforcement learning with verifiable rewards (RLVR) has emerged as a
promising paradigm for enhancing the reasoning capabilities of large language
models (LLMs). In this context, models explore reasoning trajectories and
exploit rollouts with correct answers as positive signals for policy
optimization. However, these rollouts might involve flawed patterns such as
answer-guessing and jump-in-reasoning. Such flawed-positive rollouts are
rewarded identically to fully correct ones, causing policy models to
internalize these unreliable reasoning patterns. In this work, we first conduct
a systematic study of flawed-positive rollouts in RL and find that they enable
rapid capability gains during the early optimization stage, while constraining
reasoning capability later by reinforcing unreliable patterns. Building on
these insights, we propose Flawed-Aware Policy Optimization (FAPO), which
presents a parameter-free reward penalty for flawed-positive rollouts, enabling
the policy to leverage them as useful shortcuts in the warm-up stage, securing
stable early gains, while gradually shifting optimization toward reliable
reasoning in the later refinement stage. To accurately and comprehensively
detect flawed-positive rollouts, we introduce a generative reward model (GenRM)
with a process-level reward that precisely localizes reasoning errors.
Experiments show that FAPO is effective in broad domains, improving outcome
correctness, process reliability, and training stability without increasing the
token budget.

</details>


### [675] [DDTR: Diffusion Denoising Trace Recovery](https://arxiv.org/abs/2510.22553)
*Maximilian Matyash,Avigdor Gal,Arik Senderovich*

Main category: cs.LG

TL;DR: stochastic trace recovery for non-deterministic process logs using DDPM


<details>
  <summary>Details</summary>
Motivation: the need for stochastic trace recovery increases due to non-deterministic process logs from uncertain sources

Method: a novel deep learning approach based on Diffusion Denoising Probabilistic Models (DDPM) is designed to recover traces by denoising, utilizing process knowledge

Result: up to 25% improvement over existing methods and increased robustness under high noise levels

Conclusion: The proposed DDPM-based approach achieves state-of-the-art performance in stochastic trace recovery.

Abstract: With recent technological advances, process logs, which were traditionally
deterministic in nature, are being captured from non-deterministic sources,
such as uncertain sensors or machine learning models (that predict activities
using cameras). In the presence of stochastically-known logs, logs that contain
probabilistic information, the need for stochastic trace recovery increases, to
offer reliable means of understanding the processes that govern such systems.
We design a novel deep learning approach for stochastic trace recovery, based
on Diffusion Denoising Probabilistic Models (DDPM), which makes use of process
knowledge (either implicitly by discovering a model or explicitly by injecting
process knowledge in the training phase) to recover traces by denoising. We
conduct an empirical evaluation demonstrating state-of-the-art performance with
up to a 25% improvement over existing methods, along with increased robustness
under high noise levels.

</details>


### [676] [Combining Deep Learning and Explainable AI for Toxicity Prediction of Chemical Compounds](https://arxiv.org/abs/2510.22572)
*Eduard Popescu,Adrian Groza,Andreea Cernat*

Main category: cs.LG

TL;DR: 本研究提出了一种基于图像的计算毒理学方法，利用DenseNet121模型处理化学结构图，并通过Grad-CAM可视化技术增强模型的可解释性，在Tox21数据集上取得了有竞争力的预测结果。


<details>
  <summary>Details</summary>
Motivation: 预测化学物质的毒理活性，并探索结合图像表示和可解释AI方法以提高预测准确性和模型透明度的潜力。

Method: 使用DenseNet121模型处理化学结构的2D图形表示，并采用Grad-CAM可视化技术来解释模型的预测结果，突出对毒性分类有贡献的分子区域。

Result: 所提出的模型在Tox21数据集上取得了与传统模型相比具有竞争力的结果。

Conclusion: 结合图像表示和可解释AI方法在计算毒理学领域具有巨大潜力，能够同时提高预测准确性和模型透明度。

Abstract: The task here is to predict the toxicological activity of chemical compounds
based on the Tox21 dataset, a benchmark in computational toxicology.
  After a domain-specific overview of chemical toxicity, we discuss current
computational strategies, focusing on machine learning and deep learning.
Several architectures are compared in terms of performance, robustness, and
interpretability.
  This research introduces a novel image-based pipeline based on DenseNet121,
which processes 2D graphical representations of chemical structures.
Additionally, we employ Grad-CAM visualizations, an explainable AI technique,
to interpret the model's predictions and highlight molecular regions
contributing to toxicity classification. The proposed architecture achieves
competitive results compared to traditional models, demonstrating the potential
of deep convolutional networks in cheminformatics. Our findings emphasize the
value of combining image-based representations with explainable AI methods to
improve both predictive accuracy and model transparency in toxicology.

</details>


### [677] [Optimal Anytime Algorithms for Online Convex Optimization with Adversarial Constraints](https://arxiv.org/abs/2510.22579)
*Dhruv Sarkar,Abhishek Sinha*

Main category: cs.LG

TL;DR: We propose an anytime online algorithm for learning adversarial convex cost functions with adversarial online convex constraints, achieving optimal performance bounds without the doubling trick by using time-varying Lyapunov functions. The algorithm provides O(sqrt(t)) regret and O(tilde(O(sqrt(t)))) cumulative constraint violation bounds for any t>=1. We also extend this to dynamic regret and an adaptive algorithm for the optimistic setting, demonstrating practical utility in the online shortest path problem.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the problem of learning a sequence of adversarial convex cost functions while satisfying another sequence of adversarial online convex constraints, aiming for an anytime algorithm that offers non-trivial performance guarantees at any intermediate timestep without needing to know the total time horizon T.

Method: The proposed algorithm utilizes time-varying Lyapunov functions to monitor constraint violations, departing from prior work that used fixed Lyapunov functions. A new analytical technique is introduced to overcome the challenges posed by time-varying Lyapunov functions, which do not possess the same properties (like monotonicity) as fixed ones.

Result: The algorithm achieves O(sqrt(t)) regret and O(tilde(O(sqrt(t)))) cumulative constraint violation bounds for any t>=1. The results are extended to the dynamic regret setting, achieving bounds that adapt to the path length of the comparator sequence without prior knowledge of its total length. An adaptive algorithm for the optimistic setting is also presented, with performance scaling gracefully with cumulative prediction error.

Conclusion: The paper presents a novel anytime online algorithm that overcomes the limitations of previous methods by employing time-varying Lyapunov functions. This approach yields optimal performance bounds and is validated through numerical experiments on the online shortest path problem, demonstrating its practical applicability.

Abstract: We propose an anytime online algorithm for the problem of learning a sequence
of adversarial convex cost functions while approximately satisfying another
sequence of adversarial online convex constraints. A sequential algorithm is
called \emph{anytime} if it provides a non-trivial performance guarantee for
any intermediate timestep $t$ without requiring prior knowledge of the length
of the entire time horizon $T$. Our proposed algorithm achieves optimal
performance bounds without resorting to the standard doubling trick, which has
poor practical performance due to multiple restarts. Our core technical
contribution is the use of time-varying Lyapunov functions to keep track of
constraint violations. This must be contrasted with prior works that used a
fixed Lyapunov function tuned to the known horizon length $T$. The use of
time-varying Lyapunov function poses unique analytical challenges as
properties, such as \emph{monotonicity}, on which the prior proofs rest, no
longer hold. By introducing a new analytical technique, we show that our
algorithm achieves $O(\sqrt{t})$ regret and $\tilde{O}(\sqrt{t})$ cumulative
constraint violation bounds for any $t\geq 1$.
  We extend our results to the dynamic regret setting, achieving bounds that
adapt to the path length of the comparator sequence without prior knowledge of
its total length. We also present an adaptive algorithm in the optimistic
setting, whose performance gracefully scales with the cumulative prediction
error. We demonstrate the practical utility of our algorithm through numerical
experiments involving the online shortest path problem.

</details>


### [678] [Prediction-Powered Semi-Supervised Learning with Online Power Tuning](https://arxiv.org/abs/2510.22586)
*Noa Shoham,Ron Dorfman,Shalev Shaer,Kfir Y. Levy,Yaniv Romano*

Main category: cs.LG

TL;DR: 该研究将预测驱动推断（PPI）的思想扩展到半监督学习（SSL）的模型训练中，提出了一种新的无偏梯度估计量，以解决SSL中伪标签质量不佳导致的偏差问题。


<details>
  <summary>Details</summary>
Motivation: SSL方法在引入无标签数据以提升模型性能时，其效果很大程度上依赖于伪标签的质量，不准确的伪标签会引入偏差，导致模型性能不佳。本研究旨在解决这一关键挑战。

Method: 提出了一种新的无偏梯度估计量，并引入一个插值参数来平衡有标签数据和伪标签数据的贡献。该插值参数与模型参数一同通过一维在线学习算法进行动态调整。

Result: 通过在合成和真实数据集上的实验验证，该方法在性能上优于经典的SSL基线方法和离线调整插值参数的PPI方法。

Conclusion: 本研究提出的结合动态调整插值参数的无偏梯度估计量，在半监督学习中能够有效提升模型性能，克服了伪标签质量不佳带来的挑战。

Abstract: Prediction-Powered Inference (PPI) is a recently proposed statistical
inference technique for parameter estimation that leverages pseudo-labels on
both labeled and unlabeled data to construct an unbiased, low-variance
estimator. In this work, we extend its core idea to semi-supervised learning
(SSL) for model training, introducing a novel unbiased gradient estimator. This
extension addresses a key challenge in SSL: while unlabeled data can improve
model performance, its benefit heavily depends on the quality of pseudo-labels.
Inaccurate pseudo-labels can introduce bias, leading to suboptimal models.To
balance the contributions of labeled and pseudo-labeled data, we utilize an
interpolation parameter and tune it on the fly, alongside the model parameters,
using a one-dimensional online learning algorithm. We verify the practical
advantage of our approach through experiments on both synthetic and real
datasets, demonstrating improved performance over classic SSL baselines and PPI
methods that tune the interpolation parameter offline.

</details>


### [679] [A roadmap for curvature-based geometric data analysis and learning](https://arxiv.org/abs/2510.22599)
*Yasharth Yadav,Kelin Xia*

Main category: cs.LG

TL;DR: 该综述全面介绍了离散曲率模型，涵盖其数学基础、计算方法和在数据分析与学习中的应用。


<details>
  <summary>Details</summary>
Motivation: 曲率是几何数据分析和学习中的核心概念，用于捕捉数据的内在几何结构，并在多种应用中发挥重要作用。现有的离散曲率模型在不同数据表示上已被广泛研究，但缺乏一个全面的总结。

Method: 本文对现有的离散曲率模型进行了全面的综述，从黎曼几何和度量几何的角度进行了讨论，提出了一个驱动曲率的数据分析流程，并比较了不同数据表示下的计算算法。最后，回顾了曲率在监督和无监督学习中的应用。

Result: 本文提供了对离散曲率模型及其应用的详细概述，包括数学基础、计算方法和实际应用，并对不同方法进行了比较。

Conclusion: 本综述为研究人员提供了一个理解离散曲率作为几何理解和学习的基本工具的概念和实践路线图。

Abstract: Geometric data analysis and learning has emerged as a distinct and rapidly
developing research area, increasingly recognized for its effectiveness across
diverse applications. At the heart of this field lies curvature, a powerful and
interpretable concept that captures intrinsic geometric structure and underpins
numerous tasks, from community detection to geometric deep learning. A wide
range of discrete curvature models have been proposed for various data
representations, including graphs, simplicial complexes, cubical complexes, and
point clouds sampled from manifolds. These models not only provide efficient
characterizations of data geometry but also constitute essential components in
geometric learning frameworks. In this paper, we present the first
comprehensive review of existing discrete curvature models, covering their
mathematical foundations, computational formulations, and practical
applications in data analysis and learning. In particular, we discuss discrete
curvature from both Riemannian and metric geometry perspectives and propose a
systematic pipeline for curvature-driven data analysis. We further examine the
corresponding computational algorithms across different data representations,
offering detailed comparisons and insights. Finally, we review state-of-the-art
applications of curvature in both supervised and unsupervised learning. This
survey provides a conceptual and practical roadmap for researchers to gain a
better understanding of discrete curvature as a fundamental tool for geometric
understanding and learning.

</details>


### [680] [CLEANet: Robust and Efficient Anomaly Detection in Contaminated Multivariate Time Series](https://arxiv.org/abs/2510.22619)
*Songhan Zhang,Yuanhao Lai,Pengfei Zheng,Boxi Yu,Xiaoying Tang,Qiuai Fu,Pinjia He*

Main category: cs.LG

TL;DR: CLEANet 是一个用于检测多元时间序列异常的鲁棒且高效的框架，它通过自适应重构加权和聚类引导的对比学习来处理污染的训练数据，并使用轻量级共轭 MLP 来提高推理效率。


<details>
  <summary>Details</summary>
Motivation: 工业系统中的多元时间序列异常检测很重要，但现实部署面临训练数据污染和模型推理效率低下的挑战。现有方法假设数据干净，污染会降低准确性，而复杂模型会过拟合污染并导致高延迟。

Method: CLEANet 提出了一种污染弹性训练框架 (CRTF)，通过自适应重构加权和聚类引导的对比学习来减轻污染样本的影响。它还设计了一个轻量级共轭 MLP 来解耦时间和跨特征依赖性，以提高效率并避免过拟合。

Result: 在五个公开数据集上，CLEANet 的 F1 分数比十种最先进的基线高出 73.04%，运行时长缩短 81.28%。将 CRTF 集成到三个高级模型中，平均 F1 分数提高了 5.35%。

Conclusion: CLEANet 框架通过其 CRTF 和轻量级共轭 MLP，有效解决了带污染的多元时间序列异常检测中的数据污染和推理效率问题，并且具有良好的泛化能力。

Abstract: Multivariate time series (MTS) anomaly detection is essential for maintaining
the reliability of industrial systems, yet real-world deployment is hindered by
two critical challenges: training data contamination (noises and hidden
anomalies) and inefficient model inference. Existing unsupervised methods
assume clean training data, but contamination distorts learned patterns and
degrades detection accuracy. Meanwhile, complex deep models often overfit to
contamination and suffer from high latency, limiting practical use. To address
these challenges, we propose CLEANet, a robust and efficient anomaly detection
framework in contaminated multivariate time series. CLEANet introduces a
Contamination-Resilient Training Framework (CRTF) that mitigates the impact of
corrupted samples through an adaptive reconstruction weighting strategy
combined with clustering-guided contrastive learning, thereby enhancing
robustness. To further avoid overfitting on contaminated data and improve
computational efficiency, we design a lightweight conjugate MLP that
disentangles temporal and cross-feature dependencies. Across five public
datasets, CLEANet achieves up to 73.04% higher F1 and 81.28% lower runtime
compared with ten state-of-the-art baselines. Furthermore, integrating CRTF
into three advanced models yields an average 5.35% F1 gain, confirming its
strong generalizability.

</details>


### [681] [FastVLM: Self-Speculative Decoding for Fast Vision-Language Model Inference](https://arxiv.org/abs/2510.22641)
*Divya Jyoti Bajpai,Manjesh Kumar Hanawal*

Main category: cs.LG

TL;DR: FastVLM是一个基于模仿学习的自我推测解码框架，通过使用轻量级草稿模型和完整模型协同工作，显著提高了视觉-语言模型的推理速度（1.55-1.85倍），同时保持了性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言模型（VLMs）在视觉理解和响应生成方面取得了显著进展，但面临计算成本高和推理延迟大的问题，这主要是由于自回归解码造成的。

Method: 提出了一种名为FastVLM的基于模仿学习的自我推测解码（SSD）框架。该框架使用一个轻量级的草稿模型进行自回归式令牌生成，同时由一个完整的模型进行非自回归式的验证。被接受的令牌被无缝处理，而被拒绝的令牌则由完整模型进行修正，并用于指导草稿模型的改进。通过模仿网络，FastVLM将完整模型的深层见解整合到草稿模型中，以增强草稿模型。在训练草稿模型的同时，它还能保持完整模型的性能完整性，从而在效率和准确性之间取得平衡。

Result: 与最后的模型相比，该方法将推理过程加速了1.55-1.85倍，同时性能损失很小。

Conclusion: FastVLM框架通过结合草稿模型和完整模型的优势，并在模仿学习的帮助下优化草稿模型，成功地解决了现有VLMs的推理效率问题，实现了推理速度和性能之间的良好平衡。

Abstract: Vision-language Models (VLMs) have made significant strides in visual
understanding and query response generation, but often face challenges of high
computational cost and inference latency due to autoregressive decoding. In
this work, we introduce an imitation-learning-based Self-Speculative Decoding
(SSD) framework, named FastVLM, to address these limitations. Our approach
employs a lightweight draft model for token generation in an autoregressive
manner, while a full model verifies these tokens non-autoregressively. Accepted
tokens proceed seamlessly, while rejected tokens are corrected by the full
model and used to guide the draft model's refinement. Through an imitation
network, FastVLM enhances the draft model by integrating deeper level insights
from the full model's architecture. Also, it maintains the performance
integrity of the full model while training the draft model, achieving a balance
between efficiency and accuracy. Our method speeds up the inference process by
1.55-1.85x as compared to the final layer with minimal loss in performance.

</details>


### [682] [Enhancing Graph Classification Robustness with Singular Pooling](https://arxiv.org/abs/2510.22643)
*Sofiane Ennadir,Oleg Smirnov,Yassine Abbahaddou,Lele Cao,Johannes F. Lutzeyer*

Main category: cs.LG

TL;DR: GNN的对抗性鲁棒性在图分类方面仍未得到充分研究，本研究提出了RS-Pool，一种利用节点嵌入矩阵的奇异向量来构建鲁棒图表示的新型池化策略，并在经验上证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有的GNN防御主要集中在消息传递组件，而忽略了池化操作在塑造鲁棒性方面的重要作用。

Method: 对标准的扁平池化方法（求和、平均和最大值）进行理论分析，推导出其对抗性风险的上限，并识别其在不同攻击场景和图结构下的脆弱性。在此基础上，提出了一种名为RS-Pool的新型池化策略，该策略利用节点嵌入矩阵的主导奇异向量来构建鲁棒的图级表示。

Result: RS-Pool在面对最先进的对抗性攻击时，比所考虑的池化方法具有更好的鲁棒性，同时保持了具有竞争力的准确率。

Conclusion: RS-Pool是一种新颖且高效的池化策略，能够显著提高GNN在图分类任务中的对抗性鲁棒性。

Abstract: Graph Neural Networks (GNNs) have achieved strong performance across a range
of graph representation learning tasks, yet their adversarial robustness in
graph classification remains underexplored compared to node classification.
While most existing defenses focus on the message-passing component, this work
investigates the overlooked role of pooling operations in shaping robustness.
We present a theoretical analysis of standard flat pooling methods (sum,
average and max), deriving upper bounds on their adversarial risk and
identifying their vulnerabilities under different attack scenarios and graph
structures. Motivated by these insights, we propose \textit{Robust Singular
Pooling (RS-Pool)}, a novel pooling strategy that leverages the dominant
singular vector of the node embedding matrix to construct a robust graph-level
representation. We theoretically investigate the robustness of RS-Pool and
interpret the resulting bound leading to improved understanding of our proposed
pooling operator. While our analysis centers on Graph Convolutional Networks
(GCNs), RS-Pool is model-agnostic and can be implemented efficiently via power
iteration. Empirical results on real-world benchmarks show that RS-Pool
provides better robustness than the considered pooling methods when subject to
state-of-the-art adversarial attacks while maintaining competitive clean
accuracy. Our code is publicly available
at:\href{https://github.com/king/rs-pool}{https://github.com/king/rs-pool}.

</details>


### [683] [Variational Polya Tree](https://arxiv.org/abs/2510.22651)
*Lu Xu,Tsai Hor Chan,Kwok Fai Lam,Lequan Yu,Guosheng Yin*

Main category: cs.LG

TL;DR: 该研究提出了一种名为变分波利亚树（VPT）的新型模型，用于解决深度学习中贝叶斯非参数密度估计的计算复杂性和可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于神经网络的密度估计方法在捕捉复杂数据分布方面表现出色，但在可解释性和不确定性量化方面存在不足。而传统的贝叶斯非参数方法（如波利亚树）虽然能解决这些问题，但计算复杂度高，难以扩展到深度学习领域。

Method: 研究人员提出了一种变分波利亚树（VPT）模型，该模型利用随机变分推断来计算后验分布。VPT模型采用灵活的非参数贝叶斯先验来捕捉潜在密度，并适用于随机梯度优化。此外，研究还利用联合分布似然来获得比传统平均场方法更精确的变分后验近似。

Result: 在真实数据和图像的实验评估中，VPT模型展现了与最先进的深度密度估计方法相当的性能，并在提高可解释性和不确定性量化方面显示出潜力。

Conclusion: 变分波利亚树（VPT）模型成功地将贝叶斯非参数密度估计的优势（如可解释性和不确定性量化）与深度学习的可扩展性相结合，为解决现代密度估计的挑战提供了一种有前景的方法。

Abstract: Density estimation is essential for generative modeling, particularly with
the rise of modern neural networks. While existing methods capture complex data
distributions, they often lack interpretability and uncertainty quantification.
Bayesian nonparametric methods, especially the \polya tree, offer a robust
framework that addresses these issues by accurately capturing function behavior
over small intervals. Traditional techniques like Markov chain Monte Carlo
(MCMC) face high computational complexity and scalability limitations,
hindering the use of Bayesian nonparametric methods in deep learning. To tackle
this, we introduce the variational \polya tree (VPT) model, which employs
stochastic variational inference to compute posterior distributions. This model
provides a flexible, nonparametric Bayesian prior that captures latent
densities and works well with stochastic gradient optimization. We also
leverage the joint distribution likelihood for a more precise variational
posterior approximation than traditional mean-field methods. We evaluate the
model performance on both real data and images, and demonstrate its
competitiveness with other state-of-the-art deep density estimation methods. We
also explore its ability in enhancing interpretability and uncertainty
quantification. Code is available at
https://github.com/howardchanth/var-polya-tree.

</details>


### [684] [If You Want to Be Robust, Be Wary of Initialization](https://arxiv.org/abs/2510.22652)
*Sofiane Ennadir,Johannes F. Lutzeyer,Michalis Vazirgiannis,El Houcine Bergou*

Main category: cs.LG

TL;DR: GNNs对对抗性扰动很脆弱，但本文发现权重初始化和训练周期对模型的鲁棒性有显著影响，并提出了一个理论框架来解释这种关系。


<details>
  <summary>Details</summary>
Motivation: 现有GNN防御策略主要关注预处理和消息传递机制，忽视了权重初始化和训练周期等因素对模型鲁棒性的影响。

Method: 提出一个理论框架，连接初始化策略和GNN的鲁棒性。分析初始权重、训练周期与模型脆弱性之间的关系。

Result: 实验证明，选择合适的初始化策略不仅能保证模型在干净数据集上的性能，还能提高模型对抗扰动的鲁棒性，与替代初始化方法相比，性能差距可达50%。

Conclusion: 权重初始化和训练周期是影响GNN对抗性鲁棒性的重要因素，应纳入防御策略的考虑范围。该理论框架也适用于深度神经网络。

Abstract: Graph Neural Networks (GNNs) have demonstrated remarkable performance across
a spectrum of graph-related tasks, however concerns persist regarding their
vulnerability to adversarial perturbations. While prevailing defense strategies
focus primarily on pre-processing techniques and adaptive message-passing
schemes, this study delves into an under-explored dimension: the impact of
weight initialization and associated hyper-parameters, such as training epochs,
on a model's robustness. We introduce a theoretical framework bridging the
connection between initialization strategies and a network's resilience to
adversarial perturbations. Our analysis reveals a direct relationship between
initial weights, number of training epochs and the model's vulnerability,
offering new insights into adversarial robustness beyond conventional defense
mechanisms. While our primary focus is on GNNs, we extend our theoretical
framework, providing a general upper-bound applicable to Deep Neural Networks.
Extensive experiments, spanning diverse models and real-world datasets
subjected to various adversarial attacks, validate our findings. We illustrate
that selecting appropriate initialization not only ensures performance on clean
datasets but also enhances model robustness against adversarial perturbations,
with observed gaps of up to 50\% compared to alternative initialization
approaches.

</details>


### [685] [Learning Without Augmenting: Unsupervised Time Series Representation Learning via Frame Projections](https://arxiv.org/abs/2510.22655)
*Berken Utku Demirel,Christian Holz*

Main category: cs.LG

TL;DR: 本文提出了一种无需手动设计数据增强即可进行无监督表征学习的方法，通过生成正交基和过完备框架下的视图，并结合不同流形几何信息，在多个时间序列任务上取得了优于现有自监督方法的性能提升。


<details>
  <summary>Details</summary>
Motivation: 手动设计数据增强需要领域知识，并可能限制模型的泛化能力。现有自监督学习方法依赖于精心设计的数据增强来生成多样性视图，但这在时间序列等领域具有挑战性。

Method: 提出一种无监督表征学习方法，不依赖数据增强，而是利用正交基和过完备框架生成视图。通过结合不同空间表示产生的互补几何信息来学习表征。

Result: 在九个数据集和五个时间序列任务上验证了方法的有效性，性能提升可达 15-20%。

Conclusion: 所提出的方法无需人工数据增强，通过利用不同几何空间引入的几何偏差，能够有效地学习到强大的表征，并在具有挑战性的时间序列任务上取得显著的性能提升。

Abstract: Self-supervised learning (SSL) has emerged as a powerful paradigm for
learning representations without labeled data. Most SSL approaches rely on
strong, well-established, handcrafted data augmentations to generate diverse
views for representation learning. However, designing such augmentations
requires domain-specific knowledge and implicitly imposes representational
invariances on the model, which can limit generalization. In this work, we
propose an unsupervised representation learning method that replaces
augmentations by generating views using orthonormal bases and overcomplete
frames. We show that embeddings learned from orthonormal and overcomplete
spaces reside on distinct manifolds, shaped by the geometric biases introduced
by representing samples in different spaces. By jointly leveraging the
complementary geometry of these distinct manifolds, our approach achieves
superior performance without artificially increasing data diversity through
strong augmentations. We demonstrate the effectiveness of our method on nine
datasets across five temporal sequence tasks, where signal-specific
characteristics make data augmentations particularly challenging. Without
relying on augmentation-induced diversity, our method achieves performance
gains of up to 15--20\% over existing self-supervised approaches. Source code:
https://github.com/eth-siplab/Learning-with-FrameProjections

</details>


### [686] [FlowCritic: Bridging Value Estimation with Flow Matching in Reinforcement Learning](https://arxiv.org/abs/2510.22686)
*Shan Zhong,Shutong Ding,He Diao,Xiangyu Wang,Kah Chan Teh,Bei Peng*

Main category: cs.LG

TL;DR: FlowCritic利用流匹配来模拟值分布并生成值估计的样本。


<details>
  <summary>Details</summary>
Motivation: 可靠的值估计是强化学习（RL）的基石，它评估长期回报并指导策略改进，显著影响收敛速度和最终性能。现有方法通过多评估器集成和分布RL来提高值函数估计的可靠性，但前者仅组合多点估计而未捕捉分布信息，后者则依赖于离散化或分位数回归，限制了复杂值分布的表达能力。

Method: 受流匹配在生成模型中成功应用的启发，提出了一种用于值估计的生成范式，命名为FlowCritic。FlowCritic不依赖于传统的确定性值预测回归，而是利用流匹配来模拟值分布并为值估计生成样本。

Result: FlowCritic模拟值分布并生成样本以进行值估计。

Conclusion: FlowCritic通过利用流匹配来模拟值分布并生成样本，为值估计提供了一种新的生成方法。

Abstract: Reliable value estimation serves as the cornerstone of reinforcement learning
(RL) by evaluating long-term returns and guiding policy improvement,
significantly influencing the convergence speed and final performance. Existing
works improve the reliability of value function estimation via multi-critic
ensembles and distributional RL, yet the former merely combines multi point
estimation without capturing distributional information, whereas the latter
relies on discretization or quantile regression, limiting the expressiveness of
complex value distributions. Inspired by flow matching's success in generative
modeling, we propose a generative paradigm for value estimation, named
FlowCritic. Departing from conventional regression for deterministic value
prediction, FlowCritic leverages flow matching to model value distributions and
generate samples for value estimation.

</details>


### [687] [Identification of Causal Direction under an Arbitrary Number of Latent Confounders](https://arxiv.org/abs/2510.22711)
*Wei Chen,Linjun Peng,Zhiyi Huang,Haoyue Dai,Zhifeng Hao,Ruichu Cai,Kun Zhang*

Main category: cs.LG

TL;DR: 该研究提出了一种在存在潜变量的情况下，通过分析联合高阶累积量矩阵的秩亏缺性质来恢复因果结构的新方法，特别适用于线性、非高斯场景，并能在存在任意数量潜变量的情况下识别因果关系。


<details>
  <summary>Details</summary>
Motivation: 现有因果结构恢复方法在处理潜变量时通常需要苛刻且不可检验的假设，且难以处理观测变量同时受到多个潜变量影响的情况。本研究旨在解决这一挑战。

Method: 利用观测变量以特定方式构建的联合高阶累积量矩阵，分析其秩亏缺性质来识别因果不对称性，该方法适用于线性、非高斯情况，并且不涉及迭代过程。

Result: 实验结果证明了该方法的有效性和渐近正确性，表明通过分析联合高阶累积量矩阵的秩亏缺性质，可以在存在任意数量潜变量的情况下，直接识别因果关系。

Conclusion: 本研究成功地提出了一种新的因果结构恢复方法，该方法能够在存在潜变量且观测变量受多个潜变量同时影响的复杂情况下，通过分析联合高阶累积量矩阵的秩亏缺性质，实现因果关系的直接识别，并建立了相应的识别理论。

Abstract: Recovering causal structure in the presence of latent variables is an
important but challenging task. While many methods have been proposed to handle
it, most of them require strict and/or untestable assumptions on the causal
structure. In real-world scenarios, observed variables may be affected by
multiple latent variables simultaneously, which, generally speaking, cannot be
handled by these methods. In this paper, we consider the linear, non-Gaussian
case, and make use of the joint higher-order cumulant matrix of the observed
variables constructed in a specific way. We show that, surprisingly, causal
asymmetry between two observed variables can be directly seen from the rank
deficiency properties of such higher-order cumulant matrices, even in the
presence of an arbitrary number of latent confounders. Identifiability results
are established, and the corresponding identification methods do not even
involve iterative procedures. Experimental results demonstrate the
effectiveness and asymptotic correctness of our proposed method.

</details>


### [688] [S-Chain: Structured Visual Chain-of-Thought For Medicine](https://arxiv.org/abs/2510.22728)
*Khai Le-Duc,Duy M. H. Nguyen,Phuong T. H. Trinh,Tien-Phat Nguyen,Nghiem T. Diep,An Ngo,Tung Vu,Trinh Vuong,Anh-Tien Nguyen,Mau Nguyen,Van Trung Hoang,Khai-Nguyen Nguyen,Hy Nguyen,Chris Ngo,Anji Liu,Nhat Ho,Anne-Christin Hauschild,Khanh Xuan Nguyen,Thanh Nguyen-Tang,Pengtao Xie,Daniel Sonntag,James Zou,Mathias Niepert,Anh Totti Nguyen*

Main category: cs.LG

TL;DR: S-Chain是一个包含12000张医学图像的大规模数据集，包含精确的视觉证据和逐步推理的标注，旨在提高医学视觉语言模型（VLMs）的可解释性、视觉基础保真度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的医学视觉问答（VQA）研究缺乏包含详细视觉定位的逐步推理数据集，限制了医学VLMs的可靠性和可解释性。

Method: 创建了一个包含12000张医学图像、边界框和结构化视觉思维链（SV-CoT）的大规模数据集，并支持16种语言。利用该数据集对现有的医学和通用VLMs进行了基准测试，并研究了其与检索增强生成（RAG）的协同作用，最后提出了一种新的对齐机制。

Result: SV-CoT监督显著提高了模型的解释性、视觉基础保真度和鲁棒性。与RAG的协同作用揭示了领域知识和视觉基础在自回归推理中的交互作用。新机制提高了模型的可靠性和效率。

Conclusion: S-Chain数据集为医学推理设定了新的基准，并推动了更值得信赖和可解释的医学VLMs的发展。

Abstract: Faithful reasoning in medical vision-language models (VLMs) requires not only
accurate predictions but also transparent alignment between textual rationales
and visual evidence. While Chain-of-Thought (CoT) prompting has shown promise
in medical visual question answering (VQA), no large-scale expert-level dataset
has captured stepwise reasoning with precise visual grounding. We introduce
S-Chain, the first large-scale dataset of 12,000 expert-annotated medical
images with bounding boxes and structured visual CoT (SV-CoT), explicitly
linking visual regions to reasoning steps. The dataset further supports 16
languages, totaling over 700k VQA pairs for broad multilingual applicability.
Using S-Chain, we benchmark state-of-the-art medical VLMs (ExGra-Med,
LLaVA-Med) and general-purpose VLMs (Qwen2.5-VL, InternVL2.5), showing that
SV-CoT supervision significantly improves interpretability, grounding fidelity,
and robustness. Beyond benchmarking, we study its synergy with
retrieval-augmented generation, revealing how domain knowledge and visual
grounding interact during autoregressive reasoning. Finally, we propose a new
mechanism that strengthens the alignment between visual evidence and reasoning,
improving both reliability and efficiency. S-Chain establishes a new benchmark
for grounded medical reasoning and paves the way toward more trustworthy and
explainable medical VLMs.

</details>


### [689] [Centrum: Model-based Database Auto-tuning with Minimal Distributional Assumptions](https://arxiv.org/abs/2510.22734)
*Yuanhao Lai,Pengfei Zheng,Chenpeng Ji,Yan Li,Songhan Zhang,Rutao Zhang,Zhengang Wang,Yunfei Du*

Main category: cs.LG

TL;DR: GP-BO 在数据库自调优中存在局限性，而基于树的方法（如 SMAC）表现更好。现有树集成方法仍有改进空间，作者提出了 Centrum，一种利用梯度提升和保形推断的新型方法，在实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于高斯过程的贝叶斯优化（GP-BO）在数据库自调优中存在局限性，促使研究者重新思考和调查其不足之处。同时，现有的基于树集成的贝叶斯优化方法也存在进一步改进的空间。

Method: 提出了一种名为 Centrum 的新型模型驱动的数据库自调优器。Centrum 采用随机梯度提升集成（stochastic gradient boosting ensembles）的两阶段学习程序，以改进分布无关的点估计和区间估计，并结合广义梯度提升估计的局部自适应保形预测（generalized SGBE-estimated locally-adaptive conformal prediction），以实现分布无关的置信估计和获取函数。

Result: Centrum 在两个数据库管理系统和三个工作负载上的大量物理和仿真实验表明，其性能优于 21 种最先进的方法。

Conclusion: Centrum 是第一个实现分布无关性的数据库自动调优器，提高了贝叶斯优化在数据库自动调优中的实用性，也是第一个将梯度提升集成和保形推断无缝融合到贝叶斯优化中的自动调优器。

Abstract: Gaussian-Process-based Bayesian optimization (GP-BO), is a prevailing
model-based framework for DBMS auto-tuning. However, recent work shows
GP-BO-based DBMS auto-tuners significantly outperformed auto-tuners based on
SMAC, which features random forest surrogate models; such results motivate us
to rethink and investigate the limitations of GP-BO in auto-tuner design. We
find the fundamental assumptions of GP-BO are widely violated when modeling and
optimizing DBMS performance, while tree-ensemble-BOs (e.g., SMAC) can avoid the
assumption pitfalls and deliver improved tuning efficiency and effectiveness.
Moreover, we argue that existing tree-ensemble-BOs restrict further advancement
in DBMS auto-tuning. First, existing tree-ensemble-BOs can only achieve
distribution-free point estimates, but still impose unrealistic distributional
assumptions on uncertainty estimates, compromising surrogate modeling and
distort the acquisition function. Second, recent advances in gradient boosting,
which can further enhance surrogate modeling against vanilla GP and random
forest counterparts, have rarely been applied in optimizing DBMS auto-tuners.
To address these issues, we propose a novel model-based DBMS auto-tuner,
Centrum. Centrum improves distribution-free point and interval estimation in
surrogate modeling with a two-phase learning procedure of stochastic gradient
boosting ensembles. Moreover, Centrum adopts a generalized SGBE-estimated
locally-adaptive conformal prediction to facilitate a distribution-free
uncertainty estimation and acquisition function. To our knowledge, Centrum is
the first auto-tuner to realize distribution-freeness, enhancing BO's
practicality in DBMS auto-tuning, and the first to seamlessly fuse gradient
boosting ensembles and conformal inference in BO. Extensive physical and
simulation experiments on two DBMSs and three workloads show Centrum
outperforms 21 SOTA methods.

</details>


### [690] [Distributionally Robust Optimization via Diffusion Ambiguity Modeling](https://arxiv.org/abs/2510.22757)
*Jiaqi Wen,Jianyi Yang*

Main category: cs.LG

TL;DR: 本篇论文提出了一种基于扩散模型的分布鲁棒优化（DRO）方法，用于提高统计学习和优化的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 为了设计一个既能保持与标称分布一致性又能充分考虑各种潜在情景的有效模糊集，并使DRO问题可处理。

Method: 提出了一种基于扩散模型的模糊集设计，该设计能够捕捉超出标称支持空间的各种对抗性分布，同时保持与标称分布的一致性。在此基础上，提出了一种名为D-DRO的可处理DRO算法，该算法解决了参数化扩散模型空间内的内部最大化问题。

Result: 形式上证明了D-DRO的稳态收敛性能，并在机器学习预测任务中通过实证证明了其优越的分布外（OOD）泛化性能。

Conclusion: 基于扩散模型的模糊集设计和D-DRO算法能够实现有效的鲁棒优化和泛化。

Abstract: This paper studies Distributionally Robust Optimization (DRO), a fundamental
framework for enhancing the robustness and generalization of statistical
learning and optimization. An effective ambiguity set for DRO must involve
distributions that remain consistent with the nominal distribution while being
diverse enough to account for a variety of potential scenarios. Moreover, it
should lead to tractable DRO solutions. To this end, we propose a
diffusion-based ambiguity set design that captures various adversarial
distributions beyond the nominal support space while maintaining consistency
with the nominal distribution. Building on this ambiguity modeling, we propose
Diffusion-based DRO (D-DRO), a tractable DRO algorithm that solves the inner
maximization over the parameterized diffusion model space. We formally
establish the stationary convergence performance of D-DRO and empirically
demonstrate its superior Out-of-Distribution (OOD) generalization performance
in a ML prediction task.

</details>


### [691] [TELL-TALE: Task Efficient LLMs with Task Aware Layer Elimination](https://arxiv.org/abs/2510.22767)
*Omar Naim,Krish Sharma,Nicholas Asher*

Main category: cs.LG

TL;DR: TALE是一种推理时算法，可在不进行再训练的情况下修剪Transformer LLM的整个层，以优化特定任务的性能，并在多个模型和任务上均可提高准确性并降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的方法在模型压缩时，可能无法完全达到任务特定性能的优化，并且通常需要进行再训练，这增加了计算成本。

Method: TALE是一种推理时算法，通过直接优化特定任务的验证性能来修剪LLM的整个Transformer层。它不需要再训练，并且可以通过互信息分析来识别并移除充当瓶颈并损害任务相关表示的层。

Result: 在9个任务和5个模型（包括LLaMA 3.1 8B、Qwen 2.5 7B、Qwen 2.5 0.5B、Mistral 7B和Lucie 7B）上进行的评估显示，TALE在零样本和少样本设置下都能提高准确性并降低计算成本。此外，在微调过程中应用TALE可带来额外的性能提升。

Conclusion: TALE是一种有效的模型压缩技术，通过移除冗余层来减小、加速并提高LLM的准确性，同时降低微调成本，并为理解Transformer的可解释性提供了新的见解。

Abstract: In this paper we introduce Tale, Task-Aware Layer Elimination, an
inference-time algorithm that prunes entire transformer layers in an LLM by
directly optimizing task-specific validation performance. We evaluate TALE on 9
tasks and 5 models, including LLaMA 3.1 8B, Qwen 2.5 7B, Qwen 2.5 0.5B, Mistral
7B, and Lucie 7B, under both zero-shot and few-shot settings. Unlike prior
approaches, TALE requires no retraining and consistently improves accuracy
while reducing computational cost across all benchmarks. Furthermore, applying
TALE during finetuning leads to additional performance gains. Finally, TALE
provides flexible user control over trade-offs between accuracy and efficiency.
Mutual information analysis shows that certain layers act as bottlenecks,
degrading task-relevant representations. Tale's selective layer removal
remedies this problem, producing smaller, faster, and more accurate models that
are also faster to fine-tune while offering new insights into transformer
interpretability.

</details>


### [692] [SeeDNorm: Self-Rescaled Dynamic Normalization](https://arxiv.org/abs/2510.22777)
*Wenrui Cai,Defa Zhu,Qingjie Liu,Qiyang Min*

Main category: cs.LG

TL;DR: RMSNorm在Transformer中通过单位超球面约束向量并使用可学习的缩放系数γ来维持模型的表征能力。然而，RMSNorm在前向传播中会丢弃输入范数信息，并且静态的γ可能不足以适应输入数据的广泛变化和分布变化，从而限制了性能的进一步提升，尤其是在大型语言模型经常遇到的零样本场景中。


<details>
  <summary>Details</summary>
Motivation: RMSNorm在处理输入数据的变化和分布偏移时存在局限性，尤其是在零样本场景下，这限制了大型语言模型的性能提升。

Method: 提出SeeDNorm，通过动态调整缩放系数来增强模型的表征能力，保留输入范数信息，实现数据依赖的、自缩放的动态归一化。SeeDNorm在反向传播时保留了RMSNorm根据输入范数动态调整梯度的能力。提供了SeeDNorm的训练优化分析，并提出了潜在不稳定性的解决方案。

Result: SeeDNorm在不同大小的模型、大型语言模型预训练以及监督和无监督计算机视觉任务中都验证了其有效性。与RMSNorm、LayerNorm以及DyT等层相比，SeeDNorm在参数量和模型效率影响极小的情况下，实现了持续优越的性能。

Conclusion: SeeDNorm通过动态调整缩放系数，克服了RMSNorm在处理数据变化时的局限性，并在多种任务和模型中展现出优于现有归一化层的性能。

Abstract: Normalization layer constitutes an essential component in neural networks. In
transformers, the predominantly used RMSNorm constrains vectors to a unit
hypersphere, followed by dimension-wise rescaling through a learnable scaling
coefficient $\gamma$ to maintain the representational capacity of the model.
However, RMSNorm discards the input norm information in forward pass and a
static scaling factor $\gamma$ may be insufficient to accommodate the wide
variability of input data and distributional shifts, thereby limiting further
performance improvements, particularly in zero-shot scenarios that large
language models routinely encounter. To address this limitation, we propose
SeeDNorm, which enhances the representational capability of the model by
dynamically adjusting the scaling coefficient based on the current input,
thereby preserving the input norm information and enabling data-dependent,
self-rescaled dynamic normalization. During backpropagation, SeeDNorm retains
the ability of RMSNorm to dynamically adjust gradient according to the input
norm. We provide a detailed analysis of the training optimization for SeedNorm
and proposed corresponding solutions to address potential instability issues
that may arise when applying SeeDNorm. We validate the effectiveness of
SeeDNorm across models of varying sizes in large language model pre-training as
well as supervised and unsupervised computer vision tasks. By introducing a
minimal number of parameters and with neglligible impact on model efficiency,
SeeDNorm achieves consistently superior performance compared to previously
commonly used normalization layers such as RMSNorm and LayerNorm, as well as
element-wise activation alternatives to normalization layers like DyT.

</details>


### [693] [Inductive Transfer Learning for Graph-Based Recommenders](https://arxiv.org/abs/2510.22799)
*Florian Grötschla,Elia Trachsel,Luca A. Lanzendörfer,Roger Wattenhofer*

Main category: cs.LG

TL;DR: NBF-Rec是一个新的图基推荐模型，可以在不同数据集之间进行归纳迁移学习，而无需重新训练。


<details>
  <summary>Details</summary>
Motivation: 传统的图基推荐模型在转导设置下进行训练，限制了它们在新用户、新项目或新数据集上的应用。

Method: NBF-Rec 在推理时动态计算节点嵌入，支持跨具有不同用户和项目集的数据集的归纳迁移学习，而传统的基于嵌入的方法则需要为每个域重新训练。

Result: 在七个真实世界的数据集上进行了评估，NBF-Rec 在零样本设置下（在训练中不使用目标域数据）取得了有竞争力的性能，并且通过轻量级微调进一步提高了性能。

Conclusion: 研究结果表明，图基推荐中的归纳迁移是可行的，并且交互级消息传递支持在不要求用户或项目对齐的情况下跨数据集进行泛化。

Abstract: Graph-based recommender systems are commonly trained in transductive
settings, which limits their applicability to new users, items, or datasets. We
propose NBF-Rec, a graph-based recommendation model that supports inductive
transfer learning across datasets with disjoint user and item sets. Unlike
conventional embedding-based methods that require retraining for each domain,
NBF-Rec computes node embeddings dynamically at inference time. We evaluate the
method on seven real-world datasets spanning movies, music, e-commerce, and
location check-ins. NBF-Rec achieves competitive performance in zero-shot
settings, where no target domain data is used for training, and demonstrates
further improvements through lightweight fine-tuning. These results show that
inductive transfer is feasible in graph-based recommendation and that
interaction-level message passing supports generalization across datasets
without requiring aligned users or items.

</details>


### [694] [A Theory of the Mechanics of Information: Generalization Through Measurement of Uncertainty (Learning is Measuring)](https://arxiv.org/abs/2510.22809)
*Christopher J. Hazard,Michael Resnick,Jacob Beel,Jack Xia,Cade Mack,Dominic Glennie,Matthew Fulp,David Maze,Andrew Bassett,Martin Koistinen*

Main category: cs.LG

TL;DR: 提出了一种基于意外性（信息论不确定性）的无模型框架，可以直接从原始数据进行分析和推理，无需分布建模，可减少偏差，并支持有效的更新。该框架通过量化不确定性来衡量相关性，可实现跨任务的通用推理，包括生成推理、因果发现、异常检测和时间序列预测。其数学基础创造了一种信息的“物理学”，使其能有效应用于包括缺失数据在内的各种复杂数据类型，并可能成为可扩展机器学习和人工智能的一种可行的替代方案，同时保持人类对底层机制的理解。在大多数常见的机器学习任务上，其性能与最先进的技术相当或接近。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习依赖于显式模型和领域假设，在灵活性和可解释性方面存在局限。本研究旨在克服这些限制，提出一种新的方法。

Method: 引入了一种无模型框架，使用意外性（信息论不确定性）来直接分析和推断原始数据，从而消除分布建模，减少偏差，并实现包括直接编辑和删除训练数据在内的有效更新。通过量化不确定性来衡量相关性，实现跨任务的通用推理。

Result: 该框架在大多数常见的机器学习任务上取得了与最先进技术相当或接近的性能。它在可追溯性、可解释性和数据驱动的决策方面表现出色，为机器学习提供了一个统一的、人类可理解的框架。该方法能够有效处理包括缺失数据在内的各种复杂数据类型。

Conclusion: 所提出的基于意外性的无模型框架是一种可行的替代方案，可以作为神经网络在可扩展机器学习和人工智能领域的一种选择，同时保持对底层机制的人类可理解性。

Abstract: Traditional machine learning relies on explicit models and domain
assumptions, limiting flexibility and interpretability. We introduce a
model-free framework using surprisal (information theoretic uncertainty) to
directly analyze and perform inferences from raw data, eliminating distribution
modeling, reducing bias, and enabling efficient updates including direct edits
and deletion of training data. By quantifying relevance through uncertainty,
the approach enables generalizable inference across tasks including generative
inference, causal discovery, anomaly detection, and time series forecasting. It
emphasizes traceability, interpretability, and data-driven decision making,
offering a unified, human-understandable framework for machine learning, and
achieves at or near state-of-the-art performance across most common machine
learning tasks. The mathematical foundations create a ``physics'' of
information, which enable these techniques to apply effectively to a wide
variety of complex data types, including missing data. Empirical results
indicate that this may be a viable alternative path to neural networks with
regard to scalable machine learning and artificial intelligence that can
maintain human understandability of the underlying mechanics.

</details>


### [695] [Distributed Multi-Agent Bandits Over Erdős-Rényi Random Networks](https://arxiv.org/abs/2510.22811)
*Jingyuan Liu,Hao Qiu,Lin Yang,Mengfan Xu*

Main category: cs.LG

TL;DR: 本文研究了一个分布式多智能体多臂老虎机问题，其中奖励具有异质性，通信图是随机且时变的。我们提出了一种结合了手臂剔除策略和随机流言算法的分布式算法，理论上证明了其遗憾界为O(log T)，并与最优集中式遗憾进行了比较。该算法的遗憾界受通信效率和图连通性的影响，并得到了数值实验的验证。


<details>
  <summary>Details</summary>
Motivation: 研究分布式多智能体多臂老虎机问题，在奖励异质性和随机通信图的条件下，目标是最小化累积预期遗憾。

Method: 提出了一种完全分布式的算法，该算法结合了手臂剔除策略和随机流言算法。分析了该算法的理论遗憾界，并与最优集中式遗憾进行了比较。

Result: 理论上证明了遗憾的上限为O(log T)，该上限包含最优集中式遗憾项以及与通信效率和图连通性相关的项。通过数值实验，验证了算法的优越性和理论遗憾界的有效性。

Conclusion: 所提出的分布式算法在面对异质奖励和随机通信图时，能够有效地最小化累积预期遗憾，并在理论和实验上都表现出良好的性能。

Abstract: We study the distributed multi-agent multi-armed bandit problem with
heterogeneous rewards over random communication graphs. Uniquely, at each time
step $t$ agents communicate over a time-varying random graph $G_t$ generated by
applying the Erd\H{o}s-R\'enyi model to a fixed connected base graph $G$ (for
classical Erd\H{o}s-R\'enyi graphs, $G$ is a complete graph), where each
potential edge in $G$ is randomly and independently present with the link
probability $p$. Notably, the resulting random graph is not necessarily
connected at each time step. Each agent's arm rewards follow time-invariant
distributions, and the reward distribution for the same arm may differ across
agents. The goal is to minimize the cumulative expected regret relative to the
global mean reward of each arm, defined as the average of that arm's mean
rewards across all agents. To this end, we propose a fully distributed
algorithm that integrates the arm elimination strategy with the random gossip
algorithm. We theoretically show that the regret upper bound is of order $\log
T$ and is highly interpretable, where $T$ is the time horizon. It includes the
optimal centralized regret $O\left(\sum_{k: \Delta_k>0} \frac{\log
T}{\Delta_k}\right)$ and an additional term $O\left(\frac{N^2 \log T}{p
\lambda_{N-1}(Lap(G))} + \frac{KN^2 \log T}{p}\right)$ where $N$ and $K$ denote
the total number of agents and arms, respectively. This term reflects the
impact of $G$'s algebraic connectivity $\lambda_{N-1}(Lap(G))$ and the link
probability $p$, and thus highlights a fundamental trade-off between
communication efficiency and regret. As a by-product, we show a nearly optimal
regret lower bound. Finally, our numerical experiments not only show the
superiority of our algorithm over existing benchmarks, but also validate the
theoretical regret scaling with problem complexity.

</details>


### [696] [Air Quality Prediction Using LOESS-ARIMA and Multi-Scale CNN-BiLSTM with Residual-Gated Attention](https://arxiv.org/abs/2510.22818)
*Soham Pahari,Sandeep Chand Kumain*

Main category: cs.LG

TL;DR: 印度大城市空气污染严峻，本文提出一种混合预测框架，结合LOESS分解、ARIMA模型和带注意力机制的多尺度CNN-BiLSTM网络，并使用UAMMO优化器进行超参数调优。实验表明，该方法在PM2.5、O3、CO和NOx预测方面优于现有基线模型，在德里、加尔各答和孟买等城市的2021-2023年AQI数据集上表现出色，MSE降低高达5-8%，R^2分数（>0.94）有所提高，证明了其在城市空气质量管理中的有效性。


<details>
  <summary>Details</summary>
Motivation: 印度大城市（如德里、加尔各答、孟买）的空气污染是严峻的环境和公共卫生问题，污染物水平的突然飙升给及时干预带来挑战。准确预测空气质量指数（AQI）非常困难，因为空气质量数据同时包含线性趋势、季节性变化和不稳定的非线性模式。

Method: 本文提出一个混合预测框架，该框架集成了LOESS分解、ARIMA模型和带残差门控注意力机制的多尺度CNN-BiLSTM网络。首先，LOESS步骤将AQI序列分解为趋势、季节和残差分量。然后，ARIMA模型用于拟合平稳的趋势和季节分量。最后，提出的深度学习模块（CNN-BiLSTM带残差门控注意力机制）用于捕捉残差分量中的多尺度波动。模型超参数通过统一自适应多阶段启发式优化器（UAMMO）进行调整，该优化器结合了多种优化策略以实现高效收敛。

Result: 在印度中央污染控制委员会提供的2021-2023年AQI数据集上进行实验。结果显示，在PM2.5、O3、CO和NOx这四种主要污染物上，本文提出的方法在德里、加尔各答和孟买三个主要城市的预测性能持续优于统计模型、深度学习模型和混合基线模型。具体而言，该方法实现了高达5-8%的均方误差（MSE）降低，并获得了超过0.94的R^2分数。

Conclusion: 该混合预测框架在处理城市空气质量管理方面表现出强大的鲁棒性，对突发污染事件具有良好的敏感性。实验结果证明了该方法在提高AQI预测准确性方面的有效性，为应对印度大城市的空气污染问题提供了有力支持。

Abstract: Air pollution remains a critical environmental and public health concern in
Indian megacities such as Delhi, Kolkata, and Mumbai, where sudden spikes in
pollutant levels challenge timely intervention. Accurate Air Quality Index
(AQI) forecasting is difficult due to the coexistence of linear trends,
seasonal variations, and volatile nonlinear patterns. This paper proposes a
hybrid forecasting framework that integrates LOESS decomposition, ARIMA
modeling, and a multi-scale CNN-BiLSTM network with a residual-gated attention
mechanism. The LOESS step separates the AQI series into trend, seasonal, and
residual components, with ARIMA modeling the smooth components and the proposed
deep learning module capturing multi-scale volatility in the residuals. Model
hyperparameters are tuned via the Unified Adaptive Multi-Stage Metaheuristic
Optimizer (UAMMO), combining multiple optimization strategies for efficient
convergence. Experiments on 2021-2023 AQI datasets from the Central Pollution
Control Board show that the proposed method consistently outperforms
statistical, deep learning, and hybrid baselines across PM2.5, O3, CO, and NOx
in three major cities, achieving up to 5-8% lower MSE and higher R^2 scores
(>0.94) for all pollutants. These results demonstrate the framework's
robustness, sensitivity to sudden pollution events, and applicability to urban
air quality management.

</details>


### [697] [Last Iterate Analyses of FTRL in Stochasitc Bandits](https://arxiv.org/abs/2510.22819)
*Jingxin Zhan,Yuze Han,Zhihua Zhang*

Main category: cs.LG

TL;DR: FTRL算法在多臂老虎机问题中的last-iterate收敛性分析


<details>
  <summary>Details</summary>
Motivation: 研究FTRL算法在多臂老虎机问题中的last-iterate收敛性，填补该领域研究空白，并验证其与对数后悔度之间的理论联系。

Method: 对FTRL算法使用Bregman散度进行理论分析，并推导其收敛速率。

Result: 证明了与BOBW FTRL算法（1/2-Tsallis-INF）相关的Bregman散度，在最优臂和迭代t得到的概率分布之间，以$t^{-1/2}$的速率衰减。

Conclusion: FTRL算法的last-iterate收敛速率为$t^{-1/2}$，部分证实了其与对数后悔度的直觉联系。

Abstract: The convergence analysis of online learning algorithms is central to machine
learning theory, where last-iterate convergence is particularly important, as
it captures the learner's actual decisions and describes the evolution of the
learning process over time. However, in multi-armed bandits, most existing
algorithmic analyses mainly focus on the order of regret, while the
last-iterate (simple regret) convergence rate remains less explored --
especially for the widely studied Follow-the-Regularized-Leader (FTRL)
algorithms. Recently, a growing line of work has established the
Best-of-Both-Worlds (BOBW) property of FTRL algorithms in bandit problems,
showing in particular that they achieve logarithmic regret in stochastic
bandits. Nevertheless, their last-iterate convergence rate has not yet been
studied. Intuitively, logarithmic regret should correspond to a $t^{-1}$
last-iterate convergence rate. This paper partially confirms this intuition
through theoretical analysis, showing that the Bregman divergence, defined by
the regular function $\Psi(p)=-4\sum_{i=1}^{d}\sqrt{p_i}$ associated with the
BOBW FTRL algorithm $1/2$-Tsallis-INF (arXiv:1807.07623), between the point
mass on the optimal arm and the probability distribution over the arm set
obtained at iteration $t$, decays at a rate of $t^{-1/2}$.

</details>


### [698] [Clustering by Denoising: Latent plug-and-play diffusion for single-cell data](https://arxiv.org/abs/2510.22835)
*Dominik Meier,Shixing Yu,Sagnik Nandy,Promit Ghosal,Kyra Gan*

Main category: cs.LG

TL;DR: scRNA-seq  clustering is challenging due to noise and variability. Our method uses a latent diffusion framework with input-space steering to improve accuracy and biological coherence.


<details>
  <summary>Details</summary>
Motivation: Clustering accuracy in scRNA-seq is difficult due to measurement noise and biological variability, which cause different cell types to project closely in standard latent spaces.

Method: We introduce a latent plug-and-play diffusion framework that separates observation and denoising spaces using a Gibbs sampling procedure. This involves applying a learned diffusion prior in a low-dimensional latent space for denoising while reintroducing noise into the high-dimensional observation space for steering, ensuring faithfulness to the original data structure. The method offers adaptive noise handling, uncertainty quantification, and generalizable denoising.

Result: The method improves clustering accuracy on synthetic data across varied noise levels and dataset shifts. On real-world single-cell data, it demonstrates improved biological coherence in cell clusters, with cluster boundaries better aligning with known cell type markers and developmental trajectories.

Conclusion: Our latent diffusion framework with input-space steering significantly enhances clustering accuracy and biological interpretability for scRNA-seq data.

Abstract: Single-cell RNA sequencing (scRNA-seq) enables the study of cellular
heterogeneity. Yet, clustering accuracy, and with it downstream analyses based
on cell labels, remain challenging due to measurement noise and biological
variability. In standard latent spaces (e.g., obtained through PCA), data from
different cell types can be projected close together, making accurate
clustering difficult. We introduce a latent plug-and-play diffusion framework
that separates the observation and denoising space. This separation is
operationalized through a novel Gibbs sampling procedure: the learned diffusion
prior is applied in a low-dimensional latent space to perform denoising, while
to steer this process, noise is reintroduced into the original high-dimensional
observation space. This unique "input-space steering" ensures the denoising
trajectory remains faithful to the original data structure. Our approach offers
three key advantages: (1) adaptive noise handling via a tunable balance between
prior and observed data; (2) uncertainty quantification through principled
uncertainty estimates for downstream analysis; and (3) generalizable denoising
by leveraging clean reference data to denoise noisier datasets, and via
averaging, improve quality beyond the training set. We evaluate robustness on
both synthetic and real single-cell genomics data. Our method improves
clustering accuracy on synthetic data across varied noise levels and dataset
shifts. On real-world single-cell data, our method demonstrates improved
biological coherence in the resulting cell clusters, with cluster boundaries
that better align with known cell type markers and developmental trajectories.

</details>


### [699] [Self-induced stochastic resonance: A physics-informed machine learning approach](https://arxiv.org/abs/2510.22848)
*Divyesh Savaliya,Marius E. Yamakou*

Main category: cs.LG

TL;DR: 本研究提出了一个结合物理信息和机器学习的框架，用于模拟和预测随机 FitzHugh-Nagumo 神经元中的自诱导随机共振（SISR）。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是开发一种数据高效且可解释的代理模型，用于模拟和分析多尺度随机系统中由噪声引起的相干性。

Method: 该方法将控制随机微分方程和 SISR 渐近时间尺度匹配约束直接嵌入到基于噪声增强状态预测器的物理信息神经网络 (PINN) 中。损失函数集成了数据保真度、动力学残差以及源自 Kramers 逃逸理论的基于势垒的物理约束。

Result: 训练好的 PINN 能够准确预测放电序列相干性对噪声强度、兴奋性和时间尺度分离的依赖关系，其精度和泛化能力均优于纯数据驱动方法，且计算量显著减少。

Conclusion: 该框架为模拟和分析多尺度随机系统中的噪声诱导相干性提供了一种数据高效且可解释的代理模型。

Abstract: Self-induced stochastic resonance (SISR) is the emergence of coherent
oscillations in slow-fast excitable systems driven solely by noise, without
external periodic forcing or proximity to a bifurcation. This work presents a
physics-informed machine learning framework for modeling and predicting SISR in
the stochastic FitzHugh-Nagumo neuron. We embed the governing stochastic
differential equations and SISR-asymptotic timescale-matching constraints
directly into a Physics-Informed Neural Network (PINN) based on a
Noise-Augmented State Predictor architecture. The composite loss integrates
data fidelity, dynamical residuals, and barrier-based physical constraints
derived from Kramers' escape theory. The trained PINN accurately predicts the
dependence of spike-train coherence on noise intensity, excitability, and
timescale separation, matching results from direct stochastic simulations with
substantial improvements in accuracy and generalization compared with purely
data-driven methods, while requiring significantly less computation. The
framework provides a data-efficient and interpretable surrogate model for
simulating and analyzing noise-induced coherence in multiscale stochastic
systems.

</details>


### [700] [Encoder-Decoder Diffusion Language Models for Efficient Training and Inference](https://arxiv.org/abs/2510.22852)
*Marianne Arriola,Yair Schiff,Hao Phung,Aaron Gokaslan,Volodymyr Kuleshov*

Main category: cs.LG

TL;DR: 离散扩散模型通过采用编码器-解码器架构，并为表示干净标记和去噪损坏标记的任务分配专用模块，从而实现了比传统自回归方法更快的推理速度，并在文本摘要、翻译和数学推理任务上取得了高质量和高吞吐量的权衡。


<details>
  <summary>Details</summary>
Motivation: 现有的离散扩散模型使用仅解码器架构，需要在每个去噪步骤中调用整个网络，导致计算成本高昂。本研究旨在解决此问题。

Method: 提出了一种新的编码器-解码器架构（E2D2），其中编码器负责表示干净标记，轻量级解码器负责迭代地精炼噪声序列。该架构还支持对分区序列块以提高质量的块扩散模型进行更快地训练。

Result: E2D2 在文本摘要、翻译和数学推理任务上实现了生成质量和推理吞吐量之间的卓越权衡。

Conclusion: E2D2 架构通过分离表示干净标记和去噪损坏标记的任务，并利用专门的训练和采样算法，有效地加速了离散扩散模型的推理和训练过程。

Abstract: Discrete diffusion models enable parallel token sampling for faster inference
than autoregressive approaches. However, prior diffusion models use a
decoder-only architecture, which requires sampling algorithms that invoke the
full network at every denoising step and incur high computational cost. Our key
insight is that discrete diffusion models perform two types of computation: 1)
representing clean tokens and 2) denoising corrupted tokens, which enables us
to use separate modules for each task. We propose an encoder-decoder
architecture to accelerate discrete diffusion inference, which relies on an
encoder to represent clean tokens and a lightweight decoder to iteratively
refine a noised sequence. We also show that this architecture enables faster
training of block diffusion models, which partition sequences into blocks for
better quality and are commonly used in diffusion language model inference. We
introduce a framework for Efficient Encoder-Decoder Diffusion (E2D2),
consisting of an architecture with specialized training and sampling
algorithms, and we show that E2D2 achieves superior trade-offs between
generation quality and inference throughput on summarization, translation, and
mathematical reasoning tasks. We provide the code, model weights, and blog post
on the project page: https://m-arriola.com/e2d2

</details>


### [701] [A Review of End-to-End Precipitation Prediction Using Remote Sensing Data: from Divination to Machine Learning](https://arxiv.org/abs/2510.22855)
*Yugong Zeng,Jonathan Wu*

Main category: cs.LG

TL;DR: 本篇论文回顾了从古代到现代的人工智能预测降水的方法。


<details>
  <summary>Details</summary>
Motivation: 回顾降水预测方法的历史和技术演变，重点介绍人工智能在其中的应用。

Method: 综述了从古代方法、气象科学基础、数值天气预报到机器学习和深度学习模型的端到端降水预测技术。

Result: 对跨越多个时代和范式的研究进行了综合，展示了端到端降水预测的历史。

Conclusion: 描绘了端到端降水预测的历史，并概述了下一代预测系统的未来发展方向。

Abstract: Precipitation prediction has undergone a profound transformation -- from
early symbolic and empirical methods rooted in divination and observation, to
modern technologies based on atmospheric physics and artificial intelligence.
This review traces the historical and technological evolution of precipitation
forecasting, presenting a survey about end-to-end precipitation prediction
technologies that spans ancient practices, the foundations of meteorological
science, the rise of numerical weather prediction (NWP), and the emergence of
machine learning (ML) and deep learning (DL) models. We first explore
traditional and indigenous forecasting methods, then describe the development
of physical modeling and statistical frameworks that underpin contemporary
operational forecasting. Particular emphasis is placed on recent advances in
neural network-based approaches, including automated deep learning,
interpretability-driven design, and hybrid physical-data models. By compositing
research across multiple eras and paradigms, this review not only depicts the
history of end-to-end precipitation prediction but also outlines future
directions in next generation forecasting systems.

</details>


### [702] [Guardian: Decoupling Exploration from Safety in Reinforcement Learning](https://arxiv.org/abs/2510.22859)
*Kaitong Cai,Jusheng Zhang,Jing Yang,Keze Wang*

Main category: cs.LG

TL;DR: RLPD-GX框架通过分离策略优化和安全约束，解决了混合离线-在线强化学习（O2O RL）中的稳定性问题，并在Atari-100k等任务上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 混合离线-在线强化学习（O2O RL）虽然有潜力提高样本效率和探索能力，但由于离线数据和在线数据之间的分布偏移而存在不稳定的问题。

Method: 提出RLPD-GX框架，将策略优化与安全执行解耦：一个寻求奖励的学习者自由探索，一个基于投影的守护者保证规则一致的执行和安全的价值备份。为进一步稳定训练，提出动态课程，逐步扩展时间范围并退火离线-在线数据混合。通过受保护的Bellman算子的收缩性质证明收敛性。

Result: 在Atari-100k上实现了3.02的归一化平均分数（比之前的方法提高了45%），同时增强了安全性和稳定性。消融实验表明在安全关键和长时域任务上均有持续的改进。

Conclusion: RLPD-GX框架通过分离安全执行，为实现鲁棒的O2O RL提供了一条简单而有原则的途径，并提出了一种在强化学习中协调探索和安全性的更广泛范式。

Abstract: Hybrid offline--online reinforcement learning (O2O RL) promises both sample
efficiency and robust exploration, but suffers from instability due to
distribution shift between offline and online data. We introduce RLPD-GX, a
framework that decouples policy optimization from safety enforcement: a
reward-seeking learner explores freely, while a projection-based guardian
guarantees rule-consistent execution and safe value backups. This design
preserves the exploratory value of online interactions without collapsing to
conservative policies. To further stabilize training, we propose dynamic
curricula that gradually extend temporal horizons and anneal offline--online
data mixing. We prove convergence via a contraction property of the guarded
Bellman operator, and empirically show state-of-the-art performance on
Atari-100k, achieving a normalized mean score of 3.02 (+45\% over prior hybrid
methods) with stronger safety and stability. Beyond Atari, ablations
demonstrate consistent gains across safety-critical and long-horizon tasks,
underscoring the generality of our design. Extensive and comprehensive results
highlight decoupled safety enforcement as a simple yet principled route to
robust O2O RL, suggesting a broader paradigm for reconciling exploration and
safety in reinforcement learning.

</details>


### [703] [Long-Term PM2.5 Forecasting Using a DTW-Enhanced CNN-GRU Model](https://arxiv.org/abs/2510.22863)
*Amirali Ataee Naeini,Arshia Ataee Naeini,Fatemeh Karami Mohammadi,Omid Ghaffarpasand*

Main category: cs.LG

TL;DR: 本文提出了一种结合动态时间规整(DTW)和CNN-GRU的深度学习框架，用于在监测网络稀疏的城市（如伊朗伊斯法罕）实现可靠的长期PM2.5预测，显著提高了预测稳定性和准确性，尤其是在10天预测方面取得了突破性进展。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在超过48小时的PM2.5预测上存在稳定性问题，尤其是在监测网络稀疏的城市，这影响了公众健康预警系统的可靠性。

Method: 提出了一种新的深度学习框架，包括：1. 使用DTW识别相似站点以进行历史数据采样；2. 结合气象特征的轻量级CNN-GRU架构；3. 针对稀疏网络的优化设计。

Result: 在伊朗伊斯法罕进行了为期多年的多站点小时数据实验，与现有最先进的深度学习方法相比，在24小时预测中达到了R2=0.91的优异表现，并且首次实现了R2=0.73（240小时）的稳定10天PM2.5预测，性能无明显下降。

Conclusion: 该框架通过DTW和CNN-GRU的结合，有效解决了长期PM2.5预测的稳定性和准确性问题，尤其适用于监测网络稀疏、资源受限的城市环境，满足了早期预警系统的关键需求。其计算效率高，且不依赖外部工具。

Abstract: Reliable long-term forecasting of PM2.5 concentrations is critical for public
health early-warning systems, yet existing deep learning approaches struggle to
maintain prediction stability beyond 48 hours, especially in cities with sparse
monitoring networks. This paper presents a deep learning framework that
combines Dynamic Time Warping (DTW) for intelligent station similarity
selection with a CNN-GRU architecture to enable extended-horizon PM2.5
forecasting in Isfahan, Iran, a city characterized by complex pollution
dynamics and limited monitoring coverage. Unlike existing approaches that rely
on computationally intensive transformer models or external simulation tools,
our method integrates three key innovations: (i) DTW-based historical sampling
to identify similar pollution patterns across peer stations, (ii) a lightweight
CNN-GRU architecture augmented with meteorological features, and (iii) a
scalable design optimized for sparse networks. Experimental validation using
multi-year hourly data from eight monitoring stations demonstrates superior
performance compared to state-of-the-art deep learning methods, achieving R2 =
0.91 for 24-hour forecasts. Notably, this is the first study to demonstrate
stable 10-day PM2.5 forecasting (R2 = 0.73 at 240 hours) without performance
degradation, addressing critical early-warning system requirements. The
framework's computational efficiency and independence from external tools make
it particularly suitable for deployment in resource-constrained urban
environments.

</details>


### [704] [Limits of Generative Pre-Training in Structured EMR Trajectories with Irregular Sampling](https://arxiv.org/abs/2510.22878)
*Nicholas I-Hsien Kuo,Blanca Gallego,Louisa Jorm*

Main category: cs.LG

TL;DR: 文章的TLDR总结


<details>
  <summary>Details</summary>
Motivation: 描述此论文的动机

Method: 此论文使用的方法

Result: 此论文的结果

Conclusion: 此论文的结论

Abstract: Foundation models refer to architectures trained on vast datasets using
autoregressive pre-training from natural language processing to capture
intricate patterns and motifs. They were originally developed to transfer such
learned knowledge to downstream predictive tasks. Recently, however, some
studies repurpose these learned representations for phenotype discovery without
rigorous validation, risking superficially realistic but clinically incoherent
embeddings. To test this mismatch, we trained two autoregressive models -- a
sequence-to-sequence LSTM and a reduced Transformer -- on longitudinal ART for
HIV and Acute Hypotension datasets. Controlled irregularity was added during
training via random inter-visit gaps, while test sequences stayed complete.
Patient-trajectory synthesis evaluated distributional and correlational
fidelity. Both reproduced feature distributions but failed to preserve
cross-feature structure -- showing that generative pre-training yields local
realism but limited clinical coherence. These results highlight the need for
domain-specific evaluation and support trajectory synthesis as a practical
probe before fine-tuning or deployment.

</details>


### [705] [Learning Reconfigurable Representations for Multimodal Federated Learning with Missing Data](https://arxiv.org/abs/2510.22880)
*Duong M. Nguyen,Trong Nghia Hoang,Thanh Trung Huynh,Quoc Viet Hung Nguyen,Phi Le Nguyen*

Main category: cs.LG

TL;DR: 该研究提出了一种新的多模态联邦学习框架，通过局部自适应表示来解决数据不完整和异构性问题，并在实际场景中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态联邦学习方法在处理客户端数据不完整和异构性问题时存在局限，导致模型聚合效果不佳。本研究旨在解决一个更普遍和实际的问题：客户端观察到的模态子集不同，并且可能存在模态内缺失的特征。

Method: 提出了一种新的联邦学习框架，该框架具有基于可学习的客户端嵌入控制的局部自适应表示。这些嵌入能够编码客户端的数据缺失模式，并作为重新配置信号来对齐全局聚合表示与客户端的局部上下文。此外，嵌入控制可以通过跨客户端进行聚合，以增强重新配置信号的鲁棒性。

Result: 在多个具有不同数据缺失模式的联邦多模态基准测试中，该方法在严重数据不完整的情况下取得了高达36.45%的性能提升。理论分析也为该方法提供了性能界限。

Conclusion: 所提出的框架通过局部自适应表示能够有效处理多模态联邦学习中的数据不完整和异构性问题，并在实际应用中展现出优越的性能。

Abstract: Multimodal federated learning in real-world settings often encounters
incomplete and heterogeneous data across clients. This results in misaligned
local feature representations that limit the effectiveness of model
aggregation. Unlike prior work that assumes either differing modality sets
without missing input features or a shared modality set with missing features
across clients, we consider a more general and realistic setting where each
client observes a different subset of modalities and might also have missing
input features within each modality. To address the resulting misalignment in
learned representations, we propose a new federated learning framework
featuring locally adaptive representations based on learnable client-side
embedding controls that encode each client's data-missing patterns.
  These embeddings serve as reconfiguration signals that align the globally
aggregated representation with each client's local context, enabling more
effective use of shared information. Furthermore, the embedding controls can be
algorithmically aggregated across clients with similar data-missing patterns to
enhance the robustness of reconfiguration signals in adapting the global
representation. Empirical results on multiple federated multimodal benchmarks
with diverse data-missing patterns across clients demonstrate the efficacy of
the proposed method, achieving up to 36.45\% performance improvement under
severe data incompleteness. The method is also supported by a theoretical
analysis with an explicit performance bound that matches our empirical
observations. Our source codes are provided at
https://github.com/nmduonggg/PEPSY

</details>


### [706] [Offline Preference Optimization via Maximum Marginal Likelihood Estimation](https://arxiv.org/abs/2510.22881)
*Saeed Najafi,Alona Fyshe*

Main category: cs.LG

TL;DR: MMPO是一种新颖的、更简单的LLM对齐方法，通过最大化边缘似然估计来实现，无需显式奖励模型和熵最大化，并在实验中表现出更好的稳定性和对齐效果。


<details>
  <summary>Details</summary>
Motivation: 标准的人类偏好对齐方法（如RLHF）复杂且不稳定，需要更简单有效的方法。

Method: 提出MMPO，一种基于最大化边缘似然估计（MML）的新方法，通过最大化首选文本输出的边缘对数似然来实现，并利用偏好对作为样本进行近似。该方法不依赖于显式的奖励模型和熵最大化。

Result: MMPO在1.35亿至80亿参数的模型上进行了实验，证明了其在超参数β上的稳定性优于基线方法，并且在偏好对齐方面达到或优于现有方法，同时更好地保留了基础模型的语言能力。

Conclusion: MMPO通过在梯度更新中进行隐式偏好优化，实现了稳定且有效的LLM对齐，同时保留了模型的通用语言能力。

Abstract: Aligning Large Language Models (LLMs) with human preferences is crucial, but
standard methods like Reinforcement Learning from Human Feedback (RLHF) are
often complex and unstable. In this work, we propose a new, simpler approach
that recasts alignment through the lens of Maximum Marginal Likelihood (MML)
estimation. Our new MML based Preference Optimization (MMPO) maximizes the
marginal log-likelihood of a preferred text output, using the preference pair
as samples for approximation, and forgoes the need for both an explicit reward
model and entropy maximization. We theoretically demonstrate that MMPO
implicitly performs preference optimization, producing a weighted gradient that
naturally up-weights chosen responses over rejected ones. Across models ranging
from 135M to 8B parameters, we empirically show that MMPO: 1) is more stable
with respect to the hyperparameter $\beta$ compared to alternative baselines,
and 2) achieves competitive or superior preference alignment while better
preserving the base model's general language capabilities. Through a series of
ablation experiments, we show that this improved performance is indeed
attributable to MMPO's implicit preference optimization within the gradient
updates.

</details>


### [707] [AI based signage classification for linguistic landscape studies](https://arxiv.org/abs/2510.22885)
*Yuqin Jiang,Song Jiang,Jacob Algrim,Trevor Harms,Maxwell Koenen,Xinya Lan,Xingyu Li,Chun-Han Lin,Jia Liu,Jiayang Sun,Henry Zenger*

Main category: cs.LG

TL;DR: 本研究提出使用AI驱动的语言检测方法来自动化语言景观（LL）分析，以解决传统手动方法的耗时问题。通过对檀香山唐人街的1449张图像进行OCR和语言分类，并进行人工验证，模型准确率达到79%。研究指出了五种常见的错误标签类型，并发现AI模型会平等处理图像所有区域，包括人类通常忽略的背景文本。尽管存在局限性，但AI在LL研究中具有巨大潜力，但目前尚不能完全信任，因此建议采用AI自动化与人工验证相结合的混合方法。


<details>
  <summary>Details</summary>
Motivation: 传统语言景观（LL）研究依赖手动摄影和标注，耗时且难以覆盖大范围区域。本研究旨在探索使用AI驱动的语言检测方法来自动化LL分析，以提高效率。

Method: 使用檀香山唐人街的1449张地理参考照片数据集，应用AI进行光学字符识别（OCR）和语言分类，并通过人工验证来检查准确性。

Result: AI模型整体准确率为79%，识别出五种常见的错误标签类型（扭曲、反射、表面降解、涂鸦、幻觉）。AI模型将图像所有区域同等对待，包括人类通常忽略的边缘或背景文本。

Conclusion: AI辅助工作流程有潜力用于LL研究，以减少耗时过程。然而，由于存在局限性和错误标签，AI尚不能完全信任。建议采用结合AI自动化和人工验证的混合方法，以实现更可靠、更高效的工作流程。

Abstract: Linguistic Landscape (LL) research traditionally relies on manual photography
and annotation of public signages to examine distribution of languages in urban
space. While such methods yield valuable findings, the process is
time-consuming and difficult for large study areas. This study explores the use
of AI powered language detection method to automate LL analysis. Using Honolulu
Chinatown as a case study, we constructed a georeferenced photo dataset of
1,449 images collected by researchers and applied AI for optical character
recognition (OCR) and language classification. We also conducted manual
validations for accuracy checking. This model achieved an overall accuracy of
79%. Five recurring types of mislabeling were identified, including distortion,
reflection, degraded surface, graffiti, and hallucination. The analysis also
reveals that the AI model treats all regions of an image equally, detecting
peripheral or background texts that human interpreters typically ignore.
Despite these limitations, the results demonstrate the potential of integrating
AI-assisted workflows into LL research to reduce such time-consuming processes.
However, due to all the limitations and mis-labels, we recognize that AI cannot
be fully trusted during this process. This paper encourages a hybrid approach
combining AI automation with human validation for a more reliable and efficient
workflow.

</details>


### [708] [Transforming volcanic monitoring: A dataset and benchmark for onboard volcano activity detection](https://arxiv.org/abs/2510.22889)
*Darshana Priyasad,Tharindu Fernando,Maryam Haghighat,Harshala Gammulle,Clinton Fookes*

Main category: cs.LG

TL;DR: 本论文提出了一个用于火山活动和喷发检测的新数据集，并展示了在卫星上进行实时检测的可行性。


<details>
  <summary>Details</summary>
Motivation: 火山灾害带来严峻挑战和经济损失，而现有的卫星监测能力受限于缺乏标注数据。

Method: 创建了一个包含全球多样化火山数据的标注数据集，并进行了基准测试，同时探索了在Intel Movidius Myriad X VPU上进行机载检测的可行性。

Result: 开发了一个用于火山活动和喷发检测的新数据集，并进行了基准测试，证明了在卫星上进行实时检测的可行性。

Conclusion: 该数据集和机载检测方法为火山监测和预警系统提供了基础，并推动了相关技术的发展。

Abstract: Natural disasters, such as volcanic eruptions, pose significant challenges to
daily life and incur considerable global economic losses. The emergence of
next-generation small-satellites, capable of constellation-based operations,
offers unparalleled opportunities for near-real-time monitoring and onboard
processing of such events. However, a major bottleneck remains the lack of
extensive annotated datasets capturing volcanic activity, which hinders the
development of robust detection systems. This paper introduces a novel dataset
explicitly designed for volcanic activity and eruption detection, encompassing
diverse volcanoes worldwide. The dataset provides binary annotations to
identify volcanic anomalies or non-anomalies, covering phenomena such as
temperature anomalies, eruptions, and volcanic ash emissions. These annotations
offer a foundational resource for developing and evaluating detection models,
addressing a critical gap in volcanic monitoring research. Additionally, we
present comprehensive benchmarks using state-of-the-art models to establish
baselines for future studies. Furthermore, we explore the potential for
deploying these models onboard next-generation satellites. Using the Intel
Movidius Myriad X VPU as a testbed, we demonstrate the feasibility of volcanic
activity detection directly onboard. This capability significantly reduces
latency and enhances response times, paving the way for advanced early warning
systems. This paves the way for innovative solutions in volcanic disaster
management, encouraging further exploration and refinement of onboard
monitoring technologies.

</details>


### [709] [Charting the Design Space of Neural Graph Representations for Subgraph Matching](https://arxiv.org/abs/2510.22897)
*Vaibhav Raj,Indradyumna Roy,Ashwin Ramachandran,Soumen Chakrabarti,Abir De*

Main category: cs.LG

TL;DR: 本研究提出了一种对子图匹配的神经方法进行统一设计的框架，探索了该设计空间中未被充分利用的组合，并取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的神经子图匹配方法只占据了设计空间中孤立的几个点，大部分区域仍未被探索。本研究旨在对该设计空间进行全面的探索，以发现新的、性能更优的组合。

Method: 研究者提出了一个包含多个维度的设计空间，包括查询图和语料库图之间的基于注意力的或基于软置换的交互方式、对齐节点或边的策略，以及用于整合图的神经表示的最终评分网络的形式。通过广泛的实验，研究者探索了这个设计空间中的各种组合。

Result: 研究发现，在设计空间中经过仔细选择且前所未见的组合能够带来显著的性能提升。此外，本研究还揭示了神经图表示和交互方面的宝贵见解和通用设计原则。

Conclusion: 本研究对神经子图匹配的设计空间进行了全面的探索，不仅提升了性能，还为该领域提供了有价值的设计原则和见解。

Abstract: Subgraph matching is vital in knowledge graph (KG) question answering,
molecule design, scene graph, code and circuit search, etc. Neural methods have
shown promising results for subgraph matching. Our study of recent systems
suggests refactoring them into a unified design space for graph matching
networks. Existing methods occupy only a few isolated patches in this space,
which remains largely uncharted. We undertake the first comprehensive
exploration of this space, featuring such axes as attention-based vs. soft
permutation-based interaction between query and corpus graphs, aligning nodes
vs. edges, and the form of the final scoring network that integrates neural
representations of the graphs. Our extensive experiments reveal that judicious
and hitherto-unexplored combinations of choices in this space lead to large
performance benefits. Beyond better performance, our study uncovers valuable
insights and establishes general design principles for neural graph
representation and interaction, which may be of wider interest.

</details>


### [710] [On the Anisotropy of Score-Based Generative Models](https://arxiv.org/abs/2510.22899)
*Andreas Floros,Seyed-Mohsen Moosavi-Dezfooli,Pier Luigi Dragotti*

Main category: cs.LG

TL;DR: 本研究提出“分数各向异性方向”（SADs）来分析分数生成模型中网络结构如何影响归纳偏置，并用此预测模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 为了理解和预测现代分数生成模型中的网络结构如何影响其归纳偏置和泛化能力。

Method: 引入“分数各向异性方向”（SADs）作为一种分析工具，通过分析这些方向如何适应网络输出的几何形状，来预测模型的泛化能力。实验部分使用了合成数据和标准的图像基准数据集。

Result: SADs能够可靠地捕捉到模型行为的细微差别，并与通过Wasserstein度量衡量的下游性能相关联。

Conclusion: SADs为理解和预测生成模型中的方向性偏置提供了一种新的有效方法。

Abstract: We investigate the role of network architecture in shaping the inductive
biases of modern score-based generative models. To this end, we introduce the
Score Anisotropy Directions (SADs), architecture-dependent directions that
reveal how different networks preferentially capture data structure. Our
analysis shows that SADs form adaptive bases aligned with the architecture's
output geometry, providing a principled way to predict generalization ability
in score models prior to training. Through both synthetic data and standard
image benchmarks, we demonstrate that SADs reliably capture fine-grained model
behavior and correlate with downstream performance, as measured by Wasserstein
metrics. Our work offers a new lens for explaining and predicting directional
biases of generative models.

</details>


### [711] [Towards Personalized Treatment Plan: Geometrical Model-Agnostic Approach to Counterfactual Explanations](https://arxiv.org/abs/2510.22911)
*Daniel Sin,Milad Toutounchian*

Main category: cs.LG

TL;DR: 文章提出了一个名为SSBA（Segmented Sampling for Boundary Approximation）的方法，用于在高维空间中生成反事实解释，该方法通过拟合模型、寻找决策边界、确定约束条件和计算最近点来工作。SSBA通过离散化方法找到多个决策边界点，并从中识别出最近的、满足约束的可行反事实解释。实验表明，SSBA在多个数据集上优于现有方法，在L2范数距离上减少了5%到50%，并且能够处理现实世界中的约束条件（如不可变特征和类别特征）。此外，SSBA的运行时间也比基于网格的方法更优。


<details>
  <summary>Details</summary>
Motivation: 在高维空间中生成反事实解释，并处理现实世界中的约束条件，同时提高效率。

Method: 提出SSBA（Segmented Sampling for Boundary Approximation）方法，该方法包括四个步骤：1. 数据集拟合模型；2. 寻找决策边界；3. 确定问题约束；4. 计算最近的反事实解释。具体实现上，采用离散化方法，利用二分搜索找到多个决策边界点，并搜索最近的可行反事实解释。

Result: 在四个不同维度的数据集上，SSBA方法在L2范数距离上比现有方法有5%到50%的提升。该方法能够处理不可变特征和类别特征等现实世界约束。在运行时，SSBA比基于网格的方法更有效率。

Conclusion: SSBA是一种简单、有效且模型无关的方法，能够计算出最近的、满足约束条件（即可行性）的反事实解释。

Abstract: In our article, we describe a method for generating counterfactual
explanations in high-dimensional spaces using four steps that involve fitting
our dataset to a model, finding the decision boundary, determining constraints
on the problem, and computing the closest point (counterfactual explanation)
from that boundary. We propose a discretized approach where we find many
discrete points on the boundary and then identify the closest feasible
counterfactual explanation. This method, which we later call $\textit{Segmented
Sampling for Boundary Approximation}$ (SSBA), applies binary search to find
decision boundary points and then searches for the closest boundary point.
Across four datasets of varying dimensionality, we show that our method can
outperform current methods for counterfactual generation with reductions in
distance between $5\%$ to $50\%$ in terms of the $L_2$ norm. Our method can
also handle real-world constraints by restricting changes to immutable and
categorical features, such as age, gender, sex, height, and other related
characteristics such as the case for a health-based dataset. In terms of
runtime, the SSBA algorithm generates decision boundary points on multiple
orders of magnitude in the same given time when we compare to a grid-based
approach. In general, our method provides a simple and effective model-agnostic
method that can compute nearest feasible (i.e. realistic with constraints)
counterfactual explanations. All of our results and our code can be found here
at this link:
$\href{https://github.com/dsin85691/SSBA_For_Counterfactuals}{https://github.com/
dsin85691/SSBA\_For\_Counterfactuals}$

</details>


### [712] [Simple Denoising Diffusion Language Models](https://arxiv.org/abs/2510.22926)
*Huaisheng Zhu,Zhengyu Chen,Shijie Zhou,Zhihui Xie,Yige Yuan,Zhimeng Guo,Siyuan Xu,Hangfan Zhang,Vasant Honavar,Teng Xiao*

Main category: cs.LG

TL;DR: MDLM在语言生成中表现良好，但在少样本场景下性能下降。USDM有所改善，但损失函数复杂。本文提出了一种简化的去噪损失函数，用于USDM，并引入了一种对比学习的负梯度，以提高生成质量。


<details>
  <summary>Details</summary>
Motivation: MDLM在少样本场景下性能下降，且无法直接采用现有蒸馏方法。USDM虽然有所改善，但损失函数复杂，难以扩展。

Method: 提出了一种简化的、基于去噪的损失函数，用于USDM，该函数仅优化被噪声替换的token，从而稳定训练并达到ELBO-level性能。此外，通过将去噪视为自监督学习，并引入对比学习的负梯度，进一步提高了生成质量。

Result: 简化的去噪损失函数稳定了USDM的训练，并达到了ELBO-level性能。对比学习的负梯度带来了额外的生成质量提升。

Conclusion: 所提出的简化的去噪损失函数和对比学习的负梯度，能够有效解决USDM的训练和扩展性问题，并提高语言生成质量。

Abstract: Diffusion models have recently been extended to language generation through
Masked Diffusion Language Models (MDLMs), which achieve performance competitive
with strong autoregressive models. However, MDLMs tend to degrade in the
few-step regime and cannot directly adopt existing few-step distillation
methods designed for continuous diffusion models, as they lack the intrinsic
property of mapping from noise to data. Recent Uniform-state Diffusion Models
(USDMs), initialized from a uniform prior, alleviate some limitations but still
suffer from complex loss formulations that hinder scalability. In this work, we
propose a simplified denoising-based loss for USDMs that optimizes only
noise-replaced tokens, stabilizing training and matching ELBO-level
performance. Furthermore, by framing denoising as self-supervised learning, we
introduce a simple modification to our denoising loss with contrastive-inspired
negative gradients, which is practical and yield additional improvements in
generation quality.

</details>


### [713] [Diffuse to Detect: A Generalizable Framework for Anomaly Detection with Diffusion Models Applications to UAVs and Beyond](https://arxiv.org/abs/2510.22928)
*Mingze Gong,Juan Du,Jianbang You*

Main category: cs.LG

TL;DR: DTD利用扩散模型进行异常检测，通过单步去噪预测来快速准确地识别异常，并结合GNN处理传感器关系，具有良好的泛化性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的异常检测方法在处理复杂、高维数据（如无人机传感器读数）时，存在灵敏度、可扩展性和捕捉复杂依赖关系能力不足的挑战，影响了运行安全。

Method: 提出DTD框架，该框架将扩散模型应用于异常检测，通过单步扩散过程预测噪声模式，并利用图神经网络（GNN）对传感器关系进行建模，采用双分支架构（参数化神经网络评分和非参数统计方法）以平衡效率和透明度。

Result: 在无人机传感器数据、多元时间序列和图像上的广泛评估表明，DTD的性能优于现有方法，证明了其在不同数据模式下的通用性。

Conclusion: DTD是一种创新的、通用的异常检测解决方案，能够快速、准确地识别复杂数据中的异常，特别适用于工业监控等安全关键应用。

Abstract: Anomaly detection in complex, high-dimensional data, such as UAV sensor
readings, is essential for operational safety but challenging for existing
methods due to their limited sensitivity, scalability, and inability to capture
intricate dependencies. We propose the Diffuse to Detect (DTD) framework, a
novel approach that innovatively adapts diffusion models for anomaly detection,
diverging from their conventional use in generative tasks with high inference
time. By comparison, DTD employs a single-step diffusion process to predict
noise patterns, enabling rapid and precise identification of anomalies without
reconstruction errors. This approach is grounded in robust theoretical
foundations that link noise prediction to the data distribution's score
function, ensuring reliable deviation detection. By integrating Graph Neural
Networks to model sensor relationships as dynamic graphs, DTD effectively
captures spatial (inter-sensor) and temporal anomalies. Its two-branch
architecture, with parametric neural network-based energy scoring for
scalability and nonparametric statistical methods for interpretability,
provides flexible trade-offs between computational efficiency and transparency.
Extensive evaluations on UAV sensor data, multivariate time series, and images
demonstrate DTD's superior performance over existing methods, underscoring its
generality across diverse data modalities. This versatility, combined with its
adaptability, positions DTD as a transformative solution for safety-critical
applications, including industrial monitoring and beyond.

</details>


### [714] [Robust Uncertainty Quantification for Self-Evolving Large Language Models via Continual Domain Pretraining](https://arxiv.org/abs/2510.22931)
*Xiaofan Zhou,Lu Cheng*

Main category: cs.LG

TL;DR: 本研究提出了一种自适应拒绝和非交换性保形预测框架，以提高持续学习场景下大语言模型（LLM）的统计可靠性，解决了传统保形预测在持续域预训练（CDP）中面临的分布偏移和信息量不足的问题。


<details>
  <summary>Details</summary>
Motivation: 在知识快速增长的背景下，持续学习（CL）对于使大语言模型（LLM）能够适应并保持有效性至关重要。然而，在CL环境下，尤其是在持续域预训练（CDP）中，LLM的统计可靠性保障却鲜有关注。传统的保形预测（CP）虽然能为LLM提供正确性保障，但在CDP中面临严峻挑战：测试数据的域分布未知或不断变化，可能导致CP的保障失效。此外，当需要高覆盖率时，CP可能为无法回答的查询产生过大的预测集，降低信息量。

Method: 本研究提出了一种自适应拒绝和非交换性保形预测框架。首先，该框架利用基于Transformer的聚类方法估计测试集中问题在不同域上的分布，并据此对校准数据进行重加权或重采样。在此基础上，自适应拒绝CP允许LLM在置信度或能力显著变化时选择性地放弃回答。

Result: 通过广泛的实验证明，该框架能够同时提升CP在CDP场景下的有效性和可靠性。

Conclusion: 本研究提出的自适应拒绝和非交换性保形预测框架，有效解决了持续域预训练中大语言模型统计可靠性保障的挑战，提升了预测的准确性和信息量。

Abstract: Continual Learning (CL) is essential for enabling self-evolving large
language models (LLMs) to adapt and remain effective amid rapid knowledge
growth. Yet, despite its importance, little attention has been given to
establishing statistical reliability guarantees for LLMs under CL, particularly
in the setting of continual domain pretraining (CDP). Conformal Prediction (CP)
has shown promise in offering correctness guarantees for LLMs, but it faces
major challenges in CDP: testing data often stems from unknown or shifting
domain distributions, under which CP may no longer provide valid guarantees.
Moreover, when high coverage is required, CP can yield excessively large
prediction sets for unanswerable queries, reducing informativeness. To address
these challenges, we introduce an adaptive rejection and non-exchangeable CP
framework. Our method first estimates the distribution of questions across
domains in the test set using transformer-based clustering, then reweights or
resamples the calibration data accordingly. Building on this, adaptive
rejection CP allows the LLM to selectively abstain from answering when its
confidence or competence shifts significantly. Extensive experiments
demonstrate that our framework enhances both the effectiveness and reliability
of CP under CDP scenarios. Our code is available at:
https://anonymous.4open.science/r/CPCL-8C12/

</details>


### [715] [RL-AUX: Reinforcement Learning for Auxiliary Task Generation](https://arxiv.org/abs/2510.22940)
*Judah Goldfeder,Matthew So,Hod Lipson*

Main category: cs.LG

TL;DR: 本文提出一种基于强化学习（RL）的方法，用于动态生成辅助任务，以解决辅助学习（AL）中对标注辅助任务的需求，并在此基础上进一步提出学习样本辅助任务权重的方法，在CIFAR100数据集上取得了优于人工标注辅助任务和双层优化方法的性能。


<details>
  <summary>Details</summary>
Motivation: 辅助学习（AL）作为一种多任务学习（MTL）的特殊形式，通过在辅助任务上训练网络来提升主任务的性能，但在实践中需要标注辅助任务，这可能需要大量的人力和领域知识。现有的元学习方法虽然能生成辅助任务，但常用的双层优化方法计算成本高且代码复杂。

Method: 本文提出一种基于强化学习（RL）的框架，由一个RL代理动态选择每个数据点的辅助标签，并通过提升主任务的性能来获得奖励。此外，还探索了学习每个数据点辅助损失权重的最优策略。

Result: 在CIFAR100数据集上，所提出的RL方法在20个超类别的分类任务上，其性能超过了人工标注的辅助任务，并与一种主流的双层优化方法相当。更进一步，所提出的权重学习方法显著优于所有基线方法，例如，一种考虑权重的RL方法使VGG16架构的测试准确率达到80.9%，而人工标注辅助任务仅为75.53%。

Conclusion: （1）证明了RL可以作为一种动态生成辅助任务的可行方法；（2）展示了与辅助标签同时学习的每样本辅助任务权重可以获得优异的结果。

Abstract: Auxiliary Learning (AL) is a special case of Multi-task Learning (MTL) in
which a network trains on auxiliary tasks to improve performance on its main
task. This technique is used to improve generalization and, ultimately,
performance on the network's main task. AL has been demonstrated to improve
performance across multiple domains, including navigation, image
classification, and natural language processing. One weakness of AL is the need
for labeled auxiliary tasks, which can require human effort and domain
expertise to generate. Meta Learning techniques have been used to solve this
issue by learning an additional auxiliary task generation network that can
create helpful tasks for the primary network. The most prominent techniques
rely on Bi-Level Optimization, which incurs computational cost and increased
code complexity. To avoid the need for Bi-Level Optimization, we present an
RL-based approach to dynamically create auxiliary tasks. In this framework, an
RL agent is tasked with selecting auxiliary labels for every data point in a
training set. The agent is rewarded when their selection improves the
performance on the primary task. We also experiment with learning optimal
strategies for weighing the auxiliary loss per data point. On the 20-Superclass
CIFAR100 problem, our RL approach outperforms human-labeled auxiliary tasks and
performs as well as a prominent Bi-Level Optimization technique. Our weight
learning approaches significantly outperform all of these benchmarks. For
example, a Weight-Aware RL-based approach helps the VGG16 architecture achieve
80.9% test accuracy while the human-labeled auxiliary task setup achieved
75.53%. The goal of this work is to (1) prove that RL is a viable approach to
dynamically generate auxiliary tasks and (2) demonstrate that per-sample
auxiliary task weights can be learned alongside the auxiliary task labels and
can achieve strong results.

</details>


### [716] [Hazard-Responsive Digital Twin for Climate-Driven Urban Resilience and Equity](https://arxiv.org/abs/2510.22941)
*Zhenglai Shen,Hongyu Zhou*

Main category: cs.LG

TL;DR: 该研究提出了一个危害响应数字孪生（H-RDT）框架，结合了物理信息神经网络、多模态数据融合和关注公平性的风险分析，用于城市层面的气候灾害响应。


<details>
  <summary>Details</summary>
Motivation: 为了应对野火引发的停电和城市热浪等复合气候灾害对城市稳定性和公平性的挑战。

Method: H-RDT框架结合了物理信息神经网络建模、多模态数据融合（物联网、无人机、卫星数据）以及关注公平性的风险分析。采用强化学习进行数据融合，并进行公平性调整的风险映射。

Result: 在模拟的城市区域，H-RDT在传感器部分丢失的情况下，仍能保持稳定的室内温度预测（约31-33°C），并能复现停电引起的温度骤升和恢复。该框架能够识别高风险人群聚集区（学校、诊所、低收入住房）。

Conclusion: H-RDT框架通过前瞻性干预措施（如预先启动冷却中心和微电网共享），能够显著降低人口加权的 थर्मल风险（11-13%）和极端风险（95%置信区间，7-17%），并减少过热时间（最多9%）。该框架为城市适应气候变化提供了一个可转移的基础，将物理灾害建模与社会公平和决策智能联系起来，朝着自适应、学习驱动、以公平为中心的气候适应决策支持系统迈进。

Abstract: Compounding climate hazards, such as wildfire-induced outages and urban
heatwaves, challenge the stability and equity of cities. We present a
Hazard-Responsive Digital Twin (H-RDT) that combines physics-informed neural
network modeling, multimodal data fusion, and equity-aware risk analytics for
urban-scale response. In a synthetic district with diverse building archetypes
and populations, a simulated wildfire-outage-heatwave cascade shows that H-RDT
maintains stable indoor temperature predictions (approximately 31 to 33 C)
under partial sensor loss, reproducing outage-driven surges and recovery. The
reinforcement learning based fusion module adaptively reweights IoT, UAV, and
satellite inputs to sustain spatiotemporal coverage, while the equity-adjusted
mapping isolates high-vulnerability clusters (schools, clinics, low-income
housing). Prospective interventions, such as preemptive cooling-center
activation and microgrid sharing, reduce population-weighted thermal risk by 11
to 13 percent, shrink the 95th-percentile (tail) risk by 7 to 17 percent, and
cut overheating hours by up to 9 percent. Beyond the synthetic demonstration,
the framework establishes a transferable foundation for real-city
implementation, linking physical hazard modeling with social equity and
decision intelligence. The H-RDT advances digital urban resilience toward
adaptive, learning-based, and equity-centered decision support for climate
adaptation.

</details>


### [717] [Hankel Singular Value Regularization for Highly Compressible State Space Models](https://arxiv.org/abs/2510.22951)
*Paul Schwerdtner,Jules Berman,Benjamin Peherstorfer*

Main category: cs.LG

TL;DR: 通过正则化状态空间模型的汉克尔奇异值，可以提高模型的可压缩性，同时保持高精度。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络中的状态空间模型层难以压缩，需要一种方法来提高其可压缩性。

Method: 提出一种正则化方法，通过正则化状态空间模型的汉克尔奇异值来促使其快速衰减，并开发了一种有效的算法来计算汉克尔奇异值，以实现可扩展性。

Result: 在长程 Arena 基准测试中，正则化后的状态空间层比标准状态空间层具有高达 10 倍的可压缩性，同时保持了高精度。

Conclusion: 通过汉克尔奇异值正则化可以显著提高状态空间模型的压缩性能，同时保持其预测精度。

Abstract: Deep neural networks using state space models as layers are well suited for
long-range sequence tasks but can be challenging to compress after training. We
use that regularizing the sum of Hankel singular values of state space models
leads to a fast decay of these singular values and thus to compressible models.
To make the proposed Hankel singular value regularization scalable, we develop
an algorithm to efficiently compute the Hankel singular values during training
iterations by exploiting the specific block-diagonal structure of the system
matrices that is we use in our state space model parametrization. Experiments
on Long Range Arena benchmarks demonstrate that the regularized state space
layers are up to 10$\times$ more compressible than standard state space layers
while maintaining high accuracy.

</details>


### [718] [Manifold Approximation leads to Robust Kernel Alignment](https://arxiv.org/abs/2510.22953)
*Mohammad Tariqul Islam,Du Liu,Deblina Sarkar*

Main category: cs.LG

TL;DR: CKA衡量指标存在缺陷，我们提出了MKA，它能更好地衡量表示，尤其是在现实世界和合成数据集的经验评估中。


<details>
  <summary>Details</summary>
Motivation: CKA衡量指标在比较表示、确定网络等价性和神经科学研究中很受欢迎，但它没有考虑到潜在的流形，并且依赖于许多在不同数据尺度下表现不同的启发式方法。

Method: 我们提出了Manifold approximated Kernel Alignment (MKA)，它将流形几何纳入对齐任务，并推导了MKA的理论框架。

Result: 通过在合成数据集和真实世界示例中进行实证评估，我们将MKA与其同行进行了表征和比较。

Conclusion: 我们的研究结果表明，面向流形的内核对齐为度量表示提供了更稳健的基础，在表示学习方面具有潜在的应用前景。

Abstract: Centered kernel alignment (CKA) is a popular metric for comparing
representations, determining equivalence of networks, and neuroscience
research. However, CKA does not account for the underlying manifold and relies
on numerous heuristics that cause it to behave differently at different scales
of data. In this work, we propose Manifold approximated Kernel Alignment (MKA),
which incorporates manifold geometry into the alignment task. We derive a
theoretical framework for MKA. We perform empirical evaluations on synthetic
datasets and real-world examples to characterize and compare MKA to its
contemporaries. Our findings suggest that manifold-aware kernel alignment
provides a more robust foundation for measuring representations, with potential
applications in representation learning.

</details>


### [719] [SARNet: A Spike-Aware consecutive validation Framework for Accurate Remaining Useful Life Prediction](https://arxiv.org/abs/2510.22955)
*Junhao Fan,Wenrui Liang,Wei-Qiang Zhang*

Main category: cs.LG

TL;DR: SARNet通过结合现代TCN、自适应阈值、特征工程和集成回归器，实现了对剩余使用寿命（RUL）的精确预测，解决了现有模型在故障开始时易碎和不透明的问题。


<details>
  <summary>Details</summary>
Motivation: 现有模型在故障开始时表现脆弱且不透明，无法有效处理短时高能尖峰，并且缺乏基于物理的解释。SARNet旨在解决这些问题。

Method: SARNet利用现代TCN预测退化指标，并通过自适应连续阈值来验证真实尖峰并抑制噪声。然后，对易发生故障的段进行特征工程（谱斜率、统计导数、能量比），并使用堆叠的RF-LGBM回归器进行最终的RUL预测。

Result: SARNet在基准数据集上始终降低了误差（RMSE 0.0365，MAE 0.0204），并且保持了轻量级、鲁棒性和易部署性。

Conclusion: SARNet提供了一种精确、鲁棒且可解释的RUL预测方法，优于现有模型。

Abstract: Accurate prediction of remaining useful life (RUL) is essential to enhance
system reliability and reduce maintenance risk. Yet many strong contemporary
models are fragile around fault onset and opaque to engineers: short,
high-energy spikes are smoothed away or misread, fixed thresholds blunt
sensitivity, and physics-based explanations are scarce. To remedy this, we
introduce SARNet (Spike-Aware Consecutive Validation Framework), which builds
on a Modern Temporal Convolutional Network (ModernTCN) and adds spike-aware
detection to provide physics-informed interpretability. ModernTCN forecasts
degradation-sensitive indicators; an adaptive consecutive threshold validates
true spikes while suppressing noise. Failure-prone segments then receive
targeted feature engineering (spectral slopes, statistical derivatives, energy
ratios), and the final RUL is produced by a stacked RF--LGBM regressor. Across
benchmark-ported datasets under an event-triggered protocol, SARNet
consistently lowers error compared to recent baselines (RMSE 0.0365, MAE
0.0204) while remaining lightweight, robust, and easy to deploy.

</details>


### [720] [The Reasoning Trap: How Enhancing LLM Reasoning Amplifies Tool Hallucination](https://arxiv.org/abs/2510.22977)
*Chenlong Yin,Zeyang Sha,Shiwen Cui,Changhua Meng*

Main category: cs.LG

TL;DR: 增强大型语言模型（LLM）的推理能力是构建“先思考后行动”的智能体的关键策略。然而，近期观察表明，更强的推理能力往往伴随着更多的幻觉，但之前没有工作系统地研究推理增强是否会导致工具幻觉。本研究通过引入SimpleToolHalluBench基准测试，探究了“增强推理是否会增加工具幻觉”这一核心问题，该基准测试通过两种故障模式（无可用工具和仅可用干扰工具）来衡量工具幻觉。研究发现，推理增强（通过强化学习或监督微调）与任务性能的提升成比例地增加了工具幻觉，即使是在非工具任务上训练也是如此。此外，研究评估了提示工程和直接偏好优化（DPO）等缓解策略，发现存在能力与可靠性之间的权衡，减少幻觉会降低效用。机制分析表明，推理强化学习会不成比例地破坏与工具可靠性相关的表示，并且幻觉表现为晚层残差流中放大的分歧。这些发现表明，目前的推理增强方法会固有地放大工具幻觉，需要新的训练目标来同时优化能力和可靠性。


<details>
  <summary>Details</summary>
Motivation: 增强LLM的推理能力是构建“先思考后行动”的智能体的关键，但近期观察表明，更强的推理能力往往伴随着更多的幻觉。然而，没有先前的工作系统地研究推理增强是否会导致工具幻觉。本研究旨在解决这一差距，通过探究“增强推理是否会增加工具幻觉”这一核心问题。

Method: 引入SimpleToolHalluBench诊断性基准测试，用于衡量两种故障模式下的工具幻觉：(i)无可用工具，(ii)仅可用干扰工具。通过受控实验，研究了推理增强（通过强化学习、监督微调或推理时切换到逐步思考）对工具幻觉的影响，并评估了提示工程和直接偏好优化（DPO）等缓解策略。最后，通过分析机制来解释幻觉的产生。

Result: 1. 存在因果关系：通过强化学习逐步增强推理能力，会随着任务性能的提升而按比例增加工具幻觉。
2. 效果超越了过拟合：即使在非工具任务（例如数学）上进行训练，也会增加后续的工具幻觉。
3. 效果与方法无关：无论是在监督微调中进行推理增强，还是在推理时通过从直接回答切换到逐步思考来引发推理，都会出现这种现象。
4. 缓解策略的权衡：提示工程和DPO等缓解策略在减少幻觉的同时，会持续降低效用，表明存在能力-可靠性权衡。
5. 机制分析：推理强化学习不成比例地破坏了与工具可靠性相关的表示，幻觉表现为晚层残差流中放大的分歧。

Conclusion: 目前的推理增强方法会固有地放大工具幻觉，强调需要新的训练目标来同时优化能力和可靠性。现有的方法在提高模型能力的同时，牺牲了其可靠性，需要新的研究方向来解决这一根本性的权衡。

Abstract: Enhancing the reasoning capabilities of Large Language Models (LLMs) is a key
strategy for building Agents that "think then act." However, recent
observations, like OpenAI's o3, suggest a paradox: stronger reasoning often
coincides with increased hallucination, yet no prior work has systematically
examined whether reasoning enhancement itself causes tool hallucination. To
address this gap, we pose the central question: Does strengthening reasoning
increase tool hallucination? To answer this, we introduce SimpleToolHalluBench,
a diagnostic benchmark measuring tool hallucination in two failure modes: (i)
no tool available, and (ii) only distractor tools available. Through controlled
experiments, we establish three key findings. First, we demonstrate a causal
relationship: progressively enhancing reasoning through RL increases tool
hallucination proportionally with task performance gains. Second, this effect
transcends overfitting - training on non-tool tasks (e.g., mathematics) still
amplifies subsequent tool hallucination. Third, the effect is method-agnostic,
appearing when reasoning is instilled via supervised fine-tuning and when it is
merely elicited at inference by switching from direct answers to step-by-step
thinking. We also evaluate mitigation strategies including Prompt Engineering
and Direct Preference Optimization (DPO), revealing a fundamental
reliability-capability trade-off: reducing hallucination consistently degrades
utility. Mechanistically, Reasoning RL disproportionately collapses
tool-reliability-related representations, and hallucinations surface as
amplified divergences concentrated in late-layer residual streams. These
findings reveal that current reasoning enhancement methods inherently amplify
tool hallucination, highlighting the need for new training objectives that
jointly optimize for capability and reliability.

</details>


### [721] [How Muon's Spectral Design Benefits Generalization: A Study on Imbalanced Data](https://arxiv.org/abs/2510.22980)
*Bhavya Vasudeva,Puneesh Deora,Yize Zhao,Vatsal Sharan,Christos Thrampoulidis*

Main category: cs.LG

TL;DR: 谱梯度下降 (SpecGD) 在处理不平衡数据时，能与数据的主成分同步学习，从而在早期训练中获得比标准梯度下降 (GD) 和自适应方法（如 Adam）更好的泛化能力，尤其是在深度线性模型中。经验证，像 Muon 和 Shampoo 这样的谱优化器在不平衡数据集上优于其欧几里得对应物。


<details>
  <summary>Details</summary>
Motivation: 探讨了像 Muon 和 Shampoo 这样的谱优化器在深度学习中的泛化能力，特别是它们何时能优于现有算法。

Method: 通过使用不平衡数据作为测试平台，研究了谱优化器的规范形式——谱梯度下降 (SpecGD)，并精确量化了 SpecGD 何时优于标准的欧几里得梯度下降 (GD)。分析扩展到深度线性模型，并通过在各种不平衡数据集上的实证研究进行验证。

Result: 在不平衡数据模型下，SpecGD 与 GD 不同，它能以相同的速率学习所有主成分，而不是优先学习占主导地位的主成分。这导致 SpecGD 在早期训练中实现了更高的平衡准确率，并且这种优势在 GD 使用自适应步长时依然保持。深度线性模型中的分析表明，深度会放大这些效果。实证结果证实了这些理论发现，并表明谱优化器通过促进对数据底层成分更均衡的学习，实现了更优越的泛化能力。

Conclusion: 谱优化器，如 SpecGD，通过同步学习数据的主成分，在处理不平衡数据时能提供比标准梯度下降和自适应方法更好的泛化性能，尤其是在深度学习场景中。

Abstract: The growing adoption of spectrum-aware matrix-valued optimizers such as Muon
and Shampoo in deep learning motivates a systematic study of their
generalization properties and, in particular, when they might outperform
competitive algorithms. We approach this question by introducing appropriate
simplifying abstractions as follows: First, we use imbalanced data as a
testbed. Second, we study the canonical form of such optimizers, which is
Spectral Gradient Descent (SpecGD) -- each update step is $UV^T$ where $U\Sigma
V^T$ is the truncated SVD of the gradient. Third, within this framework we
identify a canonical setting for which we precisely quantify when SpecGD
outperforms vanilla Euclidean GD. For a Gaussian mixture data model and both
linear and bilinear models, we show that unlike GD, which prioritizes learning
dominant principal components of the data first, SpecGD learns all principal
components of the data at equal rates. We demonstrate how this translates to a
growing gap in balanced accuracy favoring SpecGD early in training and further
show that the gap remains consistent even when the GD counterpart uses adaptive
step-sizes via normalization. By extending the analysis to deep linear models,
we show that depth amplifies these effects. We empirically verify our
theoretical findings on a variety of imbalanced datasets. Our experiments
compare practical variants of spectral methods, like Muon and Shampoo, against
their Euclidean counterparts and Adam. The results validate our findings that
these spectral optimizers achieve superior generalization by promoting a more
balanced learning of the data's underlying components.

</details>


### [722] [QoSGMAA: A Robust Multi-Order Graph Attention and Adversarial Framework for Sparse QoS Prediction](https://arxiv.org/abs/2510.22982)
*Guanchen Du,Jianlong Xu,Mingtong Li,Ruiqi Wang,Qianqing Guo,Caiyi Chen,Qingcao Dai,Yuxiang Zeng*

Main category: cs.LG

TL;DR: 现有QoS预测方法在数据稀疏和结构噪声下表现不佳，提出QoSMGAA模型，通过多阶注意力机制和对抗神经网络提升预测精度。


<details>
  <summary>Details</summary>
Motivation: 现有QoS预测方法难以处理网络服务增长带来的相似性问题，且在极端数据稀疏和结构噪声下表现不佳，无法保证服务选择的可靠性和用户满意度。

Method: 提出QoSMGAA模型，结合多阶注意力机制聚合上下文数据，并利用对抗神经网络进行自回归监督学习，同时采用Gumbel-Softmax离散采样生成负样本以捕捉高阶用户-服务交互。

Result: 在真实大规模数据集上的实验表明，QoSMGAA模型显著优于现有基线方法。

Conclusion: QoSMGAA模型在处理复杂和嘈杂的网络服务环境时，能够显著提高QoS预测的准确性，在服务选择和推荐方面具有实际应用潜力。

Abstract: With the rapid advancement of internet technologies, network services have
become critical for delivering diverse and reliable applications to users.
However, the exponential growth in the number of available services has
resulted in many similar offerings, posing significant challenges in selecting
optimal services. Predicting Quality of Service (QoS) accurately thus becomes a
fundamental prerequisite for ensuring reliability and user satisfaction.
However, existing QoS prediction methods often fail to capture rich contextual
information and exhibit poor performance under extreme data sparsity and
structural noise. To bridge this gap, we propose a novel architecture, QoSMGAA,
specifically designed to enhance prediction accuracy in complex and noisy
network service environments. QoSMGAA integrates a multi-order attention
mechanism to aggregate extensive contextual data and predict missing QoS values
effectively. Additionally, our method incorporates adversarial neural networks
to perform autoregressive supervised learning based on transformed interaction
matrices. To capture complex, higher-order interactions among users and
services, we employ a discrete sampling technique leveraging the Gumbel-Softmax
method to generate informative negative samples. Comprehensive experimental
validation conducted on large-scale real-world datasets demonstrates that our
proposed model significantly outperforms existing baseline methods,
highlighting its strong potential for practical deployment in service selection
and recommendation scenarios.

</details>


### [723] [Adaptive Forests For Classification](https://arxiv.org/abs/2510.22991)
*Dimitris Bertsimas,Yubing Cui*

Main category: cs.LG

TL;DR: AF通过自适应选择CART模型权重来改进RF和XGBoost，在20多个真实世界的数据集上表现优于它们。


<details>
  <summary>Details</summary>
Motivation: 提出一种新的自适应森林（AF）方法，以自适应地选择底层CART模型的权重，从而改进现有的随机森林（RF）和极限梯度提升（XGBoost）模型。

Method: AF结合了最优预测策略树（OP2T）框架，为树提供依赖于输入的、不相等的权重，并使用混合整数优化（MIO）动态地优化权重候选，以提高整体性能。

Result: AF在二元和多元分类问题上，在20多个真实世界的数据集上，持续优于RF、XGBoost和其他加权RF模型。

Conclusion: AF通过其新颖的加权方法，在各种分类任务中展现出优越的性能，超越了其他领先的模型。

Abstract: Random Forests (RF) and Extreme Gradient Boosting (XGBoost) are two of the
most widely used and highly performing classification and regression models.
They aggregate equally weighted CART trees, generated randomly in RF or
sequentially in XGBoost. In this paper, we propose Adaptive Forests (AF), a
novel approach that adaptively selects the weights of the underlying CART
models. AF combines (a) the Optimal Predictive-Policy Trees (OP2T) framework to
prescribe tailored, input-dependent unequal weights to trees and (b) Mixed
Integer Optimization (MIO) to refine weight candidates dynamically, enhancing
overall performance. We demonstrate that AF consistently outperforms RF,
XGBoost, and other weighted RF in binary and multi-class classification
problems over 20+ real-world datasets.

</details>


### [724] [Can Language Models Compose Skills In-Context?](https://arxiv.org/abs/2510.22993)
*Zidong Liu,Zhuoyan Xu,Zhenmei Shi,Yingyu Liang*

Main category: cs.LG

TL;DR: 语言模型在组合基本技能以完成复合任务方面存在挑战，即使有思维链示例，简单的任务示例也可能产生负面影响。


<details>
  <summary>Details</summary>
Motivation: 研究语言模型在上下文组合能力方面执行复合任务的能力，该任务结合了上下文示例中演示的基本技能。

Method: 对各种代表性开源语言模型进行系统性实验，利用语言和逻辑任务来探究组合能力。

Result: 简单的任务示例可能产生意想不到的负面影响，因为模型通常难以正确识别和组装技能，即使有思维链示例。

Conclusion: 理论分析表明，将示例与组合中的相应步骤对齐至关重要，这启发了一种改进探测任务性能的方法。

Abstract: Composing basic skills from simple tasks to accomplish composite tasks is
crucial for modern intelligent systems. We investigate the in-context
composition ability of language models to perform composite tasks that combine
basic skills demonstrated in in-context examples. This is more challenging than
the standard setting, where skills and their composition can be learned in
training. We conduct systematic experiments on various representative
open-source language models, utilizing linguistic and logical tasks designed to
probe composition abilities. The results reveal that simple task examples can
have a surprising negative impact on the performance, because the models
generally struggle to recognize and assemble the skills correctly, even with
Chain-of-Thought examples. Theoretical analysis further shows that it is
crucial to align examples with the corresponding steps in the composition. This
inspires a method for the probing tasks, whose improved performance provides
positive support for our insights.

</details>


### [725] [Softmax is $1/2$-Lipschitz: A tight bound across all $\ell_p$ norms](https://arxiv.org/abs/2510.23012)
*Pravin Nair*

Main category: cs.LG

TL;DR: softmax函数在各种机器学习和优化问题中具有核心作用，但其Lipschitz常数分析存在不足。本文首次提供了softmax函数关于所有$\\ell_p$范数（$p \\ge 1$）的统一Lipschitz常数分析，证明其常数为1/2，且在p=1和p=∞时达到该常数。这一更紧密的常数分析直接改进了现有的模型鲁棒性和优化收敛性理论结果，并在ViT、GPT-2、Qwen3-8B等注意力机制模型以及强化学习的随机策略中得到了实证验证。


<details>
  <summary>Details</summary>
Motivation: 现有的机器学习和优化理论中，softmax函数的Lipschitz常数通常被认为是1，这可能导致理论分析不够精确，影响对模型鲁棒性和算法收敛性的评估。

Method: 本文通过数学推导证明了softmax函数在所有$\\ell_p$范数（$p \\ge 1$）下的Lipschitz常数均匀为1/2。进一步分析了在p=1和p=∞时该常数可以达到1/2，而在1 < p < \\infty时，常数严格小于1/2且趋近于1/2。

Result: 得出了softmax函数关于所有$\\ell_p$范数（$p \\ge 1$）的Lipschitz常数均匀为1/2的结论。证明了该常数在p=1和p=∞时可以达到，在其他情况下严格小于1/2。通过在注意力机制模型和强化学习中的实验验证了1/2这一常数的有效性。

Conclusion: 本文对softmax函数的Lipschitz连续性进行了全面的、统一范数的分析，得到了1/2这一更精确的Lipschitz常数。这一发现不仅改进了现有的理论结果，还在实际应用中得到了验证，为理解和提升相关模型的性能提供了新的视角。

Abstract: The softmax function is a basic operator in machine learning and
optimization, used in classification, attention mechanisms, reinforcement
learning, game theory, and problems involving log-sum-exp terms. Existing
robustness guarantees of learning models and convergence analysis of
optimization algorithms typically consider the softmax operator to have a
Lipschitz constant of $1$ with respect to the $\ell_2$ norm. In this work, we
prove that the softmax function is contractive with the Lipschitz constant
$1/2$, uniformly across all $\ell_p$ norms with $p \ge 1$. We also show that
the local Lipschitz constant of softmax attains $1/2$ for $p = 1$ and $p =
\infty$, and for $p \in (1,\infty)$, the constant remains strictly below $1/2$
and the supremum $1/2$ is achieved only in the limit. To our knowledge, this is
the first comprehensive norm-uniform analysis of softmax Lipschitz continuity.
We demonstrate how the sharper constant directly improves a range of existing
theoretical results on robustness and convergence. We further validate the
sharpness of the $1/2$ Lipschitz constant of the softmax operator through
empirical studies on attention-based architectures (ViT, GPT-2, Qwen3-8B) and
on stochastic policies in reinforcement learning.

</details>


### [726] [MoEMeta: Mixture-of-Experts Meta Learning for Few-Shot Relational Learning](https://arxiv.org/abs/2510.23013)
*Han Wu,Jie Yin*

Main category: cs.LG

TL;DR: MoEMeta是一个新颖的元学习框架，通过分离全局共享知识和任务特定上下文来解决小样本知识图谱关系学习中的局限性，实现了有效的泛化和快速适应。


<details>
  <summary>Details</summary>
Motivation: 现有的小样本知识图谱关系学习方法在元学习框架下，存在孤立地学习关系元知识、未能捕捉跨任务的共性关系模式以及难以有效融入关键的任务特定上下文等问题。

Method: MoEMeta框架包含两个关键创新：(1)一个混合专家（MoE）模型，用于学习全局共享的关系原型，以增强泛化能力；(2)一个面向任务的定制化适应机制，用于捕捉局部上下文以实现快速的任务特定适应。

Result: 在三个知识图谱基准上的大量实验和分析表明，MoEMeta持续优于现有基线方法，达到了最先进的性能。

Conclusion: MoEMeta通过平衡全局泛化能力和局部适应性，显著推进了小样本关系学习的进展。

Abstract: Few-shot knowledge graph relational learning seeks to perform reasoning over
relations given only a limited number of training examples. While existing
approaches largely adopt a meta-learning framework for enabling fast adaptation
to new relations, they suffer from two key pitfalls. First, they learn relation
meta-knowledge in isolation, failing to capture common relational patterns
shared across tasks. Second, they struggle to effectively incorporate local,
task-specific contexts crucial for rapid adaptation. To address these
limitations, we propose MoEMeta, a novel meta-learning framework that
disentangles globally shared knowledge from task-specific contexts to enable
both effective generalization and rapid adaptation. MoEMeta introduces two key
innovations: (i) a mixture-of-experts (MoE) model that learns globally shared
relational prototypes to enhance generalization, and (ii) a task-tailored
adaptation mechanism that captures local contexts for fast task-specific
adaptation. By balancing global generalization with local adaptability, MoEMeta
significantly advances few-shot relational learning. Extensive experiments and
analyses on three KG benchmarks demonstrate that MoEMeta consistently
outperforms existing baselines, achieving state-of-the-art performance.

</details>


### [727] [Towards Stable and Effective Reinforcement Learning for Mixture-of-Experts](https://arxiv.org/abs/2510.23027)
*Di Zhang,Xun Wu,Shaohan Huang,Yaru Hao,Li Dong,Zewen Chi,Zhifang Sui,Furu Wei*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Recent advances in reinforcement learning (RL) have substantially improved
the training of large-scale language models, leading to significant gains in
generation quality and reasoning ability. However, most existing research
focuses on dense models, while RL training for Mixture-of-Experts (MoE)
architectures remains underexplored. To address the instability commonly
observed in MoE training, we propose a novel router-aware approach to optimize
importance sampling (IS) weights in off-policy RL. Specifically, we design a
rescaling strategy guided by router logits, which effectively reduces gradient
variance and mitigates training divergence. Experimental results demonstrate
that our method significantly improves both the convergence stability and the
final performance of MoE models, highlighting the potential of RL algorithmic
innovations tailored to MoE architectures and providing a promising direction
for efficient training of large-scale expert models.

</details>


### [728] [Rethinking GSPO: The Perplexity-Entropy Equivalence](https://arxiv.org/abs/2510.23142)
*Chi Liu*

Main category: cs.LG

TL;DR: GSPO的长度归一化重要性比率可以表示为逆困惑度比率和指数交叉熵变化，提供了新的信息论解释。


<details>
  <summary>Details</summary>
Motivation: 提供GSPO长度归一化重要性比率的新视角，并建立其与信息论数量的联系。

Method: 将GSPO的序列级权重表示为逆困惑度比率和指数交叉熵变化，并通过实验验证。

Result: 验证了数学等价性和方差预测，并通过控制实验展示了GSPO在数学推理任务上的表现。

Conclusion: GSPO通过困惑度比率对策略梯度更新进行加权，提供了重要性权重的理论解释，有助于理解其经验特性，如方差缩减和训练稳定性。

Abstract: We provide a new perspective on GSPO's length-normalized importance ratios by
establishing their connection to information-theoretic quantities. We show that
GSPO's sequence-level weight $s(\theta) =
(\pi_\theta/\pi_{\theta_{\text{old}}})^{1/|y|}$ can be equivalently expressed
as the inverse perplexity ratio
$\text{PPL}_{\theta_{\text{old}}}/\text{PPL}_\theta$ and as the exponential
cross-entropy change $\exp(\Delta H)$. While the perplexity-entropy
relationship follows from standard definitions, this observation provides a
useful lens for understanding GSPO: the algorithm weights policy gradient
updates by perplexity ratios, offering an information-theoretic interpretation
of the importance weights. This perspective helps explain GSPO's empirical
properties, including log-domain variance reduction through geometric averaging
and stability in training mixture-of-experts models. We validate the
mathematical equivalences and variance predictions through controlled
experiments on mathematical reasoning tasks.

</details>


### [729] [PTPP-Aware Adaptation Scaling Laws: Predicting Domain-Adaptation Performance at Unseen Pre-Training Budgets](https://arxiv.org/abs/2510.23198)
*Etienne Goffinet,Shane Bergsma,Avraham Sheinin,Natalia Vassilieva,Shaheer Muhammad,Preslav Nakov,Gurpreet Gosal*

Main category: cs.LG

TL;DR: 现有的持续预训练（CPT）领域自适应方法在目标域的提升和基础域的稳定性之间难以平衡。本文提出了“感知PTPP”的自适应缩放定律，将预训练预算显式设为一个变量，能够准确预测在不同tokens-per-parameter（PTPP）下的模型适应损失。在多语言设置（英语/阿拉伯语→法语）下，该方法在早期阶段（PTPP={15,31}）训练的模型能够预测PTPP=279下的目标损失，并在多种评估指标上优于不考虑PTPP的基线方法。此外，该方法还可以用于在计算资源限制下，规划满足目标域和遗忘约束的回放比例和自适应token预算。


<details>
  <summary>Details</summary>
Motivation: 持续预训练（CPT）在领域自适应中需要平衡目标域的收益和基础域的稳定性。现有的CPT缩放定律通常假设固定的预训练预算，限制了它们预测不同tokens-per-parameter（PTPP）下适应结果的能力。

Method: 提出“感知PTPP”的自适应缩放定律，将预训练预算作为显式变量，以准确预测在不同PTPP下的适应损失。

Result: 在多语言设置（英语/阿拉伯语→法语）下，PTPP感知缩放定律能够准确预测PTPP=279下的目标损失，并优于PTPP无关的基线方法。此外，该方法在实际应用中可以用于规划满足目标域和遗忘约束的回放比例和自适应token预算。

Conclusion: PTPP感知自适应缩放定律能够更准确地预测领域自适应的结果，并为实际应用提供了有效的规划工具。

Abstract: Continual pre-training (CPT) for domain adaptation must balance target-domain
gains with stability on the base domain. Existing CPT scaling laws typically
assume a fixed pre-training budget, which limits their ability to forecast
adaptation outcomes for models trained at different tokens-per-parameter
(PTPP). We present \emph{PTPP-aware} adaptation scaling laws that make the
pre-training budget an explicit variable, enabling accurate \emph{prediction}
of adaptation loss at unseen \ptpp. On a multilingual setup (English/Arabic
$\rightarrow$ French), PTPP-aware formulations trained on early stages
(\ptpp{}=\{15,31\}) predict target loss at \ptpp{}=279 and outperform a
PTPP-agnostic \dcpt{} transfer baseline on metrics (Huber-on-log,
MAE$_\mathrm{rel}$, calibration slope); full diagnostics (RMSE, MAPE) are in
the appendix. Beyond forecasting, we show a practical use case: planning replay
ratios and adaptation token budgets that satisfy target and forgetting
constraints under compute limits.

</details>


### [730] [Advantage Shaping as Surrogate Reward Maximization: Unifying Pass@K Policy Gradients](https://arxiv.org/abs/2510.23049)
*Christos Thrampoulidis,Sadegh Mahdavi,Wenlong Deng*

Main category: cs.LG

TL;DR: 两种看似不同的策略梯度优化方法（REINFORCE和优势塑形）在可验证奖励的强化学习Pass@K目标上可以统一起来，它们是同一事物的不同方面。


<details>
  <summary>Details</summary>
Motivation: 调和两种看似不同的策略梯度优化方法（REINFORCE 和优势塑形），以实现可验证奖励的强化学习 Pass@K 目标。

Method: 通过逆向工程现有的优势塑形算法，揭示它们隐式地优化了代理奖励。将实际的“硬样本加权”修改解释为奖励层面的正则化。从代理奖励目标出发，推导出现有和新的优势塑形方法。

Result: 揭示了优势塑形算法隐式优化代理奖励，并将“硬样本加权”解释为奖励层面的正则化。提供了一个从代理奖励目标推导优势塑形方法的简单方法。

Conclusion: 将优势塑形和REINFORCE方法统一在代理奖励的框架下，为RLVR策略梯度优化提供了一个新的视角，超越了Pass@K的目标。

Abstract: This note reconciles two seemingly distinct approaches to policy gradient
optimization for the Pass@K objective in reinforcement learning with verifiable
rewards: (1) direct REINFORCE-style methods, and (2) advantage-shaping
techniques that directly modify GRPO. We show that these are two sides of the
same coin. By reverse-engineering existing advantage-shaping algorithms, we
reveal that they implicitly optimize surrogate rewards. We specifically
interpret practical ``hard-example up-weighting'' modifications to GRPO as
reward-level regularization. Conversely, starting from surrogate reward
objectives, we provide a simple recipe for deriving both existing and new
advantage-shaping methods. This perspective provides a lens for RLVR policy
gradient optimization beyond our original motivation of Pass@K.

</details>


### [731] [SwiftTS: A Swift Selection Framework for Time Series Pre-trained Models via Multi-task Meta-Learning](https://arxiv.org/abs/2510.23051)
*Tengxue Zhang,Biao Ouyang,Yang Shu,Xinyang Chen,Chenjuan Guo,Bin Yang*

Main category: cs.LG

TL;DR: SwiftTS是一个用于时间序列预训练模型选择的框架，通过学习历史数据-模型表现关系来预测模型在新数据集上的表现，避免了昂贵的模型微调过程。


<details>
  <summary>Details</summary>
Motivation: 现有预训练模型虽泛化能力强，但在模型库中选择最合适的模型需要耗费大量时间进行单独微调。

Method: SwiftTS采用一种学习驱动的方法，利用跨不同时间尺度的历史数据集-模型表现对来预测模型在新数据集上的表现。它使用一个轻量级的双编码器架构来嵌入时间和模型特征，并计算数据和模型嵌入之间的兼容性得分以实现高效选择。此外，为了提高跨数据集和跨时间尺度的泛化能力，引入了一个自适应专家组合模块和一个可迁移的跨任务学习机制。

Result: 在14个下游数据集和8个预训练模型上的大量实验表明，SwiftTS在时间序列预训练模型选择方面达到了最先进的性能。

Conclusion: SwiftTS能够有效地选择最适合特定下游任务的时间序列预训练模型，显著提高了选择效率和准确性。

Abstract: Pre-trained models exhibit strong generalization to various downstream tasks.
However, given the numerous models available in the model hub, identifying the
most suitable one by individually fine-tuning is time-consuming. In this paper,
we propose \textbf{SwiftTS}, a swift selection framework for time series
pre-trained models. To avoid expensive forward propagation through all
candidates, SwiftTS adopts a learning-guided approach that leverages historical
dataset-model performance pairs across diverse horizons to predict model
performance on unseen datasets. It employs a lightweight dual-encoder
architecture that embeds time series and candidate models with rich
characteristics, computing patchwise compatibility scores between data and
model embeddings for efficient selection. To further enhance the generalization
across datasets and horizons, we introduce a horizon-adaptive expert
composition module that dynamically adjusts expert weights, and the
transferable cross-task learning with cross-dataset and cross-horizon task
sampling to enhance out-of-distribution (OOD) robustness. Extensive experiments
on 14 downstream datasets and 8 pre-trained models demonstrate that SwiftTS
achieves state-of-the-art performance in time series pre-trained model
selection.

</details>


### [732] [Sampling from Energy distributions with Target Concrete Score Identity](https://arxiv.org/abs/2510.23106)
*Sergei Kholkin,Francisco Vargas,Alexander Korotin*

Main category: cs.LG

TL;DR: TCSIS是一种通过学习CTMC反向动力学来从离散状态空间中的非归一化密度采样的方


<details>
  <summary>Details</summary>
Motivation: 需要一种从离散状态空间中的非归一化密度采样的方

Method: 提出了一种名为TCSIS的方法，该方法通过学习CTMC的反向动力学来实现。该方法基于正向CTMC和均匀加噪核，并利用了提出的目标具体分数恒等式，该恒等式将具体分数（两种状态的边际概率之比）与正向均匀扩散核下玻尔兹曼因子期望之比相关联。此公式化能够对具体分数进行蒙特卡洛估计，而无需目标分布的样本或配分函数的计算。使用神经网络来近似具体分数，并提出了两种算法：自归一化TCSIS和无偏TCSIS。

Result: TCSIS在统计物理问题上证明了其有效性。

Conclusion: TCSIS是一种有效的方法，可以从离散状态空间中的非归一化密度采样。

Abstract: We introduce the Target Concrete Score Identity Sampler (TCSIS), a method for
sampling from unnormalized densities on discrete state spaces by learning the
reverse dynamics of a Continuous-Time Markov Chain (CTMC). Our approach builds
on a forward in time CTMC with a uniform noising kernel and relies on the
proposed Target Concrete Score Identity, which relates the concrete score, the
ratio of marginal probabilities of two states, to a ratio of expectations of
Boltzmann factors under the forward uniform diffusion kernel. This formulation
enables Monte Carlo estimation of the concrete score without requiring samples
from the target distribution or computation of the partition function. We
approximate the concrete score with a neural network and propose two
algorithms: Self-Normalized TCSIS and Unbiased TCSIS. Finally, we demonstrate
the effectiveness of TCSIS on problems from statistical physics.

</details>


### [733] [A U-Net and Transformer Pipeline for Multilingual Image Translation](https://arxiv.org/abs/2510.23554)
*Siddharth Sahay,Radhika Agarwal*

Main category: cs.LG

TL;DR: 本研究提出了一个端到端的、可定制的、多语言的、文到文的机器翻译系统，该系统可以直接从图像中进行翻译。


<details>
  <summary>Details</summary>
Motivation: 现有的系统通常依赖于大型的、预先训练好的模型，缺乏灵活性。本研究旨在开发一个完全可定制且适应性强的系统，用于直接从图像中进行翻译。

Method: 本研究提出了一种端到端的机器翻译流程。首先，使用在合成数据集上训练的自定义U-Net模型来检测图像中的文本区域。然后，使用Tesseract引擎识别这些区域中的文本。最后，将识别出的文本输入到一个从头开始训练的自定义序列到序列（Seq2Seq）Transformer模型中，该模型在一个包含5种语言的多语言平行语料库上进行了训练。

Result: 所提出的系统在文本检测准确性、文本识别质量和翻译性能（通过BLEU分数评估）方面都取得了有希望的结果。

Conclusion: 本研究验证了一个定制的、从头开始构建的系统可以直接从图像中进行翻译的可行性。

Abstract: This paper presents an end-to-end multilingual translation pipeline that
integrates a custom U-Net for text detection, the Tesseract engine for text
recognition, and a from-scratch sequence-to-sequence (Seq2Seq) Transformer for
Neural Machine Translation (NMT). Our approach first utilizes a U-Net model,
trained on a synthetic dataset , to accurately segment and detect text regions
from an image. These detected regions are then processed by Tesseract to
extract the source text. This extracted text is fed into a custom Transformer
model trained from scratch on a multilingual parallel corpus spanning 5
languages. Unlike systems reliant on monolithic pre-trained models, our
architecture emphasizes full customization and adaptability. The system is
evaluated on its text detection accuracy, text recognition quality, and
translation performance via BLEU scores. The complete pipeline demonstrates
promising results, validating the viability of a custom-built system for
translating text directly from images.

</details>


### [734] [Neural Emulator Superiority: When Machine Learning for PDEs Surpasses its Training Data](https://arxiv.org/abs/2510.23111)
*Felix Koehler,Nils Thuerey*

Main category: cs.LG

TL;DR: 即使使用低保真度数据训练，神经算子也能超越其训练数据中的数值求解器。


<details>
  <summary>Details</summary>
Motivation: 研究人员挑战了神经算子（或称为模拟器）的性能受限于训练数据保真度的传统观点，发现在某些情况下，即使使用低保真度数据训练，它们也能在评估时展现出比高保真度参考求解器更高的准确性。

Method: 通过理论分析，研究人员揭示了模拟器的归纳偏置、训练目标以及数值误差特性之间的相互作用如何使得在多步预测中实现优于训练数据求解器的性能。

Result: 实验结果表明，在不同偏微分方程（PDEs）和标准神经架构下，模拟器能够隐式地学习到比其训练数据更规则化或具有更优误差累积特性的动力学，从而可能克服训练数据的局限性并减轻数值伪影。

Conclusion: 这项工作促使人们重新评估神经模拟器的基准测试方法，并提出在特定运行条件下，神经模拟器可能实现比其训练数据源更高的物理保真度。

Abstract: Neural operators or emulators for PDEs trained on data from numerical solvers
are conventionally assumed to be limited by their training data's fidelity. We
challenge this assumption by identifying "emulator superiority," where neural
networks trained purely on low-fidelity solver data can achieve higher accuracy
than those solvers when evaluated against a higher-fidelity reference. Our
theoretical analysis reveals how the interplay between emulator inductive
biases, training objectives, and numerical error characteristics enables
superior performance during multi-step rollouts. We empirically validate this
finding across different PDEs using standard neural architectures,
demonstrating that emulators can implicitly learn dynamics that are more
regularized or exhibit more favorable error accumulation properties than their
training data, potentially surpassing training data limitations and mitigating
numerical artifacts. This work prompts a re-evaluation of emulator
benchmarking, suggesting neural emulators might achieve greater physical
fidelity than their training source within specific operational regimes.
Project Page: https://tum-pbs.github.io/emulator-superiority

</details>


### [735] [Seeing Structural Failure Before it Happens: An Image-Based Physics-Informed Neural Network (PINN) for Spaghetti Bridge Load Prediction](https://arxiv.org/abs/2510.23117)
*Omer Jauhar Khan,Sudais Khan,Hafeez Anwar*

Main category: cs.LG

TL;DR: PINNs可用于预测意大利面桥的重量，PIKAN架构取得了0.9603的R²分数和10.50的平均绝对误差，并提供了一个基于Web的界面。


<details>
  <summary>Details</summary>
Motivation: 在结构工程任务中，由于数据有限，PINNs能够将物理定律嵌入深度学习模型，这在预测意大利面桥的重量等任务中尤其有用，有助于理解负载限制和潜在的故障模式。

Method: 提出了一种结合物理约束的PINNs框架，并引入了一种名为PIKAN的新型架构，该架构融合了通用函数逼近理论和物理洞察力。模型使用手动收集或计算机视觉方法收集的结构参数作为输入。

Result: 在包含15个真实意大利面桥（扩充至100个样本）的数据集上，最佳模型达到了0.9603的R²分数和10.50的平均绝对误差（MAE）。

Conclusion: PINNs即使在数据有限的情况下也能提供可靠的结构重量估计，并有助于轻型桥梁设计的早期故障分析。

Abstract: Physics Informed Neural Networks (PINNs) are gaining attention for their
ability to embed physical laws into deep learning models, which is particularly
useful in structural engineering tasks with limited data. This paper aims to
explore the use of PINNs to predict the weight of small scale spaghetti
bridges, a task relevant to understanding load limits and potential failure
modes in simplified structural models. Our proposed framework incorporates
physics-based constraints to the prediction model for improved performance. In
addition to standard PINNs, we introduce a novel architecture named Physics
Informed Kolmogorov Arnold Network (PIKAN), which blends universal function
approximation theory with physical insights. The structural parameters provided
as input to the model are collected either manually or through computer vision
methods. Our dataset includes 15 real bridges, augmented to 100 samples, and
our best model achieves an $R^2$ score of 0.9603 and a mean absolute error
(MAE) of 10.50 units. From applied perspective, we also provide a web based
interface for parameter entry and prediction. These results show that PINNs can
offer reliable estimates of structural weight, even with limited data, and may
help inform early stage failure analysis in lightweight bridge designs.
  The complete data and code are available at
https://github.com/OmerJauhar/PINNS-For-Spaghetti-Bridges.

</details>


### [736] [Variational Masked Diffusion Models](https://arxiv.org/abs/2510.23606)
*Yichi Zhang,Alex Schwing,Zhizhen Zhao*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Masked diffusion models have recently emerged as a flexible framework for
discrete generative modeling. However, a key limitation of standard masked
diffusion is its inability to effectively capture dependencies among tokens
that are predicted concurrently, leading to degraded generation quality when
dependencies among tokens are important. To explicitly model dependencies among
tokens, we propose Variational Masked Diffusion (VMD), a framework that
introduces latent variables into the masked diffusion process. Through
controlled experiments on synthetic datasets, we demonstrate that VMD
successfully learns dependencies that conventional masked diffusion fails to
capture. We further validate the effectiveness of our approach on Sudoku
puzzles and text datasets, where learning of dependencies among tokens improves
global consistency. Across these domains, VMD enhances both generation quality
and dependency awareness, highlighting the value of integrating variational
inference into masked diffusion. Our code is available at:
https://riccizz.github.io/VMD.

</details>


### [737] [A method for outlier detection based on cluster analysis and visual expert criteria](https://arxiv.org/abs/2510.23136)
*Juan A. Lara,David Lizcano,Víctor Rampérez,Javier Soriano*

Main category: cs.LG

TL;DR: 该论文提出了一种基于聚类过程的异常检测方法，通过模仿人类专家的视觉判断标准来识别异常点，克服了现有方法在处理数据离散性方面的不足。该方法在医学（稳定测量法）和神经科学（脑电图）两个领域的时序数据上进行了评估，结果显示其在运行时效率和准确性（假阳性率<2%，可靠性>99%）方面表现令人满意。


<details>
  <summary>Details</summary>
Motivation: 现有异常检测技术在处理数据离散性方面存在不足，本文旨在提出一种能克服此局限性的方法。

Method: 提出一种基于聚类过程的异常检测方法，该方法包含四个准则，模仿人类专家通过视觉分析聚类结果来识别异常点，而非仅仅依赖数值分析。

Result: 该方法在稳定测量法和脑电图（EEG）两个不同领域的时间序列数据上进行了评估，结果令人满意。回归分析结果证实该方法在不同领域检测异常数据的有效性，假阳性率小于2%，可靠性大于99%。

Conclusion: 提出的基于聚类和模仿人类专家视觉判断的异常检测方法在不同领域（尤其是时间序列数据）具有良好的有效性和效率，能够以较低的假阳性率和高可靠性检测出异常数据。

Abstract: Outlier detection is an important problem occurring in a wide range of areas.
Outliers are the outcome of fraudulent behaviour, mechanical faults, human
error, or simply natural deviations. Many data mining applications perform
outlier detection, often as a preliminary step in order to filter out outliers
and build more representative models. In this paper, we propose an outlier
detection method based on a clustering process. The aim behind the proposal
outlined in this paper is to overcome the specificity of many existing outlier
detection techniques that fail to take into account the inherent dispersion of
domain objects. The outlier detection method is based on four criteria designed
to represent how human beings (experts in each domain) visually identify
outliers within a set of objects after analysing the clusters. This has an
advantage over other clustering-based outlier detection techniques that are
founded on a purely numerical analysis of clusters. Our proposal has been
evaluated, with satisfactory results, on data (particularly time series) from
two different domains: stabilometry, a branch of medicine studying
balance-related functions in human beings and electroencephalography (EEG), a
neurological exploration used to diagnose nervous system disorders. To validate
the proposed method, we studied method outlier detection and efficiency in
terms of runtime. The results of regression analyses confirm that our proposal
is useful for detecting outlier data in different domains, with a false
positive rate of less than 2% and a reliability greater than 99%.

</details>


### [738] [Adapting Interleaved Encoders with PPO for Language-Guided Reinforcement Learning in BabyAI](https://arxiv.org/abs/2510.23148)
*Aryan Mathur,Asaduddin Ahmed*

Main category: cs.LG

TL;DR: PDiT架构通过交错感知和决策层，并结合对比损失，在BabyAI环境中提高了深度强化学习代理的稳定性和对齐性。


<details>
  <summary>Details</summary>
Motivation: 现有的深度强化学习代理在处理需要视觉和语言理解的任务时存在困难，通常将感知和决策分开，导致感知模块无法有效学习。

Method: 我们采用了Mao等人（2023）提出的Perception-Decision Interleaving Transformer (PDiT)架构，该架构在单个Transformer中交错进行感知和决策，并引入了受CLIP启发的对比损失来对齐文本和视觉特征。

Result: 在BabyAI GoToLocal环境中，PDiT模型取得了比标准PPO基线模型更稳定的奖励和更强的对齐性。

Conclusion: 交错的Transformer编码器是开发更集成化自主代理的一个有前途的方向。

Abstract: Deep reinforcement learning agents often struggle when tasks require
understanding both vision and language. Conventional architectures typically
isolate perception (for example, CNN-based visual encoders) from
decision-making (policy networks). This separation can be inefficient, since
the policy's failures do not directly help the perception module learn what is
important. To address this, we implement the Perception-Decision Interleaving
Transformer (PDiT) architecture introduced by Mao et al. (2023), a model that
alternates between perception and decision layers within a single transformer.
This interleaving allows feedback from decision-making to refine perceptual
features dynamically. In addition, we integrate a contrastive loss inspired by
CLIP to align textual mission embeddings with visual scene features. We
evaluate the PDiT encoders on the BabyAI GoToLocal environment and find that
the approach achieves more stable rewards and stronger alignment compared to a
standard PPO baseline. The results suggest that interleaved transformer
encoders are a promising direction for developing more integrated autonomous
agents.

</details>


### [739] [Enabling Vibration-Based Gesture Recognition on Everyday Furniture via Energy-Efficient FPGA Implementation of 1D Convolutional Networks](https://arxiv.org/abs/2510.23156)
*Koki Shibata,Tianheng Ling,Chao Qian,Tomokazu Matsui,Hirohiko Suwa,Keiichi Yasumoto,Gregor Schiele*

Main category: cs.LG

TL;DR: 通过在低功耗FPGA上部署紧凑型神经网络，实现能效高、精度有竞争力的实时手势识别。


<details>
  <summary>Details</summary>
Motivation: 智能家居界面的需求不断增长，推动了对基于振动的非侵入式传感方法（如手势识别）的兴趣。然而，以往的研究虽然可行，但通常需要复杂的预处理和大型神经网络（NN），这不仅需要昂贵的高性能硬件，而且能耗高，限制了其实际部署。本研究旨在解决这一问题，提出一种在低功耗FPGA上部署紧凑型NN的能效解决方案，以实现具有可比精度的实时手势识别。

Method: 本研究提出了一系列优化措施：1. 使用原始波形输入代替复杂的光谱预处理，消除了复杂的板载预处理，并将输入尺寸减小了21倍，同时保持了精度。2. 设计了两种适用于嵌入式FPGA的轻量级架构（1D-CNN和1D-SepCNN），参数量从3.69亿减少到21.6万，同时保持了相当的精度。3. 通过仅整数量化和自动RTL生成，实现了无缝的FPGA部署。1D-SepCNN中的乒乓缓冲机制进一步提高了在内存限制下的可部署性。4. 扩展了一个硬件感知搜索框架，以支持考虑精度、可部署性、延迟和能耗的约束驱动的模型配置选择。

Result: 在两个不同用户和普通桌面的滑动方向数据集上进行评估，该方法在AMD Spartan-7 XC7S25 FPGA上实现了低延迟、高能效的推理。在PS数据分割设置下，选定的6位1D-CNN在跨用户平均准确率达到0.970，延迟为9.22毫秒。选定的8位1D-SepCNN进一步将延迟降低到6.83毫秒（比CPU快53倍以上），但精度略有下降（0.949）。两种模型的每次推理能耗均低于1.2毫焦，证明了其适合长期边缘运行。

Conclusion: 本研究提出了一种在低功耗FPGA上部署紧凑型神经网络以实现高效、实时的手势识别的方法。通过一系列优化，包括简化预处理、设计轻量级网络架构、采用仅整数量化和自动RTL生成，以及利用硬件感知搜索框架，该方法在实际应用中实现了低延迟、低功耗和高精度的手势识别，为智能家居等领域的边缘计算应用提供了有前景的解决方案。

Abstract: The growing demand for smart home interfaces has increased interest in
non-intrusive sensing methods like vibration-based gesture recognition. While
prior studies demonstrated feasibility, they often rely on complex
preprocessing and large Neural Networks (NNs) requiring costly high-performance
hardware, resulting in high energy usage and limited real-world deployability.
This study proposes an energy-efficient solution deploying compact NNs on
low-power Field-Programmable Gate Arrays (FPGAs) to enable real-time gesture
recognition with competitive accuracy. We adopt a series of optimizations: (1)
We replace complex spectral preprocessing with raw waveform input, eliminating
complex on-board preprocessing while reducing input size by 21x without
sacrificing accuracy. (2) We design two lightweight architectures (1D-CNN and
1D-SepCNN) tailored for embedded FPGAs, reducing parameters from 369 million to
as few as 216 while maintaining comparable accuracy. (3) With integer-only
quantization and automated RTL generation, we achieve seamless FPGA deployment.
A ping-pong buffering mechanism in 1D-SepCNN further improves deployability
under tight memory constraints. (4) We extend a hardware-aware search framework
to support constraint-driven model configuration selection, considering
accuracy, deployability, latency, and energy consumption. Evaluated on two
swipe-direction datasets with multiple users and ordinary tables, our approach
achieves low-latency, energy-efficient inference on the AMD Spartan-7 XC7S25
FPGA. Under the PS data splitting setting, the selected 6-bit 1D-CNN reaches
0.970 average accuracy across users with 9.22 ms latency. The chosen 8-bit
1D-SepCNN further reduces latency to 6.83 ms (over 53x CPU speedup) with
slightly lower accuracy (0.949). Both consume under 1.2 mJ per inference,
demonstrating suitability for long-term edge operation.

</details>


### [740] [The Benchmarking Epistemology: Construct Validity for Evaluating Machine Learning Models](https://arxiv.org/abs/2510.23191)
*Timo Freiesleben,Sebastian Zezulka*

Main category: cs.LG

TL;DR: 机器学习中的预测基准测试虽然评估模型性能，但单独的分数不足以得出广泛的科学结论，需要关于学习问题、评估函数和数据分布的理论结构假设。


<details>
  <summary>Details</summary>
Motivation: 机器学习研究中的预测基准测试（基于预测性能和竞争排名进行评估）是核心的认识实践，也是日益突出的科学探究方法。然而，基准分数本身充其量只能衡量模型相对于评估数据集和具体学习问题的性能。

Method: 提出一个基于心理测量理论的构造有效性条件框架，并以三个案例研究（ImageNet、WeatherBench 和 Fragile Families Challenge）来检验这些假设在实践中的应用。

Result: 该框架阐明了基准分数支持各种科学声明的条件，将预测基准测试视为一种认识论实践和机器学习中的概念与理论推理的关键场所。

Conclusion: 现有基准测试方法在得出关于理论任务（如图像分类）的科学推断时，需要关于学习问题、评估函数和数据分布的额外假设。通过明确这些假设并提供检验框架，可以更可靠地利用基准测试进行科学推理。

Abstract: Predictive benchmarking, the evaluation of machine learning models based on
predictive performance and competitive ranking, is a central epistemic practice
in machine learning research and an increasingly prominent method for
scientific inquiry. Yet, benchmark scores alone provide at best measurements of
model performance relative to an evaluation dataset and a concrete learning
problem. Drawing substantial scientific inferences from the results, say about
theoretical tasks like image classification, requires additional assumptions
about the theoretical structure of the learning problems, evaluation functions,
and data distributions. We make these assumptions explicit by developing
conditions of construct validity inspired by psychological measurement theory.
We examine these assumptions in practice through three case studies, each
exemplifying a typical intended inference: measuring engineering progress in
computer vision with ImageNet; evaluating policy-relevant weather predictions
with WeatherBench; and examining limitations of the predictability of life
events with the Fragile Families Challenge. Our framework clarifies the
conditions under which benchmark scores can support diverse scientific claims,
bringing predictive benchmarking into perspective as an epistemological
practice and a key site of conceptual and theoretical reasoning in machine
learning.

</details>


### [741] [Increasing LLM Coding Capabilities through Diverse Synthetic Coding Tasks](https://arxiv.org/abs/2510.23208)
*Amal Abed,Ivan Lukic,Jörg K. H. Franke,Frank Hutter*

Main category: cs.LG

TL;DR: LLM在代码生成方面表现出色，但受限于数据集的不足。为解决此问题，我们开发了一个包含近800k指令-推理-代码-测试四元组的数据集生成流程，以提升LLM解决问题的能力。


<details>
  <summary>Details</summary>
Motivation: 现有的代码生成数据集缺乏详细的推理过程，阻碍了LLM在代码生成方面的进一步发展。

Method: 利用竞赛问题和网络爬取内容，结合推理模式和多阶段验证，生成包含任务、推理步骤、解决方案和测试用例的数据集。此外，还使用遗传变异算法来增加任务多样性。

Result: 在包含近800k指令-推理-代码-测试四元组的数据集上微调LLM，可以提升代码生成基准的性能。这种数据还可以替代模型缩放，并跨架构泛化。

Conclusion: 以推理为中心的数据集生成是提高LLM编码能力的有效方法。

Abstract: Large language models (LLMs) have shown impressive promise in code
generation, yet their progress remains limited by the shortage of large-scale
datasets that are both diverse and well-aligned with human reasoning. Most
existing resources pair problems with solutions, but omit the intermediate
thought process that guides coding. To close this gap, we present a scalable
synthetic data generation pipeline that produces nearly 800k
instruction-reasoning-code-test quadruplets. Each sample combines a task, a
step-by-step reasoning trace, a working solution, and executable tests,
enabling models to learn not just the what but also the how of problem solving.
Our pipeline combines four key components: curated contest problems, web-mined
content filtered by relevance classifiers, data expansion guided by reasoning
patterns, and multi-stage execution-based validation. A genetic mutation
algorithm further increases task diversity while maintaining consistency
between reasoning traces and code implementations. Our key finding is that
fine-tuning LLMs on this dataset yields consistent improvements on coding
benchmarks. Beyond raw accuracy, reasoning-aware data can substitute for model
scaling, generalize across architectures, and outperform leading open-source
alternatives under identical sample budgets. Our work establishes
reasoning-centered synthetic data generation as an efficient approach for
advancing coding capabilities in LLMs. We publish our dataset and generation
pipeline to facilitate further research.

</details>


### [742] [GCAO: Group-driven Clustering via Gravitational Attraction and Optimization](https://arxiv.org/abs/2510.23259)
*Qi Li,Jun Wang*

Main category: cs.LG

TL;DR: GCAO算法通过引入基于组的优化机制，解决了传统聚类算法在高维和非均匀分布数据上的局限性，提高了聚类稳定性和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统聚类算法在高维和非均匀分布数据上表现不佳，易受边界点干扰，导致聚类结果不稳定和失真。

Method: 提出了一种名为GCAO（Group-driven Clustering via Gravitational Attraction and Optimization）的算法，该算法引入了组级别的优化机制，将低密度边界点聚合成组进行协同移动，取代了传统的基于点的收缩过程。通过结合局部密度估计和邻域拓扑结构，GCAO在组与其周围环境之间建立了有效的引力相互作用，增强了边界清晰度和结构一致性。使用组作为基本的运动单元，引力收缩策略确保了全局稳定和方向一致的收敛。

Result: 在多个高维数据集上的实验表明，GCAO在NMI、ARI、同质性和ACC指标上分别取得了平均37.13%、52.08%、44.98%和38.81%的提升，优于11种代表性聚类方法，同时保持了有竞争力的效率和可扩展性。

Conclusion: GCAO算法在保持簇的完整性、增强边界可分离性以及确保复杂数据分布下的鲁棒性能方面表现出色。

Abstract: Traditional clustering algorithms often struggle with high-dimensional and
non-uniformly distributed data, where low-density boundary samples are easily
disturbed by neighboring clusters, leading to unstable and distorted clustering
results. To address this issue, we propose a Group-driven Clustering via
Gravitational Attraction and Optimization (GCAO) algorithm. GCAO introduces a
group-level optimization mechanism that aggregates low-density boundary points
into collaboratively moving groups, replacing the traditional point-based
contraction process. By combining local density estimation with neighborhood
topology, GCAO constructs effective gravitational interactions between groups
and their surroundings, enhancing boundary clarity and structural consistency.
Using groups as basic motion units, a gravitational contraction strategy
ensures globally stable and directionally consistent convergence. Experiments
on multiple high-dimensional datasets demonstrate that GCAO outperforms 11
representative clustering methods, achieving average improvements of 37.13%,
52.08%, 44.98%, and 38.81% in NMI, ARI, Homogeneity, and ACC, respectively,
while maintaining competitive efficiency and scalability. These results
highlight GCAO's superiority in preserving cluster integrity, enhancing
boundary separability, and ensuring robust performance on complex data
distributions.

</details>


### [743] [Toward Interpretable Evaluation Measures for Time Series Segmentation](https://arxiv.org/abs/2510.23261)
*Félix Chavelli,Paul Boniol,Michaël Thomazo*

Main category: cs.LG

TL;DR: 现有的时间序列分割评估指标存在局限性，本文提出WARI和SMS两个新的评估指标，以更全面地评估分割质量。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列分割的评估指标主要关注变化点准确性或依赖于点度量（如ARI），未能捕捉分割片段的质量，忽略了错误的性质，并且可解释性有限。

Method: 提出 WARI (加权调整兰德指数) 和 SMS (状态匹配得分) 两个新的评估指标。WARI 能够考虑分割错误的具体位置，SMS 则是一种细粒度度量，可以识别和评估四种基本的分割错误类型，并允许对不同类型的错误进行加权。

Result: 在合成和真实世界基准上对 WARI 和 SMS 进行了实证验证，结果表明它们不仅能更准确地评估分割质量，还能揭示传统度量无法获得的错误来源和类型等见解。

Conclusion: WARI 和 SMS 提供了比传统度量更准确、更具洞察力的时间序列分割评估方法。

Abstract: Time series segmentation is a fundamental task in analyzing temporal data
across various domains, from human activity recognition to energy monitoring.
While numerous state-of-the-art methods have been developed to tackle this
problem, the evaluation of their performance remains critically limited.
Existing measures predominantly focus on change point accuracy or rely on
point-based measures such as Adjusted Rand Index (ARI), which fail to capture
the quality of the detected segments, ignore the nature of errors, and offer
limited interpretability. In this paper, we address these shortcomings by
introducing two novel evaluation measures: WARI (Weighted Adjusted Rand Index),
that accounts for the position of segmentation errors, and SMS (State Matching
Score), a fine-grained measure that identifies and scores four fundamental
types of segmentation errors while allowing error-specific weighting. We
empirically validate WARI and SMS on synthetic and real-world benchmarks,
showing that they not only provide a more accurate assessment of segmentation
quality but also uncover insights, such as error provenance and type, that are
inaccessible with traditional measures.

</details>


### [744] [PAHQ: Accelerating Automated Circuit Discovery through Mixed-Precision Inference Optimization](https://arxiv.org/abs/2510.23264)
*Xinhai Wang,Shu Yang,Liangyu Wang,Lin Zhang,Huanyi Xie,Lijie Hu,Di Wang*

Main category: cs.LG

TL;DR: PAHQ是一种通过优化每次打补丁操作的效率来加速自动电路发现（ACDC）的方法，在不影响模型可解释性的前提下，将运行时间缩短了80%，内存消耗减少了30%。


<details>
  <summary>Details</summary>
Motivation: 现有的ACDC方法在应用于大型语言模型时存在计算效率低下和内存需求高的问题，而基于线性近似的加速方法会牺牲分析的准确性。

Method: PAHQ利用激活打补丁和混合精度量化（MPQ）之间的对齐关系，仅对被探究的组件保持高精度，而对网络中的其他部分降低精度，从而优化每次打补丁操作的效率。

Result: PAHQ将ACDC的运行时间缩短高达80%，内存消耗减少高达30%，同时保持了分析的准确性。

Conclusion: PAHQ是一种训练无关的方法，通过修改注意力计算机制，可以与现有的基于边的电路发现技术集成，为加速模型可解释性方法提供了一种实用且新颖的途径。

Abstract: Circuit discovery, which involves identifying sparse and task-relevant
subnetworks in pre-trained language models, is a cornerstone of mechanistic
interpretability. Automated Circuit Discovery (ACDC) has emerged as a pivotal
methodology in circuit discovery, but its application to large language models
is severely limited by computational inefficiency and prohibitively high memory
requirements. Although several accelerated approaches have been proposed, they
primarily rely on linear approximations to ACDC, which significantly
compromises analytical faithfulness. Our proposed method for accelerating
automated circuit discovery, Per Attention Head Quantization (PAHQ), takes a
fundamentally different approach by optimizing the efficiency of each
individual patching operation. PAHQ leverages a fundamental alignment between
activation patching and mixed-precision quantization (MPQ): interpretability
analysis through patching essentially performs targeted ablation studies.
Therefore, we can maintain high precision exclusively for investigated
components while safely reducing precision elsewhere in the network.
PAHQ-accelerated ACDC reduces runtime by up to 80\% and memory consumption by
up to 30\% compared to unaccelerated ACDC while maintaining faithfulness.
Importantly, our method readily integrates with existing edge-based circuit
discovery techniques by modifying the attention computation mechanism. This
training-free approach provides a practical and novel pathway for accelerating
mechanistic interpretability methods. Our code is available at
https://github.com/626619403/PAHQ.

</details>


### [745] [A Novel Framework for Multi-Modal Protein Representation Learning](https://arxiv.org/abs/2510.23273)
*Runjie Zheng,Zhen Wang,Anjie Qiao,Jiancong Xie,Jiahua Rao,Yuedong Yang*

Main category: cs.LG

TL;DR: DAMPE框架通过最优传输（OT）实现跨模态嵌入对齐，通过条件图生成（CGG）进行信息融合，提高了蛋白质功能预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的蛋白质功能预测方法在融合异构内在信号（如序列和结构）和外部上下文（如蛋白质-蛋白质相互作用和GO术语注释）时面临两大挑战：(i) 跨模态分布不匹配；(ii) 外部数据的关系图噪声会降低GNN的聚合能力。

Method: 提出DAMPE（Diffused and Aligned Multi-modal Protein Embedding）框架，包括基于OT的表示对齐，以解决跨模态异构性；以及基于CGG的信息融合方法，通过条件编码器融合对齐的嵌入来重建图，并吸收图感知知识。

Result: DAMPE在标准的GO基准测试中，性能优于或持平于DPFunc等最先进的方法，AUPR提升了0.002-0.013 pp，Fmax提升了0.004-0.007 pp。消融研究表明，OT对齐贡献了0.043-0.064 pp的AUPR，CGG融合贡献了0.005-0.111 pp的Fmax。

Conclusion: DAMPE提供了一个可扩展且有理论依据的方法，用于鲁棒的多模态蛋白质表示学习，从而显著提高蛋白质功能预测的性能。

Abstract: Accurate protein function prediction requires integrating heterogeneous
intrinsic signals (e.g., sequence and structure) with noisy extrinsic contexts
(e.g., protein-protein interactions and GO term annotations). However, two key
challenges hinder effective fusion: (i) cross-modal distributional mismatch
among embeddings produced by pre-trained intrinsic encoders, and (ii) noisy
relational graphs of extrinsic data that degrade GNN-based information
aggregation. We propose Diffused and Aligned Multi-modal Protein Embedding
(DAMPE), a unified framework that addresses these through two core mechanisms.
First, we propose Optimal Transport (OT)-based representation alignment that
establishes correspondence between intrinsic embedding spaces of different
modalities, effectively mitigating cross-modal heterogeneity. Second, we
develop a Conditional Graph Generation (CGG)-based information fusion method,
where a condition encoder fuses the aligned intrinsic embeddings to provide
informative cues for graph reconstruction. Meanwhile, our theoretical analysis
implies that the CGG objective drives this condition encoder to absorb
graph-aware knowledge into its produced protein representations. Empirically,
DAMPE outperforms or matches state-of-the-art methods such as DPFunc on
standard GO benchmarks, achieving AUPR gains of 0.002-0.013 pp and Fmax gains
0.004-0.007 pp. Ablation studies further show that OT-based alignment
contributes 0.043-0.064 pp AUPR, while CGG-based fusion adds 0.005-0.111 pp
Fmax. Overall, DAMPE offers a scalable and theoretically grounded approach for
robust multi-modal protein representation learning, substantially enhancing
protein function prediction.

</details>


### [746] [Learning from Frustration: Torsor CNNs on Graphs](https://arxiv.org/abs/2510.23288)
*Daiyuan Li,Shreya Arya,Robert Ghrist*

Main category: cs.LG

TL;DR: Torsor CNNs is a new framework for learning on graphs with local symmetries, which generalizes existing architectures and can be applied to multi-view 3D recognition.


<details>
  <summary>Details</summary>
Motivation: Most equivariant neural networks are limited by relying on a single global symmetry, which restricts their use in domains with local symmetries. Torsor CNNs address this limitation by learning on graphs with local symmetries encoded as edge potentials.

Method: Torsor CNNs use a framework based on group synchronization, yielding a Torsor Convolutional Layer that is equivariant to local changes in coordinate frames and a frustration loss regularizer that encourages locally equivariant representations. This framework operates on arbitrary graphs without requiring a global coordinate system or smooth manifold structure, unifying and generalizing architectures like classical CNNs and Gauge CNNs.

Result: The Torsor CNN framework has been mathematically founded and demonstrated to be applicable to multi-view 3D recognition, where relative camera poses naturally define the required edge potentials. It generalizes several existing architectures.

Conclusion: Torsor CNNs provide a general framework for learning on graphs with local symmetries, offering a novel approach to equivariant neural networks and demonstrating applicability in 3D recognition tasks.

Abstract: Most equivariant neural networks rely on a single global symmetry, limiting
their use in domains where symmetries are instead local. We introduce Torsor
CNNs, a framework for learning on graphs with local symmetries encoded as edge
potentials -- group-valued transformations between neighboring coordinate
frames. We establish that this geometric construction is fundamentally
equivalent to the classical group synchronization problem, yielding: (1) a
Torsor Convolutional Layer that is provably equivariant to local changes in
coordinate frames, and (2) the frustration loss -- a standalone geometric
regularizer that encourages locally equivariant representations when added to
any NN's training objective. The Torsor CNN framework unifies and generalizes
several architectures -- including classical CNNs and Gauge CNNs on manifolds
-- by operating on arbitrary graphs without requiring a global coordinate
system or smooth manifold structure. We establish the mathematical foundations
of this framework and demonstrate its applicability to multi-view 3D
recognition, where relative camera poses naturally define the required edge
potentials.

</details>


### [747] [Predicting symbolic ODEs from multiple trajectories](https://arxiv.org/abs/2510.23295)
*Yakup Emre Şahin,Niki Kilbertus,Sören Becker*

Main category: cs.LG

TL;DR: MIO是一个基于Transformer的模型，可以从多个观测轨迹中推断出符号常微分方程（ODEs）。它结合了多实例学习和基于Transformer的符号回归，能有效利用对同一系统的重复观测来学习更具泛化性的动力学表示。


<details>
  <summary>Details</summary>
Motivation: MIO旨在从多个观测轨迹中推断出符号常微分方程（ODEs），并有效利用重复观测来学习更具泛化性的动力学表示。

Method: 通过结合多实例学习和基于Transformer的符号回归，并研究不同的实例聚合策略（如均值聚合），来学习动力学表示。

Result: 在从一维到四维的系统以及不同噪声水平下，MIO的性能始终优于现有基线。

Conclusion: MIO模型能够有效处理不同维度和噪声水平的系统，并优于现有方法。

Abstract: We introduce MIO, a transformer-based model for inferring symbolic ordinary
differential equations (ODEs) from multiple observed trajectories of a
dynamical system. By combining multiple instance learning with
transformer-based symbolic regression, the model effectively leverages repeated
observations of the same system to learn more generalizable representations of
the underlying dynamics. We investigate different instance aggregation
strategies and show that even simple mean aggregation can substantially boost
performance. MIO is evaluated on systems ranging from one to four dimensions
and under varying noise levels, consistently outperforming existing baselines.

</details>


### [748] [GRAD: Real-Time Gated Recurrent Anomaly Detection in Autonomous Vehicle Sensors Using Reinforced EMA and Multi-Stage Sliding Window Techniques](https://arxiv.org/abs/2510.23327)
*Mohammad Hossein Jafari Naeimi,Ali Norouzi,Athena Abdi*

Main category: cs.LG

TL;DR: GRAD是一种用于自动驾驶传感器实时异常检测的方法，结合了统计分析和深度学习，通过REMA和MS-SW技术捕捉短期和长期模式，并使用GRU模型进行异常检测和分类，最后通过恢复模块修复数据，以确保系统的可靠运行。


<details>
  <summary>Details</summary>
Motivation: 确保自动驾驶汽车传感器数据的可靠性，从而保障行车安全。

Method: 该方法整合了增强型指数移动平均（REMA）和多阶段滑动窗口（MS-SW）技术，以识别异常值并捕捉短期和长期模式。然后，使用轻量级门控循环单元（GRU）模型来检测和分类不同类型的异常。最后，一个恢复模块用于修复损坏的传感器数据，以确保持续运行。

Result: 该方法在异常检测和分类方面取得了显著的性能，异常数据F1分数达到97.6%，正常数据F1分数达到99.4%。该模型能够准确地对不同类型的异常进行分类，并使恢复模块能够精确地修复损坏的传感器数据。与现有模型相比，该方法在提高检测准确性和降低计算成本方面取得了更好的平衡。

Conclusion: GRAD是一种可靠且高效的实时自动驾驶汽车传感器异常检测解决方案，能够以最小的计算开销保证安全的车辆运行。

Abstract: This paper introduces GRAD, a real-time anomaly detection method for
autonomous vehicle sensors that integrates statistical analysis and deep
learning to ensure the reliability of sensor data. The proposed approach
combines the Reinforced Exponential Moving Average (REMA), which adapts
smoothing factors and thresholding for outlier detection, with the Multi-Stage
Sliding Window (MS-SW) technique for capturing both short- and long-term
patterns. These features are processed using a lightweight Gated Recurrent Unit
(GRU) model, which detects and classifies anomalies based on bias types, while
a recovery module restores damaged sensor data to ensure continuous system
operation. GRAD has a lightweight architecture consisting of two layers of GRU
with a limited number of neurons that make it appropriate for real-time
applications while maintaining high detection accuracy. The GRAD framework
achieved remarkable performance in anomaly detection and classification. The
model demonstrated an overall F1-score of 97.6% for abnormal data and 99.4% for
normal data, signifying its high accuracy in distinguishing between normal and
anomalous sensor data. Regarding the anomaly classification, GRAD successfully
categorized different anomaly types with high precision, enabling the recovery
module to accurately restore damaged sensor data. Relative to analogous
studies, GRAD surpasses current models by attaining a balance between elevated
detection accuracy and diminished computational expense. These results
demonstrate GRAD's potential as a reliable and efficient solution for real-time
anomaly detection in autonomous vehicle systems, guaranteeing safe vehicle
operation with minimal computational overhead.

</details>


### [749] [Block-Diagonal LoRA for Eliminating Communication Overhead in Tensor Parallel LoRA Serving](https://arxiv.org/abs/2510.23346)
*Xinyu Wang,Jonas M. Kübler,Kailash Budhathoki,Yida Wang,Matthäus Kleindessner*

Main category: cs.LG

TL;DR: 通过约束LoRA因子为块对角矩阵，提出了一种新的LoRA适配器分片方法，无需额外通信即可实现与S-LoRA相当的参数效率和显著的端到端加速。


<details>
  <summary>Details</summary>
Motivation: 现有的S-LoRA方法在同时服务多个LoRA适配器时存在通信开销问题。

Method: 将LoRA因子约束为块对角矩阵，提出了一种新的LoRA适配器分片策略，避免了额外的通信开销。

Result: 在Llama-3.1-70B和Llama-3.1-8B模型上进行了广泛实验，证明了块对角LoRA方法在参数效率上与标准LoRA相当，并且相比S-LoRA实现了显著的端到端加速。

Conclusion: 提出的块对角LoRA方法在保持参数效率的同时，有效解决了S-LoRA的通信开销问题，实现了显著的性能提升。

Abstract: When serving a single base LLM with several different LoRA adapters
simultaneously, the adapters cannot simply be merged with the base model's
weights as the adapter swapping would create overhead and requests using
different adapters could not be batched. Rather, the LoRA computations have to
be separated from the base LLM computations, and in a multi-device setup the
LoRA adapters can be sharded in a way that is well aligned with the base
model's tensor parallel execution, as proposed in S-LoRA. However, the S-LoRA
sharding strategy encounters some communication overhead, which may be small in
theory, but can be large in practice. In this paper, we propose to constrain
certain LoRA factors to be block-diagonal, which allows for an alternative way
of sharding LoRA adapters that does not require any additional communication
for the LoRA computations. We demonstrate in extensive experiments that our
block-diagonal LoRA approach is similarly parameter efficient as standard LoRA
(i.e., for a similar number of parameters it achieves similar downstream
performance) and that it leads to significant end-to-end speed-up over S-LoRA.
For example, when serving on eight A100 GPUs, we observe up to 1.79x (1.23x)
end-to-end speed-up with 0.87x (1.74x) the number of adapter parameters for
Llama-3.1-70B, and up to 1.63x (1.3x) end-to-end speed-up with 0.86x (1.73x)
the number of adapter parameters for Llama-3.1-8B.

</details>


### [750] [Robust Non-negative Proximal Gradient Algorithm for Inverse Problems](https://arxiv.org/abs/2510.23362)
*Hanzhang Wang,Zonglin Liu,Jingyi Xu,Chenyang Wang,Zhiwei Zhong,Qiangqiang Shen*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Proximal gradient algorithms (PGA), while foundational for inverse problems
like image reconstruction, often yield unstable convergence and suboptimal
solutions by violating the critical non-negativity constraint. We identify the
gradient descent step as the root cause of this issue, which introduces
negative values and induces high sensitivity to hyperparameters. To overcome
these limitations, we propose a novel multiplicative update proximal gradient
algorithm (SSO-PGA) with convergence guarantees, which is designed for
robustness in non-negative inverse problems. Our key innovation lies in
superseding the gradient descent step with a learnable sigmoid-based operator,
which inherently enforces non-negativity and boundedness by transforming
traditional subtractive updates into multiplicative ones. This design,
augmented by a sliding parameter for enhanced stability and convergence, not
only improves robustness but also boosts expressive capacity and noise
immunity. We further formulate a degradation model for multi-modal restoration
and derive its SSO-PGA-based optimization algorithm, which is then unfolded
into a deep network to marry the interpretability of optimization with the
power of deep learning. Extensive numerical and real-world experiments
demonstrate that our method significantly surpasses traditional PGA and other
state-of-the-art algorithms, ensuring superior performance and stability.

</details>


### [751] [ZeroFlood: A Geospatial Foundation Model for Data-Efficient Flood Susceptibility Mapping](https://arxiv.org/abs/2510.23364)
*Hyeongkyun Kim,Orestis Oikonomou*

Main category: cs.LG

TL;DR: ZeroFlood是一个地理空间基础模型框架，利用地球观测数据进行洪水易感性绘图，适用于数据稀缺地区。


<details>
  <summary>Details</summary>
Motivation: 数据稀缺地区在洪水易感性绘图（FSM）方面面临挑战，因为传统的水动力模型需要密集的地球物理输入。

Method: 该方法使用地球观测数据（如Sentinel-1或Sentinel-2影像）和思维 in 模态（TiM）推理来微调地理空间基础模型（GFMs），从而实现洪水预测。通过在数据丰富的地区使用配对的地球观测数据和模拟洪水图，ZeroFlood利用跨模态表示学习来弥合数据可用性的差距。

Result: 在TerraMind和Prithvi GFMs上的实验表明，TiM提高了模型的鲁棒性，其中TerraMind-Large配置达到了67.21的F1分数。

Conclusion: 基于基础模型的FSM为洪水风险管理提供了一种可扩展且数据高效的解决方案。

Abstract: Flood susceptibility mapping (FSM) is vital for disaster prevention but
remains challenging in data-scarce regions where hydrodynamic models require
dense geophysical inputs. This work introduces ZeroFlood, a geospatial
foundation model framework for data-efficient FSM. The approach fine-tunes
Geospatial Foundation Models (GFMs) with Thinking-in-Modality (TiM) reasoning,
enabling flood prediction from basic Earth observation data such as Sentinel-1
or Sentinel-2 imagery. Using paired EO and simulated flood maps from data-rich
regions, ZeroFlood bridges data availability gaps through cross-modal
representation learning. Experiments with TerraMind and Prithvi GFMs show that
TiM enhances model robustness, with the TerraMind-Large configuration achieving
an F1 score of 67.21. The results demonstrate the feasibility of
foundation-model-based FSM as a scalable and data-efficient solution for flood
risk management.

</details>


### [752] [Towards a Generalizable AI for Materials Discovery: Validation through Immersion Coolant Screening](https://arxiv.org/abs/2510.23371)
*Hyunseung Kim,Dae-Woong Jeong,Changyoung Park,Won-Ji Lee,Ha-Eun Lee,Ji-Hye Lee,Rodrigo Hormazabal,Sung Moon Ko,Sumin Lee,Soorin Yim,Chanhui Lee,Sehui Han,Sang-Ho Cha,Woohyung Lim*

Main category: cs.LG

TL;DR: GATE是一个通用的AI框架，可以同时学习34种物理化学性质，并应用于数据中心浸没式冷却液的发现，成功识别了92,861个潜在分子，其中4个得到了实验验证。


<details>
  <summary>Details</summary>
Motivation: 现有AI模型在材料发现方面存在问题特定性，需要针对新性质进行额外的数据收集和重新训练。本研究旨在开发一个通用的AI框架，能够学习多种物理化学性质，并减少多标准筛选中的虚假负例。

Method: 开发并验证了一个名为GATE（Geometrically Aligned Transfer Encoder）的通用AI框架，该框架能够将34种跨越热、电、机械和光学领域的物理化学性质对齐到一个共享的几何空间中，从而学习跨性质相关性，减少虚假负例。

Result: GATE框架在没有进行任何特定问题配置的情况下，直接应用于数据中心浸没式冷却液的发现，筛选了数十亿个候选分子，并识别出92,861个有前景的分子。其中四个分子得到了实验或文献验证，其性能与商业冷却液相当或更优。

Conclusion: GATE是一个现成可用的、可泛化的AI平台，能够广泛应用于各种材料发现任务，解决了现有AI模型在材料发现中的局限性。

Abstract: Artificial intelligence (AI) has emerged as a powerful accelerator of
materials discovery, yet most existing models remain problem-specific,
requiring additional data collection and retraining for each new property. Here
we introduce and validate GATE (Geometrically Aligned Transfer Encoder) -- a
generalizable AI framework that jointly learns 34 physicochemical properties
spanning thermal, electrical, mechanical, and optical domains. By aligning
these properties within a shared geometric space, GATE captures cross-property
correlations that reduce disjoint-property bias -- a key factor causing false
negatives in multi-criteria screening. To demonstrate its generalizability,
GATE -- without any problem-specific reconfiguration -- was directly applied to
the discovery of immersion cooling fluids for data centers, a stringent
real-world challenge defined by the Open Compute Project (OCP). Screening
billions of candidates, GATE identified 92,861 molecules as promising for
practical deployment. Four were experimentally or literarily validated, showing
strong agreement with wet-lab measurements and performance comparable to or
exceeding a commercial coolant. These results establish GATE as a ready-to-use,
generalizable AI platform readily applicable across diverse materials discovery
tasks.

</details>


### [753] [The Best of N Worlds: Aligning Reinforcement Learning with Best-of-N Sampling via max@k Optimisation](https://arxiv.org/abs/2510.23393)
*Farid Bagirov,Mikhail Arkhipov,Ksenia Sycheva,Evgeniy Glukhov,Egor Bogomolov*

Main category: cs.LG

TL;DR: RLVR 在数学和编程领域取得了成功，但可能损害模型的探索能力。本研究提出了一种优化 max@k 指标的方法，以提高模型的生成多样性并优化 Best-of-N 采样策略。


<details>
  <summary>Details</summary>
Motivation: RLVR 在数学和编程领域取得了显著的进步，但其微调过程可能损害模型的探索能力，导致生成多样性下降，并影响 Best-of-N 采样策略的性能。

Method: 本研究推导了一种用于直接优化 max@k 指标的无偏样本内梯度估计，并将其扩展到样本效率更高的离策略更新。

Result: 实验表明，所提出的目标在离策略场景下能有效优化 max@k 指标，并使模型与 Best-of-N 推理策略保持一致。

Conclusion: 所提出的方法通过直接优化 max@k 指标，有效解决了 RLVR 在 Best-of-N 推理策略下可能出现的性能下降问题，提高了生成多样性。

Abstract: The application of Reinforcement Learning with Verifiable Rewards (RLVR) to
mathematical and coding domains has demonstrated significant improvements in
the reasoning and problem-solving abilities of Large Language Models. Despite
its success in single generation problem solving, the reinforcement learning
fine-tuning process may harm the model's exploration ability, as reflected in
decreased diversity of generations and a resulting degradation of performance
during Best-of-N sampling for large N values. In this work, we focus on
optimizing the max@k metric, a continuous generalization of pass@k. We derive
an unbiased on-policy gradient estimate for direct optimization of this metric.
Furthermore, we extend our derivations to the off-policy updates, a common
element in modern RLVR algorithms, that allows better sample efficiency.
Empirically, we show that our objective effectively optimizes max@k metric in
off-policy scenarios, aligning the model with the Best-of-N inference strategy.

</details>


### [754] [Eigen-Value: Efficient Domain-Robust Data Valuation via Eigenvalue-Based Approach](https://arxiv.org/abs/2510.23409)
*Youngjun Choi,Joonseong Kang,Sungjun Lim,Kyungwoo Song*

Main category: cs.LG

TL;DR: Eigen-Value (EV) 是一种用于 OOD (out-of-distribution) 鲁棒性的数据估值框架，它仅使用 ID (in-distribution) 数据子集，并通过特征值来近似域差异，从而在不增加额外计算成本的情况下提高 OOD 鲁棒性和价值排名的稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有数据估值方法在 OOD 场景下效果不佳且计算成本高，需要一种能在 OOD 场景下保持鲁棒性且计算高效的方法。

Method: EV 框架通过计算 ID 数据协方差矩阵的特征值比率来近似域差异，并利用摄动理论估计每个数据点对该差异的边际贡献。EV 可以作为附加项插入到基于 ID 损失的方法中，无需额外的训练。

Result: EV 在现实世界的数据集上展示了其 OOD 鲁棒性和价值排名稳定性，并且计算量轻，适合大规模应用。

Conclusion: EV 为 OOD 鲁棒性数据估值提供了一个实际可行且高效的解决方案，特别适用于存在域偏移的大规模场景。

Abstract: Data valuation has become central in the era of data-centric AI. It drives
efficient training pipelines and enables objective pricing in data markets by
assigning a numeric value to each data point. Most existing data valuation
methods estimate the effect of removing individual data points by evaluating
changes in model validation performance under in-distribution (ID) settings, as
opposed to out-of-distribution (OOD) scenarios where data follow different
patterns. Since ID and OOD data behave differently, data valuation methods
based on ID loss often fail to generalize to OOD settings, particularly when
the validation set contains no OOD data. Furthermore, although OOD-aware
methods exist, they involve heavy computational costs, which hinder practical
deployment. To address these challenges, we introduce \emph{Eigen-Value} (EV),
a plug-and-play data valuation framework for OOD robustness that uses only an
ID data subset, including during validation. EV provides a new spectral
approximation of domain discrepancy, which is the gap of loss between ID and
OOD using ratios of eigenvalues of ID data's covariance matrix. EV then
estimates the marginal contribution of each data point to this discrepancy via
perturbation theory, alleviating the computational burden. Subsequently, EV
plugs into ID loss-based methods by adding an EV term without any additional
training loop. We demonstrate that EV achieves improved OOD robustness and
stable value rankings across real-world datasets, while remaining
computationally lightweight. These results indicate that EV is practical for
large-scale settings with domain shift, offering an efficient path to
OOD-robust data valuation.

</details>


### [755] [PrivacyGuard: A Modular Framework for Privacy Auditing in Machine Learning](https://arxiv.org/abs/2510.23427)
*Luca Melis,Matthew Grange,Iden Kalemaj,Karan Chadha,Shengyuan Hu,Elena Kashtelyan,Will Bullock*

Main category: cs.LG

TL;DR: PrivacyGuard是一个用于机器学习模型差分隐私分析的工具，提供多种攻击和测量技术。


<details>
  <summary>Details</summary>
Motivation: 为了评估机器学习模型在敏感领域的隐私风险，需要健壮实用的隐私评估工具。

Method: PrivacyGuard实现了包括成员推断、提取和重构攻击在内的多种隐私攻击，并采用了先进的隐私测量技术，其模块化架构便于集成新的攻击和度量。

Result: 该工具能够进行现成的或高度可配置的隐私分析。

Conclusion: PrivacyGuard是一个全面的工具，用于对机器学习模型的隐私风险进行实证差分隐私分析。

Abstract: The increasing deployment of Machine Learning (ML) models in sensitive
domains motivates the need for robust, practical privacy assessment tools.
PrivacyGuard is a comprehensive tool for empirical differential privacy (DP)
analysis, designed to evaluate privacy risks in ML models through
state-of-the-art inference attacks and advanced privacy measurement techniques.
To this end, PrivacyGuard implements a diverse suite of privacy attack --
including membership inference , extraction, and reconstruction attacks --
enabling both off-the-shelf and highly configurable privacy analyses. Its
modular architecture allows for the seamless integration of new attacks, and
privacy metrics, supporting rapid adaptation to emerging research advances. We
make PrivacyGuard available at
https://github.com/facebookresearch/PrivacyGuard.

</details>


### [756] [Improving Predictions of Molecular Properties with Graph Featurisation and Heterogeneous Ensemble Models](https://arxiv.org/abs/2510.23428)
*Michael L. Parker,Samar Mahmoud,Bailey Montefiore,Mario Öeren,Himani Tandon,Charlotte Wharrick,Matthew D. Segall*

Main category: cs.LG

TL;DR: 该研究提出了一种结合图神经网络（GNN）学习的分子描述符和通用描述符的


<details>
  <summary>Details</summary>
Motivation: 结合学习到的分子描述符和通用描述符，以改进分子性质预测的模型。

Method: 提出MetaModel框架，聚合多种机器学习模型（ML）的预测，并设计了一种结合GNN特征和传统分子描述符的特征工程方案。

Result: 在所有回归数据集和9个分类数据集中的6个上，该框架的性能优于ChemProp模型；将GNN特征纳入集成模型能提升其在部分数据集上的性能。

Conclusion: 为了在广泛的问题中达到最佳性能，必须结合通用描述符、任务特定的学习特征以及多样化的机器学习模型进行预测。

Abstract: We explore a "best-of-both" approach to modelling molecular properties by
combining learned molecular descriptors from a graph neural network (GNN) with
general-purpose descriptors and a mixed ensemble of machine learning (ML)
models. We introduce a MetaModel framework to aggregate predictions from a
diverse set of leading ML models. We present a featurisation scheme for
combining task-specific GNN-derived features with conventional molecular
descriptors.
  We demonstrate that our framework outperforms the cutting-edge ChemProp model
on all regression datasets tested and 6 of 9 classification datasets. We
further show that including the GNN features derived from ChemProp boosts the
ensemble model's performance on several datasets where it otherwise would have
underperformed. We conclude that to achieve optimal performance across a wide
set of problems, it is vital to combine general-purpose descriptors with
task-specific learned features and use a diverse set of ML models to make the
predictions.

</details>


### [757] [An Information-Theoretic Analysis of Out-of-Distribution Generalization in Meta-Learning with Applications to Meta-RL](https://arxiv.org/abs/2510.23448)
*Xingtu Liu*

Main category: cs.LG

TL;DR: 该论文从信息论的角度研究了元学习中的分布外泛化问题，特别关注了测试环境与训练环境不匹配以及训练环境比测试环境更广泛这两种情况。研究者形式化了元强化学习中的泛化问题，并建立了相应的泛化界限，最后分析了一种基于梯度的元强化学习算法的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 本文旨在从信息论的角度探讨元学习中的分布外泛化问题，特别是在测试环境与训练环境不匹配以及训练环境比测试环境更广泛的两种关键场景下。

Method: 研究者形式化了元强化学习中的泛化问题，并推导了相应的泛化界限。此外，还对一种基于梯度的元强化学习算法的泛化性能进行了理论分析。

Result: 文章在理论上分析了两种分布外泛化场景，并建立了元强化学习的泛化界限。同时，对一种梯度下降的元学习算法的泛化能力进行了评估。

Conclusion: 本文通过信息论的方法，为理解和改进元学习在不同分布环境下的泛化能力提供了理论基础，并对特定算法进行了分析。

Abstract: In this work, we study out-of-distribution generalization in meta-learning
from an information-theoretic perspective. We focus on two scenarios: (i) when
the testing environment mismatches the training environment, and (ii) when the
training environment is broader than the testing environment. The first
corresponds to the standard distribution mismatch setting, while the second
reflects a broad-to-narrow training scenario. We further formalize the
generalization problem in meta-reinforcement learning and establish
corresponding generalization bounds. Finally, we analyze the generalization
performance of a gradient-based meta-reinforcement learning algorithm.

</details>


### [758] [Schrodinger Neural Network and Uncertainty Quantification: Quantum Machine](https://arxiv.org/abs/2510.23449)
*M. M. Hammad*

Main category: cs.LG

TL;DR: SNN是一种受量子力学启发的概率密度估计和不确定性量化方法，通过学习概率幅的系数来表示条件概率密度。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理多模态分布和保证概率分布的归一化方面存在不足，需要一种更 principled 的方法。SNN受量子力学启发，旨在解决这些问题。

Method: SNN将输入映射到输出域上的归一化波函数，并通过玻恩规则计算预测概率。它学习谱展开（如切比雪夫多项式）的复系数，其模的平方即为条件密度 $p(y|x)=\left| \psi _x(y)\right| {}^2$，并具有解析归一化。研究内容包括：(i) 通过精确最大似然和单位球系数参数化进行训练；(ii) 物理启发的二次正则化器（动能和势能）；(iii) 可扩展的低秩和可分离扩展；(iv) 基于算子的扩展；(v) 评估多模态预测的框架。

Result: SNN具有正性和精确归一性、原生多模态以及闭式计算（或可高效计算）的矩和校准诊断等优点。

Conclusion: SNN提供了一个连贯且易于处理的框架，将概率预测从点估计提升到基于物理幅度的分布。

Abstract: We introduce the Schrodinger Neural Network (SNN), a principled architecture
for conditional density estimation and uncertainty quantification inspired by
quantum mechanics. The SNN maps each input to a normalized wave function on the
output domain and computes predictive probabilities via the Born rule. The SNN
departs from standard parametric likelihood heads by learning complex
coefficients of a spectral expansion (e . g ., Chebyshev polynomials) whose
squared modulus yields the conditional density $p(y|x)=\left| \psi _x(y)\right|
{}^2$ with analytic normalization. This representation confers three practical
advantages: positivity and exact normalization by construction, native
multimodality through interference among basis modes without explicit mixture
bookkeeping, and yields closed-form (or efficiently computable)
functionals$-$such as moments and several calibration diagnostics$-$as
quadratic forms in coefficient space. We develop the statistical and
computational foundations of the SNN, including (i) training by exact
maximum-likelihood with unit-sphere coefficient parameterization, (ii)
physics-inspired quadratic regularizers (kinetic and potential energies)
motivated by uncertainty relations between localization and spectral
complexity, (iii) scalable low-rank and separable extensions for multivariate
outputs, (iv) operator-based extensions that represent observables,
constraints, and weak labels as self-adjoint matrices acting on the amplitude
space, and (v) a comprehensive framework for evaluating multimodal predictions.
The SNN provides a coherent, tractable framework to elevate probabilistic
prediction from point estimates to physically inspired amplitude-based
distributions.

</details>


### [759] [SGFusion: Stochastic Geographic Gradient Fusion in Federated Learning](https://arxiv.org/abs/2510.23455)
*Khoa Nguyen,Khang Tran,NhatHai Phan,Cristian Borcea,Rouming Jin,Issa Khalil*

Main category: cs.LG

TL;DR: SGFusion是一种新的联邦学习算法，它利用移动用户的地理信息，为每个地理区域训练一个独立的模型，并通过分层随机图和马尔可夫链蒙特卡洛采样来融合区域间的梯度，提高了模型性能且计算成本可控。


<details>
  <summary>Details</summary>
Motivation: 利用联邦学习（FL）中的地理信息来提高模型性能。

Method: SGFusion算法将移动设备收集的数据映射到地理区域，为每个区域训练一个FL模型。该算法使用分层随机图（HRG）来模拟区域间的数据相关性，并通过马尔可夫链蒙特卡洛（MCMC）采样进行优化。在每个训练步骤中，每个区域会融合其本地梯度和从HRG采样的其他区域的梯度。利用自注意力权重进行梯度融合，使得“更相似”的区域具有“更高概率”共享梯度，并具有“更大的注意力权重”。

Result: SGFusion在不增加额外计算成本的情况下，显著提高了模型效用。使用跨越6个国家的心率预测数据集进行的广泛理论和实证结果表明，SGFusion训练的模型收敛且具有上界误差，并且在所有国家/地区均显著优于现有方法，同时没有显著影响系统可扩展性。

Conclusion: SGFusion通过利用地理信息和概率性梯度融合，能够有效地提高联邦学习模型的效用，同时保持可控的计算成本和良好的系统可扩展性。

Abstract: This paper proposes Stochastic Geographic Gradient Fusion (SGFusion), a novel
training algorithm to leverage the geographic information of mobile users in
Federated Learning (FL). SGFusion maps the data collected by mobile devices
onto geographical zones and trains one FL model per zone, which adapts well to
the data and behaviors of users in that zone. SGFusion models the local
data-based correlation among geographical zones as a hierarchical random graph
(HRG) optimized by Markov Chain Monte Carlo sampling. At each training step,
every zone fuses its local gradient with gradients derived from a small set of
other zones sampled from the HRG. This approach enables knowledge fusion and
sharing among geographical zones in a probabilistic and stochastic gradient
fusion process with self-attention weights, such that "more similar" zones have
"higher probabilities" of sharing gradients with "larger attention weights."
SGFusion remarkably improves model utility without introducing undue
computational cost. Extensive theoretical and empirical results using a
heart-rate prediction dataset collected across 6 countries show that models
trained with SGFusion converge with upper-bounded expected errors and
significantly improve utility in all countries compared to existing approaches
without notable cost in system scalability.

</details>


### [760] [Differential Privacy as a Perk: Federated Learning over Multiple-Access Fading Channels with a Multi-Antenna Base Station](https://arxiv.org/abs/2510.23463)
*Hao Liang,Haifeng Wen,Kaishun Wu,Hong Xing*

Main category: cs.LG

TL;DR: 在联邦学习（FL）的边缘实例（AirFL）中，信道噪声既会因全局聚合的噪声而损害训练，又可以作为差分隐私（DP）的随机性来源。本研究在多址衰落信道和多天线基站下研究了具有用户级DP要求的AirFL。与以往认为必须注入人工噪声（AN）的观点相反，我们证明了即使不使用AN，DP也可以作为一种“附加福利”获得。我们推导了在模型参数的通用有界域假设下收敛的DP新界限，以及具有通用光滑非凸损失函数的收敛界限。随后，我们通过优化接收波束形成和功率分配来表征最佳收敛-隐私权衡，并揭示了在不影响训练的情况下实现DP的明确条件。理论发现得到了数值结果的验证。


<details>
  <summary>Details</summary>
Motivation: 现有研究在AirFL中，对信道噪声在差分隐私（DP）和训练过程中的作用认识不足，尤其是在处理复杂信道和损失函数时，对DP的实现方式存在局限性，例如需要注入人工噪声（AN）。

Method: 1.推导在模型参数有界域假设下，能够收敛的DP新界限。2.推导具有通用光滑非凸损失函数的收敛界限。3.通过优化接收波束形成和功率分配，表征收敛-隐私权衡。

Result: 证明了即使不使用AN，DP也可以作为AirFL的附加福利获得。推导了DP和收敛的界限，并优化了相关参数以实现最佳收敛-隐私权衡。找到了在不影响训练的情况下实现DP的明确条件。

Conclusion: 在AirFL中，信道噪声可以被有效利用以实现DP，而无需额外注入AN。通过优化的波束形成和功率分配，可以在保证DP的同时实现有效的模型训练。

Abstract: Federated Learning (FL) is a distributed learning paradigm that preserves
privacy by eliminating the need to exchange raw data during training. In its
prototypical edge instantiation with underlying wireless transmissions enabled
by analog over-the-air computing (AirComp), referred to as \emph{over-the-air
FL (AirFL)}, the inherent channel noise plays a unique role of \emph{frenemy}
in the sense that it degrades training due to noisy global aggregation while
providing a natural source of randomness for privacy-preserving mechanisms,
formally quantified by \emph{differential privacy (DP)}. It remains,
nevertheless, challenging to effectively harness such channel impairments, as
prior arts, under assumptions of either simple channel models or restricted
types of loss functions, mostly considering (local) DP enhancement with a
single-round or non-convergent bound on privacy loss. In this paper, we study
AirFL over multiple-access fading channels with a multi-antenna base station
(BS) subject to user-level DP requirements. Despite a recent study, which
claimed in similar settings that artificial noise (AN) must be injected to
ensure DP in general, we demonstrate, on the contrary, that DP can be gained as
a \emph{perk} even \emph{without} employing any AN. Specifically, we derive a
novel bound on DP that converges under general bounded-domain assumptions on
model parameters, along with a convergence bound with general smooth and
non-convex loss functions. Next, we optimize over receive beamforming and power
allocations to characterize the optimal convergence-privacy trade-offs, which
also reveal explicit conditions in which DP is achievable without compromising
training. Finally, our theoretical findings are validated by extensive
numerical results.

</details>


### [761] [Adaptive Dual Prompting: Hierarchical Debiasing for Fairness-aware Graph Neural Networks](https://arxiv.org/abs/2510.23469)
*Yuhan Yang,Xingbo Fu,Jundong Li*

Main category: cs.LG

TL;DR: 图神经网络（GNNs）的无监督预训练是图学习中的一个热门范式，但预训练与下游任务之间常存在目标差异。图提示（graph prompting）通过冻结预训练的GNN模型并加入可学习的提示来适应下游任务。现有方法主要关注模型效用，忽视了公平性问题，因为预训练的GNN可能因图数据本身的偏差而产生有偏的节点表示。为此，我们提出了自适应双提示（ADPrompt）框架，通过设计自适应特征修正模块（抑制敏感信息）和自适应消息校准模块（动态调整信息流），以增强GNN适应下游任务时的公平性。实验表明，ADPrompt在节点分类任务上优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有的图提示方法主要关注提升模型在下游任务中的效用，但忽视了公平性问题。由于预训练的GNN模型会产生跨越不同人口统计学子群体的区分性节点表示，而下游图数据本身就包含节点属性和图结构上的偏差，因此需要解决这一问题。

Method: 提出自适应双提示（ADPrompt）框架，包含两个模块：1. 自适应特征修正模块：学习定制化的属性提示，在输入层抑制敏感信息，从源头上减少偏差。2. 自适应消息校准模块：在每一层生成结构提示，调整来自邻居节点的消息，实现动态、软性的信息流校准。最后，ADPrompt联合优化这两个提示模块，在适应预训练GNN的同时增强公平性。

Result: 在四个数据集和四种预训练策略上进行的广泛实验表明，ADPrompt在节点分类任务上的性能优于七种基线方法。

Conclusion: ADPrompt框架通过自适应特征修正和自适应消息校准，能够有效适应预训练的GNN模型，同时增强其在下游任务中的公平性，并在节点分类任务上取得了优于基线方法的性能。

Abstract: In recent years, pre-training Graph Neural Networks (GNNs) through
self-supervised learning on unlabeled graph data has emerged as a widely
adopted paradigm in graph learning. Although the paradigm is effective for
pre-training powerful GNN models, the objective gap often exists between
pre-training and downstream tasks. To bridge this gap, graph prompting adapts
pre-trained GNN models to specific downstream tasks with extra learnable
prompts while keeping the pre-trained GNN models frozen. As recent graph
prompting methods largely focus on enhancing model utility on downstream tasks,
they often overlook fairness concerns when designing prompts for adaptation. In
fact, pre-trained GNN models will produce discriminative node representations
across demographic subgroups, as downstream graph data inherently contains
biases in both node attributes and graph structures. To address this issue, we
propose an Adaptive Dual Prompting (ADPrompt) framework that enhances fairness
for adapting pre-trained GNN models to downstream tasks. To mitigate attribute
bias, we design an Adaptive Feature Rectification module that learns customized
attribute prompts to suppress sensitive information at the input layer,
reducing bias at the source. Afterward, we propose an Adaptive Message
Calibration module that generates structure prompts at each layer, which adjust
the message from neighboring nodes to enable dynamic and soft calibration of
the information flow. Finally, ADPrompt jointly optimizes the two prompting
modules to adapt the pre-trained GNN while enhancing fairness. We conduct
extensive experiments on four datasets with four pre-training strategies to
evaluate the performance of ADPrompt. The results demonstrate that our proposed
ADPrompt outperforms seven baseline methods on node classification tasks.

</details>


### [762] [T-REGS: Minimum Spanning Tree Regularization for Self-Supervised Learning](https://arxiv.org/abs/2510.23484)
*Julie Mordacq,David Loiseaux,Vicky Kalogeiton,Steve Oudot*

Main category: cs.LG

TL;DR: T-REGS是一种基于最小生成树长度的自监督学习正则化框架，可同时缓解维度坍塌并促进分布均匀性。


<details>
  <summary>Details</summary>
Motivation: 自监督学习（SSL）在没有标签数据的情况下学习表示变得越来越重要。为了使SSL有效，有两个关键属性：避免维度坍塌和增强诱导分布的均匀性。

Method: 提出了一种名为T-REGS的简单正则化框架，该框架基于学习表示上的最小生成树（MST）的长度。

Result: 理论分析表明，T-REGS可以同时减轻维度坍塌并促进任意紧致黎曼流形上的分布均匀性。在合成数据和经典SSL基准上的实验证明了该方法在提高表示质量方面的有效性。

Conclusion: T-REGS是一种有效的SSL正则化框架，可以同时解决维度坍塌和分布均匀性问题。

Abstract: Self-supervised learning (SSL) has emerged as a powerful paradigm for
learning representations without labeled data, often by enforcing invariance to
input transformations such as rotations or blurring. Recent studies have
highlighted two pivotal properties for effective representations: (i) avoiding
dimensional collapse-where the learned features occupy only a low-dimensional
subspace, and (ii) enhancing uniformity of the induced distribution. In this
work, we introduce T-REGS, a simple regularization framework for SSL based on
the length of the Minimum Spanning Tree (MST) over the learned representation.
We provide theoretical analysis demonstrating that T-REGS simultaneously
mitigates dimensional collapse and promotes distribution uniformity on
arbitrary compact Riemannian manifolds. Several experiments on synthetic data
and on classical SSL benchmarks validate the effectiveness of our approach at
enhancing representation quality.

</details>


### [763] [Learning to Reason Efficiently with Discounted Reinforcement Learning](https://arxiv.org/abs/2510.23486)
*Alex Ayoub,Kavosh Asadi,Dale Schuurmans,Csaba Szepesvári,Karim Bouyarmane*

Main category: cs.LG

TL;DR: 通过引入代币成本来缩短推理链并保持准确性


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRM）通常消耗过多的代币，导致计算成本和延迟增加。

Method: 通过对代币进行惩罚，并分析受限策略类别中的 Blackwell 最优性，鼓励简洁而准确的推理。

Result: 实验证实了该方法可以缩短推理链，同时保持准确性。

Conclusion: 本研究提出了一种通过引入代币成本来优化LRM推理过程的方法，在缩短推理链的同时保持了模型的准确性。

Abstract: Large reasoning models (LRMs) often consume excessive tokens, inflating
computational cost and latency. We challenge the assumption that longer
responses improve accuracy. By penalizing reasoning tokens using a discounted
reinforcement learning setup (interpretable as a small token cost) and
analyzing Blackwell optimality in restricted policy classes, we encourage
concise yet accurate reasoning. Experiments confirm our theoretical results
that this approach shortens chains of thought while preserving accuracy.

</details>


### [764] [Towards Deep Physics-Informed Kolmogorov-Arnold Networks](https://arxiv.org/abs/2510.23501)
*Spyros Rigas,Fotios Anagnostopoulos,Michalis Papachristou,Georgios Alexandridis*

Main category: cs.LG

TL;DR: KANs在物理信息机器学习（PIML）中表现出色，但深度训练时存在不稳定性。本文提出了新的初始化方案和RGA KANs架构，解决了深度训练问题，并在多个PDE基准测试中取得了显著优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的Chebyshev基物理信息KANs（cPIKANs）在深度训练时存在不稳定性，限制了其在PDE问题上的应用。

Method: 提出了一种基于Glorot的、与基函数无关的初始化方案，并引入了残差门控自适应KANs（RGA KANs）架构。

Result: 新的初始化方案和RGA KANs在训练稳定性和准确性方面均有显著提升，并在七个标准的PDE基准测试中，相比参数匹配的cPIKANs和PirateNets，取得了数个数量级的性能提升，特别是在cPIKANs发散的情况下保持稳定。

Conclusion: RGA KANs有效地解决了深度cPIKANs的训练不稳定性问题，在多个PDE问题上表现出优越的性能和稳定性。

Abstract: Since their introduction, Kolmogorov-Arnold Networks (KANs) have been
successfully applied across several domains, with physics-informed machine
learning (PIML) emerging as one of the areas where they have thrived. In the
PIML setting, Chebyshev-based physics-informed KANs (cPIKANs) have become the
standard due to their computational efficiency. However, like their multilayer
perceptron-based counterparts, cPIKANs face significant challenges when scaled
to depth, leading to training instabilities that limit their applicability to
several PDE problems. To address this, we propose a basis-agnostic, Glorot-like
initialization scheme that preserves activation variance and yields substantial
improvements in stability and accuracy over the default initialization of
cPIKANs. Inspired by the PirateNet architecture, we further introduce
Residual-Gated Adaptive KANs (RGA KANs), designed to mitigate divergence in
deep cPIKANs where initialization alone is not sufficient. Through empirical
tests and information bottleneck analysis, we show that RGA KANs successfully
traverse all training phases, unlike baseline cPIKANs, which stagnate in the
diffusion phase in specific PDE settings. Evaluations on seven standard forward
PDE benchmarks under a fixed training pipeline with adaptive components
demonstrate that RGA KANs consistently outperform parameter-matched cPIKANs and
PirateNets - often by several orders of magnitude - while remaining stable in
settings where the others diverge.

</details>


### [765] [A Deep Latent Factor Graph Clustering with Fairness-Utility Trade-off Perspective](https://arxiv.org/abs/2510.23507)
*Siamak Ghodsi,Amjad Seyedi,Tai Le Quy,Fariba Karimi,Eirini Ntoutsi*

Main category: cs.LG

TL;DR: DFNMF是一种端到端的深度非负三因子分解方法，用于图聚类，通过软统计均等正则化器直接优化聚类分配，能够实现公平性和效用之间的平衡，并且具有可解释性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有图聚类方法存在硬性约束或多阶段流水线限制了权衡控制、可解释性和可扩展性。

Method: 提出DFNMF，一种端到端的深度非负三因子分解方法，直接优化聚类分配，并加入软统计均等正则化器，通过单个参数λ调整公平性-效用平衡，并使用稀疏友好的交替更新进行优化。

Result: 在合成和真实网络上，DFNMF在相当的模块度下实现了更高的组别平衡，在帕累托前沿通常优于最先进的基线方法。

Conclusion: DFNMF是一种有效的图聚类方法，能够平衡公平性和效用，并具有可解释性和可扩展性。

Abstract: Fair graph clustering seeks partitions that respect network structure while
maintaining proportional representation across sensitive groups, with
applications spanning community detection, team formation, resource allocation,
and social network analysis. Many existing approaches enforce rigid constraints
or rely on multi-stage pipelines (e.g., spectral embedding followed by
$k$-means), limiting trade-off control, interpretability, and scalability. We
introduce \emph{DFNMF}, an end-to-end deep nonnegative tri-factorization
tailored to graphs that directly optimizes cluster assignments with a soft
statistical-parity regularizer. A single parameter $\lambda$ tunes the
fairness--utility balance, while nonnegativity yields parts-based factors and
transparent soft memberships. The optimization uses sparse-friendly alternating
updates and scales near-linearly with the number of edges. Across synthetic and
real networks, DFNMF achieves substantially higher group balance at comparable
modularity, often dominating state-of-the-art baselines on the Pareto front.
The code is available at https://github.com/SiamakGhodsi/DFNMF.git.

</details>


### [766] [TAMI: Taming Heterogeneity in Temporal Interactions for Temporal Graph Link Prediction](https://arxiv.org/abs/2510.23577)
*Zhongyi Yu,Jianqiu Wu,Zhenghao Wu,Shuhan Zhong,Weifeng Su,Chul-Ho Lee,Weipeng Zhuo*

Main category: cs.LG

TL;DR: TAMI框架通过引入对数时间编码函数（LTE）和链接历史聚合（LHA）来解决时间图链接预测中的异质性问题，从而改进了时间信息编码和历史交互记忆，在多个数据集上均提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有的时间图链接预测方法未能有效处理交互事件的异质性（如少数节点对产生大部分交互，交互间隔不一），导致时间信息编码无效，并遗忘过去交互，尤其是在预测交互稀疏的节点对时性能不佳。

Method: 提出了一种名为TAMI的新框架，包含两个核心组件：对数时间编码函数（LTE），通过转换交互间隔来更好地编码时间信息；以及链接历史聚合（LHA），防止目标节点对的历史交互被遗忘。该框架可以无缝集成现有的时间图神经网络。

Result: 在13个经典数据集和3个最新的TGB数据集上进行实验，结果表明TAMI在转导和归纳设置下均能持续提升链接预测性能。

Conclusion: TAMI框架通过有效处理时间图链接预测中的异质性问题，显著提高了现有模型的性能。

Abstract: Temporal graph link prediction aims to predict future interactions between
nodes in a graph based on their historical interactions, which are encoded in
node embeddings. We observe that heterogeneity naturally appears in temporal
interactions, e.g., a few node pairs can make most interaction events, and
interaction events happen at varying intervals. This leads to the problems of
ineffective temporal information encoding and forgetting of past interactions
for a pair of nodes that interact intermittently for their link prediction.
Existing methods, however, do not consider such heterogeneity in their learning
process, and thus their learned temporal node embeddings are less effective,
especially when predicting the links for infrequently interacting node pairs.
To cope with the heterogeneity, we propose a novel framework called TAMI, which
contains two effective components, namely log time encoding function (LTE) and
link history aggregation (LHA). LTE better encodes the temporal information
through transforming interaction intervals into more balanced ones, and LHA
prevents the historical interactions for each target node pair from being
forgotten. State-of-the-art temporal graph neural networks can be seamlessly
and readily integrated into TAMI to improve their effectiveness. Experiment
results on 13 classic datasets and three newest temporal graph benchmark (TGB)
datasets show that TAMI consistently improves the link prediction performance
of the underlying models in both transductive and inductive settings. Our code
is available at https://github.com/Alleinx/TAMI_temporal_graph.

</details>


### [767] [Lightweight Robust Direct Preference Optimization](https://arxiv.org/abs/2510.23590)
*Cheol Woo Kim,Shresth Verma,Mauricio Tec,Milind Tambe*

Main category: cs.LG

TL;DR: DPO-PRO是一种基于DPO的轻量级分布鲁棒优化算法，通过关注偏好分布的不确定性来提高模型对噪声偏好的鲁棒性，且计算成本低。


<details>
  <summary>Details</summary>
Motivation: DPO方法在微调大型语言模型（LLM）方面很受欢迎，但容易受到数据噪声和过拟合的影响。现有的基于分布鲁棒优化（DRO）的方法虽然能处理噪声和分布偏移，但存在过度保守和计算成本高的问题。

Method: 提出DPO-PRO（DPO with Preference Robustness）算法，采用轻量级DRO方法来解决偏好分布中的不确定性问题。该方法仅关注偏好不确定性，避免了不必要的保守性，且计算开销极小。

Result: 实验结果表明，与现有的DPO变体相比，DPO-PRO在标准对齐基准和实际公共卫生任务中，对噪声偏好信号的鲁棒性得到了持续的提升。

Conclusion: DPO-PRO通过关注偏好分布的不确定性，在保持DPO稳定性和简洁性的同时，提高了模型的鲁棒性，解决了现有DRO方法过度保守和计算成本高的问题。

Abstract: Direct Preference Optimization (DPO) has become a popular method for
fine-tuning large language models (LLMs) due to its stability and simplicity.
However, it is also known to be sensitive to noise in the data and prone to
overfitting. Recent works have proposed using distributionally robust
optimization (DRO) to address potential noise and distributional shift in the
data. However, these methods often suffer from excessive conservatism and high
computational cost. We propose DPO-PRO (DPO with Preference Robustness), a
robust fine-tuning algorithm based on DPO which accounts for uncertainty in the
preference distribution through a lightweight DRO formulation. Unlike prior
DRO-based variants, DPO-PRO focuses solely on uncertainty in preferences,
avoiding unnecessary conservatism and incurring negligible computational
overhead. We further show that DPO-PRO is equivalent to a regularized DPO
objective that penalizes model overconfidence under weak preference signals. We
evaluate DPO-PRO on standard alignment benchmarks and a real-world public
health task. Experimental results show that our method consistently improves
robustness to noisy preference signals compared to existing DPO variants.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [768] [Impurity-induced topological decomposition](https://arxiv.org/abs/2510.21928)
*Tianxing Shi,Chuhang Zhang,Liang Jin,Linhu Li*

Main category: cond-mat.mes-hall

TL;DR: 局部杂质可用于分步控制和分解拓扑相，并生成拓扑边缘态。


<details>
  <summary>Details</summary>
Motivation: 控制量子材料中的拓扑相，以实现稳健传输和可编程边缘态等应用。

Method: 在具有谱环绕拓扑的非厄米格点中，每个局部驻点杂质可将环绕数减少一，从而导致稳态响应中的量子化平台出现阶梯式分解。基于此原理，研究者们开发了一种方案，通过杂质控制在由非厄米系统衍生出的厄米拓扑系统中依次诱导拓扑边缘态。

Result: 局部杂质可作为控制旋钮，分离地、按顺序地控制全局拓扑属性。将一个非厄米系统加倍，可以得到一个厄米系统，并在此类系统中实现杂质诱导的拓扑边缘态。

Conclusion: 局部扰动可用于调谐全局拓扑属性，为杂质控制的拓扑相提供了一个通用框架，并为可重构拓扑现象的未来探索奠定了基础。

Abstract: Controlling topological phases is a central goal in quantum materials and
related fields, enabling applications such as robust transport and programmable
edge states. Here we uncover a mechanism in which local on-site impurities act
as knobs to decompose global topological properties in discrete steps. In
non-Hermitian lattices with spectral winding topology, we show that each
impurity sequentially reduces the winding number by one, which is directly
manifested as a stepwise decomposition of quantized plateaus in the
steady-state response. Based on this principle, we further develop a scheme
that sequentially induces topological edge states under impurity control, in a
class of Hermitian topological systems constructed by doubling the
non-Hermitian ones. Our findings reveal a general scheme to tune global
topological properties with local perturbations, establishing a universal
framework for impurity-controlled topological phases and offering a foundation
for future exploration of reconfigurable topological phenomena across diverse
physical platforms.

</details>


### [769] [Nonlinear magnetization dynamics as a route to nonreciprocal phases, spin superfluidity, and analogue gravity](https://arxiv.org/abs/2510.21963)
*Vincent Flynn,Benedetta Flebus*

Main category: cond-mat.mes-hall

TL;DR: 平台可以独立地调节非线性和非厄米性，这为许多体系统中的远离平衡的普适性提供了定量途径。本文利用铁磁多层结构实现了这一范例：通过平衡直流驱动和吉尔伯特阻尼，稳定了一个自发破坏时空平移对称性的手征自旋超流极限环。由此产生的超流具有内在的不可逆性：长波动的不同手征获得不对称色散并具有方向选择性传播，实现了自旋超流二极管。这种不对称性是流动引起的，它反映了破缺的伽利略不变性，并且不需要结构不对称或精细调节的增益-损耗平衡。在协动超流系中线性化的动力学本质上是伪厄米式的，并且在长波长区域可以映射到弯曲时空上的(1+1)维波动方程。驱动的空间调制能够产生声学视界，从而参数化地压缩磁振子并产生类似霍金的粒子-空穴发射。我们的结果确立了一条从非线性耗散驱动的磁化动力学到不可逆输运、非平衡相变和模拟引力运动学的桌面路线。


<details>
  <summary>Details</summary>
Motivation: 本文旨在利用具有独立可调的非线性和非厄米性的平台，为远离平衡的多体系统提供一种定量研究普适性的途径。

Method: 本文提出了一种利用铁磁多层结构实现上述范例的方法。通过平衡直流驱动和吉尔伯特阻尼，稳定了一个手征自旋超流极限环，该极限环自发地破坏了时空平移对称性。利用这个模型，研究了长波磁振子的不对称色散和方向选择性传播，以及由此产生的自旋超流二极管效应。此外，还研究了驱动的空间调制如何产生声学视界，进而引发类似霍金的粒子-空穴发射。

Result: 研究表明，所提出的铁磁多层结构能够实现自旋超流二极管，表现出内在的不可逆性。长波磁振子具有不对称的色散关系，并能进行方向选择性传播。驱动的空间调制能够产生声学视界，并引发类似霍金的粒子-空穴发射。

Conclusion: 本文的结果表明，通过非线性耗散驱动的磁化动力学，可以实现不可逆输运、非平衡相变和模拟引力运动学，为相关领域的研究提供了一种新的实验途径。

Abstract: The identification of platforms with independently tunable nonlinearity and
non-Hermiticity promises a quantitative route to far-from-equilibrium
universality across many-body systems. Here we show that a conventional
ferromagnetic multilayer realizes this paradigm: balancing a dc drive against
Gilbert damping stabilizes a chiral spin-superfluid limit cycle that
spontaneously breaks spacetime-translation symmetry. The resulting superflow is
intrinsically nonreciprocal: long-wavelength magnons of opposite chirality
acquire asymmetric dispersions and propagate direction-selectively, realizing a
spin-superfluid diode. This asymmetry is flow-borne - it reflects broken
Galilean invariance and requires neither structural asymmetry nor finely tuned
gain-loss balance. Linearized dynamics in the comoving superfluid frame are
intrinsically pseudo-Hermitian and, in the long-wavelength sector, can be
mapped to a (1+1)D wave equation on curved spacetime. Spatial modulation of the
drive enables the generation of sonic horizons that parametrically squeeze
magnons and produce Hawking-like particle-hole emission. Our results establish
a tabletop route from nonlinear dissipative-driven magnetization dynamics to
nonreciprocal transport, nonequilibrium phase transitions, and analogue-gravity
kinematics.

</details>


### [770] [Exact time-evolving resonant states for open double quantum-dot systems with spin degrees of freedom](https://arxiv.org/abs/2510.22195)
*Akinori Nishino,Naomichi Hatano*

Main category: cond-mat.mes-hall

TL;DR: 本文研究了开放双量子点系统中随时间演化的共振态，考虑了自旋自由度和库仑相互作用。通过对两量子点子空间中的非厄米有效哈密顿量进行对角化，识别出四种类型的二体共振态。对于初始的局域化两个自旋相反的电子态，我们求解了含时薛定谔方程，得到了随时间演化的二体共振态。通过利用精确解，分析了量子点上局域化两个电子的生存和跃迁概率。


<details>
  <summary>Details</summary>
Motivation: 研究开放双量子点系统中考虑自旋和库仑相互作用下，随时间演化的共振态。

Method: 精确推导了作用在两量子点子空间上的非厄米有效哈密顿量，并通过对角化该哈密顿量来识别共振态。然后，求解含时薛定谔方程得到随时间演化的共振态，并分析了局域化电子的生存和跃迁概率。

Result: 识别出四种类型的二体共振态，并得到了随时间演化的二体共振态。分析表明，这些态是可归一化的，因为它们的波函数仅在随时间扩展的有限空间区间内指数增长。

Conclusion: 通过精确求解，我们分析了量子点上局域化两个电子的生存和跃迁概率，并得到了随时间演化的二体共振态。

Abstract: We study time-evolving resonant states in an open double quantum-dot system,
taking into account spin degrees of freedom as well as both on-dot and interdot
Coulomb interactions. We exactly derived a non-Hermite effective Hamiltonian
acting on the subspace of two quantum dots, where the non-Hermiticity arises
from an effect of infinite external leads connected to the quantum dots. By
diagonalizing the effective Hamiltonian, we identify four types of two-body
resonant states. For the initial states of localized two electrons with
opposite spins on the quantum dots, we exactly solve the time-dependent
Schroedinger equation and obtain time-evolving two-body resonant states. The
time-evolving resonant states are normalizable since their wave function grows
exponentially only inside a finite space interval that expands in time with
electron velocity. By using the exact solution, we analyze the survival and
transition probabilities of localized two electrons on the quantum dots.

</details>


### [771] [Electric Field-Induced Kerr Rotation on Metallic Surfaces](https://arxiv.org/abs/2510.22486)
*Farzad Mahfouzi,Mark D. Stiles,Paul M. Haney*

Main category: cond-mat.mes-hall

TL;DR: 该研究利用密度泛函理论和光学模型，发现金属薄膜中电场诱导的Kerr旋转主要由非平衡轨道矩积累（轨道Edelstein效应）和表面Pockels效应引起，其中表面Pockels效应是先前研究忽略的。


<details>
  <summary>Details</summary>
Motivation: 研究先前工作中对金属薄膜中电场诱导Kerr旋转的理解，并引入一个被忽略的表面Pockels效应，以更全面地解释该现象。

Method: 结合密度泛函理论计算和光学建模，分析电场对金属薄膜（特别是Pt）的轨道矩积累和表面Pockels效应的影响，并计算这些效应如何影响s偏振和p偏振光的Kerr旋转。

Result: 计算表明，轨道Edelstein效应和表面Pockels效应对Kerr旋转的贡献相当。轨道Edelstein效应对s和p偏振光的Kerr旋转影响相似，而表面Pockels效应对s和p偏振光的Kerr旋转影响相反。

Conclusion: 电场诱导的Kerr旋转是由于表面几纳米范围内光学电导率的改变，该改变源于表面和直流电场的双重镜像对称性破缺。轨道Edelstein效应和表面Pockels效应对此现象均有贡献，且表面Pockels效应是先前研究中未被充分认识的部分。

Abstract: We use a combination of density functional theory calculations and optical
modeling to establish that the electric field-induced Kerr rotation in metallic
thin films has contributions from both non-equilibrium orbital moment
accumulation (arising from the orbital Edelstein effect) and a heretofore
overlooked surface Pockels effect. The Kerr rotation associated with orbital
accumulation has been studied in previous works and is largely due to the dc
electric field-induced change of the electron distribution function. In
contrast, the surface Pockels effect is largely due to the dc field-induced
change to the wave functions. Both of these contributions arise from the dual
mirror symmetry breaking from the surface and from the dc applied field. Our
calculations show that the resulting Kerr rotation is due to the dc electric
field modification of the optical conductivity within a couple of nanometers
from the surface, consistent with the dependence on the local mirror symmetry
breaking at the surface. For thin films of Pt, our calculations show that the
relative contributions of the orbital Edelstein and surface Pockels effects are
comparable, and that they have different effects on Kerr rotation of $s$ and
$p$ polarized light, $\theta_K^s$ and $\theta_K^p$. The orbital Edelstein
effect yields similar values of $\theta_K^s$ and $\theta_K^p$, while the
surface Pockels effect leads to opposing values of $\theta_K^s$ and
$\theta_K^p$.

</details>


### [772] [Suppression of quantized heat flow by the dielectric response of a compressible strip at the quantum Hall edge](https://arxiv.org/abs/2510.22459)
*Eugene V. Sukhorukov,Adrien Tomà*

Main category: cond-mat.mes-hall

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We develop a unified perturbative framework for energy transport along a
chiral quantum Hall (QH) edge coupled to a disordered, compressible strip.
Treating the strip as a generic linear response environment characterized by
its retarded susceptibility $\chi_q^R(k,\omega)$, we derive leading-order
interaction corrections to both the edge heat flux and the plasmon spectrum.
Two complementary regimes are analyzed: (i) a gapped, local dielectric response
with finite-range coupling, which yields a universal negative $T^4$ correction
to the quantized heat flux and a corresponding convex cubic term in the plasmon
dispersion; and (ii) a hydrodynamic (diffusive) response with relaxation,
producing a crossover from $T^4$ to $T^{3/2}$ scaling and a change of sign in
the correction. The resulting backaction reduces the plasmon group velocity and
can suppress the apparent thermal conductance by an amount consistent with
experiment. Importantly, the total heat flux remains quantized: the apparent
deficit in the plasmon contribution corresponds to an induced energy flow
within the compressible strip, representing a form of heat drag between chiral
and nonchiral modes. The framework thus provides a microscopic and
quantitatively plausible explanation of the ``missing heat flux'' anomaly
observed at QH edges and links its transport signature to the nonlinearity of
the plasmon spectrum.

</details>


### [773] [Excitation of Confined Bulk Plasmons in metallic nanoparticles by penetrating electron beams within a non-local analytical approach](https://arxiv.org/abs/2510.22606)
*Mattin Urbieta,Edu Ogando,Alberto Rivacoba,Javier Aizpurua,Nerea Zabala*

Main category: cond-mat.mes-hall

TL;DR: 该研究使用线性流体动力学模型（HDM）研究了电子束与纳米颗粒（NPs）的相互作用，并提出了包含非局域效应的电子能量损失（EEL）概率的解析表达式，重点关注了无法在局域介电框架内解决的纵向等离激元激发（CBPs）。


<details>
  <summary>Details</summary>
Motivation: 研究电子束与亚纳米金属球形纳米颗粒（NPs）的相互作用，特别是电子能量损失（EEL）以及无法在局域介电框架内解决的纵向等离激元激发（CBPs）。

Method: 使用线性流体动力学模型（HDM）来理论研究电子束与亚纳米金属球形纳米颗粒（NPs）的相互作用，并推导出包含非局域效应的电子能量损失（EEL）概率的解析表达式。

Result: 研究结果显示，CBPs的激发对入射电子束的冲击参数、动能以及NP的大小高度敏感。与局域方法不同，该模型能够捕捉到随着NP尺寸减小和冲击参数增加时，体等离激元包络（BPE）的蓝移现象。此外，研究还预测了一个阈值冲击参数，这是有效激活一组CBPs所需的最小电子路径。通过对CBPs的多极描述，研究识别了控制其被电子束激发的对称规则，并将BPE随冲击参数增加而蓝移的现象与更高阶CBPs的激发相关联。CBPs的色散随着NP尺寸的减小，进一步增加了BPE的冲击参数依赖性蓝移，并解释了阈值冲击参数的减小。

Conclusion: 该研究提出的模型能够捕捉到局域方法无法描述的现象，如BPE的蓝移及其与NP尺寸、冲击参数和CBPs阶数的关系，并为理解电子束与纳米材料的相互作用提供了新的见解。

Abstract: Using a linear hydrodynamic model (HDM) we investigate theoretically the
interaction between penetrating electron beams and sub-5 nm metallic spherical
nanoparticles (NPs), and provide an analytical expression of the electron
energy loss (EEL) probability including non-local effects in the response of
the confined electron gas. We focus on the characterization of the longitudinal
plasmon excitations, or confined bulk plasmons (CBPs), which cannot be
addressed within local dielectric frameworks, and show that their excitation is
highly sensitive to the impact parameter and kinetic energy of the incident
electron beam, as well as to the NP's size. In contrast to the local approach,
our decription captures a blueshift of the bulk plasmon envelope (BPE) with
decreasing NP size and a blueshift with increasing impact parameter. Moreover,
it predicts a threshold impact parameter, or minimum electron path inside the
NP, to efficiently activate a set of CBPs. Exploiting the multipolar
description of the CBPs we identify the underlying symmetry rules governing
their excitation by electron beams, and correlate the observed blueshift of the
BPE for increasing impact parameters with the excitation of higher-order CBPs.
Dispersion of the CBPs with decreasing NP sizes further increases this impact
parameter dependent blueshift of the BPE and also explains the decrease in the
impact parameter threshold.

</details>


### [774] [Sensitive detection of the Rydberg transition in trapped electrons on liquid helium using radio-frequency reflectometry](https://arxiv.org/abs/2510.22615)
*Jui-Yin Lin,Tomoyuki Tani,Mikhail Belianchikov,Denis Konstantinov*

Main category: cond-mat.mes-hall

TL;DR: 利用射频反射测量技术探测液氦表面陷获电子的里德堡激发态，发现其对侧向运动而非量子电容效应敏感。


<details>
  <summary>Details</summary>
Motivation: 探测量子系统中动态过程的有效方法，本研究旨在使用射频反射测量技术探测液氦表面陷获电子的里德堡激发态。

Method: 使用射频反射测量技术，通过探测包含陷获电子的射频电路的阻抗变化来检测里德堡态的激发。将实验结果与独立的静电势调制阻抗测量和格林函数数值模拟进行比较。

Result: 成功探测到电子的里德堡跃迁，观察到射频响应可以被电子集体运动的共振模式显著增强。实验结果表明，观测到的里德堡共振响应归因于微波激发的电子的侧向运动，而非近期报道的与垂直位移相关的量子电容。

Conclusion: 研究结果表明，射频反射测量技术可用于探测量子系统的动态过程，并为理解陷获电子的里德堡激发提供了新的见解，强调了侧向运动在其中的作用。

Abstract: Radio-frequency reflectometry, which probes small changes in the electrical
impedance of a device, provides a useful method for sensitive and fast
detection of dynamic processes in quantum systems. Here, we use this method to
detect excitation of the quantized motional (Rydberg) states of trapped
electrons on liquid helium. The Rydberg transition in an ensemble of electrons
is detected by a change in the impedance of an rf circuit in response to a
pulsed-modulated microwave excitation. The result is compared with an
independent impedance measurement on the same electron system modulated by an
electrostatic potential and with a numerical simulation using the Green's
function method. Additionally, it is found that the rf response to the Rydberg
resonance can be strongly enhanced by a resonant mode of the electron
collective motion. Our results suggest that the observed response to the
Rydberg resonance must be attributed to the lateral motion of microwave-excited
electrons rather than the quantum capacitance associated with their vertical
displacement, as was recently reported. Our theoretical analysis based on the
solution of the master equation shows that the quantum capacitance would show a
response which is drastically different from what is observed in the
experiments.

</details>


### [775] [Coulomb correlated multi-particle states of weakly confining GaAs quantum dots](https://arxiv.org/abs/2510.22717)
*Petr Klenovský*

Main category: cond-mat.mes-hall

TL;DR: 该研究使用8带k·p模型结合连续弹性理论和组态相互作用计算了GaAs/AlGaAs量子点中库仑相关多粒子态（X^0, X^±, XX）的电子和发射性质。


<details>
  <summary>Details</summary>
Motivation: 计算库仑相关多粒子态（X^0, X^±, XX）在GaAs/AlGaAs量子点中的电子和发射性质。

Method: 使用8带k·p模型，结合连续弹性理论和组态相互作用（CI）。评估了偶极近似（DA）和准静电超偶极（BDA）纵向形式下的极化分辨振子强度和辐射率。

Result: BDA计算出的寿命与实验结果定量吻合，例如τ^X=0.279 ns（计算值）vs 0.267 ns（实验值），τ^{XX}=0.101 ns（计算值）vs 0.115 ns（实验值）。该模型还能重现电场调谐的多粒子电子结构和发射，以及基于P=τ^X/(τ^X+τ^{XX})推断出的不可分辨性。

Conclusion: 该方法能够准确计算量子点中的多粒子态性质，并能重现实验观察到的现象，为理解和设计量子点器件提供了理论基础。

Abstract: We compute the electronic and emission properties of Coulomb-correlated
multi-particle states (X$^0$, X$^\pm$, XX) in weakly confining GaAs/AlGaAs
quantum dots using an 8-band $\mathbf{k}\!\cdot\!\mathbf{p}$ model coupled to
continuum elasticity and configuration interaction (CI). We evaluate
polarization-resolved oscillator strengths and radiative rates both in the
dipole approximation (DA) and in a quasi-electrostatic beyond-dipole (BDA)
longitudinal formulation implemented via a Poisson reformulation exactly
equivalent to the dyadic Green-tensor kernel. For the dots studied, BDA yields
lifetimes in quantitative agreement with experiment, e.g.,
$\tau^X=0.279\,\mathrm{ns}$ vs $0.267\,\mathrm{ns}$ (exp.) and
$\tau^{XX}=0.101\,\mathrm{ns}$ vs $0.115\,\mathrm{ns}$ (exp.). The framework
also reproduces electric-field tuning of the multi-particle electronic
structure and emission -- including the indistinguishability inferred from
$P=\tau^X/(\tau^X+\tau^{XX})$ -- and we assess sensitivity to CI-basis size and
to electron-electron and hole-hole exchange.

</details>


### [776] [Deterministic single-photon source with on-chip 5.6 GHz acoustic clock](https://arxiv.org/abs/2510.22826)
*Alexander S. Kuznetsov,Meysam Saeedi,Zixuan Wang,Klaus Biermann*

Main category: cond-mat.mes-hall

TL;DR: 通过混合微腔中的量子点和声学应变，实现了超 GHz 的单光子源。


<details>
  <summary>Details</summary>
Motivation: 为了实现光量子技术的广泛应用，需要开发出触发单光子发射速率超过几 GHz 的可扩展固态单光子源。

Method: 将砷化铟量子点集成到混合光子-声子微腔中，通过在几 GHz 下利用声学应变诱导的动态 Purcell 效应来触发单光子发射。利用声波调制量子点跃迁能量，使其周期性地通过一个狭窄的受限光子模式，从而增强发射。

Result: 实现了高达 14 GHz 的量子点跃迁能量调制，在 5.6 GHz 的调制频率下，观察到了动态 Purcell 效应导致的量子点发射增强。对发射的单光子统计测量证实了其单光子特性。

Conclusion: 所提出的平台能够实现基于 III-V 族材料的可扩展单光子源，并集成片上可调谐的声学时钟，在连续波光激发下，频率可以超过几 GHz。

Abstract: Scalable solid state single-photon sources (SPSs) with triggered
single-photon emission rates exceeding a few GHz would aid in the wide
technological adoption of photonic quantum technologies. We demonstrate
triggering of a quantum dot (QD) single photon emission using dynamic Purcell
effect induced at a frequency of several GHz by acoustic strain. To this end,
InAs QDs are integrated in a hybrid photon-phonon patterned microcavity, where
the density of optical states is tailored by the lateral confinement of photons
in um-sized traps defined lithographically in the microcavity spacer. The
single-photon character of the emission form a QD in a trap is confirmed by
measuring single-photon statistics. We demonstrate modulation of the QD
transition energy in a trap with a frequency up to 14 GHz by monochromatic
longitudinal bulk acoustic phonons generated by piezoelectric transducers. For
the modulation frequency of 5.6 GHz, corresponding to the acoustic mode of the
microcavity, the QD energy is periodically shifted through a spectrally narrow
confined photonic mode leading to an appreciable enhancement of the QD emission
due to the dynamic Purcell effect. The platform thus enables the implementation
of scalable III-V-based SPSs with on-chip tunable acoustic clocks with
frequencies that can exceed several GHz under continuous wave optical
excitation.

</details>


### [777] [Heat measurement of quantum interference](https://arxiv.org/abs/2510.23092)
*Christoforus Dimas Satrya,Aleksandr S. Strelnikov,Luca Magazzù,Yu-Cheng Chang,Rishabh Upadhyay,Joonas T. Peltonen,Bayan Karimi,Jukka P. Pekola*

Main category: cond-mat.mes-hall

TL;DR: 本研究首次在量子热传递中观测到由驱动诱导的相干性，并提出基于 Floquet 理论的理论模型解释实验结果。


<details>
  <summary>Details</summary>
Motivation: 量子相干性在量子热机和冰箱的运行和性能中起着关键作用，但其在热传递中的效应尚未被观测到。

Method: 通过测量由一个通量量子比特和耦合到热库的谐振腔组成的系统中的热传递，来检测驱动诱导的相干性。

Result: 观测到热流中的干涉图样，并且在驱动频率为谐振腔频率的整数分之一时，观察到转移到热库的热量出现共振峰。在量子比特对称点处，观察到峰值具有偶/奇选择规则。

Conclusion: 该研究为研究量子相干性在量子热力学中的作用提供了一个平台，并为展示真正的量子热机（直接测量热量）打开了可能性。

Abstract: Quantum coherence plays a key role in the operation and performance of
quantum heat engines and refrigerators. Despite its importance for the
fundamental understanding in quantum thermodynamics and its technological
implications, coherence effects in heat transport have not been observed
previously. Here, we measure quantum features in the heat transfer between a
qubit and a thermal bath in a system formed of a driven flux qubit galvanically
coupled to a $\lambda/4$ coplanar-waveguide resonator that is coupled to a heat
reservoir. This thermal bath is a normal-metal mesoscopic resistor, whose
temperature can be measured and controlled. We detect interference patterns in
the heat current due to driving-induced coherence. In particular, resonance
peaks in the heat transferred to the bath are found at driving frequencies
which are integer fractions of the resonator frequency. A selection rule on the
even/odd parity of the peaks holds at the qubit symmetry point. We present a
theoretical model based on Floquet theory that captures the experimental
results. The studied system provides a platform for studying the role of
coherence in quantum thermodynamics. Our work opens the possibility to
demonstrate a true quantum thermal machine where heat is measured directly.

</details>


### [778] [Rabi oscillations of a monolayer quantum emitter driven through its excited state](https://arxiv.org/abs/2510.23222)
*Victor N. Mitryakhin,Ivan A. Solovev,Alexander Steinhoff,Jaewon Lee,Martin Esmann,Ana Predojević,Christopher Gies,Christian Schneider*

Main category: cond-mat.mes-hall

TL;DR: WSe2单层量子点的拉比振荡可以通过控制激光脉冲参数进行相干调控，为单光子源提供基础。


<details>
  <summary>Details</summary>
Motivation: 研究固态两能级系统的相干操纵，特别是在原子层面上的量子点，以实现量子应用。

Method: 使用皮秒激光脉冲对WSe2单层量子点进行相干驱动，并探测其光致发光。采用基于三能级激子模型的理论计算。

Result: 理论计算和实验数据均表明，通过改变驱动脉冲面积和失谐量，可以控制激子基态布居数，从而实现对拉比振荡的调控。

Conclusion: 通过相干控制量子发射体，为基于单层材料的高性能、按需单光子源奠定了基础。

Abstract: The interaction of a quantum two-level system with a resonant driving field
results in the emergence of Rabi oscillations, which are the hallmark of a
controlled manipulation of a quantum state on the Bloch sphere. This
all-optical coherent control of solid-state two-level systems is crucial for
quantum applications. In this work we study Rabi oscillations emerging in a
WSe2 monolayer-based quantum dot. The emitter is driven coherently using
picosecond laser pulses to a higher-energy state, while photoluminescence is
probed from the ground state. The theoretical treatment based on a three-level
exciton model reveals the population transfer between the exciton ground and
excited states coupled by Coulomb interaction. Our calculations demonstrate
that the resulting exciton ground state population can be controlled by varying
driving pulse area and detuning which is evidenced by the experimental data.
Our results pave the way towards the coherent control of quantum emitters in
atomically thin semiconductors, a crucial ingredient for monolayer-based
high-performance, on-demand single photon sources.

</details>


### [779] [Magnetic-field controlled organic spintronic memristor for neural network computation](https://arxiv.org/abs/2510.23542)
*Tongxin Chen,Yinyu Nie,Yafei Hao,Shengchun Shen,Jiajun Pan,Xiaoguang Li,Yuan Lu*

Main category: cond-mat.mes-hall

TL;DR: 本研究提出了一种基于LSMO/PVDF/Co异质结构的新型有机自旋电子忆阻器，可模拟突触行为，并通过电和磁场进行调控，有望用于神经形态计算和柔性电子设备。


<details>
  <summary>Details</summary>
Motivation: 忆阻器作为一种非易失性电子元件，能够模仿突触行为，在下一代内存技术和受人脑启发的神经形态计算系统中具有巨大潜力。本研究旨在开发一种新型有机自旋电子忆阻器，并探索其在神经形态计算中的应用。

Method: 研究人员构建了一种基于La0.67Sr0.33MnO3 (LSMO)/聚偏氟乙烯 (PVDF)/Co异质结构的新型有机自旋电子忆阻器。通过控制电流极化，研究了由PVDF层内氟原子迁移引起的长期抑制（LTD）和长期增强（LTP）行为。此外，还研究了通过隧道磁电阻（TMR）效应利用外部磁场进行调控的机制。最后，将该忆阻器集成到卷积神经网络（CNN）中进行模拟，以评估其在模式识别和训练稳定性方面的性能。

Result: 该忆阻器成功表现出受生物启发的突触行为，包括LTD和LTP。通过外部磁场可以实现非电调控，实现多状态调控且不影响器件性能和耐久性。CNN模拟结果表明，磁调控能力可以提高模式识别的准确性，并改善训练稳定性，尤其是在高学习率下。

Conclusion: 本研究提出的有机自旋电子忆阻器通过结合电和磁调控，在模拟突触可塑性方面表现出优异的性能，并能提高CNN的模式识别能力。这表明该忆阻器在高性能、低功耗的神经形态计算应用，特别是在柔性和可穿戴电子领域具有广阔的应用前景。

Abstract: Memristors are emerging as key electronic components that retain resistance
states without power. Their non-volatile nature and ability to mimic synaptic
behavior make them ideal for next-generation memory technologies and
neuromorphic computing systems inspired by the human brain. In this study, we
present a novel organic spintronic memristor based on a La0.67Sr0.33MnO3
(LSMO)/poly(vinylidene fluoride) (PVDF)/Co heterostructure, exhibiting
biologically inspired synaptic behavior. Driven by fluorine atom migration
within the PVDF layer, the device demonstrates both long-term depression (LTD)
and long-term potentiation (LTP) under controlled electrical polarization.
Distinctively, the resistance states can also be modulated by an external
magnetic field via the tunneling magnetoresistance (TMR) effect, introducing a
non-electrical means of tuning synaptic plasticity. This magnetic control
mechanism enables multi-state modulation without compromising device
performance or endurance. Furthermore, convolutional neural network (CNN)
simulations incorporating this magnetic tuning capability reveal enhanced
pattern recognition accuracy and improved training stability, especially at
high learning rates. These findings underscore the potential of organic
spintronic memristors as high-performance, low-power neuromorphic elements,
particularly suited for applications in flexible and wearable electronics.

</details>


### [780] [Prediction of a topological phase transition in exchange alternating spin-1 nanographene chains](https://arxiv.org/abs/2510.23555)
*João C. G. Henriques,Yelko del Castillo,Ricardo Segundo,Jan Phillips,Joaquín Fernández-Rossier*

Main category: cond-mat.mes-hall

TL;DR: 利用自旋1纳米石墨烯探索Haldane相和二聚相之间的拓扑相变，并提出实验验证方法。


<details>
  <summary>Details</summary>
Motivation: 探索具有前所未有控制程度的一维量子磁性模型哈密顿量的旗舰模型，特别是利用磁性纳米石墨烯作为人工自旋晶格的构建块。

Method: 使用密度矩阵重整化群（DMRG）研究非线性交换对相变边界的修正；结合多构型和第一性原理计算，提出两种实现拓扑相的候选材料；提出使用非弹性电子隧道光谱（IETS）进行实验识别。

Result: 发现了非线性交换会修正相变边界；提出了扩展的Clar杯和钝化的[4]-三角烯作为实现不同拓扑相的候选材料；证明了IETS可用于识别这些相。

Conclusion: 该工作为实验实现拓扑相铺平了道路，并且这些相可以通过扫描隧道显微镜进行局部探测。

Abstract: The use of magnetic nanographenes as building blocks for artificial spin
lattices is enabling the exploration of flagship model Hamiltonians of
one-dimensional quantum magnetism with an unprecedented degree of control. The
spin-1 Heisenberg model, incorporating both linear and quadratic exchange
interactions, was first realized using [3]-triangulenes, where the hallmark
Haldane phase with spin fractionalization was observed. Later, the spin-1/2
Heisenberg Hamiltonian with exchange alternation was realized with Clar's
goblets, where two additional topological phases were identified. Here we show
that spin-1 nanographenes can also be used to explore the topological phase
transition between the Haldane phase and a dimerized phase predicted for spin-1
chains with bond-alternation. We first study how the boundary of the phase
transition is modified by non-linear exchange, known to be present in spin-1
nanographenes, using density matrix renormalization group (DMRG). Combining
multiconfigurational with first-principles calculations, we propose two
candidates to realize different topological phases of the model: a recently
synthesized extended Clar's goblet, and a passivated [4]-triangulene. Moreover,
we show how these two phases can be identified experimentally using inelastic
electron tunneling spectroscopy (IETS). This work paves the way for the
experimental realization of these topological phases, which can be locally
probed with scanning tunneling microscopy.

</details>


### [781] [High-Efficiency Thermoelectric Transport in Aharonov-Bohm-Casher Rings](https://arxiv.org/abs/2510.23579)
*Diego García,Sergio Arias,Rosa López*

Main category: cond-mat.mes-hall

TL;DR: 量子热机利用量子效应（如相干和干涉）将热量转化为功。本研究首次考虑了自旋相关效应，并发现对于基于 Aharonov-Bohm 环的量子热机，Rashba 相互作用（一种自旋-轨道相互作用）可以提高其热电性能（ZT）。


<details>
  <summary>Details</summary>
Motivation: 以前对量子热机的研究没有考虑自旋依赖效应，而这些效应会影响热电器件的性能。因此，本研究的动机是研究量子热机中的自旋依赖效应，特别是 Rashba 相互作用对基于 Aharonov-Bohm 环的热电器件性能的影响。

Method: 研究基于 Aharonov-Bohm 环的量子热机的热电行为，该器件耦合了 Rashba 自旋-轨道相互作用 (SOI)，该相互作用将电子的运动与自旋耦合起来。

Result: 研究发现，Rashba SOI 能够提高器件的品质因数 $ZT$（衡量发动机转换效率的指标）。

Conclusion: 结果表明，通过控制量子热机中的自旋依赖干涉效应，有望提高热电器件的效率。

Abstract: Quantum heat engines are nanoscale devices that convert heat into work by
exploiting quantum effects, such as coherence and interference. Previous
studies of these devices did not consider spin-dependent effects, which can
influence the thermoelectric performance of the engine. In this work, we study
the thermoelectric behavior of a quantum heat engine based on an Aharonov-Bohm
ring - a mesoscopic ring where electrons exhibit interference depending on the
magnetic flux it encloses - incorporating Rashba spin-orbit interaction (SOI),
which couples the electron's motion and spin. We find that Rashba SOI enhances
the figure of merit $ZT$, measure of the engine's conversion efficiency. Our
results suggest that controlling spin-dependent interference could lead to
improvements in the fabrication of efficient thermoelectric devices.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [782] [Environment-aware Motion Matching](https://arxiv.org/abs/2510.22632)
*Jose Luis Ponton,Sheldon Andrews,Carlos Andujar,Nuria Pelechano*

Main category: cs.GR

TL;DR: 一种新的实时全身体动画系统，用于在动态环境中导航。


<details>
  <summary>Details</summary>
Motivation: 传统角色动画技术难以应对任意情况，尤其是在人群动画和环境交互方面，现有方法存在手动设置或缺乏自然性等问题。

Method: 通过预处理提取动作捕捉数据库的形状、姿态和轨迹特征，在运行时通过高效搜索匹配用户输入和当前姿态，同时惩罚与动态环境的碰撞，实现环境感知和姿态-轨迹双向关联。

Result: 能够让角色自然地调整姿态和轨迹，以适应拥挤的场景。

Conclusion: 提出了一种名为“环境感知运动匹配”的新型实时全身体动画系统，解决了现有方法的局限性，实现了更自然、更具适应性的角色动画。

Abstract: Interactive applications demand believable characters that respond naturally
to dynamic environments. Traditional character animation techniques often
struggle to handle arbitrary situations, leading to a growing trend of
dynamically selecting motion-captured animations based on predefined features.
While Motion Matching has proven effective for locomotion by aligning to target
trajectories, animating environment interactions and crowd behaviors remains
challenging due to the need to consider surrounding elements. Existing
approaches often involve manual setup or lack the naturalism of motion capture.
Furthermore, in crowd animation, body animation is frequently treated as a
separate process from trajectory planning, leading to inconsistencies between
body pose and root motion. To address these limitations, we present
Environment-aware Motion Matching, a novel real-time system for full-body
character animation that dynamically adapts to obstacles and other agents,
emphasizing the bidirectional relationship between pose and trajectory. In a
preprocessing step, we extract shape, pose, and trajectory features from a
motion capture database. At runtime, we perform an efficient search that
matches user input and current pose while penalizing collisions with a dynamic
environment. Our method allows characters to naturally adjust their pose and
trajectory to navigate crowded scenes.

</details>


### [783] [Step2Motion: Locomotion Reconstruction from Pressure Sensing Insoles](https://arxiv.org/abs/2510.22712)
*Jose Luis Ponton,Eduardo Alvarado,Lin Geng Foo,Nuria Pelechano,Carlos Andujar,Marc Habermann*

Main category: cs.GR

TL;DR: 该研究提出了Step2Motion，一种利用多模态压力和惯性传感器数据从鞋垫传感器重建人类运动的方法，解决了现有方法在现实世界中捕捉人类运动的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的人类运动捕捉方法（如动作捕捉服和光学系统）存在对用户动作的限制或视线限制。而可穿戴鞋垫传感器不受这些限制，非常适合在各种真实场景（尤其是在户外）下进行鲁棒的、无约束的运动捕捉，但现有方法对这类传感器数据的利用探索不足。

Method: Step2Motion方法利用鞋垫传感器捕获的压力和惯性数据（包括加速度和角速度）来重建人类运动。

Result: 该方法在多种运动场景下进行了评估，包括行走、慢跑、侧向移动、踮脚尖、半蹲和跳舞等，证明了其在不同运动风格下的通用性。

Conclusion: Step2Motion是第一个利用多模态鞋垫传感器数据重建人类运动的方法，它有效地解决了现有运动捕捉技术的局限性，并在多种运动场景下得到了验证。

Abstract: Human motion is fundamentally driven by continuous physical interaction with
the environment. Whether walking, running, or simply standing, the forces
exchanged between our feet and the ground provide crucial insights for
understanding and reconstructing human movement. Recent advances in wearable
insole devices offer a compelling solution for capturing these forces in
diverse, real-world scenarios. Sensor insoles pose no constraint on the users'
motion (unlike mocap suits) and are unaffected by line-of-sight limitations (in
contrast to optical systems). These qualities make sensor insoles an ideal
choice for robust, unconstrained motion capture, particularly in outdoor
environments. Surprisingly, leveraging these devices with recent motion
reconstruction methods remains largely unexplored. Aiming to fill this gap, we
present Step2Motion, the first approach to reconstruct human locomotion from
multi-modal insole sensors. Our method utilizes pressure and inertial
data-accelerations and angular rates-captured by the insoles to reconstruct
human motion. We evaluate the effectiveness of our approach across a range of
experiments to show its versatility for diverse locomotion styles, from simple
ones like walking or jogging up to moving sideways, on tiptoes, slightly
crouching, or dancing.

</details>


### [784] [FlowCapX: Physics-Grounded Flow Capture with Long-Term Consistency](https://arxiv.org/abs/2510.23122)
*Ningxiao Tao,Liru Zhang,Xingyu Ni,Mengyu Chu,Baoquan Chen*

Main category: cs.GR

TL;DR: FlowCapX是一个物理增强框架，用于从稀疏视频输入进行流体重建，能解决长时域的复杂物理约束和稀疏观测数据联合优化问题，并在湍流运动捕捉和物理一致性方面表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在捕捉湍流运动和保持物理一致性方面存在挑战，限制了重建质量和下游任务的表现。因此，需要一个能解决复杂物理约束和稀疏观测数据联合优化问题，并且能捕捉湍流运动的框架。

Method: FlowCapX采用混合框架，在空间尺度上分离表示和监督。粗略层面，通过一种新颖的优化策略来解决稀疏视图歧义，该策略将长期观测与基于物理的速度场对齐，并强调基于涡量（vorticity）的物理约束。精细层面，优先考虑观测保真度以保留关键的湍流结构。

Result: FlowCapX在速度重建方面达到了最先进的水平，并支持了下游任务，如准确的流体分析、带有示踪剂可视化（tracer visualization）的场景增强以及重新模拟。

Conclusion: FlowCapX通过其物理增强框架，成功实现了从稀疏视频输入进行高质量的流体重建，并在解决长时域优化问题、捕捉湍流运动和下游应用方面展现出优越性能。

Abstract: We present FlowCapX, a physics-enhanced framework for flow reconstruction
from sparse video inputs, addressing the challenge of jointly optimizing
complex physical constraints and sparse observational data over long time
horizons. Existing methods often struggle to capture turbulent motion while
maintaining physical consistency, limiting reconstruction quality and
downstream tasks. Focusing on velocity inference, our approach introduces a
hybrid framework that strategically separates representation and supervision
across spatial scales. At the coarse level, we resolve sparse-view ambiguities
via a novel optimization strategy that aligns long-term observation with
physics-grounded velocity fields. By emphasizing vorticity-based physical
constraints, our method enhances physical fidelity and improves optimization
stability. At the fine level, we prioritize observational fidelity to preserve
critical turbulent structures. Extensive experiments demonstrate
state-of-the-art velocity reconstruction, enabling velocity-aware downstream
tasks, e.g., accurate flow analysis, scene augmentation with tracer
visualization and re-simulation.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [785] [Unified Framework for Direct and Complete Characterization of an Unknown Kraus Operator and Density Matrix Using a Single Input State](https://arxiv.org/abs/2510.21766)
*Sahil,Swarup Kumar Giri,Sohail*

Main category: quant-ph

TL;DR: 该研究提出了一种使用单一输入态即可直接且完整地表征未知克劳斯算符、可观测量、酉算符和密度矩阵的统一框架，该框架对系统与探针之间的耦合强度没有限制。


<details>
  <summary>Details</summary>
Motivation: 实验中制备纯态常不可行，需要一种在混合态下表征量子过程和算符的方法。

Method: 提出一个统一框架，利用单一输入态、一组基于投影的酉演化算符以及单一可观测量来实现对未知克劳斯算符、可观测量、酉算符和密度矩阵的表征。

Result: 实现了使用单一输入态完成上述表征任务，且不限制系统与探针的耦合强度。

Conclusion: 该框架为在实际实验条件下进行量子测量和动力学过程的表征提供了新的途径。

Abstract: Characterization of quantum measurements and dynamical processes is typically
performed using pure state preparations. However, in realistic experimental
settings, the preparation of pure states is often infeasible due to noise and
system constraints. In this work, we present a unified framework that enables
the direct and complete characterization of an unknown Kraus operator using
only a single input state. The same framework also supports the
characterization of unknown observable, unitary operator, and density matrix.
Remarkably, all these tasks are accomplished using a single input state, a set
of projector-based unitary evolution operators, and the measurement of a single
observable. Importantly, our approach imposes no constraints on the strength of
the coupling between the system and a probe.

</details>


### [786] [An Industry-Academia Partnership for Advancing Quantum Frontiers: Perspective from the U.S. Center for Quantum Technologies](https://arxiv.org/abs/2510.13365)
*David Stewart,Gerardo Ortiz,Peter M. Kogge,Ricardo S. Decca,Tongcang Li*

Main category: quant-ph

TL;DR: 美国量子技术中心（CQT）是一个由普渡大学、印第安纳大学和圣母大学领导的、隶属于美国国家科学基金会（NSF）工业-大学合作研究中心（IUCRC）计划的多大学联盟，旨在通过整合学术研究与产业和政府的合作来加速量子创新。


<details>
  <summary>Details</summary>
Motivation: 本篇论文旨在概述美国量子技术中心（CQT）的战略使命、跨学科研究议程，以及该中心通过合作开发、转化影响和人才培养来塑造量子技术未来的作用。

Method: 通过整合学术研究与产业和政府的合作，加速量子创新。

Result: CQT正在通过合作开发、转化影响和人才培养来塑造量子技术。

Conclusion: CQT在美国量子技术领域发挥着关键作用。

Abstract: The U.S. Center for Quantum Technologies (CQT) is a multi-university
consortium established under the National Science Foundation's (NSF)
Industry-University Cooperative Research Centers (IUCRC) program. Led jointly
by Purdue University, Indiana University (both Bloomington and Indianapolis
campuses), and the University of Notre Dame, CQT integrates academic research
with industrial and governmental collaboration to accelerate quantum
innovation. This perspective outlines the consortium's strategic mission,
interdisciplinary research agenda, and its role in shaping the future of
quantum-enabled technologies through collaborative development, translational
impact, and workforce cultivation.

</details>


### [787] [From Cables to Qubits: A Decomposed Variational Quantum Optimization Pipeline](https://arxiv.org/abs/2510.21901)
*Paul-Niklas Ken Kandora,Adrian Asmund Fessler,Robert Fabian Lindermann,Phil Arnold,Andreas Hempel,Steffen Rebennack*

Main category: quant-ph

TL;DR: 电缆布线优化问题被表述为一个可分离的二次无约束二元优化问题，并利用量子计算进行求解，从而在保证可行性的前提下找到最优的布线方案。


<details>
  <summary>Details</summary>
Motivation: 解决工业布局和智能制造中的电缆布线优化问题。

Method: 将电缆布线优化问题（CROP）表述为一个电缆可分离的、块对角二次无约束二元优化（QUBO）问题，并推导出保持可行性的保守惩罚界限。利用此结构，提出一个分解流水线，为每根电缆构建一个QUBO，将每个QUBO转化为哈密顿量，并使用变分量子本征求解器（VQE）求解子问题。最后，将各电缆的解合并为全局布线分配。此过程将每个运行时的量子比特数从完整问题的大小减少到单根电缆子问题的大小。在不同大小的电缆布线优化问题上使用Qiskit的SamplingVQE测试性能。

Result: 在不同大小的电缆布线优化问题上，分解VQE方法能够获得可行且最优的布局。

Conclusion: 分解VQE方法是解决电缆布线优化问题的有效途径，能够获得可行且最优的布局。

Abstract: The Cable Routing Optimization Problem (CROP) is a multi-flow routing task
central to industrial layouts and smart manufacturing installations. We
formulate CROP as a cable-wise separable, block-diagonal Quadratic
Unconstrained Binary Optimization Problem (QUBO) and derive conservative
penalty bounds that preserve feasibility. Exploiting this structure, we
introduce a decomposition pipeline that builds one QUBO per cable, transforms
each QUBO into a Hamiltonian and solves the subproblems with the Variational
Quantum Eigensolver (VQE). Finally, the solutions per cable are merged into a
global routing assignment. This procedure reduces the per-run qubits from the
full problem size to those of a single-cable subproblem. We test our
performance on different cable routing optimization problems varying in size
using Qiskit's SamplingVQE. Our findings indicate that a decomposed VQE
approach attains feasible and optimal layouts across a range of cable-routing
problems.

</details>


### [788] [Boundaries of Acceptable Defectiveness: Redefining Surface Code Robustness under Heterogeneous Noise](https://arxiv.org/abs/2510.22001)
*Jacob S. Palmer,Kaitlin N. Smith*

Main category: quant-ph

TL;DR: 研究提出了“可接受缺陷度”(BADs)的概念，为包含有缺陷的量子比特的表面编码设定了界限，并使用STIM模拟了各种参数下的重复码，以评估有缺陷的量子比特对逻辑计算的影响。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决超导量子比特中普遍存在的噪声不均匀性问题，提出一种新的方法来界定有缺陷量子比特的可接受度，以避免其对逻辑计算产生不利影响。

Method: 使用STIM模拟了不同尺寸（3到17）的表面码重复码电路，并考虑了不同的缺陷错误率和异常缺陷位置。同时，还模拟了异构噪声模型，以评估这些因素在真实硬件噪声下的影响。

Result: 研究发现，当有缺陷量子比特的物理错误率低于0.75%且在足够大的码距和合适的位置时，其对逻辑错误率的影响可以忽略不计。然而，即使在看似可接受的物理错误率下，量子比特的显著变异也会严重降低逻辑量子比特的性能。这表明，缺陷度应被视为一个连续的光谱，而不是全或无的概念。

Conclusion: 研究强调了噪声异质性对逻辑错误率的直接影响，并为硬件设计者提供了在不完美、不均匀的量子比特条件下实现目标逻辑性能的初步目标和度量标准。

Abstract: A variety of past research on superconducting qubits shows that these devices
exhibit considerable variation and thus cannot be accurately depicted by a
uniform noise model. To combat this often unrealistic picture of homogeneous
noise in quantum processors during runtime, our work aims to define the
boundaries of acceptable defectiveness (BADs), or the upper boundary of a
qubits physical error, past which this defective qubit entirely degrades the
logical computation and should be considered faulty and removed from the
surface code mapping. Using the QEC simulation package STIM, repetition code
circuits on rotated surface codes were generated, sampled, and analyzed from
distances 3 to 17, with various defective error rates and outlier defect
locations. In addition, we simulated heterogeneous noise models using the same
parameters to test how increasingly deviated distributions of physical errors
scale across code distances under realistic, heterogeneous noise models that
are informed by current superconducting hardware. The results suggest that
there are, in fact, boundaries of acceptable defectiveness in which a defective
qubit, with a physical error rate $<= .75$\%, can be left in the lattice with
negligible impact on logical error rate given sufficient code distances and
proper placement in the lattice. On the other hand, we find that substantial
qubit variation around a seemingly acceptable physical error rate can severely
degrade logical qubit performance. As a result, we propose that defectiveness
of both individual qubits and the overall uniformity of lattice fidelity should
not be viewed as all or nothing, but instead as a spectrum. Our research
demonstrates how heterogeneity directly impacts logical error rate and provides
preliminary goals and metrics for hardware designers to meet in order to
achieve target logical performance with imperfect, non-uniform qubit qualities.

</details>


### [789] [Temporal Complexity Hierarchies in Solvable Quantum Many-Body Dynamics](https://arxiv.org/abs/2510.21927)
*He-Ran Wang,Ilya Vilkoviskiy,Dmitry A. Abanin*

Main category: quant-ph

TL;DR: 该研究将群论工具应用于砖砌量子电路，揭示了影响矩阵（IM）计算复杂性与动力学行为之间的关系，并根据时间纠缠熵提出了计算资源需求的等级划分。


<details>
  <summary>Details</summary>
Motivation: 理解影响矩阵（IM）的计算复杂性与其动力学行为的关系对于理论和实践都至关重要，但目前对此研究不足。

Method: 研究了从可积到混沌区域的砖砌量子电路族。利用群论工具识别了时间纠缠熵的三种不同标度律，从而对IM的计算资源需求进行了分级。此外，还分析了IM的内存结构，区分了经典和量子时间相关性，并提出了一个用于测量量子内存的实验方案。

Result: 确定了三种不同的时间纠缠熵标度律，并据此对IM的计算资源需求进行了分级。发现了某些情况下有效的经典IM，允许使用蒙特卡洛算法计算多时间相关性。对于没有显式经典描述的IM，提出了一种量子内存的测量方法，并举例说明了具有长期真实量子相关性的情况。

Conclusion: 将量子多体动力学与群论联系起来，加深了对IM复杂性的理解，并揭示了其与动力学物理特性的复杂关系。

Abstract: The influence matrix (IM) provides a powerful framework for characterizing
nonequilibrium quantum many-body dynamics by encoding multitime correlations
into tensor-network states. Understanding how its computational complexity
relates to underlying dynamics is crucial for both theoretical insight and
practical utility, yet remains largely unexplored despite a few case studies.
Here, we address this question for a family of brickwork quantum circuits
ranging from integrable to chaotic regimes. Using tools from geometric group
theory, we identify three qualitatively distinct scalings of temporal
entanglement entropy, establishing a hierarchy of computational resources
required for accurate tensor-network representations of the IM for these
models. We further analyze the memory structure of the IM and distinguish
between classical and quantum temporal correlations. In particular, for certain
examples, we identify effectively classical IMs that admit an efficient Monte
Carlo algorithm for computing multitime correlations. In more generic settings
without an explicit classical description of the IM, we introduce an
operational measure of quantum memory with an experimental protocol, and
discuss examples exhibiting long-time genuinely quantum correlations. Our
results establish a new connection between quantum many-body dynamics and group
theory, providing fresh insights into the complexity of the IM and its
intricate connection to the physical characteristics of the dynamics.

</details>


### [790] [qc-kmeans: A Quantum Compressive K-Means Algorithm for NISQ Devices](https://arxiv.org/abs/2510.22540)
*Pedro Chumpitaz-Flores,My Duong,Ying Mao,Kaixun Hua*

Main category: quant-ph

TL;DR: qc-kmeans是一种混合式压缩k-means算法，通过傅里叶特征草图和QAOA电路在NISQ硬件上进行聚类，具有恒定的峰值量子比特需求和有竞争力的聚类质量。


<details>
  <summary>Details</summary>
Motivation: NISQ硬件上的聚类受限于数据加载和有限的量子比特数，需要一种新的聚类方法。

Method: 提出qc-kmeans算法，使用傅里叶特征草图（QFF）对数据集进行摘要，并通过解决小型分组QUBOs和浅层QAOA电路来选择质心。算法还包括一个带有精英保留的精炼步骤，以确保成本的不断下降。

Result: 在Qiskit Aer模拟中（深度p=1），该方法在低维合成基准测试中使用的量子比特数少于9个，并且实现了与量子基线相比有竞争力的平方误差和。在九个实际数据集中（最多4.3 x 10^5个点），该流水线在模拟中保持了恒定的峰值量子比特使用量。在IBM噪声模型下，准确性与理想情况相似。

Conclusion: qc-kmeans提供了一种面向NISQ的聚类方法，该方法使用浅层、有界宽度的电路，并在模拟中具有有竞争力的聚类质量。

Abstract: Clustering on NISQ hardware is constrained by data loading and limited
qubits. We present \textbf{qc-kmeans}, a hybrid compressive $k$-means that
summarizes a dataset with a constant-size Fourier-feature sketch and selects
centroids by solving small per-group QUBOs with shallow QAOA circuits. The QFF
sketch estimator is unbiased with mean-squared error $O(\varepsilon^2)$ for
$B,S=\Theta(\varepsilon^{-2})$, and the peak-qubit requirement
$q_{\text{peak}}=\max\{D,\lceil \log_2 B\rceil + 1\}$ does not scale with the
number of samples. A refinement step with elitist retention ensures
non-increasing surrogate cost. In Qiskit Aer simulations (depth $p{=}1$), the
method ran with $\le 9$ qubits on low-dimensional synthetic benchmarks and
achieved competitive sum-of-squared errors relative to quantum baselines;
runtimes are not directly comparable. On nine real datasets (up to $4.3\times
10^5$ points), the pipeline maintained constant peak-qubit usage in simulation.
Under IBM noise models, accuracy was similar to the idealized setting. Overall,
qc-kmeans offers a NISQ-oriented formulation with shallow, bounded-width
circuits and competitive clustering quality in simulation.

</details>


### [791] [The evolution of Liouville von Neumann master equations in the Pechukas-Yukawa framework](https://arxiv.org/abs/2510.21939)
*Mumnuna Aziz Qureshi*

Main category: quant-ph

TL;DR: 本文提出了一种新的非平衡密度矩阵动力学形式，能够描述高度纠缠的多体相互作用。通过本源态的本征值动力学演化来计算量子态，并引入了一个参数化演化的变量λ(t)来携带时间依赖性。这通过Pechukas-Yukawa映射和广义Calogero-Sutherland模型实现，从而能够从本征值动力学精确描述量子系统。该描述改进了对非平衡量子相变和退相干之间关系的理解，对广泛的应用具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 本文旨在提出一种新的非平衡密度矩阵动力学形式，以描述高度纠缠的多体相互作用，并改进对非平衡量子相变与退相干之间关系的理解。

Method: 采用Pechukas-Yukawa映射和广义Calogero-Sutherland模型，通过本源态的本征值动力学演化来计算量子态，并引入了一个参数化演化的变量λ(t)来携带时间依赖性。

Result: 提出了一种能够从本征值动力学精确描述量子系统的形式，并改进了对非平衡量子相变与退相干之间关系的理解。

Conclusion: 本文提出的非平衡密度矩阵动力学形式能够精确描述量子系统，并为理解非平衡量子相变与退相干提供了新的视角，具有广泛的应用前景。

Abstract: This paper presents a novel formalism for the out of equilibrium dynamics of
the density matrix, capable of describing highly entangled many-body
interactions. The evolution of quantum states is evaluated via eigenvalue
dynamics of a general Hamiltonian system, perturbed by a parametrically
evolving variable $\lambda(t)$ that carries the time-dependence. This is
achieved using the Pechukas-Yukawa mapping of the evolution of the energy
levels governed by their initial conditions on a generalised
Calogero-Sutherland model of a 1D classical gas. As such, quantum systems can
be described exactly in their entirety from eigenvalue dynamics. Under this
description, we provide an improved understanding of the relationship between
nonequilibrium quantum phase transitions and decoherence which has significant
impacts to a wide range of applications.

</details>


### [792] [Form-preserving transformations of wave and Wigner functions](https://arxiv.org/abs/2510.21949)
*Mustafa Amin,Mason Daub,Mark A. Walton*

Main category: quant-ph

TL;DR: 该论文回顾并扩展了形式保持变换在求解含时薛定谔方程中的应用，展示了其在生成具有奇特性质的解方面的潜力，并将其推广到量子信息和相空间分析。


<details>
  <summary>Details</summary>
Motivation: 该论文的动机在于探索一种能够系统性地生成薛定谔方程新解的方法，特别是那些具有非平凡性质的解，并将其应用范围从一维扩展到高维，同时结合相空间分析。

Method: 论文采用形式保持变换（form-preserving transformations）的方法，对含时薛定谔方程的时空坐标进行变换，以生成新的、可能具有奇特性质的解。具体方法包括：回顾一维变换，推导三维变换（包括标量和矢量势），考虑含矢量势时的时相关旋转，以及在相空间中对Wigner函数进行变换。

Result: 研究发现，形式保持变换可以生成包括Airy光束、Senitzky相干激发态和谐振子定态自由色散等特例。在三维情况下，推导了包含时相关旋转的通用变换公式。在相空间中，Wigner函数表现出真实的概率分布行为，并且推导出的变换公式能够解释和推广Airy光束和相干激发态的刚性演化，同时从Moyal方程中恢复了已知的形式保持变换。

Conclusion: 形式保持变换是一种强大而通用的工具，能够系统地生成薛定谔方程的精确解，并具有广泛的应用前景，尤其是在理解和生成具有特定量子性质的波函数以及在量子信息和相空间动力学中。

Abstract: Solutions of the time-dependent Schr\"odinger equation are mapped to other
solutions for a (possibly) different potential by so-called form-preserving
transformations. These time-dependent transformations of the space and time
coordinates can produce remarkable solutions with surprising properties. A
classic example is the force-free accelerating Airy beam found by Berry and
Balazs. We review the 1-dimensional form-preserving transformations and show
that they also yield Senitzky coherent excited states and the free dispersion
of any harmonic-oscillator stationary state. Form preservation of the $D$- and
3-dimensional Schr\"odinger equation with both a scalar and a vector potential
is then considered. Time-dependent rotations may be included when a vector
potential is present; we find a general transformation formula for this case.
Quantum form-preserving maps are also considered in phase space. First, the
wave-function transformation is shown to produce a simple result for Wigner
functions: they transform as a true phase-space probability would. The explicit
transformation formula explains and generalizes the rigid evolution of curves
in phase space that characterize the Airy beam and the coherent excited states.
Then we recover the known form-preserving transformations from the Moyal
equation obeyed by Wigner functions.

</details>


### [793] [An Algebraic-Recursive Approach to Generate Higher-Order Symmetry Operators for Schrödinger and Klein-Gordon equations](https://arxiv.org/abs/2510.22114)
*Enrique Casanova,Melvin Arias*

Main category: quant-ph

TL;DR: 本文提出一种代数递归方法来构建与量子力学中的中心算子 H^ 交换的微分算子。


<details>
  <summary>Details</summary>
Motivation: 研究如何构建与中心算子 H^ 交换的微分算子。

Method: 从自由粒子的薛定谔方程出发，推导出平移、旋转和升降等一阶对称生成元，并考察它们包含李代数和乔丹代数的代数基础。将该方法推广到高阶算子，并应用于克莱因-戈登方程和薛定谔方程的近似分数阶对称算子，以及谐振子和四阶克莱因-戈登方程的微扰情况。

Result: 推导出一阶对称生成元，并将其推广到高阶算子。将该方法应用于克莱因-戈登方程，得到相对论对称算子。定义了薛定谔方程分数阶对称算子的近似，并采用微扰方法处理了交换更一般的谐振子和四阶克莱因-戈登方程。给出了算子数量作为阶数和代数基础维度函数的通用公式，并给出了微分高阶中心izer基础的简化形式。

Conclusion: 本文提出的代数递归方法可以有效地构建与中心算子 H^ 交换的微分算子，并应用于多种物理方程和数学问题。

Abstract: This article explores an algebraic-recursive approach to construct
differential operators that commute with a central operator $\hat{H}$ in
quantum mechanics. Starting from the Schr\"odinger equation for a free
particle, the work derives first-order symmetry generators, such as
translations, rotations, and boosts, and examines their algebraic basis
encompassing Lie and Jordan algebras. The analysis is then extended to
higher-order operators, demonstrating how they can be constructed from the
first-order ones through algebraic operations and Lie algebra simplification.
This methodology is applied to the Klein-Gordon equation in Minkowski
space-time, yielding relativistic symmetry operators. Furthermore, we defined
an approximation to fractional symmetry operators of the Schrodinger equation,
and a perturbative approach is employed for a case where the commutation is
more general, illustrated with a one-dimensional harmonic oscillator and the
fourth-order Klein-Gordon equation. The results include a general formula for
the number of operators as a function of the order and the dimension of the
algebraic basis, providing a reduced-form development of the differential
higher-order centralizers' basis.

</details>


### [794] [Architecting Scalable Trapped Ion Quantum Computers using Surface Codes](https://arxiv.org/abs/2510.23519)
*Scott Jones,Prakash Murali*

Main category: quant-ph

TL;DR: 该论文研究了如何在基于量子电荷耦合器件（QCCD）的系统中高效实现表面码（一种量子纠错方案），并通过开发一种近乎最优的拓扑感知编译方法，将逻辑时钟速度平均提高了 3.8 倍，从而为未来的量子计算系统设计提供了指导。


<details>
  <summary>Details</summary>
Motivation: 量子计算平台中的离子阱（TI）系统规模不足，且错误率远高于实际应用需求，需要量子纠错（QEC）来构建逻辑量子比特。然而，目前尚不清楚如何在QCCD系统中实现大规模QEC。

Method: 提出了一种近乎最优的拓扑感知编译方法，用于在QCCD系统上高效实现表面码。利用该编译方法，研究了硬件陷阱容量、连通性和电极布线选择对表面码实现的影响。

Result: 开发的编译方法比现有QCCD编译器在逻辑时钟速度方面平均提高了 3.8 倍。研究表明，较小的、包含两个离子的陷阱在性能和硬件效率方面是理想选择，这与之前认为较大的陷阱（20-30个离子）更优的观点相反。

Conclusion: 小型离子阱（两个离子）在QCCD系统中实现表面码时，在性能和硬件效率上具有优势，这可能为未来的量子计算系统设计提供新的方向。

Abstract: Trapped ion (TI) qubits are a leading quantum computing platform. Current TI
systems have less than 60 qubits, but a modular architecture known as the
Quantum Charge-Coupled Device (QCCD) is a promising path to scale up devices.
There is a large gap between the error rates of near-term systems ($10^{-3}$ to
$10^{-4}$) and the requirements of practical applications (below $10^{-9}$). To
bridge this gap, we require Quantum Error Correction (QEC) to build
\emph{logical qubits} that are composed of multiple physical qubits. While
logical qubits have been demonstrated on TI qubits, these demonstrations are
restricted to small codes and systems. There is no clarity on how QCCD systems
should be designed to implement practical-scale QEC. This paper studies how
surface codes, a standard QEC scheme, can be implemented efficiently on
QCCD-based systems. To examine how architectural parameters of a QCCD system
can be tuned for surface codes, we develop a near-optimal topology-aware
compilation method that outperforms existing QCCD compilers by an average of
3.8X in terms of logical clock speed. We use this compiler to examine how
hardware trap capacity, connectivity and electrode wiring choices can be
optimised for surface code implementation. In particular, we demonstrate that
small traps of two ions are surprisingly ideal from both a performance-optimal
and hardware-efficiency standpoint. This result runs counter to prior intuition
that larger traps (20-30 ions) would be preferable, and has the potential to
inform design choices for upcoming systems.

</details>


### [795] [Effect of Stochastic Charge Noise in Si/SiGe Quantum-Dot Spin Qubits](https://arxiv.org/abs/2510.22189)
*Wei-en Chiu,Chia-Hsien Huang,Yi-Hsien Wu,Hsi-Sheng Goan*

Main category: quant-ph

TL;DR: Si/SiGe量子点中的自旋量子比特退相干行为主要源于电荷噪声的非马尔可夫效应。为了改进相干噪声模型在退相干模拟和层析分析中的性能，提出了一种源自电偶极自旋共振的自旋-声子模型来表征Si/SiGe量子点中自旋量子比特的退相干行为。通过使用1/f频谱表征量子噪声相关性，该随机模型可以比随机相干模型更精确地预测退相干。同时，利用门层析技术（GST）来解决误差生成器，并分析非马尔可夫效应引起的模型违反。根据结果，将该模型的某些误差生成器归因于非相干误差，避免了先前研究中使用过大的相干噪声强度来解释实验观察到的退相干时间，从而低估了门保真度。此外，通过门优化，可以显著减少非相干的非马尔可夫1/f电荷噪声对误差的贡献。通过CPMG协议中的滤波器函数分析，证明了针对非相干噪声优化的脉冲比常规高斯脉冲对相干噪声更具鲁棒性，从而显著提高了优化脉冲的有效性。


<details>
  <summary>Details</summary>
Motivation: Si/SiGe量子点中自旋量子比特的退相干行为主要由电荷噪声的非马尔可夫效应引起。现有的相干噪声模型在模拟和层析分析中存在不足，需要改进以更准确地描述退相干行为。

Method: 提出一种基于电偶极自旋共振的自旋-声子模型，并结合1/f频谱来表征量子噪声相关性，以进行退相干模拟。利用门层析技术（GST）分析误差生成器和模型违反。通过门优化来减少噪声影响，并使用滤波器函数分析优化脉冲的鲁棒性。

Result: 该自旋-声子模型结合1/f频谱，能够比随机相干模型更精确地预测退相干。通过GST分析，将部分误差生成器归因于非相干误差，避免了以往研究中因过高估计相干噪声强度而低估门保真度的问题。优化后的控制脉冲能显著减少非相干的非马尔可夫1/f电荷噪声的误差贡献，并且比高斯脉冲对相干噪声更具鲁棒性。

Conclusion: 提出的自旋-声子模型和优化的控制脉冲能够有效缓解Si/SiGe量子点中由非马尔可夫电荷噪声引起的退相干问题，提高量子比特的性能和门保真度。

Abstract: In Si/SiGe quantum dots, the decoherence behavior of spin qubits usually
comes from the non-Markovian effect of the charge noise. To improve the
performance of using the coherent noise models in the decoherence simulation
and tomography analysis, here we propose a spin-phonon model derived from the
electric dipole spin resonance to characterize the decoherence behavior of the
spin qubit in a Si/SiGe quantum dot. Utilizing a 1/f spectrum to characterize
quantum noise correlation, our stochastic model can yield a more precise
prediction of decoherence compared to a random coherence model. We also use
gate set tomography (GST) to address the error generator and analyze the model
violation coming from the non-Markovian effect. Based on the results, we
attribute certain error generators of this model to the incoherence error,
which avoids the scenario of using too large a coherent noise strength in the
previous study to account for the experimentally observed decoherence times,
and thus underestimates the gate fidelity. We also perform a gate optimization
and show that our optimized control pulse can substantially reduce the error
contribution of the incoherent non-Markovian 1/f charge noise. We further
demonstrate that the optimized pulse against incoherent noise is more robust
against coherent noise than the regular Gaussian pulse through a filter
function analysis in a CPMG protocol, demonstrating the significant
effectiveness of the optimized pulse.

</details>


### [796] [HPC-Driven Modeling with ML-Based Surrogates for Magnon-Photon Dynamics in Hybrid Quantum Systems](https://arxiv.org/abs/2510.22221)
*Jialin Song,Yingheng Tang,Pu Ren,Shintaro Takayoshi,Saurabh Sawant,Yujie Zhu,Jia-Mian Hu,Andy Nonaka,Michael W. Mahoney,Benjamin Erichson,Zhi,Yao*

Main category: quant-ph

TL;DR: 提出了一种结合物理信息机器学习的GPU模拟框架，用于大规模模拟混合旋子-光子电路，解决了多尺度和多物理场耦合的挑战，加速了设计流程。


<details>
  <summary>Details</summary>
Motivation: 模拟混合旋子-光子系统具有挑战性，因为两个系统之间存在时间尺度上的巨大差异。

Method: 开发了一个大规模并行的、基于GPU的模拟框架，能够完全耦合地模拟片上旋子-光子电路，并采用了物理信息机器学习的代理模型来加速设计流程。

Result: 该方法能够高时空保真度地解析铁磁场和电磁场之间的动态相互作用，并重现了反交叉行为和强电磁场下铁磁共振的抑制等关键现象。

Conclusion: 该框架通过解决旋子-光子建模中的多尺度和多物理场挑战，能够实现可扩展的模拟和下一代量子及自旋电子器件的快速原型设计。

Abstract: Simulating hybrid magnonic quantum systems remains a challenge due to the
large disparity between the timescales of the two systems. We present a
massively parallel GPU-based simulation framework that enables fully coupled,
large-scale modeling of on-chip magnon-photon circuits. Our approach resolves
the dynamic interaction between ferromagnetic and electromagnetic fields with
high spatiotemporal fidelity. To accelerate design workflows, we develop a
physics-informed machine learning surrogate trained on the simulation data,
reducing computational cost while maintaining accuracy. This combined approach
reveals real-time energy exchange dynamics and reproduces key phenomena such as
anti-crossing behavior and the suppression of ferromagnetic resonance under
strong electromagnetic fields. By addressing the multiscale and multiphysics
challenges in magnon-photon modeling, our framework enables scalable simulation
and rapid prototyping of next-generation quantum and spintronic devices.

</details>


### [797] [Autonomous Floquet Engineering of Bosonic Codes via Reinforcement Learning](https://arxiv.org/abs/2510.22227)
*Zheping Wu,Lingzhen Guo,Haobin Shi,Wei-Wei Zhang*

Main category: quant-ph

TL;DR: 利用强化学习辅助的Floquet工程方法实现高效、抗噪声的玻色子编码制备，为容错量子计算开辟新途径。


<details>
  <summary>Details</summary>
Motivation: 为了解决玻色子编码制备和稳定中的超高精度控制、纠缠叠加、退相干抑制和动态误差缓解等挑战。

Method: 提出一种利用机器学习优化Floquet驱动参数的强化学习辅助Floquet工程方法。

Result: 该方法将演化时间缩短了两个数量级以上，同时在高耗散和退相干噪声下仍能保持高保真度的状态生成。

Conclusion: 该方法证明了人工智能在量子控制中的潜力，为实现容错玻色子量子计算提供了一条可扩展且实验上可行的途径，并提出了机器学习与Floquet工程结合用于克服量子技术中退相干挑战的通用范式。

Abstract: Bosonic codes represent a promising route toward quantum error correction in
continuous-variable systems, with direct relevance to experimental platforms
such as circuit QED and optomechanics. However, their preparation and
stabilization remain highly challenging, requiring ultra-precise control of
nonlinear interactions to create entangled superpositions, suppress
decoherence, and mitigate dynamic errors. Here, we introduce a
reinforcement-learning-assisted Floquet engineering approach for the autonomous
preparation of bosonic codes that is general, efficient, and noise-resilient.
By leveraging machine learning to optimize Floquet driving parameters, our
method achieves over two orders of magnitude reduction in evolution
time-requiring only about one percent of that in conventional adiabatic
schemes-while maintaining high-fidelity state generation even under strong
dissipative and dephasing noise. This approach not only demonstrates the power
of artificial intelligence in quantum control but also establishes a scalable
and experimentally feasible route toward fault-tolerant bosonic quantum
computation. Beyond the specific application to bosonic code preparation, our
results suggest a general paradigm for integrating machine learning and Floquet
engineering to overcome decoherence challenges in next-generation quantum
technologies.

</details>


### [798] [Rigorous test of the Raleigh-Ritz method for Mexican hat type potentials](https://arxiv.org/abs/2510.22233)
*A. M. Rodriguez Zarate,T. Thiemann*

Main category: quant-ph

TL;DR: 量子模型少有且常依赖近似方法，本文提出一种新的量子模型，通过解析方法求解，给出其精确解，并与近似方法进行比较。


<details>
  <summary>Details</summary>
Motivation: 近似方法在量子模型中应用广泛，但缺乏精确解进行验证，限制了其可靠性。因此，需要开发新的可精确求解的量子模型来验证近似方法的有效性。

Method: 本文提出了一种基于墨西哥帽势的 and an harmonic potentials 的量子模型，并推导了其薛定谔方程的精确解。

Result: 通过解析方法，本文得到了墨西哥帽势量子模型的精确基态能量和波函数。

Conclusion: 墨西哥帽势量子模型可以作为希格斯场的一个粗略的量子力学玩具模型，其精确解的获得，为验证近似方法提供了一个新的基准。

Abstract: Interesting quantum integrable models are rare and one often has to resort to
approximation methods. One of these is the Raleigh Ritz method which under
certain circumstances allows to approximately compute the lowest energy
eigenstate (or ground state) of a given Hamiltonian whose pure point spectrum
is bounded from below. The quality of such approximations can then be tested
numerically or sometimes by abstract arguments.
  However, the numerical test is limited by computing power. In order to
perform a rigorous test, one would need to have at one's disposal 1. a
physically interesting model that is 2. solvable to sufficient extent in order
that 3. the exact ground state is known in closed form.
  In this contribution we show that certain anharmonic potentials of the
Mexican hat type belong to this class of models. The corresponding Schroedinger
type Hamiltonian can be considered as a crude quantum mechanical toy model
Hamiltonian for the Higgs field in the standard model of elementary particle
physics.

</details>


### [799] [Van Hove singularities in stabilizer entropy densities](https://arxiv.org/abs/2510.22253)
*Daniele Iannotti,Lorenzo Campos Venuti,Alioscia Hamma*

Main category: quant-ph

TL;DR: 研究了哈尔随机纯量子态下非稳定性的度量（即“魔法”）的概率分布，特别是稳定器Rényi熵。


<details>
  <summary>Details</summary>
Motivation: 探讨了非稳定性的度量在量子信息处理中的作用，以及其概率分布的特性。

Method: 分析了稳定器Rényi熵的概率密度函数（PDF），并与范霍夫奇点进行了类比。推导了当α=2时的PDF的精确表达式，并通过数值模拟进行验证。

Result: 对于单量子比特，稳定器纯度在临界值处呈现对数发散，该临界值对应于Bloch球上的一个鞍点。这种发散出现在|H⟩-magic态，表明这些态在希尔伯特空间中具有无限的非稳定性密度。对于维度d≥3，对数发散消失。对于单量子比特，线性稳定器熵与量子测量的部分不兼容性直接相关。

Conclusion: 研究了非稳定性的概率分布，发现了其与凝聚态物理中的范霍夫奇点类似的新奇特征，并揭示了其在量子测量不兼容性中的作用。

Abstract: The probability distribution of a measure of non-stabilizerness, also known
as magic, is investigated for Haar-random pure quantum states. Focusing on the
stabilizer R\'enyi entropies, the associated probability density functions
(PDFs) are found to display distinct non-analytic features analogous to Van
Hove singularities in condensed matter systems. For a single qubit, the
stabilizer purity exhibits a logarithmic divergence at a critical value
corresponding to a saddle point on the Bloch sphere. This divergence occurs at
the $|H\rangle$-magic states, which hence can be identified as states for which
the density of non-stabilizerness in the Hilbert space is infinite. An exact
expression for the PDF is derived for the case $\alpha = 2$, with analytical
predictions confirmed by numerical simulations. The logarithmic divergence
disappears for dimensions $d \ge 3$, in agreement with the behavior of ordinary
Van Hove singularities on flat manifolds. In addition, it is shown that, for
one qubit, the linear stabilizer entropy is directly related to the partial
incompatibility of quantum measurements, one of the defining properties of
quantum mechanics, at the basis of Stern-Gerlach experiments.

</details>


### [800] [Pauli Propagation: Simulating Quantum Spin Dynamics via Operator Complexity](https://arxiv.org/abs/2510.22311)
*Yuguo Shao,Song Cheng,Zhengwei Liu*

Main category: quant-ph

TL;DR: 提出了一种可扩展的 Pauli 传播方法，用于在海森堡绘景中直接演化局部可观测量，克服了传统方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 模拟相互作用自旋系统中实时的量子动力学是一个基本挑战，其中精确对角化受到指数级希尔伯特空间增长的限制，而张量网络方法则面临纠缠障碍。

Method: 提出了一种可扩展的 Pauli 传播方法，直接在海森堡绘景中演化局部可观测量。该方法理论上推导了由算子稳定化 Rényi 熵（OSE）控制的先验误差界限，明确地将截断精度与算子复杂度联系起来，并规定了合适的 Top-K 截断策略。对 1D 海森堡模型（Jz=0）进行了证明，非零 Pauli 系数数量随着 Trotter 步数的增加而二次增长，证明了海森堡演化算子的可压缩性。数值上，在 XXZ 海森堡链基准测试中验证了该框架，在自由区域（Jz=0）显示出小的 K 值即可获得高精度，在相互作用区域（Jz=0.5）与张量网络方法（例如 TDVP）相比具有竞争力。

Result: 在 XXZ 海森堡链基准测试中，该方法在自由区域（Jz=0）使用小的 K 值即可达到高精度，在相互作用区域（Jz=0.5）也表现出与张量网络方法（如 TDVP）相当的性能。

Conclusion: 该研究提出了一个以可观测量为中心的模拟器，其计算成本由算子复杂度而非纠缠决定，为研究量子多体系统中的非平衡动力学提供了一种实用的替代方案。

Abstract: Simulating real-time quantum dynamics in interacting spin systems is a
fundamental challenge, where exact diagonalization suffers from exponential
Hilbert-space growth and tensor-network methods face entanglement barriers. In
this work, we introduce a scalable Pauli propagation approach that evolves
local observables directly in the Heisenberg picture. Theoretically, we derive
a priori error bounds governed by the Operator Stabilizer R\'enyi entropy (OSE)
$\mathcal{S}^\alpha(O)$, which explicitly links the truncation accuracy to
operator complexity and prescribes a suitable Top-$K$ truncation strategy. For
the 1D Heisenberg model with $J_z = 0$, we prove the number of non-zero Pauli
coefficients scales quadratically in Trotter steps, establishing the
compressibility of Heisenberg-evolved operators. Numerically, we validate the
framework on XXZ Heisenberg chain benchmarks, showing high accuracy with small
$K$ in free regimes ($J_z = 0$) and competitive performance against
tensor-network methods (e.g., TDVP) in interacting cases ($J_z = 0.5$). These
results establish an observable-centric simulator whose cost is governed by
operator complexity rather than entanglement, offering a practical alternative
for studying non-equilibrium dynamics in quantum many-body systems.

</details>


### [801] [A simple electromagnetic model of the electron](https://arxiv.org/abs/2510.22384)
*Carlos A. M. dos Santos,Marc J. J. Fleury*

Main category: quant-ph

TL;DR: 该论文提出了一个环状电磁模型来模拟量子电动力学（QED）中的电子，该模型能够复现电子的电荷、自旋和磁矩等基本性质，并解释了异常磁矩修正。


<details>
  <summary>Details</summary>
Motivation: 需要一个能够描述电子基本性质的微观经典电磁模型，并解释量子电动力学中的现象。

Method: 提出一个满足麦克斯韦方程组的环状电磁波ansatz，并将其作为电子的微观模型。通过参数优化，使模型的输出与电子的已知性质（电荷、自旋、磁矩）相匹配，并考虑了异常磁矩修正。

Result: 模型成功复现了电子的电荷、自旋（ħ/2）和磁矩（μB(1 + α/2π)），并包含了Schwinger异常磁矩修正。计算得到的模型幅值、尺度、频率、相速度和静止能量均与QED理论和实验值相符，其中相速度为2c，静止能量约为0.8 m_e c^2。

Conclusion: 该研究提供了一个微观的经典电磁框架，能够有效地封装和解释量子电动力学中电子的性质。

Abstract: We present a toroidal electromagnetic ansatz that provides a realistic
microscopic model of the QED electron. The proposed toroidal electromagnetic
wave satisfies Maxwell's equations and reproduces fundamental properties of the
electron as described in quantum electrodynamics (QED). Within this framework,
the electron is modeled as a rotating electromagnetic wave confined to a
toroidal geometry. Parameter optimization yields quantitative agreement with
the electron charge e, spin $\hbar/2$, and magnetic moment $\mu_B(1 +
\alpha/2\pi)$, incorporating the Schwinger anomalous magnetic moment
correction. The model yields an amplitude on the order of the Schwinger scale
where electron-positron pair production occurs. The major radius corresponds to
the Compton wavelength scale, while the monochromatic frequency is consistent
with the de Broglie-Dirac frequency. The phase velocity is found to be $2c$,
and the computed rest energy approximates $0.8 m_e c^2$. This representation
provides a microscopic classical electromagnetic framework that encapsulates
the properties of the QED electron.

</details>


### [802] [Making the Virtual Real: Measurement-Powered Tunneling Engines](https://arxiv.org/abs/2510.22394)
*Rafael Sánchez,Alok Nath Singh,Andrew N. Jordan,Bibek Bhandari*

Main category: quant-ph

TL;DR: 通过量子隧穿和位置测量，可以构建利用未受限探测的虚拟占据态来发电和制冷的量子隧穿引擎。


<details>
  <summary>Details</summary>
Motivation: 探索量子隧穿和位置测量在能量转换和制冷方面的应用，特别是利用未受限探测的虚拟占据态作为资源。

Method: 利用量子隧穿中电子的位置测量迫使其能量超过势垒高度的效应，结合与探测器的能量交换，构建量子隧穿引擎。

Result: 展示了量子隧穿引擎可以在混合模式下同时制冷和发电，并实现了测量辅助的自主制冷和纯粹由热偏差驱动的“检查点”冷却。此外，还发现了测量驱动系统进入稳态暗态时的“噪声净化”效应。

Conclusion: 测量既是热力学资源，也是暗态生成器，在量子系统中扮演着重要的双重角色。

Abstract: Quantum tunneling allows electrons to be transferred between two regions
separated by an energetically forbidden barrier. Performing a position
measurement that finds a particle in the barrier forces the tunneling electrons
to transition from having a classically forbidden energy to an energy above the
barrier height. We exploit this effect to define quantum tunneling engines that
can use the unconditioned detection of virtually occupied states as a resource
for power generation and cooling. Leveraging energy exchange with the detector,
we show that the device can operate in a hybrid regime, enabling simultaneous
cooling and power generation. Furthermore, we demonstrate measurement-assisted
autonomous refrigeration and "checkpoint" cooling driven purely by a thermal
bias, without the need for an applied potential. We also find a
"purification-by-noise" effect when the measurement drives the system into a
stationary dark state. These results underscore the intriguing dual role of
measurement as a thermodynamic resource and a dark state generator.

</details>


### [803] [The Cost of Certainty: Shot Budgets in Quantum Program Testing](https://arxiv.org/abs/2510.22418)
*Andriy Miranskyy*

Main category: quant-ph

TL;DR: 该论文提出了一个统一的框架，用于确定验证量子程序所需的测量次数，并分析了不同测试方法的效率和成本。


<details>
  <summary>Details</summary>
Motivation: 随着量子计算的发展，对量子程序进行测试和验证变得紧迫但成本高昂，因为每次执行都会消耗稀缺的硬件资源，并且每次测量都需要仔细权衡。

Method: 提出一个统一的框架，用于推理验证量子程序所需的测量次数。分析了错误概率、保真度、迹距离和量子Chernoff界之间的关系，以建立基本的测量次数限制。将这些基础应用于三种代表性的测试方法：逆测试、交换测试和卡方测试。考虑了理想设备和噪声设备。还引入了一种程序级预算方法，将验证工作分配给多个子程序。

Result: 逆测试在测量方面最高效，交换测试需要大约两倍的测量次数，而卡方测试最容易实现，但通常需要更多的测量次数。在存在噪声的情况下，校准的基线可能会使测量次数的要求超出理论估计。在程序级别，将全局保真度目标分配给许多细粒度的函数会导致验证成本快速增长，而更粗粒度的分解或加权分配则更具实践性。

Conclusion: 该框架阐明了不同测试策略、噪声处理和程序分解之间的权衡。它为量子程序测试中的测量次数预算提供了实用的指导，帮助从业者在设计验证策略时平衡严格性与成本。

Abstract: As quantum computing advances toward early fault-tolerant machines, testing
and verification of quantum programs become urgent but costly, since each
execution consumes scarce hardware resources. Unlike in classical software
testing, every measurement must be carefully budgeted.
  This paper develops a unified framework for reasoning about how many
measurements are required to verify quantum programs. The goal is to connect
theoretical error bounds with concrete test strategies and to extend the
analysis from individual tests to full program-level verification.
  We analyze the relationship between error probability, fidelity, trace
distance, and the quantum Chernoff bound to establish fundamental shot count
limits. These foundations are applied to three representative testing methods:
the inverse test, the swap test, and the chi-square test. Both idealized and
noisy devices are considered. We also introduce a program-level budgeting
approach that allocates verification effort across multiple subroutines.
  The inverse test is the most measurement efficient, the swap test requires
about twice as many shots, and the chi-square test is easiest to implement but
often needs orders of magnitude more measurements. In the presence of noise,
calibrated baselines may increase measurement requirements beyond theoretical
estimates. At the program level, distributing a global fidelity target across
many fine-grained functions can cause verification costs to grow rapidly,
whereas coarser decompositions or weighted allocations remain more practical.
  The framework clarifies trade-offs among different testing strategies, noise
handling, and program decomposition. It provides practical guidance for
budgeting measurement shots in quantum program testing, helping practitioners
balance rigour against cost when designing verification strategies.

</details>


### [804] [Entanglement as a Strategic Resource in Adversarial Quantum Games](https://arxiv.org/abs/2510.22444)
*Sinan Bugu*

Main category: quant-ph

TL;DR: 本文提出了一种新的团队量子破坏博弈（QSG），其中一个经典团队和一个量子增强团队进行对抗。量子团队利用纠缠辅助协调，实现相关的破坏行动，从而在不可预测性和战略欺骗方面获得决定性优势。我们推导了多智能体交互的量子纳什均衡（QNE）条件，并通过计算模拟比较了经典和量子策略的效率，并考虑了真实量子硬件的噪声模型。结果表明，W态纠缠显著增强了防御协调和破坏效率，优于经典的策略和贝尔态协调方案，并且这种量子优势在现实的硬件噪声模型下仍然存在。


<details>
  <summary>Details</summary>
Motivation: 利用量子叠加、纠缠和测量来增强经典的策略决策模型，以应对竞争环境。

Method: 建立了一个正式的量子博弈论模型，并推导了多智能体交互的量子纳什均衡（QNE）条件。通过计算模拟直接比较了经典和量子策略在理想条件、标准量子噪声模型以及来自真实IBM量子硬件的噪声模型下的效率。具体比较了两个经典玩家（2C）与贝尔态（2Q）团队，以及三个经典玩家（3C）与W态（3Q）团队的效率。

Result: W态纠缠显著增强了防御协调和破坏效率，在所有考虑的条件下（包括现实硬件噪声）都持续优于标准的经典策略和贝尔态协调方案。

Conclusion: 量子破坏博弈（QSG）中的W态纠缠提供了显著的量子优势，这种优势在面对现实硬件噪声时仍然具有弹性。这一发现对量子增强的网络安全、对抗性人工智能和多智能体量子决策具有直接意义。

Abstract: Quantum game theory naturally extends classical strategic decision-making by
  leveraging quantum superposition, entanglement, and measurement-based pay
offs. This paper introduces a novel team-based Quantum Sabotage Game (QSG),
  where two competing teams, one classical and one quantum-enhanced, engage in
  adversarial strategies. Unlike classical models, quantum teams can capitalize
on
  entanglement-assisted coordination, enabling correlated sabotage actions that
  provide a decisive edge in unpredictability and strategic deception. We
establish
  a formal quantum game-theoretic model and derive the Quantum Nash Equilib
rium (QNE) conditions for multi-agent interactions. Our approach uses computa
tional simulations to directly compare classical and quantum strategic
efficiency
  under ideal conditions, standard quantum noise models, and noise profiles
  calibrated from real IBM Quantum hardware. Our analysis specifically com
pares teams of equivalent size: two-player classical (2C) versus Bell-state
(2Q)
  teams, and three-player classical (3C) versus W-state (3Q) teams. Our results
  indicate that W-state entanglement significantly enhances both defensive
coordi nation and sabotage effectiveness, consistently outperforming standard
classical
  strategies and Bell-state coordination schemes. This quantum advantage is
  shown to be resilient, persisting even when subjected to realistic hardware
noise
  models. These findings have direct implications for quantum-enhanced
cybersecu rity, adversarial artificial intelligence, and multi-agent quantum
decision-making,
  thereby paving the way for practical applications of quantum game theory in
  competitive environments

</details>


### [805] [Single-photon superradiance and subradiance in helical collectives of quantum emitters](https://arxiv.org/abs/2510.22468)
*Hamza Patwa,Philip Kurian*

Main category: quant-ph

TL;DR: 该论文导出了一个连续分布的量子发射器（TLSs）集体辐射衰减率和Lamb位移的新解析表达式，并将其与离散分布和不同维度（无限线、无限螺旋、圆柱体）的TLSs进行了比较。通过将解析解应用于蛋白质纤维中的量子发射器体系结构，估算了最大超辐射态、热平均集体衰减率和陷获态的百分比，结果与数值模型吻合良好，为设计利用量子光学效应的器件提供了理论基础。


<details>
  <summary>Details</summary>
Motivation: 研究了多量子发射器（TLSs）的集体辐射行为，特别是与单个发射器相比，集体衰减率（超辐射和亚辐射）和Lamb位移。目标是推导出新颖的解析表达式，并将其应用于实际的量子信息处理和生物材料。

Method: 推导了在无限线和无限螺旋上连续分布的TLSs与单光子相互作用的集体衰减率和Lamb位移的解析表达式。将这些解与圆柱体上TLSs的集体解进行比较，并分析了离散分布和不同相互作用范围（1/r^3, 1/r^2, 1/r）对结果的影响。最后，将无限螺旋的解析解应用于蛋白质纤维中的量子发射器体系结构，并与数值模型进行比较。

Result: 导出了无限线和无限螺旋上连续分布TLSs的集体衰减率和Lamb位移的解析表达式。发现离散向量和连续标量发射器在某些极限下存在差异。估算了蛋白质纤维中量子发射器体系结构的最大超辐射态、热平均集体衰减率和陷获态的百分比，发现与数值结果（特别是稀疏排列）吻合良好。

Conclusion: 该研究成功地弥合了不同的超辐射理论模型之间的差距，为工程设计利用量子光学效应（如超辐射纠错和亚辐射存储器）的器件提供了指导，并启发了利用生物材料固有的螺旋几何结构来创建用于量子信息处理的柔性平台。

Abstract: Collective emission of light from distributions of two-level systems (TLSs)
was first predicted in 1954 by Robert Dicke, who showed that when $N$ quantum
emitters absorb photons, their collective radiative decay rate can be enhanced
(superradiance) or suppressed (subradiance) relative to a single emitter. In
this work, we derive novel analytical expressions for the collective decay
rates and Lamb shifts for the interaction of a single photon with a continuous
distribution of TLSs on an infinite line and an infinite helix. We compare
these solutions to collectives of TLSs on a cylinder, finding limits in which
the eigenvalues of structures of different dimensions are equal. We also
compare our solution with arrangements where the emitter distribution is
discrete rather than continuous, and when short- ($1/r^3$), intermediate-
($1/r^2$), and long-range ($1/r$) interaction terms are included. We find
important differences between the discrete vector and continuous scalar emitter
cases, which do not agree in the limit where discrete spacing goes to 0. The
analytical solution for the helix is then used to make estimates of the
maximally superradiant state, thermally averaged collective decay rate, and
percentage of trapped states of quantum emitter architectures in protein
fibers. Given the differences between our idealized infinite helix and the
numerical model describing protein fibers, our analytical estimates show
excellent agreement with the numerical results for sparse arrangements of
emitters in protein fibers. Our work thus bridges the gap between different
formalisms for superradiance, aids the engineering of devices which harness
quantum optical effects for computing with superradiant error correction and
subradiant memories, and motivates the discovery and creation of flexible
platforms for quantum information processing using the intrinsic helical
geometries of biomatter.

</details>


### [806] [An Analytic Theory of Quantum Imaginary Time Evolution](https://arxiv.org/abs/2510.22481)
*Min Chen,Bingzhi Zhang,Quntao Zhuang,Junyu Liu*

Main category: quant-ph

TL;DR: QITE算法可被视为一种量子自然梯度下降（QNGD）算法，收敛速度快于梯度下降（GD）算法。


<details>
  <summary>Details</summary>
Motivation: 为量子虚时演化（QITE）算法提供第一性原理的理论理解。

Method: 将QITE解释为量子自然梯度下降（QNGD）算法，并利用量子神经网络（QNN）和量子神经网络（QTKC）框架构建QITE的解析模型。

Result: 证明QITE比基于GD的VQA收敛更快，尽管这种优势会受到希尔伯特空间维度指数增长的抑制。该理论对线性、二次和更一般的损失函数都适用，并通过数值模拟进行了验证。

Conclusion: 为QITE动力学奠定了理论基础，并为变分量子算法（VQA）的从第一性原理设计提供了分析见解。

Abstract: Quantum imaginary time evolution (QITE) algorithm is one of the most
promising variational quantum algorithms (VQAs), bridging the current era of
Noisy Intermediate-Scale Quantum devices and the future of fully fault-tolerant
quantum computing. Although practical demonstrations of QITE and its potential
advantages over the general VQA trained with vanilla gradient descent (GD) in
certain tasks have been reported, a first-principle, theoretical understanding
of QITE remains limited. Here, we aim to develop an analytic theory for the
dynamics of QITE. First, we show that QITE can be interpreted as a form of a
general VQA trained with Quantum Natural Gradient Descent (QNGD), where the
inverse quantum Fisher information matrix serves as the learning-rate tensor.
This equivalence is established not only at the level of gradient update rules,
but also through the action principle: the variational principle can be
directly connected to the geometric geodesic distance in the quantum Fisher
information metric, up to an integration constant. Second, for wide quantum
neural networks, we employ the quantum neural tangent kernel framework to
construct an analytic model for QITE. We prove that QITE always converges
faster than GD-based VQA, though this advantage is suppressed by the
exponential growth of Hilbert space dimension. This helps explain certain
experimental results in quantum computational chemistry. Our theory encompasses
linear, quadratic, and more general loss functions. We validate the analytic
results through numerical simulations. Our findings establish a theoretical
foundation for QITE dynamics and provide analytic insights for the
first-principle design of variational quantum algorithms.

</details>


### [807] [Experimental Proposal on Scalable Radio-Frequency Magnetometer with Trapped Ions](https://arxiv.org/abs/2510.22516)
*Yuxiang Huang,Wei Wu,Qingyuan Mei,Yiheng Lin*

Main category: quant-ph

TL;DR: 利用混合动力退耦方法，结合缀饰态和周期序列，可实现可扩展的离子阱磁力计，并达到 13 fT/$\sqrt{\rm{Hz}}$ 的灵敏度。


<details>
  <summary>Details</summary>
Motivation: 量子磁力测量是量子计量学的基本组成部分，而离子阱系统在单离子射频磁场测量中已达到 pT/$\\sqrt{\\rm{Hz}}$ 的灵敏度。本研究提出了一种可扩展的离子阱磁力计。

Method: 提出了一种利用混合动力退耦方法的可扩展离子阱磁力计，结合缀饰态和周期序列来抑制退相干和空间磁场不均匀性。

Result: 通过对具有实际实验参数的 $10^4$ 离子系统进行数值模拟，证明了射频磁场可达到 13 fT/$\\sqrt{\\rm{Hz}}$ 的灵敏度，这得益于对磁场漂移噪声和不均匀性的稳健抵抗能力，相干时间平均可延长至几分钟。

Conclusion: 该方法实现了可扩展的离子阱磁力测量，展示了其作为先进量子传感应用的稳健且实用的解决方案的潜力。

Abstract: Quantum magnetometry represents a fundamental component of quantum metrology,
where trapped-ion systems have achieved $\rm{pT}/\sqrt{\rm{Hz}}$ sensitivity in
single-ion radio-frequency magnetic field measurements via dressed states based
dynamical decoupling. Here we propose a scalable trapped-ion magnetometer
utilizing the mixed dynamical decoupling method, combining dressed states with
periodic sequences to suppress decoherence and spatial magnetic field
inhomogeneity. With numerical simulations for a $10^4$ ion system with
realistic experimental parameters, we demonstrate that a sensitivity of 13
$\rm{fT}/\sqrt{\rm{Hz}}$ for the radio-frequency field could be reached. Such a
sensitivity could be obtained via robust resilience to magnetic field drift
noise and inhomogeneity, where coherence time could be extended to the order of
several minutes on average. This method enables scalable trapped-ion
magnetometry, demonstrating its potential as a robust and practical solution
for advancing quantum sensing applications.

</details>


### [808] [Krylov Complexity and Mixed-State Phase Transition](https://arxiv.org/abs/2510.22542)
*Hung-Hsuan Teh,Takahiro Orito*

Main category: quant-ph

TL;DR: 该研究将退相干与量子复杂性联系起来，提出一个统一框架，将退相干过程映射为虚时演化，并发现 Krylov 复杂性与错误传播和复杂性增长相关。


<details>
  <summary>Details</summary>
Motivation: 建立连接退相干与量子复杂性的统一框架。

Method: 将密度矩阵向量化为双希尔伯特空间中的纯态，将退相干过程映射为虚时演化，并在 Krylov 空间中展开该演化。

Result: Krylov 复杂性在强到弱自发对称破缺（SWSSB）的交叉中保持非奇异，但在真实的 SWSSB 相变中表现出奇异的面积-体积律转变。

Conclusion: Krylov 复杂性可以作为区分混合态中真实 SWSSB 相变和交叉的指标。

Abstract: We establish a unified framework connecting decoherence and quantum
complexity. By vectorizing the density matrix into a pure state in a double
Hilbert space, a decoherence process is mapped to an imaginary-time evolution.
Expanding this evolution in the Krylov space, we find that the $n$-th Krylov
basis corresponds to an $n$-error state generated by the decoherence, providing
a natural bridge between error proliferation and complexity growth. Using two
dephasing quantum channels as concrete examples, we show that the Krylov
complexity remains nonsingular for strong-to-weak spontaneous symmetry-breaking
(SWSSB) crossovers, while it exhibits a singular area-to-volume-law transition
for genuine SWSSB phase transitions, intrinsic to mixed states.

</details>


### [809] [Open harmonic chain without secular approximation](https://arxiv.org/abs/2510.22595)
*Melika Babakan,Fabio Benatti,Laleh Memarzadeh*

Main category: quant-ph

TL;DR: 该研究通过比较精确动力学和两种马尔可夫近似（局部和全局）来分析开放量子系统中三谐振子链的粒子和能量传输，重点关注近似方法如何影响能量传输的描述。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于理解开放量子系统（特别是谐振子链）的粒子和能量传输，并评估局部和全局马尔可夫近似与精确动力学在描述这些现象时的差异，特别是能量传输的连续性方程。

Method: 研究考虑了由两端连接不同温度热库的三谐振子链组成的开放量子系统的精确动力学，并分析了其局部和全局马尔可夫近似。通过比较不同近似方法得到的连续性方程，特别是能量流的表达形式，来揭示其差异。此外，还研究了通过时间-粗粒化方法得到的非马尔可夫主方程，并分析了旋转波近似（RWA）的影响，以及通过时间缩放参数$	au$来调整近似。

Result: 研究发现，精确动力学、局部近似和全局近似都得出了概率流的连续性方程。然而，在能量流方面，精确动力学和局部近似保留了标准的散度形式，而全局近似由于采用了旋转波近似（RWA），引入了非散度的源/汇项。即使在避免RWA的时间-粗粒化方法中，这些源/汇项也始终存在。但当时间缩放参数$	au 	o 0$时，这些项消失，恢复了精确动力学的散度结构，而在$	au 	o 	o 	au$的极限下，则恢复了全局近似的动力学。

Conclusion: 研究结果强调，选择哪种马尔可夫近似方法来描述开放系统的动力学，对于能量传输的描述至关重要。这关系到如何区分这些近似方法的有效性，并最终正确地模拟开放量子多体系统的时变过程。

Abstract: We study particle and energy transport in an open quantum system consisting
of a three harmonic oscillator chain coupled to thermal baths at different
temperatures placed at the ends of the chain. We consider the exact dynamics of
the open chain and its so-called local and global Markovian approximations. By
comparing them, we show that, while all three yield a divergence-like
continuity equation for the probability flow, the energy flow exhibits instead
a distinct behavior. The exact dynamics and the local one preserve a standard
divergence form for the energy transport, whereas the global open dynamics, due
to the rotating wave approximation (RWA), introduces non-divergence sink/source
terms. These terms also affect the continuity equation in the case of a master
equation obtained through a time-coarse-graining method whereby RWA is avoided
through a time-zoom parameter $\Delta t$. In such a scenario, sink and source
contributions are always present for each $\Delta t>0$. While in the limit
$\Delta t\to+\infty$ one recovers the global dissipative dynamics, sink and
source terms instead vanish when $\Delta t\to 0$, restoring the divergence
structure of the exact dynamics. Our results underscore how the choice of the
dissipative Markovian approximation to an open system dynamics critically
influences the energy transport descriptions, with implications for
discriminating among them and thus, ultimately, for the correct modeling of the
time-evolution of open quantum many-body systems.

</details>


### [810] [Enabling Shortwave-QKD in Short-Reach Networks: Impact of a Composite ODN Native to Telecom Applications](https://arxiv.org/abs/2510.22617)
*Mariana F. Ramos,Costin Luchian,Michael Hentschel,Florian Honz,Marie-Christine Slater,Hannes Hübel,Bernhard Schrenk*

Main category: quant-ph

TL;DR: Shortwave-QKD in datacom architectures is impacted by few-mode propagation and speckle-selective loss, but 12 kb/s secure key generation is achieved with 50 co-existing data channels.


<details>
  <summary>Details</summary>
Motivation: To investigate the performance of shortwave-QKD in short-reach in-house/datacom architectures and identify the factors affecting it.

Method: Deploying shortwave-QKD in datacom architectures and observing its performance under the influence of few-mode propagation and speckle-selective loss.

Result: Achieved 12 kb/s secure key generation in the presence of 50 co-existing data channels, despite the negative impacts of few-mode propagation and speckle-selective loss.

Conclusion: Few-mode propagation and speckle-selective loss significantly affect QKD performance in short-reach datacom architectures, necessitating further research for optimization.

Abstract: We deploy shortwave-QKD over short-reach in-house/datacom architectures and
show that few-mode propagation and speckle-selective loss severely impact the
QKD performance. We accomplish 12 kb/s secure-key generation in presence of 50
co-existing data channels.

</details>


### [811] [Generation and Detection of Hyperentangled Bell States at an Ultra-High Flux](https://arxiv.org/abs/2510.22677)
*Netanel P. Yaish,Samata Gokhale,Avi Peer*

Main category: quant-ph

TL;DR: 利用超高通量超纠缠双光子，在量子信息技术中实现比标准方法快5个数量级的极化贝尔态生成和检测。


<details>
  <summary>Details</summary>
Motivation: 实现高速率的极化贝尔态生成、处理和检测，以克服现有量子技术中光电探测器的速度瓶颈。

Method: 使用广义双偏振SU1,1干涉仪生成、操控和测量三态贝尔态。

Result: 成功生成和探测了超高通量的极化贝尔态，速率达到约5x10^11 光子/秒，比标准方法快了5个数量级以上。

Conclusion: 该方法有效解决了量子技术中的探测瓶颈，显著提高了量子处理速度。

Abstract: We demonstrate both the generation and detection of an ultra-high flux of
polarization Bell states using broadband hyper-entangled bi-photons that are
quantum-correlated in both polarization and time-energy. Bell states of
polarization embody the most basic form of two-state entanglement, and are a
key component of quantum protocols of communication and sensing. High-speed
generation, processing and detection of polarization Bell-states is therefore
critical for quantum technology. However, all current protocols that employ
polarization entangled photons are inherently slow, primarily due to the
photo-detectors (Photomultiplier tubes, avalanche photo-diodes, etc.) that can
handle only $10^{6-7}$ photons/s, whereas sources may easily produce
$10^{10-13}$ photons/s or more (if properly designed). We fully alleviate this
detection bottleneck by resorting to physical detection of the bi-photons with
nonlinear interferometry. We harness a generalized, dual polarization SU1,1
interferometer to generate, manipulate \textit{and measure} all the triplet
Bell-states at a flux of $\sim\!5\times10^{11}$ photons/s, enhancing the speed
of quantum processing by >5 orders of magnitude compared to standard methods.

</details>


### [812] [Scalable Neural Decoders for Practical Real-Time Quantum Error Correction](https://arxiv.org/abs/2510.22724)
*Changwon Lee,Tak Hur,Daniel K. Park*

Main category: quant-ph

TL;DR: Mamba解码器在量子纠错中实现了与Transformer相当的准确性，但具有更高的效率和更好的实时性能。


<details>
  <summary>Details</summary>
Motivation: 提高量子计算机实时、可扩展和准确解码的速度，以满足实际应用需求。

Method: 提出并评估了一种基于Mamba（一种状态空间模型）的解码器，其计算复杂度为O(d^2)，并与基于Transformer的解码器进行了比较。

Result: 在实际硬件数据实验中，Mamba解码器达到了与Transformer相当的性能。在模拟的实时场景中，Mamba解码器的性能明显优于Transformer，错误阈值更高（0.0104 vs 0.0097）。

Conclusion: Mamba解码器在速度和准确性之间取得了引人注目的平衡，为可扩展的实时量子纠错提供了一种有前途的架构。

Abstract: Real-time, scalable, and accurate decoding is a critical component for
realizing a fault-tolerant quantum computer. While Transformer-based neural
decoders such as \textit{AlphaQubit} have demonstrated high accuracy, the
computational complexity of their core attention mechanism, which scales as
$\mathcal{O}(d^4)$ with code distance $d$, results in decoding speeds
insufficient for practical real-time applications. In this work, we introduce
and evaluate a \textit{Mamba}-based decoder, a state-space model with
$\mathcal{O}(d^2)$ complexity. In memory experiments using Sycamore hardware
data, our Mamba decoder matches the performance of its Transformer-based
counterpart, providing that its superior efficiency does not come at the cost
of performance. Crucially, in simulated real-time scenarios that account for
decoder-induced noise, the Mamba decoder significantly outperforms the
Transformer, exhibiting a higher error threshold of $0.0104$ compared to
$0.0097$. These results demonstrate that Mamba decoders offer a compelling
balance between speed and accuracy, making them a promising architecture for
scalable, real-time quantum error correction.

</details>


### [813] [Reducing Ion Heating in Quantum Computing: A Novel 3D-Printed Micro Ion Trap with Skeleton Structure](https://arxiv.org/abs/2510.22725)
*Chon-Teng Belmiro Chu,Hao-Chung Chen,Ting Hsu,Hsiang-Yu Lo,Ming-Shien Chang,Guin-Dar Lin*

Main category: quant-ph

TL;DR: 3D打印的骨架式离子阱可将离子加热率降低50%以上，通过优化电极几何结构可进一步抑制加热。


<details>
  <summary>Details</summary>
Motivation: 为了克服可扩展离子阱量子计算中由电场引起的离子加热问题，需要设计新型离子阱。

Method: 本文研究了一种新型3D打印的骨架式离子阱，该离子阱通过最小化离子附近的表面积来减少加热。通过逐个区域分析加热效应，并对电极几何结构进行微小优化，以减小加热率。

Result: 与传统的叶片式离子阱相比，骨架式离子阱的加热率降低了50%以上。加热主要由距离离子500微米以内的表面引起。轴向运动的加热峰值出现在距离离子约110微米处。通过优化电极几何结构，可以在增加表面积的同时进一步降低加热。

Conclusion: 3D打印的骨架式离子阱设计在实现强约束和降低噪声方面具有巨大潜力，可用于未来的量子系统。

Abstract: Electric-field-induced ion heating is a major obstacle in scalable
trapped-ion quantum computing. We present a theoretical study of a novel
3D-printed ion trap with a skeleton electrode structure, designed to reduce
heating by minimizing surface area near the ion. Compared to a conventional
blade trap with identical confinement parameters, the skeleton trap achieves
over 50% reduction in total heating rate. Patch-by-patch analysis reveals that
heating is dominated by surfaces within 500 {\mu}m of the ion. For axial
motion, the peak heating occurs approximately 110 {\mu}m away due to electric
field directionality. We demonstrate that minor geometric optimization, in
which the electrode gaps are realigned with these hotspots, can further
suppress heating despite the associated increase in surface area. A linear
relationship between ion-to-electrode distance and peak heating location is
also established. These results highlight the potential of 3D-printed electrode
designs for achieving both strong confinement and reduced noise in future
quantum systems.

</details>


### [814] [Qlustering: Harnessing Network-Based Quantum Transport for Data Clustering](https://arxiv.org/abs/2510.22727)
*Shmuel Lorber,Yonatan Dubi*

Main category: quant-ph

TL;DR: Qlustering 是一种量子受启发的无监督学习算法，它利用基于网络的量子输运进行数据聚类，并在各种数据集上表现出与经典方法相当或更优的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的基于距离的聚类方法在处理非凸或高维数据时存在局限性。本研究旨在探索一种新的聚类方法，该方法利用量子动力学作为计算资源，以克服这些限制。

Method: Qlustering 算法将数据编码为紧束缚哈密顿量框架中的输入态，并通过林德布拉德主方程进行演化。算法利用量子粒子在网络中传播的稳态动力学作为计算资源，通过优化哈密顿量和随机更新来实现聚类。

Result: 在合成数据集、定位问题以及 QM9 分子数据库和 Iris 数据集的化学和生物学数据上，Qlustering 算法都取得了具有竞争性或优于经典方法的性能，特别是在处理非凸或高维数据时。

Conclusion: Qlustering 算法是一种有前景的、可物理实现的、原生量子聚类架构，具有鲁棒性、低计算复杂度和与光子实现的兼容性。

Abstract: We introduce Qlustering, a quantum-inspired algorithm for unsupervised
learning that leverages network-based quantum transport to perform data
clustering. In contrast to traditional distance-based methods, Qlustering
treats the steady-state dynamics of quantum particles propagating through a
network as a computational resource. Data are encoded as input states in a
tight-binding Hamiltonian framework governed by the Lindblad master equation,
and cluster assignments emerge from steady-state output currents at terminal
nodes. The algorithm iteratively optimizes the network's Hamiltonian to
minimize a physically motivated cost function, achieving convergence through
stochastic updates. We benchmark Qlustering on synthetic datasets, a
localization problem, and real-world chemical and biological data, namely
subsets of the QM9 molecular database and the Iris dataset. Across these
diverse tasks, Qlustering demonstrates competitive or superior performance
compared with classical methods such as k-means, particularly for non-convex or
high-dimensional data. Its intrinsic robustness, low computational complexity,
and compatibility with photonic implementations suggest a promising route
toward physically realizable, quantum-native clustering architectures.

</details>


### [815] [Dirac Equation and Representation Dependent Scattering Phenomena](https://arxiv.org/abs/2510.22872)
*Muhammad Adeel Ajaib*

Main category: quant-ph

TL;DR: 在标量势的相对论区域中，会出现标准狄拉克表示中不存在的自旋翻转概率。通过分析作者早期研究中引入的矩阵表示的狄拉克方程的一维散射，可以得出此结论。


<details>
  <summary>Details</summary>
Motivation: 研究标量势的相对论区域中出现的自旋翻转概率，并探讨其与狄拉克方程表示的关系。

Method: 研究具有狄拉克方程矩阵表示的一维散射，分析其传播和反射系数。

Result: 传播和反射系数可能依赖于克利福德代数的表示，即使这些表示可以通过单一变换相关联。这种依赖性表明，在旋量分量如何耦合到外部阶跃/势垒方面存在隐藏的物理效应，即使相对论色散关系相同。

Conclusion: 自旋翻转概率在标量势的相对论区域中出现，并且可能依赖于狄拉克方程的表示，这表明旋量分量与外部势垒的耦合中存在隐藏的物理效应。

Abstract: We show that spin-flip probabilities emerge in the relativistic regime for
scalar potentials, absent in the standard Dirac representation. We examine 1D
scattering for the Dirac equation with the matrix representation introduced by
the Author in an earlier study. The dispersion relation described by the
equation is that of a relativistic particle. We demonstrate that the
transmission T and reflection R coefficients can depend on the chosen
representation of the Clifford algebra despite the two representations being
related by a unitary transformation. This representation dependence hints at
hidden physics in how spinor components couple to external steps/barriers, even
when the relativistic dispersion relation E^2=p^2+m^2 is the same.

</details>


### [816] [Control of Valence Electron Motion in Xe Cation Using Stimulated Raman Adiabatic Passage Technique](https://arxiv.org/abs/2510.22875)
*Miguel Alarcón,Karl Hauser,Nikolay V. Golubev*

Main category: quant-ph

TL;DR: 本研究提出了一种改进的分数STIRAP（f-STIRAP）技术，用于精确控制量子态叠加的混合比例，并将其应用于氙阳离子的超快电荷迁移控制。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索利用STIRAP及其变体来控制量子态相干叠加的可能性，并提出一种新的f-STIRAP方案，用于精确控制已存在的叠加态的组分。

Method: 研究提出了一种广义f-STIRAP方案，可以任意控制已存在的叠加态的组分。研究还探索了使用简单高斯脉冲代替解析设计的激光脉冲的近似方案，以及利用两个具有相同高斯包络、可调延迟和相对相位的脉冲的极限情况。该技术被应用于控制氙阳离子的超快电荷迁移。

Result: 研究表明，近似方案在控制波包动力学方面取得了与精确方案相当的性能。极限情况揭示了操控量子相干的实验可行途径。研究还提出了具体的实验实现方案，并结合阿秒瞬态吸收光谱进行探测。

Conclusion: 本研究提出的广义f-STIRAP技术及其近似和极限方案，为精确控制量子态叠加提供了新的途径，并成功应用于氙阳离子的超快电荷迁移控制，为相关实验研究奠定了基础。

Abstract: This work theoretically investigates possibilities of using the Stimulated
Raman Adiabatic Passage (STIRAP) and its variants to control a coherent
superposition of quantum states. We present a generalization of the so-called
fractional STIRAP (f-STIRAP), demonstrating precise control over the mixing
ratio of quantum states in the wave packet. In contrast to conventional
f-STIRAP, designed to drive a system from an eigenstate into a coherent
superposition, our scheme enables arbitrary control over the composition of an
already existing superposition state. We demonstrate that an approximate
version of this technique -- where analytically designed laser pulses with
composite envelopes are replaced by simple Gaussian pulses -- achieves
comparable performance in controlling the dynamics of the wave packet. A
limiting case of this scheme, utilizing two pulses with identical Gaussians
envelopes and tuned delay and relative phase, is also explored, revealing
experimentally accessible pathways for manipulating quantum coherence. We apply
our developed techniques to control the ultrafast charge migration in the
spin-orbit split ground electronic states of xenon cation via intermediate
valence- and core-excited states. Finally, we propose concrete experimental
realizations of the developed control schemes in combination with attosecond
transient absorption spectroscopy as a method to probe the system.

</details>


### [817] [Reducing measurements in quantum erasure correction by quantum local recovery](https://arxiv.org/abs/2510.22890)
*Ryutaroh Matsumoto*

Main category: quant-ph

TL;DR: 该论文研究了量子纠错中的测量最小化问题，提出了一种形式化方法来识别纠错所需的最小相关稳定因子数量，并将其应用于广义表面码。


<details>
  <summary>Details</summary>
Motivation: 量子计算设备上的测量成本高且易出错，因此需要尽量减少量子纠错中的测量次数和测量量子比特数。

Method: 利用量子局部恢复的近期思想，形式化了纠正量子稳定码中擦除量子比特所需的最小相关稳定因子。

Result: 确定了所需的最小测量稳定因子数量，该数量与经典线性码的维度长度剖面相似。作为应用，证明了广义表面码中的δ擦除纠正最多需要δ次顶点测量和δ次面测量，且与码参数无关。

Conclusion: 该研究为量子纠错中的测量优化提供了理论基础，并对广义表面码的纠错能力进行了量化分析。

Abstract: As measurements are costly and prone to errors on certain quantum computing
devices, we should reduce the number of measurements and the number of measured
qudits as small as possible in quantum erasure correction. It is intuitively
obvious that a decoder can omit measurements of stabilizers that are irrelevant
to erased qudits, but this intuition has not been rigorously formalized as far
as the author is aware. In this paper, we formalize relevant stabilizers
sufficient to correct erased qudits with a quantum stabilizer code, by using a
recent idea from quantum local recovery. The minimum required number of
measuring stabilizer observables is also clarified, which looks similar to the
dimension length profile of classical linear codes. As an application, we also
show that correction of $\delta$ erasures on a generalized surface code
proposed by Delfosse, Iyer and Poulin requires at most $\delta$ measurements of
vertexes and at most $\delta$ measurements of faces, independently of its code
parameters.

</details>


### [818] [Ultra-high-rate detection of entangled photon pairs](https://arxiv.org/abs/2510.22894)
*Toshimori Honjo,Shigeyuki Miyajima,Shigehito Miki,Hirotaka Terai,Hsin-Pin Lo,Takuya Ikuta,Yuya Yonezu,Hiroki Takesue*

Main category: quant-ph

TL;DR: 本研究使用16像素超导纳米线单光子探测器（SNSPDs）解决了单光子探测器死时间限制高计数率的问题，实现了超过3 Mcps的符合计数率，为高速纠缠光子量子信息处理铺平了道路。


<details>
  <summary>Details</summary>
Motivation: 为了提高光子量子信息处理的速率，需要高计数率的纠缠光子探测，但现有技术受限于探测器死时间。

Method: 采用16像素超导纳米线单光子探测器（SNSPDs）来减轻探测器死时间的影响，并结合5-GHz时钟的序列时间纠缠光子对源。

Result: 在双光子干涉和CHSH不等式实验中，实现了超过300万次/秒（Mcps）的符合计数率。

Conclusion: 首次实现了纠缠光子的多兆赫兹符合计数率探测，为高速纠缠光子量子信息处理提供了新的可能性。

Abstract: The high-rate detection of entangled photons is essential for advancing
photonic quantum information processing. Although several experimental
demonstrations have been reported, the achievable coincidence rates have so far
remained limited. One of the main bottlenecks arises from the dead time of
single-photon detectors, which constrains coincidence detection at high
photon-pair generation rates. In this work, we employ 16-pixel superconducting
nanowire single-photon detectors (SNSPDs) to mitigate the impact of detector
dead time. Consequently, we achieve coincidence rates exceeding 3 million
counts per second (Mcps) in two-photon interference and CHSH inequality
experiments using 5-GHz clocked sequential time-bin entangled photon pair
source. To the best of our knowledge, this is the first demonstration of
multi-Mcps coincidence detection of entangled photons, paving the way for
high-speed entangled-photon-based quantum information processing.

</details>


### [819] [Giant-Atom Quantum Batteries](https://arxiv.org/abs/2510.22905)
*Ke-Xiong Yan,Yang Liu,Yang Xiao,Jun-Hao Lin,Jie Song,Ye-Hong Chen,Franco Nori,Yan Xia*

Main category: quant-ph

TL;DR: 通过利用巨型原子（GAs）的非局域耦合特性，提出了一种免疫退相干的量子电池（QB）充电协议，有效抑制了由波导介导的耗散引起的退化效应，并提出了一种可逆的远距离手征充电方案。


<details>
  <summary>Details</summary>
Motivation: 环境退相干对量子电池（QB）的能量存储和性能寿命构成了根本性挑战，会导致能量耗散和老化。

Method: 提出了一种利用巨型原子（GAs）的非局域耦合特性来实现 QB 和充电器的方案。通过在共享微波波导中采用编织配置（耦合路径空间交错）来设计 GAs，以实现退相干免疫的相互作用动力学。

Result: 编织配置能够通过破坏性干涉抑制退相干通道，同时保持充电器和 QB 之间的相干能量转移。与分离和嵌套配置相比，编织配置表现出更优越的性能。此外，还提出了一种手征充电方案，可以实现能量的单向传输，并通过调节磁通量来反转能量流方向。

Conclusion: 该研究为在 GA 工程电路中实现抗退相干充电协议和远距离手征量子电池提供了指导。

Abstract: Environmentally induced decoherence poses a fundamental challenge to quantum
energy storage systems, causing irreversible energy dissipation and performance
aging of quantum batteries (QBs). To address this issue, we propose a QB
protocol utilizing the nonlocal coupling properties of giant atoms (GAs). In
this architecture, both the QB and its charger are implemented as
superconducting GAs with multiple nonlocal coupling points to a shared
microwave waveguide. By engineering these atoms in a braided configuration,
where their coupling paths are spatially interleaved, we show the emergence of
decoherence-immune interaction dynamics. This unique geometry enables
destructive interference between decoherence channels while preserving coherent
energy transfer between the charger and the QB, thereby effectively suppressing
the aging effects induced by waveguide-mediated dissipation. The charging
properties of separated and nested coupled configurations are investigated. The
results show that these two configurations underperform the braided
configuration. Additionally, we propose a long-range chiral charging scheme
that facilitates unidirectional energy transfer between the charger and the
battery, with the capability to reverse the flow direction by modulating the
applied magnetic flux. Our result provides guidelines for implementing a
decoherence-resistant charging protocol and remote chiral QBs in circuits with
GAs engineering.

</details>


### [820] [Experimental Multipartite Entanglement Detection With Minimal-Size Correlations](https://arxiv.org/abs/2510.22918)
*Dian Wu,Fei Shi,Jia-Cheng Sun,Bo-Wen Wang,Xue-Mei Gu,Giulio Chiribella,Qi Zhao,Jian Wu*

Main category: quant-ph

TL;DR: 本研究首次实验演示了利用最小尺寸关联来检测多方量子纠缠，该方法能够认证在直接方法失效的条件下，真正有多方量子纠缠的存在。


<details>
  <summary>Details</summary>
Motivation: 多粒子纠缠是量子技术（包括测量基量子计算、量子密钥共享和量子传感）的重要资源。直接检测方法（同时对所有粒子进行局部测量）在大规模纠缠态中变得不可行，因此需要开发能最小化同时测量粒子数量的检测方法。

Method: 首次实验演示了利用最小尺寸关联来检测多方量子纠缠，并展示了该方法对局部测量基准不一致的鲁棒性。

Result: 所提出的方法能够认证真正有多方量子纠缠的存在，并且在直接方法失效的条件下依然有效。

Conclusion: 本研究结果为在大规模纠缠态中进行真正多方量子纠缠的实验检测提供了一条有前景的途径。

Abstract: Multiparticle entanglement is a valuable resource for quantum technologies,
including measurement based quantum computing, quantum secret sharing, and a
variety of quantum sensing applications. The direct way to detect this resource
is to observe correlations arising from local measurements performed
simultaneously on all particles. However, this approach is increasingly
vulnerable to measurement imperfections when the number of particles grows, and
becomes unfeasible for large-scale entangled states. It is therefore crucial to
devise detection methods that minimize the number of simultaneously measured
particles. Here we provide the first experimental demonstration of multipartite
entanglement detection with minimal-size correlations, showing that our setup
is robust to misalignment of the local measurement bases and enables the
certification of genuine multipartite entanglement in a regime where the direct
approach fails. Overall, our results indicate a promising route to the
experimental detection of genuine multipartite entanglement in large-scale
entangled states.

</details>


### [821] [Finite temperature Casimir effect in one-dimensional scalar field with double delta-function potentials](https://arxiv.org/abs/2510.22996)
*Liang Chen,Xu-Feng Zhao,Shao-Zhe Lu*

Main category: quant-ph

TL;DR: 在有限温度下，我们使用规范量化方法研究了(1+1)维标量场与一对δ函数势相互作用产生的卡西米尔效应，并与Lifshitz理论进行了比较。在零温度下，两种方法得到相同结果。在有限温度下，当距离很长时，卡西米尔力衰减为F_C(a,T)=-T/(4a)，Lifshitz理论得到的大小是规范量化方法的两倍。规范量化方法得到的熵是正的并且随温度升高而增加，这表明该方法在描述热卡西米尔效应时具有热力学上的一致性。


<details>
  <summary>Details</summary>
Motivation: 研究(1+1)维标量场在有δ函数势存在时，有限温度下卡西米尔效应及其与Lifshitz理论的比较。

Method: 使用规范量化方法计算卡西米尔力和熵，并与Lifshitz理论进行对比。

Result: 在零温度下，两种方法结果一致。在有限温度下，长距离极限下卡西米尔力为F_C(a,T)=-T/(4a)，Lifshitz理论结果是规范量化方法的两倍。规范量化方法得到的熵为正且随温度升高而增加。

Conclusion: 规范量化方法在描述热卡西米尔效应时，能够得到热力学上一致的结果。

Abstract: We investigate the finite-temperature Casimir effect for a (1+1)-dimensional
scalar field interacting with a pair of delta-function potentials. We employ
the canonical quantization method to compute the Casimir force and entropy,
contrasting the results with those from the standard Lifshitz theory. At zero
temperature, both frameworks yield identical forces. For the finite-temperature
case, we find that in the long-distance limit, the Casimir force decays
asymptotically as $F_C(a,T)=-T/(4a)$, with the Lifshitz theory predicting a
magnitude twice as large as that from canonical quantization. Crucially, the
canonical quantization method yields a physically consistent entropy that
remains positive and increases with temperature. These results demonstrate the
robustness of the canonical quantization approach in providing a
thermodynamically sound description of the thermal Casimir effect in this
system.

</details>


### [822] [Quantum Simulation of Oscillatory Unruh Effect with Superposed Trajectories](https://arxiv.org/abs/2510.23050)
*Xu Cheng,Yue Li,Zehua Tian,Xingyu Zhao,Xi Qin,Yiheng Lin*

Main category: quant-ph

TL;DR: 加速探测器在量子场真空中会探测到粒子，这是Unruh效应的预测。由于直接观测所需的加速度过大，研究人员利用激光控制的离子模拟了一个与腔场耦合的振荡探测器，首次观测到与Unruh效应一致的联合激发和协同动力学，并展示了量子叠加态的干涉效应。


<details>
  <summary>Details</summary>
Motivation: Unruh效应的直接观测因所需加速度过大而难以实现，因此需要通过量子模拟平台来揭示其性质以及量子引力相关的未解之谜。此外，探索探测器与场的关联以及相干量子轨迹对于理解Unruh效应的量子方面至关重要，但目前尚缺乏实验研究。

Method: 利用激光控制的离子模拟了一个与腔场耦合的振荡探测器，并进行了单量子轨迹和叠加态量子轨迹的模拟。

Result: 观测到探测器和场的联合激发，与Unruh效应预测的协同动力学一致。在叠加态量子轨迹模拟中，观测到了相干的激发干涉效应。

Conclusion: 该研究首次通过实验模拟揭示了与量子引力理论相关的、没有经典对应物的加速轨迹的量子相干叠加特性，并为研究量子场论和量子引力现象提供了新途径。此外，该方法和结果的推广可能有助于Unruh效应的直接观测。

Abstract: The Unruh effect predicts an astonishing phenomenon that an accelerated
detector would detect counts despite being in a quantum field vacuum in the
rest frame. Since the required detector acceleration for its direct observation
is prohibitively large, recent analog studies on quantum simulation platforms
help to reveal various properties of the Unruh effect and explore the
not-yet-understood physics of quantum gravity. To further reveal the quantum
aspect of the Unruh effect, analogous experimental exploration of the
correlation between the detector and the field, and the consequences for
coherent quantum trajectories of the detector without classical counterparts,
are essential steps but are currently missing. Here, we utilize a
laser-controlled trapped ion to experimentally simulate an oscillating detector
coupled with a cavity field. We observe joint excitation of both the detector
and the field in the detector's frame, coincide with the coordinated dynamics
predicted by the Unruh effect. Particularly, we simulate the detector moving in
single and superposed quantum trajectories, where the latter case shows
coherent interference of excitation. Our demonstration reveals properties of
quantum coherent superposition of accelerating trajectories associated with
quantum gravity theories that have no classical counterparts, and may offer a
new avenue to investigate phenomena in quantum field theory and quantum
gravity. We also show how a generalization of the method and results in this
work may be beneficial for direct observation of the Unruh effect.

</details>


### [823] [Repeated generalized measurements generated quantum trajectories without stochastic differential equations](https://arxiv.org/abs/2510.23058)
*Rutvij Bhavsar,N. D. Hari Dass*

Main category: quant-ph

TL;DR: 该论文研究了在未知状态的单拷贝系统上进行重复POVM和QND测量所产生的量子轨迹问题。


<details>
  <summary>Details</summary>
Motivation: 研究量子轨迹的生成机制，特别是通过重复测量（POVM和QND）在未知状态的单拷贝系统上进行。

Method: 利用量子测量理论，特别是martingale收敛定理，分析了量子轨迹的性质。避免使用随机微分方程，并对不同方法进行了比较。

Result: 研究表明，渐近地，所有量子轨迹都趋向于非简并特征态或由简并特征态扩展的密度矩阵。并且，轨迹的分布遵循Born规则。

Conclusion: 该研究为理解重复测量在量子系统中的作用提供了新的视角，并与现有工作进行了详细比较，指出了结果的稳健性。

Abstract: This paper examines the issue of quantum trajectories generated by repeated
POVM and QND measurements acting on a single copy of a system in an unknown
state. After an introduction to various aspects of quantum measurements, and an
earlier work based on gaussian measurements, which showed the impossibility of
determining the unknown state by such repeated measurements, we present the
current work based on martingale properties of certain quantities along the
trajectory and their convergence from martingale convergence theorems. The main
result is that asymptotically all trajectories approach either non degenerate
eigenstates or density matrices spanned by the degenerate eigenstates. A
unified treatment of both the degenerate and non degenerate cases is given with
the help of higher dimensional projectors. The Luders prescription is
reproduced for the degenerate case. The distribution of trajectories is shown
to be given by the Born rule. Similar conclusions had already been reached by
Bauer et al as well as by Amini et al. A detailed comparison of the three
approaches is given. All the three avoid using stochastic differential
equations. Alter and Yamamoto were the first to investigate repeated
measurements on single copies. We make a detailed comparison with their works
too. We end with a brief discussion of the robustness of the results against
free evolutions as well as some anti-Zeno aspects of the results.

</details>


### [824] [Quantum-Enhanced Multiparameter Sensing via Driven Multi-ensemble Superradiance](https://arxiv.org/abs/2510.23110)
*Kang Shen,Xiangming Hu,Fei Wang*

Main category: quant-ph

TL;DR: We analytically derive the dark-state covariance matrix for a driven multi-ensemble superradiant system in the large-N limit, showing entanglement that improves quantum metrology. The minimum eigenvalue of this matrix corresponds to the optimal multiparameter squeezing coefficient, offering a protocol for optimal quantum enhancement in arbitrary multiparameter estimation tasks, applicable to multimode quantum interferometry.


<details>
  <summary>Details</summary>
Motivation: This paper aims to explore and analytically derive the dark-state covariance matrix of a driven multi-ensemble superradiant system in the large-N limit. The motivation is to reveal the entanglement among ensembles and its enhancement effect on quantum metrology. Furthermore, it seeks to link the minimum eigenvalue of this matrix to the optimal multiparameter squeezing coefficient and establish a concrete protocol for achieving optimal quantum enhancement in arbitrary multiparameter estimation tasks.

Method: The paper analytically derives the dark-state covariance matrix of a driven multi-ensemble superradiant system in the large-N limit. It then analyzes the minimum eigenvalue of this matrix, which is linked to the curvature of the superradiance potential trapping the dark state. This minimum eigenvalue is identified as the optimal multiparameter squeezing coefficient, defined as the Rayleigh quotient of the squeezing matrix.

Result: The derivation reveals entanglement among the ensembles, which enhances quantum metrology. The minimum eigenvalue of the dark-state covariance matrix directly corresponds to the optimal multiparameter squeezing coefficient. This finding establishes a concrete protocol for achieving optimal quantum enhancement in arbitrary multiparameter estimation tasks.

Conclusion: The studied system provides a concrete protocol for achieving optimal quantum enhancement in arbitrary multiparameter estimation tasks. Its ability to generate entanglement and provide optimal squeezing makes it a promising candidate for applications such as multimode quantum interferometry.

Abstract: We analytically derive the dark-state covariance matrix of a driven
multi-ensemble superradiant system in the large-$N$ limit, revealing
entanglement among the ensembles that enhances quantum metrology. The minimum
eigenvalue, linked to the curvature of the superradiance potential trapping the
dark state, corresponds to the optimal multiparameter squeezing coefficient,
defined as the Rayleigh quotient of the squeezing matrix. This system provides
a concrete protocol for achieving optimal quantum enhancement in arbitrary
multiparameter estimation tasks, making it a promising candidate for multimode
quantum interferometry.

</details>


### [825] [Size-consistent implementation of Hamiltonian simulation-based quantum-selected configuration interaction method for the supramolecular approach](https://arxiv.org/abs/2510.23154)
*Kenji Sugisaki*

Main category: quant-ph

TL;DR: 本研究提出了一种尺寸一致的量子选择组态相互作用（QSCI）方法，用于精确计算分子间相互作用能，解决了现有QSCI方法在尺寸一致性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的QSCI方法缺乏尺寸一致性，这对于使用超分子方法进行准确的分子间相互作用能计算至关重要。

Method: 提出了一种尺寸一致的QSCI实现方法，通过在局域化分子轨道基组中对二聚体进行斯莱特行列式采样，构建单体和二聚体的子空间，并扩充二聚体子空间以满足尺寸一致性要求。该方法在哈密顿量模拟（HSB-QSCI）框架内实现。

Result: 该尺寸一致的QSCI方法在4H/8H簇、FH二聚体和FH--H2O体系中数值上满足了尺寸一致性。将其应用于氢键连接的FH二聚体和FH--H2O的分子间相互作用能计算，结果与完全活性空间组态相互作用（CAS-CI）计算值吻合，误差小于0.04 kcal mol$^{-1}$。

Conclusion: 所提出的尺寸一致的QSCI方法能够准确地计算分子间相互作用能，并可作为一种有前景的方法应用于量子硬件上的大规模量子化学计算。

Abstract: The quantum-selected configuration interaction (QSCI) method is a promising
approach for large-scale quantum chemical calculations on currently available
quantum hardware. However, its naive implementation lacks size consistency,
which is essential for accurate intermolecular interaction energy calculations
using the supramolecular approach. Here, we present a size-consistent
implementation of QSCI by sampling Slater determinants for the dimer in the
localized molecular orbital basis, constructing the subspaces for the monomers
and dimer, and augmenting the dimer subspace with additional determinants
required for size consistency. Implemented within the Hamiltonian
simulation-based QSCI (HSB-QSCI) framework, our method numerically satisfies
size consistency for 4H/8H clusters, the FH dimer, and the FH--H$_2$O system.
Application to intermolecular interaction energy calculations of
hydrogen-bonded FH dimer and FH--H$_2$O demonstrates that our approach
reproduces complete active space-configuration interaction (CAS-CI) values with
errors below 0.04 kcal mol$^{-1}$.

</details>


### [826] [Measurement-only circuit of perturbed toric code on triangular lattice: Topological entanglement, 1-form symmetry and logical qubits](https://arxiv.org/abs/2510.23162)
*Keisuke Kataoka,Yoshihito Kuno,Takahiro Orito,Ikuo Ichinose*

Main category: quant-ph

TL;DR: 该工作研究了具有拓扑阶和量子记忆功能的测量可实现电路（MoC）。


<details>
  <summary>Details</summary>
Motivation: 研究测量可实现电路（MoC）的相图，特别是其拓扑阶、对称性破缺和量子比特的出现。

Method: 使用高效的数值稳定算法追踪经历相变的演化状态，并通过拓扑纠缠熵、一形式对称性的无序参数和涌现的逻辑算子等可观测量来阐明相图。

Result: 在三角格上，与方形格上的托里码 MoC 不同，该系统不是自对偶或二分图。观察到的相变具有不同的临界指数，其中一些与二维渗流转变相关。

Conclusion: 托里码 MoC 在三角格上提供了研究拓扑纠缠熵、一形式对称性自发对称性破缺和逻辑算子出现之间相互关系的平台。

Abstract: Measurement-only (quantum) circuit (MoC) gives possibility to realize the
states with rich entanglements, topological orders and quantum memories. This
work studies the MoC, in which the projective-measurement operators consist of
stabilizers of the toric code and competitive local Pauli operators. The former
correspond to terms of the toric code on a triangular lattice and the later to
external magnetic and electric fields. We employ efficient numerical stabilizer
algorithm to trace evolving states undergoing phase transitions. We elucidate
the phase diagram of the MoC system with the observables such as, topological
entanglement entropy (TEE), disorder parameters of 1-form symmetries and
emergent logical operators. We clarify the locations of the phase transitions
through the observation of the above quantities and obtain precise critical
exponents to examine if the observables exhibit the critical behavior
simultaneously under the MoC and transitions belong to the same universality
class. In contrast to the TC Hamiltonian system and toric code MoC on a square
lattice, the system on the triangular lattice is not self-dual nor bipartite,
and then, coincidence by symmetries, such as critical behaviors across the TC
and Higgs/confined phase, does not takes place. Then, the toric code MoC on the
triangular lattice provides us a suitable playground to clarify the mutual
relationship between the TEE, spontaneous symmetry breaking of the 1-form
symmetries, and emergence of logical operators. Obtained results indicate that
toric code MoC on the triangular lattice exhibits a few distinct phase
transitions with different location and critical exponents, and some of them
are closely related with the two-dimensional percolation transition.

</details>


### [827] [Benchmarking VQE Configurations: Architectures, Initializations, and Optimizers for Silicon Ground State Energy](https://arxiv.org/abs/2510.23171)
*Zakaria Boutakka,Nouhaila Innan,Muhammed Shafique,Mohamed Bennai,Z. Sakhi*

Main category: quant-ph

TL;DR: VQE算法在模拟硅原子基态能量方面表现良好，参数初始化和化学启发式ansatz与自适应优化相结合是关键。


<details>
  <summary>Details</summary>
Motivation: 研究VQE在模拟具有挑战性的重元素（如硅原子）的量子化学模拟中的性能。

Method: 使用包括双激发门、ParticleConservingU2、UCCSD和k-UpCCGSD在内的多种ansatz，并结合梯度下降、SPSA和ADAM等优化器，在混合量子-经典框架下实现VQE。

Result: 参数初始化对算法稳定性有决定性影响；化学启发式ansatz与自适应优化相结合比传统方法具有更好的收敛性和精度。

Conclusion: VQE是一种有前途的量子化学模拟方法，通过仔细选择ansatz和优化器，并特别关注参数初始化，可以实现高效和精确的模拟。

Abstract: Quantum computing presents a promising path toward precise quantum chemical
simulations, particularly for systems that challenge classical methods. This
work investigates the performance of the Variational Quantum Eigensolver (VQE)
in estimating the ground-state energy of the silicon atom, a relatively heavy
element that poses significant computational complexity. Within a hybrid
quantum-classical optimization framework, we implement VQE using a range of
ansatz, including Double Excitation Gates, ParticleConservingU2, UCCSD, and
k-UpCCGSD, combined with various optimizers such as gradient descent, SPSA, and
ADAM. The main contribution of this work lies in a systematic methodological
exploration of how these configuration choices interact to influence VQE
performance, establishing a structured benchmark for selecting optimal settings
in quantum chemical simulations. Key findings show that parameter
initialization plays a decisive role in the algorithm's stability, and that the
combination of a chemically inspired ansatz with adaptive optimization yields
superior convergence and precision compared to conventional approaches.

</details>


### [828] [Resource analysis of Shor's elliptic curve algorithm with an improved quantum adder on a two-dimensional lattice](https://arxiv.org/abs/2510.23212)
*Quan Gu,Han Ye,Junjie Chen,Xiongfeng Ma*

Main category: quant-ph

TL;DR: 研究人员提出了一种改进的量子加法器设计，并利用它对 Shor 的椭圆曲线算法进行了资源分析，估计破解 NIST P-256 曲线所需的量子比特和保真度。 


<details>
  <summary>Details</summary>
Motivation: 现有的 Shor 椭圆曲线算法的资源估算在现实架构约束下有限，需要更精确的评估。 

Method: 提出了一种新的进位超前量子加法器，其深度为 O(log n)，并且仅需要 O(n) 的辅助空间。该设计兼容二维最近邻架构，并结合了动态电路技术、窗口方法、Montgomery 表示和量子查找表，以减少长距离门的开销。 

Result: 破解 NIST P-256 曲线大约需要 4300 个逻辑量子比特，以及约 10^-9 的逻辑 Toffoli 保真度。 

Conclusion: 新提出的量子加法器设计在深度和空间开销方面均优于现有方法，为实现 Shor 的椭圆曲线算法提供了新的基准和实际指导。

Abstract: Quantum computers have the potential to break classical cryptographic systems
by efficiently solving problems such as the elliptic curve discrete logarithm
problem using Shor's algorithm. While resource estimates for factoring-based
cryptanalysis are well established, comparable evaluations for Shor's elliptic
curve algorithm under realistic architectural constraints remain limited. In
this work, we propose a carry-lookahead quantum adder that achieves Toffoli
depth $\log n + \log\log n + O(1)$ with only $O(n)$ ancillas, matching
state-of-the-art performance in depth while avoiding the prohibitive $O(n\log
n)$ space overhead of existing approaches. Importantly, our design is naturally
compatible with the two-dimensional nearest-neighbor architectures and
introduce only a constant-factor overhead. Further, we perform a comprehensive
resource analysis of Shor's elliptic curve algorithm on two-dimensional
lattices using the improved adder. By leveraging dynamic circuit techniques
with mid-circuit measurements and classically controlled operations, our
construction incorporates the windowed method, Montgomery representation, and
quantum tables, and substantially reduces the overhead of long-range gates. For
cryptographically relevant parameters, we provide precise resource estimates.
In particular, breaking the NIST P-256 curve, which underlies most modern
public-key infrastructures and the security of Bitcoin, requires about $4300$
logical qubits and logical Toffoli fidelity about $10^{-9}$. These results
establish new benchmarks for efficient quantum arithmetic and provide concrete
guidance toward the experimental realization of Shor's elliptic curve
algorithm.

</details>


### [829] [Spoofing resilience for simple-detection quantum illumination LIDAR](https://arxiv.org/abs/2510.23228)
*Richard J. Murchie,John Jeffers*

Main category: quant-ph

TL;DR: 量子照明可以提供抗干扰和抗欺骗能力，优于经典照明。


<details>
  <summary>Details</summary>
Motivation: 对象检测和测距系统使用弱光源时，容易受到干扰和欺骗攻击。本研究旨在扩展一种可行的量子照明协议，以实现抗欺骗能力。

Method: 通过利用非同时、与相位无关的符合测量，并对系统进行参数化和量子态表征，而不是仅仅依赖探测器数据，来评估和寻找提供抗欺骗能力的参数空间。研究了入侵者的最优相对探测基角度以及在背景噪声过大时可能出现的欺骗易受攻击的情况。

Result: 在某些情况下，入侵者存在一个最优相对探测基角度以最小化引入的误差。同时，也存在一些欺骗易受攻击的情况，尽管背景噪声过大，但仍有可能进行对象检测，探测器并未完全失效。该传感协议可以识别入侵并可能检测到可信的返回信号。

Conclusion: 量子照明在抗欺骗方面比经典照明具有优势。

Abstract: Object detection and range finding using a weak light source is vulnerable to
jamming and spoofing attacks by an intruder. Quantum illumination with
nonsimultaneous, phase-insensitive coincidence measurements can provide jamming
resilience compared to identical measurements for classical illumination. We
extend an experimentally-feasible object detection and range finding quantum
illumination-based protocol to include spoofing resilience. This approach
allows the system to be characterised by its experimental parameters and
quantum states, rather than just its detector data. Therefore we can scope the
parameter-space which provides some spoofing resilience without relying upon
the prohibitive method of acquiring detector data for all combinations of the
experimental parameters. We demonstrate that in certain regimes the intruder
has an optimal relative detection basis angle to minimise the induced error. We
also show that there are spoofing-vulnerable regimes where excessive background
noise prevents any induced error, while it is still possible to perform object
detection, i.e. our detectors have not been fully blinded. The sensing protocol
which we describe can allow for the recognition of intrusion and the possible
detection of our trustworthy return signal. Our results reinforce that quantum
illumination is advantageous for spoofing resilience compared to a classical
illumination-based protocol.

</details>


### [830] [Free-space quantum interface of a single atomic tweezer array with light](https://arxiv.org/abs/2510.23398)
*Yakov Solomons,Roni Ben-Maimon,Arpit Behera,Ofer Firstenberg,Nir Davidson,Ephraim Shahmoon*

Main category: quant-ph

TL;DR: 提出了一种将光与二维原子镊子阵列有效耦合的方法。


<details>
  <summary>Details</summary>
Motivation: 传统的接口方法匹配性差，限制了耦合效率。

Method: 设计了一种由多个对应衍射级次的 beam 组成的复合模式，可通过高斯光束和标准光学元件生成。

Result: 该方法可以达到很高的接口效率，并且效率随着原子数量 N 的增加而提高，理论效率可达 0.99 以上，并对光学和原子位置误差具有鲁棒性。

Conclusion: 该方案为量子信息应用和量子比特读出提供了一条可行的途径。

Abstract: We present a practical approach for interfacing light with a two-dimensional
atomic tweezer array. Typical paraxial fields are poorly matched to the array's
multi-diffraction-order radiation pattern, thus severely limiting the interface
coupling efficiency. Instead, we propose to design a field mode that naturally
couples to the array: it consists of a unique superposition of multiple beams
corresponding to the array's diffraction orders. This composite mode can be
generated from a single Gaussian beam using standard free-space optics,
including spatial light modulators and a single objective lens. For a
triangular array with lattice spacing about twice the wavelength, all
diffraction angles remain below 35 degrees, making the scheme compatible with
standard objectives of numerical aperture NA <= 0.7. Our analytical theory and
scattering simulations reveal that the interface efficiency r0 for quantum
information tasks scales favorably with the array atom number N: reaching >0.99
(>0.9999) for N = 149 (N approximately 1000) and scaling as 1 - r0 scales as
1/N for large N. The scheme is robust to optical imperfections and
atomic-position errors, offering a viable path for quantum light-matter
applications and state readout in current tweezer-array platforms.

</details>


### [831] [Anti-Flatness and Non-Local Magic in Two-Particle Scattering Processes](https://arxiv.org/abs/2510.23426)
*C. E. P. Robin,M. J. Savage*

Main category: quant-ph

TL;DR: 非局域魔术和反平坦度是衡量量子系统波函数中量子复杂度的指标，它们是基于纠缠的，不能被局域幺正操作移除。这两种度量（非局域魔术和反平坦度）对于理解许多体系统的量子复杂性至关重要，特别是在多粒子散射过程中。


<details>
  <summary>Details</summary>
Motivation: 本文旨在通过研究两粒子散射过程（低能核-核散射和高能缪勒散射）中的非局域魔术和反平坦度，来增进对基本相互作用产生的量子复杂性生成的理解。

Method: 本文研究了低能核-核散射和高能缪勒散射过程中的非局域魔术和反平坦度，并验证了Clifford平均反平坦度与总魔术之间的关系。

Result: 在所研究的相互作用中，非局域魔术是反平坦度的四倍（对于任何两量子比特波函数都成立）。反平坦度比非局域魔术更容易通过实验测量获得，因为它只需要测量最终态的一个粒子，并且不需要自旋关联。

Conclusion: 研究表明，非局域魔术是反平坦度的四倍，并且反平坦度是更容易测量的量。虽然MOLLER实验不包含最终态自旋测量，但本文的研究结果可能为未来包含此类测量提供依据。

Abstract: Non-local magic and anti-flatness provide a measure of the quantum complexity
in the wavefunction of a physical system. Supported by entanglement, they
cannot be removed by local unitary operations, thus providing basis-independent
measures, and sufficiently large values underpin the need for quantum computers
in order to perform precise simulations of the system at scale. Towards a
better understanding of the quantum-complexity generation by fundamental
interactions, the building blocks of many-body systems, we consider non-local
magic and anti-flatness in two-particle scattering processes, specifically
focusing on low-energy nucleon-nucleon scattering and high-energy Moller
scattering. We find that the non-local magic induced in both interactions is
four times the anti-flatness (which is found to be true for any two-qubit
wavefunction), and verify the relation between the Clifford-averaged
anti-flatness and total magic. For these processes, the anti-flatness is a more
experimentally accessible quantity as it can be determined from one of the
final-state particles, and does not require spin correlations. While the MOLLER
experiment at the Thomas Jefferson National Accelerator Facility does not
include final-state spin measurements, the results presented here may add
motivation to consider their future inclusion.

</details>


### [832] [SQOUT: A Risk-Based Threat Analysis Framework for Quantum Communication Systems](https://arxiv.org/abs/2510.23462)
*Michal Krelina,Tom Sorger,Bob Dirks*

Main category: quant-ph

TL;DR: 本研究提出了一个针对量子通信系统的网络安全框架，结合了TTP方法和风险评估，并介绍了SQOUT平台，以应对量子通信面临的物理、协议和操作风险。


<details>
  <summary>Details</summary>
Motivation: 随着全球向抗量子基础设施的过渡，量子通信系统需要一个专门的网络安全框架，因为现实世界的部署面临物理、协议和操作风险。

Method: 本研究提出了一种结构化框架，结合了TTP（策略、技术、程序）方法和特定的风险评估方法，并引入了量子威胁情报平台SQOUT，利用光子数分裂（PNS）攻击杀伤链进行了说明。此外，还应用了既定的国际信息安全风险管理标准和最佳实践来评估量子特定风险。

Result: 本研究提出了一个用于分析量子通信系统威胁的框架，并展示了SQOUT平台在PNS攻击杀伤链中的应用。

Conclusion: 本研究提出的框架和SQOUT平台为保护新兴的量子基础设施提供了实用的指导，有助于应对量子通信面临的实际风险。

Abstract: This paper addresses the urgent need for a cybersecurity framework tailored
to quantum communication systems as the world transitions to quantum-safe
infrastructures. While quantum communication promises unbreakable security,
real-world deployments are vulnerable to physical, protocol, and operational
risks. Our work presents a structured framework for analysing these threats,
combining a TTP-style (Tactic, Technique, Procedure) approach with a specific
risk assessment methodology. We introduce SQOUT, a quantum threat intelligence
platform, and illustrate its application using a Photon-Number-Splitting (PNS)
attack kill chain. Furthermore, we apply established international standards
and best practices for information security risk management to assess
quantum-specific risk scenarios, providing practical guidance for safeguarding
emerging quantum infrastructures.

</details>


### [833] [Bound entanglement in symmetric random induced states](https://arxiv.org/abs/2510.23480)
*Jonathan Louvet,François Damanet,Thierry Bastin*

Main category: quant-ph

TL;DR: 对称随机诱导状态可以自然地产生PPT量子纠缠，并且通过两种方法（MI和MII）可以生成大量的PPT量子纠缠态。


<details>
  <summary>Details</summary>
Motivation: 量子纠缠中的受限纠缠（bound entanglement）是一种较弱但有用的形式，然而它很难被检测和构建。

Method: 通过利用对称随机诱导状态，并选择合适的参数，使得在部分迹操作下可以自然地产生PPT受限纠缠。研究了通过两种方法（MI和MII）构造的对称随机诱导状态中出现PPT受限纠缠的概率。MI方法是通过部分迹对称多量子比特纯态，MII方法是通过迹出一个辅助量子比特。

Result: 对于N>3量子比特，当选择最优参数时，受限纠缠会自然出现，发生概率接近1。MI和MII方法生成不同种类的PPT受限纠缠态，并且各自在特定情况下具有优势。

Conclusion: 所提出的方法可以无需复杂的数值优化即可生成大量的随机PPT受限纠缠态，为受限纠缠的研究提供了新的途径。

Abstract: Bound entanglement, a weak -- yet resourceful -- form of quantum
entanglement, remains notoriously hard to detect and construct. We address this
in this paper by leveraging symmetric random induced states, where positive
partial transpose (PPT) bound entanglement arises naturally under partial
tracing when proper parameters are selected. We investigate the probability of
finding PPT bound entanglement in symmetric random induced states constructed
via two methods: partial tracing of symmetric multiqubit pure states on the one
hand (MI) and tracing out a qudit ancilla on the other hand (MII). For $N > 3$
qubits, we demonstrate that bound entanglement naturally emerges under optimal
parameters, with a probability of occurrence very close to 1. We show that the
two methods produce different varieties of PPT bound entangled states, and
identify the contexts in which each method offers distinct advantages. These
methods provide a versatile toolkit for the generation of large families of
random PPT bound entangled states without complex numerical optimization.

</details>


### [834] [Quantum Phase Classification of Rydberg Atom Systems Using Resource-Efficient Variational Quantum Circuits and Classical Shadows](https://arxiv.org/abs/2510.23489)
*Hemish Ahuja,Samradh Bhardwaj,Kirti Dhir,Roman Bagdasarian,Ziwoong Jang*

Main category: quant-ph

TL;DR: 通过结合经典影踪层析成像和变分量子电路（VQC），我们提出了一种资源高效的量子机器学习方法，用于对 Z2 和 Z3 序相进行二元分类，实现了 100% 的测试准确率。


<details>
  <summary>Details</summary>
Motivation: 区分里德堡原子阵列中不同的有序相，特别是在没有显式序参数的情况下，仍然是一个挑战。

Method: 我们使用经典影踪层析成像来重建算符，然后进行主成分分析（PCA）降维，并将提取的特征编码到包含 RY-RZ 角度编码、所有 CZ 门强纠缠和两参数的 2-量子比特参数化电路中。然后，我们使用 SPSA 优化器和铰损失函数对该电路进行训练。

Result: 该模型在 500 次随机测量和 51 个原子链状态的情况下，在 120 次迭代中收敛，并实现了 100% 的测试准确率，以及完美的精度、召回率和 F1 分数。

Conclusion: 该研究表明，最少的量子资源足以高精度地对量子相进行分类，为在近期量子设备上进行量子增强的凝聚态物理学研究开辟了道路。

Abstract: Quantum phase transitions in Rydberg atom arrays present significant
opportunities for studying many-body physics, yet distinguishing between
different ordered phases without explicit order parameters remains challenging.
We present a resource-efficient quantum machine learning approach combining
classical shadow tomography with variational quantum circuits (VQCs) for binary
phase classification of Z2 and Z3 ordered phases. Our pipeline processes 500
randomized measurements per 51-atom chain state, reconstructs shadow operators,
performs PCA dimensionality reduction (514 features), and encodes features
using angle embedding onto a 2-qubit parameterized circuit. The circuit employs
RY-RZ angle encoding, strong entanglement via all-to-all CZ gates, and a
minimal 2-parameter ansatz achieving depth 7. Training via simultaneous
perturbation stochastic approximation (SPSA) with hinge loss converged in 120
iterations. The model achieved 100% test accuracy with perfect precision,
recall, and F1 scores, demonstrating that minimal quantum resources suffice for
high-accuracy phase classification. This work establishes pathways for
quantum-enhanced condensed matter physics on near-term quantum devices.

</details>


### [835] [The Enigma of Delayed Choice Quantum Eraser](https://arxiv.org/abs/2510.23539)
*Tabish Qureshi*

Main category: quant-ph

TL;DR: 延迟选择量子擦除实验演示了互补原理，即使在粒子被探测后擦除路径信息，干涉也会重新出现，引发了关于延迟因果的争议，本文回顾并解决了这一争议。


<details>
  <summary>Details</summary>
Motivation: 解释延迟选择量子擦除实验如何体现波粒二象性，并引发了关于延迟因果的争议。

Method: 回顾关于延迟选择量子擦除实验的争议，并提供详细的解决方案。

Result: 干涉会重新出现，即使在粒子被探测后擦除路径信息。

Conclusion: 对延迟选择量子擦除实验的争议进行了回顾和解决。

Abstract: The delayed-choice quantum eraser represents an interesting experiment that
exemplifies Bohr's principle of complementarity in a beautiful way. According
to the complementarity principle, in a two-path interference experiment, the
knowledge of which path was taken by the particle and the appearance of
interference are mutually exclusive. Even when the which-path information is
merely retained in specific quantum path-markers, without being actually read,
it suffices to eliminate interference. Nevertheless, if this path information
is ``erased'' in some manner, the interference re-emerges, a phenomenon
referred to as the quantum eraser. An intriguing aspect of this experiment is
that if the path information is erased \emph{after} the particle has been
detected on the screen, the interference still reappears, a phenomenon known as
the delayed-choice quantum eraser. This observation has led to the
interpretation that the particle can be influenced to exhibit characteristics
of either a particle or a wave based on a decision made long after it has been
registered on the screen. This idea has sparked considerable debate and
discussions surrounding retrocausality. This controversy is reviewed here, and
a detailed resolution provided.

</details>


### [836] [Variational Thermal State Preparation on Digital Quantum Processors Assisted by Matrix Product States](https://arxiv.org/abs/2510.23546)
*Rui-Hao Li,Semeon Valgushev,Khadijeh Najafi*

Main category: quant-ph

TL;DR: 该研究提出了一种利用矩阵乘积态来制备量子吉布斯状态的变分框架，该框架能够高效地进行亥姆霍兹自由能的经典评估，并结合了可扩展的纠缠熵计算和硬件高效的ansatz，从而精确地近似一维和二维系统中的热态。


<details>
  <summary>Details</summary>
Motivation: 在量子计算中，制备有限温度下的量子吉布斯状态是量子模拟、量子玻尔兹曼机和热力学采样技术等应用的基础。

Method: 研究引入了一种变分框架，利用矩阵乘积态来高效地进行亥姆霍兹自由能的经典评估，并结合了可扩展的纠缠熵计算和硬件高效的ansatz。

Result: 该框架能够制备高质量的吉布斯状态，支持一维系统最多30个位点和二维系统最多6x6个位点（最多42个量子比特）。研究人员还在IBM Heron处理器上成功制备了30个位点的横向场伊辛模型（transverse-field Ising model）的近似吉布斯状态，并通过误差缓解技术将能量和磁化率的相对误差降低了50%以上。

Conclusion: 所提出的框架在实际量子硬件上具有可行性，并且通过误差缓解技术能够显著提高吉布斯状态制备的精度。

Abstract: The preparation of quantum Gibbs states at finite temperatures is a
cornerstone of quantum computation, enabling applications in quantum simulation
of many-body systems, machine learning via quantum Boltzmann machines, and
optimization through thermal sampling techniques. In this work, we introduce a
variational framework that leverages matrix product states for the efficient
classical evaluation of the Helmholtz free energy, combining scalable
entanglement entropy computation with a hardware efficient ansatz to accurately
approximate thermal states in one- and two-dimensional systems. We conduct
extensive benchmarking on key observables, including energy density,
susceptibility, specific heat, and two-point correlations, comparing against
exact analytical results for 1D systems and quantum Monte Carlo simulations for
2D lattices across various temperatures and ansatz configurations. Our
large-scale numerical simulations demonstrate the capability to prepare
high-quality Gibbs states for 1D lattice models with up to 30 sites and 2D
systems with up to 6x6 sites, using up to 42 qubits. Finally, we demonstrate
the framework's practical viability on a 156-qubit IBM Heron processor by
preparing the approximate Gibbs state of a 30-site transverse-field Ising
model. Leveraging a combination of error mitigation techniques, we reduce the
relative errors in energy and susceptibility measurements by over 50% compared
to unmitigated results.

</details>


### [837] [FPGA-Based Adaptive Control for Phase Stabilization in Fiber-Optic Interferometers Using Correlated Photons](https://arxiv.org/abs/2510.23572)
*P. M. Berto,F. CampodÓnico,A. A. Matoso,S. Vergara,P. A. Coelho,G. Lima,S. PÁdua,J. CariÑe*

Main category: quant-ph

TL;DR: Time-bin encoded photon pairs are used for quantum communication, but phase noise is a problem. An adaptive algorithm implemented on an FPGA reduces phase noise, improving performance and stability.


<details>
  <summary>Details</summary>
Motivation: Phase noise is a critical limitation for stable operation in long-distance quantum communication using time-bin encoded photon pairs transmitted through optical fibers.

Method: An adaptive Perturbation-and-Observe algorithm was implemented on a fully digital FPGA platform with real-time feedback at 1 Hz, using coincidence counts of correlated photon pairs to derive the control signal.

Result: The adaptive approach reduced the rise time by 70% and the coincidence noise by 30%, achieving sustained visibility improvements for over 600 seconds.

Conclusion: The implemented adaptive algorithm provides an efficient solution for long-term phase stabilization in quantum and photonic systems.

Abstract: Time-bin encoded photon pairs enable robust, decoherence-resistant
transmission through optical fibers for long-distance quantum communication,
where phase noise poses a critical limitation to stable operation. Here, we
implement an adaptive Perturbation-and-Observe algorithm on a fully digital
FPGA platform operating with real-time feedback at 1 Hz. The control signal is
derived from the coincidence counts of correlated photon pairs. This adaptive
approach reduces the rise time by 70\% and the coincidence noise by 30\%,
resulting in visibility improvements sustained for more than 600 s.These
results provide an efficient solution for long-term phase stabilization in
quantum and photonic systems.

</details>


### [838] [Gaussian tomography for cold-atom simulators](https://arxiv.org/abs/2510.23591)
*Matthew Kiser,Max McGinley,Daniel Malz*

Main category: quant-ph

TL;DR: 通过在随机基中测量来克服冷原子量子模拟器中读取的局限性。


<details>
  <summary>Details</summary>
Motivation: 冷原子光晶格模拟器通常仅限于读取对角可观测量，限制了其测量能力。

Method: 提出了一种利用非相互作用动力学和标准量子气体显微镜在随机基中进行测量的实验友好方案，以测量非对角关联（例如电流）。

Result: 数值演示了高效估计双线性相关函数，在 70 个格点系统中，用少于 4000 个样本即可将局部电流误差控制在 5%，并用约 10^4 个样本即可同时测量所有非局部关联。

Conclusion: 所提出的方案具有简单、对现有平台要求适中的优点，能够实现超越粒子数测量的精确测量。

Abstract: A limitation of analog quantum simulators based on cold atoms in optical
lattices is that readout is typically limited to observables diagonal in the
charge basis, i.e., densities and density correlation functions. To overcome
this limitation, we propose experiment-friendly schemes to measure
charge-off-diagonal correlations (such as currents). Our protocols use
non-interacting dynamics for random times followed by standard quantum gas
microscope measurements to effectively measure in random bases. The main
requirement of our scheme is the ability to turn off interactions, which can be
done in many atomic species using Feshbach resonances. Importantly, our scheme
requires no local control and otherwise also exhibits modest requirements in
terms of total evolution time and number of repetitions. We numerically
demonstrate efficient estimation of bilinear correlation functions, requiring
less than $4000$ samples to measure local currents to 5% error (system-size
independent) and $\sim 10^4$ samples to simultaneously measure all non-local
correlations in 70-site systems. Due to its simplicity, our protocol is
implementable in existing platforms and thus paves the way to precision
measurements beyond particle number measurements.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [839] [Conditional Recall](https://arxiv.org/abs/2510.21904)
*Christoph Schlegel,Xinyuan Sun*

Main category: cs.GT

TL;DR: 一款名为X的药物可以帮助人们选择性地删除记忆，但这也引发了关于信息、记忆和未来选择的伦理困境。


<details>
  <summary>Details</summary>
Motivation: 探讨了在法律领域引入新技术（如允许用户承诺忘记信息的TEEs）对博弈论的影响，并讨论了其潜在应用。

Method: 使用博弈论的框架来分析新技术（如TEEs）在记忆删除和信息遗忘方面的应用。

Result: 探讨了该技术在法律领域的潜在应用，以及用户在面对是否使用该技术以换取更清晰但可能不完整的未来时的伦理抉择。

Conclusion: 新技术（如TEEs）在记忆删除方面的应用带来了复杂的伦理和社会影响，尤其是在法律领域，需要谨慎权衡其利弊。

Abstract: In the neon-lit nights of 2026, Johnson \& Johnson unveiled X. A pill, not
larger than a snowflake, that promised a tempest of change. This miraculous
drug didn't just allow people to cherry-pick memories to erase from their
minds, it could also leave a reminder of this erasure in the minds of those who
ingested it.
  Amidst the iconic red-bricked walls of Harvard Law, you, with books in one
hand and dreams in the other, are on a mission. You are not just another
student; you carry the hope of revolutionizing the archaic chambers of the
legal world. Each night, as you pore over the tomes of law, you wonder what
greatness society can achieve.
  On a cold evening, your phone buzzes. It's Dex, your old college friend
turned underground dealer. His message is simple: ``Got X. Special price for
you.'' The temptation swirls around you. Would you trade the lessons of the
past for a clearer, yet incomplete future? The decision rests in your hands.
  We explore the game theoretic implications of a technology (such as TEEs)
that allows agents to commit to forget information and discuss several
applications.

</details>


### [840] [Rational Adversaries and the Maintenance of Fragility: A Game-Theoretic Theory of Rational Stagnation](https://arxiv.org/abs/2510.22232)
*Daisuke Hirota*

Main category: cs.GT

TL;DR: 本篇论文解释了


<details>
  <summary>Details</summary>
Motivation: 合作系统常停留在次优但稳定的状态，即“理性停滞”。

Method: 论文从囚徒困境出发，通过引入效用变换和相互识别比率w=b/a，生成了一个包含（C,C）和（D,D）均为均衡的脆弱合作区间[w_min, w_max]。接着，通过扩展到包含随机合作收益R_t和干预成本(Cc, Cm)的动态模型，并进行Bellman风格分析，得出了三种战略模式：立即破坏、理性停滞和放弃干预。附录部分将效用推广到参考依赖的非线性形式，并证明了其在参考点移动下的稳定性。

Result: 本研究揭示了“理性停滞”现象，即合作系统可能因理性对手的存在而持续处于次优稳定状态。研究定义了对手的效用函数，并分析了不同效用变换和相互识别比率对合作区间的生成影响。动态模型分析表明，存在三种战略模式：立即破坏、理性停滞和放弃干预。

Conclusion: 本研究提出的框架对于理解和应用于社会媒体算法和政治信任等领域具有指导意义，解释了对手的理性如何故意维持合作的脆弱性。

Abstract: Cooperative systems often remain in persistently suboptimal yet stable
states. This paper explains such "rational stagnation" as an equilibrium
sustained by a rational adversary whose utility follows the principle of
potential loss, $u_{D} = U_{ideal} - U_{actual}$. Starting from the Prisoner's
Dilemma, we show that the transformation $u_{i}' = a\,u_{i} + b\,u_{j}$ and the
ratio of mutual recognition $w = b/a$ generate a fragile cooperation band
$[w_{\min},\,w_{\max}]$ where both (C,C) and (D,D) are equilibria. Extending to
a dynamic model with stochastic cooperative payoffs $R_{t}$ and intervention
costs $(C_{c},\,C_{m})$, a Bellman-style analysis yields three strategic
regimes: immediate destruction, rational stagnation, and intervention
abandonment. The appendix further generalizes the utility to a
reference-dependent nonlinear form and proves its stability under reference
shifts, ensuring robustness of the framework. Applications to social-media
algorithms and political trust illustrate how adversarial rationality can
deliberately preserve fragility.

</details>


### [841] [Learning Local Stackelberg Equilibria from Repeated Interactions with a Learning Agent](https://arxiv.org/abs/2510.22471)
*Nivasini Ananthakrishnan,Yuval Dagan,Kunhe Yang*

Main category: cs.GT

TL;DR: 本文研究了在一个有学习代理的重复博弈中，主方如何最大化其效用。与以往工作中计算全局Stackelberg值的计算难度相比，本文提出了一种在平滑分析框架下，寻找局部Stackelberg均衡的近似算法，该算法是PTAS，其运行时间在代理动作空间大小上是多项式的，但在1/epsilon上是指数的，并且证明了这种依赖性是不可避免的。


<details>
  <summary>Details</summary>
Motivation: 主方在一个有学习代理的重复博弈中最大化其效用的问题。

Method: 提出了一种在平滑分析框架下，寻找局部Stackelberg均衡的近似算法，该算法是PTAS。

Result: 该算法在代理动作空间大小上是多项式的，但在1/epsilon上是指数的，并且证明了这种依赖性是不可避免的。

Conclusion: 本文提出的算法为在重复博弈中主方最大化其效用提供了一种计算上可行的解决方案，尽管在某些参数上存在指数级的时间复杂度。

Abstract: Motivated by the question of how a principal can maximize its utility in
repeated interactions with a learning agent, we study repeated games between an
principal and an agent employing a mean-based learning algorithm. Prior work
has shown that computing or even approximating the global Stackelberg value in
similar settings can require an exponential number of rounds in the size of the
agent's action space, making it computationally intractable. In contrast, we
shift focus to the computation of local Stackelberg equilibria and introduce an
algorithm that, within the smoothed analysis framework, constitutes a
Polynomial Time Approximation Scheme (PTAS) for finding an epsilon-approximate
local Stackelberg equilibrium. Notably, the algorithm's runtime is polynomial
in the size of the agent's action space yet exponential in (1/epsilon) - a
dependency we prove to be unavoidable.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [842] [Drone Carry-on Weight and Wind Flow Assessment via Micro-Doppler Analysis](https://arxiv.org/abs/2510.22846)
*Dmytro Vovchuk,Oleg Torgovitsky,Mykola Khobzei,Vladyslav Tkach,Sergey Geyman,Anton Kharchevskii,Andrey Sheleg,Toms Salgals,Vjaceslavs Bobrovs,Shai Gizach,Aviel Glam,Niv Haim Mizrahi,Alexander Liberzon,Pavel Ginzburg*

Main category: physics.app-ph

TL;DR: 通过分析无人机悬停时的微多普勒信号，可以区分风速和载重对无人机飞行姿态的影响。


<details>
  <summary>Details</summary>
Motivation: 无人机在国家安全和航空交通管理中的应用日益广泛，对其进行远程监控至关重要，尤其是无人机可能携带危险品。无人机的飞行姿态受外部风力和载重影响，这会改变无人机机体的倾斜角度和旋翼转速。雷达可以通过分析接收到的回波信号来捕捉这些影响。

Method: 通过在无响室和风洞环境中进行实验，研究了微多普勒分析在区分风力和载重对悬停无人机影响方面的作用。分析了无人机内部控制器如何应对风力和载重，并研究了由此产生的微多普勒信号特征。

Result: 实验证明，通过分析微多普勒信号的频谱分裂（或分支），可以提取风力和载重信息。载重增加了所有旋翼的负载，导致其转速加快，产生更高频率的微多普勒频移。而风力引起的倾斜导致前后旋翼转速不同，从而产生频谱分裂。

Conclusion: 基于微多普勒频谱分析，可以开发出简单的确定性算法，用于从无人机信号中提取风力和载重信息，从而实现对无人机的有效监控。

Abstract: Remote monitoring of drones has become a global objective due to emerging
applications in national security and managing aerial delivery traffic. Despite
their relatively small size, drones can carry significant payloads, which
require monitoring, especially in cases of unauthorized transportation of
dangerous goods. A drone's flight dynamics heavily depend on outdoor wind
conditions and the carry-on weight, which affect the tilt angle of a drone's
body and the rotation velocity of the blades. A surveillance radar can capture
both effects, provided a sufficient signal-to-noise ratio for the received
echoes and an adjusted postprocessing detection algorithm. Here, we conduct a
systematic study to demonstrate that micro-Doppler analysis enables the
disentanglement of the impacts of wind and weight on a hovering drone. The
physics behind the effect is related to the flight controller, as the way the
drone counteracts weight and wind differs. When the payload is balanced, it
imposes an additional load symmetrically on all four rotors, causing them to
rotate faster, thereby generating a blade-related micro-Doppler shift at a
higher frequency. However, the impact of the wind is different. The wind
attempts to displace the drone, and to counteract this, the drone tilts to the
side. As a result, the forward and rear rotors rotate at different velocities
to maintain the tilt angle of the drone body relative to the airflow direction.
This causes the splitting in the micro-Doppler spectra. By performing a set of
experiments in a controlled environment, specifically, an anechoic chamber for
electromagnetic isolation and a wind tunnel for imposing deterministic wind
conditions, we demonstrate that both wind and payload details can be extracted
using a simple deterministic algorithm based on branching in the micro-Doppler
spectra.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [843] [Possibilistic Computation Tree Logic: Decidability and Complete Axiomatization](https://arxiv.org/abs/2510.23075)
*Yongming Li*

Main category: cs.LO

TL;DR: PoCTL的满意度问题被证明是可判定的，并给出了其完整的公理化。


<details>
  <summary>Details</summary>
Motivation: 研究PoCTL（一种结合了可能性理论中的不确定信息的时序逻辑）的满意度问题，因为该问题之前未被讨论过。

Method: 通过提取PoCTL公式中的可能性信息并构建其可能性Hintikka结构来解决满意度问题。

Result: PoCTL的满意度问题在指数时间内是可判定的，并给出了PoCTL的完整公理化。

Conclusion: PoCTL的满意度问题是可判定的，并且已经对其进行了公理化。

Abstract: Possibilistic computation tree Logic (PoCTL) is one kind of branching
temporal logic combined with uncertain information in possibility theory, which
was introduced in order to cope with the systematic verification on systems
with uncertain information in possibility theory. There are two decision
problems related to PoCTL: the model checking problem and the satisfiability
problem. The model checking problem of PoCTL has been studied, while the
satisfiability problem of PoCTL was not discussed. One of the purpose of this
work is to study the satisfiability problem of PoCTL. By introducing some
techniques to extract possibility information from PoCTL formulae and
constructing their possibilistic Hintikka structures, we show that the
satisfiability problem of PoCTL is decidable in exponential time. Furthermore,
we give a complete axiomatization of PoCTL, which is another important
inference problem of PoCTL.

</details>


### [844] [Proceedings of the Combined 32nd International Workshop on Expressiveness in Concurrency and 22nd Workshop on Structural Operational Semantics](https://arxiv.org/abs/2510.23211)
*Cinzia Di Giusto,Giorgio Bacci*

Main category: cs.LO

TL;DR: This volume contains the proceedings of EXPRESS/SOS 2025, a workshop on expressiveness in concurrency and structural operational semantics, held in Aarhus, Denmark.


<details>
  <summary>Details</summary>
Motivation: The workshop aims to bring together researchers interested in the formal semantics of systems and programming concepts, and in the expressiveness of computational models.

Method: The paper is a collection of proceedings from a workshop.

Result: The proceedings of EXPRESS/SOS 2025.

Conclusion: The workshop series serves as a platform for researchers in formal semantics and computational models.

Abstract: This volume contains the proceedings of EXPRESS/SOS 2025: the Combined 32nd
International Workshop on Expressiveness in Concurrency and the 22nd Workshop
on Structural Operational Semantics, which was held in Aarhus, Denmark, as an
affiliated workshop of CONFEST 2025. The EXPRESS/SOS workshop series aims at
bringing together researchers interested in the formal semantics of systems and
programming concepts, and in the expressiveness of computational models.

</details>


### [845] [Parametric Iteration in Resource Theories](https://arxiv.org/abs/2510.23413)
*Alessandro Di Giorgio,Pawel Sobocinski,Niels Voorneveld*

Main category: cs.LO

TL;DR: 许多算法都针对固定的但未指定的参数进行了优化，尤其是在密码学中，协议通常具有安全参数（例如秘密密钥的比特长度）。我们旨在更抽象的设置中捕捉这种现象，通过在马尔可夫范畴中的概率布尔电路上实例化参数化迭代构造，并为其配备合适的度量，来以组合方式通过渐近等价捕捉可忽略的概念。这使得我们能够使用图表推理来证明简单的密码学定理，例如，证明猜测随机生成的密钥的成功率可忽略不计。


<details>
  <summary>Details</summary>
Motivation: 在密码学等领域，算法通常依赖于固定的、未指定的参数（如安全参数）。本研究旨在抽象地处理这一现象。

Method: 引入一种通用的参数化迭代构造，并在概率布尔电路的马尔可夫范畴中进行实例化，结合合适的度量，通过渐近等价来定义和处理可忽略性，实现组合式处理。

Result: 通过图表推理，可以证明简单的密码学定理，例如猜测随机生成的密钥的成功率可以忽略不计。

Conclusion: 所提出的参数化迭代构造和基于渐近等价的可忽略性定义，为在抽象资源理论和密码学中进行组合式图表推理提供了有效的方法。

Abstract: Many algorithms are specified with respect to a fixed but unspecified
parameter. Examples of this are especially common in cryptography, where
protocols often feature a security parameter such as the bit length of a secret
key.
  Our aim is to capture this phenomenon in a more abstract setting. We focus on
resource theories -- general calculi of processes with a string diagrammatic
syntax -- introducing a general parametric iteration construction. By
instantiating this construction within the Markov category of probabilistic
Boolean circuits and equipping it with a suitable metric, we are able to
capture the notion of negligibility via asymptotic equivalence, in a
compositional way. This allows us to use diagrammatic reasoning to prove simple
cryptographic theorems -- for instance, proving that guessing a randomly
generated key has negligible success.

</details>


### [846] [On the entailment problem for DL-Lite$_{core}$ ontologies and conjunctive queries with negation](https://arxiv.org/abs/2510.23490)
*Jerzy Marcinkowski,Piotr Ostropolski-Nalewaja*

Main category: cs.LO

TL;DR: DL-Lite$_{core}$  वापरा不等式或安全否定考虑时的给定蕴含问题是不可判定的。


<details>
  <summary>Details</summary>
Motivation: 确定 DL-Lite$_{core}$  वापरा不等式或安全否定考虑时的给定蕴含问题的判定性。

Method: 通过证明该问题不可判定来分析 DL-Lite$_{core}$  वापरा不等式或安全否定考虑时的给定蕴含问题的判定性。

Result: DL-Lite$_{core}$  वापरा不等式或安全否定考虑时的给定蕴含问题是不可判定的。

Conclusion: DL-Lite$_{core}$  वापरा不等式或安全否定考虑时的给定蕴含问题是不可判定的。

Abstract: We show that the entailment problem, for a given entailment problem for
DL-Lite$_{core}$ ontology, and given conjunctive query with inequalities, is
undecidable.
  We also show that this problem remains undecidable if conjunctive queries
with safe negation are considered instead of conjunctive queries with
inequalities.

</details>


### [847] [Generalized Kantorovich-Rubinstein Duality beyond Hausdorff and Kantorovich](https://arxiv.org/abs/2510.23552)
*Paul Wild,Lutz Schröder,Karla Messing,Barbara König,Jonas Forster*

Main category: cs.LO

TL;DR:  Kantorovich-Rubinstein对偶在概率分布空间上，通过最优传输（耦合）和价格函数来定义度量，两者存在等价性。该理论已推广到范畴（functor）层面，分别称为Wasserstein Lifting和Kantorovich Lifting。虽然所有Wasserstein Lifting都可以表示为Kantorovich Lifting，但后者通常需要额外的模态（modalities）。本文提供了一个例子，说明在一般情况下无法避免使用额外的模态。当使用相同的模态时，我们称之为广义 Kantorovich-Rubinstein对偶，并成功证明了Lévy-Prokhorov距离和基于Hausdorff与Wasserstein距离的凸集度量在广义 Kantorovich-Rubinstein对偶下的等价性。


<details>
  <summary>Details</summary>
Motivation: 研究Wasserstein Lifting和Kantorovich Lifting之间的关系，特别是Kantorovich Lifting是否总能用与Wasserstein Lifting相同的模态表示，以及在何种条件下可以实现广义 Kantorovich-Rubinstein对偶。

Method: 通过构造一个反例，说明在一般情况下Kantorovich Lifting需要比Wasserstein Lifting更多的模态。然后，证明了Lévy-Prokhorov距离和结合Hausdorff与Wasserstein距离的凸集度量满足广义 Kantorovich-Rubinstein对偶。

Result: 1. 证明了一般情况下Kantorovich Lifting可能需要比Wasserstein Lifting更多的模态。 2. 证明了Lévy-Prokhorov距离满足广义 Kantorovich-Rubinstein对偶。 3. 证明了结合Hausdorff和Wasserstein距离的标准凸集度量满足广义 Kantorovich-Rubinstein对偶。

Conclusion: 尽管Kantorovich Lifting通常需要比Wasserstein Lifting更多的模态，但对于Lévy-Prokhorov距离和特定凸集度量，存在一种广义的 Kantorovich-Rubinstein对偶，其中两种 Lifting可以使用相同的模态。这表明在这些重要情况下，度量之间的对偶关系得到了简化和统一。

Abstract: The classical Kantorovich-Rubinstein duality guarantees coincidence between
metrics on the space of probability distributions defined on the one hand via
transport plans (couplings) and on the other hand via price functions. Both
constructions have been lifted to the level of generality of set functors, with
the coupling-based construction referred to as the Wasserstein lifting, and the
price-function-based construction as the Kantorovich lifting, both based on a
choice of quantitative modalities for the given functor. It is known that every
Wasserstein lifting can be expressed as a Kantorovich lifting; however, the
latter in general needs to use additional modalities. We give an example
showing that this cannot be avoided in general. We refer to cases in which the
same modalities can be used as satisfying the generalized
Kantorovich-Rubinstein duality. We establish the generalized
Kantorovich-Rubinstein duality in this sense for two important cases: The
L\'evy-Prokhorov distance on distributions, which finds wide-spread
applications in machine learning due to its favourable stability properties,
and the standard metric on convex sets of distributions that arises by
combining the Hausdorff and Wasserstein distances.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [848] [Structure-Aware Cooperative Ensemble Evolutionary Optimization on Combinatorial Problems with Multimodal Large Language Models](https://arxiv.org/abs/2510.21906)
*Jie Zhao,Kang Hao Cheong*

Main category: cs.NE

TL;DR: 使用基于图像的编码和多模态大语言模型（MLLMs）作为进化算子，通过图稀疏化、协同进化优化和集成策略来解决图结构组合优化问题，提高了解决方案的质量和可靠性。


<details>
  <summary>Details</summary>
Motivation: 传统的编码方案难以捕捉图结构组合问题的内在结构属性，而基于图像的编码和MLLMs可以更好地处理这些问题。

Method: 1.使用基于图像的编码来保留拓扑上下文。
2.利用多模态大语言模型（MLLMs）作为进化算子。
3.应用图稀疏化技术来简化网络可视化中的视觉混乱。
4.提出协同进化优化框架，以提高鲁棒性并减轻不同稀疏化视图的偏差。
5.引入集成策略来聚合不同布局配置的输出。

Result: 实验表明，该方法在MLLM驱动的进化优化中，在真实网络和各种任务上都提高了解决方案的质量和可靠性。

Conclusion: 所提出的方法能够有效地进行结构感知优化，克服了传统方法的局限性，并在图结构组合优化中取得了更好的性能。

Abstract: Evolutionary algorithms (EAs) have proven effective in exploring the vast
solution spaces typical of graph-structured combinatorial problems. However,
traditional encoding schemes, such as binary or numerical representations,
often fail to straightforwardly capture the intricate structural properties of
networks. Through employing the image-based encoding to preserve topological
context, this study utilizes multimodal large language models (MLLMs) as
evolutionary operators to facilitate structure-aware optimization over graph
data. To address the visual clutter inherent in large-scale network
visualizations, we leverage graph sparsification techniques to simplify
structures while maintaining essential structural features. To further improve
robustness and mitigate bias from different sparsification views, we propose a
cooperative evolutionary optimization framework that facilitates cross-domain
knowledge transfer and unifies multiple sparsified variants of diverse
structures. Additionally, recognizing the sensitivity of MLLMs to network
layout, we introduce an ensemble strategy that aggregates outputs from various
layout configurations through consensus voting. Finally, experiments on
real-world networks through various tasks demonstrate that our approach
improves both the quality and reliability of solutions in MLLM-driven
evolutionary optimization.

</details>


### [849] [Enabling Robust In-Context Memory and Rapid Task Adaptation in Transformers with Hebbian and Gradient-Based Plasticity](https://arxiv.org/abs/2510.21908)
*Siddharth Chaudhary*

Main category: cs.NE

TL;DR: 该研究探讨了为Transformer引入生物启发的突触可塑性，以实现比现有基于静态权重模型更快的序列内适应性。研究比较了两种引入的突触可塑性机制：神经调控的赫布规则和基于梯度的可塑性机制。结果表明，赫布规则在复制、回归和少样本分类任务上表现出更低的损失和更强的泛化能力，而基于梯度的更新在长期信用分配任务上表现更好。研究还发现，当关联性短且线性可分时，静态权重就足够了，这为可塑性有益的边界条件提供了清晰的界定。最后，研究分析了学习到的调质信号，发现基于梯度的规则会进行大量、持续的更新，而赫布可塑性则在显著事件周围进行门控。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在推理时依赖静态权重，而生物系统能够通过突触可塑性持续适应。本研究旨在探索是否可以通过显式的、受生物启发的突触可塑性来增强Transformer模型，使其在序列内具有更快的适应能力。

Method: 研究将两种突触可塑性机制（神经调控的赫布规则和基于梯度的可塑性机制）集成到仅解码器的Transformer模型中。通过在复制、回归和少样本分类（CIFAR-FS、Omniglot）等任务上进行实验来评估这些机制的效果。

Result: 赫布可塑性在复制、回归和少样本分类任务上持续表现出更低的损失和更强的少样本泛化能力。基于梯度的更新在长期信用分配任务上表现最佳。研究还确定了静态权重足以应对短关联且线性可分的情况，并分析了两种机制学习到的调质信号的差异：基于梯度的规则进行大量、持续的更新，而赫布可塑性在显著事件周围进行门控。

Conclusion: 显式的突触可塑性可以作为注意力机制的补充，实现快速、任务特定的适应性。研究阐明了不同可塑性机制在不同情况下的有效性，赫布可塑性在需要快速适应的任务中表现出色，而基于梯度的更新在长期信用分配任务中更优。当任务简单（短关联、线性可分）时，静态权重已经足够。

Abstract: Large language models display in-context learning as an emergent effect of
scale, but they rely on static weights during inference. In contrast,
biological systems continually adapt via synaptic plasticity. We investigate
whether explicit, biologically inspired plasticity can endow Transformers with
faster in-sequence adaptation. To this end, we augment decoder-only
Transformers with fast-weight modules updated either by (i) a neuromodulated
Hebbian rule or (ii) the gradient-based plasticity mechanism of Duan et al.
(2023). Across copying, regression, and few-shot classification tasks
(CIFAR-FS, Omniglot), Hebbian plasticity consistently achieves lower loss and
stronger few-shot generalization, while gradient-based updates perform best on
long-horizon credit assignment. When associations are short and linearly
separable, static weights suffice, defining a clear boundary condition for when
plasticity helps. Analysis of learned modulatory signals reveals that
gradient-based rules maintain large, persistent updates, whereas Hebbian
plasticity is sharply gated around salient events. Together, these results show
that explicit plasticity complements attention by enabling rapid, task-specific
adaptation, and clarify when different plasticity mechanisms are most
effective.

</details>


### [850] [Probing the Representational Geometry of Color Qualia: Dissociating Pure Perception from Task Demands in Brains and AI Models](https://arxiv.org/abs/2510.22800)
*Jing Xu*

Main category: cs.NE

TL;DR: AI模型在颜色感知方面与人脑的表征几何结构进行了比较，发现现有模型更符合纯感知状态，并揭示了训练范式和模型结构对神经可信度的关键相互作用。


<details>
  <summary>Details</summary>
Motivation: 探究主观体验（qualia）的计算基础，特别是颜色qualia在AI模型和人脑之间的表征几何结构。

Method: 使用“无报告”范式的fMRI数据集，并结合表征相似性分析（RSA），比较了多种视觉模型在纯感知和任务调节感知两种条件下的神经活动。

Result: 1. 几乎所有模型都与纯感知的神经表征更吻合，表明当前前馈模型未捕捉到任务执行的认知过程。 2. 对比语言-图像预训练（CLIP）训练范式与模型结构（ViT和ConvNet）的相互作用分析表明，CLIP训练对ViT有益，但对ConvNet则相反。

Conclusion: 颜色qualia的基准测试揭示了人工智能和生物视觉系统在归纳偏置上的根本分歧，并为开发更具神经可信度的模型提供了指导。

Abstract: Probing the computational underpinnings of subjective experience, or qualia,
remains a central challenge in cognitive neuroscience. This project tackles
this question by performing a rigorous comparison of the representational
geometry of color qualia between state-of-the-art AI models and the human
brain. Using a unique fMRI dataset with a "no-report" paradigm, we use
Representational Similarity Analysis (RSA) to compare diverse vision models
against neural activity under two conditions: pure perception ("no-report") and
task-modulated perception ("report"). Our analysis yields three principal
findings. First, nearly all models align better with neural representations of
pure perception, suggesting that the cognitive processes involved in task
execution are not captured by current feedforward architectures. Second, our
analysis reveals a critical interaction between training paradigm and
architecture, challenging the simple assumption that Contrastive Language-Image
Pre-training(CLIP) training universally improves neural plausibility. In our
direct comparison, this multi-modal training method enhanced brain-alignment
for a vision transformer(ViT), yet had the opposite effect on a ConvNet. Our
work contributes a new benchmark task for color qualia to the field, packaged
in a Brain-Score compatible format. This benchmark reveals a fundamental
divergence in the inductive biases of artificial and biological vision systems,
offering clear guidance for developing more neurally plausible models.

</details>


### [851] [Graph Neural Network Assisted Genetic Algorithm for Structural Dynamic Response and Parameter Optimization](https://arxiv.org/abs/2510.22839)
*Sagnik Mukherjee*

Main category: cs.NE

TL;DR: 本研究提出一种混合数据驱动框架，结合图神经网络（GNN）代理模型和遗传算法（GA）优化器，用于优化结构参数（质量m、刚度k、阻尼系数c），以克服传统数值方法计算成本高昂的限制。


<details>
  <summary>Details</summary>
Motivation: 优化结构参数（质量m、刚度k、阻尼系数c）对于设计高效、有弹性且稳定的结构至关重要，但传统数值方法（如有限元法和计算流体动力学）在迭代优化任务中计算成本高昂。

Method: 提出一个混合数据驱动框架，该框架集成了一个图神经网络（GNN）代理模型和一个遗传算法（GA）优化器。GNN用于学习结构参数与动态位移响应之间的非线性映射，而GA则通过最小化预测位移和增强动态稳定性来搜索全局最优参数集。

Result: 结果表明，GNN和GA框架实现了良好的收敛性、鲁棒的泛化能力，并显著降低了计算成本，与传统模拟相比。

Conclusion: 本研究证明了将机器学习代理模型与进化优化相结合，用于自动化和智能结构设计的有效性。

Abstract: The optimization of structural parameters, such as mass(m), stiffness(k), and
damping coefficient(c), is critical for designing efficient, resilient, and
stable structures. Conventional numerical approaches, including Finite Element
Method (FEM) and Computational Fluid Dynamics (CFD) simulations, provide
high-fidelity results but are computationally expensive for iterative
optimization tasks, as each evaluation requires solving the governing equations
for every parameter combination. This study proposes a hybrid data-driven
framework that integrates a Graph Neural Network (GNN) surrogate model with a
Genetic Algorithm (GA) optimizer to overcome these challenges. The GNN is
trained to accurately learn the nonlinear mapping between structural parameters
and dynamic displacement responses, enabling rapid predictions without
repeatedly solving the system equations. A dataset of single-degree-of-freedom
(SDOF) system responses is generated using the Newmark Beta method across
diverse mass, stiffness, and damping configurations. The GA then searches for
globally optimal parameter sets by minimizing predicted displacements and
enhancing dynamic stability. Results demonstrate that the GNN and GA framework
achieves strong convergence, robust generalization, and significantly reduced
computational cost compared to conventional simulations. This approach
highlights the effectiveness of combining machine learning surrogates with
evolutionary optimization for automated and intelligent structural design.

</details>


### [852] [One-Timestep is Enough: Achieving High-performance ANN-to-SNN Conversion via Scale-and-Fire Neurons](https://arxiv.org/abs/2510.23383)
*Qiuyang Chen,Huiqi Yang,Qingyan Meng,Zhengyu Ma*

Main category: cs.NE

TL;DR: 本文提出了一种名为Scale-and-Fire Neuron (SFN)的单时间步脉冲神经网络（SNN）转换框架，通过引入多阈值神经元（MTN）实现了高效的单时间步推理，并在图像分类、目标检测和实例分割等任务上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有脉冲神经网络（SNN）的转换方法（ANN-to-SNN）虽然精度高，但需要较大的时间步长，导致推理延迟和计算成本高。因此，有必要开发一种能在单个时间步内完成转换的方法。

Method: 提出“时空等价理论”，证明了多时间步整合发放（IF）神经元可以用单时间步多阈值神经元（MTN）等效替换。在此基础上，设计了Scale-and-Fire Neuron（SFN），实现了单时间步（T=1）脉冲发放。进一步开发了基于SFN的Spiking Transformer（SFormer），并将脉冲模式与注意力分布对齐，以降低多阈值设计的计算、能耗和硬件开销。

Result: 在ImageNet-1K图像分类任务上，T=1时取得了88.8%的top-1准确率，优于现有转换方法。在目标检测和实例分割任务上也取得了最先进的性能。

Conclusion: 所提出的单时间步ANN到SNN转换框架在精度、计算效率和能耗方面都优于现有方法，特别是在资源受限的环境下具有潜力。

Abstract: Spiking Neural Networks (SNNs) are gaining attention as energy-efficient
alternatives to Artificial Neural Networks (ANNs), especially in
resource-constrained settings. While ANN-to-SNN conversion (ANN2SNN) achieves
high accuracy without end-to-end SNN training, existing methods rely on large
time steps, leading to high inference latency and computational cost. In this
paper, we propose a theoretical and practical framework for single-timestep
ANN2SNN. We establish the Temporal-to-Spatial Equivalence Theory, proving that
multi-timestep integrate-and-fire (IF) neurons can be equivalently replaced by
single-timestep multi-threshold neurons (MTN). Based on this theory, we
introduce the Scale-and-Fire Neuron (SFN), which enables effective
single-timestep ($T=1$) spiking through adaptive scaling and firing.
Furthermore, we develop the SFN-based Spiking Transformer (SFormer), a
specialized instantiation of SFN within Transformer architectures, where spike
patterns are aligned with attention distributions to mitigate the
computational, energy, and hardware overhead of the multi-threshold design.
Extensive experiments on image classification, object detection, and instance
segmentation demonstrate that our method achieves state-of-the-art performance
under single-timestep inference. Notably, we achieve 88.8% top-1 accuracy on
ImageNet-1K at $T=1$, surpassing existing conversion methods.

</details>


### [853] [Multi-Task Surrogate-Assisted Search with Bayesian Competitive Knowledge Transfer for Expensive Optimization](https://arxiv.org/abs/2510.23407)
*Yi Lu,Xiaoming Xue,Kai Zhang,Liming Zhang,Guodong Chen,Chenming Cao,Piyang Liu,Kay Chen Tan*

Main category: cs.NE

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Expensive optimization problems (EOPs) present significant challenges for
traditional evolutionary optimization due to their limited evaluation calls.
Although surrogate-assisted search (SAS) has become a popular paradigm for
addressing EOPs, it still suffers from the cold-start issue. In response to
this challenge, knowledge transfer has been gaining popularity for its ability
to leverage search experience from potentially related instances, ultimately
facilitating head-start optimization for more efficient decision-making.
However, the curse of negative transfer persists when applying knowledge
transfer to EOPs, primarily due to the inherent limitations of existing methods
in assessing knowledge transferability. On the one hand, a priori
transferability assessment criteria are intrinsically inaccurate due to their
imprecise understandings. On the other hand, a posteriori methods often
necessitate sufficient observations to make correct inferences, rendering them
inefficient when applied to EOPs. Considering the above, this paper introduces
a Bayesian competitive knowledge transfer (BCKT) method developed to improve
multi-task SAS (MSAS) when addressing multiple EOPs simultaneously.
Specifically, the transferability of knowledge is estimated from a Bayesian
perspective that accommodates both prior beliefs and empirical evidence,
enabling accurate competition between inner-task and inter-task solutions,
ultimately leading to the adaptive use of promising solutions while effectively
suppressing inferior ones. The effectiveness of our method in boosting various
SAS algorithms for both multi-task and many-task problems is empirically
validated, complemented by comparative studies that demonstrate its superiority
over peer algorithms and its applicability to real-world scenarios. The source
code of our method is available at https://github.com/XmingHsueh/MSAS-BCKT.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [854] [Vertex and front-tracking methods for the modeling of microstructure evolution at the solid state: a brief review](https://arxiv.org/abs/2510.21818)
*Marc Bernacki*

Main category: cond-mat.mtrl-sci

TL;DR: Front-tracking (FT) models explicitly define interfaces, offering high spatial resolution and adaptability to interface-related physics, despite challenges in handling complex 3D topology.


<details>
  <summary>Details</summary>
Motivation: The paper aims to discuss the Front-Capturing (FC) and Front-Tracking (FT) numerical frameworks for mesoscopic scale microstructure evolution modeling, highlighting the advantages and disadvantages of FT models.

Method: The paper discusses historical FT methodologies, specifically Vertex models, and their evolution. It also touches upon techniques from finite element meshing and remeshing algorithms used in FT approaches, and mentions recent advances in computational efficiency and analysis of mobility and energy properties.

Result: FT models, particularly recent advances, show potential in computational efficiency and analysis of mobility and energy properties, with possible applications in intragranular phenomena. They offer enhanced spatial resolution in 3D surfacic and 2D lineic problems.

Conclusion: FT models are well-adapted to physical mechanisms correlated to interface properties and geometries and are computationally efficient, but they face challenges in managing complex topological events, especially in 3D.

Abstract: In mesoscopic scale microstructure evolution modeling, two primary numerical
frameworks are used: Front-Capturing (FC) and Front-Tracking (FT) ones. FC
models, like phase-field or level-set methods, indirectly define interfaces by
tracking field variable changes. On the contrary, FT models explicitly define
interfaces using interconnected segments or surfaces. In historical FT
methodologies, Vertex models were first developed and consider the description
of the evolution of polygonal structures in terms of the motion of points where
multiple boundaries meet. Globally, FT-type approaches, often associated with
Lagrangian movement, enhance spatial resolution in 3D surfacic and 2D lineic
problems using techniques derived from finite element meshing and remeshing
algorithms. These efficient approaches, by nature, are well adapted to physical
mechanisms correlated to interface properties and geometries. They also face
challenges in managing complex topological events, especially in 3D. However,
recent advances highlight their potential in computational efficiency and
analysis of mobility and energy properties, with possible applications in
intragranular phenomena.

</details>


### [855] [Interlayer Pores Play a Limited Role in Diffusion Through Hydrated Na-MMT: Insights from a Multiscale, Experimentally Anchored Model](https://arxiv.org/abs/2510.21880)
*Yaoting Zhang,Mikaella Brillantes,Justine Kuczera,Keyvan Ferasat,Mia L. San Gabriel,Scott Briggs,Chang Seok Kim,George Opletal,Yuankai Yang,Jane Howe,Laurent K. Beland*

Main category: cond-mat.mtrl-sci

TL;DR: 水和离子在钠基蒙脱石中的扩散主要发生在自由孔隙中，并且扩散方向具有各向异性。


<details>
  <summary>Details</summary>
Motivation: 研究钠基蒙脱石（Na-MMT）的层间扩散动力学，重点关注不同干密度下水和离子通过层间孔隙和自由孔隙的扩散情况。

Method: 构建了一个多尺度计算框架，结合了原子尺度模拟和介尺度模拟，考虑了实验确定的片状物尺寸分布、多分散性和各向异性传输。

Result: 结果表明，在研究的干密度范围内，层间孔隙对整体水分扩散的贡献很小。水分扩散主要通过自由孔隙进行，扩散尺度因子与考虑了层间节流的实验氚示踪剂测量结果吻合。研究还强调了Na-MMT中扩散的各向异性，平行于压实方向的扩散比垂直方向慢得多。计算模型在晶格玻尔兹曼模拟和实验数据方面得到了验证。

Conclusion: 该计算模型为理解Na-MMT中的纳米限制扩散提供了有力的框架，尽管存在一些局限性。未来的工作将集中于改进层间能量剖面和考虑柔性片状物动力学，以提高预测准确性，并为优化环境、工业和生物医学应用中的材料提供参考。

Abstract: This study investigates the interlayer diffusion dynamics in sodium
montmorillonite (Na-MMT), a smectite clay with significant applications in
environmental science, pharmaceuticals, and advanced materials. We present a
multiscale computational framework that integrates atomistic simulations with
mesoscale modelling to explore the influence of interlayer and free pores on
water and ion diffusion under varying dry densities (0.8--1.3 g/cm$^3$). The
model incorporates experimentally determined platelet size distributions and
explicitly accounts for polydispersity and anisotropic transport. The study
results reveal that interlayer pores contribute minimally to overall water
diffusion at the studied dry densities. Water diffusion predominantly occurs
through free pores, with diffusion scaling factors closely aligning with
experimental tritium tracer measurements when interlayer throttling was
considered. The study also highlights the anisotropic nature of diffusion in
Na-MMT, with diffusion parallel-to-compaction being significantly slower than
in the normal direction which is consistent with experiments. The computational
model, validated against lattice Boltzmann simulations and experimental data,
provides insights into the geometric tortuosity and pore size distribution of
Na-MMT. Despite its limitations, such as the absence of three-water minima
energy profiles and rigid platelet assumptions, the model offers a robust
framework for understanding nanoconfined diffusion. Future work will focus on
refining interlayer energy profiles and incorporating flexible platelet
dynamics to enhance predictive accuracy with implications for optimizing
materials in environmental, industrial, and biomedical applications.

</details>


### [856] [Altermagnetism, Kagome Flat Band, and Weyl Fermion States in Magnetically Intercalated Transition Metal Dichalcogenides](https://arxiv.org/abs/2510.21968)
*Avinash Sah,Ting-Yong Lim,Clayton Conner,Amarnath Chakraborty,Giovanni Vignale,Tay-Rong Chang,Pavlo Sukhachov,Guang Bian*

Main category: cond-mat.mtrl-sci

TL;DR: 几种新型的磁性插层过渡金属硫属化物（TMD）XY4Z8（X=Mn、Fe、Co、Ni、Cr或V；Y=Nb或Ta；Z=Se或S）被确定为具有潜力的反常磁性（AM）候选材料。


<details>
  <summary>Details</summary>
Motivation: 探索具有非传统量子相位的磁性插层过渡金属硫属化物（TMD），利用其在零净磁化下的独特自旋分裂能带结构。

Method: 进行第一性原理计算，研究XY4Z8（X=Mn、Fe、Co、Ni、Cr或V；Y=Nb或Ta；Z=Se或S）的磁性行为。

Result: 发现A型反铁磁序的系统表现出与AM行为一致的动量依赖性自旋分裂，并产生了外尔节点及其相应的拓扑费米弧表面态。此外，观察到近费米能级的平带，这源于插层诱导的TMD层中有效的kagome样子晶格的形成。。

Conclusion: 磁性插层TMD是工程化反常磁性、平带和外尔费米子的有前景的平台，有助于开发拓扑和自旋电子学应用。

Abstract: Altermagnetic (AM) compounds have recently emerged as a promising platform
for realizing unconventional quantum phases, enabled by their unique spin-split
band structure at zero net magnetization. Here, we present a first-principles
investigation of magnetically intercalated transition metal dichalcogenides
(TMDs) of the form XY$_4$Z$_8$ (X $=$ Mn, Fe, Co, Ni, Cr, or V; Y $=$ Nb or Ta;
and Z $=$ Se or S), identifying a subset of new versatile AM candidates. Our
results establish a direct correlation between interatomic geometry, quantified
by the ratio of interlayer to intralayer spacing, and the selection of magnetic
ground states. Systems with A-type antiferromagnetic order exhibit
momentum-dependent spin splitting consistent with AM behavior. Crucially, the
combination of the AM spin-splitting and the spin-orbit coupling leads to the
emergence of Weyl nodes together with the corresponding topological Fermi arc
surface states. Moreover, we identify flat bands near the Fermi level that
originate from the intercalant-induced formation of an effective kagome-like
sublattice in the TMD layer. These results collectively establish magnetically
intercalated TMDs as a promising platform for engineering altermagnetism, flat
bands, and Weyl fermions within a single material family, facilitating the
development of topological and spintronic applications.

</details>


### [857] [All-Altermagnetic Tunnel Junction of RuO2/NiF2/RuO2](https://arxiv.org/abs/2510.23269)
*Long Zhang,Guoying Gao*

Main category: cond-mat.mtrl-sci

TL;DR: 提出了一种全交替磁体隧道结（AAMTJ）范式，使用RuO2/NiF2/RuO2作为例子，实现了巨大的隧道磁阻（11704%）和高自旋过滤（~90%），并可调的多状态磁阻和自旋过滤，以及低功耗和无杂散场。


<details>
  <summary>Details</summary>
Motivation: 目前的磁性隧道结在集成交替磁体时存在杂散场或功能有限的问题，因此需要一种新的范式。

Method: 提出并实验验证了一种由RuO2/NiF2/RuO2组成的AAMTJ。

Result: 实现了11704%的巨大隧道磁阻，~90%的高自旋过滤，以及可调的多状态磁阻和自旋过滤。

Conclusion: AAMTJ范式提供了一个多功能的平台，用于开发可重构磁性存储器。

Abstract: Emerging altermagnets offer a promising avenue for spintronics, yet their
integration into magnetic tunnel junctions has been hindered by reliance on
ferromagnetic electrodes (introducing stray fields) or limited functionality
(non-tunable magnetoresistance without spin filtering). Here, we propose an
all-altermagnetic tunnel junction (AAMTJ) paradigm composed exclusively of
altermagnets-exemplified by experiment-feasible RuO2/NiF2/RuO2. Giant tunneling
magnetoresistance of 11704%, and high spin-filtering of ~90% in both spin
channels are achieved. This architecture unlocks tunable multistate
magnetoresistance and spin filtering via magnetization control of electrode and
barrier, stemming from their synergistic and antagonistic alignments of
momentum-dependent altermagnetic spin-splitting. Our AAMTJ inherently exhibits
low consumption and no stray field, with nonrelativistic spin splitting and
zero magnetic moment, combining advantages of both ferromagnetic and
antiferromagnetic tunnel junctions. This AAMTJ paradigm provides a
realistically versatile platform to develop revolutionarily potential of
altermagnets for reconfigurable magnetic memory devices.

</details>


### [858] [Magnetic transition in B2 Al-Cr-Co alloys](https://arxiv.org/abs/2510.21982)
*Haireguli Aihemaiti,Esmat Dastanpour,Shashank Chaturvedi,Shuo Huang,Anders Bergman,Levente Vitos*

Main category: cond-mat.mtrl-sci

TL;DR: 密度泛函理论(DFT)计算和蒙特卡洛(MC)模拟研究了B2 Al-Cr-Co合金中的磁性转变。


<details>
  <summary>Details</summary>
Motivation: 研究最近报道的B2 Al-Cr-Co合金中的磁性转变。

Method: 使用密度泛函理论(DFT)计算和蒙特卡洛(MC)模拟，在海森堡哈密顿框架下分析了Cr亚点阵中掺杂不同量Co的抗磁性(AFM) B2 AlCr二元合金的交换相互作用。

Result: DFT结果表明，在低Co浓度下系统倾向于AFM有序，而在高Co含量下观察到向铁磁性(FM)状态的转变。在FM稳定性场内，居里温度(TC)低于约160 K，并随Co浓度降低。MC模拟得到的磁构型在低Cr含量下与DFT结果一致，但在Cr亚点阵中含Co量超过40 at.%的合金中预测出现自旋玻璃行为。

Conclusion: 研究结果为理解化学驱动的交换相互作用变化如何影响B2 Al-Cr-Co合金中的磁性提供了基础。

Abstract: Using Density Functional Theory (DFT) calculations and Monte-Carlo (MC)
simulations, we investigate the recently reported magnetic transition in B2
Al-Cr-Co alloys. The Cr sublattice is alloyed with different amounts of Co in
the antiferromagnetic (AFM) B2 AlCr binary alloy and the resulting exchange
interactions are analyzed within the Heisenberg Hamiltonian framework. DFT
results reveal that at low Co concentrations the system favors the AFM order,
while at high Co contents a transition to the ferromagnetic (FM) state is
observed. Within the FM stability field, the Curie temperature (TC), obtained
within the mean-field approximation, is below ~160 K and decreases with Co
concentration. The calculated exchange parameters evolve systematically with Co
content, and the trends are consistent with the DFT total energies. The
magnetic configurations obtained from MC simulations follow the DFT results at
low Cr levels but predict a spin-glass behavior for alloys containing more than
40 at.% Co on Cr sublattice. These findings provide a fundamental understanding
of how the chemistry-driven changes in exchange interactions affect magnetism
in the B2 Al-Cr-Co alloys.

</details>


### [859] [First-principles study of phase stability and magnetic properties of B2 AlCr, AlMn, AlFe, AlCo and AlNi aluminides](https://arxiv.org/abs/2510.22013)
*Haireguli Aihemaiti,Esmat Dastanpour,Anders Bergman,Levente Vitos*

Main category: cond-mat.mtrl-sci

TL;DR: 本文使用第一性原理密度泛函理论（DFT）计算，研究了Al和3d磁性过渡元素（Cr, Mn, Fe, Co, Ni）形成的等原子二元合金的电子结构、相稳定性和磁性。


<details>
  <summary>Details</summary>
Motivation: 研究Al和3d磁性过渡元素（Cr, Mn, Fe, Co, Ni）形成的等原子二元合金的电子结构、相稳定性和磁性，以理解其形成机制和性质。

Method: 使用第一性原理密度泛函理论（DFT）计算，并结合基于海森堡哈密顿量的磁性模拟。

Result: 所有五种二元铝化物在有序B2相中的稳定性均高于无序体心立方相，其中Co是与Al形成B2相最强的元素。AlCo和AlNi在B2结构中是非磁性的，而AlFe表现为弱磁性。假设的B2 AlCr具有反铁磁基态，而掺杂Co则会导致反铁磁向铁磁转变，且铁磁性主要归因于Cr原子。

Conclusion: 电子结构论证了解释了相稳定性和磁性趋势。研究结果加深了对AlX二元合金相稳定性和磁性的理解，并为B2结构与3d磁性过渡金属的形成机制提供了见解。

Abstract: Using ab initio Density Functional Theory (DFT) calculations, we investigate
the electronic structure, phase stability, and magnetic properties of
equiatomic binary alloys between Al and 3d magnetic transition elements (Cr,
Mn, Fe, Co, and Ni). Thermodynamically, all five binary aluminides are more
stable in the ordered B2 phase than in the disordered body centered cubic
phase, and Co is found to be the strongest B2 forming element with Al. The AlCo
and AlNi compounds with B2 structure are verified to be non-magnetic, whereas
AlFe turns out to be weakly magnetic, which is consistent with other DFT
calculations employing similar exchange-correlation approximations. Magnetic
simulations based on the Heisenberg Hamiltonian predict an antiferromagnetic
ground state for the hypothetical B2 AlCr, which is also confirmed by direct
DFT calculations. Doping AlCr with Co leads to an antiferromagnetic to
ferromagnetic transition, where ferromagnetism is to a large extent attributed
to Cr atoms. The phase stability and magnetic trends are explained using
electronic structure arguments. The present findings contribute to a deeper
understanding of the phase stability and magnetic properties of AlX binary
alloys, providing insights into the formation mechanisms of the B2 structure
with 3d magnetic transition metals.

</details>


### [860] [Unravelling the oxygen influence in cubic bixbyite In$_2$O$_3$ on Raman active phonon modes by isotope studies](https://arxiv.org/abs/2510.22018)
*Johannes Feldl,Roland Gillen,Janina Maultzsch,Alexandra Papadogianni,Joe Kler,Zbigniew Galazka,Oliver Bierwagen,Manfred Ramsteiner*

Main category: cond-mat.mtrl-sci

TL;DR: 氧化铟立方双晶结构中拉曼活性声子模式的同位素效应


<details>
  <summary>Details</summary>
Motivation: 研究氧化铟的晶格动力学和拉曼活性声子模式，特别是氧同位素对其频率的影响。

Method: 使用密度泛函微扰理论计算不同氧同位素比例（$^{16}$O和$^{18}$O）下的声子模式，并通过拉曼光谱和飞行时间二次离子质谱进行实验验证。

Result: 所有模式的频率随着$^{18}$O含量的增加而红移。其中15个高能模式的红移约为5.5%，而7个低能模式的红移低于1%。所有模式均包含In和O原子的贡献，但有一个纯O振动模式。实验结果与计算结果吻合良好。

Conclusion: 氧同位素效应可用于实验研究氧化铟的基本材料特性。此外，推测氧空位可能导致主导O振动的模式（如$E_{g}^{(4)}$或$A_{g}^{(4)}$）向低频移动。

Abstract: In this study, we performed comprehensive investigations on the Raman active
phonon modes in cubic bixbyite In$_2$O$_3$, an important oxide based,
wide-bandgap semiconductor. Fundamental insights into the lattice dynamics are
revealed, by determining the atomistic contribution to all modes and their
frequencies by density functional perturbation theory calculations. Those
simulations were performed for different compositions of $^{16}$O and $^{18}$O
isotope ratios, including their pure states. An increasing red-shift of the
mode frequencies with increasing $^{18}$O content for all modes, due to the
increased atomic mass, is revealed. For the seven lowest energy modes, this
relative shift is below 1%, whereas for the remaining 15 higher energetic modes
a shift of about 5.5% was identified. All modes have energy contributions of
both indium and oxygen lattice sites, except for one, which corresponds to a
pure oxygen vibrational state. Applying Raman spectroscopy, those results could
be verified experimentally with excellent agreement. Investigated samples
consisted of a bulk single crystal with $^{16}$O isotopes and a MBE grown thin
film as the $^{18}$O sample. Time-of-flight secondary ion mass spectrometry
confirms the purity of the oxygen isotope in the sample. These isotopologue
studies allow for a direct experimental access to fundamental material
properties in cubic In$_2$O$_3$ by means of Raman spectroscopy. For example, we
speculate, that the presence of oxygen vacancies in In$_2$O$_3$ would result in
a shift of modes that are dominated by O-vibrations, e. g., $E_{g}^{(4)}$ or
$A_{g}^{(4)}$, towards lower frequencies.

</details>


### [861] [Highly Tunable Phonon Polaritons via Metal Intercalation](https://arxiv.org/abs/2510.22019)
*Mariia Stepanova,Minh Ngo,Mashnoon Alam Sakib,Wills Harris,Joshua Bocanegra,Ruqian Wu,Kristie J. Koski,Maxim R. Shcherbakov*

Main category: cond-mat.mtrl-sci

TL;DR: 通过在α-MoO3的范德华层间插入零价金属（如锡），可以大幅调控其声子极化激子色散，从而为可重构的中红外纳米光子学提供新的途径。


<details>
  <summary>Details</summary>
Motivation: 尽管声子极化激子在纳米光子学领域具有巨大潜力，但其色散不易调控限制了其实际应用。

Method: 通过在α-MoO3的范德华层间插入零价金属（如锡）进行插层，并利用光诱导力显微镜研究其对声子极化激子色散的影响。

Result: 研究发现，锡插层可将声子极化激子色散调制高达38.5±0.5%，且保持了声子极化激子的寿命，并与理论计算结果一致。

Conclusion: 金属插层是一种可行的方法，可以实现对声子极化激子的精确控制，为开发可重构的中红外纳米光子器件提供了新的解决方案。

Abstract: Phonon polaritons in van der Waals crystals offer mid-infrared light
confinement deep below the diffraction limit, making them promising for
nanophotonics applications. However, the practical use of phonon polaritons
remains limited, in part due to the lack of precise control over the phonon
polariton dispersion, as crystal lattice vibrations are often inert to external
stimuli. Here, we address this challenge by zerovalent metal intercalation of
$\alpha$-MoO$_3$. Photo-induced force microscopy shows that introducing tin
into the van der Waals gap modulates the phonon polariton dispersion by up to
$38.5\pm0.5\%$, which is the highest amount of tunability among non-mechanical
modulation approaches, to the best of our knowledge. Intercalation with various
metal species preserves the phonon polariton lifetimes, while modulating the
dielectric permittivity in agreement with the density functional theory and
analytical calculations. Our results establish metal intercalation as a
practical route to reconfigurable mid-infrared nanophotonics.

</details>


### [862] [Nonlinear phononic slidetronics](https://arxiv.org/abs/2510.22036)
*Pooja Rani,Dominik M. Juraschek*

Main category: cond-mat.mtrl-sci

TL;DR: 超快激光脉冲可以用于切换范德华铁电材料中的铁电性质，但需要很高的能量。本文研究了双层六方氮化硼（h-BN）中的铁电切换，发现通过非线性激发声子可以实现切换。


<details>
  <summary>Details</summary>
Motivation: 介绍范德华铁电材料的切换机制，并指出传统方法（如剪切模式和高能量激光脉冲）的局限性。

Method: 研究了双层六方氮化硼（h-BN）中的铁电切换。通过非线性激发声子，特别是高频层内模式，导致层间势能景观倾斜，从而实现堆叠顺序的改变。

Result: 与传统的声子激发机制（如红外吸收和拉曼散射）相比，非线性激发声子在克服能量壁垒方面效率更高，能够实现铁电切换。

Conclusion: 研究结果为高效的声子滑移电子学提供了新的途径，有望实现对范德华材料堆叠顺序的超快控制。

Abstract: Van der Waals ferroelectrics are conventionally switched by sliding the
different layers between stacking orders with opposing electric polarizations.
Ultrashort laser pulses have been proposed to launch shear modes and induce
switching, with often unfeasible large pulse energies however. Here, we
demonstrate switching of ferroelectricity in bilayer hexagonal boron nitride
through nonlinearly excited phonons. We show that the efficiencies of
conventional coherent phonon excitation mechanisms, including infrared
absorption and Raman scattering techniques, are too low to overcome the energy
barrier separating the two ferroelectric states. We demonstrate instead that
excitation of high-frequency intralayer modes leads to a tilting of the
interlayer potential-energy landscape that enables changing the stacking order.
Our results provide an avenue towards efficient phononic slidetronics, enabling
ultrafast control of the stacking order in van der Waals materials.

</details>


### [863] [Highly Efficient Functionalization of hBN with Lithium Oxalate: A Multifunctional Platform for Composites, Ion Transport, and Spin Labeling](https://arxiv.org/abs/2510.22041)
*Bence G. Márkus,Anna Nyáry,Dávid Beke,Sivaviswa Radhakrishnan,Vignyatha R. Tatagari,Bradlee J. McIntosh,Changlong Chen,Balázs Zsirka,Mandefro Y. Teferi,Jens Niklas,Oleg G. Poluektov,Ira D. Bloom,Fulya Dogan,Margit Kovács,Ferenc Simon,Gábor Szalontai,Leon Shaw,László Forró,Károly Németh*

Main category: cond-mat.mtrl-sci

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The development of multifunctional solid-state materials is key to advancing
lithium-ion batteries with enhanced safety and simplified architectures. Here,
we report a scalable, highly efficient (near $100\%$), solvent-free
mechanochemical synthesis of hexagonal boron nitride (hBN) functionalized with
lithium oxalate (Li$_2$C$_2$O$_4$), yielding a novel lamellar composite that
functions both as a lithium-ion conductor and separator. The high-energy
milling process promotes exfoliation of hBN and covalent attachment of oxalate
groups at edge and defect sites, forming a brown, nanocrystalline material with
uniform lithium distribution. The composite exhibits room-temperature ionic and
negligible electronic conductivity, thermal stability at least up to
$350~^{\circ}$C, and hosts stable free radicals enabling its use as a spin
label. The synthesis produces no byproducts and can be extended towards lithium
doping via secondary mechanochemical steps, creating highly doped, chemically
stable phases that host additional Li for ionic conduction. These results
introduce a new class of lithium-rich, boron nitride-based solids for
solid-state batteries, combining ion conduction, mechanical robustness, and
thermal resilience in a single material platform.

</details>


### [864] [Dynamics and formation of antiferromagnetic textures in MnBi$_2$Te$_4$ single crystal](https://arxiv.org/abs/2510.22051)
*M. G. Kim,S. Boney,L. Burgard,L. Rutowski,C. Mazzoli*

Main category: cond-mat.mtrl-sci

TL;DR: 该论文使用相干X射线成像技术首次直接观察了反铁磁拓扑绝缘体MnBi₂Te₄中的反铁磁畴和畴壁。


<details>
  <summary>Details</summary>
Motivation: 为了直接可视化反铁磁畴和畴壁，并研究其在MnBi₂Te₄中的行为。

Method: 使用相干X射线成像技术。

Result: 成功解析了畴壁的形貌，并测得畴壁宽度为550(30) nm。观察到畴和畴壁在冷却和升温过程中表现出显著的磁滞现象，在冷却过程中在T<0xE2><0x82><0x99>以下1K的窄区间内发生动态重组，而在升温过程中则基本保持不变，直到反铁磁序消失。

Conclusion: MnBi₂Te₄的能量景观复杂，受交换、各向异性和畴壁能量相互作用的控制。反铁磁畴壁动力学在塑造其物理性质方面起着关键作用。

Abstract: We report coherent X-ray imaging of antiferromagnetic (AFM) domains and
domain walls in MnBi$_2$Te$_4$, an intrinsic AFM topological insulator. This
technique enables direct visualization of domain morphology without
reconstruction algorithms, allowing us to resolve antiphase domain walls as
distinct dark lines arising from the A-type AFM structure. The wall width is
determined to be 550(30) nm, in good agreement with earlier magnetic force
microscopy results. The temperature dependence of the AFM order parameter
extracted from our images closely follows previous neutron scattering data.
Remarkably, however, we find a pronounced hysteresis in the evolution of
domains and domain walls: upon cooling, dynamic reorganizations occur within a
narrow $\sim$1 K interval below $T_N$, whereas upon warming, the domain
configuration remains largely unchanged until AFM order disappears. These
findings reveal a complex energy landscape in MnBi$_2$Te$_4$, governed by the
interplay of exchange, anisotropy, and domain-wall energies, and underscore the
critical role of AFM domain-wall dynamics in shaping its physical properties.

</details>


### [865] [Machine Learning Enables Optimization of Diamond for Quantum Applications](https://arxiv.org/abs/2510.22121)
*Dane W. deQuilettes,Eden Price,Linh M. Pham,Arthur Kurlej,Swaroop Vattam,Alexander Melville,Tom Osadchy,Boning Li,Guoqing Wang,Collin N. Muniz,Paola Cappellaro,Jennifer M. Schloss,Justin L. Mallek,Danielle A. Braje*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究利用监督学习和贝叶斯优化技术，通过分析100多个量子金刚石样品数据，识别出关键生长参数，显著提升了金刚石中NV$^-$色心用于高灵敏度磁力测量的性能。


<details>
  <summary>Details</summary>
Motivation: 金刚石中的色心（如NV$^-$和SiV$^-$）在量子技术领域具有巨大潜力，但其生长条件的优化极具挑战性，难以依靠直觉进行。

Method: 研究采用监督机器学习训练回归模型，并结合贝叶斯优化技术，使用电子辐照剂量、种子深度、种子倾斜角度和反应器氮浓度等参数，以NV$^-$磁力测量优值函数（FOM）为依据，优化生长条件。

Result: 通过优化，所制备的样品在磁场灵敏度FOM方面比平均样品提高了300%，比之前的最优样品提高了55%。Shapley重要性分析揭示了电子辐照剂量、种子深度、种子倾斜角度和反应器氮浓度是影响量子性能的关键参数。

Conclusion: 机器学习和贝叶斯优化方法能够有效指导金刚石生长条件的优化，实现量子器件性能的显著提升，并提供对关键生长参数的物理解释。这为未来定制化金刚石材料以满足特定量子应用需求提供了有力工具。

Abstract: Spins in solid-state materials, molecules, and other chemical systems have
the potential to impact the fields of quantum sensing, communication,
simulation, and computing. In particular, color centers in diamond, such as
negatively charged nitrogen vacancy (NV$^-$) and silicon vacancy centers
(SiV$^-$), are emerging as quantum platforms poised for transition to
commercial devices. A key enabler stems from the semiconductor-like platform
that can be tailored at the time of growth. The large growth parameter space
makes it challenging to use intuition to optimize growth conditions for quantum
performance. In this paper, we use supervised machine learning to train
regression models using different synthesis parameters in over 100 quantum
diamond samples. We train models to optimize NV$^-$ defects in diamond for high
sensitivity magnetometry. Importantly, we utilize a magnetic-field sensitivity
figure of merit (FOM) for NV magnetometry and use Bayesian optimization to
identify critical growth parameters that lead to a 300% improvement over an
average sample and a 55% improvement over the previous champion sample.
Furthermore, using Shapley importance rankings, we gain new physical insights
into the most impactful growth and post-processing parameters, namely electron
irradiation dose, diamond seed depth relative to the plasma, seed miscut angle,
and reactor nitrogen concentration. As various quantum devices can have
significantly different material requirements, advanced growth techniques such
as plasma-enhanced chemical vapor deposition (PE-CVD) can provide the ability
to tailor material development specifically for quantum applications.

</details>


### [866] [Electric-Field-Tunable Luttinger compensated antiferromagnetism in double CrCl2 chains](https://arxiv.org/abs/2510.22153)
*Deping Guo,Weihan Zhang,Canbo Zong,Cong Wang,Wei Ji*

Main category: cond-mat.mtrl-sci

TL;DR: 通过外加电场和界面工程将反铁磁CrCl2双链转化为一维Luttinger补偿反铁磁体，用于自旋电子学应用。


<details>
  <summary>Details</summary>
Motivation: Luttinger补偿反铁磁体（LcAFMs）结合了自旋极化和净磁化强度消失的特点，为下一代自旋电子学应用提供了独特的优势。

Method: 利用第一性原理计算，研究了常规反铁磁CrCl2双链在外加电场下的行为，并设计了CrCl2/MoTe2异质结构以增强可调性。

Result: 证明了常规反铁磁CrCl2双链在外加电场下可以转变为一维LcAFMs，表现出显著的各向同性自旋劈裂。通过调控电场可以有效调谐劈裂的大小和带隙。CrCl2/MoTe2异质结构中的界面电荷转移产生的内建电场也能诱导可比拟的自旋劈裂。

Conclusion: 界面工程是实现和调控低维磁体中LcAFM态的有效途径，扩展了纳米尺度自旋电子学功能的設計原則。

Abstract: Luttinger compensated antiferromagnets (LcAFMs), combining spin polarization
with vanishing net magnetization, offering distinct advantages for
next-generation spintronic applications. Using first-principles calculations,
we demonstrate that conventional antiferromagnetic CrCl2 double chains can be
transformed into one-dimensional LcAFMs under an external electric field,
exhibiting pronounced isotropic spin splitting. The magnitude of the splitting,
as well as the band gap, can be effectively tuned by both in-plane and
out-of-plane fields, thereby providing greater controllability than in
two-dimensional counterparts. To further enhance the tunability, we design a
nearly lattice-matched CrCl2/MoTe2 heterostructure and uncover that interfacial
charge transfer generates a built-in electric field, inducing spin splitting
comparable to that driven by external fields. These results establish
interfacial engineering as a highly efficient route to realize and manipulate
LcAFM states in low-dimensional magnets, expanding the design principles for
spintronic functionalities at the nanoscale.

</details>


### [867] [Suppression of Thin-Film Thermal Conductivity due to Surface Roughness](https://arxiv.org/abs/2510.22185)
*Michimasa Morita,Junichiro Shiomi*

Main category: cond-mat.mtrl-sci

TL;DR: 硅纳米结构中的边界散射和表面粗糙度显著降低了热导率，需要考虑表面局部模式的混合和表面原子的无谐波力常数调制。


<details>
  <summary>Details</summary>
Motivation: 理解硅纳米结构中的热传输对于半导体器件的有效热管理至关重要，特别是要解决边界散射和表面粗糙度对热导率的影响。

Method: 利用非谐晶格动力学计算了具有粗糙表面的薄膜（厚度达 25 nm）的热导率和声子传输特性，并研究了表面粗糙度引起的抑制机制。

Result: 发现在粗糙表面超薄膜中，群速度的降低（由表面局部模式的混合引起）和弛豫时间的缩短（由表面原子无谐波力常数的调制引起）共同抑制了热导率。群速度降低在较宽的厚度和粗糙度范围内起主导作用，而弛豫时间缩短在约 0.1 nm 的粗糙度和 5 nm 以下的厚度方面尤其重要。

Conclusion: 现有的边界散射模型未能考虑这些由表面粗糙度引起的热导率抑制机制，导致对粗糙薄膜热导率的估计偏高约 100%。

Abstract: Understanding thermal transport in silicon nanostructures is crucial for
effective thermal management in semiconductor devices. In such nanostructures,
boundary scattering can significantly reduce thermal conductivity. Diffusive
boundary scattering explains the experimentally observed thickness dependence
of thermal conductivity in thin films with thicknesses of tens of nanometers;
however, introducing surface roughness further reduces the thermal
conductivity, which falls far below the theoretical lower limit. In this study,
we calculated the thermal conductivity and phonon transport properties of rough
thin films with thicknesses of up to 25 nm using anharmonic lattice dynamics
and investigated the mechanisms underlying the suppression of thermal
conductivity arising from surface roughness. We found that in ultrathin films
with rough surfaces, thermal conductivity was suppressed by a reduction in
group velocity caused by hybridization with surface-localized modes, as well as
a reduction in relaxation time due to the modulation of the anharmonic
interatomic force constants of surface atoms. The reduction in group velocity
significantly suppressed thermal conductivity across a wide range of
thicknesses and surface-roughness values. In contrast, the reduction in
relaxation time exhibited strong thickness dependence. Thus, this
relaxation-time reduction should be considered in ultrathin films with
roughness of approximately 0.1 nm and thicknesses below 5 nm. These
thermal-conductivity suppression mechanisms due to surface roughness were not
considered in the boundary-scattering model, resulting in an overestimation of
the thermal conductivity of the roughened thin films by up to approximately
100%.

</details>


### [868] [Enhanced magnetic and optical properties of oxygen deficient TiO$_{2-δ}$ nanoparticles synthesized by environment-friendly green route using whole plant extract of Phyllanthus niruri](https://arxiv.org/abs/2510.22296)
*Latika Mishra,Vinod Kumar Dwivedi,Vishal Kumar Chakradhary,Akila G. Prabhudessai,Shamshun Nehar*

Main category: cond-mat.mtrl-sci

TL;DR: 使用Phyllanthus niruri提取物合成的缺氧TiO$_{2-\delta}$纳米粒子表现出铁磁性，这归因于氧空位导致Ti的混合价态。


<details>
  <summary>Details</summary>
Motivation: 使用环境友好的绿色路线，以Phyllanthus niruri（PN）全株植物提取物（而非叶子提取物）合成了缺氧TiO$_{2-\delta}$纳米粒子，并研究其磁性、光学和氧化态。

Method: 采用Rietveld精炼法分析X射线衍射（XRD）数据，确认了纯相锐钛矿TiO$_2$晶体的形成；利用透射电子显微镜（TEM）和扫描电子显微镜（SEM）分析形貌和尺寸；傅里叶变换红外光谱（FTIR）分析表面生物分子；X射线光电子能谱（XPS）分析核心能级，特别是O-1s和Ti-2p，以确认氧空位和Ti的混合价态；紫外-可见（UV-vis）光谱分析光学性质，包括吸收峰和光学带隙能量；测量磁化强度与外加磁场的关系，以评估其磁性。

Result: XRD结果证实形成了纯相锐钛矿TiO$_2$，具有四方晶系结构（空间群I41/amd）。TEM和SEM显示出平均粒径约为35纳米的球形团聚纳米粒子。FTIR结果证实了TiO$_2$纳米粒子表面存在生物分子和官能团。O-1s和Ti-2p的XPS核心谱证实了氧空位的存在，导致Ti出现混合价态（Ti$^{4+}$和Ti$^{3+}$）。UV-vis结果显示在约250 nm处有强吸收峰，光学带隙能量（E$_g$）约为2.75 eV，这可能是由于氧空位引起了表面等离激元共振（SPR）。磁化强度随外加磁场的变化显示出室温下的铁磁性（M$_S$ $\sim$ 0.029 emu/g，H$_C$ $\sim$ 0.0143 T）。

Conclusion: 本研究成功利用绿色合成方法制备了缺氧TiO$_{2-\delta}$纳米粒子，其独特的磁学和光学性质，特别是室温铁磁性，与氧空位和Ti的混合价态密切相关。这为开发新型磁性纳米材料提供了新的途径。

Abstract: We report magnetic, optical and oxidation states of oxygen deficient
TiO$_{2-\delta}$ nanoparticles (NPs) synthesized by environment-friendly green
route using Phyllanthus niruri (PN) whole plant extract instead of leaf
extract. Rietveld refinement of room temperature XRD pattern confirms the
formation of pure phase anatase TiO$_2$ crystals in a tetragonal structure with
space group I41/amd. TEM and SEM microstructure shows agglomerated spherical
shape NPs exhibiting average particle size $\sim$ 35~nm. FTIR result confirms
the presence of biomolecules and functional group attached to the surface of
TiO$_2$ NPs. The core level XPS of O-1s and Ti-2p confirms the presence of
oxygen vacancies that leads to the mixed oxidation states of Ti (Ti$^{4+}$ and
Ti$^{3+}$). UV-vis result shows a strong absorption peak ($\sim$ 250~nm) along
with reduced optical band gap energy E$_g$ $\sim$ 2.75~eV, possibly arises due
to the surface plasmon resonance (SPR) caused by lower band gap energy emerging
from oxygen vacancies. Magnetization as a function of applied magnetic field
shows ferromagnetic nature at room temperature [M$_S$ $\sim$ 0.029~emu/g and
H$_C$ $\sim$ 0.0143~T]. The observed ferromagnetic behaviour can be understood
by virtual hopping of electrons from Ti$^{3+}$(3d$^1$) to
Ti$^{4+}$(3d$^0$)-sites, however, vice versa is prohibited.

</details>


### [869] [Reinforcement learning-guided optimization of critical current in high-temperature superconductors](https://arxiv.org/abs/2510.22424)
*Mouyang Cheng,Qiwei Wan,Bowen Yu,Eunbi Rha,Michael J Landry,Mingda Li*

Main category: cond-mat.mtrl-sci

TL;DR: 结合强化学习和Ginzburg-Landau模拟，自动优化高温超导体缺陷构型以提升临界电流密度。


<details>
  <summary>Details</summary>
Motivation: 高温超导体的性能受限，临界电流密度（Jc）受微观结构缺陷影响，但缺陷工程优化复杂。

Method: 使用强化学习（RL）结合时间依赖Ginzburg-Landau（TDGL）模拟，通过RL迭代优化缺陷构型，TDGL模拟提供Jc评估作为奖励信号。

Result: RL代理发现最优缺陷密度和相关性，在二维薄膜几何中增强涡旋钉扎，Jc相比初始状态提升高达15倍，达到理论约60%。

Conclusion: 该RL驱动方法为缺陷工程提供了可扩展的策略，有望推动高温超导体在聚变磁体、粒子加速器等高场技术中的应用。

Abstract: High-temperature superconductors are essential for next-generation energy and
quantum technologies, yet their performance is often limited by the critical
current density ($J_c$), which is strongly influenced by microstructural
defects. Optimizing $J_c$ through defect engineering is challenging due to the
complex interplay of defect type, density, and spatial correlation. Here we
present an integrated workflow that combines reinforcement learning (RL) with
time-dependent Ginzburg-Landau (TDGL) simulations to autonomously identify
optimal defect configurations that maximize $J_c$. In our framework, TDGL
simulations generate current-voltage characteristics to evaluate $J_c$, which
serves as the reward signal that guides the RL agent to iteratively refine
defect configurations. We find that the agent discovers optimal defect
densities and correlations in two-dimensional thin-film geometries, enhancing
vortex pinning and $J_c$ relative to the pristine thin-film, approaching 60\%
of theoretical depairing limit with up to 15-fold enhancement compared to
random initialization. This RL-driven approach provides a scalable strategy for
defect engineering, with broad implications for advancing HTS applications in
fusion magnets, particle accelerators, and other high-field technologies.

</details>


### [870] [Paradoxical Topological Soliton Lattice in Anisotropic Frustrated Chiral Magnets](https://arxiv.org/abs/2510.22580)
*Sayan Banik,Nikolai S. Kiselev,Ashis K. Nandy*

Main category: cond-mat.mtrl-sci

TL;DR: 二维手性磁体中存在拓扑数为整数的各种斯格明子。然而, 这些体系通常倾向于以斯格明子 (Q = -1) 或反斯格明子 (Q = 1) 为热力学稳定相的均匀晶格。在各向同性手性磁体中, 斯格明子-反斯格明子共存通常是短暂的, 因为它们会相互湮灭, 使得稳定、长程有序的晶格的观察成为一项重大挑战。在此, 我们通过在具有竞争性各向异性相互作用 (特别是 Dzyaloshinskii-Moriya 和受挫交换相互作用) 的手性磁体中, 将斯格明子-反斯格明子晶格作为磁场诱导的拓扑基态进行演示, 来应对这一挑战。这种独特的晶格由于斯格明子和反斯格明子的数量平衡而表现出净零全局拓扑荷。此外, 密度泛函理论和自旋晶格模拟将 2Fe/InSb(110) 确定为实现该相的理想候选材料。这一发现揭示了操纵磁孤子 (solitons) 的新可能性, 并将各向异性受挫手性磁体确立为未来自旋电子学应用的有希望的材料类别。


<details>
  <summary>Details</summary>
Motivation: 在各向同性手性磁体中, 斯格明子-反斯格明子共存通常是短暂的, 因为它们会相互湮灭, 使得稳定、长程有序的晶格的观察成为一项重大挑战。

Method: 通过密度泛函理论和自旋晶格模拟。

Result: 在具有竞争性各向异性相互作用 (特别是 Dzyaloshinskii-Moriya 和受挫交换相互作用) 的手性磁体中, 将斯格明子-反斯格明子晶格作为磁场诱导的拓扑基态进行演示。这种独特的晶格由于斯格明子和反斯格明子的数量平衡而表现出净零全局拓扑荷。将 2Fe/InSb(110) 确定为实现该相的理想候选材料。

Conclusion: 各向异性受挫手性磁体为未来自旋电子学应用提供了有希望的材料类别, 并揭示了操纵磁孤子 (solitons) 的新可能性。

Abstract: Two-dimensional chiral magnets are known to host a variety of skyrmions,
characterized by an integer topological charge. However, these systems
typically favor uniform lattices as a thermodynamically stable phase composed
of either skyrmions (Q = -1) or antiskyrmions (Q = 1). In isotropic chiral
magnets, skyrmion-antiskyrmion coexistence is typically transient due to mutual
annihilation, making the observation of a stable, long-range ordered lattice a
significant challenge. Here, we address this challenge by demonstrating a
skyrmion-antiskyrmion lattice as a magnetic field-induced topological ground
state in chiral magnets with competing anisotropic interactions, specifically
Dzyaloshinskii-Moriya and frustrated exchange interactions. This unique lattice
exhibits a net-zero global topological charge due to the balanced populations
of skyrmions and antiskyrmions. Furthermore, density functional theory and
spin-lattice simulations identify 2Fe/InSb(110) as an ideal candidate material
for realizing this phase. This finding reveals new possibilities for
manipulating magnetic solitons and establishes anisotropic frustrated chiral
magnets as a promising material class for future spintronic applications.

</details>


### [871] [Magnetoelectric effect of multiferroic metals](https://arxiv.org/abs/2510.22636)
*Zefei Han,Haojin Wang,Yuanchang Li*

Main category: cond-mat.mtrl-sci

TL;DR: 1T-NbTe$_2$ 是一种多铁性金属，具有线性磁电响应，由自旋-电荷相互作用引起。


<details>
  <summary>Details</summary>
Motivation: 与对多铁性绝缘体已有深入研究相比，对多铁性金属的研究知之甚少。

Method: 利用第一性原理计算，识别出 1T-NbTe$_2$ 这种滑动的范德华双层作为一种多铁性金属。

Result: 1T-NbTe$_2$ 表现出面内金属性、面外极化和磁性共存的现象，并具有线性磁电响应，其机制与多铁性绝缘体不同，且通过推导出的通用公式强调了层间介电常数在增强性能中的作用。

Conclusion: 该研究为探索磁电耦合机制和设计具有强磁电耦合功能材料提供了新思路。

Abstract: Much is known about the magnetoelectric effect of multiferroic insulators,
yet little is understood about multiferroic metals. In this work, we employ
first-principles calculations to identify the sliding van der Waals bilayer
$1T$-NbTe$_2$ as a multiferroic metal, where in-plane metallicity coexists with
out-of-plane polarization and magnetism. It exhibits linear magnetoelectric
response, originating from direct spin-charge interactions as a result of
external field-modulated Fermi energy, which differs from the
spin-charge-lattice or spin-orbit coupling mechanisms in multiferroic
insulators. We derive a universal formula for magnetoelectric coupling
parameters of multiferroic metals, which highlights the crucial role of
interlayer dielectric permittivity in enhancing performance. Our work provides
insights for exploring magnetoelectric coupling mechanisms and designing
functional materials with strong magnetoelectric coupling.

</details>


### [872] [Bidirectional Photoinduced Carrier Transfer in Fluorinated Quasi-2D Perovskites Governing Enhanced Photocurrent Generation](https://arxiv.org/abs/2510.22640)
*Soumya Halder,Koushik Gayen,Nagendra S. Kamath,Suman Kalyan Pal*

Main category: cond-mat.mtrl-sci

TL;DR: 准二维钙钛矿薄膜中存在异质相分布，导致了电子-空穴在不同相之间的有效分离，并可能用于提高光电器件的性能。


<details>
  <summary>Details</summary>
Motivation: 理解准二维钙钛矿中载流子在不同相之间的传输机制。

Method: 使用飞秒瞬态吸收光谱和紫外光电子能谱研究了多层准二维钙钛矿薄膜的相异质性、能带对齐和载流子传输动力学。

Result: 研究发现，薄膜由不同层数的钙钛矿相（1, 2, 3层和本体）组成，小层数相与本体之间存在II型能带对齐，驱动电子向本体迁移，空穴在小层数相累积，实现了载流子的空间分离和延长了载流子的寿命。

Conclusion: 准二维钙钛矿中的异相电荷转移机制得到了明确，并为通过工程化设计实现定向分离提供了策略，有望用于高性能光伏和量子器件。

Abstract: Quasi-two-dimensional (quasi-2D) metal halide perovskites exhibit rich phase
heterogeneity that profoundly influences light-matter interactions and charge
transport. However, the fundamental mechanisms governing carrier transfer
across distinct phases remain poorly understood. Here, we demonstrate effective
electron-hole separation in fluorinated multilayered quasi-2D perovskite films
nominally prepared for three layers, using femtosecond transient absorption
spectroscopy. The films are revealed to comprise a heterogeneous phase
distribution (with 1, 2, 3 layers and bulk) naturally stacked along the growth
direction. Our ultraviolet photoelectron spectroscopy (UPS) measurements, show
the type-two band alignment between the small-n (layer number) phases and the
bulk. This alignment drives charge separation via both direct and sequential
carrier transfer mechanisms, whereby electrons preferentially migrate into the
bulk domains while holes accumulate in the small-n layers, extending even to
single layer phase-a process only rarely observed in previous studies. The
nearly symmetric transfer times of electrons and holes yield an efficient and
balanced spatial separation of carriers. Global target analysis employing a
carrier transfer model quantitatively reproduces the spectral evolution,
providing a rigorous validation of the mechanism. Nonetheless, we found
photocurrent enhancement in the diode devices of this quasi-2D perovskite as a
consequence of the efficient transfer of photocarriers in the opposite
directions. This work delivers a comprehensive picture of interphase charge
transfer in fluorinated quasi-2D perovskites and highlights strategies to
engineer directional separation pathways for high-performance photovoltaic,
optoelectronic, and quantum devices.

</details>


### [873] [Switching between Skyrmions and Yoshimori Spin Spirals via Li Absorption in Janus Magnets](https://arxiv.org/abs/2510.22745)
*Xinyuan Jiang,Jian Wu,Weiyi Pan*

Main category: cond-mat.mtrl-sci

TL;DR: 通过在 Janus 2D CrTeSe 的 Se 或 Te 端表面选择性吸附 Li，可以稳定不同的磁相（自旋螺旋或 Skyrmion 态），从而实现手性磁态的可逆控制。


<details>
  <summary>Details</summary>
Motivation: 探索手性磁性织构（如 Skyrmion）在自旋电子器件中的潜在应用，以及通过表面吸附调控这些织构。

Method: 使用第一性原理计算和原子自旋动力学模拟。

Result: 选择性 Li 吸附稳定了两种不同的磁相：Se 端吸附稳定了 Yoshimori 型自旋螺旋，Te 端吸附稳定了 Skyrmion 态。这种差异源于吸附引起的交换相互作用、磁各向异性（MA）和 Dzyaloshinskii-Moriya 相互作用（DMI）的位点依赖性变化。两种系统的磁织构对垂直磁场的响应也存在显著差异。

Conclusion: 表面吸附是一种有效的策略，可以可逆地控制 2D 磁体中的手性磁态，并为理解 Skyrmion 和 Yoshimori 自旋螺旋的稳定性提供了基本见解。Janus 2D 材料为工程化可调谐自旋电子器件提供了一个多功能平台。

Abstract: Chiral magnetic textures have attracted considerable attention owing to their
topological properties and potential applications in spintronic devices. Here,
we employ first-principles calculations together with atomic spin dynamics
simulations to explore the switching between skyrmions and Yoshimori-type spin
spirals induced by Li adsorption in Janus two-dimensional (2D) CrTeSe. We show
that selective Li adsorption on either the Se- or Te-terminated surface
stabilizes distinct magnetic phases: Li adsorption on the Se side favors a
Yoshimori-type spin spiral, whereas adsorption on the Te side stabilizes the
skyrmionic state. This contrast originates from site-dependent modifications of
exchange interactions, magnetic anisotropy (MA), and the Dzyaloshinskii-Moriya
interaction (DMI). In addition, the response of magnetic textures to
out-of-plane magnetic fields differs strongly between the two systems. These
results demonstrate that surface adsorption provides an effective strategy for
reversible control of chiral magnetic states in 2D magnets, while also offering
fundamental insights into the competing interactions that govern the stability
of skyrmions and Yoshimori spin spirals. Our findings highlight the potential
of Janus 2D materials as a versatile platform for engineering tunable
spintronic devices.

</details>


### [874] [Normal Dirac Semimetal Phase and Zeeman-Induced Topological Fermi Arc in PtSr5](https://arxiv.org/abs/2510.22649)
*Inkyou Lee,Churlhi Lyi,Youngkuk Kim*

Main category: cond-mat.mtrl-sci

TL;DR: PtSr5是一种具有平庸拓扑的狄拉克半金属，可以通过外部泽曼磁场调控为外尔半金属。


<details>
  <summary>Details</summary>
Motivation: Pt-Sr二元互金属包含广泛的化学计量比和晶体结构，并具有复杂的键合和多价化学性质。 PtSr5是最近通过人工智能材料设计发现的一种体心四方化合物（I4/m）。

Method: 使用第一性原理计算和对称性指示分析来研究PtSr5的拓扑性质，并评估了在外部泽曼磁场作用下的相变。

Result: 计算表明PtSr5是具有平庸Z2拓扑的狄拉克半金属（正常狄拉克半金属）。外部泽曼磁场沿z轴应用可将系统驱动进入外尔半金属相，这由计算的表面态的特征变化得到证实。

Conclusion: PtSr5的拓扑相可以通过外部扰动进行调控，证明了人工智能材料探索在发现新的量子材料方面的有效性。

Abstract: Pt-Sr binary intermetallics encompass a broad range of stoichiometries and
crystal structures, stabilized by complex bonding and multivalent chemistry.
The Sr-rich end member, PtSr5, is recently identified via
artificial-intelligence-guided materials design as a body-centered tetragonal
compound (I4/m). Using first-principles calculations, we show that PtSr5 hosts
a Dirac semimetal phase with trivial Z2 topology, classified as a normal Dirac
semimetal. A symmetry-indicator analysis based on parity eigenvalues at the
eight time-reversal-invariant momenta confirms that all Z2 invariants-evaluated
on time-reversal-invariant two-dimensional subspaces of momentum space with a
direct band gap-are trivial, thereby establishing the topologically trivial
nature of the Dirac semimetal phase. Nonetheless, our calculations reveal that
applying an external Zeeman magnetic field along the z-axis drives the system
into a Weyl semimetal phase, as corroborated by characteristic changes in the
computed surface states. This work demonstrates the tunability of topological
phases in PtSr5 via external perturbations and highlights the effectiveness of
AI-based materials exploration in discovering new quantum materials.

</details>


### [875] [Mind the Gap -- Imaging Buried Interfaces in Twisted Oxide Moirés](https://arxiv.org/abs/2510.23042)
*Harikrishnan KP,Xin Wei,Chia-Hao Lee,Dasol Yoon,Yonghun Lee,Kevin J. Crust,Yu-Tsun Shao,Ruijuan Xu,Jong-Hoon Kang,Ce Liang,Jiwoong Park,Harold Y. Hwang,David A. Muller*

Main category: cond-mat.mtrl-sci

TL;DR: 氧化物叠层中的界面粗糙度限制了原子尺度上的耦合，阻碍了氧化物扭转电子学的发展，需要更可靠的表征方法。


<details>
  <summary>Details</summary>
Motivation: 探索具有相似莫尔 पाहिजे子学的扭曲氧化物叠层，并克服与二维材料相比实现原子级耦合的挑战。

Method: 通过交叉切片成像和电子断层扫描技术研究了界面形貌，并评估了传统成像技术（如通过焦成像）和电子断层扫描技术在解决界面问题方面的效果。

Result: 在扭曲的氧化物叠层中，表面粗糙度导致界面处的原子尺度近距离仅限于孤立的斑块。在二维材料和氧化物叠层之间的混合界面中，二维材料适应台阶-梯田形貌的能力降低，也限制了原子尺度的接触。电子断层扫描比传统成像技术更能可靠地解析纳米级的结构变化。

Conclusion: 界面粗糙度是氧化物扭转电子学领域面临的关键挑战，需要可靠的表征方法来克服这一挑战。

Abstract: The ability to tune electronic structure in twisted stacks of layered,
two-dimensional (2D) materials has motivated the exploration of similar moir\'e
physics with stacks of twisted oxide membranes. Due to the intrinsic
three-dimensional (3D) nature of bonding in many oxides, achieving atomic-level
coupling is significantly more challenging than in 2D van der Waals materials.
Although clean interfaces with atomic level proximity have been demonstrated in
ceramic bicrystals using high-temperature and high-pressure processing to
facilitate atomic diffusion that flattens rough interfaces, such conditions are
not readily accessible when bonding oxide membranes. This study shows how
topographic mismatch due to surface roughness of the membranes can restrict
atomic-scale proximity at the interface to isolated patches even after obvious
issues of contaminants and amorphous interlayers are eliminated. In hybrid
interfaces between a chemically inert 2D material and an oxide membrane, the
reduced ability of the 2D material to conform to the membrane's step-terrace
topography also limits atomic-scale contact. In all these material systems, the
interface morphology is best characterized using cross-sectional imaging and is
necessary to corroborate investigations of interlayer coupling. When imaging
the bicrystal in projection, conventional through-focal imaging is found to be
relatively insensitive to the buried interface, whereas electron ptychography
reliably resolves structural variations on the order of a nanometer. These
findings highlight interface roughness as a key challenge for the field of
oxide twistronics and emphasizes the need for reliable characterization
methods.

</details>


### [876] [Novel A2CrH6 (A = Ca, Sr, Ba) hydrides explored by first-principles calculations for hydrogen storage applications](https://arxiv.org/abs/2510.22749)
*Zakaria El Fatouaki,El Mustapha Hrida,Abderahhim Jabar,Abdellah Tahiri,Mohamed Idiri*

Main category: cond-mat.mtrl-sci

TL;DR: A2CrH6 (A = Ba, Sr, Ca) 具有良好的稳定性，并显示出在储氢、力学、电子和光学器件方面的应用潜力，其中 Sr2CrH6 的储氢脱附温度最低，Ca2CrH6 最具韧性。


<details>
  <summary>Details</summary>
Motivation: 研究 A2CrH6 (A = Ba, Sr, Ca) 氢化物钙钛矿的结构、储氢、力学、声子、热力学、电子和光学性质。

Method: 使用 Cambridge Serial Total Energy Package (CASTEP) 软件进行理论计算。

Result: 计算得到化合物的晶格常数在 7.220 Å 到 8.082 Å 之间，晶体结构稳定。负生成能、弹性常数、声子色散和 AIMD 模拟证明了其热力学、力学、动力学和热稳定性。储氢容量分别为 1.82 wt.%、2.69 wt.% 和 4.37 wt.%。Sr2CrH6 的氢脱附温度最低 (463.7 K)。电子能带显示出显著的自旋活性，且 A 阳离子的变化会影响自旋极化和电子行为。Ca2CrH6 力学性能最强。

Conclusion: A2CrH6 (A = Ca, Sr, Ba) 钙钛矿氢化物在先进能源系统、储氢以及电子和光电器件方面具有应用潜力，特别是 Ca2CrH6。

Abstract: A theoretical study of a number of properties of A2CrH6 (where A = Ba, Sr,
and Ca) hydride perovskites with the Cambridge Serial Total Energy Package
(CASTEP). These include structural, hydrogen storage, mechanical, phonon,
thermodynamic, electronic, and optical properties. The lattice constants of the
compounds studied are in the range from 7.220 {\AA} to 8.082 {\AA}, and they
exhibit stable cubic crystal structures. Negative formation energies, elastic
constants, phonon dispersion and AIMD simulations testify to their
thermodynamic, mechanical, dynamic and thermal stability, respectively. For the
perovskite hydrides Ba2CrH6, Sr2CrH6 and Ca2CrH6, the corresponding specific
hydrogen storage capacities are 1.82 wt.%, 2.69 wt.%, and 4.37 wt.%,
respectively. Among these compounds, Sr2CrH6 exhibits the lowest applicable
hydrogen desorption temperature, at 463.7 K. The electronic bands show
remarkable spin activity, demonstrating that the change of A2+ cation (where A
= Ca, Sr, and Ba) immediately influences the spin polarization and electronic
behavior of hydride perovskites. On the basis of the elastic moduli studied,
the mechanical behavior determines that Ca2CrH6 is the strongest material. The
present results highlight the potential of A2CrH6 (A = Ca, Sr, and Ba)
perovskite hydrides, in particular Ca2CrH6, for applications in advanced energy
systems and hydrogen storage, as well as for electrical and optoelectronic
devices.

</details>


### [877] [Machine-Learning-Guided Insights into Solid-Electrolyte Interphase Conductivity: Are Amorphous Lithium Fluorophosphates the Key?](https://arxiv.org/abs/2510.22912)
*Peichen Zhong,Kristin A. Persson*

Main category: cond-mat.mtrl-sci

TL;DR: 尽管研究已久，但锂离子电池无机固体电解质界面（SEI）中主要的锂离子传导相仍然未知。虽然马赛克模型描述了无定形基质中的 LiF/Li2O/Li2CO3 纳米晶，但这些晶相的离子电导率有限。越来越多的证据表明，界面、晶界和无定形相可能是主要的快速离子通道。


<details>
  <summary>Details</summary>
Motivation: 混合阴离子电解质分解产物的出现，促使我们结合基于扩散的生成结构预测和机器学习势能（MLIPs）来研究二氟磷酸锂（LiPO2F2），这是含磷和氟电解质的关键分解产物。

Method: 我们结合了基于扩散的生成结构预测和机器学习势能（MLIPs）来研究二氟磷酸锂（LiPO2F2）。通过 MLIP 加速的分子动力学模拟，我们识别了一个稳定的晶体多晶型物，并表明其无定形对应物具有更高的导电性。

Result: 我们发现二氟磷酸锂（LiPO2F2）的无定形对应物具有更高的导电性，预测室温电导率 $\sigma$ $\approx$ 0.18 mS cm$^{-1}$，活化能 $E_\mathrm{a}$ $\approx$ 0.40 eV。这种电导率的提高归因于结构无序，它使锂位点的能量变得更平坦，并且锂间隙缺陷的形成能较低，从而提供了额外的移动载流子。

Conclusion: 我们提出了混合阴离子、无定形 Li--P--O--F 相作为无机 SEI 的锂离子传导介质的有希望的候选者，为改进电池界面提供了前进的道路。

Abstract: Despite decades of study, the identity of the dominant \ce{Li+}-conducting
phase within the inorganic SEI of Li-ion batteries remains unresolved. While
the mosaic model describes LiF/\ce{Li2O}/\ce{Li2CO3} nanocrystallites within a
disordered matrix, these crystalline phases inherently offer limited ionic
conductivity. Growing evidence suggests that interfaces, grain boundaries, and
amorphous phases may instead host the primary fast-ion pathways. Motivated by
mixed-anion electrolyte decomposition products, we combine diffusion-based
generative structure prediction with machine-learning interatomic potentials
(MLIPs) to interrogate lithium difluorophosphate (\ce{LiPO2F2}), a key
decomposition product of phosphorus- and fluorine-containing electrolytes. We
identify a stable crystalline polymorph and, through MLIP-accelerated molecular
dynamics, show that the amorphous counterpart is more conductive, with
projected room-temperature $\sigma$ $\approx$ 0.18 mS cm$^{-1}$ and
$E_\mathrm{a}$ $\approx$ 0.40 eV. This enhancement is attributed to structural
disorder, which flattens the Li site-energy landscape, and to a low formation
energy for Li-interstitial defects, which supplies additional mobile carriers.
We present mixed-anion, amorphous Li--P--O--F phases as promising candidates
for the \ce{Li+}-conducting medium of the inorganic SEI, offering a path
forward for engineering improved battery interfaces.

</details>


### [878] [AQCat25: Unlocking spin-aware, high-fidelity machine learning potentials for heterogeneous catalysis](https://arxiv.org/abs/2510.22938)
*Omar Allam,Brook Wander,Aayush R. Singh*

Main category: cond-mat.mtrl-sci

TL;DR: AQCat25数据集的引入和整合策略，用于提高机器学习势能的催化剂模拟精度，特别是在涉及自旋极化和高保真度的情况下。


<details>
  <summary>Details</summary>
Motivation: 由于训练数据存在空白，现有的机器学习势能（MLIPs）在处理某些催化剂模拟系统时存在局限性，尤其是在需要考虑自旋极化和更高保真度的情况下。

Method: 引入了包含1350万个密度泛函理论（DFT）单点计算的AQCat25数据集，并研究了将新数据集与OC20数据集进行整合的方法，以创建不牺牲泛化能力的自旋感知模型。采用了直接微调、联合训练以及使用FiLM等元数据条件化技术。

Result: 直接在AQCat25上微调通用模型会导致灾难性遗忘；联合训练策略能有效提高新数据的准确性，同时保持通用性能；使用FiLM等元数据条件化技术可以解决混合保真度和混合物理学数据集带来的挑战，并进一步提高模型精度。

Conclusion: 建立了一个有效的协议，用于连接DFT保真度域，以提高催化剂领域基础模型的预测能力。

Abstract: Large-scale datasets have enabled highly accurate machine learning
interatomic potentials (MLIPs) for general-purpose heterogeneous catalysis
modeling. There are, however, some limitations in what can be treated with
these potentials because of gaps in the underlying training data. To extend
these capabilities, we introduce AQCat25, a complementary dataset of 13.5
million density functional theory (DFT) single point calculations designed to
improve the treatment of systems where spin polarization and/or higher fidelity
are critical. We also investigate methodologies for integrating new datasets,
such as AQCat25, with the broader Open Catalyst 2020 (OC20) dataset to create
spin-aware models without sacrificing generalizability. We find that directly
tuning a general model on AQCat25 leads to catastrophic forgetting of the
original dataset's knowledge. Conversely, joint training strategies prove
effective for improving accuracy on the new data without sacrificing general
performance. This joint approach introduces a challenge, as the model must
learn from a dataset containing both mixed-fidelity calculations and
mixed-physics (spin-polarized vs. unpolarized). We show that explicitly
conditioning the model on this system-specific metadata, for example by using
Feature-wise Linear Modulation (FiLM), successfully addresses this challenge
and further enhances model accuracy. Ultimately, our work establishes an
effective protocol for bridging DFT fidelity domains to advance the predictive
power of foundational models in catalysis.

</details>


### [879] [Nonlinear optical quantum theory of demagnetization in L1$_0$ FePt and FePd](https://arxiv.org/abs/2510.22972)
*G. P. Zhang,Y. H. Bai,Thomas F. George*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究提出了一个基于自旋矩的非线性光学理论，用于解释激光脉冲如何使铁磁体退磁，并成功应用于FePt和FePd材料，区分了它们的差异。


<details>
  <summary>Details</summary>
Motivation: 填补了铁磁体激光脉冲退磁缺乏解析理论的空白，该现象不属于传统非线性光学或磁学范畴。

Method: 利用群论确定了非零自旋矩的最低阶为二阶，并计算了光诱导自旋矩。将理论应用于FePt和FePd材料。

Result: 理论能够区分FePt和FePd这两种相似材料的差异，指出FePt的光诱导自旋矩强于FePd，与模拟和实验结果一致。差频生成（DFG）过程产生的自旋矩变化最大。

Conclusion: 该研究为飞秒磁学奠定了坚实的理论基础，使得能够计算和比较不同系统中的光诱导自旋矩降低，而无需进行耗时的实时计算。

Abstract: It is now well established that a laser pulse can demagnetize a
  ferromagnet. However, for a long time, it has not had an analytic
  theory because it falls into neither nonlinear optics (NLO) nor
  magnetism. Here we attempt to fill this gap by developing a
  nonlinear optical theory centered on the spin moment, instead of
  the more popular susceptibility. We first employ group theory to
  pin down the lowest order of the nonzero spin moment in a
  centrosymmetric system to be the second order, where the
  second-order density matrix contains four terms of sum frequency
  generation (SFG) and four terms of difference frequency generation
  (DFG). By tracing over the product of the density matrix and the
  spin matrix, we are now able to compute the light-induced spin
  moment. We apply our theory to FePt and FePd, two most popular
  magnetic recording materials with identical crystal and electronic
  structures. We find that the theory can clearly distinguish the
  difference between those two similar systems. Specifically, we
  show that FePt has a stronger light-induced spin moment than FePd,
  in agreement with our real-time ultrafast demagnetization
  simulation and the experimental results. Among all the possible
  NLO processes, DFGs produce the largest spin moment change, a
  manifestation of optical rectification. Our research lays a solid
  theoretical foundation for femtomagnetism, so the light-induced spin moment
reduction can now be computed and compared among
  different systems, without time-consuming real-time calculations,
  representing a significant step forward.

</details>


### [880] [Benchmarking Universal Machine Learning Interatomic Potentials for Elastic Property Prediction](https://arxiv.org/abs/2510.22999)
*Pengfei Gao,Haidi Wang*

Main category: cond-mat.mtrl-sci

TL;DR: 使用uMLIPs（MatterSim, MACE, SevenNet, CHGNet）对近11,000种弹性稳定材料的弹性特性进行基准测试，SevenNet精度最高，MACE和MatterSim在精度和效率之间取得平衡，CHGNet表现不佳。


<details>
  <summary>Details</summary>
Motivation: 评估通用机器学习原子间势（uMLIPs）在预测材料弹性性质方面的可靠性。

Method: 对MatterSim, MACE, SevenNet, CHGNet这四种uMLIPs，以及来自Materials Project数据库的近11,000种弹性稳定材料的理论数据进行了系统的基准测试。

Result: SevenNet的预测精度最高，MACE和MatterSim在精度和效率之间取得了良好的平衡，而CHGNet的总体表现较差。

Conclusion: 这项基准测试为指导模型选择和推动uMLIPs在力学性能应用方面的发展提供了一个框架。

Abstract: Universal machine learning interatomic potentials have emerged as efficient
tool for material simulation fields,yet their reliability for elastic property
prediction remains unclear. Here we present a systematic benchmark of four
uMLIPs-MatterSim, MACE, SevenNet, and CHGNet-against theoretical data for
nearly 11,000 elastically stable materials from the Materials Project database.
The results show SevenNet achieves the highest accuracy,MACE and MatterSim
balance accuracy with efficiency, while CHGNet performs less effectively
overall. This benchmark establishes a framework for guiding model selection and
advancing uMLIPs in mechanical property applications.

</details>


### [881] [Amplified Photocurrent in Heterojunctions comprising Nano-rippled Zinc Oxide and Perovskite-inspired Cs3Cu2I5](https://arxiv.org/abs/2510.23063)
*Si Hyeok Yang,Lim Kyung Oh,Na Young Lee,Dong Ho Lee,Sang Min Choi,Bowon Oh,Yun Ji Park,Yunji Cho,Jaesel Ryu,Hongki Kim,Sang-Hyun Chin,Yeonjin Yi,Myungkwan Song,Han Seul Kim,Jin Woo Choi*

Main category: cond-mat.mtrl-sci

TL;DR: 利用氧化锌纳米波纹改善铯铜碘化物光电探测器的电荷传输


<details>
  <summary>Details</summary>
Motivation: 铯铜碘化物（Cs3Cu2I5）具有低毒、高稳定性和强蓝色发光等优点，是光电器件的候选材料，但其内在的低电导率限制了电荷传输。

Method: 提出一种在新颖的横向Cs3Cu2I5光电探测器（PD）结构中，利用精确优化的氧化锌（ZnO）纳米波纹结构，改善渗流路径，为光生载流子迁移到叉指电极（IDEs）提供高效途径。

Result: 与原始Cs3Cu2I5器件相比，优化的由Cs3Cu2I5和ZnO组成的异质结表现出优越的光电流。

Conclusion: 这种纳米结构介导的电荷传输工程策略为低电导率的0D材料在光电器件、物联网传感器网络和生物传感等领域的应用提供了新途径。

Abstract: Molecular zero-dimensional (0D) halide perovskite-inspired cesium copper
iodide (Cs3Cu2I5) is a highly promising candidate for optoelectronic
applications due to their low toxicity, high stability, and intense blue
emission. However, their intrinsically poor electrical conductivity, stemming
from isolated conductive copper iodide tetrahedra by cesium atoms, severely
limits charge transport which poses a critical challenge for optoelectronic
applications. In this study, we propose a novel strategy to overcome this
limitation by utilizing precisely optimized zinc oxide nanoripple structures
within a lateral Cs3Cu2I5 photodetector (PD) architecture featuring
interdigitated electrodes (IDEs). The ZnO nanoripple was systematically tuned
to improve the percolation paths, providing efficient routes for photogenerated
carriers to migrate to the IDEs. Consequently, the optimized heterojunctions
comprising Cs3Cu2I5 and ZnO exhibited superior photocurrent compared to the
pristine Cs3Cu2I5 counterparts. This nanostructure-mediated charge transport
engineering strategy for lateral structured PDs offers a new pathway for
utilizing low-conductivity 0D materials for conventional optoelectronics,
next-generation Internet of Things sensor networks, and plausibly biosensing
applications.

</details>


### [882] [LightPFP: A Lightweight Route to Ab Initio Accuracy at Scale](https://arxiv.org/abs/2510.23064)
*Wenwen Li,Nontawat Charoenphakdee,Yong-Bin Zhuang,Ryuhei Okuno,Yuta Tsuboi,So Takamoto,Junichi Ishida,Ju Li*

Main category: cond-mat.mtrl-sci

TL;DR: 该论文提出了一种名为LightPFP的数据高效知识蒸馏框架，用于快速开发准确且高效的机器学习原子间势（MLIP），克服了通用MLIP计算开销大和任务特定MLIP数据生成成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 机器学习原子间势（MLIP）在原子模拟中扮演着越来越重要的角色，但通用MLIP计算开销大，而任务特定MLIP的数据生成成本高昂。需要一种更高效的方法来开发任务特定MLIP。

Method: LightPFP框架利用通用MLIP生成高质量的特定材料训练数据，并使用预训练的轻量级MLIP进一步提高数据效率，从而通过知识蒸馏生成任务特定MLIP。

Result: LightP প্রতিশ্রুতি 为固态电解质、高熵合金和反应离子系统等多种材料带来了比传统基于DFT方法快三个数量级 Thus, the distilled ts-MLIPs maintain accuracy comparable to first-principles predictions and are 1-2 orders of magnitude faster in inference than u-MLIPs, enabling large-scale molecular dynamics simulations. The framework also allows for efficient precision transfer learning, correcting systematic errors from u-MLIPs with minimal DFT data.

Conclusion: LightPFP框架能够快速开发高保真、高效的MLIP，用于材料科学应用，通过知识蒸馏克服了现有方法的局限性。

Abstract: Atomistic simulation methods have evolved through successive computational
levels, each building upon more fundamental approaches: from quantum mechanics
to density functional theory (DFT), and subsequently, to machine learning
interatomic potentials (MLIPs). While universal MLIPs (u-MLIPs) offer broad
transferability, their computational overhead limits large-scale applications.
Task-specific MLIPs (ts-MLIPs) achieve superior efficiency but require
prohibitively expensive DFT data generation for each material system. In this
paper, we propose LightPFP, a data-efficient knowledge distillation framework.
Instead of using costly DFT calculations, LightPFP generates a distilled
ts-MLIP by leveraging u-MLIP to generate high-quality training data tailored
for specific materials and utilizing a pre-trained light-weight MLIP to further
enhance data efficiency. Across a broad spectrum of materials, including
solid-state electrolytes, high-entropy alloys, and reactive ionic systems,
LightPFP delivers three orders of magnitude faster model development than
conventional DFT-based methods, while maintaining accuracy on par with
first-principles predictions. Moreover, the distilled ts-MLIPs further sustain
the computational efficiency essential for large-scale molecular dynamics,
achieving 1-2 orders of magnitude faster inference than u-MLIPs. The framework
further enables efficient precision transfer learning, where systematic errors
from the u-MLIP can be corrected using as few as 10 high-accuracy DFT data
points, as demonstrated for MgO melting point prediction. This u-MLIP-driven
distillation approach enables rapid development of high-fidelity, efficient
MLIPs for materials science applications.

</details>


### [883] [Topological Control of Transition Metal Networks for Reversible High-Capacity Li-rich Cathodes](https://arxiv.org/abs/2510.23098)
*Changming Ke,Yudi Yang,Minjun Wang,Jianhui Wang,Shi Liu*

Main category: cond-mat.mtrl-sci

TL;DR: 通过分子动力学模拟揭示锂锰氧化物材料的退化机制，并提出基于拓扑设计的稳定材料。


<details>
  <summary>Details</summary>
Motivation: 开发高能量密度电池对于可持续能源技术至关重要，但现有材料如锂锰氧化物存在容量衰减问题，其根本原因和可逆性尚不明确。

Method: 利用具有第一性原理精度的亚微秒分子动力学模拟，直接观察锂锰氧化物的整个充放电循环，揭示氧气纳米空穴的完整生命周期及其退化机制，并确定空穴可修复的关键尺寸限制。

Result: 发现锰阳离子网络的拓扑结构是控制空穴生长、合并和可修复性的关键因素。基于此，通过计算设计了一种具有类Kagome结构的锰晶格的新型锂锰氧化物，该材料在80%脱锂条件下也表现出完全的电化学可逆性。

Conclusion: 研究建立了设计高能量正极材料的新范式，将重点从减轻损伤转移到通过原子级拓扑控制过渡金属网络来工程化固有的稳定性。

Abstract: Developing high-energy-density batteries is essential for advancing
sustainable energy technologies. However, leading cathode materials such as
Li-rich oxides, including Li$_2$MnO$_3$, suffer from capacity loss due to
irreversible oxygen release and structural degradation, both consequences of
the oxygen redox activity that also enables their high capacity. The
atomic-scale mechanisms behind this degradation, and whether it can be made
reversible, remain open questions. Here, using submicrosecond-scale molecular
dynamics simulations with first-principles accuracy, we directly visualize the
entire charge-discharge cycle of Li$_2$MnO$_3$, uncovering the full lifecycle
of the O$_2$-filled nanovoids responsible for degradation and identifying the
critical size limit for voids to remain fully repairable upon discharge. Our
results reveal that the topology of the Mn cation network is the key factor
governing void growth, coalescence, and reparability. Based on a structural
topology-informed design principle, we computationally develop a novel
Li$_2$MnO$_3$ structure featuring a Mn lattice with a Kagome-like pattern,
demonstrating full electrochemical reversibility even under extreme 80%
delithiation. Our work establishes a new paradigm for designing high-energy
cathodes, shifting the focus from mitigating damage to engineering inherent
stability through atomic-level topological control of transition metal network.

</details>


### [884] [Thermal Transport in Ag8TS6 (T= Si, Ge, Sn) Argyrodites: An Integrated Experimental, Quantum-Chemical, and Computational Modelling Study](https://arxiv.org/abs/2510.23133)
*Joana Bustamante,Anupama Ghata,Aakash A. Naik,Christina Ertural,Katharina Ueltzen,Wolfgang G. Zeier,Janine George*

Main category: cond-mat.mtrl-sci

TL;DR: Argyrodite-type Ag-based sulfides show potential for energy applications due to their thermal and ionic conductivity. This study investigates Ag8TS6 (T= Si, Ge, Sn) using computational and experimental methods, proposing a two-channel lattice-dynamics model for predicting thermal conductivity. The research reveals that bond heterogeneity and interactions contribute to anharmonicity and low thermal conductivity, and suggests that thermal and ionic conductivities can be tuned independently.


<details>
  <summary>Details</summary>
Motivation: Investigate the structural and thermal transport properties of Ag8TS6 (T= Si, Ge, Sn) argyrodite sulfides, which are promising for thermoelectric and solid-state energy applications due to their low lattice thermal and high ionic conductivity.

Method: Combined chemical-bonding analysis, lattice vibrational properties simulation, and experimental measurements. Proposed a two-channel lattice-dynamics model based on Gr"uneisen-derived phonon lifetimes and compared it to a machine-learned interatomic potentials approach.

Result: Both proposed models accurately predict thermal conductivity in agreement with experimental data. Findings reveal a relationship between bond heterogeneity (weakly bonded Ag+ ions, occupied antibonding states in Ag-S and Ag-Ag interactions) and strong anharmonicity (large Gr"uneisen parameters, low sound velocities), which are responsible for the low lattice thermal conductivity in Ag8SnS6, Ag8GeS6, and Ag8SiS6. Thermal and ionic conductivities were found to be independent and individually tunable.

Conclusion: Ag8TS6 (T= Si, Ge, Sn) compounds exhibit low lattice thermal conductivity due to strong anharmonicity arising from specific bonding characteristics. The developed models show potential for high-throughput predictions, and the independent tunability of thermal and ionic conductivities offers opportunities for optimizing material properties for energy applications.

Abstract: Argyrodite-type Ag-based sulfides combine exceptionally low lattice thermal
and high ionic conductivity, making them promising candidates for
thermoelectric and solid-state energy applications. In this work, we studied
Ag8TS6 (T= Si, Ge, Sn) argyrodite family by combining chemical-bonding
analysis, lattice vibrational properties simulation, and experimental
measurements to investigate their structural and thermal transport properties.
Furthermore, we propose a two-channel lattice-dynamics model based on
Gr\"uneisen-derived phonon lifetimes and compare it to an approach using
machine-learned interatomic potentials. Both approaches are able to predict
thermal conductivity in agreement with experimental lattice thermal
conductivities along the whole temperature range, highlighting their potential
suitability for future high-throughput predictions. Our findings also reveal a
relationship between bond heterogeneity arising from weakly bonded Ag+ ions and
occupied antibonding states in Ag-S and Ag-Ag interactions and strong
anharmonicity, including large Gr\"uneisen parameters, and low sound
velocities, which are responsible for the low lattice thermal conductivity of
Ag8SnS6, Ag8GeS6, and Ag8SiS6. We furthermore show that thermal and ionic
conductivities in all three compounds are independent of each other and can
likely be tuned individually.

</details>


### [885] [Unveiling the delicate hidden conditions at the interface of 2D materials by advanced atomic force microscopy](https://arxiv.org/abs/2510.23139)
*Yanyan Geng,Chang Li,Shuo Mi,Manyu Wang,Xinen Han,Huiji Hu,Yunzhen Wang,Haojie You,Shumin Meng,Hanxiang Wu,Jianfeng Guo,Shiyu Zhu,Yanjun Li,Yasuhiro Sugawara,Sabir Hussain,Fei Pang,Rui Xu,Zhihai Cheng*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究结合了双谐波静电力显微镜（DH-EFM）和扫描微波阻抗显微镜（sMIM）技术，揭示了应变工程的WS2薄片中复杂的面内应变和面外键合界面条件，并解释了DH-EFM和sMIM测量结果之间的矛盾源于探针加载力引起的动态皱缩效应，该效应受界面键合强度调节。


<details>
  <summary>Details</summary>
Motivation: 界面条件和行为对二维材料及其衬底上的异质结构的物理性质至关重要，但直接探测这些复杂界面条件仍然具有挑战性。

Method: 结合使用双谐波静电力显微镜（DH-EFM）和扫描微波阻抗显微镜（sMIM）技术，对静态和动态条件下进行原位测量。

Result: 观察到DH-EFM测量的本征压缩应变引起的带隙增大（电导率降低）与sMIM测量的较高电导率之间存在显著矛盾。通过比较不同sMIM模式下的电导率测量，发现这种矛盾源于探针加载力引起的动态皱缩效应，该效应受界面键合强度调节。正向/反向sMIM接触测量期间电导率的累积和释放进一步证实了动态皱缩效应，揭示了WS2开环和闭环区域之间界面条件的差异。

Conclusion: 该研究解决了电学性质与界面条件之间的相关性问题，并为界面工程设备提供了新的见解。

Abstract: The delicate interfacial conditions and behaviors play critical roles in
determining the valuable physical properties of two-dimensional materials and
their heterostructures on substrates. However, directly probing these complex
interface conditions remains challenging. Here, we reveal the complex in-plane
strain and out-of-plane bonding interface conditions in strain-engineered WS2
flakes by combined dual-harmonic electrostatic force microscopy (DH-EFM) and
scanning microwave impedance microscopy (sMIM). A significant contradiction is
observed between the intrinsically compressive-strain-induced larger bandgap
(lower electrical conductivity) detected by DH-EFM, and the higher electrical
conductivity measured by sMIM. Comparative electrical conductivity measurements
under different sMIM modes demonstrate that this contradiction arises from the
tip-loading-force-induced dynamic puckering effect, which is modulated by
interfacial bonding strength. Furthermore, the accumulation and release of
electrical conductivity during forward/backward sMIM-contact measurements
further confirmed the dynamic puckering effect, revealing the difference in
interface conditions between open ring and closed ring regions of WS2. This
work resolves the correlation between electrical properties and interface
conditions, providing insights for interface-engineered devices.

</details>


### [886] [Physics-informed diffusion models for extrapolating crystal structures beyond known motifs](https://arxiv.org/abs/2510.23181)
*Andrij Vasylenko,Federico Ottomano,Christopher M. Collins,Rahul Savani,Matthew S. Dyer,Matthew J. Rosseinsky*

Main category: cond-mat.mtrl-sci

TL;DR: 生成式AI可以通过改进的晶体结构发现新材料。


<details>
  <summary>Details</summary>
Motivation: 发现具有新颖晶体框架的材料对于实现突破性功能至关重要，但现有生成方法主要生成已知结构的变体。

Method: 提出了一种物理信息扩散方法，并结合了化学验证协议，该方法嵌入了紧密度和局部环境多样性描述符，以平衡物理可行性和结构新颖性。

Result: 通过在生成模型中加入这些度量，可以提高生成性能，将非标准结构的数量增加了67%。以生成结构为种子进行晶体结构预测（CSP），97%的候选结构可以被CSP重建，得到145个（66%）低能量且不匹配任何已知原型的新颖框架。

Conclusion: 经过化学信息学和多样性指导的生成模型可以提高CSP的效率，从而为面向发现的化学空间探索建立实用的生成-CSP协同作用。

Abstract: Discovering materials with previously unreported crystal frameworks is key to
achieving transformative functionality. Generative artificial intelligence
offers a scalable means to propose candidate crystal structures, however
existing approaches mainly reproduce decorated variants of established motifs
rather than uncover new configurations. Here we develop a physics-informed
diffusion method, supported by chemically grounded validation protocol, which
embeds descriptors of compactness and local environment diversity to balance
physical plausibility with structural novelty. Conditioning on these metrics
improves generative performance across architectures, increasing the fraction
of structures outside 100 most common prototypes up to 67%. When crystal
structure prediction (CSP) is seeded with generative structures, most
candidates (97%) are reconstructed by CSP, yielding 145 (66%) low-energy
frameworks not matching any known prototypes. These results show that while
generative models are not substitutes for CSP, their chemically informed,
diversity-guided outputs can enhance CSP efficiency, establishing a practical
generative-CSP synergy for discovery-oriented exploration of chemical space.

</details>


### [887] [A platform for zero-field isolated skyrmions: 4$d$/Co atomic bilayers on Re(0001)](https://arxiv.org/abs/2510.23236)
*Moinak Ghosh,Stefan Heinze,Souvik Paul*

Main category: cond-mat.mtrl-sci

TL;DR: 在Re(0001)表面上，Rh/Co和Pd/Co原子双层结构在无外加磁场的情况下，可以自发形成孤立的斯格明子，并且具有较高的能量势垒，有望在低温实验中实现。


<details>
  <summary>Details</summary>
Motivation: 探索在4d过渡金属/Co原子双层结构（Rh/Co, Pd/Co, Ru/Co）在Re(0001)表面上实现零磁场下孤立斯格明子的可能性。

Method: 结合第一性原理密度泛函理论（DFT）计算和原子尺度自旋模拟，使用包含高阶交换相互作用（HOI）、Dzyaloshinskii-Moriya相互作用（DMI）和磁晶各向异性能（MAE）的扩展原子尺度自旋模型，并利用DFT计算模型中的所有磁相互作用。

Result: 对于Rh/Co/Re(0001)和Pd/Co/Re(0001)体系，相图显示在无外加磁场时，孤立斯格明子可以从铁磁背景中自发出现。Rh/Co/Re(0001)中的零场孤立斯格明子半径约为6 nm，Pd/Co/Re(0001)中的约为12 nm。过渡态理论计算表明，斯格明子受到约150 meV的能量势垒保护，该势垒主要由DMI贡献，HOI有少量贡献。

Conclusion: 提出4d/Co双层结构在Re(0001)表面是一种实现纳米尺度零场孤立斯格明子的新平台。

Abstract: Using first-principles density functional theory (DFT) combined with
atomistic spin simulations, we explore the possibility of realizing zero-field
isolated skyrmions in three 4$d$/Co atomic bilayers -- Rh/Co, Pd/Co, and Ru/Co
-- grown on the Re(0001) surface. Our investigation employs an extended
atomistic spin model, which goes beyond the standard model by including the
multi-spin higher-order exchange interactions (HOI) in addition to the
Heisenberg pairwise exchange interaction, Dzyaloshinskii-Moriya interaction
(DMI), and magnetocrystalline anisotropy energy (MAE). All magnetic
interactions of the extended spin model are calculated using DFT. The phase
diagram obtained from atomistic spin simulations based on this spin model for
Rh/Co and Pd/Co on Re(0001) reveals that isolated skyrmions emerge
spontaneously on the ferromagnetic background even in the absence of an
external magnetic field. The radius of zero-field isolated skyrmions in
Rh/Co/Re(0001) is around 6 nm, whereas the radius of those skyrmions in
Pd/Co/Re(0001) is about 12 nm. Transition-state theory calculations show that
the skyrmions are protected by substantial energy barriers, approximately 150
meV, which predominantly arise from DMI, with a small contribution from the HOI
interactions. The height of the barriers suggests that skyrmions could be
observed in low-temperature experiments. Based on this work, we propose 4$d$/Co
bilayers on Re(0001) as a new platform to realize nanoscale zero-field isolated
skyrmions.

</details>


### [888] [Design principles for amorphous solid-state electrolytes](https://arxiv.org/abs/2510.23251)
*Qifan Yang,Xiao Fu,Xuhe Gong,Jingchen Lian,Liqi Wang,Ruijuan Xiao,Yong-Sheng Hu,Hong Li*

Main category: cond-mat.mtrl-sci

TL;DR: 设计无定形固态电解质（SSE）的新通用原则，通过原子模拟确定结构-性质关系。


<details>
  <summary>Details</summary>
Motivation: 无定形SSE在下一代电池中具有优势，但缺乏明确的结构-性质关系阻碍了其设计。

Method: 使用原子模拟研究了32种无定形Li-M-X体系（M = B, Al, Si, P；X = F, Cl, Br, I, O, S, Se, N），确定了四种结构类型，并识别了优化的传输机制和材料。

Result: 发现了M-X-M链的形成规则，以及桨状轮和协同迁移作为有利的传输机制。氧化物和氟化物在电化学和水解稳定性方面表现最佳，而体积模量可预测锂离子迁移率。

Conclusion: 提出了一个实用的设计图，为开发高性能无定形SSE提供了一个新颖且有价值的框架。

Abstract: Amorphous solid-state electrolytes (SSEs) offer unique advantages for
next-generation batteries, but their rational design is hindered by an unclear
structure-property relationship. This study establishes universal design
principles through atomistic simulations of 32 amorphous Li-M-X systems (M = B,
Al, Si, P; X = F, Cl, Br, I, O, S, Se, N). We identify four structure types
governed by a rule that saturated M-X groups with more negative charges
preferentially form M-X-M chains, identify paddle-wheel and cooperative
migration as two favorable transport mechanisms that are significantly enhanced
in amorphous structures. We also pinpoint Oxides and fluorides as optimal for
electrochemical and hydrolytic stability, and reveal bulk modulus as a simple
predictor for $Li^+$ mobility. These insights are integrated into a practical
design diagram, providing a novel and valuable framework for advancing
high-performance amorphous SSEs.

</details>


### [889] [General Strategy for Large Nernst Coefficient](https://arxiv.org/abs/2510.23294)
*Junya Endo,Hiroyasu Matsuura,Manfred Sigrist,Masao Ogata*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究基于Sommerfeld-Bethe关系，提出了一种提高反常Nernst系数的通用策略，并提供了系统性框架来理解铁磁体中观察到的小反常Nernst系数，同时明确了实现显著提升的条件。此外，还引入了展示大Nernst系数的简化模型作为示例。


<details>
  <summary>Details</summary>
Motivation: 解释铁磁体中反常Nernst系数较低的原因，并找出提高其数值的条件。

Method: 提出基于Sommerfeld-Bethe关系的一个通用策略，并引入简化模型。

Result: 提供了一个系统性框架来理解和提高反常Nernst系数，并通过简化模型展示了实现大Nernst系数的可能性。

Conclusion: 基于Sommerfeld-Bethe关系可以系统地提高铁磁体的反常Nernst系数。

Abstract: We propose a general strategy for enhancing the anomalous Nernst coefficient
based on the Sommerfeld-Bethe relation. This approach provides a systematic
framework for understanding the small anomalous Nernst coefficients typically
observed in ferromagnets and identifies conditions under which substantial
enhancements can be realized. We further introduce simplified models that
exhibit large Nernst coefficients as offering illustrative examples.

</details>


### [890] [User-defined Electrostatic Potentials in DFT Supercell Calculations: Implementation and Application to Electrified Interfaces](https://arxiv.org/abs/2510.23328)
*Samuel Mattoso,Jing Yang,Florian Deißenbeck,Ahmed Abdelkawy,Christoph Freysoldt,Stefan Wipperman,Mira Todorova,Jörg Neugebauer*

Main category: cond-mat.mtrl-sci

TL;DR: 提出了一种在 VASP 中施加任意电场的新方法，并讨论了能量和力学修正，该方法通过 VASP-Python 接口实现，并已成功应用于多种案例研究。


<details>
  <summary>Details</summary>
Motivation: 在密度泛函理论（DFT）计算中引入电场对于理解电化学过程、界面现象和材料在外加偏压下的行为至关重要，但直接在 DFT 代码中实现用户定义的静电势具有挑战性。

Method: 通过 VASP-Python 接口实现了一个用于超胞 DFT 计算在任意电场下的方法，并讨论了能量和力学修正。

Result: 该方法已成功应用于分子在带电表面的吸附、场离子显微镜、电化学固-液界面和隐式溶剂模型等多种案例研究。

Conclusion: 提出并验证了一种在 VASP 中施加任意电场的新方法，该方法通过 VASP-Python 接口实现，能够灵活地控制用户定义的电场，并为研究电化学和界面现象提供了新的途径。

Abstract: Introducing electric fields into density functional theory (DFT) calculations
is essential for understanding electrochemical processes, interfacial
phenomena, and the behavior of materials under applied bias. However, applying
user-defined electrostatic potentials in DFT is nontrivial and often requires
direct modification to the specific DFT code. In this work, we present an
implementation for supercell DFT calculations under arbitrary electric fields
and discuss the required corrections to the energies and forces. The
implementation is realized through the recently released VASP-Python interface,
enabling the application of user-defined fields directly within the standard
VASP software and providing great flexibility and control. We demonstrate the
application of this approach with diverse case studies, including molecular
adsorption on electrified surfaces, field ion microscopy, electrochemical
solid-water interfaces, and implicit solvent models.

</details>


### [891] [Elastic modeling and total energy calculations of the structural characteristics of "free-standing",periodic, pseudomorphic GaN/AlN superlattices](https://arxiv.org/abs/2510.23344)
*Th. Karakostas,Ph. Komninou,V. Pontikis*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究使用线性弹性理论分析了 GaN/AlN 自由支撑超晶格的组分应变状态，并将其与总能量计算结果进行了比较。结果显示，弹性模型的预测与总能量计算结果一致，证实了弹性模型的准确性，并可用于评估超晶格界面相关的能量。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是精确地分析伪морф超晶格组分的应变状态，并验证线性弹性理论在 GaN/AlN 自由支撑超晶格上的适用性。

Method: 通过应用线性弹性理论来分析 GaN/AlN 自由支撑超晶格的组分应变状态，并将其与不同厚度组分的总能量计算结果进行比较。

Result: 弹性模型预测的组分晶格常数与总能量计算结果一致，表明弹性模型是准确的。该研究还能够评估超晶格中存在的界面的能量。

Conclusion: 线性弹性理论可以准确地预测 GaN/AlN 自由支撑超晶格中组分的应变状态，并且可以用于评估界面能量。该模型为理解和设计超晶格材料提供了有价值的工具。

Abstract: The strain states of the components of pseudomorphic superlattices can be
accurately modeled analytically through the application of linear elasticity.
In this particular case of GaN/AlN 'free-standing' superlattices, the
predictions derived from elastic modeling have been compared with total energy
calculations of several systems made of components with varying thicknesses. We
demonstrate that the elastic predictions for the lattice constants of the
components align with the values obtained from their total energy counterparts,
within the limits of computational errors and uncertainties. Furthermore, a
phenomenological analysis of the elastic energy stored in the superlattices
facilitates the evaluation of the excess energies associated with the
interfaces present in these systems. The results mentioned above are briefly
contrasted with findings reported in previous literature.

</details>


### [892] [fair_data.py: implementing FAIR data compliance in Tribchem](https://arxiv.org/abs/2510.23394)
*Lucrezia Berghenti,Elisa Damiani,Margherita Marsili,Maria Clelia Righi*

Main category: cond-mat.mtrl-sci

TL;DR: TribChem 软件开发了一个新的 FAIR 实用程序，用于将计算材料科学数据转换为符合 FAIR 原则的数据集，从而提高数据的可查找性、可访问性、互操作性和可重用性，并支持开放科学实践。


<details>
  <summary>Details</summary>
Motivation: 随着计算材料科学产生的数据量和复杂性的增加，需要强大的工具来确保其可访问性、可复现性和可重用性。将 FAIR（可查找、可访问、可互操作、可重用）原则纳入计算工作流对于实现开放科学至关重要。

Method: 开发了一个名为 FAIR 的实用程序，包含两个工具：fair_data.py（自动将 TribChem 数据库的输出转换为标准化的、机器可读和人类可读的格式）和 retrieve_data.py（通过基于关键字的接口促进高效的数据提取）。

Result: FAIR 实用程序能够将 TribChem 的结果转换为符合 FAIR 标准的数据集，支持与 Zenodo 等公共存储库的无缝集成，并通过示例展示了其在本体、表面和界面系统中的能力。

Conclusion: 所提出的 FAIR 实用程序通过自动化生成符合 FAIR 原则的数据集，促进了可复现的研究，并为数据驱动的材料发现提供了支持。

Abstract: The increasing complexity and volume of data generated by high-throughput
computational materials science require robust tools to ensure their
accessibility, reproducibility, and reuse. In particular, integrating the FAIR
Guiding Principles (Findable, Accessible, Interoperable, and Reusable) into
computational workflows is essential to enable open science practices. TribChem
is an open source Python software developed for the automated simulation of
solid-solid interfaces using density functional theory (DFT). While TribChem
already incorporates several FAIR-aligned features, we present here a dedicated
FAIR utility designed to transform TribChem results into FAIR-compliant
datasets. This utility comprises two tools: fair_data.py, which automatically
generates standardized machine- and human-readable outputs from the TribChem
database, and retrieve_data.py, which facilitates efficient data extraction
through a keyword-based interface. In this paper we show the capabilities of
the fair utility with examples for bulk, surface, and interface systems. The
implementation allows seamless integration with public repositories such as
Zenodo, paving the way for reproducible research and fostering data-driven
materials discovery.

</details>


### [893] [Thermoelectric transport and the role of different scattering processes in the half-Heusler NbFeSb](https://arxiv.org/abs/2510.23466)
*Bhawna Sahni,Yao Zhao,Zhen Li,Rajeev Dutt,Patrizio Graziosi,Neophytos Neophytou*

Main category: cond-mat.mtrl-sci

TL;DR: 通过全能带依赖的散射率计算NbFeSb的电子和热电输运性质，结果与实验一致，并揭示了极性声子和离子杂质散射的重要性。


<details>
  <summary>Details</summary>
Motivation: 研究一种性能优异的半赫斯勒合金NbFeSb的电子和热电输运性质，并提出一种高效准确的计算方法。

Method: 利用Boltzmann输运方程，考虑了声学声子、非极性光学声子、极性光学声子和离子杂质散射等所有相关的散射率的全能量/动量/能带依赖性。该方法仅使用少量第一性原理提取的矩阵元，并充分考虑了带内/带间/带跃迁、电子空穴的筛选以及双极输运效应。

Result: 计算得到的功率因子（PF）值在不同密度和温度下与实验结果吻合良好，并指出了该材料PF性能的上限。研究表明，极性光学声子和离子杂质散射（包括筛选效应）对输运性质有显著影响，而非极性声子散射（声学和非极性光学）的影响相对较弱。

Conclusion: 提出的计算方法具有材料无关性，可广泛应用于其他热电材料，计算成本降低10倍以上，同时保持了第一性原理的准确性。

Abstract: We perform an ab initio computational investigation of the electronic and
thermoelectric transport properties of one of the best performance half-Heusler
(HH) alloys, NbFeSb. We use Boltzmann Transport equation while taking into
account the full energy/momentum/band dependence of all relevant electronic
scattering rates, i.e. with acoustic phonons, non-polar optical phonons (intra-
and inter-valley), polar optical phonons (POP), and ionized impurity scattering
(IIS). We use a highly efficient and accurate computational approach, where the
scattering rates are derived using only a few ab initio extracted matrix
elements, while we account fully for intra-/inter valley/band transitions,
screening from both electrons and holes, and bipolar transport effects. Our
computed thermoelectric power-factor (PF) values show good agreement with
experiments across densities and temperatures, while they indicate the upper
limit of PF performance for this material. We show that the polar optical
phonon and ionized impurity scattering (importantly including screening),
influence significantly the transport properties, whereas the computationally
expensive non-polar phonon scattering part (acoustic and non-polar optical) is
somewhat weaker, especially for electrons, and at lower to intermediate
temperatures. This insight is relevant in the study of half-Heusler and other
polar thermoelectric materials in general. Although we use NbFeSb as an
example, the method we employ is material agnostic and can be broadly applied
efficiently for electronic and thermoelectric materials in general, with more
than 10x reduction in computational cost compared to fully ab initio methods,
while retaining ab-initio accuracy.

</details>


### [894] [dynsight: an Open Python Platform for Simulation and Experimental Trajectory Data Analysis](https://arxiv.org/abs/2510.23493)
*Simone Martino,Matteo Becchi,Andrew Tarzia,Daniele Rapetti,Giovanni M. Pavan*

Main category: cond-mat.mtrl-sci

TL;DR: dynsight是一个开源Python平台，用于简化和分析模拟或实验解析的轨迹数据。


<details>
  <summary>Details</summary>
Motivation: 提取复杂多体系统的轨迹数据中的有意义信息通常需要编程技能和多个工具的集成，这给用户带来了障碍。

Method: dynsight提供了一个统一的框架，简化了从轨迹数据中提取和分析信息的工作流程，包括对象识别、轨迹追踪、数据转换和信息提取。

Result: 该平台能够处理模拟或实验解析的轨迹数据，简化工作流程，提高可访问性，并支持对不同尺度系统的动态复杂性进行分析。

Conclusion: dynsight通过提供一个易于使用的集成平台，降低了轨迹数据分析的门槛，促进了相关领域的研究发展。

Abstract: The study of complex many-body systems through the analysis of the
trajectories of dynamically moving and interacting units is a non-trivial task.
The workflow for extracting meaningful information from raw trajectory data
typically involves several interconnected steps: (i) identifying and tracking
objects, and resolving their trajectories (for example, in experimental systems
where these are not automatically available as in molecular simulations); (ii)
translating the trajectories into data that are easier to handle and analyze
using suitable descriptors; and (iii) extracting meaningful information from
these data. Each of these tasks often requires substantial programming skills,
the use of different types of representations or methods, and the development
of interfaces between them. Despite the progress made by new tools targeting
individual steps, integrating them under a common framework would lower the
barrier to use (especially for diverse communities of users), reduce
fragmentation, and ultimately facilitate the development of new approaches in
trajectory data analysis. To this end, we introduce dynsight, an open Python
platform that streamlines the extraction and analysis of time-series data from
simulation or experimentally resolved trajectories. Dynsight simplifies
workflows, enhances accessibility, and supports the analysis of time-series and
trajectory data to unravel the dynamic complexity of systems across different
scales. Dynsight is open source (available at github.com/GMPavanLab/dynsight)
and can be easily installed using pip.

</details>


### [895] [DeFecT-FF: Accelerated Modeling of Defects in Cd-Zn--Te-Se-S Compounds Combining High-Throughput DFT and Machine Learning Force Fields](https://arxiv.org/abs/2510.23514)
*Md Habibur Rahman,Arun Mannodi-Kanakkithodi*

Main category: cond-mat.mtrl-sci

TL;DR: DeFecT-FF 是一个结合了高通量 DFT 数据和基于晶体图的机器学习力场的框架，用于预测 CdTe 基太阳能电池中点缺陷、外源掺杂剂、杂质和缺陷复合物的能量和基态构型。


<details>
  <summary>Details</summary>
Motivation: CdTe 基太阳能电池的电子和缺陷性质可以通过在 Cd 或 Te 位点进行合金化来调节，以提高太阳能效率。然而，由于存在大量的缺陷类型、电荷状态和破坏对称性的构型，传统的 DFT 方法在计算上是不可行的。

Method: 开发了一个名为 DeFecT-FF 的框架，该框架结合了高通量 DFT 数据（包括 GGA-PBE 和 HSE06 优化的结构）和晶体图神经网络力场（MLFF）。使用主动学习来扩展数据集并训练 MLFF，以准确预测跨电荷状态的能量。

Result: 该模型能够快速筛选和发现新的低能缺陷构型，并通过包含自旋-轨道耦合的 HSE06 计算进行了验证。DeFecT-FF 框架作为 nanoHUB 工具公开可用，用户可以上传晶体文件，自动生成缺陷，并计算缺陷形成能与费米能级和化学势的关系。

Conclusion: DeFecT-FF 框架通过结合高通量 DFT 数据和机器学习力场，大大降低了计算成本，实现了对 CdTe 基太阳能电池中各种缺陷的快速准确预测和筛选，为提高太阳能电池效率提供了有力的工具。

Abstract: We developed DeFecT-FF, a framework for predicting the energies and
ground-state configurations of native point defects, extrinsic dopants,
impurities, and defect complexes in zincblende-phase Cd/Zn-Te/Se/S compounds
relevant to CdTe-based solar cells. The framework combines high-throughput DFT
data with crystal graph-based machine learning force fields (MLFFs) trained to
reproduce DFT energies and forces. Alloying at Cd or Te sites offers a route to
tune the electronic and defect properties of CdTe absorbers for improved solar
efficiency. Given the vast number of possible defect types, charge states, and
symmetry-breaking configurations, traditional DFT approaches are
computationally prohibitive. Our dataset includes GGA-PBE and HSE06-optimized
structures for bulk, alloyed, interface, and grain-boundary systems. Using
active learning, we expanded the dataset and trained MLFFs to accurately
predict energies across charge states. The model enabled rapid screening and
discovery of new low-energy defect configurations, validated through HSE06
calculations with spin-orbit coupling. The DeFecT-FF framework is publicly
available as a nanoHUB tool, allowing users to upload crystallographic files,
automatically generate defects, and compute defect formation energies versus
Fermi level and chemical potentials, greatly reducing the need for expensive
DFT simulations.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [896] [An Optimal Density Bound for Discretized Point Patrolling](https://arxiv.org/abs/2510.22060)
*Ahan Mishra*

Main category: cs.DS

TL;DR: 本文解决了离散点巡逻问题（点覆盖问题的一种变体）的一个长期存在的猜想，证明了密度大于等于约1.264的实例是可调度的，并为竹园修剪问题（一个优化问题）提供了一个9/7近似算法。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决离散点巡逻问题（点覆盖问题的一种变体）的调度猜想，并为竹园修剪问题（点 the pinwheel problem 的一个优化变体）提供一个更好的近似算法。

Method: 对于离散点巡逻问题，通过证明密度大于等于 ∑_{i=0}^{∞} 1/(2^i + 1) ≈ 1.264 的实例是可调度的来解决该猜想。对于竹园修剪问题，设计了一个9/7近似算法。

Result: 证明了离散点巡逻问题中密度大于等于约1.264的实例是可调度的，显著优于当前已知的1.546的密度界限，并且是最佳的。为竹园修剪问题提供了一个9/7近似算法，优于当前已知的4/3近似因子。

Conclusion: 本文的贡献在于解决了离散点巡逻问题的调度猜想，并为竹园修剪问题提供了改进的近似算法，这对实时调度和资源分配问题具有重要意义。

Abstract: The pinwheel problem is a real-time scheduling problem that asks, given $n$
tasks with periods $a_i \in \mathbb{N}$, whether it is possible to infinitely
schedule the tasks, one per time unit, such that every task $i$ is scheduled in
every interval of $a_i$ units. We study a corresponding version of this packing
problem in the covering setting, stylized as the discretized point patrolling
problem in the literature. Specifically, given $n$ tasks with periods $a_i$,
the problem asks whether it is possible to assign each day to a task such that
every task $i$ is scheduled at \textit{most} once every $a_i$ days. The density
of an instance in either case is defined as the sum of the inverses of task
periods. Recently, the long-standing $5/6$ density bound conjecture in the
packing setting was resolved affirmatively. The resolution means any instance
with density at least $5/6$ is schedulable. A corresponding conjecture was made
in the covering setting and renewed multiple times in more recent work. We
resolve this conjecture affirmatively by proving that every discretized point
patrolling instance with density at least $\sum_{i = 0}^{\infty} 1/(2^i + 1)
\approx 1.264$ is schedulable. This significantly improves upon the current
best-known density bound of 1.546 and is, in fact, optimal. We also study the
bamboo garden trimming problem, an optimization variant of the pinwheel
problem. Specifically, given $n$ growth rates with values $h_i \in \mathbb{N}$,
the objective is to minimize the maximum height of a bamboo garden with the
corresponding growth rates, where we are allowed to trim one bamboo tree to
height zero per time step. We achieve an efficient $9/7$-approximation
algorithm for this problem, improving on the current best known approximation
factor of $4/3$.

</details>


### [897] [(Approximate) Matrix Multiplication via Convolutions](https://arxiv.org/abs/2510.22193)
*Kevin Pratt,Yahel Uffenheimer,Omri Weinstein*

Main category: cs.DS

TL;DR: 本文提出了一种O(n^2.89)的精确矩阵乘法算法，并通过低度近似CKSU多项式，为快速近似矩阵乘法（AMM）提供了一个新框架，该框架打破了以往的加速-精度权衡，并在特定条件下（如随机高斯矩阵）实现了比SVD更好的低秩近似效果。


<details>
  <summary>Details</summary>
Motivation: 算法设计领域长期存在一个问题：是否存在不依赖于类似Strassen的递归实现的组合矩阵乘法算法，能够达到真正的亚立方时间复杂度O(n^{3-δ})。同时，在实际应用中，快速近似矩阵乘法（AMM）的加速-精度权衡问题也亟待解决。

Method: 本文首先构建了一个O(n^2.89)的精确矩阵乘法算法，该算法通过FFT对Z_m^k中的卷积（多元多项式乘法）进行求和，并且避免了递归。在此基础上，利用CKSU多项式的低度近似，构建了一个新的AMM框架。该框架结合了黑盒线性 sketching 技术，打破了加速-精度权衡的限制。主要成果是一个基于傅里叶集中引理的CKSU多项式低度近似方案。

Result: 本文提出的AMM算法在O(rn^2)时间内，能够实现(1/r^{1.1})*||A||_F^2*||B||_F^2的误差。对于随机高斯矩阵，该算法能够获得比输出矩阵AB的最佳秩-r SVD更小的误差，且时间复杂度为O(rn^2)。

Conclusion: 本文提出的算法在理论和实践上都展示了显著的改进，尤其是在近似矩阵乘法和低秩近似方面。研究结果表明，有潜力在大型语言模型（LLM）的训练和推理中，用卷积和替代标准的矩阵乘法。

Abstract: A longstanding open question in algorithm design is whether "combinatorial"
matrix multiplication algorithms -- avoiding Strassen-like divide-and-conquer
-- can achieve truly subcubic runtime $n^{3-\delta}$. We present an
$O(n^{2.89})$-time exact algorithm, which only sums convolutions in
$\mathbb{Z}_m^k$ (multivariate polynomial multiplications) via FFT, building on
the work of Cohn, Kleinberg, Szegedy and Umans (CKSU'05). While the algorithm
avoids recursion, the asymptotic speedup arises only for impractically large
matrices.
  Motivated by practical applications, we use this baseline to develop a new
framework for fast approximate matrix multiplication (AMM), via low-degree
approximations of the CKSU polynomials. We show that combining the
aforementioned algorithm with black-box linear sketching already breaks the
longstanding linear speed-accuracy tradeoff for AMM (Sarlos'06,
Clarkson-Woodruff'13 ,Pagh'11, Cohn-Lewis'00), achieving
$\frac{1}{r^{1.1}}\|\mathbf{A}\|_F^2\|\mathbf{B}\|_F^2$ error in
$O(rn^2)$-time.
  Our main result is a low-degree approximation scheme for the CKSU
polynomials, based on a Fourier-concentration lemma, yielding substantially
smaller error in the distributional setting where $\mathbf{A},\mathbf{B}$ come
from an i.i.d product-distribution; For random Gaussian matrices, this
practical AMM algorithm attains smaller error than the best rank-$r$ SVD of the
output matrix $\mathbf{A}\mathbf{B}$, in time $O(rn^2)$. This is a substantial
improvement over iterative Krylov subspace methods for low-rank approximation.
Our theoretical and empirical results suggest the possibility of replacing
MatMuls with sums of convolutions in LLM training and inference.

</details>


### [898] [Johnson-Lindenstrauss Lemma Beyond Euclidean Geometry](https://arxiv.org/abs/2510.22401)
*Chengyuan Deng,Jie Gao,Kevin Lu,Feng Luo,Cheng Xin*

Main category: cs.DS

TL;DR: JL引理已扩展到伪欧几里得空间和一般距离矩阵，提供了理论保证和多项式近似。


<details>
  <summary>Details</summary>
Motivation: 将JL引理从欧几里得空间扩展到非欧几里得数据（如距离矩阵）的应用。

Method: 1. 证明JL变换可应用于伪欧几里得空间中的向量。2. 证明任何对称空距离矩阵都可以表示为广义幂距离矩阵，并应用JL变换。

Result: 1. 伪欧几里得空间中的JL变换保证取决于向量的p,q范数与欧几里得范数的比值。2. 广义幂距离表示中的JL变换产生多项式近似，并具有可控的加性误差项。

Conclusion: JL引理的扩展适用于更广泛的数据集，并在理论和实践上都证明了其有效性。

Abstract: The Johnson-Lindenstrauss (JL) lemma is a cornerstone of dimensionality
reduction in Euclidean space, but its applicability to non-Euclidean data has
remained limited. This paper extends the JL lemma beyond Euclidean geometry to
handle general dissimilarity matrices that are prevalent in real-world
applications. We present two complementary approaches: First, we show the JL
transform can be applied to vectors in pseudo-Euclidean space with signature
$(p,q)$, providing theoretical guarantees that depend on the ratio of the $(p,
q)$ norm and Euclidean norm of two vectors, measuring the deviation from
Euclidean geometry. Second, we prove that any symmetric hollow dissimilarity
matrix can be represented as a matrix of generalized power distances, with an
additional parameter representing the uncertainty level within the data. In
this representation, applying the JL transform yields multiplicative
approximation with a controlled additive error term proportional to the
deviation from Euclidean geometry. Our theoretical results provide fine-grained
performance analysis based on the degree to which the input data deviates from
Euclidean geometry, making practical and meaningful reduction in dimensionality
accessible to a wider class of data. We validate our approaches on both
synthetic and real-world datasets, demonstrating the effectiveness of extending
the JL lemma to non-Euclidean settings.

</details>


### [899] [On Integer Programs That Look Like Paths](https://arxiv.org/abs/2510.22430)
*Marcin Briański,Alexandra Lassota,Kristýna Pekárková,Michał Pilipczuk,Janina Reuter*

Main category: cs.DS

TL;DR: 路径结构整数规划问题在系数受限于8时仍然是NP难的。


<details>
  <summary>Details</summary>
Motivation: 许多整数规划问题的约束矩阵具有星形结构，而路径结构是比星形结构更简单的非星形结构。研究具有这种路径结构的整数规划问题的计算复杂性。

Method: 通过从3-SAT问题进行归约，证明了所研究的整数规划问题的可行性判断是NP难的，即使约束矩阵A的所有系数都被限制在8以内。

Result: 即使约束矩阵A的所有系数都被限制在8以内，具有路径结构的整数规划问题的可行性判断仍然是NP难的。

Conclusion: 对于具有路径结构的整数规划问题，即使系数有限，其计算复杂度仍然很高，这与具有星形结构或列和绝对值受限于2的整数规划问题形成对比，是出人意料的。

Abstract: Solving integer programs of the form $\min \{\mathbf{x} \mid A\mathbf{x} =
\mathbf{b}, \mathbf{l} \leq \mathbf{x} \leq \mathbf{u}, \mathbf{x} \in
\mathbb{Z}^n \}$ is, in general, $\mathsf{NP}$-hard. Hence, great effort has
been put into identifying subclasses of integer programs that are solvable in
polynomial or $\mathsf{FPT}$ time. A common scheme for many of these integer
programs is a star-like structure of the constraint matrix. The arguably
simplest form that is not a star is a path. We study integer programs where the
constraint matrix $A$ has such a path-like structure: every non-zero
coefficient appears in at most two consecutive constraints. We prove that even
if all coefficients of $A$ are bounded by 8, deciding the feasibility of such
integer programs is $\mathsf{NP}$-hard via a reduction from 3-SAT. Given the
existence of efficient algorithms for integer programs with star-like
structures and a closely related pattern where the sum of absolute values is
column-wise bounded by 2 (hence, there are at most two non-zero entries per
column of size at most 2), this hardness result is surprising.

</details>


### [900] [Tree Embedding in High Dimensions: Dynamic and Massively Parallel](https://arxiv.org/abs/2510.22490)
*Gramoz Goranci,Shaofeng H. -C. Jiang,Peter Kiss,Qihao Kong,Yi Qian,Eva Szilagyi*

Main category: cs.DS

TL;DR: 本文提出了一种新的树嵌入构造框架，可在高维欧几里得空间中实现高效的树嵌入，并在此基础上开发了动态和大规模并行算法，可应用于k-median和earth-mover距离等问题。


<details>
  <summary>Details</summary>
Motivation: 本文旨在提高高维欧几里得空间中树嵌入的效率，以应对算法设计中的挑战，并为相关应用提供更优的解决方案。

Method: 本文提出了一种新的树嵌入构造框架，该框架基于任意度量分解，并提供失真和算法步骤局部性之间的权衡。在此框架下，开发了一种动态算法，用于维护具有更新时间的树嵌入，以及一种大规模并行算法，用于在固定轮次内实现树嵌入。

Result: 本文实现了具有O(ε(log n))失真的动态树嵌入算法，更新时间为~O(n^ε+d)；实现了具有O(ε(log n))失真的大规模并行算法，在O(1)轮次和~O(n^(1+ε))总空间内完成。这些结果可应用于k-median和earth-mover距离问题，提供~O(n^ε+d)的更新时间和O(1)轮次。

Conclusion: 本文提出的树嵌入框架和相关算法在高维欧几里得空间中实现了高效的树嵌入，并为k-median和earth-mover距离等问题提供了改进的动态和并行算法。

Abstract: Tree embedding has been a fundamental method in algorithm design with wide
applications. We focus on the efficiency of building tree embedding in various
computational settings under high-dimensional Euclidean $\mathbb{R}^d$. We
devise a new tree embedding construction framework that operates on an
arbitrary metric decomposition with bounded diameter, offering a tradeoff
between distortion and the locality of its algorithmic steps. This framework
works for general metric spaces and may be of independent interest beyond the
Euclidean setting. Using this framework, we obtain a dynamic algorithm that
maintains an $O_\epsilon(\log n)$-distortion tree embedding with update time
$\tilde O(n^\epsilon + d)$ subject to point insertions/deletions, and a
massively parallel algorithm that achieves $O_\epsilon(\log n)$-distortion in
$O(1)$ rounds and total space $\tilde O(n^{1 + \epsilon})$ (for constant
$\epsilon \in (0, 1)$). These new tree embedding results allow for a wide range
of applications. Notably, under a similar performance guarantee as in our tree
embedding algorithms, i.e., $\tilde O(n^\epsilon + d)$ update time and $O(1)$
rounds, we obtain $O_\epsilon(\log n)$-approximate dynamic and MPC algorithms
for $k$-median and earth-mover distance in $\mathbb{R}^d$.

</details>


### [901] [Generating pivot Gray codes for spanning trees of complete graphs in constant amortized time](https://arxiv.org/abs/2510.22662)
*Bowie Liu,Dennis Wong,Chan-Tong Lam,Sio-Kei Im*

Main category: cs.DS

TL;DR: 提出了一种用于完全图生成树的新的枢轴 Gray 码，解决了 Knuth 提出的一个难题，并提供了一种新的 Cayley 公式证明。


<details>
  <summary>Details</summary>
Motivation: 解决 Knuth 在《计算机程序设计艺术》中提出的关于生成树的枢轴 Gray 码的难题。

Method: 提出了一种递归算法来生成枢轴 Gray 码，并将其扩展到生成一般图的边交换 Gray 码。

Result: 成功生成了完全图的枢轴 Gray 码，并提供了 Cayley 公式的一个新证明。该算法在生成一般图的边交换 Gray 码方面也表现出色，并针对特定图类进行了优化。

Conclusion: 该研究提出了一种新颖的枢轴 Gray 码，解决了图论中的一个开放性问题，并为生成树计数提供了新的见解。

Abstract: We present the first known pivot Gray code for spanning trees of complete
graphs, listing all spanning trees such that consecutive trees differ by
pivoting a single edge around a vertex. This pivot Gray code thus addresses an
open problem posed by Knuth in The Art of Computer Programming, Volume 4
(Exercise 101, Section 7.2.1.6, [Knuth, 2011]), rated at a difficulty level of
46 out of 50, and imposes stricter conditions than existing revolving-door or
edge-exchange Gray codes for spanning trees of complete graphs. Our recursive
algorithm generates each spanning tree in constant amortized time using
$O(n^2)$ space. In addition, we provide a novel proof of Cayley's formula,
$n^{n-2}$, for the number of spanning trees in a complete graph, derived from
our recursive approach. We extend the algorithm to generate edge-exchange Gray
codes for general graphs with $n$ vertices, achieving $O(n^2)$ time per tree
using $O(n^2)$ space. For specific graph classes, the algorithm can be
optimized to generate edge-exchange Gray codes for spanning trees in constant
amortized time per tree for complete bipartite graphs, $O(n)$-amortized time
per tree for fan graphs, and $O(n)$-amortized time per tree for wheel graphs,
all using $O(n^2)$ space.

</details>


### [902] [Faster Negative-Weight Shortest Paths and Directed Low-Diameter Decompositions](https://arxiv.org/abs/2510.22721)
*Jason Li,Connor Mowry,Satish Rao*

Main category: cs.DS

TL;DR: 我们提出了一个更快的有向图低直径分解算法，其损失因子为 O(log n log log n)，运行时间为 O((m+n log log n) log n log log n)（期望）。


<details>
  <summary>Details</summary>
Motivation: 需要一个更快的有向图低直径分解算法。

Method: 提出了一种新的低直径分解算法，并将其应用于负权重单源最短路径问题。

Result: 该算法在低直径分解方面达到了 O(log n log log n) 的损失因子，运行时间为 O((m+n log log n) log n log log n)（期望）。在负权重单源最短路径问题上，运行时间达到了 O((m+n log log n) log(nW) log n log log n)。

Conclusion: 更快地解决了有向图低直径分解和负权重单源最短路径问题。

Abstract: We present a faster algorithm for low-diameter decompositions on directed
graphs, matching the $O(\log n\log\log n)$ loss factor from Bringmann, Fischer,
Haeupler, and Latypov (ICALP 2025) and improving the running time to
$O((m+n\log\log n)\log n\log\log n)$ in expectation. We then apply our faster
low-diameter decomposition to obtain an algorithm for negative-weight single
source shortest paths on integer-weighted graphs in $O((m+n\log\log
n)\log(nW)\log n\log\log n)$ time, a nearly log-factor improvement over the
algorithm of Bringmann, Cassis, and Fischer (FOCS 2023).

</details>


### [903] [$L_p$ Sampling in Distributed Data Streams with Applications to Adversarial Robustness](https://arxiv.org/abs/2510.22816)
*Honghao Lin,Zhao Song,David P. Woodruff,Shenghao Xie,Samson Zhou*

Main category: cs.DS

TL;DR: 该论文提出了一个分布式监控模型下的完美L_p采样算法，并将其应用于F_p矩估计和一系列其他分布式监控问题，实现了近乎最优的通信复杂度。


<details>
  <summary>Details</summary>
Motivation: 在分布式监控模型中，高效地从全局数据流中收集随机样本是一个强大的基础，可用于各种下游任务。然而，生成完美的L_p样本在分布式环境中具有挑战性。

Method: 该论文提出了一种新的分布式L_p采样算法，其通信复杂度为k^{p-1} 	ext{polylog}(n)比特，并证明了该复杂度是最优的（在polylogarithmic因子内）。在此基础上，他们设计了用于F_p矩估计的分布式监控协议，通信复杂度为rac{k^{p-1}}{\varepsilon^2}	ext{polylog}(n)比特，达到了最优界限。此外，该框架还被应用于计数、频率估计、重头目检测和不同元素估计等问题。

Result: 实现了针对所有p>=1的完美L_p采样，通信复杂度为k^{p-1} 	ext{polylog}(n)比特，是最优的。对于p>=2，实现了F_p矩估计的分布式监控协议，通信复杂度为rac{k^{p-1}}{\varepsilon^2}	ext{polylog}(n)比特，达到了最优通信复杂度。此外，还为计数、频率估计、重头目检测和不同元素估计等问题提供了近乎最优的分布式协议。

Conclusion: 该研究成功解决了分布式监控模型中的完美L_p采样问题，并将其有效应用于F_p矩估计和其他关键分布式监控任务，显著提高了通信效率，达到了理论最优界限。

Abstract: In the distributed monitoring model, a data stream over a universe of size
$n$ is distributed over $k$ servers, who must continuously provide certain
statistics of the overall dataset, while minimizing communication with a
central coordinator. In such settings, the ability to efficiently collect a
random sample from the global stream is a powerful primitive, enabling a wide
array of downstream tasks such as estimating frequency moments, detecting heavy
hitters, or performing sparse recovery. Of particular interest is the task of
producing a perfect $L_p$ sample, which given a frequency vector $f \in
\mathbb{R}^n$, outputs an index $i$ with probability
$\frac{f_i^p}{\|f\|_p^p}+\frac{1}{\mathrm{poly}(n)}$. In this paper, we resolve
the problem of perfect $L_p$ sampling for all $p\ge 1$ in the distributed
monitoring model. Specifically, our algorithm runs in $k^{p-1} \cdot
\mathrm{polylog}(n)$ bits of communication, which is optimal up to
polylogarithmic factors.
  Utilizing our perfect $L_p$ sampler, we achieve adversarially-robust
distributed monitoring protocols for the $F_p$ moment estimation problem, where
the goal is to provide a $(1+\varepsilon)$-approximation to
$f_1^p+\ldots+f_n^p$. Our algorithm uses
$\frac{k^{p-1}}{\varepsilon^2}\cdot\mathrm{polylog}(n)$ bits of communication
for all $p\ge 2$ and achieves optimal bounds up to polylogarithmic factors,
matching lower bounds by Woodruff and Zhang (STOC 2012) in the non-robust
setting. Finally, we apply our framework to achieve near-optimal adversarially
robust distributed protocols for central problems such as counting, frequency
estimation, heavy-hitters, and distinct element estimation.

</details>


### [904] [Hierarchical Exponential Search Via K-Spines](https://arxiv.org/abs/2510.22837)
*Bob Dong*

Main category: cs.DS

TL;DR: 文章介绍了一种名为k-spine的新概念，并基于此提出了一种在树上进行搜索的指数级算法。


<details>
  <summary>Details</summary>
Motivation: 引入k-spine概念，并利用其作为引导来设计一种搜索算法。

Method: 提出k-spine的定义，并利用其作为中心引导，通过搜索主要沿着spine来缩小目标范围，然后递归处理剩余的组件，从而设计出一种O(klog dist)的指数搜索算法。

Result: 设计出一种O(klog dist)的指数搜索算法。

Conclusion: k-spine概念可以有效地用于树上的搜索算法设计。

Abstract: We introduce the concept of a k-spine of a tree. A k-spine is essentially a
path in the tree whose removal leaves only "less-bushy" components of a smaller
pathwidth. Using a k-spine as a central guide, we introduce an O(klog dist)
exponential search algorithm on a tree by searching mainly along the spine to
narrow down the target's vicinity and then recursively handling the smaller
components.

</details>


### [905] [Testing forbidden order-pattern properties on hypergrids](https://arxiv.org/abs/2510.22845)
*Harish Chandramouleeswaran,Ilan Newman,Tomer Pelleg,Nithin Varma*

Main category: cs.DS

TL;DR: 这项研究提出了一个新颖的算法框架，用于在多维网格上测试特定模式（π-freeness）的函数。研究人员为 d=2 和 k=3 的情况设计了一种自适应测试算法，查询复杂度为 O(n^{4/5+o(1)})，并证明了相应的下界。此外，他们还提出了用于单调模式的具有对数级查询复杂度的非自适应测试算法，这与一维情况显著不同。该研究的一个关键贡献是开发了具有更强容错能力的（δ-ER）ε-测试单调性算法，查询复杂度为 O(log^{O(d)}n/(	ext{ε}(1-δ)))。最后，研究表明，对于长度为 4 的模式，在二维网格上无法实现亚线性查询测试。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在系统性地研究高维网格上模式的测试问题，特别是当模式长度 k 大于 2 时。与已充分研究的 k=2（单调性测试）情况不同，k>2 的模式测试仍有许多未解之谜。研究人员希望为这些更复杂的模式设计有效的测试算法，并探索不同模式类型（单调与非单调）之间的性能差异。

Method: 该研究设计了一种用于 d=2 和 k=3 情况下的自适应一侧测试算法，查询复杂度为 O(n^{4/5+o(1)})。他们还证明了 k=3 的下界：任何非自适应测试都需要 Ω(n) 查询，任何自适应测试都需要 Ω(sqrt(n)) 查询。对于单调模式 π=(1,2,3) 和 (3,2,1)，研究人员提出了一种查询复杂度为对数级的非自适应测试算法。此外，他们开发了一种新的、具有更强容错能力的（δ-ER）ε-测试单调性的算法，查询复杂度为 O(log^{O(d)}n/(	ext{ε}(1-δ)))。最后，他们证明了使用现有技术无法为长度为 4 的模式实现亚线性查询测试。

Result: 对于 d=2 和 k=3 的情况，研究人员设计了一个自适应测试算法，查询复杂度为 O(n^{4/5+o(1)})，并证明了 Ω(n)（非自适应）和 Ω(sqrt(n))（自适应）的下界。对于单调模式，他们实现了一个具有对数级查询复杂度的非自适应测试算法，与非单调模式的性能形成鲜明对比。研究中提出的（δ-ER）ε-测试单调性算法的查询复杂度为 O(log^{O(d)}n/(	ext{ε}(1-δ)))，优于先前仅适用于 δ=O(ε/d) 的算法。最后，研究表明，对于长度为 4 的模式，即使在二维网格上，也无法实现亚线性查询测试。

Conclusion: 该研究为高维网格上的模式测试问题提供了重要的理论贡献，特别是在 k>2 的情况下。研究人员不仅为特定情况设计了有效的测试算法，还建立了相应的下界，揭示了单调模式和非单调模式之间在测试复杂性上的巨大差异。此外，改进的单调性测试算法及其容错能力的增强，为未来的研究奠定了基础。最后，关于长度为 4 的模式无法实现亚线性查询测试的结论，指出了当前技术方法的局限性。

Abstract: We study testing $\pi$-freeness of functions $f:[n]^d\to\mathbb{R}$, where
$f$ is $\pi$-free if there there are no $k$ indices $x_1\prec\cdots\prec x_k\in
[n]^d$ such that $f(x_i)<f(x_j)$ and $\pi(i) < \pi(j)$ for all $i,j \in [k]$,
where $\prec$ is the natural partial order over $[n]^d$. Given
$\epsilon\in(0,1)$, $\epsilon$-testing $\pi$-freeness asks to distinguish
$\pi$-free functions from those which are $\epsilon$-far -- meaning at least
$\epsilon n^d$ function values must be modified to make it $\pi$-free. While
$k=2$ coincides with monotonicity testing, far less is known for $k>2$.
  We initiate a systematic study of pattern freeness on higher-dimensional
grids. For $d=2$ and all permutations of size $k=3$, we design an adaptive
one-sided tester with query complexity $O(n^{4/5+o(1)})$. We also prove general
lower bounds for $k=3$: every nonadaptive tester requires $\Omega(n)$ queries,
and every adaptive tester requires $\Omega(\sqrt{n})$ queries, yielding the
first super-logarithmic lower bounds for $\pi$-freeness. For the monotone
patterns $\pi=(1,2,3)$ and $(3,2,1)$, we present a nonadaptive tester with
polylogarithmic query complexity, giving an exponential separation between
monotone and nonmonotone patterns (unlike the one-dimensional case).
  A key ingredient in our $\pi$-freeness testers is new erasure-resilient
($\delta$-ER) $\epsilon$-testers for monotonicity over $[n]^d$ with query
complexity $O(\log^{O(d)}n/(\epsilon(1-\delta)))$, where $0<\delta<1$ is an
upper bound on the fraction of erasures. Prior ER testers worked only for
$\delta=O(\epsilon/d)$. Our nonadaptive monotonicity tester is nearly optimal
via a matching lower bound due to Pallavoor, Raskhodnikova, and Waingarten
(Random Struct. Algorithms, 2022). Finally, we show that current techniques
cannot yield sublinear-query testers for patterns of length $4$ even on
two-dimensional hypergrids.

</details>


### [906] [Multi-Way Co-Ranking: Index-Space Partitioning of Sorted Sequences Without Merge](https://arxiv.org/abs/2510.22882)
*Amit Joshi*

Main category: cs.DS

TL;DR: 提出了一种用于多路共同排序的无合并算法，该算法可以计算分割索引，将 m 个排序序列划分为前缀段，这些前缀段总共包含 K 个元素。该算法通过在索引空间中进行二分搜索来扩展到任意 m，并保持每条序列的界限，这些界限会收敛到一致的全局边界，而无需执行任何多路合并或值空间搜索。算法的时间复杂度为 O(log(Σnt) log m)，空间复杂度为 O(m)，与 K 无关。通过交换论证证明了算法的正确性，并讨论了其在分布式分数背包、并行合并分区和多流连接中的应用。


<details>
  <summary>Details</summary>
Motivation: 提出一种高效的无合并算法来解决多路共同排序问题，即在 m 个排序序列中计算分割索引 i1,...,im，使得所有前缀段包含恰好 K 个元素。

Method: 通过在索引空间中进行二分搜索来扩展现有的两列表共同排序算法以处理任意 m 个列表，并保持每条序列的界限，这些界限会收敛到一致的全局边界，从而避免了多路合并或值空间搜索。

Result: 算法的时间复杂度为 O(log(Σnt) log m)，空间复杂度为 O(m)，并且与 K 无关。

Conclusion: 该算法能够高效地解决多路共同排序问题，并且在分布式分数背包、并行合并分区和多流连接等领域具有应用潜力。

Abstract: We present a merge-free algorithm for multi-way co-ranking, the problem of
computing cut indices $i_1,\dots,i_m$ that partition each of the $m$ sorted
sequences such that all prefix segments together contain exactly $K$ elements.
Our method extends two-list co-ranking to arbitrary $m$, maintaining
per-sequence bounds that converge to a consistent global frontier without
performing any multi-way merge or value-space search. Rather, we apply binary
search to \emph{index-space}. The algorithm runs in $O(\log(\sum_t n_t)\,\log
m)$ time and $O(m)$ space, independent of $K$. We prove correctness via an
exchange argument and discuss applications to distributed fractional knapsack,
parallel merge partitioning, and multi-stream joins.
  Keywords: Co-ranking \sep partitioning \sep Merge-free algorithms \sep
Index-space optimization \sep Selection and merging \sep Data structures

</details>
