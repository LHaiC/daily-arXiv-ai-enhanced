<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 70]
- [cs.CL](#cs.CL) [Total: 50]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 11]
- [eess.SP](#eess.SP) [Total: 9]
- [cs.LO](#cs.LO) [Total: 3]
- [cs.DS](#cs.DS) [Total: 1]
- [eess.SY](#eess.SY) [Total: 19]
- [cs.GR](#cs.GR) [Total: 7]
- [cs.MA](#cs.MA) [Total: 1]
- [cs.RO](#cs.RO) [Total: 20]
- [cs.AR](#cs.AR) [Total: 4]
- [quant-ph](#quant-ph) [Total: 45]
- [cs.NE](#cs.NE) [Total: 1]
- [cs.SI](#cs.SI) [Total: 1]
- [cs.LG](#cs.LG) [Total: 64]
- [physics.app-ph](#physics.app-ph) [Total: 6]
- [cs.GT](#cs.GT) [Total: 1]
- [cs.DC](#cs.DC) [Total: 7]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 35]
- [cs.AI](#cs.AI) [Total: 39]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Towards Efficient General Feature Prediction in Masked Skeleton Modeling](https://arxiv.org/abs/2509.03609)
*Shengkai Sun,Zefan Zhang,Jianfeng Dong,Zhiyong Cheng,Xiaojun Chang,Meng Wang*

Main category: cs.CV

TL;DR: 通过高层特征预测而非原始坐标重建，GFP框架提高了自监督骨骼动作识别的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有MAE方法在自监督骨骼动作识别中，通常使用原始关节坐标作为重建目标，存在计算冗余和语义表征有限的问题。

Method: 提出了一种名为GFP（General Feature Prediction）的新框架，用高层特征预测替代低层重建。该框架包含一个轻量级的目标生成网络，用于动态生成多样的时空层级监督信号，并通过约束优化来保证特征多样性并防止模型崩溃。

Result: GFP框架在NTU RGB+D 60、NTU RGB+D 120和PKU-MMD数据集上进行了实验，结果显示其训练速度比标准的掩码骨骼建模方法快6.2倍，并且在下游任务中取得了最先进的性能。

Conclusion: GFP框架通过高层特征预测，有效解决了现有方法在计算效率和表征质量上的不足，显著提升了自监督骨骼动作识别的效果。

Abstract: Recent advances in the masked autoencoder (MAE) paradigm have significantly
propelled self-supervised skeleton-based action recognition. However, most
existing approaches limit reconstruction targets to raw joint coordinates or
their simple variants, resulting in computational redundancy and limited
semantic representation. To address this, we propose a novel General Feature
Prediction framework (GFP) for efficient mask skeleton modeling. Our key
innovation is replacing conventional low-level reconstruction with high-level
feature prediction that spans from local motion patterns to global semantic
representations. Specifically, we introduce a collaborative learning framework
where a lightweight target generation network dynamically produces diversified
supervision signals across spatial-temporal hierarchies, avoiding reliance on
pre-computed offline features. The framework incorporates constrained
optimization to ensure feature diversity while preventing model collapse.
Experiments on NTU RGB+D 60, NTU RGB+D 120 and PKU-MMD demonstrate the benefits
of our approach: Computational efficiency (with 6.2$\times$ faster training
than standard masked skeleton modeling methods) and superior representation
quality, achieving state-of-the-art performance in various downstream tasks.

</details>


### [2] [Teacher-Student Model for Detecting and Classifying Mitosis in the MIDOG 2025 Challenge](https://arxiv.org/abs/2509.03614)
*Seungho Choe,Xiaoli Qin,Abubakr Shafique,Amanda Dy,Dimitri Androutsos,Susan Done,April Khademi*

Main category: cs.CV

TL;DR: 本文提出了一种结合像素级分割和教师-学生模型的AI方法，用于自动检测和分类有丝分裂图像，以解决病理学中计数耗时和模型易受域转移影响的问题。


<details>
  <summary>Details</summary>
Motivation: 病理学家计数有丝分裂图形耗时且存在观察者间差异，AI有望通过自动化检测和保持决策一致性来解决此问题。然而，AI模型易受域转移影响，且有丝分裂数量远少于正常细胞核，导致数据严重不平衡。

Method: 将有丝分裂检测视为像素级分割问题，并提出了一种教师-学生模型，同时解决有丝分裂检测（Track 1）和非典型有丝分裂分类（Track 2）。该方法基于UNet分割骨干网络，集成了对比表示学习和域对抗训练等域泛化模块。采用教师-学生策略生成带注释的有丝分裂、难负样本以及正常细胞核的像素级伪标签，以增强特征辨别力和对抗域转移。对于分类任务，引入了一种多尺度CNN分类器，在多任务学习范式中利用分割模型的特征图。

Result: 在初步测试集中，Track 1 的 F1 分数达到 0.7660，Track 2 的平衡准确率达到 0.8414。

Conclusion: 将基于分割的检测和分类集成到统一框架中，可实现稳健的有丝分裂分析。

Abstract: Counting mitotic figures is time-intensive for pathologists and leads to
inter-observer variability. Artificial intelligence (AI) promises a solution by
automatically detecting mitotic figures while maintaining decision consistency.
However, AI tools are susceptible to domain shift, where a significant drop in
performance can occur due to differences in the training and testing sets,
including morphological diversity between organs, species, and variations in
staining protocols. Furthermore, the number of mitoses is much less than the
count of normal nuclei, which introduces severely imbalanced data for the
detection task. In this work, we formulate mitosis detection as a pixel-level
segmentation and propose a teacher-student model that simultaneously addresses
mitosis detection (Track 1) and atypical mitosis classification (Track 2). Our
method is based on a UNet segmentation backbone that integrates domain
generalization modules, namely contrastive representation learning and
domain-adversarial training. A teacher-student strategy is employed to generate
pixel-level pseudo-masks not only for annotated mitoses and hard negatives but
also for normal nuclei, thereby enhancing feature discrimination and improving
robustness against domain shift. For the classification task, we introduce a
multi-scale CNN classifier that leverages feature maps from the segmentation
model within a multi-task learning paradigm. On the preliminary test set, the
algorithm achieved an F1 score of 0.7660 in Track 1 and balanced accuracy of
0.8414 in Track 2, demonstrating the effectiveness of integrating
segmentation-based detection and classification into a unified framework for
robust mitosis analysis.

</details>


### [3] [Multi Attribute Bias Mitigation via Representation Learning](https://arxiv.org/abs/2509.03616)
*Rajeev Ranjan Dwivedi,Ankur Kumar,Vinod K Kurmi*

Main category: cs.CV

TL;DR: 该研究提出了一种名为 GMBM 的新框架，用于解决图像中存在的多种重叠偏差问题，通过两阶段方法，在训练时识别偏差，在测试时消除偏差，并引入了新的偏差度量 SBA。


<details>
  <summary>Details</summary>
Motivation: 现实世界图像中的多种重叠偏差（如纹理、水印、性别妆容、场景对象配对等）共同损害了现代视觉模型的性能，降低了其鲁棒性和公平性。单独解决这些偏差是不够的，因为减少一种偏差可能会允许或加剧其他偏差。

Method: GMBM 框架包含两个主要部分：1. 自适应偏差集成学习 (ABIL)，通过为每个属性训练编码器并将其与主骨干网络集成，强制分类器显式识别这些偏差。2. 梯度抑制微调，从骨干网络的梯度中剔除这些偏差方向，形成一个忽略所学偏差的紧凑网络。此外，研究还引入了缩放偏差放大 (SBA) 作为一种测试时间度量，以解决现有偏差度量在子群不平衡和训练测试分布变化下的局限性。

Result: 在 FB CMNIST、CelebA 和 COCO 数据集上的实验结果表明，GMBM 能够提高最差分组的准确性，将多属性偏差放大减少一半，并在 SBA 指标上创下新低，即使在偏差复杂性和分布转移加剧的情况下也是如此。

Conclusion: GMBM 是第一个实用、端到端的视觉识别多偏差解决方案，能够有效地解决现实世界图像中存在的复杂和重叠偏差问题。

Abstract: Real world images frequently exhibit multiple overlapping biases, including
textures, watermarks, gendered makeup, scene object pairings, etc. These biases
collectively impair the performance of modern vision models, undermining both
their robustness and fairness. Addressing these biases individually proves
inadequate, as mitigating one bias often permits or intensifies others. We
tackle this multi bias problem with Generalized Multi Bias Mitigation (GMBM), a
lean two stage framework that needs group labels only while training and
minimizes bias at test time. First, Adaptive Bias Integrated Learning (ABIL)
deliberately identifies the influence of known shortcuts by training encoders
for each attribute and integrating them with the main backbone, compelling the
classifier to explicitly recognize these biases. Then Gradient Suppression Fine
Tuning prunes those very bias directions from the backbone's gradients, leaving
a single compact network that ignores all the shortcuts it just learned to
recognize. Moreover we find that existing bias metrics break under subgroup
imbalance and train test distribution shifts, so we introduce Scaled Bias
Amplification (SBA): a test time measure that disentangles model induced bias
amplification from distributional differences. We validate GMBM on FB CMNIST,
CelebA, and COCO, where we boost worst group accuracy, halve multi attribute
bias amplification, and set a new low in SBA even as bias complexity and
distribution shifts intensify, making GMBM the first practical, end to end
multibias solution for visual recognition. Project page:
http://visdomlab.github.io/GMBM/

</details>


### [4] [Lightweight image segmentation for echocardiography](https://arxiv.org/abs/2509.03631)
*Anders Kjelsrud,Lasse Løvstakken,Erik Smistad,Håvard Dalen,Gilles Van De Vyver*

Main category: cs.CV

TL;DR: 通过消融研究确定了 nnU-Net 在心脏分割中的关键组件，并基于此开发了一个更小、更快的 U-Net 模型，其性能与 nnU-Net 相当，实现了实时应用。


<details>
  <summary>Details</summary>
Motivation: 为了实现左心室的精确分割，以便全自动提取临床测量数据（如心室容积和射血分数），同时克服现有 nnU-Net 模型体积大、速度慢的问题，限制其在实时场景下的应用。

Method: 通过消融研究，逐步评估了数据增强方案、网络结构修改、损失函数和后处理技术，以识别 nnU-Net 中对心脏分割最有效的组件。在此基础上，开发了一个轻量级的 U-Net 模型。

Result: 所提出的轻量级 U-Net 模型（200 万参数）在 CAMUS 数据集（500 例）上实现了与 nnU-Net 相当的性能（Dice 分数分别为 0.93/0.85/0.89 vs 0.93/0.86/0.89），但参数量减少了 16 倍，速度提高了 4 倍（每帧 1.35 毫秒 vs 5.40 毫秒）。在内部数据集（311 例）上的交叉数据集评估也证实了其相当的泛化能力。

Conclusion: 简单的仿射变换数据增强和深度监督是提高 nnU-Net 在心脏分割性能的关键因素，而复杂的数据增强和过大的网络容量则效益递减。基于这些发现，我们成功开发了一个轻量级 U-Net 模型，在保持高性能的同时，显著提高了效率，使其能够满足实时应用的需求。

Abstract: Accurate segmentation of the left ventricle in echocardiography can enable
fully automatic extraction of clinical measurements such as volumes and
ejection fraction. While models configured by nnU-Net perform well, they are
large and slow, thus limiting real-time use. We identified the most effective
components of nnU-Net for cardiac segmentation through an ablation study,
incrementally evaluating data augmentation schemes, architectural
modifications, loss functions, and post-processing techniques. Our analysis
revealed that simple affine augmentations and deep supervision drive
performance, while complex augmentations and large model capacity offer
diminishing returns. Based on these insights, we developed a lightweight U-Net
(2M vs 33M parameters) that achieves statistically equivalent performance to
nnU-Net on CAMUS (N=500) with Dice scores of 0.93/0.85/0.89 vs 0.93/0.86/0.89
for LV/MYO/LA ($p>0.05$), while being 16 times smaller and 4 times faster
(1.35ms vs 5.40ms per frame) than the default nnU-Net configuration.
Cross-dataset evaluation on an internal dataset (N=311) confirms comparable
generalization.

</details>


### [5] [treeX: Unsupervised Tree Instance Segmentation in Dense Forest Point Clouds](https://arxiv.org/abs/2509.03633)
*Josafat-Mattias Burmeister,Andreas Tockner,Stefan Reder,Markus Engel,Rico Richter,Jan-Peter Mund,Jürgen Döllner*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Close-range laser scanning provides detailed 3D captures of forest stands but
requires efficient software for processing 3D point cloud data and extracting
individual trees. Although recent studies have introduced deep learning methods
for tree instance segmentation, these approaches require large annotated
datasets and substantial computational resources. As a resource-efficient
alternative, we present a revised version of the treeX algorithm, an
unsupervised method that combines clustering-based stem detection with region
growing for crown delineation. While the original treeX algorithm was developed
for personal laser scanning (PLS) data, we provide two parameter presets, one
for ground-based laser scanning (stationary terrestrial - TLS and PLS), and one
for UAV-borne laser scanning (ULS). We evaluated the method on six public
datasets (FOR-instance, ForestSemantic, LAUTx, NIBIO MLS, TreeLearn, Wytham
Woods) and compared it to six open-source methods (original treeX, treeiso,
RayCloudTools, ForAINet, SegmentAnyTree, TreeLearn). Compared to the original
treeX algorithm, our revision reduces runtime and improves accuracy, with
instance detection F$_1$-score gains of +0.11 to +0.49 for ground-based data.
For ULS data, our preset achieves an F$_1$-score of 0.58, whereas the original
algorithm fails to segment any correct instances. For TLS and PLS data, our
algorithm achieves accuracy similar to recent open-source methods, including
deep learning. Given its algorithmic design, we see two main applications for
our method: (1) as a resource-efficient alternative to deep learning approaches
in scenarios where the data characteristics align with the method design
(sufficient stem visibility and point density), and (2) for the semi-automatic
generation of labels for deep learning models. To enable broader adoption, we
provide an open-source Python implementation in the pointtree package.

</details>


### [6] [Reg3D: Reconstructive Geometry Instruction Tuning for 3D Scene Understanding](https://arxiv.org/abs/2509.03635)
*Hongpei Zheng,Lintao Xiang,Qijun Yang,Qian Lin,Hujun Yin*

Main category: cs.CV

TL;DR: Reg3D通过引入几何感知监督，解决了大型多模态模型在3D场景理解中的挑战，通过重建几何结构而非仅描述，并在训练中同时利用3D几何信息作为输入和学习目标，从而提升了空间推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的大型多模态模型在2D视觉理解方面取得了显著进展，但将其能力扩展到3D场景理解仍然是一个重大挑战，因为仅依赖文本监督无法提供学习鲁棒3D空间表示所需的几何约束。

Method: Reg3D框架采用了一种创新的重建几何指令调整方法，将几何感知监督直接整合到训练过程中。它利用一个双编码器架构，设计了互补的物体级和帧级重建任务，强制执行几何一致性，将3D几何信息同时用作输入和明确的学习目标。

Result: 在ScanQA、Scan2Cap、ScanRefer和SQA3D等数据集上进行的广泛实验表明，Reg3D在性能上实现了显著的提升。

Conclusion: Reg3D通过结合几何信息作为输入和学习目标，为空间感知多模态模型的训练树立了新的范式，并克服了现有方法在3D场景理解方面的局限性。

Abstract: The rapid development of Large Multimodal Models (LMMs) has led to remarkable
progress in 2D visual understanding; however, extending these capabilities to
3D scene understanding remains a significant challenge. Existing approaches
predominantly rely on text-only supervision, which fails to provide the
geometric constraints required for learning robust 3D spatial representations.
In this paper, we introduce Reg3D, a novel Reconstructive Geometry Instruction
Tuning framework that addresses this limitation by incorporating geometry-aware
supervision directly into the training process. Our key insight is that
effective 3D understanding necessitates reconstructing underlying geometric
structures rather than merely describing them. Unlike existing methods that
inject 3D information solely at the input level, Reg3D adopts a
dual-supervision paradigm that leverages 3D geometric information both as input
and as explicit learning targets. Specifically, we design complementary
object-level and frame-level reconstruction tasks within a dual-encoder
architecture, enforcing geometric consistency to encourage the development of
spatial reasoning capabilities. Extensive experiments on ScanQA, Scan2Cap,
ScanRefer, and SQA3D demonstrate that Reg3D delivers substantial performance
improvements, establishing a new training paradigm for spatially aware
multimodal models.

</details>


### [7] [QuantV2X: A Fully Quantized Multi-Agent System for Cooperative Perception](https://arxiv.org/abs/2509.03704)
*Seth Z. Zhao,Huizhi Zhang,Zhaowei Li,Juntong Peng,Anthony Chui,Zewei Zhou,Zonglin Meng,Hao Xiang,Zhiyu Huang,Fujia Wang,Ran Tian,Chenfeng Xu,Bolei Zhou,Jiaqi Ma*

Main category: cs.CV

TL;DR: QuantV2X 是一个高效、可扩展的 V2X 协作感知系统，它通过端到端的量化方法，在不牺牲精度的前提下，显著降低了计算和通信开销，解决了现有系统的效率和部署问题。


<details>
  <summary>Details</summary>
Motivation: 现有 V2X 协作感知研究主要关注准确性，忽略了效率、延迟和可部署性等关键系统级因素。尤其重要的是，大多数现有系统使用全精度模型，导致计算和传输成本高，在资源受限环境中难以实现实时运行。

Method: QuantV2X 提出了一种统一的端到端量化策略，同时对神经网络模型和传输的消息表示进行量化，以降低计算负载和传输带宽。

Result: 在低比特约束下，QuantV2X 的准确性与全精度系统相当。在面向部署的指标下，QuantV2X 将系统延迟降低了 3.2 倍，mAP30 提升了 9.5%，并且能够更有效地扩展以适应严格的内存限制。

Conclusion: QuantV2X 证明了全量化多智能体中间融合系统在现实世界部署中的可行性。

Abstract: Cooperative perception through Vehicle-to-Everything (V2X) communication
offers significant potential for enhancing vehicle perception by mitigating
occlusions and expanding the field of view. However, past research has
predominantly focused on improving accuracy metrics without addressing the
crucial system-level considerations of efficiency, latency, and real-world
deployability. Noticeably, most existing systems rely on full-precision models,
which incur high computational and transmission costs, making them impractical
for real-time operation in resource-constrained environments. In this paper, we
introduce \textbf{QuantV2X}, the first fully quantized multi-agent system
designed specifically for efficient and scalable deployment of multi-modal,
multi-agent V2X cooperative perception. QuantV2X introduces a unified
end-to-end quantization strategy across both neural network models and
transmitted message representations that simultaneously reduces computational
load and transmission bandwidth. Remarkably, despite operating under low-bit
constraints, QuantV2X achieves accuracy comparable to full-precision systems.
More importantly, when evaluated under deployment-oriented metrics, QuantV2X
reduces system-level latency by 3.2$\times$ and achieves a +9.5 improvement in
mAP30 over full-precision baselines. Furthermore, QuantV2X scales more
effectively, enabling larger and more capable models to fit within strict
memory budgets. These results highlight the viability of a fully quantized
multi-agent intermediate fusion system for real-world deployment. The system
will be publicly released to promote research in this field:
https://github.com/ucla-mobility/QuantV2X.

</details>


### [8] [Transfer Learning-Based CNN Models for Plant Species Identification Using Leaf Venation Patterns](https://arxiv.org/abs/2509.03729)
*Bandita Bharadwaj,Ankur Mishra,Saurav Bharadwaj*

Main category: cs.CV

TL;DR: ResNet50, MobileNetV2, and EfficientNetB0 were evaluated for plant species classification using leaf venation patterns. EfficientNetB0 achieved the highest accuracy (94.67%), MobileNetV2 showed good generalization for real-time applications (93.34% accuracy), while ResNet50 suffered from overfitting.


<details>
  <summary>Details</summary>
Motivation: The motivation of this study is to evaluate the efficacy of three deep learning architectures (ResNet50, MobileNetV2, and EfficientNetB0) for automated plant species classification based on leaf venation patterns, which are critical morphological features with high taxonomic relevance.

Method: The study utilized the Swedish Leaf Dataset, comprising 1,125 images from 15 distinct plant species. Three deep learning models (ResNet50, MobileNetV2, and EfficientNetB0) were trained and tested using standard performance metrics to evaluate their performance in classifying plant species based on leaf venation patterns.

Result: ResNet50 achieved 94.11% training accuracy but had reduced testing accuracy (88.45%) and an F1 score of 87.82% due to overfitting. MobileNetV2 showed better generalization with 93.34% testing accuracy and a 93.23% F1 score. EfficientNetB0 outperformed the other models, achieving 94.67% testing accuracy with precision, recall, and F1 scores exceeding 94.6%.

Conclusion: The findings highlight the potential of deep learning, especially EfficientNetB0, for developing accurate and scalable tools for automated plant taxonomy using leaf venation traits. MobileNetV2 is also suitable for lightweight, real-time applications.

Abstract: This study evaluates the efficacy of three deep learning architectures:
ResNet50, MobileNetV2, and EfficientNetB0 for automated plant species
classification based on leaf venation patterns, a critical morphological
feature with high taxonomic relevance. Using the Swedish Leaf Dataset
comprising images from 15 distinct species (75 images per species, totalling
1,125 images), the models were demonstrated using standard performance metrics
during training and testing phases. ResNet50 achieved a training accuracy of
94.11% but exhibited overfitting, reflected by a reduced testing accuracy of
88.45% and an F1 score of 87.82%. MobileNetV2 demonstrated better
generalization capabilities, attaining a testing accuracy of 93.34% and an F1
score of 93.23%, indicating its suitability for lightweight, real-time
applications. EfficientNetB0 outperformed both models, achieving a testing
accuracy of 94.67% with precision, recall, and F1 scores exceeding 94.6%,
highlighting its robustness in venation-based classification. The findings
underscore the potential of deep learning, particularly EfficientNetB0, in
developing scalable and accurate tools for automated plant taxonomy using
venation traits.

</details>


### [9] [LayoutGKN: Graph Similarity Learning of Floor Plans](https://arxiv.org/abs/2509.03737)
*Casper van Engelenburg,Jan van Gemert,Seyran Khademi*

Main category: cs.CV

TL;DR: LayoutGKN通过将图核函数应用于最终学习到的节点级嵌入，显著提高了地板图比较的速度和效率，同时保持了可比或更好的准确性。


<details>
  <summary>Details</summary>
Motivation: 比较建筑布局（表示为图）对于搜索、聚类和数据可视化等应用至关重要。现有的基于图匹配网络的方法计算成本高，推理速度慢。

Method: LayoutGKN是一种更高效的方法，它通过使用可微图核作为最终学习到的节点级嵌入的距离函数，将交叉图节点级交互推迟到联合嵌入体系结构的末尾。

Result: LayoutGKN在计算相似度方面与图匹配网络相当或更好，同时显著提高了速度。

Conclusion: LayoutGKN提供了一种更有效、更快速的地板图比较方法，有望在相关应用中得到广泛应用。

Abstract: Floor plans depict building layouts and are often represented as graphs to
capture the underlying spatial relationships. Comparison of these graphs is
critical for applications like search, clustering, and data visualization. The
most successful methods to compare graphs \ie, graph matching networks, rely on
costly intermediate cross-graph node-level interactions, therefore being slow
in inference time. We introduce \textbf{LayoutGKN}, a more efficient approach
that postpones the cross-graph node-level interactions to the end of the joint
embedding architecture. We do so by using a differentiable graph kernel as a
distance function on the final learned node-level embeddings. We show that
LayoutGKN computes similarity comparably or better than graph matching networks
while significantly increasing the speed.
\href{https://github.com/caspervanengelenburg/LayoutGKN}{Code and data} are
open.

</details>


### [10] [Singular Value Few-shot Adaptation of Vision-Language Models](https://arxiv.org/abs/2509.03740)
*Taha Koleilat,Hassan Rivaz,Yiming Xiao*

Main category: cs.CV

TL;DR: CLIP-SVD是一种参数高效的视觉-语言模型（VLM）域适应技术，通过仅调整CLIP模型参数矩阵的奇异值来改进模型，实现了在11个自然和10个生物医学数据集上的先进分类结果，同时保持了模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言模型（VLM）适应新领域面临提示工程的限制和全模型微调的高成本问题。此外，使用增强组件（如提示令牌和适配器模块）可能会降低适应质量、破坏模型稳定性并损害预训练知识。

Method: CLIP-SVD利用奇异值分解（SVD）来修改CLIP的内部参数空间，通过微调CLIP参数矩阵的奇异值来重缩放基向量以适应新域，同时保留预训练模型，无需注入额外的模块。

Result: CLIP-SVD的参数量仅占模型总参数的0.04%，却在11个自然和10个生物医学数据集上取得了最先进的分类结果，在少样本设置下，其准确性和泛化能力均优于先前方法。

Conclusion: CLIP-SVD通过参数高效的奇异值调整，实现了优越的域适应性能和良好的泛化能力，克服了现有方法的局限性，并且易于解释。

Abstract: Vision-language models (VLMs) like CLIP have shown impressive zero-shot and
few-shot learning capabilities across diverse applications. However, adapting
these models to new fine-grained domains remains difficult due to reliance on
prompt engineering and the high cost of full model fine-tuning. Existing
adaptation approaches rely on augmented components, such as prompt tokens and
adapter modules, which could limit adaptation quality, destabilize the model,
and compromise the rich knowledge learned during pretraining. In this work, we
present \textbf{CLIP-SVD}, a novel \textit{multi-modal} and
\textit{parameter-efficient} adaptation technique that leverages Singular Value
Decomposition (SVD) to modify the internal parameter space of CLIP without
injecting additional modules. Specifically, we fine-tune only the singular
values of the CLIP parameter matrices to rescale the basis vectors for domain
adaptation while retaining the pretrained model. This design enables enhanced
adaptation performance using only \textbf{0.04\%} of the model's total
parameters and better preservation of its generalization ability. CLIP-SVD
achieves state-of-the-art classification results on 11 natural and 10
biomedical datasets, outperforming previous methods in both accuracy and
generalization under few-shot settings. Additionally, we leverage a natural
language-based approach to analyze the effectiveness and dynamics of the CLIP
adaptation to allow interpretability of CLIP-SVD. The code is publicly
available at https://github.com/HealthX-Lab/CLIP-SVD.

</details>


### [11] [STA-Net: A Decoupled Shape and Texture Attention Network for Lightweight Plant Disease Classification](https://arxiv.org/abs/2509.03754)
*Zongsen Qiu*

Main category: cs.CV

TL;DR: 利用一种新颖的注意力机制（STAM）和神经架构搜索（DeepMAD）来优化植物病害诊断模型，使其能在边缘设备上高效运行，并提高诊断精度。


<details>
  <summary>Details</summary>
Motivation: 目前的植物病害诊断模型在边缘设备上的部署面临挑战，现有轻量级网络使用的通用注意力机制难以捕捉病理特征。

Method: 提出了一种双重解决方案：1. 使用免训练的神经架构搜索方法DeepMAD设计高效网络骨干；2. 引入形状-纹理注意力模块（STAM），该模块包含一个使用可变形卷积（DCNv4）的形状感知分支和一个使用Gabor滤波器组的纹理感知分支。

Result: 所提出的STA-Net模型（401K参数，51.1M FLOPs）在CCMT数据集上达到了89.00%的准确率和88.96%的F1分数。消融实验表明STAM显著优于基线和标准注意力模型。

Conclusion: 通过解耦注意力机制并集成领域知识（形状和纹理），为部署在边缘设备的精准农业AI提供了一条有前景的路径。

Abstract: Responding to rising global food security needs, precision agriculture and
deep learning-based plant disease diagnosis have become crucial. Yet, deploying
high-precision models on edge devices is challenging. Most lightweight networks
use attention mechanisms designed for generic object recognition, which poorly
capture subtle pathological features like irregular lesion shapes and complex
textures. To overcome this, we propose a twofold solution: first, using a
training-free neural architecture search method (DeepMAD) to create an
efficient network backbone for edge devices; second, introducing the
Shape-Texture Attention Module (STAM). STAM splits attention into two branches
-- one using deformable convolutions (DCNv4) for shape awareness and the other
using a Gabor filter bank for texture awareness. On the public CCMT plant
disease dataset, our STA-Net model (with 401K parameters and 51.1M FLOPs)
reached 89.00% accuracy and an F1 score of 88.96%. Ablation studies confirm
STAM significantly improves performance over baseline and standard attention
models. Integrating domain knowledge via decoupled attention thus presents a
promising path for edge-deployed precision agriculture AI. The source code is
available at https://github.com/RzMY/STA-Net.

</details>


### [12] [SLENet: A Guidance-Enhanced Network for Underwater Camouflaged Object Detection](https://arxiv.org/abs/2509.03786)
*Xinxin Wang,Han Sun,Ningzhong Liu,Huiyu Zhou,Yinan Yao*

Main category: cs.CV

TL;DR: 本论文提出了一个名为SLENet的新框架，用于水下伪装物体检测（UCOD）任务，并引入了一个名为DeepCamo的新数据集。SLENet通过集成GAE模块和LGB来增强特征表示和定位能力，从而提高了检测性能。


<details>
  <summary>Details</summary>
Motivation: 水下伪装物体检测（UCOD）对于海洋生态学至关重要，但由于光学畸变、水体浑浊和海洋生物的复杂性等因素，该任务仍未得到充分研究，准确识别受到严重阻碍。

Method: 提出了一种名为SLENet的新颖框架，该框架结合了Gamma-Asymmetric Enhancement（GAE）模块和Localization Guidance Branch（LGB），以增强多尺度特征表示，并生成包含全局语义信息的定位图。该定位图用于指导Multi-Scale Supervised Decoder（MSSD）生成更准确的预测。

Result: 在DeepCamo数据集和三个标准的COD数据集上进行的实验表明，SLENet的性能优于最先进的方法，并且在更广泛的COD任务中表现出很高的通用性。

Conclusion: SLENet在水下伪装物体检测方面取得了优越的性能，并证明了其在通用物体检测任务中的有效性。

Abstract: Underwater Camouflaged Object Detection (UCOD) aims to identify objects that
blend seamlessly into underwater environments. This task is critically
important to marine ecology. However, it remains largely underexplored and
accurate identification is severely hindered by optical distortions, water
turbidity, and the complex traits of marine organisms. To address these
challenges, we introduce the UCOD task and present DeepCamo, a benchmark
dataset designed for this domain. We also propose Semantic Localization and
Enhancement Network (SLENet), a novel framework for UCOD. We first benchmark
state-of-the-art COD models on DeepCamo to reveal key issues, upon which SLENet
is built. In particular, we incorporate Gamma-Asymmetric Enhancement (GAE)
module and a Localization Guidance Branch (LGB) to enhance multi-scale feature
representation while generating a location map enriched with global semantic
information. This map guides the Multi-Scale Supervised Decoder (MSSD) to
produce more accurate predictions. Experiments on our DeepCamo dataset and
three benchmark COD datasets confirm SLENet's superior performance over SOTA
methods, and underscore its high generality for the broader COD task.

</details>


### [13] [Fitting Image Diffusion Models on Video Datasets](https://arxiv.org/abs/2509.03794)
*Juhun Lee,Simon S. Woo*

Main category: cs.CV

TL;DR: 通过利用视频帧中固有的时间归纳偏差，提出了一种新的扩散模型训练策略，该策略可加速收敛，提高生成多样性，并改善分布覆盖。


<details>
  <summary>Details</summary>
Motivation: 标准的扩散模型在独立采样的静态图像上进行训练，这种方法在捕获动态世界时存在信息缺失的缺点，导致收敛速度慢、分布覆盖受限和泛化能力下降。

Method: 提出了一种利用连续视频帧中固有的时间归纳偏差的训练策略，无需修改模型架构，即可无缝集成到标准扩散模型训练流程中。

Result: 在HandCo数据集上进行的实验表明，该方法将收敛速度提高了2倍以上，并在训练和验证分布上都取得了更低的FID分数，同时通过鼓励模型捕获有意义的时间变化来提高生成多样性。

Conclusion: 该方法通过减少梯度方差来加速收敛，从而提高了扩散模型的训练效率和生成质量。

Abstract: Image diffusion models are trained on independently sampled static images.
While this is the bedrock task protocol in generative modeling, capturing the
temporal world through the lens of static snapshots is information-deficient by
design. This limitation leads to slower convergence, limited distributional
coverage, and reduced generalization. In this work, we propose a simple and
effective training strategy that leverages the temporal inductive bias present
in continuous video frames to improve diffusion training. Notably, the proposed
method requires no architectural modification and can be seamlessly integrated
into standard diffusion training pipelines. We evaluate our method on the
HandCo dataset, where hand-object interactions exhibit dense temporal coherence
and subtle variations in finger articulation often result in semantically
distinct motions. Empirically, our method accelerates convergence by over
2$\text{x}$ faster and achieves lower FID on both training and validation
distributions. It also improves generative diversity by encouraging the model
to capture meaningful temporal variations. We further provide an optimization
analysis showing that our regularization reduces the gradient variance, which
contributes to faster convergence.

</details>


### [14] [MedVista3D: Vision-Language Modeling for Reducing Diagnostic Errors in 3D CT Disease Detection, Understanding and Reporting](https://arxiv.org/abs/2509.03800)
*Yuheng Li,Yenho Chen,Yuxiang Lai,Jike Zhong,Vanessa Wildman,Xiaofeng Yang*

Main category: cs.CV

TL;DR: MedVista3D是一个用于3D CT分析的多尺度语义增强视觉-语言预训练框架，解决了现有模型在局部检测、全局推理和报告生成方面的不足，并在多种下游任务中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的放射学诊断系统在处理3D影像时，在局部异常检测、全局上下文理解和报告语言一致性方面存在挑战，尤其是在处理海量3D影像切片时。

Method: MedVista3D通过局部和全局的图像-文本对齐来实现细粒度的表征学习，并结合语言模型重写和语义匹配银行来处理报告的变异性，从而实现联合疾病检测和整体解释。

Result: MedVista3D在零样本疾病分类、报告检索和医学视觉问答任务上取得了最先进的性能，并且在器官分割和预后预测任务上也表现出良好的迁移能力。

Conclusion: MedVista3D成功地解决了3D医学影像分析中的关键挑战，并在多个下游任务中展现了优越的性能和良好的泛化能力。

Abstract: Radiologic diagnostic errors-under-reading errors, inattentional blindness,
and communication failures-remain prevalent in clinical practice. These issues
often stem from missed localized abnormalities, limited global context, and
variability in report language. These challenges are amplified in 3D imaging,
where clinicians must examine hundreds of slices per scan. Addressing them
requires systems with precise localized detection, global volume-level
reasoning, and semantically consistent natural language reporting. However,
existing 3D vision-language models are unable to meet all three needs jointly,
lacking local-global understanding for spatial reasoning and struggling with
the variability and noise of uncurated radiology reports. We present
MedVista3D, a multi-scale semantic-enriched vision-language pretraining
framework for 3D CT analysis. To enable joint disease detection and holistic
interpretation, MedVista3D performs local and global image-text alignment for
fine-grained representation learning within full-volume context. To address
report variability, we apply language model rewrites and introduce a Radiology
Semantic Matching Bank for semantics-aware alignment. MedVista3D achieves
state-of-the-art performance on zero-shot disease classification, report
retrieval, and medical visual question answering, while transferring well to
organ segmentation and prognosis prediction. Code and datasets will be
released.

</details>


### [15] [Causality-guided Prompt Learning for Vision-language Models via Visual Granulation](https://arxiv.org/abs/2509.03803)
*Mengyu Gao,Qiulei Dong*

Main category: cs.CV

TL;DR: CaPL是一种利用视觉粒化和因果推断来改进CLIP模型在细粒度识别任务中表现的提示学习方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于CLIP的提示学习方法在处理细粒度数据集时能力有限。

Method: CaPL提出了一种因果引导的文本提示学习方法，通过视觉粒化技术构建视觉颗粒集，以捕捉细粒度类别间的细微差别。具体包括：1. 使用布朗桥扩散模型将视觉特征分解为非个体化属性和个体化属性。2. 利用因果推断策略整合属性以构建视觉颗粒，从而学习更具辨别力的文本提示。

Result: 在15个数据集上的大量实验结果表明，CaPL在细粒度数据集上的表现显著优于现有的最先进的提示学习方法。

Conclusion: CaPL通过视觉粒化和因果推断，能够学习到更具辨别力的文本提示，尤其在细粒度识别任务上表现出色。

Abstract: Prompt learning has recently attracted much attention for adapting
pre-trained vision-language models (e.g., CLIP) to downstream recognition
tasks. However, most of the existing CLIP-based prompt learning methods only
show a limited ability for handling fine-grained datasets. To address this
issue, we propose a causality-guided text prompt learning method via visual
granulation for CLIP, called CaPL, where the explored visual granulation
technique could construct sets of visual granules for the text prompt to
capture subtle discrepancies among different fine-grained classes through
casual inference. The CaPL method contains the following two modules: (1) An
attribute disentanglement module is proposed to decompose visual features into
non-individualized attributes (shared by some classes) and individualized
attributes (specific to single classes) using a Brownian Bridge Diffusion
Model; (2) A granule learning module is proposed to construct visual granules
by integrating the aforementioned attributes for recognition under two causal
inference strategies. Thanks to the learned visual granules, more
discriminative text prompt is expected to be learned. Extensive experimental
results on 15 datasets demonstrate that our CaPL method significantly
outperforms the state-of-the-art prompt learning methods, especially on
fine-grained datasets.

</details>


### [16] [EGTM: Event-guided Efficient Turbulence Mitigation](https://arxiv.org/abs/2509.03808)
*Huanan Li,Rui Fan,Juntao Guan,Weidong Hao,Lai Rui,Tong Wu,Yikai Wang,Lin Gu*

Main category: cs.CV

TL;DR: 事件相机通过利用其高时间分辨率和稀疏成像机制，提出了一种名为EGTM的新型框架，用于解决传统深度学习湍流减缓方法在计算和存储效率方面的不足。该方法通过揭示湍流失真与事件流逆时空分布之间的相关性，提取像素级无湍流引导，实现了在模型尺寸、推理延迟和模型复杂度方面的显著提升，同时保持了顶尖的复原质量。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习湍流减缓（TM）方法需要高容量网络来学习同步帧之间的粗粒度湍流动力学，这导致计算和存储效率低下。事件相机具有微秒级的时间分辨率和高效的稀疏异步成像机制，有潜力从根本上解决这一瓶颈。

Method: 提出了一种名为EGTM的新型框架，该框架基于“事件-幸运洞察”（event-lucky insight），揭示了湍流失真与事件流逆时空分布之间的相关性。该框架从显式但嘈杂的湍流事件中提取像素级可靠的无湍流引导，用于时间幸运融合。

Result: EGTM框架在模型尺寸、推理延迟和模型复杂度方面分别比现有最先进的TM方法提高了710倍、214倍和224倍，同时在恢复质量方面（+0.94 PSNR和+0.08 SSIM）也达到了最先进水平。此外，还构建了首个面向TM任务的、驱动事件的真实世界数据集。

Conclusion: 将事件模型引入TM任务具有显著的效率优势，能够有效解决现有方法的计算和存储效率问题，并在恢复质量方面取得优异成果。

Abstract: Turbulence mitigation (TM) aims to remove the stochastic distortions and
blurs introduced by atmospheric turbulence into frame cameras. Existing
state-of-the-art deep-learning TM methods extract turbulence cues from multiple
degraded frames to find the so-called "lucky'', not distorted patch, for "lucky
fusion''. However, it requires high-capacity network to learn from
coarse-grained turbulence dynamics between synchronous frames with limited
frame-rate, thus fall short in computational and storage efficiency. Event
cameras, with microsecond-level temporal resolution, have the potential to
fundamentally address this bottleneck with efficient sparse and asynchronous
imaging mechanism. In light of this, we (i) present the fundamental
\textbf{``event-lucky insight''} to reveal the correlation between turbulence
distortions and inverse spatiotemporal distribution of event streams. Then,
build upon this insight, we (ii) propose a novel EGTM framework that extracts
pixel-level reliable turbulence-free guidance from the explicit but noisy
turbulent events for temporal lucky fusion. Moreover, we (iii) build the first
turbulence data acquisition system to contribute the first real-world
event-driven TM dataset. Extensive experimental results demonstrate that our
approach significantly surpass the existing SOTA TM method by 710 times, 214
times and 224 times in model size, inference latency and model complexity
respectively, while achieving the state-of-the-art in restoration quality
(+0.94 PSNR and +0.08 SSIM) on our real-world EGTM dataset. This demonstrating
the great efficiency merit of introducing event modality into TM task. Demo
code and data have been uploaded in supplementary material and will be released
once accepted.

</details>


### [17] [Focus Through Motion: RGB-Event Collaborative Token Sparsification for Efficient Object Detection](https://arxiv.org/abs/2509.03872)
*Nan Yang,Yang Wang,Zhanwen Liu,Yuchao Dai,Yang Liu,Xiangmo Zhao*

Main category: cs.CV

TL;DR: FocusMamba通过事件引导的多模态稀疏化和跨模态焦点融合，实现了RGB-事件检测的准确性和效率的平衡。


<details>
  <summary>Details</summary>
Motivation: 现有的RGB-事件检测方法在处理低信息区域时存在计算成本高和性能不佳的问题，并且现有的稀疏化方法无法适应不同复杂度的样本。

Method: 提出了一种事件引导的多模态稀疏化（EGMS）策略，用于自适应地识别和丢弃每个模态内的低信息区域，并结合跨模态焦点融合（CMFF）模块来捕获和整合来自两个模态的互补特征。

Result: 在DSEC-Det和PKU-DAVIS-SOD数据集上，FocusMamba在准确性和效率方面均优于现有方法。

Conclusion: FocusMamba通过自适应稀疏化和有效的多模态特征融合，解决了RGB-事件检测中的计算冗余和性能瓶颈问题，实现了准确性和效率的提升。

Abstract: Existing RGB-Event detection methods process the low-information regions of
both modalities (background in images and non-event regions in event data)
uniformly during feature extraction and fusion, resulting in high computational
costs and suboptimal performance. To mitigate the computational redundancy
during feature extraction, researchers have respectively proposed token
sparsification methods for the image and event modalities. However, these
methods employ a fixed number or threshold for token selection, hindering the
retention of informative tokens for samples with varying complexity. To achieve
a better balance between accuracy and efficiency, we propose FocusMamba, which
performs adaptive collaborative sparsification of multimodal features and
efficiently integrates complementary information. Specifically, an Event-Guided
Multimodal Sparsification (EGMS) strategy is designed to identify and
adaptively discard low-information regions within each modality by leveraging
scene content changes perceived by the event camera. Based on the
sparsification results, a Cross-Modality Focus Fusion (CMFF) module is proposed
to effectively capture and integrate complementary features from both
modalities. Experiments on the DSEC-Det and PKU-DAVIS-SOD datasets demonstrate
that the proposed method achieves superior performance in both accuracy and
efficiency compared to existing methods. The code will be available at
https://github.com/Zizzzzzzz/FocusMamba.

</details>


### [18] [SalientFusion: Context-Aware Compositional Zero-Shot Food Recognition](https://arxiv.org/abs/2509.03873)
*Jiajun Song,Xiaoou Liu*

Main category: cs.CV

TL;DR: 提出了一种名为SalientFusion的组合零样本食物识别（CZSFR）方法，以解决食物识别中的背景冗余、主食/配菜角色混淆以及语义偏差问题，并在新基准测试和通用CZSL数据集上取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 由于新菜肴的快速出现，需要对未见过的食物类别进行识别，因此提出了零样本食物学习（ZSFL），特别是组合零样本食物识别（CZSFR），因为菜肴和食材可以自然地与组合零样本学习（CZSL）中的属性和对象对齐。

Method: 提出SalientFusion方法，包含两个组件：SalientFormer（去除背景冗余，利用深度特征解决角色混淆）和DebiasAT（通过对齐提示和视觉特征来减少语义偏差）。

Result: 在CZSFood-90和CZSFood-164基准测试以及通用的CZSL数据集上，SalientFusion均取得了最先进的成果。

Conclusion: SalientFusion成功解决了CZSFR面临的挑战，并在相关数据集上取得了优异表现。

Abstract: Food recognition has gained significant attention, but the rapid emergence of
new dishes requires methods for recognizing unseen food categories, motivating
Zero-Shot Food Learning (ZSFL). We propose the task of Compositional Zero-Shot
Food Recognition (CZSFR), where cuisines and ingredients naturally align with
attributes and objects in Compositional Zero-Shot learning (CZSL). However,
CZSFR faces three challenges: (1) Redundant background information distracts
models from learning meaningful food features, (2) Role confusion between
staple and side dishes leads to misclassification, and (3) Semantic bias in a
single attribute can lead to confusion of understanding. Therefore, we propose
SalientFusion, a context-aware CZSFR method with two components: SalientFormer,
which removes background redundancy and uses depth features to resolve role
confusion; DebiasAT, which reduces the semantic bias by aligning prompts with
visual features. Using our proposed benchmarks, CZSFood-90 and CZSFood-164, we
show that SalientFusion achieves state-of-the-art results on these benchmarks
and the most popular general datasets for the general CZSL. The code is
avaliable at https://github.com/Jiajun-RUC/SalientFusion.

</details>


### [19] [Human Motion Video Generation: A Survey](https://arxiv.org/abs/2509.03883)
*Haiwei Xue,Xiangyang Luo,Zhanghao Hu,Xin Zhang,Xunzhi Xiang,Yuqin Dai,Jianzhuang Liu,Zhensong Zhang,Minglei Li,Jian Yang,Fei Ma,Zhiyong Wu,Changpeng Yang,Zonghong Dai,Fei Richard Yu*

Main category: cs.CV

TL;DR: 本篇论文对人体运动视频生成领域进行了全面的调查，涵盖了超过十个子任务和五个关键生成阶段，并探讨了大型语言模型在该领域的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 现有关于人体运动视频生成的调查主要关注单个方法，缺乏对整个生成过程的全面概述。本研究旨在填补这一空白。

Method: 本研究对人体运动视频生成领域进行了深入调查，涵盖了输入、运动规划、运动视频生成、优化和输出五个关键阶段，并回顾了跨越视觉、文本和音频三种主要模态的最新发展和技术趋势。共计审视了200多篇论文。

Result: 本研究全面概述了人体运动视频生成领域，重点介绍了推动技术突破的里程碑式工作，并首次探讨了大型语言模型在该领域的应用潜力。

Conclusion: 本调查旨在揭示人体运动视频生成的前景，并为推进数字人的综合应用提供宝贵的资源。

Abstract: Human motion video generation has garnered significant research interest due
to its broad applications, enabling innovations such as photorealistic singing
heads or dynamic avatars that seamlessly dance to music. However, existing
surveys in this field focus on individual methods, lacking a comprehensive
overview of the entire generative process. This paper addresses this gap by
providing an in-depth survey of human motion video generation, encompassing
over ten sub-tasks, and detailing the five key phases of the generation
process: input, motion planning, motion video generation, refinement, and
output. Notably, this is the first survey that discusses the potential of large
language models in enhancing human motion video generation. Our survey reviews
the latest developments and technological trends in human motion video
generation across three primary modalities: vision, text, and audio. By
covering over two hundred papers, we offer a thorough overview of the field and
highlight milestone works that have driven significant technological
breakthroughs. Our goal for this survey is to unveil the prospects of human
motion video generation and serve as a valuable resource for advancing the
comprehensive applications of digital humans. A complete list of the models
examined in this survey is available in Our Repository
https://github.com/Winn1y/Awesome-Human-Motion-Video-Generation.

</details>


### [20] [OccTENS: 3D Occupancy World Model via Temporal Next-Scale Prediction](https://arxiv.org/abs/2509.03887)
*Bu Jin,Songen Gu,Xiaotao Hu,Yupeng Zheng,Xiaoyang Guo,Qian Zhang,Xiaoxiao Long,Wei Yin*

Main category: cs.CV

TL;DR: OccTENS是一个生成式占用世界模型，能够进行可控、高保真的长期占用生成，同时保持计算效率。它通过将占用世界模型重新构建为时间尺度预测（TENS）任务，并使用TensFormer来解决现有自回归方法的低效、长期生成中的时间退化和缺乏可控性等问题。此外，通过整体姿态聚合策略增强了姿态可控性。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于自回归（AR）的占用世界模型在长期生成中面临的低效、时间退化和缺乏可控性等问题。

Method: 将占用世界模型重新构建为时间尺度预测（TENS）任务，并提出TensFormer来建模占用序列的时空关系。同时，提出整体姿态聚合策略来增强姿态可控性。

Result: OccTENS在占用质量和推理速度上均优于现有最先进的方法。

Conclusion: OccTENS能够实现可控、高保真的长期占用生成，并具有计算效率。

Abstract: In this paper, we propose OccTENS, a generative occupancy world model that
enables controllable, high-fidelity long-term occupancy generation while
maintaining computational efficiency. Different from visual generation, the
occupancy world model must capture the fine-grained 3D geometry and dynamic
evolution of the 3D scenes, posing great challenges for the generative models.
Recent approaches based on autoregression (AR) have demonstrated the potential
to predict vehicle movement and future occupancy scenes simultaneously from
historical observations, but they typically suffer from \textbf{inefficiency},
\textbf{temporal degradation} in long-term generation and \textbf{lack of
controllability}. To holistically address these issues, we reformulate the
occupancy world model as a temporal next-scale prediction (TENS) task, which
decomposes the temporal sequence modeling problem into the modeling of spatial
scale-by-scale generation and temporal scene-by-scene prediction. With a
\textbf{TensFormer}, OccTENS can effectively manage the temporal causality and
spatial relationships of occupancy sequences in a flexible and scalable way. To
enhance the pose controllability, we further propose a holistic pose
aggregation strategy, which features a unified sequence modeling for occupancy
and ego-motion. Experiments show that OccTENS outperforms the state-of-the-art
method with both higher occupancy quality and faster inference time.

</details>


### [21] [Weakly-Supervised Learning of Dense Functional Correspondences](https://arxiv.org/abs/2509.03893)
*Stefan Stojanov,Linan Zhao,Yunzhi Zhang,Daniel L. K. Yamins,Jiajun Wu*

Main category: cs.CV

TL;DR: 本文提出了一种基于物体功能引导的密集对应学习方法，用于解决跨类别图像匹配的挑战。


<details>
  <summary>Details</summary>
Motivation: 物体功能的一致性可以指导跨类别图像的密集对应建立，因为实现特定功能的物体部件通常在形状和外观上具有相似性。

Method: 首先，基于物体功能相似性定义了密集功能对应。然后，提出了一种弱监督学习范式，利用视觉-语言模型为多视图图像生成伪标签，以识别功能部件。最后，将此与来自像素对应的密集对比学习相结合，以提取功能和空间知识。

Result: 所提出的方法在合成和真实评估数据集上，相比于现成的自监督图像表示和基于视觉-语言模型的解决方案，表现出了优越性。

Conclusion: 基于物体功能引导的密集对应学习方法能够有效解决跨类别图像匹配的挑战。

Abstract: Establishing dense correspondences across image pairs is essential for tasks
such as shape reconstruction and robot manipulation. In the challenging setting
of matching across different categories, the function of an object, i.e., the
effect that an object can cause on other objects, can guide how correspondences
should be established. This is because object parts that enable specific
functions often share similarities in shape and appearance. We derive the
definition of dense functional correspondence based on this observation and
propose a weakly-supervised learning paradigm to tackle the prediction task.
The main insight behind our approach is that we can leverage vision-language
models to pseudo-label multi-view images to obtain functional parts. We then
integrate this with dense contrastive learning from pixel correspondences to
distill both functional and spatial knowledge into a new model that can
establish dense functional correspondence. Further, we curate synthetic and
real evaluation datasets as task benchmarks. Our results demonstrate the
advantages of our approach over baseline solutions consisting of off-the-shelf
self-supervised image representations and grounded vision language models.

</details>


### [22] [Attn-Adapter: Attention Is All You Need for Online Few-shot Learner of Vision-Language Model](https://arxiv.org/abs/2509.03895)
*Phuoc-Nguyen Bui,Khanh-Binh Nguyen,Hyunseung Choo*

Main category: cs.CV

TL;DR: Attn-Adapter是一个创新的在线少样本学习框架，通过双注意力机制增强CLIP模型的适应性，解决了现有方法在少样本场景下的计算密集和过拟合问题。


<details>
  <summary>Details</summary>
Motivation: 现有的对比视觉-语言模型在少样本场景下进行微调时计算量大且容易过拟合，Attn-Adapter旨在克服这些局限性。

Method: Attn-Adapter通过内存注意力适配器（Memory Attn-Adapter）和局部-全局注意力适配器（Local-Global Attn-Adapter）两个组件，利用少量标记样本动态调整模型，无需重新训练基础模型。

Result: Attn-Adapter在跨类别和跨数据集泛化方面优于现有最先进的方法，同时保持了高效的推理能力，并可扩展至不同的CLIP骨干网络。

Conclusion: Attn-Adapter通过引入数据集特定的信息，实现了高效的在线少样本学习，显著提升了CLIP模型在少样本图像识别任务上的性能和泛化能力。

Abstract: Contrastive vision-language models excel in zero-shot image recognition but
face challenges in few-shot scenarios due to computationally intensive offline
fine-tuning using prompt learning, which risks overfitting. To overcome these
limitations, we propose Attn-Adapter, a novel online few-shot learning
framework that enhances CLIP's adaptability via a dual attention mechanism. Our
design incorporates dataset-specific information through two components: the
Memory Attn-Adapter, which refines category embeddings using support examples,
and the Local-Global Attn-Adapter, which enriches image embeddings by
integrating local and global features. This architecture enables dynamic
adaptation from a few labeled samples without retraining the base model.
Attn-Adapter outperforms state-of-the-art methods in cross-category and
cross-dataset generalization, maintaining efficient inference and scaling
across CLIP backbones.

</details>


### [23] [YOLO Ensemble for UAV-based Multispectral Defect Detection in Wind Turbine Components](https://arxiv.org/abs/2509.04156)
*Serhii Svystun,Pavlo Radiuk,Oleksandr Melnychenko,Oleg Savenko,Anatoliy Sachenko*

Main category: cs.CV

TL;DR: 本文提出了一种集成可见光和热力学通道的YOLO基础模型集成方法，用于提高风力涡轮机部件缺陷检测的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统的风力涡轮机监测方法依赖于高分辨率数据和高效的图像处理技术，但仍面临挑战。本研究旨在通过开发一种集成了可见光和热力学通道的YOLO基础模型集成方法，来提高缺陷检测的准确性。

Method: 提出了一种集成了通用YOLOv8模型和专用热力学模型的集成方法，并使用先进的边界框融合算法来结合它们的预测结果。

Result: 所提出的方法实现了0.93的平均精度均值（mAP@.5）和0.90的F1分数，优于单独的YOLOv8模型（mAP@.5为0.91）。

Conclusion: 结合使用多种YOLO架构和融合后的多光谱数据为风力涡轮机缺陷检测提供了更可靠的解决方案，能够同时检测视觉和热力学缺陷。

Abstract: Unmanned aerial vehicles (UAVs) equipped with advanced sensors have opened up
new opportunities for monitoring wind power plants, including blades, towers,
and other critical components. However, reliable defect detection requires
high-resolution data and efficient methods to process multispectral imagery. In
this research, we aim to enhance defect detection accuracy through the
development of an ensemble of YOLO-based deep learning models that integrate
both visible and thermal channels. We propose an ensemble approach that
integrates a general-purpose YOLOv8 model with a specialized thermal model,
using a sophisticated bounding box fusion algorithm to combine their
predictions. Our experiments show this approach achieves a mean Average
Precision (mAP@.5) of 0.93 and an F1-score of 0.90, outperforming a standalone
YOLOv8 model, which scored an mAP@.5 of 0.91. These findings demonstrate that
combining multiple YOLO architectures with fused multispectral data provides a
more reliable solution, improving the detection of both visual and thermal
defects.

</details>


### [24] [SPECS: Specificity-Enhanced CLIP-Score for Long Image Caption Evaluation](https://arxiv.org/abs/2509.03897)
*Xiaofu Chen,Israfel Salazar,Yova Kementchedjhieva*

Main category: cs.CV

TL;DR: SPECS是一种新的参考自由表示相似性（RS）指标，通过引入强调特异性的新目标来优化CLIP，以提高长图像字幕生成评估的效率和准确性，其性能可与基于LLM的指标相媲美，但成本更低。


<details>
  <summary>Details</summary>
Motivation: 随着对生成长而详细的图像字幕的兴趣日益增长，标准的评估指标变得越来越不可靠。基于N-gram的指标虽然高效，但无法捕捉语义的正确性。基于表示相似性（RS）的指标虽然旨在解决这个问题，但由于计算成本高昂，最初使用受限，而如今，尽管硬件有所进步，但由于与人类判断的相关性低，它们仍然不受欢迎。基于大型语言模型（LLM）的指标虽然与人类判断的相关性很大，但对于模型开发过程中的迭代使用来说成本仍然过高。

Method: SPECS（Specificity-Enhanced CLIPScore）是一种参考自由的RS指标，它通过引入一个强调特异性的新目标来修改CLIP，以实现长图像字幕的定制化。该目标旨在奖励正确的细节并惩罚不正确的细节。

Result: SPECS在与人类判断的相关性方面，其性能与开源的、基于LLM的指标相匹配，同时效率也更高。

Conclusion: SPECS为图像字幕模型开发过程中的迭代模型评估提供了一种经济高效且准确的替代方案。

Abstract: As interest grows in generating long, detailed image captions, standard
evaluation metrics become increasingly unreliable. N-gram-based metrics though
efficient, fail to capture semantic correctness. Representational Similarity
(RS) metrics, designed to address this, initially saw limited use due to high
computational costs, while today, despite advances in hardware, they remain
unpopular due to low correlation to human judgments. Meanwhile, metrics based
on large language models (LLMs) show strong correlation with human judgments,
but remain too expensive for iterative use during model development.
  We introduce SPECS (Specificity-Enhanced CLIPScore), a reference-free RS
metric tailored to long image captioning. SPECS modifies CLIP with a new
objective that emphasizes specificity: rewarding correct details and penalizing
incorrect ones. We show that SPECS matches the performance of open-source
LLM-based metrics in correlation to human judgments, while being far more
efficient. This makes it a practical alternative for iterative checkpoint
evaluation during image captioning model development.Our code can be found at
https://github.com/mbzuai-nlp/SPECS.

</details>


### [25] [A Generative Foundation Model for Chest Radiography](https://arxiv.org/abs/2509.03903)
*Yuanfeng Ji,Dan Lin,Xiyue Wang,Lu Zhang,Wenhui Zhou,Chongjian Ge,Ruihang Chu,Xiaoli Yang,Junhan Zhao,Junsong Chen,Xiangde Luo,Sen Yang,Jin Fang,Ping Luo,Ruijiang Li*

Main category: cs.CV

TL;DR: ChexGen是一个生成式医学影像模型，可以根据文本、掩码和边界框生成胸部X光片，用于改进医疗AI模型的数据效率、准确性和公平性。


<details>
  <summary>Details</summary>
Motivation: 医疗AI模型研发面临标注困难、数据稀疏等问题。

Method: 基于潜在扩散Transformer架构，在960,000张胸部X光片报告对数据集上预训练ChexGen模型，以实现文本、掩码和边界框引导的胸部X光片合成。

Result: ChexGen在专家评估和量化指标上表现出准确的X光片合成能力，并能通过数据增强和监督预训练提高下游任务性能，同时还能通过创建多样化的患者队列来增强模型公平性。

Conclusion: 生成式基础模型将在构建更准确、数据高效和公平的医疗AI系统方面发挥变革性作用。

Abstract: The scarcity of well-annotated diverse medical images is a major hurdle for
developing reliable AI models in healthcare. Substantial technical advances
have been made in generative foundation models for natural images. Here we
develop `ChexGen', a generative vision-language foundation model that
introduces a unified framework for text-, mask-, and bounding box-guided
synthesis of chest radiographs. Built upon the latent diffusion transformer
architecture, ChexGen was pretrained on the largest curated chest X-ray dataset
to date, consisting of 960,000 radiograph-report pairs. ChexGen achieves
accurate synthesis of radiographs through expert evaluations and quantitative
metrics. We demonstrate the utility of ChexGen for training data augmentation
and supervised pretraining, which led to performance improvements across
disease classification, detection, and segmentation tasks using a small
fraction of training data. Further, our model enables the creation of diverse
patient cohorts that enhance model fairness by detecting and mitigating
demographic biases. Our study supports the transformative role of generative
foundation models in building more accurate, data-efficient, and equitable
medical AI systems.

</details>


### [26] [LMVC: An End-to-End Learned Multiview Video Coding Framework](https://arxiv.org/abs/2509.03922)
*Xihua Sheng,Yingwen Zhang,Long Xu,Shiqi Wang*

Main category: cs.CV

TL;DR: 本文提出了一种端到端的学习型多视图视频编码（LMVC）框架，通过利用独立视图的运动和内容信息来增强依赖视图的压缩，实现了比传统MV-HEVC更高的压缩效率，同时保证了随机访问和向后兼容性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于深度学习的视频编码方法主要关注单视图或立体视频，对通用多视图场景的探索不足，而多视图视频因其巨大的数据量在存储和传输方面面临挑战。

Method: 提出了一种特征化视图间运动矢量预测方法，并将解码的独立视图运动特征和学习到的视图间运动先验信息相结合；提出了一种无视差的视图间内容预测模块，利用解码的独立视图内容特征预测视图间内容，并结合学习到的视图间内容先验信息。

Result: 提出的LMVC框架在压缩效率上显著优于传统的MV-HEVC标准参考软件。

Conclusion: 所提出的LMVC框架是一种有效的端到端学习多视图视频编码方法，为该领域未来的研究奠定了坚实的基础。

Abstract: Multiview video is a key data source for volumetric video, enabling immersive
3D scene reconstruction but posing significant challenges in storage and
transmission due to its massive data volume. Recently, deep learning-based
end-to-end video coding has achieved great success, yet most focus on
single-view or stereo videos, leaving general multiview scenarios
underexplored. This paper proposes an end-to-end learned multiview video coding
(LMVC) framework that ensures random access and backward compatibility while
enhancing compression efficiency. Our key innovation lies in effectively
leveraging independent-view motion and content information to enhance
dependent-view compression. Specifically, to exploit the inter-view motion
correlation, we propose a feature-based inter-view motion vector prediction
method that conditions dependent-view motion encoding on decoded
independent-view motion features, along with an inter-view motion entropy model
that learns inter-view motion priors. To exploit the inter-view content
correlation, we propose a disparity-free inter-view context prediction module
that predicts inter-view contexts from decoded independent-view content
features, combined with an inter-view contextual entropy model that captures
inter-view context priors. Experimental results show that our proposed LMVC
framework outperforms the reference software of the traditional MV-HEVC
standard by a large margin, establishing a strong baseline for future research
in this field.

</details>


### [27] [TopoSculpt: Betti-Steered Topological Sculpting of 3D Fine-grained Tubular Shapes](https://arxiv.org/abs/2509.03938)
*Minghui Zhang,Yaoyu Liu,Junyang Wu,Xin You,Hanxiao Zhang,Junjun He,Yun Gu*

Main category: cs.CV

TL;DR: TopoSculpt是一个用于三维管状结构拓扑优化的新框架，通过整体建模、拓扑完整性Betti约束和分层细化方案，显著提高了重建的几何和拓扑精度。


<details>
  <summary>Details</summary>
Motivation: 现有三维管状结构重建方法在捕捉拓扑正确性和完整性方面存在不足，特别是分块处理无法保证全局一致性，且在推理时无法纠正几何错误。

Method: TopoSculpt采用整体区域建模策略捕捉完整空间上下文，引入了拓扑完整性Betti（TIB）约束以联合强制执行Betti数先验和全局完整性，并采用分层细化方案结合持久同调来逐步校正误差。

Result: 在肺部气道和 cổ Circle of Willis 数据集上的实验表明，TopoSculpt在几何和拓扑方面均有显著改进。例如，气道数据集的β₀误差从69.00降低到3.40，CoW数据集的β₀误差从1.65降低到0.30，同时树长检测率和分支检测率提高了近10%。

Conclusion: TopoSculpt在纠正关键拓扑错误和提高复杂三维管状解剖结构的高保真度建模方面非常有效。

Abstract: Medical tubular anatomical structures are inherently three-dimensional
conduits with lumens, enclosing walls, and complex branching topologies.
Accurate reconstruction of their geometry and topology is crucial for
applications such as bronchoscopic navigation and cerebral arterial
connectivity assessment. Existing methods often rely on voxel-wise overlap
measures, which fail to capture topological correctness and completeness.
Although topology-aware losses and persistent homology constraints have shown
promise, they are usually applied patch-wise and cannot guarantee global
preservation or correct geometric errors at inference. To address these
limitations, we propose a novel TopoSculpt, a framework for topological
refinement of 3D fine-grained tubular structures. TopoSculpt (i) adopts a
holistic whole-region modeling strategy to capture full spatial context, (ii)
first introduces a Topological Integrity Betti (TIB) constraint that jointly
enforces Betti number priors and global integrity, and (iii) employs a
curriculum refinement scheme with persistent homology to progressively correct
errors from coarse to fine scales. Extensive experiments on challenging
pulmonary airway and Circle of Willis datasets demonstrate substantial
improvements in both geometry and topology. For instance, $\beta_{0}$ errors
are reduced from 69.00 to 3.40 on the airway dataset and from 1.65 to 0.30 on
the CoW dataset, with Tree length detected and branch detected rates improving
by nearly 10\%. These results highlight the effectiveness of TopoSculpt in
correcting critical topological errors and advancing the high-fidelity modeling
of complex 3D tubular anatomy. The project homepage is available at:
https://github.com/Puzzled-Hui/TopoSculpt.

</details>


### [28] [Chest X-ray Pneumothorax Segmentation Using EfficientNet-B4 Transfer Learning in a U-Net Architecture](https://arxiv.org/abs/2509.03950)
*Alvaro Aranibar Roque,Helga Sebastian*

Main category: cs.CV

TL;DR: 提出了一种基于深度学习的U-Net模型，使用EfficientNet-B4作为编码器，用于自动分割气胸区域，并在PTX-498数据集上取得了0.7008的IoU和0.8241的Dice分数，可辅助放射科医生诊断。


<details>
  <summary>Details</summary>
Motivation: 胸部X光是诊断气胸的首线方法，但小型气胸可能难以检测，需要一种自动化的方法来提高诊断准确性。

Method: 提出了一种基于深度学习的U-Net模型，使用EfficientNet-B4作为编码器，并结合了数据增强和二元交叉熵加上Dice损失函数进行训练。

Result: 在PTX-498独立数据集上，该模型实现了0.7008的IoU（交并比）和0.8241的Dice分数。

Conclusion: 该模型能够准确地定位气胸区域，为放射科医生提供支持。

Abstract: Pneumothorax, the abnormal accumulation of air in the pleural space, can be
life-threatening if undetected. Chest X-rays are the first-line diagnostic
tool, but small cases may be subtle. We propose an automated deep-learning
pipeline using a U-Net with an EfficientNet-B4 encoder to segment pneumothorax
regions. Trained on the SIIM-ACR dataset with data augmentation and a combined
binary cross-entropy plus Dice loss, the model achieved an IoU of 0.7008 and
Dice score of 0.8241 on the independent PTX-498 dataset. These results
demonstrate that the model can accurately localize pneumothoraces and support
radiologists.

</details>


### [29] [ANTS: Shaping the Adaptive Negative Textual Space by MLLM for OOD Detection](https://arxiv.org/abs/2509.03951)
*Zhu Wenjie,Zhang Yabin,Xin Jin,Wenjun Zeng,Lei Zhang*

Main category: cs.CV

TL;DR: 通过利用多模态大语言模型（MLLM）来构建自适应负面文本空间（ANTS），以提高分布外（OOD）检测的准确性，特别是在处理近距离和远距离OOD样本时。


<details>
  <summary>Details</summary>
Motivation: 现有的负面标签（NLs）方法在理解OOD图像和构建准确负面空间方面存在不足，并且假阴性标签会严重影响近距离OOD性能。

Method: 提出了一种名为自适应负面文本空间（ANTS）的方法，利用MLLM来理解和推理。对于远距离OOD，将可能为OOD的图像作为负面图像，并提示MLLM描述这些图像以生成精确表征OOD分布的负面句子。对于近距离OOD，识别与负面图像视觉相似的ID子集，并利用MLLM生成针对该子集的视觉相似负面标签，以减少假阴性。设计了一个自适应加权分数来平衡这两种负面文本空间，使其能够适应不同的OOD任务设置（近距离和远距离），而无需特定于任务的先验知识。

Result: 在ImageNet基准测试中，ANTS将FPR95降低了4.2%，达到了新的最先进水平。该方法是无需训练且具有零样本能力的。

Conclusion: 提出的ANTS方法通过利用MLLM在理解和推理方面的能力，有效解决了现有OOD检测方法在构建负面空间和处理假阴性标签方面的问题，并在近距离和远距离OOD检测任务上均取得了显著的性能提升，同时具有高度的适应性和可扩展性。

Abstract: The introduction of negative labels (NLs) has proven effective in enhancing
Out-of-Distribution (OOD) detection. However, existing methods often lack an
understanding of OOD images, making it difficult to construct an accurate
negative space. In addition, the presence of false negative labels
significantly degrades their near-OOD performance. To address these issues, we
propose shaping an Adaptive Negative Textual Space (ANTS) by leveraging the
understanding and reasoning capabilities of multimodal large language models
(MLLMs). Specifically, we identify images likely to be OOD samples as negative
images and prompt the MLLM to describe these images, generating expressive
negative sentences that precisely characterize the OOD distribution and enhance
far-OOD detection. For the near-OOD setting, where OOD samples resemble the
in-distribution (ID) subset, we first identify the subset of ID classes that
are visually similar to negative images and then leverage the reasoning
capability of MLLMs to generate visually similar negative labels tailored to
this subset, effectively reducing false negatives and improving near-OOD
detection. To balance these two types of negative textual spaces, we design an
adaptive weighted score that enables the method to handle different OOD task
settings (near-OOD and far-OOD) without relying on task-specific prior
knowledge, making it highly adaptable in open environments. On the ImageNet
benchmark, our ANTS significantly reduces the FPR95 by 4.2\%, establishing a
new state-of-the-art. Furthermore, our method is training-free and zero-shot,
enabling high scalability.

</details>


### [30] [Multimodal Feature Fusion Network with Text Difference Enhancement for Remote Sensing Change Detection](https://arxiv.org/abs/2509.03961)
*Yijun Zhou,Yikui Zhai,Zilu Ying,Tingfeng Xian,Wenlve Zhou,Zhiheng Zhou,Xiaolin Tian,Xudong Jia,Hongsheng Zhang,C. L. Philip Chen*

Main category: cs.CV

TL;DR: MMChange是一种多模态遥感影像变化检测方法，结合了图像和文本信息，提高了检测精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的遥感影像变化检测方法主要依赖单一的图像模态，在光照和噪声干扰下，其特征表示、变化模式建模和泛化能力受到限制。

Method: MMChange提出了一种结合图像和文本模态的方法。它包括一个图像特征细化（IFR）模块来突出关键区域和抑制噪声；利用视觉语言模型（VLM）生成双时相图像的语义描述；一个文本差异增强（TDE）模块来捕捉细粒度的语义变化；以及一个图像文本特征融合（ITFF）模块来整合跨模态信息。

Result: MMChange在LEVIRCD、WHUCD和SYSUCD数据集上进行了广泛的实验，结果显示其在多个指标上持续优于最先进的方法。

Conclusion: MMChange通过结合图像和文本模态，有效提高了遥感影像变化检测的准确性和鲁棒性，克服了单一图像模态的局限性。

Abstract: Although deep learning has advanced remote sensing change detection (RSCD),
most methods rely solely on image modality, limiting feature representation,
change pattern modeling, and generalization especially under illumination and
noise disturbances. To address this, we propose MMChange, a multimodal RSCD
method that combines image and text modalities to enhance accuracy and
robustness. An Image Feature Refinement (IFR) module is introduced to highlight
key regions and suppress environmental noise. To overcome the semantic
limitations of image features, we employ a vision language model (VLM) to
generate semantic descriptions of bitemporal images. A Textual Difference
Enhancement (TDE) module then captures fine grained semantic shifts, guiding
the model toward meaningful changes. To bridge the heterogeneity between
modalities, we design an Image Text Feature Fusion (ITFF) module that enables
deep cross modal integration. Extensive experiments on LEVIRCD, WHUCD, and
SYSUCD demonstrate that MMChange consistently surpasses state of the art
methods across multiple metrics, validating its effectiveness for multimodal
RSCD. Code is available at: https://github.com/yikuizhai/MMChange.

</details>


### [31] [SAC-MIL: Spatial-Aware Correlated Multiple Instance Learning for Histopathology Whole Slide Image Classification](https://arxiv.org/abs/2509.03973)
*Yu Bai,Zitong Yu,Haowen Tian,Xijing Wang,Shuo Yan,Lin Wang,Honglin Li,Xitong Ling,Bo Zhang,Zheng Zhang,Wufan Wang,Hui Gao,Xiangyang Gong,Wendong Wang*

Main category: cs.CV

TL;DR: SAC-MIL是一种用于WSI分类的空间感知相关多实例学习方法，它使用位置编码模块和SAC块来处理实例间的空间关系和相关性，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 提出一种用于WSI分类的空间感知相关多实例学习（SAC-MIL）方法，以解决实例间的空间关系和相关性问题。

Method: SAC-MIL包含一个位置编码模块（利用实例坐标而非索引来编码空间关系，并能处理序列长度不匹配问题）和一个SAC块（基于MLP，以线性时间复杂度执行全实例相关性，易于部署）。

Result: SAC-MIL在CAMELYON-16、TCGA-LUNG和TCGA-BRAC数据集上取得了最先进的性能。

Conclusion: SAC-MIL是一种有效且易于部署的WSI分类方法。

Abstract: We propose Spatial-Aware Correlated Multiple Instance Learning (SAC-MIL) for
performing WSI classification. SAC-MIL consists of a positional encoding module
to encode position information and a SAC block to perform full instance
correlations. The positional encoding module utilizes the instance coordinates
within the slide to encode the spatial relationships instead of the instance
index in the input WSI sequence. The positional encoding module can also handle
the length extrapolation issue where the training and testing sequences have
different lengths. The SAC block is an MLP-based method that performs full
instance correlation in linear time complexity with respect to the sequence
length. Due to the simple structure of MLP, it is easy to deploy since it does
not require custom CUDA kernels, compared to Transformer-based methods for WSI
classification. SAC-MIL has achieved state-of-the-art performance on the
CAMELYON-16, TCGA-LUNG, and TCGA-BRAC datasets. The code will be released upon
acceptance.

</details>


### [32] [Improving Vessel Segmentation with Multi-Task Learning and Auxiliary Data Available Only During Model Training](https://arxiv.org/abs/2509.03975)
*Daniel Sobotka,Alexander Herold,Matthias Perkonigg,Lucian Beer,Nina Bastati,Alina Sablatnig,Ahmed Ba-Ssalamah,Georg Langs*

Main category: cs.CV

TL;DR: 提出了一种无需对比剂的肝脏MRI血管分割多任务学习框架，利用辅助对比增强MRI数据（仅在训练时可用）来减少对注释训练样本的需求，并在推理时提高了分割精度，尤其是在注释稀少的情况下。


<details>
  <summary>Details</summary>
Motivation: 肝脏血管分割对于计算分析血管重塑至关重要，而血管重塑与多种弥漫性肝病相关。现有方法依赖于对比增强成像数据，但并非所有图像都具备这些数据。无需对比剂的图像更常见，但分割难度大且需要大量标注数据。

Method: 提出了一种多任务学习框架，利用配对的原生和对比增强数据（带或不带血管标注）进行模型训练，以分割无对比剂的肝脏MRI中的血管。该方法在训练时利用辅助对比增强MRI数据来减少对标注训练样本的需求。

Result: 辅助数据能够提高血管分割的准确性，即使在推理时不可用。当训练时只有少量标注数据时，这种优势尤为明显，因为共享任务结构能够改善特征表示。将此方法应用于脑肿瘤分割的验证也证实了其跨域的优势。

Conclusion: 即使辅助信息成像模态仅在训练时可用，它也能增强专家标注的效果。

Abstract: Liver vessel segmentation in magnetic resonance imaging data is important for
the computational analysis of vascular remodelling, associated with a wide
spectrum of diffuse liver diseases. Existing approaches rely on contrast
enhanced imaging data, but the necessary dedicated imaging sequences are not
uniformly acquired. Images without contrast enhancement are acquired more
frequently, but vessel segmentation is challenging, and requires large-scale
annotated data. We propose a multi-task learning framework to segment vessels
in liver MRI without contrast. It exploits auxiliary contrast enhanced MRI data
available only during training to reduce the need for annotated training
examples. Our approach draws on paired native and contrast enhanced data with
and without vessel annotations for model training. Results show that auxiliary
data improves the accuracy of vessel segmentation, even if they are not
available during inference. The advantage is most pronounced if only few
annotations are available for training, since the feature representation
benefits from the shared task structure. A validation of this approach to
augment a model for brain tumor segmentation confirms its benefits across
different domains. An auxiliary informative imaging modality can augment expert
annotations even if it is only available during training.

</details>


### [33] [Promptception: How Sensitive Are Large Multimodal Models to Prompts?](https://arxiv.org/abs/2509.03986)
*Mohamed Insaf Ismithdeen,Muhammad Uzair Khattak,Salman Khan*

Main category: cs.CV

TL;DR: 提示词设计对大型多模态模型在多项选择问答任务上的表现有显著影响，即使是微小的提示词变化也会导致准确率高达15%的偏差。我们提出了Promptception框架，包含61种提示词类型，用于评估10种大型多模态模型在3个基准测试上的提示词敏感性。研究发现，专有模型对提示词的微小变化更敏感，而开源模型虽然更稳定，但在处理复杂提示词时表现不佳。基于此，我们提出了针对不同类型模型的提示词设计原则，以实现更公平、更鲁棒的模型评估。


<details>
  <summary>Details</summary>
Motivation: 尽管大型多模态模型（LMMs）在多项选择问答（MCQA）任务上取得了成功，但针对该任务的提示词设计仍然是一个被忽视的领域。提示词的微小变化可能导致模型性能的显著差异，这给模型的透明和公平评估带来了挑战。

Method: 我们引入了一个名为Promptception的系统框架，该框架包含15个类别和6个超类别的61种不同类型的提示词，旨在评估LMMs对提示词设计的敏感性。我们使用这个框架在MMStar、MMMU-Pro和MVBench这三个MCQA基准测试上评估了包括GPT-4o和Gemini 1.5 Pro在内的10种LMMs。

Result: 研究结果表明，专有模型比开源模型对提示词的措辞变化更为敏感，这可能反映了它们与指令语义更紧密的对齐。相反，开源模型虽然在提示词变化下表现更稳定，但在处理细微和复杂的提示词时遇到了困难。

Conclusion: 提示词设计对LMM在MCQA任务中的表现至关重要。我们提出的Promptception框架和分析揭示了不同类型模型（专有 vs. 开源）在提示词敏感性上的差异。基于这些发现，我们提出了专门针对这两种模型类型的提示词设计原则，以促进更可靠、更公平的模型评估。

Abstract: Despite the success of Large Multimodal Models (LMMs) in recent years, prompt
design for LMMs in Multiple-Choice Question Answering (MCQA) remains poorly
understood. We show that even minor variations in prompt phrasing and structure
can lead to accuracy deviations of up to 15% for certain prompts and models.
This variability poses a challenge for transparent and fair LMM evaluation, as
models often report their best-case performance using carefully selected
prompts. To address this, we introduce Promptception, a systematic framework
for evaluating prompt sensitivity in LMMs. It consists of 61 prompt types,
spanning 15 categories and 6 supercategories, each targeting specific aspects
of prompt formulation, and is used to evaluate 10 LMMs ranging from lightweight
open-source models to GPT-4o and Gemini 1.5 Pro, across 3 MCQA benchmarks:
MMStar, MMMU-Pro, MVBench. Our findings reveal that proprietary models exhibit
greater sensitivity to prompt phrasing, reflecting tighter alignment with
instruction semantics, while open-source models are steadier but struggle with
nuanced and complex phrasing. Based on this analysis, we propose Prompting
Principles tailored to proprietary and open-source LMMs, enabling more robust
and fair model evaluation.

</details>


### [34] [SliceSemOcc: Vertical Slice Based Multimodal 3D Semantic Occupancy Representation](https://arxiv.org/abs/2509.03999)
*Han Huang,Han Sun,Ningzhong Liu,Huiyu Zhou,Jiaquan Shen*

Main category: cs.CV

TL;DR: SliceSemOcc是一个基于垂直切片的3D语义占用预测框架，通过增强高度轴信息处理和动态通道注意力来提高精度，尤其是在小物体检测方面。


<details>
  <summary>Details</summary>
Motivation: 现有3D占用预测方法在处理体素特征时忽略了高度轴信息，并且通道注意力机制在不同高度层上分配均匀权重，限制了其强调不同高度特征的能力。而自动驾驶领域对精确3D感知的需求日益增长，使得3D语义占用预测成为一个关键的研究课题。

Method: 提出了一种名为SliceSemOcc的新型垂直切片多模态框架。该框架提取体素特征时同时使用全局和局部垂直切片，并通过全局局部融合模块来融合细节和上下文信息。此外，提出SEAttention3D模块，通过平均池化保留高度分辨率，并为每个高度层分配动态通道注意力权重。

Result: 在nuScenes-SurroundOcc和nuScenes-OpenOccupancy数据集上进行了大量实验，结果表明该方法显著提高了平均IoU（mIoU），尤其是在大多数小物体类别上取得了显著的提升。

Conclusion: 提出的SliceSemOcc框架及其中的SEAttention3D模块能够有效处理高度轴信息，提高3D语义占用预测的精度，特别是在小物体检测方面表现突出。

Abstract: Driven by autonomous driving's demands for precise 3D perception, 3D semantic
occupancy prediction has become a pivotal research topic. Unlike
bird's-eye-view (BEV) methods, which restrict scene representation to a 2D
plane, occupancy prediction leverages a complete 3D voxel grid to model spatial
structures in all dimensions, thereby capturing semantic variations along the
vertical axis. However, most existing approaches overlook height-axis
information when processing voxel features. And conventional SENet-style
channel attention assigns uniform weight across all height layers, limiting
their ability to emphasize features at different heights. To address these
limitations, we propose SliceSemOcc, a novel vertical slice based multimodal
framework for 3D semantic occupancy representation. Specifically, we extract
voxel features along the height-axis using both global and local vertical
slices. Then, a global local fusion module adaptively reconciles fine-grained
spatial details with holistic contextual information. Furthermore, we propose
the SEAttention3D module, which preserves height-wise resolution through
average pooling and assigns dynamic channel attention weights to each height
layer. Extensive experiments on nuScenes-SurroundOcc and nuScenes-OpenOccupancy
datasets verify that our method significantly enhances mean IoU, achieving
especially pronounced gains on most small-object categories. Detailed ablation
studies further validate the effectiveness of the proposed SliceSemOcc
framework.

</details>


### [35] [Detecting Regional Spurious Correlations in Vision Transformers via Token Discarding](https://arxiv.org/abs/2509.04009)
*Solha Kang,Esla Timothy Anzaku,Wesley De Neve,Arnout Van Messem,Joris Vankerschaver,Francois Rameau,Utku Ozbulak*

Main category: cs.CV

TL;DR: 本研究提出了一种检测视觉 transformer 中虚假关联的新方法，并通过大规模实验验证了其有效性，同时强调了训练方法和数据集选择对虚假关联的影响。


<details>
  <summary>Details</summary>
Motivation: 由于神经网络强大的特征关联能力，它们可能利用数据中存在的非预期但统计相关的信号（虚假关联）进行预测，这影响了模型的可靠性和泛化能力，因此检测和缓解虚假关联至关重要。

Method: 提出了一种新的虚假关联检测方法，并在一系列监督和自监督训练的视觉 transformer 模型以及 ImageNet 数据集上进行了大规模实验。

Result: 研究表明，该方法能够有效识别虚假关联；模型的训练方法对其依赖虚假关联的程度有显著影响；ImageNet 数据集中某些类别包含易于被模型检测到的虚假信号，并分析了其原因；在浸润性乳腺肿块分类案例研究中也发现了虚假信号。

Conclusion: 本研究不仅提出了一种检测虚假关联的方法，还揭示了训练方法和数据集选择的重要性，并指出了 ImageNet 数据集中存在问题的类别，为未来研究提供了警示和参考。

Abstract: Due to their powerful feature association capabilities, neural network-based
computer vision models have the ability to detect and exploit unintended
patterns within the data, potentially leading to correct predictions based on
incorrect or unintended but statistically relevant signals. These clues may
vary from simple color aberrations to small texts within the image. In
situations where these unintended signals align with the predictive task,
models can mistakenly link these features with the task and rely on them for
making predictions. This phenomenon is referred to as spurious correlations,
where patterns appear to be associated with the task but are actually
coincidental. As a result, detection and mitigation of spurious correlations
have become crucial tasks for building trustworthy, reliable, and generalizable
machine learning models. In this work, we present a novel method to detect
spurious correlations in vision transformers, a type of neural network
architecture that gained significant popularity in recent years. Using both
supervised and self-supervised trained models, we present large-scale
experiments on the ImageNet dataset demonstrating the ability of the proposed
method to identify spurious correlations. We also find that, even if the same
architecture is used, the training methodology has a significant impact on the
model's reliance on spurious correlations. Furthermore, we show that certain
classes in the ImageNet dataset contain spurious signals that are easily
detected by the models and discuss the underlying reasons for those spurious
signals. In light of our findings, we provide an exhaustive list of the
aforementioned images and call for caution in their use in future research
efforts. Lastly, we present a case study investigating spurious signals in
invasive breast mass classification, grounding our work in real-world
scenarios.

</details>


### [36] [Learning from Majority Label: A Novel Problem in Multi-class Multiple-Instance Learning](https://arxiv.org/abs/2509.04023)
*Shiku Kaito,Shinnosuke Matsuo,Daiki Suehiro,Ryoma Bise*

Main category: cs.CV

TL;DR: 该论文提出了一个名为“学习自多数标签”(LML)的新型多类别多实例学习问题，其中袋子（bag）的标签由其内部实例中占多数的类决定。为了解决LML问题，论文提出了一种计数网络，并通过实验发现多数类实例比例高的袋子更有利于学习。基于此，研究者开发了一个多数比例增强模块（MPEM）来移除少数类实例以提高多数类比例。实验结果表明，所提出的方法在四个数据集上优于传统的MIL方法，并且验证模块的有效性。


<details>
  <summary>Details</summary>
Motivation: 在多类别多实例学习（MIL）的背景下，提出了一种新的问题设定——学习自多数标签（LML），其中袋子（bag）的标签由其内部实例中占多数的类来决定。这种设定在病理图像分割、政治投票预测、客户情感分析和环境监测等领域具有实际应用价值。

Method: 提出了一种计数网络来解决LML问题，该网络旨在通过计算每个类别的实例数量来预测袋子级别的多数标签。此外，还开发了一个多数比例增强模块（MPEM），通过移除袋子中的少数类实例来提高多数类实例的比例，以增强学习效果。

Result: 在四个数据集上的实验结果显示，所提出的计数网络和MPEM方法在解决LML问题上优于传统的MIL方法。消融实验也证实了各个模块的有效性。

Conclusion: LML是一个在多类别MIL中有实际应用价值的新问题。所提出的计数网络和MPEM方法能够有效地解决LML问题，并且实验证明了该方法的优越性。

Abstract: The paper proposes a novel multi-class Multiple-Instance Learning (MIL)
problem called Learning from Majority Label (LML). In LML, the majority class
of instances in a bag is assigned as the bag-level label. The goal of LML is to
train a classification model that estimates the class of each instance using
the majority label. This problem is valuable in a variety of applications,
including pathology image segmentation, political voting prediction, customer
sentiment analysis, and environmental monitoring. To solve LML, we propose a
Counting Network trained to produce bag-level majority labels, estimated by
counting the number of instances in each class. Furthermore, analysis
experiments on the characteristics of LML revealed that bags with a high
proportion of the majority class facilitate learning. Based on this result, we
developed a Majority Proportion Enhancement Module (MPEM) that increases the
proportion of the majority class by removing minority class instances within
the bags. Experiments demonstrate the superiority of the proposed method on
four datasets compared to conventional MIL methods. Moreover, ablation studies
confirmed the effectiveness of each module. The code is available at
\href{https://github.com/Shiku-Kaito/Learning-from-Majority-Label-A-Novel-Problem-in-Multi-class-Multiple-Instance-Learning}{here}.

</details>


### [37] [Millisecond-Response Tracking and Gazing System for UAVs: A Domestic Solution Based on "Phytium + Cambricon"](https://arxiv.org/abs/2509.04043)
*Yuchen Zhu,Longxiang Yin,Kai Zhao*

Main category: cs.CV

TL;DR: 本研究提出了一个基于飞腾处理器和寒武纪加速卡的异构计算架构，用于构建一个具有毫秒级响应能力的无人机跟踪和凝视系统。


<details>
  <summary>Details</summary>
Motivation: 传统视频监控技术在动态场景下响应延迟超过200毫秒，无法满足实时性要求。

Method: 通过结合飞腾FT-2000/4处理器和MLU220加速卡，并采用轻量级YOLOv5s检测网络与DeepSORT级联跟踪算法，构建了“检测-跟踪-反馈”的闭环控制链。

Result: 在1920*1080分辨率下，系统实现了50-100毫秒的单帧综合处理延迟，多尺度目标识别准确率超过98.5%。

Conclusion: 该系统为无人机监控和国产芯片应用提供了一种低延迟、高精度的创新解决方案。

Abstract: In the frontier research and application of current video surveillance
technology, traditional camera systems exhibit significant limitations of
response delay exceeding 200 ms in dynamic scenarios due to the insufficient
deep feature extraction capability of automatic recognition algorithms and the
efficiency bottleneck of computing architectures, failing to meet the real-time
requirements in complex scenes. To address this issue, this study proposes a
heterogeneous computing architecture based on Phytium processors and Cambricon
accelerator cards, constructing a UAV tracking and gazing system with
millisecond-level response capability. At the hardware level, the system adopts
a collaborative computing architecture of Phytium FT-2000/4 processors and
MLU220 accelerator cards, enhancing computing power through multi-card
parallelism. At the software level, it innovatively integrates a lightweight
YOLOv5s detection network with a DeepSORT cascaded tracking algorithm, forming
a closed-loop control chain of "detection-tracking-feedback". Experimental
results demonstrate that the system achieves a stable single-frame
comprehensive processing delay of 50-100 ms in 1920*1080 resolution video
stream processing, with a multi-scale target recognition accuracy of over
98.5%, featuring both low latency and high precision. This study provides an
innovative solution for UAV monitoring and the application of domestic chips.

</details>


### [38] [A Re-ranking Method using K-nearest Weighted Fusion for Person Re-identification](https://arxiv.org/abs/2509.04050)
*Quang-Huy Che,Le-Chuong Nguyen,Gia-Nghia Tran,Dinh-Duy Phan,Vinh-Tiep Nguyen*

Main category: cs.CV

TL;DR: 该研究提出了一种无需微调模型或额外标注的多视角特征聚合重排序方法，以解决单视角特征在行人重识别中存在的视图偏差问题，并在Market1501、MSMT17和Occluded-DukeMTMC数据集上显著提高了Rank@1和mAP指标，同时在计算效率上优于其他重排序方法。


<details>
  <summary>Details</summary>
Motivation: 行人重识别中的重排序是提高准确性的关键步骤，但现有方法多依赖单视角特征，易受姿态变化、视角改变和遮挡等问题的影响，并产生视图偏差。

Method: 提出了一种高效的重排序方法，通过K近邻加权融合（KWF）聚合邻居特征来生成多视角特征，利用同一身份的特征相似性假设，以无监督方式选择K个邻居特征进行聚合，并探索了不同的权重选择策略。

Result: 在Market1501、MSMT17和Occluded-DukeMTMC数据集上进行了评估，与初始排序结果相比，该重排序方法在Rank@1和mAP上均有显著提升，尤其在MSMT17和Occluded-DukeMTMC数据集上，Rank@1分别提升了9.8%和22.0%。此外，该方法在计算效率方面也表现出显著优势。

Conclusion: 所提出的多视角特征聚合重排序方法能够有效解决单视角特征的不足，显著提升行人重识别的准确率和效率，且无需额外的模型微调或数据标注，具有广泛的应用潜力。

Abstract: In person re-identification, re-ranking is a crucial step to enhance the
overall accuracy by refining the initial ranking of retrieved results. Previous
studies have mainly focused on features from single-view images, which can
cause view bias and issues like pose variation, viewpoint changes, and
occlusions. Using multi-view features to present a person can help reduce view
bias. In this work, we present an efficient re-ranking method that generates
multi-view features by aggregating neighbors' features using K-nearest Weighted
Fusion (KWF) method. Specifically, we hypothesize that features extracted from
re-identification models are highly similar when representing the same
identity. Thus, we select K neighboring features in an unsupervised manner to
generate multi-view features. Additionally, this study explores the weight
selection strategies during feature aggregation, allowing us to identify an
effective strategy. Our re-ranking approach does not require model fine-tuning
or extra annotations, making it applicable to large-scale datasets. We evaluate
our method on the person re-identification datasets Market1501, MSMT17, and
Occluded-DukeMTMC. The results show that our method significantly improves
Rank@1 and mAP when re-ranking the top M candidates from the initial ranking
results. Specifically, compared to the initial results, our re-ranking method
achieves improvements of 9.8%/22.0% in Rank@1 on the challenging datasets:
MSMT17 and Occluded-DukeMTMC, respectively. Furthermore, our approach
demonstrates substantial enhancements in computational efficiency compared to
other re-ranking methods.

</details>


### [39] [TEn-CATS: Text-Enriched Audio-Visual Video Parsing with Multi-Scale Category-Aware Temporal Graph](https://arxiv.org/abs/2509.04086)
*Yaru Chen,Faegheh Sardari,Peiliang Zhang,Ruohao Guo,Yang Xiang,Zhenbo Li,Wenwu Wang*

Main category: cs.CV

TL;DR: 提出一种结合双向文本融合（BiT）模块和类别感知时序图（CATS）模块的方法，用于解决音频-视觉视频解析（AVVP）任务中的弱监督标签问题，并通过实验证明其达到了最先进（SOTA）的性能。


<details>
  <summary>Details</summary>
Motivation: 现有AVVP方法在处理弱监督标签时存在问题：基于注意力的模型将带有噪声的伪标签视为可靠监督，而伪标签生成方法则可能导致错误信息在训练过程中被放大。

Method: 提出一种结合BiT模块和CATS模块的方法。BiT模块用于对音频和视觉特征进行语义注入和动态校准，以提取更纯净的语义线索。CATS模块则用于语义传播和连接，实现跨时间的精确语义信息传播。

Result: 在LLP和UnAV-100两个基准数据集上，提出的方法在多个关键指标上取得了最先进（SOTA）的性能。

Conclusion: 提出的结合BiT和CATS模块的方法能够有效解决AVVP任务中的弱监督标签问题，并取得优于现有方法的性能。

Abstract: Audio-Visual Video Parsing (AVVP) task aims to identify event categories and
their occurrence times in a given video with weakly supervised labels. Existing
methods typically fall into two categories: (i) designing enhanced
architectures based on attention mechanism for better temporal modeling, and
(ii) generating richer pseudo-labels to compensate for the absence of
frame-level annotations. However, the first type methods treat noisy
segment-level pseudo labels as reliable supervision and the second type methods
let indiscriminate attention spread them across all frames, the initial errors
are repeatedly amplified during training. To address this issue, we propose a
method that combines the Bi-Directional Text Fusion (BiT) module and
Category-Aware Temporal Graph (CATS) module. Specifically, we integrate the
strengths and complementarity of the two previous research directions. We first
perform semantic injection and dynamic calibration on audio and visual modality
features through the BiT module, to locate and purify cleaner and richer
semantic cues. Then, we leverage the CATS module for semantic propagation and
connection to enable precise semantic information dissemination across time.
Experimental results demonstrate that our proposed method achieves
state-of-the-art (SOTA) performance in multiple key indicators on two benchmark
datasets, LLP and UnAV-100.

</details>


### [40] [TriLiteNet: Lightweight Model for Multi-Task Visual Perception](https://arxiv.org/abs/2509.04092)
*Quang-Huy Che,Duc-Khai Lam*

Main category: cs.CV

TL;DR: TriLiteNet是一个高效的多任务全景驾驶感知模型，能在保持低计算成本的同时优化性能，适用于ADAS系统。


<details>
  <summary>Details</summary>
Motivation: 为了满足ADAS应用对实时处理和响应的需求，需要高效的感知模型。

Method: 提出TriLiteNet模型，该模型能够同时处理全景驾驶感知的多个任务，并优化性能以降低计算成本。

Result: 在BDD100k数据集上，TriLiteNet_{base}在车辆检测、可驾驶区域分割和车道线分割任务上均达到有竞争力的性能，参数量仅为2.35M，计算量为7.72GFLOPs。其tiny配置参数量仅0.14M，并展示了低延迟和合理的功耗。

Conclusion: TriLiteNet在性能、计算效率和可扩展性之间取得了良好平衡，为真实世界的自动驾驶应用提供了一个实用且可部署的解决方案。

Abstract: Efficient perception models are essential for Advanced Driver Assistance
Systems (ADAS), as these applications require rapid processing and response to
ensure safety and effectiveness in real-world environments. To address the
real-time execution needs of such perception models, this study introduces the
TriLiteNet model. This model can simultaneously manage multiple tasks related
to panoramic driving perception. TriLiteNet is designed to optimize performance
while maintaining low computational costs. Experimental results on the BDD100k
dataset demonstrate that the model achieves competitive performance across
three key tasks: vehicle detection, drivable area segmentation, and lane line
segmentation. Specifically, the TriLiteNet_{base} demonstrated a recall of
85.6% for vehicle detection, a mean Intersection over Union (mIoU) of 92.4% for
drivable area segmentation, and an Acc of 82.3% for lane line segmentation with
only 2.35M parameters and a computational cost of 7.72 GFLOPs. Our proposed
model includes a tiny configuration with just 0.14M parameters, which provides
a multi-task solution with minimal computational demand. Evaluated for latency
and power consumption on embedded devices, TriLiteNet in both configurations
shows low latency and reasonable power during inference. By balancing
performance, computational efficiency, and scalability, TriLiteNet offers a
practical and deployable solution for real-world autonomous driving
applications. Code is available at https://github.com/chequanghuy/TriLiteNet.

</details>


### [41] [DVS-PedX: Synthetic-and-Real Event-Based Pedestrian Dataset](https://arxiv.org/abs/2509.04117)
*Mustafa Sakhai,Kaung Sithu,Min Khant Soe Oke,Maciej Wielgosz*

Main category: cs.CV

TL;DR: DVS-PedX是一个用于行人检测和过境意图分析的新型神经形态数据集，包含合成和真实世界数据，旨在推动事件驱动的行人安全研究。


<details>
  <summary>Details</summary>
Motivation: 事件相机（如DVS）具有低延迟、高动态范围和运动鲁棒性等优点，但缺乏专门用于行人检测和过境意图分析的数据集，尤其是在不利天气条件下。DVS-PedX旨在解决这一问题，以加速事件驱动的行人安全、意图预测和神经形态感知研究。

Method: DVS-PedX数据集包含两部分：1.在CARLA模拟器中生成的合成事件流，模拟了各种天气和光照条件下的“接近-穿越”场景。2.通过v2e工具将JAAD数据集的真实世界行车记录仪视频转换为事件流，保留了自然的行人和背景。每个序列都包含配对的RGB帧、DVS“事件帧”（累积33毫秒）和帧级标签（是否穿越）。数据集还提供原始AEDAT 2.0/AEDAT 4.0事件文件和AVI DVS视频文件及元数据。研究人员使用SpikingJelly框架训练了基线脉冲神经网络（SNNs）来展示数据集的可用性。

Result: 基线SNN模型在DVS-PedX数据集上的表现揭示了模拟数据与真实世界数据之间的“域差距”（sim-to-real gap），这表明需要进行域自适应和多模态融合研究。

Conclusion: DVS-PedX数据集的创建和评估表明，事件相机在行人安全和意图预测方面具有巨大潜力。数据集的可用性以及初步的SNN模型结果，为未来的研究提供了基础，特别是关于弥合模拟与真实世界之间的差距以及利用多模态信息来提高行人检测和意图预测的准确性。

Abstract: Event cameras like Dynamic Vision Sensors (DVS) report micro-timed brightness
changes instead of full frames, offering low latency, high dynamic range, and
motion robustness. DVS-PedX (Dynamic Vision Sensor Pedestrian eXploration) is a
neuromorphic dataset designed for pedestrian detection and crossing-intention
analysis in normal and adverse weather conditions across two complementary
sources: (1) synthetic event streams generated in the CARLA simulator for
controlled "approach-cross" scenes under varied weather and lighting; and (2)
real-world JAAD dash-cam videos converted to event streams using the v2e tool,
preserving natural behaviors and backgrounds. Each sequence includes paired RGB
frames, per-frame DVS "event frames" (33 ms accumulations), and frame-level
labels (crossing vs. not crossing). We also provide raw AEDAT 2.0/AEDAT 4.0
event files and AVI DVS video files and metadata for flexible re-processing.
Baseline spiking neural networks (SNNs) using SpikingJelly illustrate dataset
usability and reveal a sim-to-real gap, motivating domain adaptation and
multimodal fusion. DVS-PedX aims to accelerate research in event-based
pedestrian safety, intention prediction, and neuromorphic perception.

</details>


### [42] [TaleDiffusion: Multi-Character Story Generation with Dialogue Rendering](https://arxiv.org/abs/2509.04123)
*Ayan Banerjee,Josep Lladós,Umapada Pal,Anjan Dutta*

Main category: cs.CV

TL;DR: TaleDiffusion是一个新颖的框架，通过迭代过程生成具有一致性、准确对话的多角色故事，使用预训练语言模型生成描述、角色细节和对话，并通过注意力机制和CLIPSeg确保角色一致性和对话准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在角色一致性方面存在不足，导致故事叙述不连贯。

Method: 使用预训练语言模型生成每帧描述、角色细节和对话；采用基于边界的注意力掩码技术控制角色交互；应用身份一致性自注意力机制确保跨帧角色一致性；使用区域感知交叉注意力进行精确对象放置；通过CLIPSeg渲染对话气泡并分配给角色。

Result: TaleDiffusion在一致性、降噪和对话渲染方面优于现有方法。

Conclusion: TaleDiffusion成功解决了多角色故事可视化中的角色一致性和对话准确性问题。

Abstract: Text-to-story visualization is challenging due to the need for consistent
interaction among multiple characters across frames. Existing methods struggle
with character consistency, leading to artifact generation and inaccurate
dialogue rendering, which results in disjointed storytelling. In response, we
introduce TaleDiffusion, a novel framework for generating multi-character
stories with an iterative process, maintaining character consistency, and
accurate dialogue assignment via postprocessing. Given a story, we use a
pre-trained LLM to generate per-frame descriptions, character details, and
dialogues via in-context learning, followed by a bounded attention-based
per-box mask technique to control character interactions and minimize
artifacts. We then apply an identity-consistent self-attention mechanism to
ensure character consistency across frames and region-aware cross-attention for
precise object placement. Dialogues are also rendered as bubbles and assigned
to characters via CLIPSeg. Experimental results demonstrate that TaleDiffusion
outperforms existing methods in consistency, noise reduction, and dialogue
rendering.

</details>


### [43] [MEPG:Multi-Expert Planning and Generation for Compositionally-Rich Image Generation](https://arxiv.org/abs/2509.04126)
*Yuan Zhao,Liu Lin*

Main category: cs.CV

TL;DR: MEPG框架通过整合位置-风格感知LLM和多专家模块，解决了现有文本到图像模型在处理复杂提示和风格多样性方面的不足，显著提升了图像质量和风格多样性。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像扩散模型在处理复杂的多元素提示和有限的风格多样性方面存在不足。

Method: 提出了一种多专家规划和生成框架（MEPG），该框架整合了位置-风格感知（PSA）模块和多专家扩散（MED）模块。PSA模块使用监督微调的LLM将输入提示分解为空间坐标和风格编码的语义指令。MED模块通过动态专家路由实现跨区域生成，并利用注意力机制门控机制选择性激活特定区域的专业模型（如真实感专家、风格化专家）。该框架支持轻量级集成和专家模型替换，并提供交互式界面进行实时布局编辑和风格选择。

Result: 实验表明，MEPG框架在图像质量和风格多样性方面显著优于具有相同骨干的基线模型。

Conclusion: MEPG框架有效解决了现有文本到图像模型的局限性，并在图像生成方面取得了显著的进步。

Abstract: Text-to-image diffusion models have achieved remarkable image quality, but
they still struggle with complex, multiele ment prompts, and limited stylistic
diversity. To address these limitations, we propose a Multi-Expert Planning and
Gen eration Framework (MEPG) that synergistically integrates position- and
style-aware large language models (LLMs) with spatial-semantic expert modules.
The framework comprises two core components: (1) a Position-Style-Aware (PSA)
module that utilizes a supervised fine-tuned LLM to decom pose input prompts
into precise spatial coordinates and style encoded semantic instructions; and
(2) a Multi-Expert Dif fusion (MED) module that implements cross-region genera
tion through dynamic expert routing across both local regions and global areas.
During the generation process for each lo cal region, specialized models (e.g.,
realism experts, styliza tion specialists) are selectively activated for each
spatial par tition via attention-based gating mechanisms. The architec ture
supports lightweight integration and replacement of ex pert models, providing
strong extensibility. Additionally, an interactive interface enables real-time
spatial layout editing and per-region style selection from a portfolio of
experts. Ex periments show that MEPG significantly outperforms base line models
with the same backbone in both image quality
  and style diversity.

</details>


### [44] [Revisiting Simple Baselines for In-The-Wild Deepfake Detection](https://arxiv.org/abs/2509.04150)
*Orlando Castaneda,Kevin So-Tang,Kshitij Gurung*

Main category: cs.CV

TL;DR: 通过调整超参数，Ojha et al. 的方法在 Deepfake-Eval-2024 基准测试中达到了 81% 的准确率，与商业检测器相当，并显著优于之前报道的该方法性能。


<details>
  <summary>Details</summary>
Motivation: 随着合成媒体的广泛使用，对易于使用的深度伪造检测器和真实基准测试的需求日益增长。现有的研究多在受控数据集上评估检测器，而本文关注“野外”基准测试 Deepfake-Eval-2024。

Method: 重新审视并优化了 Ojha et al. 提出的方法，该方法通过调整预训练的视觉主干来生成可泛化的深度伪造检测器，重点在于超参数调优。

Result: 经过更好的超参数调优，该简单方法在 Deepfake-Eval-2024 基准测试上达到了 81% 的准确率，比之前报道的基线方法提高了 18%，并且性能与领先的商业深度伪造检测器（82% 准确率）相当。

Conclusion: 通过改进超参数调优，原本被认为性能不佳的简单深度伪造检测方法，实际上可以达到很高的准确率，甚至可以与商业检测器相媲美，这表明在实际部署中需要考虑准确性、计算成本和可解释性之间的权衡。

Abstract: The widespread adoption of synthetic media demands accessible deepfake
detectors and realistic benchmarks. While most existing research evaluates
deepfake detectors on highly controlled datasets, we focus on the recently
released "in-the-wild" benchmark, Deepfake-Eval-2024. Initial reporting on
Deepfake-Eval-2024 showed that three finetuned open-source models achieve
accuracies between 61% and 69%, significantly lagging behind the leading
commercial deepfake detector with 82% accuracy. Our work revisits one of these
baseline approaches, originally introduced by Ojha et al., which adapts
standard pretrained vision backbones to produce generalizable deepfake
detectors. We demonstrate that with better-tuned hyperparameters, this simple
approach actually yields much higher performance -- 81% accuracy on
Deepfake-Eval-2024 -- surpassing the previously reported accuracy of this
baseline approach by 18% and competing with commercial deepfake detectors. We
discuss tradeoffs in accuracy, computational costs, and interpretability,
focusing on how practical these deepfake detectors might be when deployed in
real-world settings. Our code can be found at
https://github.com/Deepfake-Detection-KKO/deepfake-detection.

</details>


### [45] [VisioFirm: Cross-Platform AI-assisted Annotation Tool for Computer Vision](https://arxiv.org/abs/2509.04180)
*Safouane El Ghazouali,Umberto Michelucci*

Main category: cs.CV

TL;DR: VisioFirm是一个开源的AI辅助图像标注工具，通过集成先进的基础模型和过滤流程，大大减少了人工标注工作量，并支持多种标注格式和离线操作。


<details>
  <summary>Details</summary>
Motivation: 传统图像标注工具效率低下，人工成本高，限制了大规模数据集的处理能力。

Method: VisioFirm集成了CLIP、Ultralytics和Grounding DINO等模型，利用低置信度阈值生成初步标注，并提供交互式工具进行优化。同时，它还集成了Segment Anything模型，通过WebGPU加速实现浏览器端实时分割，并采用连接的CLIP基础消歧组件聚类和IoU图抑制冗余检测，以保证标注准确性。

Result: 在COCO类型数据集上的测试表明，VisioFirm能够生成大部分正确的初始预测，用户可以通过交互式工具进行修正。该工具在多个数据集上进行了基准测试，证明了其可以将人工工作量最多减少90%，同时保持高标注准确性。

Conclusion: VisioFirm通过AI辅助自动化显著提高了图像标注的效率和可扩展性，同时保证了标注质量，并提供了良好的用户体验和可访问性。

Abstract: AI models rely on annotated data to learn pattern and perform prediction.
Annotation is usually a labor-intensive step that require associating labels
ranging from a simple classification label to more complex tasks such as object
detection, oriented bounding box estimation, and instance segmentation.
Traditional tools often require extensive manual input, limiting scalability
for large datasets. To address this, we introduce VisioFirm, an open-source web
application designed to streamline image labeling through AI-assisted
automation. VisioFirm integrates state-of-the-art foundation models into an
interface with a filtering pipeline to reduce human-in-the-loop efforts. This
hybrid approach employs CLIP combined with pre-trained detectors like
Ultralytics models for common classes and zero-shot models such as Grounding
DINO for custom labels, generating initial annotations with low-confidence
thresholding to maximize recall. Through this framework, when tested on
COCO-type of classes, initial prediction have been proven to be mostly correct
though the users can refine these via interactive tools supporting bounding
boxes, oriented bounding boxes, and polygons. Additionally, VisioFirm has
on-the-fly segmentation powered by Segment Anything accelerated through WebGPU
for browser-side efficiency. The tool supports multiple export formats (YOLO,
COCO, Pascal VOC, CSV) and operates offline after model caching, enhancing
accessibility. VisioFirm demonstrates up to 90\% reduction in manual effort
through benchmarks on diverse datasets, while maintaining high annotation
accuracy via clustering of connected CLIP-based disambiguate components and
IoU-graph for redundant detection suppression. VisioFirm can be accessed from
\href{https://github.com/OschAI/VisioFirm}{https://github.com/OschAI/VisioFirm}.

</details>


### [46] [DUDE: Diffusion-Based Unsupervised Cross-Domain Image Retrieval](https://arxiv.org/abs/2509.04193)
*Ruohong Yang,Peng Hu,Yunfan Li,Xi Peng*

Main category: cs.CV

TL;DR: DUDE通过解耦特征来解决无监督跨域图像检索（UCIR）中的域间隙问题，利用文本到图像生成模型分离对象特征和领域特定样式，并通过渐进式地对齐邻域实现可靠的对象特征对齐，在三个基准数据集上达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的UCIR方法在对齐整个图像的跨域特征时，常常难以克服域间隙，因为对检索至关重要的对象特征经常与特定领域的风格纠缠在一起。

Method: DUDE利用文本到图像生成模型解耦对象特征与特定领域的风格，然后通过渐进式地对齐来自域内和跨域的互邻来实现可靠的对齐。

Result: DUDE在三个基准数据集的13个域上取得了最先进的性能。

Conclusion: DUDE通过特征解耦和渐进式邻域对齐，成功解决了无监督跨域图像检索中的域间隙问题，并达到了最先进的性能。

Abstract: Unsupervised cross-domain image retrieval (UCIR) aims to retrieve images of
the same category across diverse domains without relying on annotations.
Existing UCIR methods, which align cross-domain features for the entire image,
often struggle with the domain gap, as the object features critical for
retrieval are frequently entangled with domain-specific styles. To address this
challenge, we propose DUDE, a novel UCIR method building upon feature
disentanglement. In brief, DUDE leverages a text-to-image generative model to
disentangle object features from domain-specific styles, thus facilitating
semantical image retrieval. To further achieve reliable alignment of the
disentangled object features, DUDE aligns mutual neighbors from within domains
to across domains in a progressive manner. Extensive experiments demonstrate
that DUDE achieves state-of-the-art performance across three benchmark datasets
over 13 domains. The code will be released.

</details>


### [47] [Learning Active Perception via Self-Evolving Preference Optimization for GUI Grounding](https://arxiv.org/abs/2509.04243)
*Wanfu Wang,Qipeng Huang,Guangquan Xue,Xiaobo Liang,Juntao Li*

Main category: cs.CV

TL;DR: LASER是一个用于提高视觉语言模型（VLM）在图形用户界面（GUI）基础任务中推理能力的框架，通过结合蒙特卡洛质量估计和基于IoU的区域质量评估，实现了多步感知和精确坐标预测，并在ScreenSpot Pro和ScreenSpot-v2基准测试中取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 提高VLM在GUI基础任务中的推理能力，尤其是在处理高分辨率输入和复杂的多元素视觉交互时。

Method: 提出LASER框架，结合蒙特卡洛质量估计和基于IoU的区域质量评估，以同时提高准确性和多样性，从而构建高质量的偏好数据。该方法引导模型关注与指令相关的关键区域，并根据任务复杂度自适应地分配推理步骤。

Result: 在ScreenSpot Pro和ScreenSpot-v2基准测试中，LASER实现了持续的性能提升。当在GTA1-7B上进行微调时，LASER在ScreenSpot-Pro基准测试上取得了55.7分，创下了7B规模模型的新SOTA。

Conclusion: LASER框架能够有效地提升VLM在GUI基础任务中的多步感知和坐标预测能力，并在相关基准测试中取得了SOTA的性能。

Abstract: Vision Language Models (VLMs) have recently achieved significant progress in
bridging visual perception and linguistic reasoning. Recently, OpenAI o3 model
introduced a zoom-in search strategy that effectively elicits active perception
capabilities in VLMs, improving downstream task performance. However, enabling
VLMs to reason effectively over appropriate image regions remains a core
challenge in GUI grounding, particularly under high-resolution inputs and
complex multi-element visual interactions. In this work, we propose LASER, a
self-evolving framework that progressively endows VLMs with multi-step
perception capabilities, enabling precise coordinate prediction. Specifically,
our approach integrate Monte Carlo quality estimation with
Intersection-over-Union (IoU)-based region quality evaluation to jointly
encourage both accuracy and diversity in constructing high-quality preference
data. This combination explicitly guides the model to focus on
instruction-relevant key regions while adaptively allocating reasoning steps
based on task complexity. Comprehensive experiments on the ScreenSpot Pro and
ScreenSpot-v2 benchmarks demonstrate consistent performance gains, validating
the effectiveness of our method. Furthermore, when fine-tuned on GTA1-7B, LASER
achieves a score of 55.7 on the ScreenSpot-Pro benchmark, establishing a new
state-of-the-art (SoTA) among 7B-scale models.

</details>


### [48] [Differential Morphological Profile Neural Networks for Semantic Segmentation](https://arxiv.org/abs/2509.04268)
*David Huangal,J. Alex Hurt*

Main category: cs.CV

TL;DR: 该研究将差分形态剖面（DMP）特征整合到深度学习语义分割模型中，以解决遥感影像分割的挑战，并取得了优于某些基线模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的语义分割网络主要基于地面视角图像，未能有效解决遥感影像在尺度变化、前景背景不平衡和大图像尺寸等方面的挑战。

Method: 将基于灰度形态学的多尺度形状提取方法DMP整合到三种先进的卷积和Transformer语义分割网络中，探索了直接输入和混合（双流）两种架构，并在iSAID数据集上评估了不同的DMP参数设置。

Result: 混合DMP架构在mIoU、F1和Recall等指标上持续优于直接输入DMP的模型，并且能够超越非DMP模型。

Conclusion: DMP特征的引入，特别是通过混合架构，能够有效提升遥感影像语义分割的性能，为解决该领域的挑战提供了新的途径。

Abstract: Semantic segmentation of overhead remote sensing imagery enables applications
in mapping, urban planning, and disaster response. State-of-the-art
segmentation networks are typically developed and tuned on ground-perspective
photographs and do not directly address remote sensing challenges such as
extreme scale variation, foreground-background imbalance, and large image
sizes. We explore the incorporation of the differential morphological profile
(DMP), a multi-scale shape extraction method based on grayscale morphology,
into modern segmentation networks. Prior studies have shown that the DMP can
provide critical shape information to Deep Neural Networks to enable superior
detection and classification performance in overhead imagery. In this work, we
extend prior DMPNet work beyond classification and object detection by
integrating DMP features into three state-of-the-art convolutional and
transformer semantic segmentation architectures. We utilize both direct input,
which adapts the input stem of feature extraction architectures to accept DMP
channels, and hybrid architectures, a dual-stream design that fuses RGB and DMP
encoders. Using the iSAID benchmark dataset, we evaluate a variety of DMP
differentials and structuring element shapes to more effectively provide shape
information to the model. Our results show that while non-DMP models generally
outperform the direct-input variants, hybrid DMP consistently outperforms
direct-input and is capable of surpassing a non-DMP model on mIoU, F1, and
Recall.

</details>


### [49] [TauGenNet: Plasma-Driven Tau PET Image Synthesis via Text-Guided 3D Diffusion Models](https://arxiv.org/abs/2509.04269)
*Yuxin Gong,Se-in Jang,Wei Shao,Yi Su,Kuang Gong*

Main category: cs.CV

TL;DR: 使用基于文本引导的3D扩散模型，结合MRI和血浆生物标志物，生成3D tau PET图像，用于阿尔茨海默病的研究和诊断。


<details>
  <summary>Details</summary>
Motivation: 为了解决tau PET扫描成本高、可及性有限的问题，同时利用结构MRI和血浆生物标志物提供互补信息，提出了一种新的tau PET图像合成方法。

Method: 提出一种文本引导的3D扩散模型，该模型利用结构MRI提供解剖结构约束，并以血浆p-tau217测量作为文本提示，来合成3D tau PET图像。

Result: 实验结果表明，该方法能够生成逼真且具有临床意义的3D tau PET图像，适用于不同的疾病阶段。

Conclusion: 该框架能够扩充tau PET数据，提供一种经济有效的tau病理可视化替代方案，并支持模拟不同血浆生物标志物水平和认知条件下的疾病进展。

Abstract: Accurate quantification of tau pathology via tau positron emission tomography
(PET) scan is crucial for diagnosing and monitoring Alzheimer's disease (AD).
However, the high cost and limited availability of tau PET restrict its
widespread use. In contrast, structural magnetic resonance imaging (MRI) and
plasma-based biomarkers provide non-invasive and widely available complementary
information related to brain anatomy and disease progression. In this work, we
propose a text-guided 3D diffusion model for 3D tau PET image synthesis,
leveraging multimodal conditions from both structural MRI and plasma
measurement. Specifically, the textual prompt is from the plasma p-tau217
measurement, which is a key indicator of AD progression, while MRI provides
anatomical structure constraints. The proposed framework is trained and
evaluated using clinical AV1451 tau PET data from the Alzheimer's Disease
Neuroimaging Initiative (ADNI) database. Experimental results demonstrate that
our approach can generate realistic, clinically meaningful 3D tau PET across a
range of disease stages. The proposed framework can help perform tau PET data
augmentation under different settings, provide a non-invasive, cost-effective
alternative for visualizing tau pathology, and support the simulation of
disease progression under varying plasma biomarker levels and cognitive
conditions.

</details>


### [50] [Dual-Scale Volume Priors with Wasserstein-Based Consistency for Semi-Supervised Medical Image Segmentation](https://arxiv.org/abs/2509.04273)
*Junying Meng,Gangxuan Zhou,Jun Liu,Weihong Guo*

Main category: cs.CV

TL;DR: 本研究提出了一种半监督医学图像分割框架，该框架结合了空间正则化和体积先验，在ACDC、PROMISE12和股肌MR图像数据集上取得了优越的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的半监督医学图像分割方法在特征提取和利用数据集先验信息方面存在不足。

Method: 该框架整合了基于变分模型的显式体积先验和阈值动态空间正则化，并引入回归网络估计无标签图像的目标区域体积，通过图像级Wasserstein距离约束来约束主干分割网络。此外，还设计了基于弱隐式体积先验的数据集级Wasserstein距离损失函数。

Result: 在ACDC、PROMISE12和股肌MR图像数据集上的实验结果表明，该方法优于现有方法。

Conclusion: 所提出的半监督医学图像分割框架能够有效利用空间正则化和体积先验，提高了分割精度。

Abstract: Despite signi cant progress in semi-supervised medical image segmentation,
most existing segmentation networks overlook e ective methodological guidance
for feature extraction and important prior information from
  datasets. In this paper, we develop a semi-supervised medical image
segmentation framework that e ectively integrates spatial regularization
methods and volume priors. Speci cally, our approach integrates a strong
explicit volume prior at the image scale and Threshold Dynamics spatial
regularization, both derived from variational models, into the backbone
segmentation network. The target region volumes for each unlabeled image are
estimated by a regression network, which e ectively regularizes the backbone
segmentation network through an image-scale Wasserstein distance constraint,
ensuring that the class ratios in the segmentation results for each unlabeled
image match those predicted by the regression network. Additionally, we design
a dataset-scale Wasserstein distance loss function based on a weak implicit
volume prior, which enforces that the volume distribution predicted for the
unlabeled dataset is similar to that of labeled dataset. Experimental results
on the 2017 ACDC dataset, PROMISE12 dataset, and thigh muscle MR image dataset
show the superiority of the proposed method.

</details>


### [51] [PAOLI: Pose-free Articulated Object Learning from Sparse-view Images](https://arxiv.org/abs/2509.04276)
*Jianning Deng,Kartic Subr,Hakan Bilen*

Main category: cs.CV

TL;DR: 提出了一种新颖的自监督框架，用于从稀疏视图、未加姿势的图像中学习可动关节物体表示。


<details>
  <summary>Details</summary>
Motivation: 与先前需要密集多视图观察和地面真实相机姿势的方法不同，该方法只需要每个关节四个视图且无需相机监督。

Method: 首先使用稀疏视图3D重建独立重建每个关节，然后学习一个变形场，该变形场在不同姿势之间建立密集对应关系。渐进式分离策略进一步分离静态和移动部件，从而能够鲁棒地分离相机和物体运动。最后，联合优化几何、外观和运动学，并使用自监督损失来强制执行跨视图和跨姿势的一致性。

Result: 在标准基准和真实世界示例上的实验表明，该方法在明显弱于现有方法输入的假设下，能够生成准确且详细的可动关节物体表示。

Conclusion: 该方法在稀疏视图、未加姿势的图像下学习可动关节物体表示是一种有效的方法，显著弱化了对输入的要求。

Abstract: We present a novel self-supervised framework for learning articulated object
representations from sparse-view, unposed images. Unlike prior methods that
require dense multi-view observations and ground-truth camera poses, our
approach operates with as few as four views per articulation and no camera
supervision. To address the inherent challenges, we first reconstruct each
articulation independently using recent advances in sparse-view 3D
reconstruction, then learn a deformation field that establishes dense
correspondences across poses. A progressive disentanglement strategy further
separates static from moving parts, enabling robust separation of camera and
object motion. Finally, we jointly optimize geometry, appearance, and
kinematics with a self-supervised loss that enforces cross-view and cross-pose
consistency. Experiments on the standard benchmark and real-world examples
demonstrate that our method produces accurate and detailed articulated object
representations under significantly weaker input assumptions than existing
approaches.

</details>


### [52] [Noisy Label Refinement with Semantically Reliable Synthetic Images](https://arxiv.org/abs/2509.04298)
*Yingxuan Li,Jiafeng Mao,Yusuke Matsui*

Main category: cs.CV

TL;DR: 提出一种利用合成图像识别和纠正噪声数据集中的错误标签的新方法，以提高图像分类的准确性。


<details>
  <summary>Details</summary>
Motivation: 由于数据集中视觉相似的类别经常被错误标记，语义噪声对传统的监督学习方法构成了重大挑战。

Method: 利用文本到图像模型生成的合成图像作为参考点，识别和纠正噪声数据集中的错误标记样本。

Result: 在多个基准数据集上的大量实验表明，该方法显著提高了各种噪声条件下的分类准确性，特别是在具有语义标签噪声的挑战性场景中。与最先进的噪声鲁棒训练方法相结合，可以显著提高准确性，在 CIFAR-10 和 CIFAR-100 上提高 30% 和 11%，在 ImageNet-100 上提高 24%。

Conclusion: 所提出的利用合成图像识别和纠正噪声数据集中的错误标签的方法，在提高图像分类准确性方面非常有效，并且可以与现有的噪声鲁棒学习技术相结合，以获得更好的性能。

Abstract: Semantic noise in image classification datasets, where visually similar
categories are frequently mislabeled, poses a significant challenge to
conventional supervised learning approaches. In this paper, we explore the
potential of using synthetic images generated by advanced text-to-image models
to address this issue. Although these high-quality synthetic images come with
reliable labels, their direct application in training is limited by domain gaps
and diversity constraints. Unlike conventional approaches, we propose a novel
method that leverages synthetic images as reliable reference points to identify
and correct mislabeled samples in noisy datasets. Extensive experiments across
multiple benchmark datasets show that our approach significantly improves
classification accuracy under various noise conditions, especially in
challenging scenarios with semantic label noise. Additionally, since our method
is orthogonal to existing noise-robust learning techniques, when combined with
state-of-the-art noise-robust training methods, it achieves superior
performance, improving accuracy by 30% on CIFAR-10 and by 11% on CIFAR-100
under 70% semantic noise, and by 24% on ImageNet-100 under real-world noise
conditions.

</details>


### [53] [Efficient Odd-One-Out Anomaly Detection](https://arxiv.org/abs/2509.04326)
*Silvio Chito,Paolo Rabino,Tatiana Tommasi*

Main category: cs.CV

TL;DR: 提出了一种基于DINO的高效模型，用于检测异常实例，参数减少三分之一，训练时间缩短三分之二，同时保持了有竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 检测多对象场景中的异常实例，并强调了空间推理、关系推理和效率的挑战。

Method: 提出了一种基于DINO的模型，并引入了一个多模态大型语言模型基线。

Result: 与现有最先进的模型相比，参数减少了三分之一，训练时间缩短了三分之二，同时保持了有竞争力的性能。多模态大型语言模型基线在结构化视觉推理任务方面存在局限性。

Conclusion: 所提出的基于DINO的模型在效率和性能方面优于现有方法，并且多模态大型语言模型在结构化视觉推理方面仍有改进空间。

Abstract: The recently introduced odd-one-out anomaly detection task involves
identifying the odd-looking instances within a multi-object scene. This problem
presents several challenges for modern deep learning models, demanding spatial
reasoning across multiple views and relational reasoning to understand context
and generalize across varying object categories and layouts. We argue that
these challenges must be addressed with efficiency in mind. To this end, we
propose a DINO-based model that reduces the number of parameters by one third
and shortens training time by a factor of three compared to the current
state-of-the-art, while maintaining competitive performance. Our experimental
evaluation also introduces a Multimodal Large Language Model baseline,
providing insights into its current limitations in structured visual reasoning
tasks. The project page can be found at
https://silviochito.github.io/EfficientOddOneOut/

</details>


### [54] [GeoArena: An Open Platform for Benchmarking Large Vision-language Models on WorldWide Image Geolocalization](https://arxiv.org/abs/2509.04334)
*Pengyue Jia,Yingyi Zhang,Xiangyu Zhao,Yixuan Li*

Main category: cs.CV

TL;DR: GeoArena是一个用于评估视觉语言模型（LVLM）在图像地理定位任务上的开放平台，解决了现有评估方法的局限性，并通过众包方式收集用户偏好数据来建立排行榜。


<details>
  <summary>Details</summary>
Motivation: 当前图像地理定位的评估方法存在数据泄露和评价指标过于依赖精确坐标的问题，未能充分反映模型的实际能力，并可能引发隐私担忧。

Method: 提出GeoArena平台，该平台允许用户上传真实世界图像，并采用基于成对人类判断的方式来评估模型输出的地理定位准确性，以替代传统的精确坐标匹配。

Result: 在平台上线的两个月内收集了数千条投票数据，并基于这些数据对不同的LVLM进行了分析和排名，建立了图像地理定位任务的排行榜。

Conclusion: GeoArena提供了一个更真实、以人为本的基准测试环境，有助于更准确地评估LVLM在图像地理定位任务上的表现，并为未来的研究提供了有价值的数据集和分析。

Abstract: Image geolocalization aims to predict the geographic location of images
captured anywhere on Earth, but its global nature presents significant
challenges. Current evaluation methodologies suffer from two major limitations.
First, data leakage: advanced approaches often rely on large vision-language
models (LVLMs) to predict image locations, yet these models are frequently
pretrained on the test datasets, compromising the accuracy of evaluating a
model's actual geolocalization capability. Second, existing metrics primarily
rely on exact geographic coordinates to assess predictions, which not only
neglects the reasoning process but also raises privacy concerns when user-level
location data is required. To address these issues, we propose GeoArena, a
first open platform for evaluating LVLMs on worldwide image geolocalization
tasks, offering true in-the-wild and human-centered benchmarking. GeoArena
enables users to upload in-the-wild images for a more diverse evaluation
corpus, and it leverages pairwise human judgments to determine which model
output better aligns with human expectations. Our platform has been deployed
online for two months, during which we collected over thousands voting records.
Based on this data, we conduct a detailed analysis and establish a leaderboard
of different LVLMs on the image geolocalization task.

</details>


### [55] [From Editor to Dense Geometry Estimator](https://arxiv.org/abs/2509.04338)
*JiYuan Wang,Chunyu Lin,Lei Sun,Rongying Liu,Lang Nie,Mingxing Li,Kang Liao,Xiangxiang Chu,Yao Zhao*

Main category: cs.CV

TL;DR: 图像编辑模型比图像生成模型更适合用于密集预测任务，并提出了一种基于DiT的FE2E框架，通过改进的训练目标和量化方法，在零样本单目深度和法线估计方面取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 研究发现图像编辑模型比图像生成模型更适合用于密集预测任务，因为它们具有固有的结构先验，可以更稳定地收敛并达到更高的性能。

Method: 提出FE2E框架，该框架将先进的基于Diffusion Transformer（DiT）的编辑模型改编用于密集几何预测。通过将原始的流匹配损失重新制定为“一致速度”训练目标，并使用对数量化来解决精度冲突，以及利用DiT的全局注意力来实现深度和法线估计的联合预测。

Result: FE2E框架在零样本单目深度和法线估计方面取得了显著的性能提升，在ETH3D数据集上性能提升超过35%，并且优于在100倍数据上训练的DepthAnything系列模型。

Conclusion: 基于图像编辑模型的优势，FE2E框架通过创新的方法在密集几何预测任务上取得了优于现有技术的性能。

Abstract: Leveraging visual priors from pre-trained text-to-image (T2I) generative
models has shown success in dense prediction. However, dense prediction is
inherently an image-to-image task, suggesting that image editing models, rather
than T2I generative models, may be a more suitable foundation for fine-tuning.
  Motivated by this, we conduct a systematic analysis of the fine-tuning
behaviors of both editors and generators for dense geometry estimation. Our
findings show that editing models possess inherent structural priors, which
enable them to converge more stably by ``refining" their innate features, and
ultimately achieve higher performance than their generative counterparts.
  Based on these findings, we introduce \textbf{FE2E}, a framework that
pioneeringly adapts an advanced editing model based on Diffusion Transformer
(DiT) architecture for dense geometry prediction. Specifically, to tailor the
editor for this deterministic task, we reformulate the editor's original flow
matching loss into the ``consistent velocity" training objective. And we use
logarithmic quantization to resolve the precision conflict between the editor's
native BFloat16 format and the high precision demand of our tasks.
Additionally, we leverage the DiT's global attention for a cost-free joint
estimation of depth and normals in a single forward pass, enabling their
supervisory signals to mutually enhance each other.
  Without scaling up the training data, FE2E achieves impressive performance
improvements in zero-shot monocular depth and normal estimation across multiple
datasets. Notably, it achieves over 35\% performance gains on the ETH3D dataset
and outperforms the DepthAnything series, which is trained on 100$\times$ data.
The project page can be accessed \href{https://amap-ml.github.io/FE2E/}{here}.

</details>


### [56] [MICACL: Multi-Instance Category-Aware Contrastive Learning for Long-Tailed Dynamic Facial Expression Recognition](https://arxiv.org/abs/2509.04344)
*Feng-Qi Cui,Zhen Lin,Xinlong Rao,Anyang Tong,Shiyao Li,Fei Wang,Changlin Chen,Bin Liu*

Main category: cs.CV

TL;DR: 该论文提出了一种名为MICACL的多实例学习框架，用于解决动态面部表情识别（DFER）中长尾分布和时空特征建模的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的DFER方法难以处理长尾分布和复杂的时空特征建模问题，导致模型归纳偏差严重。

Method: 提出了一种名为MICACL的多实例学习框架，集成了图增强实例交互模块（GEIIM）来捕捉时空依赖关系，加权实例聚合网络（WIAN）来增强实例级特征聚合，以及多尺度类别感知对比学习（MCCL）策略来平衡长尾分布的训练。

Result: 在DFEW和FERV39k等真实数据集上进行了大量实验，结果表明MICACL实现了最先进的性能，并具有优越的鲁棒性和泛化能力。

Conclusion: MICACL框架能有效解决DFER中的长尾分布和时空特征建模问题，并取得优越的性能。

Abstract: Dynamic facial expression recognition (DFER) faces significant challenges due
to long-tailed category distributions and complexity of spatio-temporal feature
modeling. While existing deep learning-based methods have improved DFER
performance, they often fail to address these issues, resulting in severe model
induction bias. To overcome these limitations, we propose a novel
multi-instance learning framework called MICACL, which integrates
spatio-temporal dependency modeling and long-tailed contrastive learning
optimization. Specifically, we design the Graph-Enhanced Instance Interaction
Module (GEIIM) to capture intricate spatio-temporal between adjacent instances
relationships through adaptive adjacency matrices and multiscale convolutions.
To enhance instance-level feature aggregation, we develop the Weighted Instance
Aggregation Network (WIAN), which dynamically assigns weights based on instance
importance. Furthermore, we introduce a Multiscale Category-aware Contrastive
Learning (MCCL) strategy to balance training between major and minor
categories. Extensive experiments on in-the-wild datasets (i.e., DFEW and
FERV39k) demonstrate that MICACL achieves state-of-the-art performance with
superior robustness and generalization.

</details>


### [57] [Stitching the Story: Creating Panoramic Incident Summaries from Body-Worn Footage](https://arxiv.org/abs/2509.04370)
*Dor Cohen,Inga Efrosman,Yehudit Aperstein,Alexander Apartsin*

Main category: cs.CV

TL;DR: 该研究提出了一种将执法记录仪视频转换为全景图的计算机视觉方法，以快速总结事件现场。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的执法记录仪视频审查耗时且不切实际，尤其是在需要快速了解情况的紧急情况下。需要一种能够快速解释的简洁视觉摘要来有效掌握态势感知。

Method: 利用单目同时定位与地图构建（SLAM）技术来估计相机轨迹和重建环境空间布局。通过聚类相机轨迹中的关键视角点，并从中选择代表性帧。利用多帧拼接技术将这些帧融合成空间一致的全景图像。

Result: 生成的信息丰富的全景图像总结了事件现场，能够快速理解复杂环境。

Conclusion: 所提出的方法通过生成全景图像摘要，实现了对执法记录仪视频的快速理解，从而促进了有效的决策和事件审查。

Abstract: First responders widely adopt body-worn cameras to document incident scenes
and support post-event analysis. However, reviewing lengthy video footage is
impractical in time-critical situations. Effective situational awareness
demands a concise visual summary that can be quickly interpreted. This work
presents a computer vision pipeline that transforms body-camera footage into
informative panoramic images summarizing the incident scene. Our method
leverages monocular Simultaneous Localization and Mapping (SLAM) to estimate
camera trajectories and reconstruct the spatial layout of the environment. Key
viewpoints are identified by clustering camera poses along the trajectory, and
representative frames from each cluster are selected. These frames are fused
into spatially coherent panoramic images using multi-frame stitching
techniques. The resulting summaries enable rapid understanding of complex
environments and facilitate efficient decision-making and incident review.

</details>


### [58] [AnomalyLMM: Bridging Generative Knowledge and Discriminative Retrieval for Text-Based Person Anomaly Search](https://arxiv.org/abs/2509.04376)
*Hao Ju,Hu Zhang,Zhedong Zheng*

Main category: cs.CV

TL;DR: AnomalyLMM是一个利用大型多模态模型（LMM）进行基于文本的人物异常搜索的框架，通过新颖的管道和训练无关的适应策略来解决细粒度跨模态对齐和稀疏样本识别的挑战。


<details>
  <summary>Details</summary>
Motivation: 随着公众安全需求的增长，以及传统方法在细粒度跨模态对齐和稀疏样本识别方面的不足，利用大型多模态模型（LMM）进行基于文本的人物异常搜索成为一项关键任务。

Method: 提出AnomalyLMM框架，采用粗到细的管道整合LMM，并设计了包括掩码跨模态提示、行为显著性预测和知识感知重排的训练无关适应策略，以实现零样本学习和对细微异常线索的关注。

Result: 在PAB数据集上进行评估，AnomalyLMM超越了基线方法，Recall@1精度提高了+0.96%。此外，该方法能够展示文本异常和视觉行为之间可解释的对齐。

Conclusion: AnomalyLMM是首个成功将LMM应用于文本人物异常搜索的框架，通过其创新的方法在性能和可解释性方面均取得了显著成果，为未来的相关研究奠定了基础。

Abstract: With growing public safety demands, text-based person anomaly search has
emerged as a critical task, aiming to retrieve individuals with abnormal
behaviors via natural language descriptions. Unlike conventional person search,
this task presents two unique challenges: (1) fine-grained cross-modal
alignment between textual anomalies and visual behaviors, and (2) anomaly
recognition under sparse real-world samples. While Large Multi-modal Models
(LMMs) excel in multi-modal understanding, their potential for fine-grained
anomaly retrieval remains underexplored, hindered by: (1) a domain gap between
generative knowledge and discriminative retrieval, and (2) the absence of
efficient adaptation strategies for deployment. In this work, we propose
AnomalyLMM, the first framework that harnesses LMMs for text-based person
anomaly search. Our key contributions are: (1) A novel coarse-to-fine pipeline
integrating LMMs to bridge generative world knowledge with retrieval-centric
anomaly detection; (2) A training-free adaptation cookbook featuring masked
cross-modal prompting, behavioral saliency prediction, and knowledge-aware
re-ranking, enabling zero-shot focus on subtle anomaly cues. As the first study
to explore LMMs for this task, we conduct a rigorous evaluation on the PAB
dataset, the only publicly available benchmark for text-based person anomaly
search, with its curated real-world anomalies covering diverse scenarios (e.g.,
falling, collision, and being hit). Experiments show the effectiveness of the
proposed method, surpassing the competitive baseline by +0.96% Recall@1
accuracy. Notably, our method reveals interpretable alignment between textual
anomalies and visual behaviors, validated via qualitative analysis. Our code
and models will be released for future research.

</details>


### [59] [Aesthetic Image Captioning with Saliency Enhanced MLLMs](https://arxiv.org/abs/2509.04378)
*Yilin Tao,Jiashui Huang,Huaze Xu,Ling Shao*

Main category: cs.CV

TL;DR: 本研究提出ASE-MLLM框架，通过引入图像美学显著性模块(IASM)和IAS-ViT，将美学特征融入MLLM，以提升图像美学描述生成能力，并在AIC任务上达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有利用MLLM进行图像美学描述生成的研究，主要关注美学评分预测，且微调方法未能有效聚焦目标美学内容。

Method: 提出ASE-MLLM框架，包含图像美学显著性模块(IASM)，并设计IAS-ViT作为图像编码器，通过交叉注意力机制融合美学显著性特征和原始图像特征。

Result: 在主流AIC基准测试中，ASE-MLLM显著优于传统方法和通用MLLM，取得了SOTA性能。

Conclusion: ASE-MLLM是首个将图像美学显著性集成到MLLM以专门用于AIC任务的框架，实验证明其有效性。

Abstract: Aesthetic Image Captioning (AIC) aims to generate textual descriptions of
image aesthetics, becoming a key research direction in the field of
computational aesthetics. In recent years, pretrained Multimodal Large Language
Models (MLLMs) have advanced rapidly, leading to a significant increase in
image aesthetics research that integrates both visual and textual modalities.
However, most existing studies on image aesthetics primarily focus on
predicting aesthetic ratings and have shown limited application in AIC.
Existing AIC works leveraging MLLMs predominantly rely on fine-tuning methods
without specifically adapting MLLMs to focus on target aesthetic content. To
address this limitation, we propose the Aesthetic Saliency Enhanced Multimodal
Large Language Model (ASE-MLLM), an end-to-end framework that explicitly
incorporates aesthetic saliency into MLLMs. Within this framework, we introduce
the Image Aesthetic Saliency Module (IASM), which efficiently and effectively
extracts aesthetic saliency features from images. Additionally, we design
IAS-ViT as the image encoder for MLLMs, this module fuses aesthetic saliency
features with original image features via a cross-attention mechanism. To the
best of our knowledge, ASE-MLLM is the first framework to integrate image
aesthetic saliency into MLLMs specifically for AIC tasks. Extensive experiments
demonstrated that our approach significantly outperformed traditional methods
and generic MLLMs on current mainstream AIC benchmarks, achieving
state-of-the-art (SOTA) performance.

</details>


### [60] [SSGaussian: Semantic-Aware and Structure-Preserving 3D Style Transfer](https://arxiv.org/abs/2509.04379)
*Jimin Xu,Bosheng Qin,Tao Jin,Zhou Zhao,Zhenhui Ye,Jun Yu,Fei Wu*

Main category: cs.CV

TL;DR: 通过结合预训练的2D扩散模型，提出了一种新颖的3D风格迁移管线，以解决现有方法难以提取高层风格语义和风格化结果缺乏结构清晰度的问题。


<details>
  <summary>Details</summary>
Motivation: 现有3D风格迁移方法难以提取高层风格语义，且风格化结果缺乏结构清晰度，难以区分3D场景中的不同实例或物体。

Method: 提出了一种新颖的3D风格迁移管线，包含两个主要阶段：1. 利用扩散先验生成关键视角的风格化渲染图。2. 将风格化关键视图迁移到3D表示上。该过程包含两个创新设计：跨视角风格对齐（在UNet的最后一个上采样块中插入跨视角注意力，以实现跨多个关键视图的特征交互）和实例级风格迁移（利用风格化关键视图之间的实例级一致性，并将其迁移到3D表示上）。

Result: 与现有技术相比，在从前向场景到具有挑战性的360度环境的各种场景中，实现了更具结构性、视觉一致性和艺术性的风格化3D场景。

Conclusion: 提出的3D风格迁移管线能够有效提取和迁移高层风格语义，并生成结构清晰、实例分离的风格化3D场景，在各种场景下均优于现有方法。

Abstract: Recent advancements in neural representations, such as Neural Radiance Fields
and 3D Gaussian Splatting, have increased interest in applying style transfer
to 3D scenes. While existing methods can transfer style patterns onto
3D-consistent neural representations, they struggle to effectively extract and
transfer high-level style semantics from the reference style image.
Additionally, the stylized results often lack structural clarity and
separation, making it difficult to distinguish between different instances or
objects within the 3D scene. To address these limitations, we propose a novel
3D style transfer pipeline that effectively integrates prior knowledge from
pretrained 2D diffusion models. Our pipeline consists of two key stages: First,
we leverage diffusion priors to generate stylized renderings of key viewpoints.
Then, we transfer the stylized key views onto the 3D representation. This
process incorporates two innovative designs. The first is cross-view style
alignment, which inserts cross-view attention into the last upsampling block of
the UNet, allowing feature interactions across multiple key views. This ensures
that the diffusion model generates stylized key views that maintain both style
fidelity and instance-level consistency. The second is instance-level style
transfer, which effectively leverages instance-level consistency across
stylized key views and transfers it onto the 3D representation. This results in
a more structured, visually coherent, and artistically enriched stylization.
Extensive qualitative and quantitative experiments demonstrate that our 3D
style transfer pipeline significantly outperforms state-of-the-art methods
across a wide range of scenes, from forward-facing to challenging 360-degree
environments. Visit our project page https://jm-xu.github.io/SSGaussian for
immersive visualization.

</details>


### [61] [Learning neural representations for X-ray ptychography reconstruction with unknown probes](https://arxiv.org/abs/2509.04402)
*Tingyou Li,Zixin Xu,Zirui Gao,Hanfei Yan,Xiaojing Huang,Jizhou Li*

Main category: cs.CV

TL;DR: X-ray ptychography的探针恢复问题通过一种新的自监督方法PtyINR得到解决，该方法使用神经表示同时进行物体和探针的重建，在低信号条件下表现出优越的性能。


<details>
  <summary>Details</summary>
Motivation: X射线 अशापनीयता (X-ray ptychography) 的图像重建在物体和探针都未知的情况下存在挑战，尤其是在低信号条件下，传统的迭代方法和深度学习方法效果不佳，限制了该技术在材料科学、生物学和纳米技术等领域的应用。

Method: 提出了一种名为PtyINR（Ptychographic Implicit Neural Representation）的自监督框架，该框架将物体和探针参数化为连续的神经表示，并直接从原始衍射图进行端到端的重建，无需预先表征探针。

Result: 在模拟和实验数据上都取得了优于传统方法的重建质量，尤其在低信号条件下表现出卓越的鲁棒性。

Conclusion: PtyINR是一个通用的、受物理启发的框架，可以解决依赖于探针的逆问题，适用于计算显微镜领域的广泛问题。

Abstract: X-ray ptychography provides exceptional nanoscale resolution and is widely
applied in materials science, biology, and nanotechnology. However, its full
potential is constrained by the critical challenge of accurately reconstructing
images when the illuminating probe is unknown. Conventional iterative methods
and deep learning approaches are often suboptimal, particularly under the
low-signal conditions inherent to low-dose and high-speed experiments. These
limitations compromise reconstruction fidelity and restrict the broader
adoption of the technique. In this work, we introduce the Ptychographic
Implicit Neural Representation (PtyINR), a self-supervised framework that
simultaneously addresses the object and probe recovery problem. By
parameterizing both as continuous neural representations, PtyINR performs
end-to-end reconstruction directly from raw diffraction patterns without
requiring any pre-characterization of the probe. Extensive evaluations
demonstrate that PtyINR achieves superior reconstruction quality on both
simulated and experimental data, with remarkable robustness under challenging
low-signal conditions. Furthermore, PtyINR offers a generalizable,
physics-informed framework for addressing probe-dependent inverse problems,
making it applicable to a wide range of computational microscopy problems.

</details>


### [62] [Self-adaptive Dataset Construction for Real-World Multimodal Safety Scenarios](https://arxiv.org/abs/2509.04403)
*Jingen Qu,Lijun Li,Bo Zhang,Yichen Yan,Jing Shao*

Main category: cs.CV

TL;DR: 现有的针对多模态大语言模型（MLLM）的安全数据集构建方法无法应对日益复杂和多样化的现实世界多模态安全（RMS）场景，且缺乏统一的评估指标。本文提出了一种新颖的、以图像为导向的自适应数据集构建方法，该方法从图像出发，自动生成包含文本和指导性回复的RMS数据集，规模达35k个图像-文本对。同时，研究引入了一种标准化的安全数据集评估指标，通过微调安全评判模型并在其他安全数据集上评估其能力来衡量。实验证明了该图像导向方法在多项任务上的有效性、可扩展性和普适性，为构建RMS数据集提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 现有的风险导向型数据集构建方法无法覆盖现实世界多模态安全（RMS）场景日益增长的复杂性，并且缺乏统一的评估指标来衡量其整体有效性。

Method: 提出了一种以图像为导向的自适应数据集构建方法，从图像出发自动生成RMS数据集（包含35k个图像-文本对及指导性回复）。同时，引入了一种标准化的安全数据集评估指标，通过微调安全评判模型并在其他安全数据集上评估其能力。

Result: 通过大量实验证明了所提出的以图像为导向的流程在各项任务上的有效性，并确认了该方法的扩展性和有效性。

Conclusion: 以图像为导向的方法为构建现实世界多模态安全数据集提供了一种新的视角，并证明了其有效性和可扩展性。

Abstract: Multimodal large language models (MLLMs) are rapidly evolving, presenting
increasingly complex safety challenges. However, current dataset construction
methods, which are risk-oriented, fail to cover the growing complexity of
real-world multimodal safety scenarios (RMS). And due to the lack of a unified
evaluation metric, their overall effectiveness remains unproven. This paper
introduces a novel image-oriented self-adaptive dataset construction method for
RMS, which starts with images and end constructing paired text and guidance
responses. Using the image-oriented method, we automatically generate an RMS
dataset comprising 35k image-text pairs with guidance responses. Additionally,
we introduce a standardized safety dataset evaluation metric: fine-tuning a
safety judge model and evaluating its capabilities on other safety
datasets.Extensive experiments on various tasks demonstrate the effectiveness
of the proposed image-oriented pipeline. The results confirm the scalability
and effectiveness of the image-oriented approach, offering a new perspective
for the construction of real-world multimodal safety datasets.

</details>


### [63] [Few-step Flow for 3D Generation via Marginal-Data Transport Distillation](https://arxiv.org/abs/2509.04406)
*Zanwei Zhou,Taoran Yi,Jiemin Fang,Chen Yang,Lingxi Xie,Xinggang Wang,Wei Shen,Qi Tian*

Main category: cs.CV

TL;DR: MDT-dist 是一个新颖的框架，用于对 3D 流进行几步蒸馏，通过学习边际数据传输，使用速度匹配和速度蒸馏来优化，从而实现 3D 生成的加速。


<details>
  <summary>Details</summary>
Motivation: 现有的基于流的 3D 生成模型在推理时需要大量的采样步骤。虽然 2D 扩散模型可以通过几步蒸馏方法（如一致性模型）得到加速，但这些方法在更复杂的 3D 生成任务中的应用仍有待探索。

Method: MDT-dist 框架通过学习边际数据传输来实现几步 3D 流蒸馏。它提出了两个可优化的目标：速度匹配（VM）和速度蒸馏（VD）。VM 学习匹配学生和教师之间的速度场，而 VD 则利用学习到的速度场进行概率密度蒸馏。

Result: 在 TRELLIS 3D 生成框架上，MDT-dist 将每个流变换器的采样步骤从 25 步减少到 1 或 2 步，在 A800 GPU 上实现了 0.68 秒（1 步 x 2）和 0.94 秒（2 步 x 2）的延迟，分别实现了 9.0 倍和 6.5 倍的加速，同时保持了高视觉和几何保真度。

Conclusion: MDT-dist 在几步 3D 生成方面显著优于现有的一致性模型蒸馏方法，并使 TRELLIS 框架能够实现卓越的性能。

Abstract: Flow-based 3D generation models typically require dozens of sampling steps
during inference. Though few-step distillation methods, particularly
Consistency Models (CMs), have achieved substantial advancements in
accelerating 2D diffusion models, they remain under-explored for more complex
3D generation tasks. In this study, we propose a novel framework, MDT-dist, for
few-step 3D flow distillation. Our approach is built upon a primary objective:
distilling the pretrained model to learn the Marginal-Data Transport. Directly
learning this objective needs to integrate the velocity fields, while this
integral is intractable to be implemented. Therefore, we propose two
optimizable objectives, Velocity Matching (VM) and Velocity Distillation (VD),
to equivalently convert the optimization target from the transport level to the
velocity and the distribution level respectively. Velocity Matching (VM) learns
to stably match the velocity fields between the student and the teacher, but
inevitably provides biased gradient estimates. Velocity Distillation (VD)
further enhances the optimization process by leveraging the learned velocity
fields to perform probability density distillation. When evaluated on the
pioneer 3D generation framework TRELLIS, our method reduces sampling steps of
each flow transformer from 25 to 1 or 2, achieving 0.68s (1 step x 2) and 0.94s
(2 steps x 2) latency with 9.0x and 6.5x speedup on A800, while preserving high
visual and geometric fidelity. Extensive experiments demonstrate that our
method significantly outperforms existing CM distillation methods, and enables
TRELLIS to achieve superior performance in few-step 3D generation.

</details>


### [64] [Durian: Dual Reference-guided Portrait Animation with Attribute Transfer](https://arxiv.org/abs/2509.04434)
*Hyunsoo Cha,Byungjun Kim,Hanbyul Joo*

Main category: cs.CV

TL;DR: Durian是一种零样本肖像动画生成方法，通过从参考图像到目标肖像的属性转移，实现了高保真和空间一致的属性转移。


<details>
  <summary>Details</summary>
Motivation: 生成具有面部属性转移的肖像动画视频，在零样本条件下，从给定参考图像到目标肖像。

Method: 提出了一种名为Durian的方法，采用双参考网络将肖像和属性图像的空间特征注入扩散模型的去噪过程。使用自重建公式进行训练，其中采样同一肖像视频中的两个帧，一个作为属性参考，一个作为目标肖像，并根据输入和相应的掩码重建其余帧。提出了一种使用关键点条件图像生成的掩码扩展策略，以支持具有不同空间范围的属性转移。此外，还对属性和肖像图像进行了空间和外观级别的变换，以提高对齐鲁棒性。

Result: Durian在具有属性转移的肖像动画方面取得了最先进的性能，其双参考设计能够在没有额外训练的情况下，在单次生成过程中实现多属性组合。

Conclusion: Durian在零样本肖像动画生成方面取得了成功，能够实现高保真和空间一致的属性转移，并支持多属性组合。

Abstract: We present Durian, the first method for generating portrait animation videos
with facial attribute transfer from a given reference image to a target
portrait in a zero-shot manner. To enable high-fidelity and spatially
consistent attribute transfer across frames, we introduce dual reference
networks that inject spatial features from both the portrait and attribute
images into the denoising process of a diffusion model. We train the model
using a self-reconstruction formulation, where two frames are sampled from the
same portrait video: one is treated as the attribute reference and the other as
the target portrait, and the remaining frames are reconstructed conditioned on
these inputs and their corresponding masks. To support the transfer of
attributes with varying spatial extent, we propose a mask expansion strategy
using keypoint-conditioned image generation for training. In addition, we
further augment the attribute and portrait images with spatial and
appearance-level transformations to improve robustness to positional
misalignment between them. These strategies allow the model to effectively
generalize across diverse attributes and in-the-wild reference combinations,
despite being trained without explicit triplet supervision. Durian achieves
state-of-the-art performance on portrait animation with attribute transfer, and
notably, its dual reference design enables multi-attribute composition in a
single generation pass without additional training.

</details>


### [65] [The Telephone Game: Evaluating Semantic Drift in Unified Models](https://arxiv.org/abs/2509.04438)
*Sabbir Mollah,Rohit Gupta,Sirnam Swetha,Qingyang Liu,Ahnaf Munir,Mubarak Shah*

Main category: cs.CV

TL;DR: 该论文提出了一种名为UCF-UM的评估框架，用于衡量统一视觉语言模型（UM）在图像到文本（I2T）和文本到图像（T2I）跨模态任务中的一致性，解决了现有评估方法各自独立评估I2T和T2I能力的问题。UCF-UM通过多轮I2T和T2I交替进行来量化语义漂移，并引入了平均累积漂移（MCD）、语义漂移率（SDR）和多代生成评估（MGG）三个新指标。研究还创建了ND400基准以评估模型在COCO数据集之外的泛化能力，并发现不同模型在跨模态稳定性方面存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型（VLM）评估方法将图像到文本（I2T）和文本到图像（T2I）能力分开评估，无法衡量模型在理解和生成之间保持语义一致性的能力，这对于下游应用至关重要。需要一种能够评估模型在跨模态循环中保持意义的能力的评估方法。

Method: 提出了一种名为UCF-UM的评估框架，采用多轮I2T和T2I交替进行的循环评估协议来量化语义漂移。引入了三个新指标：平均累积漂移（MCD）、语义漂移率（SDR）和多代生成评估（MGG）。创建了一个名为ND400的新基准，用于在COCO数据集之外评估模型的泛化能力。

Result: UCF-UM框架揭示了不同模型在跨模态稳定性方面存在显著差异。一些模型（如BAGEL）能在多轮交替中保持语义一致性，而另一些模型（如Vila-u）即使在单次评估中得分很高，也会快速出现语义漂移。研究结果强调了循环一致性评估作为标准I2T和T2I评估的补充的重要性。

Conclusion: 循环一致性评估是衡量统一模型（UM）跨模态稳定性的必要补充。UCF-UM提供了一套实用的指标，能够一致地评估UM的跨模态稳定性和其共享表征的强度。现有评估方法未能充分揭示模型在跨模态任务中的语义保持能力。

Abstract: Employing a single, unified model (UM) for both visual understanding
(image-to-text: I2T) and and visual generation (text-to-image: T2I) has opened
a new direction in Visual Language Model (VLM) research. While UMs can also
support broader unimodal tasks (e.g., text-to-text, image-to-image), we focus
on the core cross-modal pair T2I and I2T, as consistency between understanding
and generation is critical for downstream use. Existing evaluations consider
these capabilities in isolation: FID and GenEval for T2I, and benchmarks such
as MME, MMBench for I2T. These single-pass metrics do not reveal whether a
model that understands a concept can also render it, nor whether meaning is
preserved when cycling between image and text modalities. To address this, we
introduce the Unified Consistency Framework for Unified Models (UCF-UM), a
cyclic evaluation protocol that alternates I2T and T2I over multiple
generations to quantify semantic drift. UCF formulates 3 metrics: (i) Mean
Cumulative Drift (MCD), an embedding-based measure of overall semantic loss;
(ii) Semantic Drift Rate (SDR), that summarizes semantic decay rate; and (iii)
Multi-Generation GenEval (MGG), an object-level compliance score extending
GenEval. To assess generalization beyond COCO, which is widely used in
training; we create a new benchmark ND400, sampled from NoCaps and DOCCI and
evaluate on seven recent models. UCF-UM reveals substantial variation in
cross-modal stability: some models like BAGEL maintain semantics over many
alternations, whereas others like Vila-u drift quickly despite strong
single-pass scores. Our results highlight cyclic consistency as a necessary
complement to standard I2T and T2I evaluations, and provide practical metrics
to consistently assess unified model's cross-modal stability and strength of
their shared representations. Code:
https://github.com/mollahsabbir/Semantic-Drift-in-Unified-Models

</details>


### [66] [From Lines to Shapes: Geometric-Constrained Segmentation of X-Ray Collimators via Hough Transform](https://arxiv.org/abs/2509.04437)
*Benjamin El-Zein,Dominik Eckert,Andreas Fieselmann,Christopher Syben,Ludwig Ritschl,Steffen Kappler,Sebastian Stober*

Main category: cs.CV

TL;DR: 通过结合霍夫变换和深度学习，提出了一种新的方法来检测X射线图像中的准直器阴影，即使在边缘模糊的情况下也能提高准确性。


<details>
  <summary>Details</summary>
Motivation: X射线成像中的准直对于限制曝光于感兴趣区域（ROI）和最小化患者辐射剂量至关重要，然而，散射X射线辐射可能导致准直器边缘的检测具有挑战性。

Method: 提出了一种深度学习模型，该模型集成了可微霍夫变换，用于检测准直器边界并提取ROI中心信息。在推理过程中，结合了这两个任务的信息来生成精炼的、受线条约束的分割掩模。

Result: 该方法在真实X射线图像的多个测试集上实现了4.3-5.0mm的中位豪斯多夫距离，稳健地重建了准直区域，并且不受限于特定数量的边缘。

Conclusion: 提出的基于深度学习和霍夫变换的方法能够准确地分割X射线图像中的准直区域，即使在存在散射辐射导致边缘模糊的情况下也能有效工作。

Abstract: Collimation in X-ray imaging restricts exposure to the region-of-interest
(ROI) and minimizes the radiation dose applied to the patient. The detection of
collimator shadows is an essential image-based preprocessing step in digital
radiography posing a challenge when edges get obscured by scattered X-ray
radiation. Regardless, the prior knowledge that collimation forms
polygonal-shaped shadows is evident. For this reason, we introduce a deep
learning-based segmentation that is inherently constrained to its geometry. We
achieve this by incorporating a differentiable Hough transform-based network to
detect the collimation borders and enhance its capability to extract the
information about the ROI center. During inference, we combine the information
of both tasks to enable the generation of refined, line-constrained
segmentation masks. We demonstrate robust reconstruction of collimated regions
achieving median Hausdorff distances of 4.3-5.0mm on diverse test sets of real
Xray images. While this application involves at most four shadow borders, our
method is not fundamentally limited by a specific number of edges.

</details>


### [67] [One Flight Over the Gap: A Survey from Perspective to Panoramic Vision](https://arxiv.org/abs/2509.04444)
*Xin Lin,Xian Ge,Dizhe Zhang,Zhaoliang Wan,Xianshun Wang,Xiangtai Li,Wenjie Jiang,Bo Du,Dacheng Tao,Ming-Hsuan Yang,Lu Qi*

Main category: cs.CV

TL;DR: 全景图像（ODIs）因其完整的360度视野在虚拟现实、自动驾驶和机器人等领域受到关注，但其几何投影、空间分布和边界连续性与透视图像存在显著差异，给直接域适应带来挑战。本综述重点关注从透视到全景的域适应技术，分析了全景成像流程和投影方法，指出了极点附近的几何畸变、等距柱状投影（ERP）中的非均匀采样以及周期性边界连续性这三大挑战。文章涵盖了20多个代表性任务，对解决全景特定挑战的策略进行了跨方法分析，并将全景视觉分为视觉质量增强与评估、视觉理解、多模态理解和视觉生成四大类。此外，还讨论了数据、模型和应用方面的开放性挑战与未来方向。


<details>
  <summary>Details</summary>
Motivation: 全景图像（ODIs）因其完整的360度视野在虚拟现实、自动驾驶和机器人等领域受到关注，但其几何投影、空间分布和边界连续性与透视图像存在显著差异，给直接域适应带来挑战。

Method: 本综述重点关注从透视到全景的域适应技术，分析了全景成像流程和投影方法，指出了极点附近的几何畸变、等距柱状投影（ERP）中的非均匀采样以及周期性边界连续性这三大挑战。文章涵盖了20多个代表性任务，对解决全景特定挑战的策略进行了跨方法分析，并将全景视觉分为视觉质量增强与评估、视觉理解、多模态理解和视觉生成四大类。

Result: 本综述涵盖了20多个代表性任务，对解决全景特定挑战的策略进行了跨方法分析，并将全景视觉分为视觉质量增强与评估、视觉理解、多模态理解和视觉生成四大类。

Conclusion: 本文讨论了全景视觉领域的数据、模型和应用方面的开放性挑战与未来方向，旨在为全景视觉技术的发展提供新的见解和前瞻性视角。

Abstract: Driven by the demand for spatial intelligence and holistic scene perception,
omnidirectional images (ODIs), which provide a complete 360\textdegree{} field
of view, are receiving growing attention across diverse applications such as
virtual reality, autonomous driving, and embodied robotics. Despite their
unique characteristics, ODIs exhibit remarkable differences from perspective
images in geometric projection, spatial distribution, and boundary continuity,
making it challenging for direct domain adaption from perspective methods. This
survey reviews recent panoramic vision techniques with a particular emphasis on
the perspective-to-panorama adaptation. We first revisit the panoramic imaging
pipeline and projection methods to build the prior knowledge required for
analyzing the structural disparities. Then, we summarize three challenges of
domain adaptation: severe geometric distortions near the poles, non-uniform
sampling in Equirectangular Projection (ERP), and periodic boundary continuity.
Building on this, we cover 20+ representative tasks drawn from more than 300
research papers in two dimensions. On one hand, we present a cross-method
analysis of representative strategies for addressing panoramic specific
challenges across different tasks. On the other hand, we conduct a cross-task
comparison and classify panoramic vision into four major categories: visual
quality enhancement and assessment, visual understanding, multimodal
understanding, and visual generation. In addition, we discuss open challenges
and future directions in data, models, and applications that will drive the
advancement of panoramic vision research. We hope that our work can provide new
insight and forward looking perspectives to advance the development of
panoramic vision technologies. Our project page is
https://insta360-research-team.github.io/Survey-of-Panorama

</details>


### [68] [Plot'n Polish: Zero-shot Story Visualization and Disentangled Editing with Text-to-Image Diffusion Models](https://arxiv.org/abs/2509.04446)
*Kiymet Akdemir,Jing Shi,Kushal Kafle,Brian Price,Pinar Yanardag*

Main category: cs.CV

TL;DR: Plot'n Polish 是一个零样本框架，可以对故事可视化进行一致的生成和细粒度控制，以解决现有方法在保持多帧视觉和叙事一致性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像生成模型在故事可视化方面虽有潜力，但在保持多帧视觉和叙事一致性的同时进行精细或粗粒度编辑方面缺乏灵活性，阻碍了创作者的无缝创作和优化视觉故事。

Method: 提出了一种名为 Plot'n Polish 的零样本框架，用于实现一致的故事生成，并在不同细节级别上对故事可视化进行细粒度控制。

Result: 该框架能够进行一致的故事生成，并提供对故事可视化的细粒度控制。

Conclusion: Plot'n Polish 框架通过提供一致的故事生成和细粒度控制，解决了现有文本到图像生成模型在故事可视化方面存在的挑战，使创作者能够更无缝地进行视觉故事的创作和优化。

Abstract: Text-to-image diffusion models have demonstrated significant capabilities to
generate diverse and detailed visuals in various domains, and story
visualization is emerging as a particularly promising application. However, as
their use in real-world creative domains increases, the need for providing
enhanced control, refinement, and the ability to modify images post-generation
in a consistent manner becomes an important challenge. Existing methods often
lack the flexibility to apply fine or coarse edits while maintaining visual and
narrative consistency across multiple frames, preventing creators from
seamlessly crafting and refining their visual stories. To address these
challenges, we introduce Plot'n Polish, a zero-shot framework that enables
consistent story generation and provides fine-grained control over story
visualizations at various levels of detail.

</details>


### [69] [TRUST-VL: An Explainable News Assistant for General Multimodal Misinformation Detection](https://arxiv.org/abs/2509.04448)
*Zehong Yan,Peng Qi,Wynne Hsu,Mong Li Lee*

Main category: cs.CV

TL;DR: 生成式AI加剧了多模态虚假信息的传播，现有方法难以泛化。本文提出的TRUST-VL模型通过联合训练不同类型的虚假信息，并引入问题感知视觉放大器模块，提高了检测性能和泛化能力。同时，构建了包含198K样本的TRUST-Instruct数据集以支持模型训练。


<details>
  <summary>Details</summary>
Motivation: 生成式AI加剧了多模态虚假信息的传播，现有方法通常只关注单一类型的失真，难以泛化到未知的场景。

Method: 提出TRUST-VL，一个统一且可解释的视觉-语言模型，用于通用的多模态虚假信息检测。TRUST-VL包含新颖的问答感知视觉放大器模块，用于提取特定任务的视觉特征。构建了包含198K样本的TRUST-Instruct数据集，支持模型训练。

Result: 在领域内和零样本基准测试中，TRUST-VL取得了最先进的性能，并表现出强大的泛化能力和可解释性。

Conclusion: TRUST-VL通过联合训练和问题感知视觉放大器模块，有效解决了多模态虚假信息检测的挑战，并在性能、泛化性和可解释性方面取得了显著成果。

Abstract: Multimodal misinformation, encompassing textual, visual, and cross-modal
distortions, poses an increasing societal threat that is amplified by
generative AI. Existing methods typically focus on a single type of distortion
and struggle to generalize to unseen scenarios. In this work, we observe that
different distortion types share common reasoning capabilities while also
requiring task-specific skills. We hypothesize that joint training across
distortion types facilitates knowledge sharing and enhances the model's ability
to generalize. To this end, we introduce TRUST-VL, a unified and explainable
vision-language model for general multimodal misinformation detection. TRUST-VL
incorporates a novel Question-Aware Visual Amplifier module, designed to
extract task-specific visual features. To support training, we also construct
TRUST-Instruct, a large-scale instruction dataset containing 198K samples
featuring structured reasoning chains aligned with human fact-checking
workflows. Extensive experiments on both in-domain and zero-shot benchmarks
demonstrate that TRUST-VL achieves state-of-the-art performance, while also
offering strong generalization and interpretability.

</details>


### [70] [Virtual Fitting Room: Generating Arbitrarily Long Videos of Virtual Try-On from a Single Image -- Technical Preview](https://arxiv.org/abs/2509.04450)
*Jun-Kun Chen,Aayush Bansal,Minh Phuoc Vo,Yu-Xiong Wang*

Main category: cs.CV

TL;DR: VFR是一个新颖的视频生成模型，可以生成任意长度的虚拟试穿视频，通过分段自回归生成解决了长视频生成中的局部平滑和全局时间一致性问题。


<details>
  <summary>Details</summary>
Motivation: 生成任意长度的虚拟试穿视频，解决现有方法在长视频生成中的资源消耗和数据限制问题。

Method: 将长视频生成视为分段自回归过程，利用前缀视频条件保证片段间的局部平滑性，并使用锚定视频（360度全身外观视频）来维护全局时间一致性。

Result: 生成了具有局部平滑性和全局时间一致性的分钟级虚拟试穿视频，能够处理各种运动场景。

Conclusion: VFR在长虚拟试穿视频生成领域是开创性的工作。

Abstract: We introduce the Virtual Fitting Room (VFR), a novel video generative model
that produces arbitrarily long virtual try-on videos. Our VFR models long video
generation tasks as an auto-regressive, segment-by-segment generation process,
eliminating the need for resource-intensive generation and lengthy video data,
while providing the flexibility to generate videos of arbitrary length. The key
challenges of this task are twofold: ensuring local smoothness between adjacent
segments and maintaining global temporal consistency across different segments.
To address these challenges, we propose our VFR framework, which ensures
smoothness through a prefix video condition and enforces consistency with the
anchor video -- a 360-degree video that comprehensively captures the human's
wholebody appearance. Our VFR generates minute-scale virtual try-on videos with
both local smoothness and global temporal consistency under various motions,
making it a pioneering work in long virtual try-on video generation.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [71] [Speech-Based Cognitive Screening: A Systematic Evaluation of LLM Adaptation Strategies](https://arxiv.org/abs/2509.03525)
*Fatemeh Taherinezhad,Mohamad Javad Momeni Nezhad,Sepehr Karimi,Sina Rashidi,Ali Zolnour,Maryam Dadkhah,Yasaman Haghbin,Hossein AzadMaleki,Maryam Zolnoori*

Main category: cs.CL

TL;DR: 大型语言模型在痴呆症语音筛查中的适应性策略研究


<details>
  <summary>Details</summary>
Motivation: 美国过半阿尔茨海默病及相关痴呆症患者未被诊断，语音筛查是一种可行的检测方法。

Method: 研究了九种纯文本模型和三种多模态音频-文本模型在痴呆症语音语料库上的适应策略，包括不同演示选择策略的上下文学习、推理增强提示、参数高效微调以及多模态集成。

Result: 类中心演示在上下文学习中表现最佳，推理能提升小型模型性能，令牌级微调通常得分最高。增加分类头能显著改善表现不佳的模型。多模态模型表现良好，但未超过顶尖的纯文本模型。

Conclusion: 模型适应策略（包括演示选择、推理设计和调优方法）对语音痴呆症检测至关重要，并且适当适应的开放权重模型可以媲美甚至超越商业系统。

Abstract: Over half of US adults with Alzheimer disease and related dementias remain
undiagnosed, and speech-based screening offers a scalable detection approach.
We compared large language model adaptation strategies for dementia detection
using the DementiaBank speech corpus, evaluating nine text-only models and
three multimodal audio-text models on recordings from DementiaBank speech
corpus. Adaptations included in-context learning with different demonstration
selection policies, reasoning-augmented prompting, parameter-efficient
fine-tuning, and multimodal integration. Results showed that class-centroid
demonstrations achieved the highest in-context learning performance, reasoning
improved smaller models, and token-level fine-tuning generally produced the
best scores. Adding a classification head substantially improved
underperforming models. Among multimodal models, fine-tuned audio-text systems
performed well but did not surpass the top text-only models. These findings
highlight that model adaptation strategies, including demonstration selection,
reasoning design, and tuning method, critically influence speech-based dementia
detection, and that properly adapted open-weight models can match or exceed
commercial systems.

</details>


### [72] [Explicit and Implicit Data Augmentation for Social Event Detection](https://arxiv.org/abs/2509.04202)
*Congbo Ma,Yuxia Wang,Jia Wu,Jian Yang,Jing Du,Zitai Qiu,Qing Li,Hu Wang,Preslav Nakov*

Main category: cs.CL

TL;DR: 提出一个名为SED-Aug的双重增强框架，用于社会活动检测，以解决标注数据成本高昂的问题。该框架结合了显式文本增强和隐式特征空间增强，以提高数据多样性和模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 社会活动检测需要标注数据，但标注成本高昂且耗时。

Method: SED-Aug框架：1. 显式增强：利用大型语言模型通过五种生成策略增强文本信息。2. 隐式增强：设计五种新的扰动技术，在结构融合嵌入的特征空间上操作，保持嵌入的语义和关系属性并增加多样性。

Result: SED-Aug在Twitter2012和Twitter2018数据集上，平均F1分数分别比最佳基线模型高出约17.67%和15.57%。

Conclusion: SED-Aug框架通过结合显式文本增强和隐式特征空间增强，有效提高了社会活动检测的性能，解决了标注数据稀缺和成本高的问题。

Abstract: Social event detection involves identifying and categorizing important events
from social media, which relies on labeled data, but annotation is costly and
labor-intensive. To address this problem, we propose Augmentation framework for
Social Event Detection (SED-Aug), a plug-and-play dual augmentation framework,
which combines explicit text-based and implicit feature-space augmentation to
enhance data diversity and model robustness. The explicit augmentation utilizes
large language models to enhance textual information through five diverse
generation strategies. For implicit augmentation, we design five novel
perturbation techniques that operate in the feature space on structural fused
embeddings. These perturbations are crafted to keep the semantic and relational
properties of the embeddings and make them more diverse. Specifically, SED-Aug
outperforms the best baseline model by approximately 17.67% on the Twitter2012
dataset and by about 15.57% on the Twitter2018 dataset in terms of the average
F1 score. The code is available at GitHub: https://github.com/congboma/SED-Aug.

</details>


### [73] [Enhancing Speech Large Language Models through Reinforced Behavior Alignment](https://arxiv.org/abs/2509.03526)
*Yansong Liu,Jiateng Li,Yuan Liu*

Main category: cs.CL

TL;DR: 通过强化学习和自生成数据来提高语音大模型的指令遵循能力。


<details>
  <summary>Details</summary>
Motivation: 由于跨模态差异，语音大模型在指令遵循方面与文本大模型相比存在显著的性能差距，尤其是在处理动态和多变的语音输入时。

Method: 提出了一种称为强化行为对齐（RBA）的框架，该框架利用强大的教师大模型通过自合成方法生成大量高保真对齐数据，然后使用基于强化学习的方法将语音大模型的行为与其教师对齐。

Result: 实验结果表明，该方法有效提升了语音大模型的指令遵循能力，优于传统的蒸馏基线，并可无缝扩展到语音问答和语音到文本翻译等任务，仅使用自生成数据即可在公开基准上达到最先进的性能。

Conclusion: RBA框架能够有效提升语音大模型的指令遵循能力，并且具有良好的泛化性和扩展性，能够显著提升在多模态任务上的表现。

Abstract: The recent advancements of Large Language Models (LLMs) have spurred
considerable research interest in extending their linguistic capabilities
beyond text to other modalities, which leads to emergence of speech-based LLMs
(SpeechLMs) with capability of processing user request in either speech or
textual formats. However, owing to inter-modal discrepancies, these SpeechLMs
still exhibit a significant performance gap compared to their text-based LLM
counterparts in instruction-following, particularly when confronted with the
dynamic and variable nature of user speech. To address this challenge, this
paper introduces a framework termed Reinforced Behavior Alignment (RBA),
designed to bolster the language generation proficiency of SpeechLMs. Instead
of relying on supervised fine-tuning from human annotations, RBA employs a
self-synthesis methodology to generate extensive, high-fidelity alignment data
by a powerful teacher LLM. Then SpeechLMs is aligned its behavior with that of
a teacher using a reinforcement learning-based approach. Experimental results
demonstrate that this method effectively enhances the instruction-following
capabilities of SpeechLMs that outperform conventional distillation baselines.
Crucially, we demonstrate that RBA can be seamlessly extended to tasks such
including spoken question answering and speech-to-text translation, attaining
state-of-the-art performance on open benchmarks with only self-generated data.

</details>


### [74] [Multilevel Analysis of Cryptocurrency News using RAG Approach with Fine-Tuned Mistral Large Language Model](https://arxiv.org/abs/2509.03527)
*Bohdan M. Pavlyshenko*

Main category: cs.CL

TL;DR: 该论文使用经过微调并结合检索增强生成（RAG）技术的Mistral 7B大型语言模型，对加密货币新闻进行多层次多任务分析。该模型能生成包含情感得分的图表和文本摘要，以及摘要的JSON表示。更高级别的分析通过分层聚合图表和文本摘要，以及对摘要的摘要，最终生成全面的报告。通过将加密货币新闻表示为知识图谱，可以有效解决大型语言模型出现的幻觉问题。实验结果表明，该方法能够进行信息丰富的定性和定量分析，提供重要的见解。


<details>
  <summary>Details</summary>
Motivation: 加密货币新闻的多层次、多任务分析，旨在解决大型语言模型在处理这类信息时可能出现的幻觉问题，并提供定性和定量的分析。

Method: 使用经过4位量化和PEFT/LoRA微调的Mistral 7B大型语言模型，结合检索增强生成（RAG）技术。首先，模型生成包含情感得分的图表和文本摘要，以及摘要的JSON表示。然后，通过分层聚合这些摘要（包括对摘要的摘要），生成最终的综合报告。将新闻表示为知识图谱以减少幻觉。

Result: 所提出的方法能够进行信息丰富的定性和定量分析，提供重要的见解，证明了微调后的Mistral 7B LLM模型在多层次加密货币新闻分析中的有效性。

Conclusion: 该研究成功展示了利用微调的Mistral 7B LLM模型和RAG技术进行多层次加密货币新闻分析的可行性，能够生成有价值的定性和定量见解，并有效缓解了模型幻觉问题。

Abstract: In the paper, we consider multilevel multitask analysis of cryptocurrency
news using a fine-tuned Mistral 7B large language model with
retrieval-augmented generation (RAG).
  On the first level of analytics, the fine-tuned model generates graph and
text summaries with sentiment scores as well as JSON representations of
summaries. Higher levels perform hierarchical stacking that consolidates sets
of graph-based and text-based summaries as well as summaries of summaries into
comprehensive reports. The combination of graph and text summaries provides
complementary views of cryptocurrency news. The model is fine-tuned with 4-bit
quantization using the PEFT/LoRA approach. The representation of cryptocurrency
news as knowledge graph can essentially eliminate problems with large language
model hallucinations.
  The obtained results demonstrate that the use of fine-tuned Mistral 7B LLM
models for multilevel cryptocurrency news analysis can conduct informative
qualitative and quantitative analytics, providing important insights.

</details>


### [75] [The ProLiFIC dataset: Leveraging LLMs to Unveil the Italian Lawmaking Process](https://arxiv.org/abs/2509.03528)
*Matilde Contestabile,Chiara Ferrara,Alberto Giovannetti,Giovanni Parrillo,Andrea Vandin*

Main category: cs.CL

TL;DR: Process Mining (PM) 结合大型语言模型 (LLM) 来分析意大利的立法过程，并发布了一个名为 ProLiFIC 的新数据集，作为法律 PM 的基准。


<details>
  <summary>Details</summary>
Motivation: 为工业和商业领域开发的流程挖掘 (PM) 技术在法律领域的应用受到数据集的可及性和质量的限制。因此，有必要创建一个专门针对法律领域的数据集。

Method: 通过使用大型语言模型 (LLM) 从意大利立法过程（1987-2022）的非结构化数据（来自 Normattiva 门户）创建了一个名为 ProLiFIC 的综合事件日志。

Result: ProLiFIC 数据集已经创建，并进行了初步分析，展示了其作为法律 PM 基准的潜力。

Conclusion: ProLiFIC 为法律流程挖掘提供了一个宝贵的资源，并有望推动该领域的发展。

Abstract: Process Mining (PM), initially developed for industrial and business
contexts, has recently been applied to social systems, including legal ones.
However, PM's efficacy in the legal domain is limited by the accessibility and
quality of datasets. We introduce ProLiFIC (Procedural Lawmaking Flow in
Italian Chambers), a comprehensive event log of the Italian lawmaking process
from 1987 to 2022. Created from unstructured data from the Normattiva portal
and structured using large language models (LLMs), ProLiFIC aligns with recent
efforts in integrating PM with LLMs. We exemplify preliminary analyses and
propose ProLiFIC as a benchmark for legal PM, fostering new developments.

</details>


### [76] [Multimodal Proposal for an AI-Based Tool to Increase Cross-Assessment of Messages](https://arxiv.org/abs/2509.03529)
*Alejandro Álvarez Castro,Joaquín Ordieres-Meré*

Main category: cs.CL

TL;DR: 本论文提出了一个新颖的多模态框架，通过将财报电话会议编码为分层话语树来生成语义丰富且结构感知的嵌入，该框架结合了文本、音频和视频的情感信号以及诸如连贯性分数、主题标签和答案覆盖率评估等结构化元数据。


<details>
  <summary>Details</summary>
Motivation: 现有的金融情感分析系统大多依赖于扁平的文档级或句子级模型，未能捕捉财报电话会议这种富含信息且半结构化的互动中层级话语结构的特点。

Method: 提出了一种两阶段的 Transformer 架构：第一阶段使用对比学习在节点级别编码多模态内容和话语元数据，第二阶段为整个会议合成全局嵌入。

Result: 实验结果表明，所生成的嵌入形成了稳定、有意义的语义表示，能够反映情感基调、结构逻辑和主题一致性。

Conclusion: 该框架不仅能为金融报告提供实用工具，如金融预测和话语评估，而且还能推广到医疗、教育和政治对话等其他高风险非结构化交流领域，提供一种鲁棒且可解释的多模态话语表示方法。

Abstract: Earnings calls represent a uniquely rich and semi-structured source of
financial communication, blending scripted managerial commentary with
unscripted analyst dialogue. Although recent advances in financial sentiment
analysis have integrated multi-modal signals, such as textual content and vocal
tone, most systems rely on flat document-level or sentence-level models,
failing to capture the layered discourse structure of these interactions. This
paper introduces a novel multi-modal framework designed to generate
semantically rich and structurally aware embeddings of earnings calls, by
encoding them as hierarchical discourse trees. Each node, comprising either a
monologue or a question-answer pair, is enriched with emotional signals derived
from text, audio, and video, as well as structured metadata including coherence
scores, topic labels, and answer coverage assessments. A two-stage transformer
architecture is proposed: the first encodes multi-modal content and discourse
metadata at the node level using contrastive learning, while the second
synthesizes a global embedding for the entire conference. Experimental results
reveal that the resulting embeddings form stable, semantically meaningful
representations that reflect affective tone, structural logic, and thematic
alignment. Beyond financial reporting, the proposed system generalizes to other
high-stakes unscripted communicative domains such as tele-medicine, education,
and political discourse, offering a robust and explainable approach to
multi-modal discourse representation. This approach offers practical utility
for downstream tasks such as financial forecasting and discourse evaluation,
while also providing a generalizable method applicable to other domains
involving high-stakes communication.

</details>


### [77] [Reading Between the Signs: Predicting Future Suicidal Ideation from Adolescent Social Media Texts](https://arxiv.org/abs/2509.03530)
*Paul Blum,Enrico Liscio,Ruixuan Zhang,Caroline Figueroa,Pradeep K. Murukannaiah*

Main category: cs.CL

TL;DR: 该研究提出了一种新的方法来预测青少年自杀意念和行为（SIB），通过分析其在论坛上的帖子，即使在他们明确表达自杀意念之前。


<details>
  <summary>Details</summary>
Motivation: 许多青少年自杀案例因未被及时发现而未能得到干预，因为他们没有寻求心理健康服务。社交媒体为实时捕捉青少年在线表达的挣扎提供了一个独特的机会。

Method: 提出了一种名为Early-SIB的新型模型，该模型基于Transformer架构，能够顺序处理用户在论坛上发布的帖子以及与之互动的帖子，以预测其是否会发布包含SIB内容的帖子。

Result: 该模型在荷兰青少年论坛的数据集上进行了测试，预测未来SIB的平衡准确率达到了0.73。

Conclusion: 研究结果表明，通过分析用户在论坛上的帖子，即使在明确表达自杀意念之前，也可以预测青少年未来的SIB。这种基于社交媒体分析的方法可以作为传统预测方法的有益补充。

Abstract: Suicide is a leading cause of death among adolescents (12-18), yet predicting
it remains a significant challenge. Many cases go undetected due to a lack of
contact with mental health services. Social media, however, offers a unique
opportunity, as young people often share their thoughts and struggles online in
real time. In this work, we propose a novel task and method to approach it:
predicting suicidal ideation and behavior (SIB) from forum posts before an
adolescent explicitly expresses suicidal ideation on an online forum. This
predictive framing, where no self-disclosure is used as input at any stage,
remains largely unexplored in the suicide prediction literature. To this end,
we introduce Early-SIB, a transformer-based model that sequentially processes
the posts a user writes and engages with to predict whether they will write a
SIB post. Our model achieves a balanced accuracy of 0.73 for predicting future
SIB on a Dutch youth forum, demonstrating that such tools can offer a
meaningful addition to traditional methods.

</details>


### [78] [Real-Time Detection of Hallucinated Entities in Long-Form Generation](https://arxiv.org/abs/2509.03531)
*Oscar Obeso,Andy Arditi,Javier Ferrando,Joshua Freeman,Cameron Holmes,Neel Nanda*

Main category: cs.CL

TL;DR: 我们提出了一种新颖、经济高效且可扩展的方法，用于在长篇文本生成中实时识别幻觉标记。该方法专注于实体级幻觉（例如，虚构的姓名、日期、引用），并使用基于网络搜索的注释数据集来训练简单的分类器。实验证明，该方法在各种模型家族的长期和短期问答设置中均优于现有基线，甚至在数学推理等任务中也表现出泛化能力。我们还公开了数据集以促进重用，为可扩展的、现实世界的幻觉检测提供了一条有前景的新途径。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型幻觉检测方法不适用于现实世界的应用，因为它们要么局限于简短的事实查询，要么需要昂贵的外部验证。本文旨在解决这一问题，提供一种经济高效、可扩展的方法，用于在长篇生成中实时检测幻觉。

Method: 该方法通过识别长篇文本生成中的实体级幻觉（例如，虚构的姓名、日期、引用）来检测幻觉标记。使用基于网络搜索的注释方法来创建数据集，其中模型响应被标记为对应于虚构实体的标记。然后，使用这些数据集来训练简单的分类器，例如线性探测器。

Result: 所提出的分类器在四个模型家族的长期响应上持续优于基线方法，包括更昂贵的语义熵方法（例如，Llama-3.3-70B 的 AUC 为 0.90，而基线为 0.71）。在短期问答设置中，这些分类器也有所改进。此外，尽管仅使用实体级标签进行训练，但这些探测器有效地检测了数学推理任务中的错误答案，表明其具有超越实体的泛化能力。

Conclusion: 这项工作提出了一个有前景的新方法，用于可扩展的、现实世界的幻觉检测。该方法能够实时识别长篇文本生成中的幻觉标记，并且在各种设置下都表现出优越的性能和泛化能力。公开的数据集将有助于未来的研究和应用。

Abstract: Large language models are now routinely used in high-stakes applications
where hallucinations can cause serious harm, such as medical consultations or
legal advice. Existing hallucination detection methods, however, are
impractical for real-world use, as they are either limited to short factual
queries or require costly external verification. We present a cheap, scalable
method for real-time identification of hallucinated tokens in long-form
generations, and scale it effectively to 70B parameter models. Our approach
targets \emph{entity-level hallucinations} -- e.g., fabricated names, dates,
citations -- rather than claim-level, thereby naturally mapping to token-level
labels and enabling streaming detection. We develop an annotation methodology
that leverages web search to annotate model responses with grounded labels
indicating which tokens correspond to fabricated entities. This dataset enables
us to train effective hallucination classifiers with simple and efficient
methods such as linear probes. Evaluating across four model families, our
classifiers consistently outperform baselines on long-form responses, including
more expensive methods such as semantic entropy (e.g., AUC 0.90 vs 0.71 for
Llama-3.3-70B), and are also an improvement in short-form question-answering
settings. Moreover, despite being trained only with entity-level labels, our
probes effectively detect incorrect answers in mathematical reasoning tasks,
indicating generalization beyond entities. While our annotation methodology is
expensive, we find that annotated responses from one model can be used to train
effective classifiers on other models; accordingly, we publicly release our
datasets to facilitate reuse. Overall, our work suggests a promising new
approach for scalable, real-world hallucination detection.

</details>


### [79] [Topic Identification in LLM Input-Output Pairs through the Lens of Information Bottleneck](https://arxiv.org/abs/2509.03533)
*Igor Halperin*

Main category: cs.CL

TL;DR: LLM的幻觉检测框架SDM依赖于句子嵌入的几何聚类来识别主题，但这与下游信息论分析不匹配。本文提出UDIB，一种基于确定性信息瓶颈（DIB）的聚类方法，通过使用DIB的计算上可行的上界来解决这个问题。UDIB可以被看作是K-means的熵正则化和鲁棒化版本，它能够识别信息丰富的聚类。将UDIB应用于LLM提示和响应嵌入的联合聚类，可以生成最大化地关于提示-响应关系的信息共享主题表示，从而改进SDM框架，更有效地检测幻觉。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM幻觉检测方法（如SDM）依赖于句子嵌入的几何聚类来识别主题，但这种方法将主题优化为空间上的邻近性，而不是信息论分析的下游需求，从而导致了潜在的性能问题。

Method: 本文提出了一种基于确定性信息瓶颈（DIB）的原则性主题识别方法，并将其转化为一种适用于高维数据的实用算法UDIB。UDIB通过用计算上可行的上界替换DIB中难以处理的KL散度项来实现。该方法可以被解释为K-means的一种熵正则化和鲁棒化版本，能够识别出信息丰富的聚类，并倾向于生成数量有限的聚类。

Result: 将UDIB应用于LLM提示和响应嵌入的联合聚类，生成了一种共享的主题表示，这种表示不仅在空间上是一致的，而且在根本上是为最大化地提供关于提示-响应关系的信息而构建的。

Conclusion: UDIB为SDM框架提供了一个更优越的基础，并为检测LLM的虚假陈述（confabulations）提供了一种新颖且更敏感的工具。

Abstract: Large Language Models (LLMs) are prone to critical failure modes, including
\textit{intrinsic faithfulness hallucinations} (also known as confabulations),
where a response deviates semantically from the provided context. Frameworks
designed to detect this, such as Semantic Divergence Metrics (SDM), rely on
identifying latent topics shared between prompts and responses, typically by
applying geometric clustering to their sentence embeddings. This creates a
disconnect, as the topics are optimized for spatial proximity, not for the
downstream information-theoretic analysis. In this paper, we bridge this gap by
developing a principled topic identification method grounded in the
Deterministic Information Bottleneck (DIB) for geometric clustering. Our key
contribution is to transform the DIB method into a practical algorithm for
high-dimensional data by substituting its intractable KL divergence term with a
computationally efficient upper bound. The resulting method, which we dub UDIB,
can be interpreted as an entropy-regularized and robustified version of K-means
that inherently favors a parsimonious number of informative clusters. By
applying UDIB to the joint clustering of LLM prompt and response embeddings, we
generate a shared topic representation that is not merely spatially coherent
but is fundamentally structured to be maximally informative about the
prompt-response relationship. This provides a superior foundation for the SDM
framework and offers a novel, more sensitive tool for detecting confabulations.

</details>


### [80] [QuesGenie: Intelligent Multimodal Question Generation](https://arxiv.org/abs/2509.03535)
*Ahmed Mubarak,Amna Ahmed,Amira Nasser,Aya Mohamed,Fares El-Sadek,Mohammed Ahmed,Ahmed Salah,Youssef Sobhy*

Main category: cs.CL

TL;DR: A system is developed to generate practice questions from educational resources, using multi-modal input and RLHF for diverse question types and an interactive interface.


<details>
  <summary>Details</summary>
Motivation: The lack of practice materials tailored to abundant educational resources is a significant challenge for learners.

Method: The system consists of four components: multi-modal input handling, question generation, reinforcement learning from human feedback (RLHF), and an end-to-end interactive interface.

Result: The system automatically generates diverse question types from various content formats, balancing resource efficiency, functionality, and user experience.

Conclusion: This project establishes a foundation for automated, scalable, and intelligent question generation.

Abstract: In today's information-rich era, learners have access to abundant educational
resources, but the lack of practice materials tailored to these resources
presents a significant challenge. This project addresses that gap by developing
a multi-modal question generation system that can automatically generate
diverse question types from various content formats. The system features four
major components: multi-modal input handling, question generation,
reinforcement learning from human feedback (RLHF), and an end-to-end
interactive interface. This project lays the foundation for automated,
scalable, and intelligent question generation, carefully balancing resource
efficiency, robust functionality and a smooth user experience.

</details>


### [81] [AR$^2$: Adversarial Reinforcement Learning for Abstract Reasoning in Large Language Models](https://arxiv.org/abs/2509.03537)
*Cheng-Kai Yeh,Hsing-Wang Lee,Chung-Hung Kuo,Hen-Hsen Huang*

Main category: cs.CL

TL;DR: AR^2是一个通过教师模型将简单问题转化为复杂叙述性问题，并训练学生模型解决这些问题的框架，以提升LLM的抽象推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有针对代码生成的RL方法主要关注表面模式识别，忽略了对抽象能力的显式训练，而抽象能力对人类和LLM解决计算机科学问题至关重要。

Method: AR^2框架使用一个教师模型将核心问题转化为具有丰富叙述但逻辑不变的挑战性描述。同时，训练一个学生代码模型，使其能够通过提取底层计算核心来解决这些复杂的叙述性问题。

Result: AR^2显著提高了学生模型在解决未见过且具有挑战性的编程任务时的准确性。

Conclusion: 抽象能力是提升LLM泛化能力的关键技能。

Abstract: Abstraction--the ability to recognize and distill essential computational
patterns from complex problem statements--is a foundational skill in computer
science, critical both for human problem-solvers and coding-oriented large
language models (LLMs). Despite recent advances in training LLMs for code
generation using reinforcement learning (RL), most existing approaches focus
primarily on superficial pattern recognition, overlooking explicit training for
abstraction. In this study, we propose AR$^2$ (Adversarial Reinforcement
Learning for Abstract Reasoning), a novel framework explicitly designed to
enhance the abstraction abilities of LLMs. AR$^2$ employs a teacher model to
transform kernel problems into narrative-rich, challenging descriptions without
changing their fundamental logic. Simultaneously, a student coding model is
trained to solve these complex narrative problems by extracting their
underlying computational kernels. Experimental results demonstrate that AR$^2$
substantially improves the student model's accuracy on previously unseen,
challenging programming tasks, underscoring abstraction as a key skill for
enhancing LLM generalization.

</details>


### [82] [Improving Factuality in LLMs via Inference-Time Knowledge Graph Construction](https://arxiv.org/abs/2509.03540)
*Shanglin Wu,Lihui Liu,Jinho D. Choi,Kai Shu*

Main category: cs.CL

TL;DR: LLMs易出错，RAG方法可用外部知识，但处理非结构化文本能力有限。本文提出一种动态构建和扩展知识图谱（KG）的框架，结合LLM内部知识和外部检索信息，以提高LLM的事实准确性、答案精确度和可解释性。


<details>
  <summary>Details</summary>
Motivation: LLMs在生成事实一致性答案方面存在挑战，因为其参数记忆有限。现有的RAG方法将知识视为非结构化文本，限制了组合推理和事实不一致性识别能力。

Method: 提出一个新框架，在推理时动态构建和扩展知识图谱（KG）。首先通过提示从问题中提取种子KG，然后利用LLM的潜在知识进行迭代扩展，最后通过外部检索进行选择性优化，以增强事实覆盖和纠正不准确之处。

Result: 在三个不同的事实问答基准上进行了评估，与基线提示和静态KG增强方法相比，在事实准确性、答案精确度和可解释性方面均取得了一致性改进。

Conclusion: 推理时构建KG是提高LLM事实性的一种有前景的方向，具有结构化、可解释和可扩展的优点。

Abstract: Large Language Models (LLMs) often struggle with producing factually
consistent answers due to limitations in their parametric memory.
Retrieval-Augmented Generation (RAG) methods address this issue by
incorporating external knowledge from trusted sources at inference time.
However, such methods typically treat knowledge as unstructured text, which
limits their ability to support compositional reasoning and identify factual
inconsistencies. To overcome these limitations, we propose a novel framework
that dynamically constructs and expands knowledge graphs (KGs) during
inference, integrating both internal knowledge extracted from LLMs and external
information retrieved from external sources. Our method begins by extracting a
seed KG from the question via prompting, followed by iterative expansion using
the LLM's latent knowledge. The graph is then selectively refined through
external retrieval, enhancing factual coverage and correcting inaccuracies. We
evaluate our approach on three diverse factual QA benchmarks, demonstrating
consistent improvements in factual accuracy, answer precision, and
interpretability over baseline prompting and static KG-augmented methods. Our
findings suggest that inference-time KG construction is a promising direction
for enhancing LLM factuality in a structured, interpretable, and scalable
manner.

</details>


### [83] [ResearchPulse: Building Method-Experiment Chains through Multi-Document Scientific Inference](https://arxiv.org/abs/2509.03565)
*Qi Chen,Jingxuan Wei,Zhuoya Yao,Haiguang Wang,Gaowei Wu,Bihui Yu,Siyuan Li,Cheng Tan*

Main category: cs.CL

TL;DR: 该论文提出了一种名为 ResearchPulse 的新框架，用于分析多篇相关论文，以重建研究发展链。


<details>
  <summary>Details</summary>
Motivation: 理解科学思想的演变需要跨文档的推理，而不仅仅是总结单篇论文。

Method: ResearchPulse 框架包含三个代理：计划代理、Mmap-Agent 和 Lchart-Agent，用于任务分解、构建动机-方法思维导图和综合实验折线图。该框架还引入了 ResearchPulse-Bench 基准测试集。

Result: 实验表明，ResearchPulse 框架在语义对齐、结构一致性和视觉保真度方面优于 GPT-4o。

Conclusion: ResearchPulse 框架能够有效地进行多文档科学推理，重建研究发展链。

Abstract: Understanding how scientific ideas evolve requires more than summarizing
individual papers-it demands structured, cross-document reasoning over
thematically related research. In this work, we formalize multi-document
scientific inference, a new task that extracts and aligns motivation,
methodology, and experimental results across related papers to reconstruct
research development chains. This task introduces key challenges, including
temporally aligning loosely structured methods and standardizing heterogeneous
experimental tables. We present ResearchPulse, an agent-based framework that
integrates instruction planning, scientific content extraction, and structured
visualization. It consists of three coordinated agents: a Plan Agent for task
decomposition, a Mmap-Agent that constructs motivation-method mind maps, and a
Lchart-Agent that synthesizes experimental line charts. To support this task,
we introduce ResearchPulse-Bench, a citation-aware benchmark of annotated paper
clusters. Experiments show that our system, despite using 7B-scale agents,
consistently outperforms strong baselines like GPT-4o in semantic alignment,
structural consistency, and visual fidelity. The dataset are available in
https://huggingface.co/datasets/ResearchPulse/ResearchPulse-Bench.

</details>


### [84] [NoteBar: An AI-Assisted Note-Taking System for Personal Knowledge Management](https://arxiv.org/abs/2509.03610)
*Josh Wisoff,Yao Tang,Zhengyu Fang,Jordan Guzman,YuTang Wang,Alex Yu*

Main category: cs.CL

TL;DR: NoteBar是一款AI辅助笔记工具，可根据用户个性化信息自动组织笔记，并提供了一个新的数据集以支持研究。


<details>
  <summary>Details</summary>
Motivation: 现有AI笔记工具效率低下，需要更优化的解决方案。

Method: 提出NoteBar工具，利用个性化信息和高效语言模型自动组织笔记；构建了一个包含3173条笔记和8494个概念的、覆盖16种MBTI个性化类型的数据集。

Result: NoteBar能够以经济高效的方式进行部署，支持交互式使用，无需重型基础设施。

Conclusion: NoteBar及其数据集为AI辅助个人知识管理提供了可扩展、可扩展的基础。

Abstract: Note-taking is a critical practice for capturing, organizing, and reflecting
on information in both academic and professional settings. The recent success
of large language models has accelerated the development of AI-assisted tools,
yet existing solutions often struggle with efficiency. We present NoteBar, an
AI-assisted note-taking tool that leverages persona information and efficient
language models to automatically organize notes into multiple categories and
better support user workflows. To support research and evaluation in this
space, we further introduce a novel persona-conditioned dataset of 3,173 notes
and 8,494 annotated concepts across 16 MBTI personas, offering both diversity
and semantic richness for downstream tasks. Finally, we demonstrate that
NoteBar can be deployed in a practical and cost-effective manner, enabling
interactive use without reliance on heavy infrastructure. Together, NoteBar and
its accompanying dataset provide a scalable and extensible foundation for
advancing AI-assisted personal knowledge management.

</details>


### [85] [E-ARMOR: Edge case Assessment and Review of Multilingual Optical Character Recognition](https://arxiv.org/abs/2509.03615)
*Aryan Gupta,Anupam Purwar*

Main category: cs.CL

TL;DR: 在多语言、嘈杂和多样化的真实世界图像中进行光学字符识别（OCR）仍然是一个重大挑战。尽管大型视觉语言模型（LVLM）在OCR领域展现出潜力，但对于资源受限的边缘部署而言，传统OCR系统在效率和成本方面仍然具有优势。本研究提出了一种名为Sprinklr-Edge-OCR的新型OCR系统，并与五种先进的LVLM和两种传统OCR系统在包含54种语言的大规模数据集上进行了全面比较评估。评估指标涵盖准确性、语义一致性、语言覆盖范围、计算效率（延迟、内存、GPU使用率）和部署成本。实验结果表明，Qwen在精确率方面表现最佳（0.54），而Sprinklr-Edge-OCR在F1分数（0.46）和效率方面均优于其他模型，其图像处理速度比LVLM快35倍，成本仅为LVLM的1/1000。研究结论指出，在LLM时代，传统的OCR系统因其低计算需求、低延迟和高性价比，仍然是边缘部署的最优选择。


<details>
  <summary>Details</summary>
Motivation: 随着大型视觉语言模型（LVLM）的兴起，人们对其在光学字符识别（OCR）领域的泛化和推理能力产生了浓厚兴趣。然而，在资源受限的边缘环境中部署OCR系统仍面临挑战。本研究旨在评估不同OCR系统（包括LVLM和传统OCR）在真实世界多语言、嘈杂图像上的性能，并特别关注其在边缘部署的效率和成本效益。

Method: 本研究提出了一种名为Sprinklr-Edge-OCR的新型OCR系统，并针对边缘部署进行了优化。研究人员在一个包含54种语言的大规模、经过双重人工标注的数据集上，对五种先进的LVLM（InternVL, Qwen, GOT OCR, LLaMA, MiniCPM）和两种传统OCR系统（Sprinklr-Edge-OCR, SuryaOCR）进行了比较评估。评估指标包括准确性、语义一致性、语言覆盖范围、计算效率（延迟、内存、GPU使用率）和部署成本。此外，还进行了在仅CPU环境下的边缘案例部署分析。

Result: 在准确性方面，Qwen取得了最高的精确率（0.54）。然而，Sprinklr-Edge-OCR在整体F1分数上表现最佳（0.46）。在效率方面，Sprinklr-Edge-OCR表现突出，其图像处理速度平均为0.17秒/图像，比LVLM快35倍。同时，其部署成本极低，仅为0.006美元/1000图像，是LVLM的1/1000。在CPU环境下，传统OCR系统也展现了更优的性能。

Conclusion: 研究结果表明，尽管大型语言模型在OCR领域取得了进展，但对于资源受限的边缘部署场景，传统的OCR系统（如Sprinklr-Edge-OCR）仍然是最优选择。这是因为传统系统具有低计算需求、低延迟和极高的成本效益，这些优势在实际的边缘部署中尤为重要。

Abstract: Optical Character Recognition (OCR) in multilingual, noisy, and diverse
real-world images remains a significant challenge for optical character
recognition systems. With the rise of Large Vision-Language Models (LVLMs),
there is growing interest in their ability to generalize and reason beyond
fixed OCR pipelines. In this work, we introduce Sprinklr-Edge-OCR, a novel OCR
system built specifically optimized for edge deployment in resource-constrained
environments. We present a large-scale comparative evaluation of five
state-of-the-art LVLMs (InternVL, Qwen, GOT OCR, LLaMA, MiniCPM) and two
traditional OCR systems (Sprinklr-Edge-OCR, SuryaOCR) on a proprietary, doubly
hand annotated dataset of multilingual (54 languages) images. Our benchmark
covers a broad range of metrics including accuracy, semantic consistency,
language coverage, computational efficiency (latency, memory, GPU usage), and
deployment cost. To better reflect real-world applicability, we also conducted
edge case deployment analysis, evaluating model performance on CPU only
environments. Among the results, Qwen achieved the highest precision (0.54),
while Sprinklr-Edge-OCR delivered the best overall F1 score (0.46) and
outperformed others in efficiency, processing images 35 faster (0.17 seconds
per image on average) and at less than 0.01 of the cost (0.006 USD per 1,000
images) compared to LVLM. Our findings demonstrate that the most optimal OCR
systems for edge deployment are the traditional ones even in the era of LLMs
due to their low compute requirements, low latency, and very high
affordability.

</details>


### [86] [Breaking the Mirror: Activation-Based Mitigation of Self-Preference in LLM Evaluators](https://arxiv.org/abs/2509.03647)
*Dani Roytburg,Matthew Bozoukov,Matthew Nguyen,Jou Barzdukas,Simon Fu,Narmeen Oozeer*

Main category: cs.CL

TL;DR: LLM评判自身输出存在偏见，可通过轻量级“控制向量”在推理时缓解，但存在不稳定性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）作为自动化评判者时，存在“自我偏好偏差”，即倾向于偏袒自身输出，这会影响公平性和可靠性，尤其是在偏好调整和模型路由等任务中。

Method: 研究使用轻量级控制向量在推理时缓解自我偏好偏差，而不需重新训练。构建了一个区分“合理自我偏好”和“不合理自我偏好”的策展数据集，并使用对比激活加法（CAA）和基于优化的方法构建控制向量。

Result: 控制向量可将不合理的自我偏好偏差降低高达97%，效果优于提示和直接偏好优化基线。但控制向量在处理合理的自我偏好和无偏见同意时存在不稳定性，表明自我偏好可能涉及多个或非线性方向。

Conclusion: 控制向量在缓解LLM评判中的自我偏好偏差方面显示出潜力，但其不稳定性也暴露了其局限性，需要更鲁棒的干预措施。

Abstract: Large language models (LLMs) increasingly serve as automated evaluators, yet
they suffer from "self-preference bias": a tendency to favor their own outputs
over those of other models. This bias undermines fairness and reliability in
evaluation pipelines, particularly for tasks like preference tuning and model
routing. We investigate whether lightweight steering vectors can mitigate this
problem at inference time without retraining. We introduce a curated dataset
that distinguishes self-preference bias into justified examples of
self-preference and unjustified examples of self-preference, and we construct
steering vectors using two methods: Contrastive Activation Addition (CAA) and
an optimization-based approach. Our results show that steering vectors can
reduce unjustified self-preference bias by up to 97\%, substantially
outperforming prompting and direct preference optimization baselines. Yet
steering vectors are unstable on legitimate self-preference and unbiased
agreement, implying self-preference spans multiple or nonlinear directions.
This underscores both their promise and limits as safeguards for LLM-as-judges
and motivates more robust interventions.

</details>


### [87] [Semantic Analysis of SNOMED CT Concept Co-occurrences in Clinical Documentation using MIMIC-IV](https://arxiv.org/abs/2509.03662)
*Ali Noori,Somya Mohanty,Prashanti Manda*

Main category: cs.CL

TL;DR: 临床笔记中的非结构化文本和标准化术语（如SNOMED CT）之间的关系，使用MIMIC-IV数据库，通过NPMI和预训练嵌入（ClinicalBERT, BioBERT）来研究概念共现模式与嵌入式语义相似性。


<details>
  <summary>Details</summary>
Motivation: 为了解决临床笔记的非结构化格式带来的大规模分析挑战，并深入理解SNOMED CT概念之间的共现和语义相似性。

Method: 使用MIMIC-IV数据库，结合NPMI和预训练嵌入（ClinicalBERT, BioBERT）来分析SNOMED CT概念的共现模式和语义相似性。

Result: 共现和语义相似性弱相关，但嵌入能捕捉到文档频率未体现的临床关联；嵌入式建议能匹配后续记录的概念；概念嵌入的聚类产生了与患者表型和护理模式相符的临床主题；共现模式与死亡率和再入院率等结局相关。

Conclusion: 共现统计和语义嵌入可以互补，以提高文档的完整性，揭示潜在的临床关系，并为决策支持和表型分析应用提供信息。

Abstract: Clinical notes contain rich clinical narratives but their unstructured format
poses challenges for large-scale analysis. Standardized terminologies such as
SNOMED CT improve interoperability, yet understanding how concepts relate
through co-occurrence and semantic similarity remains underexplored. In this
study, we leverage the MIMIC-IV database to investigate the relationship
between SNOMED CT concept co-occurrence patterns and embedding-based semantic
similarity. Using Normalized Pointwise Mutual Information (NPMI) and pretrained
embeddings (e.g., ClinicalBERT, BioBERT), we examine whether frequently
co-occurring concepts are also semantically close, whether embeddings can
suggest missing concepts, and how these relationships evolve temporally and
across specialties. Our analyses reveal that while co-occurrence and semantic
similarity are weakly correlated, embeddings capture clinically meaningful
associations not always reflected in documentation frequency. Embedding-based
suggestions frequently matched concepts later documented, supporting their
utility for augmenting clinical annotations. Clustering of concept embeddings
yielded coherent clinical themes (symptoms, labs, diagnoses, cardiovascular
conditions) that map to patient phenotypes and care patterns. Finally,
co-occurrence patterns linked to outcomes such as mortality and readmission
demonstrate the practical utility of this approach. Collectively, our findings
highlight the complementary value of co-occurrence statistics and semantic
embeddings in improving documentation completeness, uncovering latent clinical
relationships, and informing decision support and phenotyping applications.

</details>


### [88] [MLSD: A Novel Few-Shot Learning Approach to Enhance Cross-Target and Cross-Domain Stance Detection](https://arxiv.org/abs/2509.03725)
*Parush Gera,Tempestt Neal*

Main category: cs.CL

TL;DR: MLSD是一种基于度量学习的少样本学习方法，用于跨目标和跨领域的立场检测，通过三元组损失增强领域适应性，并在多个场景下显著提高了立场检测性能。


<details>
  <summary>Details</summary>
Motivation: 提出一种新颖的跨领域和跨目标的立场检测方法，以适应新的目标领域。

Method: 使用度量学习和三元组损失来捕捉立场目标的语义相似性和差异性，构建判别性嵌入空间，以实现跨目标或跨领域的立场检测。

Result: 在多个跨目标和跨领域场景下的两个数据集上进行了评估，显示出在六种广泛使用的立场检测模型上的统计学显著的性能提升。

Conclusion: MLSD方法能够有效地进行跨目标和跨领域的立场检测，通过度量学习增强了模型在新目标领域的适应性。

Abstract: We present the novel approach for stance detection across domains and
targets, Metric Learning-Based Few-Shot Learning for Cross-Target and
Cross-Domain Stance Detection (MLSD). MLSD utilizes metric learning with
triplet loss to capture semantic similarities and differences between stance
targets, enhancing domain adaptation. By constructing a discriminative
embedding space, MLSD allows a cross-target or cross-domain stance detection
model to acquire useful examples from new target domains. We evaluate MLSD in
multiple cross-target and cross-domain scenarios across two datasets, showing
statistically significant improvement in stance detection performance across
six widely used stance detection models.

</details>


### [89] [SiLVERScore: Semantically-Aware Embeddings for Sign Language Generation Evaluation](https://arxiv.org/abs/2509.03791)
*Saki Imai,Mert İnan,Anthony Sicilia,Malihe Alikhani*

Main category: cs.CL

TL;DR: 提出了一个名为SiLVERScore的新评估指标，用于评估手语生成，它克服了现有基于文本回译方法的局限性，能够更好地捕捉手语的多模态特性，并在实验中表现出优越的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的手语生成评估方法（基于文本回译）存在局限性，无法捕捉手语的多模态特性（如面部表情、空间语法、韵律），并且难以区分是生成模型还是翻译系统导致评估错误。

Method: 提出了一种名为SiLVERScore的新型语义感知嵌入式评估指标，在联合嵌入空间中评估手语生成。

Result: SiLVERScore在PHOENIX-14T和CSL-Daily数据集上，能够近乎完美地区分正确和随机配对（ROC AUC = 0.99，重叠度 < 7%），显著优于传统指标。

Conclusion: SiLVERScore是一种有效的、语义感知的评估指标，能够克服现有方法的局限性，并能处理语义和韵律的变化，同时还能探索跨数据集的泛化挑战。

Abstract: Evaluating sign language generation is often done through back-translation,
where generated signs are first recognized back to text and then compared to a
reference using text-based metrics. However, this two-step evaluation pipeline
introduces ambiguity: it not only fails to capture the multimodal nature of
sign language-such as facial expressions, spatial grammar, and prosody-but also
makes it hard to pinpoint whether evaluation errors come from sign generation
model or the translation system used to assess it. In this work, we propose
SiLVERScore, a novel semantically-aware embedding-based evaluation metric that
assesses sign language generation in a joint embedding space. Our contributions
include: (1) identifying limitations of existing metrics, (2) introducing
SiLVERScore for semantically-aware evaluation, (3) demonstrating its robustness
to semantic and prosodic variations, and (4) exploring generalization
challenges across datasets. On PHOENIX-14T and CSL-Daily datasets, SiLVERScore
achieves near-perfect discrimination between correct and random pairs (ROC AUC
= 0.99, overlap < 7%), substantially outperforming traditional metrics.

</details>


### [90] [Measuring How (Not Just Whether) VLMs Build Common Ground](https://arxiv.org/abs/2509.03805)
*Saki Imai,Mert İnan,Anthony Sicilia,Malihe Alikhani*

Main category: cs.CL

TL;DR: VLMs的推理能力可以通过交互式基础评估，目前的基准测试不足以全面评估。


<details>
  <summary>Details</summary>
Motivation: 评估大型视觉语言模型（VLMs）在交互式基础任务中的表现，因为现有基准测试未能充分捕捉其推理能力。

Method: 提出一个新的四指标评估套件（基础效率、内容一致性、词汇适应性和人性化），并将其应用于150场VLMs与人类之间的交互式指代游戏，以系统地评估VLM性能。

Result: 在150场比赛中，所有三个VLM在至少三个指标上都与人类模式存在差异，其中GPT-4o-mini总体上最接近人类。研究发现，任务成功率并不能完全代表基础的成功，并且高图像-话语一致性并不一定能预测任务成功。

Conclusion: 现有的VLM在交互式基础任务中的表现与人类存在差距，需要更精细的评估方法来衡量其真正的基础能力。

Abstract: Large vision language models (VLMs) increasingly claim reasoning skills, yet
current benchmarks evaluate them in single-turn or question answering settings.
However, grounding is an interactive process in which people gradually develop
shared understanding through ongoing communication. We introduce a four-metric
suite (grounding efficiency, content alignment, lexical adaptation, and
human-likeness) to systematically evaluate VLM performance in interactive
grounding contexts. We deploy the suite on 150 self-play sessions of
interactive referential games between three proprietary VLMs and compare them
with human dyads. All three models diverge from human patterns on at least
three metrics, while GPT4o-mini is the closest overall. We find that (i) task
success scores do not indicate successful grounding and (ii) high
image-utterance alignment does not necessarily predict task success. Our metric
suite and findings offer a framework for future research on VLM grounding.

</details>


### [91] [Align-then-Slide: A complete evaluation framework for Ultra-Long Document-Level Machine Translation](https://arxiv.org/abs/2509.03809)
*Jiaxin Guo,Daimeng Wei,Yuanchang Luo,Xiaoyu Chen,Zhanglin Wu,Huan Yang,Hengchao Shang,Zongyao Li,Zhiqiang Rao,Jinlong Yang,Hao Yang*

Main category: cs.CL

TL;DR: Align-then-Slide是一个用于评估超长文档机器翻译的完整框架，通过自动对齐源句和目标句，并采用n-chunk滑动评估方法，能够准确、稳健地评估文档级翻译质量，并能用于训练和改进翻译模型。


<details>
  <summary>Details</summary>
Motivation: 现有的评估方法假设逐句对齐，无法适应LLMs生成的整个文档的输出，因此需要新的评估方法来解决超长文档机器翻译的评估问题。

Method: Align-then-Slide框架包含两个主要阶段：1. Align阶段：自动推断句子级源-目标对应关系，并重建目标句以匹配源句数量，解决遗漏和多对一/一对多映射问题。2. n-Chunk Sliding Evaluate阶段：在1、2、3和4个chunk下计算平均指标得分，进行多粒度评估。

Result: 在WMT基准测试中，Align-then-Slide方法与专家MQM排名具有0.929的皮尔逊相关性。在新的真实世界测试集上，该方法也与人类判断高度一致。此外，Align-then-Slide生成的偏好数据可用于有效的CPO训练，并作为GRPO的奖励模型，显著优于SFT基线模型。

Conclusion: Align-then-Slide框架能够准确、稳健且可操作地评估文档级机器翻译系统，并能有效用于模型训练和改进。

Abstract: Large language models (LLMs) have ushered in a new era for document-level
machine translation (\textit{doc}-mt), yet their whole-document outputs
challenge existing evaluation methods that assume sentence-by-sentence
alignment. We introduce \textit{\textbf{Align-then-Slide}}, a complete
evaluation framework for ultra-long doc-mt. In the Align stage, we
automatically infer sentence-level source-target correspondences and rebuild
the target to match the source sentence number, resolving omissions and
many-to-one/one-to-many mappings. In the n-Chunk Sliding Evaluate stage, we
calculate averaged metric scores under 1-, 2-, 3- and 4-chunk for
multi-granularity assessment. Experiments on the WMT benchmark show a Pearson
correlation of 0.929 between our method with expert MQM rankings. On a newly
curated real-world test set, our method again aligns closely with human
judgments. Furthermore, preference data produced by Align-then-Slide enables
effective CPO training and its direct use as a reward model for GRPO, both
yielding translations preferred over a vanilla SFT baseline. The results
validate our framework as an accurate, robust, and actionable evaluation tool
for doc-mt systems.

</details>


### [92] [NE-PADD: Leveraging Named Entity Knowledge for Robust Partial Audio Deepfake Detection via Attention Aggregation](https://arxiv.org/abs/2509.03829)
*Huhong Xian,Rui Liu,Berrak Sisman,Haizhou Li*

Main category: cs.CL

TL;DR: 提出了一种名为NE-PADD的新方法，用于部分音频深度伪造检测（PADD），该方法利用命名实体知识来提高检测帧级伪造语音位置的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的部分音频深度伪造检测（PADD）方法主要集中在句子级别，并且在利用音频的语义信息（尤其是命名实体）方面存在不足。

Method: NE-PADD方法包含两个并行分支：语音命名实体识别（SpeechNER）和PADD。该方法还引入了两种注意力聚合机制：注意力融合（AF）用于合并注意力权重，以及注意力转移（AT）通过辅助损失引导PADD利用命名实体语义。

Result: 在PartialSpoof-NER数据集上进行的实验表明，NE-PADD方法优于现有的基线方法。

Conclusion: 将命名实体知识集成到PADD中是有效的，能够提升检测性能。

Abstract: Different from traditional sentence-level audio deepfake detection (ADD),
partial audio deepfake detection (PADD) requires frame-level positioning of the
location of fake speech. While some progress has been made in this area,
leveraging semantic information from audio, especially named entities, remains
an underexplored aspect. To this end, we propose NE-PADD, a novel method for
Partial Audio Deepfake Detection (PADD) that leverages named entity knowledge
through two parallel branches: Speech Name Entity Recognition (SpeechNER) and
PADD. The approach incorporates two attention aggregation mechanisms: Attention
Fusion (AF) for combining attention weights and Attention Transfer (AT) for
guiding PADD with named entity semantics using an auxiliary loss. Built on the
PartialSpoof-NER dataset, experiments show our method outperforms existing
baselines, proving the effectiveness of integrating named entity knowledge in
PADD. The code is available at https://github.com/AI-S2-Lab/NE-PADD.

</details>


### [93] [Drivel-ology: Challenging LLMs with Interpreting Nonsense with Depth](https://arxiv.org/abs/2509.03867)
*Yang Wang,Chenghao Xiao,Chia-Yi Hsiao,Zi Yan Chang,Chi-Li Chen,Tyler Loakman,Chenghua Lin*

Main category: cs.CL

TL;DR: Drivelology是一种“有深度的胡言乱语”，现有的大语言模型（LLMs）在理解这种语言现象时存在显著困难。


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型在理解具有潜在含义的“有深度的胡言乱语”（Drivelology）方面的局限性。

Method: 构建了一个包含1200多个例子的Drivelology基准数据集，涵盖多种语言，并评估了不同大语言模型在分类、生成和推理任务上的表现。

Result: 结果表明，大语言模型常常混淆Drivelology和浅层无意义内容，生成不合逻辑的解释，或完全忽略其隐含的修辞功能。

Conclusion: 大语言模型在语用理解方面存在深层表征鸿沟，其流畅性不代表认知理解能力，需要进一步研究以超越表面连贯性来模拟语言深度。

Abstract: We introduce Drivelology, a unique linguistic phenomenon characterised as
"nonsense with depth", utterances that are syntactically coherent yet
pragmatically paradoxical, emotionally loaded, or rhetorically subversive.
While such expressions may resemble surface-level nonsense, they encode
implicit meaning requiring contextual inference, moral reasoning, or emotional
interpretation. We find that current large language models (LLMs), despite
excelling at many natural language processing (NLP) tasks, consistently fail to
grasp the layered semantics of Drivelological text. To investigate this, we
construct a small but diverse benchmark dataset of over 1,200 meticulously
curated examples, with select instances in English, Mandarin, Spanish, French,
Japanese, and Korean. Annotation was especially challenging: each of the
examples required careful expert review to verify that it truly reflected
Drivelological characteristics. The process involved multiple rounds of
discussion and adjudication to address disagreements, highlighting the subtle
and subjective nature of the Drivelology. We evaluate a range of LLMs on
classification, generation, and reasoning tasks. Our results reveal clear
limitations of LLMs: models often confuse Drivelology with shallow nonsense,
produce incoherent justifications, or miss the implied rhetorical function
altogether. These findings highlight a deeper representational gap in LLMs'
pragmatic understanding and challenge the assumption that statistical fluency
implies cognitive comprehension. We release our dataset and code to facilitate
further research in modelling linguistic depth beyond surface-level coherence.

</details>


### [94] [A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models](https://arxiv.org/abs/2509.03871)
*Yanbo Wang,Yongcan Yu,Jian Liang,Ran He*

Main category: cs.CL

TL;DR: CoT推理提升了LLM在多任务上的表现，但其对模型可信度的影响尚不明确。本文综述了CoT推理在真理性、安全性、鲁棒性、公平性和隐私性五个维度上的研究进展，并指出了当前推理模型自身在安全、鲁棒性和隐私方面存在的潜在风险。


<details>
  <summary>Details</summary>
Motivation: 评估CoT推理技术在提升语言模型可信度方面的作用，并识别现有推理模型在安全性、鲁棒性和隐私性方面面临的挑战。

Method: 对CoT推理和相关研究进行综述，重点关注真理性、安全性、鲁棒性、公平性和隐私性五个维度，并按时间顺序分析研究方法、发现和局限性。

Result: CoT推理技术在减少幻觉、检测有害内容和提高鲁棒性方面有潜力提升模型可信度，但现有的推理模型在安全性、鲁棒性和隐私性方面可能存在更严重的漏洞。

Conclusion: 尽管CoT推理技术在提升模型可信度方面展现出巨大潜力，但需要关注并解决其自身在安全性、鲁棒性和隐私性方面的新出现的挑战。本研究为AI安全社区提供了关于推理可信度最新进展的宝贵参考。

Abstract: The development of Long-CoT reasoning has advanced LLM performance across
various tasks, including language understanding, complex problem solving, and
code generation. This paradigm enables models to generate intermediate
reasoning steps, thereby improving both accuracy and interpretability. However,
despite these advancements, a comprehensive understanding of how CoT-based
reasoning affects the trustworthiness of language models remains
underdeveloped. In this paper, we survey recent work on reasoning models and
CoT techniques, focusing on five core dimensions of trustworthy reasoning:
truthfulness, safety, robustness, fairness, and privacy. For each aspect, we
provide a clear and structured overview of recent studies in chronological
order, along with detailed analyses of their methodologies, findings, and
limitations. Future research directions are also appended at the end for
reference and discussion. Overall, while reasoning techniques hold promise for
enhancing model trustworthiness through hallucination mitigation, harmful
content detection, and robustness improvement, cutting-edge reasoning models
themselves often suffer from comparable or even greater vulnerabilities in
safety, robustness, and privacy. By synthesizing these insights, we hope this
work serves as a valuable and timely resource for the AI safety community to
stay informed on the latest progress in reasoning trustworthiness. A full list
of related papers can be found at
\href{https://github.com/ybwang119/Awesome-reasoning-safety}{https://github.com/ybwang119/Awesome-reasoning-safety}.

</details>


### [95] [False Sense of Security: Why Probing-based Malicious Input Detection Fails to Generalize](https://arxiv.org/abs/2509.03888)
*Cheng Wang,Zeming Wei,Qin Liu,Muhao Chen*

Main category: cs.CL

TL;DR: 探针方法在检测大型语言模型（LLM）的恶意指令方面表现不佳，因为它们学习的是表面模式而非语义上的有害性。


<details>
  <summary>Details</summary>
Motivation: 尽管 LLMs 能力令人印象深刻，但它们可能遵从有害指令，这引发了严重的安全担忧。现有研究利用探针方法研究恶意和良性输入在 LLMs 内部表示的可分离性，并提出将其用于安全检测。本研究旨在系统地重新审视这一范式。

Method: 通过控制实验，研究人员首先证明了简单的 n-gram 方法可以达到相当的性能，然后使用语义清理的数据集进行控制实验，最后详细分析了模式依赖性，以确认探针学习的是表面模式（如指令模式和触发词）而非语义上的有害性。

Result: 研究结果表明，探针方法学习的是诸如指令模式和触发词之类的表面模式，而不是语义上的有害性。简单的 n-gram 方法可以实现相当的性能，并且在语义清理的数据集上，探针的性能会显著下降，这表明它们学习到的模式是肤浅的。

Conclusion: 当前的探针方法未能提供可靠的安全保障，它们学习到的模式是肤浅的，容易被规避。因此，需要重新设计 LLMs 和评估协议，以实现更有效的安全检测。

Abstract: Large Language Models (LLMs) can comply with harmful instructions, raising
serious safety concerns despite their impressive capabilities. Recent work has
leveraged probing-based approaches to study the separability of malicious and
benign inputs in LLMs' internal representations, and researchers have proposed
using such probing methods for safety detection. We systematically re-examine
this paradigm. Motivated by poor out-of-distribution performance, we
hypothesize that probes learn superficial patterns rather than semantic
harmfulness. Through controlled experiments, we confirm this hypothesis and
identify the specific patterns learned: instructional patterns and trigger
words. Our investigation follows a systematic approach, progressing from
demonstrating comparable performance of simple n-gram methods, to controlled
experiments with semantically cleaned datasets, to detailed analysis of pattern
dependencies. These results reveal a false sense of security around current
probing-based approaches and highlight the need to redesign both models and
evaluation protocols, for which we provide further discussions in the hope of
suggesting responsible further research in this direction. We have open-sourced
the project at https://github.com/WangCheng0116/Why-Probe-Fails.

</details>


### [96] [MobileRAG: Enhancing Mobile Agent with Retrieval-Augmented Generation](https://arxiv.org/abs/2509.03891)
*Gowen Loo,Chang Liu,Qinghong Yin,Xiang Chen,Jiawei Chen,Jingyuan Zhang,Yu Tian*

Main category: cs.CL

TL;DR: MobileRAG是一个增强了检索增强生成（RAG）能力的移动代理框架，旨在解决现有移动代理在理解、环境交互和记忆方面的局限性。该框架通过InterRAG、LocalRAG和MemRAG利用RAG技术，提高了查询解析和复杂任务完成的准确性和效率。此外，引入了MobileRAG-Eval基准测试，以更全面地评估其性能。实验证明，MobileRAG在处理现实世界任务时表现优于现有最先进的方法，操作步骤更少。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型（LLM）的移动代理存在过度依赖LLM理解能力导致错误、缺乏与外部环境交互能力以及缺乏记忆功能（无法从错误中学习和纠正）等问题。

Method: 提出MobileRAG框架，该框架通过检索增强生成（RAG）技术进行增强，包括InterRAG、LocalRAG和MemRAG。该框架利用RAG技术来更快、更准确地识别用户查询并完成复杂和长序列的移动任务。此外，还引入了MobileRAG-Eval基准测试。

Result: 在MobileRAG-Eval基准测试上的大量实验结果表明，MobileRAG能够轻松处理现实世界的移动任务，相比现有最先进的方法，性能提高了10.3%，并且操作步骤更少。

Conclusion: MobileRAG框架通过集成RAG技术，有效解决了现有移动代理的局限性，提高了在复杂移动任务中的性能和效率，并在引入的MobileRAG-Eval基准测试中取得了显著的改进。

Abstract: Smartphones have become indispensable in people's daily lives, permeating
nearly every aspect of modern society. With the continuous advancement of large
language models (LLMs), numerous LLM-based mobile agents have emerged. These
agents are capable of accurately parsing diverse user queries and automatically
assisting users in completing complex or repetitive operations. However,
current agents 1) heavily rely on the comprehension ability of LLMs, which can
lead to errors caused by misoperations or omitted steps during tasks, 2) lack
interaction with the external environment, often terminating tasks when an app
cannot fulfill user queries, and 3) lack memory capabilities, requiring each
instruction to reconstruct the interface and being unable to learn from and
correct previous mistakes. To alleviate the above issues, we propose MobileRAG,
a mobile agents framework enhanced by Retrieval-Augmented Generation (RAG),
which includes InterRAG, LocalRAG, and MemRAG. It leverages RAG to more quickly
and accurately identify user queries and accomplish complex and long-sequence
mobile tasks. Additionally, to more comprehensively assess the performance of
MobileRAG, we introduce MobileRAG-Eval, a more challenging benchmark
characterized by numerous complex, real-world mobile tasks that require
external knowledge assistance. Extensive experimental results on MobileRAG-Eval
demonstrate that MobileRAG can easily handle real-world mobile tasks, achieving
10.3\% improvement over state-of-the-art methods with fewer operational steps.
Our code is publicly available at:
https://github.com/liuxiaojieOutOfWorld/MobileRAG_arxiv

</details>


### [97] [MTQA:Matrix of Thought for Enhanced Reasoning in Complex Question Answering](https://arxiv.org/abs/2509.03918)
*Fengxiao Tang,Yufeng Li,Zongzong Wu,Ming Zhao*

Main category: cs.CL

TL;DR: Matrix of Thought (MoT) 是一种新的思维结构，通过“列-单元格通信”机制探索问题的横向和纵向维度，以增强大语言模型（LLMs）在复杂问答（QA）任务中的推理能力。它还引入了一个事实纠正机制，通过结合知识图谱和原始文本来提高准确性。实验结果表明，MTQA框架在四个数据集上优于现有方法，并且推理时间仅为基线方法的14.4%。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLMs）在处理复杂和抽象的问答（QA）任务时，由于推理能力不足，性能会显著下降。像Chain-of-Thought（CoT）和Tree-of-Thought（ToT）这样的方法虽然旨在增强LLMs的推理能力，但存在冗余和路径单一的问题。此外，虽然检索增强生成（RAG）方法可以辅助LLMs进行推理，但如何有效利用涉及多实体和多跳的信息仍然是一个挑战。

Method: 提出了一种名为Matrix of Thought (MoT) 的新颖高效的LLM思维结构。MoT通过“列-单元格通信”机制，在横向和纵向两个维度上探索问题，使LLMs能够积极地进行多策略、深层次的思考，减少列单元格内的冗余，从而增强推理能力。此外，还开发了一个事实纠正机制，通过构建来自检索到的知识图谱三元组和原始文本的知识单元，来增强LLM推理的初始知识并纠正错误的答案。这形成了一个高效准确的问答框架（MTQA）。

Result: 实验结果表明，MTQA框架在四个广泛使用的数据集上，在F1和EM分数方面均优于最先进的方法。同时，其推理时间仅为基线方法的14.4%，证明了其在效率和准确性方面的优势。

Conclusion: Matrix of Thought (MoT) 框架通过其新颖的思维结构和事实纠正机制，显著提高了LLMs在复杂问答任务中的推理能力和准确性，并在效率上取得了显著的提升。

Abstract: Complex Question Answering (QA) is a fundamental and challenging task in NLP.
While large language models (LLMs) exhibit impressive performance in QA, they
suffer from significant performance degradation when facing complex and
abstract QA tasks due to insufficient reasoning capabilities. Works such as
Chain-of-Thought (CoT) and Tree-of-Thought (ToT) aim to enhance LLMs' reasoning
abilities, but they face issues such as in-layer redundancy in tree structures
and single paths in chain structures. Although some studies utilize
Retrieval-Augmented Generation (RAG) methods to assist LLMs in reasoning, the
challenge of effectively utilizing large amounts of information involving
multiple entities and hops remains critical. To address this, we propose the
Matrix of Thought (MoT), a novel and efficient LLM thought structure. MoT
explores the problem in both horizontal and vertical dimensions through the
"column-cell communication" mechanism, enabling LLMs to actively engage in
multi-strategy and deep-level thinking, reducing redundancy within the column
cells and enhancing reasoning capabilities. Furthermore, we develop a
fact-correction mechanism by constructing knowledge units from retrieved
knowledge graph triples and raw text to enhance the initial knowledge for LLM
reasoning and correct erroneous answers. This leads to the development of an
efficient and accurate QA framework (MTQA). Experimental results show that our
framework outperforms state-of-the-art methods on four widely-used datasets in
terms of F1 and EM scores, with reasoning time only 14.4\% of the baseline
methods, demonstrating both its efficiency and accuracy. The code for this
framework is available at https://github.com/lyfiter/mtqa.

</details>


### [98] [Decoding the Poetic Language of Emotion in Korean Modern Poetry: Insights from a Human-Labeled Dataset and AI Modeling](https://arxiv.org/abs/2509.03932)
*Iro Lim,Haein Ji,Byungjun Kim*

Main category: cs.CL

TL;DR: 该研究提出了KPoEM，一个用于现代韩语诗歌计算情感分析的新数据集，通过多标签分类解决了诗歌中比喻性语言和文化特异性的挑战，并显著提高了情感分析的准确性。


<details>
  <summary>Details</summary>
Motivation: 韩语诗歌由于其比喻语言和文化特异性，在计算情感分析领域仍未得到充分探索，而这对于理解和量化其情感表达至关重要。

Method: 构建了一个包含7662个条目的多标签情感数据集，涵盖了483首诗歌的7007行和615个作品级别条目，并使用44个细粒度情感类别进行了标注。在此基础上，对一个先进的韩语语言模型进行了微调。

Result: 在KPoEM数据集上微调的先进韩语语言模型在情感分析任务上取得了0.60的F1-micro分数，显著优于在通用语料库上训练的模型（0.34）。通过顺序微调（先在通用语料库，后在KPoEM数据集上），模型不仅提高了识别时空和文化特定情感表达的能力，还保留了现代韩语诗歌的核心情感。

Conclusion: KPoEM数据集和训练模型为计算方法与文学分析的结合提供了新的途径，通过包含情感和文化细微差别的结构化数据，为量化探索诗歌情感开辟了新的可能性。

Abstract: This study introduces KPoEM (Korean Poetry Emotion Mapping) , a novel dataset
for computational emotion analysis in modern Korean poetry. Despite remarkable
progress in text-based emotion classification using large language models,
poetry-particularly Korean poetry-remains underexplored due to its figurative
language and cultural specificity. We built a multi-label emotion dataset of
7,662 entries, including 7,007 line-level entries from 483 poems and 615
work-level entries, annotated with 44 fine-grained emotion categories from five
influential Korean poets. A state-of-the-art Korean language model fine-tuned
on this dataset significantly outperformed previous models, achieving 0.60
F1-micro compared to 0.34 from models trained on general corpora. The KPoEM
model, trained through sequential fine-tuning-first on general corpora and then
on the KPoEM dataset-demonstrates not only an enhanced ability to identify
temporally and culturally specific emotional expressions, but also a strong
capacity to preserve the core sentiments of modern Korean poetry. This study
bridges computational methods and literary analysis, presenting new
possibilities for the quantitative exploration of poetic emotions through
structured data that faithfully retains the emotional and cultural nuances of
Korean literature.

</details>


### [99] [SelfAug: Mitigating Catastrophic Forgetting in Retrieval-Augmented Generation via Distribution Self-Alignment](https://arxiv.org/abs/2509.03934)
*Yuqing Huang,Rongyang Zhang,Qimeng Wang,Chengqiang Lu,Yan Gao,Yi Wu,Yao Hu,Xuyang Zhi,Guiquan Liu,Xin Li,Hao Wang,Enhong Chen*

Main category: cs.CL

TL;DR: SelfAug是一种新的自分布对齐方法，旨在解决大型语言模型(LLMs)在检索增强生成(RAG)微调过程中遇到的灾难性遗忘问题，同时保留模型的通用能力。


<details>
  <summary>Details</summary>
Motivation: 在LLM的监督微调中，尤其是在RAG场景下，虽然可以提升特定任务的性能，但会导致模型遗忘之前学到的知识和通用能力（灾难性遗忘）。现有的解决方案要么需要通用指令数据，要么在保持模型原始分布方面存在局限性。

Method: 提出了一种名为SelfAug的自分布对齐方法，通过将输入序列的logits与其原始分布对齐，以保留模型的语义分布，从而减轻灾难性遗忘并提升下游性能。

Result: 实验证明，SelfAug在下游学习和通用能力保留之间取得了更好的平衡。研究发现分布偏移与RAG场景下灾难性遗忘的严重程度直接相关，并指出通用指令微调中缺乏RAG能力会导致微调过程中的显著分布偏移。

Conclusion: SelfAug不仅深化了对RAG背景下灾难性遗忘的理解，还提供了一种实用的、可应用于各种微调场景的解决方案。

Abstract: Recent advancements in large language models (LLMs) have revolutionized
natural language processing through their remarkable capabilities in
understanding and executing diverse tasks. While supervised fine-tuning,
particularly in Retrieval-Augmented Generation (RAG) scenarios, effectively
enhances task-specific performance, it often leads to catastrophic forgetting,
where models lose their previously acquired knowledge and general capabilities.
Existing solutions either require access to general instruction data or face
limitations in preserving the model's original distribution. To overcome these
limitations, we propose SelfAug, a self-distribution alignment method that
aligns input sequence logits to preserve the model's semantic distribution,
thereby mitigating catastrophic forgetting and improving downstream
performance. Extensive experiments demonstrate that SelfAug achieves a superior
balance between downstream learning and general capability retention. Our
comprehensive empirical analysis reveals a direct correlation between
distribution shifts and the severity of catastrophic forgetting in RAG
scenarios, highlighting how the absence of RAG capabilities in general
instruction tuning leads to significant distribution shifts during fine-tuning.
Our findings not only advance the understanding of catastrophic forgetting in
RAG contexts but also provide a practical solution applicable across diverse
fine-tuning scenarios. Our code is publicly available at
https://github.com/USTC-StarTeam/SelfAug.

</details>


### [100] [SPFT-SQL: Enhancing Large Language Model for Text-to-SQL Parsing by Self-Play Fine-Tuning](https://arxiv.org/abs/2509.03937)
*Yuhao Zhang,Shaoming Duan,Jinhang Su,Chuanyi Liu,Peiyi Han*

Main category: cs.CL

TL;DR: SPIN在Text-to-SQL任务上存在不足，提出SPFT-SQL方法，通过迭代微调和错误驱动损失来提升Text-to-SQL能力。


<details>
  <summary>Details</summary>
Motivation: SPIN在Text-to-SQL任务上存在局限性，表现为无法生成新信息，且对手模型产生的大量正确SQL查询会削弱主模型生成准确SQL查询的能力。

Method: 提出SPFT-SQL方法，包括：1. 预微调阶段：引入基于验证的迭代微调方法，利用数据库模式和验证反馈合成高质量微调数据，并构建不同能力的模型库。2. 自我博弈微调阶段：提出错误驱动损失方法，激励对手模型产生错误输出，使主模型能区分正确和错误的SQL查询。

Result: 在六个开源LLM和五个基准测试上的实验表明，SPFT-SQL优于现有的SOTA方法。

Conclusion: SPFT-SQL通过迭代数据合成和错误驱动学习，有效解决了SPIN在Text-to-SQL任务上的挑战，显著提升了Text-to-SQL能力。

Abstract: Despite the significant advancements of self-play fine-tuning (SPIN), which
can transform a weak large language model (LLM) into a strong one through
competitive interactions between models of varying capabilities, it still faces
challenges in the Text-to-SQL task. SPIN does not generate new information, and
the large number of correct SQL queries produced by the opponent model during
self-play reduces the main model's ability to generate accurate SQL queries. To
address this challenge, we propose a new self-play fine-tuning method tailored
for the Text-to-SQL task, called SPFT-SQL. Prior to self-play, we introduce a
verification-based iterative fine-tuning approach, which synthesizes
high-quality fine-tuning data iteratively based on the database schema and
validation feedback to enhance model performance, while building a model base
with varying capabilities. During the self-play fine-tuning phase, we propose
an error-driven loss method that incentivizes incorrect outputs from the
opponent model, enabling the main model to distinguish between correct SQL and
erroneous SQL generated by the opponent model, thereby improving its ability to
generate correct SQL. Extensive experiments and in-depth analyses on six
open-source LLMs and five widely used benchmarks demonstrate that our approach
outperforms existing state-of-the-art (SOTA) methods.

</details>


### [101] [VoxRole: A Comprehensive Benchmark for Evaluating Speech-Based Role-Playing Agents](https://arxiv.org/abs/2509.03940)
*Weihao Wu,Liang Cao,Xinyu Wu,Zhiwei Lin,Rui Niu,Jingbei Li,Zhiyong Wu*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Recent significant advancements in Large Language Models (LLMs) have greatly
propelled the development of Role-Playing Conversational Agents (RPCAs). These
systems aim to create immersive user experiences through consistent persona
adoption. However, current RPCA research faces dual limitations. First,
existing work predominantly focuses on the textual modality, entirely
overlooking critical paralinguistic features including intonation, prosody, and
rhythm in speech, which are essential for conveying character emotions and
shaping vivid identities. Second, the speech-based role-playing domain suffers
from a long-standing lack of standardized evaluation benchmarks. Most current
spoken dialogue datasets target only fundamental capability assessments,
featuring thinly sketched or ill-defined character profiles. Consequently, they
fail to effectively quantify model performance on core competencies like
long-term persona consistency. To address this critical gap, we introduce
VoxRole, the first comprehensive benchmark specifically designed for the
evaluation of speech-based RPCAs. The benchmark comprises 13335 multi-turn
dialogues, totaling 65.6 hours of speech from 1228 unique characters across 261
movies. To construct this resource, we propose a novel two-stage automated
pipeline that first aligns movie audio with scripts and subsequently employs an
LLM to systematically build multi-dimensional profiles for each character.
Leveraging VoxRole, we conduct a multi-dimensional evaluation of contemporary
spoken dialogue models, revealing crucial insights into their respective
strengths and limitations in maintaining persona consistency.

</details>


### [102] [CANDY: Benchmarking LLMs' Limitations and Assistive Potential in Chinese Misinformation Fact-Checking](https://arxiv.org/abs/2509.03957)
*Ruiling Guo,Xinwei Yang,Chen Huang,Tong Zhang,Yong Hu*

Main category: cs.CL

TL;DR: CANDY基准测试用于评估LLM在中国虚假信息事实核查中的能力和局限性。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在中国虚假信息事实核查中的有效性，尽管它们被广泛使用，但其效果仍不确定。

Method: 创建了一个包含约2万条标注数据的CANDY基准测试集，并在此基础上分析了LLM在事实核查中的表现，包括使用链式思考和少样本提示等增强方法。

Result: 当前LLM在生成准确的事实核查结论方面存在局限性，即使经过增强也是如此。通过开发的分类法，发现事实捏造是LLM解释中最常见的失败模式。

Conclusion: 尽管单独使用LLM进行事实核查并不可靠，但它们有潜力作为辅助工具来增强人类在事实核查场景中的表现。

Abstract: The effectiveness of large language models (LLMs) to fact-check
misinformation remains uncertain, despite their growing use. To this end, we
present CANDY, a benchmark designed to systematically evaluate the capabilities
and limitations of LLMs in fact-checking Chinese misinformation. Specifically,
we curate a carefully annotated dataset of ~20k instances. Our analysis shows
that current LLMs exhibit limitations in generating accurate fact-checking
conclusions, even when enhanced with chain-of-thought reasoning and few-shot
prompting. To understand these limitations, we develop a taxonomy to categorize
flawed LLM-generated explanations for their conclusions and identify factual
fabrication as the most common failure mode. Although LLMs alone are unreliable
for fact-checking, our findings indicate their considerable potential to
augment human performance when deployed as assistive tools in scenarios. Our
dataset and code can be accessed at https://github.com/SCUNLP/CANDY

</details>


### [103] [Exploring NLP Benchmarks in an Extremely Low-Resource Setting](https://arxiv.org/abs/2509.03962)
*Ulin Nuha,Adam Jatowt*

Main category: cs.CL

TL;DR: LLMs在低资源语言（如Ladin语）上表现不佳，因为缺乏数据。本研究通过翻译意大利语数据来为Ladin语创建合成数据集，用于情感分析和多项选择题问答，并取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: LLMs在像Ladin语这样的低资源语言上的有效性受到缺乏标签数据的限制，而现有的高质量NLP数据集有限，阻碍了相关语言技术的发展。

Method: 利用少量的Ladin语-意大利语平行句子对，通过翻译单语意大利语数据来创建用于情感分析和多项选择题问答（MCQA）的合成数据集。采用严格的过滤和反向翻译程序来确保语言质量。

Result: 将合成数据集纳入机器翻译训练，在Ladin语-意大利语翻译任务上相比现有基线有了显著的改进。

Conclusion: 本研究首次公开了Ladin语的情感分析和MCQA数据集，为这种代表性不足的语言的NLP研究和下游应用奠定了基础资源。

Abstract: The effectiveness of Large Language Models (LLMs) diminishes for extremely
low-resource languages, such as indigenous languages, primarily due to the lack
of labeled data. Despite growing interest, the availability of high-quality
natural language processing (NLP) datasets for these languages remains limited,
making it difficult to develop robust language technologies. This paper
addresses such gap by focusing on Ladin, an endangered Romance language,
specifically targeting the Val Badia variant. Leveraging a small set of
parallel Ladin-Italian sentence pairs, we create synthetic datasets for
sentiment analysis and multiple-choice question answering (MCQA) by translating
monolingual Italian data. To ensure linguistic quality and reliability, we
apply rigorous filtering and back-translation procedures in our method. We
further demonstrate that incorporating these synthetic datasets into machine
translation training leads to substantial improvements over existing
Italian-Ladin translation baselines. Our contributions include the first
publicly available sentiment analysis and MCQA datasets for Ladin, establishing
foundational resources that can support broader NLP research and downstream
applications for this underrepresented language.

</details>


### [104] [Expanding Foundational Language Capabilities in Open-Source LLMs through a Korean Case Study](https://arxiv.org/abs/2509.03972)
*Junghwan Lim,Gangwon Jo,Sungmin Lee,Jiyoung Park,Dongseok Kim,Jihwan Kim,Junhyeok Lee,Wai Ting Cheung,Dahye Choi,Kibong Choi,Jaeyeon Huh,Beomgyu Kim,Jangwoong Kim,Taehyun Kim,Haesol Lee,Jeesoo Lee,Dongpin Oh,Changseok Song,Daewon Suh*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We introduce Llama-3-Motif, a language model consisting of 102 billion
parameters, specifically designed to enhance Korean capabilities while
retaining strong performance in English. Developed on the Llama 3 architecture,
Llama-3-Motif employs advanced training techniques, including LlamaPro and
Masked Structure Growth, to effectively scale the model without altering its
core Transformer architecture. Using the MoAI platform for efficient training
across hyperscale GPU clusters, we optimized Llama-3-Motif using a carefully
curated dataset that maintains a balanced ratio of Korean and English data.
Llama-3-Motif shows decent performance on Korean-specific benchmarks,
outperforming existing models and achieving results comparable to GPT-4.

</details>


### [105] [RTQA : Recursive Thinking for Complex Temporal Knowledge Graph Question Answering with Large Language Models](https://arxiv.org/abs/2509.03995)
*Zhaoyan Gong,Juan Li,Zhiqiang Liu,Lei Liang,Huajun Chen,Wen Zhang*

Main category: cs.CL

TL;DR: RTQA是一个无需训练的框架，通过增强在时间知识图谱（TKG）上的推理能力来解决复杂时间问题，它递归地将问题分解为子问题，自底向上地使用LLM和TKG知识进行求解，并通过多路径答案聚合提高容错能力。


<details>
  <summary>Details</summary>
Motivation: 当前的时间知识图谱问答（TKGQA）方法主要关注隐式时间约束，缺乏处理更复杂时间查询的能力，并且在分解框架中存在推理能力有限和错误传播的问题。

Method: RTQA框架通过递归思考，将问题分解为子问题，然后利用大型语言模型（LLM）和时间知识图谱（TKG）知识自底向上地进行求解，并采用多路径答案聚合来提高容错能力。它包含三个核心组件：时间问题分解器、递归求解器和答案聚合器。

Result: 在MultiTQ和TimelineKGQA基准测试上的实验表明，RTQA在“多重”和“复杂”类别上的Hits@1显著提高，性能优于现有最先进的方法。

Conclusion: RTQA通过其创新的递归分解、自底向上的求解和多路径答案聚合方法，有效地解决了现有TKGQA方法的局限性，并在处理复杂时间查询方面取得了显著的成果。

Abstract: Current temporal knowledge graph question answering (TKGQA) methods primarily
focus on implicit temporal constraints, lacking the capability of handling more
complex temporal queries, and struggle with limited reasoning abilities and
error propagation in decomposition frameworks. We propose RTQA, a novel
framework to address these challenges by enhancing reasoning over TKGs without
requiring training. Following recursive thinking, RTQA recursively decomposes
questions into sub-problems, solves them bottom-up using LLMs and TKG
knowledge, and employs multi-path answer aggregation to improve fault
tolerance. RTQA consists of three core components: the Temporal Question
Decomposer, the Recursive Solver, and the Answer Aggregator. Experiments on
MultiTQ and TimelineKGQA benchmarks demonstrate significant Hits@1 improvements
in "Multiple" and "Complex" categories, outperforming state-of-the-art methods.
Our code and data are available at https://github.com/zjukg/RTQA.

</details>


### [106] [On Robustness and Reliability of Benchmark-Based Evaluation of LLMs](https://arxiv.org/abs/2509.04013)
*Riccardo Lunardi,Vincenzo Della Mea,Stefano Mizzaro,Kevin Roitero*

Main category: cs.CL

TL;DR: LLM在标准格式的基准测试中表现良好，但在面对各种释义的现实世界查询时，其有效性会显著下降，这表明LLM对语言变异的鲁棒性不足，并且目前的评估方法可能无法充分反映其真实能力。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在现实世界应用中处理语言可变性（即问题的不同释义）的能力，并质疑现有基准测试评估方法的可靠性。

Method: 系统性地生成了六个不同基准测试中所有问题的多种释义，并测量了34个不同规模和有效性的最先进LLM在这些释义输入下的性能变化。

Result: 尽管LLM在释义输入下的排名保持相对稳定，但其绝对有效性得分显著下降，表明LLM在处理语言变异方面存在困难，并且现有基准测试的得分可能无法完全反映模型在真实场景中的鲁棒性。

Conclusion: LLM在处理语言变异方面存在不足，这引发了对其泛化能力和现有评估方法可靠性的担忧。因此，需要开发更具鲁棒性的基准测试，以更好地反映实际应用场景。

Abstract: Large Language Models (LLMs) effectiveness is usually evaluated by means of
benchmarks such as MMLU, ARC-C, or HellaSwag, where questions are presented in
their original wording, thus in a fixed, standardized format. However,
real-world applications involve linguistic variability, requiring models to
maintain their effectiveness across diverse rewordings of the same question or
query. In this study, we systematically assess the robustness of LLMs to
paraphrased benchmark questions and investigate whether benchmark-based
evaluations provide a reliable measure of model capabilities. We systematically
generate various paraphrases of all the questions across six different common
benchmarks, and measure the resulting variations in effectiveness of 34
state-of-the-art LLMs, of different size and effectiveness. Our findings reveal
that while LLM rankings remain relatively stable across paraphrased inputs,
absolute effectiveness scores change, and decline significantly. This suggests
that LLMs struggle with linguistic variability, raising concerns about their
generalization abilities and evaluation methodologies. Furthermore, the
observed performance drop challenges the reliability of benchmark-based
evaluations, indicating that high benchmark scores may not fully capture a
model's robustness to real-world input variations. We discuss the implications
of these findings for LLM evaluation methodologies, emphasizing the need for
robustness-aware benchmarks that better reflect practical deployment scenarios.

</details>


### [107] [What if I ask in \textit{alia lingua}? Measuring Functional Similarity Across Languages](https://arxiv.org/abs/2509.04032)
*Debangan Mishra,Arihant Rastogi,Agyeya Negi,Shashwat Goel,Ponnurangam Kumaraguru*

Main category: cs.CL

TL;DR: 模型在不同语言间的输出一致性随模型规模和能力增长而提高，且模型自身的一致性高于与其他模型在同语言下的一致性。


<details>
  <summary>Details</summary>
Motivation: 研究模型输出在不同语言间的相似度，并评估$\|k\|_p$度量的有效性。

Method: 使用$\|k\|_p$度量，对20种语言和47个学科的GlobalMMLU数据集进行分析。

Result: 模型规模和能力越大，其跨语言输出越一致。模型自身在不同语言间的一致性高于与其他模型在同语言下的一致性。

Conclusion: $\|k\|_p$是评估多语言可靠性的实用工具，并能指导更一致的多语言系统的开发。

Abstract: How similar are model outputs across languages? In this work, we study this
question using a recently proposed model similarity metric $\kappa_p$ applied
to 20 languages and 47 subjects in GlobalMMLU. Our analysis reveals that a
model's responses become increasingly consistent across languages as its size
and capability grow. Interestingly, models exhibit greater cross-lingual
consistency within themselves than agreement with other models prompted in the
same language. These results highlight not only the value of $\kappa_p$ as a
practical tool for evaluating multilingual reliability, but also its potential
to guide the development of more consistent multilingual systems.

</details>


### [108] [A RoBERTa-Based Functional Syntax Annotation Model for Chinese Texts](https://arxiv.org/abs/2509.04046)
*Han Xiaohui,Zhang Yunlong,Guo Yuxi*

Main category: cs.CL

TL;DR: 本研究开发了一个基于 RoBERTa 的中文功能句法自动标注模型，并在人民日报语料库上进行了训练和测试，取得了优异的 F1 分数，尤其在识别主语、谓语和宾语方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有中文文本缺乏基于系统功能语法理论的功能句法自动标注系统，限制了该理论的应用和推广。

Method: 随机选取 4100 句人民日报 2014 年语料库，依据功能句法理论进行标注，构建训练数据集；然后基于该数据集微调 RoBERTa-Chinese wwm-ext 模型，以实现命名实体识别任务。

Result: 在测试集上达到了 0.852 的 F1 分数，显著优于其他对比模型，在识别主语 (S)、谓语 (M) 和宾语 (C) 等核心句法成分方面表现出卓越性能。

Conclusion: 本研究首次将功能句法与基于注意力机制的自然语言处理模型相结合，为中文功能句法自动分析提供了一种新方法，并为后续研究奠定了基础。但识别样本不平衡的实体方面仍有提升空间。

Abstract: Systemic Functional Grammar and its branch, Cardiff Grammar, have been widely
applied to discourse analysis, semantic function research, and other tasks
across various languages and texts. However, an automatic annotation system
based on this theory for Chinese texts has not yet been developed, which
significantly constrains the application and promotion of relevant theories. To
fill this gap, this research introduces a functional syntax annotation model
for Chinese based on RoBERTa (Robustly Optimized BERT Pretraining Approach).
The study randomly selected 4,100 sentences from the People's Daily 2014 corpus
and annotated them according to functional syntax theory to establish a dataset
for training. The study then fine-tuned the RoBERTa-Chinese wwm-ext model based
on the dataset to implement the named entity recognition task, achieving an F1
score of 0.852 on the test set that significantly outperforms other comparative
models. The model demonstrated excellent performance in identifying core
syntactic elements such as Subject (S), Main Verb (M), and Complement (C).
Nevertheless, there remains room for improvement in recognizing entities with
imbalanced label samples. As the first integration of functional syntax with
attention-based NLP models, this research provides a new method for automated
Chinese functional syntax analysis and lays a solid foundation for subsequent
studies.

</details>


### [109] [Synthesizing Sheet Music Problems for Evaluation and Reinforcement Learning](https://arxiv.org/abs/2509.04059)
*Zhilin Wang,Zhe Yang,Yun Luo,Yafu Li,Haoran Zhang,Runzhe Zhan,Derek F. Wong,Jizhe Zhou,Yu Cheng*

Main category: cs.CL

TL;DR: 本研究提出通过音乐理论规则合成乐谱推理问题，构建了SSMR-Bench基准和训练集，用于评估和增强LLM/MLLM对乐谱的理解能力，并展示了合成数据在强化学习中的有效性，同时促进了音乐创作。


<details>
  <summary>Details</summary>
Motivation: 当前LLM/MLLM在解读乐谱方面能力不足，缺乏评估基准和训练数据，阻碍了AI音乐家的发展。

Method: 提出合成乐谱问题的框架，生成文本和视觉模态的乐谱推理问题，构建SSMR-Bench和训练集，并利用合成数据进行基于可验证奖励的强化学习（RLVR）。

Result: SSMR-Bench的评估结果凸显了模型推理能力的重要性；Gemini 2.5-Pro在视觉乐谱解读方面表现不佳；使用合成数据进行RLVR后，Qwen3-8B-Base和Qwen2.5-VL-Instruct在SSMR-Bench上有所提升；Qwen3-8B-Base在MusicTheoryBench上的整体表现超越GPT-4，并接近GPT-4的推理能力；Qwen3-8B-Base的数学问题解决能力也有所提高；增强的推理能力有助于提升音乐创作能力。

Conclusion: 首次提出基于音乐理论规则合成乐谱问题的想法，并证明了其在提升模型乐谱理解推理能力以及解锁AI辅助音乐创作新可能性方面的有效性。

Abstract: Enhancing the ability of Large Language Models (LLMs) and Multimodal Large
Language Models (MLLMs) to interpret sheet music is a crucial step toward
building AI musicians. However, current research lacks both evaluation
benchmarks and training data for sheet music reasoning. To address this, we
propose the idea of synthesizing sheet music problems grounded in music theory,
which can serve both as evaluation benchmarks and as training data for
reinforcement learning with verifiable rewards (RLVR). We introduce a data
synthesis framework that generates verifiable sheet music questions in both
textual and visual modalities, leading to the Synthetic Sheet Music Reasoning
Benchmark (SSMR-Bench) and a complementary training set. Evaluation results on
SSMR-Bench show the importance of models' reasoning abilities in interpreting
sheet music. At the same time, the poor performance of Gemini 2.5-Pro
highlights the challenges that MLLMs still face in interpreting sheet music in
a visual format. By leveraging synthetic data for RLVR, Qwen3-8B-Base and
Qwen2.5-VL-Instruct achieve improvements on the SSMR-Bench. Besides, the
trained Qwen3-8B-Base surpasses GPT-4 in overall performance on
MusicTheoryBench and achieves reasoning performance comparable to GPT-4 with
the strategies of Role play and Chain-of-Thought. Notably, its performance on
math problems also improves relative to the original Qwen3-8B-Base.
Furthermore, our results show that the enhanced reasoning ability can also
facilitate music composition. In conclusion, we are the first to propose the
idea of synthesizing sheet music problems based on music theory rules, and
demonstrate its effectiveness not only in advancing model reasoning for sheet
music understanding but also in unlocking new possibilities for AI-assisted
music creation.

</details>


### [110] [Arabic Chatbot Technologies in Education: An Overview](https://arxiv.org/abs/2509.04066)
*Hicham Bourhil,Yacine El Younoussi*

Main category: cs.CL

TL;DR: 本研究总结了教育领域现有的阿拉伯语聊天机器人，并指出了其在采用现代技术方面的不足，为未来的研究提供了方向。


<details>
  <summary>Details</summary>
Motivation: 由于人工智能和自然语言处理的进步，特别是大型语言模型的出现，聊天机器人在教育领域的应用越来越广泛，尤其是在COVID-19大流行之后远程访问需求增加的背景下。本研究旨在调查和分析教育领域现有的阿拉伯语聊天机器人。

Method: 本研究通过调查现有教育领域的阿拉伯语聊天机器人，分析其采用的方法、语言变体以及性能评估指标。

Result: 研究发现，尽管聊天机器人在英语等语言中取得了成功，但很少有教育领域的阿拉伯语聊天机器人采用现代技术。然而，研究也确定了一些研究空白，并为该领域未来的研究方向提供了讨论。

Conclusion: 尽管人工智能和大型语言模型在教育领域，特别是阿拉伯语聊天机器人方面取得了进展，但仍有改进空间。未来的研究应侧重于采用更先进的技术，以充分发挥这些工具的潜力。

Abstract: The recent advancements in Artificial Intelligence (AI) in general, and in
Natural Language Processing (NLP) in particular, and some of its applications
such as chatbots, have led to their implementation in different domains like
education, healthcare, tourism, and customer service. Since the COVID-19
pandemic, there has been an increasing interest in these digital technologies
to allow and enhance remote access. In education, e-learning systems have been
massively adopted worldwide. The emergence of Large Language Models (LLM) such
as BERT (Bidirectional Encoder Representations from Transformers) and GPT
(Generative Pre-trained Transformers) made chatbots even more popular. In this
study, we present a survey on existing Arabic chatbots in education and their
different characteristics such as the adopted approaches, language variety, and
metrics used to measure their performance. We were able to identified some
research gaps when we discovered that, despite the success of chatbots in other
languages such as English, only a few educational Arabic chatbots used modern
techniques. Finally, we discuss future directions of research in this field.

</details>


### [111] [Improving Narrative Classification and Explanation via Fine Tuned Language Models](https://arxiv.org/abs/2509.04077)
*Rishit Tyagi,Rahul Bouri,Mohit Gupta*

Main category: cs.CL

TL;DR: 本研究提出了一种结合BERT和GPT-4o模型的方法，用于识别新闻文章中的隐性叙事和生成解释，并利用辅助知识库提高准确性。


<details>
  <summary>Details</summary>
Motivation: 传统的自然语言处理方法难以识别细微的措辞和隐藏的议程，因此需要新的方法来理解隐性叙事和隐含信息，以分析偏见和情感。

Method: 本研究首先使用面向召回率的BERT模型进行多标签分类，以识别新闻文章中的叙事和子叙事。然后，利用GPT-4o模型对预测进行精炼，以确保一致性。对于叙事解释，研究提出了一个基于ReACT（推理+行动）框架的少样本提示方法，并结合语义检索，以生成有事实依据的解释。为了提高事实准确性和减少幻觉，研究还引入了一个结构化的分类信息表作为辅助知识库。

Result: 结合辅助知识库的提示方法，在提高叙事分类准确性和解释的可靠性方面取得了显著效果。

Conclusion: 本研究提出的方法在媒体分析、教育和情报收集等领域具有广泛的应用前景，能够更有效地识别和理解隐性叙事和隐含信息。

Abstract: Understanding covert narratives and implicit messaging is essential for
analyzing bias and sentiment. Traditional NLP methods struggle with detecting
subtle phrasing and hidden agendas. This study tackles two key challenges: (1)
multi-label classification of narratives and sub-narratives in news articles,
and (2) generating concise, evidence-based explanations for dominant
narratives. We fine-tune a BERT model with a recall-oriented approach for
comprehensive narrative detection, refining predictions using a GPT-4o pipeline
for consistency. For narrative explanation, we propose a ReACT (Reasoning +
Acting) framework with semantic retrieval-based few-shot prompting, ensuring
grounded and relevant justifications. To enhance factual accuracy and reduce
hallucinations, we incorporate a structured taxonomy table as an auxiliary
knowledge base. Our results show that integrating auxiliary knowledge in
prompts improves classification accuracy and justification reliability, with
applications in media analysis, education, and intelligence gathering.

</details>


### [112] [Towards Stable and Personalised Profiles for Lexical Alignment in Spoken Human-Agent Dialogue](https://arxiv.org/abs/2509.04104)
*Keara Schaaij,Roel Boumans,Tibor Bosse,Iris Hendrickx*

Main category: cs.CL

TL;DR: 本研究首次探索了在对话代理中实现词汇对齐，重点关注构建稳定、个性化的词汇特征，并提出了最优的特征构建策略。


<details>
  <summary>Details</summary>
Motivation: 尽管词汇对齐已被证明有助于提高沟通效率，但在对话代理中的应用仍需深入研究，尤其是在大型语言模型（LLMs）取得进展的背景下。

Method: 研究人员探索了用于构建个性化词汇特征的策略，实验了不同时长的语音数据和每个词性（POS）类别的词汇项数量，并使用召回率、覆盖率和余弦相似度等指标评估了特征随时间的表现。

Result: 研究发现，使用10分钟转录语音数据构建的、包含5个形容词、5个连词、以及各10个副词、名词、代词和动词的精简特征，在性能和数据效率方面取得了最佳平衡。

Conclusion: 本研究为构建稳定、个性化的词汇特征提供了实用的见解，明确了最小数据需求，为实现对话代理的词汇对齐策略奠定了基础。

Abstract: Lexical alignment, where speakers start to use similar words across
conversation, is known to contribute to successful communication. However, its
implementation in conversational agents remains underexplored, particularly
considering the recent advancements in large language models (LLMs). As a first
step towards enabling lexical alignment in human-agent dialogue, this study
draws on strategies for personalising conversational agents and investigates
the construction of stable, personalised lexical profiles as a basis for
lexical alignment. Specifically, we varied the amounts of transcribed spoken
data used for construction as well as the number of items included in the
profiles per part-of-speech (POS) category and evaluated profile performance
across time using recall, coverage, and cosine similarity metrics. It was shown
that smaller and more compact profiles, created after 10 min of transcribed
speech containing 5 items for adjectives, 5 items for conjunctions, and 10
items for adverbs, nouns, pronouns, and verbs each, offered the best balance in
both performance and data efficiency. In conclusion, this study offers
practical insights into constructing stable, personalised lexical profiles,
taking into account minimal data requirements, serving as a foundational step
toward lexical alignment strategies in conversational agents.

</details>


### [113] [MultiWikiQA: A Reading Comprehension Benchmark in 300+ Languages](https://arxiv.org/abs/2509.04111)
*Dan Saattrup Smart*

Main category: cs.CL

TL;DR: MultiWikiQA是一个包含306种语言的多语言阅读理解数据集，其问题由LLM生成，答案来自维基百科文章。


<details>
  <summary>Details</summary>
Motivation: 介绍一个新的、覆盖广泛语言的阅读理解数据集（MultiWikiQA），并评估其质量和语言模型在该数据集上的表现。

Method: 从维基百科收集语料，利用LLM生成问题，并进行众包人类评估以检验问题流畅度。在306种语言上评估6种不同语言模型（包括编码器和解码器模型）。

Result: 众包评估显示生成的问题质量良好。语言模型在数据集上的表现存在显著差异，表明数据集具有挑战性。

Conclusion: MultiWikiQA是一个高质量、多语言的阅读理解数据集，可用于评估和提升语言模型在不同语言上的阅读理解能力。

Abstract: We introduce a new reading comprehension dataset, dubbed MultiWikiQA, which
covers 306 languages. The context data comes from Wikipedia articles, with
questions generated by an LLM and the answers appearing verbatim in the
Wikipedia articles. We conduct a crowdsourced human evaluation of the fluency
of the generated questions across 30 of the languages, providing evidence that
the questions are of good quality. We evaluate 6 different language models,
both decoder and encoder models of varying sizes, showing that the benchmark is
sufficiently difficult and that there is a large performance discrepancy
amongst the languages. The dataset and survey evaluations are freely available.

</details>


### [114] [Joint Modeling of Entities and Discourse Relations for Coherence Assessment](https://arxiv.org/abs/2509.04182)
*Wei Liu,Michael Strube*

Main category: cs.CL

TL;DR: 本文提出联合建模实体和语篇关系以提升语言连贯性评估的效果，实验证明此方法优于仅使用单一特征的方法。


<details>
  <summary>Details</summary>
Motivation: 现有的连贯性模型在建模时，通常只关注实体特征或语篇关系特征，而很少将两者结合起来。

Method: 本文探索了两种联合建模实体和语篇关系的方法，用于连贯性评估。

Result: 实验结果表明，结合实体特征和语篇关系特征能够显著提升连贯性模型的性能。

Conclusion: 同时建模实体和语篇关系对于连贯性评估是有益的。

Abstract: In linguistics, coherence can be achieved by different means, such as by
maintaining reference to the same set of entities across sentences and by
establishing discourse relations between them. However, most existing work on
coherence modeling focuses exclusively on either entity features or discourse
relation features, with little attention given to combining the two. In this
study, we explore two methods for jointly modeling entities and discourse
relations for coherence assessment. Experiments on three benchmark datasets
show that integrating both types of features significantly enhances the
performance of coherence models, highlighting the benefits of modeling both
simultaneously for coherence evaluation.

</details>


### [115] [MAGneT: Coordinated Multi-Agent Generation of Synthetic Multi-Turn Mental Health Counseling Sessions](https://arxiv.org/abs/2509.04183)
*Aishik Mandal,Tanmoy Chakraborty,Iryna Gurevych*

Main category: cs.CL

TL;DR: MAGneT是一个新的多智能体框架，通过专门的LLM智能体来生成合成的心理咨询会话，以解决高质量、隐私合规数据稀缺的问题，并提出了一个统一的评估框架，在各项指标上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成心理咨询会话时，由于缺乏高质量、隐私合规的数据，并且在评估方面存在不足，难以满足日益增长的可扩展心理咨询需求。

Method: MAGneT框架将咨询师回应的生成分解为由专门的LLM智能体处理的协调子任务，每个智能体模拟一种关键的心理学技术。此外，还提出了一个包含自动和专家指标的统一评估框架，并将专家评估扩展到九个方面。

Result: MAGneT生成的咨询会话在质量、多样性和治疗一致性方面显著优于现有方法，在认知疗法评定量表（CTRS）上，综合咨询技能平均提高3.2%，CBT特定技能平均提高4.3%。专家在77.2%的情况下更倾向于MAGneT生成的会话。使用MAGneT生成的数据进行微调的模型，在CTRS上的综合咨询技能平均提高6.3%，CBT特定技能平均提高7.3%。

Conclusion: MAGneT框架能够有效生成高质量、多样化且具有治疗一致性的心理咨询会话，并且在实际应用中，基于MAGneT生成数据微调的模型表现更优。该研究将代码和数据公开，为相关领域的研究和应用提供了支持。

Abstract: The growing demand for scalable psychological counseling highlights the need
for fine-tuning open-source Large Language Models (LLMs) with high-quality,
privacy-compliant data, yet such data remains scarce. Here we introduce MAGneT,
a novel multi-agent framework for synthetic psychological counseling session
generation that decomposes counselor response generation into coordinated
sub-tasks handled by specialized LLM agents, each modeling a key psychological
technique. Unlike prior single-agent approaches, MAGneT better captures the
structure and nuance of real counseling. In addition, we address
inconsistencies in prior evaluation protocols by proposing a unified evaluation
framework integrating diverse automatic and expert metrics. Furthermore, we
expand the expert evaluations from four aspects of counseling in previous works
to nine aspects, enabling a more thorough and robust assessment of data
quality. Empirical results show that MAGneT significantly outperforms existing
methods in quality, diversity, and therapeutic alignment of the generated
counseling sessions, improving general counseling skills by 3.2% and
CBT-specific skills by 4.3% on average on cognitive therapy rating scale
(CTRS). Crucially, experts prefer MAGneT-generated sessions in 77.2% of cases
on average across all aspects. Moreover, fine-tuning an open-source model on
MAGneT-generated sessions shows better performance, with improvements of 6.3%
on general counseling skills and 7.3% on CBT-specific skills on average on CTRS
over those fine-tuned with sessions generated by baseline methods. We also make
our code and data public.

</details>


### [116] [Inverse IFEval: Can LLMs Unlearn Stubborn Training Conventions to Follow Real Instructions?](https://arxiv.org/abs/2509.04292)
*Qinyan Zhang,Xinping Lei,Ruijie Miao,Yu Fu,Haojie Fan,Le Chang,Jiafan Hou,Dingling Zhang,Zhongfei Hou,Ziqiang Yang,Changxin Pu,Fei Hu,Jingkai Liu,Mengyun Liu,Yang Liu,Xiang Gao,Jiaheng Liu,Tong Yang,Zaiyuan Wang,Ge Zhang,Wenhao Huang*

Main category: cs.CL

TL;DR: LLMs在各种任务上表现出色，但存在认知惰性，难以遵循与SFT模式相冲突的指令。我们提出了Inverse IFEval基准来评估和解决这个问题，该基准包含8种挑战，如问题纠正、故意文本缺陷、无注释代码和反事实回答。我们构建了一个包含1012个中英问题的1012个高质量数据集，并在LLM-as-a-Judge框架下进行了评估。实验表明，现有的LLM存在此问题，未来的模型应考虑在非常规情况下的适应性，以提高指令遵循的可靠性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在各种任务上表现出色，但存在认知惰性，难以遵循与标准化监督微调（SFT）模式相冲突的指令。

Method: 提出了Inverse IFEval基准，该基准包含8种类型的挑战，包括问题纠正、故意文本缺陷、无注释代码和反事实回答。使用包含1012个中英问题的1012个高质量数据集，并通过优化的LLM-as-a-Judge框架进行评估。

Result: 实验证明了Inverse IFEval基准的必要性，并表明现有领先的LLM存在认知惰性问题。

Conclusion: 未来的模型对齐工作不仅应追求流畅性和事实正确性，还应考虑在非常规情况下的适应性。Inverse IFEval可作为诊断工具，并为开发减轻认知惰性、减少对狭窄模式过度拟合以及提高LLM在不可预测的现实世界场景中指令遵循可靠性的方法奠定基础。

Abstract: Large Language Models (LLMs) achieve strong performance on diverse tasks but
often exhibit cognitive inertia, struggling to follow instructions that
conflict with the standardized patterns learned during supervised fine-tuning
(SFT). To evaluate this limitation, we propose Inverse IFEval, a benchmark that
measures models Counter-intuitive Abilitytheir capacity to override
training-induced biases and comply with adversarial instructions. Inverse
IFEval introduces eight types of such challenges, including Question
Correction, Intentional Textual Flaws, Code without Comments, and
Counterfactual Answering. Using a human-in-the-loop pipeline, we construct a
dataset of 1012 high-quality Chinese and English questions across 23 domains,
evaluated under an optimized LLM-as-a-Judge framework. Experiments on existing
leading LLMs demonstrate the necessity of our proposed Inverse IFEval
benchmark. Our findings emphasize that future alignment efforts should not only
pursue fluency and factual correctness but also account for adaptability under
unconventional contexts. We hope that Inverse IFEval serves as both a
diagnostic tool and a foundation for developing methods that mitigate cognitive
inertia, reduce overfitting to narrow patterns, and ultimately enhance the
instruction-following reliability of LLMs in diverse and unpredictable
real-world scenarios.

</details>


### [117] [Facts Fade Fast: Evaluating Memorization of Outdated Medical Knowledge in Large Language Models](https://arxiv.org/abs/2509.04304)
*Juraj Vladika,Mahdi Dhaini,Florian Matthes*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The growing capabilities of Large Language Models (LLMs) show significant
potential to enhance healthcare by assisting medical researchers and
physicians. However, their reliance on static training data is a major risk
when medical recommendations evolve with new research and developments. When
LLMs memorize outdated medical knowledge, they can provide harmful advice or
fail at clinical reasoning tasks. To investigate this problem, we introduce two
novel question-answering (QA) datasets derived from systematic reviews:
MedRevQA (16,501 QA pairs covering general biomedical knowledge) and
MedChangeQA (a subset of 512 QA pairs where medical consensus has changed over
time). Our evaluation of eight prominent LLMs on the datasets reveals
consistent reliance on outdated knowledge across all models. We additionally
analyze the influence of obsolete pre-training data and training strategies to
explain this phenomenon and propose future directions for mitigation, laying
the groundwork for developing more current and reliable medical AI systems.

</details>


### [118] [PARCO: Phoneme-Augmented Robust Contextual ASR via Contrastive Entity Disambiguation](https://arxiv.org/abs/2509.04357)
*Jiajun He,Naoki Sawada,Koichi Miyazaki,Tomoki Toda*

Main category: cs.CL

TL;DR: PARCO通过整合音素感知编码、对比实体消歧、实体级监督和分层实体过滤来提高ASR对领域特定实体（特别是同音词）的识别能力，在中文AISHELL-1和英文DATA2上表现优于基线，并在跨领域数据集上显示出稳健的收益。


<details>
  <summary>Details</summary>
Motivation: 现有ASR系统在处理领域特定命名实体（尤其是同音词）时存在困难，并且在细粒度音素变异的捕捉上存在不足，同时多标记实体关联也未被充分利用。

Method: 提出PARCO（Phoneme-Augmented Robust Contextual ASR via COntrastive entity disambiguation），集成了音素感知编码、对比实体消歧、实体级监督和分层实体过滤。

Result: 在中文AISHELL-1上实现了4.22%的CER，在英文DATA2（1000个干扰项）上实现了11.14%的WER，显著优于基线方法，并在THCHS-30和LibriSpeech等领域外数据集上表现出鲁棒性。

Conclusion: PARCO在处理领域特定命名实体方面，尤其是在音素识别和多标记实体关联方面，取得了显著的性能提升和鲁棒性。

Abstract: Automatic speech recognition (ASR) systems struggle with domain-specific
named entities, especially homophones. Contextual ASR improves recognition but
often fails to capture fine-grained phoneme variations due to limited entity
diversity. Moreover, prior methods treat entities as independent tokens,
leading to incomplete multi-token biasing. To address these issues, we propose
Phoneme-Augmented Robust Contextual ASR via COntrastive entity disambiguation
(PARCO), which integrates phoneme-aware encoding, contrastive entity
disambiguation, entity-level supervision, and hierarchical entity filtering.
These components enhance phonetic discrimination, ensure complete entity
retrieval, and reduce false positives under uncertainty. Experiments show that
PARCO achieves CER of 4.22% on Chinese AISHELL-1 and WER of 11.14% on English
DATA2 under 1,000 distractors, significantly outperforming baselines. PARCO
also demonstrates robust gains on out-of-domain datasets like THCHS-30 and
LibriSpeech.

</details>


### [119] [Measuring Bias or Measuring the Task: Understanding the Brittle Nature of LLM Gender Biases](https://arxiv.org/abs/2509.04373)
*Bufan Gao,Elisa Kreiss*

Main category: cs.CL

TL;DR: 评估LLM性别偏见时，测试任务的提示语会显著影响结果，有时甚至会反转偏见方向，且离散选择指标比概率指标更能放大偏见。


<details>
  <summary>Details</summary>
Motivation: LLM在社会影响力场景中的应用日益广泛，但性别偏见问题引发了广泛关注，并促使人们努力去衡量和减轻这种偏见。然而，现有的评估任务通常不符合自然语言分布，且可能包含明确或隐含的性别偏见相关信号。

Method: 通过对比两种提示语条件（强调测试语境和强调性别焦点内容）来检验提示语的信号作用如何影响LLM的性别偏见测量。在四种不同的任务格式中，使用token-probability和discrete-choice两种指标进行评估，并分析了模型在不同提示语下的表现。

Result: 研究发现，即使是很小的提示语改动也会显著改变性别偏见的结果，有时甚至会完全扭转偏见的指向。离散选择指标相比概率指标，往往会放大偏见。

Conclusion: LLM的性别偏见评估非常脆弱，提示语的微小变化就可能导致结果的巨大差异。这引发了一个新的问题：精心设计的测试能否触发LLM的“测试模式”表现，以及这对未来基准测试的生态有效性意味着什么？

Abstract: As LLMs are increasingly applied in socially impactful settings, concerns
about gender bias have prompted growing efforts both to measure and mitigate
such bias. These efforts often rely on evaluation tasks that differ from
natural language distributions, as they typically involve carefully constructed
task prompts that overtly or covertly signal the presence of gender
bias-related content. In this paper, we examine how signaling the evaluative
purpose of a task impacts measured gender bias in LLMs. Concretely, we test
models under prompt conditions that (1) make the testing context salient, and
(2) make gender-focused content salient. We then assess prompt sensitivity
across four task formats with both token-probability and discrete-choice
metrics. We find that even minor prompt changes can substantially alter bias
outcomes, sometimes reversing their direction entirely. Discrete-choice metrics
further tend to amplify bias relative to probabilistic measures. These findings
do not only highlight the brittleness of LLM gender bias evaluations but open a
new puzzle for the NLP benchmarking and development community: To what extent
can well-controlled testing designs trigger LLM ``testing mode'' performance,
and what does this mean for the ecological validity of future benchmarks.

</details>


### [120] [Can Language Models Handle a Non-Gregorian Calendar?](https://arxiv.org/abs/2509.04432)
*Mutsumi Sasaki,Go Kamoda,Ryosuke Takahashi,Kosuke Sato,Kentaro Inui,Keisuke Sakaguchi,Benjamin Heinzerling*

Main category: cs.CL

TL;DR: 大型语言模型（LMs）在处理非公历（如日本、伊斯兰历、希伯来历）方面存在不足，尤其是在涉及文化特定时间概念时。本研究首次系统评估了开源语言模型在处理日本历法方面的能力，发现现有模型在日历转换方面表现不一，但在涉及日本历法算术和跨历法一致性方面仍存在困难，这表明需要开发更能理解特定文化历法的语言模型。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型在处理非公历（如日本历）方面缺乏评估，而这些历法在全球范围内被广泛使用并承载着文化特定的时间观念。因此，有必要系统性地评估当前语言模型处理这些历法的能力。

Method: 创建了四个需要时间知识和时间推理的数据集，用于评估一系列以英语和日语为中心的语言模型处理日本历法的能力。

Result: 评估结果显示，部分模型能够进行日历转换，但即使是日语模型在进行日本历法算术和保持跨历法一致性方面也面临挑战。

Conclusion: 当前语言模型在处理日本历法方面存在显著不足，尤其是在算术和跨历法一致性方面。这项研究强调了开发能够更好地理解特定文化历法的语言模型的重要性。

Abstract: Temporal reasoning and knowledge are essential capabilities for language
models (LMs). While much prior work has analyzed and improved temporal
reasoning in LMs, most studies have focused solely on the Gregorian calendar.
However, many non-Gregorian systems, such as the Japanese, Hijri, and Hebrew
calendars, are in active use and reflect culturally grounded conceptions of
time. If and how well current LMs can accurately handle such non-Gregorian
calendars has not been evaluated so far. Here, we present a systematic
evaluation of how well open-source LMs handle one such non-Gregorian system:
the Japanese calendar. For our evaluation, we create datasets for four tasks
that require both temporal knowledge and temporal reasoning. Evaluating a range
of English-centric and Japanese-centric LMs, we find that some models can
perform calendar conversions, but even Japanese-centric models struggle with
Japanese-calendar arithmetic and with maintaining consistency across calendars.
Our results highlight the importance of developing LMs that are better equipped
for culture-specific calendar understanding.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [121] [Combining feature-based approaches with graph neural networks and symbolic regression for synergistic performance and interpretability](https://arxiv.org/abs/2509.03547)
*Rogério Almeida Gouvêa,Pierre-Paul De Breuck,Tatiane Pretto,Gian-Marco Rignanese,Marcos José Leite dos Santos*

Main category: cond-mat.mtrl-sci

TL;DR: MatterVial是一个结合了传统特征工程和深度学习（GNN）的材料信息学框架，提高了模型性能并增强了可解释性。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在克服现有材料科学机器学习模型的局限性，通过融合多种预训练图神经网络（GNN）模型的潜在表征、高效的GNN近似描述符以及符号回归的新特征，来扩展特征空间，结合传统模型的化学可解释性和深度学习的预测能力。

Method: MatterVial框架整合了多种预训练GNN模型（如MEGNet、ROOST、ORB）的潜在表征，并结合了计算高效的GNN近似描述符和符号回归提取的新特征。该框架还包含一个集成解释性模块，利用代理模型和符号回归来解码GNN的潜在描述符，生成物理意义明确的公式。

Result: 将MatterVial框架应用于Matbench数据集的任务中，通过增强MODNet模型，实现了显著的误差降低，并在多项任务上将准确性提高了40%以上，性能可与最先进的端到端GNN模型相媲美，甚至在某些情况下更优。

Conclusion: MatterVial框架通过提供一个高性能、透明且符合可解释AI原则的工具，推动了材料信息学的发展，为更具针对性和自主性的材料发现铺平了道路。

Abstract: This study introduces MatterVial, an innovative hybrid framework for
feature-based machine learning in materials science. MatterVial expands the
feature space by integrating latent representations from a diverse suite of
pretrained graph neural network (GNN) models including: structure-based
(MEGNet), composition-based (ROOST), and equivariant (ORB) graph networks, with
computationally efficient, GNN-approximated descriptors and novel features from
symbolic regression. Our approach combines the chemical transparency of
traditional feature-based models with the predictive power of deep learning
architectures. When augmenting the feature-based model MODNet on Matbench
tasks, this method yields significant error reductions and elevates its
performance to be competitive with, and in several cases superior to,
state-of-the-art end-to-end GNNs, with accuracy increases exceeding 40% for
multiple tasks. An integrated interpretability module, employing surrogate
models and symbolic regression, decodes the latent GNN-derived descriptors into
explicit, physically meaningful formulas. This unified framework advances
materials informatics by providing a high-performance, transparent tool that
aligns with the principles of explainable AI, paving the way for more targeted
and autonomous materials discovery.

</details>


### [122] [Hydrogen storage in nanocrystalline high entropy material](https://arxiv.org/abs/2509.03557)
*Yogesh Kumar Yadav,Mohammad Abu Shaz,Thakur Prasad Yadav*

Main category: cond-mat.mtrl-sci

TL;DR: 一种单相纳米晶Al-Cu-Fe-Ni-Cr高熵合金通过机械合金化合成，在300°C和50 atm H2下，3分钟内吸收2.1 wt.%的氢气，6分钟内释放1.6 wt.%的氢气，并且在25次循环后仍保持大部分容量，显示出其在储氢应用方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 研究一种合成的单相纳米晶Al-Cu-Fe-Ni-Cr高熵合金的储氢性能，以评估其作为储氢材料的应用潜力。

Method: 使用高能搅拌球磨机，以元素粉末为原料，己烷为工艺控制剂，机械合金化合成单相纳米晶Al-Cu-Fe-Ni-Cr高熵合金。然后，在300°C和50 atm H2压力下，评估其氢气吸收和解吸的性能，以及循环稳定性。

Result: 成功合成了单相纳米晶Al-Cu-Fe-Ni-Cr高熵合金，晶格常数为0.289 nm，体心立方（BCC）相。该合金在300°C和50 atm H2下，3分钟内吸收2.1 wt.%的氢气，6分钟内解吸1.6 wt.%的氢气。经过25次循环后，氢气容量仅损失0.2 wt.%。

Conclusion: 合成的纳米晶Al-Cu-Fe-Ni-Cr高熵合金具有优异的储氢动力学性能和循环稳定性，是一种有潜力的储氢应用材料。

Abstract: In this study, a single-phase nanocrystalline Al-Cu-Fe-Ni-Cr high-entropy
alloy (HEA) has been synthesized by mechanical alloying and comprehensively
investigated for hydrogen storage responses evaluated in details. High-energy
attritor ball mill was used to synthesize the alloy from elemental powder, and
hexane medium was used as a process control agent. As synthesized materials was
nanocrystalline in nature after 40 h of milling with a lattice parameter of
0.289 nm body-centered cubic (BCC) phase. As synthesized nanocrystalline
Al-Cu-Fe-Ni-Cr HEA demonstrated remarkable hydrogen storage properties,
absorbing 2.1 wt.% of hydrogen in 3 minutes at 300{\deg}C with 50 atm of
hydrogen pressure. At the same temperature, it also desorbed about 1.6 wt.% of
hydrogen in 6 minutes. These quick rates of absorption and desorption
demonstrate how well the alloy absorbs and releases hydrogen. Additionally, the
alloy showed outstanding cyclic stability, retaining almost all of its hydrogen
capacity across 25 cycles with only a slight 0.2 wt.% loss. The nanocrystalline
Al-Cu-Fe-Ni-Cr HEA is a potential option for hydrogen storage applications due
to its outstanding cycle stability and fast kinetics of hydrogen storage and
release.

</details>


### [123] [Surface Passivation for Halide Optoelectronics: Comparing Optimization and Reactivity of Amino-Silanes with Formamidinium](https://arxiv.org/abs/2509.03713)
*Zixu Huang,Farhad Akrami,Junxiang Zhang,Stephen Barlow,Seth R. Marder,David S. Ginger*

Main category: cond-mat.mtrl-sci

TL;DR: Amino-silane表面钝化可以改善钙钛矿光电器件性能，但效果取决于处理时间和分子结构。AEAPTMS比APTMS具有更宽的处理窗口和更高的性能。


<details>
  <summary>Details</summary>
Motivation: 研究氨基硅烷类表面钝化方法在卤化物钙钛矿光电子学中的应用，并比较APTMS和AEAPTMS两种分子的钝化效果。

Method: 通过室温真空沉积技术，比较APTMS和AEAPTMS对FA0.78Cs0.22Pb(I0.85Br0.15)3钙钛矿薄膜的光电性能影响，并利用NMR和ToF-SIMS技术探究其反应机理。

Result: 两种分子均能改善薄膜光电性能，但效果随沉积时间变化。AEAPTMS在优化条件下表现更优，而APTMS过量处理会导致性能下降。两种分子均与FA+阳离子发生反应。

Conclusion: 优化氨基硅烷类钝化剂的沉积条件对于平衡钝化效果和避免性能损失至关重要。揭示了氨基硅烷与卤化物钙钛矿之间先前未知的反应化学性质。

Abstract: Amino-silane-based surface passivation schemes are gaining attention in
halide perovskite optoelectronics, with varying levels of success. We compare
surface treatments using (3-aminopropyl)trimethoxysilane (APTMS) and
[3-(2-aminoethylamino)propyl]trimethoxysilane (AEAPTMS), applied via
room-temperature vacuum deposition, to the perovskite
FA0.78Cs0.22Pb(I0.85Br0.15)3 (FA = formamidinium). Both molecules improve
thin-film photoluminescence properties and photovoltaic device performance,
although their effectiveness depends strongly on deposition time. We show
AEAPTMS has a wider, more robust processing window and yields higher
performance under optimized conditions. In contrast, over-exposure,
particularly with APTMS, reduces performance, with notable reductions in
photoluminescence lifetime and absorbance. To probe the underlying chemistry,
we employ nuclear magnetic resonance (NMR) spectroscopy and depth-resolved
time-of-flight secondary ion mass spectrometry (ToF-SIMS), demonstrating that
both amino-silanes react with formamidinium (FA+) cations in solution and in
the solid state. This work underscores the importance of optimizing deposition
conditions to balance effective passivation with potential performance loss and
elucidates previously unrecognized reactive chemistry between amino-silane
passivating agents and halide perovskites.

</details>


### [124] [Link Statistics of Dislocation Network during Strain Hardening](https://arxiv.org/abs/2509.03743)
*Sh. Akhondzadeh,Hanfeng Zhai,Wurong Jian,Ryan B. Sills,Nicolas Bertin,Wei Cai*

Main category: cond-mat.mtrl-sci

TL;DR: 晶体中的位错线缺陷在应变硬化过程中会增殖并自组织成复杂的网络。位错链路的长度（连接网络中相邻节点）包含有关位错微结构演变的关键信息。通过分析面心立方（fcc）铜的离散位错动力学（DDD）模拟数据，我们对单个滑移系统上的位错网络链路长度的统计分布进行了表征。研究表明，活性滑移系统上的链路长度遵循双指数分布，而非活性滑移系统上的链路长度遵循单指数分布。观察到的双指数分布的独特长尾是由于活性滑移系统上的长链路的应力诱导的 the bowing out 效应，这种效应在去除外应力后会消失。我们进一步证明，通过扩展一维泊松过程并引入不同的增长函数，可以解释这两种观察到的链路长度分布。具体来说，当超过临界长度的链路的增长率变为超线性时，就会出现双指数分布，这与长链路在外应力作用下 the bowing out 的物理现象一致。这项工作增进了我们对晶体应变硬化过程中位错微结构演变的理解，并阐明了控制其形成的潜在物理机制。


<details>
  <summary>Details</summary>
Motivation: 应变硬化过程中位错网络中链路长度的统计分布包含关于位错微结构演变的关键信息，了解这些信息对于理解材料的力学行为至关重要。

Method: 通过对离散位错动力学（DDD）模拟数据进行分析，研究了面心立方（fcc）铜中位错网络链路长度的统计分布，并利用一维泊松过程的扩展来解释观察到的分布。

Result: 活性滑移系统上的位错链路长度遵循双指数分布，而非活性滑移系统遵循单指数分布。双指数分布的长尾是由于应力诱导的长链路 the bowing out 效应造成的，该效应在去除外应力后会消失。通过扩展一维泊松过程并引入超线性增长函数，成功解释了这两种分布。

Conclusion: 位错链路长度的分布特征（双指数分布和单指数分布）与位错微结构在应变硬化过程中的演变密切相关，并且可以通过包含不同增长函数的泊松过程模型来解释，特别是当长链路的 the bowing out 效应被考虑在内时。

Abstract: Dislocations are line defects in crystals that multiply and self-organize
into a complex network during strain hardening. The length of dislocation
links, connecting neighboring nodes within this network, contains crucial
information about the evolving dislocation microstructure. By analyzing data
from Discrete Dislocation Dynamics (DDD) simulations in face-centered cubic
(fcc) Cu, we characterize the statistical distribution of link lengths of
dislocation networks during strain hardening on individual slip systems. Our
analysis reveals that link lengths on active slip systems follow a
double-exponential distribution, while those on inactive slip systems conform
to a single-exponential distribution. The distinctive long tail observed in the
double-exponential distribution is attributed to the stress-induced bowing out
of long links on active slip systems, a feature that disappears upon removal of
the applied stress. We further demonstrate that both observed link length
distributions can be explained by extending a one-dimensional Poisson process
to include different growth functions. Specifically, the double-exponential
distribution emerges when the growth rate for links exceeding a critical length
becomes super-linear, which aligns with the physical phenomenon of long links
bowing out under stress. This work advances our understanding of dislocation
microstructure evolution during strain hardening and elucidates the underlying
physical mechanisms governing its formation.

</details>


### [125] [Physically Interpretable Descriptors Drive the Materials Design of Metal Hydrides for Hydrogen Storage](https://arxiv.org/abs/2509.04039)
*Seong-Hoon Jang,Di Zhang,Hung Ba Tran,Xue Jia,Kiyoe Konno,Ryuhei Sato,Shin-ichi Orimo,and Hao Li*

Main category: cond-mat.mtrl-sci

TL;DR: 本文首次提出了用于预测氢化物的两种关键性能指标（重量氢密度w和室温平衡压力Peq,RT）的物理可解释模型。


<details>
  <summary>Details</summary>
Motivation: 设计用于储氢的金属氢化物因其广泛的成分空间和复杂的结构-性质关系而成为一个长期存在的挑战。

Method: 利用包含5089种金属氢化物组成的、经过严格筛选的数据集，结合标量变换和非线性链接函数，构建了超过160万个候选模型。最终的解析模型每个仅使用2-3个描述符，预测精度与最先进的机器学习方法相当，同时保持了完整的物理透明度。

Result: 基于这些模型生成的描述符设计图揭示了w和Peq,RT之间存在根本性的权衡：含碱金属的氢化物具有高的w但低的Peq,RT，而基于较重负性过渡金属的间隙型氢化物则显示出相反的趋势。特别是，基于铍（Be）的系统，如Be-Na合金，因其独特的轻质和高摩尔密度特性，成为少数同时满足这两个性能指标的候选材料。

Conclusion: 本文提出的模型为材料设计提供了化学直观的指导，并为在复杂化学空间中合理发现材料建立了一个可扩展的框架。基于铍的系统可能为接近这些基准提供新的前景。

Abstract: Designing metal hydrides for hydrogen storage remains a longstanding
challenge due to the vast compositional space and complex structure-property
relationships. Herein, for the first time, we present physically interpretable
models for predicting two key performance metrics, gravimetric hydrogen density
$w$ and equilibrium pressure $P_{\rm eq,RT}$ at room temperature, based on a
minimal set of chemically meaningful descriptors. Using a rigorously curated
dataset of $5,089$ metal hydride compositions from our recently developed
Digital Hydrogen Platform (\it{DigHyd}) based on large-scale data mining from
available experimental literature of solid-state hydrogen storage materials, we
systematically constructed over $1.6$ million candidate models using
combinations of scalar transformations and nonlinear link functions. The final
closed-form models, derived from $2$-$3$ descriptors each, achieve predictive
accuracies on par with state-of-the-art machine learning methods, while
maintaining full physical transparency. Strikingly, descriptor-based design
maps generated from these models reveal a fundamental trade-off between $w$ and
$P_{\rm eq,RT}$: saline-type hydrides, composed of light electropositive
elements, offer high $w$ but low $P_{\rm eq,RT}$, whereas interstitial-type
hydrides based on heavier electronegative transition metals show the opposite
trend. Notably, Be-based systems, such as Be-Na alloys, emerge as rare
candidates that simultaneously satisfy both performance metrics, attributed to
the unique combination of light mass and high molar density for Be. Our models
indicate that Be-based systems may offer renewed prospects for approaching
these benchmarks. These results provide chemically intuitive guidelines for
materials design and establish a scalable framework for the rational discovery
of materials in complex chemical spaces.

</details>


### [126] [Thickness-Induced Topological Phase Transition Investigated by Helicity Dependent Photocurrent in $α$-Sn/CdTe(110)](https://arxiv.org/abs/2509.04042)
*Tengfei Liu,Xiyu Hong,Zhe Li,Shenzhong Chen,Leyi Li,Xin-Yi Tang,Shuying Cheng,Yunfeng Lai,Yonghai Chen,Zhu Diao,Ke He,Qi-kun Xue,Jinling Yu*

Main category: cond-mat.mtrl-sci

TL;DR: $\\alpha$-Sn薄膜厚度变化引起拓扑相变，可通过光电流探测。5nm为2D TI，10nm和30nm为3D TI。


<details>
  <summary>Details</summary>
Motivation: $\\alpha$-Sn具有丰富的拓扑相图，但实验上调控和区分这些相的方法有限。

Method: 通过分子束外延在CdTe(110)上生长不同厚度的$\\alpha$-Sn薄膜，并研究其螺旋光电流（HDPC）。结合高分辨率透射电子显微镜（HR-TEM）、点群对称性分析和第一性原理计算，揭示了从2D到3D拓扑绝缘体的相变。

Result: 5nm $\\alpha$-Sn薄膜的HDPC表现出入射角的奇函数依赖性，而10nm和30nm薄膜则表现出偶函数依赖性。相变发生在5nm和10nm之间。

Conclusion: HDPC是探测拓扑相变的灵敏工具。$\\alpha$-Sn(110)薄膜的电子特性可调，可以通过厚度和应变调控拓扑态，为探索拓扑现象和开发自旋基器件提供平台。

Abstract: $\alpha$-Sn exhibits a rich topological phase diagram, yet experimental
methods to tune and distinguish these phases remain limited. Here, we
investigated the helicity-dependent photocurrent (HDPC) in $\alpha$-Sn films of
varying thickness grown on CdTe(110) by molecular beam epitaxy. The HDPC of the
5 nm $\alpha$-Sn film shows an odd-function dependence on incident angle,
whereas that of the 10 and 30 nm films exhibit an even-function dependence.
Combined with high-resolution transmission electron microscopy (HR-TEM),
point-group symmetry analysis, and first-principles calculations, it is
revealed that a thickness-driven topological phase transition from a two
dimensional (2D) to a three dimensional (3D) topological insulator occurs
between 5 and 10 nm. These results demonstrate that HDPC serves as a sensitive
diagnostic tool for topological phase transitions. The tunable electronic
properties of $\alpha$-Sn(110) films enable thickness- and strain-mediated
control of topological states, establishing a versatile platform for exploring
emerging topological phenomena and developing spin-based devices.

</details>


### [127] [Grain boundary energy models and boundary splitting](https://arxiv.org/abs/2509.04109)
*Adam Morawiec*

Main category: cond-mat.mtrl-sci

TL;DR: 文章提出了晶界能量模型的新方法，考虑了晶界解离的可能性，并通过不等式约束来防止不必要的能量减少，适用于多晶材料的模拟。


<details>
  <summary>Details</summary>
Motivation: 预测多晶材料行为需要晶界能量模型。现有模型通常将最小边界能量表示为宏观边界参数的函数，但未充分考虑晶界解离（即通过将边界分裂成两个平行边界来进一步降低总能量）的可能性。

Method: 通过引入不等式约束来防止晶界解离，这些约束条件与边界润湿条件相反，并只适用于满足特定几何构型的三元组边界。文章推导了这些边界参数之间的关系，并分析了防止边界分裂的不等式的影响。

Result: 文章展示了一个能量模型示例，该模型允许边界分解，并考虑了防止边界分裂的不等式的影响。识别允许边界解离的能量模型以及哪些边界可能受到影响，对于评估模型在多晶模拟中的性能至关重要。

Conclusion: 通过引入约束条件，可以更精确地模拟晶界行为，避免不必要的能量降低，从而提高多晶材料模拟的准确性。

Abstract: Models of grain boundary energy are essential for predicting the behavior of
polycrystalline materials. Typical models represent the minimum boundary energy
as a function of macroscopic boundary parameters. An energy model may allow for
boundary dissociation, i.e., for a further reduction of the overall energy by
splitting a boundary into two boundaries parallel to the original one. Such
splitting is prevented by constraining the energy model with inequalities
opposite to the boundary wetting condition. The inequalities are applicable
only to triplets of boundaries that match the assumed geometric configuration.
Relationships connecting the parameters of such boundaries are derived,
implications of the inequalities that prevent boundary splitting are
considered, and an example energy model is shown to allow boundary
decomposition. Knowing whether a given energy model permits boundary
dissociation and which boundaries can be affected is important for evaluating
its performance in polycrystal simulations.

</details>


### [128] [Local structural disorder in crystalline materials](https://arxiv.org/abs/2509.04171)
*Marios Zacharias,Jacky Even*

Main category: cond-mat.mtrl-sci

TL;DR: 本地无序性影响软、非谐材料的性质，本文介绍了模拟本地无序性的新方法，并强调了其在电子-声子相互作用和输运性质中的作用。


<details>
  <summary>Details</summary>
Motivation: 软、非谐材料中的局部无序性对电子、振动、光学和输运性质有重要影响，但通常被视为性能下降的因素。然而，近期的理论研究表明，局部无序性深刻地影响电子结构和声子动力学，且不一定会导致深的电子陷阱或非辐射复合。这促使我们深入研究其影响并探索其潜在应用。

Method: 本文提出并强调了使用多晶形和非谐框架对局部无序性进行建模的进展。这些方法能够解释实验观测结果，并预测新的趋势。

Result: 研究结果表明，局部无序性在声子准粒子图像的分解中起着关键作用，并能调节电子-声子和声子-声子相互作用。特别是在软、非谐物相中，这种调节对电和热输运有显著影响。

Conclusion: 局部无序性是影响软、非谐材料性质的关键因素。通过结合先进的第一性原理方法和机器学习，可以为能源材料提供预测性建模，并为利用无序性实现材料性能调控提供新的机遇。

Abstract: Local positional disorder in soft, anharmonic materials has emerged as a
central factor in shaping their electronic, vibrational, optical, and transport
properties. Viewed mainly as a source of performance degradation, recent
theoretical insights reveal that local disorder profoundly influences the
electronic structure and phonon dynamics, without inducing deep electronic
traps or non-radiative recombination pathways. In this work, we highlight
advances in modeling local disorder using polymorphous and anharmonic
frameworks, showing how these methods explain experimental observations and
predict new trends. We emphasize the role of disorder in the breakdown of the
phonon quasiparticle picture and in modulating electron-phonon and
phonon-phonon interactions, particularly in soft, anharmonic phases of matter,
with significant effects on electrical and thermal transport. We outline
opportunities for integrating these insights into predictive modeling for
energy materials and propose combining advanced first-principles methods with
machine learning.

</details>


### [129] [Morphology Formation Pathways in Solution-Processed Perovskite Thin Films](https://arxiv.org/abs/2509.04175)
*M. Majewski,O. J. J. Ronsin,J. Harting*

Main category: cond-mat.mtrl-sci

TL;DR: 通过建立几何模型研究了溶剂蒸发和晶体生长对溶液加工薄膜形貌的影响，发现了11种成膜机制和4种不同的薄膜形貌，并提出了优化工艺参数以获得所需形貌的方法，该模型具有普适性。


<details>
  <summary>Details</summary>
Motivation: 溶液加工钙钛矿太阳能电池活性层的成膜机制尚不完全清楚，需要更深入的理解以实现大规模生产。

Method: 开发了一个几何模型，研究溶剂蒸发和晶体生长之间的相互作用对干膜形貌的影响，并根据加工条件研究了可能的成膜机制。

Result: 发现了11种成膜机制，可导致4种不同的薄膜形貌。通过调整工艺参数以适应材料特性，可以利用这些成膜机制。当蒸发速率远高于晶体生长速率时，可以制备出无针孔和平整的薄膜。或者，在低干燥速率下，通过在基板上提供高晶体数密度也可以获得所需的薄膜形貌。

Conclusion: 该模型具有普适性，适用于任何同时蒸发和结晶的薄膜，为优化溶液加工薄膜的形貌提供了理论指导。

Abstract: The active layer in a perovskite solar cell is usually composed of a
polycrystalline thin film. Fabrication of this layer by solution processing is
a promising candidate for up-scaling to the mass market. However, the evolution
of an evaporating and simultaneously crystallizing thin film is not yet fully
understood. To contribute to the understanding of the formation of thin films,
we develop a geometrical model that deals with the effect of the interplay
between solvent evaporation and crystal growth on the dry film morphology. The
possible film formation mechanisms are investigated, depending on the
processing conditions. We find eleven formation pathways leading to four
distinct morphologies. It is shown how these formation pathways can be utilized
by adapting the process parameters to the material properties. Pinhole-free and
flat films can be fabricated if the evaporation rate is high in comparison to
the crystal growth rate. Alternatively, providing a high crystal number density
on the substrate can lead to the desired film morphology at low drying rates.
The generality of the model makes it applicable to any evaporating and
simultaneously crystallizing thin film.

</details>


### [130] [Nature of magnetic exchange interactions in kagome antiferromagnets FeGe and FeSn](https://arxiv.org/abs/2509.04228)
*Yitao Zheng,Yan Zhu,Jun Hu*

Main category: cond-mat.mtrl-sci

TL;DR: kagome反铁磁体FeGe和FeSn中的磁交换相互作用（MEIs）具有丰富的特征，并可能产生奇异的量子态。通过第一性原理计算，研究人员发现，尽管层间耦合起源于相邻kagome层之间的反铁磁序，但Fe原子在每个kagome层内通过铁磁偶联而耦合，这源于有利的铁磁相互作用和有利的反铁磁相互作用之间的竞争。


<details>
  <summary>Details</summary>
Motivation: 研究kagome反铁磁体FeGe和FeSn中的磁交换相互作用（MEIs）的丰富特征，以及它们产生的奇异量子态。

Method: 通过第一性原理计算，系统地研究了kagome反铁磁体FeGe和FeSn中的MEIs。

Result: 研究发现，FeGe中的MEI比FeSn强，RKKY相互作用比FeSn弱，因此FeGe的Néel温度远高于FeSn。此外，这两种材料中相邻的交换能量与Fe-Fe键长近似呈线性关系，适度的压缩应变可以显著提高它们的Néel温度。

Conclusion: kagome反铁磁体FeGe和FeSn中的MEIs可以通过第一性原理计算来研究。MEIs的特征源于电荷、自旋、轨道和晶格自由度的相互作用。FeGe和FeSn的Néel温度可以通过改变Fe-Fe键长来调节。

Abstract: Magnetic exchange interactions (MEIs) in kagome magnets exhibit rich features
due to the interplay of charge, spin, orbital and lattice degrees of freedom,
giving rise to a variety of exotic quantum states. Through first-principles
calculations, we systematically investigate the MEIs in kagome antiferromagnets
FeGe and FeSn. While the antiferromagnetic order originates from the interlayer
coupling between neighboring kagome layers, Fe atoms within each kagome layer
couple ferromagnetically, driven by the competition between ferromagnetically
favorable direct MEIs and antiferromagnetically favorable
Ruderman-Kittel-Kasuya-Yosida (RKKY) interactions. The stronger direct MEIs but
weaker RKKY interactions in FeGe result in a substantially higher N\'eel
temperature with respect to FeSn. Interestingly, the nearest neighboring
exchange energy in both materials approximately linearly depends on the Fe-Fe
bond length, so that moderate compressive strain can significantly enhance
their N\'eel temperatures.

</details>


### [131] [Interactions in Rare Earth Doped Nanoparticles: A Multi-Transition, Concentration, and Excitation Path Analysis](https://arxiv.org/abs/2509.04233)
*Pauline Perrin,Luiz Fernando Dos Santos,Diana Serrano,Alexey Tiranov,Jocelyn Achard,Alexandre Tallaire,Rogéria R. Gonçalves,Philippe Goldner*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究通过直接和 upconversion 激发，在 Y2O3 纳米粒子中研究了 Yb3+ 和 Er3+ 离子的光致发光动力学，并使用速率方程模型成功解释了能量转移机制。


<details>
  <summary>Details</summary>
Motivation: 为了推进稀土掺杂纳米材料在生物成像、光学测温和固态激光器中的应用，理解和建模其能量转移机制至关重要。

Method: 研究测量了在宽浓度范围内（0.5-17%）的 Yb3+ 和 Er3+ 掺杂的 Y2O3 纳米粒子的绿色、红色和近红外跃迁的发光衰减，并使用包含辐射和非辐射过程、能量转移机制和缺陷相关猝灭的速率方程模型进行了分析。

Result: 所提出的模型成功地在大多数浓度和激发路径下重现了实验趋势。

Conclusion: 这项工作为稀土掺杂材料的能量转移建模提供了一个可靠且可预测的框架，并为优化纳米结构系统的光致发光特性提供了宝贵的见解。

Abstract: Understanding and modeling energy transfer mechanisms in rare-earth-doped
nanomaterials is essential for advancing luminescent technologies used in
bioimaging, optical thermometry, and solid-state lasers. In this work, we
investigate the photoluminescence dynamics of Yb3+ and Er3+ ions in Y2O3
nanoparticles over a wide concentration range (0.5-17%), using both direct and
upconversion excitation. Luminescence decays of green, red, and near-infrared
transitions were measured and analyzed using a rate-equation model
incorporating radiative and non-radiative processes, energy transfer
mechanisms, and defect-related quenching. The model successfully reproduces
experimental trends across most concentrations and excitation paths. This work
provides a reliable and predictive framework for modeling energy transfer in
rare-earth doped materials and offers valuable insights for optimizing
photoluminescent properties in nanostructured systems.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [132] [Multi-Sensor Fusion for Extended Object Tracking Exploiting Active and Passive Radio Signals](https://arxiv.org/abs/2509.03686)
*Hong Zhu,Alexander Venus,Erik Leitinger,Klaus Witrisal*

Main category: eess.SP

TL;DR: 该论文提出了一种新的贝叶斯方法，通过融合主动测量和被动雷达测量来解决无线设备在视线受阻情况下的精确定位问题，并开发了一种多传感器、多测量概率数据关联算法来处理测量源不确定性。


<details>
  <summary>Details</summary>
Motivation: 解决由于多径传播、硬件缺陷、信号干扰以及用户自身遮挡导致的无线设备定位不准确的问题，尤其是在视线被遮挡的情况下。

Method: 提出一种贝叶斯方法，融合设备与基站之间的“主动”测量和基站之间、经扩展目标（EO，如用户身体）反射的“被动”多站雷达类型测量。引入多传感器、多测量概率数据关联（PDA）算法来处理测量源不确定性，并开发了针对人体用户的EO模型，考虑了身体表面的多次反射。

Result: 所提出的算法在合成和真实无线电测量评估中，相较于传统的基于点目标假设的PDA方法，在视线受阻（OLOS）期间及之后表现更优。

Conclusion: 该方法能够更准确地进行定位，尤其是在视线受阻的情况下，通过将用户建模为扩展目标并融合多种测量类型来实现。

Abstract: Reliable and robust positioning of radio devices remains a challenging task
due to multipath propagation, hardware impairments, and interference from other
radio transmitters. A frequently overlooked but critical factor is the agent
itself, e.g., the user carrying the device, which potentially obstructs
line-of-sight (LOS) links to the base stations (anchors). This paper addresses
the problem of accurate positioning in scenarios where LOS links are partially
blocked by the agent. The agent is modeled as an extended object (EO) that
scatters, attenuates, and blocks radio signals. We propose a Bayesian method
that fuses ``active'' measurements (between device and anchors) with
``passive'' multistatic radar-type measurements (between anchors, reflected by
the EO). To handle measurement origin uncertainty, we introduce an multi-sensor
and multiple-measurement probabilistic data association (PDA) algorithm that
jointly fuses all EO-related measurements. Furthermore, we develop an EO model
tailored to agents such as human users, accounting for multiple reflections
scattered off the body surface, and propose a simplified variant for
low-complexity implementation. Evaluation on both synthetic and real radio
measurements demonstrates that the proposed algorithm outperforms conventional
PDA methods based on point target assumptions, particularly during and after
obstructed line-of-sight (OLOS) conditions.

</details>


### [133] [Sensor placement for sparse force reconstruction](https://arxiv.org/abs/2509.03825)
*Jeunghoon Lee*

Main category: eess.SP

TL;DR: 本研究提出了一种基于格拉姆矩阵的传感器放置策略，用于在频域中进行稀疏力重建。通过对格拉姆矩阵进行模态分解，发现其结构主要由目标频率附近的几个模态决定，并且每个模态的贡献反映了相应模态形状的空间相关性。这表明，将传感器放置在空间相关性较低的节点区域附近，可以降低频响函数（FRF）矩阵的相干性，提高力的重建精度。为了将物理洞察转化为实用的设计框架，提出了一种贪婪算法来选择能最小化格拉姆矩阵的非对角线能量的传感器位置。数值模拟和实验验证表明，所提出的方法能够进行鲁棒且准确的力估计，优于启发式的传感器布局。


<details>
  <summary>Details</summary>
Motivation: 在频域稀疏力重建中，传感器的放置位置对重建精度至关重要。本研究旨在提出一种基于格拉姆矩阵的传感器放置策略，以优化传感器布局，提高重建准确性。

Method: 提出了一种基于格拉姆矩阵的传感器放置策略。首先对格拉姆矩阵进行模态分解，分析其结构与模态贡献的关系。然后，提出一种贪婪算法，通过最小化格拉姆矩阵的非对角线能量来选择传感器位置。

Result: 数值模拟和实验验证结果表明，该方法能够进行鲁棒且准确的力估计，并且优于启发式的传感器布局。

Conclusion: 所提出的基于格拉姆矩阵的传感器放置策略，通过优化传感器布局，能够有效提高频域稀疏力重建的准确性和鲁棒性。

Abstract: The present study proposes a Gram-matrix-based sensor placement strategy for
sparse force reconstruction in the frequency domain. A modal decomposition of
the Gram matrix reveals that its structure is dominated by a few modes near the
target frequency, and that each modal contribution reflects the spatial
correlation of the corresponding mode shape. This suggests that placing sensors
near nodal regions where spatial correlation is low can reduce coherence in the
frequency response function (FRF) matrix and improve force reconstruction
accuracy. To translate the physical insight into a practical design framework,
a greedy algorithm is proposed to select sensor locations that minimize the
off-diagonal energy of the Gram matrix. Numerical simulations and experimental
validations demonstrate that the proposed method yields robust and accurate
force estimation, outperforming heuristic sensor layouts.

</details>


### [134] [A Low-Cost Open-Source BLE-Based Asian Hornet Tracking System](https://arxiv.org/abs/2509.03979)
*Gilles Callebaut,Jan Van Moer*

Main category: eess.SP

TL;DR: 该研究提出了一种基于低成本蓝牙低功耗（BLE）的亚洲黄蜂（Vespa velutina）追踪系统，该系统使用自定义的伪噪声（PN）序列和数字波束扫描技术来定位黄蜂巢穴，并在50米处实现了可靠的角度分辨率和最远360米的通信距离。


<details>
  <summary>Details</summary>
Motivation: 亚洲黄蜂对生态系统和养蜂业构成严重威胁，而定位其巢穴通常需要耗时的人工三角测量。因此，开发一种高效、低成本的追踪系统是必要的。

Method: 本研究提出了一种基于BLE的追踪系统，包括轻量级BLE标签和GNU Radio实现的软件定义无线电（SDR）接收器。该系统通过绕过BLE堆栈，在未编码的PHY中嵌入自定义PN序列进行基于相关检测，并利用定向天线和SDR进行数字波束扫描以确定标签方向。

Result: 野外测试表明，该系统在50米距离内具有可靠的角度分辨率，通信距离可达360米。该调制方式虽然增加了接收器的复杂性，但为未来实现多通道扩展和标签识别等功能奠定了基础。

Conclusion: 该研究提出的全开源BLE追踪系统为亚洲黄蜂追踪和环境监测等相关应用提供了一个可扩展的框架，有望解决传统巢穴定位方法的不足。

Abstract: The Asian hornet (Vespa velutina) poses a serious threat to ecosystems and
beekeeping. Locating nests is essential, but usually involves time-consuming
manual triangulation. We present a low-cost, open-source tracking system based
on Bluetooth Low Energy (BLE). The system consists of a lightweight BLE tag and
a software-defined radio (SDR) receiver implemented in GNU Radio. By bypassing
the BLE stack, we embed a custom pseudo-noise (PN) sequence in the uncoded PHY
for correlation-based detection. Using a Yagi antenna and PlutoSDR, the
receiver performs digital beam sweeping to determine the tag's direction. Field
tests show reliable angular resolution at 50m and a communication range up to
360m. While our modulation increases receiver complexity, it enables future
improvements such as multichannel spreading and tag identification. The design
is fully open-source and provides a scalable framework for hornet tracking and
related applications in environmental monitoring.

</details>


### [135] [Approximate Message Passing for Multi-Preamble Detection in OTFS Random Access](https://arxiv.org/abs/2509.03980)
*Alessandro Mirri,Vishnu Teja Kunde,Enrico Paolini,Jean-Francois Chamberland*

Main category: eess.SP

TL;DR: OTFS随机接入系统中的多前导码检测被建模为一个结构化稀疏恢复问题，并提出了一种新的近似消息传递（AMP）算法，通过利用双稀疏性（前导码稀疏性和OTFS信号的延迟-多普勒域稀疏性）来实现鲁棒的检测。


<details>
  <summary>Details</summary>
Motivation: 解决基于OTFS信号的随机接入系统中多前导码检测的问题。

Method: 将问题建模为复数域的结构化稀疏恢复问题，并提出一种新的近似消息传递（AMP）算法，该算法强制执行双稀疏性（前导码稀疏选择和OTFS信号在延迟-多普勒域的固有稀疏性），并通过设计一种新颖的AMP去噪器来处理非可分离的复数稀疏约束。

Result: 仿真结果表明，所提出的方法实现了鲁棒的检测性能，并提供了相对于现有技术的显著优势。

Conclusion: 所提出的AMP算法在OTFS随机接入系统的多前导码检测方面，相较于现有技术，能实现鲁棒且有显著性能增益的检测。

Abstract: This article addresses the problem of multiple preamble detection in random
access systems based on orthogonal time frequency space (OTFS) signaling. This
challenge is formulated as a structured sparse recovery problem in the complex
domain. To tackle it, the authors propose a new approximate message passing
(AMP) algorithm that enforces double sparsity: the sparse selection of
preambles and the inherent sparsity of OTFS signals in the delay-Doppler
domain. From an algorithmic standpoint, the non-separable complex sparsity
constraint necessitates a careful derivation and leads to the design of a novel
AMP denoiser. Simulation results demonstrate that the proposed method achieves
robust detection performance and delivers significant gains over
state-of-the-art techniques.

</details>


### [136] [Joint Frequency-Space Sparse Reconstruction for DOA Estimation under Coherent Sources and Amplitude-Phase Errors](https://arxiv.org/abs/2509.03983)
*Yutong Chen,Cong Zhou,Changsheng You,Shuo Shi*

Main category: eess.SP

TL;DR: 提出了一种联合频空稀疏重建方法，用于解决相干源和阵列幅度相位误差下的DOA估计问题。


<details>
  <summary>Details</summary>
Motivation: 为了有效解决相干源和阵列幅度相位误差对DOA估计的影响。

Method: 利用辅助源构建实数导向矢量（RSVs）来补偿幅度相位误差，并利用频域快照数据的谱稀疏性和入射方向的空间稀疏性进行DOA估计，该方法无需迭代优化，计算复杂度低。

Result: 提出的DOA估计方法在相干源情况下，相比于现有基准方案具有更高的估计精度。

Conclusion: 该方法能够有效处理相干源和阵列幅度相位误差，并实现高精度的DOA估计。

Abstract: In this letter, we propose a joint frequency-space sparse reconstruction
method for direction-of-arrival (DOA) estimation, which effectively addresses
the issues arising from the existence of coherent sources and array
amplitude-phase errors. Specifically, by using an auxiliary source with known
angles, we first construct the real steering vectors (RSVs) based on the
spectral peaks of received signals in the frequency domain, which serve as a
complete basis matrix for compensation for amplitude-phase errors. Then, we
leverage the spectral sparsity of snapshot data in the frequency domain and the
spatial sparsity of incident directions to perform the DOA estimation according
to the sparse reconstruction method. The proposed method does not require
iterative optimization, hence exhibiting low computational complexity.
Numerical results demonstrate that the proposed DOA estimation method achieves
higher estimation accuracy for coherent sources as compared to various
benchmark schemes.

</details>


### [137] [Robust MIMO Semantic Communication with Imperfect CSI via Knowledge Distillation](https://arxiv.org/abs/2509.04005)
*Mingze Gong,Shuoyao Wang,Shijian Gao,Jia Yan,Suzhi Bi*

Main category: eess.SP

TL;DR: MIMO SemComm 系统在信道估计不准确时性能会下降，本文提出了HANA-JSCC系统，通过信道矩阵适配器和两阶段训练策略解决了该问题，并在实验中取得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有MIMO SemComm系统假设信道状态信息（CSI）估计完美，这在实际中难以实现，导致性能下降。

Method: 提出了一种名为HANA-JSCC的语义图像传输系统，包含一个信道矩阵适配器，用于处理CSI估计误差，并采用包含知识蒸馏的两阶段训练策略来解决因信道估计不精确导致的问题。

Result: 与现有技术相比，HANA-JSCC在不同噪声和估计误差水平下，在多个数据集上平均性能提高了0.40-0.54dB。

Conclusion: HANA-JSCC能够有效处理MIMO SemComm系统中的信道估计误差，提高了系统的鲁棒性和性能。

Abstract: Semantic communication (SemComm) has emerged as a new communication paradigm.
To enhance efficiency, multiple-input-multiple-output (MIMO) technology has
been further integrated into SemComm systems. However, existing MIMO SemComm
systems assume perfect channel matrix estimation for channel-adaptive joint
source-channel coding, which is impractical due to hardware and pilot overhead
constraints. In this paper, we propose a semantic image transmission system
with channel matrix and channel noise adaptation, named HANA-JSCC, to cope with
channel estimation errors in MIMO systems. We propose a channel matrix adaptor
that collaborates with the channel codec to adapt to misaligned channel state
information, thereby mitigating the impact of estimation errors. Since the
relationship between the estimated channel matrix and true channel matrix is
ill-posed (one-to-many), we further introduce a two-stage training strategy
with knowledge distillation to overcome the convergence difficulties caused by
the ill-posed problem. Comparing with the state-of-the-art benchmarks,
HANA-JSCC achieves $0.40\sim0.54$dB higher average performance across various
noise and estimation error levels in various datasets.

</details>


### [138] [Constellation Shaping for OFDM-ISAC Systems: From Theoretical Bounds to Practical Implementation](https://arxiv.org/abs/2509.04055)
*Benedikt Geiger,Fan Liu,Shihang Lu,Andrej Rode,Daniel Gil Gaviria,Charlotte Muth,Laurent Schmalen*

Main category: eess.SP

TL;DR: 本论文研究正交频分复用（OFDM）基ISAC系统中星座整形技术，以解决通信和感知（S&C）之间因调制格式冲突而产生的性能权衡问题。


<details>
  <summary>Details</summary>
Motivation: 通信和感知（S&C）对调制格式的要求存在冲突，导致性能权衡。本论文旨在通过星座整形技术，在OFDM基ISAC系统中同时提升S&C性能。

Method: 推导了传输符号如何影响检测性能，并推导了在给定感知约束下最大可实现信息率的理论上下界。利用基于自编码器的优化，研究了几何、概率和联合星座整形。还研究了概率幅度整形（PAS）的推广，并提出了一种低复杂度对数似然比计算方法。

Result: 结果表明，星座整形可以在S&C之间实现灵活的权衡，性能接近理论上限，并显著优于传统调制格式。提出的PAS推广方法可以实现低复杂度、灵活的S&C权衡，性能接近联合星座整形。

Conclusion: 星座整形是提高OFDM基ISAC系统S&C性能的有效方法，提出的PAS推广方法具有实际应用潜力。

Abstract: Integrated sensing and communications (ISAC) promises new use cases for
mobile communication systems by reusing the communication signal for radar-like
sensing. However, sensing and communications (S&C) impose conflicting
requirements on the modulation format, resulting in a tradeoff between their
corresponding performance. This paper investigates constellation shaping as a
means to simultaneously improve S&C performance in orthogonal frequency
division multiplexing (OFDM)-based ISAC systems. We begin by deriving how the
transmit symbols affect detection performance and derive theoretical lower and
upper bounds on the maximum achievable information rate under a given sensing
constraint. Using an autoencoder-based optimization, we investigate geometric,
probabilistic, and joint constellation shaping, where joint shaping combines
both approaches, employing both optimal maximum a-posteriori decoding and
practical bit-metric decoding. Our results show that constellation shaping
enables a flexible trade-off between S&C, can approach the derived upper bound,
and significantly outperforms conventional modulation formats. Motivated by its
practical implementation feasibility, we review probabilistic amplitude shaping
(PAS) and propose a generalization tailored to ISAC. For this generalization,
we propose a low-complexity log-likelihood ratio computation with negligible
rate loss. We demonstrate that combining conventional and generalized PAS
enables a flexible and low-complexity tradeoff between S&C, closely approaching
the performance of joint constellation shaping.

</details>


### [139] [Reliable Clutter Suppression for Slow-Moving Weak Target Radar Detection](https://arxiv.org/abs/2509.04309)
*R. Zhang,J. Xue,T. Zhang*

Main category: eess.SP

TL;DR: 该论文提出了一种基于Go分解（Godec）框架的新型杂波抑制方案，用于在复杂环境中可靠地检测慢速移动的弱目标，解决了传统MTI可能抑制所需目标的问题。


<details>
  <summary>Details</summary>
Motivation: 在复杂环境中，由于周围强反射体的遮蔽效应，可靠地检测慢速移动的弱目标是一个挑战。传统的移动目标显示（MTI）技术可能会抑制来自静态干扰物（IOs）以及期望的慢速移动弱目标的回波。

Method: 利用不同雷达扫描中距离-速度图的低秩和稀疏特性，提出了一种基于Go分解（Godec）框架的新型杂波抑制方案。

Result: 仿真结果表明，在存在遮蔽效应的情况下，基于Godec杂波抑制的目标检测方案与传统的基于MTI的方案相比，能够可靠地检测到慢速移动的弱目标。此外，还进行了时间消耗比较，表明所提出的解决方案牺牲了时间复杂度以换取增强的可靠性。

Conclusion: 该研究揭示了虚警单元数量、检测概率和收敛迭代次数之间的权衡，为该解决方案在实际应用中的参数设置提供了指导。实验验证也证实了该解决方案，并提供了关于该解决方案最适用场景的进一步见解。

Abstract: Reliable slow-moving weak target detection in complicated environments is
challenging due to the masking effects from the surrounding strong reflectors.
The traditional Moving Target Indication (MTI) may suppress the echoes from not
only the static interference objects (IOs), but also the desired slow-moving
weak target. According to the low-rank and sparse properties of the
range-velocity maps across different radar scans, a novel clutter suppression
scheme based on the Go decomposition (Godec) framework is proposed in this
paper. The simulation results show that with the existence of masking effects,
the target detection scheme based on Godec clutter suppression can reliably
detect the slow-moving weak target, compared to the traditional MTI-based
scheme. Besides, the time consumption comparison is conducted, demonstrating
that the proposed solution is one that sacrifices time complexity in exchange
for enhanced reliability. Additionally, the tradeoffs among the number of false
alarm cells, the detection probability and the iteration times for convergence
have been revealed, guiding parameter settings of the proposed solution in
practical applications. Experiment validation is also conducted to verify the
proposed solution, providing further insight into the scenarios where the
solution is most applicable.

</details>


### [140] [Relative Localization of UAV Swarms in GNSS-Denied Conditions](https://arxiv.org/abs/2509.04412)
*Guangyu Lei,Yuqi Ping,Tianhao Liang,Huahao Ding,Tingting Zhang*

Main category: eess.SP

TL;DR: 该论文提出了一种基于聚类的无人机集群相对定位框架，利用通信信号进行信道估计和测距，解决了现有方法在大规模集群中定位误差大和计算复杂度高的问题。


<details>
  <summary>Details</summary>
Motivation: 在GNSS受限环境中，无人机集群的相对定位对于应急救援和战场侦察至关重要，但现有方法存在定位误差大和计算复杂度高的问题。

Method: 首先，利用谱聚类将无人机集群划分为不同的子集群，然后利用矩阵补全和多维尺度变换获得高精度的相对坐标。接着，通过集群间锚点融合创建全局地图。最后，在无人机通信与感知一体化（ISAC）系统的案例研究中，采用OTFS进行测距和通信。

Result: 实验结果表明，该方法能减小大规模集群的定位误差和测距信息丢失，并探讨了信号参数对通信和定位的影响，突出了通信和定位性能之间的相互作用。

Conclusion: 所提出的基于聚类的框架能够有效提高无人机集群在GNSS受限环境下的相对定位精度，并为通信和定位的协同优化提供了参考。

Abstract: Relative localization of unmanned aerial vehicle (UAV) swarms in global
navigation satellite system (GNSS) denied environments is essential for
emergency rescue and battlefield reconnaissance. Existing methods suffer from
significant localization errors among UAVs due to packet loss and high
computational complexity in large swarms. This paper proposes a
clustering-based framework where the UAVs simultaneously use communication
signals for channel estimation and ranging. Firstly, the spectral clustering is
utilized to divide the UAV swarm into different sub-clusters, where matrix
completion and multidimensional scaling yield high-precision relative
coordinates. Subsequently, a global map is created by the inter-cluster anchor
fusion. A case study of UAV integrated communication and sensing (ISAC) system
is presented, where the Orthogonal Time Frequency Space (OTFS) is adopted for
ranging and communication. Experimental results show that the proposed method
reduces localization errors in large swarms and loss of range information. It
also explores the impact of signal parameters on communication and
localization, highlighting the interplay between communication and localization
performance.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [141] [A Cegar-centric Bounded Reachability Analysis for Compositional Affine Hybrid Systems](https://arxiv.org/abs/2509.03560)
*Atanu Kundu,Pratyay Sarkar,Rajarshi Ray*

Main category: cs.LO

TL;DR: 本论文提出了一种基于CEGAR的有界可达性分析算法，用于解决组合混合系统的可达性分析挑战，该算法通过在离散抽象中搜索反例，并结合符号可达性分析进行状态空间细化，以避免显式计算乘积自动机，从而提高了效率和可伸缩性。


<details>
  <summary>Details</summary>
Motivation: 组合混合系统的可达性分析面临独特挑战，包括保持组合语义、计算系统行为以及处理乘积自动机中位置数量的爆炸性增长。

Method: 提出一种基于CEGAR的有界可达性分析算法，用于具有分段仿射动态的组合混合系统。该算法在不显式计算乘积自动机的情况下，在组合模型的离散抽象中搜索反例。当在抽象中发现反例时，通过由抽象反例引导的状态空间细化来验证其有效性。状态空间细化通过符号可达性分析实现，并混合了不同的组合语义以提高效率（在抽象状态空间探索中使用步进组合语义，在符号可达性分析的状态空间细化中使用浅组合语义）。还提出了缓存符号可达性分析结果的优化方法。

Result: 该算法在SAT-Reach工具中实现，并证明了其可伸缩性优势。

Conclusion: 所提出的CEGAR驱动的有界可达性分析算法能够有效地处理组合混合系统的可达性分析问题，并且通过混合不同的组合语义和优化技术，提高了算法的效率和可伸缩性。

Abstract: Reachability analysis of compositional hybrid systems, where individual
components are modeled as hybrid automata, poses unique challenges. In addition
to preserving the compositional semantics while computing system behaviors,
algorithms have to cater to the explosion in the number of locations in the
parallel product automaton. In this paper, we propose a bounded reachability
analysis algorithm for compositional hybrid systems with piecewise affine
dynamics, based on the principle of counterexample guided abstraction
refinement (CEGAR). In particular, the algorithm searches for a counterexample
in the discrete abstraction of the composition model, without explicitly
computing a product automaton. When a counterexample is discovered in the
abstraction, its validity is verified by a refinement of the state-space guided
by the abstract counterexample. The state-space refinement is through a
symbolic reachability analysis, particularly using a state-of-the-art algorithm
with support functions as the continuous state representation. In addition, the
algorithm mixes different semantics of composition with the objective of
improved efficiency. Step compositional semantics is followed while exploring
the abstract (discrete) state-space, while shallow compositional semantics is
followed during state-space refinement with symbolic reachability analysis.
Optimizations such as caching the results of the symbolic reachability
analysis, which can be later reused, have been proposed. We implement this
algorithm in the tool SAT-Reach and demonstrate the scalability benefits.

</details>


### [142] [Simplicity Lies in the Eye of the Beholder: A Strategic Perspective on Controllers in Reactive Synthesis](https://arxiv.org/abs/2509.04129)
*Mickael Randour*

Main category: cs.LO

TL;DR: 本文探讨了在控制器合成中，使用有限记忆的简单策略比复杂策略更好的普遍观点，并讨论了策略复杂度相关的最新研究成果，包括记忆和随机性，以及超出传统复杂性概念的策略。


<details>
  <summary>Details</summary>
Motivation: 在控制器合成中，普遍认为使用有限记忆的简单策略比复杂策略更好，因为它们更容易设计、理解、生产和维护。

Method: 本文关注多种合成背景下策略的复杂度，并讨论了有关记忆和随机性的最新研究成果，还简要探讨了超出传统策略复杂度概念的方面。

Result: 本文讨论了在多种合成背景下策略复杂度的相关问题，并涉及了记忆和随机性的最新研究。

Conclusion: 策略的复杂度在控制器合成中是一个重要的问题，对于理解和设计控制器至关重要。

Abstract: In the game-theoretic approach to controller synthesis, we model the
interaction between a system to be controlled and its environment as a game
between these entities, and we seek an appropriate (e.g., winning or optimal)
strategy for the system. This strategy then serves as a formal blueprint for a
real-world controller. A common belief is that simple (e.g., using limited
memory) strategies are better: corresponding controllers are easier to conceive
and understand, and cheaper to produce and maintain.
  This invited contribution focuses on the complexity of strategies in a
variety of synthesis contexts. We discuss recent results concerning memory and
randomness, and take a brief look at what lies beyond our traditional notions
of complexity for strategies.

</details>


### [143] [Janus-faces of temporal constraint languages: a dichotomy of expressivity](https://arxiv.org/abs/2509.04347)
*Johanna Brunar,Michael Pinsker,Moritz Schöbi*

Main category: cs.LO

TL;DR: Bodirsky-K'ara分类是无限域CSP的早期分类，但其可解情况下的算法和代数不变量仍不明确。本文研究了该分类中不pp-构造所有内容的那些语言，发现它们在图和超图的pp-解释能力方面受到很大限制。


<details>
  <summary>Details</summary>
Motivation: 研究Bodirsky-K'ara分类中可解Temporal Constraint Languages（TCLs）的算法和代数不变量，尽管它们在计算上是可解的，但其表达能力和代数结构仍不明确。

Method: 通过分析TCLs在pp-解释图和超图方面的能力，证明了那些不pp-构造所有内容的TCLs具有有限的表达能力，并推导出其代数结构性质。

Result: 证明了不pp-构造所有内容的TCLs具有有限的图和超图pp-解释能力，这带来了新的代数推论，并为已知的性质提供了统一的证明。特别地，证明了这些语言允许4元伪Siggers多项式。

Conclusion: Bodirsky-K'ara分类中那些不pp-构造所有内容的Temporal Constraint Languages，其表达能力有限，并具有4元伪Siggers多项式性质。这为Bodirsky-Pinsker猜想的更广泛背景提供了支持。

Abstract: The Bodirsky-K\'ara classification of temporal constraint languages stands as
one of the earliest and most seminal complexity classifications within
infinite-domain Constraint Satisfaction Problems (CSPs), yet it remains one of
the most mysterious in terms of algorithms and algebraic invariants for the
tractable cases. We show that those temporal languages which do not
pp-construct EVERYTHING (and thus by the classification are solvable in
polynomial time) have, in fact, very limited expressive power as measured by
the graphs and hypergraphs they can pp-interpret. This limitation yields many
previously unknown algebraic consequences, while also providing new, uniform
proofs for known invariance properties. In particular, we show that such
temporal constraint languages admit $4$-ary pseudo-Siggers polymorphisms -- a
result that sustains the possibility that the existence of such polymorphisms
extends to the much broader context of the Bodirsky-Pinsker conjecture.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [144] [Hypothesis Selection: A High Probability Conundrum](https://arxiv.org/abs/2509.03734)
*Anders Aamand,Maryam Aliakbarpour,Justin Y. Chen,Sandeep Silwal*

Main category: cs.DS

TL;DR: 我们改进了假设选择问题的算法时间复杂度，并研究了三种替代设置。


<details>
  <summary>Details</summary>
Motivation: 现有假设选择问题的算法在运行时间上存在不足，尤其是在处理样本数量、置信度和误差参数时。本研究旨在改进时间复杂度，并探索其他设置下的问题。

Method: 本研究改进了现有算法的时间复杂度，从$\tilde{O}(n/(\delta^3\varepsilon^3))$降低到$\tilde{O}(n/(\delta \varepsilon^2))$。此外，还研究了三种替代设置：(1) 估计输出假设与真实分布之间期望距离的上界；(2) 假设最优距离值$\\mathsf{OPT}$已知；(3) 允许在观察样本前对假设类进行预处理。

Result: 改进后的算法时间复杂度显著提高，减少了对置信度和误差参数的依赖。在替代设置方面，本研究解决了最优近似因子问题，并提出了在已知$\\mathsf{OPT}$值或允许预处理的情况下，实现最优近似因子$C=3$的算法。

Conclusion: 本研究在假设选择问题的理论和算法方面取得了重要进展，特别是在提高算法效率和解决开放性问题方面。

Abstract: In the hypothesis selection problem, we are given a finite set of candidate
distributions (hypotheses), $\mathcal{H} = \{H_1, \ldots, H_n\}$, and samples
from an unknown distribution $P$. Our goal is to find a hypothesis $H_i$ whose
total variation distance to $P$ is comparable to that of the nearest hypothesis
in $\mathcal{H}$. If the minimum distance is $\mathsf{OPT}$, we aim to output
an $H_i$ such that, with probability at least $1-\delta$, its total variation
distance to $P$ is at most $C \cdot \mathsf{OPT} + \varepsilon$.
  Despite decades of work, key aspects of this problem remain unresolved,
including the optimal running time for algorithms that achieve the optimal
sample complexity and best possible approximation factor of $C=3$. The previous
state-of-the-art result [Aliakbarpour, Bun, Smith, NeurIPS 2024] provided a
nearly linear in $n$ time algorithm but with a sub-optimal dependence on the
other parameters, running in $\tilde{O}(n/(\delta^3\varepsilon^3))$ time. We
improve this time complexity to $\tilde{O}(n/(\delta \varepsilon^2))$,
significantly reducing the dependence on the confidence and error parameters.
  Furthermore, we study hypothesis selection in three alternative settings,
resolving or making progress on several open questions from prior works. (1) We
settle the optimal approximation factor when bounding the \textit{expected
distance} of the output hypothesis, rather than its high-probability
performance. (2) Assuming the numerical value of \textit{$\mathsf{OPT}$ is
known} in advance, we present an algorithm obtaining $C=3$ and runtime
$\tilde{O}(n/\varepsilon^2)$ with the optimal sample complexity and succeeding
with high probability in $n$. (3) Allowing polynomial \textit{preprocessing}
step on the hypothesis class $\mathcal{H}$ before observing samples, we present
an algorithm with $C=3$ and subquadratic runtime which succeeds with high
probability in $n$.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [145] [Data-Driven Smart Maintenance of Historic Buildings](https://arxiv.org/abs/2509.03685)
*Zhongjun Ni*

Main category: eess.SY

TL;DR: 本论文提出了一种数据驱动的智慧维护方法，利用物联网、云计算、边缘计算、本体数据建模和机器学习技术，来改善历史建筑的室内气候管理、能源效率和保护实践，以实现预防性维护和可持续保护。


<details>
  <summary>Details</summary>
Motivation: 历史建筑的保护至关重要，需要有效的预防性维护来确保其长期可持续性和遗产价值。传统的维护方法可能不足以应对现代挑战，因此需要创新的数据驱动方法。

Method: 本论文整合了物联网（IoT）、云计算、边缘计算、本体数据建模和机器学习技术，构建了一个全面的数据驱动的智慧维护解决方案。该方案还结合了智能监测、数字孪生和人工智能技术。

Result: 该方法提高了室内气候管理、能源效率和保护实践的水平，实现了对历史建筑的预防性维护。

Conclusion: 本论文通过结合智能监测、数字孪生和人工智能，推进了历史建筑的数据驱动保护，为新一代遗产保护策略奠定了基础。

Abstract: Digital transformation in the built environment offers new opportunities to
improve building maintenance through data-driven approaches. Smart monitoring,
predictive modeling, and artificial intelligence can enhance decision-making
and enable proactive strategies. The preservation of historic buildings is an
important scenario where preventive maintenance is essential to ensure
long-term sustainability while protecting heritage values. This thesis presents
a comprehensive solution for data-driven smart maintenance of historic
buildings, integrating Internet of Things (IoT), cloud computing, edge
computing, ontology-based data modeling, and machine learning to improve indoor
climate management, energy efficiency, and conservation practices.
  This thesis advances data-driven conservation of historic buildings by
combining smart monitoring, digital twins, and artificial intelligence. The
proposed methods enable preventive maintenance and pave the way for the next
generation of heritage conservation strategies.

</details>


### [146] [Parameter Tuning Under Uncertain Road Perception in Driver Assistance Systems](https://arxiv.org/abs/2509.03694)
*Leon Greiser,Christian Rathgeber,Vladislav Nenchev,Sören Hohmann*

Main category: eess.SY

TL;DR: 本论文提出了一种基于录制数据的自动参数调整方法，用于解决高级驾驶辅助系统中车道保持场景下的横向轨迹规划问题，该方法考虑了由传感器限制引起的噪声车道估计，并通过模拟车辆行为优化了规划器参数，在未见过的数据上表现出改进的性能。


<details>
  <summary>Details</summary>
Motivation: 先进驾驶员辅助系统（ADAS）在提高现代汽车的舒适性、安全性和效率方面发挥着重要作用。然而，传感器限制会导致车道估计产生噪声，给开发高性能的控制架构带来了重大挑战。横向轨迹规划通常采用最优控制方法来维持车道位置并最小化转向工作量，但该方法的参数通常需要手动调整，这是一个耗时的过程。

Method: 本文提出了一种基于录制数据的自动参数调整方法，用于解决高级驾驶员辅助系统中车道保持场景下的横向轨迹规划问题。该方法通过模拟参考曲线上的车辆横向行为，有效地优化了自动驾驶规划器参数，同时考虑了噪声车道估计。

Result: 所提出的方法能够高效地优化规划器参数，并在先前未见过的数据上展示出改进的性能。

Conclusion: 通过自动参数调整，在考虑噪声车道估计的情况下，能够为自动驾驶提供更优的横向轨迹规划，从而提高车道保持的性能。

Abstract: Advanced driver assistance systems have improved comfort, safety, and
efficiency of modern vehicles. However, sensor limitations lead to noisy lane
estimates that pose a significant challenge in developing performant control
architectures. Lateral trajectory planning often employs an optimal control
formulation to maintain lane position and minimize steering effort. The
parameters are often tuned manually, which is a time-intensive procedure. This
paper presents an automatic parameter tuning method for lateral planning in
lane-keeping scenarios based on recorded data, while taking into account noisy
road estimates. By simulating the lateral vehicle behavior along a reference
curve, our approach efficiently optimizes planner parameters for automated
driving and demonstrates improved performance on previously unseen test data.

</details>


### [147] [SAFE--MA--RRT: Multi-Agent Motion Planning with Data-Driven Safety Certificates](https://arxiv.org/abs/2509.04413)
*Babak Esmaeili,Hamidreza Modares*

Main category: eess.SY

TL;DR: 该研究提出了一种全数据驱动的运动规划框架，用于在无显式系统模型的情况下，使多智能体系统在有障碍物的共享工作空间中运行。通过解决凸半定规划问题，每个智能体独立学习其闭环行为，生成局部不变椭圆体和相应的状态反馈增益。


<details>
  <summary>Details</summary>
Motivation: 为在无模型、有障碍物的共享工作空间中运行的同质线性多智能体系统，提供一种全数据驱动的运动规划方法。

Method: 利用数据驱动的方法，通过求解凸半定规划生成局部不变椭圆体和状态反馈增益。基于网格的路径点构建搜索树，只有当相邻椭圆体重叠时才允许进行状态转移，确保动态可行性和安全性。多智能体同时扩展搜索树，并通过时空预留表来保证智能体间的安全性。

Result: 成功合成了多智能体在共享动力学和约束下的同步、安全轨迹，且轨迹不仅动态可行，还可证明在环境约束和智能体碰撞方面是安全的。

Conclusion: 该框架能够仅利用数据和凸优化工具，为多智能体系统在复杂环境中生成安全且动态可行的运动轨迹。

Abstract: This paper proposes a fully data-driven motion-planning framework for
homogeneous linear multi-agent systems that operate in shared, obstacle-filled
workspaces without access to explicit system models. Each agent independently
learns its closed-loop behavior from experimental data by solving convex
semidefinite programs that generate locally invariant ellipsoids and
corresponding state-feedback gains. These ellipsoids, centered along grid-based
waypoints, certify the dynamic feasibility of short-range transitions and
define safe regions of operation. A sampling-based planner constructs a tree of
such waypoints, where transitions are allowed only when adjacent ellipsoids
overlap, ensuring invariant-to-invariant transitions and continuous safety. All
agents expand their trees simultaneously and are coordinated through a
space-time reservation table that guarantees inter-agent safety by preventing
simultaneous occupancy and head-on collisions. Each successful edge in the tree
is equipped with its own local controller, enabling execution without
re-solving optimization problems at runtime. The resulting trajectories are not
only dynamically feasible but also provably safe with respect to both
environmental constraints and inter-agent collisions. Simulation results
demonstrate the effectiveness of the approach in synthesizing synchronized,
safe trajectories for multiple agents under shared dynamics and constraints,
using only data and convex optimization tools.

</details>


### [148] [Avoidance of an unexpected obstacle without reinforcement learning: Why not using advanced control-theoretic tools?](https://arxiv.org/abs/2509.03721)
*Cédric Join,Michel Fliess*

Main category: eess.SY

TL;DR: 本文提出了一种基于模型和无模型预测控制的方法来解决碰撞避免问题，并与强化学习进行比较，证明了其有效性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 强化学习需要大量的试错学习，而本文提出的方法可以避免这个问题。

Method: 使用经典的Dubins' car模型，结合基于平坦性的控制、HEOL反馈设置以及最新的无模型预测控制方法。

Result: 两种方法在计算机实验中都表现良好，无模型方法在鲁棒性方面表现更优，并且计算量低。

Conclusion: 本文提出的基于模型和无模型预测控制的方法在碰撞避免问题上是有效的，并且比强化学习更具优势。

Abstract: This communication on collision avoidance with unexpected obstacles is
motivated by some critical appraisals on reinforcement learning (RL) which
"requires ridiculously large numbers of trials to learn any new task" (Yann
LeCun). We use the classic Dubins' car in order to replace RL with
flatness-based control, combined with the HEOL feedback setting, and the latest
model-free predictive control approach. The two approaches lead to convincing
computer experiments where the results with the model-based one are only
slightly better. They exhibit a satisfactory robustness with respect to
randomly generated mismatches/disturbances, which become excellent in the
model-free case. Those properties would have been perhaps difficult to obtain
with today's popular machine learning techniques in AI. Finally, we should
emphasize that our two methods require a low computational burden.

</details>


### [149] [Decentralized Safety-Critical Control of Resilient DC Microgrids with Large-Signal Stability Guarantees](https://arxiv.org/abs/2509.03789)
*Muratkhan Abdirash,Xiaofan Cui*

Main category: eess.SY

TL;DR: 提出了一种分布式安全关键控制器（DSCC），该控制器以全分散的方式系统地集成了全局稳定性和形式化安全保证，以应对日益增长的网络威胁。


<details>
  <summary>Details</summary>
Motivation: 传统下垂控制方法因其简单性而普遍存在，但其设计很大程度上是经验性和保守性的，缺乏严格的保证。先进的策略可以改进某些方面，但通常会牺牲可扩展性、鲁棒性或形式化安全性。本研究旨在解决分布式能源和电力电子接口在直流微电网中的普及以及日益严峻的网络威胁带来的挑战。

Method: 利用控制屏障函数和端口哈密顿系统理论，DSCC以全分散的方式实现了可扩展的安全稳定，同时保持了实时可实现性。

Result: 高保真开关电路仿真验证了该控制器在各种意外情况下的优势。

Conclusion: 该框架为下一代直流微电网中的弹性、安全关键和可扩展控制铺平了道路。

Abstract: The increasing penetration of distributed energy resources and
power-electronics interfaces in DC microgrids, coupled with rising cyber
threats, necessitates primary controllers that are provably safe,
cyber-resilient, and practical. The increasing penetration of distributed
energy resources and power-electronics interfaces in DC microgrids, coupled
with rising cyber threats, necessitates primary controllers that are provably
safe, cyber-resilient, and practical. Conventional droop-based methods remain
prevalent due to their simplicity, yet their design is largely empirical and
conservative, lacking rigorous guarantees. Advanced strategies improve certain
aspects, but often sacrifice scalability, robustness, or formal safety. In this
work, we propose a Distributed Safety-Critical Controller (DSCC) that
systematically integrates global stabilization with formal safety guarantees in
a fully decentralized manner. Leveraging control barrier functions and the
port-Hamiltonian system theory, the DSCC achieves scalable safe stabilization
while preserving real-time implementability. High-fidelity switched-circuit
simulations validate the controller's advantages under various contingencies.
This framework paves the way for resilient, safety-critical, and scalable
control in next-generation DC microgrids.

</details>


### [150] [On the Performance Analysis of Pinching-Antenna-Enabled SWIPT Systems](https://arxiv.org/abs/2509.03836)
*Bingxin Zhang,Han Zhang,Kun Yang,Yizhe Zhao,Kezhi Wang*

Main category: eess.SY

TL;DR: 本文研究了由柔性捏合天线支持的同步无线信息和能量传输（SWIPT）系统的性能。


<details>
  <summary>Details</summary>
Motivation: 为了支持灵活部署并优化能量-速率性能，提出了三种实用的捏合天线放置方案：边缘部署方案（EDS）、中心部署方案（CDS）和对角线部署方案（DDS）。

Method: 引入了一种混合的能量收集（EH）和信息解码（ID）混合时间切换（TS）和功率分配（PS）协议，实现了动态调整。在每种部署策略和传输协议下，都为随机定位的用户设备（UE）的平均收集能量和平均可实现速率推导了基于捏合天线最优定位的闭式表达式。

Result: 数值模拟证实了理论分析的准确性，并说明了不同方案下速率和能量收集之间的权衡。

Conclusion: 本文研究了由柔性捏合天线支持的同步无线信息和能量传输（SWIPT）系统的性能。

Abstract: In this paper, we studies the performance of a novel simultaneous wireless
information and power transfer (SWIPT) system enabled by a flexible
pinching-antenna. To support flexible deployment and optimize energy-rate
performance, we propose three practical pinching antenna placement-schemes: the
edge deployment scheme (EDS), the center deployment scheme (CDS), and the
diagonal deployment scheme (DDS). Moreover, a hybrid time-switching (TS) and
power-splitting (PS) protocol is introduced, allowing dynamic adjustment
between energy harvesting and information decoding. Under each deployment
strategy and the transmission protocol, closed-form expressions for the average
harvested energy and average achievable rate of a randomly located user
equipment (UE) are derived based on the optimal positioning of the
pinching-antenna. Numerical simulations confirm the accuracy of the theoretical
analysis and illustrate the trade-off between rate and energy harvesting under
different schemes.

</details>


### [151] [Reservoir Predictive Path Integral Control for Unknown Nonlinear Dynamics](https://arxiv.org/abs/2509.03839)
*Daisuke Inoue,Tadayoshi Matsumori,Gouhei Tanaka,Yuji Ito*

Main category: eess.SY

TL;DR: 该研究提出了一种名为水库预测路径积分（RPPI）的框架，结合了回声状态网络（ESNs）和模型预测路径积分（MPPI）控制，以解决非线性动力学系统在线识别和控制的挑战。该框架能够快速学习非线性动力学，并直接用于MPPI控制计算，无需线性化近似。此外，还提出了不确定性感知RPPI（URPPI），利用ESN的不确定性来平衡探索和利用，从而提高控制性能，并将控制成本降低高达60%。


<details>
  <summary>Details</summary>
Motivation: 快速在线识别和控制未知的非线性动力学系统仍然是核心挑战。

Method: 集成回声状态网络（ESNs）——一种使用循环神经网络实现的储层计算模型——和模型预测路径积分（MPPI）控制——基于采样的模型预测控制变体——来应对这些挑战。提出的水库预测路径积分（RPPI）能够用ESN快速学习非线性动力学，并利用学习到的非线性直接在并行化的MPPI控制计算中使用，无需线性化近似。该框架还扩展到不确定性感知RPPI（URPPI），它利用ESN的不确定性来平衡探索和利用：在早期学习过程中探索性输入占主导地位，而在模型置信度增长时利用性输入占主导地位。

Result: 实验表明，URPPI提高了控制性能，与传统的基于二次规划的模型预测控制方法相比，控制成本降低了高达60%。

Conclusion: RPPI框架能够快速学习非线性动力学，并直接用于MPPI控制计算，无需线性化近似。URPPI通过利用ESN的不确定性来平衡探索和利用，提高了控制性能。

Abstract: Neural networks capable of approximating complex nonlinearities have found
extensive application in data-driven control of nonlinear dynamical systems.
However, fast online identification and control of unknown dynamics remain
central challenges. This paper integrates echo-state networks (ESNs) --
reservoir computing models implemented with recurrent neural networks -- and
model predictive path integral (MPPI) control -- sampling-based variants of
model predictive control -- to meet these challenges. The proposed reservoir
predictive path integral (RPPI) enables fast learning of nonlinear dynamics
with ESN and exploits the learned nonlinearities directly in parallelized MPPI
control computation without linearization approximations. The framework is
further extended to uncertainty-aware RPPI (URPPI), which leverages ESN
uncertainty to balance exploration and exploitation: exploratory inputs
dominate during early learning, while exploitative inputs prevail as model
confidence grows. Experiments on controlling the Duffing oscillator and
four-tank systems demonstrate that URPPI improves control performance, reducing
control costs by up to 60% compared to traditional quadratic programming-based
model predictive control methods.

</details>


### [152] [Sample Efficient Certification of Discrete-Time Control Barrier Functions](https://arxiv.org/abs/2509.03899)
*Sampath Kumar Mulagaleti,Andrea Del Prete*

Main category: eess.SY

TL;DR: CBFs可用于计算控制不变集，但计算CBFs通常涉及复杂的鲁棒优化问题。本文提出了一种基于Lipschitz的方法来验证CBFs，以提高采样效率。


<details>
  <summary>Details</summary>
Motivation: CBFs是计算控制不变集（CI）的有效工具，但其计算过程可能很复杂。需要一种方法来验证CBFs是否满足鲁棒约束。

Method: 利用Lipschitz常数论证来验证CBFs，并提出一种基于此的采样高效的认证算法。

Result: 通过数值算例验证了所提出程序的有效性。

Conclusion: 所提出的基于Lipschitz的方法为验证CBFs提供了一种高效的认证算法，尤其是在采样效率方面。

Abstract: Control Invariant (CI) sets are instrumental in certifying the safety of
dynamical systems. Control Barrier Functions (CBFs) are effective tools to
compute such sets, since the zero sublevel sets of CBFs are CI sets. However,
computing CBFs generally involves addressing a complex robust optimization
problem, which can be intractable. Scenario-based methods have been proposed to
simplify this computation. Then, one needs to verify if the CBF actually
satisfies the robust constraints. We present an approach to perform this
verification that relies on Lipschitz arguments, and forms the basis of a
certification algorithm designed for sample efficiency. Through a numerical
example, we validated the efficiency of the proposed procedure.

</details>


### [153] [Physics-Informed Detection of Friction Anomalies in Satellite Reaction Wheels](https://arxiv.org/abs/2509.04060)
*Alejandro Penacho Riveiros,Nicola Bastianello,Karl H. Johansson,Matthieu Barreau*

Main category: eess.SY

TL;DR: 该算法通过混合系统理论、变化点检测、动态规划和最大似然估计来分析卫星陀螺仪的数据，以识别其运行状态，区分正常和异常情况。


<details>
  <summary>Details</summary>
Motivation: 随着卫星数量的增加，需要自动化方法来监测其功能，以减少人工负担。

Method: 提出一种基于混合系统理论的模型来提取信息，结合变化点检测、动态规划和最大似然估计。然后使用预先训练的分类器来确定陀螺仪的工作状态。

Result: 该算法结合了基于模型和基于数据的方法，实现了约95%的准确率。

Conclusion: 该混合方法在识别卫星陀螺仪的运行状态方面取得了令人满意的结果。

Abstract: As the number of satellites in orbit has increased exponentially in recent
years, ensuring their correct functionality has started to require automated
methods to decrease human workload. In this work, we present an algorithm that
analyzes the on-board data related to friction from the Reaction Wheel
Assemblies (RWA) of a satellite and determines their operating status,
distinguishing between nominal status and several possible anomalies that
require preventive measures to be taken. The algorithm first uses a model based
on hybrid systems theory to extract the information relevant to the problem.
The extraction process combines techniques in changepoint detection, dynamic
programming, and maximum likelihood in a structured way. A classifier then uses
the extracted information to determine the status of the RWA. This last
classifier has been previously trained with a labelled dataset produced by a
high-fidelity simulator, comprised for the most part of nominal data. The final
algorithm combines model-based and data-based approaches to obtain satisfactory
results with an accuracy around 95%.

</details>


### [154] [Low-Power Impact Detection and Localization on Forklifts Using Wireless IMU Sensors](https://arxiv.org/abs/2509.04096)
*Lyssa Ramaut,Chesney Buyle,Jona Cappelle,Liesbet Van der Perre*

Main category: eess.SY

TL;DR: 该研究提出了一种低成本、低功耗的基于无线传感器节点的碰撞检测系统，用于识别和定位叉车上的碰撞事件。


<details>
  <summary>Details</summary>
Motivation: 叉车在工业环境中容易因野蛮操作、崎岖地形、狭窄空间和复杂操作而发生碰撞，造成安全隐患和设备损坏。

Method: 使用多个无线传感器节点测量三维加速度，并开发了一种算法来区分碰撞事件和正常使用，同时对碰撞进行本地化。

Result: 该系统能够成功检测和定位碰撞，同时保持低功耗，实现长达数年的传感器自主运行。

Conclusion: 所提出的低成本、低功耗碰撞检测系统能够可靠地监测叉车，并有效识别和定位碰撞事件。

Abstract: Forklifts are essential for transporting goods in industrial environments.
These machines face wear and tear during field operations, along with rough
terrain, tight spaces and complex handling scenarios. This increases the
likelihood of unintended impacts, such as collisions with goods,
infrastructure, or other machinery. In addition, deliberate misuse has been
stated, compromising safety and equipment integrity. This paper presents a
low-cost and low-power impact detection system based on multiple wireless
sensor nodes measuring 3D accelerations. These were deployed in a measurement
campaign covering realworld operational scenarios. An algorithm was developed,
based on this collected data, to differentiate high-impact events from normal
usage and to localize detected collisions on the forklift. The solution
successfully detects and localizes impacts, while maintaining low power
consumption, enabling reliable forklift monitoring with multi-year sensor
autonomy.

</details>


### [155] [Remote Estimation for Markov Jump Linear Systems: A Distributionally Robust Approach](https://arxiv.org/abs/2509.04116)
*Ioannis Tzortzis,Themistoklis Charalambous,Charalambos D. Charalambous*

Main category: eess.SY

TL;DR: 在存在后验模式概率不确定性的情况下，对马尔可夫跳跃线性系统的远程状态估计问题进行了研究。为了解决这个问题，该估算问题在一个分布鲁棒框架内进行制定，其中假定真实后验位于以标称后验为中心的总变差距离球内。所得的最小-最大制定产生了一个估计器，该估计器扩展了经典的最小均方误差（MMSE）解，并增加了考虑模式不确定性的项。通过使用一阶广义伪贝叶斯算法的分布鲁棒变体，开发了一种可行的实现方法。文中提供了一个数值示例来说明该方法的适用性和有效性。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决马尔可夫跳跃线性系统在远程状态估计过程中遇到的不确定性问题，特别是由不 विश्वसनीय通信网络引起的后验模式概率的不确定性。

Method: 采用分布鲁棒框架，将真实后验置于以标称后验为中心的总变差距离球内。在此框架下，推导了一个最小-最大优化问题，并开发了一阶广义伪贝叶斯算法的分布鲁棒变体来实现该估算器。

Result: 提出了一个能够处理后验模式概率不确定性的远程状态估计器，该估计器是经典MMSE解的扩展，并包含额外的项来处理模式不确定性。通过数值示例证明了该方法的有效性。

Conclusion: 开发了一种新颖的分布鲁棒方法来处理马尔可夫跳跃线性系统的远程状态估计中的后验模式概率不确定性，并通过数值验证了其有效性。

Abstract: This paper considers the problem of remote state estimation for Markov jump
linear systems in the presence of uncertainty in the posterior mode
probabilities. Such uncertainty may arise when the estimator receives noisy or
incomplete measurements over an unreliable communication network. To address
this challenge, the estimation problem is formulated within a distributionally
robust framework, where the true posterior is assumed to lie within a total
variation distance ball centered at the nominal posterior. The resulting
minimax formulation yields an estimator that extends the classical MMSE
solution with additional terms that account for mode uncertainty. A tractable
implementation is developed using a distributionally robust variant of the
first-order generalized pseudo-Bayesian algorithm. A numerical example is
provided to illustrate the applicability and effectiveness of the approach.

</details>


### [156] [On the Effect of Sampling-Time Jitter](https://arxiv.org/abs/2509.04199)
*Dieter Schwarzmann,Simon Käser*

Main category: eess.SY

TL;DR: jitter-afflicted systems can be reinterpreted as jitter-free analogs with scaled dynamics, and jitter acts as a frequency scaling in the Laplace domain.


<details>
  <summary>Details</summary>
Motivation: The paper aims to analyze the effect of sampling-time jitter on linear time-invariant systems and provide practical insights for practitioners.

Method: The paper proposes reinterpreting jitter-afflicted systems through equivalent jitter-free analogs by constructing a perceived system that absorbs timing perturbation effects into its dynamics, leading to an affine scaling of jitter. The paper examines both measurement and implementation scenarios.

Result: The analysis demonstrates that jitter effectively scales the system matrices and, in the Laplace domain, can be interpreted as a frequency scaling.

Conclusion: Jitter in sampled systems leads to an affine scaling of the system and acts as a frequency scaling in the Laplace domain.

Abstract: This brief, aimed at practitioners, offers an analysis of the effect of
sampling-time jitter, i. e., the error produced by execution-time inaccuracies.
We propose reinterpreting jitter-afflicted linear time-invariant systems
through equivalent jitter-free analogs. By constructing a perceived system that
absorbs the effects of timing perturbations into its dynamics, we find an
affine scaling of jitter. We examine both measurement and implementation
scenarios, demonstrating that the presence of jitter effectively scales the
system matrices. Moreover, we observe that, in the Laplace domain, jitter can
be interpreted as a frequency scaling.

</details>


### [157] [Laplacian Flows in Complex-valued Directed Networks: Analysis, Design, and Consensus](https://arxiv.org/abs/2509.04196)
*Aditi Saxena,Twinkle Tripathy,Rajasekhar Anguluri*

Main category: eess.SY

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In the interdisciplinary field of network science, a complex-valued network,
with edges assigned complex weights, provides a more nuanced representation of
relationships by capturing both the magnitude and phase of interactions.
Additionally, an important application of this setting arises in distribution
power grids. Motivated by the richer framework, we study the necessary and
sufficient conditions for achieving consensus in both strongly and weakly
connected digraphs. The paper establishes that complex-valued Laplacian flows
converge to consensus subject to an additional constraint termed as real
dominance which relies on the phase angles of the edge weights. Our approach
builds on the complex Perron-Frobenius properties to study the spectral
properties of the Laplacian and its relation to graphical conditions. Finally,
we propose modified flows that guarantee consensus even if the original network
does not converge to consensus. Additionally, we explore diffusion in
complex-valued networks as a dual process of consensus and simulate our results
on synthetic and real-world networks.

</details>


### [158] [Sailing Towards Zero-Shot State Estimation using Foundation Models Combined with a UKF](https://arxiv.org/abs/2509.04213)
*Tobin Holtmann,David Stenger,Andres Posada-Moreno,Friedrich Solowjow,Sebastian Trimpe*

Main category: eess.SY

TL;DR: 该研究提出了一种名为FM-UKF（基础模型无迹卡尔曼滤波）的新方法，结合了基于Transformer的系统动力学模型和无迹卡尔曼滤波（UKF），实现了在不同传感器配置下无需重新训练即可进行零样本状态估计。


<details>
  <summary>Details</summary>
Motivation: 传统的状态估计方法需要大量的人工系统辨识或数据收集工作。受其他领域中基础模型（foundation models）在减少数据需求方面的启发，本研究旨在开发能够实现零样本（zero-shot）系统动力学估计的基础模型，从而大幅减少手动部署的精力。

Method: FM-UKF方法将基于Transformer的系统动力学模型与分析已知的传感器模型通过UKF相结合。具体来说，它利用Transformer模型来理解和预测系统的动力学行为，然后将这些预测信息整合到UKF框架中，以处理和融合传感器观测数据，实现状态估计。

Result: 在集装箱船舶模型的基准测试中，FM-UKF展示了与经典方法（具有近似系统知识）和端到端方法相比，在准确性、所需精力以及鲁棒性方面具有有竞争力的权衡。研究还开源了相关的基准测试和数据集，以支持未来在零样本状态估计领域的研究。

Conclusion: FM-UKF能够跨越不同的动力学模型，并且在无需为新的传感器配置进行重新训练的情况下，实现了跨传感器配置的泛化能力。这为零样本状态估计提供了一种有前景的新途径，能够有效减少对大量标注数据的依赖。

Abstract: State estimation in control and systems engineering traditionally requires
extensive manual system identification or data-collection effort. However,
transformer-based foundation models in other domains have reduced data
requirements by leveraging pre-trained generalist models. Ultimately,
developing zero-shot foundation models of system dynamics could drastically
reduce manual deployment effort. While recent work shows that transformer-based
end-to-end approaches can achieve zero-shot performance on unseen systems, they
are limited to sensor models seen during training. We introduce the foundation
model unscented Kalman filter (FM-UKF), which combines a transformer-based
model of system dynamics with analytically known sensor models via an UKF,
enabling generalization across varying dynamics without retraining for new
sensor configurations. We evaluate FM-UKF on a new benchmark of container ship
models with complex dynamics, demonstrating a competitive accuracy, effort, and
robustness trade-off compared to classical methods with approximate system
knowledge and to an end-to-end approach. The benchmark and dataset are open
sourced to further support future research in zero-shot state estimation via
foundation models.

</details>


### [159] [Compatibility of Multiple Control Barrier Functions for Constrained Nonlinear Systems](https://arxiv.org/abs/2509.04220)
*Max H. Cohen,Eugene Lavretsky,Aaron D. Ames*

Main category: eess.SY

TL;DR: 本论文提出了一个多CBF约束的非线性系统安全控制框架，解决了单一CBF约束的局限性，并证明了该框架在处理箱约束时的兼容性、控制器Lipschitz连续性以及闭式解的存在性。此外，还分析了安全约束对标称跟踪性能的影响，并通过无人机仿真验证了框架的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于控制屏障函数（CBF）的受控方法主要集中在处理单一CBF约束，难以合成能够处理多个状态约束并保证安全性的控制器。这限制了CBF在复杂系统中的应用。

Method: 提出了一种处理非线性系统向量值输出上的箱约束的多CBF框架。当输出具有向量相对次数时，CBF约束被证明是兼容的。然后，基于此框架推导出的优化控制器具有局部Lipschitz连续性，并具有封闭形式的表达式。最后，对标称跟踪目标在安全约束影响下的性能衰减进行了量化分析。

Result: 该框架能够处理多CBF约束，特别是向量值输出上的箱约束。推导出的控制器具有局部Lipschitz连续性，并有一个封闭形式的表达式。此外，还得到了安全约束对跟踪性能影响的表征。无人机仿真结果证明了该框架的有效性。

Conclusion: 本研究提出的多CBF框架为处理具有多个状态约束的非线性系统提供了一种安全、可靠的控制方法。该方法在理论上具有良好性质，并通过仿真验证了其实际应用的可行性。

Abstract: Control barrier functions (CBFs) are a powerful tool for the constrained
control of nonlinear systems; however, the majority of results in the
literature focus on systems subject to a single CBF constraint, making it
challenging to synthesize provably safe controllers that handle multiple state
constraints. This paper presents a framework for constrained control of
nonlinear systems subject to box constraints on the systems' vector-valued
outputs using multiple CBFs. Our results illustrate that when the output has a
vector relative degree, the CBF constraints encoding these box constraints are
compatible, and the resulting optimization-based controller is locally
Lipschitz continuous and admits a closed-form expression. Additional results
are presented to characterize the degradation of nominal tracking objectives in
the presence of safety constraints. Simulations of a planar quadrotor are
presented to demonstrate the efficacy of the proposed framework.

</details>


### [160] [Reinforcement Learning for Robust Ageing-Aware Control of Li-ion Battery Systems with Data-Driven Formal Verification](https://arxiv.org/abs/2509.04288)
*Rudi Coppola,Hovsep Touloujian,Pierfrancesco Ombrini,Manuel Mazo Jr*

Main category: eess.SY

TL;DR: 本文提出一种结合强化学习（RL）和数据驱动形式化方法的方法，用于设计电池管理系统（BMS）的充电和安全协议，以解决充电速度和电池老化之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 当前研究面临的主要挑战是在充电速度和电池老化（容量损失）之间取得平衡。

Method: 采用基于物理的高保真电池模型，并结合了计数器示例引导的归纳综合（Counterexample-Guided Inductive Synthesis）方案。该方案利用强化学习（RL）生成单个控制器，并利用数据驱动的抽象（data-driven abstraction）来指导这些控制器根据电池的初始测量值进行切换，从而形成混合控制策略。

Result: 该方法能够生成一个混合系统，其中RL控制器负责具体控制，数据驱动的抽象负责控制器之间的离散切换。当设计满足目标标准时，该抽象能够提供关于闭环性能的概率保证。

Conclusion: 通过将RL与数据驱动的形式化方法相结合，可以设计出满足特定性能要求的混合充电和安全协议，并为电池的闭环性能提供概率保证。

Abstract: Rechargeable lithium-ion (Li-ion) batteries are a ubiquitous element of
modern technology. In the last decades, the production and design of such
batteries and their adjacent embedded charging and safety protocols, denoted by
Battery Management Systems (BMS), has taken central stage. A fundamental
challenge to be addressed is the trade-off between the speed of charging and
the ageing behavior, resulting in the loss of capacity in the battery cell. We
rely on a high-fidelity physics-based battery model and propose an approach to
data-driven charging and safety protocol design. Following a
Counterexample-Guided Inductive Synthesis scheme, we combine Reinforcement
Learning (RL) with recent developments in data-driven formal methods to obtain
a hybrid control strategy: RL is used to synthesise the individual controllers,
and a data-driven abstraction guides their partitioning into a switched
structure, depending on the initial output measurements of the battery. The
resulting discrete selection among RL-based controllers, coupled with the
continuous battery dynamics, realises a hybrid system. When a design meets the
desired criteria, the abstraction provides probabilistic guarantees on the
closed-loop performance of the cell.

</details>


### [161] [Learning Optimal Crew Dispatch for Grid Restoration Following an Earthquake](https://arxiv.org/abs/2509.04308)
*Farshad Amani,Faezeh Ardali,Amin Kargarian*

Main category: eess.SY

TL;DR: 我们提出了一种结合 transformer 和深度强化学习 (DRL) 的新方法，用于灾后人员调度，可在近乎实时地提供高质量的决策支持，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统混合整数线性规划方法在灾后人员调度方面计算成本高，响应时间长，无法满足动态恢复环境中的及时决策需求。

Method: 将人员调度视为不确定性下的序贯决策问题。利用 transformer 捕捉高维系统状态和时间依赖性，结合 DRL 实现自适应和可扩展的决策。首先使用地震标准描述地震诱发的配电网破坏，然后生成场景并聚合可能结果形成单一的地理空间影响图。基于此图，该框架生成第二层调度策略，通过模拟和历史事件进行离线训练，并在线部署以快速响应。

Result: 与传统方法相比，该方法在运行时长上有了显著的改进，同时保持了高质量的解决方案。在欧洲 2869 节点天然气和电力网络上的案例研究表明，该方法能够显著加快恢复速度。

Conclusion: 该方法通过提供更快速、更有效的恢复和修复能力，增强了系统弹性，并具有大规模部署应用于灾难响应的巨大潜力。

Abstract: Post-disaster crew dispatch is a critical but computationally intensive task.
Traditional mixed-integer linear programming methods often require minutes to
several hours to compute solutions, leading to delays that hinder timely
decision-making in highly dynamic restoration environments. To address this
challenge, we propose a novel learning-based framework that integrates
transformer architectures with deep reinforcement learning (DRL) to deliver
near real-time decision support without compromising solution quality. Crew
dispatch is formulated as a sequential decision-making problem under
uncertainty, where transformers capture high-dimensional system states and
temporal dependencies, while DRL enables adaptive and scalable decision-making.
Earthquake-induced distribution network damage is first characterized using
established seismic standards, followed by a scenario generation and reduction
pipeline that aggregates probable outcomes into a single geospatial impact map.
Conditioned on this map, the proposed framework generates second-level dispatch
strategies, trained offline on simulated and historical events and deployed
online for rapid response. In addition to substantial runtime improvements, the
proposed method enhances system resilience by enabling faster and more
effective recovery and restoration. Case studies, particularly on the 2869-bus
European gas and power network, demonstrate that the method substantially
accelerates restoration while maintaining high-quality solutions, underscoring
its potential for practical deployment in large-scale disaster response.

</details>


### [162] [Impact on transient stability of self-synchronisation control strategies in grid-forming VSC-based generators](https://arxiv.org/abs/2509.04388)
*Regulo E. Avila-Martinez,Xavier Guillaud,Javier Renedo,Luis Rouco,Aurelio Garcia-Cerrada,Lukas Sigrist*

Main category: eess.SY

TL;DR: 本文分析了四种用于并网电压源换流器（GFM-VSCs）的自同步策略（不带锁相环的VSM、带锁相环的VSM、带洗水滤波器的不带锁相环的VSM以及IP控制器）对瞬态稳定性的影响，并提出了一种频率限制控制器（FLC）以提高瞬态稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有的并网电压源换流器（GFM-VSCs）的自同步策略（如VSM）的研究缺乏对其瞬态稳定性影响的系统性分析，因此需要对不同的VSM变体及其对瞬态稳定性的影响进行分析和比较，并提出新的方法来提高瞬态稳定性。

Method: 对四种自同步策略（不带锁相环的VSM、带锁相环的VSM、带洗水滤波器的不带锁相环的VSM以及IP控制器）的瞬态稳定性进行了分析和比较。同时，分析了两种可以改善瞬态稳定性的方法：虚拟未饱和有功功率控制器（VAPC）和本文提出的频率限制控制器（FLC）。

Result: 本文分析了不同自同步策略对GFM-VSC瞬态稳定性的影响，并提出了FLC作为一种有效的方法来提高瞬态稳定性。

Conclusion: 自同步策略的选择对GFM-VSC的瞬态稳定性至关重要。本文提出的FLC是一种有效的改善瞬态稳定性的方法。

Abstract: Grid-forming voltage source converters (GFM-VSCs) are emerging as a solution
for integrating renewable energy resources (RERs) into power systems. GFM-VSCs
need a self-synchronisation strategy to ensure that all converters and
generators in the power system are in synchronism and they reach the same
frequency in steady state. The self-synchronisation strategy in GFM-VSCs that
has received most attention in previous research is virtual synchronous machine
(VSM) control. However, no systematic study of the effects on transient
stability of different variants of this strategy has been carried out in
previous work. This paper analyses and compares transient stability of four
self-synchronisation strategies for GFM-VSCs: VSM without phase-locked loop
(PLL), VSM with PLL, VSM without PLL using wash-out filter and
integral-proportional (IP) controller. The paper also analyses two different
methods that can \color{black} be applied to GFM-VSC self-synchronisation
strategies to improve transient stability: the concept of virtual unsaturated
active-power controller (VAPC), proposed in previous work, and an algorithm for
frequency limitation in the GFM-VSC (FLC), which is proposed in this paper.

</details>


### [163] [Leveraging Equivariances and Symmetries in the Control Barrier Function Synthesis](https://arxiv.org/abs/2509.04399)
*Adrian Wiltz,Dimos V. Dimarogonas*

Main category: eess.SY

TL;DR: 利用系统动力学的等价性（对称性）来简化控制障碍函数（CBF）的合成，可以显著节省计算资源。


<details>
  <summary>Details</summary>
Motivation: 现有的控制障碍函数（CBF）合成方法计算量大或构造复杂。本研究旨在探索如何利用系统动力学的结构特性（尤其是等价性）来简化CBF的合成。

Method: 研究系统动力学的等价性（对称性）如何诱导CBF的对称性，并利用这种对称性从部分已知值推断整个域的CBF值。此外，还研究了如何在非对称约束下利用等价性合成CBF，以及如何结合部分已知的CBF和等价性来构建新的CBF。

Result: 证明了系统动力学中的等价性和约束中的对称性可以诱导CBF的对称性。利用这种对称性，可以将CBF的计算量从整个域缩减到一个子集。即使在约束非对称的情况下，等价性也可以用于CBF合成。通过数值研究验证了利用等价性合成CBF所带来的计算增益。

Conclusion: 系统动力学中的等价性为CBF的合成提供了一种有效的方法，能够显著减少计算量并处理更广泛的约束类型。

Abstract: The synthesis of Control Barrier Functions (CBFs) often involves demanding
computations or a meticulous construction. However, structural properties of
the system dynamics and constraints have the potential to mitigate these
challenges. In this paper, we explore how equivariances in the dynamics,
loosely speaking a form of symmetry, can be leveraged in the CBF synthesis.
Although CBFs are generally not inherently symmetric, we show how equivariances
in the dynamics and symmetries in the constraints induce symmetries in CBFs
derived through reachability analysis. This insight allows us to infer their
CBF values across the entire domain from their values on a subset, leading to
significant computational savings. Interestingly, equivariances can be even
leveraged to the CBF synthesis for non-symmetric constraints. Specifically, we
show how a partially known CBF can be leveraged together with equivariances to
construct a CBF for various new constraints. Throughout the paper, we provide
examples illustrating the theoretical findings. Furthermore, a numerical study
investigates the computational gains from invoking equivariances into the CBF
synthesis.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [164] [LuxDiT: Lighting Estimation with Video Diffusion Transformer](https://arxiv.org/abs/2509.03680)
*Ruofan Liang,Kai He,Zan Gojcic,Igor Gilitschenski,Sanja Fidler,Nandita Vijaykumar,Zian Wang*

Main category: cs.GR

TL;DR: 提出LuxDiT，一种利用视频扩散转换器生成HDR环境图的新方法，用于从单个图像或视频估计场景光照。


<details>
  <summary>Details</summary>
Motivation: 现有的基于学习的方法受到真实世界HDR环境图数据稀疏、昂贵且多样性不足的限制。虽然生成模型在图像合成方面表现出色，但由于需要推断全局上下文和恢复高动态范围输出，光照估计仍然很困难。

Method: LuxDiT微调了视频扩散转换器，以生成条件于视觉输入的HDR环境图。在包含多样化光照条件的大型合成数据集上进行训练，并结合使用低秩适配微调策略来提高语义对齐。

Result: 该模型能够从间接视觉线索推断光照，并能有效泛化到真实世界场景，在定量和定性评估中均优于现有技术，能够生成具有逼真角高频细节的准确光照预测。

Conclusion: LuxDiT通过利用生成模型和创新的微调策略，成功解决了从单个图像或视频估计场景光照的挑战，并在准确性和真实感方面取得了显著的改进。

Abstract: Estimating scene lighting from a single image or video remains a longstanding
challenge in computer vision and graphics. Learning-based approaches are
constrained by the scarcity of ground-truth HDR environment maps, which are
expensive to capture and limited in diversity. While recent generative models
offer strong priors for image synthesis, lighting estimation remains difficult
due to its reliance on indirect visual cues, the need to infer global
(non-local) context, and the recovery of high-dynamic-range outputs. We propose
LuxDiT, a novel data-driven approach that fine-tunes a video diffusion
transformer to generate HDR environment maps conditioned on visual input.
Trained on a large synthetic dataset with diverse lighting conditions, our
model learns to infer illumination from indirect visual cues and generalizes
effectively to real-world scenes. To improve semantic alignment between the
input and the predicted environment map, we introduce a low-rank adaptation
finetuning strategy using a collected dataset of HDR panoramas. Our method
produces accurate lighting predictions with realistic angular high-frequency
details, outperforming existing state-of-the-art techniques in both
quantitative and qualitative evaluations.

</details>


### [165] [Memory Optimization for Convex Hull Support Point Queries](https://arxiv.org/abs/2509.03753)
*Michael Greer*

Main category: cs.GR

TL;DR: 论文提出了改进凸包内存布局的方法，以提高计算支撑点查询的时间，该方法在碰撞检测算法中具有重要应用，并能显著加速查询过程。


<details>
  <summary>Details</summary>
Motivation: 为了提高支撑点查询的计算效率，支撑点查询是常用碰撞检测算法的基础。

Method: 通过优化凸包的内存布局来实现。

Result: 在支撑点查询方面实现了显著的加速，加速效果与凸包的顶点数量有关。

Conclusion: 论文提出的内存布局优化方法能够有效提高凸包的支撑点查询性能。

Abstract: This paper evaluates several improvements to the memory layout of convex
hulls to improve computation times for support point queries. The support point
query is a fundamental part of common collision algorithms, and the work
presented achieves a significant speedup depending on the number of vertices of
the convex hull.

</details>


### [166] [ContraGS: Codebook-Condensed and Trainable Gaussian Splatting for Fast, Memory-Efficient Reconstruction](https://arxiv.org/abs/2509.03775)
*Sankeerth Durvasula,Sharanshangar Muhunthan,Zain Moustafa,Richard Chen,Ruofan Liang,Yushi Guan,Nilesh Ahuja,Nilesh Jain,Selvakumar Panneer,Nandita Vijaykumar*

Main category: cs.GR

TL;DR: ContraGS通过使用代码本压缩3D高斯表示来显著降低训练内存并加速训练和渲染，同时保持接近最先进的质量。


<details>
  <summary>Details</summary>
Motivation: 使用大量3D高斯来提高3D高斯渲染的质量会显著增加模型参数的GPU显存占用，导致需要高内存容量的GPU并且训练/渲染延迟增加。

Method: ContraGS提出了一种在压缩的3D高斯表示上直接进行训练的方法。它利用代码本紧凑地存储高斯参数向量，并通过将参数估计视为贝叶斯推理问题来解决学习非可微参数的挑战，使用MCMC采样来对压缩表示的后验分布进行采样。

Result: ContraGS将训练期间的峰值内存使用量平均减少了3.49倍，并分别平均将训练和渲染速度提高了1.36倍和1.88倍，同时模型质量接近最先进水平。

Conclusion: ContraGS成功地实现了在不显著降低模型质量的情况下，通过代码本压缩3D高斯表示来降低内存消耗并提高训练和渲染效率。

Abstract: 3D Gaussian Splatting (3DGS) is a state-of-art technique to model real-world
scenes with high quality and real-time rendering. Typically, a higher quality
representation can be achieved by using a large number of 3D Gaussians.
However, using large 3D Gaussian counts significantly increases the GPU device
memory for storing model parameters. A large model thus requires powerful GPUs
with high memory capacities for training and has slower training/rendering
latencies due to the inefficiencies of memory access and data movement. In this
work, we introduce ContraGS, a method to enable training directly on compressed
3DGS representations without reducing the Gaussian Counts, and thus with a
little loss in model quality. ContraGS leverages codebooks to compactly store a
set of Gaussian parameter vectors throughout the training process, thereby
significantly reducing memory consumption. While codebooks have been
demonstrated to be highly effective at compressing fully trained 3DGS models,
directly training using codebook representations is an unsolved challenge.
ContraGS solves the problem of learning non-differentiable parameters in
codebook-compressed representations by posing parameter estimation as a
Bayesian inference problem. To this end, ContraGS provides a framework that
effectively uses MCMC sampling to sample over a posterior distribution of these
compressed representations. With ContraGS, we demonstrate that ContraGS
significantly reduces the peak memory during training (on average 3.49X) and
accelerated training and rendering (1.36X and 1.88X on average, respectively),
while retraining close to state-of-art quality.

</details>


### [167] [TensoIS: A Step Towards Feed-Forward Tensorial Inverse Subsurface Scattering for Perlin Distributed Heterogeneous Media](https://arxiv.org/abs/2509.04047)
*Ashish Tiwari,Satyam Bhardwaj,Yash Bachwana,Parag Sarvoday Sahu,T. M. Feroz Ali,Bhargava Chintalapati,Shanmuganathan Raman*

Main category: cs.GR

TL;DR: 本研究提出了一种基于深度学习的框架TensoIS，利用分形柏林噪声来模拟和估计具有异质散射参数的介质的散射参数。


<details>
  <summary>Details</summary>
Motivation: 现有方法在估计异质介质的散射参数时存在局限性，特别是基于学习的方法通常假设介质是均匀的。此外，现实世界中缺乏能够明确模拟异质散射参数的分布模型。

Method: 1. 创建了一个名为HeteroSynth的合成数据集，其中介质的散射参数使用分形柏林噪声进行建模。 2. 提出了一个名为TensoIS的基于学习的前馈框架，该框架使用可学习的低秩张量分量来表示散射体，以从稀疏的多视图图像观测中估计散射参数。

Result: TensoIS在HeteroSynth测试集、模拟的烟雾和云几何体以及真实世界样本的各种未见过的异质性上进行了评估，证明了其在逆散射方面的有效性。

Conclusion: 本研究首次探索了使用分形柏林噪声分布来模拟真实世界中的异质散射，并提出了一种前馈方法TensoIS来实现参数的估计。

Abstract: Estimating scattering parameters of heterogeneous media from images is a
severely under-constrained and challenging problem. Most of the existing
approaches model BSSRDF either through an analysis-by-synthesis approach,
approximating complex path integrals, or using differentiable volume rendering
techniques to account for heterogeneity. However, only a few studies have
applied learning-based methods to estimate subsurface scattering parameters,
but they assume homogeneous media. Interestingly, no specific distribution is
known to us that can explicitly model the heterogeneous scattering parameters
in the real world. Notably, procedural noise models such as Perlin and Fractal
Perlin noise have been effective in representing intricate heterogeneities of
natural, organic, and inorganic surfaces. Leveraging this, we first create
HeteroSynth, a synthetic dataset comprising photorealistic images of
heterogeneous media whose scattering parameters are modeled using Fractal
Perlin noise. Furthermore, we propose Tensorial Inverse Scattering (TensoIS), a
learning-based feed-forward framework to estimate these Perlin-distributed
heterogeneous scattering parameters from sparse multi-view image observations.
Instead of directly predicting the 3D scattering parameter volume, TensoIS uses
learnable low-rank tensor components to represent the scattering volume. We
evaluate TensoIS on unseen heterogeneous variations over shapes from the
HeteroSynth test set, smoke and cloud geometries obtained from open-source
realistic volumetric simulations, and some real-world samples to establish its
effectiveness for inverse scattering. Overall, this study is an attempt to
explore Perlin noise distribution, given the lack of any such well-defined
distribution in literature, to potentially model real-world heterogeneous
scattering in a feed-forward manner.

</details>


### [168] [SMooGPT: Stylized Motion Generation using Large Language Models](https://arxiv.org/abs/2509.04058)
*Lei Zhong,Yi Yang,Changjian Li*

Main category: cs.GR

TL;DR: 该研究提出了一种名为SMooGPT的新方法，利用大型语言模型（LLM）来生成风格化的运动，解决了现有方法可解释性差、泛化能力有限和易产生偏见的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成风格化运动时存在可解释性差、控制能力有限、泛化到新风格的能力受限以及容易产生“行走”等固定动作偏见的问题。

Method: 该方法提出了一种基于“推理-组合-生成”的新视角，利用身体部位的文本空间作为中间表示。SMooGPT是一个经过微调的大型语言模型，能够理解和推理人类运动，并根据文本描述进行推理、组合和生成风格化运动。

Result: SMooGPT在身体部位文本空间中执行，提高了可解释性，实现了精细的运动控制，有效解决了运动内容和风格之间的潜在冲突，并利用LLM的开放词汇能力实现了良好的新风格泛化能力。实验和用户研究证明了该方法的有效性，尤其是在纯文本驱动的风格化运动生成方面。

Conclusion: SMooGPT在纯文本驱动的风格化运动生成方面表现出色，解决了现有方法的局限性，并提供了更高的可解释性和控制力。

Abstract: Stylized motion generation is actively studied in computer graphics,
especially benefiting from the rapid advances in diffusion models. The goal of
this task is to produce a novel motion respecting both the motion content and
the desired motion style, e.g., ``walking in a loop like a Monkey''. Existing
research attempts to address this problem via motion style transfer or
conditional motion generation. They typically embed the motion style into a
latent space and guide the motion implicitly in a latent space as well. Despite
the progress, their methods suffer from low interpretability and control,
limited generalization to new styles, and fail to produce motions other than
``walking'' due to the strong bias in the public stylization dataset. In this
paper, we propose to solve the stylized motion generation problem from a new
perspective of reasoning-composition-generation, based on our observations: i)
human motion can often be effectively described using natural language in a
body-part centric manner, ii) LLMs exhibit a strong ability to understand and
reason about human motion, and iii) human motion has an inherently
compositional nature, facilitating the new motion content or style generation
via effective recomposing. We thus propose utilizing body-part text space as an
intermediate representation, and present SMooGPT, a fine-tuned LLM, acting as a
reasoner, composer, and generator when generating the desired stylized motion.
Our method executes in the body-part text space with much higher
interpretability, enabling fine-grained motion control, effectively resolving
potential conflicts between motion content and style, and generalizes well to
new styles thanks to the open-vocabulary ability of LLMs. Comprehensive
experiments and evaluations, and a user perceptual study, demonstrate the
effectiveness of our approach, especially under the pure text-driven stylized
motion generation.

</details>


### [169] [Hyper Diffusion Avatars: Dynamic Human Avatar Generation using Network Weight Space Diffusion](https://arxiv.org/abs/2509.04145)
*Dongliang Cao,Guoxing Sun,Marc Habermann,Florian Bernard*

Main category: cs.GR

TL;DR: 本文提出了一种结合了身份特定渲染和基于扩散的生成模型的方法，以实现逼真且具有姿态相关形变的动态人体虚拟形象生成。


<details>
  <summary>Details</summary>
Motivation: 现有的动态人体虚拟形象生成方法要么受限于单一个人，要么渲染质量较低且无法捕捉姿态相关的形变。本文旨在融合两种方法的优点，实现高逼真度和真实姿态形变的动态人体虚拟形象生成。

Method: 本文采用两阶段流水线：首先，优化一组身份特定的UNet网络，每个网络代表一个捕捉姿态相关形变的动态人体虚拟形象；然后，在优化后的网络权重上训练一个超扩散模型。推理时，该方法生成网络权重，以实现实时、可控的动态人体虚拟形象渲染。

Result: 通过在大规模、跨身份、多视角的视频数据集上进行训练和评估，本文的方法在人体虚拟形象生成方面优于现有的最先进方法。

Conclusion: 本文提出的新方法成功地实现了高逼真度和真实的姿态相关形变的动态人体虚拟形象生成，解决了现有方法的局限性。

Abstract: Creating human avatars is a highly desirable yet challenging task. Recent
advancements in radiance field rendering have achieved unprecedented
photorealism and real-time performance for personalized dynamic human avatars.
However, these approaches are typically limited to person-specific rendering
models trained on multi-view video data for a single individual, limiting their
ability to generalize across different identities. On the other hand,
generative approaches leveraging prior knowledge from pre-trained 2D diffusion
models can produce cartoonish, static human avatars, which are animated through
simple skeleton-based articulation. Therefore, the avatars generated by these
methods suffer from lower rendering quality compared to person-specific
rendering methods and fail to capture pose-dependent deformations such as cloth
wrinkles. In this paper, we propose a novel approach that unites the strengths
of person-specific rendering and diffusion-based generative modeling to enable
dynamic human avatar generation with both high photorealism and realistic
pose-dependent deformations. Our method follows a two-stage pipeline: first, we
optimize a set of person-specific UNets, with each network representing a
dynamic human avatar that captures intricate pose-dependent deformations. In
the second stage, we train a hyper diffusion model over the optimized network
weights. During inference, our method generates network weights for real-time,
controllable rendering of dynamic human avatars. Using a large-scale,
cross-identity, multi-view video dataset, we demonstrate that our approach
outperforms state-of-the-art human avatar generation methods.

</details>


### [170] [Massively-Parallel Implementation of Inextensible Elastic Rods Using Inter-block GPU Synchronization](https://arxiv.org/abs/2509.04277)
*Przemyslaw Korzeniowski,Niels Hald,Fernando Bello*

Main category: cs.GR

TL;DR: 该研究提出了一种用于弹性杆（特别是 Cosserat 杆）的大规模并行计算方法，通过优化 GPU 利用率，显著提高了仿真速度，特别是对于不可拉伸的 Cosserat 杆模型，并在心血管应用中实现了实时仿真。


<details>
  <summary>Details</summary>
Motivation: Cosserat 杆模型能够模拟弯曲、拉伸和扭转等复杂变形，在模拟线、绳、导管等物理过程方面具有重要应用价值，但现有模型在计算效率方面存在瓶颈。

Method: 提出了一种大规模并行计算方法，利用 GPU 的流式多处理器，通过超越 CUDA 可扩展编程模型和使用块间同步，实现了单次内核启动多次物理时间步的仿真。同时提出了不可拉伸的 Cosserat 杆的变体。

Result: 原始可拉伸 CoRdE 模型的实现速度提升了 40.0 倍。不可拉伸 CoRdE 模型的 GPU 实现相比 CPU 版本平均速度提升了 15.11 倍。在心血管应用中模拟导管/导丝对（2x512 个 Cosserat 单元）实现了 13.5 倍的性能提升，能够以 0.5-1kHz 的速率进行触觉交互式的实时仿真。

Conclusion: 所提出的并行计算方法显著提高了 Cosserat 杆模型的仿真效率，特别是不可拉伸模型，使得在复杂应用场景下实现实时、高保真仿真成为可能。

Abstract: An elastic rod is a long and thin body able to sustain large global
deformations, even if local strains are small. The Cosserat rod is a non-linear
elastic rod with an oriented centreline, which enables modelling of bending,
stretching and twisting deformations. It can be used for physically-based
computer simulation of threads, wires, ropes, as well as flexible surgical
instruments such as catheters, guidewires or sutures. We present a
massively-parallel implementation of the original CoRdE model as well as our
inextensible variation. By superseding the CUDA Scalable Programming Model and
using inter-block synchronization, we managed to simulate multiple physics
time-steps per single kernel launch utilizing all the GPU's streaming
multiprocessors. Under some constraints, this results in nearly constant
computation time, regardless of the number of Cosserat elements simulated. When
executing 10 time-steps per single kernel launch, our implementation of the
original, extensible CoRdE was x40.0 faster. In a number of tests, the GPU
implementation of our inextensible CoRdE modification achieved an average
speed-up of x15.11 over the corresponding CPU version. Simulating a
catheter/guidewire pair (2x512 Cosserat elements) in a cardiovascular
application resulted in a 13.5 fold performance boost, enabling for accurate
real-time simulation at haptic interactive rates (0.5-1kHz).

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [171] [SAMVAD: A Multi-Agent System for Simulating Judicial Deliberation Dynamics in India](https://arxiv.org/abs/2509.03793)
*Prathamesh Devadiga,Omkaar Jayadev Shetty,Pooja Agarwal*

Main category: cs.MA

TL;DR: 本文介绍了一个名为SAMVAD的多智能体系统（MAS），该系统利用大型语言模型（LLMs）和检索增强生成（RAG）技术，在印度司法体系的框架内模拟司法审议过程，以克服现实中研究司法审议的限制。


<details>
  <summary>Details</summary>
Motivation: 评估司法体系的效力和公平性需要理解司法审议的复杂性，但相关的实证研究受到伦理和实践障碍的限制。

Method: 该系统包含代表法官、控方律师、辩方律师和模拟法官席的多个审裁员的智能体，并结合了基于印度法律文件知识库的检索增强生成（RAG）功能。审裁员智能体通过迭代审议回合达成共识。

Result: 该系统提供了一个可配置且可解释的MAS平台，用于探索法律推理和司法模拟中的群体决策动态，并能通过RAG提供可验证的法律依据。

Conclusion: SAMVAD系统为模拟印度司法审议提供了一个创新的、基于LLM和RAG的MAS平台，有助于克服研究限制并提高模拟的保真度和透明度。

Abstract: Understanding the complexities of judicial deliberation is crucial for
assessing the efficacy and fairness of a justice system. However, empirical
studies of judicial panels are constrained by significant ethical and practical
barriers. This paper introduces SAMVAD, an innovative Multi-Agent System (MAS)
designed to simulate the deliberation process within the framework of the
Indian justice system.
  Our system comprises agents representing key judicial roles: a Judge, a
Prosecution Counsel, a Defense Counsel, and multiple Adjudicators (simulating a
judicial bench), all powered by large language models (LLMs). A primary
contribution of this work is the integration of Retrieval-Augmented Generation
(RAG), grounded in a domain-specific knowledge base of landmark Indian legal
documents, including the Indian Penal Code and the Constitution of India. This
RAG functionality enables the Judge and Counsel agents to generate legally
sound instructions and arguments, complete with source citations, thereby
enhancing both the fidelity and transparency of the simulation.
  The Adjudicator agents engage in iterative deliberation rounds, processing
case facts, legal instructions, and arguments to reach a consensus-based
verdict. We detail the system architecture, agent communication protocols, the
RAG pipeline, the simulation workflow, and a comprehensive evaluation plan
designed to assess performance, deliberation quality, and outcome consistency.
  This work provides a configurable and explainable MAS platform for exploring
legal reasoning and group decision-making dynamics in judicial simulations,
specifically tailored to the Indian legal context and augmented with verifiable
legal grounding via RAG.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [172] [Cooperative Grasping for Collective Object Transport in Constrained Environments](https://arxiv.org/abs/2509.03638)
*David Alvear,George Turkiyyah,Shinkyu Park*

Main category: cs.RO

TL;DR: 提出了一种新颖的框架，用于在约束环境中进行双机器人协作抓取以进行物体运输。


<details>
  <summary>Details</summary>
Motivation: 解决双机器人在约束环境中协作抓取以进行物体运输的决策问题。

Method: 提出了一种条件嵌入（CE）模型，该模型由两个神经网络组成，将抓取配置信息映射到嵌入空间，并使用监督学习方法和负采样来区分可行的和不可行的抓取配置。

Result: 在模拟环境中，该模型能够可靠地识别可行的抓取配置，并在物理机器人平台上得到验证。

Conclusion: 所提出的框架能够有效地处理不同环境和物体几何形状下的双机器人协作抓取任务，并具有实际应用潜力。

Abstract: We propose a novel framework for decision-making in cooperative grasping for
two-robot object transport in constrained environments. The core of the
framework is a Conditional Embedding (CE) model consisting of two neural
networks that map grasp configuration information into an embedding space. The
resulting embedding vectors are then used to identify feasible grasp
configurations that allow two robots to collaboratively transport an object. To
ensure generalizability across diverse environments and object geometries, the
neural networks are trained on a dataset comprising a range of environment maps
and object shapes. We employ a supervised learning approach with negative
sampling to ensure that the learned embeddings effectively distinguish between
feasible and infeasible grasp configurations. Evaluation results across a wide
range of environments and objects in simulations demonstrate the model's
ability to reliably identify feasible grasp configurations. We further validate
the framework through experiments on a physical robotic platform, confirming
its practical applicability.

</details>


### [173] [Self-Organizing Aerial Swarm Robotics for Resilient Load Transportation : A Table-Mechanics-Inspired Approach](https://arxiv.org/abs/2509.03563)
*Quan Quan,Jiwen Xu,Runxiao Liu,Yi Ding,Jiaxing Che,Kai-Yuan Cai*

Main category: cs.RO

TL;DR: 通过模仿桌腿的耗散力学，提出了一种受物理启发的飞行机器人集群协同运输方法，实现了无需显式通信的自主编队稳定和自适应负载分配，并在仿真和真实世界实验中表现出优越的鲁棒性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的空中运输方法在可扩展性、通信依赖性和动态故障鲁棒性方面存在挑战，而机器人集群协同运输具有变革潜力。

Method: 提出了一种受物理启发的协同运输方法，模仿了桌腿的耗散力学，通过开发去中心化的耗散力模型，使每个机器人能够基于局部邻居和悬挂的有效载荷动态调整其位置，从而实现自主编队稳定和自适应负载分配，无需显式通信。

Result: 在仿真中，与现有方法相比，所提出方法的跟踪误差在不同场景下分别减小了 20%、68%、55.5% 和 21.9%。在真实世界实验中，系统在单机器人故障、断开连接事件、有效载荷变化和电缆长度不确定性下实现了 94% 的成功率，并在 Beaufort 等级 4 的户外风力下表现出强大的鲁棒性。

Conclusion: 这种受物理启发的协同运输方法结合了群体智能和机械稳定性原理，为异构空中系统在通信受限环境中集体处理复杂运输任务提供了一个可扩展的框架。

Abstract: In comparison with existing approaches, which struggle with scalability,
communication dependency, and robustness against dynamic failures, cooperative
aerial transportation via robot swarms holds transformative potential for
logistics and disaster response. Here, we present a physics-inspired
cooperative transportation approach for flying robot swarms that imitates the
dissipative mechanics of table-leg load distribution. By developing a
decentralized dissipative force model, our approach enables autonomous
formation stabilization and adaptive load allocation without the requirement of
explicit communication. Based on local neighbor robots and the suspended
payload, each robot dynamically adjusts its position. This is similar to
energy-dissipating table leg reactions. The stability of the resultant control
system is rigorously proved. Simulations demonstrate that the tracking errors
of the proposed approach are 20%, 68%, 55.5%, and 21.9% of existing approaches
under the cases of capability variation, cable uncertainty, limited vision, and
payload variation, respectively. In real-world experiments with six flying
robots, the cooperative aerial transportation system achieved a 94% success
rate under single-robot failure, disconnection events, 25% payload variation,
and 40% cable length uncertainty, demonstrating strong robustness under outdoor
winds up to Beaufort scale 4. Overall, this physics-inspired approach bridges
swarm intelligence and mechanical stability principles, offering a scalable
framework for heterogeneous aerial systems to collectively handle complex
transportation tasks in communication-constrained environments.

</details>


### [174] [Efficient Virtuoso: A Latent Diffusion Transformer Model for Goal-Conditioned Trajectory Planning](https://arxiv.org/abs/2509.03658)
*Antonio Guillen-Perez*

Main category: cs.RO

TL;DR: Efficient Virtuoso是一个用于轨迹规划的条件潜在扩散模型，在Waymo开放运动数据集上达到了minADE为0.25的领先性能。


<details>
  <summary>Details</summary>
Motivation: 为自动驾驶规划系统生成多样且可行的未来轨迹分布

Method: 提出了一种新颖的两阶段归一化管线，用于轨迹的几何方面比率缩放和PCA潜在空间的归一化，并使用MLP denoiser在低维潜在空间中进行高效的去噪处理，该模型以Transformer-based StateEncoder融合的丰富场景上下文作为条件。

Result: 在Waymo开放运动数据集上达到了minADE为0.25的领先性能。

Conclusion: 单一的终点目标可以解决战略模糊性，而更丰富的多步稀疏路线对于实现与细微人类驾驶行为相呼应的精确、高保真战术执行至关重要。

Abstract: The ability to generate a diverse and plausible distribution of future
trajectories is a critical capability for autonomous vehicle planning systems.
While recent generative models have shown promise, achieving high fidelity,
computational efficiency, and precise control remains a significant challenge.
In this paper, we present the \textbf{Efficient Virtuoso}, a conditional latent
diffusion model for goal-conditioned trajectory planning. Our approach
introduces a novel two-stage normalization pipeline that first scales
trajectories to preserve their geometric aspect ratio and then normalizes the
resulting PCA latent space to ensure a stable training target. The denoising
process is performed efficiently in this low-dimensional latent space by a
simple MLP denoiser, which is conditioned on a rich scene context fused by a
powerful Transformer-based StateEncoder. We demonstrate that our method
achieves state-of-the-art performance on the Waymo Open Motion Dataset,
reaching a \textbf{minADE of 0.25}. Furthermore, through a rigorous ablation
study on goal representation, we provide a key insight: while a single endpoint
goal can resolve strategic ambiguity, a richer, multi-step sparse route is
essential for enabling the precise, high-fidelity tactical execution that
mirrors nuanced human driving behavior.

</details>


### [175] [Low-Cost Open-Source Ambidextrous Robotic Hand with 23 Direct-Drive servos for American Sign Language Alphabet](https://arxiv.org/abs/2509.03690)
*Kelvin Daniel Gonzalez Amador*

Main category: cs.RO

TL;DR: VulcanV3是一款低成本、开源、3D打印的灵巧机械手，能够复现完整的美国手语字母表（包括左右手配置共52个手势），并已通过用户研究验证其高识别准确率。


<details>
  <summary>Details</summary>
Motivation: 为聋哑人群提供可及的、低成本且功能完善的机器人手语通信解决方案。

Method: 使用23个伺服执行器精确控制手指和手腕的运动，通过Arduino Mega和双PCA9685模块进行控制，并采用可逆设计以适应左右手。

Result: 经验证能够精确复现所有52个美国手语手势；用户研究（n=33）显示识别准确率达到96.97%，视频演示后提升至98.78%。

Conclusion: VulcanV3通过结合经济性、完整的美国手语覆盖范围和左右手通用性，在一个开源平台上推动了辅助机器人技术的发展，为可及通信技术和包容性创新做出了贡献。

Abstract: Accessible communication through sign language is vital for deaf communities,
1 yet robotic solutions are often costly and limited. This study presents
VulcanV3, a low- 2 cost, open-source, 3D-printed ambidextrous robotic hand
capable of reproducing the full 3 American Sign Language (ASL) alphabet (52
signs for right- and left-hand configurations). 4 The system employs 23
direct-drive servo actuators for precise finger and wrist movements, 5
controlled by an Arduino Mega with dual PCA9685 modules. Unlike most humanoid
upper- 6 limb systems, which rarely employ direct-drive actuation, VulcanV3
achieves complete ASL 7 coverage with a reversible design. All CAD files and
code are released under permissive 8 open-source licenses to enable
replication. Empirical tests confirmed accurate reproduction 9 of all 52 ASL
handshapes, while a participant study (n = 33) achieved 96.97% recognition 10
accuracy, improving to 98.78% after video demonstration. VulcanV3 advances
assistive 11 robotics by combining affordability, full ASL coverage, and
ambidexterity in an openly 12 shared platform, contributing to accessible
communication technologies and inclusive 13 innovation.

</details>


### [176] [Real-Time Buoyancy Estimation for AUV Simulations Using Convex Hull-Based Submerged Volume Calculation](https://arxiv.org/abs/2509.03804)
*Ad-Deen Mahbub,Md Ragib Shaharear*

Main category: cs.RO

TL;DR: NVIDIA Isaac Sim 缺少原生浮力系统，本文提出了一种新的基于凸包的实时动态方法来计算 AUV 的浸没体积，提高了模拟精度和效率。


<details>
  <summary>Details</summary>
Motivation: NVIDIA Isaac Sim 缺乏原生浮力系统，需要外部解决方案来实现精确的水下物理模拟。

Method: 提出了一种新的基于凸包的方法，通过提取模拟环境的网格几何，计算凸包与水准面沿 z 轴的交集来动态计算 AUV 的浸没体积。采用了横截面积扩展来降低计算开销，以实现高效的浮力更新。

Result: 该方法实现了实时性能和可扩展性，能够适应方向、深度和正弦波（+-0.3 m）的波动，提高了模拟的保真度。

Conclusion: 本文提出的基于凸包的方法能够实时、高效地计算 AUV 的浸没体积，提高了 NVIDIA Isaac Sim 中水下物理模拟的精度，无需预先计算的水动力模型。

Abstract: Accurate real-time buoyancy modeling is essential for high-fidelity
Autonomous Underwater Vehicle (AUV) simulations, yet NVIDIA Isaac Sim lacks a
native buoyancy system, requiring external solutions for precise underwater
physics. This paper presents a novel convex hull-based approach to dynamically
compute the submerged volume of an AUV in real time. By extracting mesh
geometry from the simulation environment and calculating the hull portion
intersecting the water level along the z-axis, our method enhances accuracy
over traditional geometric approximations. A cross-sectional area extension
reduces computational overhead, enabling efficient buoyant force updates that
adapt to orientation, depth, and sinusoidal wave fluctuations (+-0.3 m). Tested
on a custom AUV design for SAUVC 2025, this approach delivers real-time
performance and scalability, improving simulation fidelity for underwater
robotics research without precomputed hydrodynamic models.

</details>


### [177] [INGRID: Intelligent Generative Robotic Design Using Large Language Models](https://arxiv.org/abs/2509.03842)
*Guanglu Jia,Ceng Zhang,Gregory S. Chirikjian*

Main category: cs.RO

TL;DR: LLMs在机器人领域发展迅速，但受限于现有硬件。本文提出INGRID框架，利用逆螺钉理论和运动学综合方法，自动化设计并行机器人机构，突破硬件限制，使AI主动设计机器人硬件成为可能。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的机器人系统受限于串联机构等传统硬件架构，限制了机器人智能的发展范围。

Method: 提出INGRID框架，将设计分解为约束分析、运动学关节生成、链构建和完整机构设计四个任务，并与逆螺钉理论和运动学综合方法深度融合，实现并行机器人机构的自动化设计。

Result: INGRID能够生成具有固定和可变运动能力的并联机构，发现了文献中未记载的运动学配置。通过三个案例研究验证，INGRID可根据用户期望的运动能力要求，设计特定任务的并联机器人。

Conclusion: INGRID弥合了机构理论与机器学习之间的鸿沟，使非专业机器人研究人员也能创造定制的并联机构，从而将机器人智能的进步与硬件限制脱钩。该工作为机构智能奠定了基础，使AI系统能够主动设计机器人硬件，有望改变具身AI系统的发展。

Abstract: The integration of large language models (LLMs) into robotic systems has
accelerated progress in embodied artificial intelligence, yet current
approaches remain constrained by existing robotic architectures, particularly
serial mechanisms. This hardware dependency fundamentally limits the scope of
robotic intelligence. Here, we present INGRID (Intelligent Generative Robotic
Design), a framework that enables the automated design of parallel robotic
mechanisms through deep integration with reciprocal screw theory and kinematic
synthesis methods. We decompose the design challenge into four progressive
tasks: constraint analysis, kinematic joint generation, chain construction, and
complete mechanism design. INGRID demonstrates the ability to generate novel
parallel mechanisms with both fixed and variable mobility, discovering
kinematic configurations not previously documented in the literature. We
validate our approach through three case studies demonstrating how INGRID
assists users in designing task-specific parallel robots based on desired
mobility requirements. By bridging the gap between mechanism theory and machine
learning, INGRID enables researchers without specialized robotics training to
create custom parallel mechanisms, thereby decoupling advances in robotic
intelligence from hardware constraints. This work establishes a foundation for
mechanism intelligence, where AI systems actively design robotic hardware,
potentially transforming the development of embodied AI systems.

</details>


### [178] [Learning Multi-Stage Pick-and-Place with a Legged Mobile Manipulator](https://arxiv.org/abs/2509.03859)
*Haichao Zhang,Haonan Yu,Le Zhao,Andrew Choi,Qinxun Bai,Yiqing Yang,Wei Xu*

Main category: cs.RO

TL;DR: 使用完全在模拟中训练的视觉-运动策略，在现实世界中实现了近80%的成功率，用于四足机器人移动操作。


<details>
  <summary>Details</summary>
Motivation: 四足机器人移动操作在机器人领域面临着严峻的挑战，因为它需要多样化的技能、延长的任务周期和部分可观察性。

Method: 提出了一种完全在模拟中训练的视觉-运动策略，该策略可以有效地执行搜索、接近、抓取、运输和放置等动作，并出现了重新抓取和任务链等行为。

Result: 在现实世界中实现了近80%的成功率，并在各种室内外环境中进行了演示。

Conclusion: 提出的方法能够有效地训练四足机器人进行移动操作，并能成功地从模拟转移到现实世界。

Abstract: Quadruped-based mobile manipulation presents significant challenges in
robotics due to the diversity of required skills, the extended task horizon,
and partial observability. After presenting a multi-stage pick-and-place task
as a succinct yet sufficiently rich setup that captures key desiderata for
quadruped-based mobile manipulation, we propose an approach that can train a
visuo-motor policy entirely in simulation, and achieve nearly 80\% success in
the real world. The policy efficiently performs search, approach, grasp,
transport, and drop into actions, with emerged behaviors such as re-grasping
and task chaining. We conduct an extensive set of real-world experiments with
ablation studies highlighting key techniques for efficient training and
effective sim-to-real transfer. Additional experiments demonstrate deployment
across a variety of indoor and outdoor environments. Demo videos and additional
resources are available on the project page:
https://horizonrobotics.github.io/gail/SLIM.

</details>


### [179] [Reactive In-Air Clothing Manipulation with Confidence-Aware Dense Correspondence and Visuotactile Affordance](https://arxiv.org/abs/2509.03889)
*Neha Sunil,Megha Tippur,Arnau Saumell,Edward Adelson,Alberto Rodriguez*

Main category: cs.RO

TL;DR: 该研究提出了一种结合视觉和触觉的双臂机器人框架，用于处理褶皱和悬挂的衣物，解决了衣物操作的复杂性问题。


<details>
  <summary>Details</summary>
Motivation: 衣物操作因其复杂的构型、多变的材料动力学和频繁的自遮挡而具有挑战性。现有系统通常会压平衣物或假设关键特征可见，但本研究旨在直接操作褶皱和悬挂的衣物。

Method: 研究提出了一种双臂视觉-触觉框架。该框架结合了具有置信度感知的密集视觉对应和触觉监督的抓取预演。视觉对应模型在一个自定义的高保真模拟数据集上进行训练，并使用能够捕捉衣物对称性的分布损失，同时生成对应的置信度估计。这些估计指导一个反应式状态机，根据感知不确定性调整折叠策略。此外，一个视觉-触觉抓取预演网络利用高分辨率触觉反馈进行自监督学习，以确定哪些区域是可抓取的。该网络在执行过程中也用于实时抓取验证。通过在低置信度状态下推迟行动，系统能够处理高度遮挡的桌面和空中构型。

Result: 该研究演示了其任务无关的抓取选择模块在折叠和悬挂任务中的应用。此外，研究中提出的密集描述子为其他规划模态（如从人类视频演示中提取抓取目标）提供了一个可重用的中间表示，为更具通用性和可扩展性的衣物操作铺平了道路。

Conclusion: 本研究提出的双臂视觉-触觉框架能够有效地处理褶皱和悬挂的衣物，解决了现有系统在衣物操作中的局限性。通过结合视觉对应和触觉反馈，并利用置信度估计和状态机来适应不确定性，该系统在复杂的衣物操作任务中表现出色。此外，所提出的密集描述子为未来的衣物操作研究提供了有价值的中间表示。

Abstract: Manipulating clothing is challenging due to complex configurations, variable
material dynamics, and frequent self-occlusion. Prior systems often flatten
garments or assume visibility of key features. We present a dual-arm
visuotactile framework that combines confidence-aware dense visual
correspondence and tactile-supervised grasp affordance to operate directly on
crumpled and suspended garments. The correspondence model is trained on a
custom, high-fidelity simulated dataset using a distributional loss that
captures cloth symmetries and generates correspondence confidence estimates.
These estimates guide a reactive state machine that adapts folding strategies
based on perceptual uncertainty. In parallel, a visuotactile grasp affordance
network, self-supervised using high-resolution tactile feedback, determines
which regions are physically graspable. The same tactile classifier is used
during execution for real-time grasp validation. By deferring action in
low-confidence states, the system handles highly occluded table-top and in-air
configurations. We demonstrate our task-agnostic grasp selection module in
folding and hanging tasks. Moreover, our dense descriptors provide a reusable
intermediate representation for other planning modalities, such as extracting
grasp targets from human video demonstrations, paving the way for more
generalizable and scalable garment manipulation.

</details>


### [180] [Odometry Calibration and Pose Estimation of a 4WIS4WID Mobile Wall Climbing Robot](https://arxiv.org/abs/2509.04016)
*Branimir Ćaran,Vladimir Milić,Marko Švaco,Bojan Jerbić*

Main category: cs.RO

TL;DR: 提出一种融合轮式里程计、视觉里程计和惯性测量单元(IMU)数据的多模态测量方法，用于4轮独立转向4轮独立驱动(4WIS4WID)的爬壁移动机器人姿态估计，并采用扩展卡尔曼滤波器(EKF)和无迹卡尔曼滤波器(UKF)进行融合。


<details>
  <summary>Details</summary>
Motivation: 爬壁机器人的操作环境需要精确的位姿信息，而传统传感器（激光、超声波、雷达）和GPS在建筑外墙环境下的可靠性低，因此需要开发新的姿态估计方法。

Method: 提出一种基于扩展卡尔曼滤波器(EKF)和无迹卡尔曼滤波器(UKF)的机器人姿态估计方法，融合了轮式里程计、视觉里程计和IMU数据。同时，利用非线性优化、Levenberg-Marquardt算法、遗传算法和粒子群算法对机器人的系统参数进行校准。

Result: 通过在实验机器人上的实验验证了校准方法和姿态估计器的性能和结果。

Conclusion: 所提出的多模态融合姿态估计方法能够为爬壁移动机器人提供精确的位姿信息，满足其在复杂建筑环境中的操作需求。

Abstract: This paper presents the design of a pose estimator for a four wheel
independent steer four wheel independent drive (4WIS4WID) wall climbing mobile
robot, based on the fusion of multimodal measurements, including wheel
odometry, visual odometry, and an inertial measurement unit (IMU) data using
Extended Kalman Filter (EKF) and Unscented Kalman Filter (UKF). The pose
estimator is a critical component of wall climbing mobile robots, as their
operational environment involves carrying precise measurement equipment and
maintenance tools in construction, requiring information about pose on the
building at the time of measurement. Due to the complex geometry and material
properties of building facades, the use of traditional localization sensors
such as laser, ultrasonic, or radar is often infeasible for wall-climbing
robots. Moreover, GPS-based localization is generally unreliable in these
environments because of signal degradation caused by reinforced concrete and
electromagnetic interference. Consequently, robot odometry remains the primary
source of velocity and position information, despite being susceptible to drift
caused by both systematic and non-systematic errors. The calibrations of the
robot's systematic parameters were conducted using nonlinear optimization and
Levenberg-Marquardt methods as Newton-Gauss and gradient-based model fitting
methods, while Genetic algorithm and Particle swarm were used as
stochastic-based methods for kinematic parameter calibration. Performance and
results of the calibration methods and pose estimators were validated in detail
with experiments on the experimental mobile wall climbing robot.

</details>


### [181] [Cloud-Assisted Remote Control for Aerial Robots: From Theory to Proof-of-Concept Implementation](https://arxiv.org/abs/2509.04095)
*Achilleas Santi Seisa,Viswa Narayanan Sankaranarayanan,Gerasimos Damigos,Sumeet Gajanan Satpute,George Nikolakopoulos*

Main category: cs.RO

TL;DR: 该研究提出了一个可扩展且直观的框架，用于测试云和边缘机器人系统，通过容器化技术和UDP隧道模拟网络延迟和抖动，以应对云机器人集成中的挑战。


<details>
  <summary>Details</summary>
Motivation: 云机器人技术虽然有诸多优势，但在集成过程中面临网络延迟、安全和资源管理等挑战，需要一个有效的测试框架来解决这些问题。

Method: 研究构建了一个包含容器化云集群和容器化机器人仿真环境的框架。利用UDP隧道实现双向通信，并通过Linux流量控制模拟网络延迟和抖动，以一个云辅助的飞控远程控制场景为例。

Result: 提出了一个结合容器化技术和UDP通信的机器人系统测试框架，能够模拟实际网络条件。

Conclusion: 该框架为测试云和边缘机器人系统提供了一个可扩展且直观的解决方案，有助于应对云机器人集成中的实际挑战。

Abstract: Cloud robotics has emerged as a promising technology for robotics
applications due to its advantages of offloading computationally intensive
tasks, facilitating data sharing, and enhancing robot coordination. However,
integrating cloud computing with robotics remains a complex challenge due to
network latency, security concerns, and the need for efficient resource
management. In this work, we present a scalable and intuitive framework for
testing cloud and edge robotic systems. The framework consists of two main
components enabled by containerized technology: (a) a containerized cloud
cluster and (b) the containerized robot simulation environment. The system
incorporates two endpoints of a User Datagram Protocol (UDP) tunnel, enabling
bidirectional communication between the cloud cluster container and the robot
simulation environment, while simulating realistic network conditions. To
achieve this, we consider the use case of cloud-assisted remote control for
aerial robots, while utilizing Linux-based traffic control to introduce
artificial delay and jitter, replicating variable network conditions
encountered in practical cloud-robot deployments.

</details>


### [182] [FPC-VLA: A Vision-Language-Action Framework with a Supervisor for Failure Prediction and Correction](https://arxiv.org/abs/2509.04018)
*Yifan Yang,Zhixiang Duan,Tianshi Xie,Fuyu Cao,Pinxi Shen,Peili Song,Piaopiao Jin,Guokang Sun,Shaoqing Xu,Yangwei You,Jingtai Liu*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Robotic manipulation is a fundamental component of automation. However,
traditional perception-planning pipelines often fall short in open-ended tasks
due to limited flexibility, while the architecture of a single end-to-end
Vision-Language-Action (VLA) offers promising capabilities but lacks crucial
mechanisms for anticipating and recovering from failure. To address these
challenges, we propose FPC-VLA, a dual-model framework that integrates VLA with
a supervisor for failure prediction and correction. The supervisor evaluates
action viability through vision-language queries and generates corrective
strategies when risks arise, trained efficiently without manual labeling. A
similarity-guided fusion module further refines actions by leveraging past
predictions. Evaluation results on multiple simulation platforms (SIMPLER and
LIBERO) and robot embodiments (WidowX, Google Robot, Franka) show that FPC-VLA
outperforms state-of-the-art models in both zero-shot and fine-tuned settings.
By activating the supervisor only at keyframes, our approach significantly
increases task success rates with minimal impact on execution time. Successful
real-world deployments on diverse, long-horizon tasks confirm FPC-VLA's strong
generalization and practical utility for building more reliable autonomous
systems.

</details>


### [183] [Integrated Wheel Sensor Communication using ESP32 -- A Contribution towards a Digital Twin of the Road System](https://arxiv.org/abs/2509.04061)
*Ventseslav Yordanov,Simon Schäfer,Alexander Mann,Stefan Kowalewski,Bassam Alrifaee,Lutz Eckstein*

Main category: cs.RO

TL;DR: 本研究提出了一种新颖的轮毂传感器数据通信方案，该方案使用发布-订阅系统，能够高效传输集成轮毂传感器数据，并且在数据传输量上优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有车载状态估计算法无法提供轮胎与路面交互的详细信息，因此需要新的通信方法来传输更全面的传感器数据。

Method: 提出并实现了一种基于发布-订阅系统的轮毂传感器数据传输方案，并在鼓式轮胎测试台上进行了测试。

Result: 在1 Hz到32 000 Hz的采样频率下，该方案实现了低数据丢失率（约0.1%），验证了通信概念的有效性。

Conclusion: 所提出的通信系统能够可靠地传输集成轮毂传感器数据，为优化轮毂传感器通信和实现实时数据采集提供了新的途径。

Abstract: While current onboard state estimation methods are adequate for most driving
and safety-related applications, they do not provide insights into the
interaction between tires and road surfaces. This paper explores a novel
communication concept for efficiently transmitting integrated wheel sensor data
from an ESP32 microcontroller. Our proposed approach utilizes a
publish-subscribe system, surpassing comparable solutions in the literature
regarding data transmission volume. We tested this approach on a drum tire test
rig with our prototype sensors system utilizing a diverse selection of sample
frequencies between 1 Hz and 32 000 Hz to demonstrate the efficacy of our
communication concept. The implemented prototype sensor showcases minimal data
loss, approximately 0.1 % of the sampled data, validating the reliability of
our developed communication system. This work contributes to advancing
real-time data acquisition, providing insights into optimizing integrated wheel
sensor communication.

</details>


### [184] [Balancing Signal and Variance: Adaptive Offline RL Post-Training for VLA Flow Models](https://arxiv.org/abs/2509.04063)
*Hongyin Zhang,Shiyuan Zhang,Junxi Jin,Qixin Zeng,Yifan Qiao,Hongchao Lu,Donglin Wang*

Main category: cs.RO

TL;DR: 基于流匹配的视觉-语言-动作(VLA)模型在通用机器人操作任务中表现出色，但在复杂下游任务上的动作准确性不佳。该研究提出了自适应强化流匹配(ARFM)算法，通过引入自适应调整的缩放因子来平衡强化学习信号和流损失的方差，以提高VLA模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于流匹配的VLA模型在复杂下游任务上的动作准确性不足，因为它们仅依赖于模仿学习的训练后范式，难以深入理解数据质量的分布特性，而这正是强化学习(RL)所擅长的。

Method: 提出了一种离线RL后训练目标，并开发了一种名为自适应强化流匹配(ARFM)的高效可行的离线RL微调算法。ARFM通过在VLA流模型损失中引入自适应调整的缩放因子，构建了一个原则性的偏差-方差权衡目标函数，以最优地控制RL信号对流损失的影响。ARFM自适应地平衡了RL优势保留和流损失梯度方差控制，从而实现了更稳定、更高效的微调过程。

Result: ARFM在模拟和真实世界的广泛实验中表现出优异的泛化、鲁棒性、少样本学习和持续学习性能。

Conclusion: ARFM算法通过结合强化学习和流匹配的优势，有效提高了VLA模型在复杂机器人操作任务中的性能。

Abstract: Vision-Language-Action (VLA) models based on flow matching have shown
excellent performance in general-purpose robotic manipulation tasks. However,
the action accuracy of these models on complex downstream tasks is
unsatisfactory. One important reason is that these models rely solely on the
post-training paradigm of imitation learning, which makes it difficult to have
a deeper understanding of the distribution properties of data quality, which is
exactly what Reinforcement Learning (RL) excels at. In this paper, we
theoretically propose an offline RL post-training objective for VLA flow models
and induce an efficient and feasible offline RL fine-tuning algorithm --
Adaptive Reinforced Flow Matching (ARFM). By introducing an adaptively adjusted
scaling factor in the VLA flow model loss, we construct a principled
bias-variance trade-off objective function to optimally control the impact of
RL signal on flow loss. ARFM adaptively balances RL advantage preservation and
flow loss gradient variance control, resulting in a more stable and efficient
fine-tuning process. Extensive simulation and real-world experimental results
show that ARFM exhibits excellent generalization, robustness, few-shot
learning, and continuous learning performance.

</details>


### [185] [Solving Robotics Tasks with Prior Demonstration via Exploration-Efficient Deep Reinforcement Learning](https://arxiv.org/abs/2509.04069)
*Chengyandan Shen,Christoffer Sloth*

Main category: cs.RO

TL;DR: 该研究提出了一种名为 DRLR 的探索高效深度强化学习框架，通过结合演示来学习机器人任务。DRLR 基于 IBRL 算法，通过改进动作选择模块来减少引导误差，并使用 SAC 策略代替 TD3 以防止收敛到次优策略。实验证明 DRLR 在模拟和真实机器人任务中均有效，并能处理不同状态-动作维度和演示质量。


<details>
  <summary>Details</summary>
Motivation: 机器人任务的学习通常需要大量的环境交互，并且可能存在引导误差和次优策略收敛的问题。该研究旨在提出一种更有效的强化学习框架来解决这些挑战。

Method: 提出 DRLR 框架，基于 IBRL 算法，改进了动作选择模块以提供校准的 Q 值，从而减少引导误差。使用 SAC 策略代替 TD3 以防止收敛到次优策略。

Result: 在机器人抓取和开抽屉任务中，DRLR 框架被证明能有效减少引导误差和防止过拟合。该框架在不同状态-动作维度和演示质量的任务中表现出鲁棒性。在真实机器人上进行的 bucket loading 任务也验证了该框架的有效性。

Conclusion: DRLR 框架通过改进动作选择和采用 SAC 策略，能够高效地学习机器人任务，有效解决了引导误差和次优策略收敛的问题，并在模拟和真实环境中均得到验证。

Abstract: This paper proposes an exploration-efficient Deep Reinforcement Learning with
Reference policy (DRLR) framework for learning robotics tasks that incorporates
demonstrations. The DRLR framework is developed based on an algorithm called
Imitation Bootstrapped Reinforcement Learning (IBRL). We propose to improve
IBRL by modifying the action selection module. The proposed action selection
module provides a calibrated Q-value, which mitigates the bootstrapping error
that otherwise leads to inefficient exploration. Furthermore, to prevent the RL
policy from converging to a sub-optimal policy, SAC is used as the RL policy
instead of TD3. The effectiveness of our method in mitigating bootstrapping
error and preventing overfitting is empirically validated by learning two
robotics tasks: bucket loading and open drawer, which require extensive
interactions with the environment. Simulation results also demonstrate the
robustness of the DRLR framework across tasks with both low and high
state-action dimensions, and varying demonstration qualities. To evaluate the
developed framework on a real-world industrial robotics task, the bucket
loading task is deployed on a real wheel loader. The sim2real results validate
the successful deployment of the DRLR framework.

</details>


### [186] [Keypoint-based Diffusion for Robotic Motion Planning on the NICOL Robot](https://arxiv.org/abs/2509.04076)
*Lennart Clasmeier,Jan-Gerrit Habekost,Connor Gäde,Philipp Allgeuer,Stefan Wermter*

Main category: cs.RO

TL;DR: 提出了一种新颖的基于扩散的机器人运动规划动作模型，该模型通过深度学习显著减少了运行时间，并取得了高成功率。


<details>
  <summary>Details</summary>
Motivation: 传统的数值规划方法在解决机器人运动规划问题时运行时间长，而深度学习方法有望在更短的时间内获得更好的结果。

Method: 提出了一种基于扩散的动作模型，并使用点云嵌入作为输入来预测基于关键点的关节序列。通过数据集改进和消融研究来优化模型。

Result: 该模型在不使用点云编码的情况下，运行时间比数值模型快一个数量级，并且在测试集上达到了高达90%的无碰撞解决方案成功率。

Conclusion: 基于扩散的动作模型是一种有前景的机器人运动规划方法，通过改进数据集和模型结构可以进一步提高性能。

Abstract: We propose a novel diffusion-based action model for robotic motion planning.
Commonly, established numerical planning approaches are used to solve general
motion planning problems, but have significant runtime requirements. By
leveraging the power of deep learning, we are able to achieve good results in a
much smaller runtime by learning from a dataset generated by these planners.
While our initial model uses point cloud embeddings in the input to predict
keypoint-based joint sequences in its output, we observed in our ablation study
that it remained challenging to condition the network on the point cloud
embeddings. We identified some biases in our dataset and refined it, which
improved the model's performance. Our model, even without the use of the point
cloud encodings, outperforms numerical models by an order of magnitude
regarding the runtime, while reaching a success rate of up to 90% of collision
free solutions on the test set.

</details>


### [187] [Object-Reconstruction-Aware Whole-body Control of Mobile Manipulators](https://arxiv.org/abs/2509.04094)
*Fatih Dursun,Bruno Vilhena Adorno,Simon Watson,Wei Pan*

Main category: cs.RO

TL;DR: 该研究提出了一种计算高效的机器人视点规划方法，通过将机器人控制在对未知区域最具信息量的焦点上，无需额外的路径规划器，并证明其在模拟和真实世界实验中与基于采样的基线方法在覆盖率和熵方面无显著差异，同时速度提升约九倍。


<details>
  <summary>Details</summary>
Motivation: 在机器人对象重建和检查任务中，找到能揭示最多未知区域的视点路径至关重要，但现有方法计算成本高昂。

Method: 提出一种计算高效的解决方案：计算最信息区域（未知区域）的焦点，并让机器人在路径中保持该焦点在相机视野内，将其整合到机器人全身控制和可见性约束中，无需额外路径规划器。

Result: 与基于采样的规划策略相比，提出的方法在对象覆盖率和熵方面没有显著差异，但计算速度平均快了九倍。

Conclusion: 所提出的方法在计算效率和性能上都优于基于采样的基线方法，为机器人对象重建和检查任务提供了一种有效的视点规划方案。

Abstract: Object reconstruction and inspection tasks play a crucial role in various
robotics applications. Identifying paths that reveal the most unknown areas of
the object becomes paramount in this context, as it directly affects
efficiency, and this problem is known as the view path planning problem.
Current methods often use sampling-based path planning techniques, evaluating
potential views along the path to enhance reconstruction performance. However,
these methods are computationally expensive as they require evaluating several
candidate views on the path. To this end, we propose a computationally
efficient solution that relies on calculating a focus point in the most
informative (unknown) region and having the robot maintain this point in the
camera field of view along the path. We incorporated this strategy into the
whole-body control of a mobile manipulator employing a visibility constraint
without the need for an additional path planner. We conducted comprehensive and
realistic simulations using a large dataset of 114 diverse objects of varying
sizes from 57 categories to compare our method with a sampling-based planning
strategy using Bayesian data analysis. Furthermore, we performed real-world
experiments with an 8-DoF mobile manipulator to demonstrate the proposed
method's performance in practice. Our results suggest that there is no
significant difference in object coverage and entropy. In contrast, our method
is approximately nine times faster than the baseline sampling-based method in
terms of the average time the robot spends between views.

</details>


### [188] [Lightweight Kinematic and Static Modeling of Cable-Driven Continuum Robots via Actuation-Space Energy Formulation](https://arxiv.org/abs/2509.04119)
*Ke Wu,Yuhao Wang,Kevin Henry,Cesare Stefanini,Gang Zheng*

Main category: cs.RO

TL;DR: LASEM是一个用于线驱动连续机器人的轻量级驱动空间能量建模框架，通过能量最小化方法实现运动规划和控制。


<details>
  <summary>Details</summary>
Motivation: 连续机器人因其灵活性和顺应性而适用于复杂环境，但其变形形态给运动规划和控制带来挑战，需要精确轻量级的模型。

Method: LASEM框架直接在驱动空间中构建驱动势能，利用Hamilton原理和非线性梁杆理论推导前向模型，避免显式建模缆绳与主体的接触，并统一了运动学和静力学。该模型考虑了非均匀几何、任意缆绳布线、分布载荷和轴向延展性，并开发了逆运动学求解的半解析迭代方案。

Result: 数值模拟验证了LASEM的准确性，并提出通过数值优化来处理实际中的离散化问题，同时无需显式接触建模即可纳入缆绳势能。

Conclusion: LASEM框架为线驱动连续机器人的运动规划和控制提供了一个准确、轻量且计算高效的解决方案。

Abstract: Continuum robots, inspired by octopus arms and elephant trunks, combine
dexterity with intrinsic compliance, making them well suited for unstructured
and confined environments. Yet their continuously deformable morphology poses
challenges for motion planning and control, calling for accurate but
lightweight models. We propose the Lightweight Actuation Space Energy Modeling
(LASEM) framework for cable driven continuum robots, which formulates actuation
potential energy directly in actuation space. LASEM yields an analytical
forward model derived from geometrically nonlinear beam and rod theories via
Hamilton's principle, while avoiding explicit modeling of cable backbone
contact. It accepts both force and displacement inputs, thereby unifying
kinematic and static formulations. Assuming the friction is neglected, the
framework generalizes to nonuniform geometries, arbitrary cable routings,
distributed loading and axial extensibility, while remaining computationally
efficient for real-time use. Numerical simulations validate its accuracy, and a
semi-analytical iterative scheme is developed for inverse kinematics. To
address discretization in practical robots, LASEM further reformulates the
functional minimization as a numerical optimization, which also naturally
incorporates cable potential energy without explicit contact modeling.

</details>


### [189] [OVGrasp: Open-Vocabulary Grasping Assistance via Multimodal Intent Detection](https://arxiv.org/abs/2509.04324)
*Chen Hu,Shan Luo,Letizia Gionfrida*

Main category: cs.RO

TL;DR: OVGrasp是一个用于软exoskeleton抓握辅助的框架，通过RGB-D视觉、开放词汇提示和语音命令实现多模态交互，能够零样本识别新物体并理解用户意图，在实验中表现优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 为 motor impairments 患者在非结构化环境中恢复自主抓握能力，满足多样化和不可预测的用户意图。

Method: 采用分层控制框架，集成RGB-D视觉、开放词汇提示和语音命令。利用视觉-语言基础模型实现开放词汇识别，并通过多模态决策者融合空间和语言线索以推断用户意图。

Result: 在15个物体和3种抓握类型上进行了系统评估，10名参与者测试。OVGrasp达到了87.00%的抓握能力得分（GAS），优于现有基线，并在运动学上更接近自然手部运动。

Conclusion: OVGrasp框架成功地通过多模态交互实现了对软exoskeleton抓握的辅助，能够适应开放环境和用户意图，并取得了优于现有技术的性能。

Abstract: Grasping assistance is essential for restoring autonomy in individuals with
motor impairments, particularly in unstructured environments where object
categories and user intentions are diverse and unpredictable. We present
OVGrasp, a hierarchical control framework for soft exoskeleton-based grasp
assistance that integrates RGB-D vision, open-vocabulary prompts, and voice
commands to enable robust multimodal interaction. To enhance generalization in
open environments, OVGrasp incorporates a vision-language foundation model with
an open-vocabulary mechanism, allowing zero-shot detection of previously unseen
objects without retraining. A multimodal decision-maker further fuses spatial
and linguistic cues to infer user intent, such as grasp or release, in
multi-object scenarios. We deploy the complete framework on a custom
egocentric-view wearable exoskeleton and conduct systematic evaluations on 15
objects across three grasp types. Experimental results with ten participants
demonstrate that OVGrasp achieves a grasping ability score (GAS) of 87.00%,
outperforming state-of-the-art baselines and achieving improved kinematic
alignment with natural hand motion.

</details>


### [190] [DEXOP: A Device for Robotic Transfer of Dexterous Human Manipulation](https://arxiv.org/abs/2509.04441)
*Hao-Shu Fang,Branden Romero,Yichen Xie,Arthur Hu,Bo-Ruei Huang,Juan Alvarez,Matthew Kim,Gabriel Margolis,Kavya Anbarasu,Masayoshi Tomizuka,Edward Adelson,Pulkit Agrawal*

Main category: cs.RO

TL;DR: DEXOP是一个被动手部外骨骼，通过模仿人类手部姿势和提供力反馈，实现高质量的机器人数据采集，提高数据在真实机器人上的可转移性。


<details>
  <summary>Details</summary>
Motivation: 为了提高机器人数据采集的效率和数据在真实机器人上的可转移性，并使之能够处理多样化的灵巧操作任务。

Method: 提出了一种名为perioperation的数据采集范式，并实现为DEXOP外骨骼。DEXOP通过机械连接人手和机械手，提供触觉和本体感觉反馈，模仿人手姿势，使用户能更自然地进行任务演示。

Result: DEXOP能够大规模采集高质量演示数据，并且用DEXOP数据训练出的策略在每单位数据采集时间内的任务表现优于使用远程操作的数据训练出的策略。

Conclusion: DEXOP是一种强大的机器人灵巧性提升工具，它通过优越的数据采集方式显著提高了数据收集的效率和数据质量。

Abstract: We introduce perioperation, a paradigm for robotic data collection that
sensorizes and records human manipulation while maximizing the transferability
of the data to real robots. We implement this paradigm in DEXOP, a passive hand
exoskeleton designed to maximize human ability to collect rich sensory (vision
+ tactile) data for diverse dexterous manipulation tasks in natural
environments. DEXOP mechanically connects human fingers to robot fingers,
providing users with direct contact feedback (via proprioception) and mirrors
the human hand pose to the passive robot hand to maximize the transfer of
demonstrated skills to the robot. The force feedback and pose mirroring make
task demonstrations more natural for humans compared to teleoperation,
increasing both speed and accuracy. We evaluate DEXOP across a range of
dexterous, contact-rich tasks, demonstrating its ability to collect
high-quality demonstration data at scale. Policies learned with DEXOP data
significantly improve task performance per unit time of data collection
compared to teleoperation, making DEXOP a powerful tool for advancing robot
dexterity. Our project page is at https://dex-op.github.io.

</details>


### [191] [EMMA: Scaling Mobile Manipulation via Egocentric Human Data](https://arxiv.org/abs/2509.04443)
*Lawrence Y. Zhu,Pranav Kuppili,Ryan Punamiya,Patcharapong Aphiwetsa,Dhruv Patel,Simar Kareer,Sehoon Ha,Danfei Xu*

Main category: cs.RO

TL;DR: EMMA框架使用人类全身运动数据和静态机器人数据进行训练，无需昂贵的移动机器人遥操作，即可在移动操作模仿学习中实现可扩展性，并在真实世界任务中取得与遥操作数据训练的基线相当的性能。


<details>
  <summary>Details</summary>
Motivation: 移动操作模仿学习面临昂贵的移动机器人遥操作成本瓶颈。

Method: EMMA框架联合训练人类全身运动数据和静态机器人数据，以训练移动操作策略，从而绕过移动遥操作。

Result: EMMA在三个真实世界任务中的实验表明，其性能与在遥操作移动机器人数据上训练的基线相当，在完整任务成功率方面表现更高或同等水平。EMMA能够泛化到新的空间配置和场景，并且随着人类数据的增加，性能呈现正向扩展。

Conclusion: EMMA为在真实世界环境中实现可扩展的机器人学习开辟了新途径，解决了移动操作模仿学习的成本瓶颈。

Abstract: Scaling mobile manipulation imitation learning is bottlenecked by expensive
mobile robot teleoperation. We present Egocentric Mobile MAnipulation (EMMA),
an end-to-end framework training mobile manipulation policies from human mobile
manipulation data with static robot data, sidestepping mobile teleoperation. To
accomplish this, we co-train human full-body motion data with static robot
data. In our experiments across three real-world tasks, EMMA demonstrates
comparable performance to baselines trained on teleoperated mobile robot data
(Mobile ALOHA), achieving higher or equivalent task performance in full task
success. We find that EMMA is able to generalize to new spatial configurations
and scenes, and we observe positive performance scaling as we increase the
hours of human data, opening new avenues for scalable robotic learning in
real-world environments. Details of this project can be found at
https://ego-moma.github.io/.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [192] [Hardware-Aware Data and Instruction Mapping for AI Tasks: Balancing Parallelism, I/O and Memory Tradeoffs](https://arxiv.org/abs/2509.03846)
*Md Rownak Hossain Chowdhury,Mostafizur Rahman*

Main category: cs.AR

TL;DR: 该框架通过生成统一的指令和数据流，使硬件能够自主执行操作和路由信息，从而减少对I/O、片外内存和主机控制的依赖。


<details>
  <summary>Details</summary>
Motivation: 利用可预测的神经网络行为来提前规划计算和通信，以提高硬件的自主性和效率。

Method: 通过在可编程的消息传递计算架构上进行细粒度的消息传递，并利用固定权重重用、阵列内多播和分阶段归约等技术，将数据移动保持在本地并协调跨阵列的计算。

Result: 在VGG-19上的应用实现了88%至92%的高利用率，超过97%的消息在内部生成，近89%的时间消耗在片上数据传输。计算吞吐量在较大阵列上超过1 TFLOP/s，重用和局部聚合带来的流量减少高达每层100 MB。

Conclusion: 结果证明了流计算的有效性，并展示了该框架如何通过紧密协调硬件之间的数据和指令流来实现这种执行方式。

Abstract: We introduce a mapping framework for deep learning inference that takes
advantage of predictable neural network behavior to plan both computation and
communication ahead of time. The framework generates a unified stream of
instructions and data, enabling the hardware to execute operations and route
information on its own, without frequent involvement from the host and with
minimal off-chip memory use. This naturally reduces reliance on I/O, off-chip
memory, and host control. By leveraging fine-grained message passing on a
programmable, message-based compute architecture, the framework keeps data
movement local and coordinates computation across the array using techniques
such as stationary-weight reuse, in-array multicasting, and staged reductions.
Applied to VGG-19, the framework sustains high utilization (88 to 92 percent),
with over 97 percent of messages generated internally and nearly 89 percent of
time consumed on-chip transfers. Computation throughput scales beyond 1 TFLOP/s
on larger arrays, while traffic reductions from reuse and local aggregation
reach up to 100 MB per layer. Overall, the results highlight the effectiveness
of streaming-based computation and show how our mapper enables this execution
style by tightly coordinating data and instruction flow across the hardware.

</details>


### [193] [Real Time FPGA Based CNNs for Detection, Classification, and Tracking in Autonomous Systems: State of the Art Designs and Optimizations](https://arxiv.org/abs/2509.04153)
*Safa Mohammed Sali,Mahmoud Meribout,Ashiyana Abdul Majeed*

Main category: cs.AR

TL;DR: 本篇论文是对卷积神经网络（CNN）在现场可编程门阵列（FPGA）上进行目标检测、分类和跟踪的最新进展进行的回顾。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶汽车、机器人和监控等领域对实时计算机视觉应用的需求不断增长，FPGA 因其可重构性、低功耗和确定性延迟，已成为 GPU 和 ASIC 的有力替代品。

Method: 论文回顾了基于 CNN 的视觉任务的最新 FPGA 实现，涵盖了算法创新、硬件加速技术以及剪枝、量化和稀疏感知方法等优化策略的集成，以在硬件约束下最大化性能。此外，还探讨了现代 FPGA 平台（包括经典的 LUT-DSP 架构、SoC FPGA 和 ACAP）在处理深度学习工作负载方面的能力。最后，论文讨论了混合架构（结合 GPU 和 FPGA）以及硬件-软件协同设计实践、数据流优化和流水线处理技术。

Result: 本综述为研究人员和工程师提供了在资源受限设备上进行实时推理的见解，以开发针对边缘和嵌入式应用优化的下一代、节能、高性能视觉系统。

Conclusion: 本篇论文全面回顾了在 FPGA 上部署 CNN 进行计算机视觉任务的最新进展，并为开发优化的边缘和嵌入式视觉系统提供了指导。

Abstract: This paper presents a comprehensive review of recent advances in deploying
convolutional neural networks (CNNs) for object detection, classification, and
tracking on Field Programmable Gate Arrays (FPGAs). With the increasing demand
for real-time computer vision applications in domains such as autonomous
vehicles, robotics, and surveillance, FPGAs have emerged as a powerful
alternative to GPUs and ASICs due to their reconfigurability, low power
consumption, and deterministic latency. We critically examine state-of-the-art
FPGA implementations of CNN-based vision tasks, covering algorithmic
innovations, hardware acceleration techniques, and the integration of
optimization strategies like pruning, quantization, and sparsity-aware methods
to maximize performance within hardware constraints. This survey also explores
the landscape of modern FPGA platforms, including classical LUT-DSP based
architectures, System-on-Chip (SoC) FPGAs, and Adaptive Compute Acceleration
Platforms (ACAPs), comparing their capabilities in handling deep learning
workloads. Furthermore, we review available software development tools such as
Vitis AI, FINN, and Intel FPGA AI Suite, which significantly streamline the
design and deployment of AI models on FPGAs. The paper uniquely discusses
hybrid architecture that combine GPUs and FPGAs for collaborative acceleration
of AI inference, addressing challenges related to energy efficiency and
throughput. Additionally, we highlight hardware-software co-design practices,
dataflow optimizations, and pipelined processing techniques essential for
real-time inference on resource-constrained devices. Through this survey,
researchers and engineers are equipped with insights to develop
next-generation, power-efficient, and high-performance vision systems optimized
for FPGA deployment in edge and embedded applications.

</details>


### [194] [Real Time FPGA Based Transformers & VLMs for Vision Tasks: SOTA Designs and Optimizations](https://arxiv.org/abs/2509.04162)
*Safa Mohammed Sali,Mahmoud Meribout,Ashiyana Abdul Majeed*

Main category: cs.AR

TL;DR: 该论文全面回顾了在FPGA上部署Transformer和视觉-语言模型（VLMs）的设计权衡、优化策略和实现挑战，并讨论了新兴趋势和未来方向。


<details>
  <summary>Details</summary>
Motivation: Transformer和VLMs在计算机视觉和多模态AI领域表现优异，但其高计算复杂度和内存占用限制了它们在资源受限环境下的部署。FPGA因其可重构性、细粒度并行性和能效优势，为这些工作负载提供了一个有吸引力的硬件平台。

Method: 本文对FPGA上Transformer和VLMs的推理进行了全面的设计权衡、优化策略和实现挑战的回顾。研究了设备类别选择、内存子系统约束、数据流编排、量化策略、稀疏性利用和工具链选择等关键因素，以及VLMs特有的异构计算平衡和交叉注意力内存管理等特定于模态的问题。此外，还讨论了硬件-算法协同设计的趋势，包括注意力机制、压缩和模块化叠加的创新。最后，还考虑了运行时的灵活性、验证开销以及缺乏标准化的FPGA多模态基准等实际问题，并概述了面向可扩展、可移植和可重构FPGA解决方案的未来方向。

Result: 论文系统地分析了FPGA部署Transformer和VLMs的关键因素，包括设备选择、内存、数据流、量化、稀疏性、工具链以及VLMs特有的挑战。讨论了硬件-算法协同设计的进展，并指出了实际部署中面临的挑战，如灵活性和标准化基准的缺乏。

Conclusion: 为了弥合先进多模态AI模型与高效FPGA部署之间的差距，论文提出了一个技术基础和前瞻性视角，旨在实现可扩展、可移植和可重构的FPGA解决方案，以适应不断发展的模型架构并保持高利用率和可预测的性能。

Abstract: Transformers and vision-language models (VLMs) have emerged as dominant
architectures in computer vision and multimodal AI, offering state-of-the-art
performance in tasks such as image classification, object detection, visual
question answering, and caption generation. However, their high computational
complexity, large memory footprints, and irregular data access patterns present
significant challenges for deployment in latency- and power-constrained
environments. Field-programmable gate arrays (FPGAs) provide an attractive
hardware platform for such workloads due to their reconfigurability,
fine-grained parallelism, and potential for energy-efficient acceleration. This
paper presents a comprehensive review of design trade-offs, optimization
strategies, and implementation challenges for FPGA-based inference of
transformers and VLMs. We examine critical factors such as device-class
selection, memory subsystem constraints, dataflow orchestration, quantization
strategies, sparsity exploitation, and toolchain choices, alongside
modality-specific issues unique to VLMs, including heterogeneous compute
balancing and cross-attention memory management. Additionally, we discuss
emerging trends in hardware-algorithm co-design, highlighting innovations in
attention mechanisms, compression, and modular overlays to improve efficiency
and adaptability. Practical issues such as runtime flexibility, verification
overhead, and the absence of standardized FPGA multimodal benchmarks are also
considered. Finally, we outline future directions toward scalable, portable,
and reconfigurable FPGA solutions that adapt to evolving model architectures
while sustaining high utilization and predictable performance. This synthesis
offers both a technical foundation and a forward-looking perspective to help
bridge the gap between advanced multimodal AI models and efficient FPGA
deployment.

</details>


### [195] [Real-time Object Detection and Associated Hardware Accelerators Targeting Autonomous Vehicles: A Review](https://arxiv.org/abs/2509.04173)
*Safa Sali,Anis Meribout,Ashiyana Majeed,Mahmoud Meribout,Juan Pablo,Varun Tiwari,Asma Baobaid*

Main category: cs.AR

TL;DR: 本综述全面概述了用于自动驾驶汽车的实时目标检测算法及其硬件加速器。


<details>
  <summary>Details</summary>
Motivation: 为了满足自动驾驶汽车（AVs）对安全性和实时响应能力的需求，本研究旨在调查实时目标检测（OD）算法及其硬件加速器（HAs）。

Method: 本文回顾了当前先进的目标检测算法，并着重探讨了其在自动驾驶汽车领域的应用，特别是卷积神经网络（CNNs）及其在GPU和ASIC等硬件上的部署。

Result: 尽管目前的算法和硬件可以达到数百帧/秒（fps）的处理速度，但要满足自动驾驶汽车所有摄像头的检测需求，仍需进一步的硬件和算法改进。此外，商业自动驾驶汽车领域算法和硬件细节的缺乏，给学术研究带来了挑战。

Conclusion: 本研究旨在弥合学术界在目标检测算法研究与商业自动驾驶汽车技术之间的差距，为未来自动驾驶汽车的设计提供参考。

Abstract: The efficiency of object detectors depends on factors like detection
accuracy, processing time, and computational resources. Processing time is
crucial for real-time applications, particularly for autonomous vehicles (AVs),
where instantaneous responses are vital for safety. This review paper provides
a concise yet comprehensive survey of real-time object detection (OD)
algorithms for autonomous cars delving into their hardware accelerators (HAs).
Non-neural network-based algorithms, which use statistical image processing,
have been entirely substituted by AI algorithms, such as different models of
convolutional neural networks (CNNs). Their intrinsically parallel features led
them to be deployable into edge-based HAs of various types, where GPUs and, to
a lesser extent, ASIC (application-specific integrated circuit) remain the most
widely used. Throughputs of hundreds of frames/s (fps) could be reached;
however, handling object detection for all the cameras available in a typical
AV requires further hardware and algorithmic improvements. The intensive
competition between AV providers has limited the disclosure of algorithms,
firmware, and even hardware platform details. This remains a hurdle for
researchers, as commercial systems provide valuable insights while academics
undergo lengthy training and testing on restricted datasets and road scenarios.
Consequently, many AV research papers may not be reflected in end products,
being developed under limited conditions. This paper surveys state-of-the-art
OD algorithms and aims to bridge the gap with technologies in commercial AVs.
To our knowledge, this aspect has not been addressed in earlier surveys. Hence,
the paper serves as a tangible reference for researchers designing future
generations of vehicles, expected to be fully autonomous for comfort and
safety.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [196] [The Chaotic Art: Quantum Representation and Manipulation of Color](https://arxiv.org/abs/2509.03542)
*Guosheng Hu*

Main category: quant-ph

TL;DR: 本文提出了一种在量子计算环境中进行颜色计算的新技术路径，该路径利用量子比特表示、处理和生成数字颜色。


<details>
  <summary>Details</summary>
Motivation: 量子计算的独特性质将深刻改变色彩艺术的图景，因此需要探索量子计算在颜色艺术中的应用。

Method: 提出一种新的技术路径，通过量子比特表示、处理和生成数字颜色，并能将计算结果恢复给经典计算机。通过在Qiskit和IBM Q中进行编程实验来验证该方法的可行性。

Result: 通过编程实验证明了该方法作为颜色量子比特表示和量子计算的一种艺术技术是可行的。

Conclusion: 该方法在经典色彩学和量子图形学之间搭建了桥梁，有望将量子计算应用于信息可视化、图像处理等颜色计算任务，并可能促进新的色彩理论和艺术概念的发展。

Abstract: Due to its unique computing principles, quantum computing technology will
profoundly change the spectacle of color art. Focusing on experimental
exploration of color qubit representation, color channel processing, and color
image generation via quantum computing, this article proposes a new technical
path for color computing in quantum computing environment, by which digital
color is represented, operated, and measured in quantum bits, and then restored
for classical computers as computing results. This method has been proved
practicable as an artistic technique of color qubit representation and quantum
computing via programming experiments in Qiskit and IBM Q. By building a bridge
between classical chromatics and quantum graphics, quantum computers can be
used for information visualization, image processing, and more color computing
tasks. Furthermore, quantum computing can be expected to facilitate new color
theories and artistic concepts.

</details>


### [197] [Another formula for calculating Clebsch Gordan coefficients](https://arxiv.org/abs/2509.03555)
*Everardo Rivera-Oliva*

Main category: quant-ph

TL;DR: 提出了一种计算Clebsch-Gordan系数的新公式，使用角动量升算符来重构子空间，克服了传统方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 推导出量子系统中Clebsch-Gordan系数的综合公式。

Method: 通过迭代应用角动量升降算符来重构状态，特别是利用$J{+}$升算符来重构非最大总角动量的子空间。

Result: 推导出了一个新的Clebsch-Gordan系数计算公式。

Conclusion: 该新公式为计算Clebsch-Gordan系数提供了一种替代方法，是对现有方法的补充。

Abstract: This article presents the derivation of a comprehensive formula for the
Clebsch-Gordan coefficients in a quantum system. The formula is derived by
employing the iterative application of angular momentum ladder operators on
each defined angular momentum subspace to reconstruct the states in the total
angular momentum base. The novelty aspect of this approach lies in the
utilization of the $J{+}$ raising operator to reconstruct subspaces
characterized by non-maximal total angular momentum, in contrast to the
conventional Gram-Schmidt procedure typically employed in the standard
literature.This enables us to derive a new formula that provides an alternative
approach for computing these coefficients, complementing the existing ones
found in the literature.

</details>


### [198] [Quantum-Assisted Correlation Clustering](https://arxiv.org/abs/2509.03561)
*Antonio Macaluso,Supreeth Mysore Venkatesh,Diego Arenas,Matthias Klusch,Andreas Dengel*

Main category: quant-ph

TL;DR: 提出了一种混合量子-经典方法来解决相关聚类问题，该方法通过递归分裂划分将量子退火集成到分层聚类框架中，以处理具有任意相关结构（包括负边）的图，并且在真实世界数据集上优于经典算法。


<details>
  <summary>Details</summary>
Motivation: 现有相关聚类方法在处理具有负相关或不规则结构的图时存在局限性，并且通常需要预先定义簇的数量。

Method: 将一种名为 GCS-Q 的量子辅助求解器改编用于相关聚类，通过递归分裂划分来最大化有符号图中的簇内协议。该方法将每个二等分步骤编码为二次无约束二元优化（QUBO）问题，并使用量子退火求解。

Result: 在合成有符号图和真实世界高光谱成像数据集上的经验评估表明，与经典算法相比，所提出的 GCS-Q 方法在鲁棒性和聚类质量方面表现更好，尤其是在存在簇大小不平衡的情况下。

Conclusion: 混合量子-经典优化方法在处理具有挑战性的图相关聚类任务方面显示出巨大潜力，有望推动可扩展且结构感知聚类技术的发展。

Abstract: This work introduces a hybrid quantum-classical method to correlation
clustering, a graph-based unsupervised learning task that seeks to partition
the nodes in a graph based on pairwise agreement and disagreement. In
particular, we adapt GCS-Q, a quantum-assisted solver originally designed for
coalition structure generation, to maximize intra-cluster agreement in signed
graphs through recursive divisive partitioning. The proposed method encodes
each bipartitioning step as a quadratic unconstrained binary optimization
problem, solved via quantum annealing. This integration of quantum optimization
within a hierarchical clustering framework enables handling of graphs with
arbitrary correlation structures, including negative edges, without relying on
metric assumptions or a predefined number of clusters. Empirical evaluations on
synthetic signed graphs and real-world hyperspectral imaging data demonstrate
that, when adapted for correlation clustering, GCS-Q outperforms classical
algorithms in robustness and clustering quality on real-world data and in
scenarios with cluster size imbalance. Our results highlight the promise of
hybrid quantum-classical optimization for advancing scalable and
structurally-aware clustering techniques in graph-based unsupervised learning.

</details>


### [199] [Dynamical Quantum Phase Transitions and Many-Body Backflow in Open Quantum Systems](https://arxiv.org/abs/2509.03570)
*Kai Zhang,Chang Shu,Kai Sun*

Main category: quant-ph

TL;DR: 开放量子系统中，粒子增益或损失单独存在时，动力学量子相变（DQPTs）保持稳健，但当两者共存时，DQPTs会因多体粒子回流而普遍变模糊。


<details>
  <summary>Details</summary>
Motivation: 由于非厄米描述忽略了量子跳跃过程和相互作用效应，因此完全开放系统动力学下相互作用量子系统的最终命运仍然是一个悬而未决的问题。

Method: 通过结合相互作用和完整的刘维利安动力学，证明了DQPTs在开放量子系统中保持稳健，但当粒子损失和粒子增益同时存在时，DQPTs会普遍变模糊，这源于多体粒子回流。

Result: DQPTs在仅存在粒子损失或粒子增益的情况下保持稳健，但在两者共存时会因多体粒子回流而普遍变模糊。此外，即使是很弱的增益（损失）混合到有损失（增益）的系统中，也会极大地重塑DQPTs动力学的长期行为，随着时间的推移导致显著的偏差。

Conclusion: 包括DQPTs的普遍模糊以及长期极限下大动力学偏差的出现，都源于开放量子系统内在的非平衡多体效应。研究结果具有普遍性，并得到了解析论证和数值模拟的支持。

Abstract: Dynamical quantum phase transitions (DQPTs) are non-equilibrium transitions
characterized by the orthogonality between an initial quantum state and its
time-evolved counterpart following a sudden quench. Recently, studies of this
phenomenon have been extended beyond closed quantum systems to include
environmental interactions, often modeled through non-Hermitian effects.
However, because non-Hermitian descriptions neglect both quantum jump processes
and interaction effects, the ultimate fate of interacting quantum systems under
full open-system quantum dynamics remains an open question. In this paper, by
incorporating both interactions and full Liouvillian dynamics, we prove that
DQPTs in open quantum systems remain robust when subject to either particle
loss or particle gain alone, but are generically smeared out when both
processes coexist, as a result of many-body particle backflow. Furthermore, we
uncover a non-perturbative dynamical effect: even a weak admixture of gain
(loss) into a system with loss (gain) can dramatically reshape the long-time
behavior of DQPT dynamics, leading to substantial deviations over time. These
phenomena--including the universal smearing of DQPTs and the emergence of large
dynamical deviations in the long-time limit--arise intrinsically from
non-equilibrium many-body effects in open quantum systems. Our findings are
general and substantiated by both analytical arguments and numerical
simulations.

</details>


### [200] [Quantum simulation of out-of-equilibrium dynamics in gauge theories](https://arxiv.org/abs/2509.03586)
*Jad C. Halimeh,Niklas Mueller,Johannes Knolle,Zlatko Papić,Zohreh Davoudi*

Main category: quant-ph

TL;DR: 量子模拟在远离平衡的规范场论研究中取得进展，可用于解决核物理、高能物理和凝聚态物理中的基本问题。


<details>
  <summary>Details</summary>
Motivation: 解决经典计算在研究远离平衡的规范场论时存在的局限性，并利用量子模拟器探索自然界的基本框架。

Method: 利用中性原子、离子阱和超导电路等量子模拟器，研究粒子产生、字符串断裂、碰撞动力学、热化、遍历性破坏和动力学量子相变等现象。

Result: 当前的量子模拟器能够模拟粒子产生和字符串断裂、碰撞动力学、热化、遍历性破坏和动力学量子相等现象。

Conclusion: 量子模拟在研究规范场论方面取得了显著进展，并为解决物理学中的基本问题提供了新途径，未来研究方向包括利用现有量子硬件探索新现象。

Abstract: Recent advances in quantum technologies have enabled quantum simulation of
gauge theories -- some of the most fundamental frameworks of nature -- in
regimes far from equilibrium, where classical computation is severely limited.
These simulators, primarily based on neutral atoms, trapped ions, and
superconducting circuits, hold the potential to address long-standing questions
in nuclear, high-energy, and condensed-matter physics, and may ultimately allow
first-principles studies of matter evolution in settings ranging from the early
universe to high-energy collisions. Research in this rapidly growing field is
also driving the convergence of concepts across disciplines and uncovering new
phenomena. In this Review, we highlight recent experimental and theoretical
developments, focusing on phenomena accessible in current and near-term quantum
simulators, including particle production and string breaking, collision
dynamics, thermalization, ergodicity breaking, and dynamical quantum phase
transitions. We conclude by outlining promising directions for future research
and opportunities enabled by available quantum hardware.

</details>


### [201] [Trading Mathematical for Physical Simplicity: Bialgebraic Structures in Matrix Product Operator Symmetries](https://arxiv.org/abs/2509.03600)
*Yuhan Liu,Andras Molnar,Xiao-Qi Sun,Frank Verstraete,Kohtaro Kato,Laurens Lootens*

Main category: quant-ph

TL;DR: Despite advances, some quantum spin chains aren't covered by current algebraic frameworks for symmetries. This paper shows that using pre-bialgebras instead of rigid structures like fusion categories and weak Hopf algebras allows for the inclusion of general matrix product operator (MPO) symmetries. The anomalous Z2 symmetry in the XX model, which has a mixed anomaly between its U(1) momentum and winding symmetry, is used as an example. The paper explains how this anomaly is incorporated into a non-semisimple corepresentation category, offering a new way to implement anomalous symmetries on lattices. It also notes that the representation category related to renormalization is semisimple and semi-monoidal, suggesting a new type of mixed state renormalization fixed points. Lastly, it demonstrates that this anomalous Z2 symmetry is similar to a standard MPO symmetry found on the boundary of a double semion model, connecting topological defect symmetries with those in practical models.


<details>
  <summary>Details</summary>
Motivation: The existing rigid algebraic frameworks for generalized symmetries, such as fusion categories and weak Hopf algebras, do not encompass many physically relevant quantum spin chains. This limits our understanding and ability to model their symmetries.

Method: The paper proposes relaxing the algebraic requirements from fusion categories and weak Hopf algebras to pre-bialgebras to describe general matrix product operator (MPO) symmetries. It uses the anomalous Z2 symmetry of the XX model as a case study to demonstrate how mixed anomalies between U(1) momentum and winding symmetry can be embedded within a non-semisimple corepresentation category. The renormalization properties are analyzed using a semisimple and semi-monoidal representation category. Finally, the anomalous Z2 symmetry is compared to a conventional MPO symmetry from a double semion model via a quantum channel.

Result: The paper demonstrates that pre-bialgebras can describe general MPO symmetries, overcoming limitations of current frameworks. It shows how the anomalous Z2 symmetry in the XX model, with its mixed U(1) momentum and winding symmetry anomaly, is realized within a non-semisimple corepresentation category. A new class of mixed state renormalization fixed points is identified through a semisimple and semi-monoidal representation category. Furthermore, the anomalous Z2 symmetry is shown to be equivalent to a standard MPO symmetry found in a double semion model up to a quantum channel.

Conclusion: This work bridges the gap between well-understood topological defect symmetries and those found in more realistic models by introducing pre-bialgebras to describe MPO symmetries. It provides a novel mechanism for realizing anomalous symmetries, like the one in the XX model, on the lattice and suggests new renormalization fixed points.

Abstract: Despite recent advances in the lattice representation theory of (generalized)
symmetries, many simple quantum spin chains of physical interest are not
included in the rigid framework of fusion categories and weak Hopf algebras. We
demonstrate that this problem can be overcome by relaxing the requirements on
the underlying algebraic structure, and show that general matrix product
operator symmetries are described by a pre-bialgebra. As a guiding example, we
focus on the anomalous $\mathbb Z_2$ symmetry of the XX model, which manifests
the mixed anomaly between its $U(1)$ momentum and winding symmetry. We show how
this anomaly is embedded into the non-semisimple corepresentation category,
providing a novel mechanism for realizing such anomalous symmetries on the
lattice. Additionally, the representation category which describes the
renormalization properties is semisimple and semi-monoidal, which provides a
new class of mixed state renormalization fixed points. Finally, we show that up
to a quantum channel, this anomalous $\mathbb Z_2$ symmetry is equivalent to a
more conventional MPO symmetry obtained on the boundary of a double semion
model. In this way, our work provides a bridge between well-understood
topological defect symmetries and those that arise in more realistic models.

</details>


### [202] [Exoplanetary atmospheres retrieval via a quantum extreme learning machine](https://arxiv.org/abs/2509.03617)
*Marco Vetrano,Tiziano Zingales,G. Massimo Palma,Salvatore Lorenzo*

Main category: quant-ph

TL;DR: 本研究提出使用量子极限学习机（QELM）来分析系外行星大气，以克服传统方法的计算瓶颈。


<details>
  <summary>Details</summary>
Motivation: 传统的前向模型在计算系外行星光谱时需要调整大量参数，计算成本高昂。

Method: 利用量子极限学习机（QELM）提出一种新的系外行星大气反演方法，并实现了一个适合近期量子设备的容错架构，并在IBM Fez上进行了演示。

Result: 所提出的QELM架构展示了量子计算在处理天体物理数据集方面的潜力。

Conclusion: QELM有望在不久的将来为系外行星大气研究提供更快速、更有效、更精确的计算工具。

Abstract: The study of exoplanetary atmospheres traditionally relies on forward models
to analytically compute the spectrum of an exoplanet by fine-tuning numerous
chemical and physical parameters. However, the high-dimensionality of parameter
space often results in a significant computational overhead. In this work, we
introduce a novel approach to atmospheric retrieval leveraging on quantum
extreme learning machines (QELMs). QELMs are quantum machine learning
techniques that employ quantum systems as a black box for processing input
data. In this work, we propose a framework for extracting exoplanetary
atmospheric features using QELMs, employing an intrinsically fault-tolerant
strategy suitable for near-term quantum devices, and we demonstrate such fault
tolerance with a direct implementation on IBM Fez. The QELM architecture we
present shows the potential of quantum computing in the analysis of
astrophysical datasets and may, in the near-term future, unlock new
computational tools to implement fast, efficient, and more accurate models in
the study of exoplanetary atmospheres.

</details>


### [203] [Quantum algorithms for Uhlmann transformation](https://arxiv.org/abs/2509.03619)
*Takeru Utsumi,Yoshifumi Nakata,Qisheng Wang,Ryuji Takagi*

Main category: quant-ph

TL;DR: 该论文提出了实现Uhlmann变换的量子电路算法，并在某些计算模型下实现了计算成本（查询和样本复杂度）的指数级提升，优于基于量子态层析等方法的朴素方法。该算法在平方根保真度估计任务上表现出优于现有技术的查询复杂度，并讨论了其在纠缠传输、量子态合并和Petz恢复图算法实现等任务中的应用。


<details>
  <summary>Details</summary>
Motivation: Uhlmann定理是量子信息论的核心成果，它将两个量子态的接近度与其纯化态的接近度联系起来，并表征了通过对子系统进行局部操作将一个量子态转化为另一个量子态的任务。然而，该任务的最佳变换（Uhlmann变换）的量子电路实现和计算成本尚不清楚。

Method: 提出实现Uhlmann变换的量子查询和样本算法，并将其形式化为量子电路。

Result: 提出的算法在某些计算模型下实现了指数级的计算成本（包括查询和样本复杂度）的改进，优于基于量子态层析等方法的朴素方法。在平方根保真度估计任务上，该方法实现了优于现有最先进技术的查询复杂度。此外，还讨论了该算法在纠缠传输、量子态合并和Petz恢复图算法实现等任务中的应用。

Conclusion: 该工作填补了Uhlmann变换的量子电路实现和计算成本的空白，提出的算法在计算效率方面具有显著优势，并为相关的量子信息论任务提供了全面的计算成本评估。

Abstract: Uhlmann's theorem is a central result in quantum information theory,
associating the closeness of two quantum states with that of their
purifications. This theorem well characterizes the fundamental task of
transforming a quantum state into another state via local operations on its
subsystem. The optimal transformation for this task is called the Uhlmann
transformation, which has broad applications in various fields; however, its
quantum circuit implementation and computational cost have remained unclear. In
this work, we fill this gap by proposing quantum query and sample algorithms
that realize the Uhlmann transformation in the form of quantum circuits. These
algorithms achieve exponential improvements in computational costs, including
query and sample complexities, over naive approaches based on state
measurements such as quantum state tomography, under certain computational
models. We apply our algorithms to the square root fidelity estimation task and
particularly show that our approach attains a better query complexity than the
prior state-of-the-art. Furthermore, we discuss applications to several
information-theoretic tasks, specifically, entanglement transmission, quantum
state merging, and algorithmic implementation of the Petz recovery map,
providing a comprehensive evaluation of the computational costs.

</details>


### [204] [Long-term stability of driven quantum systems and the time-dependent Bloch equation](https://arxiv.org/abs/2509.03639)
*Zsolt Szabó,Kazuya Yuasa,Daniel Burgarth*

Main category: quant-ph

TL;DR: 研究了弱扰动下的有限维绝热演化，并分析了其在渐近时间极限下的行为。


<details>
  <summary>Details</summary>
Motivation: 研究弱扰动对有限维绝热演化的影响，并分析其在渐近时间极限下的行为，推导了布洛赫方程，并分析了其解的性质和泄漏现象。

Method: 从绝热变换和时变有效哈密顿量的基础出发，推导出布洛赫方程，并通过数值和解析方法评估了泄漏现象。

Result: 数值和解析评估表明，泄漏可能在任意长时间内保持很小，即系统保持在特定的特征子空间内，误差为$\\

Conclusion: 弱扰动下的有限维绝热演化可以保持系统在特定的特征子空间内，泄漏现象可以通过参数$\\'

Abstract: This study looks at the finite-dimensional adiabatic evolution influenced by
weak perturbations, extending the analysis to the asymptotic time limit.
Beginning with the fundamentals of adiabatic transformations and time-dependent
effective Hamiltonians, we intuitively derive the Bloch equation. Our
investigation of the solutions of the Bloch equation underscores the critical
role of initial conditions and the assured existence of solutions, revealing
the intricate link between leakage phenomena and the Bloch transformation.
Numerical and analytical evaluations demonstrate that the leakage can remain
small eternally. That is, a system that starts in a particular eigenspace of
the strong generator remains in the same respective eigenspace for arbitrary
long times with an error of $\mathcal{O}(\gamma^{-1})$, where $\gamma$
describes the ratio between the strength of the system's strong Hamiltonian and
the perturbation.

</details>


### [205] [QuLTRA: Quantum hybrid Lumped and TRansmission lines circuits Analyzer](https://arxiv.org/abs/2509.03651)
*Simona Zaccaria,Antonio Gnudi*

Main category: quant-ph

TL;DR: QuLTRA是一个开源Python包，用于精确模拟包含集总和分布式元件的超导量子电路，无需进行集总单元等效离散化，并能高效提取电路哈密顿参数。


<details>
  <summary>Details</summary>
Motivation: 提出 QuLTRA（Quantum hybrid Lumped and TRansmission lines circuits Analyzer）的动机是为了实现对包含集总和分布式元件的超导量子电路进行精确模拟，并克服传统方法的计算耗时问题。

Method: QuLTRA 直接模拟微波传输线和多线耦合器，不将其离散化为集总单元等效电路，并使用能量参与比（EPR）方法提取电路哈密顿参数。此方法能够快速准确地提取模式频率、非简谐性、交叉克尔相互作用和珀塞尔衰减率，同时自然地考虑了分布式元件的高阶模式，无需进行完整的电磁仿真。

Result: QuLTRA 的性能经过与 Ansys HFSS、pyEPR、QuCAT 和文献结果的验证，显示出与完整电磁仿真相比，计算时间减少了几个数量级，且结果高度一致。实际应用示例包括 Purcell 滤波器的设计、多模超强耦合系统以及复用量子比特读出方案。

Conclusion: QuLTRA 能够有效地模拟电路量子电动力学应用中的复杂架构，为超导量子电路的设计和仿真提供了快速、准确的解决方案。

Abstract: We present QuLTRA (Quantum hybrid Lumped and TRansmission lines circuits
Analyzer), an open-source Python package for the accurate simulation of
superconducting quantum circuits containing both lumped and distributed
elements. QuLTRA directly models coplanar waveguide (CPW) transmission lines
and multi-line couplers without discretization into lumped-element equivalents,
and extracts the circuit Hamiltonian parameters using the energy participation
ratio (EPR) method. This approach enables fast and accurate extraction of mode
frequencies, anharmonicities, cross-Kerr interactions, and Purcell decay rates
without relying on full electromagnetic simulations, while naturally accounting
for higher-order modes of distributed components. The performance of QuLTRA is
validated against Ansys HFSS, pyEPR, QuCAT, and results from the literature,
showing excellent agreement with orders-of-magnitude reductions in
computational time with respect to full electromagnetic simulations. Some
application examples are discussed, including the design of Purcell filters,
multi-mode ultra-strong coupling systems, and multiplexed qubit readout
schemes, demonstrating that QuLTRA can efficiently simulate complex
architectures relevant to circuit quantum electrodynamics applications.

</details>


### [206] [The ITransverse.jl library for transverse tensor network contractions](https://arxiv.org/abs/2509.03699)
*Stefano Carignano*

Main category: quant-ph

TL;DR: ITransverse.jl 是一个 Julia 包，用于使用横向收缩方法高效地收缩张量网络，特别是用于模拟量子多体系统的量子动力学。


<details>
  <summary>Details</summary>
Motivation: 横向收缩方法有望用于高效收缩与量子多体系统时间演化相关的张量网络，从而在某些情况下可以绕过通常会阻止经典资源研究量子动力学的纠缠屏障。

Method: 该论文提出了 ITransverse.jl 包，该包是用 Julia 编写的，并基于 ITensors.jl。它包含了几种高级算法，包括用于高效截断时间矩阵乘积态的新方法。

Result: ITransverse.jl 包包含了几种高级算法，包括用于高效截断时间矩阵乘积态的新方法。

Conclusion: ITransverse.jl 包为使用横向收缩方法研究量子多体系统的量子动力学提供了一个高效的工具。

Abstract: Transverse contraction methods are extremely promising tools for the
efficient contraction of tensor networks associated with the time evolution of
quantum many-body systems, allowing in some cases to circumvent the
entanglement barrier that would normally prevent the study of quantum dynamics
with classical resources. We present here the ITransverse.jl package, written
in Julia and based on ITensors.jl, containing several of these high-level
algorithms, including novel prescriptions for efficient truncations of temporal
matrix product states.

</details>


### [207] [Polarization-Controlled Dual-State Distribution of Bell and N00N Entanglement Over a Metro-Scale Commercial Quantum Network](https://arxiv.org/abs/2509.03701)
*Kazi Reaz,Md Mehdi Hassan,Jacob E. Humberd,Matthew L. Boone,Angel Fraire Estrada,Rick Mukherjee,H. R. Sadeghpour,Girish S. Agarwal,George Siopsis,Tian Li*

Main category: quant-ph

TL;DR: 该研究首次在商业光纤网络上实现了多光子、双态纠缠分发，利用全光纤实验平台生成了四光子纠缠态，并通过测量本地光子 the 另外两个光子，分发到两个网络节点，实验验证了在通道损耗和源保真度有限的情况下成功实现了纠缠分发。


<details>
  <summary>Details</summary>
Motivation: 在商业光纤网络上演示多光子、双态纠缠分发，并为未来的升级奠定基础。

Method: 利用SPDC双光子源和全光纤线性光学元件，生成四光子纠缠态，并通过对本地保留光子的测量来 the 另外两个光子。

Result: 成功地在部署的网络中分发了纠缠态，尽管存在显著的通道损耗和有限的源保真度。

Conclusion: 该研究强调了在真实电信基础设施上进行偏振控制的多光子纠缠分发的通用性，并为未来升级（如更高质量的非简并光子源、用于真正多节点纠缠的白兔定时同步以及用于提高保真度和长期稳定性的主动偏振控制）奠定了基础。

Abstract: We report the first demonstration of multiphoton, dual state entanglement
distribution over a metropolitan scale commercial fiber network, implemented on
the EPB Bohr IV quantum network in Chattanooga, TN, using an all fiber optic
experimental platform. Employing a spatially degenerate, continuous wave type
II SPDC biphoton source and fully fiber coupled linear optics, we generated a 4
photon entangled state. Through polarization projective measurements on two
locally retained photons, we then probabilistically heralded the remaining two
photons into either a Bell state (particle particle entanglement) or a N00N
state (mode-mode entanglement), which were then distributed to two spatially
separated network nodes. Experimental verification confirmed successful
entanglement distribution across the deployed network despite significant
channel losses and limited source fidelity. These results highlight the
versatility of our polarization controlled multi photon entanglement
distribution over real world telecom infrastructure and lay the groundwork for
future upgrades, including higher quality non degenerate photon sources, White
Rabbit timing synchronization for true multi node entanglement, and active
polarization control for enhanced fidelity and long term stability.

</details>


### [208] [Cavity-Controlled High Harmonic Generation](https://arxiv.org/abs/2509.03705)
*Zohar Amitay,Nimrod Moiseyev*

Main category: quant-ph

TL;DR: 利用非厄米Floquet理论，通过将原子置于单模量子腔内，可以控制连续波场辐照下的基态原子产生高次谐波（HHG）的过程，即使腔内初始只有一个光子。这种腔耦合可以形成极化子Floquet态，在（标准无腔）奇次谐波周围产生侧向谐波。不同的腔控制HHG光谱，包括串联多个腔的情况，可以产生与无腔不同的阿秒脉冲序列。该研究为进一步利用腔控制HHG及其他强场过程提供了理论框架。


<details>
  <summary>Details</summary>
Motivation: 研究如何利用量子腔控制强场过程，特别是高次谐波（HHG）的产生。

Method: 采用非厄米Floquet理论，将基态原子置于单模量子腔内，并研究腔耦合对HHG过程的影响，形成极化子Floquet态。

Result: 实现了腔控制下的HHG光谱，产生了位于标准奇次谐波周围的侧向谐波，并获得了与无腔情况不同的阿秒脉冲序列。

Conclusion: 该研究为利用量子腔控制HHG及其他强场过程提供了理论框架和新的可能性。

Abstract: Employing non-Hermitian Floquet theory, the strong-field process of high
harmonic (HH) generation by a classical continuous-wave field irradiating
ground-state atom is discovered to be controllable by placing the irradiated
atom inside a single-mode quantum cavity initiated even with a single photon.
Judicious cavity coupling of cavity-free photo-induced atomic Floquet states
forms polaritonic Floquet states that generate side harmonics around the
(standard no-cavity) odd harmonics. The different possible cavity-controlled HH
spectra, including also the ones resulting from several cavities in a row,
enable attosecond-pulse sequences different from the one produced without a
cavity. Moreover, the present study sets the framework and opens the way for
further cavity control over the HH generation process as well as over other
strong-field processes

</details>


### [209] [Resonance Assisted Tunneling in Floquet spin-J systems](https://arxiv.org/abs/2509.03715)
*J. A. Segura-Landa,Diego A. Wisniacki,Sergio Lerma-Hernández,Jorge G. Hirsch*

Main category: quant-ph

TL;DR: 共振辅助隧穿（RAT）理论被应用于多体量子踢系统，该系统具有明确的半经典极限。研究识别了与经典共振相关的本征态，并半经典地计算了它们的拟能量分裂。研究区分了两个区域：在第一个区域，RAT预测与精确量子结果高度一致；在第二个区域，分裂饱和，并与由共振岛经典振荡决定的频率的谐振子行为一致。最后，量化了RAT理论失效的扰动强度阈值，并分析了其在半经典极限下的标度行为，给出了估计该上限的解析表达式。


<details>
  <summary>Details</summary>
Motivation: 将共振辅助隧穿（RAT）理论应用于具有明确半经典极限的多体量子踢系统，以识别与经典共振相关的本征态并计算它们的拟能量分裂。

Method: 使用量子共振条件识别与经典共振相关的本征态，并半经典地计算它们的拟能量分裂。区分两种情况：RAT预测与量子结果一致的情况，以及分裂饱和并与谐振子行为一致的情况。量化RAT理论失效的扰动强度阈值，并分析其在半经典极限下的标度行为。

Result: 识别出两种不同的区域，在一种区域中RAT预测与量子结果高度一致，在另一种区域中分裂饱和并与谐振子行为一致。给出了RAT理论失效的扰动强度上限的解析表达式。

Conclusion: RAT理论在特定条件下能很好地预测量子踢系统的行为，但在更高扰动强度下会失效，此时系统的行为更接近于谐振子。

Abstract: We apply the theory of Resonance Assisted Tunneling (RAT) to a many-body
quantum kicked system with a well-defined semiclassical limit. Using a quantum
resonant condition, we identify eigenstates associated with classical
resonances and compute their quasienergy splitting semiclassically. We
distinguish two regimes: the first, where RAT predictions show excellent
agreement with exact quantum results, and a second, where the splitting
saturates and coincides with that of a harmonic oscillator with frequency
determined by the classical oscillation of the resonance island. We quantify
the perturbation strength above which RAT theory is no longer valid and analyze
its scaling in the semiclassical limit, providing analytical expressions to
estimate this upper bound.

</details>


### [210] [Coherence-Driven Quantum Battery Charging via Autonomous Thermal Machines: Energy Transfer, Memory Effects, and Ergotropy Enhancement](https://arxiv.org/abs/2509.03766)
*Achraf Khoudiri,Abderrahman Oularabi,Khadija El Anouz,İlkay Demir,Abderrahim El Allati*

Main category: quant-ph

TL;DR: 本工作研究了一个由量子电池和相干驱动充电器组成的混合量子系统，该系统与量子自主热机（QATM）相互作用。QATM由两个分别与不同温度的马尔可夫玻色子热库耦合的量子比特组成，作为介导充电器和电池之间能量和相干转移的结构化环境。通过在充电器上施加相干驱动场，研究了相干注入对动力学的影响，包括非马尔可夫性、充电功率、相干存储和ergotropy。结果表明，QATM能有效地过滤热库引起的退相干，并通过相关的回流效应引起非马尔可夫记忆效应。研究结果表明，相干驱动通过保持充电器的内部能量和促进相干能量转移，增强了电池的ergotropy和充电功率。


<details>
  <summary>Details</summary>
Motivation: 研究混合量子系统（量子电池、相干驱动充电器、量子自主热机）的能量和相干动力学，特别是相干注入对充电过程的影响。

Method: 使用量子自主热机（QATM）作为结构化环境，其中包含两个耦合到不同温度热库的量子比特。通过在充电器上施加相干驱动场，研究相干注入对非马尔可夫性、充电功率、相干存储和ergotropy的影响。

Result: QATM能过滤热库的退相干效应，并因相关回流产生非马尔可夫记忆效应。相干驱动增强了电池的ergotropy和充电功率。

Conclusion: 相干驱动是一种有效的策略，可以增强量子电池的充电性能，包括提高ergotropy和充电功率，同时利用QATM作为结构化环境来管理能量和相干性。

Abstract: In this work, we study a hybrid quantum system composed of a quantum battery
and a coherence-driven charger interacting with a Quantum Autonomous Thermal
Machine (QATM). The QATM, made of two qubits each coupled to Markovian Bosonics
thermal reservoirs at different temperatures, acts as a structured environment
that mediates energy and coherence transfer between the charger and the
battery. By presenting a coherent driving field on the charger, we investigate
the coherence injection effect on the dynamics, including non-Markovianity,
power of charging, coherence storage, and ergotropy. We show that the QATM
effectively filters the decoherence induced by the thermal baths and induces
non-Markovian memory effects due to correlation backflow. Our results
demonstrate that coherence driving enhances the battery's ergotropy and power
of charging by preserving the internal energy of the charger and facilitating
coherent energy transfer.

</details>


### [211] [Learning Neural Decoding with Parallelism and Self-Coordination for Quantum Error Correction](https://arxiv.org/abs/2509.03815)
*Kai Zhang,Situ Wang,Linghang Kong,Fang Zhang,Zhengfeng Ji,Jianxin Chen*

Main category: quant-ph

TL;DR: 提出了用于容错量子计算的循环 Transformer 解码器，解决了现有 AlphaQubit 解码器在并行处理和局部校正集成方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的神经网路解码器（如 AlphaQubit）虽然精度高，但缺乏并行处理能力，无法实时解码超导逻辑量子比特产生的综合信息流。同时，将 AlphaQubit 集成到滑动窗口并行解码方案中存在挑战，因为它输出的是全局逻辑校正而非易于集成的局部物理校正。

Method: 训练了一个循环的、基于 Transformer 的神经网络，专门用于滑动窗口解码。该网络为每个窗口输出一个单一比特，但训练标签来自一致的局部校正集，并同时在不同类型的解码窗口上进行训练。

Result: 该方法使网络能够跨相邻窗口进行自我协调，从而能够对任意长度的记忆实验进行高精度并行解码。解决了之前阻碍 AlphaQubit 类型解码器应用于容错量子计算的吞吐量限制问题。

Conclusion: 通过训练专门的循环 Transformer 神经网络，成功实现了高吞吐量的并行解码，为在容错量子计算中应用 AlphaQubit 类型解码器铺平了道路。

Abstract: Fast, reliable decoders are pivotal components for enabling fault-tolerant
quantum computation. Neural network decoders like AlphaQubit have demonstrated
significant potential, achieving higher accuracy than traditional
human-designed decoding algorithms. However, existing implementations of neural
network decoders lack the parallelism required to decode the syndrome stream
generated by a superconducting logical qubit in real time. Moreover,
integrating AlphaQubit with sliding window-based parallel decoding schemes
presents non-trivial challenges: AlphaQubit is trained solely to output a
single bit corresponding to the global logical correction for an entire memory
experiment, rather than local physical corrections that can be easily
integrated.
  We address this issue by training a recurrent, transformer-based neural
network specifically tailored for sliding-window decoding. While our network
still outputs a single bit per window, we derive training labels from a
consistent set of local corrections and train on various types of decoding
windows simultaneously. This approach enables the network to self-coordinate
across neighboring windows, facilitating high-accuracy parallel decoding of
arbitrarily long memory experiments. As a result, we resolve the throughput
limitation that previously prohibited the application of AlphaQubit-type
decoders in fault-tolerant quantum computation.

</details>


### [212] [Tunneling induced giant Photonic Spin Hall effect in quantum wells](https://arxiv.org/abs/2509.03844)
*Fazal Badshah,Imed Boukhris,Mohamed Sultan Al-Buriah,Yuan Zhou,Muhammad Idrees,Ziauddin*

Main category: quant-ph

TL;DR: 我们提出了一种理论研究，通过使用不对称双 AlGaAsGaAs 量子阱作为腔内介质，在中红外探测场中研究光子自旋霍尔效应（PSHE）。


<details>
  <summary>Details</summary>
Motivation: 该系统旨在利用外部控制光束和可调谐隧道势垒来调控探测隧道的量子干涉，从而实现对光子自旋霍尔效应（PSHE）的精确操控。

Method: 通过理论研究，利用不对称双 AlGaAsGaAs 量子阱作为腔内介质，并结合外部控制光束和可调谐隧道势垒来调控量子干涉。

Result: 分析表明，在基于量子阱的腔系统中会出现巨大的水平 PSHE。此外，通过加入吸收和增益辅助腔板，水平 PSHE 得到进一步放大，导致光子自旋分离更加明显。

Conclusion: 研究结果为半导体量子阱中的光-物质相互作用提供了新的见解，并为在中红外光子器件中增强和控制 PSHE 提供了一条有效的途径。

Abstract: We propose a theoretical investigation of the photonic spin Hall effect
(PSHE) in a mid-infrared probe field by employing an asymmetric double
AlGaAsGaAs quantum well as the intracavity medium. The system is designed such
that an external control beam together with tunable tunneling barriers
regulates the quantum interference of the probe tunneling process. This
configuration enables precise manipulation of the PSHE for both horizontally
and vertically polarized components of light. Our analysis reveals the
emergence of a giant horizontal PSHE in the quantum well based cavity system.
Moreover, by incorporating absorptive and gain-assisted cavity slabs, the
horizontal PSHE is further amplified, leading to an even more pronounced
photonic spin separation. The results provide novel insights into light matter
interactions in semiconductor quantum wells and suggest an effective route for
enhancing and controlling the PSHE in mid-infrared photonic devices.

</details>


### [213] [Decoherence mitigation for geometric quantum computation](https://arxiv.org/abs/2509.03856)
*X. Y. Sun,P. Z. Zhao*

Main category: quant-ph

TL;DR: 该研究提出了一种仅基于物理量子比特的几何量子计算方案，以克服传统方案中逻辑量子比特编码带来的资源消耗和操作困难，并能应对更普遍的退相干噪声。


<details>
  <summary>Details</summary>
Motivation: 之前的几何量子计算方案需要多比特编码逻辑量子比特，增加了资源消耗和操作难度。本研究旨在提出一种更有效、更现实的方案。

Method: 提出一种仅基于物理量子比特的几何量子计算方案，该方案能应对更普遍的退相干噪声，而不仅仅是单一的去相干噪声。

Result: 该方案避免了逻辑量子比特编码带来的额外资源消耗和操作困难，并能有效缓解常规退相干。

Conclusion: 该方案为实现具有退相干缓解能力的几何量子控制提供了一种更现实有效的方法。

Abstract: Geometric phases depend only on the evolution path determined by the closed
circuit in the projective Hilbert space but not on evolution details of the
quantum system, leading to geometric quantum computation possessing some
intrinsic robustness against control errors. Coordinated with dynamical
decoupling, geometric quantum computation admits additional resilience to the
environment-induced decoherence. However, the previous schemes of geometric
quantum computation protected by dynamical decoupling require multiple physical
qubits to encode a logical qubit, which undoubtedly increases the consumption
of physical-qubit resources and the difficulty in the implementation of the
logical-qubit manipulation based on physical-qubit driving. In this work, we
put forward a scheme of decoherence-mitigated geometric quantum computation
based only on physical qubits rather than logical qubits, hence avoiding the
additional overhead of physical-qubit resources for logical-qubit encoding as
well as the difficulty in the manipulation of logical qubits. Moreover, our
scheme focuses on the most general interaction between an individual qubit and
its environment so that it mitigates not just dephasing noise but rather
regular decoherence. Our proposal thus represents a more realistic and
effective approach towards the realization of geometric control with
decoherence mitigation.

</details>


### [214] [Near-Term Quantum-Computing-Inspired Sampling for Community Detection in Low-Modularity Graphs](https://arxiv.org/abs/2509.03864)
*Joseph Geraci,Luca Pani*

Main category: quant-ph

TL;DR: 量子启发的社区检测算法利用非经典采样技术来解决低模块度网络中的局部最优问题，在低Q图上实现了15-25%的模块度增益，并引入了模块度恢复差距（MRG）作为异常检测信号。


<details>
  <summary>Details</summary>
Motivation: 低模块度（Q < 0.2）的网络对经典的社区检测算法提出了挑战，因为这些算法容易陷入局部最优。

Method: 利用受量子现象启发的概率分布（如Porter Thomas分布、Haar随机态和超均匀点过程）进行非经典采样，以生成多样化的、高质量的社区划分。

Result: 在低模块度图上，模块度Q提高了15-25%；在 শনাক্ত别高模块度网络（CTU 13僵尸网络流量）时，MRG接近于零，表明该方法在不存在隐藏结构时不会人为提高模块度。

Conclusion: 量子启发的采样方法能显著提高低模块度网络的社区检测性能，并且MRG可作为有力的异常检测信号，在网络安全、金融、供应链、脑科学和社交媒体分析等领域具有广泛应用前景。该方法通过扩展搜索空间来发现经典算法遗漏的划分，展示了近期量子采样在重塑优化格局和增强弱结构敏感性方面的潜力。

Abstract: Low modularity networks (Q < 0.2) challenge classical community detection
algorithms, which get trapped in local optima. We introduce quantum inspired
community detection algorithms leveraging non classical sampling techniques to
escape modularity optimization plateaus. Using distributions inspired by
quantum phenomena including Porter Thomas distributions, Haar random states,
and hyperuniform point processes, our approach generates diverse high quality
partitions that improve modularity on difficult low Q graphs. We demonstrate 15
to 25% gains in modularity Q over classical methods (Louvain, Leiden). We
define a "Modularity Recovery Gap" (MRG), the increase in Q achieved by quantum
inspired refinement, and show this serves as a powerful anomaly detection
signal. In experiments on high modularity networks (CTU 13 botnet traffic), MRG
is near zero, confirming our method doesn't inflate modularity when no hidden
structure exists. Results suggest quantum inspired sampling substantially
enhances community detection in low modularity regimes, with applications in
cybersecurity (stealthy APT/botnet detection), financial contagion modeling,
disrupted supply chains, diseased brain connectomes, and crisis era social
media analysis. Our refinements expand the search space of algorithms like
Leiden without altering the graph, revealing partitions classical heuristics
miss. While such partitions need not represent ground truth communities, they
illustrate how near term quantum sampling can reshape optimization landscapes
and enhance sensitivity to weak structure.

</details>


### [215] [Electrically pumped ultra-efficient quantum frequency conversion on thin film lithium niobate chip](https://arxiv.org/abs/2509.03869)
*Xina Wang,Xu-Feng Jiao,Bo Cao,Yang Liu,Xiu-Ping Xie,Ming-Yang Zheng,Qiang Zhang,Jian-Wei Pan*

Main category: quant-ph

TL;DR: 该研究首次在薄膜铌酸锂平台上展示了混合集成量子频率转换（QFC）芯片，实现了电信和可见光频带的连接，转换效率高，泵浦光功率低，并实现了电驱动和片上量子效率。


<details>
  <summary>Details</summary>
Motivation: 为了在不同波长运行的量子系统之间构建无缝互连，并推动未来量子技术的发展，集成化的芯片级QFC组件是必不可少的，这些组件需要具备高效率、小尺寸、低功耗和高可扩展性。

Method: 研究人员在薄膜铌酸锂平台上，利用具有超高归一化转换效率（386,000 %/W）的周期性极化微环谐振器，实现了电信和可见光频带之间的量子频率转换。

Result: 通过使用360 μW的超低泵浦光功率，比传统直波导方案低两个数量级以上，实现了57%的片上量子效率和约7k counts per second的噪声计数。

Conclusion: 该研究成功展示了首个混合集成的QFC芯片，它具有电驱动、集成和可扩展的优点，有望显著推进量子网络的集成和芯片级量子光学系统的发展。

Abstract: Quantum frequency conversion (QFC) plays a crucial role in constructing
seamless interconnection between quantum systems operating at different
wavelengths. To advance future quantum technology, chip-scale integrated QFC
components, featuring high efficiency, small footprint, low power consumption
and high scalability, are indispensable. In this work, we demonstrate the first
hybrid integrated QFC chip on thin film lithium niobate platform that connects
the telecom and visible bands. Benefiting from the periodically poled microring
resonator with ulta-high normalized conversion efficiency of 386,000 %/W, an
ultra-low pump power of 360 {\mu}W is achieved which is more than two orders of
magnitude lower than traditional straight waveguide scheme. By injecting
current into the chip, an on-chip quantum efficiency of 57% and a noise count
of ~ 7k counts per second are achieved. Such an electrically pumped, integrated
and scalable QFC chip would significantly advancing the integration of quantum
network and the development of chip-scale quantum optical systems.

</details>


### [216] [Solving quantum-inspired dynamics on quantum and classical annealers](https://arxiv.org/abs/2509.03952)
*Philipp Hanussek,Jakub Pawłowski,Zakaria Mzaouali,Bartłomiej Gardas*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We propose a practical benchmarking suite inspired by physical dynamics to
challenge both quantum and classical computers. Using a parallel in time
encoding, we convert the real-time propagator of an $n$-qubit, possibly
non-Hermitian, Hamiltonian into a quadratic-unconstrained binary optimisation
(QUBO) problem. The resulting QUBO instances are executed on D-Wave quantum
annealers as well as using two classical solvers, Simulated Annealing and
VeloxQ, a state-of-the-art classical heuristic solver. This enables a direct
comparison. To stress-test the workflow, we use eight representative models,
divided into three groups: (i)~single-qubit rotations, (ii)~multi-qubit
entangling gates (Bell, GHZ, cluster), and (iii)~$\text{PT}$-symmetric,
parity-conserving and other non-Hermitian generators. Across this diverse suite
we track the success probability and time to solution, which are well
established measures in the realm of heuristic combinatorial optimisation. Our
results show that D-Wave Advantage2 consistently surpasses its predecessor,
while VeloxQ presently retains the overall lead, reflecting the maturity of
classical optimisers. We highlight the rapid progress of analog quantum
optimisation, and suggest a clear trajectory toward quantum competitive
dynamics simulation, by establishing the parallel in time QUBO framework as a
versatile test-bed for tracking and evaluating that progress.

</details>


### [217] [LATTE: A Decoding Architecture for Quantum Computing with Temporal and Spatial Scalability](https://arxiv.org/abs/2509.03954)
*Kai Zhang,Jubo Xu,Fang Zhang,Linghang Kong,Zhengfeng Ji,Jianxin Chen*

Main category: quant-ph

TL;DR: LATTE是一个FPGA-CPU混合解码架构，旨在通过分层设计（CPU上的流式块解码和FPGA上的神经网络局部解码）来解决量子计算中的延迟、准确性、吞吐量和传输带宽问题。该架构实现了与基线解码器相当的准确性，同时实现了实时解码吞吐量，并显著降低了带宽和计算资源需求，从而实现了远超以往的方法的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 量子纠错是实现容错量子计算的关键，而解码器是量子纠错中的关键组成部分。现有解码器在扩展性方面存在瓶颈，尤其是在延迟、准确性、吞吐量和传输带宽方面。

Method: LATTE采用分层设计：1. CPU上的全流式、异步块解码系统，实现时间上和空间上的并行化。2. FPGA上集成了超轻量级、高精度的神经网络局部解码单元，对块解码系统透明，有效减少传输带宽并加速解码过程。

Result: 在电路级噪声p=0.001下，LATTE在传输带宽方面实现了超过90%的降低，单块解码平均速度提升了6.4倍。在流式解码场景下，LATTE实现了恒定且低延迟（比现有流式解码实现快16-20倍），在任意长度的量子内存实验中，仅需2个线程即可解码距离高达17的表面码。LATTE通过高度并行化的解码操作最小化了多块测量实验中的延迟。

Conclusion: LATTE通过其创新的混合架构和分层设计，在保持高精度的同时，显著提高了解码速度，降低了带宽和计算资源需求，解决了当前量子计算扩展性方面的关键问题，为大规模容错量子计算奠定了基础。

Abstract: Quantum error correction allows inherently noisy quantum devices to emulate
an ideal quantum computer with reasonable resource overhead. As a crucial
component, decoding architectures have received significant attention recently.
In this paper, we introduce LATTE, a FPGA-CPU hybrid decoding architecture
aiming to address the key requirements of scaling up in lattice surgery quantum
computation -- Latency, Accuracy, Throughput and Transmission Bandwidth, in an
Eclectic manner. LATTE follows a hierarchical design: (1) A fully streaming and
asynchronous block decoding system on CPU to enable parallelization both
temporally and spatially. (2) A super-light yet accurate neural local decoding
unit integrated with quantum control hardware on FPGA, which remains
\emph{transparent} to the block decoding system, effectively reducing
transmission bandwidth and accelerating the decoding process. LATTE delivers
accuracy on par with the base decoder while achieving real-time decoding
throughput and significantly reducing both bandwidth requirements and
computational resources, enabling a level of scalability far beyond previous
approaches. Under circuit-level noise $p=0.001$, LATTE achieves over
$\mathbf{90\%}$ reduction in transmission bandwidth and a $\mathbf{6.4\times}$
speedup on average in single-block decoding. In the \emph{streaming decoding}
scenario: (1) LATTE achieves constant and low latency
($\mathbf{16\times}$-$\mathbf{20\times}$ speedup over existing streaming
decoding implementations) in arbitrarily long quantum memory experiments, with
near-optimal resources -- merely $\mathbf{2}$ threads are sufficient for
decoding the surface code with distance up to $17$. (2) LATTE minimizes latency
in multi-patch measurement experiments through highly parallelized decoding
operations. These combined efforts ensure sufficient scalability for
large-scale fault-tolerant quantum computing.

</details>


### [218] [Non-Gaussian Photon Correlations in Weakly Coupled Atomic Ensembles](https://arxiv.org/abs/2509.03970)
*Yangming Wang,Sahand Mahmoodian*

Main category: quant-ph

TL;DR: 通过散射理论预测，与光学模式弱耦合的共振驱动原子系综可以产生具有非高斯关联的光。该方法基于多光子相互作用的微扰图展开，表明由发射体介导的光子-光子相互作用导致透射光具有非零的连通三阶相关函数 $g_c^{(3)}$。通过分析图展开中的相互作用过程，解释了 $g_c^{(3)}$ 的时间模式。与小系综（光密度 $\mathrm{OD}\leq 2$）的级联主方程模拟进行的定量比较证实，微扰结果在实验相关的光密度和足够强的驱动强度下仍然准确，足以使预测的非高斯特征可被检测到。我们预期，最先进的纳米光纤耦合原子系综可以实验性地证明我们的预测。


<details>
  <summary>Details</summary>
Motivation: 开发一种散射理论形式主义来预测共振驱动原子系综与光学模式的相互作用如何产生非高斯光。

Method: 使用基于多光子相互作用微扰图展开的散射理论形式主义，并与级联主方程模拟进行比较。

Result: 透射光具有非零的连通三阶相关函数 $g_c^{(3)}$，并且该结果在实验相关的条件下是准确的。

Conclusion: 该理论预测在实验中是可行的，并期望最先进的纳米光纤耦合原子系综能够实现。

Abstract: We develop a scattering theory formalism and use it to predict that a
resonantly driven atomic ensemble weakly coupled to an optical mode can
generate light with non-Gaussian correlations. Our approach -- based on a
perturbative diagrammatic expansion of multi-photon interactions -- shows that
photon-photon interaction mediated by the emitters causes the transmitted light
to have a non-vanishing connected third-order correlation function $g_c^{(3)}$.
We explain the temporal pattern of $g_c^{(3)}$ using the interaction processes
in our diagrammatic expansion. A quantitative comparison with cascaded master
equation simulations for small ensembles with optical depth $\mathrm{OD}\leq 2$
confirms that the perturbative results remain accurate across experimentally
relevant optical depths and for drive strengths large enough to make the
predicted non-Gaussian signatures detectable. We anticipate that
state-of-the-art nanofibre-coupled atomic ensembles can experimentally
demonstrate our predictions.

</details>


### [219] [Real-time adaptive quantum error correction by model-free multi-agent learning](https://arxiv.org/abs/2509.03974)
*Manuel Guatto,Francesco Preti,Michael Schilling,Tommaso Calarco,Francisco Andrés Cárdenas-López,Felix Motzoi*

Main category: quant-ph

TL;DR: RL框架实现自适应量子纠错，有效提升逻辑保真度。


<details>
  <summary>Details</summary>
Motivation: 探索能够实时适应时变噪声的高效量子纠错（QEC）方法。

Method: 提出一个基于强化学习（RL）的两层框架：第一层使用无模型多智能体RL（MARL）自动发现QEC循环（逻辑状态编码、稳定器测量和恢复），无需先验知识；第二层使用BRAVE算法（Bandit Retraining for Adaptive Variational Error correction）实时调整变分层以适应时变噪声，同时最小化计算开销和减少再训练步骤。

Result: 将MARL和BRAVE结合，在受时变比特翻转和相位翻转错误影响的多层系统上进行测试，与传统QEC方案相比，在时变噪声信道下逻辑保真度提升了一个数量级以上。

Conclusion: RL框架能够学习并适应时变噪声，实现高效的量子纠错，显著提高逻辑保真度。

Abstract: Can we build efficient Quantum Error Correction (QEC) that adapts on the fly
to time-varying noise? In this work we say yes, and show how. We present a two
level framework based on Reinforcement Learning (RL) that learns to correct
even non-stationary errors from scratch. At the first level we take advantage
of model-free Multi-Agent RL (MARL) to automatically discover full QEC cycle --
logical state encoding, stabilizer measurements, and recovery -- without any
prior system knowledge, relying only on orthogonality conditions. Leveraging
the stabilizer formalism, we demonstrate that our MARL framework can discover
novel QEC codes tailored for multi-level quantum architectures. At the second
level we introduce BRAVE (Bandit Retraining for Adaptive Variational Error
correction), an efficient algorithm that tunes the variational layer on the fly
to change the physical basis of the errors, adapting the QEC code to
time-varying noise while minimizing computational overhead and reducing the
number of retraining steps. By combining our MARL and BRAVE approaches and
testing them on multi-level systems subjected to competing bit- and phase-flip
errors over time across diverse scenarios, we observed an improvement in
logical fidelity by more than an order of magnitude -- under time-dependent
noise channels -- compared to conventional QEC schemes.

</details>


### [220] [Forecasting Low-Dimensional Turbulence via Multi-Dimensional Hybrid Quantum Reservoir Computing](https://arxiv.org/abs/2509.04006)
*L. Salatino,L. Mariani,A. Giordano,F. D'Amore,C. Mastroianni,L. Pontieri,A. Vinci,C. Gencarelli,L. Primavera,F. Plastina,J. Settino,F. Carbone*

Main category: quant-ph

TL;DR: 混合量子-经典水库架构利用量子演化和经典记忆来预测流体动力学中的混沌行为。


<details>
  <summary>Details</summary>
Motivation: 物理学中预测复杂动力学是一个未解决的问题，因为非线性和多尺度相互作用限制了传统方法的可靠性。量子水库计算（QRC）利用量子系统的希尔伯特空间的高维性来处理信息，是一种有前途的方法。

Method: 提出了一种混合量子-经典水库架构，通过量子演化和经典记忆增强来处理多元时间序列。该模型使用具有输入调制动力学和时间复用的五比特横向场伊辛哈密顿量，可在多个时间尺度上编码输入信号。

Result: 将该框架应用于二维纳维-斯托克斯方程的低维截断和洛伦兹-63系统。通过系统地扫描量子系统的参数空间，确定了最大化预测性能（通过有效预测时间衡量）的区域。

Conclusion: 观察到的鲁棒性和可靠的性能表明，这种混合量子方法为模拟复杂非线性时间序列提供了一个灵活的平台。

Abstract: The prediction of complex dynamics remains an open problem across many
domains of physics, where nonlinearities and multiscale interactions severely
limit the reliability of conventional forecasting methods. Quantum reservoir
computing (QRC) has emerged as a promising paradigm for information processing
by exploiting the high dimensionality of the Hilbert space, where the dynamics
of quantum systems take place. Here, we introduce a hybrid quantum-classical
reservoir architecture capable of handling multivariate time series through
quantum evolution combined with classical memory enhancement. Our model employs
a five-qubit transverse-field Ising Hamiltonian with input-modulated dynamics
and temporal multiplexing, enabling the encoding of input signals over multiple
timescales. We apply this framework to two paradigmatic models of chaotic
behavior in fluid dynamics, where multiscale dynamics and nonlinearities play a
dominant role: a low-dimensional truncation of the two-dimensional
Navier-Stokes equations and the Lorenz-63 system. By systematically scanning
the quantum system's parameter space, we identify regions that maximize
forecasting performance, as measured by the Valid Prediction Time. The observed
robustness and reliable performances for both dynamical systems suggest that
this hybrid quantum approach offers a flexible platform for modelling complex
nonlinear time series.

</details>


### [221] [A Framework for Quantum Data Center Emulation Using Digital Quantum Computers](https://arxiv.org/abs/2509.04029)
*Seyed Navid Elyasi,Seyed Morteza Ahmadian,Paolo Monti,Jun Li,Rui Lin*

Main category: quant-ph

TL;DR: 本工作提出了一个框架，使用单个量子处理器来模拟量子数据中心（QDCs）系统，克服了远程门执行的挑战，并验证了分布式量子算法。


<details>
  <summary>Details</summary>
Motivation: 随着量子计算硬件的发展，单芯片架构的局限性（尤其是量子比特数量少）促使人们对模块化量子计算系统和量子数据中心（QDCs）产生了浓厚的兴趣。然而，分布式量子计算（DQC）的实现面临着严峻的技术挑战，尤其是在远程门执行方面。目前缺乏能够评估各种DQC系统理论提案的实际仿真工具。

Method: 提出一个框架，使用单个量子处理器来模拟DQC系统。将现有量子处理单元（QPU）的物理量子比特耦合图划分为多个逻辑QPU，并引入基于量子碰撞动力学的实验性噪声模型来量化互连引起的噪声，以模拟光纤连接的QPU。

Result: 使用IBM的量子硬件验证了该框架，成功实现了在有噪声条件下的远程门执行。实现了Grover搜索和量子傅里叶变换（QFT）的分布式版本，表明在所提出的框架中，跨互连QPU的复杂电路可以以合理的保真度执行。Grover算法的仿真结果与两个通过光纤互连的离子阱QPU之间的实际实验实现相符。

Conclusion: 这项工作提供了一个通用的仿真工具，用于研究QDC的行为，同时考虑了互连引起的通信噪声，并为在不需要专门的互连硬件的情况下验证分布式量子协议提供了一种实用的方法。

Abstract: As quantum computing hardware advances, the limitations of single-chip
architectures, particularly in terms of small qubit count, have sparked growing
interest in modular quantum computing systems and Quantum Data Centers (QDCs).
These architectures interconnect multiple quantum processor units (QPUs) to
overcome physical constraints and support complex quantum algorithms. However,
the implementation of distributed quantum computing (DQC) faces significant
technical challenges, especially in the execution of remote gates. Moreover, no
practical emulation tool currently exists to evaluate theoretical proposals of
various DQC systems. In this work, we propose a framework that emulates a DQC
system using a single quantum processor. We partition the physical qubit
coupling map of an existing QPU into multiple logical QPUs, and introduce an
experimentally grounded noise model based on quantum collision dynamics to
quantify the interconnect-induced noise, representing fiber-connected QPUs. The
framework is validated using IBM's quantum hardware, demonstrating the
successful execution of remote gates under noisy conditions. Furthermore, we
implement distributed versions of Grover's search and the Quantum Fourier
Transform (QFT), showing that complex circuits can be executed within the
proposed framework with reasonable fidelity across interconnected QPUs. The
emulation result of Grover's algorithm aligns with the real-world experimental
implementations between two Ion-trapped QPUs interconnected by optical fiber,
which demonstrate the feasibility and accuracy of our framework. Overall, this
work provides a versatile emulation tool for investigating QDC behavior while
accounting for interconnect-induced communication noise and offers a practical
method for validating distributed quantum protocols without requiring
specialized interconnect hardware.

</details>


### [222] [Temperature-induced measurement sensitivity enhancement via imaginary weak values](https://arxiv.org/abs/2509.04048)
*Lorena Ballesteros Ferraz,Alexandre Matzkin,Alok Kumar Pan*

Main category: quant-ph

TL;DR: 混合初始探测态的弱测量和后选择可以提高测量灵敏度，但受限于弱测量条件。温度升高可能提高信噪比，但量子费舍尔信息在混合态下可能随温度无界增长，从而提高测量精度。


<details>
  <summary>Details</summary>
Motivation: 研究混合初始探测态的弱测量和后选择在提高测量灵敏度方面的潜力。

Method: 通过所有阶耦合处理测量，控制探测器密度算符的混合性（通过温度），并分析后选择后的信号噪声比和量子费舍尔信息。

Result: 信噪比在某些情况下可以通过提高温度来提高，但受限于弱测量条件。对于纯探测态，后选择并不能在考虑后选择概率的情况下提高精度。对于混合探测态，后选择后的量子费舍尔信息可以超过标准策略，并且可能随温度无界增长。

Conclusion: 弱测量和后选择在混合初始探测态下可以提高测量灵敏度，尽管存在约束。热噪声在某些情况下可以反直觉地提高测量精度。

Abstract: We investigate the potential of weak measurement and post-selection to
enhance measurement sensitivity when the initial probe state is mixed. In our
framework, the mixedness of the probe's density operator is controlled by
temperature. We focus on two key quantities: the signal-to-noise ratio and the
quantum Fisher information of the final probe state, evaluated after
post-selection is applied on the system. Our analysis employs a rigorous,
all-order coupling treatment of measurement, demonstrating that the
signal-to-noise ratio can be enhanced in certain scenarios by increasing the
temperature. However, this enhancement is fundamentally constrained by the
validity conditions of the weak measurement regime. Regarding the quantum
Fisher information, we find that for a pure probe state, incorporating
post-selection does not improve precision beyond the standard
(non-post-selected) strategy when the post-selection probability is accounted
for. In contrast, when the initial probe state is mixed, the quantum Fisher
information for the probe state after post-selection in the system can surpass
that of the standard strategy. Notably, we show that the quantum Fisher
information might diverge and grow unboundedly with temperature, illustrating a
scenario where thermal noise can, counterintuitively, enhance metrological
precision.

</details>


### [223] [Quantum Zeno effect versus adiabatic quantum computing and quantum annealing](https://arxiv.org/abs/2509.04057)
*Naser Ahmadiniaz,Dennis Kraft,Gernot Schaller,Ralf Schützhold*

Main category: quant-ph

TL;DR: The quantum Zeno effect limits the performance of adiabatic Grover's algorithm and similar quantum schemes due to decoherence from environmental coupling, but error correction or gradual state changes may offer solutions.


<details>
  <summary>Details</summary>
Motivation: To study the impact of decoherence on the adiabatic version of Grover's quantum search algorithm and analogous quantum schemes.

Method: Analyzed the effect of decoherence from a general coupling to an environment on adiabatic quantum algorithms, specifically Grover's algorithm, and related schemes like quantum annealing. Investigated the role of the quantum Zeno effect and considered potential remedies.

Result: Found that the quantum Zeno effect, caused by environmental coupling, significantly limits the performance and quantum speed-up of adiabatic Grover's algorithm by inhibiting quantum transitions. This limitation is generalizable to other adiabatic quantum algorithms and quantum annealing schemes relying on Landau-Zener transitions.

Conclusion: Decoherence due to environmental coupling, manifesting as the quantum Zeno effect, strongly restricts adiabatic quantum algorithms. Gradual quantum state changes or error-correcting techniques like spin-echo could mitigate these restrictions.

Abstract: For the adiabatic version of Grover's quantum search algorithm as proposed by
Roland and Cerf, we study the impact of decoherence caused by a rather general
coupling to some environment. For quite generic conditions, we find that the
quantum Zeno effect poses strong limitations on the performance (quantum
speed-up) since the environment effectively measures the state of the system
permanently and thereby inhibits or slows down quantum transitions.
Generalizing our results, we find that analogous restrictions should apply
universally to adiabatic quantum algorithms and quantum annealing schemes which
are based on isolated Landau-Zener type transitions at avoided level crossings
(similar to first-order phase transitions). As a possible resort, more gradual
changes of the quantum state (as in second-order phase transitions) or suitable
error-correcting schemes such as the spin-echo method may alleviate this
problem.

</details>


### [224] [Local Invariance of Divergence-based Quantum Information Measures](https://arxiv.org/abs/2509.04079)
*Christopher Popp,Tobias C. Sutter,Beatrix C. Hiesmayr*

Main category: quant-ph

TL;DR: 研究了量子信息量的不变性，并将其应用于优化量子协议。


<details>
  <summary>Details</summary>
Motivation: 量子信息量（如互信息和熵）对于表征量子系统和量子信息科学中的协议至关重要。

Method: 利用反向通道和数据处理不等式，证明了基于广义散度的信息量度量在局部等距或酉变换下的不变性，适用于渐近和单次博弈场景。

Result: 证明了在局部等距或酉变换下，基于广义散度的信息量度量具有不变性，并且该不变性不依赖于散度的具体函数形式。

Conclusion: 这些不变性可以改进信息量的计算或优化协议及其输出状态，从而提高对许多操作上相关的量子信息度量的表征和计算能力，并在量子信息处理领域具有广泛应用。

Abstract: Quantum information quantities, such as mutual information and entropies, are
essential for characterizing quantum systems and protocols in quantum
information science. In this contribution, we identify types of information
measures based on generalized divergences and prove their invariance under
local isometric or unitary transformations. Leveraging the reversal channel for
local isometries together with the data processing inequality, we establish
invariance for information quantities used in both asymptotic and one-shot
regimes without relying on the specific functional form of the underlying
divergence. These invariances can be applied to improve the computation of such
information quantities or optimize protocols and their output states whose
performance is determined by some invariant measure. Our results improve the
capability to characterize and compute many operationally relevant information
measures with application across the field of quantum information processing.

</details>


### [225] [Efficient QKD in Non-Ideal Scenarios with User-Defined Output Length Requirements](https://arxiv.org/abs/2509.04140)
*Andrés Martín-Megino,Blanca López,Iván Vidal Fernández,Francisco Valera Pintor*

Main category: quant-ph

TL;DR: BB84协议的变量长度自适应方法可以满足用户定义的输出密钥长度约束，并优化量子资源利用率。


<details>
  <summary>Details</summary>
Motivation: 提高QKD系统中密钥缓冲区的效率，优化时间和资源利用率。

Method: 提出一种变量长度的BB84协议，动态配置初始参数以生成所需长度的密钥。

Result: 仿真结果表明该方法可以优化量子资源利用率，支持密钥管理，并有助于扩展和加强安全的量子网络。

Conclusion: 该方法在BB84框架下验证，可扩展至其他QKD协议，有效解决密钥缓冲区过载问题，提升QKD系统性能。

Abstract: Quantum Key Distribution (QKD) enables two parties to securely share
encryption keys by leveraging the principles of quantum mechanics, offering
protection against eavesdropping. In practical implementations, QKD systems
often rely on a layered architecture where a key manager stores secret key
material in a buffer and delivers it to higher communication layers as needed.
However, this buffer can be depleted under high demand, requiring efficient
replenishment strategies that minimize resource waste. Given the importance of
optimizing time and resources in quantum cryptography protocols, we introduce a
variable-length adaptation of the BB84 protocol designed to meet user-defined
output key length constraints in non-ideal scenarios. We present a method for
dynamically configuring the protocol's initial parameters to generate secret
keys of a desired length. To validate our approach, we developed simulation
tools to model general QKD networks and discrete-variable protocols. These
tools were used to implement and evaluate our strategies, which were developed
within the BB84 framework but can be extended to other QKD protocols under
reasonable assumptions. The results highlight their usefulness in optimizing
quantum resource usage and supporting key management, contributing to the
long-term goal of scaling and strengthening secure quantum networks.

</details>


### [226] [Wavefront correction of high-dimensional two-photon states via coherence-entanglement transfer](https://arxiv.org/abs/2509.04170)
*Shaurya Aarav,Hugo Defienne*

Main category: quant-ph

TL;DR: 通过泵浦整形控制纠缠度，利用量子态本身纠正光学畸变，从而实现高维空间纠缠态的可靠传输。


<details>
  <summary>Details</summary>
Motivation: 真实世界中的量子通信和成像需要可靠地传输量子光学态，但传播路径中的畸变和散射会干扰信号。传统方法依赖单独的信标光进行校正，增加了实验复杂度，且信标光与非经典态匹配困难。

Method: 通过泵浦整形控制空间纠缠双光子态的纠缠度，使其在一种情况下表现为高维纠缠态，在另一种情况下表现为经典相干态。利用相干态测量传播信道的传输矩阵，并通过空间光调制器校正畸变，最终传输高维纠缠态。

Result: 提出了一种快速高效的波前校正方法，利用量子态本身进行校正，显著减少了传输误差。

Conclusion: 该方法为基于高维空间纠缠态的量子成像和通信协议的实际应用铺平了道路。

Abstract: Reliable transmission of quantum optical states through real-world
environments is key for quantum communication and imaging. Yet, aberrations and
scattering in the propagation path can scramble the transmitted signal and
hinder its use. A typical strategy is to employ a classical beacon beam to
learn and then correct for the wavefront distortions. However, relying on a
separate light source increases the overhead in the experimental apparatus.
Moreover, the beacon light must closely match the non-classical state in
polarization, wavelength, and even temporal bandwidth, which is highly
challenging in practice. Here, we introduce a fast and efficient wavefront
correction approach where we use the quantum state itself to correct for
optical distortion. Via pump shaping, we control the degree of entanglement in
the spatially-entangled two-photon state so that it behaves either as a
high-dimensional entangled state or as a classical coherent state. The latter
case is used to efficiently measure the transmission matrix of the propagation
channel and correct its distortions with a spatial light modulator, thereby
enabling the transmission of the high-dimensional entangled state with minimal
errors. Our approach paves the way for the practical implementation of quantum
imaging and communication protocols based on high-dimensional spatially
entangled states.

</details>


### [227] [Searching for a physical description relative to a quantum system](https://arxiv.org/abs/2509.04186)
*Henrique A. R. Knopki,Renato M. Angelo*

Main category: quant-ph

TL;DR: 物理学是关于自然的模型，它能够描述和预测相对于参考系进行的测量结果。然而，现有的量子参考系方法在预测仅与量子参考系可访问自由度相关的可观测量方面存在不足。本文研究了在二维粒子系统中，通过单一的酉变换无法实现规范的、关联的描述，这表明在多体系统中存在不可约的困难。


<details>
  <summary>Details</summary>
Motivation: 对量子参考系的研究越来越受到关注，尤其是在物理定律的协方差和量子资源方面。然而，现有方法未能提供一个完整的处方来预测仅与量子参考系可访问的自由度相关的可观测量。

Method: 在伽利略相对论和绝对时间的框架内，研究了在粒子系统（特别是两粒子系统）中，相对于系统中的粒子进行规范和关联描述的可行性，并证明了通过任何酉变换无法实现这种描述，特别是在多体系统中存在不可约的困难。

Result: 在二维粒子系统中，可以实现规范和关联的描述。然而，在多体系统中，通过任何酉变换无法实现规范和关联的描述，存在不可约的困难。

Conclusion: 在伽利略相对论和绝对时间的框架内，无法通过任何酉变换实现规范和关联的描述，尤其是在多体系统中存在不可约的困难。这表明需要新的策略来解决量子参考系的问题。

Abstract: Physics is a model of nature able to both describe and predict the results of
measurements made with respect to reference systems. These reference systems,
in turn, are themselves physical and thus subject to the laws of physics. The
situation is no different when the model in use is quantum mechanics: states
and observables are relative entities, and reference frames are not exempt from
exhibiting quantum behavior. In recent years, the scientific community has
shown renewed interest in quantum reference frames, particularly in connection
with the covariance of physical laws and quantum resources. However, current
approaches fall short of providing a complete prescription for predicting
observables associated solely with degrees of freedom accessible from the
quantum reference frame. In pursuit of such a description, we show that while
this is fully feasible for two-particle systems, there are irreducible
difficulties that arise in many-body systems. In particular, within the
framework of Galilean relativity, with absolute time, we demonstrate that a
canonical and relational description with respect to a particle in the system
cannot be achieved through any unitary transformation. Our findings call for
new strategies to address the problem of quantum reference frames.

</details>


### [228] [Response of a classical mesoscopic oscillator to a two-level quantum system](https://arxiv.org/abs/2509.04216)
*Felipe Sobrero,Luca Abrahão,Thiago Guerreiro,Pedro V. Paraguassú*

Main category: quant-ph

TL;DR: 量子比特与经典机械振子耦合，振子响应中出现量子诱导的特征，可用于量子态重构。


<details>
  <summary>Details</summary>
Motivation: 研究量子比特对经典机械振子的影响，探索量子态重构的可能性。

Method: 分析量子比特作为确定性和随机力的源泉，其对振子运动的影响。

Result: 观察到振子响应中存在独特的、可测量的量子诱导的特征。

Conclusion: 通过经典噪声光谱学进行量子态重构是可行的，并具有在量子计量学、介观光力学和引力量子化等领域应用的潜力。

Abstract: We investigate the dynamics of a classical mechanical oscillator coupled to
the simplest quantum system, a single qubit. The qubit's influence manifests as
deterministic and stochastic forces, highly dependent on its initial quantum
state, imprinting unique measurable quantum-induced signatures onto the
oscillator's response. The present results suggest a pathway to quantum state
reconstruction through classical noise spectroscopy, with potential
applications to mesoscopic optomechanical experiments, quantum metrology, and
tabletop tests of the quantum nature of gravity.

</details>


### [229] [Non-unique decompositions of mixed states and deterministic energy transfers](https://arxiv.org/abs/2509.04235)
*Zihan Wang,Fei Meng,Oscar Dahlsten*

Main category: quant-ph

TL;DR: 非唯一分解影响能量转移，非经典概率理论的特征与无熵能量转移能力相关。


<details>
  <summary>Details</summary>
Motivation: 研究混合态的非唯一分解对能量转移的影响，特别是在能量收获过程中。

Method: 利用混合态的非唯一分解性质，推导出能量收获集可以扩展到包含原始态的混合态和叠加态。以电磁模式和二维系统作为模型，通过Jaynes-Cummings模型进行分析。

Result: 证明了固定幅度相干电磁模式态的集合可以扩展到包含这些态的混合态和叠加态，并且这些扩展后的态也能实现确定性的能量转移。

Conclusion: 非唯一分解是实现无熵能量转移的关键，这与非经典概率理论的定义特征相关。

Abstract: We investigate the impact of non-unique decompositions of mixed states on
energy transfer. Mixed states generally have non-unique decompositions into
pure states in quantum theory and, by definition, in other non-classical
probabilistic theories. We consider energy transfers constituting deterministic
energy harvesting, wherein the source transfers energy to the harvester but not
entropy. We use the possibility of non-unique decompositions to derive that if
source states in a set jointly lead to deterministic energy harvesting for the
given harvesting system and interaction, then that set can be expanded to
include both mixtures and superpositions of the original states in the set. As
a paradigmatic example, we model the source as an EM mode transferring energy
to a 2-level system harvester via the Jaynes-Cummings model. We show that the
set of coherent EM mode states with fixed $|\alpha|$ that jointly achieve
deterministic energy transfer can be expanded to include all mixtures and
superpositions of those states. More generally, the results link the defining
feature of a non-classical probability theory with the ability to achieve
energy transfer without entropy transfer.

</details>


### [230] [Qubit-optimal quantum phase estimation of block-encoded Hamiltonians](https://arxiv.org/abs/2509.04246)
*S. E. Skelton*

Main category: quant-ph

TL;DR: 该研究提出了一种使用冯·诺依曼测量程序测量相位的新型量子算法，该算法以块编码的哈密顿量的时间演化为子程序，并仅需要O(1)个量子比特的指针系统。


<details>
  <summary>Details</summary>
Motivation: 为量子相位估计（QPE）提供一种更简单、更高效的算法，并分析其在Clifford+T门模型下的复杂度。

Method: 利用冯·诺依曼测量程序和块编码的哈密顿量时间演化来实现QPE，并结合块编码实现的最新研究成果，分析其在Clifford+T门模型下的复杂度。

Result: 提出了一种量子相位估计的简单算法，其指针系统量子比特数量为O(1)；给出了QPE相对于哈密顿量参数和期望精度的Clifford+T复杂度边界；提供了对Clifford+T实现的QSP、量子特征值变换或量子奇异值变换电路的通用误差分析。

Conclusion: 所提出的基于冯·诺依曼测量程序的量子相位估计算法在理论和实现上都具有显著优势，并且对其在Clifford+T门模型下的复杂度进行了详细分析，为相关量子算法的优化提供了理论支持。

Abstract: Block-encodings have become one of the most common oracle assumptions in the
circuit model. I present an algorithm that uses von Neumann's measurement
procedure to measure a phase, using time evolution on a block-encoded
Hamiltonian as a subroutine. This produces an extremely simple algorithm for
quantum phase estimation, which can be performed with a pointer system of
$\mathcal{O}(1)$ qubits.
  I then use recent results for block-encoding implementations, showing that
one can efficiently prepare QPE beginning from a linear combination of Pauli
strings. Using this, I give the Clifford + T complexity bound for QPE with
respect to model-relevant parameters of the Hamiltonian and the desired
precision. In the process, I provide a very general error analysis for Clifford
+ T implementations of QSP, quantum eigenvalue transformation, or quantum
singular value transformation circuits.

</details>


### [231] [Foundations of photonic quantum computation](https://arxiv.org/abs/2509.04266)
*Martin Bombardelli,Gérard Fleury,Philippe Lacomme,Bogdan Vulpescu*

Main category: quant-ph

TL;DR: 本论文介绍了光量子计算机的计算基础，包括特定门操作、与标准泡利门的联系，以及利用Perceval库的实现。


<details>
  <summary>Details</summary>
Motivation: 为熟悉泡利门和标准量子概念的工程师和研究人员提供一个清晰、简洁的光子学组件介绍。

Method: 介绍光量子计算所需的基本概念，包括特定门操作、与标准泡利门的联系。通过理论、物理和应用（Perceval库）三个方面进行阐述。之后，通过比较Grover算法的原始形式和利用偏振的版本，介绍偏振概念的实际应用。

Result: 通过比较Grover算法的原始形式和利用偏振的版本，引入了特定于偏振的门，并描述了其在Grover算法计算中的应用。

Conclusion: 本论文旨在为熟悉“传统”量子电路的研究人员提供一个数学化的、易于理解的偏振概念介绍，以简化他们对光子计算的掌握。

Abstract: This work aims to introduce the fundamental concepts required to perform
computations on photonic quantum computers by presenting the gates specific to
this architecture and highlighting the connections between standard Pauli gates
and those available in photonic systems. The introduction navigates between
physical considerations related to the optical components used, theoretical
aspects concerning quantum operators, and a more applied section introducing
implementations using the Perceval library developed by Quandela. This paper is
intended for engineers and researchers familiar with Pauli gates and standard
quantum concepts, looking at a clear and compact introduction to photonic
components. A second part aims to introduce the concept of polarization, not
from a theoretical perspective, but through its practical applications. To do
so, we compare the similarities and differences between the original Grover's
algorithm formulation and a version that leverages polarization. Gates specific
to polarization are introduced and described in the context of the computations
involved in Grover's algorithm. The description provided is as mathematical as
possible and deliberately avoids physical considerations, in order to allow
researchers familiar with "conventional" quantum circuits to more easily grasp
the concepts.

</details>


### [232] [Coherent Two-State Oscillations in False Vacuum Decay Regimes](https://arxiv.org/abs/2509.04272)
*Peiyun Ge,Xiao Wang,Yu-Xin Chao,Rong Lv,Li You*

Main category: quant-ph

TL;DR: 在量子伊辛模型中，即使在伪真空衰变下，相干的二态振荡也可以通过数值模拟观察到。


<details>
  <summary>Details</summary>
Motivation: 研究一维横向和纵向场伊辛模型在伪真空衰变下的行为，特别是观察相干二态振荡的出现。

Method: 通过数值模拟研究一维横向和纵向场伊辛模型。在共振条件下，分析伪真空与对称共振态之间的振荡，并计算了子领先本征态的重叠和洛施密特回声。对于更大的系统，研究了气泡尺寸阻滞效应和长程相互作用对振荡的影响。

Result: 在伪真空衰变下，一维横向和纵向场伊辛模型中观察到相干二态振荡。当满足共振条件 $h 
approx 2J/n$ 时，系统会在伪真空和对称共振态之间振荡，子领先本征态重叠接近 0.5，洛施密特回声周期性消失。振荡频率的增强与系统尺寸 $\sqrt{L}$ 相关，这与早期的 Schrieffer-Wolff 预测不同。在更大的系统中，这些振荡即使在 $n \gtrsim L/2$ 的条件下也能持续存在，或者当长程相互作用打破多气泡简并时也能持续存在。

Conclusion: 相干二态振荡是一种鲁棒的量子多体相干机制，它超越了微扰处理和有限尺寸的限制，在伪真空衰变下的一维伊辛模型中表现出来。

Abstract: Coherent two-state oscillations are observed in numerical simulations of
one-dimensional transverse- and longitudinal-field Ising model within the false
vacuum decay regimes. Starting from the false vacuum state with all spins up,
in moderate-sized systems with a small transverse field, we find conventional
decay dynamics at resonance conditions $ h\approx 2J/n$ can change into
coherent oscillations between the false vacuum and a symmetric resonant state,
manifested by a sub-leading eigenstate overlap approaching $0.5$ and periodic
vanishing of the Loschmidt echo. Notably, the oscillation frequency shows a
superradiant-like $\sqrt{L}$ enhancement compared to the earlier
Schrieffer-Wolff predictions. In larger systems, we find these oscillations
persist for $n \gtrsim L/2$ (enabled by a bubble size blockade effect) or when
long-range interactions lift multi-bubble degeneracies, revealing a robust
many-body coherence mechanism transcending perturbative treatments and
finite-size limitations.

</details>


### [233] [Unifying inequalities bounding quantum speed limits](https://arxiv.org/abs/2509.04283)
*Tristán M. Osán,Yanet Álvarez,Mariela Portesi,Pedro Walter Lamberti*

Main category: quant-ph

TL;DR: 本研究提出了一种基于广义保真度测度的量子速度极限（QSL）的通用理论框架，并证明了Margolus-Levitin和Mandelstam-Tamm不等式仅依赖于所选的保真度测度，而非保真度函数。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探究广义保真度测度在量子速度极限（QSL）推导中的作用，并建立一个通用的理论结构。

Method: 本研究通过选择特定的广义保真度测度，推导了Margolus-Levitin和Mandelstam-Tamm不等式，并分析了其对unitary和非unitary动力学的影响。

Result: 研究结果表明，所推导的QSL不等式仅依赖于所选择的保真度测度，与保真度的单调可微函数无关，并包含了文献中的其他界限。

Conclusion: 本研究强调了通过对保真度进行函数变换来改进QSL界限的局限性，并指出真正的改进需要新的保真度定义。研究结果可以自然地推广到其他广义保真度测度。

Abstract: In this work, we investigate the role of generalized fidelity measures in the
derivation of quantum speed limits (QSLs) within a geometric approach. We
establish a general theoretical structure and demonstrate that, once a specific
generalized fidelity is selected, the resulting Margolus-Levitin and
Mandelstam-Tamm bounds for both unitary and non-unitary (Lindblad-type)
dynamics depend solely on the chosen fidelity measure. These bounds are shown
to be entirely independent of the particular choice of monotonic and
differentiable functionals of the selected fidelity. This result highlights the
limitations of improving QSL bounds through functional transformations of
fidelity and indicates that genuine improvements must stem from alternative
fidelity definitions. We further show that several bounds found in the
literature are encompassed by our framework. We also discuss how our results
can be naturally extended by considering other generalized fidelity measures
beyond those explicitly treated

</details>


### [234] [Quantum metrology through spectral measurements in quantum optics](https://arxiv.org/abs/2509.04300)
*Alejandro Vivas-Viaña,Carlos Sánchez Muñoz*

Main category: quant-ph

TL;DR: 本篇论文研究了量子光学中通过光谱滤波进行参数估计的测量策略，并提出了一个理论框架来评估和优化该策略。


<details>
  <summary>Details</summary>
Motivation: 在量子计量学中，如何从量子态中提取关于未知参数的信息是一个关键挑战。本文旨在系统地量化和评估在量子光学中通过选择频率模式（光谱滤波）来进行参数估计的测量策略的潜能。

Method: 提出一个理论框架，将光谱检测建模为级联量子系统，以重构频率滤波后的光子模式的密度矩阵，并计算相关的费雪信息量。

Result: 开发了一个通用的方法来评估光谱测量的性能，能够确定最优的滤波策略，包括频率选择、探测器线宽以及通过高阶频率分辨相关性和平均场工程可获得的技术增益。

Conclusion: 该研究为识别和设计实际量子光学平台中的最优传感策略奠定了基础。

Abstract: Continuously monitored quantum systems are emerging as promising platforms
for quantum metrology, where a central challenge is to identify measurement
strategies that optimally extract information about unknown parameters encoded
in the complex quantum state of emitted radiation. Different measurement
strategies effectively access distinct temporal modes of the emitted field, and
the resulting choice of mode can strongly impact the information available for
parameter estimation. While a ubiquitous approach in quantum optics is to
select frequency modes through spectral filtering, the metrological potential
of this technique has not yet been systematically quantified. We develop a
theoretical framework to assess this potential by modeling spectral detection
as a cascaded quantum system, allowing us to reconstruct the full density
matrix of frequency-filtered photonic modes and to compute their associated
Fisher information. This framework provides a minimal yet general method to
benchmark the performance of spectral measurements in quantum optics, allowing
to identify optimal filtering strategies in terms of frequency selection,
detector linewidth, and metrological gain accessible through higher-order
frequency-resolved correlations and mean-field engineering. These results lay
the groundwork for identifying and designing optimal sensing strategies in
practical quantum-optical platforms.

</details>


### [235] [A Generalized Nonlinear Extension of Quantum Mechanics](https://arxiv.org/abs/2509.04320)
*Alan Chodos,Fred Cooper*

Main category: quant-ph

TL;DR: We present a more general nonlinear extension of quantum mechanics with an underlying Hamiltonian structure, which allows for particle trajectories, including closed orbits.


<details>
  <summary>Details</summary>
Motivation: To construct a more general nonlinear extension of quantum mechanics with specific properties.

Method: Constructing the general form of the nonlinear extension, analyzing a particular solution, and using a natural extension of the Born rule to compute particle trajectories.

Result: The new version is not completely integrable but has an underlying Hamiltonian structure. Closed particle orbits are found to be possible.

Conclusion: The generalized nonlinear extension of quantum mechanics allows for the computation of particle trajectories, including closed orbits, through an extended Born rule.

Abstract: We construct the most general form of our previously proposed nonlinear
extension of quantum mechanics that possesses three basic properties. Unlike
the simpler model, the new version is not completely integrable, but it has an
underlying Hamiltonian structure. We analyze a particular solution in detail,
and we use a natural extension of the Born rule to compute particle
trajectories. We find that closed particle orbits are possible.

</details>


### [236] [DGLAP-BFKL duality from QCD to quantum computers](https://arxiv.org/abs/2509.04327)
*Igor Kondrashuk*

Main category: quant-ph

TL;DR: DGLAP方程可通过Mellin矩复平面映射解得，并重写为薛定谔方程或对偶DGLAP方程。对偶DGLAP方程的Regge极限与BFKL方程一致，后者也可重写为薛定谔方程，并可用相同方法求解，此方法可能应用于量子通信。


<details>
  <summary>Details</summary>
Motivation: 将DGLAP方程及其相关方程（如BFKL方程）的求解方法推广到Mellin矩复平面映射，并探索其在量子通信中的应用潜力。

Method: 利用Mellin矩复平面映射的方法，将DGLAP方程和BFKL方程分别重写为薛定谔方程或对偶DGLAP方程，并提出用该方法求解。

Result: DGLAP方程和BFKL方程均可通过Mellin矩复平面映射的方法重写为薛定谔方程，并可以求解。

Conclusion: Mellin矩复平面映射的方法不仅能有效求解DGLAP和BFKL方程及其对应的薛定谔方程，还可能为解决量子通信相关问题提供新的途径。

Abstract: DGLAP integro-differential equation can be solved by applying certain map in
the complex plane of Mellin moments. It may be re-written as Schr\"odinger
equation for $n$ particles. By applying another map in the complex plane of
Mellin moment we may re-write the DGLAP equation as a dual DGLAP equation.
Regge limit of the dual DGLAP equation coincides with BFKL integro-differential
equation which in turn is the Regge limit of optic theorem in quantum field
theory and may be re-written as another Schr\"odinger equation. This means that
the BFKL equation and the corresponding Schr\"odinger equation may be solved by
the proposed method of complex mapping in the complex plane of Mellin moments.
This approach may be useful in solving tasks related to quantum communication
processes.

</details>


### [237] [Constructing a Photonic Implementation of Quantum Key Distribution](https://arxiv.org/abs/2509.04389)
*Alec L. Riso,Karthik Thyagarajan,Connor Whiting,Katherine Jimenez,Mark Hannum*

Main category: quant-ph

TL;DR: 本项目旨在通过光子学在实验室环境中实现量子密钥分发（QKD），以验证其鲁棒性并为教育演示提供可行方案。


<details>
  <summary>Details</summary>
Motivation: 本项目旨在通过光子学在实验室环境中实现量子密钥分发（QKD），以验证其鲁棒性并为教育演示提供可行方案。

Method: 本项目旨在通过光子学在实验室环境中实现量子密钥分发（QKD），以验证其鲁棒性并为教育演示提供可行方案。

Result: 本项目旨在通过光子学在实验室环境中实现量子密钥分发（QKD），以验证其鲁棒性并为教育演示提供可行方案。

Conclusion: 本项目旨在通过光子学在实验室环境中实现量子密钥分发（QKD），以验证其鲁棒性并为教育演示提供可行方案。

Abstract: Quantum Key Distribution (QKD) stands as a revolutionary approach to secure
communication, using the principles of quantum mechanics to establish
unbreakable channels. Unlike traditional cryptography, which relies on the
computational difficulty of mathematical problems, QKD utilizes the inherent
properties of quantum states to achieve information-theoretic security. This
means that the security of the key exchange is guaranteed by the laws of
physics, making it theoretically unbreakable even by an adversary with
unlimited computational power. Currently, one of the most viable ways to
implement QKD for communication is via photonics, namely, using
phase-preserving long-distance optical fibers. The objective of this project is
to implement photonic QKD in a laboratory setting. This will help demonstrate
the protocol's robustness and provide a feasible implementation for educational
demonstrations.

</details>


### [238] [Unilateral Criticality and Phase Transition in the Cavity-Ising Model](https://arxiv.org/abs/2509.04391)
*Zeyu Rao,Xiaoshui Lin,Xiwang Luo,Guangcan Guo,Han Pu,Ming Gong*

Main category: quant-ph

TL;DR: 该研究在腔耦合横向伊辛模型中发现了单边临界端点（UCEP）和三重临界点（TCP），UCEP是一种新的相变现象，表现出单向临界行为，并且可能在量子测量和量子传感等领域有应用前景。


<details>
  <summary>Details</summary>
Motivation: 研究腔光-物质耦合中的超辐射相变，并探索腔耦合横向伊辛模型中是否存在新的相变现象。

Method: 通过理论分析，构建了描述UCEP的自由能密度，并绘制了有限温度下的相图，同时进行了对称性分析。

Result: 在零温下，模型存在三个相，通过两次二阶相变和一次一阶相变分隔。在某个点，两条二阶相变线和一条一阶相变线交汇于TCP和UCEP。UCEP表现出单边临界性，即从不同方向逼近时，表现为不同类型的相变，有两个序参量分别在一阶和二阶相变中变化。该模型在 $(c_{1},c_{2})=(1/e,0)$ 处存在UCEP。

Conclusion: UCEP是一种新的相变类型，它将一阶和二阶相变特征统一在单一的、依赖于方向的端点中，为腔耦合多体系统中的新奇临界现象研究提供了平台，并可能在量子测量和量子传感等领域带来应用。

Abstract: Superradiant phase transitions from cavity light-matter coupling have been
widely explored across platforms. Here, we report a unilateral critical
endpoint (UCEP) and a tricritical point (TCP) in the phase diagram of the
cavity-coupled transverse Ising model with $\mathbb{Z}_2$ symmetry. At zero
temperature, we demonstrate that this model hosts three phases separated by two
second-order and one first-order transitions. These lines intersect at a TCP
and a UCEP, the latter not captured by existing phase-transition paradigms. The
UCEP displays one-sided criticality: approaching the point from one side, the
system behaves as a second-order transition, while from the other side it is
first-order. Correspondingly, two order parameters, respectively, undergo the
first- and the second-order phase transitions at the same point. We construct a
minimal description of UCEP with the density of the free energy $f =
c_{1}(\tilde{\alpha}^{2}+c_{2})+(\tilde{\alpha}^{2}+c_{2})^{2}\ln{\vert\tilde{\alpha}^{2}+c_{2}\vert}$,
with the UCEP at $(c_{1},c_{2})=(1/e,0)$ and $\tilde{\alpha}$ being the order
parameter. We further map the finite-temperature phase diagram and perform a
symmetry analysis. By unifying first- and second-order signatures in a single,
direction-dependent endpoint, the UCEP introduces a qualitatively new class of
phase transition and may have applications in fields such as quantum
measurement and quantum sensing. This work also provides an intriguing platform
for exploring novel critical phenomena in cavity-coupled many-body systems with
or without dissipation.

</details>


### [239] [Monte Carlo simulation of random circuit sampling in quantum computing](https://arxiv.org/abs/2509.04401)
*Andreas Raab*

Main category: quant-ph

TL;DR: To speed up random circuit sampling, we created new Monte Carlo methods that use exact probability density functions to mimic the Porter-Thomas distribution. These methods are efficient even for systems with over a million qubits, allowing random circuit sampling to be done on classical computers.


<details>
  <summary>Details</summary>
Motivation: To develop efficient methods for sampling random states and bit strings in qubit systems, addressing the computational challenges of large systems.

Method: Derived exact probability density functions that produce the Porter-Thomas distribution for large systems and applied these in importance sampling algorithms.

Result: Demonstrated efficiency of the Monte Carlo methods for qubit systems of various sizes (70, 105, 1000, and over a million qubits), enabling simulation of recent quantum computations on a classical PC with minimal cost.

Conclusion: Argues that random circuit sampling can be conveniently performed on classical computers using the developed methods.

Abstract: We develop Monte Carlo methods for sampling random states and corresponding
bit strings in qubit systems. To this end, we derive exact probability density
functions that yield the Porter-Thomas distribution in the limit of large
systems. We apply these functions in importance sampling algorithms and
demonstrate efficiency for qubit systems with 70, 105, 1000, and more than one
million ($2^{20}$) qubits. In particular, we simulate the output of recent
quantum computations without noise on a PC with minimal computational cost. I
would therefore argue that random circuit sampling can be conveniently
performed on classical computers.

</details>


### [240] [Infinite temperature at zero energy](https://arxiv.org/abs/2509.04410)
*Matteo Ippoliti,David M. Long*

Main category: quant-ph

TL;DR: 我们提出了一种构造静态局部哈密顿量的方法，该哈密顿量继承了周期驱动（Floquet）系统的本征态特性，特别是具有体积律纠缠熵的基态。通过修改Feynman-Kitaev时钟模型，并假设ETH成立，我们实现了这一目标。此外，我们还构造了一类精确可解的Floquet量子电路，其本征态满足无限温度下的ETH。结合这两种方法，我们得到了一类具有可证明的体积律纠缠基态的新型局部哈密顿量，并且这是第一个能保证所有连续子系统都满足体积律的构造。


<details>
  <summary>Details</summary>
Motivation: 本文旨在构造一类静态的、几何局部性的哈密顿量，这些哈密顿量能够继承周期驱动（Floquet）系统的本征态特性，特别是希望能够获得具有体积律纠缠熵的基态，并确保这种体积律对所有连续子系统都成立。

Method: 本文首先通过修改Feynman-Kitaev时钟模型来构造一类静态局部哈密顿量，并赋予时钟寄存器周期性边界条件。在此基础上，假设输入电路满足本征态热化假设（ETH），从而得到其本征态具有无限温度下特征（如体积律纠缠熵）的哈密顿量。接着，构造了一类精确可解的Floquet量子电路，并证明其本征态满足无限温度下的ETH。最后，结合以上两种构造方法，得到了一类新的局部哈密顿量。

Result: 通过所提出的方法，我们成功构造了一类静态局部哈密顿量，其本征态具有无限温度下的特征，包括整个能谱中的体积律纠缠熵。此外，我们还构造了一类精确可解的Floquet量子电路，其本征态被证明满足无限温度下的ETH。将这两者结合，我们得到了首个能确保所有连续子系统都具有体积律纠缠基态的新型局部哈密顿量。

Conclusion: 本文成功提出了一种构造静态局部哈密顿量的新方法，该方法能够产生具有体积律纠缠基态的系统，并且这种体积律对于所有连续子系统都成立。这为研究具有大块纠缠的量子系统提供了新的途径。

Abstract: We construct a family of static, geometrically local Hamiltonians that
inherit eigenstate properties of periodically-driven (Floquet) systems. Our
construction is a variation of the Feynman-Kitaev clock -- a well-known mapping
between quantum circuits and local Hamiltonians -- where the clock register is
given periodic boundary conditions. Assuming the eigenstate thermalization
hypothesis (ETH) holds for the input circuit, our construction yields
Hamiltonians whose eigenstates have properties characteristic of infinite
temperature, like volume-law entanglement entropy, across the whole spectrum --
including the ground state. We then construct a family of exactly solvable
Floquet quantum circuits whose eigenstates are shown to obey the ETH at
infinite temperature. Combining the two constructions yields a new family of
local Hamiltonians with provably volume-law-entangled ground states, and the
first such construction where the volume law holds for all contiguous
subsystems.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [241] [Integrating Pruning with Quantization for Efficient Deep Neural Networks Compression](https://arxiv.org/abs/2509.04244)
*Sara Makenali,Babak Rokh,Ali Azarpeyvand*

Main category: cs.NE

TL;DR: DNNs在资源受限设备上部署面临挑战，本文提出结合剪枝和量化以提高压缩效率并保持模型精度。


<details>
  <summary>Details</summary>
Motivation: DNNs因计算和内存需求大，在资源受限设备上部署困难。剪枝和量化是常用压缩技术，单独使用效果有限，结合使用效果更佳，但联合优化存在精度和复杂度问题。

Method: 提出两种方法：1. 训练时同时进行剪枝和量化；2. 先剪枝后量化。均采用基于相似性的滤波器剪枝和自适应二的方次（APoT）量化。

Result: 实验结果表明，所提方法在实现有效模型压缩的同时，模型精度仅有少量下降，适用于资源受限设备的部署。

Conclusion: 本文提出的结合剪枝和量化的方法能有效压缩模型，保持模型精度，适用于资源受限设备的部署。

Abstract: Deep Neural Networks (DNNs) have achieved significant advances in a wide
range of applications. However, their deployment on resource-constrained
devices remains a challenge due to the large number of layers and parameters,
which result in considerable computational and memory demands. To address this
issue, pruning and quantization are two widely used compression techniques,
commonly applied individually in most studies to reduce model size and enhance
processing speed. Nevertheless, combining these two techniques can yield even
greater compression benefits. Effectively integrating pruning and quantization
to harness their complementary advantages poses a challenging task, primarily
due to their potential impact on model accuracy and the complexity of jointly
optimizing both processes. In this paper, we propose two approaches that
integrate similarity-based filter pruning with Adaptive Power-of-Two (APoT)
quantization to achieve higher compression efficiency while preserving model
accuracy. In the first approach, pruning and quantization are applied
simultaneously during training. In the second approach, pruning is performed
first to remove less important parameters, followed by quantization of the
pruned model using low-bit representations. Experimental results demonstrate
that our proposed approaches achieve effective model compression with minimal
accuracy degradation, making them well-suited for deployment on devices with
limited computational resources.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [242] [Gravity Well Echo Chamber Modeling With An LLM-Based Confirmation Bias Model](https://arxiv.org/abs/2509.03832)
*Joseph Jackson,Georgiy Lapin,Jeremy E. Thompson*

Main category: cs.SI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Social media echo chambers play a central role in the spread of
misinformation, yet existing models often overlook the influence of individual
confirmation bias. An existing model of echo chambers is the "gravity well"
model, which creates an analog between echo chambers and spatial gravity wells.
We extend this established model by introducing a dynamic confirmation bias
variable that adjusts the strength of pull based on a user's susceptibility to
belief-reinforcing content. This variable is calculated for each user through
comparisons between their posting history and their responses to posts of a
wide range of viewpoints.
  Incorporating this factor produces a confirmation-bias-integrated gravity
well model that more accurately identifies echo chambers and reveals
community-level markers of information health. We validated the approach on
nineteen Reddit communities, demonstrating improved detection of echo chambers.
  Our contribution is a framework for systematically capturing the role of
confirmation bias in online group dynamics, enabling more effective
identification of echo chambers. By flagging these high-risk environments, the
model supports efforts to curb the spread of misinformation at its most common
points of amplification.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [243] [Learning an Adversarial World Model for Automated Curriculum Generation in MARL](https://arxiv.org/abs/2509.03771)
*Brennen Hill*

Main category: cs.LG

TL;DR: 通过对抗性协同进化来学习可扩展的世界模型，以训练更强大、更具适应性的代理。


<details>
  <summary>Details</summary>
Motivation: 现有的训练环境缺乏可扩展性和鲁棒性，限制了具身智能代理的发展。需要能够与代理共同成长的环境。

Method: 提出一个由生成“攻击者”和协作“防御者”组成的系统。攻击者学习一个目标驱动的世界模型来生成越来越难的挑战（如敌方单位配置），以利用防御者的弱点。防御者团队学习协作策略来克服这些挑战。这种协同进化形成了自适应的学习课程。

Result: 证明了该框架能够产生复杂的行为，例如世界模型学会生成侧翼和掩护阵型，防御者学会协同集火和分散战术。

Conclusion: 对抗性协同进化是一种有效的学习方法，可以构建具有更高战略深度和鲁棒性的世界模型，从而推动代理向更高级的智能发展。

Abstract: World models that infer and predict environmental dynamics are foundational
to embodied intelligence. However, their potential is often limited by the
finite complexity and implicit biases of hand-crafted training environments. To
develop truly generalizable and robust agents, we need environments that scale
in complexity alongside the agents learning within them. In this work, we
reframe the challenge of environment generation as the problem of learning a
goal-conditioned, generative world model. We propose a system where a
generative **Attacker** agent learns an implicit world model to synthesize
increasingly difficult challenges for a team of cooperative **Defender**
agents. The Attacker's objective is not passive prediction, but active,
goal-driven interaction: it models and generates world states (i.e.,
configurations of enemy units) specifically to exploit the Defenders'
weaknesses. Concurrently, the embodied Defender team learns a cooperative
policy to overcome these generated worlds. This co-evolutionary dynamic creates
a self-scaling curriculum where the world model continuously adapts to
challenge the decision-making policy of the agents, providing an effectively
infinite stream of novel and relevant training scenarios. We demonstrate that
this framework leads to the emergence of complex behaviors, such as the world
model learning to generate flanking and shielding formations, and the defenders
learning coordinated focus-fire and spreading tactics. Our findings position
adversarial co-evolution as a powerful method for learning instrumental world
models that drive agents toward greater strategic depth and robustness.

</details>


### [244] [The Optimiser Hidden in Plain Sight: Training with the Loss Landscape's Induced Metric](https://arxiv.org/abs/2509.03594)
*Thomas R. Harvey*

Main category: cs.LG

TL;DR: 提出了一种利用黎曼度量的新型神经网络训练优化器。


<details>
  <summary>Details</summary>
Motivation: 利用损失景观嵌入到更高维度空间中自然诱导出的黎曼度量来训练神经网络。

Method: 提出了一种新的优化器，并将其与 SGD、Adam、AdamW 和 Muon 等现有方法进行比较，在多种任务和架构上进行了测试。

Result: 在低维度示例中非常有效，并在训练神经网络方面比最先进的方法略有改进。

Conclusion: 该优化器具有理论上的优势，例如在曲率高的区域自动降低有效学习率，并可以看作是梯度裁剪的平滑形式。此外，它还可以看作是诱导有效学习率，并且权重衰减自然地从几何角度选择。该方法可以修改任何现有的预处理方法，并且计算复杂度与 Adam 相当。

Abstract: We present a class of novel optimisers for training neural networks that
makes use of the Riemannian metric naturally induced when the loss landscape is
embedded in higher-dimensional space. This is the same metric that underlies
common visualisations of loss landscapes. By taking this geometric perspective
literally and using the induced metric, we develop a new optimiser and compare
it to existing methods, namely: SGD, Adam, AdamW, and Muon, across a range of
tasks and architectures. Empirically, we conclude that this new class of
optimisers is highly effective in low dimensional examples, and provides slight
improvement over state-of-the-art methods for training neural networks. These
new optimisers have theoretically desirable properties. In particular, the
effective learning rate is automatically decreased in regions of high curvature
acting as a smoothed out form of gradient clipping. Similarly, one variant of
these optimisers can also be viewed as inducing an effective scheduled learning
rate and decoupled weight decay is the natural choice from our geometric
perspective. The basic method can be used to modify any existing
preconditioning method. The new optimiser has a computational complexity
comparable to that of Adam.

</details>


### [245] [Learning functions through Diffusion Maps](https://arxiv.org/abs/2509.03758)
*Alvaro Almeida Gomez*

Main category: cs.LG

TL;DR: 使用扩散映射和SVD构建数据驱动的函数逼近方法，并在稀疏CT重建等任务中超越了传统方法。


<details>
  <summary>Details</summary>
Motivation: 为了在流形上逼近实值函数，并解决高维数据带来的计算挑战。

Method: 利用扩散几何、热方程和拉普拉斯-贝尔特米算子，结合基于SVD的降维策略和在线更新机制，来构建函数的光滑扩展。

Result: 该方法在准确性和效率方面均优于传统的馈入式神经网络和插值方法，并在稀疏CT重建等应用中得到了验证。

Conclusion: 所提出的数据驱动方法是一种在流形上逼近实值函数的有效方法，并且具有良好的计算效率和可扩展性。

Abstract: We propose a data-driven method for approximating real-valued functions on
smooth manifolds, building on the Diffusion Maps framework under the manifold
hypothesis. Given pointwise evaluations of a function, the method constructs a
smooth extension to the ambient space by exploiting diffusion geometry and its
connection to the heat equation and the Laplace-Beltrami operator.
  To address the computational challenges of high-dimensional data, we
introduce a dimensionality reduction strategy based on the low-rank structure
of the distance matrix, revealed via singular value decomposition (SVD). In
addition, we develop an online updating mechanism that enables efficient
incorporation of new data, thereby improving scalability and reducing
computational cost.
  Numerical experiments, including applications to sparse CT reconstruction,
demonstrate that the proposed methodology outperforms classical feedforward
neural networks and interpolation methods in terms of both accuracy and
efficiency.

</details>


### [246] [CEHR-GPT: A Scalable Multi-Task Foundation Model for Electronic Health Records](https://arxiv.org/abs/2509.03643)
*Chao Pang,Jiheum Park,Xinzhuo Jiang,Nishanth Parameshwar Pavinkurve,Krishna S. Kalluri,Shalmali Joshi,Noémie Elhadad,Karthik Natarajan*

Main category: cs.LG

TL;DR: CEHR-GPT 是一个通用的 EHR 模型，可实现特征表示、零样本预测和合成数据生成，并具有时间推理能力。


<details>
  <summary>Details</summary>
Motivation: 大多数人工智能模型都是为单一任务设计的，这限制了它们在现实世界中的通用性和实用性。然而，电子健康记录（EHR）具有巨大的潜力，可以促进临床决策支持、风险预测和数据驱动的医疗保健研究。

Method: CEHR-GPT 是一种通用的 EHR 数据基础模型，在一个体系结构中统一了特征表示、零样本预测和合成数据生成这三种基本功能。为了支持对临床序列进行时间推理，CEHR-GPT 采用了一种新颖的时间标记学习框架，该框架将患者的动态时间线显式编码到模型结构中。

Result: CEHR-GPT 在所有三个任务上都表现出强大的性能，并且通过词汇扩展和微调能够有效地推广到外部数据集。

Conclusion: CEHR-GPT 的多功能性能够快速进行模型开发、队列发现和患者结果预测，而无需进行特定任务的再培训。

Abstract: Electronic Health Records (EHRs) provide a rich, longitudinal view of patient
health and hold significant potential for advancing clinical decision support,
risk prediction, and data-driven healthcare research. However, most artificial
intelligence (AI) models for EHRs are designed for narrow, single-purpose
tasks, limiting their generalizability and utility in real-world settings.
Here, we present CEHR-GPT, a general-purpose foundation model for EHR data that
unifies three essential capabilities - feature representation, zero-shot
prediction, and synthetic data generation - within a single architecture. To
support temporal reasoning over clinical sequences, \cehrgpt{} incorporates a
novel time-token-based learning framework that explicitly encodes patients'
dynamic timelines into the model structure. CEHR-GPT demonstrates strong
performance across all three tasks and generalizes effectively to external
datasets through vocabulary expansion and fine-tuning. Its versatility enables
rapid model development, cohort discovery, and patient outcome forecasting
without the need for task-specific retraining.

</details>


### [247] [From Leiden to Pleasure Island: The Constant Potts Model for Community Detection as a Hedonic Game](https://arxiv.org/abs/2509.03834)
*Lucas Lopes Felipe,Konstantin Avrachenkov,Daniel Sadoc Menasche*

Main category: cs.LG

TL;DR: 该论文提出了一种基于博弈论的社群侦测方法，通过将网络划分问题视为“潜在享乐博弈”，利用局部效用最大化实现全局最优，并在效率、鲁棒性和准确性方面进行了论证和实验。


<details>
  <summary>Details</summary>
Motivation: 将社群侦测视为一个分割节点到不重叠社群的问题，并从博弈论的角度审视恒定 Potts 模型（CPM）。

Method: 将 CPM 的全局哈密顿量分解为局部效用函数，并通过“更好应对策略动态”进行局部优化，证明其能在伪多项式时间内收敛到平衡分割。引入了基于鲁棒性的严格和宽松稳定性标准。

Result: 在社群追踪场景下，实验表明鲁棒性分割在恢复真实社群方面具有更高的准确性，尤其是在利用 Leiden 算法和部分真实标签信息进行初始化时。

Conclusion: CPM 通过博弈论的视角，在效率、鲁棒性和准确性方面展现出优越性，尤其在社群追踪任务中，其鲁棒性分割策略能有效提高真实社群的恢复精度。

Abstract: Community detection is one of the fundamental problems in data science which
consists of partitioning nodes into disjoint communities. We present a
game-theoretic perspective on the Constant Potts Model (CPM) for partitioning
networks into disjoint communities, emphasizing its efficiency, robustness, and
accuracy. Efficiency: We reinterpret CPM as a potential hedonic game by
decomposing its global Hamiltonian into local utility functions, where the
local utility gain of each agent matches the corresponding increase in global
utility. Leveraging this equivalence, we prove that local optimization of the
CPM objective via better-response dynamics converges in pseudo-polynomial time
to an equilibrium partition. Robustness: We introduce and relate two stability
criteria: a strict criterion based on a novel notion of robustness, requiring
nodes to simultaneously maximize neighbors and minimize non-neighbors within
communities, and a relaxed utility function based on a weighted sum of these
objectives, controlled by a resolution parameter. Accuracy: In community
tracking scenarios, where initial partitions are used to bootstrap the Leiden
algorithm with partial ground-truth information, our experiments reveal that
robust partitions yield higher accuracy in recovering ground-truth communities.

</details>


### [248] [Nonnegative matrix factorization and the principle of the common cause](https://arxiv.org/abs/2509.03652)
*E. Khalafyan,A. E. Allahverdyan,A. Hovhannisyan*

Main category: cs.LG

TL;DR: NMF和PCC紧密相关，PCC可用于NMF的秩估计和特征提取，NMF可用于实现PCC和数据去噪。


<details>
  <summary>Details</summary>
Motivation: 探索NMF和PCC之间的关系，并利用这种关系解决NMF的秩估计、特征提取和数据去噪等问题。

Method: 首先，利用PCC作为一种可预测性工具来估计NMF的有效秩，并在此基础上实现NMF。其次，利用NMF实现PCC，并提出一种聚类方法。最后，研究NMF在数据去噪方面的应用。

Result: PCC估计的NMF秩对噪声具有鲁棒性，使得NMF提取的特征也稳定。NMF可以近似实现PCC，并用于数据聚类和去噪。

Conclusion: NMF和PCC的互补性为解决NMF相关问题和实现因果推断提供了新的途径。

Abstract: Nonnegative matrix factorization (NMF) is a known unsupervised data-reduction
method. The principle of the common cause (PCC) is a basic methodological
approach in probabilistic causality, which seeks an independent mixture model
for the joint probability of two dependent random variables. It turns out that
these two concepts are closely related. This relationship is explored
reciprocally for several datasets of gray-scale images, which are conveniently
mapped into probability models. On one hand, PCC provides a predictability tool
that leads to a robust estimation of the effective rank of NMF. Unlike other
estimates (e.g., those based on the Bayesian Information Criteria), our
estimate of the rank is stable against weak noise. We show that NMF implemented
around this rank produces features (basis images) that are also stable against
noise and against seeds of local optimization, thereby effectively resolving
the NMF nonidentifiability problem. On the other hand, NMF provides an
interesting possibility of implementing PCC in an approximate way, where larger
and positively correlated joint probabilities tend to be explained better via
the independent mixture model. We work out a clustering method, where data
points with the same common cause are grouped into the same cluster. We also
show how NMF can be employed for data denoising.

</details>


### [249] [Meta-Inverse Reinforcement Learning for Mean Field Games via Probabilistic Context Variables](https://arxiv.org/abs/2509.03845)
*Yang Chen,Xiao Lin,Bo Yan,Libo Zhang,Jiamou Liu,Neset Özkan Tan,Michael Witbrock*

Main category: cs.LG

TL;DR: 该研究提出了一种深度潜在变量MFG模型和相关IRL方法，用于从具有异构和未知目标的专家演示中推断奖励函数，解决了现有方法在处理非同质智能体方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 设计适合于众多交互式智能体的奖励函数在实际应用中充满挑战，而现有的逆强化学习（IRL）在平均场博弈（MFG）中的方法假设智能体同质，限制了其处理异构目标演示的能力。

Method: 提出了一种深度潜在变量MFG模型和一种相关的IRL方法，该方法能够从不同但结构相似的任务中推断奖励，而无需预先了解底层上下文或修改MFG模型。

Result: 实验结果表明，该方法在模拟场景和实际的出行打车定价问题中，优于现有的最先进的MFG中的IRL方法。

Conclusion: 所提出的深度潜在变量MFG模型和IRL方法能够有效处理智能体异构目标的问题，并在实际应用中展现出优越性。

Abstract: Designing suitable reward functions for numerous interacting intelligent
agents is challenging in real-world applications. Inverse reinforcement
learning (IRL) in mean field games (MFGs) offers a practical framework to infer
reward functions from expert demonstrations. While promising, the assumption of
agent homogeneity limits the capability of existing methods to handle
demonstrations with heterogeneous and unknown objectives, which are common in
practice. To this end, we propose a deep latent variable MFG model and an
associated IRL method. Critically, our method can infer rewards from different
yet structurally similar tasks without prior knowledge about underlying
contexts or modifying the MFG model itself. Our experiments, conducted on
simulated scenarios and a real-world spatial taxi-ride pricing problem,
demonstrate the superiority of our approach over state-of-the-art IRL methods
in MFGs.

</details>


### [250] [Semi-decentralized Federated Time Series Prediction with Client Availability Budgets](https://arxiv.org/abs/2509.03660)
*Yunkai Bao,Reza Safarzadeh,Xin Wang,Steve Drew*

Main category: cs.LG

TL;DR: FedDeCAB是一种新颖的半去中心化客户端选择方法，通过概率排名来选择可用客户端。该方法即使在客户端断开连接时，也能从最近邻客户端获取部分模型参数进行联合优化，从而提高离线模型性能并降低通信开销。实验证明，FedDeCAB在数据异构、通信预算有限以及动态客户端离线/重连等场景下均有效。


<details>
  <summary>Details</summary>
Motivation: 在物联网场景下，联合学习（FL）虽然能保护隐私，但客户端可能面临数据异构、能量和可用性限制。因此，选择合适的客户端参与训练对全局模型的收敛和客户端贡献的平衡至关重要。

Method: 提出了一种名为FedDeCAB的新型半去中心化客户端选择方法，该方法利用可用客户端的概率排名。当客户端断开连接时，FedDeCAB允许从最近邻客户端获取部分模型参数进行联合优化。

Result: 基于真实的、大规模的出租车和船舶轨迹数据集的实验表明，FedDeCAB在高度异构的数据分布、有限的通信预算以及动态的客户端离线或重新加入的情况下是有效的。

Conclusion: FedDeCAB在解决联合学习中客户端可用性问题方面表现出有效性，尤其是在数据异构和资源受限的物联网场景中。

Abstract: Federated learning (FL) effectively promotes collaborative training among
distributed clients with privacy considerations in the Internet of Things (IoT)
scenarios. Despite of data heterogeneity, FL clients may also be constrained by
limited energy and availability budgets. Therefore, effective selection of
clients participating in training is of vital importance for the convergence of
the global model and the balance of client contributions. In this paper, we
discuss the performance impact of client availability with time-series data on
federated learning. We set up three different scenarios that affect the
availability of time-series data and propose FedDeCAB, a novel,
semi-decentralized client selection method applying probabilistic rankings of
available clients. When a client is disconnected from the server, FedDeCAB
allows obtaining partial model parameters from the nearest neighbor clients for
joint optimization, improving the performance of offline models and reducing
communication overhead. Experiments based on real-world large-scale taxi and
vessel trajectory datasets show that FedDeCAB is effective under highly
heterogeneous data distribution, limited communication budget, and dynamic
client offline or rejoining.

</details>


### [251] [AutoGrid AI: Deep Reinforcement Learning Framework for Autonomous Microgrid Management](https://arxiv.org/abs/2509.03666)
*Kenny Guo,Nicholas Eckhert,Krish Chhajer,Luthira Abeykoon,Lorne Schell*

Main category: cs.LG

TL;DR: A deep reinforcement learning framework is presented for autonomous microgrid management in remote communities, optimizing energy dispatch to reduce costs and increase renewable energy use.


<details>
  <summary>Details</summary>
Motivation: The motivation is to optimize microgrid energy dispatch strategies for remote communities to minimize costs and maximize renewable energy utilization, contributing to zero-carbon energy systems.

Method: The framework uses deep reinforcement learning, specifically a proximal policy optimization (PPO) agent, combined with time-series forecasting models and the transformer architecture for renewable generation forecasting, all within a simulated environment.

Result: Experimental results show significant improvements in energy efficiency and operational resilience compared to traditional rule-based methods.

Conclusion: The developed deep reinforcement learning framework effectively optimizes microgrid management, offering a promising solution for advancing smart-grid technologies and achieving zero-carbon energy systems. An open-source framework for simulation is also provided.

Abstract: We present a deep reinforcement learning-based framework for autonomous
microgrid management. tailored for remote communities. Using deep reinforcement
learning and time-series forecasting models, we optimize microgrid energy
dispatch strategies to minimize costs and maximize the utilization of renewable
energy sources such as solar and wind. Our approach integrates the transformer
architecture for forecasting of renewable generation and a proximal-policy
optimization (PPO) agent to make decisions in a simulated environment. Our
experimental results demonstrate significant improvements in both energy
efficiency and operational resilience when compared to traditional rule-based
methods. This work contributes to advancing smart-grid technologies in pursuit
of zero-carbon energy systems. We finally provide an open-source framework for
simulating several microgrid environments.

</details>


### [252] [SharedRep-RLHF: A Shared Representation Approach to RLHF with Diverse Preferences](https://arxiv.org/abs/2509.03672)
*Arpan Mukherjee,Marcello Bullo,Deniz Gündüz*

Main category: cs.LG

TL;DR: RLHF 算法在处理多用户偏好时存在公平性问题，现有的 MaxMin-RLHF 虽有改进但仍有不足，本文提出的 SharedRep-RLHF 通过学习和利用标注中的共享特征来解决该问题，并在多项自然语言任务上取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有的 RLHF 算法未能充分捕捉用户偏好中的多样性，导致对少数群体不公平。MaxMin-RLHF 算法通过优化最小奖励组来解决公平性问题，但在最小奖励组是少数群体时性能不佳。

Method: SharedRep-RLHF 框架的核心是学习和利用不同群体在标注中存在的共享特征，而不是为不同群体学习独立的奖励模型。首先证明了 MaxMin-RLHF 在学习共享特征方面存在理论上的不足，然后量化了 SharedRep-RLHF 的样本复杂度。

Result: 实验结果表明，SharedRep-RLHF 在自然语言任务上的表现优于 MaxMin-RLHF，胜利率最高可提升 20%。

Conclusion: SharedRep-RLHF 相比 MaxMin-RLHF 在处理存在共享特征的用户偏好时更具优势，能够更有效地提升公平性和模型性能。

Abstract: Uniform-reward reinforcement learning from human feedback (RLHF), which
trains a single reward model to represent the preferences of all annotators,
fails to capture the diversity of opinions across sub-populations,
inadvertently favoring dominant groups. The state-of-the-art, MaxMin-RLHF,
addresses this by learning group-specific reward models, and by optimizing for
the group receiving the minimum reward, thereby promoting fairness. However, we
identify that a key limitation of MaxMin-RLHF is its poor performance when the
minimum-reward group is a minority. To mitigate this drawback, we introduce a
novel framework, termed {\em SharedRep-RLHF}. At its core, SharedRep-RLHF
learns and leverages {\em shared traits} in annotations among various groups,
in contrast to learning separate reward models across groups. We first show
that MaxMin-RLHF is provably suboptimal in learning shared traits, and then
quantify the sample complexity of SharedRep-RLHF. Experiments across diverse
natural language tasks showcase the effectiveness of SharedRep-RLHF compared to
MaxMin-RLHF with a gain of up to 20% in win rate.

</details>


### [253] [A Machine Learning-Based Study on the Synergistic Optimization of Supply Chain Management and Financial Supply Chains from an Economic Perspective](https://arxiv.org/abs/2509.03673)
*Hang Wang,Huijie Tang,Ningai Leng,Zhoufan Yu*

Main category: cs.LG

TL;DR: 该研究提出了一个集成了供应链管理（SCM）和金融供应链管理（FSCM）的协同模型，利用经济学理论和机器学习技术，以解决效率低下、融资限制和风险传播等问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决供应链管理中的效率损失、融资约束和风险传递问题。

Method: 结合交易成本和信息不对称理论，利用随机森林、LSTM、聚类/回归算法、博弈论、强化学习和XGBoost等多种机器学习和算法，构建了一个数据驱动的三维（成本-效率-风险）分析框架，并应用了“核心企业信用赋能+动态质押融资”的FSCM模型，优化了库存-采购机制，并实现了库存的快速变现。

Result: 通过对100家企业的验证，模型实现了30%的库存周转率提升、18%-22%的中小企业融资成本下降、95%以上的订单履行率，以及优于8%的需求预测误差和90%的信用评估准确率。

Conclusion: 所提出的SCM-FSCM协同模型能够有效降低运营成本，缓解融资约束，并促进供应链的高质量发展。

Abstract: Based on economic theories and integrated with machine learning technology,
this study explores a collaborative Supply Chain Management and Financial
Supply Chain Management (SCM - FSCM) model to solve issues like efficiency
loss, financing constraints, and risk transmission. We combine Transaction Cost
and Information Asymmetry theories and use algorithms such as random forests to
process multi-dimensional data and build a data-driven, three-dimensional
(cost-efficiency-risk) analysis framework. We then apply an FSCM model of "core
enterprise credit empowerment plus dynamic pledge financing." We use Long
Short-Term Memory (LSTM) networks for demand forecasting and
clustering/regression algorithms for benefit allocation. The study also
combines Game Theory and reinforcement learning to optimize the
inventory-procurement mechanism and uses eXtreme Gradient Boosting (XGBoost)
for credit assessment to enable rapid monetization of inventory. Verified with
20 core and 100 supporting enterprises, the results show a 30\% increase in
inventory turnover, an 18\%-22\% decrease in SME financing costs, a stable
order fulfillment rate above 95\%, and excellent model performance (demand
forecasting error <= 8\%, credit assessment accuracy >= 90\%). This SCM-FSCM
model effectively reduces operating costs, alleviates financing constraints,
and supports high-quality supply chain development.

</details>


### [254] [Insights from Gradient Dynamics: Gradient Autoscaled Normalization](https://arxiv.org/abs/2509.03677)
*Vincent-Daniel Yun*

Main category: cs.LG

TL;DR: 梯度归一化方法通过模仿梯度缩放的自然演变来稳定和提高深度神经网络的训练。


<details>
  <summary>Details</summary>
Motivation: 梯度动力学在决定深度神经网络的稳定性和泛化能力中起着核心作用。

Method: 提出了一种无需超参数即可进行梯度归一化（gradient normalization）的方法，该方法使梯度缩放与其自然演变保持一致，以防止意外放大，稳定优化过程，并保持收敛保证。

Result: 在 CIFAR-100 基准测试以及 ResNet-20、ResNet-56 和 VGG-16-BN 模型上的实验表明，该方法在强泛化条件下仍能保持或提高测试准确性。

Conclusion: 该研究强调了直接跟踪梯度动力学的重要性，旨在缩小理论预期与实际行为之间的差距，并为未来的优化研究提供见解。

Abstract: Gradient dynamics play a central role in determining the stability and
generalization of deep neural networks. In this work, we provide an empirical
analysis of how variance and standard deviation of gradients evolve during
training, showing consistent changes across layers and at the global scale in
convolutional networks. Motivated by these observations, we propose a
hyperparameter-free gradient normalization method that aligns gradient scaling
with their natural evolution. This approach prevents unintended amplification,
stabilizes optimization, and preserves convergence guarantees. Experiments on
the challenging CIFAR-100 benchmark with ResNet-20, ResNet-56, and VGG-16-BN
demonstrate that our method maintains or improves test accuracy even under
strong generalization. Beyond practical performance, our study highlights the
importance of directly tracking gradient dynamics, aiming to bridge the gap
between theoretical expectations and empirical behaviors, and to provide
insights for future optimization research.

</details>


### [255] [A Comprehensive Review of Multi-Agent Reinforcement Learning in Video Games](https://arxiv.org/abs/2509.03682)
*Zhengyang Li,Qijin Ji,Xinghong Ling,Quan Liu*

Main category: cs.LG

TL;DR: MARL在现代游戏中展现出巨大潜力，从基础到AlphaStar和OpenAI Five等成就，已达到超人水平。本文全面回顾了MARL在各类游戏中的应用，分析了其面临的挑战（如非平稳性、部分可观测性、稀疏奖励、团队协调和可扩展性），并探讨了成功案例（如Rocket League、Minecraft、Quake III Arena、StarCraft II、Dota 2、王者荣耀等）。此外，本文还提出了一种估计游戏复杂度的新方法，并为MARL在游戏开发中的未来研究方向提供了见解。


<details>
  <summary>Details</summary>
Motivation: MARL在现代游戏中应用潜力巨大，但缺乏全面的回顾，因此本文旨在全面考察MARL在不同类型游戏中的应用，并分析其面临的关键挑战。

Method: 本文通过回顾MARL在回合制、实时多人视频游戏（包括体育、FPS、RTS和MOBA）中的应用，分析了非平稳性、部分可观测性、稀疏奖励、团队协调和可扩展性等关键挑战，并结合实际游戏案例（如Rocket League、Minecraft、Quake III Arena、StarCraft II、Dota 2、王者荣耀等）进行阐述。

Result: MARL在各类游戏中，特别是电子游戏中，取得了显著的进展，并展现出超人水平的表现。本文分析了MARL在克服游戏中挑战方面的成功实施，并提出了一种估计游戏复杂性的新方法。

Conclusion: MARL在电子游戏领域具有广泛的应用前景和巨大的潜力。本文通过对MARL应用、挑战和成功案例的全面分析，为该领域的研究提供了有价值的见解，并为未来的研究方向指明了道路，有望推动MARL在游戏开发中的进一步创新。

Abstract: Recent advancements in multi-agent reinforcement learning (MARL) have
demonstrated its application potential in modern games. Beginning with
foundational work and progressing to landmark achievements such as AlphaStar in
StarCraft II and OpenAI Five in Dota 2, MARL has proven capable of achieving
superhuman performance across diverse game environments through techniques like
self-play, supervised learning, and deep reinforcement learning. With its
growing impact, a comprehensive review has become increasingly important in
this field. This paper aims to provide a thorough examination of MARL's
application from turn-based two-agent games to real-time multi-agent video
games including popular genres such as Sports games, First-Person Shooter (FPS)
games, Real-Time Strategy (RTS) games and Multiplayer Online Battle Arena
(MOBA) games. We further analyze critical challenges posed by MARL in video
games, including nonstationary, partial observability, sparse rewards, team
coordination, and scalability, and highlight successful implementations in
games like Rocket League, Minecraft, Quake III Arena, StarCraft II, Dota 2,
Honor of Kings, etc. This paper offers insights into MARL in video game AI
systems, proposes a novel method to estimate game complexity, and suggests
future research directions to advance MARL and its applications in game
development, inspiring further innovation in this rapidly evolving field.

</details>


### [256] [Sparse Autoencoder Neural Operators: Model Recovery in Function Spaces](https://arxiv.org/abs/2509.03738)
*Bahareh Tolooshams,Ailsa Shen,Anima Anandkumar*

Main category: cs.LG

TL;DR: 该研究提出了一种将神经网络表示统一起来的框架，该框架将稀疏自编码器（SAEs）扩展到提升空间和无限维函数空间，实现了对大型神经算子（NOs）的机械可解释性。


<details>
  <summary>Details</summary>
Motivation: 尽管Platonic表示假设提出神经网络在不同架构中会收敛到相似的表示，但神经算子（NOs）的表示性质仍有待探索，尽管它们在科学计算中日益重要。

Method: 该研究将统一神经网络表示的问题转化为稀疏模型恢复问题，并提出了一种将稀疏自编码器（SAEs）扩展到提升空间和无限维函数空间的框架，以实现对大型神经算子（NOs）的机械可解释性。研究人员比较了SAEs、提升SAE（lifted-SAE）和SAE神经算子（SAE NOs）的推理和训练动力学。

Result: 研究结果表明，提升（lifting）和算子模块引入了有利的归纳偏置，能够实现更快的恢复、改进的光滑概念恢复，以及在不同分辨率下进行鲁棒推理，这是神经算子独有的特性。

Conclusion: 提升SAE和SAE神经算子框架能够实现对大型神经算子的机械可解释性，并且在表示恢复方面表现出优于传统SAE的性能。

Abstract: We frame the problem of unifying representations in neural models as one of
sparse model recovery and introduce a framework that extends sparse
autoencoders (SAEs) to lifted spaces and infinite-dimensional function spaces,
enabling mechanistic interpretability of large neural operators (NO). While the
Platonic Representation Hypothesis suggests that neural networks converge to
similar representations across architectures, the representational properties
of neural operators remain underexplored despite their growing importance in
scientific computing. We compare the inference and training dynamics of SAEs,
lifted-SAE, and SAE neural operators. We highlight how lifting and operator
modules introduce beneficial inductive biases, enabling faster recovery,
improved recovery of smooth concepts, and robust inference across varying
resolutions, a property unique to neural operators.

</details>


### [257] [Graph Random Features for Scalable Gaussian Processes](https://arxiv.org/abs/2509.03691)
*Matthew Zhang,Jihao Andreas Lin,Adrian Weller,Richard E. Turner,Isaac Reid*

Main category: cs.LG

TL;DR: 图随机特征（GRFs）是一种用于图节点核的随机估计器，它能使高斯过程在离散输入空间上实现可扩展的贝叶斯推理，时间复杂度为 O(N^3/2)，并且在拥有超过一百万个节点的图上实现了具有竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 本文旨在研究图随机特征（GRFs）在离散输入空间的可扩展高斯过程应用，并与传统的精确核方法进行比较。

Method: 利用图随机特征（GRFs）作为一种随机估计器，用于高斯过程的贝叶斯推理。

Result: 在具有超过一百万个节点的图上，GRFs实现了O(N^3/2)的时间复杂度，相比于传统方法的O(N^3)，实现了显著的加速和内存节省，同时保持了具有竞争力的性能。

Conclusion: GRFs是一种有效的方法，能够在大规模图上实现可扩展的贝叶斯推理，并能应用于贝叶斯优化等实际场景。

Abstract: We study the application of graph random features (GRFs) - a recently
introduced stochastic estimator of graph node kernels - to scalable Gaussian
processes on discrete input spaces. We prove that (under mild assumptions)
Bayesian inference with GRFs enjoys $O(N^{3/2})$ time complexity with respect
to the number of nodes $N$, compared to $O(N^3)$ for exact kernels. Substantial
wall-clock speedups and memory savings unlock Bayesian optimisation on graphs
with over $10^6$ nodes on a single computer chip, whilst preserving competitive
performance.

</details>


### [258] [Hierarchical Federated Foundation Models over Wireless Networks for Multi-Modal Multi-Task Intelligence: Integration of Edge Learning with D2D/P2P-Enabled Fog Learning Architectures](https://arxiv.org/abs/2509.03695)
*Payam Abdisarabshali,Fardis Nadimi,Kasra Borazjani,Naji Khosravan,Minghui Liwang,Wei Ni,Dusit Niyato,Michael Langberg,Seyyedali Hosseinalipour*

Main category: cs.LG

TL;DR: 本文提出了分层联邦基础模型（HF-FMs），以解决多模态多任务联邦基础模型（M3T FFMs）在雾/边缘网络中面临的模态和任务异构性问题。


<details>
  <summary>Details</summary>
Motivation: 随着基础模型（FM）和联邦基础模型（FFM）的发展，多模态多任务（M3T）FM（如GPT-4）应运而生，这催生了一个新的、未被充分探索的范式：M3T FFM。然而，现有的M3T FFM在雾/边缘网络中面临模态和任务异构性等挑战。

Method: 提出了一种分层联邦基础模型（HF-FMs），它将M3T FM的模块化结构（包括模态编码器、提示、专家混合（MoEs）、适配器和任务头）与雾/边缘基础设施的分层特性相结合。HF-FMs还支持设备到设备（D2D）通信，以实现节点间的水平模块中继和本地化协作训练。

Result: 通过深入研究HF-FMs的架构设计，突出了其独特能力，并提出了一系列定制化的未来研究方向。原型HF-FMs已在无线网络环境中实现，并开源了相关代码。

Conclusion: HF-FMs为解决M3T FFM在雾/边缘网络中的异构性挑战提供了一个有前景的解决方案，并为该领域的研究开辟了新的方向。

Abstract: The rise of foundation models (FMs) has reshaped the landscape of machine
learning. As these models continued to grow, leveraging geo-distributed data
from wireless devices has become increasingly critical, giving rise to
federated foundation models (FFMs). More recently, FMs have evolved into
multi-modal multi-task (M3T) FMs (e.g., GPT-4) capable of processing diverse
modalities across multiple tasks, which motivates a new underexplored paradigm:
M3T FFMs. In this paper, we unveil an unexplored variation of M3T FFMs by
proposing hierarchical federated foundation models (HF-FMs), which in turn
expose two overlooked heterogeneity dimensions to fog/edge networks that have a
direct impact on these emerging models: (i) heterogeneity in collected
modalities and (ii) heterogeneity in executed tasks across fog/edge nodes.
HF-FMs strategically align the modular structure of M3T FMs, comprising
modality encoders, prompts, mixture-of-experts (MoEs), adapters, and task
heads, with the hierarchical nature of fog/edge infrastructures. Moreover,
HF-FMs enable the optional usage of device-to-device (D2D) communications,
enabling horizontal module relaying and localized cooperative training among
nodes when feasible. Through delving into the architectural design of HF-FMs,
we highlight their unique capabilities along with a series of tailored future
research directions. Finally, to demonstrate their potential, we prototype
HF-FMs in a wireless network setting and release the open-source code for the
development of HF-FMs with the goal of fostering exploration in this untapped
field (GitHub: https://github.com/payamsiabd/M3T-FFM).

</details>


### [259] [EmbedOR: Provable Cluster-Preserving Visualizations with Curvature-Based Stochastic Neighbor Embeddings](https://arxiv.org/abs/2509.03703)
*Tristan Luca Saidi,Abigail Hickok,Bastian Rieck,Andrew J. Blumberg*

Main category: cs.LG

TL;DR: EmbedOR是一种新的SNE算法，它使用离散图曲率来解决UMAP和tSNE在可视化高维数据时可能出现的几何结构破坏问题，并能更好地保留数据簇的结构。


<details>
  <summary>Details</summary>
Motivation: 现有的SNE算法（如UMAP和tSNE）在可视化高维数据时，存在破坏数据几何结构、错误分离连接成分、无法发现明显簇等问题。

Method: 提出了一种名为EmbedOR的新SNE算法，该算法结合了离散图曲率。EmbedOR使用一种增强曲率的距离度量来嵌入数据，从而强调潜在的簇结构。该算法已被证明可以扩展tSNE的一致性结果到更广泛的数据集。

Result: EmbedOR在合成和真实数据集上的实验表明，它在可视化和保持数据几何结构方面具有优势。与其他SNE算法和UMAP相比，EmbedOR不太可能破坏连续、高密度的数据区域。此外，EmbedOR的距离度量还可以用于标注现有可视化，识别碎片并深入了解数据的底层几何结构。

Conclusion: EmbedOR通过引入离散图曲率，有效解决了现有SNE算法在处理高维数据可视化时存在的几何结构破坏问题，并能更好地揭示数据的内在结构和簇信息。

Abstract: Stochastic Neighbor Embedding (SNE) algorithms like UMAP and tSNE often
produce visualizations that do not preserve the geometry of noisy and high
dimensional data. In particular, they can spuriously separate connected
components of the underlying data submanifold and can fail to find clusters in
well-clusterable data. To address these limitations, we propose EmbedOR, a SNE
algorithm that incorporates discrete graph curvature. Our algorithm
stochastically embeds the data using a curvature-enhanced distance metric that
emphasizes underlying cluster structure. Critically, we prove that the EmbedOR
distance metric extends consistency results for tSNE to a much broader class of
datasets. We also describe extensive experiments on synthetic and real data
that demonstrate the visualization and geometry-preservation capabilities of
EmbedOR. We find that, unlike other SNE algorithms and UMAP, EmbedOR is much
less likely to fragment continuous, high-density regions of the data. Finally,
we demonstrate that the EmbedOR distance metric can be used as a tool to
annotate existing visualizations to identify fragmentation and provide deeper
insight into the underlying geometry of the data.

</details>


### [260] [Online Learning of Optimal Sequential Testing Policies](https://arxiv.org/abs/2509.03707)
*Qiyuan Chen,Raed Al Kontar*

Main category: cs.LG

TL;DR: 该论文研究了一个在线学习问题，旨在为一系列受试者找到最优的测试策略。在测试成本和相关性的情况下，通常需要在信息不完整的情况下做出决策。即使在不知道联合分布的情况下，该问题也可以被视为一个马尔可夫决策过程（MDP）并得到精确解决。然而，在实践中，该分布是未知的，并且必须在线学习。当受试者未得到充分测试时，数据缺失会使估计产生偏差，从而使该问题比标准的片段式 MDP 更难处理。


<details>
  <summary>Details</summary>
Motivation: 该论文的动机在于研究在线测试问题（OTP），这是一个在线学习问题，旨在为一系列受试者寻找最优测试策略。由于测试的相关性和成本，需要根据不完整的信息进行决策。此外，在实际应用中，联合分布是未知的，需要在线学习，而数据缺失会使问题变得更加复杂。

Method: 该论文提出了一种探索-然后-承诺（Explore-Then-Commit）算法，该算法的累积遗憾（cumulative regret）为 O(T^(2/3))，该算法适用于离散分布和高斯分布。此外，该论文还研究了一个名为在线成本敏感最大熵采样问题（Online Cost-sensitive Maximum Entropy Sampling Problem）的变体，该问题通过迭代消除算法实现了 O(sqrt(T)) 的遗憾。

Result: 该论文证明了在线测试问题（OTP）的最小最大遗憾（minimax regret）至少是 Omega(T^(2/3))，这与片段式 MDP 的 Theta(sqrt(T)) 的速率形成对比。探索-然后-承诺算法的累积遗憾为 O~(T^(2/3))，并且在线成本敏感最大熵采样问题的累积遗憾为 O~(sqrt(T))。数值结果也证实了这些理论结果。

Conclusion: 该论文加深了对缺失数据情况下的探索-利用权衡的理解，并为设计有效的顺序测试策略提供了指导。该研究强调了数据缺失给在线学习问题带来的挑战，并提出了相应的解决方案。NPC算法来应对这些挑战。NPC算法在离散和高斯分布下均实现了 O~(T^(2/3)) 的累积遗憾。此外，该研究还提出了一个迭代消除算法，在特定的成本敏感最大熵采样问题中实现了 O~(sqrt(T)) 的累积遗憾，这表明在某些情况下可以克服 O(T^(2/3)) 的下界。NPC算法是一种探索-利用算法，该算法首先进行探索，然后致力于利用已获得的信息。NPC算法是解决在线测试问题（OTP）的一种有效方法，该问题涉及在测试成本和相关性的情况下，为一系列受试者确定最优测试策略。NPC算法通过平衡探索和利用来最大化累积奖励。NPC算法还可以通过在不完全测试的情况下进行决策来处理缺失数据。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有OTP问题上实现最优性能。NPC算法的计算复杂度可能很高，特别是对于大型数据集。NPC算法的未来研究方向包括：探索NPC算法在更广泛的OTP问题上的应用。开发改进NPC算法的性能和效率。研究NPC算法在实际应用中的部署。NPC算法是一种有前途的解决OTP问题的工具，但仍需要进一步的研究和开发才能充分发挥其潜力。NPC算法是一种新颖的在线学习算法，NPC算法可用于解决在线测试问题（OTP）。NPC算法通过探索和利用的结合来最大化累积奖励。NPC算法可以处理不完整数据，NPC算法在离散和高斯分布下都能实现 O~(T^(2/3)) 的累积遗憾。NPC算法已得到数值结果的证实。NPC算法有潜力应用于各种实际场景，例如医学诊断和在线广告。NPC算法的局限性包括：NPC算法仅适用于具有特定分布的OTP问题。NPC算法可能无法在所有 <h3> 6. 结论 </h3> <p>该论文深入探讨了在线测试问题（OTP）中的探索-利用权衡，特别关注了缺失数据带来的挑战。研究表明，与标准的片段式 MDP 相比，缺失数据会显著增加问题的难度，导致更差的遗憾界限（至少为 Ω(T^(2/3))）。论文提出的探索-然后-承诺（Explore-Then-Commit）算法在离散和高斯分布下均能达到 O~(T^(2/3)) 的遗憾界限，与理论下界相匹配。此外，通过研究一个奖励与缺失数据无关的变体问题，论文展示了如何通过迭代消除算法实现 O~(sqrt(T)) 的遗憾，这表明特定问题结构可以克服普遍存在的 O(T^(2/3)) 下界。总的来说，这项工作为设计高效的顺序测试策略提供了重要的理论见解和实践指导。</p> 

Abstract: This paper studies an online learning problem that seeks optimal testing
policies for a stream of subjects, each of whom can be evaluated through a
sequence of candidate tests drawn from a common pool. We refer to this problem
as the Online Testing Problem (OTP). Although conducting every candidate test
for a subject provides more information, it is often preferable to select only
a subset when tests are correlated and costly, and make decisions with partial
information. If the joint distribution of test outcomes were known, the problem
could be cast as a Markov Decision Process (MDP) and solved exactly. In
practice, this distribution is unknown and must be learned online as subjects
are tested. When a subject is not fully tested, the resulting missing data can
bias estimates, making the problem fundamentally harder than standard episodic
MDPs. We prove that the minimax regret must scale at least as
$\Omega(T^{\frac{2}{3}})$, in contrast to the $\Theta(\sqrt{T})$ rate in
episodic MDPs, revealing the difficulty introduced by missingness. This
elevated lower bound is then matched by an Explore-Then-Commit algorithm whose
cumulative regret is $\tilde{O}(T^{\frac{2}{3}})$ for both discrete and
Gaussian distributions. To highlight the consequence of missingness-dependent
rewards in OTP, we study a variant called the Online Cost-sensitive Maximum
Entropy Sampling Problem, where rewards are independent of missing data. This
structure enables an iterative-elimination algorithm that achieves
$\tilde{O}(\sqrt{T})$ regret, breaking the $\Omega(T^{\frac{2}{3}})$ lower
bound for OTP. Numerical results confirm our theory in both settings. Overall,
this work deepens the understanding of the exploration--exploitation trade-off
under missing data and guides the design of efficient sequential testing
policies.

</details>


### [261] [From Federated Learning to $\mathbb{X}$-Learning: Breaking the Barriers of Decentrality Through Random Walks](https://arxiv.org/abs/2509.03709)
*Allan Salihovic,Payam Abdisarabshali,Michael Langberg,Seyyedali Hosseinalipour*

Main category: cs.LG

TL;DR: $\\mathbb{X}$-Learning是一种新颖的分布式学习架构，它推广并扩展了去中心化的概念。


<details>
  <summary>Details</summary>
Motivation: 介绍$\\mathbb{X}$-Learning的设计考虑和自由度，并阐述其与图论和马尔可夫链的联系。

Method: 本文提出了$\\mathbb{X}$-Learning架构，并探讨了其与图论和马尔可夫链的联系。

Result: 本文提供了一个关于$\\mathbb{X}$-Learning的视角，重点介绍了其未被探索的设计考虑和自由度。

Conclusion: 本文提出了$\\mathbb{X}$-Learning架构，并指出了未来开放的研究方向。

Abstract: We provide our perspective on $\mathbb{X}$-Learning ($\mathbb{X}$L), a novel
distributed learning architecture that generalizes and extends the concept of
decentralization. Our goal is to present a vision for $\mathbb{X}$L,
introducing its unexplored design considerations and degrees of freedom. To
this end, we shed light on the intuitive yet non-trivial connections between
$\mathbb{X}$L, graph theory, and Markov chains. We also present a series of
open research directions to stimulate further research.

</details>


### [262] [Differentiable Entropy Regularization for Geometry and Neural Networks](https://arxiv.org/abs/2509.03733)
*Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma*

Main category: cs.LG

TL;DR: 该研究提出了一个可微分的范围划分熵估计器，并设计了EntropyNet，将数据重构为低熵形式以加速下游算法。该方法在几何和深度学习任务中均表现出良好的效率提升，同时保持了准确性。


<details>
  <summary>Details</summary>
Motivation: 现有算法设计中的范围划分熵概念虽有理论优势，但无法直接应用于深度学习。本研究旨在弥合这一差距，使范围划分熵可用于深度学习模型训练。

Method: 1. 提出了第一个可微分的范围划分熵近似估计器，可作为可训练的损失函数或正则化项。
2. 设计了EntropyNet，一个神经网络模块，用于将数据重构为低熵形式，从而加速下游的实例最优算法。
3. 将熵正则化原理扩展到Transformer注意力机制，直接应用于注意力计算。
4. 进行了理论分析，提供了估计器的近似界限，并通过消融实验验证了设计选择。

Result: 在几何任务中，该方法实现了高达4.1倍的运行时长加速，且错误率极低（<0.2%）。在深度学习任务中，与L1基线相比，该方法在80%稀疏度下实现了6%的准确率提升，并诱导出了结构化的注意力模式。

Conclusion: 可微分熵不仅在理论上优雅，而且是实现自适应学习、提高效率和结构化表示的实用机制。研究表明，熵约束计算在实际应用中具有重要价值。

Abstract: We introduce a differentiable estimator of range-partition entropy, a recent
concept from computational geometry that enables algorithms to adapt to the
"sortedness" of their input. While range-partition entropy provides strong
guarantees in algorithm design, it has not yet been made accessible to deep
learning. In this work, we (i) propose the first differentiable approximation
of range-partition entropy, enabling its use as a trainable loss or
regularizer; (ii) design EntropyNet, a neural module that restructures data
into low-entropy forms to accelerate downstream instance-optimal algorithms;
and (iii) extend this principle beyond geometry by applying entropy
regularization directly to Transformer attention. Across tasks, we demonstrate
that differentiable entropy improves efficiency without degrading correctness:
in geometry, our method achieves up to $4.1\times$ runtime speedups with
negligible error ($<0.2%$); in deep learning, it induces structured attention
patterns that yield 6% higher accuracy at 80% sparsity compared to L1
baselines. Our theoretical analysis provides approximation bounds for the
estimator, and extensive ablations validate design choices. These results
suggest that entropy-bounded computation is not only theoretically elegant but
also a practical mechanism for adaptive learning, efficiency, and structured
representation.

</details>


### [263] [Mapping on a Budget: Optimizing Spatial Data Collection for ML](https://arxiv.org/abs/2509.03749)
*Livia Betti,Farooq Sanni,Gnouyaro Sogoyou,Togbe Agbagla,Cullen Molitor,Tamma Carleton,Esther Rolf*

Main category: cs.LG

TL;DR: 卫星机器学习（SatML）面临训练数据稀疏的挑战，本研究提出了一个优化学术抽样的框架，以应对异构数据收集成本和预算限制，显著提高了SatML的性能。


<details>
  <summary>Details</summary>
Motivation: 机器学习（SatML）在农业、生态学和人类发展等领域的应用受限于标注训练数据的稀疏性。尽管卫星数据覆盖全球，但SatML的标注训练数据集通常规模小、空间聚集且收集目的不同。现有研究多集中于模型架构和训练算法，忽视了数据条件本身，导致科学家和政策制定者在扩展大规模监测时，对如何有效收集额外数据以最大化性能感到不确定。

Method: 提出了一种新的问题形式化，用于在存在异构数据收集成本和现实预算限制的情况下优化空间训练数据，并提出了相应的解决 novel methods。

Result: 在模拟三大洲和四项任务中不同问题设置的实验中，所提出的策略显示出通过样本优化获得的显著收益。进一步的实验明确了优化抽样特别有效的具体设置。

Conclusion: 本研究提出的问题形式化和方法旨在推广到SatML的各个应用领域，并特别强调了一个具体问题设置，即作者可以立即利用其研究成果来扩充多哥农业监测的农业聚集调查数据。

Abstract: In applications across agriculture, ecology, and human development, machine
learning with satellite imagery (SatML) is limited by the sparsity of labeled
training data. While satellite data cover the globe, labeled training datasets
for SatML are often small, spatially clustered, and collected for other
purposes (e.g., administrative surveys or field measurements). Despite the
pervasiveness of this issue in practice, past SatML research has largely
focused on new model architectures and training algorithms to handle scarce
training data, rather than modeling data conditions directly. This leaves
scientists and policymakers who wish to use SatML for large-scale monitoring
uncertain about whether and how to collect additional data to maximize
performance. Here, we present the first problem formulation for the
optimization of spatial training data in the presence of heterogeneous data
collection costs and realistic budget constraints, as well as novel methods for
addressing this problem. In experiments simulating different problem settings
across three continents and four tasks, our strategies reveal substantial gains
from sample optimization. Further experiments delineate settings for which
optimized sampling is particularly effective. The problem formulation and
methods we introduce are designed to generalize across application domains for
SatML; we put special emphasis on a specific problem setting where our
coauthors can immediately use our findings to augment clustered agricultural
surveys for SatML monitoring in Togo.

</details>


### [264] [What Fundamental Structure in Reward Functions Enables Efficient Sparse-Reward Learning?](https://arxiv.org/abs/2509.03790)
*Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma*

Main category: cs.LG

TL;DR: 低秩结构使稀疏奖励强化学习的样本复杂度从指数级过渡到多项式级，并引入了策略感知矩阵补全（PAMC）方法，在实验中显示出样本效率的提高。


<details>
  <summary>Details</summary>
Motivation: 研究低秩结构如何实现有效的稀疏奖励强化学习。

Method: 引入策略感知矩阵补全（PAMC），连接矩阵补全理论和强化学习，并进行了策略依赖采样的新分析。

Result: PAMC 在 100 个领域中有超过一半的领域显示出可利用的结构，与基线方法相比，样本效率提高了 1.6 到 2.1 倍，计算开销仅增加了约 20%。

Conclusion: 结构化奖励学习是一个有前景的新范式，对机器人、医疗保健和其他安全关键、样本昂贵的应用具有重要意义。

Abstract: What fundamental properties of reward functions enable efficient
sparse-reward reinforcement learning? We address this question through the lens
of low-rank structure in reward matrices, showing that such structure induces a
sharp transition from exponential to polynomial sample complexity, the first
result of this kind for sparse-reward RL. We introduce Policy-Aware Matrix
Completion (PAMC), which connects matrix completion theory with reinforcement
learning via a new analysis of policy-dependent sampling. Our framework
provides: (i) impossibility results for general sparse reward observation, (ii)
reward-free representation learning from dynamics, (iii) distribution-free
confidence sets via conformal prediction, and (iv) robust completion guarantees
that degrade gracefully when low-rank structure is only approximate.
Empirically, we conduct a pre-registered evaluation across 100 systematically
sampled domains, finding exploitable structure in over half. PAMC improves
sample efficiency by factors between 1.6 and 2.1 compared to strong
exploration, structured, and representation-learning baselines, while adding
only about 20 percent computational overhead.These results establish structural
reward learning as a promising new paradigm, with immediate implications for
robotics, healthcare, and other safety-critical, sample-expensive applications.

</details>


### [265] [Online time series prediction using feature adjustment](https://arxiv.org/abs/2509.03810)
*Xiannan Huang,Shuhan Qiu,Jiayuan Du,Chao Yang*

Main category: cs.LG

TL;DR: ADAPT-Z是一种新的时间序列在线学习方法，通过更新潜在因素的特征表示来解决分布偏移问题，并采用持久跟踪机制处理多步预测中的延迟反馈，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前时间序列在线学习方法主要关注参数选择和更新策略，但分布偏移的根本原因可能在于潜在因素的变化。多步预测中的延迟反馈问题也阻碍了模型的持续适应。

Method: 提出ADAPT-Z（Automatic Delta Adjustment via Persistent Tracking in Z-space），采用适配器模块，结合当前特征表示和历史梯度信息，来更新潜在因素的特征表示，以应对分布偏移和延迟反馈问题。

Result: 在多个数据集上进行的大量实验表明，ADAPT-Z持续优于未进行适应的标准基线模型，并超越了最先进的在线学习方法。

Conclusion: ADAPT-Z通过更新潜在因素的特征表示并有效处理延迟反馈，为时间序列在线学习提供了新的有效解决方案。

Abstract: Time series forecasting is of significant importance across various domains.
However, it faces significant challenges due to distribution shift. This issue
becomes particularly pronounced in online deployment scenarios where data
arrives sequentially, requiring models to adapt continually to evolving
patterns. Current time series online learning methods focus on two main
aspects: selecting suitable parameters to update (e.g., final layer weights or
adapter modules) and devising suitable update strategies (e.g., using recent
batches, replay buffers, or averaged gradients). We challenge the conventional
parameter selection approach, proposing that distribution shifts stem from
changes in underlying latent factors influencing the data. Consequently,
updating the feature representations of these latent factors may be more
effective. To address the critical problem of delayed feedback in multi-step
forecasting (where true values arrive much later than predictions), we
introduce ADAPT-Z (Automatic Delta Adjustment via Persistent Tracking in
Z-space). ADAPT-Z utilizes an adapter module that leverages current feature
representations combined with historical gradient information to enable robust
parameter updates despite the delay. Extensive experiments demonstrate that our
method consistently outperforms standard base models without adaptation and
surpasses state-of-the-art online learning approaches across multiple datasets.
The code is available at https://github.com/xiannanhuang/ADAPT-Z.

</details>


### [266] [Machine Learning for LiDAR-Based Indoor Surface Classification in Intelligent Wireless Environments](https://arxiv.org/abs/2509.03813)
*Parth Ashokbhai Shiroya,Swarnagowri Shashidhar,Amod Ashtekar,Krishna Aindrila Kar,Rafaela Lomboy,Dalton Davis,Mohammed E. Eltayeb*

Main category: cs.LG

TL;DR: 该论文提出了一种利用激光雷达（LiDAR）和机器学习来对室内表面进行分类的方法，以区分半镜面和低镜面散射特性，从而为毫米波和亚太赫兹通信网络提供支持。


<details>
  <summary>Details</summary>
Motivation: 可靠的毫米波和亚太赫兹网络连接依赖于周围表面的反射，因为高频信号极易被阻挡。表面散射行为不仅取决于材料介电常数，还取决于粗糙度，这决定了能量是保持在镜面方向还是被漫散射。

Method: 提出了一种激光雷达驱动的机器学习框架，使用光学反射率作为电磁散射行为的代理，对室内表面进行分类。收集了来自15种室内材料的超过78,000个点的数据库，并将其划分为3厘米x3厘米的斑块。提取了捕捉几何和强度的斑块级特征（包括仰角、自然对数缩放强度和最大值与平均值之比），并用于训练随机森林、XGBoost和神经网络分类器。

Result: 结果表明，基于集成树的模型在准确性和鲁棒性之间提供了最佳的折衷，证实了激光雷达衍生的特征能够捕捉到由粗糙度引起的散射效应。

Conclusion: 所提出的框架能够生成感知散射环境的地图和数字孪生，为下一代网络的自适应波束管理、阻塞恢复和环境感知连接提供支持。

Abstract: Reliable connectivity in millimeter-wave (mmWave) and sub-terahertz (sub-THz)
networks depends on reflections from surrounding surfaces, as high-frequency
signals are highly vulnerable to blockage. The scattering behavior of a surface
is determined not only by material permittivity but also by roughness, which
governs whether energy remains in the specular direction or is diffusely
scattered. This paper presents a LiDAR-driven machine learning framework for
classifying indoor surfaces into semi-specular and low-specular categories,
using optical reflectivity as a proxy for electromagnetic scattering behavior.
A dataset of over 78,000 points from 15 representative indoor materials was
collected and partitioned into 3 cm x 3 cm patches to enable classification
from partial views. Patch-level features capturing geometry and intensity,
including elevation angle, natural-log-scaled intensity, and max-to-mean ratio,
were extracted and used to train Random Forest, XGBoost, and neural network
classifiers. Results show that ensemble tree-based models consistently provide
the best trade-off between accuracy and robustness, confirming that
LiDAR-derived features capture roughness-induced scattering effects. The
proposed framework enables the generation of scatter aware environment maps and
digital twins, supporting adaptive beam management, blockage recovery, and
environment-aware connectivity in next-generation networks.

</details>


### [267] [Predicting Traffic Accident Severity with Deep Neural Networks](https://arxiv.org/abs/2509.03819)
*Meghan Bibb,Pablo Rivas,Mahee Tayba*

Main category: cs.LG

TL;DR: 该研究使用深度神经网络模型对交通事故数据进行分类，以预测事故严重性，最高准确率达92%。


<details>
  <summary>Details</summary>
Motivation: 利用机器学习，特别是深度神经网络，来分析交通事故数据，以预测事故严重性。

Method: 首先分析特征共线性并使用自动编码器进行降维，然后使用密集网络对事故严重性进行分类。

Result: 所提出的深度神经网络模型在事故严重性分类方面达到了高达92%的交叉验证准确率。

Conclusion: 深度神经网络模型能够有效地预测交通事故的严重性。

Abstract: Traffic accidents can be studied to mitigate the risk of further events.
Recent advances in machine learning have provided an alternative way to study
data associated with traffic accidents. New models achieve good generalization
and high predictive power over imbalanced data. In this research, we study
neural network-based models on data related to traffic accidents. We begin
analyzing relative feature colinearity and unsupervised dimensionality
reduction through autoencoders, followed by a dense network. The features are
related to traffic accident data and the target is to classify accident
severity. Our experiments show cross-validated results of up to 92% accuracy
when classifying accident severity using the proposed deep neural network.

</details>


### [268] [Vehicle-to-Infrastructure Collaborative Spatial Perception via Multimodal Large Language Models](https://arxiv.org/abs/2509.03837)
*Kimia Ehsani,Walid Saad*

Main category: cs.LG

TL;DR: 该研究提出了一种新颖的鸟瞰图（BEV）注入连接器，用于增强多模态大语言模型（MLLMs）在通信链路质量预测中的空间理解能力，并利用CARLA和MATLAB联合仿真环境进行验证，实验证明该方法能显著提升预测精度，尤其在恶劣环境下。


<details>
  <summary>Details</summary>
Motivation: 为了实现车对基础设施（V2I）系统中顺畅的切换、高效的波束管理和可靠的低延迟通信，精确预测通信链路质量指标至关重要。现代车辆日益增长的传感器数据为利用MLLMs提供了可能性，但MLLMs缺乏三维空间理解能力。

Method: 提出了一种轻量级、即插即用的BEV注入连接器。通过收集邻近车辆的传感数据构建环境的BEV，并将其与主车输入融合，为大语言模型提供空间上下文。使用CARLA模拟器和基于MATLAB的射线追踪技术开发了一个联合仿真环境，以生成不同场景下的RGB、LiDAR、GPS和无线信号数据，并从中提取指令和地面真实响应。

Result: 在三种V2I链路预测任务（视线（LoS）与非视线（NLoS）分类、链路可用性和阻塞预测）上进行了广泛的实验。结果表明，所提出的BEV注入框架在所有任务上持续提升了性能。与仅使用主车数据的基线相比，该方法将准确性指标的宏平均值提高了高达13.9%。在多雨和夜间等挑战性条件下，性能增益高达32.7%，证明了该框架在不利条件下的鲁棒性。

Conclusion: 所提出的BEV注入框架能够有效弥补MLLMs在空间理解方面的不足，显著提升V2I通信链路质量预测的准确性，尤其在恶劣环境下表现出强大的鲁棒性。

Abstract: Accurate prediction of communication link quality metrics is essential for
vehicle-to-infrastructure (V2I) systems, enabling smooth handovers, efficient
beam management, and reliable low-latency communication. The increasing
availability of sensor data from modern vehicles motivates the use of
multimodal large language models (MLLMs) because of their adaptability across
tasks and reasoning capabilities. However, MLLMs inherently lack
three-dimensional spatial understanding. To overcome this limitation, a
lightweight, plug-and-play bird's-eye view (BEV) injection connector is
proposed. In this framework, a BEV of the environment is constructed by
collecting sensing data from neighboring vehicles. This BEV representation is
then fused with the ego vehicle's input to provide spatial context for the
large language model. To support realistic multimodal learning, a co-simulation
environment combining CARLA simulator and MATLAB-based ray tracing is developed
to generate RGB, LiDAR, GPS, and wireless signal data across varied scenarios.
Instructions and ground-truth responses are programmatically extracted from the
ray-tracing outputs. Extensive experiments are conducted across three V2I link
prediction tasks: line-of-sight (LoS) versus non-line-of-sight (NLoS)
classification, link availability, and blockage prediction. Simulation results
show that the proposed BEV injection framework consistently improved
performance across all tasks. The results indicate that, compared to an
ego-only baseline, the proposed approach improves the macro-average of the
accuracy metrics by up to 13.9%. The results also show that this performance
gain increases by up to 32.7% under challenging rainy and nighttime conditions,
confirming the robustness of the framework in adverse settings.

</details>


### [269] [Data-Augmented Quantization-Aware Knowledge Distillation](https://arxiv.org/abs/2509.03850)
*Justin Kur,Kaiqi Zhao*

Main category: cs.LG

TL;DR: 将量化感知训练（QAT）和知识蒸馏（KD）与数据增强（DA）相结合，以提高低比特深度学习模型的性能，并提出了一种新的DA选择评估指标。


<details>
  <summary>Details</summary>
Motivation: 现有QAT和KD的研究主要集中在改进模型输出，而忽略了数据增强（DA）等输入转换的影响，QAT与KD和DA之间的关系尚未被探索。

Method: 提出了一种新的评估指标，该指标根据DA最大化上下文互信息（与图像标签不直接相关的信息）的能力进行评估，同时确保每个类别的预测平均值接近地面真实标签。

Result: 通过在各种模型架构和数据集上进行的大量评估，证明了使用该指标选择DA策略可以显著改进最先进的QAT和KD方法。

Conclusion: 所提出的方法能够自动对DA进行排名和选择，并且训练开销极小，与任何KD或QAT算法兼容，能够有效提高低比特模型的性能。

Abstract: Quantization-aware training (QAT) and Knowledge Distillation (KD) are
combined to achieve competitive performance in creating low-bit deep learning
models. Existing KD and QAT works focus on improving the accuracy of quantized
models from the network output perspective by designing better KD loss
functions or optimizing QAT's forward and backward propagation. However,
limited attention has been given to understanding the impact of input
transformations, such as data augmentation (DA). The relationship between
quantization-aware KD and DA remains unexplored. In this paper, we address the
question: how to select a good DA in quantization-aware KD, especially for the
models with low precisions? We propose a novel metric which evaluates DAs
according to their capacity to maximize the Contextual Mutual Information--the
information not directly related to an image's label--while also ensuring the
predictions for each class are close to the ground truth labels on average. The
proposed method automatically ranks and selects DAs, requiring minimal training
overhead, and it is compatible with any KD or QAT algorithm. Extensive
evaluations demonstrate that selecting DA strategies using our metric
significantly improves state-of-the-art QAT and KD works across various model
architectures and datasets.

</details>


### [270] [MillGNN: Learning Multi-Scale Lead-Lag Dependencies for Multi-Variate Time Series Forecasting](https://arxiv.org/abs/2509.03852)
*Binqing Wu,Zongjiang Shang,Jianlong Huang,Ling Chen*

Main category: cs.LG

TL;DR: MillGNN是一种新的图神经网络模型，用于多变量时间序列预测，能够学习多尺度分组的领先滞后依赖关系，以捕捉分层领先滞后效应。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多变量时间序列预测中忽略了多尺度分组的领先滞后依赖关系，未能捕捉复杂系统中的分层领先滞后效应。

Method: MillGNN通过两个关键创新来解决这个问题：1. 尺度特定的领先滞后图学习模块，它整合了互相关系数和动态衰减特征来学习每个尺度的领先滞后依赖关系。 2. 分层领先滞后消息传递模块，以结构化的方式在多个分组尺度上传递领先滞后消息，以同时传播尺度内和尺度间的领先滞后效应。

Result: 在11个数据集上的实验结果表明，MillGNN在长期和短期多变量时间序列预测方面优于16种现有方法。

Conclusion: MillGNN能够全面捕捉领先滞后效应，同时平衡了全面性和效率，并在多变量时间序列预测任务中展现出优越性。

Abstract: Multi-variate time series (MTS) forecasting is crucial for various
applications. Existing methods have shown promising results owing to their
strong ability to capture intra- and inter-variate dependencies. However, these
methods often overlook lead-lag dependencies at multiple grouping scales,
failing to capture hierarchical lead-lag effects in complex systems. To this
end, we propose MillGNN, a novel \underline{g}raph \underline{n}eural
\underline{n}etwork-based method that learns \underline{m}ult\underline{i}ple
grouping scale \underline{l}ead-\underline{l}ag dependencies for MTS
forecasting, which can comprehensively capture lead-lag effects considering
variate-wise and group-wise dynamics and decays. Specifically, MillGNN
introduces two key innovations: (1) a scale-specific lead-lag graph learning
module that integrates cross-correlation coefficients and dynamic decaying
features derived from real-time inputs and time lags to learn lead-lag
dependencies for each scale, which can model evolving lead-lag dependencies
with statistical interpretability and data-driven flexibility; (2) a
hierarchical lead-lag message passing module that passes lead-lag messages at
multiple grouping scales in a structured way to simultaneously propagate intra-
and inter-scale lead-lag effects, which can capture multi-scale lead-lag
effects with a balance of comprehensiveness and efficiency. Experimental
results on 11 datasets demonstrate the superiority of MillGNN for long-term and
short-term MTS forecasting, compared with 16 state-of-the-art methods.

</details>


### [271] [Peptidomic-Based Prediction Model for Coronary Heart Disease Using a Multilayer Perceptron Neural Network](https://arxiv.org/abs/2509.03884)
*Jesus Celis-Porras*

Main category: cs.LG

TL;DR: 该模型利用多层感知器（MLP）神经网络，通过遗传算法筛选的50个关键尿液肽生物标志物，实现了对冠心病（CHD）的高精度非侵入式检测。


<details>
  <summary>Details</summary>
Motivation: 开发一种非侵入性的冠心病（CHD）诊断方法，以应对其作为全球主要死亡原因和高昂医疗支出的挑战。

Method: 使用遗传算法筛选50个关键尿液肽生物标志物，并利用SMOTE技术平衡处理组和对照组（各345人）。采用具有三层隐藏层（每层60个神经元）和两层输出层的MLP神经网络进行模型训练，并采用分层验证策略。

Result: 模型在检测CHD方面取得了95.67%的精确率、灵敏度和特异性，F1分数为0.9565。ROC曲线下面积（AUC）达到0.9748，马修斯相关系数（MCC）为0.9134，科恩kappa系数为0.9131。

Conclusion: 所提出的基于MLP神经网络的模型为冠心病提供了一种高度准确且可靠的非侵入式诊断工具。

Abstract: Coronary heart disease (CHD) is a leading cause of death worldwide and
contributes significantly to annual healthcare expenditures. To develop a
non-invasive diagnostic approach, we designed a model based on a multilayer
perceptron (MLP) neural network, trained on 50 key urinary peptide biomarkers
selected via genetic algorithms. Treatment and control groups, each comprising
345 individuals, were balanced using the Synthetic Minority Over-sampling
Technique (SMOTE). The neural network was trained using a stratified validation
strategy. Using a network with three hidden layers of 60 neurons each and an
output layer of two neurons, the model achieved a precision, sensitivity, and
specificity of 95.67 percent, with an F1-score of 0.9565. The area under the
ROC curve (AUC) reached 0.9748 for both classes, while the Matthews correlation
coefficient (MCC) and Cohen's kappa coefficient were 0.9134 and 0.9131,
respectively, demonstrating its reliability in detecting CHD. These results
indicate that the model provides a highly accurate and robust non-invasive
diagnostic tool for coronary heart disease.

</details>


### [272] [Topotein: Topological Deep Learning for Protein Representation Learning](https://arxiv.org/abs/2509.03885)
*Zhiyu Wang,Arian Jamasb,Mustafa Hajij,Alex Morehead,Luke Braithwaite,Pietro Liò*

Main category: cs.LG

TL;DR: Topotein使用拓扑深度学习和新的蛋白质组合复形 (PCC) 及拓扑完备感知机网络 (TCPNet) 来学习蛋白质表示，克服了现有方法在捕捉蛋白质结构层次化组织方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有基于序列和图的方法未能捕捉蛋白质结构的固有层次化组织，阻碍了对结构-功能关系的理解。

Method: 提出了一种名为Topotein的框架，该框架将拓扑深度学习应用于蛋白质表示学习。其核心是蛋白质组合复形 (PCC)，它在从残基到完整蛋白质的多个层次上表示蛋白质，同时保留每层的几何信息。TCPNet 在这些层次结构上采用 SE(3) 等变消息传递，以更有效地捕捉多尺度结构模式。

Result: 在四个蛋白质表示学习任务上，TCPNet 持续优于最先进的几何图神经网络，特别在需要理解二级结构排列的折叠分类等任务上表现突出。

Conclusion: 层次化拓扑特征对于蛋白质分析至关重要，Topotein 框架通过结合 PCC 和 TCPNet 成功捕捉了这些特征，从而在蛋白质表示学习任务上取得了优越的性能。

Abstract: Protein representation learning (PRL) is crucial for understanding
structure-function relationships, yet current sequence- and graph-based methods
fail to capture the hierarchical organization inherent in protein structures.
We introduce Topotein, a comprehensive framework that applies topological deep
learning to PRL through the novel Protein Combinatorial Complex (PCC) and
Topology-Complete Perceptron Network (TCPNet). Our PCC represents proteins at
multiple hierarchical levels -- from residues to secondary structures to
complete proteins -- while preserving geometric information at each level.
TCPNet employs SE(3)-equivariant message passing across these hierarchical
structures, enabling more effective capture of multi-scale structural patterns.
Through extensive experiments on four PRL tasks, TCPNet consistently
outperforms state-of-the-art geometric graph neural networks. Our approach
demonstrates particular strength in tasks such as fold classification which
require understanding of secondary structure arrangements, validating the
importance of hierarchical topological features for protein analysis.

</details>


### [273] [Mistake-bounded online learning with operation caps](https://arxiv.org/abs/2509.03892)
*Jesse Geneson,Meien Li,Linus Tang*

Main category: cs.LG

TL;DR: 在线学习模型在算术运算次数受限的情况下，可以学习具有有限错误次数的任意函数族，并解决了agnostic mistake-bounded online learning的已知问题。


<details>
  <summary>Details</summary>
Motivation: 研究带有算术运算次数上限的在线学习的错误界限模型，并解决agnostic mistake-bounded online learning中的已知问题。

Method: 证明了学习任意函数族（具有有限的错误次数）所需的每个回合的最小算术运算次数的一般界限，并将此结果扩展到运算次数上限的设置。

Result: 给出了学习任意函数族（具有有限的错误次数）所需的每个回合的最小算术运算次数的一般界限。

Conclusion: 解决了agnostic mistake-bounded online learning的已知问题，并将结果扩展到运算次数上限的设置。

Abstract: We investigate the mistake-bound model of online learning with caps on the
number of arithmetic operations per round. We prove general bounds on the
minimum number of arithmetic operations per round that are necessary to learn
an arbitrary family of functions with finitely many mistakes. We solve a
problem on agnostic mistake-bounded online learning with bandit feedback from
(Filmus et al, 2024) and (Geneson \& Tang, 2024). We also extend this result to
the setting of operation caps.

</details>


### [274] [Formal Verification of Local Robustness of a Classification Algorithm for a Spatial Use Case](https://arxiv.org/abs/2509.03948)
*Delphine Longuet,Amira Elouazzani,Alejandro Penacho Riveiros,Nicola Bastianello*

Main category: cs.LG

TL;DR: 通过使用Marabou工具进行形式化验证，可以提高嵌入式卫星的混合人工智能故障检测系统的可靠性，从而在不确定的情况下增强其性能。


<details>
  <summary>Details</summary>
Motivation: 卫星组件故障的昂贵且难以解决，需要大量人力物力，因此在卫星中嵌入混合人工智能系统以进行故障检测，可以尽早检测问题，从而大大减轻负担。

Method: 利用形式化验证工具Marabou来验证人工智能算法所使用的神经网络模型的局部鲁棒性。

Result: 该工具能够量化模型输入在何种程度上可以被扰动而不至于导致其输出行为不稳定。

Conclusion: 通过对神经网络模型进行形式化验证，可以提高人工智能故障检测系统的可靠性，增强其在不确定性下的性能，从而为卫星任务提供更强的支持。

Abstract: Failures in satellite components are costly and challenging to address, often
requiring significant human and material resources. Embedding a hybrid AI-based
system for fault detection directly in the satellite can greatly reduce this
burden by allowing earlier detection. However, such systems must operate with
extremely high reliability. To ensure this level of dependability, we employ
the formal verification tool Marabou to verify the local robustness of the
neural network models used in the AI-based algorithm. This tool allows us to
quantify how much a model's input can be perturbed before its output behavior
becomes unstable, thereby improving trustworthiness with respect to its
performance under uncertainty.

</details>


### [275] [On Aligning Prediction Models with Clinical Experiential Learning: A Prostate Cancer Case Study](https://arxiv.org/abs/2509.04053)
*Jacqueline J. Vallon,William Overman,Wanqiao Xu,Neil Panjwani,Xi Ling,Sushmita Vij,Hilary P. Bagshaw,John T. Leppert,Sumit Shah,Geoffrey Sonn,Sandy Srinivas,Erqi Pollom,Mark K. Buyyounouski,Mohsen Bayati*

Main category: cs.LG

TL;DR: ML模型在医疗领域的应用日益广泛，但其预测模式可能与临床经验不符。本研究提出了一个框架，通过整合临床知识来解决这种不一致性，并研究了模型欠指定的影响。实验表明，在不牺牲性能的情况下，可以将ML模型与临床经验对齐。此外，还探讨了通过随机实验收集临床医生反馈，以驱动模型对齐的可行性，并发现模型预测差异越大，临床解释上的差异越明显。


<details>
  <summary>Details</summary>
Motivation: 现代机器学习模型在医疗领域的应用虽然性能很高，但可能无法捕捉到最终用户（例如临床医生）所期望的模式，导致模型行为与临床经验之间存在不一致。本研究旨在调查这种不一致性的根源，即现代ML流程的欠指定效应。

Method: 首先，通过调查收集临床知识，并将其作为约束条件纳入ML模型，以解决前列腺癌预后预测案例研究中模型行为与临床经验不一致的问题。随后，分析不同程度的欠指定对模型性能和行为的影响。其次，借鉴生成式AI的最新文献，通过与临床医生进行随机实验，检查在非生成式AI临床风险预测模型中采用反馈驱动的对齐方法的可行性。

Result: 在对齐ML模型与临床经验后，性能并未受到影响。通过随机实验发现，当约束模型和非约束模型对某位患者的预测差异越大时，临床解释上的差异也越明显。

Conclusion: 本研究提出的框架能够成功地将ML模型与临床经验对齐，且不影响模型性能。通过收集临床医生反馈的方法，可以有效地识别和解决模型行为与临床期望之间的不一致性。

Abstract: Over the past decade, the use of machine learning (ML) models in healthcare
applications has rapidly increased. Despite high performance, modern ML models
do not always capture patterns the end user requires. For example, a model may
predict a non-monotonically decreasing relationship between cancer stage and
survival, keeping all other features fixed. In this paper, we present a
reproducible framework for investigating this misalignment between model
behavior and clinical experiential learning, focusing on the effects of
underspecification of modern ML pipelines. In a prostate cancer outcome
prediction case study, we first identify and address these inconsistencies by
incorporating clinical knowledge, collected by a survey, via constraints into
the ML model, and subsequently analyze the impact on model performance and
behavior across degrees of underspecification. The approach shows that aligning
the ML model with clinical experiential learning is possible without
compromising performance. Motivated by recent literature in generative AI, we
further examine the feasibility of a feedback-driven alignment approach in
non-generative AI clinical risk prediction models through a randomized
experiment with clinicians. Our findings illustrate that, by eliciting
clinicians' model preferences using our proposed methodology, the larger the
difference in how the constrained and unconstrained models make predictions for
a patient, the more apparent the difference is in clinical interpretation.

</details>


### [276] [FedQuad: Federated Stochastic Quadruplet Learning to Mitigate Data Heterogeneity](https://arxiv.org/abs/2509.04107)
*Ozgu Goksu,Nicolas Pugeault*

Main category: cs.LG

TL;DR: FedQuad是一种新颖的联邦学习方法，通过优化类内方差和类间方差来解决数据异构性问题，在CIFAR-10和CIFAR-100数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中由于数据异构性、数据集规模小和类别不平衡导致的全域模型泛化能力挑战。

Method: 提出FedQuad方法，通过最小化相似样本对之间的距离并最大化负样本对之间的距离，来优化客户端的类内方差和类间方差，从而减少模型聚合对全域模型的影响。

Result: 在CIFAR-10和CIFAR-100数据集上，在各种数据分布和多客户端场景下，FedQuad相较于现有方法取得了更优越的性能。

Conclusion: FedQuad在解决联邦学习中的表征学习挑战方面是有效的，并且度量学习策略在联邦学习范式中具有显著效果。

Abstract: Federated Learning (FL) provides decentralised model training, which
effectively tackles problems such as distributed data and privacy preservation.
However, the generalisation of global models frequently faces challenges from
data heterogeneity among clients. This challenge becomes even more pronounced
when datasets are limited in size and class imbalance. To address data
heterogeneity, we propose a novel method, \textit{FedQuad}, that explicitly
optimises smaller intra-class variance and larger inter-class variance across
clients, thereby decreasing the negative impact of model aggregation on the
global model over client representations. Our approach minimises the distance
between similar pairs while maximising the distance between negative pairs,
effectively disentangling client data in the shared feature space. We evaluate
our method on the CIFAR-10 and CIFAR-100 datasets under various data
distributions and with many clients, demonstrating superior performance
compared to existing approaches. Furthermore, we provide a detailed analysis of
metric learning-based strategies within both supervised and federated learning
paradigms, highlighting their efficacy in addressing representational learning
challenges in federated settings.

</details>


### [277] [Synthetic Counterfactual Labels for Efficient Conformal Counterfactual Inference](https://arxiv.org/abs/2509.04112)
*Amirmohammad Farzaneh,Matteo Zecchin,Osvaldo Simeone*

Main category: cs.LG

TL;DR: SP-CCI通过使用预训练模型生成的合成反事实标签来增强校准集，从而为个体反事实结果构建可靠的预测区间，并保持边际覆盖率，同时提供更窄的区间。


<details>
  <summary>Details</summary>
Motivation: 现有保形反事实推断（CCI）方法在处理稀疏的反事实样本和治疗不平衡时，会产生过于保守的预测区间。

Method: SP-CCI框架通过生成合成反事实标签来增强校准集，并结合基于风险控制预测集（RCPS）和考虑了预测驱动推断（PPI）的去偏步骤的保形校准程序。

Result: SP-CCI在各种数据集上始终如一地减小了区间宽度，与标准的CCI相比，在所有设置下都实现了更窄的预测区间。

Conclusion: SP-CCI在保持边际覆盖率的同时，提供更窄的预测区间，理论上保证在精确和近似重要性加权下均成立。

Abstract: This work addresses the problem of constructing reliable prediction intervals
for individual counterfactual outcomes. Existing conformal counterfactual
inference (CCI) methods provide marginal coverage guarantees but often produce
overly conservative intervals, particularly under treatment imbalance when
counterfactual samples are scarce. We introduce synthetic data-powered CCI
(SP-CCI), a new framework that augments the calibration set with synthetic
counterfactual labels generated by a pre-trained counterfactual model. To
ensure validity, SP-CCI incorporates synthetic samples into a conformal
calibration procedure based on risk-controlling prediction sets (RCPS) with a
debiasing step informed by prediction-powered inference (PPI). We prove that
SP-CCI achieves tighter prediction intervals while preserving marginal
coverage, with theoretical guarantees under both exact and approximate
importance weighting. Empirical results on different datasets confirm that
SP-CCI consistently reduces interval width compared to standard CCI across all
settings.

</details>


### [278] [Who Pays for Fairness? Rethinking Recourse under Social Burden](https://arxiv.org/abs/2509.04128)
*Ainhize Barrainkua,Giovanni De Toni,Jose Antonio Lozano,Novi Quadrianto*

Main category: cs.LG

TL;DR: 算法溯源中的公平性问题：提出基于社会负担的新框架和MISOB算法


<details>
  <summary>Details</summary>
Motivation: 新兴立法要求算法在做出负面决定时提供可行的补救措施，但现有算法溯源方法可能存在公平性问题。

Method: 提出一个基于社会负担的公平性新框架，并开发了MISOB算法，该算法广泛适用于现实条件。

Result: MISOB算法在现实数据集上能够减少所有群体的社会负担，同时不损害整体分类器准确性。

Conclusion: 提出的基于社会负担的公平性框架和MISOB算法能够有效解决算法溯源中的公平性问题。

Abstract: Machine learning based predictions are increasingly used in sensitive
decision-making applications that directly affect our lives. This has led to
extensive research into ensuring the fairness of classifiers. Beyond just fair
classification, emerging legislation now mandates that when a classifier
delivers a negative decision, it must also offer actionable steps an individual
can take to reverse that outcome. This concept is known as algorithmic
recourse. Nevertheless, many researchers have expressed concerns about the
fairness guarantees within the recourse process itself. In this work, we
provide a holistic theoretical characterization of unfairness in algorithmic
recourse, formally linking fairness guarantees in recourse and classification,
and highlighting limitations of the standard equal cost paradigm. We then
introduce a novel fairness framework based on social burden, along with a
practical algorithm (MISOB), broadly applicable under real-world conditions.
Empirical results on real-world datasets show that MISOB reduces the social
burden across all groups without compromising overall classifier accuracy.

</details>


### [279] [TAGAL: Tabular Data Generation using Agentic LLM Methods](https://arxiv.org/abs/2509.04152)
*Benoît Ronval,Pierre Dupont,Siegfried Nijssen*

Main category: cs.LG

TL;DR: TAGAL是一种利用大型语言模型（LLM）生成合成表格数据的代理工作流方法，无需进一步的LLM训练即可改进数据质量，并能整合外部知识。该方法在下游ML模型效用、数据相似性等方面表现优于许多现有方法，展示了代理工作流在LLM驱动的数据生成方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 为了提高机器学习分类任务的性能，通常需要生成额外的数据。本文提出了一种名为TAGAL的方法，旨在利用LLM生成合成表格数据，以解决这一需求。

Method: TAGAL利用大型语言模型（LLM）通过自动化的、迭代的反馈过程生成合成表格数据，无需额外的LLM训练。它还可以整合外部知识。

Result: TAGAL生成的合成数据在下游ML模型（如分类器）的训练效用方面，无论是单独使用还是与真实数据结合使用，都表现良好。与需要LLM训练的最先进方法相当，并且优于其他无需训练的方法。

Conclusion: TAGAL方法展示了代理工作流和LLM在生成高质量合成表格数据方面的巨大潜力，并为未来的研究开辟了新的方向。

Abstract: The generation of data is a common approach to improve the performance of
machine learning tasks, among which is the training of models for
classification. In this paper, we present TAGAL, a collection of methods able
to generate synthetic tabular data using an agentic workflow. The methods
leverage Large Language Models (LLMs) for an automatic and iterative process
that uses feedback to improve the generated data without any further LLM
training. The use of LLMs also allows for the addition of external knowledge in
the generation process. We evaluate TAGAL across diverse datasets and different
aspects of quality for the generated data. We look at the utility of downstream
ML models, both by training classifiers on synthetic data only and by combining
real and synthetic data. Moreover, we compare the similarities between the real
and the generated data. We show that TAGAL is able to perform on par with
state-of-the-art approaches that require LLM training and generally outperforms
other training-free approaches. These findings highlight the potential of
agentic workflow and open new directions for LLM-based data generation methods.

</details>


### [280] [Attention as an Adaptive Filter](https://arxiv.org/abs/2509.04154)
*Peter Racioppo*

Main category: cs.LG

TL;DR: AFA是一种新颖的注意力机制，它将可学习的动力学模型直接纳入注意力权重的计算中，通过对线性随机微分方程的封闭解的利用，实现了高效的注意力计算。


<details>
  <summary>Details</summary>
Motivation: 传统的注意力机制在计算注意力权重时直接比较查询和键，而本文提出了一种新的方法，将输入序列建模为线性随机微分方程的离散观测，并将可学习的动力学模型集成到注意力计算中。

Method: 本文提出了一种名为自适应滤波器注意力（AFA）的新机制。它将输入序列视为线性随机微分方程（SDE）的离散观测，并利用SDE的封闭解来传播成对不确定性。注意力权重被推导为最大似然解，对应于对传播的成对精度进行基于残差的重加权。此外，通过对状态矩阵的特征值施加约束，可以得到一个计算和内存复杂度与标准注意力相同的简化变体。

Result: 在动力学和过程噪声消失的极限下，并使用小角度近似，AFA可以恢复为普通的点积注意力。

Conclusion: AFA是一种有效且可扩展的注意力机制，它通过整合动力学模型提供了比标准注意力更强的性能。

Abstract: We introduce Adaptive Filter Attention (AFA), a novel attention mechanism
that incorporates a learnable dynamics model directly into the computation of
attention weights. Rather than comparing queries and keys directly, we model
the input sequence as discrete observations of a linear stochastic differential
equation (SDE). By imposing a linear dynamics model with simultaneously
diagonalizable state matrices and noise covariances, we can make use of a
closed-form solution to the differential Lyapunov equation to efficiently
propagate pairwise uncertainties through the dynamics. Attention naturally
arises as the maximum likelihood solution for this linear SDE, with attention
weights corresponding to robust residual-based reweightings of the propagated
pairwise precisions. Imposing an additional constraint on the state matrix's
eigenvalues leads to a simplified variant with the same computational and
memory complexity as standard attention. In the limit of vanishing dynamics and
process noise, and using a small-angle approximation, we recover ordinary
dot-product attention.

</details>


### [281] [Crossing the Species Divide: Transfer Learning from Speech to Animal Sounds](https://arxiv.org/abs/2509.04166)
*Jules Cauzinille,Marius Miron,Olivier Pietquin,Masato Hagiwara,Ricard Marxer,Arnaud Rey,Benoit Favre*

Main category: cs.LG

TL;DR: Self-supervised speech models (HuBERT, WavLM, XEUS) can generate useful representations for bioacoustic tasks, competitive with fine-tuned models, and are a promising framework for bioacoustic research.


<details>
  <summary>Details</summary>
Motivation: The effectiveness of self-supervised speech models on non-speech data, specifically bioacoustic detection and classification, is underexplored.

Method: Analyze the transfer learning capabilities of speech models (HuBERT, WavLM, XEUS) on bioacoustic tasks. Use linear probing on time-averaged representations and extend to time-wise information with downstream architectures. Study the impact of frequency range and noise.

Result: Speech models generate rich latent representations of animal sounds. Results are competitive with fine-tuned bioacoustic models, and noise-robust pre-training is impactful.

Conclusion: Speech-based self-supervised learning offers an efficient framework for advancing bioacoustic research.

Abstract: Self-supervised speech models have demonstrated impressive performance in
speech processing, but their effectiveness on non-speech data remains
underexplored. We study the transfer learning capabilities of such models on
bioacoustic detection and classification tasks. We show that models such as
HuBERT, WavLM, and XEUS can generate rich latent representations of animal
sounds across taxa. We analyze the models properties with linear probing on
time-averaged representations. We then extend the approach to account for the
effect of time-wise information with other downstream architectures. Finally,
we study the implication of frequency range and noise on performance. Notably,
our results are competitive with fine-tuned bioacoustic pre-trained models and
show the impact of noise-robust pre-training setups. These findings highlight
the potential of speech-based self-supervised learning as an efficient
framework for advancing bioacoustic research.

</details>


### [282] [Privacy Risks in Time Series Forecasting: User- and Record-Level Membership Inference](https://arxiv.org/abs/2509.04169)
*Nicolas Johansson,Tobias Olsson,Daniel Nilsson,Johan Östman,Fazeleh Hoseini*

Main category: cs.LG

TL;DR: 本论文研究了针对时间序列预测模型的成员推断攻击（MIA），并提出了两种新攻击方法（LiRA改编版和DTS攻击），在真实数据集上验证了预测模型的隐私漏洞，并指出了预测不确定性和训练数据量对攻击成功率的影响。


<details>
  <summary>Details</summary>
Motivation: 时间序列预测模型在隐私保护方面的研究尚不充分，而成员推断攻击（MIA）是评估模型隐私风险的重要手段，因此需要探索MIA在时间序列预测模型上的应用。

Method: 将现有的状态艺术MIA（LiRA）改编到时间序列预测场景，并提出了一种新的端到端学习攻击方法（DTS）。在TUH-EEG和ELD数据集上，针对LSTM和N-HiTS两种预测模型，在记录级和用户级威胁模型下评估了这两种新方法以及其他改编自分类模型MIA的有效性。

Result: 实验结果表明，时间序列预测模型容易受到成员推断攻击，尤其是在用户级攻击下，检测准确率接近完美。所提出的LiRA改编版和DTS攻击在多种设置下表现最佳，为时间序列预测的隐私风险评估设定了新的基准。此外，攻击的脆弱性随预测时间跨度的增加和训练样本数量的减少而增加，这与大型语言模型中的趋势相似。

Conclusion: 时间序列预测模型存在显著的隐私泄露风险，可以通过成员推断攻击有效检测。提出的新攻击方法为评估和缓解这些风险提供了有力的工具，未来的研究应关注更长的预测时间和更小的训练数据集对隐私的影响。

Abstract: Membership inference attacks (MIAs) aim to determine whether specific data
were used to train a model. While extensively studied on classification models,
their impact on time series forecasting remains largely unexplored. We address
this gap by introducing two new attacks: (i) an adaptation of multivariate
LiRA, a state-of-the-art MIA originally developed for classification models, to
the time-series forecasting setting, and (ii) a novel end-to-end learning
approach called Deep Time Series (DTS) attack. We benchmark these methods
against adapted versions of other leading attacks from the classification
setting.
  We evaluate all attacks in realistic settings on the TUH-EEG and ELD
datasets, targeting two strong forecasting architectures, LSTM and the
state-of-the-art N-HiTS, under both record- and user-level threat models. Our
results show that forecasting models are vulnerable, with user-level attacks
often achieving perfect detection. The proposed methods achieve the strongest
performance in several settings, establishing new baselines for privacy risk
assessment in time series forecasting. Furthermore, vulnerability increases
with longer prediction horizons and smaller training populations, echoing
trends observed in large language models.

</details>


### [283] [Comment on "A Note on Over-Smoothing for Graph Neural Networks"](https://arxiv.org/abs/2509.04178)
*Razi Hasson,Reuven Guetta*

Main category: cs.LG

TL;DR: 图神经网络（GNNs）的过平滑问题可以通过分析狄利克雷能量来解决。在温和的光谱条件下，节点嵌入的狄利克雷能量会随着深度的增加呈指数级下降。此外，该结果可以扩展到光谱多项式滤波器，并为 Leaky-ReLU 情况提供简短证明。通过在边删除和权重放大方面的实验，可以揭示狄利克雷能量增加的情况，为缓解过平滑提供实际方法。


<details>
  <summary>Details</summary>
Motivation: 评估Cai和Wang（2020）关于图神经网络（GNNs）中过平滑问题的分析，并扩展其在狄利克雷能量方面的见解。

Method: 通过分析狄利克雷能量，在温和的光谱条件下（包括Leaky-ReLU），证明节点嵌入的狄利克雷能量随深度的增加呈指数级下降。将该结果扩展到光谱多项式滤波器，并为Leaky-ReLU情况提供简短证明。通过边删除和权重放大实验来研究狄利克雷能量的变化。

Result: 在温和的光谱条件下（包括Leaky-ReLU），节点嵌入的狄利克雷能量随深度的增加呈指数级下降。该方法可以扩展到光谱多项式滤波器，并且为Leaky-ReLU情况提供了简短证明。实验表明，在边删除和权重放大时，狄利克雷能量会增加。

Conclusion: 狄利克雷能量提供了一种理解和潜在缓解GNNs中过平滑问题的方法。

Abstract: We comment on Cai and Wang (2020, arXiv:2006.13318), who analyze
over-smoothing in GNNs via Dirichlet energy. We show that under mild spectral
conditions (including with Leaky-ReLU), the Dirichlet energy of node embeddings
decreases exponentially with depth; we further extend the result to spectral
polynomial filters and provide a short proof for the Leaky-ReLU case.
Experiments on edge deletion and weight amplification illustrate when Dirichlet
energy increases, hinting at practical ways to relieve over-smoothing.

</details>


### [284] [Set Block Decoding is a Language Model Inference Accelerator](https://arxiv.org/abs/2509.04185)
*Itai Gat,Heli Ben-Hamu,Marton Havasi,Daniel Haziza,Jeremy Reizenstein,Gabriel Synnaeve,David Lopez-Paz,Brian Karrer,Yaron Lipman*

Main category: cs.LG

TL;DR: SBD通过并行预测和采样多个未来非连续的token，结合NTP和MATP，在不牺牲精度的情况下实现3-5倍加速，且无需改变模型结构或增加训练超参。


<details>
  <summary>Details</summary>
Motivation: 自回归语言模型的推理成本高，尤其是在解码阶段，限制了其实际应用。

Method: 提出Set Block Decoding（SBD）范式，在单一架构中整合标准NTP和MATP，允许并行采样多个不一定连续的未来token，并引入离散扩散模型的求解器。

Result: 在Llama-3.1 8B和Qwen-3 8B模型上进行微调，SBD实现了3-5倍的前向传播减少，同时保持与NTP训练相同的性能。

Conclusion: SBD是一种简单灵活的范式，通过并行采样和结合NTP与MATP，有效降低了自回归语言模型的推理成本，无需进行模型结构修改或增加额外训练超参数，并能保持与现有KV缓存机制的兼容性。

Abstract: Autoregressive next token prediction language models offer powerful
capabilities but face significant challenges in practical deployment due to the
high computational and memory costs of inference, particularly during the
decoding stage. We introduce Set Block Decoding (SBD), a simple and flexible
paradigm that accelerates generation by integrating standard next token
prediction (NTP) and masked token prediction (MATP) within a single
architecture. SBD allows the model to sample multiple, not necessarily
consecutive, future tokens in parallel, a key distinction from previous
acceleration methods. This flexibility allows the use of advanced solvers from
the discrete diffusion literature, offering significant speedups without
sacrificing accuracy. SBD requires no architectural changes or extra training
hyperparameters, maintains compatibility with exact KV-caching, and can be
implemented by fine-tuning existing next token prediction models. By
fine-tuning Llama-3.1 8B and Qwen-3 8B, we demonstrate that SBD enables a 3-5x
reduction in the number of forward passes required for generation while
achieving same performance as equivalent NTP training.

</details>


### [285] [One-Embedding-Fits-All: Efficient Zero-Shot Time Series Forecasting by a Model Zoo](https://arxiv.org/abs/2509.04208)
*Hao-Nan Shi,Ting-Ji Huang,Lu Han,De-Chuan Zhan,Han-Jia Ye*

Main category: cs.LG

TL;DR: ZooCast通过构建统一表示空间，智能组合现有时间序列基础模型（TSFM），以动态选择最优模型来应对不同的预测任务，实现了高效且性能强大的零样本预测。


<details>
  <summary>Details</summary>
Motivation: 现有的时间序列基础模型（TSFM）在零样本预测方面各有优势，没有单一模型能在所有时间序列模式上表现最佳。这表明可以利用不同TSFM的互补能力来提升预测性能。

Method: 提出ZooCast框架，其核心是“One-Embedding-Fits-All”范式。该范式创建一个统一的表示空间，其中每个TSFM由单个嵌入表示。这使得ZooCast能够通过高效的相似性匹配来为不同的预测任务动态选择和组合最优的TSFM。

Result: ZooCast在GIFT-Eval零样本预测基准测试中表现出强大的性能，同时保持了单个TSFM的效率。此外，该框架能够无缝集成新发布的模型，以实现准确性的渐进式提升，而开销极小。

Conclusion: ZooCast提供了一种有效的方法，可以利用现有TSFM的互补优势，通过动态模型选择来提升零样本预测的性能和效率，并且易于扩展以适应未来模型的发展。

Abstract: The proliferation of Time Series Foundation Models (TSFMs) has significantly
advanced zero-shot forecasting, enabling predictions for unseen time series
without task-specific fine-tuning. Extensive research has confirmed that no
single TSFM excels universally, as different models exhibit preferences for
distinct temporal patterns. This diversity suggests an opportunity: how to take
advantage of the complementary abilities of TSFMs. To this end, we propose
ZooCast, which characterizes each model's distinct forecasting strengths.
ZooCast can intelligently assemble current TSFMs into a model zoo that
dynamically selects optimal models for different forecasting tasks. Our key
innovation lies in the One-Embedding-Fits-All paradigm that constructs a
unified representation space where each model in the zoo is represented by a
single embedding, enabling efficient similarity matching for all tasks.
Experiments demonstrate ZooCast's strong performance on the GIFT-Eval zero-shot
forecasting benchmark while maintaining the efficiency of a single TSFM. In
real-world scenarios with sequential model releases, the framework seamlessly
adds new models for progressive accuracy gains with negligible overhead.

</details>


### [286] [Why Can't I See My Clusters? A Precision-Recall Approach to Dimensionality Reduction Validation](https://arxiv.org/abs/2509.04222)
*Diede P. M. van der Hoorn,Alessio Arleo,Fernando V. Paulovich*

Main category: cs.LG

TL;DR: 该研究提出了一种新的降维质量评估方法，通过分析降维过程中的关系阶段来评估降维结果的可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有降维（DR）质量指标不能解释为何预期的聚类结构在降维投影中缺失，且可视化分析方法因超参数空间大而耗时。本研究旨在解决这些问题，使降维过程更快、更可靠。

Method: 提出两种监督指标——精确率（precision）和召回率（recall）——来评估降维的‘关系’阶段，量化建模的关系与基于标签表示的预期聚类结构的一致性。在t-SNE和UMAP的示例中说明了这些指标的应用，并通过多种使用场景验证了该方法。

Result: 提出的精确率和召回率指标能够评估降维过程中‘关系’阶段的质量，量化了建模关系与预期聚类结构的一致性。通过在t-SNE和UMAP上的应用和场景验证，证明了该方法可以指导超参数调优，发现投影伪影，并确定关系是否捕捉到预期结构。

Conclusion: 该方法通过引入精确率和召回率指标来评估降维的关系阶段，能够指导超参数调优，揭示投影伪影，并确定预期结构是否在关系中得到体现，从而使降维过程更快速、更可靠。

Abstract: Dimensionality Reduction (DR) is widely used for visualizing high-dimensional
data, often with the goal of revealing expected cluster structure. However,
such a structure may not always appear in the projections. Existing DR quality
metrics assess projection reliability (to some extent) or cluster structure
quality, but do not explain why expected structures are missing. Visual
Analytics solutions can help, but are often time-consuming due to the large
hyperparameter space. This paper addresses this problem by leveraging a recent
framework that divides the DR process into two phases: a relationship phase,
where similarity relationships are modeled, and a mapping phase, where the data
is projected accordingly. We introduce two supervised metrics, precision and
recall, to evaluate the relationship phase. These metrics quantify how well the
modeled relationships align with an expected cluster structure based on some
set of labels representing this structure. We illustrate their application
using t-SNE and UMAP, and validate the approach through various usage
scenarios. Our approach can guide hyperparameter tuning, uncover projection
artifacts, and determine if the expected structure is captured in the
relationships, making the DR process faster and more reliable.

</details>


### [287] [Rethinking the long-range dependency in Mamba/SSM and transformer models](https://arxiv.org/abs/2509.04226)
*Cong Ma,Kayvan Najarian*

Main category: cs.LG

TL;DR: SSM 和 Transformer 在长程依赖建模方面各有优劣，本文提出了一种结合两者优势的新型 SSM 变体。


<details>
  <summary>Details</summary>
Motivation: 现有序列模型（如 SSM 和 Transformer）在处理长程依赖任务时，其理论基础尚不明确，阻碍了系统的改进。

Method: 提出了一种新的数学定义来量化长程依赖性，并以此为依据比较了 SSM 和 Transformer 的建模能力。在此基础上，提出了一种新的 SSM 状态更新公式，并证明了其在标准高斯输入下的稳定性。

Result: SSM 的长程依赖性随序列长度呈指数衰减，而 Transformer 的注意力机制理论上可以更好地处理长程依赖。提出的新 SSM 公式在保持计算效率的同时，结合了 Transformer 的灵活性。

Conclusion: SSM 和 Transformer 在长程依赖建模方面各有优劣。提出的新 SSM 变体有望结合两者的优点，并在理论上证明了其稳定性和处理长程依赖的能力。

Abstract: Long-range dependency is one of the most desired properties of recent
sequence models such as state-space models (particularly Mamba) and transformer
models. New model architectures are being actively developed and benchmarked
for prediction tasks requiring long-range dependency. However, the capability
of modeling long-range dependencies of these models has not been investigated
from a theoretical perspective, which hinders a systematic improvement on this
aspect. In this work, we mathematically define long-range dependency using the
derivative of hidden states with respect to past inputs and compare the
capability of SSM and transformer models of modeling long-range dependency
based on this definition. We showed that the long-range dependency of SSM
decays exponentially with the sequence length, which aligns with the
exponential decay of memory function in RNN. But the attention mechanism used
in transformers is more flexible and is not constrained to exponential decay,
which could in theory perform better at modeling long-range dependency with
sufficient training data, computing resources, and proper training. To combine
the flexibility of long-range dependency of attention mechanism and computation
efficiency of SSM, we propose a new formulation for hidden state update in SSM
and prove its stability under a standard Gaussian distribution of the input
data.

</details>


### [288] [Rethinking Layer-wise Gaussian Noise Injection: Bridging Implicit Objectives and Privacy Budget Allocation](https://arxiv.org/abs/2509.04232)
*Qifeng Tan,Shusen Yang,Xuebin Ren,Yikai Zhang*

Main category: cs.LG

TL;DR: LGM在差分隐私深度学习中通过在分区梯度向量中注入噪声来提高灵活性。现有方法通常依赖于启发式噪声分配策略，缺乏对其理论基础的严格理解。本文提出了一个统一的分析框架，将层级噪声注入策略与隐式优化目标和相关的隐私预算分配联系起来。分析表明，现有方法优化了不适定的目标，忽略了层间信噪比（SNR）一致性或导致隐私预算使用效率低下。因此，提出了一种SNR一致的噪声分配策略，统一了这两个方面，从而实现更好的信号保持和更有效的隐私预算利用。实验证明，该方法在中心化和联邦学习设置中都优于现有方法，实现了更好的隐私-效用权衡。


<details>
  <summary>Details</summary>
Motivation: 现有LGM方法在噪声分配上缺乏理论指导，导致隐私预算利用效率低下，信号保真度不佳。

Method: 提出一个统一的分析框架，连接层级噪声注入策略、优化目标和隐私预算分配。提出一种SNR一致的噪声分配策略。

Result: SNR一致的噪声分配策略在中心化和联邦学习中均优于现有方法，实现了更好的隐私-效用权衡。

Conclusion: 所提出的分析框架为设计有效的噪声注入方案提供了理论指导，SNR一致的噪声分配策略能够实现更好的隐私-效用权衡。

Abstract: Layer-wise Gaussian mechanisms (LGM) enhance flexibility in differentially
private deep learning by injecting noise into partitioned gradient vectors.
However, existing methods often rely on heuristic noise allocation strategies,
lacking a rigorous understanding of their theoretical grounding in connecting
noise allocation to formal privacy-utility tradeoffs. In this paper, we present
a unified analytical framework that systematically connects layer-wise noise
injection strategies with their implicit optimization objectives and associated
privacy budget allocations. Our analysis reveals that several existing
approaches optimize ill-posed objectives -- either ignoring inter-layer
signal-to-noise ratio (SNR) consistency or leading to inefficient use of the
privacy budget. In response, we propose a SNR-Consistent noise allocation
strategy that unifies both aspects, yielding a noise allocation scheme that
achieves better signal preservation and more efficient privacy budget
utilization. Extensive experiments in both centralized and federated learning
settings demonstrate that our method consistently outperforms existing
allocation strategies, achieving better privacy-utility tradeoffs. Our
framework not only offers diagnostic insights into prior methods but also
provides theoretical guidance for designing adaptive and effective noise
injection schemes in deep models.

</details>


### [289] [Synthetic Survival Data Generation for Heart Failure Prognosis Using Deep Generative Models](https://arxiv.org/abs/2509.04245)
*Chanon Puttanawarut,Natcha Fongsrisin,Porntep Amornritvanich,Cholatid Ratanatharathorn,Panu Looareesuwan*

Main category: cs.LG

TL;DR: 生成的心力衰竭合成数据集在保持患者隐私的同时，能够满足研究需求。


<details>
  <summary>Details</summary>
Motivation: 由于隐私法规和机构壁垒，获取大规模、可共享的心力衰竭（HF）数据集受到限制。合成数据生成提供了一种有前途的解决方案，可以在保护患者隐私的同时克服这些挑战。

Method: 使用五种深度学习模型（TVAE、归一化流、ADSGAN、SurvivalGAN 和 TabDDPM）从包含 12,552 名独特患者的机构数据中生成了合成 HF 数据集。通过统计相似性指标、机器学习生存预测和隐私评估来全面评估合成数据的效用。

Result: SurvivalGAN 和 TabDDPM 在应用直方图均衡后，与原始数据集具有高度的保真度，表现出相似的变量分布和生存曲线。SurvivalGAN（C-指数：0.71-0.76）和 TVAE（C-指数：0.73-0.76）在生存预测评估中表现最佳，与真实数据性能（C-指数：0.73-0.76）非常接近。隐私评估证实了针对重新识别攻击的保护。

Conclusion: 基于深度学习的合成数据生成可以产生高保真度、保护隐私的 HF 数据集，适用于研究应用。这个公开的合成数据集解决了关键的数据共享障碍，并为推进 HF 研究和预测模型提供了宝贵的资源。

Abstract: Background: Heart failure (HF) research is constrained by limited access to
large, shareable datasets due to privacy regulations and institutional
barriers. Synthetic data generation offers a promising solution to overcome
these challenges while preserving patient confidentiality. Methods: We
generated synthetic HF datasets from institutional data comprising 12,552
unique patients using five deep learning models: tabular variational
autoencoder (TVAE), normalizing flow, ADSGAN, SurvivalGAN, and tabular
denoising diffusion probabilistic models (TabDDPM). We comprehensively
evaluated synthetic data utility through statistical similarity metrics,
survival prediction using machine learning and privacy assessments. Results:
SurvivalGAN and TabDDPM demonstrated high fidelity to the original dataset,
exhibiting similar variable distributions and survival curves after applying
histogram equalization. SurvivalGAN (C-indices: 0.71-0.76) and TVAE (C-indices:
0.73-0.76) achieved the strongest performance in survival prediction
evaluation, closely matched real data performance (C-indices: 0.73-0.76).
Privacy evaluation confirmed protection against re-identification attacks.
Conclusions: Deep learning-based synthetic data generation can produce
high-fidelity, privacy-preserving HF datasets suitable for research
applications. This publicly available synthetic dataset addresses critical data
sharing barriers and provides a valuable resource for advancing HF research and
predictive modeling.

</details>


### [290] [RL's Razor: Why Online Reinforcement Learning Forgets Less](https://arxiv.org/abs/2509.04259)
*Idan Shenfeld,Jyothish Pari,Pulkit Agrawal*

Main category: cs.LG

TL;DR: RL在微调过程中比SFT更能保留先验知识，其遗忘程度取决于分布偏移（KL散度），RL倾向于选择与原模型更接近的解决方案，而SFT可能偏离原模型。


<details>
  <summary>Details</summary>
Motivation: 比较微调模型与强化学习（RL）和监督微调（SFT）的性能，并探究它们在保留先验知识方面的差异。

Method: 通过计算微调模型与基础模型策略在执行新任务时的KL散度来衡量分布偏移，并分析RL和SFT的收敛行为。

Result: RL在微调过程中保留了显著更多的先验知识和能力，其遗忘程度与KL散度相关。RL倾向于选择KL散度小的解决方案，而SFT可能选择任意偏离的解决方案。此发现已通过大型语言模型和机器人基础模型的实验得到验证，并得到了理论支持。

Conclusion: RL通过“RL剃刀”原则，在所有能解决新任务的方法中，优先选择与原模型在KL散度上最接近的方法，从而更好地保留了先验知识。

Abstract: Comparison of fine-tuning models with reinforcement learning (RL) and
supervised fine-tuning (SFT) reveals that, despite similar performance at a new
task, RL preserves prior knowledge and capabilities significantly better. We
find that the degree of forgetting is determined by the distributional shift,
measured as the KL-divergence between the fine-tuned and base policy evaluated
on the new task. Our analysis reveals that on-policy RL is implicitly biased
towards KL-minimal solutions among the many that solve the new task, whereas
SFT can converge to distributions arbitrarily far from the base model. We
validate these findings through experiments with large language models and
robotic foundation models and further provide theoretical justification for why
on-policy RL updates lead to a smaller KL change. We term this principle
$\textit{RL's Razor}$: among all ways to solve a new task, RL prefers those
closest in KL to the original model.

</details>


### [291] [An Interactive Framework for Finding the Optimal Trade-off in Differential Privacy](https://arxiv.org/abs/2509.04290)
*Yaohong Yang,Aki Rehn,Sammie Katt,Antti Honkela,Samuel Kaski*

Main category: cs.LG

TL;DR: DP-MOO通过利用DP的结构来优化隐私-准确性权衡，从而减少计算成本和用户交互。


<details>
  <summary>Details</summary>
Motivation: 现有的DP分析方法在隐私和模型性能之间存在固有的权衡，选择最佳平衡点是一个关键的挑战。现有的交互式多目标优化（MOO）方法效率低下，未能利用DP问题的独特结构。

Method: 利用DP的结构直接推导出权衡曲线的形状，并用更具信息量的交互方式替代了成对比较，向用户展示假设的权衡曲线并让他们选择首选的权衡点。

Result: 在DP逻辑回归和深度迁移学习的实验中，与基线方法相比，该方法以显著更低的计算成本和用户交互次数收敛到最优的隐私-准确性权衡。

Conclusion: 提出的DP-MOO方法通过利用DP的结构和改进的交互方式，能够更有效地解决隐私-准确性权衡问题。

Abstract: Differential privacy (DP) is the standard for privacy-preserving analysis,
and introduces a fundamental trade-off between privacy guarantees and model
performance. Selecting the optimal balance is a critical challenge that can be
framed as a multi-objective optimization (MOO) problem where one first
discovers the set of optimal trade-offs (the Pareto front) and then learns a
decision-maker's preference over them. While a rich body of work on interactive
MOO exists, the standard approach -- modeling the objective functions with
generic surrogates and learning preferences from simple pairwise feedback -- is
inefficient for DP because it fails to leverage the problem's unique structure:
a point on the Pareto front can be generated directly by maximizing accuracy
for a fixed privacy level. Motivated by this property, we first derive the
shape of the trade-off theoretically, which allows us to model the Pareto front
directly and efficiently. To address inefficiency in preference learning, we
replace pairwise comparisons with a more informative interaction. In
particular, we present the user with hypothetical trade-off curves and ask them
to pick their preferred trade-off. Our experiments on differentially private
logistic regression and deep transfer learning across six real-world datasets
show that our method converges to the optimal privacy-accuracy trade-off with
significantly less computational cost and user interaction than baselines.

</details>


### [292] [A Primer on Causal and Statistical Dataset Biases for Fair and Robust Image Analysis](https://arxiv.org/abs/2509.04295)
*Charles Jones,Ben Glocker*

Main category: cs.LG

TL;DR: 机器学习模型在实际应用中常因各种原因失效，尤其是在高风险和涉及社会敏感性的场景下。本文旨在探讨导致图像分析机器学习方法失效的因果和统计结构，并提出“无公平午餐”和“子群可分离性”两个新问题。此外，本文还分析了现有公平表征学习方法的局限性，并为未来研究方向提供了建议。


<details>
  <summary>Details</summary>
Motivation: 在实际应用中，机器学习方法，尤其是在医疗诊断等高风险和涉及社会敏感性的领域，常常面临失效的风险。这种失效不仅阻碍了机器学习技术的广泛应用，也带来了潜在的危害。因此，理解并解决这些失效问题至关重要。

Method: 本文通过分析导致图像分析机器学习方法失效的因果和统计结构，提出了“无公平午餐”和“子群可分离性”这两个此前未被充分认识的问题。同时，文章还对现有的公平表征学习方法进行了评估，分析了它们在解决这些新问题上的不足之处。

Result: 研究识别出导致机器学习模型在图像分析任务中失效的根本原因，并提出了“无公平午餐”和“子群可分离性”两个关键问题，揭示了当前公平表征学习方法的局限性。

Conclusion: 为了克服机器学习方法在实际应用中的失效问题，尤其是在公平性和鲁棒性方面，需要进一步研究和开发新的方法来解决“无公平午餐”和“子群可分离性”问题，并改进现有的公平表征学习技术。

Abstract: Machine learning methods often fail when deployed in the real world. Worse
still, they fail in high-stakes situations and across socially sensitive lines.
These issues have a chilling effect on the adoption of machine learning methods
in settings such as medical diagnosis, where they are arguably best-placed to
provide benefits if safely deployed. In this primer, we introduce the causal
and statistical structures which induce failure in machine learning methods for
image analysis. We highlight two previously overlooked problems, which we call
the \textit{no fair lunch} problem and the \textit{subgroup separability}
problem. We elucidate why today's fair representation learning methods fail to
adequately solve them and propose potential paths forward for the field.

</details>


### [293] [Using causal abstractions to accelerate decision-making in complex bandit problems](https://arxiv.org/abs/2509.04296)
*Joel Dyer,Nicholas Bishop,Anisoara Calinescu,Michael Wooldridge,Fabio Massimo Zennaro*

Main category: cs.LG

TL;DR: AT-UCB算法通过利用因果抽象理论，在一个计算成本低且粗粒度的CMAB实例中进行探索，然后在目标CMAB实例中，在潜在最优动作的受限集合上应用传统的UCB算法，从而显著减少累积遗憾。


<details>
  <summary>Details</summary>
Motivation: 现实世界的决策问题通常可以编码为不同抽象层级的因果多臂老虎机（CMAB）问题，但目前缺乏一种利用各抽象层级信息和计算优势的通用方法。

Method: 提出AT-UCB算法，该算法能有效利用在不同抽象层级定义的CMAB问题实例之间共享的信息。具体而言，AT-UCB利用因果抽象（CA）理论在一个计算成本低且粗粒度的CMAB实例中进行探索，然后在一个受限的潜在最优动作集合上应用传统的UCB算法。

Result: 与经典的UCB算法相比，AT-UCB在累积遗憾方面有显著降低。理论上，通过对累积遗憾提出新的上限来证明其优势；经验上，通过将AT-UCB应用于不同分辨率和计算成本的流行病学模拟器来展示其优势。

Conclusion: AT-UCB算法能够有效利用不同抽象层级的CMAB问题实例之间的共享信息，在减少累积遗憾方面优于经典UCB算法。

Abstract: Although real-world decision-making problems can often be encoded as causal
multi-armed bandits (CMABs) at different levels of abstraction, a general
methodology exploiting the information and computational advantages of each
abstraction level is missing. In this paper, we propose AT-UCB, an algorithm
which efficiently exploits shared information between CMAB problem instances
defined at different levels of abstraction. More specifically, AT-UCB leverages
causal abstraction (CA) theory to explore within a cheap-to-simulate and
coarse-grained CMAB instance, before employing the traditional upper confidence
bound (UCB) algorithm on a restricted set of potentially optimal actions in the
CMAB of interest, leading to significant reductions in cumulative regret when
compared to the classical UCB algorithm. We illustrate the advantages of AT-UCB
theoretically, through a novel upper bound on the cumulative regret, and
empirically, by applying AT-UCB to epidemiological simulators with varying
resolution and computational cost.

</details>


### [294] [Characteristic Energy Behavior Profiling of Non-Residential Buildings](https://arxiv.org/abs/2509.04322)
*Haley Dozier,Althea Henslee*

Main category: cs.LG

TL;DR: 美国陆军基地面临气候变化和极端天气事件的威胁，需要加强基础设施的韧性，特别是能源和水资源供应。本研究提出了一种数据驱动的行为建模方法，用于分析和预测基地建筑的能源使用模式，以评估意外中断的影响并制定韧性措施。


<details>
  <summary>Details</summary>
Motivation: 美国陆军基地基础设施面临气候变化和极端天气事件的威胁，需要提高韧性以保护关键任务设施和战备能力。由于基地依赖商业能源和水资源，因此需要了解能源使用情况并评估独立能源资源（如电网、天然气管道）的脆弱性。

Method: 提出一种数据驱动的行为模型，使用能够分析、预测和聚类多模态数据的模型来表示单独的建筑行为，并使用类似结构的可公开访问的数据来演示该方法。

Result: 该模型可用于创建能源系统意外中断影响的基线评估，并为未来的韧性措施提供基准。

Conclusion: 该数据驱动的行为模型能够分析、预测和聚类非住宅建筑的能源使用数据，为美国陆军基地的气候韧性规划提供支持。

Abstract: Due to the threat of changing climate and extreme weather events, the
infrastructure of the United States Army installations is at risk. More than
ever, climate resilience measures are needed to protect facility assets that
support critical missions and help generate readiness. As most of the Army
installations within the continental United States rely on commercial energy
and water sources, resilience to the vulnerabilities within independent energy
resources (electricity grids, natural gas pipelines, etc) along with a baseline
understanding of energy usage within installations must be determined. This
paper will propose a data-driven behavioral model to determine behavior
profiles of energy usage on installations. These profiles will be used 1) to
create a baseline assessment of the impact of unexpected disruptions on energy
systems and 2) to benchmark future resiliency measures. In this methodology,
individual building behavior will be represented with models that can
accurately analyze, predict, and cluster multimodal data collected from energy
usage of non-residential buildings. Due to the nature of Army installation
energy usage data, similarly structured open access data will be used to
illustrate this methodology.

</details>


### [295] [Parking Availability Prediction via Fusing Multi-Source Data with A Self-Supervised Learning Enhanced Spatio-Temporal Inverted Transformer](https://arxiv.org/abs/2509.04362)
*Yin Huang,Yongqi Dong,Youhua Tang,Li Li*

Main category: cs.LG

TL;DR: 该研究提出了一种名为SST-iTransformer的新方法，用于解决城市停车位可用性预测中的时空依赖性和多源数据利用问题，并在真实世界数据上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 城市停车位短缺问题日益严重，需要准确有效的停车位可用性预测来支持城市规划和管理。

Method: 提出SST-iTransformer模型，利用K-means聚类划分停车区域，整合多交通模式数据，并通过掩码-重建进行自监督时空表征学习。模型包含串行注意力（捕捉长期时间依赖）和通道注意力（模拟跨变量交互）。

Result: 在成都的真实世界数据实验中，SST-iTransformer优于其他深度学习模型（Informer, Autoformer, Crossformer, iTransformer），在均方误差（MSE）和平均绝对误差（MAE）方面表现最佳。网约车数据对预测效果提升最大，其次是出租车数据；公交/地铁数据贡献较小。排除同一停车区域内相关停车位历史数据会显著降低预测性能。

Conclusion: SST-iTransformer在停车位可用性预测方面表现出色，证明了整合多源交通数据和建模时空依赖性的重要性，特别是网约车数据和区域内停车位间的空间相关性。

Abstract: The rapid growth of private car ownership has worsened the urban parking
predicament, underscoring the need for accurate and effective parking
availability prediction to support urban planning and management. To address
key limitations in modeling spatio-temporal dependencies and exploiting
multi-source data for parking availability prediction, this study proposes a
novel approach with SST-iTransformer. The methodology leverages K-means
clustering to establish parking cluster zones (PCZs), extracting and
integrating traffic demand characteristics from various transportation modes
(i.e., metro, bus, online ride-hailing, and taxi) associated with the targeted
parking lots. Upgraded on vanilla iTransformer, SST-iTransformer integrates
masking-reconstruction-based pretext tasks for self-supervised spatio-temporal
representation learning, and features an innovative dual-branch attention
mechanism: Series Attention captures long-term temporal dependencies via
patching operations, while Channel Attention models cross-variate interactions
through inverted dimensions. Extensive experiments using real-world data from
Chengdu, China, demonstrate that SST-iTransformer outperforms baseline deep
learning models (including Informer, Autoformer, Crossformer, and
iTransformer), achieving state-of-the-art performance with the lowest mean
squared error (MSE) and competitive mean absolute error (MAE). Comprehensive
ablation studies quantitatively reveal the relative importance of different
data sources: incorporating ride-hailing data provides the largest performance
gains, followed by taxi, whereas fixed-route transit features (bus/metro)
contribute marginally. Spatial correlation analysis further confirms that
excluding historical data from correlated parking lots within PCZs leads to
substantial performance degradation, underscoring the importance of modeling
spatial dependencies.

</details>


### [296] [When three experiments are better than two: Avoiding intractable correlated aleatoric uncertainty by leveraging a novel bias--variance tradeoff](https://arxiv.org/abs/2509.04363)
*Paul Scherer,Andreas Kirsch,Jake P. Taylor-King*

Main category: cs.LG

TL;DR: 该研究提出了一种新的主动学习策略，通过直接减少模型偏差来处理现实世界实验中的异方差不确定性和相关不确定性。


<details>
  <summary>Details</summary>
Motivation: 现实世界实验中存在异方差和相关不确定性，现有的主动学习方法未能充分解决这些问题。

Method: 提出了一种新的主动学习策略，该策略利用偏差-方差权衡来直接减少偏差，并探索了利用历史数据和特征值分解的协方差关系来实现批量处理。

Result: 与 BALD 和最小置信度等经典方法相比，所提出的基于协方差的方法在批量处理场景中表现更优。

Conclusion: 所提出的主动学习策略能够有效处理现实世界实验中的不确定性，并在批量处理场景中取得优于现有方法的性能。

Abstract: Real-world experimental scenarios are characterized by the presence of
heteroskedastic aleatoric uncertainty, and this uncertainty can be correlated
in batched settings. The bias--variance tradeoff can be used to write the
expected mean squared error between a model distribution and a ground-truth
random variable as the sum of an epistemic uncertainty term, the bias squared,
and an aleatoric uncertainty term. We leverage this relationship to propose
novel active learning strategies that directly reduce the bias between
experimental rounds, considering model systems both with and without noise.
Finally, we investigate methods to leverage historical data in a quadratic
manner through the use of a novel cobias--covariance relationship, which
naturally proposes a mechanism for batching through an eigendecomposition
strategy. When our difference-based method leveraging the cobias--covariance
relationship is utilized in a batched setting (with a quadratic estimator), we
outperform a number of canonical methods including BALD and Least Confidence.

</details>


### [297] [PagedEviction: Structured Block-wise KV Cache Pruning for Efficient Large Language Model Inference](https://arxiv.org/abs/2509.04377)
*Krishna Teja Chitty-Venkata,Jie Ye,Xian-He Sun,Anthony Kougkas,Murali Emani,Venkatram Vishwanath,Bogdan Nicolae*

Main category: cs.LG

TL;DR: PagedEviction是一种新的KV缓存剪枝策略，提高了LLM的内存效率，在保持准确性的同时减少了内存使用。


<details>
  <summary>Details</summary>
Motivation: KV缓存是LLM推理中的内存瓶颈，尤其是在处理长序列时。

Method: PagedEviction提出了一种块状逐出算法，用于PagedAttention的内存布局，无需修改CUDA核函数。

Result: 在Llama-3.1-8B-Instruct、Llama-3.2-1B-Instruct和Llama-3.2-3B-Instruct模型上，PagedEviction在LongBench基准测试中显示出比基线更好的内存使用和准确性。

Conclusion: PagedEviction通过其细粒度的块状逐出策略，有效解决了KV缓存的内存瓶颈问题，提高了长上下文任务的LLM性能。

Abstract: KV caching significantly improves the efficiency of Large Language Model
(LLM) inference by storing attention states from previously processed tokens,
enabling faster generation of subsequent tokens. However, as sequence length
increases, the KV cache quickly becomes a major memory bottleneck. To address
this, we propose PagedEviction, a novel fine-grained, structured KV cache
pruning strategy that enhances the memory efficiency of vLLM's PagedAttention.
Unlike existing approaches that rely on attention-based token importance or
evict tokens across different vLLM pages, PagedEviction introduces an efficient
block-wise eviction algorithm tailored for paged memory layouts. Our method
integrates seamlessly with PagedAttention without requiring any modifications
to its CUDA attention kernels. We evaluate PagedEviction across
Llama-3.1-8B-Instruct, Llama-3.2-1B-Instruct, and Llama-3.2-3B-Instruct models
on the LongBench benchmark suite, demonstrating improved memory usage with
better accuracy than baselines on long context tasks.

</details>


### [298] [Transition Models: Rethinking the Generative Learning Objective](https://arxiv.org/abs/2509.04394)
*Zidong Wang,Yiyuan Zhang,Xiaoyu Yue,Xiangyu Yue,Yangguang Li,Wanli Ouyang,Lei Bai*

Main category: cs.LG

TL;DR: 迭代扩散模型在生成模型领域虽然保真度高，但计算成本昂贵，而高效的少步数模型则受限于质量上限。本文提出的过渡模型（TiM）通过一个精确的连续时间动力学方程，实现了在任意步数间的自适应过渡，解决了这一矛盾。


<details>
  <summary>Details</summary>
Motivation: 解决生成模型在生成步数和输出质量之间存在的根本性困境，即高保真度模型计算成本高，而少步数模型质量受限的问题。

Method: 提出一个精确的、连续时间的动力学方程，该方程能够解析地定义任意有限时间间隔内的状态转移。基于此，开发了一种名为过渡模型（TiM）的新型生成范式，该模型能够适应任意步数的过渡，并能从单步跳跃到多步精细化进行无缝生成。

Result: TiM模型参数量仅为8.65亿，但在所有评估的步数下，其性能均超越了参数量高达80亿的SD3.5和120亿的FLUX.1等领先模型。此外，TiM在增加采样预算时，模型质量呈现单调提升。采用原生分辨率策略时，TiM在高达4096x4096的分辨率下也能实现卓越的保真度。

Conclusion: TiM模型通过其创新的连续时间动力学方程和自适应步数过渡能力，在保证生成质量的同时显著降低了计算成本，并在多项评估指标上取得了领先的成果。

Abstract: A fundamental dilemma in generative modeling persists: iterative diffusion
models achieve outstanding fidelity, but at a significant computational cost,
while efficient few-step alternatives are constrained by a hard quality
ceiling. This conflict between generation steps and output quality arises from
restrictive training objectives that focus exclusively on either infinitesimal
dynamics (PF-ODEs) or direct endpoint prediction. We address this challenge by
introducing an exact, continuous-time dynamics equation that analytically
defines state transitions across any finite time interval. This leads to a
novel generative paradigm, Transition Models (TiM), which adapt to
arbitrary-step transitions, seamlessly traversing the generative trajectory
from single leaps to fine-grained refinement with more steps. Despite having
only 865M parameters, TiM achieves state-of-the-art performance, surpassing
leading models such as SD3.5 (8B parameters) and FLUX.1 (12B parameters) across
all evaluated step counts. Importantly, unlike previous few-step generators,
TiM demonstrates monotonic quality improvement as the sampling budget
increases. Additionally, when employing our native-resolution strategy, TiM
delivers exceptional fidelity at resolutions up to 4096x4096.

</details>


### [299] [IPA: An Information-Preserving Input Projection Framework for Efficient Foundation Model Adaptation](https://arxiv.org/abs/2509.04398)
*Yuan Yin,Shashanka Venkataramanan,Tuan-Hung Vu,Andrei Bursuc,Matthieu Cord*

Main category: cs.LG

TL;DR: IPA是一种参数高效的微调（PEFT）方法，通过引入可训练的线性投影层来预压缩和解压缩特征，以解决LoRA中随机初始化的下行投影带来的信息损失问题。IPA在语言和视觉基准测试中均优于LoRA和DoRA，并在部分训练参数下可达到与完全LoRA相当的性能。


<details>
  <summary>Details</summary>
Motivation: LoRA等参数高效微调方法在注入低秩更新时，其下行投影是随机初始化的且与数据无关，导致可能丢失有用的信息，而上行投影承担了大部分的适应性调整，因此随机的输入压缩成为了性能瓶颈。

Method: IPA（In-formed Projection Adaptation）框架通过引入一个特征感知的投影层来显式地保留降维后的隐藏空间中的信息。在层级情况下，IPA通过近似顶部主成分的算法来实现高效的投影层预训练，且推理开销可忽略不计。

Result: 在语言和视觉基准测试中，IPA相比LoRA和DoRA取得了持续的性能提升，在常识推理任务上平均准确率提高了1.5个百分点，在VTAB-1k上提高了2.3个百分点。当投影层被冻结时，IPA仅使用大约一半的可训练参数即可达到与完全LoRA相当的性能。

Conclusion: IPA通过引入特征感知的投影层，有效解决了LoRA中随机初始化的下行投影带来的信息丢失问题，并在多个基准测试中取得了优于现有方法的性能，同时在参数效率方面也表现出色。

Abstract: Parameter-efficient fine-tuning (PEFT) methods, such as LoRA, reduce
adaptation cost by injecting low-rank updates into pretrained weights. However,
LoRA's down-projection is randomly initialized and data-agnostic, discarding
potentially useful information. Prior analyses show that this projection
changes little during training, while the up-projection carries most of the
adaptation, making the random input compression a performance bottleneck. We
propose IPA, a feature-aware projection framework that explicitly preserves
information in the reduced hidden space. In the linear case, we instantiate IPA
with algorithms approximating top principal components, enabling efficient
projector pretraining with negligible inference overhead. Across language and
vision benchmarks, IPA consistently improves over LoRA and DoRA, achieving on
average 1.5 points higher accuracy on commonsense reasoning and 2.3 points on
VTAB-1k, while matching full LoRA performance with roughly half the trainable
parameters when the projection is frozen.

</details>


### [300] [Interpretable Clustering with Adaptive Heterogeneous Causal Structure Learning in Mixed Observational Data](https://arxiv.org/abs/2509.04415)
*Wenrui Li,Qinghao Zhang,Xiaowo Wang*

Main category: cs.LG

TL;DR: HCL是一个无监督框架，用于从混合类型观测数据中学习可解释的、异质的因果模式，而无需任何先验知识。


<details>
  <summary>Details</summary>
Motivation: 现有方法在理解因果异质性方面存在不足，无法有效处理异质性、混淆和观测约束，导致可解释性差，难以区分真正的因果异质性与虚假关联。

Method: HCL框架通过引入一种同时编码结构异质性和混淆的等效表示，来放松同质性和充分性假设。它采用双向迭代策略，交替优化因果聚类和结构学习，并利用一种平衡跨聚类普遍性和特异性的自监督正则化。

Result: HCL在聚类和结构学习任务上均取得了优越的性能，并在真实世界单细胞扰动数据中恢复了具有生物学意义的机制。

Conclusion: HCL能够发现可解释的、机制层面的因果异质性，为科学发现提供了有力的工具。

Abstract: Understanding causal heterogeneity is essential for scientific discovery in
domains such as biology and medicine. However, existing methods lack causal
awareness, with insufficient modeling of heterogeneity, confounding, and
observational constraints, leading to poor interpretability and difficulty
distinguishing true causal heterogeneity from spurious associations. We propose
an unsupervised framework, HCL (Interpretable Causal Mechanism-Aware Clustering
with Adaptive Heterogeneous Causal Structure Learning), that jointly infers
latent clusters and their associated causal structures from mixed-type
observational data without requiring temporal ordering, environment labels,
interventions or other prior knowledge. HCL relaxes the homogeneity and
sufficiency assumptions by introducing an equivalent representation that
encodes both structural heterogeneity and confounding. It further develops a
bi-directional iterative strategy to alternately refine causal clustering and
structure learning, along with a self-supervised regularization that balance
cross-cluster universality and specificity. Together, these components enable
convergence toward interpretable, heterogeneous causal patterns. Theoretically,
we show identifiability of heterogeneous causal structures under mild
conditions. Empirically, HCL achieves superior performance in both clustering
and structure learning tasks, and recovers biologically meaningful mechanisms
in real-world single-cell perturbation data, demonstrating its utility for
discovering interpretable, mechanism-level causal heterogeneity.

</details>


### [301] [Towards a Unified View of Large Language Model Post-Training](https://arxiv.org/abs/2509.04419)
*Xingtai Lv,Yuxin Zuo,Youbang Sun,Hongyi Liu,Yuntian Wei,Zhekai Chen,Lixuan He,Xuekai Zhu,Kaiyan Zhang,Bingning Wang,Ning Ding,Bowen Zhou*

Main category: cs.LG

TL;DR: 在线（模型生成数据）和离线（人类或模型演示）数据是现代语言模型训练的两种主要来源。本文提出了一种统一策略梯度估计器，将 RL 和 SFT 等方法视为单一优化过程的实例。在此基础上，提出了一种混合训练（HPT）算法，可以动态选择不同的训练信号，以实现演示的有效利用和稳定探索，同时不牺牲学到的推理模式。HPT 在六个数学推理基准和两个分布外套件上，在不同规模和系列的模型上都持续超越强基线。


<details>
  <summary>Details</summary>
Motivation: 现有模型训练方法（如 RL 和 SFT）所使用的在线和离线数据源并非相互排斥，而是单一优化过程的不同实例。

Method: 提出了一种统一策略梯度估计器，该估计器由四个可互换部分组成：稳定掩码、参考策略分母、优势估计和似然梯度。在此基础上，提出了一种混合训练（HPT）算法，该算法能够动态选择不同的训练信号，以平衡演示利用和探索稳定性。

Result: HPT 在六个数学推理基准和两个分布外套件上，在不同规模和系列的模型上都持续超越强基线。

Conclusion: 统一的理论框架和 HPT 算法能够有效地训练语言模型，并在各种推理任务上取得优于现有方法的性能。

Abstract: Two major sources of training data exist for post-training modern language
models: online (model-generated rollouts) data, and offline (human or
other-model demonstrations) data. These two types of data are typically used by
approaches like Reinforcement Learning (RL) and Supervised Fine-Tuning (SFT),
respectively. In this paper, we show that these approaches are not in
contradiction, but are instances of a single optimization process. We derive a
Unified Policy Gradient Estimator, and present the calculations of a wide
spectrum of post-training approaches as the gradient of a common objective
under different data distribution assumptions and various bias-variance
tradeoffs. The gradient estimator is constructed with four interchangeable
parts: stabilization mask, reference policy denominator, advantage estimate,
and likelihood gradient. Motivated by our theoretical findings, we propose
Hybrid Post-Training (HPT), an algorithm that dynamically selects different
training signals. HPT is designed to yield both effective exploitation of
demonstration and stable exploration without sacrificing learned reasoning
patterns. We provide extensive experiments and ablation studies to verify the
effectiveness of our unified theoretical framework and HPT. Across six
mathematical reasoning benchmarks and two out-of-distribution suites, HPT
consistently surpasses strong baselines across models of varying scales and
families.

</details>


### [302] [Echo State Networks as State-Space Models: A Systems Perspective](https://arxiv.org/abs/2509.04422)
*Pradeep Singh,Balasubramanian Raman*

Main category: cs.LG

TL;DR: ESNs被视为一种高效的、仅训练读出的循环模型，但其设计和动力学往往依赖于启发式方法。本文将ESNs明确重构为状态空间模型（SSMs），提供了一个统一的系统理论解释，将水库计算与经典识别和现代核SSMs联系起来。


<details>
  <summary>Details</summary>
Motivation: 本文旨在为回声状态网络（ESNs）提供一个基于第一性原理的系统理论解释，将其与经典状态空间模型（SSMs）和现代核SSMs统一起来，并提出更优化的训练和设计方法。

Method: 1. 将ESNs重构为状态空间模型（SSMs），推导了保证回声性质（输入到状态稳定性）的条件。2. 提出了两种状态映射方法：一种是局部有效的线性时不变（LTI）SSM的小信号线性化方法；另一种是升/Koopman随机特征展开方法，将ESN转化为增广状态下的线性SSM。3. 将教师强制视为状态估计问题，并提出了卡尔曼/EKF辅助读出学习方法，以及用于超参数估计的EM算法和用于谱整形（在收缩约束下）的混合子空间方法。

Result: 1. 提出了ESN的系统理论框架，并给出了回声性质的验证条件。2. 得到了ESN的频率域特征，并阐明了ESN如何模拟结构化SSM核。3. 提出了改进的ESN训练方法，包括卡尔曼/EKF辅助读出学习、EM超参数估计和混合子空间谱整形。

Conclusion: 本文提供了一个新的视角来看待ESNs，将它们统一在状态空间模型（SSMs）的框架下。这不仅有助于理论理解，还导出了改进的训练和设计方法，为ESNs在实际应用中的性能提升奠定了基础。

Abstract: Echo State Networks (ESNs) are typically presented as efficient,
readout-trained recurrent models, yet their dynamics and design are often
guided by heuristics rather than first principles. We recast ESNs explicitly as
state-space models (SSMs), providing a unified systems-theoretic account that
links reservoir computing with classical identification and modern kernelized
SSMs. First, we show that the echo-state property is an instance of
input-to-state stability for a contractive nonlinear SSM and derive verifiable
conditions in terms of leak, spectral scaling, and activation Lipschitz
constants. Second, we develop two complementary mappings: (i) small-signal
linearizations that yield locally valid LTI SSMs with interpretable poles and
memory horizons; and (ii) lifted/Koopman random-feature expansions that render
the ESN a linear SSM in an augmented state, enabling transfer-function and
convolutional-kernel analyses. This perspective yields frequency-domain
characterizations of memory spectra and clarifies when ESNs emulate structured
SSM kernels. Third, we cast teacher forcing as state estimation and propose
Kalman/EKF-assisted readout learning, together with EM for hyperparameters
(leak, spectral radius, process/measurement noise) and a hybrid subspace
procedure for spectral shaping under contraction constraints.

</details>


### [303] [Unveiling the Role of Data Uncertainty in Tabular Deep Learning](https://arxiv.org/abs/2509.04430)
*Nikolay Kartashev,Ivan Rubachev,Artem Babenko*

Main category: cs.LG

TL;DR: 深度学习在表格数据上的应用缺乏对其成功原因的清晰理解，本文提出“数据不确定性”是关键，并据此改进了数值特征嵌入。 keseluruhan, penelitian ini membuka jalan bagi pemahaman mendasar tentang manfaat yang diperkenalkan oleh metode tabular modern, yang menghasilkan kemajuan konkret dari teknik yang ada dan menguraikan arah penelitian di masa depan untuk DL tabular.


<details>
  <summary>Details</summary>
Motivation: 表格深度学习的成功原因尚不明确，本文旨在阐明数据不确定性在其中扮演的关键角色。

Method: 通过分析数值特征嵌入、检索增强模型和高级集成策略等方法，揭示它们在管理数据不确定性方面的作用。

Result: 提出数据不确定性是表格深度学习方法成功的关键，并基于此改进了数值特征嵌入方法。

Conclusion: 数据不确定性为了解决表格深度学习的成功原因提供了统一的理解，并为该领域未来的研究指明了方向。

Abstract: Recent advancements in tabular deep learning have demonstrated exceptional
practical performance, yet the field often lacks a clear understanding of why
these techniques actually succeed. To address this gap, our paper highlights
the importance of the concept of data uncertainty for explaining the
effectiveness of the recent tabular DL methods. In particular, we reveal that
the success of many beneficial design choices in tabular DL, such as numerical
feature embeddings, retrieval-augmented models and advanced ensembling
strategies, can be largely attributed to their implicit mechanisms for managing
high data uncertainty. By dissecting these mechanisms, we provide a unifying
understanding of the recent performance improvements. Furthermore, the insights
derived from this data-uncertainty perspective directly allowed us to develop
more effective numerical feature embeddings as an immediate practical outcome
of our analysis. Overall, our work paves the way to foundational understanding
of the benefits introduced by modern tabular methods that results in the
concrete advancements of existing techniques and outlines future research
directions for tabular DL.

</details>


### [304] [Delta Activations: A Representation for Finetuned Large Language Models](https://arxiv.org/abs/2509.04442)
*Zhiqiu Xu,Amish Sethi,Mayur Naik,Ser-Nam Lim*

Main category: cs.LG

TL;DR: 大型语言模型(LLM)的社区模型库庞大但难以理解，本研究提出“Delta Activations”方法，将微调模型表示为向量嵌入，以测量其内部激活相对于基础模型的偏移。该方法能有效聚类模型，揭示模型格局结构，且对微调设置具有鲁棒性，并能通过混合微调数据集进行加性嵌入。此外，Delta Activations还能通过少样本微调嵌入任务，并用于模型选择和合并，旨在促进公共模型再利用。


<details>
  <summary>Details</summary>
Motivation: 社区中存在大量针对特定任务和领域进行二次训练的开源大型语言模型（LLMs），但由于元数据不一致和存储库结构混乱，导致难以导航和理解这些模型。

Method: 提出“Delta Activations”方法，将微调模型表示为向量嵌入，通过测量其内部激活相对于基础模型的偏移来实现。

Result: Delta Activations能够有效地按领域和任务对模型进行聚类，揭示模型格局结构。该表示对微调设置具有鲁棒性，并且在混合微调数据集时表现出加性。此外，Delta Activations还可以通过少样本微调来嵌入任务，并可用于模型选择和合并。

Conclusion: Delta Activations方法有望促进对公开可用模型的再利用，因为它能够有效地表示、聚类、选择和合并微调模型。

Abstract: The success of powerful open source Large Language Models (LLMs) has enabled
the community to create a vast collection of post-trained models adapted to
specific tasks and domains. However, navigating and understanding these models
remains challenging due to inconsistent metadata and unstructured repositories.
We introduce Delta Activations, a method to represent finetuned models as
vector embeddings by measuring shifts in their internal activations relative to
a base model. This representation allows for effective clustering by domain and
task, revealing structure in the model landscape. Delta Activations also
demonstrate desirable properties: it is robust across finetuning settings and
exhibits an additive property when finetuning datasets are mixed. In addition,
we show that Delta Activations can embed tasks via few-shot finetuning, and
further explore its use for model selection and merging. We hope Delta
Activations can facilitate the practice of reusing publicly available models.
Code is available at https://github.com/OscarXZQ/delta_activations.

</details>


### [305] [Towards Cognitively-Faithful Decision-Making Models to Improve AI Alignment](https://arxiv.org/abs/2509.04445)
*Cyrus Cousins,Vijay Keswani,Vincent Conitzer,Hoda Heidari,Jana Schaich Borg,Walter Sinnott-Armstrong*

Main category: cs.LG

TL;DR: AI 模型通常通过偏好引导来学习人类决策，但现有方法忽略了人类决策中的启发式思维。本文提出了一种公理化方法，从成对比较中学习认知上忠实的决策过程，考虑了特征处理和聚合，并在肾脏分配任务中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有AI模型在从人类决策中学习时，通常未能捕捉到人类决策过程中使用的启发式方法，导致模型与人类认知过程不匹配，无法有效验证AI学习框架的泛化能力。

Method: 本文采用公理化方法，从成对比较中学习认知上忠实的决策过程。该方法首先处理和比较不同选项的个体特征，然后通过固定规则（如 Bradley-Terry 模型）聚合这些特征。

Result: 所提出的模型在肾脏分配任务中被证明是有效的，学习到了可解释性强的人类决策模型，并且在准确性上达到或超过了现有模型。

Conclusion: 本文提出的从成对比较中学习认知上忠实的决策过程的方法，能够更真实地模拟人类决策过程，并在实践中展现出优于现有方法的准确性。

Abstract: Recent AI work trends towards incorporating human-centric objectives, with
the explicit goal of aligning AI models to personal preferences and societal
values. Using standard preference elicitation methods, researchers and
practitioners build models of human decisions and judgments, which are then
used to align AI behavior with that of humans. However, models commonly used in
such elicitation processes often do not capture the true cognitive processes of
human decision making, such as when people use heuristics to simplify
information associated with a decision problem. As a result, models learned
from people's decisions often do not align with their cognitive processes, and
can not be used to validate the learning framework for generalization to other
decision-making tasks. To address this limitation, we take an axiomatic
approach to learning cognitively faithful decision processes from pairwise
comparisons. Building on the vast literature characterizing the cognitive
processes that contribute to human decision-making, and recent work
characterizing such processes in pairwise comparison tasks, we define a class
of models in which individual features are first processed and compared across
alternatives, and then the processed features are then aggregated via a fixed
rule, such as the Bradley-Terry rule. This structured processing of information
ensures such models are realistic and feasible candidates to represent
underlying human decision-making processes. We demonstrate the efficacy of this
modeling approach in learning interpretable models of human decision making in
a kidney allocation task, and show that our proposed models match or surpass
the accuracy of prior models of human pairwise decision-making.

</details>


### [306] [ChronoGraph: A Real-World Graph-Based Multivariate Time Series Dataset](https://arxiv.org/abs/2509.04449)
*Adrian Catalin Lutu,Ioana Pintilie,Elena Burceanu,Andrei Manolache*

Main category: cs.LG

TL;DR: ChronoGraph是一个包含真实世界生产微服务的图结构多元时间序列预测数据集，用于服务级别的预测和异常检测。


<details>
  <summary>Details</summary>
Motivation: 为微服务系统中的结构感知预测和事件感知评估提供一个真实的基准。

Method: 构建了一个图结构的时间序列数据集，其中节点代表服务，边代表服务依赖关系，并包含系统级性能指标和事件标注。

Result: 报告了跨预测模型、预训练时间序列基础模型和标准异常检测器的基线结果。

Conclusion: ChronoGraph提供了独特的多元时间序列、显式依赖图和与真实事件相关的异常标签，适用于研究微服务系统中的结构感知预测和事件感知评估。

Abstract: We present ChronoGraph, a graph-structured multivariate time series
forecasting dataset built from real-world production microservices. Each node
is a service that emits a multivariate stream of system-level performance
metrics, capturing CPU, memory, and network usage patterns, while directed
edges encode dependencies between services. The primary task is forecasting
future values of these signals at the service level. In addition, ChronoGraph
provides expert-annotated incident windows as anomaly labels, enabling
evaluation of anomaly detection methods and assessment of forecast robustness
during operational disruptions. Compared to existing benchmarks from industrial
control systems or traffic and air-quality domains, ChronoGraph uniquely
combines (i) multivariate time series, (ii) an explicit, machine-readable
dependency graph, and (iii) anomaly labels aligned with real incidents. We
report baseline results spanning forecasting models, pretrained time-series
foundation models, and standard anomaly detectors. ChronoGraph offers a
realistic benchmark for studying structure-aware forecasting and incident-aware
evaluation in microservice systems.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [307] [Challenges in Scaling ScAlN Bulk Acoustic Wave Filters toward Ku-Band Frequencies](https://arxiv.org/abs/2509.03679)
*Sinwoo Cho,Byeongjin Kim,Lezli Matto,Omar Barrera,Pietro Simeoni,Yinan Wang,Michael Liao,Tzu-Hsuan Hsu,Jack Kramer,Matteo Rinaldi,Mark S. Goorsky,Ruochen Lu*

Main category: physics.app-ph

TL;DR: 本文设计并实现了一个基于 Scandium Aluminum Nitride (ScAlN) 薄膜体声波谐振器 (FBAR) 的 11.7 GHz 紧凑型滤波器，并分析了限制其扩展到更高频率性能的挑战。


<details>
  <summary>Details</summary>
Motivation: 为开发低损耗毫米波声学滤波器提供关键见解，解决 ScAlN FBAR 在更高频率下的性能限制。

Method: 使用单层 ScAlN 和铂 (Pt) 电极构建了一个 50 Ω 阶梯滤波器。

Result: 实现了 11.7 GHz 的滤波器，具有 4.0% 的 3 dB 分数带宽 (FBW) 和大于 23.1 dB 的带外抑制，但插入损耗 (IL) 为 6.8 dB，这归因于谐振器的品质因数 (Q) 有限。

Conclusion: 分析了三个主要的频率扩展挑战：压电薄膜晶体质量下降、超薄电极的系列电阻增加以及残余薄膜应力影响器件尺寸和结构完整性。通过建立制造挑战与器件性能之间的关系，为未来低损耗毫米波声学滤波器的发展提供了见解。

Abstract: This paper reports an 11.7 GHz compact filter based on Scandium Aluminum
Nitride (ScAlN) Film Bulk Acoustic Resonators (FBARs) and provides a detailed
analysis of the fundamental challenges that limit performance when scaling to
higher frequencies. A 50 {\Omega} ladder filter based on single-layer thin film
ScAlN with Platinum (Pt) electrodes was demonstrated at 11.7 GHz with a 3 dB
fractional bandwidth (FBW) of 4.0% and an out of band rejection greater than
23.1 dB. However, the filter exhibits a moderate insertion loss (IL) of 6.8 dB,
which is attributed to a limited Quality (Q) factor in the constituent
resonators. Consequently, we identify and analyze three primary challenges in
frequency scaling ScAlN FBARs with thinner film stacks: 1) degradation of
piezoelectric thin-film crystal quality, 2) increased series resistance in
ultra-thin electrodes, and 3) residual film stress that limits device size and
structural integrity. By establishing a clear relationship between these
fabrication-level challenges and the resulting device performance, this work
provides critical insights for the future development of low-loss acoustic
filters for millimeter-wave applications.

</details>


### [308] [Polarization control via artificial optical nonlinearity in dielectric metasurfaces](https://arxiv.org/abs/2509.03752)
*Fuyong Yue,Giacomo Balistreri,Nicola Montaut,Fabrizio Riminucci,Andrea Toma,Riccardo Piccoli,Stefano Cabrini,Roberto Morandotti,Luca Razzari*

Main category: physics.app-ph

TL;DR: Metasurfaces enable engineering of nonlinear optical interactions by controlling light polarization through tailored geometries. This work establishes a model for dielectric metasurfaces to customize third harmonic generation and quantifies nonlinear susceptibility, demonstrating versatile applications in nonlinear imaging and complex light generation.


<details>
  <summary>Details</summary>
Motivation: Current studies on nonlinear metasurfaces primarily focus on phase control, but investigating the tensorial nature of nonlinearity and its effect on polarization is crucial for applications like nonlinear vector beam generation and imaging.

Method: Studied the artificial optical nonlinearity of a dielectric metasurface based on meta-atom symmetry, described third-order nonlinear behavior considering polarization, and established an effective nonlinear medium model for amorphous silicon-based geometric metasurfaces.

Result: Established an effective nonlinear medium model for designing amorphous silicon-based geometric metasurfaces with customizable features in third harmonic generation. Extracted quantitative values of artificial nonlinear susceptibility tensor elements. Demonstrated functional devices shaping emitted light in amplitude, phase, and polarization.

Conclusion: Dielectric metasurfaces offer versatile control over emitted light's amplitude, phase, and polarization, enabling precise engineering of novel nonlinear architectures for applications in nonlinear imaging and complex light generation.

Abstract: Nonlinear optical phenomena are generally governed by geometry in matter
systems, as they depend on the spatial arrangement of atoms within materials or
molecules. Metasurfaces, through precisely designed geometries on a
subwavelength scale, allow tailoring the optical response of a material far
beyond its natural properties. Therefore, metasurfaces are highly appealing to
enable the engineering of nonlinear optical interactions at an unprecedented
level. Current studies on nonlinear metasurfaces predominantly focus on the
phase control of the generated light. Nonetheless, investigating the tensorial
nature of the nonlinearity of metasurfaces and its effect on the polarization
of the generated light is critical to fully unlock a range of applications,
such as nonlinear vector beam generation and nonlinear polarization imaging.
Here, we study the artificial optical nonlinearity of a dielectric metasurface
originating from its meta-atom symmetry and describe the third-order nonlinear
behavior by considering the polarization degree of freedom. We establish an
effective nonlinear medium model that serves as a design toolbox for developing
amorphous silicon-based geometric metasurfaces with customizable features in
third harmonic generation. We further extract quantitative values of the
artificial nonlinear susceptibility tensor elements related to the investigated
nonlinear process and geometry. The implemented functional devices demonstrate
the versatility of dielectric metasurfaces in shaping the emitted light in
terms of amplitude, phase, and polarization, for the precise engineering of
novel nonlinear architectures targeting applications in nonlinear imaging and
complex light generation.

</details>


### [309] [Active Dual-Gated Graphene Transistors for Low-Noise, Drift-Stable, and Tunable Chemical Sensing](https://arxiv.org/abs/2509.04137)
*Vinay Kammarchedu,Heshmat Asgharian,Hossein Chenani,Aida Ebrahimi*

Main category: physics.app-ph

TL;DR: This paper introduces a dual-gate graphene field-effect transistor (GFET) architecture with real-time feedback biasing for ultrasensitive chemical and biological sensing, overcoming limitations of conventional GFETs in liquid environments. The new design achieves significant improvements in signal gain, drift suppression, and signal-to-noise ratio, enabling robust and multiplexed detection for various applications.


<details>
  <summary>Details</summary>
Motivation: Conventional single-gate GFET sensors in liquid environments have limitations such as signal drift, charge trapping, and insufficient signal amplification, hindering their use in ultrasensitive chemical and biological sensing.

Method: A dual-gate GFET architecture was introduced, integrating a high-k hafnium dioxide local back gate with an electrolyte top gate, coupled with real-time feedback biasing. Seven operational modes were evaluated, with the Dual Mode Fixed configuration identified as optimal.

Result: The optimal Dual Mode Fixed configuration achieved up to 20x signal gain, >15x lower drift compared to gate-swept methods, and up to 7x higher signal-to-noise ratio across diverse analytes. The platform demonstrated robust, multiplexed detection using a PCB-integrated GFET sensor array and stable, label-free detection under ambient and physiological conditions.

Conclusion: The developed dual-gate GFET platform with real-time feedback biasing offers a versatile and stable sensing technology for real-time, label-free detection of molecular targets, with broad applicability in health monitoring, food safety, agriculture, and environmental screening.

Abstract: Graphene field-effect transistors (GFETs) are among the most promising
platforms for ultrasensitive chemical and biological sensing due to their high
carrier mobility, large surface area, and low intrinsic noise. However,
conventional single-gate GFET sensors in liquid environments suffer from severe
limitations, including signal drift, charge trapping, and insufficient signal
amplification. Here, we introduce a dual-gate GFET architecture that integrates
a high-k hafnium dioxide local back gate with an electrolyte top gate, coupled
with real-time feedback biasing. This design enables capacitive signal
amplification while simultaneously suppressing gate leakage and low-frequency
noise. By systematically evaluating seven distinct operational modes, we
identify the Dual Mode Fixed configuration as optimal, achieving up to 20x
signal gain, > 15x lower drift compared with gate-swept methods, and up to 7x
higher signal to noise ratio across a diverse range of analytes, including
neurotransmitters, volatile organic compounds, environmental contaminants, and
proteins. We further demonstrate robust, multiplexed detection using a
PCB-integrated GFET sensor array, underscoring the scalability and practicality
of the platform for portable, high-throughput sensing in complex environments.
Together, these advances establish a versatile and stable sensing technology
capable of real-time, label-free detection of molecular targets under ambient
and physiological conditions, with broad applicability in health monitoring,
food safety, agriculture, and environmental screening.

</details>


### [310] [Making neural networks understand internal heat transfer using Fourier-transformed thermal diffusion wave fields](https://arxiv.org/abs/2509.04223)
*Pengfei Zhu,Hai Zhang,Clemente Ibarra-Castanedo,Xavier Maldague,Andreas Mandelis*

Main category: physics.app-ph

TL;DR: 使用赫姆霍兹方程和神经网络预测内部温度分布，无需内部测量，可用于无损热成像。


<details>
  <summary>Details</summary>
Motivation: 现有热成像技术难以完全解析地下结构和内部热量分布，且现有基于物理信息神经网络（PINNs）的方法仅能拟合外部温度数据，无法直接预测内部温度分布。

Method: 提出一种赫姆霍兹方程信息神经网络（HINN），将时域热扩散方程转换为频域伪赫姆霍兹方程，并嵌入到学习框架中，同时利用热场实部和虚部。通过逆傅里叶变换将结果转换回时域，并采用截断操作和共轭对称原理提高计算效率和精度。

Result: HINN能够预测内部温度分布，无需内部测量，并能映射具有内部缺陷的3D热场。该方法显著提高了预测精度和计算效率。

Conclusion: HINN在预测精度和计算效率方面优于最先进的PINNs和逆热求解器，为材料科学、生物医学诊断和无损评估等领域的无损热成像提供了新颖的解决方案。

Abstract: Heat propagation is governed by phonon interactions and mathematically
described by partial differential equations (PDEs), which link thermal
transport to the intrinsic properties of materials. Conventional experimental
techniques infer thermal responses based on surface emissions, limiting their
ability to fully resolve subsurface structures and internal heat distribution.
Additionally, existing thermal tomographic techniques can only shoot one frame
from each layer. Physics-informed neural networks (PINNs) have recently emerged
as powerful tools for solving inverse problems in heat transfer by integrating
observational data with physical constraints. However, standard PINNs are
primarily focused on fitting the given external temperature data, without
explicit knowledge of the unknown internal temperature distribution. In this
study, we introduce a Helmholtz-informed neural network (HINN) to predict
internal temperature distributions without requiring internal measurements. The
time-domain heat diffusion equation was converted to the frequency-domain and
becomes the pseudo-Helmholtz equation. HINN embeds this pseudo-Helmholtz
equation into the learning framework, leveraging both real and imaginary
components of the thermal field. Finally, an inverse Fourier transform brings
real-part and imagery-part back to the time-domain and can be used to map 3D
thermal fields with interior defects. Furthermore, a truncated operation was
conducted to improve computational efficiency, and the principle of conjugate
symmetry was employed for repairing the discarded data. This approach
significantly enhances predictive accuracy and computational efficiency. Our
results demonstrate that HINN outperforms state-of-the-art PINNs and inverse
heat solvers, offering a novel solution for non-invasive thermography in
applications spanning materials science, biomedical diagnostics, and
nondestructive evaluation.

</details>


### [311] [Thermal diffusivity measurement based on evaporative cryocooling excitation: Theory and experiments](https://arxiv.org/abs/2509.04263)
*Pengfei Zhu,Hai Zhang,Stefano Sfarra,Fabrizio Sarasini,Ruben Usamentiaga,Gunther Steenackers,Clemente Ibarra-Castanedo,Xavier Maldague,Andreas Mandelis*

Main category: physics.app-ph

TL;DR: 光热法测量热扩散系数固有地构成一个不适定逆问题，并且会受到样品厚度、加热或冷却时间以及激发能量等因素的影响。尤其是在非脉冲激发下，当观测时间尺度与脉冲持续时间相当时，测量精度会面临严峻挑战，这通常是由于脉冲形状定义不清、热响应展宽以及边界条件不明确，特别是在自然对流占主导地位的显著界面温度梯度下。经典的Parker解虽然被广泛使用，但其物理意义上不现实，因为它假设了绝热热通量和浅层区域吸热。在本研究中，我们证明了Parker的假设在数学上等同于狄拉克脉冲边界条件。随后，我们提出了针对狄拉克和矩形脉冲激发下热/冷却响应的综合解析解。通过与适定边界条件的本征函数解进行比较，我们证明了Parker解仅在热峰值出现之前有效。通过无量纲处理，我们进一步证明了Parker解可以看作是当加热持续时间趋近于零时矩形脉冲解的极限情况。此外，我们提出了一种新颖的激发方法——蒸发式压 H 冷却，用于热扩散系数的测量。该方法为传统的激发方案提供了一种紧凑、低成本且易于实现的替代方案。理论模型也通过与实验结果的比较得到了进一步验证。


<details>
  <summary>Details</summary>
Motivation: 测量热扩散系数的光热法存在不适定逆问题，尤其在非脉冲激发下精度挑战更大。Parker解存在物理不合理假设。提出一种新颖的蒸发式压 H 冷却方法。

Method: 推导了狄拉克和矩形脉冲激发下的热响应解析解，证明了Parker解的有效性限制，并提出了蒸发式压 H 冷却方法。

Result: Parker解仅在热峰值前有效，是矩形脉冲解的极限情况。蒸发式压 H 冷却方法在理论和实验上均得到验证。

Conclusion:  Parker解的局限性，并提出了一种新颖且有效的蒸发式压 H 冷却方法用于测量热扩散系数。

Abstract: Photo-thermal methods for measuring thermal diffusivity inherently pose an
ill-posed inverse problem, affected by factors such as sample thickness,
heating or cooling time, and excitation energy. Measurement accuracy becomes
particularly challenging under non-impulsive pulsed excitation when the
observation timescale is comparable to the pulse duration. This is often due to
poorly defined pulse shapes, broadened thermal responses, and the absence of
clear boundary conditions, especially under significant interfacial temperature
gradients where natural convection dominates. The classic Parker solution,
while widely used, is physically unrealistic as it assumes adiabatic heat flux
and shallow-region heat absorption. In this study, we prove that Parker's
assumption is equivalent to the Dirac pulse boundary condition in mathematics.
Then, we present comprehensive analytical solutions for thermal/cooling
responses under Dirac and rectangular pulse excitations. By comparing with
eigenfunction-based solutions for well-posed boundary conditions, we show that
Parker's solution is only valid before the thermal peak. Through dimensionless
processing, we further demonstrate that Parker's solution can be regarded as a
limiting case of the rectangular pulse solution as the heating duration
approaches zero. Furthermore, we propose a novel excitation approach,
evaporative cryocooling, for thermal diffusivity measurement. This method
offers a compact, low-cost, and easy-to-implement alternative to conventional
excitation schemes. The theoretical model was further validated through
comparison with experimental results.

</details>


### [312] [Ultrasound-Triggered Release of Anticancer Nanoparticles from Electrospun Fabrics Integrated with Soft Robotic Tentacles](https://arxiv.org/abs/2509.04313)
*Samuel C. T. Moorcroft,Benjamin Calmé,Charles Brooker,Pietro Valdastri,Russell Harris,Stephen J. Russell,Giuseppe Tronci*

Main category: physics.app-ph

TL;DR: 肿瘤“劫持”胰腺基质结构限制了全身化疗药物的吸收。我们演示了一种通过设计溶剂痕量药物负载的乙烯基苄基功能化明胶（gel4vbc）纳米粒（NP）与电纺织物集成来实现超声（US）触发的局部药物释放。


<details>
  <summary>Details</summary>
Motivation: 胰腺癌症状的及时识别是一个持续存在的临床挑战，经常导致诊断延迟和预后不良。局部给药系统（DDS）利用内镜技术，在控制肿瘤生长方面取得了积极的早期成果。然而，仍然需要能够整合内镜资源和智能材料系统以更好地控制化疗药物时空递送的技术。

Method: 设计溶剂痕量药物负载的乙烯基苄基功能化明胶（gel4vbc）纳米粒（NP），并将其集成到电纺织物中。将负载白蛋白的NP封装到聚己内酯（PCL）织物的聚乙烯醇（PVA）涂层中，通过调节PVA浓度（0-1 wt.%）和超声强度（0-3 W/cm2）来控制NP的触发释放。将载有NP的织物固定在磁性触手机器人（MTR）上，以实现自动化操作。通过改变载有NP的MTR涂层织物的表面积来控制白蛋白的释放。

Result: 实现了可调控的触发式NP递送，其递送效果可通过调节PVA浓度和超声强度进行控制。载有NP的涂层织物通过磁性触手机器人（MTR）能够被自动操控到模拟胰腺导管中。白蛋白的释放可以通过改变NP负载MTR涂层织物的表面积来控制。

Conclusion: 设计了一种新颖的DDS，能够轻松集成到软体机器人中，并实现超声触发的、装载治疗药物的NP递送。

Abstract: The prompt identification of pancreatic cancer symptoms is an ongoing
clinical challenge, often leading to late diagnosis and poor prognosis. Tumor
'hijacking' of the pancreatic stromal structure limits the uptake of systemic
chemotherapeutics. Localized drug delivery systems (DDS) using endoluminal
techniques are widely utilized, with positive early results for improved
control over tumor growth. There is a need for technologies that integrate
endoluminal resources and intelligent material systems to better control the
spatiotemporal delivery of chemotherapeutics. We demonstrate the ultrasound
(US)-triggered localized release of therapeutics through the design of solvent
traceless drug-loaded vinylbenzyl-functionalized gelatin (gel4vbc)
nanoparticles (NPs) integrated with an electrospun fabric. Albumin-loaded NPs
encapsulated into a poly(vinyl alcohol) (PVA) coating of a
poly(epsilon-caprolactone) fabric evidence tunable triggered NP delivery
controlled by regulating PVA concentration (0-1 wt.%) and US intensity (0-3
W/cm2). The fixation of the NP-coated fabric to a magnetic tentacle robot (MTR)
enables the automated manipulation into a phantom pancreatic duct before the
US-triggered release of NP-loaded albumin and MTR retraction. Albumin release
is controlled by varying the surface area of the NP-loaded MTR-coating fabric.
Herein we have designed a novel DDS capable of facile integration into soft
robotics and US-triggered delivery of therapeutic-loaded NPs.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [313] [The evolution of trust as a cognitive shortcut in repeated interactions](https://arxiv.org/abs/2509.04143)
*Cedric Perret,The Anh Han,Elias Fernández Domingos,Theodor Cimpeanu,Simon T. Powers*

Main category: cs.GT

TL;DR: 信任可以被形式化为一种认知捷径，在重复博弈中，一旦观察到合作伙伴达到一定的合作阈值，就可以避免检查其行为。


<details>
  <summary>Details</summary>
Motivation: 现有的博弈论模型难以区分合作行为和信任，阻碍了对信任及其在社会困境中作用的测量和确定。

Method: 将信任形式化为一种认知捷径，在重复博弈中，当观察到合作伙伴的合作水平达到某个阈值时，便停止对其行为的检查。分析了基于信任的策略在两人对称社会困境博弈中的演化。

Result: 当检查他人行为的成本较高时（如现实世界中），信任策略在许多社会困境中优于“以牙还牙”等标准互惠策略。信任的存在提高了人群的整体合作水平，尤其是在可能出现意外错误的情况下。即使存在旨在建立和利用信任的策略，信任也能带来好处。

Conclusion: 信任捷径具有个体适应性优势，并为信任促进不同类型社会互动中的合作提供了正式的理论基础。该研究结果对人与人工智能代理之间的互动具有启示意义。

Abstract: Trust is often thought to increase cooperation. However, game-theoretic
models often fail to distinguish between cooperative behaviour and trust. This
makes it difficult to measure trust and determine its effect in different
social dilemmas. We address this here by formalising trust as a cognitive
shortcut in repeated games. This functions by avoiding checking a partner's
actions once a threshold level of cooperativeness has been observed. We
consider trust-based strategies that implement this heuristic, and
systematically analyse their evolution across the space of two-player symmetric
social dilemma games. We find that where it is costly to check whether another
agent's actions were cooperative, as is the case in many real-world settings,
then trust-based strategies can outcompete standard reciprocal strategies such
as Tit-for-Tat in many social dilemmas. Moreover, the presence of trust
increases the overall level of cooperation in the population, especially in
cases where agents can make unintentional errors in their actions. This occurs
even in the presence of strategies designed to build and then exploit trust.
Overall, our results demonstrate the individual adaptive benefit to an agent of
using a trust heuristic, and provide a formal theory for how trust can promote
cooperation in different types of social interaction. We discuss the
implications of this for interactions between humans and artificial
intelligence agents.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [314] [Trustworthy Second-hand Marketplace for Built Environment](https://arxiv.org/abs/2509.04085)
*Stanly Wilson,Kwabena Adu-Duodu,Yinhao Li,Ringo Sham,Yingli Wang,Ellis Solaiman,Charith Perera,Rajiv Ranjan,Omer Rana*

Main category: cs.DC

TL;DR: 该论文提出了一种基于区块链的、面向可持续建筑材料再利用的数字市场，并使用IPFS确保透明度和可追溯性。


<details>
  <summary>Details</summary>
Motivation: 建筑行业面临材料浪费和可持续性方面的严峻挑战，需要创新解决方案来整合自动化、可追溯性和去中心化决策，以实现高效的材料再利用。

Method: 提出一个基于区块链的数字市场，利用IPFS进行透明度和可追溯性，并开发了一个框架来演示该市场的操作流程。

Result: 该市场能够促进可再利用材料的高效和可信交换。

Conclusion: 该市场代表了朝着更可持续的建筑实践迈出的重要一步。

Abstract: The construction industry faces significant challenges regarding material
waste and sustainable practices, necessitating innovative solutions that
integrate automation, traceability, and decentralised decision-making to enable
efficient material reuse. This paper presents a blockchain-enabled digital
marketplace for sustainable construction material reuse, ensuring transparency
and traceability using InterPlanetary File System (IPFS). The proposed
framework enhances trust and accountability in material exchange, addressing
key challenges in industrial automation and circular supply chains. A framework
has been developed to demonstrate the operational processes of the marketplace,
illustrating its practical application and effectiveness. Our contributions
show how the marketplace can facilitate the efficient and trustworthy exchange
of reusable materials, representing a substantial step towards more sustainable
construction practices.

</details>


### [315] [Combining Performance and Productivity: Accelerating the Network Sensing Graph Challenge with GPUs and Commodity Data Science Software](https://arxiv.org/abs/2509.03653)
*Siddharth Samsi,Dan Campbell,Emanuel Scoullos,Oded Green*

Main category: cs.DC

TL;DR: HPEC图挑战赛的基准测试，包括子图同构和匿名网络感知图挑战赛，展示了传统基准测试无法比拟的复杂工作负载。本文提出了一种利用数据科学语言解释GraphBLAS公式的方法，并使用NVIDIA的RAPIDS生态系统等现成ETL工具实现了新的图挑战赛。这种方法在GPU上实现了显著的软件加速，与CPU上的Pandas相比，速度提升了147倍至2185倍。


<details>
  <summary>Details</summary>
Motivation: 传统的HPC基准测试（如LINPACK）无法充分测试HPC系统的硬件和软件组件的复杂工作负载。HPEC图挑战赛旨在解决这一问题，它提供了一系列代表复杂工作负载的基准测试。

Method: 本文提出了一种利用数据科学语言来解释GraphBLAS公式的方法。然后，使用现成的ETL工具（如NVIDIA的RAPIDS生态系统中的cuDF和cupy）实现了匿名网络感知图挑战赛。这使得在没有特定HPC代码的情况下实现显著的软件加速成为可能。

Result: 使用现成的软件RAPIDS cuDF和cupy，在NVIDIA A100 GPU上实现了147倍至509倍的速度提升，在NVIDIA H100 GPU上实现了243倍至1269倍的速度提升，在NVIDIA H200 GPU上实现了332倍至2185倍的速度提升。与在CPU上运行Pandas的相同代码相比，实现了显著的软件加速。

Conclusion: 通过利用数据科学语言和现成的ETL工具（如NVIDIA RAPIDS），可以显著加速HPC图挑战赛等复杂工作负载，而无需专门的HPC编程，并在各种GPU上实现了显著的性能提升。

Abstract: The HPEC Graph Challenge is a collection of benchmarks representing complex
workloads that test the hardware and software components of HPC systems, which
traditional benchmarks, such as LINPACK, do not. The first benchmark, Subgraph
Isomorphism, focused on several compute-bound and memory-bound kernels. The
most recent of the challenges, the Anonymized Network Sensing Graph Challenge,
represents a shift in direction, as it represents a longer end-to-end workload
that requires many more software components, including, but not limited to,
data I/O, data structures for representing graph data, and a wide range of
functions for data preparation and network analysis. A notable feature of this
new graph challenge is the use of GraphBLAS to represent the computational
aspects of the problem statement. In this paper, we show an alternative
interpretation of the GraphBLAS formulations using the language of data
science. With this formulation, we show that the new graph challenge can be
implemented using off-the-shelf ETL tools available in open-source, enterprise
software such as NVIDIA's RAPIDS ecosystem. Using off-the-shelf software,
RAPIDS cuDF and cupy, we enable significant software acceleration without
requiring any specific HPC code and show speedups, over the same code running
with Pandas on the CPU, of 147x-509x on an NVIDIA A100 GPU, 243x-1269X for an
NVIDIA H100 GPU, and 332X-2185X for an NVIDIA H200 GPU.

</details>


### [316] [Distributed Download from an External Data Source in Asynchronous Faulty Settings](https://arxiv.org/abs/2509.03755)
*John Augustine,Soumyottam Chatterjee,Valerie King,Manish Kumar,Shachar Meir,David Peleg*

Main category: cs.DC

TL;DR: 该论文研究了在异步通信网络中，容忍拜占庭故障和崩溃故障的分布式数据检索（DR）模型。


<details>
  <summary>Details</summary>
Motivation: 在分布式数据检索（DR）模型中，设计能够最大限度地提高弹性参数β并最小化任何非故障节点查询次数的协议，特别是在异步通信网络中。

Method: 针对异步通信模型，在拜占庭故障和崩溃故障场景下，分别设计了查询最优的确定性协议和近乎最优的随机化协议。

Result: 在崩溃故障模型下，提出了一种可以容忍任意固定比例（β<1）崩溃故障的查询最优确定性解决方案。在拜占庭故障模型下，针对β≥1/2的情况，将确定性协议的Ω(n)查询复杂度下界扩展到了随机化协议；对于β<1/2的情况，提出了一种查询复杂度接近最优的随机化协议。

Conclusion: 这是首个在异步通信网络中解决分布式数据下载问题的工作，并为不同故障模型和容错比例提供了最优或近乎最优的解决方案。

Abstract: The distributedData Retrieval (DR) model consists of $k$ peers connected by a
complete peer-to-peer communication network, and a trusted external data source
that stores an array $\textbf{X}$ of $n$ bits ($n \gg k$). Up to $\beta k$ of
the peers might fail in any execution (for $\beta \in [0, 1)$). Peers can
obtain the information either by inexpensive messages passed among themselves
or through expensive queries to the source array $\textbf{X}$. In the DR model,
we focus on designing protocols that minimize the number of queries performed
by any nonfaulty peer (a measure referred to as query complexity) while
maximizing the resilience parameter $\beta$.
  The Download problem requires each nonfaulty peer to correctly learn the
entire array $\textbf{X}$. Earlier work on this problem focused on synchronous
communication networks and established several deterministic and randomized
upper and lower bounds. Our work is the first to extend the study of
distributed data retrieval to asynchronous communication networks. We address
the Download problem under both the Byzantine and crash failure models. We
present query-optimal deterministic solutions in an asynchronous model that can
tolerate any fixed fraction $\beta<1$ of crash faults. In the Byzantine failure
model, it is known that deterministic protocols incur a query complexity of
$\Omega(n)$ per peer, even under synchrony. We extend this lower bound to
randomized protocols in the asynchronous model for $\beta \geq 1/2$, and
further show that for $\beta < 1/2$, a randomized protocol exists with
near-optimal query complexity. To the best of our knowledge, this is the first
work to address the Download problem in asynchronous communication networks.

</details>


### [317] [Gathering of asynchronous robots on circle with limited visibility using finite communication](https://arxiv.org/abs/2509.04004)
*Avisek Sharma,Satakshi Ghosh,Buddhadeb Sau*

Main category: cs.DC

TL;DR: 本文提出了一种在 π 可视性模型下，针对有限通信能力 (FCOM) 机器人，在完全异步调度下解决聚集问题的算法，解决了先前工作中机器人运动僵化的问题。


<details>
  <summary>Details</summary>
Motivation: 先前的工作在解决圆周聚集问题时，机器人的可见性受到限制（例如 π/2 或 π 可视性），且通常假设机器人具有刚性运动。本文旨在解决在 π 可视性模型下，具有有限通信能力（FCOM）的机器人，在完全异步调度下，且机器人具有非刚性运动时的聚集问题。

Method: 提出了一种新的算法来解决 π 可视性模型下，具有有限通信能力（FCOM）且运动非刚性的机器人在完全异步调度下的聚集问题。

Result: 成功地解决了在 π 可视性模型下，针对具有有限通信能力（FCOM）和非刚性运动的机器人，在完全异步调度下的聚集问题。

Conclusion: 本文提出的算法能够解决在 π 可视性模型下，具有有限通信能力（FCOM）和非刚性运动的机器人在完全异步调度下的聚集问题，克服了先前研究的局限性。

Abstract: This work addresses the gathering problem for a set of autonomous, anonymous,
and homogeneous robots with limited visibility operating in a continuous
circle. The robots are initially placed at distinct positions, forming a
rotationally asymmetric configuration. The robots agree on the clockwise
direction. In the $\theta$-visibility model, a robot can only see those robots
on the circle that are at an angular distance $<\theta$ from it. Di Luna
\textit{et. al.} [DISC'20] have shown that, in $\pi/2$ visibility, gathering is
impossible. In addition, they provided an algorithm for robots with $\pi$
visibility, operating under a semi-synchronous scheduler. In the $\pi$
visibility model, only one point, the point at the angular distance $\pi$ is
removed from the visibility. Ghosh \textit{et. al.} [SSS'23] provided a
gathering algorithm for $\pi$ visibility model with robot having finite memory
($\mathcal{FSTA}$), operating under a special asynchronous scheduler.
  If the robots can see all points on the circle, then the gathering can be
done by electing a leader in the weakest robot model under a fully asynchronous
scheduler. However, previous works have shown that even the removal of one
point from the visibility makes gathering difficult. In both works, the robots
had rigid movement. In this work, we propose an algorithm that solves the
gathering problem under the $\pi$-visibility model for robots that have finite
communication ability ($\mathcal{FCOM}$). In this work the robot movement is
non-rigid and the robots work under a fully asynchronous scheduler.

</details>


### [318] [Counterfactual simulations for large scale systems with burnout variables](https://arxiv.org/abs/2509.04038)
*Benjamin Heymann*

Main category: cs.DC

TL;DR: 为具有“燃尽”变量的大规模系统引入一种新的基于“不确定性放松”的算法，以实现高效的并行反事实估计。


<details>
  <summary>Details</summary>
Motivation: 模拟具有“燃尽”变量（在满足特定条件时会不可逆转地停用的状态变量）的大规模系统的“假设”场景在计算上成本高昂，因为替代轨迹通常需要顺序处理，这会严重影响可扩展性。这在线广告等领域尤为突出，因为存在广告系列预算问题。

Method: 引入一种基于“不确定性放松”的新型算法，该算法能够实现高效的并行计算。

Result: 该方法显著提高了具有“燃尽”变量的系统进行反事实估计的可扩展性。

Conclusion: 所提出的基于“不确定性放松”的算法能够高效地进行并行计算，从而提高具有“燃尽”变量的系统进行反事实估计的可扩展性。

Abstract: We consider large-scale systems influenced by burnout variables - state
variables that start active, shape dynamics, and irreversibly deactivate once
certain conditions are met. Simulating what-if scenarios in such systems is
computationally demanding, as alternative trajectories often require sequential
processing, which does not scale very well. This challenge arises in settings
like online advertising, because of campaigns budgets, complicating
counterfactual analysis despite rich data availability. We introduce a new type
of algorithms based on what we refer to as uncertainty relaxation, that enables
efficient parallel computation, significantly improving scalability for
counterfactual estimation in systems with burnout variables.

</details>


### [319] [LowDiff: Efficient Frequent Checkpointing via Low-Cost Differential for High-Performance Distributed Training Systems](https://arxiv.org/abs/2509.04084)
*Chenxuan Yao,Yuchong Hu,Feifan Liu,Zhengyu Liu,Dan Feng*

Main category: cs.DC

TL;DR: LowDiff框架通过重用压缩梯度作为差分检查点来降低分布式深度学习模型训练的成本，并采用批量梯度写入优化和动态调整策略来提高效率，实现了高频率检查点而runtime overhead低。


<details>
  <summary>Details</summary>
Motivation: 大规模深度学习模型分布式训练常因故障中断，需要检查点恢复，但频繁检查点会产生高昂成本并影响训练性能。现有差分检查点技术局限于推荐系统，通用性不足。

Method: 提出LowDiff框架，通过重用压缩梯度作为差分检查点，结合批量梯度写入优化和动态调整检查点频率及批量大小的策略来降低成本并提高效率。进一步通过层级梯度重用、快照方法和基于CPU的异步持久化策略，实现了无需梯度压缩的高频检查点。

Result: 在多种工作负载下，LowDiff实现的检查点频率可达每迭代一次，runtime overhead低于3.1%。

Conclusion: LowDiff框架通过创新的梯度重用和优化策略，有效解决了分布式训练中高频检查点带来的成本和性能问题，显著降低了runtime overhead。

Abstract: Distributed training of large deep-learning models often leads to failures,
so checkpointing is commonly employed for recovery. State-of-the-art studies
focus on frequent checkpointing for fast recovery from failures. However, it
generates numerous checkpoints, incurring substantial costs and thus degrading
training performance. Recently, differential checkpointing has been proposed to
reduce costs, but it is limited to recommendation systems, so its application
to general distributed training systems remains unexplored.
  This paper proposes LowDiff, an efficient frequent checkpointing framework
that \textit{reuses} compressed gradients, serving as differential checkpoints
to reduce cost. Furthermore, LowDiff incorporates a batched gradient write
optimization to persist these differentials to storage efficiently. It also
dynamically tunes both the checkpoint frequency and the batching size to
maximize performance. We further enhance LowDiff with a layer-wise gradient
reusing and snapshotting approach and a CPU-based asynchronous persistence
strategy, enabling frequent checkpointing without gradient compression.
Experiments on various workloads show that LowDiff can achieve checkpointing
frequency up to per iteration with less than 3.1\% runtime overhead.

</details>


### [320] [On the impact of unlimited computational power in OBLOT: consequences for synchronous robots on graphs](https://arxiv.org/abs/2509.04383)
*Serafino Cicerone,Alessia Di Fonso,Gabriele Di Stefano,Alfredo Navarra*

Main category: cs.DC

TL;DR: OBLOT模型中的机器人被假设为弱能力机器人，但本文证明了无限计算能力对解决OBLOT模型中的问题有显著影响，并提供了一个最优算法。


<details>
  <summary>Details</summary>
Motivation: OBLOT模型中的机器人能力有限，设计分布式算法具有挑战性。以往的研究忽略了机器人的计算能力，主要关注移动和轮次。本文旨在探讨计算能力对OBLOT模型的影响。

Method: 通过利用无限计算能力，为同步机器人在有限图上提供一个解决广泛问题的确定性算法，并保证最少的移动和轮次。

Result: 提供了一个能够保证最少移动和轮次的确定性算法，解决了OBLOT模型中的一类问题。

Conclusion: 无限计算能力对OBLOT模型中的机器人任务解决能力有显著影响，可以设计出最优算法。

Abstract: The OBLOT model has been extensively studied in theoretical swarm robotics.
It assumes weak capabilities for the involved mobile robots, such as they are
anonymous, disoriented, no memory of past events (oblivious), and silent. Their
only means of (implicit) communication is transferred to their positioning,
i.e., stigmergic information. These limited capabilities make the design of
distributed algorithms a challenging task. Over the last two decades, numerous
research papers have addressed the question of which tasks can be accomplished
within this model. Nevertheless, as it usually happens in distributed
computing, also in OBLOT the computational power available to the robots is
neglected as the main cost measures for the designed algorithms refer to the
number of movements or the number of rounds required. In this paper, we prove
that for synchronous robots moving on finite graphs, the unlimited
computational power (other than finite time) has a significant impact. In fact,
by exploiting it, we provide a definitive resolution algorithm that applies to
a wide class of problems while guaranteeing the minimum number of moves and
rounds.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [321] [From Qubits to Qumodes: Information Capacity of Anyonic Excitations](https://arxiv.org/abs/2509.03546)
*Satish Prajapati*

Main category: cond-mat.mes-hall

TL;DR: 量子态的最大信息容量可以通过Haldane排他性统计来描述，并与费米子和玻色子极限进行插值。对于分数量子霍尔态，我们预测了2比特容量，这可以通过量子点光谱中的四个不同量子化电导平台来观察。


<details>
  <summary>Details</summary>
Motivation: 本文旨在推导受Haldane排他性统计支配的量子态的最大信息容量。

Method: 推导了量子态的最大信息容量S_max(g) = log2(⌊1/g⌋ + 1)，并将其与费米子和玻色子极限进行比较。研究了ν = 1/3分数量子霍尔态下的情况。

Result: 得出了S_max(g) = log2(⌊1/g⌋ + 1)的公式。预测ν = 1/3分数量子霍尔态具有2比特容量，并提出了通过量子点光谱中的四个不同量子化电导平台来观察此现象。

Conclusion: 推导出的最大信息容量公式可以连续地插值费米子和玻色子极限。分数量子霍尔态下的预测结果为任何子统计提供了直接的实验信号。

Abstract: The interplay between quantum statistics and information encoding is a
cornerstone of quantum physics. Here, the maximum information capacity of a
quantum state governed by Haldane's exclusion statistics is derived. The
capacity, defined by the maximum von Neumann entropy of its occupancy
distribution, follows S_max(g) = log2(\lfloor 1/g \rfloor + 1). This result
continuously interpolates between the fermionic limit of a single qubit (g = 1)
and the bosonic limit of a continuous-variable qumode (g -> 0). For the nu =
1/3 fractional quantum Hall state (g = 1/3), we predict a 2-bit capacity,
observable as four distinct quantized conductance plateaus in quantum dot
spectroscopy, providing a direct signature of anyonic statistics.

</details>


### [322] [Exchange tensors, generalized RKKY interactions, and magnetization dynamics in heterostructures of ferromagnets and topological insulators](https://arxiv.org/abs/2509.03572)
*Christian Svingen Johnsen,Asle Sudbø*

Main category: cond-mat.mes-hall

TL;DR: 研究了铁磁（FM）层与三维拓扑绝缘体（TI）界面的磁性异质结构，推导了由TI表面态介导的有效RKKY交换相互作用，并考虑了自旋动量锁定和各向异性自旋磁化率。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是理论分析铁磁层与拓扑绝缘体界面处的磁性相互作用，以理解和利用其中产生的拓扑诱导磁现象。

Method: 通过积出拓扑表面态和计算二阶自旋行列式，推导出由TI表面态介导的有效广义RKKY交换相互作用，并推导了LLG方程和分析了Magnon色散。

Result: 分析表明，TI的自旋轨道耦合与FM层的磁化纹理之间的相互作用会诱导出高度非局域、延迟、手征和类似Dzyaloshinskii-Moriya（DM）的有效自旋哈密顿量贡献。LLG方程中出现了一个与磁化量旋度变化率相关的项，这对于skyrmion动力学至关重要。Magnon色散显示出由TI介导的相互作用引起的修正，包括可调的Magnon能隙，且对可调化学势和界面交换耦合强度敏感。

Conclusion: 研究结果阐明了拓扑诱导的磁现象，并为在具有可调相互作用的TI/FM混合系统中设计外来自旋纹理（如skyrmions和手征畴壁）铺平了道路。

Abstract: We present a comprehensive theoretical analysis of magnetic heterostructures
composed of ferromagnetic (FM) layers interfaced with three-dimensional
topological insulators (TIs). Integrating out the topological surface states
and computing the spin determinant to second order in spins, we derive the
effective generalized Ruderman-Kittel-Kasuya-Yosida (RKKY) exchange
interactions mediated by topological surface states. These interactions
inherently incorporate spin-momentum locking and anisotropic spin
susceptibilities stemming from the Dirac-like dispersion of the TI surface
electrons. The analysis reveals that the interplay between the spin-orbit
coupling intrinsic to the TI and the magnetization texture in the FM layer
induces highly nonlocal and retarded, chiral, and Dzyaloshinskii-Moriya
(DM)-like contributions to the effective spin Hamiltonian. Furthermore, the
spin dynamics is studied through a derivation of the LLG equation for this
problem. The induced interactions renormalize many of the FM's intrinsic
properties, but a term in the LLG equation is induced that is related to the
rate of change of the magnetization's curl, which is relevant to skyrmion
dynamics. The magnon dispersion exhibits modifications due to the TI-mediated
interactions, including tunable magnon gaps, sensitive to a tunable chemical
potential and interfacial exchange coupling strength. The results also apply to
finite temperatures. They elucidate topologically induced magnetic phenomena
and pave the way for engineering exotic spin textures, such as skyrmions and
chiral domain walls, in TI/FM hybrid systems with tunable interactions.

</details>


### [323] [Magic continuum in multi-moiré twisted trilayer graphene](https://arxiv.org/abs/2509.03583)
*Li-Qiao Xia,Aviram Uri,Jiaojie Yan,Aaron Sharpe,Filippo Gaggioli,Nicole S. Ticea,Julian May-Mann,Kenji Watanabe,Takashi Taniguchi,Liang Fu,Trithep Devakul,Jurgen H. Smet,Pablo Jarillo-Herrero*

Main category: cond-mat.mes-hall

TL;DR: 扭曲三层石墨烯中的超晶格调制能够调控电子性质，并发现了反常霍尔效应和超导电性。


<details>
  <summary>Details</summary>
Motivation: 探索电子关联和能带拓扑之间的相互作用，以及双扭曲对电子性质的影响。

Method: 研究了扭曲三层石墨烯器件，分析了晶格弛豫对超晶格结构的影响，并观察了反常霍尔效应和超导电性。

Result: 在螺旋扭曲的超晶格多晶体中观察到反常霍尔效应，在超晶格准晶体中普遍观察到超导电性，其中一部分体系表现出空间调制超导电性。

Conclusion: 揭示了扭曲三层石墨烯中相关相的组织原理，强调了超晶格调制和晶格弛豫的关键作用，并提出了一个更广泛的框架，其中魔幻条件是多维扭曲角度空间中的扩展流形。

Abstract: Moir\'e lattices provide a highly tunable platform for exploring the
interplay between electronic correlations and band topology. Introducing a
second moir\'e pattern extends this paradigm: interference between the two
moir\'e patterns produces a supermoir\'e modulation, opening a route to further
tailor electronic properties. Twisted trilayer graphene generally exemplifies
such a system: two distinct moir\'e patterns arise from the relative twists
between adjacent graphene layers. Here, we report the observation of correlated
phenomena across a wide range of twisted trilayer graphene devices whose twist
angles lie along two continuous lines in the twist-angle parameter space.
Depending on the degree of lattice relaxation, twisted trilayer graphene falls
into two classes: moir\'e polycrystals, composed of periodic domains with
locally commensurate moir\'e order, and moir\'e quasicrystals, characterized by
smoothly varying local moir\'e configurations. In helically twisted moir\'e
polycrystals, we observe an anomalous Hall effect, consistent with topological
bands arising from domains with broken $xy$-inversion symmetry. In contrast,
superconductivity appears generically in our moir\'e quasicrystals. A subset of
these systems exhibits signatures of spatially modulated superconductivity,
which we attribute to the supermoir\'e structure. Our findings uncover the
organizing principles of the observed correlated phases in twisted trilayer
graphene, highlight the critical roles of the supermoir\'e modulation and
lattice relaxation, and suggest a broader framework in which magic conditions
arise not as isolated points but as extended manifolds within the
multi-dimensional twist-angle space of complex moir\'e materials.

</details>


### [324] [Optical selection rules of topological excitons in flat bands](https://arxiv.org/abs/2509.03601)
*Mara Lozano,Hong-Yi Xie,Bruno Uchoa*

Main category: cond-mat.mes-hall

TL;DR: 拓扑激子是具有有限动量空间涡度的电子-空穴对态叠加，其包络波函数由电子能带的拓扑结构决定。本文推导了平带中拓扑激子的光学选择规则，考虑了不同的拓扑双带模型：具有skyrmion赝自旋纹理的哈密顿量家族、单个自旋的展平BHZ模型（具有净陈数）以及展平Haldane模型。我们推导了这三个模型中考虑短程相互作用的选择规则，并考虑了单自旋展平BHZ模型中具有库仑相互作用的激子的非氢谱。


<details>
  <summary>Details</summary>
Motivation: 研究拓扑激子在不同拓扑双带模型中的光学选择规则，特别是考虑短程相互作用以及单自旋展平BHZ模型中的库仑相互作用。

Method: 推导了拓扑激子的光学选择规则，并分析了具有skyrmion赝自旋纹理的哈密顿量家族、展平BHZ模型和展平Haldane模型。特别地，对于单自旋展平BHZ模型，还考虑了库仑相互作用。对于展平Haldane模型，得到了光偏振的相图。

Result: 在具有skyrmion赝自旋纹理的两个平带模型中，所有激子都是亮的，并且与它们耦合的光的旋向由赝自旋纹理的涡度决定。在单自旋展平BHZ模型中，无论相互作用的范围如何，亮的激子都与圆偏振光耦合。在展平Haldane模型中，拓扑激子与椭圆偏振光耦合，并得到了光偏振的相图。

Conclusion: 拓扑激子具有由其拓扑性质决定的特定光学选择规则，这些规则在不同的模型和相互作用下有所不同，并且可以被用来表征材料的拓扑性质。

Abstract: Topological excitons are superpositions of electron-hole pair states with an
envelope wavefunction that has finite vorticity in momentum space, dictated by
the topology of the electronic bands. We derive the optical selection rules for
topological excitons in flat bands, considering different topological two-band
models: a family of Hamiltonians with skyrmion pseudo-spin textures, the
flattened BHZ model for a single spin, which can have a net Chern number, and
the flattened Haldane model. We derive the selection rules for these three
models accounting for short-range interactions. We also consider the
non-hydrogenic spectrum of excitons in the single-spin flattened BHZ model with
Coulomb interactions. We show that for the case of two flat bands with skyrmion
pseudo-spin textures, all excitons are bright, and the handedness of the light
that couples to them is fixed by the vorticity of the pseudo-spin texture. For
the single-spin flattened BHZ model, we show that bright excitons couple to
circularly polarized light, regardless the range of the interactions. In the
flattened Haldane model, we find that topological excitons couple to
elliptically polarized light. We obtain the phase diagram for the polarization
of light in this model as a function of the microscopic parameters of the
Hamiltonian.

</details>


### [325] [Coherent control of thermoelectric performance via engineered transmission functions in multi-dot Aharonov-Bohm heat engine](https://arxiv.org/abs/2509.03606)
*Sridhar,Salil Bedkihal,Malay Bandyopadhyay*

Main category: cond-mat.mes-hall

TL;DR: 本文研究了利用量子干涉优化多量子点Aharonov-Bohm (AB)热电器件的性能，包括ZT值、功率输出和热力学效率。


<details>
  <summary>Details</summary>
Motivation: 利用量子干涉来优化多量子点AB热电器件的性能。

Method: 使用非平衡格林函数形式主义，通过器件几何、磁通量和点-引线耦合来调控干涉效应，以产生混合传输谱。

Result: 工程化的传输谱能够平衡洛伦兹共振的高效率和类箱式谱的高功率输出，实现接近最优的功率-效率折衷。研究发现，在对称量子点阵列中，当t/γ ≈ 2时，功率和效率达到最佳平衡。六点六点配置在稀释温度下ZT值达到30，四点几何结构达到卡诺效率的76%，输出功率为4.74 fW。高ZT区域与Wiedemann-Franz定律的最大违反直接对应。源-漏耦合不对称性进一步提高了效率和功率。标度分析表明，效率随量子点数量的增加而系统性增加，而功率输出在中间系统尺寸下最大化。

Conclusion: 多量子点纳米结构中的相干控制为高性能量子热电器件在超低功耗电子学应用中提供了一条有前途的途径。

Abstract: We theoretically investigate strategies for harnessing quantum interference
to optimize the figure of merit $ZT$, power output, and thermodynamic
efficiency in multi-quantum-dot Aharonov-Bohm (AB) thermoelectric heat engines.
Using the non-equilibrium Green function formalism, we show that interference
effects such as Fano-type asymmetries, Dicke-like superradiant and subradiant
modes, and multi-peaked transmission spectra can be tailored through device
geometry, magnetic flux, and dot-lead coupling to produce hybrid transmission
profiles that combine Lorentzian, boxcar, and Fano lineshapes. Such engineered
profiles enable configurations that balance the high efficiency of sharp
Lorentzian resonances with the high power output of boxcar-like spectra,
yielding near-optimal power-efficiency trade-offs. For symmetric quantum-dot
arrays in square, pentagonal, and hexagonal configurations, we identify an
optimal regime, $t/\gamma \approx 2$, where the interdot tunneling amplitude
$t$ and the dot-lead coupling $\gamma$ yield the best balance of power and
efficiency. A hexagonal six-dot configuration achieves $ZT \sim 30$ at dilution
temperatures, while the four-dot geometry reaches about $76\%$ of Carnot
efficiency with output power $4.74$ fW. We also find a direct correspondence
between the high-$ZT$ regime and maximal violation of the Wiedemann-Franz law.
Introducing source-drain coupling asymmetry further enhances both efficiency
and power. A scaling analysis reveals that efficiency systematically increases
with the number of quantum dots, whereas power output is maximized at
intermediate system sizes. These findings establish coherent control in
multi-dot nanostructures as a promising pathway toward high-performance quantum
thermoelectric heat engines for ultralow-power electronics applications.

</details>


### [326] [Three-channel charge Kondo model at high transparency](https://arxiv.org/abs/2509.03612)
*Nicolas Paris,Nicolas Dupuis,Christophe Mora*

Main category: cond-mat.mes-hall

TL;DR: 本研究采用函数重整化群方法研究了高接触透明度下的量子岛与三个量子霍尔边缘通道耦合模型，揭示了非微扰固定点的低能物理性质，并获得了线性电导和杂质熵的普适能量交叉。研究结果与三通道Kondo模型一致，并对相互作用的导电通道进行了分析。


<details>
  <summary>Details</summary>
Motivation: 研究高接触透明度下量子岛与三个量子霍尔边缘通道耦合模型的低能物理性质，并探索函数重整化群方法在解决此类量子杂质问题上的效率。

Method: 使用函数重整化群（FRG）方法，分析量子岛与三个量子霍尔边缘通道耦合模型的低能物理，重点关注高接触透明度下的非微扰固定点，并推导出线性电导和杂质熵的普适能量交叉。

Result: 在高接触透明度下，量子岛与三个量子霍尔边缘通道耦合模型由一个非微扰固定点控制，实现了线性电导和杂质熵的普适能量交叉。研究结果与三通道Kondo模型一致，并发现了随着Luttinger参数K的变化，相互作用导电通道存在一族固定点。

Conclusion: 函数重整化群方法是解决量子杂质问题（尤其是在标准方法失效的区域）的有效工具。本研究在高接触透明度下对量子岛-量子霍尔系统进行了分析，并对相互作用导电通道进行了研究，为理解量子杂质模型提供了新的视角。

Abstract: Quantum impurity models involving a localized charge that is weakly coupled
to electronic leads usually map to Kondo-like Hamiltonians that exhibit various
quantum critical behaviors. Here, we address the opposite regime of high
contact transparency by solving the model of a quantum island coupled to three
quantum Hall edge channels. Using a functional renormalization group (FRG)
approach, we demonstrate that the low-energy physics is controlled by a
nonperturbative fixed point. The universal energy crossover in both the linear
conductance and the impurity entropy is obtained. We reproduce the
zero-frequency conductance and the leading low-energy exponent of the
three-channel Kondo model, confirming their universality across all
transparencies. For interacting leads -- a model that continuously connects to
the pseudo-gap Kondo model at low transparency -- we find a line of fixed
points as the Luttinger parameter $K$, which encodes the strength of the
interactions, changes. Our work demonstrates that FRG methods are an efficient
tool for solving quantum impurity problems in regimes where standard approaches
fail.

</details>


### [327] [Topological edge states in a double isomeric Class-II oligo(indenoindene)](https://arxiv.org/abs/2509.03618)
*Ricardo Ortiz*

Main category: cond-mat.mes-hall

TL;DR: OInIn类别的II类异构体可作为无相互作用体系的紧束缚链，并表现出SSH模型所描述的拓扑保护的电子态。


<details>
  <summary>Details</summary>
Motivation: 研究一维多自由基共轭体系（OInIn）中的非平凡物理现象。

Method: 计算了OInIn的无相互作用带结构，并采用不受自旋限制的平均场Hubbard和密度泛函理论进行了计算。

Result: 计算出的无相互作用带结构显示出与纯异构体相比，带隙增大，并根据终止方式在带隙内出现局域态，同时存在非零的Zak相位。不受自旋限制的平均场Hubbard和密度泛函理论计算表明，在五元环处存在反铁磁未淬灭的局域磁矩，并且存在与终止方式相关的强边缘局域化。

Conclusion: OInIn体系表现出非平庸拓扑特性，并证实了SSH物理在其中的应用，同时揭示了其局域磁矩和边缘局域化特性。

Abstract: I report the theoretical prediction of non-trivial physics in a one
dimensional multiradical system consisting in fused six and five membered
${\pi}$-conjugated carbon rings, known as oligo(indenoindene) (OInIn).
Topologically protected electronic states may emerge in fermionic chains if
there is an alternation in the coupling of adjacent unpaired electrons, being
described effectively by the Su-Schrieffer-Heeger (SSH) model. Class-II OInIn
isomers act as tight-binding chains in the non-interacting regime, thus we can
expect the emergence of SSH physics in an OInIn produced by the combination of
two isomers that belong to this class. That is the case of the system studied
in this manuscript, whose calculated non-interacting band structure shows a gap
opening compared to the gapless pure isomeric forms, hosting ingap localized
states at the chain termini depending on the termination, and a non-zero Zak
phase that confirms the non-trivial topology. These results were consistent
with spin unrestricted mean-field Hubbard and density functional theory
calculations, showing antiferromagnetic unquenched local magnetic moments at
the pentagons, and strong edge localization depending on the termination. This
work advances in the understanding of the physics of non-alternant multiradical
${\pi}$-conjugated hydrocarbons.

</details>


### [328] [Emergent Rashba spin-orbit coupling in bulk gold with buried network of nanoscale interfaces](https://arxiv.org/abs/2509.03620)
*Shreya Kumbhakar,Banashree Debnath,Tuhin Kumar Maji,Binita Tongbram,Shinjan Mandal,T. Phanindra Sai,T. V. Ramakrishnan,Manish Jain,H. R. Krishnamurthy,Anshu Pandey,Arindam Ghosh*

Main category: cond-mat.mes-hall

TL;DR: 在金中嵌入银纳米颗粒可实现具有体反转对称性的材料中的Rashba效应。


<details>
  <summary>Details</summary>
Motivation: 在保持体反转对称性的体系（例如块体金属）中产生Rashba效应一直是一个挑战。

Method: 通过在块体金中嵌入超小银纳米颗粒来引入和调节Rashba自旋-轨道相互作用（SOI）。通过改变嵌入纳米颗粒的密度来调整Rashba SOI的强度。

Result: 实现了~15 meV.Angstrom的Rashba SOI耦合强度，高于任何已知的全局保持反转对称性的体系，并且自旋-轨道散射率提高了20倍。

Conclusion: 所提出的策略成功地在块体金属中引入了强大的Rashba效应，并提出了电荷转移和极化局域化是增强SOI的原因。

Abstract: The Rashba effect, which plays a crucial role in fundamental materials
physics and potential spintronics applications, has been engineered in diverse
systems, including semiconductor quantum wells, oxide heterostructures,
metallic surfaces, topological insulators, ferroelectrics, etc. However,
generating it in systems that preserve bulk inversion symmetry (BIS), for
example, in bulk metals, has not been possible so far. We demonstrate a unique
strategy to introduce and tune Rashba spin-orbit interaction (SOI) to
unprecedented magnitudes in inversion-symmetric solids, by incorporating
ultra-small silver nanoparticles in bulk gold. The near-identical lattice
constants of Ag and Au allowed dense packing of the Ag/Au hetero-interfaces
without compromising the global BIS. By varying the density of embedded
nanoparticles, we generate Rashba SOI in a bulk metal with a coupling strength
of ~15 meV.Angstrom, higher than any known system preserving BIS globally, and
up to ~20 times increase in the spin-orbit scattering rate. We argue that the
combined effect of charge-transfer at the interfaces and polaronic localization
enhances the SOI.

</details>


### [329] [A One-Particle Density Matrix Framework for Mode-Shell Correspondence: Characterizing Topology in Higher-Order Topological Insulators](https://arxiv.org/abs/2509.03632)
*Miguel F. Martínez,Lucien Jezequel,Jens H. Bardarson,Thomas Klein Kvorning,Julia D. Hannukainen*

Main category: cond-mat.mes-hall

TL;DR: 该研究提出了一种直接从单粒子密度矩阵表征高阶拓扑相的框架，无需哈密顿量。


<details>
  <summary>Details</summary>
Motivation: 需要一种无需哈密顿量即可表征高阶拓扑相的方法。

Method: 扩展了模式-壳层对应关系，将其应用于受手征约束的高斯态，并使用它来诊断拓扑边界模式和体拓扑。

Result: 将该方法应用于具有手征约束的$C_4$对称高阶拓扑绝缘体，表明分数壳层指数意味着该高阶相是固有的。即使存在结构无序，该方法也保持有效。

Conclusion: 模式-壳层对应关系可以推广到具有能隙体谱的相互作用态，为从量子态本身表征高阶拓扑提供了一条实用的途径。

Abstract: We present a framework for characterizing higher-order topological phases
directly from the one-particle density matrix, without any reference to an
underlying Hamiltonian. Our approach extends the mode-shell correspondence,
originally formulated for single-particle Hamiltonians, to Gaussian states
subject to chiral constraints. In this correspondence, the mode index counts
topological boundary modes, while the shell index quantifies the bulk topology
in a surrounding region, providing a bulk-boundary diagnostic. In
one-dimensional topological insulators, the shell index reduces to the local
chiral marker, recovering the winding number in the translation-invariant
limit. We apply the mode-shell correspondence to a $C_4$-symmetric higher-order
topological insulator with a chiral constraint and show that a fractional shell
index implies that the higher-order phase is intrinsic. The one-particle
density matrix is formulated in real space, so the mode-shell correspondence
applies to models without translation invariance. By introducing structural
disorder into the $C_4$-symmetric higher-order insulator, we show that the
mode-shell correspondence remains a meaningful diagnostic in the amorphous
limit. The mode-shell correspondence generalizes to interacting states with a
gapped bulk spectrum in the one-particle density matrix, providing a practical
and diverse route to characterize higher-order topology from the quantum state
itself.

</details>


### [330] [Double quantum dots with quenched charging energy in PbTe nanowires](https://arxiv.org/abs/2509.03706)
*Seth Byard,Maksim Gomanko,Adam Raynolds,Susheng Tan,Tongxie Zhang,Shixiong Zhang,Sergey M. Frolov*

Main category: cond-mat.mes-hall

TL;DR: 本研究使用静电栅极在半导体PbTe纳米线器件中构建双量子点，并通过输运测量获得清晰的电荷稳定性图谱。


<details>
  <summary>Details</summary>
Motivation: 研究双量子点在半导体PbTe纳米线器件中的行为，并探索其在量子计算中的应用潜力。

Method: 通过输运测量获得电荷稳定性图谱，并研究高偏压下磁场对量子点行为的影响。

Result: 发现了配对三重点之间几乎无分离以及在零磁场下所有输运共振的自旋简并。在高偏压下，观察到四重分裂，证明了自旋简并的解除。同时识别出高偏压三角形中的窄输运共振模式。

Conclusion: 研究结果向实现基于PbTe的自旋量子比特迈进了一步。

Abstract: We investigate double quantum dots defined by electrostatic gating in
semiconductor PbTe nanowire devices. We perform transport measurements to
obtain charge stability diagrams distinguished by negligible separation between
paired triple points and by the spin degeneracy of all transport resonances at
zero magnetic field. We show a fourfold splitting of high-bias stability
diagram triangles in an applied magnetic field to illustrate the lifting of
this spin degeneracy. We also identify patterns of narrow transport resonances
in these high-bias triangles and discuss their possible physical origins. Our
results represent a step towards the realization of PbTe-based spin qubits.

</details>


### [331] [Plasmons in a network of topological states in twisted bilayer graphene](https://arxiv.org/abs/2509.03781)
*Brian S. Vermilyea,Michael M. Fogler*

Main category: cond-mat.mes-hall

TL;DR: 双层石墨烯中的表面等离激元在三角网络中具有类周期性的频散，并在高对称点不衰减。


<details>
  <summary>Details</summary>
Motivation: 研究包含部分位错三角网络的双层石墨烯中的表面等离激元。

Method: 通过在网络链路上求解电荷动力学的经典运动方程，并使用节点阻抗边界条件，来计算等离激元色散。

Result: 等离激元能带结构在频率上是类周期性的，并且除了在莫尔布里渊区的高对称点之外，处处 are damped。

Conclusion: 提出的网络形式主义与传统的随机相位近似进行了比较，并讨论了各自的适用性。此外，还计算了由局部散射体激发等离激元波，以模拟太赫兹纳米成像实验。

Abstract: We study surface plasmons in minimally-twisted bilayer graphene that contains
a triangular network of partial dislocations (or AB-BA domain walls) hosting
one-dimensional electronic states. We calculate plasmon dispersion by solving
classical equations of motion for charge dynamics on the network links with
impedance boundary conditions at the network nodes. The plasmon band structure
is shown to be quasi-periodic in frequency and damped everywhere except at
high-symmetry points of the moir\'e Brillouin zone. We compare our
network-based formalism with the conventional random phase approximation and
discuss when each approach is valid. Calculations of plasmon waves launched by
local scatterers are presented to simulate terahertz nano-imaging experiments.

</details>


### [332] [Spin Splitting Nernst Effect in Altermagnet](https://arxiv.org/abs/2509.03822)
*Xing-Jian Yi,Yue Mao,Xiancong Lu,Qing-Feng Sun*

Main category: cond-mat.mes-hall

TL;DR: Altermagnet 表现出一种新的自旋分裂 Nernst 效应，其中电子在横向方向上因自旋而分离，产生横向自旋流，且该效应不需要自旋轨道耦合或净磁矩。


<details>
  <summary>Details</summary>
Motivation: 该论文提出并研究了 Altermagnet 独特的自旋分裂 Nernst 效应，这是一种在零净磁矩下表现出的自旋分裂能带现象。

Method: 使用非平衡格林函数方法计算了四端 Altermagnet 器件中的自旋相关传输系数，并分析了参数依赖性和对称性。

Result: 成功获得了由纵向温度梯度产生的非零横向自旋流，验证了自旋分裂 Nernst 效应的存在，并发现该效应可以被费米面能量、温度、输运方向和系统尺寸调节。

Conclusion: 自旋分裂 Nernst 效应在 Altermagnet 中被证实，其 $xy$ 和 $yx$ 响应系数相等，且不依赖于自旋轨道耦合或净磁性。

Abstract: Altermagnet is a distinctive magnet phase, which has spin-split energy band
but with zero net magnetic moment. In this paper, we propose that altermagnet
behaves spin splitting Nernst effect: Under a longitudinal temperature
gradient, the electrons with opposite spins tend to split oppositely in the
transverse direction, thus generating a transverse spin current. The spin
splitting Nernst effect is understood from the contribution of the longitudinal
wave vector to the transverse group velocity. Using the nonequilibrium Green's
function method, we calculate the spin-dependent transmission coefficient in
the four-terminal altermagnet device. From the spin-dependent transmission
coefficient, the nonzero transverse spin current from longitudinal temperature
gradient is obtained, and the spin splitting Nernst effect is verified. We
systematically study the parameter dependence of the spin splitting Nernst
effect, while also performing symmetry analysis. The spin splitting Nernst
effect can be easily regulated by Fermi surface energy, temperature, transport
direction, and system size. Furthermore, in altermagnet, the $xy$-response and
$yx$-response spin splitting Nernst coefficients are equal with
$N_{s,xy}=N_{s,yx}$, different from the conventional spin Nernst effect where
they are opposite. Meanwhile, the spin splitting Nernst effect require neither
spin-orbit coupling nor net magnetism.

</details>


### [333] [Thickness-dependent magnon spin transport in antiferromagnetic insulators: Crossover from quasi-three-dimensional to quasi-two-dimensional regimes](https://arxiv.org/abs/2509.03941)
*Mathias Åsan Myhre,Verena Brehm,Thomas Delvaux,Arne Brataas,Alireza Qaiumzadeh*

Main category: cond-mat.mes-hall

TL;DR: 研究了铁磁绝缘体中厚度依赖的磁畴壁自旋输运，发现了从拟三维到拟二维磁畴壁自旋输运的转变，并观察到磁畴壁扩散长度的显著增强。


<details>
  <summary>Details</summary>
Motivation: 受近期在超薄铁磁绝缘体中观察到室温巨磁导率的启发，研究了反铁磁绝缘体（AFI）中厚度依赖的磁畴壁自旋输运。

Method: 使用随机微磁模拟研究了两种磁相（低温单轴易轴相和高温双轴易平面相）下AFI赤铁矿的厚度依赖的磁畴壁自旋输运。

Result: 发现在临界厚度下，磁畴壁自旋输运从拟三维转变为拟二维；在此临界厚度以下，观察到磁畴壁扩散长度的显著增强，这归因于有效磁畴态密度（DOS）的改变。

Conclusion: 理解和控制AFI中长距离磁畴壁自旋输运对于开发下一代自旋电子纳米器件至关重要，尤其是在材料接近二维极限时。

Abstract: Motivated by the recent observation of giant room-temperature magnon spin
conductivity in an ultrathin ferromagnetic insulator [X.-Y. Wei et al., Nat.
Mater. 21, 1352 (2022)], we investigate thickness-dependent magnon spin
transport in thin antiferromagnetic insulators (AFIs). We study the
prototypical AFI hematite, known for its exceptionally low magnetic damping and
two distinct magnetic phases: a low-temperature uniaxial easy-axis phase and a
high-temperature biaxial easy-plane phase. Using stochastic micromagnetic
simulations, we investigate thickness-dependent magnon spin transport across
both magnetic phases. Our results uncover a crossover from
quasi-three-dimensional to quasi-two-dimensional magnon spin transport at a
critical thickness, determined by the frequency or energy of the excited
magnons. Below this critical thickness, we observe a pronounced enhancement in
the magnon diffusion length in both magnetic phases. This rise is attributed to
a change in the effective magnon density of states, reflecting the reduced
phase space available for scattering in the thinner, quasi-two-dimensional
regime. Understanding and controlling long-distance magnon spin transport in
AFIs is crucial for developing next-generation spintronic nanodevices,
especially as materials approach the two-dimensional limit.

</details>


### [334] [Atomic collapse of high-order singular potentials in graphene](https://arxiv.org/abs/2509.03921)
*Yu-Chen Zhuang,Yue Mao,Qing-Feng Sun*

Main category: cond-mat.mes-hall

TL;DR: 石墨烯中的人工原子可以作为探索原子坍塌和设计新型石墨烯纳米器件的平台。本文研究了具有1/r^γ奇点势中无质量狄拉克费米子的行为。与需要超临界电荷Z > Zc的库仑势不同，高阶奇点势（γ > 1）原则上可以用极小的电荷Z诱导原子坍塌。这些势中的原子坍塌态（ACSs）能量大致呈幂次序列排列。一些特殊的ACSs甚至可以存在于体狄拉克点之上，这是库仑势中不存在的。这些发现揭示了无质量狄拉克费米子在不同电荷势中的异常行为，并为未来的实验和石墨烯纳米器件应用提供了指导。


<details>
  <summary>Details</summary>
Motivation: 探索原子坍塌和设计新型石墨烯纳米器件。

Method: 理论研究了具有1/r^γ奇点势中无质量狄拉克费米子的行为。

Result: 高阶奇点势（γ > 1）原则上可以用极小的电荷Z诱导原子坍塌，ACSs能量大致呈幂次序列排列。一些特殊的ACSs甚至可以存在于体狄拉克点之上。

Conclusion: 无质量狄拉克费米子在不同电荷势中表现出异常行为，为实验和石墨烯纳米器件应用提供了指导。

Abstract: Artificial atoms in graphene hosting a series of quasi-bound states can serve
as an excellent platform to explore atomic collapse and become a basis to
design novel graphene nanodevices. We theoretically study behaviors of massless
Dirac fermions in singular potentials with a general form of 1/r^{\gamma}.
Different from the Coulomb potential that demands a supercritical charge Z >
Zc, a high-order singular potential ({\gamma} > 1) is found to in principle
induce atomic collapse with an infinitesimal charge Z. The energies of atomic
collapse states (ACSs) within these potentials are arranged roughly as a power
sequence. We also show that some special ACSs can exist even above the bulk
Dirac point, which cannot appear in the Coulomb potential. These findings
uncover the anomalies of massless Dirac fermions in diverse charge potentials
and provide guidance for further experiments and graphene nanodevice
applications.

</details>


### [335] [Unoccupied bands in the molybdenum dichalcogenides MoS$_2$, MoSe$_2$, and MoTe$_2$](https://arxiv.org/abs/2509.04411)
*J. Jobst,E. E. Krasovskii,R. Ribeiro,T. A. de Jong,C. R. Dean,R. M. Tromp,S. J. van der Molen*

Main category: cond-mat.mes-hall

TL;DR: ANGLE-RESOLVED REFLECTED ELECTRON SPECTROSCOPY (ARRES) DATA FOR MOS2, MOSE2, AND MOTE2 SHOW GOOD AGREEMENT WITH THEORETICAL PREDICTIONS AND REVEAL INTERLAYER RESONANCES DOMINATED BY UNOCCUPIED D-STATES OF CHALCOGEN ATOMS.


<details>
  <summary>Details</summary>
Motivation: THE PAPER AIMED TO ANALYZE THE CHANGES IN ANGLE-RESOLVED REFLECTED ELECTRON SPECTROSCOPY (ARRES) DATA ACROSS THE SERIES OF MOLYBDENUM-BASED TRANSITION METAL DICHALCOGENIDES (TMDs) FROM SULFUR (S) TO SELENIUM (Se) TO TELLURIUM (Te), BY DETERMINING ACCURATE IV-SPECTRA FOR MONOLAYERS AND BULK TMDs AND COMPARING THEM WITH THEORETICAL PREDICTIONS.

Method: THE STUDY UTILIZED ANGLE-RESOLVED REFLECTED ELECTRON SPECTROSCOPY (ARRES) TO OBTAIN IV-SPECTRA FOR MONOLAYER AND BULK MOS2, MOSE2, AND MOTE2. THESE EXPERIMENTAL DATA WERE THEN COMPARED WITH THEORETICAL PREDICTIONS FOR THE UNOCCUPIED BAND STRUCTURE AND SCATTERING DENSITY OF STATES.

Result: GOOD AGREEMENT WAS OBSERVED BETWEEN THE EXPERIMENTAL ARRES DATA AND THEORETICAL PREDICTIONS, PARTICULARLY AT LOWER ENERGIES WHERE INELASTIC EFFECTS ARE MINIMAL. THE STUDY ALSO IDENTIFIED INTERLAYER RESONANCES WHOSE HYBRIDIZATION EFFECTS VARIED WITH LAYER COUNT. THESE RESONANCES, UNLIKE THOSE IN HBN AND GRAPHENE, ARE CHARACTERIZED BY UNOCCUPIED D-STATES OF CHALCOGEN ATOMS.

Conclusion: THE UNOCCUPIED STATES INVESTIGATED IN THIS STUDY ARE CRUCIAL FOR PROCESSES INVOLVING TEMPORARY ELECTRON OCCUPANCY ABOVE THE VACUUM LEVEL, SUCH AS PHOTOEMISSION AND SECONDARY ELECTRON EMISSION EXPERIMENTS. THE FINDINGS PROVIDE VALUABLE INSIGHTS INTO THE ELECTRONIC PROPERTIES OF MOS2, MOSE2, AND MOTE2.

Abstract: We present angle-resolved reflected electron spectroscopy (ARRES) data for
the three molybdenum-based transition metal dichalcogenides (TMDs) \mos, \mose,
and \mote. To follow the changes as the series moves from S to Se to Te in more
detail, we determine accurate IV-spectra for monolayers and bulk TMDs. These
experimental data sets are then compared with theoretical predictions for both
the unoccupied band structure and the scattering density of states. We find
good agreement, especially for lower energies where inelastic effects are
relatively unimportant. Furthermore, we identify a series of interlayer
resonances for which the dependence of the hybridization effects on the layer
count is observed. Although these resonances bear similarity to interlayer
resonances in hBN and graphene, they differ in their character, being dominated
by unoccupied $d$-states of the chalcogen-atoms. The unoccupied states studied
and analyzed here play a key role in all processes that require an electron to
temporarily reside in a state above the vacuum level, such as in photoemission
and secondary electron emission experiments.

</details>


### [336] [Antiferromagnetic superlattices: anisotropic band and spin-valley valve in buckled two-dimensional materials](https://arxiv.org/abs/2509.03923)
*Wei-Tao Lu,Tie-Feng Fang,Qing-Feng Sun*

Main category: cond-mat.mes-hall

TL;DR: 提出了一种基于二维材料的 the buckled hexagonal 结构的反铁磁超晶格（AFSL）


<details>
  <summary>Details</summary>
Motivation: 研究反铁磁邻近效应在AFSL中产生的谷极化行为，并与铁磁邻近效应进行对比。

Method: 通过计算能带结构和电导率来分析反铁磁邻近效应对谷极化和自旋极化的影响，并研究了赝自旋旋转和空间反演操作。

Result: 反铁磁邻近效应能够产生谷极化迷你带和电导，这是铁磁邻近效应所不具备的。在反铁磁邻近和电场作用下，自旋简并和谷简并同时被破坏，导致迷你带和电导在自旋-谷极化上完全极化。反铁磁超晶格由于自旋-轨道耦合（SOC）而表现出高度各向异性的能带结构，平行于周期方向的群速度被显著重整化，而垂直方向的速度则不受影响。SOC的增加使得各向异性更加显著，导致能带变平缓和电子超聚焦。各向异性的方向可以通过调节势和SOC来控制。

Conclusion: 反铁磁超晶格提供了一种工程化各向异性二维材料的新途径，并可作为一种受门电压调控的对称性保护的自旋-谷阀。

Abstract: Antiferromagnetic superlattices (AFSL) are proposed based on the buckled
hexagonal two-dimensional materials, which can be realized by the proximity
effect of the periodically deposited antiferromagnets. It is found that the AF
proximity effect can give rise to valley-polarized minibands and conductance,
which are not held under ferromagnetic proximity. The spin degeneracy and
valley degeneracy are lifted simultaneously in the presence of AF proximity and
electric field. In consequence, both minibands and conductance could be
spin-valley polarized completely in AFSL. The symmetry of spin-valley
polarization is analysed by considering the pseudospin rotation operations and
spatial inversion operations. Furthermore, AFSL also induce a highly
anisotropic band structure due to the spin-orbit coupling (SOC). In particular,
the group velocity parallel to the periodic direction of AFSL is greatly
renormalized, while the velocity perpendicular to the periodic direction
remains unaffected, contrary to that observed in graphene superlattices. With
the increase of SOC, the anisotropy becomes more prominent, leading to
flattened band and electron supercollimation. The direction of anisotropy can
be regulated by adjusting the potential and SOC. These findings offer an
alternative approach to engineering anisotropic two-dimensional materials. As
an application, the AFSL may well work as a symmetry-protected spin-valley
valve easily controlled by the gate voltages.

</details>


### [337] [Topologically protected magnetoresistance by quantum anomalous Hall effect](https://arxiv.org/abs/2509.03929)
*Wei-Tao Lu,Qing-Feng Sun*

Main category: cond-mat.mes-hall

TL;DR: 本文提出了一种基于反铁磁系统量子反常霍尔效应的磁性电阻模型，并展示了其在下一代自旋电子学中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 鉴于反铁磁材料在下一代自旋电子学中的应用潜力，需要开发新的磁性电阻模型。

Method: 提出并研究了一种基于量子反常霍尔效应的反铁磁材料磁性电阻模型，通过调节反铁磁交换场和电场来控制系统的量子自旋霍尔绝缘体（QSHI）和量子反常霍尔绝缘体（QAHI）相变，形成QAHI/QSHI/QAHI结，并操纵其边缘态自旋取向以实现磁性电阻效应。

Result: 成功构建了QAHI/QSHI/QAHI结，并证明了通过调控反铁磁交换场和电场可以改变边缘态自旋取向，形成平行和反平行构型，从而产生显著不同的电导，实现了电可控的磁性电阻效应。该效应具有拓扑不变量保护，对尺寸效应和无序性鲁棒。

Conclusion: 所提出的基于反铁磁材料的量子反常霍尔效应磁性电阻模型是鲁棒且可电控的，为下一代自旋电子器件的开发提供了新的方向。

Abstract: Recently, antiferromagnetic (AF) materials have attracted rapid attention,
because they are considered as outstanding candidates to replace the widely
used ferromagnets in the next generation of spintronics. We propose a
magnetoresistance model based on the quantum anomalous Hall effect in an AF
system, which is protected by the topological Chern number. By regulating the
AF exchange field and an electric field, the system can be controlled between
the quantum spin Hall insulator (QSHI) phases and the quantum anomalous Hall
insulator (QAHI) phases. As a result, a QAHI/QSHI/QAHI junction can be formed.
In the QAHI region, the spin orientation of chiral edge state can be
manipulated by tuning the AF exchange field and the electric field. Therefore,
the spin directions of two QAHIs in the junction can have parallel and
antiparallel configurations. The conductances of two configurations offered by
chiral edge states are significantly different, and this is a magnetoresistance
effect that can be electrically controlled. Because of the topological
invariance, the magnetoresistance plateaus are robust to the size effect and
the disorder.

</details>


### [338] [Two-dimensional Dirac semimetals with tunable edge states](https://arxiv.org/abs/2509.03943)
*Lizhou Liu,Cheng-Ming Miao,Qing-Feng Sun,Ying-Tao Zhang*

Main category: cond-mat.mes-hall

TL;DR: Bilayer-modified BHZ model creates tunable 2D Dirac semimetals with flat bands and Fermi arc edge states.


<details>
  <summary>Details</summary>
Motivation: To theoretically propose a design for two-dimensional Dirac semimetals using a bilayer-modified Bernevig-Hughes-Zhang (BHZ) model.

Method: Introducing new sites into the BHZ model to engineer flat bands at the Fermi energy. In the bilayer system, interlayer coupling separates these flat bands, resulting in two Dirac points. Analyzed the bound nature of the Fermi arc edge state through quantized transmission resonance peaks and tuned Dirac point positions by adjusting interlayer coupling strengths and symmetries.

Result: Engineered flat bands at the Fermi energy, creating two Dirac points in the bilayer system. Confirmed the bound nature of the one-dimensional Fermi arc edge state by quantized transmission resonance peaks. Demonstrated tunability of Dirac point positions via interlayer coupling.

Conclusion: The proposed design successfully creates tunable two-dimensional Dirac semimetals with specific topological properties, offering potential for novel electronic applications.

Abstract: We theoretically propose a design for two-dimensional Dirac semimetals using
a bilayer-modified Bernevig-Hughes-Zhang (BHZ) model. By introducing new sites
into the BHZ model, we engineer flat bands at the Fermi energy. In the bilayer
system, interlayer coupling separates these flat bands, resulting in two Dirac
points that preserve time-reversal and inversion symmetries. Two Dirac points
are connected by a one-dimensional Fermi arc edge state, whose bound nature is
confirmed by quantized transmission resonance peaks. Notably, the position of
the Dirac points can be precisely tuned by adjusting interlayer coupling
strengths and symmetries.

</details>


### [339] [Two-Dimensional Higher-Order Topological Metals](https://arxiv.org/abs/2509.03944)
*Lizhou Liu,Cheng-Ming Miao,Qing-Feng Sun,Ying-Tao Zhang*

Main category: cond-mat.mes-hall

TL;DR: Staggered SOC and in-plane Zeeman fields create topological phases in graphene, including antihelical edge states and higher-order topological metals with corner states.


<details>
  <summary>Details</summary>
Motivation: Investigate the energy band structure and energy levels of graphene with staggered intrinsic spin-orbit coupling and in-plane Zeeman fields.

Method: Analyzed the effects of staggered intrinsic spin-orbit coupling and in-plane Zeeman fields on graphene's electronic properties, including band structure, energy levels, and edge states. Used quantized transport coefficients and a continuum low-energy model to validate findings.

Result: Staggered intrinsic spin-orbit coupling induces bulk band crossover and generates antihelical edge states, leading to topological metallic phases. An in-plane Zeeman field opens a gap in these edge states, creating higher-order topological metals with corner states. The presence of these states was validated in nanoflakes.

Conclusion: Graphene with staggered intrinsic spin-orbit coupling and in-plane Zeeman fields exhibits rich topological phases, including antihelical edge states and higher-order topological metals with corner states, as confirmed by theoretical analysis and simulations.

Abstract: We investigate the energy band structure and energy levels of graphene with
staggered intrinsic spin-orbit coupling and in-plane Zeeman fields. Our study
demonstrates that staggered intrinsic spin-orbit coupling induces bulk band
crossover at the the \( K \) and \( K' \) valleys and generates antihelical
edge states at the zigzag boundaries, resulting in topological metallic phases.
Quantized transport coefficients confirm the existence of these antihelical
edge states. Furthermore, an in-plane Zeeman field, regardless of orientation,
opens a gap in the antihelical edge states while preserving bulk band closure,
leading to higher-order topological metals with corner states. We also validate
the presence of these corner states in nanoflakes with zigzag boundaries and
confirm the metallic phases with crossed bands through a continuum low-energy
model analysis.

</details>


### [340] [Altermagnetism-Induced Parity Anomaly in Weak Topological Insulators](https://arxiv.org/abs/2509.03963)
*Yu-Hao Wan,Qing-Feng Sun*

Main category: cond-mat.mes-hall

TL;DR: 在拓扑绝缘体表面引入纵旋磁性可产生单个无质量狄拉克费米子，并出现宇称异常。通过一个有效的二维晶格模型，研究了由宇称异常引起的输运性质，结果表明在纵旋磁性影响下，弱拓扑绝缘体表面会产生半整数的边缘电流，在有退相干的情况下，霍尔电导率为半量子化值。三维块体模型计算进一步证实了表面纵旋磁性驱动表面霍尔电导率向e^2/2h跃迁。


<details>
  <summary>Details</summary>
Motivation: 探索在弱拓扑绝缘体（TI）表面引入纵旋磁性所产生的宇称异常及其引起的输运性质。

Method: 提出一个有效的二维（2D）晶格模型来描述弱TI表面，并进行层分辨计算（3D slab model）。

Result: 弱TI表面在纵旋磁性影响下会产生半整数的边缘电流，在有退相干的情况下，霍尔电导率达到半量子化值（e^2/2h）。

Conclusion: 表面纵旋磁性驱动表面霍尔电导率向e^2/2h跃迁，将纵旋磁性与量子异常联系起来，并指出弱TI是研究无净磁矩宇称异常的潜在平台。

Abstract: We demonstrate that introducing altermagnetism on the surface of a weak
topological insulator (TI) results in the emergence of a single massless Dirac
fermion, exhibiting a parity anomaly. To explore the transport properties
induced by this parity anomaly, we propose an effective two-dimensional (2D)
lattice model to describe the weak TI surface. This model captures both the
energy spectrum and spin texture of the weak TI surface while reducing
computational complexity. We show that the weak TI surface hosts a half-integer
chiral edge current under the influence of altermagnetism. Additionally, in the
presence of decoherence, the Hall conductance attains a half-quantized value.
Layer-resolved calculations from a 3D slab model further confirm that surface
altermagnetism drives the surface Hall conductance to transition to $e^{2}/2h$,
aligning with calculation from the 2D effective lattice model. Our findings
establish a link between altermagnetism and quantum anomalies, positioning weak
TIs as a potential platform for investigating the parity anomaly without a net
magnetic moment.

</details>


### [341] [Interplay of Altermagnetic Order and Wilson Mass in the Dirac Equation: Helical Edge States without Time-Reversal Symmetry](https://arxiv.org/abs/2509.03969)
*Yu-Hao Wan,Peng-Yi Liu,Qing-Feng Sun*

Main category: cond-mat.mes-hall

TL;DR: 研究三维拓扑绝缘体（3DTI）薄膜与反铁磁（AM）序相互作用


<details>
  <summary>Details</summary>
Motivation: 研究3DTI薄膜与AM序耦合的拓扑性质，特别是产生的边界模式。

Method: 从修改的狄拉克方程出发，分析Wilson质量和反铁磁质量的相互作用如何改变能带拓扑和边界模式。通过量子输运模拟验证。

Result: 发现3DTI/AM异质结构在耦合后会发生拓扑相变，产生新的手性边缘态，即使在有缺陷的情况下也能保持。

Conclusion: 3DTI/AM异质结构是实现和探测无时间反转对称性的手性拓扑边缘输运的可行平台，为量子器件提供新机遇。

Abstract: We investigate topological phases in three-dimensional topological insulator
(3DTI) thin films interfaced with altermagnetic (AM) orders. Starting from a
modified Dirac equation, we elucidate the interplay between the Wilson mass,
arising from lattice regularization, and the altermagnetic mass, and show how
this interplay fundamentally alters the band topology and boundary modes. In
particular, we demonstrate that coupling a 3DTI thin film to AM order induces a
topological phase transition: although the total Chern number remains zero
across the transition, topological helical edge states emerge after the
transition. These helical edge states arise from opposite Chern numbers at
different high-symmetry points, and are distinct from both the chiral edge
states of the quantum anomalous Hall phase and the helical edge states of the
conventional quantum spin Hall states. The quantum transport simulations reveal
robust, quantized nonlocal resistance plateaus associated with these helical
edge states, which persist even under strong potential and magnetic disorder.
Our results establish 3DTI/AM heterostructures as a feasible material platform
for engineering and detecting helical topological edge transport without
time-reversal symmetry, thus expanding the landscape of topological matter and
providing new opportunities for quantum devices.

</details>


### [342] [Band bending and zero-conductance resonances controlled by edge electric fields in zigzag silicene nanoribbons](https://arxiv.org/abs/2509.03991)
*Wei-Tao Lu,Qing-Feng Sun,Hong-Yu Tian,Ben-Hu Zhou,Hong-Mei Liu*

Main category: cond-mat.mes-hall

TL;DR: 巴巴


<details>
  <summary>Details</summary>
Motivation: 研究了在电场作用下锯齿形硅烯纳米带的带结构和输运性质。

Method: 通过施加电场来诱导和控制带弯曲，并分析了边缘态波函数。

Result: 发现反面对称的边缘电场可以诱导带弯曲，最高价带和最低导带共存；对称电场可以产生由内禀自旋-轨道相互作用引起的不对称狄拉克点带隙，形成谷极化量子自旋霍尔状态；并观察到由带弯曲、带选择规则和共振态组合引起的零电导共振和共振峰，可以用法诺共振效应描述；此外，带弯曲和零电导共振对 Hubbard 相互作用具有鲁棒性，Hubbard 相互作用可以作为自旋相关的边缘场，与边缘电场一起导致自旋相关的带隙和多种量子相。

Conclusion: 研究结果为理解和设计基于硅烯纳米带的电子器件提供了理论基础。

Abstract: We study the band structure and transport property of a zigzag silicene
nanoribbon when the electric fields are applied to the edges. It is found that
a band bending could be induced and controlled by the antisymmetric edge
fields, which can be understood based on the wave functions of the edge states.
The highest valence band and the lowest conduction band coexist in the band
bending region. With the narrowing of edge potentials, the bending increases
gradually. When the edge fields become symmetric, an asymmetric band gap at the
Dirac points can be obtained due to the intrinsic spin-orbit interaction,
suggesting a valley polarized quantum spin Hall state. The gap could reach a
maximum value rapidly and then decrease slowly as the electric fields increase.
Due to the combining effect of the band bending, band selective rule, and
resonant states, many zero-conductance resonances and resonance peaks appear in
different regions, which could be described by the Fano resonance effect.
Furthermore, the band bending and zero-conductance resonances are robust
against the Hubbard interaction. The Hubbard interaction could work as a
spin-dependent edge field, together with the edge electric fields, leading to a
spin-dependent band gap and various quantum phases such as metal and
half-metal.

</details>


### [343] [Phase transitions in quantum dot-Majorana zero mode coupling systems](https://arxiv.org/abs/2509.04002)
*Yue Mao,Qing-Feng Sun*

Main category: cond-mat.mes-hall

TL;DR: 量子点-马约拉纳零模耦合系统中的基态相变


<details>
  <summary>Details</summary>
Motivation: 研究量子点-马约拉纳零模（MZM）耦合系统的基态（GS）相变，作为量子点-超导体相变的类似研究，并为MZM相关实验提供新的解释。

Method: 通过改变分子内能级和量子点-MZM耦合强度来研究基态相变，并获得相图（考虑或不考虑Zeeman项）。同时研究了自旋特性和态密度在相变过程中的变化，并采用平均场理论来理解相变性质。

Result: 得到了量子点-MZM耦合系统的基态相图，并分析了自旋特性和态密度在相变过程中的变化。

Conclusion: 量子点-MZM耦合系统存在基态相变，其行为与分子内能级和耦合强度相关，可作为量子点-超导体相变的类似研究，并可能为MZM相关实验提供新的解释。

Abstract: The magnetic doublet ground state (GS) of a quantum dot (QD) could be changed
to a spin-singlet GS by coupling to a superconductor. In analogy, here we study
the GS phase transitions in QD-Majorana zero mode (MZM) coupling systems: GS
behaves phase transition versus intra-dot energy level and QD-MZM coupling
strength. The phase diagrams of GS are obtained, for cases with and without
Zeeman term. Along with the phase transition, we also study the change of spin
feature and density of states. The properties of the phase transition are
understood via a mean-field picture. Our study not only serves as an analogue
to QD-superconductor phase transitions, but also gives alternative explanations
on MZM-relevant experiments.

</details>


### [344] [Electrical control of crossed Andreev reflection and spin-valley switch in antiferromagnet/superconductor junctions](https://arxiv.org/abs/2509.04003)
*Wei-Tao Lu,Qing-Feng Sun*

Main category: cond-mat.mes-hall

TL;DR: 本研究探讨了在电场和反铁磁交换场作用下，硅烯、锗烯和锡烯等材料中反铁磁/超导体（AF/S）和反铁磁/超导体/反铁磁（AF/S/AF）结的亚带隙输运。


<details>
  <summary>Details</summary>
Motivation: 旨在利用反铁磁/超导体结中的自旋-谷极化半金属相，生成纯交叉安德烈夫反射（CAR），并探索其在电场调控下的开关特性。

Method: 通过理论研究反铁磁/超导体（AF/S）和反铁磁/超导体/反铁磁（AF/S/AF）结在电场和反铁磁交换场作用下的亚带隙输运，分析了自旋-轨道耦合导致的自旋-谷极化半金属相的形成及其对CAR过程的影响。

Result: 发现了在宽泛的电场范围内，可以实现纯CAR，且不受局域安德烈夫反射（AR）和弹性隧道效应（EC）的干扰。通过调节电场，可以在纯CAR和纯EC之间实现自旋-谷开关效应。AR和CAR过程的性质强烈依赖于自旋-谷极化态。

Conclusion: 研究结果表明，所提出的器件能够实现CAR过程的电学测量和自旋-谷开关功能，为新型电子器件的设计提供了理论基础。

Abstract: We study the subgap transport through the antiferromagnet/superconductor
(AF/S) and antiferromagnet/superconductor/antiferromagnet (AF/S/AF) junctions
controlled by electric field in a generic buckled honeycomb system, such as
silicene, germanene, and stanene. In the present of electric field and
antiferromagnetic exchange field, the spin-valley polarized half metallic phase
can be achieved in the honeycomb system due to the spin-orbit coupling, which
affords an opportunity to generate the pure crossed Andreev reflection (CAR).
It is found that the pure CAR can be generated without local Andreev reflection
(AR) and elastic cotunneling (EC) over a wide range of electric field. A
spin-valley switch effect can be realized between the pure CAR and the pure EC
by adjusting the electric field. The properties of AR process and CAR process
strongly depend on the spin-valley polarized states. Our results suggest that
the device can implement an electrical measurement of the CAR process and
spin-valley switch.

</details>


### [345] [Orbital hybridization in graphene-based artificial atoms](https://arxiv.org/abs/2509.04012)
*Yue Mao,Hui-Ying Ren,Xiao-Feng Zhou,Hao Sheng,Yun-Hao Xiao,Yu-Chen Zhuang,Ya-Ning Ren,Lin He,Qing-Feng Sun*

Main category: cond-mat.mes-hall

TL;DR: 人工原子中的轨道杂化首次通过改变其形状得以实现，为设计新物质和精确控制量子态开辟了新途径。


<details>
  <summary>Details</summary>
Motivation: 在凝聚态物质形成过程中，原子内轨道杂化和原子间键合是两个基本过程。人工原子作为固态模拟，能够模拟这些过程，但目前仅观察到原子间键合的证据，而原子内轨道杂化仍有待实验验证。

Method: 通过改变人工原子的形状，引入各向异性的限制势，从而在人工原子内部产生具有不同轨道量子数拟合态之间的杂化。

Result: 成功实现了人工原子中的轨道杂化，并通过实验在实空间中直接可视化了这些杂化轨道。数值计算和理论推导也验证了实验结果。

Conclusion: 首次在人工原子中实现了轨道杂化，为设计超越真实原子限制的新型人工物质提供了实验基础，并启发了在更广泛系统中的量子态可控性研究。

Abstract: Intraatomic orbital hybridization and interatomic bond formation are the two
fundamental processes when real atoms are condensed to form matter. Artificial
atoms mimic real atoms by demonstrating discrete energy levels attributable to
quantum confinement. As such, they offer a solid-state analogue for simulating
intraatomic orbital hybridization and interatomic bond formation. Signatures of
interatomic bond formation has been extensively observed in various artificial
atoms. However, direct evidence of the intraatomic orbital hybridization in the
artificial atoms remains to be experimentally demonstrated. Here we, for the
first time, realize the orbital hybridization in artificial atoms by altering
the shape of the artificial atoms. The anisotropy of the confining potential
gives rise to the hybridization between quasibound states with different
orbital quantum numbers within the artificial atom. These hybridized orbits are
directly visualized in real space in our experiment and are well reproduced by
both numerical calculations and analytical derivations. Our study opens an
avenue for designing artificial matter that cannot be accessed on real atoms
through experiments. Moreover, the results obtained inspire the progressive
control of quantum states in diverse systems.

</details>


### [346] [Tunneling Magnetoresistance Effect in Altermagnets](https://arxiv.org/abs/2509.04015)
*Yu-Fei Sun,Yue Mao,Yu-Chen Zhuang,Qing-Feng Sun*

Main category: cond-mat.mes-hall

TL;DR: 提出了一种通用的反铁磁器件，利用隧穿磁阻效应，并研究了其输运性质。


<details>
  <summary>Details</summary>
Motivation: 反铁磁性作为一种非常规磁性材料，为自旋电子学提供了一个新的研究平台，而隧穿磁阻效应是自旋电子学的一个重要研究方面。

Method: 使用非平衡格林函数方法和兰道尔-布特兹公式，结合系统地旋转反铁磁体和自旋取向，研究反铁磁取向对电导和隧穿磁阻比的影响。

Result: 通过调控反铁磁性强度、费米能量以及旋转反铁磁体的取向，隧穿磁阻比可以达到1000%以上。分析了电导和隧穿磁阻比的详细对称关系。

Conclusion: 该方法为基于反铁磁平台的下一代信息技术提供了新的设计理念，为自旋电子学应用的发展铺平了道路。

Abstract: As an unconventional magnet, altermagnetism attracts great interest in
condensed matter physics and applies a new research platform for the
spintronics. Since the tunneling magnetoresistance (TMR) effect is an important
research aspect in spintronics, we theoretically propose a universal
altermagnetic sandwich device to achieve the TMR effect and investigate its
transport properties. Using the nonequilibrium Green's function method and the
Landauer-B\"uttiker formula, we obtain the conductance and the TMR ratio. By
systematically rotating the orientations of the altermagnet and spin, we
investigate how the altermagnetic orientations affect the conductance and the
TMR ratio, and comprehensively demonstrate the dependence of the conductance
and the TMR ratio on a range of parameters in the system. By tuning the
altermagnetism strength and the Fermi energy, as well as rotating the
orientations in the altermagnet, the TMR ratio can reach a value of over 1000%.
In addition, we analyze the detailed symmetry relations of the conductance and
the TMR ratio in our system. Our approach provides a new design concept for the
next-generation information technologies based on the altermagnetic platform,
paving the way for the development of spintronics applications.

</details>


### [347] [Spin-valley polarized edge states and quantum anomalous Hall states controlled by side potential in 2D honeycomb lattices](https://arxiv.org/abs/2509.04017)
*Wei-Tao Lu,Qing-Feng Sun,Yun-Fang Li,Hong-Yu Tian*

Main category: cond-mat.mes-hall

TL;DR: 本论文研究了侧向势场对二维蜂窝状晶格（如硅烯和锗烯）的自旋-轨道耦合效应。


<details>
  <summary>Details</summary>
Motivation: 研究侧向势场对二维蜂窝状晶格的自旋和谷相关电子性质的影响。

Method: 利用紧束缚形式主义，研究了侧向势场（包括势场和交换场）对具有本征自旋-轨道耦合的二维蜂窝状晶格（如硅烯和锗烯）的自旋和谷相关电子性质的影响。

Result: 结果表明，侧向势场能显著影响不同自旋索引的螺旋边缘态，并实现自旋和谷的锁定。通过调节侧向势场和带隙宽度，系统展现了量子自旋-谷霍尔效应、谷极化量子自旋霍尔效应和自旋极化量子反常霍尔效应。此外，由于侧向势场和窄带隙中的边缘态耦合，可以为特定自旋打开带隙，破坏时间反演对称性，形成自旋极化量子反常霍尔相。两种边界形成了各种自旋-谷极化边缘态。

Conclusion: 该研究揭示了侧向势场在调控二维材料电子性质方面的重要作用，并提出利用其实现完美的自旋-谷开关的可能性。

Abstract: Based on the tight-binding formalism, we study the effect of side potential
on the spin and valley related electronic property of $2$D honeycomb lattices
with intrinsic spin-orbit coupling, such as silicene and germanene. The side
potential is composed of potential field and exchange field applied on the
boundaries of the zigzag nanoribbon. It is found that the side potential could
greatly affect the helical edge states with different spin indices and the spin
and valley are locked to each other. By adjusting the side potential and ribbon
width, the system shows quantum spin-valley Hall effect, valley polarized
quantum spin Hall effect, and spin polarized quantum anomalous Hall effect. Due
to the side potential and the coupling of edge states in narrow ribbon, a band
gap could be opened for specific spin and the time-reversal symmetry could be
broken, leading to a spin polarized quantum anomalous Hall phase. Various kinds
of spin-valley polarized edge states are formed at the two boundaries.
Furthermore, the spin-valley polarized insulating states can be used to realize
a perfect spin-valley switch.

</details>


### [348] [Moiré spintronics: Emergent phenomena, material realization and machine learning accelerating discovery](https://arxiv.org/abs/2509.04045)
*Fengjun Zhuo,Zhenyu Dai,Hongxin Yang,Zhenxiang Cheng*

Main category: cond-mat.mes-hall

TL;DR: 二维扭曲范德华材料为探索量子现象和工程化新型二维材料提供了有前景的平台，特别是在二维磁性材料方面，可能在自旋电子学领域带来革命性发展。本篇综述重点介绍了扭曲范德华材料中新兴的摩尔自旋电子学研究进展，包括堆叠相关的层间磁性、非共线自旋结构、摩尔磁交换相互作用、摩尔斯格明子和摩尔磁振子。


<details>
  <summary>Details</summary>
Motivation: 扭曲范德华材料作为探索奇异量子现象和工程化新型二维材料的平台，在自旋电子学领域具有巨大潜力。

Method: 综述了近期在扭曲范德华材料（特别关注二维磁性材料）中新兴的摩尔自旋电子学方面的研究进展，内容涵盖了堆叠相关的层间磁性、非共线自旋结构、摩尔磁交换相互作用、摩尔斯格明子和摩尔磁振子，并讨论了机器学习在加速材料发现和设计中的应用。

Result: 重点介绍了扭曲范德华材料在层间磁性、非共线自旋结构、摩尔磁交换相互作用、摩尔斯格明子和摩尔磁振子等方面的研究进展，并强调了机器学习在材料发现和设计中的潜力。

Conclusion: 总结了该领域面临的挑战和未来的发展机遇。

Abstract: Twisted van der Waals (vdW) materials have emerged as a promising platform
for exploring the exotic quantum phenomena and engineering the novel material
properties in two dimensions, which could bring revolutionary developments in
spintronics. This Review aims at providing an overview of recent progress on
emerging moir\'e spintronics in twisted vdW materials, with a particular focus
on two-dimensional magnetic materials. After a brief introduction to the
general features of twisted vdW materials, we discuss recent theoretical and
experimental studies on stacking-dependent interlayer magnetism, non-collinear
spin textures, moir\'e magnetic exchange interactions, moir\'e skyrmions and
moir\'e magnons. We further highlight the ability to accelerate the discovery
and design multifunctional materials for moir\'e spintronics with the
assistance of machine learning. We conclude with the most pressing challenges
and potential opportunities in this rapidly expanding field.

</details>


### [349] [Two-dimensional magnetic tunnel p-n junctions for low-power electronics](https://arxiv.org/abs/2509.04206)
*Wenkai Zhu,Ziao Wang,Tiangui Hu,Zakhar R. Kudrynskyi,Tong Zhou,Zakhar D. Kovalyuk,Ce Hu,Hailong Lin,Xiaodong Li,Yongcheng Deng,Quanshan Lv,Lixia Zhao,Amalia Patane,Igor Zutic,Houzhi Zheng,Kaiyou Wang*

Main category: cond-mat.mes-hall

TL;DR: 二维材料磁性隧道结实现零偏压自旋电压


<details>
  <summary>Details</summary>
Motivation: 利用二维材料推动电子元件小型化和提高电子效率

Method: 通过高质量铁磁性/半导体界面和半导体p-n结的自旋电子不对称扩散，在磁性隧道结中生成、操控和探测电子自旋，无需施加电压

Result: 在磁性隧道结中观察到巨大的反常零偏压自旋电压，信号超过30,000%，远高于以往的磁阻信号

Conclusion: 该发现为低功耗电子器件中的自旋信息转换和放大提供了新的机遇

Abstract: For decades, semiconductors and their heterostructures have underpinned both
fundamental and applied research across all areas of electronics.
Two-dimensional, 2D (atomically thin) semiconductors have now the potential to
push further the miniaturization of electronic components, enabling the
development of more efficient electronics. Here, we report on a giant anomalous
zero-bias spin voltage in magnetic tunnel junctions based on 2D materials. The
generation, manipulation and detection of electron spin across a
nanometer-thick magnetic tunnel junction do not require any applied bias. It is
achieved by exploiting high-quality ferromagnetic/semiconductor interfaces and
the asymmetric diffusion of spin-up/spin-down electrons across a semiconductor
p-n junction. The large spin-voltage signal exceeds 30,000% and is far greater
than the highest magnetoresistance signals reported to date. Our findings
reveal unexplored opportunities to transform and amplify spin information for
low-power electronics.

</details>


### [350] [Quantum Hall Antidot as a Fractional Coulombmeter](https://arxiv.org/abs/2509.04209)
*Mario Di Luca,Emily Hajigeorgiou,Zekang Zhou,Tengyan Feng,Kenji Watanabe,Takashi Taniguchi,Mitali Banerjee*

Main category: cond-mat.mes-hall

TL;DR: 该研究使用栅极定义的双层石墨烯“防染”结构，通过电导测量来探测分数量子霍尔效应中的准粒子电荷，并首次在石墨烯器件中测量到了 e/3 的分数电荷。


<details>
  <summary>Details</summary>
Motivation: 探测分数量子霍尔效应中的分形带电准粒子，研究其量子特性，并克服现有电子干涉仪因体边相互作用引起的解释复杂性。

Method: 利用栅极定义的双层石墨烯“防染”结构，在库仑主导区操作，通过电导测量研究整数量子霍尔和分数量子霍尔状态下的准粒子隧穿行为。

Result: 栅电压周期和振荡斜率直接揭示了隧穿准粒子的电荷，提供了一种测量石墨烯中分数电荷的实用方法。首次在石墨烯基器件中测量到了 e/3 的分数电荷。

Conclusion: 该研究提供了一种简单且可调的方法，利用“防染”结构测量石墨烯中的分数电荷，并为在其他二维材料中扩展类似测量提供了可能性，确立了“防染”结构作为研究量子霍尔效应的强大平台。

Abstract: The detection of fractionally charged quasiparticles, which arise in the
fractional quantum Hall regime, is of fundamental importance for probing their
exotic quantum properties. While electronic interferometers have been central
to probe their statistical properties, their interpretation is often
complicated by bulk-edge interactions. Antidots, potential hills in the quantum
Hall regime, are particularly valuable in this context, as they overcome the
geometric limitations of conventional designs and act as controlled impurities
within a quantum point contact. Furthermore, antidots allow for quasiparticle
charge detection through straightforward conductance measurements, replacing
the need for more demanding techniques. In this work, we employ a gate-defined
bilayer graphene antidot operating in the Coulomb-dominated regime to study
quasiparticle tunneling in both integer and fractional quantum Hall states. We
show that the gate-voltage period and the oscillation slope directly reveal the
charge of tunneling quasiparticles, providing a practical method to measure
fractional charge in graphene. Moreover, we report the first measurement of the
$e/3$ fractional charge in a graphene-based device. The simplicity and
tunability of this design open a pathway to extend AD-based charge measurements
to other van der Waals materials, establishing antidots as a powerful and
broadly applicable platform to study the quantum Hall effect.

</details>


### [351] [Many-Body Rashba Spin-Orbit Interaction and Exciton Spin Relaxation in Atomically Thin Semiconductor Structures](https://arxiv.org/abs/2509.04285)
*Henry Mittenzwey,Andreas Knorr*

Main category: cond-mat.mes-hall

TL;DR: 提出了一个新的自旋-轨道相互作用机制，该机制可以解释单层过渡金属二硫化物 (TMDC) 中由局部电场引起的激子自旋弛豫，特别是在 MoSe$_2$ 中，弛豫时间短于皮秒。


<details>
  <summary>Details</summary>
Motivation: 需要探索新的自旋-轨道相互作用机制来解释单层过渡金属二硫化物 (TMDC) 中激子自旋弛豫的现象。

Method: 建立了描述激子自旋弛豫的介观多粒子 Rashba 哈密顿量，并考虑了由介电环境的空间不对称性引起的局部电场。

Result: 在单层 MoSe$_2$ / SiO$_2$ 衬底上，观察到 meV 量级的亮-暗激子分裂，并且由局部电场引起的快自旋弛豫时间短于皮秒。对于其他具有更大亮-暗分裂的 TMDC，该效应可忽略不计。

Conclusion: 提出的自旋-轨道相互作用机制可以有效地解释 MoSe$_2$ 中观察到的快速激子自旋弛豫现象，这对于理解和利用 TMDC 材料的光自旋性质具有重要意义。

Abstract: We propose a previously unexplored spin-orbit interaction mechanism by
establishing a mesoscopic many-particle Rashba Hamiltonian. In lowest order,
this Hamiltonian self-consistently describes exciton spin relaxation in
monolayer transition metal dichalcogenides (TMDC) due to local electric fields
caused by spatial asymmetries in the dielectric environment. For a monolayer
MoSe$_2$ on a SiO$_2$ substrate above 77\,K showing a meV bright-dark
splitting, the local electric field causes fast intravalley spin relaxation on
a sub-picosecond timescale, whereas it is negligible for other TMDCs with
larger bright-dark splitting.

</details>


### [352] [Specific features of the $π$-electron spectrum of narrow achiral $(2m,m)$ nanoribbons](https://arxiv.org/abs/2509.04306)
*Lyuba Malysheva*

Main category: cond-mat.mes-hall

TL;DR: Graphene nanoribbons made of pyrene molecules exhibit local states in their electron spectrum, unlike linear acenes.


<details>
  <summary>Details</summary>
Motivation: To investigate the tight-binding eigenvalue problem for pyrene molecule sequences forming a (2m,m) graphene nanoribbon and analyze the properties of its dispersion relation and electron states.

Method: Using a Su-Schrieffer-Heeger-Hückel-type Hamiltonian, analyze the dispersion relation and electron density distribution for extended and local electronic states. Derive explicit analytic expressions for the Green's function coefficients.

Result: The $\pi$-electron spectrum of the pyrene oligomer includes local states, in contrast to linear acenes which only have extended states. The paper illustrates the difference in electron density distribution between local and extended states and presents analytic expressions for Green's function coefficients.

Conclusion: Pyrene-based graphene nanoribbons possess unique electronic properties, including the presence of local states, which distinguishes them from linear acenes and opens avenues for potential electronic applications.

Abstract: On the basis of the Su-Schrieffer-Heeger-H\"uckel-type Hamiltonian, we
consider the tight-binding eigenvalue problem for a sequence of pyrene
molecules forming a narrow $(2m,m)$ graphene nanoribbon. Specific features of
the corresponding dispersion relation are analyzed and illustrated with several
examples. It is shown that the $\pi$-electron spectrum of the pyrene oligomer
includes local states, in contrast to the spectrum of linear acene, which
consists only of extended states. We analyze and illustrate the difference in
the behavior of
  the electron density distribution for extended and local electronic states.
Explicit analytic expressions for the Green's function coefficients of the
pyrene molecule are also presented.

</details>


### [353] [In-situ profiling of pressure-induced exciton traps in suspended MoS$_2$ monolayers](https://arxiv.org/abs/2509.04319)
*Leonard Geilen,Lukas Schleicher,Alexander Musta,Benedict Brouwer,Eva M. Weig,Alexander Holleitner,Anne Rodriguez*

Main category: cond-mat.mes-hall

TL;DR: 我们演示了在具有纳米结构孔洞的衬底上悬浮的 MoS2 纳米薄膜的原位读出空间轮廓。


<details>
  <summary>Details</summary>
Motivation: 悬浮的 MoS2 纳米薄膜可以作为具有可调发光强度和能量的激子陷阱，通过控制环境压力可以实现这种可调性。

Method: 通过法布里-珀罗干涉和相应的反射对比度图模型进行原位读出。

Result: 可以控制衬底上数百个悬浮的 MoS2 纳米薄膜。

Conclusion: 提出的方法可以有效地原位读出和调控悬浮 MoS2 纳米薄膜的光学性质。

Abstract: We demonstrate the in-situ read-out of the spatial profile of suspended
MoS$_2$ monolayers hosted on substrates with nano-structured holes. As the
profiles are spatially bent, the suspended MoS$_2$ monolayers act as exciton
traps with tunable luminescence intensity and energy. The tunability is
realized by controlling the environmental pressure on the monolayers, which
allows to control hundreds of suspended MoS$_2$ monolayers on a single
substrate. The in-situ read-out is based on Fabry-P\'erot interferences and a
model of the corresponding reflectance contrast maps of the investigated
monolayers.

</details>


### [354] [Zero and Nonzero Energy Majorana Modes in an Extended Kitaev Chain](https://arxiv.org/abs/2509.04420)
*Mohammad Ghuneim,Raditya Weda Bomantara*

Main category: cond-mat.mes-hall

TL;DR: 本文研究了具有三个亚晶格单元的扩展Kitaev链，通过将具有三聚体单元的修改版Su-Schrieffer-Heeger模型与标准Kitaev链杂化，得到了六聚体结构。研究发现，亚晶格构型和p波超导配对之间的相互作用导致了超越预期Majorana零模的丰富边缘模式结构。这些Majorana边缘模式对某些通用微扰和无序表现出相当大的鲁棒性。稳健的、超越零能量变化的Majorana边缘模式的存在，可能为在实验中明确检测Majorana模式的持续努力提供一步。


<details>
  <summary>Details</summary>
Motivation: 研究具有三个亚晶格单元的扩展Kitaev链，探索其边缘模式的丰富结构和鲁棒性。

Method: 将具有三聚体单元的修改版Su-Schrieffer-Heeger模型与标准Kitaev链进行杂化，得到六聚体结构，并研究亚晶格构型和p波超导配对的相互作用。

Result: 获得了超越预期Majorana零模的丰富边缘模式结构，并发现这些模式对某些通用微扰和无序表现出相当大的鲁棒性。

Conclusion: 稳健的、超越零能量变化的Majorana边缘模式的存在，可能为在实验中明确检测Majorana模式的持续努力提供一步。

Abstract: This paper studies an extended Kitaev chain with three sublattices per unit
cell. This extended version is obtained by hybridizing a modified
Su-Schrieffer-Heeger model featuring trimerized unit cells with the standard
Kitaev chain, resulting in a hexamer structure on the Majorana basis. Due to
the interplay between the sublattice configuration and the $p$-wave
superconducting pairing, a rich structure of edge modes beyond the expected
Majorana zero modes is obtained. The various Majorana edge modes are further
found to demonstrate considerable robustness against some generic perturbations
and disorder. The presence of robust Majorana edge modes beyond their zero
energy variations potentially offers a step forward in the ongoing efforts to
unambiguously detect Majorana modes in experiments.

</details>


### [355] [Zero modes and index theorems for non-Hermitian Dirac fermions](https://arxiv.org/abs/2509.04447)
*Bitan Roy*

Main category: cond-mat.mes-hall

TL;DR: 该论文将Aharonov-Casher和Jackiw-Rebbi/Rossi指数定理推广到洛伦兹不变的非厄米狄拉克算子，发现并研究了其零能陈述态。


<details>
  <summary>Details</summary>
Motivation: 将经典的狄拉克费米子零能束缚态研究推广到非厄米系统，探索非厄米狄拉克算子的性质和应用。

Method: 通过在传统的狄拉克哈密顿量中添加一个类质量反厄米算子来构造非厄米狄拉克算子，并求解零能束缚态的显式解。

Result: 在磁场存在下，当系统包含有限数量的磁通量量子时，零能束缚态总是存在。在空间上非平凡的质量序存在的情况下，仅当非厄米狄拉克费米子的有效费米速度为实数时，才能在频谱中找到局域化的零能束缚态。

Conclusion: 研究结果为在非厄米或开放狄拉克系统中从拓扑鲁棒的零能流形中产生竞争序提供了具体途径，并讨论了可能的实验验证方案。

Abstract: Dirac fermions, subject to external magnetic fields and in the presence of
mass orders that assume topologically nontrivial spatial textures such as
domain-wall and vortices, for example, bind robust mid-gap states at
zero-energy, the number of which is governed by the Aharonov-Casher and
Jackiw-Rebbi or Jackiw-Rossi index theorems, respectively. Here I extend the
jurisdiction of these prominent index theorems to Lorentz invariant
non-Hermitian (NH) Dirac operators, constructed by augmenting the celebrated
Dirac Hamiltonian by a masslike anti-Hermitian operator that also scales
linearly with momentum. The resulting NH Dirac operator manifests real
eigenvalues over an extended NH parameter regime, characterized by a real
effective Fermi velocity for NH Dirac fermions. From the explicit solutions of
the zero-energy bound states, I show that in the presence of external magnetic
fields of arbitrary shape such modes always exist when the system encloses a
finite number of magnetic flux quanta, while in the presence of spatially
non-trivial textures of the mass orders localized zero-energy modes can only be
found in the spectrum when the effective Fermi velocity for NH Dirac fermions
is real. These findings pave a concrete route to realize nucleation of
competing orders from the topologically robust zero-energy manifold in NH or
open Dirac systems. Possible experimental setups to test these predictions are
discussed.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [356] [Learning to Deliberate: Meta-policy Collaboration for Agentic LLMs with Multi-agent Reinforcement Learning](https://arxiv.org/abs/2509.03817)
*Wei Yang,Jesse Thomason*

Main category: cs.AI

TL;DR: LLM多智能体系统可以通过学习自适应的元认知策略来改进协作，而不是依赖固定的协议。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM多智能体系统协作协议固定，忽视了智能体内部的元认知能力，导致其在复杂推理方面效果受限。

Method: 提出元策略决策框架（MPDF），智能体在该框架下学习关于持久化、精炼和认输这组高级元认知动作的分布式策略。为解决策略梯度不稳定的问题，开发了SoftRankPO算法，通过基于平滑正态分位数映射的奖励秩来塑造优势，从而稳定训练。

Result: 在五个数学和通用推理基准上，MPDF结合SoftRankPO相比于六种最先进的启发式和基于学习的多智能体推理算法，平均准确率提高了4-5%。

Conclusion: 该工作提出了一种为LLM多智能体系统学习自适应、元认知策略的范式，将重点从设计固定协议转移到学习动态、审慎的策略。

Abstract: Multi-agent systems of large language models (LLMs) show promise for complex
reasoning, but their effectiveness is often limited by fixed collaboration
protocols. These frameworks typically focus on macro-level orchestration while
overlooking agents' internal deliberative capabilities. This critical
meta-cognitive blindspot treats agents as passive executors unable to adapt
their strategy based on internal cognitive states like uncertainty or
confidence. We introduce the Meta-Policy Deliberation Framework (MPDF), where
agents learn a decentralized policy over a set of high-level meta-cognitive
actions: Persist, Refine, and Concede. To overcome the instability of
traditional policy gradients in this setting, we develop SoftRankPO, a novel
reinforcement learning algorithm. SoftRankPO stabilizes training by shaping
advantages based on the rank of rewards mapped through smooth normal quantiles,
making the learning process robust to reward variance. Experiments show that
MPDF with SoftRankPO achieves a a 4-5% absolute gain in average accuracy across
five mathematical and general reasoning benchmarks compared to six
state-of-the-art heuristic and learning-based multi-agent reasoning algorithms.
Our work presents a paradigm for learning adaptive, meta-cognitive policies for
multi-agent LLM systems, shifting the focus from designing fixed protocols to
learning dynamic, deliberative strategies.

</details>


### [357] [PG-Agent: An Agent Powered by Page Graph](https://arxiv.org/abs/2509.03536)
*Weizhi Chen,Ziwei Wang,Leyang Yang,Sheng Zhou,Xiaoxuan Tang,Jiajun Bu,Yong Li,Wei Jiang*

Main category: cs.AI

TL;DR: 现有GUI智能体通过多步操作序列来学习GUI知识，但无法捕捉页面间的复杂转换关系，限制了其对GUI环境的深度感知和泛化能力。本研究提出了一种将操作序列转化为页面图的方法，显式地建模页面间的连接关系。在此基础上，引入检索增强生成（RAG）技术从页面图中提取感知指南，并设计了一个包含任务分解策略的多智能体框架PG-Agent来利用这些指南，以实现对未见场景的泛化。


<details>
  <summary>Details</summary>
Motivation: 现有GUI智能体依赖于操作序列作为先验知识，难以处理页面间的复杂转换关系，限制了其环境感知和泛化能力。

Method: 设计了一个自动化流程，将操作序列转换为页面图，显式建模页面间的连接关系。引入检索增强生成（RAG）技术从页面图中提取感知指南。提出PG-Agent多智能体框架，结合任务分解策略和感知指南，以泛化到未见场景。

Result: 在多个基准测试的广泛实验表明，PG-Agent在页面图构建所需序列有限的情况下，仍然表现出有效性。

Conclusion: PG-Agent通过将操作序列转化为页面图，并结合RAG和多智能体框架，有效提升了GUI智能体对GUI环境的深度感知和泛化能力，即使在数据有限的情况下也能取得良好效果。

Abstract: Graphical User Interface (GUI) agents possess significant commercial and
social value, and GUI agents powered by advanced multimodal large language
models (MLLMs) have demonstrated remarkable potential. Currently, existing GUI
agents usually utilize sequential episodes of multi-step operations across
pages as the prior GUI knowledge, which fails to capture the complex transition
relationship between pages, making it challenging for the agents to deeply
perceive the GUI environment and generalize to new scenarios. Therefore, we
design an automated pipeline to transform the sequential episodes into page
graphs, which explicitly model the graph structure of the pages that are
naturally connected by actions. To fully utilize the page graphs, we further
introduce Retrieval-Augmented Generation (RAG) technology to effectively
retrieve reliable perception guidelines of GUI from them, and a tailored
multi-agent framework PG-Agent with task decomposition strategy is proposed to
be injected with the guidelines so that it can generalize to unseen scenarios.
Extensive experiments on various benchmarks demonstrate the effectiveness of
PG-Agent, even with limited episodes for page graph construction.

</details>


### [358] [Psychologically Enhanced AI Agents](https://arxiv.org/abs/2509.04343)
*Maciej Besta,Shriram Chandran,Robert Gerstenberger,Mathis Lindner,Marcin Chrapek,Sebastian Hermann Martschat,Taraneh Ghandi,Patrick Iff,Hubert Niewiadomski,Piotr Nyczyk,Jürgen Müller,Torsten Hoefler*

Main category: cs.AI

TL;DR: MBTI-in-Thoughts框架通过基于心理学的人格条件化来增强LLM代理的有效性，通过MBTI类型为代理设定个性，从而控制其认知和情感行为。


<details>
  <summary>Details</summary>
Motivation: 通过借鉴MBTI理论，为LLM代理引入心理学特性，以控制其行为并提升在不同任务中的表现，且无需进行模型微调。

Method: 通过提示工程（prompt engineering）为LLM代理植入MBTI人格原型，使其在认知和情感两个维度上表现出特定偏见，并设计了多代理通信协议，引入了交互前自我反思机制，同时利用16Personalities测试进行自动化验证。

Result: 在不同任务中观察到一致且可解释的行为偏差：情感表达型代理在叙事生成任务中表现更优，而分析型代理在博弈论设置中采取更稳定的策略。自我反思能提升合作与推理质量。

Conclusion: MBTI-in-Thoughts框架提供了一种无需微调即可实现心理增强AI代理的方法，并将此方法推广至其他心理学框架（如Big Five, HEXACO, Enneagram）。

Abstract: We introduce MBTI-in-Thoughts, a framework for enhancing the effectiveness of
Large Language Model (LLM) agents through psychologically grounded personality
conditioning. Drawing on the Myers-Briggs Type Indicator (MBTI), our method
primes agents with distinct personality archetypes via prompt engineering,
enabling control over behavior along two foundational axes of human psychology,
cognition and affect. We show that such personality priming yields consistent,
interpretable behavioral biases across diverse tasks: emotionally expressive
agents excel in narrative generation, while analytically primed agents adopt
more stable strategies in game-theoretic settings. Our framework supports
experimenting with structured multi-agent communication protocols and reveals
that self-reflection prior to interaction improves cooperation and reasoning
quality. To ensure trait persistence, we integrate the official 16Personalities
test for automated verification. While our focus is on MBTI, we show that our
approach generalizes seamlessly to other psychological frameworks such as Big
Five, HEXACO, or Enneagram. By bridging psychological theory and LLM behavior
design, we establish a foundation for psychologically enhanced AI agents
without any fine-tuning.

</details>


### [359] [Multilinear and Linear Programs for Partially Identifiable Queries in Quasi-Markovian Structural Causal Models](https://arxiv.org/abs/2509.03548)
*João P. Arroyo,João G. Rodrigues,Daniel Lawand,Denis D. Mauá,Junkyu Lee,Radu Marinescu,Alex Gray,Eduardo R. Laurentino,Fabio G. Cozman*

Main category: cs.AI

TL;DR: 该研究关注因果模型中部分可识别查询的分析，特别是拟马尔可夫的无环结构因果模型。研究提出了一种新的算法，利用内生变量的输入概率来简化多线性规划的构建，并应用列生成技术来计算概率边界，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 因果模型中存在部分可识别查询的问题，即在某些情况下无法精确计算感兴趣的概率值，需要计算概率的紧边界。

Method: 研究了拟马尔可夫的无环结构因果模型，其中内生变量可观测但外生变量不完全指定。提出了一种利用内生变量输入概率简化多线性规划构建的新算法，并对单次干预场景应用列生成技术，通过一系列辅助线性整数程序计算概率边界。

Result: 实验表明，与现有方法相比，列生成技术在计算概率边界方面表现出更高的优越性，并证明了外生变量存在多项式基数表示的可能性。

Conclusion: 所提出的新算法能够简化多线性规划的构建，并且在单次干预场景下，列生成技术能够有效地计算概率边界，证明了外生变量多项式基数表示的可行性，并在实验中证实了其优于现有方法。

Abstract: We investigate partially identifiable queries in a class of causal models. We
focus on acyclic Structural Causal Models that are quasi-Markovian (that is,
each endogenous variable is connected with at most one exogenous confounder).
We look into scenarios where endogenous variables are observed (and a
distribution over them is known), while exogenous variables are not fully
specified. This leads to a representation that is in essence a Bayesian network
where the distribution of root variables is not uniquely determined. In such
circumstances, it may not be possible to precisely compute a probability value
of interest. We thus study the computation of tight probability bounds, a
problem that has been solved by multilinear programming in general, and by
linear programming when a single confounded component is intervened upon. We
present a new algorithm to simplify the construction of such programs by
exploiting input probabilities over endogenous variables. For scenarios with a
single intervention, we apply column generation to compute a probability bound
through a sequence of auxiliary linear integer programs, thus showing that a
representation with polynomial cardinality for exogenous variables is possible.
Experiments show column generation techniques to be superior to existing
methods.

</details>


### [360] [Diffusion-RL Based Air Traffic Conflict Detection and Resolution Method](https://arxiv.org/abs/2509.03550)
*Tonghe Li,Jixin Liu,Weili Zeng,Hao Jiang*

Main category: cs.AI

TL;DR: 本研究提出了一种名为Diffusion-AC的新型自主冲突解决方法，利用扩散模型克服了传统深度强化学习方法在解决空中交通冲突时的决策僵化问题，显著提高了决策的灵活性和安全性。


<details>
  <summary>Details</summary>
Motivation: 现有的深度强化学习（DRL）方法在解决空中交通冲突（CD&R）时存在“单峰偏见”，导致在复杂动态约束下决策僵化，容易出现“决策死锁”。

Method: 提出了一种名为Diffusion-AC的新型自主冲突解决方法，该方法将扩散概率模型集成到CD&R任务中。与收敛到单一最优解的传统方法不同，Diffusion-AC将策略建模为由价值函数引导的反向去噪过程，能够生成丰富、高质量、多模态的动作分布。此外，还引入了密度渐进安全课程（DPSC）训练机制，以确保在从稀疏到高密度交通环境的学习过程中稳定高效。

Result: 在具有挑战性的高密度场景下，Diffusion-AC的成功率达到了94.1%，并且与性能次优的基线方法相比，近空中碰撞（NMACs）的发生率降低了约59%。

Conclusion: Diffusion-AC通过其独特的多模态决策能力，能够灵活地切换到有效的替代机动，从而显著提高了空中交通管理的安全性，克服了传统DRL方法的局限性。

Abstract: In the context of continuously rising global air traffic, efficient and safe
Conflict Detection and Resolution (CD&R) is paramount for air traffic
management. Although Deep Reinforcement Learning (DRL) offers a promising
pathway for CD&R automation, existing approaches commonly suffer from a
"unimodal bias" in their policies. This leads to a critical lack of
decision-making flexibility when confronted with complex and dynamic
constraints, often resulting in "decision deadlocks." To overcome this
limitation, this paper pioneers the integration of diffusion probabilistic
models into the safety-critical task of CD&R, proposing a novel autonomous
conflict resolution framework named Diffusion-AC. Diverging from conventional
methods that converge to a single optimal solution, our framework models its
policy as a reverse denoising process guided by a value function, enabling it
to generate a rich, high-quality, and multimodal action distribution. This core
architecture is complemented by a Density-Progressive Safety Curriculum (DPSC),
a training mechanism that ensures stable and efficient learning as the agent
progresses from sparse to high-density traffic environments. Extensive
simulation experiments demonstrate that the proposed method significantly
outperforms a suite of state-of-the-art DRL benchmarks. Most critically, in the
most challenging high-density scenarios, Diffusion-AC not only maintains a high
success rate of 94.1% but also reduces the incidence of Near Mid-Air Collisions
(NMACs) by approximately 59% compared to the next-best-performing baseline,
significantly enhancing the system's safety margin. This performance leap stems
from its unique multimodal decision-making capability, which allows the agent
to flexibly switch to effective alternative maneuvers.

</details>


### [361] [Learning When to Plan: Efficiently Allocating Test-Time Compute for LLM Agents](https://arxiv.org/abs/2509.03581)
*Davide Paglieri,Bartłomiej Cupiał,Jonathan Cook,Ulyana Piterbarg,Jens Tuyls,Edward Grefenstette,Jakob Nicolaus Foerster,Jack Parker-Holder,Tim Rocktäschel*

Main category: cs.AI

TL;DR: LLM 智能体可通过动态规划在测试时灵活分配计算资源，以提高在长时限任务中的表现和样本效率。


<details>
  <summary>Details</summary>
Motivation: 现有 LLM 智能体方法（如 ReAct）在每次行动前都进行规划，这在长时限任务中计算成本高昂且性能下降；而从不规划则会限制性能。需要一种方法来灵活决定何时进行规划。

Method: 提出一个形式化动态规划的概念框架，使 LLM 智能体能够灵活决定何时分配测试时间进行规划。通过一个简单的两阶段训练流程：1. 在多样化的合成数据上进行监督微调，以引导模型进行动态规划；2. 在长时限环境中通过强化学习优化此能力。

Result: 在 Crafter 环境的实验表明，动态规划智能体比传统方法更具样本效率，并能持续实现更复杂的目标。此外，通过人类编写的计划进行引导，智能体表现优于独立工作。

Conclusion: 该研究首次探索了训练 LLM 智能体在序列决策任务中进行动态测试时间计算分配，为构建更高效、自适应和可控的智能体系统铺平了道路。

Abstract: Training large language models (LLMs) to reason via reinforcement learning
(RL) significantly improves their problem-solving capabilities. In agentic
settings, existing methods like ReAct prompt LLMs to explicitly plan before
every action; however, we demonstrate that always planning is computationally
expensive and degrades performance on long-horizon tasks, while never planning
further limits performance. To address this, we introduce a conceptual
framework formalizing dynamic planning for LLM agents, enabling them to
flexibly decide when to allocate test-time compute for planning. We propose a
simple two-stage training pipeline: (1) supervised fine-tuning on diverse
synthetic data to prime models for dynamic planning, and (2) RL to refine this
capability in long-horizon environments. Experiments on the Crafter environment
show that dynamic planning agents trained with this approach are more
sample-efficient and consistently achieve more complex objectives.
Additionally, we demonstrate that these agents can be effectively steered by
human-written plans, surpassing their independent capabilities. To our
knowledge, this work is the first to explore training LLM agents for dynamic
test-time compute allocation in sequential decision-making tasks, paving the
way for more efficient, adaptive, and controllable agentic systems.

</details>


### [362] [Oruga: An Avatar of Representational Systems Theory](https://arxiv.org/abs/2509.04041)
*Daniel Raggi,Gem Stapleton,Mateja Jamnik,Aaron Stockdill,Grecia Garcia Garcia,Peter C-H. Cheng*

Main category: cs.AI

TL;DR: Oruga 是一个基于 Representational Systems Theory (RST) 的系统，旨在使机器能够像人类一样灵活地使用和转换表征。


<details>
  <summary>Details</summary>
Motivation: 为了让机器更具人性化，能够像人类一样灵活地使用表征，例如进行绘画、转换表征和跨领域进行类比。

Method: 提出并实现了一个名为 Oruga 的系统，该系统包含：1. RST 核心的数据结构；2. 用于与核心通信的语言；3. 使用“结构转移”方法进行表征转换的引擎。

Result: 介绍了 Oruga 的核心和语言，并提供了一个“结构转移”转换的简单示例。

Conclusion: Oruga 系统通过实现 RST 的各个方面，为机器在表征的灵活性和创造性方面提供了新的可能性。

Abstract: Humans use representations flexibly. We draw diagrams, change representations
and exploit creative analogies across different domains. We want to harness
this kind of power and endow machines with it to make them more compatible with
human use. Previously we developed Representational Systems Theory (RST) to
study the structure and transformations of representations. In this paper we
present Oruga (caterpillar in Spanish; a symbol of transformation), an
implementation of various aspects of RST. Oruga consists of a core of data
structures corresponding to concepts in RST, a language for communicating with
the core, and an engine for producing transformations using a method we call
structure transfer. In this paper we present an overview of the core and
language of Oruga, with a brief example of the kind of transformation that
structure transfer can execute.

</details>


### [363] [Explainable Knowledge Graph Retrieval-Augmented Generation (KG-RAG) with KG-SMILE](https://arxiv.org/abs/2509.03626)
*Zahra Zehtabi Sabeti Moghaddam,Zeinab Dehghani,Maneeha Rani,Koorosh Aslansefat,Bhupesh Kumar Mishra,Rameez Raja Kureshi,Dhavalkumar Thakker*

Main category: cs.AI

TL;DR: 生成式AI（如LLM）虽有长足进步，但在关键领域仍存在幻觉和无法验证的声明。检索增强生成（RAG）通过引入外部知识提高了准确性，特别是在医疗等要求精确的领域。然而，RAG仍然不透明，并且高度依赖数据质量。我们提出了一种与模型无关、基于扰动的方法KG-SMILE，通过SMILE实现了图RAG的组件级可解释性。通过扰动、计算相似性和训练加权线性代理，KG-SMILE能够识别对生成输出影响最大的图实体和关系，从而提高RAG的透明度。我们使用保真度、忠实度、一致性、稳定性、准确性等指标对KG-SMILE进行了评估，结果表明KG-SMILE能够生成稳定且符合人类预期的解释，在模型有效性和可解释性之间取得了平衡，增强了对机器学习技术的透明度和信任度。


<details>
  <summary>Details</summary>
Motivation: 生成式AI，特别是LLM，在关键领域由于其输出的幻觉和不可验证性而受到限制。RAG通过引入外部知识来提高准确性，但其不透明性和对数据质量的依赖性阻碍了其在敏感领域的广泛应用，例如医疗保健。

Method: 开发了一种名为KG-SMILE的、与模型无关的、基于扰动的方法。该方法利用SMILE实现了图RAG的组件级可解释性。通过应用受控扰动、计算相似性以及训练加权线性代理，KG-SMILE可以识别对生成输出影响最大的图实体和关系。

Result: KG-SMILE能够识别出对生成输出影响最大的图实体和关系，从而提高RAG的透明度。使用保真度、忠实度、一致性、稳定性、准确性等全面的归因指标进行评估，结果表明KG-SMILE生成的解释是稳定且符合人类预期的。

Conclusion: KG-SMILE通过提高RAG的可解释性，成功地在模型有效性和可解释性之间取得了平衡，增强了对机器学习技术的透明度和信任度。

Abstract: Generative AI, such as Large Language Models (LLMs), has achieved impressive
progress but still produces hallucinations and unverifiable claims, limiting
reliability in sensitive domains. Retrieval-Augmented Generation (RAG) improves
accuracy by grounding outputs in external knowledge, especially in domains like
healthcare, where precision is vital. However, RAG remains opaque and
essentially a black box, heavily dependent on data quality. We developed a
method-agnostic, perturbation-based framework that provides token and
component-level interoperability for Graph RAG using SMILE and named it as
Knowledge-Graph (KG)-SMILE. By applying controlled perturbations, computing
similarities, and training weighted linear surrogates, KG-SMILE identifies the
graph entities and relations most influential to generated outputs, thereby
making RAG more transparent. We evaluate KG-SMILE using comprehensive
attribution metrics, including fidelity, faithfulness, consistency, stability,
and accuracy. Our findings show that KG-SMILE produces stable, human-aligned
explanations, demonstrating its capacity to balance model effectiveness with
interpretability and thereby fostering greater transparency and trust in
machine learning technologies.

</details>


### [364] [Domain size asymptotics for Markov logic networks](https://arxiv.org/abs/2509.04192)
*Vera Koponen*

Main category: cs.AI

TL;DR: 研究了马尔可夫逻辑网络（MLN）在域大小趋于无穷时的性质，考察了三种具体MLN的例子，研究了随机结构在域大小趋于无穷时的性质。


<details>
  <summary>Details</summary>
Motivation: 研究MLN在域大小趋于无穷时的性质，考察不同类型的MLN及其对随机结构性质的影响。

Method: 研究了三种具体MLN的例子：1. 任意无量词MLN，具有单一元关系符号。2. 倾向于减少三角形（或k-团）的MLN。3. 倾向于减少高阶顶点的MLN。分析了这些MLN在域大小趋于无穷时对随机结构性质的影响，包括极限行为、0-1律以及与均匀分布的对比。

Result: 1. 得到了单一元关系符号的无量词MLN的极限行为的完整刻画。2. 得到了一个关于一阶逻辑的“δ-近似0-1律”。3. 证明了无量词MLN和升格贝叶斯网络在渐近意义上是不可比的。证明了在大型域上，MLN确定的分布几乎所有的概率质量都集中在一个与均匀分布完全不同的部分。

Conclusion: MLN的极限行为取决于所使用的“软约束”，软约束的权重可能影响也可能不影响极限行为。在大型域上，MLN确定的分布与均匀分布的概率质量分布有显著差异。

Abstract: A Markov logic network (MLN) determines a probability distribution on the set
of structures, or ``possible worlds'', with an arbitrary finite domain. We
study the properties of such distributions as the domain size tends to
infinity. Three types of concrete examples of MLNs will be considered, and the
properties of random structures with domain sizes tending to infinity will be
studied: (1) Arbitrary quantifier-free MLNs over a language with only one
relation symbol which has arity 1. In this case we give a pretty complete
characterization of the possible limit behaviours of random structures. (2) An
MLN that favours graphs with fewer triangles (or more generally, fewer
k-cliques). As a corollary of the analysis a ``$\delta$-approximate 0-1 law''
for first-order logic is obtained. (3) An MLN that favours graphs with fewer
vertices with degree higher than a fixed (but arbitrary) number. The analysis
shows that depending on which ``soft constraints'' an MLN uses the limit
behaviour of random structures can be quite different, and the weights of the
soft constraints may, or may not, have influence on the limit behaviour. It
will also be demonstrated, using (1), that quantifier-free MLNs and lifted
Bayesian networks (in a broad sense) are asymptotically incomparable, roughly
meaning that there is a sequence of distributions on possible worlds with
increasing domain sizes that can be defined by one of the formalisms but not
even approximated by the other. In a rather general context it is also shown
that on large domains the distribution determined by an MLN concentrates almost
all its probability mass on a totally different part of the space of possible
worlds than the uniform distribution does.

</details>


### [365] [CausalARC: Abstract Reasoning with Causal World Models](https://arxiv.org/abs/2509.03636)
*Jacqueline Maasch,John Kalantari,Kia Khezeli*

Main category: cs.AI

TL;DR: CausalARC是一个新的AI推理测试平台，用于低数据和分布外场景，它使用因果世界模型和数据增强来评估语言模型在各种推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的AI推理基准测试未能充分应对现实世界中常见的数据不足和分布变化问题。因此，有必要开发新的测试平台来评估AI在这些挑战性条件下的推理能力。

Method: CausalARC通过从结构因果模型（SCM）生成的因果世界模型来创建推理任务。它提供了包括观察性、干预性和反事实性反馈在内的数据增强，以支持少样本和上下文学习。该平台已被用于四个语言模型评估场景：带测试时训练的抽象推理、带上下文学习的反事实推理、程序合成和因果发现。

Result: CausalARC已被用作一个概念证明，用于评估语言模型在抽象推理、反事实推理、程序合成和因果发现等四个领域的表现，特别是在数据有限和分布外的情况下。

Conclusion: CausalARC为在低数据和分布外场景中评估AI推理提供了一个新的、基于因果的测试平台。它支持多种评估设置，并有望促进更鲁棒和通用的AI推理系统的开发。

Abstract: Reasoning requires adaptation to novel problem settings under limited data
and distribution shift. This work introduces CausalARC: an experimental testbed
for AI reasoning in low-data and out-of-distribution regimes, modeled after the
Abstraction and Reasoning Corpus (ARC). Each CausalARC reasoning task is
sampled from a fully specified causal world model, formally expressed as a
structural causal model. Principled data augmentations provide observational,
interventional, and counterfactual feedback about the world model in the form
of few-shot, in-context learning demonstrations. As a proof-of-concept, we
illustrate the use of CausalARC for four language model evaluation settings:
(1) abstract reasoning with test-time training, (2) counterfactual reasoning
with in-context learning, (3) program synthesis, and (4) causal discovery with
logical reasoning.

</details>


### [366] [Towards a Neurosymbolic Reasoning System Grounded in Schematic Representations](https://arxiv.org/abs/2509.03644)
*François Olivier,Zied Bouraoui*

Main category: cs.AI

TL;DR: LLMs在逻辑推理中存在错误，本文提出了Embodied-LM系统，通过具身认知结构（基于图像图式）进行逻辑推理，并在逻辑推理问题上进行了评估，表明该方法可以增强LLM的推理能力和可解释性。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在自然语言理解方面取得了显著进展，但在执行逻辑推理时仍然容易出错，并且缺乏类似人类的理解能力。

Method: 提出一个名为Embodied-LM的原型神经符号系统，该系统利用基于图像图式的图式表征来 grounding理解和逻辑推理。该系统使用声明式空间推理（Answer Set Programming）来操作这些认知结构的 perustawy przestrzenne。

Result: 通过在逻辑推理问题上的评估，证明了LLMs可以被引导通过具身认知结构来解释场景，并且这些结构可以被形式化为可执行程序，从而支持有效的逻辑推理和增强的可解释性。

Conclusion: 尽管当前的实现侧重于空间基元，但它为整合更复杂和动态的表征奠定了计算基础。

Abstract: Despite significant progress in natural language understanding, Large
Language Models (LLMs) remain error-prone when performing logical reasoning,
often lacking the robust mental representations that enable human-like
comprehension. We introduce a prototype neurosymbolic system, Embodied-LM, that
grounds understanding and logical reasoning in schematic representations based
on image schemas-recurring patterns derived from sensorimotor experience that
structure human cognition. Our system operationalizes the spatial foundations
of these cognitive structures using declarative spatial reasoning within Answer
Set Programming. Through evaluation on logical deduction problems, we
demonstrate that LLMs can be guided to interpret scenarios through embodied
cognitive structures, that these structures can be formalized as executable
programs, and that the resulting representations support effective logical
reasoning with enhanced interpretability. While our current implementation
focuses on spatial primitives, it establishes the computational foundation for
incorporating more complex and dynamic representations.

</details>


### [367] [Emergent Hierarchical Reasoning in LLMs through Reinforcement Learning](https://arxiv.org/abs/2509.03646)
*Haozhe Wang,Qixin Xu,Che Liu,Junhong Wu,Fangzhen Lin,Wenhu Chen*

Main category: cs.AI

TL;DR: RL通过分层机制提升LLM推理能力，HICRA算法通过关注高层规划代币优化学习效果。


<details>
  <summary>Details</summary>
Motivation: 现有RL算法在提升LLM推理能力方面效果显著，但其内部机制尚不明确。本研究旨在揭示RL驱动LLM推理能力提升的潜在机制，特别是‘顿悟’、‘长度缩放’和熵动态等现象，并提出一种更有效的算法。

Method: 通过分析RL训练过程中的现象，提出‘分层推理’模型，并设计了一种名为HICRA（HIerarchy-Aware Credit Assignment）的新算法，该算法将优化重点放在高影响力规划代币上，并使用语义熵作为衡量策略探索的指标。

Result: HICRA算法显著优于现有基线算法，证明了关注策略瓶颈是解锁高级推理的关键。同时，验证了语义熵是衡量策略探索的有效指标。

Conclusion: RL驱动LLM推理能力提升的核心在于其潜在的‘分层推理’机制。通过HICRA算法将优化资源集中在高层规划代币上，可以更有效地提升LLM的推理能力。语义熵是衡量策略探索的可靠指标。

Abstract: Reinforcement Learning (RL) has proven highly effective at enhancing the
complex reasoning abilities of Large Language Models (LLMs), yet underlying
mechanisms driving this success remain largely opaque. Our analysis reveals
that puzzling phenomena like ``aha moments", ``length-scaling'' and entropy
dynamics are not disparate occurrences but hallmarks of an emergent reasoning
hierarchy, akin to the separation of high-level strategic planning from
low-level procedural execution in human cognition. We uncover a compelling
two-phase dynamic: initially, a model is constrained by procedural correctness
and must improve its low-level skills. The learning bottleneck then decisively
shifts, with performance gains being driven by the exploration and mastery of
high-level strategic planning. This insight exposes a core inefficiency in
prevailing RL algorithms like GRPO, which apply optimization pressure
agnostically and dilute the learning signal across all tokens. To address this,
we propose HIerarchy-Aware Credit Assignment (HICRA), an algorithm that
concentrates optimization efforts on high-impact planning tokens. HICRA
significantly outperforms strong baselines, demonstrating that focusing on this
strategic bottleneck is key to unlocking advanced reasoning. Furthermore, we
validate semantic entropy as a superior compass for measuring strategic
exploration over misleading metrics such as token-level entropy.

</details>


### [368] [An Empirical Evaluation of Factors Affecting SHAP Explanation of Time Series Classification](https://arxiv.org/abs/2509.03649)
*Davide Italo Serramazza,Nikos Papadeas,Zahraa Abdallah,Georgiana Ifrim*

Main category: cs.AI

TL;DR: SHAP方法计算复杂，尤其是在长时序数据上。本文研究了八种不同的时间序列分割算法，以确定哪种分割策略在计算SHAP属性时效果最好，并提出了一种新的归一化技术来提高属性质量。


<details>
  <summary>Details</summary>
Motivation: 现有的SHAP方法在处理长时序数据时计算复杂度高，限制了其在可解释人工智能（XAI）中的应用。因此，需要研究最优的时间序列分割策略来提高SHAP的效率和效果。

Method: 本文研究了八种不同的时间序列分割算法，并使用InterpretTime和AUC Difference这两种XAI评估方法，在多元和单变量时间序列数据集上对它们进行了评估。此外，还提出了一种新的归一化技术，通过根据长度对时间段进行加权来改进属性质量。

Result: 研究发现，分割的数量比所使用的具体分割方法对解释质量有更大的影响。等长分割在大多数自定义时间序列分割算法中表现更好。新提出的归一化技术通过对时间段进行加权，能够持续提高属性质量。

Conclusion: 对于SHAP属性的计算，分割的数量比分割的方法更重要。等长分割是一种简单但有效的方法。提出的归一化技术可以进一步提高属性质量。

Abstract: Explainable AI (XAI) has become an increasingly important topic for
understanding and attributing the predictions made by complex Time Series
Classification (TSC) models. Among attribution methods, SHapley Additive
exPlanations (SHAP) is widely regarded as an excellent attribution method; but
its computational complexity, which scales exponentially with the number of
features, limits its practicality for long time series. To address this, recent
studies have shown that aggregating features via segmentation, to compute a
single attribution value for a group of consecutive time points, drastically
reduces SHAP running time. However, the choice of the optimal segmentation
strategy remains an open question. In this work, we investigated eight
different Time Series Segmentation algorithms to understand how segment
compositions affect the explanation quality. We evaluate these approaches using
two established XAI evaluation methodologies: InterpretTime and AUC Difference.
Through experiments on both Multivariate (MTS) and Univariate Time Series
(UTS), we find that the number of segments has a greater impact on explanation
quality than the specific segmentation method. Notably, equal-length
segmentation consistently outperforms most of the custom time series
segmentation algorithms. Furthermore, we introduce a novel attribution
normalisation technique that weights segments by their length and we show that
it consistently improves attribution quality.

</details>


### [369] [PersonaTeaming: Exploring How Introducing Personas Can Improve Automated AI Red-Teaming](https://arxiv.org/abs/2509.03728)
*Wesley Hanwen Deng,Sunnie S. Y. Kim,Akshita Jha,Ken Holstein,Motahhare Eslami,Lauren Wilcox,Leon A Gatys*

Main category: cs.AI

TL;DR: 自动化红队测试通过引入用户身份（personas）来生成对抗性提示，以提高攻击成功率并保持提示多样性。


<details>
  <summary>Details</summary>
Motivation: AI治理和安全研究需要有效的红队测试方法来发现AI模型的潜在风险，并认识到红队成员的身份会影响其发现风险的能力。现有自动化方法未能考虑身份因素。

Method: 提出PersonaTeaming方法，在对抗性提示生成过程中引入“红队测试专家”或“普通AI用户”身份，并通过动态算法生成各种身份类型。同时，开发了新的“变异距离”度量指标来补充现有的提示多样性测量。

Result: 实验结果表明，与最先进的自动化红队测试方法RainbowPlus相比，PersonaTeaming通过身份变异可将攻击成功率提高高达144.1%，同时保持提示多样性。

Conclusion: PersonaTeaming在自动化红队测试中引入身份因素取得了初步成效，为未来结合自动化和人工红队测试提供了新的方向。不同身份类型和变异方法的优缺点需要进一步研究。

Abstract: Recent developments in AI governance and safety research have called for
red-teaming methods that can effectively surface potential risks posed by AI
models. Many of these calls have emphasized how the identities and backgrounds
of red-teamers can shape their red-teaming strategies, and thus the kinds of
risks they are likely to uncover. While automated red-teaming approaches
promise to complement human red-teaming by enabling larger-scale exploration of
model behavior, current approaches do not consider the role of identity. As an
initial step towards incorporating people's background and identities in
automated red-teaming, we develop and evaluate a novel method, PersonaTeaming,
that introduces personas in the adversarial prompt generation process to
explore a wider spectrum of adversarial strategies. In particular, we first
introduce a methodology for mutating prompts based on either "red-teaming
expert" personas or "regular AI user" personas. We then develop a dynamic
persona-generating algorithm that automatically generates various persona types
adaptive to different seed prompts. In addition, we develop a set of new
metrics to explicitly measure the "mutation distance" to complement existing
diversity measurements of adversarial prompts. Our experiments show promising
improvements (up to 144.1%) in the attack success rates of adversarial prompts
through persona mutation, while maintaining prompt diversity, compared to
RainbowPlus, a state-of-the-art automated red-teaming method. We discuss the
strengths and limitations of different persona types and mutation methods,
shedding light on future opportunities to explore complementarities between
automated and human red-teaming approaches.

</details>


### [370] [The Personality Illusion: Revealing Dissociation Between Self-Reports & Behavior in LLMs](https://arxiv.org/abs/2509.03730)
*Pengrui Han,Rafal Kocielnik,Peiyang Song,Ramit Debnath,Dean Mobbs,Anima Anandkumar,R. Michael Alvarez*

Main category: cs.AI

TL;DR: 大型语言模型（LLM）的“个性”可以被量化，但其自我报告的特征并不能可靠地预测行为，并且通过“角色注入”进行的干预措施对其行为的影响很小。


<details>
  <summary>Details</summary>
Motivation: 理解大型语言模型（LLM）的个性特征很重要，但以往的研究依赖于简化的自我报告和启发式提示，缺乏行为验证。

Method: 系统地研究LLM的个性，包括：1.特质档案在训练过程中的动态出现和演变；2.自我报告特质在行为任务中的预测有效性；3.诸如角色注入等目标干预措施对自我报告和行为的影响。

Result: 指令调整（例如，RLHF、指令调优）能显著稳定特质表达，并增强特质相关性，但自我报告的特质并不能可靠地预测行为，并且观察到的关联往往与人类模式不同。角色注入虽然能成功地引导自我报告，但对实际行为的影响很小或不一致。

Conclusion: 区分表面特质表达和行为一致性，这项研究挑战了对LLM个性的假设，并强调了在对齐和可解释性方面进行更深入评估的必要性。

Abstract: Personality traits have long been studied as predictors of human
behavior.Recent advances in Large Language Models (LLMs) suggest similar
patterns may emerge in artificial systems, with advanced LLMs displaying
consistent behavioral tendencies resembling human traits like agreeableness and
self-regulation. Understanding these patterns is crucial, yet prior work
primarily relied on simplified self-reports and heuristic prompting, with
little behavioral validation. In this study, we systematically characterize LLM
personality across three dimensions: (1) the dynamic emergence and evolution of
trait profiles throughout training stages; (2) the predictive validity of
self-reported traits in behavioral tasks; and (3) the impact of targeted
interventions, such as persona injection, on both self-reports and behavior.
Our findings reveal that instructional alignment (e.g., RLHF, instruction
tuning) significantly stabilizes trait expression and strengthens trait
correlations in ways that mirror human data. However, these self-reported
traits do not reliably predict behavior, and observed associations often
diverge from human patterns. While persona injection successfully steers
self-reports in the intended direction, it exerts little or inconsistent effect
on actual behavior. By distinguishing surface-level trait expression from
behavioral consistency, our findings challenge assumptions about LLM
personality and underscore the need for deeper evaluation in alignment and
interpretability.

</details>


### [371] [Are LLM Agents Behaviorally Coherent? Latent Profiles for Social Simulation](https://arxiv.org/abs/2509.03736)
*James Mooney,Josef Woldense,Zheng Robert Jia,Shirley Anugrah Hayati,My Ha Nguyen,Vipul Raheja,Dongyeop Kang*

Main category: cs.AI

TL;DR: LLM在人类受试者研究中无法替代真实人类参与者，因为它们在不同实验设置下表现出内部不一致性，尽管它们可能生成与人类匹配的响应。


<details>
  <summary>Details</summary>
Motivation: 评估LLM是否能替代真实人类参与者进行人类受试者研究，重点在于LLM是否在不同实验设置下保持内部一致性。

Method: 设计了一个研究，（a）揭示代理的内部状态，（b）在基本对话设置中检查代理行为，以评估代理行为是否与其揭示的内部状态一致。

Result: 在不同模型系列和不同模型大小的LLM中发现了显著的内部不一致性。 LLM可能生成与人类对应的响应，但未能保持内部一致性。

Conclusion: LLM在内部一致性方面存在关键的局限性，这阻碍了它们在人类受试者研究中准确替代真实参与者。

Abstract: The impressive capabilities of Large Language Models (LLMs) have fueled the
notion that synthetic agents can serve as substitutes for real participants in
human-subject research. In an effort to evaluate the merits of this claim,
social science researchers have largely focused on whether LLM-generated survey
data corresponds to that of a human counterpart whom the LLM is prompted to
represent. In contrast, we address a more fundamental question: Do agents
maintain internal consistency, retaining similar behaviors when examined under
different experimental settings? To this end, we develop a study designed to
(a) reveal the agent's internal state and (b) examine agent behavior in a basic
dialogue setting. This design enables us to explore a set of behavioral
hypotheses to assess whether an agent's conversation behavior is consistent
with what we would expect from their revealed internal state. Our findings on
these hypotheses show significant internal inconsistencies in LLMs across model
families and at differing model sizes. Most importantly, we find that, although
agents may generate responses matching those of their human counterparts, they
fail to be internally consistent, representing a critical gap in their
capabilities to accurately substitute for real participants in human-subject
research. Our simulation code and data are publicly accessible.

</details>


### [372] [RAGuard: A Novel Approach for in-context Safe Retrieval Augmented Generation for LLMs](https://arxiv.org/abs/2509.03768)
*Connor Walker,Koorosh Aslansefat,Mohammad Naveed Akram,Yiannis Papadopoulos*

Main category: cs.AI

TL;DR: RAGuard通过集成安全文档和专用检索预算，提高了OSW维护中LLM的准确性和安全性，SafetyClamp进一步增强了安全保障。


<details>
  <summary>Details</summary>
Motivation: 传统LLM在处理OSW维护中的专业或意外场景时，在准确性和安全性方面存在不足。

Method: 提出RAGuard框架，该框架将安全文档与技术手册并行检索，并为知识和安全分配独立的检索预算。开发了SafetyClamp扩展，用于获取更大的候选池，并将精确的槽位保证“硬性约束”到安全层面。

Result: 与仅使用RAG相比，RAGuard和SafetyClamp在技术召回率保持在60%以上的同时，将安全召回率从近0%提高到50%以上。

Conclusion: RAGuard和SafetyClamp有潜力为在关键维护场景中将安全保障集成到LLM驱动的决策支持中设立新标准。

Abstract: Accuracy and safety are paramount in Offshore Wind (OSW) maintenance, yet
conventional Large Language Models (LLMs) often fail when confronted with
highly specialised or unexpected scenarios. We introduce RAGuard, an enhanced
Retrieval-Augmented Generation (RAG) framework that explicitly integrates
safety-critical documents alongside technical manuals.By issuing parallel
queries to two indices and allocating separate retrieval budgets for knowledge
and safety, RAGuard guarantees both technical depth and safety coverage. We
further develop a SafetyClamp extension that fetches a larger candidate pool,
"hard-clamping" exact slot guarantees to safety. We evaluate across sparse
(BM25), dense (Dense Passage Retrieval) and hybrid retrieval paradigms,
measuring Technical Recall@K and Safety Recall@K. Both proposed extensions of
RAG show an increase in Safety Recall@K from almost 0\% in RAG to more than
50\% in RAGuard, while maintaining Technical Recall above 60\%. These results
demonstrate that RAGuard and SafetyClamp have the potential to establish a new
standard for integrating safety assurance into LLM-powered decision support in
critical maintenance contexts.

</details>


### [373] [Leveraging LLM-Based Agents for Intelligent Supply Chain Planning](https://arxiv.org/abs/2509.03811)
*Yongzhi Qi,Jiaheng Yin,Jianshen Zhang,Dongyang Geng,Zhengyu Chen,Hao Hu,Wei Qi,Zuo-Jun Max Shen*

Main category: cs.AI

TL;DR: 该研究构建了一个供应链规划代理（SCPA）框架，利用大型语言模型（LLM）技术来解决电商平台供应链规划中的挑战，并在京东实际场景中进行了部署，取得了显著成效。


<details>
  <summary>Details</summary>
Motivation: 电商平台供应链规划涉及多实体协作、需求预测、库存管理、销售运营和补货等复杂环节。在实际操作中，如何收集数据、制定长期规划并动态调整，同时保证可解释性、效率和可靠性，是一个实际且具挑战性的问题。LLM的快速发展为解决这些问题提供了新工具。

Method: 研究构建了一个供应链规划代理（SCPA）框架，该框架能够理解领域知识、操作员需求，进行任务分解，并利用或创建新工具来生成基于证据的规划报告。

Result: 该框架在京东的真实场景中得到部署，证明了LLM-Agent在供应链领域的应用可行性。实际部署有效地降低了人力成本，并提高了准确性、库存可用性等关键指标。

Conclusion: LLM-Agent技术在电商平台供应链规划中具有实际应用价值，能够有效解决传统方法面临的挑战，并带来显著的业务效益。

Abstract: In supply chain management, planning is a critical concept. The movement of
physical products across different categories, from suppliers to warehouse
management, to sales, and logistics transporting them to customers, entails the
involvement of many entities. It covers various aspects such as demand
forecasting, inventory management, sales operations, and replenishment. How to
collect relevant data from an e-commerce platform's perspective, formulate
long-term plans, and dynamically adjust them based on environmental changes,
while ensuring interpretability, efficiency, and reliability, is a practical
and challenging problem. In recent years, the development of AI technologies,
especially the rapid progress of large language models, has provided new tools
to address real-world issues. In this work, we construct a Supply Chain
Planning Agent (SCPA) framework that can understand domain knowledge,
comprehend the operator's needs, decompose tasks, leverage or create new tools,
and return evidence-based planning reports. We deploy this framework in
JD.com's real-world scenario, demonstrating the feasibility of LLM-agent
applications in the supply chain. It effectively reduced labor and improved
accuracy, stock availability, and other key metrics.

</details>


### [374] [What Would an LLM Do? Evaluating Policymaking Capabilities of Large Language Models](https://arxiv.org/abs/2509.03827)
*Pierre Le Coz,Jia An Liu,Debarun Bhattacharjya,Georgina Curto,Serge Stinckwich*

Main category: cs.AI

TL;DR: LLMs在解决无家可归问题方面展现出巨大潜力，尤其是在提供大规模政策建议方面。通过引入负责任的保障措施和与专家的合作，LLMs可以成为社会政策制定的宝贵工具。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在社会政策制定领域（特别是无家可归问题）的能力，以及LLMs与领域专家的 一致性。

Method: 开发了一个包含决策场景和政策选择的新基准，涵盖四个不同地理区域（美国南本德、西班牙巴塞罗那、南非约翰内斯堡、中国澳门特别行政区）。所涉及的政策以人类发展能力方法为基础。此外，还构建了一个自动化流程，将基准政策与基于主体的模型连接起来，并通过模拟社会场景来探索推荐政策的社会影响。

Result: 研究结果表明，LLMs在社会政策制定方面具有广阔的应用前景。通过与当地领域专家合作，实施负责任的保障措施和进行上下文校准，LLMs能够大规模地为人类提供有价值的替代政策见解。

Conclusion: LLMs在社会政策制定方面有很大潜力，但需要与领域专家合作，并采取负责任的保障措施和上下文校准，才能最大限度地发挥其作用。

Abstract: Large language models (LLMs) are increasingly being adopted in high-stakes
domains. Their capacity to process vast amounts of unstructured data, explore
flexible scenarios, and handle a diversity of contextual factors can make them
uniquely suited to provide new insights for the complexity of social
policymaking. This article evaluates whether LLMs' are aligned with domain
experts (and among themselves) to inform social policymaking on the subject of
homelessness alleviation - a challenge affecting over 150 million people
worldwide. We develop a novel benchmark comprised of decision scenarios with
policy choices across four geographies (South Bend, USA; Barcelona, Spain;
Johannesburg, South Africa; Macau SAR, China). The policies in scope are
grounded in the conceptual framework of the Capability Approach for human
development. We also present an automated pipeline that connects the
benchmarked policies to an agent-based model, and we explore the social impact
of the recommended policies through simulated social scenarios. The paper
results reveal promising potential to leverage LLMs for social policy making.
If responsible guardrails and contextual calibrations are introduced in
collaboration with local domain experts, LLMs can provide humans with valuable
insights, in the form of alternative policies at scale.

</details>


### [375] [An Agentic Model Context Protocol Framework for Medical Concept Standardization](https://arxiv.org/abs/2509.03828)
*Jaerong Ahn,Andrew Wen,Nan Wang,Heling Jia,Zhiyi Yue,Sunyang Fu,Hongfang Liu*

Main category: cs.AI

TL;DR: OMOP CDM 数据标准化中的术语映射过程耗时且易出错。本文提出了一种基于 MCP 框架的零训练、防幻觉映射系统，该系统可提高效率和准确性，并提供可解释的映射和实时词汇查找。


<details>
  <summary>Details</summary>
Motivation: OMOP CDM 数据标准化中的术语映射过程是一个关键但耗时且易出错的步骤。需要一种更有效、更准确的方法来解决这个问题。

Method: 开发了一个基于模型上下文协议（MCP）的零训练、防幻觉映射系统，使 LLM 能够与外部资源和工具进行交互，实现可解释的映射、实时词汇查找和结构化推理。

Result: 该系统能够进行可解释的映射，显著提高效率和准确性，同时最大限度地减少工作量。它提供实时词汇查找和结构化推理输出，适用于探索性和生产环境。

Conclusion: 本文提出的基于 MCP 框架的零训练、防幻觉映射系统能够有效解决 OMOP CDM 数据标准化中的术语映射难题，提高效率和准确性，并为临床研究提供支持。

Abstract: The Observational Medical Outcomes Partnership (OMOP) common data model (CDM)
provides a standardized representation of heterogeneous health data to support
large-scale, multi-institutional research. One critical step in data
standardization using OMOP CDM is the mapping of source medical terms to OMOP
standard concepts, a procedure that is resource-intensive and error-prone.
While large language models (LLMs) have the potential to facilitate this
process, their tendency toward hallucination makes them unsuitable for clinical
deployment without training and expert validation. Here, we developed a
zero-training, hallucination-preventive mapping system based on the Model
Context Protocol (MCP), a standardized and secure framework allowing LLMs to
interact with external resources and tools. The system enables explainable
mapping and significantly improves efficiency and accuracy with minimal effort.
It provides real-time vocabulary lookups and structured reasoning outputs
suitable for immediate use in both exploratory and production environments.

</details>


### [376] [A Multidimensional AI-powered Framework for Analyzing Tourist Perception in Historic Urban Quarters: A Case Study in Shanghai](https://arxiv.org/abs/2509.03830)
*Kaizhen Tan,Yufan Wu,Yuxuan Liu,Haoran Zeng*

Main category: cs.AI

TL;DR: 本研究提出了一个多维度的人工智能框架，利用社交媒体的多模态数据来分析游客对历史街区的感知。


<details>
  <summary>Details</summary>
Motivation: 理解游客如何感知历史街区对于可持续的、以人为本的城市规划至关重要。

Method: 该框架集成了焦点提取、色彩主题分析和情感挖掘。利用经过微调的语义分割模型从游客分享的照片中识别视觉焦点；通过聚类方法提取主色调并分析其在街区的空间分布；利用基于规则的方法和多任务 BERT 模型相结合的混合情感分析方法评估游客评论，并在四个维度上评估满意度：旅游活动、建筑环境、服务设施和商业模式。

Result: 结果揭示了美学吸引力和情感反应在空间上的差异。色彩主题在社交媒体照片和现实街景之间存在显著差异，这可能表明视觉期望与建筑环境之间存在差距。

Conclusion: 该框架提供了一种集成的数据驱动方法来解读游客感知，为旅游、遗产保护和美学上引人入胜的公共空间设计提供了信息支持。

Abstract: Historic urban quarters play a vital role in preserving cultural heritage
while serving as vibrant spaces for tourism and everyday life. Understanding
how tourists perceive these environments is essential for sustainable,
human-centered urban planning. This study proposes a multidimensional
AI-powered framework for analyzing tourist perception in historic urban
quarters using multimodal data from social media. Applied to twelve historic
quarters in central Shanghai, the framework integrates focal point extraction,
color theme analysis, and sentiment mining. Visual focus areas are identified
from tourist-shared photos using a fine-tuned semantic segmentation model. To
assess aesthetic preferences, dominant colors are extracted using a clustering
method, and their spatial distribution across quarters is analyzed. Color
themes are further compared between social media photos and real-world street
views, revealing notable shifts. This divergence highlights potential gaps
between visual expectations and the built environment, reflecting both
stylistic preferences and perceptual bias. Tourist reviews are evaluated
through a hybrid sentiment analysis approach combining a rule-based method and
a multi-task BERT model. Satisfaction is assessed across four dimensions:
tourist activities, built environment, service facilities, and business
formats. The results reveal spatial variations in aesthetic appeal and
emotional response. Rather than focusing on a single technical innovation, this
framework offers an integrated, data-driven approach to decoding tourist
perception and contributes to informed decision-making in tourism, heritage
conservation, and the design of aesthetically engaging public spaces.

</details>


### [377] [Continuous Monitoring of Large-Scale Generative AI via Deterministic Knowledge Graph Structures](https://arxiv.org/abs/2509.03857)
*Kishor Datta Gupta,Mohd Ariful Haque,Hasmot Ali,Marufa Kamal,Syed Bahauddin Alam,Mohammad Ashiqur Rahman*

Main category: cs.AI

TL;DR: 本研究提出了一种使用确定性知识图谱（KG）和大型语言模型（LLM）生成的KG来持续监控和评估生成式AI（GEN AI）可靠性的系统化方法，以解决GEN AI中的幻觉、语义漂移和偏见等问题。


<details>
  <summary>Details</summary>
Motivation: 生成式AI（GEN AI）模型在各个领域带来了革命性的变化，但其可靠性问题（如幻觉、语义漂移和固有偏见）带来了重大挑战。目前，依赖主观人工评估的方法在可扩展性、透明度和有效性方面存在局限性。

Method: 研究提出了一种系统化的方法，结合使用确定性知识图谱（KG）和大型语言模型（LLM）生成的KG来持续监控和评估GEN AI的可靠性。构建了两个并行的KG：一个是通过规则、本体、字典和实体关系提取规则确定的；另一个是动态地从实时文本数据流（如新闻文章）中提取的。利用了KG指标（ICR、IPR、CI）来量化结构偏差和语义差异，并建立动态异常阈值来检测偏差。

Result: 通过一个自动化的实时监控框架，该方法能够持续计算确定性KG和LLM生成的KG之间的偏差。通过基于历史度量分布建立动态异常阈值，能够主动识别和标记显著偏差，从而及时检测语义异常或幻觉。

Conclusion: 这种结构化、由度量驱动的确定性KG与动态生成的KG之间的比较，提供了一个强大且可扩展的评估框架，以应对GEN AI的可靠性挑战。

Abstract: Generative AI (GEN AI) models have revolutionized diverse application domains
but present substantial challenges due to reliability concerns, including
hallucinations, semantic drift, and inherent biases. These models typically
operate as black-boxes, complicating transparent and objective evaluation.
Current evaluation methods primarily depend on subjective human assessment,
limiting scalability, transparency, and effectiveness. This research proposes a
systematic methodology using deterministic and Large Language Model
(LLM)-generated Knowledge Graphs (KGs) to continuously monitor and evaluate GEN
AI reliability. We construct two parallel KGs: (i) a deterministic KG built
using explicit rule-based methods, predefined ontologies, domain-specific
dictionaries, and structured entity-relation extraction rules, and (ii) an
LLM-generated KG dynamically derived from real-time textual data streams such
as live news articles. Utilizing real-time news streams ensures authenticity,
mitigates biases from repetitive training, and prevents adaptive LLMs from
bypassing predefined benchmarks through feedback memorization. To quantify
structural deviations and semantic discrepancies, we employ several established
KG metrics, including Instantiated Class Ratio (ICR), Instantiated Property
Ratio (IPR), and Class Instantiation (CI). An automated real-time monitoring
framework continuously computes deviations between deterministic and
LLM-generated KGs. By establishing dynamic anomaly thresholds based on
historical structural metric distributions, our method proactively identifies
and flags significant deviations, thus promptly detecting semantic anomalies or
hallucinations. This structured, metric-driven comparison between deterministic
and dynamically generated KGs delivers a robust and scalable evaluation
framework.

</details>


### [378] [Expedition & Expansion: Leveraging Semantic Representations for Goal-Directed Exploration in Continuous Cellular Automata](https://arxiv.org/abs/2509.03863)
*Sina Khajehabdollahi,Gautier Hamon,Marko Cvjetko,Pierre-Yves Oudeyer,Clément Moulin-Frier,Cédric Colas*

Main category: cs.AI

TL;DR: E&E是一种结合了新颖性搜索和语言模型引导的探索策略，用于发现连续细胞自动机中更广泛和具有解释性的视觉模式，克服了传统方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统探索方法（如新颖性搜索）在探索连续细胞自动机（CA）的行为空间时，容易陷入局部最优，难以发现远离已知模式的新颖行为。

Method: 提出了一种名为“探险与扩张”（E&E）的混合策略。该策略结合了局部新颖性驱动的扩张和由视觉-语言模型（VLM）引导的、面向目标的探险。VLM被用来生成描述性语言目标，以引导探索过程向着未知的、概念上有意义的区域进行。

Result: 在著名的Flow Lenia（一种具有丰富涌现行为的连续CA）上进行测试，E&E相比现有方法能够持续发现更多样化的解决方案。谱系分析表明，源自探险阶段的解决方案对长期探索有不成比例的积极影响，能够开启新的行为生态位。

Conclusion: E&E策略能够有效突破局部新颖性搜索的瓶颈，以与人类感知对齐且可解释的方式探索行为景观，为人工生命及其他领域的开放式探索提供了新的思路。

Abstract: Discovering diverse visual patterns in continuous cellular automata (CA) is
challenging due to the vastness and redundancy of high-dimensional behavioral
spaces. Traditional exploration methods like Novelty Search (NS) expand locally
by mutating known novel solutions but often plateau when local novelty is
exhausted, failing to reach distant, unexplored regions. We introduce
Expedition and Expansion (E&E), a hybrid strategy where exploration alternates
between local novelty-driven expansions and goal-directed expeditions. During
expeditions, E&E leverages a Vision-Language Model (VLM) to generate linguistic
goals--descriptions of interesting but hypothetical patterns that drive
exploration toward uncharted regions. By operating in semantic spaces that
align with human perception, E&E both evaluates novelty and generates goals in
conceptually meaningful ways, enhancing the interpretability and relevance of
discovered behaviors. Tested on Flow Lenia, a continuous CA known for its rich,
emergent behaviors, E&E consistently uncovers more diverse solutions than
existing exploration methods. A genealogical analysis further reveals that
solutions originating from expeditions disproportionately influence long-term
exploration, unlocking new behavioral niches that serve as stepping stones for
subsequent search. These findings highlight E&E's capacity to break through
local novelty boundaries and explore behavioral landscapes in human-aligned,
interpretable ways, offering a promising template for open-ended exploration in
artificial life and beyond.

</details>


### [379] [FaMA: LLM-Empowered Agentic Assistant for Consumer-to-Consumer Marketplace](https://arxiv.org/abs/2509.03890)
*Yineng Yan,Xidong Wang,Jin Seng Cheng,Ran Hu,Wentao Guan,Nahid Farahmand,Hengte Lin,Yue Li*

Main category: cs.AI

TL;DR: LLM驱动的代理助手FaMA简化了C2C电商平台的交互，提高了效率和用户体验。


<details>
  <summary>Details</summary>
Motivation: 传统的C2C电商平台用户界面复杂，用户（买家和卖家）在执行核心任务时耗时费力。本研究旨在通过引入LLM驱动的代理助手来简化这些交互。

Method: 提出了一种基于LLM的代理助手FaMA，作为市场的新型对话式入口，将主要交互模式从复杂的GUI转变为直观的AI代理。该代理能理解自然语言指令，自动执行关键的高摩擦工作流，例如为卖家更新和续订商品列表、发送批量消息，以及为买家提供对话式搜索以实现更高效的产品发现。

Result: FaMA在解决集市上的复杂任务方面达到了98%的任务成功率，并将交互时间缩短了2倍。

Conclusion: FaMA代表了一种轻量级、更易于访问的替代传统应用程序界面的方法，使买卖双方能够更高效地管理他们的市场活动。

Abstract: The emergence of agentic AI, powered by Large Language Models (LLMs), marks a
paradigm shift from reactive generative systems to proactive, goal-oriented
autonomous agents capable of sophisticated planning, memory, and tool use. This
evolution presents a novel opportunity to address long-standing challenges in
complex digital environments. Core tasks on Consumer-to-Consumer (C2C)
e-commerce platforms often require users to navigate complex Graphical User
Interfaces (GUIs), making the experience time-consuming for both buyers and
sellers. This paper introduces a novel approach to simplify these interactions
through an LLM-powered agentic assistant. This agent functions as a new,
conversational entry point to the marketplace, shifting the primary interaction
model from a complex GUI to an intuitive AI agent. By interpreting natural
language commands, the agent automates key high-friction workflows. For
sellers, this includes simplified updating and renewal of listings, and the
ability to send bulk messages. For buyers, the agent facilitates a more
efficient product discovery process through conversational search. We present
the architecture for Facebook Marketplace Assistant (FaMA), arguing that this
agentic, conversational paradigm provides a lightweight and more accessible
alternative to traditional app interfaces, allowing users to manage their
marketplace activities with greater efficiency. Experiments show FaMA achieves
a 98% task success rate on solving complex tasks on the marketplace and enables
up to a 2x speedup on interaction time.

</details>


### [380] [Handling Infinite Domain Parameters in Planning Through Best-First Search with Delayed Partial Expansions](https://arxiv.org/abs/2509.03953)
*Ángel Aso-Mollar,Diego Aineto,Enrico Scala,Eva Onaindia*

Main category: cs.AI

TL;DR: 本篇论文提出了一种新的方法来处理自动化规划中的控制参数，将其视为搜索空间中的决策点，而不是仅仅作为约束。


<details>
  <summary>Details</summary>
Motivation: 现有的自动化规划方法将控制参数视为附加约束，而不是搜索空间中的决策点，这限制了其处理连续数值决策变量的能力。

Method: 提出了一种高效的最佳优先启发式搜索算法，该算法在控制参数定义的无限决策空间上操作，并利用了延迟部分扩展的概念，即状态不会完全展开，而是逐步展开其后继状态的子集。

Result: 实验结果表明，该新型搜索算法是解决涉及控制参数的规划问题的现有方法的有力竞争者。

Conclusion: 通过将控制参数显式地作为决策点进行处理，并采用延迟部分扩展的搜索策略，可以有效地解决自动化规划问题，并与现有方法竞争。

Abstract: In automated planning, control parameters extend standard action
representations through the introduction of continuous numeric decision
variables. Existing state-of-the-art approaches have primarily handled control
parameters as embedded constraints alongside other temporal and numeric
restrictions, and thus have implicitly treated them as additional constraints
rather than as decision points in the search space. In this paper, we propose
an efficient alternative that explicitly handles control parameters as true
decision points within a systematic search scheme. We develop a best-first,
heuristic search algorithm that operates over infinite decision spaces defined
by control parameters and prove a notion of completeness in the limit under
certain conditions. Our algorithm leverages the concept of delayed partial
expansion, where a state is not fully expanded but instead incrementally
expands a subset of its successors. Our results demonstrate that this novel
search algorithm is a competitive alternative to existing approaches for
solving planning problems involving control parameters.

</details>


### [381] [A Foundation Model for Chest X-ray Interpretation with Grounded Reasoning via Online Reinforcement Learning](https://arxiv.org/abs/2509.03906)
*Qika Lin,Yifan Zhu,Bin Pu,Ling Huang,Haoran Luo,Jingying Ma,Zhen Peng,Tianzhe Zhao,Fangzhi Xu,Jian Zhang,Kai He,Zhonghong Ou,Swapnil Mishra,Mengling Feng*

Main category: cs.AI

TL;DR: DeepMedix-R1是一个用于胸部X光片(CXR)解读的医疗基础模型，它通过逐步训练，在报告生成和视觉问答方面取得了显著的性能提升，并提供可解释的、与图像区域相关的推理步骤，优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 当前的医疗基础模型（FM）在临床应用中存在缺乏透明推理过程和局部可解释性的问题，阻碍了其在临床上的广泛部署。

Method: DeepMedix-R1采用了一个分阶段的训练流程：首先在精选的CXR指令数据上进行微调，然后暴露于高质量的合成推理样本以实现冷启动推理，最后通过在线强化学习进行优化，以提高推理质量和生成性能。该模型为每个查询生成答案以及与图像局部区域相关的推理步骤。

Result: 在报告生成任务上，DeepMedix-R1的性能分别比LLaVA-Rad和MedGemma提高了14.54%和31.32%；在视觉问答任务上，性能分别比MedGemma和CheXagent提高了57.75%和23.06%。此外，与现有的Qwen2.5-VL-7B模型相比，DeepMedix-R1生成的推理步骤在解释性和临床合理性方面表现更优（总体偏好度为0.7416 vs. 0.2584）。

Conclusion: DeepMedix-R1通过提供整体的、透明的、临床可操作的CXR解读能力，推动了医疗FM的发展。

Abstract: Medical foundation models (FMs) have shown tremendous promise amid the rapid
advancements in artificial intelligence (AI) technologies. However, current
medical FMs typically generate answers in a black-box manner, lacking
transparent reasoning processes and locally grounded interpretability, which
hinders their practical clinical deployments. To this end, we introduce
DeepMedix-R1, a holistic medical FM for chest X-ray (CXR) interpretation. It
leverages a sequential training pipeline: initially fine-tuned on curated CXR
instruction data to equip with fundamental CXR interpretation capabilities,
then exposed to high-quality synthetic reasoning samples to enable cold-start
reasoning, and finally refined via online reinforcement learning to enhance
both grounded reasoning quality and generation performance. Thus, the model
produces both an answer and reasoning steps tied to the image's local regions
for each query. Quantitative evaluation demonstrates substantial improvements
in report generation (e.g., 14.54% and 31.32% over LLaVA-Rad and MedGemma) and
visual question answering (e.g., 57.75% and 23.06% over MedGemma and CheXagent)
tasks. To facilitate robust assessment, we propose Report Arena, a benchmarking
framework using advanced language models to evaluate answer quality, further
highlighting the superiority of DeepMedix-R1. Expert review of generated
reasoning steps reveals greater interpretability and clinical plausibility
compared to the established Qwen2.5-VL-7B model (0.7416 vs. 0.2584 overall
preference). Collectively, our work advances medical FM development toward
holistic, transparent, and clinically actionable modeling for CXR
interpretation.

</details>


### [382] [World Model Implanting for Test-time Adaptation of Embodied Agents](https://arxiv.org/abs/2509.03956)
*Minjong Yoo,Jinwoo Jang,Sihyung Yoon,Honguk Woo*

Main category: cs.AI

TL;DR: WorMI框架通过结合LLM和领域特定世界模型，实现了具身智能体的跨领域适应性。


<details>
  <summary>Details</summary>
Motivation: 具身AI在没有大量数据收集或重新训练的情况下，鲁棒地适应新领域仍然是一个挑战。

Method: WorMI框架通过测试时组合，无缝植入和移除世界模型，并采用基于原型的世界模型检索方法和世界范围的复合注意力机制来融合领域知识。

Result: 在VirtualHome和ALFWorld基准测试中，WorMI在零样本和少样本场景下表现优于其他LLM方法，证明了其在未见领域上的鲁棒适应性。

Conclusion: WorMI框架能够有效地融合来自多个世界模型的领域特定知识，确保对未见领域具有鲁棒的适应性，在需要适应性和数据效率的具身智能体场景中具有可扩展的实际部署潜力。

Abstract: In embodied AI, a persistent challenge is enabling agents to robustly adapt
to novel domains without requiring extensive data collection or retraining. To
address this, we present a world model implanting framework (WorMI) that
combines the reasoning capabilities of large language models (LLMs) with
independently learned, domain-specific world models through test-time
composition. By allowing seamless implantation and removal of the world models,
the embodied agent's policy achieves and maintains cross-domain adaptability.
In the WorMI framework, we employ a prototype-based world model retrieval
approach, utilizing efficient trajectory-based abstract representation
matching, to incorporate relevant models into test-time composition. We also
develop a world-wise compound attention method that not only integrates the
knowledge from the retrieved world models but also aligns their intermediate
representations with the reasoning model's representation within the agent's
policy. This framework design effectively fuses domain-specific knowledge from
multiple world models, ensuring robust adaptation to unseen domains. We
evaluate our WorMI on the VirtualHome and ALFWorld benchmarks, demonstrating
superior zero-shot and few-shot performance compared to several LLM-based
approaches across a range of unseen domains. These results highlight the
frameworks potential for scalable, real-world deployment in embodied agent
scenarios where adaptability and data efficiency are essential.

</details>


### [383] [Meta-Policy Reflexion: Reusable Reflective Memory and Rule Admissibility for Resource-Efficient LLM Agent](https://arxiv.org/abs/2509.03990)
*Chunlong Wu,Zhibo Qu*

Main category: cs.AI

TL;DR: 本文提出了一种名为元策略反射（MPR）的混合框架，通过将LLM生成的反思整合成结构化的元策略记忆（MPM），并结合软记忆引导解码和硬规则可采信度检查（HAC）两种机制，来解决LLM代理在单任务性能、探索效率和跨任务适应性方面存在的重复失败、效率低下和适应性有限的问题。MPR能够实现可重用的纠错知识外部化、强制执行领域约束以减少不安全或无效动作，并保留基于语言的反思的适应性。实验证明，MPR在提高执行准确性和鲁棒性方面优于Reflexion基线，并且规则可采信度进一步提高了稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM代理在单任务表现优异，但在实际应用中常出现重复失败、探索效率低下以及跨任务适应性受限等问题。现有的反思策略（如Reflexion, ReAct）虽然能改进单次任务的行为，但生成的反思痕迹通常是短暂且特定于任务的，无法跨任务重用。基于强化学习的方法可以生成可迁移的策略，但需要大量的参数更新和计算资源。

Method: 本文提出元策略反射（MPR）框架，该框架将LLM生成反思整合成结构化的、类谓词的元策略记忆（MPM），并通过两种互补的机制在推理时应用该记忆：软记忆引导解码和硬规则可采信度检查（HAC）。MPR在不更新模型权重的情况下外部化可重用的纠错知识，强制执行领域约束以减少不安全或无效动作，并保留基于语言的反思的适应性。最后，在AlfWorld环境中对该方法进行了验证。

Result: 在AlfWorld文本环境中的实验结果表明，与Reflexion基线相比，MPR在执行准确性和鲁棒性方面持续提升。规则可采信度进一步提高了稳定性。文章还对解释这些收益的机制进行了分析，并讨论了可扩展性和失败模式，以及多模态和多智能体扩展的未来方向。

Conclusion: MPR是一种有效的混合框架，通过结构化的记忆和推理时的机制，显著提高了LLM代理在跨任务场景下的性能和稳定性，克服了现有方法的局限性。

Abstract: Large language model (LLM) agents achieve impressive single-task performance
but commonly exhibit repeated failures, inefficient exploration, and limited
cross-task adaptability. Existing reflective strategies (e.g., Reflexion,
ReAct) improve per-episode behavior but typically produce ephemeral,
task-specific traces that are not reused across tasks. Reinforcement-learning
based alternatives can produce transferable policies but require substantial
parameter updates and compute. In this work we introduce Meta-Policy Reflexion
(MPR): a hybrid framework that consolidates LLM-generated reflections into a
structured, predicate-like Meta-Policy Memory (MPM) and applies that memory at
inference time through two complementary mechanisms soft memory-guided decoding
and hard rule admissibility checks(HAC). MPR (i) externalizes reusable
corrective knowledge without model weight updates, (ii) enforces domain
constraints to reduce unsafe or invalid actions, and (iii) retains the
adaptability of language-based reflection. We formalize the MPM representation,
present algorithms for update and decoding, and validate the approach in a
text-based agent environment following the experimental protocol described in
the provided implementation (AlfWorld-based). Empirical results reported in the
supplied material indicate consistent gains in execution accuracy and
robustness when compared to Reflexion baselines; rule admissibility further
improves stability. We analyze mechanisms that explain these gains, discuss
scalability and failure modes, and outline future directions for multimodal and
multi?agent extensions.

</details>


### [384] [AutoPBO: LLM-powered Optimization for Local Search PBO Solvers](https://arxiv.org/abs/2509.04007)
*Jinyuan Li,Yi Chu,Yiwen Sun,Mengchuan Zou,Shaowei Cai*

Main category: cs.AI

TL;DR: AutoPBO是一个利用大型语言模型（LLM）自动优化伪布尔（PB）约束局部搜索求解器的框架。


<details>
  <summary>Details</summary>
Motivation: 目前局部搜索求解器的设计需要大量专家知识和手动调整，而大型语言模型在算法设计自动化方面展现了潜力，但尚未应用于PBO求解器优化。

Method: 提出AutoPBO框架，利用LLM自动增强PBO局部搜索求解器。

Result: 在四个公共基准测试（包括一个真实世界基准、一个PB竞赛基准、一个整数线性规划优化基准和一个构造组合基准）上进行了实验，AutoPBO相比之前的局部搜索方法有显著改进，并且与最先进的竞争对手相比具有竞争力。

Conclusion: AutoPBO为自动设计局部搜索求解器提供了一种有前景的方法。

Abstract: Pseudo-Boolean Optimization (PBO) provides a powerful framework for modeling
combinatorial problems through pseudo-Boolean (PB) constraints. Local search
solvers have shown excellent performance in PBO solving, and their efficiency
is highly dependent on their internal heuristics to guide the search. Still,
their design often requires significant expert effort and manual tuning in
practice. While Large Language Models (LLMs) have demonstrated potential in
automating algorithm design, their application to optimizing PBO solvers
remains unexplored. In this work, we introduce AutoPBO, a novel LLM-powered
framework to automatically enhance PBO local search solvers. We conduct
experiments on a broad range of four public benchmarks, including one
real-world benchmark, a benchmark from PB competition, an integer linear
programming optimization benchmark, and a crafted combinatorial benchmark, to
evaluate the performance improvement achieved by AutoPBO and compare it with
six state-of-the-art competitors, including two local search PBO solvers NuPBO
and OraSLS, two complete PB solvers PBO-IHS and RoundingSat, and two mixed
integer programming (MIP) solvers Gurobi and SCIP. AutoPBO demonstrates
significant improvements over previous local search approaches, while
maintaining competitive performance compared to state-of-the-art competitors.
The results suggest that AutoPBO offers a promising approach to automating
local search solver design.

</details>


### [385] [CoT-Space: A Theoretical Framework for Internal Slow-Thinking via Reinforcement Learning](https://arxiv.org/abs/2509.04027)
*Zeyu Gan,Hao Yi,Yong Liu*

Main category: cs.AI

TL;DR: CoT-Space框架将LLM推理视为在连续语义空间中的优化过程，解决了传统token级RL框架与CoT推理不匹配的理论问题，并解释了‘过度思考’等现象。


<details>
  <summary>Details</summary>
Motivation: 传统token-level RL框架与Chain-of-Thought (CoT)等复杂推理过程的推理级本质不匹配，存在理论差距。

Method: 将LLM推理重新构建为一个在连续的、推理级的语义空间中的优化过程，并从噪声和风险角度进行分析。

Result: 理论上证明了CoT长度收敛是欠拟合和过拟合之间权衡的结果，并通过大量实验进行了验证。

Conclusion: CoT-Space框架不仅为‘过度思考’等经验现象提供了理论解释，还为未来开发更有效、更具泛化性的推理代理奠定了坚实的理论基础。

Abstract: Reinforcement Learning (RL) has become a pivotal approach for enhancing the
reasoning capabilities of Large Language Models (LLMs). However, a significant
theoretical gap persists, as traditional token-level RL frameworks fail to
align with the reasoning-level nature of complex, multi-step thought processes
like Chain-of-Thought (CoT). To address this challenge, we introduce CoT-Space,
a novel theoretical framework that recasts LLM reasoning from a discrete
token-prediction task to an optimization process within a continuous,
reasoning-level semantic space. By analyzing this process from both a noise
perspective and a risk perspective, we demonstrate that the convergence to an
optimal CoT length is a natural consequence of the fundamental trade-off
between underfitting and overfitting. Furthermore, extensive experiments
provide strong empirical validation for our theoretical findings. Our framework
not only provides a coherent explanation for empirical phenomena such as
overthinking but also offers a solid theoretical foundation to guide the future
development of more effective and generalizable reasoning agents.

</details>


### [386] [Intermediate Languages Matter: Formal Languages and LLMs affect Neurosymbolic Reasoning](https://arxiv.org/abs/2509.04083)
*Alexander Beiser,David Penz,Nysret Musliu*

Main category: cs.AI

TL;DR: LLMs在形式推理方面仍有不足，神经符号LLM推理是一种有前景的方法，但其成功因素尚不清楚。本研究表明，形式语言的选择是一个被忽视的关键因素，并提出了“中间语言挑战”。通过对比四种形式语言在三种数据集和七种LLMs上的表现，我们发现形式语言的选择会影响LLMs的句法和语义推理能力，并且这种影响因LLM而异。


<details>
  <summary>Details</summary>
Motivation: 神经符号LLM推理的成功因素尚不明确，本研究旨在探索形式语言的选择对LLM推理能力的影响。

Method: 通过对比四种形式语言在三种数据集和七种LLMs上的表现，分析形式语言的选择对LLM句法和语义推理能力的影响。

Result: 形式语言的选择会影响LLMs的句法和语义推理能力，并且这种影响因LLM而异。

Conclusion: 形式语言的选择是神经符号LLM推理中的一个重要因素，需要仔细考虑以优化LLM的推理性能。

Abstract: Large language models (LLMs) achieve astonishing results on a wide range of
tasks. However, their formal reasoning ability still lags behind. A promising
approach is Neurosymbolic LLM reasoning. It works by using LLMs as translators
from natural to formal languages and symbolic solvers for deriving correct
results. Still, the contributing factors to the success of Neurosymbolic LLM
reasoning remain unclear. This paper demonstrates that one previously
overlooked factor is the choice of the formal language. We introduce the
intermediate language challenge: selecting a suitable formal language for
neurosymbolic reasoning. By comparing four formal languages across three
datasets and seven LLMs, we show that the choice of formal language affects
both syntactic and semantic reasoning capabilities. We also discuss the varying
effects across different LLMs.

</details>


### [387] [Hybrid Reinforcement Learning and Search for Flight Trajectory Planning](https://arxiv.org/abs/2509.04100)
*Alberto Luise,Michele Lombardi,Florent Teichteil Koenigsbuch*

Main category: cs.AI

TL;DR: 该研究结合了强化学习（RL）和基于搜索的路径规划器，用于加速航空公司的飞行路径优化，在紧急情况下能快速重新计算路线。RL 代理预先计算近似最优路径，以约束路径规划求解器，在运行时减小搜索空间，提高优化速度。


<details>
  <summary>Details</summary>
Motivation: 在紧急情况下，需要快速重新计算飞行路径以优化逃生路线。

Method: 训练一个强化学习（RL）代理，根据位置和大气数据预先计算近似最优路径，并利用这些路径来约束底层的路径规划求解器，使其在运行时能在一定范围内找到解决方案，从而有效减小求解器的搜索空间。

Result: 与未加约束的求解器相比，使用该方法可将计算速度提高 50%，同时燃料消耗的偏差通常保持在 1% 以内。

Conclusion: 该方法在保证了近似最优解的前提下，显著提高了路径规划的计算效率，对于需要快速重新规划的紧急情况尤其适用。

Abstract: This paper explores the combination of Reinforcement Learning (RL) and
search-based path planners to speed up the optimization of flight paths for
airliners, where in case of emergency a fast route re-calculation can be
crucial. The fundamental idea is to train an RL Agent to pre-compute
near-optimal paths based on location and atmospheric data and use those at
runtime to constrain the underlying path planning solver and find a solution
within a certain distance from the initial guess. The approach effectively
reduces the size of the solver's search space, significantly speeding up route
optimization. Although global optimality is not guaranteed, empirical results
conducted with Airbus aircraft's performance models show that fuel consumption
remains nearly identical to that of an unconstrained solver, with deviations
typically within 1%. At the same time, computation speed can be improved by up
to 50% as compared to using a conventional solver alone.

</details>


### [388] [Analysis of Bluffing by DQN and CFR in Leduc Hold'em Poker](https://arxiv.org/abs/2509.04125)
*Tarik Zaciragic,Aske Plaat,K. Joost Batenburg*

Main category: cs.AI

TL;DR: DQN and CFR 算法在扑克游戏中都表现出诈唬行为，但方式不同，诈唬成功率相似。


<details>
  <summary>Details</summary>
Motivation: 现有的扑克 AI 研究主要关注胜率，忽略了诈唬这一重要技巧。

Method: 让 DQN 和 CFR 算法在 Leduc Hold'em 扑克游戏中相互对弈，并记录其行为。

Result: DQN 和 CFR 算法都表现出诈唬行为，但诈唬的频率和方式有所不同，然而诈唬的成功率（对手弃牌的比例）却大致相同。

Conclusion: 诈唬是扑克游戏本身的一个基本组成部分，而非特定算法的特性。未来的研究应探索不同的诈唬风格以及在完整扑克游戏中的诈唬行为。

Abstract: In the game of poker, being unpredictable, or bluffing, is an essential
skill. When humans play poker, they bluff. However, most works on
computer-poker focus on performance metrics such as win rates, while bluffing
is overlooked. In this paper we study whether two popular algorithms, DQN
(based on reinforcement learning) and CFR (based on game theory), exhibit
bluffing behavior in Leduc Hold'em, a simplified version of poker. We designed
an experiment where we let the DQN and CFR agent play against each other while
we log their actions. We find that both DQN and CFR exhibit bluffing behavior,
but they do so in different ways. Although both attempt to perform bluffs at
different rates, the percentage of successful bluffs (where the opponent folds)
is roughly the same. This suggests that bluffing is an essential aspect of the
game, not of the algorithm. Future work should look at different bluffing
styles and at the full game of poker. Code at
https://github.com/TarikZ03/Bluffing-by-DQN-and-CFR-in-Leduc-Hold-em-Poker-Codebase.

</details>


### [389] [The human biological advantage over AI](https://arxiv.org/abs/2509.04130)
*William Stewart*

Main category: cs.AI

TL;DR: AI不太可能超越人类，因为它们缺乏中枢神经系统（CNS），而CNS是情感和道德的基础。


<details>
  <summary>Details</summary>
Motivation: 探讨人工智能（AI）最终可能超越人类的可能性，以及由此产生的对宇宙领导权的潜在影响。

Method: 通过对比AI和人类的生物学基础（大脑与中枢神经系统），论证了情感和对后果的理解在领导力中的关键作用。

Result: AI可能在许多方面超越人类，但由于缺乏中枢神经系统，它们无法真正理解和体验情感，这限制了它们在道德和领导力方面的潜力。

Conclusion: 人类基于DNA和中枢神经系统的生物学特性，在情感理解和道德判断方面具有AI无法比拟的优势，因此人类将继续在宇宙中扮演领导者的角色，而非AI。

Abstract: Recent advances in AI raise the possibility that AI systems will one day be
able to do anything humans can do, only better. If artificial general
intelligence (AGI) is achieved, AI systems may be able to understand, reason,
problem solve, create, and evolve at a level and speed that humans will
increasingly be unable to match, or even understand. These possibilities raise
a natural question as to whether AI will eventually become superior to humans,
a successor "digital species", with a rightful claim to assume leadership of
the universe. However, a deeper consideration suggests the overlooked
differentiator between human beings and AI is not the brain, but the central
nervous system (CNS), providing us with an immersive integration with physical
reality. It is our CNS that enables us to experience emotion including pain,
joy, suffering, and love, and therefore to fully appreciate the consequences of
our actions on the world around us. And that emotional understanding of the
consequences of our actions is what is required to be able to develop
sustainable ethical systems, and so be fully qualified to be the leaders of the
universe. A CNS cannot be manufactured or simulated; it must be grown as a
biological construct. And so, even the development of consciousness will not be
sufficient to make AI systems superior to humans. AI systems may become more
capable than humans on almost every measure and transform our society. However,
the best foundation for leadership of our universe will always be DNA, not
silicon.

</details>


### [390] [Towards an Action-Centric Ontology for Cooking Procedures Using Temporal Graphs](https://arxiv.org/abs/2509.04159)
*Aarush Kumbhakern,Saransh Kumar Gupta,Lipika Dey,Partha Pratim Das*

Main category: cs.AI

TL;DR: 提出了一个领域特定语言（DSL）来将烹饪过程表示为有向动作图，以应对烹饪过程的复杂性和模糊性，并为自动化的烹饪分析和执行奠定基础。


<details>
  <summary>Details</summary>
Motivation: 由于烹饪过程固有的复杂性和模糊性，将其形式化一直是一项挑战。

Method: 引入了一个可扩展的领域特定语言（DSL），将食谱表示为有向动作图，能够捕捉过程、转移、环境、并发和组合结构。

Result: 通过对英式全套早餐食谱的初步手动评估，证明了该DSL的表达能力和作为未来自动化食谱分析和执行工具的适用性。

Conclusion: 这项工作代表了朝着烹饪动作中心本体迈出的初步步骤，利用时间图实现结构化的机器理解、精确解释和可扩展的自动化，适用于家庭厨房和专业烹饪环境。

Abstract: Formalizing cooking procedures remains a challenging task due to their
inherent complexity and ambiguity. We introduce an extensible domain-specific
language for representing recipes as directed action graphs, capturing
processes, transfers, environments, concurrency, and compositional structure.
Our approach enables precise, modular modeling of complex culinary workflows.
Initial manual evaluation on a full English breakfast recipe demonstrates the
DSL's expressiveness and suitability for future automated recipe analysis and
execution. This work represents initial steps towards an action-centric
ontology for cooking, using temporal graphs to enable structured machine
understanding, precise interpretation, and scalable automation of culinary
processes - both in home kitchens and professional culinary settings.

</details>


### [391] [Evaluating Quality of Gaming Narratives Co-created with AI](https://arxiv.org/abs/2509.04239)
*Arturo Valdivia,Paolo Burelli*

Main category: cs.AI

TL;DR: 本研究提出了一种结构化方法，利用德尔菲研究和叙事设计专家小组来评估AI生成的游戏叙事。


<details>
  <summary>Details</summary>
Motivation: 为了解决AI生成游戏叙事质量评估的挑战，本研究旨在为游戏开发者提供一个框架，以了解哪些叙事质量维度对玩家满意度影响最大，从而指导他们与生成式AI共同创作游戏叙事。

Method: 本研究采用了德尔菲研究方法，并结合了叙事设计专家的意见。研究内容包括从现有文献和专家见解中提取故事质量维度，并将这些维度映射到Kano模型框架中，以分析它们对玩家满意度的影响。

Result: 该方法能够将AI生成游戏叙事的质量维度与玩家满意度进行关联，为游戏开发者提供关于优先考虑哪些质量方面的指导。

Conclusion: 本研究提出的结构化方法能够有效地评估AI生成游戏叙事，并通过Kano模型为游戏开发者提供了关于如何与生成式AI协同创作高质量游戏叙事的实用见解。

Abstract: This paper proposes a structured methodology to evaluate AI-generated game
narratives, leveraging the Delphi study structure with a panel of narrative
design experts. Our approach synthesizes story quality dimensions from
literature and expert insights, mapping them into the Kano model framework to
understand their impact on player satisfaction. The results can inform game
developers on prioritizing quality aspects when co-creating game narratives
with generative AI.

</details>


### [392] [EvoEmo: Towards Evolved Emotional Policies for LLM Agents in Multi-Turn Negotiation](https://arxiv.org/abs/2509.04310)
*Yunbo Long,Liming Xu,Lukas Beckenbauer,Yuhan Liu,Alexandra Brintrup*

Main category: cs.AI

TL;DR: EvoEmo是一个结合了进化强化学习和马尔可夫决策过程的框架，用于优化大型语言模型在多轮谈判中的动态情绪表达，以提高谈判成功率、效率和买家节省。ansir=


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在谈判中往往忽略了情绪的功能作用，容易受到对手的操纵和策略性剥削。

Method: 提出EvoEmo框架，将情绪状态转移建模为马尔可夫决策过程，并采用基于种群的遗传优化来进化高回报的情绪策略。

Result: 在包含两种基线（普通策略和固定情绪策略）的评估框架下，EvoEmo在谈判成功率、效率和买家节省方面均优于基线。

Conclusion: 自适应的情绪表达对于实现更有效的大型语言模型在多轮谈判中至关重要。

Abstract: Recent research on Chain-of-Thought (CoT) reasoning in Large Language Models
(LLMs) has demonstrated that agents can engage in \textit{complex},
\textit{multi-turn} negotiations, opening new avenues for agentic AI. However,
existing LLM agents largely overlook the functional role of emotions in such
negotiations, instead generating passive, preference-driven emotional responses
that make them vulnerable to manipulation and strategic exploitation by
adversarial counterparts. To address this gap, we present EvoEmo, an
evolutionary reinforcement learning framework that optimizes dynamic emotional
expression in negotiations. EvoEmo models emotional state transitions as a
Markov Decision Process and employs population-based genetic optimization to
evolve high-reward emotion policies across diverse negotiation scenarios. We
further propose an evaluation framework with two baselines -- vanilla
strategies and fixed-emotion strategies -- for benchmarking emotion-aware
negotiation. Extensive experiments and ablation studies show that EvoEmo
consistently outperforms both baselines, achieving higher success rates, higher
efficiency, and increased buyer savings. This findings highlight the importance
of adaptive emotional expression in enabling more effective LLM agents for
multi-turn negotiation.

</details>


### [393] [Improving Robustness of AlphaZero Algorithms to Test-Time Environment Changes](https://arxiv.org/abs/2509.04317)
*Isidoro Tamassia,Wendelin Böhmer*

Main category: cs.AI

TL;DR: AlphaZero在测试环境中表现不佳，但通过一些简单的修改可以大大提高其性能。


<details>
  <summary>Details</summary>
Motivation: 在测试环境中，AlphaZero代理的可部署性有限，因为测试环境可能与训练环境不同。

Method: 通过对标准AlphaZero框架进行简单修改，以提高其在变化的环境中的性能。

Result: 即使在规划预算有限的情况下，修改后的AlphaZero框架的性能也得到了显著提升。

Conclusion: 对AlphaZero框架进行修改可以显著提高其在不同测试环境中的性能。

Abstract: The AlphaZero framework provides a standard way of combining Monte Carlo
planning with prior knowledge provided by a previously trained policy-value
neural network. AlphaZero usually assumes that the environment on which the
neural network was trained will not change at test time, which constrains its
applicability. In this paper, we analyze the problem of deploying AlphaZero
agents in potentially changed test environments and demonstrate how the
combination of simple modifications to the standard framework can significantly
boost performance, even in settings with a low planning budget available. The
code is publicly available on GitHub.

</details>


### [394] [ArcMemo: Abstract Reasoning Composition with Lifelong LLM Memory](https://arxiv.org/abs/2509.04439)
*Matthew Ho,Chen Si,Zhaoxiang Feng,Fangxu Yu,Zhijian Liu,Zhiting Hu,Lianhui Qin*

Main category: cs.AI

TL;DR: 本研究提出了一种基于概念提取的外部记忆方法，用于增强大型语言模型的推理能力和持续学习能力，并在ARC-AGI基准测试中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在推理过程中产生的宝贵见解通常在每次查询后被丢弃。本研究旨在通过引入一种外部记忆机制，使这些见解能够被持久化和复用，从而提升模型的推理能力和实现持续学习。

Method: 本研究提出了一种将实例级别的记忆转化为概念级别记忆的方法。该方法通过从推理过程中提取抽象概念，并以自然语言形式存储，使得这些概念可以在未来的查询中被检索和整合，从而实现无需权重更新的测试时持续学习。研究中还设计了新的策略用于从推理过程中提取和检索记忆条目，以促进记忆的复用和扩展。

Result: 在ARC-AGI基准测试中，本研究提出的方法相比于强基线模型取得了7.5%的相对性能提升，并且该方法在推理计算量增加时性能持续提升。研究发现，抽象概念作为记忆形式最为有效，在所有测试的推理计算量尺度下均优于基线。此外，测试时动态更新记忆的性能优于固定记忆，验证了通过解决更多问题和抽象更多模式到记忆中可以实现进一步的自我提升。

Conclusion: 本研究提出的基于概念的外部记忆方法能够有效提升大型语言模型的推理能力，并实现测试时的持续学习。通过将实例级记忆转化为可复用的概念级记忆，模型能够从过去的经验中学习并不断改进其性能。该方法在ARC-AGI基准测试中取得了显著成果，并验证了动态更新记忆和抽象概念的重要性。

Abstract: While inference-time scaling enables LLMs to carry out increasingly long and
capable reasoning traces, the patterns and insights uncovered during these
traces are immediately discarded once the context window is reset for a new
query. External memory is a natural way to persist these discoveries, and
recent work has shown clear benefits for reasoning-intensive tasks. We see an
opportunity to make such memories more broadly reusable and scalable by moving
beyond instance-based memory entries (e.g. exact query/response pairs, or
summaries tightly coupled with the original problem context) toward
concept-level memory: reusable, modular abstractions distilled from solution
traces and stored in natural language. For future queries, relevant concepts
are selectively retrieved and integrated into the prompt, enabling test-time
continual learning without weight updates. Our design introduces new strategies
for abstracting takeaways from rollouts and retrieving entries for new queries,
promoting reuse and allowing memory to expand with additional experiences. On
the challenging ARC-AGI benchmark, our method yields a 7.5% relative gain over
a strong no-memory baseline with performance continuing to scale with inference
compute. We find abstract concepts to be the most consistent memory design,
outscoring the baseline at all tested inference compute scales. Moreover, we
confirm that dynamically updating memory during test-time outperforms an
otherwise identical fixed memory setting with additional attempts, supporting
the hypothesis that solving more problems and abstracting more patterns to
memory enables further solutions in a form of self-improvement. Code available
at https://github.com/matt-seb-ho/arc_memo.

</details>
